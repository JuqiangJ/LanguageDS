FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Stroganova, TA
   Komarov, KS
   Sysoeva, OV
   Goiaeva, DE
   Obukhova, TS
   Ovsiannikova, TM
   Prokofyev, AO
   Orekhova, EV
AF Stroganova, T. A.
   Komarov, K. S.
   Sysoeva, O. V.
   Goiaeva, D. E.
   Obukhova, T. S.
   Ovsiannikova, T. M.
   Prokofyev, A. O.
   Orekhova, E. V.
TI Left hemispheric deficit in the sustained neuromagnetic response to
   periodic click trains in children with ASD
SO MOLECULAR AUTISM
LA English
DT Article
DE Autism spectrum disorders (ASD); Magnetoencephalogram (MEG); Pitch
   processing; 40&#160; Hz clicks; Auditory steady state response (ASSR);
   Sustained field (SF); Children
ID HUMAN AUDITORY-CORTEX; STEADY-STATE RESPONSE; TEMPORAL REGULARITY;
   SPEECH SOUNDS; HESCHLS GYRUS; AUTISM; PITCH; ASYMMETRY; MEG; PERCEPTION
AB Background Deficits in perception and production of vocal pitch are often observed in people with autism spectrum disorder (ASD), but the neural basis of these deficits is unknown. In magnetoencephalogram (MEG), spectrally complex periodic sounds trigger two continuous neural responses-the auditory steady state response (ASSR) and the sustained field (SF). It has been shown that the SF in neurotypical individuals is associated with low-level analysis of pitch in the 'pitch processing center' of the Heschl's gyrus. Therefore, alternations in this auditory response may reflect atypical processing of vocal pitch. The SF, however, has never been studied in people with ASD. Methods We used MEG and individual brain models to investigate the ASSR and SF evoked by monaural 40 Hz click trains in boys with ASD (N = 35) and neurotypical (NT) boys (N = 35) aged 7-12-years. Results In agreement with the previous research in adults, the cortical sources of the SF in children were located in the left and right Heschl's gyri, anterolateral to those of the ASSR. In both groups, the SF and ASSR dominated in the right hemisphere and were higher in the hemisphere contralateral to the stimulated ear. The ASSR increased with age in both NT and ASD children and did not differ between the groups. The SF amplitude did not significantly change between the ages of 7 and 12 years. It was moderately attenuated in both hemispheres and was markedly delayed and displaced in the left hemisphere in boys with ASD. The SF delay in participants with ASD was present irrespective of their intelligence level and severity of autism symptoms. Limitations We did not test the language abilities of our participants. Therefore, the link between SF and processing of vocal pitch in children with ASD remains speculative. Conclusion Children with ASD demonstrate atypical processing of spectrally complex periodic sound at the level of the core auditory cortex of the left-hemisphere. The observed neural deficit may contribute to speech perception difficulties experienced by children with ASD, including their poor perception and production of linguistic prosody.
C1 [Stroganova, T. A.; Komarov, K. S.; Goiaeva, D. E.; Obukhova, T. S.; Ovsiannikova, T. M.; Prokofyev, A. O.; Orekhova, E. V.] Moscow State Univ Psychol & Educ, MEG Ctr, Ctr Neurocognit Res, Moscow, Russia.
   [Orekhova, E. V.] Univ Gothenburg, Sahlgrenska Acad, MedTech West, Gothenburg, Sweden.
   [Orekhova, E. V.] Univ Gothenburg, Sahlgrenska Acad, Inst Neurosci & Physiol, Gothenburg, Sweden.
   [Sysoeva, O. V.] Russian Acad Sci, Inst Higher Nervous Act, Moscow, Russia.
RP Orekhova, EV (corresponding author), Moscow State Univ Psychol & Educ, MEG Ctr, Ctr Neurocognit Res, Moscow, Russia.
EM Orekhova.elena@gnc.gu.se
RI Orekhova, Elena/S-9043-2018
OI Orekhova, Elena/0000-0003-0950-1613
FU Gothenburg University Library; Moscow State University of Psychology and
   Education (MSUPE); Charity Foundation "Way Out"
FX Open Access funding provided by Gothenburg University Library. This work
   has been supported by the research grant from The Moscow State
   University of Psychology and Education (MSUPE). The author TAS was
   supported by the Charity Foundation "Way Out".
CR Abdul-Kareem IA, 2008, J MAGN RESON IMAGING, V28, P287, DOI 10.1002/jmri.21445
   American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU
   An JY, 2016, NEUROSCI BIOBEHAV R, V68, P442, DOI 10.1016/j.neubiorev.2016.06.013
   Auyeung B, 2008, J AUTISM DEV DISORD, V38, P1230, DOI 10.1007/s10803-007-0504-z
   Belyk M, 2014, SOC COGN AFFECT NEUR, V9, P1395, DOI 10.1093/scan/nst124
   Bendor D, 2007, NAT NEUROSCI, V10, P763, DOI 10.1038/nn1888
   Bendor D, 2006, CURR OPIN NEUROBIOL, V16, P391, DOI 10.1016/j.conb.2006.07.001
   Bendor D, 2010, J NEUROPHYSIOL, V103, P1809, DOI 10.1152/jn.00281.2009
   Berument SK, 1999, BRIT J PSYCHIAT, V175, P444, DOI 10.1192/bjp.175.5.444
   Boddaert N, 2004, NEUROIMAGE, V23, P364, DOI 10.1016/j.neuroimage.2004.06.016
   Brugge JF, 2009, J NEUROPHYSIOL, V102, P2358, DOI 10.1152/jn.91346.2008
   Button KS, 2013, NAT REV NEUROSCI, V14, P365, DOI 10.1038/nrn3475
   Cho RY, 2015, CEREB CORTEX, V25, P1509, DOI 10.1093/cercor/bht341
   Constantino J.N., 2012, SOCIAL RESPONSIVENES
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   De Stefano LA, 2019, FRONT INTEGR NEUROSC, V13, DOI 10.3389/fnint.2019.00034
   Destrieux C, 2010, NEUROIMAGE, V53, P1, DOI 10.1016/j.neuroimage.2010.06.010
   Diehl JJ, 2013, APPL PSYCHOLINGUIST, V34, P135, DOI 10.1017/S0142716411000646
   Edgar JC, 2016, DEV NEUROSCI-BASEL, V38, P1, DOI 10.1159/000441943
   Edgar JC, 2015, J AUTISM DEV DISORD, V45, P395, DOI 10.1007/s10803-013-1904-x
   Eyler LT, 2012, BRAIN, V135, P949, DOI 10.1093/brain/awr364
   Floris DL, 2016, HUM BRAIN MAPP, V37, P230, DOI 10.1002/hbm.23023
   Gage NM, 2009, J NEURODEV DISORD, V1, P205, DOI 10.1007/s11689-009-9010-2
   Ghitza O, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00238
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Gomot M, 2002, PSYCHOPHYSIOLOGY, V39, P577, DOI 10.1017/S0048577202394058
   Gramfort A, 2014, NEUROIMAGE, V86, P446, DOI 10.1016/j.neuroimage.2013.10.027
   Gutschalk A, 2004, NEUROIMAGE, V22, P755, DOI 10.1016/j.neuroimage.2004.01.025
   Gutschalk A, 2002, NEUROIMAGE, V15, P207, DOI 10.1006/nimg.2001.0949
   Gutschalk A, 2011, NEUROIMAGE, V56, P1578, DOI 10.1016/j.neuroimage.2011.02.026
   Gwilliams L, 2016, NEUROIMAGE, V132, P320, DOI 10.1016/j.neuroimage.2016.02.057
   Hackett TA, 2001, J COMP NEUROL, V441, P197, DOI 10.1002/cne.1407
   Heaton P, 2008, COGN NEUROPSYCHOL, V25, P771, DOI 10.1080/02643290802336277
   Herbert MR, 2002, ANN NEUROL, V52, P588, DOI 10.1002/ana.10349
   Herdman AT, 2011, BRAIN TOPOGR, V24, P271, DOI 10.1007/s10548-011-0182-1
   Huang MX, 1999, PHYS MED BIOL, V44, P423, DOI 10.1088/0031-9155/44/2/010
   Humphries C, 2010, NEUROIMAGE, V50, P1202, DOI 10.1016/j.neuroimage.2010.01.046
   Hyde KL, 2010, HUM BRAIN MAPP, V31, P556, DOI 10.1002/hbm.20887
   Jasmin K, 2019, NAT REV NEUROSCI, V20, P425, DOI 10.1038/s41583-019-0160-2
   Jiang J, 2015, J AUTISM DEV DISORD, V45, P2067, DOI 10.1007/s10803-015-2370-4
   Johnsrude IS, 2000, BRAIN, V123, P155, DOI 10.1093/brain/123.1.155
   Kaufman AS, 2004, KABC 2 KAUFMAN ASSES
   Keceli S, 2015, BRAIN TOPOGR, V28, P459, DOI 10.1007/s10548-013-0300-3
   Khader P, 2008, INT J PSYCHOPHYSIOL, V67, P252, DOI 10.1016/j.ijpsycho.2007.05.018
   Krumbholz K, 2000, J ACOUST SOC AM, V108, P1170, DOI 10.1121/1.1287843
   Lakens D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00863
   Lepisto T, 2005, BRAIN RES, V1066, P147, DOI 10.1016/j.brainres.2005.10.052
   Mamashli F, 2017, AUTISM RES, V10, P631, DOI 10.1002/aur.1714
   Marie D, 2015, BRAIN STRUCT FUNCT, V220, P729, DOI 10.1007/s00429-013-0680-x
   Maris E, 2007, J NEUROSCI METH, V163, P161, DOI 10.1016/j.jneumeth.2007.02.011
   McCann J, 2007, INT J LANG COMM DIS, V42, P682, DOI 10.1080/13682820601170102
   Muthukumaraswamy SD, 2014, J PSYCHOPHARMACOL, V28, P815, DOI 10.1177/0269881114536790
   Nakai Y, 2014, BRAIN DEV-JPN, V36, P516, DOI 10.1016/j.braindev.2013.07.006
   Okamoto H, 2009, CEREB CORTEX, V19, P2290, DOI 10.1093/cercor/bhn245
   Ono Y, 2020, PSYCHIAT CLIN NEUROS, V74, P354, DOI 10.1111/pcn.12998
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Orekhova EV, 2009, CLIN NEUROPHYSIOL, V120, P520, DOI 10.1016/j.clinph.2008.12.034
   Orekhova EV, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00034
   Orekhova EV, 2013, BRAIN TOPOGR, V26, P410, DOI 10.1007/s10548-012-0262-x
   Orekhova EV, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0039906
   PANTEV C, 1994, ELECTROEN CLIN NEURO, V90, P82, DOI 10.1016/0013-4694(94)90115-5
   Parviainen T, 2019, HUM BRAIN MAPP, V40, P2699, DOI 10.1002/hbm.24553
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P5
   Patel SP, 2020, J AUTISM DEV DISORD, V50, P3032, DOI 10.1007/s10803-020-04392-9
   Patterson RD, 2002, NEURON, V36, P767, DOI 10.1016/S0896-6273(02)01060-7
   Peppe S, 2007, J SPEECH LANG HEAR R, V50, P1015, DOI 10.1044/1092-4388(2007/071)
   Ponton C, 2002, CLIN NEUROPHYSIOL, V113, P407, DOI 10.1016/S1388-2457(01)00733-7
   Postema MC, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13005-8
   Poulsen C, 2009, DEVELOPMENTAL SCI, V12, P220, DOI 10.1111/j.1467-7687.2008.00760.x
   Puts DA, 2006, EVOL HUM BEHAV, V27, P283, DOI 10.1016/j.evolhumbehav.2005.11.003
   Roberts TPL, 2019, MOL AUTISM, V10, DOI 10.1186/s13229-019-0283-3
   Roberts TPL, 2010, AUTISM RES, V3, P8, DOI 10.1002/aur.111
   Rojas DC, 2006, CLIN NEUROPHYSIOL, V117, P110, DOI 10.1016/j.clinph.2005.08.032
   Rojas DC, 2011, MOL AUTISM, V2, DOI 10.1186/2040-2392-2-11
   Rojas DC, 2008, BMC PSYCHIATRY, V8, DOI 10.1186/1471-244X-8-66
   Rosanova M, 2009, J NEUROSCI, V29, P7679, DOI 10.1523/JNEUROSCI.0445-09.2009
   Ross B, 2005, CEREB CORTEX, V15, P2029, DOI 10.1093/cercor/bhi078
   Ross B, 2002, HEARING RES, V165, P68, DOI 10.1016/S0378-5955(02)00285-X
   Ruhnau P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00717
   Schneider P, 2005, NAT NEUROSCI, V8, P1241, DOI 10.1038/nn1530
   Schonwiesner M, 2005, EUR J NEUROSCI, V22, P1521, DOI 10.1111/j.1460-9568.2005.04315.x
   Schwartz S, 2018, NEUROSCI BIOBEHAV R, V87, P106, DOI 10.1016/j.neubiorev.2018.01.008
   Scott SK, 2013, BRAIN LANG, V127, P36, DOI 10.1016/j.bandl.2013.07.006
   Seymour RA, 2020, MOL AUTISM, V11, DOI 10.1186/s13229-020-00357-y
   Sivarao DV, 2016, NEUROPSYCHOPHARMACOL, V41, P2232, DOI 10.1038/npp.2016.17
   Spencer KM, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-85
   Stefanatos GA, 2008, NEUROPSYCHOLOGIA, V46, P301, DOI 10.1016/j.neuropsychologia.2007.07.008
   Steinmann I, 2011, NEUROIMAGE, V54, P495, DOI 10.1016/j.neuroimage.2010.07.064
   Stroganova TA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0069100
   Tadel F, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/879716
   Tager-Flusberg H, 2003, PHILOS T R SOC B, V358, P303, DOI 10.1098/rstb.2002.1198
   Tan HRM, 2015, NEUROIMAGE, V122, P417, DOI 10.1016/j.neuroimage.2015.07.055
   Tang HZ, 2016, NEUROIMAGE, V128, P32, DOI 10.1016/j.neuroimage.2015.12.053
   Thune H, 2016, JAMA PSYCHIAT, V73, P1145, DOI 10.1001/jamapsychiatry.2016.2619
   Walker KMM, 2011, HEARING RES, V271, P74, DOI 10.1016/j.heares.2010.04.015
   Wang XQ, 2018, ANNU REV NEUROSCI, V41, P527, DOI 10.1146/annurev-neuro-072116-031302
   Wang YC, 2019, STRESS, V22, P492, DOI 10.1080/10253890.2019.1583203
   Whitehouse AJO, 2008, DEVELOPMENTAL SCI, V11, P516, DOI 10.1111/j.1467-7687.2008.00697.x
   Wilson TW, 2007, BIOL PSYCHIAT, V62, P192, DOI 10.1016/j.biopsych.2006.07.002
   Wong PCM, 2008, CEREB CORTEX, V18, P828, DOI 10.1093/cercor/bhm115
   Yu LD, 2015, J AUTISM DEV DISORD, V45, P3656, DOI 10.1007/s10803-015-2510-x
NR 101
TC 0
Z9 0
U1 0
U2 0
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2040-2392
J9 MOL AUTISM
JI Mol. Autism
PD DEC 31
PY 2020
VL 11
IS 1
AR 100
DI 10.1186/s13229-020-00408-4
PG 22
WC Genetics & Heredity; Neurosciences
SC Genetics & Heredity; Neurosciences & Neurology
GA PM8GO
UT WOS:000604030500001
PM 33384021
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Cummings, AE
   Ogiela, DA
   Wu, YC
AF Cummings, Alycia E.
   Ogiela, Diane A.
   Wu, Ying C.
TI Evidence for [Coronal] Underspecification in Typical and Atypical
   Phonological Development
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE ERP; underspecification; MMN; phonology; children; phonological disorder
ID MISMATCH NEGATIVITY MMN; SPEECH-PERCEPTION; FREQUENCY DISCRIMINATION;
   NEUROBIOLOGICAL EVIDENCE; PHONEME REPRESENTATIONS; PROCESSING DEFICITS;
   CONVERGING EVIDENCE; EVOKED-POTENTIALS; LANGUAGE; CHILDREN
AB The Featurally Underspecified Lexicon (FUL) theory predicts that [coronal] is the language universal default place of articulation for phonemes. This assumption has been consistently supported with adult behavioral and event-related potential (ERP) data; however, this underspecification claim has not been tested in developmental populations. The purpose of this study was to determine whether children demonstrate [coronal] underspecification patterns similar to those of adults. Two English consonants differing in place of articulation, [labial] /b/ and [coronal] /d/, were presented to 24 children (ages 4-6 years) characterized by either a typically developing phonological system (TD) or a phonological disorder (PD). Two syllables, /balpha/ and /dalpha/, were presented in an ERP oddball paradigm where both syllables served as the standard and deviant stimulus in opposite stimulus sets. Underspecification was examined with three analyses: traditional mean amplitude measurements, cluster-based permutation tests, and single-trial general linear model (GLM) analyses of single-subject data. Contrary to previous adult findings, children with PD demonstrated a large positive mismatch response (PMR) to /balpha/ while the children with TD exhibited a negative mismatch response (MMN); significant group differences were not observed in the /dalpha/ responses. Moreover, the /balpha/ deviant ERP response was significantly larger in the TD children than in the children with PD. At the single-subject level, more children demonstrated mismatch responses to /dalpha/ than to /balpha/, though some children had a /balpha/ mismatch response and no /dalpha/ mismatch response. While both groups of children demonstrated similar responses to the underspecified /dalpha/, their neural responses to the more specified /balpha/ varied. These findings are interpreted within a proposed developmental model of phonological underspecification, wherein children with PD are functioning at a developmentally less mature stage of phonological acquisition than their same-aged TD peers. Thus, phonological underspecification is a phenomenon that likely develops over time with experience and exposure to language.
C1 [Cummings, Alycia E.; Ogiela, Diane A.] Idaho State Univ, Dept Commun Sci & Disorders, Meridian, ID 83642 USA.
   [Wu, Ying C.] Univ Calif San Diego, Swartz Ctr Computat Neurosci, San Diego, CA 92103 USA.
RP Cummings, AE (corresponding author), Idaho State Univ, Dept Commun Sci & Disorders, Meridian, ID 83642 USA.
EM cummalyc@isu.edu
FU NIH from the National Institute on Deafness and Other Communication
   Disorders [R15DC013359]; NSFNational Science Foundation (NSF) [1540943];
   Idaho State University
FX This research was supported by NIH grant R15DC013359 (from the National
   Institute on Deafness and Other Communication Disorders) awarded to the
   first author. The third author was supported, in part, by NSF grant
   1540943. Open access publication funds were provided by Idaho State
   University as part of the first author's start-up package.
CR Ahmmed AU, 2008, DEV MED CHILD NEUROL, V50, P938, DOI 10.1111/j.1469-8749.2008.03093.x
   Archangeli D., 1988, PHONOLOGY, V5, DOI [DOI 10.1017/S0952675700002268, 10.1017/S0952675700002268]
   ASLIN RN, 1988, ANNU REV PSYCHOL, V39, P435, DOI 10.1146/annurev.psych.39.1.435
   Austin D., 1997, LIFESPAN REFERENCE D
   BERNHARDT B, 1992, CLIN LINGUIST PHONET, V6, P283, DOI 10.3109/02699209208985537
   Boada R, 2006, J EXP CHILD PSYCHOL, V95, P153, DOI 10.1016/j.jecp.2006.04.003
   Bonte ML, 2005, CLIN NEUROPHYSIOL, V116, P2765, DOI 10.1016/j.clinph.2005.08.012
   Bullmore ET, 1999, IEEE T MED IMAGING, V18, P32, DOI 10.1109/42.750253
   Cabbage KL, 2018, LANG SPEECH HEAR SER, V49, P774, DOI 10.1044/2018_LSHSS-DYSLC-18-0008
   Carr KW, 2016, DEV COGN NEUROS-NETH, V17, P76, DOI 10.1016/j.dcn.2015.12.003
   CHANEY C, 1988, J SPEECH HEAR DISORD, V53, P252, DOI 10.1044/jshd.5303.252
   Cheour M, 1998, NAT NEUROSCI, V1, P351, DOI 10.1038/1561
   Cheour M, 2002, SCAND J PSYCHOL, V43, P33, DOI 10.1111/1467-9450.00266
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Clements G. N., 1990, PAPERS LAB PHONOLOGY, P283, DOI DOI 10.1017/CBO9780511627736.017
   Cornell SA, 2013, J EXP PSYCHOL HUMAN, V39, P757, DOI 10.1037/a0030862
   Cornell SA, 2011, BRAIN RES, V1394, P79, DOI 10.1016/j.brainres.2011.04.001
   Crowe K, 2020, AM J SPEECH-LANG PAT, V29, P2155, DOI 10.1044/2020_AJSLP-19-00168
   Cummings A, 2017, J NEUROLINGUIST, V44, P147, DOI 10.1016/j.jneuroling.2017.05.003
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   EIMAS PD, 1975, PERCEPT PSYCHOPHYS, V18, P341, DOI 10.3758/BF03211210
   Elbro C, 2005, SCAND J PSYCHOL, V46, P375, DOI 10.1111/j.1467-9450.2005.00468.x
   Eulitz C, 2004, J COGNITIVE NEUROSCI, V16, P577, DOI 10.1162/089892904323057308
   Froud K, 2012, AM J SPEECH-LANG PAT, V21, P302, DOI 10.1044/1058-0360(2012/11-0003)
   Goldman R., 2015, GOLDMAN FRISTOE TEST, V3rd edition.
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Groppe DM, 2011, PSYCHOPHYSIOLOGY, V48, P1711, DOI 10.1111/j.1469-8986.2011.01273.x
   Hestvik A, 2016, BRAIN LANG, V152, P28, DOI 10.1016/j.bandl.2015.10.007
   International Expert Panel on Multilingual Children's Speech, 2012, MULT CHILDR SPEECH S
   Jung TP, 2000, CLIN NEUROPHYSIOL, V111, P1745, DOI 10.1016/S1388-2457(00)00386-2
   Khan T, 2015, WILEY FINANC SER, P3
   Kiparsky Paul, 1985, PHONOLOGY YB, V2, P85, DOI DOI 10.1017/S0952675700000397
   KORPILAHTI P, 1994, ELECTROEN CLIN NEURO, V91, P256, DOI 10.1016/0013-4694(94)90189-9
   Kral A, 2007, BRAIN RES REV, V56, P259, DOI 10.1016/j.brainresrev.2007.07.021
   Kraus N, 1996, SCIENCE, V273, P971, DOI 10.1126/science.273.5277.971
   Kraus N, 1998, AUDIOL NEURO-OTOL, V3, P168, DOI 10.1159/000013788
   Kraus N, 2001, AUDIOL NEURO-OTOL, V6, P221, DOI 10.1159/000046837
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2010, NEURON, V67, P713, DOI 10.1016/j.neuron.2010.08.038
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 2000, P NATL ACAD SCI USA, V97, P11850, DOI 10.1073/pnas.97.22.11850
   Lahiri A, 2002, PHONOL PHONET, V4-1, P637
   LAHIRI A, 1991, COGNITION, V38, P245, DOI 10.1016/0010-0277(91)90008-R
   Lahiri A, 2010, J PHONETICS, V38, P44, DOI 10.1016/j.wocn.2010.01.002
   Law J, 2000, INT J LANG COMM DIS, V35, P165, DOI 10.1080/136828200247133
   Linnavalli T, 2017, NEUROPSYCHOLOGIA, V101, P76, DOI 10.1016/j.neuropsychologia.2017.05.013
   MACKEN MA, 1980, J LINGUIST, V16, P1, DOI 10.1017/S0022226700006307
   Manly B. F. J., 2006, RANDOMIZATION BOOTST
   Maurer U, 2003, CLIN NEUROPHYSIOL, V114, P808, DOI 10.1016/S1388-2457(03)00032-4
   MCGREGOR KK, 1992, J SPEECH HEAR RES, V35, P596, DOI 10.1044/jshr.3503.596
   McLeod S., 2017, CHILDRENS SPEECH EVI
   McLeod S, 2018, AM J SPEECH-LANG PAT, V27, P1546, DOI 10.1044/2018_AJSLP-17-0100
   MOHANAN KP, 1991, NAT LANG LINGUIST TH, V9, P285, DOI 10.1007/BF00134678
   Mueller JL, 2012, P NATL ACAD SCI USA, V109, P15953, DOI 10.1073/pnas.1204319109
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   NAATANEN R, 1992, NEUROREPORT, V3, P493
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Naatanen R, 2001, PSYCHOPHYSIOLOGY, V38, P1, DOI 10.1017/S0048577201000208
   Nittrouer S, 1997, J ACOUST SOC AM, V101, P2253, DOI 10.1121/1.418207
   Palmer JA, 2008, INT CONF ACOUST SPEE, P1805, DOI 10.1109/ICASSP.2008.4517982
   Pennington BF, 2009, ANNU REV PSYCHOL, V60, P283, DOI 10.1146/annurev.psych.60.110707.163548
   Pernalete C, 2011, CIENC ING, P1, DOI 10.1155/2011/831409
   Phillips C, 2000, J COGNITIVE NEUROSCI, V12, P1038, DOI 10.1162/08989290051137567
   Poeppel D, 2008, PHILOS T R SOC B, V363, P1071, DOI 10.1098/rstb.2007.2160
   Ponton C, 2002, CLIN NEUROPHYSIOL, V113, P407, DOI 10.1016/S1388-2457(01)00733-7
   Ponton CW, 1999, SCAND AUDIOL, V28, P13
   Rinker T, 2007, NEUROSCI LETT, V413, P99, DOI 10.1016/j.neulet.2006.11.033
   ROBBINS J, 1987, J SPEECH HEAR DISORD, V52, P271, DOI 10.1044/jshd.5203.271
   Rousselet GA, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00137
   Rvachew S., 1995, SPEECH PERCEPTION LI, P411
   SAMS M, 1985, ELECTROEN CLIN NEURO, V62, P437, DOI 10.1016/0168-5597(85)90054-1
   Scharinger M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040953
   Scharinger M, 2011, BRAIN LANG, V116, P71, DOI 10.1016/j.bandl.2010.11.002
   Scharinger M, 2010, LANG SPEECH, V53, P245, DOI 10.1177/0023830909357154
   Schluter K, 2016, LANG COGN NEUROSCI, V31, P728, DOI 10.1080/23273798.2016.1151058
   Scott SK, 2004, COGNITION, V92, P13, DOI 10.1016/j.cognition.2002.12.002
   Scott SK, 2012, J COMMUN DISORD, V45, P419, DOI 10.1016/j.jcomdis.2012.06.007
   Shafer VL, 2005, J COGNITIVE NEUROSCI, V17, P1168, DOI 10.1162/0898929054475217
   Sharma M, 2006, CLIN NEUROPHYSIOL, V117, P1130, DOI 10.1016/j.clinph.2006.02.001
   Shriberg LD, 1999, J SPEECH LANG HEAR R, V42, P1461, DOI 10.1044/jslhr.4206.1461
   SHRIBERG LD, 1982, J SPEECH HEAR DISORD, V47, P256, DOI 10.1044/jshd.4703.256
   Steriade D., 1995, HDB PHONOLOGICAL THE, P114, DOI 10.1111/b.9780631201267.1996.00006.x
   Uwer R, 2002, DEV MED CHILD NEUROL, V44, P527
   Vitevitch MS, 2004, BEHAV RES METH INS C, V36, P481, DOI 10.3758/BF03195594
   Volkmer S, 2018, SCHIZOPHR RES, V191, P148, DOI 10.1016/j.schres.2017.07.010
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wilcox R.R., 2005, INTRO ROBUST ESTIMAT, V2nd ed.
   Winkler I, 1999, COGNITIVE BRAIN RES, V7, P357, DOI 10.1016/S0926-6410(98)00039-1
NR 90
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD DEC 22
PY 2020
VL 14
AR 580697
DI 10.3389/fnhum.2020.580697
PG 20
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA PN6SR
UT WOS:000604607200001
PM 33414710
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Scholes, C
   Skipper, JI
   Johnston, A
AF Scholes, Chris
   Skipper, Jeremy, I
   Johnston, Alan
TI The interrelationship between the face and vocal tract configuration
   during audiovisual speech
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
LA English
DT Article
DE audiovisual; speech; PCA
ID HEARING LIPS; PERCEPTION; MODEL; MOTION; INTELLIGIBILITY; RECOGNITION;
   ATTENTION; DEAF
AB It is well established that speech perception is improved when we are able to see the speaker talking along with hearing their voice, especially when the speech is noisy. While we have a good understanding of where speech integration occurs in the brain, it is unclear how visual and auditory cues are combined to improve speech perception. One suggestion is that integration can occur as both visual and auditory cues arise from a common generator: the vocal tract. Here, we investigate whether facial and vocal tract movements are linked during speech production by comparing videos of the face and fast magnetic resonance (MR) image sequences of the vocal tract. The joint variation in the face and vocal tract was extracted using an application of principal components analysis (PCA), and we demonstrate that MR image sequences can be reconstructed with high fidelity using only the facial video and PCA. Reconstruction fidelity was significantly higher when images from the two sequences corresponded in time, and including implicit temporal information by combining contiguous frames also led to a significant increase in fidelity. A "Bubbles" technique was used to identify which areas of the face were important for recovering information about the vocal tract, and vice versa, on a frame-by-frame basis. Our data reveal that there is sufficient information in the face to recover vocal tract shape during speech. In addition, the facial and vocal tract regions that are important for reconstruction are those that are used to generate the acoustic speech signal.
C1 [Scholes, Chris; Johnston, Alan] Univ Nottingham, Sch Psychol, Visual Neurosci Grp, Nottingham NG7 2RD, England.
   [Skipper, Jeremy, I] UCL, Expt Psychol, London WC1H 0AP, England.
RP Scholes, C (corresponding author), Univ Nottingham, Sch Psychol, Visual Neurosci Grp, Nottingham NG7 2RD, England.
EM chris.scholes@nottingham.ac.uk
RI ; Scholes, Chris/A-1437-2019
OI Skipper, Jeremy/0000-0002-5503-764X; Scholes, Chris/0000-0002-1597-3070
FU Engineering and Physical Sciences Research Council New Pathways to
   Hearing grantUK Research & Innovation (UKRI)Engineering & Physical
   Sciences Research Council (EPSRC) [EP/M026965/1]; National Institute for
   Health Research Nottingham Biomedical Research Centre
FX We thank Anh Cat Le Ngo for data collection. C.S., J.I.S., and A.J. were
   supported by an Engineering and Physical Sciences Research Council New
   Pathways to Hearing grant [grant number EP/M026965/1]. A.J. was
   supported by the National Institute for Health Research Nottingham
   Biomedical Research Centre.
CR Alsius A, 2016, ATTEN PERCEPT PSYCHO, V78, P1472, DOI 10.3758/s13414-016-1109-4
   Altieri N, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00678
   Barenholtz E, 2016, COGNITION, V147, P100, DOI 10.1016/j.cognition.2015.11.013
   Berisha F, 2010, J VISION, V10, DOI 10.1167/10.11.27
   Bernstein LE, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00386
   Bernstein LE, 2011, HUM BRAIN MAPP, V32, P1660, DOI 10.1002/hbm.21139
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Burton AM, 2016, COGNITIVE SCI, V40, P202, DOI 10.1111/cogs.12231
   Calvert GA, 2003, J COGNITIVE NEUROSCI, V15, P57, DOI 10.1162/089892903321107828
   Capek CM, 2008, NEUROPSYCHOLOGIA, V46, P1233, DOI 10.1016/j.neuropsychologia.2007.11.026
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Cowe G. A., 2003, THESIS
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Erber NP, 2003, INT J AUDIOL, V42, pS21
   Fowler C. A., 2004, HDB MULTISENSORY PRO, P189
   Gosselin F, 2001, VISION RES, V41, P2261, DOI 10.1016/S0042-6989(01)00097-9
   HALLE M, 1962, IRE T INFORM THEOR, V8, P155, DOI 10.1109/TIT.1962.1057686
   JOHNSTON A, 1992, P ROY SOC B-BIOL SCI, V250, P297, DOI 10.1098/rspb.1992.0162
   Johnston A, 1999, P ROY SOC B-BIOL SCI, V266, P509, DOI 10.1098/rspb.1999.0666
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Kohonen T., 1989, SELF ORG ASS MEMORY, V3rd
   Lansing CR, 1999, J SPEECH LANG HEAR R, V42, P526, DOI 10.1044/jslhr.4203.526
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Pattem AK, 2018, COMPUT SPEECH LANG, V47, P157, DOI 10.1016/j.csl.2017.07.008
   Peelle JE, 2015, CORTEX, V68, P169, DOI 10.1016/j.cortex.2015.03.006
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Santi A, 2003, J COGNITIVE NEUROSCI, V15, P800, DOI 10.1162/089892903322370726
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Stevens K., 1967, MODELS PERCEPTION SP, P88
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vatikiotis-Bateson E, 1998, PERCEPT PSYCHOPHYS, V60, P926, DOI 10.3758/BF03211929
   Worster E, 2018, LANG LEARN, V68, P159, DOI 10.1111/lang.12264
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
NR 41
TC 0
Z9 0
U1 3
U2 3
PU NATL ACAD SCIENCES
PI WASHINGTON
PA 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA
SN 0027-8424
J9 P NATL ACAD SCI USA
JI Proc. Natl. Acad. Sci. U. S. A.
PD DEC 22
PY 2020
VL 117
IS 51
BP 32791
EP 32798
DI 10.1073/pnas.2006192117
PG 8
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA PI8DQ
UT WOS:000601315200072
PM 33293422
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Menashe, S
AF Menashe, Shay
TI Audiovisual processing and selective attention in adult dyslexic
   readers: An event-related potential study
SO DYSLEXIA
LA English
DT Article; Early Access
DE attention; audiovisual; dyslexia; event&#8208; related potentials;
   hemispheres
ID DEVELOPMENTAL DYSLEXIA; SPEECH-PERCEPTION; VISUAL-ATTENTION;
   INTEGRATION; LATERALIZATION; RECOGNITION; MODULATION; CHILDREN;
   EFFICIENCY; ASYNCHRONY
AB Developmental dyslexia is a specific reading disability characterized by decoding and spelling deficits that continue into adulthood. Because reading involves both attentional functions and audiovisual (AV) processing, the aim of this study was to explore the associations between the two factors in adult dyslexic readers. Adult non-impaired and dyslexic readers undertook alphabetic and non-alphabetic tasks, each composed of three experimental blocks. Two experimental blocks contained left and right spatial selective attention manipulations, and another block included central presentations of the stimuli. Event-related potential (ERP) and behavioural parameters were collected and analysed, particularly with respect to the N1-P2 ERP complex. The dyslexic readers showed deviant patterns of amplitudes when it came to alphabetic stimuli processing. However, there was no difference between the two groups with regard to the non-alphabetic stimuli. These results imply that adult dyslexic readers allocate altered attentional resources when it comes to the processing of AV alphabetic stimuli.
C1 [Menashe, Shay] Univ Haifa, Fac Educ, Edmond J Safra Brain Res Ctr Study Learning Disab, Haifa, Israel.
RP Menashe, S (corresponding author), Univ Haifa, Edmond J Safra Brain Res Ctr Study Learning Disab, IL-31905 Haifa, Israel.
EM menashe_shay@yahoo.com
CR Asbjornsen AE, 1998, NEUROPSYCHOLOGIA, V36, P143, DOI 10.1016/S0028-3932(97)00090-0
   Blau V, 2009, CURR BIOL, V19, P503, DOI 10.1016/j.cub.2009.01.065
   Breznitz Z, 2001, DYSLEXIA, FLUENCY, AND THE BRAIN, P245
   Breznitz Z, 2003, BRAIN LANG, V85, P486, DOI 10.1016/S0093-934X(03)00071-3
   Breznitz Z., 2006, READING FLUENCY SYNC
   Breznitz Z., 2002, READ WRIT, V15, DOI [10.1023/A:1013864203452, DOI 10.1023/A:1013864203452]
   Casco C, 1998, CORTEX, V34, P531, DOI 10.1016/S0010-9452(08)70512-4
   COHEN M, 1992, BRAIN LANG, V42, P187, DOI 10.1016/0093-934X(92)90124-W
   Fabiani M, 1996, PSYCHOPHYSIOLOGY, V33, P462, DOI 10.1111/j.1469-8986.1996.tb01072.x
   Facoetti A, 2000, EXP BRAIN RES, V132, P531, DOI 10.1007/s002219900330
   Facoetti A, 2005, ACTA NEUROBIOL EXP, V65, P61
   Facoetti A, 2001, EXP BRAIN RES, V138, P46, DOI 10.1007/s002210100700
   Fan J, 2002, J COGNITIVE NEUROSCI, V14, P340, DOI 10.1162/089892902317361886
   Ferretti G, 2008, BEHAV NEUROL, V19, P87, DOI 10.1155/2008/564561
   Francisco A. A., 2014, P 15 ANN C INT SPEEC, P2575
   Giard MH, 1999, J COGNITIVE NEUROSCI, V11, P473, DOI 10.1162/089892999563544
   Giuliano RJ, 2014, J COGNITIVE NEUROSCI, V26, P2682, DOI 10.1162/jocn_a_00684
   GoldWave Inc, 2003, DIG AUD ED SOFTW VER
   Goswami U, 2002, ANN DYSLEXIA, V52, P141
   GRATTON G, 1983, ELECTROEN CLIN NEURO, V55, P468, DOI 10.1016/0013-4694(83)90135-9
   Habib M, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00026
   Hairston WD, 2005, EXP BRAIN RES, V166, P474, DOI 10.1007/s00221-005-2387-6
   Hamalainen JA, 2015, INT J PSYCHOPHYSIOL, V95, P101, DOI 10.1016/j.ijpsycho.2014.04.004
   Heiervang E, 2003, J LEARN DISABIL-US, V36, P68, DOI 10.1177/00222194030360010801
   Helland T, 2001, LATERALITY, V6, P289
   Hugdahl K, 2000, ACTA PSYCHOL, V105, P211, DOI 10.1016/S0001-6918(00)00062-7
   Karipidis II, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24909-8
   Kimura D, 1967, CORTEX, V3, P163, DOI [DOI 10.1016/S0010-9452(67)80010-8, 10.1016/s0010-9452(67)80010-8]
   KINSBOURNE M, 1970, ACTA PSYCHOL, V33, P193, DOI 10.1016/0001-6918(70)90132-0
   Kinsbourne M., 1973, ATTENTION PERFORM, P239
   Kinsbourne M., 1975, ATTENTION PERFORM, P81
   Knowland VCP, 2014, DEVELOPMENTAL SCI, V17, P110, DOI 10.1111/desc.12098
   Kronschnabel J, 2014, NEUROPSYCHOLOGIA, V62, P245, DOI 10.1016/j.neuropsychologia.2014.07.024
   Lyon GR, 2003, ANN DYSLEXIA, V53, P1, DOI 10.1007/s11881-003-0001-9
   Marendaz C, 1996, ANN PSYCHOL, V96, P193
   Martinez JA, 1999, J CLIN EXP NEUROPSYC, V21, P519, DOI 10.1076/jcen.21.4.519.880
   Mcpherson D, 1996, LATE POTENTIALS AUDI
   Menashe S., 2017, J INTEGR NEUROSCI, V16, P1
   Menashe S, 2018, ANN DYSLEXIA, V68, P145, DOI 10.1007/s11881-018-0160-3
   Mittag M, 2013, PSYCHOPHYSIOLOGY, V50, P1034, DOI 10.1111/psyp.12085
   Mittag M, 2013, CLIN NEUROPHYSIOL, V124, P315, DOI 10.1016/j.clinph.2012.08.003
   Parasuraman R, 1998, ATTENTIVE BRAIN, P3
   Pilling M, 2009, J SPEECH LANG HEAR R, V52, P1073, DOI [10.1044/1092-4388, 10.1044/1092-4388(2009/07-0276)]
   Poghosyan V, 2008, NEURON, V58, P802, DOI 10.1016/j.neuron.2008.04.013
   POSNER MI, 1980, J EXP PSYCHOL GEN, V109, P160, DOI 10.1037/0096-3445.109.2.160
   Ramus F, 2003, CURR OPIN NEUROBIOL, V13, P212, DOI 10.1016/S0959-4388(03)00035-7
   Reynolds JH, 2004, ANNU REV NEUROSCI, V27, P611, DOI 10.1146/annurev.neuro.26.041002.131039
   ROSENZWEIG MR, 1951, AM J PHYSIOL, V167, P147, DOI 10.1152/ajplegacy.1951.167.1.147
   Russeler J, 2015, NEUROSCIENCE, V287, P55, DOI 10.1016/j.neuroscience.2014.12.023
   Russeler J, 2018, BRAIN IMAGING BEHAV, V12, P357, DOI 10.1007/s11682-017-9694-y
   Schulte-Korne G, 2001, INT J PSYCHOPHYSIOL, V40, P77, DOI 10.1016/S0167-8760(00)00152-5
   Sebastian C, 2008, INT J PSYCHOPHYSIOL, V70, P115, DOI 10.1016/j.ijpsycho.2008.08.004
   Senkowski D, 2005, EXP BRAIN RES, V166, P411, DOI 10.1007/s00221-005-2381-z
   Shaul S, 2013, J INTEGR NEUROSCI, V12, P259, DOI 10.1142/S0219635213500167
   Shaywitz SE, 2005, BIOL PSYCHIAT, V57, P1301, DOI 10.1016/j.biopsych.2005.01.043
   SNODGRASS JG, 1980, J EXP PSYCHOL-HUM L, V6, P174, DOI 10.1037/0278-7393.6.2.174
   Snowling M., 2000, DYSLEXIA
   Stein B. E., 1993, MERGING SENSES
   Stein J, 2001, Dyslexia, V7, P12, DOI 10.1002/dys.186
   STELMACH LB, 1991, J EXP PSYCHOL HUMAN, V17, P539, DOI 10.1037/0096-1523.17.2.539
   Stevens C, 2012, DEV COGN NEUROS-NETH, V2, pS30, DOI 10.1016/j.dcn.2011.11.001
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Talsma D, 2005, J COGNITIVE NEUROSCI, V17, P1098, DOI 10.1162/0898929054475172
   Talsma D, 2007, CEREB CORTEX, V17, P679, DOI 10.1093/cercor/bhk016
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   Wijers A. A., 1996, HDB PERCEPTION ACTIO, P333
   WOLDORFF MG, 1993, P NATL ACAD SCI USA, V90, P8722, DOI 10.1073/pnas.90.18.8722
   WOLDORFF MG, 1991, ELECTROEN CLIN NEURO, V79, P170, DOI 10.1016/0013-4694(91)90136-R
   Zaric G, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110337
   Zhao S, 2018, NEUROIMAGE, V174, P208, DOI 10.1016/j.neuroimage.2018.03.036
NR 71
TC 0
Z9 0
U1 7
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1076-9242
EI 1099-0909
J9 DYSLEXIA
JI Dyslexia
DI 10.1002/dys.1674
EA DEC 2020
PG 20
WC Education, Special; Psychology, Educational; Rehabilitation
SC Education & Educational Research; Psychology; Rehabilitation
GA PH7SS
UT WOS:000600608100001
PM 33350029
DA 2021-02-24
ER

PT J
AU Pena, M
   Jara, C
   Flores, JC
   Hoyos-Bachiloglu, R
   Iturriaga, C
   Medina, M
   Carcey, J
   Espinoza, J
   Bohmwald, K
   Kalergis, AM
   Borzutzky, A
AF Pena, Marcela
   Jara, Cristina
   Flores, Juan C.
   Hoyos-Bachiloglu, Rodrigo
   Iturriaga, Carolina
   Medina, Mariana
   Carcey, Javier
   Espinoza, Janyra
   Bohmwald, Karen
   Kalergis, Alexis M.
   Borzutzky, Arturo
TI Severe respiratory disease caused by human respiratory syncytial virus
   impairs language learning during early infancy
SO SCIENTIFIC REPORTS
LA English
DT Article
ID MISMATCH NEGATIVITY; SPEECH-PERCEPTION; BRAIN RESPONSES; INFECTION;
   CHILDREN; DISCRIMINATION; PREMATURE; GENOTYPES; PATIENT
AB Human respiratory syncytial virus infection is a leading cause of pediatric morbidity and mortality. A previous murine study showed that during severe acute respiratory infections the virus invades the central nervous system, and that infected animals evolve with long-lasting learning difficulties associated with long-term potentiation impairment in their hippocampus. We hypothesized here that human infants who presented a severe episode of respiratory syncytial virus infection before 6 months of age would develop long-term learning difficulties. We measured the acquisition of the native phoneme repertoire during the first year, a milestone in early human development, comprising a reduction in the sensitivity to the irrelevant nonnative phonetic information and an increase in the sensitivity to the information relevant for the native one. We found that infants with a history of severe respiratory infection by the human respiratory syncytial virus presented poor distinction of native and nonnative phonetic contrasts at 6 months of age, and remained atypically sensitive to nonnative contrasts at 12 months, which associated with weak communicative abilities. Our results uncover previously unknown long-term language learning difficulties associated with a single episode of severe respiratory infection by the human respiratory syncytial virus, which could relate to memory impairments.
C1 [Pena, Marcela; Jara, Cristina] Pontificia Univ Catolica Chile, Escuela Psicol, Lab Neurociencias Cognit, Santiago 7820436, Chile.
   [Flores, Juan C.; Medina, Mariana] Pontificia Univ Catolica Chile, Escuela Med, Div Pediat, Santiago 8330077, Chile.
   [Flores, Juan C.; Medina, Mariana; Carcey, Javier] Complejo Asistencial Dr Sotero Rio, Serv Pediat, Santiago 8207257, Chile.
   [Hoyos-Bachiloglu, Rodrigo; Iturriaga, Carolina; Borzutzky, Arturo] Pontificia Univ Catolica Chile, Dept Enfermedades Infecciosas & Inmunol Pediat, Santiago 8330077, Chile.
   [Espinoza, Janyra; Bohmwald, Karen; Kalergis, Alexis M.] Pontificia Univ Catolica Chile, Dept Genet Mol & Microbiol, Millennium Inst Immunol & Immunotherapy, Fac Ciencias Biol, Santiago 8330025, Chile.
   [Jara, Cristina; Kalergis, Alexis M.] Pontificia Univ Catolica Chile, Dept Endocrinol, Fac Med, Santiago 8330077, Chile.
   [Jara, Cristina] Pontificia Univ Catolica Chile, Dept Ciencias Salud, Fac Med, Santiago 7820436, Chile.
RP Pena, M (corresponding author), Pontificia Univ Catolica Chile, Escuela Psicol, Lab Neurociencias Cognit, Santiago 7820436, Chile.
EM mpenag@uc.cl
RI bohmwald, karen/AAF-2934-2021
FU Pontificia Universidad Catolica de Chile Interdisciplinary Grant
   [14/2013]; Pontificia Universidad Catolica de Chile Puente Grant
   [P1609]; Millennium Institute of Immunology and Immunotherapy
   [P09/016-F, ICN09_016]; FONDECYTComision Nacional de Investigacion
   Cientifica y Tecnologica (CONICYT)CONICYT FONDECYT [1190830]
FX We thank infants and parents who participated in this study. We are
   grateful with Diana Arias and Cesar Gutierrez for their support with EEG
   recordings. This study received the support of the Pontificia
   Universidad Catolica de Chile Interdisciplinary Grant #14/2013 to A.B.,
   A.M.K., and M.P., Pontificia Universidad Catolica de Chile Puente Grant
   #P1609 to M.P., and Millennium Institute of Immunology and Immunotherapy
   (P09/016-F and ICN09_016) and FONDECYT 1190830 to A.M.K.
CR Ahmmed AU, 2008, DEV MED CHILD NEUROL, V50, P938, DOI 10.1111/j.1469-8749.2008.03093.x
   Amini R, 2019, INFECTION, V47, P595, DOI 10.1007/s15010-019-01287-5
   Bohmwald K, 2021, BRAIN BEHAV IMMUN, V91, P159, DOI 10.1016/j.bbi.2020.09.021
   Cheng YY, 2015, INT J PSYCHOPHYSIOL, V96, P84, DOI 10.1016/j.ijpsycho.2015.03.007
   Comas-Garcia A, 2018, J INFECT DIS, V217, P1089, DOI 10.1093/infdis/jiy025
   Dehaene-Lambertz G, 2001, NEUROREPORT, V12, P3155, DOI 10.1097/00001756-200110080-00034
   DEHAENELAMBERTZ G, 1994, NATURE, V370, P292, DOI 10.1038/370292a0
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Espinoza JA, 2013, P NATL ACAD SCI USA, V110, P9112, DOI 10.1073/pnas.1217508110
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   Flores JC, 2016, REV CHIL INFECTOL, V33, P537, DOI 10.4067/S0716-10182016000500008
   Friederici AD, 2002, NEUROREPORT, V13, P1251, DOI 10.1097/00001756-200207190-00006
   Garcia-Sierra A, 2016, INT J PSYCHOPHYSIOL, V110, P1, DOI 10.1016/j.ijpsycho.2016.10.004
   Gilca R, 2006, J INFECT DIS, V193, P54, DOI 10.1086/498526
   Hawa VV, 2014, RES DEV DISABIL, V35, P400, DOI 10.1016/j.ridd.2013.10.027
   Hirayama K, 1999, PEDIATR RADIOL, V29, P282, DOI 10.1007/s002470050589
   Jafri HS, 2013, PEDIATR INFECT DIS J, V32, P335, DOI 10.1097/INF.0b013e318282603a
   Kawashima H, 2012, J INFECT CHEMOTHER, V18, P827, DOI 10.1007/s10156-012-0418-3
   Kuhl P, 2008, ANNU REV NEUROSCI, V31, P511, DOI 10.1146/annurev.neuro.30.051606.094321
   Kushnerenko E, 2002, NEUROREPORT, V13, P1843, DOI 10.1097/00001756-200210280-00002
   Diaz MFL, 2011, REV LAT AM PSICOL, V43, P241
   Leppanen PHT, 2012, NEUROPHYSIOL CLIN, V42, P35, DOI 10.1016/j.neucli.2011.08.005
   Lohvansuu K, 2018, NEUROPSYCHOLOGIA, V108, P6, DOI 10.1016/j.neuropsychologia.2017.11.018
   Mahmoudzadeh M, 2013, P NATL ACAD SCI USA, V110, P4846, DOI 10.1073/pnas.1212220110
   Maurer U, 2003, NEUROREPORT, V14, P2245, DOI 10.1097/00001756-200312020-00022
   McAllister DA, 2019, LANCET GLOB HEALTH, V7, pE47, DOI 10.1016/S2214-109X(18)30408-X
   MCINTOSH EDG, 1993, PEDIATR INFECT DIS J, V12, P815, DOI 10.1097/00006454-199310000-00004
   Midulla F, 2019, J INFECT DIS, V219, P526, DOI 10.1093/infdis/jiy496
   Millichap JJ, 2009, J CHILD NEUROL, V24, P1499, DOI 10.1177/0883073808331362
   Miyamoto K, 2013, J INFECT CHEMOTHER, V19, P978, DOI 10.1007/s10156-013-0558-0
   Morichi S, 2011, J INFECT CHEMOTHER, V17, P776, DOI 10.1007/s10156-011-0259-5
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Otake Y, 2007, BRAIN DEV-JPN, V29, P117, DOI 10.1016/j.braindev.2006.06.008
   Park A, 2014, NEURORADIOLOGY, V56, P163, DOI 10.1007/s00234-013-1305-z
   Pena M, 2012, J NEUROSCI, V32, P11159, DOI 10.1523/JNEUROSCI.6516-11.2012
   Pena M, 2010, P NATL ACAD SCI USA, V107, P3823, DOI 10.1073/pnas.0914326107
   Perszyk DR, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39511-9
   Rivera-Gaxiola M, 2005, NEUROREPORT, V16, P495, DOI 10.1097/00001756-200504040-00015
   Rivera-Gaxiola M, 2005, DEVELOPMENTAL SCI, V8, P162, DOI 10.1111/j.1467-7687.2005.00403.x
   Scott PD, 2004, J MED VIROL, V74, P344, DOI 10.1002/jmv.20183
   Shi T, 2017, LANCET, V390, P946, DOI [10.1016/S0140-6736(17)30938-8, 10.1016/s0140-6736(17)30938-8]
   Sugimoto M, 2020, J INFECT CHEMOTHER, V26, P393, DOI 10.1016/j.jiac.2019.11.008
   Sweetman LL, 2005, PEDIATR NEUROL, V32, P307, DOI 10.1016/j.pediatrneurol.2005.01.010
   Tadel F, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/879716
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Wacongne C, 2011, P NATL ACAD SCI USA, V108, P20754, DOI 10.1073/pnas.1117807108
   WERKER JF, 1988, DEV PSYCHOL, V24, P672, DOI 10.1037/0012-1649.24.5.672
   Werker JF, 1999, ANNU REV PSYCHOL, V50, P509, DOI 10.1146/annurev.psych.50.1.509
   Zlateva KT, 2004, PEDIATR INFECT DIS J, V23, P1065, DOI 10.1097/01.inf.0000143654.12493.c9
NR 50
TC 0
Z9 0
U1 0
U2 0
PU NATURE RESEARCH
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD DEC 21
PY 2020
VL 10
IS 1
AR 22356
DI 10.1038/s41598-020-79140-1
PG 10
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA PL3XN
UT WOS:000603059100001
PM 33349647
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Ehrhorn, AM
   Adlof, SM
   Fogerty, D
   Laing, S
AF Ehrhorn, Anna M.
   Adlof, Suzanne M.
   Fogerty, Daniel
   Laing, Spencer
TI Probing Phonological Processing Differences in Nonword Repetition for
   Children with Separate or Co-Occurring Dyslexia and Developmental
   Language Disorder
SO SCIENTIFIC STUDIES OF READING
LA English
DT Article; Early Access
ID NON-WORD REPETITION; SHORT-TERM-MEMORY; WORKING-MEMORY; PHONOTACTIC
   PROBABILITY; SPEECH-PERCEPTION; VOCABULARY SIZE; IMPAIRMENT; DEFICITS;
   AWARENESS; REPRESENTATIONS
AB We assessed nonword repetition (NWR) skills in 7-9 year-old children with dyslexia (dyslexia-only), developmental language disorder (DLD-only), co-occurring DLD+dyslexia, and typical development (TD) with a norm-referenced and an experimental task. The experimental task manipulated phonemic variability (dissimilarity among consonant phonemes within the nonword) and presentation modality (audio-only versus audiovisual) to probe potential phonological processing differences among the groups. Across tasks, the dyslexia-only and DLD-only groups performed similarly to each other and intermediately to the TD and DLD+dyslexia groups. In the experimental task, nonwords with low phonemic variability were produced less accurately in both modalities, and audiovisual presentation facilitated accurate repetition of low phonemic variability nonwords. A lack of a group interaction with phonemic variability or presentation modality suggests similarities, despite group differences, in how underlying phonological representations influence task performance. Overall, results suggest that poor NWR is associated with both dyslexia and DLD, and that co-occurrence compounds this difficulty.
C1 [Ehrhorn, Anna M.; Adlof, Suzanne M.; Fogerty, Daniel; Laing, Spencer] Univ South Carolina, Dept Commun Sci & Disorders, 1705 Coll St,2nd Floor, Columbia, SC 29208 USA.
   [Fogerty, Daniel] Univ Illinois, Dept Speech & Hearing Sci, Champaign, IL USA.
   [Laing, Spencer] Univ N Carolina, Lineberger Comprehens Canc Ctr, Chapel Hill, NC 27515 USA.
RP Adlof, SM (corresponding author), Univ South Carolina, Dept Commun Sci & Disorders, 1705 Coll St,2nd Floor, Columbia, SC 29208 USA.
EM sadlof@mailbox.sc.edu
FU National Institute of Deafness and Other Communication Disorders of the
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R03DC013399,
   R01DC017156]
FX This research was supported by grants from the National Institute of
   Deafness and Other Communication Disorders of the National Institutes of
   Health under award numbers R03DC013399 (PI: Adlof) and R01DC017156 (PI:
   Adlof).
CR Adlof SM, 2017, J SPEECH LANG HEAR R, V60, P3507, DOI 10.1044/2017_JSLHR-L-16-0473
   Adlof SM, 2017, J SPEECH LANG HEAR R, V60, P682, DOI 10.1044/2016_JSLHR-L-15-0441
   American Psychiatric Association, 2019, WHAT IS SPEC LEARN D
   Archibald LMD, 2006, INT J LANG COMM DIS, V41, P675, DOI 10.1080/13682820500442602
   Archibald LMD, 2009, J SPEECH LANG HEAR R, V52, P899, DOI 10.1044/1092-4388(2009/08-0099)
   Astle DE, 2020, CURR DIR PSYCHOL SCI, V29, P431, DOI 10.1177/0963721420925518
   Baddeley A, 2010, CURR BIOL, V20, pR136, DOI 10.1016/j.cub.2009.12.014
   Baird G, 2011, DEV MED CHILD NEUROL, V53, P711, DOI 10.1111/j.1469-8749.2011.03936.x
   Barbosa T, 2009, READ WRIT, V22, P201, DOI 10.1007/s11145-007-9109-3
   Bishop DVM, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0158753
   Bishop DVM, 2017, J CHILD PSYCHOL PSYC, V58, P1068, DOI 10.1111/jcpp.12721
   Bishop DVM, 2009, CHILD DEV, V80, P593, DOI 10.1111/j.1467-8624.2009.01281.x
   Bishop DVM, 2006, GENES BRAIN BEHAV, V5, P158, DOI 10.1111/j.1601-183X.2005.00148.x
   Bishop DVM, 2004, AM J MED GENET B, V129B, P94, DOI 10.1002/ajmg.b.30065
   Bowey JA, 1997, J EXP CHILD PSYCHOL, V67, P295, DOI 10.1006/jecp.1997.2408
   Brown L., 2010, TEST NONVERBAL INTEL
   Catts HW, 2017, READ WRIT, V30, P613, DOI 10.1007/s11145-016-9692-2
   Catts HW, 2005, J SPEECH LANG HEAR R, V48, P1378, DOI 10.1044/1092-4388(2005/096)
   DARWIN CJ, 1974, COGNITIVE PSYCHOL, V6, P41, DOI 10.1016/0010-0285(74)90003-6
   de Bree E. H., 2007, DYSLEXIA PHONOLOGY S
   de Gelder B, 1998, BRAIN LANG, V64, P269, DOI 10.1006/brln.1998.1973
   DOLLAGHAN C, 1993, J SPEECH HEAR RES, V36, P1051, DOI 10.1044/jshr.3605.1051
   Dollaghan C, 1998, J SPEECH LANG HEAR R, V41, P1136, DOI 10.1044/jslhr.4105.1136
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   Edwards J, 2004, J SPEECH LANG HEAR R, V47, P421, DOI 10.1044/1092-4388(2004/034)
   Elbro C, 2005, SCAND J PSYCHOL, V46, P375, DOI 10.1111/j.1467-9450.2005.00468.x
   Estes KG, 2007, J SPEECH LANG HEAR R, V50, P177, DOI 10.1044/1092-4388(2007/015)
   Farquharson K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00838
   Francisco AA, 2017, J SPEECH LANG HEAR R, V60, P144, DOI 10.1044/2016_JSLHR-H-15-0375
   Fraser J, 2010, SCI STUD READ, V14, P8, DOI 10.1080/10888430903242068
   Gallinat E, 2014, J SPEECH LANG HEAR R, V57, P1363, DOI 10.1044/2014_JSLHR-L-12-0363
   Garlock VM, 2001, J MEM LANG, V45, P468, DOI 10.1006/jmla.2000.2784
   Gathercole S E, 1994, Memory, V2, P103, DOI 10.1080/09658219408258940
   GATHERCOLE SE, 1989, J MEM LANG, V28, P200, DOI 10.1016/0749-596X(89)90044-2
   Gathercole SE, 1997, DEV PSYCHOL, V33, P966, DOI 10.1037/0012-1649.33.6.966
   Gathercole SE, 2006, APPL PSYCHOLINGUIST, V27, P513, DOI 10.1017/S0142716406060383
   Gough P.B., 1986, REMEDIAL SPECIAL ED, V7, DOI [DOI 10.1177/074193258600700104, https://doi.org/10.1177/074193258600700104, 10.1177/074193258600700104]
   Gray S, 2019, J SPEECH LANG HEAR R, V62, P1839, DOI 10.1044/2019_JSLHR-L-18-0148
   Hendricks AE, 2017, LANG SPEECH HEAR SER, V48, P168, DOI 10.1044/2017_LSHSS-16-0060
   Hoff E, 2008, J CHILD LANG, V35, P903, DOI 10.1017/S0305000908008751
   Hogan TP, 2005, LANG SPEECH HEAR SER, V36, P285, DOI 10.1044/0161-1461(2005/029)
   HOOVER WA, 1990, READ WRIT, V2, P127, DOI 10.1007/BF00401799
   International Dyslexia Association, 2002, DEF DYSL
   Jackson E, 2019, J COMMUN DISORD, V79, P11, DOI 10.1016/j.jcomdis.2019.02.001
   Korkman M., 1998, NEPSY DEV NEUROPSYCH
   Leonard LB, 2014, CHILDREN WITH SPECIFIC LANGUAGE IMPAIRMENT, 2ND EDITION, P1
   Leybaert J, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00422
   Lyon GR, 2003, ANN DYSLEXIA, V53, P1, DOI 10.1007/s11881-003-0001-9
   McArthur G, 2013, J RES READ, V36, P280, DOI 10.1111/j.1467-9817.2011.01503.x
   Megnin-Viggars O, 2013, BRAIN LANG, V124, P165, DOI 10.1016/j.bandl.2012.12.002
   Melby-Lervag M, 2012, SCI STUD READ, V16, P1, DOI 10.1080/10888438.2010.537715
   Menghini D, 2011, DEV NEUROPSYCHOL, V36, P199, DOI 10.1080/87565641.2010.549868
   Meronen A, 2013, J SPEECH LANG HEAR R, V56, P211, DOI 10.1044/1092-4388(2012/11-0270)
   Montgomery JW, 2010, AM J SPEECH-LANG PAT, V19, P78, DOI 10.1044/1058-0360(2009/09-0028)
   Munson B, 2005, J SPEECH LANG HEAR R, V48, P1033, DOI 10.1044/1092-4388(2005/072)
   Nation K, 2011, DEVELOPMENTAL SCI, V14, P649, DOI 10.1111/j.1467-7687.2010.01008.x
   Norbury CF, 2016, J CHILD PSYCHOL PSYC, V57, P1247, DOI 10.1111/jcpp.12573
   Norrix LW, 2007, J SPEECH LANG HEAR R, V50, P1639, DOI 10.1044/1092-4388(2007/111)
   Pickering S.J., 2001, WORKING MEMORY TEST
   Ramirez J, 2005, J ACOUST SOC AM, V118, P1122, DOI 10.1121/1.1940509
   Ramus F, 2013, BRAIN, V136, P630, DOI 10.1093/brain/aws356
   Redmond SM, 2019, J SPEECH LANG HEAR R, V62, P2438, DOI 10.1044/2019_JSLHR-L-18-0388
   Redmond SM, 2011, J SPEECH LANG HEAR R, V54, P99, DOI 10.1044/1092-4388(2010/10-0010)
   Rice ML, 2004, J SPEECH LANG HEAR R, V47, P816, DOI 10.1044/1092-4388(2004/061)
   Rispens J, 2012, J SPEECH LANG HEAR R, V55, P683, DOI 10.1044/1092-4388(2011/10-0263)
   Rispens J, 2010, BRIT J DEV PSYCHOL, V28, P177, DOI 10.1348/026151009X482633
   Rosenblum L. D., 2002, INT C SPOK LANG PROC
   Saiegh-Haddad E, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02010
   Schneider E., 2007, E PRIME 2 0
   Schuchardt K, 2013, TOP LANG DISORD, V33, P298, DOI 10.1097/01.TLD.0000437943.41140.36
   Semel E.M., 2004, CLIN EVALUATION LANG
   Seymour H. N., 2003, DIAGNOSTIC EVALUATIO
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Tomblin JB, 1997, J SPEECH LANG HEAR R, V40, P1245, DOI 10.1044/jslhr.4006.1245
   Torgesen J. K., 2012, TEST WORD READING EF
   TORGESEN JK, 1994, J LEARN DISABIL, V27, P276, DOI 10.1177/002221949402700503
   Wagner R. K., 2003, COMPREHENSIVE TEST P
   Williams K.T., 2001, GROUP READING ASSESS
   Woodcock R.W., 2011, WOODCOCK READING MAS
   Ye Z, 2017, NEUROSCIENCE, V356, P1, DOI 10.1016/j.neuroscience.2017.05.017
NR 81
TC 0
Z9 0
U1 2
U2 2
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1088-8438
EI 1532-799X
J9 SCI STUD READ
JI Sci. Stud. Read.
DI 10.1080/10888438.2020.1849223
EA DEC 2020
PG 18
WC Education & Educational Research; Psychology, Educational
SC Education & Educational Research; Psychology
GA PF9SW
UT WOS:000599387100001
DA 2021-02-24
ER

PT J
AU Haro, S
   Smalt, CJ
   Ciccarelli, GA
   Quatieri, TF
AF Haro, Stephanie
   Smalt, Christopher J.
   Ciccarelli, Gregory A.
   Quatieri, Thomas F.
TI Deep Neural Network Model of Hearing-Impaired Speech-in-Noise Perception
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE speech-in-noise (SIN); deep neural network (DNN); cochlear modeling;
   cochlear synapatopathy; medial olivocochlear (MOC) efferents
ID AUDITORY-NERVE FIBERS; MODULATION TRANSFER-FUNCTION; PHENOMENOLOGICAL
   MODEL; OLIVOCOCHLEAR REFLEX; EFFERENT SUPPRESSION; RESPONSES;
   INTELLIGIBILITY; RECOGNITION; CORTEX; PREDICTIONS
AB Many individuals struggle to understand speech in listening scenarios that include reverberation and background noise. An individual's ability to understand speech arises from a combination of peripheral auditory function, central auditory function, and general cognitive abilities. The interaction of these factors complicates the prescription of treatment or therapy to improve hearing function. Damage to the auditory periphery can be studied in animals; however, this method alone is not enough to understand the impact of hearing loss on speech perception. Computational auditory models bridge the gap between animal studies and human speech perception. Perturbations to the modeled auditory systems can permit mechanism-based investigations into observed human behavior. In this study, we propose a computational model that accounts for the complex interactions between different hearing damage mechanisms and simulates human speech-in-noise perception. The model performs a digit classification task as a human would, with only acoustic sound pressure as input. Thus, we can use the model's performance as a proxy for human performance. This two-stage model consists of a biophysical cochlear-nerve spike generator followed by a deep neural network (DNN) classifier. We hypothesize that sudden damage to the periphery affects speech perception and that central nervous system adaptation over time may compensate for peripheral hearing damage. Our model achieved human-like performance across signal-to-noise ratios (SNRs) under normal-hearing (NH) cochlear settings, achieving 50% digit recognition accuracy at -20.7 dB SNR. Results were comparable to eight NH participants on the same task who achieved 50% behavioral performance at -22 dB SNR. We also simulated medial olivocochlear reflex (MOCR) and auditory nerve fiber (ANF) loss, which worsened digit-recognition accuracy at lower SNRs compared to higher SNRs. Our simulated performance following ANF loss is consistent with the hypothesis that cochlear synaptopathy impacts communication in background noise more so than in quiet. Following the insult of various cochlear degradations, we implemented extreme and conservative adaptation through the DNN. At the lowest SNRs (<0 dB), both adapted models were unable to fully recover NH performance, even with hundreds of thousands of training samples. This implies a limit on performance recovery following peripheral damage in our human-inspired DNN architecture.
C1 [Haro, Stephanie; Smalt, Christopher J.; Ciccarelli, Gregory A.; Quatieri, Thomas F.] MIT, Lincoln Lab, Human Hlth & Performance Syst, 244 Wood St, Lexington, MA 02173 USA.
   [Haro, Stephanie; Quatieri, Thomas F.] Harvard Med Sch, Speech & Hearing Biosci & Technol, Boston, MA 02115 USA.
RP Smalt, CJ (corresponding author), MIT, Lincoln Lab, Human Hlth & Performance Syst, 244 Wood St, Lexington, MA 02173 USA.
EM Christopher.Smalt@LL.mit.edu
FU Under Secretary of Defense for Research and Engineering under Air Force
   [FA8702-15-D-0001]; National Institute of HealthUnited States Department
   of Health & Human ServicesNational Institutes of Health (NIH) - USA
   [5T32DC000038-27]; National Science FoundationNational Science
   Foundation (NSF) [DGE1745303]
FX This material was based upon work supported by the Under Secretary of
   Defense for Research and Engineering under Air Force Contract No.
   FA8702-15-D-0001. Any opinions, findings, conclusions or recommendations
   expressed in this material are those of the author(s) and do not
   necessarily reflect the views of the Under Secretary of Defense for
   Research and Engineering. SH was supported in part by an National
   Institute of Health T32 Trainee Grant No. 5T32DC000038-27 and the
   National Science Foundation Graduate Research Fellowship Programunder
   Grant No. DGE1745303.
CR Akbari H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37359-z
   Arai K., 2019, INTERSPEECH, P4275, DOI [10.21437/Interspeech.2019-1381, DOI 10.21437/INTERSPEECH.2019-1381]
   Baby D., 2020, ARXIV200414832
   Backus BC, 2006, J ACOUST SOC AM, V119, P2889, DOI 10.1121/1.2169918
   Bernstein JGW, 2009, J ACOUST SOC AM, V125, P3358, DOI 10.1121/1.3110132
   Bharadwaj HM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00026
   Bramhall N, 2019, HEARING RES, V377, P88, DOI 10.1016/j.heares.2019.02.016
   Brown GJ, 2010, J ACOUST SOC AM, V127, P943, DOI 10.1121/1.3273893
   Bruce I. C., 2015, 38 ARO MIDW RES M BA
   Carandini M, 2012, NAT REV NEUROSCI, V13, P51, DOI 10.1038/nrn3136
   Carney LH, 2018, JARO-J ASSOC RES OTO, V19, P331, DOI 10.1007/s10162-018-0669-5
   CARNEY LH, 1993, J ACOUST SOC AM, V93, P401, DOI 10.1121/1.405620
   Chintanpalli A, 2012, JARO-J ASSOC RES OTO, V13, P219, DOI 10.1007/s10162-011-0310-3
   Ciorba A, 2012, CLIN INTERV AGING, V7, P159, DOI 10.2147/CIA.S26059
   Clark NR, 2012, J ACOUST SOC AM, V132, P1535, DOI 10.1121/1.4742745
   David SV, 2009, J NEUROSCI, V29, P3374, DOI 10.1523/JNEUROSCI.5249-08.2009
   Elhilali M, 2003, SPEECH COMMUN, V41, P331, DOI 10.1016/S0167-6393(02)00134-6
   Fontan L, 2017, J SPEECH LANG HEAR R, V60, P2394, DOI 10.1044/2017_JSLHR-S-16-0269
   Frisina DR, 1997, HEARING RES, V106, P95, DOI 10.1016/S0378-5955(97)00006-3
   Furman AC, 2013, J NEUROPHYSIOL, V110, P577, DOI 10.1152/jn.00164.2013
   Geisler WS, 2011, VISION RES, V51, P771, DOI 10.1016/j.visres.2010.09.027
   GREENWOOD D, 1961, J ACOUST SOC AM, V33, P1344, DOI 10.1121/1.1908437
   Heinrich A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00782
   Heinz M.G., 2001, ARLO, V2, P91, DOI DOI 10.1121/1.1387155
   Hines A, 2012, SPEECH COMMUN, V54, P306, DOI 10.1016/j.specom.2011.09.004
   Hossain ME, 2019, COMPUT SPEECH LANG, V57, P59, DOI 10.1016/j.csl.2019.02.003
   Hossain ME, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150415
   HOUTGAST T, 1980, ACUSTICA, V46, P60
   Irvine D. R. F., 1995, WORLD SCI, P3
   Kell AJE, 2018, NEURON, V98, P630, DOI 10.1016/j.neuron.2018.03.044
   Keshishzadeh S., 2019, P INT S AUD AUD RES, V7, P13
   Kingma D. P., 2014, ARXIV14126980, P1
   Kujawa SG, 2009, J NEUROSCI, V29, P14077, DOI 10.1523/JNEUROSCI.2845-09.2009
   Le Prell CG, 2019, J ACOUST SOC AM, V146, P3646, DOI 10.1121/1.5133385
   Leonard R. Gary, 1993, TIDIGITS LDC93S10
   Liberman MC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162726
   LIBERMAN MC, 1978, J ACOUST SOC AM, V63, P442, DOI 10.1121/1.381736
   London M, 2005, ANNU REV NEUROSCI, V28, P503, DOI 10.1146/annurev.neuro.28.061604.135703
   Moore BCJ, 2008, JARO-J ASSOC RES OTO, V9, P399, DOI 10.1007/s10162-008-0143-x
   MORGAN BJT, 1973, PERCEPT PSYCHOPHYS, V14, P375, DOI 10.3758/BF03212408
   Moritz N, 2015, IEEE-ACM T AUDIO SPE, V23, P1926, DOI 10.1109/TASLP.2015.2456420
   Oxenham AJ, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516686768
   Parthasarathy A, 2020, ELIFE, V9, DOI 10.7554/eLife.51419
   Paszke A., 2019, P ADV NEUR INF PROC, V32, P8024
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   Plack CJ, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514550621
   Rahman M, 2019, PLOS COMPUT BIOL, V15, DOI 10.1371/journal.pcbi.1006618
   REUTHER A, 2018, IEEE HIGH PERF EXTR, P1, DOI DOI 10.1109/HPEC.2018.8547629
   Schadler MR, 2016, J ACOUST SOC AM, V139, P2708, DOI 10.1121/1.4948772
   Schilling A., 2020, BIORXIV, DOI [10.1101/2020.03.16.993725, DOI 10.1101/2020.03.16.993725]
   Schonwiesner M, 2009, P NATL ACAD SCI USA, V106, P14611, DOI 10.1073/pnas.0907682106
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Smalt C, 2016, J ACOUST SOC AM, V140, P3151, DOI DOI 10.1121/1.4969883
   Smalt CJ, 2014, JARO-J ASSOC RES OTO, V15, P159, DOI 10.1007/s10162-013-0430-z
   Spille C, 2018, COMPUT SPEECH LANG, V48, P51, DOI 10.1016/j.csl.2017.10.004
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881
   Tan Q, 2005, J ACOUST SOC AM, V117, P1210, DOI 10.1121/1.1856391
   Tan Q, 2003, J ACOUST SOC AM, V114, P2007, DOI 10.1121/1.1608963
   Tepe V, 2017, MIL MED, V182, pE1785, DOI 10.7205/MILMED-D-17-00025
   Verhulst S, 2018, HEARING RES, V360, P55, DOI 10.1016/j.heares.2017.12.018
   Whitton JP, 2017, CURR BIOL, V27, P3237, DOI 10.1016/j.cub.2017.09.014
   Zhang XD, 2001, J ACOUST SOC AM, V109, P648, DOI 10.1121/1.1336503
   Zilany MSA, 2007, J ACOUST SOC AM, V122, P402, DOI 10.1121/1.2735117
   Zilany MSA, 2006, J ACOUST SOC AM, V120, P1446, DOI 10.1121/1.2225512
   Zilany MSA, 2014, J ACOUST SOC AM, V135, P283, DOI 10.1121/1.4837815
   Zilany MSA, 2009, J ACOUST SOC AM, V126, P2390, DOI 10.1121/1.3238250
NR 67
TC 0
Z9 0
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD DEC 15
PY 2020
VL 14
AR 588448
DI 10.3389/fnins.2020.588448
PG 18
WC Neurosciences
SC Neurosciences & Neurology
GA PL3QP
UT WOS:000603041100001
PM 33384579
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Hardison, DM
   Pennington, MC
AF Hardison, Debra M.
   Pennington, Martha C.
TI Multimodal Second-Language Communication: Research Findings and
   Pedagogical Implications
SO RELC JOURNAL
LA English
DT Article; Early Access
DE Visual cues; co-speech gesture; auditory&#8211; visual integration;
   speech perception; speech production; second-language learning
ID BIMODAL SPEECH-PERCEPTION; VISUAL CUES; HEARING LIPS; GESTURES;
   LISTENERS; LANGUAGE; CONTEXT
AB This article reviews research findings involving visual input in speech processing in the form of facial cues and co-speech gestures for second-language (L2) learners, and provides pedagogical implications for the teaching of listening and speaking. It traces the foundations of auditory-visual speech research and explores the role of a speaker's facial cues in L2 perception training and gestural cues in listening comprehension. There is a strong role for pedagogy to maximize the salience of multimodal cues for L2 learners. Visible articulatory gestures that precede the acoustic signal and the preparation phase of a hand gesture that precedes the acoustic onset of a word provide a priming effect on perceivers' attention to signal upcoming information and facilitate processing, and visible gestures that co-occur with speech aid ongoing processing and comprehension. L2 learners benefit from an awareness of these visual cues and exposure to input.
C1 [Hardison, Debra M.] Michigan State Univ, 619 Red Cedar Rd,Wells Hall B256, E Lansing, MI 48824 USA.
   [Pennington, Martha C.] Birkbeck Univ London, London, England.
RP Hardison, DM (corresponding author), Michigan State Univ, 619 Red Cedar Rd,Wells Hall B256, E Lansing, MI 48824 USA.
EM hardiso2@msu.edu
CR ACTON W, 1984, TESOL QUART, V18, P71, DOI 10.2307/3586336
   BENOI C, 1994, J SPEECH HEAR RES, V37, P1195, DOI 10.1044/jshr.3705.1195
   Boersma P., 2014, PRAAT DOING PHONETIC
   Bolinger D, 1986, INTONATION ITS PARTS
   CELCE-MURCIA Marianne, 2010, TEACHING PRONUNCIATI
   Clark JM, 1991, EDUC PSYCHOL REV, V3, P149, DOI 10.1007/BF01320076
   Condon W, 1982, INTERACTION RHYTHMS, P53, DOI DOI 10.1016/B978-0-12-234980-5.50008-0
   Davis P, 1990, CONFIDENCE BOOK BUIL
   DODD B, 1977, PERCEPTION, V6, P31, DOI 10.1068/p060031
   Goldin-Meadow S, 2013, ANNU REV PSYCHOL, V64, P257, DOI 10.1146/annurev-psych-113011-143802
   GOTO H, 1971, NEUROPSYCHOLOGIA, V9, P317, DOI 10.1016/0028-3932(71)90027-3
   Green KP, 1988, J ACOUST SOC AM, V84, pS155, DOI DOI 10.1121/1.2025888
   Hagiwara RE, 1995, UCLA WORKING PAPERS, V90
   Hardison DM, 2014, TRENDS APPL LINGUIST, V10, P195
   Hardison DM, 2003, APPL PSYCHOLINGUIST, V24, P495, DOI 10.1017/S0142716403000250
   Hardison DM, 1996, LANG LEARN, V46, P3, DOI 10.1111/j.1467-1770.1996.tb00640.x
   Hardison DM, 2019, RELATIONSHIPS GESTUR
   Hardison DM, 2018, SALIENCE 2 LANGUAGE, P201
   Hardison DM, 2019, L1 L2 AUDITORY UNPUB
   Hardison DM, 2012, ROUTLEDGE HDB 2 LANG, P349
   Hardison DM, 2018, J 2 LANGUAGE PRONUNC, V4, P232
   Hattori T., 1987, JAPAN ASS LANGUAGE T, V8, P109
   Hazan V, 2006, J ACOUST SOC AM, V119, P1740, DOI 10.1121/1.2166611
   Hazan V, 2010, SPEECH COMMUN, V52, P996, DOI 10.1016/j.specom.2010.05.003
   Hirata Y, 2014, J SPEECH LANG HEAR R, V57, P2090, DOI 10.1044/2014_JSLHR-S-14-0049
   Hirata Y, 2010, J SPEECH LANG HEAR R, V53, P298, DOI 10.1044/1092-4388(2009/08-0243)
   Hisanaga S, 2016, SCI REP-UK, V6, DOI 10.1038/srep35265
   Kendon A., 1972, STUDIES DYADIC COMMU, P177, DOI [10.1016/B978-0-08-015867-9.50013-7, DOI 10.1016/B978-0-08-015867-9.50013-7]
   Kipp M, 2001, P 7 EUR C SPEECH COM, P1367
   LaScotte D, 2020, RELC J, DOI 10.1177/0033688220953910
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   MASSARO DW, 1993, J PHONETICS, V21, P445, DOI 10.1016/S0095-4470(19)30230-X
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McGurk H, 1988, DEV PSYCHOL VISION S
   McNeill D., 1992, HAND MIND WHAT GESTU
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Morett LM, 2015, LANG COGN NEUROSCI, V30, P347, DOI 10.1080/23273798.2014.923105
   Munhall KG, 1998, J ACOUST SOC AM, V104, P530, DOI 10.1121/1.423300
   Pennington M. C., 1996, PHONOLOGY ENGLISH LA
   Pennington MC, 2019, RELC J, V50, P371, DOI 10.1177/0033688219892096
   Pennington MC, 2019, RES PRACT APPL LINGU, P1, DOI 10.1007/978-1-137-47677-7
   Pennington MC, PRONUNCIATION BOOK L
   Pennington MC., 1989, RELC J, V20, P20
   PENNYCOOK A, 1985, TESOL QUART, V19, P259, DOI 10.2307/3586829
   Reisberg D, 1987, HEARING EYE PSYCHOL, P97
   SEKIYAMA K, 1993, J PHONETICS, V21, P427, DOI 10.1016/S0095-4470(19)30229-3
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Shams L, 2008, TRENDS COGN SCI, V12, P411, DOI 10.1016/j.tics.2008.07.006
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Sueyoshi A, 2005, LANG LEARN, V55, P661, DOI 10.1111/j.0023-8333.2005.00320.x
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1979, PHONETICA, V36, P314, DOI 10.1159/000259969
   Tarone E, 2018, SPEAKING 2 LANGUAGE, P197
   TUITE K, 1993, SEMIOTICA, V93, P83, DOI 10.1515/semi.1993.93.1-2.83
   Valimaa-Blum R, 2009, CORELA COGNITION REP, V7, P1
   Volterra V, 2002, GESTURE LANGUAGE HEA
   WALDEN BE, 1977, J SPEECH HEAR RES, V20, P130, DOI 10.1044/jshr.2001.130
   Wang Y, 2009, J PHONETICS, V37, P344, DOI 10.1016/j.wocn.2009.04.002
   WELCH RB, 1980, PSYCHOL BULL, V88, P638, DOI 10.1037/0033-2909.88.3.638
   Yi H-G, 2013, J ACOUSTICAL SOC AM, V134, pEL387
NR 61
TC 0
Z9 0
U1 2
U2 2
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0033-6882
EI 1745-526X
J9 RELC J
JI RELC J.
AR 0033688220966635
DI 10.1177/0033688220966635
EA DEC 2020
PG 15
WC Linguistics
SC Linguistics
GA PG2PR
UT WOS:000599583100001
DA 2021-02-24
ER

PT J
AU Szalardy, O
   Toth, B
   Farkas, D
   Hajdu, B
   Orosz, G
   Winkler, I
AF Szalardy, Orsolya
   Toth, Brigitta
   Farkas, David
   Hajdu, Botond
   Orosz, Gabor
   Winkler, Istvan
TI Who said what? The effects of speech tempo on target detection and
   information extraction in a multi-talker situation: An ERP and
   functional connectivity study
SO PSYCHOPHYSIOLOGY
LA English
DT Article; Early Access
DE functional brain networks; N2; P3; speech perception; speech tempo
ID EEG SOURCE LOCALIZATION; AUDITORY STREAM SEGREGATION; EVENT-RELATED
   POTENTIALS; SELECTIVE ATTENTION; PHASE SYNCHRONIZATION; BRAIN NETWORKS;
   P300; ALPHA; MEMORY; ORGANIZATION
AB People with normal hearing can usually follow one of the several concurrent speakers. Speech tempo affects both the separation of concurrent speech streams and information extraction from them. The current study varied the tempo of two concurrent speech streams to investigate these processes in a multi-talker situation. Listeners performed a target-detection and a content-tracking task, while target-related ERPs and functional brain networks sensitive to speech tempo were extracted from the EEG signal. At slower than normal speech tempo, building the two streams required longer processing times, and possibly the utilization of higher-order, for example, syntactic and semantic cues. The observed longer reaction times and higher connectivity strength in a theta band network associated with frontal control over auditory/speech processing are compatible with this notion. With increasing tempo, target detection performance decreased and the N2b and the P3b amplitudes increased. These data suggest an increased need for strictly allocating target-detection-related resources at higher tempo. This was also reflected by the observed increase in the strength of gamma-band networks within and between frontal, temporal, and cingular areas. At the fastest tested speech tempo, there was a sharp drop in recognition memory performance, while target detection performance increased compared to the normal speech tempo. This was accompanied by a significant increase in the strength of a low alpha network associated with the suppression of task-irrelevant speech. These results suggest that participants prioritized the immediate target detection task over the continuous content tracking, likely due to some capacity limit reached the fastest speech tempo.
C1 [Szalardy, Orsolya] Semmelweis Univ, Inst Behav Sci, Fac Med, Nagyvarad Ter 4, H-1089 Budapest, Hungary.
   [Szalardy, Orsolya; Toth, Brigitta; Farkas, David; Hajdu, Botond; Winkler, Istvan] Res Ctr Nat Sci, Inst Cognit Neurosci & Psychol, Budapest, Hungary.
   [Orosz, Gabor] Univ Littoral Cote dOpale, Univ Artois, Univ Lille, Unite Rech Pluridisciplinaire Sport Sante Soc, Lievin, France.
RP Szalardy, O (corresponding author), Semmelweis Univ, Inst Behav Sci, Fac Med, Nagyvarad Ter 4, H-1089 Budapest, Hungary.; Szalardy, O (corresponding author), Res Ctr Nat Sci, Inst Cognit Neurosci & Psychol, Budapest, Hungary.
EM szalardy.orsolya@med.semmelweis-univ.hu
OI Szalardy, Orsolya/0000-0001-9171-1147
FU National Research, Development and Innovation Office, Hungary [K132642]
FX National Research, Development and Innovation Office, Hungary,
   Grant/Award Number: K132642
CR Ahveninen J, 2013, J COGNITIVE NEUROSCI, V25, P1926, DOI 10.1162/jocn_a_00452
   Akimoto Y, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0059969
   ANSTIS S, 1985, J EXP PSYCHOL HUMAN, V11, P257, DOI 10.1037/0096-1523.11.3.257
   Astheimer LB, 2009, BIOL PSYCHOL, V80, P23, DOI 10.1016/j.biopsycho.2008.01.015
   Baddeley A. D., 1986, WORKING MEMORY APPL, DOI [10.1002/acp.2350020209, DOI 10.1002/ACP.2350020209]
   Baillet S, 2001, PHYS MED BIOL, V46, P77, DOI 10.1088/0031-9155/46/1/306
   Bastos AM, 2016, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00175
   Best V, 2008, P NATL ACAD SCI USA, V105, P13174, DOI 10.1073/pnas.0803718105
   Brancucci A, 2008, HUM BRAIN MAPP, V29, P253, DOI 10.1002/hbm.20385
   Brazdil M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0063293
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   Bregman AS, 2000, PERCEPT PSYCHOPHYS, V62, P626, DOI 10.3758/BF03212114
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   CHUN MM, 1995, J EXP PSYCHOL HUMAN, V21, P109
   Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135
   Conroy MA, 2007, J PSYCHOPHYSIOL, V21, P22, DOI 10.1027/0269-8803.21.1.22
   Cooper NR, 2003, INT J PSYCHOPHYSIOL, V47, P65, DOI 10.1016/S0167-8760(02)00107-1
   CRYSTAL TH, 1990, J ACOUST SOC AM, V88, P101, DOI 10.1121/1.399955
   Daitch AL, 2013, P NATL ACAD SCI USA, V110, P19585, DOI 10.1073/pnas.1307947110
   Delorme A, 2007, NEUROIMAGE, V34, P1443, DOI 10.1016/j.neuroimage.2006.11.004
   Denham SL, 2006, J PHYSIOL-PARIS, V100, P154, DOI 10.1016/j.jphysparis.2006.09.012
   Dombrowe I, 2014, J NEUROPHYSIOL, V112, P1307, DOI 10.1152/jn.00654.2013
   DONCHIN E, 1988, BEHAV BRAIN SCI, V11, P357, DOI 10.1017/S0140525X00058027
   Dowling WJ, 2008, PERCEPT PSYCHOPHYS, V70, P496, DOI 10.3758/PP.70.3.496
   Fell J, 2011, NAT REV NEUROSCI, V12, P105, DOI 10.1038/nrn2979
   Foxe JJ, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00154
   Gazzaley A, 2012, TRENDS COGN SCI, V16, P129, DOI 10.1016/j.tics.2011.11.014
   Gramfort A, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/923703
   Hopfinger JB, 2000, NAT NEUROSCI, V3, P284
   Huang Y, 2016, NEUROIMAGE, V140, P150, DOI 10.1016/j.neuroimage.2015.12.019
   ISREAL JB, 1980, PSYCHOPHYSIOLOGY, V17, P259, DOI 10.1111/j.1469-8986.1980.tb00146.x
   Kahlbrock N, 2012, NEUROIMAGE, V59, P673, DOI 10.1016/j.neuroimage.2011.07.017
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Klein A, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00171
   Klimesch W, 2007, NEUROSCI BIOBEHAV R, V31, P1003, DOI 10.1016/j.neubiorev.2007.03.005
   KUTAS M, 1983, MEM COGNITION, V11, P539, DOI 10.3758/BF03196991
   MacDonald AW, 2000, SCIENCE, V288, P1835, DOI 10.1126/science.288.5472.1835
   MICHIE PT, 1984, ANN NY ACAD SCI, V425, P250, DOI 10.1111/j.1749-6632.1984.tb23542.x
   Mizuhara H, 2007, NEUROIMAGE, V36, P232, DOI 10.1016/j.neuroimage.2007.02.026
   NAATANEN R, 1982, BIOL PSYCHOL, V14, P53, DOI 10.1016/0301-0511(82)90017-5
   NAATANEN R, 1990, BEHAV BRAIN SCI, V13, P201, DOI 10.1017/S0140525X00078407
   Najafi M, 2016, NEUROIMAGE, V135, P92, DOI 10.1016/j.neuroimage.2016.04.054
   NASMAN VT, 1990, PSYCHOPHYSIOLOGY, V27, P338, DOI 10.1111/j.1469-8986.1990.tb00393.x
   Osterhout L, 1997, BRAIN LANG, V59, P494, DOI 10.1006/brln.1997.1793
   Palva S, 2002, J NEUROSCI, V22, DOI 10.1523/JNEUROSCI.22-04-j0003.2002
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P91
   Peeva MG, 2010, NEUROIMAGE, V50, P626, DOI 10.1016/j.neuroimage.2009.12.065
   Pizzagalli DA, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P56, DOI 10.1017/CBO9780511546396.003
   Polich J, 2000, INT J PSYCHOPHYSIOL, V38, P1, DOI 10.1016/S0167-8760(00)00126-4
   POLICH J, 1995, BIOL PSYCHOL, V41, P103, DOI 10.1016/0301-0511(95)05130-9
   Polich J., 2003, DETECTION CHANGE EVE, P83, DOI [10.1007/978-1-4615-0294-4_5, DOI 10.1007/978-1-4615-0294-4_5]
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   Potes C, 2014, NEUROIMAGE, V97, P188, DOI 10.1016/j.neuroimage.2014.04.045
   Reinhart RMG, 2011, INT J PSYCHOPHYSIOL, V79, P16, DOI 10.1016/j.ijpsycho.2010.08.009
   Ridderinkhof KR, 2004, SCIENCE, V306, P443, DOI 10.1126/science.1100301
   RITTER W, 1979, SCIENCE, V203, P1358, DOI 10.1126/science.424760
   RITTER W, 1983, PSYCHOPHYSIOLOGY, V20, P168, DOI 10.1111/j.1469-8986.1983.tb03283.x
   Sauseng P, 2005, INT J PSYCHOPHYSIOL, V57, P97, DOI 10.1016/j.ijpsycho.2005.03.018
   Sauseng P, 2008, NEUROIMAGE, V40, P308, DOI 10.1016/j.neuroimage.2007.11.032
   Snyder JS, 2007, PSYCHOL BULL, V133, P780, DOI 10.1037/0033-2909.133.5.780
   Song J, 2015, J NEUROSCI METH, V256, P9, DOI 10.1016/j.jneumeth.2015.08.015
   Stam CJ, 2012, CLIN NEUROPHYSIOL, V123, P1067, DOI 10.1016/j.clinph.2012.01.011
   Stam CJ, 2007, HUM BRAIN MAPP, V28, P1178, DOI 10.1002/hbm.20346
   Strauss A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00350
   Stropahl M, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00309
   Szalardy O, 2013, BIOL PSYCHOL, V93, P97, DOI 10.1016/j.biopsycho.2013.01.015
   Szalardy O, 2020, PSYCHOPHYSIOLOGY, V57, DOI 10.1111/psyp.13547
   Szalardy O, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00786
   Szalardy O, 2018, COGN AFFECT BEHAV NE, V18, P932, DOI 10.3758/s13415-018-0614-4
   Tadel F, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/879716
   Toth B, 2020, CORTEX, V130, P387, DOI 10.1016/j.cortex.2020.06.007
   Toth B, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212754
   van Norden L. P. A. S., 1975, TEMPORAL COHERENCE P
   Winkler I, 2012, PHILOS T R SOC B, V367, P1001, DOI 10.1098/rstb.2011.0359
   Woldorff MG, 2004, J COGNITIVE NEUROSCI, V16, P149, DOI 10.1162/089892904322755638
   Womelsdorf T, 2007, CURR OPIN NEUROBIOL, V17, P154, DOI 10.1016/j.conb.2007.02.002
   WOOD NL, 1995, J EXP PSYCHOL GEN, V124, P243, DOI 10.1037/0096-3445.124.3.243
   Xia MR, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068910
   Zalesky A, 2010, NEUROIMAGE, V53, P1197, DOI 10.1016/j.neuroimage.2010.06.041
NR 79
TC 0
Z9 0
U1 5
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0048-5772
EI 1469-8986
J9 PSYCHOPHYSIOLOGY
JI Psychophysiology
AR e13747
DI 10.1111/psyp.13747
EA DEC 2020
PG 18
WC Psychology, Biological; Neurosciences; Physiology; Psychology;
   Psychology, Experimental
SC Psychology; Neurosciences & Neurology; Physiology
GA PE3HA
UT WOS:000598257200001
PM 33314262
DA 2021-02-24
ER

PT J
AU Magyari, L
   Huszar, Z
   Turzo, A
   Andics, A
AF Magyari, L.
   Huszar, Zs.
   Turzo, A.
   Andics, A.
TI Event-related potentials reveal limited readiness to access phonetic
   details during word processing in dogs
SO ROYAL SOCIETY OPEN SCIENCE
LA English
DT Article
DE dog; word processing; event-related potentials; phonetic similarity
ID SPEECH-PERCEPTION; INFANTS; DISCRIMINATION; SENSITIVITY; SOUND
AB While dogs have remarkable abilities for social cognition and communication, the number of words they learn to recognize typically remains very low. The reason for this limited capacity is still unclear. We hypothesized that despite their human-like auditory abilities for analysing speech sounds, their word processing capacities might be less ready to access phonetic details. To test this, we developed procedures for non-invasive measurement of event-related potentials (ERPs) for language stimuli in awake dogs (n = 17). Dogs listened to familiar instruction words and phonetically similar and dissimilar nonsense words. We compared two different artefact cleaning procedures on the same data; they led to similar results. An early (200-300 ms; only after one of the cleaning procedures) and a late (650-800 ms; after both cleaning procedures) difference was present in the ERPs for known versus phonetically dissimilar nonsense words. There were no differences between the ERPs for known versus phonetically similar nonsense words. ERPs of dogs who heard the instructions more often also showed larger differences between instructions and dissimilar nonsense words. The study revealed not only dogs' sensitivity to known words, but also their limited capacity to access phonetic details. Future work should confirm the reported ERP correlates of word processing abilities in dogs.
C1 [Magyari, L.; Turzo, A.; Andics, A.] Eotvos Lorand Univ, Hungarian Acad Sci, MTA ELTE Lendulet Neuroethol Commun Res Grp, H-1117 Budapest, Hungary.
   [Magyari, L.; Huszar, Zs.; Turzo, A.; Andics, A.] Eotvos Lorand Univ, Inst Biol, Dept Ethol, H-1117 Budapest, Hungary.
   [Magyari, L.] Eotvos Lorand Univ, Inst Psychol, Dept Cognit Psychol, H-1064 Budapest, Hungary.
   [Huszar, Zs.] Budapest Univ Technol & Econ, Fac Nat Sci, Dept Cognit Sci, H-1111 Budapest, Hungary.
RP Magyari, L (corresponding author), Eotvos Lorand Univ, Hungarian Acad Sci, MTA ELTE Lendulet Neuroethol Commun Res Grp, H-1117 Budapest, Hungary.; Magyari, L (corresponding author), Eotvos Lorand Univ, Inst Biol, Dept Ethol, H-1117 Budapest, Hungary.; Magyari, L (corresponding author), Eotvos Lorand Univ, Inst Psychol, Dept Cognit Psychol, H-1064 Budapest, Hungary.
EM lillamagyari@gmail.com
OI Magyari, Lilla/0000-0002-1188-2593
FU Hungarian Academy of SciencesHungarian Academy of Sciences
   [LP2017-13/2017]; Eotvos Lorand University; National Research,
   Development and Innovation Office (NKFI, OTKA)Orszagos Tudomanyos
   Kutatasi Alapprogramok (OTKA) [FK125417]
FX The study was supported by the Hungarian Academy of Sciences via a grant
   to the MTA-ELTE 'Lendulet' Neuroethology of Communication Research Group
   (grant no. LP2017-13/2017) and the Eotvos Lorand University. L.M. also
   received funding from National Research, Development and Innovation
   Office (NKFI, OTKA no. FK125417).
CR ADAMS CL, 1987, DEV NEUROPSYCHOL, V3, P175, DOI 10.1080/87565648709540375
   Andics A, 2016, SCIENCE, V353, P1030, DOI 10.1126/science.aaf3777
   Baru AV, 1975, AUDITORY ANAL PERCEP, P91
   Becker ABC, 2014, DEV COGN NEUROS-NETH, V9, P44, DOI 10.1016/j.dcn.2013.12.004
   Boersma P., 2018, PRAAT DOING PHONETIC
   Czeibert K, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0213458
   DeBoer T., 2007, INFANT EEG EVENT REL, P5, DOI DOI 10.4324/9780203759660
   DEWSON JH, 1964, SCIENCE, V144, P555, DOI 10.1126/science.144.3618.555
   Fennell CT, 2012, INFANCY, V17, P339, DOI 10.1111/j.1532-7078.2011.00080.x
   Fitch WT, 2017, PSYCHON B REV, V24, P3, DOI 10.3758/s13423-017-1236-5
   Forgacs B, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12751
   FOX M. W., 1967, J SMALL ANIMPRACT, V8, P703, DOI 10.1111/j.1748-5827.1967.tb04521.x
   Friedrich M, 2005, J COGNITIVE NEUROSCI, V17, P1785, DOI 10.1162/089892905774589172
   Friedrich M, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12357
   Fukuzawa M, 2005, J COMP PSYCHOL, V119, P117, DOI 10.1037/0735-7036.119.1.117
   Gibson JM, 2014, ABC, V1, P281, DOI DOI 10.12966/ABC.08.05.2014
   Gonzalez-Gomez N, 2019, J EXP CHILD PSYCHOL, V178, P170, DOI 10.1016/j.jecp.2018.08.014
   Gregg NM, 2020, BRAIN COMMUN, V2, DOI 10.1093/braincomms/fcaa008
   Howell TJ, 2012, BEHAV PROCESS, V89, P8, DOI 10.1016/j.beproc.2011.09.009
   Iotcheve IB, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46434-y
   Kaminski J, 2004, SCIENCE, V304, P1682, DOI 10.1126/science.1097859
   KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572
   Kis A, 2017, SCI REP-UK, V7, DOI 10.1038/srep41873
   Kis A, 2014, PHYSIOL BEHAV, V130, P149, DOI 10.1016/j.physbeh.2014.04.004
   Kleiner M, 2007, PERCEPTION, V36, P14
   KLUENDER KR, 1987, SCIENCE, V237, P1195, DOI 10.1126/science.3629235
   Kujala MV, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0061818
   Lausberg H, 2009, BEHAV RES METHODS, V41, P841, DOI 10.3758/BRM.41.3.841
   Mani N, 2012, DEVELOPMENTAL SCI, V15, P2, DOI 10.1111/j.1467-7687.2011.01092.x
   Mills DL, 2005, COGNITIVE DEV, V20, P19, DOI 10.1016/j.cogdev.2004.07.001
   Mills DL, 2004, J COGNITIVE NEUROSCI, V16, P1452, DOI 10.1162/0898929042304697
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Pepperberg IM, 2010, BRAIN LANG, V115, P81, DOI 10.1016/j.bandl.2009.11.002
   Pilley JW, 2011, BEHAV PROCESS, V86, P184, DOI 10.1016/j.beproc.2010.11.007
   R Core Team, 2018, R LANG ENV STAT COMP
   Ratcliffe VF, 2014, CURR BIOL, V24, DOI 10.1016/j.cub.2014.10.030
   Rouder JN, 2012, J MATH PSYCHOL, V56, P356, DOI 10.1016/j.jmp.2012.08.001
   SAVAGERUMBAUGH ES, 1993, MONOGR SOC RES CHILD, V58, pR5
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Swingley D, 2009, PHILOS T R SOC B, V364, P3617, DOI 10.1098/rstb.2009.0107
   Thierry G, 2003, NEUROREPORT, V14, P2307, DOI 10.1097/00001756-200312190-00004
   Tornqvist H, 2013, ANIM COGN, V16, P973, DOI 10.1007/s10071-013-0630-2
   Viranyi Z, 2004, BEHAV PROCESS, V66, P161, DOI 10.1016/j.beproc.2004.01.012
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   White KS, 2013, J MEM LANG, V68, P362, DOI 10.1016/j.jml.2013.01.003
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3_1
NR 47
TC 0
Z9 0
U1 3
U2 3
PU ROYAL SOC
PI LONDON
PA 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND
SN 2054-5703
J9 ROY SOC OPEN SCI
JI R. Soc. Open Sci.
PD DEC 9
PY 2020
VL 7
IS 12
AR 200851
DI 10.1098/rsos.200851
PG 13
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA PH1YW
UT WOS:000600218300001
PM 33489257
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Farahani, ED
   Wouters, J
   van Wieringen, A
AF Farahani, Ehsan Darestani
   Wouters, Jan
   van Wieringen, Astrid
TI Neural Generators Underlying Temporal Envelope Processing Show Altered
   Responses and Hemispheric Asymmetry Across Age
SO FRONTIERS IN AGING NEUROSCIENCE
LA English
DT Article
DE aging; neural generators; auditory temporal processing; ASSR; auditory
   steady-state response; EEG
ID STEADY-STATE RESPONSES; AUDITORY-EVOKED POTENTIALS;
   AMPLITUDE-MODULATION; SPEECH-PERCEPTION; NORMAL-HEARING; PHASE-LOCKING;
   AGING ALTERS; OLDER-ADULTS; MEG; FMRI
AB Speech understanding problems are highly prevalent in the aging population, even when hearing sensitivity is clinically normal. These difficulties are attributed to changes in central temporal processing with age and can potentially be captured by age-related changes in neural generators. The aim of this study is to investigate age-related changes in a wide range of neural generators during temporal processing in middle-aged and older persons with normal audiometric thresholds. A minimum-norm imaging technique is employed to reconstruct cortical and subcortical neural generators of temporal processing for different acoustic modulations. The results indicate that for relatively slow modulations (<50 Hz), the response strength of neural sources is higher in older adults than in younger ones, while the phase-locking does not change. For faster modulations (80 Hz), both the response strength and the phase-locking of neural sources are reduced in older adults compared to younger ones. These age-related changes in temporal envelope processing of slow and fast acoustic modulations are possibly due to loss of functional inhibition, which is accompanied by aging. Both cortical (primary and non-primary) and subcortical neural generators demonstrate similar age-related changes in response strength and phase-locking. Hemispheric asymmetry is also altered in older adults compared to younger ones. Alterations depend on the modulation frequency and side of stimulation. The current findings at source level could have important implications for the understanding of age-related changes in auditory temporal processing and for developing advanced rehabilitation strategies to address speech understanding difficulties in the aging population.
C1 [Farahani, Ehsan Darestani; Wouters, Jan; van Wieringen, Astrid] Katholieke Univ Leuven, Res Grp Expt Otorhino Laryngol ExpORL, Dept Neurosci, Leuven, Belgium.
RP Farahani, ED (corresponding author), Katholieke Univ Leuven, Res Grp Expt Otorhino Laryngol ExpORL, Dept Neurosci, Leuven, Belgium.
EM ehsan.darestani@kuleuven.be
OI Darestani Farahani, Ehsan/0000-0002-1559-3676
FU Research Council, KU LeuvenKU Leuven [C14/19/110, C14/17/046]; Research
   Foundation Flanders through FWO-projects [G066213, G0A9115]
FX This work was supported by the Research Council, KU Leuven, through
   projects C14/19/110, C14/17/046, and by the Research Foundation Flanders
   through FWO-projects G066213 and G0A9115.
CR Anderson S, 2012, J NEUROSCI, V32, P14156, DOI 10.1523/JNEUROSCI.2176-12.2012
   Ben Shalom D, 2008, NEUROSCIENTIST, V14, P119, DOI 10.1177/1073858407305726
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Berlingeri M, 2013, EXP BRAIN RES, V224, P393, DOI 10.1007/s00221-012-3319-x
   Boettcher FA, 2001, HEARING RES, V153, P32, DOI 10.1016/S0378-5955(00)00255-0
   Bradley A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147266
   Cabeza R, 2002, NEUROIMAGE, V17, P1394, DOI 10.1006/nimg.2002.1280
   Cabeza R, 2002, PSYCHOL AGING, V17, P85, DOI 10.1037//0882-7974.17.1.85
   Caspary DM, 2008, J EXP BIOL, V211, P1781, DOI 10.1242/jeb.013581
   Caspary DM, 2013, NEUROBIOL AGING, V34, P1486, DOI 10.1016/j.neurobiolaging.2012.11.009
   Chambers AR, 2016, NEURON, V89, P867, DOI 10.1016/j.neuron.2015.12.041
   Chen JL, 2013, HUM BRAIN MAPP, V34, P852, DOI 10.1002/hbm.21475
   Clinard CG, 2013, J AM ACAD AUDIOL, V24, P590, DOI 10.3766/jaaa.24.7.7
   Clinard CG, 2010, HEARING RES, V264, P48, DOI 10.1016/j.heares.2009.11.010
   Coffey EBJ, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11070
   Cogan GB, 2011, J NEUROPHYSIOL, V106, P554, DOI 10.1152/jn.00075.2011
   Cohen B. H., 2002, Understanding Statistics, V1, P191, DOI 10.1207/S15328031US0103_04
   Cohen J., 1988, STAT POWER ANAL BEHA
   Dale AM, 2000, NEURON, V26, P55, DOI 10.1016/S0896-6273(00)81138-1
   Del Gratta C, 2002, NEUROIMAGE, V17, P1373, DOI 10.1006/nimg.2002.1253
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Dimitrijevic A, 2004, EAR HEARING, V25, P68, DOI 10.1097/01.AUD.0000111545.71693.48
   Dobie RA, 1996, J ACOUST SOC AM, V100, P2236, DOI 10.1121/1.417933
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P2670, DOI 10.1121/1.409836
   Du Y, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12241
   Edgar JC, 2017, PSYCHOPHYSIOLOGY, V54, P1110, DOI 10.1111/psyp.12876
   EFRON B, 1981, ANN STAT, V9, P586, DOI 10.1214/aos/1176345462
   Farahani ED, 2021, HUM BRAIN MAPP, V42, P780, DOI 10.1002/hbm.25262
   Farahani ED, 2019, NEUROIMAGE, V191, P303, DOI 10.1016/j.neuroimage.2019.02.037
   Farahani ED, 2017, NEUROIMAGE, V148, P240, DOI 10.1016/j.neuroimage.2017.01.032
   Fonov V, 2011, NEUROIMAGE, V54, P313, DOI 10.1016/j.neuroimage.2010.07.033
   Frisina RD, 2006, HEARING RES, V216, P216, DOI 10.1016/j.heares.2006.02.003
   Ghumare EG, 2018, BRAIN TOPOGR, V31, P721, DOI 10.1007/s10548-018-0621-3
   Giraud AL, 2000, J NEUROPHYSIOL, V84, P1588
   Giroud N, 2019, NEUROBIOL AGING, V80, P116, DOI 10.1016/j.neurobiolaging.2019.04.017
   Giroud N, 2018, EUR J NEUROSCI, V47, P58, DOI 10.1111/ejn.13772
   Goossens T, 2019, NEUROBIOL AGING, V74, P202, DOI 10.1016/j.neurobiolaging.2018.10.008
   Goossens T, 2017, HEARING RES, V344, P109, DOI 10.1016/j.heares.2016.11.004
   Goossens T, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00133
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Gramfort A, 2010, BIOMED ENG ONLINE, V9, DOI 10.1186/1475-925X-9-45
   Greenwald R R, 2001, J Am Acad Audiol, V12, P167
   Hamalainen JA, 2012, NEUROIMAGE, V59, P2952, DOI 10.1016/j.neuroimage.2011.09.075
   Hauk O, 2011, NEUROIMAGE, V54, P1966, DOI 10.1016/j.neuroimage.2010.09.053
   He B, 2018, ANNU REV BIOMED ENG, V20, P171, DOI 10.1146/annurev-bioeng-062117-120853
   Hemond CC, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000574
   Herdman AT, 2002, BRAIN TOPOGR, V15, P69, DOI 10.1023/A:1021470822922
   Herrmann B, 2017, EUR J NEUROSCI, V45, P299, DOI 10.1111/ejn.13463
   Hincapie AS, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3979547
   Hughes LF, 2010, HEARING RES, V264, P79, DOI 10.1016/j.heares.2009.09.005
   International Organization for Standardization, 2000, ISO7029
   John MS, 2000, HEARING RES, V141, P57, DOI 10.1016/S0378-5955(99)00209-9
   Kang SS, 2015, NEUROPSYCHIATR ELECT, V1, P9, DOI [10.1186/s40810-015-0009-5, DOI 10.1186/S40810-015-0009-5]
   Koerner TK, 2015, HEARING RES, V328, P113, DOI 10.1016/j.heares.2015.08.002
   Langers DRM, 2005, NEUROIMAGE, V28, P490, DOI 10.1016/j.neuroimage.2005.06.024
   Lehmann C, 2007, NEUROIMAGE, V34, P1637, DOI 10.1016/j.neuroimage.2006.11.011
   Leigh-Paffenroth ED, 2006, J AM ACAD AUDIOL, V17, P582, DOI 10.3766/jaaa.17.8.5
   Leigh-Paffenroth ED, 2011, J AM ACAD AUDIOL, V22, P393, DOI 10.3766/jaaa.22.7.2
   Liegeois-Chauvel C, 2004, CEREB CORTEX, V14, P731, DOI 10.1093/cercor/bhh033
   Lin FH, 2006, NEUROIMAGE, V31, P160, DOI 10.1016/j.neuroimage.2005.11.054
   Ling LL, 2005, NEUROSCIENCE, V132, P1103, DOI 10.1016/j.neuroscience.2004.12.043
   Livingston G, 2017, LANCET, V390, P2673, DOI 10.1016/S0140-6736(17)31363-6
   Luke R, 2017, NEUROIMAGE, V147, P568, DOI 10.1016/j.neuroimage.2016.11.023
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Millman RE, 2017, J NEUROSCI, V37, P7727, DOI 10.1523/JNEUROSCI.2722-16.2017
   Nagy P., 2013, N WAY ANOVA SUMMARY
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Ostroff JM, 2003, HEARING RES, V181, P1, DOI 10.1016/S0378-5955(03)00113-8
   Overath T, 2012, J NEUROPHYSIOL, V107, P2042, DOI 10.1152/jn.00308.2011
   Parthasarathy A, 2019, NEUROBIOL AGING, V73, P30, DOI 10.1016/j.neurobiolaging.2018.08.023
   Parthasarathy A, 2014, JARO-J ASSOC RES OTO, V15, P649, DOI 10.1007/s10162-014-0460-1
   Parthasarathy A, 2012, HEARING RES, V289, P52, DOI 10.1016/j.heares.2012.04.014
   Parthasarathy A, 2010, FRONT AGING NEUROSCI, V2, DOI 10.3389/fnagi.2010.00152
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   PERRIN F, 1989, ELECTROEN CLIN NEURO, V72, P184, DOI 10.1016/0013-4694(89)90180-6
   Picton T, 2013, EAR HEARING, V34, P385, DOI 10.1097/AUD.0b013e31827ada02
   Picton Terence W, 2005, J Am Acad Audiol, V16, P140, DOI 10.3766/jaaa.16.3.3
   Picton TW, 2001, CLIN NEUROPHYSIOL, V112, P1698, DOI 10.1016/S1388-2457(01)00608-3
   Poelmans H, 2012, JARO-J ASSOC RES OTO, V13, P867, DOI 10.1007/s10162-012-0348-x
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Poulsen C, 2007, CEREB CORTEX, V17, P1454, DOI 10.1093/cercor/bhl056
   Presacco A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0213899
   Presacco A, 2015, EAR HEARING, V36, pE352, DOI 10.1097/AUD.0000000000000193
   Purcell DW, 2004, J ACOUST SOC AM, V116, P3581, DOI 10.1121/1.1798354
   Roque L, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00749
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Ross B, 2005, CEREB CORTEX, V15, P2029, DOI 10.1093/cercor/bhi078
   Ross B, 2008, J NEUROPHYSIOL, V100, P1265, DOI 10.1152/jn.00048.2008
   Ross B, 2007, J NEUROSCI, V27, P11172, DOI 10.1523/JNEUROSCI.1813-07.2007
   Ross B, 2020, NEUROIMAGE, V204, DOI 10.1016/j.neuroimage.2019.116253
   Ross B, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010101
   Rueda-Delgado LM, 2017, NEUROIMAGE, V146, P883, DOI 10.1016/j.neuroimage.2016.10.030
   Sawilowsky SS, 2009, J MOD APPL STAT METH, V8, P597, DOI 10.22237/jmasm/1257035100
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Steinmann I, 2011, NEUROIMAGE, V54, P495, DOI 10.1016/j.neuroimage.2010.07.064
   Stone MA, 2010, J ACOUST SOC AM, V128, P2127, DOI 10.1121/1.3479546
   Sullivan Gail M, 2012, J Grad Med Educ, V4, P279, DOI 10.4300/JGME-D-12-00156.1
   Tadel F, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00076
   Tadel F, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/879716
   Tlumak AI, 2015, AM J AUDIOL, V24, P494, DOI 10.1044/2015_AJA-15-0036
   Vanvooren S, 2014, J NEUROSCI, V34, P1523, DOI 10.1523/JNEUROSCI.3209-13.2014
   Walton JP, 1998, J NEUROSCI, V18, P2764
   Walton JP, 2002, J NEUROPHYSIOL, V88, P565, DOI 10.1152/jn.2002.88.2.565
NR 105
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1663-4365
J9 FRONT AGING NEUROSCI
JI Front. Aging Neurosci.
PD DEC 4
PY 2020
VL 12
AR 596551
DI 10.3389/fnagi.2020.596551
PG 18
WC Geriatrics & Gerontology; Neurosciences
SC Geriatrics & Gerontology; Neurosciences & Neurology
GA PG2MS
UT WOS:000599575400001
PM 33343335
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Zhang, LJ
   Li, Y
   Zhou, H
   Zhang, Y
   Shu, H
AF Zhang, Linjun
   Li, Yu
   Zhou, Hong
   Zhang, Yang
   Shu, Hua
TI Sentence Context Differentially Modulates Contributions of Fundamental
   Frequency Contours to Word Recognition in Chinese-Speaking Children With
   and Without Dyslexia
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE dyslexia; word recognition; semantic context; F-0 contours; noise
ID SPEECH-PERCEPTION; DEVELOPMENTAL DYSLEXIA; DEFICIT; MEMORY; LEVEL;
   NOISE; INTELLIGIBILITY; DISCRIMINATION; IMPAIRMENT; ADULTS
AB Previous work has shown that children with dyslexia are impaired in speech recognition in adverse listening conditions. Our study further examined how semantic context and fundamental frequency (F-0) contours contribute to word recognition against interfering speech in dyslexic and non-dyslexic children. Thirty-two children with dyslexia and 35 chronological-age-matched control children were tested on the recognition of words in normal sentences versus wordlist sentences with natural versus flat F-0 contours against single-talker interference. The dyslexic children had overall poorer recognition performance than non-dyslexic children. Furthermore, semantic context differentially modulated the effect of F-0 contours on the recognition performances of the two groups. Specifically, compared with flat F-0 contours, natural F-0 contours increased the recognition accuracy of dyslexic children less than non-dyslexic children in the wordlist condition. By contrast, natural F-0 contours increased the recognition accuracy of both groups to a similar extent in the sentence condition. These results indicate that access to semantic context improves the effect of natural F-0 contours on word recognition in adverse listening conditions by dyslexic children who are more impaired in the use of natural F-0 contours during isolated and unrelated word recognition. Our findings have practical implications for communication with dyslexic children when listening conditions are unfavorable.
C1 [Zhang, Linjun] Beijing Language & Culture Univ, Beijing Adv Innovat Ctr Language Resources, Beijing, Peoples R China.
   [Zhang, Linjun] Beijing Language & Culture Univ, Coll Adv Chinese Training, Beijing, Peoples R China.
   [Li, Yu] Hong Kong Baptist Univ, Beijing Normal Univ, United Int Coll, Dept Appl Psychol, Zhuhai, Peoples R China.
   [Zhou, Hong] Shanghai Univ Finance & Econ, Int Cultural Exchange Sch, Shanghai, Peoples R China.
   [Zhang, Yang] Univ Minnesota, Dept Speech Language Hearing Sci, Minneapolis, MN USA.
   [Zhang, Yang] Univ Minnesota, Ctr Neurobehav Dev, Minneapolis, MN USA.
   [Shu, Hua] Beijing Normal Univ, Natl Key Lab Cognit Neurosci & Learning, Beijing, Peoples R China.
RP Zhou, H (corresponding author), Shanghai Univ Finance & Econ, Int Cultural Exchange Sch, Shanghai, Peoples R China.
EM hellozhouhong@163.com
RI Zhang, Yang/Q-1780-2015
OI Zhang, Yang/0000-0001-6777-3487
FU Social Science Fund of Beijing [17YYA004]; National Social Science Fund
   of China [20BYY092]; Discipline Team Support Program of Beijing Language
   and Culture University [JC201901]; Humanities and Social Sciences Fund
   of Ministry of Education of ChinaMinistry of Education, China
   [20YJCZH079]
FX This research was supported by the Social Science Fund of Beijing
   (17YYA004), the National Social Science Fund of China (20BYY092), and
   the Discipline Team Support Program of Beijing Language and Culture
   University (JC201901) to LZ, and the Humanities and Social Sciences Fund
   of Ministry of Education of China (20YJCZH079) to YL.
CR Binns C, 2007, J ACOUST SOC AM, V122, P1765, DOI 10.1121/1.2751394
   Blomert L, 2004, J SPEECH LANG HEAR R, V47, P1030, DOI 10.1044/1092-4388(2004/077)
   Boets B, 2007, BRAIN LANG, V101, P19, DOI 10.1016/j.bandl.2006.06.009
   Bogliotti C, 2008, J EXP CHILD PSYCHOL, V101, P137, DOI 10.1016/j.jecp.2008.03.006
   BRADY S, 1983, J EXP CHILD PSYCHOL, V35, P345, DOI 10.1016/0022-0965(83)90087-5
   Cheung H, 2009, J CHILD PSYCHOL PSYC, V50, P726, DOI 10.1111/j.1469-7610.2008.02001.x
   COLE RA, 1980, J VERB LEARN VERB BE, V19, P297, DOI 10.1016/S0022-5371(80)90239-X
   Dole M, 2012, NEUROPSYCHOLOGIA, V50, P1543, DOI 10.1016/j.neuropsychologia.2012.03.007
   Dubno JR, 2000, J ACOUST SOC AM, V107, P538, DOI 10.1121/1.428322
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   Jiang W, 2017, J ACOUST SOC AM, V141, pEL338, DOI 10.1121/1.4979565
   Landerl K, 2009, J EXP CHILD PSYCHOL, V103, P309, DOI 10.1016/j.jecp.2009.03.006
   Laures JS, 2003, J COMMUN DISORD, V36, P449, DOI 10.1016/S0021-9924(03)00032-7
   Lecumberri MLG, 2006, J ACOUST SOC AM, V119, P2445, DOI 10.1121/1.2180210
   Lei L, 2011, J CHILD PSYCHOL PSYC, V52, P212, DOI 10.1111/j.1469-7610.2010.02311.x
   Liu H, 1997, APPL PSYCHOLINGUIST, V18, P157, DOI 10.1017/S0142716400009954
   Marshall CR, 2009, INT J LANG COMM DIS, V44, P466, DOI 10.1080/13682820802591643
   Maxwell S. E., 2004, DESIGNING EXPT ANAL, V2nd
   McInnes A, 2003, J ABNORM CHILD PSYCH, V31, P427, DOI 10.1023/A:1023895602957
   Miller SE, 2010, J ACOUST SOC AM, V128, P435, DOI 10.1121/1.3397384
   Nittrouer S, 2018, RES DEV DISABIL, V77, P98, DOI 10.1016/j.ridd.2018.04.014
   Nittrouer S, 2011, J EXP CHILD PSYCHOL, V108, P762, DOI 10.1016/j.jecp.2010.10.012
   Patel A. D., 2010, P SPEECH PROS 2010 C
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   REED MA, 1989, J EXP CHILD PSYCHOL, V48, P270, DOI 10.1016/0022-0965(89)90006-4
   Scott SK, 2004, J ACOUST SOC AM, V115, P813, DOI 10.1121/1.1639336
   Shu H, 2006, J EDUC PSYCHOL, V98, P122, DOI 10.1037/0022-0663.98.1.122
   Shu H, 2003, CHILD DEV, V74, P27, DOI 10.1111/1467-8624.00519
   Snowling M., 2000, DYSLEXIA
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Tannock R, 2000, J ABNORM CHILD PSYCH, V28, P237, DOI 10.1023/A:1005192220001
   Tiffin-Richards MC, 2008, J NEURAL TRANSM, V115, P227, DOI 10.1007/s00702-007-0816-3
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   Wang JJ, 2013, J ACOUST SOC AM, V134, pEL91, DOI 10.1121/1.4811159
   Watson PJ, 2008, AM J SPEECH-LANG PAT, V17, P348, DOI 10.1044/1058-0360(2008/07-0048)
   Xu GQ, 2013, NEUROPSYCHOLOGIA, V51, P550, DOI 10.1016/j.neuropsychologia.2012.12.006
   Zhang LJ, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00908
   Zhang YJ, 2012, J CHILD PSYCHOL PSYC, V53, P874, DOI 10.1111/j.1469-7610.2012.02528.x
   Zhou H, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01090
   Ziegler JC, 2009, DEVELOPMENTAL SCI, V12, P732, DOI 10.1111/j.1467-7687.2009.00817.x
NR 40
TC 0
Z9 0
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD DEC 3
PY 2020
VL 11
AR 598658
DI 10.3389/fpsyg.2020.598658
PG 7
WC Psychology, Multidisciplinary
SC Psychology
GA PF8CM
UT WOS:000599275700001
PM 33343469
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Fazal, MA
   Ferguson, S
   Johnston, A
AF Fazal, Muhammad Abu Ul
   Ferguson, Sam
   Johnston, Andrew
TI Evaluation of Information Comprehension in Concurrent Speech-based
   Designs
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Concurrent speech; audio streams; auditory display; concurrent
   streaming; voice-based interaction; concurrent speech-based information
   comprehension; audio spatial location; intermittent & continuous speech
   presentation; comprehension depth; speech perception; listening
   comprehension
ID COCKTAIL PARTY; DISCOURSE
AB In human-computer interaction, particularly in multimedia delivery, information is communicated to users sequentially, whereas users are capable of receiving information from multiple sources concurrently. This mismatch indicates that a sequential mode of communication does not utilise human perception capabilities as efficiently as possible. This article reports an experiment that investigated various speech-based (audio) concurrent designs and evaluated the comprehension depth of information by comparing comprehension performance across several different formats of questions (main/detailed, implied/stated). The results showed that users, besides answering the main questions, were also successful in answering the implied questions, as well as the questions that required detailed information, and that the pattern of comprehension depth remained similar to that seen to a baseline condition, where only one speech source was presented. However, the participants answered more questions correctly that were drawn from the main information, and performance remained low where the questions were drawn from detailed information. The results are encouraging to explore the concurrent methods further for communicating multiple information streams efficiently in human-computer interaction, including multimedia.
C1 [Fazal, Muhammad Abu Ul; Ferguson, Sam; Johnston, Andrew] Univ Technol, Fac Engn & IT, Sch Comp Sci, Creat & Cognit Studios, Sydney, NSW 2007, Australia.
RP Fazal, MA (corresponding author), Univ Technol, Fac Engn & IT, Sch Comp Sci, Creat & Cognit Studios, Sydney, NSW 2007, Australia.
EM fazalsidhu@gmail.com; Samuel.Ferguson@uts.edu.au;
   Andrew.Johnston@uts.edu.au
FU School of Computer Science, Faculty of Engineering and IT, University of
   Technology, Sydney, Australia
FX This research was supported by the School of Computer Science, Faculty
   of Engineering and IT, University of Technology, Sydney, Australia.
CR Fazal MA, 2019, PROCEEDINGS OF 3RD INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND DATA MINING (ICISDM 2019), P143, DOI 10.1145/3325917.3325922
   Fazal MA, 2018, 2018 CONFERENCE ON INTERACTION WITH SOUND (AUDIO MOSTLY): SOUND IN IMMERSION AND EMOTION (AM'18), DOI 10.1145/3243274.3243284
   Abu ul Fazal M, 2017, ADV INTELL SYST, V506, P101, DOI 10.1007/978-3-319-43982-2_9
   Abu ul Fazal Muhammad, 2019, THESIS
   Abu ul Fazal Muhammad, 2018, P 145 CONV AUD ENG S
   Alvarez Yolanda Vazquez, 2010, P MOBILEHCI 10, P253
   Aydelott J, 2015, J ACOUST SOC AM, V138, P964, DOI 10.1121/1.4927410
   Aydelott J, 2012, LANG COGNITIVE PROC, V27, P1108, DOI 10.1080/01690965.2011.589735
   Beattie David, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3130901
   Beattie D, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P451, DOI 10.1145/2750858.2807519
   Best V, 2006, J ACOUST SOC AM, V120, P1506, DOI 10.1121/1.2234849
   Biatov Konstantin, 2003, P 11 ACM INT C MULT, P211
   Brayda Luca, 2015, P 2015 ACM INT JOINT, DOI DOI 10.1145/2800835.2806207
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   Bregman AS., 1994, AUDITORY SCENE ANAL
   Brookshire Robert H., 1997, DISCOURSE COMPREHENS
   Brungart D. S., 2005, ACM T APPL PERCEPT, V2, P430, DOI DOI 10.1145/1101530.1101538
   Chernyshov G, 2016, IEEE INT SYM WRBL CO, P58, DOI 10.1145/2971763.2971789
   Church K, 2014, ACM T COMPUT-HUM INT, V21, DOI 10.1145/2552193
   Conway ARA, 2001, PSYCHON B REV, V8, P331, DOI 10.3758/BF03196169
   Csapo A, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543586
   Dix Alan, 2003, HUM FAC ER
   Doherty J, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487273
   Elhilali M, 2008, J ACOUST SOC AM, V124, P3751, DOI 10.1121/1.3001672
   Feng Wu-chi, 2012, P 22 INT WORKSH NETW, P57
   Griffiths TD, 2004, NAT REV NEUROSCI, V5, P887, DOI 10.1038/nrn1538
   Guerreiro J, 2016, ACM T ACCESS COMPUT, V8, DOI 10.1145/2822910
   Guerreiro Joao, 2013, P 10 INT CROSS DISC, P8
   Guerreiro Joao, 2016, ACM SIGACCESS ACCESS, V115, P12, DOI DOI 10.1145/2961108.2961110
   Guerreiro Joao, 2014, P 16 INT ACM SIGACCE, P169, DOI DOI 10.1145/2661334.2661367
   Gulliver SR, 2006, ACM T MULTIM COMPUT, V2, P241, DOI 10.1145/1201730.1201731
   Hinde Alistair F., 2016, THESIS
   Hines A, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1173, DOI 10.1145/2647868.2655025
   Iyer Nandini, 2013, P M AC, V19
   Kortum P, 2008, MORG KAUF SER INTER, P1, DOI 10.1016/B978-0-12-374017-5.00001-8
   LAWSON EA, 1966, Q J EXP PSYCHOL, V18, P260, DOI 10.1080/14640746608400038
   Li GP, 2005, Seventh International Conference on Electronic Commerce, Vols 1 and 2, Selected Proceedings, P66
   Matassa Assunta, 2015, ADJ P 2015 ACM INT J, P923, DOI DOI 10.1145/2800835.2806201
   McDermott JH, 2009, CURR BIOL, V19, pR1024, DOI 10.1016/j.cub.2009.09.005
   McGookin D., 2004, ACM T APPL PERCEPT, V1, P130, DOI DOI 10.1145/1024083.1024087
   Moffat D, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3165287
   MORAY N, 1959, Q J EXP PSYCHOL, V11, P56, DOI 10.1080/17470215908416289
   Nelson Cowan, 1995, OXFORD PSYCHOL SER, V26, P1995
   Obermeyer JA, 2018, AM J SPEECH-LANG PAT, V27, P392, DOI 10.1044/2017_AJSLP-16-0200
   Patel D, 2018, PROCEEDINGS OF CHINESE CHI 2018: SIXTH INTERNATIONAL SYMPOSIUM OF CHINESE CHI (CHINESE CHI 2018), P160, DOI 10.1145/3202667.3202696
   Qudah B, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823754
   Rivenez M, 2006, J ACOUST SOC AM, V119, P4027, DOI 10.1121/1.2190162
   Sato D, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2769
   Schmandt Chris, 1995, C COMP HUM FACT COMP, P218, DOI DOI 10.1145/223355.223533
   Welland RJ, 2002, J SPEECH LANG HEAR R, V45, P1175, DOI 10.1044/1092-4388(2002/095)
   WILLIAMS SM, 1994, SFI S SCI C, V18, P95
   Wu TT, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2983642
   Xu CS, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198303
   Zimmermann Roger, 2008, P 16 ACM INT C MULT, P299
NR 54
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD DEC
PY 2020
VL 16
IS 4
AR 129
DI 10.1145/3409463
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
SC Computer Science
GA QB4FR
UT WOS:000614096700013
DA 2021-02-24
ER

PT J
AU Pascalis, O
   Fort, M
   Quinn, PC
AF Pascalis, Olivier
   Fort, Mathilde
   Quinn, Paul C.
TI Development of face processing: are there critical or sensitive periods?
SO CURRENT OPINION IN BEHAVIORAL SCIENCES
LA English
DT Article
ID SELECTIVE ATTENTION; SPEECH-PERCEPTION; RACE; INFANCY; EXPERIENCE;
   LANGUAGE; TALKING; DISCRIMINATION; BILINGUALISM; RECOGNITION
AB The existence of critical or sensitive periods has been argued for cognitive functions such as language, which allows for communication with conspecifics. Faces also play a crucial role in establishing social communication. Here we discuss if critical or sensitive period concepts apply to face processing. We describe how experience shapes face processing during development. While there is not clear support for a critical period, there is some evidence of a sensitive period, with the face processing system showing early sensitivity to experience in the first year, remaining flexible until 10-12 years, and becoming less sensitive to experience thereafter. We also discuss possible links between sensitive periods for faces and language. We conclude that sensitive periods may reflect the need to adapt rapidly to the communication culture within one's native social group, while retaining a degree of openness to perturbations to one's local environment that can occur across the lifespan.
C1 [Pascalis, Olivier; Fort, Mathilde] Univ Grenoble Alpes, Lab Psychol & Neurocognit, Grenoble, France.
   [Fort, Mathilde] Univ Lyon 1, Inst Sci Cognit Marc Jeannerod, Villeurbanne, France.
   [Quinn, Paul C.] Univ Delaware, Dept Psychol & Brain Sci, Newark, DE 19716 USA.
RP Pascalis, O (corresponding author), Univ Grenoble Alpes, Lab Psychol & Neurocognit, Grenoble, France.; Quinn, PC (corresponding author), Univ Delaware, Dept Psychol & Brain Sci, Newark, DE 19716 USA.
EM olivier.pascalis@univ-grenoble-alpes.fr; pquinn@udel.edu
CR Anzures G, 2012, J EXP CHILD PSYCHOL, V112, P484, DOI 10.1016/j.jecp.2012.04.005
   Arcaro MJ, 2019, ANNU REV VIS SCI, V5, P341, DOI 10.1146/annurev-vision-091718-014917
   Ayneto A, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12446
   Bar-Haim Y, 2006, PSYCHOL SCI, V17, P159, DOI 10.1111/j.1467-9280.2006.01679.x
   Birules J, 2018, DEV SCI, V22
   de Heering A, 2010, DEVELOPMENTAL SCI, V13, P181, DOI 10.1111/j.1467-7687.2009.00876.x
   Emberson LL, 2015, P NATL ACAD SCI USA, V112, P9585, DOI 10.1073/pnas.1510343112
   Fort M, 2018, LANG LEARN, V68, P31, DOI 10.1111/lang.12273
   Frankenhuis WE, 2020, DEV COGN NEUROS-NETH, V41, DOI 10.1016/j.dcn.2019.100715
   Freiwald WA, 2020, CURR OPIN NEUROBIOL, V60, P184, DOI 10.1016/j.conb.2019.12.007
   Friedmann N, 2015, CURR OPIN NEUROBIOL, V35, P27, DOI 10.1016/j.conb.2015.06.003
   Gandhi TK, 2017, P NATL ACAD SCI USA, V114, P6139, DOI 10.1073/pnas.1616050114
   Gauthier I, 2001, CURR OPIN NEUROBIOL, V11, P219, DOI 10.1016/S0959-4388(00)00200-2
   Gauthier I, 2018, CURR DIR PSYCHOL SCI, V27, P97, DOI 10.1177/0963721417737151
   Heron-Delaney M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019858
   Jack RE, 2015, CURR BIOL, V25, pR621, DOI 10.1016/j.cub.2015.05.052
   Jayaraman S, 2019, VISION RES, V157, P213, DOI 10.1016/j.visres.2018.05.005
   Kandel S, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01080
   Kelly DJ, 2007, PSYCHOL SCI, V18, P1084, DOI 10.1111/j.1467-9280.2007.02029.x
   Kelly DJ, 2005, DEVELOPMENTAL SCI, V8, pF31, DOI 10.1111/j.1467-7687.2005.0434a.x
   Krasotkina A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01711
   Lai CK, 2016, J EXP PSYCHOL GEN, V145, DOI 10.1037/xge0000179
   Lebrecht S, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004215
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Marquis AR, 2019, DEV REV, V53, DOI 10.1016/j.dr.2019.100868
   Maurer D, 2017, COGNITIVE DEV, V42, P27, DOI 10.1016/j.cogdev.2017.02.006
   Mayberry RI, 2018, BILING-LANG COGN, V21, P886, DOI 10.1017/S1366728917000724
   McGugin RW, 2011, COGNITIVE SCI, V35, P330, DOI 10.1111/j.1551-6709.2010.01148.x
   McKone E, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49202-0
   Nelson CA, 2019, NEURAL PLAST, V2019, DOI 10.1155/2019/1676285
   Newport EL, 2018, BILING-LANG COGN, V21, P928, DOI 10.1017/S1366728918000305
   Ortiz-Mantilla S, 2016, J NEUROSCI, V36, P12095, DOI 10.1523/JNEUROSCI.1162-16.2016
   Pascalis O, 2014, CHILD DEV PERSPECT, V8, P65, DOI 10.1111/cdep.12064
   Picci G, 2016, PSYCHOL SCI, V27, P1461, DOI 10.1177/0956797616663142
   Pons F, 2015, PSYCHOL SCI, V26, P490, DOI 10.1177/0956797614568320
   Qian MK, 2019, CHILD DEV, V90, pE290, DOI 10.1111/cdev.12971
   Quinn PC, 2020, ADV CHILD DEV BEHAV, V58, P35, DOI 10.1016/bs.acdb.2020.01.002
   Quinn PC, 2020, DEV PSYCHOL, V56, P15, DOI 10.1037/dev0000858
   Quinn PC, 2019, ANNU REV PSYCHOL, V70, P165, DOI 10.1146/annurev-psych-010418-102753
   Quinn PC, 2018, CHILD DEV PERSPECT, V12, P204, DOI 10.1111/cdep.12286
   Quinn PC, 2016, DEVELOPMENTAL SCI, V19, P362, DOI 10.1111/desc.12301
   Rennels JL, 2017, DEV PSYCHOL, V53, P1437, DOI 10.1037/dev0000335
   Rennels JL, 2008, INFANT BEHAV DEV, V31, P665, DOI 10.1016/j.infbeh.2008.04.009
   Roder B, 2013, P NATL ACAD SCI USA, V110, P16760, DOI 10.1073/pnas.1309963110
   Sangrigoli S, 2005, PSYCHOL SCI, V16, P440
   Scott LS, 2007, CURR DIR PSYCHOL SCI, V16, P197, DOI 10.1111/j.1467-8721.2007.00503.x
   Singh L, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01563
   Smith LB, 2018, TRENDS COGN SCI, V22, P325, DOI 10.1016/j.tics.2018.02.004
   Sourav S, 2019, PSYCHOL SCI, V30, P1473, DOI 10.1177/0956797619866625
   Sugden NA, 2019, VISION RES, V157, P230, DOI 10.1016/j.visres.2018.09.005
   Sugden NA, 2017, PSYCHOL BULL, V143, P1201, DOI 10.1037/bul0000116
   Sugden NA, 2014, DEV PSYCHOBIOL, V56, P249, DOI 10.1002/dev.21183
   Sugita Y, 2008, P NATL ACAD SCI USA, V105, P394, DOI 10.1073/pnas.0706079105
   Tham DSY, 2019, DEV PSYCHOBIOL, V61, P107, DOI 10.1002/dev.21783
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   Xiao NQG, 2018, J EXP CHILD PSYCHOL, V176, P113, DOI 10.1016/j.jecp.2018.06.007
   Zhou X., 2019, VIS COGN, V27, P687, DOI DOI 10.1080/13506285.2019.1638478
NR 57
TC 2
Z9 2
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2352-1546
EI 2352-1554
J9 CURR OPIN BEHAV SCI
JI Curr. Opin. Behav. Sci.
PD DEC
PY 2020
VL 36
BP 7
EP 12
DI 10.1016/j.cobeha.2020.05.005
PG 6
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA QB1RF
UT WOS:000613919800003
DA 2021-02-24
ER

PT J
AU Heggdal, POL
   Larsen, KS
   Brannstrom, J
   Aarstad, HJ
   Specht, K
AF Heggdal, Peder O. Laugen
   Larsen, Kristina S.
   Brannstrom, Jonas
   Aarstad, Hans Jorgen
   Specht, Karsten
TI Reduced grey- and white matter volumes due to unilateral hearing loss
   following treatment for vestibular schwannoma
SO HELIYON
LA English
DT Article
DE Hearing loss; Voxel-based morphometry; Single-sided deafness; Neurology;
   Nervous system; Eye-Ear-Nose-Throat; Medical imaging; Radiology
ID FUNCTIONAL CONNECTIVITY; AUDITORY-CORTEX; SPEECH; PERCEPTION; LANGUAGE;
   DEAFNESS; CLASSIFICATION; RADIOSURGERY; ORGANIZATION; CEREBELLUM
AB Objective: Previous studies of the consequences of unilateral hearing loss (UHL) on the functional-structural organization of the brain has included subjects with various degrees of UHL. We suggest that the consequences of a total loss of hearing in one ear might differ from those seen in subjects with residual hearing in the affected ear. Thus, the main aim of the present study was to compare the structural properties of auditory and non-auditory brain regions in persons with complete UHL to those of normal hearing controls. We hypothesize that the consequences of complete UHL following treatment for vestibular schwannoma will differ between ipsiand contralateral structures, as well as between rightand left side deafness.
   Design:A 3T Siemens Prisma MR-scanner was used. Anatomical images were acquired using a high-resolution T1weighted sequence. Greyand white matter volumes were assessed using voxel-based morphometry.
   Study sample: Twenty-two patients with leftor right-side unilateral hearing loss. Fifty normal hearing controls.
   Results: Reductions in greyand white matter volumes were seen in cortical and sub-cortical regions, mainly in the right hemisphere including the auditory cortex, lingual gyrus, cuneus, middle temporal gyrus, occipital fusiform gyrus, middle cingulate gyrus and the superior temporal gyrus. Patients displayed reduced greyand white matter volumes in cerebellar exterior structures ipsilateral to the tumor side.
   Conclusion: When compared to controls, right side hearing loss yields more widespread reduction of grey matter volume than left side hearing loss. The findings of reduced greyand white matter volumes in auditory and nonauditory brain regions could be related to problems with speech perception in adverse listening conditions, increased listening effort and reduced quality of life reported by persons with unilateral hearing loss despite normal hearing in the unaffected ear.
C1 [Heggdal, Peder O. Laugen; Aarstad, Hans Jorgen] Univ Bergen, Fac Med, Dept Clin Med, Jonas Lies Vei 87, N-5021 Bergen, Norway.
   [Heggdal, Peder O. Laugen; Larsen, Kristina S.; Aarstad, Hans Jorgen] Haukeland Hosp, Dept Otolaryngol Head & Neck Surg, PB 1400, N-5021 Bergen, Norway.
   [Specht, Karsten] Univ Bergen, Dept Biol & Med Psychol, PB 7807, N-5020 Bergen, Norway.
   [Brannstrom, Jonas] Lund Univ, Sect Logoped Phoniatr & Audiol, Dept Clin Sci, Box 117, S-22100 Lund, Sweden.
   [Specht, Karsten] UiT Arctic Univ Norway, Dept Educ, Tromso, Norway.
   [Specht, Karsten] Haukeland Hosp, Mohn Med Imaging & Visualizat Ctr, Bergen, Norway.
RP Heggdal, POL (corresponding author), Univ Bergen, Fac Med, Dept Clin Med, Jonas Lies Vei 87, N-5021 Bergen, Norway.; Heggdal, POL (corresponding author), Haukeland Hosp, Dept Otolaryngol Head & Neck Surg, PB 1400, N-5021 Bergen, Norway.
EM pederheggdal@gmail.com
RI Specht, Karsten/C-3762-2009
OI Specht, Karsten/0000-0002-9946-3704
CR Ahsan SF, 2017, OTOL NEUROTOL, V38, P1505, DOI 10.1097/MAO.0000000000001560
   Amaral L, 2016, EUR J NEUROSCI, V44, P2334, DOI 10.1111/ejn.13340
   ANNETT M, 1970, BRIT J PSYCHOL, V61, P303, DOI 10.1111/j.2044-8295.1970.tb01248.x
   Ashburner J, 2000, NEUROIMAGE, V11, P805, DOI 10.1006/nimg.2000.0582
   Bartlett EL, 2013, BRAIN LANG, V126, P29, DOI 10.1016/j.bandl.2013.03.003
   Burton H, 2013, OTOLARYNG HEAD NECK, V149, P492, DOI 10.1177/0194599813495179
   Burton H, 2012, BRAIN RES, V1454, P33, DOI 10.1016/j.brainres.2012.02.066
   Cabeza R, 2000, J COGNITIVE NEUROSCI, V12, P1, DOI 10.1162/08989290051137585
   Chang JL, 2016, LARYNGOSCOPE, V126, P2785, DOI 10.1002/lary.25961
   Chen YC, 2016, FRONT AGING NEUROSCI, V8, DOI [10.3389/tnagi.2015.00174, 10.3389/fnagi.2016.00174]
   De Smet HJ, 2013, BRAIN LANG, V127, P334, DOI 10.1016/j.bandl.2012.11.001
   Durisala N, 2017, CLIN OTOLARYNGOL, V42, P748, DOI 10.1111/coa.12671
   Eckert MA, 2012, JARO-J ASSOC RES OTO, V13, P703, DOI 10.1007/s10162-012-0332-5
   Eggermont JJ, 2017, HEARING RES, V343, P176, DOI 10.1016/j.heares.2016.05.008
   Falchier A, 2002, J NEUROSCI, V22, P5749
   Gatehouse S, 2004, INT J AUDIOL, V43, P85, DOI 10.1080/14992020400050014
   Good CD, 2001, NEUROIMAGE, V14, P21, DOI 10.1006/nimg.2001.0786
   Halliday J, 2018, EXPERT REV NEUROTHER, V18, P29, DOI 10.1080/14737175.2018.1399795
   Hanss J, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-23
   Heggdal POL, 2016, HEARING RES, V332, P73, DOI 10.1016/j.heares.2015.11.015
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2008, BRAIN LANG, V107, P179, DOI 10.1016/j.bandl.2008.09.006
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hinkley LB, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3389/fnhum2015.00568, 10.3389/fnhum.2015.00568]
   Hribar M, 2014, HEARING RES, V318, P1, DOI 10.1016/j.heares.2014.09.008
   Hufner K, 2009, ANN NY ACAD SCI, V1164, P383, DOI 10.1111/j.1749-6632.2008.03719.x
   Langers DRM, 2011, BRAIN CONNECT, V1, P233, DOI 10.1089/brain.2011.0023
   Lepore N, 2010, HUM BRAIN MAPP, V31, P970, DOI 10.1002/hbm.20910
   Li ZL, 2015, INT J CLIN EXP MED, V8, P569
   Macaluso E, 2000, SCIENCE, V289, P1206, DOI 10.1126/science.289.5482.1206
   Mormina E, 2017, WORLD J RADIOL, V9, P371, DOI 10.4329/wjr.v9.i10.371
   Myrseth E, 2007, ACTA NEUROCHIR, V149, P647, DOI 10.1007/s00701-007-1179-0
   Myrseth E, 2005, NEUROSURGERY, V56, P927, DOI 10.1227/01.NEU.0000158315.64079.0A
   Myrseth E, 2006, NEUROSURGERY, V59, P67, DOI 10.1227/01.NEU.0000219838.80931.6B
   Myrseth E, 2009, NEUROSURGERY, V64, P654, DOI 10.1227/01.NEU.0000340684.60443.55
   Olulade OA, 2014, J NEUROSCI, V34, P5613, DOI 10.1523/JNEUROSCI.3700-13.2014
   Peelle JE, 2016, TRENDS NEUROSCI, V39, P486, DOI 10.1016/j.tins.2016.05.001
   Prasad SC, 2018, NEUROSURGERY, V83, P858, DOI 10.1093/neuros/nyx568
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Rosahl S., 2017, GMS CURR TOP OTORHIN, V16
   Sequeira SDS, 2008, SCAND J PSYCHOL, V49, P305, DOI 10.1111/j.1467-9450.2008.00664.x
   Shibata DK, 2007, AM J NEURORADIOL, V28, P243
   Specht K, 2003, NEUROIMAGE, V20, P1944, DOI 10.1016/j.neuroimage.2003.07.034
   Tibbetts K, 2011, OTOLARYNG HEAD NECK, V144, P602, DOI 10.1177/0194599810394954
   Vannson N, 2017, NEUROPSYCHOLOGIA, V102, P135, DOI 10.1016/j.neuropsychologia.2017.06.013
   Wang XC, 2016, SCI REP-UK, V6, DOI 10.1038/srep25811
   Wang XC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096126
   Yomo S, 2012, J NEUROSURG, V117, P877, DOI 10.3171/2012.7.JNS10672
NR 48
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 2405-8440
J9 HELIYON
JI Heliyon
PD DEC
PY 2020
VL 6
IS 12
AR e05658
DI 10.1016/j.heliyon.2020.e05658
PG 6
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA PQ8PF
UT WOS:000606804700028
PM 33364477
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Swaminathan, S
   Schellenberg, EG
AF Swaminathan, Swathi
   Schellenberg, E. Glenn
TI Musical Ability, Music Training, and Language Ability in Childhood
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION
LA English
DT Article
DE music; rhythm; language; speech; grammar
ID DELIBERATE PRACTICE; SPEECH; RHYTHM; DISCRIMINATION; PERCEPTION;
   CHILDREN; CONTRASTS; MEMORY; SKILLS
AB We tested theories of links between musical expertise and language ability in a sample of 6- to 9-year-old children. Language ability was measured with tests of speech perception and grammar. Musical expertise was measured with a test of musical ability that had 3 subtests (melody discrimination, rhythm discrimination, and long-term memory for music) and as duration of music training. Covariates included measures of demographics, general cognitive ability (IQ, working memory), and personality (openness-to-experience). Music training was associated positively with performance on the grammar test, musical ability, IQ, openness, and age. Musical ability predicted performance on the tests of speech perception and grammar, as well as IQ, working memory, openness, and age. Regression analyses-with other variables held constant-revealed that language abilities had significant partial associations with musical ability and IQ but not with music training. Rhythm discrimination was a better predictor of language skills compared with melody discrimination, but memory for music was equally good. Bayesian analyses confirmed the results from the standard analyses. The implications of the findings are threefold: (a) musical ability predicts language ability, and the association is independent of IQ and other confounding variables; (b) links between music and language appear to arise primarily from preexisting factors and not from formal training in music; and (c) evidence for a special link between rhythm and language may emerge only when rhythm discrimination is compared with melody discrimination.
C1 [Swaminathan, Swathi] Univ Toronto, Dept Psychol, Toronto, ON, Canada.
   [Schellenberg, E. Glenn] Univ Toronto Mississauga, Dept Psychol, Mississauga, ON L5L 1C6, Canada.
RP Schellenberg, EG (corresponding author), Univ Toronto Mississauga, Dept Psychol, Mississauga, ON L5L 1C6, Canada.
EM g.schellenberg@utoronto.ca
OI Swaminathan, Swathi/0000-0003-0940-6448; Schellenberg,
   Glenn/0000-0003-3681-6020
FU Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR
FX Funding provided by the Natural Sciences and Engineering Research
   Council of Canada. Laura Cirelli and Haley Kragness provided helpful
   comments on a draft.
CR BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Bhatara A, 2015, J EXP PSYCHOL HUMAN, V41, P277, DOI 10.1037/a0038736
   Bishop D. V. M., 2003, TEST RECEPTION GRAMM
   Carroll J. B., 1993, HUMAN COGNITIVE ABIL, DOI [10.1017/CBO9780511571312, DOI 10.1017/CBO9780511571312]
   Cohen J., 1988, STAT POWER ANAL BEHA
   Corrigall KA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00222
   Corriveau K, 2007, J SPEECH LANG HEAR R, V50, P647, DOI 10.1044/1092-4388(2007/046)
   Corriveau KH, 2009, CORTEX, V45, P119, DOI 10.1016/j.cortex.2007.09.008
   Darlington R. B., 1990, REGRESSION LINEAR MO
   Dege F, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00124
   Doidge N., 2007, BRAIN CHANGES ITSELF
   ERICSSON KA, 1993, PSYCHOL REV, V100, P363, DOI 10.1037/0033-295X.100.3.363
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Fernald A, 1996, SIGNAL TO SYNTAX: BOOTSTRAPPING FROM SPEECH TO GRAMMAR IN EARLY ACQUISITION, P365
   Flaugnacco E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138715
   Francois C, 2013, CEREB CORTEX, V23, P2038, DOI 10.1093/cercor/bhs180
   Gordon RL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01777
   Gordon RL, 2015, DEVELOPMENTAL SCI, V18, P635, DOI 10.1111/desc.12230
   Gordon RL, 2015, ANN NY ACAD SCI, V1337, P16, DOI 10.1111/nyas.12683
   Goswami U., 2011, LANGUAGE MUSIC COGNI, P292, DOI 10.1093/acprof:oso/9780199553426.003.0030
   Hambrick DZ, 2015, PSYCHON B REV, V22, P112, DOI 10.3758/s13423-014-0671-9
   Hansen M, 2013, PSYCHOL MUSIC, V41, P779, DOI 10.1177/0305735612452186
   Hausen M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00566
   Hidalgo C, 2019, J SPEECH LANG HEAR R, V62, P3234, DOI 10.1044/2019_JSLHR-S-18-0349
   Hidalgo C, 2017, HEARING RES, V351, P11, DOI 10.1016/j.heares.2017.05.006
   JASP Team, 2019, JASP VERS 0 11 0 COM
   John O. P., 2008, HDB PERSONALITY THEO, P114, DOI [10.1016/S0191-8869(97)81000-8, DOI 10.1016/S0191-8869(97)81000-8]
   John O. P., 1991, THE BIG FIVE INVENTO, DOI DOI 10.1037/t07550-000
   Kraus N., 2018, OXFORD HDB AUDITORY
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Loui P, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01198
   Macnamara BN, 2014, PSYCHOL SCI, V25, P1608, DOI 10.1177/0956797614535810
   Moreno S, 2011, PSYCHOL SCI, V22, P1425, DOI 10.1177/0956797611416999
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Mosing MA, 2016, DEVELOPMENTAL SCI, V19, P504, DOI 10.1111/desc.12306
   Mosing MA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0113874
   Mosing MA, 2014, PSYCHOL SCI, V25, P1795, DOI 10.1177/0956797614541990
   Patel AD, 2007, TRENDS COGN SCI, V11, P369, DOI 10.1016/j.tics.2007.08.003
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Patscheke H, 2019, PSYCHOL MUSIC, V47, P376, DOI 10.1177/0305735618756763
   Patscheke H, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01647
   Peretz I, 2003, NAT NEUROSCI, V6, P688, DOI 10.1038/nn1083
   Peretz I, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00030
   Politimou N, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00948
   Port R, 2007, NEW IDEAS PSYCHOL, V25, P143, DOI 10.1016/j.newideapsych.2007.02.001
   Roncaglia-Denissen MP, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0056000
   Rothermich K, 2012, NEUROPSYCHOLOGIA, V50, P232, DOI 10.1016/j.neuropsychologia.2011.10.025
   Sala G, 2017, CURR DIR PSYCHOL SCI, V26, P515, DOI 10.1177/0963721417712760
   Schellenberg EG, 2006, J EDUC PSYCHOL, V98, P457, DOI 10.1037/0022-0663.98.2.457
   Schellenberg EG, 2020, PSYCHOL AESTHET CREA, V14, P475, DOI 10.1037/aca0000263
   Schellenberg EG, 2013, PSYCHOLOGY OF MUSIC, THIRD EDITION, P499, DOI 10.1016/B978-0-12-381460-9.00012-2
   Slater J, 2015, BEHAV BRAIN RES, V291, P244, DOI 10.1016/j.bbr.2015.05.026
   Swaminathan S., 2013, PSYCHOL STUD, V58, P164, DOI DOI 10.1007/S12646-013-0180-3
   Swaminathan S., 2018, OXFORD HDB MUSIC BRA, DOI [10.1093/oxfordhb/9780198804123.013.26, DOI 10.1093/OXFORDHB/9780198804123.013.26]
   Swaminathan S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27571-2
   Swaminathan S, 2018, J EXP PSYCHOL LEARN, V44, P992, DOI 10.1037/xlm0000493
   Swaminathan S, 2017, PSYCHON B REV, V24, P1929, DOI 10.3758/s13423-017-1244-5
   Tallal P, 2006, TRENDS NEUROSCI, V29, P382, DOI 10.1016/j.tins.2006.06.003
   Tierney A, 2013, PROG BRAIN RES, V207, P209, DOI 10.1016/B978-0-444-63327-9.00008-4
   Wechsler D, 1999, WASI WECHSLER ABBREV
NR 62
TC 2
Z9 2
U1 0
U2 3
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0278-7393
EI 1939-1285
J9 J EXP PSYCHOL LEARN
JI J. Exp. Psychol.-Learn. Mem. Cogn.
PD DEC
PY 2020
VL 46
IS 12
BP 2340
EP 2348
DI 10.1037/xlm0000798
PG 9
WC Psychology; Psychology, Experimental
SC Psychology
GA PS0IM
UT WOS:000607612300007
PM 31750723
DA 2021-02-24
ER

PT J
AU Wilhelm, LA
AF Wilhelm, Lindsey A.
TI Using Contextual and Visual Cues to Improve Sung Word Recognition in
   Hearing Aid Users
SO JOURNAL OF MUSIC THERAPY
LA English
DT Article
DE older adults; hearing loss; music therapy; lyrics; non-auditory cues
ID QUALITY-OF-LIFE; OLDER-ADULTS; MUSIC; IMPACT; POWER
AB Older adults commonly experience hearing loss that negatively affects the quality of life and creates barriers to effective therapeutic interactions as well as music listening. Music therapists have the potential to address some needs of older adults, but the effectiveness of music interventions is dependent on the perception of spoken and musical stimuli. Nonauditory information, such as contextual (e.g., keywords, picture related to song) and visual cues (e.g., clear view of singer's face), can improve speech perception. The purpose of this study was to examine the benefit of contextual and visual cues on sung word recognition in the presence of guitar accompaniment. The researcher tested 24 community-dwelling older adult hearing aid (HA) users recruited through a university HA clinic and laboratory under 3 study conditions: (a) auditory stimuli only, (b) auditory stimuli with contextual cues, and (c) auditory stimuli with visual cues. Both visual and contextual nonauditory cues benefited participants on sung word recognition. Participants' music background and training were predictive of success without nonauditory cues, and visual cues provided greater benefit than contextual cues. Based on the results of this study, it is recommended that music therapists increase the accessibility of music interventions reliant upon lyric recognition through the incorporation of clear visual and contextual cues.
C1 [Wilhelm, Lindsey A.] Colorado State Univ, Sch Mus Theatre & Dance, 1778 Campus Delivery, Ft Collins, CO 80523 USA.
RP Wilhelm, LA (corresponding author), Colorado State Univ, Sch Mus Theatre & Dance, 1778 Campus Delivery, Ft Collins, CO 80523 USA.
EM Lindsey.Wilhelm@colostate.edu
FU Graduate College at The University of Iowa
FX This research was supported in part through financial support from Dr.
   Richard and Mrs. Ellen Caplan in addition to a Graduate Student Research
   Grant from the Graduate College at The University of Iowa awarded in
   2015.
CR Alain C., 2006, HDB MODELS HUMAN AGI, P759, DOI DOI 10.1016/B978-012369391-4/50065-5
   American Music Therapy Association, 2018, 2018 AMTA MEMB SURV
   Beck DL, 2009, AUDIOLOGY TODAY, V21, P48
   Belgrave M, 2011, MUSIC THERAPY GERIAT
   Bergman A., 1990, AUDITORY SCENE ANAL
   Chasin M, 2014, HEARING RES, V308, P2, DOI 10.1016/j.heares.2013.07.003
   Chen DS, 2014, J AM GERIATR SOC, V62, P850, DOI 10.1111/jgs.12800
   Ciorba A, 2012, CLIN INTERV AGING, V7, P159, DOI 10.2147/CIA.S26059
   Clair A. A., 2008, THERAPEUTIC USES MUS
   Cohen GD, 2006, GERONTOLOGIST, V46, P726, DOI 10.1093/geront/46.6.726
   Condit-Schultz N, 2017, J VOICE, V31, DOI 10.1016/j.jvoice.2016.02.011
   Correia R., 2018, J GERIATRIC MED GERO, V4, P1, DOI [10.23937/2469-5858/1510048, DOI 10.23937/2469-5858/1510048]
   COX RM, 1987, EAR HEARING, V8, pS119, DOI 10.1097/00003446-198710001-00010
   COX RM, 1988, EAR HEARING, V9, P198, DOI 10.1097/00003446-198808000-00005
   COX RM, 1989, EAR HEARING, V10, P29, DOI 10.1097/00003446-198902000-00005
   Creech A, 2013, RES STUD MUSIC EDUC, V35, P87, DOI 10.1177/1321103X13478862
   Dalton DS, 2003, GERONTOLOGIST, V43, P661, DOI 10.1093/geront/43.5.661
   DiCarlo LA, 1951, J SPEECH HEAR DISORD, V16, P226, DOI 10.1044/jshd.1603.226
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fine PA, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00809
   Gfeller K, 2000, J Am Acad Audiol, V11, P390
   Gfeller K. E., 2018, MUSIC THERAPY INTRO, P217
   Ginsborg J., 2011, INT S PERF SCI EUR A, P111
   Heinrich A, 2015, J ACOUST SOC AM, V138, P2373, DOI 10.1121/1.4929901
   Jeffries K. J., 2003, BRAIN IMAGING, V14, DOI [10.1097/01.wnr.0000066198.94941.a4, DOI 10.1097/01.WNR.0000066198.94941.A4]
   Jesse A, 2010, PSYCHON B REV, V17, P323, DOI 10.3758/PBR.17.3.323
   Johnson R, 2014, EMPIR MUSICOL REV, V9, P2
   Kleinbaum D. G., 2008, APPL REGRESSION ANAL
   Krout RE, 2007, ART PSYCHOTHER, V34, P36, DOI 10.1016/j.aip.2006.08.005
   Laukka P., 2007, J HAPPINESS STUDIES, V8, DOI [10.1007/s10902-006-9024-3, DOI 10.1007/S10902-006-9024-3]
   Leek MR, 2008, J AM ACAD AUDIOL, V19, P519, DOI 10.3766/jaaa.19.6.7
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P582, DOI 10.1093/gerona/glr002
   Lindblom B., 2007, SPRINGER HDB ACOUSTI, P669, DOI [10.1007/978-0-387-30425-0_16, DOI 10.1007/978-0-387-30425-0_16]
   Lotfi Y, 2009, ARCH IRAN MED, V12, P365
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   National Institute on Deafness and Other Communication Disorders (NIDCD), 2014, AG REL HEAR LOSS
   Parbery-Clark A, 2009, J NEUROSCI, V29, P14100, DOI 10.1523/JNEUROSCI.3256-09.2009
   Picou EM, 2011, J SPEECH LANG HEAR R, V54, P1416, DOI 10.1044/1092-4388(2011/10-0154)
   Prickett C. A., 2000, EFFECTIVENESS MUSIC, P297
   Rowe J. W., 2016, PREPARING BETTER HLT, DOI [10.31478/201609n, DOI 10.31478/201609N]
   Rutledge K. L., 2009, THESIS
   Schumm W. R., 2013, COMPREHENSIVE PSYCHO, V2, P1, DOI 10.2466/03.CP.2.10
   Strong W. J., 2007, MUSIC SPEECH AUDIO
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Tye-Murray N., 2009, FDN AURAL REHABILITA
   Utley J, 1946, J SPEECH DISORD, V11, P109, DOI 10.1044/jshd.1102.109
   Weinstein B. E., 2012, GERIATRIC AUDIOLOGY
   Yinger OS, 2014, INT J MUSIC EDUC, V32, P203, DOI 10.1177/0255761413508064
NR 49
TC 0
Z9 0
U1 1
U2 1
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 0022-2917
EI 2053-7395
J9 J MUSIC THER
JI J. Music Ther.
PD WIN
PY 2020
VL 57
IS 4
BP 379
EP 405
DI 10.1093/jmt/thaa009
PG 27
WC Music; Rehabilitation
SC Music; Rehabilitation
GA PP6PH
UT WOS:000605981900002
PM 32574363
DA 2021-02-24
ER

PT J
AU Hirst, RJ
   Setti, A
   De Looze, C
   Akuffo, KO
   Peto, T
   Kenny, RA
   Newell, FN
AF Hirst, Rebecca J.
   Setti, Annalisa
   De Looze, Celine
   Akuffo, Kwadwo O.
   Peto, Tunde
   Kenny, Rose A.
   Newell, Fiona N.
TI The effect of eye disease, cataract surgery and hearing aid use on
   multisensory integration in ageing
SO CORTEX
LA English
DT Article
DE Sound-induced flash illusion; Multisensory; Ageing; Eye disease; Hearing
   aids
ID INDUCED FLASH ILLUSION; TEMPORAL BINDING WINDOW; MACULAR DEGENERATION;
   SPEECH-PERCEPTION; SUSCEPTIBILITY; PREVALENCE; RESOLUTION; SYNCHRONY;
   PEOPLE; SEE
AB Sensory impairment is common in ageing, as are approaches to treat it. However, the impact of age-related sensory impairment upon multisensory perception remains unexplored, despite the multisensory nature of our environment. Here, we used data from The Irish Longitudinal Study of Ageing (TILDA) to investigate whether common, age-related eye diseases (cataracts, glaucoma and Age-Related Macular Degeneration, ARMD) and clinical intervention to improve sensory function (cataract removal and hearing aids) influence multisensory integration in older adults. Integration was measured using the Sound Induced Flash Illusion (SIFI), and the extent to which identifying two flashes was improved by accompanying auditory information ("visual gain"). Visual gain was not influenced by eye disease or treatment. For the SIFI, participants self-reporting cataracts, ARMD or glaucoma were as susceptible as healthy controls, even when controlling for age, sex, cognition, self-reported vision/hearing and visual acuity. In a second analysis using retinal photographs, glaucoma and ARMD (hard drusen) did not influence susceptibility relative to controls. However, participants with soft drusen ARMD were more susceptible to the illusion at long Stimulus-Onset Asynchronies (SOAs) compared with controls. Following this, we identified groups reporting bilateral cataract removal or hearing aid acquisition 4 years and <2 years prior to assessment, enabling comparison of longer- and shorter- term effects of interventions. Cataract removal groups did not differ from controls. Longer-term hearing aid users were less susceptible to the SIFI at short SOAs compared with controls. Our findings suggest that multisensory integration in ageing might be specifically influenced by ARMD (soft drusen) and hearing aid use. (C) 2020 The Authors. Published by Elsevier Ltd.
C1 [Hirst, Rebecca J.; Newell, Fiona N.] Trinity Coll Dublin, Sch Psychol, Dublin, Ireland.
   [Hirst, Rebecca J.; Newell, Fiona N.] Trinity Coll Dublin, Inst Neurosci, Dublin, Ireland.
   [Hirst, Rebecca J.; Setti, Annalisa; De Looze, Celine; Kenny, Rose A.] Trinity Coll Dublin, Irish Longitudinal Study Ageing, Dublin, Ireland.
   [Setti, Annalisa] Univ Coll Cork, Sch Appl Psychol, Cork, Ireland.
   [Akuffo, Kwadwo O.] Kwame Nkrumah Univ Sci & Technol, Coll Sci, Dept Optometry & Visual Sci, Kumasi, Ghana.
   [Peto, Tunde] Queens Univ Belfast, Dept Ophthalmol, Belfast, Antrim, North Ireland.
   [Kenny, Rose A.] St James Hosp, Mercer Inst Successful Ageing, Dublin, Ireland.
RP Hirst, RJ (corresponding author), Trinity Coll Dublin, Inst Neurosci, Dublin, Ireland.
EM hirstr@tcd.ie
RI Akuffo, Kwadwo Owusu/J-2036-2019; Akuffo, Kwadwo/A-2141-2013; Peto,
   Tunde/M-2081-2013
OI Kenny, Rose Anne/0000-0002-9336-8124; Akuffo,
   Kwadwo/0000-0001-6683-249X; Peto, Tunde/0000-0001-6265-0381
FU Health Research Board (HRB), Ireland [ILP-PHR-2017-014]
FX This work was supported by the Health Research Board (HRB), Ireland;
   Grant reference ILP-PHR-2017-014. The authors would like to thank Dr.
   John Newell (School of Mathematics, Statistics and Applied Mathematics,
   National University of Ireland Galway, Ireland) for his feedback on the
   statistical analysis performed within previous versions of this
   manuscript.
CR Abdelsalam A, 1999, SURV OPHTHALMOL, V44, P1, DOI 10.1016/S0039-6257(99)00072-7
   Akuffo KO, 2015, BRIT J OPHTHALMOL, V99, P1037, DOI 10.1136/bjophthalmol-2014-305768
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beauchamp MS, 2010, FRONT SYST NEUROSCI, V4, DOI 10.3389/fnsys.2010.00025
   BIRD AEC, 1995, SURV OPHTHALMOL, V39, P367, DOI 10.1016/S0039-6257(05)80092-X
   Chan JSS, 2018, MULTISENS RES, V31, P175, DOI 10.1163/22134808-00002605
   Chan JS, 2015, CURR ALZHEIMER RES, V12, P61, DOI 10.2174/1567205012666141218124744
   Chen YC, 2017, CURR BIOL, V27, P583, DOI 10.1016/j.cub.2017.01.009
   Chen YC, 2011, J EXP PSYCHOL HUMAN, V37, P1784, DOI 10.1037/a0025638
   Cheong AMY, 2007, VISION RES, V47, P2943, DOI 10.1016/j.visres.2007.07.010
   Conrey B, 2006, J ACOUST SOC AM, V119, P4065, DOI 10.1121/1.2195091
   Core Team R, 2018, R LANG ENV STAT COMP
   Dawes P, 2017, EAR HEARING, V38, P174, DOI 10.1097/AUD.0000000000000366
   Dawes P, 2014, INT J AUDIOL, V53, P861, DOI 10.3109/14992027.2014.938782
   de Boer-Schellekens L, 2014, EXP BRAIN RES, V232, P253, DOI 10.1007/s00221-013-3736-5
   de Dieuleveult AL, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00080
   de Heering A, 2016, CURR BIOL, V26, P3101, DOI 10.1016/j.cub.2016.10.014
   DIXON NF, 1980, PERCEPTION, V9, P719, DOI 10.1068/p090719
   Donoghue OA, 2018, INT J EPIDEMIOL, V47, P1398, DOI 10.1093/ije/dyy163
   Donoghue OA, 2014, GERIATR GERONTOL INT, V14, P827, DOI 10.1111/ggi.12174
   Feng YM, 2010, EAR HEARING, V31, P115, DOI 10.1097/AUD.0b013e3181bb69be
   Fonseca Gabriela Cavagnoli Rodrigues da, 2015, Rev. CEFAC, V17, P809, DOI 10.1590/1982-0216201513114
   Foreman J, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09421-9
   FREIHERR J, 2013, FRONT HUM NEUROSCI, V7, DOI DOI 10.3389/J.25798
   Frtusova JB, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00490
   Garcia SE, 2017, J EXP PSYCHOL HUMAN, V43, P729, DOI 10.1037/xhp0000344
   Gieseler A., 2020, LINKING AUDIOVISUAL, DOI [10.31219/osf.io/46caf., DOI 10.31219/OSF.IO/46CAF]
   Gieseler A, 2018, EXP BRAIN RES, V236, P1161, DOI 10.1007/s00221-018-5206-6
   Gondan M, 2005, PERCEPT PSYCHOPHYS, V67, P713, DOI 10.3758/BF03193527
   Guerreiro MJS, 2016, CURR BIOL, V26, P3096, DOI 10.1016/j.cub.2016.08.069
   Harrison NR, 2010, J VISION, V10, DOI 10.1167/10.14.16
   Hernandez B, 2019, PSYCHOL AGING, V34, P978, DOI 10.1037/pag0000396
   Hillock AR, 2011, NEUROPSYCHOLOGIA, V49, P461, DOI 10.1016/j.neuropsychologia.2010.11.041
   Hirst RJ, 2020, NEUROSCI BIOBEHAV R, V118, P759, DOI 10.1016/j.neubiorev.2020.09.006
   Hirst RJ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-55901-5
   Holmes NP, 2009, BRAIN TOPOGR, V21, P168, DOI 10.1007/s10548-009-0097-2
   Kang S. J., 2007, AGE RELATED MACULAR, V223, P1, DOI [10.3109/9781420019865-2, DOI 10.3109/9781420019865-2]
   Keil J, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00298
   Kenny Gibson William, 2014, BMC Res Notes, V7, P361, DOI 10.1186/1756-0500-7-361
   LACHENMAYR BJ, 1994, INVEST OPHTH VIS SCI, V35, P2741
   Laurienti PJ, 2006, NEUROBIOL AGING, V27, P1155, DOI 10.1016/j.neurobiolaging.2005.05.024
   Lessa A. H., 2016, AUDIOLOGY COMMUNICAT, V21, P1, DOI [10.1590/10.1590/2317-6431-2016-1686, DOI 10.1590/10.1590/2317-6431-2016-1686]
   Lin HT, 2018, EBIOMEDICINE, V30, P52, DOI 10.1016/j.ebiom.2018.03.002
   Lou AR, 2013, ACTA OPHTHALMOL, V91, P58, DOI 10.1111/j.1755-3768.2011.02304.x
   Lovelace CT, 2003, COGNITIVE BRAIN RES, V17, P447, DOI 10.1016/S0926-6410(03)00160-5
   MADDEN JP, 1992, J SPEECH HEAR RES, V35, P436, DOI 10.1044/jshr.3502.436
   McGovern D., 2014, FRONT AGING NEUROSCI, V6, P1
   MEREDITH MA, 1987, J NEUROSCI, V7, P3215
   MEREDITH MA, 1983, SCIENCE, V221, P389, DOI 10.1126/science.6867718
   MILLER J, 1982, COGNITIVE PSYCHOL, V14, P247, DOI 10.1016/0010-0285(82)90010-X
   Moro SS, 2018, EXP BRAIN RES, V236, P1825, DOI 10.1007/s00221-018-5263-x
   Narinesingh C, 2017, INVEST OPHTH VIS SCI, V58, P1442, DOI 10.1167/iovs.16-21258
   Putzar L, 2007, NAT NEUROSCI, V10, P1243, DOI 10.1038/nn1978
   Rosen E, 2009, EYE, V23, P1120, DOI 10.1038/eye.2008.203
   Rudolf M, 2008, INVEST OPHTH VIS SCI, V49, P1200, DOI 10.1167/iovs.07-1466
   Setti A, 2011, EXP BRAIN RES, V209, P375, DOI 10.1007/s00221-011-2560-z
   Shams L, 2005, NEUROREPORT, V16, P1923, DOI 10.1097/01.wnr.0000187634.68504.bb
   Shams L, 2000, NATURE, V408, P788, DOI 10.1038/35048669
   Shams L, 2002, COGNITIVE BRAIN RES, V14, P147, DOI 10.1016/S0926-6410(02)00069-1
   Stanford TR, 2007, NEUROREPORT, V18, P787, DOI 10.1097/WNR.0b013e3280c1e315
   Stapleton J, 2014, EXP BRAIN RES, V232, P423, DOI 10.1007/s00221-013-3750-7
   Stein BE, 2008, NAT REV NEUROSCI, V9, P406, DOI 10.1038/nrn2377
   Stevenson RA, 2017, EAR HEARING, V38, P521, DOI 10.1097/AUD.0000000000000435
   Stevenson RA, 2012, J EXP PSYCHOL HUMAN, V38, P1517, DOI 10.1037/a0027339
   Stevenson RA, 2010, NEUROIMAGE, V49, P3308, DOI 10.1016/j.neuroimage.2009.12.001
   Stiles N. R. B., 2019, AUDITORY VISUA UNPUB, DOI [10.1101/519850, DOI 10.1101/519850]
   van Atteveldt NM, 2007, CEREB CORTEX, V17, P962, DOI 10.1093/cercor/bhl007
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   Venezia JH, 2016, ATTEN PERCEPT PSYCHO, V78, P583, DOI 10.3758/s13414-015-1026-y
   Vottonen P, 2017, CLIN OPHTHALMOL, V11, P1245, DOI 10.2147/OPTH.S132583
   Vroomen J, 2010, ATTEN PERCEPT PSYCHO, V72, P871, DOI 10.3758/APP.72.4.871
   Whelan BJ, 2013, J AM GERIATR SOC, V61, pS265, DOI 10.1111/jgs.12199
   Yousefi S, 2018, INVEST OPHTH VIS SCI, V59, P5717, DOI 10.1167/iovs.18-25140
NR 73
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER MASSON, CORP OFF
PI PARIS
PA 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE
SN 0010-9452
EI 1973-8102
J9 CORTEX
JI Cortex
PD DEC
PY 2020
VL 133
BP 161
EP 176
DI 10.1016/j.cortex.2020.08.030
PG 16
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA PN7NX
UT WOS:000604662800010
PM 33126009
OA Other Gold
DA 2021-02-24
ER

PT J
AU Magnotti, JF
   Dzeda, KB
   Wegner-Clemens, K
   Rennig, J
   Beauchamp, MS
AF Magnotti, John F.
   Dzeda, Kristen B.
   Wegner-Clemens, Kira
   Rennig, Johannes
   Beauchamp, Michael S.
TI Weak observer-level correlation and strong stimulus-level correlation
   between the McGurk effect and audiovisual speech-in-noise: A causal
   inference explanation
SO CORTEX
LA English
DT Article
DE Audiovisual; Multisensory integration; Causal inference; Bayesian
   inference; Illusions
ID NEUROCOMPUTATIONAL MODEL; INDIVIDUAL-DIFFERENCES; CUE INTEGRATION;
   HEARING-LIPS; PSYCHOPHYSICS; SUSCEPTIBILITY; RECOGNITION; PERCEPTION;
   PREDICTION; SENTENCES
AB The McGurk effect is a widely used measure of multisensory integration during speech perception. Two observations have raised questions about the validity of the effect as a tool for understanding speech perception. First, there is high variability in perception of the McGurk effect across different stimuli and observers. Second, across observers there is low correlation between McGurk susceptibility and recognition of visual speech paired with auditory speech-in-noise, another common measure of multisensory integration. Using the framework of the causal inference of multisensory speech (CIMS) model, we explored the relationship between the McGurk effect, syllable perception, and sentence perception in seven experiments with a total of 296 different participants. Perceptual reports revealed a relationship between the efficacy of different McGurk stimuli created from the same talker and perception of the auditory component of the McGurk stimuli presented in isolation, both with and without added noise. The CIMS model explained this strong stimulus-level correlation using the principles of noisy sensory encoding followed by optimal cue combination within a common representational space across speech types. Because the McGurk effect (but not speech-in-noise) requires the resolution of conflicting cues between modalities, there is an additional source of individual variability that can explain the weak observerelevel correlation between McGurk and noisy speech. Power calculations show that detecting this weak correlation requires studies with many more participants than those conducted to-date. Perception of the McGurk effect and other types of speech can be explained by a common theoretical framework that includes causal inference, suggesting that the McGurk effect is a valid and useful experimental tool. (C) 2020 The Author(s). Published by Elsevier Ltd.
C1 [Magnotti, John F.; Dzeda, Kristen B.; Wegner-Clemens, Kira; Rennig, Johannes; Beauchamp, Michael S.] Baylor Coll Med, Dept Neurosurg, Houston, TX 77030 USA.
RP Beauchamp, MS (corresponding author), Baylor Coll Med, Dept Neurosurg, Houston, TX 77030 USA.
EM michael.beauchamp@pennmedicine.upenn.edu
OI Beauchamp, Michael/0000-0002-7599-9934
CR Abramson AS, 2017, J PHONETICS, V63, P75, DOI 10.1016/j.wocn.2017.05.002
   Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029
   Aller M, 2019, PLOS BIOL, V17, DOI 10.1371/journal.pbio.3000210
   Alsius A, 2018, MULTISENS RES, V31, P111, DOI 10.1163/22134808-00002565
   Arnold DH, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37888-7
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Baum SH, 2015, PROG NEUROBIOL, V134, P140, DOI 10.1016/j.pneurobio.2015.09.007
   Beauchamp MS, 2018, MULTISENS RES, V31, P1, DOI 10.1163/22134808-00002598
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Brown VA, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0207160
   Buhrmester MD, 2018, PERSPECT PSYCHOL SCI, V13, P149, DOI 10.1177/1745691617706516
   Cope TE, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01958-7
   Cuppini C, 2017, EUR J NEUROSCI, V46, P2481, DOI 10.1111/ejn.13725
   Cuppini C, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00518
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014
   Deneve S, 2001, NAT NEUROSCI, V4, P826, DOI 10.1038/90541
   Erickson LC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00534
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   French RL, 2020, CURR OPIN PHYSIOL, V16, P8, DOI 10.1016/j.cophys.2020.04.004
   Gau R, 2016, NEUROIMAGE, V124, P876, DOI 10.1016/j.neuroimage.2015.09.045
   Grant KW, 1998, J ACOUST SOC AM, V104, P2438, DOI 10.1121/1.423751
   Grant KW, 2000, J ACOUST SOC AM, V107, P1000, DOI 10.1121/1.428280
   Gurler D, 2015, ATTEN PERCEPT PSYCHO, V77, P1333, DOI 10.3758/s13414-014-0821-1
   HOLMBERG EB, 1994, J SPEECH HEAR RES, V37, P484, DOI 10.1044/jshr.3703.484
   Jiang JT, 2011, J EXP PSYCHOL HUMAN, V37, P1193, DOI 10.1037/a0023100
   Kording KP, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000943
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Ma WJ, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004638
   Magnotti JF, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-36772-8
   Magnotti JF, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202908
   Magnotti JF, 2018, MULTISENS RES, V31, P19, DOI 10.1163/22134808-00002586
   Magnotti JF, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005229
   Magnotti JF, 2015, EXP BRAIN RES, V233, P2581, DOI 10.1007/s00221-015-4324-7
   Magnotti JF, 2015, PSYCHON B REV, V22, P701, DOI 10.3758/s13423-014-0722-2
   Magnotti JF, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00798
   Massaro D. W., 1998, PERCEIVING TALKING F
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Fernandez LM, 2017, HUM BRAIN MAPP, V38, P5691, DOI 10.1002/hbm.23758
   Noppeney U, 2018, ANN NY ACAD SCI, V1423, P102, DOI 10.1111/nyas.13615
   Odegaard B, 2016, PSYCHOL SCI, V27, P583, DOI 10.1177/0956797616628860
   Olasagasti I, 2015, CORTEX, V68, P61, DOI 10.1016/j.cortex.2015.04.008
   Peelle JE, 2015, CORTEX, V68, P169, DOI 10.1016/j.cortex.2015.03.006
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   R Core Team, 2020, R LANG ENV STAT COMP
   Rennig J, 2020, PSYCHON B REV, V27, P70, DOI 10.3758/s13423-019-01665-y
   Rohe T, 2015, PLOS BIOL, V13, DOI 10.1371/journal.pbio.1002073
   Rosenblum L., 2019, OXFORD RES ENCY
   Sanchez-Garcia C, 2018, MULTISENS RES, V31, P57, DOI 10.1163/22134808-00002560
   Shams L, 2010, TRENDS COGN SCI, V14, P425, DOI 10.1016/j.tics.2010.07.001
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   Soto-Faraco S, 2009, J EXP PSYCHOL HUMAN, V35, P580, DOI 10.1037/a0013483
   Stacey JE, 2020, ATTEN PERCEPT PSYCHO, V82, P3544, DOI 10.3758/s13414-020-02042-x
   Stevenson RA, 2012, J EXP PSYCHOL HUMAN, V38, P1517, DOI 10.1037/a0027339
   Strand JF, 2018, J SPEECH LANG HEAR R, V61, P1463, DOI 10.1044/2018_JSLHR-H-17-0257
   Stropahl M, 2017, PSYCHON B REV, V24, P863, DOI 10.3758/s13423-016-1148-9
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Tuennerhoff J, 2016, NEUROIMAGE, V124, P641, DOI 10.1016/j.neuroimage.2015.09.004
   Van Engen KJ, 2017, ATTEN PERCEPT PSYCHO, V79, P396, DOI 10.3758/s13414-016-1238-9
   Vroomen J, 2010, PHYS LIFE REV, V7, P289, DOI 10.1016/j.plrev.2010.06.010
   Whalen DH, 2018, J PHONETICS, V68, P1, DOI 10.1016/j.wocn.2018.01.003
NR 61
TC 0
Z9 0
U1 3
U2 3
PU ELSEVIER MASSON, CORP OFF
PI PARIS
PA 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE
SN 0010-9452
EI 1973-8102
J9 CORTEX
JI Cortex
PD DEC
PY 2020
VL 133
BP 371
EP 383
DI 10.1016/j.cortex.2020.10.002
PG 13
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA PN7NX
UT WOS:000604662800024
PM 33221701
OA Other Gold
DA 2021-02-24
ER

PT J
AU Brosseau-Lapre, F
   Schumaker, J
AF Brosseau-Lapre, Francoise
   Schumaker, Jennifer
TI Perception of Correctly and Incorrectly Produced Words in Children With
   and Without Phonological Speech Sound Disorders
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID ARTICULATION NORMS PROJECT; LANGUAGE DISORDERS; CHILDHOOD APRAXIA;
   CONSONANTS; AWARENESS; SKILLS; REPRESENTATIONS; DISCRIMINATION;
   PREVALENCE; DEFICITS
AB Purpose: The purpose of this study was to examine the perception of correctly and incorrectly produced words in children with and without phonological speech sound disorder (SSD) with similar vocabulary and language skills.
   Method: Thirty-six monolingual English-speaking children aged 4 and 5 years, half with SSD and half with typical speech and language skills, participated in this study. Participants completed standardized speech and language tests as well as a mispronunciation detection task targeting omissions and substitutions of the phonemes /k, s, r/ in five word positions/shapes.
   Results: The children with SSD obtained significantly lower perceptual accuracy than the children with typical development. There was no statistically significant effect for phoneme. Omissions were more likely to be detected by both groups of participants compared with substitutions, and children with SSD had greater difficulty identifying substitutions as incorrectly produced words.
   Conclusions: Speech perception difficulties may be a distinguishing feature of children with phonological SSD and without concomitant language difficulties. Further research is needed to investigate specific speech contexts in which perception predicts accurate production in children with SSD.
C1 [Brosseau-Lapre, Francoise; Schumaker, Jennifer] Purdue Univ, Dept Speech Language & Hearing Sci, W Lafayette, IN 47907 USA.
RP Brosseau-Lapre, F (corresponding author), Purdue Univ, Dept Speech Language & Hearing Sci, W Lafayette, IN 47907 USA.
EM fbrossea@purdue.edu
OI Brosseau-Lapre, Francoise/0000-0002-6638-5383
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R21DC016142]
FX The work reported in this article was supported by National Institute on
   Deafness and Other Communication Disorders Grant R21DC016142 (awarded to
   F. B.-L.). The authors are grateful to the children and their parents
   who agreed to participate in the study. The authors thank members of the
   Purdue Child Phonology Lab for their valuable assistance during the
   project and, in particular, Kathryn Bower, Ellen Graham-Platt, Rose
   Reyling, Krista Riegsecker, Elizabeth Roepke, and Leyna Schroeder. The
   authors also thank Sophie and Laura for their enthusiasm and helpful
   comments when designing and piloting the task.
CR Anthony JL, 2010, READ WRIT, V23, P969, DOI 10.1007/s11145-009-9185-7
   BEITCHMAN JH, 1986, J SPEECH HEAR DISORD, V51, P98, DOI 10.1044/jshd.5102.98
   Boersma P., 2018, PRAAT DOING PHONETIC
   BROEN PA, 1983, J SPEECH HEAR RES, V26, P601, DOI 10.1044/jshr.2604.601
   Brosseau-Lapre F, 2020, AM J SPEECH-LANG PAT, V29, P883, DOI 10.1044/2020_AJSLP-19-00062
   Brosseau-Lapre F, 2019, J SPEECH LANG HEAR R, V62, P3276, DOI 10.1044/2019_JSLHR-S-17-0461
   Brosseau-Lapre F, 2017, J CHILD LANG, V44, P1337, DOI 10.1017/S0305000916000556
   Cabbage KL, 2016, SPEECH COMMUN, V82, P14, DOI 10.1016/j.specom.2016.05.002
   Claessen M, 2009, INT J LANG COMM DIS, V44, P121, DOI 10.1080/13682820801966317
   Cooper A, 2018, COGNITION, V173, P16, DOI 10.1016/j.cognition.2017.12.013
   Dodd B, 2003, CLIN LINGUIST PHONET, V17, P617, DOI 10.1080/0269920031000111348
   Dunn L. M., 2007, PEABODY PICTURE VOCA, DOI [10.1037/t15144-000, DOI 10.1037/T15144-000]
   Edwards J, 2002, J SPEECH LANG HEAR R, V45, P231, DOI 10.1044/1092-4388(2002/018)
   Edwards J, 1999, J SPEECH LANG HEAR R, V42, P169, DOI 10.1044/jslhr.4201.169
   Endress AD, 2010, J EXP PSYCHOL HUMAN, V36, P235, DOI 10.1037/a0017164
   Fenson L., 2007, MACARTHUR BATES COMM, DOI [10.1037/t11538-000, DOI 10.1037/T11538-000]
   Fitzmaurice G. M., 2011, APPL LONGITUDINAL AN, DOI [10.1002/9781119513469, DOI 10.1002/9781119513469]
   Gierut JA, 1998, J SPEECH LANG HEAR R, V41, pS85, DOI 10.1044/jslhr.4101.s85
   Goldman R., 2015, GOLDMAN FRISTOE TEST, V3rd edition.
   Groenen P, 1996, J SPEECH HEAR RES, V39, P468, DOI 10.1044/jshr.3903.468
   Haelsig P. C., 1986, LANG SPEECH HEAR SER, V17, P107, DOI DOI 10.1044/0161-1461.1702.107
   Hazan V, 2004, J ACOUST SOC AM, V116, P3108, DOI 10.1121/1.1806826
   Hearnshaw S, 2019, J SPEECH LANG HEAR R, V62, P3771, DOI 10.1044/2019_JSLHR-S-18-0519
   Hearnshaw S, 2018, J COMMUN DISORD, V71, P61, DOI 10.1016/j.jcomdis.2017.12.004
   Hodson B. W., 2007, EVALUATING ENHANCING
   HOFFMAN PR, 1985, J SPEECH HEAR DISORD, V50, P46, DOI 10.1044/jshd.5001.46
   IBM, 2019, SPSS STAT VERS 26 0
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Kaufman A., 2004, KAUFMAN BRIEF INTELL, V2nd
   Louis K. O., 2000, ORAL SPEECH MECH SCR
   McIntosh B, 2008, INT J SPEECH-LANG PA, V10, P460, DOI 10.1080/17549500802149683
   McLeod S, 2009, J SPEECH LANG HEAR R, V52, P1213, DOI 10.1044/1092-4388(2009/08-0085)
   McNeill BC, 2010, INT J LANG COMM DIS, V45, P72, DOI 10.3109/13682820902745479
   Munson B, 2005, J SPEECH LANG HEAR R, V48, P108, DOI 10.1044/1092-4388(2005/009)
   Munson B, 2005, J SPEECH LANG HEAR R, V48, P61, DOI 10.1044/1092-4388(2005/006)
   Nathan L, 2004, J SPEECH LANG HEAR R, V47, P377, DOI 10.1044/1092-4388(2004/031)
   Psychology Software Tools Inc, 2017, E PRIM VERS 3 0
   RAAYMAKERS EMJA, 1988, J SPEECH HEAR DISORD, V53, P262, DOI 10.1044/jshd.5303.262
   Redford MA, 1999, J ACOUST SOC AM, V106, P1555, DOI 10.1121/1.427152
   Redford MA, 2007, J ACOUST SOC AM, V121, P1665, DOI 10.1121/1.2431339
   Rizzo M, 2005, TRANSPORT RES REC, P1
   Rvachew S, 2006, J SPEECH LANG HEAR R, V49, P74, DOI 10.1044/1092-4388(2006/006)
   Rvachew S, 2004, AM J SPEECH-LANG PAT, V13, P250, DOI 10.1044/1058-0360(2004/026)
   RVACHEW S, 1989, J SPEECH HEAR DISORD, V54, P193, DOI 10.1044/jshd.5402.193
   Rvachew S., 2009, SPEECH ASSESSMENT IN
   Rvachew S., 2018, DEV PHONOLOGICAL DIS, VSecond
   Rvachew S, 2007, AM J SPEECH-LANG PAT, V16, P260, DOI 10.1044/1058-0360(2007/030)
   Rvachew S, 2007, LANG SPEECH HEAR SER, V38, P60, DOI 10.1044/0161-1461(2007/006)
   Shriberg LD, 2012, CLIN LINGUIST PHONET, V26, P445, DOI 10.3109/02699206.2012.655841
   SMIT AB, 1993, J SPEECH HEAR RES, V36, P533, DOI 10.1044/jshr.3603.533
   SMIT AB, 1990, J SPEECH HEAR DISORD, V55, P779, DOI 10.1044/jshd.5504.779
   STACKHOUSE J, 1993, EUR J DISORDER COMM, V28, P331
   Storkel HL, 2010, BEHAV RES METHODS, V42, P497, DOI 10.3758/BRM.42.2.497
   Strombergsson S, 2014, CLIN LINGUIST PHONET, V28, P373, DOI 10.3109/02699206.2013.868928
   Sutherland D, 2005, LANG SPEECH HEAR SER, V36, P294, DOI 10.1044/0161-1461(2005/030)
   Vance M, 2009, INT J AUDIOL, V48, P708, DOI 10.1080/14992020902930550
   Waring R, 2013, INT J LANG COMM DIS, V48, P25, DOI 10.1111/j.1460-6984.2012.00195.x
   Williams K. T., 2007, EXPRESSIVE VOCABULAR, DOI [10.1037/t15094-000, DOI 10.1037/T15094-000]
   Wren Y, 2016, J SPEECH LANG HEAR R, V59, P647, DOI 10.1044/2015_JSLHR-S-14-0282
   Zuk J, 2018, J SPEECH LANG HEAR R, V61, P583, DOI 10.1044/2017_JSLHR-S-16-0106
NR 60
TC 0
Z9 0
U1 0
U2 0
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD DEC
PY 2020
VL 63
IS 12
BP 3961
EP 3973
DI 10.1044/2020_JSLHR-20-00119
PG 13
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA PK7OO
UT WOS:000602629500005
PM 33197364
DA 2021-02-24
ER

PT J
AU Jaisinghani, P
   Manjula, P
AF Jaisinghani, Priyanka
   Manjula, P.
TI Acoustical and Perceptual Analysis of Noise Reduction Strategies in
   Individuals With Auditory Neuropathy Spectrum Disorders
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID HEARING-AID; SPEECH-INTELLIGIBILITY; ALGORITHM; CHILDREN; TIME;
   CONSEQUENCES; PERFORMANCE; POTENTIALS
AB Purpose: The conventional amplification devices render minimal or no benefit at abating the speech perception problems of individuals with auditory neuropathy spectrum disorder (ANSD). This study was undertaken to evaluate the effect of noise reduction strategies (multiband spectral subtraction, Wiener-as, Karhunen-Loeve transform [Subspace], and ideal binary mask [IdBM] algorithm) on speech using speech perception measures and acoustic measure among individuals with ANSD.
   Method: Two groups of participants (age: 17-43 years) were recruited in the study. Group I comprised 12 individuals with a confirmed diagnosis of ANSD and not exceeding moderate degree of hearing loss and Group II of 10 individuals with normal hearing in both ears. The signal-to-noise required for 50% speech recognition (SNR-50) was measured for the participants in five conditions, that is, unprocessed speech and speech processed with four noise reduction strategies. Additionally, an acoustic objective measure Extended Short-Time Objective Intelligibility algorithm was employed to estimate the intelligibility index across the conditions.
   Results: Significant difference was found across conditions in both the groups. Pairwise comparison revealed significantly better speech perception on SNR-50 measure with IdBM strategy, for both the groups. No significant difference in SNR-50 was observed with other noise reduction strategies. IdBM condition also gave the highest intelligibility index (d) values using Extended Short-Time Objective Intelligibility algorithm. This finding needs to be verified on a larger group of individuals with ANSD.
   Conclusions: IdBM noise reduction strategy rendered significantly lower SNR-50 compared to other noise reduction strategies for individuals with ANSD in this study. This provides clinical evidence for the same and also recommends trying on a larger group of participants before its implementation in hearing devices. Apart from this, the current strategies used in hearing aids provide no improvement in speech identification in noise for this population. Hence, though the present hearing aids may show benefit in quiet condition, chances of its rejection are high in noisy backgrounds.
C1 [Jaisinghani, Priyanka; Manjula, P.] All India Inst Speech & Hearing, Dept Audiol, Mysore, Karnataka, India.
RP Jaisinghani, P (corresponding author), All India Inst Speech & Hearing, Dept Audiol, Mysore, Karnataka, India.
EM jaisinghani.priyanka1@gmail.com
CR Alcantara JI, 2003, INT J AUDIOL, V42, P34, DOI 10.3109/14992020309056083
   American National Standards Institute, 2018, MAX PERM AMB NOIS LE
   Balan J. R., 2018, THESIS
   Barman A, 2016, HEARING BALANC COMMU, V14, P25, DOI 10.3109/21695717.2015.1075322
   Berlin Charles I., 2002, Seminars in Hearing, V23, P209, DOI 10.1055/s-2002-34458
   Berlin Charles I., 1999, Seminars in Hearing, V20, P307, DOI 10.1055/s-0028-1082946
   Boersma P., 2013, PRAAT COMPUTER SOFTW
   Boymans M, 2000, AUDIOLOGY, V39, P260
   Brungart DS, 2006, J ACOUST SOC AM, V120, P4007, DOI 10.1121/1.2363929
   Chung King, 2004, Trends Amplif, V8, P83, DOI 10.1177/108471380400800302
   Clark J G, 1981, ASHA, V23, P493
   Dell'aringa AHB, 2009, INT ARCH OTORHINOLAR, V13, P107
   Dillon H., 2008, HEARING AIDS
   Finney D.J., 1952, STAT METHOD BIOL ASS
   Geetha C, 2014, J HEAR SCI, V4, P18
   Hu Y, 2007, J ACOUST SOC AM, V122, P1777, DOI 10.1121/1.2766778
   Hu Y, 2007, SPEECH COMMUN, V49, P588, DOI 10.1016/j.specom.2006.12.006
   Hyde M, 1997, AUDIOL NEURO-OTOL, V2, P281, DOI 10.1159/000259253
   Jensen J, 2016, IEEE-ACM T AUDIO SPE, V24, P2009, DOI 10.1109/TASLP.2016.2585878
   Kim G, 2009, J ACOUST SOC AM, V126, P1486, DOI 10.1121/1.3184603
   Kraus N, 2000, JARO-J ASSOC RES OTO, V1, P33, DOI 10.1007/s101620010004
   Levitt H, 2001, J REHABIL RES DEV, V38, P111
   Li N, 2008, J ACOUST SOC AM, V123, P1673, DOI 10.1121/1.2832617
   Loizou P. C., 2013, SPEECH ENHANCEMENT T, DOI [10.1201/b14529, DOI 10.1201/B14529]
   Martin B. A., 2007, AUDITORY EVOKED POTE, P482
   Mathai JP, 2017, EAR HEARING, V38, pE109, DOI 10.1097/AUD.0000000000000368
   Mathai JP, 2015, J AM ACAD AUDIOL, V26, P815, DOI 10.3766/jaaa.14102
   Mathai JP, 2018, J AUDIOL OTOL, V22, P171, DOI 10.7874/jao.2018.00031
   Miyamoto RT, 1999, LARYNGOSCOPE, V109, P181, DOI 10.1097/00005537-199902000-00002
   Narayanan A, 2013, INT CONF ACOUST SPEE, P7092, DOI 10.1109/ICASSP.2013.6639038
   Narne VK, 2016, J AM ACAD AUDIOL, V27, P839, DOI 10.3766/jaaa.15145
   Narne VK, 2014, HEARING BALANC COMMU, V12, P112, DOI 10.3109/21695717.2014.938481
   Narne VK, 2008, BEHAV BRAIN FUNCT, V4, DOI 10.1186/1744-9081-4-15
   Narne VK, 2009, EAR HEARING, V30, P136, DOI 10.1097/AUD.0b013e3181926545
   Rance G, 2002, EAR HEARING, V23, P239, DOI 10.1097/00003446-200206000-00008
   Rance G, 1999, EAR HEARING, V20, P238, DOI 10.1097/00003446-199906000-00006
   Rance G, 2007, EAR HEARING, V28, P694, DOI 10.1097/AUD.0b013e31812f71de
   Rangachari S, 2006, SPEECH COMMUN, V48, P220, DOI 10.1016/j.specom.2005.08.005
   Shetty HN, 2017, INDIAN J OTOL, V23, P7, DOI 10.4103/0971-7749.199509
   Sininger Y., 2001, AUDITORY NEUROPATHY, P15
   Starr A, 1996, BRAIN, V119, P741, DOI 10.1093/brain/119.3.741
   Steever S. B., 2015, DRAVIDIAN LANGUAGES, P19, DOI 10.1093/obo/9780199772810-0188
   Tanyer SG, 2000, IEEE T SPEECH AUDI P, V8, P478, DOI 10.1109/89.848229
   TYLER RS, 1983, SCAND AUDIOL, V12, P285, DOI 10.3109/01050398309044432
   Vanaja C. S., 2004, 1 C AUD NEUR, P136
   Wang D. L., 2006, COMPUTATIONAL AUDITO
   Wang DL, 2009, J ACOUST SOC AM, V125, P2336, DOI 10.1121/1.3083233
   Yuvaraj P, 2016, J AUDIOL OTOL, V20, P158, DOI 10.7874/jao.2016.20.3.158
   Yuvaraj P, 2015, J INT ADV OTOL, V11, P236, DOI [10.5152/iao.2015.1162, 10.5152/Iao.2015.1162]
   Zeng FG, 2005, J NEUROPHYSIOL, V93, P3050, DOI 10.1152/jn.00985.2004
NR 50
TC 0
Z9 0
U1 0
U2 0
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD DEC
PY 2020
VL 63
IS 12
BP 4208
EP 4218
DI 10.1044/2020_JSLHR-20-00176
PG 11
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA PK7OO
UT WOS:000602629500022
PM 33175645
DA 2021-02-24
ER

PT J
AU Zhang, H
   Zhang, J
   Peng, G
   Ding, HW
   Zhang, Y
AF Zhang, Hao
   Zhang, Jing
   Peng, Gang
   Ding, Hongwei
   Zhang, Yang
TI Bimodal Benefits Revealed by Categorical Perception of Lexical Tones in
   Mandarin-Speaking Kindergarteners With a Cochlear Implant and a
   Contralateral Hearing Aid
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SPEECH-PERCEPTION; LANGUAGE EXPERIENCE; FREQUENCY DISCRIMINATION;
   INFANTS SHOW; ONE EAR; CHILDREN; IDENTIFICATION; STIMULATION;
   RECOGNITION; INFORMATION
AB Purpose: Pitch reception poses challenges for individuals with cochlear implants (CIs), and adding a hearing aid (HA) in the nonimplanted ear is potentially beneficial. The current study used fine-scale synthetic speech stimuli to investigate the bimodal benefit for lexical tone categorization in Mandarin-speaking kindergarteners using a CI and an HA in opposite ears.
   Method: The data were collected from 16 participants who were required to complete two classical tasks for speech categorical perception (CP) with CI + HA device condition and CI alone condition. Linear mixed-effects models were constructed to evaluate the identification and discrimination scores across different device conditions.
   Results: The bimodal kindergarteners showed CP for the continuum varying from Mandarin Tone 1 and Tone 2. Moreover, the additional acoustic information from the contralateral HA contributes to improved lexical tone categorization, with a steeper slope, a higher discrimination score of between-category stimuli pair, and an improved peakedness score (i.e., an increased benefit magnitude for discriminations of between-category over within-category pairs) for the CI + HA condition than the CI alone condition. The bimodal kindergarteners with better residual hearing thresholds at 250 Hz level in the nonimplanted ear could perceive lexical tones more categorically.
   Conclusion: The enhanced CP results with bimodal listening provide clear evidence for the clinical practice to fit a contralateral HA in the nonimplanted ear in kindergarteners with unilateral CIs with direct benefits from the low-frequency acoustic hearing.
C1 [Zhang, Hao; Zhang, Jing; Ding, Hongwei] Shanghai Jiao Tong Univ, Speech Language Hearing Ctr, Sch Foreign Languages, Shanghai, Peoples R China.
   [Zhang, Hao; Peng, Gang] Hong Kong Polytech Univ, Res Ctr Language Cognit & Neurosci, Dept Chinese & Bilingual Studies, Hong Kong, Peoples R China.
   [Zhang, Yang] Univ Minnesota, Dept Speech Language Hearing Sci, Minneapolis, MN 55455 USA.
   [Zhang, Yang] Univ Minnesota, Ctr Neurobehav Dev, Minneapolis, MN 55455 USA.
RP Ding, HW (corresponding author), Shanghai Jiao Tong Univ, Speech Language Hearing Ctr, Sch Foreign Languages, Shanghai, Peoples R China.; Zhang, Y (corresponding author), Univ Minnesota, Dept Speech Language Hearing Sci, Minneapolis, MN 55455 USA.; Zhang, Y (corresponding author), Univ Minnesota, Ctr Neurobehav Dev, Minneapolis, MN 55455 USA.
EM hwding@sjtu.edu.cn; zhanglab@umn.edu
RI Zhang, Yang/Q-1780-2015
OI Zhang, Yang/0000-0001-6777-3487
FU Major Program of National Social Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) [18ZDA293]; University of
   Minnesota's Brain Imaging Grant
FX This study was supported by grants from the Major Program of National
   Social Science Foundation of China (No. 18ZDA293) awarded to H. Ding and
   Y. Zhang. Y. Zhang received additional support from the University of
   Minnesota's Brain Imaging Grant and Grand Challenges Exploratory
   Research Grant for international collaboration. We would like to thank
   Yongqin Li, Rentao Wei, and Renxia Tao from the Shanghai Rehabilitation
   Center of the Deaf Children for their assistance in implementing this
   study.
CR Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Boersma P., 2018, PRAAT DOING PHONETIC
   Carroll J, 2007, HEARING RES, V231, P42, DOI 10.1016/j.heares.2007.05.004
   Chao Y. R., 1948, MANDARIN PRIMER INTE
   Chatterjee M, 2008, HEARING RES, V235, P143, DOI 10.1016/j.heares.2007.11.004
   Chatterjee M, 2015, HEARING RES, V322, P151, DOI 10.1016/j.heares.2014.10.003
   Chen F, 2017, J CHILD LANG, V44, P1413, DOI 10.1017/S0305000916000581
   Chen Y, 2014, INT J PEDIATR OTORHI, V78, P1923, DOI 10.1016/j.ijporl.2014.08.025
   Cheng XT, 2018, NEURAL PLAST, V2018, DOI 10.1155/2018/4610592
   Ching TYC, 2001, EAR HEARING, V22, P365, DOI 10.1097/00003446-200110000-00002
   Cullington HE, 2011, EAR HEARING, V32, P16, DOI 10.1097/AUD.0b013e3181edfbd2
   Deroche MLD, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00639
   Dorman MF, 2007, JARO-J ASSOC RES OTO, V8, P234, DOI 10.1007/s10162-007-0071-1
   FINNEY D J, 1971, P333
   Fu QJ, 2005, J ACOUST SOC AM, V118, P1711, DOI 10.1121/1.1985024
   Gerrits E, 2004, PERCEPT PSYCHOPHYS, V66, P363, DOI 10.3758/BF03194885
   Gifford RH, 2019, EAR HEARING, V40, P501, DOI 10.1097/AUD.0000000000000657
   Gu X, 2017, OTOL NEUROTOL, V38, pE421, DOI 10.1097/MAO.0000000000001580
   Hiskey M. S., 1966, HISKEY NEBRASKA TEST
   Holt CM, 2018, J SPEECH LANG HEAR R, V61, P174, DOI 10.1044/2017_JSLHR-H-17-0027
   Ingvalson EM, 2013, J SPEECH LANG HEAR R, V56, P81, DOI 10.1044/1092-4388(2012/11-0291)
   Jiam NT, 2017, HEARING RES, V352, P30, DOI 10.1016/j.heares.2017.01.006
   Jiang CM, 2012, MEM COGNITION, V40, P1109, DOI 10.3758/s13421-012-0208-2
   Kessler DM, 2020, TRENDS HEAR, V24, DOI 10.1177/2331216520902001
   Kuhl P, 2008, ANNU REV NEUROSCI, V31, P511, DOI 10.1146/annurev.neuro.30.051606.094321
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Li JN, 2017, EAR HEARING, V38, P647, DOI 10.1097/AUD.0000000000000441
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   Liu QY, 2014, NAT GEOSCI, V7
   Liu YWY, 2019, EAR HEARING, V40, P1316, DOI 10.1097/AUD.0000000000000712
   Luo X, 2014, HEARING RES, V312, P1, DOI 10.1016/j.heares.2014.02.005
   MacMillan N. A., 2005, DETECTION THEORY USE
   McDermott Hugh J, 2004, Trends Amplif, V8, P49, DOI 10.1177/108471380400800203
   Meister H, 2016, J SPEECH LANG HEAR R, V59, P546, DOI 10.1044/2015_JSLHR-H-15-0128
   Meister H, 2009, INT J AUDIOL, V48, P38, DOI 10.1080/14992020802293539
   Miller SE, 2016, J SPEECH LANG HEAR R, V59, P90, DOI 10.1044/2015_JSLHR-H-15-0154
   Mok M, 2006, J SPEECH LANG HEAR R, V49, P338, DOI 10.1044/1092-4388(2006/027)
   Mok M, 2017, EAR HEARING, V38, pE359, DOI 10.1097/AUD.0000000000000453
   Morera C, 2005, ACTA OTO-LARYNGOL, V125, P596, DOI 10.1080/00016480510027493
   Morton KD, 2008, HEARING RES, V244, P66, DOI 10.1016/j.heares.2008.07.008
   Most T, 2012, J DEAF STUD DEAF EDU, V17, P244, DOI 10.1093/deafed/enr046
   Most T, 2011, J SPEECH LANG HEAR R, V54, P668, DOI 10.1044/1092-4388(2010/10-0071)
   Nakata T, 2012, J ACOUST SOC AM, V131, P1307, DOI 10.1121/1.3672697
   Neuman AC, 2017, TRENDS HEAR, V21, P1, DOI 10.1177/2331216517699530
   Paquette S, 2018, HEARING RES, V370, P272, DOI 10.1016/j.heares.2018.08.009
   Park LR, 2019, EAR HEARING, V40, P849, DOI 10.1097/AUD.0000000000000658
   Peng G, 2010, J PHONETICS, V38, P616, DOI 10.1016/j.wocn.2010.09.003
   Peng SC, 2004, EAR HEARING, V25, P251, DOI 10.1097/01.AUD.0000130797.73809.40
   Peng SC, 2008, EAR HEARING, V29, P336, DOI 10.1097/AUD.0b013e318168d94d
   Peng SC, 2017, J SPEECH LANG HEAR R, V60, P1223, DOI 10.1044/2016_JSLHR-S-16-0048
   Peterson NR, 2010, RESTOR NEUROL NEUROS, V28, P237, DOI 10.3233/RNN-2010-0535
   Shannon RV, 2004, ACTA OTO-LARYNGOL, V124, P50, DOI 10.1080/03655230410017562
   Shen GN, 2019, BILING-LANG COGN, V22, P253, DOI 10.1017/S136672891800038X
   SHEN XNS, 1991, LANG SPEECH, V34, P145, DOI 10.1177/002383099103400202
   SHEN XNS, 1993, J ACOUST SOC AM, V93, P2241, DOI 10.1121/1.406688
   Shpak T, 2014, EAR HEARING, V35, P97, DOI 10.1097/AUD.0b013e3182a2c814
   Tan J, 2016, AM J AUDIOL, V25, P246, DOI 10.1044/2016_AJA-15-0069
   Tao D., 2018, TRENDS HEAR, V22, P1, DOI [10.1177/2331216518757892, DOI 10.1177/]
   Tao DD, 2015, EAR HEARING, V36, P102, DOI 10.1097/AUD.0000000000000086
   Van De Velde DJ, 2019, J CHILD LANG, V46, P111, DOI 10.1017/S0305000918000387
   van Wieringen A, 2015, HEARING RES, V322, P171, DOI 10.1016/j.heares.2014.09.002
   Wang S, 2012, LARYNGOSCOPE, V122, P1353, DOI 10.1002/lary.23271
   WANG WSY, 1973, SCI AM, V228, P50, DOI 10.1038/scientificamerican0273-50
   Wang XY, 2017, SCI REP-UK, V7, P1, DOI 10.1038/srep43254
   WHALEN DH, 1992, PHONETICA, V49, P25, DOI 10.1159/000261901
   Xi J, 2010, NEUROSCIENCE, V170, P223, DOI 10.1016/j.neuroscience.2010.06.077
   Xu YS, 2006, J ACOUST SOC AM, V120, P1063, DOI 10.1121/1.2213572
   Yang HI, 2017, INT J AUDIOL, V56, pS17, DOI 10.1080/14992027.2017.1321789
   Yang X.J., 2011, J CLIN PSYCHOL, V19, P195
   Yip M., 2002, TONE
   Yu KK, 2019, PSYCHOPHYSIOLOGY, V56, DOI 10.1111/psyp.13448
   Zhang H., 2019, P 19 INT C PHON SCI, P278
   Zhang H, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10040238
   Zhang LJ, 2018, J SPEECH LANG HEAR R, V61, DOI 10.1044/2018_JSLHR-H-17-0327
   Zhang T, 2013, EAR HEARING, V34, P133, DOI 10.1097/AUD.0b013e31826709af
   Zhang T, 2012, EAR HEARING, V33, pE70, DOI 10.1097/AUD.0b013e318259e5dd
   Zhang T, 2010, EAR HEARING, V31, P63, DOI 10.1097/AUD.0b013e3181b7190c
   Zhang Y, 2005, NEUROIMAGE, V26, P703, DOI 10.1016/j.neuroimage.2005.02.040
   Zhang Y., 2016, ENCY CHINESE LANGUAG, DOI [10.1163/2210-7363_ecll_COM_000071, DOI 10.1163/2210-7363_ECLL_COM_000071]
   Zhang YJ, 2012, J CHILD PSYCHOL PSYC, V53, P874, DOI 10.1111/j.1469-7610.2012.02528.x
   Zheng HY, 2012, LANG COGNITIVE PROC, V27, P184, DOI 10.1080/01690965.2010.520493
   Zhou N, 2013, OTOL NEUROTOL, V34, P499, DOI 10.1097/MAO.0b013e318287ca86
NR 87
TC 0
Z9 0
U1 0
U2 0
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD DEC
PY 2020
VL 63
IS 12
BP 4238
EP 4251
DI 10.1044/2020_JSLHR-20-00224
PG 14
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA PK7OO
UT WOS:000602629500024
PM 33186505
DA 2021-02-24
ER

PT J
AU Toya, T
   Birkholz, P
   Unoki, M
AF Toya, Teruki
   Birkholz, Peter
   Unoki, Masashi
TI Measurements of Transmission Characteristics Related to Bone-Conducted
   Speech Using Excitation Signals in the Oral Cavity
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SOUND; AIR; MICROPHONE; FEEDBACK; HEARING; VOICE
AB Purpose: Psychoacoustical studies on transmission characteristics related to bone-conducted (BC) speech, perceived by speakers during vocalization, are important for further understanding the relationship between speech production and perception, especially auditory feedback. For exploring how the outer ear part contributes to BC speech transmission, this article aims to measure the transmission characteristics of bone conduction focusing on the vibration of the regio temporalis (RT) and sound radiation in the ear canal (EC) due to the excitation in the oral cavity (OC).
   Method: While an excitation signal was presented through a loudspeaker located in the enclosed cavity below the hard palate, transmitted signals were measured on the RT and in the EC. The transfer functions of the RT vibration and EC sound pressure relative to OC sound pressure were determined from the measured signals using the sweep-sine method.
   Results: Our findings obtained from the measurements of five participants are as follows: (a) the transfer function of the RT vibration relative to the OC sound pressure attenuated the frequency components above 1 kHz and (b) the transfer function of the EC relative to the OC sound pressure emphasized the frequency components between 2 and 3 kHz.
   Conclusions: The vibration of the soft tissue or the skull bone has an effect of low-pass filtering, whereas the sound radiation in the EC has an effect of 2-3 kHz bandpass filtering. Considering the perceptual effect of low-pass filtering in BC speech, our findings suggest that the transmission to the outer ear may not be a dominant contributor to BC speech perception during vocalization.
C1 [Toya, Teruki; Unoki, Masashi] Japan Adv Inst Sci & Technol, Grad Sch Adv Sci & Technol, Nomi, Ishikawa, Japan.
   [Birkholz, Peter] Tech Univ Dresden, Inst Acoust & Speech Commun, Dresden, Germany.
RP Toya, T (corresponding author), Japan Adv Inst Sci & Technol, Grad Sch Adv Sci & Technol, Nomi, Ishikawa, Japan.
EM yattin_yatson@jaist.ac.jp
FU Japan Society for the Promotion of Science KAKENHIMinistry of Education,
   Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for
   the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)
   [16H01669, 17J03679, 18H05004]
FX This work was supported by Japan Society for the Promotion of Science
   KAKENHI Grants 16H01669 (to Teruki Toya), 17J03679 (to Masashi Unoki),
   and 18H05004 (to Masashi Unoki). We are grateful to Naoto Nishide,
   associate dean of Houju Memorial Hospital, and all dental technicians in
   this hospital for helping us make the plaster replicas of the upper jaws
   for the measurements. We are also grateful to Tatsuya Hirahara of Toyama
   Prefectural University for providing us with the equipment and knowhow
   for measuring the frequency response of the bone-conduction microphone.
   We also thank Shumpei Taniguchi, a research fellow in Japan Advanced
   Institute of Science and Technology, for providing us with the equipment
   and knowhow for making the rubber enclosures used in the measurements.
CR Chen SH, 2007, J ACOUST SOC AM, V121, P1157, DOI 10.1121/1.2404624
   Denes P. B., 1993, THE SPEECH CHAIN
   Fagelson M.A., 1998, AM J AUDIOL, V7, P50
   Farina A, 2000, PREPRINTS AUDIO ENG, V108, P1
   GOLDSTEIN DP, 1965, J SPEECH HEAR RES, V8, P137, DOI 10.1044/jshr.0802.137
   Hakansson B, 1996, J ACOUST SOC AM, V99, P2239, DOI 10.1121/1.415411
   HAKANSSON B, 1994, J ACOUST SOC AM, V95, P1474, DOI 10.1121/1.408535
   Kent R.D., 1992, ACOUSTIC ANAL SPEECH
   LEE BS, 1950, J ACOUST SOC AM, V22, P824, DOI 10.1121/1.1906696
   Madaule Paul, 2001, J SINGING NATL ASS T, V57, P15
   MEHRGARDT S, 1977, J ACOUST SOC AM, V61, P1567, DOI 10.1121/1.381470
   MOLLER AAGE R., 1962, JOUR ACOUSTICAL SOC AMER, V34, P1524, DOI 10.1121/1.1918384
   Nakayama I., 1997, Journal of the Acoustical Society of Japan (E), V18, P67
   Okazaki S, 2010, ACOUST SCI TECHNOL, V31, P408, DOI 10.1250/ast.31.408
   Porschmann C, 2000, ACUSTICA, V86, P1038
   Rahman MS, 2019, ACOUST SCI TECHNOL, V40, P293, DOI 10.1250/ast.40.293
   Reinfeldt S, 2010, J ACOUST SOC AM, V128, P751, DOI 10.1121/1.3458855
   Shimizu S, 2009, ACOUST SCI TECHNOL, V30, P139, DOI 10.1250/ast.30.139
   Stenfelt S, 2005, OTOL NEUROTOL, V26, P1245, DOI 10.1097/01.mao.0000187236.10842.d5
   Stenfelt S, 2004, J ACOUST SOC AM, V115, P797, DOI 10.1121/1.1639903
   Stenfelt S, 2002, J ACOUST SOC AM, V111, P947, DOI 10.1121/1.1432977
   Stenfelt S, 2003, J ACOUST SOC AM, V113, P902, DOI 10.1121/1.1534606
   Stenfelt S, 2000, J ACOUST SOC AM, V107, P422, DOI 10.1121/1.428314
   Stenfelt S, 2007, INT J AUDIOL, V46, P595, DOI 10.1080/14992020701545880
   Stenfelt S, 2015, HEARING RES, V329, P41, DOI 10.1016/j.heares.2014.12.003
   Stenfelt S, 2011, ADV OTO-RHINO-LARYNG, V71, P10, DOI 10.1159/000323574
   Sundberg J., 1987, SCI SINGING VOICE
   Tonndorf J., 1976, HDB SENSORY PHYSL, DOI [10.1007/978-3-642-66082-5_2, DOI 10.1007/978-3-642-66082-5_2]
   Toya T., 2019, LECT NOTES COMPUTER, V11658, P491, DOI [10.1007/978-3-030-26061-3_50, DOI 10.1007/978-3-030-26061-3_50]
   Toya T., 2016, J SIGNAL PROCESS, V20, P197, DOI [10.2299/jsp. 20.197, DOI 10.2299/JSP.20.197]
   Tran PK, 2013, J ACOUST SOC AM, V133, P3900, DOI 10.1121/1.4803870
   VONBEKESY G, 1949, J ACOUST SOC AM, V21, P217
   Watakabe M, 2001, MED BIOL ENG COMPUT, V39, P195, DOI 10.1007/BF02344804
NR 33
TC 0
Z9 0
U1 2
U2 2
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD DEC
PY 2020
VL 63
IS 12
BP 4252
EP 4264
DI 10.1044/2020_JSLHR-20-00097
PG 13
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA PK7OO
UT WOS:000602629500025
PM 33170762
OA Other Gold
DA 2021-02-24
ER

PT J
AU Kimel, E
   Weiss, AH
   Jakoby, H
   Daikhin, L
   Ahissar, M
AF Kimel, Eva
   Weiss, Atalia Hai
   Jakoby, Hilla
   Daikhin, Luba
   Ahissar, Merav
TI Short-term memory capacity and sensitivity to language statistics in
   dyslexia and among musicians
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Memory span; Sequence learning; Short-term memory; Long-term memory;
   Dyslexia; Musicians
ID ORDER LEARNING IMPAIRMENT; WORKING-MEMORY; SYLLABLE FREQUENCY;
   SPEECH-PERCEPTION; READING-ABILITY; WORD-FREQUENCY; SPAN; SEGMENTATION;
   SEQUENCE; INFORMATION
AB Poor short-term memory (STM) capacity in individuals with dyslexia (IDDs) and enhanced STM capacity in musicians are well documented, yet their causes are disputed. Previous studies also found poor use of stimuli statistics by IDDs and enhanced use by musicians. We hypothesized that these observations are functionally related, as follows: Enhanced sensitivity to statistics facilitates musicians' benefit from each exposure, and reduced sensitivity to statistics hinders IDDs' benefit. Thus, larger group differences are expected for larger exposure: STM capacity, which is sensitive to item familiarity, will thus be larger among musicians, and smaller among IDDS, particularly for high-frequency items. Testing this hypothesis using syllable span, we found that musicians' advantage and IDDs' difficulty were indeed larger for high-frequency syllables than for low-frequency ones. By contrast, benefits from sequence repetition did not differ between musicians, controls and IDDs, suggesting that online sequence learning is based on a different mechanism. To test this dissociation we recruited, in addition to native Hebrew speakers, native English speakers, matched to the Hebrew-speaking controls. Their spans for high-frequency syllables in Hebrew, which do not have high frequency in English, were small as expected from reduced exposure to these syllables. Yet, their benefit from sequence repetition was similar to that of the three Hebrew-speaking groups. Taken together, these experiments suggest that different sensitivities to item frequency explain some of the population-related variability in STM tasks. By contrast, benefits from sequence repetition do not depend on item familiarity, and do not differ between groups.
C1 [Kimel, Eva] Hebrew Univ Jerusalem, Edmond & Lily Safra Ctr Brain Sci, Edmond J Safra Campus Givat Ram, IL-9190401 Jerusalem, Israel.
   [Weiss, Atalia Hai; Jakoby, Hilla; Daikhin, Luba; Ahissar, Merav] Hebrew Univ Jerusalem, Dept Psychol, IL-9190501 Jerusalem, Israel.
   [Weiss, Atalia Hai; Jakoby, Hilla] Hadassah Acad Coll, Dept Commun Disorders, 37 Haneviim St, IL-9101001 Jerusalem, Israel.
RP Kimel, E (corresponding author), Hebrew Univ Jerusalem, Edmond & Lily Safra Ctr Brain Sci, Edmond J Safra Campus Givat Ram, IL-9190401 Jerusalem, Israel.
EM eva.kelman@mail.huji.ac.il
FU European Research Council (ERC) under the European Union's Horizon 2020
   research and innovation programEuropean Research Council (ERC) [833694];
   Israel Science FoundationIsrael Science Foundation [1650/17]
FX This project has received funding from the European Research Council
   (ERC) under the European Union's Horizon 2020 research and innovation
   program (grant agreement No 833694) and the Israel Science Foundation
   (Grant No. 1650/17), both awarded to Merav Ahissar.
CR ACKERMAN PT, 1990, J LEARN DISABIL, V23, P325, DOI 10.1177/002221949002300514
   Ahissar M, 2007, TRENDS COGN SCI, V11, P458, DOI 10.1016/j.tics.2007.08.015
   Ahissar M, 2006, NAT NEUROSCI, V9, P1558, DOI 10.1038/nn1800
   Alain C, 2007, CEREB CORTEX, V17, P1074, DOI 10.1093/cercor/bhl018
   American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU
   Anvari SH, 2002, J EXP CHILD PSYCHOL, V83, P111, DOI 10.1016/S0022-0965(02)00124-8
   Banai K, 2018, LANG COGN NEUROSCI, V33, P321, DOI 10.1080/23273798.2017.1408851
   Banai K, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0075876
   Ben-Yehudah G, 2001, BRAIN, V124, P1381, DOI 10.1093/brain/124.7.1381
   BENDROR I, 1995, PSYCHOL SCI, V6, P176, DOI 10.1111/j.1467-9280.1995.tb00328.x
   Bogaerts L, 2015, RES DEV DISABIL, V43-44, P106, DOI 10.1016/j.ridd.2015.06.012
   Carlisle JF, 2000, READ WRIT, V12, P169, DOI 10.1023/A:1008131926604
   Chandrasekaran B., 2010, MUSIC PRECEPTION, P297
   Chen JL, 2008, CEREB CORTEX, V18, P2844, DOI 10.1093/cercor/bhn042
   Chen JL, 2008, J COGNITIVE NEUROSCI, V20, P226, DOI 10.1162/jocn.2008.20018
   Clements G.N., 1983, CV PHONOLOGY GENERAT, DOI [10.2307/414790, DOI 10.2307/414790]
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Corrigall KA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00222
   Cowan N, 2019, PSYCHOL BULL, V145, DOI 10.1037/bul0000199
   Cowan N, 2010, CURR DIR PSYCHOL SCI, V19, P51, DOI 10.1177/0963721409359277
   CROSSMAN ERF, 1958, ERGONOMICS, V2, P153
   CUTLER A, 1988, J EXP PSYCHOL HUMAN, V14, P113, DOI 10.1037/0096-1523.14.1.113
   DAUER RM, 1983, J PHONETICS, V11, P51, DOI 10.1016/S0095-4470(19)30776-4
   Deutsch A, 1996, J EXP CHILD PSYCHOL, V63, P386, DOI 10.1006/jecp.1996.0055
   Duanmu S., 2010, LINGUISTIC ESSAYS HO, P295
   Franklin MS, 2008, PSYCHOL MUSIC, V36, P353, DOI 10.1177/0305735607086044
   Fujioka T, 2006, BRAIN, V129, P2593, DOI 10.1093/brain/awl247
   Gagnon S, 2004, COGN NEUROPSYCHOL, V21, P867, DOI 10.1080/02643290342000609
   Garrido MI, 2009, NEUROIMAGE, V48, P269, DOI 10.1016/j.neuroimage.2009.06.034
   Gathercole SE, 1999, J EXP PSYCHOL LEARN, V25, P84, DOI 10.1037/0278-7393.25.1.84
   GATHERCOLE SE, 1989, J MEM LANG, V28, P200, DOI 10.1016/0749-596X(89)90044-2
   GATHERCOLE SE, 1993, DEV PSYCHOL, V29, P770, DOI 10.1037/0012-1649.29.4.770
   Heathcote A, 2000, PSYCHON B REV, V7, P185, DOI 10.3758/BF03212979
   Hebb D. O., 1961, BRAIN MECH LEARN, P37, DOI DOI 10.5962/BHL.TITLE.7220
   Henderson LM, 2017, RES DEV DISABIL, V60, P198, DOI 10.1016/j.ridd.2016.11.002
   Hulme C, 1997, J EXP PSYCHOL LEARN, V23, P1217, DOI 10.1037/0278-7393.23.5.1217
   HULME C, 1991, J MEM LANG, V30, P685, DOI 10.1016/0749-596X(91)90032-F
   Jaffe-Dax S, 2018, ELIFE, V7, DOI 10.7554/eLife.30018
   Jaffe-Dax S, 2017, ELIFE, V6, DOI 10.7554/eLife.20557
   Jaffe-Dax S, 2015, J NEUROSCI, V35, P12116, DOI 10.1523/JNEUROSCI.1302-15.2015
   Jakoby H, 2019, J EXP PSYCHOL GEN, V148, P1953, DOI 10.1037/xge0000573
   Janata P, 2003, NAT NEUROSCI, V6, P682, DOI 10.1038/nn1081
   Janata P, 2002, COGN AFFECT BEHAV NE, V2, P121, DOI 10.3758/CABN.2.2.121
   Jeffries S, 2004, DYSLEXIA, V10, P196, DOI 10.1002/dys.278
   Kalm K, 2013, J COGNITIVE NEUROSCI, V25, P1111, DOI 10.1162/jocn_a_00378
   Kimel E., 2020, CAPACITY SHORT TERM
   Kimel E, 2020, J EXP PSYCHOL LEARN, V46, P155, DOI 10.1037/xlm0000717
   Kok P, 2018, J NEUROSCI, V38, P6888, DOI 10.1523/JNEUROSCI.0163-18.2018
   Krishnan S, 2016, TRENDS COGN SCI, V20, P701, DOI 10.1016/j.tics.2016.06.012
   Lee YS, 2007, LEARN INSTR, V17, P336, DOI 10.1016/j.learninstruc.2007.02.010
   LIBERMAN IY, 1974, J EXP CHILD PSYCHOL, V18, P201, DOI 10.1016/0022-0965(74)90101-5
   Lieder I, 2019, NAT NEUROSCI, V22, P256, DOI 10.1038/s41593-018-0308-9
   Lunden S.L.A., 2011, W COAST C FORM LING, P152
   Mahony D, 2000, READ WRIT, V12, P191, DOI 10.1023/A:1008136012492
   Majerus S, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01522
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   MORAIS J, 1979, COGNITION, V7, P323, DOI 10.1016/0010-0277(79)90020-9
   MORAIS J, 1987, CAH PSYCHOL COGN, V7, P415
   NAVEHBENJAMIN M, 1986, Q J EXP PSYCHOL-A, V38, P739, DOI 10.1080/14640748608401623
   Nimmo LM, 2002, APPL PSYCHOLINGUIST, V23, P643, DOI 10.1017/S0142716402004071
   Oganian Y, 2012, NEUROPSYCHOLOGIA, V50, P1895, DOI 10.1016/j.neuropsychologia.2012.04.014
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Pasquini ES, 2007, SCI STUD READ, V11, P259, DOI 10.1080/10888430701344280
   PERFETTI CA, 1987, MERRILL PALMER QUART, V33, P283
   Ramus F, 2008, Q J EXP PSYCHOL, V61, P129, DOI 10.1080/17470210701508822
   Ramus F, 2014, TRENDS COGN SCI, V18, P274, DOI 10.1016/j.tics.2014.01.009
   Rispens J, 2004, J NEUROLINGUIST, V17, P333, DOI 10.1016/j.jneuroling.2003.09.001
   Roodenrys S, 2002, J EXP PSYCHOL LEARN, V28, P1019, DOI 10.1037//0278-7393.28.6.1019
   Roodenrys S, 2001, READ WRIT, V14, P379, DOI 10.1023/A:1011123406884
   Sala G, 2017, CURR DIR PSYCHOL SCI, V26, P515, DOI 10.1177/0963721417712760
   Schapiro AC, 2014, J COGNITIVE NEUROSCI, V26, P1736, DOI 10.1162/jocn_a_00578
   Schiff R, 2007, J PSYCHOLINGUIST RES, V36, P237, DOI 10.1007/s10936-006-9043-6
   Schwarzlose RF, 2008, P NATL ACAD SCI USA, V105, P4447, DOI 10.1073/pnas.0800431105
   Share DL, 2005, J EXP CHILD PSYCHOL, V92, P182, DOI 10.1016/j.jecp.2005.05.003
   Shook A, 2013, AM J PSYCHOL, V126, P95, DOI 10.5406/amerjpsyc.126.1.0095
   SNOWLING M, 1986, J EXP CHILD PSYCHOL, V41, P489, DOI 10.1016/0022-0965(86)90006-8
   Snowling M., 2000, DYSLEXIA
   SNOWLING MJ, 1981, PSYCHOL RES-PSYCH FO, V43, P219, DOI 10.1007/BF00309831
   SOMMER BA, 1970, INT J AM LINGUIST, V36, P57, DOI 10.1086/465090
   Sperling AJ, 2005, NAT NEUROSCI, V8, P862, DOI 10.1038/nn1474
   SPRING C, 1976, J SPEC EDUC, V10, P35, DOI 10.1177/002246697601000104
   Sreenivasan KK, 2014, TRENDS COGN SCI, V18, P82, DOI 10.1016/j.tics.2013.12.001
   Staels E, 2015, J EXP PSYCHOL LEARN, V41, P650, DOI 10.1037/xlm0000054
   Staels E, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00732
   Stoel-Gammon C., 1989, FIRST LANG, V9, P207, DOI DOI 10.1177/014272378900900607
   Szmalec A, 2011, J EXP PSYCHOL LEARN, V37, P1270, DOI 10.1037/a0023820
   Talamini F, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0186773
   TORGESEN JK, 1990, LEARN DISABILITY Q, V13, P236, DOI 10.2307/1510350
   Tremblay P, 2016, NEUROIMAGE, V136, P106, DOI 10.1016/j.neuroimage.2016.05.018
   Velupillai V., 2012, INTRO LINGUISTIC TOP
   Wang XL, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00208
   Wechsler D., 1997, WAIS 3 ADM SCORING M
   Weiss AH, 2014, NEUROPSYCHOLOGIA, V54, P28, DOI 10.1016/j.neuropsychologia.2013.12.009
   WIMMER H, 1993, APPL PSYCHOLINGUIST, V14, P1, DOI 10.1017/S0142716400010122
NR 94
TC 0
Z9 0
U1 0
U2 0
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD DEC
PY 2020
VL 149
AR 107624
DI 10.1016/j.neuropsychologia.2020.107624
PG 10
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA PI5SK
UT WOS:000601150300003
PM 32920031
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Magee, M
   Lewis, C
   Noffs, G
   Reece, H
   Chan, JCS
   Zaga, CJ
   Paynter, C
   Birchall, O
   Azocar, SR
   Ediriweera, A
   Kenyon, K
   Caverle, MW
   Schultz, BG
   Vogel, AP
AF Magee, Michelle
   Lewis, Courtney
   Noffs, Gustavo
   Reece, Hannah
   Chan, Jess C. S.
   Zaga, Charissa J.
   Paynter, Camille
   Birchall, Olga
   Azocar, Sandra Rojas
   Ediriweera, Angela
   Kenyon, Katherine
   Caverle, Marja W.
   Schultz, Benjamin G.
   Vogel, Adam P.
TI Effects of face masks on acoustic analysis and speech perception:
   Implications for peri-pandemic protocols
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SARS-COV-2
AB Wearing face masks (alongside physical distancing) provides some protection against infection from COVID-19. Face masks can also change how people communicate and subsequently affect speech signal quality. This study investigated how three common face mask types (N95, surgical, and cloth) affected acoustic analysis of speech and perceived intelligibility in healthy subjects. Acoustic measures of timing, frequency, perturbation, and power spectral density were measured. Speech intelligibility and word and sentence accuracy were also examined using the Assessment of Intelligibility of Dysarthric Speech. Mask type impacted the power distribution in frequencies above 3kHz for the N95 mask, and above 5kHz in surgical and cloth masks. Measures of timing and spectral tilt mainly differed with N95 mask use. Cepstral and harmonics to noise ratios remained unchanged across mask type. No differences were observed across conditions for word or sentence intelligibility measures; however, accuracy of word and sentence translations were affected by all masks. Data presented in this study show that face masks change the speech signal, but some specific acoustic features remain largely unaffected (e.g., measures of voice quality) irrespective of mask type. Outcomes have bearing on how future speech studies are run when personal protective equipment is worn.
C1 [Magee, Michelle; Lewis, Courtney; Noffs, Gustavo; Reece, Hannah; Chan, Jess C. S.; Zaga, Charissa J.; Paynter, Camille; Birchall, Olga; Azocar, Sandra Rojas; Ediriweera, Angela; Kenyon, Katherine; Caverle, Marja W.; Schultz, Benjamin G.; Vogel, Adam P.] Univ Melbourne, Ctr Neurosci Speech, 550 Swanston St, Carlton, Vic 3053, Australia.
   [Magee, Michelle; Lewis, Courtney; Vogel, Adam P.] Redenlab, 669-585 Little Collins St, Melbourne, Vic 3000, Australia.
RP Magee, M (corresponding author), Univ Melbourne, Ctr Neurosci Speech, 550 Swanston St, Carlton, Vic 3053, Australia.
OI Caverle, Marja/0000-0003-4877-0269
FU University of Melbourne, AustraliaUniversity of Melbourne; National
   Health and Medical Research Council (Australia) FellowshipNational
   Health and Medical Research Council of Australia [10135683]; National
   Health and Medical Research Council (Australia)/Motor Neuron Disease
   Research Australia postgraduate scholarshipNational Health and Medical
   Research Council of Australia [1133541]; Australian Postgraduate
   Research Scholarships
FX This work received institutional support from The University of
   Melbourne, Australia. A.P.V. holds a National Health and Medical
   Research Council (Australia) Fellowship (#10135683). M.M., C.L., H.R.,
   and G.N. contributed equally to this work. C.L., G.N., O.B., and M.C.
   are supported by Australian Postgraduate Research Scholarships. C.P. is
   funded by a joint National Health and Medical Research Council
   (Australia)/Motor Neuron Disease Research Australia postgraduate
   scholarship (#1133541). We thank Sam Peterson, Jack Peterson, and
   Michael Reece for their help in data collection.
CR Asadi S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38808-z
   Bahl P, 2020, THORAX, V75, P1024, DOI 10.1136/thoraxjnl-2020-215748
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Centers for Disease Control and Prevention, 2020, US MASKS HELP SLOW S
   Chu DK, 2020, LANCET, V395, P1973, DOI 10.1016/S0140-6736(20)31142-9
   Corey RM, 2020, J ACOUST SOC AM, V148, P2371, DOI 10.1121/10.0002279
   Goldin A, 2020, HEAR REV, V27, P8
   Hampton T., 2020, SPEECH DISCRIMINATIO, DOI [10.22541/au.159050338.83886289, DOI 10.22541/AU.159050338.83886289]
   O'Dowd K, 2020, MATERIALS, V13, DOI 10.3390/ma13153363
   R Development Core Team, 2020, R LANG ENV STAT COMP
   Redenlab, 2020, GUID MIN RISK PAT ST
   Rosen K, 2010, CLIN LINGUIST PHONET, V24, P141, DOI 10.3109/02699200903440983
   Stadnytskyi V, 2020, P NATL ACAD SCI USA, V117, P11875, DOI 10.1073/pnas.2006874117
   Van Riper C., 1963, SPEECH CORRECTION
   Vogel AP, 2017, NEUROLOGY, V89, P837, DOI 10.1212/WNL.0000000000004248
   Vogel AP, 2009, BEHAV RES METHODS, V41, P318, DOI 10.3758/BRM.41.2.318
   Yorkston K. M., 1984, ASSESSMENT INTELLIGI
   Zaga CJ, 2020, AM J SPEECH-LANG PAT, V29, P1320, DOI 10.1044/2020_AJSLP-20-00089
NR 18
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD DEC
PY 2020
VL 148
IS 6
BP 3562
EP 3568
DI 10.1121/10.0002873
PG 7
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA PH0UA
UT WOS:000600137800003
PM 33379897
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Kothare, H
   Raharjo, I
   Ramanarayanan, V
   Ranasinghe, K
   Parrell, B
   Johnson, K
   Houde, JF
   Nagarajan, SS
AF Kothare, Hardik
   Raharjo, Inez
   Ramanarayanan, Vikram
   Ranasinghe, Kamalini
   Parrell, Benjamin
   Johnson, Keith
   Houde, John F.
   Nagarajan, Srikantan S.
TI Sensorimotor adaptation of speech depends on the direction of auditory
   feedback alteration
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID VOWEL-LENGTH; COMPENSATION; PITCH; RESPONSES; TESTS; FREQUENCY;
   DURATION; FIT
AB A hallmark feature of speech motor control is its ability to learn to anticipate and compensate for persistent feedback alterations, a process referred to as sensorimotor adaptation. Because this process involves adjusting articulation to counter the perceived effects of altering acoustic feedback, there are a number of factors that affect it, including the complex relationship between acoustics and articulation and non-uniformities of speech perception. As a consequence, sensorimotor adaptation is hypothesised to vary as a function of the direction of the applied auditory feedback alteration in vowel formant space. This hypothesis was tested in two experiments where auditory feedback was altered in real time, shifting the frequency values of the first and second formants (F1 and F2) of participants' speech. Shifts were designed on a subject-by-subject basis and sensorimotor adaptation was quantified with respect to the direction of applied shift, normalised for individual speakers. Adaptation was indeed found to depend on the direction of the applied shift in vowel formant space, independent of shift magnitude. These findings have implications for models of sensorimotor adaptation of speech.
C1 [Kothare, Hardik; Raharjo, Inez] Univ Calif San Francisco, UC Berkeley UCSF Grad Program Bioengn, San Francisco, CA 94143 USA.
   [Ramanarayanan, Vikram] Educ Testing Serv R&D, San Francisco, CA 94105 USA.
   [Ranasinghe, Kamalini] Univ Calif San Francisco, Dept Neurol, San Francisco, CA 94143 USA.
   [Parrell, Benjamin] Univ Wisconsin Madison, Dept Commun Sci & Disorders, Madison, WI 53715 USA.
   [Johnson, Keith] Univ Calif Berkeley, Dept Linguist, Berkeley, CA 94720 USA.
   [Houde, John F.] Univ Calif San Francisco, Dept Otolaryngol Head & Neck Surg, San Francisco, CA 94143 USA.
   [Nagarajan, Srikantan S.] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, San Francisco, CA 94143 USA.
RP Kothare, H (corresponding author), Univ Calif San Francisco, UC Berkeley UCSF Grad Program Bioengn, San Francisco, CA 94143 USA.
EM hardik.kothare@ucsf.edu
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01DC010145,
   R01DC013979]; National Science FoundationNational Science Foundation
   (NSF); BCS [1262297]; UCSF Discovery Fellows Program
FX The authors would like to thank Danielle Mizuiri for help with study
   coordination and Zarinah Agnew and Megan Thompson for their assistance
   in subject recruitment. This work was supported by the National
   Institutes of Health Grant Nos. R01DC010145 and R01DC013979, National
   Science Foundation Grant No. BCS 1262297 and the UCSF Discovery Fellows
   Program.
CR Behroozmand R, 2012, J ACOUST SOC AM, V132, P2468, DOI 10.1121/1.4746984
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Berens P, 2009, J STAT SOFTW, V31, P1, DOI 10.18637/jss.v031.i10
   Bourguignon Nicolas J, 2014, Front Hum Neurosci, V8, P208, DOI 10.3389/fnhum.2014.00208
   Burnett TA, 1998, J ACOUST SOC AM, V103, P3153, DOI 10.1121/1.423073
   Caudrelier T., 2019, CHANGES SPEECH PRODU
   Cremers J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02040
   Daliri A, 2019, J NEUROPHYSIOL, V122, P552, DOI 10.1152/jn.00662.2018
   Fairbanks G, 1954, J SPEECH HEAR DISORD, V19, P133, DOI 10.1044/jshd.1902.133
   Fant G., 1960, ACOUSTIC THEORY SPEE
   Gick B., 2013, ARTICULATORY PHONETI
   Greenwood DD, 1997, HEARING RES, V103, P199, DOI 10.1016/S0378-5955(96)00175-X
   Guenther FH, 2016, NEURAL CONTROL OF SPEECH, P1, DOI 10.7551/mitpress/10471.001.0001
   Hall-Lew L, 2010, LANG LINGUIST COMPAS, V4, P458, DOI 10.1111/j.1749-818x.2010.00207.x
   Harrison D., 1988, J APPL STAT, V15, P197, DOI DOI 10.1080/02664768800000026
   HARSHMAN R, 1977, J ACOUST SOC AM, V62, P693, DOI 10.1121/1.381581
   Hillenbrand JM, 2000, J ACOUST SOC AM, V108, P3013, DOI 10.1121/1.1323463
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213
   Houde JF, 2002, J COGNITIVE NEUROSCI, V14, P1125, DOI 10.1162/089892902760807140
   Houde JF, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00082
   HOUSE AS, 1953, J ACOUST SOC AM, V25, P105, DOI 10.1121/1.1906982
   HOUSE AS, 1961, J ACOUST SOC AM, V33, P1174, DOI 10.1121/1.1908941
   Johnson K., 2018, 14 UC BERK PHONLAB
   Johnson K., 2012, ACOUSTIC AUDITORY PH
   Jones JA, 2000, J ACOUST SOC AM, V108, P1246, DOI 10.1121/1.1288414
   Katseff S, 2012, LANG SPEECH, V55, P295, DOI 10.1177/0023830911417802
   Kitago T, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00307
   KLUENDER KR, 1988, J PHONETICS, V16, P153, DOI 10.1016/S0095-4470(19)30480-2
   Korzyukov O, 2017, NEUROPSYCHOLOGIA, V101, P106, DOI 10.1016/j.neuropsychologia.2017.04.035
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Lametti DR, 2018, CURR BIOL, V28, P3106, DOI 10.1016/j.cub.2018.07.030
   Lametti DR, 2012, J NEUROSCI, V32, P9351, DOI 10.1523/JNEUROSCI.0404-12.2012
   LEE BS, 1950, J ACOUST SOC AM, V22, P639, DOI 10.1121/1.1906665
   Levelt W. J., 1993, SPEAKING INTENTION A
   LEVELT WJM, 1983, COGNITION, V14, P41, DOI 10.1016/0010-0277(83)90026-4
   Littell R.C., 2006, SAS MIXED MODELS
   LOCKHART RA, 1985, BIOMETRIKA, V72, P647, DOI 10.2307/2336737
   Mardia KV., 2009, DIRECTIONAL STAT
   Mitsuya T, 2015, J ACOUST SOC AM, V138, P413, DOI 10.1121/1.4923154
   Mitsuya T, 2013, J ACOUST SOC AM, V133, P2993, DOI 10.1121/1.4795786
   Niziolek CA, 2013, J NEUROSCI, V33, P12090, DOI 10.1523/JNEUROSCI.1008-13.2013
   O'Shaughnessy D., 1987, SPEECH COMMUNICATION
   Parrell B, 2019, PLOS COMPUT BIOL, V15, DOI 10.1371/journal.pcbi.1007321
   Perrier P., 2007, ARXIV07091405
   Pisoni DB, 2005, BLACKW HBK LINGUIST, P1, DOI 10.1002/9780470757024
   Purcell DW, 2006, J ACOUST SOC AM, V120, P966, DOI 10.1121/1.2217714
   QUATIERI TF, 1986, IEEE T ACOUST SPEECH, V34, P1449, DOI 10.1109/TASSP.1986.1164985
   Rositzke HA, 1939, LANGUAGE, V15, P99, DOI 10.2307/408728
   SAVARIAUX C, 1995, J ACOUST SOC AM, V98, P2428, DOI 10.1121/1.413277
   Schuerman WL, 2017, J ACOUST SOC AM, V141, P2693, DOI 10.1121/1.4979791
   Shiller DM, 2009, J ACOUST SOC AM, V125, P1103, DOI 10.1121/1.3058638
   Stevens K. N., 1968, THESIS
   STEVENS KN, 1989, J PHONETICS, V17, P3, DOI 10.1016/S0095-4470(19)31520-7
   STEVENS KN, 1955, J ACOUST SOC AM, V27, P484, DOI 10.1121/1.1907943
   Stevens KN, 1998, ACOUSTIC PHONETICS
   Subramaniam K, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00082
   Takano S, 2007, SPEECH COMMUN, V49, P49, DOI 10.1016/j.specom.2006.09.004
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   von Mises R, 1918, PHYS Z, V19, P490
   WATSON GS, 1961, BIOMETRIKA, V48, P109, DOI 10.2307/2333135
   WATSON GS, 1956, BIOMETRIKA, V43, P344, DOI 10.2307/2332913
   Wells J. C., 1962, THESIS
   Wells J. C., 1990, STUDIES PRONUNCIATIO, P76
NR 63
TC 0
Z9 0
U1 2
U2 2
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD DEC
PY 2020
VL 148
IS 6
BP 3682
EP 3697
DI 10.1121/10.0002876
PG 16
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA PH0UR
UT WOS:000600139500002
PM 33379892
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Nault, DR
   Munhall, KG
AF Nault, Daniel R.
   Munhall, Kevin G.
TI Individual variability in auditory feedback processing: Responses to
   real-time formant perturbations and their relation to perceptual acuity
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SENSORIMOTOR ADAPTATION; SPEECH; COMPENSATION; NOISE; REPRESENTATION;
   CATEGORIES; LANGUAGE; HEARING
AB In this study, both between-subject and within-subject variability in speech perception and speech production were examined in the same set of speakers. Perceptual acuity was determined using an ABX auditory discrimination task, whereby speakers made judgments between pairs of syllables on a // to /ae/ acoustic continuum. Auditory feedback perturbations of the first two formants were implemented in a production task to obtain measures of compensation, normal speech production variability, and vowel spacing. Speakers repeated the word "head" 120 times under varying feedback conditions, with the final Hold phase involving the strongest perturbations of +240Hz in F1 and -300Hz in F2. Multiple regression analyses were conducted to determine whether individual differences in compensatory behavior in the Hold phase could be predicted by perceptual acuity, speech production variability, and vowel spacing. Perceptual acuity significantly predicted formant changes in F1, but not in F2. These results are discussed in consideration of the importance of using larger sample sizes in the field and developing new methods to explore feedback processing at the individual participant level. The potential positive role of variability in speech motor control is also considered.
C1 [Nault, Daniel R.; Munhall, Kevin G.] Queens Univ, Dept Psychol, Humphrey Hall,62 Arch St, Kingston, ON K7L 3N6, Canada.
   [Nault, Daniel R.; Munhall, Kevin G.] Queens Univ, Kingston, ON K7L 3N6, Canada.
RP Nault, DR (corresponding author), Queens Univ, Dept Psychol, Humphrey Hall,62 Arch St, Kingston, ON K7L 3N6, Canada.
EM 14drn1@queensu.ca
FU Natural Science and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)
FX This research was supported by the Natural Science and Engineering
   Research Council of Canada. The authors would like to thank Dr. Ewen
   MacDonald for sharing his data for reanalysis and for use in Fig. 1. The
   authors also acknowledge Yifei Yin's help with programming assistance in
   data analysis.
CR Abstracts from The Academy of Breastfeeding Medicine, 2015, BREASTFEED MED, V10, pS1, DOI DOI 10.1371/JOURNAL.PONE.0129731
   [Anonymous], 2012, REGEN MED S3, V7, pS14, DOI DOI 10.1371/JOURNAL.PONE.0041830
   [Anonymous], 2015, IEEE T IMAGE PROCESS, V24, DOI DOI 10.1044/2014_AJSLP-13-0148
   [Anonymous], 2016, DETERMINATION WATER, V89, P1, DOI DOI 10.1016/J.JML.2016.03.002
   [Anonymous], 2019, PRION S1, V13, P1, DOI [10.1080/19336896.2019.1615197, DOI 10.1080/19336896.2019.1615197]
   Bauer JJ, 2006, J ACOUST SOC AM, V119, P2363, DOI 10.1121/1.2173513
   Berisha V, 2014, J ACOUST SOC AM, V135, P421, DOI 10.1121/1.4829528
   Cooper A, 2018, COGNITION, V173, P16, DOI 10.1016/j.cognition.2017.12.013
   COWIE R, 1982, J LARYNGOL OTOL, V96, P101, DOI 10.1017/S002221510009229X
   Dhawale AK, 2019, CURR BIOL, V29, P3551, DOI 10.1016/j.cub.2019.08.052
   Dhawale AK, 2017, ANNU REV NEUROSCI, V40, P479, DOI 10.1146/annurev-neuro-072116-031548
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   ESTES WK, 1956, PSYCHOL BULL, V53, P134, DOI 10.1037/h0045156
   Feng YQ, 2011, J NEUROPHYSIOL, V106, P667, DOI 10.1152/jn.00638.2010
   Franken MK, 2017, J ACOUST SOC AM, V142, P2007, DOI 10.1121/1.5006899
   Fuchs RK, 2019, WOODH PUBL SER BIOM, P15, DOI 10.1016/B978-0-08-102451-5.00002-0
   Ghosh SS, 2010, J ACOUST SOC AM, V128, P3079, DOI 10.1121/1.3493430
   Girdhar A, 2018, IET IMAGE PROCESS, V12, P1, DOI 10.1049/iet-ipr.2017.0162
   Guenther FH, 2004, J SPEECH LANG HEAR R, V47, P46, DOI 10.1044/1092-4388(2004/005)
   GUENTHER FH, 1995, PSYCHOL REV, V102, P594, DOI 10.1037/0033-295X.102.3.594
   Harris CM, 1998, NATURE, V394, P780, DOI 10.1038/29528
   Heathcote A, 2000, PSYCHON B REV, V7, P185, DOI 10.3758/BF03212979
   Hopp J, 2004, PROG NEUROBIOL, V72, P27, DOI 10.1016/j.pneurobio.2003.12.002
   Houde J. F., 1997, THESIS
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213
   HOWELL P, 1984, PERCEPT PSYCHOPHYS, V36, P296, DOI 10.3758/BF03206371
   Katseff S, 2012, LANG SPEECH, V55, P295, DOI 10.1177/0023830911417802
   Klein E., 2019, P INT 2019 SEPT 15 1, P899
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Lametti DR, 2018, CURR BIOL, V28, P3106, DOI 10.1016/j.cub.2018.07.030
   Lametti DR, 2012, J NEUROSCI, V32, P9351, DOI 10.1523/JNEUROSCI.0404-12.2012
   LANE H, 1971, J SPEECH HEAR RES, V14, P677, DOI 10.1044/jshr.1404.677
   LEE BS, 1950, J ACOUST SOC AM, V22, P824, DOI 10.1121/1.1906696
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Lombard E., 1911, ANN MALADIES OREILLE, V37, P101
   MacDonald EN, 2011, J ACOUST SOC AM, V129, P955, DOI 10.1121/1.3531932
   MacDonald EN, 2010, J ACOUST SOC AM, V127, P1059, DOI 10.1121/1.3278606
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   Mitsuya T, 2015, J ACOUST SOC AM, V138, P413, DOI 10.1121/1.4923154
   Mitsuya T, 2013, J ACOUST SOC AM, V133, P2993, DOI 10.1121/1.4795786
   Mitsuya T, 2011, J ACOUST SOC AM, V130, P2978, DOI 10.1121/1.3643826
   Munhall KG, 2009, J ACOUST SOC AM, V125, P384, DOI 10.1121/1.3035829
   Murre JMJ, 2011, PSYCHON B REV, V18, P592, DOI 10.3758/s13423-011-0076-y
   NEAREY TM, 1989, J ACOUST SOC AM, V85, P2088, DOI 10.1121/1.397861
   Niziolek CA, 2013, J NEUROSCI, V33, P12090, DOI 10.1523/JNEUROSCI.1008-13.2013
   OLLER DK, 1988, CHILD DEV, V59, P441, DOI 10.1111/j.1467-8624.1988.tb01479.x
   Orfanidis S. J., 1988, OPTIMUM SIGNAL PROCE
   Perkell J. S., 2008, P 8 INT SEM SPEECH P, P29
   Perkell JS, 2012, J NEUROLINGUIST, V25, P382, DOI 10.1016/j.jneuroling.2010.02.011
   Perkell JS, 2004, J ACOUST SOC AM, V116, P2338, DOI 10.1121/1.1787524
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   PICK HL, 1989, J ACOUST SOC AM, V85, P894, DOI 10.1121/1.397561
   Polka L, 2003, SPEECH COMMUN, V41, P221, DOI 10.1016/S0167-6393(02)00105-X
   Purcell DW, 2006, J ACOUST SOC AM, V120, P966, DOI 10.1121/1.2217714
   Shadle CH, 2016, J ACOUST SOC AM, V139, P713, DOI 10.1121/1.4940665
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Stein RB, 2005, NAT REV NEUROSCI, V6, P389, DOI 10.1038/nrn1668
   Sternad D, 2018, CURR OPIN BEHAV SCI, V20, P183, DOI 10.1016/j.cobeha.2018.01.004
   Story BH, 2017, J ACOUST SOC AM, V141, pEL458, DOI 10.1121/1.4983342
   Uitterhoeve RJ, 2004, BRIT J CANCER, V91, P1050, DOI 10.1038/sj.bjc.6602103
   Villacorta VM, 2007, J ACOUST SOC AM, V122, P2306, DOI 10.1121/1.2773966
   Weismer G, 2000, FOLIA PHONIATR LOGO, V52, P201, DOI 10.1159/000021536
   YATES AJ, 1963, PSYCHOL BULL, V60, P213, DOI 10.1037/h0044155
   2019, FRONT PLANT SCI, V10, P1, DOI DOI 10.3389/FPSYG.2019.00658
NR 65
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD DEC
PY 2020
VL 148
IS 6
BP 3709
EP 3721
DI 10.1121/10.0002923
PG 13
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA PH0UR
UT WOS:000600139500004
PM 33379900
OA Other Gold
DA 2021-02-24
ER

PT J
AU Swanborough, H
   Staib, M
   Fruhholz, S
AF Swanborough, Huw
   Staib, Matthias
   Fruhholz, Sascha
TI Neurocognitive dynamics of near-threshold voice signal detection and
   affective voice evaluation
SO SCIENCE ADVANCES
LA English
DT Article
ID AUDITORY-CORTEX; HUMAN AMYGDALA; ACOUSTIC FEATURES; SPEECH-PERCEPTION;
   SOUND; ACTIVATION; MECHANISMS; SYSTEM; REPRESENTATION; ORGANIZATION
AB Communication and voice signal detection in noisy environments are universal tasks for many species. The fundamental problem of detecting voice signals in noise (VIN) is underinvestigated especially in its temporal dynamic properties. We investigated VIN as a dynamic signal-to-noise ratio (SNR) problem to determine the neurocognitive dynamics of subthreshold evidence accrual and near-threshold voice signal detection. Experiment 1 showed that dynamic VIN, including a varying SNR and subthreshold sensory evidence accrual, is superior to similar conditions with nondynamic SNRs or with acoustically matched sounds. Furthermore, voice signals with affective meaning have a detection advantage during VIN. Experiment 2 demonstrated that VIN is driven by an effective neural integration in an auditory cortical-limbic network at and beyond the near-threshold detection point, which is preceded by activity in subcortical auditory nuclei. This demonstrates the superior recognition advantage of communication signals in dynamic noise contexts, especially when carrying socio-affective meaning.
C1 [Swanborough, Huw; Staib, Matthias; Fruhholz, Sascha] Univ Zurich, Dept Psychol, Cognit & Affect Neurosci Unit, Zurich, Switzerland.
   [Swanborough, Huw; Staib, Matthias; Fruhholz, Sascha] Univ Zurich, Neurosci Ctr Zurich, Zurich, Switzerland.
   [Swanborough, Huw; Staib, Matthias; Fruhholz, Sascha] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Fruhholz, Sascha] Univ Oslo, Dept Psychol, Oslo, Norway.
RP Swanborough, H; Fruhholz, S (corresponding author), Univ Zurich, Dept Psychol, Cognit & Affect Neurosci Unit, Zurich, Switzerland.; Swanborough, H; Fruhholz, S (corresponding author), Univ Zurich, Neurosci Ctr Zurich, Zurich, Switzerland.; Swanborough, H; Fruhholz, S (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.; Fruhholz, S (corresponding author), Univ Oslo, Dept Psychol, Oslo, Norway.
EM huw.swanborough@uzh.ch; sascha.fruehholz@uzh.ch
OI Swanborough, Huw/0000-0002-5530-0583
FU Swiss National Science FoundationSwiss National Science Foundation
   (SNSF)European Commission [SNSF PP00P1_157409/1, PP00P1_183711/1]
FX The study was supported by the Swiss National Science Foundation (SNSF
   PP00P1_157409/1 and PP00P1_183711/1 to S.F.).
CR Bendixen A, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00060
   Bigand E, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027024
   Bizley JK, 2013, NAT REV NEUROSCI, V14, P693, DOI 10.1038/nrn3565
   Blackford JU, 2010, NEUROIMAGE, V50, P1188, DOI 10.1016/j.neuroimage.2009.12.083
   Bouton S, 2018, P NATL ACAD SCI USA, V115, pE1299, DOI 10.1073/pnas.1714279115
   Bronkhorst AW, 2015, ATTEN PERCEPT PSYCHO, V77, P1465, DOI 10.3758/s13414-015-0882-9
   Capilla A, 2013, CEREB CORTEX, V23, P1388, DOI 10.1093/cercor/bhs119
   Chennu S, 2016, J NEUROSCI, V36, P8305, DOI 10.1523/JNEUROSCI.1125-16.2016
   De Lucia M, 2012, NEUROIMAGE, V60, P1704, DOI 10.1016/j.neuroimage.2012.01.131
   Dyson BJ, 2004, J ACOUST SOC AM, V115, P280, DOI 10.1121/1.1631945
   Ethofer T, 2012, CEREB CORTEX, V22, P191, DOI 10.1093/cercor/bhr113
   Evans S, 2014, CEREB CORTEX, V24, P2350, DOI 10.1093/cercor/bht083
   Fishman YI, 2004, J ACOUST SOC AM, V116, P1656, DOI 10.1121/1.1778903
   Friston KJ, 2003, NEUROIMAGE, V19, P1273, DOI 10.1016/S1053-8119(03)00202-7
   Fruhholz S, 2017, NEUROSCI BIOBEHAV R, V83, P516, DOI 10.1016/j.neubiorev.2017.09.009
   Fruhholz S, 2015, P NATL ACAD SCI USA, V112, P1583, DOI 10.1073/pnas.1411315112
   Fruhholz S, 2014, PROG NEUROBIOL, V123, P1, DOI 10.1016/j.pneurobio.2014.09.003
   Fruhholz S, 2013, CORTEX, V49, P1394, DOI 10.1016/j.cortex.2012.08.003
   Fruhholz S, 2012, CEREB CORTEX, V22, P1107, DOI 10.1093/cercor/bhr184
   Fruhholz S, 2016, SOC COGN AFFECT NEUR, V11, P1638, DOI 10.1093/scan/nsw066
   Fruhholz S, 2016, NEUROSCI BIOBEHAV R, V68, P96, DOI 10.1016/j.neubiorev.2016.05.002
   Gao PP, 2014, NEUROIMAGE, V91, P220, DOI 10.1016/j.neuroimage.2014.01.043
   Griffiths TD, 2004, NAT REV NEUROSCI, V5, P887, DOI 10.1038/nrn1538
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hwang JH, 2007, AUDIOL NEURO-OTOL, V12, P285, DOI 10.1159/000103209
   Hwang JH, 2006, ACTA OTO-LARYNGOL, V126, P916, DOI 10.1080/00016480500546375
   JAVITT DC, 1994, BRAIN RES, V667, P192, DOI 10.1016/0006-8993(94)91496-6
   Kumar S, 2007, PLOS COMPUT BIOL, V3, P977, DOI 10.1371/journal.pcbi.0030100
   Kumar S, 2012, J NEUROSCI, V32, P14184, DOI 10.1523/JNEUROSCI.1759-12.2012
   Lamm C, 2010, BRAIN STRUCT FUNCT, V214, P579, DOI 10.1007/s00429-010-0251-3
   Mandel MI, 2016, J ACOUST SOC AM, V140, P2542, DOI 10.1121/1.4964102
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Mihai PG, 2019, ELIFE, V8, DOI 10.7554/eLife.44837
   Molholm S, 2005, CEREB CORTEX, V15, P545, DOI 10.1093/cercor/bhh155
   O'Connell RG, 2012, NAT NEUROSCI, V15, P1729, DOI 10.1038/nn.3248
   Obleser J, 2007, J NEUROSCI, V27, P2283, DOI 10.1523/JNEUROSCI.4663-06.2007
   Ousdal OT, 2008, NEUROSCIENCE, V156, P450, DOI 10.1016/j.neuroscience.2008.07.066
   Pannese A, 2016, CORTEX, V85, P116, DOI 10.1016/j.cortex.2016.10.013
   Pannese A, 2015, HEARING RES, V328, P67, DOI 10.1016/j.heares.2015.07.003
   Patel S, 2011, BIOL PSYCHOL, V87, P93, DOI 10.1016/j.biopsycho.2011.02.010
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Pernet CR, 2015, NEUROIMAGE, V119, P164, DOI 10.1016/j.neuroimage.2015.06.050
   Salvi RJ, 2002, HEARING RES, V170, P96, DOI 10.1016/S0378-5955(02)00386-6
   Sander D, 2003, REV NEUROSCIENCE, V14, P303, DOI 10.1515/REVNEURO.2003.14.4.303
   Schomers MR, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00435
   Scott SK, 2004, J ACOUST SOC AM, V115, P813, DOI 10.1121/1.1639336
   Scott SK, 2013, HEARING RES, V303, P58, DOI 10.1016/j.heares.2013.05.001
   Scott SK, 2009, J ACOUST SOC AM, V125, P1737, DOI 10.1121/1.3050255
   Shamma SA, 2011, TRENDS NEUROSCI, V34, P114, DOI 10.1016/j.tins.2010.11.002
   Sohn J, 1999, IEEE SIGNAL PROC LET, V6, P1, DOI 10.1109/97.736233
   Stephan KE, 2010, NEUROIMAGE, V49, P3099, DOI 10.1016/j.neuroimage.2009.11.015
   Tang Y, 2016, INTERSPEECH, P2488, DOI 10.21437/Interspeech.2016-14
   Tang Y, 2016, J ACOUST SOC AM, V140, P1858, DOI 10.1121/1.4962484
   Vouloumanos A, 2001, J COGNITIVE NEUROSCI, V13, P994, DOI 10.1162/089892901753165890
   Wiley RH, 2013, ANIMAL COMMUNICATION THEORY: INFORMATION AND INFLUENCE, P113
   Wong PCM, 2008, J SPEECH LANG HEAR R, V51, P1026, DOI 10.1044/1092-4388(2008/075)
NR 56
TC 0
Z9 0
U1 0
U2 0
PU AMER ASSOC ADVANCEMENT SCIENCE
PI WASHINGTON
PA 1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA
SN 2375-2548
J9 SCI ADV
JI Sci. Adv.
PD DEC
PY 2020
VL 6
IS 50
AR eabb3884
DI 10.1126/sciadv.abb3884
PG 11
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA PG7HZ
UT WOS:000599903600006
PM 33310844
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Sarrett, ME
   McMurray, B
   Kapnoula, EC
AF Sarrett, McCall E.
   McMurray, Bob
   Kapnoula, Efthymia C.
TI Dynamic EEG analysis during language comprehension reveals interactive
   cascades between perceptual processing and sentential expectations
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Electroencephalography; Speech perception; N100; N400; Semantic
   integration; Top-down effects; Predictive coding
ID SPEECH-PERCEPTION; PHONETIC CATEGORIES; INTERNAL STRUCTURE; WORD
   RECOGNITION; INFORMATION; DISTINCTION; IMPAIRMENT; MORPHOLOGY; REFLECT;
   CONTEXT
AB Understanding spoken language requires analysis of the rapidly unfolding speech signal at multiple levels: acoustic, phonological, and semantic. However, there is not yet a comprehensive picture of how these levels relate. We recorded electroencephalography (EEG) while listeners (N = 31) heard sentences in which we manipulated acoustic ambiguity (e.g., a bees/peas continuum) and sentential expectations (e.g., Honey is made by bees). EEG was analyzed with a mixed effects model over time to quantify how language processing cascades proceed on a millisecond-by-millisecond basis. Our results indicate: (1) perceptual processing and memory for fine-grained acoustics is preserved in brain activity for up to 900 msec; (2) contextual analysis begins early and is graded with respect to the acoustic signal; and (3) top-down predictions influence perceptual processing in some cases, however, these predictions are available simultaneously with the veridical signal. These mechanistic in-sights provide a basis for a better understanding of the cortical language network.
C1 [Sarrett, McCall E.] Univ Iowa, Interdisciplinary Grad Program Neurosci, 356 Med Res Ctr, Iowa City, IA 52242 USA.
   [McMurray, Bob; Kapnoula, Efthymia C.] Univ Iowa, Dept Psychol & Brain Sci, W311 Seashore Hall, Iowa City, IA 52242 USA.
   [Kapnoula, Efthymia C.] Basque Ctr Cognit Brain & Language, Mikeletegi Pasealekua 69, Donostia San Sebastian 20009, Gipuzkoa, Spain.
RP Sarrett, ME (corresponding author), Univ Iowa, Interdisciplinary Grad Program Neurosci, 356 Med Res Ctr, Iowa City, IA 52242 USA.
EM mccall-sarrett@uiowa.edu
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [DC008089]; Basque GovernmentBasque
   Government; Spanish State Research Agency through BCBL Severo Ochoa
   excellence accreditation [SEV-2015-0490]; Spanish Ministry of Economy
   and Competitiveness (MINECO) [FJCI-2016-28019]
FX This work was supported by NIH grant DC008089 awarded to BM. This work
   was partially supported by the Basque Government through the BERC
   2018-2021 program and by the Spanish State Research Agency through BCBL
   Severo Ochoa excellence accreditation SEV-2015-0490, as well as by a
   postdoctoral grant from the Spanish Ministry of Economy and
   Competitiveness (MINECO; reference FJCI-2016-28019), awarded to EK. We
   would like to thank Thomas Farmer for helpful discussions and advice
   during the development of the experiment.
CR Allen JS, 2003, J ACOUST SOC AM, V113, P544, DOI 10.1121/1.1528172
   Allen JS, 2001, PERCEPT PSYCHOPHYS, V63, P798, DOI 10.3758/BF03194439
   ANDRUSKI JE, 1994, COGNITION, V52, P163, DOI 10.1016/0010-0277(94)90042-6
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Blank H, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002577
   Boersma P., 2006, PRAAT DOING PHONETIC
   Broderick M. P., 2019, J NEUROSCI
   Broderick MP, 2018, CURR BIOL, V28, P803, DOI 10.1016/j.cub.2018.01.080
   Brown-Schmidt S, 2017, LANG COGN NEUROSCI, V32, P1211, DOI 10.1080/23273798.2017.1325508
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   CONNINE CM, 1991, J MEM LANG, V30, P234, DOI 10.1016/0749-596X(91)90005-5
   Dahan D, 2004, J EXP PSYCHOL LEARN, V30, P498, DOI 10.1037/0278-7393.30.2.498
   Ettinger A, 2014, BRAIN LANG, V129, P14, DOI 10.1016/j.bandl.2013.11.004
   Firestone C, 2016, BEHAV BRAIN SCI, P39
   Friedman D, 2001, NEUROSCI BIOBEHAV R, V25, P355, DOI 10.1016/S0149-7634(01)00019-7
   Frye RE, 2007, J COGNITIVE NEUROSCI, V19, P1476, DOI 10.1162/jocn.2007.19.9.1476
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Gaskell MG, 1999, COGNITIVE SCI, V23, P439
   Gauthier B, 2007, COGNITION, V103, P80, DOI 10.1016/j.cognition.2006.03.002
   Getz L., 2019, PSYCHOL SCI
   Gow DW, 2016, LANG COGN NEUROSCI, V31, P841, DOI 10.1080/23273798.2015.1029498
   Gwilliams L, 2018, J NEUROSCI, V38, P7585, DOI 10.1523/JNEUROSCI.0065-18.2018
   Hauk O, 2006, NEUROIMAGE, V30, P1383, DOI 10.1016/j.neuroimage.2005.11.048
   Herrmann M., 1995, PERCEPTUAL MAGNET EF
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Kapnoula EC, 2017, J EXP PSYCHOL HUMAN, V43, P1594, DOI 10.1037/xhp0000410
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Lupyan G, 2015, CURR DIR PSYCHOL SCI, V24, P279, DOI 10.1177/0963721415570732
   Magnuson JS, 2003, COGNITIVE SCI, V27, P285, DOI 10.1016/S0364-0213(03)00004-1
   Malmierca M.S., 2010, OXFORD HDB AUDITORY, V2, P9
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Maye J, 2008, DEVELOPMENTAL SCI, V11, P122, DOI 10.1111/j.1467-7687.2007.00653.x
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   McMurray B, 2010, COGNITIVE PSYCHOL, V60, P1, DOI 10.1016/j.cogpsych.2009.06.003
   McMurray B, 2009, J MEM LANG, V60, P65, DOI 10.1016/j.jml.2008.07.002
   McQueen JM, 2016, LANG COGN NEUROSCI, V31, P860, DOI 10.1080/23273798.2016.1154975
   McQueen JM, 2003, COGNITIVE SCI, V27, P795, DOI 10.1016/S0364-0213(03)00069-7
   Miller JL, 1997, LANG COGNITIVE PROC, V12, P865, DOI 10.1080/016909697386754
   MILLER JL, 1984, PERCEPT PSYCHOPHYS, V36, P329, DOI 10.3758/BF03202785
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   Oleson JJ, 2017, STAT METHODS MED RES, V26, P2708, DOI 10.1177/0962280215607411
   Pereira O., 2018, AUDITORY PERCEPTION, V1, P112
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   Port R, 2007, NEW IDEAS PSYCHOL, V25, P143, DOI 10.1016/j.newideapsych.2007.02.001
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580
   Robertson EK, 2009, DEVELOPMENTAL SCI, V12, P753, DOI 10.1111/j.1467-7687.2009.00806.x
   Salminen NH, 2009, COGN AFFECT BEHAV NE, V9, P304, DOI 10.3758/CABN.9.3.304
   Seedorff M., MAYBE MAXIMAL UNPUB
   Seedorff M, 2018, J MEM LANG, V102, P55, DOI 10.1016/j.jml.2018.05.004
   Sharma A, 2000, J ACOUST SOC AM, V108, P3030, DOI 10.1121/1.1320474
   Szostak CM, 2013, ATTEN PERCEPT PSYCHO, V75, P1533, DOI 10.3758/s13414-013-0492-3
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Tomblin JB, 1997, J SPEECH LANG HEAR R, V40, P1245, DOI 10.1044/jslhr.4006.1245
   Toscano JC, 2010, PSYCHOL SCI, V21, P1532, DOI 10.1177/0956797610384142
   Vandewalle E, 2012, RES DEV DISABIL, V33, P635, DOI 10.1016/j.ridd.2011.11.005
   WERKER JF, 1987, CAN J PSYCHOL, V41, P48, DOI 10.1037/h0084150
   Zellou G, 2019, J PHONETICS, V76, DOI 10.1016/j.wocn.2019.06.001
NR 63
TC 0
Z9 0
U1 4
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD DEC
PY 2020
VL 211
AR 104875
DI 10.1016/j.bandl.2020.104875
PG 11
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA OU4US
UT WOS:000591525900002
PM 33086178
DA 2021-02-24
ER

PT J
AU Ceolini, E
   Hjortkjaer, J
   De Wong, D
   O'Sullivan, J
   Raghavan, VS
   Herrero, J
   Mehta, AD
   Liu, SC
   Mesgarani, N
AF Ceolini, Enea
   Hjortkjaer, Jens
   De Wong, Daniel
   O'Sullivan, James
   Raghavan, Vinay S.
   Herrero, Jose
   Mehta, Ashesh D.
   Liu, Shih-Chii
   Mesgarani, Nima
TI Brain-informed speech separation (BISS) for enhancement of target
   speaker in multitalker speech perception
SO NEUROIMAGE
LA English
DT Article
DE EEG; Neuro-steered; Cognitive control; Speech separation; Deep learning;
   Hearing aid
ID AUDITORY ATTENTION; ATTENDED SPEAKER; LCMV BEAMFORMER; TRACKING;
   ALGORITHMS; TIME
AB Hearing-impaired people often struggle to follow the speech stream of an individual talker in noisy environments. Recent studies show that the brain tracks attended speech and that the attended talker can be decoded from neural data on a single-trial level. This raises the possibility of "neuro-steered" hearing devices in which the brain-decoded intention of a hearing-impaired listener is used to enhance the voice of the attended speaker from a speech separation front-end. So far, methods that use this paradigm have focused on optimizing the brain decoding and the acoustic speech separation independently. In this work, we propose a novel framework called brain-informed speech separation (BISS)(1) in which the information about the attended speech, as decoded from the subject's brain, is directly used to perform speech separation in the front-end. We present a deep learning model that uses neural data to extract the clean audio signal that a listener is attending to from a multi-talker speech mixture. We show that the framework can be applied successfully to the decoded output from either invasive intracranial electroencephalography (iEEG) or non-invasive electroencephalography (EEG) recordings from hearing-impaired subjects. It also results in improved speech separation, even in scenes with background noise. The generalization capability of the system renders it a perfect candidate for neuro-steered hearing-assistive devices.
C1 [Ceolini, Enea; Liu, Shih-Chii] Univ Zurich, Zurich, Switzerland.
   [Ceolini, Enea; Liu, Shih-Chii] Swiss Fed Inst Technol, Inst Neuroinformat, Zurich, Switzerland.
   [Hjortkjaer, Jens] Danmarks Tekniske Univ DTU, Dept Hlth Technol, Lyngby, Denmark.
   [Hjortkjaer, Jens] Copenhagen Univ Hosp Hvidovre, Danish Res Ctr Magnet Resonance, Hvidovre, Denmark.
   [De Wong, Daniel] CNRS, Lab Syst Perceptifs, UMR 8248, Paris, France.
   [De Wong, Daniel] PSL Res Univ, Ecole Normale Super, Dept Etud Cognit, Paris, France.
   [O'Sullivan, James; Raghavan, Vinay S.; Mesgarani, Nima] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
   [O'Sullivan, James; Raghavan, Vinay S.; Mesgarani, Nima] Columbia Univ, Mortimer B Zuckerman Mind Brain Behav Inst, New York, NY 10027 USA.
   [Herrero, Jose; Mehta, Ashesh D.] Hofstra Northwell Sch Med, Dept Neurosurg, Manhasset, NY USA.
RP Ceolini, E (corresponding author), Univ Zurich, Zurich, Switzerland.; Mesgarani, N (corresponding author), Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.; Mesgarani, N (corresponding author), Columbia Univ, Mortimer B Zuckerman Mind Brain Behav Inst, New York, NY 10027 USA.
EM enea.ceolini@ini.uzh.ch; nima@ee.columbia.edu
OI Ceolini, Enea/0000-0002-2676-0804; Hjortkjaer, Jens/0000-0003-3724-3332;
   Raghavan, Vinay/0000-0002-4387-0781
FU European UnionEuropean Commission [644732]; SNSFSwiss National Science
   Foundation (SNSF) [200021172553]; National Institutes of HealthUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USA [NIDCD-DC014279]; National Science Foundation CAREER
   awardNational Science Foundation (NSF)
FX This work was partially supported by the European Union's Horizon 2020
   research and innovation program under grant agreement No 644732, the
   SNSF grant No. 200021172553, the grant from the National Institutes of
   Health NIDCD-DC014279, and the National Science Foundation CAREER award.
CR Akbari H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37359-z
   Aroudi A, 2019, INT CONF ACOUST SPEE, P406, DOI 10.1109/ICASSP.2019.8683635
   Barfuss H., 2016, P IEEE INT WORKSH AC, P1
   Braun S, 2017, EUR SIGNAL PR CONF, P548, DOI 10.23919/EUSIPCO.2017.8081267
   BREGMAN AS, 1978, CAN J PSYCHOL, V32, P19, DOI 10.1037/h0081664
   Ceolini E., 2019, P 2019 IEEE BIOM CIR, P1, DOI DOI 10.1109/BIOCAS.2019.8919210
   Ceolini E, 2020, IEEE-ACM T AUDIO SPE, V28, P1428, DOI 10.1109/TASLP.2020.2989545
   Chen Z, 2017, INT CONF ACOUST SPEE, P246, DOI 10.1109/ICASSP.2017.7952155
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Clark JL, 2014, DISABIL REHABIL-ASSI, V9, P408, DOI 10.3109/17483107.2014.905642
   Conn P.M., 2006, HDB MODELS HUMAN AGI
   de Cheveigne A, 2018, NEUROIMAGE, V172, P206, DOI 10.1016/j.neuroimage.2018.01.033
   Dijkstra KV, 2015, BRAIN-COMPUT INTERFA, V2, P161, DOI 10.1080/2326263X.2015.1063363
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Doclo S., 2008, HDB ARRAY PROCESSING, P269
   Doclo S, 2015, IEEE SIGNAL PROC MAG, V32, P18, DOI 10.1109/MSP.2014.2366780
   Ephrat A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201357
   Fuglsang S., 2020, J NEUROSCI
   Fuglsang SA, 2017, NEUROIMAGE, V156, P435, DOI 10.1016/j.neuroimage.2017.04.026
   Gannot S, 2017, IEEE-ACM T AUDIO SPE, V25, P692, DOI 10.1109/TASLP.2016.2647702
   Geirnaert S, 2020, IEEE T NEUR SYS REH, V28, P307, DOI 10.1109/TNSRE.2019.2952724
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Han C, 2019, INT CONF ACOUST SPEE, P361, DOI 10.1109/ICASSP.2019.8682884
   Han C, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aav6134
   Hershey JR, 2016, INT CONF ACOUST SPEE, P31, DOI 10.1109/ICASSP.2016.7471631
   Hjortkjaer J, 2020, EUR J NEUROSCI, V51, P1279, DOI 10.1111/ejn.13855
   Horton C, 2014, J NEURAL ENG, V11, DOI 10.1088/1741-2560/11/4/046015
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Kim D, 2017, INT CONF SIM SEMI PR, P241, DOI 10.23919/SISPAD.2017.8085309
   Kingma D. P., 2014, ARXIV14126980, P1
   Kiselev I, 2017, 2017 IEEE 42ND CONFERENCE ON LOCAL COMPUTER NETWORKS WORKSHOPS (LCN WORKSHOPS 2017), P35, DOI 10.1109/LCN.Workshops.2017.62
   Le Roux J, 2019, INT CONF ACOUST SPEE, P626, DOI 10.1109/ICASSP.2019.8683855
   Liu YZ, 2019, IEEE-ACM T AUDIO SPE, V27, P2092, DOI 10.1109/TASLP.2019.2941148
   Luo Y, 2019, IEEE-ACM T AUDIO SPE, V27, P1256, DOI 10.1109/TASLP.2019.2915167
   Luo Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P696, DOI 10.1109/ICASSP.2018.8462116
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Mesgarani N, 2009, J NEUROPHYSIOL, V102, P3329, DOI 10.1152/jn.91128.2008
   Miran S, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00262
   O'Sullivan J, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa7ab4
   Oreinos C, 2013, ACTA ACUST UNITED AC, V99, P836, DOI 10.3813/AAA.918662
   Peelle JE, 2016, TRENDS NEUROSCI, V39, P486, DOI 10.1016/j.tins.2016.05.001
   Power AJ, 2012, EUR J NEUROSCI, V35, P1497, DOI 10.1111/j.1460-9568.2012.08060.x
   Reindl K, 2014, IEEE-ACM T AUDIO SPE, V22, P1096, DOI 10.1109/TASLP.2014.2319155
   Schwartz O, 2017, IEEE-ACM T AUDIO SPE, V25, P940, DOI 10.1109/TASLP.2017.2655258
   van den Oord A., 2016, WAVENET GENERATIVE M
   Van Eyndhoven S, 2017, IEEE T BIO-MED ENG, V64, P1045, DOI 10.1109/TBME.2016.2587382
   Wang DL, 2018, IEEE-ACM T AUDIO SPE, V26, P1702, DOI 10.1109/TASLP.2018.2842159
   Wang JE, 2018, CHINA PERSPECT
   Williamson DS, 2016, IEEE-ACM T AUDIO SPE, V24, P483, DOI 10.1109/TASLP.2015.2512042
   Wong D.D.E., 2018, ARO MIDW M ARO MIDW
   Wong DDE, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00531
   Xiao X, 2019, INT CONF ACOUST SPEE, P86, DOI 10.1109/ICASSP.2019.8682245
   Zhao LH, 2014, IEEE-ACM T AUDIO SPE, V22, P1455, DOI 10.1109/TASLP.2014.2337844
NR 53
TC 0
Z9 0
U1 5
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD DEC
PY 2020
VL 223
AR 117282
DI 10.1016/j.neuroimage.2020.117282
PG 12
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA OH7US
UT WOS:000582799600013
PM 32828921
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Noroozia, M
   Nikakhlaghb, S
   Angalic, KA
   Bagheripourd, H
   Sakid, N
AF Noroozia, Mahdokht
   Nikakhlaghb, Soheila
   Angalic, Kambiz Ahmadi
   Bagheripourd, Hossein
   Sakid, Nader
TI Relationship between age at cochlear implantation and auditory speech
   perception development skills in children
SO CLINICAL EPIDEMIOLOGY AND GLOBAL HEALTH
LA English
DT Article
DE Cochlear implantation; Auditory perceptual skills; Children
ID IDENTIFIED CHILDREN; HEARING; LANGUAGE
AB Objective: Sensorineural hearing loss (SNHL) is an important risk factor for the development of linguistic abilities in children. In recent years, technological improvement and transition from hearing aids to cochlear implants from have showed a brighter image for the future of this children involved. However, there are many unknowns along this path. The present study attempted to address some of these unknowns by check the data from children treated at Khuzestan Cochlear Implant Center.
   Materials and methods: This study was performed on 104 children admitted to Khuzestan Cochlear Implant Center, Ahvaz, Iran. These children where children undergoing cochlear implantation were followed for one year and Categories of Auditory Performance (CAP) scores were recorded.
   Results: The results of this study showed that implantation age was inversely correlated with speech perception at the end of one year. Girls in the ninth month, monolingual children in the sixth and ninth month, and children with higher education mothers performed better results in the one-year follow up.
   Conclusion: Lower age at the time of cochlear implantation, being a girl, living in a monolingual environment, lack of accompanying disorders, and having a more educated mother can significantly improve children's performance.
C1 [Noroozia, Mahdokht] Ahvaz Jundishapur Univ Med Sci, Student Res Comm, Ahwaz, Iran.
   [Nikakhlaghb, Soheila] Ahvaz Jundishapur Univ Med Sci, Imam Khomeini Hosp, Hearing Res Ctr, Ahwaz, Iran.
   [Angalic, Kambiz Ahmadi] Ahvaz Jundishapur Univ Med Sci, Sch Hlth, Biostat Dept, Ahwaz, Iran.
   [Bagheripourd, Hossein; Sakid, Nader] Ahvaz Jundishapur Univ Med Sci, Hearing Res Ctr, Ahwaz, Iran.
RP Sakid, N (corresponding author), Ahvaz Jundishapur Univ Med Sci, Imam Khomeini Hosp, Hearing Res Ctr, Ahwaz, Iran.
EM Mahdokht.noroozi@gmail.com; nikakhlagh.s@gmail.com; kzfir4@gmail.com;
   bagheripourhossein@yahoo.com; saki-n@ajums.ac.ir
FU Ahvaz Jundishapur University Research Department and Hearing Research
   Center, Ahvaz, Iran
FX This article was derived from a MD thesis with the number B-98031.
   Funding was provided by the Ahvaz Jundishapur University Research
   Department and Hearing Research Center, Ahvaz, Iran.
CR Akin Istemihan, 2012, Kulak Burun Bogaz Ihtis Derg, V22, P123, DOI 10.5606/kbbihtisas.2012.024
   Ching TYC, 2013, EAR HEARING, V34, P535, DOI 10.1097/AUD.0b013e3182857718
   Cosetti MK, 2013, OTOL NEUROTOL, V34, P516, DOI 10.1097/MAO.0b013e3182785210
   Dashti R, 2015, J AUDIOL OTOL, V19, P14, DOI 10.7874/jao.2015.19.1.14
   Doubi A, 2019, OTOL NEUROTOL, V40, P602, DOI 10.1097/MAO.0000000000002192
   Govaerts PJ, 2002, OTOL NEUROTOL, V23, P885, DOI 10.1097/00129492-200211000-00013
   Houston DM, 2010, OTOL NEUROTOL, V31, P1248, DOI 10.1097/MAO.0b013e3181f1cc6a
   Lenarz T, 2017, AUDIOL NEURO-OTOL, V22, P61, DOI 10.1159/000477533
   Liu YY, 2014, AURIS NASUS LARYNX, V41, P502, DOI 10.1016/j.anl.2014.06.001
   Robbins AM, 2004, ARCH OTOLARYNGOL, V130, P570
   Saki Nader, 2019, Int Tinnitus J, V23, P74, DOI 10.5935/0946-5448.20190013
   Saki N, 2019, INT J PEDIATR OTORHI, V127, DOI 10.1016/j.ijporl.2019.109669
   Saki N, 2017, INT J PEDIATR OTORHI, V97, P89, DOI 10.1016/j.ijporl.2017.03.038
   Saki N, 2017, INT J MENT HEALTH AD, V15, P288, DOI 10.1007/s11469-016-9672-4
   Sharma A, 2005, HEARING RES, V203, P134, DOI 10.1016/j.heares.2004.12.010
   Yoshinaga-Itano C, 1998, PEDIATRICS, V102, P1161, DOI 10.1542/peds.102.5.1161
   Zimmerman FJ, 2009, PEDIATRICS, V124, P342, DOI 10.1542/peds.2008-2267
NR 17
TC 0
Z9 0
U1 4
U2 4
PU ELSEVIER - DIVISION REED ELSEVIER INDIA PVT LTD
PI NEW DELHI
PA 17-A/1 MAIN RING ROAD, LAJPAT NAGAR IV, NEW DELHI, 110024, INDIA
SN 2452-0918
EI 2213-3984
J9 CLIN EPIDEMIOL GLOB
JI Clin. Epidemiol. Glob. Health
PD DEC
PY 2020
VL 8
IS 4
BP 1356
EP 1359
DI 10.1016/j.cegh.2020.05.011
PG 4
WC Public, Environmental & Occupational Health
SC Public, Environmental & Occupational Health
GA NZ5EF
UT WOS:000577120900022
OA Bronze
DA 2021-02-24
ER

PT J
AU Saito, K
   Kachlicka, M
   Sun, H
   Tierney, A
AF Saito, Kazuya
   Kachlicka, Magdalena
   Sun, Hui
   Tierney, Adam
TI Domain-general auditory processing as an anchor of post-pubertal second
   language pronunciation learning: Behavioural and neurophysiological
   investigations of perceptual acuity, age, experience, development, and
   attainment
SO JOURNAL OF MEMORY AND LANGUAGE
LA English
DT Article
DE Auditory processing; Second language; Speech production; Age; Experience
ID FREQUENCY-FOLLOWING RESPONSE; INDIVIDUAL-DIFFERENCES; VERTICAL-BAR;
   LANGUAGE IMPAIRMENT; JAPANESE LEARNERS; SPEECH-PERCEPTION; NATIVE
   SPEAKERS; CHILDREN; ENGLISH; DEFICITS
AB In the cognitive psychology literature, auditory processing has been extensively researched and suggested as a foundation of first language acquisition in childhood. This study tests an emerging theoretical view that the same faculty underpins post-pubertal second language (L2) pronunciation learning. A total of 100 late Polish-English bilinguals in the UK with diverse age and experience backgrounds were assessed for their ability to represent various characteristics of sounds via behavioural and neurophysiological measures. Subsequently, the participants' biographical backgrounds and auditory processing profiles were compared to various dimensions of their L2 pronunciation proficiency. According to the results of mixed-effects modeling analyses, individual differences in participants' L2 pronunciation proficiency were equally accounted for by age (age of arrival), experience (length of residence), and auditory processing (encoding, reproduction). Within the current dataset, the degree of auditory precision was negatively associated with participants' chronological age (19-45 years). The findings suggest that earlier age of onset may allow them to take advantage of more precise auditory processing, which in turn helps them to make the most of every input opportunity throughout extensive immersion experience, leading to more advanced L2 phonological skills in the long run.
C1 [Saito, Kazuya; Kachlicka, Magdalena] UCL, London, England.
   [Sun, Hui] Univ Birmingham, Birmingham, W Midlands, England.
   [Tierney, Adam] Birkbeck Univ London, London, England.
RP Saito, K (corresponding author), UCL, Inst Educ, 20 Bedford Way, London WC1H 0AL, England.
EM k.saito@ucl.ac.uk
RI Sun, Hui/Y-1898-2019
OI Sun, Hui/0000-0001-5783-0126; Kachlicka, Magdalena/0000-0002-6345-4152
FU Leverhulme Trust Research GrantLeverhulme Trust [RPG-2019-039]; Arnold
   Bentley New Initiatives Fund
FX This study was funded by Leverhulme Trust Research Grant (RPG-2019-039)
   and Arnold Bentley New Initiatives Fund. We would like to thank Yui
   Suzukida, Shungo Suzuki, and the anonymous reviewers from the Journal of
   Memory and Language for their useful and constructive comments on the
   earlier versions of the manuscript.
CR Abrahamsson N, 2009, LANG LEARN, V59, P249, DOI 10.1111/j.1467-9922.2009.00507.x
   Aiken SJ, 2008, HEARING RES, V245, P35, DOI 10.1016/j.heares.2008.08.004
   Baayen R.H., 2008, ANAL LINGUISTIC DATA
   Barriuso AT., 2018, CATESOL J, V30, P177
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Birdsong D, 2001, J MEM LANG, V44, P235, DOI 10.1006/jmla.2000.2750
   Boets B, 2008, BRAIN LANG, V106, P29, DOI 10.1016/j.bandl.2007.12.004
   Boets B, 2011, RES DEV DISABIL, V32, P560, DOI 10.1016/j.ridd.2010.12.020
   Bongaerts T., 1997, STUDIES 2 LANGUAGE A, V19, P447, DOI DOI 10.1017/S0272263197004026
   Bosker HR, 2013, LANG TEST, V30, P159, DOI 10.1177/0265532212455394
   Campbell KL, 2018, CURR OPIN BEHAV SCI, V21, P132, DOI 10.1016/j.cobeha.2018.04.008
   Carcagno S, 2011, JARO-J ASSOC RES OTO, V12, P503, DOI 10.1007/s10162-011-0266-3
   Casini L, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12530
   Chandrasekaran B, 2012, J NEUROPHYSIOL, V107, P1325, DOI 10.1152/jn.00923.2011
   Clinard CG, 2010, HEARING RES, V264, P48, DOI 10.1016/j.heares.2009.11.010
   Coffey EBJ, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11070
   Corrigall KA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00222
   Darcy I, 2016, LANG LEARN, V66, P741, DOI 10.1111/lang.12161
   Darcy I, 2015, LEARN INDIVID DIFFER, V40, P63, DOI 10.1016/j.lindif.2015.04.005
   DeKeyser RM, 2013, LANG LEARN, V63, P52, DOI 10.1111/j.1467-9922.2012.00737.x
   Derwing TM, 2013, LANG LEARN, V63, P163, DOI 10.1111/lang.12000
   Doughty CJ, 2019, LANG LEARN, V69, P101, DOI 10.1111/lang.12322
   Espy-Wilson CY, 2000, J ACOUST SOC AM, V108, P343, DOI 10.1121/1.429469
   Flaugnacco E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138715
   Flaugnacco E, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00392
   Flege J., 2016, PLENARY ADDRESS DELI
   FLEGE JE, 1995, LANG SPEECH, V38, P25, DOI 10.1177/002383099503800102
   FLEGE JE, 1995, J ACOUST SOC AM, V97, P3125, DOI 10.1121/1.413041
   Freed BF, 2004, STUD SECOND LANG ACQ, V26, P349, DOI 10.1017/S0272263104062096
   Gibson LY, 2006, COGN NEUROPSYCHOL, V23, P621, DOI 10.1080/02643290500412545
   Gokula R, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02383
   Goswami U, 2015, NAT REV NEUROSCI, V16, P43, DOI 10.1038/nrn3836
   Goswami U, 2011, J COGNITIVE NEUROSCI, V23, P325, DOI 10.1162/jocn.2010.21453
   Granena G, 2013, SECOND LANG RES, V29, P311, DOI 10.1177/0267658312461497
   Halliday LF, 2017, COGNITION, V166, P139, DOI 10.1016/j.cognition.2017.04.014
   Hamrick P, 2018, P NATL ACAD SCI USA, V115, P1487, DOI 10.1073/pnas.1713975115
   Hayes EA, 2003, CLIN NEUROPHYSIOL, V114, P673, DOI 10.1016/S1388-2457(02)00414-5
   Hornickel J, 2013, J NEUROSCI, V33, P3500, DOI 10.1523/JNEUROSCI.4205-12.2013
   Jasmin K., 2020, BIORXIV, DOI [10.1101/2020.01.02.892943, DOI 10.1101/2020.01.02.892943]
   Jasmin K, 2020, J EXP PSYCHOL GEN, V149, P914, DOI 10.1037/xge0000688
   Kachlicka M, 2019, BRAIN LANG, V192, P15, DOI 10.1016/j.bandl.2019.02.004
   Kempe V, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048623
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Lahmann C, 2017, INT J BILINGUAL, V21, P228, DOI 10.1177/1367006915613162
   Lambert C, 2017, STUD SECOND LANG ACQ, V39, P167, DOI 10.1017/S0272263116000085
   Lee J, 2015, APPL LINGUIST, V36, P345, DOI 10.1093/applin/amu040
   Lengeris A, 2010, J ACOUST SOC AM, V128, P3757, DOI 10.1121/1.3506351
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Li SF, 2016, STUD SECOND LANG ACQ, V38, P801, DOI 10.1017/S027226311500042X
   Linck JA, 2013, LANG LEARN, V63, P530, DOI 10.1111/lang.12011
   McAllister R, 2002, J PHONETICS, V30, P229, DOI 10.1006/jpho.2002.0174
   McArthur GM, 2008, COGNITION, V107, P946, DOI 10.1016/j.cognition.2007.12.005
   McArthur GM, 2005, BRAIN LANG, V94, P260, DOI 10.1016/j.bandl.2005.01.002
   Mora JC, 2017, STUD SECOND LANG ACQ, V39, P381, DOI 10.1017/S0272263117000183
   Mueller JL, 2012, P NATL ACAD SCI USA, V109, P15953, DOI 10.1073/pnas.1204319109
   Munoz C, 2014, APPL LINGUIST, V35, P463, DOI 10.1093/applin/amu024
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   O'Brien I, 2007, STUD SECOND LANG ACQ, V29, P557, DOI 10.1017/S027226310707043X
   Omote A, 2017, CORTEX, V93, P146, DOI 10.1016/j.cortex.2017.05.005
   Park DC, 2017, J GERONTOL B-PSYCHOL, V72, P82, DOI 10.1093/geronb/gbw066
   Piske T., 2011, ACHIEVEMENTS PERSPEC, V2, P195
   Plag I, 2011, J PHONETICS, V39, P362, DOI 10.1016/j.wocn.2011.03.004
   POVEL DJ, 1985, MUSIC PERCEPT, V2, P411
   R Core Team, 2018, R LANG ENV STAT COMP
   Roncaglia-Denissen MP, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00288
   Rosen S, 2003, J PHONETICS, V31, P509, DOI 10.1016/S0095-4470(03)00046-9
   Rosen S, 2001, J SPEECH LANG HEAR R, V44, P720, DOI 10.1044/1092-4388(2001/057)
   Russo NM, 2008, CLIN NEUROPHYSIOL, V119, P1720, DOI 10.1016/j.clinph.2008.01.108
   Saito K., 2020, ARTICLE ACCEPTED STU
   Saito K., 2020, SUPPORTING DATA DOMA, DOI [10.48316/PN8Q-D936, DOI 10.48316/PN8Q-D936]
   Saito K., 2020, APPL PSYCHOLINGUISTI
   Saito K., 2020, BIORXIV, DOI [10.1101/2020.06.12.149484, DOI 10.1101/2020.06.12.149484]
   Saito K, 2019, LANG LEARN, V69, P652, DOI 10.1111/lang.12345
   Saito K, 2019, BILING-LANG COGN, V22, P1123, DOI 10.1017/S1366728918000895
   Saito K, 2017, APPL LINGUIST, V38, P439, DOI 10.1093/applin/amv047
   Saito K, 2015, STUD SECOND LANG ACQ, V37, P713, DOI 10.1017/S0272263115000248
   Saito K, 2015, LANG LEARN, V65, P563, DOI 10.1111/lang.12120
   Saito K, 2013, J MEM LANG, V69, P546, DOI 10.1016/j.jml.2013.07.003
   Saito K, 2012, LANG LEARN, V62, P595, DOI 10.1111/j.1467-9922.2011.00639.x
   Sakai M, 2018, APPL PSYCHOLINGUIST, V39, P187, DOI 10.1017/S0142716417000418
   Silbert NH, 2015, J PHONETICS, V50, P99, DOI 10.1016/j.wocn.2015.03.001
   Skehan P., 2019, LANGUAGE APTITUDE AD
   Skoe E, 2015, CEREB CORTEX, V25, P1415, DOI 10.1093/cercor/bht311
   Skoe E, 2010, EAR HEARING, V31, P302, DOI 10.1097/AUD.0b013e3181cdb272
   Smith JO, 2007, INTRO DIGITAL FILTER
   Snowling MJ, 2018, PSYCHOL SCI, V29, P1270, DOI 10.1177/0956797618763090
   Spada N, 2010, LANG LEARN, V60, P263, DOI 10.1111/j.1467-9922.2010.00562.x
   Strehlow U, 2006, EUR CHILD ADOLES PSY, V15, P19, DOI 10.1007/s00787-006-0500-4
   Sun H., STUDIES 2 LANGUAGE A
   Surprenant AM, 2001, J ACOUST SOC AM, V110, P2085, DOI 10.1121/1.1404973
   Tallal P, 2004, NAT REV NEUROSCI, V5, P721, DOI 10.1038/nrn1499
   Tavakoli P., 2005, PLANNING TASK PERFOR, P239, DOI DOI 10.1075/LLLT.11.15TAV
   Thompson EC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128839
   Tierney A, 2017, J COGNITIVE NEUROSCI, V29, P855, DOI 10.1162/jocn_a_01092
   Tierney A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00949
   Tierney A, 2013, J NEUROSCI, V33, P14981, DOI 10.1523/JNEUROSCI.0612-13.2013
   Tierney AT, 2015, P NATL ACAD SCI USA, V112, P10062, DOI 10.1073/pnas.1505114112
   Tomasello M, 2000, COGN LINGUIST, V11, P61
   Trofimovich P, 2006, STUD SECOND LANG ACQ, V28, P1, DOI 10.1017/S0272263106060013
   Trofimovich P, 2015, BLACKW HBK LINGUIST, P353
   Varghese L, 2015, BRAIN RES, V1626, P146, DOI 10.1016/j.brainres.2015.06.038
   Verhaeghen P, 2011, CURR DIR PSYCHOL SCI, V20, P174, DOI 10.1177/0963721411408772
   Wagenmakers EJ, 2007, PSYCHOL REV, V114, P830, DOI 10.1037/0033-295X.114.3.830
   Warrier CM, 2004, EXP BRAIN RES, V157, P431, DOI 10.1007/s00221-004-1857-6
   White-Schwoch T, 2015, PLOS BIOL, V13, DOI 10.1371/journal.pbio.1002196
   Whiteford KL, 2018, CORTEX, V103, P164, DOI 10.1016/j.cortex.2018.03.012
   Won JH, 2016, J ACOUST SOC AM, V139, P1, DOI 10.1121/1.4931909
   Wong PCM, 2007, APPL PSYCHOLINGUIST, V28, P565, DOI 10.1017/S0142716407070312
   Wright BA, 2000, CURR OPIN NEUROBIOL, V10, P482, DOI 10.1016/S0959-4388(00)00119-7
   Zhu L, 2013, J ACOUST SOC AM, V134, P384, DOI 10.1121/1.4807498
   Zuniga M, 2019, J PSYCHOLINGUIST RES, V48, P43, DOI 10.1007/s10936-018-9587-2
NR 113
TC 2
Z9 2
U1 21
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0749-596X
EI 1096-0821
J9 J MEM LANG
JI J. Mem. Lang.
PD DEC
PY 2020
VL 115
AR 104168
DI 10.1016/j.jml.2020.104168
PG 15
WC Linguistics; Psychology; Psychology, Experimental
SC Linguistics; Psychology
GA OA0XF
UT WOS:000577519000012
DA 2021-02-24
ER

PT J
AU Steffman, J
   Katsuda, H
AF Steffman, Jeremy
   Katsuda, Hironori
TI Intonational Structure Influences Perception of Contrastive Vowel
   Length: The Case of Phrase-Final Lengthening in Tokyo Japanese
SO LANGUAGE AND SPEECH
LA English
DT Article; Early Access
DE Speech perception; prosody; intonation; Japanese; vowel length
AB Recent research has proposed that listeners use prosodic information to guide their processing of phonemic contrasts. Given that prosodic organization of the speech signal systematically modulates durational patterns (e.g., accentual lengthening and phrase-final (PF) lengthening), listeners' perception of durational contrasts has been argued to be influenced by prosodic factors. For example, given that sounds are generally lengthened preceding a prosodic boundary, listeners may adjust their perception of durational cues accordingly, effectively compensating for prosodically-driven temporal patterns. In the present study we present two experiments designed to test the importance of pitch-based cues to prosodic structure for listeners' perception of contrastive vowel length (CVL) in Tokyo Japanese along these lines. We tested if, when a target sound is cued as being PF, listeners compensatorily adjust categorization of vowel duration, in accordance with PF lengthening. Both experiments were a two-alternative forced choice task in which listeners categorized a vowel duration continuum as a phonemically short or long vowel. We manipulated only pitch surrounding the target sound in a carrier phrase to cue it as intonational phrase final, or accentual phrase medial. In Experiment 1 we tested perception of an accented target word, and in Experiment 2 we tested perception of an unaccented target word. In both experiments, we found that contextual changes in pitch influenced listeners' perception of CVL, in accordance with their function as signaling intonational structure. Results therefore suggest that listeners use tonal information to compute prosodic structure and bring this to bear on their perception of durational contrasts in speech.
C1 [Steffman, Jeremy; Katsuda, Hironori] Univ Calif Los Angeles, Los Angeles, CA USA.
RP Steffman, J (corresponding author), Univ Calif Los Angeles, Dept Linguist, 3125 Campbell Hall, Los Angeles, CA 90095 USA.
EM jeremysteffman@gmail.com
OI Steffman, Jeremy/0000-0003-3675-910X
FU University of California, Los Angeles Ladefoged ScholarshipUniversity of
   California System
FX This research was funded by the University of California, Los Angeles
   Ladefoged Scholarship, awarded to Hironori Katsuda.
CR Abramson A.S., 1970, P 6 INT C PHON SCI P, P569
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beckman M. E., 1986, PHONOLOGY YB, V3, P255, DOI [DOI 10.1017/S095267570000066X, 10.1017/S095267570000066X]
   Boersma Paul, 2019, PRAAT DOING PHONETIC
   Byrd D., 2000, PAPERS LAB PHONOLOGY, P70
   CHEN M, 1970, PHONETICA, V22, P129, DOI 10.1159/000259312
   Cho TH, 2007, J PHONETICS, V35, P210, DOI 10.1016/j.wocn.2006.03.003
   Cho T, 2016, LANG LINGUIST COMPAS, V10, P120, DOI 10.1111/lnc3.12178
   Cho T, 2015, BLACKW HBK LINGUIST, P505
   Cho T, 2009, J PHONETICS, V37, P466, DOI 10.1016/j.wocn.2009.08.001
   Christophe A, 2004, J MEM LANG, V51, P523, DOI 10.1016/j.jml.2004.07.001
   DEJONG KJ, 1995, J ACOUST SOC AM, V97, P491, DOI 10.1121/1.412275
   DIEHL RL, 1989, J ACOUST SOC AM, V85, P2154, DOI 10.1121/1.397864
   Fougeron C, 1997, J ACOUST SOC AM, V101, P3728, DOI 10.1121/1.418332
   Katsika A, 2016, J PHONETICS, V55, P149, DOI 10.1016/j.wocn.2015.12.003
   Keating P., 2006, SPEECH PRODUCTION MO, P167
   Keating P., 2003, PHONETIC INTERPRETAT, P145
   Kim S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202912
   Kim S, 2013, J ACOUST SOC AM, V134, pEL19, DOI 10.1121/1.4807431
   Kingston J, 2016, J EXP PSYCHOL HUMAN, V42, P1969, DOI 10.1037/xhp0000269
   Kubozono H., 1993, ORG JAPANESE PROSODY
   Lunden A, 2013, J COMP GER LINGUIST, V16, P1, DOI 10.1007/s10828-013-9053-3
   Maekawa K., 2002, P 7 INT C SPOK LANG, P1545
   Maekawa K., 2003, ISCA IEEE WORKSH SPO, P7
   Maekawa K., 2000, P 2 INT C LANG RES E, P947
   Maekawa Kikuo., 1994, OHIO STATE U WORKING, P146
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001
   MILLER JL, 1979, PERCEPT PSYCHOPHYS, V25, P457, DOI 10.3758/BF03213823
   Mitterer H, 2019, J MEM LANG, V108, DOI 10.1016/j.jml.2019.104034
   Mitterer H, 2016, J PHONETICS, V54, P68, DOI 10.1016/j.wocn.2015.09.002
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Nakai S, 2011, J ACOUST SOC AM, V129, P966, DOI 10.1121/1.3514419
   Nakai S, 2009, J PHONETICS, V37, P29, DOI 10.1016/j.wocn.2008.08.002
   Newman RS, 1996, PERCEPT PSYCHOPHYS, V58, P540, DOI 10.3758/BF03213089
   Newman RS, 1997, J EXP PSYCHOL HUMAN, V23, P873, DOI 10.1037/0096-1523.23.3.873
   NOOTEBOOM SG, 1980, J ACOUST SOC AM, V67, P276, DOI 10.1121/1.383737
   Pierrehumbert J., 1988, LINGUISTIC INQUIRY M, V15, P1, DOI [10.1017/s0022226700014286, DOI 10.1017/S0022226700014286]
   Poser W., 1984, THESIS MIT US
   RAPHAEL LJ, 1972, J ACOUST SOC AM, V51, P1296, DOI 10.1121/1.1912974
   Redi L, 2001, J PHONETICS, V29, P407, DOI 10.1006/jpho.2001.0145
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   Salverda AP, 2003, COGNITION, V90, P51, DOI 10.1016/S0010-0277(03)00139-2
   Seo J, 2019, J ACOUST SOC AM, V146, P1817, DOI 10.1121/1.5122191
   Shepherd M.A., 2008, USC WORKING PAPERS L, P1
   Steffman J., 2019, P LINGUISTIC SOC AM, V4, DOI [10.3765/plsa.v4i1.4536, DOI 10.3765/PLSA.V4I1.4536]
   Steffman J, 2019, J ACOUST SOC AM, V145, pEL560, DOI 10.1121/1.5111772
   Steffman J, 2019, J PHONETICS, V74, P114, DOI 10.1016/j.wocn.2019.03.002
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   TAKEDA K, 1989, J ACOUST SOC AM, V86, P2081, DOI 10.1121/1.398467
   Turk AE, 1997, J PHONETICS, V25, P25, DOI 10.1006/jpho.1996.0032
   Turk AE, 1999, J PHONETICS, V27, P171, DOI 10.1006/jpho.1999.0093
   Turk AE, 2007, J PHONETICS, V35, P445, DOI 10.1016/j.wocn.2006.12.001
   Ueyama M, 1999, UCLA WORKING PAPERS, V97, P174
   VANDOMMELEN WA, 1993, J PHONETICS, V21, P367, DOI 10.1016/S0095-4470(19)30226-8
   Venditti J.J., 1995, OHIO STATE U WORKING, V50, P127, DOI [11/81780/WPL_50_July_1997_127.pdf, DOI 11/81780/WPL_50_JULY_1997_127.PDF]
   Venditti Jennifer., 2005, PROSODIC TYPOLOGY PH, P172, DOI [10.1093/acprof:oso/9780199249633.003.0007, DOI 10.1093/ACPROF:OSO/9780199249633.003.0007]
   WIGHTMAN CW, 1992, J ACOUST SOC AM, V91, P1707, DOI 10.1121/1.402450
NR 58
TC 1
Z9 1
U1 1
U2 1
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
AR 0023830920971842
DI 10.1177/0023830920971842
EA NOV 2020
PG 20
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA PI7ED
UT WOS:000601248800001
PM 33251945
DA 2021-02-24
ER

PT J
AU Leliveld, LMC
   Dupjan, S
   Tuchscherer, A
   Puppe, B
AF Leliveld, Lisette M. C.
   Dupjan, Sandra
   Tuchscherer, Armin
   Puppe, Birger
TI Hemispheric Specialization for Processing the Communicative and
   Emotional Content of Vocal Communication in a Social Mammal, the
   Domestic Pig
SO FRONTIERS IN BEHAVIORAL NEUROSCIENCE
LA English
DT Article
DE acoustic communication; conspecific calls; ear preference; hemispheric
   asymmetry; orienting bias; domestic pig; auditory lateralization
ID AUDITORY-CORTEX; DISTRESS CALLS; FARM-ANIMALS; VOCALIZATIONS; LANGUAGE;
   BRAIN; LATERALIZATION; ASYMMETRIES; ADVANTAGE; EVOLUTION
AB In humans, speech perception is lateralized, with the left hemisphere of the brain dominant in processing the communicative content and the right hemisphere dominant in processing the emotional content. However, still little is known about such a division of tasks in other species. We therefore investigated lateralized processing of communicative and emotionally relevant calls in a social mammal, the pig (Sus scrofa). Based on the contralateral connection between ears and hemispheres, we compared the behavioural and cardiac responses of 36 young male pigs during binaural and monaural (left or right) playback to the same sounds. The playback stimuli were calls of social isolation and physical restraint, whose communicative and emotional relevance, respectively, were validated prior to the test by acoustic analyses and during binaural playbacks. There were indications of lateralized processing mainly in the initial detection (left head-turn bias, indicating right hemispheric dominance) of the more emotionally relevant restraint calls. Conversely, there were indications of lateralized processing only in the appraisal (increased attention during playback to the right ear) of the more communicative relevant isolation calls. This implies differential involvement of the hemispheres in the auditory processing of vocalizations in pigs and thereby hints at similarities in the auditory processing of vocal communication in non-human animals and speech in humans. Therefore, these findings provide interesting new insight in the evolution of human language and auditory lateralization.
C1 [Leliveld, Lisette M. C.; Dupjan, Sandra; Puppe, Birger] Leibniz Inst Farm Anim Biol FBN, Inst Behav Physiol, Dummerstorf, Germany.
   [Tuchscherer, Armin] Leibniz Inst Farm Anim Biol FBN, Inst Genet & Biometry, Dummerstorf, Germany.
   [Puppe, Birger] Univ Rostock, Fac Agr & Environm Sci, Behav Sci, Rostock, Germany.
   [Leliveld, Lisette M. C.] Univ Milan, Dept Agr & Environm Sci, Milan, Italy.
RP Leliveld, LMC (corresponding author), Leibniz Inst Farm Anim Biol FBN, Inst Behav Physiol, Dummerstorf, Germany.; Leliveld, LMC (corresponding author), Univ Milan, Dept Agr & Environm Sci, Milan, Italy.
EM lisette.leliveld@unimi.it
FU Deutsche Forschungsgemeinschaft, DFGGerman Research Foundation (DFG) [LE
   3421/11, DU 1526/1-1]; German Federal Ministry of Food and Agriculture
   (BMEL) through the Federal Office for Agriculture and Food (BLE) under
   the Era-Net Anihwa project (SOUNDWEL) [2815ERA04D]; Open Access Fund of
   the Leibniz Institute for Farm Animal Biology (FBN)
FX This research was supported by the Deutsche Forschungsgemeinschaft, DFG
   [Grant Numbers LE 3421/11 and DU 1526/1-1]. LL was supported by the
   German Federal Ministry of Food and Agriculture (BMEL) through the
   Federal Office for Agriculture and Food (BLE) under the Era-Net Anihwa
   project (SOUNDWEL), Grant Number 2815ERA04D. The publication of this
   article was funded by the Open Access Fund of the Leibniz Institute for
   Farm Animal Biology (FBN).
CR Andrew Richard J., 2002, P94, DOI 10.1017/CBO9780511546372.005
   Beckers GJL, 2011, HUM BIOL, V83, P191, DOI 10.3378/027.083.0204
   Belin P, 2006, PHILOS T R SOC B, V361, P2091, DOI 10.1098/rstb.2006.1933
   Bodin C, 2020, PHILOS T R SOC B, V375, DOI 10.1098/rstb.2018.0386
   Boye M, 2005, EUR J NEUROSCI, V21, P1727, DOI 10.1111/j.1460-9568.2005.04005.x
   Briefer EF, 2012, J ZOOL, V288, P1, DOI 10.1111/j.1469-7998.2012.00920.x
   Buchanan TW, 2000, COGNITIVE BRAIN RES, V9, P227, DOI 10.1016/S0926-6410(99)00060-9
   Casseday JH, 1996, BRAIN BEHAV EVOLUT, V47, P311, DOI 10.1159/000113249
   Chan WY, 2011, ANIM BEHAV, V82, P767, DOI 10.1016/j.anbehav.2011.07.007
   Demaree Heath A, 2005, Behav Cogn Neurosci Rev, V4, P3, DOI 10.1177/1534582305276837
   Dubois J, 2009, CEREB CORTEX, V19, P414, DOI 10.1093/cercor/bhn097
   Dupjan S, 2011, PHYSIOL BEHAV, V103, P445, DOI 10.1016/j.physbeh.2011.03.017
   EHRET G, 1987, NATURE, V325, P249, DOI 10.1038/325249a0
   Fitch WT, 2005, BIOL PHILOS, V20, P193, DOI 10.1007/s10539-005-5597-1
   Fureix C, 2015, APPL ANIM BEHAV SCI, V171, P8, DOI 10.1016/j.applanim.2015.08.036
   Ghazanfar AA, 1999, TRENDS COGN SCI, V3, P377, DOI 10.1016/S1364-6613(99)01379-0
   HAUSER MD, 1994, P NATL ACAD SCI USA, V91, P3946, DOI 10.1073/pnas.91.9.3946
   Hook-Costigan MA, 1998, NEUROPSYCHOLOGIA, V36, P1265, DOI 10.1016/S0028-3932(98)00037-2
   Kanwal JS, 2007, FRONT BIOSCI-LANDMRK, V12, P4621, DOI 10.2741/2413
   KILEY M, 1972, Zeitschrift fuer Tierpsychologie, V31, P171
   Kubicek LF, 2012, INFANT MENT HEALTH J, V33, P553, DOI 10.1002/imhj.21364
   Leliveld LMC, 2016, PHYSIOL BEHAV, V157, P116, DOI 10.1016/j.physbeh.2016.02.002
   Leliveld LMC, 2013, APPL ANIM BEHAV SCI, V145, P1, DOI 10.1016/j.applanim.2013.02.002
   Leliveld LMG, 2017, PHYSIOL BEHAV, V181, P117, DOI 10.1016/j.physbeh.2017.09.010
   Lindell AK, 2006, NEUROPSYCHOL REV, V16, P131, DOI 10.1007/s11065-006-9011-9
   Manteuffel G, 2004, APPL ANIM BEHAV SCI, V88, P163, DOI 10.1016/j.applanim.2004.02.012
   Marchant JN, 2001, APPL ANIM BEHAV SCI, V72, P23, DOI 10.1016/S0168-1591(00)00190-8
   Murphy E, 2014, APPL ANIM BEHAV SCI, V159, P9, DOI 10.1016/j.applanim.2014.08.002
   Ocklenburg S, 2013, LATERALITY, V18, P1, DOI 10.1080/1357650X.2011.626561
   PETERSEN MR, 1984, BEHAV NEUROSCI, V98, P779, DOI 10.1037/0735-7044.98.5.779
   Poremba A, 2013, HEARING RES, V305, P31, DOI 10.1016/j.heares.2013.06.005
   Ratcliffe VF, 2014, CURR BIOL, V24, DOI 10.1016/j.cub.2014.10.030
   Rogers LJ, 2014, GENESIS, V52, P555, DOI 10.1002/dvg.22741
   Scheumann M, 2008, BMC BIOL, V6, DOI 10.1186/1741-7007-6-3
   Siniscalchi M, 2016, LATERALITY, V21, P215, DOI 10.1080/1357650X.2015.1116541
   Siniscalchi M, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003349
   Tervaniemi M, 2003, BRAIN RES REV, V43, P231, DOI 10.1016/j.brainresrev.2003.08.004
   Teufel C, 2010, BEHAV NEUROSCI, V124, P437, DOI 10.1037/a0019925
   Vallortigara G, 2000, BRAIN LANG, V73, P189, DOI 10.1006/brln.2000.2303
   von Borell E, 2007, PHYSIOL BEHAV, V92, P293, DOI 10.1016/j.physbeh.2007.01.007
   Wallez C, 2012, BEHAV BRAIN RES, V234, P69, DOI 10.1016/j.bbr.2012.06.004
   WEARY DM, 1995, ANIM BEHAV, V50, P1047, DOI 10.1016/0003-3472(95)80105-7
   Xue F, 2015, J EXP BIOL, V218, P740, DOI 10.1242/jeb.114694
   Yasin I, 2007, NEUROPSYCHOLOGIA, V45, P2718, DOI 10.1016/j.neuropsychologia.2007.04.009
   Zatorre RJ, 2008, PHILOS T R SOC B, V363, P1087, DOI 10.1098/rstb.2007.2161
   Zhang DD, 2017, NEUROSCI LETT, V658, P62, DOI 10.1016/j.neulet.2017.08.047
NR 46
TC 0
Z9 0
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5153
J9 FRONT BEHAV NEUROSCI
JI Front. Behav. Neurosci.
PD NOV 20
PY 2020
VL 14
AR 596758
DI 10.3389/fnbeh.2020.596758
PG 10
WC Behavioral Sciences; Neurosciences
SC Behavioral Sciences; Neurosciences & Neurology
GA PA1UA
UT WOS:000595413900001
PM 33328923
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Majorano, M
   Brondino, M
   Morelli, M
   Ferrari, R
   Lavelli, M
   Guerzoni, L
   Cuda, D
   Persici, V
AF Majorano, Marinella
   Brondino, Margherita
   Morelli, Marika
   Ferrari, Rachele
   Lavelli, Manuela
   Guerzoni, Letizia
   Cuda, Domenico
   Persici, Valentina
TI Preverbal Production and Early Lexical Development in Children With
   Cochlear Implants: A Longitudinal Study Following Pre-implanted Children
   Until 12 Months After Cochlear Implant Activation
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE Cochlear-implant; children; babbling; first words; latent growth
   analysis; language development
ID EARLY LANGUAGE-DEVELOPMENT; PROFOUNDLY DEAF-CHILDREN; EXPRESSIVE
   LANGUAGE; HEARING-LOSS; VOCAL DEVELOPMENT; SPEECH-PERCEPTION;
   YOUNG-CHILDREN; 1ST WORDS; PART II; AGE
AB Studies have shown that children vary in the trajectories of their language development after cochlear implant (CI) activation. The aim of the present study is to assess the preverbal and lexical development of a group of 20 Italian-speaking children observed longitudinally before CI activation and at three, 6 and 12 months after CI surgery (mean age at the first session: 17.5 months; SD: 8.3; and range: 10-35). The group of children with CIs (G-CI) was compared with two groups of normally-hearing (NH) children, one age-matched (G-NHA; mean age at the first session: 17.4 months; SD: 8.0; and range: 10-34) and one language-matched (G-NHL; n = 20; mean age at the first session: 11.2 months; SD: 0.4; and range: 11-12). The spontaneous interactions between children and their mothers during free-play were transcribed. Preverbal babbling production and first words were considered for each child. Data analysis showed significant differences in babbling and word production between groups, with a lower production of words in children with CIs compared to the G-NHA group and a higher production of babbling compared to the G-NHL children. Word production 1 year after activation was significantly lower for the children with CIs than for language-matched children only when maternal education was controlled for. Furthermore, latent class growth analysis showed that children with CIs belonged mainly to classes that exhibited a low level of initial production but also progressive increases over time. Babbling production had a statistically significant effect on lexical growth but not on class membership, and only for groups showing slower and constant increases. Results highlight the importance of preverbal vocal patterns for later lexical development and may support families and speech therapists in the early identification of risk and protective factors for language delay in children with CIs.
C1 [Majorano, Marinella; Brondino, Margherita; Morelli, Marika; Ferrari, Rachele; Lavelli, Manuela; Persici, Valentina] Univ Verona, Dept Human Sci, Verona, Italy.
   [Guerzoni, Letizia; Cuda, Domenico] Guglielmo da Saliceto Hosp, UO Otorhinolaryngol, Piacenza, Italy.
RP Majorano, M (corresponding author), Univ Verona, Dept Human Sci, Verona, Italy.
EM marinella.majorano@univr.it
OI Persici, Valentina/0000-0003-0475-104X
FU University of Verona; Cochlear S.r.l.
FX This work was supported by the University of Verona and Cochlear S.r.l.
   (Joint-Project Grant 2016).; The authors declare that this study
   received funding from Cochlear S.r.l. The funder was not involved in the
   study design, collection, analysis, interpretation of data, the writing
   of this article or the decision to submit it for publication.
CR Apuzzo Mah-Rya L., 1995, Seminars in Hearing, V16, P124, DOI 10.1055/s-0028-1083710
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   BLOOM K, 1987, J CHILD LANG, V14, P211, DOI 10.1017/S0305000900012897
   BRUNER JS, 1964, AM PSYCHOL, V19, P1, DOI 10.1037/h0044160
   Caselli MC, 2015, PRIMO VOCABOLARIO BA
   Clark J G, 1981, ASHA, V23, P493
   Davidson K, 2014, J DEAF STUD DEAF EDU, V19, P238, DOI 10.1093/deafed/ent045
   DesJardin JL, 2014, COMMUN DISORD Q, V35, P167, DOI 10.1177/1525740113518062
   Dettman SJ, 2007, EAR HEARING, V28, p11S, DOI 10.1097/AUD.0b013e31803153f8
   Duchesne L, 2009, J DEAF STUD DEAF EDU, V14, P465, DOI 10.1093/deafed/enp010
   Ertmer DJ, 2009, J SPEECH LANG HEAR R, V52, P1579, DOI 10.1044/1092-4388(2009/06-0145)
   Ertmer DJ, 2002, LANG SPEECH HEAR SER, V33, DOI 10.1044/0161-1461(2002/016)
   Ertmer DJ, 2001, J SPEECH LANG HEAR R, V44, P192, DOI 10.1044/1092-4388(2001/017)
   Fagan MK, 2015, J EXP CHILD PSYCHOL, V137, P125, DOI 10.1016/j.jecp.2015.04.005
   Ferguson C. A., 1992, PHONOLOGICAL DEV MOD
   Fry D. B., 1966, GENESIS LANGUAGE PSY, P187
   Geers A. E., 2006, ADV SPOKEN LANGUAGE, P244, DOI DOI 10.1001/JAMA.2010.451
   Geers AE, 2017, PEDIATRICS, V140, DOI 10.1542/peds.2016-3489
   Goldstein MH, 2008, PSYCHOL SCI, V19, P515, DOI 10.1111/j.1467-9280.2008.02117.x
   Gros-Louis J, 2006, INT J BEHAV DEV, V30, P509, DOI 10.1177/0165025406071914
   Hoff E, 2006, DEV REV, V26, P55, DOI 10.1016/j.dr.2005.11.002
   Hoff Erika, 2013, LANGUAGE DEV
   Jung J, 2020, J SPEECH LANG HEAR R, V63, P393, DOI 10.1044/2019_JSLHR-19-00158
   Jung T, 2008, SOC PERSONAL PSYCHOL, V2, P302, DOI 10.1111/j.1751-9004.2007.00054.x
   Keren-Portnoy T, 2009, J CHILD LANG, V36, P235, DOI 10.1017/S0305000908008933
   Kirk KI, 2002, ANN OTO RHINOL LARYN, V111, P69
   Kishon-Rabin L, 2005, EAR HEARING, V26, p17S, DOI 10.1097/00003446-200508001-00004
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2014, P NATL ACAD SCI USA, V111, P11238, DOI 10.1073/pnas.1410963111
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Lickliter R., 2004, HDB MULTISENSORY PRO, P643
   Lieu JEC, 2013, B-ENT, V9, P107
   Lindblom B, 2000, PHONETICA, V57, P297, DOI 10.1159/000028482
   Locke JL, 1997, BRAIN LANG, V58, P265, DOI 10.1006/brln.1997.1791
   Lofkvist U, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02808
   MacNeilage PF, 2000, SCIENCE, V288, P527, DOI 10.1126/science.288.5465.527
   MacWhinney B., 2000, COMPUT LINGUIST, VI, P657, DOI DOI 10.1162/C0LI.2000.26.4.657
   Majorano M, 2018, INT J LANG COMM DIS, V53, P70, DOI 10.1111/1460-6984.12327
   Majorano M, 2014, LANG LEARN DEV, V10, P179, DOI 10.1080/15475441.2013.829740
   Majorano M, 2014, INT J LANG COMM DIS, V49, P204, DOI 10.1111/1460-6984.12062
   Mayberry R, 2006, ENCY LANGUAGE LINGUI, P739
   McDaniel J, 2020, EAR HEARING, V41, P1064, DOI 10.1097/AUD.0000000000000829
   McGillion M, 2017, CHILD DEV, V88, P156, DOI 10.1111/cdev.12671
   Menyuk P., 1986, PRECURSORS EARLY SPE, P79
   Miyamoto RT, 1997, ACTA OTO-LARYNGOL, V117, P154, DOI 10.3109/00016489709117758
   Moeller MP, 2007, EAR HEARING, V28, P628, DOI 10.1097/AUD.0b013e31812564c9
   Moore JA, 2002, ANN OTO RHINOL LARYN, V111, P52
   Muthen B., 2004, HDB QUANTITATIVE MET, P346, DOI [10.4135/9781412986311.n19, DOI 10.4135/9781412986311.N19]
   Muthen LK, 2006, MPLUS USERS GUIDE
   Nicholas JG, 2007, J SPEECH LANG HEAR R, V50, P1048, DOI 10.1044/1092-4388(2007/073)
   Nott P, 2009, EAR HEARING, V30, P526, DOI 10.1097/AUD.0b013e3181a9ea14
   Nott P, 2009, EAR HEARING, V30, P541, DOI 10.1097/AUD.0b013e3181aa00ea
   Nylund KL, 2007, STRUCT EQU MODELING, V14, P535, DOI 10.1080/10705510701575396
   OLLER DK, 1988, CHILD DEV, V59, P441, DOI 10.1111/j.1467-8624.1988.tb01479.x
   Oller DK, 1999, J COMMUN DISORD, V32, P223, DOI 10.1016/S0021-9924(99)00013-1
   Olswang L., 1987, ASSESSING LINGUISTIC
   PAUL R, 1992, J SPEECH HEAR RES, V35, P99, DOI 10.1044/jshr.3501.99
   R Core Team, 2018, R LANG ENV STAT COMP
   Rescorla L, 2000, J CHILD LANG, V27, P643, DOI 10.1017/S0305000900004232
   Schauwers K, 2004, OTOL NEUROTOL, V25, P263, DOI 10.1097/00129492-200405000-00011
   Schramm B, 2010, Cochlear Implants Int, V11 Suppl 1, P375, DOI 10.1179/146701010X12671177990073
   Spencer Patricia E, 2004, J Deaf Stud Deaf Educ, V9, P395, DOI 10.1093/deafed/enh033
   Squire LR, 1996, P NATL ACAD SCI USA, V93, P13515, DOI 10.1073/pnas.93.24.13515
   Stoel-Gammon C., 1989, FIRST LANG, V9, P207, DOI DOI 10.1177/014272378900900607
   Stoel-Gammon C, 2011, J CHILD LANG, V38, P1, DOI 10.1017/S0305000910000425
   STOELGAMMON C, 1988, J SPEECH HEAR DISORD, V53, P302, DOI 10.1044/jshd.5303.302
   Svirsky MA, 2004, AUDIOL NEURO-OTOL, V9, P224, DOI 10.1159/000078392
   Svirsky MA, 2000, PSYCHOL SCI, V11, P153, DOI 10.1111/1467-9280.00231
   Szagun G, 2016, J CHILD LANG, V43, P505, DOI 10.1017/S0305000915000641
   THELEN E, 1981, DEV PSYCHOL, V17, P237, DOI 10.1037/0012-1649.17.3.237
   Tomblin JB, 2005, J SPEECH LANG HEAR R, V48, P853, DOI 10.1044/1092-4388(2005/059)
   Vihman M. M., 2014, PHONOLOGICAL DEV 1 2
   Vihman MM, 1996, PHONOLOGICAL DEV ORI
   Volling BL, 2019, MONOGR SOC RES CHILD, V84, P7, DOI 10.1111/mono.12404
   Walker EA, 2008, OTOL NEUROTOL, V29, P225, DOI 10.1097/mao.0b013e31815f6673
   Westermann G, 2004, BRAIN LANG, V89, P393, DOI 10.1016/S0093-934X(03)00345-6
   WHITEHURST GJ, 1991, J SPEECH HEAR RES, V34, P1121, DOI 10.1044/jshr.3405.1121
NR 77
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD NOV 19
PY 2020
VL 11
AR 591584
DI 10.3389/fpsyg.2020.591584
PG 15
WC Psychology, Multidisciplinary
SC Psychology
GA PA9ZK
UT WOS:000595987300001
PM 33329253
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Manker, J
AF Manker, Jonathan
TI The perceptual filtering of predictable coarticulation in exemplar
   memory
SO LABORATORY PHONOLOGY
LA English
DT Article
DE Exemplar theory; discrimination; speech perception; coarticulation;
   sound change
ID FUNDAMENTAL-FREQUENCY; IMITATION; REPRESENTATION
AB Exemplar models of word representations have remained ambivalent or impressionistic as to precisely what veridical auditory information is stored in individual word exemplars. Earlier models (Johnson, 1997b) suggest all perceived information was stored in memory, whereas more recent proposals (Pierrehumbert, 2002; Goldinger, 2007) suggest some degree of abstraction occurs in storing particular exemplars. Findings from the phonetic accommodation paradigm (Goldinger, 1998; Nielsen, 2011, etc.) suggest that the accumulation of new exemplars may drive the spread of sound change. At the same time, some theories of sound change suggest that perceptual biases serve as a starting point for change (Ohala, 1981, 1983). The current study investigates how perceptual biases, such as the predictability of coarticulation, can shape the contents of exemplars. The experimental results suggest that an expected phonetic alteration, such as f0 raising on vowels following voiceless consonants-a predictable coarticulatory effect-is more likely to undergo some degree of abstraction when stored in exemplar memory, whereas unexpected phonetic detail (e.g., f0 raising following voiced consonants) is more faithfully stored or maintained for longer in memory. These findings suggest perceptual biases that could shape pools of exemplars, leading to different expectations for conditioned versus unconditioned sound changes.
C1 [Manker, Jonathan] Rice Univ, Dept Linguist, Houston, TX 77005 USA.
RP Manker, J (corresponding author), Rice Univ, Dept Linguist, Houston, TX 77005 USA.
EM jonathan.manker@rice.edu
CR Beddor P., 2001, ROLE PERCEPTUAL PHEN, P55
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   GERSTMAN LJ, 1968, IEEE T ACOUST SPEECH, VAU16, P78, DOI 10.1109/TAU.1968.1161953
   Gill H., 1972, PAKHA SANJAM, V4, P1
   Goldinger S. D., 2007, 16 INT C PHON SCI, P49
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Goldinger SD, 2003, J PHONETICS, V31, P305, DOI 10.1016/S0095-4470(03)00030-5
   HAUTUS MJ, 1995, BEHAV RES METH INS C, V27, P46, DOI 10.3758/BF03203619
   Hawkins S, 2003, J PHONETICS, V31, P373, DOI 10.1016/j.wocn.2003.09.006
   Hawkins S, 2010, LAB PHONOLOGY, V10, P479
   Holt LL, 2001, J ACOUST SOC AM, V109, P764, DOI 10.1121/1.1339825
   HOMBERT JM, 1979, LANGUAGE, V55, P37, DOI 10.2307/412518
   HOMBERT JM, 1976, J ACOUST SOC AM, V59, pS72, DOI 10.1121/1.2002863
   HOUSE AS, 1953, J ACOUST SOC AM, V25, P105, DOI 10.1121/1.1906982
   Johnson K., 2007, EXPT APPROACHES PHON, P25
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Johnson K., 1997, OSU WORKING PAP LING, V50, P101
   KINGSTON J, 1994, LANGUAGE, V70, P419, DOI 10.2307/416481
   Kingston J., 2011, BLACKWELL COMPANION, DOI 10.1002/9781444335262.wbctp0097
   Kingston J., 1989, J ACOUST SOC AM, V85, pS149, DOI 10.1121/1.2026802
   Kingston J, 2008, J PHONETICS, V36, P28, DOI 10.1016/j.wocn.2007.02.001
   KLATT DH, 1979, J PHONETICS, V7, P279, DOI 10.1016/S0095-4470(19)31059-9
   LAHIRI A, 1991, COGNITION, V38, P245, DOI 10.1016/0010-0277(91)90008-R
   LEHISTE I, 1961, J ACOUST SOC AM, V33, P419, DOI 10.1121/1.1908681
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Luce PA, 2005, BLACKW HBK LINGUIST, P591
   MacMillan N. A., 2005, DETECTION THEORY USE
   Manker J, 2019, J PHONETICS, V75, P94, DOI 10.1016/j.wocn.2019.05.005
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P213, DOI 10.3758/BF03204377
   McLennan CT, 2005, J EXP PSYCHOL LEARN, V31, P306, DOI 10.1037/0278-7393.31.2.306
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007
   Nye PW, 2003, J PHONETICS, V31, P63, DOI 10.1016/S0095-4470(02)00072-4
   Ohala J., 1983, PRODUCTION SPEECH, P189, DOI [DOI 10.1007/978-1-4613-8202-7_9, 10.1007/978-1-4613-8202-7_9]
   Ohala John, 1981, PAPERS PARASESSION L, P178
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Ratliff M., 2015, OXFORD HDB HIST PHON, P245, DOI [10.1093/oxfordhb/9780199232819.013.021, DOI 10.1093/OXFORDHB/9780199232819.013.021]
   Shockley K, 2004, PERCEPT PSYCHOPHYS, V66, P422, DOI 10.3758/BF03194890
   Stanislaw H, 1999, BEHAV RES METH INS C, V31, P137, DOI 10.3758/BF03207704
   Stevens K.N., 1972, HUMAN COMMUNICATION
   Svantesson J.-O., 1991, AUSTROASIATIC LANGUA, P67
   Thurgood G., 1999, ANCIENT CHAM MODERN
   Tilsen S, 2009, J PHONETICS, V37, P276, DOI 10.1016/j.wocn.2009.03.004
   TRAUNMULLER H, 1981, J ACOUST SOC AM, V69, P1465, DOI 10.1121/1.385780
   Wolff E., 1987, LANGUES CULTURES BAS, P193
   Yu ACL, 2014, J ACOUST SOC AM, V136, P382, DOI 10.1121/1.4883380
   Yu ACL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0074746
   Yu ACL, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011950
   Zellou G, 2016, J ACOUST SOC AM, V140, P3560, DOI 10.1121/1.4966232
NR 50
TC 0
Z9 0
U1 0
U2 0
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD NOV 19
PY 2020
VL 11
IS 1
AR 20
DI 10.5334/labphon.240
PG 17
WC Linguistics; Language & Linguistics
SC Linguistics
GA OZ9VD
UT WOS:000595265600001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Morett, LM
   Landi, N
   Irwin, J
   McPartland, JC
AF Morett, Laura M.
   Landi, Nicole
   Irwin, Julia
   McPartland, James C.
TI N400 amplitude, latency, and variability reflect temporal integration of
   beat gesture and pitch accent during language processing
SO BRAIN RESEARCH
LA English
DT Article
DE N400; Evoked response variability; Beat gesture; Pitch accent; Temporal
   integration
ID NEURAL INTEGRATION; HAND GESTURES; INFORMATION-STRUCTURE; SEMANTIC
   INTEGRATION; MEANINGFUL GESTURES; SPEECH-PERCEPTION; ICONIC GESTURES;
   RESPONSES; FOCUS; WORD
AB This study examines how across-trial (average) and trial-by-trial (variability in) amplitude and latency of the N400 event-related potential (ERP) reflect temporal integration of pitch accent and beat gesture. Thirty native English speakers viewed videos of a talker producing sentences with beat gesture co-occurring with a pitch accented focus word (synchronous), beat gesture co-occurring with the onset of a subsequent non-focused word (asynchronous), or the absence of beat gesture (no beat). Across trials, increased amplitude and earlier latency were observed when beat gesture was temporally asynchronous with pitch accenting than when it was temporally synchronous with pitch accenting or absent. Moreover, temporal asynchrony of beat gesture relative to pitch accent increased trial-by-trial variability of N400 amplitude and latency and influenced the relationship between across-trial and trial-by-trial N400 latency. These results indicate that across-trial and trial-by-trial amplitude and latency of the N400 ERP reflect temporal integration of beat gesture and pitch accent during language comprehension, supporting extension of the integrated systems hypothesis of gesture-speech processing and neural noise theories to focus processing in typical adult populations.
C1 [Morett, Laura M.] Univ Alabama, Tuscaloosa, AL 35487 USA.
   [Landi, Nicole] Univ Connecticut, Haskins Labs, Mansfield, CT USA.
   [Irwin, Julia] Southern Connecticut State Univ, Haskins Labs, New Haven, CT USA.
   [McPartland, James C.] Yale Univ, New Haven, CT 06520 USA.
RP Morett, LM (corresponding author), Univ Alabama, Tuscaloosa, AL 35487 USA.
EM lmorett@ua.edu
RI landi, nicole/ABG-5374-2020
FU NIMH NIH HHSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute of Mental Health
   (NIMH) [R01 MH107426] Funding Source: Medline
CR Anderson S, 2010, J NEUROSCI, V30, P4922, DOI 10.1523/JNEUROSCI.0107-10.2010
   Baptista NI, 2018, SOC NEUROSCI-UK, V13, P495, DOI 10.1080/17470919.2017.1356744
   Bastiaansen M, 2010, J COGNITIVE NEUROSCI, V22, P1333, DOI 10.1162/jocn.2009.21283
   Biau E, 2018, LANG LEARN, V68, P102, DOI 10.1111/lang.12257
   Biau E, 2016, NEUROIMAGE, V132, P129, DOI 10.1016/j.neuroimage.2016.02.018
   Biau E, 2015, CORTEX, V68, P76, DOI 10.1016/j.cortex.2014.11.018
   Biau E, 2013, BRAIN LANG, V124, P143, DOI 10.1016/j.bandl.2012.10.008
   Birch S, 1997, MEM COGNITION, V25, P653, DOI 10.3758/BF03211306
   Birch SL, 2000, DISCOURSE PROCESS, V30, P285, DOI 10.1207/S15326950dp3003_4
   BOCK JK, 1983, MEM COGNITION, V11, P64, DOI 10.3758/BF03197663
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Bornkessel I, 2003, J EXP PSYCHOL LEARN, V29, P871, DOI 10.1037/0278-7393.29.5.871
   Borovsky A, 2012, LANG LEARN DEV, V8, P278, DOI 10.1080/15475441.2011.614893
   BREDART S, 1988, ACTA PSYCHOL, V67, P135, DOI 10.1016/0001-6918(88)90009-1
   Cowles HW, 2007, BRAIN LANG, V102, P228, DOI 10.1016/j.bandl.2007.04.004
   CUTLER A, 1979, COGNITION, V7, P49, DOI 10.1016/0010-0277(79)90010-6
   Dahan D, 2002, J MEM LANG, V47, P292, DOI 10.1016/S0749-596X(02)00001-3
   Davidson DJ, 2007, BRAIN RES, V1158, P81, DOI 10.1016/j.brainres.2007.04.082
   de Marchena A, 2010, AUTISM RES, V3, P311, DOI 10.1002/aur.159
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dick AS, 2009, HUM BRAIN MAPP, V30, P3509, DOI 10.1002/hbm.20774
   Dimitrova D, 2016, J COGNITIVE NEUROSCI, V28, P1255, DOI 10.1162/jocn_a_00963
   Dimitrova DV, 2012, J COGNITIVE NEUROSCI, V24, P2400, DOI 10.1162/jocn_a_00302
   Dinstein I, 2015, TRENDS COGN SCI, V19, P322, DOI 10.1016/j.tics.2015.04.005
   Dinstein I, 2012, NEURON, V75, P981, DOI 10.1016/j.neuron.2012.07.026
   Drijvers L, 2018, HUM BRAIN MAPP, V39, P2075, DOI 10.1002/hbm.23987
   Duann JR, 2002, NEUROIMAGE, V15, P823, DOI 10.1006/nimg.2001.1049
   Esteve-Gibert N, 2015, INFANT BEHAV DEV, V38, P126, DOI 10.1016/j.infbeh.2014.12.016
   Esteve-Gibert N, 2013, J SPEECH LANG HEAR R, V56, P850, DOI 10.1044/1092-4388(2012/12-0049)
   Garrett DD, 2011, J NEUROSCI, V31, P4496, DOI 10.1523/JNEUROSCI.5641-10.2011
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Green A, 2009, HUM BRAIN MAPP, V30, P3309, DOI 10.1002/hbm.20753
   Habets B, 2011, J COGNITIVE NEUROSCI, V23, P1845, DOI 10.1162/jocn.2010.21462
   Haigh SM, 2015, J AUTISM DEV DISORD, V45, P1176, DOI 10.1007/s10803-014-2276-6
   Hancock R, 2017, TRENDS COGN SCI, V21, P434, DOI 10.1016/j.tics.2017.03.008
   He Y., 2020, BIORXIV
   He YF, 2018, BRAIN STRUCT FUNCT, V223, P3073, DOI 10.1007/s00429-018-1674-5
   He YF, 2015, NEUROPSYCHOLOGIA, V72, P27, DOI 10.1016/j.neuropsychologia.2015.04.018
   Holle H, 2008, NEUROIMAGE, V39, P2010, DOI 10.1016/j.neuroimage.2007.10.055
   Holle H, 2007, J COGNITIVE NEUROSCI, V19, P1175, DOI 10.1162/jocn.2007.19.7.1175
   Holle H, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00074
   Holler J, 2019, TRENDS COGN SCI, V23, P639, DOI 10.1016/j.tics.2019.05.006
   Hornickel J, 2013, J NEUROSCI, V33, P3500, DOI 10.1523/JNEUROSCI.4205-12.2013
   Hubbard AL, 2009, HUM BRAIN MAPP, V30, P1028, DOI 10.1002/hbm.20565
   Kelly SD, 2004, BRAIN LANG, V89, P253, DOI 10.1016/S0093-934X(03)00335-3
   Kelly SD, 2008, LANG LINGUIST COMPAS, V2, DOI 10.1111/j.1749-818x.2008.00067.x
   Kelly SD, 2010, PSYCHOL SCI, V21, P260, DOI 10.1177/0956797609357327
   Kelly SD, 2010, J COGNITIVE NEUROSCI, V22, P683, DOI 10.1162/jocn.2009.21254
   Kielar A, 2014, J COGNITIVE NEUROSCI, V26, P2840, DOI 10.1162/jocn_a_00670
   Krahmer E, 2007, J MEM LANG, V57, P396, DOI 10.1016/j.jml.2007.06.005
   Kushch O, 2016, P 8 INT C SPEECH PRO, V8, P922
   Kushch O, 2018, LANG COGN NEUROSCI, V33, P992, DOI 10.1080/23273798.2018.1435894
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Ladd DR, 2008, CAMB STUD LINGUIST, V79, P1
   Lau EF, 2013, J COGNITIVE NEUROSCI, V25, P484, DOI 10.1162/jocn_a_00328
   Leonard T, 2011, LANG COGNITIVE PROC, V26, P1457, DOI 10.1080/01690965.2010.500218
   Llanes-Coromina J, 2018, J EXP CHILD PSYCHOL, V172, P168, DOI 10.1016/j.jecp.2018.02.004
   Loehr D, 2012, J LAB PHONOL, V3, P71, DOI [DOI 10.1515/lp-2012-0006, DOI 10.1515/LP-2012-0006]
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   Luo Y, 2010, NEUROSCIENCE, V169, P654, DOI 10.1016/j.neuroscience.2010.05.032
   Malins JG, 2018, J NEUROSCI, V38, P2981, DOI 10.1523/JNEUROSCI.0907-17.2018
   MCNEILL D, 1985, PSYCHOL REV, V92, P350, DOI 10.1037/0033-295X.92.3.350
   McNeill D., 2006, ENCY LANGUAGE LINGUI, P58, DOI DOI 10.1016/B0-08-044854-2/00798-7
   McNeill D., 1992, HAND MIND
   McNeill D., 2005, GESTURE THOUGHT
   Milne E, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00051
   Morett L. M., CONTRAST IS EYE BEHO
   Morett L. M., EYE SEE WHAT YOURE S
   Morett LM, 2019, MEM COGNITION, V47, P1515, DOI 10.3758/s13421-019-00945-1
   Morett LM, 2016, J AUTISM DEV DISORD, V46, P998, DOI 10.1007/s10803-015-2645-9
   MORRELSAMUELS P, 1992, J EXP PSYCHOL LEARN, V18, P615, DOI 10.1037/0278-7393.18.3.615
   NOOTEBOOM SG, 1987, J ACOUST SOC AM, V82, P1512, DOI 10.1121/1.395195
   Nunez PL., 2006, ELECT FIELDS BRAIN N
   Obermeier C, 2015, J COGNITIVE NEUROSCI, V27, P292, DOI 10.1162/jocn_a_00688
   Obermeier C, 2011, J COGNITIVE NEUROSCI, V23, P1648, DOI 10.1162/jocn.2010.21498
   Ozyurek A, 2007, J COGNITIVE NEUROSCI, V19, P605, DOI 10.1162/jocn.2007.19.4.605
   Power AJ, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00777
   Prieto P., 2018, P 9 INT C SPEECH PRO, P201, DOI [10.21437/SpeechProsody.2018-41, DOI 10.21437/SPEECHPROSODY.2018-41]
   Regel S, 2011, J COGNITIVE NEUROSCI, V23, P277, DOI 10.1162/jocn.2010.21411
   Roustan B., 2010, SPEECH PROSODY 2010
   Rusiewicz HL, 2014, SPEECH COMMUN, V57, P283, DOI 10.1016/j.specom.2013.06.004
   Rusiewicz HL, 2013, J SPEECH LANG HEAR R, V56, P458, DOI 10.1044/1092-4388(2012/11-0283)
   Schumacher PB, 2010, NEUROREPORT, V21, P618, DOI 10.1097/WNR.0b013e328339874a
   Schurger A, 2015, P NATL ACAD SCI USA, V112, pE2083, DOI 10.1073/pnas.1418730112
   Shattuck-Hufnagel S., 2016, P 8 INT C SPEECH PRO, P836, DOI [10.21437/SpeechProsody.2016, DOI 10.21437/SPEECHPROSODY.2016-171]
   Shattuck-Hufnagel S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01514
   Silverman LB, 2010, COGNITION, V115, P380, DOI 10.1016/j.cognition.2010.01.002
   Simon DM, 2016, NEUROSCI BIOBEHAV R, V68, P848, DOI 10.1016/j.neubiorev.2016.07.016
   Skipper JI, 2007, BRAIN LANG, V101, P260, DOI 10.1016/j.bandl.2007.02.008
   Skipper JI, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0297
   Ter Bekke M., 2020, PREDICTIVE POTENTIAL
   van Berkum JJA, 1999, J COGNITIVE NEUROSCI, V11, P657, DOI 10.1162/089892999563724
   Wang L, 2014, COGN NEURODYNAMICS, V8, P353, DOI 10.1007/s11571-014-9305-1
   Wang L, 2013, NEUROPSYCHOLOGIA, V51, P2847, DOI 10.1016/j.neuropsychologia.2013.09.027
   Wang L, 2012, HUM BRAIN MAPP, V33, P2898, DOI 10.1002/hbm.21410
   Willems RM, 2007, CEREB CORTEX, V17, P2322, DOI 10.1093/cercor/bhl141
   Willems RM, 2009, NEUROIMAGE, V47, P1992, DOI 10.1016/j.neuroimage.2009.05.066
   Wu YC, 2005, PSYCHOPHYSIOLOGY, V42, P654, DOI 10.1111/j.1469-8986.2005.00356.x
   Wu YC, 2007, BRAIN LANG, V101, P234, DOI 10.1016/j.bandl.2006.12.003
   Xue G, 2010, SCIENCE, V330, P97, DOI 10.1126/science.1193125
   Zellin M, 2011, INT J PSYCHOPHYSIOL, V81, P133, DOI 10.1016/j.ijpsycho.2011.05.009
   Zhang Y., 2020, BIORXIV
NR 102
TC 0
Z9 0
U1 5
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0006-8993
EI 1872-6240
J9 BRAIN RES
JI Brain Res.
PD NOV 15
PY 2020
VL 1747
AR 147059
DI 10.1016/j.brainres.2020.147059
PG 15
WC Neurosciences
SC Neurosciences & Neurology
GA NR3EY
UT WOS:000571446800003
PM 32818527
DA 2021-02-24
ER

PT J
AU Berti, LC
   Guilherme, J
   Esperandino, C
   de Oliveira, AM
AF Berti, Larissa Cristina
   Guilherme, Jhulya
   Esperandino, Cassio
   de Oliveira, Aline Mara
TI Relationship between speech production and perception in children with
   Speech Sound Disorders
SO JOURNAL OF PORTUGUESE LINGUISTICS
LA English
DT Article
DE speech perception; speech production; speech sound disorder
AB This study investigated the relationship between speech production and perception in children with Speech Sound Disorders (SSD). We hypothesized that there might be a positive correlation and the difference between speech and perceptual data for children with SSD; and that the positive correlation between speech production and speech perception errors might depend on the phonological class involved. Thirty-three children with SSD were evaluated during a speech production task and a phonological contrast identification test. The Percentage of Correct Consonant-Revised (PCC-R) and the Percentage of Correct Identification (PCI) were calculated for each child. The results of the paired t-test showed a higher perception performance mean (PCI = 87.41%) when compared to the production performance mean (PCC-R = 74.97%). The overall results of Pearson's correlation test was also statistically significant, showing a moderate, positive correlation (r = 0.49) between production and perception performances in children with SSD. The results of the correlation analyses between speech production and speech perception errors by class show that only in the fricative class, the correlation was statistically moderately significant (r = 0.52). Stops and sonorants showed no correlation. The results confirmed the relationship between speech production and speech perception, but speech perception does not mirror speech production. The positive correlation between speech production and speech perception errors depends on the phonological class.
C1 [Berti, Larissa Cristina] Univ Estadual Paulista, Sao Paulo State Univ, Dept Speech Language & Hearing Sci, Sao Paulo, SP, Brazil.
   [Guilherme, Jhulya; Esperandino, Cassio] Univ Estadual Paulista, Sao Paulo State Univ, Programa Posgrad Fonoaudiol, Sao Paulo, SP, Brazil.
   [de Oliveira, Aline Mara] Univ Fed Santa Catarina, Dept Speech Language & Hearing Sci, Santa Catarina Fed Univ, Florianopolis, SC, Brazil.
RP Berti, LC (corresponding author), Univ Estadual Paulista, Sao Paulo State Univ, Dept Speech Language & Hearing Sci, Sao Paulo, SP, Brazil.
EM larissa.berti@unesp.br
OI Guilherme, Jhulya/0000-0003-3353-0051
FU FAPESP -Fundacao de Amparo a Pesquisa do Estado de Sao PauloFundacao de
   Amparo a Pesquisa do Estado de Sao Paulo (FAPESP) [2016/08775-0]; CNPq -
   Conselho Nacional de Desenvolvimento Cientifico e TecnologicoNational
   Council for Scientific and Technological Development (CNPq)
   [303439/2016-5, 429025/2018-1]; Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior - Brasil (CAPES)CAPES [001]
FX To the FAPESP -Fundacao de Amparo a Pesquisa do Estado de Sao Paulo
   (grant number 2016/08775-0) and to the CNPq - Conselho Nacional de
   Desenvolvimento Cientifico e Tecnologico (grants number 303439/2016-5;
   429025/2018-1) for the granted funding to carry out the research whose
   results were reported in the present article. This study was also
   financed in part by the Coordenacao de Aperfeicoamento de Pessoal de
   Nivel Superior - Brasil (CAPES) - Finance Code 001.
CR American Speech-Language-Hearing Association, 2018, SPEECH SOUND DIS ART
   Andre C., 2009, PERCEVAL PERCEPTION
   Barbosa P. A., 2004, J INT PHON ASSOC, V34, P227, DOI DOI 10.1017/S0025100304001756
   Berti L, 2016, CLIN LINGUIST PHONET, V30, P131, DOI 10.3109/02699206.2015.1116607
   Berti Larissa Cristina, 2017, Audiol., Commun. Res., V22, pe1727, DOI 10.1590/2317-6431-2016-1727
   BERTI Larissa Cristina, 2017, Alfa, rev. linguíst. (São José Rio Preto), V61, P81, DOI 10.1590/1981-5794-1704-4
   Berti Larissa Cristina, 2009, Rev. soc. bras. fonoaudiol., V14, P305, DOI 10.1590/S1516-80342009000300005
   Boersma Paul, 2019, PRAAT DOING PHONETIC
   Burnham D., 2002, INTEGRATED VIEW LANG, P281
   Cabbage KL, 2016, SPEECH COMMUN, V82, P14, DOI 10.1016/j.specom.2016.05.002
   Cagliari LC, 2009, ELEMENTOS FONETICA P
   Dodd B, 2008, CLIN LINGUIST PHONET, V22, P69, DOI 10.1080/02699200701660100
   Edwards M. L., 1974, J CHILD LANG, V1, P205, DOI [DOI 10.1017/S0305000900000659, 10.1017/S0305000900000659]
   Farquharson K, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01708
   Gibbon FE, 1999, J SPEECH LANG HEAR R, V42, P382, DOI 10.1044/jslhr.4202.382
   Goozee J, 2007, INT J LANG COMM DIS, V42, P703, DOI 10.1080/13682820601104960
   Hearnshaw S, 2018, J COMMUN DISORD, V71, P61, DOI 10.1016/j.jcomdis.2017.12.004
   HOWARD S, 2010, HDB LANGUAGE SPEECH, V49, P339
   Ingram D., 1997, PERSPECTIVES APPL PH, P19
   Johnson K., 1997, ACOUSTIC AUDITORY PH
   Kent R.D., 1992, ACOUSTIC ANAL SPEECH
   Lewis BA, 2006, J COMMUN DISORD, V39, P139, DOI 10.1016/j.jcomdis.2005.11.003
   Munson B, 2005, TOP LANG DISORD, V25, P190, DOI 10.1097/00011363-200507000-00003
   Nagao K., 2012, 13 ANN C INT SPEECH
   Nijland L, 2009, CLIN LINGUIST PHONET, V23, P222, DOI 10.1080/02699200802399947
   Panneton R, 2012, SPRINGER HANDB AUDIT, V42, P197, DOI 10.1007/978-1-4614-1421-6_7
   Patah Luciane Kalil, 2008, Rev. CEFAC, V10, P158, DOI 10.1590/S1516-18462008000200004
   RVACHEW S, 2013, COMMUNICATION DISORD, V1, P61
   Shriberg LD, 1997, J SPEECH LANG HEAR R, V40, P708, DOI 10.1044/jslhr.4004.708
   Silva T. C., 1999, FONETICA FONOLOGIA P
NR 30
TC 0
Z9 0
U1 1
U2 1
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1645-4537
EI 2397-5563
J9 J PORT LINGUIST
JI J. Port. Linguist.
PD NOV 12
PY 2020
VL 19
BP 1
EP 13
AR 13
DI 10.5334/jpl.244
PG 13
WC Language & Linguistics
SC Linguistics
GA OZ8OJ
UT WOS:000595178400001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Aubanel, V
   Schwartz, JL
AF Aubanel, Vincent
   Schwartz, Jean-Luc
TI The role of isochrony in speech perception in noise
SO SCIENTIFIC REPORTS
LA English
DT Article
ID NEURONAL OSCILLATIONS; ENTRAINMENT; RHYTHM; PHASE; COMPREHENSION;
   RESPONSES; PATTERNS; TRACKING
AB The role of isochrony in speech-the hypothetical division of speech units into equal duration intervals-has been the subject of a long-standing debate. Current approaches in neurosciences have brought new perspectives in that debate through the theoretical framework of predictive coding and cortical oscillations. Here we assess the comparative roles of naturalness and isochrony in the intelligibility of speech in noise for French and English, two languages representative of two well-established contrastive rhythm classes. We show that both top-down predictions associated with the natural timing of speech and to a lesser extent bottom-up predictions associated with isochrony at a syllabic timescale improve intelligibility. We found a similar pattern of results for both languages, suggesting that temporal characterisation of speech from different rhythm classes could be unified around a single core speech unit, with neurophysiologically defined duration and linguistically anchored temporal location. Taken together, our results suggest that isochrony does not seem to be a main dimension of speech processing, but may be a consequence of neurobiological processing constraints, manifesting in behavioural performance and ultimately explaining why isochronous stimuli occupy a particular status in speech and human perception in general.
C1 [Aubanel, Vincent; Schwartz, Jean-Luc] Univ Grenoble Alpes, GIPSA Lab, CNRS, Grenoble, France.
RP Aubanel, V (corresponding author), Univ Grenoble Alpes, GIPSA Lab, CNRS, Grenoble, France.
EM vincent.aubanel@gipsa-lab.fr
FU European Research Council under the European CommunityEuropean Research
   Council (ERC) [339152]
FX This work was supported by the European Research Council under the
   European Community's Seventh Framework Program (FP7/2007-2013 Grant
   Agreement No. 339152, "Speech Unit(e)s"). We thank Christine Nies for
   her help in collecting data and Silvain Gerber for assistance with
   statistical analysis.
CR Abercrombie David, 1967, ELEMENTS GEN PHONETI
   Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   Arvaniti A, 2012, J PHONETICS, V40, P351, DOI 10.1016/j.wocn.2012.02.003
   Aubanel V, 2017, MAVA CORPUS, DOI [10.4227/139/59a4c21a896a3, DOI 10.4227/139/59A4C21A896A3]
   Aubanel V, 2020, SPEECH COMMUN, V124, P68, DOI 10.1016/j.specom.2020.07.004
   Aubanel V, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00430
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bishop GH, 1933, AM J PHYSIOL, V103, P213
   Busch NA, 2009, J NEUROSCI, V29, P7869, DOI 10.1523/JNEUROSCI.0113-09.2009
   Cason N, 2015, ACTA PSYCHOL, V155, P43, DOI 10.1016/j.actpsy.2014.12.002
   Cason N, 2012, NEUROPSYCHOLOGIA, V50, P2652, DOI 10.1016/j.neuropsychologia.2012.07.018
   Cooke M, 2019, COMPUT SPEECH LANG, V55, P26, DOI 10.1016/j.csl.2018.10.003
   Cummins F, 2015, BLACKW HBK LINGUIST, P158
   Cummins F, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00364
   DAUER RM, 1983, J PHONETICS, V11, P51, DOI 10.1016/S0095-4470(19)30776-4
   Demol M., 2005, INT C SPEECH COMP SP, P163
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Ding N, 2013, J NEUROSCI, V33, P5728, DOI 10.1523/JNEUROSCI.5297-12.2013
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Fontolan L, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5694
   Ghitza O, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00652
   Ghitza O, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00138
   Ghitza O, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00238
   Giraud AL, 2012, SPRINGER HANDB AUDIT, V43, P225, DOI 10.1007/978-1-4614-2314-0_9
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Goldman Philippe, 2011, P INT, P3233
   Greenberg S, 2003, J PHONETICS, V31, P465, DOI 10.1016/j.wocn.2003.09.005
   Greenberg S, 1999, SPEECH COMMUN, V29, P159, DOI 10.1016/S0167-6393(99)00050-3
   Haegens S, 2018, NEUROSCI BIOBEHAV R, V86, P150, DOI 10.1016/j.neubiorev.2017.12.002
   Hickok G, 2015, PSYCHOL SCI, V26, P1006, DOI 10.1177/0956797615576533
   Hothorn T, 2008, BIOMETRICAL J, V50, P346, DOI 10.1002/bimj.200810425
   Hyafil A, 2015, ELIFE, V4, DOI 10.7554/eLife.06213
   Jaeger B, 2017, R2GLMM COMPUTES R SQ
   James A. Lloyd, 1940, SPEECH SIGNALS TELEP
   Jun SA, 2000, TEXT SPEECH LANG TEC, V15, P209
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735
   Lehiste Ilse, 1977, J PHONETICS, V5, P253, DOI 10.1016/S0095-4470(19)31139-8
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   MEHLER J, 1981, J VERB LEARN VERB BE, V20, P298, DOI 10.1016/S0022-5371(81)90450-3
   MORTON J, 1976, PSYCHOL REV, V83, P405, DOI 10.1037/0033-295X.83.5.405
   Nespor M, 2007, STUD GENERAT GRAMM, V28, P1
   Nozaradan S, 2011, J NEUROSCI, V31, P10234, DOI 10.1523/JNEUROSCI.0411-11.2011
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Pefkou M, 2017, J NEUROSCI, V37, P7930, DOI 10.1523/JNEUROSCI.2882-16.2017
   Pike Kenneth, 1945, INTONATION AM ENGLIS
   Rimmele JM, 2018, TRENDS COGN SCI, V22, P870, DOI 10.1016/j.tics.2018.08.003
   Schroeder CE, 2010, CURR OPIN NEUROBIOL, V20, P172, DOI 10.1016/j.conb.2010.02.010
   Schroeder CE, 2009, TRENDS NEUROSCI, V32, P9, DOI 10.1016/j.tins.2008.09.012
   Scott S. K, 1993, THESIS
   Steele R, 1779, ESSAY ESTABLISHING M
   Strauss A., BOTTOM UP TOP UNPUB
   ten Oever S, 2015, P NATL ACAD SCI USA, V112, P15833, DOI 10.1073/pnas.1517519112
   van Atteveldt N, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01663
NR 55
TC 0
Z9 0
U1 2
U2 2
PU NATURE RESEARCH
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD NOV 11
PY 2020
VL 10
IS 1
AR 19580
DI 10.1038/s41598-020-76594-1
PG 12
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA OZ3IP
UT WOS:000594824100007
PM 33177590
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Gao, X
   Yan, TT
   Huang, T
   Li, XL
   Zhang, YX
AF Gao, Xiang
   Yan, Tingting
   Huang, Ting
   Li, Xiaoli
   Zhang, Yu-Xuan
TI Speech in noise perception improved by training fine auditory
   discrimination: far and applicable transfer of perceptual learning
SO SCIENTIFIC REPORTS
LA English
DT Article
ID INTERAURAL TIME DIFFERENCES; FUNDAMENTAL-FREQUENCY; VOICE SEGREGATION;
   RECEPTIVE-FIELDS; COCKTAIL-PARTY; PLASTICITY; PITCH; IDENTIFICATION;
   DIFFERENCE; PATTERNS
AB A longstanding focus of perceptual learning research is learning specificity, the difficulty for learning to transfer to tasks and situations beyond the training setting. Previous studies have focused on promoting transfer across stimuli, such as from one sound frequency to another. Here we examined whether learning could transfer across tasks, particularly from fine discrimination of sound features to speech perception in noise, one of the most frequently encountered perceptual challenges in real life. Separate groups of normal-hearing listeners were trained on auditory interaural level difference (ILD) discrimination, interaural time difference (ITD) discrimination, and fundamental frequency (F-0) discrimination with non-speech stimuli delivered through headphones. While ITD training led to no improvement, both ILD and F-0 training produced learning as well as transfer to speech-in-noise perception when noise differed from speech in the trained feature. These training benefits did not require similarity of task or stimuli between training and application settings, construing far and wide transfer. Thus, notwithstanding task specificity among basic perceptual skills such as discrimination of different sound features, auditory learning appears readily transferable between these skills and their "upstream" tasks utilizing them, providing an effective approach to improving performance in challenging situations or challenged populations.
C1 [Gao, Xiang; Yan, Tingting; Huang, Ting; Li, Xiaoli; Zhang, Yu-Xuan] Beijing Normal Univ, IDG McGovern Inst Brain Res, State Key Lab Cognit Neurosci & Learning, Beijing 100875, Peoples R China.
RP Zhang, YX (corresponding author), Beijing Normal Univ, IDG McGovern Inst Brain Res, State Key Lab Cognit Neurosci & Learning, Beijing 100875, Peoples R China.
EM zhangyuxuan@bnu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [91432102]; State Key Development Program for
   Basic Research of ChinaState Key Development Program for Basic Research
   of China [2014CB846101]
FX The work was funded by the National Natural Science Foundation of China
   (91432102) and State Key Development Program for Basic Research of China
   (2014CB846101).
CR Ahissar M, 2004, TRENDS COGN SCI, V8, P457, DOI 10.1016/j.tics.2004.08.011
   Amitay S, 2005, PERCEPT PSYCHOPHYS, V67, P691, DOI 10.3758/BF03193525
   Amitay S, 2014, VISION RES, V99, P69, DOI 10.1016/j.visres.2013.11.006
   [Anonymous], 2016, PRAAT DOING PHONETIC
   ASSMANN PF, 1990, J ACOUST SOC AM, V88, P680, DOI 10.1121/1.399772
   Bejjanki VR, 2014, P NATL ACAD SCI USA, V111, P16961, DOI 10.1073/pnas.1417056111
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Bronkhorst AW, 2015, ATTEN PERCEPT PSYCHO, V77, P1465, DOI 10.3758/s13414-015-0882-9
   Brown CA, 2010, HEARING RES, V266, P52, DOI 10.1016/j.heares.2009.08.011
   Burk MH, 2008, J SPEECH LANG HEAR R, V51, P759, DOI 10.1044/1092-4388(2008/054)
   Carcagno S, 2011, JARO-J ASSOC RES OTO, V12, P503, DOI 10.1007/s10162-011-0266-3
   Carcagno S, 2011, JARO-J ASSOC RES OTO, V12, P89, DOI 10.1007/s10162-010-0236-1
   Garcia MC, 2006, SEEKING REFUGE: CENTRAL AMERICAN MIGRATION TO MEXICO, THE UNITED STATES, AND CANADA, P119
   CULLING JF, 1993, J ACOUST SOC AM, V93, P3454, DOI 10.1121/1.405675
   Culling JF, 2004, J ACOUST SOC AM, V116, P1057, DOI 10.1121/1.1772396
   de Cheveigne A, 1998, J ACOUST SOC AM, V103, P1261, DOI 10.1121/1.423232
   Deroche MLD, 2014, J ACOUST SOC AM, V136, P1225, DOI 10.1121/1.4890649
   Deroche MLD, 2013, J ACOUST SOC AM, V134, pEL465, DOI 10.1121/1.4826152
   Deroche MLD, 2011, J ACOUST SOC AM, V130, P2855, DOI 10.1121/1.3643812
   Dosher BA, 1998, P NATL ACAD SCI USA, V95, P13988, DOI 10.1073/pnas.95.23.13988
   Edmonds BA, 2006, J ACOUST SOC AM, V120, P1539, DOI 10.1121/1.2228573
   Fritz J, 2003, NAT NEUROSCI, V6, P1216, DOI 10.1038/nn1141
   Fritz JB, 2005, J NEUROSCI, V25, P7623, DOI 10.1523/JNEUROSCI.1318-05.2005
   Gallun FJ, 2005, J ACOUST SOC AM, V118, P1614, DOI 10.1121/1.1984876
   Glyde H, 2013, J ACOUST SOC AM, V134, P2937, DOI 10.1121/1.4817930
   Gold J, 1999, NATURE, V402, P176
   Green CS, 2012, CURR BIOL, V22, pR197, DOI 10.1016/j.cub.2012.02.012
   Grimault N, 2002, PERCEPT PSYCHOPHYS, V64, P189, DOI 10.3758/BF03195785
   Guest DR, 2019, J ACOUST SOC AM, V145, P3011, DOI 10.1121/1.5102169
   Hawley ML, 2004, J ACOUST SOC AM, V115, P833, DOI 10.1121/1.1639908
   Hopkins K, 2008, J ACOUST SOC AM, V123, P1140, DOI 10.1121/1.2824018
   Horton JC, 2017, GRAEF ARCH CLIN EXP, V255, P435, DOI 10.1007/s00417-016-3580-y
   Irvine D. R. F, 2018, HEAR RES
   Irvine DRF, 2018, HEARING RES, V362, P61, DOI 10.1016/j.heares.2017.10.011
   Kattner F, 2017, CURR BIOL, V27, P840, DOI 10.1016/j.cub.2017.01.046
   Kawato M, 2014, VISION RES, V99, P1, DOI 10.1016/j.visres.2014.05.002
   Kleiner M, 2007, PERCEPTION, V36, P14
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Li W, 2016, ANNU REV VIS SCI, V2, P109, DOI 10.1146/annurev-vision-111815-114351
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Lu ZL, 2010, VISION RES, V50, P375, DOI 10.1016/j.visres.2009.08.027
   Miyazono H, 2010, J ACOUST SOC AM, V128, P3649, DOI 10.1121/1.3504713
   Moon IJ, 2014, J NEUROSCI, V34, P12145, DOI 10.1523/JNEUROSCI.1025-14.2014
   Moore BCJ, 2009, J ACOUST SOC AM, V125, P3214, DOI 10.1121/1.3106135
   Mossbridge JA, 2008, LEARN MEMORY, V15, P13, DOI 10.1101/lm.573608
   Ortiz JA, 2010, EXP BRAIN RES, V201, P441, DOI 10.1007/s00221-009-2053-5
   Oxenham AJ, 2009, J ACOUST SOC AM, V125, P457, DOI 10.1121/1.3021299
   Rowan D, 2007, INT J AUDIOL, V46, P585, DOI 10.1080/14992020701524828
   Rudner M, 2010, AGING NEUROPSYCHOL C, V17, P360, DOI 10.1080/13825580903311832
   SABERI K, 1995, J ACOUST SOC AM, V98, P1803, DOI 10.1121/1.413379
   Sagi D, 2011, VISION RES, V51, P1552, DOI 10.1016/j.visres.2010.10.019
   Shibata K, 2014, ANN NY ACAD SCI, V1316, P18, DOI 10.1111/nyas.12419
   Simpson SA, 2005, J ACOUST SOC AM, V118, P2775, DOI 10.1121/1.2062650
   Webb BS, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0001323
   Wright BA, 2001, P NATL ACAD SCI USA, V98, P12307, DOI 10.1073/pnas.211220498
   Wright BA, 2010, J NEUROSCI, V30, P12868, DOI 10.1523/JNEUROSCI.0487-10.2010
   Wright BA, 2009, PHILOS T R SOC B, V364, P301, DOI 10.1098/rstb.2008.0262
   Xiao LQ, 2008, CURR BIOL, V18, P1922, DOI 10.1016/j.cub.2008.10.030
   Zhang YD, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0153054
   Zhang YX, 2007, J ACOUST SOC AM, V121, P2207, DOI 10.1121/1.2434758
   Zhang YX, 2009, J ACOUST SOC AM, V126, P1349, DOI 10.1121/1.3177267
   Zurek P. M, 1983, J ACOUST SOC AM, V71
NR 62
TC 0
Z9 0
U1 1
U2 1
PU NATURE RESEARCH
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD NOV 9
PY 2020
VL 10
IS 1
AR 19320
DI 10.1038/s41598-020-76295-9
PG 12
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA OZ0LI
UT WOS:000594627400009
PM 33168921
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Moreno-Torres, I
   Nava, E
AF Moreno-Torres, Ignacio
   Nava, Enrique
TI Consonant and vowel articulation accuracy in younger and middle-aged
   Spanish healthy adults
SO PLOS ONE
LA English
DT Article
ID SPEAKING CHILDREN; SPEECH; PERCEPTION; INTELLIGIBILITY; RECOGNITION;
   MODEL
AB Children acquire vowels earlier than consonants, and the former are less vulnerable to speech disorders than the latter. This study explores the hypothesis that a similar contrast exists later in life and that consonants are more vulnerable to ageing than vowels. Data was obtained with two experiments comparing the speech of Younger Adults (YAs) and Middle-aged Adults (MAs). In the first experiment an Automatic Speech Recognition (ASR) system was trained with a balanced corpus of 29 YAs and 27 MAs. The productions of each speaker were obtained in a Spanish language word (W) and non-word (NW) repetition task. The performance of the system was evaluated with the same corpus used for training using a cross validation approach. The ASR system recognized to a similar extent the Ws of both groups of speakers, but it was more successful with the NWs of the YAs than with those of the MAs. Detailed error analysis revealed that the MA speakers scored below the YA speakers for consonants and also for the place and manner of articulation features; the results were almost identical in both groups of speakers for vowels and for the voicing feature. In the second experiment a group of healthy native listeners was asked to recognize isolated syllables presented with background noise. The target speakers were one YA and one MA that had taken part in the first experiment. The results were consistent with those of the ASR experiment: the manner and place of articulation were better recognized, and vowels and voicing were worse recognized, in the YA speaker than in the MA speaker. We conclude that consonant articulation is more vulnerable to ageing than vowel articulation. Future studies should explore whether or not these early and selective changes in articulation accuracy might be caused by changes in speech perception skills (e.g., in auditory temporal processing).
C1 [Moreno-Torres, Ignacio] Univ Malaga, Dept Spanish Language, Malaga, Spain.
   [Nava, Enrique] Univ Malaga, Dept Commun Engn, Malaga, Spain.
RP Moreno-Torres, I (corresponding author), Univ Malaga, Dept Spanish Language, Malaga, Spain.
EM imoreno@uma.es
OI Moreno Torres Sanchez, Ignacio/0000-0002-2649-7145; Nava Baro,
   Enrique/0000-0001-7817-6442
FU Ministerio de Ciencia, Innovacion y Universidades
   [RTI2018-094846-B-I00]; Junta de AndaluciaJunta de Andalucia
   [UMA18-FEDERJA-021]; Ministerio de Economia, Industria y Competitividad,
   Gobierno de Espana [PI16/01514]
FX IMT an EN received a grant from Ministerio de Ciencia, Innovacion y
   Universidades (RTI2018-094846-B-I00) and a grant from Junta de Andalucia
   (UMA18-FEDERJA-021). Speech data acquisition was funded by Ministerio de
   Economia, Industria y Competitividad, Gobierno de Espana, PI16/01514.
   The funders had no role in study design, data collection and analysis,
   decision to publish, or preparation of the manuscript.
CR Adi-Bensaid L, 2009, CLIN LINGUIST PHONET, V23, P122, DOI 10.1080/02699200802564961
   BENJAMIN BJ, 1982, J PSYCHOLINGUIST RES, V11, P159
   Bilodeau-Mercure M, 2016, J AM GERIATR SOC, V64, pE177, DOI 10.1111/jgs.14491
   Bilodeau-Mercure M, 2015, AGE, V37, DOI 10.1007/s11357-015-9813-x
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bouton S, 2012, J SPEECH LANG HEAR R, V55, P139, DOI 10.1044/1092-4388(2011/10-0330)
   Celdran EM, 2007, ARIEL LINGUISTICA
   Cieri C, 2014, LANG LINGUIST COMPAS, V8, P472, DOI 10.1111/lnc3.12112
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   Eichhorn JT, 2018, J VOICE, V32, DOI 10.1016/j.jvoice.2017.08.003
   Green KP, 1997, J SPEECH LANG HEAR R, V40, P646, DOI 10.1044/jslhr.4003.646
   Harrington J, 2007, INTERSPEECH, P2753
   Helfer KS, 2009, J AM ACAD AUDIOL, V20, P264, DOI 10.3766/jaaa.20.4.6
   Kong X, 2017, INT CONF ACOUST SPEE, P5810, DOI 10.1109/ICASSP.2017.7953270
   Le Normand MT, 2000, J CLIN EXP NEUROPSYC, V22, P408, DOI 10.1076/1380-3395(200006)22:3;1-V;FT408
   LENORMAND MT, 1991, CLIN LINGUIST PHONET, V5, P99, DOI 10.3109/02699209108985508
   McKechnie J, 2018, AUTOMATED SPEECH ANA
   Metz D, 1980, SPEECH ASSESSMENT SP, P72
   Meyer BT, 2007, P INT, P1485
   Meyer J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0079279
   Moreno-Torres I, 2017, J ACOUST SOC AM, V141, P3079, DOI 10.1121/1.4982251
   PARNELL MM, 1987, J COMMUN DISORD, V20, P339, DOI 10.1016/0021-9924(87)90015-3
   Phatak SA, 2007, J ACOUST SOC AM, V121, P2312, DOI 10.1121/1.2642397
   Pichora-Fuller MK, 2003, INT J AUDIOL, V42, pS26
   Povey D., 2011, P ASRU
   RASTATTER MP, 1990, FOLIA PHONIATR, V42, P312, DOI 10.1159/000266088
   SHIPP T, 1992, J VOICE, V6, P211, DOI 10.1016/S0892-1997(05)80145-6
   SHUEY EM, 1989, J COMMUN DISORD, V22, P437, DOI 10.1016/0021-9924(89)90036-1
   Sroka JJ, 2005, SPEECH COMMUN, V45, P401, DOI 10.1016/j.specom.2004.11.009
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   Tremblay P, 2019, EXP GERONTOL, V126, DOI 10.1016/j.exger.2019.110695
   Tremblay P, 2018, PSYCHOL AGING, V33, P1022, DOI 10.1037/pag0000306
   VanRavenhorst-Bell HA, 2017, TONGUE STRENGTH ENDU
   Vihman MM, 1996, PHONOLOGICAL DEV ORI
   Vipperla R, 2010, EURASIP J AUDIO SPEE, DOI 10.1155/2010/525783
   WEISMER G, 1988, J ACOUST SOC AM, V84, P1281, DOI 10.1121/1.396627
NR 36
TC 0
Z9 0
U1 0
U2 0
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD NOV 9
PY 2020
VL 15
IS 11
AR e0242018
DI 10.1371/journal.pone.0242018
PG 19
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA OV7JZ
UT WOS:000592382600008
PM 33166341
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Sohoglu, E
   Davis, MH
AF Sohoglu, Ediz
   Davis, Matthew H.
TI Rapid computations of spectrotemporal prediction error support
   perception of degraded speech
SO ELIFE
LA English
DT Article
AB Human speech perception can be described as Bayesian perceptual inference but how are these Bayesian computations instantiated neurally? We used magnetoencephalographic recordings of brain responses to degraded spoken words and experimentally manipulated signal quality and prior knowledge. We first demonstrate that spectrotemporal modulations in speech are more strongly represented in neural responses than alternative speech representations (e.g. spectrogram or articulatory features). Critically, we found an interaction between speech signal quality and expectations from prior written text on the quality of neural representations; increased signal quality enhanced neural representations of speech that mismatched with prior expectations, but led to greater suppression of speech that matched prior expectations. This interaction is a unique neural signature of prediction error computations and is apparent in neural responses within 100 ms of speech input. Our findings contribute to the detailed specification of a computational model of speech perception based on predictive coding frameworks.
C1 [Sohoglu, Ediz] Univ Sussex, Sch Psychol, Brighton, E Sussex, England.
   [Davis, Matthew H.] MRC Cognit & Brain Sci Unit, Cambridge, England.
RP Sohoglu, E (corresponding author), Univ Sussex, Sch Psychol, Brighton, E Sussex, England.
EM E.Sohoglu@sussex.ac.uk
OI Davis, Matt/0000-0003-2239-0778; Sohoglu, Ediz/0000-0002-0755-6445
FU Medical Research CouncilUK Research & Innovation (UKRI)Medical Research
   Council UK (MRC)European Commission [SUAG/044 G101400]
FX Medical Research Council SUAG/044 G101400 Matthew H Davis; Medical
   Research Council Centenary Award Ediz Sohoglu; The funders had no role
   in study design, data collection and interpretation, or the decision to
   submit the work for publication.
CR Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Aitchison L, 2017, CURR OPIN NEUROBIOL, V46, P219, DOI 10.1016/j.conb.2017.08.010
   Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810
   Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038
   Blank H, 2018, J NEUROSCI, V38, P6076, DOI 10.1523/JNEUROSCI.3258-17.2018
   Blank H, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002577
   Bonte M, 2006, CEREB CORTEX, V16, P115, DOI 10.1093/cercor/bhi091
   Brodbeck C, 2018, CURR BIOL, V28, P3976, DOI 10.1016/j.cub.2018.10.042
   Broderick MP, 2019, J NEUROSCI, V39, P7564, DOI 10.1523/JNEUROSCI.0584-19.2019
   Chi T, 2005, J ACOUST SOC AM, V118, P887, DOI 10.1121/1.1945807
   Cope TE, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01958-7
   Crosse MJ, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00604
   Daube C, 2019, CURR BIOL, V29, P1924, DOI 10.1016/j.cub.2019.04.067
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   Davis MH, 2003, J NEUROSCI, V23, P3423
   de Cheveigne A, 2014, NEUROIMAGE, V98, P487, DOI 10.1016/j.neuroimage.2014.05.068
   de Lange FP, 2018, TRENDS COGN SCI, V22, P764, DOI 10.1016/j.tics.2018.06.002
   Di Liberto GM, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0084-18.2018
   Di Liberto GM, 2018, NEUROIMAGE, V166, P247, DOI 10.1016/j.neuroimage.2017.10.066
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Ding N, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00311
   Ding N, 2013, J NEUROSCI, V33, P5728, DOI 10.1523/JNEUROSCI.5297-12.2013
   Ding N, 2012, J NEUROPHYSIOL, V107, P78, DOI 10.1152/jn.00297.2011
   Donhauser PW, 2020, NEURON, V105, P385, DOI 10.1016/j.neuron.2019.10.019
   Elliott TM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000302
   Evans S, 2015, CEREB CORTEX, V25, P4772, DOI 10.1093/cercor/bhv136
   Flinker A, 2019, NAT HUM BEHAV, V3, P393, DOI 10.1038/s41562-019-0548-z
   Frank SL, 2017, LANG COGN NEUROSCI, V32, P1192, DOI 10.1080/23273798.2017.1323109
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Garrido MI, 2007, P NATL ACAD SCI USA, V104, P20961, DOI 10.1073/pnas.0706274105
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052
   Grill-Spector K, 2006, TRENDS COGN SCI, V10, P14, DOI 10.1016/j.tics.2005.11.006
   HAMALAINEN M, 1993, REV MOD PHYS, V65, P413, DOI 10.1103/RevModPhys.65.413
   Hamalainen Matti S., 1995, Brain Topography, V7, P283, DOI 10.1007/BF01195254
   Hervais-Adelman A, 2008, J EXP PSYCHOL HUMAN, V34, P460, DOI 10.1037/0096-1523.34.2.460
   Holdgraf CR, 2017, FRONT SYST NEUROSCI, V11, DOI 10.3389/fnsys.2017.00061
   Holdgraf CR, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13654
   Hullett PW, 2016, J NEUROSCI, V36, P2014, DOI 10.1523/JNEUROSCI.1779-15.2016
   International Phonetic Association, 1999, HDB INT PHONETIC ASS, DOI [10.1017/S0952675700003894, DOI 10.1017/S0952675700003894]
   Kisler T, 2017, COMPUT SPEECH LANG, V45, P326, DOI 10.1016/j.csl.2017.01.005
   Kok P, 2017, P NATL ACAD SCI USA, V114, P10473, DOI 10.1073/pnas.1705652114
   Kok P, 2016, CURR BIOL, V26, P371, DOI 10.1016/j.cub.2015.12.038
   Kok P, 2012, NEURON, V75, P265, DOI 10.1016/j.neuron.2012.04.034
   Kriegeskorte N, 2019, CURR OPIN NEUROBIOL, V55, P167, DOI 10.1016/j.conb.2019.04.002
   Lalor EC, 2010, EUR J NEUROSCI, V31, P189, DOI 10.1111/j.1460-9568.2009.07055.x
   Lamme VAF, 2000, TRENDS NEUROSCI, V23, P571, DOI 10.1016/S0166-2236(00)01657-X
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LOFTUS GR, 1994, PSYCHON B REV, V1, P476, DOI 10.3758/BF03210951
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   McClelland JL, 2014, COGNITIVE SCI, V38, P1139, DOI 10.1111/cogs.12146
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Murray SO, 2004, NEURAL NETWORKS, V17, P695, DOI 10.1016/j.neunet.2004.03.010
   Norman-Haignere SV, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2005127
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Nunez-Elizalde AO, 2019, NEUROIMAGE, V197, P482, DOI 10.1016/j.neuroimage.2019.04.012
   O'Sullivan JA, 2015, CEREB CORTEX, V25, P1697, DOI 10.1093/cercor/bht355
   Obleser J, 2008, J NEUROSCI, V28, P8116, DOI 10.1523/JNEUROSCI.1290-08.2008
   Obleser J, 2019, TRENDS COGN SCI, V23, P913, DOI 10.1016/j.tics.2019.08.004
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   Peelle JE, 2018, EAR HEARING, V39, P204, DOI 10.1097/AUD.0000000000000494
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Press C, 2020, TRENDS COGN SCI, V24, P13, DOI 10.1016/j.tics.2019.11.003
   Rabovsky M, 2018, NAT HUM BEHAV, V2, P693, DOI 10.1038/s41562-018-0406-4
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Roberts B, 2011, P ROY SOC B-BIOL SCI, V278, P1595, DOI 10.1098/rspb.2010.1554
   Rogers JC, 2017, J COGNITIVE NEUROSCI, V29, P919, DOI 10.1162/jocn_a_01096
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Santoro R, 2017, P NATL ACAD SCI USA, V114, P4799, DOI 10.1073/pnas.1617622114
   Santoro R, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003412
   Scott SK, 2006, J ACOUST SOC AM, V120, P1075, DOI 10.1121/1.2216725
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Singh NC, 2003, J ACOUST SOC AM, V114, P3394, DOI 10.1121/1.1624067
   Sohoglu E, 2016, P NATL ACAD SCI USA, V113, pE1747, DOI 10.1073/pnas.1523266113
   Sohoglu E, 2014, J EXP PSYCHOL HUMAN, V40, P186, DOI 10.1037/a0033206
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   Spratling MW, 2008, FRONT COMPUT NEUROSC, V2, P1, DOI 10.3389/neuro.10.004.2008
   Stone MA, 2008, J ACOUST SOC AM, V124, P2272, DOI 10.1121/1.2968678
   Taulu S, 2005, IEEE T SIGNAL PROCES, V53, P3359, DOI 10.1109/TSP.2005.853302
   Theunissen FE, 2014, NAT REV NEUROSCI, V15, P355, DOI 10.1038/nrn3731
   Ulanovsky N, 2003, NAT NEUROSCI, V6, P391, DOI 10.1038/nn1032
   Venezia JH, 2016, J ACOUST SOC AM, V140, P1072, DOI 10.1121/1.4960544
   VOSS RF, 1975, NATURE, V258, P317, DOI 10.1038/258317a0
   Warner N, 2014, J ACOUST SOC AM, V135, P2995, DOI 10.1121/1.4870486
   Yi HG, 2019, NEURON, V102, P1096, DOI 10.1016/j.neuron.2019.04.023
NR 89
TC 0
Z9 0
U1 0
U2 0
PU ELIFE SCIENCES PUBLICATIONS LTD
PI CAMBRIDGE
PA SHERATON HOUSE, CASTLE PARK, CAMBRIDGE, CB3 0AX, ENGLAND
SN 2050-084X
J9 ELIFE
JI eLife
PD NOV 4
PY 2020
VL 9
AR e58077
DI 10.7554/eLife.58077
PG 25
WC Biology
SC Life Sciences & Biomedicine - Other Topics
GA OR2SL
UT WOS:000589324800001
PM 33147138
OA DOAJ Gold, Green Published, Green Accepted
DA 2021-02-24
ER

PT J
AU Eshaghi, M
   Darouie, A
   Teymouri, R
AF Eshaghi, Mahnaz
   Darouie, Akbar
   Teymouri, Robab
TI The Auditory Perception of Consonant Contrasts in Cochlear Implant
   Children
SO INDIAN JOURNAL OF OTOLARYNGOLOGY AND HEAD & NECK SURGERY
LA English
DT Article; Early Access
DE Auditory perception; Phonological contrast; Consonant; Cochlear implant
ID SPEECH-PERCEPTION; RECOGNITION; DEAF
AB Background and ObjectivesA major part of speech perception is based on understanding and distinguishing between vocal cues in the speaker's speech. Consonants and vowels are vocal cues that can be affected by hearing impairment and their perception may thus be reduced or distorted. The present study aims to investigate the auditory perception of consonant contrasts in cochlear implant children. Materials and Methods The present cross-sectional, descriptive-analytical study was conducted on 24 cochlear implant children aged 9-13 selected through convenience sampling from schools and cochlear implant centers. A test of non-word pairs based on a study conducted by Khavar-Ghazlani was carried out to measure contrast in consonants, place of and manner of articulation and voicing. Results The results of the test showed that cochlear implant children scored lower in the perception of voicing compared to the other two features. No significant differences were observed between their perceptions of place of articulation and manner of articulation. Conclusion Cochlear implant children appear to have a poorer perception of voicing contrast compared to the other features, which may be due to the greater reliance of this feature on auditory signs.
C1 [Eshaghi, Mahnaz; Darouie, Akbar] Univ Social Welf & Rehabil Sci, Speech Therapy Dept, Tehran, Iran.
   [Teymouri, Robab] Univ Social Welf & Rehabil Sci, Pediat Neurorehabil Res Ctr, Tehran, Iran.
RP Darouie, A (corresponding author), Univ Social Welf & Rehabil Sci, Speech Therapy Dept, Tehran, Iran.
EM mahnazeshaghi@yahoo.com; adarouie@hotmail.com; robab.teymouri@yahoo.com
RI Darouie, Akbar/J-5052-2017
CR Bouton S, 2012, J SPEECH LANG HEAR R, V55, P139, DOI 10.1044/1092-4388(2011/10-0330)
   Cole E.B., 2015, CHILDREN HEARING LOS
   Ebrahimian S, 2013, BIMONTHLY AUDIOL TEH, V22, P32
   Kalaiah MK, 2017, J AUDIOL OTOL, V21, P146, DOI 10.7874/jao.2017.00122
   Khavarghazalani B, 2013, COMPARISON AUDITORY
   Kishon-Rabin L, 2002, ANN OTO RHINOL LARYN, V111, P85
   Mahshie J, 2015, EAR HEARING, V36, P653, DOI 10.1097/AUD.0000000000000181
   Mazaher Yazdi M, 2004, RAZI J MED SCI, V10, P943
   Mendel LL, 1997, AUDIOLOGIC EVALUATIO
   Mildner V, 2006, CLIN LINGUIST PHONET, V20, P219, DOI 10.1080/02699200400027031
   Moein N, 2017, INT J PEDIATR OTORHI, V101, P1, DOI 10.1016/j.ijporl.2017.07.018
   Movallali G, 2013, ARCH REHABIL, V14, P29
   Munson B, 2003, J ACOUST SOC AM, V113, P925, DOI 10.1121/1.1536630
   Rezaei M., 2013, AUDIOLOGY, V22, P67
   Rouger J, 2008, BRAIN RES, V1188, P87, DOI 10.1016/j.brainres.2007.10.049
   Ryalls JH, 1996, BASIC INTRO SPEECH P
   Samadi Z, 2012, AUDITORY TRAINING HE
   Scheidiger C, 2017, J ACOUST SOC AM, V141, P1739, DOI 10.1121/1.4976066
   Teymouri R, 2011, ARCH REHABIL, V11, P31
   Turgeon C, 2017, INT J PEDIATR OTORHI, V101, P87, DOI 10.1016/j.ijporl.2017.07.022
   Tye-Murray N, 2014, FDN AURAL REHABILITA
   TYEMURRAY N, 1995, J ACOUST SOC AM, V98, P2454, DOI 10.1121/1.413278
   Valimaa TT, 2002, J SPEECH LANG HEAR R, V45, P1055, DOI 10.1044/1092-4388(2002/085)
NR 23
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER INDIA
PI NEW DELHI
PA 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001,
   INDIA
SN 2231-3796
EI 0973-7707
J9 INDIAN J OTOLARYNGOL
JI Indian J. Otolaryngol. Head Neck Surg.
DI 10.1007/s12070-020-02250-9
EA NOV 2020
PG 5
WC Surgery
SC Surgery
GA OM0OG
UT WOS:000585728700003
DA 2021-02-24
ER

PT J
AU Risueno-Segovia, C
   Hage, SR
AF Risueno-Segovia, Cristina
   Hage, Steffen R.
TI Theta Synchronization of Phonatory and Articulatory Systems in Marmoset
   Monkey Vocal Production
SO CURRENT BIOLOGY
LA English
DT Article
ID SPEECH-PERCEPTION; MOTOR CONTROL; EVOLUTION; RHYTHMS; VOCALIZATIONS;
   OSCILLATIONS; MODEL
AB Human speech shares a 3-8-Hz theta rhythm across all languages [1-3]. According to the frame/content theory of speech evolution, this rhythm corresponds to syllabic rates derived from natural mandibular-associated oscillations [4]. The underlying pattern originates from oscillatory movements of articulatory muscles [4, 5] tightly linked to periodic vocal fold vibrations [4, 6, 7]. Such phono-articulatory rhythms have been proposed as one of the crucial preadaptations for human speech evolution [3, 8, 9]. However, the evolutionary link in phono-articulatory rhythmicity between vertebrate vocalization and human speech remains unclear. Fromthe phonatory perspective, theta oscillations might be phylogenetically preserved throughout all vertebrate clades [10-12]. From the articulatory perspective, theta oscillations are present in non-vocal lip smacking [1, 13, 14], teeth chattering [15], vocal lip smacking [16], and clicks and faux-speech [17] in non-human primates, potential evolutionary precursors for speech rhythmicity [1, 13]. Notably, a universal phono-articulatory rhythmicity similar to that in human speech is considered to be absent in non-human primate vocalizations, typically produced with sound modulations lacking concomitant articulatory movements [1, 9, 18]. Here, we challenge this viewby investigating the coupling of phonatory and articulatory systems in marmoset vocalizations. Using quantitative measures of acoustic call structure, e.g., amplitude envelope, and callassociated articulatory movements, i.e., inter-lip distance, we show that marmosets display speech-like bi-motor rhythmicity. These oscillations are synchronized and phase locked at theta rhythms. Our findings suggest that oscillatory rhythms underlying speech production evolved early in the primate lineage, identifying marmosets as a suitable animal model to decipher the evolutionary and neural basis of coupled phono-articulatory movements.
C1 [Risueno-Segovia, Cristina; Hage, Steffen R.] Univ Tubingen, Hearing Res Ctr, Dept Otolaryngol Head & Neck Surg, Neurobiol Social Commun,Med Ctr, Elfriede Aulhorn Str 5, D-72076 Tubingen, Germany.
   [Risueno-Segovia, Cristina; Hage, Steffen R.] Univ Tubingen, Werner Reichardt Ctr Integrat Neurosci, Otfried Muller Str 25, D-72076 Tubingen, Germany.
   [Risueno-Segovia, Cristina] Univ Tubingen, Grad Sch Neural & Behav Sci, Int Max Planck Res Sch, Osterberg Str 3, D-72074 Tubingen, Germany.
RP Hage, SR (corresponding author), Univ Tubingen, Hearing Res Ctr, Dept Otolaryngol Head & Neck Surg, Neurobiol Social Commun,Med Ctr, Elfriede Aulhorn Str 5, D-72076 Tubingen, Germany.; Hage, SR (corresponding author), Univ Tubingen, Werner Reichardt Ctr Integrat Neurosci, Otfried Muller Str 25, D-72076 Tubingen, Germany.
EM steffen.hage@uni-tuebingen.de
FU Werner Reichardt Centre for Integrative Neuroscience (DFG) at the
   Eberhard Karls University of Tubingen (Deutsche
   Forschungsgemeinschaft)German Research Foundation (DFG) [EXC 307]
FX We thank John Holmes for proofreading and Vera Voigtlander for fruitful
   discussion on the manuscript. This work was supported by the Werner
   Reichardt Centre for Integrative Neuroscience (DFG) at the Eberhard
   Karls University of Tubingen (CIN is an Excellence Cluster funded by the
   Deutsche Forschungsgemeinschaft within the framework of the Excellence
   Initiative EXC 307).
CR Agamaite JA, 2015, J ACOUST SOC AM, V138, P2906, DOI 10.1121/1.4934268
   Assaneo MF, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aao3842
   Bass AH, 2008, SCIENCE, V321, P417, DOI 10.1126/science.1157632
   Berens P, 2009, J STAT SOFTW, V31, P1, DOI 10.18637/jss.v031.i10
   Bergman TJ, 2019, ANIM BEHAV, V151, P229, DOI 10.1016/j.anbehav.2019.02.015
   Bergman TJ, 2013, CURR BIOL, V23, pR268, DOI 10.1016/j.cub.2013.02.038
   Castellucci GA, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199929
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Coupe C, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aaw2594
   Fischer J, 2019, HUMAN LANGUAGE: FROM GENES AND BRAINS TO BEHAVIOR, P639
   Fujii S, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00777
   Ghazanfar AA, 2014, TRENDS COGN SCI, V18, P543, DOI 10.1016/j.tics.2014.06.004
   Ghazanfar AA, 2014, J COGNITIVE NEUROSCI, V26, P1196, DOI 10.1162/jocn_a_00575
   Ghazanfar AA, 2012, CURR BIOL, V22, P1176, DOI 10.1016/j.cub.2012.04.055
   Ghitza O, 2009, PHONETICA, V66, P113, DOI 10.1159/000208934
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Gross J, 2002, P NATL ACAD SCI USA, V99, P2299, DOI 10.1073/pnas.032682099
   Hage SR, 2016, TRENDS NEUROSCI, V39, P813, DOI 10.1016/j.tins.2016.10.006
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Jurgens U, 2002, NEUROSCI BIOBEHAV R, V26, P235, DOI 10.1016/S0149-7634(01)00068-9
   Kotz SA, 2018, TRENDS COGN SCI, V22, P896, DOI 10.1016/j.tics.2018.08.002
   Kotz SA, 2010, TRENDS COGN SCI, V14, P392, DOI 10.1016/j.tics.2010.06.005
   Lameira AR, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116136
   Landau AN, 2012, CURR BIOL, V22, P1000, DOI 10.1016/j.cub.2012.03.054
   Lee B, 2016, SCI REP-UK, V6, DOI 10.1038/srep37647
   LIEBERMAN P, 1968, J ACOUST SOC AM, V44, P1574, DOI 10.1121/1.1911299
   Loh KK, 2017, NEUROSCI BIOBEHAV R, V82, P32, DOI 10.1016/j.neubiorev.2016.12.001
   LUDLOW CL, 1987, BRAIN LANG, V32, P195, DOI 10.1016/0093-934X(87)90124-6
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   MacNeilage PF, 1998, BEHAV BRAIN SCI, V21, P499, DOI 10.1017/S0140525X98001265
   Miller CT, 2016, NEURON, V90, P219, DOI 10.1016/j.neuron.2016.03.018
   Moore JD, 2013, NATURE, V497, P205, DOI 10.1038/nature12076
   OKEEFE J, 1993, HIPPOCAMPUS, V3, P317, DOI 10.1002/hipo.450030307
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Pereira AS, 2020, BIOL LETTERS, V16, DOI 10.1098/rsbl.2020.0232
   Poeppel D, 2020, NAT REV NEUROSCI, V21, P322, DOI 10.1038/s41583-020-0304-4
   Pomberger T, 2018, CURR BIOL, V28, P788, DOI 10.1016/j.cub.2018.01.070
   Simonyan K, 2016, J NEUROSCI, V36, P11440, DOI 10.1523/JNEUROSCI.2424-16.2016
   Terband H, 2004, SPEECH MOTOR CONTROL, P389
   Terleph TA, 2018, AM J PHYS ANTHROPOL, V166, P649, DOI 10.1002/ajpa.23451
   Toyoda A, 2017, AM J PHYS ANTHROPOL, V164, P435, DOI 10.1002/ajpa.23276
   Tremblay S, 2003, NATURE, V423, P866, DOI 10.1038/nature01710
   Wieland EA, 2015, BRAIN LANG, V144, P26, DOI 10.1016/j.bandl.2015.03.008
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Zhao LY, 2019, HEARING RES, V384, DOI 10.1016/j.heares.2019.107811
   Zurcher Y, 2017, INT J PRIMATOL, V38, P780, DOI 10.1007/s10764-017-9979-4
NR 48
TC 0
Z9 0
U1 1
U2 1
PU CELL PRESS
PI CAMBRIDGE
PA 50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA
SN 0960-9822
EI 1879-0445
J9 CURR BIOL
JI Curr. Biol.
PD NOV 2
PY 2020
VL 30
IS 21
BP 4276
EP +
DI 10.1016/j.cub.2020.08.019
PG 11
WC Biochemistry & Molecular Biology; Biology; Cell Biology
SC Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other
   Topics; Cell Biology
GA OM3MN
UT WOS:000585930500034
PM 32888481
DA 2021-02-24
ER

PT J
AU Gryllia, S
   Doetjes, JS
   Yang, Y
   Cheng, LL
AF Gryllia, Stella
   Doetjes, Jenny S.
   Yang, Yang
   Cheng, Lisa L.
TI Prosody, clause typing, and wh-in-situ: Evidence from Mandarin
SO LABORATORY PHONOLOGY
LA English
DT Article
DE prosody; wh-in-situ; Mandarin
ID EYE-MOVEMENTS; INTONATION; INFORMATION; LANGUAGE; TONE; PREDICTION;
   SENTENCE; GERMAN; FOCUS
AB This paper examines the use of prosody for marking upcoming linguistic material in speech production and for anticipating them in speech perception. More specifically, it examines whether in the absence of any overt morphosyntactic cues in the beginning of an utterance, speakers use prosodic means to mark the clause type (declarative or wh-question) and whether listeners use these prosodic cues to anticipate the clause type. We report the results of a production and an audio gating experiment. The results of the production experiment show that speakers of Mandarin differentiate declaratives from wh-questions right from the onset of the clause by means of duration, F0, and intensity. The results of the audio gating experiment demonstrate that prosody is used by listeners to anticipate the clause type which is intended by the speaker.
C1 [Gryllia, Stella; Doetjes, Jenny S.; Cheng, Lisa L.] Leiden Univ, Ctr Linguist, Leiden, Netherlands.
   [Yang, Yang] Guangdong Univ Foreign Studies, Ctr Linguist & Appl Linguist, Guangzhou, Peoples R China.
   [Cheng, Lisa L.] Leiden Univ, Leiden Inst Brain & Cognit, Leiden, Netherlands.
RP Gryllia, S (corresponding author), Leiden Univ, Ctr Linguist, Leiden, Netherlands.
EM s.gryllia@hum.leidenuniv.nl
OI Cheng, Lisa/0000-0002-0350-5640
FU Dutch Research Council (NWO)Netherlands Organization for Scientific
   Research (NWO) [360-70-480]
FX The research reported here was funded by the Dutch Research Council
   (NWO) via the project Understanding Questions (360-70-480). We would
   like to thank three anonymous reviewers and the journal's editors for
   their insightful comments on the paper. We would also like to thank our
   team members Aliza Glasbergen-Plas and Leticia Pablos for comments and
   discussion. We thank Roger Luo, our assistant for segmenting the
   production data. We would also like to thank Xiaolu Yang at Tsinghua
   University, Beijing for assistance in conducting the experiments. At
   last we would like to thank all our participants.
CR Agresti A., 2002, CATEGORICAL DATA ANA, DOI [10.1002/0471249688, DOI 10.1002/0471249688, https://doi.org/10.1002/0471249688]
   Altmann GTM, 2007, J MEM LANG, V57, P502, DOI 10.1016/j.jml.2006.12.004
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   Arai M, 2013, LANG COGNITIVE PROC, V28, P525, DOI 10.1080/01690965.2012.658072
   Baltazani M., 2015, P 18 INT C PHON SCI
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boersma P., 2018, PRAAT DOING PHONETIC
   Brown M, 2011, PSYCHON B REV, V18, P1189, DOI 10.3758/s13423-011-0167-9
   Chen SH, 2005, J ACOUST SOC AM, V117, P3225, DOI 10.1121/1.1872312
   Chen YY, 2008, J PHONETICS, V36, P724, DOI 10.1016/j.wocn.2008.06.003
   Chen YY, 2010, J PHONETICS, V38, P517, DOI 10.1016/j.wocn.2010.06.004
   CHENG CC, 1968, PHONETICA, V18, P77, DOI 10.1159/000258601
   Cheng L., 1991, THESIS
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477
   Cooper S., 2015, P 18 INT C PHON SCI
   De Francis J., 1963, BEGINNING CHINESE
   Duanmu S., 2000, PHONOLOGY STANDARD C
   Duanmu S., 2011, BLACKWELL COMPANION, P2754, DOI 10.1002/9781444335262.wbctp0
   Face Timothy, 2007, ESTUDIOS FONETICA EX, V16, P185
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   GROSJEAN F, 1980, PERCEPT PSYCHOPHYS, V28, P267, DOI 10.3758/BF03204386
   Gunlogson C., 2002, P SEMANTICS LINGUIST, P124, DOI [10.3765/salt.v12i0.2860, DOI 10.3765/SALT.V12I0.2860]
   Haan J., 1997, LINGUISTICS NETHERLA, P99
   Heeren WFL, 2015, LANG SPEECH, V58, P474, DOI 10.1177/0023830914564452
   HO AT, 1977, PHONETICA, V34, P446, DOI 10.1159/000259916
   Huang C.-T.J., 1982, LINGUIST REV, V1, P369, DOI DOI 10.1515/TLIR.1982.1.4.369
   Ito K, 2008, J MEM LANG, V58, P541, DOI 10.1016/j.jml.2007.06.013
   Kamide Y, 2003, J PSYCHOLINGUIST RES, V32, P37, DOI 10.1023/A:1021933015362
   LAHIRI A, 1991, COGNITION, V38, P245, DOI 10.1016/0010-0277(91)90008-R
   Lee O., 2005, THESIS
   Li A., 2002, P SPEECH PROS AIX EN, V2002, P39
   Li Boya, 2006, THESIS
   Li C. N., 1981, MANDARIN CHINESE FUN
   Liu F., 2009, THESIS
   Liu M, 2016, NEUROPSYCHOLOGIA, V91, P307, DOI 10.1016/j.neuropsychologia.2016.08.025
   Ouyang IC, 2015, LANG COGN NEUROSCI, V30, P57, DOI 10.1080/01690965.2013.805795
   Petrone C., 2008, P 4 C SPEECH PROS CA, P301
   Petrone C, 2014, LANG SPEECH, V57, P108, DOI 10.1177/0023830913495651
   R Core Team, 2017, R LANG ENV STAT COMP
   Shen X., 1990, PROSODY MANDARIN CHI
   Staub A, 2006, J EXP PSYCHOL LEARN, V32, P425, DOI 10.1037/0278-7393.32.2.425
   Titze I. R., 1988, VOCAL PHYSL VOICE PR, P227
   Tsao W.-Y., 1967, J CHINESE LANGUAGE T, V2, P15
   van de Weijer J., 2014, LINGUISTICS NETHERLA, V2014, P180, DOI [10.1075/avt.31.13wei, DOI 10.1075/AVT.31.13WEI]
   van Heuven VJ, 2002, PHONOL PHONET, V4-1, P61
   Xu Y, 1999, J PHONETICS, V27, P55, DOI 10.1006/jpho.1999.0086
   Yuan JH, 2006, LECT NOTES COMPUT SC, V4274, P19
   Yuan JH, 2011, J ACOUST SOC AM, V130, P4063, DOI 10.1121/1.3651818
NR 48
TC 0
Z9 0
U1 2
U2 2
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD NOV 2
PY 2020
VL 11
IS 1
AR 19
DI 10.5334/labphon.169
PG 30
WC Linguistics; Language & Linguistics
SC Linguistics
GA OI7HS
UT WOS:000583445600001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Al-Azary, H
   Katz, AN
AF Al-Azary, Hamad
   Katz, Albert N.
TI Do metaphorical sharks bite? Simulation and abstraction in metaphor
   processing
SO MEMORY & COGNITION
LA English
DT Article; Early Access
DE Psycholinguistics; Semantic priming; Speech perception; Metaphor
ID APTNESS; CONVENTIONALITY; COMPREHENSION; EMBODIMENT; CAREER; REAL
AB In a metaphor such as lawyers are sharks, the concept lawyers, which is the metaphor topic, and the concept sharks, which is the metaphor vehicle, interact to produce a figurative meaning such that lawyers are predatory. Some theorists argue that sensorimotor properties of the vehicle are the basis of metaphor comprehension. Accordingly, the metaphor lawyers are sharks is processed as a simulation in which bodily actions related to sharks are accessed (e.g., sharks chasing prey). In contrast, the long-standing assumption is that metaphors are processed as abstractions with no role played by sensorimotor properties. From this theoretical perspective, abstract characteristics of sharks (e.g., vicious, predatory) are argued to be the core properties involved in metaphor processing. Here, we juxtapose these two opposing views of metaphor processing using cross-modal lexical priming. We find evidence that low-familiar metaphors (e.g., highways are snakes) prime bodily-action associates (i.e., slither) but not abstraction associates (i.e., danger), and are hence processed via simulation, whereas high-familiar metaphors (e.g., lawyers are sharks) prime abstraction associates (i.e., killer) but not bodily-action associates (i.e., bite) and are therefore processed via abstraction. The results align with views of cognition and language that posit the presence of both embodied and abstract representations.
C1 [Al-Azary, Hamad] Lawrence Technol Univ, Dept Humanities Social Sci & Commun, Southfield, MI 48075 USA.
   [Katz, Albert N.] Univ Western Ontario, Dept Psychol, London, ON, Canada.
RP Al-Azary, H (corresponding author), Lawrence Technol Univ, Dept Humanities Social Sci & Commun, Southfield, MI 48075 USA.
EM halazary@ltu.edu
FU Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR
   [06P007040] Funding Source: Medline
CR Balota DA, 2007, BEHAV RES METHODS, V39, P445, DOI 10.3758/BF03193014
   Barsalou L.W., 2008, SYMBOLS EMBODIMENT M, P245, DOI DOI 10.1093/ACPROF:OSO/9780199217274.003.0013
   Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577, DOI 10.1017/S0140525X99532147
   BLASKO DG, 1993, J EXP PSYCHOL LEARN, V19, P295, DOI 10.1037/0278-7393.19.2.295
   Bowdle BF, 2005, PSYCHOL REV, V112, P193, DOI 10.1037/0033-295X.112.1.193
   Cardillo ER, 2017, BEHAV RES METHODS, V49, P471, DOI 10.3758/s13428-016-0717-1
   Chatterjee A, 2010, LANG COGN, V2, P79, DOI 10.1515/LANGCOG.2010.004
   Chiappe D, 2003, METAPHOR SYMBOL, V18, P85, DOI 10.1207/S15327868MS1802_2
   Desai RH, 2013, NEUROIMAGE, V83, P862, DOI 10.1016/j.neuroimage.2013.07.044
   Desai RH, 2011, J COGNITIVE NEUROSCI, V23, P2376, DOI 10.1162/jocn.2010.21596
   Dove G, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2010.00242
   Gentner D, 2019, LANG COGN NEUROSCI, V34, P1298, DOI 10.1080/23273798.2017.1410560
   Gentner D, 2008, CAMB HANDB PSYCHOL, P109
   Gernsbacher MA, 2001, J MEM LANG, V45, P433, DOI 10.1006/jmla.2000.2782
   Gibbs Jr R. W., 2006, EMBODIMENT COGNITIVE
   Gibbs Raymond W., 2017, METAPHOR WARS
   Gibbs RW, 2013, LANG SCI, V40, P45, DOI 10.1016/j.langsci.2013.03.001
   Gibbs RW, 2008, CAMB HANDB PSYCHOL, P161
   GLUCKSBERG S, 1982, J VERB LEARN VERB BE, V21, P85, DOI 10.1016/S0022-5371(82)90467-4
   GLUCKSBERG S, 1990, PSYCHOL REV, V97, P3, DOI 10.1037/0033-295X.97.1.3
   Glucksberg S., 2001, METAPHOR SYMBOL, V16, P277, DOI DOI 10.1080/10926488.2001.9678898
   Glucksberg S, 2006, MIND LANG, V21, P360
   Glucksberg S, 2008, CAMB HANDB PSYCHOL, P67
   Jamrozik A, 2016, PSYCHON B REV, V23, P1080, DOI 10.3758/s13423-015-0861-0
   Jones LL, 2006, J MEM LANG, V55, P18, DOI 10.1016/j.jml.2006.02.004
   KATZ AN, 1988, METAPHOR SYMB ACT, V3, P191, DOI 10.1207/s15327868ms0304_1
   Lakoff G, 2012, TOP COGN SCI, V4, P773, DOI 10.1111/j.1756-8765.2012.01222.x
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   Louwerse MM, 2018, TOP COGN SCI, V10, P573, DOI 10.1111/tops.12349
   Masson MEJ, 2008, J MEM LANG, V59, P256, DOI 10.1016/j.jml.2008.05.003
   Matlock T, 2004, MEM COGNITION, V32, P1389, DOI 10.3758/BF03206329
   McElree B, 1999, PSYCHON B REV, V6, P486, DOI 10.3758/BF03210839
   McGlone MS, 2001, MEM COGNITION, V29, P1209, DOI 10.3758/BF03206390
   Nelson DL, 2004, BEHAV RES METH INS C, V36, P402, DOI 10.3758/BF03195588
   ORTONY A, 1975, EDUC THEORY, V25, P45, DOI 10.1111/j.1741-5446.1975.tb00666.x
   PAIVIO A, 1986, COMMUN COGNITION, V19, P367
   Paivio A., 2007, MIND ITS EVOLUTION D
   Paivio A, 1993, METAPHOR THOUGHT, P307, DOI DOI 10.1017/CBO9781139173865.016
   Paivio A., 1971, IMAGERY VERBAL PROCE
   Paivio A., 1986, MENTAL REPRESENTATIO
   Roncero C, 2015, BEHAV RES METHODS, V47, P800, DOI 10.3758/s13428-014-0502-y
   Rubio Fernandez P., 2007, J SEMANT, V24, P345, DOI [10.1093/jos/ffm006, DOI 10.1093/JOS/FFM006]
   Sadoski M., 2001, IMAGERY TEXT DUAL CO
   StataCorp, 2019, STAT STAT SOFTW REL
   SWINNEY DA, 1979, J VERB LEARN VERB BE, V18, P645, DOI 10.1016/S0022-5371(79)90355-4
   Tabossi P, 1996, LANG COGNITIVE PROC, V11, P569, DOI 10.1080/016909696386953
   TABOSSI P, 1988, J MEM LANG, V27, P324, DOI 10.1016/0749-596X(88)90058-7
   Thibodeau PH, 2011, METAPHOR SYMBOL, V26, P206, DOI 10.1080/10926488.2011.583196
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   Wilson NL, 2007, COGNITIVE SCI, V31, P721, DOI 10.1080/15326900701399962
   Wolff P, 2000, J EXP PSYCHOL LEARN, V26, P529, DOI 10.1037//0278-7393.26.2.529
   Wolff P, 2011, COGNITIVE SCI, V35, P1456, DOI 10.1111/j.1551-6709.2011.01194.x
   Zwaan RA, 2014, TRENDS COGN SCI, V18, P229, DOI 10.1016/j.tics.2014.02.008
NR 53
TC 1
Z9 1
U1 7
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0090-502X
EI 1532-5946
J9 MEM COGNITION
JI Mem. Cogn.
DI 10.3758/s13421-020-01109-2
EA NOV 2020
PG 14
WC Psychology, Experimental
SC Psychology
GA OK0EH
UT WOS:000584325000001
PM 33140133
DA 2021-02-24
ER

PT J
AU Chen, JQ
   Best, CT
   Antoniou, M
AF Chen, Juqiang
   Best, Catherine T.
   Antoniou, Mark
TI Native phonological and phonetic influences in perceptual assimilation
   of monosyllabic Thai lexical tones by Mandarin and Vietnamese listeners
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Perceptual assimilation; Non-native lexical tones; Thai; Mandarin;
   Vietnamese
ID LANGUAGE EXPERIENCE; ENGLISH R; JAPANESE; DISCRIMINATION; VOWELS;
   SPEAKERS
AB A cross tone-language perceptual assimilation study investigated native categorisations and goodness ratings of non-native Thai tones by Thai-naive listeners differing in their native tone systems: Mandarin, Northern Vietnamese and Southern Vietnamese. We derived hypotheses from the Perceptual Assimilation Model (PAM: Best, 1995), which considers both native phonological and phonetic influences on perceptual assimilation of non-native speech contrasts. Mandarin listeners reliably categorised the Thai mid level tone to their single native level tone category, reflecting a native phonological effect, but they also showed high residual phonetic sensitivity to differences between the non-native tone and the native tone it was assimilated to, indicated by low category goodness ratings. Native phonological and phonetic differences in tones of the two Vietnamese dialects also affected perceptual assimilation of the Thai high level and rising tones. In addition, categorisation responses were faster overall for Categorised than Uncategorised assimilations, revealing the processing cost of perceptual uncertainty due to phonological competition among and/or phonetic discrepancies from multiple native categories. This indicates, furthermore, a more focused and thus stronger native phonological contribution for Categorised than Uncategorised assimilations. PAM principles thus extend to non-native tone assimilations and indicate the importance of both native phonological and phonetic contributions to non-native speech perception. (c) 2020 Elsevier Ltd. All rights reserved.
C1 [Chen, Juqiang; Best, Catherine T.; Antoniou, Mark] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Locked Bag 1797, Penrith, NSW 2751, Australia.
   [Best, Catherine T.] Haskins Labs Inc, New Haven, CT 06511 USA.
RP Chen, JQ; Best, CT (corresponding author), Western Sydney Univ, MARCS Inst Brain Behav & Dev, Locked Bag 1797, Penrith, NSW 2751, Australia.; Best, CT (corresponding author), Haskins Labs Inc, New Haven, CT 06511 USA.
EM J.Chen2@westernsydney.edu.au; C.Best@westernsydney.edu.au;
   m.antoniou@westernsydney.edu.au
FU China Scholarship CouncilChina Scholarship Council; Western Sydney
   University
FX This research was supported by a China Scholarship Council and Western
   Sydney University Joint scholarship awarded to the first author, Juqiang
   Chen.
CR Antoniou M, 2015, J ACOUST SOC AM, V138, P571, DOI 10.1121/1.4923362
   Baddeley A, 2010, CURR BIOL, V20, pR136, DOI 10.1016/j.cub.2009.12.014
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00364
   BEST CT, 1992, J PHONETICS, V20, P305, DOI 10.1016/S0095-4470(19)30637-0
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bohn OS, 2012, J PHONETICS, V40, P109, DOI 10.1016/j.wocn.2011.08.002
   Brunelle M, 2010, PHONETICA, V67, P147, DOI 10.1159/000321053
   Brunelle M, 2009, J PHONETICS, V37, P79, DOI 10.1016/j.wocn.2008.09.003
   Burnham D., 2009, MAKING SPEECH 3 DIME
   Chao Y. R., 1930, MAITRE PHONETIQUE, V45, P24
   Chao Yuen Ren, 1968, GRAMMAR SPOKEN CHINE
   Chen J., 2019, P 19 INT C PHON SCI, P1684
   Erickson D., 1976, PHYSL ANAL TONES THA
   ERICKSON DM, 1976, J ACOUST SOC AM, V60, pS63, DOI 10.1121/1.2003454
   Escudero P., 2005, LINGUISTIC PERCEPTIO
   Escudero P, 2011, J ACOUST SOC AM, V130, pEL277, DOI 10.1121/1.3632043
   Escudero P, 2011, J ACOUST SOC AM, V129, pEL1, DOI 10.1121/1.3525042
   Faris MM, 2018, J PHONETICS, V70, P1, DOI 10.1016/j.wocn.2018.05.003
   Faris MM, 2016, J ACOUST SOC AM, V139, pEL1, DOI 10.1121/1.4939608
   Flege James, 1995, SPEECH PERCEPTION LI, P229
   Gandour J. T., 1978, TONE LINGUISTIC SURV, P41, DOI DOI 10.1016/B978-0-12-267350-4.50007-8
   Gottfried T. L., 2004, J ACOUST SOC AM, V115, P2545, DOI DOI 10.1121/1.4783674
   Halekoh U, 2014, J STAT SOFTW, V59, P1
   Halle PA, 1999, J PHONETICS, V27, P281, DOI 10.1006/jpho.1999.0097
   HARRISON T, 2019, P INTERSPEECH, P1653, DOI DOI 10.21437/INTERSPEECH.2019-1403
   Haudricourt A.-G., 1954, J ASIATIQUE, V142, P69
   Kuhl P. K., 1995, SPEECH PERCEPTION LI, P121
   LOBANOV BM, 1971, J ACOUST SOC AM, V49, P606, DOI 10.1121/1.1912396
   MACKAIN KS, 1981, APPL PSYCHOLINGUIST, V2, P369, DOI 10.1017/S0142716400009796
   MIYAWAKI K, 1975, PERCEPT PSYCHOPHYS, V18, P331, DOI 10.3758/BF03211209
   Moore DA, 2013, MOL BIOL CELL, V24
   NGUYEN VL, 1998, MON KHMER STUDIES J, V28, P1
   Nhan N. T., 1984, THESIS
   Nixon JS, 2016, J MEM LANG, V90, P103, DOI 10.1016/j.jml.2016.03.005
   Nyvad A. M., 2019, SOUND APPROACH LANGU, P13
   Pham A. H., 2004, VIETNAMESE TONE NEW
   Pham A. H., 2003, KEY PHONETIC PROPERT, P1703
   POLKA L, 1992, PERCEPT PSYCHOPHYS, V52, P37, DOI 10.3758/BF03206758
   POLKA L, 1995, J ACOUST SOC AM, V97, P1286, DOI 10.1121/1.412170
   Reid A, 2015, ATTEN PERCEPT PSYCHO, V77, P571, DOI 10.3758/s13414-014-0791-3
   Sagart L., 1986, CAHIERS LINGUISTIQUE, V15, P205, DOI DOI 10.3406/clao.1986.1204
   SHELDON A, 1982, APPL PSYCHOLINGUIST, V3, P243, DOI 10.1017/S0142716400001417
   So CK, 2014, STUD SECOND LANG ACQ, V36, P195, DOI 10.1017/S0272263114000047
   Strange W, 2001, J ACOUST SOC AM, V109, P1691, DOI 10.1121/1.1353594
   The International Phonetic Alphabet, 2015, IPA CHART
   Tyler MD, 2014, PHONETICA, V71, P4, DOI 10.1159/000356237
   Wieling M, 2018, J PHONETICS, V70, P86, DOI 10.1016/j.wocn.2018.03.002
   Wieling M, 2016, J PHONETICS, V59, P122, DOI 10.1016/j.wocn.2016.09.004
   Wu XH, 2014, J PHONETICS, V46, P86, DOI 10.1016/j.wocn.2014.06.005
   Xu Y., 2013, PROSODYPRO TOOL LARG
   YAMADA RA, 1992, PERCEPT PSYCHOPHYS, V52, P376, DOI 10.3758/BF03206698
   Yip M., 2002, TONE
NR 54
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
EI 1095-8576
J9 J PHONETICS
JI J. Phon.
PD NOV
PY 2020
VL 83
AR 101013
DI 10.1016/j.wocn.2020.101013
PG 16
WC Linguistics; Language & Linguistics
SC Linguistics
GA PZ2AX
UT WOS:000612543600001
DA 2021-02-24
ER

PT J
AU Cronenberg, J
   Gubian, M
   Harrington, J
   Ruch, H
AF Cronenberg, Johanna
   Gubian, Michele
   Harrington, Jonathan
   Ruch, Hanna
TI A dynamic model of the change from pre- to post-aspiration in Andalusian
   Spanish
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Sound change; Functional principal component analysis; Andalusian
   Spanish; Aspiration
ID SPEECH-PERCEPTION; INDIVIDUAL-DIFFERENCES; COARTICULATED SPEECH; CUE
   WEIGHTS; SOUND; ACQUISITION; ATTENTION; PHONOLOGY; TIME
AB In Andalusian Spanish, there is a well-documented sound change in which prehas become post-aspiration in sequences of /s/ followed by voiceless stops. Here we investigate acoustically its synchronic basis across two age groups and two different regions of Andalusia that differ in the degree to which the sound change has advanced. For this purpose, Functional Principal Component Analysis (FPCA) was applied to the probability of voicing and to the degree of closure that had been estimated from the speech signal extending between the two vowels on either side of the aspirated cluster. The first principal component derived from FPCA was mostly associated with changes to the timing of the closure. Earlier closures were characteristic of both younger and West Andalusian speakers and of alveolar stops. In the signals parametrised by the first PC score, postand pre-aspiration were found to be acoustically inversely related to each other and predictable from closure timing. The general conclusion is that the sound change by which preevolves into post-aspiration is a derivative of resynchronising the closure relative to the voiceless interval that emerges after decomposing speech signals varying over a wide range of speakers into principal components of variation. (C) 2020 The Author(s). Published by Elsevier Ltd.
C1 [Cronenberg, Johanna; Gubian, Michele; Harrington, Jonathan] Ludwig Maximilian Univ Munich, Inst Phonet & Speech Proc, Schellingstr 3 VG,Room 224, D-80799 Munich, Germany.
   [Ruch, Hanna] Univ Zurich, Univ Res Prior Program Language & Space, Zurich, Switzerland.
RP Gubian, M (corresponding author), Ludwig Maximilian Univ Munich, Inst Phonet & Speech Proc, Schellingstr 3 VG,Room 224, D-80799 Munich, Germany.
EM johanna.cronenberg@campus.lmu.de
FU European Research CouncilEuropean Research Council (ERC)European
   Commission [742289, 2017-2022]
FX This research was supported by European Research Council Grant No.
   742289 "Human interaction and the evolution of spoken accent"
   (2017-2022).
CR Aleza Izquierdo M., 2002, ESPANOL AM APROXIMAC
   ALFONSO PJ, 1982, LANG SPEECH, V25, P151, DOI 10.1177/002383098202500203
   Alvar M., 1955, REV FILOL ESPAN, V39, P284, DOI [10.3989/rfe.1955.v39.i1/4.1136, DOI 10.3989/RFE.1955.V39.I1/4.1136, 10.3989/rfe.1955.v39.i1/4.1136.]
   Asano Y, 2018, SPEECH COMMUN, V99, P183, DOI 10.1016/j.specom.2017.12.011
   Beddor P. S., 2007, EXPT APPROACHES PHON, P127
   Beddor P. S., 2012, INITIATION SOUND CHA, P37, DOI DOI 10.1075/CILT.323.06BED
   Beddor PS, 2018, LANGUAGE, V94, P931, DOI 10.1353/lan.2018.0051
   Beddor PS, 2009, LANGUAGE, V85, P785
   Bermudez-Otero R., 2015, OXFORD HDB HIST PHON, P374, DOI DOI 10.1093/OXFORDHB/9780199232819.001.0001
   Bermudez-Otero R., 2012, OXFORD HDB HIST ENGL, P691, DOI DOI 10.1093/OXFORDHB/9780199922765.013.0059
   BEST CT, 1981, PERCEPT PSYCHOPHYS, V29, P191, DOI 10.3758/BF03207286
   Bladon A., 1986, LANGUAGE HEARERS, P1, DOI DOI 10.1093/LLC/8.4.243
   Boersma P., 2003, P 15 INT C PHON SCI, P1013
   Browman Catherine, 1986, PHONOLOGY YB, V3, P219, DOI DOI 10.1017/S0952675700000658
   BROWMAN CP, 1992, PHONETICA, V49, P155, DOI 10.1159/000261913
   Butterworth S., 1930, WIRELESS ENG, V7, P536
   Canfield D. L., 1981, SPANISH PRONUNCIATIO
   Clayards M, 2018, J ACOUST SOC AM, V144, pEL172, DOI 10.1121/1.5052025
   Davidson L, 2006, PHONETICA, V63, P79, DOI 10.1159/000095304
   Ettlinger M., 2007, P 16 INT C PHON SCI, P685
   Fant G., 1973, SPEECH SOUNDS FEATUR
   Fowler C. A., 1986, INVARIANCE VARIABILI, P123
   Fowler CA, 2005, J PHONETICS, V33, P199, DOI 10.1016/j.wocn.2004.10.003
   FOWLER CA, 1993, LANG SPEECH, V36, P171, DOI 10.1177/002383099303600304
   FOWLER CA, 1984, PERCEPT PSYCHOPHYS, V36, P359, DOI 10.3758/BF03202790
   Fowler Carol A., 2003, HDB PSYCHOL EXPT PSY, V4, P237, DOI DOI 10.1057/9780230513969
   Francis AL, 2002, J EXP PSYCHOL HUMAN, V28, P349, DOI 10.1037//0096-1523.28.2.349
   Francis AL, 2000, PERCEPT PSYCHOPHYS, V62, P1668, DOI 10.3758/BF03212164
   Gerfen C., 2002, PROBUS, V14, P247, DOI DOI 10.1515/PRBS.2002.010
   Gonzalez S, 2014, IEEE-ACM T AUDIO SPE, V22, P518, DOI 10.1109/TASLP.2013.2295918
   Gubian M., 2019, TRACKING NEW ZEALAND, DOI [10.21437/Interspeech.2019-2115, DOI 10.21437/INTERSPEECH.2019-2115]
   Gubian M., 2011, JOINT ANAL F0 SPEECH, DOI [10.1109/ICASSP.2011.5947472, DOI 10.1109/ICASSP.2011.5947472]
   Gubian M, 2015, J PHONETICS, V49, P16, DOI 10.1016/j.wocn.2014.10.001
   Hagege C., 1978, PHONOLOGIE PANCHRONI
   HAGGARD M, 1981, J PHONETICS, V9, P49, DOI 10.1016/S0095-4470(19)30926-X
   Harmon Z, 2019, COGNITION, V189, P76, DOI 10.1016/j.cognition.2019.03.011
   Harrington J., 1999, TECHNIQUES SPEECH AC
   Harrington J, 2018, TOP COGN SCI, V10, P707, DOI 10.1111/tops.12329
   Herrero de Haro Alfredo, 2017, Íkala, V22, P313, DOI 10.17533/udea.ikala.v22n02a09
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   HOMBERT JM, 1979, LANGUAGE, V55, P37, DOI 10.2307/412518
   Hualde Jose I., 1995, ANN M BERKELEY LINGU, V21, P426
   Hualde JI, 2016, MANUALS ROMANCE LING, V10, P23
   Hyman L. M., 2013, ORIGINS SOUND CHANGE, P3, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0001
   Idemaru K, 2012, J ACOUST SOC AM, V132, P3950, DOI 10.1121/1.4765076
   Idemaru K, 2011, J EXP PSYCHOL HUMAN, V37, P1939, DOI 10.1037/a0025641
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Johnson K, 2006, J PHONETICS, V34, P485, DOI 10.1016/j.wocn.2005.08.004
   Johnson PCD, 2014, METHODS ECOL EVOL, V5, P944, DOI 10.1111/2041-210X.12225
   Kingston J, 2008, J PHONETICS, V36, P28, DOI 10.1016/j.wocn.2007.02.001
   Kiparsky P., 2015, OXFORD HDB HIST PHON, P563, DOI DOI 10.1093/OXFORDHB/9780199232819.013.017
   Kirby JP, 2014, LAB PHONOL, V5, P195, DOI 10.1515/lp-2014-0008
   Kirchner R, 2010, J PHONETICS, V38, P540, DOI 10.1016/j.wocn.2010.07.005
   Labov W., 1994, PRINCIPLES LINGUISTI, V1
   Lehet M, 2017, COGNITIVE SCI, V41, P885, DOI 10.1111/cogs.12413
   LINDBLOM BJORN, 1995, RIV LINGUISTICA, P75
   MARTIN JG, 1982, J EXP PSYCHOL HUMAN, V8, P473, DOI 10.1037/0096-1523.8.3.473
   McQueen JM, 2006, LANG SPEECH, V49, P101, DOI 10.1177/00238309060490010601
   Momcilovic N. B., 2009, LINCOM STUDIES ROMAN
   Mondejar Cumpian J., 2001, DIALECTOLOGIA ANDALU
   Corral JAM, 2007, REV FILOL UNIV LAGUN, V25, P457
   Nakagawa S, 2013, METHODS ECOL EVOL, V4, P133, DOI 10.1111/j.2041-210x.2012.00261.x
   Navarro Tomas T., 1938, TRAVAUX CERCLE LINGU, V8, P184
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   O'Neill P., 2010, ESTUDIOS FONETICA EX, VXIX, P11
   Ohala J. J., 1990, PAPERS LABORATORY PH, P258, DOI DOI 10.1017/CBO9780511627736.014
   Ohala J. J., 1993, HIST LINGUISTICS PRO, P237
   OHALA JJ, 1993, SPEECH COMMUN, V13, P155, DOI 10.1016/0167-6393(93)90067-U
   Parrell B, 2012, J PHONETICS, V40, P37, DOI 10.1016/j.wocn.2011.08.004
   Penzl H, 1949, LANGUAGE, V25, P223, DOI 10.2307/410084
   Pierrehumbert JB, 2006, J PHONETICS, V34, P516, DOI 10.1016/j.wocn.2006.06.003
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   Ramsammy M, 2015, LANG LINGUIST COMPAS, V9, P33, DOI 10.1111/lnc3.12102
   Ramsay JO, 2009, USE R, P1, DOI 10.1007/978-0-387-98185-7_1
   Reinisch E, 2014, J EXP PSYCHOL HUMAN, V40, P539, DOI 10.1037/a0034409
   REPP BH, 1982, PSYCHOL BULL, V92, P81, DOI 10.1037/0033-2909.92.1.81
   Romero J., 1994, HASKINS LAB STATUS R, P255
   Ruch H., 2013, THESIS
   Ruch H., 2018, J LING GEOGR, V6, P40, DOI [10.1017/jlg.2018.4., DOI 10.1017/JLG.2018.4]
   Ruch H, 2016, LAB PHONOL, V7, DOI 10.5334/labphon.2
   Ruch H, 2014, J PHONETICS, V45, P12, DOI 10.1016/j.wocn.2014.02.009
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   Savoia L., 1997, DIALECTS ITALY, P15
   Sole MJ, 2010, J PHONETICS, V38, P289, DOI 10.1016/j.wocn.2010.02.001
   Stevens M, 2019, GLOSSA-UK, V4, DOI 10.5334/gjgl.620
   Terrell T. D., 1980, VARIATION OMNIBUS, P115
   Todd S, 2019, COGNITION, V185, P1, DOI 10.1016/j.cognition.2019.01.004
   Torreira F., 2006, SEL P 9 HISP LING S, P113
   Torreira F., 2007, SEGMENTAL PROSODIC I, P67, DOI 10.1075/cilt.282.06tor
   Torreira F, 2012, J INT PHON ASSOC, V42, P49, DOI 10.1017/S0025100311000491
   Torres-Tamarit F., 2016, APPROACHES METAPHONY
   Twaddell W. F., 1938, MONATSHEFTE DTSCH UN, V30, P177
   van der Kooij E., 2005, INTERNAL ORG PHONOLO, P153, DOI DOI 10.1515/9783110890402.153
   Villena-Ponsoda J. A., 2008, INT J SOCIOL LANG, V2008, P139, DOI [10.1515/IJSL.2008.052, DOI 10.1515/IJSL.2008.052]
   Wedel AB, 2006, LINGUIST REV, V23, P247, DOI 10.1515/TLR.2006.010
   WHALEN DH, 1990, PHONETICA, V47, P36, DOI 10.1159/000261851
   Zellou G, 2017, J PHONETICS, V61, P13, DOI 10.1016/j.wocn.2016.12.002
NR 97
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
EI 1095-8576
J9 J PHONETICS
JI J. Phon.
PD NOV
PY 2020
VL 83
AR 101016
DI 10.1016/j.wocn.2020.101016
PG 22
WC Linguistics; Language & Linguistics
SC Linguistics
GA PZ2AX
UT WOS:000612543600003
OA Other Gold
DA 2021-02-24
ER

PT J
AU Falk, S
   Tsang, CD
AF Falk, Simone
   Tsang, Christine D.
TI 6-to 9-Month old infants discriminate vowel durations in variable speech
   contexts
SO INFANT BEHAVIOR & DEVELOPMENT
LA English
DT Article
DE Infant; Speech perception; Phonetic discrimination; Temporal relations;
   Rhythmic regularity
ID PERCEPTION; JAPANESE; ENGLISH; PITCH; LENGTH; TEMPO; SONG
AB Discriminating temporal relationships in speech is crucial for speech and language development. However, temporal variation of vowels is difficult to perceive for young infants when it is determined by surrounding speech sounds. Using a familiarization-discrimination paradigm, we show that English-learning 6- to 9-month-olds are capable of discriminating non-native acoustic vowel duration differences that systematically vary with subsequent consonantal durations. Furthermore, temporal regularity of stimulus presentation potentially makes the task easier for infants. These findings show that young infants can process fine-grained temporal aspects of speech sounds, a capacity that lays the foundation for building a phonological system of their ambient language(s).
C1 [Falk, Simone] Univ Montreal, Int Lab Brain Mus & Sound Res BRAMS, Dept Linguist & Translat, CP 6128,Succursale Ctr ville, Montreal, PQ H3C 3J7, Canada.
   [Tsang, Christine D.] Huron Univ Coll Western, Dept Psychol, London, ON, Canada.
RP Falk, S (corresponding author), Univ Montreal, Int Lab Brain Mus & Sound Res BRAMS, Dept Linguist & Translat, CP 6128,Succursale Ctr ville, Montreal, PQ H3C 3J7, Canada.
EM Simone.falk@umontreal.ca
FU Huron University College
FX This research was supported by a Faculty of Arts and Social Science
   research grant from Huron University College to CDT. We thank Alyssa
   Kuiack for her assistance in participant recruitment, data collection
   and data analysis, and Sabrina Habte for her assistance with participant
   recruitment.
CR Bergelson E, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12724
   Bergeson TR, 2002, PSYCHOL SCI, V13, P72, DOI 10.1111/1467-9280.00413
   Brannon EM, 2007, DEVELOPMENTAL SCI, V10, P770, DOI 10.1111/j.1467-7687.2007.00635.x
   CHANG HW, 1977, CHILD DEV, V48, P1666, DOI 10.2307/1128532
   de Jong K, 2004, J PHONETICS, V32, P493, DOI 10.1016/j.wocn.2004.05.002
   Dietrich C, 2007, P NATL ACAD SCI USA, V104, P16027, DOI 10.1073/pnas.0705270104
   EILERS RE, 1984, J ACOUST SOC AM, V75, P1213, DOI 10.1121/1.390773
   Elert C. C., 1964, PHONOLOGIC STUDIES Q
   Falk S, 2011, LANG SPEECH, V54, P167, DOI 10.1177/0023830910397490
   Galle ME, 2014, PSYCHON B REV, V21, P884, DOI 10.3758/s13423-013-0569-y
   Gogate L, 2016, CHILD DEV, V87, P345, DOI 10.1111/cdev.12509
   HILLENBRAND J, 1984, J ACOUST SOC AM, V76, P18, DOI 10.1121/1.391094
   Hunter M. A., 1988, ADV INFANCY RES, V5, P69, DOI DOI 10.1037/0012-1649.19.3.338
   KLATT DH, 1976, J ACOUST SOC AM, V59, P1208, DOI 10.1121/1.380986
   Ko ES, 2009, J ACOUST SOC AM, V126, pEL134, DOI 10.1121/1.3239465
   Ladefoged Peter, 1996, SOUNDS WORLDS LANGUA
   Levinson SC, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00731
   Lewkowicz DJ, 2006, DEV PSYCHOBIOL, V48, P631, DOI 10.1002/dev.20179
   Mugitani R, 2009, DEV PSYCHOL, V45, P236, DOI 10.1037/a0014043
   Nakata T, 2005, MUSIC PERCEPT, V22, P401, DOI 10.1525/mp.2005.22.3.401
   NELSON DGK, 1995, INFANT BEHAV DEV, V18, P111
   Otte RA, 2013, BIOL PSYCHOL, V92, P315, DOI 10.1016/j.biopsycho.2012.09.009
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   Quene H, 2005, PHONETICA, V62, P1, DOI 10.1159/000087222
   Ramirez-Esparza N, 2014, DEVELOPMENTAL SCI, V17, P880, DOI 10.1111/desc.12172
   Sato Y, 2012, DEV PSYCHOL, V48, P18, DOI 10.1037/a0025528
   Sato Y, 2010, DEV PSYCHOL, V46, P106, DOI 10.1037/a0016718
   Seidl A, 2009, LANG LEARN DEV, V5, P191, DOI 10.1080/15475440902754326
   Trainor LJ, 2004, DEVELOPMENTAL SCI, V7, P289, DOI 10.1111/j.1467-7687.2004.00348.x
   Trainor LJ, 2002, PSYCHON B REV, V9, P335, DOI 10.3758/BF03196290
   Trehub S.E., 1998, ADV INFANCY RES, V12, P43
   Tsang CD, 2017, CHILD DEV, V88, P1207, DOI 10.1111/cdev.12647
   Tsang CD, 2010, INFANT BEHAV DEV, V33, P96, DOI 10.1016/j.infbeh.2009.11.006
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Tsuji S, 2014, DEV PSYCHOBIOL, V56, P179, DOI 10.1002/dev.21179
   Whalen D., 1990, HASKINS LAB STATUS R, P149
   Zheng XJ, 2010, J ACOUST SOC AM, V128, P851, DOI 10.1121/1.3455796
NR 37
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0163-6383
EI 1879-0453
J9 INFANT BEHAV DEV
JI Infant Behav. Dev.
PD NOV
PY 2020
VL 61
AR 101475
DI 10.1016/j.infbeh.2020.101475
PG 7
WC Psychology, Developmental
SC Psychology
GA PR8PP
UT WOS:000607495000008
PM 32768730
DA 2021-02-24
ER

PT J
AU Muller, AM
   Dalal, TC
   Stevenson, RA
AF Muller, Anne-Marie
   Dalal, Tyler C.
   Stevenson, Ryan A.
TI Schizotypal traits are not related to multisensory integration or
   audiovisual speech perception
SO CONSCIOUSNESS AND COGNITION
LA English
DT Article
DE Multisensory integration; Schizophrenia spectrum disorders; Schizotypy;
   Audiovisual; Speech perception; Distractibility; McGurk effect; Ternary
   synchrony judgment task; Speech-in-noise task; Schizophrenia
ID SCHIZOPHRENIA-SPECTRUM DISORDERS; RUBBER HAND ILLUSION; 3-FACTOR
   STRUCTURE; PERSONALITY; SIMULTANEITY; MEMORY; SPOKEN; MODEL; AGE;
   HALLUCINATIONS
AB Multisensory integration, the binding of sensory information from different sensory modalities, may contribute to perceptual symptomatology in schizophrenia, including hallucinations and aberrant speech perception. Differences in multisensory integration and temporal processing, an important component of multisensory integration, are consistently found in schizophrenia. Evidence is emerging that these differences extend across the schizophrenia spectrum, including individuals in the general population with higher schizotypal traits. In the current study, we investigated the relationship between schizotypal traits and perceptual functioning, using audiovisual speech-in-noise, McGurk, and ternary synchrony judgment tasks. We measured schizotypal traits using the Schizotypal Personality Questionnaire (SPQ), hypothesizing that higher scores on Unusual Perceptual Experiences and Odd Speech subscales would be associated with decreased multisensory integration, increased susceptibility to distracting auditory speech, and less precise temporal processing. Surprisingly, these measures were not associated with the predicted subscales, suggesting that these perceptual differences may not be present across the schizophrenia spectrum.
C1 Univ Western Ontario, Dept Psychol, London, ON, Canada.
   Univ Western Ontario, Brain & Mind Inst, London, ON, Canada.
RP Stevenson, RA (corresponding author), Western Interdisciplinary Res Bldg,1151 Richmond, London, ON N6A 5B7, Canada.
EM rsteve28@uwo.ca
FU NSERCNatural Sciences and Engineering Research Council of Canada (NSERC)
   [RGPIN-2017-04656]; SSHRC Insight Grant [435-2017-0936]; University of
   Western Ontario Faculty Development Research Fund; province of Ontario
   Early Researcher AwardMinistry of Research and Innovation, Ontario;
   Canadian Foundation for Innovation John R. Evans Leaders Fund [37497];
   Canada Graduate Scholarship from the Canadian Institutes of Health
   ResearchCanadian Institutes of Health Research (CIHR)
FX RS is funded by an NSERC Discovery Grant (RGPIN-2017-04656), a SSHRC
   Insight Grant (435-2017-0936), the University of Western Ontario Faculty
   Development Research Fund, the province of Ontario Early Researcher
   Award, and a Canadian Foundation for Innovation John R. Evans Leaders
   Fund (37497). AM is funded by a Canada Graduate Scholarship from the
   Canadian Institutes of Health Research.
CR Alcala-Quintana R, 2013, BEHAV RES METHODS, V45, P972, DOI 10.3758/s13428-013-0325-2
   Asai T, 2011, CONSCIOUS COGN, V20, P1744, DOI 10.1016/j.concog.2011.02.005
   Badcock JC, 2006, PERS INDIV DIFFER, V40, P77, DOI 10.1016/j.paid.2005.06.015
   Benson TL, 2019, PSYCH J, V8, P110, DOI 10.1002/pchj.280
   Bestelmeyer PEG, 2012, PSYCHIAT RES, V197, P140, DOI 10.1016/j.psychres.2011.09.030
   Bora E, 2009, PSYCHIAT CLIN NEUROS, V63, P663, DOI 10.1111/j.1440-1819.2009.02011.x
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Braunstein-Bercovitz H, 1998, J ABNORM PSYCHOL, V107, P659, DOI 10.1037/0021-843X.107.4.659
   BULL HC, 1974, BRIT J PSYCHIAT, V125, P350, DOI 10.1192/bjp.125.4.350
   Capa RL, 2014, SCHIZOPHR RES, V156, P51, DOI 10.1016/j.schres.2014.04.001
   Chen WJ, 1997, J ABNORM PSYCHOL, V106, P649, DOI 10.1037/0021-843X.106.4.649
   Corlett PR, 2019, TRENDS COGN SCI, V23, P114, DOI 10.1016/j.tics.2018.12.001
   de Boer-Schellekens L, 2014, ACTA PSYCHOL, V147, P136, DOI 10.1016/j.actpsy.2013.06.013
   de Jong JJ, 2009, SCHIZOPHR RES, V107, P286, DOI 10.1016/j.schres.2008.10.001
   DeLisi LE, 1997, SCHIZOPHRENIA BULL, V23, P255, DOI 10.1093/schbul/23.2.255
   Ettinger U, 2014, FRONT PSYCHIATRY, V5, DOI 10.3389/fpsyt.2014.00018
   Ferri F, 2018, CONSCIOUS COGN, V65, P263, DOI 10.1016/j.concog.2018.09.006
   Ferri F, 2017, SCHIZOPHRENIA BULL, V43, P801, DOI 10.1093/schbul/sbw174
   Ferri F, 2016, SCI REP-UK, V6, DOI 10.1038/srep38735
   Fossati A, 2003, PERS INDIV DIFFER, V35, P1007, DOI 10.1016/S0191-8869(02)00314-8
   Foucher JR, 2007, SCHIZOPHR RES, V97, P118, DOI 10.1016/j.schres.2007.08.013
   Friston K, 2016, SCHIZOPHR RES, V176, P83, DOI 10.1016/j.schres.2016.07.014
   Germine L, 2013, PSYCHIAT RES, V207, P45, DOI 10.1016/j.psychres.2012.11.022
   Giersch A, 2009, SCHIZOPHRENIA BULL, V35, P816, DOI 10.1093/schbul/sbn016
   Hoffman RE, 2007, BRIT J PSYCHIAT, V191, P355, DOI 10.1192/bjp.bp.106.031195
   Hoffman RE, 1999, AM J PSYCHIAT, V156, P393
   Hur JW, 2014, SCHIZOPHR RES, V152, P58, DOI 10.1016/j.schres.2013.08.042
   Jarosz AF, 2014, J PROBL SOLVING, V7, P2, DOI 10.7771/1932-6246.1167
   Javitt DC, 1999, SCHIZOPHRENIA BULL, V25, P763, DOI 10.1093/oxfordjournals.schbul.a033417
   Jones SR, 2007, CONSCIOUS COGN, V16, P391, DOI 10.1016/j.concog.2005.12.003
   Jones SR, 2010, SCHIZOPHRENIA BULL, V36, P566, DOI 10.1093/schbul/sbn129
   Kasai K, 2003, SCHIZOPHR RES, V59, P159, DOI 10.1016/S0920-9964(01)00382-6
   Kasai K, 2002, AM J PSYCHIAT, V159, P546, DOI 10.1176/appi.ajp.159.4.546
   Kessler RC, 2007, CURR OPIN PSYCHIATR, V20, P359, DOI 10.1097/YCO.0b013e32816ebc8c
   Kwapil TR, 2013, J ABNORM PSYCHOL, V122, P807, DOI 10.1037/a0033759
   Lachs L., 1998, 22 IND U
   Lalanne L, 2012, NEUROPSYCHOLOGIA, V50, P2736, DOI 10.1016/j.neuropsychologia.2012.07.023
   Lee SH, 2004, ACTA NEUROPSYCHIATR, V16, P154, DOI 10.1111/j.0924-2708.2004.00071.x
   Li Rena, 2016, J Transl Neurosci (Beijing), V1, P37
   Lim A, 2016, SCHIZOPHR RES, V176, P493, DOI 10.1016/j.schres.2016.06.010
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Marsh JE, 2017, Q J EXP PSYCHOL, V70, P565, DOI 10.1080/17470218.2016.1172094
   Martin B, 2013, NEUROPSYCHOLOGIA, V51, P358, DOI 10.1016/j.neuropsychologia.2012.07.002
   McCarthy-Jones S, 2017, PSYCHIAT RES, V252, P154, DOI 10.1016/j.psychres.2017.01.102
   MCDOWD JM, 1993, SCHIZOPHRENIA BULL, V19, P733, DOI 10.1093/schbul/19.4.733
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MEEHL PE, 1962, AM PSYCHOL, V17, P827, DOI 10.1037/h0041029
   Moser RK, 2001, SCHIZOPHR RES, V51, P163, DOI 10.1016/S0920-9964(00)00122-5
   Muller A.-M., 2020, SCHIZOTYPAL PERSONAL, DOI [10.31234/osf.io/qrmuk., DOI 10.31234/OSF.IO/QRMUK]
   Noel JP, 2018, EUR J NEUROSCI, V47, P1230, DOI 10.1111/ejn.13911
   OLTMANNS TF, 1975, J ABNORM PSYCHOL, V84, P205, DOI 10.1037/h0076721
   Peled A, 2000, BIOL PSYCHIAT, V48, P1105, DOI 10.1016/S0006-3223(00)00947-1
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Quinto L, 2010, ATTEN PERCEPT PSYCHO, V72, P1450, DOI 10.3758/APP.72.6.1450
   RAINE A, 1994, SCHIZOPHRENIA BULL, V20, P191, DOI 10.1093/schbul/20.1.191
   RAINE A, 1991, SCHIZOPHRENIA BULL, V17, P555, DOI 10.1093/schbul/17.4.555
   Reynolds CA, 2000, SCHIZOPHRENIA BULL, V26, P603, DOI 10.1093/oxfordjournals.schbul.a033481
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Ross LA, 2007, SCHIZOPHR RES, V97, P173, DOI 10.1016/j.schres.2007.08.008
   Schmidt H, 2011, J ABNORM PSYCHOL, V120, P476, DOI 10.1037/a0023387
   Schonauer K, 1998, J NERV MENT DIS, V186, P247, DOI 10.1097/00005053-199804000-00008
   Shedlack K, 1997, SCHIZOPHR RES, V25, P43, DOI 10.1016/S0920-9964(97)00004-2
   Stein B. E., 1993, MERGING SENSES, DOI [10.1162/jocn.1993.5.3.373., DOI 10.1162/JOCN.1993.5.3.373]
   Stevenson RA, 2018, AUTISM, V22, P609, DOI 10.1177/1362361317704413
   Stevenson RA, 2017, AUTISM RES, V10, P1280, DOI 10.1002/aur.1776
   Stevenson RA, 2017, SCHIZOPHR RES, V179, P97, DOI 10.1016/j.schres.2016.09.035
   Stevenson RA, 2015, NEUROBIOL AGING, V36, P283, DOI 10.1016/j.neurobiolaging.2014.08.003
   Stevenson RA, 2014, BRAIN TOPOGR, V27, P707, DOI 10.1007/s10548-014-0365-7
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Stevenson RA, 2011, NEUROIMAGE, V55, P1339, DOI 10.1016/j.neuroimage.2010.12.063
   Stevenson RA, 2010, NEUROIMAGE, V49, P3308, DOI 10.1016/j.neuroimage.2009.12.001
   Stevenson RA, 2009, EXP BRAIN RES, V198, P183, DOI 10.1007/s00221-009-1783-8
   Stevenson RA, 2009, NEUROIMAGE, V44, P1210, DOI 10.1016/j.neuroimage.2008.09.034
   Tenckhoff A, 2002, NERVENARZT, V73, P428, DOI 10.1007/s00115-001-1254-3
   Thakkar KN, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027089
   Titone D, 2004, SCHIZOPHR RES, V68, P75, DOI 10.1016/S0920-9964(03)00212-3
   Tseng HH, 2015, NEUROSCI BIOBEHAV R, V55, P444, DOI 10.1016/j.neubiorev.2015.04.019
   Van Doorn G, 2018, COGN NEUROPSYCHIATRY, V23, P284, DOI 10.1080/13546805.2018.1495623
   Vroomen J, 2010, ATTEN PERCEPT PSYCHO, V72, P871, DOI 10.3758/APP.72.4.871
   Williams LE, 2010, NEUROPSYCHOLOGIA, V48, P3128, DOI 10.1016/j.neuropsychologia.2010.06.028
   Wu C, 2012, SCHIZOPHR RES, V134, P33, DOI 10.1016/j.schres.2011.09.019
   Wuthrich VM, 2006, J PERS ASSESS, V87, P292, DOI 10.1207/s15327752jpa8703_10
   Zhou HY, 2018, NEUROSCI BIOBEHAV R, V86, P66, DOI 10.1016/j.neubiorev.2017.12.013
NR 83
TC 1
Z9 1
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8100
EI 1090-2376
J9 CONSCIOUS COGN
JI Conscious. Cogn.
PD NOV
PY 2020
VL 86
AR 103030
DI 10.1016/j.concog.2020.103030
PG 16
WC Psychology, Experimental
SC Psychology
GA PG1OZ
UT WOS:000599513400005
PM 33120291
DA 2021-02-24
ER

PT J
AU Cabrera, L
   Halliday, LF
AF Cabrera, Laurianne
   Halliday, Lorna F.
TI Relationship between sensitivity to temporal fine structure and spoken
   language abilities in children with mild-to-moderate sensorineural
   hearing loss
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH-PERCEPTION; STRUCTURE CUES; FREQUENCY DISCRIMINATION; STRUCTURE
   INFORMATION; MODULATION DETECTION; ENVELOPE; IMPAIRMENT; RECOGNITION;
   AGE; OUTCOMES
AB Children with sensorineural hearing loss show considerable variability in spoken language outcomes. The present study tested whether specific deficits in supra-threshold auditory perception might contribute to this variability. In a previous study by Halliday, Rosen, Tuomainen, and Calcus [(2019). J. Acoust. Soc. Am. 146, 4299], children with mild-to-moderate sensorineural hearing loss (MMHL) were shown to perform more poorly than those with normal hearing (NH) on measures designed to assess sensitivity to the temporal fine structure (TFS; the rapid oscillations in the amplitude of narrowband signals over short time intervals). However, they performed within normal limits on measures assessing sensitivity to the envelope (E; the slow fluctuations in the overall amplitude). Here, individual differences in unaided sensitivity to the TFS accounted for significant variance in the spoken language abilities of children with MMHL after controlling for nonverbal intelligence quotient, family history of language difficulties, and hearing loss severity. Aided sensitivity to the TFS and E cues was equally important for children with MMHL, whereas for children with NH, E cues were more important. These findings suggest that deficits in TFS perception may contribute to the variability in spoken language outcomes in children with sensorineural hearing loss.
C1 [Cabrera, Laurianne] Univ Paris, Ctr Natl Rech Sci CNRS, Integrat Neurosci & Cognit Ctr, F-75006 Paris, France.
   [Halliday, Lorna F.] Univ Cambridge, Med Res Council MRC, Cognit & Brain Sci Unit, Cambridge CB2 7EF, England.
   [Cabrera, Laurianne; Halliday, Lorna F.] UCL, Speech Hearing & Phonet Sci, Div Psychol & Language Sci, London WC1N 1PF, England.
RP Cabrera, L (corresponding author), Univ Paris, Ctr Natl Rech Sci CNRS, Integrat Neurosci & Cognit Ctr, F-75006 Paris, France.
EM laurianne.cabrera@parisdescartes.fr
FU Economic and Social Research Council (ESPC) First Grants Award
   [RES-061-25-0440]; Medical Research Council (MRC) Senior Fellowship in
   Hearing ResearchUK Research & Innovation (UKRI)Medical Research Council
   UK (MRC) [MR/S002464/1]; FP7 people programme (Marie Curie Actions)
   Grant [FP7-607139]; European Union's Horizon 2020 research and
   innovation programme under the Marie Sklodowska-Curie Grant [659204];
   Agence National de la Recherche (ANR), France, under Grant DESINFrench
   National Research Agency (ANR) [ANR-17-CE28-0008]
FX The authors would like to thank Stuart Rosen for constructing the
   stimuli and assisting with extracting psychophysical thresholds, Steve
   Nevard for his assistance with setting up the laboratory facilities,
   Michael Coleman for the development of the psychophysical testing
   software, Paraic Scanlon and Outi Tuomainen for participant testing, and
   Axelle Calcus for help with Fig. 1. The authors are especially grateful
   to all the children who participated, along with their parents, as well
   as the Local Educational Authorities and schools who assisted with
   recruitment. This work was supported by an Economic and Social Research
   Council (ESPC) First Grants Award (Grant No. RES-061-25-0440) and
   Medical Research Council (MRC) Senior Fellowship in Hearing Research
   (Grant No. MR/S002464/1) to L.F. H. and the FP7 people programme (Marie
   Curie Actions) Grant No. FP7-607139 (improving Children's Auditory
   REhabilitation, iCARE). L.C. was supported by the European Union's
   Horizon 2020 research and innovation programme under the Marie
   Sklodowska-Curie Grant No. 659204 and is now supported by the Agence
   National de la Recherche (ANR), France, under Grant No. ANR-17-CE28-0008
   DESIN. The data that support the findings of this study, as well as R
   codes used for the analyses, are available from L.H. via
   email(lorna.halliday@mrc-cbu.cam.ac.uk) upon reasonable request.
CR Ardoint M, 2010, HEARING RES, V260, P89, DOI 10.1016/j.heares.2009.12.002
   Bates D, 2012, PACKAGE LME4
   Bishop D. V. M., 2003, TEST RECEPTION GRAMM
   Blamey PJ, 2001, J SPEECH LANG HEAR R, V44, P264, DOI 10.1044/1092-4388(2001/022)
   British Society of Audiology, 2011, READ BR SOC AUDIOL
   Buss E, 2004, EAR HEARING, V25, P242, DOI 10.1097/01.AUD.0000130796.73809.09
   Ching TYC, 2013, INT J AUDIOL, V52, pS4, DOI 10.3109/14992027.2013.866342
   Corriveau K, 2007, J SPEECH LANG HEAR R, V50, P647, DOI 10.1044/1092-4388(2007/046)
   Corriveau KH, 2009, CORTEX, V45, P119, DOI 10.1016/j.cortex.2007.09.008
   Davidson Lisa S, 2011, Ear Hear, V32, p19S, DOI 10.1097/AUD.0b013e3181ffdb8b
   Davies-Venn E, 2015, J ACOUST SOC AM, V138, P492, DOI 10.1121/1.4922700
   De Vos A, 2017, BRAIN LANG, V164, P106, DOI 10.1016/j.bandl.2016.10.002
   Dockrell JE, 2006, BRIT EDUC RES J, V32, P509, DOI 10.1080/01411920600635494
   DRESCHLER WA, 1985, J ACOUST SOC AM, V78, P1261, DOI 10.1121/1.392895
   DRULLMAN R, 1995, J ACOUST SOC AM, V97, P585, DOI 10.1121/1.413112
   Dunn L.M., 2009, BRIT PICTURE VOCABUL
   GILBERTSON M, 1995, J SPEECH HEAR RES, V38, P630, DOI 10.1044/jshr.3803.630
   Goldsworthy RL, 2019, J SPEECH LANG HEAR R, V62, P758, DOI 10.1044/2018_JSLHR-H-17-0389
   Goswami U, 2002, P NATL ACAD SCI USA, V99, P10911, DOI 10.1073/pnas.122368599
   Goswami U, 2019, ANN NY ACAD SCI, V1453, P67, DOI 10.1111/nyas.14137
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Halliday LF, 2006, BRAIN LANG, V97, P200, DOI 10.1016/j.bandl.2005.10.007
   Halliday LF, 2005, J SPEECH LANG HEAR R, V48, P1187, DOI 10.1044/1092-4388(2005/083)
   Halliday LF, 2019, J ACOUST SOC AM, V146, P4299, DOI 10.1121/1.5134059
   Halliday LF, 2017, J SPEECH LANG HEAR R, V60, P1551, DOI 10.1044/2016_JSLHR-L-16-0297
   Halliday LF, 2017, COGNITION, V166, P139, DOI 10.1016/j.cognition.2017.04.014
   Hamalainen JA, 2008, CLIN NEUROPHYSIOL, V119, P100, DOI 10.1016/j.clinph.2007.09.064
   Henry BA, 2005, J ACOUST SOC AM, V118, P1111, DOI 10.1121/1.1944567
   Henry KS, 2013, HEARING RES, V303, P39, DOI 10.1016/j.heares.2013.01.014
   Hopkins K, 2008, J ACOUST SOC AM, V123, P1140, DOI 10.1121/1.2824018
   Hopkins K, 2011, J ACOUST SOC AM, V130, P334, DOI 10.1121/1.3585848
   Hopkins K, 2010, J ACOUST SOC AM, V127, P1595, DOI 10.1121/1.3293003
   Johannesen PT, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516641055
   Kalashnikova M, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12836
   Klein KE, 2017, J SPEECH LANG HEAR R, V60, P2281, DOI 10.1044/2017_JSLHR-H-16-0086
   Korkman M, 1998, DEV NEUROPSYCHOLOGIC
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   McCreery RW, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01093
   McCreery RW, 2015, EAR HEARING, V36, P309, DOI [10.1097/AUD.0000000000000213, 10.1097/AUD.0000000000000120]
   Mehraei G, 2014, J ACOUST SOC AM, V136, P301, DOI 10.1121/1.4881918
   Moore B. C. J., 2007, COCHLEAR HEARING LOS
   Moore BCJ, 2014, AUDITORY PROCESSING OF TEMPORAL FINE STRUCTURE: EFFECTS OF AGE AND HEARING LOSS, P1, DOI 10.1142/9064
   Moore BCJ, 2012, J ACOUST SOC AM, V132, P1542, DOI 10.1121/1.4739444
   Moore BCJ, 2011, HEARING RES, V276, P88, DOI 10.1016/j.heares.2011.01.003
   Oxenham AJ, 2009, J ACOUST SOC AM, V125, P2189, DOI 10.1121/1.3089220
   Papakonstantinou A, 2011, HEARING RES, V280, P30, DOI 10.1016/j.heares.2011.02.005
   PETERS RW, 1992, J ACOUST SOC AM, V91, P256, DOI 10.1121/1.402769
   Poeppel D, 2008, PHILOS T R SOC B, V363, P1071, DOI 10.1098/rstb.2007.2160
   Power AJ, 2016, BRAIN LANG, V160, P1, DOI 10.1016/j.bandl.2016.06.006
   R Core Team, 2019, R LANG ENV STAT COMP
   Rance G, 2004, EAR HEARING, V25, P34, DOI 10.1097/01.AUD.0000111259.59690.B8
   Ricketts J, 2020, SCI STUD READ, V24, P380, DOI 10.1080/10888438.2019.1689244
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Rosen S, 2003, J PHONETICS, V31, P509, DOI 10.1016/S0095-4470(03)00046-9
   RStudio Team, 2019, RSTUDIO INT DEV ENV
   Semel E, 2006, CLIN EVALUATION LANG
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   Summers V, 2013, J AM ACAD AUDIOL, V24, P274, DOI 10.3766/jaaa.24.4.4
   Swaminathan J, 2012, J NEUROSCI, V32, P1747, DOI 10.1523/JNEUROSCI.4493-11.2012
   TERKEURS M, 1993, J ACOUST SOC AM, V94, P1307, DOI 10.1121/1.408158
   Tomblin JB, 2020, EAR HEARING, V41, P775, DOI 10.1097/AUD.0000000000000823
   Tomblin J Bruce, 2015, Ear Hear, V36 Suppl 1, p76S, DOI 10.1097/AUD.0000000000000219
   Tomblin JB, 2014, JAMA OTOLARYNGOL, V140, P403, DOI 10.1001/jamaoto.2014.267
   Tomblin JB, 1999, J SPEECH LANG HEAR R, V42, P497, DOI 10.1044/jslhr.4202.497
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Wake M, 2005, ARCH DIS CHILD, V90, P238, DOI 10.1136/adc.2003.039354
   Wake M, 2004, AMBUL PEDIATR, V4, P411, DOI 10.1367/A03-191R.1
   Walker EA, 2020, LANG SPEECH HEAR SER, V51, P17, DOI [10.1044/2019_LSHSS-OCHL-19-0015, 10.1044/2019_LSHSS-OCHL_19-0015]
   Walker EA, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02421
   Wallaert N, 2017, J ACOUST SOC AM, V141, P971, DOI 10.1121/1.4976080
   Wechsler D., 2005, WECHSLER INDIVIDUAL, V2nd edn
   Wechsler D., 1999, ABBREVIATED SCALE IN
   Wickham H., 2019, GGPLOT2 CREATE ELEGA
   WIER CC, 1977, J ACOUST SOC AM, V61, P178, DOI 10.1121/1.381251
   Xu YY, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12975-3
   Yoshinaga-Itano C, 1998, PEDIATRICS, V102, P1161, DOI 10.1542/peds.102.5.1161
   Zeng FG, 2004, J ACOUST SOC AM, V116, P1351, DOI 10.1121/1.1777938
   Ziegler JC, 2005, P NATL ACAD SCI USA, V102, P14110, DOI 10.1073/pnas.0504446102
NR 80
TC 0
Z9 0
U1 2
U2 2
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD NOV
PY 2020
VL 148
IS 5
BP 3334
EP 3347
DI 10.1121/10.0002669
PG 14
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA PB7RV
UT WOS:000596514700005
PM 33261401
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Helfer, KS
   van Emmerik, R
   Banks, JJ
   Freyman, RL
AF Helfer, Karen S.
   van Emmerik, Richard
   Banks, Jacob J.
   Freyman, Richard L.
TI Early aging and postural control while listening and responding
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID AGE-RELATED DIFFERENCES; OLDER-ADULTS; HEARING-AIDS; SPEECH-PERCEPTION;
   BALANCE; WALKING; STABILITY; FALLS; GAIT; PREDICTOR
AB It is not unusual for communication to take place while people are involved in another activity. This paper describes a study that measures the impact of listening while also completing an active postural control task. The focus was on whether the combination of listening and balancing was more detrimental to middle-aged adults than it was to younger adults as age-related changes in both hearing and postural control can occur within this age range. Speech understanding in the presence of noise and speech maskers was measured when participants (n = 15/group) were simply standing still, as well as when they were asked to complete a balancing-with-feedback postural control task, requiring different levels of effort. Performance on the postural control task also was measured in isolation. Results indicated that dual-task costs for postural control were larger when the masker was speech (vs noise) for the middle-aged group but not for the younger group. Dual-task costs in postural control increased with degree of high-frequency hearing loss even when age was controlled. Overall, results suggest that postural control in middle-aged adults can be compromised when individuals are communicating in challenging environments, perhaps reflecting an increased need for cognitive resources to successfully understand messages.
C1 [Helfer, Karen S.; Freyman, Richard L.] Univ Massachusetts, Dept Commun Disorders, 358 North Pleast St, Amherst, MA 01003 USA.
   [van Emmerik, Richard; Banks, Jacob J.] Univ Massachusetts, Dept Kinesiol, Tolman Bldg, Amherst, MA 01003 USA.
RP Helfer, KS (corresponding author), Univ Massachusetts, Dept Commun Disorders, 358 North Pleast St, Amherst, MA 01003 USA.
EM khelfer@comdis.umass.edu
FU National Institutes of Health (NIH)/National Institute on Deafness and
   Other Communication Disorders (NIDCD)United States Department of Health
   & Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute on Deafness & Other Communication Disorders (NIDCD) [R01 DC
   012057]
FX The authors thank Michael Rogers, Lincoln Dunn, and Mike Clauss for
   their assistance with this project. This work was supported by research
   Grant No. R01 DC 012057 from the National Institutes of Health
   (NIH)/National Institute on Deafness and Other Communication Disorders
   (NIDCD).
CR [Anonymous], 2017, CELL ADHES MIGR, V21, P1, DOI DOI 10.1177/2331216517737230
   [Anonymous], 2015, PHYSIOL MEAS, V36, pR1, DOI DOI 10.1097/AUD.0000000000000195
   [Anonymous], 2018, MED BALTIMORE, V97, pe9654, DOI DOI 10.1097/MD.0000000000010244
   [Anonymous], 2014, J ACOUST SOC AM, V135, pEL88, DOI [10.1121/1.4862879, DOI 10.1121/1.4865261]
   [Anonymous], 2017, DIABETOLOGIE STOF S2, V12, pS94, DOI [10.1055/s-0043-115953, DOI 10.1371/journal.pone.0181698]
   [Anonymous], 2019, CIRCULATION, V2019
   Ayers EI, 2014, GERONTOLOGY, V60, P108, DOI 10.1159/000355119
   Aylward SR, 2002, IEEE T MED IMAGING, V21, P61, DOI 10.1109/42.993126
   Bainbridge KE, 2014, ANNU REV PUBL HEALTH, V35, P139, DOI 10.1146/annurev-publhealth-032013-182510
   Boisgontier MP, 2013, NEUROSCI BIOBEHAV R, V37, P1824, DOI 10.1016/j.neubiorev.2013.07.014
   Bruce H., 2017, J GERONTOL B-PSYCHOL, V74, P275
   Cameron S, 2011, J AM ACAD AUDIOL, V22, P697, DOI 10.3766/jaaa.22.10.7
   Campos J, 2018, HEARING RES, V369, P42, DOI 10.1016/j.heares.2018.03.025
   Carpenter MG, 2001, GAIT POSTURE, V13, P35, DOI 10.1016/S0966-6362(00)00093-X
   COX RM, 1987, EAR HEARING, V8, pS119, DOI 10.1097/00003446-198710001-00010
   Dault MC, 2003, COGNITIVE BRAIN RES, V16, P434, DOI 10.1016/S0926-6410(03)00058-2
   Degeest S, 2015, J SPEECH LANG HEAR R, V58, P1592, DOI 10.1044/2015_JSLHR-H-14-0288
   Demeester K, 2012, EAR HEARING, V33, P615, DOI 10.1097/AUD.0b013e31824e0ba7
   Deviterne D, 2005, BRAIN RES BULL, V64, P487, DOI 10.1016/j.brainresbull.2004.10.007
   Dozza M, 2011, GAIT POSTURE, V34, P313, DOI 10.1016/j.gaitpost.2011.05.016
   Duarte M, 2010, REV BRAS FISIOTER, V14, P183, DOI 10.1590/S1413-35552010000300003
   Fraizer EV, 2008, GAIT POSTURE, V27, P271, DOI 10.1016/j.gaitpost.2007.04.002
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Gandemer L, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00357
   Ghosh A, 2000, IEEE T POWER DELIVER, V15, P417, DOI 10.1109/61.847283
   Glyde H, 2013, EAR HEARING, V34, P15, DOI 10.1097/AUD.0b013e3182617f94
   Goossens T, 2017, HEARING RES, V344, P109, DOI 10.1016/j.heares.2016.11.004
   Granacher U, 2011, GERONTOLOGY, V57, P247, DOI 10.1159/000322196
   Hannula S, 2011, J AM ACAD AUDIOL, V22, P550, DOI 10.3766/jaaa.22.8.7
   Helfer KS, 2020, EAR HEARING, V41, P1383, DOI 10.1097/AUD.0000000000000861
   Helfer KS, 2018, INT J AUDIOL, V57, P695, DOI 10.1080/14992027.2018.1475756
   Helfer KS, 2017, J SPEECH LANG HEAR R, V60, P3009, DOI 10.1044/2017_JSLHR-H-17-0030
   Helfer KS, 2016, J ACOUST SOC AM, V140, P3844, DOI 10.1121/1.4967297
   Helfer KS, 2016, J ACOUST SOC AM, V140, pEL371, DOI 10.1121/1.4966586
   Helfer KS, 2014, J ACOUST SOC AM, V136, P748, DOI 10.1121/1.4887463
   Hollman JH, 2007, GAIT POSTURE, V26, P113, DOI 10.1016/j.gaitpost.2006.08.005
   Jiam NTL, 2016, LARYNGOSCOPE, V126, P2587, DOI 10.1002/lary.25927
   Kahneman D., 1973, ATTENTION EFFORT
   Kemper S, 2003, PSYCHOL AGING, V18, P181, DOI 10.1037/0882-7974.18.2.181
   Ku PX, 2016, J BIOMECH, V49, P3943, DOI 10.1016/j.jbiomech.2016.11.006
   LAJOIE Y, 1993, EXP BRAIN RES, V97, P139
   Li LS, 2013, GAIT POSTURE, V38, P25, DOI 10.1016/j.gaitpost.2012.10.006
   Lin FR, 2012, ARCH INTERN MED, V172, P369, DOI 10.1001/archinternmed.2011.728
   McDaniel DM, 2018, AM J AUDIOL, V27, P121, DOI 10.1044/2017_AJA-16-0071
   Mitrega KA, 2016, APOPTOSIS, V21, P195, DOI 10.1007/s10495-015-1205-2
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Negahban H, 2017, GAIT POSTURE, V58, P126, DOI 10.1016/j.gaitpost.2017.07.112
   Park JH, 2016, EXP GERONTOL, V85, P48, DOI 10.1016/j.exger.2016.09.018
   Pinsault N, 2008, ARCH PHYS MED REHAB, V89, P1772, DOI 10.1016/j.apmr.2008.02.024
   Raffegeau TE, 2018, GAIT POSTURE, V64, P59, DOI 10.1016/j.gaitpost.2018.05.029
   Regierungsprasidium Stuttgart, 2018, TEILPLAN LANDESHAUPT, V3, P12
   Ross JM, 2016, NEUROSCI LETT, V630, P216, DOI 10.1016/j.neulet.2016.07.060
   Ruffieux J, 2015, SPORTS MED, V45, P1739, DOI 10.1007/s40279-015-0369-9
   Rumalla K, 2015, LARYNGOSCOPE, V125, P720, DOI 10.1002/lary.24974
   Saul M, 2015, HUM RIGHTS LAW REV, V15, P745, DOI 10.1093/hrlr/ngv027
   Shinn-Cunningham B, 2013, ADV EXP MED BIOL, V787, P501, DOI 10.1007/978-1-4614-1590-9_55
   Stevens MN, 2016, J VESTIBUL RES-EQUIL, V26, P433, DOI 10.3233/VES-160599
   Vaillant J, 2004, ARCH PHYS MED REHAB, V85, P1962, DOI 10.1016/j.apmr.2004.02.019
   van Emmerik REA, 2002, EXERC SPORT SCI REV, V30, P177, DOI 10.1097/00003677-200210000-00007
   Viljanen A, 2009, J AM GERIATR SOC, V57, P2282, DOI 10.1111/j.1532-5415.2009.02553.x
   Viljanen A, 2009, J GERONTOL A-BIOL, V64, P312, DOI 10.1093/gerona/gln015
   Weaver TS, 2017, OTOL NEUROTOL, V38, P1327, DOI 10.1097/MAO.0000000000001551
   Wiley T L, 1998, J Am Acad Audiol, V9, P191
   Wymann MP, 2008, NAT REV MOL CELL BIO, V9, P162, DOI 10.1038/nrm2335
   Yardley L, 1999, NEUROREPORT, V10, P215, DOI 10.1097/00001756-199902050-00003
   Zhong X, 2013, J AM ACAD AUDIOL, V24, P782, DOI 10.3766/jaaa.24.9.3
NR 66
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD NOV
PY 2020
VL 148
IS 5
BP 3117
EP 3130
DI 10.1121/10.0002485
PG 14
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA PA6OG
UT WOS:000595751800010
PM 33261409
DA 2021-02-24
ER

PT J
AU Guediche, S
   Baart, M
   Samuel, AG
AF Guediche, Sara
   Baart, Martijn
   Samuel, Arthur G.
TI Semantic priming effects can be modulated by crosslinguistic
   interactions during second-language auditory word recognition
SO BILINGUALISM-LANGUAGE AND COGNITION
LA English
DT Article
DE speech perception; speech in noise; lexical-semantics; cognate effects;
   lexical decision
ID SPEECH-IN-NOISE; EMBEDDED WORDS; LEXICAL COMPETITION; ENGLISH
   BILINGUALS; COGNATE STATUS; LANGUAGE; IDENTIFICATION; ACTIVATION;
   TRANSLATION; PROFICIENCY
AB The current study investigates how second language auditory word recognition, in early and highly proficient Spanish-Basque (L1-L2) bilinguals, is influenced by crosslinguistic phonological-lexical interactions and semantic priming. Phonological overlap between a word and its translation equivalent (phonological cognate status), and semantic relatedness of a preceding prime were manipulated. Experiment 1 examined word recognition performance in noisy listening conditions that introduce a high degree of uncertainty, whereas Experiment 2 employed clear listening conditions, with low uncertainty. Under noisy listening conditions, semantic priming effects interacted with phonological cognate status: for word recognition accuracy, a related prime overcame inhibitory effects of phonological overlap between target words and their translations. These findings are consistent with models of bilingual word recognition that incorporate crosslinguistic phonological-lexical-semantic interactions. Moreover, they suggest an interplay between L2-L1 interactions and the integration of information across acoustic and semantic levels of processing in flexibly mapping the speech signal onto the spoken words, under adverse listening conditions.
C1 [Guediche, Sara; Baart, Martijn; Samuel, Arthur G.] BCBL Basque Ctr Cognit Brain & Language, San Sebastian, Spain.
   [Baart, Martijn] Tilburg Univ, Dept Cognit Neuropsychol, Tilburg, Netherlands.
   [Samuel, Arthur G.] SUNY Stony Brook, Stony Brook, NY 11794 USA.
   [Samuel, Arthur G.] Ikerbasque, Basque Fdn Sci, Bilbao, Spain.
RP Guediche, S (corresponding author), BCBL Basque Ctr Cognit Brain & Language, San Sebastian, Spain.
EM s.guediche@bcbl.eu
FU Spanish Ministry of Science and InnovationSpanish Government
   [PSI2017-82563-P]; Netherlands Organization for Scientific research (NWO
   Veni grant)Netherlands Organization for Scientific Research (NWO)
   [275-89-027]; Basque Government through the BERC 2018-2021 programBasque
   Government; Spanish State Agency Severo Ochoa excellence accreditation
   [SEV-2015-0490]; European UnionEuropean Commission [799554]
FX The authors thank Angela de Bruin for helping with the PsychoPy
   programming, Sara Martinez Narvarte, for help with the Basque
   semantic-prime stimulus design, Paula Rios-Lopez for providing the
   babble recording, Ainhoa Bastarrika-Iriarte for facilitating the
   automatization of noisy stimulus creation, Itziar Basterra, Amets Esnal,
   Larraitz Lopez for running participants in Basque, and Clara Martin,
   Sendy Caffarra, Angela de Bruin, and Effie Kapnoula for helpful
   discussions. In addition, we thank two anonymous reviewers for helpful
   comments during the revision process. This research was funded by the
   Spanish Ministry of Science and Innovation (Grant PSI2017-82563-P,
   awarded to A.G.S.), the Netherlands Organization for Scientific research
   (NWO Veni grant 275-89-027, awarded to M.B.), the Basque Government
   through the BERC 2018-2021 program, and the Spanish State Agency Severo
   Ochoa excellence accreditation SEV-2015-0490; Programme for
   Centres/Units of Excellence (awarded to the BCBL), and the European
   Union's Horizon 2020 research and innovation programme under the Marie
   Sklodowska-Curie grant agreement No. 799554.
CR Acheson DJ, 2012, BRAIN LANG, V123, P131, DOI 10.1016/j.bandl.2012.08.008
   [Anonymous], 2007, J BRAS PNEUMOL S2, V33, pS51
   Barroso N, 2010, ADV INTEL SOFT COMPU, V71, P697
   Blanco-Elorrieta E, 2019, 609628 BIORXIV, DOI [10.1101/609628, DOI 10.1101/609628]
   Blumenfeld HK, 2016, INT J SPEECH-LANG PA, V18, P190, DOI 10.3109/17549507.2015.1081288
   Blumenfeld HK, 2005, P ANN M COGN SCI SOC
   Bowers JS, 2009, J EXP PSYCHOL HUMAN, V35, P1585, DOI 10.1037/a0015870
   Bowers JS, 2000, PSYCHON B REV, V7, P83, DOI 10.3758/BF03210726
   Broersma M, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01461
   Bultena S, 2014, Q J EXP PSYCHOL, V67, P1214, DOI 10.1080/17470218.2013.853090
   CARAMAZZA A, 1979, B PSYCHONOMIC SOC, V13, P212, DOI 10.3758/BF03335062
   Chen Q, 2015, COGNITIVE SCI, V39, P538, DOI 10.1111/cogs.12156
   Chiarello C, 2018, NEUROPSYCHOLOGIA, V111, P103, DOI 10.1016/j.neuropsychologia.2018.01.032
   Costa A, 2000, J EXP PSYCHOL LEARN, V26, P1283, DOI 10.1037//0278-7393.26.5.1283
   Coumans J, 2014, INTERSPEECH, P519
   Cutler A, 2004, J ACOUST SOC AM, V116, P3668, DOI 10.1121/1.1810292
   Cutler A, 2005, NEWSLETTER AM ASS TE, V48, P16
   de Bruin A, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00522
   Dijkstra T., 2007, HDB PSYCHOLINGUISTIC, P251
   Dijkstra T, 2019, BILING-LANG COGN, V22, P703, DOI 10.1017/S1366728918000986
   Dijkstra T, 2015, BILING-LANG COGN, V18, P597, DOI 10.1017/S1366728914000388
   Dijkstra T, 2002, BILING-LANG COGN, V5, P175, DOI 10.1017/S1366728902003012
   Dunabeitia J.A., BASP BASQUE SPANISH
   Golestani N, 2009, BILING-LANG COGN, V12, P385, DOI 10.1017/S1366728909990150
   Gollan TH, 1997, J EXP PSYCHOL LEARN, V23, P1122, DOI 10.1037/0278-7393.23.5.1122
   Hernandez A, 2005, TRENDS COGN SCI, V9, P220, DOI 10.1016/j.tics.2005.03.003
   Hervais-Adelman A, 2014, BRAIN LANG, V132, P1, DOI 10.1016/j.bandl.2014.01.009
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Kim JH, 2019, FRONT NANOSCI, P103, DOI 10.1016/B978-0-08-102572-7.00004-0
   Kousaie S, 2019, BRAIN LANG, V196, DOI 10.1016/j.bandl.2019.104645
   Krizman J, 2017, BILING-LANG COGN, V20, P834, DOI 10.1017/S1366728916000444
   Kroll JF, 2010, BILING-LANG COGN, V13, P373, DOI 10.1017/S136672891000009X
   Larraza S, 2016, J EXP PSYCHOL LEARN, V42, P1774, DOI 10.1037/xlm0000252
   Lemhofer K, 2004, MEM COGNITION, V32, P533, DOI 10.3758/BF03195845
   LI P, 2002, BILINGUAL SENTENCE P
   Manoj PDS, 2015, IEEE T COMPUT, V64, P3022, DOI 10.1109/TC.2015.2389827
   MARSLENWILSON W, 1994, PSYCHOL REV, V101, P3, DOI 10.1037/0033-295X.101.1.3
   Morini G, 2019, LANG SPEECH
   Peeters D, 2013, J MEM LANG, V68, P315, DOI 10.1016/j.jml.2012.12.003
   Perea M, 2008, J MEM LANG, V58, P916, DOI 10.1016/j.jml.2008.01.003
   Poort ED, 2017, ACTA PSYCHOL, V180, P52, DOI 10.1016/j.actpsy.2017.08.008
   Reetzke R, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168048
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Salverda AP, 2003, COGNITION, V90, P51, DOI 10.1016/S0010-0277(03)00139-2
   Samuel AG, 2015, PSYCHON B REV, V22, P1746, DOI 10.3758/s13423-015-0847-y
   Scharenborg O., 2019, SPEECH COMMUNICATION
   Schmidtke J, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00678
   Sheng L, 2016, J EXP CHILD PSYCHOL, V141, P229, DOI 10.1016/j.jecp.2015.09.007
   Shi LF, 2015, AM J AUDIOL, V24, P53, DOI 10.1044/2014_AJA-14-0041
   Shi LF, 2014, INT J AUDIOL, V53, P30, DOI 10.3109/14992027.2013.825052
   Shi LF, 2012, J SPEECH LANG HEAR R, V55, P219, DOI 10.1044/1092-4388(2011/10-0240)
   Shook A, 2013, BILING-LANG COGN, V16, P304, DOI 10.1017/S1366728912000466
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Taler V, 2010, J GERONTOL B-PSYCHOL, V65, P551, DOI 10.1093/geronb/gbq039
   Temnikova IG, 2015, PROCD SOC BEHV, V200, P381, DOI 10.1016/j.sbspro.2015.08.082
   Thomas MS, 2005, HDB BILINGUALISM PSY, P202
   van Hell JG, 2008, ACTA PSYCHOL, V128, P431, DOI 10.1016/j.actpsy.2008.03.010
   van Hell JG, 2002, PSYCHON B REV, V9, P780, DOI 10.3758/BF03196335
   van Heuven WJ, 2005, 2 LANGUAGE WRITING S, P260, DOI 10.21832/9781853597954-012
   van Heuven WJB, 1998, J MEM LANG, V39, P458, DOI 10.1006/jmla.1998.2584
   Vroomen J, 1997, J EXP PSYCHOL HUMAN, V23, P710, DOI 10.1037/0096-1523.23.3.710
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0
   Zhang XJ, 2018, J MEM LANG, V100, P32, DOI 10.1016/j.jml.2018.01.002
   Zhang XJ, 2015, J MEM LANG, V79, P53, DOI 10.1016/j.jml.2014.12.001
NR 64
TC 0
Z9 0
U1 4
U2 4
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 1366-7289
EI 1469-1841
J9 BILING-LANG COGN
JI Biling.-Lang. Cogn.
PD NOV
PY 2020
VL 23
IS 5
BP 1082
EP 1092
AR PII S1366728920000164
DI 10.1017/S1366728920000164
PG 11
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA PA0LT
UT WOS:000595309000016
DA 2021-02-24
ER

PT J
AU Brosseau-Lapre, F
   Schumaker, J
   Kluender, KR
AF Brosseau-Lapre, Francoise
   Schumaker, Jennifer
   Kluender, Keith R.
TI Perception of Medial Consonants by Preschoolers With and Without Speech
   Sound Disorders
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID PHONOLOGICAL AWARENESS; CHILDREN; SKILLS; IMPAIRMENT; DYSLEXIA;
   DEFICITS; DELAY
AB Purpose: This study compared perception of consonants in medial position by preschoolers, with and without speech sound disorder (SSD), with similar vocabulary and language skills. In addition, we investigated the association between speech perception and production skills.
   Method: Participants were 36 monolingual English-speaking children with similar vocabulary and language skills, half with SSD and half with typical speech and language development (TD). Participants completed a speech perception task targeting phonemes /p, k, s, / in /aCa/ disyllables and a comprehensive battery of speech and language measures.
   Results: Children with SSD were significantly less accurate in perceiving speech sound distinctions relative to peers with TD. The phoneme /p/ was perceived significantly more accurately than the three other target phonemes. The correlation between overall perceptual accuracy and overall production accuracy was significant. Furthermore, perceptual accuracy of targets /k, s, / was significantly correlated with production accuracy of these phonemes.
   Conclusions: Many children with SSD have greater difficulty perceiving the specific speech sounds they misarticulate. Nonetheless, most children with SSD present with broader perceptual difficulties than peers with TD with similar vocabulary and language skills.
C1 [Brosseau-Lapre, Francoise; Schumaker, Jennifer; Kluender, Keith R.] Purdue Univ, Dept Speech Language & Hearing Sci, W Lafayette, IN 47907 USA.
RP Brosseau-Lapre, F (corresponding author), Purdue Univ, Dept Speech Language & Hearing Sci, W Lafayette, IN 47907 USA.
EM fbrossea@purdue.edu
OI Brosseau-Lapre, Francoise/0000-0002-6638-5383
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [NIDCD R21DC016142]
FX The work reported in this article was supported by a grant from the
   National Institutes of Health (NIDCD R21DC016142, F. Brosseau-Lapre,
   PI). We thank the children and parents who participated in the study. We
   also thank members of the Purdue Child Phonology Lab for their valuable
   assistance during the project and, in particular, Kathryn Bower and
   Elizabeth Roepke for transcription, Brittany Miller for illustrations,
   and Rose Reyling for assistance in programming.
CR Alexander JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0024630
   Alonzo CN, 2020, J SPEECH LANG HEAR R, V63, P151, DOI 10.1044/2019_JSLHR-L-18-0265
   Anthony JL, 2011, AM J SPEECH-LANG PAT, V20, P146, DOI 10.1044/1058-0360(2011/10-0053)
   Bent T, 2014, J CHILD LANG, V41, P1334, DOI 10.1017/S0305000913000457
   Brosseau-Lapre F, 2020, AM J SPEECH-LANG PAT, V29, P883, DOI 10.1044/2020_AJSLP-19-00062
   Brosseau-Lapre F, 2019, J SPEECH LANG HEAR R, V62, P3276, DOI 10.1044/2019_JSLHR-S-17-0461
   Brosseau-Lapre F, 2014, INT J SPEECH-LANG PA, V16, P98, DOI 10.3109/17549507.2013.794863
   Cabbage KL, 2016, SPEECH COMMUN, V82, P14, DOI 10.1016/j.specom.2016.05.002
   Claessen M, 2009, INT J LANG COMM DIS, V44, P121, DOI 10.1080/13682820801966317
   Coady JA, 2007, J SPEECH LANG HEAR R, V50, P41, DOI 10.1044/1092-4388(2007/004)
   Dawson J., 2005, STRUCTURED PHOTOGRAP
   Dodd B. J., 2006, DIAGNOSTIC EVALUATIO
   Dodd B, 2011, TOP LANG DISORD, V31, P96, DOI 10.1097/TLD.0b013e318217b66a
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   Edwards J, 2002, J SPEECH LANG HEAR R, V45, P231, DOI 10.1044/1092-4388(2002/018)
   Edwards J, 1999, J SPEECH LANG HEAR R, V42, P169, DOI 10.1044/jslhr.4201.169
   Elbro C., 2002, PRECURSORS FUNCTIONA
   Endress AD, 2010, J EXP PSYCHOL HUMAN, V36, P235, DOI 10.1037/a0017164
   Gierut JA, 1998, J SPEECH LANG HEAR R, V41, pS85, DOI 10.1044/jslhr.4101.s85
   Goldman R., 2015, GOLDMAN FRISTOE TEST, V3rd edition.
   Gray S, 1999, LANG SPEECH HEAR SER, V30, P196, DOI 10.1044/0161-1461.3002.196
   Hearnshaw S, 2019, J SPEECH LANG HEAR R, V62, P3771, DOI 10.1044/2019_JSLHR-S-18-0519
   Hearnshaw S, 2018, J COMMUN DISORD, V71, P61, DOI 10.1016/j.jcomdis.2017.12.004
   Kaufman A., 2004, KAUFMAN BRIEF INTELL, V2nd
   Lewis BA, 2000, J LEARN DISABIL-US, V33, P433, DOI 10.1177/002221940003300504
   McCormack J, 2009, INT J SPEECH-LANG PA, V11, P155, DOI 10.1080/17549500802676859
   McLeod S, 2018, AM J SPEECH-LANG PAT, V27, P1546, DOI 10.1044/2018_AJSLP-17-0100
   Mcleod S, 2014, CLIN LINGUIST PHONET, V28, P508, DOI 10.3109/02699206.2014.926994
   McLeod S, 2009, J SPEECH LANG HEAR R, V52, P1213, DOI 10.1044/1092-4388(2009/08-0085)
   McNeill BC, 2010, INT J LANG COMM DIS, V45, P72, DOI 10.3109/13682820902745479
   MINES MA, 1978, LANG SPEECH, V21, P221, DOI 10.1177/002383097802100302
   PICKETT JM, 1995, PHONETICA, V52, P1, DOI 10.1159/000262027
   Psychological Software Tools Inc, 2017, E PRIM VERS 3 0
   Raitano NA, 2004, J CHILD PSYCHOL PSYC, V45, P821, DOI 10.1111/j.1469-7610.2004.00275.x
   Ramus F, 2013, BRAIN, V136, P630, DOI 10.1093/brain/aws356
   Roepke E, 2019, J SPEECH LANG HEAR R, V62, P3763, DOI 10.1044/2019_JSLHR-S-19-0127
   Rvachew S, 2006, J SPEECH LANG HEAR R, V49, P74, DOI 10.1044/1092-4388(2006/006)
   Rvachew S, 2004, AM J SPEECH-LANG PAT, V13, P250, DOI 10.1044/1058-0360(2004/026)
   RVACHEW S, 1989, J SPEECH HEAR DISORD, V54, P193, DOI 10.1044/jshd.5402.193
   Rvachew S., 2018, DEV PHONOLOGICAL DIS, VSecond
   Rvachew S, 2007, AM J SPEECH-LANG PAT, V16, P260, DOI 10.1044/1058-0360(2007/030)
   Shriberg LD, 1999, J SPEECH LANG HEAR R, V42, P1461, DOI 10.1044/jslhr.4206.1461
   SHRIBERG LD, 1993, J SPEECH HEAR RES, V36, P105, DOI 10.1044/jshr.3601.105
   Skahan SM, 2007, AM J SPEECH-LANG PAT, V16, P246, DOI 10.1044/1058-0360(2007/029)
   SMIT AB, 1993, J SPEECH HEAR RES, V36, P533, DOI 10.1044/jshr.3603.533
   Smit AB, 2018, AM J SPEECH-LANG PAT, V27, P536, DOI 10.1044/2017_AJSLP-16-0225
   St Louis K.O., 2000, ORAL SPEECH MECH SCR
   Stackhouse J., 1997, CHILDRENS SPEECH LIT
   VanRiper C., 1963, SPEECH CORRECTION PR
   Wagner R. K., 2013, COMPREHENSIVE TEST P, DOI [10.1037/t52630-000, DOI 10.1037/T52630-000]
   Wang YY, 2016, LANG LEARN DEV, V12, P447, DOI 10.1080/15475441.2016.1150185
   Webber S. G., 2000, W JUMBO ARTICULATION
   Williams K. T., 2007, EXPRESSIVE VOCABULAR, DOI [10.1037/t15094-000, DOI 10.1037/T15094-000]
NR 53
TC 0
Z9 0
U1 1
U2 1
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD NOV
PY 2020
VL 63
IS 11
BP 3600
EP 3610
DI 10.1044/2020_JSLHR-20-00146
PG 11
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA OS4XF
UT WOS:000590167400004
PM 32976079
DA 2021-02-24
ER

PT J
AU Buchanan-Worster, E
   MacSweeney, M
   Pimperton, H
   Kyle, F
   Harris, M
   Beedie, I
   Ralph-Lewis, A
   Hulme, C
AF Buchanan-Worster, Elizabeth
   MacSweeney, Mairead
   Pimperton, Hannah
   Kyle, Fiona
   Harris, Margaret
   Beedie, Indie
   Ralph-Lewis, Amelia
   Hulme, Charles
TI Speechreading Ability Is Related to Phonological Awareness and
   Single-Word Reading in Both Deaf and Hearing Children
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID VISUAL SPEECH-PERCEPTION; HARD-OF-HEARING; PHONETIC INFORMATION; SKILLS;
   LIPS; DISCRIMINATION; CONTRIBUTES; ACHIEVEMENT; PERFORMANCE; PREDICTORS
AB Purpose: Speechreading (lipreading) is a correlate of reading ability in both deaf and hearing children. We investigated whether the relationship between speechreading and single -word reading is mediated by phonological awareness in deaf and hearing children.
   Method: In two separate studies, 66 deaf children and 138 hearing children, aged 5-8 years old, were assessed on measures of speechreading, phonological awareness, and single-word reading. We assessed the concurrent relationships between latent variables measuring speechreading, phonological awareness, and single-word reading.
   Results: In both deaf and hearing children, there was a strong relationship between speechreading and single -word reading, which was fully mediated by phonological awareness.
   Conclusions: These results are consistent with ideas from previous studies that visual speech information contributes to the development of phonological representations in both deaf and hearing children, which, in turn, support learning to read. Future longitudinal and training studies are required to establish whether these relationships reflect causal effects.
C1 [Buchanan-Worster, Elizabeth; MacSweeney, Mairead; Pimperton, Hannah] UCL, Inst Cognit Neurosci, London, England.
   [Buchanan-Worster, Elizabeth; MacSweeney, Mairead; Kyle, Fiona; Beedie, Indie; Ralph-Lewis, Amelia] UCL, Deafness Cognit & Language Res Ctr, London, England.
   [Harris, Margaret] Oxford Brookes Univ, Fac Hlth & Life Sci, Oxford, England.
   [Hulme, Charles] Univ Oxford, Dept Educ, Oxford, England.
RP Buchanan-Worster, E (corresponding author), UCL, Inst Cognit Neurosci, London, England.; Buchanan-Worster, E (corresponding author), UCL, Deafness Cognit & Language Res Ctr, London, England.
EM e.buchanan-worster@ucl.ac.uk
OI Buchanan-Worster, Elizabeth/0000-0003-4630-5945
FU Wellcome Trust Senior Research FellowshipWellcome Trust [100229/Z/12/Z];
   Economic and Social Research Council PhD StudentshipUK Research &
   Innovation (UKRI)Economic & Social Research Council (ESRC) [1474670];
   Economic and Social Research Council (Deafness Cognition and Language
   Research Centre) [RES-620-28-0002]
FX This research was supported by Wellcome Trust Senior Research Fellowship
   awarded to M. M. (100229/Z/12/Z). E. B.-W. was supported by an Economic
   and Social Research Council PhD Studentship (1474670). A. R.-L. was
   supported by the Economic and Social Research Council (Deafness
   Cognition and Language Research Centre; RES-620-28-0002). Many thanks to
   Laura Monroy for assistance with testing and to all schools that
   participated.
CR Altvater-Mackensen N, 2015, CHILD DEV, V86, P362, DOI 10.1111/cdev.12320
   Arnold P, 1996, SCAND AUDIOL, V25, P13, DOI 10.3109/01050399609047550
   Bernstein LE, 2000, PERCEPT PSYCHOPHYS, V62, P233, DOI 10.3758/BF03205546
   Bus AG, 1999, J EDUC PSYCHOL, V91, P403, DOI 10.1037/0022-0663.91.3.403
   CAMPBELL R, 1988, Q J EXP PSYCHOL-A, V40, P771, DOI 10.1080/14640748808402298
   Campbell R., 2011, 1 INT C COGN HEAR SC
   Carroll JM, 2003, DEV PSYCHOL, V39, P913, DOI 10.1037/0012-1649.39.5.913
   Colin S, 2007, J CHILD PSYCHOL PSYC, V48, P139, DOI 10.1111/j.1469-7610.2006.01700.x
   Conrad R., 1979, DEAF SCH CHILD LANGU
   CORNETT RO, 1967, AM ANN DEAF, V112, P3
   DODD B, 1977, PERCEPT PSYCHOPHYS, V21, P413, DOI 10.3758/BF03199495
   Dodd B., 1998, HEARING EYE, P229
   Dodd B., 1983, BRIT J DEV PSYCHOL, V1, P353
   Dyer A., 2003, J DEAF STUD DEAF EDU, V8, P215, DOI [10.1093/deafed/eng012, DOI 10.1093/DEAFED/ENG012]
   Erdener D, 2018, J CHILD LANG, V45, P273, DOI 10.1017/S0305000917000174
   GREEN KW, 1981, AM ANN DEAF, V126, P505, DOI 10.1353/aad.2012.1361
   HANSON VL, 1987, MEM COGNITION, V15, P199, DOI 10.3758/BF03197717
   Harris M, 1998, J Deaf Stud Deaf Educ, V3, P205
   Harris M, 2017, J DEAF STUD DEAF EDU, V22, P233, DOI 10.1093/deafed/enw101
   Harris M, 2017, J SPEECH LANG HEAR R, V60, P701, DOI 10.1044/2016_JSLHR-H-15-0403
   Heikkila J, 2018, CHILD LANG TEACH THE, V34, P269, DOI 10.1177/0265659018793697
   Heikkila J, 2017, J SPEECH LANG HEAR R, V60, P485, DOI 10.1044/2016_JSLHR-S-15-0071
   Herman R, 2019, READ RES QUART, V54, P553, DOI 10.1002/rrq.244
   Hjetland HN, 2019, J EDUC PSYCHOL, V111, P751, DOI 10.1037/edu0000321
   Hulme C, 2002, J EXP CHILD PSYCHOL, V82, P58, DOI 10.1006/jecp.2002.2674
   Hulme C, 1998, J EXP CHILD PSYCHOL, V71, P39, DOI 10.1006/jecp.1998.2456
   Hulme C., 2009, YORK ASSESSMENT READ
   Hulme C, 2013, CHILD DEV PERSPECT, V7, P1, DOI 10.1111/cdep.12005
   Hulme C, 2012, PSYCHOL SCI, V23, P572, DOI 10.1177/0956797611435921
   Jerger S, 2018, J CHILD LANG, V45, P392, DOI 10.1017/S0305000917000265
   Jerger S, 2009, J SPEECH LANG HEAR R, V52, P412, DOI 10.1044/1092-4388(2009/08-0021)
   Johnson C, 2010, J SPEECH LANG HEAR R, V53, P237, DOI 10.1044/1092-4388(2009/08-0139)
   Knowland VCP, 2016, J SPEECH LANG HEAR R, V59, P1, DOI 10.1044/2015_JSLHR-S-14-0269
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Kyle F. E., 2015, RES METHODS SIGN LAN, P300, DOI 10.1002/
   Kyle FE, 2006, J DEAF STUD DEAF EDU, V11, P273, DOI 10.1093/deafed/enj037
   Kyle FE, 2013, J SPEECH LANG HEAR R, V56, P416, DOI 10.1044/1092-4388(2012/12-0039)
   Kyle FE, 2011, J DEAF STUD DEAF EDU, V16, P289, DOI 10.1093/deafed/enq069
   Kyle FE, 2010, J EXP CHILD PSYCHOL, V107, P229, DOI 10.1016/j.jecp.2010.04.011
   Kyle FE, 2016, RES DEV DISABIL, V48, P13, DOI 10.1016/j.ridd.2015.10.004
   LEYBAERT J, 1995, READ WRIT, V7, P89, DOI 10.1007/BF01026949
   Leybaert J., 2003, HDB DEEF STUDIES LAN, P261, DOI 10.1093/oxfordhb/9780199750986.013.0020
   Leybaert J., 1993, PSYCHOL PERSPECTIVES, P269
   Lusk LG, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00052
   LYXELL B, 1993, SCAND AUDIOL, V22, P67, DOI 10.3109/01050399309046021
   Lyxell B, 2000, BRIT J EDUC PSYCHOL, V70, P505, DOI 10.1348/000709900158272
   Mayberry RI, 2011, J DEAF STUD DEAF EDU, V16, P164, DOI 10.1093/deafed/enq049
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Melby-Lervag M, 2012, PSYCHOL BULL, V138, P322, DOI 10.1037/a0026744
   Mohammed T, 2006, CLIN LINGUIST PHONET, V20, P621, DOI 10.1080/02699200500266745
   Muthen L.K., 2017, MPLUS USERS GUIDE, V8th ed.
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Patterson ML, 1999, INFANT BEHAV DEV, V22, P237, DOI 10.1016/S0163-6383(99)00003-X
   Pimperton H, 2019, J SPEECH LANG HEAR R, V62, P2882, DOI 10.1044/2019_JSLHR-H-19-0073
   Qi S, 2012, J DEAF STUD DEAF EDU, V17, P1, DOI 10.1093/deafed/enr028
   Rodriguez-Ortiz IR, 2017, J RES READ, V40, P75, DOI 10.1111/1467-9817.12062
   Rucker DD, 2011, SOC PERSONAL PSYCHOL, V5, P359, DOI 10.1111/j.1751-9004.2011.00355.x
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Sutcliffe A., 1999, J DEAF STUD DEAF EDU, V4, P111, DOI [10.1093/deafed/4.2.111, DOI 10.1093/DEAFED/4.2.111]
   Teinonen T, 2008, COGNITION, V108, P850, DOI 10.1016/j.cognition.2008.05.009
   Thompson PA, 2015, J CHILD PSYCHOL PSYC, V56, P976, DOI 10.1111/jcpp.12412
   Tye-Murray N, 2007, J AM ACAD AUDIOL, V18, P883, DOI 10.3766/jaaa.18.10.7
   Weatherhead D, 2017, COGNITION, V160, P103, DOI 10.1016/j.cognition.2017.01.002
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
NR 65
TC 0
Z9 0
U1 1
U2 1
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD NOV
PY 2020
VL 63
IS 11
BP 3775
EP 3785
DI 10.1044/2020_JSLHR-20-00159
PG 11
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA OS4XF
UT WOS:000590167400016
PM 33108258
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU D'Onofrio, K
   Richards, V
   Gifford, R
AF D'Onofrio, Kristen
   Richards, Virginia
   Gifford, Rene
TI Spatial Release From Informational and Energetic Masking in Bimodal and
   Bilateral Cochlear Implant Users
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID INTERAURAL TIME DIFFERENCES; SPEECH-PERCEPTION; FUNDAMENTAL-FREQUENCY;
   ACOUSTIC HEARING; BINAURAL ADVANTAGES; COMPETING-SPEECH; COCKTAIL-PARTY;
   HEAD SHADOW; LOCALIZATION; LISTENERS
AB Purpose: Spatially separating speech and background noise improves speech understanding in normal-hearing listeners, an effect referred to as spatial release from masking (SRM). In cochlear implant (CI) users, SRM has often been demonstrated using asymmetric noise configurations, which maximize benefit from head shadow and the potential availability of binaural cues. In contrast, SRM in symmetrical configurations has been minimal to absent in CI users. We examined the interaction between two types of maskers (informational and energetic) and SRM in bimodal and bilateral CI users. We hypothesized that SRM would be absent or "negative" using symmetrically separated noise maskers. Second, we hypothesized that bimodal listeners would exhibit greater release from informational masking due to access to acoustic information in the non-CI ear.
   Method: Participants included 10 bimodal and 10 bilateral CI users. Speech understanding in noise was tested in 24 conditions: 3 spatial configurations (S0N0, S0N45&315, S0N90&270) x 2 masker types (speech, signal-correlated noise) x 2 listening configurations (best-aided, CI-alone) x 2 talker gender conditions (different-gender, same-gender).
   Results: In support of our first hypothesis, both groups exhibited negative SRM with increasing spatial separation. In opposition to our second hypothesis, both groups exhibited similar magnitudes of release from informational masking. The magnitude of release was greater for bimodal listeners, though this difference failed to reach statistical significance.
   Conclusions: Both bimodal and bilateral CI recipients exhibited negative SRM. This finding is consistent with CI signal processing limitations, the audiologic factors associated with SRM, and known effects of behind-the-ear microphone technology. Though release from informational masking was not significantly different across groups, the magnitude of release was greater for bimodal listeners. This suggests that bimodal listeners may be at least marginally more susceptible to informational masking than bilateral CI users, though further research is warranted.
C1 [D'Onofrio, Kristen; Gifford, Rene] Vanderbilt Univ, Med Ctr, Dept Hearing & Speech Sci, Nashville, TN 37235 USA.
   [Richards, Virginia] Univ Calif Irvine, Dept Cognit Sci, Irvine, CA 92717 USA.
RP D'Onofrio, K (corresponding author), Vanderbilt Univ, Med Ctr, Dept Hearing & Speech Sci, Nashville, TN 37235 USA.
EM kristen.l.donofrio@Vanderbilt.edu
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [NIDCD R01 DC009404]; Vanderbilt
   Institute for Clinical and Translational Research [NIH UL1 TR000445]
FX This research was supported by the National Institute on Deafness and
   Other Communication Disorders (NIDCD R01 DC009404, PI: Gifford) and the
   Vanderbilt Institute for Clinical and Translational Research (NIH UL1
   TR000445). We would also like to thank Linsey Sunderhaus and Katelyn
   Berg for their assistance with participant recruitment and data
   collection.
CR [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   Arbogast TL, 2002, J ACOUST SOC AM, V112, P2086, DOI 10.1121/1.1510141
   Aronoff JM, 2011, EAR HEARING, V32, P468, DOI 10.1097/AUD.0b013e31820dd3f0
   Aronoff JM, 2010, J ACOUST SOC AM, V127, pEL87, DOI 10.1121/1.3298451
   BACON SP, 1989, J ACOUST SOC AM, V85, P2575, DOI 10.1121/1.397751
   Bernstein JGW, 2015, J ACOUST SOC AM, V137, P702, DOI 10.1121/1.4906167
   BROKX JPL, 1982, J PHONETICS, V10, P23, DOI 10.1016/S0095-4470(19)30909-X
   Brungart DS, 2012, J ACOUST SOC AM, V132, P2545, DOI 10.1121/1.4747005
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Buss E, 2008, EAR HEARING, V29, P20
   Ching TYC, 2004, EAR HEARING, V25, P9, DOI 10.1097/01.AUD.0000111261.84611.C8
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   Culling JF, 2012, EAR HEARING, V33, P673, DOI 10.1097/AUD.0b013e3182587356
   Darwin CJ, 2003, J ACOUST SOC AM, V114, P2913, DOI 10.1121/1.1616924
   Davis TJ, 2018, J SPEECH LANG HEAR R, V61, P752, DOI 10.1044/2017_JSLHR-H-16-0441
   Deroche MLD, 2013, J ACOUST SOC AM, V134, pEL465, DOI 10.1121/1.4826152
   Dunn CC, 2005, J SPEECH LANG HEAR R, V48, P668, DOI 10.1044/1092-4388(2005/046)
   Durlach NI, 2003, J ACOUST SOC AM, V114, P368, DOI 10.1121/1.1577562
   Dwyer R. T., 2020, J AM ACAD AUDIOL, DOI [10.1055/s-0040-1709449, DOI 10.1055/S-0040]
   FESTEN JM, 1986, J ACOUST SOC AM, V79, P465, DOI 10.1121/1.393534
   Francart T, 2014, JARO-J ASSOC RES OTO, V15, P633, DOI 10.1007/s10162-014-0457-9
   Freyman RL, 2007, J ACOUST SOC AM, V121, P1040, DOI 10.1121/1.2427117
   Gifford RH, 2019, EAR HEARING, V40, P501, DOI 10.1097/AUD.0000000000000657
   Gifford RH, 2018, J SPEECH LANG HEAR R, V61, P1306, DOI 10.1044/2018_JSLHR-H-16-0444
   Gifford RH, 2014, AUDIOL NEURO-OTOL, V19, P57, DOI 10.1159/000355700
   Glyde H, 2013, J ACOUST SOC AM, V134, P2937, DOI 10.1121/1.4817930
   Goupell MJ, 2018, EAR HEARING, V39, P895, DOI 10.1097/AUD.0000000000000541
   Goupell MJ, 2018, EAR HEARING, V39, P110, DOI 10.1097/AUD.0000000000000470
   Goupell MJ, 2016, J ACOUST SOC AM, V140, P1652, DOI 10.1121/1.4962378
   Hawley ML, 2004, J ACOUST SOC AM, V115, P833, DOI 10.1121/1.1639908
   Holder JT, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518755288
   Hu HM, 2018, J ACOUST SOC AM, V143, P2128, DOI 10.1121/1.5030918
   Ihiefeld A, 2008, J ACOUST SOC AM, V123, P4369, DOI 10.1121/1.2904826
   Kan A, 2015, HEARING RES, V322, P127, DOI 10.1016/j.heares.2014.08.005
   Kidd G, 2005, J ACOUST SOC AM, V118, P982, DOI 10.1121/1.1953167
   Kokkinakis K, 2018, AM J AUDIOL, V27, P85, DOI 10.1044/2017_AJA-17-0065
   Kokkinakis K, 2014, J ACOUST SOC AM, V135, pEL47, DOI 10.1121/1.4831955
   Kolberg ER, 2015, J AM ACAD AUDIOL, V26, P51, DOI 10.3766/jaaa.26.1.6
   Laback B, 2004, EAR HEARING, V25, P488, DOI 10.1097/01.aud.0000145124.85517.e8
   Laback B, 2015, HEARING RES, V322, P138, DOI 10.1016/j.heares.2014.10.004
   LEEK MR, 1991, PERCEPT PSYCHOPHYS, V50, P205, DOI 10.3758/BF03206743
   Lenssen A, 2011, J ACOUST SOC AM, V129, P3457, DOI 10.1121/1.3557051
   Litovsky R, 2006, EAR HEARING, V27, P714, DOI 10.1097/01.aud.0000246816.50820.42
   Litovsky RY, 2009, EAR HEARING, V30, P419, DOI 10.1097/AUD.0b013e3181a165be
   Loiselle LH, 2016, J SPEECH LANG HEAR R, V59, P810, DOI 10.1044/2015_JSLHR-H-14-0355
   Loizou PC, 1998, J ACOUST SOC AM, V103, P1141, DOI 10.1121/1.421248
   Loizou PC, 2009, J ACOUST SOC AM, V125, P372, DOI 10.1121/1.3036175
   LUTFI RA, 1990, J ACOUST SOC AM, V88, P2607, DOI 10.1121/1.399980
   Mackersie CL, 2011, J ACOUST SOC AM, V130, P1006, DOI 10.1121/1.3605548
   Misurelli SM, 2015, J ACOUST SOC AM, V138, P319, DOI 10.1121/1.4922777
   Misurelli SM, 2012, J ACOUST SOC AM, V132, P380, DOI 10.1121/1.4725760
   Morera C, 2005, ACTA OTO-LARYNGOL, V125, P596, DOI 10.1080/00016480510027493
   Plant K, 2016, INT J AUDIOL, V55, P472, DOI 10.1080/14992027.2016.1178857
   Potts LG, 2009, J AM ACAD AUDIOL, V20, P353, DOI 10.3766/jaaa.20.6.4
   Pyschny V, 2014, J SPEECH LANG HEAR R, V57, P1942, DOI 10.1044/2014_JSLHR-H-13-0144
   Revit L. J., 2002, HEAR REV, V9, P34
   Schleich P, 2004, EAR HEARING, V25, P197, DOI 10.1097/01.AUD.0000130792.43315.97
   Seeber BU, 2008, J ACOUST SOC AM, V123, P1030, DOI 10.1121/1.2821965
   Sheffield SW, 2019, J ACOUST SOC AM, V145, P1129, DOI 10.1121/1.5090494
   Sheffield SW, 2015, J AM ACAD AUDIOL, V26, P145, DOI 10.3766/jaaa.26.2.5
   Slaney M., 1993, 35 APPL
   van Hoesel RJM, 2003, J ACOUST SOC AM, V113, P1617, DOI 10.1121/1.1539520
   Williges B, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216519858311
NR 63
TC 0
Z9 0
U1 1
U2 1
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD NOV
PY 2020
VL 63
IS 11
BP 3816
EP 3833
DI 10.1044/2020_JSLHR-20-00044
PG 18
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA OS4XF
UT WOS:000590167400019
PM 33049147
DA 2021-02-24
ER

PT J
AU O'Neill, ER
   Parke, MN
   Kreft, HA
   Oxenham, AJ
AF O'Neill, Erin R.
   Parke, Morgan N.
   Kreft, Heather A.
   Oxenham, Andrew J.
TI Development and Validation of Sentences Without Semantic Context to
   Complement the Basic English Lexicon Sentences
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID COCHLEAR-IMPLANT USERS; NORMAL-HEARING; SPEECH-PERCEPTION; WORD
   RECOGNITION; NOISE; INTELLIGIBILITY; LISTENERS; PHONEME; LOAD; AGE
AB Purpose: The goal of this study was to develop and validate a new corpus of sentences without semantic context to facilitate research aimed at isolating the effects of semantic context in speech perception.
   Method: The newly developed corpus contains nonsensical sentences but is matched in vocabulary and syntactic structure to the existing Basic English Lexicon (BEL) corpus. It consists of 20 lists, with each list containing 25 sentences and each sentence having four keywords. Each new list contains the same keywords as the respective list in the original BEL corpus, but the keywords within each list are scrambled across sentences to eliminate semantic context within each sentence, while maintaining the original syntactic structure. All sentences in the original and nonsense BEL corpora were recorded by the same two male and two female talkers.
   Results: Mean intelligibility scores for each list were estimated by calculating the mean proportion of correct keywords achieved by 40 normal-hearing listeners for one male and one female talker. Although small but significant differences were found between some pairs of lists, mean performance for all 20 lists fell within the 95% confidence intervals of the mean.
   Conclusions: Lists in the newly developed nonsense corpus are reasonably well equated for difficulty and can be used interchangeably in a randomized experimental design. Both the original and nonsense BEL sentences, all recorded by the same four talkers, are publicly available.
C1 [O'Neill, Erin R.; Parke, Morgan N.; Kreft, Heather A.; Oxenham, Andrew J.] Univ Minnesota, Dept Psychol, Minneapolis, MN 55455 USA.
RP O'Neill, ER (corresponding author), Univ Minnesota, Dept Psychol, Minneapolis, MN 55455 USA.
EM oneil554@umn.edu
OI Oxenham, Andrew/0000-0002-9365-1157
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01 DC012262]
FX This work was supported by National Institute on Deafness and Other
   Communication Disorders Grant R01 DC012262, awarded to Andrew J.
   Oxenham. We thank Benjamin Munson for his advice during the development
   of this new corpus and for his helpful comments on an earlier version of
   this article.
CR [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   BEATTY J, 1982, PSYCHOL BULL, V91, P276, DOI 10.1037/0033-2909.91.2.276
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32
   Bolia RS, 2000, J ACOUST SOC AM, V107, P1065, DOI 10.1121/1.428288
   BOOTHROYD A, 1988, J ACOUST SOC AM, V84, P101, DOI 10.1121/1.396976
   Calandruccio L, 2012, J SPEECH LANG HEAR R, V55, P1342, DOI 10.1044/1092-4388(2012/11-0260)
   Carroll L., 1883, LOOKING GLASS WHAT A
   Freyman RL, 2012, J ACOUST SOC AM, V132, P2514, DOI 10.1121/1.4747614
   HAGERMAN B, 1982, SCAND AUDIOL, V11, P79, DOI 10.3109/01050398209076203
   Harris R. W., 1991, SPEECH AUDIOMETRY MA
   Helfer KS, 1997, J SPEECH LANG HEAR R, V40, P432, DOI 10.1044/jslhr.4002.432
   Hughes SE, 2018, EAR HEARING, V39, P922, DOI 10.1097/AUD.0000000000000553
   KAHNEMAN D, 1966, SCIENCE, V154, P1583, DOI 10.1126/science.154.3756.1583
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Kollmeier B, 2015, INT J AUDIOL, V54, P3, DOI 10.3109/14992027.2015.1020971
   Lash A, 2013, EXP AGING RES, V39, P235, DOI 10.1080/0361073X.2013.779175
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Nilsson M. J., 1996, MINIMUM SPEECH TEST
   NITTROUER S, 1990, J ACOUST SOC AM, V87, P2705, DOI 10.1121/1.399061
   O'Neill ER, 2019, J ACOUST SOC AM, V146, P195, DOI 10.1121/1.5116009
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Rimikis S, 2013, J SPEECH LANG HEAR R, V56, P792, DOI 10.1044/1092-4388(2012/12-0178)
   Ruggles DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086980
   Sarampalis A, 2009, J SPEECH LANG HEAR R, V52, P1230, DOI 10.1044/1092-4388(2009/08-0111)
   Spahr AJ, 2012, EAR HEARING, V33, P112, DOI 10.1097/AUD.0b013e31822c2549
   Stelmachowicz PG, 2000, J SPEECH LANG HEAR R, V43, P902, DOI 10.1044/jslhr.4304.902
   Turner CW, 2004, J ACOUST SOC AM, V115, P1729, DOI 10.1121/1.1687425
   Winn MB, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516669723
   Yamada Y, 2007, BRAIN RES, V1130, P167, DOI 10.1016/j.brainres.2006.10.052
NR 31
TC 0
Z9 0
U1 0
U2 0
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD NOV
PY 2020
VL 63
IS 11
BP 3847
EP 3854
DI 10.1044/2020_JSLHR-20-00174
PG 8
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA OS4XF
UT WOS:000590167400021
PM 33049146
OA Other Gold
DA 2021-02-24
ER

PT J
AU Huang, WT
   Wong, LLN
   Chen, F
   Liu, HH
   Liang, W
AF Huang, Wanting
   Wong, Lena L. N.
   Chen, Fei
   Liu, Haihong
   Liang, Wei
TI Effects of Fundamental Frequency Contours on Sentence Recognition in
   Mandarin-Speaking Children With Cochlear Implants
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID LEXICAL TONE PERCEPTION; SCHOOL-AGE-CHILDREN; SPEECH-PERCEPTION;
   INFORMATIONAL MASKING; PITCH PERCEPTION; NORMAL-HEARING; DEAF-CHILDREN;
   CHINESE; INTELLIGIBILITY; NOISE
AB Purpose: Fundamental frequency (F0) is the primary acoustic cue for lexical tone perception in tonal languages but is processed in a limited way in cochlear implant (CI) systems. The aim of this study was to evaluate the importance of F0 contours in sentence recognition in Mandarin-speaking children with CIs and find out whether it is similar to/different from that in age-matched normal-hearing (NH) peers.
   Method: Age-appropriate sentences, with F0 contours manipulated to be either natural or flattened, were randomly presented to preschool children with CIs and their age-matched peers with NH under three test conditions: in quiet, in white noise, and with competing sentences at 0 dB signal-to-noise ratio.
   Results: The neutralization of F0 contours resulted in a significant reduction in sentence recognition. While this was seen only in noise conditions among NH children, it was observed throughout all test conditions among children with CIs. Moreover, the F0 contour-induced accuracy reduction ratios (i.e., the reduction in sentence recognition resulting from the neutralization of F0 contours compared to the normal F0 condition) were significantly greater in children with CIs than in NH children in all test conditions.
   Conclusions: F0 contours play a major role in sentence recognition in both quiet and noise among pediatric implantees, and the contribution of the F0 contour is even more salient than that in age-matched NH children. These results also suggest that there may be differences between children with CIs and NH children in how F0 contours are processed.
C1 [Huang, Wanting; Wong, Lena L. N.] Univ Hong Kong, Fac Educ, Unit Human Commun Dev & Informat Sci, Hong Kong, Peoples R China.
   [Chen, Fei] Southern Univ Sci & Technol, Dept Elect & Elect Engn, Shenzhen, Peoples R China.
   [Liu, Haihong] Beijing Childrens Hosp, Beijing Key Lab Pediat Dis Otolaryngol Head & Nec, Beijing, Peoples R China.
   [Liang, Wei] China Rehabil Res Ctr Hearing & Speech Impairment, Beijing, Peoples R China.
RP Huang, WT (corresponding author), Univ Hong Kong, Fac Educ, Unit Human Commun Dev & Informat Sci, Hong Kong, Peoples R China.; Chen, F (corresponding author), Southern Univ Sci & Technol, Dept Elect & Elect Engn, Shenzhen, Peoples R China.
EM wtwong88@connect.hku.hk; fchen@sustech.edu.cn
CR Bacon SP, 1998, J SPEECH LANG HEAR R, V41, P549, DOI 10.1044/jslhr.4103.549
   Boersma P., 2002, PRAAT SYSTEM DOING P
   Buss E, 2017, J ACOUST SOC AM, V141, P2650, DOI 10.1121/1.4979936
   Calandruccio L, 2016, AM J AUDIOL, V25, P34, DOI 10.1044/2015_AJA-15-0053
   Chen Y, 2016, RES DEV DISABIL, V49-50, P1, DOI 10.1016/j.ridd.2015.11.021
   Chen Y, 2014, INT J PEDIATR OTORHI, V78, P1923, DOI 10.1016/j.ijporl.2014.08.025
   Fu Q-J, 2000, ASIA PAC J SPEECH LA, V5, P45, DOI DOI 10.1179/136132800807547582
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P180, DOI 10.1007/s10162-005-5061-6
   Fu QJ, 1998, J ACOUST SOC AM, V104, P505, DOI 10.1121/1.423251
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   Gandour J. T., 1978, TONE LINGUISTIC SURV, P41, DOI DOI 10.1016/B978-0-12-267350-4.50007-8
   Gfeller K, 2007, EAR HEARING, V28, P412, DOI 10.1097/AUD.0b013e3180479318
   Gfeller Kate, 2002, Cochlear Implants Int, V3, P29, DOI 10.1179/cim.2002.3.1.29
   Guo M., 2006, CHINESE TEACHING WOR, V2, P129
   Han DM, 2009, EAR HEARING, V30, P169, DOI 10.1097/AUD.0b013e31819342cf
   Hiskey M. S., 1966, HISKEY NEBRASKA TEST
   Huang CY, 2005, INT J PEDIATR OTORHI, V69, P505, DOI 10.1016/j.ijporl.2004.10.017
   Kong YY, 2006, J ACOUST SOC AM, V120, P2830, DOI 10.1121/1.2346009
   Lee CY, 2012, NEUROPSYCHOLOGIA, V50, P3228, DOI 10.1016/j.neuropsychologia.2012.08.025
   Lin MC, 1988, CHINESE YUWEN, V204, P182
   Milczynski M, 2012, HEARING RES, V285, P1, DOI 10.1016/j.heares.2012.02.006
   Nelson PB, 2003, J ACOUST SOC AM, V113, P961, DOI 10.1121/1.1531983
   Newman RS, 2015, J ACOUST SOC AM, V138, pEL93, DOI 10.1121/1.4921677
   Pan Y., 2016, FREE COCHLEAR IMPLAN
   Patel A. D., 2010, SPEECH PROS 2010 5 I
   Peng SC, 2004, EAR HEARING, V25, P251, DOI 10.1097/01.AUD.0000130797.73809.40
   Peng SC, 2017, J SPEECH LANG HEAR R, V60, P1223, DOI 10.1044/2016_JSLHR-S-16-0048
   Ping Lichuan, 2017, Cochlear Implants Int, V18, P240, DOI 10.1080/14670100.2017.1339492
   POLLACK I, 1958, J ACOUST SOC AM, V30, P131, DOI 10.1121/1.1909505
   Schatzer R, 2010, ACTA OTO-LARYNGOL, V130, P1031, DOI 10.3109/00016481003591731
   Seligman P., 1995, Annals of Otology Rhinology and Laryngology, V104, P139
   Sherbecoe RL, 2004, INT J AUDIOL, V43, P442, DOI 10.1080/14992020400050056
   SKINNER MW, 1994, AM J OTOL, V15, P15
   Studebaker G A, 1995, J Am Acad Audiol, V6, P173
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Taitelbaum-Swead R, 2016, FOLIA PHONIATR LOGO, V68, P16, DOI 10.1159/000444749
   Tao DD, 2018, J ACOUST SOC AM, V144, pEL131, DOI 10.1121/1.5051051
   Tao DD, 2015, EAR HEARING, V36, P102, DOI 10.1097/AUD.0000000000000086
   Van Engen KJ, 2007, J ACOUST SOC AM, V121, P519, DOI 10.1121/1.2400666
   Vandali AE, 2005, J ACOUST SOC AM, V117, P3126, DOI 10.1121/1.1874632
   Wang JJ, 2013, J ACOUST SOC AM, V134, pEL91, DOI 10.1121/1.4811159
   Wang WQ, 2011, INT J AUDIOL, V50, P270, DOI 10.3109/14992027.2010.542490
   Wei CG, 2004, HEARING RES, V197, P87, DOI 10.1016/j.heares.2004.06.002
   Wei CG, 2007, EAR HEARING, V28, p62S, DOI 10.1097/AUD.0b013e318031512c
   Wightman FL, 2005, J ACOUST SOC AM, V118, P3164, DOI 10.1121/1.2082567
   WILSON BS, 1991, NATURE, V352, P236, DOI 10.1038/352236a0
   Wong PS, 2005, J SPEECH LANG HEAR R, V48, P1065, DOI 10.1044/1092-4388(2005/074)
   Wu JL, 2003, INT J PEDIATR OTORHI, V67, P247, DOI 10.1016/S0165-5876(02)00378-6
   Xu L., 2009, 12 INT S COCHL IMPL
   Zhang LJ, 2018, J SPEECH LANG HEAR R, V61, DOI 10.1044/2018_JSLHR-H-17-0327
   Zheng Y, 2009, INT J AUDIOL, V48, P718, DOI 10.1080/14992020902902658
NR 51
TC 0
Z9 0
U1 0
U2 0
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD NOV
PY 2020
VL 63
IS 11
BP 3855
EP 3864
DI 10.1044/2020_JSLHR-20-00033
PG 10
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA OS4XF
UT WOS:000590167400022
PM 33022190
DA 2021-02-24
ER

PT J
AU Icht, M
   Mama, Y
   Taitelbaum-Swead, R
AF Icht, Michal
   Mama, Yaniv
   Taitelbaum-Swead, Riki
TI Visual and Auditory Verbal Memory in Older Adults: Comparing
   Postlingually Deaf Cochlear Implant Users to Normal-Hearing Controls
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID WORKING-MEMORY; SELECTIVE ATTENTION; LANGUAGE PRODUCTION; DIVIDED
   ATTENTION; SPEECH-PERCEPTION; AGE; COGNITION; RECOGNITION; RETRIEVAL;
   FRAMEWORK
AB Purpose: The aim of this study was to test whether a group of older postlingually deafened cochlear implant users (OCIs) use similar verbal memory strategies to those used by older normal-hearing adults (ONHs). Verbal memory functioning was assessed in the visual and auditory modalities separately, enabling us to eliminate possible modality-based biases.
   Method: Participants performed two separate visual and auditory verbal memory tasks. In each task, the visually or aurally presented study words were learned by vocal production (saying aloud) or by no production (reading silently or listening), followed by a free recall test. Twenty-seven older adults (> 60 years) participated (OCI = 13, ONH = 14), all of whom demonstrated intact cognitive abilities. All OCIs showed good open-set speech perception results in quiet.
   Results: Both ONHs and OCIs showed production benefits (higher recall rates for vocalized than nonvocalized words) in the visual and auditory tasks. The ONHs showed similar production benefits in the visual and auditory tasks. The OCIs demonstrated a smaller production effect in the auditory task.
   Conclusions: These results may indicate that different modality-specific memory strategies were used by the ONHs and the OCIs. The group differences in memory performance suggest that, even when deafness occurs after the completion of language acquisition, the reduced and distorted external auditory stimulation leads to a deterioration in the phonological representation of sounds. Possibly, this deterioration leads to a less efficient auditory long-term verbal memory.
C1 [Icht, Michal; Taitelbaum-Swead, Riki] Ariel Univ, Dept Commun Disorders, Ariel, Israel.
   [Mama, Yaniv] Ariel Univ, Dept Behav Sci & Psychol, Ariel, Israel.
   [Taitelbaum-Swead, Riki] Meuhedet Hlth Serv, Tel Aviv, Israel.
RP Icht, M (corresponding author), Ariel Univ, Dept Commun Disorders, Ariel, Israel.
EM lmichal@ariel.ac.il
OI Icht, Michal/0000-0002-9228-309X
CR Acheson DJ, 2009, J MEM LANG, V60, P329, DOI 10.1016/j.jml.2008.12.002
   Acheson DJ, 2009, PSYCHOL BULL, V135, P50, DOI 10.1037/a0014411
   Adams EJ, 2018, LANG SPEECH HEAR SER, V49, P340, DOI 10.1044/2018_LSHSS-17-0114
   Andersson U, 2002, EUR J COGN PSYCHOL, V14, P335, DOI 10.1080/09541440143000096
   Backman L, 2000, AM J PSYCHIAT, V157, P635
   Baddeley A, 2010, CURR BIOL, V20, pR136, DOI 10.1016/j.cub.2009.12.014
   Ben-David BM, 2018, LANG SPEECH, V61, P113, DOI 10.1177/0023830917708808
   Berrettini S, 2011, ACTA OTORHINOLARYNGO, V31, P299
   Boothroyd A., 1968, AUDIOL BR J, V2, P3, DOI DOI 10.3109/00381796809075436
   Castiglione A, 2015, HEARING BALANC COMMU, V13, P86, DOI 10.3109/13625187.2015.1030885
   Castiglione A, 2016, AUDIOL NEURO-OTOL, V21, P21, DOI 10.1159/000448350
   COWAN N, 1988, PSYCHOL BULL, V104, P163, DOI 10.1037/0033-2909.104.2.163
   Cowan N, 1995, EEG CL N SU, P21
   Craik FIM, 1996, J EXP PSYCHOL GEN, V125, P159, DOI 10.1037/0096-3445.125.2.159
   CRAIK FIM, 1972, J VERB LEARN VERB BE, V11, P671, DOI 10.1016/S0022-5371(72)80001-X
   Davidson Lisa S, 2011, Ear Hear, V32, p19S, DOI 10.1097/AUD.0b013e3181ffdb8b
   Delis D, 2000, CALIFORNIA VERBAL LE
   Dupuis K, 2015, AGING NEUROPSYCHOL C, V22, P413, DOI 10.1080/13825585.2014.968084
   Fawcett JM, 2016, CAN J EXP PSYCHOL, V70, P99, DOI 10.1037/cep0000089
   Fernandes MA, 2000, J EXP PSYCHOL GEN, V129, P155, DOI 10.1037/0096-3445.129.2.155
   Forrin ND, 2012, MEM COGNITION, V40, P1046, DOI 10.3758/s13421-012-0210-8
   Geers AE, 2013, OTOL NEUROTOL, V34, P396, DOI 10.1097/MAO.0b013e318277a0cb
   Hertzog C, 2017, PSYCHOL AGING, V32, P557, DOI 10.1037/pag0000177
   Heydebrand G, 2007, AUDIOL NEURO-OTOL, V12, P254, DOI 10.1159/000101473
   Holden LK, 2013, EAR HEARING, V34, P342, DOI 10.1097/AUD.0b013e3182741aa7
   Humes LE, 2010, SPRINGER HANDB AUDIT, V34, P211, DOI 10.1007/978-1-4419-0993-0_8
   Icht M, 2019, LANG TEACH RES, DOI 10.1177/1362168819883894
   Icht M, 2019, NEUROPSYCHOL REHABIL, V29, P131, DOI 10.1080/09602011.2016.1272466
   Icht M, 2015, J CHILD LANG, V42, P1102, DOI 10.1017/S0305000914000713
   Icht M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00886
   IVES DG, 1995, J AM GERIATR SOC, V43, P803, DOI 10.1111/j.1532-5415.1995.tb07056.x
   Kueider AM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040588
   Lavie N, 2005, TRENDS COGN SCI, V9, P75, DOI 10.1016/j.tics.2004.12.004
   Lazard DS, 2010, NEUROIMAGE, V49, P3443, DOI 10.1016/j.neuroimage.2009.11.013
   Leal SL, 2017, NEUROBIOL AGING, V49, P9, DOI 10.1016/j.neurobiolaging.2016.08.018
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P1131, DOI 10.1093/gerona/glr115
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P582, DOI 10.1093/gerona/glr002
   Lin OYH, 2012, CAN J EXP PSYCHOL, V66, P212, DOI 10.1037/a0028309
   Lowenstein JH, 2019, J EXP CHILD PSYCHOL, V183, P276, DOI 10.1016/j.jecp.2019.03.003
   Lyxell B, 1998, SCAND J PSYCHOL, V39, P175, DOI 10.1111/1467-9450.393075
   Lyxell B, 2003, INT J AUDIOL, V42, pS86
   MacDonald PA, 1998, ACTA PSYCHOL, V98, P291, DOI 10.1016/S0001-6918(97)00047-4
   MacLeod CM, 2017, CURR DIR PSYCHOL SCI, V26, P390, DOI 10.1177/0963721417691356
   MacLeod CM, 2010, J EXP PSYCHOL LEARN, V36, P671, DOI 10.1037/a0018785
   Mama Y, 2019, J INT NEUROPSYCH SOC, V25, P230, DOI 10.1017/S1355617718001017
   Mama Y, 2018, MEMORY, V26, P589, DOI 10.1080/09658211.2017.1384496
   Mama Y, 2018, ACTA PSYCHOL, V185, P235, DOI 10.1016/j.actpsy.2018.03.002
   Mama Y, 2016, CAN J EXP PSYCHOL, V70, P177, DOI 10.1037/cep0000090
   Mama Y, 2016, MEMORY, V24, P98, DOI 10.1080/09658211.2014.986135
   Martin F. N., 2000, J AM ACAD AUDIOL, V11, P509
   Meinke DK, 2017, INT J AUDIOL, V56, P41, DOI 10.1080/14992027.2016.1261189
   Melby-Lervag M, 2010, PSYCHOL SCI, V21, P1694, DOI 10.1177/0956797610385355
   Moberly Aaron C, 2017, World J Otorhinolaryngol Head Neck Surg, V3, P224, DOI 10.1016/j.wjorl.2017.12.003
   Moberly AC, 2017, J SPEECH LANG HEAR R, V60, P1046, DOI 10.1044/2016_JSLHR-H-16-0119
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Newgard CB, 2013, J CLIN INVEST, V123, P946, DOI 10.1172/JCI68833
   Nimrod G, 2017, INFORM COMMUN SOC, V20, P233, DOI 10.1080/1369118X.2016.1164740
   Nittrouer S, 2014, APPL PSYCHOLINGUIST, V35, P333, DOI 10.1017/S0142716412000410
   O'Neill ER, 2019, J ACOUST SOC AM, V146, P195, DOI 10.1121/1.5116009
   Ozubko JD, 2012, MEMORY, V20, P717, DOI 10.1080/09658211.2012.699070
   PENNEY CG, 1989, MEM COGNITION, V17, P398, DOI 10.3758/BF03202613
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Pisoni DB, 2018, EAR HEARING, V39, P720, DOI 10.1097/AUD.0000000000000530
   Ronnberg J, 2003, INT J AUDIOL, V42, pS68
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2011, J SPEECH LANG HEAR R, V54, P705, DOI 10.1044/1092-4388(2010/09-0088)
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   Schneider BA, 2010, SPRINGER HANDB AUDIT, V34, P167, DOI 10.1007/978-1-4419-0993-0_7
   Segal O., 1998, THESIS
   Stone ME, 2017, J GERONTOL B-PSYCHOL, V72, P162, DOI 10.1093/geronb/gbv068
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Surprenant AM, 2007, AGING NEUROPSYCHOL C, V14, P126, DOI 10.1080/13825580701217710
   Swead RT, 2018, J AM ACAD AUDIOL, V29, P875, DOI 10.3766/jaaa.17030
   Taitelbaum-Swead R, 2019, J SPEECH LANG HEAR R, V62, P4554, DOI 10.1044/2019_JSLHR-H-19-0134
   Taitelbaum-Swead R, 2017, J AM ACAD AUDIOL, V28, P222, DOI 10.3766/jaaa.16032
   Taitelbaum-Swead R, 2016, FOLIA PHONIATR LOGO, V68, P16, DOI 10.1159/000444749
   Tillmann B, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01990
   Tun PA, 2009, PSYCHOL AGING, V24, P761, DOI 10.1037/a0014802
   UHLMANN RF, 1989, JAMA-J AM MED ASSOC, V261, P1916, DOI 10.1001/jama.261.13.1916
   Wayne RV, 2015, AGEING RES REV, V23, P154, DOI 10.1016/j.arr.2015.06.002
   Yueh B, 2003, JAMA-J AM MED ASSOC, V289, P1976, DOI 10.1001/jama.289.15.1976
NR 81
TC 1
Z9 1
U1 5
U2 5
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD NOV
PY 2020
VL 63
IS 11
BP 3865
EP 3876
DI 10.1044/2020_JSLHR-20-00170
PG 12
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA OS4XF
UT WOS:000590167400023
PM 33049151
DA 2021-02-24
ER

PT J
AU Bell, L
   Peng, ZE
   Pausch, F
   Reindl, V
   Neuschaefer-Rube, C
   Fels, J
   Konrad, K
AF Bell, Laura
   Peng, Z. Ellen
   Pausch, Florian
   Reindl, Vanessa
   Neuschaefer-Rube, Christiane
   Fels, Janina
   Konrad, Kerstin
TI fNIRS Assessment of Speech Comprehension in Children with Normal Hearing
   and Children with Hearing Aids in Virtual Acoustic Environments: Pilot
   Data and Practical Recommendations
SO CHILDREN-BASEL
LA English
DT Article
DE functional near-infrared spectroscopy; virtual acoustics; speech
   perception; multimethod approach; virtual acoustic environments
ID NEAR-INFRARED SPECTROSCOPY; LANGUAGE-DEVELOPMENT; SOUND LOCALIZATION;
   LISTENING COMPREHENSION; CLASSROOM ACOUSTICS; AUDITORY DISTANCE;
   SENTENCE TEST; TEST SCORE; NOISE; REVERBERATION
AB The integration of virtual acoustic environments (VAEs) with functional near-infrared spectroscopy (fNIRS) offers novel avenues to investigate behavioral and neural processes of speech-in-noise (SIN) comprehension in complex auditory scenes. Particularly in children with hearing aids (HAs), the combined application might offer new insights into the neural mechanism of SIN perception in simulated real-life acoustic scenarios. Here, we present first pilot data from six children with normal hearing (NH) and three children with bilateral HAs to explore the potential applicability of this novel approach. Children with NH received a speech recognition benefit from low room reverberation and target-distractors' spatial separation, particularly when the pitch of the target and the distractors was similar. On the neural level, the left inferior frontal gyrus appeared to support SIN comprehension during effortful listening. Children with HAs showed decreased SIN perception across conditions. The VAE-fNIRS approach is critically compared to traditional SIN assessments. Although the current study shows that feasibility still needs to be improved, the combined application potentially offers a promising tool to investigate novel research questions in simulated real-life listening. Future modified VAE-fNIRS applications are warranted to replicate the current findings and to validate its application in research and clinical settings.
C1 [Bell, Laura; Reindl, Vanessa; Konrad, Kerstin] Rhein Westfal TH Aachen, Child Neuropsychol Sect, Dept Child & Adolescent Psychiat Psychosomat & Ps, Fac Med, D-52074 Aachen, Germany.
   [Peng, Z. Ellen; Pausch, Florian; Fels, Janina] Rhein Westfal TH Aachen, Inst Tech Acoust, Teaching & Res Area Med Acoust, D-52074 Aachen, Germany.
   [Peng, Z. Ellen] Univ Wisconsin Madison, Waisman Ctr, Madison, WI 53705 USA.
   [Reindl, Vanessa; Konrad, Kerstin] Rhein Westfal TH Aachen, JARA Brain Inst 2, Mol Neurosci & Neuroimaging, D-52428 Julich, Germany.
   [Reindl, Vanessa; Konrad, Kerstin] Res Ctr Juelich, D-52428 Julich, Germany.
   [Neuschaefer-Rube, Christiane] Rhein Westfal TH Aachen, Fac Med, Clin Phoniatr Pedaudiol & Commun Disorders, D-52074 Aachen, Germany.
RP Bell, L (corresponding author), Rhein Westfal TH Aachen, Child Neuropsychol Sect, Dept Child & Adolescent Psychiat Psychosomat & Ps, Fac Med, D-52074 Aachen, Germany.
EM lbell@ukaachen.de; z.ellen.peng@wisc.edu;
   florian.pausch@akustik.rwth-aachen.de; vreindl@ukaachen.de;
   cneuschaefer@ukaachen.de; Janina.Fels@akustik.rwth-aachen.de;
   kkonrad@ukaachen.de
RI Pausch, Florian/T-1017-2016
OI Pausch, Florian/0000-0003-2728-3170; Peng, Z. Ellen/0000-0002-3487-2144;
   Fels, Janina/0000-0002-8694-7750; Neuschaefer-Rube,
   Christiane/0000-0002-2207-0670
FU Excellence Initiative of the German Federal and State Governments (ERS)
   [OPBF090]; Deutsche Forschungsgemeinschaft (DFG, German Research
   Foundation)German Research Foundation (DFG) [INST 948/18-1 FUGG,
   269953372/GRK2150]; European Union's Seventh Framework Programme:
   Improving Children's Auditory Rehabilitation (iCARE) [ITN FP7-607139]
FX This work was supported by the Excellence Initiative of the German
   Federal and State Governments (ERS Boost Fund 2014; OPBF090), the
   Deutsche Forschungsgemeinschaft (DFG, German Research Foundation;
   269953372/GRK2150), and the European Union's Seventh Framework
   Programme: Improving Children's Auditory Rehabilitation (iCARE, ITN
   FP7-607139). The purchase of the Hitachi fNIRS system for the University
   Hospital RWTH Aachen (Germany) was supported by funding from the
   Deutsche Forschungsgemeinschaft (DFG, German Research Foundation; INST
   948/18-1 FUGG), awarded to K.K.
CR Ahrens A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214603
   Ahrens A, 2019, HEARING RES, V377, P307, DOI 10.1016/j.heares.2019.02.003
   Anderson CA, 2019, JARO-J ASSOC RES OTO, V20, P511, DOI 10.1007/s10162-019-00729-z
   Anderson CA, 2017, P NATL ACAD SCI USA, V114, P10256, DOI 10.1073/pnas.1704785114
   Aspock L., 2016, P EUROREGIO 2016 POR
   Bell L, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10050307
   Bell L, 2019, NEURAL PLAST, V2019, DOI 10.1155/2019/9603469
   Best V, 2010, INT J AUDIOL, V49, P723, DOI 10.3109/14992027.2010.484827
   Bomhardt R., 2014, P AUD ENG SOC CONV L
   Bonna K., 2019, ARXIV190311915
   BRONKHORST AW, 1995, J ACOUST SOC AM, V98, P2542, DOI 10.1121/1.413219
   Brown AD, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516668303
   Buss E, 2001, J ACOUST SOC AM, V109, P727, DOI 10.1121/1.1337960
   Cameron S, 2006, INT J AUDIOL, V45, P99, DOI 10.1080/14992020500377931
   Cameron S, 2007, EAR HEARING, V28, P196, DOI 10.1097/AUD.0b013e318031267f
   Chen LC, 2015, BRAIN TOPOGR, V28, P710, DOI 10.1007/s10548-015-0424-8
   Ching TYC, 2018, INT J AUDIOL, V57, pS70, DOI 10.1080/14992027.2017.1346307
   Ching TYC, 2011, J ACOUST SOC AM, V129, P368, DOI 10.1121/1.3523295
   Ching TYC, 2001, EAR HEARING, V22, P212, DOI 10.1097/00003446-200106000-00005
   Courtois G, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216519887615
   Crandell CC, 2000, LANG SPEECH HEAR SER, V31, P362, DOI 10.1044/0161-1461.3104.362
   Crawford JR, 2010, COGN NEUROPSYCHOL, V27, P245, DOI 10.1080/02643294.2010.513967
   Crawford JR, 2002, NEUROPSYCHOLOGIA, V40, P1196, DOI 10.1016/S0028-3932(01)00224-X
   Crawford JR, 1998, CLIN NEUROPSYCHOL, V12, P482, DOI 10.1076/clin.12.4.482.7241
   Dai BH, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04819-z
   Defenderfer J, 2017, NEUROPSYCHOLOGIA, V106, P31, DOI 10.1016/j.neuropsychologia.2017.09.004
   Delage H, 2007, J SPEECH LANG HEAR R, V50, P1300, DOI 10.1044/1092-4388(2007/091)
   Denk F, 2019, J ACOUST SOC AM, V146, P1732, DOI 10.1121/1.5126521
   Dewey RS, 2015, HEARING RES, V325, P55, DOI 10.1016/j.heares.2015.03.007
   Di Lorenzo R, 2019, NEUROIMAGE, V200, P511, DOI 10.1016/j.neuroimage.2019.06.056
   Dimitrijevic A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-47643-1
   Doring W.H., 1992, NEUE SPRACHVERSTANDL, P137
   Fels J, 2004, ACTA ACUST UNITED AC, V90, P918
   Fels J, 2009, ACTA ACUST UNITED AC, V95, P331, DOI 10.3813/AAA.918156
   Fruend I, 2011, J VISION, V11, DOI 10.1167/11.6.16
   Gagnon L, 2012, NEUROIMAGE, V59, P3933, DOI 10.1016/j.neuroimage.2011.10.054
   Garcia D.P., 2014, P 7 FOR AC KRAK POL
   Glista D, 2012, J SPEECH LANG HEAR R, V55, P1765, DOI 10.1044/1092-4388(2012/11-0163)
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Grimm G, 2006, ACTA ACUST UNITED AC, V92, P618
   Grimm G, 2019, ACTA ACUST UNITED AC, V105, P566, DOI 10.3813/AAA.919337
   Grimm G, 2018, INT J AUDIOL, V57, pS112, DOI 10.1080/14992027.2016.1247501
   HochmairDesoyer I, 1997, AM J OTOL, V18, pS83
   Holmer E, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00107
   Huppert TJ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184918
   Huppert TJ, 2009, APPL OPTICS, V48, pD280, DOI 10.1364/AO.48.00D280
   IBM Corp, 2015, IBM SPSS STAT WIND V
   Ihlefeld A, 2011, J ACOUST SOC AM, V130, P324, DOI 10.1121/1.3596476
   Jahani S, 2018, NEUROPHOTONICS, V5, DOI 10.1117/1.NPh.5.1.015003
   Jiang J, 2012, J NEUROSCI, V32, P16064, DOI 10.1523/JNEUROSCI.2926-12.2012
   Johnstone PM, 2010, J AM ACAD AUDIOL, V21, P522, DOI 10.3766/jaaa.21.8.4
   Keidser G, 2011, AUDIOL RES, V1, P88, DOI 10.4081/audiores.2011.e24
   Kidd G, 2005, ACTA ACUST UNITED AC, V91, P526
   Klatte M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00578
   Klatte M, 2010, NOISE HEALTH, V12, P270, DOI 10.4103/1463-1741.70506
   Klatte M, 2010, ENVIRON BEHAV, V42, P659, DOI 10.1177/0013916509336813
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Kolarik AJ, 2017, EXP BRAIN RES, V235, P597, DOI 10.1007/s00221-016-4823-1
   Kolarik AJ, 2013, EXP BRAIN RES, V224, P623, DOI 10.1007/s00221-012-3340-0
   Kollmeier B, 1997, J ACOUST SOC AM, V102, P2412, DOI 10.1121/1.419624
   Kuehnel V, 1999, Z AUDIOL, V38, P4
   Lalonde K, 2020, EAR HEARING, V41, P705, DOI 10.1097/AUD.0000000000000830
   Lawler Carly A, 2015, Cochlear Implants Int, V16 Suppl 1, pS30, DOI 10.1179/1467010014Z.000000000230
   Lawrence RJ, 2018, HEARING RES, V370, P53, DOI 10.1016/j.heares.2018.09.005
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   MacCutcheon D, 2019, J SPEECH LANG HEAR R, V62, P3741, DOI 10.1044/2019_JSLHR-S-19-0012
   MacCutcheon D, 2019, J COGN PSYCHOL, V31, P175, DOI 10.1080/20445911.2019.1575387
   MacCutcheon D, 2018, SCAND J PSYCHOL, V59, P567, DOI 10.1111/sjop.12466
   Marsella P, 2017, INT J PEDIATR OTORHI, V99, P1, DOI 10.1016/j.ijporl.2017.05.006
   Masiero B.S., 2012, INDIVIDUALIZED BINAU, V13
   McCreery RW, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01093
   Mei N, 2020, NEUROPSYCHOLOGIA, V140, DOI 10.1016/j.neuropsychologia.2020.107389
   Middlebrooks JC, 1999, J ACOUST SOC AM, V106, P1480, DOI 10.1121/1.427176
   Minagawa Y, 2018, JPN PSYCHOL RES, V60, P196, DOI 10.1111/jpr.12207
   Minagawa-Kawai Y., 2009, NEW APPROACH FUNCTIO
   Minagawa-Kawai Y, 2011, DEV COGN NEUROS-NETH, V1, P217, DOI 10.1016/j.dcn.2011.03.005
   Moeller MP, 2007, EAR HEARING, V28, P740, DOI 10.1097/AUD.0b013e318157f07f
   Mushtaq F, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00308
   Mushtaq F, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219927
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Nirme J, 2020, SPEECH COMMUN, V116, P44, DOI 10.1016/j.specom.2019.11.005
   Oberem J, 2018, HEARING RES, V359, P32, DOI 10.1016/j.heares.2017.12.013
   Oberem J, 2014, ACTA ACUST UNITED AC, V100, P1139, DOI 10.3813/AAA.918793
   Olds C, 2016, EAR HEARING, V37, pE160, DOI 10.1097/AUD.0000000000000258
   Pausch F, 2020, TRENDS HEAR, V24, DOI 10.1177/2331216520908704
   Pausch F, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518800871
   Peelle JE, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00309
   Pelzer S, 2014, BUILD ACOUST, V21, P65, DOI 10.1260/1351-010X.21.1.65
   Peng Z.E., 2016, P DAGA 2016 42 JAHR
   Peng ZE, 2019, J SPEECH LANG HEAR R, V62, P1068, DOI 10.1044/2018_JSLHR-H-17-0423
   Peng ZE, 2016, J ACOUST SOC AM, V139, P2772, DOI 10.1121/1.4948564
   Pollonini L, 2014, HEARING RES, V309, P84, DOI 10.1016/j.heares.2013.11.007
   Puschmann S, 2019, NEUROIMAGE, V196, P261, DOI 10.1016/j.neuroimage.2019.04.017
   Puschmann S, 2017, J NEUROSCI, V37, P11505, DOI 10.1523/JNEUROSCI.1007-17.2017
   Quaresima V, 2012, BRAIN LANG, V121, P79, DOI 10.1016/j.bandl.2011.03.009
   R Core Team, 2019, R LANG ENV STAT COMP
   Ricketts TA, 2019, J SPEECH LANG HEAR R, V62, P3834, DOI 10.1044/2019_JSLHR-H-19-0013
   Ronnberg J, 2019, INT J AUDIOL, V58, P247, DOI 10.1080/14992027.2018.1551631
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Rowland SC, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518804116
   Rudner M, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01193
   Rudner M, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01047
   SCHMITZ A, 1995, ACUSTICA, V81, P416
   Scholkmann F, 2014, NEUROIMAGE, V85, P6, DOI 10.1016/j.neuroimage.2013.05.004
   Scholkmann F, 2013, J BIOMED OPT, V18, DOI 10.1117/1.JBO.18.10.105004
   Schroder D., 2011, PHYSICALLY BASED REA, V11
   Schutt HH, 2016, VISION RES, V122, P105, DOI 10.1016/j.visres.2016.02.002
   Sevy ABG, 2010, HEARING RES, V270, P39, DOI 10.1016/j.heares.2010.09.010
   Shinn-Cunningham B.G., 2000, P IEEE PCM 2000 SYDN, P227, DOI 10.1.1.73.2560
   Signoret C, 2019, EAR HEARING, V40, P1140, DOI 10.1097/AUD.0000000000000689
   Soli SD, 2008, INT J AUDIOL, V47, P356, DOI 10.1080/14992020801895136
   Stelmachowicz PG, 2004, ARCH OTOLARYNGOL, V130, P556, DOI 10.1001/archotol.130.5.556
   Stone MA, 2008, EAR HEARING, V29, P601, DOI 10.1097/AUD.0b013e3181734ef2
   Subramaniam N., 2006, IE J AR, V87, P28
   Tachtsidis Ilias, 2016, Neurophotonics, V3, P030401, DOI 10.1117/1.NPh.3.3.030401
   Tak S, 2016, J NEUROSCI METH, V264, P103, DOI 10.1016/j.jneumeth.2016.03.003
   Telkemeyer S, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00062
   Tillery KH, 2012, J ACOUST SOC AM, V131, P416, DOI 10.1121/1.3664101
   Tomblin JB, 2014, JAMA OTOLARYNGOL, V140, P403, DOI 10.1001/jamaoto.2014.267
   Toolbox Global Optimization, 2019, TOOLB GLOB OPT US GU
   Torkildsen Janne von Koss, 2019, Front Psychol, V10, P2530, DOI 10.3389/fpsyg.2019.02530
   Tsuzuki D, 2007, NEUROIMAGE, V34, P1506, DOI 10.1016/j.neuroimage.2006.10.043
   van de Rijt Luuk P H, 2018, J Hear Sci, V8, P9, DOI 10.17430/1003278
   van de Rijt LPH, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00048
   Van den Bogaert T, 2011, INT J AUDIOL, V50, P164, DOI 10.3109/14992027.2010.537376
   Van Deun L, 2010, EAR HEARING, V31, P702, DOI 10.1097/AUD.0b013e3181e40dfe
   Vickers D, 2016, ADV EXP MED BIOL, V894, P115, DOI 10.1007/978-3-319-25474-6_13
   Wagener K, 2005, Z AUDIOL, V44, P134
   Weder S, 2020, EAR HEARING, V41, P1187, DOI 10.1097/AUD.0000000000000836
   WENZEL EM, 1993, J ACOUST SOC AM, V94, P111, DOI 10.1121/1.407089
   Wiggins I. M., 2016, J ACOUST SOC AM, V139, P2074, DOI [10. 1121/1. 4950150, DOI 10.1121/1.4950150]
   Wijayasiri P, 2017, HEARING RES, V351, P55, DOI 10.1016/j.heares.2017.05.010
   Wilson Richard H, 2003, J Am Acad Audiol, V14, P453
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
   Yang W, 2009, J ACOUST SOC AM, V125, P922, DOI 10.1121/1.3058900
   Zahorik P, 2002, J ACOUST SOC AM, V111, P1832, DOI 10.1121/1.1458027
   Zhang M, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518817464
   Zhou X, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518786850
NR 138
TC 0
Z9 0
U1 3
U2 3
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2227-9067
J9 CHILDREN-BASEL
JI Children-Basel
PD NOV
PY 2020
VL 7
IS 11
AR 219
DI 10.3390/children7110219
PG 25
WC Pediatrics
SC Pediatrics
GA OW3JF
UT WOS:000592786800001
PM 33171753
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Jimenez-Bravo, M
   Marrero-Aguiar, V
AF Jimenez-Bravo, Miguel
   Marrero-Aguiar, Victoria
TI Multimodal perception of prominence in spontaneous speech: A
   methodological proposal using mixed models and AIC
SO SPEECH COMMUNICATION
LA English
DT Article
DE Audiovisual prosody; Gesture; Prominence; Speech perception; Spontaneous
   speech; Generalised linear mixed models; Akaike Information Criterion
ID PROSODIC PROMINENCE; BEAT GESTURES; REPRESENTATION; MULTILEVEL;
   SELECTION; ECOLOGY; DUTCH
AB Research on prominence perception has made use of animated agents and controlled speech in experimental settings, but these methodologies have disregarded some aspects of the acoustic and visual correlates of prom-inence. To overcome these limitations we propose a new methodological approach using spontaneous speech data. For this, we created a small database with extracts from a television talent show and neutralised the prominence-lending properties of the acoustic cues of prominence in the speech signal. In our pilot study twelve naive listeners marked words for binary prominence (prominent vs. non-prominent) in two modalities, i.e. audio only and audiovisual, under three conditions involving neutralisation of (a) fundamental frequency, (b) intensity, and (c) both fundamental frequency and intensity. Additionally, the marks of two trained listeners served as control condition. Different generalised linear mixed models were estimated and compared using the Akaike Information Criterion (AIC). The most parsimonious model was then examined using traditional null-hypothesis testing in order to provisionally establish the effects of our independent variables on prominence marking. We argue that spontaneous speech can be successfully applied to the study of the multimodal perception of prominence.
C1 [Jimenez-Bravo, Miguel] Univ Complutense Madrid, Fac Filol, Dept Gen Linguist, Edificio D,C Prof Aranguren S-N,Ciudad Univ, Madrid 28040, Spain.
   [Marrero-Aguiar, Victoria] Univ Nacl Educ Distancia, Dept Gen Linguist, Madrid, Spain.
RP Jimenez-Bravo, M (corresponding author), Univ Complutense Madrid, Fac Filol, Dept Gen Linguist, Edificio D,C Prof Aranguren S-N,Ciudad Univ, Madrid 28040, Spain.
EM miguel.jimenez.bravo@ucm.es; vmarrero@flog.uned.es
OI Jimenez-Bravo, Miguel/0000-0003-3579-1618
CR Adamou E., 2018, STUDIES LANGUAGE COM, V199, P51
   Agelfors E., 1998, P INT C SPOK LANG PR, P3047
   Akaike H., 1973, 2 INT S INF THEOR AK, P267, DOI DOI 10.1007/978-1-4612-1694-0_15
   Al Moubayed S, 2011, LECT NOTES COMPUT SC, V6456, P55, DOI 10.1007/978-3-642-18184-9_6
   Ambrazaitis G, 2017, SPEECH COMMUN, V95, P100, DOI 10.1016/j.specom.2017.08.008
   Armstrong D.F., 1995, GESTURE NATURE LANGU, DOI [10.1017/CBO9780511620911, DOI 10.1017/CBO9780511620911]
   Arnold TW, 2010, J WILDLIFE MANAGE, V74, P1175, DOI 10.2193/2009-367
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, PARSIMONIOUS MIXED M
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beckman M. E., 1994, PHONOLOGICAL STRUCTU, P7, DOI DOI 10.1017/CBO9780511659461.002
   Bednarek M., 2013, REAL TALK REALITY TE, P88, DOI [10.1057/9781137313461_6., DOI 10.1057/9781137313461_6]
   Beskow J, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1272
   Biau E, 2015, CORTEX, V68, P76, DOI 10.1016/j.cortex.2014.11.018
   Biau E, 2013, BRAIN LANG, V124, P143, DOI 10.1016/j.bandl.2012.10.008
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bolker BM, 2009, TRENDS ECOL EVOL, V24, P127, DOI 10.1016/j.tree.2008.10.008
   Brentari D., 2012, STUDI SAGGI LINGUIST, V1, P83
   Brugman H, 2004, P LREC 2004 4 INT C
   Burnham KP, 2011, BEHAV ECOL SOCIOBIOL, V65, P23, DOI 10.1007/s00265-010-1029-6
   Burnham KP., 2002, MODEL SELECTION MULT, V2
   Cartmill EA, 2012, PHILOS T R SOC B, V367, P129, DOI 10.1098/rstb.2011.0162
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Dohen M, 2009, LANG SPEECH, V52, P177, DOI 10.1177/0023830909103166
   Eberhardt M, 2015, J ENGL LINGUIST, V43, P118, DOI 10.1177/0075424215578147
   Estebas-Vilaplana Eva, 2010, TRANSCRIPTION INTONA, P17
   Esteve-Gibert N, 2014, SPEECH COMMUN, V57, P301, DOI 10.1016/j.specom.2013.06.006
   Face T., 2003, CATALAN J LINGUISTIC, V2, P115
   Foxton JM, 2010, COGNITION, V115, P71, DOI 10.1016/j.cognition.2009.11.009
   Garrido J.M., 1995, TRABAJOS DEFONETICA, P177
   Gentilucci M, 2006, NEUROSCI BIOBEHAV R, V30, P949, DOI 10.1016/j.neubiorev.2006.02.004
   Granstrom B, 2005, SPEECH COMMUN, V46, P473, DOI 10.1016/j.specom.2005.02.017
   Granstrom B., 1999, P INT C PHON SCI, V1, P655
   Gries ST, 2015, CORPORA, V10, P95, DOI 10.3366/cor.2015.0068
   Grueber CE, 2011, J EVOLUTION BIOL, V24, P699, DOI 10.1111/j.1420-9101.2010.02210.x
   House D., 2001, P EUR 2001, P387
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Jannedy S., 2005, INTERDISCIPLINARY ST, V3, P199
   Kendon A., 2004, GESTURE VISIBLE ACTI
   Kendon A., 1980, RELATIONSHIP VERBAL, P207, DOI DOI 10.1515/9783110813098.207
   Kim J, 2014, SPEECH COMMUN, V57, P317, DOI 10.1016/j.specom.2013.06.003
   KLATT DH, 1973, J ACOUST SOC AM, V53, P8, DOI 10.1121/1.1913333
   Kochanski G, 2005, J ACOUST SOC AM, V118, P1038, DOI 10.1121/1.1923349
   Kohler KJ, 2008, PHONETICA, V65, P257, DOI 10.1159/000192795
   Krahmer E, 2004, HUM-COMPUT INT-SPRIN, V7, P191
   Krahmer E., 2002, P INT C SPOK LANG PR, P1933
   Krahmer E, 2007, J MEM LANG, V57, P396, DOI 10.1016/j.jml.2007.06.005
   Kuhn M, 2013, APPL PREDICTIVE MODE, P419, DOI DOI 10.1007/978-1-4614-6849-3
   Kuhn M., 2013, APPL PREDICTIVE MODE, P247, DOI [10.1007/978-1-4614-6849-3., DOI 10.1007/978-1-4614-6849-3_11, 10.1007/978-1-4614-6849-3_11]
   Kuhn M, 2008, J STAT SOFTW, V28, P1, DOI 10.18637/jss.v028.i05
   Kushch O, 2016, P 8 INT C SPEECH PRO, V8, P922
   Laan GPM, 1997, SPEECH COMMUN, V22, P43, DOI 10.1016/S0167-6393(97)00012-5
   Ladd D.Robert., 1996, INTONATIONAL PHONOLO
   Leonard T, 2011, LANG COGNITIVE PROC, V26, P1457, DOI 10.1080/01690965.2010.500218
   Loehr D, 2012, J LAB PHONOL, V3, P71, DOI [DOI 10.1515/lp-2012-0006, DOI 10.1515/LP-2012-0006]
   Loehr D., 2007, GESTURE, V7, P179, DOI [10.1075/gest.7.2.04loe, DOI 10.1075/GEST.7.2.04LOE]
   Mahrt T, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P2421
   Masson-Carro I, 2017, J NONVERBAL BEHAV, V41, P367, DOI 10.1007/s10919-017-0261-4
   Mazerolle M.J., 2017, R PACKAGE VERS, V2, P1, DOI DOI 10.1515/pacres-2017-0001
   McNeill D., 1992, HAND MIND WHAT GESTU
   McNeill D., 2012, LANGUAGE BEGAN
   Mo Y., 2008, ANN M BERK LING SOC, V34, P257
   Mo Y., 2008, P SPEECH PROS 2008
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Ortega-Llebaria M, 2011, LANG SPEECH, V54, P73, DOI 10.1177/0023830910388014
   Ortega-Llebaria Marta, 2006, SEL P 2 C LAB APPR S, P104
   Pierrehumbert J., 1980, THESIS
   Powell M. J., 2009, NA200906 DEP APPL MA
   Prieto P, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P984
   Quak M, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00197
   Quene H, 2008, J ACOUST SOC AM, V123, P1104, DOI 10.1121/1.2821762
   R Development Core Team, 2018, R LANGUAGE ENV STAT
   RIETVELD ACM, 1985, J PHONETICS, V13, P299, DOI 10.1016/S0095-4470(19)30761-2
   Rosenberg A., 2009, P HUM LANG TECHN 200, P81, DOI 10.3115/1620853.1620878
   Scarborough R, 2009, LANG SPEECH, V52, P135, DOI 10.1177/0023830909103165
   Silipo R., 2000, P NIST SPEECH TRANSC
   Singmann H., 2019, NEW METHODS COGNITIV, P4, DOI DOI 10.4324/9780429318405-2
   Snipes M., 2014, Wine Economics and Policy, V3, P3, DOI 10.1016/j.wep.2014.03.001
   Sonderegger M., 2012, PHONETIC PHONOLOGICA
   Streefkerk B.M., 2002, ACOUSTIC LEXICAL SYN
   Streefkert B.M., 1997, P I PHONETIC SCI U A, P101
   Swerts M, 2002, J PHONETICS, V30, P629, DOI 10.1006/jpho.2002.0178
   Swerts M, 2008, J PHONETICS, V36, P219, DOI 10.1016/j.wocn.2007.05.001
   Swerts M, 2010, J PHONETICS, V38, P197, DOI 10.1016/j.wocn.2009.10.002
   Tamburini F., 2007, P INTERSPEECH 2007 A, P1809
   Terken J., 1996, COMPUTING PROSODY AP, P95
   THART J, 1981, J ACOUST SOC AM, V69, P811, DOI 10.1121/1.385592
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   van Maastricht L, 2016, LANG LEARN, V66, P124, DOI 10.1111/lang.12141
   Wagner P, 2014, SPEECH COMMUN, V57, P209, DOI 10.1016/j.specom.2013.09.008
NR 91
TC 0
Z9 0
U1 2
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-6393
EI 1872-7182
J9 SPEECH COMMUN
JI Speech Commun.
PD NOV
PY 2020
VL 124
BP 28
EP 45
DI 10.1016/j.specom.2020.07.006
PG 18
WC Acoustics; Computer Science, Interdisciplinary Applications
SC Acoustics; Computer Science
GA OU4NC
UT WOS:000591505000004
DA 2021-02-24
ER

PT J
AU Aubanel, V
   Bayard, C
   Strauss, A
   Schwartz, JL
AF Aubanel, Vincent
   Bayard, C.
   Strauss, A.
   Schwartz, J-L
TI The Fharvard corpus: A phonemically-balanced French sentence resource
   for audiology and intelligibility research
SO SPEECH COMMUNICATION
LA English
DT Article
DE Speech perception; Noise; Psychoacoustics; hearing science; Behavioural
   measures; Speech intelligibility; Speech database; French
ID SPEECH-INTELLIGIBILITY; NOISE; HEARING; INFORMATION; RECEPTION
AB The current study describes the collection of a new phonemically-balanced sentence resource for French, known as the Fharvard corpus. The resource consists of 700 sentences inspired by the original English Harvard sentences, along with audio recordings from one female and one male native French talker. Each of the sentences contains five monoor bisyllabic keywords and are grouped into 70 lists of 10 sentences using an automatic phoneme-balancing procedure. Twenty-three normal-hearing French listeners identified keywords in the Fharvard sentences in speech-shaped noise. Psychometric functions for the Fharvard sentences indicate mean speech reception thresholds of -4.48 and -3.87 dB and slopes of 10.55 and 12.52 percentage points per dB at the 50% keywords correct point for the female and male talkers respectively. The complete list of Fharvard sentences and the associated audio recordings are available online for speech perception testing.
C1 [Aubanel, Vincent; Bayard, C.; Schwartz, J-L] Univ Grenoble Alpes, GIPSA Lab, Grenoble INP, CNRS, Grenoble, France.
   [Strauss, A.] Univ Konstanz, Constance, Germany.
RP Aubanel, V (corresponding author), Univ Grenoble Alpes, GIPSA Lab, Grenoble INP, CNRS, Grenoble, France.
EM vincent.aubanel@gipsa-lab.fr
FU European Research Council under the European Community's Seventh
   Framework Program (FP7/2007-2013) [339152]
FX This work was supported by the European Research Council under the
   European Community's Seventh Framework Program (FP7/2007-2013 Grant
   Agreement no. 339152, "Speech Unit(e)s''). We thank Laura Machart for
   her help in collecting data.
CR Adda-Decker M., 2006, ACT 26 JOURN ET PAR, P389
   Aubanel V, 2013, INTERSPEECH, P3559
   Aubanel V, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00430
   Aubanel V, 2014, INT J AUDIOL, V53, P633, DOI 10.3109/14992027.2014.907507
   Barker J, 2007, SPEECH COMMUN, V49, P402, DOI 10.1016/j.specom.2006.11.003
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bayard C, 2019, J DEAF STUD DEAF EDU, V24, P223, DOI 10.1093/deafed/enz003
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   Bertrand R, 2008, TRAIT AUTOM LANG, V49, P105
   Brysbaert M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00027
   Combescure P, 1981, REV ACOUSTIQUE, V56, P34
   Content A., 1990, ANN PSYCHOL, P1
   Cooke M, 2017, J ACOUST SOC AM, V141, P4126, DOI 10.1121/1.4983826
   Cooke M, 2013, SPEECH COMMUN, V55, P572, DOI 10.1016/j.specom.2013.01.001
   Dodele L., 2000, CAHIERS LAUDITION, V13
   Durand J., 2003, CORPUS VARIATION PHO, P213
   Fournier J.E., 1951, AUDIOMETRIE VOCALE E
   Gibson E, 2000, IMAGE, LANGUAGE, BRAIN, P95
   Giraud AL, 2012, SPRINGER HANDB AUDIT, V43, P225, DOI 10.1007/978-1-4614-2314-0_9
   Goldman Philippe, 2011, P INT, P3233
   Greenberg S., 1997, P ESCA WORKSH ROB SP, P23
   Jansen S, 2012, INT J AUDIOL, V51, P164, DOI 10.3109/14992027.2011.633568
   Kressner AA, 2018, J ACOUST SOC AM, V144, P1113, DOI 10.1121/1.5051640
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Lopez-Poveda EA, 2017, HEARING RES, V348, P134, DOI 10.1016/j.heares.2017.02.003
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Luts H, 2008, INT J AUDIOL, V47, P373, DOI 10.1080/14992020801887786
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493
   Nelson MJ, 2017, P NATL ACAD SCI USA, V114, pE3669, DOI 10.1073/pnas.1701590114
   New B, 2001, ANN PSYCHOL, V101, P447
   New B, 2007, APPL PSYCHOLINGUIST, V28, P661, DOI 10.1017/S014271640707035X
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Qin MK, 2003, J ACOUST SOC AM, V114, P446, DOI 10.1121/1.1579009
   Quilis A., 1993, TRATADO FONOLOGIA FO
   Rothauser E.H., 1969, IEEE T AUDIO ACOUST, V22, P5
   Scott SK, 2000, BRAIN, V123, P2400, DOI 10.1093/brain/123.12.2400
   Stajner S., 2017, P 26 INT JOINT C ART, P4096
   Vaillancourt H, 2005, INT J AUDIOL, V44, P358, DOI 10.1080/14992020500060875
   Wioland F., 1985, STRUCTURES SYLLABIQU
   Wolff A., 2014, FRENCH LANGUAGE WORL
   Zychaluk K, 2009, ATTEN PERCEPT PSYCHO, V71, P1414, DOI 10.3758/APP.71.6.1414
NR 41
TC 1
Z9 1
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-6393
EI 1872-7182
J9 SPEECH COMMUN
JI Speech Commun.
PD NOV
PY 2020
VL 124
BP 68
EP 74
DI 10.1016/j.specom.2020.07.004
PG 7
WC Acoustics; Computer Science, Interdisciplinary Applications
SC Acoustics; Computer Science
GA OU4NC
UT WOS:000591505000006
DA 2021-02-24
ER

PT J
AU Guldner, S
   Nees, F
   McGettigan, C
AF Guldner, Stella
   Nees, Frauke
   McGettigan, Carolyn
TI Vocomotor and Social Brain Networks Work Together to Express Social
   Traits in Voices
SO CEREBRAL CORTEX
LA English
DT Article
DE fMRI; social communication; social traits; vocal control; voice
   production
ID MEDIAL PREFRONTAL CORTEX; INFERIOR FRONTAL-CORTEX; NEURAL
   REPRESENTATION; VOCAL EXPRESSIONS; SPEECH-PERCEPTION; COMPETENCE;
   COGNITION; DISTINCT; MODEL; TRUSTWORTHINESS
AB Voice modulation is important when navigating social interactions-tone of voice in a business negotiation is very different from that used to comfort an upset child. While voluntary vocal behavior relies on a cortical vocomotor network, social voice modulation may require additional social cognitive processing. Using functional magnetic resonance imaging, we investigated the neural basis for social vocal control and whether it involves an interplay of vocal control and social processing networks. Twenty-four healthy adult participants modulated their voice to express social traits along the dimensions of the social trait space (affiliation and competence) or to express body size (control for vocal flexibility). Naive listener ratings showed that vocal modulations were effective in evoking social trait ratings along the two primary dimensions of the social trait space. Whereas basic vocal modulation engaged the vocomotor network, social voice modulation specifically engaged social processing regions including the medial prefrontal cortex, superior temporal sulcus, and precuneus. Moreover, these regions showed task-relevant modulations in functional connectivity to the left inferior frontal gyrus, a core vocomotor control network area. These findings highlight the impact of the integration of vocal motor control and social information processing for socially meaningful voice modulation.
C1 [Guldner, Stella; Nees, Frauke] Heidelberg Univ, Med Fac Mannheim, Cent Inst Mental Hlth, Dept Cognit & Clin Neurosci, D-68159 Mannheim, Germany.
   [Guldner, Stella] Univ Mannheim, Grad Sch Econ & Social Sci, D-68159 Mannheim, Germany.
   [Guldner, Stella; McGettigan, Carolyn] UCL, Dept Speech Hearing & Phonet Sci, 2 Wakefield St, London WC1N 1PF, England.
   [Nees, Frauke] Univ Kiel, Univ Med Ctr Schleswig Holstein, Inst Med Psychol & Med Sociol, D-24105 Kiel, Germany.
   [McGettigan, Carolyn] Royal Holloway Univ London, Dept Psychol, Egham TW20 0EX, Surrey, England.
RP McGettigan, C (corresponding author), UCL, Dept Speech Hearing & Phonet Sci, 2 Wakefield St, London WC1N 1PF, England.; Guldner, S (corresponding author), Cent Inst Mental Hlth, Inst Cognit & Clin Neurosci, J5, D-68159 Mannheim, Germany.
EM stella.guldner@zi-mannheim.de; c.mcgettigan@ucl.ac.uk
OI Nees, Frauke/0000-0002-7796-8234; Guldner, Stella/0000-0001-7060-7711
FU Leverhulme TrustLeverhulme Trust [RL2016-013]
FX Research Leadership Award from The Leverhulme Trust (RL2016-013 to C.M.)
CR Ackermann H, 2014, BEHAV BRAIN SCI, V37, DOI 10.1017/S0140525X13003099
   Agnew ZK, 2017, BIORXIV, DOI [10.1101/107441, DOI 10.1101/107441]
   Austin John L., 1975, DO THINGS WORDS
   Aziz-Zadeh L, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0008759
   Banai IP, 2017, EVOL HUM BEHAV, V38, P309, DOI 10.1016/j.evolhumbehav.2016.10.012
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Barrett J, 2004, EUR J NEUROSCI, V19, P458, DOI 10.1111/j.0953-816X.2003.03113.x
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Baus C, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-36518-6
   Belin P, 2003, NEUROREPORT, V14, P2105, DOI 10.1097/00001756-200311140-00019
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Belin P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185651
   Belyk M, 2016, SOC COGN AFFECT NEUR, V11, P1078, DOI 10.1093/scan/nsv074
   Blair KS, 2007, NEUROIMAGE, V35, P430, DOI 10.1016/j.neuroimage.2006.11.048
   BOOK A, 2015, EVOLUTIONARY PSYCHOL, V1, P91, DOI DOI 10.1007/S40806-015-0012-X
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Brett M. A. J., 2002, NEUROIMAGE, V13, P210
   Brown S, 2019, ROY SOC OPEN SCI, V6, DOI 10.1098/rsos.181908
   Bzdok D, 2012, BRAIN STRUCT FUNCT, V217, P783, DOI 10.1007/s00429-012-0380-y
   Cabanis M, 2013, COGN AFFECT BEHAV NE, V13, P330, DOI 10.3758/s13415-012-0143-5
   Cartei V, 2014, BRIT J DEV PSYCHOL, V32, P100, DOI 10.1111/bjdp.12027
   Chuenwattanapranithi S, 2008, PHONETICA, V65, P210, DOI 10.1159/000192793
   Dricu M, 2016, NEUROSCI BIOBEHAV R, V71, P810, DOI 10.1016/j.neubiorev.2016.10.020
   Engell AD, 2007, J COGNITIVE NEUROSCI, V19, P1508, DOI 10.1162/jocn.2007.19.9.1508
   Ewbank MP, 2009, SOC COGN AFFECT NEUR, V4, P127, DOI 10.1093/scan/nsn048
   Fiske ST, 2002, J PERS SOC PSYCHOL, V82, P878, DOI 10.1037//0022-3514.82.6.878
   Fiske ST, 2007, TRENDS COGN SCI, V11, P77, DOI 10.1016/j.tics.2006.11.005
   Fraccaro PJ, 2013, ANIM BEHAV, V85, P127, DOI 10.1016/j.anbehav.2012.10.016
   Fruhholz S, 2015, CEREB CORTEX, V25, P2752, DOI 10.1093/cercor/bhu074
   Fruhholz S, 2013, CORTEX, V49, P1394, DOI 10.1016/j.cortex.2012.08.003
   Golestani N, 2007, CEREB CORTEX, V17, P929, DOI 10.1093/cercor/bhl003
   Gough PM, 2005, J NEUROSCI, V25, P8010, DOI 10.1523/JNEUROSCI.2307-05.2005
   Grice H. Paul, 1975, SYNTAX SEMANTICS, V3, P41, DOI [10.1057/9780230005853_5., DOI 10.1111/J.1365-2664.2006.01229.X]
   Hage SR, 2016, TRENDS NEUROSCI, V39, P813, DOI 10.1016/j.tins.2016.10.006
   Harris LT, 2007, SOC COGN AFFECT NEUR, V2, P45, DOI 10.1093/scan/nsl037
   Harris LT, 2005, NEUROIMAGE, V28, P763, DOI 10.1016/j.neuroimage.2005.05.021
   Hellbernd N, 2018, SOC COGN AFFECT NEUR, V13, P604, DOI 10.1093/scan/nsy034
   Hellbernd N, 2016, J MEM LANG, V88, P70, DOI 10.1016/j.jml.2016.01.001
   Hu CP, 2016, NEUROSCI BIOBEHAV R, V61, P197, DOI 10.1016/j.neubiorev.2015.12.003
   Hughes SM, 2014, J NONVERBAL BEHAV, V38, P107, DOI 10.1007/s10919-013-0163-z
   Jiang XM, 2017, SPEECH COMMUN, V88, P106, DOI 10.1016/j.specom.2017.01.011
   Klaas HS, 2015, FRONT BEHAV NEUROSCI, V9, DOI 10.3389/fnbeh.2015.00121
   Klasen M, 2018, SOC COGN AFFECT NEUR, V13, P418, DOI 10.1093/scan/nsy015
   Kleiner M, 2007, PERCEPTION, V36, P14
   Ko SJ, 2015, PSYCHOL SCI, V26, P3, DOI 10.1177/0956797614553009
   Krauss RM, 2002, J EXP SOC PSYCHOL, V38, P618, DOI 10.1016/S0022-1031(02)00510-3
   Kreifelts B, 2009, NEUROPSYCHOLOGIA, V47, P3059, DOI 10.1016/j.neuropsychologia.2009.07.001
   Krueger F, 2009, TRENDS COGN SCI, V13, P103, DOI 10.1016/j.tics.2008.12.005
   Laukka P, 2011, COGN AFFECT BEHAV NE, V11, P413, DOI 10.3758/s13415-011-0032-3
   LeDoux J, 2012, NEURON, V73, P653, DOI 10.1016/j.neuron.2012.02.004
   Ma N., 2013, SOCIAL COGNITIVE AFF, V9, P1506
   Ma N, 2016, SCI REP-UK, V6, DOI 10.1038/srep39609
   Ma N, 2014, SOC COGN AFFECT NEUR, V9, P1185, DOI 10.1093/scan/nst098
   Ma N, 2012, SOC NEUROSCI-UK, V7, P591, DOI 10.1080/17470919.2012.686925
   Ma N, 2011, SOC NEUROSCI-UK, V6, P123, DOI 10.1080/17470919.2010.485884
   McAleer P, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090779
   McGettigan C, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00129
   McGettigan C, 2013, J COGNITIVE NEUROSCI, V25, P1875, DOI 10.1162/jocn_a_00427
   Mitchell RLC, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00518
   Molenberghs P, 2016, NEUROSCI BIOBEHAV R, V65, P276, DOI 10.1016/j.neubiorev.2016.03.020
   Morningstar M, 2017, J NONVERBAL BEHAV, V41, P155, DOI 10.1007/s10919-017-0250-7
   Nicolle A, 2012, NEURON, V75, P1114, DOI 10.1016/j.neuron.2012.07.023
   Oleszkiewicz A, 2017, PSYCHON B REV, V24, P856, DOI 10.3758/s13423-016-1146-y
   Ongur D, 2003, J COMP NEUROL, V460, P425, DOI 10.1002/cne.10609
   Pannese A, 2016, CORTEX, V85, P116, DOI 10.1016/j.cortex.2016.10.013
   Peschke C, 2012, NEUROIMAGE, V59, P788, DOI 10.1016/j.neuroimage.2011.07.025
   Pichon S, 2013, J NEUROSCI, V33, P1640, DOI 10.1523/JNEUROSCI.3530-12.2013
   Pisanski K, 2016, J ACOUST SOC AM, V140, P3397
   Pisanski K, 2018, P ROY SOC B-BIOL SCI, V285, DOI 10.1098/rspb.2018.1634
   Pisanski K, 2016, SCI REP-UK, V6, DOI 10.1038/srep34389
   Pisanski K, 2016, TRENDS COGN SCI, V20, P304, DOI 10.1016/j.tics.2016.01.002
   Ponsot E, 2018, P NATL ACAD SCI USA, V115, P3972, DOI 10.1073/pnas.1716090115
   Redcay E, 2008, NEUROSCI BIOBEHAV R, V32, P123, DOI 10.1016/j.neubiorev.2007.06.004
   Redcay E, 2016, HUM BRAIN MAPP, V37, P3444, DOI 10.1002/hbm.23251
   Redcay E, 2010, NEUROIMAGE, V50, P1639, DOI 10.1016/j.neuroimage.2010.01.052
   Reiterer SM, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00782
   Sauter DA, 2010, Q J EXP PSYCHOL, V63, P2251, DOI 10.1080/17470211003721642
   Saxe R, 2006, PSYCHOL SCI, V17, P692, DOI 10.1111/j.1467-9280.2006.01768.x
   Schall S, 2015, J COGNITIVE NEUROSCI, V27, P280, DOI 10.1162/jocn_a_00707
   Schilbach L, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0081
   Schroeder J, 2015, PSYCHOL SCI, V26, P877, DOI 10.1177/0956797615572906
   Schurz M, 2014, NEUROSCI BIOBEHAV R, V42, P9, DOI 10.1016/j.neubiorev.2014.01.009
   Shultz S, 2012, J COGNITIVE NEUROSCI, V24, P1224, DOI 10.1162/jocn_a_00208
   Simmonds AJ, 2014, J NEUROPHYSIOL, V112, P792, DOI 10.1152/jn.00901.2013
   Simonyan K, 2011, NEUROSCIENTIST, V17, P197, DOI 10.1177/1073858410386727
   Slotnick SD, 2003, COGNITIVE BRAIN RES, V17, P75, DOI 10.1016/S0926-6410(03)00082-X
   Tavares RM, 2015, NEURON, V87, P231, DOI 10.1016/j.neuron.2015.06.011
   Thornton MA, 2019, J NEUROSCI, V39, P140, DOI 10.1523/JNEUROSCI.1431-18.2018
   Todorov A, 2005, SCIENCE, V308, P1623, DOI 10.1126/science.1110589
   Todorov A, 2008, SOC COGN AFFECT NEUR, V3, P119, DOI 10.1093/scan/nsn009
   Todorov A, 2008, TRENDS COGN SCI, V12, P455, DOI 10.1016/j.tics.2008.10.001
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   Van Duynslaeger M, 2007, SOC COGN AFFECT NEUR, V2, P174, DOI 10.1093/scan/nsm016
   Van Overwalle F, 2016, SOC NEUROSCI-UK, V11, P567, DOI 10.1080/17470919.2015.1120239
   Van Overwalle F, 2009, HUM BRAIN MAPP, V30, P829, DOI 10.1002/hbm.20547
   Venables W. N, 2002, MODERN APPL STAT S
   Waller SS, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01814
   Winter K, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-00745-0
   Wolpert DM, 2003, PHILOS T R SOC B, V358, P593, DOI 10.1098/rstb.2002.1238
NR 99
TC 0
Z9 0
U1 1
U2 1
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 1047-3211
EI 1460-2199
J9 CEREB CORTEX
JI Cereb. Cortex
PD NOV
PY 2020
VL 30
IS 11
BP 6004
EP 6020
DI 10.1093/cercor/bhaa175
PG 17
WC Neurosciences
SC Neurosciences & Neurology
GA OH6NK
UT WOS:000582709400028
PM 32577719
DA 2021-02-24
ER

PT J
AU Segers, M
   Bebko, JM
   Zapparoli, BL
   Stevenson, RA
AF Segers, Magali
   Bebko, James M.
   Zapparoli, Busisiwe L.
   Stevenson, Ryan A.
TI A Pupillometry Study of Multisensory Social and Linguistic Processing in
   Autism and Typical Development
SO DEVELOPMENTAL PSYCHOLOGY
LA English
DT Article
DE autism spectrum disorder; sensory processing; social; language;
   multisensory
ID TEMPORAL BINDING WINDOW; REPETITIVE BEHAVIORS; SPECTRUM DISORDER;
   SPEECH-PERCEPTION; PUPILLARY RESPONSES; YOUNG-CHILDREN; INTEGRATION;
   VALIDATION; SYNCHRONY; SYMPTOMS
AB Autism spectrum disorder is a neurodevelopmental disorder that is characterized by impairments in social communication, restricted interests, and repetitive behaviors. Many studies have demonstrated atypical responses to audiovisual sensory inputs. particularly those containing sociolinguistic information. It is currently unclear whether these atypical responses are due to the linguistic nature of the inputs or the social aspect itself. Further, it is unclear how atypical sensory responses to sociocommunicative stimuli intersect with autism symptomatology. The current study addressed these outstanding questions by using pupillometry in mental age-matched children with and without autism (N = 71) to examine physiological responses to dynamic, audiovisual stimuli including social, sociolinguistic, socioemotional, and nonsocial stimuli, as well as to temporally manipulated stimuli. Data revealed group differences in pupillary responses with social stimuli but not nonsocial stimuli and, importantly, showed no variation through the inclusion of linguistic or emotional information. This suggests that atypical sensory responses are driven primarily by the inclusion of social information broadly. Further. individual responses to social stimuli were significantly correlated with a wide range of autism spectrum disorder symptomatology, including social communication, restricted interests and repetitive behaviors, and sensory processing issues. Pupillary responses to social but not nonsocial presentation were also capable of predicting diagnosis with a high level of selectivity, but only with marginal sensitivity. Finally, responses to the temporal manipulation did not yield any group differences. suggesting that while atypical multisensory temporal processing has been well documented in autism at the level of behavior and perception, these issues may be intact at the physiological level.
C1 [Segers, Magali; Bebko, James M.; Zapparoli, Busisiwe L.] York Univ, Dept Psychol, N York, ON, Canada.
   [Segers, Magali; Stevenson, Ryan A.] Univ Western Ontario, Dept Psychol, Western Interdisciplinary Res Bldg, London, ON N6A 3K7, Canada.
   [Stevenson, Ryan A.] Univ Western Ontario, Brain & Mind Inst, Western Interdisciplinary Res Bldg, London, ON N6A 3K7, Canada.
RP Stevenson, RA (corresponding author), Univ Western Ontario, Dept Psychol, Western Interdisciplinary Res Bldg, London, ON N6A 3K7, Canada.; Stevenson, RA (corresponding author), Univ Western Ontario, Brain & Mind Inst, Western Interdisciplinary Res Bldg, London, ON N6A 3K7, Canada.
EM rsteve28@uwo.ca
FU NSERC Discovery GrantNatural Sciences and Engineering Research Council
   of Canada (NSERC) [RGPIN-2017-04656]; SSHRC Insight Grant
   [435-2017-0936]; University of Western Ontario Faculty Development
   Research Fund; Province of Ontario Early Researcher AwardMinistry of
   Research and Innovation, Ontario; Canadian Foundation for Innovation
   John R. Evans Leaders Fund [37,497]
FX Ryan A. Stevenson is funded by an NSERC Discovery Grant
   (RGPIN-2017-04656), an SSHRC Insight Grant (435-2017-0936), the
   University of Western Ontario Faculty Development Research Fund, the
   Province of Ontario Early Researcher Award, and a Canadian Foundation
   for Innovation John R. Evans Leaders Fund (37,497).
CR American Psychiatric Association (APA), 2013, DIAGN STAT MAN MENT
   Anderson CJ, 2006, J CLIN EXP NEUROPSYC, V28, P1238, DOI 10.1080/13803390500376790
   Anderson CJ, 2013, DEV PSYCHOBIOL, V55, P465, DOI 10.1002/dev.21051
   Arnott B, 2010, J DEV BEHAV PEDIATR, V31, P223, DOI 10.1097/DBP.0b013e3181d5a2ad
   Bahrick L. E, 2012, NEW HDB MULTISENSORY, P657
   BAHRICK LE, 1992, J EXP CHILD PSYCHOL, V53, P180, DOI 10.1016/0022-0965(92)90048-B
   Baranek GT, 1999, J AUTISM DEV DISORD, V29, P213, DOI 10.1023/A:1023080005650
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Baum SH, 2015, PROG NEUROBIOL, V134, P140, DOI 10.1016/j.pneurobio.2015.09.007
   Bebko JM, 2014, AUTISM RES, V7, P50, DOI 10.1002/aur.1343
   Bebko JM, 2006, J CHILD PSYCHOL PSYC, V47, P88, DOI 10.1111/j.1469-7610.2005.01443.x
   Beuker KT, 2013, J AUTISM DEV DISORD, V43, P45, DOI 10.1007/s10803-012-1546-4
   BIRREN JE, 1950, J GERONTOL, V5, P216
   Black KR, 2017, J AUTISM DEV DISORD, V47, P2459, DOI 10.1007/s10803-017-3161-x
   Boyd BA, 2010, AUTISM RES, V3, P78, DOI 10.1002/aur.124
   Bradley MM, 2008, PSYCHOPHYSIOLOGY, V45, P602, DOI 10.1111/j.1469-8986.2008.00654.x
   Brandwein AB, 2013, CEREB CORTEX, V23, P1329, DOI 10.1093/cercor/bhs109
   Bruni TP, 2014, J PSYCHOEDUC ASSESS, V32, P365, DOI 10.1177/0734282913517525
   Chen YC, 2016, J EXP CHILD PSYCHOL, V146, P17, DOI 10.1016/j.jecp.2016.01.010
   Chen YH, 2009, J AUTISM DEV DISORD, V39, P635, DOI 10.1007/s10803-008-0663-6
   Chevallier C, 2012, TRENDS COGN SCI, V16, P231, DOI 10.1016/j.tics.2012.02.007
   Collignon O, 2013, CORTEX, V49, P1704, DOI 10.1016/j.cortex.2012.06.001
   Constantino JN, 2003, J AUTISM DEV DISORD, V33, P427, DOI 10.1023/A:1025014929212
   COOPER RP, 1990, CHILD DEV, V61, P1584, DOI 10.1111/j.1467-8624.1990.tb02885.x
   Corden B, 2008, NEUROPSYCHOLOGIA, V46, P137, DOI 10.1016/j.neuropsychologia.2007.08.005
   de Boer-Schellekens L, 2013, FRONT INTEGR NEUROSC, V7, DOI 10.3389/fnint.2013.00008
   De Gelder B, 1991, EUROPEAN J COGNITIVE, V3, P69, DOI DOI 10.1080/09541449108406220
   DiLavore P. C., 2012, AUTISM DIAGNOSTIC OB
   Dunn W, 1997, AM J OCCUP THER, V51, P25, DOI 10.5014/ajot.51.1.25
   Erstenyuk V, 2014, RES AUTISM SPECT DIS, V8, P644, DOI 10.1016/j.rasd.2014.03.003
   Falck-Ytter T, 2008, AUTISM RES, V1, P297, DOI 10.1002/aur.45
   Fan XF, 2009, J AUTISM DEV DISORD, V39, P1499, DOI 10.1007/s10803-009-0767-7
   Feldman JI, 2018, NEUROSCI BIOBEHAV R, V95, P220, DOI 10.1016/j.neubiorev.2018.09.020
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   Grossman RB, 2009, J CHILD PSYCHOL PSYC, V50, P491, DOI 10.1111/j.1469-7610.2008.02002.x
   Harrar V, 2008, EXP BRAIN RES, V186, P517, DOI 10.1007/s00221-007-1253-0
   Hillock AR, 2011, NEUROPSYCHOLOGIA, V49, P461, DOI 10.1016/j.neuropsychologia.2010.11.041
   Hillock-Dunn A, 2012, DEVELOPMENTAL SCI, V15, P688, DOI 10.1111/j.1467-7687.2012.01171.x
   Iarocci G, 2006, J AUTISM DEV DISORD, V36, P77, DOI 10.1007/s10803-005-0044-3
   Iarocci G, 2010, AUTISM, V14, P305, DOI 10.1177/1362361309353615
   Jones EJH, 2016, J NEURODEV DISORD, V8, DOI 10.1186/s11689-016-9139-8
   JONES R, 1990, INVEST OPHTH VIS SCI, V31, P1413
   Klin A, 2002, ARCH GEN PSYCHIAT, V59, P809, DOI 10.1001/archpsyc.59.9.809
   Kuchinke L, 2011, NEUROPSYCHOLOGIA, V49, P331, DOI 10.1016/j.neuropsychologia.2010.12.026
   KWAKYE LD, 2011, NEUROSCIENCE, V4, DOI DOI 10.3389/FNINT.2010.00129
   Leekam S, 2007, J CHILD PSYCHOL PSYC, V48, P1131, DOI 10.1111/j.1469-7610.2007.01778.x
   MacLachlan C, 2002, OPHTHAL PHYSL OPT, V22, P175, DOI 10.1046/j.1475-1313.2002.00023.x
   Martineau J, 2011, J PSYCHIATR RES, V45, P1077, DOI 10.1016/j.jpsychires.2011.01.008
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MENDELSON MJ, 1982, CHILD DEV, V53, P1022, DOI 10.2307/1129143
   Mongillo EA, 2008, J AUTISM DEV DISORD, V38, P1349, DOI 10.1007/s10803-007-0521-y
   Nuske HJ, 2014, J NEURODEV DISORD, V6, DOI 10.1186/1866-1955-6-14
   Nystrom P, 2015, MOL AUTISM, V6, DOI 10.1186/s13229-015-0011-6
   OSTERLING J, 1994, J AUTISM DEV DISORD, V24, P247, DOI 10.1007/BF02172225
   Patten Elena, 2014, Autism Res Treat, V2014, P678346, DOI 10.1155/2014/678346
   Rieffe C, 2010, PERS INDIV DIFFER, V49, P362, DOI 10.1016/j.paid.2010.03.046
   Schulz SE, 2019, AUTISM, V23, P1028, DOI 10.1177/1362361318774559
   Segers M., 2012, DYNAMIC APPROACH TEM
   Smith EG, 2007, J CHILD PSYCHOL PSYC, V48, P813, DOI 10.1111/j.1469-7610.2007.01766.x
   Stevenson RA, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-14632-1
   Stevenson RA, 2018, J EXP PSYCHOL HUMAN, V44, P106, DOI 10.1037/xhp0000424
   Stevenson RA, 2017, AUTISM RES, V10, P1280, DOI 10.1002/aur.1776
   Stevenson RA, 2016, AUTISM RES, V9, P720, DOI 10.1002/aur.1566
   Stevenson RA, 2014, BRAIN TOPOGR, V27, P707, DOI 10.1007/s10548-014-0365-7
   Stevenson RA, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00379
   Stevenson RA, 2014, J AUTISM DEV DISORD, V44, P1470, DOI 10.1007/s10803-013-1992-7
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Stevenson RA, 2013, EXP BRAIN RES, V227, P249, DOI 10.1007/s00221-013-3507-3
   Stevenson RA, 2012, J EXP PSYCHOL HUMAN, V38, P1517, DOI 10.1037/a0027339
   Stevenson RA, 2010, NEUROIMAGE, V49, P3308, DOI 10.1016/j.neuroimage.2009.12.001
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   VANENGELAND H, 1991, PSYCHIAT RES, V38, P27, DOI 10.1016/0165-1781(91)90050-Y
   Vroomen J, 2010, ATTEN PERCEPT PSYCHO, V72, P871, DOI 10.3758/APP.72.4.871
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   Wechsler D, 2011, WASI 2 WECHSLER ABBR
   Williams DL, 2005, ARCH CLIN NEUROPSYCH, V20, P1, DOI 10.1016/j.acn.2002.08.001
   WINN B, 1994, INVEST OPHTH VIS SCI, V35, P1132
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
NR 78
TC 0
Z9 0
U1 3
U2 3
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0012-1649
EI 1939-0599
J9 DEV PSYCHOL
JI Dev. Psychol.
PD NOV
PY 2020
VL 56
IS 11
BP 2080
EP 2094
DI 10.1037/dev0001090
PG 15
WC Psychology, Developmental
SC Psychology
GA OK1RK
UT WOS:000584429000006
PM 32772527
DA 2021-02-24
ER

PT J
AU Lim, J
   Kim, Y
   Kim, N
AF Lim, Jongwoo
   Kim, Yeongjin
   Kim, Namkeun
TI Mechanical Effects of Cochlear Implants on Residual Hearing Loss: A
   Finite Element Analysis
SO IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
LA English
DT Article
DE Auditory system; Finite element analysis; Ligaments; Data models;
   Cochlear implants; Fluids; Geometry; Cochlear implant; finite element
   model; lateral CI; perimodiolar CI; residual hearing
ID HUMAN MIDDLE-EAR; ELECTRIC-ACOUSTIC STIMULATION; SPEECH-PERCEPTION;
   PRESERVATION; CHILDREN; BONE; LENGTH; RECOGNITION; STIFFNESS; INSERTION
AB The effects of cochlear implants on residual hearing loss is investigated through a finite element model of human auditory periphery consisting of the cochlea and middle ear. The simulation results show that a round window stiffness is the dominant factor in residual hearing loss. The increased round window stiffness to five times caused over 4 dB residual hearing loss at low frequencies below 500 Hz. Without considering round window ossification, inserting a cochlear implant can show at most 4 dB difference of residual hearing loss in magnitude from the no-implant case although the cochlear implant's geometry and position has been varied. If the stiffness of the round window is the same, the simulation results suggest to use a thin-straight-cochlear implant inserted into the lateral side in order to preserve residual hearing at frequencies below 700 Hz. In addition, when the distance between the basilar membrane and a cochlear implant is closer, the residual hearing loss becomes severe at high frequencies above 1 kHz. The results would be helpful for choice of a cochlear implant depending on a patient's condition.
C1 [Lim, Jongwoo; Kim, Yeongjin; Kim, Namkeun] Incheon Natl Univ, Dept Mech Engn, Incheon 22012, South Korea.
   [Kim, Namkeun] Ton Duc Thang Univ, Fac Elect & Elect Engn, Inst Computat Sci, Div Thermal & Fluids Sci, Ho Chi Minh City 758307, Vietnam.
RP Kim, Y (corresponding author), Incheon Natl Univ, Dept Mech Engn, Incheon 22012, South Korea.; Kim, N (corresponding author), Ton Duc Thang Univ, Fac Elect & Elect Engn, Inst Computat Sci, Div Thermal & Fluids Sci, Ho Chi Minh City 758307, Vietnam.
EM ykim@inu.ac.kr; nkim@tdtu.edu.vn
OI Kim, Yeongjin/0000-0001-5130-001X
FU Bio and Medical Technology Development Program of the NRF - Korean
   government [NRF-2017M3A9E2065287]; Incheon National University
FX This work was supported in part by the Bio and Medical Technology
   Development Program of the NRF funded by the Korean government
   (NRF-2017M3A9E2065287), and in part by the Incheon National University
   Research Grant in 2016.
CR Adunka OF, 2013, LARYNGOSCOPE, V123, P2509, DOI 10.1002/lary.23741
   Aibara R, 2001, HEARING RES, V152, P100, DOI 10.1016/S0378-5955(00)00240-9
   Baskent D, 2005, J ACOUST SOC AM, V117, P1405, DOI 10.1121/1.1856273
   BOGGESS WJ, 1989, LARYNGOSCOPE, V99, P1002
   Briggs R J, 2001, Cochlear Implants Int, V2, P135, DOI 10.1179/cim.2001.2.2.135
   Bruce IA, 2011, OTOL NEUROTOL, V32, P1444, DOI 10.1097/MAO.0b013e3182355824
   Chan WX, 2019, IEEE T BIO-MED ENG, V66, P1609, DOI 10.1109/TBME.2018.2876402
   Elliott SJ, 2016, HEARING RES, V341, P155, DOI 10.1016/j.heares.2016.08.006
   Fitzgerald MB, 2008, OTOL NEUROTOL, V29, P168, DOI 10.1097/mao.0b013e31815c4875
   Gan RZ, 2004, ANN BIOMED ENG, V32, P847, DOI 10.1023/B:ABME.0000030260.22737.53
   Gantz BJ, 2009, AUDIOL NEURO-OTOL, V14, P32, DOI 10.1159/000206493
   Gifford RH, 2013, EAR HEARING, V34, P413, DOI 10.1097/AUD.0b013e31827e8163
   Greene NT, 2015, OTOL NEUROTOL, V36, P1554, DOI 10.1097/MAO.0000000000000838
   Gstoettner WG, 2009, ACTA OTO-LARYNGOL, V129, P372, DOI 10.1080/00016480802552568
   Homma K, 2010, HEARING RES, V263, P204, DOI 10.1016/j.heares.2009.11.013
   Homma K, 2009, J ACOUST SOC AM, V125, P968, DOI 10.1121/1.3056564
   Huarte RM, 2014, CURR OPIN OTOLARYNGO, V22, P349, DOI 10.1097/MOO.0000000000000089
   Kha HN, 2004, MED ENG PHYS, V26, P677, DOI 10.1016/j.medengphy.2004.05.001
   Kiefer J, 2006, HEARING RES, V221, P36, DOI 10.1016/j.heares.2006.07.013
   Kim N, 2014, BIOPHYS J, V107, P233, DOI 10.1016/j.bpj.2014.04.052
   Kim N, 2011, JARO-J ASSOC RES OTO, V12, P261, DOI 10.1007/s10162-011-0258-3
   Koike T, 2002, J ACOUST SOC AM, V111, P1306, DOI 10.1121/1.1451073
   Lenarz T, 2013, INT J AUDIOL, V52, P838, DOI 10.3109/14992027.2013.802032
   Nakajima HH, 2009, JARO-J ASSOC RES OTO, V10, P23, DOI 10.1007/s10162-008-0150-y
   O'Donoghue GM, 2000, LANCET, V356, P466, DOI 10.1016/S0140-6736(00)02555-1
   Quesnel AM, 2016, HEARING RES, V333, P225, DOI 10.1016/j.heares.2015.08.018
   Reiss LAJ, 2012, J ACOUST SOC AM, V132, P3406, DOI 10.1121/1.4757735
   Sim JH, 2007, J MECH MATER STRUCT, V2, P1515, DOI 10.2140/jomms.2007.2.1515
   Skarzynski H, 2007, INT J PEDIATR OTORHI, V71, P1407, DOI 10.1016/j.ijporl.2007.05.014
   Soda-Merhy A, 2008, OTOLARYNG HEAD NECK, V139, P399, DOI 10.1016/j.otohns.2008.06.006
   Suhling MC, 2016, OTOL NEUROTOL, V37, P1006, DOI 10.1097/MAO.0000000000001110
   Svirsky MA, 2000, PSYCHOL SCI, V11, P153, DOI 10.1111/1467-9280.00231
   Usami SI, 2014, ACTA OTO-LARYNGOL, V134, P717, DOI 10.3109/00016489.2014.894254
   Van Abel KM, 2015, OTOL NEUROTOL, V36, P416, DOI 10.1097/MAO.0000000000000703
   Verschuur Carl, 2016, Cochlear Implants Int, V17 Suppl 1, P62, DOI 10.1080/14670100.2016.1152007
   Wiley S, 2005, INT J PEDIATR OTORHI, V69, P791, DOI 10.1016/j.ijporl.2005.01.011
   WILSON BS, 1991, NATURE, V352, P236, DOI 10.1038/352236a0
   Zeitler DM, 2019, INT J PEDIATR OTORHI, V118, P128, DOI 10.1016/j.ijporl.2018.12.037
NR 38
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9294
EI 1558-2531
J9 IEEE T BIO-MED ENG
JI IEEE Trans. Biomed. Eng.
PD NOV
PY 2020
VL 67
IS 11
BP 3253
EP 3261
DI 10.1109/TBME.2020.2981863
PG 9
WC Engineering, Biomedical
SC Engineering
GA OI7ZQ
UT WOS:000583492300024
PM 32191879
DA 2021-02-24
ER

PT J
AU Tezel-Bayraktaroglu, O
   Bayraktaroglu, Z
   Demirtas-Tatlidede, A
   Demiralp, T
   Oge, AE
AF Tezel-Bayraktaroglu, Oyku
   Bayraktaroglu, Zubeyir
   Demirtas-Tatlidede, Asli
   Demiralp, Tamer
   Oge, A. Emre
TI Neuronavigated rTMS inhibition of right pars triangularis anterior in
   stuttering: Differential effects on reading and speaking
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Stuttering; Repetitive Transcranial Magnetic Stimulation; Broca's
   homologue; Inferior Frontal Gyrus; Pars Triangularis; Pars Opercularis;
   Percentage of Syllables Stuttered; Speech Fluency; Reading; Speaking
ID TRANSCRANIAL MAGNETIC STIMULATION; POSITRON-EMISSION-TOMOGRAPHY;
   CEREBRAL BLOOD-FLOW; SPEECH-PERCEPTION; BRAIN-STIMULATION; BASIC
   PRINCIPLES; RIGHT-HEMISPHERE; APHASIC PATIENT; ACTIVATION; CORTEX
AB Functional neuroimaging studies show an overactivation of speech and language related homologous areas of the right hemisphere in persons who stutter. In this study, we inhibited Broca's homologues using 1 Hz repetitive transcranial magnetic stimulation (rTMS) and assessed its effects on stuttering severity. The investigated cortical areas included pars opercularis (BA44), anterior and posterior pars triangularis (BA45), mouth area on the primary motor cortex (BA4). We collected reading and speaking samples before and after rTMS sessions and calculated the percentage of syllables stuttered. Only right anterior pars triangularis stimulation induced significant changes in speech fluency. Notably, the effects were differential for reading and speaking conditions. Overall, our results provide supportive evidence that right anterior BA45 may be a critical region for stuttering. The observed differential effects following the inhibition of right anterior BA45 merits further study of contributions of this region on different language domains in persons who stutter.
C1 [Tezel-Bayraktaroglu, Oyku] Lali Speech & Language Disorders Ctr, TR-34365 Istanbul, Turkey.
   [Demiralp, Tamer] Istanbul Univ, Hulusi Behcet Life Sci Res Lab, Neuroimaging Unit, TR-34093 Istanbul, Turkey.
   [Demiralp, Tamer] Istanbul Univ, Istanbul Fac Med, Dept Physiol, TR-34093 Istanbul, Turkey.
   [Demirtas-Tatlidede, Asli; Oge, A. Emre] Istanbul Univ, Istanbul Fac Med, Dept Neurol, TR-34093 Istanbul, Turkey.
   [Bayraktaroglu, Zubeyir] Istanbul Medipol Univ, Int Sch Med, Dept Physiol, TR-34815 Istanbul, Turkey.
   [Bayraktaroglu, Zubeyir] Istanbul Medipol Univ, Res Inst Hlth Sci & Technol SABITA, Restorat & Regenerat Med Res Ctr REMER, Funct Imaging & Cognit Affect Neurosci Lab fINCAN, TR-34810 Istanbul, Turkey.
   [Demirtas-Tatlidede, Asli] Bahcesehir Univ, Sch Med, Dept Neurol, TR-34734 Istanbul, Turkey.
RP Tezel-Bayraktaroglu, O (corresponding author), Lali Dil Konusma Bozukluklari Merkezi, Ahmet Fetgari Sok 35-4, TR-34365 Istanbul, Turkey.
EM oyku.tezel@lali.com.tr
FU Scientific Research Projects Coordination Unit of Istanbul
   UniversityIstanbul University [324-22913/2012, 1567-42362/2014]
FX This work was supported by the Scientific Research Projects Coordination
   Unit of Istanbul University [grant numbers 324-22913/2012 and
   1567-42362/2014].
CR Abo M, 2004, NEUROREPORT, V15, P1891, DOI 10.1097/00001756-200408260-00011
   Ackermann H, 2008, TRENDS NEUROSCI, V31, P265, DOI 10.1016/j.tins.2008.02.011
   Ambrose NG., 2004, CONT ISSUE COMMUN SC, V31, P80, DOI [10.1044/cicsd_31_S_80, DOI 10.1044/CICSD_31_S_80]
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   [Anonymous], 2020, JAM VERS 1 2 COMP SO
   Beal DS, 2007, NEUROREPORT, V18, P1257, DOI 10.1097/WNR.0b013e3282202c4d
   Beal DS, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00089
   Biermann-Ruben K, 2005, NEUROIMAGE, V25, P793, DOI 10.1016/j.neuroimage.2004.11.024
   Bloodstein O., 1995, HDB STUTTERING
   Bozkurt B, 2016, WORLD NEUROSURG, V95, P99, DOI 10.1016/j.wneu.2016.07.072
   Braun A. R., 1997, BRAIN, P120
   Breier JI, 2004, NEUROIMAGE, V23, P1308, DOI 10.1016/j.neuroimage.2004.07.069
   Buchel C, 2004, PLOS BIOL, V2, P159, DOI 10.1371/journal.pbio.0020046
   Busan P, 2017, CLIN NEUROPHYSIOL, V128, P952, DOI 10.1016/j.clinph.2017.03.039
   Cai S, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00054
   Catani M, 2012, CORTEX, V48, P273, DOI 10.1016/j.cortex.2011.12.001
   Chang SE, 2008, NEUROIMAGE, V39, P1333, DOI 10.1016/j.neuroimage.2007.09.067
   Chenausky K, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00175
   Chesters J, 2018, BRAIN, V141, DOI 10.1093/brain/awy011
   Constantino CD, 2016, J COMMUN DISORD, V60, P39, DOI 10.1016/j.jcomdis.2016.02.001
   CORDES AK, 1995, J SPEECH HEAR RES, V38, P33, DOI 10.1044/jshr.3801.33
   Crosson Bruce, 2008, Seminars in Speech and Language, V29, P188, DOI 10.1055/s-0028-1082883
   De Nil LF, 2003, J FLUENCY DISORD, V28, P357, DOI 10.1016/j.jfludis.2003.07.002
   De Nil LF, 2001, NEUROSCI LETT, V302, P77, DOI 10.1016/S0304-3940(01)01671-8
   De Nil LF, 2000, J SPEECH LANG HEAR R, V43, P1038, DOI 10.1044/jslhr.4304.1038
   Devlin JT, 2003, J COGNITIVE NEUROSCI, V15, P71, DOI 10.1162/089892903321107837
   Duffau H, 2001, NEUROREPORT, V12, P2159, DOI 10.1097/00001756-200107200-00023
   Eisenegger C, 2008, NEUROIMAGE, V42, P379, DOI 10.1016/j.neuroimage.2008.04.172
   Fox PT, 1996, NATURE, V382, P158, DOI 10.1038/382158a0
   Fridriksson J, 2013, BRAIN, V136, P3451, DOI 10.1093/brain/awt267
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   Friederici AD, 2009, TRENDS COGN SCI, V13, P175, DOI 10.1016/j.tics.2009.01.001
   Gold BT, 2000, BRAIN LANG, V73, P456, DOI 10.1006/brln.2000.2317
   Gold BT, 2002, NEURON, V35, P803, DOI 10.1016/S0896-6273(02)00800-0
   Gough PM, 2005, J NEUROSCI, V25, P8010, DOI 10.1523/JNEUROSCI.2307-05.2005
   Hartwigsen G, 2015, BRAIN LANG, V148, P81, DOI 10.1016/j.bandl.2014.10.007
   Hartwigsen G, 2010, P NATL ACAD SCI USA, V107, P16494, DOI 10.1073/pnas.1008121107
   Harvey DY, 2019, BRAIN LANG, V192, P25, DOI 10.1016/j.bandl.2019.02.005
   Jancke L, 2004, BMC NEUROL, V4, DOI 10.1186/1471-2377-4-23
   Kell CA, 2009, BRAIN, V132, P2747, DOI 10.1093/brain/awp185
   Kemerdere R, 2016, J NEUROL, V263, P157, DOI 10.1007/s00415-015-7949-3
   Klomjai W, 2015, ANN PHYS REHABIL MED, V58, P208, DOI 10.1016/j.rehab.2015.05.005
   Koenraads SPC, 2019, BRAIN LANG, V194, P121, DOI 10.1016/j.bandl.2019.04.008
   Le Guilloux J., 2018, CLIN MED REP, V2, P1, DOI [10.15761/CMR.1000107., DOI 10.15761/CMR.1000107]
   Leger A, 2002, NEUROIMAGE, V17, P174, DOI 10.1006/nimg.2002.1238
   Martin PI, 2009, BRAIN LANG, V111, P20, DOI 10.1016/j.bandl.2009.07.007
   Min YS, 2016, SCI REP-UK, V6, DOI 10.1038/srep36058
   Miura K, 1999, J NEUROL, V246, P939, DOI 10.1007/s004150050486
   Naeser MA, 2005, BRAIN LANG, V93, P95, DOI 10.1016/j.bandl.2004.08.004
   Naeser MA, 2011, BRAIN LANG, V119, P206, DOI 10.1016/j.bandl.2011.07.005
   Neef NE, 2015, CURR NEUROL NEUROSCI, V15, DOI 10.1007/s11910-015-0579-4
   Neumann K, 2003, J FLUENCY DISORD, V28, P381, DOI 10.1016/j.jfludis.2003.07.003
   Nixon P, 2004, J COGNITIVE NEUROSCI, V16, P289, DOI 10.1162/089892904322984571
   Norise C, 2017, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00675
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Orton ST, 1927, ARCH NEURO PSYCHIATR, V18, P671, DOI 10.1001/archneurpsyc.1927.02210050003001
   Peck KK, 2004, STROKE, V35, P554, DOI 10.1161/01.STR.0000110983.50753.9D
   Poldrack RA, 1999, NEUROIMAGE, V10, P15, DOI 10.1006/nimg.1999.0441
   POOL KD, 1991, ARCH NEUROL-CHICAGO, V48, P509, DOI 10.1001/archneur.1991.00530170069022
   Preibisch C, 2003, NEUROIMAGE, V20, P1356, DOI 10.1016/S1053-8119(03)00376-8
   Robertson EM, 2003, J COGNITIVE NEUROSCI, V15, P948, DOI 10.1162/089892903770007344
   ROSSINI PM, 1994, ELECTROEN CLIN NEURO, V91, P79, DOI 10.1016/0013-4694(94)90029-9
   Sandak R, 2000, LANCET, V356, P445, DOI 10.1016/S0140-6736(00)02547-2
   Seghier M, 2001, NEUROREPORT, V12, P2785, DOI 10.1097/00001756-200109170-00007
   Sommer M, 2002, LANCET, V360, P380, DOI 10.1016/S0140-6736(02)09610-1
   Starkweather C.W., 1987, FLUENCY STUTTERING
   Travis L., 1931, SPEECH PATHOLOGY
   Usler E, 2015, J NEURODEV DISORD, V7, DOI 10.1186/1866-1955-7-4
   Vanhoutte S, 2016, NEUROPSYCHOLOGIA, V86, P93, DOI 10.1016/j.neuropsychologia.2016.04.018
   Vigneau M, 2006, NEUROIMAGE, V30, P1414, DOI 10.1016/j.neuroimage.2005.11.002
   Weiduschat N, 2009, BRAIN STIMUL, V2, P93, DOI 10.1016/j.brs.2008.09.005
   WEILLER C, 1995, ANN NEUROL, V37, P723, DOI 10.1002/ana.410370605
   WOOD F, 1980, BRAIN LANG, V9, P141, DOI 10.1016/0093-934X(80)90079-6
   Yada Y, 2019, PSYCHIAT CLIN NEUROS, V73, P63, DOI 10.1111/pcn.12796
   Yairi E, 2013, J FLUENCY DISORD, V38, P66, DOI 10.1016/j.jfludis.2012.11.002
NR 75
TC 0
Z9 0
U1 4
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD NOV
PY 2020
VL 210
AR 104862
DI 10.1016/j.bandl.2020.104862
PG 7
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA OH2JJ
UT WOS:000582395300005
PM 32979643
DA 2021-02-24
ER

PT J
AU Wang, LC
   Yang, HM
AF Wang, Li-Chih
   Yang, Hsien-Ming
TI The Roles of Various Forms of Attention in Temporal Processing Deficits
   in Chinese Children With and Without Dyslexia
SO LEARNING DISABILITY QUARTERLY
LA English
DT Article
DE reading; learning disabilities; identification; thinking; cognition
ID DEFICIT/HYPERACTIVITY DISORDER; SPEECH-PERCEPTION; DEVELOPMENTAL
   DYSLEXIA; PHONOLOGICAL AWARENESS; SUSTAINED ATTENTION; READING
   DEVELOPMENT; WORKING-MEMORY; PERFORMANCE; ABILITIES; SEARCH
AB This study examined the extent to which Chinese children with dyslexia show temporal processing deficits in addition to deficits in various forms of attention. In total, 104 Chinese children in primary school (Grades 3-6) were recruited in Taiwan. Half of the children were identified as having dyslexia, and the other half were typically developing children who were matched by gender, IQ, and age with the children with dyslexia. Our results indicated that Chinese children with dyslexia performed significantly worse on tasks of temporal processing, selective attention, and switching attention. Furthermore, both visual and auditory temporal processing, in addition to various attention types, could be significant distinguishing predictors between the two groups. Moreover, we found that visual temporal processing, but not auditory temporal processing, significantly contributed to Chinese character reading. This study was among the first to confirm the unique role of visual temporal processing in Chinese character reading.
C1 [Wang, Li-Chih] Educ Univ Hong Kong, Hong Kong, Peoples R China.
   [Yang, Hsien-Ming] Natl Univ Tainan, Tainan, Taiwan.
RP Wang, LC (corresponding author), Educ Univ Hong Kong, Dept Special Educ & Counselling, 10 Ping Rd, Hong Kong, Peoples R China.
EM wanglca@eduhk.hk
RI WANG, Li-Chih/H-8173-2019
OI WANG, Li-Chih/0000-0002-4011-7305
CR Alloway TP, 2014, INT J EDUC RES, V67, P11, DOI 10.1016/j.ijer.2014.04.001
   Anderson P, 2002, CHILD NEUROPSYCHOL, V8, P71, DOI 10.1076/chin.8.2.71.8724
   Birch S, 2004, J LEARN DISABIL-US, V37, P389, DOI 10.1177/00222194040370050301
   Boets B, 2007, NEUROPSYCHOLOGIA, V45, P1608, DOI 10.1016/j.neuropsychologia.2007.01.009
   Booth JR, 2000, SCI STUD READ, V4, P101, DOI DOI 10.1207/S1532799XSSR0402_02
   Bradley RH, 2002, ANNU REV PSYCHOL, V53, P371, DOI 10.1146/annurev.psych.53.100901.135233
   Breier JI, 2002, J EXP CHILD PSYCHOL, V82, P226, DOI 10.1016/S0022-0965(02)00005-X
   Bretherton L, 2003, J EXP CHILD PSYCHOL, V84, P218, DOI 10.1016/S0022-0965(03)00023-7
   Cain K, 2004, J EDUC PSYCHOL, V96, P31, DOI 10.1037/0022-0663.96.1.31
   CASTLES A, 1993, COGNITION, V47, P149, DOI 10.1016/0010-0277(93)90003-E
   Chan DW, 2007, EDUC STUD, V33, P249, DOI 10.1080/03055690601068535
   Chen J. H., 2006, RAVENS PROGR MATRICE
   Chung KKH, 2008, ANN DYSLEXIA, V58, P15, DOI 10.1007/s11881-008-0015-4
   COHEN J, 1994, ANN DYSLEXIA, V44, P165, DOI 10.1007/BF02648160
   Ding Y, 2016, DYSLEXIA, V22, P362, DOI 10.1002/dys.1541
   Eimer M, 2015, CONSCIOUS COGN, V35, P274, DOI 10.1016/j.concog.2015.01.001
   Farmer ME, 1995, PSYCHON B REV, V2, P460, DOI 10.3758/BF03210983
   Fostick L, 2017, J SPEECH LANG HEAR R, V60, P2124, DOI 10.1044/2017_JSLHR-H-16-0074
   Habib M, 2000, BRAIN, V123, P2373, DOI 10.1093/brain/123.12.2373
   Hackman DA, 2009, TRENDS COGN SCI, V13, P65, DOI 10.1016/j.tics.2008.11.003
   Hari R, 2001, BRAIN, V124, P1373, DOI 10.1093/brain/124.7.1373
   Ho C.S.H., 2003, READING DEV CHINESE, P51
   Ho CSH, 1997, READ RES QUART, V32, P276, DOI 10.1598/RRQ.32.3.3
   Ho CSH, 2004, COGNITION, V91, P43, DOI 10.1016/S0010-0277(03)00163-X
   Ho CSH, 2003, J LIT RES, V35, P849, DOI 10.1207/s15548430jlr3503_3
   Ho CSH, 2002, DEV PSYCHOL, V38, P543, DOI 10.1037//0012-1649.38.4.543
   Huang H. S., 2001, CHINESE CHARACTER RE
   Hung L. Y., 2006, PHONETIC RADICAL TES
   Hung L. Y., 2006, SEMANTIC RADICAL TES
   International Dyslexia Association, 2002, DEF DYSL
   JASKOWSKI P, 1993, PERCEPTION, V22, P681, DOI 10.1068/p220681
   JUST MA, 1980, PSYCHOL REV, V87, P329, DOI 10.1037/0033-295X.87.4.329
   Kershner JR, 2016, J LEARN DISABIL-US, V49, P282, DOI 10.1177/0022219414547222
   Kieffer MJ, 2013, READ RES QUART, V48, P333, DOI 10.1002/rrq.54
   Klein R. M., 2002, READING WRITING INTE, V15, P207, DOI [10.1023/A:1013828723016, DOI 10.1023/A:1013828723016]
   Krause MB, 2015, DYSLEXIA, V21, P285, DOI 10.1002/dys.1505
   Kuwabara M, 2012, J EXP CHILD PSYCHOL, V113, P20, DOI 10.1016/j.jecp.2012.04.009
   Lallier M, 2010, NEUROPSYCHOLOGIA, V48, P4125, DOI 10.1016/j.neuropsychologia.2010.09.027
   LAM CM, 1991, REM SPEC EDUC, V12, P40, DOI 10.1177/074193259101200208
   Landerl K, 2010, LEARN INDIVID DIFFER, V20, P393, DOI 10.1016/j.lindif.2010.03.008
   LEE JR, 2006, LANGUAGE LINGUISTICS, V7, P573
   Lin D, 2010, PSYCHOL SCI, V21, P1117, DOI 10.1177/0956797610375447
   Liu D, 2016, READ WRIT, V29, P1435, DOI 10.1007/s11145-016-9644-x
   Liu D, 2015, SCI STUD READ, V19, P307, DOI 10.1080/10888438.2015.1030749
   Liu PD, 2010, J EDUC PSYCHOL, V102, P62, DOI 10.1037/a0016933
   Lum JAG, 2007, BRAIN COGNITION, V63, P287, DOI 10.1016/j.bandc.2006.09.010
   Manly T, 2001, J CHILD PSYCHOL PSYC, V42, P1065, DOI 10.1111/1469-7610.00806
   Manly T., 1998, TEST EVERYDAY ATTENT
   McBride-Chang C, 2004, J EXP CHILD PSYCHOL, V89, P93, DOI 10.1016/j.jecp.2004.05.001
   Meng XZ, 2005, DYSLEXIA, V11, P292, DOI 10.1002/dys.309
   Moll K, 2016, J LEARN DISABIL-US, V49, P272, DOI 10.1177/0022219414547221
   Powell D, 2007, J EXP CHILD PSYCHOL, V98, P46, DOI 10.1016/j.jecp.2007.04.003
   Ramus F, 2003, CURR OPIN NEUROBIOL, V13, P212, DOI 10.1016/S0959-4388(03)00035-7
   Sawada M, 2010, PSYCHIAT CLIN NEUROS, V64, P491, DOI 10.1111/j.1440-1819.2010.02134.x
   SCHNEIDER W, 1977, PSYCHOL REV, V84, P1, DOI 10.1037/0033-295X.84.1.1
   Schulte-Korne G, 1999, EUR CHILD ADOLES PSY, V8, P28
   Shinn-Cunningham BG, 2008, TRENDS COGN SCI, V12, P182, DOI 10.1016/j.tics.2008.02.003
   Skottun BC, 2006, CLIN EXP OPTOM, V89, P241, DOI 10.1111/j.1444-0938.2006.00052.x
   Sterr AM, 2004, LEARN INDIVID DIFFER, V14, P125, DOI 10.1016/j.lindif.2003.10.001
   Strehlow U, 2006, EUR CHILD ADOLES PSY, V15, P19, DOI 10.1007/s00787-006-0500-4
   TALLAL P, 1984, APPL PSYCHOLINGUIST, V5, P167, DOI 10.1017/S0142716400004963
   Tavassoli NT, 1999, J CONSUM RES, V26, P170, DOI 10.1086/209558
   Tzeng S. J., 2006, PHONOLOGICAL AWARENE
   Tzeng S. J., 2011, RAPID AUTOMATIZED NA
   Wang LC, 2018, READ WRIT, V31, P1645, DOI 10.1007/s11145-018-9857-2
   Wang LC, 2018, DYSLEXIA, V24, P276, DOI 10.1002/dys.1579
   Wang LC, 2018, J LEARN DISABIL-US, V51, P302, DOI 10.1177/0022219416680798
   Wolf M, 2000, J LEARN DISABIL-US, V33, P387, DOI 10.1177/002221940003300409
   Yin WG, 2003, ANN DYSLEXIA, V53, P255, DOI 10.1007/s11881-003-0012-6
   Zhang J, 2014, DEV PSYCHOL, V50, P1001, DOI 10.1037/a0035086
   Zhao J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21578-5
NR 71
TC 0
Z9 0
U1 11
U2 11
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0731-9487
EI 2168-376X
J9 LEARN DISABILITY Q
JI Learn. Disabil. Q.
PD NOV
PY 2020
VL 43
IS 4
BP 241
EP 253
DI 10.1177/0731948719856300
PG 13
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA NX8HR
UT WOS:000575945600005
DA 2021-02-24
ER

PT J
AU Ullas, S
   Hausfeld, L
   Cutler, A
   Eisner, F
   Formisano, E
AF Ullas, Shruti
   Hausfeld, Lars
   Cutler, Anne
   Eisner, Frank
   Formisano, Elia
TI Neural Correlates of Phonetic Adaptation as Induced by Lexical and
   Audiovisual Context
SO JOURNAL OF COGNITIVE NEUROSCIENCE
LA English
DT Article
ID AUDITORY-CORTEX; PERCEPTUAL ADAPTATION; SPEECH-PERCEPTION; HEARING LIPS;
   BRAIN; RECALIBRATION; REPRESENTATION; ORGANIZATION; INFORMATION;
   ACTIVATION
AB When speech perception is difficult, one way listeners adjust is by reconfiguring phoneme category boundaries, drawing on contextual information. Both lexical knowledge and lipreading cues are used in this way, but it remains unknown whether these two differing forms of perceptual learning are similar at a neural level. This study compared phoneme boundary adjustments driven by lexical or audiovisual cues, using ultra-high-field 7-T fMRI. During imaging, participants heard exposure stimuli and test stimuli. Exposure stimuli for lexical retuning were audio recordings of words, and those for audiovisual recalibration were audio-video recordings of lip movements during utterances of pseudowords. Test stimuli were ambiguous phonetic strings presented without context, and listeners reported what phoneme they heard. Reports reflected phoneme biases in preceding exposure blocks (e.g., more reported /p/ after /p/-biased exposure). Analysis of corresponding brain responses indicated that both forms of cue use were associated with a network of activity across the temporal cortex, plus parietal, insula, and motor areas. Audiovisual recalibration also elicited significant occipital cortex activity despite the lack of visual stimuli. Activity levels in several ROIs also covaried with strength of audiovisual recalibration, with greater activity accompanying larger recalibration shifts. Similar activation patterns appeared for lexical retuning, but here, no significant ROIs were identified. Audiovisual and lexical forms of perceptual learning thus induce largely similar brain response patterns. However, audiovisual recalibration involves additional visual cortex contributions, suggesting that previously acquired visual information (on lip movements) is retrieved and deployed to disambiguate auditory perception.
C1 [Ullas, Shruti; Hausfeld, Lars; Formisano, Elia] Maastricht Univ, Maastricht, Netherlands.
   [Ullas, Shruti; Hausfeld, Lars; Formisano, Elia] Maastricht Brain Imaging Ctr, Maastricht, Netherlands.
   [Cutler, Anne] Western Sydney Univ, MARCS Inst, Penrith, NSW, Australia.
   [Eisner, Frank] Radboud Univ Nijmegen, Nijmegen, Netherlands.
   [Formisano, Elia] Maastricht Ctr Syst Biol, Maastricht, Netherlands.
RP Ullas, S (corresponding author), Maastricht Univ, Fac Psychol & Neurosci, Dept Cognit Neurosci, NL-6200 MD Maastricht, Netherlands.
EM shruti.ullas@maastrichtuniversity.nl
OI Formisano, Elia/0000-0001-5008-2460; Hausfeld, Lars/0000-0002-4396-8201;
   Ullas, Shruti/0000-0002-0056-651X
FU Maastricht University; Netherlands Organization for Scientific Research
   (NWO) gravitation program Language in InteractionNetherlands
   Organization for Scientific Research (NWO); NWO VENI grant [451-17-033]
FX This project was supported by Maastricht University, the Netherlands
   Organization for Scientific Research (NWO) gravitation program Language
   in Interaction, and a NWO VENI grant (451-17-033 to L. H.).
CR Beauchamp MS, 2005, CURR OPIN NEUROBIOL, V15, P145, DOI 10.1016/j.conb.2005.03.011
   Bernstein LE, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00386
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   Binder JR, 1997, J NEUROSCI, V17, P353
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bonte M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05356-3
   Buchsbaum BR, 2001, COGNITIVE SCI, V25, P663, DOI 10.1207/s15516709cog2505_2
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Dick AS, 2010, BRAIN LANG, V114, P101, DOI 10.1016/j.bandl.2009.08.005
   Duyck W, 2004, BEHAV RES METH INS C, V36, P488, DOI 10.3758/BF03195595
   Eisner F, 2006, J ACOUST SOC AM, V119, P1950, DOI 10.1121/1.2178721
   Erb J, 2013, J NEUROSCI, V33, P10688, DOI 10.1523/JNEUROSCI.4596-12.2013
   Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Goebel R, 2006, HUM BRAIN MAPP, V27, P392, DOI 10.1002/hbm.20249
   Guediche S, 2014, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00126
   Guediche S, 2013, J COGNITIVE NEUROSCI, V25, P706, DOI 10.1162/jocn_a_00351
   Hagoort P, 2005, TRENDS COGN SCI, V9, P416, DOI 10.1016/j.tics.2005.07.004
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Jancke L, 2002, NEUROIMAGE, V15, P733, DOI 10.1006/nimg.2001.1027
   Jesse A, 2010, ATTEN PERCEPT PSYCHO, V72, P209, DOI 10.3758/APP.72.1.209
   Jones JA, 2003, NEUROREPORT, V14, P1129, DOI 10.1097/00001756-200306110-00006
   Kilian-Hutten N, 2011, J NEUROSCI, V31, P1715, DOI 10.1523/JNEUROSCI.4572-10.2011
   Kilian-Hutten N, 2011, NEUROIMAGE, V57, P1601, DOI 10.1016/j.neuroimage.2011.05.043
   Kosslyn SM, 2001, NAT REV NEUROSCI, V2, P635, DOI 10.1038/35090055
   Leonard MK, 2014, TRENDS COGN SCI, V18, P472, DOI 10.1016/j.tics.2014.05.001
   Liebenthal E, 2005, CEREB CORTEX, V15, P1621, DOI 10.1093/cercor/bhi040
   Liebenthal E, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00069
   Luttke CS, 2016, SCI REP-UK, V6, DOI 10.1038/srep32891
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mesgarani N, 2008, J ACOUST SOC AM, V123, P899, DOI 10.1121/1.2816572
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Mitterer H, 2013, COGNITION, V129, P356, DOI 10.1016/j.cognition.2013.07.011
   Myers EB, 2008, CEREB CORTEX, V18, P278, DOI 10.1093/cercor/bhm053
   Myers EB, 2014, J MEM LANG, V76, P80, DOI 10.1016/j.jml.2014.06.007
   Newman SD, 2001, HUM BRAIN MAPP, V14, P39, DOI 10.1002/hbm.1040
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Obleser J, 2009, TRENDS COGN SCI, V13, P14, DOI 10.1016/j.tics.2008.09.005
   Oh A, 2014, BRAIN LANG, V135, P96, DOI 10.1016/j.bandl.2014.06.003
   Ojanen V, 2005, NEUROIMAGE, V25, P333, DOI 10.1016/j.neuroimage.2004.12.001
   Pearson J, 2019, NAT REV NEUROSCI, V20, P624, DOI 10.1038/s41583-019-0202-9
   Poldrack RA, 1999, NEUROIMAGE, V10, P15, DOI 10.1006/nimg.1999.0441
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rutten S, 2019, NAT HUM BEHAV, V3, P1125, DOI 10.1038/s41562-019-0739-7
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   Sharp DJ, 2005, BRAIN LANG, V92, P309, DOI 10.1016/j.bandl.2004.07.002
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Sparing R, 2002, BRAIN RES, V938, P92, DOI 10.1016/S0006-8993(02)02478-2
   Talairach J, 1988, COPLANAR STEREOTAXIC
   Ullas S, 2020, PSYCHON B REV, V27, P707, DOI 10.3758/s13423-020-01728-5
   Ullas S, 2020, ATTEN PERCEPT PSYCHO, V82, P2018, DOI 10.3758/s13414-019-01961-8
   van der Zande P, 2014, J PHONETICS, V43, P38, DOI 10.1016/j.wocn.2014.01.003
   van Linden S, 2007, J EXP PSYCHOL HUMAN, V33, P1483, DOI 10.1037/0096-1523.33.6.1483
   Vroomen J, 2004, SPEECH COMMUN, V44, P55, DOI 10.1016/j.specom.2004.03.009
   Yi HG, 2019, NEURON, V102, P1096, DOI 10.1016/j.neuron.2019.04.023
   ZATORRE RJ, 1992, SCIENCE, V256, P846, DOI 10.1126/science.1589767
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
NR 60
TC 0
Z9 0
U1 3
U2 3
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0898-929X
EI 1530-8898
J9 J COGNITIVE NEUROSCI
JI J. Cogn. Neurosci.
PD NOV
PY 2020
VL 32
IS 11
BP 2145
EP 2158
DI 10.1162/jocn_a_01608
PG 14
WC Neurosciences; Psychology, Experimental
SC Neurosciences & Neurology; Psychology
GA NV2ON
UT WOS:000574168000008
PM 32662723
OA Green Published
DA 2021-02-24
ER

PT J
AU Kapadia, AM
   Perrachione, TK
AF Kapadia, Alexandra M.
   Perrachione, Tyler K.
TI Selecting among competing models of talker adaptation: Attention,
   cognition, and memory in speech processing efficiency
SO COGNITION
LA English
DT Article
DE Speech perception; Phonetic variability; Processing cost; Talker
   adaptation; Auditory streaming
ID SPOKEN WORD RECOGNITION; STIMULUS VARIABILITY; NORMALIZATION; CONTINUITY
AB Phonetic variability across talkers imposes additional processing costs during speech perception, often measured by performance decrements between single- and mixed-talker conditions. However, models differ in their predictions about whether accommodating greater phonetic variability (i.e., more talkers) imposes greater processing costs. We measured speech processing efficiency in a speeded word identification task, in which we manipulated the number of talkers (1, 2, 4, 8, or 16) listeners heard. Word identification was less efficient in every mixed-talker condition compared to the single-talker condition, but the magnitude of this performance decrement was not affected by the number of talkers. Furthermore, in a condition with uniform transition probabilities between two talkers, word identification was more efficient when the talker was the same as the prior trial compared to trials when the talker switched. These results support an auditory streaming model of talker adaptation, where processing costs associated with changing talkers result from attentional reorientation.
C1 [Kapadia, Alexandra M.; Perrachione, Tyler K.] Boston Univ, Dept Speech Language & Hearing Sci, 635 Commonwealth Ave, Boston, MA 02215 USA.
RP Perrachione, TK (corresponding author), Boston Univ, Dept Speech Language & Hearing Sci, 635 Commonwealth Ave, Boston, MA 02215 USA.
EM tkp@bu.edu
FU National Institute on Deafness and Other Communication Disorders (NIDCD)
   of the National Institutes of HealthUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute on Deafness & Other Communication Disorders (NIDCD) [R03
   DC014045, R01 DC004545, T32 DC013017]
FX We thank Yaminah Carter, Jessica Tin, Ja Young Choi, Sung-Joo Lim,
   Jayden Lee, Kamilah Harruna, Nicole Chen, Chinazo Otiono, Trista Lin,
   Grace Mecha, Maya Saupe, Amabel Antwi, and Michelle Njoroge. Portions of
   these results were presented at the 19th International Congress of
   Phonetic Sciences. This work was supported by the National Institute on
   Deafness and Other Communication Disorders (NIDCD) of the National
   Institutes of Health under awards R03 DC014045 (to TKP), R01 DC004545
   (to Gerald Kidd), and T32 DC013017.
CR Bent T, 2017, WIRES COGN SCI, V8, DOI 10.1002/wcs.1434
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P206, DOI 10.3758/BF03206883
   Bressler S, 2014, PSYCHOL RES-PSYCH FO, V78, P349, DOI 10.1007/s00426-014-0555-7
   Carter Y. D., 2019, P 19 INT C PHON SCI
   Choi JY, 2019, BRAIN LANG, V196, DOI 10.1016/j.bandl.2019.104655
   Choi JY, 2019, COGNITION, V192, DOI 10.1016/j.cognition.2019.05.019
   Choi JY, 2018, ATTEN PERCEPT PSYCHO, V80, P784, DOI 10.3758/s13414-017-1395-5
   Green KP, 1997, PERCEPT PSYCHOPHYS, V59, P675, DOI 10.3758/BF03206015
   Heald SLM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00035
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   JOHNSON K, 1990, J ACOUST SOC AM, V88, P642, DOI 10.1121/1.399767
   Johnson K, 2005, BLACKW HBK LINGUIST, P363, DOI 10.1002/9780470757024.ch15
   Kleinschmidt DF, 2019, LANG COGN NEUROSCI, V34, P43, DOI 10.1080/23273798.2018.1500698
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Lim S.-J., 2019, P 19 INT C PHON SCI
   Lim SJ, 2019, ATTEN PERCEPT PSYCHO, V81, P1167, DOI 10.3758/s13414-019-01684-w
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   Mehraei G, 2018, NEUROIMAGE, V179, P548, DOI 10.1016/j.neuroimage.2018.06.067
   Morton JR, 2015, J ACOUST SOC AM, V137, P1443, DOI 10.1121/1.4913456
   MULLENNIX JW, 1990, PERCEPT PSYCHOPHYS, V47, P379, DOI 10.3758/BF03210878
   Mullennix JW, 1999, PERCEPT MOTOR SKILL, V89, P447, DOI 10.2466/PMS.89.6.447-457
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Nusbaum H.C., 1997, TALKER VARIABILITY S, P109
   Nusbaum H. C., 1986, PATTERN RECOGN, V1, P113, DOI DOI 10.1016/B978-0-12-631403-8.50009-6
   Nusbaum HC, 1992, SPEECH PERCEPTION PR, P113
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Perrachione TK, 2016, NEURON, V92, P1383, DOI 10.1016/j.neuron.2016.11.020
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   Shinn-Cunningham BG, 2008, TRENDS COGN SCI, V12, P182, DOI 10.1016/j.tics.2008.02.003
   Sjerps MJ, 2011, NEUROPSYCHOLOGIA, V49, P3831, DOI 10.1016/j.neuropsychologia.2011.09.044
   Sjerps MJ, 2011, ATTEN PERCEPT PSYCHO, V73, P1195, DOI 10.3758/s13414-011-0096-8
   SOMMERS MS, 1994, J ACOUST SOC AM, V96, P1314, DOI 10.1121/1.411453
   Sommers MS, 1997, EAR HEARING, V18, P89, DOI 10.1097/00003446-199704000-00001
   Townsend J. T., 1978, COGNITIVE THEORY, V3, P200
   Uddin S, 2020, BRAIN LANG, V201, DOI 10.1016/j.bandl.2019.104722
   Winkler I, 2009, TRENDS COGN SCI, V13, P532, DOI 10.1016/j.tics.2009.09.003
   Wong PCM, 2004, J COGNITIVE NEUROSCI, V16, P1173, DOI 10.1162/0898929041920522
   Xie X, 2017, J MEM LANG, V97, P30, DOI 10.1016/j.jml.2017.07.005
   Zhang CC, 2016, J EXP PSYCHOL HUMAN, V42, P1252, DOI 10.1037/xhp0000216
NR 41
TC 0
Z9 0
U1 2
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD NOV
PY 2020
VL 204
AR 104393
DI 10.1016/j.cognition.2020.104393
PG 7
WC Psychology, Experimental
SC Psychology
GA NR8UR
UT WOS:000571837900001
PM 32688132
DA 2021-02-24
ER

PT J
AU Roettger, TB
   Rimland, K
AF Roettger, Timo B.
   Rimland, Kim
TI Listeners' adaptation to unreliable intonation is speaker-sensitive
SO COGNITION
LA English
DT Article
DE Prosody; Intonation; Speech adaptation; Mouse tracking; Rational
   analysis
ID PERCEPTUAL ADAPTATION; SPEECH-PERCEPTION; SPOKEN-LANGUAGE; PROSODY;
   ACCENT; COMPREHENSION; INFORMATION
AB Variable linguistic environments require the ability to quickly update expectations and behavior including speech comprehension. This adaptive capacity is key to understanding how listeners successfully recognize speaker intentions in light of the ubiquitous variability in speech. The present study investigates how listeners' real-time sentence comprehension adapts to speaker-specific prosodic variability. In two forced choice mouse tracking experiments, listeners had to identify a visual referent guided by pre-recorded instructions. When exposed to a speaker that uses unconventional pitch accent placement, listeners discard intonational information for that speaker, but keep using intonation to resolve the referential ambiguity for another speaker that places pitch accents conventionally. These results show for the first time that intonationally guided sentence comprehension adapts in a speaker-sensitive way. The study further provides valuable first insights into the temporal unfolding of this adaptation process. Listeners first attribute unconventional patterns to the context, thus discarding the informational value of intonation for both speakers. After sufficient evidence, however, listeners start attributing unexpected patterns to only the unconventional speaker. Materials, data, and scripts can be retrieved here: http://osf.io/fdpg4
C1 [Roettger, Timo B.] Univ Osnabruck, Inst Cognit Sci, Wachsbleiche 27,Bldg 50, D-49090 Osnabruck, Germany.
   [Rimland, Kim] Univ Cologne, IfL Phonet, Herbert Lewin Str 6, D-50931 Cologne, Germany.
RP Roettger, TB (corresponding author), Univ Osnabruck, Inst Cognit Sci, Wachsbleiche 27,Bldg 50, D-49090 Osnabruck, Germany.
EM timo.b.roettger@gmail.com; Kim@Rimland.de
FU "Zukunftskonzept" of the University of Cologne as part of the Excellence
   Initiative
FX Timo Roettger's work was supported by the "Zukunftskonzept" of the
   University of Cologne as part of the Excellence Initiative. We would
   like to thank Chigusa Kurumada, two anonymous reviewers, and the editor
   for their insightful comments and suggestions. All remaining errors are
   our own.
CR Anderson J., 1990, ADAPTIVE CHARACTER T
   Arnold JE, 2007, J EXP PSYCHOL LEARN, V33, P914, DOI 10.1037/0278-7393.33.5.914
   Baese-Berk MM, 2013, J ACOUST SOC AM, V133, pEL174, DOI 10.1121/1.4789864
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, PARSIMONIOUS MIXED M
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Baumann S., 2006, INTONATION GIVENNESS, V508
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Bolinger Dwight, 1989, INTONATION ITS USES
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Braun B, 2019, LANG SPEECH, V62, P751, DOI 10.1177/0023830918814279
   Brodeur MB, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010773
   Burkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   BuxoLugo A., 2019, ENCODING DECODING ME, DOI [10.31234/osf.io/9y7xj., DOI 10.31234/OSF.IO/9Y7XJ]
   Calhoun S., 2012, PROSODY AND MEANING, V25, P271
   Chater N, 1999, TRENDS COGN SCI, V3, P57, DOI 10.1016/S1364-6613(98)01273-X
   Chodroff E, 2017, J PHONETICS, V61, P30, DOI 10.1016/j.wocn.2017.01.001
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Clopper CG, 2011, J PHONETICS, V39, P237, DOI 10.1016/j.wocn.2011.02.006
   Cole J, 2016, LAB PHONOL, V7, DOI 10.5334/labphon.29
   Creel SC, 2008, COGNITION, V106, P633, DOI 10.1016/j.cognition.2007.03.013
   Cruttenden A., 1997, INTONATION
   Cutler A, 1997, LANG SPEECH, V40, P141, DOI 10.1177/002383099704000203
   Dahan D, 2002, J MEM LANG, V47, P292, DOI 10.1016/S0749-596X(02)00001-3
   Dahan D, 2015, WIRES COGN SCI, V6, P441, DOI 10.1002/wcs.1355
   Degen J, 2015, COGNITIVE SCI, V39, P667, DOI 10.1111/cogs.12171
   Fery C, 2008, J PHONETICS, V36, P680, DOI 10.1016/j.wocn.2008.05.001
   Fischer MH, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01315
   Frank MC, 2012, SCIENCE, V336, P998, DOI 10.1126/science.1218633
   Franke Michael, 2009, SIGNAL ACT GAME THEO
   Fuchs S., 2015, INDIVIDUAL DIFFERENC, P123, DOI DOI 10.3726/978-3-653-05777-5
   Gelman A, 2008, ANN APPL STAT, V2, P1360, DOI 10.1214/08-AOAS191
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Grice M, 2017, J PHONETICS, V64, P90, DOI 10.1016/j.wocn.2017.03.003
   Grodner D. J., 2011, PROCESSING ACQUISITI, P239, DOI DOI 10.7551/MITPRESS/9780262015127.003.0010
   Gussenhoven Carlos, 2004, PHONOLOGY TONE INTON
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Holliday NR, 2019, AM SPEECH, V94, P110, DOI 10.1215/00031283-7308038
   Idemaru K, 2011, J EXP PSYCHOL HUMAN, V37, P1939, DOI 10.1037/a0025641
   Ito K., 2004, P SPEECH PROS INT C
   Ito K, 2008, J MEM LANG, V58, P541, DOI 10.1016/j.jml.2007.06.013
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Kieslich P., 2019, HDB PROCESS TRACING
   Kieslich P. J., 2017, BEHAV RES METHODS, P1
   Kleinschmidt DF, 2018, TOP COGN SCI, V10, P818, DOI 10.1111/tops.12331
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Kurumada C., 2014, P COGNITIVE SCI SOC, V36
   Kurumada C, 2018, PSYCHON B REV, V25, P1153, DOI 10.3758/s13423-017-1332-6
   Kurumada C, 2014, COGNITION, V133, P335, DOI 10.1016/j.cognition.2014.05.017
   Ladd DR, 2008, CAMB STUD LINGUIST, V79, P1
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Liu LD, 2018, COGNITION, V174, P55, DOI 10.1016/j.cognition.2018.01.003
   Mathot S, 2012, BEHAV RES METHODS, V44, P314, DOI 10.3758/s13428-011-0168-7
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   Peppe S, 2000, LANG SPEECH, V43, P309, DOI 10.1177/00238309000430030501
   PIERREHUMBERT J, 1990, SYS DEV FDN, P271
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   R Core Team, 2019, R LANG ENV STAT COMP
   Reinisch E, 2014, J EXP PSYCHOL HUMAN, V40, P539, DOI 10.1037/a0034409
   Roessig S, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216859
   Roettger T. B., 2017, TONAL PLACEMENT TASH, V3
   Roettger TB, 2019, LANG COGN NEUROSCI, V34, P841, DOI 10.1080/23273798.2019.1587482
   Roettger TB, 2019, COGNITIVE SCI, V43, DOI 10.1111/cogs.12745
   Ryskin R., 2019, LANGUAGE COGNITION N, P1
   Schielzeth H, 2009, BEHAV ECOL, V20, P416, DOI 10.1093/beheco/arn145
   Schuster S, 2020, COGNITION, V203, DOI 10.1016/j.cognition.2020.104285
   Schweitzer K., 2011, THESIS
   Sumner M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01015
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   Tomlinson JM, 2017, LANG SPEECH, V60, P200, DOI 10.1177/0023830917716101
   Trude AM, 2012, LANG COGNITIVE PROC, V27, P979, DOI 10.1080/01690965.2011.597153
   Turnbull R, 2017, LANG COGN NEUROSCI, V32, P1017, DOI 10.1080/23273798.2017.1279341
   Warren P, 2016, UPTALK: THE PHENOMENON OF RISING INTONATION, P1, DOI 10.1017/CBO9781316403570
   Watson DG, 2008, COGNITIVE SCI, V32, P1232, DOI 10.1080/03640210802138755
   Weatherholtz K., 2016, OXFORD RES ENCY LING
   Weber A, 2006, LANG SPEECH, V49, P367, DOI 10.1177/00238309060490030301
   Yildirim I, 2016, J MEM LANG, V87, P128, DOI 10.1016/j.jml.2015.08.003
NR 78
TC 1
Z9 1
U1 3
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD NOV
PY 2020
VL 204
AR 104372
DI 10.1016/j.cognition.2020.104372
PG 10
WC Psychology, Experimental
SC Psychology
GA NR8UR
UT WOS:000571837900009
PM 32615469
DA 2021-02-24
ER

PT J
AU Louleli, N
   Hamalainen, JA
   Nieminen, L
   Parviainen, T
   Leppanen, PHT
AF Louleli, Natalia
   Hamalainen, Jarmo A.
   Nieminen, Lea
   Parviainen, Tiina
   Leppanen, Paavo H. T.
TI Dynamics of morphological processing in pre-school children with and
   without familial risk for dyslexia
SO JOURNAL OF NEUROLINGUISTICS
LA English
DT Article
DE Derivational morphology; Phonology; Pre-school children; Familial risk
   for developmental dyslexia; Magnetoencephalography; Reading acquisition
ID EARLY LANGUAGE-ACQUISITION; ATTENTION SPAN DEFICIT; DEVELOPMENTAL
   DYSLEXIA; READING DEVELOPMENT; BRAIN; PHONOLOGY; AWARENESS; SKILLS;
   VIOLATIONS; RESPONSES
AB Difficulties in phonological processing and speech perception are associated with developmental dyslexia, but there is considerable diversity across people with developmental dyslexia (e.g., dyslexics with and without phonological difficulties). Phonological and morphological awareness are both known to play an important role in reading acquisition. Problems in morpho-phonological information processing could arguably be associated with developmental dyslexia, especially for Finnish, which is a rich morphologically language. We used MEG to study the connection between morpho-phonology in the Finnish language and familial risk for developmental dyslexia. We measured event-related fields (ERFs) of 22 pre-school children without risk and 18 children with familial risk for developmental dyslexia during a morphological task. Pairs of sentences consisting of a verb and its derived noun with the derivational suffix/-jA/and pairs of sentences consisting of a pseudo-verb and its pseudo-noun ending with the same suffix were presented to the participants. The derived nouns were also divided into correctly and incorrectly derived forms. Incorrectly derived forms contained an incorrect morpho-phonological change in the last vowel before the derivational suffix/-jA/. Both typically developing children and children at-risk for developmental dyslexia were sensitive to the morphological information, both in the case of real words and pseudowords, as shown by the sensor level analysis and cluster-based permutation tests for the responses to the morphologically correct vs. incorrect contrast. The groups showed somewhat different response patterns to this contrast. However, no significant differences were found in the between-group differences. No significant differences emerged between typically developing children and children at-risk for developmental dyslexia neither for real words nor for pseudowords. Overall, these findings suggest that pre-school children with and without risk for developmental dyslexia are already sensitive to the processing of morpho-phonological information before entering school.
C1 [Louleli, Natalia; Hamalainen, Jarmo A.; Parviainen, Tiina; Leppanen, Paavo H. T.] Univ Jyvaskyla, Dept Psychol, Jyvaskyla, Finland.
   [Louleli, Natalia; Hamalainen, Jarmo A.; Parviainen, Tiina; Leppanen, Paavo H. T.] Univ Jyvaskyla, Ctr Interdisciplinary Brain Res, Jyvaskyla, Finland.
   [Nieminen, Lea] Univ Jyvaskyla, Ctr Appl Language Studies, Jyvaskyla, Finland.
RP Louleli, N (corresponding author), Univ Jyvaskyla, Dept Psychol, Jyvaskyla, Finland.
EM natalia.n.louleli@jyu.fi
FU European Union H2020 Marie-Sklodowska-Curie Actions (MSCA) ETN programme
   for "Understanding and predicting developmental language abilities and
   disorders in multilingual Europe" (PredictAble project) [641858]
FX This study was supported by the European Union H2020
   Marie-Sklodowska-Curie Actions (MSCA) ETN programme for "Understanding
   and predicting developmental language abilities and disorders in
   multilingual Europe" (PredictAble project, no. 641858).
CR Baillet S, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/972050
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bolte J, 2010, NEUROSCI LETT, V469, P107, DOI 10.1016/j.neulet.2009.11.054
   Boets B, 2013, SCIENCE, V342, P1251, DOI 10.1126/science.1244333
   Bosse ML, 2007, COGNITION, V104, P198, DOI 10.1016/j.cognition.2006.05.009
   Bozic M, 2007, J COGNITIVE NEUROSCI, V19, P1464, DOI 10.1162/jocn.2007.19.9.1464
   Brauer J, 2007, J COGNITIVE NEUROSCI, V19, P1609, DOI 10.1162/jocn.2007.19.10.1609
   Byrne B, 2006, J RES READ, V29, P33, DOI 10.1111/j.1467-9817.2006.00291.x
   Cantiani C, 2019, NEUROIMAGE-CLIN, V22, DOI 10.1016/j.nicl.2019.101778
   Cantiani C, 2016, DEV COGN NEUROS-NETH, V20, P23, DOI 10.1016/j.dcn.2016.03.002
   Cantiani C, 2015, DEV NEUROPSYCHOL, V40, P291, DOI 10.1080/87565641.2015.1072536
   Cantiani C, 2013, APPL PSYCHOLINGUIST, V34, P1135, DOI 10.1017/S0142716412000185
   Cantiani C, 2013, NEUROPSYCHOLOGIA, V51, P1595, DOI 10.1016/j.neuropsychologia.2013.04.009
   Carlisle J. F., 2003, READING PSYCHOL, V24, P291, DOI DOI 10.1080/02702710390227369
   Casalis S, 2004, ANN DYSLEXIA, V54, P114, DOI 10.1007/s11881-004-0006-z
   Casalis S, 2000, READ WRIT, V12, P303, DOI 10.1023/A:1008177205648
   Cavalli E, 2016, J COGNITIVE NEUROSCI, V28, P1228, DOI 10.1162/jocn_a_00959
   Chung KKH, 2010, DYSLEXIA, V16, P2, DOI 10.1002/dys.392
   Cunningham AJ, 2015, APPL PSYCHOLINGUIST, V36, P509, DOI 10.1017/S0142716413000295
   de Jong PF, 2003, J EDUC PSYCHOL, V95, P22, DOI 10.1037/0022-0663.95.1.22
   DENCKLA MB, 1976, BRAIN LANG, V3, P1, DOI 10.1016/0093-934X(76)90001-8
   Egan J., 2004, READING WRITING INTE, V17, P567, DOI DOI 10.1023/B:READ.0000044433.30864.23
   Fisher SE, 2002, NAT REV NEUROSCI, V3, P767, DOI 10.1038/nrn936
   Friederici AD, 2005, TRENDS COGN SCI, V9, P481, DOI 10.1016/j.tics.2005.08.008
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8
   Gaillard WD, 2003, HUM BRAIN MAPP, V18, P176, DOI 10.1002/hbm.10091
   Garces P, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122926
   Gold B. T., 2007, NEURAL CORRELATES MO
   Goswami U, 2002, ANN DYSLEXIA, V52, P141
   Guttorm T. K., 2005, BRAIN EVENT RELATED
   Guttorm TK, 2010, J LEARN DISABIL-US, V43, P391, DOI 10.1177/0022219409345005
   Hamalainen JA, 2013, J LEARN DISABIL-US, V46, P413, DOI 10.1177/0022219411436213
   Hanna J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00886
   Hauk O., 2006, TIME COURSE VISUAL W
   Helenius P, 2002, J NEUROSCI, V22, P2936, DOI 10.1523/JNEUROSCI.22-07-02936.2002
   Holland SK, 2001, NEUROIMAGE, V14, P837, DOI 10.1006/nimg.2001.0875
   Janssen U, 2006, J NEUROLINGUIST, V19, P466, DOI 10.1016/j.jneuroling.2006.04.002
   Joanisse MF, 2000, J EXP CHILD PSYCHOL, V77, P30, DOI 10.1006/jecp.1999.2553
   Kaan E, 2000, LANG COGNITIVE PROC, V15, P159, DOI 10.1080/016909600386084
   Karlsson F., 1982, SUOMEN KIELEN AANNE
   Kirby JR, 2012, READ WRIT, V25, P389, DOI 10.1007/s11145-010-9276-5
   Korkman M., 2007, NEPSY 2 CLIN INTERPR
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kuo LJ, 2006, EDUC PSYCHOL-US, V41, P161, DOI 10.1207/s15326985ep4103_3
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Lallier M., 2012, DYSLEXIA COMPREHENSI, P73, DOI DOI 10.5772/39042
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532
   Law J. M., 2016, DEV SCI
   Law JM, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12453
   Law JM, 2017, RES DEV DISABIL, V67, P47, DOI 10.1016/j.ridd.2017.05.003
   Leinonen A, 2008, BRAIN RES, V1218, P181, DOI 10.1016/j.brainres.2008.04.049
   Leminen A, 2013, CORTEX, V49, P2758, DOI 10.1016/j.cortex.2013.08.007
   Leminen A, 2010, NEUROREPORT, V21, P948, DOI 10.1097/WNR.0b013e32833e4b90
   Leppanen P. H. T., 2010, NEWBORN BRAIN EVENT
   Lobier M, 2012, CORTEX, V48, P768, DOI 10.1016/j.cortex.2011.09.003
   Lohvansuu K, 2018, NEUROPSYCHOLOGIA, V108, P6, DOI 10.1016/j.neuropsychologia.2017.11.018
   Lyytinen H, 2001, DEV NEUROPSYCHOL, V20, P535, DOI 10.1207/S15326942DN2002_5
   Lyytinen P, 2004, APPL PSYCHOLINGUIST, V25, P397, DOI 10.1017/S0142716404001183
   Maris E., 2007, NONPARAMETRIC STAT T
   Meinzer M, 2009, NEUROPSYCHOLOGIA, V47, P1964, DOI 10.1016/j.neuropsychologia.2009.03.008
   Molinaro N, 2008, BRAIN RES, V1228, P161, DOI 10.1016/j.brainres.2008.06.064
   Molinaro N, 2011, CORTEX, V47, P908, DOI 10.1016/j.cortex.2011.02.019
   Muller K, 2001, READ WRIT, V14, P757, DOI 10.1023/A:1012217704834
   Nagy W, 2006, J EDUC PSYCHOL, V98, P134, DOI 10.1037/0022-0663.98.1.134
   Nora A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171034
   Olson RK, 2014, SCI STUD READ, V18, P38, DOI 10.1080/10888438.2013.800521
   Papadopoulos TC, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01217
   Parviainen T, 2006, J NEUROSCI, V26, P6052, DOI 10.1523/JNEUROSCI.0673-06.2006
   Parviainen T, 2019, HUM BRAIN MAPP, V40, P2699, DOI 10.1002/hbm.24553
   Parviainen T, 2011, HUM BRAIN MAPP, V32, P2193, DOI 10.1002/hbm.21181
   Pennington BF, 2001, CHILD DEV, V72, P816, DOI 10.1111/1467-8624.00317
   Pennington BF, 2006, COGNITION, V101, P385, DOI 10.1016/j.cognition.2006.04.008
   Ponton C., 2000, MATURATION HUMAN CEN
   Pulvermuller F., 2006, TRACKING SPEECH COMP
   Puolakanaho A, 2007, J CHILD PSYCHOL PSYC, V48, P923, DOI 10.1111/j.1469-7610.2007.01763.x
   Puolakanaho A, 2008, J LEARN DISABIL-US, V41, P353, DOI 10.1177/0022219407311747
   Ramirez G, 2010, READ WRIT, V23, P337, DOI 10.1007/s11145-009-9203-9
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   Richardson U., 2010, DEVELOPMENTAL NEUROP, V23, P385, DOI [10.1207/S15326942DN2303, DOI 10.1207/S15326942DN2303]
   Rispens JE, 2006, DYSLEXIA, V12, P134, DOI 10.1002/dys.316
   Salmelin R., 2007, CLIN NEUROPHYSIOLOGY
   Sassenhagen J, 2019, PSYCHOPHYSIOLOGY, V56, DOI 10.1111/psyp.13335
   Shaywitz SE, 2005, BIOL PSYCHIAT, V57, P1301, DOI 10.1016/j.biopsych.2005.01.043
   Silva-Pereyra J, 2005, COGNITIVE BRAIN RES, V23, P247, DOI 10.1016/j.cogbrainres.2004.10.015
   Snowling M. J., 2016, ORAL LANGUAGE DEFICI
   Solomyak O, 2010, J COGNITIVE NEUROSCI, V22, P2042, DOI 10.1162/jocn.2009.21296
   Taulu S, 2005, J APPL PHYS, V97, DOI 10.1063/1.1935742
   Taulu S, 2006, PHYS MED BIOL, V51, P1759, DOI 10.1088/0031-9155/51/7/008
   Torppa M, 2007, ANN DYSLEXIA, V57, P3, DOI 10.1007/s11881-007-0003-0
   Valdois S, 2004, DYSLEXIA, V10, P339, DOI 10.1002/dys.284
   van Bergen E, 2011, DYSLEXIA, V17, P2, DOI 10.1002/dys.423
   van der Leij A., 2001, DYSLEXIA THEORY GOOD, P160
   van Zuijen TL, 2012, NEUROSCI LETT, V528, P31, DOI 10.1016/j.neulet.2012.08.058
   Vartiainen J, 2009, J NEUROSCI, V29, P9271, DOI 10.1523/JNEUROSCI.5860-08.2009
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   Wang M, 2009, APPL PSYCHOLINGUIST, V30, P291, DOI 10.1017/S0142716409090122
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
   Zweig E, 2009, LANG COGNITIVE PROC, V24, P412, DOI 10.1080/01690960802180420
NR 98
TC 0
Z9 0
U1 5
U2 5
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0911-6044
J9 J NEUROLINGUIST
JI J. Neurolinguist.
PD NOV
PY 2020
VL 56
AR 100931
DI 10.1016/j.jneuroling.2020.100931
PG 21
WC Linguistics; Neurosciences; Psychology, Experimental
SC Linguistics; Neurosciences & Neurology; Psychology
GA NR2MG
UT WOS:000571396200009
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Furubacke, A
   Albonico, A
   Barton, JJS
AF Furubacke, Amanda
   Albonico, Andrea
   Barton, Jason J. S.
TI Alternating dual-task interference between visual words and faces
SO BRAIN RESEARCH
LA English
DT Article
DE Hemispheric specialization; Many-to-many hypothesis; Perceptual
   expertise; Prosopagnosia; Alexia
ID FORM AREA; HEMISPHERIC LATERALIZATION; ACQUIRED PROSOPAGNOSIA;
   SPEECH-PERCEPTION; WORKING-MEMORY; PURE ALEXIA; RECOGNITION; BRAIN;
   NETWORKS
AB The many-to-many hypothesis proposes that face and visual word recognition share and even compete for high-level perceptual resources in both hemispheres. However, it is still not clear whether the processing performed by the two hemispheres on faces and visual words is equivalent or complementary. We performed an alternating dual-task experiment to determine if the processing of visual words and faces interfered with each other, and if such interference depended upon the stimulus attribute being processed. Subjects saw a series of alternating stimuli and made same-different judgments comparing the current stimulus with the one two trials before. In some blocks faces or visual words alternated with colored gratings, in other blocks they alternated between different sets of words or different sets of faces. In the key experimental blocks they alternated between visual words and faces. Subjects were also asked to focus on different properties of the stimuli (identity or speech sounds for faces, handwriting or word content for visual words, color or orientation for gratings). There was no evidence of specific interference when subjects alternated between face and word attributes thought to be processed by opposite hemispheres (e.g. face identity and word identity, facial speech and handwriting). Rather interference occurred when subjects alternated between attributes that may be processed by the same hemisphere. The results support a modified version of the many-to-many hypothesis which takes into account complementary functions of the left and the right hemispheres in the processing of faces and visual words.
C1 [Furubacke, Amanda; Albonico, Andrea; Barton, Jason J. S.] Univ British Columbia, Dept Med Neurol, Human Vis & Eye Movement Lab, Psychol, Vancouver, BC, Canada.
   [Furubacke, Amanda; Albonico, Andrea; Barton, Jason J. S.] Univ British Columbia, Dept Ophthalmol, Human Vis & Eye Movement Lab, Psychol, Vancouver, BC, Canada.
   [Furubacke, Amanda; Albonico, Andrea; Barton, Jason J. S.] Univ British Columbia, Dept Visual Sci, Human Vis & Eye Movement Lab, Psychol, Vancouver, BC, Canada.
   [Furubacke, Amanda] Linkoping Univ, Fac Med, Linkoping, Sweden.
RP Barton, JJS (corresponding author), VGH Eye Care Ctr, Neuroophthalmol Sect K, 2550 Willow St, Vancouver, BC V5Z 3N9, Canada.
EM jasonbarton@shaw.ca
OI Albonico, Andrea/0000-0003-1975-0824
FU Natural Sciences and Engineering Research CouncilNatural Sciences and
   Engineering Research Council of Canada (NSERC) [RGPIN 319129]; Canada
   Research ChairNatural Resources CanadaCanadian Forest ServiceCanada
   Research Chairs [950-228984]; Marianne Koerner Chair in Brain Diseases
FX This work was supported by Discovery Grant RGPIN 319129 from the Natural
   Sciences and Engineering Research Council. JB was supported by Canada
   Research Chair 950-228984 and the Marianne Koerner Chair in Brain
   Diseases.
CR Albonico A, 2017, CORTEX, V96, P59, DOI 10.1016/j.cortex.2017.08.029
   Barton JJS, 2008, J NEUROPSYCHOL, V2, P197, DOI 10.1348/174866407X214172
   Barton JJS, 2010, NEUROPSYCHOLOGIA, V48, P3866, DOI 10.1016/j.neuropsychologia.2010.09.012
   Barton JJS, 2010, J COGNITIVE NEUROSCI, V22, P1649, DOI 10.1162/jocn.2009.21286
   Behrmann M, 2014, CEREB CORTEX, V24, P1102, DOI 10.1093/cercor/bhs390
   Behrmann M, 2013, TRENDS COGN SCI, V17, P210, DOI 10.1016/j.tics.2013.03.007
   CAMPBELL R, 1986, BRAIN, V109, P509, DOI 10.1093/brain/109.3.509
   CAMPBELL R, 1990, NEUROPSYCHOLOGIA, V28, P787, DOI 10.1016/0028-3932(90)90003-7
   Cheung OS, 2010, J EXP PSYCHOL HUMAN, V36, P448, DOI 10.1037/a0016471
   Cohen L, 2002, BRAIN, V125, P1054, DOI 10.1093/brain/awf094
   Curby KM, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00955
   Davies-Thompson J, 2016, BRAIN RES, V1644, P88, DOI 10.1016/j.brainres.2016.05.009
   Davies-Thompson J, 2012, J NEUROPHYSIOL, V108, P3087, DOI 10.1152/jn.01171.2011
   Dehaene S, 2011, TRENDS COGN SCI, V15, P254, DOI 10.1016/j.tics.2011.04.003
   Dehaene S, 2010, SCIENCE, V330, P1359, DOI 10.1126/science.1194140
   Dundas EM, 2014, NEUROPSYCHOLOGIA, V61, P315, DOI 10.1016/j.neuropsychologia.2014.05.006
   Dundas EM, 2013, J EXP PSYCHOL GEN, V142, P348, DOI 10.1037/a0029503
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Franz VH, 2012, PSYCHON B REV, V19, P395, DOI 10.3758/s13423-012-0230-1
   Gauthier I, 2003, NAT NEUROSCI, V6, P428, DOI 10.1038/nn1029
   Gerlach C, 2014, J COGN PSYCHOL, V26, P550, DOI 10.1080/20445911.2014.928713
   Harris RJ, 2016, CEREB CORTEX, V26, P3161, DOI 10.1093/cercor/bhv147
   Hasson U, 2002, NEURON, V34, P479, DOI 10.1016/S0896-6273(02)00662-1
   Haxby JV, 2000, TRENDS COGN SCI, V4, P223, DOI 10.1016/S1364-6613(00)01482-0
   Hills CS, 2015, ANN NEUROL, V78, P258, DOI 10.1002/ana.24437
   Jones JA, 2003, NEUROREPORT, V14, P1129, DOI 10.1097/00001756-200306110-00006
   Kanwisher N, 1997, J NEUROSCI, V17, P4302
   Kleinschmidt A, 2006, CURR OPIN NEUROL, V19, P386, DOI 10.1097/01.wco.0000236619.89710.ee
   Leff AP, 2006, J NEUROL NEUROSUR PS, V77, P1004, DOI 10.1136/jnnp.2005.086983
   Longcamp M, 2011, HUM BRAIN MAPP, V32, P1250, DOI 10.1002/hbm.21105
   Matsuo T, 2015, CEREB CORTEX, V25, P1265, DOI 10.1093/cercor/bht319
   Nestor A, 2013, CEREB CORTEX, V23, P1673, DOI 10.1093/cercor/bhs158
   Plaut DC, 2011, COGN NEUROPSYCHOL, V28, P251, DOI 10.1080/02643294.2011.609812
   Postle BR, 2006, NEUROSCIENCE, V139, P23, DOI 10.1016/j.neuroscience.2005.06.005
   Reinke K, 2008, BRAIN LANG, V104, P180, DOI 10.1016/j.bandl.2007.04.006
   Roberts DJ, 2015, CORTEX, V72, P79, DOI 10.1016/j.cortex.2015.02.003
   Robinson AK, 2017, J EXP PSYCHOL GEN, V146, P943, DOI 10.1037/xge0000302
   Rossion B, 2012, BRAIN COGNITION, V79, P138, DOI 10.1016/j.bandc.2012.01.001
   Ruchkin D. S., 2003, BEHAV BRAIN SCI, V26, P728
   Ruchkin DS, 2003, BEHAV BRAIN SCI, V26, P709, DOI 10.1017/S0140525X03000165
   Ruytjens L, 2006, EUR J NEUROSCI, V24, P1835, DOI 10.1111/j.1460-9568.2006.05072.x
   Sekiyama K, 2003, NEUROSCI RES, V47, P277, DOI 10.1016/S0168-0102(03)00214-1
   Susilo T, 2015, COGN NEUROPSYCHOL, V32, P321, DOI 10.1080/02643294.2015.1081882
   Szwed M, 2011, NEUROIMAGE, V56, P330, DOI 10.1016/j.neuroimage.2011.01.073
   Weiner KS, 2016, NEUROPSYCHOLOGIA, V83, P48, DOI 10.1016/j.neuropsychologia.2015.06.033
NR 46
TC 0
Z9 0
U1 5
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0006-8993
EI 1872-6240
J9 BRAIN RES
JI Brain Res.
PD NOV 1
PY 2020
VL 1746
AR 147004
DI 10.1016/j.brainres.2020.147004
PG 9
WC Neurosciences
SC Neurosciences & Neurology
GA NL4NJ
UT WOS:000567394400004
PM 32615082
DA 2021-02-24
ER

PT J
AU Hu, AX
   Gu, F
   Wong, LLN
   Tong, XL
   Zhang, XC
AF Hu, Axu
   Gu, Feng
   Wong, Lena L. N.
   Tong, Xiuli
   Zhang, Xiaochu
TI Visual mismatch negativity elicited by semantic violations in visual
   words
SO BRAIN RESEARCH
LA English
DT Article
DE Word reading; Speech perception; Language processing; Semantic
   processing; Visual mismatch negativity; Chinese words
ID PHONEME REPRESENTATIONS; BRAIN POTENTIALS; MEMORY TRACES; LANGUAGE;
   CATEGORY; CHINESE; MMN; PERCEPTION; GRAMMAR; LATERALIZATION
AB The remarkable rapidity and effortlessness of speech perception and word reading by skilled listeners or readers suggest implicit or automatic mechanisms underlying language processing. In speech perception, the implicit mechanisms are reflected by the auditory mismatch negativity (MMN) response, suggesting that phonemic, lexical, semantic, and syntactic information are automatically and rapidly processed in the absence of focused attention. In visual word reading, implicit orthographic and lexical processing are reflected by visual mismatch negativity (vMMN), the visual counterpart of auditory MMN. The semantic processing of spoken words is reflected by MMN. This study investigated whether semantic processing is also reflected by vMMN. For this purpose, visual Chinese words belonging to different semantic categories (color, taste, and action) were presented to participants in oddball paradigms. A set of words belonging to the same semantic category was frequently presented as standards; a word belonging to a different semantic category was presented sporadically as deviant. Participants were instructed to perform a visual cross-change detection task and ignore the words. Significant vMMN was elicited in Experiments 1 to 3, in which the deviant word carried a semantic radical that overtly indicated the word's semantic category information. The vMMNs were most prominent around 260 ms after word onset, were parieto-occipital distributed, and were significantly left-hemisphere lateralized, suggesting rapid semantic processing of the visual words' category-related information. No significant vMMN was elicited in Experiment 4, in which the deviant word did not carry any semantic radicals. Thus, the semantic radical, which has a high frequency of occurrence because it is carried by many words, may be critical for the elicitation of vMMN.
C1 [Hu, Axu; Gu, Feng] Northwest Minzu Univ, Key Lab Chinas Ethn Languages & Informat Technol, Minist Educ, Lanzhou 730030, Peoples R China.
   [Gu, Feng] Sichuan Univ, Coll Literature & Journalism, Chengdu 610207, Peoples R China.
   [Gu, Feng; Wong, Lena L. N.; Tong, Xiuli] Univ Hong Kong, Fac Educ, Human Commun Dev & Informat Sci, Hong Kong, Peoples R China.
   [Zhang, Xiaochu] Univ Sci & Technol China, Affiliated Hosp 1, Eye Ctr,Dept Ophthalmol, Hefei Natl Lab Phys Sci Microscale, Hefei 230027, Anhui, Peoples R China.
   [Zhang, Xiaochu] Univ Sci & Technol China, Sch Life Sci, Div Life Sci & Med, Hefei 230027, Peoples R China.
   [Zhang, Xiaochu] Anhui Med Univ, Hefei Peoples Hosp 4, Anhui Mental Hlth Ctr, Affiliated Psychol Hosp, Hefei 230017, Peoples R China.
   [Zhang, Xiaochu] Univ Sci & Technol China, Sch Humanities & Social Sci, Hefei 230026, Peoples R China.
   [Zhang, Xiaochu] Tianjin Normal Univ, Acad Psychol & Behav, Tianjin 300387, Peoples R China.
RP Gu, F (corresponding author), Northwest Minzu Univ, Key Lab Chinas Ethn Languages & Informat Technol, Minist Educ, Lanzhou 730030, Peoples R China.; Gu, F (corresponding author), Sichuan Univ, Coll Literature & Journalism, Chengdu 610207, Peoples R China.; Gu, F (corresponding author), Univ Hong Kong, Fac Educ, Human Commun Dev & Informat Sci, Hong Kong, Peoples R China.; Zhang, XC (corresponding author), Univ Sci & Technol China, Affiliated Hosp 1, Eye Ctr,Dept Ophthalmol, Hefei Natl Lab Phys Sci Microscale, Hefei 230027, Anhui, Peoples R China.; Zhang, XC (corresponding author), Anhui Med Univ, Hefei Peoples Hosp 4, Anhui Mental Hlth Ctr, Affiliated Psychol Hosp, Hefei 230017, Peoples R China.; Zhang, XC (corresponding author), Univ Sci & Technol China, Sch Humanities & Social Sci, Hefei 230026, Peoples R China.; Zhang, XC (corresponding author), Tianjin Normal Univ, Acad Psychol & Behav, Tianjin 300387, Peoples R China.
EM fgu@scu.edu.cn; zxcustc@ustc.edu.cn
RI Zhang, Xiaochu/O-9592-2014
OI Zhang, Xiaochu/0000-0002-7541-0130; Gu, Feng/0000-0002-5954-5596
FU National Social Science Fund of China [15CYY042]; Program for Young
   Talent; National Natural Science Foundation of ChinaNational Natural
   Science Foundation of China (NSFC) [71942003, 31771221, 61773360,
   71874170, 11964034]; Open Project of the Key Laboratory of China's
   Ethnic Languages and Information Technology of Ministry of Education
   [KFJJ201902]; National Key Basic Research ProgramNational Basic Research
   Program of China [2016YFA0400900, 2018YFC0831101]; Major Project of
   Philosophy and Social Science Research, Ministry of Education of
   ChinaMinistry of Education, China [19JZD1010]; Fundamental Research
   Funds for the Central Universities of ChinaFundamental Research Funds
   for the Central Universities
FX This work was supported by the National Social Science Fund of China
   (15CYY042, to A. Hu), the Program for Young Talent (to A. Hu), National
   Natural Science Foundation of China (11964034, to A. Hu), Open Project
   of the Key Laboratory of China's Ethnic Languages and Information
   Technology of Ministry of Education (KFJJ201902, to F. Gu), National Key
   Basic Research Program (2016YFA0400900 and 2018YFC0831101, to X. Zhang),
   National Natural Science Foundation of China (71942003, 31771221,
   61773360 and 71874170, to X. Zhang), Major Project of Philosophy and
   Social Science Research, Ministry of Education of China (19JZD1010, to
   X. Zhang), and Fundamental Research Funds for the Central Universities
   of China (to X. Zhang).
CR Alexandrov AA, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0022999
   Alho K, 1998, NEUROSCI LETT, V258, P9, DOI 10.1016/S0304-3940(98)00836-2
   Amado C, 2016, EUR J NEUROSCI, V43, P1590, DOI 10.1111/ejn.13263
   Astikainen P, 2008, EUR J NEUROSCI, V28, P2319, DOI 10.1111/j.1460-9568.2008.06510.x
   Cappelle B, 2010, BRAIN LANG, V115, P189, DOI 10.1016/j.bandl.2010.09.004
   Cheour M, 1998, NAT NEUROSCI, V1, P351, DOI 10.1038/1561
   Czigler I, 2002, PSYCHOPHYSIOLOGY, V39, P869, DOI 10.1111/1469-8986.3960869
   Czigler I, 2014, BRAIN TOPOGR, V27, P590, DOI 10.1007/s10548-013-0316-8
   Czigler I, 2009, BIOL PSYCHOL, V80, P339, DOI 10.1016/j.biopsycho.2008.12.001
   Dikker S, 2010, PSYCHOL SCI, V21, P629, DOI 10.1177/0956797610367751
   Emadi N, 2014, J NEUROPHYSIOL, V112, P2628, DOI 10.1152/jn.00761.2013
   Freedman DJ, 2001, SCIENCE, V291, P312, DOI 10.1126/science.291.5502.312
   Freedman DJ, 2003, J NEUROSCI, V23, P5235
   Garrido MI, 2009, CLIN NEUROPHYSIOL, V120, P453, DOI 10.1016/j.clinph.2008.11.029
   Grimm S, 2009, INT J PSYCHOPHYSIOL, V72, P260, DOI 10.1016/j.ijpsycho.2009.01.005
   Gu F, 2018, NEUROSCIENCE, V385, P38, DOI 10.1016/j.neuroscience.2018.06.009
   Gu F, 2013, NEUROIMAGE, V83, P637, DOI 10.1016/j.neuroimage.2013.02.080
   Gu F, 2012, PSYCHOPHYSIOLOGY, V49, P1353, DOI 10.1111/j.1469-8986.2012.01447.x
   Hamalainen M. S, 1984, TKKFA559 HELS U TECH
   HAMALAINEN MS, 1994, MED BIOL ENG COMPUT, V32, P35, DOI 10.1007/BF02512476
   Hauk O, 2004, HUM BRAIN MAPP, V21, P191, DOI 10.1002/hbm.10157
   HOLCOMB PJ, 1990, LANG COGNITIVE PROC, V5, P281, DOI 10.1080/01690969008407065
   HOLCOMB PJ, 1988, BRAIN LANG, V35, P66, DOI 10.1016/0093-934X(88)90101-0
   Jackendoff Ray, 1983, SEMANTICS COGNITION
   Jacobsen T, 2001, PSYCHOPHYSIOLOGY, V38, P723, DOI 10.1017/S0048577201000993
   Kimura M, 2014, NEUROPSYCHOLOGIA, V65, P63, DOI 10.1016/j.neuropsychologia.2014.10.017
   Kimura M, 2012, INT J PSYCHOPHYSIOL, V83, P144, DOI 10.1016/j.ijpsycho.2011.11.010
   Kimura M, 2010, NEUROSCI LETT, V485, P198, DOI 10.1016/j.neulet.2010.09.011
   Kimura M, 2010, BRAIN RES, V1317, P165, DOI 10.1016/j.brainres.2009.12.076
   Kimura M, 2009, PSYCHOPHYSIOLOGY, V46, P402, DOI 10.1111/j.1469-8986.2008.00767.x
   Kraus N, 2000, AUDIOL NEURO-OTOL, V5, P140, DOI 10.1159/000013876
   KRAUS N, 1995, EAR HEARING, V16, P19, DOI 10.1097/00003446-199502000-00003
   Kreegipuu K, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00714
   Kriegeskorte N, 2008, NEURON, V60, P1126, DOI 10.1016/j.neuron.2008.10.043
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657
   Kutas M, 2000, TRENDS COGN SCI, V4, P463, DOI 10.1016/S1364-6613(00)01560-6
   KUTAS M, 1980, BIOL PSYCHOL, V11, P99, DOI 10.1016/0301-0511(80)90046-0
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532
   Li P, 2004, NEUROIMAGE, V21, P1533, DOI 10.1016/j.neuroimage.2003.10.044
   Maekawa T, 2005, CLIN NEUROPHYSIOL, V116, P2392, DOI 10.1016/j.clinph.2005.07.006
   Maess B, 2007, NEUROIMAGE, V37, P561, DOI 10.1016/j.neuroimage.2007.05.040
   Martin A, 1996, NATURE, V379, P649, DOI 10.1038/379649a0
   Martin BA, 2008, EAR HEARING, V29, P285, DOI 10.1097/AUD.0b013e3181662c0e
   Martin FMD, 2006, NEUROIMAGE, V29, P29, DOI 10.1016/j.neuroimage.2005.07.055
   May PJC, 2010, PSYCHOPHYSIOLOGY, V47, P66, DOI 10.1111/j.1469-8986.2009.00856.x
   MCCARTHY G, 1993, ELECTROEN CLIN NEURO, V88, P210, DOI 10.1016/0168-5597(93)90005-A
   Meyers EM, 2008, J NEUROPHYSIOL, V100, P1407, DOI 10.1152/jn.90248.2008
   Moseley RL, 2013, SCI REP-UK, V3, DOI 10.1038/srep01928
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 2001, TRENDS NEUROSCI, V24, P283, DOI 10.1016/S0166-2236(00)01790-2
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Naatanen R, 2001, PSYCHOPHYSIOLOGY, V38, P1, DOI 10.1017/S0048577201000208
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Penolazzi B, 2007, BIOL PSYCHOL, V74, P374, DOI 10.1016/j.biopsycho.2006.09.008
   Picton TW, 2000, AUDIOL NEURO-OTOL, V5, P111, DOI 10.1159/000013875
   Pulvermuller F, 2007, J COGNITIVE NEUROSCI, V19, P971, DOI 10.1162/jocn.2007.19.6.971
   Pulvermuller F, 2001, NEUROIMAGE, V14, P607, DOI 10.1006/nimg.2001.0864
   Pulvermuller F, 2005, J COGNITIVE NEUROSCI, V17, P884, DOI 10.1162/0898929054021111
   Pulvermuller F, 2004, PSYCHOPHYSIOLOGY, V41, P106, DOI 10.1111/j.1469-8986.2003.00135.x
   Pulvermuller F, 2003, NEUROIMAGE, V20, P159, DOI 10.1016/S1053-8119(03)00261-1
   Pulvermuller F, 2006, PROG NEUROBIOL, V79, P49, DOI 10.1016/j.pneurobio.2006.04.004
   Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811
   Pulvermuller F, 2009, BRAIN LANG, V110, P81, DOI 10.1016/j.bandl.2008.12.001
   Relander K, 2009, J COGNITIVE NEUROSCI, V21, P1511, DOI 10.1162/jocn.2009.21127
   SEMLITSCH HV, 1986, PSYCHOPHYSIOLOGY, V23, P695, DOI 10.1111/j.1469-8986.1986.tb00696.x
   Shtyrov Y, 2004, EUR J NEUROSCI, V19, P1083, DOI 10.1111/j.0953-816X.2004.03126.x
   Shtyrov Y, 2003, J COGNITIVE NEUROSCI, V15, P1195, DOI 10.1162/089892903322598148
   Shtyrov Y, 2007, J PSYCHOPHYSIOL, V21, P176, DOI 10.1027/0269-8803.21.34.176
   Shtyrov Y, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00421
   Shtyrov Y, 2011, NEUROIMAGE, V55, P658, DOI 10.1016/j.neuroimage.2010.12.002
   Stefanics G, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00666
   Sulykos I, 2015, BRAIN RES, V1626, P108, DOI 10.1016/j.brainres.2015.02.035
   Sulykos I, 2011, BRAIN RES, V1398, P64, DOI 10.1016/j.brainres.2011.05.009
   Sysoeva OV, 2015, INT J PSYCHOPHYSIOL, V95, P310, DOI 10.1016/j.ijpsycho.2014.12.007
   Taft M, 1999, J MEM LANG, V40, P498, DOI 10.1006/jmla.1998.2625
   Thierry G, 2009, P NATL ACAD SCI USA, V106, P4567, DOI 10.1073/pnas.0811155106
   Tong XL, 2018, J LEARN DISABIL-US, V51, P482, DOI 10.1177/0022219417718199
   Wacongne C, 2012, J NEUROSCI, V32, P3665, DOI 10.1523/JNEUROSCI.5003-11.2012
   Wang W, 2014, BIOL PSYCHOL, V100, P71, DOI 10.1016/j.biopsycho.2014.05.004
   Wang XD, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0056778
   Wei DW, 2019, NEUROREPORT, V30, P383, DOI 10.1097/WNR.0000000000001212
   Wei DW, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02455
   Wei DW, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19394-y
   Winkler I, 2007, J PSYCHOPHYSIOL, V21, P147, DOI 10.1027/0269-8803.21.34.147
   Winkler I, 2012, INT J PSYCHOPHYSIOL, V83, P132, DOI 10.1016/j.ijpsycho.2011.10.001
   Xi J, 2010, NEUROSCIENCE, V170, P223, DOI 10.1016/j.neuroscience.2010.06.077
   Yang XX, 2016, CLIN NEUROPHYSIOL, V127, P431, DOI 10.1016/j.clinph.2015.05.013
   Zhou XL, 1999, J MEM LANG, V41, P579, DOI 10.1006/jmla.1999.2663
NR 89
TC 1
Z9 1
U1 7
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0006-8993
EI 1872-6240
J9 BRAIN RES
JI Brain Res.
PD NOV 1
PY 2020
VL 1746
AR 147010
DI 10.1016/j.brainres.2020.147010
PG 11
WC Neurosciences
SC Neurosciences & Neurology
GA NK4XE
UT WOS:000566735000002
PM 32663455
DA 2021-02-24
ER

PT J
AU Sanker, C
AF Sanker, Chelsea
TI A perceptual pathway for voicing-conditioned vowel duration
SO LABORATORY PHONOLOGY
LA English
DT Article
DE Vowel duration; coda voicing; voicing-conditioned vowel duration; speech
   perception
ID INCOMPLETE NEUTRALIZATION; SUBJECTIVE DURATION; CLOSURE DURATION;
   SEGMENTAL FOCUS; LEXICAL FOCUS; ONSET TIME; CONTRAST; ENGLISH;
   DISCRIMINATION; PATTERNS
AB When codas and vowels are cross-spliced, vowels originally produced with voiced codas are perceived as longer than vowels of the same duration produced with voiceless codas. The spliced coda has the opposite effect: Vowels presented with voiced codas are perceived as shorter. To explain what characteristics make vowels produced with voiced codas sound longer than vowels produced with voiceless codas, four experiments tested how acoustic correlates of voicing affect English speakers' perception of vowel duration. Vowels were manipulated in a ten-step duration continuum, and listeners categorized each vowel as 'long' or 'short.' Study 1 tested effects of vowel height categories (/ae, epsilon, I/) and within-category F1. Study 2 tested effects of intensity contour. Study 3 tested effects of spectral tilt. Perceived vowel duration increased with vowel height and rising intensity. Perceived vowel duration decreased with falling intensity and with higher spectral tilt. There was no effect of within-category F1. Study 4 confirmed that the effect of the original coda environment is not specific to English stimuli. The effects of spectral tilt and intensity contour on perceived duration provide a possible perceptual pathway for the development of voicing-conditioned vowel duration; coda voicing influences these characteristics and they in turn influence perceived vowel duration.
C1 [Sanker, Chelsea] Yale Univ, Dept Linguist, New Haven, CT 06520 USA.
RP Sanker, C (corresponding author), Yale Univ, Dept Linguist, New Haven, CT 06520 USA.
EM chelsea.sanker@yale.edu
CR Abdelli-Beruh NB, 2004, PHONETICA, V61, P201, DOI 10.1159/000084158
   Archer SL, 2016, LANG LEARN DEV, V12, P60, DOI 10.1080/15475441.2014.979490
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bauer M., 2011, P 17 INT C PHON SCI, P292
   Benki JR, 2001, J PHONETICS, V29, P1, DOI 10.1006/jpho.2000.0128
   BERGLUND B, 1969, SCAND J PSYCHOL, V10, P21, DOI 10.1111/j.1467-9450.1969.tb00003.x
   Casillas JV, 2015, PHONETICA, V72, P182, DOI 10.1159/000431101
   CHEN M, 1970, PHONETICA, V22, P129, DOI 10.1159/000259312
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Chong AJ, 2018, LAB PHONOL, V9, DOI 10.5334/labphon.70
   Coleman J, 2003, J PHONETICS, V31, P351, DOI 10.1016/j.wocn.2003.10.001
   COOPER WE, 1981, PHONETICA, V38, P106, DOI 10.1159/000260017
   Coretta S, 2019, GLOSSA-UK, V4, DOI 10.5334/gjgl.869
   CROWTHER CS, 1992, J ACOUST SOC AM, V92, P711, DOI 10.1121/1.403996
   de Jong K, 2004, J PHONETICS, V32, P493, DOI 10.1016/j.wocn.2004.05.002
   de Jong K, 2002, J PHONETICS, V30, P53, DOI 10.1006/jpho.2001.0151
   DEJONG K, 1991, PHONETICA, V48, P1, DOI 10.1159/000261868
   Durvasula K., 2014, P M AC, DOI [10.1121/1.4895027, DOI 10.1121/1.4895027]
   Fletcher H, 1933, BELL SYST TECH J, V12, P377, DOI 10.1002/j.1538-7305.1933.tb00403.x
   FOURAKIS M, 1984, PHONETICA, V41, P140, DOI 10.1159/000261720
   FOWLER CA, 1992, J PHONETICS, V20, P143, DOI 10.1016/S0095-4470(19)30244-X
   GOLDSTON.S, 1974, PERCEPT MOTOR SKILL, V39, P63, DOI 10.2466/pms.1974.39.1.63
   GORDON PC, 1993, COGNITIVE PSYCHOL, V25, P1, DOI 10.1006/cogp.1993.1001
   Grassi M, 2006, PERCEPT PSYCHOPHYS, V68, P1382, DOI 10.3758/BF03193737
   Gussenhoven Carlos, 2007, LAB PHONOLOGY, V9, P145
   Halle M., 1967, 85 MIT RES LAB EL, V85
   HILLENBRAND J, 1984, J ACOUST SOC AM, V76, P18, DOI 10.1121/1.391094
   HOUSE AS, 1953, J ACOUST SOC AM, V25, P105, DOI 10.1121/1.1906982
   HOUSE AS, 1961, J ACOUST SOC AM, V33, P1174, DOI 10.1121/1.1908941
   Javkin H. R., 1976, REPORT PHONOLOGY LAB, V1, P78, DOI 10.1121/1.2002209
   Keating P. A., 1979, THESIS
   KEWLEYPORT D, 1994, J ACOUST SOC AM, V95, P485, DOI 10.1121/1.410024
   Kim D, 2019, LANG COGN NEUROSCI, V34, P769, DOI 10.1080/23273798.2019.1582787
   KLUENDER KR, 1988, J PHONETICS, V16, P153, DOI 10.1016/S0095-4470(19)30480-2
   Kong EJ, 2012, J PHONETICS, V40, P725, DOI 10.1016/j.wocn.2012.07.002
   LAEUFER C, 1992, J PHONETICS, V20, P411, DOI 10.1016/S0095-4470(19)30648-5
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001
   MERMELSTEIN P, 1978, J ACOUST SOC AM, V63, P572, DOI 10.1121/1.381756
   MITLEB FM, 1984, J PHONETICS, V12, P23, DOI 10.1016/S0095-4470(19)30847-2
   Moreton E, 2004, J PHONETICS, V32, P1, DOI 10.1016/S0095-4470(03)00004-4
   Myers S, 2007, NAT LANG LINGUIST TH, V25, P157, DOI 10.1007/s11049-006-0001-7
   Nagamma K., 1988, IETE J RES, V34, P57
   Ohman S., 1967, SPEECH TRANSM LAB Q, P30
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Penney J, 2018, INTERSPEECH, P1422, DOI 10.21437/Interspeech.2018-1677
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   PETERSON GE, 1960, J ACOUST SOC AM, V32, P693, DOI 10.1121/1.1908183
   PORT RF, 1985, J PHONETICS, V13, P455, DOI 10.1016/S0095-4470(19)30797-1
   PORT RF, 1980, PHONETICA, V37, P235, DOI 10.1159/000259994
   PORT RF, 1982, PERCEPT PSYCHOPHYS, V32, P141, DOI 10.3758/BF03204273
   Pycha A, 2016, J PHONETICS, V56, P15, DOI 10.1016/j.wocn.2016.01.002
   ROBINSON DW, 1956, BRIT J APPL PHYS, V7, P166, DOI 10.1088/0508-3443/7/5/302
   Sanker C, 2018, PAPERS HIST PHONOLOG, V3, P180, DOI DOI 10.2218/PIHPH.3.2018.2898
   Sanker C., 2019, P 19 INT C PHON SCI, P3323
   Sanker C, 2019, J PHONETICS, V75, P43, DOI 10.1016/j.wocn.2019.04.003
   Schlauch RS, 2001, J ACOUST SOC AM, V109, P2880, DOI 10.1121/1.1372913
   Seyfarth S., 2015, P 18 INT C PHON SCI
   Seyfarth S, 2018, J PHONETICS, V71, P425, DOI 10.1016/j.wocn.2018.09.001
   SHARF DJ, 1964, LANG SPEECH, V7, P89, DOI 10.1177/002383096400700204
   Sole M.J., 2007, EXPT APPROACHES PHON, P302
   Sole M-J., 2010, LAB PHONOLOGY, P607
   Toivonen I, 2015, W COAST C FORM LING, P64
   UMEDA N, 1975, J ACOUST SOC AM, V58, P434, DOI 10.1121/1.380688
   VANSUMMERS W, 1988, J ACOUST SOC AM, V84, P485, DOI 10.1121/1.396826
   VANSUMMERS W, 1987, J ACOUST SOC AM, V82, P847, DOI 10.1121/1.395284
   WANG WSY, 1976, J ACOUST SOC AM, V60, pS92, DOI 10.1121/1.2003607
   Warner N, 2004, J PHONETICS, V32, P251, DOI 10.1016/S0095-4470(03)00032-9
NR 68
TC 0
Z9 0
U1 1
U2 1
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD OCT 28
PY 2020
VL 11
IS 1
AR 18
DI 10.5334/labphon.268
PG 28
WC Linguistics; Language & Linguistics
SC Linguistics
GA OI7HO
UT WOS:000583445200001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Michon, M
   Boncompte, G
   Lopez, V
AF Michon, Maeva
   Boncompte, Gonzalo
   Lopez, Vladimir
TI Electrophysiological Dynamics of Visual Speech Processing and the Role
   of Orofacial Effectors for Cross-Modal Predictions
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE orofacial movements; place of articulation; ERPs; viseme; articuleme;
   speech motor system; cross-modal prediction
ID AUDITORY-CORTEX; LANGUAGE DISCRIMINATION; MOTOR THEORY; PERCEPTION;
   HEARING; INFORMATION; ACTIVATION; MECHANISMS; COMPREHENSION; RECOGNITION
AB The human brain generates predictions about future events. During face-to-face conversations, visemic information is used to predict upcoming auditory input. Recent studies suggest that the speech motor system plays a role in these cross-modal predictions, however, usually only audio-visual paradigms are employed. Here we tested whether speech sounds can be predicted on the basis of visemic information only, and to what extent interfering with orofacial articulatory effectors can affect these predictions. We registered EEG and employed N400 as an index of such predictions. Our results show that N400's amplitude was strongly modulated by visemic salience, coherent with cross-modal speech predictions. Additionally, N400 ceased to be evoked when syllables' visemes were presented backwards, suggesting that predictions occur only when the observed viseme matched an existing articuleme in the observer's speech motor system (i.e., the articulatory neural sequence required to produce a particular phoneme/viseme). Importantly, we found that interfering with the motor articulatory system strongly disrupted cross-modal predictions. We also observed a late P1000 that was evoked only for syllable-related visual stimuli, but whose amplitude was not modulated by interfering with the motor system. The present study provides further evidence of the importance of the speech production system for speech sounds predictions based on visemic information at the pre-lexical level. The implications of these results are discussed in the context of a hypothesized trimodal repertoire for speech, in which speech perception is conceived as a highly interactive process that involves not only your ears but also your eyes, lips and tongue.
C1 [Michon, Maeva] Pontificia Univ Catolica Chile, Lab Neurociencia Cognit & Evolutiva, Escuela Med, Santiago, Chile.
   [Michon, Maeva] Univ Diego Portales, Lab Neurociencia Cognit & Social, Fac Psicol, Santiago, Chile.
   [Boncompte, Gonzalo] Pontificia Univ Catolica Chile, Lab Neurodinam Cogn, Escuela Med, Santiago, Chile.
   [Lopez, Vladimir] Pontificia Univ Catolica Chile, Lab Psicol Expt, Escuela Psicol, Santiago, Chile.
RP Michon, M (corresponding author), Pontificia Univ Catolica Chile, Lab Neurociencia Cognit & Evolutiva, Escuela Med, Santiago, Chile.; Michon, M (corresponding author), Univ Diego Portales, Lab Neurociencia Cognit & Social, Fac Psicol, Santiago, Chile.
EM mmichon@uc.cl
FU Agencia Nacional de Investigacion y Desarrollo (ANID) from the Chilean
   government [3201057, 3200248, 1150241]
FX This research was supported by a post-doctoral fellowship from the
   Agencia Nacional de Investigacion y Desarrollo (ANID) from the Chilean
   government to MM (Grant No. 3201057) and GB (Grant No. 3200248) and by a
   regular grant to VL (Grant No. 1150241).
CR Archila-Melendez ME, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0252-17.2018
   [Ардила А. Ardila A.], 2020, [Неврология, нейропсихиатрия, психосоматика, Neurology, Neuropsychiatry, Psychosomatics, Nevrologiya, neiropsikhiatriya, psikhosomatika], V12, P4, DOI 10.14412/2074-2711-2020-1-4-12
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009
   Assaneo MF, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aao3842
   Auer ET, 2007, J SPEECH LANG HEAR R, V50, P1157, DOI 10.1044/1092-4388(2007/080)
   Baart M, 2016, PSYCHOPHYSIOLOGY, V53, P1295, DOI 10.1111/psyp.12683
   Bernstein LE, 2000, PERCEPT PSYCHOPHYS, V62, P233, DOI 10.3758/BF03205546
   Bernstein LE, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00386
   Blank H, 2013, NEUROIMAGE, V65, P109, DOI 10.1016/j.neuroimage.2012.09.047
   Bourguignon M., 2018, HEARING LIP READING, DOI [10.1101/395483, DOI 10.1101/395483]
   Bourguignon M, 2020, J NEUROSCI, V40, P1053, DOI 10.1523/JNEUROSCI.1101-19.2019
   Bruderer AG, 2015, P NATL ACAD SCI USA, V112, P13531, DOI 10.1073/pnas.1508631112
   Brunelliere A, 2013, INT J PSYCHOPHYSIOL, V89, P136, DOI 10.1016/j.ijpsycho.2013.06.016
   Calvert GA, 2003, J COGNITIVE NEUROSCI, V15, P57, DOI 10.1162/089892903321107828
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Chennu S, 2016, J NEUROSCI, V36, P8305, DOI 10.1523/JNEUROSCI.1125-16.2016
   Correia JM, 2015, J NEUROSCI, V35, P15015, DOI 10.1523/JNEUROSCI.0977-15.2015
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   DeLong KA, 2020, LANG COGN NEUROSCI, V35, P1044, DOI 10.1080/23273798.2019.1708960
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dole M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00030
   Duffau H, 2018, J CHEM NEUROANAT, V89, P73, DOI 10.1016/j.jchemneu.2017.04.003
   Gambi C, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00340
   Garrod S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00751
   Glenberg AM, 2012, CORTEX, V48, P905, DOI 10.1016/j.cortex.2011.04.010
   Golumbic EZ, 2013, J NEUROSCI, V33, P1417, DOI 10.1523/JNEUROSCI.3675-12.2013
   Gomez-Marin A, 2019, NEURON, V104, P25, DOI 10.1016/j.neuron.2019.09.017
   Hauswald A, 2018, CURR BIOL, V28, P1453, DOI 10.1016/j.cub.2018.03.044
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hirata Y, 2010, J SPEECH LANG HEAR R, V53, P298, DOI 10.1044/1092-4388(2009/08-0243)
   JASP Team, 2020, JASP VERS 0 12 2 COM
   Jesse A, 2010, ATTEN PERCEPT PSYCHO, V72, P209, DOI 10.3758/APP.72.1.209
   Kaganovich N, 2019, J EXP CHILD PSYCHOL, V184, P98, DOI 10.1016/j.jecp.2019.03.009
   Kaganovich N, 2016, BRAIN LANG, V157, P14, DOI 10.1016/j.bandl.2016.04.010
   Kilner James M, 2007, Cogn Process, V8, P159, DOI 10.1007/s10339-007-0170-2
   Kuperberg GR, 2020, J COGNITIVE NEUROSCI, V32, P12, DOI 10.1162/jocn_a_01465
   KUTAS M, 1980, BIOL PSYCHOL, V11, P99, DOI 10.1016/0301-0511(80)90046-0
   Letourneau SM, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00319
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   Luria A R, 1965, J Neurol Sci, V2, P278, DOI 10.1016/0022-510X(65)90112-7
   LURIA AR, 1973, NEUROPSYCHOLOGIA, V11, P417, DOI 10.1016/0028-3932(73)90028-6
   Martin CD, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19499-4
   Massaro DW, 2008, PSYCHON B REV, V15, P453, DOI 10.3758/PBR.15.2.453
   Maturana H.R., 1987, TREE KNOWLEDGE BIOL
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Michon M, 2019, PROG BRAIN RES, V250, P345, DOI 10.1016/bs.pbr.2019.01.005
   Navarra J, 2007, PSYCHOL RES-PSYCH FO, V71, P4, DOI 10.1007/s00426-005-0031-5
   Nuttall HE, 2018, BRAIN LANG, V187, P74, DOI 10.1016/j.bandl.2017.12.002
   Okada K, 2018, PSYCHON B REV, V25, P423, DOI 10.3758/s13423-017-1284-x
   Okland H. S., 2018, PREDICTING AUDIOVISU, DOI [10.1101/360578, DOI 10.1101/360578]
   Paris T, 2017, NEUROSCIENCE, V343, P157, DOI 10.1016/j.neuroscience.2016.09.023
   Paris T, 2013, BRAIN LANG, V126, P350, DOI 10.1016/j.bandl.2013.06.008
   Park Hyojin, 2018, Lang Cogn Neurosci, V35, P739, DOI 10.1080/23273798.2018.1506589
   Park H, 2016, ELIFE, V5, DOI 10.7554/eLife.14521
   Peelle J. E., 2019, ROUTLEDGE HDB PHONET
   Peelle JE, 2015, CORTEX, V68, P169, DOI 10.1016/j.cortex.2015.03.006
   Peirce JW, 2009, FRONT NEUROINFORM, V2, DOI 10.3389/neuro.11.010.2008
   Pekkola J, 2005, NEUROREPORT, V16, P125, DOI 10.1097/00001756-200502080-00010
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   Poeppel D, 2020, NAT REV NEUROSCI, V21, P322, DOI 10.1038/s41583-020-0304-4
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Pulvermuller F., 2016, HDB NEUROBIOLOGY LAN, P311, DOI 10.1016/C2011-0-07351-9
   Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   SAMS M, 1991, NEUROSCI LETT, V127, P141, DOI 10.1016/0304-3940(91)90914-F
   Sato M, 2010, SPEECH COMMUN, V52, P533, DOI 10.1016/j.specom.2009.12.004
   Sebastian-Galles N, 2012, PSYCHOL SCI, V23, P994, DOI 10.1177/0956797612436817
   Seth AK, 2013, TRENDS COGN SCI, V17, P565, DOI 10.1016/j.tics.2013.09.007
   Shahin AJ, 2018, J NEUROSCI, V38, P1835, DOI 10.1523/JNEUROSCI.1566-17.2017
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Stokes RC, 2019, PSYCHON B REV, V26, P1354, DOI 10.3758/s13423-019-01580-2
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Swaminathan S, 2013, BRAIN LANG, V126, P1, DOI 10.1016/j.bandl.2013.03.002
   ten Oever S, 2014, NEUROPSYCHOLOGIA, V63, P43, DOI 10.1016/j.neuropsychologia.2014.08.008
   Tenenbaum EJ, 2013, INFANCY, V18, P534, DOI 10.1111/j.1532-7078.2012.00135.x
   Thompson E., 2011, PHILOS TOPICS, V39, P163, DOI [10.5840/philtopics201139119, DOI 10.5840/PHILTOPICS201139119, DOI 10.5840/PHILT0PICS201139119)]
   Tremblay P, 2016, BRAIN LANG, V162, P60, DOI 10.1016/j.bandl.2016.08.004
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   van Wassenhove V., 2007, P 16 ICPHS
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   van Wassenhove V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00388
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   Worster E, 2018, LANG LEARN, V68, P159, DOI 10.1111/lang.12264
NR 91
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD OCT 27
PY 2020
VL 14
AR 538619
DI 10.3389/fnhum.2020.538619
PG 11
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA OO9MQ
UT WOS:000587697900001
PM 33192386
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Egorova, MA
   Akimov, AG
   Khorunzhii, GD
   Ehret, G
AF Egorova, Marina A.
   Akimov, Alexander G.
   Khorunzhii, Gleb D.
   Ehret, Guenter
TI Frequency response areas of neurons in the mouse inferior colliculus.
   III. Time-domain responses: Constancy, dynamics, and precision in
   relation to spectral resolution, and perception in the time domain
SO PLOS ONE
LA English
DT Article
ID AUDITORY MIDBRAIN; CENTRAL NUCLEUS; INTRINSIC-PROPERTIES; GAP DETECTION;
   HOUSE MOUSE; DURATION DISCRIMINATION; COMMUNICATION CALLS; DISCHARGE
   PATTERNS; IDENTIFIED NEURONS; SPEECH-PERCEPTION
AB The auditory midbrain (central nucleus of inferior colliculus, ICC) receives multiple brainstem projections and recodes auditory information for perception in higher centers. Many neural response characteristics are represented in gradients (maps) in the three-dimensional ICC space. Map overlap suggests that neurons, depending on their ICC location, encode information in several domains simultaneously by different aspects of their responses. Thus, interdependence of coding, e.g. in spectral and temporal domains, seems to be a general ICC principle. Studies on covariation of response properties and possible impact on sound perception are, however, rare. Here, we evaluated tone-evoked single neuron activity from the mouse ICC and compared shapes of excitatory frequency-response areas (including strength and shape of inhibition within and around the excitatory area; classes I, II, III) with types of temporal response patterns and first-spike response latencies. Analyses showed covariation of sharpness of frequency tuning with constancy and precision of responding to tone onsets. Highest precision (first-spike latency jitter < 1 ms) and stable phasic responses throughout frequency-response areas were the quality mainly of class III neurons with broad frequency tuning, least influenced by inhibition. Class II neurons with narrow frequency tuning and dominating inhibitory influence were unsuitable for time domain coding with high precision. The ICC center seems specialized rather for high spectral resolution (class II presence), lateral parts for constantly precise responding to sound onsets (class III presence). Further, the variation of tone-response latencies in the frequency-response areas of individual neurons with phasic, tonic, phasic-tonic, or pauser responses gave rise to the definition of a core area, which represented a time window of about 20 ms from tone onset for tone-onset responding of the whole ICC. This time window corresponds to the roughly 20 ms shortest time interval that was found critical in several auditory perceptual tasks in humans and mice.
C1 [Egorova, Marina A.; Akimov, Alexander G.; Khorunzhii, Gleb D.] Russian Acad Sci, Sechenov Inst Evolutionary Physiol & Biochem, St Petersburg, Russia.
   [Ehret, Guenter] Univ Ulm, Inst Neurobiol, Ulm, Germany.
RP Ehret, G (corresponding author), Univ Ulm, Inst Neurobiol, Ulm, Germany.
EM guenter.ehret@uni-ulm.de
FU Russian Foundation for Basic ResearchRussian Foundation for Basic
   Research (RFBR) [06-0448616, 18-015-00188]; VW foundationVolkswagen
   [I/69589]; Deutsche ForschungsgemeinschaftGerman Research Foundation
   (DFG) [EH 53/16-1, EH 53/22-1];  [AAAA-A18-118013090245-6]
FX This study was supported by the Russian Foundation for Basic Research
   (projects 06-0448616 and 18-015-00188), by the state budget for state
   orders for 2018-2020 (state registration #AAAA-A18-118013090245-6). It
   was also supported by grants of the VW foundation (I/69589), and by the
   Deutsche Forschungsgemeinschaft to GE: EH 53/16-1, 22-1. The funders had
   no role in study design, data collection and analysis, decision to
   publish, or preparation of the manuscript.
CR ABEL SM, 1972, J ACOUST SOC AM, V51, P1219, DOI 10.1121/1.1912963
   AITKIN LM, 1985, J NEUROPHYSIOL, V53, P43
   Akimov AG, 2017, EUR J NEUROSCI, V45, P440, DOI 10.1111/ejn.13488
   [Anonymous], 1997, Healthc Demand Dis Manag, V3, P135
   [Anonymous], 2010, DRUG DISCOV TODAY TE, V7, pe1
   Bal R, 2002, NEUROSCI LETT, V317, P42, DOI 10.1016/S0304-3940(01)02425-9
   Basta D, 2003, BRAIN RES, V968, P171, DOI 10.1016/S0006-8993(03)02233-9
   Baumann S, 2011, NAT NEUROSCI, V14, P423, DOI 10.1038/nn.2771
   BOCK GR, 1972, J NEUROPHYSIOL, V35, P265
   Brand A, 2000, J NEUROPHYSIOL, V84, P1790
   BRUNSOBECHTOLD JK, 1981, J COMP NEUROL, V197, P705, DOI 10.1002/cne.901970410
   Cant NB, 2006, J COMP NEUROL, V495, P511, DOI 10.1002/cne.20888
   Casseday JH, 2002, SPR HDB AUD, V15, P238
   Casseday JH, 2000, J NEUROPHYSIOL, V84, P1475
   Chase SM, 2007, P NATL ACAD SCI USA, V104, P5175, DOI 10.1073/pnas.0610368104
   Chen C, 2019, PLOS BIOL, V17, DOI 10.1371/journal.pbio.2005861
   COVEY E, 1991, J NEUROSCI, V11, P3456
   DARWIN CJ, 1984, Q J EXP PSYCHOL-A, V36, P193, DOI 10.1080/14640748408402155
   DIXON WJ, 1953, BIOMETRICS, V9, P74, DOI 10.2307/3001634
   Egorova M, 2001, EXP BRAIN RES, V140, P145, DOI 10.1007/s002210100786
   Egorova MA, 2018, J EVOL BIOCHEM PHYS+, V54, P482, DOI 10.1134/S002209301806008X
   Egorova M, 2008, EUR J NEUROSCI, V28, P675, DOI 10.1111/j.1460-9568.2008.06376.x
   Ehret G, 2005, AUDITORY SIGNAL PROCESSINGP: PHYSIOLOGY, PSYCHOACOUSTICS, AND MODELS, P162, DOI 10.1007/0-387-27045-0_20
   EHRET G, 1985, J COMP PHYSIOL A, V156, P619, DOI 10.1007/BF00619111
   Ehret G, 2005, INFERIOR COLLICULUS, P312, DOI 10.1007/0-387-27083-3_11
   Ehret G, 2003, NEUROREPORT, V14, P1365, DOI 10.1097/01.wnr.0000078545.07662.85
   EHRET G, 1982, J COMP PHYSIOL, V148, P245, DOI 10.1007/BF00619131
   EHRET G, 1988, BRAIN RES REV, V13, P139, DOI 10.1016/0165-0173(88)90018-5
   EHRET G, 1992, ANIM BEHAV, V43, P409, DOI 10.1016/S0003-3472(05)80101-0
   Ehret G., 1997, CENTRAL AUDITORY SYS, P259
   Ehret G, 1987, CATEGORICAL PERCEPTI, P301
   Ehret G, 2010, HBK BEHAV NEUROSCI, V19, P125, DOI 10.1016/B978-0-12-374593-4.00013-9
   Ferragamo MJ, 1998, J COMP PHYSIOL A, V182, P65
   FITZGIBBONS PJ, 1983, J ACOUST SOC AM, V74, P67, DOI 10.1121/1.389619
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407
   Fu ZY, 2013, NEUROSCI BULL, V29, P541, DOI 10.1007/s12264-013-1346-7
   Geissler DB, 2002, P NATL ACAD SCI USA, V99, P9021, DOI 10.1073/pnas.122606499
   Gershuni G, 1969, NEIROFIZIOLOGIYA, V1, P105
   Gersuni GV, 1971, SENSORY PROCESSES NE, P157
   GIRAUDI D, 1980, J ACOUST SOC AM, V68, P802, DOI 10.1121/1.384818
   Grimsley CA, 2013, FRONT NEURAL CIRCUIT, V7, DOI 10.3389/fncir.2013.00174
   Hage SR, 2003, EUR J NEUROSCI, V18, P2301, DOI 10.1046/j.1460-9568.2003.02945.x
   Hanafin Patrick, 1996, Eur J Health Law, V3, P179, DOI 10.1007/BF02731853
   Hattori T, 1997, J COMP PHYSIOL A, V180, P271, DOI 10.1007/s003590050047
   Heil P, 1997, J NEUROPHYSIOL, V78, P2438
   Hernandez O, 2005, NEUROSCIENCE, V132, P203, DOI 10.1016/j.neuroscience.2005.01.001
   HIRSH IJ, 1959, J ACOUST SOC AM, V31, P759, DOI 10.1121/1.1907782
   HORIKAWA J, 1988, P JPN ACAD B-PHYS, V64, P181, DOI 10.2183/pjab.64.181
   Hurley LM, 2005, J NEUROSCI, V25, P7876, DOI 10.1523/JNEUROSCI.1178-05.2005
   IRWIN RJ, 1981, AUDIOLOGY, V20, P234
   Ito T, 2018, SPRINGER HANDB AUDIT, V65, P127, DOI 10.1007/978-3-319-71798-2_6
   Khorunzhii GD, 2014, J EVOL BIOCHEM PHYS+, V50, P357, DOI 10.1134/S0022093014040097
   Klink KB, 2004, J COMP PHYSIOL A, V190, P1039, DOI 10.1007/s00359-004-0561-0
   Klug A, 2000, HEARING RES, V148, P107, DOI 10.1016/S0378-5955(00)00146-5
   Koch U, 2003, J NEUROPHYSIOL, V90, P3679, DOI 10.1152/jn.00375.2003
   Kudo M, 1988, PATHWAY STRUCTURE FU, P171
   KUHL PK, 1978, J ACOUST SOC AM, V63, P905, DOI 10.1121/1.381770
   Kuwada S, 1997, J NEUROSCI, V17, P7565
   Langner G, 2002, HEARING RES, V168, P110, DOI 10.1016/S0378-5955(02)00367-2
   LeBeau FEN, 2001, J NEUROSCI, V21, P7303, DOI 10.1523/JNEUROSCI.21-18-07303.2001
   Lee J, 2019, J NEUROSCI, V39, P6905, DOI 10.1523/JNEUROSCI.0659-19.2019
   Liang FX, 2011, BRAIN RES, V1369, P46, DOI 10.1016/j.brainres.2010.11.011
   Loftus WC, 2010, J NEUROSCI, V30, P13396, DOI 10.1523/JNEUROSCI.0338-10.2010
   Malinina E S, 2016, Dokl Biol Sci, V470, P209
   Malmierca MS, 2012, MOUSE NERVOUS SYSTEM, P607, DOI 10.1016/B978-0-12-369497-3.10024-X
   MILLER JD, 1976, J ACOUST SOC AM, V60, P410, DOI 10.1121/1.381097
   Murphy BA, 2003, ANN EMERG MED, V41, P123, DOI 10.1067/mem.2003.13
   Neff WD, 1975, HDB SENSORY PHYSIOLO, P307
   Oliver DL, 1997, J COMP NEUROL, V382, P215, DOI 10.1002/(SICI)1096-9861(19970602)382:2<215::AID-CNE6>3.0.CO;2-6
   Ono M, 2017, J NEUROSCI, V37, P8952, DOI 10.1523/JNEUROSCI.0745-17.2017
   Ono M, 2014, J PHYSIOL-LONDON, V592, P3647, DOI 10.1113/jphysiol.2014.275446
   Palmer AR, 2013, J PHYSIOL-LONDON, V591, P4003, DOI 10.1113/jphysiol.2013.255943
   Perez CA, 2013, CEREB CORTEX, V23, P670, DOI 10.1093/cercor/bhs045
   Perez-Gonzalez D, 2006, J NEUROPHYSIOL, V95, P823, DOI 10.1152/jn.00741.2005
   Peruzzi D, 2000, NEUROSCIENCE, V101, P403, DOI 10.1016/S0306-4522(00)00382-1
   PISONI DB, 1977, J ACOUST SOC AM, V61, P1352, DOI 10.1121/1.381409
   PISONI DB, 1974, J ACOUST SOC AM, V55, P328, DOI 10.1121/1.1914506
   Pollak GD, 2011, HEARING RES, V274, P27, DOI 10.1016/j.heares.2010.05.010
   Portfors CV, 2011, NEUROSCIENCE, V193, P429, DOI 10.1016/j.neuroscience.2011.07.025
   Recio-Spinoso A, 2014, J NEUROPHYSIOL, V111, P817, DOI 10.1152/jn.00971.2011
   Rees A, 1997, J NEUROPHYSIOL, V77, P2945
   Reetz G, 1999, BRAIN RES, V816, P527, DOI 10.1016/S0006-8993(98)01230-X
   Rodriguez FA, 2010, J NEUROPHYSIOL, V103, P887, DOI 10.1152/jn.00813.2009
   ROMAND R, 1990, DEV BRAIN RES, V54, P221, DOI 10.1016/0165-3806(90)90145-O
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Rouiller EM, 1997, ACOUSTICAL SIGNAL PROCESSING IN THE CENTRAL AUDITORY SYSTEM, P33, DOI 10.1007/978-1-4419-8712-9_3
   Sachs L, 1999, ANGEW STAT
   SCHREINER CE, 1988, J NEUROPHYSIOL, V60, P1823
   Schreiner CE, 1997, NATURE, V388, P383, DOI 10.1038/41106
   Schreiner CE, 1988, AUDITORY FUNCTION NE, P337
   SEMPLE MN, 1979, J NEUROPHYSIOL, V42, P1626
   Seshagiri CV, 2007, J NEUROPHYSIOL, V98, P2058, DOI 10.1152/jn.01317.2006
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sidman RL, 1971, ATLAS MOUSE BRAIN SP
   Sivaramakrishnan S, 2004, J NEUROSCI, V24, P5031, DOI 10.1523/JNEUROSCI.0357-04.2004
   Sivaramakrishnan S, 2001, J NEUROSCI, V21, P2861, DOI 10.1523/JNEUROSCI.21-08-02861.2001
   STEVENS KN, 1974, J ACOUST SOC AM, V55, P653, DOI 10.1121/1.1914578
   STIEBLER I, 1986, NEUROSCI LETT, V65, P336, DOI 10.1016/0304-3940(86)90285-5
   STIEBLER I, 1985, J COMP NEUROL, V238, P65, DOI 10.1002/cne.902380106
   Stiebler I., 1987, FREQUENZREPRASENTATI, V173
   Straka MM, 2014, J NEUROPHYSIOL, V112, P981, DOI 10.1152/jn.00008.2014
   Tan ML, 2007, J NEUROPHYSIOL, V98, P454, DOI 10.1152/jn.00174.2007
   Tan XD, 2008, HEARING RES, V235, P90, DOI 10.1016/j.heares.2007.10.002
   Voytenko SV, 2008, NEUROSCIENCE, V155, P923, DOI 10.1016/j.neuroscience.2008.06.031
   WAGNER T, 1994, NEUROREPORT, V6, P89, DOI 10.1097/00001756-199412300-00024
   Wallace MN, 2012, FRONT NEURAL CIRCUIT, V6, DOI 10.3389/fncir.2012.00055
   Walton JP, 1998, J NEUROSCI, V18, P2764
   Walton JP, 1997, J COMP PHYSIOL A, V181, P161, DOI 10.1007/s003590050103
   Winer JA, 2005, INFERIOR COLLICULUS, P1, DOI 10.1007/0-387-27083-3_1
   Xie R, 2008, NEUROSCIENCE, V154, P245, DOI 10.1016/j.neuroscience.2008.02.039
   Yassin L, 2016, HEARING RES, V341, P79, DOI 10.1016/j.heares.2016.08.005
   Zwicker E, 1967, OHR ALS NACHRICHTENE
NR 112
TC 0
Z9 0
U1 0
U2 0
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD OCT 26
PY 2020
VL 15
IS 10
AR e0240853
DI 10.1371/journal.pone.0240853
PG 30
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA OP8VY
UT WOS:000588370000040
PM 33104718
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Rouse, SL
   Matthews, IR
   Li, J
   Sherr, EH
   Chan, DK
AF Rouse, Stephanie L.
   Matthews, Ian R.
   Li, Jiang
   Sherr, Elliott H.
   Chan, Dylan K.
TI Integrated stress response inhibition provides sex-dependent protection
   against noise-induced cochlear synaptopathy
SO SCIENTIFIC REPORTS
LA English
DT Article
AB Noise-induced hearing loss (NIHL) is a common health concern with significant social, psychological, and cognitive implications. Moderate levels of acoustic overstimulation associated with tinnitus and impaired speech perception cause cochlear synaptopathy, characterized physiologically by reduction in wave I of the suprathreshold auditory brainstem response (ABR) and reduced number of synapses between sensory hair cells and auditory neurons. The unfolded protein response (UPR), an endoplasmic reticulum stress response pathway, has been implicated in the pathogenesis and treatment of NIHL as well as neurodegeneration and synaptic damage in the brain. In this study, we used the small molecule UPR modulator Integrated Stress Response InhiBitor (ISRIB) to treat noise-induced cochlear synaptopathy in a mouse model. Mice pretreated with ISRIB prior to noise-exposure were protected against noise-induced synapse loss. Male, but not female, mice also exhibited ISRIB-mediated protection against noise-induced suprathreshold ABR wave-I amplitude reduction. Female mice had higher baseline wave-I amplitudes but greater sensitivity to noise-induced wave-I reduction. Our results suggest that the UPR is implicated in noise-induced cochlear synaptopathy, and can be targeted for treatment.
C1 [Rouse, Stephanie L.; Matthews, Ian R.; Chan, Dylan K.] Univ Calif San Francisco UCSF, Dept Otolaryngol Head & Neck Surg, 513 Parnassus Ave,Rm 719, San Francisco, CA 94143 USA.
   [Li, Jiang; Sherr, Elliott H.] UCSF, Dept Neurol, 675 Nelson Rising Lane,Room 214B, San Francisco, CA 94158 USA.
   [Sherr, Elliott H.] UCSF, Inst Human Genet, Weill Inst Neurosci, Dept Pediat, San Francisco, CA 94143 USA.
RP Chan, DK (corresponding author), Univ Calif San Francisco UCSF, Dept Otolaryngol Head & Neck Surg, 513 Parnassus Ave,Rm 719, San Francisco, CA 94143 USA.; Sherr, EH (corresponding author), UCSF, Dept Neurol, 675 Nelson Rising Lane,Room 214B, San Francisco, CA 94158 USA.; Sherr, EH (corresponding author), UCSF, Inst Human Genet, Weill Inst Neurosci, Dept Pediat, San Francisco, CA 94143 USA.
EM Elliott.Sherr@ucsf.edu; Dylan.Chan@ucsf.edu
OI Rouse, Stephanie/0000-0002-2967-3351
FU National Institute on Deafness and Other Communication Disorders
   (NIDCD)United States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R03DC015082]; Hearing Research,
   Inc.; National Institute of Neurological Disorders and Stroke
   (NINDS)United States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute of Neurological
   Disorders & Stroke (NINDS) [2R01NS058721]
FX This work was supported in part by a grant from the National Institute
   on Deafness and Other Communication Disorders (NIDCD) to DKC
   (R03DC015082), from Hearing Research, Inc., to DKC, and from the
   National Institute of Neurological Disorders and Stroke (NINDS) to EHS
   (2R01NS058721).
CR Bardo S, 2002, BRIT J PHARMACOL, V137, P529, DOI 10.1038/sj.bjp.0704901
   Beurg M, 2005, EUR J NEUROSCI, V22, P1109, DOI 10.1111/j.1460-9568.2005.04310.x
   Castellano-Munoz M, 2014, FRONT CELL NEUROSCI, V8, DOI 10.3389/fncel.2014.00162
   Chan DK, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0167850
   Chen A, 2003, NEURON, V39, P655, DOI 10.1016/S0896-6273(03)00501-4
   Chou A, 2017, P NATL ACAD SCI USA, V114, pE6420, DOI 10.1073/pnas.1707661114
   Costa-Mattioli M, 2007, CELL, V129, P195, DOI 10.1016/j.cell.2007.01.050
   Halliday M, 2015, NEUROPATH APPL NEURO, V41, P414, DOI 10.1111/nan.12211
   Herranen A, 2020, CELL DEATH DIS, V11, DOI 10.1038/s41419-020-2286-6
   Hickox AE, 2014, J NEUROPHYSIOL, V111, P552, DOI 10.1152/jn.00184.2013
   Hoozemans JJM, 2007, BIOCHEM BIOPH RES CO, V354, P707, DOI 10.1016/j.bbrc.2007.01.043
   Hu N, 2020, P NATL ACAD SCI USA, V117, P3828, DOI 10.1073/pnas.1914247117
   Kennedy HJ, 2002, J PHYSIOL-LONDON, V539, P15, DOI 10.1113/jphysiol.2001.013171
   Kim KX, 2019, J NEUROSCI, V39, P4434, DOI 10.1523/JNEUROSCI.2228-18.2019
   Krukowski K, 2020, J NEUROTRAUM, V37, P1370, DOI 10.1089/neu.2019.6827
   Kujawa SG, 2009, J NEUROSCI, V29, P14077, DOI 10.1523/JNEUROSCI.2845-09.2009
   Lauer AM, 2017, NOISE HEALTH, V19, P207, DOI 10.4103/nah.NAH_12_17
   Li J, 2018, J CLIN INVEST, V128, P5150, DOI 10.1172/JCI97498
   Liberman LD, 2015, JARO-J ASSOC RES OTO, V16, P205, DOI 10.1007/s10162-015-0510-3
   MITCHELL C, 1989, HEARING RES, V40, P75, DOI 10.1016/0378-5955(89)90101-9
   Moreno JA, 2012, NATURE, V485, P507, DOI 10.1038/nature11058
   Muller M, 2005, HEARING RES, V202, P63, DOI 10.1016/j.heares.2004.08.011
   Nouvian R, 2006, J MEMBRANE BIOL, V209, P153, DOI 10.1007/s00232-005-0854-4
   Ruiz A, 2010, CELL DEATH DIS, V1, DOI 10.1038/cddis.2010.31
   Shi L, 2015, ACTA OTO-LARYNGOL, V135, P1093, DOI 10.3109/00016489.2015.1061699
   Sidrauski C, 2013, ELIFE, V2, DOI 10.7554/eLife.00498
   Sokka AL, 2007, J NEUROSCI, V27, P901, DOI 10.1523/JNEUROSCI.4289-06.2007
   Stamper GC, 2015, EAR HEARING, V36, P172, DOI 10.1097/AUD.0000000000000107
   Zhu PJ, 2019, SCIENCE, V366, P843, DOI 10.1126/science.aaw5185
NR 29
TC 0
Z9 0
U1 0
U2 0
PU NATURE RESEARCH
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD OCT 22
PY 2020
VL 10
IS 1
AR 18063
DI 10.1038/s41598-020-75058-w
PG 11
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA QD2UK
UT WOS:000615379800056
PM 33093490
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Kutlu, E
AF Kutlu, Ethan
TI Now You See Me, Now You Mishear Me: Raciolinguistic accounts of speech
   perception in different English varieties
SO JOURNAL OF MULTILINGUAL AND MULTICULTURAL DEVELOPMENT
LA English
DT Article; Early Access
DE Audio-visual speech perception; raciolinguistics; English varieties;
   accentedness judgments; Indian English
ID IDEOLOGIES; ACCENT; DISCRIMINATION; EXPECTATIONS; IMPLICIT
AB Listeners can access information about a speaker such as age, gender identity, socioeconomic status, and their linguistic background upon hearing their speech. However, it is still not clear if listeners use these factors to assess speakers' speech. Here, an audio-visual (matched-guise) test is used to measure whether listeners' accentedness judgments can be modulated depending on the type of face that they see. American and Indian English were used as different English varieties and presented with either a White female face or a South Asian female face. Results show that listeners' accentedness judgments increased for Indian English compared to American English. Importantly, the increase in accentedness judgments was also observed when both American English and Indian English were presented with a South Asian face compared to a White face. These findings suggest that linguistic evaluations are modulated by non-linguistic factors and that speech perception is socially gated.
C1 [Kutlu, Ethan] Univ Florida, Dept Linguist, Gainesville, FL USA.
   [Kutlu, Ethan] Univ Florida, Dept Psychol, Gainesville, FL 32611 USA.
RP Kutlu, E (corresponding author), Univ Florida, Dept Psychol, Gainesville, FL 32611 USA.
EM ethankutlu@gmail.com
OI Kutlu, Ethan/0000-0001-9096-146X
CR Alba R.D., 2009, REMAKING AM MAINSTRE
   Babel M, 2015, J ACOUST SOC AM, V137, P2823, DOI 10.1121/1.4919317
   Baese-Berk MM, 2013, J ACOUST SOC AM, V133, pEL174, DOI 10.1121/1.4789864
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bonilla-silva E, 2004, ETHNIC RACIAL STUD, V27, P931, DOI 10.1080/0141987042000268530
   Bradac James J., 2001, NEW HDB LANGUAGE SOC, P137
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Chand V, 2009, LANG SOC, V38, P393, DOI 10.1017/S0047404509990200
   Cowie C., 2007, WORLD ENGLISH, V26, P316, DOI DOI 10.1111/J.1467-971X.2007.00511.X
   Dalton C., 2000, IRAL-INT REV APPL LI, V38, P229, DOI [10.1515/iral.2000.38.3-4.229, DOI 10.1515/IRAL.2000.38.3-4.229]
   De Houwer A, 2015, INT J BILINGUAL, V19, P169, DOI 10.1177/1367006913489202
   de Souza LEC, 2016, EUR J SOC PSYCHOL, V46, P609, DOI 10.1002/ejsp.2216
   Derwing TM, 2009, CAN MOD LANG REV, V66, P181, DOI 10.3138/cmlr.66.2.181
   Dewaele J. M., 2020, EUROPEAN J APPL LING, V1, DOI [10.1515/eujal-2019-0030, DOI 10.1515/EUJAL-2019-0030]
   Dewaele JM, 2018, APPL LINGUIST, V39, P236, DOI 10.1093/applin/amw055
   FLEGE JE, 1991, J ACOUST SOC AM, V89, P395, DOI 10.1121/1.400473
   Floccia C, 2006, J EXP PSYCHOL HUMAN, V32, P1276, DOI 10.1037/0096-1523.32.5.1276
   Flores N, 2015, HARVARD EDUC REV, V85, P7
   Gawronski B, 2006, PSYCHOL BULL, V132, P692, DOI 10.1037/0033-2909.132.5.692
   Gluszek A, 2010, PERS SOC PSYCHOL REV, V14, P214, DOI 10.1177/1088868309359288
   Guion S., 2004, BILING-LANG COGN, V7, P207, DOI DOI 10.1017/S1366728904001592
   Gullifer JW, 2020, BILING-LANG COGN, V23, P283, DOI 10.1017/S1366728919000026
   Hoffman MF, 2010, LANG VAR CHANGE, V22, P37, DOI 10.1017/S0954394509990238
   HOLM S, 1979, SCAND J STAT, V6, P65
   Huang P, 2020, ENVIRON POLIT, V29, P524, DOI 10.1080/09644016.2019.1589935
   Ibm Corp, 2019, IBM SPSS STAT WIND V
   Itzhak I., 2017, TRANSLATIONAL ISSUES, V3, P48, DOI DOI 10.1037/TPS0000103
   Kachru B., 1983, INDIANIZATION ENGLIS
   Kachru B. B., 1992, OTHER TONGUE ENGLISH, V2
   Kachru B. B., 1986, ALCHEMY ENGLISH
   Kang O, 2009, J LANG SOC PSYCHOL, V28, P441, DOI 10.1177/0261927X09341950
   Kim SJ, 2011, WATER RESOUR RES, V47, DOI 10.1029/2011WR010561
   Kirkpatrick A., 2008, WORLD ENGLISH, V27, P480
   Kutlu E., 2020, P LINGUISTIC SOC AM, V5
   Labov W, 1972, LANGUAGE INNER CITY
   LAMBERT WE, 1960, J ABNORM SOC PSYCH, V60, P44, DOI 10.1037/h0044430
   Lee J, 2010, DIVERSITY PARADOX: IMMIGRATION AND THE COLOR LINE IN TWENTY-FIRST CENTURY AMERICA, P1
   Lemhofer K, 2012, BEHAV RES METHODS, V44, P325, DOI 10.3758/s13428-011-0146-0
   Lippi-Green R., 2012, ENGLISH ACCENT LANGU
   Ma DS, 2015, BEHAV RES METHODS, V47, P1122, DOI 10.3758/s13428-014-0532-5
   MAHBOOB A, 2013, AGE, V3, P21
   Mahboob A, 2018, RELC J, V49, P36, DOI 10.1177/0033688218754944
   McGowan KB, 2015, LANG SPEECH, V58, P502, DOI 10.1177/0023830914565191
   Niedzielski Nancy, 1999, J LANG SOC PSYCHOL, V18, P1
   Osgood C. E., 1964, AM ANTHROPOL, V66
   Pantos AJ, 2013, J LANG SOC PSYCHOL, V32, P3, DOI 10.1177/0261927X12463005
   Peirce J, 2019, BEHAV RES METHODS, V51, P195, DOI 10.3758/s13428-018-01193-y
   Pietraszewski D, 2014, EVOL HUM BEHAV, V35, P51, DOI 10.1016/j.evolhumbehav.2013.09.005
   R Core Team, 2018, R LANG ENV STAT COMP
   Ramjattan VA, 2019, RACE ETHNIC EDUC-UK, V22, P374, DOI 10.1080/13613324.2017.1377171
   Registrar General  I, 2011, CENSUS INDIA 2011 PR
   Rogers C., 1997, THESIS
   Rosa JD, 2016, J LINGUIST ANTHROPOL, V26, P162, DOI 10.1111/jola.12116
   RUBIN DL, 1992, RES HIGH EDUC, V33, P511, DOI 10.1007/BF00973770
   Satone M., 2017, INT J ENG TRENDS TEC, V54
   Schneider EW, 2003, LANGUAGE, V79, P233, DOI 10.1353/lan.2003.0136
   Seidl A, 2012, FRONT PSYCHOL, V3, DOI [10.3389/fpsyg.2012.00448, 10.3389/fpsyg.2012.00479]
   Silverstein M., 1996, MATRIX LANGUAGE CONT, P284
   Sumner M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01015
   Trofimovich P, 2006, STUD SECOND LANG ACQ, V28, P1, DOI 10.1017/S0272263106060013
   Wickham H, 2016, GGPLOT2 ELEGANT GRAP
   Yi H.-G., 2013, J ACOUST SOC AM, V134, pEL387
   Yi HG, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00768
NR 65
TC 0
Z9 0
U1 1
U2 1
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0143-4632
EI 1747-7557
J9 J MULTILING MULTICUL
JI J. Multiling. Multicult. Develop.
DI 10.1080/01434632.2020.1835929
EA OCT 2020
PG 15
WC Linguistics; Language & Linguistics
SC Linguistics
GA OF3VV
UT WOS:000581140700001
DA 2021-02-24
ER

PT J
AU Simmons, D
   Dorsi, J
   Dias, JW
   Rosenblum, LD
AF Simmons, Dominique
   Dorsi, Josh
   Dias, James W.
   Rosenblum, Lawrence D.
TI Cross-modal transfer of talker-identity learning
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Multisensory processing; Speech perception; Face perception
ID SPEECH-PERCEPTION; SOURCE INFORMATION; FACE; VOICE; HEARING;
   IDENTIFICATION; RECOGNITION; ADAPTATION; LISTENERS; DISPLAYS
AB A speech signal carries information about meaning and about the talker conveying that meaning. It is now known that these two dimensions are related. There is evidence that gaining experience with a particular talker in one modality not only facilitates better phonetic perception in that modality, but also transfers across modalities to allow better phonetic perception in the other. This finding suggests that experience with a talker provides familiarity with some amodal properties of their articulation such that the experience can be shared across modalities. The present study investigates if experience with talker-specific articulatory information can also support cross-modaltalkerlearning. In Experiment1we show that participants can learn to identify ten novel talkers from point-light and sinewave speech, expanding on prior work. Point-light and sinewave speech also supported similar talker identification accuracies, and similar patterns of talker confusions were found across stimulus types. Experiment2showed these stimuli could also support cross-modal talker matching, further expanding on prior work. Finally, in Experiment3we show that learning to identify talkers in one modality (visual-only point-light speech) facilitates learning of those same talkers in another modality (auditory-only sinewave speech). These results suggest that some of the information for talker identity takes a modality-independent form.
C1 [Simmons, Dominique; Dorsi, Josh; Dias, James W.; Rosenblum, Lawrence D.] Univ Calif Riverside, Dept Psychol, Riverside, CA 92521 USA.
RP Rosenblum, LD (corresponding author), Univ Calif Riverside, Dept Psychol, Riverside, CA 92521 USA.
EM lawrence.rosenblum@ucr.edu
FU NSFNational Science Foundation (NSF) [1632530]
FX This research was supported by NSF grant 1632530 to LDR.
CR Allen JS, 2004, J ACOUST SOC AM, V115, P3171, DOI 10.1121/1.1701898
   Amerman JD, 1977, J PHONETICS, V5, P107, DOI 10.1016/S0095-4470(19)31122-2
   Arnold P, 2001, BRIT J PSYCHOL, V92, P339, DOI 10.1348/000712601162220
   Bladon RAW, 1976, J PHONETICS, V4, P137, DOI [10.1016/S0095-4470(19)31234-3, DOI 10.1016/S0095-4470(19)31234-3]
   Blank H, 2011, J NEUROSCI, V31, P12906, DOI 10.1523/JNEUROSCI.2091-11.2011
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bradlow AR, 1999, J ACOUST SOC AM, V106, P2074, DOI 10.1121/1.427952
   COHEN J, 1993, BEHAV RES METH INSTR, V25, P257, DOI 10.3758/BF03204507
   Fellowes JM, 1997, PERCEPT PSYCHOPHYS, V59, P839, DOI 10.3758/BF03205502
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Jesse A., 2017, ANN M AUD VIS SPEECH
   Jesse A, 2018, COGNITION, V176, P195, DOI 10.1016/j.cognition.2018.03.018
   Kamachi M, 2003, CURR BIOL, V13, P1709, DOI 10.1016/j.cub.2003.09.005
   Kitagawa N, 2002, NATURE, V416, P172, DOI 10.1038/416172a
   Konkle T, 2009, CURR BIOL, V19, P745, DOI 10.1016/j.cub.2009.03.035
   Lachs L, 2004, ECOL PSYCHOL, V16, P159, DOI 10.1207/s15326969eco1603_1
   Lachs L, 2004, J ACOUST SOC AM, V116, P507, DOI 10.1121/1.1757454
   Lachs L, 2004, J EXP PSYCHOL HUMAN, V30, P378, DOI 10.1037/0096-1523.30.2.378
   Levitan CA, 2015, SCI REP-UK, V5, DOI 10.1038/srep08857
   MATLAB, 2010, MATLAB VERS 7 10 0
   Matsumiya K, 2013, PSYCHOL SCI, V24, P2088, DOI 10.1177/0956797613486981
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   PERKELL JS, 1992, J ACOUST SOC AM, V91, P2911, DOI 10.1121/1.403778
   Reisberg D, 1987, HEARING EYE PSYCHOL, P97
   Remez RE, 1997, J EXP PSYCHOL HUMAN, V23, P651, DOI 10.1037/0096-1523.23.3.651
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   REMEZ RE, 1987, J EXP PSYCHOL HUMAN, V13, P40, DOI 10.1037/0096-1523.13.1.40
   Ricciardi E, 2014, NEUROSCI BIOBEHAV R, V41, P64, DOI 10.1016/j.neubiorev.2013.10.006
   Rosenblum LD, 2007, PSYCHOL SCI, V18, P392, DOI 10.1111/j.1467-9280.2007.01911.x
   Rosenblum LD, 2007, PERCEPTION, V36, P157, DOI 10.1068/p5613
   Rosenblum LD, 2005, BLACKW HBK LINGUIST, P51, DOI 10.1002/9780470757024.ch3
   Rosenblum LD, 2016, ECOL PSYCHOL, V28, P262, DOI 10.1080/10407413.2016.1230373
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   Rosenblum LD, 2006, PERCEPT PSYCHOPHYS, V68, P84, DOI 10.3758/BF03193658
   Rosenblum LD, 2002, PERCEPT PSYCHOPHYS, V64, P220, DOI 10.3758/BF03195788
   Rosenblum LD, 1996, J SPEECH HEAR RES, V39, P1159, DOI 10.1044/jshr.3906.1159
   Rosenblum LD, 1996, J EXP PSYCHOL HUMAN, V22, P318, DOI 10.1037/0096-1523.22.2.318
   Rosenthal R., 1991, ESSENTIALS BEHAV RES
   Sanchez K, 2013, ATTEN PERCEPT PSYCHO, V75, P1359, DOI 10.3758/s13414-013-0534-x
   Schall S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086325
   Seitz A, 2005, TRENDS COGN SCI, V9, P329, DOI 10.1016/j.tics.2005.05.010
   Sheffert SM, 2002, J EXP PSYCHOL HUMAN, V28, P1447, DOI 10.1037//0096-1523.28.6.1447
   Smith R, 2015, INDIVIDUAL DIFFERENC, P11
   Smith R, 2012, J PHONETICS, V40, P213, DOI 10.1016/j.wocn.2011.11.003
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   van der Zande P, 2014, J PHONETICS, V43, P38, DOI 10.1016/j.wocn.2014.01.003
   van der Zande P, 2014, SPEECH COMMUN, V59, P31, DOI 10.1016/j.specom.2014.01.001
   von Kriegstein K, 2005, J COGNITIVE NEUROSCI, V17, P367, DOI 10.1162/0898929053279577
   von Kriegstein K, 2006, PLOS BIOL, V4, P1809, DOI 10.1371/journal.pbio.0040326
NR 50
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD JAN
PY 2021
VL 83
IS 1
BP 415
EP 434
DI 10.3758/s13414-020-02141-9
EA OCT 2020
PG 20
WC Psychology; Psychology, Experimental
SC Psychology
GA QF8TK
UT WOS:000580406700007
PM 33083986
DA 2021-02-24
ER

PT J
AU Kortje, M
   Baumann, U
   Stover, T
   Weissgerber, T
AF Koertje, Monika
   Baumann, Uwe
   Stoever, Timo
   Weissgerber, Tobias
TI Sensitivity to interaural time differences and localization accuracy in
   cochlear implant users with combined electric-acoustic stimulation
SO PLOS ONE
LA English
DT Article
ID SOUND SOURCE LOCALIZATION; TEMPORAL-FINE-STRUCTURE; SPEECH-PERCEPTION;
   AUDITORY-SYSTEM; NORMAL-HEARING; NOISE; CUES; LISTENERS; RESPONSES;
   ENVELOPE
AB Objectives In this study, localization accuracy and sensitivity to acoustic interaural time differences (ITDs) in subjects using cochlear implants with combined electric-acoustic stimulation (EAS) were assessed and compared with the results of a normal hearing control group. Methods Eight CI users with EAS (2 bilaterally implanted, 6 unilaterally implanted) and symmetric binaural acoustic hearing and 24 normal hearing subjects participated in the study. The first experiment determined mean localization error (MLE) for different angles of sound incidence between +/- 60 degrees (frontal and dorsal presentation). The stimuli were either low-pass, high-pass or broadband noise bursts. In a second experiment, just noticeable differences (JND) of ITDs were measured for pure tones of 125 Hz, 250 Hz and 500 Hz (headphone presentation). Results Experiment 1: MLE of EAS subjects was 8.5 degrees, 14.3 degrees and 14.7 degrees, (low-, high-pass and broadband stimuli respectively). In the control group, MLE was 1.8 degrees (broadband stimuli). In the differentiation between sound incidence from front and back, EAS subjects performed on chance level. Experiment 2: The JND-ITDs were 88.7 mu s for 125 Hz, 48.8 mu s for 250 Hz and 52.9 mu s for 500 Hz (EAS subjects). Compared to the control group, JND-ITD for 125 Hz was on the same level of performance. No statistically significant correlation was found between MLE and JND-ITD in the EAS cohort. Conclusions Near to normal ITD sensitivity in the lower frequency acoustic hearing was demonstrated in a cohort of EAS users. However, in an acoustic localization task, the majority of the subjects did not reached the level of accuracy of normal hearing. Presumably, signal processing time delay differences between devices used on both sides are deteriorating the transfer of precise binaural timing cues.
C1 [Koertje, Monika; Baumann, Uwe; Weissgerber, Tobias] Goethe Univ Frankfurt, Univ Hosp Frankfurt, ENT Dept, Audiol Acoust, Frankfurt, Germany.
   [Stoever, Timo] Goethe Univ Frankfurt, Univ Hosp Frankfurt, ENT Dept, Frankfurt, Germany.
RP Kortje, M (corresponding author), Goethe Univ Frankfurt, Univ Hosp Frankfurt, ENT Dept, Audiol Acoust, Frankfurt, Germany.
EM monika.koertje@kgu.de
OI Koertje, Monika/0000-0003-2432-7609; Baumann, Uwe/0000-0002-1295-2661
FU German Research FoundationGerman Research Foundation (DFG) [337436298]
FX The study was funded by the German Research Foundation (Project Number
   337436298). The funders had no role in study design, data collection and
   analysis, decision to publish, or preparation of the manuscript.
CR Aronoff JM, 2010, J ACOUST SOC AM, V127, pEL87, DOI 10.1121/1.3298451
   Baumann U, 2009, HNO, V57, P542, DOI 10.1007/s00106-009-1923-2
   Bernstein JGW, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518765514
   Blauert J., 1997, SPATIAL HEARING PSYC
   Dietz M, 2013, P NATL ACAD SCI USA, V110, P15151, DOI 10.1073/pnas.1309712110
   Dillon H., 2003, HEAR J, V56, P30
   Doge J, 2017, OTOL NEUROTOL, V38, pE563, DOI 10.1097/MAO.0000000000001520
   Dunn CC, 2010, J AM ACAD AUDIOL, V21, P44, DOI 10.3766/jaaa.21.1.6
   Francart T, 2009, JARO-J ASSOC RES OTO, V10, P131, DOI 10.1007/s10162-008-0145-8
   Fullgrabe C, 2013, AM J AUDIOL, V22, P313, DOI 10.1044/1059-0889(2013/12-0070)
   Gifford RH, 2020, HEARING RES, V390, DOI 10.1016/j.heares.2020.107929
   Gifford RH, 2017, EAR HEARING, V38, P539, DOI 10.1097/AUD.0000000000000418
   Gifford RH, 2014, HEARING RES, V312, P28, DOI 10.1016/j.heares.2014.02.007
   Gifford RH, 2013, EAR HEARING, V34, P413, DOI 10.1097/AUD.0b013e31827e8163
   Grantham DW, 2007, EAR HEARING, V28, P524, DOI 10.1097/AUD.0b013e31806dc21a
   Grothe B, 2010, PHYSIOL REV, V90, P983, DOI 10.1152/physrev.00026.2009
   HAHLBROCK K H, 1953, Arch Ohren Nasen Kehlkopfheilkd, V162, P394, DOI 10.1007/BF02105664
   Helbig S, 2016, OTOL NEUROTOL, V37, pE353, DOI 10.1097/MAO.0000000000001066
   Hildebrandt KJ, 2015, PLOS BIOL, V13, DOI 10.1371/journal.pbio.1002096
   Jones H, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514554574
   Killan C, 2019, EAR HEARING, V40, P870, DOI 10.1097/AUD.0000000000000666
   Lammers MJW, 2014, OTOL NEUROTOL, V35, P1433, DOI 10.1097/MAO.0000000000000433
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Loiselle LH, 2016, J SPEECH LANG HEAR R, V59, P810, DOI 10.1044/2015_JSLHR-H-14-0355
   Loiselle LH, 2015, AUDIOL NEURO-OTOL, V20, P166, DOI 10.1159/000367883
   Moore, 2013, INTRO PSYCHOL HEARIN
   Moore BCJ, 2018, J ACOUST SOC AM, V143, P1287, DOI 10.1121/1.5025845
   Mueller Martin F, 2014, Cochlear Implants Int, V15, P36, DOI 10.1179/1754762813Y.0000000040
   Ochi A, 2016, ADV EXP MED BIOL, V894, P19, DOI 10.1007/978-3-319-25474-6_3
   Ozmeral EJ, 2016, J NEUROPHYSIOL, V116, P2720, DOI 10.1152/jn.00560.2016
   Papesh MA, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00124
   Plant K, 2016, INT J AUDIOL, V55, pS31, DOI 10.3109/14992027.2016.1150609
   Rader T, 2015, HNO, V63, P85, DOI 10.1007/s00106-014-2943-0
   Risoud M, 2020, EUR ANN OTORHINOLARY, V137, P21, DOI 10.1016/j.anorl.2019.09.007
   Ross B, 2007, J NEUROSCI, V27, P11172, DOI 10.1523/JNEUROSCI.1813-07.2007
   Seebacher J, 2019, HEARING RES, V371, P19, DOI 10.1016/j.heares.2018.10.015
   Seeber B, 2002, ACTA ACUST UNITED AC, V88, P446
   Seeber BU, 2008, J ACOUST SOC AM, V123, P1030, DOI 10.1121/1.2821965
   Spencer NJ, 2016, J ACOUST SOC AM, V140, P1783, DOI 10.1121/1.4962444
   Veugen LCE, 2016, HEARING RES, V336, P72, DOI 10.1016/j.heares.2016.04.008
   von Ilberg C, 1999, ORL J OTO-RHINO-LARY, V61, P334, DOI 10.1159/000027695
   von Ilberg CA, 2011, AUDIOL NEURO-OTOL, V16, P1, DOI 10.1159/000327765
   Weissgerber T, 2014, DGA 2014
   Yost WA, 2017, J ACOUST SOC AM, V142, P173, DOI 10.1121/1.4990656
   Zirn S, 2015, HEARING RES, V328, P148, DOI 10.1016/j.heares.2015.08.010
   Zirn S, 2018, J ACOUST SOC AM, V143, P1939, DOI [10.1121/1.5036343, DOI 10.1121/1.5036343]
   Zirn S, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216519843876
NR 47
TC 0
Z9 0
U1 0
U2 0
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD OCT 19
PY 2020
VL 15
IS 10
AR e0241015
DI 10.1371/journal.pone.0241015
PG 17
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA OM3IS
UT WOS:000585920200029
PM 33075114
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Lu, LX
   Ding, Y
   Xue, CW
   Li, L
AF Lu, Lingxi
   Ding, Yu
   Xue, Chuanwei
   Li, Liang
TI Negative emotions in the target speaker's voice enhance speech
   recognition under "cocktail-party" environments
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Cocktail-party problem; Speech unmasking; Vocal cue; Emotion; Perceived
   spatial separation
ID PERCEIVED SPATIAL SEPARATION; INFORMATIONAL MASKING; ENERGETIC MASKING;
   PERCEPTION; ATTENTION; RELEASE; PROSODY; YOUNGER
AB Under a "cocktail-party" environment with simultaneous multiple talkers, recognition of target speech is effectively improved by a number of perceptually unmasking cues. It remains unclear whether emotions embedded in the target-speaker's voice can either improve speech perception alone or interact with other cues facilitating speech perception against a masker background. This study used two target-speaker voices with different emotional valences to examine whether recognition of target speech is modulated by the emotional valence when the target speech and the maskers were perceptually co-located or separated. The results showed that both the speech recognition against the masker background and the separation-induced unmasking effect were higher for the target speaker with a negatively emotional voice than for the target speaker with a positively emotional voice. Moreover, when the negative voice was fear conditioned, the target-speech recognition was further improved against speech informational masking. These results suggested that the emotionally vocal unmasking cue interacts significantly with the perceived spatial-separation unmasking cue, facilitating the unmasking effect against a masking background. Thus, emotional features embedded in the target-speaker's vocal timbre are also useful for unmasking the target speech in "cocktail-party" environments.
C1 [Lu, Lingxi; Ding, Yu; Li, Liang] Peking Univ, Sch Psychol & Cognit Sci, Beijing 100080, Peoples R China.
   [Lu, Lingxi; Ding, Yu; Li, Liang] Peking Univ, Minist Educ, Key Lab Machine Percept, Speech & Hearing Res Ctr, Beijing, Peoples R China.
   [Xue, Chuanwei; Li, Liang] Capital Med Univ, Beijing Inst Brain Disorders, Beijing, Peoples R China.
RP Li, L (corresponding author), Peking Univ, Sch Psychol & Cognit Sci, Beijing 100080, Peoples R China.; Li, L (corresponding author), Peking Univ, Minist Educ, Key Lab Machine Percept, Speech & Hearing Res Ctr, Beijing, Peoples R China.; Li, L (corresponding author), Capital Med Univ, Beijing Inst Brain Disorders, Beijing, Peoples R China.
EM liangli@pku.edu.cn
FU National Natural Sciences Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [31771252]
FX This work was supported by the National Natural Sciences Foundation of
   China (31771252).
CR Arbogast TL, 2002, J ACOUST SOC AM, V112, P2086, DOI 10.1121/1.1510141
   Arons B., 1992, J AM VOICE I O SOC, V12, P35
   Bradley M. M., 2007, INT AFFECTIVE PICTUR, P29
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Bragman A. S, 1994, AUDITORY SCENE ANAL
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Bregman AS., 1994, AUDITORY SCENE ANAL
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Case J, 2018, J ACOUST SOC AM, V144, pEL497, DOI 10.1121/1.5081469
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Dupuis K, 2014, EAR HEARING, V35, P695, DOI 10.1097/AUD.0000000000000082
   Dupuis K, 2010, PSYCHOL AGING, V25, P16, DOI 10.1037/a0018777
   Eastwood JD, 2001, PERCEPT PSYCHOPHYS, V63, P1004, DOI 10.3758/BF03194519
   Fox E, 2002, COGN AFFECT BEHAV NE, V2, P52, DOI 10.3758/CABN.2.1.52
   Freyman RL, 2004, J ACOUST SOC AM, V115, P2246, DOI 10.1121/1.1689343
   Freyman RL, 1999, J ACOUST SOC AM, V106, P3578, DOI 10.1121/1.428211
   Freyman RL, 2001, J ACOUST SOC AM, V109, P2112, DOI 10.1121/1.1354984
   Fruhholz S, 2016, NEUROSCI BIOBEHAV R, V68, P96, DOI 10.1016/j.neubiorev.2016.05.002
   Gordon MS, 2017, Q J EXP PSYCHOL, V70, P163, DOI 10.1080/17470218.2015.1130069
   Gordon MS, 2011, Q J EXP PSYCHOL, V64, P730, DOI 10.1080/17470218.2010.516835
   Grandjean D, 2005, NAT NEUROSCI, V8, P145, DOI 10.1038/nn1392
   Haykin S, 2005, NEURAL COMPUT, V17, P1875, DOI 10.1162/0899766054322964
   Helfer KS, 1997, J SPEECH LANG HEAR R, V40, P432, DOI 10.1044/jslhr.4002.432
   Holmes E, 2018, PSYCHOL SCI, V29, P1575, DOI 10.1177/0956797618779083
   Huang Y, 2010, EAR HEARING, V31, P579, DOI 10.1097/AUD.0b013e3181db6dc2
   Huang Y, 2009, J EXP PSYCHOL HUMAN, V35, P1618, DOI 10.1037/a0015791
   Iwashiro N, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083201
   Jeong JW, 2011, NEUROIMAGE, V54, P2973, DOI 10.1016/j.neuroimage.2010.11.017
   Johnsrude IS, 2013, PSYCHOL SCI, V24, P1995, DOI 10.1177/0956797613482467
   Koster EHW, 2005, COGNITION EMOTION, V19, P771, DOI 10.1080/02699930441000418
   Levi SV, 2011, J ACOUST SOC AM, V130, P4053, DOI 10.1121/1.3651816
   Li HH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0063106
   Li L, 2004, J EXP PSYCHOL HUMAN, V30, P1077, DOI 10.1037/0096-1523.30.6.1077
   Lu LX, 2018, ATTEN PERCEPT PSYCHO, V80, P871, DOI 10.3758/s13414-018-1489-8
   New JJ, 2015, EVOL HUM BEHAV, V36, P165, DOI 10.1016/j.evolhumbehav.2014.08.004
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   Ohman A, 2001, J EXP PSYCHOL GEN, V130, P466, DOI 10.1037/0096-3445.130.3.466
   Pischek-Simpson LK, 2009, BEHAV RES THER, V47, P322, DOI 10.1016/j.brat.2009.01.007
   POLLACK I, 1954, J ACOUST SOC AM, V26, P403, DOI 10.1121/1.1907349
   Sander D, 2005, NEUROIMAGE, V28, P848, DOI 10.1016/j.neuroimage.2005.06.023
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Schneider BA, 2007, J AM ACAD AUDIOL, V18, P559, DOI 10.3766/jaaa.18.7.4
   SINGER W, 1993, ANNU REV PHYSIOL, V55, P349, DOI 10.1146/annurev.ph.55.030193.002025
   Spreadborough K. L., 2018, PSYCHOL MUSIC
   von der Malsburg C, 1999, NEURON, V24, P95, DOI 10.1016/S0896-6273(00)80825-9
   Vuilleumier P, 2005, TRENDS COGN SCI, V9, P585, DOI 10.1016/j.tics.2005.10.011
   Wallach H, 1949, J ACOUST SOC AM, V21, P468, DOI [10.1121/1.1917119, DOI 10.1121/1.1917119]
   Wolfram S., 1991, MATH SYSTEM DOING MA
   Wu X., 2007, INTERSPEECH, P390
   Wu XH, 2005, HEARING RES, V199, P1, DOI 10.1016/j.heares.2004.03.010
   Yang ZG, 2007, SPEECH COMMUN, V49, P892, DOI 10.1016/j.specom.2007.05.005
NR 51
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD JAN
PY 2021
VL 83
IS 1
BP 247
EP 259
DI 10.3758/s13414-020-02149-1
EA OCT 2020
PG 13
WC Psychology; Psychology, Experimental
SC Psychology
GA QF8TK
UT WOS:000579709300002
PM 33078380
DA 2021-02-24
ER

PT J
AU Chen, HC
   Han, QW
AF Chen, Hsueh Chu
   Han, Qian Wen
TI The effects of metaphonological awareness training on L3 Mandarin tone
   acquisition by Cantonese learners
SO INTERNATIONAL JOURNAL OF MULTILINGUALISM
LA English
DT Article; Early Access
DE Mandarin tone; metaphonological awareness; verbal protocols
ID PERCEPTION; ENGLISH; L2; PRONUNCIATION; INSTRUCTION; L1
AB According to the speech learning model [Flege, J. E. (1995). Second language speech learning: Theory, findings, and problems. In W. Strange (Ed.),Speech perception and linguistic experience: Issues in cross-language research(pp. 233-277). York Press], learners whose first language (L1) is a tonal language (e.g. Cantonese) can be confused by similar yet different tones in their L1 and another tonal language (e.g. Mandarin). Encouraged by the biliteracy and trilingualism language policy in Hong Kong, L1 Cantonese learners of Mandarin have been committed to learning the third language (L3) Mandarin tones but are struggling with that task. The main purpose of this study is to examine Cantonese learners' perceptions and production of Mandarin tones, and to investigate learners' performance in production tasks before and after implementing metaphonological awareness protocols. Twenty-five Cantonese learners studying at a local university were recruited to complete the production, perception and verbal protocol tasks. Based on Wrembel's [2015. Metaphonologcial awareness in multilinguals: A case of L3 Polish.Language Awareness,24(1), 60-83. https://doi.org/10.1080/09658416.2014.890209] framework, this study categorised the participants' statements of metaphonological awareness shown in their self-correction and self-reflection performances in the introspective and retrospective protocols. The error rates and patterns in the production and perception tasks were analysed. Metaphonological awareness training has a significant positive effect on improving learners' Mandarin tone pronunciation.
C1 [Chen, Hsueh Chu] Educ Univ Hong Kong, Dept Linguist & Modern Language Studies, Taipo, 10 LoPing Rd, Hong Kong, Peoples R China.
   [Han, Qian Wen] City Univ Hong Kong, Dept Linguist & Translat, Kowloon, Hong Kong, Peoples R China.
RP Chen, HC (corresponding author), Educ Univ Hong Kong, Dept Linguist & Modern Language Studies, Taipo, 10 LoPing Rd, Hong Kong, Peoples R China.
EM hsuehchu@eduhk.hk
OI CHEN, Hsueh Chu/0000-0003-0947-7246; Han, Qianwen/0000-0001-9144-9724
FU Education University of Hong Kong
FX This work was supported by The Education University of Hong Kong [grant
   number Internal Research Fund].
CR Aarts F., 1982, STUDIA ANGLICA POSNA, V14
   Angelovska T., 2014, GRAMMAR DIMENSION IN
   Angelovska T, 2018, LANG AWARE, V27, P136, DOI 10.1080/09658416.2018.1431243
   Angelovska T, 2017, STUD SECOND LANG LE, V7, P397, DOI 10.14746/ssllt.2017.7.3.3
   Benedict P. K., 1997, MODERN CANTONESE PHO
   BIALYSTOK E, 1982, APPL LINGUIST, V3, P181, DOI 10.1093/applin/3.3.181
   Chao Y. R., 1930, MAITRE PHONETIQUE, V45, P24
   Chao Yuen Ren, 1968, GRAMMAR SPOKEN CHINE
   Chen HC, 2019, INT J MULTILING, V16, P492, DOI 10.1080/14790718.2019.1573901
   Corder S., 1973, INTRO APPL LINGUISTI
   Duanmu S., 2000, PHONOLOGY STANDARD C
   Duncan LG, 2000, Q J EXP PSYCHOL-A, V53, P1081
   Ellis R, 2006, APPL LINGUIST, V27, P431, DOI 10.1093/applin/aml022
   Fallahi M., 1991, CONTRASTIVE LINGUIST
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   Gibson M, 2011, SECOND LANG ACQUIS, P74
   Hao Y, 2012, THESIS
   Jessner U., 2006, LINGUISTIC AWARENESS
   Kopeckova R, 2018, LANG AWARE, V27, P153, DOI 10.1080/09658416.2018.1432629
   Lado R., 1957, LINGUISTIC CULTURE
   Lee K. A., 2002, THESIS
   Li DCS, 2017, MULTILINGUAL HONG KO
   Li XX, 2017, BILING-LANG COGN, V20, P549, DOI 10.1017/S1366728916000195
   Medina A. D., 2008, THESIS
   MOLHOLT G, 1988, TESOL QUART, V22, P91, DOI 10.2307/3587063
   Osburne A. G., 2003, IRAL-INT REV APPL LI, V41, P131, DOI DOI 10.1515/IRAL.2003.005
   Peng G, 2012, J SPEECH LANG HEAR R, V55, P579, DOI 10.1044/1092-4388(2011/11-0025)
   Rahimpour M, 2011, INT J ENGL LINGUIST, V1, P73, DOI 10.5539/ijel.v1n2p73
   Ringbom H., 1994, ENCY LANGUAGE LINGUI
   Roehr K., 2006, LANGUAGE AWARENESS, V15, P180, DOI [10.2167/la403.0, DOI 10.2167/LA403.0]
   Schmidt R., 2001, COGNITION 2 LANGUAGE, P3, DOI DOI 10.1017/CBO9781139524780.003
   Serrano R, 2011, LANG AWARE, V20, P1, DOI 10.1080/09658416.2010.529911
   Sharwood S.M., 2007, ENCY LANGUAGE ED, V6
   So C. K., 2005, J ACOUST SOC AM, V177, DOI [10.1121/1.4786607, DOI 10.1121/1.4786607]
   WARDHAUGH R, 1970, TESOL QUART, V4, P63, DOI 10.2307/3585779
   WHITMAN RL, 1972, LANG LEARN, V22, P29, DOI 10.1111/j.1467-1770.1972.tb00071.x
   Wrembel M., 2013, METALINGUISTIC DIMEN, P119
   Wrembel M, 2015, LANG AWARE, V24, P60, DOI 10.1080/09658416.2014.890209
   Yarmohammadi L., 1996, CONTRASTIVE PHONOLOG
   Zhang KL, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01982
NR 41
TC 0
Z9 0
U1 6
U2 6
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1479-0718
EI 1747-7530
J9 INT J MULTILING
JI Int. J. Multiling.
DI 10.1080/14790718.2020.1820509
EA OCT 2020
PG 20
WC Education & Educational Research; Linguistics; Language & Linguistics
SC Education & Educational Research; Linguistics
GA OD2FD
UT WOS:000579668200001
DA 2021-02-24
ER

PT J
AU Forseth, KJ
   Hickok, G
   Rollo, PS
   Tandon, N
AF Forseth, K. J.
   Hickok, G.
   Rollo, P. S.
   Tandon, N.
TI Language prediction mechanisms in human auditory cortex
SO NATURE COMMUNICATIONS
LA English
DT Article
ID LOW-FREQUENCY OSCILLATIONS; NEURONAL OSCILLATIONS; CORTICAL
   OSCILLATIONS; GAMMA ACTIVITY; SPEECH; DYNAMICS; ENTRAINMENT; PATTERNS;
   RHYTHMS; LOCALIZATION
AB Spoken language, both perception and production, is thought to be facilitated by an ensemble of predictive mechanisms. We obtain intracranial recordings in 37 patients using depth probes implanted along the anteroposterior extent of the supratemporal plane during rhythm listening, speech perception, and speech production. These reveal two predictive mechanisms in early auditory cortex with distinct anatomical and functional characteristics. The first, localized to bilateral Heschl's gyri and indexed by low-frequency phase, predicts the timing of acoustic events. The second, localized to planum temporale only in language-dominant cortex and indexed by high-gamma power, shows a transient response to acoustic stimuli that is uniquely suppressed during speech production. Chronometric stimulation of Heschl's gyrus selectively disrupts speech perception, while stimulation of planum temporale selectively disrupts speech production. This work illuminates the fundamental acoustic infrastructure-both architecture and function-for spoken language, grounding cognitive models of speech perception and production in human neurobiology. The human brain fluently parses continuous speech during perception and production. Using direct brain recordings coupled with stimulation, the authors identify separable substrates underlying two distinct predictive mechanisms of "when" in Heschl's gyrus and "what" in planum temporale.
C1 [Forseth, K. J.; Rollo, P. S.; Tandon, N.] McGovern Med Sch, Vivian L Smith Dept Neurosurg, Houston, TX 77030 USA.
   [Hickok, G.] Univ Calif Irvine, Dept Cognit Sci, Irvine, CA 92717 USA.
   [Tandon, N.] Texas Med Ctr, Mem Hermann Hosp, Houston, TX 77030 USA.
RP Tandon, N (corresponding author), McGovern Med Sch, Vivian L Smith Dept Neurosurg, Houston, TX 77030 USA.; Tandon, N (corresponding author), Texas Med Ctr, Mem Hermann Hosp, Houston, TX 77030 USA.
EM nitin.tandon@uth.tmc.edu
OI Forseth, Kiefer/0000-0003-1624-8329; Tandon, Nitin/0000-0002-2752-2365
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [1F30DC017083]; National Institute of
   Neurological Disorders and StrokeUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute of Neurological Disorders & Stroke (NINDS) [5U01NS098981]
FX We thank all the patients who participated in this study; laboratory
   members at the Tandon lab (Matthew Rollo and Jessica Johnson);
   neurologists at the Texas Comprehensive Epilepsy Program (Jeremy Slater,
   Giridhar Kalamangalam, Omotola Hope, Melissa Thomas) who participated in
   the care of these patients; and all the nurses and technicians in the
   Epilepsy Monitoring Unit at Memorial Hermann Hospital who helped make
   this research possible. This work was supported by the National
   Institute on Deafness and Other Communication Disorders 5R01DC014589,
   National Institute of Neurological Disorders and Stroke 5U01NS098981,
   and National Institute on Deafness and Other Communication Disorders
   1F30DC017083.
CR Ahissar E, 2005, AUDITORY CORTEX: SYNTHESIS OF HUMAN AND ANIMAL RESEARCH, P295
   Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Aliu SO, 2009, J COGNITIVE NEUROSCI, V21, P791, DOI 10.1162/jocn.2009.21055
   Argall BD, 2006, HUM BRAIN MAPP, V27, P14, DOI 10.1002/hbm.20158
   Arieli A, 1996, SCIENCE, V273, P1868, DOI 10.1126/science.273.5283.1868
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Berry MW, 2007, COMPUT STAT DATA AN, V52, P155, DOI 10.1016/j.csda.2006.11.006
   Bruns A, 2000, NEUROREPORT, V11, P1509, DOI 10.1097/00001756-200005150-00028
   Buzsaki G, 2012, NAT REV NEUROSCI, V13, P407, DOI 10.1038/nrn3241
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   Cravo AM, 2011, J NEUROPHYSIOL, V106, P2964, DOI 10.1152/jn.00157.2011
   CREUTZFELDT O, 1989, EXP BRAIN RES, V77, P451, DOI 10.1007/BF00249600
   Crone NE, 2001, CLIN NEUROPHYSIOL, V112, P565, DOI 10.1016/S1388-2457(00)00545-9
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P1053, DOI 10.1121/1.408467
   Ellmore TM, 2010, NEUROIMAGE, V49, P2033, DOI 10.1016/j.neuroimage.2009.10.055
   Ermentrout GB, 2001, NEURON, V29, P33, DOI 10.1016/S0896-6273(01)00178-7
   Fischl B, 1999, HUM BRAIN MAPP, V8, P272, DOI 10.1002/(SICI)1097-0193(1999)8:4<272::AID-HBM10>3.0.CO;2-4
   Flinker A, 2010, J NEUROSCI, V30, P16643, DOI 10.1523/JNEUROSCI.1809-10.2010
   Forseth KJ, 2018, BRAIN, V141, P2112, DOI 10.1093/brain/awy120
   Fries P, 2005, TRENDS COGN SCI, V9, P474, DOI 10.1016/j.tics.2005.08.011
   Ghitza O, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00130
   Ghitza O, 2009, PHONETICA, V66, P113, DOI 10.1159/000208934
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Gonzalez-Martinez J, 2016, NEUROSURGERY, V78, P169, DOI 10.1227/NEU.0000000000001034
   Guenther FH, 2006, J COMMUN DISORD, V39, P350, DOI 10.1016/j.jcomdis.2006.06.013
   Haegens S, 2018, NEUROSCI BIOBEHAV R, V86, P150, DOI 10.1016/j.neubiorev.2017.12.002
   Hamberger MJ, 2003, J INT NEUROPSYCH SOC, V9, P479, DOI 10.1017/S135561770393013X
   Hamilton LS, 2018, CURR BIOL, V28, P1860, DOI 10.1016/j.cub.2018.04.033
   Held R., 1958, PERCEPT MOTOR SKILL, V8, P87, DOI DOI 10.2466/PMS.1958.8.3.87
   Henry MJ, 2012, P NATL ACAD SCI USA, V109, P20095, DOI 10.1073/pnas.1213390109
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2015, PSYCHOL SCI, V26, P1006, DOI 10.1177/0956797615576533
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158
   Hopfield JJ, 2004, P NATL ACAD SCI USA, V101, P6255, DOI 10.1073/pnas.0401125101
   Houde JF, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00082
   Howard MF, 2012, NEUROIMAGE, V60, P2118, DOI 10.1016/j.neuroimage.2012.02.028
   Howard MF, 2010, J NEUROPHYSIOL, V104, P2500, DOI 10.1152/jn.00251.2010
   Jensen O, 2012, TRENDS COGN SCI, V16, P200, DOI 10.1016/j.tics.2012.03.002
   Kadipasaoglu CM, 2014, NEUROIMAGE, V101, P215, DOI 10.1016/j.neuroimage.2014.07.006
   Keller GB, 2018, NEURON, V100, P424, DOI 10.1016/j.neuron.2018.10.003
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Lakatos P, 2005, J NEUROPHYSIOL, V94, P1904, DOI 10.1152/jn.00263.2005
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735
   LIEGEOISCHAUVEL C, 1991, BRAIN, V114, P139
   Lotto AJ, 2016, NEUROBIOL LANG, DOI [10.1016/B978-0-12-407794-2.00016-X, DOI 10.1016/B978-0-12-407794-2.00016-X]
   Luo H, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000445
   Monto S, 2008, J NEUROSCI, V28, P8268, DOI 10.1523/JNEUROSCI.1910-08.2008
   Muller L, 2016, ELIFE, V5, DOI 10.7554/eLife.17267
   MULLERPREUSS P, 1981, BRAIN RES, V215, P61, DOI 10.1016/0006-8993(81)90491-1
   Neuling T, 2012, NEUROIMAGE, V63, P771, DOI 10.1016/j.neuroimage.2012.07.024
   Ng BSW, 2012, J NEUROSCI, V32, P12268, DOI 10.1523/JNEUROSCI.1877-12.2012
   Nobrel AC, 2007, CURR OPIN NEUROBIOL, V17, P465, DOI 10.1016/j.conb.2007.07.006
   Okada K, 2018, PSYCHON B REV, V25, P423, DOI 10.3758/s13423-017-1284-x
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Pieters TA, 2013, J NEUROSURG, V118, P1086, DOI 10.3171/2013.2.JNS121450
   Roberts TPL, 1996, NEUROREPORT, V7, P1138, DOI 10.1097/00001756-199604260-00007
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Saad ZS, 2012, NEUROIMAGE, V62, P768, DOI 10.1016/j.neuroimage.2011.09.016
   Schroeder CE, 2010, CURR OPIN NEUROBIOL, V20, P172, DOI 10.1016/j.conb.2010.02.010
   Schroeder CE, 2009, TRENDS NEUROSCI, V32, P9, DOI 10.1016/j.tins.2008.09.012
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   SPERRY RW, 1950, J COMP PHYSIOL PSYCH, V43, P482, DOI 10.1037/h0055479
   Stefanics G, 2010, J NEUROSCI, V30, P13578, DOI 10.1523/JNEUROSCI.0703-10.2010
   Tandon N., 2012, CLIN BRAIN MAPPING, P203
   Tandon N, 2008, TXB EPILEPSY SURG, P1001, DOI DOI 10.3109/9780203091708-129
   Tandon N, 2019, JAMA NEUROL, V76, P672, DOI 10.1001/jamaneurol.2019.0098
   Towle VL, 2008, BRAIN, V131, P2013, DOI 10.1093/brain/awn147
   Wada J, 2007, J NEUROSURG, V106, P1117, DOI 10.3171/jns.2007.106.6.1117
   Zhang HH, 2018, NEURON, V98, P1269, DOI 10.1016/j.neuron.2018.05.019
   Zoefel B, 2017, NEUROIMAGE, V150, P344, DOI 10.1016/j.neuroimage.2017.02.014
   Zoefel B, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00262
NR 74
TC 0
Z9 0
U1 2
U2 2
PU NATURE RESEARCH
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2041-1723
J9 NAT COMMUN
JI Nat. Commun.
PD OCT 16
PY 2020
VL 11
IS 1
AR 5240
DI 10.1038/s41467-020-19010-6
PG 14
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA OG7JV
UT WOS:000582056600003
PM 33067457
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Quam, C
   Clough, L
   Knight, S
   Gerken, L
AF Quam, Carolyn
   Clough, Lauren
   Knight, Sara
   Gerken, LouAnn
TI Infants' discrimination of consonant contrasts in the presence and
   absence of talker variability
SO INFANCY
LA English
DT Article
ID SPEECH-PERCEPTION; PHONETIC DETAIL; STIMULUS VARIABILITY; MONTE-CARLO;
   1ST YEAR; CUES; SENSITIVITY; WORDS; CONSEQUENCES; INFORMATION
AB To learn speech-sound categories, infants must identify the acoustic dimensions that differentiate categories and selectively attend to them as opposed to irrelevant dimensions. Variability on irrelevant acoustic dimensions can aid formation of robust categories in infants through adults in tasks such as word learning (e.g., Rost and McMurray, 2009) or speech-sound learning (e.g., Lively et al., 1993). At the same time, variability sometimes overwhelms learners, interfering with learning and processing. Two prior studies (Kuhl & Miller, 1982; Jusczyk, Pisoni, & Mullennix, 1992) found that irrelevant variability sometimes impaired early sound discrimination. We asked whether variability would impair or facilitate discrimination for older infants, comparing 7.5-month-old infants' discrimination of an early acquired native contrast, /p/ vs. /b/ (in the word forms /pIm/ vs. /bIm/), in Experiment 1, with an acoustically subtle, non-native contrast, /n/ vs. /LATIN SMALL LETTER ENG/ (in /nIm/ vs. /LATIN SMALL LETTER ENGIm/), in Experiment 2. Words were spoken by one or four talkers. Infants discriminated the native but not the non-native contrast, and there were no significant effects of talker condition. We discuss implications for theories of phonological learning and avenues for future research.
C1 [Quam, Carolyn] Portland State Univ, Dept Speech & Hearing Sci, Portland, OR 97207 USA.
   [Quam, Carolyn] Univ Arizona, Dept Speech Language & Hearing Sci, Tucson, AZ USA.
   [Quam, Carolyn; Knight, Sara; Gerken, LouAnn] Univ Arizona, Dept Psychol, Tucson, AZ 85721 USA.
   [Clough, Lauren] Univ Arizona, Dept Educ Psychol, Tucson, AZ USA.
   [Clough, Lauren] Univ Arizona, Dept Linguist, Tucson, AZ USA.
   [Knight, Sara] Univ Arizona, Dept Psychiat, Tucson, AZ 85721 USA.
RP Quam, C (corresponding author), Portland State Univ, Dept Speech & Hearing Sci, POB 751, Portland, OR 97207 USA.
EM cquam@pdx.edu
OI Quam, Carolyn/0000-0003-2607-8597
FU Eunice Kennedy Shriver National Institute of Child Health and Human
   DevelopmentUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [F32HD065382];
   Division of Behavioral and Cognitive SciencesNational Science Foundation
   (NSF)NSF - Directorate for Social, Behavioral & Economic Sciences (SBE)
   [0950601]
FX Eunice Kennedy Shriver National Institute of Child Health and Human
   Development, Grant/Award Number: F32HD065382; Division of Behavioral and
   Cognitive Sciences, Grant/Award Number: 0950601
CR [Anonymous], 2008, COGNITION, V106, P833, DOI 10.1016/j.cognition.2007.05.002
   Antoniou M, 2016, J ACOUST SOC AM, V139, P271, DOI 10.1121/1.4939736
   Apfelbaum KS, 2011, COGNITIVE SCI, V35, P1105, DOI 10.1111/j.1551-6709.2011.01181.x
   Bates E., 1995, HDB CHILD LANGUAGE, P95, DOI 10.1111/b.9780631203124.1996.00005.X
   Bergelson E, 2018, CHILD DEV, V89, P1567, DOI 10.1111/cdev.12888
   Bosch L, 2003, LANG SPEECH, V46, P217, DOI 10.1177/00238309030460020801
   Cohen J., 1988, STAT POWER ANAL BEHA
   Cohen L.B, 2004, HABIT X NEW PROGRAM
   Creel SC, 2010, J EXP PSYCHOL LEARN, V36, P110, DOI 10.1037/a0017527
   DANNEMILLER JL, 1984, INFANT BEHAV DEV, V7, P147, DOI 10.1016/S0163-6383(84)80055-7
   Davis A., 2015, THESIS
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Fennell CT, 2010, CHILD DEV, V81, P1376, DOI 10.1111/j.1467-8624.2010.01479.x
   Fennell CT, 2003, LANG SPEECH, V46, P245, DOI 10.1177/00238309030460020901
   Gerken L, 2005, J CHILD LANG, V32, P249, DOI 10.1017/S0305000904006786
   Gerken L, 2015, COGNITION, V143, P187, DOI 10.1016/j.cognition.2015.04.018
   GLASS GV, 1972, REV EDUC RES, V42, P237, DOI 10.2307/1169991
   Gonzales K, 2018, COGNITIVE PSYCHOL, V106, P1, DOI 10.1016/j.cogpsych.2018.04.003
   HARWELL MR, 1992, J EDUC STAT, V17, P315, DOI 10.3102/10769986017004315
   Hohle B, 2020, DEVELOPMENTAL SCI, V23, DOI 10.1111/desc.12950
   Houston DM, 2000, J EXP PSYCHOL HUMAN, V26, P1570, DOI 10.1037/0096-1523.26.5.1570
   Jusczyk PW, 1999, J MEM LANG, V40, P62, DOI 10.1006/jmla.1998.2605
   JUSCZYK PW, 1992, COGNITION, V43, P253, DOI 10.1016/0010-0277(92)90014-9
   JUSCZYK PW, 1993, J MEM LANG, V32, P402, DOI 10.1006/jmla.1993.1022
   Kidd C, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036399
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   KUHL PK, 1983, INFANT BEHAV DEV, V6, P263, DOI 10.1016/S0163-6383(83)80036-8
   KUHL PK, 1982, PERCEPT PSYCHOPHYS, V31, P279, DOI 10.3758/BF03202536
   Legendre P L, 1998, NUMERICAL ECOLOGY
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Mazuka R, 2014, DEV PSYCHOBIOL, V56, P192, DOI 10.1002/dev.21193
   Medina TN, 2011, P NATL ACAD SCI USA, V108, P9014, DOI 10.1073/pnas.1105040108
   Narayan CR, 2008, J PHONETICS, V36, P191, DOI 10.1016/j.wocn.2007.10.001
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Oakes LM, 2010, J COGN DEV, V11, P255, DOI 10.1080/15248371003699977
   Perrachione TK, 2011, J ACOUST SOC AM, V130, P461, DOI 10.1121/1.3593366
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Potter CE, 2017, COGNITION, V166, P67, DOI 10.1016/j.cognition.2017.05.031
   Quam C, 2017, LAB PHONOL, V8, DOI 10.5334/labphon.25
   Quam C, 2014, J EXP CHILD PSYCHOL, V123, P73, DOI 10.1016/j.jecp.2014.01.010
   Quam C, 2010, J MEM LANG, V62, P135, DOI 10.1016/j.jml.2009.09.003
   Rost GC, 2010, INFANCY, V15, P608, DOI 10.1111/j.1532-7078.2010.00033.x
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Sadakata M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01318
   Sadakata M, 2013, J ACOUST SOC AM, V134, P1324, DOI 10.1121/1.4812767
   Seidl A, 2014, LANG LEARN DEV, V10, P297, DOI 10.1080/15475441.2013.858575
   Singh L, 2004, J MEM LANG, V51, P173, DOI 10.1016/j.jml.2004.04.004
   Singh L, 2008, LANG LEARN DEV, V4, P157, DOI 10.1080/15475440801922131
   Sloutsky VM, 2010, COGNITIVE SCI, V34, P1244, DOI 10.1111/j.1551-6709.2010.01129.x
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Sundara M, 2018, COGNITION, V178, P57, DOI 10.1016/j.cognition.2018.05.009
   Swingley D, 2009, J MEM LANG, V60, P252, DOI 10.1016/j.jml.2008.11.003
   Teinonen T, 2008, COGNITION, V108, P850, DOI 10.1016/j.cognition.2008.05.009
   van der Feest SVH, 2016, LANG ACQUIS, V23, P89, DOI 10.1080/10489223.2015.1047096
   Von Holzen K, 2018, BRAIN SCI, V8, DOI 10.3390/brainsci8020024
   Weatherhead D, 2016, LANG LEARN DEV, V12, P92, DOI 10.1080/15475441.2015.1024835
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Yeung HH, 2009, COGNITION, V113, P234, DOI 10.1016/j.cognition.2009.08.010
   Yoshida KA, 2009, DEVELOPMENTAL SCI, V12, P412, DOI 10.1111/j.1467-7687.2008.00789.x
   Zamuner TS, 2006, INFANCY, V10, P77, DOI 10.1207/s15327078in1001_5
NR 66
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1525-0008
EI 1532-7078
J9 INFANCY
JI Infancy
PD JAN
PY 2021
VL 26
IS 1
BP 84
EP 103
DI 10.1111/infa.12371
EA OCT 2020
PG 20
WC Psychology, Developmental
SC Psychology
GA PK8WP
UT WOS:000577535600001
PM 33063948
DA 2021-02-24
ER

PT J
AU Kanazawa, Y
   Kishimoto, Y
   Tateya, I
   Ishii, T
   Sanuki, T
   Hiroshiba, S
   Aso, T
   Omori, K
   Nakamura, K
AF Kanazawa, Yuji
   Kishimoto, Yo
   Tateya, Ichiro
   Ishii, Toru
   Sanuki, Tetsuji
   Hiroshiba, Shinya
   Aso, Toshihiko
   Omori, Koichi
   Nakamura, Kimihiro
TI Hyperactive sensorimotor cortex during voice perception in spasmodic
   dysphonia
SO SCIENTIFIC REPORTS
LA English
DT Article
ID SOMATOSENSORY CORTEX; ADDUCTOR; ACTIVATION; AREAS; COMPLEXITY;
   DIAGNOSIS; MOVEMENT; FEATURES; THERAPY
AB Spasmodic dysphonia (SD) is characterized by an involuntary laryngeal muscle spasm during vocalization. Previous studies measured brain activation during voice production and suggested that SD arises from abnormal sensorimotor integration involving the sensorimotor cortex. However, it remains unclear whether this abnormal sensorimotor activation merely reflects neural activation produced by abnormal vocalization. To identify the specific neural correlates of SD, we used a sound discrimination task without overt vocalization to compare neural activation between 11 patients with SD and healthy participants. Participants underwent functional MRI during a two-alternative judgment task for auditory stimuli, which could be modal or falsetto voice. Since vocalization in falsetto is intact in SD, we predicted that neural activation during speech perception would differ between the two groups only for modal voice and not for falsetto voice. Group-by-stimulus interaction was observed in the left sensorimotor cortex and thalamus, suggesting that voice perception activates different neural systems between the two groups. Moreover, the sensorimotor signals positively correlated with disease severity of SD, and classified the two groups with 73% accuracy in linear discriminant analysis. Thus, the sensorimotor cortex and thalamus play a central role in SD pathophysiology and sensorimotor signals can be a new biomarker for SD diagnosis.
C1 [Kanazawa, Yuji; Kishimoto, Yo; Tateya, Ichiro; Omori, Koichi] Kyoto Univ, Grad Sch Med, Dept Otolaryngol Head & Neck Surg, Kyoto, Japan.
   [Kanazawa, Yuji] Shiga Med Ctr Children, Dept Otolaryngol, Moriyama, Japan.
   [Kanazawa, Yuji] Shiga Med Ctr Res Inst, Dept Otolaryngol, Moriyama, Japan.
   [Tateya, Ichiro] Fujita Hlth Univ, Dept Otolaryngol, Sch Med, Nagoya, Aichi 4701192, Japan.
   [Ishii, Toru; Aso, Toshihiko; Nakamura, Kimihiro] Kyoto Univ, Grad Sch Med, Human Brain Res Ctr, Kyoto, Japan.
   [Sanuki, Tetsuji] Kumamoto Univ, Dept Otolaryngol Head & Neck Surg, Kumamoto, Japan.
   [Sanuki, Tetsuji] Nagoya City Univ, Grad Sch Med Sci, Dept Otolaryngol Head & Neck Surg, Nagoya, Aichi, Japan.
   [Hiroshiba, Shinya] Isshiki Mem Voice Ctr, HIROSHIBA ENT Clin, Kyoto, Japan.
   [Nakamura, Kimihiro] Natl Rehabil Ctr Res Inst, Sect Syst Neurosci, Tokorozawa, Saitama, Japan.
RP Tateya, I (corresponding author), Kyoto Univ, Grad Sch Med, Dept Otolaryngol Head & Neck Surg, Kyoto, Japan.; Tateya, I (corresponding author), Fujita Hlth Univ, Dept Otolaryngol, Sch Med, Nagoya, Aichi 4701192, Japan.
EM ichiro.tateya@fujita-hu.ac.jp
FU Japan Agency for Medical Research and Development, AMEDJapan Agency for
   Medical Research and Development (AMED) [16ek0109006h0003]; Shimizu
   Foundation for Immunology and Neuroscience Grant for 2015; Brain Science
   Foundation; Japan Society for the Promotion of Science (KAKENHI)Ministry
   of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan
   Society for the Promotion of ScienceGrants-in-Aid for Scientific
   Research (KAKENHI) [16KT0005, 26560274]
FX This research was supported by Japan Agency for Medical Research and
   Development, AMED under Grant Number 16ek0109006h0003 and a research
   grant from The Shimizu Foundation for Immunology and Neuroscience Grant
   for 2015. KN was supported by the Brain Science Foundation and the Japan
   Society for the Promotion of Science (KAKENHI, 16KT0005 and 26560274).
CR Adler CH, 1997, J NEUROL NEUROSUR PS, V63, P688, DOI 10.1136/jnnp.63.5.688
   Ali SO, 2006, J SPEECH LANG HEAR R, V49, P1127, DOI 10.1044/1092-4388(2006/081)
   Baumer T, 2007, MOVEMENT DISORD, V22, P81, DOI 10.1002/mds.21219
   Battistella G, 2016, EUR J NEUROL, V23, P1517, DOI 10.1111/ene.13067
   Belin P, 2002, COGNITIVE BRAIN RES, V13, P17, DOI 10.1016/S0926-6410(01)00084-2
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Bonilha L, 2007, MOVEMENT DISORD, V22, P1110, DOI 10.1002/mds.21295
   Bonilha L, 2009, PARKINSONISM RELAT D, V15, P64, DOI 10.1016/j.parkreldis.2008.01.018
   Brown S, 2008, CEREB CORTEX, V18, P837, DOI 10.1093/cercor/bhm131
   Chou YH, 2012, AM J NEURORADIOL, V33, P833, DOI 10.3174/ajnr.A2894
   Creighton FX, 2015, J VOICE, V29, P592, DOI 10.1016/j.jvoice.2013.10.022
   Deary IJ, 2004, OTOLARYNG HEAD NECK, V131, P232, DOI 10.1016/j.otohns.2004.02.048
   Deguchi S, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017503
   Erickson ML, 2003, AM J SPEECH-LANG PAT, V12, P416, DOI 10.1044/1058-0360(2003/087)
   Faham Maryam, 2019, J Voice, DOI 10.1016/j.jvoice.2019.08.017
   Friston KJ, 1997, NEUROIMAGE, V6, P218, DOI 10.1006/nimg.1997.0291
   Haslinger B, 2005, NEUROLOGY, V65, P1562, DOI 10.1212/01.wnl.0000184478.59063.db
   Haslinger B, 2010, NEUROLOGY, V74, P1790, DOI 10.1212/WNL.0b013e3181e0f784
   Havrankova P, 2010, NEUROENDOCRINOL LETT, V31, P73
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Hintze JM, 2017, OTOLARYNG HEAD NECK, V157, P558, DOI 10.1177/0194599817728465
   Hirano S, 2001, AM J OTOLARYNG, V22, P219, DOI 10.1053/ajot.2001.23436
   ISSHIKI N, 1969, FOLIA PHONIATR, V21, P9, DOI 10.1159/000263230
   IZDEBSKI K, 1984, AM J OTOLARYNG, V5, P7, DOI 10.1016/S0196-0709(84)80015-0
   Kelly C, 2012, TRENDS COGN SCI, V16, P181, DOI 10.1016/j.tics.2012.02.001
   Kiyuna A, 2014, AURIS NASUS LARYNX, V41, P278, DOI 10.1016/j.anl.2013.10.017
   Kobayashi K, 2017, J Alzheimers Dis Parkinsonism, V7, DOI 10.4172/2161-0460.1000324
   Lacadie CM, 2008, NEUROIMAGE, V42, P717, DOI 10.1016/j.neuroimage.2008.04.240
   Langeveld TPM, 2000, ANN OTO RHINOL LARYN, V109, P741, DOI 10.1177/000348940010900808
   Leonard R, 1999, LARYNGOSCOPE, V109, P295, DOI 10.1097/00005537-199902000-00022
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Ludlow CL, 2011, J NEUROSCI, V31, P793, DOI 10.1523/JNEUROSCI.2758-10.2011
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Morzaria S, 2012, J VOICE, V26, P378, DOI 10.1016/j.jvoice.2010.07.011
   Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009
   Obermann M, 2010, MOVEMENT DISORD, V25, P2627, DOI 10.1002/mds.23321
   Patel N, 2014, LANCET NEUROL, V13, P100, DOI 10.1016/S1474-4422(13)70213-8
   Pernet CR, 2015, NEUROIMAGE, V119, P164, DOI 10.1016/j.neuroimage.2015.06.050
   Perruchoud D, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00458
   Phukan J, 2011, LANCET NEUROL, V10, P1074, DOI 10.1016/S1474-4422(11)70232-0
   Powers D. M., 2011, J MACH LEARN TECHNOL, V2, P37, DOI DOI 10.9735/2229-3981
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Quartarone A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00956
   Riecker A, 2005, NEUROLOGY, V64, P700, DOI 10.1212/01.WNL.0000152156.90779.89
   Rosen CA, 2004, LARYNGOSCOPE, V114, P1549, DOI 10.1097/00005537-200409000-00009
   Roy N, 2005, LARYNGOSCOPE, V115, P311, DOI 10.1097/01.mlg.0000154739.48314.ee
   Roy N, 2010, CURR OPIN OTOLARYNGO, V18, P165, DOI 10.1097/MOO.0b013e328339376c
   Samargia S, 2016, NEUROREHAB NEURAL RE, V30, P221, DOI 10.1177/1545968315591705
   Samargia S, 2014, NEUROSCI LETT, V560, P12, DOI 10.1016/j.neulet.2013.12.007
   Sanuki T, 2014, AURIS NASUS LARYNX, V41, P285, DOI 10.1016/j.anl.2013.11.001
   SAPIR S, 1995, J VOICE, V9, P270, DOI 10.1016/S0892-1997(05)80234-6
   Simonyan K, 2016, J NEUROSCI, V36, P11440, DOI 10.1523/JNEUROSCI.2424-16.2016
   Simonyan K, 2010, CEREB CORTEX, V20, P2749, DOI 10.1093/cercor/bhq023
   Stepp CE, 2017, J SPEECH LANG HEAR R, V60, P1545, DOI 10.1044/2017_JSLHR-S-16-0282
   Stewart CF, 1997, J VOICE, V11, P95, DOI 10.1016/S0892-1997(97)80029-X
   Suppa A, 2015, EUR J NEUROSCI, V42, P2051, DOI 10.1111/ejn.12977
   Tateya I, 2015, AURIS NASUS LARYNX, V42, P139, DOI 10.1016/j.anl.2014.08.012
   Tisch SHD, 2003, J CLIN NEUROSCI, V10, P434, DOI 10.1016/S0967-5868(03)00020-1
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Xu JQ, 2013, NEUROIMAGE, V83, P991, DOI 10.1016/j.neuroimage.2013.07.055
NR 61
TC 0
Z9 0
U1 1
U2 1
PU NATURE RESEARCH
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD OCT 14
PY 2020
VL 10
IS 1
AR 17298
DI 10.1038/s41598-020-73450-0
PG 11
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA OH6DQ
UT WOS:000582679600032
PM 33057071
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Mallikarjun, A
   Shroads, E
   Newman, RS
AF Mallikarjun, Amritha
   Shroads, Emily
   Newman, Rochelle S.
TI The role of linguistic experience in the development of the consonant
   bias
SO ANIMAL COGNITION
LA English
DT Article; Early Access
DE Canine cognition; Consonant bias; Dogs; Speech perception
ID PHONOLOGICAL SPECIFICITY; LEXICAL SELECTION; DOMESTIC DOG; VOWELS;
   CONSTRAINTS; INFORMATION; NAME
AB Consonants and vowels play different roles in speech perception: listeners rely more heavily on consonant information rather than vowel information when distinguishing between words. This reliance on consonants for word identification is the consonant bias Nespor et al. (Ling 2:203-230, 2003). Several factors modulate infants' development of the consonant bias, including fine-grained temporal processing ability and native language exposure [for review, see Nazzi et al. (Curr Direct Psychol Sci 25:291-296, 2016)]. A rat model demonstrated that mature fine-grained temporal processing alone cannot account forconsonant biasemergence; linguistic exposure is also necessary Bouchon and Toro (An Cog 22:839-850, 2019). This study tested domestic dogs, who have similarly fine-grained temporal processing but more language exposure than rats, to assess whether a minimal lexicon and small degree of regular linguistic exposure can allow for consonant bias development. Dogs demonstrated a vowel bias rather than a consonant bias, preferring their own name over a vowel-mispronounced version of their name, but not in comparison to a consonant-mispronounced version. This is the pattern seen in young infants Bouchon et al. (Dev Sci 18:587-598, 2015) and rats Bouchon et al. (An Cog 22:839-850, 2019). In a follow-up study, dogs treated a consonant-mispronounced version of their name similarly to their actual name, further suggesting that dogs do not treat consonant differences as meaningful for word identity. These results support the findings from Bouchon and Toro (An Cog 2:839-850, 2019), suggesting that there may be a default preference for vowel information over consonant information when identifying word forms, and that the consonant bias may be a human-exclusive tool for language learning.
C1 [Mallikarjun, Amritha; Shroads, Emily; Newman, Rochelle S.] Univ Maryland, College Pk, MD 20742 USA.
RP Mallikarjun, A (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM amritham@umd.edu
OI Mallikarjun, Amritha/0000-0003-3845-1694
CR ADAMS CL, 1987, DEV NEUROPSYCHOL, V3, P175, DOI 10.1080/87565648709540375
   Andics A, 2016, SCIENCE, V353, P1030, DOI 10.1126/science.aaf3777
   Andics A, 2014, CURR BIOL, V24, P574, DOI 10.1016/j.cub.2014.01.058
   [Anonymous], 2019, MOST POPULAR US PET
   Bach JP, 2016, BMC VET RES, V12, DOI 10.1186/s12917-016-0660-5
   Ballem KD, 2005, J CHILD LANG, V32, P159, DOI 10.1017/S0305000904006567
   Bonatti LL, 2005, PSYCHOL SCI, V16, P451, DOI 10.1111/j.0956-7976.2005.01556.x
   Bouchon C, 2017, BOST U C LANG DEV BO
   Bouchon C, 2019, ANIM COGN, V22, P839, DOI 10.1007/s10071-019-01280-3
   Bouchon C, 2015, DEVELOPMENTAL SCI, V18, P587, DOI 10.1111/desc.12242
   Burnham D, 2002, SCIENCE, V296, P1435, DOI 10.1126/science.1069587
   Cutler A, 2000, MEM COGNITION, V28, P746, DOI 10.3758/BF03198409
   CUTLER A, 1993, J PHONETICS, V21, P103, DOI 10.1016/S0095-4470(19)31323-3
   Delle Luche C, 2014, J MEM LANG, V72, P1, DOI 10.1016/j.jml.2013.12.001
   Fernald A, 2016, SOC RES CHILD DEV, V64, P657, DOI [10.2307/1131209, DOI 10.2307/1131209]
   Floccia C, 2014, J CHILD LANG, V41, P1085, DOI 10.1017/S0305000913000287
   GERKEN L, 1994, COGNITION, V51, P237, DOI 10.1016/0010-0277(94)90055-8
   Griebel U, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030182
   Hare B, 2002, SCIENCE, V298, P1634, DOI 10.1126/science.1072702
   Hare B, 1998, EVOLUTION COMMUNICAT, V2, P137, DOI DOI 10.1075/E0C.2.1.06HAR
   Hochmann JR, 2018, INFANCY, V23, P136, DOI 10.1111/infa.12203
   Hochmann JR, 2011, DEVELOPMENTAL SCI, V14, P1445, DOI 10.1111/j.1467-7687.2011.01089.x
   Hojen A, 2016, DEVELOPMENTAL SCI, V19, P41, DOI 10.1111/desc.12286
   Horowitz A, 2009, ANIM COGN, V12, P107, DOI 10.1007/s10071-008-0175-y
   JUSCZYK PW, 1993, CHILD DEV, V64, P675, DOI 10.2307/1131210
   Kaminski J, 2004, SCIENCE, V304, P1682, DOI 10.1126/science.1097859
   Keidel JL, 2007, PSYCHOL SCI, V18, P922, DOI 10.1111/j.1467-9280.2007.02001.x
   Kutsumi A, 2013, J VET MED SCI, V75, P141, DOI 10.1292/jvms.12-0008
   Ladefoged P, 2001, VOWEL CONSONANTS INT
   Mallikarjun A, 2019, LANGUAGE DISCRIMINAT
   Mallikarjun A, 2019, ANIM COGN, V22, P423, DOI 10.1007/s10071-019-01255-4
   Mani N, 2007, J MEM LANG, V57, P252, DOI 10.1016/j.jml.2007.03.005
   Mehler J, 1996, SIGNAL TO SYNTAX: BOOTSTRAPPING FROM SPEECH TO GRAMMAR IN EARLY ACQUISITION, P101
   Miklosi A, 1998, Anim Cogn, V1, P113, DOI 10.1007/s100710050016
   Nazzi T, 2005, COGNITION, V98, P13, DOI 10.1016/j.cognition.2004.10.005
   Nazzi T, 2016, CURR DIR PSYCHOL SCI, V25, P291, DOI 10.1177/0963721416655786
   Nazzi T, 2009, J EXP CHILD PSYCHOL, V102, P522, DOI 10.1016/j.jecp.2008.05.003
   NELSON DGK, 1995, INFANT BEHAV DEV, V18, P111
   Nespor M., 2003, LINGUE LINGUAGGIO, V2, P203, DOI [10. 1418/ 10879, DOI 10.1418/10879]
   Newman RS, 2009, ATTEN PERCEPT PSYCHO, V71, P822, DOI 10.3758/APP.71.4.822
   Newman RS, 2005, DEV PSYCHOL, V41, P352, DOI 10.1037/0012-1649.41.2.352
   Newman RS, 2019, BITTSY BEHAV INFANT
   Nishibayashi LL, 2016, COGNITION, V155, P188, DOI 10.1016/j.cognition.2016.07.003
   Perez CA, 2013, CEREB CORTEX, V23, P670, DOI 10.1093/cercor/bhs045
   Pilley JW, 2011, BEHAV PROCESS, V86, P184, DOI 10.1016/j.beproc.2010.11.007
   Poltrock S, 2015, J EXP CHILD PSYCHOL, V131, P135, DOI 10.1016/j.jecp.2014.11.011
   Song S, 2012, P NATL ACAD SCI USA, V109, P14942, DOI 10.1073/pnas.1211733109
   Thiessen ED, 2010, CHILD DEV, V81, P1287, DOI 10.1111/j.1467-8624.2010.01468.x
   vanOoijen B, 1996, MEM COGNITION, V24, P573, DOI 10.3758/BF03201084
   Yip MJ, 2006, TRENDS COGN SCI, V10, P442, DOI 10.1016/j.tics.2006.08.001
NR 50
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1435-9448
EI 1435-9456
J9 ANIM COGN
JI Anim. Cogn.
DI 10.1007/s10071-020-01436-6
EA OCT 2020
PG 13
WC Behavioral Sciences; Zoology
SC Behavioral Sciences; Zoology
GA NZ7KX
UT WOS:000577283600001
PM 33052544
DA 2021-02-24
ER

PT J
AU Schulte, A
   Thiel, CM
   Gieseler, A
   Tahden, M
   Colonius, H
   Rosemann, S
AF Schulte, Alina
   Thiel, Christiane M.
   Gieseler, Anja
   Tahden, Maike
   Colonius, Hans
   Rosemann, Stephanie
TI Reduced resting state functional connectivity with increasing
   age-related hearing loss and McGurk susceptibility
SO SCIENTIFIC REPORTS
LA English
DT Article
ID SPEECH-PERCEPTION; OLDER-ADULTS; ALZHEIMERS-DISEASE; NETWORK; BRAIN;
   INTEGRATION; REPRESENTATION; ATTENTION; DEMENTIA; DECLINE
AB Age-related hearing loss has been related to a compensatory increase in audio-visual integration and neural reorganization including alterations in functional resting state connectivity. How these two changes are linked in elderly listeners is unclear. The current study explored modulatory effects of hearing thresholds and audio-visual integration on resting state functional connectivity. We analysed a large set of resting state data of 65 elderly participants with a widely varying degree of untreated hearing loss. Audio-visual integration, as gauged with the McGurk effect, increased with progressing hearing thresholds. On the neural level, McGurk illusions were negatively related to functional coupling between motor and auditory regions. Similarly, connectivity of the dorsal attention network to sensorimotor and primary motor cortices was reduced with increasing hearing loss. The same effect was obtained for connectivity between the salience network and visual cortex. Our findings suggest that with progressing untreated age-related hearing loss, functional coupling at rest declines, affecting connectivity of brain networks and areas associated with attentional, visual, sensorimotor and motor processes. Especially connectivity reductions between auditory and motor areas were related to stronger audio-visual integration found with increasing hearing loss.
C1 [Schulte, Alina; Thiel, Christiane M.; Rosemann, Stephanie] Carl Von Ossietzky Univ Oldenburg, Biol Psychol, Sch Med & Hlth Sci, Dept Psychol, Ammerlander Heerstr 114-118, D-26111 Oldenburg, Germany.
   [Thiel, Christiane M.; Gieseler, Anja; Tahden, Maike; Colonius, Hans; Rosemann, Stephanie] Carl Von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, Oldenburg, Germany.
   [Gieseler, Anja; Tahden, Maike; Colonius, Hans] Carl Von Ossietzky Univ Oldenburg, Dept Psychol, Sch Med & Hlth Sci, Cognit Psychol, Oldenburg, Germany.
RP Thiel, CM (corresponding author), Carl Von Ossietzky Univ Oldenburg, Biol Psychol, Sch Med & Hlth Sci, Dept Psychol, Ammerlander Heerstr 114-118, D-26111 Oldenburg, Germany.; Thiel, CM (corresponding author), Carl Von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, Oldenburg, Germany.
EM christiane.thiel@uni-oldenburg.de
FU German Research Foundation (Deutsche Forschungsgemeinschaft, DFG;
   Cluster of Excellence)German Research Foundation (DFG) [DFG 1077];
   Neuroimaging Unit of the Carl von Ossietzky Universitat Oldenburg -
   German Research Foundation [3T MRI INST 184/152-1 FUGG]; Hearing
   Industry Research Consortium (IRC) Grant 2017
FX This work was funded by the German Research Foundation (Deutsche
   Forschungsgemeinschaft, DFG; Cluster of Excellence DFG 1077
   "Hearing4all'') and supported by the Neuroimaging Unit of the Carl von
   Ossietzky Universitat Oldenburg funded by grants from the German
   Research Foundation (3T MRI INST 184/152-1 FUGG). The work was further
   funded by the Hearing Industry Research Consortium (IRC) Grant 2017. The
   authors wish to thank Gulsen Yanc and Katharina Grote for helping with
   MRI data acquisition.
CR Andrews-Hanna JR, 2014, ANN NY ACAD SCI, V1316, P29, DOI 10.1111/nyas.12360
   Beauchamp MS, 2010, J NEUROSCI, V30, P2414, DOI 10.1523/JNEUROSCI.4865-09.2010
   Benoit MM, 2010, HUM BRAIN MAPP, V31, P526, DOI 10.1002/hbm.20884
   Bernstein LE, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00386
   Binder JR, 1996, BRAIN, V119, P1239, DOI 10.1093/brain/119.4.1239
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   Campbell J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00071
   Cardin V, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00199
   Chen YC, 2018, FRONT BEHAV NEUROSCI, V12, DOI 10.3389/fnbeh.2018.00044
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Damoiseaux JS, 2008, CEREB CORTEX, V18, P1856, DOI 10.1093/cercor/bhm207
   Erickson LC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00534
   Fitzhugh MC, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02485
   Fox MD, 2010, FRONT SYST NEUROSCI, V4, DOI [10.3389/fnsys.2010.00019, 10.3389/fnsys.2010.0001]
   FRISTON KJ, 1993, J CEREBR BLOOD F MET, V13, P5, DOI 10.1038/jcbfm.1993.4
   Glick H, 2017, HEARING RES, V343, P191, DOI 10.1016/j.heares.2016.08.012
   Goman AM, 2016, AM J PUBLIC HEALTH, V106, P1820, DOI 10.2105/AJPH.2016.303299
   Greicius MD, 2004, P NATL ACAD SCI USA, V101, P4637, DOI 10.1073/pnas.0308627101
   Guerreiro MJS, 2017, NEUROBIOL AGING, V56, P180, DOI 10.1016/j.neurobiolaging.2017.05.001
   Gurgel RK, 2014, OTOL NEUROTOL, V35, P775, DOI 10.1097/MAO.0000000000000313
   Heine L, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00295
   Helfer KS, 2008, EAR HEARING, V29, P87, DOI 10.1097/AUD.0b013e31815d638b
   Hermundstad AM, 2013, P NATL ACAD SCI USA, V110, P6169, DOI 10.1073/pnas.1219562110
   Hesselmann V, 2004, BRAIN TOPOGR, V16, P159
   Husain FT, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00010
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Lin FR, 2014, NEUROIMAGE, V90, P84, DOI 10.1016/j.neuroimage.2013.12.059
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Lin FR, 2012, JAMA-J AM MED ASSOC, V307, P1147, DOI 10.1001/jama.2012.321
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P1131, DOI 10.1093/gerona/glr115
   Liu XZ, 2007, J PATHOL, V211, P188, DOI 10.1002/path.2102
   Londei A, 2010, HUM BRAIN MAPP, V31, P567, DOI 10.1002/hbm.20888
   Luan Y, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00055
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   Magnotti JF, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202908
   Maldjian JA, 2003, NEUROIMAGE, V19, P1233, DOI 10.1016/S1053-8119(03)00169-1
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McKiernan KA, 2006, NEUROIMAGE, V29, P1185, DOI 10.1016/j.neuroimage.2005.09.030
   Miller LM, 2005, J NEUROSCI, V25, P5884, DOI 10.1523/JNEUROSCI.0896-05.2005
   Miyamoto JJ, 2006, CEREB CORTEX, V16, P669, DOI 10.1093/cercor/bhj012
   Murakami T, 2018, J NEUROSCI, V38, P9679, DOI 10.1523/JNEUROSCI.3650-17.2018
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Onoda K, 2012, J COGNITIVE NEUROSCI, V24, P2186, DOI 10.1162/jocn_a_00269
   Park H, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2006558
   Pronk M, 2019, J SPEECH LANG HEAR R, V62, P1167, DOI 10.1044/2018_JSLHR-H-ASCC7-18-0120
   Puschmann S, 2017, CORTEX, V86, P109, DOI 10.1016/j.cortex.2016.10.014
   Rosemann S, 2020, CORTEX, V129, P266, DOI 10.1016/j.cortex.2020.04.022
   Rosemann S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38816-z
   Rosemann S, 2018, NEUROIMAGE, V175, P425, DOI 10.1016/j.neuroimage.2018.04.023
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Sprinzl GM, 2010, GERONTOLOGY, V56, P351, DOI 10.1159/000275062
   Stein BE, 2008, NAT REV NEUROSCI, V9, P255, DOI 10.1038/nrn2331
   Stropahl M, 2017, NEUROIMAGE-CLIN, V16, P514, DOI 10.1016/j.nicl.2017.09.001
   Tiippana K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00725
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Uddin LQ, 2015, NAT REV NEUROSCI, V16, P55, DOI 10.1038/nrn3857
   Vossel S, 2014, NEUROSCIENTIST, V20, P150, DOI 10.1177/1073858413494269
   Whitfield-Gabrieli S, 2012, BRAIN CONNECT, V2, P125, DOI 10.1089/brain.2012.0073
   Whitfield-Gabrieli S, 2011, NEUROIMAGE, V55, P225, DOI 10.1016/j.neuroimage.2010.11.048
   Wingfield A, 2006, J NEUROPHYSIOL, V96, P2830, DOI 10.1152/jn.00628.2006
   Wong PCM, 2010, EAR HEARING, V31, P471, DOI 10.1097/AUD.0b013e3181d709c2
   Woodhouse L, 2009, INT J LANG COMM DIS, V44, P253, DOI 10.1080/13682820802090281
   Zhou J, 2014, BIOL PSYCHIAT, V75, P565, DOI 10.1016/j.biopsych.2014.01.020
NR 63
TC 0
Z9 0
U1 1
U2 1
PU NATURE RESEARCH
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD OCT 12
PY 2020
VL 10
IS 1
AR 16987
DI 10.1038/s41598-020-74012-0
PG 12
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA OH6FU
UT WOS:000582685800013
PM 33046800
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Assaneo, MF
   Rimmele, JM
   Perl, YS
   Poeppel, D
AF Assaneo, M. Florencia
   Rimmele, Johanna M.
   Sanz Perl, Yonatan
   Poeppel, David
TI Speaking rhythmically can shape hearing
SO NATURE HUMAN BEHAVIOUR
LA English
DT Article
ID PHASE ENTRAINMENT; SPEECH; OSCILLATIONS; DYNAMICS; PERCEPTION; RHYTHMS;
   TIME; STIMULATION; SOUNDS; ROLES
AB Evidence suggests that temporal predictions arising from the motor system can enhance auditory perception. However, in speech perception, we lack evidence of perception being modulated by production. Here we show a behavioural protocol that captures the existence of such auditory-motor interactions. Participants performed a syllable discrimination task immediately after producing periodic syllable sequences. Two speech rates were explored: a 'natural' (individually preferred) and a fixed 'non-natural' (2 Hz) rate. Using a decoding approach, we show that perceptual performance is modulated by the stimulus phase determined by a participant's own motor rhythm. Remarkably, for 'natural' and 'non-natural' rates, this finding is restricted to a subgroup of the population with quantifiable auditory-motor coupling. The observed pattern is compatible with a neural model assuming a bidirectional interaction of auditory and speech motor cortices. Crucially, the model matches the experimental results only if it incorporates individual differences in the strength of the auditory-motor connection.
   Assaneo et al. show that speech production timing can facilitate perception. Individuals differed in whether they utilized motor timing depending on the auditory-motor cortex connection strength.
C1 [Assaneo, M. Florencia; Poeppel, David] NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
   [Assaneo, M. Florencia] Univ Nacl Autonoma Mexico, Inst Neurobiol, Santiago De Queretaro, Mexico.
   [Rimmele, Johanna M.; Poeppel, David] Max Planck Inst Empir Aesthet, Dept Neurosci, Frankfurt, Germany.
   [Sanz Perl, Yonatan] Univ Buenos Aires, Dept Phys, FCEyN, Buenos Aires, DF, Argentina.
   [Sanz Perl, Yonatan] Consejo Nacl Invest Cient & Tecn, Natl Sci & Tech Res Council, Buenos Aires, DF, Argentina.
   [Sanz Perl, Yonatan] Univ San Andres, Buenos Aires, DF, Argentina.
RP Assaneo, MF (corresponding author), NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.; Assaneo, MF (corresponding author), Univ Nacl Autonoma Mexico, Inst Neurobiol, Santiago De Queretaro, Mexico.; Rimmele, JM (corresponding author), Max Planck Inst Empir Aesthet, Dept Neurosci, Frankfurt, Germany.
EM fassaneo@gmail.com; johanna.rimmele@ae.mpg.de
OI Sanz Perl, Yonatan/0000-0002-1270-5564; Poeppel,
   David/0000-0003-0184-163X
FU Max-Planck-Institute for Empirical Aesthetics
FX We thank M. Grabenhorst, J.-R. King and L. Gwilliams for their valuable
   input regarding the data analysis, M. Fichter for data recordings and S.
   Brendecke for graphics support. This work was funded by the
   Max-Planck-Institute for Empirical Aesthetics. The funders had no role
   in the conceptualization, design, data collection, analysis, decision to
   publish, or preparation of the manuscript.
CR Assaneo MF, 2019, NAT NEUROSCI, V22, P627, DOI 10.1038/s41593-019-0353-z
   Assaneo MF, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aao3842
   Besle J, 2011, J NEUROSCI, V31, P3176, DOI 10.1523/JNEUROSCI.4518-10.2011
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Cabral J, 2014, NEUROIMAGE, V90, P423, DOI 10.1016/j.neuroimage.2013.11.047
   Cao LY, 2017, NEUROIMAGE, V147, P895, DOI 10.1016/j.neuroimage.2016.11.001
   Cason N, 2015, ACTA PSYCHOL, V155, P43, DOI 10.1016/j.actpsy.2014.12.002
   Cason N, 2012, NEUROPSYCHOLOGIA, V50, P2652, DOI 10.1016/j.neuropsychologia.2012.07.018
   Chang EF, 2013, P NATL ACAD SCI USA, V110, P2653, DOI 10.1073/pnas.1216827110
   Chen JL, 2008, CEREB CORTEX, V18, P2844, DOI 10.1093/cercor/bhn042
   Chi T, 2005, J ACOUST SOC AM, V118, P887, DOI 10.1121/1.1945807
   Coull J.T., 2015, BRAIN MAPPING ENCYCL, P565
   Coupe C, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aaw2594
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Devlin JT, 2009, CURR BIOL, V19, pR198, DOI 10.1016/j.cub.2009.01.005
   Ding N, 2017, NEUROSCI BIOBEHAV R, V81, P181, DOI 10.1016/j.neubiorev.2017.02.011
   Doelling KB, 2019, P NATL ACAD SCI USA, V116, P10113, DOI 10.1073/pnas.1816414116
   Falk S, 2017, J COGNITIVE NEUROSCI, V29, P1378, DOI 10.1162/jocn_a_01136
   Fujioka T, 2012, J NEUROSCI, V32, P1791, DOI 10.1523/JNEUROSCI.4107-11.2012
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Grabenhorst M, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13849-0
   Grahn JA, 2009, J NEUROSCI, V29, P7540, DOI 10.1523/JNEUROSCI.2018-08.2009
   Guenther FH, 2006, BRAIN LANG, V96, P280, DOI 10.1016/j.bandl.2005.06.001
   Haegens S, 2018, NEUROSCI BIOBEHAV R, V86, P150, DOI 10.1016/j.neubiorev.2017.12.002
   Hansen PC, 2010, MEG INTRO METHODS
   Henry MJ, 2012, P NATL ACAD SCI USA, V109, P20095, DOI 10.1073/pnas.1213390109
   Hickok G, 2015, PSYCHOL SCI, V26, P1006, DOI 10.1177/0956797615576533
   Huang Y, 2007, BIOMETRICS, V63, P1181, DOI 10.1111/j.1541-0420.2007.00814.x
   Jasp Team, 2020, JASP VERS 0 12
   Keitel A, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2004473
   Kontsevich LL, 1999, VISION RES, V39, P2729, DOI 10.1016/S0042-6989(98)00285-5
   Kosem A, 2016, J NEUROPHYSIOL, V116, P2497, DOI 10.1152/jn.00074.2016
   Lakatos P, 2005, J NEUROPHYSIOL, V94, P1904, DOI 10.1152/jn.00263.2005
   Lakatos P, 2019, CURR BIOL, V29, pR890, DOI 10.1016/j.cub.2019.07.075
   Large EW, 1999, PSYCHOL REV, V106, P119, DOI 10.1037/0033-295X.106.1.119
   Lee M. D., 2013, BAYESIAN COGNITIVE M, p[xiii, 264]
   McPherson T, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-29267-z
   Merchant H, 2016, CURR OPIN BEHAV SCI, V8, P22, DOI 10.1016/j.cobeha.2016.01.006
   Morillon B, 2019, NEUROSCI BIOBEHAV R, V107, P136, DOI 10.1016/j.neubiorev.2019.09.012
   Morillon B, 2017, P NATL ACAD SCI USA, V114, pE8913, DOI 10.1073/pnas.1705373114
   Morillon B, 2015, CURR OPIN NEUROBIOL, V31, P230, DOI 10.1016/j.conb.2014.12.005
   Morillon B, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms6255
   Moskowitz CS, 2004, BIOSTATISTICS, V5, P113, DOI 10.1093/biostatistics/5.1.113
   Nobrel AC, 2007, CURR OPIN NEUROBIOL, V17, P465, DOI 10.1016/j.conb.2007.07.006
   NSL, 2003, NSL MATLAB TOOLB
   Park Hyojin, 2018, Lang Cogn Neurosci, V35, P739, DOI 10.1080/23273798.2018.1506589
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049
   Poeppel D, 2020, NAT REV NEUROSCI, V21, P322, DOI 10.1038/s41583-020-0304-4
   Repp BH, 2004, PSYCHOL RES-PSYCH FO, V68, P252, DOI 10.1007/s00426-003-0143-8
   Riecke L, 2018, CURR BIOL, V28, P161, DOI 10.1016/j.cub.2017.11.033
   Riecke L, 2015, CURR BIOL, V25, P3196, DOI 10.1016/j.cub.2015.10.045
   Riecke L, 2015, BRAIN STIMUL, V8, P777, DOI 10.1016/j.brs.2015.04.004
   Rimmele JM, 2018, TRENDS COGN SCI, V22, P870, DOI 10.1016/j.tics.2018.08.003
   Ruspantini I, 2012, J NEUROSCI, V32, P3786, DOI 10.1523/JNEUROSCI.3191-11.2012
   Sanabria D, 2013, BIOL PSYCHOL, V92, P98, DOI 10.1016/j.biopsycho.2012.11.012
   Schonbrodt FD, 2018, PSYCHON B REV, V25, P128, DOI 10.3758/s13423-017-1230-y
   Schroeder CE, 2010, CURR OPIN NEUROBIOL, V20, P172, DOI 10.1016/j.conb.2010.02.010
   Scott SK, 2009, NAT REV NEUROSCI, V10, P295, DOI 10.1038/nrn2603
   Stefanics G, 2010, J NEUROSCI, V30, P13578, DOI 10.1523/JNEUROSCI.0703-10.2010
   THOMAS EAC, 1967, BRIT J MATH STAT PSY, V20, P1, DOI 10.1111/j.2044-8317.1967.tb00375.x
   Tian X, 2015, J COGNITIVE NEUROSCI, V27, P352, DOI 10.1162/jocn_a_00692
   Tian X, 2013, J COGNITIVE NEUROSCI, V25, P1020, DOI 10.1162/jocn_a_00381
   Timm J, 2016, CORTEX, V80, P5, DOI 10.1016/j.cortex.2016.03.018
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
   Yeung MKS, 1999, PHYS REV LETT, V82, P648, DOI 10.1103/PhysRevLett.82.648
   Zalta A, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-14888-8
   Zoefel B, 2019, NEUROIMAGE, V202, DOI 10.1016/j.neuroimage.2019.116175
NR 68
TC 0
Z9 0
U1 6
U2 6
PU NATURE RESEARCH
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2397-3374
J9 NAT HUM BEHAV
JI Nat. Hum. Behav.
PD JAN
PY 2021
VL 5
IS 1
DI 10.1038/s41562-020-00962-0
EA OCT 2020
PG 14
WC Psychology, Biological; Multidisciplinary Sciences; Neurosciences;
   Psychology, Experimental
SC Psychology; Science & Technology - Other Topics; Neurosciences &
   Neurology
GA PU3GF
UT WOS:000577054800001
PM 33046860
DA 2021-02-24
ER

PT J
AU McGarrigle, R
   Rakusen, L
   Mattys, S
AF McGarrigle, Ronan
   Rakusen, Lyndon
   Mattys, Sven
TI Effortful listening under the microscope: Examining relations between
   pupillometric and subjective markers of effort and tiredness from
   listening
SO PSYCHOPHYSIOLOGY
LA English
DT Article
DE Fatigue; Listening efforListening effort; Pupillometry; Rmcorr; Speech
   perception
ID MENTAL FATIGUE; SPEECH-PERCEPTION; PUPIL-DILATION; HEARING IMPAIRMENT;
   RECOGNITION; COGNITION; MASKING; NOISE
AB Effort during listening is commonly measured using the task-evoked pupil response (TEPR); a pupillometric marker of physiological arousal. However, studies to date report no association between TEPR and perceived effort. One possible reason for this is the way in which self-report effort measures are typically administered, namely as a single data point collected at the end of a testing session. Another possible reason is that TEPR might relate more closely to the experience of tiredness from listening than to effort per se. To examine these possibilities, we conducted two preregistered experiments that recorded subjective ratings of effort and tiredness from listening at multiple time points and examined their covariance with TEPR over the course of listening tasks varying in levels of acoustic and attentional demand. In both experiments, we showed a within-subject association between TEPR and tiredness from listening, but no association between TEPR and effort. The data also suggest that the effect of task difficulty on the experience of tiredness from listening may go undetected using the traditional approach of collecting a single data point at the end of a listening block. Finally, this study demonstrates the utility of a novel correlation analysis technique ("rmcorr"), which can be used to overcome statistical power constraints commonly found in the literature. Teasing apart the subjective and physiological mechanisms that underpin effortful listening is a crucial step toward addressing these difficulties in older and/or hearing-impaired individuals.
C1 [McGarrigle, Ronan; Rakusen, Lyndon; Mattys, Sven] Univ York, Dept Psychol, York YO10 5DD, N Yorkshire, England.
RP McGarrigle, R (corresponding author), Univ York, Dept Psychol, York YO10 5DD, N Yorkshire, England.
EM ronanomcg@gmail.com
RI McGarrigle, Ronan/T-6505-2019
OI McGarrigle, Ronan/0000-0003-1704-1135
FU Economic and Social Research CouncilUK Research & Innovation
   (UKRI)Economic & Social Research Council (ESRC) [ES/R003572/1]
FX Economic and Social Research Council, Grant/Award Number: ES/R003572/1
CR Agus TR, 2009, J ACOUST SOC AM, V126, P1926, DOI 10.1121/1.3205403
   Agus TR, 2009, J ACOUST SOC AM, V125, P23, DOI 10.1121/1.3025915
   Alhanbali S, 2017, EAR HEARING, V38, pE39, DOI 10.1097/AUD.0000000000000361
   [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   Aston-Jones G, 2005, ANNU REV NEUROSCI, V28, P403, DOI 10.1146/annurev.neuro.28.061604.135709
   Bakdash JZ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00456
   Bath KG, 2020, TRENDS NEUROSCI, V43, P300, DOI 10.1016/j.tins.2020.02.004
   Borghini G, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00152
   Brisson J, 2013, BEHAV RES METHODS, V45, P1322, DOI 10.3758/s13428-013-0327-0
   Clayson PE, 2019, PSYCHOPHYSIOLOGY, V56, DOI 10.1111/psyp.13437
   DeLuca J, 2005, ISS CLIN COGN NEUROP, P1
   Dimitrijevic A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-47643-1
   Fairbanks G., 1960, VOICE ARTICULATION D
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Francis AL, 2020, WIRES COGN SCI, V11, DOI 10.1002/wcs.1514
   Gergelyfi M, 2015, FRONT BEHAV NEUROSCI, V9, DOI [10.3389/fnbeh.2015.00176, 10.3389/fnbeh.2015,00176]
   HART S G, 1988, P139
   HETU R, 1988, British Journal of Audiology, V22, P251
   Hockey R., 2013, PSYCHOL FATIGUE WORK, DOI [10.1017/CBO9781139015394, DOI 10.1017/CB09781139015394]
   Holman JA, 2019, INT J AUDIOL, V58, P408, DOI 10.1080/14992027.2019.1597284
   Hopstaken JF, 2015, BIOL PSYCHOL, V110, P100, DOI 10.1016/j.biopsycho.2015.06.013
   Hornsby BWY, 2016, EAR HEARING, V37, p136S, DOI 10.1097/AUD.0000000000000289
   Hornsby BWY, 2016, EAR HEARING, V37, pe1, DOI 10.1097/AUD.0000000000000203
   Hornsby BWY, 2013, EAR HEARING, V34, P523, DOI 10.1097/AUD.0b013e31828003d8
   KAERNBACH C, 1991, PERCEPT PSYCHOPHYS, V49, P227, DOI 10.3758/BF03214307
   Kidd Gerald Jr., 2008, V29, P143
   Koelewijn T, 2012, EAR HEARING, V33, P291, DOI 10.1097/AUD.0b013e3182310019
   Krueger M, 2017, J ACOUST SOC AM, V141, P4680, DOI 10.1121/1.4986938
   Kuchinsky SE, 2014, PSYCHOPHYSIOLOGY, V51, P1046, DOI 10.1111/psyp.12242
   Mathot Sebastiaan, 2018, J Cogn, V1, P16, DOI 10.5334/joc.18
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McGarrigle R, 2017, PSYCHOPHYSIOLOGY, V54, P193, DOI 10.1111/psyp.12772
   McGarrigle R, 2014, INT J AUDIOL, V53, P433, DOI 10.3109/14992027.2014.890296
   McLaughlin DJ, 2020, J ACOUST SOC AM, V147, pEL151, DOI 10.1121/10.0000718
   McMahon CM, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00745
   Moore TM, 2018, J SPEECH LANG HEAR R, V61, P2405, DOI 10.1044/2018_JSLHR-H-17-0451
   Moore TM, 2017, NEUROPSYCHOLOGIA, V106, P371, DOI 10.1016/j.neuropsychologia.2017.10.025
   Nachtegaal J, 2009, INT J AUDIOL, V48, P684, DOI 10.1080/14992020902962421
   Nike, 2020, SPEECH NOIS MIX SIGN
   Ohlenforst B, 2017, HEARING RES, V351, P68, DOI 10.1016/j.heares.2017.05.012
   Pals C, 2019, EAR HEARING, V40, P3, DOI 10.1097/AUD.0000000000000587
   Peng ZE, 2019, J SPEECH LANG HEAR R, V62, P1068, DOI 10.1044/2018_JSLHR-H-17-0423
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Picou EM, 2018, INT J AUDIOL, V57, P457, DOI 10.1080/14992027.2018.1431696
   Picou EM, 2017, J SPEECH LANG HEAR R, V60, P199, DOI 10.1044/2016_JSLHR-H-15-0416
   PISONI DB, 1985, J ACOUST SOC AM, V78, P381, DOI 10.1121/1.392451
   Rennies J, 2014, J ACOUST SOC AM, V136, P2642, DOI 10.1121/1.4897398
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   Rovetti J, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216519886722
   RStudio Team, 2019, RSTUDIO INT DEV R
   Seeman S, 2015, J SPEECH LANG HEAR R, V58, P1781, DOI 10.1044/2015_JSLHR-H-14-0180
   Smith SL, 2011, INT J AUDIOL, V50, P417, DOI 10.3109/14992027.2011.553205
   Strand JF, 2018, J SPEECH LANG HEAR R, V61, P1463, DOI 10.1044/2018_JSLHR-H-17-0257
   Thones S, 2018, CONSCIOUS COGN, V63, P99, DOI 10.1016/j.concog.2018.06.014
   van der Linden D, 2003, ACTA PSYCHOL, V113, P45, DOI 10.1016/S0001-6918(02)00150-6
   Wagenmakers EJ, 2018, PERSPECT PSYCHOL SCI, V13, P418, DOI 10.1177/1745691618771357
   Wang Y, 2018, EAR HEARING, V39, P573, DOI 10.1097/AUD.0000000000000512
   Winn MB, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518800869
   Zekveld AA, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518777174
   Zekveld AA, 2010, EAR HEARING, V31, P480, DOI 10.1097/AUD.0b013e3181d4f251
NR 61
TC 0
Z9 0
U1 1
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0048-5772
EI 1469-8986
J9 PSYCHOPHYSIOLOGY
JI Psychophysiology
PD JAN
PY 2021
VL 58
IS 1
AR e13703
DI 10.1111/psyp.13703
EA OCT 2020
PG 22
WC Psychology, Biological; Neurosciences; Physiology; Psychology;
   Psychology, Experimental
SC Psychology; Neurosciences & Neurology; Physiology
GA PI9MZ
UT WOS:000576032900001
PM 33031584
OA Green Accepted, Other Gold
DA 2021-02-24
ER

PT J
AU Wang, L
   Wu, EX
   Chen, F
AF Wang, Lei
   Wu, Ed X.
   Chen, Fei
TI Robust EEG-Based Decoding of Auditory Attention With High-RMS-Level
   Speech Segments in Noisy Conditions
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE EEG; temporal response function (TRF); auditory attention decoding;
   speech RMS-level segments; signal-to-noise ratio
ID CORTICAL ENTRAINMENT; NORMAL-HEARING; INTELLIGIBILITY; TRACKING;
   COMPREHENSION; OSCILLATIONS; RESPONSES; BRAIN; DELTA; THETA
AB The attended speech stream can be detected robustly, even in adverse auditory scenarios with auditory attentional modulation, and can be decoded using electroencephalographic (EEG) data. Speech segmentation based on the relative root-mean-square (RMS) intensity can be used to estimate segmental contributions to perception in noisy conditions. High-RMS-level segments contain crucial information for speech perception. Hence, this study aimed to investigate the effect of high-RMS-level speech segments on auditory attention decoding performance under various signal-to-noise ratio (SNR) conditions. Scalp EEG signals were recorded when subjects listened to the attended speech stream in the mixed speech narrated concurrently by two Mandarin speakers. The temporal response function was used to identify the attended speech from EEG responses of tracking to the temporal envelopes of intact speech and high-RMS-level speech segments alone, respectively. Auditory decoding performance was then analyzed under various SNR conditions by comparing EEG correlations to the attended and ignored speech streams. The accuracy of auditory attention decoding based on the temporal envelope with high-RMS-level speech segments was not inferior to that based on the temporal envelope of intact speech. Cortical activity correlated more strongly with attended than with ignored speech under different SNR conditions. These results suggest that EEG recordings corresponding to high-RMS-level speech segments carry crucial information for the identification and tracking of attended speech in the presence of background noise. This study also showed that with the modulation of auditory attention, attended speech can be decoded more robustly from neural activity than from behavioral measures under a wide range of SNR.
C1 [Wang, Lei; Chen, Fei] Southern Univ Sci & Technol, Dept Elect & Elect Engn, Shenzhen, Peoples R China.
   [Wang, Lei; Wu, Ed X.] Univ Hong Kong, Dept Elect & Elect Engn, Hong Kong, Peoples R China.
RP Chen, F (corresponding author), Southern Univ Sci & Technol, Dept Elect & Elect Engn, Shenzhen, Peoples R China.
EM fchen@sustech.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61971212, 61828104]; Basic Research
   Foundation of Shenzhen [KQJSCX20180319114453986, GJHZ20180928155002157];
   High-level University Fund [G02236002]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 61971212 and 61828104), the Basic Research Foundation
   of Shenzhen (Grant Nos. KQJSCX20180319114453986 and
   GJHZ20180928155002157), and High-level University Fund G02236002.
CR Alickovic E, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00153
   Aroudi A, 2019, IEEE T NEUR SYS REH, V27, P652, DOI 10.1109/TNSRE.2019.2903404
   Biesmans W, 2017, IEEE T NEUR SYS REH, V25, P402, DOI 10.1109/TNSRE.2016.2571900
   Broderick MP, 2019, J NEUROSCI, V39, P7564, DOI 10.1523/JNEUROSCI.0584-19.2019
   Chen F, 2013, INT CONF ACOUST SPEE, P7810, DOI 10.1109/ICASSP.2013.6639184
   Chen F, 2012, J ACOUST SOC AM, V131, P4104, DOI 10.1121/1.3695401
   Chen F, 2011, J ACOUST SOC AM, V129, P3281, DOI 10.1121/1.3570957
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Christensen CB, 2018, IEEE T BIO-MED ENG, V65, P1026, DOI 10.1109/TBME.2017.2737700
   Crosse MJ, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00604
   Dai LS, 2018, P NATL ACAD SCI USA, V115, pE3286, DOI 10.1073/pnas.1721226115
   Dai LS, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00530
   Das N, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aae0a6
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Ding N, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00311
   Ding N, 2014, NEUROIMAGE, V88, P41, DOI 10.1016/j.neuroimage.2013.10.054
   Ding N, 2013, J NEUROSCI, V33, P5728, DOI 10.1523/JNEUROSCI.5297-12.2013
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Drennan DP, 2019, ENEURO, V6, DOI 10.1523/ENEURO.0082-19.2019
   Fuglsang SA, 2017, NEUROIMAGE, V156, P435, DOI 10.1016/j.neuroimage.2017.04.026
   Golumbic EMZ, 2012, BRAIN LANG, V122, P151, DOI 10.1016/j.bandl.2011.12.010
   Guan T, 2016, J ACOUST SOC AM, V140, P3745, DOI 10.1121/1.4967453
   HOMAN RW, 1987, ELECTROEN CLIN NEURO, V66, P376, DOI 10.1016/0013-4694(87)90206-9
   Horton C, 2014, J NEURAL ENG, V11, DOI 10.1088/1741-2560/11/4/046015
   Horton C, 2013, J NEUROPHYSIOL, V109, P3082, DOI 10.1152/jn.01026.2012
   Iotzov I, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab07fe
   Kates JM, 2005, J ACOUST SOC AM, V117, P2224, DOI 10.1121/1.1862575
   Kewley-Port D, 2007, J ACOUST SOC AM, V122, P2365, DOI 10.1121/1.2773986
   Kong YY, 2014, HEARING RES, V316, P73, DOI 10.1016/j.heares.2014.07.009
   Lalor EC, 2009, J NEUROPHYSIOL, V102, P349, DOI 10.1152/jn.90896.2008
   Loeb G E, 1995, Ann Otol Rhinol Laryngol Suppl, V166, P290
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493
   Mai GT, 2016, NEUROIMAGE, V133, P516, DOI 10.1016/j.neuroimage.2016.02.064
   Mc Laughlin M, 2012, IEEE T NEUR SYS REH, V20, P443, DOI 10.1109/TNSRE.2012.2186982
   Miran S, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00262
   Mirkovic B, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/4/046007
   Mognon A, 2011, PSYCHOPHYSIOLOGY, V48, P229, DOI 10.1111/j.1469-8986.2010.01061.x
   O'Sullivan JA, 2015, CEREB CORTEX, V25, P1697, DOI 10.1093/cercor/bht355
   Obleser J, 2019, TRENDS COGN SCI, V23, P913, DOI 10.1016/j.tics.2019.08.004
   Obleser J, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00250
   Peelle JE, 2018, EAR HEARING, V39, P204, DOI 10.1097/AUD.0000000000000494
   Peelle JE, 2018, CURR BIOL, V28, pR68, DOI 10.1016/j.cub.2017.12.005
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Peelle JE, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00051
   Petersen EB, 2017, J NEUROPHYSIOL, V117, P18, DOI 10.1152/jn.00527.2016
   Schneider W., 2002, E PRIME USERS GUIDE
   Shamma SA, 2011, TRENDS NEUROSCI, V34, P114, DOI 10.1016/j.tins.2010.11.002
   Simon JZ, 2015, INT J PSYCHOPHYSIOL, V95, P184, DOI 10.1016/j.ijpsycho.2014.05.005
   Snyder JS, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00015
   Somers B, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/aae6b9
   Teng XB, 2019, NEUROIMAGE, V202, DOI 10.1016/j.neuroimage.2019.116152
   Teoh ES, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab0cf1
   Van Eyndhoven S, 2017, IEEE T BIO-MED ENG, V64, P1045, DOI 10.1109/TBME.2016.2587382
   Vanthornhout J., 2019, BIORXIV
   Wang L, 2019, HEARING RES, V383, DOI 10.1016/j.heares.2019.107808
   Xu DY, 2019, J ACOUST SOC AM, V146, pEL151, DOI 10.1121/1.5122190
   Zink R, 2017, BIORXIV, DOI [10.1101/218727, DOI 10.1101/218727]
NR 60
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD OCT 7
PY 2020
VL 14
AR 557534
DI 10.3389/fnhum.2020.557534
PG 13
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA OD4OZ
UT WOS:000579833200001
PM 33132874
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Sun, Z
   Seo, JW
   Park, HJ
   Lee, JY
   Kwak, MY
   Kim, Y
   Lee, JY
   Park, JW
   Kang, WS
   Ahn, JH
   Chung, JW
   Kim, H
AF Sun, Zhe
   Seo, Ji Won
   Park, Hong Ju
   Lee, Jee Yeon
   Kwak, Min Young
   Kim, Yehree
   Lee, Je Yeon
   Park, Jun Woo
   Kang, Woo Seok
   Ahn, Joong Ho
   Chung, Jong Woo
   Kim, Hosung
TI Cortical reorganization following auditory deprivation predicts cochlear
   implant performance in postlingually deaf adults
SO HUMAN BRAIN MAPPING
LA English
DT Article
DE cochlear implant; hearing loss; plasticity; prognosis; voxel-based
   morphometry
ID CROSS-MODAL PLASTICITY; HEARING-LOSS; FUNCTIONAL CONNECTIVITY;
   SPEECH-PERCEPTION; SIGN-LANGUAGE; CORTEX; ORGANIZATION; USERS;
   ACTIVATION; PATHWAYS
AB Long-term hearing loss in postlingually deaf (PD) adults may lead to brain structural changes that affect the outcomes of cochlear implantation. We studied 94 PD patients who underwent cochlear implantation and 37 patients who were MRI-scanned within 2 weeks after the onset of sudden hearing loss and expected with minimal brain structural changes in relation to deafness. Compared with those with sudden hearing loss, we found lower gray matter (GM) probabilities in bilateral thalami, superior, middle, inferior temporal cortices as well as the central cortical regions corresponding to the movement and sensation of the lips, tongue, and larynx in the PD group. Among these brain areas, the GM in the middle temporal cortex showed negative correlation with disease duration, whereas the other areas displayed positive correlations. Left superior, middle temporal cortical, and bilateral thalamic GMs were the most accurate predictors of post-cochlear implantation word recognition scores (mean absolute error [MAE] = 10.1,r= .82), which was superior to clinical variables used (MAE: 12.1,p < .05). Using the combined brain morphological and clinical features, we achieved the best prediction of the outcome (MAE: 8.51,r= .90). Our findings suggest that the cross-modal plasticity allowing the superior temporal cortex and thalamus to process other modal sensory inputs reverses the initially lower volume when deafness becomes persistent. The middle temporal cortex processing higher-level language comprehension shows persistent negative correlations with disease duration, suggesting this area's association with degraded speech comprehensions due to long-term deafness. Morphological features combined with clinical variables might play a key role in predicting outcomes of cochlear implantation.
C1 [Sun, Zhe; Kim, Hosung] Univ Southern Calif, Keck Sch Med, Dept Neurol, USC Stevens Neuroimaging & Informat Inst, Los Angeles, CA 90007 USA.
   [Seo, Ji Won] Sungkyunkwan Univ, Sch Med, Samsung Changwon Hosp, Dept Otorhinolaryngol Head & Neck Surg, Chang Won, South Korea.
   [Park, Hong Ju; Lee, Jee Yeon; Kwak, Min Young; Kim, Yehree; Park, Jun Woo; Kang, Woo Seok; Ahn, Joong Ho; Chung, Jong Woo] Univ Ulsan, Coll Med, Asan Med Ctr, Dept Otorhinolaryngol Head & Neck Surg, Seoul, South Korea.
   [Lee, Jee Yeon] Inje Univ, Sanggye Paik Hosp, Dept Otorhinolaryngol, Seoul, South Korea.
RP Park, HJ (corresponding author), Univ Ulsan, Coll Med, Asan Med Ctr, Otorhinolaryngol Head & Neck Surg, 88,Olymp Ro 43 Gil, Seoul 05505, South Korea.
EM dzness@amc.seoul.kr
FU BrightFocus FoundationBrightFocus Foundation [A2019052S]; National
   Institute on AgingUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Aging (NIA) [P41EB015922, U54EB020406]
FX BrightFocus Foundation, Grant/Award Number: A2019052S; National
   Institute on Aging, Grant/Award Numbers: P41EB015922, U54EB020406
CR Alfandari D, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518763689
   Bartlett EL, 2013, BRAIN LANG, V126, P29, DOI 10.1016/j.bandl.2013.03.003
   Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Beyea JA, 2016, OTOL NEUROTOL, V37, P1238, DOI 10.1097/MAO.0000000000001162
   Blamey P, 2013, AUDIOL NEURO-OTOL, V18, P36, DOI 10.1159/000343189
   Bohland JW, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007200
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   Chabot N, 2015, J COMP NEUROL, V523, P2297, DOI 10.1002/cne.23790
   Collignon O, 2011, PROG BRAIN RES, V191, P211, DOI 10.1016/B978-0-444-53752-2.00003-5
   Cunningham LL, 2017, NEW ENGL J MED, V377, P2465, DOI 10.1056/NEJMra1616601
   Fan WL, 2015, OTOL NEUROTOL, V36, P1622, DOI 10.1097/MAO.0000000000000892
   Fine I, 2005, J COGNITIVE NEUROSCI, V17, P1621, DOI 10.1162/089892905774597173
   Finney EM, 2003, NEUROREPORT, V14, P1425, DOI 10.1097/00001756-200308060-00004
   Finney EM, 2001, NAT NEUROSCI, V4, P1171, DOI 10.1038/nn763
   Friedland DR, 2003, OTOL NEUROTOL, V24, P582, DOI 10.1097/00129492-200307000-00009
   Giraud AL, 2007, RESTOR NEUROL NEUROS, V25, P381
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Goman AM, 2016, AM J PUBLIC HEALTH, V106, P1820, DOI 10.2105/AJPH.2016.303299
   Green KMJ, 2005, HEARING RES, V205, P184, DOI 10.1016/j.heares.2005.03.016
   Han JH, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00038
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Holden LK, 2013, EAR HEARING, V34, P342, DOI 10.1097/AUD.0b013e3182741aa7
   Kim E, 2014, HEARING RES, V315, P88, DOI 10.1016/j.heares.2014.06.007
   Kim H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-36404-1
   Kral A, 2010, NEW ENGL J MED, V363, P1438, DOI 10.1056/NEJMra0911225
   Krittanawong C, 2017, J AM COLL CARDIOL, V69, P2657, DOI 10.1016/j.jacc.2017.03.571
   Kujala T, 1997, PSYCHOPHYSIOLOGY, V34, P213, DOI 10.1111/j.1469-8986.1997.tb02134.x
   Lazard DS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048739
   Lee DS, 2001, NATURE, V409, P149, DOI 10.1038/35051653
   Lee HJ, 2007, CEREB CORTEX, V17, P909, DOI 10.1093/cercor/bhl001
   Lee JS, 2003, J NUCL MED, V44, P1435
   Leung J, 2005, ARCH OTOLARYNGOL, V131, P1049, DOI 10.1001/archotol.131.12.1049
   Levanen S, 2001, NEUROSCI LETT, V301, P75, DOI 10.1016/S0304-3940(01)01597-X
   Lin FR, 2012, MEDICINE, V91, P229, DOI 10.1097/MD.0b013e31826b145a
   McGettigan C, 2012, NEUROPSYCHOLOGIA, V50, P762, DOI 10.1016/j.neuropsychologia.2012.01.010
   Moradi E, 2015, NEUROIMAGE, V104, P398, DOI 10.1016/j.neuroimage.2014.10.002
   Mortensen MV, 2006, NEUROIMAGE, V31, P842, DOI 10.1016/j.neuroimage.2005.12.020
   Nishimura H, 1999, NATURE, V397, P116, DOI 10.1038/16376
   Nishimura H, 2000, NEUROREPORT, V11, P811, DOI 10.1097/00001756-200003200-00031
   Oh SH, 2003, ACTA OTO-LARYNGOL, V123, P148, DOI 10.1080/0036554021000028111
   Pacala JT, 2012, JAMA-J AM MED ASSOC, V307, P1185, DOI 10.1001/jama.2012.305
   Parker GJM, 2005, NEUROIMAGE, V24, P656, DOI 10.1016/j.neuroimage.2004.08.047
   Peelle JE, 2011, J NEUROSCI, V31, P12638, DOI 10.1523/JNEUROSCI.2559-11.2011
   PELSON RO, 1974, J SPEECH HEAR RES, V17, P518, DOI 10.1044/jshr.1703.518
   Pereira-Jorge MR, 2018, NEURAL PLAST, V2018, DOI 10.1155/2018/9303674
   Polley DB, 2006, J NEUROSCI, V26, P4970, DOI 10.1523/JNEUROSCI.3771-05.2006
   Roditi RE, 2009, OTOL NEUROTOL, V30, P449, DOI 10.1097/MAO.0b013e31819d3480
   Rubinstein JT, 1999, AM J OTOL, V20, P445
   Rudner M, 2019, J SPEECH LANG HEAR R, V62, P1117, DOI 10.1044/2018_JSLHR-H-ASCC7-18-0142
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Shibata DK, 2001, ACAD RADIOL, V8, P598, DOI 10.1016/S1076-6332(03)80684-0
   Shiell MM, 2015, J COGNITIVE NEUROSCI, V27, P150, DOI 10.1162/jocn_a_00683
   Sled JG, 1998, IEEE T MED IMAGING, V17, P87, DOI 10.1109/42.668698
   Steven MS, 2004, PERCEPTION, V33, P855, DOI 10.1068/p5160
   Strelnikov K, 2013, BRAIN, V136, P3682, DOI 10.1093/brain/awt274
   Stropahl M, 2017, HEARING RES, V343, P128, DOI 10.1016/j.heares.2016.07.005
   Verger A, 2017, HEARING RES, V353, P8, DOI 10.1016/j.heares.2017.07.011
   Worsley DF, 2010, CAN ASSOC RADIOL J, V61, P13, DOI 10.1016/j.carj.2009.07.005
NR 59
TC 0
Z9 0
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1065-9471
EI 1097-0193
J9 HUM BRAIN MAPP
JI Hum. Brain Mapp.
PD JAN
PY 2021
VL 42
IS 1
BP 233
EP 244
DI 10.1002/hbm.25219
EA OCT 2020
PG 12
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA PB1EJ
UT WOS:000575312700001
PM 33022826
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Tan, HZ
   Reed, CM
   Jiao, Y
   Perez, ZD
   Wilson, EC
   Jung, J
   Martinez, JS
   Severgnini, FM
AF Tan, Hong Z.
   Reed, Charlotte M.
   Jiao, Yang
   Perez, Zachary D.
   Wilson, E. Courtenay
   Jung, Jaehong
   Martinez, Juan S.
   Severgnini, Frederico M.
TI Acquisition of 500 English Words through a TActile Phonemic Sleeve
   (TAPS)
SO IEEE TRANSACTIONS ON HAPTICS
LA English
DT Article
DE Oral communication; Haptic interfaces; Auditory system; Thumb; Skin;
   Performance evaluation; Visualization; Tactile speech communication;
   phonemic coding; tactile phoneme identification; tactile word
   identification; language acquisition; learning rate; haptic symbols for
   English phonemes
ID TADOMA METHOD; SPEECH-PERCEPTION; HEARING; VIBROTACTILE; VOCABULARY;
   CHILDREN; DEAF
AB Recently, a phonemic-based tactile speech communication system was developed with the goal to transmit speech through the skin for people with hearing impairments and those whose auditory and visual channels are overloaded or compromised. The display, called the TActile Phonemic Sleeve (TAPS), consisted of a 4-by-6 tactor array worn on the dorsal and volar surfaces of the forearm. Earlier work showed that people were able to learn the haptic symbols for 39 English phonemes and reach a mean phoneme recognition rate of 86% correct within one to four hours of training. The current research evaluated the acquisition of up to 500 words using TAPS. A total of 51 participants were trained and tested in three studies with increasing number of phonemes and vocabulary sizes. Individual achievements varied, but the results clearly demonstrate the potential of transmitting any English word using TAPS within a reasonable period of learning. Future work will include increasing the speech transmission rate with TAPS by improving the phonemic codes and reducing the inter-phoneme intervals, addressing the reception of words and sentences composed of strings of tactile phonemes, and assessing the performance of TAPS as a speech communication system for people with severe hearing impairments.
C1 [Tan, Hong Z.; Jiao, Yang; Jung, Jaehong; Martinez, Juan S.; Severgnini, Frederico M.] Purdue Univ, Hapt Interface Res Lab, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
   [Reed, Charlotte M.; Perez, Zachary D.; Wilson, E. Courtenay] MIT, Res Lab Elect, Cambridge, MA 02139 USA.
RP Tan, HZ (corresponding author), Purdue Univ, Hapt Interface Res Lab, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM hongtan@purdue.edu; cmreed@mit.edu; jiao12@purdue.edu; zperez@mit.edu;
   ecwilson@mit.edul; jung137@purdue.edu; mart1304@purdue.edu;
   fredericomqs@gmail.com
OI Martinez, Juan/0000-0002-5457-3790
FU Facebook, Inc.
FX This work was supported by a Grant from Facebook, Inc. This article was
   recommended for publication by Associate Editor A. Kapper and
   Editor-in-Chief L. Jones upon evaluation of the reviewers' comments.
CR [Anonymous], 2009, BRAILLE LITERACY CRI
   BROOKS PL, 1983, J ACOUST SOC AM, V74, P34, DOI 10.1121/1.389685
   BROOKS PL, 1985, J ACOUST SOC AM, V77, P1576, DOI 10.1121/1.392000
   Bryan W. L., 1899, PSYCHOL REV, V6, P345, DOI DOI 10.1037/H0073117
   Carrera A, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7040317
   Cholewiak RW, 2003, PERCEPT PSYCHOPHYS, V65, P1058, DOI 10.3758/BF03194834
   COWAN RSC, 1989, J ACOUST SOC AM, V85, P2593, DOI 10.1121/1.397754
   Duchesne L, 2009, J DEAF STUD DEAF EDU, V14, P465, DOI 10.1093/deafed/enp010
   Dudai Y, 2015, NEURON, V88, P20, DOI 10.1016/j.neuron.2015.09.004
   Dunkelberger N, 2018, ISWC'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P25, DOI 10.1145/3267242.3267244
   Ecroyd D. H., 1966, VOICE ARTICULATION H
   ENGELMANN S, 1975, EXCEPT CHILDREN, V41, P243, DOI 10.1177/001440297504100402
   Foster NL, 2019, MEM COGNITION, V47, P1088, DOI 10.3758/s13421-019-00918-4
   Franklin D., 1984, HEAR J, V37, P20
   Gallace A, 2006, PERCEPTION, V35, P247, DOI 10.1068/p5380
   Galvin KL, 1999, J ACOUST SOC AM, V106, P1084, DOI 10.1121/1.428054
   GELDARD FA, 1966, PERCEPT PSYCHOPHYS, V1, P377
   Hu FQ, 2018, ANN PHYS-NEW YORK, V392, P1, DOI 10.1016/j.aop.2018.02.020
   Jiao Y, 2018, LECT NOTES COMPUT SC, V10894, P623, DOI 10.1007/978-3-319-93399-3_53
   Jones LA, 2013, IEEE T HAPTICS, V6, P268, DOI 10.1109/TOH.2012.74
   Jung JH, 2018, LECT NOTES COMPUT SC, V10919, P447, DOI 10.1007/978-3-319-91803-7_34
   Keidel W. D., 1973, CUTANEOUS COMMUNICAT, P27
   Krause JC, 2002, J ACOUST SOC AM, V112, P2165, DOI 10.1121/1.1509432
   Luzhnica G, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300465
   Luzhnica G, 2016, IEEE INT SYM WRBL CO, P148, DOI 10.1145/2971763.2971769
   Lynch M P, 1988, J Rehabil Res Dev, V25, P41
   NOLAN MF, 1982, PHYS THER, V62, P965, DOI 10.1093/ptj/62.7.965
   NORTON SJ, 1977, J SPEECH HEAR RES, V20, P574, DOI 10.1044/jshr.2003.574
   Novich S., 2015, THESIS
   Rabinowitz W. M., 1990, J ACOUST SOC AM, V87, pS88
   Reed C. M., SUBMITTED ACM T APPL
   Reed C. M., 1992, TACTILE AIDS HEARING, P218
   Reed C. M., 1982, AM SPEECH LANGUAGE H, V23
   Reed C. M., 1995, PROFOUND DEAFNESS SP, P40
   Reed CM, 2019, IEEE T HAPTICS, V12, P2, DOI 10.1109/TOH.2018.2861010
   Reed Charlotte M., 1995, Seminars in Hearing, V16, P305, DOI 10.1055/s-0028-1083728
   REED CM, 1982, J SPEECH HEAR RES, V25, P108, DOI 10.1044/jshr.2501.108
   REED CM, 1985, J ACOUST SOC AM, V77, P247, DOI 10.1121/1.392266
   REED CM, 1989, VOLTA REV, V91, P65
   REED CM, 1978, J SPEECH HEAR RES, V21, P625, DOI 10.1044/jshr.2104.625
   REED CM, 1982, J SPEECH HEAR RES, V25, P216, DOI 10.1044/jshr.2502.216
   Rohrer D, 2015, J EDUC PSYCHOL, V21, P1323
   SCHULTZ MC, 1984, VOLTA REV, V86, P282
   Spens K., 1983, STL QPSR, V24, P52
   Summers I. R., 2000, CAHIERS LAUDITION, V13, P34
   Svirsky MA, 2000, PSYCHOL SCI, V11, P153, DOI 10.1111/1467-9280.00231
   Tan HZ, 1997, PERCEPT PSYCHOPHYS, V59, P1004, DOI 10.3758/BF03205516
   TURCOTT R, 2018, LECT NOTES COMPUT SC, V894, P600, DOI DOI 10.1007/978-3-319-93399-3_51
   Wang DX, 2018, IEEE T HAPTICS, V11, P97, DOI 10.1109/TOH.2017.2742507
   WEISENBERGER JM, 1995, EAR HEARING, V16, P392, DOI 10.1097/00003446-199508000-00006
NR 50
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1939-1412
EI 2329-4051
J9 IEEE T HAPTICS
JI IEEE Trans. Haptics
PD OCT
PY 2020
VL 13
IS 4
BP 745
EP 760
DI 10.1109/TOH.2020.2973135
PG 16
WC Computer Science, Cybernetics
SC Computer Science
GA PM0BF
UT WOS:000603475100008
PM 32070998
DA 2021-02-24
ER

PT J
AU Wisniewski, MG
   Zakrzewski, AC
AF Wisniewski, Matthew G.
   Zakrzewski, Alexandria C.
TI Effects of auditory training on low-pass filtered speech perception and
   listening-related cognitive load
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID HEARING PROTECTION USE; OLDER-ADULTS; MEMORY
AB Studies supporting learning-induced reductions in listening-related cognitive load have lacked procedural learning controls, making it difficult to determine the extent to which effects arise from perceptual or procedural learning. Here, listeners were trained in the coordinate response measure (CRM) task under unfiltered (UT) or degraded low-pass filtered (FT) conditions. Improvements in low-pass filtered CRM performance were larger for FT. Both conditions showed training-related reductions in cognitive load as indexed by a secondary working memory task. However, only the FT condition showed a correlation between CRM improvement and secondary task performance, suggesting that effects can be driven by perceptual and procedural learning. (C) 2020 Acoustical Society of America
C1 [Wisniewski, Matthew G.; Zakrzewski, Alexandria C.] Kansas State Univ, Dept Psychol Sci, 1114 Midcampus Dr North, Manhattan, KS 66506 USA.
RP Wisniewski, MG (corresponding author), Kansas State Univ, Dept Psychol Sci, 1114 Midcampus Dr North, Manhattan, KS 66506 USA.
EM mgwisniewski@ksu.edu; aczakrzewski@ksu.edu
OI Zakrzewski, Alexandria/0000-0002-0169-2761
FU Cognitive and Neurobiological Approaches to Plasticity (CNAP) Center of
   Biomedical Research Excellence (COBRE) of the National Institutes of
   Health [P20GM113109]
FX We thank Michelle Wheeler, Victoria Robinson, Raelynn Slipke, Francis
   Guffy, Kelly Wilkerson, and Emma Harmon for help with data collection.
   Research reported in this publication was supported by the the Cognitive
   and Neurobiological Approaches to Plasticity (CNAP) Center of Biomedical
   Research Excellence (COBRE) of the National Institutes of Health under
   Grant No. P20GM113109.
CR Banai K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047099
   Benard MR, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0058149
   Bernarding C, 2013, BRAIN RES BULL, V91, P21, DOI 10.1016/j.brainresbull.2012.11.005
   Bolia RS, 2000, J ACOUST SOC AM, V107, P1065, DOI 10.1121/1.428288
   Borghini G, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00152
   Church BA, 2013, J EXP PSYCHOL LEARN, V39, P270, DOI 10.1037/a0028647
   Clarke-Davidson CM, 2008, PERCEPT PSYCHOPHYS, V70, P604, DOI 10.3758/PP.70.4.604
   Downs D W, 1982, ASHA, V24, P1009
   Fu Qian-Jie, 2007, Trends Amplif, V11, P193, DOI 10.1177/1084713807301379
   Gallagher H. L., 2014, AFRLRHWPTR20140148 U
   Hervais-Adelman AG, 2011, J EXP PSYCHOL HUMAN, V37, P283, DOI 10.1037/a0020772
   Hong OS, 2005, INT J AUDIOL, V44, P522, DOI 10.1080/14992020500190029
   Kuchinsky SE, 2014, PSYCHOPHYSIOLOGY, V51, P1046, DOI 10.1111/psyp.12242
   Lusk SL, 1995, HUM FACTORS, V37, P635, DOI 10.1518/001872095779049390
   McCoy SL, 2005, Q J EXP PSYCHOL-A, V58, P22, DOI 10.1080/02724980443000151
   McGarrigle R, 2014, INT J AUDIOL, V53, P433, DOI 10.3109/14992027.2014.890296
   Miles K, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517706396
   Mishra S, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00096
   Neitzel R, 2008, AM J IND MED, V51, P120, DOI 10.1002/ajim.20531
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Piquado T, 2010, PSYCHOPHYSIOLOGY, V47, P560, DOI 10.1111/j.1469-8986.2009.00947.x
   Rakauskas ME, 2004, J SAFETY RES, V35, P453, DOI 10.1016/j.jsr.2004.06.003
   Reddy R, 2014, OCCUP MED-OXFORD, V64, P198, DOI 10.1093/occmed/kqt178
   Rennies J, 2014, J ACOUST SOC AM, V135, P1556, DOI 10.1121/1.4863197
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   Schwartz BL, 2008, MEM COGNITION, V36, P9, DOI 10.3758/MC.36.1.9
   Smalt CJ, 2020, EAR HEARING, V41, P82, DOI 10.1097/AUD.0000000000000733
   Sommers Mitchell S., 2015, Seminars in Hearing, V36, P263, DOI 10.1055/s-0035-1564454
   Spencer N., 2016, J ACOUST SOC AM, V140, P3269, DOI [10.1121/1.4970377, DOI 10.1121/1.4970377]
   Strand JF, 2018, J SPEECH LANG HEAR R, V61, P1463, DOI 10.1044/2018_JSLHR-H-17-0257
   Strauss DJ, 2017, COGN AFFECT BEHAV NE, V17, P809, DOI 10.3758/s13415-017-0513-0
   Thompson ER, 2015, J ACOUST SOC AM, V138, P1297, DOI 10.1121/1.4928395
   Trabeau M, 2008, AM J IND MED, V51, P130, DOI 10.1002/ajim.20499
   Wisniewski MG, 2019, PSYCHON B REV, V26, P1889, DOI 10.3758/s13423-019-01627-4
   Wisniewski MG, 2017, PSYCHOPHYSIOLOGY, V54, P1916, DOI 10.1111/psyp.12968
   Wisniewski MG, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0180959
   Wisniewski MG, 2017, EAR HEARING, V38, pE69, DOI 10.1097/AUD.0000000000000354
   Yeung N, 2012, PHILOS T R SOC B, V367, P1310, DOI 10.1098/rstb.2011.0416
   Zekveld AA, 2014, NEUROIMAGE, V101, P76, DOI 10.1016/j.neuroimage.2014.06.069
NR 39
TC 0
Z9 0
U1 1
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD OCT
PY 2020
VL 148
IS 4
BP EL394
EP EL400
DI 10.1121/10.0001742
PG 7
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA OP4TR
UT WOS:000588076400001
PM 33138495
OA Bronze, Green Published
DA 2021-02-24
ER

PT J
AU Benson, PJ
   Wallace, L
   Beedie, SA
AF Benson, Philip J.
   Wallace, Lisa
   Beedie, Sara A.
TI Sensory auditory interval perception errors in developmental dyslexia
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Dyslexia; Auditory; Temporal; Magnocellular
ID LATERAL GENICULATE-NUCLEUS; MONOCLONAL-ANTIBODY CAT-301; VISUAL-MOTION;
   EYE-MOVEMENTS; GLOBAL MOTION; MAGNOCELLULAR DEFECT; SPEECH-PERCEPTION;
   SURFACE SUBTYPES; READING-ABILITY; WORKING-MEMORY
AB Developmental dyslexia (DD) is a heritable condition associated with reading, visual and auditory deficits. Atypical processes involved in low-level sensory coding have been implicated. We tested the contribution made by auditory magnocellular function using a behavioural task which considered the temporal difference between pairs of identical sinewave tones. Adult undergraduates with an existing diagnosis of DD (n = 78) were compared with controls (n = 111) from the same population on error rates and response times at different interval durations. Error rates and response times increased in both groups with increasing task difficulty. However, on average the DD group made uniformly more errors and slower decisions than controls. Unsupervised learning of error patterns exposed a trait continuum associated with individual differences in response efficiency. Difficulty in using temporal information in DD arising from impaired sensory coding in the auditory thalamus is suggested. The results provide strong support for the idea that auditory processing difficulties in dyslexia, along with visual and sensorimotor deficits, have a common neurodevelopmental cause.
C1 [Benson, Philip J.; Wallace, Lisa; Beedie, Sara A.] Univ Aberdeen, Sch Psychol, Aberdeen AB24 3UB, Scotland.
RP Benson, PJ (corresponding author), Univ Aberdeen, Sch Psychol, Aberdeen AB24 3UB, Scotland.
EM pjjb@gmx.com
CR Adlard A, 1998, Q J EXP PSYCHOL-A, V51, P153
   Ahissar M, 2007, TRENDS COGN SCI, V11, P458, DOI 10.1016/j.tics.2007.08.015
   Andrews TJ, 1997, J NEUROSCI, V17, P2859
   Arnett AB, 2017, J CHILD PSYCHOL PSYC, V58, P719, DOI 10.1111/jcpp.12691
   Arvaniti A, 2009, PHONETICA, V66, P46, DOI 10.1159/000208930
   Balan PF, 2009, J NEUROSCI, V29, P8166, DOI 10.1523/JNEUROSCI.0243-09.2009
   Barbeau EB, 2017, NEUROPSYCHOLOGIA, V98, P169, DOI 10.1016/j.neuropsychologia.2016.10.003
   Bartlett EL, 2013, BRAIN LANG, V126, P29, DOI 10.1016/j.bandl.2013.03.003
   Benasich AA, 2002, BEHAV BRAIN RES, V136, P31, DOI 10.1016/S0166-4328(02)00098-0
   Benassi M, 2010, DYSLEXIA, V16, P341, DOI 10.1002/dys.412
   Benson PJ, 2010, PERCEPTION, V39, P188
   Benson PJ, 2012, BIOL PSYCHIAT, V72, P716, DOI 10.1016/j.biopsych.2012.04.019
   Biscaldi M, 2000, PERCEPTION, V29, P509, DOI 10.1068/p2666a
   BLACK JL, 1984, PERCEPT MOTOR SKILL, V59, P91, DOI 10.2466/pms.1984.59.1.91
   Blythe HI, 2018, BRAIN SCI, V8, DOI 10.3390/brainsci8060100
   Bradlee Q., 2012, COMMUNICATION
   Bucci MP, 2008, GRAEF ARCH CLIN EXP, V246, P417, DOI 10.1007/s00417-007-0723-1
   Carreiras M, 2014, TRENDS COGN SCI, V18, P90, DOI 10.1016/j.tics.2013.11.005
   CASTLES A, 1993, COGNITION, V47, P149, DOI 10.1016/0010-0277(93)90003-E
   Catts HW, 2005, J SPEECH LANG HEAR R, V48, P1378, DOI 10.1044/1092-4388(2005/096)
   Centanni TM, 2016, J NEUROSCI, V36, P4895, DOI 10.1523/JNEUROSCI.4202-15.2016
   Cheeseman P.C., 1988, P 5 INT C MACH LEARN, P54
   Colling LJ, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00360
   Conlon EG, 2009, NEUROPSYCHOLOGIA, V47, P907, DOI 10.1016/j.neuropsychologia.2008.12.037
   CORNELISSEN P, 1991, DEV MED CHILD NEUROL, V33, P755
   Cornelissen PL, 1996, COGNITION, V59, P275, DOI 10.1016/0010-0277(95)00697-4
   Corriveau KH, 2009, CORTEX, V45, P119, DOI 10.1016/j.cortex.2007.09.008
   Crawford JR, 2008, BRIT J CLIN PSYCHOL, V47, P215, DOI 10.1348/014466507X258859
   Davalos DB, 2003, BRAIN COGNITION, V52, P295, DOI 10.1016/S0278-2626(03)00157-X
   Dehaene S, 2011, TRENDS COGN SCI, V15, P254, DOI 10.1016/j.tics.2011.04.003
   Demb JB, 1998, VISION RES, V38, P1555, DOI 10.1016/S0042-6989(98)00075-3
   Diaz B, 2012, P NATL ACAD SCI USA, V109, P13841, DOI 10.1073/pnas.1119828109
   Dohla D, 2016, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.02045
   DUVELLEROYHOMMET C, 1995, NEUROPSYCHOLOGIA, V33, P823, DOI 10.1016/0028-3932(95)00020-4
   Ebrahimi L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37753-7
   Eden GF, 1996, NATURE, V382, P66, DOI 10.1038/382066a0
   EDEN GF, 1994, VISION RES, V34, P1345, DOI 10.1016/0042-6989(94)90209-7
   Elliott JG, 2008, J PHILOS EDUC, V42, P475, DOI 10.1111/j.1467-9752.2008.00653.x
   Farmer ME, 1995, PSYCHON B REV, V2, P460, DOI 10.3758/BF03210983
   Fawcett AJ, 1996, ANN DYSLEXIA, V46, P259, DOI 10.1007/BF02648179
   Flint S, 2019, DYSLEXIA, V25, P69, DOI 10.1002/dys.1607
   Fostick L, 2018, ACTA PSYCHOL, V183, P19, DOI 10.1016/j.actpsy.2017.12.010
   Frederikse ME, 1999, CEREB CORTEX, V9, P896, DOI 10.1093/cercor/9.8.896
   Froyen D, 2011, DEVELOPMENTAL SCI, V14, P635, DOI 10.1111/j.1467-7687.2010.01007.x
   GALABURDA A, 1993, ANN NY ACAD SCI, V682, P70, DOI 10.1111/j.1749-6632.1993.tb22960.x
   Galaburda AM, 2006, NAT NEUROSCI, V9, P1213, DOI 10.1038/nn1772
   GALABURDA AM, 1994, P NATL ACAD SCI USA, V91, P8010, DOI 10.1073/pnas.91.17.8010
   GILGER JW, 1992, J AM ACAD CHILD PSY, V31, P343, DOI 10.1097/00004583-199203000-00024
   Giraldo-Chica M, 2015, NEUROIMAGE-CLIN, V7, P830, DOI 10.1016/j.nicl.2015.03.011
   GLICKSTEIN M, 1985, J COMP NEUROL, V235, P343, DOI 10.1002/cne.902350306
   Gori S, 2016, CEREB CORTEX, V26, P4356, DOI 10.1093/cercor/bhv206
   Gori S, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00460
   Goswami U, 2013, CORTEX, V49, P1363, DOI 10.1016/j.cortex.2012.05.005
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Grande M, 2011, NEUROIMAGE, V57, P1212, DOI 10.1016/j.neuroimage.2011.05.033
   Guerreiro MM, 2002, NEUROLOGY, V59, P245, DOI 10.1212/WNL.59.2.245
   Guo K, 1998, NEUROREPORT, V9, P3543, DOI 10.1097/00001756-199810260-00038
   Hamalainen J, 2005, BRAIN LANG, V94, P32, DOI 10.1016/j.bandl.2004.11.005
   Helenius P, 2002, J COGNITIVE NEUROSCI, V14, P603, DOI 10.1162/08989290260045846
   HENDRY SHC, 1988, J NEUROSCI, V8, P518
   HOCKFIELD S, 1990, J COMP NEUROL, V300, P320, DOI 10.1002/cne.903000305
   Howard JH, 2006, NEUROPSYCHOLOGIA, V44, P1131, DOI 10.1016/j.neuropsychologia.2005.10.015
   Hu W, 2010, BRAIN, V133, P1694, DOI 10.1093/brain/awq106
   Huss M, 2011, CORTEX, V47, P674, DOI 10.1016/j.cortex.2010.07.010
   Ivry R B, 1989, J Cogn Neurosci, V1, P136, DOI 10.1162/jocn.1989.1.2.136
   Jaffe-Dax S, 2018, ELIFE, V7, DOI 10.7554/eLife.30018
   Jaffe-Dax S, 2017, ELIFE, V6, DOI 10.7554/eLife.20557
   Jainta S, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018694
   Johnston R, 2016, BRAIN COGNITION, V108, P20, DOI 10.1016/j.bandc.2016.07.004
   Joo SJ, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04471-5
   Kaplan BJ, 1998, HUM MOVEMENT SCI, V17, P471, DOI 10.1016/S0167-9457(98)00010-4
   KETTNER RE, 1982, J COMP PHYSIOL PSYCH, V96, P328, DOI 10.1037/h0077874
   Kirby P, 2018, PSYCHOLOGIST, V31, P56
   Krafnick AJ, 2019, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02669
   Kuba M, 2001, Acta Medica (Hradec Kralove), V44, P131
   Kubova Z, 1996, PHYSIOL RES, V45, P87
   Landerl K, 2010, J CHILD PSYCHOL PSYC, V51, P287, DOI 10.1111/j.1469-7610.2009.02164.x
   Leong V, 2011, J MEM LANG, V64, P59, DOI 10.1016/j.jml.2010.09.003
   Lerma-Usabiaga G, 2018, P NATL ACAD SCI USA, V115, pE9981, DOI 10.1073/pnas.1803003115
   Linke R, 1999, EUR J NEUROSCI, V11, P187, DOI 10.1046/j.1460-9568.1999.00422.x
   LIVINGSTONE MS, 1991, P NATL ACAD SCI USA, V88, P7943, DOI 10.1073/pnas.88.18.7943
   Lorusso ML, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00313
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Lurie DI, 1997, J COMP NEUROL, V380, P319, DOI 10.1002/(SICI)1096-9861(19970414)380:3<319::AID-CNE3>3.0.CO;2-5
   Mannel C, 2015, CORTEX, V71, P291, DOI 10.1016/j.cortex.2015.06.029
   Maisog JM, 2008, ANN NY ACAD SCI, V1145, P237, DOI 10.1196/annals.1416.024
   Marino C, 2014, CORTEX, V57, P227, DOI 10.1016/j.cortex.2014.04.016
   McAnally KI, 1996, P ROY SOC B-BIOL SCI, V263, P961, DOI 10.1098/rspb.1996.0142
   McAnally KI, 2000, J DEV PHYS DISABIL, V12, P145, DOI 10.1023/A:1009459622805
   MILES FA, 1986, J NEUROPHYSIOL, V56, P1321
   Miura K, 2014, J NEUROSCI, V34, P2160, DOI 10.1523/JNEUROSCI.3797-13.2014
   MOWFORTH P, 1981, PERCEPTION, V10, P299, DOI 10.1068/p100299
   Muller-Axt C, 2017, CURR BIOL, V27, P3692, DOI 10.1016/j.cub.2017.10.034
   Nagarajan S, 1999, P NATL ACAD SCI USA, V96, P6483, DOI 10.1073/pnas.96.11.6483
   Nicolson RI, 2019, FRONT BEHAV NEUROSCI, V13, DOI 10.3389/fnbeh.2019.00112
   O'Brien BA, 2005, J RES READ, V28, P332, DOI 10.1111/j.1467-9817.2005.00273.x
   Olulade OA, 2013, NEURON, V79, P180, DOI 10.1016/j.neuron.2013.05.002
   Ozernov-Palchik O, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12471
   Pammer K, 2005, J RES READ, V28, P320, DOI 10.1111/j.1467-9817.2005.00272.x
   Paradis J., 2011, DUAL LANGUAGE DEV DI
   Paulesu E, 2001, SCIENCE, V291, P2165, DOI 10.1126/science.1057179
   Paulesu E, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00830
   Paz-Alonso PM, 2018, NEUROIMAGE-CLIN, V20, P433, DOI 10.1016/j.nicl.2018.08.018
   Penolazzi B, 2008, PSYCHOPHYSIOLOGY, V45, P1025, DOI 10.1111/j.1469-8986.2008.00709.x
   Peterson RL, 2014, SCI STUD READ, V18, P347, DOI 10.1080/10888438.2014.904870
   Peterson RL, 2013, COGNITION, V126, P20, DOI 10.1016/j.cognition.2012.08.007
   Peterson RL, 2012, LANCET, V379, P1997, DOI 10.1016/S0140-6736(12)60198-6
   Piotrowska B, 2019, VISION RES, V159, P48, DOI 10.1016/j.visres.2019.03.007
   Pitt A.T., 2009, AUDITORY DISCRIMINAT
   Protopapas A, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0090
   Przekoracka-Krawczyk A, 2017, INVEST OPHTH VIS SCI, V58, P6470, DOI 10.1167/iovs.16-21305
   Quaia C, 2012, J VISION, V12, DOI 10.1167/12.4.13
   Ramsay MW, 2014, STRABISMUS, V22, P147, DOI 10.3109/09273972.2014.971823
   Ramus F, 2018, NEUROSCI BIOBEHAV R, V84, P434, DOI 10.1016/j.neubiorev.2017.08.001
   Raschle NM, 2014, CEREB CORTEX, V24, P2489, DOI 10.1093/cercor/bht104
   REED MA, 1989, J EXP CHILD PSYCHOL, V48, P270, DOI 10.1016/0022-0965(89)90006-4
   Reilhac C, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00154
   Rendall AR, 2019, GENES BRAIN BEHAV, V18, DOI 10.1111/gbb.12450
   Richlan F, 2011, NEUROIMAGE, V56, P1735, DOI 10.1016/j.neuroimage.2011.02.040
   Richlan F, 2009, HUM BRAIN MAPP, V30, P3299, DOI 10.1002/hbm.20752
   Rodrigues AP, 2017, INVEST OPHTH VIS SCI, V58, P309, DOI 10.1167/iovs.16-20095
   Roehm D, 2004, NEUROREPORT, V15, P409, DOI 10.1097/00001756-200403010-00005
   Rosen S, 1999, CURR BIOL, V9, pR698, DOI 10.1016/S0960-9822(99)80443-6
   Saalmann YB, 2007, SCIENCE, V316, P1612, DOI 10.1126/science.1139140
   Schulte-Korne G, 2004, NEUROREPORT, V15, P1075, DOI 10.1097/01.wnr.000012338787650.e2
   Sebastian R, 2014, COGN NEUROPSYCHOL, V31, P511, DOI 10.1080/02643294.2014.884060
   SHAYWITZ BA, 1992, J LEARN DISABIL, V25, P639, DOI 10.1177/002221949202501003
   Siegel Linda S, 2006, Paediatr Child Health, V11, P581
   Skoyles J, 2004, BRAIN LANG, V88, P79, DOI 10.1016/S0093-934X(03)00162-7
   Sperling AJ, 2005, NAT NEUROSCI, V8, P862, DOI 10.1038/nn1474
   Sperling AJ, 2006, PSYCHOL SCI, V17, P1047, DOI 10.1111/j.1467-9280.2006.01825.x
   Stanovich KE, 1997, J EDUC PSYCHOL, V89, P114, DOI 10.1037/0022-0663.89.1.114
   Stein J, 2001, Dyslexia, V7, P12, DOI 10.1002/dys.186
   STEIN J, 1985, LANCET, V2, P69
   Stein J. F., 1993, J RES READ, V16, P30, DOI DOI 10.1111/J.1467-9817.1993.TB00033.X
   STEIN JF, 1992, PHYSIOL REV, V72, P967
   Stein JF, 2000, BRAIN, V123, P164, DOI 10.1093/brain/123.1.164
   Stein J, 2019, NEUROPSYCHOLOGIA, V130, P66, DOI 10.1016/j.neuropsychologia.2018.03.022
   Stein J, 2018, BRAIN SCI, V8, DOI 10.3390/brainsci8020026
   Stringer G., DYSLEXIA IS MYTH
   Talcott JB, 2000, NEUROPSYCHOLOGIA, V38, P935, DOI 10.1016/S0028-3932(00)00020-8
   Talcott Joel B, 2002, Dyslexia, V8, P204, DOI 10.1002/dys.224
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Tallal P, 2004, NAT REV NEUROSCI, V5, P721, DOI 10.1038/nrn1499
   TALLAL P, 1993, ANN NY ACAD SCI, V682, P27, DOI 10.1111/j.1749-6632.1993.tb22957.x
   Tanaka H, 2011, PSYCHOL SCI, V22, P1442, DOI 10.1177/0956797611419521
   Thomson JM, 2008, J PHYSIOL-PARIS, V102, P120, DOI 10.1016/j.jphysparis.2008.03.007
   Thomson JM, 2006, J RES READ, V29, P334, DOI 10.1111/j.1467-9817.2006.00312.x
   Trehub SE, 1996, J SPEECH HEAR RES, V39, P1315, DOI 10.1044/jshr.3906.1315
   Truong DT, 2014, GENES BRAIN BEHAV, V13, P802, DOI 10.1111/gbb.12170
   Trussell LO, 1997, CURR OPIN NEUROBIOL, V7, P487, DOI 10.1016/S0959-4388(97)80027-X
   Tschentscher N, 2019, J NEUROSCI, V39, P1720, DOI 10.1523/JNEUROSCI.1435-18.2018
   Valsecchi M, 2013, J VISION, V13, DOI 10.1167/13.13.7
   van der Lely HKJ, 1998, CURR BIOL, V8, P1253, DOI 10.1016/S0960-9822(07)00534-9
   van der Mark S, 2011, NEUROIMAGE, V54, P2426, DOI 10.1016/j.neuroimage.2010.10.002
   Vandermosten M, 2012, BRAIN, V135, P935, DOI 10.1093/brain/awr363
   Vidyasagar TR, 2019, FRONT NEURAL CIRCUIT, V13, DOI 10.3389/fncir.2019.00003
   Vidyasagar TR, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00811
   von Kriegstein K, 2008, CURR BIOL, V18, P1855, DOI 10.1016/j.cub.2008.10.052
   Waye Mary M Y, 2017, Clin Pract Epidemiol Ment Health, V13, P104, DOI 10.2174/1745017901713010104
   White-Schwoch T, 2015, PLOS BIOL, V13, DOI 10.1371/journal.pbio.1002196
   Wilson AJ, 2015, LEARN INDIVID DIFFER, V37, P118, DOI 10.1016/j.lindif.2014.11.017
   WINER JA, 1984, HEARING RES, V15, P225, DOI 10.1016/0378-5955(84)90031-5
   Winer JA, 2005, TRENDS NEUROSCI, V28, P255, DOI 10.1016/j.tins.2005.03.009
   Witton C, 1998, CURR BIOL, V8, P791, DOI 10.1016/S0960-9822(98)70320-3
   Wolff P. H., 2002, READ WRIT, V15, P179, DOI [10.1023/A:1013880723925, DOI 10.1023/A:1013880723925]
   WOLFF PH, 1990, J SPEECH HEAR RES, V33, P281, DOI 10.1044/jshr.3302.281
   Wright BA, 1997, NATURE, V387, P176, DOI 10.1038/387176a0
   Zorzi M, 2012, P NATL ACAD SCI USA, V109, P11455, DOI 10.1073/pnas.1205566109
NR 169
TC 0
Z9 0
U1 5
U2 5
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD OCT
PY 2020
VL 147
AR 107587
DI 10.1016/j.neuropsychologia.2020.107587
PG 11
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA OG3AN
UT WOS:000581761400021
PM 32841631
DA 2021-02-24
ER

PT J
AU Zou, Y
   Lui, M
   Tsang, YK
AF Zou, Yun
   Lui, Ming
   Tsang, Yiu-Kei
TI The roles of lexical tone and rime during Mandarin sentence
   comprehension: An event-related potential study
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Lexical tone; Rime; Mandarin Chinese; Event-related potentials; Speech
   perception
ID SPOKEN WORD RECOGNITION; PHONOLOGICAL AWARENESS; CHINESE; INFORMATION;
   PERCEPTION; ACTIVATION; LANGUAGE; ERP
AB This study used event-related potential (ERP) recording to examine the role of lexical tone and rime in Mandarin Chinese spoken sentence comprehension. A violation paradigm was adopted, such that selected target syllables in the sentences were replaced with tone-violated, rime-violated, or double-violated syllables. Participants judged whether each sentence was congruent. The behavioral results confirmed previous findings: Tone violation was more difficult to detect than rime violation. The ERP results showed that rime and double violations, but not tone violation, elicited a larger N400 than the original condition. Similarly, tone and rime violations elicited a larger P600 than the original condition, and the effect started and ended 50 ms earlier in the tone-violation type. Interestingly, the double-violation type differed significantly from the original type only in the posterior electrodes, suggesting a weaker P600 effect than the tone- and rime-violation types. The differences in ERP effects between rime and tone processing indicate that rime played a more important role in semantic access, while tone played a more important role in error recovery. A model of Chinese speech perception was proposed to accommodate the different roles of lexical tone and rime at different processing stages during sentence comprehension.
C1 Hong Kong Baptist Univ, Dept Educ Studies, Hong Kong, Peoples R China.
   Hong Kong Baptist Univ, Ctr Learning Sci, Hong Kong, Peoples R China.
RP Tsang, YK (corresponding author), Hong Kong Baptist Univ, Dept Educ Studies, Kowloon Tong, Kowloon, Hong Kong, Peoples R China.
EM yktsang@hkbu.edu.hk
FU General Research Fund [12606717]; Research Grants Council of the Hong
   Kong Special Administrative Region, ChinaHong Kong Research Grants
   Council
FX This work was supported by General Research Fund (No: 12606717) from the
   Research Grants Council of the Hong Kong Special Administrative Region,
   China.
CR Bao Y, 2013, COGNITION, V129, P579, DOI 10.1016/j.cognition.2013.08.019
   Barber HA, 2013, BRAIN LANG, V125, P47, DOI 10.1016/j.bandl.2013.01.005
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Choi W, 2017, J NEUROLINGUIST, V41, P11, DOI 10.1016/j.jneuroling.2016.09.003
   Cutler A, 1997, PERCEPT PSYCHOPHYS, V59, P165, DOI 10.3758/BF03211886
   Gouvea AC, 2010, LANG COGNITIVE PROC, V25, P149, DOI 10.1080/01690960902965951
   GREENHOUSE SW, 1959, PSYCHOMETRIKA, V24, P95, DOI 10.1007/BF02289823
   Hu JH, 2012, PSYCHOPHYSIOLOGY, V49, P1179, DOI 10.1111/j.1469-8986.2012.01406.x
   Huang XJ, 2018, NEUROREPORT, V29, P356, DOI 10.1097/WNR.0000000000000973
   Huang XJ, 2014, NEUROPSYCHOLOGIA, V63, P165, DOI 10.1016/j.neuropsychologia.2014.08.015
   Jaisin K, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00662
   Jarvikivi J, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0012603
   Jia S, 2015, NEUROSCIENCE, V305, P351, DOI 10.1016/j.neuroscience.2015.08.009
   Koelsch S, 2004, NAT NEUROSCI, V7, P302, DOI 10.1038/nn1197
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Li CC, 2013, PSYCHON B REV, V20, P773, DOI 10.3758/s13423-013-0395-2
   Li K, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0071290
   Liu SY, 2007, LANG COGNITIVE PROC, V22, P566, DOI 10.1080/01690960600989600
   Liu YY, 2007, BEHAV RES METHODS, V39, P192, DOI 10.3758/BF03193147
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Malins JG, 2012, NEUROPSYCHOLOGIA, V50, P2032, DOI 10.1016/j.neuropsychologia.2012.05.002
   Malins JG, 2010, J MEM LANG, V62, P407, DOI 10.1016/j.jml.2010.02.004
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   McBride-Chang C, 2004, J EXP CHILD PSYCHOL, V89, P93, DOI 10.1016/j.jecp.2004.05.001
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   Nygaard LC, 2002, MEM COGNITION, V30, P583, DOI 10.3758/BF03194959
   OSTERHOUT L, 1993, LANG COGNITIVE PROC, V8, P413, DOI 10.1080/01690969308407584
   Schirmer A, 2005, J COGNITIVE NEUROSCI, V17, P1, DOI 10.1162/0898929052880057
   Sereno JA, 2015, LANG SPEECH, V58, P131, DOI 10.1177/0023830914522956
   Shao J, 2019, NEUROIMAGE-CLIN, V23, DOI 10.1016/j.nicl.2019.101814
   Shu H, 2008, DEVELOPMENTAL SCI, V11, P171, DOI 10.1111/j.1467-7687.2007.00654.x
   Shuai L., 2016, BEHAV RES METHODS, P1, DOI DOI 10.3758/S13428-015-0567-2
   Shuai L, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00097
   Sun CC, 2018, BEHAV RES METHODS, V50, P2606, DOI 10.3758/s13428-018-1038-3
   Taft M., 1992, LANGUAGE PROCESSING, V90, P151, DOI DOI 10.1016/S0166-4115(08)61891-9
   Tanner D, 2017, PSYCHOPHYSIOLOGY, V54, P248, DOI 10.1111/psyp.12788
   Tong XL, 2014, J SPEECH LANG HEAR R, V57, P1589, DOI 10.1044/2014_JSLHR-S-13-0145
   Tong YX, 2008, LANG COGNITIVE PROC, V23, P689, DOI 10.1080/01690960701728261
   Tsang YK, 2011, NEUROSCI LETT, V487, P268, DOI 10.1016/j.neulet.2010.10.035
   Wang JB, 2015, ACSR ADV COMPUT, V10, P11
   Wiener S., 2014, LANG COGN NEUROSCI, V30, P1048, DOI DOI 10.1080/23273798.2014.946934
   Wiener S, 2016, LANG SPEECH, V59, P59, DOI 10.1177/0023830915578000
   Ye Y, 1999, LANG COGNITIVE PROC, V14, P609, DOI 10.1080/016909699386202
   Zhao JJ, 2011, NEUROPSYCHOLOGIA, V49, P1761, DOI 10.1016/j.neuropsychologia.2011.02.054
NR 44
TC 0
Z9 0
U1 1
U2 1
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD OCT
PY 2020
VL 147
AR 107578
DI 10.1016/j.neuropsychologia.2020.107578
PG 9
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA OG3AN
UT WOS:000581761400012
PM 32745475
DA 2021-02-24
ER

PT J
AU Zhang, YX
   Nakajima, Y
   Ueda, K
   Kishida, T
   Remijn, GB
AF Zhang, Yixin
   Nakajima, Yoshitaka
   Ueda, Kazuo
   Kishida, Takuya
   Remijn, Gerard B.
TI Comparison of Multivariate Analysis Methods as Applied to English Speech
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE speech perception; English phoneme; factor analysis; spectral change;
   sonority
AB A newly developed factor analysis, origin-shifted factor analysis, was compared with a normal factor analysis to analyze the spectral changes of English speech. Our first aim was to investigate whether these analyses would cause differences in the factor loadings and the extracted spectral-factor scores. The methods mainly differed in whether to use cepstral liftering and an origin shift. The results showed that three spectral factors were obtained in four main frequency bands, but neither the cepstral liftering nor the origin shift distorted the essential characteristics of the factors. This confirms that the origin-shifted factor analysis is more recommendable for future speech analyses, since it would reduce the generation of noise in resynthesized speech. Our second aim was to further identify acoustic correlates of English phonemes. Our data show for the first time that the distribution of obstruents in English speech constitutes an L-shape related to two spectral factors on the three-dimensional configuration. One factor had center loadings around 4100 Hz, while the other was bimodal with peaks around 300 Hz and 2300 Hz. This new finding validates the use of multivariate analyses to connect English phonology and speech acoustics.
C1 [Zhang, Yixin] Kyushu Univ, Human Sci Int Course, Fukuoka 8158540, Japan.
   [Nakajima, Yoshitaka] Sound Corp, Fukuoka 8130001, Japan.
   [Ueda, Kazuo] Kyushu Univ, Dept Human Sci, Fac Design, Res Ctr Appl Perceptual Sci,Res & Dev Ctr Five Se, Fukuoka 8158540, Japan.
   [Kishida, Takuya] Univ Electrocommun, Grad Sch Informat & Engn, Tokyo 1828585, Japan.
   [Remijn, Gerard B.] Kyushu Univ, Dept Human Sci, Res Ctr Appl Perceptual Sci, Fukuoka 8158540, Japan.
RP Zhang, YX (corresponding author), Kyushu Univ, Human Sci Int Course, Fukuoka 8158540, Japan.
EM 3DS20005M@s.kyushu-u.ac.jp; yoshitaka.nakajima@100years.life;
   ueda@design.kyushu-u.ac.jp; kishida@uec.ac.jp;
   remijn@design.kyushu-u.ac.jp
RI 上田, 和夫/I-5213-2019
OI 上田, 和夫/0000-0002-1885-0463; Remijn, Gerard/0000-0002-8681-9951
FU JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [JP17H06197,
   JP19H00630]; JST SCORE
FX This research and the APC were funded by JSPS KAKENHI, grant numbers
   JP17H06197 and JP19H00630, and JST SCORE (to Y.N. in FY2019).
CR Awan SN, 2012, J VOICE, V26, DOI 10.1016/j.jvoice.2011.12.001
   Campbell N, 1993, ATR BRIT ENGLISH SPE
   Fery C, 2003, SYLLABLE OPTIMALITY, P356
   Harris J., 1994, ENGLISH SOUND STRUCT, P47
   KAISER HF, 1958, PSYCHOMETRIKA, V23, P187, DOI 10.1007/BF02289233
   Kishida T, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00517
   LENNIG M, 1984, SPEECH COMMUN, V3, P165, DOI 10.1016/0167-6393(84)90038-4
   Nakajima Y, 2018, ACOUST SCI TECHNOL, V39, P179, DOI 10.1250/ast.39.179
   Nakajima Y, 2017, SCI REP-UK, V7, DOI 10.1038/srep46049
   Nyquist H, 1928, T AIEE, V47, P617, DOI [10.1109/T-AIEE.1928.5055024, DOI 10.1109/T-AIEE.1928.5055024]
   PLOMP R, 1967, J ACOUST SOC AM, V41, P707, DOI 10.1121/1.1910398
   POLS LCW, 1973, J ACOUST SOC AM, V53, P1093, DOI 10.1121/1.1913429
   Smith JO, 1999, IEEE T SPEECH AUDI P, V7, P697, DOI 10.1109/89.799695
   Spencer A., 1996, PHONOLOGY THEORY DES
   Ueda K, 2017, SCI REP-UK, V7, DOI 10.1038/srep42468
   ZAHORIAN SA, 1981, J ACOUST SOC AM, V69, P832, DOI 10.1121/1.385539
   ZWICKER E, 1980, J ACOUST SOC AM, V68, P1523, DOI 10.1121/1.385079
   ZWICKER E, 1961, J ACOUST SOC AM, V33, P248, DOI 10.1121/1.1908630
NR 18
TC 0
Z9 0
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD OCT
PY 2020
VL 10
IS 20
AR 7076
DI 10.3390/app10207076
PG 12
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
SC Chemistry; Engineering; Materials Science; Physics
GA OL3EK
UT WOS:000585223700001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Marchetta, P
   Savitska, D
   Kubler, A
   Asola, G
   Manthey, M
   Mohrle, D
   Schimmang, T
   Ruttiger, L
   Knipper, M
   Singer, W
AF Marchetta, Philine
   Savitska, Daria
   Kuebler, Angelika
   Asola, Giulia
   Manthey, Marie
   Moehrle, Dorit
   Schimmang, Thomas
   Ruettiger, Lukas
   Knipper, Marlies
   Singer, Wibke
TI Age-Dependent Auditory Processing Deficits after Cochlear Synaptopathy
   Depend on Auditory Nerve Latency and the Ability of the Brain to Recruit
   LTP/BDNF
SO BRAIN SCIENCES
LA English
DT Article
DE central compensation; cochlear synaptopathy; auditory nerve latency;
   age-related hearing loss; activity dependent BDNF; long term
   potentiation
ID HAIR-CELLS; SPEECH-PERCEPTION; HEARING-LOSS; NOISE; NUCLEUS; FIBERS;
   PLASTICITY; HYPERACTIVITY; MODULATION; AUDIOGRAMS
AB Age-related decoupling of auditory nerve fibers from hair cells (cochlear synaptopathy) has been linked to temporal processing deficits and impaired speech recognition performance. The link between both is elusive. We have previously demonstrated that cochlear synaptopathy, if centrally compensated through enhanced input/output function (neural gain), can prevent age-dependent temporal discrimination loss. It was also found that central neural gain after acoustic trauma was linked to hippocampal long-term potentiation (LTP) and upregulation of brain-derived neurotrophic factor (BDNF). Using middle-aged and old BDNF-live-exon-visualization (BLEV) reporter mice we analyzed the specific recruitment of LTP and the activity-dependent usage of Bdnf exon-IV and -VI promoters relative to cochlear synaptopathy and central (temporal) processing. For both groups, specimens with higher or lower ability to centrally compensate diminished auditory nerve activity were found. Strikingly, low compensating mouse groups differed from high compensators by prolonged auditory nerve latency. Moreover, low compensators exhibited attenuated responses to amplitude-modulated tones, and a reduction of hippocampal LTP and Bdnf transcript levels in comparison to high compensators. These results suggest that latency of auditory nerve processing, recruitment of hippocampal LTP, and Bdnf transcription, are key factors for age-dependent auditory processing deficits, rather than cochlear synaptopathy or aging per se.
C1 [Marchetta, Philine; Savitska, Daria; Kuebler, Angelika; Asola, Giulia; Manthey, Marie; Moehrle, Dorit; Ruettiger, Lukas; Knipper, Marlies; Singer, Wibke] Univ Tubingen, Tubingen Hearing Res Ctr THRC, Dept Otolaryngol Head & Neck Surg, Mol Physiol Hearing, Elfriede Aulhorn Str 5, D-72076 Tubingen, Germany.
   [Schimmang, Thomas] Univ Valladolid, Inst Biol Genet Mol, E-47003 Valladolid, Spain.
   [Schimmang, Thomas] CSIC, E-47003 Valladolid, Spain.
RP Knipper, M (corresponding author), Univ Tubingen, Tubingen Hearing Res Ctr THRC, Dept Otolaryngol Head & Neck Surg, Mol Physiol Hearing, Elfriede Aulhorn Str 5, D-72076 Tubingen, Germany.
EM philine.marchetta@uni-tuebingen.de; daria.savitska@uni-tuebingen.de;
   kuebler.angelika@gmail.com; guiliaasola@hotmail.it;
   marie.manthey@tufts.edu; dorit.moehrle@googlemail.com;
   schimman@ibgm.uva.es; lukas.ruettiger@uni-tuebingen.de;
   marlies.knipper@uni-tuebingen.de; wibke.singer@uni-tuebingen.de
RI Schimmang, Thomas/Z-2834-2019
OI Schimmang, Thomas/0000-0002-3801-1640
FU Deutsche ForschungsgemeinschaftGerman Research Foundation (DFG) [FOR
   2060, RU 713/3-2, 335549539/GRK 2381, SPP 1608 RU 316/12-1, KN
   316/12-1]; Siegmund Kiener Stiftung;  [BFU2016-76580-P]
FX We acknowledge grants from the Deutsche Forschungsgemeinschaft FOR 2060
   project RU 713/3-2 (W.S., L.R., D.M.), Projektnummer 335549539/GRK 2381
   (P.M.), SPP 1608 RU 316/12-1 (L.R.), and KN 316/12-1 (M.M, M.K.),
   Siegmund Kiener Stiftung (D.S.) and BFU2016-76580-P (T.S).
CR Arango-Lievano M, 2019, P NATL ACAD SCI USA, V116, P13097, DOI 10.1073/pnas.1903203116
   Bharadwaj HM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00026
   Bidet-Caulet A, 2007, J NEUROSCI, V27, P9252, DOI 10.1523/JNEUROSCI.1402-07.2007
   Bourien J, 2014, J NEUROPHYSIOL, V112, P1025, DOI 10.1152/jn.00738.2013
   Bramhall N, 2015, J AM ACAD AUDIOL, V26, P509, DOI 10.3766/jaaa.14100
   Broadway JM, 2011, ACTA PSYCHOL, V137, P115, DOI 10.1016/j.actpsy.2011.03.008
   Brugge JF, 2009, J NEUROPHYSIOL, V102, P2358, DOI 10.1152/jn.91346.2008
   Buran BN, 2010, J NEUROSCI, V30, P7587, DOI 10.1523/JNEUROSCI.0389-10.2010
   Burkard R.F., 2007, AUDITORY EVOKED POTE
   Cai SQ, 2009, JARO-J ASSOC RES OTO, V10, P5, DOI 10.1007/s10162-008-0142-y
   CASPARY DM, 1995, EXP GERONTOL, V30, P349, DOI 10.1016/0531-5565(94)00052-5
   Chacon-Fernandez P, 2016, J BIOL CHEM, V291, P9872, DOI 10.1074/jbc.M116.720029
   Chenaux G, 2016, ENEURO, V3, DOI 10.1523/ENEURO.0130-16.2016
   Chumak T, 2016, MOL NEUROBIOL, V53, P5607, DOI 10.1007/s12035-015-9474-x
   de Kloet ER, 2014, ENDOCRINOLOGY, V155, P2754, DOI 10.1210/en.2014-1048
   Dehmel S, 2012, J NEUROSCI, V32, P1660, DOI 10.1523/JNEUROSCI.4608-11.2012
   Dieni S, 2012, J CELL BIOL, V196, P775, DOI 10.1083/jcb.201201038
   Dragicevic CD, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0208939
   Engel J, 2006, NEUROSCIENCE, V143, P837, DOI 10.1016/j.neuroscience.2006.08.060
   Frisina DR, 1997, HEARING RES, V106, P95, DOI 10.1016/S0378-5955(97)00006-3
   Frisina RD, 1996, J ACOUST SOC AM, V99, P475, DOI 10.1121/1.414559
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Fullgrabe C, 2014, J ACOUST SOC AM, V136, pEL185, DOI 10.1121/1.4890201
   Furman AC, 2013, J NEUROPHYSIOL, V110, P577, DOI 10.1152/jn.00164.2013
   Gleich O, 2016, EXP GERONTOL, V84, P61, DOI 10.1016/j.exger.2016.08.011
   Groschel M, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/909260
   Grose JH, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216519839615
   Grose JH, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517737417
   Heeringa AN, 2014, HEARING RES, V312, P38, DOI 10.1016/j.heares.2014.03.004
   Heinz MG, 2005, JARO-J ASSOC RES OTO, V6, P91, DOI 10.1007/s10162-004-5043-0
   Heinz MG, 2004, J NEUROPHYSIOL, V91, P784, DOI 10.1152/jn.00776.2003
   Hillman EMC, 2014, ANNU REV NEUROSCI, V37, P161, DOI 10.1146/annurev-neuro-071013-014111
   Hu H, 2014, SCIENCE, V345, P529, DOI 10.1126/science.1255263
   Irvine DRF, 2018, HEARING RES, V362, P61, DOI 10.1016/j.heares.2017.10.011
   Irvine DRF, 2018, HEARING RES, V366, P3, DOI 10.1016/j.heares.2018.03.011
   Jaumann M, 2012, NAT MED, V18, P252, DOI 10.1038/nm.2634
   JOHNSON DH, 1976, BIOPHYS J, V16, P719, DOI 10.1016/S0006-3495(76)85724-4
   Kaltenbach JA, 2007, HEARING RES, V226, P232, DOI 10.1016/j.heares.2006.07.001
   Kamerer AM, 2019, AM J AUDIOL, V28, P843, DOI 10.1044/2019_AJA-19-0063
   Khimich D, 2005, NATURE, V434, P889, DOI 10.1038/nature03418
   Kilgard MP, 2002, BIOL CYBERN, V87, P333, DOI 10.1007/s00422-002-0352-z
   KING K, 1992, SCAND AUDIOL, V21, P109, DOI 10.3109/01050399209045990
   Knipper M, 2020, J NEUROSCI, V40, P7190, DOI 10.1523/JNEUROSCI.1314-19.2020
   Kobel M, 2017, HEARING RES, V349, P148, DOI 10.1016/j.heares.2016.12.008
   Kraus N, 2015, TRENDS COGN SCI, V19, P642, DOI 10.1016/j.tics.2015.08.017
   Kujawa SG, 2015, HEARING RES, V330, P191, DOI 10.1016/j.heares.2015.02.009
   Kujawa SG, 2009, J NEUROSCI, V29, P14077, DOI 10.1523/JNEUROSCI.2845-09.2009
   Kuwada Shigeyuki, 2002, J Am Acad Audiol, V13, P188
   Levakova M, 2015, BIOSYSTEMS, V136, P23, DOI 10.1016/j.biosystems.2015.04.008
   Liberman MC, 2017, HEARING RES, V349, P138, DOI 10.1016/j.heares.2017.01.003
   Lin VYW, 2017, LARYNGOSCOPE, V127, pS4, DOI 10.1002/lary.26590
   Livingston G, 2015, LANCET, V386, P933, DOI 10.1016/S0140-6736(15)00078-1
   Malmierca MS, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00111
   Marchetta P, 2020, FRONT AGING NEUROSCI, V12, DOI 10.3389/fnagi.2020.00083
   Matt L, 2018, FRONT MOL NEUROSCI, V11, DOI 10.3389/fnmol.2018.00260
   Matt L, 2011, CELL MOL LIFE SCI, V68, P125, DOI 10.1007/s00018-010-0446-z
   Melcher JR, 1996, HEARING RES, V93, P52, DOI 10.1016/0378-5955(95)00200-6
   Miller EK, 2013, CURR OPIN NEUROBIOL, V23, P216, DOI 10.1016/j.conb.2012.11.011
   Mohrle D, 2016, NEUROBIOL AGING, V44, P173, DOI 10.1016/j.neurobiolaging.2016.05.001
   Montero-Odasso M, 2020, ALZHEIMERS RES THER, V12, DOI 10.1186/s13195-020-00646-x
   Nunez A, 2007, ADV ANAT EMBRYOL CEL, V187, P1
   Ouda L, 2015, CELL TISSUE RES, V361, P337, DOI 10.1007/s00441-014-2107-2
   Parthasarathy A, 2018, J NEUROSCI, V38, P7108, DOI 10.1523/JNEUROSCI.3240-17.2018
   Prendergast G, 2017, HEARING RES, V344, P68, DOI 10.1016/j.heares.2016.10.028
   RHODE WS, 1986, J NEUROPHYSIOL, V56, P261
   RHODE WS, 1986, J NEUROPHYSIOL, V56, P287
   Ridley CL, 2018, EAR HEARING, V39, P829, DOI 10.1097/AUD.0000000000000543
   Ruel J, 2008, J NEUROSCI, V28, P7313, DOI 10.1523/JNEUROSCI.5335-07.2008
   Ruttiger L, 2017, ORL J OTO-RHINO-LARY, V79, P93, DOI 10.1159/000455705
   Salvi RJ, 2000, HEARING RES, V147, P261, DOI 10.1016/S0378-5955(00)00136-2
   SAUNDERS G H, 1992, British Journal of Audiology, V26, P33, DOI 10.3109/03005369209077869
   Schaette R, 2012, FRONT SYST NEUROSCI, V6, DOI 10.3389/fnsys.2012.00034
   Schaette R, 2009, J NEUROPHYSIOL, V101, P3042, DOI 10.1152/jn.91256.2008
   Schmiedt RA, 1996, J NEUROPHYSIOL, V76, P2799
   Schonwiesner M, 2007, J NEUROPHYSIOL, V97, P2075, DOI 10.1152/jn.01083.2006
   Sergeyenko Y, 2013, J NEUROSCI, V33, P13686, DOI 10.1523/JNEUROSCI.1783-13.2013
   Shi YL, 2016, J CEREBR BLOOD F MET, V36, P1653, DOI 10.1177/0271678X16662891
   Singer W, 2020, HEARING BALANC COMMU, V18, P225, DOI 10.1080/21695717.2020.1816116
   Singer W, 2018, FRONT MOL NEUROSCI, V11, DOI 10.3389/fnmol.2018.00325
   Singer W, 2016, METHODS MOL BIOL, V1427, P263, DOI 10.1007/978-1-4939-3615-1_15
   Sowell ER, 2001, J INT NEUROPSYCH SOC, V7, P312, DOI 10.1017/S135561770173305X
   Stephens D, 2000, ACTA OTO-LARYNGOL, V120, P197
   Tucsek Z, 2017, GEROSCIENCE, V39, P385, DOI 10.1007/s11357-017-9981-y
   Valero MD, 2017, HEARING RES, V353, P213, DOI 10.1016/j.heares.2017.07.003
   Viana LM, 2015, HEARING RES, V327, P78, DOI 10.1016/j.heares.2015.04.014
   Viho EMG, 2019, NEUROENDOCRINOLOGY, V109, P266, DOI 10.1159/000499659
   Vogler DP, 2011, J NEUROSCI, V31, P6639, DOI 10.1523/JNEUROSCI.6538-10.2011
   Wang H, 2009, NEUROSCIENCE, V164, P747, DOI 10.1016/j.neuroscience.2009.08.026
   Weinberger Norman M, 2015, Handb Clin Neurol, V129, P117, DOI 10.1016/B978-0-444-62630-1.00007-X
   Williamson TT, 2015, CELL TISSUE RES, V361, P359, DOI 10.1007/s00441-014-2003-9
   Wittekindt A, 2014, J NEUROSCI, V34, P9995, DOI 10.1523/JNEUROSCI.4861-13.2014
   Wu PZ, 2019, NEUROSCIENCE, V407, P8, DOI 10.1016/j.neuroscience.2018.07.053
   YATES GK, 1991, HEARING RES, V57, P57, DOI 10.1016/0378-5955(91)90074-J
   Yeend I, 2017, HEARING RES, V353, P224, DOI 10.1016/j.heares.2017.07.006
   Zampini V, 2010, J PHYSIOL-LONDON, V588, P187, DOI 10.1113/jphysiol.2009.181917
NR 95
TC 0
Z9 0
U1 2
U2 2
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3425
J9 BRAIN SCI
JI Brain Sci.
PD OCT
PY 2020
VL 10
IS 10
AR 710
DI 10.3390/brainsci10100710
PG 26
WC Neurosciences
SC Neurosciences & Neurology
GA OJ8ON
UT WOS:000584213400001
PM 33036168
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Priva, UC
   Sanker, C
AF Cohen Priva, Uriel
   Sanker, Chelsea
TI Natural Leaders: Some Interlocutors Elicit Greater Convergence Across
   Conversations and Across Characteristics
SO COGNITIVE SCIENCE
LA English
DT Article
DE Convergence; Consistency; Corpus study; Individual differences;
   Interlocutor effects; Cross-characteristic; Social mediation
ID INDIVIDUAL-DIFFERENCES; PHONETIC CONVERGENCE; SPEECH-PERCEPTION;
   ACCOMMODATION; COARTICULATION; COMMUNICATION; COMPENSATION; PRODUCTIONS;
   GENDER; LINK
AB Are there individual tendencies in convergence, such that some speakers consistently converge more than others? Similarly, are there natural "leaders," speakers with whom others converge more? Are such tendencies consistent across different linguistic characteristics? We use the Switchboard Corpus to perform a large-scale convergence study of speakers in multiple conversations with different interlocutors, across six linguistic characteristics. Because each speaker participated in several conversations, it is possible to look for individual differences in speakers' likelihood of converging and interlocutors' likelihood of eliciting convergence. We only find evidence for individual differences by interlocutor, not by speaker: There are natural leaders of convergence, who elicit more convergence than others across characteristics and across conversations. The lack of similar evidence for speakers who converge more than others suggests that social factors have a stronger effect in mediating convergence than putative individual tendencies in producing convergence, or that such tendencies are characteristic-specific.
C1 [Cohen Priva, Uriel] Brown Univ, Dept Cognit Linguist & Psychol Sci, 190 Thayer St, Providence, RI 02912 USA.
   [Sanker, Chelsea] Yale Univ, Dept Linguist, New Haven, CT 06520 USA.
RP Priva, UC (corresponding author), Brown Univ, Dept Cognit Linguist & Psychol Sci, 190 Thayer St, Providence, RI 02912 USA.
EM urielc@gmail.com
OI Cohen Priva, Uriel/0000-0002-5689-1186
CR Abel J, 2017, LANG SPEECH, V60, P479, DOI 10.1177/0023830916665652
   Acton E. K., 2011, U PENNSYLVANIA WORKI, V17, P2
   Babel M, 2014, LAB PHONOL, V5, P123, DOI 10.1515/lp-2014-0006
   Babel M, 2012, LANG SPEECH, V55, P231, DOI 10.1177/0023830911417695
   Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001
   Babel M, 2010, LANG SOC, V39, P437, DOI 10.1017/S0047404510000400
   Babel Molly, 2009, THESIS
   Baker A, 2011, LANG VAR CHANGE, V23, P347, DOI 10.1017/S0954394511000135
   BANE MAX, 2010, CHICAGO LINGUISTIC S, V46, P43
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D., 2018, ARXIV150604967V2STAT
   Beddor PS, 2018, LANGUAGE, V94, P931, DOI 10.1353/lan.2018.0051
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   BILOUS FR, 1988, LANG COMMUN, V8, P183, DOI 10.1016/0271-5309(88)90016-X
   Bourhis R. Y., 1977, LANGUAGE ETHNICITY I, V13, P119
   Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893
   Cieri C., 2004, L REC, P69
   Cieri C., 2005, FISHER ENGLISH TRA 2
   Clark HH, 2002, COGNITION, V84, P73, DOI 10.1016/S0010-0277(02)00017-3
   Cohen Priva U., 2018, P 40 ANN M COGN SCI, P1515
   Cohen RL, 2018, PAST IMPERFECT, P4
   Delvaux V, 2007, PHONETICA, V64, P145, DOI 10.1159/000107914
   Dingemanse NJ, 2010, TRENDS ECOL EVOL, V25, P81, DOI 10.1016/j.tree.2009.07.013
   Dorgeloh H, 2004, J PRAGMATICS, V36, P1761, DOI 10.1016/j.pragma.2004.04.004
   Drager K, 2012, LANG VAR CHANGE, V24, P59, DOI 10.1017/S0954394512000014
   Fowler CA, 2003, J MEM LANG, V49, P396, DOI 10.1016/S0749-596X(03)00072-X
   Gijssels T, 2016, DISCOURSE PROCESS, V53, P233, DOI 10.1080/0163853X.2015.1023965
   Giles H., 1991, CONTEXTS ACCOMMODATI, P1, DOI [10.1017/CBO9780511663673.001, DOI 10.1017/CBO9780511663673.001]
   Giles H., 1972, LANG SOC, V2, DOI [https://doi.org/10.1017/S0047404500000701, DOI 10.1017/S0047404500000701]
   Godfrey J., 1997, SWITCHBOARD 1 RELEAS
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Gregory SW, 1996, J PERS SOC PSYCHOL, V70, P1231, DOI 10.1037/0022-3514.70.6.1231
   Grosvald M., 2012, INITIATION SOUND CHA, P77, DOI DOI 10.1075/CILT.323.08GRO
   Harkins D., 2003, SWITCHBOARD MS STATE
   Harrington J, 2008, J ACOUST SOC AM, V123, P2825, DOI 10.1121/1.2897042
   Heath J., 2017, P LINGUISTIC SOC AM, V2, DOI 10.3765/plsa.v2i0.4088
   Hornickel J, 2009, P NATL ACAD SCI USA, V106, P13022, DOI 10.1073/pnas.0901123106
   Hwang H, 2018, COGNITIVE SCI, V42, P303, DOI 10.1111/cogs.12604
   Ishida M, 2016, COGNITION, V151, P68, DOI 10.1016/j.cognition.2016.03.008
   Jiang J, 2015, P NATL ACAD SCI USA, V112, P4274, DOI 10.1073/pnas.1422930112
   JOHNSON DM, 1987, J ACOUST SOC AM, V81, P427, DOI 10.1121/1.394907
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Jun SA, 2015, STUD THEOR PSYCHOLIN, V46, P217, DOI 10.1007/978-3-319-12961-7_12
   Kapnoula E. E., 2016, THESIS
   Kaschak MP, 2011, PSYCHON B REV, V18, P1133, DOI 10.3758/s13423-011-0157-y
   Kataoka R., 2011, THESIS
   Kidd GR, 2007, J ACOUST SOC AM, V122, P418, DOI 10.1121/1.2743154
   Kim Midam, 2011, Lab Phonol, V2, P125
   Kong EJ, 2016, J PHONETICS, V59, P40, DOI 10.1016/j.wocn.2016.08.006
   Labov W., 2001, PRINCIPLES LINGUISTI, V2
   Large NR, 1998, RES SPOKEN LANG P, V22, P95
   Lev-Ari S, 2018, Q J EXP PSYCHOL, V71, P2249, DOI 10.1177/1747021817739865
   Lev-Ari S, 2018, COGNITION, V176, P31, DOI 10.1016/j.cognition.2018.03.003
   Levitan R., 2011, P INT, V5, P3081
   Martin JGA, 2011, METHODS ECOL EVOL, V2, P362, DOI 10.1111/j.2041-210X.2010.00084.x
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001
   Mitterer H, 2008, COGNITION, V109, P168, DOI 10.1016/j.cognition.2008.08.002
   Namy LL, 2002, J LANG SOC PSYCHOL, V21, P422, DOI 10.1177/026192702237958
   NATALE M, 1975, J PERS SOC PSYCHOL, V32, P790, DOI 10.1037/0022-3514.32.5.790
   Oben B, 2016, J PRAGMATICS, V104, P32, DOI 10.1016/j.pragma.2016.07.002
   Pardo JS, 2018, J PHONETICS, V69, P1, DOI 10.1016/j.wocn.2018.04.001
   Pardo JS, 2017, ATTEN PERCEPT PSYCHO, V79, P637, DOI 10.3758/s13414-016-1226-0
   Pardo JS, 2012, J PHONETICS, V40, P190, DOI 10.1016/j.wocn.2011.10.001
   Pardo JS, 2010, ATTEN PERCEPT PSYCHO, V72, P2254, DOI 10.3758/APP.72.8.2254
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720
   Perkell JS, 2004, J ACOUST SOC AM, V116, P2338, DOI 10.1121/1.1787524
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Pitt M., 2007, BUCKEYE CORPUS CONVE
   Priva UC, 2019, LAB PHONOL, V10, DOI 10.5334/labphon.200
   Priva UC, 2017, J ACOUST SOC AM, V141, P2989, DOI 10.1121/1.4982199
   Priva UC, 2017, COGNITION, V160, P27, DOI 10.1016/j.cognition.2016.12.002
   Rahimi Z, 2017, INTERSPEECH, P1696, DOI 10.21437/Interspeech.2017-1568
   Reitter D., 2006, P 28 ANN C COGN SCI, P685
   REPP BH, 1981, PERCEPT PSYCHOPHYS, V30, P217, DOI 10.3758/BF03214276
   Sanker C., 2015, CORNELL WORKING PAPE, V2015, P60
   Schertz J, 2020, WIRES COGN SCI, V11, DOI 10.1002/wcs.1521
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   SCHIFFRIN D, 1986, J PRAGMATICS, V10, P41, DOI 10.1016/0378-2166(86)90099-8
   Schweitzer A, 2013, INTERSPEECH, P525
   Shultz AA, 2012, J ACOUST SOC AM, V132, pEL95, DOI 10.1121/1.4736711
   Song JH, 2011, CLIN NEUROPHYSIOL, V122, P346, DOI 10.1016/j.clinph.2010.07.009
   Stevens SS, 1937, J ACOUST SOC AM, V8, P185, DOI 10.1121/1.1915893
   Stewart ME, 2008, COGNITION, V109, P157, DOI 10.1016/j.cognition.2008.07.010
   Street Robert. L., 1982, SOCIAL COGNITION COM, P193
   Surprenant AM, 2001, J ACOUST SOC AM, V110, P2085, DOI 10.1121/1.1404973
   Wade L., LANGUAGE SPEECH
   Weatherholtz K, 2014, LANG VAR CHANGE, V26, P387, DOI 10.1017/S0954394514000155
   Weise A., 2018, P 2018 C N AM CHAPT, P297, DOI DOI 10.18653/V1/N18-2048
   Yu A. C. L., 2013, ORIGINS SOUND CHANGE, P201, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0010
   Yu A. C. L., 2011, U PENNSYLVANIA WORKI, V17, P235
   Yu ACL, 2019, LAB PHONOL, V10, DOI 10.5334/labphon.97
   Yu ACL, 2019, ANNU REV LINGUIST, V5, P131, DOI 10.1146/annurev-linguistics-011516-033815
   Yu ACL, 2014, J ACOUST SOC AM, V136, P382, DOI 10.1121/1.4883380
   Yu ACL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0074746
   Yu ACL, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011950
   Yun K, 2012, SCI REP-UK, V2, DOI 10.1038/srep00959
   Zellou G, 2017, J PHONETICS, V61, P13, DOI 10.1016/j.wocn.2016.12.002
NR 99
TC 0
Z9 0
U1 1
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0364-0213
EI 1551-6709
J9 COGNITIVE SCI
JI Cogn. Sci.
PD OCT
PY 2020
VL 44
IS 10
AR e12897
DI 10.1111/cogs.12897
PG 34
WC Psychology, Experimental
SC Psychology
GA OI2XT
UT WOS:000583148700001
PM 33037640
DA 2021-02-24
ER

PT J
AU Quinto, A
   Abu El Adas, S
   Levi, SV
AF Quinto, Ashley
   Abu El Adas, Sandy
   Levi, Susannah V.
TI Re-Examining the Effect of Top-Down Linguistic Information on
   Speaker-Voice Discrimination
SO COGNITIVE SCIENCE
LA English
DT Article
DE Top-down processing; Voice perception; Lexical processing
ID SPEECH-PERCEPTION; LISTENER SENSITIVITY; TALKER; IDENTIFICATION;
   VARIABILITY; FAMILIARITY
AB The current study replicated and extended the results from a study conducted by Narayan, Mak, and Bialystok (2017) that found effects of top-down linguistic information on a speaker discrimination task by examining four conditions: rhymes (day-bay), compounds (day-dream), reverse compounds (dream-day), and unrelated words (day-bee). The original study found that participants were more likely to judge two words to be spoken by the same speaker if the words cohered lexically (created lexical compounds such as day-dream) or were phonologically related (rhymes, such as day-bay), but their study contained two limitations: (a) Same- and different-speaker trials were analyzed separately, which obscures effects of response bias, and (b) cross-gender pairs were used in the different-speaker trials, potentially inflating performance. The current study addresses these limitations by including only within-gender trials and by examining sensitivity and bias using signal detection theory. Our results not only provide support of the original study but also provide clear evidence that listeners are biased to judge two words as being produced by the same person when they share either phonological information (rhymes) or lexical-semantic coherence (compounds). Thus, the current study provides an important modified replication of previous research.
C1 [Quinto, Ashley; Abu El Adas, Sandy; Levi, Susannah V.] New York Univ, Dept Communicat Sci & Disorders, 665 Broadway,9th Floor, New York, NY 10012 USA.
RP Levi, SV (corresponding author), New York Univ, Dept Communicat Sci & Disorders, 665 Broadway,9th Floor, New York, NY 10012 USA.
EM svlevi@nyu.edu
OI Levi, Susannah/0000-0002-3115-8981
CR Abercrombie David, 1967, ELEMENTS GEN PHONETI
   Allen JS, 2004, J ACOUST SOC AM, V115, P3171, DOI 10.1121/1.1701898
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boersma Paul, 2008, PRAAT DOING PHONETIC
   DONALDSON W, 1992, J EXP PSYCHOL GEN, V121, P275, DOI 10.1037/0096-3445.121.3.275
   Dunn LM, 2007, PPVT 4 PEABODY PICTU
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   GOLDINGER SD, 1991, J EXP PSYCHOL LEARN, V17, P152, DOI 10.1037/0278-7393.17.1.152
   GOLDSTEIN AG, 1981, B PSYCHONOMIC SOC, V17, P217
   GRIER JB, 1971, PSYCHOL BULL, V75, P424, DOI 10.1037/h0031246
   HOLLIEN H, 1982, J PHONETICS, V10, P139, DOI 10.1016/S0095-4470(19)30953-2
   Johnsrude IS, 2013, PSYCHOL SCI, V24, P1995, DOI 10.1177/0956797613482467
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   LADEFOGED P, 1978, LANG SPEECH, V21, P373, DOI 10.1177/002383097802100412
   Lenth R, 2019, ESTIMATED MARGINAL M
   Levi SV, 2019, WIRES COGN SCI, V10, DOI 10.1002/wcs.1483
   Levi SV, 2014, PHONETICA, V71, P201, DOI 10.1159/000370160
   Levi SV, 2011, J ACOUST SOC AM, V130, P4053, DOI 10.1121/1.3651816
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   MULLENNIX JW, 1990, PERCEPT PSYCHOPHYS, V47, P379, DOI 10.3758/BF03210878
   Narayan CR, 2017, COGNITIVE SCI, V41, P1361, DOI 10.1111/cogs.12396
   Newman RS, 2007, J PHONETICS, V35, P85, DOI 10.1016/j.wocn.2005.10.004
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Perrachione T.K., 2019, OXFORD HDB VOICE PER, P515
   Schneider W., 2007, E PRIME 2 0 PROFESSI
   Singmann H., 2019, AFEX ANAL FACTORIAL
   Souza P, 2013, J AM ACAD AUDIOL, V24, P689, DOI 10.3766/jaaa.24.8.6
   Theodore RM, 2010, J ACOUST SOC AM, V128, P2090, DOI 10.1121/1.3467771
   THOMPSON CP, 1987, APPL COGNITIVE PSYCH, V1, P121, DOI 10.1002/acp.2350010205
NR 31
TC 0
Z9 0
U1 1
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0364-0213
EI 1551-6709
J9 COGNITIVE SCI
JI Cogn. Sci.
PD OCT
PY 2020
VL 44
IS 10
AR e12902
DI 10.1111/cogs.12902
PG 16
WC Psychology, Experimental
SC Psychology
GA OI2XT
UT WOS:000583148700008
PM 33025646
DA 2021-02-24
ER

PT J
AU O'Brien, GE
   Gijbels, L
   Yeatman, JD
AF O'Brien, Gabrielle E.
   Gijbels, Liesbeth
   Yeatman, Jason D.
TI Context effects on phoneme categorization in children with dyslexia
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH-PERCEPTION; READING DISABILITIES; HYPERACTIVITY DISORDER;
   DEVELOPMENTAL DYSLEXIA; DEFICIT; HYPOTHESIS; LANGUAGE; IMPAIRMENTS;
   VARIABILITY; COMORBIDITY
AB Research shows that, on average, children with dyslexia behave less categorically in phoneme categorization tasks. This study investigates three subtle ways that struggling readers may perform differently than their typically developing peers in this experimental context: sensitivity to the frequency distribution from which speech tokens are drawn, bias induced by previous stimulus presentations, and fatigue during the course of the task. We replicate findings that reading skill is related to categorical labeling, but we do not find evidence that sensitivity to the stimulus frequency distribution, the influence of previous stimulus presentations, and a measure of task engagement differs in children with dyslexia. It is, therefore, unlikely that the reliable relationship between reading skill and categorical labeling is attributable to artifacts of the task design, abnormal neural encoding, or executive function. Rather, categorical labeling may index a general feature of linguistic development whose causal relationship to literacy remains to be ascertained.
C1 [O'Brien, Gabrielle E.; Gijbels, Liesbeth] Univ Washington, Inst Learning & Brain Sci, Seattle, WA 98105 USA.
   [Yeatman, Jason D.] Stanford Univ, Grad Sch Educ, Stanford, CA 94305 USA.
RP O'Brien, GE (corresponding author), Univ Washington, Inst Learning & Brain Sci, Seattle, WA 98105 USA.
EM andronovhopf@gmail.com
FU Auditory Neuroscience Training Grant [National Institutes of Health
   (NIH)]United States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [T32DC005361-16]; National Science
   Foundation, Division of Behavioral and Cognitive SciencesNational
   Science Foundation (NSF) [1551330]; Eunice Kennedy Shriver National
   Institute of Child Health and Human DevelopmentUnited States Department
   of Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   Eunice Kennedy Shriver National Institute of Child Health & Human
   Development (NICHD) [P50 HD052120, R21 HD092771]; Microsoft (Redmond,
   Washington)
FX We would like to thank Daniel McCloy for helpful discussion in planning
   the experiment and analyses. G.E.O. was supported by the Auditory
   Neuroscience Training Grant [National Institutes of Health (NIH) Grant
   No. T32DC005361-16]. This work was also supported by the National
   Science Foundation, Division of Behavioral and Cognitive Sciences Grant
   No. 1551330, Eunice Kennedy Shriver National Institute of Child Health
   and Human Development Grant Nos. P50 HD052120 and R21 HD092771, and
   research grants from Microsoft (Redmond, Washington) to J.D.Y.
CR Ahissar M, 2007, TRENDS COGN SCI, V11, P458, DOI 10.1016/j.tics.2007.08.015
   Ahissar M, 2006, NAT NEUROSCI, V9, P1558, DOI 10.1038/nn1800
   Amitay S, 2002, BRAIN, V125, P2272, DOI 10.1093/brain/awf231
   [Anonymous], 2018, DEV COGN NEUROSCI, V21, DOI [10.1016/S1878-9293(18)30129-4, DOI 10.1111/DESC.12530]
   [Anonymous], 2018, U TORONTO LAW J S1, V68, P1, DOI DOI 10.1007/S11881-018-0158-X
   [Anonymous], 2017, ONCOGENESIS, V6, pe345, DOI DOI 10.7554/ELIFE.20557
   [Anonymous], 2011, TEACHING PROFESSOR, V15, P3, DOI DOI 10.1016/J.TICS.2010.10.001
   [Anonymous], 2018, OBSTET GYNECOL, V13, pe49, DOI DOI 10.1371/JOURNAL.PONE.0198146
   [Anonymous], 2018, DEV COGN NEUROSCI, V21, DOI [10.1016/S1878-9293(18)30129-4, DOI 10.1111/DESC.12558]
   Apfelbaum KS, 2013, DEV PSYCHOL, V49, P1348, DOI 10.1037/a0029839
   Banai K, 2004, AUDIOL NEURO-OTOL, V9, P328, DOI 10.1159/000081282
   Banai K, 2006, CEREB CORTEX, V16, P1718, DOI 10.1093/cercor/bhj107
   Blomert L, 2004, BRAIN LANG, V89, P21, DOI 10.1016/S0093-934X(03)00305-5
   Boada R, 2012, TOP LANG DISORD, V32, P264, DOI 10.1097/TLD.0b013e31826203ac
   Boersma P., 2020, PRAAT DOING PHONETIC
   Booth JR, 2000, SCI STUD READ, V4, P101, DOI DOI 10.1207/S1532799XSSR0402_02
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Dich N, 2013, LINGUA, V133, P213, DOI 10.1016/j.lingua.2013.04.010
   Du WC, 2013, ANN DYSLEXIA, V63, P154, DOI 10.1007/s11881-012-0077-1
   Gabay Y, 2015, J SPEECH LANG HEAR R, V58, P934, DOI 10.1044/2015_JSLHR-L-14-0324
   Germano E, 2010, DEV NEUROPSYCHOL, V35, P475, DOI 10.1080/87565641.2010.494748
   Goswami U, 2002, P NATL ACAD SCI USA, V99, P10911, DOI 10.1073/pnas.122368599
   GOULD JH, 1990, NEUROPSYCHOLOGIA, V28, P271, DOI 10.1016/0028-3932(90)90020-O
   Hamalainen JA, 2013, J LEARN DISABIL-US, V46, P413, DOI 10.1177/0022219411436213
   Hancock R, 2017, TRENDS COGN SCI, V21, P434, DOI 10.1016/j.tics.2017.03.008
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   Hillman EMC, 2014, ANNU REV NEUROSCI, V37, P161, DOI 10.1146/annurev-neuro-071013-014111
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   Jimenez-Fernandez G, 2011, ANN DYSLEXIA, V61, P85, DOI 10.1007/s11881-010-0048-3
   KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572
   Krause MB, 2015, DYSLEXIA, V21, P285, DOI 10.1002/dys.1505
   Lachmann T., 2018, READING DYSLEXIA BAS, P235, DOI DOI 10.1007/978-3-319-90805-2_12
   Lieder I, 2019, NAT NEUROSCI, V22, P256, DOI 10.1038/s41593-018-0308-9
   LIGHT JG, 1995, DEV NEUROPSYCHOL, V11, P323, DOI 10.1080/87565649509540623
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   McMurray B, 2018, DEV PSYCHOL, V54, P1472, DOI 10.1037/dev0000542
   McMurray B, 2009, DEVELOPMENTAL SCI, V12, P369, DOI 10.1111/j.1467-7687.2009.00822.x
   Messaoud-Galusi S, 2011, J SPEECH LANG HEAR R, V54, P1682, DOI 10.1044/1092-4388(2011/09-0261)
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   O'Brien GE, 2019, J ACOUST SOC AM, V146, P245, DOI 10.1121/1.5116568
   O'Brien GE, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34823-8
   Pennington BF, 2012, J ABNORM PSYCHOL, V121, P212, DOI 10.1037/a0025823
   Perrachione TK, 2016, NEURON, V92, P1383, DOI 10.1016/j.neuron.2016.11.020
   Peters L, 2019, TRENDS NEUROSCI EDUC, V17, DOI 10.1016/j.tine.2019.100115
   Ramus F, 2012, COGN NEUROPSYCHOL, V29, P104, DOI 10.1080/02643294.2012.677420
   Roach NW, 2004, PERCEPTION, V33, P817, DOI 10.1068/p5207
   Robertson EK, 2009, DEVELOPMENTAL SCI, V12, P753, DOI 10.1111/j.1467-7687.2009.00806.x
   Rosen S, 2003, J PHONETICS, V31, P509, DOI 10.1016/S0095-4470(03)00046-9
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Samara A, 2017, SCI STUD READ, V21, P76, DOI 10.1080/10888438.2016.1262865
   Schatschneider C, 2016, SCI STUD READ, V20, P34, DOI 10.1080/10888438.2015.1107072
   SHAYWITZ SE, 1992, NEW ENGL J MED, V326, P145, DOI 10.1056/NEJM199201163260301
   Snowling MJ, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12723
   Staels E, 2015, J EXP PSYCHOL LEARN, V41, P650, DOI 10.1037/xlm0000054
   Stein J, 2019, NEUROPSYCHOLOGIA, V130, P66, DOI 10.1016/j.neuropsychologia.2018.03.022
   Stevenson J, 2005, J CHILD PSYCHOL PSYC, V46, P1081, DOI 10.1111/j.1469-7610.2005.01533.x
   Stuart GW, 2006, COGN NEUROPSYCHOL, V23, P1215, DOI 10.1080/02643290600814624
   Talcott JB, 2000, P NATL ACAD SCI USA, V97, P2952, DOI 10.1073/pnas.040546597
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Tallal P, 1996, SCIENCE, V271, P81, DOI 10.1126/science.271.5245.81
   Vandermosten M, 2019, SCI STUD READ, V23, P116, DOI 10.1080/10888438.2018.1473404
   Vandermosten M, 2011, RES DEV DISABIL, V32, P593, DOI 10.1016/j.ridd.2010.12.015
   Vandermosten M, 2010, P NATL ACAD SCI USA, V107, P10389, DOI 10.1073/pnas.0912858107
   Wagenmakers EJ, 2007, PSYCHON B REV, V14, P779, DOI 10.3758/BF03194105
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1293, DOI 10.3758/BF03194544
   Wolf M, 2000, J LEARN DISABIL-US, V33, P322, DOI 10.1177/002221940003300404
   Ziegler J. C., 2019, DEV DYSLEXIA LANGUAG, P350, DOI 10.1017/9781108553377.016
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
   Ziegler JC, 2008, TRENDS COGN SCI, V12, P244, DOI 10.1016/j.tics.2008.04.001
NR 70
TC 0
Z9 0
U1 3
U2 3
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD OCT
PY 2020
VL 148
IS 4
BP 2209
EP 2222
DI 10.1121/10.0002181
PG 14
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA OK4YN
UT WOS:000584658000005
PM 33138541
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Thoidis, I
   Vrysis, L
   Markou, D
   Papanikolaou, G
AF Thoidis, Iordanis
   Vrysis, Lazaros
   Markou, Dimitrios
   Papanikolaou, George
TI Temporal Auditory Coding Features for Causal Speech Enhancement
SO ELECTRONICS
LA English
DT Article
DE speech enhancement; speech intelligibility; temporal envelope; temporal
   fine structure; neural networks
ID PERCEPTUAL EVALUATION; QUALITY ASSESSMENT; ITU STANDARD; NOISE; HEARING;
   MODULATION; INTELLIGIBILITY; INFORMATION; LISTENERS; STEADY
AB Perceptually motivated audio signal processing and feature extraction have played a key role in the determination of high-level semantic processes and the development of emerging systems and applications, such as mobile phone telecommunication and hearing aids. In the era of deep learning, speech enhancement methods based on neural networks have seen great success, mainly operating on the log-power spectra. Although these approaches surpass the need for exhaustive feature extraction and selection, it is still unclear whether they target the important sound characteristics related to speech perception. In this study, we propose a novel set of auditory-motivated features for single-channel speech enhancement by fusing temporal envelope and temporal fine structure information in the context of vocoder-like processing. A causal gated recurrent unit (GRU) neural network is employed to recover the low-frequency amplitude modulations of speech. Experimental results indicate that the exploited system achieves considerable gains for normal-hearing and hearing-impaired listeners, in terms of objective intelligibility and quality metrics. The proposed auditory-motivated feature set achieved better objective intelligibility results compared to the conventional log-magnitude spectrogram features, while mixed results were observed for simulated listeners with hearing loss. Finally, we demonstrate that the proposed analysis/synthesis framework provides satisfactory reconstruction accuracy of speech signals.
C1 [Thoidis, Iordanis; Vrysis, Lazaros; Markou, Dimitrios; Papanikolaou, George] Aristotle Univ Thessaloniki, Sch Elect & Comp Engn, Fac Engn, Thessaloniki 54124, Greece.
RP Thoidis, I (corresponding author), Aristotle Univ Thessaloniki, Sch Elect & Comp Engn, Fac Engn, Thessaloniki 54124, Greece.
EM ithoidis@auth.gr; lvrysis@auth.gr; dkmarkou@ece.auth.gr; pap@eng.auth.gr
RI Vrysis, Lazaros/V-2260-2019
OI Vrysis, Lazaros/0000-0003-2900-4657; Thoidis,
   Iordanis/0000-0001-6636-4745
CR Abolhassani MD, 2008, IEEE ENG MED BIO, P2956, DOI 10.1109/IEMBS.2008.4649823
   Anderson MC, 2014, HEARING RES, V309, P75, DOI 10.1016/j.heares.2013.11.011
   [Anonymous], 2007, TELECOMMUN STAND SEC, P12, DOI [10.1016/S1389-1286(03)00243-3, DOI 10.1016/S1389-1286(03)00243-3]
   Apoux F, 2004, HEARING RES, V189, P13, DOI 10.1016/S0378-5955(03)00397-6
   Apoux F, 2011, J ACOUST SOC AM, V130, P273, DOI 10.1121/1.3596463
   Bae SH, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112289
   Beerends JG, 2002, J AUDIO ENG SOC, V50, P765
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
   Cariani P, 1999, NEURAL PLAST, V6, P147, DOI 10.1155/NP.1999.147
   Chen JT, 2016, J ACOUST SOC AM, V139, P2604, DOI 10.1121/1.4948445
   Chi T, 2005, J ACOUST SOC AM, V118, P887, DOI 10.1121/1.1945807
   Chou KF, 2019, JARO-J ASSOC RES OTO, V20, P579, DOI 10.1007/s10162-019-00732-4
   Cui XY, 2020, APPL ACOUST, V157, DOI 10.1016/j.apacoust.2019.107019
   Czyzewski A., 2007, AUDIO ENG SOC CONVEN, V122
   Czyzewski A, 2017, J INTELL INF SYST, V49, P167, DOI 10.1007/s10844-016-0438-z
   Elhilali M, 2008, J ACOUST SOC AM, V124, P3751, DOI 10.1121/1.3001672
   EPHRAIM Y, 1984, IEEE T ACOUST SPEECH, V32, P1109, DOI 10.1109/TASSP.1984.1164453
   Ewert SD, 2020, EUR J NEUROSCI, V51, P1265, DOI 10.1111/ejn.13846
   Gabor D., 1946, Journal of the Institution of Electrical Engineers. III. Radio and Communication Engineering, V93, P429
   GLASBERG BR, 1990, HEARING RES, V47, P103, DOI 10.1016/0378-5955(90)90170-T
   Goehring T, 2019, J ACOUST SOC AM, V146, P705, DOI 10.1121/1.5119226
   Grose JH, 2009, EAR HEARING, V30, P568, DOI 10.1097/AUD.0b013e3181ac128f
   Hopkins K, 2009, J ACOUST SOC AM, V125, P442, DOI 10.1121/1.3037233
   Jensen J, 2016, IEEE-ACM T AUDIO SPE, V24, P2009, DOI 10.1109/TASLP.2016.2585878
   Kates JM, 2014, SPEECH COMMUN, V65, P75, DOI 10.1016/j.specom.2014.06.002
   Kates JM, 2014, J AUDIO ENG SOC, V62, P99, DOI 10.17743/jaes.2014.0006
   Kingma D. P., 2014, ARXIV14126980, P1
   Korvel G, 2019, INTEL SYST REF LIBR, V149, P129, DOI 10.1007/978-3-319-94030-4_6
   Koutsogiannaki M, 2017, INTERSPEECH, P1973, DOI 10.21437/Interspeech.2017-1157
   LANG HT, 2020, ELECTRONICS-SWITZ, V9, DOI DOI 10.3390/ELECTRONICS9071125
   Langhans T., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P156
   Lee GW, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093230
   Loizou P. C., 2013, SPEECH ENHANCEMENT T
   Maganti HK, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2014-21
   Moore BCJ, 1996, ACUSTICA, V82, P335
   Necciari T, 2013, INT CONF ACOUST SPEE, P498, DOI 10.1109/ICASSP.2013.6637697
   Necciari T, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010096
   Oord A.v.d., 2016, ARXIV160903499
   PALMER AR, 1986, HEARING RES, V24, P1, DOI 10.1016/0378-5955(86)90002-X
   Pardede H, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8080897
   Park G, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10176077
   Purwins H, 2019, IEEE J-STSP, V13, P206, DOI 10.1109/JSTSP.2019.2908700
   Rao A, 2014, IEEE T BIO-MED ENG, V61, P2081, DOI 10.1109/TBME.2014.2313618
   Rix AW, 2002, J AUDIO ENG SOC, V50, P755
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Salamon J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1041, DOI 10.1145/2647868.2655045
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   SHEFT S, 1990, J ACOUST SOC AM, V88, P796, DOI 10.1121/1.399729
   Shetty Hemanth Narayan, 2016, J Otol, V11, P95, DOI 10.1016/j.joto.2016.08.001
   Shetty HN, 2015, HEARING BALANC COMMU, V13, P111, DOI 10.3109/21695717.2015.1058609
   Souza PE, 2015, J SPEECH LANG HEAR R, V58, P520, DOI 10.1044/2015_JSLHR-H-14-0138
   Srinivasan S, 2006, SPEECH COMMUN, V48, P1486, DOI 10.1016/j.specom.2006.09.003
   Thiemann J., 2013, J ACOUST SOC AM, P3591, DOI DOI 10.1121/1.4806631
   Thoidis I, 2020, AUDIO ENG SOC CONVEN, V148
   Thoidis I., 2019, AUDIO ENG SOC CONVEN, V146
   Thoidis I, 2019, INT J AUDIOL, V58, P476, DOI 10.1080/14992027.2019.1600204
   Tsoukalas DE, 1997, J AUDIO ENG SOC, V45, P22
   VANTASELL DJ, 1987, J ACOUST SOC AM, V82, P1152, DOI 10.1121/1.395251
   Velasco G.A., 2011, P 14 INT C DIG AUD E, P93
   Vrysis L., 2020, AUDIO ENG SOC CONVEN, V148
   Vrysis L, 2020, J AUDIO ENG SOC, V68, P66, DOI 10.17743/jaes.2019.0058
   Vryzas N, 2020, J AUDIO ENG SOC, V68, P14, DOI 10.17743/jaes.2019.0043
   Wang DL, 2018, IEEE-ACM T AUDIO SPE, V26, P1702, DOI 10.1109/TASLP.2018.2842159
   Wang KS, 1994, IEEE T SPEECH AUDI P, V2, P421, DOI 10.1109/89.294356
   YANG XW, 1992, IEEE T INFORM THEORY, V38, P824, DOI 10.1109/18.119739
   ZUE V, 1990, SPEECH COMMUN, V9, P351, DOI 10.1016/0167-6393(90)90010-7
NR 66
TC 0
Z9 0
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2079-9292
J9 ELECTRONICS-SWITZ
JI Electronics
PD OCT
PY 2020
VL 9
IS 10
AR 1698
DI 10.3390/electronics9101698
PG 17
WC Engineering, Electrical & Electronic
SC Engineering
GA OH8PW
UT WOS:000582854700001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Simon, J
   Balla, VR
AF Simon, Julia
   Balla, Viktoria Roxana
TI Electrophysiological correlates of the spatial temporal order judgment
   task
SO BIOLOGICAL PSYCHOLOGY
LA English
DT Article
DE Temporal order judgment; Auditory perception; EEG; ERP; Temporal
   discrimination
ID PRIMARY AUDITORY-CORTEX; DEVELOPMENTAL DYSLEXIA; SPEECH-PERCEPTION;
   DEFICITS; LANGUAGE; SUFFICIENT; RESPONSES; CHILDREN
AB The study investigated auditory temporal processing on a tens of milliseconds scale that is the interval when two consecutive stimuli are processed either together or as distinct events. Distinctiveness is defined by one's ability to make correct order judgments of the presented sounds and is measured via the spatial temporal order judgement task (TOJ).
   The study aimed to identify electrophysiological indices of the TOJ performance. Tone pairs were presented with inter-stimulus intervals (ISI) varying between 25 and 75 ms while EEG was recorded. A pronounced amplitude change in the P2 interval was found between the event-related potential (ERP) of tone pairs having ISI = 55 and 65 ms, but it was a characteristic only of the group having poor behavioral thresholds. With the two groups combined, the amplitude change between these ERPs in the P2 interval showed a medium-size correlation with the behavioral threshold.
C1 [Simon, Julia] Hungarian Acad Sci, Res Ctr Nat Sci, Inst Cognit Neurosci & Psychol, Magyar Tudosok Korutja 2, H-1117 Budapest, Hungary.
   [Simon, Julia] Budapest Univ Technol & Econ, Fac Nat Sci, Dept Cognit Sci, Budapest, Hungary.
   [Balla, Viktoria Roxana] Univ Helsinki, Fac Med, Dept Psychol & Logoped, Cognit Brain Res Unit, Helsinki, Finland.
RP Simon, J (corresponding author), Hungarian Acad Sci, Res Ctr Nat Sci, Inst Cognit Neurosci & Psychol, Magyar Tudosok Korutja 2, H-1117 Budapest, Hungary.
EM simon.julia@ttk.mta.hu
OI Balla, Viktoria Roxana/0000-0002-3952-7999
CR Banai K, 2004, AUDIOL NEURO-OTOL, V9, P328, DOI 10.1159/000081282
   Ben-Artzi E, 2005, NEUROPSYCHOLOGIA, V43, P714, DOI 10.1016/j.neuropsychologia.2004.08.004
   Bernasconi F, 2011, INT J PSYCHOPHYSIOL, V79, P244, DOI 10.1016/j.ijpsycho.2010.10.017
   Bernasconi F, 2010, NEUROPSYCHOLOGIA, V48, P2579, DOI 10.1016/j.neuropsychologia.2010.05.004
   Bernasconi F, 2010, NEUROIMAGE, V50, P1271, DOI 10.1016/j.neuroimage.2010.01.016
   Billings CJ, 2013, JARO-J ASSOC RES OTO, V14, P891, DOI 10.1007/s10162-013-0415-y
   Bishop DVM, 1999, J SPEECH LANG HEAR R, V42, P1295, DOI 10.1044/jslhr.4206.1295
   CUTTING JE, 1976, PSYCHOL REV, V83, P114, DOI 10.1037/0033-295X.83.2.114
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Farmer ME, 1995, PSYCHON B REV, V2, P460, DOI 10.3758/BF03210983
   Fink M, 2005, RESTOR NEUROL NEUROS, V23, P281
   Fostick L., 2013, EXPT PSYCHOL
   Fostick L, 2014, J EXP PSYCHOL HUMAN, V40, P1799, DOI 10.1037/a0037527
   Fostick Leah, 2014, Journal of Basic and Clinical Physiology and Pharmacology, V25, P307, DOI 10.1515/jbcpp-2014-0036
   Gaab N, 2007, RESTOR NEUROL NEUROS, V25, P295
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Halliday LF, 2017, COGNITION, V166, P139, DOI 10.1016/j.cognition.2017.04.014
   Javitt DC, 2000, CLIN NEUROPHYSIOL, V111, P833, DOI 10.1016/S1388-2457(99)00313-2
   Kanabus M, 2002, ACTA NEUROBIOL EXP, V62, P263
   Lewandowska M, 2008, NEUROSCI LETT, V437, P139, DOI 10.1016/j.neulet.2008.03.085
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   May P. J. C., 2007, INT C SER, V1300, P53, DOI DOI 10.1016/J.ICS.2007.01.051
   Mognon A, 2011, PSYCHOPHYSIOLOGY, V48, P229, DOI 10.1111/j.1469-8986.2010.01061.x
   Papesh MA, 2015, CLIN NEUROPHYSIOL, V126, P1319, DOI 10.1016/j.clinph.2014.10.017
   Poppel E, 1997, TRENDS COGN SCI, V1, P56, DOI 10.1016/S1364-6613(97)01008-5
   Protopapas A, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0090
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   Saija JD, 2019, PSYCHOL RES-PSYCH FO, V83, P951, DOI 10.1007/s00426-017-0912-4
   Simon J., 2020, EXPT BRAIN RES, P1
   Simon J, 2019, INT J PSYCHOPHYSIOL, V140, P53, DOI 10.1016/j.ijpsycho.2019.04.006
   Steinschneider M, 2005, CEREB CORTEX, V15, P170, DOI 10.1093/cercor/bhh120
   Steinschneider M, 2003, J ACOUST SOC AM, V114, P307, DOI 10.1121/1.1582449
   Stevenson RA, 2017, SCHIZOPHR RES, V179, P97, DOI 10.1016/j.schres.2016.09.035
   Szelag E, 2014, J NEUROL SCI, V338, P77, DOI 10.1016/j.jns.2013.12.020
   Szymaszek A, 2009, COGN NEUROPSYCHOL, V26, P135, DOI 10.1080/02643290802504742
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Tallal P, 2004, NAT REV NEUROSCI, V5, P721, DOI 10.1038/nrn1499
   Zaehle T, 2004, EUR J NEUROSCI, V20, P2447, DOI 10.1111/j.1460-9568.2004.03687.x
   Zaehle T, 2007, BEHAV BRAIN FUNCT, V3, DOI 10.1186/1744-9081-3-63
   Ziegler JC, 2009, DEVELOPMENTAL SCI, V12, P732, DOI 10.1111/j.1467-7687.2009.00817.x
NR 40
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0301-0511
EI 1873-6246
J9 BIOL PSYCHOL
JI Biol. Psychol.
PD OCT
PY 2020
VL 156
AR 107947
DI 10.1016/j.biopsycho.2020.107947
PG 8
WC Psychology, Biological; Behavioral Sciences; Psychology; Psychology,
   Experimental
SC Psychology; Behavioral Sciences
GA OH6CQ
UT WOS:000582675900002
PM 32828914
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Nenadic, F
   Coulter, P
   Nearey, TM
   Kiefte, M
AF Nenadic, Filip
   Coulter, Pamela
   Nearey, Terrance M.
   Kiefte, Michael
TI Perception of vowels with missing formant peaks
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH-PERCEPTION; SPECTRAL-SHAPE; VERTICAL-BAR; IDENTIFICATION;
   INTEGRATION; AMPLITUDE; MODELS
AB Although the first two or three formant frequencies are considered essential cues for vowel identification, certain limitations of this approach have been noted. Alternative explanations have suggested listeners rely on other aspects of the gross spectral shape. A study conducted by Ito, Tsuchida, and Yano [(2001). J. Acoust. Soc. Am.110, 1141-1149] offered strong support for the latter, as attenuation of individual formant peaks left vowel identification largely unaffected. In the present study, these experiments are replicated in two dialects of English. Although the results were similar to those of Ito, Tsuchida, and Yano [(2001). J. Acoust. Soc. Am.110, 1141-1149], quantitative analyses showed that when a formant is suppressed, participant response entropy increases due to increased listener uncertainty. In a subsequent experiment, using synthesized vowels with changing formant frequencies, suppressing individual formant peaks led to reliable changes in identification of certain vowels but not in others. These findings indicate that listeners can identify vowels with missing formant peaks. However, such formant-peak suppression may lead to decreased certainty in identification of steady-state vowels or even changes in vowel identification in certain dynamically specified vowels.
C1 [Nenadic, Filip; Nearey, Terrance M.] Univ Alberta, Dept Linguist, Edmonton, AB, Canada.
   [Coulter, Pamela; Kiefte, Michael] Dalhousie Univ, Sch Commun Sci & Disorders, Halifax, NS, Canada.
RP Nenadic, F (corresponding author), Univ Alberta, Dept Linguist, Edmonton, AB, Canada.
EM nenadic@ualberta.ca
CR AINSWORTH WA, 1972, LANG SPEECH, V15, P328, DOI 10.1177/002383097201500403
   [Anonymous], 1990, PUBLICATION I MATH, V47, P103, DOI DOI 10.1016/0378-5955(90)90170-T
   ASSMANN PF, 1982, J ACOUST SOC AM, V71, P975, DOI 10.1121/1.387579
   BLADON A, 1983, SPEECH COMMUN, V2, P305, DOI 10.1016/0167-6393(83)90047-X
   BLADON RAW, 1981, J ACOUST SOC AM, V69, P1414, DOI 10.1121/1.385824
   Calson R., 1982, REPRESENTATION SPEEC, P95
   CHISTOVICH LA, 1979, HEARING RES, V1, P185, DOI 10.1016/0378-5955(79)90012-1
   Delattre P, 1952, WORD, V8, P195, DOI 10.1080/00437956.1952.11659431
   Fox RA, 2010, J ACOUST SOC AM, V128, P2070, DOI 10.1121/1.3483718
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hillenbrand JM, 2006, J ACOUST SOC AM, V119, P4041, DOI 10.1121/1.2188369
   Hillenbrand JM, 2003, J ACOUST SOC AM, V113, P1044, DOI 10.1121/1.1513647
   Hillenbrand JM, 1999, J ACOUST SOC AM, V105, P3509, DOI 10.1121/1.424676
   Ito M, 2001, J ACOUST SOC AM, V110, P1141, DOI 10.1121/1.1384908
   KAKUSHO O, 1971, ACUSTICA, V24, P179
   Kiefte M, 2005, J ACOUST SOC AM, V117, P1395, DOI 10.1121/1.1861158
   Kiefte M, 2008, J ACOUST SOC AM, V123, P366, DOI 10.1121/1.2804951
   Kiefte M, 2017, J ACOUST SOC AM, V142, P434, DOI 10.1121/1.4991022
   Kiefte M, 2013, LANG SPEECH DISORD, P160
   Kiefte M, 2010, J ACOUST SOC AM, V127, P2611, DOI 10.1121/1.3353124
   Klatt D. H., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P1278
   KLATT DH, 1980, J ACOUST SOC AM, V67, P971, DOI 10.1121/1.383940
   Lindqvist-Gauffin J., 1968, STL QPSR, V9, P12
   Maddox WT, 2002, PERCEPT PSYCHOPHYS, V64, P584, DOI 10.3758/BF03194728
   Molis MR, 2005, J ACOUST SOC AM, V118, P1062, DOI 10.1121/1.1943907
   NEAREY TM, 1990, J PHONETICS, V18, P347, DOI 10.1016/S0095-4470(19)30379-1
   Nearey TM, 1997, J ACOUST SOC AM, V101, P3241, DOI 10.1121/1.418290
   NEAREY TM, 1986, J ACOUST SOC AM, V80, P1297, DOI 10.1121/1.394433
   NEAREY TM, 1989, J ACOUST SOC AM, V85, P2088, DOI 10.1121/1.397861
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   R Core Team, 2017, R LANG ENV STAT COMP
   RAND TC, 1974, J ACOUST SOC AM, V55, P678, DOI 10.1121/1.1914584
   Roberts B, 2019, J ACOUST SOC AM, V145, P1230, DOI 10.1121/1.5091443
   Rosner B. S., 1994, VOWEL PERCEPTION PRO
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Yu D, 2015, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-4471-5779-3
   ZAHORIAN SA, 1993, J ACOUST SOC AM, V94, P1966, DOI 10.1121/1.407520
NR 37
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD OCT
PY 2020
VL 148
IS 4
BP 1911
EP 1921
DI 10.1121/10.0002110
PG 11
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA OG3BQ
UT WOS:000581764300002
PM 33138491
DA 2021-02-24
ER

PT J
AU Kim, DO
   Carney, L
   Kuwada, S
AF Kim, Duck O.
   Carney, Laurel
   Kuwada, Shigeyuki
TI Amplitude modulation transfer functions reveal opposing populations
   within both the inferior colliculus and medial geniculate body
SO JOURNAL OF NEUROPHYSIOLOGY
LA English
DT Article
DE auditory information processing; sensory coding; speech recognition;
   temporal envelopes; visual ON- and OFF-channels
ID INTERAURAL TEMPORAL DISPARITIES; LOW-FREQUENCY SOUNDS; AUDITORY
   MIDBRAIN; SPEECH RECOGNITION; DECEREBRATE CATS; TIME DIFFERENCES;
   RESPONSES; NEURONS; TONES; SENSITIVITY
AB Based on single-unit recordings of modulation transfer functions (MTFs) in the inferior colliculus (IC) and the medial geniculate body (MGB) of the unanesthetized rabbit, we identified two opposing populations: band-enhanced (BE) and band-suppressed (BS) neurons. In response to amplitude-modulated (AM) sounds, firing rates of BE and BS neurons were enhanced and suppressed, respectively, relative to their responses to an unmodulated noise with a one-octave bandwidth. We also identified a third population, designated hybrid neurons, whose firing rates were enhanced by some modulation frequencies and sup- pressed by others. Our finding suggests that perception of AM may be based on the co-occurrence of enhancement and suppression of responses of the opposing populations of neurons. Because AM carries an important part of the content of speech, progress in understanding auditory processing of AM sounds should lead to progress in under- standing speech perception. Each of the BE, BS, and hybrid types of MTFs comprised approximately one-third of the total sample. Modulation envelopes having short duty cycles of 20-50% and raised- sine envelopes accentuated the degree of enhancement and suppression and sharpened tuning of the MTFs. With sinusoidal envelopes, peak modulation frequencies were centered around 32-64 Hz among IC BE neurons, whereas the MOB peak frequencies skewed toward lower frequencies, with a median of 16 Hz. We also tested an auditory-brain- stem model and found that a simple circuit containing fast excitatory synapses and slow inhibitory synapses was able to reproduce salient features of the BE- and BS-type MTFs of IC neurons.
   NEW & NOTEWORTHY Opposing populations of neurons have been identified in the mammalian auditory midbrain and thalamus. In response to amplitude-modulated sounds, responses of one population (band-enhanced) increased whereas responses of another (band-sup- pressed) decreased relative to their responses to an unmodulated sound. These opposing auditory populations are analogous to the ON and OFF populations of the visual system and may improve transfer of information carried by the temporal envelopes of complex sounds such as speech.
C1 [Kim, Duck O.; Kuwada, Shigeyuki] Univ Connecticut, Ctr Hlth, Dept Neurosci, Farmington, CT 06030 USA.
   [Carney, Laurel] Univ Rochester, Dept Biomed Engn Neurobiol & Anat, Rochester, NY USA.
RP Kim, DO (corresponding author), Univ Connecticut, Ctr Hlth, Dept Neurosci, Farmington, CT 06030 USA.
EM kim@uchc.edu
OI Carney, Laurel/0000-0002-4729-5702; Kim, Duck O./0000-0002-1778-3887
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01 DC002178, R01
   DC010813]
FX This study was supported by National Institutes of Health Grant Nos. R01
   DC002178 and R01 DC010813.
CR Alder TB, 2000, J COMP PHYSIOL A, V186, P923, DOI 10.1007/s003590000144
   Batra R, 2006, J NEUROPHYSIOL, V96, P2388, DOI 10.1152/jn.00442.2006
   Bernstein LR, 2010, J ACOUST SOC AM, V128, P1224, DOI 10.1121/1.3466877
   Bernstein LR, 2009, J ACOUST SOC AM, V125, P3234, DOI 10.1121/1.3101454
   Carney LH, 2018, JARO-J ASSOC RES OTO, V19, P331, DOI 10.1007/s10162-018-0669-5
   Carney LH, 2015, ENEURO, V2, DOI 10.1523/ENEURO.0004-15.2015
   Carney LH, 2016, ADV EXP MED BIOL, V894, P427, DOI 10.1007/978-3-319-25474-6_45
   Carney LH, 2014, J NEUROSCI, V34, P1306, DOI 10.1523/JNEUROSCI.3031-13.2014
   D'Angelo WR, 2003, J NEUROPHYSIOL, V90, P2827, DOI 10.1152/jn.00269.2003
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   Delattre P, 1952, WORD, V8, P195, DOI 10.1080/00437956.1952.11659431
   DELGUTTE B, 1984, J ACOUST SOC AM, V75, P866, DOI 10.1121/1.390596
   Dent ML, 2002, J COMP PHYSIOL A, V187, P937, DOI 10.1007/s00359-001-0259-5
   Ding N, 2017, NEUROSCI BIOBEHAV R, V81, P181, DOI 10.1016/j.neubiorev.2017.02.011
   Dorman MF, 1997, J ACOUST SOC AM, V102, P2403, DOI 10.1121/1.419603
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P2670, DOI 10.1121/1.409836
   Dudley H, 1939, J ACOUST SOC AM, V11, P169, DOI 10.1121/1.1916020
   Dudley H, 1940, BELL SYST TECH J, V19, P495, DOI 10.1002/j.1538-7305.1940.tb00843.x
   EPPING WJM, 1986, HEARING RES, V24, P55, DOI 10.1016/0378-5955(86)90005-5
   Fan LC, 2018, ACTA ACUST UNITED AC, V104, P895, DOI [10.3813/AAA.919249, 10.3813/aaa.919249]
   Fitzgerald MB, 2005, J ACOUST SOC AM, V118, P3794, DOI 10.1121/1.2074687
   Geis HR, 2009, J NEUROPHYSIOL, V101, P2002, DOI 10.1152/jn.90966.2008
   GOOLER DM, 1992, J NEUROPHYSIOL, V67, P1, DOI 10.1152/jn.1992.67.1.1
   Grimault N, 2002, PERCEPT PSYCHOPHYS, V64, P189, DOI 10.3758/BF03195785
   HILL FJ, 1968, J ACOUST SOC AM, V44, P13, DOI 10.1121/1.1911047
   Jack J.J.B., 1975, ELECT CURRENT FLOW E
   JORIS PX, 1992, J ACOUST SOC AM, V91, P215, DOI 10.1121/1.402757
   Joris PX, 2004, PHYSIOL REV, V84, P541, DOI 10.1152/physrev.00029.2003
   Kelly JB, 2006, J COMP PSYCHOL, V120, P98, DOI 10.1037/0735-7036.120.2.98
   KIM DO, 1990, HEARING RES, V45, P95, DOI 10.1016/0378-5955(90)90186-S
   Kim DO, 2015, J NEUROSCI, V35, P5360, DOI 10.1523/JNEUROSCI.3798-14.2015
   Krause JC, 2009, J ACOUST SOC AM, V125, P3346, DOI 10.1121/1.3097491
   Krebs B, 2008, J NEUROPHYSIOL, V100, P1602, DOI 10.1152/jn.90374.2008
   Krishna BS, 2000, J NEUROPHYSIOL, V84, P255
   Kuwada S, 1999, J NEUROSCI, V19, P2273
   Kuwada S, 2014, J NEUROPHYSIOL, V112, P1340, DOI 10.1152/jn.00826.2013
   LANGNER G, 1988, J NEUROPHYSIOL, V60, P1799
   Loizou PC, 1999, J ACOUST SOC AM, V106, P2097, DOI 10.1121/1.427954
   Lu T, 2001, NAT NEUROSCI, V4, P1131, DOI 10.1038/nn737
   Mardia K.V., 2009, DIRECTIONAL STAT, V494
   MOODY DB, 1994, J ACOUST SOC AM, V95, P3499, DOI 10.1121/1.409967
   Moore B.C., 2012, INTRO PSYCHOL HEARIN
   MULLERPREUSS P, 1994, HEARING RES, V80, P197, DOI 10.1016/0378-5955(94)90111-2
   Nelson PC, 2007, J NEUROPHYSIOL, V97, P522, DOI 10.1152/jn.00776.2006
   Nelson PC, 2004, J ACOUST SOC AM, V116, P2173, DOI 10.1121/1.1784442
   Oliver DL, 2018, MAMMALIAN AUDITORY P, V65
   Palmer AR, 2013, J PHYSIOL-LONDON, V591, P4003, DOI 10.1113/jphysiol.2013.255943
   PREUSS A, 1990, EXP BRAIN RES, V79, P207
   Rabiner Lawrence R, 2011, THEORY APPL DIGITAL, V64
   Ramachandran R, 1999, J NEUROPHYSIOL, V82, P152
   REES A, 1987, HEARING RES, V27, P129, DOI 10.1016/0378-5955(87)90014-1
   REES A, 1989, J ACOUST SOC AM, V85, P1978, DOI 10.1121/1.397851
   RHODE WS, 1994, J NEUROPHYSIOL, V71, P1797
   SCHILLER PH, 1992, TRENDS NEUROSCI, V15, P86, DOI 10.1016/0166-2236(92)90017-3
   SCHROEDEMR, 1966, PR INST ELECTR ELECT, V54, P720
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sinex DG, 2002, JARO, V3, P390, DOI 10.1007/s101620020026
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464
   Sterbing SJ, 2003, J NEUROPHYSIOL, V90, P2818, DOI 10.1152/jn.00268.2003
   Stevens H, 2000, FORBES, P30
   Varnet L, 2017, J ACOUST SOC AM, V142, P1976, DOI 10.1121/1.5006179
   VIEMEISTER NF, 1979, J ACOUST SOC AM, V66, P1364, DOI 10.1121/1.383531
   Yin PB, 2011, J NEUROPHYSIOL, V105, P582, DOI 10.1152/jn.00621.2010
   Zheng Y, 2008, J NEUROSCI, V28, P14230, DOI 10.1523/JNEUROSCI.2882-08.2008
   Zilany MSA, 2014, J ACOUST SOC AM, V135, P283, DOI 10.1121/1.4837815
NR 66
TC 0
Z9 0
U1 2
U2 2
PU AMER PHYSIOLOGICAL SOC
PI BETHESDA
PA 9650 ROCKVILLE PIKE, BETHESDA, MD 20814 USA
SN 0022-3077
EI 1522-1598
J9 J NEUROPHYSIOL
JI J. Neurophysiol.
PD OCT
PY 2020
VL 124
IS 4
BP 1198
EP 1215
DI 10.1152/jn.00279.2020
PG 18
WC Neurosciences; Physiology
SC Neurosciences & Neurology; Physiology
GA OC9ON
UT WOS:000579484500018
PM 32902353
DA 2021-02-24
ER

PT J
AU Maslowski, M
   Meyer, AS
   Bosker, HR
AF Maslowski, Merel
   Meyer, Antje S.
   Bosker, Hans Rutger
TI Eye-Tracking the Time Course of Distal and Global Speech Rate Effects
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE
LA English
DT Article
DE speech rate normalization; distal context; global context; two-stage
   model; eye-tracking
ID VISUAL WORLD PARADIGM; SPEAKING-RATE; PERCEPTUAL NORMALIZATION;
   CUE-INTEGRATION; RECOGNITION; WORDS; OSCILLATIONS; INFORMATION; SIGNAL
AB To comprehend speech sounds, listeners tune in to speech rate information in the proximal (immediately adjacent), distal (nonadjacent), and global context (further removed preceding and following sentences). Effects of global contextual speech rate cues on speech perception have been shown to follow constraints not found for proximal and distal speech rate. Therefore, listeners may process such global cues at distinct time points during word recognition. We conducted a printed-word eye-tracking experiment to compare the time courses of distal and global rate effects. Results indicated that the distal rate effect emerged immediately after target sound presentation, in line with a general-auditory account. The global rate effect, however, arose more than 200 ms later than the distal rate effect, indicating that distal and global context effects involve distinct processing mechanisms. Results are interpreted in a 2-stage model of acoustic context effects. This model posits that distal context effects involve very early perceptual processes, while global context effects arise at a later stage, involving cognitive adjustments conditioned by higher-level information.
C1 [Maslowski, Merel] Royal Dutch Kentalis, POB 7, NL-5270 BA St Michielsgestel, Netherlands.
   [Maslowski, Merel; Meyer, Antje S.; Bosker, Hans Rutger] Max Planck Inst Psycholinguist, Dept Psychol Language, Nijmegen, Netherlands.
   [Meyer, Antje S.; Bosker, Hans Rutger] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
RP Maslowski, M (corresponding author), Royal Dutch Kentalis, POB 7, NL-5270 BA St Michielsgestel, Netherlands.
EM M.Maslowski@kentalis.nl
CR Adank P, 2004, J ACOUST SOC AM, V116, P1729, DOI 10.1121/1.1779271
   Alexandrou AM, 2018, J COGNITIVE NEUROSCI, V30, P1704, DOI 10.1162/jocn_a_01295
   Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Baese-Berk MM, 2019, ATTEN PERCEPT PSYCHO, V81, P571, DOI 10.3758/s13414-018-1626-4
   Baese-Berk MM, 2014, PSYCHOL SCI, V25, P1546, DOI 10.1177/0956797614533705
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boersma P, 2015, PRAAT DOING PHONETIC
   Bosker H. R., Q J EXPT PSYCHOL
   Bosker H. R., SCI REPORTS
   Bosker HR, 2018, LANG COGN NEUROSCI, V33, P955, DOI 10.1080/23273798.2018.1439179
   Bosker HR, 2017, J EXP PSYCHOL LEARN, V43, P1225, DOI 10.1037/xlm0000381
   Bosker HR, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01063
   Bosker HR, 2017, J MEM LANG, V94, P166, DOI 10.1016/j.jml.2016.12.002
   Bosker HR, 2017, ATTEN PERCEPT PSYCHO, V79, P333, DOI 10.3758/s13414-016-1206-4
   Brehm L, 2017, J EXP PSYCHOL LEARN, V43, P1537, DOI 10.1037/xlm0000390
   Brown M., 2012, P 34 ANN C COGN SCI, P1374
   Cho SJ, 2018, PSYCHOMETRIKA, V83, P751, DOI 10.1007/s11336-018-9604-2
   DIEHL RL, 1989, J ACOUST SOC AM, V85, P2154, DOI 10.1121/1.397864
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Dink J. W, 2015, EYETRACKINGR R LIB E
   Galle ME, 2019, COGNITIVE SCI, V43, DOI 10.1111/cogs.12700
   Ghitza O, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00238
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   GORDON PC, 1988, PERCEPT PSYCHOPHYS, V43, P137, DOI 10.3758/BF03214191
   Huettig F, 2007, J MEM LANG, V57, P460, DOI 10.1016/j.jml.2007.02.001
   Huettig F, 2011, ACTA PSYCHOL, V137, P151, DOI 10.1016/j.actpsy.2010.11.003
   Kaufeld G, 2020, LANG COGN NEUROSCI, V35, P933, DOI 10.1080/23273798.2019.1701691
   Kaufeld G, 2020, J EXP PSYCHOL LEARN, V46, P549, DOI 10.1037/xlm0000744
   Kingston J, 2016, J EXP PSYCHOL HUMAN, V42, P1969, DOI 10.1037/xhp0000269
   Kosem A, 2018, CURR BIOL, V28, P2867, DOI 10.1016/j.cub.2018.07.023
   Maslowski M, 2019, J ACOUST SOC AM, V146, P179, DOI 10.1121/1.5116004
   Maslowski M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203571
   Maslowski M, 2019, J EXP PSYCHOL LEARN, V45, P128, DOI 10.1037/xlm0000579
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   McMurray B, 2008, PSYCHON B REV, V15, P1064, DOI 10.3758/PBR.15.6.1064
   McMurray B, 2008, J EXP PSYCHOL HUMAN, V34, P1609, DOI 10.1037/a0011747
   McQueen JM, 2007, Q J EXP PSYCHOL, V60, P661, DOI 10.1080/17470210601183890
   MILLER JL, 1983, J ACOUST SOC AM, V73, P1751, DOI 10.1121/1.389399
   Mitterer H, 2013, J MEM LANG, V69, P527, DOI 10.1016/j.jml.2013.07.002
   Newman RS, 2009, J PHONETICS, V37, P46, DOI 10.1016/j.wocn.2008.09.001
   Newman RS, 1996, PERCEPT PSYCHOPHYS, V58, P540, DOI 10.3758/BF03213089
   Oleson JJ, 2017, STAT METHODS MED RES, V26, P2708, DOI 10.1177/0962280215607411
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Pitt MA, 2016, ATTEN PERCEPT PSYCHO, V78, P334, DOI 10.3758/s13414-015-0981-7
   R Core Team, 2014, R LANG ENV STAT COMP
   Reinisch E, 2016, APPL PSYCHOLINGUIST, V37, P1397, DOI 10.1017/S0142716415000612
   Reinisch E, 2016, ATTEN PERCEPT PSYCHO, V78, P1203, DOI 10.3758/s13414-016-1067-x
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   Reinisch E, 2011, J EXP PSYCHOL HUMAN, V37, P978, DOI 10.1037/a0021923
   Salverda AP, 2003, COGNITION, V90, P51, DOI 10.1016/S0010-0277(03)00139-2
   Sawusch JR, 2000, PERCEPT PSYCHOPHYS, V62, P285, DOI 10.3758/BF03205549
   Seedorff M, 2018, J MEM LANG, V102, P55, DOI 10.1016/j.jml.2018.05.004
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   Toscano JC, 2015, LANG COGN NEUROSCI, V30, P529, DOI 10.1080/23273798.2014.946427
   Toscano JC, 2012, ATTEN PERCEPT PSYCHO, V74, P1284, DOI 10.3758/s13414-012-0306-z
   Ulrich R, 2001, PSYCHOPHYSIOLOGY, V38, P816, DOI 10.1017/S0048577201000610
   Wade T, 2005, PERCEPT PSYCHOPHYS, V67, P939, DOI 10.3758/BF03193621
NR 59
TC 1
Z9 1
U1 2
U2 2
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0096-1523
EI 1939-1277
J9 J EXP PSYCHOL HUMAN
JI J. Exp. Psychol.-Hum. Percept. Perform.
PD OCT
PY 2020
VL 46
IS 10
BP 1148
EP 1163
DI 10.1037/xhp0000838
PG 16
WC Psychology; Psychology, Experimental
SC Psychology
GA NZ5KR
UT WOS:000577141600008
PM 32614215
OA Green Published
DA 2021-02-24
ER

PT J
AU Mamatha, NM
   Yathiraj, A
AF Mamatha, Nerale Maraiah
   Yathiraj, Asha
TI Comparison of Diagnostic Auditory Processing Test Scores Measured in
   Clinical and School Settings
SO LANGUAGE SPEECH AND HEARING SERVICES IN SCHOOLS
LA English
DT Article
ID SCREENING-TEST; CHILDREN; DISORDERS; ATTENTION; LANGUAGE; SECTOR; STAP
AB Purpose: The study aimed to compare auditory processing and cognitive test scores measured in a clinical setting with that measured in a school setting using a repeated-measures design. This was done on typically developing children and children with auditory processing disorder (APD).
   Method: Thirty-two children (16 typically developing and 16 with APD), aged 7 years, were evaluated using three diagnostic auditory processing tests and a cognitive test. The tests included the Speech Perception in Noise Test in Kannada, the Gap Detection Threshold Test, the Dichotic Consonant-Vowel Test, and the Auditory Memory and Sequencing Test in Kannada. All the children were evaluated in an audiological diagnostic setting, as well as in their school.
   Results: No significant difference in scores was obtained in the two settings for all the four tests that were administered. This was seen in the typically developing children and the children with APD. Additionally, the pass/fail decision for each test did not alter in the two settings. Moderate to almost perfect agreement was seen between the tests carried out in the two settings in both groups, on a Kappa test of agreement. In both settings, the children with APD performed significantly poorer than the typically developing children on the four diagnostic tests.
   Conclusions: The findings of the study indicate that the diagnostic auditory processing tests and the cognitive test can be carried out in school settings as effectively as tests carried out in an audiological diagnostic clinical setting. This will enable carrying out diagnostic tests on children in schools soon after they are referred on screening auditory processing tools, administered in the educational setting. This will prevent missing diagnosis of children who fail to report to a diagnostic audiological center for detailed auditory processing evaluation.
C1 [Mamatha, Nerale Maraiah; Yathiraj, Asha] All India Inst Speech & Learing, Dept Audiol, Mysore, Karnataka, India.
RP Mamatha, NM (corresponding author), All India Inst Speech & Learing, Dept Audiol, Mysore, Karnataka, India.
EM mamms_20@rediffmail.com
CR All India Institute of Speech and Hearing, 2009, ETH GUID BIOB RES IN
   American Academy of Audiology, 2010, GUID DIAGN TREATM MA
   American National Standards Institute, 2013, S311999 ANSI
   American Speech-Language-Hearing Association, 2005, GUID MAN PUR TON THR
   American Speech-Language- Hearing Association, 1997, GUID AUD SCREEN
   American Speech-Language-Hearing Association, 2005, CENTRAL AUDITORY PRO, DOI [DOI 10.1044/POLICY.TR2005-00043, 10.1044/policy.TR2005-00043]
   American Speech-Language-Hearing Association, 1995, POS STAT GUID AC ED
   [Anonymous], 2010, NEWB INF HEAR SCREEN
   Bamiou DE, 2001, ARCH DIS CHILD, V85, P361, DOI 10.1136/adc.85.5.361
   Bellis T. J., 2003, ASSESSMENT MANAGEMEN
   Bright K., 2011, AM ACAD AUDIOLOGY CH
   Byrne David C., 2015, Journal of the Acoustical Society of America, V137, DOI 10.1121/1.4920367
   Cacace Anthony T, 2005, Am J Audiol, V14, P112, DOI 10.1044/1059-0889(2005/012)
   Cacace AT, 1998, J SPEECH LANG HEAR R, V41, P355, DOI 10.1044/jslhr.4102.355
   Campbell N., 2011, BSA PRACTICE GUIDANC
   Campbell N., 2012, ENT AUDIOL NEWS, V21, P86
   Chermak G. D., 1997, CENTRAL AUDITORY PRO
   Chermak GD, 2002, OTOLARYNG CLIN N AM, V35, P733, DOI 10.1016/S0030-6665(02)00056-7
   Crandell CC, 1996, AMPLIFICATION FOR CHILDREN WITH AUDITORY DEFICITS, P229
   DIRKS DD, 1977, J SPEECH HEAR DISORD, V42, P408, DOI 10.1044/jshd.4203.408
   Esplin J., 2014, AUDITORY PROCESSING
   Ferre J. M., 1998, M3 MODEL TREATING CA
   Frank T, 2000, Am J Audiol, V9, P3, DOI 10.1044/1059-0889(2000/003)
   Govender SM, 2018, S AFR J COMMUN DISOR, V65, DOI 10.4102/sajcd.v65i1.582
   Gyldenkaerne P, 2014, J AM ACAD AUDIOL, V25, P676, DOI 10.3766/jaaa.25.7.6
   Hall JW, 1997, J ACOUST SOC AM, V101, P1044, DOI 10.1121/1.418110
   Halliday LF, 2017, COGNITION, V166, P139, DOI 10.1016/j.cognition.2017.04.014
   Hind SE, 2011, INT J AUDIOL, V50, P708, DOI 10.3109/14992027.2011.582049
   Jerger J, 2000, J Am Acad Audiol, V11, P467
   KATZ J, 1962, J AUD RES, V2, P327
   Katz J., 1971, MENORAH MED J, V2, P18
   Kreisman NV, 2012, J AM ACAD AUDIOL, V23, P222, DOI 10.3766/jaaa.23.3.8
   Lagace J, 2011, INT J AUDIOL, V50, P385, DOI 10.3109/14992027.2011.553204
   Lawton S, 2017, J AM ACAD AUDIOL, V28, P610, DOI 10.3766/jaaa.15130
   Maggu AR, 2011, CAN J SPEECH-LANG PA, V35, P56
   Mamatha N. M., 2019, J INDIAN SPEECH LANG, V33, P32, DOI [10.4103/jisha.JISHA_17_18, DOI 10.4103/JISHA.JISHA_17_18]
   Margolis RH, 2015, J AM ACAD AUDIOL, V26, P784, DOI 10.3766/jaaa.14072
   Meyer ME, 2012, INT J PEDIATR OTORHI, V76, P698, DOI 10.1016/j.ijporl.2012.02.023
   Musiek Frank E, 2004, J Am Acad Audiol, V15, P117, DOI 10.3766/jaaa.15.2.3
   Muthuselvi T., 2009, STUDENT RES ALL INDI, V7, P159
   Ravens J. C., 1952, STANDARD COLOURED PR
   Sharma M, 2014, J SPEECH LANG HEAR R, V57, P2308, DOI 10.1044/2014_JSLHR-H-13-0226
   Sharma M, 2009, J SPEECH LANG HEAR R, V52, P706, DOI 10.1044/1092-4388(2008/07-0226)
   Shivaprakash S., 2003, GAP DETECTION TEST D
   Skarzynski H, 2012, INT J PEDIATR OTORHI, V76, P120, DOI 10.1016/j.ijporl.2011.10.016
   Stein R., 1998, CENTRAL AUDITORY PRO, P89
   Swanepoel D, 2013, J AM ACAD AUDIOL, V24, P992, DOI 10.3766/jaaa.24.10.10
   Theunissen M, 2008, INT J AUDIOL, V47, pS23, DOI 10.1080/14992020802294032
   Vaidyanath R., 2012, SPEECH IN NOISE TEST
   Vandana S., 1998, SPEECH IDENTIF UNPUB
   Viera AJ, 2005, FAM MED, V37, P360
   Weihing JA, 2007, J AM ACAD AUDIOL, V18, P141, DOI 10.3766/jaaa.18.2.6
   YATHIRAJ A, 2004, J IND SPEECH HEAR AS, V18, P6
   Yathiraj A, 2006, KANNADA AUDITORY MEM
   Yathiraj A., 1999, MAT DEV DEP AUDIOLOG
   Yathiraj A, 2012, SSW REP, V34, P16
   Yathiraj A, 2018, AM J AUDIOL, V27, P173, DOI 10.1044/2018_AJA-17-0091
   Yathiraj A, 2015, INT J PEDIATR OTORHI, V79, P1224, DOI 10.1016/j.ijporl.2015.05.018
   Yathiraj A, 2014, INT J PEDIATR OTORHI, V78, P479, DOI 10.1016/j.ijporl.2013.12.025
   Yathiraj A, 2013, J AM ACAD AUDIOL, V24, P867, DOI 10.3766/jaaa.24.9.10
NR 60
TC 0
Z9 0
U1 1
U2 1
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 0161-1461
EI 1558-9129
J9 LANG SPEECH HEAR SER
JI Lang. Speech Hear. Serv. Sch.
PD OCT
PY 2020
VL 51
IS 4
BP 1071
EP 1080
DI 10.1044/2020_LSHSS-20-00020
PG 10
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA NZ5PM
UT WOS:000577157700012
PM 32924892
DA 2021-02-24
ER

PT J
AU Bosker, HR
   Peeters, D
   Holler, J
AF Bosker, Hans Rutger
   Peeters, David
   Holler, Judith
TI How visual cues to speech rate influence speech perception
SO QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY
LA English
DT Article
DE Speech rate; neural entrainment; audiovisual speech perception;
   rate-dependent perception; rate normalisation; supramodal perception
ID SPEAKING RATE; AUDITORY-CORTEX; INFORMATION; OSCILLATIONS; HEARING;
   WORDS
AB Spoken words are highly variable and therefore listeners interpret speech sounds relative to the surrounding acoustic context, such as the speech rate of a preceding sentence. For instance, a vowel midway between short /a:/ and long /a:/ in Dutch is perceived as short /./ in the context of preceding slow speech, but as long /a:/ if preceded by a fast context. Despite the well-established influence of visual articulatory cues on speech comprehension, it remains unclear whether visual cues to speech rate also influence subsequent spoken word recognition. In two "Go Fish"-like experiments, participants were presented with audio-only (auditory speech + fixation cross), visual-only (mute videos of talking head), and audiovisual (speech + videos) context sentences, followed by ambiguous target words containing vowels midway between short /./ and long /a:/. In Experiment 1, target words were always presented auditorily, without visual articulatory cues. Although the audio-only and audiovisual contexts induced a rate effect (i.e., more long /a:/ responses after fast contexts), the visual-only condition did not. When, in Experiment 2, target words were presented audiovisually, rate effects were observed in all three conditions, including visual-only. This suggests that visual cues to speech rate in a context sentence influence the perception of following visual target cues (e.g., duration of lip aperture), which at an audiovisual integration stage bias participants' target categorisation responses. These findings contribute to a better understanding of how what we see influences what we hear.
C1 [Bosker, Hans Rutger; Peeters, David; Holler, Judith] Max Planck Inst Psycholinguist, POB 310, NL-6500 AH Nijmegen, Netherlands.
   [Bosker, Hans Rutger; Peeters, David; Holler, Judith] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
   [Peeters, David] Tilburg Univ, Tilburg Ctr Cognit & Commun TiCC, Dept Commun & Cognit, Tilburg, Netherlands.
RP Bosker, HR (corresponding author), Max Planck Inst Psycholinguist, POB 310, NL-6500 AH Nijmegen, Netherlands.
EM hansrutger.bosker@mpi.nl
OI Bosker, Hans Rutger/0000-0002-2628-7738; HOLLER,
   JUDITH/0000-0003-0671-6651
FU Max Planck Society for the Advancement of Science, Munich, GermanyMax
   Planck Society; Netherlands Organisation for Scientific
   ResearchNetherlands Organization for Scientific Research (NWO)
   [275-89-037]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This
   research was supported by the Max Planck Society for the Advancement of
   Science, Munich, Germany (H.R.B., D.P., J.H.) and the Netherlands
   Organisation for Scientific Research (D.P.; Veni grant 275-89-037).
CR Assgari AA, 2015, J ACOUST SOC AM, V138, P3023, DOI 10.1121/1.4934559
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Biau E, 2015, CORTEX, V68, P76, DOI 10.1016/j.cortex.2014.11.018
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Bosker HR, 2020, ATTEN PERCEPT PSYCHO, V82, P1318, DOI 10.3758/s13414-019-01824-2
   Bosker HR, 2018, LANG COGN NEUROSCI, V33, P955, DOI 10.1080/23273798.2018.1439179
   Bosker HR, 2017, J EXP PSYCHOL LEARN, V43, P1225, DOI 10.1037/xlm0000381
   Bosker HR, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01063
   Bosker HR, 2017, J MEM LANG, V94, P166, DOI 10.1016/j.jml.2016.12.002
   Bosker HR, 2017, ATTEN PERCEPT PSYCHO, V79, P333, DOI 10.3758/s13414-016-1206-4
   Brancazio L, 2005, PERCEPT PSYCHOPHYS, V67, P759, DOI 10.3758/BF03193531
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593
   Crosse MJ, 2015, J NEUROSCI, V35, P14195, DOI 10.1523/JNEUROSCI.1829-15.2015
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Escudero P, 2009, J PHONETICS, V37, P452, DOI 10.1016/j.wocn.2009.07.006
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Golumbic EZ, 2013, J NEUROSCI, V33, P1417, DOI 10.1523/JNEUROSCI.3675-12.2013
   GREEN KP, 1985, PERCEPT PSYCHOPHYS, V38, P269, DOI 10.3758/BF03207154
   GREEN KP, 1987, PERCEPT PSYCHOPHYS, V42, P587, DOI 10.3758/BF03207990
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Iversen JR, 2015, COGNITION, V134, P232, DOI 10.1016/j.cognition.2014.10.018
   Jesse A., 2013, 54 ANN PSYCH SOC M T
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Kaufeld G, 2020, LANG COGN NEUROSCI, V35, P933, DOI 10.1080/23273798.2019.1701691
   Kaufeld G, 2020, J EXP PSYCHOL LEARN, V46, P549, DOI 10.1037/xlm0000744
   Kayser C, 2008, CEREB CORTEX, V18, P1560, DOI 10.1093/cercor/bhm187
   Kosem A, 2018, CURR BIOL, V28, P2867, DOI 10.1016/j.cub.2018.07.023
   Krahmer E, 2007, J MEM LANG, V57, P396, DOI 10.1016/j.jml.2007.06.005
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Maslowski M, 2019, J ACOUST SOC AM, V146, P179, DOI 10.1121/1.5116004
   Maslowski M, 2019, J EXP PSYCHOL LEARN, V45, P128, DOI 10.1037/xlm0000579
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McNeill D., 1992, HAND MIND WHAT GESTU
   MILLER JL, 1979, PERCEPT PSYCHOPHYS, V25, P457, DOI 10.3758/BF03213823
   Park H, 2016, ELIFE, V5, DOI 10.7554/eLife.14521
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   PICKETT JM, 1960, LANG SPEECH, V3, P11, DOI 10.1177/002383096000300103
   Pitt MA, 2016, ATTEN PERCEPT PSYCHO, V78, P334, DOI 10.3758/s13414-015-0981-7
   Quene H, 2008, J MEM LANG, V59, P413, DOI 10.1016/j.jml.2008.02.002
   R Development Core Team, 2012, R LAN ENV STAT COMP
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   Reinisch E, 2011, LANG SPEECH, V54, P147, DOI 10.1177/0023830910397489
   Reinisch E, 2011, J EXP PSYCHOL HUMAN, V37, P978, DOI 10.1037/a0021923
   Repp BH, 2004, PSYCHOL RES-PSYCH FO, V68, P252, DOI 10.1007/s00426-003-0143-8
   Rosenblum L. D., 2019, OXFORD RES ENCY LING, DOI DOI 10.1093/ACREFORE/9780199384655.001.0001/ACREF0RE-9780199384655-E-420
   Rosenblum LD, 2007, PSYCHOL SCI, V18, P392, DOI 10.1111/j.1467-9280.2007.01911.x
   Rosenblum LD, 2017, J COGN PSYCHOL, V29, P65, DOI 10.1080/20445911.2016.1181691
   Schroeder CE, 2008, TRENDS COGN SCI, V12, P106, DOI 10.1016/j.tics.2008.01.002
   Sjerps MJ, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10365-z
   Strand EA, 1996, NATURAL LANGUAGE PROCESSING AND SPEECH TECHNOLOGY, P14
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Toscano JC, 2015, LANG COGN NEUROSCI, V30, P529, DOI 10.1080/23273798.2014.946427
   Wade T, 2005, PERCEPT PSYCHOPHYS, V67, P939, DOI 10.3758/BF03193621
   Winn MB, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00824
NR 55
TC 0
Z9 0
U1 2
U2 2
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1747-0218
EI 1747-0226
J9 Q J EXP PSYCHOL
JI Q. J. Exp. Psychol.
PD OCT
PY 2020
VL 73
IS 10
BP 1523
EP 1536
DI 10.1177/1747021820914564
PG 14
WC Psychology, Biological; Physiology; Psychology; Psychology, Experimental
SC Psychology; Physiology
GA NZ5NT
UT WOS:000577151700001
PM 32160814
OA Green Published
DA 2021-02-24
ER

PT J
AU Yamamoto, K
   Irino, T
   Araki, S
   Kinoshita, K
   Nakatani, T
AF Yamamoto, Katsuhiko
   Irino, Toshio
   Araki, Shoko
   Kinoshita, Keisuke
   Nakatani, Tomohiro
TI GEDI: Gammachirp envelope distortion index for predicting
   intelligibility of enhanced speech
SO SPEECH COMMUNICATION
LA English
DT Article
DE Speech intelligibility; Objective measure; Speech enhancement
ID RECEPTION THRESHOLD; NOISE; MODULATION; MODEL; RECOGNITION; PERCEPTION;
   QUALITY; DOMAIN; RATIO
AB In this study, we propose a new concept, the gammachirp envelope distortion index (GEDI), based on the signal-to-distortion ratio in the auditory envelope, SDRenv, to predict the intelligibility of speech enhanced by nonlinear algorithms. The objective of GEDI is to calculate the distortion between enhanced and clean-speech representations in the domain of a temporal envelope extracted by the gammachirp auditory filterbank and modulation filterbank. We also extend GEDI with multi-resolution analysis (mr-GEDI) to predict the speech intelligibility of sounds under non-stationary noise conditions. We evaluate GEDI in terms of the speech intelligibility predictions of speech sounds enhanced by a classic spectral subtraction and a Wiener filtering method. The predictions are compared with human results for various signal-to-noise ratio conditions with additive pink and babble noises. The results showed that mr-GEDI predicted the intelligibility curves better than short-time objective intelligibility (STOI) measure, extended-STOI (ESTOI) measure, and hearing-aid speech perception index (HASPI) under pinknoise conditions, and better than HASPI under babble-noise conditions. The mr-GEDI method does not present an overestimation tendency and is considered a more conservative approach than STOI and ESTOI. Therefore, the evaluation with mr-GEDI may provide additional information in the development of speech enhancement algorithms.
C1 [Yamamoto, Katsuhiko; Irino, Toshio] Wakayama Univ, Grad Sch Syst Engn, Sakaedani 930, Wakayama 6408510, Japan.
   [Araki, Shoko; Kinoshita, Keisuke; Nakatani, Tomohiro] NTT Commun Sci Labs, 2-4 Hikaridai, Seika, Kyoto 6190237, Japan.
RP Yamamoto, K (corresponding author), Wakayama Univ, Grad Sch Syst Engn, Sakaedani 930, Wakayama 6408510, Japan.
EM yamamoto.katsuhiko@g.wakayama-u.jp; irino@wakayama-u.ac.jp;
   araki.shoko@lab.ntt.co.jp; kinoshita.k@lab.ntt.co.jp;
   nakatani.tomohiro@lab.ntt.co.jp
OI Araki, Shoko/0000-0003-4363-4305
FU JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [JP25280063,
   JP16H01734, JP16K12464, 17J04227]
FX This research was partially supported by JSPS KAKENHI: Grant Nos.
   JP25280063, JP16H01734, JP16K12464, and 17J04227. We thank anonymous
   reviewers for their very helpful comments and suggestions.
CR Altman D, 2013, STAT CONFIDENCE CONF
   American National Standards Institute, 1997, METHODS CALCULATION
   Berouti M., 1979, ICASSP 79. 1979 IEEE International Conference on Acoustics, Speech and Signal Processing, P208
   BLAND JM, 1986, LANCET, V1, P307, DOI 10.1016/s0140-6736(86)90837-8
   Chabot-Leclerc A, 2014, J ACOUST SOC AM, V135, P3502, DOI 10.1121/1.4873517
   Chi TS, 1999, J ACOUST SOC AM, V106, P2719, DOI 10.1121/1.428100
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   Dreschler WA, 2001, AUDIOLOGY, V40, P148
   Dubbelboer F, 2008, J ACOUST SOC AM, V124, P3937, DOI 10.1121/1.3001713
   EPHRAIM Y, 1985, IEEE T ACOUST SPEECH, V33, P443, DOI 10.1109/TASSP.1985.1164550
   Erkelens JS, 2007, IEEE T AUDIO SPEECH, V15, P1741, DOI 10.1109/TASL.2007.899233
   Falk TH, 2015, IEEE SIGNAL PROC MAG, V32, P114, DOI 10.1109/MSP.2014.2358871
   Fujimoto M., 2009, P INT 2009, P1235
   Fujimoto M, 2012, INT CONF ACOUST SPEE, P4713, DOI 10.1109/ICASSP.2012.6288971
   Furui S., 2000, P ASR 00, P244
   Green D.M., 1988, SIGNAL DETECT RECOG, P609
   GUSTAFSSON HA, 1994, J ACOUST SOC AM, V95, P518, DOI 10.1121/1.408346
   Hsu J. C, 1996, MULTIPLE COMP THEORY
   Irino T., 2019, GAMMACHIRP FILTERBAN
   Irino T, 2006, IEEE T AUDIO SPEECH, V14, P2222, DOI 10.1109/TASL.2006.874669
   *ISO, 2003, 9921 ISO
   Jensen J, 2016, IEEE-ACM T AUDIO SPE, V24, P2009, DOI 10.1109/TASLP.2016.2585878
   Jorgensen S, 2013, J ACOUST SOC AM, V134, P436, DOI 10.1121/1.4807563
   Jorgensen S, 2011, J ACOUST SOC AM, V130, P1475, DOI 10.1121/1.3621502
   Kates JM, 2015, J ACOUST SOC AM, V138, P2470, DOI 10.1121/1.4931899
   Kates JM, 2014, SPEECH COMMUN, V65, P75, DOI 10.1016/j.specom.2014.06.002
   Kates JM, 2005, J ACOUST SOC AM, V117, P2224, DOI 10.1121/1.1862575
   Kjems U, 2009, J ACOUST SOC AM, V126, P1415, DOI 10.1121/1.3179673
   Kondo K., 2007, NTT TOHOKU U FAMILIA
   Maekawa K., 2003, ISCA IEEE WORKSH SPO, P7
   Matsui T., 2016, J ACOUST SOC AM, V140, P3274, DOI 10.1121/1.4970396
   Mickes L, 2007, PSYCHON B REV, V14, P858, DOI 10.3758/BF03194112
   Moore B. C. J., 2013, INTRO PSYCHOL HEARIN
   Patterson RD, 2003, J ACOUST SOC AM, V114, P1529, DOI 10.1121/1.1600720
   Rhebergen KS, 2009, J ACOUST SOC AM, V126, P3236, DOI 10.1121/1.3257225
   Rhebergen KS, 2005, J ACOUST SOC AM, V117, P2181, DOI 10.1121/1.1861713
   Santos JF, 2014, 2014 14TH INTERNATIONAL WORKSHOP ON ACOUSTIC SIGNAL ENHANCEMENT (IWAENC), P55, DOI 10.1109/IWAENC.2014.6953337
   Smaragdis P, 2017, INT CONF ACOUST SPEE, P86, DOI 10.1109/ICASSP.2017.7952123
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Wang YX, 2014, IEEE-ACM T AUDIO SPE, V22, P1849, DOI 10.1109/TASLP.2014.2352935
   Weninger F, 2014, INTERSPEECH, P865
   Yamamoto K, 2018, INTERSPEECH, P1863, DOI 10.21437/Interspeech.2018-1291
   Yamamoto K, 2019, ACOUST SCI TECHNOL, V40, P84, DOI 10.1250/ast.40.84
   Yamamoto K, 2017, INTERSPEECH, P2949, DOI 10.21437/Interspeech.2017-170
   Yamamoto K, 2016, INTERSPEECH, P2885, DOI 10.21437/Interspeech.2016-652
NR 46
TC 0
Z9 0
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-6393
EI 1872-7182
J9 SPEECH COMMUN
JI Speech Commun.
PD OCT
PY 2020
VL 123
BP 43
EP 58
DI 10.1016/j.specom.2020.06.001
PG 16
WC Acoustics; Computer Science, Interdisciplinary Applications
SC Acoustics; Computer Science
GA NQ9YL
UT WOS:000571221800005
DA 2021-02-24
ER

PT J
AU Nunez, AIR
   Yue, QH
   Pasalar, S
   Martin, RC
AF Nunez, Aurora I. Ramos
   Yue, Qiuhai
   Pasalar, Siavash
   Martin, Randi C.
TI The role of left vs. right superior temporal gyrus in speech perception:
   An fMRI-guided TMS study
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Speech perception; Superior temporal gyrus; TMS; fMRI
ID TRANSCRANIAL MAGNETIC STIMULATION; PURE WORD DEAFNESS; LANGUAGE; BRAIN;
   DOMINANCE; ORGANIZATION; MODULATION; MUSIC; PET
AB Debate continues regarding the necessary role of right superior temporal gyrus (STG) regions in sublexical speech perception given the bilateral STG activation often observed in fMRI studies. To evaluate the causal roles, TMS pulses were delivered to inhibit and disrupt neuronal activity at the left and right STG regions during a nonword discrimination task based on peak activations from a blocked fMRI paradigm assessing speech vs. nonspeech perception (N = 20). Relative to a control region located in the posterior occipital lobe, TMS to the left anterior STG (laSTG) led to significantly worse accuracy, whereas TMS to the left posterior STG (lpSTG) and right anterior STG (raSTG) did not. Although the disruption from TMS was significantly greater for the laSTG than for raSTG, the difference in accuracy between the laSTG and lpSTG did not reach significance. The results argue for a causal role of the laSTG but not raSTG in speech perception. Further research is needed to establish the source of the differences between the laSTG and lpSTG.
C1 [Nunez, Aurora I. Ramos] Coll Coastal Georgia, Dept Social Sci, 1 Coll Dr, Brunswick, GA 31520 USA.
   [Yue, Qiuhai; Pasalar, Siavash; Martin, Randi C.] Rice Univ, Dept Psychol Sci, Houston, TX 77005 USA.
   [Yue, Qiuhai] Vanderbilt Univ, Dept Psychol, Nashville, TN 37212 USA.
RP Nunez, AIR (corresponding author), Coll Coastal Georgia, Dept Social Sci, 1 Coll Dr, Brunswick, GA 31520 USA.
EM aramosnunez@ccga.edu
FU Gertrude Maurin fund; Social Science Research Institute; T.L.L. Temple
   Foundation Neuroplasticity Lab at Rice University
FX This work was supported by the Gertrude Maurin fund, the Social Science
   Research Institute, and the T.L.L. Temple Foundation Neuroplasticity Lab
   at Rice University. We thank the Core for Advanced MRI (CAMRI) at Baylor
   College of Medicine for assistance with imaging data collection. We also
   thank Elizabeth Baca and Hania Nagy for their help with TMS data
   collection and Sophia Huang for her help in creating the speech
   perception sounds.
CR Andoh J, 2011, J COGNITIVE NEUROSCI, V23, P349, DOI 10.1162/jocn.2010.21449
   Beauchamp MS, 2010, J NEUROSCI, V30, P2414, DOI 10.1523/JNEUROSCI.4865-09.2010
   Boatman D, 1997, CORTEX, V33, P83, DOI 10.1016/S0010-9452(97)80006-8
   Buchweitz Augusto, 2009, Psychol. Neurosci., V2, P111, DOI 10.3922/j.psns.2009.2.003
   Cousineau D, 2005, TUTOR QUANT METHODS, V1, P42, DOI 10.20982/tqmp.01.1.p042
   Cox RW, 2017, BRAIN CONNECT, V7, P152, DOI 10.1089/brain.2016.0475
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   FIEZ JA, 1995, J COGNITIVE NEUROSCI, V7, P357, DOI 10.1162/jocn.1995.7.3.357
   Glickman ME, 2014, J CLIN EPIDEMIOL, V67, P850, DOI 10.1016/j.jclinepi.2014.03.012
   Hamilton LS, 2018, CURR BIOL, V28, P1860, DOI 10.1016/j.cub.2018.04.033
   Hartwigsen G, 2010, P NATL ACAD SCI USA, V107, P16494, DOI 10.1073/pnas.1008121107
   Hickok G, 2003, J COGNITIVE NEUROSCI, V15, P673, DOI 10.1162/089892903322307393
   Hickok G, 2008, BRAIN LANG, V107, P179, DOI 10.1016/j.bandl.2008.09.006
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Huettel SA, 2014, FUNCTIONAL MAGNETIC RESONANCE IMAGING, THIRD EDITION, P1
   Hugdahl K, 2016, NEUROPSYCHOLOGIA, V93, P466, DOI 10.1016/j.neuropsychologia.2015.12.011
   Hullett PW, 2016, J NEUROSCI, V36, P2014, DOI 10.1523/JNEUROSCI.1779-15.2016
   Humphries C, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00406
   Johsrude I. S., 1997, NEUROREPORT, V8, P1761, DOI [10.1097/00001756-199705060-00038., DOI 10.1097/00001756-199705060-00038]
   KIMURA D, 1961, CAN J PSYCHOLOGY, V15, P166, DOI 10.1037/h0083219
   liwiska M. W., 2014, JOVE-J VIS EXP, V89, P51735, DOI 10.3791/51735
   Maffei C, 2017, CORTEX, V97, P240, DOI 10.1016/j.cortex.2017.10.006
   MCGLONE J, 1984, BRAIN LANG, V22, P150, DOI 10.1016/0093-934X(84)90084-1
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   MILNER B, 1968, SCIENCE, V161, P184, DOI 10.1126/science.161.3837.184
   Ozker M, 2017, J COGNITIVE NEUROSCI, V29, P1044, DOI 10.1162/jocn_a_01110
   Pascual-Leone A, 1999, PHILOS T R SOC B, V354, P1229, DOI 10.1098/rstb.1999.0476
   Poeppel D, 2001, COGNITIVE SCI, V25, P679, DOI 10.1016/S0364-0213(01)00050-7
   Pollmann S, 2002, NEUROPSYCHOLOGY, V16, P56, DOI 10.1037//0894-4105.16.1.56
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Rossi S, 2009, CLIN NEUROPHYSIOL, V120, P2008, DOI 10.1016/j.clinph.2009.08.016
   Sack AT, 2005, SCIENCE, V308, P702, DOI 10.1126/science.1107784
   Schuhmann T, 2012, CEREB CORTEX, V22, P701, DOI 10.1093/cercor/bhr155
   Scott SK, 2013, BRAIN LANG, V127, P36, DOI 10.1016/j.bandl.2013.07.006
   Shinshi M, 2015, BRAIN BEHAV, V5, DOI 10.1002/brb3.317
   Slevc LR, 2011, NEUROPSYCHOLOGIA, V49, P216, DOI 10.1016/j.neuropsychologia.2010.11.009
   Sparks R., 1968, CORTEX, V4, P3, DOI DOI 10.1016/S0010-9452(68)80009-7
   Talairach J, 1988, COPLANAR STEREOTAXIC
   Thut G, 2010, BRAIN TOPOGR, V22, P219, DOI 10.1007/s10548-009-0115-4
   Turkeltaub PE, 2010, BRAIN LANG, V114, P1, DOI 10.1016/j.bandl.2010.03.008
   WADA J, 1960, J NEUROSURG, V17, P266, DOI 10.3171/jns.1960.17.2.0266
   Wingfield A, 2006, J NEUROPHYSIOL, V96, P2830, DOI 10.1152/jn.00628.2006
   Wong PCM, 2008, J SPEECH LANG HEAR R, V51, P1026, DOI 10.1044/1092-4388(2008/075)
   Yi HG, 2019, NEURON, V102, P1096, DOI 10.1016/j.neuron.2019.04.023
   Yue QH, 2019, CEREB CORTEX, V29, P1398, DOI 10.1093/cercor/bhy037
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
NR 46
TC 0
Z9 0
U1 5
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD OCT
PY 2020
VL 209
AR 104838
DI 10.1016/j.bl.2020.104838
PG 8
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA NK1AT
UT WOS:000566472900004
DA 2021-02-24
ER

PT J
AU Luthra, S
   Correia, JM
   Kleinschmidt, DF
   Mesite, L
   Myers, EB
AF Luthra, Sahil
   Correia, Joao M.
   Kleinschmidt, Dave F.
   Mesite, Laura
   Myers, Emily B.
TI Lexical Information Guides Retuning of Neural Patterns in Perceptual
   Learning for Speech
SO JOURNAL OF COGNITIVE NEUROSCIENCE
LA English
DT Article
ID FMRI; VOICE; SOUNDS; RECALIBRATION; CLASSIFICATION; CATEGORIZATION;
   DORSAL; ROBUST; AREAS
AB A listener's interpretation of a given speech sound can vary probabilistically from moment to moment. Previous experience (i.e., the contexts in which one has encountered an ambiguous sound) can further influence the interpretation of speech, a phenomenon known as perceptual learning for speech. This study used multivoxel pattern analysis to query how neural patterns reflect perceptual learning, leveraging archival fMRI data from a lexically guided perceptual learning study conducted by Myers and Mesite [Myers, E. B., & Mesite, L. M. Neural systems underlying perceptual adjustment to non-standard speech tokens.Journal of Memory and Language,76, 80-93, 2014]. In that study, participants first heard ambiguous /s/-/integral/ blends in either /s/-biased lexical contexts (epi_ode) or /integral/-biased contexts (refre_ing); subsequently, they performed a phonetic categorization task on tokens from an /asi/-/a integral i/ continuum. In the current work, a classifier was trained to distinguish between phonetic categorization trials in which participants heard unambiguous productions of /s/ and those in which they heard unambiguous productions of /integral/. The classifier was able to generalize this training to ambiguous tokens from the middle of the continuum on the basis of individual participants' trial-by-trial perception. We take these findings as evidence that perceptual learning for speech involves neural recalibration, such that the pattern of activation approximates the perceived category. Exploratory analyses showed that left parietal regions (supramarginal and angular gyri) and right temporal regions (superior, middle, and transverse temporal gyri) were most informative for categorization. Overall, our results inform an understanding of how moment-to-moment variability in speech perception is encoded in the brain.
C1 [Luthra, Sahil; Myers, Emily B.] Univ Connecticut, Storrs, CT 06269 USA.
   [Correia, Joao M.] Univ Algarve, Faro, Portugal.
   [Correia, Joao M.] Basque Ctr Cognit Brain & Language, Donostia San Sebastian, Spain.
   [Kleinschmidt, Dave F.] Rutgers State Univ, New Brunswick, NJ USA.
   [Mesite, Laura] MGH Inst Hlth Profess, Boston, MA USA.
   [Mesite, Laura] Harvard Grad Sch Educ, Cambridge, MA USA.
RP Luthra, S (corresponding author), Univ Connecticut, Dept Psychol Sci, 406 Babbidge Rd,Unit 1020, Storrs, CT 06269 USA.
EM sahil.luthra@uconn.edu
OI Luthra, Sahil/0000-0002-3517-2609
FU NSF IGERTNational Science Foundation (NSF) [DGE-1144399]; NIHUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USA [R03 DC009395, R01 DC013064]; NSFNational Science
   Foundation (NSF)
FX This work was supported by NSF IGERT DGE-1144399, NIH R03 DC009395 (PI:
   Myers), NIH R01 DC013064 (PI: Myers), and an NSF Graduate Research
   Fellowship to S. L. The authors report no conflict of interest. We thank
   attendees of the 2019 meeting of the Society for the Neurobiology of
   Language for helpful discussions on this project. Additional thanks are
   extended to two anonymous reviewers for helpful feedback on a previous
   draft of this article. All analysis scripts are available at
   osf.io/fdbwn.
CR Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Best RM, 2019, J EXP PSYCHOL LEARN, V45, P1166, DOI 10.1037/xlm0000609
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Binder JR, 1997, J NEUROSCI, V17, P353
   Bonte M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05356-3
   Correia J, 2014, J NEUROSCI, V34, P332, DOI 10.1523/JNEUROSCI.1302-13.2014
   Correia JM, 2015, J NEUROSCI, V35, P15015, DOI 10.1523/JNEUROSCI.0977-15.2015
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   De Martino F, 2008, NEUROIMAGE, V43, P44, DOI 10.1016/j.neuroimage.2008.06.037
   Drouin JR, 2018, J ACOUST SOC AM, V144, P1089, DOI 10.1121/1.5047672
   Edmister WB, 1999, HUM BRAIN MAPP, V7, P89, DOI 10.1002/(SICI)1097-0193(1999)7:2<89::AID-HBM2>3.3.CO;2-E
   Eisner F, 2006, J ACOUST SOC AM, V119, P1950, DOI 10.1121/1.2178721
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318
   FROST R, 1988, J MEM LANG, V27, P741, DOI 10.1016/0749-596X(88)90018-6
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Gow DW, 2008, NEUROIMAGE, V43, P614, DOI 10.1016/j.neuroimage.2008.07.027
   Hanley JR, 2011, PSYCHON B REV, V18, P355, DOI 10.3758/s13423-010-0043-z
   Hebart MN, 2018, NEUROIMAGE, V180, P4, DOI 10.1016/j.neuroimage.2017.08.005
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Joanisse MF, 2007, CEREB CORTEX, V17, P2084, DOI 10.1093/cercor/bhl124
   Keetels M, 2016, ATTEN PERCEPT PSYCHO, V78, P938, DOI 10.3758/s13414-015-1034-y
   Kilian-Hutten N, 2011, J NEUROSCI, V31, P1715, DOI 10.1523/JNEUROSCI.4572-10.2011
   Kleinschmidt DF, 2019, LANG COGN NEUROSCI, V34, P43, DOI 10.1080/23273798.2018.1500698
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2008, COGNITION, V107, P54, DOI 10.1016/j.cognition.2007.07.013
   Kraljic T, 2008, PSYCHOL SCI, V19, P332, DOI 10.1111/j.1467-9280.2008.02090.x
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   Kraljic T, 2011, COGNITION, V121, P459, DOI 10.1016/j.cognition.2011.08.015
   Kriegstein KV, 2004, NEUROIMAGE, V22, P948, DOI 10.1016/j.neuroimage.2004.02.020
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Leonard MK, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13619
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Liu LD, 2018, COGNITION, V174, P55, DOI 10.1016/j.cognition.2018.01.003
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mumford JA, 2012, NEUROIMAGE, V59, P2636, DOI 10.1016/j.neuroimage.2011.08.076
   Myers EB, 2008, CEREB CORTEX, V18, P278, DOI 10.1093/cercor/bhm053
   Myers EB, 2017, BRAIN LANG, V165, P33, DOI 10.1016/j.bandl.2016.11.001
   Myers EB, 2014, J MEM LANG, V76, P80, DOI 10.1016/j.jml.2014.06.007
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Prabhakaran R, 2006, NEUROPSYCHOLOGIA, V44, P2209, DOI 10.1016/j.neuropsychologia.2006.05.025
   Raizada RDS, 2007, NEURON, V56, P726, DOI 10.1016/j.neuron.2007.11.001
   Riecke L, 2009, NEURON, V64, P550, DOI 10.1016/j.neuron.2009.10.016
   Schall S, 2015, J COGNITIVE NEUROSCI, V27, P280, DOI 10.1162/jocn_a_00707
   Sjerps MJ, 2010, J EXP PSYCHOL HUMAN, V36, P195, DOI 10.1037/a0016803
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   Talairach J, 1988, COPLANAR STEREOTAXIC
   Turkeltaub PE, 2010, BRAIN LANG, V114, P1, DOI 10.1016/j.bandl.2010.03.008
   van Linden S, 2007, J EXP PSYCHOL HUMAN, V33, P1483, DOI 10.1037/0096-1523.33.6.1483
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Yi HG, 2019, NEURON, V102, P1096, DOI 10.1016/j.neuron.2019.04.023
NR 60
TC 0
Z9 0
U1 5
U2 5
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0898-929X
EI 1530-8898
J9 J COGNITIVE NEUROSCI
JI J. Cogn. Neurosci.
PD OCT
PY 2020
VL 32
IS 10
BP 2001
EP 2012
DI 10.1162/jocn_a_01612
PG 12
WC Neurosciences; Psychology, Experimental
SC Neurosciences & Neurology; Psychology
GA NG9FA
UT WOS:000564285000012
PM 32662731
OA Green Published
DA 2021-02-24
ER

PT J
AU Koskinen, M
   Kurimo, M
   Gross, J
   Hyvarinen, A
   Hari, R
AF Koskinen, Miika
   Kurimo, Mikko
   Gross, Joachim
   Hyvarinen, Aapo
   Hari, Riitta
TI Brain activity reflects the predictability of word sequences in listened
   continuous speech
SO NEUROIMAGE
LA English
DT Article
DE Speech perception; Continuous speech; MEG; Language model; N-gram;
   Speech-brain coupling; Naturalistic neuroscience; Cerebral cortex
ID TEMPORAL RECEPTIVE WINDOWS; TURN-TAKING; RESPONSES; OSCILLATIONS;
   ENTRAINMENT; PREDICTION; MECHANISM; HIERARCHY; DYNAMICS; SIGNALS
AB Natural speech builds on contextual relations that can prompt predictions of upcoming utterances. To study the neural underpinnings of such predictive processing we asked 10 healthy adults to listen to a 1-h-long audiobook while their magnetoencephalographic (MEG) brain activity was recorded. We correlated the MEG signals with acoustic speech envelope, as well as with estimates of Bayesian word probability with and without the contextual word sequence (N-gram and Unigram, respectively), with a focus on time-lags. The MEG signals of auditory and sensorimotor cortices were strongly coupled to the speech envelope at the rates of syllables (4-8 Hz) and of prosody and intonation (0.5-2 Hz). The probability structure of word sequences, independently of the acoustical features, affected the <= 2-Hz signals extensively in auditory and rolandic regions, in precuneus, occipital cortices, and lateral and medial frontal regions. Fine-grained temporal progression patterns occurred across brain regions 100-1000 ms after word onsets. Although the acoustic effects were observed in both hemispheres, the contextual influences were statistically significantly lateralized to the left hemisphere. These results serve as a brain signature of the predictability of word sequences in listened continuous speech, confirming and extending previous results to demonstrate that deeply-learned knowledge and recent contextual information are employed dynamically and in a left-hemisphere-dominant manner in predicting the forthcoming words in natural speech.
C1 [Koskinen, Miika] Univ Helsinki, Fac Med, Medicum, POB 63, FI-00014 Helsinki, Finland.
   [Koskinen, Miika; Hari, Riitta] Aalto Univ, Dept Neurosci & Biomed Engn, POB 12200, FI-00076 Aalto, Finland.
   [Koskinen, Miika; Gross, Joachim] Univ Glasgow, Inst Neurosci & Psychol, 58 Hillhead St, Glasgow G12 8QB, Lanark, Scotland.
   [Koskinen, Miika] Aalto Univ, MEG Core, Aalto NeuroImaging, FI-00076 Aalto, Finland.
   [Kurimo, Mikko] Aalto Univ, Dept Signal Proc & Acoust, POB 13000, FI-00076 Aalto, Finland.
   [Gross, Joachim] Univ Munster, Inst Biomagnetism & Biosignalanal, D-48149 Munster, Germany.
   [Hyvarinen, Aapo] Univ Helsinki, Dept Comp Sci, POB 68, FI-00014 Helsinki, Finland.
   [Hari, Riitta] Aalto Univ, Dept Art, POB 31000, FI-00076 Aalto, Finland.
RP Koskinen, M (corresponding author), Aalto Univ, MEG Core, Aalto NeuroImaging, FI-00076 Aalto, Finland.; Koskinen, M (corresponding author), POB 400, Helsinki 00029, Finland.
EM miika.koskinen@hus.fi
RI Kurimo, Mikko/F-6647-2012
OI Hyvarinen, Aapo/0000-0002-5806-4432
FU Jane and Aatos Erkko Foundation; Aalto Brain Center (ABC), Aalto
   University, Finland; Academy of Finland, Center of Excellence in
   Computational Inference [251170]; Wellcome TrustWellcome TrustEuropean
   Commission [098433]; DFGGerman Research Foundation (DFG)European
   Commission [GR 2024/5-1]; Academy of Finland, Centre-of-Excellence in
   Inverse Problems ResearchAcademy of Finland; Academy of Finland,
   Centre-of-Excellence Algorithmic Data AnalysisAcademy of Finland;
   Finnish Cultural Foundation (Eminentia grant)
FX Authors declare no conflict of interest. M. Koskinen was supported by
   Jane and Aatos Erkko Foundation and Aalto Brain Center (ABC), Aalto
   University, Finland. M. Kurimo was supported by Academy of Finland,
   Center of Excellence in Computational Inference (251170). J. Gross was
   supported by the Wellcome Trust (098433) and the DFG (GR 2024/5-1). A.
   Hyv_arinen was supported by Academy of Finland, Centre-of-Excellence in
   Inverse Problems Research and Centre-of-Excellence Algorithmic Data
   Analysis. R. Hari was supported by the Finnish Cultural Foundation
   (Eminentia grant). M. Koskinen acknowledges discussions with Prof. Lauri
   Parkkonen.
CR Armeni K, 2019, NEUROIMAGE, V198, P283, DOI 10.1016/j.neuroimage.2019.04.083
   ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663
   Bourguignon M, 2013, HUM BRAIN MAPP, V34, P314, DOI 10.1002/hbm.21442
   Brennan JR, 2016, BRAIN LANG, V157, P81, DOI 10.1016/j.bandl.2016.04.008
   Brodbeck C, 2018, CURR BIOL, V28, P3976, DOI 10.1016/j.cub.2018.10.042
   Broderick MP, 2018, CURR BIOL, V28, P803, DOI 10.1016/j.cub.2018.01.080
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   Daube C, 2019, CURR BIOL, V29, P1924, DOI 10.1016/j.cub.2019.04.067
   Di Liberto GM, 2019, NEUROIMAGE, V196, P237, DOI 10.1016/j.neuroimage.2019.04.037
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Friston KJ, 2002, PROG NEUROBIOL, V68, P113, DOI 10.1016/S0301-0082(02)00076-X
   Gramfort A, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00267
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   HAMALAINEN MS, 1994, MED BIOL ENG COMPUT, V32, P35, DOI 10.1007/BF02512476
   Hamilton LS, 2020, LANG COGN NEUROSCI, V35, P573, DOI 10.1080/23273798.2018.1499946
   Hari R, 2015, NEURON, V88, P181, DOI 10.1016/j.neuron.2015.09.022
   Hari R, 2015, PHILOS T R SOC B, V370, P93, DOI 10.1098/rstb.2014.0170
   Hari R, 2010, ANN NY ACAD SCI, V1191, P89, DOI 10.1111/j.1749-6632.2010.05438.x
   Hasson U, 2008, J NEUROSCI, V28, P2539, DOI 10.1523/JNEUROSCI.5487-07.2008
   Hirsimaki T, 2006, COMPUT SPEECH LANG, V20, P515, DOI 10.1016/j.csl.2005.07.002
   Hirsimaki T, 2009, IEEE T AUDIO SPEECH, V17, P724, DOI 10.1109/TASL.2008.2012323
   Jaaskelainen IP, 2011, BRAIN RES, V1422, P66, DOI 10.1016/j.brainres.2011.09.031
   Kikuchi Y, 2017, PLOS BIOL, V15, DOI 10.1371/journal.pbio.2000219
   Klimovich-Gray A, 2019, J NEUROSCI, V39, P519, DOI 10.1523/JNEUROSCI.3573-17.2018
   Kosem A, 2018, CURR BIOL, V28, P2867, DOI 10.1016/j.cub.2018.07.023
   Koskinen M, 2014, NEUROIMAGE, V100, P263, DOI 10.1016/j.neuroimage.2014.06.018
   Koskinen M., 2016, BIOMAG2016
   Koskinen M, 2013, HUM BRAIN MAPP, V34, P1477, DOI 10.1002/hbm.22004
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735
   Lalor EC, 2010, EUR J NEUROSCI, V31, P189, DOI 10.1111/j.1460-9568.2009.07055.x
   Lankinen K, 2014, NEUROIMAGE, V92, P217, DOI 10.1016/j.neuroimage.2014.02.004
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532
   Leonard MK, 2015, J NEUROSCI, V35, P7203, DOI 10.1523/JNEUROSCI.4100-14.2015
   Lerner Y, 2011, J NEUROSCI, V31, P2906, DOI 10.1523/JNEUROSCI.3684-10.2011
   Levinson SC, 2016, TRENDS COGN SCI, V20, P6, DOI 10.1016/j.tics.2015.10.010
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Marton Christian D, 2019, eNeuro, V6, DOI 10.1523/ENEURO.0467-18.2019
   MUMFORD D, 1992, BIOL CYBERN, V66, P241, DOI 10.1007/BF00198477
   Nelson MJ, 2017, P NATL ACAD SCI USA, V114, pE3669, DOI 10.1073/pnas.1701590114
   Niesler TR, 1999, COMPUT SPEECH LANG, V13, P99, DOI 10.1006/csla.1998.0115
   Pan S., 1999, P EMNLP VLC 99, P148
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580
   Rommers J, 2017, LANG COGN NEUROSCI, V32, P576, DOI 10.1080/23273798.2016.1183799
   Sassenhagen J, 2019, PSYCHOPHYSIOLOGY, V56, DOI 10.1111/psyp.13335
   Schultz W, 2000, ANNU REV NEUROSCI, V23, P473, DOI 10.1146/annurev.neuro.23.1.473
   Siivola V., 2007, 8 ANN C INT SPEECH C, P1549
   Smith N., 2011, P 33 ANN C COGN SCI, V33, P1637
   Stephens GJ, 2013, J NEUROPHYSIOL, V110, P2019, DOI 10.1152/jn.00268.2013
   Stivers T, 2009, P NATL ACAD SCI USA, V106, P10587, DOI 10.1073/pnas.0903616106
   Summerfield C, 2006, SCIENCE, V314, P1311, DOI 10.1126/science.1132028
   Taulu S, 2004, BRAIN TOPOGR, V16, P269, DOI 10.1023/b:brat.0000032864.93890.f9
   Torrence C, 1998, B AM METEOROL SOC, V79, P61, DOI 10.1175/1520-0477(1998)079<0061:APGTWA>2.0.CO;2
   Willems RM, 2016, CEREB CORTEX, V26, P2506, DOI 10.1093/cercor/bhv075
NR 59
TC 1
Z9 1
U1 5
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD OCT 1
PY 2020
VL 219
AR 116936
DI 10.1016/j.neuroimage.2020.116936
PG 9
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA NA4IL
UT WOS:000559780400014
PM 32474080
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Wedderburn, CJ
   Subramoney, S
   Yeung, SM
   Fouche, JP
   Joshi, SH
   Narr, KL
   Rehman, AM
   Roos, A
   Ipser, J
   Robertson, FC
   Groenewold, NA
   Gibb, DM
   Zar, HJ
   Stein, DJ
   Donald, KA
AF Wedderburn, Catherine J.
   Subramoney, Sivenesi
   Yeung, Shunmay
   Fouche, Jean-Paul
   Joshi, Shantanu H.
   Narr, Katherine L.
   Rehman, Andrea M.
   Roos, Annerine
   Ipser, Jonathan
   Robertson, Frances C.
   Groenewold, Nynke A.
   Gibb, Diana M.
   Zar, Heather J.
   Stein, Dan J.
   Donald, Kirsten A.
TI Neuroimaging young children and associations with neurocognitive
   development in a South African birth cohort study
SO NEUROIMAGE
LA English
DT Article
DE Neuroimaging; Children; Africa; Cortical surface area; Cortical
   thickness; Cognition
ID HUMAN CEREBRAL-CORTEX; BRAIN WHITE-MATTER; CORTICAL THICKNESS;
   EARLY-CHILDHOOD; PROTECTIVE FACTORS; SPEECH-PERCEPTION; GRAY-MATTER; NIH
   MRI; SEDATION; SEGMENTATION
AB Magnetic resonance imaging (MRI) is an indispensable tool for investigating brain development in young children and the neurobiological mechanisms underlying developmental risk and resilience. Sub-Saharan Africa has the highest proportion of children at risk of developmental delay worldwide, yet in this region there is very limited neuroimaging research focusing on the neurobiology of such impairment. Furthermore, paediatric MRI imaging is challenging in any setting due to motion sensitivity. Although sedation and anesthesia are routinely used in clinical practice to minimise movement in young children, this may not be ethical in the context of research. Our study aimed to investigate the feasibility of paediatric multimodal MRI at age 2-3 years without sedation, and to explore the relationship between cortical structure and neurocognitive development at this understudied age in a sub-Saharan African setting. A total of 239 children from the Drakenstein Child Health Study, a large observational South African birth cohort, were recruited for neuroimaging at 2-3 years of age. Scans were conducted during natural sleep utilising locally developed techniques. T1-MEMPRAGE and T2-weighted structural imaging, resting state functional MRI, diffusion tensor imaging and magnetic resonance spectroscopy sequences were included. Child neurodevelopment was assessed using the Bayley-III Scales of Infant and Toddler Development. Following 23 pilot scans, 216 children underwent scanning and T1-weighted images were obtained from 167/216 (77%) of children (median age 34.8 months). Furthermore, we found cortical surface area and thickness within frontal regions were associated with cognitive development, and in temporal and frontal regions with language development (beta coefficient >= 0.20). Overall, we demonstrate the feasibility of carrying out a neuroimaging study of young children during natural sleep in sub-Saharan Africa. Our findings indicate that dynamic morphological changes in heteromodal association regions are associated with cognitive and language development at this young age. These proof-of-concept analyses suggest similar links between the brain and cognition as prior literature from high income countries, enhancing understanding of the interplay between cortical structure and function yyduring brain maturation.
C1 [Wedderburn, Catherine J.; Subramoney, Sivenesi; Roos, Annerine; Zar, Heather J.; Donald, Kirsten A.] Univ Cape Town, Dept Paediat & Child Hlth, Red Cross War Mem Childrens Hosp, Rondebosch, South Africa.
   [Wedderburn, Catherine J.; Yeung, Shunmay] London Sch Hyg & Trop Med, Dept Clin Res, London WC1E 7HT, England.
   [Wedderburn, Catherine J.; Roos, Annerine; Ipser, Jonathan; Groenewold, Nynke A.; Stein, Dan J.; Donald, Kirsten A.] Univ Cape Town, Neurosci Inst, Rondebosch, South Africa.
   [Fouche, Jean-Paul; Ipser, Jonathan; Groenewold, Nynke A.; Stein, Dan J.] Univ Cape Town, Dept Psychiat, Rondebosch, South Africa.
   [Joshi, Shantanu H.; Narr, Katherine L.] Univ Calif Los Angeles, Dept Neurol Psychiat & Biobehav Sci, Los Angeles, CA 90024 USA.
   [Joshi, Shantanu H.; Narr, Katherine L.] Univ Calif Los Angeles, Dept Psychiat, Los Angeles, CA 90024 USA.
   [Joshi, Shantanu H.; Narr, Katherine L.] Univ Calif Los Angeles, Dept Biobehav Sci, Los Angeles, CA 90024 USA.
   [Rehman, Andrea M.] London Sch Hyg & Tropical Med, MRC Tropical Epidemiol Grp, London, England.
   [Roos, Annerine] Stellenbosch Univ, Dept Psychiat, SU UCT MRC Unit Risk & Resilience Mental Disorder, Stellenbosch, South Africa.
   [Robertson, Frances C.] Univ Cape Town, Dept Human Biol, Div Biomed Engn, Rondebosch, South Africa.
   [Robertson, Frances C.] Cape Univ Brain Imaging Ctr CUBIC, Cape Town, South Africa.
   [Gibb, Diana M.] UCL, MRC Clin Trials Unit, London, England.
   [Zar, Heather J.] Univ Cape Town, SAMRC Unit Child & Adolescent Hlth, Rondebosch, South Africa.
   [Zar, Heather J.] Univ Cape Town, SU UCT MRC Unit Risk & Resilience Mental Disorder, Rondebosch, South Africa.
RP Wedderburn, CJ (corresponding author), London Sch Hyg & Trop Med, Dept Clin Res, London WC1E 7HT, England.
EM catherine.wedderburn@lshtm.ac.uk
RI Donald, Kirsten A/H-9328-2015; Stein, Dan J/A-1752-2008; Rehman,
   Andrea/H-1351-2015
OI Donald, Kirsten A/0000-0002-0276-9660; Stein, Dan J/0000-0001-7218-7810;
   Gibb, Diana/0000-0002-9738-5490; Ipser, Jonathan/0000-0003-1272-0032;
   Rehman, Andrea/0000-0001-9967-5822; Zar, Heather/0000-0002-9046-759X;
   Yeung, Shunmay/0000-0002-0997-0850
FU Bill and Melinda Gates FoundationBill & Melinda Gates Foundation [OPP
   1017641]; Medical Research Council of South AfricaUK Research &
   Innovation (UKRI)Medical Research Council UK (MRC); Wellcome
   TrustWellcome TrustEuropean Commission [203525/Z/16/Z]; NRF, an Academy
   of Medical Sciences Newton Advanced Fellowship - UK Government's Newton
   Fund [NAF002/1001]; NIAAAUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Alcohol Abuse & Alcoholism (NIAAA) [R21AA023887]; Collaborative
   Initiative on Fetal Alcohol Spectrum Disorders (CIFASD) developmental
   grant [U24 AA014811]; US Brain and Behaviour Foundation Independent
   Investigator grant [24467]; UK Medical Research Council (MRC)UK Research
   & Innovation (UKRI)Medical Research Council UK (MRC); UK Department for
   International Development (DFID) under the MRC/DFID Concordat agreement,
   EDCTP2 programme - European UnionUK Research & Innovation (UKRI)Medical
   Research Council UK (MRC) [MR/R010161/1]
FX The DCHS study is funded by the Bill and Melinda Gates Foundation [OPP
   1017641]. Additional support for HJZ and DJS by the Medical Research
   Council of South Africa. CJW is supported by the Wellcome Trust through
   a Research Training Fellowship [203525/Z/16/Z]. KAD and aspects of the
   research are additionally supported by the NRF, an Academy of Medical
   Sciences Newton Advanced Fellowship (NAF002/1001) funded by the UK
   Government's Newton Fund, by NIAAA via (R21AA023887), by the
   Collaborative Initiative on Fetal Alcohol Spectrum Disorders (CIFASD)
   developmental grant (U24 AA014811), and by the US Brain and Behaviour
   Foundation Independent Investigator grant (24467). AMR is additionally
   supported by the UK Medical Research Council (MRC) and the UK Department
   for International Development (DFID) under the MRC/DFID Concordat
   agreement which is also part of the EDCTP2 programme supported by the
   European Union grant reference (MR/R010161/1).
CR Abdelgadir IS, 2018, ARCH DIS CHILD, V103, P1155, DOI 10.1136/archdischild-2017-314181
   Acock A.C., 2014, GENTLE INTRO STATA
   Albers CA, 2007, J PSYCHOEDUC ASSESS, V25, P180, DOI 10.1177/0734282906297199
   Almli CR, 2007, NEUROIMAGE, V35, P308, DOI 10.1016/j.neuroimage.2006.08.058
   Azhari A, 2020, INFANT BEHAV DEV, V58, DOI 10.1016/j.infbeh.2019.101389
   Ballot DE, 2012, BMC PEDIATR, V12, DOI 10.1186/1471-2431-12-11
   Barkovich MJ, 2019, NEUROIMAGE, V185, P793, DOI 10.1016/j.neuroimage.2018.04.044
   Bates E, 1999, CHANGING NERVOUS SYSTEM, P214
   Bayley N., 2006, BAYLEY SCALES INFANT
   Black MM, 2017, LANCET, V389, P77, DOI 10.1016/S0140-6736(16)31389-7
   Brito NH, 2017, BRAIN COGNITION, V116, P54, DOI 10.1016/j.bandc.2017.03.007
   Burgaleta M, 2014, NEUROIMAGE, V84, P810, DOI 10.1016/j.neuroimage.2013.09.038
   Cote CJ, 2000, PEDIATRICS, V105, P805, DOI 10.1542/peds.105.4.805
   Daelmans B, 2017, LANCET, V389, P9, DOI 10.1016/S0140-6736(16)31659-2
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   Dean DC, 2014, PEDIATR RADIOL, V44, P64, DOI 10.1007/s00247-013-2752-8
   Dehaene-Lambertz G, 2010, BRAIN LANG, V114, P53, DOI 10.1016/j.bandl.2009.09.003
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   Deoni SCL, 2015, NEUROIMAGE, V115, P147, DOI 10.1016/j.neuroimage.2015.04.058
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   DiMaggio C, 2011, ANESTH ANALG, V113, P1143, DOI 10.1213/ANE.0b013e3182147f42
   Donald KA, 2015, ACTA NEUROPSYCHIATR, V27, P197, DOI 10.1017/neu.2015.35
   Dubois J, 2014, NEUROSCIENCE, V276, P48, DOI 10.1016/j.neuroscience.2013.12.044
   Edwards AD, 2011, PEDIATR RADIOL, V41, P1353, DOI 10.1007/s00247-011-2147-7
   Elliott R, 2000, CEREB CORTEX, V10, P308, DOI 10.1093/cercor/10.3.308
   Every Woman Every Child, 2015, GLOB STRAT WOM CHILD
   Fischl B, 2004, NEUROIMAGE, V23, pS69, DOI 10.1016/j.neuroimage.2004.07.016
   Fischl B, 2002, NEURON, V33, P341, DOI 10.1016/S0896-6273(02)00569-X
   Fischl B, 2000, P NATL ACAD SCI USA, V97, P11050, DOI 10.1073/pnas.200033797
   Gao W, 2019, NEUROIMAGE, V185, P802, DOI 10.1016/j.neuroimage.2018.04.032
   Gilmore JH, 2018, NAT REV NEUROSCI, V19, P123, DOI 10.1038/nrn.2018.1
   Gilmore JH, 2012, CEREB CORTEX, V22, P2478, DOI 10.1093/cercor/bhr327
   Girault JB, 2020, CEREB CORTEX, V30, P786, DOI 10.1093/cercor/bhz126
   Hatton S., 2019, NEUROIMAGE
   Hermoye L, 2006, NEUROIMAGE, V29, P493, DOI 10.1016/j.neuroimage.2005.08.017
   Ibekwe R, 2017, SEIZURE-EUR J EPILEP, V51, P87, DOI 10.1016/j.seizure.2017.08.002
   Imada T, 2006, NEUROREPORT, V17, P957, DOI 10.1097/01.wnr.0000223387.51704.89
   Ines ML, 2018, EARLY HUM DEV, V116, P53, DOI 10.1016/j.earlhumdev.2017.11.003
   Jahanshad N, 2015, PEDIATR INFECT DIS J, V34, pE211, DOI 10.1097/INF.0000000000000774
   Jaimes C, 2016, PEDIATR RADIOL, V46, P916, DOI 10.1007/s00247-016-3613-z
   Jansen PR, 2017, NEW ENGL J MED, V377, P1593, DOI 10.1056/NEJMc1710724
   Jevtovic-Todorovic V, 2013, BRIT J ANAESTH, V111, P143, DOI 10.1093/bja/aet177
   Johnson K, 2002, CLIN RADIOL, V57, P502, DOI 10.1053/crad.2001.0923
   Knickmeyer RC, 2008, J NEUROSCI, V28, P12176, DOI 10.1523/JNEUROSCI.3479-08.2008
   Lyall AE, 2015, CEREB CORTEX, V25, P2204, DOI 10.1093/cercor/bhu027
   Maxfield C.M., 2019, RADIOLOGY GLOBAL HLT, P225
   McDonald S, 2016, RES DEV DISABIL, V58, P20, DOI 10.1016/j.ridd.2016.08.010
   Morita T, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00464
   Myer L, 2008, SOC SCI MED, V66, P1828, DOI 10.1016/j.socscimed.2008.01.025
   Narr KL, 2007, CEREB CORTEX, V17, P2163, DOI 10.1093/cercor/bhl125
   Natu VS, 2019, P NATL ACAD SCI USA, V116, P20750, DOI 10.1073/pnas.1904931116
   Nieminen P, 2013, EPIDEMIOL BIOSTAT PU, V10, DOI 10.2427/8854
   Nwosu EC, 2018, METAB BRAIN DIS, V33, P523, DOI 10.1007/s11011-017-0162-6
   O'Muircheartaigh J, 2014, HUM BRAIN MAPP, V35, P4475, DOI 10.1002/hbm.22488
   Ouyang MH, 2019, NEUROIMAGE, V185, P836, DOI 10.1016/j.neuroimage.2018.04.017
   Paterson SJ, 2006, NEUROSCI BIOBEHAV R, V30, P1087, DOI 10.1016/j.neubiorev.2006.05.001
   Porter JN, 2011, NEUROIMAGE, V55, P1865, DOI 10.1016/j.neuroimage.2011.01.018
   Rademeyer V, 2013, S AFR J CHILD HEALTH, V7, P54, DOI 10.7196/SAJCH.547
   Raschle N, 2012, ANN NY ACAD SCI, V1252, P43, DOI 10.1111/j.1749-6632.2012.06457.x
   Remer J, 2017, NEUROIMAGE, V153, P246, DOI 10.1016/j.neuroimage.2017.04.010
   Ronan L, 2020, CEREB CORTEX, V30, P2519, DOI 10.1093/cercor/bhz257
   Sammons HM, 2011, ARCH DIS CHILD, V96, P114, DOI 10.1136/adc.2010.185256
   Sawilowsky SS, 2009, J MOD APPL STAT METH, V8, P597, DOI 10.22237/jmasm/1257035100
   Schmidt Matthias H, 2011, IRB, V33, P1
   Shaw P, 2006, NATURE, V440, P676, DOI 10.1038/nature04513
   Sowell ER, 2003, NAT NEUROSCI, V6, P309, DOI 10.1038/nn1008
   Stats SA, 2016, STAT RELEASE RECORDE
   Stein DJ, 2015, J NEUROSCI METH, V252, P27, DOI 10.1016/j.jneumeth.2015.03.016
   Thieba C, 2018, FRONT PEDIATR, V6, DOI 10.3389/fped.2018.00146
   Tomlinson M, 2014, INFANT MENT HEALTH J, V35, P624, DOI 10.1002/imhj.21462
   Tran LT, 2016, MEDICINE, V95, DOI 10.1097/MD.0000000000002577
   VASSILEVGALINDO V, 2018, BMJ PAEDIAT OPEN, V2, DOI DOI 10.1038/S41570-018-0114
   Voevodskaya O, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00264
   Walker L, 2016, NEUROIMAGE, V124, P1125, DOI 10.1016/j.neuroimage.2015.05.083
   Walker SP, 2011, LANCET, V378, P1325, DOI 10.1016/S0140-6736(11)60555-2
   Walton M, 2018, BRAIN LANG, V176, P19, DOI 10.1016/j.bandl.2017.10.008
   Wang F, 2019, P NATL ACAD SCI USA, V116, P15855, DOI 10.1073/pnas.1821523116
   Weiss-Croft LJ, 2015, NEUROIMAGE, V123, P269, DOI 10.1016/j.neuroimage.2015.07.046
   Wierenga LM, 2018, HUM BRAIN MAPP, V39, P157, DOI 10.1002/hbm.23833
   Zar HJ, 2015, THORAX, V70, P592, DOI 10.1136/thoraxjnl-2014-206242
NR 80
TC 2
Z9 2
U1 11
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD OCT 1
PY 2020
VL 219
AR 116846
DI 10.1016/j.neuroimage.2020.116846
PG 10
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA NA4IL
UT WOS:000559780400012
PM 32304884
OA DOAJ Gold, Green Published, Green Accepted
DA 2021-02-24
ER

PT J
AU Stefanou, ME
   Dundon, NM
   Bestelmeyer, PEG
   Ioannou, C
   Bender, S
   Biscaldi, M
   Smyrnis, N
   Klein, C
AF Stefanou, Maria Elena
   Dundon, Neil M.
   Bestelmeyer, Patricia E. G.
   Ioannou, Chara
   Bender, Stephan
   Biscaldi, Monica
   Smyrnis, Nikolaos
   Klein, Christoph
TI Late attentional processes potentially compensate for early perceptual
   multisensory integration deficits in children with autism: evidence from
   evoked potentials
SO SCIENTIFIC REPORTS
LA English
DT Article
ID AUDITORY-VISUAL INTEGRATION; BILATERAL STIMULUS ARRAYS; INDEX FOCUSED
   ATTENTION; FUNCTIONAL CONNECTIVITY; SPECTRUM DISORDERS;
   SHIFTING-DEFICITS; SPEECH-PERCEPTION; HUMANS; WINDOW; MODEL
AB Sensory processing deficits and altered long-range connectivity putatively underlie Multisensory Integration (MSI) deficits in Autism Spectrum Disorder (ASD). The present study set out to investigate non-social MSI stimuli and their electrophysiological correlates in young neurotypical adolescents and adolescents with ASD. We report robust MSI effects at behavioural and electrophysiological levels. Both groups demonstrated normal behavioural MSI. However, at the neurophysiological level, the ASD group showed less MSI-related reduction of the visual P100 latency, greater MSI-related slowing of the auditory P200 and an overall temporally delayed and spatially constrained onset of MSI. Given the task design and patient sample, and the age of our participants, we argue that electro-cortical indices of MSI deficits in ASD: (a) can be detected in early-adolescent ASD, (b) occur at early stages of perceptual processing, (c) can possibly be compensated by later attentional processes, (d) thus leading to normal MSI at the behavioural level.
C1 [Stefanou, Maria Elena; Dundon, Neil M.; Ioannou, Chara; Biscaldi, Monica; Klein, Christoph] Univ Freiburg, Med Fac, Dept Child & Adolescent Psychiat Psychotherapy &, Hauptstr 8, D-79104 Freiburg, Germany.
   [Stefanou, Maria Elena] Univ Reading, Sch Psychol & Clin Language Sci, Reading RG6 6AL, Berks, England.
   [Dundon, Neil M.] Univ Calif Santa Barbara, Brain Imaging Ctr, Dept Psychol & Brain Sci, Santa Barbara, CA 93106 USA.
   [Bestelmeyer, Patricia E. G.] Bangor Univ, Sch Psychol, Bangor LL57 2AS, Gwynedd, Wales.
   [Bender, Stephan; Klein, Christoph] Univ Cologne, Med Fac, Dept Child & Adolescent Psychiat, D-50931 Cologne, Germany.
   [Smyrnis, Nikolaos; Klein, Christoph] Natl & Kapodistrian Univ Athens, Eginit Hosp, Med Sch, Dept Psychiat, Athens 11528, Greece.
RP Klein, C (corresponding author), Univ Freiburg, Med Fac, Dept Child & Adolescent Psychiat Psychotherapy &, Hauptstr 8, D-79104 Freiburg, Germany.; Klein, C (corresponding author), Univ Cologne, Med Fac, Dept Child & Adolescent Psychiat, D-50931 Cologne, Germany.; Klein, C (corresponding author), Natl & Kapodistrian Univ Athens, Eginit Hosp, Med Sch, Dept Psychiat, Athens 11528, Greece.
EM christoph.klein.kjp@uniklinik-freiburg.de
OI Stefanou, Maria Elena/0000-0001-6469-2876
FU graduate scholarship "State Law on Graduate Funding (LGFG)" of
   Albert-Ludwigs-Universitat Freiburg
FX M.E.S acknowledges the support of the graduate scholarship "State Law on
   Graduate Funding (LGFG)" of Albert-Ludwigs-Universitat Freiburg. This
   study is part of the doctoral dissertation of M.E.S, "Deficits in Social
   Cognition in Autism Spectrum Disorders and their Electro-Cortical
   Correlates: A Multisensory Integration perspective".
CR American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   [Anonymous], 1994, J Clin Neurophysiol, V11, P111
   Bahrick L. E, 2012, NEW HDB MULTISENSORY, P657
   Bair WN, 2007, EXP BRAIN RES, V183, P435, DOI 10.1007/s00221-007-1057-2
   Bao VA, 2017, J AUTISM DEV DISORD, V47, P2535, DOI 10.1007/s10803-017-3172-7
   Beker S, 2018, NEUROSCI BIOBEHAV R, V84, P182, DOI 10.1016/j.neubiorev.2017.11.008
   Belmonte M. K., 2000, AUTISM, V4, P269, DOI DOI 10.1177/1362361300004003004
   Belmonte MK, 2004, J NEUROSCI, V24, P9228, DOI 10.1523/JNEUROSCI.3340-04.2004
   Bolte S., 2005, DIAGNOSTISCHES INTER
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Brandwein AB, 2015, J AUTISM DEV DISORD, V45, P230, DOI 10.1007/s10803-014-2212-9
   Brandwein AB, 2013, CEREB CORTEX, V23, P1329, DOI 10.1093/cercor/bhs109
   Brandwein AB, 2011, CEREB CORTEX, V21, P1042, DOI 10.1093/cercor/bhq170
   Brefczynski-Lewis J, 2009, BRAIN TOPOGR, V21, P193, DOI 10.1007/s10548-009-0093-6
   Brett-Green BA, 2008, BRAIN RES, V1242, P283, DOI 10.1016/j.brainres.2008.03.090
   Charbonneau G, 2013, NEUROPSYCHOLOGIA, V51, P1002, DOI 10.1016/j.neuropsychologia.2013.02.009
   Collignon O, 2013, CORTEX, V49, P1704, DOI 10.1016/j.cortex.2012.06.001
   Constantino J., 2005, SOCIAL RESPONSIVENES
   Crowley KE, 2004, CLIN NEUROPHYSIOL, V115, P732, DOI 10.1016/j.clinph.2003.11.021
   de Boer-Schellekens L, 2013, NEUROPSYCHOLOGIA, V51, P3004, DOI 10.1016/j.neuropsychologia.2013.10.005
   Desjardins JA, 2013, J VISION, V13, DOI 10.1167/13.5.22
   Doesburg SM, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00791
   Dopfner M, 2008, DIAGNOSTIK SYSTEM PS
   Dundon NM, 2015, RESTOR NEUROL NEUROS, V33, P405, DOI 10.3233/RNN-140457
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   Giard MH, 1999, J COGNITIVE NEUROSCI, V11, P473, DOI 10.1162/089892999563544
   Gomot M, 2008, BRAIN, V131, P2479, DOI 10.1093/brain/awn172
   Gondan M, 2016, ATTEN PERCEPT PSYCHO, V78, P723, DOI 10.3758/s13414-015-1018-y
   HEINZE HJ, 1990, ELECTROEN CLIN NEURO, V75, P511, DOI 10.1016/0013-4694(90)90138-A
   Hillyard SA, 1998, PHILOS T ROY SOC B, V353, P1257, DOI 10.1098/rstb.1998.0281
   Hornix BE, 2019, NEUROSCI BIOBEHAV R, V97, P138, DOI 10.1016/j.neubiorev.2018.02.010
   Hughes JR, 2009, EPILEPSY BEHAV, V16, P569, DOI 10.1016/j.yebeh.2009.09.023
   Jessen S, 2011, NEUROIMAGE, V58, P665, DOI 10.1016/j.neuroimage.2011.06.035
   Kern JK, 2007, RES AUTISM SPECT DIS, V1, P185, DOI 10.1016/j.rasd.2006.09.002
   KINGSTONE A, 1993, PERCEPT PSYCHOPHYS, V54, P260, DOI 10.3758/BF03211762
   Kleiner M, 2007, PERCEPTION, V36, P14
   Kleinhans NM, 2008, BRAIN, V131, P1000, DOI 10.1093/brain/awm334
   Kleinhans NM, 2011, NEUROIMAGE, V54, P697, DOI 10.1016/j.neuroimage.2010.07.037
   Koelewijn T, 2010, ACTA PSYCHOL, V134, P372, DOI 10.1016/j.actpsy.2010.03.010
   Kujala T, 2013, NEUROSCI BIOBEHAV R, V37, P697, DOI 10.1016/j.neubiorev.2013.01.006
   Kwakye LD, 2011, FRONT INTEGR NEUROSC, V4, DOI 10.3389/fnint.2010.00129
   Lijffijt M, 2009, PSYCHOPHYSIOLOGY, V46, P1059, DOI 10.1111/j.1469-8986.2009.00845.x
   Luck S. J., 2005, INTRO EVENT RELATED
   LUCK SJ, 1990, ELECTROEN CLIN NEURO, V75, P528, DOI 10.1016/0013-4694(90)90139-B
   Macaluso E, 2005, TRENDS NEUROSCI, V28, P264, DOI 10.1016/j.tins.2005.03.008
   MANGUN GR, 1995, PSYCHOPHYSIOLOGY, V32, P4, DOI 10.1111/j.1469-8986.1995.tb03400.x
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Maris E, 2012, PSYCHOPHYSIOLOGY, V49, P549, DOI 10.1111/j.1469-8986.2011.01320.x
   Martinez-Sanchis S., 2014, FRONT HUM NEUROSCI, V8, P1
   MEREDITH MA, 1983, SCIENCE, V221, P389, DOI 10.1126/science.6867718
   Miller HL, 2015, J AUTISM DEV DISORD, V45, P805, DOI 10.1007/s10803-014-2244-1
   MILLER J, 1982, COGNITIVE PSYCHOL, V14, P247, DOI 10.1016/0010-0285(82)90010-X
   Molholm S, 2002, COGNITIVE BRAIN RES, V14, P115, DOI 10.1016/S0926-6410(02)00066-6
   Mongillo EA, 2008, J AUTISM DEV DISORD, V38, P1349, DOI 10.1007/s10803-007-0521-y
   Fernandez LM, 2015, NEUROIMAGE, V119, P272, DOI 10.1016/j.neuroimage.2015.06.052
   Murray MM, 2016, NEUROPSYCHOLOGIA, V83, P161, DOI 10.1016/j.neuropsychologia.2015.08.011
   O'Connor K, 2012, NEUROSCI BIOBEHAV R, V36, P836, DOI 10.1016/j.neubiorev.2011.11.008
   Panagiotidi M, 2017, ACTA PSYCHOL, V181, P10, DOI 10.1016/j.actpsy.2017.10.001
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Poppel E, 1997, TRENDS COGN SCI, V1, P56, DOI 10.1016/S1364-6613(97)01008-5
   Poustka L., 2015, DIAGNOSTISCHE BEOBAC, V2
   RIF J, 1991, ELECTROEN CLIN NEURO, V79, P464, DOI 10.1016/0013-4694(91)90166-2
   Rommelse NNJ, 2010, EUR CHILD ADOLES PSY, V19, P281, DOI 10.1007/s00787-010-0092-x
   Ruhl D., 2004, DIAGNOSTISCHE BEOBAC
   Russo N, 2010, AUTISM RES, V3, P253, DOI 10.1002/aur.152
   Santangelo V, 2008, EXP BRAIN RES, V185, P269, DOI 10.1007/s00221-007-1151-5
   Senkowski D, 2011, NEUROIMAGE, V56, P2200, DOI 10.1016/j.neuroimage.2011.03.075
   Stefanou ME, 2019, BIOL PSYCHOL, V142, P132, DOI 10.1016/j.biopsycho.2019.01.011
   Stefanou M. E., 2019, DEFICITS SOCIAL COGN
   Stein BE, 2008, NAT REV NEUROSCI, V9, P255, DOI 10.1038/nrn2331
   Stevenson RA, 2014, J AUTISM DEV DISORD, V44, P1470, DOI 10.1007/s10803-013-1992-7
   Tavassoli T, 2014, AUTISM, V18, P428, DOI 10.1177/1362361313477246
   Tomasi D, 2019, CEREB CORTEX, V29, P573, DOI 10.1093/cercor/bhx340
   Ulrich R, 2007, BEHAV RES METHODS, V39, P291, DOI 10.3758/BF03193160
   van der Smagt MJ, 2007, J AUTISM DEV DISORD, V37, P2014, DOI 10.1007/s10803-006-0346-0
   van Rijn S, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020292
   Villalobos ME, 2005, NEUROIMAGE, V25, P916, DOI 10.1016/j.neuroimage.2004.12.022
   Weiss H. R., 2006, GRUNDINTELLIGENZTEST
   World Health Organization, 2004, ICD 10 INT STAT CLAS, V2nd
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
   Yerys BE, 2009, AUTISM, V13, P523, DOI 10.1177/1362361309335716
NR 81
TC 0
Z9 0
U1 3
U2 3
PU NATURE RESEARCH
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD SEP 30
PY 2020
VL 10
IS 1
AR 16157
DI 10.1038/s41598-020-73022-2
PG 13
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA NZ6JT
UT WOS:000577212800068
PM 32999327
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Signoret, C
   Andersen, LM
   Dahlstrom, O
   Blomberg, R
   Lundqvist, D
   Rudner, M
   Ronnberg, J
AF Signoret, Carine
   Andersen, Lau M.
   Dahlstrom, Orjan
   Blomberg, Rina
   Lundqvist, Daniel
   Rudner, Mary
   Ronnberg, Jerker
TI The Influence of Form- and Meaning-Based Predictions on Cortical Speech
   Processing Under Challenging Listening Conditions: A MEG Study
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE speech perception; MEG; predictability; working memory; semantic
   knowledge; phonological knowledge
ID LANGUAGE COMPREHENSION; WORKING-MEMORY; INDIVIDUAL-DIFFERENCES;
   AUDITORY-CORTEX; PHONEME REPRESENTATIONS; MISMATCH NEGATIVITY; PERCEIVED
   CLARITY; TEMPORAL CORTEX; BRAIN; HEARING
AB Under adverse listening conditions, prior linguistic knowledge about the form (i.e., phonology) and meaning (i.e., semantics) help us to predict what an interlocutor is about to say. Previous research has shown that accurate predictions of incoming speech increase speech intelligibility, and that semantic predictions enhance the perceptual clarity of degraded speech even when exact phonological predictions are possible. In addition, working memory (WM) is thought to have specific influence over anticipatory mechanisms by actively maintaining and updating the relevance of predicted vs. unpredicted speech inputs. However, the relative impact on speech processing of deviations from expectations related to form and meaning is incompletely understood. Here, we use MEG to investigate the cortical temporal processing of deviations from the expected form and meaning of final words during sentence processing. Our overall aim was to observe how deviations from the expected form and meaning modulate cortical speech processing under adverse listening conditions and investigate the degree to which this is associated with WM capacity. Results indicated that different types of deviations are processed differently in the auditory N400 and Mismatch Negativity (MMN) components. In particular, MMN was sensitive to the type of deviation (form or meaning) whereas the N400 was sensitive to the magnitude of the deviation rather than its type. WM capacity was associated with the ability to process phonological incoming information and semantic integration.
C1 [Signoret, Carine; Dahlstrom, Orjan; Blomberg, Rina; Rudner, Mary; Ronnberg, Jerker] Linkoping Univ, Linnaeus Ctr HEAD, Swedish Inst Disabil Res, Dept Behav Sci & Learning, Linkoping, Sweden.
   [Andersen, Lau M.; Lundqvist, Daniel] Karolinska Inst, Natl Res Facil Magnetoencephalog, Dept Clin Neurosci, Solna, Sweden.
   [Andersen, Lau M.] Aarhus Univ, Ctr Functionally Integrat Neurosci, Inst Clin Med, Aarhus, Denmark.
   [Signoret, Carine] Linkoping Univ, Dept Behav Sci & Learning IBL, Disabil Res Div, Swedish Inst Disabil Res, Linkoping, Sweden.
RP Signoret, C (corresponding author), Linkoping Univ, Linnaeus Ctr HEAD, Swedish Inst Disabil Res, Dept Behav Sci & Learning, Linkoping, Sweden.; Signoret, C (corresponding author), Linkoping Univ, Dept Behav Sci & Learning IBL, Disabil Res Div, Swedish Inst Disabil Res, Linkoping, Sweden.
EM carine.signoret@liu.se
RI Rudner, Mary/S-2006-2019; Rudner, Mary/AAF-7808-2021
OI Rudner, Mary/0000-0001-8722-8232; Andersen, Lau
   Moller/0000-0001-7323-0614
FU Swedish Research CouncilSwedish Research CouncilEuropean Commission
   [2017-06092]; Knut and Alice WallenbergKnut & Alice Wallenberg
   Foundation [KAW 2011.0207]
FX This work was supported by grant no. 2017-06092 from the Swedish
   Research Council. The NatMEG facility was supported by Knut and Alice
   Wallenberg (KAW 2011.0207).
CR Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   AKERSTEDT T, 1990, INT J NEUROSCI, V52, P29, DOI 10.3109/00207459008994241
   ANSI, 2004, S3 21 2004 METH MAN
   Bar M, 2007, TRENDS COGN SCI, V11, P280, DOI 10.1016/j.tics.2007.05.005
   Besser J, 2013, TRENDS AMPLIF, V17, P75, DOI 10.1177/1084713813495459
   Brouwer H, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00758
   Chen Q, 2015, COGNITIVE SCI, V39, P538, DOI 10.1111/cogs.12156
   Chen Q, 2012, PSYCHOL REV, V119, P417, DOI 10.1037/a0027175
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477
   Corps RE, 2020, J MEM LANG, V113, DOI 10.1016/j.jml.2020.104114
   Daltrozzo J, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020273
   DANEMAN M, 1980, J VERB LEARN VERB BE, V19, P450, DOI 10.1016/S0022-5371(80)90312-6
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x
   Friston KJ, 2012, INT J PSYCHOPHYSIOL, V83, P248, DOI 10.1016/j.ijpsycho.2011.11.014
   Friston KJ, 2009, TRENDS COGN SCI, V13, P293, DOI 10.1016/j.tics.2009.04.005
   Green D. M., 1974, SIGNAL DETECTION THE
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hill T., 2005, STAT METHODS APPL
   Ito A, 2018, J MEM LANG, V98, P1, DOI 10.1016/j.jml.2017.09.002
   Ito A, 2016, J MEM LANG, V86, P157, DOI 10.1016/j.jml.2015.10.007
   Khalfa S, 2001, NEUROSCIENCE, V104, P347, DOI 10.1016/S0306-4522(01)00072-0
   Kim AE, 2018, J EXP PSYCHOL LEARN, V44, P406, DOI 10.1037/xlm0000457
   Kuperberg GR, 2020, J COGNITIVE NEUROSCI, V32, P12, DOI 10.1162/jocn_a_01465
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299
   KUTAS M, 1980, BIOL PSYCHOL, V11, P99, DOI 10.1016/0301-0511(80)90046-0
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Lau E, 2009, BRAIN LANG, V111, P161, DOI 10.1016/j.bandl.2009.08.007
   Lau EF, 2013, J NEUROSCI, V 33, P17174, DOI 10.1523/JNEUROSCI.1018-13.2013
   Luke SG, 2016, COGNITIVE PSYCHOL, V88, P22, DOI 10.1016/j.cogpsych.2016.06.002
   MacMillan N. A., 2005, DETECTION THEORY USE
   Maess B, 2006, BRAIN RES, V1096, P163, DOI 10.1016/j.brainres.2006.04.037
   Maess B, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00591
   Makeig S, 1996, ADV NEUR IN, V8, P145
   Malmberg B., 1970, MANUAL OF PHONETICS
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MILLER GA, 1951, J EXP PSYCHOL, V41, P329, DOI 10.1037/h0062491
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Nieuwland MS, 2020, PHILOS T R SOC B, V375, DOI 10.1098/rstb.2018.0522
   Nieuwland MS, 2019, NEUROSCI BIOBEHAV R, V96, P367, DOI 10.1016/j.neubiorev.2018.11.019
   Nieuwland MS, 2018, ELIFE, V7, DOI 10.7554/eLife.33468
   Obleser J, 2007, J NEUROSCI, V27, P2283, DOI 10.1523/JNEUROSCI.4663-06.2007
   Obleser J, 2010, CEREB CORTEX, V20, P633, DOI 10.1093/cercor/bhp128
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Peelle JE, 2018, EAR HEARING, V39, P204, DOI 10.1097/AUD.0000000000000494
   Poeppel D, 1997, NEUROSCI LETT, V221, P145, DOI 10.1016/S0304-3940(97)13325-0
   Rogers CS, 2012, PSYCHOL AGING, V27, P33, DOI 10.1037/a0026231
   RONNBERG J, 1989, J SPEECH HEAR RES, V32, P725, DOI 10.1044/jshr.3204.725
   Ronnberg J., J SPEECH LANG HEAR R
   Ronnberg J, 2019, INT J AUDIOL, V58, P247, DOI 10.1080/14992027.2018.1551631
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   Rudner M, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01149
   Rudner M, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00148
   Schwade LF, 2017, INT ARCH OTORHINOLAR, V21, P232, DOI 10.1055/s-0036-1586734
   Shahin AJ, 2007, BRAIN TOPOGR, V20, P55, DOI 10.1007/s10548-007-0031-4
   Sheldon S, 2008, J ACOUST SOC AM, V123, P489, DOI 10.1121/1.2783762
   Shestakova A, 2002, NEUROREPORT, V13, P1813, DOI 10.1097/00001756-200210070-00025
   Signoret C, 2019, EAR HEARING, V40, P1140, DOI 10.1097/AUD.0000000000000689
   Signoret C, 2018, J EXP PSYCHOL HUMAN, V44, P277, DOI 10.1037/xhp0000442
   Signoret C, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00176
   Strauss A, 2013, J COGNITIVE NEUROSCI, V25, P1383, DOI 10.1162/jocn_a_00389
   Taulu S, 2005, IEEE T SIGNAL PROCES, V53, P3359, DOI 10.1109/TSP.2005.853302
   Taulu S, 2006, PHYS MED BIOL, V51, P1759, DOI 10.1088/0031-9155/51/7/008
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015
   Wang L, 2012, FRONT PSYCHOL, V3, DOI [10.3389/fpsyg.2012.00438, 10.3389/fpsyg.2012.00187]
   Wild CJ, 2012, NEUROIMAGE, V60, P1490, DOI 10.1016/j.neuroimage.2012.01.035
   Winkler I, 2009, TRENDS COGN SCI, V13, P532, DOI 10.1016/j.tics.2009.09.003
   Ylinen S, 2016, BRAIN LANG, V162, P72, DOI 10.1016/j.bandl.2016.08.007
   Zekveld AA, 2013, J ACOUST SOC AM, V134, P2225, DOI 10.1121/1.4817926
   Zekveld AA, 2011, EAR HEARING, V32, pE16, DOI 10.1097/AUD.0b013e318228036a
NR 75
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD SEP 25
PY 2020
VL 14
AR 573254
DI 10.3389/fnins.2020.573254
PG 15
WC Neurosciences
SC Neurosciences & Neurology
GA NY6AN
UT WOS:000576469900001
PM 33100961
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Sajjadi, E
   Mohammadzadeh, A
   Sayadi, N
   Nazeri, A
   Tabatabai, SM
AF Sajjadi, Ebtesam
   Mohammadzadeh, Ali
   Sayadi, Nushin
   Nazeri, Ahmadreza
   Tabatabai, Seyyed Mehdi
TI Comparison of the recognition scores of stop and fricative consonants in
   babble noise between musicians and non-musicians
SO PSYCHOLOGY OF MUSIC
LA English
DT Article; Early Access
DE musician; musical training; stop consonant; fricative consonant;
   consonant perception; speech-in-noise perception
ID BIOLOGICAL IMPACT; MUSICAL EXPERTISE; SPEECH-PERCEPTION; DISCRIMINATION;
   DURATION; ENHANCEMENT; DISTINCTION; MODULATION; CHILDREN; MASKING
AB Everyday communication mostly occurs in the presence of various background noises and competing talkers. Studies have shown that musical training could have a positive effect on auditory processing, particularly in challenging listening situations. To our knowledge, no groups have specifically studied the advantage of musical training on perception of consonants in the presence of background noise. We hypothesized that musician advantage in speech in noise processing may also result in enhanced perception of speech units such as consonants in noise. Therefore, this study aimed to compare the recognition of stops and fricatives, which constitute the highest number of Persian consonants, in the presence of 12-talker babble noise between musicians and non-musicians. For this purpose, stops and fricatives presented in the consonant-vowel-consonant format and embedded in three signal-to-noise ratios of 0, -5, and -10 dB. The study was conducted on 40 young listeners (20 musicians and 20 non-musicians) with normal hearing. Our outcome indicated that musicians outperformed the non-musicians in recognition of stops and fricatives in all three signal-to-noise ratios. These findings provide important evidence about the impact of musical instruction on processing of consonants and highlight the role of musical training on perceptual abilities.
C1 [Sajjadi, Ebtesam; Mohammadzadeh, Ali; Nazeri, Ahmadreza] Shahid Beheshti Univ Med Sci, Sch Rehabil, Dept Audiol, Damavand St, Tehran 1616913111, Iran.
   [Sayadi, Nushin] Univ Tehran Med Sci, Fac Rehabil, Dept Audiol, Tehran, Iran.
   [Tabatabai, Seyyed Mehdi] Shahid Beheshti Univ Med Sci, Fac Rehabil, Dept Biostat, Tehran, Iran.
RP Mohammadzadeh, A (corresponding author), Shahid Beheshti Univ Med Sci, Sch Rehabil, Dept Audiol, Damavand St, Tehran 1616913111, Iran.
EM almedzade@gmail.com
OI Sajadi, Ebtesam/0000-0002-2285-503X
CR Abrams DA, 2011, CEREB CORTEX, V21, P1507, DOI 10.1093/cercor/bhq198
   Ahmadi A, 2015, SCI J REHABIL MED, V4, P109
   Anderson Samira, 2011, Seminars in Hearing, V32, P129, DOI 10.1055/s-0031-1277234
   Assmann Peter, 2004, VVolume 18, P231
   Baskent D, 2016, J ACOUST SOC AM, V139, pEL51, DOI 10.1121/1.4942628
   BAUM SR, 1987, J ACOUST SOC AM, V82, P1073, DOI 10.1121/1.395382
   Besser J, 2013, TRENDS AMPLIF, V17, P75, DOI 10.1177/1084713813495459
   Besson M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00094
   Bianchi F, 2017, NEUROIMAGE, V163, P398, DOI 10.1016/j.neuroimage.2017.07.057
   Bidelman GM, 2011, J COGNITIVE NEUROSCI, V23, P425, DOI 10.1162/jocn.2009.21362
   Bishop-Liebler P, 2014, DYSLEXIA, V20, P261, DOI 10.1002/dys.1479
   Boebinger D, 2015, J ACOUST SOC AM, V137, P378, DOI 10.1121/1.4904537
   Bogliotti C, 2008, J EXP CHILD PSYCHOL, V101, P137, DOI 10.1016/j.jecp.2008.03.006
   Bregman A. S., 1993, THINKING SOUND COGNI, P10
   BUUS S, 1985, J ACOUST SOC AM, V78, P1958, DOI 10.1121/1.392652
   Carey D, 2015, COGNITION, V137, P81, DOI 10.1016/j.cognition.2014.12.005
   CARHART R, 1969, J ACOUST SOC AM, V45, P694, DOI 10.1121/1.1911445
   Chan AS, 1998, NATURE, V396, P128, DOI 10.1038/24075
   Chobert J, 2014, CEREB CORTEX, V24, P956, DOI 10.1093/cercor/bhs377
   Chobert J, 2011, J COGNITIVE NEUROSCI, V23, P3874, DOI 10.1162/jocn_a_00088
   Clayton KK, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157638
   Coffey EBJ, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11070
   Cornelissen PL, 1996, COGNITION, V59, P275, DOI 10.1016/0010-0277(95)00697-4
   de Boer J, 2008, J NEUROSCI, V28, P4929, DOI 10.1523/JNEUROSCI.0902-08.2008
   Dole M, 2012, NEUROPSYCHOLOGIA, V50, P1543, DOI 10.1016/j.neuropsychologia.2012.03.007
   Elmer S, 2013, CORTEX, V49, P2812, DOI 10.1016/j.cortex.2013.03.007
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Kuhnis J, 2013, NEUROPSYCHOLOGIA, V51, P1608, DOI 10.1016/j.neuropsychologia.2013.04.007
   Kujala T, 2009, BIOL PSYCHOL, V81, P135, DOI 10.1016/j.biopsycho.2009.03.010
   Kuman PV, 2014, J HEAR SCI, V4, P35
   Liberman I. Y., 1985, REM SPEC EDUC, V6, P8, DOI DOI 10.1177/074193258500600604
   LISKER L, 1967, LANG SPEECH, V10, P1, DOI 10.1177/002383096701000101
   LISKER L, 1957, LANGUAGE, V33, P42, DOI 10.2307/410949
   Luo F, 2008, J NEUROSCI, V28, P11615, DOI 10.1523/JNEUROSCI.3972-08.2008
   MASTERSON J, 1995, COGN NEUROPSYCHOL, V12, P233, DOI 10.1080/02643299508251997
   Mattys SL, 2005, J EXP PSYCHOL GEN, V134, P477, DOI 10.1037/0096-3445.134.4.477
   Meha-Bettison K, 2018, INT J AUDIOL, V57, P40, DOI 10.1080/14992027.2017.1380850
   Meyer M, 2005, NEUROREPORT, V16, P1985, DOI 10.1097/00001756-200512190-00003
   Mosleh M., 2001, BIMONTHLY AUDIOLOGY, V9, P72
   Pantev C, 2001, NEUROREPORT, V12, P169, DOI 10.1097/00001756-200101220-00041
   Parbery-Clark A, 2012, NEUROSCIENCE, V219, P111, DOI 10.1016/j.neuroscience.2012.05.042
   Parbery-Clark A, 2013, J NEUROSCI, V33, P16741, DOI 10.1523/JNEUROSCI.5700-12.2013
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Perrot X, 1999, NEUROSCI LETT, V262, P167, DOI 10.1016/S0304-3940(99)00044-0
   Rammsayer T, 2006, MUSIC PERCEPT, V24, P37, DOI 10.1525/mp.2006.24.1.37
   Ruggles DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086980
   Schneider P, 2005, ANN NY ACAD SCI, V1060, P387, DOI 10.1196/annals.1360.033
   Simpson SA, 2005, J ACOUST SOC AM, V118, P2775, DOI 10.1121/1.2062650
   Slater J, 2015, BEHAV BRAIN RES, V291, P244, DOI 10.1016/j.bbr.2015.05.026
   Soncini Fabiana, 2006, Pró-Fono R. Atual. Cient., V18, P161, DOI 10.1590/S0104-56872006000200005
   STEVENS KN, 1992, J ACOUST SOC AM, V91, P2979, DOI 10.1121/1.402933
   Strait DL, 2014, HEARING RES, V308, P109, DOI 10.1016/j.heares.2013.08.004
   Strait DL, 2013, DEV COGN NEUROS-NETH, V6, P51, DOI 10.1016/j.dcn.2013.06.003
   Strait DL, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00113
   Strait DL, 2010, HEARING RES, V261, P22, DOI 10.1016/j.heares.2009.12.021
   Swaminathan J, 2015, SCI REP-UK, V5, DOI 10.1038/srep11628
   Tervaniemi M, 2005, EXP BRAIN RES, V161, P1, DOI 10.1007/s00221-004-2044-5
   Tervaniemi M, 2009, EUR J NEUROSCI, V30, P1636, DOI 10.1111/j.1460-9568.2009.06955.x
   Zendel BR, 2015, J COGNITIVE NEUROSCI, V27, P1044, DOI 10.1162/jocn_a_00758
   Zendel BR, 2012, PSYCHOL AGING, V27, P410, DOI 10.1037/a0024816
   Zendel BR, 2009, J COGNITIVE NEUROSCI, V21, P1488, DOI 10.1162/jocn.2009.21140
   Zuk J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080546
NR 66
TC 0
Z9 0
U1 2
U2 2
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0305-7356
EI 1741-3087
J9 PSYCHOL MUSIC
JI Psychol. Music
AR 0305735620953616
DI 10.1177/0305735620953616
EA SEP 2020
PG 12
WC Psychology, Educational; Psychology, Applied; Music; Psychology,
   Experimental
SC Psychology; Music
GA NU3DX
UT WOS:000573523200001
DA 2021-02-24
ER

PT J
AU Billot-Vasquez, K
   Lian, ZW
   Hirata, Y
   Kelly, SD
AF Billot-Vasquez, Kiana
   Lian, Zhongwen
   Hirata, Yukari
   Kelly, Spencer D.
TI Emblem Gestures Improve Perception and Evaluation of Non-native Speech
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE speech processing; non-native accent; hand gesture; multimodal; second
   language; cross-cultural communication
ID DUAL CODING THEORY; NEURAL INTEGRATION; ICONIC GESTURES; ACCENT;
   COMMUNICATION; LANGUAGE; ENGLISH; HAND; EXPRESSIONS; CHINESE
AB Traditionally, much of the attention on the communicative effects of non-native accent has focused on the accentitselfrather than how it functions within a more natural context. The present study explores how the bodily context of co-speech emblematic gestures affects perceptual and social evaluation of non-native accent. In two experiments in two different languages, Mandarin and Japanese, we filmed learners performing a short utterance in three different within-subjects conditions: speech alone, culturally familiar gesture, and culturally unfamiliar gesture. Native Mandarin participants watched videos of foreign-accented Mandarin speakers (Experiment 1), and native Japanese participants watched videos of foreign-accented Japanese speakers (Experiment 2). Following each video, native language participants were asked a set of questions targeting speech perception and social impressions of the learners. Results from both experiments demonstrate that familiar-and occasionally unfamiliar-emblems facilitated speech perception and enhanced social evaluations compared to the speech alone baseline. The variability in our findings suggests that gesture may serve varied functions in the perception and evaluation of non-native accent.
C1 [Billot-Vasquez, Kiana; Kelly, Spencer D.] Colgate Univ, Dept Psychol & Brain Sci, Hamilton, NY 13346 USA.
   [Billot-Vasquez, Kiana; Lian, Zhongwen; Hirata, Yukari; Kelly, Spencer D.] Ctr Language & Brain, Hamilton, NY 13346 USA.
   [Lian, Zhongwen; Hirata, Yukari; Kelly, Spencer D.] Colgate Univ, Linguist Program, Hamilton, NY 13346 USA.
   [Hirata, Yukari] Colgate Univ, Dept East Asian Languages, Hamilton, NY 13346 USA.
RP Kelly, SD (corresponding author), Colgate Univ, Dept Psychol & Brain Sci, Hamilton, NY 13346 USA.; Kelly, SD (corresponding author), Ctr Language & Brain, Hamilton, NY 13346 USA.; Kelly, SD (corresponding author), Colgate Univ, Linguist Program, Hamilton, NY 13346 USA.
EM skelly@colgate.edu
FU Picker Interdisciplinary Science Institute of Colgate University
FX This study was funded by the Picker Interdisciplinary Science Institute
   of Colgate University.
CR Adank P, 2009, J EXP PSYCHOL HUMAN, V35, P520, DOI 10.1037/a0013552
   ALLEN LQ, 1995, MOD LANG J, V79, P521, DOI 10.2307/330004
   Atagi E, 2017, PHONETICA, V74, P173, DOI 10.1159/000452956
   Baills F, 2019, STUD SECOND LANG ACQ, V41, P33, DOI 10.1017/S0272263118000074
   Bent T, 2017, LANG SPEECH, V60, P110, DOI 10.1177/0023830916645374
   Biau E, 2013, BRAIN LANG, V124, P143, DOI 10.1016/j.bandl.2012.10.008
   Bradac James. J., 1990, HDB LANGUAGE SOCIAL, P387
   Cheng LRL, 1999, TOP LANG DISORD, V19, P1, DOI 10.1097/00011363-199908000-00004
   Church RB, 2017, WHY GESTURE HANDS FU
   Clark JM, 1991, EDUC PSYCHOL REV, V3, P149, DOI 10.1007/BF01320076
   Dahl TI, 2014, MOD LANG J, V98, P813, DOI 10.1111/j.1540-4781.2014.12124.x
   DeJesus JM, 2017, J EXP CHILD PSYCHOL, V164, P178, DOI 10.1016/j.jecp.2017.07.005
   Dick AS, 2009, HUM BRAIN MAPP, V30, P3509, DOI 10.1002/hbm.20774
   Drijvers L, 2017, J SPEECH LANG HEAR R, V60, P212, DOI 10.1044/2016_JSLHR-H-16-0101
   Efron D, 1941, GESTURE ENV TENTATIV
   Ekman P., 1972, NEBRASKA S MOTIVATIO, P207, DOI DOI 10.1037/0022-3514.53.4.712
   Giles H., 1977, LANGUAGE ETHNICITY I
   Gluhareva D, 2017, LANG TEACH RES, V21, P609, DOI 10.1177/1362168816651463
   Gluszek A, 2010, PERS SOC PSYCHOL REV, V14, P214, DOI 10.1177/1088868309359288
   Goldin-Meadow S, 1999, TRENDS COGN SCI, V3, P419, DOI 10.1016/S1364-6613(99)01397-2
   GRAHAM JA, 1975, INT J PSYCHOL, V10, P57, DOI 10.1080/00207597508247319
   Green A, 2009, HUM BRAIN MAPP, V30, P3309, DOI 10.1002/hbm.20753
   Gregersen TS, 2005, FOREIGN LANG ANN, V38, P388, DOI 10.1111/j.1944-9720.2005.tb02225.x
   Grosjean F., 2010, BILINGUAL
   Gullberg M., 2006, IRAL-INT REV APPL LI, V44, P103, DOI [10.1515/IRAL.2006.004, DOI 10.1515/IRAL.2006.004]
   Gullberg M., 1998, GESTURE COMMUNICATIO
   Hannah B, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02051
   Hansen K, 2017, SOC COGN AFFECT NEUR, V12, P507, DOI 10.1093/scan/nsw148
   Hanulikova A, 2012, J COGNITIVE NEUROSCI, V24, P878, DOI 10.1162/jocn_a_00103
   Henrich J, 2010, BEHAV BRAIN SCI, V33, P111, DOI 10.1017/S0140525X10000725
   Hoetjes M., 2019, P C 6 GEST SPEECH IN
   Holle H, 2010, NEUROIMAGE, V49, P875, DOI 10.1016/j.neuroimage.2009.08.058
   Hostetter AB, 2011, PSYCHOL BULL, V137, P297, DOI 10.1037/a0022128
   Howie J. M., 1976, ACOUSTICAL STUDIES M, V18
   Huang XY, 2019, LANG LEARN, V69, P177, DOI 10.1111/lang.12326
   Hubbard AL, 2009, HUM BRAIN MAPP, V30, P1028, DOI 10.1002/hbm.20565
   JOHNSON JS, 1989, COGNITIVE PSYCHOL, V21, P60, DOI 10.1016/0010-0285(89)90003-0
   Jungheim N., 2001, FOCUS LANGUAGE TEST, P1
   JUSSIM L, 1987, J PERS SOC PSYCHOL, V52, P536, DOI 10.1037/0022-3514.52.3.536
   Kelly S. D., 2017, WHY GESTURE HANDS FU, P243, DOI DOI 10.1075/GS.7
   Kelly SD, 2010, PSYCHOL SCI, V21, P260, DOI 10.1177/0956797609357327
   Kelly SD, 2009, LANG COGNITIVE PROC, V24, P313, DOI 10.1080/01690960802365567
   Kendon A, 1997, ANNU REV ANTHROPOL, V26, P109, DOI 10.1146/annurev.anthro.26.1.109
   Kendon A., 2004, GESTURE VISIBLE ACTI
   Kendon A, 2017, GESTURE, V16, P157, DOI 10.1075/gest.16.2.01ken
   Kinzler KD, 2007, P NATL ACAD SCI USA, V104, P12577, DOI 10.1073/pnas.0705345104
   Kinzler KD, 2011, DEVELOPMENTAL SCI, V14, P106, DOI 10.1111/j.1467-7687.2010.00965.x
   Kinzler KD, 2009, SOC COGNITION, V27, P623, DOI 10.1521/soco.2009.27.4.623
   Kita S, 2009, LANG COGNITIVE PROC, V24, P145, DOI 10.1080/01690960802586188
   Krahmer E, 2007, J MEM LANG, V57, P396, DOI 10.1016/j.jml.2007.06.005
   Kushch O, 2018, LANG COGN NEUROSCI, V33, P992, DOI 10.1080/23273798.2018.1435894
   LaSasso C., 2003, J DEAF STUD DEAF EDU, V8, P250, DOI [10.1093/deafed/eng014, DOI 10.1093/DEAFED/ENG014]
   Lev-Ari S, 2010, J EXP SOC PSYCHOL, V46, P1093, DOI 10.1016/j.jesp.2010.05.025
   Lindemann S, 2003, J SOCIOLING, V7, P348, DOI 10.1111/1467-9481.00228
   Lippi-Green R., 2012, ENGLISH ACCENT LANGU
   Macedonia M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01467
   Macedonia M, 2014, MIND BRAIN EDUC, V8, P74, DOI 10.1111/mbe.12047
   Maricchiolo F, 2009, LANG COGNITIVE PROC, V24, P239, DOI 10.1080/01690960802159929
   Matsumoto D., 2013, ENCY CROSS CULT PSYC, V2, P464, DOI [10.1002/9781118339893.wbeccp188, DOI 10.1002/9781118339893.WBECCP188]
   McCafferty S., 2009, GESTURE 2 LANGUAGE A
   MCNEILL D, 1985, PSYCHOL REV, V92, P350, DOI 10.1037/0033-295X.92.3.350
   McNeill D., 1994, RES LANG SOC INTERAC, V27, P223, DOI DOI 10.1207/S15327973RLSI2703_4
   McNeill D., 1992, HAND MIND WHAT GESTU
   McNeill D., 2006, GESTURE THOUGHT
   Morett LM, 2015, LANG COGN NEUROSCI, V30, P347, DOI 10.1080/23273798.2014.923105
   Morett LM, 2014, MOD LANG J, V98, P834, DOI 10.1111/j.1540-4781.2014.12125.x
   Neu J., 1990, DEV COMMUNICATIVE CO, P121
   Novack M. A., 2017, UNDERSTANDING GESTUR
   Obermeier C, 2012, CORTEX, V48, P857, DOI 10.1016/j.cortex.2011.02.007
   ozyurek A., 2017, WHY GESTURE HANDS FU
   PAIVIO A, 1991, CAN J PSYCHOL, V45, P255, DOI 10.1037/h0084295
   Pickering Lucy, 2006, ANNU REV APPL LINGUI, V26, P219, DOI DOI 10.1017/S0267190506000110
   Poggi I, 2008, GESTURE, V8, P45, DOI 10.1075/gest.8.1.05pog
   POPELKA GR, 1971, AM ANN DEAF, V116, P434
   Pourtois G, 2005, CORTEX, V41, P49, DOI 10.1016/S0010-9452(08)70177-1
   Pouw W, 2020, P NATL ACAD SCI USA, V117, P11364, DOI 10.1073/pnas.2004163117
   Poyatos F., 1983, CULTURAL ANTHR SOCIA
   RUBIN DL, 1992, RES HIGH EDUC, V33, P511, DOI 10.1007/BF00973770
   Schneller R., 1988, CROSS CULTURAL PERSP, P153
   Sime D., 2006, IRAL-INT REV APPL LI, V44, P211, DOI DOI 10.1515/IRAL.2006.009
   Skipper JI, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0297
   So WC, 2012, LANG COGNITIVE PROC, V27, P665, DOI 10.1080/01690965.2011.573220
   Sueyoshi A, 2005, LANG LEARN, V55, P661, DOI 10.1111/j.0023-8333.2005.00320.x
   Van Berkum JJA, 2008, J COGNITIVE NEUROSCI, V20, P580, DOI 10.1162/jocn.2008.20054
   Van den Stock J, 2007, EMOTION, V7, P487, DOI 10.1037/1528-3542.7.3.487
   Vance Timothy J., 2008, SOUNDS JAPANESE
   Wang L, 2013, NEUROPSYCHOLOGIA, V51, P2847, DOI 10.1016/j.neuropsychologia.2013.09.027
   Willems RM, 2007, CEREB CORTEX, V17, P2322, DOI 10.1093/cercor/bhl141
   Wu YC, 2007, BRAIN LANG, V101, P234, DOI 10.1016/j.bandl.2006.12.003
   Zheng AN, 2018, J SPEECH LANG HEAR R, V61, P2179, DOI 10.1044/2018_JSLHR-S-17-0481
NR 90
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD SEP 22
PY 2020
VL 11
AR 574418
DI 10.3389/fpsyg.2020.574418
PG 16
WC Psychology, Multidisciplinary
SC Psychology
GA NW6TO
UT WOS:000575148300001
PM 33071912
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Rosemann, S
   Thiel, CM
AF Rosemann, Stephanie
   Thiel, Christiane M.
TI Neuroanatomical changes associated with age-related hearing loss and
   listening effort
SO BRAIN STRUCTURE & FUNCTION
LA English
DT Article
DE Ageing; Hearing loss; Listening effort; Grey matter volume; Cortical
   thickness; Diffusion tensor imaging
ID CORTICAL THICKNESS; AUDITORY-CORTEX; SPEECH-PERCEPTION; BRAIN VOLUME;
   OLDER-ADULTS; MATTER; IMPAIRMENT; MECHANISMS; NOISE
AB Age-related hearing loss is associated with a decrease in hearing abilities for high frequencies and therefore leads to impairments in understanding speech-in particular, under adverse listening conditions. Growing evidence suggests that age-related hearing loss is related to various neural changes, for instance, affecting auditory and frontal brain regions. How the decreased auditory input and the increased listening effort in daily life are associated with structural changes is less clear, since previous evidence is scarce and mostly involved low sample sizes. Hence, the aim of the current study was to investigate the impact of age-related untreated hearing loss and subjectively rated daily life listening effort on grey matter and white matter changes in a large sample of participants (n = 71). For that aim, we conducted anatomical MRI and diffusion tensor imaging (DTI) in elderly hard-of-hearing and age-matched normal-hearing participants. Our results showed significantly lower grey matter volume in the middle frontal cortex in hard-of-hearing compared to normal-hearing participants. Further, higher listening effort was associated with lower grey matter volume and cortical thickness in the orbitofrontal cortex and lower grey matter volume in the inferior frontal cortex. No significant relations between hearing abilities or listening effort were obtained for white matter integrity in tracts connecting auditory and prefrontal as well as visual areas. These findings provide evidence that hearing impairment as well as daily life listening effort seems to be associated with grey matter loss in prefrontal brain regions. We further conclude that alterations in cortical thickness seem to be linked to the increased listening effort rather than the hearing loss itself.
C1 [Rosemann, Stephanie; Thiel, Christiane M.] Carl von Ossietzky Univ Oldenburg, Biol Psychol, Dept Psychol, Dept Med & Hlth Sci, Ammerlander Heerstr 114-118, D-26111 Oldenburg, Germany.
   [Rosemann, Stephanie; Thiel, Christiane M.] Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, Oldenburg, Germany.
RP Rosemann, S (corresponding author), Carl von Ossietzky Univ Oldenburg, Biol Psychol, Dept Psychol, Dept Med & Hlth Sci, Ammerlander Heerstr 114-118, D-26111 Oldenburg, Germany.; Rosemann, S (corresponding author), Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, Oldenburg, Germany.
EM Stephanie.rosemann@uni-oldenburg.de
OI Rosemann, Stephanie/0000-0003-2598-0538
FU Projekt DEAL; Deutsche Forschungsgemeinschaft (DFG, German Research
   Foundation) under Germany's Excellence StrategyGerman Research
   Foundation (DFG) [EXC 2177/1, 390895286]; Neuroimaging Unit of the Carl
   von Ossietzky Universitat Oldenburg - German Research Foundation [3T MRI
   INST 184/152-1 FUGG]
FX Open Access funding enabled and organized by Projekt DEAL. This work was
   funded by the Deutsche Forschungsgemeinschaft (DFG, German Research
   Foundation) under Germany's Excellence Strategy-EXC 2177/1-Project ID
   390895286 and supported by the Neuroimaging Unit of the Carl von
   Ossietzky Universitat Oldenburg funded by grants from the German
   Research Foundation (3T MRI INST 184/152-1 FUGG).
CR Abe O, 2008, NEUROBIOL AGING, V29, P102, DOI 10.1016/j.neurobiolaging.2006.09.003
   Armstrong NM, 2020, J GERONTOL A-BIOL, V75, P574, DOI 10.1093/gerona/gly268
   Bakkour A, 2009, NEUROLOGY, V72, P1048, DOI 10.1212/01.wnl.0000340981.97664.2f
   Berding G, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128743
   Bernarding C, 2017, COGN NEURODYNAMICS, V11, P203, DOI 10.1007/s11571-017-9425-5
   Blasi A, 2011, CURR BIOL, V21, P1220, DOI 10.1016/j.cub.2011.06.009
   Boyen K, 2013, HEARING RES, V295, P67, DOI 10.1016/j.heares.2012.02.010
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   Campbell J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00071
   Cardin V, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00199
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Dickerson BC, 2012, NEUROLOGY, V78, P84, DOI 10.1212/WNL.0b013e31823efc6c
   Eckert MA, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216519857267
   Eckert MA, 2012, JARO-J ASSOC RES OTO, V13, P703, DOI 10.1007/s10162-012-0332-5
   Elliott R, 1999, NEUROPSYCHOLOGIA, V37, P403, DOI 10.1016/S0028-3932(98)00107-9
   Erb J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00116
   Francis AL, 2020, WIRES COGN SCI, V11, DOI 10.1002/wcs.1514
   Gaser C., 2016, CAT COMPUTATIONAL AN, P336
   Giroud N, 2018, BRAIN STRUCT FUNCT, V223, P145, DOI 10.1007/s00429-017-1477-0
   Hartikainen P, 2012, J ALZHEIMERS DIS, V30, P857, DOI 10.3233/JAD-2012-112060
   Humes LE, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00055
   Humes LE, 2013, ATTEN PERCEPT PSYCHO, V75, P508, DOI 10.3758/s13414-012-0406-9
   Husain FT, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0026639
   Im K, 2008, CEREB CORTEX, V18, P2181, DOI 10.1093/cercor/bhm244
   Johnson J, 2015, AM J AUDIOL, V24, P419, DOI 10.1044/2015_AJA-14-0058
   Kiesslin J, 2003, INT J AUDIOL, V42, p2S92
   Leemans A., 2009, P INT SOC MAG RESON, V17, P3537, DOI DOI 10.1093/occmed/kqr069
   Lin FR, 2014, NEUROIMAGE, V90, P84, DOI 10.1016/j.neuroimage.2013.12.059
   Lin FR, 2012, JAMA-J AM MED ASSOC, V307, P1147, DOI 10.1001/jama.2012.321
   Lovden M, 2010, NEUROPSYCHOLOGIA, V48, P3878, DOI 10.1016/j.neuropsychologia.2010.08.026
   Luan Y, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00222
   Luan Y, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00055
   Ma W, 2016, AM J NEURORADIOL, V37, P2110, DOI 10.3174/ajnr.A4870
   Madden DJ, 2012, BBA-MOL BASIS DIS, V1822, P386, DOI 10.1016/j.bbadis.2011.08.003
   Madden DJ, 2009, NEUROPSYCHOL REV, V19, P415, DOI 10.1007/s11065-009-9113-2
   Matthen M, 2016, EAR HEARING, V37, p28S, DOI 10.1097/AUD.0000000000000292
   Moore DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107720
   Mori S., 2005, MRI ATLAS HUMAN WHIT
   Neth BJ, 2020, FRONT AGING NEUROSCI, V11, DOI 10.3389/fnagi.2019.00355
   Peelle JE, 2011, J NEUROSCI, V31, P12638, DOI 10.1523/JNEUROSCI.2559-11.2011
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Pollmann S, 2004, CEREB CORTEX, V14, P903, DOI 10.1093/cercor/bhh049
   Profant O, 2014, NEUROSCIENCE, V260, P87, DOI 10.1016/j.neuroscience.2013.12.010
   Qian ZJ, 2017, NEUROIMAGE-CLIN, V16, P205, DOI 10.1016/j.nicl.2017.07.021
   Raizada RDS, 2007, NEURON, V56, P726, DOI 10.1016/j.neuron.2007.11.001
   Rigters SC, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00002
   Rolls ET, 2019, NEUROPSYCHOLOGIA, V128, P14, DOI 10.1016/j.neuropsychologia.2017.09.021
   Rosemann S, 2020, CORTEX, V129, P266, DOI 10.1016/j.cortex.2020.04.022
   Rosemann S, 2020, NEUROSCIENCE, V429, P134, DOI 10.1016/j.neuroscience.2019.12.046
   Rosemann S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38816-z
   Rosemann S, 2018, NEUROIMAGE, V175, P425, DOI 10.1016/j.neuroimage.2018.04.023
   Rudner M, 2019, J SPEECH LANG HEAR R, V62, P1117, DOI 10.1044/2018_JSLHR-H-ASCC7-18-0142
   Rudner M, 2016, EAR HEARING, V37, p69S, DOI 10.1097/AUD.0000000000000302
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schulte M, 2015, HORANSTRENGUNGS FRAG
   Schwarz CG, 2016, NEUROIMAGE-CLIN, V11, P802, DOI 10.1016/j.nicl.2016.05.017
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
   Wildgruber D, 2009, INT J SPEECH-LANG PA, V11, P277, DOI DOI 10.1080/17549500902943043
   Wong PCM, 2010, EAR HEARING, V31, P471, DOI 10.1097/AUD.0b013e3181d709c2
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
NR 61
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1863-2653
EI 1863-2661
J9 BRAIN STRUCT FUNCT
JI Brain Struct. Funct.
PD DEC
PY 2020
VL 225
IS 9
BP 2689
EP 2700
DI 10.1007/s00429-020-02148-w
EA SEP 2020
PG 12
WC Anatomy & Morphology; Neurosciences
SC Anatomy & Morphology; Neurosciences & Neurology
GA OT1YE
UT WOS:000572002300001
PM 32960318
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Nagle, CL
AF Nagle, Charles L.
TI Revisiting Perception-Production Relationships: Exploring a New Approach
   to Investigate Perception as a Time-Varying Predictor
SO LANGUAGE LEARNING
LA English
DT Article
DE speech perception; speech production; longitudinal mixed-effects
   modeling; time-varying predictors; L2 Spanish
ID VOICE-ONSET TIME; INDIVIDUAL-DIFFERENCES; SPEECH-PERCEPTION;
   CROSS-LANGUAGE; ENGLISH; ACQUISITION; SPEAKERS; BILINGUALS; CONSONANTS;
   MODELS
AB Models of L2 pronunciation learning have hypothesized that accurate speech perception promotes accurate speech production. This claim can be evaluated longitudinally by examining the extent to which changes in stop consonant perception predict changes in stop consonant production. Taking a time-sensitive view of the perception-production link, this study used longitudinal data to analyze perception as a time-varying predictor of production accuracy. Mixed-effects models were fit to oddity, delayed word repetition, and picture description tasks to examine how participants' perception and production changed over time. Oddity task perception data were then decomposed into their between- and within-subjects components and integrated into the delayed repetition and picture description production models. Surprisingly, only the between-subjects predictors reached significance, and the strength of the perception-production link varied across production tasks and target phones. The methods used have implications for future research on perception-production links.
C1 [Nagle, Charles L.] Iowa State Univ, Ames, IA USA.
RP Nagle, CL (corresponding author), Iowa State Univ, Dept World Languages & Cultures, 505 Morrill Rd,3102G Pearson Hall, Ames, IA 50011 USA.
EM cnagle@iastate.edu
OI Nagle, Charles/0000-0003-2712-2705
FU Language Learning Early Career Research Grant
FX This study was supported by a Language Learning Early Career Research
   Grant. I would like to express my sincere gratitude to German
   Zarate-Sandez and Mari Sakai, who have supported and encouraged me from
   the very start of this project. I am indebted to Shelby Bruun, Alexandra
   Urbanski, Laura Valderrama, Sonca Vo, and Ziwei Zhou for their help with
   data collection, processing, and analysis, and to Pavel Trofimovich,
   Emma Marsden, and the anonymous reviewers, whose insightful feedback has
   significantly enhanced the quality of this article.
CR [Anonymous], SUPERLAB VERS 5 0 CO
   Baese-Berk MM, 2016, J MEM LANG, V89, P23, DOI 10.1016/j.jml.2015.10.008
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bohn O.-S., 1997, 2 LANGUAGE SPEECH ST, P53
   CARAMAZZA A, 1973, J ACOUST SOC AM, V54, P421, DOI 10.1121/1.1913594
   Casillas JV, 2020, LANG LEARN, V70, P768, DOI 10.1111/lang.12392
   Casillas JV, 2020, LANG SPEECH, V63, P550, DOI 10.1177/0023830919866225
   Casillas JV, 2018, J PHONETICS, V71, P51, DOI 10.1016/j.wocn.2018.07.002
   Casserly ED, 2010, WIRES COGN SCI, V1, P629, DOI 10.1002/wcs.63
   Chang CB, 2012, J PHONETICS, V40, P249, DOI 10.1016/j.wocn.2011.10.007
   Chladkova K, 2020, LANG LEARN, V70, P1136, DOI 10.1111/lang.12422
   Cunnings I, 2015, SECOND LANG ACQUIS R, P159
   Curran PJ, 2011, ANNU REV PSYCHOL, V62, P583, DOI 10.1146/annurev.psych.093008.100356
   Eddington D, 2011, PROBUS, V23, P1, DOI 10.1515/prbs.2011.001
   Escudero P, 2006, PHONOLOGY IN CONTEXT, P109
   Evans BG, 2018, J PHONETICS, V68, P15, DOI 10.1016/j.wocn.2018.01.002
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2003, ISSUES CLIN LINGUIST, P19
   Flege J. E., 2003, PHONETICS PHONOLOGY, P319, DOI DOI 10.1515/9783110895094.319
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   FLEGE JE, 1995, PHONETICA, V52, P90, DOI 10.1159/000262062
   FLEGE JE, 1987, LANG LEARN, V37, P285, DOI 10.1111/j.1467-1770.1987.tb00569.x
   FLEGE JE, 1987, J PHONETICS, V15, P67, DOI 10.1016/S0095-4470(19)30538-8
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   Freed BF, 2004, STUD SECOND LANG ACQ, V26, P349, DOI 10.1017/S0272263104062096
   Gambi C, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00340
   Gonzales K, 2019, COGNITION, V182, P318, DOI 10.1016/j.cognition.2018.08.021
   Gustafson E, 2013, J ACOUST SOC AM, V134, pEL506, DOI 10.1121/1.4826914
   Hanulikova A, 2012, LANG LEARN, V62, P79, DOI 10.1111/j.1467-9922.2012.00707.x
   Hualde Jose Ignacio, 2011, LAB PHONOLOGY, V2, P301, DOI DOI 10.1515/LABPH0N.2011.011
   Huensch A, 2015, J PHONETICS, V52, P105, DOI 10.1016/j.wocn.2015.06.007
   Inceoglu S., 2019, P 10 PRON 2 LANG LEA, P147
   Kartushina N, 2015, J ACOUST SOC AM, V138, P817, DOI 10.1121/1.4926561
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Kuhl PK, 2000, P NATL ACAD SCI USA, V97, P11850, DOI 10.1073/pnas.97.22.11850
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Linck JA, 2015, LANG LEARN, V65, P185, DOI 10.1111/lang.12117
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   MACK M, 1989, PERCEPT PSYCHOPHYS, V46, P187, DOI 10.3758/BF03204982
   Magloire J, 1999, PHONETICA, V56, P158, DOI 10.1159/000028449
   McAuliffe M., 2017, MONTREAL FORCED ALIG
   Nagle CL, 2018, LANG LEARN, V68, P234, DOI 10.1111/lang.12275
   R Core Team, 2019, R LANG ENV STAT COMP
   Fabra LR, 2012, J PHONETICS, V40, P491, DOI 10.1016/j.wocn.2012.01.001
   Saito K, 2019, LANG LEARN, V69, P652, DOI 10.1111/lang.12345
   Saito K, 2019, SECOND LANG RES, V35, P149, DOI 10.1177/0267658318768342
   Saito K, 2018, INT J APPL LINGUIST, V28, P3, DOI 10.1111/ijal.12175
   Sakai M, 2018, APPL PSYCHOLINGUIST, V39, P187, DOI 10.1017/S0142716417000418
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   Schoonmaker-Gates E, 2015, HISPANIA-J DEV INTER, V98, P779, DOI 10.1353/hpn.2015.0110
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   van Leussen JW, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01000
   Williams L., 1977, J PHONETICS, V5, P169
   Zampini M. L., 2001, ONE MIND 2 LANGUAGES, P23
NR 58
TC 1
Z9 1
U1 4
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0023-8333
EI 1467-9922
J9 LANG LEARN
JI Lang. Learn.
PD MAR
PY 2021
VL 71
IS 1
BP 243
EP 279
DI 10.1111/lang.12431
EA SEP 2020
PG 37
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA QD4TX
UT WOS:000567451900001
DA 2021-02-24
ER

PT J
AU della Volpe, A
   Ippolito, V
   Roccamatisi, D
   Garofalo, S
   De Lucia, A
   Gambacorta, V
   Longari, F
   Ricci, G
   Di Stadio, A
AF della Volpe, Antonio
   Ippolito, Valentina
   Roccamatisi, Dalila
   Garofalo, Sabina
   De Lucia, Antonietta
   Gambacorta, Valeria
   Longari, Fabrizio
   Ricci, Giampietro
   Di Stadio, Arianna
TI Does Unilateral Hearing Loss Impair Working Memory? An Italian Clinical
   Study Comparing Patients With and Without Hearing Aids
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE unilateral hearing loss; hearing aids; speech rehabilitation; working
   memory; hearing loss; bone anchored hearing device
ID SPEECH-PERCEPTION; COCHLEAR IMPLANT; CHILDREN; INDIVIDUALS; ADULTS;
   NOISE; BONE
AB Working memory (WM) function can be reduced in patients suffering from unilateral hearing loss (UHL) and can affect their academic performance. We aimed to compare the WM abilities of three categories of children with UHL: patients implanted with hearing aids (HAs), patients receiving a bone-anchored hearing implant (BAHI), and subjects who did not receive hearing devices. A randomized clinical study, in which 45 children (mean age: 9.5 years) were evaluated by pure tone audiometry (to identify the side and the severity of the UHL), was conducted in a tertiary referral center. Patients were simply randomized into three groups: (1) children without HAs (No-HA group), (2) patients with a (digital) HA (HA group), and (3) children with a BAHI (BAHI group). Their working and short-term memories were studied in both noisy and silent conditions at the recruiting time (T0, baseline) and 6 months after (T1) the treatment. Statistical analyses were performed to analyze the variances between T0 and T1 within each group and between the three groups. The No-HA group improved its T1 WM scores in silence (p< 0.01), but not in noise. The HA and BAHI groups showed statistically significant variances of T1 WM in noise (p< 0.01 andp< 0.01, respectively). The HA and BAHI groups did not show statistically significant variances compared to T1. Our results suggest that hearing devices (HA and BAHI) in children with sensorineural UHL (SUHL) can improve WM capacity in noise. We speculate that bilateral hearing capacity might improve the quality of life of this population, especially during everyday activities where noise is present.
C1 [della Volpe, Antonio; Ippolito, Valentina; Garofalo, Sabina; De Lucia, Antonietta] Santobono Pausilipon Childrens Hosp, Dept Otolaryngol, Otol & Cochlear Implant Unit, Naples, Italy.
   [Roccamatisi, Dalila] Univ Telemat Int Uninettuno, Fac Psychol, Rome, Italy.
   [Gambacorta, Valeria; Longari, Fabrizio; Ricci, Giampietro; Di Stadio, Arianna] Univ Perugia, Dept Otolaryngol, Perugia, Italy.
   [Di Stadio, Arianna] UCL, Neuroinflammat Lab, Queen Sq Neurol, London, England.
RP Di Stadio, A (corresponding author), Univ Perugia, Dept Otolaryngol, Perugia, Italy.; Di Stadio, A (corresponding author), UCL, Neuroinflammat Lab, Queen Sq Neurol, London, England.
EM ariannadistadio@hotmail.com
RI Di Stadio, Arianna/Q-2498-2017
OI Di Stadio, Arianna/0000-0001-5510-3814
CR Arndt S, 2017, HNO, V65, P98, DOI 10.1007/s00106-016-0297-5
   BADDELEY A, 1981, COGNITION, V10, P17, DOI 10.1016/0010-0277(81)90020-2
   BADDELEY AD, 1971, BRIT MED BULL, V27, P237, DOI 10.1093/oxfordjournals.bmb.a070860
   Bagatto M, 2020, LANG SPEECH HEAR SER, V51, P68, DOI 10.1044/2019_LSHSS-OCHL-19-0025
   Bartolomeo P, 2019, CURR OPIN PSYCHOL, V29, P90, DOI 10.1016/j.copsyc.2018.12.023
   Bishop CE, 2017, J AM ACAD AUDIOL, V28, P941, DOI 10.3766/jaaa.17049
   Bisiacchi P.S., 2005, BVN 5 11 BATTERIA VA
   BROOKHOUSER PE, 1991, LARYNGOSCOPE, V101, P1264, DOI 10.1002/lary.5541011202
   Cardon G, 2013, INT J AUDIOL, V52, P577, DOI 10.3109/14992027.2013.799786
   Cherubini P., 2012, CORT RAFFAEL, V2012, P214
   Corballis MC, 2014, PLOS BIOL, V12, DOI 10.1371/journal.pbio.1001767
   DANCER J, 1995, AM ANN DEAF, V140, P291, DOI 10.1353/aad.2012.0592
   Di Stadio A., 2015, PREVENT RES, V4, P84
   Di Stadio A, 2020, J INT ADV OTOL, V16, P158, DOI 10.5152/iao.2020.7941
   Di Stadio A, 2018, AUDIOL NEURO-OTOL, V23, P238, DOI 10.1159/000493722
   Fitzpatrick EM, 2019, HEARING RES, V372, P42, DOI 10.1016/j.heares.2018.03.015
   GLASBERG BR, 1989, SCAND AUDIOL, P1
   Harkonen K, 2015, ACTA OTO-LARYNGOL, V135, P440, DOI 10.3109/00016489.2014.990056
   HUTCHERSON RW, 1979, OTOLARYNG HEAD NECK, V87, P239, DOI 10.1177/019459987908700215
   Knosche TR, 2002, NEUROIMAGE, V17, P1493, DOI 10.1006/nimg.2002.1262
   Kolb B, 2017, DEV MED CHILD NEUROL, V59, P1218, DOI 10.1111/dmcn.13546
   Krishnan LA, 2016, INT J PEDIATR OTORHI, V88, P63, DOI 10.1016/j.ijporl.2016.06.048
   Levitt Harry, 2007, Trends Amplif, V11, P7, DOI 10.1177/1084713806298000
   Lewis D, 2016, J SPEECH LANG HEAR R, V59, P1218, DOI 10.1044/2016_JSLHR-H-15-0207
   Lieu JEC, 2010, PEDIATRICS, V125, pE1348, DOI 10.1542/peds.2009-2448
   Lyxell B, 2003, INT J AUDIOL, V42, pS86
   McCoy SL, 2005, Q J EXP PSYCHOL-A, V58, P22, DOI 10.1080/02724980443000151
   McKay Sarah, 2008, Trends Amplif, V12, P43, DOI 10.1177/1084713807313570
   Mok M, 2010, AUDIOL NEURO-OTOL, V15, P44, DOI 10.1159/000219487
   Ng EHN, 2013, INT J AUDIOL, V52, P433, DOI 10.3109/14992027.2013.776181
   Peterson D. C., 2019, NEUROANATOMY AUDITOR
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   Popper A. N., 2019, MAMMALIAN AUDITORY P
   Purcell PL, 2016, INT J PEDIATR OTORHI, V90, P43, DOI 10.1016/j.ijporl.2016.08.029
   Ricci G, 2019, ADV REHABILITATION H, DOI [10.5772/intechopen.88201, DOI 10.5772/INTECHOPEN.88201]
   Skinner B. F., 1957, VERBAL BEHAV
   Sohmer H, 2000, HEARING RES, V146, P81, DOI 10.1016/S0378-5955(00)00099-X
   Stenfelt S, 2015, HEARING RES, V329, P41, DOI 10.1016/j.heares.2014.12.003
   Vicari S., 2007, PROVE MEMORIA APPREN
NR 39
TC 1
Z9 1
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD SEP 8
PY 2020
VL 14
AR 905
DI 10.3389/fnins.2020.00905
PG 9
WC Neurosciences
SC Neurosciences & Neurology
GA NV4CX
UT WOS:000574273000001
PM 33013298
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Georgiou, GP
   Perfilieva, NV
   Tenizi, M
AF Georgiou, Georgios P.
   Perfilieva, Natalia V.
   Tenizi, Maria
TI Vocabulary Size Leads to Better Attunement to L2 Phonetic Differences:
   Clues from Russian Learners of English
SO LANGUAGE LEARNING AND DEVELOPMENT
LA English
DT Article
ID PERCEPTUAL ASSIMILATION; SPEECH-PERCEPTION; BRITISH ENGLISH; NATIVE
   SPEAKERS; VOWELS; DISCRIMINATION; GREEK; ACQUISITION; CONTRASTS; SPANISH
AB Previous research has shown that an increased second language (L2) vocabulary size leads to better attunement to the cues required to distinguish L2 contrastive phones. This has been the central tenet of the vocabulary-tuning model (vocab) on the basis of evidence by Japanese learners of English in Australia. We aim to test the validity of the aforementioned hypothesis by extending the research for learners with a different first language (L1) background and learners who do not have naturalistic access to the L2 input (i.e., learn the L2 through a controlled foreign classroom setting). To this purpose, 28 Russian speakers, who were learning English in Russia at the time, participated in two psychoacoustic tests in which they were asked to assimilate L2 vowels to their L1 phonological system and discriminate vowel contrasts respectively. The participants were divided into two groups according to their vocabulary size in English; comprising the small vocabulary (SV) and the high vocabulary (HV) groups. The results showed that the HV group demonstrated similar assimilation scores to the SV group. However, the HV group was able to perceive within-category differences and more accurately discriminate specific pairs of English vowel contrasts in comparison to the SV group. The findings are partially consistent with the central hypothesis of the Perceptual Assimilation Model-L2 and the vocab model as the expansion of L2 vocabulary was linked with better attunement to phonetic differences in the L2. Another important finding is that a more developed vocabulary results in fine-tuning to L2 phonetic differences, even in a restricted L2 learning setting [work supported by the "RUDN University Program 5-100"].
C1 [Georgiou, Georgios P.; Perfilieva, Natalia V.] Peoples Friendship Univ Russia RUDN Univ, Dept Gen & Russian Linguist, Moscow, Russia.
   [Georgiou, Georgios P.] Univ Nicosia, Dept Languages & Literature, Nicosia, Cyprus.
   [Tenizi, Maria] Univ Cyprus, Dept English Studies, Nicosia, Cyprus.
RP Georgiou, GP (corresponding author), Peoples Friendship Univ Russia RUDN Univ, Dept Gen & Russian Linguist, Moscow, Russia.; Georgiou, GP (corresponding author), Univ Nicosia, Dept Languages & Literature, Nicosia, Cyprus.
EM georgiou.georgos@hotmail.com
RI Perfilieva, Natalia/X-8776-2019
OI Perfilieva, Natalia/0000-0002-1018-809X; Georgiou,
   Georgios/0000-0002-7192-2649
FU RUDN University Program 5-100; RUDN University Phonetic Lab
   [44-09/19-156]
FX The publication has been prepared with the support of the "RUDN
   University Program 5-100". The research funding (44-09/19-156) was
   granted to Dr Georgios P. Georgiou, Head of RUDN University Phonetic
   Lab. We would like to thank Dr Natalia Pavlou and Mrs Vasiliki
   Erotokritou from the Cyprus Acquisition Team (CAT) of the Department of
   English Studies, University of Cyprus, for their valuable comments on
   the paper.
CR Alispahic S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00052
   Antoniou M, 2010, THESIS
   Antoniou M, 2012, J PHONETICS, V40, P582, DOI 10.1016/j.wocn.2012.05.005
   Avanesov R. I., 1972, RUSSKOE LITERATURNOE
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma Paul, 2019, PRAAT DOING PHONETIC
   Bohn O.-S., 1995, SPEECH PERCEPTION LI, P279
   Bundgaard-Nielsen RL, 2011, STUD SECOND LANG ACQ, V33, P433, DOI 10.1017/S0272263111000040
   Bundgaard-Nielsen RL, 2011, APPL PSYCHOLINGUIST, V32, P51, DOI 10.1017/S0142716410000287
   Dawes J, 2008, INT J MARKET RES, V50, P61
   Elvin J, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01188
   Escudero P, 2004, STUD SECOND LANG ACQ, V26, P551, DOI 10.1017/S0272226310400021
   Evans BG, 2018, J PHONETICS, V68, P15, DOI 10.1016/j.wocn.2018.01.002
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   FOX RA, 1995, J ACOUST SOC AM, V97, P2540, DOI 10.1121/1.411974
   Georgiou G. P., 2020, SPEECH COMMUNICATION
   Georgiou GP, 2020, INT J BILINGUAL, DOI 10.1177/1367006920945396
   Georgiou GP, 2020, TOP LINGUIST, V21, P74, DOI 10.2478/topling-2020-0005
   Georgiou GP, 2019, LANG SCI, V72, P1, DOI 10.1016/j.langsci.2018.12.001
   Georgiou GP, 2018, SPEECH COMMUN, V102, P68, DOI 10.1016/j.specom.2018.07.003
   Gilichinskaya Y. D., 2007, J ACOUST SOC AM, V122, DOI [10.1121/1.2942831, DOI 10.1121/1.2942831]
   Gilichinskaya YD, 2010, J ACOUST SOC AM, V128, pEL80, DOI 10.1121/1.3462988
   Hattori K, 2009, J ACOUST SOC AM, V125, P469, DOI 10.1121/1.3021295
   Ivanova S., 2016, WORKING PAPERS LINGU, V3
   Iverson P, 2007, J ACOUST SOC AM, V122, P2842, DOI 10.1121/1.2783198
   Kanavos A, 2019, INT J ARTIF INTELL T, V28, DOI 10.1142/S0218213019600108
   Kondaurova M. V., 2004, J ACOUST SOC AM, V116, DOI [10.1121/1.4785274, DOI 10.1121/1.4785274]
   Laufer B, 2017, MOD LANG J, V101, P729, DOI 10.1111/modl.12431
   Law F, 2017, APPL PSYCHOLINGUIST, V38, P89, DOI 10.1017/S0142716416000126
   Lengeris A, 2009, PHONETICA, V66, P169, DOI 10.1159/000235659
   Makarova A. O., 2010, THESIS
   Masrai A, 2019, SAGE OPEN, V9, DOI 10.1177/2158244019845182
   McAllister R, 2002, J PHONETICS, V30, P229, DOI 10.1006/jpho.2002.0174
   Morrison G. S., 2002, THESIS
   Nation ISP, 2006, CAN MOD LANG REV, V63, P59, DOI 10.3138/cmlr.63.1.59
   Nation I.S.P., 2007, LANGUAGE TEACHER, V31, P9
   Nimz K., 2016, THESIS
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   Roach P., 2004, J INT PHON ASSOC, V34, P239, DOI DOI 10.1017/S0025100304001768
   Strange W., 2007, LANGUAGE EXPERIENCE, P35, DOI DOI 10.1075/LLLT.17.08STR
   Tyler MD, 2014, PHONETICA, V71, P4, DOI 10.1159/000356237
   Williams D, 2014, J ACOUST SOC AM, V136, P2751, DOI 10.1121/1.4896471
   Williams K, 2007, EXPRESSIVE VOCABULAR
NR 47
TC 2
Z9 2
U1 2
U2 2
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1547-5441
EI 1547-3341
J9 LANG LEARN DEV
JI Lang. Learn. Dev.
PD OCT 1
PY 2020
VL 16
IS 4
BP 382
EP 398
DI 10.1080/15475441.2020.1814779
EA SEP 2020
PG 17
WC Psychology, Developmental; Linguistics; Language & Linguistics;
   Psychology, Experimental
SC Psychology; Linguistics
GA OL3KL
UT WOS:000568308700001
DA 2021-02-24
ER

PT J
AU Yu, VY
AF Yu, Vickie Y.
TI Effects of Syllable Position, Fundamental Frequency, Duration and
   Amplitude on Word Stress in Mandarin Chinese
SO JOURNAL OF PSYCHOLINGUISTIC RESEARCH
LA English
DT Article; Early Access
DE Word stress; Speech perception; Suprasegmental processing; Chinese tone;
   Acoustic properties; Linguistic experience
ID PERCEPTION; SEGMENTATION; ACQUISITION; SPEAKERS; CUES
AB This study examined the importance of syllable position, duration, and tone/pitch for the assignment of stress in Chinese hums. Twenty native Mandarin speakers and 20 native English speakers were asked to assign primary stress to two-syllable Chinese hums. The importance of acoustic cues for stress assignment was also evaluated. Our findings indicate that syllable position plays the most prominent role in stress assignment. Native Chinese listeners preferred to assign stress to final syllables whereas native English listeners preferred to assign stress to initial syllables. Both language groups were sensitive to different acoustic cues in assigning stress. The effects of complex interactions of syllable position, tone, duration and intensity on stress assignment in Chinese hums for both language groups support the hypothesis that linguistic experience affects speech perception at the suprasegmental level.
C1 [Yu, Vickie Y.] Calif State Univ Northridge, Dept Commun Disorders & Sci, Northridge, CA 91330 USA.
RP Yu, VY (corresponding author), Calif State Univ Northridge, Dept Commun Disorders & Sci, Northridge, CA 91330 USA.
EM vickie.yu@csun.edu
CR Archibald J, 1997, LINGUISTICS, V35, P167, DOI 10.1515/ling.1997.35.1.167
   ARCHIBALD J, 1992, CAN J LING/REV CAN L, V37, P301
   ARCHIBALD J, 1993, IRAL-INT REV APPL LI, V31, P129
   Beckman ME, 1986, NETHERLANDS PHONETIC
   Boersma P, 2015, PRAAT DOING PHONETIC
   Chao YR, 1979, GRAMMAR SPOKEN CHINE
   Chen Matthew Y., 2000, TONE SANDHI PATTERNS
   CUTLER A, 1988, J EXP PSYCHOL HUMAN, V14, P113, DOI 10.1037/0096-1523.14.1.113
   Cutler A., 1987, Computer Speech and Language, V2, P133, DOI 10.1016/0885-2308(87)90004-0
   CUTLER A, 1992, J MEM LANG, V31, P218, DOI 10.1016/0749-596X(92)90012-M
   Duanmu S., 2004, CAHIERS LINGUISTIQUE, V33, P65, DOI DOI 10.3406/CLAO.2004.1646
   Duanmu S., 2000, PHONOLOGY STANDARD C
   Duanmu San, 2004, LANGUAGE LINGUISTICS, V5, P891
   FRY DB, 1955, J ACOUST SOC AM, V27, P765, DOI 10.1121/1.1908022
   FRY DB, 1958, LANG SPEECH, V1, P126, DOI 10.1177/002383095800100207
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   Hoa M, 1983, ACCENTUATION PEKINOI
   Hyman L. M., 1977, STUDIES STRESS ACCEN
   Jongman A., 2000, P 6 INT C SPOK LANG, VI, P62
   Jusczyk PW, 1999, COGNITIVE PSYCHOL, V39, P159, DOI 10.1006/cogp.1999.0716
   JUSCZYK PW, 1995, COGNITIVE PSYCHOL, V29, P1, DOI 10.1006/cogp.1995.1010
   Kochanski G, 2003, SPEECH COMMUN, V41, P625, DOI 10.1016/S0167-6393(03)00100-6
   LEHISTE I, 1992, LANG SPEECH, V35, P419, DOI 10.1177/002383099203500403
   Lehiste Ilde, 1970, SUPRASEGMENTALS
   Lin M., 1984, DIALECTS, V1, P57
   Pierrehumbert J., 1980, THESIS
   Selkirk E, 1990, PHONOLOGY SYNTAX CON
   Thiessen ED, 2003, DEV PSYCHOL, V39, P706, DOI 10.1037/0012-1649.39.4.706
   WANG Jing, 1993, ZHONGGUO YUWEN, V2, P112
   Wang Y, 2003, ENDOCRINE, V22, P85, DOI 10.1385/ENDO:22:2:85
   Wayland R, 2006, J PSYCHOLINGUIST RES, V35, P285, DOI 10.1007/s10936-006-9016-9
   White C. M., 1981, J CHINESE LANGUAGE T, V16, P27
   Xu I, 2000, CHINESE J ACOUSTICS, V19, P270
   Yan J., 1988, FANGYAN, V3, P227
   Yu VY, 2010, J PSYCHOLINGUIST RES, V39, P323, DOI 10.1007/s10936-009-9142-2
NR 35
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER/PLENUM PUBLISHERS
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0090-6905
EI 1573-6555
J9 J PSYCHOLINGUIST RES
JI J. Psycholinguist. Res.
DI 10.1007/s10936-020-09731-6
EA SEP 2020
PG 20
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA NK7AR
UT WOS:000566886200001
PM 32894419
DA 2021-02-24
ER

PT J
AU Saxena, U
   Damarla, V
   Kumar, SBR
   Chacko, G
AF Saxena, Udit
   Damarla, Venkata
   Kumar, S. B. Rathna
   Chacko, Gish
TI Evaluation of Temporal Processing Abilities in Competing Noise
SO INDIAN JOURNAL OF OTOLARYNGOLOGY AND HEAD & NECK SURGERY
LA English
DT Article; Early Access
DE Temporal processing; Signal-to-noise ratio; Gap detection threshold
ID AGE; INTELLIGIBILITY; DISCRIMINATION; SENTENCES; CHILDREN
AB Temporal processing is critical to a wide variety of everyday listening tasks, including speech perception. Although the importance of signal to noise ratio (SNR) is well documented in speech perception experiments, it is less explored in temporal processing experiments. The present study examined the effect of SNR on temporal processing abilities using Gap Detection Threshold (GDT) in children and adults. The study included a total of 45 subjects, where in, 25 children (Group-1) and 20 adults (Group-2) with pure-tone thresholds ranging from 0 to 25 dB HL at frequency range 250-8000 Hz. The GDT was measured at presentation level 50 dBSL. All the measurements were performed in 5 different conditions: 'Quiet', ' + 10 dB SNR', ' + 5 dB SNR', ' + 0 dB SNR' and ' - 5 dB SNR'. Gap Detection Thresholds are significantly higher from + 10 to - 5 dB SNR when compared to quiet condition in young-adults and all sub-groups of children, whereas at + 10 dB SNR, thresholds were not significantly different from quiet condition in young-adults and all sub-groups of children except for sub-group A of children, and were significantly different for all the five conditions. It was revealed that, as the signal to noise ratio (SNR) was decreased from + 10 dB SNR to 0 dB SNR there was a significant increase in Gap Detection Thresholds. There was a significant increase in Gap Detection Thresholds from + 10 dB SNR to - 5 dB SNR in both children and adults. The results also suggest that the performance on temporal processing task in the presence of background noise achieves young-adult like pattern by the age of 10-11 years. Background noise affect temporal processing in both children and young-adults. Background noise impairs temporal processing in children more than the adults, which could be because of poor temporal resolving abilities in children.
C1 [Saxena, Udit; Damarla, Venkata; Chacko, Gish] MAA Inst Speech & Hearing, Dept Audiol, Hyderabad, Telangana, India.
   [Kumar, S. B. Rathna] Ali Yavar Jung Natl Inst Speech & Hearing Disabil, Dept Audiol, Mumbai, Maharashtra, India.
RP Damarla, V (corresponding author), MAA Inst Speech & Hearing, Dept Audiol, Hyderabad, Telangana, India.
EM venkathls@gmail.com
RI Kumar, S B Rathna/ABE-9182-2020
OI SAXENA, UDIT/0000-0003-4000-7015; , S B Rathna Kumar/0000-0003-1078-4980
CR American National Standards Institute (ANSI), 1999, S311999 ANSI
   Catts H.W., 1996, AM J AUDIOL, V5, P41, DOI DOI 10.1044/POLICY.TR1996-00241
   COOPER JC, 1971, J SPEECH HEAR RES, V14, P332, DOI 10.1044/jshr.1402.332
   DAVIS SM, 1980, CHILD DEV, V51, P75, DOI 10.1111/j.1467-8624.1980.tb02511.x
   DUQUESNOY AJ, 1983, J ACOUST SOC AM, V74, P1136, DOI 10.1121/1.390037
   GROSE JH, 1993, J SPEECH HEAR RES, V36, P351, DOI 10.1044/jshr.3602.351
   HAWKINS JE, 1950, J ACOUST SOC AM, V22, P6, DOI 10.1121/1.1906581
   IRWIN RJ, 1985, CHILD DEV, V56, P614
   JENSEN JK, 1993, PSYCHOL SCI, V4, P104, DOI 10.1111/j.1467-9280.1993.tb00469.x
   MILLS JH, 1975, J ACOUST SOC AM, V58, P767, DOI 10.1121/1.380748
   MORRONGIELLO BA, 1984, CHILD DEV, V55, P461
   Phillips Dennis P., 2002, Seminars in Hearing, V23, P251, DOI 10.1055/s-2002-35875
   PLOMP R, 1979, J ACOUST SOC AM, V66, P1333, DOI 10.1121/1.383554
   SHAILER MJ, 1985, J ACOUST SOC AM, V77, P635, DOI 10.1121/1.391881
   Shivaprakash S, 2003, GAP DETECTION UNPUB
   Snell KB, 1997, J ACOUST SOC AM, V101, P2214, DOI 10.1121/1.418205
   Stuart A, 2005, EAR HEARING, V26, P78, DOI 10.1097/00003446-200502000-00007
   Wagener KC, 2005, INT J AUDIOL, V44, P144, DOI 10.1080/14992020500057517
   Wilson RH, 1999, WORD RECOGNITION MUL
NR 19
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER INDIA
PI NEW DELHI
PA 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001,
   INDIA
SN 2231-3796
EI 0973-7707
J9 INDIAN J OTOLARYNGOL
JI Indian J. Otolaryngol. Head Neck Surg.
DI 10.1007/s12070-020-02098-z
EA SEP 2020
PG 6
WC Surgery
SC Surgery
GA NJ5IJ
UT WOS:000566076300001
DA 2021-02-24
ER

PT J
AU Knight, EJ
   Oakes, L
   Hyman, SL
   Freedman, EG
   Foxe, JJ
AF Knight, Emily J.
   Oakes, Leona
   Hyman, Susan L.
   Freedman, Edward G.
   Foxe, John J.
TI Individuals With Autism Have No Detectable Deficit in Neural Markers of
   Prediction Error When Presented With Auditory Rhythms of Varied Temporal
   Complexity
SO AUTISM RESEARCH
LA English
DT Article
DE auditory perceptual disorders; autism spectrum disorder; communication
   disorders; electroencephalography; evoked potentials; auditory; mismatch
   negativity
ID EVENT-RELATED POTENTIALS; MISMATCH NEGATIVITY MMN; MULTISENSORY
   INTEGRATION; SPECTRUM DISORDER; ASPERGER-SYNDROME; NEUROPHYSIOLOGICAL
   EVIDENCE; SPEECH SOUNDS; CHILDREN; ATTENTION; DISCRIMINATION
AB The brain's ability to encode temporal patterns and predict upcoming events is critical for speech perception and other aspects of social communication. Deficits in predictive coding may contribute to difficulties with social communication and overreliance on repetitive predictable environments in individuals with autism spectrum disorder (ASD). Using a mismatch negativity (MMN) task involving rhythmic tone sequences of varying complexity, we tested the hypotheses that (1) individuals with ASD have reduced MMN response to auditory stimuli that deviate in presentation timing from expected patterns, particularly as pattern complexity increases and (2) amplitude of MMN signal is inversely correlated with level of impairment in social communication and repetitive behaviors. Electroencephalography was acquired as individuals (age 6-21 years) listened to repeated five-rhythm tones that varied in the Shannon entropy of the rhythm across three conditions (zero, medium-1 bit, and high-2 bit entropy). The majority of the tones conformed to the established rhythm (standard tones); occasionally the fourth tone was temporally shifted relative to its expected time of occurrence (deviant tones). Social communication and repetitive behaviors were measured using the Social Responsiveness Scale and Repetitive Behavior Scale-Revised. Both neurotypical controls (n= 19) and individuals with ASD (n= 21) show stepwise decreases in MMN as a function of increasing entropy. Contrary to the result forecasted by a predictive coding hypothesis, individuals with ASD do not differ from controls in these neural mechanisms of prediction error to auditory rhythms of varied temporal complexity, and there is no relationship between these signals and social communication or repetitive behavior measures. Lay summary We tested the idea that the brain's ability to use previous experience to influence processing of sounds is weaker in individuals with autism spectrum disorder (ASD) than in neurotypical individuals. We found no difference between individuals with ASD and neurotypical controls in brain wave responses to sounds that occurred earlier than expected in either simple or complex rhythms. There was also no relationship between these brain waves and social communication or repetitive behavior scores.
C1 [Knight, Emily J.; Oakes, Leona; Freedman, Edward G.; Foxe, John J.] Univ Rochester, Sch Med & Dent, Dept Neurosci, Cognit Neurophysiol Lab,Del Monte Inst Neurosci, Rochester, NY 14642 USA.
   [Knight, Emily J.; Oakes, Leona; Hyman, Susan L.] Univ Rochester, Med Ctr, Dept Pediat, Div Dev & Behav Pediat, Rochester, NY 14642 USA.
RP Knight, EJ; Foxe, JJ (corresponding author), Univ Rochester, Sch Med & Dent, Dept Neurosci, Cognit Neurophysiol Lab,Del Monte Inst Neurosci, Rochester, NY 14642 USA.
EM emilyj_knight@urmc.rochester.edu; john_foxe@urmc.rochester.edu
OI Knight, Emily/0000-0002-6971-1148
FU Ernest J. Del Monte Institute for Neuroscience Pilot Program for 2019
   via the Harry T. Mangurian Foundation; University of Rochester Medical
   Center Department of Pediatrics Chair Fellow Award; Bradford Fellowship;
   Kyle Family
FX The authors acknowledge the contribution of undergraduate students:
   Dalia Mitchel, Zhewei Cao, Oren Bazer, and Rose Cash and graduate
   student Kathryn Toffolo, B.S. for their assistance with data collection.
   This work was supported by the Ernest J. Del Monte Institute for
   Neuroscience Pilot Program for 2019 via the Harry T. Mangurian
   Foundation. The work of Dr. Knight was supported through the University
   of Rochester Medical Center Department of Pediatrics Chair Fellow Award
   and a Bradford Fellowship, as well as the generous fellowship support of
   the Kyle Family.
CR Abdeltawwab MM, 2015, J INT ADV OTOL, V11, P36, DOI 10.5152/iao.2014.438
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   Avni E, 2018, FRONT PSYCHIATRY, V9, DOI 10.3389/fpsyt.2018.00717
   Baldeweg T, 2007, J PSYCHOPHYSIOL, V21, P204, DOI 10.1027/0269-8803.21.34.204
   Baum SH, 2015, PROG NEUROBIOL, V134, P140, DOI 10.1016/j.pneurobio.2015.09.007
   Birmaher B, 1999, J AM ACAD CHILD PSY, V38, P1230, DOI 10.1097/00004583-199910000-00011
   Bishop DVM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018993
   Bishop DVM, 2011, DEVELOPMENTAL SCI, V14, P402, DOI 10.1111/j.1467-7687.2010.00990.x
   Brandwein AB, 2015, J AUTISM DEV DISORD, V45, P230, DOI 10.1007/s10803-014-2212-9
   Brandwein AB, 2013, CEREB CORTEX, V23, P1329, DOI 10.1093/cercor/bhs109
   Brandwein AB, 2011, CEREB CORTEX, V21, P1042, DOI 10.1093/cercor/bhq170
   Ceponiene R, 2003, P NATL ACAD SCI USA, V100, P5567, DOI 10.1073/pnas.0835631100
   Chen TC, 2020, CLIN NEUROPHYSIOL, V131, P766, DOI 10.1016/j.clinph.2019.10.031
   Chien YL, 2018, J AUTISM DEV DISORD, V48, P1684, DOI 10.1007/s10803-017-3426-4
   Constantino J.N., 2012, SOCIAL RESPONSIVENES
   Cornwell BR, 2017, BIOL PSYCHIAT, V82, P447, DOI 10.1016/j.biopsych.2017.06.031
   Van de Cruys S, 2014, PSYCHOL REV, V121, P649, DOI 10.1037/a0037665
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Donkers FCL, 2015, J AUTISM DEV DISORD, V45, P506, DOI 10.1007/s10803-013-1948-y
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   Dunn MA, 2008, J AUTISM DEV DISORD, V38, P52, DOI 10.1007/s10803-007-0359-3
   Fan YT, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0102471, 10.1371/journal.pone.0085880]
   Ferri R, 2003, CLIN NEUROPHYSIOL, V114, P1671, DOI 10.1016/S1388-2457(03)00153-6
   Foxe JJ, 2018, EUR J NEUROSCI, V47, P488, DOI 10.1111/ejn.13902
   Foxe JJ, 2015, CEREB CORTEX, V25, P298, DOI 10.1093/cercor/bht213
   Garrido MI, 2009, CLIN NEUROPHYSIOL, V120, P453, DOI 10.1016/j.clinph.2008.11.029
   Gomot M, 2002, PSYCHOPHYSIOLOGY, V39, P577, DOI 10.1017/S0048577202394058
   Gomot M, 2011, J AUTISM DEV DISORD, V41, P705, DOI 10.1007/s10803-010-1091-y
   Gotham K, 2007, J AUTISM DEV DISORD, V37, P613, DOI 10.1007/s10803-006-0280-1
   Hall CL, 2020, ASSESSMENT, V27, P1258, DOI 10.1177/1073191119842255
   Hsieh MH, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00223
   Huang D, 2018, EUR J NEUROSCI, V47, P662, DOI 10.1111/ejn.13657
   Hudac CM, 2018, BRAIN COGNITION, V123, P110, DOI 10.1016/j.bandc.2018.03.004
   Jansson-Verkasalo E, 2003, NEUROSCI LETT, V338, P197, DOI 10.1016/S0304-3940(02)01405-2
   Jeste SS, 2009, J AUTISM DEV DISORD, V39, P495, DOI 10.1007/s10803-008-0652-9
   Kasai K, 2002, COGNITIVE BRAIN RES, V13, P305, DOI 10.1016/S0926-6410(01)00125-2
   Kern JK, 2007, AUTISM, V11, P123, DOI 10.1177/1362361307075702
   Khalfa S, 2004, HEARING RES, V198, P87, DOI 10.1016/j.heares.2004.07.006
   Kogan MD, 2018, PEDIATRICS, V142, DOI 10.1542/peds.2017-4161
   Korostenskaja M, 2009, CURR PHARM DESIGN, V15, P2573, DOI 10.2174/138161209788957474
   Korpilahti P, 2007, J AUTISM DEV DISORD, V37, P1539, DOI 10.1007/s10803-006-0271-2
   KRAUS N, 1993, ELECTROEN CLIN NEURO, V88, P123, DOI 10.1016/0168-5597(93)90063-U
   Kruiper C, 2019, NEUROPSYCHOPHARMACOL, V44, P1062, DOI 10.1038/s41386-019-0351-6
   Kuhl PK, 2005, DEVELOPMENTAL SCI, V8, pF1, DOI 10.1111/j.1467-7687.2004.00384.x
   Kujala T, 2007, BIOL PSYCHOL, V75, P109, DOI 10.1016/j.biopsycho.2006.12.007
   Kujala T, 2005, NEUROSCI LETT, V383, P260, DOI 10.1016/j.neulet.2005.04.048
   Kujala T, 2010, CLIN NEUROPHYSIOL, V121, P1410, DOI 10.1016/j.clinph.2010.03.017
   Lam KSL, 2007, J AUTISM DEV DISORD, V37, P855, DOI 10.1007/s10803-006-0213-z
   Lepisto T, 2006, CLIN NEUROPHYSIOL, V117, P2161, DOI 10.1016/j.clinph.2006.06.709
   Lepisto T, 2005, BRAIN RES, V1066, P147, DOI 10.1016/j.brainres.2005.10.052
   Lepisto T, 2007, NEUROSCI LETT, V414, P136, DOI 10.1016/j.neulet.2006.12.009
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   Lumaca M, 2019, EUR J NEUROSCI, V49, P1597, DOI 10.1111/ejn.14329
   Lumaca M, 2018, SOC COGN AFFECT NEUR, V13, P877, DOI 10.1093/scan/nsy054
   Gonzalez-Gadea ML, 2015, J NEUROPHYSIOL, V114, P2625, DOI 10.1152/jn.00543.2015
   Macdonald M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076897
   Marco EJ, 2011, PEDIATR RES, V69, p48R, DOI [10.1203/PDR.0b013e3182130c54, 10.1109/SPL.2011.5782616]
   Molholm S, 2005, CEREB CORTEX, V15, P545, DOI 10.1093/cercor/bhh155
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   NOVICK B, 1980, PSYCHIAT RES, V3, P107, DOI 10.1016/0165-1781(80)90052-9
   O'Connor K, 2012, NEUROSCI BIOBEHAV R, V36, P836, DOI 10.1016/j.neubiorev.2011.11.008
   OADES RD, 1988, INT J PSYCHOPHYSIOL, V6, P25, DOI 10.1016/0167-8760(88)90032-3
   Paul R, 2007, J SPEECH LANG HEAR R, V50, P1350, DOI 10.1044/1092-4388(2007/094)
   Pellicano E, 2012, TRENDS COGN SCI, V16, P504, DOI 10.1016/j.tics.2012.08.009
   Quiroga-Martinez DR, 2019, CORTEX, V120, P181, DOI 10.1016/j.cortex.2019.06.010
   Ritter W, 2002, PSYCHOPHYSIOLOGY, V39, P158, DOI 10.1017/S0048577201392053
   Ritter W, 2006, PSYCHOPHYSIOLOGY, V43, P423, DOI 10.1111/j.1469-8986.2006.00423.x
   Roberts TPL, 2011, BIOL PSYCHIAT, V70, P263, DOI 10.1016/j.biopsych.2011.01.015
   Rosburg T, 2005, BRAIN, V128, P819, DOI 10.1093/brain/awh442
   Rosburg T, 2004, NEUROPSYCHOPHARMACOL, V29, P1723, DOI 10.1038/sj.npp.1300477
   Sawada M, 2010, PSYCHIAT CLIN NEUROS, V64, P491, DOI 10.1111/j.1440-1819.2010.02134.x
   Schwartz S, 2018, NEUROSCI BIOBEHAV R, V87, P106, DOI 10.1016/j.neubiorev.2018.01.008
   Shafer VL, 2000, EAR HEARING, V21, P242, DOI 10.1097/00003446-200006000-00008
   Taylor MJ, 2002, DEVELOPMENTAL SCI, V5, P318, DOI 10.1111/1467-7687.00372
   TAYLOR MJ, 1993, BIOL PSYCHOL, V36, P139, DOI 10.1016/0301-0511(93)90015-Z
   Tecchio F, 2003, BIOL PSYCHIAT, V54, P647, DOI 10.1016/S0006-3223(03)00295-6
   Teder-Salejarvi WA, 2005, COGNITIVE BRAIN RES, V23, P221, DOI 10.1016/j.cogbrainres.2004.10.021
   Umbricht D, 1999, INT J NEUROPSYCHOP, V2, P299, DOI 10.1017/S1461145799001595
   Vlaskamp C, 2017, AUTISM RES, V10, P1857, DOI 10.1002/aur.1821
   Wacongne C, 2012, J NEUROSCI, V32, P3665, DOI 10.1523/JNEUROSCI.5003-11.2012
   Walsh KS, 2020, ANN NY ACAD SCI, V1464, P242, DOI 10.1111/nyas.14321
   Wechsler D., 2011, WECHSLER ABBREVIATED
   Weismuller B, 2015, J AUTISM DEV DISORD, V45, P2168, DOI 10.1007/s10803-015-2385-x
   Weissgerber TL, 2017, J BIOL CHEM, V292, P20592, DOI 10.1074/jbc.RA117.000147
   Whitehouse AJO, 2008, DEVELOPMENTAL SCI, V11, P516, DOI 10.1111/j.1467-7687.2008.00697.x
   Wienberg M, 2010, J PSYCHOPHARMACOL, V24, P1183, DOI 10.1177/0269881109102606
   Wiens S, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146567
   Yamamuro K., 2016, NEUROREPORT, V10, P3341
   Yamamuro K, 2016, PSYCHIAT RES, V245, P217, DOI 10.1016/j.psychres.2016.07.031
   Yamamuro K, 2016, PSYCHIAT RES, V242, P288, DOI 10.1016/j.psychres.2016.05.061
   Ylinen S, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12472
   Yu LD, 2015, J AUTISM DEV DISORD, V45, P3656, DOI 10.1007/s10803-015-2510-x
   Zhou ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0052186
NR 93
TC 0
Z9 0
U1 7
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1939-3792
EI 1939-3806
J9 AUTISM RES
JI Autism Res.
PD DEC
PY 2020
VL 13
IS 12
BP 2058
EP 2072
DI 10.1002/aur.2362
EA SEP 2020
PG 15
WC Behavioral Sciences; Psychology, Developmental
SC Behavioral Sciences; Psychology
GA PG3IQ
UT WOS:000565422900001
PM 32881408
DA 2021-02-24
ER

PT J
AU Metzger, BA
   Magnotti, JF
   Wang, ZJ
   Nesbitt, E
   Karas, PJ
   Yoshor, D
   Beauchamp, MS
AF Metzger, Brian A.
   Magnotti, John F.
   Wang, Zhengjia
   Nesbitt, Elizabeth
   Karas, Patrick J.
   Yoshor, Daniel
   Beauchamp, Michael S.
TI Responses to Visual Speech in Human Posterior Superior Temporal Gyrus
   Examined with iEEG Deconvolution
SO JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE audiovisual; human; intracranial; multisensory; speech perception;
   superior temporal gyrus
ID SURFACE-BASED ANALYSIS; AUDITORY-CORTEX; MULTISENSORY INTEGRATION;
   AUDIOVISUAL INTERACTIONS; ACTIVATION; VOICE; POTENTIALS; PERCEPTION;
   PREDICTION; SOFTWARE
AB Experimentalists studying multisensory integration compare neural responses to multisensory stimuli with responses to the component modalities presented in isolation. This procedure is problematic for multisensory speech perception since audiovisual speech and auditory-only speech are easily intelligible but visual-only speech is not. To overcome this confound, we developed intracranial encephalography (iEEG) deconvolution. Individual stimuli always contained both auditory and visual speech, but littering the onset asynchrony between modalities allowed for the time course of the unisensory responses and the interaction between them to be independently estimated. We applied this procedure to electrodes implanted in human epilepsy patients (both male and female) over the posterior superior temporal gyrus (pSTG), a brain area known to be important for speech perception. iEEG deconvolution revealed sustained positive responses to visual-only speech and larger, phasic responses to auditory-only speech. Confirming results from scalp EEG, responses to audiovisual speech were weaker than responses to auditory-only speech, demonstrating a subadditive multisensory neural computation. Leveraging the spatial resolution of iEEG, we extended these results to show that subadditivity is most pronounced in more posterior aspects of the pSTG. Across electrodes, subadditivity correlated with visual responsiveness, supporting a model in which visual speech enhances the efficiency of auditory speech processing in pSTG. The ability to separate neural processes may make iEEG deconvolution useful for studying a variety of complex cognitive and perceptual tasks.
C1 [Metzger, Brian A.; Magnotti, John F.; Wang, Zhengjia; Nesbitt, Elizabeth; Karas, Patrick J.; Yoshor, Daniel; Beauchamp, Michael S.] Baylor Coll Med, Dept Neurosurg, Houston, TX 77030 USA.
RP Beauchamp, MS (corresponding author), Baylor Coll Med, Dept Neurosurg, Houston, TX 77030 USA.
EM michael.beauchamp@bcm.edu
OI Beauchamp, Michael/0000-0002-7599-9934; Magnotti,
   John/0000-0003-2093-0603
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01NS065395,
   U01NS113339, R24MH117529, R25NS070694]
FX This work was supported by National Institutes of Health Grants
   R01NS065395, U01NS113339, R24MH117529, and R25NS070694.
CR Argall BD, 2006, HUM BRAIN MAPP, V27, P14, DOI 10.1002/hbm.20158
   Baddeley A, 2012, ANNU REV PSYCHOL, V63, P1, DOI 10.1146/annurev-psych-120710-100422
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beauchamp MS, 2005, NEUROINFORMATICS, V3, P93, DOI 10.1385/NI:3:2:093
   Beauchamp MS, 2004, NAT NEUROSCI, V7, P1190, DOI 10.1038/nn1333
   Beauchamp MS, 2019, MULTISENSORY PROCESS, P161
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Bernstein LE, 2011, HUM BRAIN MAPP, V32, P1660, DOI 10.1002/hbm.21139
   Besle J, 2004, EUR J NEUROSCI, V20, P2225, DOI 10.1111/j.1460-9568.2004.03670.x
   Besle J, 2008, J NEUROSCI, V28, P14301, DOI 10.1523/JNEUROSCI.2875-08.2008
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Burock MA, 1998, NEUROREPORT, V9, P3735, DOI 10.1097/00001756-199811160-00030
   Buzsaki G, 2012, NAT REV NEUROSCI, V13, P407, DOI 10.1038/nrn3241
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Calvert GA, 1999, NEUROREPORT, V10, P2619, DOI 10.1097/00001756-199908200-00033
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Cohen MX, 2014, ISS CLIN COGN NEUROP, P1
   Conrey B. L, 2004, RES SPOKEN LANGUAGE, V26, P71
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   Dale AM, 1999, 5 INT C FUNCT MAPP H
   Dandekar S, 2012, J NEUROPHYSIOL, V107, P1776, DOI 10.1152/jn.00237.2011
   Ferraro S, 2020, CORTEX, V126, P253, DOI 10.1016/j.cortex.2019.12.032
   Fischl B, 1999, HUM BRAIN MAPP, V8, P272, DOI 10.1002/(SICI)1097-0193(1999)8:4<272::AID-HBM10>3.0.CO;2-4
   Fischl B, 1999, NEUROIMAGE, V9, P195, DOI 10.1006/nimg.1998.0396
   Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318
   Friston KJ, 1996, NEUROIMAGE, V4, P97, DOI 10.1006/nimg.1996.0033
   Ganesh AC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01340
   Glover GH, 1999, NEUROIMAGE, V9, P416, DOI 10.1006/nimg.1998.0419
   Golan T, 2016, ELIFE, V5, DOI 10.7554/eLife.17243
   Golumbic EZ, 2013, J NEUROSCI, V33, P1417, DOI 10.1523/JNEUROSCI.3675-12.2013
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Groppe DM, 2017, J NEUROSCI METH, V281, P40, DOI 10.1016/j.jneumeth.2017.01.022
   Hamilton LS, 2018, CURR BIOL, V28, P1860, DOI 10.1016/j.cub.2018.04.033
   Heald SLM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00035
   Henson R, 2004, HUMAN BRAIN FUNCTION
   Hickok Gregory, 2015, Handb Clin Neurol, V129, P149, DOI 10.1016/B978-0-444-62630-1.00008-1
   Holmes CJ, 1998, J COMPUT ASSIST TOMO, V22, P324, DOI 10.1097/00004728-199803000-00032
   Karas PJ, 2019, ELIFE, V8, DOI 10.7554/eLife.48116
   Kayser C, 2008, CEREB CORTEX, V18, P1560, DOI 10.1093/cercor/bhm187
   Kleiner M, 2007, PERCEPTION, V36, P14
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Lachs L, 1998, RES SPOKEN LANGUAGE, V22, P377
   Laurienti PJ, 2005, EXP BRAIN RES, V166, P289, DOI 10.1007/s00221-005-2370-2
   Leaver AM, 2016, J NEUROSCI, V36, P1416, DOI 10.1523/JNEUROSCI.0226-15.2016
   Leszczynski M, 2019, BIORXIV, DOI [10.1101/531368, DOI 10.1101/531368]
   Magnotti JF, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00798
   Megevand P, 2018, PHASE RESETTING HUMA, DOI [10.1101/, DOI 10.1101/]
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Mirpour K, 2018, P NATL ACAD SCI USA, V115, P804, DOI 10.1073/pnas.1716315115
   Moerel M, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00225
   Moradi S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00359
   Nath AR, 2011, J NEUROSCI, V31, P1704, DOI 10.1523/JNEUROSCI.4853-10.2011
   Okada K, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068959
   Ozker M, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00141
   Ozker M, 2018, ELIFE, V7, DOI 10.7554/eLife.30387
   Ozker M, 2017, J COGNITIVE NEUROSCI, V29, P1044, DOI 10.1162/jocn_a_01110
   Paris T, 2017, NEUROSCIENCE, V343, P157, DOI 10.1016/j.neuroscience.2016.09.023
   Peelle JE, 2015, CORTEX, V68, P169, DOI 10.1016/j.cortex.2015.03.006
   Pekkola J, 2005, NEUROREPORT, V16, P125, DOI 10.1097/00001756-200502080-00010
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Picton T, 2013, EAR HEARING, V34, P385, DOI 10.1097/AUD.0b013e31827ada02
   Pilling M, 2009, J SPEECH LANG HEAR R, V52, P1073, DOI [10.1044/1092-4388, 10.1044/1092-4388(2009/07-0276)]
   Ray S, 2008, J NEUROSCI, V28, P11526, DOI 10.1523/JNEUROSCI.2848-08.2008
   Ray S, 2011, PLOS BIOL, V9, DOI 10.1371/journal.pbio.1000610
   Rennig J, 2018, NEUROIMAGE, V183, P25, DOI 10.1016/j.neuroimage.2018.08.008
   Rhone AE, 2016, LANG COGN NEUROSCI, V31, P284, DOI 10.1080/23273798.2015.1101145
   Sack AT, 2008, J NEUROSCI, V28, P8417, DOI 10.1523/JNEUROSCI.2656-08.2008
   Schepers IM, 2015, CEREB CORTEX, V25, P4103, DOI 10.1093/cercor/bhu127
   Schwartz JL, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003743
   Shahin AJ, 2018, J NEUROSCI, V38, P1835, DOI 10.1523/JNEUROSCI.1566-17.2017
   Shahin AJ, 2012, NEUROIMAGE, V60, P530, DOI 10.1016/j.neuroimage.2011.11.097
   Sjerps MJ, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10365-z
   Sohoglu E, 2016, P NATL ACAD SCI USA, V113, pE1747, DOI 10.1073/pnas.1523266113
   Stein B. E., 1993, MERGING SENSES
   Stein BE, 2008, NAT REV NEUROSCI, V9, P255, DOI 10.1038/nrn2331
   Tuennerhoff J, 2016, NEUROIMAGE, V124, P641, DOI 10.1016/j.neuroimage.2015.09.004
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   Werner S, 2010, CEREB CORTEX, V20, P1829, DOI 10.1093/cercor/bhp248
   Westfall Jacob, 2016, Wellcome Open Res, V1, P23, DOI 10.12688/wellcomeopenres.10298.2
   Wright TM, 2003, CEREB CORTEX, V13, P1034, DOI 10.1093/cercor/13.10.1034
   Zhu LL, 2017, J NEUROSCI, V37, P2697, DOI 10.1523/JNEUROSCI.2914-16.2017
NR 85
TC 0
Z9 0
U1 0
U2 0
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
SN 0270-6474
EI 1529-2401
J9 J NEUROSCI
JI J. Neurosci.
PD SEP 2
PY 2020
VL 40
IS 36
BP 6938
EP 6948
DI 10.1523/JNEUROSCI.0279-20.2020
PG 11
WC Neurosciences
SC Neurosciences & Neurology
GA NK4HI
UT WOS:000566692800002
PM 32727820
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Rato, A
   Carlet, A
AF Rato, Anabela
   Carlet, Angelica
TI SECOND LANGUAGE PERCEPTION OF ENGLISH VOWELS BY PORTUGUESE LEARNERS: THE
   EFFECT OF STIMULUS TYPE
SO ILHA DO DESTERRO-A JOURNAL OF ENGLISH LANGUAGE LITERATURES IN ENGLISH
   AND CULTURAL STUDIES
LA English
DT Article
DE L2 Speech Perception; English Vowels; Portuguese Learners; Stimulus type
ID FOREIGN-LANGUAGE PRONUNCIATION; LEXICAL REPRESENTATIONS; SPEAKERS; L2;
   EXPERIENCE; ACCENT; AGE
AB The study investigated the effect of stimulus type on L2 English vowel perception and it also examined the relation between subject factors and L2 learners' performance. Twenty-nine adult Portuguese learners of English were tested on six English vowels (/i: I epsilon ae 3: Lambda/) with two tasks, differing in stimulus type: real and pseudo words. The language background data was collected with a questionnaire. Results confirmed the Portuguese learners' difficulties in accurately categorizing the target vowels, particularly when identifying the L2 vowel sounds embedded in pseudo words, which suggests that L2 phonological categories may be established after lexical forms. Furthermore, a significant correlation was found between L2 language use and accurate perception of four of the target vowels, which indicates that the more frequently learners use the target language, the more accurate is their L2 English vowel perception.
C1 [Rato, Anabela] Univ Toronto, Dept Spanish & Portuguese, Toronto, ON, Canada.
   [Carlet, Angelica] Univ Int Catalunya UIC, Fac Educ, Barcelona, Spain.
RP Rato, A (corresponding author), Univ Toronto, Dept Spanish & Portuguese, Toronto, ON, Canada.
EM anabela.rato@utoronto.ca; acarlet@uic.es
CR Aliaga-Garcia C., 2010, NEW SOUNDS 2010, P2
   Aliaga-Garcia C., 2017, THESIS
   Amengual M, 2016, APPL PSYCHOLINGUIST, V37, P1221, DOI 10.1017/S0142716415000557
   Barroso H., 1999, FORMA SUBSTANCIA EXP
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bion R., 2006, INTERSPEECH 2006 ICS, P17
   Bohn O-S., 2017, HDB PSYCHOLINGUISTIC, P213
   Bundgaard-Nielsen RL, 2012, APPL PSYCHOLINGUIST, V33, P643, DOI 10.1017/S0142716411000518
   Bundgaard-Nielsen RL, 2011, STUD SECOND LANG ACQ, V33, P433, DOI 10.1017/S0272263111000040
   Bundgaard-Nielsen RL, 2011, APPL PSYCHOLINGUIST, V32, P51, DOI 10.1017/S0142716410000287
   Carlet A., 2008, ILHA DESTERRO, V71, P99
   Carlet A., 2015, P 18 INT C PHON SCI
   Carlet A., 2017, THESIS
   Cebrian J., 2010, P 6 INT S ACQ 2 LANG, P77
   Cebrian J, 2006, J PHONETICS, V34, P372, DOI 10.1016/j.wocn.2005.08.003
   Cervino E., 2009, J ACOUST SOC AM, V125, P2764
   Cruttenden Alan, 2014, GIMSONS PRONUNCIATIO
   Cruz-Ferreira Madalena, 1995, J INT PHON ASSOC, V25, P90, DOI [10.1017/S0025100300005223, DOI 10.1017/S0025100300005223]
   Cutler A, 2006, J PHONETICS, V34, P269, DOI 10.1016/j.wocn.2005.06.002
   Darcy I, 2013, MENT LEX, V8, P372, DOI 10.1075/ml.8.3.06dar
   Doty A. Z., 2009, J ACOUST SOC AM, V125, P2765
   Eisner F, 2018, STEVENS HDB EXPT PSY, P1
   Escudero P, 2010, LANG SPEECH, V53, P343, DOI 10.1177/0023830910371447
   Escudero P, 2009, J ACOUST SOC AM, V126, P1379, DOI 10.1121/1.3180321
   Fife-Schaw C., 2006, RES METHODS PSYCHOL, P50
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2001, STUDIES 2 LANGUAGE A, V23, P527
   Flege JE, 1997, J PHONETICS, V25, P169, DOI 10.1006/jpho.1996.0040
   FLEGE JE, 1995, J ACOUST SOC AM, V97, P3125, DOI 10.1121/1.413041
   FLEGE JE, 1995, SPEECH COMMUN, V16, P1, DOI 10.1016/0167-6393(94)00044-B
   Flege JE, 2004, STUD SECOND LANG ACQ, V26, P1, DOI 10.1017/S0272263104261010
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   FLEGE JE, 1992, J ACOUST SOC AM, V91, P370, DOI 10.1121/1.402780
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   Jia G, 2006, J ACOUST SOC AM, V119, P1118, DOI 10.1121/1.2151806
   Kissling EM, 2014, CAN MOD LANG REV, V70, P532, DOI 10.3138/cmlr.2161
   Kivisto-de Souza H, 2017, ILHA DESTERRO, V70, P33, DOI 10.5007/2175-8026.2017v70n3p33
   Lord G, 2005, HISPANIA-J DEV INTER, V88, P557, DOI 10.2307/20063159
   Mateus Maria Helena, 2005, FONETICA FONOLOGIA P
   Meara P., 2005, DYNAMICS LANGUAGE US, P271, DOI DOI 10.1075/PBNS.140.19MEA
   Meara P. M., 2006, X LEX SWANSEA ADV VO
   Moyer A., 2013, FOREIGN ACCENT PHENO
   Nobre-Oliveira D., 2007, THESIS
   Piske T, 2001, J PHONETICS, V29, P191, DOI 10.1006/jpho.2001.0134
   Piske T., 2007, LANGUAGE EXPERIENCE, P301, DOI [10.1075/lllt.17.26pis, DOI 10.1075/LLLT.17.26PIS]
   Rato A., 2014, DIACRITICA SERIE CIE, V28, P137
   Rato A., 2018, LINGUISTICA ESTUDOS, V14, P61
   Rato A., 2014, CONCORDIA WORKING PA, V5, P529
   Rato A., 2015, P ICPHS 2015 U GLASG
   Rauber A., 2012, TP VERSION 3 1
   Rauber A. S., 2010, DIACRITICA, V24, P5
   Rauber A. S., 2010, ACOUSTIC CHARACTERIS
   Rauber A. S., 2005, P INT 2005, P2913
   Roach P., 2004, ENGLISH PHONETICS PH
   Sole M.J., 2013, P 6 PHON PHON IB C, P58
   Strange W., 2007, LANGUAGE EXPERIENCE, P35, DOI DOI 10.1075/LLLT.17.08STR
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0
NR 58
TC 0
Z9 0
U1 1
U2 1
PU UNIV FEDERAL SANTA CATARINA, PROGRAMA POS-GRADUACAO & LETRAS-INGLES
PI FLORIANOPOLIS
PA SALA 120, CCE-B, UFSC, CAMPUS UNIV, FLORIANOPOLIS, SC 88040-900, BRAZIL
SN 0101-4846
EI 2175-8026
J9 ILHA DESTERRO
JI Ilha Desterro
PD SEP-DEC
PY 2020
VL 73
IS 3
BP 205
EP 225
DI 10.5007/2175-8026.2020v73n3p205
PG 21
WC Literature
SC Literature
GA OV2OH
UT WOS:000592055600010
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Yu, ACL
   To, CKS
AF Yu, Alan Chi Lun
   To, Carol Kit Sum
TI Atypical context-dependent speech processing in autism
SO APPLIED PSYCHOLINGUISTICS
LA English
DT Article
DE context-dependent speech perception; high-functioning autism; sound
   discrimination; sibilant perception
ID PERCEPTUAL COMPENSATION; COARTICULATION; INDIVIDUALS; DISCRIMINATION
AB The ability to take contextual information into account is essential for successful speech processing. This study examines individuals with high-functioning autism and those without in terms of how they adjust their perceptual expectation while discriminating speech sounds in different phonological contexts. Listeners were asked to discriminate pairs of sibilant-vowel monosyllables. Typically, discriminability of sibilants increases when the sibilants are embedded in perceptually enhancing contexts (if the appropriate context-specific perceptual adjustment were performed) and decreases in perceptually diminishing contexts. This study found a reduction in the differences in perceptual response across enhancing and diminishing contexts among high-functioning autistic individuals relative to the neurotypical controls. The reduction in perceptual expectation adjustment is consistent with an increase in autonomy in low-level perceptual processing in autism and a reduction in the influence of top-down information from surrounding information.
C1 [Yu, Alan Chi Lun] Univ Chicago, Chicago, IL 60637 USA.
   [To, Carol Kit Sum] Univ Hong Kong, Hong Kong, Peoples R China.
RP Yu, ACL (corresponding author), Univ Chicago, Chicago, IL 60637 USA.
EM aclyu@uchicago.edu
FU National Science FoundationNational Science Foundation (NSF)
   [BCS-0949754, BCS-1827409]
FX This research was partly supported by National Science Foundation Grants
   BCS-0949754 and BCS-1827409. Many thanks to the anonymous reviewers and
   the handling associate editor for their valuable comments and
   suggestions. Naturally, any errors in this work are our own.
CR American Speech-Language-Hearing Association Audiologic Assessment Panel, 1997, GUID AUD SCREEN
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Bilker WB, 2012, ASSESSMENT, V19, P354, DOI 10.1177/1073191112446655
   Bonnel A, 2003, J COGNITIVE NEUROSCI, V15, P226, DOI 10.1162/089892903321208169
   Van de Cruys S, 2014, PSYCHOL REV, V121, P649, DOI 10.1037/a0037665
   DiLavore P. C., 2012, AUTISM DIAGNOSTIC OB
   Happe F, 1999, TRENDS COGN SCI, V3, P216, DOI 10.1016/S1364-6613(99)01318-2
   Heaton P, 2008, NEUROPSYCHOLOGIA, V46, P2095, DOI 10.1016/j.neuropsychologia.2008.02.006
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   MANN VA, 1986, COGNITION, V24, P169, DOI 10.1016/S0010-0277(86)80001-4
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P213, DOI 10.3758/BF03204377
   Mirman D., 2014, GROWTH CURVE ANAL VI
   Mitterer H, 2006, PERCEPT PSYCHOPHYS, V68, P1227, DOI 10.3758/BF03193723
   Mottron L, 2006, J AUTISM DEV DISORD, V36, P27, DOI 10.1007/s10803-005-0040-7
   O'Connor K, 2012, NEUROSCI BIOBEHAV R, V36, P836, DOI 10.1016/j.neubiorev.2011.11.008
   Ohala J. J., 1993, HIST LINGUISTICS PRO, P237
   OHALA JJ, 1993, LANG SPEECH, V36, P155, DOI 10.1177/002383099303600303
   Ota M, 2015, J SPEECH LANG HEAR R, V58, P422, DOI 10.1044/2015_JSLHR-L-14-0061
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   REPP BH, 1981, PERCEPT PSYCHOPHYS, V30, P217, DOI 10.3758/BF03214276
   Sjerps MJ, 2011, NEUROPSYCHOLOGIA, V49, P3831, DOI 10.1016/j.neuropsychologia.2011.09.044
   Stephens JDW, 2003, J ACOUST SOC AM, V114, P3036, DOI 10.1121/1.1627837
   Stewart ME, 2018, J AUTISM DEV DISORD, V48, P72, DOI 10.1007/s10803-017-3284-0
   Stewart ME, 2008, COGNITION, V109, P157, DOI 10.1016/j.cognition.2008.07.010
   Turnbull Rory John, 2015, THESIS
   Viswanathan N, 2010, J EXP PSYCHOL HUMAN, V36, P1005, DOI 10.1037/a0018391
   Walenski M., 2006, UNDERSTANDING AUTISM, P175
   WHO, 1990, INT CLASS DIS
   You RS, 2017, RES DEV DISABIL, V61, P158, DOI 10.1016/j.ridd.2016.12.009
   Yu ACL, 2019, LAB PHONOL, V10, DOI 10.5334/labphon.97
   Yu ACL, 2016, J ACOUST SOC AM, V139, P1672, DOI 10.1121/1.4944992
   Yu ACL, 2014, J ACOUST SOC AM, V136, P382, DOI 10.1121/1.4883380
   Yu ACL, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011950
NR 33
TC 0
Z9 0
U1 0
U2 0
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0142-7164
EI 1469-1817
J9 APPL PSYCHOLINGUIST
JI Appl. Psycholinguist.
PD SEP
PY 2020
VL 41
IS 5
BP 1045
EP 1059
AR PII S0142716420000387
DI 10.1017/S0142716420000387
PG 15
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA OO9GY
UT WOS:000587682800003
DA 2021-02-24
ER

PT J
AU Kazazian, K
   Norton, L
   Gofton, TE
   Debicki, D
   Owen, AM
AF Kazazian, Karnig
   Norton, Loretta
   Gofton, Teneille E.
   Debicki, Derek
   Owen, Adrian M.
TI Cortical Function in Acute Severe Traumatic Brain Injury and at
   Recovery: A Longitudinal fMRI Case Study
SO BRAIN SCIENCES
LA English
DT Article
DE coma; consciousness; awareness; disorders of consciousness; traumatic
   brain injury
ID DEFAULT MODE NETWORK; COMATOSE SURVIVORS; SPOKEN LANGUAGE;
   CONSCIOUSNESS; DISORDERS; STATE; CONNECTIVITY; SPEECH; ACTIVATION; SCALE
AB Differences in the functional integrity of the brain from acute severe brain injury to subsequent recovery of consciousness have not been well documented. Functional magnetic resonance imaging (fMRI) may elucidate this issue as it allows for the objective measurement of brain function both at rest and in response to stimuli. Here, we report the cortical function of a patient with a severe traumatic brain injury (TBI) in a critically ill state and at subsequent functional recovery 9-months post injury. A series of fMRI paradigms were employed to assess sound and speech perception, command following, and resting state connectivity. The patient retained sound perception and speech perception acutely, as indexed by his fMRI responses. Command following was absent acutely, but was present at recovery. Increases in functional connectivity across multiple resting state networks were observed at recovery. We demonstrate the clinical utility of fMRI in assessing cortical function in a patient with severe TBI. We suggest that hallmarks of the recovery of consciousness are associated with neural activity to higher-order cognitive tasks and increased resting state connectivity.
C1 [Kazazian, Karnig; Owen, Adrian M.] Western Univ, Brain & Mind Inst, London, ON N6A 3K7, Canada.
   [Kazazian, Karnig] Western Univ, Grad Program Neurosci, London, ON N6A 3K7, Canada.
   [Norton, Loretta] Western Univ, Kings Univ Coll, Dept Psychol, London, ON N6A 3K7, Canada.
   [Gofton, Teneille E.; Debicki, Derek] Western Univ, Dept Clin Neurol Sci, London, ON N6A 3K7, Canada.
   [Owen, Adrian M.] Western Univ, Dept Physiol & Pharmacol, London, ON N6A 3K7, Canada.
   [Owen, Adrian M.] Western Univ, Dept Psychol, London, ON N6A 3K7, Canada.
RP Kazazian, K (corresponding author), Western Univ, Brain & Mind Inst, London, ON N6A 3K7, Canada.; Kazazian, K (corresponding author), Western Univ, Grad Program Neurosci, London, ON N6A 3K7, Canada.
EM kkazazia@uwo.ca; lnorton5@uwo.ca; teneille.gofton@lhsc.on.ca;
   derek.debicki@lhsc.on.ca; uwocerc@uwo.ca
OI Owen, Adrian/0000-0002-5738-3765; Kazazian, Karnig/0000-0001-6157-601X
FU Canada Excellence Research Chairs (CERC) program [215063]; Canadian
   Institutes of Health Research (CIHR)Canadian Institutes of Health
   Research (CIHR) [408004]; Natural Sciences and Engineering Research
   Council of CanadaNatural Sciences and Engineering Research Council of
   Canada (NSERC)CGIAR [RGPIN-2018-05878]
FX This research was funded by the Canada Excellence Research Chairs (CERC)
   program (#215063), the Canadian Institutes of Health Research (CIHR,
   #408004), and the Natural Sciences and Engineering Research Council of
   Canada (RGPIN-2018-05878).
CR Vieira RDA, 2016, FRONT NEUROL, V7, DOI 10.3389/fneur.2016.00178
   Baars BJ, 2005, PROG BRAIN RES, V150, P45, DOI 10.1016/S0079-6123(05)50004-9
   Bateman DE, 2001, J NEUROL NEUROSUR PS, V71, P13
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   Bodien YG, 2016, ARCH PHYS MED REHAB, V97, P490, DOI 10.1016/j.apmr.2015.08.422
   Coleman MR, 2009, BRAIN, V132, P2541, DOI 10.1093/brain/awp183
   Cooksley T, 2018, CLIN MED, V18, P88, DOI 10.7861/clinmedicine.18-1-88
   D'Arcy RCN, 2016, J HEAD TRAUMA REHAB, V31, pE50, DOI 10.1097/HTR.0000000000000185
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Demertzi A, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aat7603
   Edlow BL, 2018, J HEAD TRAUMA REHAB, V33, P424, DOI 10.1097/HTR.0000000000000448
   Edlow BL, 2017, BRAIN, V140, P2399, DOI 10.1093/brain/awx176
   Fernandez-Espejo D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095082
   Gofton TE, 2009, EXP NEUROL, V217, P320, DOI 10.1016/j.expneurol.2009.03.011
   Green SM, 2011, ANN EMERG MED, V58, P427, DOI 10.1016/j.annemergmed.2011.06.009
   Johnstone T, 2006, HUM BRAIN MAPP, V27, P779, DOI 10.1002/hbm.20219
   Kirsch M, 2017, ANESTH ANALG, V124, P588, DOI 10.1213/ANE.0000000000001721
   Koenig MA, 2014, NEUROCRIT CARE, V20, P348, DOI 10.1007/s12028-014-9953-3
   Leunissen I, 2013, HUM BRAIN MAPP, V34, P1254, DOI 10.1002/hbm.21508
   Madhavan R, 2019, J NEUROTRAUM, V36, P650, DOI 10.1089/neu.2018.5739
   Mayor SA, 1999, NEUROLOGY, V52, P1602, DOI 10.1212/WNL.52.8.1602
   Monti MM, 2010, NEW ENGL J MED, V362, P579, DOI 10.1056/NEJMoa0905370
   Moritz CH, 2001, MAGN RESON IMAGING, V19, P1129, DOI 10.1016/S0730-725X(01)00432-5
   Norton L, 2012, NEUROLOGY, V78, P175, DOI 10.1212/WNL.0b013e31823fcd61
   Norton L., FUNCTIONAL NEUROIMAG
   Owen AM, 2006, SCIENCE, V313, P1402, DOI 10.1126/science.1130197
   Palacios EM, 2017, J NEUROTRAUM, V34, P1546, DOI 10.1089/neu.2016.4752
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Rodd JM, 2005, CEREB CORTEX, V15, P1261, DOI 10.1093/cercor/bhi009
   Rohaut B, 2019, CRIT CARE, V23, DOI 10.1186/s13054-019-2370-4
   Sair HI, 2018, RADIOLOGY, V287, P247, DOI 10.1148/radiol.2017162161
   Sanchez-Carrion R, 2008, NEUROIMAGE, V43, P421, DOI 10.1016/j.neuroimage.2008.08.003
   Schiff ND, 2002, BRAIN, V125, P1210, DOI 10.1093/brain/awf131
   Smith SM, 2009, P NATL ACAD SCI USA, V106, P13040, DOI 10.1073/pnas.0905267106
   Soddu A, 2011, FUNCT NEUROL, V26, P37
   Stevens RD, 2013, CRIT CARE MED, V41, P1104, DOI 10.1097/CCM.0b013e318287ee79
   Teasdale G, 2014, LANCET NEUROL, V13, P844, DOI 10.1016/S1474-4422(14)70120-6
   Tomaiuolo F, 2016, J INT NEUROPSYCH SOC, V22, P620, DOI 10.1017/S1355617716000485
   Weijer C, 2016, BRAIN, V139, P292, DOI 10.1093/brain/awv272
   Wijdicks Eelco F M, 2010, Pract Neurol, V10, P51, DOI 10.1136/jnnp.2009.200097
NR 40
TC 0
Z9 0
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3425
J9 BRAIN SCI
JI Brain Sci.
PD SEP
PY 2020
VL 10
IS 9
AR 604
DI 10.3390/brainsci10090604
PG 13
WC Neurosciences
SC Neurosciences & Neurology
GA OG2OZ
UT WOS:000581731300001
PM 32899145
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Chung, H
   Yim, D
AF Chung, Haeun
   Yim, Dongsun
TI Quick Incidental Learning of Words by Children with and without Specific
   Language Impairment: An Eye-tracking Study
SO COMMUNICATION SCIENCES AND DISORDERS-CSD
LA English
DT Article
DE Quick incidental learning; Eye-tracking; Specific language impairment
ID SCHOOL-AGED CHILDREN; SENTENCE COMPREHENSION; INDIVIDUAL-DIFFERENCES;
   VOCABULARY ACQUISITION; RECEPTIVE VOCABULARY; LEXICAL ACTIVATION;
   AUDITORY ATTENTION; SPEECH-PERCEPTION; VISUAL-ATTENTION; CONTEXT
   EVIDENCE
AB Objectives: This study's goal is to use eye-tracking technology to learn more about children's online novel word-learning processing abilities in a quick incidental learning (QUIL) task to examine how children with and without Specific Language Impairment (SLI) exhibit different patterns when learning new words and how these differences in looking behaviors lead to different learning results. Methods: Twenty typically developing (TD) children (age: M=5.15 years) and 10 children with SLI (age: M=5.11 years) participated in the study. Children completed a QUIL task while their eye movements were recorded using an eye-tracking device. The fixation count number and the average fixation time on target word AOIs (Areas of Interest) were analyzed and heat map analysis was also conducted. Results: The analysis of eye-tracking measures revealed different patterns between groups. The TD group's fixation duration on AOIs gradually increased from first to last exposure, whereas the SLI group showed decreased fixation duration over time. Heat map analysis showed that the SLI group fixated less on target AOIs and their gazes were widely scattered compared to the gazes of the TD group. A positive correlation was observed between the fixation time and learning. Conclusion: For TD, words and their referents were correctly inferred and the association between words and referents was strengthened over time. Children with SLI had difficulty associating novel labels with novel objects, as indexed by less time spent looking at AOIs. This study provides insights into the QUIL of words by children with and without SLI in a natural context.
C1 [Chung, Haeun; Yim, Dongsun] Ewha Womans Univ, Dept Commun Disorders, 52 Ewhayeodae Gil, Seoul 03760, South Korea.
RP Yim, D (corresponding author), Ewha Womans Univ, Dept Commun Disorders, 52 Ewhayeodae Gil, Seoul 03760, South Korea.
EM sunyim@ewha.ac.kr
OI Chung, Haeun/0000-0001-5113-1754
FU Ministry of Science and ICT of the Republic of Korea; National Research
   Foundation of KoreaNational Research Foundation of Korea
   [NRF-2019R1A2C1007488]
FX This work was supported by the Ministry of Science and ICT of the
   Republic of Korea and the National Research Foundation of Korea
   (NRF-2019R1A2C1007488).
CR Akhtar N, 2001, CHILD DEV, V72, P416, DOI 10.1111/1467-8624.00287
   Alt M, 2006, J SPEECH LANG HEAR R, V49, P941, DOI 10.1044/1092-4388(2006/068)
   Alt M, 2013, TOP LANG DISORD, V33, P328, DOI 10.1097/01.TLD.0000437942.85989.73
   Altmann GTM, 2007, J MEM LANG, V57, P502, DOI 10.1016/j.jml.2006.12.004
   Andreu L, 2011, CLIN LINGUIST PHONET, V25, P767, DOI 10.3109/02699206.2011.565542
   Bartolotti J, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00324
   Bergstrom JenniferRomano., 2014, EYE TRACKING USER EX
   Bisson MJ, 2015, Q J EXP PSYCHOL, V68, P1306, DOI 10.1080/17470218.2014.979211
   Bisson MJ, 2014, LANG LEARN, V64, P855, DOI 10.1111/lang.12085
   Borovsky A, 2013, J COMMUN DISORD, V46, P413, DOI 10.1016/j.jcomdis.2013.09.001
   Borovsky A, 2012, J EXP CHILD PSYCHOL, V112, P417, DOI 10.1016/j.jecp.2012.01.005
   Brock J, 2008, COGNITION, V108, P896, DOI 10.1016/j.cognition.2008.06.007
   Chambers CG, 2002, J MEM LANG, V47, P30, DOI 10.1006/jmla.2001.2832
   Chen S., 2011, P 5 BIENN C INN DAT, P21, DOI DOI 10.1145/2029956.2029964
   Colombo J, 2001, ANNU REV PSYCHOL, V52, P337, DOI 10.1146/annurev.psych.52.1.337
   COOPER RM, 1974, COGNITIVE PSYCHOL, V6, P84, DOI 10.1016/0010-0285(74)90005-X
   Desroches AS, 2006, COGNITION, V100, pB32, DOI 10.1016/j.cognition.2005.09.001
   DOLLAGHAN CA, 1987, J SPEECH HEAR DISORD, V52, P218, DOI 10.1044/jshd.5203.218
   Ellis EM, 2015, J COMMUN DISORD, V58, P143, DOI 10.1016/j.jcomdis.2015.06.011
   Engelmann JB, 2009, FRONT HUM NEUROSCI, V3, DOI 10.3389/neuro.09.004.2009
   Evans MA, 2013, J EDUC PSYCHOL, V105, P596, DOI 10.1037/a0032465
   Fernald A, 2012, CHILD DEV, V83, P203, DOI 10.1111/j.1467-8624.2011.01692.x
   Godfroid A., 2010, COGNITIVE PROCESSING, P169, DOI DOI 10.1075/CELCR.13.14GOD
   Godfroid A, 2013, STUD SECOND LANG ACQ, V35, P483, DOI 10.1017/S0272263113000119
   Gordon J., 1992, READING PSYCHOL, V13, P157
   Gray S, 2005, J SPEECH LANG HEAR R, V48, P1452, DOI 10.1044/1092-4388(2005/101)
   Gray S, 2004, J SPEECH LANG HEAR R, V47, P1117, DOI 10.1044/1092-4388(2004/083)
   Gray S, 2006, J SPEECH LANG HEAR R, V49, P955, DOI 10.1044/1092-4388(2006/069)
   Griffin ZM, 2001, COGNITION, V82, pB1, DOI 10.1016/S0010-0277(01)00138-X
   Hanley M, 2014, RES AUTISM SPECT DIS, V8, P908, DOI 10.1016/j.rasd.2014.03.020
   Henderson J. M., 2004, INTERFACE LANGUAGE V, P1, DOI DOI 10.4324/9780203488430
   Henderson J. M., 1998, EYE GUIDANCE READING, P269, DOI DOI 10.1016/B978-008043361-5/50013-4
   Henderson JM, 2003, TRENDS COGN SCI, V7, P498, DOI 10.1016/j.tics.2003.09.006
   Holmqvist K., 2011, EYE TRACKING COMPREH
   Horohov JE, 2004, APPL PSYCHOLINGUIST, V25, P43, DOI 10.1017/S0142716404001031
   Huettig F, 2005, COGNITION, V96, pB23, DOI 10.1016/j.cognition.2004.10.003
   Huettig F, 2011, ACTA PSYCHOL, V137, P151, DOI 10.1016/j.actpsy.2010.11.003
   Hyona J, 2002, J EDUC PSYCHOL, V94, P44, DOI 10.1037//0022-0663.94.1.44
   Jackson E, 2016, INT J LANG COMM DIS, V51, P61, DOI 10.1111/1460-6984.12185
   Johnson SP, 2003, P NATL ACAD SCI USA, V100, P10568, DOI 10.1073/pnas.1630655100
   JUST MA, 1980, PSYCHOL REV, V87, P329, DOI 10.1037/0033-295X.87.4.329
   Kang SN, 2018, COMMUN SCI DISORD-CS, V23, P914, DOI 10.12963/csd.18551
   Kim Y. T., 2003, PRESCHOOL RECEPTIVE
   Libben MR, 2009, J EXP PSYCHOL LEARN, V35, P381, DOI 10.1037/a0014875
   Liversedge SP, 2000, TRENDS COGN SCI, V4, P6, DOI 10.1016/S1364-6613(99)01418-7
   Lum JAG, 2017, J SPEECH LANG HEAR R, V60, P1648, DOI 10.1044/2017_JSLHR-L-16-0158
   Macroy-Higgins M, 2016, J CHILD LANG, V43, P1020, DOI 10.1017/S0305000915000379
   Mani N, 2012, J EXP PSYCHOL HUMAN, V38, P843, DOI 10.1037/a0029284
   McGregor KK, 2002, J SPEECH LANG HEAR R, V45, P332, DOI 10.1044/1092-4388(2002/026)
   McMurray B, 2004, INFANCY, V6, P203, DOI 10.1207/s15327078in0602_4
   McMurray B, 2014, J SPEECH LANG HEAR R, V57, P1344, DOI 10.1044/2014_JSLHR-L-13-0196
   McMurray B, 2010, COGNITIVE PSYCHOL, V60, P1, DOI 10.1016/j.cogpsych.2009.06.003
   Mishra J, 2009, VISION RES, V49, P1073, DOI 10.1016/j.visres.2008.02.018
   Montero Perez M, 2015, MOD LANG J, V99, P308, DOI 10.1111/modl.12215
   Montgomery JW, 2009, APPL PSYCHOLINGUIST, V30, P123, DOI 10.1017/S0142716408090061
   Moon S. B., 2003, KOREAN KAUFMAN ASSES
   Nation K, 2003, J EXP CHILD PSYCHOL, V86, P314, DOI 10.1016/j.jecp.2003.09.001
   Noterdaeme M, 2001, EUR CHILD ADOLES PSY, V10, P58, DOI 10.1007/s007870170048
   OETTING JB, 1995, J SPEECH HEAR RES, V38, P434, DOI 10.1044/jshr.3802.434
   Pellicer-Sanchez A, 2016, STUD SECOND LANG ACQ, V38, P97, DOI 10.1017/S0272263115000224
   Pivneva I, 2014, J EXP PSYCHOL LEARN, V40, P787, DOI 10.1037/a0035583
   Pons F, 2013, J CHILD LANG, V40, P687, DOI 10.1017/S0305000912000189
   Poole A, 2006, ENCY HUMAN COMPUTER, P211, DOI DOI 10.4018/978-1-59140-562-7.CH034
   Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372
   Rayner K, 2006, SCI STUD READ, V10, P241, DOI 10.1207/s1532799xssr1003_3
   Rayner K, 2009, Q J EXP PSYCHOL, V62, P1457, DOI 10.1080/17470210902816461
   Rice M., 1993, FIRST LANG, V13, P113, DOI DOI 10.1177/014272379301303707
   RICE ML, 1992, J SPEECH HEAR RES, V35, P1040, DOI 10.1044/jshr.3505.1040
   RICE ML, 1994, J SPEECH HEAR RES, V37, P106, DOI 10.1044/jshr.3701.106
   RICE ML, 1988, CHILD DEV, V59, P420, DOI 10.1111/j.1467-8624.1988.tb01477.x
   RICE ML, 1990, J SPEECH HEAR DISORD, V55, P33, DOI 10.1044/jshd.5501.33
   Stevens C, 2006, BRAIN RES, V1111, P143, DOI 10.1016/j.brainres.2006.06.114
   Storch SA, 2002, DEV PSYCHOL, V38, P934, DOI 10.1037//0012-1649.38.6.934
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Torppa M, 2010, J LEARN DISABIL-US, V43, P308, DOI 10.1177/0022219410369096
   Trueswell J. C., 2007, OXFORD HDB PSYCHOLIN, P635, DOI [DOI 10.1093/OXFORDHB/9780198568971.013.0039, 10.1093/oxfordhb/9780198568971.013.0039]
   Trueswell JC, 2008, DEVELOPMENTAL PSYCHOLINGUISTICS: ON-LINE METHODS IN CHILDREN'S LANGUAGE PROCESSING, P73
   Williams RS, 2004, EUR J COGN PSYCHOL, V16, P312, DOI 10.1080/09541440340000196
   Wochna KL, 2013, BRIT J PSYCHOL, V104, P347, DOI 10.1111/j.2044-8295.2012.02127.x
   Yang Y, 2018, COMMUN SCI DISORD-CS, V23, P43, DOI 10.12963/csd.18469
   Yang Y, 2015, COMMUN SCI DISORD-CS, V20, P1, DOI 10.12963/csd.14176
   Yang Y, 2013, COMMUN SCI DISORD-CS, V18, P379, DOI 10.12963/csd.13079
   Yarbus A.L., 1967, EYE MOVEMENTS VISION, DOI [10.1007/978-1-4899-5379-7, DOI 10.1007/978-1-4899-5379-7_8]
   Yim D, 2015, COMMUN SCI DISORD-CS, V20, P304, DOI 10.12963/csd.15241
   Yu C, 2011, DEVELOPMENTAL SCI, V14, P165, DOI 10.1111/j.1467-7687.2010.00958.x
NR 85
TC 0
Z9 0
U1 3
U2 3
PU KOREAN ACAD SPEECH-LANGUAGE PATHOLOGY & AUDIOLOGY
PI CHUONGNAM
PA KOREA NAZARENE UNIV, DEPT COMMUNICATION DISORDERS, CHUONGNAM, 331-718,
   SOUTH KOREA
SN 2288-1328
EI 2288-0917
J9 COMMUN SCI DISORD-CS
JI Commun. Sci. Disord.-CSD
PD SEP
PY 2020
VL 25
IS 3
BP 499
EP 516
DI 10.12963/csd.20715
PG 18
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA OE5ZR
UT WOS:000580608900001
OA Other Gold
DA 2021-02-24
ER

PT J
AU Andersen, TS
   Winther, O
AF Andersen, Tobias S.
   Winther, Ole
TI Regularized models of audiovisual integration of speech with predictive
   power for sparse behavioral data
SO JOURNAL OF MATHEMATICAL PSYCHOLOGY
LA English
DT Article
DE Speech perception; Audiovisual integration; Computational models
ID INFORMATION; LIKELIHOOD; PERCEPTION
AB Audiovisual integration can facilitate speech comprehension by integrating information from lip-reading with auditory speech perception. When incongruent acoustic speech is dubbed onto a video of a talking face, this integration can lead to the McGurk illusion of hearing a different phoneme than that spoken by the voice. Several computational models of the information integration process underlying these phenomena exist. All are based on the assumption that the integration process is, in some sense, optimal. They differ, however, in assuming that it is based on either continuous or categorical internal representations. Here we develop models of audiovisual integration of the phonetic information represented on an internal representation that is continuous and cyclical. We compare these models to the Fuzzy Logical Model of Perception (FLMP), which is based on a categorical internal representation. Using cross-validation, we show that model evaluation criteria based on the goodness of-fit are poor measures of the models' generalization error even if they take the number of free parameters into account. We also show that the predictive power of all the models benefit from regularization that limits the precision of the internal representation. Finally, we show that, unlike the FLMP, models based on a continuous internal representation have good predictive power when properly regularized. (c) 2020 Published by Elsevier Inc.
C1 [Andersen, Tobias S.; Winther, Ole] Tech Univ Denmark, Dept Appl Math & Comp Sci, Sect Cognit Syst, Bldg 321, DK-2800 Lyngby, Denmark.
RP Andersen, TS (corresponding author), Tech Univ Denmark, Dept Appl Math & Comp Sci, Sect Cognit Syst, Bldg 321, DK-2800 Lyngby, Denmark.
EM toban@dtu.dk
OI Winther, Ole/0000-0002-1966-3205
CR AKAIKE H, 1981, J ECONOMETRICS, V16, P3, DOI 10.1016/0304-4076(81)90071-3
   Andersen T. S., 2002, 1 INT ICSC C NEUR TE
   Andersen TS, 2015, J ACOUST SOC AM, V137, P2884, DOI 10.1121/1.4916691
   Andersen TS, 2005, NEUROSCI LETT, V380, P155, DOI 10.1016/j.neulet.2005.01.030
   [Anonymous], 2013, OPTIMIZATION TOOLBOX
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   BINNIE CA, 1974, J SPEECH HEAR RES, V17, P619, DOI 10.1044/jshr.1704.619
   Bishop C. M., 2006, PATTERN RECOGNITION
   Burkardt J., 2011, PROB PROBABILITY DEN
   Chang T.-Y., 2019, BIORXIV, DOI [10.1101/611087, DOI 10.1101/611087]
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   Hill G. W., 1977, ACM Transactions on Mathematical Software, V3, P279, DOI 10.1145/355744.355753
   Kording KP, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000943
   MacMillan N. A., 2005, DETECTION THEORY USE
   Magnotti JF, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005229
   Massaro D. W., 1998, PERCEIVING TALKING F
   Massaro DW, 2001, PSYCHON B REV, V8, P1, DOI 10.3758/BF03196136
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Murray RF, 2010, J VISION, V10, DOI 10.1167/10.11.15
   Myung I. J., 2005, HDB COGNITION, DOI [10.4135/9781848608177.n19, DOI 10.4135/9781848608177.N19]
   Myung IJ, 1997, PSYCHON B REV, V4, P79, DOI 10.3758/BF03210778
   Olasagasti I, 2015, CORTEX, V68, P61, DOI 10.1016/j.cortex.2015.04.008
   Schwartz JL, 2006, J ACOUST SOC AM, V120, P1795, DOI 10.1121/1.2258814
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1979, PHONETICA, V36, P314, DOI 10.1159/000259969
   Tiippana K, 2004, EUR J COGN PSYCHOL, V16, P457, DOI 10.1080/09541440340000268
   Tiippana K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00725
NR 29
TC 0
Z9 0
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0022-2496
EI 1096-0880
J9 J MATH PSYCHOL
JI J. Math. Psychol.
PD SEP
PY 2020
VL 98
AR 102404
DI 10.1016/j.jmp.2020.102404
PG 8
WC Mathematics, Interdisciplinary Applications; Social Sciences,
   Mathematical Methods; Psychology, Mathematical
SC Mathematics; Mathematical Methods In Social Sciences; Psychology
GA OC9MV
UT WOS:000579479700022
DA 2021-02-24
ER

PT J
AU Ogane, R
   Selila, L
   Ito, T
AF Ogane, Rintaro
   Selila, Lynda
   Ito, Takayuki
TI An experimental device for multi-directional somatosensory perturbation
   and its evaluation in a pilot psychophysical experiment
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH; LIP; JAW
AB Somatosensory stimulation associated with facial skin deformation has been developed and efficiently applied in the study of speech production and speech perception. However, the technique is limited to a simplified unidirectional pattern of stimulation, and cannot adapt to realistic stimulation patterns related to multidimensional orofacial gestures. To overcome this issue, a new multi-actuator system is developed enabling one to synchronously deform the facial skin in multiple directions. The first prototype involves stimulation in two directions and its efficiency is evaluated using a temporal order judgement test involving vertical and horizontal facial skin stretches at the sides of the mouth.
C1 [Ogane, Rintaro; Selila, Lynda; Ito, Takayuki] Univ Grenoble Alpes, Inst Polytech Grenoble, CNRS, Lab Grenoble Images Parole Signal Automat, F-38402 St Martin Dheres, France.
   [Ito, Takayuki] Haskins Labs Inc, 300 George St, New Haven, CT 06511 USA.
RP Ogane, R (corresponding author), Univ Grenoble Alpes, Inst Polytech Grenoble, CNRS, Lab Grenoble Images Parole Signal Automat, F-38402 St Martin Dheres, France.
EM rintaro.ogane@gipsa-lab.grenoble-inp.fr;
   lynda.selila@gipsa-lab.grenoble-inp.fr;
   takayuki.ito@gipsa-lab.grenoble-inp.fr
OI Ito, Takayuki/0000-0002-3265-360X
FU European Research CouncilEuropean Research Council (ERC)European
   Commission [339152]; CDP NeuroCoG [ANR-15-IDEX-02]; National Institute
   on Deafness and Other Communication DisordersUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01-DC017439]
FX This work was supported by the European Research Council under the
   European Community's Seventh Framework Program [FP7/2007-2013 Grant
   Agreement no. 339152, "Speech Unit(e)s", PI: Jean-Luc Schwartz]. This
   work was also supported by Grant No. ANR-15-IDEX-02 CDP NeuroCoG, and
   the National Institute on Deafness and Other Communication Disorders
   Grant No. R01-DC017439. We thank Jean-Luc Schwartz for his helpful
   advice and discussions. We also thank Kevin Chighine, Gael Vangheluwe,
   and Remy Jaccaz for their advice on the device development.
CR ABBS JH, 1983, TRENDS NEUROSCI, V6, P391, DOI 10.1016/0166-2236(83)90173-X
   Connor NP, 1998, EXP BRAIN RES, V123, P235, DOI 10.1007/s002210050565
   FOLKINS JW, 1975, J SPEECH HEAR RES, V18, P207, DOI 10.1044/jshr.1801.207
   Fujisaki W, 2009, EXP BRAIN RES, V198, P245, DOI 10.1007/s00221-009-1870-x
   Ghosh SS, 2010, J ACOUST SOC AM, V128, P3079, DOI 10.1121/1.3493430
   Guenther FH, 2012, J NEUROLINGUIST, V25, P408, DOI 10.1016/j.jneuroling.2009.08.006
   Ito T, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01198
   Ito T, 2012, J NEUROPHYSIOL, V107, P442, DOI 10.1152/jn.00029.2011
   Ito T, 2010, J NEUROPHYSIOL, V104, P1230, DOI 10.1152/jn.00199.2010
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   JOHANSSON RS, 1988, EXP BRAIN RES, V72, P209, DOI 10.1007/BF00248519
   KELSO JAS, 1984, J EXP PSYCHOL HUMAN, V10, P812, DOI 10.1037/0096-1523.10.6.812
   LINDBLOM B, 1979, J PHONETICS, V7, P147, DOI 10.1016/S0095-4470(19)31046-0
   Ogane R., 2019, P INT C PHON SCI 201
   Ogane R, 2020, COGNITION, V197, DOI 10.1016/j.cognition.2019.104163
   Perkell JS, 2012, J NEUROLINGUIST, V25, P382, DOI 10.1016/j.jneuroling.2010.02.011
   SAVARIAUX C, 1995, J ACOUST SOC AM, V98, P2428, DOI 10.1121/1.413277
   Tremblay S, 2003, NATURE, V423, P866, DOI 10.1038/nature01710
   Vatikiotis-Bateson E., 1999, AVSP 99, P118
NR 19
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD SEP
PY 2020
VL 148
IS 3
BP EL279
EP EL284
DI 10.1121/10.0001942
PG 6
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA NZ5DZ
UT WOS:000577120200001
PM 33003866
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Pim, NU
   Razak, RA
   Umat, C
   Din, NC
   Mukari, SZMS
   Hashim, SSM
   Kamalden, TMIT
   Salahudin, Z
AF Pim, Nanthanat Uttraphan
   Razak, Rogayah A.
   Umat, Cila
   Din, Normah Che
   Mukari, Siti Zamratol Mai-Sarah
   Hashim, Siti Sabzah Mohd
   Kamalden, Tengku Mohamed Izam Tengku
   Salahudin, Zulkiflee
TI School Readiness, Cognitive, and Language Abilities of Six 6-Year-Old
   Malay Children with Cochlear Implants: A Case Series
SO PERTANIKA JOURNAL OF SOCIAL SCIENCE AND HUMANITIES
LA English
DT Article
DE Cochlear implant; cognitive abilities; language abilities; Malay
   children; normal hearing; school readiness
ID LONG-TERM OUTCOMES; SPEECH-PERCEPTION; PERFORMANCE; MEMORY; AGE;
   RECOGNITION; ACQUISITION; RECIPIENTS; SKILLS; USERS
AB Cochlear implant is an electronic medical device that helps to restore hearing in children and adults with sensorineural hearing loss by replacing the function of the damaged parts of the cochlea and electrically providing sound signals to the brain. For school-aged children, the ability to hear is crucial as it enables them to acquire school readiness skills that are vital to their learning in mainstream schools alongside normal hearing children. This study described the school readiness of six 6-year-old Malay children with cochlear implants together with their cognitive and language abilities prior to their school entry. The school readiness of the children with cochlear implants was rated by their parents based on the Year One School Readiness Scale. Their cognitive abilities were measured using the Comprehensive Test of Nonverbal Intelligence, Second Edition (CTONI-2) while their language abilities were determined using the Malay Preschool Language Assessment Tool (MPLAT), the Malay Language Assessment, Remediation, and Screening Procedure (Malay-LARSP), and the Multilingual Phonological Test (MPT). All findings were compared with the normative values obtained from same-aged normal hearing children. Results determined that 5 of 6 children with cochlear implants were not ready for mainstream school, 4 of 6 children with cochlear implants had cognitive abilities that were below average of developmental norms, and all 6 children with cochlear implants had language abilities that were not commensurable with their chronological age.
C1 [Pim, Nanthanat Uttraphan; Razak, Rogayah A.; Umat, Cila; Din, Normah Che] Univ Kebangsaan Malaysia, Fac Hlth Sci, Ctr Rehabil & Special Needs, Kuala Lumpur 50300, Malaysia.
   [Razak, Rogayah A.; Umat, Cila; Mukari, Siti Zamratol Mai-Sarah] Univ Kebangsaan Malaysia, Inst Ear Hearing & Speech Inst HEARS, Kuala Lumpur 53200, Malaysia.
   [Hashim, Siti Sabzah Mohd] Hosp Sultanate Bahlyah, Dept Otorhinolaiyngol, Alor Setar 05460, Kedah, Malaysia.
   [Kamalden, Tengku Mohamed Izam Tengku] Hosp Sultan Ismail, Dept Otorhinolaryngol, Johor Baharu 81100, Johor, Malaysia.
   [Salahudin, Zulkiflee] Hosp Raja Perempuan Zainab II, Dept Otorhinolaryngol, Kota Baharu 15586, Kelantan, Malaysia.
RP Razak, RA (corresponding author), Univ Kebangsaan Malaysia, Fac Hlth Sci, Ctr Rehabil & Special Needs, Kuala Lumpur 50300, Malaysia.; Razak, RA (corresponding author), Univ Kebangsaan Malaysia, Inst Ear Hearing & Speech Inst HEARS, Kuala Lumpur 53200, Malaysia.
EM nanthanat.uttrapham@gmail.com; rogayah@ukm.edu.my; cila@ukm.edu.my;
   normahcd@ukm.edu.my; zamratol@hotmail.com; dr_ctsabzah@yahoo.com;
   tengkuizam@yahoo.com; zulkiflee97@yahoo.com.my
FU Research University Grant scheme - Universiti Kebangsaan Malaysia
   [GUP-2016-078]
FX This work received funding from the Research University Grant scheme
   (Grant code: GUP-2016-078) awarded by Universiti Kebangsaan Malaysia to
   the third author. The authors fully acknowledge all members of the
   National and UKM Cochlear Implant Teams and the Medical Development
   Division under the Malaysian Ministry of Health, as well as the
   teachers, parents, and children involved in the study for their
   contribution.
CR Baddeley A. D., 1974, WORKING MEMORY
   Barbosa A. C. C., 2013, PSICO-USF, V18, P183, DOI [10.1590/S1413-82712013000200002, DOI 10.1590/S1413]
   Bates M. P., 2006, CALIFORNIA SCH PSYCH, V11, P41, DOI [10.1007/BF03341114, DOI 10.1007/BF03341114]
   Bavelier D, 2008, COGNITION, V107, P433, DOI 10.1016/j.cognition.2007.10.012
   Blair C, 2015, ANNU REV PSYCHOL, V66, P711, DOI 10.1146/annurev-psych-010814-015221
   Boehm J., 2005, LARSP USERS MANUAL
   Brown R., 1973, 1 LANGUAGE EARLY STA
   Carey S., 1978, PAPERS REPORTS CHILD, P17
   Cejas I, 2018, EAR HEARING, V39, P1187, DOI 10.1097/AUD.0000000000000578
   Chang PF, 2017, PATIENT EDUC COUNS, V100, P1544, DOI 10.1016/j.pec.2017.03.005
   Conway CM, 2011, DEV NEUROPSYCHOL, V36, P237, DOI 10.1080/87565641.2010.549869
   Cowan N, 2012, PSYCHOL REV, V119, P480, DOI 10.1037/a0027791
   Cupples L, 2018, INT J AUDIOL, V57, pS93, DOI 10.1080/14992027.2016.1228127
   Dunn CC, 2008, EAR HEARING, V29, P352, DOI 10.1097/AUD.0b013e318167b870
   Dunn CC, 2014, EAR HEARING, V35, P148, DOI 10.1097/AUD.0b013e3182a4a8f0
   Emmett SD, 2015, OTOL NEUROTOL, V36, P86, DOI 10.1097/MAO.0000000000000619
   Estes KG, 2013, J EXP CHILD PSYCHOL, V114, P405, DOI 10.1016/j.jecp.2012.10.002
   Furnham A, 2009, BRIT J EDUC PSYCHOL, V79, P769, DOI 10.1348/978185409X412147
   GATHERCOLE SE, 1990, BRIT J PSYCHOL, V81, P439, DOI 10.1111/j.2044-8295.1990.tb02371.x
   Goh BS, 2018, INT J PEDIATR OTORHI, V105, P27, DOI 10.1016/j.ijporl.2017.11.024
   Grech H, 2008, INT J BILINGUAL, V12, P155, DOI 10.1177/1367006908098564
   Hammill D.D., 2009, COMPREHENSIVE TEST N
   Harrington M., 2010, COMMUNICATION DISORD, V32, P50, DOI [10.1177/1525740109348790, DOI 10.1177/1525740109348790]
   Harvill LM, 1991, ED MEASUREMENT ISSUE, P33, DOI DOI 10.1111/J.1745-3992.1991.TB00195.X
   Houston DM, 2003, INT J PEDIATR OTORHI, V67, P479, DOI 10.1016/S0165-5876(03)00005-3
   Hu CF, 2005, APPL PSYCHOLINGUIST, V26, P343, DOI 10.1017/S0142716405050204
   Janus M, 2007, CAN J BEHAV SCI, V39, P1, DOI 10.1037/cjbs2007001
   Jusczyk PW, 2002, EAR HEARING, V23, P2, DOI 10.1097/00003446-200202000-00002
   Justice L. M., 2005, ENCY EARLY CHILDHOOD
   Justice LM, 2009, DEV PSYCHOL, V45, P460, DOI 10.1037/a0014324
   Khoramian S, 2018, INT J PEDIATR OTORHI, V113, P240, DOI 10.1016/j.ijporl.2018.08.006
   Lim H. W., 2010, PHONOLOGICAL ACQUISI
   Majzub RM, 2012, PROCD SOC BEHV, V46, P3524, DOI 10.1016/j.sbspro.2012.06.098
   Majzub RM, 2009, PROCD SOC BEHV, V1, P2568, DOI 10.1016/j.sbspro.2009.01.453
   Malaysian Ministry of Health, 2017, COCHL IMPL SERV OP P
   Maluleke NP, 2019, S AFR J INFORM MANAG, V66, DOI 10.4102/sajcd.v66i1.604
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Meinzen-Derr J, 2010, LARYNGOSCOPE, V120, P405, DOI 10.1002/lary.20728
   Mukari SZ, 2007, INT J PEDIATR OTORHI, V71, P231, DOI 10.1016/j.ijporl.2006.10.005
   Nicholas JG, 2007, J SPEECH LANG HEAR R, V50, P1048, DOI 10.1044/1092-4388(2007/073)
   Oommen A., 2014, J NEUROL STROKE, V1, P1, DOI DOI 10.15406/JNSK.2014.01.00023
   Pace A, 2018, EARLY CHILD RES Q, V46, P112, DOI 10.1016/j.ecresq.2018.04.001
   Park M, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/313274
   Pisoni DB, 2003, EAR HEARING, V24, p106S, DOI 10.1097/01.AUD.0000051692.05140.8E
   Ravenska T., 2011, INDONESIAN J ENGLISH, V7, P60, DOI 10.25170%2Fijelt.v7i1.176
   Razak R. A., 2016, PROFILING MALAY CHIL
   Razak R. A., 2014, ASIA PACIFIC J SPEEC, V13, P217, DOI [10.1179/13613, DOI 10.1179/136132810805334985]
   Sabol T. J., 2017, WILEY HDB EARLY CHIL, V1, P3, DOI [10.1002/9781118937334.ch1, DOI 10.1002/9781118937334.CH1]
   Scarabello EM, 2020, BRAZ J OTORHINOLAR, V86, P91, DOI 10.1016/j.bjorl.2018.10.006
   Spaepen E, 2011, P NATL ACAD SCI USA, V108, P3163, DOI 10.1073/pnas.1015975108
   Spiric S., 2016, J PHONETICS AUDIOLOG, V1, P2, DOI [10.1016/j.ijporl.2013.01.023, DOI 10.1016/J.IJPORL.2013.01.023]
   Sprenger M., 2013, TEACHING CRITICAL VO
   Suh MW, 2009, CLIN EXP OTORHINOLAR, V2, P120, DOI 10.3342/ceo.2009.2.3.120
   Umat C, 2018, INT J PEDIATR OTORHI, V107, P69, DOI 10.1016/j.ijporl.2018.01.031
   Wei YS, 2014, MANAGEMENT AND TECHNOLOGY IN KNOWLEDGE, SERVICE, TOURISM & HOSPITALITY, P123
   Weitzman E., 2010, ABC BUILDING EMERGEN
   Wertzner Haydée Fiszbein, 2005, Pró-Fono R. Atual. Cient., V17, P185, DOI 10.1590/S0104-56872005000200007
   Williams AL, 2010, INTERVENTIONS SPEECH
   Wu CM, 2008, CLIN OTOLARYNGOL, V33, P472, DOI 10.1111/j.1749-4486.2008.01713.x
   YUSOFF YM, 2017, J SAINS KESIHAT MALA, V15, P153, DOI DOI 10.17576/JSKM-2017-1502-21
   Ziolkowski RA, 2008, J EARLY INTERVENTION, V31, P67, DOI 10.1177/1053815108324808
NR 61
TC 0
Z9 0
U1 2
U2 2
PU UNIV PUTRA MALAYSIA PRESS
PI SELANGOR
PA SERDANG, SELANGOR, 00000, MALAYSIA
SN 0128-7702
EI 2231-8534
J9 PERTANIKA J SOC SCI
JI Pertanika J. Soc. Sci. Humanit.
PD SEP
PY 2020
VL 28
IS 3
BP 1717
EP 1741
PG 25
WC Social Sciences, Interdisciplinary
SC Social Sciences - Other Topics
GA NX5ZG
UT WOS:000575788400008
DA 2021-02-24
ER

PT J
AU Lee, Y
AF Lee, Youngmee
TI Phonological Awareness Skills in Children With Early and Late Cochlear
   Implantation: Effects of Task and Phonological Unit
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SPEECH-PERCEPTION SKILLS; SPOKEN LANGUAGE; DEAF-CHILDREN;
   PRESCHOOL-CHILDREN; PROCESSING SKILLS; LETTER-NAME; VOCABULARY;
   DIMENSIONALITY; KNOWLEDGE; AGE
AB Purpose: Phonological awareness (PA) skills are critical for spoken language acquisition and literacy. PA manifests in various skills that can be identified based on task performance and speech sound unit size. This study compared the PA skills of children with early cochlear implantation (E-CI), children with late cochlear implantation (L-CI), and children with typical hearing (TH) in relation to task and phonological unit. It also attempted to identify the significant predictors of PA skills in each CI and TH group.
   Method: Twenty children with E-CI, 20 children with L-CI, and 20 children with TH participated in this study. PA skills were assessed using elision, blending, and segmenting tasks at both the syllabic and phonemic levels.
   Results: The E-CI and L-CI groups performed significantly less well than the TH group on the elision and blending tasks at the syllabic level. However, the E-CI group performed at a similar level as the TH group in the segmenting tasks at both the syllabic and phonemic levels. The regression analysis identified age at implantation and receptive vocabulary scores as significant predictors of PA skills in children with CIs.
   Conclusions: Although all the children with CIs had ageappropriate receptive vocabulary skills, the PA skills of both the E-CI and L-CI groups tended to lag behind those of the TH group in the elision and blending tasks at the syllabic level. Age at implantation and receptive vocabulary skills affected the development of PA skills in children with CIs.
C1 [Lee, Youngmee] Ewha Womans Univ, Dept Commun Disorders, Seoul, South Korea.
RP Lee, Y (corresponding author), Ewha Womans Univ, Dept Commun Disorders, Seoul, South Korea.
EM youngmee@ewha.ac.kr
OI Lee, Youngmee/0000-0003-1809-5944
FU National Research Foundation of Korea - Korean governmentNational
   Research Foundation of KoreaKorean Government [NRF-2013S1A5A8024520]
FX This work was supported by the National Research Foundation of Korea
   Grant NRF-2013S1A5A8024520, funded by the Korean government. I wish to
   acknowledge the Dong-A SpeechLanguage Hearing Centers and Sul-gi Lee for
   the assistance they provided in selecting children with cochlear
   implants and to thank all the children and their parents for their
   commitment to this study.
CR Adams M., 1990, BEGINNING READ THINK
   Ambrose SE, 2012, J SPEECH LANG HEAR R, V55, P811, DOI 10.1044/1092-4388(2011/11-0086)
   Anthony JL, 2011, J EDUC PSYCHOL, V103, P857, DOI 10.1037/a0025024
   Anthony JL, 2005, CURR DIR PSYCHOL SCI, V14, P255, DOI 10.1111/j.0963-7214.2005.00376.x
   Brown C., 2000, 2 LANGUAGE ACQUISITI, V1, P4
   Cooper DH, 2002, APPL PSYCHOLINGUIST, V23, P399, DOI 10.1017/S0142716402003053
   Dillon CM, 2012, J DEAF STUD DEAF EDU, V17, P205, DOI 10.1093/deafed/enr043
   Dunn CC, 2014, EAR HEARING, V35, P148, DOI 10.1097/AUD.0b013e3182a4a8f0
   Foulin J. N., 2005, READ WRIT, V18, P129, DOI DOI 10.1007/S11145-004-5892-2
   Geers A, 2003, EAR HEARING, V24, p24S, DOI 10.1097/01.AUD.0000051687.99218.0F
   Gillon GT, 2000, LANG SPEECH HEAR SER, V31, P126, DOI 10.1044/0161-1461.3102.126
   Hogan TP, 2005, LANG SPEECH HEAR SER, V36, P285, DOI 10.1044/0161-1461(2005/029)
   HOIEN T, 1995, READ WRIT, V7, P171, DOI 10.1007/BF01027184
   Houston D. M., 2018, HDB COMMUNICATION DI, P43, DOI [10.1515/9781614514909-003, DOI 10.1515/9781614514909-003]
   Houston Derek M, 2005, Volta Rev, V105, P41
   James D, 2005, J SPEECH LANG HEAR R, V48, P1511, DOI 10.1044/1092-4388(2005/105)
   James D, 2008, J DEAF STUD DEAF EDU, V13, P117, DOI 10.1093/deafed/enm042
   이미숙, 2012, [The Journal of Special Children Education, 특수아동교육연구], V14, P335, DOI 10.21075/kacsn.2012.14.4.335
   Johnson C, 2010, J SPEECH LANG HEAR R, V53, P237, DOI 10.1044/1092-4388(2009/08-0139)
   Jung J, 2020, J SPEECH LANG HEAR R, V63, P393, DOI 10.1044/2019_JSLHR-19-00158
   이미영, 2009, [Korean Journal of Otorhinolaryngology Head and Neck Surgery, 대한이비인후과학회지 두경부외과학], V52, P312
   Kim Mibae, 2007, [Journal of speech-language & hearing disorders, 언어치료연구], V16, P89
   Kim Y. T., 2009, RECEPTIVE EXPRESSIVE
   Kim Y.-T., ASSESSMENT KOREAN PR
   Kim YS, 2009, READ WRIT, V22, P907, DOI 10.1007/s11145-008-9131-0
   Kirk KI, 2000, ANN OTO RHINOL LARYN, V109, P79, DOI 10.1177/0003489400109S1234
   Lee Y, 2012, INT J PEDIATR OTORHI, V76, P1755, DOI 10.1016/j.ijporl.2012.08.016
   Limb CJ, 2014, HEARING RES, V308, P13, DOI 10.1016/j.heares.2013.04.009
   Lonigan CJ, 1998, J EDUC PSYCHOL, V90, P294, DOI 10.1037/0022-0663.90.2.294
   May-Mederake B, 2012, INT J PEDIATR OTORHI, V76, P939, DOI 10.1016/j.ijporl.2012.02.051
   McBride-Chang C, 1999, MERRILL PALMER QUART, V45, P285
   McBrideChang C, 1996, CHILD DEV, V67, P1836, DOI 10.2307/1131735
   Metsala JL, 1999, J EDUC PSYCHOL, V91, P3, DOI 10.1037/0022-0663.91.1.3
   Metsala JL, 1998, WORD RECOGNITION IN BEGINNING LITERACY, P89
   Muter V, 1997, J EXP CHILD PSYCHOL, V65, P370, DOI 10.1006/jecp.1996.2365
   Nicholas JG, 2007, J SPEECH LANG HEAR R, V50, P1048, DOI 10.1044/1092-4388(2007/073)
   Nicholas JG, 2006, EAR HEARING, V27, P286, DOI 10.1097/01.aud.0000215973.76912.c6
   Papadopoulos TC, 2009, READ RES QUART, V44, P127, DOI 10.1598/RRQ.44.2.2
   Pisoni DB, 1999, VOLTA REV, V101, P111
   Rvachew S, 2006, AM J SPEECH-LANG PAT, V15, P165, DOI 10.1044/1058-0360(2006/016)
   Schatschneider C, 1999, J EDUC PSYCHOL, V91, P439, DOI 10.1037/0022-0663.91.3.439
   Sharma A, 2011, J MATERN-FETAL NEO M, V24, P151, DOI 10.3109/14767058.2011.607614
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   Soleymani Z, 2016, INT J PEDIATR OTORHI, V83, P16, DOI 10.1016/j.ijporl.2016.01.013
   Spencer LJ, 2008, EAR HEARING, V29, P270, DOI 10.1097/01.aud.0000305158.84403.f7
   Spencer LJ, 2009, J DEAF STUD DEAF EDU, V14, P1, DOI 10.1093/deafed/enn013
   STAHL SA, 1994, J EDUC PSYCHOL, V86, P221, DOI 10.1037/0022-0663.86.2.221
   Suh MW, 2009, CLIN EXP OTORHINOLAR, V2, P120, DOI 10.3342/ceo.2009.2.3.120
   Sutherland D, 2005, LANG SPEECH HEAR SER, V36, P294, DOI 10.1044/0161-1461(2005/030)
   Tajudeen BA, 2010, OTOL NEUROTOL, V31, P1254, DOI 10.1097/MAO.0b013e3181f2f475
   Tse WT, 2012, INT J SPEECH-LANG PA, V14, P73, DOI 10.3109/17549507.2011.604428
   Walley AC., 2003, READING WRITING, V16, P5, DOI [DOI 10.1023/A:1021789804977, 10.1023/A:1021789804977]
NR 52
TC 0
Z9 0
U1 2
U2 2
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD SEP
PY 2020
VL 63
IS 9
BP 2930
EP 2939
DI 10.1044/2020_JSLHR-19-00340
PG 10
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA NU2TN
UT WOS:000573495800009
PM 32812849
DA 2021-02-24
ER

PT J
AU Zhang, ZK
   Wei, CG
   Zhang, YM
   Zeng, ZG
   Cao, KL
   Liu, YH
AF Zhang, Zhikai
   Wei, Chaogang
   Zhang, Yanmei
   Zeng, Zhengang
   Cao, Keli
   Liu, Yuhe
TI Sequential Bilateral Cochlear Implantation With Prolonged Time Intervals
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID QUALITY-OF-LIFE; SPEECH-PERCEPTION; SENSITIVE PERIOD; CHILDREN; ADULTS;
   HEARING; SOUND; EAR; REORGANIZATION; LOCALIZATION
AB Purpose: The aim of the study was to assess whether sequential cochlear implantation (CI) with a prolonged interimplant interval (M = 15.2 years) between the first and second CIs benefited speech recognition and health-related quality of life.
   Method: This prospective study included 14 prelingually deafened participants who received their second CI after a prolonged interimplant interval (M = 15.2 years). Additionally, speech recognition ability over a 12-month period of bilateral implant use was investigated. The results of the speech recognition test in both quiet and noisy conditions were statistically analyzed for each CI alone and both CIs together. Nijmegen Cochlear Implant Questionnaire scores were also collected at activation and at 12 months after activation.
   Results: Improvements in speech recognition ability were observed following the use of the first implant alone and with the use of both implants together; however, progress was much slower with the use of the second implant alone, following its introduction. Furthermore, a significant difference in the trajectory of speech recognition ability was observed between the first and the second implanted ear. According to Nijmegen Cochlear Implant Questionnaire scores, all participants benefitted from bilateral CI after 12 months.
   Conclusions: Prolonged interimplant intervals resulted in asymmetrical speech recognition abilities. A significant improvement in the speech recognition scores was observed with the first implanted ear, and much slower progress was observed with the second implanted ear. However, the "poorer" second implanted ear could provide a considerable beneficial effect on the improved speech recognition and health-related quality of life with the bilateral Cl.
C1 [Zhang, Zhikai; Wei, Chaogang; Zhang, Yanmei; Zeng, Zhengang; Liu, Yuhe] Peking Univ First Hosp, Dept Otolaryngol Head & Neck Surg, Beijing, Peoples R China.
   [Cao, Keli] Chinese Acad Med Sci, Dept Otorhinolaryngol, Peking Union Med Coll Hosp, Peking Union Med Coll, Beijing, Peoples R China.
RP Liu, YH (corresponding author), Peking Univ First Hosp, Dept Otolaryngol Head & Neck Surg, Beijing, Peoples R China.
EM liuyuhefeng@163.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [81470691]; Beijing Natural Science
   FoundationBeijing Natural Science Foundation [7172216]; Key Project of
   Interschool Cooperation, Beijing Normal University [201800009]; Beijing
   Municipal Science and Technology CommissionBeijing Municipal Science &
   Technology Commission [Z191100006619027]
FX This research received grants from the following funding sources:
   National Natural Science Foundation of China (81470691); Beijing Natural
   Science Foundation (7172216); Key Project of Interschool Cooperation,
   Beijing Normal University (201800009); Beijing Municipal Science and
   Technology Commission (Z191100006619027). Liu Yuhe is the recipient of
   these grants. All authors contributed equally to this work, discussed
   the results and implications, and commented on the manuscript at all
   stages. We acknowledge and thank the following: The Peking University
   First Hospital Cochlear Implant Team and Clinical Auditory Diagnostic
   Center, particularly Qin Yao, Ren Lei, Lu Xingxing, and Chen Zhe for
   their assistance with data collection; Zhou Rui and Zong Yajing for the
   testing equipment and stimuli calibration; and our patients for their
   time and participation in this study.
CR Adunka OF, 2008, LARYNGOSCOPE, V118, P2044, DOI 10.1097/MLG.0b013e3181820900
   Asp F, 2015, INT J AUDIOL, V54, P77, DOI 10.3109/14992027.2014.973536
   Asp F, 2012, INT J AUDIOL, V51, P817, DOI 10.3109/14992027.2012.705898
   Baron S, 2019, EUR ANN OTORHINOLARY, V136, P69, DOI 10.1016/j.anorl.2018.09.004
   Basura GJ, 2009, LARYNGOSCOPE, V119, P2395, DOI 10.1002/lary.20751
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   Bianchin G, 2017, INT J PEDIATR OTORHI, V102, P10, DOI 10.1016/j.ijporl.2017.08.025
   Brown Kevin D, 2007, Curr Opin Otolaryngol Head Neck Surg, V15, P315, DOI 10.1097/MOO.0b013e3282ef3d3e
   Buhagiar Roberta, 2010, Cochlear Implants Int, V11 Suppl 1, P264, DOI 10.1179/146701010X12671177989075
   Chang YS, 2019, BRAZ J OTORHINOLAR, V85, P571, DOI 10.1016/j.bjorl.2018.04.009
   Dunn CC, 2012, AM J AUDIOL, V21, P181, DOI 10.1044/1059-0889(2012/12-0004)
   Easwar V, 2017, J NEUROSCI, V37, P2349, DOI 10.1523/JNEUROSCI.2538-16.2017
   Eggermont JJ, 2008, EAR HEARING, V29, P819, DOI 10.1097/AUD.0b013e3181853030
   Friedmann DR, 2015, LARYNGOSCOPE, V125, P1952, DOI 10.1002/lary.25293
   Galvin Karyn Louise, 2009, Cochlear Implants Int, V10, P84, DOI 10.1179/cim.2009.10.2.84
   Gordon KA, 2007, HEARING RES, V233, P97, DOI 10.1016/j.heares.2007.08.001
   Gordon K A, 2011, Cochlear Implants Int, V12 Suppl 2, pS8, DOI 10.1179/146701011X13074645127199
   Gordon KA, 2013, BRAIN, V136, P1609, DOI 10.1093/brain/awt052
   Gordon KA, 2009, OTOL NEUROTOL, V30, P319, DOI 10.1097/MAO.0b013e31819a8f4c
   Goupell MJ, 2018, EAR HEARING, V39, P110, DOI 10.1097/AUD.0000000000000470
   Goupell MJ, 2016, J ACOUST SOC AM, V140, P1652, DOI 10.1121/1.4962378
   Graham John, 2009, Cochlear Implants Int, V10, P119, DOI 10.1179/cim.2009.10.3.119
   Grieco-Calub TM, 2012, EAR HEARING, V33, P561, DOI 10.1097/AUD.0b013e31824c7801
   Hinderink JB, 2000, OTOLARYNG HEAD NECK, V123, P756, DOI 10.1067/mhn.2000.108203
   Hughes Kathryn C, 2013, Cochlear Implants Int, V14, P121, DOI 10.1179/1754762812Y.0000000009
   Illg A, 2019, HEARING RES, V372, P80, DOI 10.1016/j.heares.2017.10.010
   Illg A, 2013, OTOL NEUROTOL, V34, P682, DOI 10.1097/MAO.0b013e31828bb75e
   Jang JH, 2019, AUDIOL NEURO-OTOL, V24, P174, DOI 10.1159/000500700
   Jeong SW, 2018, EUR ARCH OTO-RHINO-L, V275, P1759, DOI 10.1007/s00405-018-5021-5
   Key APF, 2010, J AM ACAD AUDIOL, V21, P225, DOI 10.3766/jaaa.21.4.2
   Kocdor P, 2016, LARYNGOSCOPE, V126, P2389, DOI 10.1002/lary.26012
   Kraaijenga VJC, 2016, OTOL NEUROTOL, V37, P1300, DOI 10.1097/MAO.0000000000001185
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   Lammers MJW, 2014, LARYNGOSCOPE, V124, P993, DOI 10.1002/lary.24395
   Laske RD, 2009, OTOL NEUROTOL, V30, P313, DOI 10.1097/MAO.0b013e31819bd7e6
   Litovsky RY, 2009, EAR HEARING, V30, P419, DOI 10.1097/AUD.0b013e3181a165be
   Liu Bo, 2008, Zhonghua Yi Xue Za Zhi, V88, P1550
   Low D, 2020, OTOL NEUROTOL, V41, P39, DOI 10.1097/MAO.0000000000002439
   Marx M, 2015, EAR HEARING, V36, P239, DOI 10.1097/AUD.0000000000000105
   Mo B, 2005, EAR HEARING, V26, P186, DOI 10.1097/00003446-200504000-00006
   Myhrum M, 2017, EAR HEARING, V38, P301, DOI 10.1097/AUD.0000000000000383
   Park HJ, 2018, OTOL NEUROTOL, V39, P177, DOI 10.1097/MAO.0000000000001640
   Ramsden JD, 2009, INT J PEDIATR OTORHI, V73, P1325, DOI 10.1016/j.ijporl.2009.05.001
   Reeder RM, 2017, J SPEECH LANG HEAR R, V60, P276, DOI 10.1044/2016_JSLHR-H-16-0175
   Reeder RM, 2014, J SPEECH LANG HEAR R, V57, P1108, DOI 10.1044/2014_JSLHR-H-13-0087
   Ryugo DK, 2005, SCIENCE, V310, P1490, DOI 10.1126/science.1119419
   Sarant J, 2014, EAR HEARING, V35, P396, DOI 10.1097/AUD.0000000000000022
   Scherf F, 2009, ANN OTO RHINOL LARYN, V118, P336, DOI 10.1177/000348940911800504
   Schnabl J, 2015, HNO, V63, P546, DOI 10.1007/s00106-015-0020-y
   Sharma A, 2005, HEARING RES, V203, P134, DOI 10.1016/j.heares.2004.12.010
   Sharma A, 2007, INT J AUDIOL, V46, P494, DOI 10.1080/14992020701524836
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   Smulders Y, 2017, AUDIOL NEURO-OTOL, V22, P356, DOI 10.1159/000488386
   Sparreboom M, 2016, INT J PEDIATR OTORHI, V86, P161, DOI 10.1016/j.ijporl.2016.05.003
   Sparreboom M, 2014, OTOL NEUROTOL, V35, P35, DOI 10.1097/MAO.0000000000000172
   Strom-Roum H, 2012, INT J PEDIATR OTORHI, V76, P95, DOI 10.1016/j.ijporl.2011.10.009
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Tillein J, 2016, CEREB CORTEX, V26, P1762, DOI 10.1093/cercor/bhv351
   Trinidade A, 2017, LARYNGOSCOPE, V127, P2615, DOI 10.1002/lary.26673
   Uecker FC, 2019, OTOL NEUROTOL, V40, pE454, DOI 10.1097/MAO.0000000000002177
   Van Deun L, 2010, EAR HEARING, V31, P702, DOI 10.1097/AUD.0b013e3181e40dfe
   Xi X, 2012, INT J AUDIOL, V51, P399, DOI 10.3109/14992027.2011.642011
   XU XS, 2018, CHINESE J OTORHINOLA, V53, P189, DOI DOI 10.3760/CMA.J.ISSN.1673-0860.2018.03.005
   Zeitler DM, 2008, OTOL NEUROTOL, V29, P314, DOI 10.1097/MAO.0b013e3181662cb5
NR 64
TC 0
Z9 0
U1 3
U2 3
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD SEP
PY 2020
VL 63
IS 9
BP 3195
EP 3207
DI 10.1044/2020_JSLHR-20-00140
PG 13
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA NU2TN
UT WOS:000573495800023
PM 32857631
DA 2021-02-24
ER

PT J
AU Conant, LL
   Liebenthal, E
   Desai, A
   Seidenberg, MS
   Binder, JR
AF Conant, Lisa L.
   Liebenthal, Einat
   Desai, Anjali
   Seidenberg, Mark S.
   Binder, Jeffrey R.
TI Differential activation of the visual word form area during auditory
   phoneme perception in youth with dyslexia
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Developmental dyslexia; Phoneme perception; Speech perception; Reading
   development; Visual word form area
ID ANTERIOR CINGULATE CORTEX; EVENT-RELATED POTENTIALS; SPEECH-PERCEPTION;
   FAMILIAL RISK; CATEGORICAL PERCEPTION; DEVELOPMENTAL DYSLEXIA;
   READING-DISABILITY; BRAIN RESPONSES; POOR READERS; CHILDREN
AB Developmental dyslexia is a learning disorder characterized by difficulties reading words accurately and/or fluently. Several behavioral studies have suggested the presence of anomalies at an early stage of phoneme processing, when the complex spectrotemporal patterns in the speech signal are analyzed and assigned to phonemic categories. In this study, fMRI was used to compare brain responses associated with categorical discrimination of speech syllables (P) and acoustically matched nonphonemic stimuli (N) in children and adolescents with dyslexia and in typically developing (TD) controls, aged 8-17 years. The TD group showed significantly greater activation during the P condition relative to N in an area of the left ventral occipitotemporal cortex that corresponds well with the region referred to as the "visual word form area (VWFA). Regression analyses using reading performance as a continuous variable across the full group of participants yielded similar results. Overall, the findings are consistent with those of previous neuroimaging studies using print stimuli in individuals with dyslexia that found reduced activation in left occipitotemporal regions; however, the current study shows that these activation differences seen during reading are apparent during auditory phoneme discrimination in youth with dyslexia, suggesting that the primary deficit in at least a subset of children may lie early in the speech processing stream and that categorical perception may be an important target of early intervention in children at risk for dyslexia.
C1 [Conant, Lisa L.; Liebenthal, Einat; Desai, Anjali; Binder, Jeffrey R.] Med Coll Wisconsin, Dept Neurol, 8701 Watertown Plank Rd, Milwaukee, WI 53226 USA.
   [Liebenthal, Einat] Harvard Med Sch, McLean Hosp, Dept Psychiat, Boston, MA USA.
   [Seidenberg, Mark S.] Univ Wisconsin, Dept Psychol, Madison, WI 53706 USA.
RP Conant, LL (corresponding author), Med Coll Wisconsin, Dept Neurol, 8701 Watertown Plank Rd, Milwaukee, WI 53226 USA.
EM lconant@mcw.edu
OI Conant, Lisa/0000-0002-5050-3437
FU National Institute of Child Health and Human DevelopmentUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH Eunice Kennedy Shriver National Institute of Child Health &
   Human Development (NICHD) [R21 HD054824, 1UL1RR031973]; National Center
   for Research ResourcesUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Center for
   Research Resources (NCRR)
FX This work was supported by the National Institute of Child Health and
   Human Development (R21 HD054824 to LC) and CTSA Grant Number
   1UL1RR031973 from the National Center for Research Resources. The
   authors are grateful for the generous donation of time and effort made
   by the children and parents who participated in this study.
CR Achenbach TM, 2001, MANUAL ASEBA SCH AGE
   Adank P, 2012, BRAIN LANG, V122, P42, DOI 10.1016/j.bandl.2012.04.014
   Adlard A, 1998, Q J EXP PSYCHOL-A, V51, P153
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Binder JR, 2006, NEUROIMAGE, V33, P739, DOI 10.1016/j.neuroimage.2006.06.053
   BINDER JR, 1992, BRAIN, V115, P1807, DOI 10.1093/brain/115.6.1807
   Blomert L, 2004, BRAIN LANG, V89, P21, DOI 10.1016/S0093-934X(03)00305-5
   Boets B, 2007, BRAIN LANG, V101, P19, DOI 10.1016/j.bandl.2006.06.009
   Bogliotti C, 2008, J EXP CHILD PSYCHOL, V101, P137, DOI 10.1016/j.jecp.2008.03.006
   Bonte M, 2017, SCI REP, V7, P1
   Booth JR, 2001, CHILD NEUROPSYCHOL, V7, P119, DOI 10.1076/chin.7.3.119.8740
   Botthali F, 2014, J NEUROSCI, V34, P15402, DOI 10.1523/JNEUROSCI.4918-13.2014
   Bowers JS, 1998, PSYCHON B REV, V5, P259, DOI 10.3758/BF03212948
   BRANDT J, 1980, BRAIN LANG, V9, P324, DOI 10.1016/0093-934X(80)90152-2
   Breier JI, 2004, J EXP CHILD PSYCHOL, V88, P152, DOI 10.1016/j.jecp.2004.03.003
   Breier JI, 2003, NEUROPSYCHOLOGY, V17, P610, DOI 10.1037/0894-4105.17.4.610
   Breier JI, 2001, J EXP CHILD PSYCHOL, V80, P245, DOI 10.1006/jecp.2001.2630
   Brown S, 2009, BRAIN COGNITION, V70, P31, DOI 10.1016/j.bandc.2008.12.006
   Cai Q, 2010, CEREB CORTEX, V20, P1153, DOI 10.1093/cercor/bhp175
   CAMPBELL R, 1986, BRAIN, V109, P509, DOI 10.1093/brain/109.3.509
   Chiappe P, 2001, J EXP CHILD PSYCHOL, V80, P58, DOI 10.1006/jecp.2000.2624
   Church JA, 2008, CEREB CORTEX, V18, P2054, DOI 10.1093/cercor/bhm228
   Clark KA, 2014, BRAIN, V137, P3136, DOI 10.1093/brain/awu229
   Cohen L, 2003, CEREB CORTEX, V13, P1313, DOI 10.1093/cercor/bhg079
   Cohen L, 2000, BRAIN, V123, P291, DOI 10.1093/brain/123.2.291
   Conant LL, 2014, NEUROIMAGE, V89, P192, DOI 10.1016/j.neuroimage.2013.11.055
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   de Gelder B, 1998, BRAIN LANG, V64, P269, DOI 10.1006/brln.1998.1973
   Debska A, 2016, NEUROIMAGE, V132, P406, DOI 10.1016/j.neuroimage.2016.02.063
   Dehaene S, 2001, NAT NEUROSCI, V4, P752, DOI 10.1038/89551
   Dehaene S, 2004, PSYCHOL SCI, V15, P307, DOI 10.1111/j.0956-7976.2004.00674.x
   Desai R, 2008, J COGNITIVE NEUROSCI, V20, P1174, DOI 10.1162/jocn.2008.20081
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Dufor O, 2007, NEUROIMAGE, V34, P1692, DOI 10.1016/j.neuroimage.2006.10.034
   Edmister WB, 1999, HUM BRAIN MAPP, V7, P89, DOI 10.1002/(SICI)1097-0193(1999)7:2<89::AID-HBM2>3.3.CO;2-E
   Eklund A, 2016, P NATL ACAD SCI USA, V113, P7900, DOI 10.1073/pnas.1602413113
   FLETCHER JM, 1994, J EDUC PSYCHOL, V86, P6, DOI 10.1037//0022-0663.86.1.6
   GODFREY JJ, 1981, J EXP CHILD PSYCHOL, V32, P401, DOI 10.1016/0022-0965(81)90105-3
   Graves WW, 2010, CEREB CORTEX, V20, P1799, DOI 10.1093/cercor/bhp245
   Grigorenko EL, 2001, J CHILD PSYCHOL PSYC, V42, P91, DOI 10.1111/1469-7610.00704
   Guttorm TK, 2001, J LEARN DISABIL-US, V34, P534, DOI 10.1177/002221940103400606
   Guttorm TK, 2010, J LEARN DISABIL-US, V43, P391, DOI 10.1177/0022219409345005
   Hancock R, 2017, NEUROSCI BIOBEHAV R, V72, P243, DOI 10.1016/j.neubiorev.2016.10.025
   Hannagan T, 2015, TRENDS COGN SCI, V19, P374, DOI 10.1016/j.tics.2015.05.006
   Hashimoto R, 2004, NEURON, V42, P311, DOI 10.1016/S0896-6273(04)00196-5
   Heilbronner SR, 2016, ANNU REV NEUROSCI, V39, P149, DOI 10.1146/annurev-neuro-070815-013952
   Hollingshead AA, 1975, 4 FACTOR INDEX UNPUB
   HURFORD DP, 1990, J LEARN DISABIL, V23, P564, DOI 10.1177/002221949002300906
   Hutchison ER, 2008, NEUROIMAGE, V40, P342, DOI 10.1016/j.neuroimage.2007.10.064
   Indefrey P, 2004, COGNITION, V92, P101, DOI 10.1016/j.cognition.2002.06.001
   Joanisse MF, 2000, J EXP CHILD PSYCHOL, V77, P30, DOI 10.1006/jecp.1999.2553
   Kanwisher N, 2006, PHILOS T R SOC B, V361, P2109, DOI 10.1098/rstb.2006.1934
   Laurienti PJ, 2002, J COGNITIVE NEUROSCI, V14, P420, DOI 10.1162/089892902317361930
   Leark R.A., 1999, T O V A TEST VARIABL
   Leff AP, 2006, J NEUROL NEUROSUR PS, V77, P1004, DOI 10.1136/jnnp.2005.086983
   Leppanen PHT, 2012, NEUROPHYSIOL CLIN, V42, P35, DOI 10.1016/j.neucli.2011.08.005
   Leppanen PHT, 2002, DEV NEUROPSYCHOL, V22, P407, DOI 10.1207/S15326942dn2201_4
   Leppanen PHT, 1999, NEUROREPORT, V10, P969, DOI 10.1097/00001756-199904060-00014
   Liebenthal E, 2005, CEREB CORTEX, V15, P1621, DOI 10.1093/cercor/bhi040
   Liebenthal E, 2010, CEREB CORTEX, V20, P2958, DOI 10.1093/cercor/bhq045
   LIEBERMAN P, 1985, J SPEECH HEAR RES, V28, P480, DOI 10.1044/jshr.2804.480
   Lima CF, 2016, TRENDS NEUROSCI, V39, P527, DOI 10.1016/j.tins.2016.06.003
   Linkersdorfer J, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043122
   Ludersdorfer P, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00491
   Lyon G. R., 1996, MENTAL RETARDATION D, V2, P2, DOI [10.1002/(SICI)1098-2779(1996)2:1&lt2::AID-MRDD2&gt3.0.CO;2-X, DOI 10.1002/(SICI)1098-2779(1996)2:1<2::AID-MRDD2>3.0.CO;2-X]
   LYON GR, 1995, J CHILD NEUROL, V10, pS120, DOI 10.1177/08830738950100S126
   Lyytinen H, 2004, DYSLEXIA, V10, P146, DOI 10.1002/dys.274
   Maassen B, 2001, CLIN LINGUIST PHONET, V15, P319
   MacMillan N. A., 2005, DETECTION THEORY USE
   Magnan A, 2006, COMPUT EDUC, V46, P407, DOI 10.1016/j.compedu.2004.08.008
   Magnan A, 2004, DYSLEXIA, V10, P131, DOI 10.1002/dys.270
   Maisog JM, 2008, ANN NY ACAD SCI, V1145, P237, DOI 10.1196/annals.1416.024
   Manis FR, 1997, J EXP CHILD PSYCHOL, V66, P211, DOI 10.1006/jecp.1997.2383
   Manis FR, 2005, CONNECTIONS BETWEEN LANGUAGE AND READING DISABILITIES, P77
   Mano QR, 2013, CEREB CORTEX, V23, P988, DOI 10.1093/cercor/bhs093
   Martin A, 2016, HUM BRAIN MAPP, V37, P2676, DOI 10.1002/hbm.23202
   Martin A, 2015, HUM BRAIN MAPP, V36, P1963, DOI 10.1002/hbm.22749
   McBrideChang C, 1996, CHILD DEV, V67, P1836, DOI 10.2307/1131735
   McCandliss BD, 2003, TRENDS COGN SCI, V7, P293, DOI 10.1016/S1364-6613(03)00134-7
   McGrath LM, 2011, J CHILD PSYCHOL PSYC, V52, P547, DOI 10.1111/j.1469-7610.2010.02346.x
   Messaoud-Galusi S, 2011, J SPEECH LANG HEAR R, V54, P1682, DOI 10.1044/1092-4388(2011/09-0261)
   Mody M, 1997, J EXP CHILD PSYCHOL, V64, P199, DOI 10.1006/jecp.1996.2343
   Moore DR, 2005, BRAIN LANG, V94, P72, DOI 10.1016/j.bandl.2004.11.009
   Mozolic JL, 2008, BMC NEUROL, V8, DOI 10.1186/1471-2377-8-35
   Nath AR, 2011, J NEUROSCI, V31, P13963, DOI 10.1523/JNEUROSCI.2605-11.2011
   Noordenbos MW, 2012, NEUROPSYCHOLOGIA, V50, P2010, DOI 10.1016/j.neuropsychologia.2012.04.026
   Noordenbos MW, 2012, RES DEV DISABIL, V33, P1469, DOI 10.1016/j.ridd.2012.03.021
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   O'Brien GE, 2019, J ACOUST SOC AM, V146, P245, DOI 10.1121/1.5116568
   O'Brien GE, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34823-8
   Obleser J, 2007, CEREB CORTEX, V17, P2251, DOI 10.1093/cercor/bhl133
   Paulesu E, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00830
   Pennington BF, 2006, COGNITION, V101, P385, DOI 10.1016/j.cognition.2006.04.008
   Pennington BF, 2012, J ABNORM PSYCHOL, V121, P212, DOI 10.1037/a0025823
   Polk TA, 2002, J EXP PSYCHOL GEN, V131, P65, DOI 10.1037//0096-3445.131.1.65
   Pollack C, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00191
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Price CJ, 2003, BRAIN LANG, V86, P272, DOI 10.1016/S0093-934X(02)00544-8
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   Raschle NM, 2011, NEUROIMAGE, V57, P742, DOI 10.1016/j.neuroimage.2010.09.055
   Richardson U, 2003, DEV NEUROPSYCHOL, V23, P385, DOI 10.1207/S15326942DN2303_5
   Richlan F, 2011, NEUROIMAGE, V56, P1735, DOI 10.1016/j.neuroimage.2011.02.040
   Richlan F, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0012073
   Richlan F, 2009, HUM BRAIN MAPP, V30, P3299, DOI 10.1002/hbm.20752
   Romanovska L, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00221
   Rosen S, 2001, J SPEECH LANG HEAR R, V44, P720, DOI 10.1044/1092-4388(2001/057)
   Russeler J, 2018, BRAIN IMAGING BEHAV, V12, P357, DOI 10.1007/s11682-017-9694-y
   Ruff S, 2003, BRAIN COGNITION, V53, P331, DOI 10.1016/S0278-2626(03)00137-4
   Sandak R, 2004, SCI STUD READ, V8, P273, DOI 10.1207/s1532799xssr0803_6
   Saygin ZM, 2016, NAT NEUROSCI, V19, P1250, DOI 10.1038/nn.4354
   Schumacher J, 2007, J MED GENET, V44, P289, DOI 10.1136/jmg.2006.046516
   Semel E. M., 2003, CLIN EVALUATION LANG
   Serniclaes W, 2001, J SPEECH LANG HEAR R, V44, P384, DOI 10.1044/1092-4388(2001/032)
   Shaywitz SE, 1998, NEW ENGL J MED, V338, P307, DOI 10.1056/NEJM199801293380507
   Shenhav A, 2013, NEURON, V79, P217, DOI 10.1016/j.neuron.2013.07.007
   Skiba T, 2011, BEHAV GENET, V41, P6, DOI 10.1007/s10519-011-9444-7
   STEFFENS ML, 1992, J SPEECH HEAR RES, V35, P192, DOI 10.1044/jshr.3501.192
   Stevens WD, 2017, J NEUROSCI, V37, P5288, DOI 10.1523/JNEUROSCI.0138-17.2017
   Talairach J, 1988, COPLANAR STEREOTAXIC
   Torgesen J, 1999, TEST WORD READING EF
   van Bergen E, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00346
   van Laarhoven T, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12504
   Vandermosten M, 2020, DEVELOPMENTAL SCI, V23, DOI 10.1111/desc.12857
   Varnet L, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0153781
   Veuillet E, 2007, BRAIN, V130, P2915, DOI 10.1093/brain/awm235
   Wagner R, 1999, COMPREHENSIVE TEST P
   Wechsler D., 2003, WECHSLER INTELLIGENC
   Wechsler D., 2008, WECHSLER ADULT INTEL
   Wiederholt J.L., 2001, GRAY ORAL READING TE
   Woodcock R.W., 1999, WOODCOCKJOHNSON 3
   Yoncheva YN, 2010, CEREB CORTEX, V20, P622, DOI 10.1093/cercor/bhp129
   Zhang YJ, 2012, J CHILD PSYCHOL PSYC, V53, P874, DOI 10.1111/j.1469-7610.2012.02528.x
   Ziegler JC, 2009, DEVELOPMENTAL SCI, V12, P732, DOI 10.1111/j.1467-7687.2009.00817.x
   Zoubrinetzky R, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151015
NR 134
TC 0
Z9 0
U1 10
U2 10
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD SEP
PY 2020
VL 146
AR 107543
DI 10.1016/j.neuropsychologia.2020.107543
PG 13
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA NT6BG
UT WOS:000573023300019
PM 32598966
DA 2021-02-24
ER

PT J
AU Altamura, M
   Prete, G
   Elia, A
   Angelini, E
   Padalino, FA
   Bellomo, A
   Tommasi, L
   Fairfield, B
AF Altamura, Mario
   Prete, Giulia
   Elia, Antonella
   Angelini, Eleonora
   Padalino, Flavia A.
   Bellomo, Antonello
   Tommasi, Luca
   Fairfield, Beth
TI Do patients with hallucinations imagine speech right?
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Auditory hallucinations; Schizophrenia; Bipolar disorder; Auditory
   imagery; Laterality
ID AUDITORY-VERBAL HALLUCINATIONS; PERCEPTIONS SCALE CAPS; INNER SPEECH;
   HEMISPHERIC LATERALIZATION; LANGUAGE LATERALIZATION; CEREBRAL
   LATERALITY; FUNCTIONAL-ANATOMY; RATING-SCALE; SCHIZOPHRENIA; BRAIN
AB A direct relationship between auditory verbal hallucinations (AVHs) and decreased left-hemispheric lateralization in speech perception has been often described, although it has not been conclusively proven. The specific lateralization of AVHs has been poorly explored. However, patients with verbal hallucinations show a weak Right Ear Advantage (REA) in verbal perception compared to non AVHs listeners suggesting that left-hemispheric language area are involved in AVHs. In the present study, 29 schizophrenia patients with AVHs, 31 patients with psychotic bipolar disorder who experienced frequent AVHs, 27 patients with schizophrenia who had never experienced AVHs and 57 healthy controls were required to imagine hearing a voice in one ear alone. In line with previous evidence healthy controls confirmed the expected REA for auditory imagery, and the same REA was also found in non-hallucinator patients. However, in line with our hypothesis, patients with schizophrenia and psychotic bipolar disorder with AVHs showed no lateral bias. Results extend the relationship between abnormal asymmetry for verbal stimuli and AVHs to verbal imagery, suggesting that atypical verbal imagery may reflect a disruption of inter-hemispheric connectivity between areas implicated in the generation and monitoring of verbal imagery and may be predictive of a predisposition for AVHs. Results also indicate that the relationship between AVHs and hemispheric lateralization for auditory verbal imagery is not specific to schizophrenia but may extend to other disorders as well.
C1 [Altamura, Mario; Elia, Antonella; Angelini, Eleonora; Padalino, Flavia A.; Bellomo, Antonello] Univ Foggia, Dept Clin & Expt Med, Psychiat Unit, Foggia, Italy.
   [Prete, Giulia; Tommasi, Luca; Fairfield, Beth] Univ G dAnnunzio, Dept Psychol Hlth & Terr Sci, Via Vestini 31, Chieti, Italy.
RP Fairfield, B (corresponding author), Univ G dAnnunzio, Dept Psychol Hlth & Terr Sci, Via Vestini 31, Chieti, Italy.
EM bfairfield@unich.it
RI Prete, Giulia/H-6401-2019
OI Prete, Giulia/0000-0001-9969-6404; Tommasi, Luca/0000-0003-0664-714X
CR Alary M, 2013, SCHIZOPHR RES, V149, P42, DOI 10.1016/j.schres.2013.06.003
   Aleman A., 2008, HALLUCINATIONS SCI I
   Allen P, 2007, INT REV PSYCHIATR, V19, P409, DOI 10.1080/09540260701486498
   Allen P, 2012, SCHIZOPHRENIA BULL, V38, P695, DOI 10.1093/schbul/sbs066
   Altamura M, 2012, PSYCHIAT RES-NEUROIM, V203, P54, DOI 10.1016/j.pscychresns.2012.02.008
   Badcock JC, 2015, COGN NEUROPSYCHIATRY, V20, P254, DOI 10.1080/13546805.2015.1021907
   BARTA PE, 1990, AM J PSYCHIAT, V147, P1457
   Bell V, 2006, SCHIZOPHRENIA BULL, V32, P366, DOI 10.1093/schbul/sbj014
   Bell V, 2011, PSYCHIAT RES, V189, P451, DOI 10.1016/j.psychres.2011.05.025
   Bozikas V.P., 2008, ANN GEN PSYCHIATR, V7, pS154
   Brancucci A, 2004, EUR J NEUROSCI, V19, P2329, DOI 10.1111/j.0953-816X.2004.03302.x
   BRUDER G, 1995, AM J PSYCHIAT, V152, P932
   Conn R, 2000, J ABNORM PSYCHOL, V109, P546, DOI 10.1037//0021-843X.109.3.546
   Crow TJ, 1997, TRENDS NEUROSCI, V20, P339
   Curcic-Blake B, 2017, PROG NEUROBIOL, V148, P1, DOI 10.1016/j.pneurobio.2016.11.002
   David AS, 1996, NEUROREPORT, V7, P932, DOI 10.1097/00001756-199603220-00021
   David AS, 1999, ACTA PSYCHIAT SCAND, V99, P95, DOI 10.1111/j.1600-0447.1999.tb05988.x
   Dollfus S, 2005, BIOL PSYCHIAT, V57, P1020, DOI 10.1016/j.biopsych.2005.01.009
   Fairfield B, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00191
   First M. B., 2015, STRUCTURED CLIN INTE
   FLAUM M, 1995, J PSYCHIAT RES, V29, P261, DOI 10.1016/0022-3956(94)00046-T
   Gavrilescu M, 2010, PSYCHOL MED, V40, P1149, DOI 10.1017/S0033291709991632
   GREEN MF, 1994, AM J PSYCHIAT, V151, P357
   HAMILTON M, 1960, J NEUROL NEUROSUR PS, V23, P56, DOI 10.1136/jnnp.23.1.56
   Heinks-Maldonado TH, 2007, ARCH GEN PSYCHIAT, V64, P286, DOI 10.1001/archpsyc.64.3.286
   Hubl D, 2007, BRIT J PSYCHIAT, V190, P57, DOI 10.1192/bjp.bp.106.022954
   Hugdahl K, 2003, ASYMMETRICAL BRAIN, P441
   Hugdahl K, 2016, NEUROPSYCHOLOGIA, V93, P466, DOI 10.1016/j.neuropsychologia.2015.12.011
   Hugdahl K, 2009, FRONT NEUROSCI-SWITZ, V3, P34, DOI 10.3389/neuro.01.001.2009
   Hugdahl Kenneth, 2008, Cogn Neuropsychiatry, V13, P166, DOI 10.1080/13546800801906808
   Hugdahl K, 2008, FRONT HUM NEUROSCI, V1, DOI 10.3389/neuro.09.006.2007
   KAPRINIS G, 1995, PERCEPT MOTOR SKILL, V80, P1275, DOI 10.2466/pms.1995.80.3c.1275
   Kimura D, 1967, CORTEX, V3, P163, DOI [DOI 10.1016/S0010-9452(67)80010-8, 10.1016/s0010-9452(67)80010-8]
   Klar AJS, 1999, SCHIZOPHR RES, V39, P207, DOI 10.1016/S0920-9964(99)00075-4
   Lennox BR, 2000, PSYCHIAT RES-NEUROIM, V100, P13, DOI 10.1016/S0925-4927(00)00068-8
   Leroux E, 2017, WORLD J BIOL PSYCHIA, V18, P528, DOI 10.1080/15622975.2016.1274053
   Levitan C, 1999, BIOL PSYCHIAT, V46, P955, DOI 10.1016/S0006-3223(98)00373-4
   Linden DEJ, 2011, CEREB CORTEX, V21, P330, DOI 10.1093/cercor/bhq097
   Loberg EM, 2004, PSYCHIAT RES, V128, P167, DOI 10.1016/j.psychres.2004.01.011
   Mammarella N, 2010, PSYCHIAT RES, V179, P267, DOI 10.1016/j.psychres.2009.05.005
   McCarthy-Jones S, 2014, SCHIZOPHRENIA BULL, V40, P225, DOI 10.1093/schbul/sbs156
   MCGUIRE PK, 1995, LANCET, V346, P596, DOI 10.1016/S0140-6736(95)91435-8
   McGuire PK, 1996, PSYCHOL MED, V26, P29, DOI 10.1017/S0033291700033699
   McGuire PK, 1996, BRIT J PSYCHIAT, V169, P148, DOI 10.1192/bjp.169.2.148
   McKay CM, 2000, AM J PSYCHIAT, V157, P759, DOI 10.1176/appi.ajp.157.5.759
   Mulert C, 2012, WORLD J BIOL PSYCHIA, V13, P153, DOI 10.3109/15622975.2011.570789
   Najt P, 2014, PSYCHIAT RES, V220, P315, DOI 10.1016/j.psychres.2014.08.015
   O'Donoghue S, 2017, J AFFECT DISORDERS, V209, P217, DOI 10.1016/j.jad.2016.11.015
   Ocklenburg S, 2014, NEUROSCI LETT, V580, P32, DOI 10.1016/j.neulet.2014.07.044
   Oertel V, 2010, J NEUROSCI, V30, P2289, DOI 10.1523/JNEUROSCI.4575-09.2010
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Pollmann S, 2002, NEUROPSYCHOLOGY, V16, P56, DOI 10.1037//0894-4105.16.1.56
   Prete G, 2020, LANG COGN NEUROSCI, V35, P409, DOI 10.1080/23273798.2019.1659990
   Prete G, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34086-3
   Prete G, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00351
   Prete G, 2016, HEARING RES, V332, P80, DOI 10.1016/j.heares.2015.12.011
   Raij TT, 2012, NEUROIMAGE-CLIN, V1, P75, DOI 10.1016/j.nicl.2012.09.007
   Rossell SL, 2005, SCHIZOPHR RES, V78, P95, DOI 10.1016/j.schres.2005.06.002
   Shenton ME, 2001, SCHIZOPHR RES, V49, P1, DOI 10.1016/S0920-9964(01)00163-3
   Shergill SS, 2004, BRIT J PSYCHIAT, V185, P516, DOI 10.1192/bjp.185.6.516
   Sommer I, 2001, BRIT J PSYCHIAT, V178, P344, DOI 10.1192/bjp.178.4.344
   Sommer IEC, 2007, SCHIZOPHR RES, V89, P364, DOI 10.1016/j.schres.2006.09.005
   Steinmann S, 2019, INT J PSYCHOPHYSIOL, V145, P83, DOI 10.1016/j.ijpsycho.2019.02.002
   Steinmann S, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00055
   Stephane M, 2001, SCHIZOPHR RES, V50, P61, DOI 10.1016/S0920-9964(00)00150-X
   Toh WL, 2015, J AFFECT DISORDERS, V184, P18, DOI 10.1016/j.jad.2015.05.040
   van der Gaag M, 2006, SCHIZOPHRENIA BULL, V32, pS113, DOI 10.1093/schbul/sbl027
   WALE J, 1988, PSYCHIAT RES, V25, P31, DOI 10.1016/0165-1781(88)90155-2
   WEXLER BE, 1991, BIOL PSYCHIAT, V29, P103, DOI 10.1016/0006-3223(91)90039-O
   WEXLER BE, 1979, ARCH GEN PSYCHIAT, V36, P278
   Wigand M, 2015, WORLD J BIOL PSYCHIA, V16, P31, DOI 10.3109/15622975.2014.948063
   WOODRUFF P, 1995, LANCET, V346, P1035, DOI 10.1016/S0140-6736(95)91715-2
   Woodruff PWR, 1997, AM J PSYCHIAT, V154, P1676, DOI 10.1176/ajp.154.12.1676
   YOUNG RC, 1978, BRIT J PSYCHIAT, V133, P429, DOI 10.1192/bjp.133.5.429
   Zhang ZJ, 2008, J PSYCHIATR RES, V42, P477, DOI 10.1016/j.jpsychires.2007.04.003
NR 75
TC 0
Z9 0
U1 2
U2 2
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD SEP
PY 2020
VL 146
AR 107567
DI 10.1016/j.neuropsychologia.2020.107567
PG 7
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA NT6AA
UT WOS:000573020100006
PM 32698031
OA Other Gold
DA 2021-02-24
ER

PT J
AU Chao, XH
   Xiao, Y
   Zhang, FG
   Luo, JF
   Wang, RJ
   Liu, WW
   Wang, HB
   Xu, L
AF Chao, Xiuhua
   Xiao, Yun
   Zhang, Fengguo
   Luo, Jianfen
   Wang, Ruijie
   Liu, Wenwen
   Wang, Haibo
   Xu, Lei
TI Cochlear Implantation in a Patient with a NovelPOU3F4Mutation and
   Incomplete Partition Type-III Malformation
SO NEURAL PLASTICITY
LA English
DT Article
ID HEARING-LOSS; SPEECH-PERCEPTION; CHILDREN; DEAFNESS; GENE; MUTATIONS;
   CLASSIFICATION; ALIGNMENT; PROTECTS; DAMAGE
AB Aims. This study is aimed at (1) analyzing the clinical manifestations and genetic features of a novelPOU3F4mutation in a nonsyndromic X-linked recessive hearing loss family and (2) reporting the outcomes of cochlear implantation in a patient with this mutation.Methods. A patient who was diagnosed as the IP-III malformation underwent cochlear implantation in our hospital. The genetic analysis was conducted in his family, including the whole-exome sequencing combined with Sanger sequencing and bioinformatic analysis. Clinical features, preoperative auditory and speech performances, and postoperative outcomes of cochlear implant (CI) were assessed on the proband and his family.Results. A novel variant c.400_401insACTC (p.Q136LfsX58) in thePOU3F4gene was detected in the family, which was cosegregated with the hearing loss. This variant was absent in 200 normal-hearing persons. The phylogenetic analysis and structure modeling of Pou3f4 protein further confirmed that the novel mutation was pathogenic. The proband underwent cochlear implantation on the right ear at four years old and gained greatly auditory and speech improvement. However, the benefits of the CI declined about three and a half years postoperation. Though the right ear had been reimplanted, the outcomes were still worse than before.Conclusion. A novel frame shift variant c.400_401insACTC (p.Q136LfsX58) in thePOU3F4gene was identified in a Chinese family with X-linked inheritance hearing loss. A patient with this mutation and IP-III malformation could get good benefits from CI. However, the outcomes of the cochlear implantation might decline as the patient grows old.
C1 [Chao, Xiuhua; Xiao, Yun; Zhang, Fengguo; Luo, Jianfen; Wang, Ruijie; Liu, Wenwen; Wang, Haibo; Xu, Lei] Shandong Univ, Cheeloo Coll Med, Shandong Prov ENT Hosp, Dept Otolaryngol Head & Neck Surg, Jinan 250022, Peoples R China.
RP Xu, L (corresponding author), Shandong Univ, Cheeloo Coll Med, Shandong Prov ENT Hosp, Dept Otolaryngol Head & Neck Surg, Jinan 250022, Peoples R China.
EM xiuhuachao@163.com; xiaoyunzju@163.com; zhangfg_vip@163.com;
   luojianfen1979@163.com; bestydp@163.com; wenwenliu_1@yahoo.com;
   whboto11@163.com; sdphxl@126.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [81800905, 81670932]; Key Project of Shandong
   Provincial Programs for Research and Development [2017CXGC1213]; Taishan
   Scholars Program of Shandong Province [ts20130913, tsqn201909189]
FX This work was supported by grants from the National Natural Science
   Foundation of China (No. 81800905 and No. 81670932), the Key Project of
   Shandong Provincial Programs for Research and Development
   (2017CXGC1213), and the Taishan Scholars Program of Shandong Province
   (No. ts20130913 and No. tsqn201909189).
CR Brooks PM, 2020, J COMP NEUROL, V528, P1967, DOI 10.1002/cne.24867
   Choi BY, 2016, LARYNGOSCOPE, V126, pE123, DOI 10.1002/lary.25573
   Coate TM, 2012, NEURON, V73, P49, DOI 10.1016/j.neuron.2011.10.029
   Corvino V, 2018, CURR GENOMICS, V19, P327, DOI 10.2174/1389202919666171218163046
   Davcheva-Chakar M, 2014, BALK MED J, V31, P60, DOI 10.5152/balkanmedj.2014.9535
   DEKOK YJM, 1995, SCIENCE, V267, P685, DOI 10.1126/science.7839145
   He SM, 2018, EAR HEARING, V39, P238, DOI 10.1097/AUD.0000000000000467
   He ZH, 2020, REDOX BIOL, V28, DOI 10.1016/j.redox.2019.101364
   He ZH, 2017, AUTOPHAGY, V13, P1884, DOI 10.1080/15548627.2017.1359449
   Kanno A, 2017, LARYNGOSCOPE, V127, P1662, DOI 10.1002/lary.26245
   Kim JR, 2010, OTOL NEUROTOL, V31, P1041, DOI 10.1097/MAO.0b013e3181ec1d92
   Kim L, 2016, ANN OTO RHINOL LARYN, V125, P173, DOI 10.1177/0003489415604167
   Lee HK, 2009, PHYSIOL GENOMICS, V39, P195, DOI 10.1152/physiolgenomics.00100.2009
   Li H, 2009, BIOINFORMATICS, V25, P1754, DOI 10.1093/bioinformatics/btp324
   Liu L, 2016, CELL DEATH DIS, V7, DOI 10.1038/cddis.2016.35
   Liu WW, 2019, ANTIOXID REDOX SIGN, V30, P1389, DOI 10.1089/ars.2017.7288
   Liu Y, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aav7803
   MATHIS JM, 1992, EMBO J, V11, P2551, DOI 10.1002/j.1460-2075.1992.tb05320.x
   Moteki H, 2015, ANN OTO RHINOL LARYN, V124, p169S, DOI 10.1177/0003489415575042
   NANCE W E, 1971, Birth Defects Original Article Series, V7, P64
   Petersen MB, 2008, CLIN GENET, V73, P14, DOI 10.1111/j.1399-0004.2007.00913.x
   Pfingst BE, 2015, HEARING RES, V330, P98, DOI 10.1016/j.heares.2015.07.010
   Phippard D, 1999, J NEUROSCI, V19, P5980, DOI 10.1523/JNEUROSCI.19-14-05980.1999
   Qi JY, 2019, CELL DISCOV, V5, DOI 10.1038/s41421-018-0076-4
   Samadi DS, 2005, HEARING RES, V199, P11, DOI 10.1016/j.heares.2004.07.013
   Sennaroglu L, 2002, LARYNGOSCOPE, V112, P2230, DOI 10.1097/00005537-200212000-00019
   Sennaroglu L, 2018, AURIS NASUS LARYNX, V45, P26, DOI 10.1016/j.anl.2017.02.006
   Sennarolu L, 2017, MED J, V34, P397, DOI DOI 10.4274/balkanmedj.2017.0367
   Smeds H, 2017, OTOL NEUROTOL, V38, P38, DOI 10.1097/MAO.0000000000001253
   Song MH, 2011, BIOCHEM BIOPH RES CO, V404, P528, DOI 10.1016/j.bbrc.2010.12.019
   Stankovic KM, 2010, ANN OTO RHINOL LARYN, V119, P815, DOI 10.1177/000348941011901205
   Tarasov A, 2015, BIOINFORMATICS, V31, P2032, DOI 10.1093/bioinformatics/btv098
   Trowe MO, 2008, DEVELOPMENT, V135, P1725, DOI 10.1242/dev.014043
   Wang K, 2010, NUCLEIC ACIDS RES, V38, DOI 10.1093/nar/gkq603
   Wang YF, 2017, FRONT MOL NEUROSCI, V10, DOI 10.3389/fnmol.2017.00401
   Xia AP, 2002, HEARING RES, V166, P150, DOI 10.1016/S0378-5955(02)00309-X
   Xu L, 2020, EAR HEARING, V41, P1306, DOI 10.1097/AUD.0000000000000854
   Zhang FG, 2016, INT J PEDIATR OTORHI, V85, P75, DOI 10.1016/j.ijporl.2016.03.020
   Zhu CW, 2018, FRONT MOL NEUROSCI, V11, DOI 10.3389/fnmol.2018.00362
NR 39
TC 0
Z9 0
U1 1
U2 1
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 2090-5904
EI 1687-5443
J9 NEURAL PLAST
JI Neural. Plast.
PD SEP 1
PY 2020
VL 2020
AR 8829587
DI 10.1155/2020/8829587
PG 9
WC Neurosciences
SC Neurosciences & Neurology
GA NS6BF
UT WOS:000572343800003
PM 32952548
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Lee, S
   Cho, MH
AF Lee, Shinsook
   Cho, Mi-Hui
TI The impact of L2-learning experience and target dialect on predicting
   English vowel identification using Korean vowel categories
SO JOURNAL OF PHONETICS
LA English
DT Article
DE L1-based model; English vowel identification; English-Korean vowel
   mapping; L2-learning experience: long LOR vs. short; LOR; Familiarity
   with L2 dialect
ID AMERICAN ENGLISH; ACOUSTIC CHARACTERISTICS; SPEECH-PERCEPTION; JAPANESE
   ADULTS; LANGUAGE; OBSTRUENTS; SYSTEMS; ACCENT
AB Park and de Jong (2008, 2017) reported that their L1-based model predicted the identification of English consonants with Korean analogues quite successfully while error rates for those without Korean analogues were systematically greater than the model predicted, and Lee and Cho (2018) obtained similar results for English vowels. However, Park and de Jong (2008, 2017) and Lee and Cho (2018) examined only L1-Korean inexperienced EFL listeners' identification of English consonants or vowels. English vowels such as /ae-a/ (bat), /3-3/ (Burt), and /alpha-D/ (stop) exhibit dialect differences between North American English (NAE) and Standard Southern British English (SSBE), but few researchers have examined Korean second language (L2) listeners' perceptions of English vowels in regional dialects other than NAE. The current study was an investigation of the degree to which the L1-based model predicts L1-Korean experienced L2 listeners' identification of NAE and SSBE vowels based on the predictions that experienced L2 listeners are less likely to use L1 (first language) categories in L2 vowel identification than are inexperienced L2 listeners and that even experienced L2 listeners might use L1 categories when identifying L2 vowels in a less familiar English dialect. Korean listeners with different lengths of residence (LOR) in the United States (long: 11.1 years vs. short: 4 years) and with limited experience with British English completed English vowel identification and English-Korean vowel mapping tasks. The results show that the L1-based model predicted only the short-LOR listeners' identification of NAE and SSBE vowels rather accurately, indicating the effect of L2-learning experience. The model also more accurately predicted the short-LOR listeners' identification of SSBE vowels relative to NAE vowels, showing that the impact of the amount of L2 learning-experience decreased with a less familiar dialect. When the listeners' goodness ratings of the category mapping were considered, the predictive power of the model weakened. Further, the new-similar distinction for L2 English vowels vis-a-vis L1-Korean may be gradient, and the new-similar distinction is variable depending on L2-learning experiences. (C) 2020 Elsevier Ltd. All rights reserved.
C1 [Lee, Shinsook] Korea Univ, Dept English Language Educ, 145 Anam Ro, Seoul 02841, South Korea.
   [Cho, Mi-Hui] Kyonggi Univ, Dept English Language & Literature, 154-42 Gwanggyosan Ro, Suwon 16227, Gyeonggi Do, South Korea.
RP Cho, MH (corresponding author), Kyonggi Univ, Dept English Language & Literature, 154-42 Gwanggyosan Ro, Suwon 16227, Gyeonggi Do, South Korea.
EM leesseng@korea.ac.kr; mcho@kgu.ac.kr
CR Baker W, 2005, LANG SPEECH, V48, P1, DOI 10.1177/00238309050480010101
   Baker W, 2008, LANG SPEECH, V51, P317, DOI 10.1177/0023830908099068
   Bent T, 2016, J PHONETICS, V58, P104, DOI 10.1016/j.wocn.2016.08.004
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boberg C, 2015, BLACKW HBK LINGUIST, P229
   CELCE-MURCIA Marianne, 2010, TEACHING PRONUNCIATI
   Chang C.C., 2010, THESIS
   Chang CB, 2019, J PHONETICS, V74, P96, DOI 10.1016/j.wocn.2019.03.001
   CHUN J, 2015, ADV SCI LETT, V21, P297, DOI DOI 10.1166/asl.2015.5872
   Clopper CG, 2005, J ACOUST SOC AM, V118, P1661, DOI 10.1121/1.2000774
   Cowie I., 1991, J ACOUST SOC AM, V89, P1936
   Escudero P, 2004, STUD SECOND LANG ACQ, V26, P551, DOI 10.1017/S0272226310400021
   Evans BG, 2004, J ACOUST SOC AM, V115, P352, DOI 10.1121/1.1635413
   Evans BG, 2007, J ACOUST SOC AM, V121, P3814, DOI 10.1121/1.2722209
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   FLEGE JE, 1995, LANG SPEECH, V38, P25, DOI 10.1177/002383099503800102
   Guion SG, 2000, J ACOUST SOC AM, V107, P2711, DOI 10.1121/1.428657
   Han Jeong-Im, 2011, [Phonetics and Speech Sciences, 말소리와 음성과학], V3, P53
   Han Jeong-Im, 2011, [Korean Journal of English Language and Linguistics, 영어학], V11, P385
   Heo Y., 2015, HARVARD STUDIES KORE, VXIV, P77
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Ingram JCL, 1997, J PHONETICS, V25, P343, DOI 10.1006/jpho.1997.0048
   Iverson P, 2009, J ACOUST SOC AM, V126, P866, DOI 10.1121/1.3148196
   Kang O., 2003, KOREAN PHONOLOGY
   Labov W, 1998, HDB DIALECTS LANGUAG, P39
   Ladefoged P., 2006, COURSE PHONETICS
   Lee S, 2018, LANG SCI, V66, P183, DOI 10.1016/j.langsci.2017.09.006
   Lee Sun-Young, 2018, [Studies in Phonetics, Phonology, and Morphology, 음성음운형태론연구], V24, P209, DOI 10.17959/sppm.2018.24.2.209
   LEHISTE I, 1961, J ACOUST SOC AM, V33, P268, DOI 10.1121/1.1908638
   Park H, 2008, J PHONETICS, V36, P704, DOI 10.1016/j.wocn.2008.06.002
   Park H, 2017, J PHONETICS, V62, P12, DOI 10.1016/j.wocn.2017.01.005
   Schmidt AM, 1996, J ACOUST SOC AM, V99, P3201, DOI 10.1121/1.414804
   Strange W, 1998, J PHONETICS, V26, P311, DOI 10.1006/jpho.1998.0078
   Strange W., 2007, LANGUAGE EXPERIENCE, P35, DOI DOI 10.1075/LLLT.17.08STR
   Tauroza S., 1997, RELC J, V28, P54, DOI [DOI 10.1177/003368829702800104, 10.1177/003368829702800104]
   Wells John, 1982, ACCENTS ENGLISH, V2
   Williams A, 1999, URBAN VOICES ACCENT, P141
   Yang BG, 1996, J PHONETICS, V24, P245, DOI 10.1006/jpho.1996.0013
NR 39
TC 0
Z9 0
U1 2
U2 2
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD SEP
PY 2020
VL 82
AR 100983
DI 10.1016/j.wocn.2020.100983
PG 20
WC Linguistics; Language & Linguistics
SC Linguistics
GA NR4JC
UT WOS:000571529500001
DA 2021-02-24
ER

PT J
AU Howson, PJ
   Kallay, JE
   Redford, MA
AF Howson, Phil J.
   Kallay, Jeffrey E.
   Redford, Melissa A.
TI A psycholinguistic method for measuring coarticulation in child and
   adult speech
SO BEHAVIOR RESEARCH METHODS
LA English
DT Article; Early Access
DE Gating paradigm; AV speech perception; Speech production; Online
   perception task
ID HORIZONTAL VIEWING ANGLE; TO-VOWEL COARTICULATION; AUDIOVISUAL SPEECH;
   MECHANICAL TURK; PERCEPTION; SPOKEN; ULTRASOUND; SYNERGIES; EXTENT
AB A perceiver's ability to accurately predict target sounds in a forward-gated AV speech task indexes the strength and scope of anticipatory coarticulation in adult speech (Redford et al.,JASA, 144, 2447-2461,2018). This suggests a perception-based method for studying coarticulation in populations who may poorly tolerate the more invasive or restrictive techniques used to measure speech movements directly. But the use of perception to measure production begs the question of confounding influences on perceiver performance and thus on the reliability and generalizability of the proposed method. The present study was therefore designed to test whether a gated AV speech method for measuring coarticulation provides reliable results across different study populations (child versus adult), different task environments (in-lab versus online), and different coarticulatory directions (forward/anticipatory versus backward/carryover). The results indicated excellent measurement reliability across age groups in the forward/anticipatory measurement direction, though more perceivers are needed to achieve the same levels of agreement and consistency when the task is completed online. Accuracy was lower in the backward/carryover direction, and although agreement and consistency were still reasonably high across perceivers, the effect of age group differed between the laboratory and online environments, suggesting measurement error in one or both environments. Overall, the results support using in-lab or online perceptual judgments to measure anticipatory coarticulation in developmental studies of speech production. Further validation study is needed before the method can be extended to measure carryover coarticulation.
C1 [Howson, Phil J.; Kallay, Jeffrey E.; Redford, Melissa A.] 1290 Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.
RP Redford, MA (corresponding author), 1290 Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.
EM redford@uoregon.edu
OI Redford, Melissa/0000-0002-0692-2810
FU Eunice Kennedy Shriver National Institute of Child Health & Human
   Development (NICHD)United States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [R01HD087452]
FX This research was wholly supported by the Eunice Kennedy Shriver
   National Institute of Child Health & Human Development (NICHD) under
   grant R01HD087452 (PI: Redford). The content is solely the authors'
   responsibility and does not necessarily reflect the views of NICHD.
CR Arditte KA, 2016, PSYCHOL ASSESSMENT, V28, P684, DOI 10.1037/pas0000217
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Baum SR, 2000, J ACOUST SOC AM, V107, P3572, DOI 10.1121/1.429429
   Beddor PS, 2002, J PHONETICS, V30, P591, DOI 10.1006/jpho.2002.0177
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155
   Davidson L, 2006, J ACOUST SOC AM, V120, P407, DOI 10.1121/1.2205133
   Dell GS, 1997, PSYCHOL REV, V104, P801, DOI 10.1037/0033-295X.104.4.801
   DELL GS, 1986, PSYCHOL REV, V93, P283, DOI 10.1037/0033-295X.93.3.283
   Derrick D, 2011, CAN J LING/REV CAN L, V56, P307, DOI 10.1353/cjl.2011.0024
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x
   FOWLER CA, 1981, J SPEECH HEAR RES, V24, P127, DOI 10.1044/jshr.2401.127
   Gamer M, 2012, PACKAGE IRR VARIOUS
   Goffman L, 2008, J SPEECH LANG HEAR R, V51, P1424, DOI 10.1044/1092-4388(2008/07-0020)
   Goldman R, 1999, GOLDMAN FRISTOE TEST
   Goldrick M, 2007, COGNITION, V102, P219, DOI 10.1016/j.cognition.2005.12.010
   Goodman JK, 2013, J BEHAV DECIS MAKING, V26, P213, DOI 10.1002/bdm.1753
   Grosvald M, 2009, J PHONETICS, V37, P173, DOI 10.1016/j.wocn.2009.01.002
   Hardcastle W. J, 2008, P 8 INT SEM SPEECH P, P161
   Hauser DJ, 2016, BEHAV RES METHODS, V48, P400, DOI 10.3758/s13428-015-0578-z
   Jordan T, 1997, IEEE SYS MAN CYBERN, P1626, DOI 10.1109/ICSMC.1997.638235
   Jordan TR, 1997, J EXP PSYCHOL HUMAN, V23, P388, DOI 10.1037/0096-1523.23.2.388
   Jordan TR, 2001, J EXP PSYCHOL HUMAN, V27, P1386, DOI 10.1037//0096-1523.27.6.1386
   Kallay Jeffrey E, 2018, Speech Prosody, V2018, P1004, DOI 10.21437/SpeechProsody.2018-203
   Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012
   Lenth R., 2018, R PACKAGE VERSION, V1, P3
   Levelt W. J., 1993, SPEAKING INTENTION A
   Magen HS, 1997, J PHONETICS, V25, P187, DOI 10.1006/jpho.1996.0041
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Miller JD, 2017, PERSONAL DISORD, V8, P26, DOI 10.1037/per0000191
   Mok PKP, 2010, J ACOUST SOC AM, V128, P1346, DOI 10.1121/1.3466859
   NITTROUER S, 1989, J SPEECH HEAR RES, V32, P120, DOI 10.1044/jshr.3201.120
   Noiray A, 2018, J SPEECH LANG HEAR R, V61, P1355, DOI 10.1044/2018_JSLHR-S-17-0148
   Noiray A, 2013, J ACOUST SOC AM, V133, P444, DOI 10.1121/1.4763983
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002
   R Core Team, 2018, R LANG ENV STAT COMP
   RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239
   Redford MA, 2018, J ACOUST SOC AM, V144, P2447, DOI 10.1121/1.5064783
   Rubertus E, 2020, LAB PHONOL, V11, DOI 10.5334/labphon.228
   Rubertus E, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203562
   Salverda AP, 2014, J MEM LANG, V71, P145, DOI 10.1016/j.jml.2013.11.002
   Sergeant P. C, 1998, HEARING EYE 2, P155
   Shapiro DN, 2013, CLIN PSYCHOL SCI, V1, P213, DOI 10.1177/2167702612469015
   Smith A, 2004, DEV PSYCHOBIOL, V45, P22, DOI 10.1002/dev.20009
   STEVENS KN, 1989, LANGUAGE, V65, P81, DOI 10.2307/414843
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Westbury JR, 1998, SPEECH COMMUN, V26, P203, DOI 10.1016/S0167-6393(98)00058-2
   WHALEN DH, 1990, J PHONETICS, V18, P3, DOI 10.1016/S0095-4470(19)30356-0
   Wickham H, 2016, GGPLOT2 ELEGANT GRAP
   Wolak ME, 2012, METHODS ECOL EVOL, V3, P129, DOI 10.1111/j.2041-210X.2011.00125.x
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
   Zharkova N, 2011, MOTOR CONTROL, V15, P118, DOI 10.1123/mcj.15.1.118
NR 52
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1554-351X
EI 1554-3528
J9 BEHAV RES METHODS
JI Behav. Res. Methods
DI 10.3758/s13428-020-01464-7
EA SEP 2020
PG 18
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA NI2HX
UT WOS:000565177700005
PM 32875402
DA 2021-02-24
ER

PT J
AU Cristia, A
AF Cristia, Alejandrina
TI Language input and outcome variation as a test of theory plausibility:
   The case of early phonological acquisition
SO DEVELOPMENTAL REVIEW
LA English
DT Article
DE Input; Phonological acquisition; Individual variation; Socioeconomic
   status; Cultural variation
ID SPEECH-PERCEPTION; SOCIOECONOMIC-STATUS; SOCIAL FEEDBACK; INFANTS;
   EXPERIENCE; MODELS; BABBLE
AB There is wide individual, social, and cultural variation in experiences afforded to young children, yet current evidence suggests there is little variation in phonological outcomes in the first year of life. This paper provides a classification of phonological acquisition theories, revealing that few of them predict no variation in phonological acquisition outcomes, and thus are plausible in view of observed patterns: Only theories with strong priors and informational fillers, and where phonological acquisition does not depend on lexical development, are compatible with great variation in early language experiences resulting in minimal or no outcome variation. The approach is then extended to consider proposals contemplating acquisition of other linguistic levels, including joint learning frameworks, and testable predictions are drawn for the acquisition of morphosyntax and vocabulary.
C1 [Cristia, Alejandrina] PSL Univ, Dept Etud Cognit, Lab Sci Cognit & Psycholinguist, CNRS,ENS,EHESS, 29 Rue Ulm, F-75005 Paris, France.
RP Cristia, A (corresponding author), PSL Univ, Dept Etud Cognit, Lab Sci Cognit & Psycholinguist, CNRS,ENS,EHESS, 29 Rue Ulm, F-75005 Paris, France.
EM alecristia@gmail.com
FU Agence Nationale de la RechercheFrench National Research Agency
   (ANR)European Commission [ANR-17-CE28-0007 LangAge, ANR-16-DATA-0004
   ACLEW, ANR-14-CE30-0003 MechELex, ANR-17-EURE-0017]; J. S. McDonnell
   Foundation Understanding Human Cognition Scholar Award
FX I am grateful for the support of the Agence Nationale de la Recherche
   (ANR-17-CE28-0007 LangAge, ANR-16-DATA-0004 ACLEW, ANR-14-CE30-0003
   MechELex, ANR-17-EURE-0017); and the J. S. McDonnell Foundation
   Understanding Human Cognition Scholar Award. I thank Emmanuel Dupoux,
   Teodora Gliga, Naomi Havron, Paul Iverson, Francis Mollica, Lisa Pearl,
   Steven Piantadosi, Amanda Seidl, Sho Tsuji, and anonymous reviewers for
   helpful discussion and/or feedback on previous versions of this work. I
   take full responsibility for the contents. Declarations of interest:
   none.
CR Ambridge B., 2015, HDB LANGUAGE EMERGEN, P478, DOI [10.1002/9781118346136.ch22, DOI 10.1002/9781118346136.CH22]
   [Anonymous], 2020, UNPUB
   Bates E., 2001, LANGUAGE DEV ESSENTI, P134
   Bergelson E, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12724
   Bergelson E, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12715
   Bergelson E, 2018, CHILD DEV, V89, P1567, DOI 10.1111/cdev.12888
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   Chambers KE, 2003, COGNITION, V87, pB69, DOI 10.1016/S0010-0277(02)00233-0
   Christiansen MH, 2008, BEHAV BRAIN SCI, V31, P489, DOI 10.1017/S0140525X08004998
   Christiansen MH, 2016, BEHAV BRAIN SCI, V39, DOI 10.1017/S0140525X1500031X
   Clark A, 2010, LINGUISTIC NATIVISM
   Costafreda Sergi G, 2009, Front Neuroinform, V3, P33, DOI 10.3389/neuro.11.033.2009
   Cristia A, 2014, CHILD DEV, V85, P1330, DOI 10.1111/cdev.12193
   Cristia A, 2014, DEVELOPMENTAL SCI, V17, P628, DOI 10.1111/desc.12160
   Csibra G, 2009, TRENDS COGN SCI, V13, P148, DOI 10.1016/j.tics.2009.01.005
   Curtin S, 2011, J PHONETICS, V39, P492, DOI 10.1016/j.wocn.2010.12.002
   Dehaene-Lambertz G, 2004, J COGNITIVE NEUROSCI, V16, P1375, DOI 10.1162/0898929042304714
   EILERS RE, 1993, INFANT BEHAV DEV, V16, P297, DOI 10.1016/0163-6383(93)80037-9
   Fourtassi A., 2014, P 18 C COMP NAT LANG, P191
   Frank MC, 2017, INFANCY, V22, P421, DOI 10.1111/infa.12182
   Frank MC, 2009, PSYCHOL SCI, V20, P578, DOI 10.1111/j.1467-9280.2009.02335.x
   Frank R, 2013, LANG ACQUIS, V20, P181, DOI 10.1080/10489223.2013.796950
   Frank S, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1073
   Goldin-Meadow S, 2015, COGNITION, V136, P381, DOI 10.1016/j.cognition.2014.11.029
   Goldin-Meadow S, 2014, J CHILD LANG, V41, P64, DOI 10.1017/S030500091400021X
   Goldstein MH, 2008, PSYCHOL SCI, V19, P515, DOI 10.1111/j.1467-9280.2008.02117.x
   Goldwater S, 2009, COGNITION, V112, P21, DOI 10.1016/j.cognition.2009.03.008
   Golinkoff RM, 2015, CURR DIR PSYCHOL SCI, V24, P339, DOI 10.1177/0963721415595345
   Gonzalez-Gomez N, 2012, DEVELOPMENTAL SCI, V15, P885, DOI 10.1111/j.1467-7687.2012.01186.x
   Gros-Louis J, 2006, INT J BEHAV DEV, V30, P509, DOI 10.1177/0165025406071914
   Hale M, 2003, J LINGUIST, V39, P219, DOI 10.1017/S0022226703002019
   Hayes Bruce, 2004, CONSTRAINTS PHONOLOG, P158, DOI DOI 10.1017/CBO9780511486418.006
   Heinz J, 2016, OXFORD HDB DEV LINGU, P633
   Horlyck S, 2012, SCI STUD READ, V16, P218, DOI 10.1080/10888438.2010.546460
   Imai M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116494
   Johnson M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P282
   Johnson S. C., 2003, PHILOS T R SOC B, V358, P549
   Kaplan F, 2008, INFANT CHILD DEV, V17, P55, DOI 10.1002/icd.544
   Kuhl PK, 2007, DEVELOPMENTAL SCI, V10, P110, DOI 10.1111/j.1467-7687.2007.00572.x
   Kuhl PK, 2003, P NATL ACAD SCI USA, V100, P9096, DOI 10.1073/pnas.1532872100
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Lakens D, 2020, J GERONTOL B-PSYCHOL, V75, P45, DOI 10.1093/geronb/gby065
   LENNEBERG EH, 1969, SCIENCE, V164, P635, DOI 10.1126/science.164.3880.635
   Lieven E, 2010, LANG ACQUIS, P91
   MacWhinney B., 2000, CHILDES PROJECT TOOL
   Magri G., 2014, P ANN M PHON
   Magri G, 2013, LINGUIST INQ, V44, DOI 10.1162/ling_a_00134
   Majorano M, 2014, LANG LEARN DEV, V10, P179, DOI 10.1080/15475441.2013.829740
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   McGillion M, 2017, CHILD DEV, V88, P156, DOI 10.1111/cdev.12671
   Melvin SA, 2017, INFANCY, V22, P42, DOI 10.1111/infa.12145
   Mollica F, 2019, ROY SOC OPEN SCI, V6, DOI 10.1098/rsos.181393
   Nespor M, 2008, LINGUE LINGUAGGIO, V7, P139, DOI 10.1418/28093
   Ochs E., 2001, LINGUISTIC ANTHR REA, P263
   Oller D. K., 1995, FIRST LANG, V15, P167, DOI DOI 10.1177/014272379501504403
   OLLER DK, 1994, J CHILD LANG, V21, P33, DOI 10.1017/S0305000900008667
   Pace A, 2017, ANNU REV LINGUIST, V3, P285, DOI 10.1146/annurev-linguistics-011516-034226
   Pearl L. S., 2019, MODELING SYNTACTIC A
   Pearl Lisa, 2013, CAMBRIDGE HDB BIOLIN, DOI [10.1017/CBO9780511980435, DOI 10.1017/CBO9780511980435.010]
   Petitto LA, 2004, COGNITION, V93, P43, DOI 10.1016/j.cognition.2003.10.007
   Phillips L, 2015, COGNITIVE SCI, V39, P1824, DOI 10.1111/cogs.12217
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   Poeppel D, 2014, CURR OPIN NEUROBIOL, V28, P142, DOI 10.1016/j.conb.2014.07.005
   Ramirez-Esparza N, 2014, DEVELOPMENTAL SCI, V17, P880, DOI 10.1111/desc.12172
   Rasanen O, 2012, SPEECH COMMUN, V54, P975, DOI 10.1016/j.specom.2012.05.001
   Rogoff B, 2003, ANNU REV PSYCHOL, V54, P175, DOI 10.1146/annurev.psych.54.101601.145118
   Rose Y., 2014, OXFORD HDB CORPUS PH, P380
   Sandler W, 2005, P NATL ACAD SCI USA, V102, P2661, DOI 10.1073/pnas.0405448102
   Scaff C., 2019, SOCIOECONOMIC UNPUB
   Shneidman L. A, 2010, THESIS
   Shneidman L, 2016, PSYCHOL BULL, V142, P1, DOI 10.1037/bul0000023
   Shneidman LA, 2013, J CHILD LANG, V40, P672, DOI 10.1017/S0305000912000141
   Smith L, 2008, COGNITION, V106, P1558, DOI 10.1016/j.cognition.2007.06.010
   Trueswell JC, 2013, COGNITIVE PSYCHOL, V66, P126, DOI 10.1016/j.cogpsych.2012.10.001
   Tsuji S., 2019, FRAMEWORK SOCIAL THE
   Tsuji S, 2014, DEV PSYCHOBIOL, V56, P179, DOI 10.1002/dev.21179
   Versteegh M., 2015, ZERO RESOURCE SPEECH
   Vouloumanos A, 2014, TRENDS COGN SCI, V18, P642, DOI 10.1016/j.tics.2014.10.001
   Warlaumont AS, 2014, PSYCHOL SCI, V25, P1314, DOI 10.1177/0956797614531023
   Weber A, 2017, CHILD DEV, V88, P1513, DOI 10.1111/cdev.12882
   Weisleder A, 2013, PSYCHOL SCI, V24, P2143, DOI 10.1177/0956797613488145
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Yang C. D., 2002, KNOWLEDGE LEARNING N
   Yurovsky D, 2018, NEW IDEAS PSYCHOL, V50, P73, DOI 10.1016/j.newideapsych.2017.09.001
NR 86
TC 1
Z9 1
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0273-2297
EI 1090-2406
J9 DEV REV
JI Dev. Rev.
PD SEP
PY 2020
VL 57
AR 100914
DI 10.1016/j.dr.2020.100914
PG 18
WC Psychology, Developmental
SC Psychology
GA NH4LI
UT WOS:000564642900006
DA 2021-02-24
ER

PT J
AU Gori, M
   Ober, KM
   Tinelli, F
   Coubard, OA
AF Gori, Monica
   Ober, Kinga M.
   Tinelli, Francesca
   Coubard, Olivier A.
TI Temporal representation impairment in developmental dyslexia for
   unisensory and multisensory stimuli
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
DE Multisensory; Development; integration; Bayesian; Audio; Visual
ID AUDITORY SPATIAL LOCALIZATION; READING-DISABILITY; SPEECH-PERCEPTION;
   PHONOLOGICAL AWARENESS; LANGUAGE IMPAIRMENT; VISUAL SPEECH; INTEGRATION;
   CHILDREN; DEFICITS; INFORMATION
AB Dyslexia has been associated with a problem in visual-audio integration mechanisms. Here, we investigate for the first time the contribution of unisensory cues on multisensory audio and visual integration in 32 dyslexic children by modelling results using the Bayesian approach. Non-linguistic stimuli were used. Children performed a temporal task: they had to report whether the middle of three stimuli was closer in time to the first one or to the last one presented. Children with dyslexia, compared with typical children, exhibited poorer unimodal thresholds, requiring greater temporal distance between items for correct judgements, while multisensory thresholds were well predicted by the Bayesian model. This result suggests that the multisensory deficit in dyslexia is due to impaired audio and visual inputs rather than impaired multisensory processing per se. We also observed that poorer temporal skills correlated with lower reading skills in dyslexic children, suggesting that this temporal capability can be linked to reading abilities.
C1 [Gori, Monica] Ist Italiano Tecnol, U VIP Unit Visually Impaired People, Genoa, Italy.
   [Ober, Kinga M.] Adam Mickiewicz Univ, Fac Educ Studies, Poznan, Poland.
   [Tinelli, Francesca] Stella Maris Sci Inst, Dept Dev Neurosci, Pisa, Italy.
   [Coubard, Olivier A.] CNS Fed, Neuropsychol Lab, Paris, France.
RP Gori, M (corresponding author), Ist Italiano Tecnol, U VIP Unit Visually Impaired People, Genoa, Italy.
EM monica.gori@iit.it
RI tinelli, francesca/T-8468-2017
OI tinelli, francesca/0000-0002-7755-5114
CR Ahissar M, 2007, TRENDS COGN SCI, V11, P458, DOI 10.1016/j.tics.2007.08.015
   Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029
   Arvaniti A, 2009, PHONETICA, V66, P46, DOI 10.1159/000208930
   Berger TD, 2003, J VISION, V3, P406, DOI 10.1167/3.6.1
   Blau V, 2010, BRAIN, V133, P868, DOI 10.1093/brain/awp308
   Blau V, 2009, CURR BIOL, V19, P503, DOI 10.1016/j.cub.2009.01.065
   Bogdanowicz M, 2008, DIAGNOZA DYSLEKSJI U
   Brandwein AB, 2013, CEREB CORTEX, V23, P1329, DOI 10.1093/cercor/bhs109
   Brandwein AB, 2011, CEREB CORTEX, V21, P1042, DOI 10.1093/cercor/bhq170
   Bresciani JP, 2007, NEUROREPORT, V18, P1157, DOI 10.1097/WNR.0b013e3281ace0ca
   Brzezinska A., 2003, KOLOKWIA PSYCHOL, V11, P135
   Burr D., 2012, NEURAL BASES MULTISE, P683
   Burr D, 2009, EXP BRAIN RES, V198, P49, DOI 10.1007/s00221-009-1933-z
   Cardon G, 2012, J AM ACAD AUDIOL, V23, P396, DOI 10.3766/jaaa.23.6.3
   Daikhin L, 2017, J SPEECH LANG HEAR R, V60, P471, DOI 10.1044/2016_JSLHR-H-16-0114
   Desantis A, 2016, COGNITION, V153, P33, DOI 10.1016/j.cognition.2016.03.009
   Doucet ME, 2006, BRAIN, V129, P3376, DOI 10.1093/brain/awl264
   Ecalle J, 2009, DYSLEXIA, V15, P218, DOI 10.1002/DYS.373
   EDEN GF, 1995, J LEARN DISABIL, V28, P272, DOI 10.1177/002221949502800503
   Efron B., 1993, INTRO BOOTSTRAP
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Flaugnacco E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138715
   Flaugnacco E, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00392
   Frost R, 1998, PSYCHOL BULL, V123, P71, DOI 10.1037/0033-2909.123.1.71
   Froyen D, 2008, NEUROSCI LETT, V430, P23, DOI 10.1016/j.neulet.2007.10.014
   Froyen D, 2011, DEVELOPMENTAL SCI, V14, P635, DOI 10.1111/j.1467-7687.2010.01007.x
   Froyen DJW, 2009, J COGNITIVE NEUROSCI, V21, P567, DOI 10.1162/jocn.2009.21061
   GALABURDA AM, 1994, COGNITION, V50, P133, DOI 10.1016/0010-0277(94)90025-6
   Gascon G, 1970, Cortex, V6, P417
   GEBHARD JW, 1959, AM J PSYCHOL, V72, P521, DOI 10.2307/1419493
   Giraud AL, 2001, NEURON, V30, P657, DOI 10.1016/S0896-6273(01)00318-X
   Gori M, 2008, CURR BIOL, V18, P694, DOI 10.1016/j.cub.2008.04.036
   Gori M, 2017, NEUROPSYCHOLOGIA, V99, P350, DOI 10.1016/j.neuropsychologia.2017.03.025
   Gori M, 2015, MULTISENS RES, V28, P71, DOI 10.1163/22134808-00002478
   Gori M, 2014, BRAIN, V137, P288, DOI 10.1093/brain/awt311
   Gori M, 2012, DEVELOPMENTAL SCI, V15, P854, DOI 10.1111/j.1467-7687.2012.2012.01183.x
   Gori M, 2012, EXP BRAIN RES, V223, P149, DOI 10.1007/s00221-012-3248-8
   Gori M, 2012, FRONT INTEGR NEUROSC, V6, DOI 10.3389/fnint.2012.00077
   Gori M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025599
   Gori M, 2010, CURR BIOL, V20, P223, DOI 10.1016/j.cub.2009.11.069
   Goswami U, 2002, P NATL ACAD SCI USA, V99, P10911, DOI 10.1073/pnas.122368599
   Goswami U, 2013, CORTEX, V49, P1363, DOI 10.1016/j.cortex.2012.05.005
   Goswami U, 2011, DEVELOPMENTAL SCI, V14, P34, DOI 10.1111/j.1467-7687.2010.00955.x
   Goswami U, 2011, J COGNITIVE NEUROSCI, V23, P325, DOI 10.1162/jocn.2010.21453
   Green KMJ, 2005, HEARING RES, V205, P184, DOI 10.1016/j.heares.2005.03.016
   Habib M, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00026
   Hahn N, 2014, NEUROSCI BIOBEHAV R, V47, P384, DOI 10.1016/j.neubiorev.2014.09.007
   Hamalainen JA, 2013, J LEARN DISABIL-US, V46, P413, DOI 10.1177/0022219411436213
   Hari R, 2001, TRENDS COGN SCI, V5, P525, DOI 10.1016/S1364-6613(00)01801-5
   Harrar V, 2014, CURR BIOL, V24, P531, DOI 10.1016/j.cub.2014.01.029
   Heim S, 2008, ACTA NEUROBIOL EXP, V68, P73
   Huss M, 2011, CORTEX, V47, P674, DOI 10.1016/j.cortex.2010.07.010
   Kast M, 2011, ANN DYSLEXIA, V61, P177, DOI 10.1007/s11881-011-0052-2
   KING AJ, 1985, EXP BRAIN RES, V60, P492
   Kovelman I, 2012, CEREB CORTEX, V22, P754, DOI 10.1093/cercor/bhr094
   Kronschnabel J, 2014, NEUROPSYCHOLOGIA, V62, P245, DOI 10.1016/j.neuropsychologia.2014.07.024
   Kujala T, 2001, P NATL ACAD SCI USA, V98, P10509, DOI 10.1073/pnas.181589198
   Landy MS, 2011, SENSORY CUE INTEGRAT
   Leong V, 2014, HEARING RES, V308, P141, DOI 10.1016/j.heares.2013.07.015
   Leppanen PHT, 2012, NEUROPHYSIOL CLIN, V42, P35, DOI 10.1016/j.neucli.2011.08.005
   Lezak M.D., 2012, NEUROPSYCHOLOGICAL A
   LOVEGROVE WJ, 1980, SCIENCE, V210, P439, DOI 10.1126/science.7433985
   LOVEGROVE WJ, 1980, NEUROPSYCHOLOGIA, V18, P111, DOI 10.1016/0028-3932(80)90093-7
   MANIS FR, 1987, J EXP CHILD PSYCHOL, V43, P25, DOI 10.1016/0022-0965(87)90049-X
   Martin JR, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119365
   Megevand P, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071608
   MEREDITH MA, 1987, J NEUROSCI, V7, P3215
   MILLER J, 1986, PERCEPT PSYCHOPHYS, V40, P331, DOI 10.3758/BF03203025
   MILLER J, 1982, COGNITIVE PSYCHOL, V14, P247, DOI 10.1016/0010-0285(82)90010-X
   Mittag M, 2013, CLIN NEUROPHYSIOL, V124, P315, DOI 10.1016/j.clinph.2012.08.003
   Molholm S, 2002, COGNITIVE BRAIN RES, V14, P115, DOI 10.1016/S0926-6410(02)00066-6
   Morgan W P, 1896, Br Med J, V2, P1378
   Nardini M, 2008, CURR BIOL, V18, P689, DOI 10.1016/j.cub.2008.04.021
   Nardini M, 2013, J EXP PSYCHOL HUMAN, V39, P773, DOI 10.1037/a0030719
   Nardini M, 2010, P NATL ACAD SCI USA, V107, P17041, DOI 10.1073/pnas.1001699107
   Nicolson RI, 2001, TRENDS NEUROSCI, V24, P508, DOI 10.1016/S0166-2236(00)01896-8
   NICOLSON RI, 1990, COGNITION, V35, P159, DOI 10.1016/0010-0277(90)90013-A
   Ober J. K., 1998, LOGOPEDIA, V25, P20
   PELHAM WE, 1977, J ABNORM CHILD PSYCH, V5, P1, DOI 10.1007/BF00915755
   Ramus F, 2003, CURR OPIN NEUROBIOL, V13, P212, DOI 10.1016/S0959-4388(03)00035-7
   Ramus F, 2001, NATURE, V412, P393, DOI 10.1038/35086683
   Ramus F, 2008, Q J EXP PSYCHOL, V61, P129, DOI 10.1080/17470210701508822
   Ramus F, 2013, BRAIN, V136, P630, DOI 10.1093/brain/aws356
   Raven J, 1998, MANUAL RAVENS PROGR
   Sartori G., 2007, BATTERIA VALUTAZIONE
   Saygin ZM, 2013, J NEUROSCI, V33, P13251, DOI 10.1523/JNEUROSCI.4383-12.2013
   Schulte-Korne G, 2010, CLIN NEUROPHYSIOL, V121, P1794, DOI 10.1016/j.clinph.2010.04.028
   Sciutti A, 2014, EXP BRAIN RES, V232, P3965, DOI 10.1007/s00221-014-4021-y
   Sciutti A, 2010, EXP BRAIN RES, V200, P259, DOI 10.1007/s00221-009-1996-x
   Sekuler AB, 1999, PERCEPTION, V28, P415, DOI 10.1068/p2909
   Shams L, 2000, NATURE, V408, P788, DOI 10.1038/35048669
   Shams L, 2001, NEUROREPORT, V12, P3849, DOI 10.1097/00001756-200112040-00049
   Shaywitz BA, 2002, BIOL PSYCHIAT, V52, P101, DOI 10.1016/S0006-3223(02)01365-3
   Snowling M, 2000, J CHILD PSYCHOL PSYC, V41, P587, DOI 10.1111/1469-7610.00651
   Spence C, 2003, CURR BIOL, V13, pR519, DOI 10.1016/S0960-9822(03)00445-7
   Spence C, 2001, PERCEPT PSYCHOPHYS, V63, P330, DOI 10.3758/BF03194473
   Sperling AJ, 2004, ANN DYSLEXIA, V54, P281, DOI 10.1007/s11881-004-0014-z
   Stefanics G, 2011, NEUROIMAGE, V57, P723, DOI 10.1016/j.neuroimage.2011.04.005
   Stein J, 2001, Dyslexia, V7, P12, DOI 10.1002/dys.186
   Stein J, 1997, TRENDS NEUROSCI, V20, P147, DOI 10.1016/S0166-2236(96)01005-3
   SUTTON S, 1961, AM J PSYCHOL, V74, P224, DOI 10.2307/1419407
   TALLAL P, 1980, Journal of Pediatric Psychology, V5, P127, DOI 10.1093/jpepsy/5.2.127
   TALLAL P, 1993, ANN NY ACAD SCI, V682, P27, DOI 10.1111/j.1749-6632.1993.tb22957.x
   Tyler RS, 1997, ADV OTO-RHINO-LARYNG, V52, P187
   Valdois S, 2004, DYSLEXIA, V10, P339, DOI 10.1002/dys.284
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   van Wassenhove V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00388
   VanRullen R, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0214
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   Vercillo T, 2016, DEV PSYCHOL, V52, P847, DOI 10.1037/dev0000103
   Vercillo T, 2015, NEUROPSYCHOLOGIA, V67, P35, DOI 10.1016/j.neuropsychologia.2014.12.001
   Veuillet E, 2007, BRAIN, V130, P2915, DOI 10.1093/brain/awm235
   Vidyasagar TR, 1999, BRAIN RES REV, V30, P66, DOI 10.1016/S0165-0173(99)00005-3
   WAGNER RK, 1986, J LEARN DISABIL, V19, P623, DOI 10.1177/002221948601901009
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   WATSON AB, 1983, PERCEPT PSYCHOPHYS, V33, P113, DOI 10.3758/BF03202828
   Wechsler D., 2014, WECHSLER INTELLIGENC
NR 118
TC 0
Z9 0
U1 3
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD SEP
PY 2020
VL 23
IS 5
AR e12977
DI 10.1111/desc.12977
PG 17
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA NE7JI
UT WOS:000562777000016
PM 32333455
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Brown, VA
   McLaughlin, DJ
   Strand, JF
   Van Engen, KJ
AF Brown, Violet A.
   McLaughlin, Drew J.
   Strand, Julia F.
   Van Engen, Kristin J.
TI Rapid adaptation to fully intelligible nonnative-accented speech reduces
   listening effort
SO QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY
LA English
DT Article
DE Speech perception; listening effort; accented speech; dual-task;
   pupillometry
ID PERCEPTUAL ADAPTATION; WORKING-MEMORY; PUPIL RESPONSE; OLDER-ADULTS;
   TASK; RECOGNITION; LOAD
AB In noisy settings or when listening to an unfamiliar talker or accent, it can be difficult to understand spoken language. This difficulty typically results in reductions in speech intelligibility, but may also increase the effort necessary to process the speech even when intelligibility is unaffected. In this study, we used a dual-task paradigm and pupillometry to assess the cognitive costs associated with processing fully intelligible accented speech, predicting that rapid perceptual adaptation to an accent would result in decreased listening effort over time. The behavioural and physiological paradigms provided converging evidence that listeners expend greater effort when processing nonnative- relative to native-accented speech, and both experiments also revealed an overall reduction in listening effort over the course of the experiment. Only the pupillometry experiment, however, revealed greater adaptation to nonnative- relative to native-accented speech. An exploratory analysis of the dual-task data that attempted to minimise practice effects revealed weak evidence for greater adaptation to the nonnative accent. These results suggest that even when speech is fully intelligible, resolving deviations between the acoustic input and stored lexical representations incurs a processing cost, and adaptation may attenuate this cost.
C1 [Brown, Violet A.; McLaughlin, Drew J.; Van Engen, Kristin J.] Washington Univ, Dept Psychol & Brain Sci, 1 Brookings Dr, St Louis, MO 63130 USA.
   [Strand, Julia F.] Carleton Coll, Dept Psychol, Northfield, MN 55057 USA.
RP Brown, VA (corresponding author), Washington Univ, Dept Psychol & Brain Sci, 1 Brookings Dr, St Louis, MO 63130 USA.
EM violet.brown@wustl.edu
FU Washington University in St. Louis; National Science Foundation through
   Graduate Research Fellowships [DGE-1745038]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by Washington University in St. Louis, and by the National
   Science Foundation through Graduate Research Fellowships awarded to
   Violet Brown and Drew McLaughlin (DGE-1745038).
CR Alexander JED, 2019, J ACOUST SOC AM, V145, P3382, DOI 10.1121/1.5110302
   Alhanbali S, 2019, EAR HEARING, V40, P1084, DOI 10.1097/AUD.0000000000000697
   Alsius A, 2007, EXP BRAIN RES, V183, P399, DOI 10.1007/s00221-007-1110-1
   Baese-Berk MM, 2013, J ACOUST SOC AM, V133, pEL174, DOI 10.1121/1.4789864
   Banks B, 2015, J ACOUST SOC AM, V137, P2015, DOI 10.1121/1.4916265
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Barto K, 2019, PACKAGE MUMIN VERSIO
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   BEATTY J, 1982, PSYCHOL BULL, V91, P276, DOI 10.1037/0033-2909.91.2.276
   Borghini G, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00152
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Brown V. A., 2018, LANG COGN NEUROSCI, V34, P628
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Desjardins JL, 2014, EAR HEARING, V35, P600, DOI 10.1097/AUD.0000000000000028
   Desjardins JL, 2013, EAR HEARING, V34, P261, DOI 10.1097/AUD.0b013e31826d0ba4
   DOWNS DW, 1978, J SPEECH HEAR RES, V21, P702, DOI 10.1044/jshr.2104.702
   DOWNS DW, 1982, J SPEECH HEAR DISORD, V47, P189, DOI 10.1044/jshd.4702.189
   Drozdova P, 2019, ATTEN PERCEPT PSYCHO, V81, P1675, DOI 10.3758/s13414-018-01657-5
   Fraser S, 2010, J SPEECH LANG HEAR R, V53, P18, DOI 10.1044/1092-4388(2009/08-0140)
   Gagne JP, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216516687287
   Geller J, 2020, BEHAV RES METHODS, V52, P2232, DOI 10.3758/s13428-020-01374-8
   Hicks CB, 2002, J SPEECH LANG HEAR R, V45, P573, DOI 10.1044/1092-4388(2002/046)
   Janse E, 2012, Q J EXP PSYCHOL, V65, P1563, DOI 10.1080/17470218.2012.658822
   Johnson J, 2015, AM J AUDIOL, V24, P419, DOI 10.1044/2015_AJA-14-0058
   Kahneman D., 1973, ATTENTION EFFORT
   Klingner J, 2011, PSYCHOPHYSIOLOGY, V48, P323, DOI 10.1111/j.1469-8986.2010.01069.x
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kuchinsky SE, 2013, PSYCHOPHYSIOLOGY, V50, P23, DOI 10.1111/j.1469-8986.2012.01477.x
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Mackersie CL, 2011, J AM ACAD AUDIOL, V22, P113, DOI 10.3766/jaaa.22.2.6
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   McCoy SL, 2005, Q J EXP PSYCHOL-A, V58, P22, DOI 10.1080/02724980443000151
   McGarrigle R, 2017, PSYCHOPHYSIOLOGY, V54, P193, DOI 10.1111/psyp.12772
   McLaughlin DJ, 2020, J ACOUST SOC AM, V147, pEL151, DOI 10.1121/10.0000718
   Mirman D., 2014, CHAPMAN HALL CRC R S
   Nakagawa S, 2017, J R SOC INTERFACE, V14, DOI 10.1098/rsif.2017.0213
   Nakagawa S, 2013, METHODS ECOL EVOL, V4, P133, DOI 10.1111/j.2041-210x.2012.00261.x
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Peelle JE, 2018, EAR HEARING, V39, P204, DOI 10.1097/AUD.0000000000000494
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Picou EM, 2014, EAR HEARING, V35, P611, DOI 10.1097/AUD.0000000000000055
   Porretta V., 2019, FRONTIERS COMMUNICAT, V4, P8, DOI [10.3389/fcomm.2019.00008, DOI 10.3389/FCOMM.2019.00008]
   R Core Team, 2016, R LANG ENV STAT COMP
   Reilly J, 2019, BEHAV RES METHODS, V51, P865, DOI 10.3758/s13428-018-1134-4
   Ronnberg J, 2019, INT J AUDIOL, V58, P247, DOI 10.1080/14992027.2018.1551631
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2010, NOISE HEALTH, V12, P263, DOI 10.4103/1463-1741.70505
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   Rudner M., 2011, J HEARING SCI, V1, P47, DOI DOI 10.1097/AUD.0000000000000302
   Sarampalis A, 2009, J SPEECH LANG HEAR R, V52, P1230, DOI 10.1044/1092-4388(2009/08-0111)
   Seeman S, 2015, J SPEECH LANG HEAR R, V58, P1781, DOI 10.1044/2015_JSLHR-H-14-0180
   Sidaras SK, 2009, J ACOUST SOC AM, V125, P3306, DOI 10.1121/1.3101452
   Strand JF, 2018, J SPEECH LANG HEAR R, V61, P1463, DOI 10.1044/2018_JSLHR-H-17-0257
   Van Engen KJ, 2018, HEARING RES, V369, P56, DOI 10.1016/j.heares.2018.04.013
   Van Engen KJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00577
   Van Engen KJ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043753
   Winn MB, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518800869
   Winn MB, 2015, EAR HEARING, V36, pe153, DOI 10.1097/AUD.0000000000000145
   Zekveld AA, 2010, EAR HEARING, V31, P480, DOI 10.1097/AUD.0b013e3181d4f251
   Zheng Y, 2020, J EXP PSYCHOL LEARN, V46, P1270, DOI 10.1037/xlm0000788
NR 61
TC 0
Z9 0
U1 2
U2 2
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1747-0218
EI 1747-0226
J9 Q J EXP PSYCHOL
JI Q. J. Exp. Psychol.
PD SEP
PY 2020
VL 73
IS 9
BP 1431
EP 1443
DI 10.1177/1747021820916726
PG 13
WC Psychology, Biological; Physiology; Psychology; Psychology, Experimental
SC Psychology; Physiology
GA NC7IA
UT WOS:000561387700011
PM 32192390
DA 2021-02-24
ER

PT J
AU Baroni, F
   Morillon, B
   Trebuchon, A
   Liegeois-Chauvel, C
   Olasagasti, I
   Giraud, AL
AF Baroni, Fabiano
   Morillon, Benjamin
   Trebuchon, Agnes
   Liegeois-Chauvel, Catherine
   Olasagasti, Itsaso
   Giraud, Anne-Lise
TI Converging intracortical signatures of two separated processing
   timescales in human early auditory cortex
SO NEUROIMAGE
LA English
DT Article
DE iEEG; Speech perception; Spectral analysis; Brain decoding;
   Computational modeling; Auditory cortex
ID LOCAL-FIELD POTENTIALS; LOW-FREQUENCY OSCILLATIONS; CORTICAL
   OSCILLATIONS; TEMPORAL INTEGRATION; NEURAL OSCILLATIONS; PHASE PATTERNS;
   GAMMA RHYTHMS; COMPUTATIONAL PRINCIPLES; NEURONAL OSCILLATIONS; NETWORK
   OSCILLATIONS
AB Neural oscillations in auditory cortex are argued to support parsing and representing speech constituents at their corresponding temporal scales. Yet, how incoming sensory information interacts with ongoing spontaneous brain activity, what features of the neuronal microcircuitry underlie spontaneous and stimulus-evoked spectral fin-gerprints, and what these fingerprints entail for stimulus encoding, remain largely open questions. We used a combination of human invasive electrophysiology, computational modeling and decoding techniques to assess the information encoding properties of brain activity and to relate them to a plausible underlying neuronal micro -architecture. We analyzed intracortical auditory EEG activity from 10 patients while they were listening to short sentences. Pre-stimulus neural activity in early auditory cortical regions often exhibited power spectra with a shoulder in the delta range and a small bump in the beta range. Speech decreased power in the beta range, and increased power in the delta-theta and gamma ranges. Using multivariate machine learning techniques, we assessed the spectral profile of information content for two aspects of speech processing: detection and discrimination. We obtained better phase than power information decoding, and a bimodal spectral profile of information content with better decoding at low (delta-theta) and high (gamma) frequencies than at intermediate (beta) frequencies. These experimental data were reproduced by a simple rate model made of two subnetworks with different timescales, each composed of coupled excitatory and inhibitory units, and connected via a negative feedback loop. Modeling and experimental results were similar in terms of pre-stimulus spectral profile (except for the iEEG beta bump), spectral modulations with speech, and spectral profile of information content. Altogether, we provide converging evidence from both univariate spectral analysis and decoding approaches for a dual timescale processing infrastructure in human auditory cortex, and show that it is consistent with the dynamics of a simple rate model.
C1 [Baroni, Fabiano; Olasagasti, Itsaso; Giraud, Anne-Lise] Univ Geneva, Dept Fundamental Neurosci, Geneva, Switzerland.
   [Baroni, Fabiano] Ecole Polytech Fed Lausanne, Sch Engn, Lausanne, Switzerland.
   [Morillon, Benjamin; Trebuchon, Agnes; Liegeois-Chauvel, Catherine] Aix Marseille Univ, INSERM, Inst Neurosci Syst INS, Marseille, France.
   [Trebuchon, Agnes] Timone Hosp, Assistance Publ Hop Marseille, Clin Neurophysiol & Epileptol Dept, Marseille, France.
   [Liegeois-Chauvel, Catherine] Univ Pittsburgh, Dept Neurol Surg, Pittsburgh, PA 15213 USA.
   [Baroni, Fabiano] Univ Aut onoma Madrid, Escuela Politecn Super, Madrid, Spain.
RP Baroni, F (corresponding author), Univ Geneva, Dept Fundamental Neurosci, Geneva, Switzerland.
EM fabianobaroni@gmail.com
OI Giraud, Anne-Lise/0000-0002-1261-3555; Morillon,
   Benjamin/0000-0002-0049-064X
FU Swiss National Science FoundationSwiss National Science Foundation
   (SNSF)European Commission [320030-163040]
FX We thank all subjects for their participation in the study. This work
   was funded by a project grant from the Swiss National Science Foundation
   to ALG (#320030-163040). The computations were performed at the
   University of Geneva on the Baobab cluster.
CR Arnal LH, 2015, CEREB CORTEX, V25, P3077, DOI 10.1093/cercor/bhu103
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Barbour DL, 2008, J NEUROSCI, V28, P11174, DOI 10.1523/JNEUROSCI.2093-08.2008
   Baroni F, 2017, NEUROIMAGE, V162, P322, DOI 10.1016/j.neuroimage.2017.08.074
   Bastiaansen M, 2015, J COGNITIVE NEUROSCI, V27, P2095, DOI 10.1162/jocn_a_00829
   Bastiaansen M, 2010, J COGNITIVE NEUROSCI, V22, P1333, DOI 10.1162/jocn.2009.21283
   Bastos AM, 2015, NEUROIMAGE, V108, P460, DOI 10.1016/j.neuroimage.2014.12.081
   Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038
   Bastos AM, 2015, NEURON, V85, P390, DOI 10.1016/j.neuron.2014.12.018
   Baumgarten TJ, 2015, P NATL ACAD SCI USA, V112, P12187, DOI 10.1073/pnas.1501438112
   Becker R, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00121
   Belitski A, 2008, J NEUROSCI, V28, P5696, DOI 10.1523/JNEUROSCI.0009-08.2008
   Belitski A, 2010, J COMPUT NEUROSCI, V29, P533, DOI 10.1007/s10827-010-0230-y
   Benitez-Burraco A, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00120
   Besle J, 2011, J NEUROSCI, V31, P3176, DOI 10.1523/JNEUROSCI.4518-10.2011
   Bhalla US, 1999, SCIENCE, V283, P381, DOI 10.1126/science.283.5400.381
   Biau E, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00434
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   Borges AFT, 2018, J NEUROSCI, V38, P710, DOI 10.1523/JNEUROSCI.1515-17.2017
   Bouton S., 2019, INTEGRATING HYPOTHES
   Bouton S, 2018, P NATL ACAD SCI USA, V115, pE1299, DOI 10.1073/pnas.1714279115
   Breska A., 2017, PLOS BIOL, V15
   Brugge JF, 2009, J NEUROPHYSIOL, V102, P2358, DOI 10.1152/jn.91346.2008
   Buschman TJ, 2007, SCIENCE, V315, P1860, DOI 10.1126/science.1138071
   BUZSAKI G, 1995, CURR OPIN NEUROBIOL, V5, P504, DOI 10.1016/0959-4388(95)80012-3
   Buzsaki G, 2004, SCIENCE, V304, P1926, DOI 10.1126/science.1099745
   Buzsaki G., 2006, RHYTHMS BRAIN
   Calderone DJ, 2014, TRENDS COGN SCI, V18, P300, DOI 10.1016/j.tics.2014.02.005
   Chambers JD, 2019, FRONT COMPUT NEUROSC, V13, DOI 10.3389/fncom.2019.00028
   Chaudhuri R, 2017, CEREB CORTEX, V8, P1, DOI [10.1093/cercor/bhx233., DOI 10.1093/CERC0R/BHX233]
   Clayton MS, 2015, TRENDS COGN SCI, V19, P188, DOI 10.1016/j.tics.2015.02.004
   Cravo AM, 2011, J NEUROPHYSIOL, V106, P2964, DOI 10.1152/jn.00157.2011
   Crunelli V, 2010, NAT NEUROSCI, V13, P10, DOI 10.1038/nn.2445
   Dimitrijevic A, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00088
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Doelling KB, 2019, P NATL ACAD SCI USA, V116, P10113, DOI 10.1073/pnas.1816414116
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Edelstein-Keshet L, 2005, CLASSICS APPL MATH
   Edwards E, 2013, HEARING RES, V305, P113, DOI 10.1016/j.heares.2013.08.017
   Elhilali M, 2004, J NEUROSCI, V24, P1159, DOI 10.1523/JNEUROSCI.3825-03.2004
   Engel AK, 2010, CURR OPIN NEUROBIOL, V20, P156, DOI 10.1016/j.conb.2010.02.015
   Fenton AA, 2015, BIOL PSYCHIAT, V77, P1079, DOI 10.1016/j.biopsych.2015.03.013
   Fontolan L, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5694
   Fries P, 2001, SCIENCE, V291, P1560, DOI 10.1126/science.1055465
   Gao R, 2015, CURR MOL MED, V15, P146, DOI 10.2174/1566524015666150303003028
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Giroud J, 2020, PLOS BIOL, V18, DOI 10.1371/journal.pbio.3000207
   Gloveli T, 2005, J PHYSIOL-LONDON, V562, P131, DOI 10.1113/jphysiol.2004.073007
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Gonzalez-Burgos G, 2008, SCHIZOPHRENIA BULL, V34, P944, DOI 10.1093/schbul/sbn070
   Goris RLT, 2014, NAT NEUROSCI, V17, P858, DOI 10.1038/nn.3711
   Halgren M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20662-0
   Hammer PJ, 2013, CHANGE AND CONTINUITY AT THE WORLD BANK: REFORMING PARADOXES OF ECONOMIC DEVELOPMENT, P7
   Harper NS, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1005113
   He B.J., 2014, TRENDS COGN SCI, V18, P480
   He BYJ, 2010, NEURON, V66, P353, DOI 10.1016/j.neuron.2010.04.020
   Hoel EP, 2013, P NATL ACAD SCI USA, V110, P19790, DOI 10.1073/pnas.1314922110
   Howard MF, 2010, J NEUROPHYSIOL, V104, P2500, DOI 10.1152/jn.00251.2010
   Hughes SW, 2004, NEURON, V42, P253, DOI 10.1016/S0896-6273(04)00191-6
   Hyafil A, 2015, TRENDS NEUROSCI, V38, P725, DOI 10.1016/j.tins.2015.09.001
   Hyafil A, 2015, ELIFE, V4, DOI 10.7554/eLife.06213
   Jerbi K, 2009, BRAIN TOPOGR, V22, P18, DOI 10.1007/s10548-009-0078-5
   Jochaut D, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3339/fnhum.2015.00171, 10.3389/fnhum.2015.00171]
   Kayser C, 2004, EUR J NEUROSCI, V19, P485, DOI 10.1111/j.0953-816X.2003.03122.x
   King JR, 2014, TRENDS COGN SCI, V18, P203, DOI 10.1016/j.tics.2014.01.002
   Klimesch W, 2012, TRENDS COGN SCI, V16, P606, DOI 10.1016/j.tics.2012.10.007
   Kopell N, 2011, P NATL ACAD SCI USA, V108, P3779, DOI 10.1073/pnas.1019676108
   Kopell N, 2000, P NATL ACAD SCI USA, V97, P1867, DOI 10.1073/pnas.97.4.1867
   Kosem A, 2017, LANG COGN NEUROSCI, V32, P536, DOI 10.1080/23273798.2016.1238495
   Kotz SA, 2018, TRENDS COGN SCI, V22, P896, DOI 10.1016/j.tics.2018.08.002
   Kotz SA, 2010, TRENDS COGN SCI, V14, P392, DOI 10.1016/j.tics.2010.06.005
   Kovach CK, 2011, NEUROIMAGE, V54, P213, DOI 10.1016/j.neuroimage.2010.08.002
   Kramer MA, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000169
   Lachaux JP, 1999, HUM BRAIN MAPP, V8, P194, DOI 10.1002/(SICI)1097-0193(1999)8:4<194::AID-HBM4>3.0.CO;2-C
   Lakatos P, 2005, J NEUROPHYSIOL, V94, P1904, DOI 10.1152/jn.00263.2005
   Lee JH, 2015, J NEUROSCI, V35, P15000, DOI 10.1523/JNEUROSCI.0629-15.2015
   Lee JH, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003164
   Lehongre K, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00454
   Lehongre K, 2011, NEURON, V72, P1080, DOI 10.1016/j.neuron.2011.11.002
   Lewis AG, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00085
   Lewis C.M., 2016, 2 FREQUENCY BANDS CO
   Li G, 2017, PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON BIOTECHNOLOGY & MEDICAL SCIENCE, P13
   Li LY, 2014, J NEUROSCI, V34, P13670, DOI 10.1523/JNEUROSCI.1516-14.2014
   LIEGEOISCHAUVEL C, 1991, BRAIN, V114, P139
   Loebel A, 2007, FRONT NEUROSCI-SWITZ, V1, P197, DOI 10.3389/neuro.01.1.1.015.2007
   Lopour BA, 2013, NEURON, V79, P594, DOI 10.1016/j.neuron.2013.06.001
   Lundqvist M, 2016, NEURON, V90, P152, DOI 10.1016/j.neuron.2016.02.028
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Luo H, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00170
   Majo Z, 2013, I S WORKL CHAR PROC, P11, DOI 10.1109/IISWC.2013.6704666
   McGinley MJ, 2015, NEURON, V87, P1143, DOI 10.1016/j.neuron.2015.09.012
   Mejias JF, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1601335
   Michalareas G, 2016, NEURON, V89, P384, DOI 10.1016/j.neuron.2015.12.018
   Miles K, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517706396
   Miller KJ, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000609
   Moore BCJ, 2003, J PHONETICS, V31, P563, DOI 10.1016/S0095-4470(03)00011-1
   Morillon B, 2017, P NATL ACAD SCI USA, V114, pE8913, DOI 10.1073/pnas.1705373114
   Morillon B, 2015, CURR OPIN NEUROBIOL, V31, P230, DOI 10.1016/j.conb.2014.12.005
   Morillon B, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00248
   Morillon B, 2010, P NATL ACAD SCI USA, V107, P18688, DOI 10.1073/pnas.1007189107
   Ng BSW, 2013, CEREB CORTEX, V23, P389, DOI 10.1093/cercor/bhs031
   Nourski KV, 2015, BRAIN LANG, V148, P37, DOI 10.1016/j.bandl.2015.03.003
   Obleser J, 2012, CEREB CORTEX, V22, P2466, DOI 10.1093/cercor/bhr325
   Obleser J, 2012, J NEUROSCI, V32, P12376, DOI 10.1523/JNEUROSCI.4908-11.2012
   Panzeri S, 2017, NEURON, V93, P491, DOI 10.1016/j.neuron.2016.12.036
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Pefkou M, 2017, J NEUROSCI, V37, P7930, DOI 10.1523/JNEUROSCI.2882-16.2017
   Pizzarelli R, 2011, NEURAL PLAST, V2011, DOI 10.1155/2011/297153
   Podvalny E, 2015, J NEUROPHYSIOL, V114, P505, DOI 10.1152/jn.00943.2014
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Rahman M, 2019, PLOS COMPUT BIOL, V15, DOI 10.1371/journal.pcbi.1006618
   Ramamoorthi K, 2011, TRENDS MOL MED, V17, P452, DOI 10.1016/j.molmed.2011.03.003
   Ravignani A, 2019, ANN NY ACAD SCI, V1453, P79, DOI 10.1111/nyas.14166
   Rene T., 1990, BIOL FEEDBACK
   Rifkin R, 2003, NATO SCI SERIES 3, V190, P131
   Rizzuto DS, 2003, P NATL ACAD SCI USA, V100, P7931, DOI 10.1073/pnas.0732061100
   Rohenkohl G, 2011, J NEUROSCI, V31, P14076, DOI 10.1523/JNEUROSCI.3387-11.2011
   Ronconi L, 2017, P NATL ACAD SCI USA, V114, P13435, DOI 10.1073/pnas.1714522114
   Roopun AK, 2008, SCHIZOPHRENIA BULL, V34, P962, DOI 10.1093/schbul/sbn059
   Ross B, 2014, J NEUROPHYSIOL, V112, P1871, DOI 10.1152/jn.00224.2014
   Saleem AB, 2017, NEURON, V93, P315, DOI 10.1016/j.neuron.2016.12.028
   Saleh M, 2010, NEURON, V65, P461, DOI 10.1016/j.neuron.2010.02.001
   Schyns PG, 2011, PLOS BIOL, V9, DOI 10.1371/journal.pbio.1001064
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sherman MA, 2016, P NATL ACAD SCI USA, V113, pE4885, DOI 10.1073/pnas.1604135113
   Silver RA, 2010, NAT REV NEUROSCI, V11, P474, DOI 10.1038/nrn2864
   Simon DM, 2016, NEUROSCI BIOBEHAV R, V68, P848, DOI 10.1016/j.neubiorev.2016.07.016
   Soltesz F., 2013, PLOS ONE, V8
   Stefanics G, 2010, J NEUROSCI, V30, P13578, DOI 10.1523/JNEUROSCI.0703-10.2010
   STERIADE M, 1993, SCIENCE, V262, P679, DOI 10.1126/science.8235588
   Strauss A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00350
   Stringer C, 2016, ELIFE, V5, DOI 10.7554/eLife.19695
   Sun LM, 2013, SCHIZOPHR RES, V150, P519, DOI 10.1016/j.schres.2013.08.023
   Szikla G., 1977, ANGIOGRAPHY HUMAN BR
   Talairach J, 1988, COPLANAR STEREOTAXIC
   TallonBaudry C, 1996, J NEUROSCI, V16, P4240
   Tavano A., 2017, LOW BETA POWER REFLE
   Teng X., 2016, SCI REP, V6
   Teng XB, 2020, CEREB CORTEX, V30, P2600, DOI 10.1093/cercor/bhz263
   Teng XB, 2017, PLOS BIOL, V15, DOI 10.1371/journal.pbio.2000812
   Thomson AM, 2003, CEREB CORTEX, V13, P5, DOI 10.1093/cercor/13.1.5
   THOMSON AM, 1994, TRENDS NEUROSCI, V17, P119, DOI 10.1016/0166-2236(94)90121-X
   Traub RD, 1996, J PHYSIOL-LONDON, V493, P471, DOI 10.1113/jphysiol.1996.sp021397
   Tsodyks M, 1998, NEURAL COMPUT, V10, P821, DOI 10.1162/089976698300017502
   Tsuchiya N, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003892
   Uhlhaas PJ, 2012, NEURON, V75, P963, DOI 10.1016/j.neuron.2012.09.004
   Uhlhaas PJ, 2010, TRENDS COGN SCI, V14, P72, DOI 10.1016/j.tics.2009.12.002
   van Kerkoerle T, 2014, P NATL ACAD SCI USA, V111, P14332, DOI 10.1073/pnas.1402773111
   VIEMEISTER NF, 1991, J ACOUST SOC AM, V90, P858, DOI 10.1121/1.401953
   Voytek B, 2015, BIOL PSYCHIAT, V77, P1089, DOI 10.1016/j.biopsych.2015.04.016
   Wang XJ, 2014, NEURON, V84, P638, DOI 10.1016/j.neuron.2014.10.018
   Wang XJ, 2010, PHYSIOL REV, V90, P1195, DOI 10.1152/physrev.00035.2008
   Wang Y., 2018, FRONT NEUROSCI, V12
   White JA, 2000, P NATL ACAD SCI USA, V97, P8128, DOI 10.1073/pnas.100124097
   Wilsch A, 2016, BRAIN RES, V1640, P193, DOI 10.1016/j.brainres.2015.10.054
   Wilsch A, 2015, CEREB CORTEX, V25, P1938, DOI 10.1093/cercor/bhu004
   WILSON HR, 1972, BIOPHYS J, V12, P1, DOI 10.1016/S0006-3495(72)86068-5
   Wostmann M, 2017, CEREB CORTEX, V27, P3307, DOI 10.1093/cercor/bhx074
   Wostmann M, 2016, P NATL ACAD SCI USA, V113, P3873, DOI 10.1073/pnas.1523357113
   Wostmann M, 2015, J NEUROSCI, V35, P1458, DOI 10.1523/JNEUROSCI.3250-14.2015
   Womelsdorf T, 2014, NAT NEUROSCI, V17, P1031, DOI 10.1038/nn.3764
   Yarden TS, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005437
NR 163
TC 0
Z9 0
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD SEP
PY 2020
VL 218
AR 116882
DI 10.1016/j.neuroimage.2020.116882
PG 17
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA MU1VC
UT WOS:000555460000008
PM 32439539
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Dobel, C
   Nestler-Collatz, B
   Guntinas-Lichius, O
   Schweinberger, SR
   Zaske, R
AF Dobel, Christian
   Nestler-Collatz, Bettina
   Guntinas-Lichius, Orlando
   Schweinberger, Stefan R.
   Zaeske, Romi
TI Deaf signers outperform hearing non-signers in recognizing happy facial
   expressions
SO PSYCHOLOGICAL RESEARCH-PSYCHOLOGISCHE FORSCHUNG
LA English
DT Article
ID PERIPHERAL VISUAL SPACE; MOVEMENT DETECTION TASK; SPATIAL-DISTRIBUTION;
   EMOTION RECOGNITION; SPEECH-PERCEPTION; ATTENTION; FACE; KNOWLEDGE;
   LANGUAGE; IDENTITY
AB The use of signs as a major means for communication affects other functions such as spatial processing. Intriguingly, this is true even for functions which are less obviously linked to language processing. Speakers using signs outperform non-signers in face recognition tasks, potentially as a result of a lifelong focus on the mouth region for speechreading. On this background, we hypothesized that the processing of emotional faces is altered in persons using mostly signs for communication (henceforth named deaf signers). While for the recognition of happiness the mouth region is more crucial, the eye region matters more for recognizing anger. Using morphed faces, we created facial composites in which either the upper or lower half of an emotional face was kept neutral while the other half varied in intensity of the expressed emotion, being either happy or angry. As expected, deaf signers were more accurate at recognizing happy faces than non-signers. The reverse effect was found for angry faces. These differences between groups were most pronounced for facial expressions of low intensities. We conclude that the lifelong focus on the mouth region in deaf signers leads to more sensitive processing of happy faces, especially when expressions are relatively subtle.
C1 [Dobel, Christian; Nestler-Collatz, Bettina; Guntinas-Lichius, Orlando; Zaeske, Romi] Jena Univ Hosp, Dept Otorhinolaryngol, Stoystr 3, D-07740 Jena, Germany.
   [Schweinberger, Stefan R.; Zaeske, Romi] Friedrich Schiller Univ, Dept Gen Psychol & Cognit Neurosci, Jena, Germany.
RP Dobel, C (corresponding author), Jena Univ Hosp, Dept Otorhinolaryngol, Stoystr 3, D-07740 Jena, Germany.
EM Christian.Dobel@med.uni-jena.de
RI Guntinas-Lichius, Orlando/L-1871-2016
OI Guntinas-Lichius, Orlando/0000-0001-9671-0784
CR Andersson U., 2001, J DEAF STUD DEAF EDU, V6, P103, DOI DOI 10.1093/DEAFED/6.2.103
   Beaudry O, 2014, COGNITION EMOTION, V28, P416, DOI 10.1080/02699931.2013.833500
   Bellugi U, 1990, ENHANCEMENT SPATIAL, P278
   Benton A. L., 1983, FACIAL RECOGNITION S
   Bernstein LE, 2000, PERCEPT PSYCHOPHYS, V62, P233, DOI 10.3758/BF03205546
   Bettger J, 1997, J Deaf Stud Deaf Educ, V2, P223
   Bettger J, 1992, THESIS
   Calvo MG, 2008, J EXP PSYCHOL GEN, V137, P471, DOI 10.1037/a0012771
   Campbell R, 1996, Q J EXP PSYCHOL-A, V49, P295, DOI 10.1080/027249896392649
   Chen Q, 2006, BRAIN RES, V1109, P117, DOI 10.1016/j.brainres.2006.06.043
   Chen Q, 2010, NEUROPSYCHOLOGIA, V48, P2693, DOI 10.1016/j.neuropsychologia.2010.05.016
   de Heering A, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00124
   Dobel C, 2011, J DEAF STUD DEAF EDU, V16, P392, DOI 10.1093/deafed/enq070
   Dyck M.J., 2003, J DEAF STUD DEAF EDU, V8, P348, DOI DOI 10.1093/DEAFED/ENG019
   Dye MWG, 2007, NEUROPSYCHOLOGIA, V45, P1801, DOI 10.1016/j.neuropsychologia.2006.12.019
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   EKMAN P, 1986, MOTIV EMOTION, V10, P159, DOI 10.1007/BF00992253
   EMMOREY K, 1993, COGNITION, V46, P139, DOI 10.1016/0010-0277(93)90017-P
   Emmorey K., 2002, SIGN LANGUAGE LINGUI, V5, P3, DOI DOI 10.1075/SLL.5.1.03EMM
   Emmorey K., 2001, LANGUAGE COGNITION B
   Emmorey K, 2009, J DEAF STUD DEAF EDU, V14, P237, DOI 10.1093/deafed/enn037
   Goldstein NE, 1996, J NONVERBAL BEHAV, V20, P111, DOI 10.1007/BF02253072
   Goldstein NE, 2000, J APPL SOC PSYCHOL, V30, P67, DOI 10.1111/j.1559-1816.2000.tb02305.x
   GOSSELIN P, 1995, CAN J EXP PSYCHOL, V49, P313, DOI 10.1037/1196-1961.49.3.313
   Hauthal N, 2012, ATTEN PERCEPT PSYCHO, V74, P1312, DOI 10.3758/s13414-012-0320-1
   He HZ, 2016, VIS COGN, V24, P201, DOI 10.1080/13506285.2016.1221488
   Huynh H., 1976, J EDUC STATIST, V1, P69, DOI [10.3102/10769986001001069, DOI 10.3102/10769986001001069]
   IZARD CE, 1994, PSYCHOL BULL, V115, P288, DOI 10.1037/0033-2909.115.2.288
   Letourneau SM, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00319
   Letourneau SM, 2011, PERCEPTION, V40, P563, DOI 10.1068/p6858
   Levinson SC, 2003, SPACE LANGUAGE COGNI
   LOKE WH, 1991, B PSYCHONOMIC SOC, V29, P437
   Ludlow A, 2010, J CLIN EXP NEUROPSYC, V32, P923, DOI 10.1080/13803391003596447
   MARASSA LK, 1995, J SPEECH HEAR RES, V38, P1387, DOI 10.1044/jshr.3806.1387
   Mastrantuono E, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01044
   Maurer D, 2002, TRENDS COGN SCI, V6, P255, DOI 10.1016/S1364-6613(02)01903-4
   McCullough S, 1997, J Deaf Stud Deaf Educ, V2, P212
   McCullough S, 2009, COGNITION, V110, P208, DOI 10.1016/j.cognition.2008.11.007
   Mitchell TV, 2017, HEARING RES, V343, P150, DOI 10.1016/j.heares.2016.10.010
   Mitchell TV, 2013, RESTOR NEUROL NEUROS, V31, P125, DOI 10.3233/RNN-120233
   NEVILLE HJ, 1987, BRAIN RES, V405, P253, DOI 10.1016/0006-8993(87)90295-2
   NEVILLE HJ, 1987, BRAIN RES, V405, P268, DOI 10.1016/0006-8993(87)90296-4
   Parasnis I, 1996, J Deaf Stud Deaf Educ, V1, P145
   Proksch J, 2002, J COGNITIVE NEUROSCI, V14, P687, DOI 10.1162/08989290260138591
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   SCHIFF W, 1973, AM J PSYCHOL, V86, P61, DOI 10.2307/1421848
   Schweinberger SR, 1998, J EXP PSYCHOL HUMAN, V24, P1748, DOI 10.1037/0096-1523.24.6.1748
   Sidera F, 2017, J DEAF STUD DEAF EDU, V22, P164, DOI 10.1093/deafed/enw072
   Sladen DP, 2005, J SPEECH LANG HEAR R, V48, P1529, DOI 10.1044/1092-4388(2005/106)
   Stoll C, 2018, J DEAF STUD DEAF EDU, V23, P62, DOI 10.1093/deafed/enx034
   Tracy JL, 2008, EMOTION, V8, P81, DOI 10.1037/1528-3542.8.1.81
   VALENTINE T, 1991, Q J EXP PSYCHOL-A, V43, P161, DOI 10.1080/14640749108400966
   Vassallo S, 2009, J VISION, V9, DOI 10.1167/9.3.11
   Watanabe K, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016919
   WEISEL A, 1985, PERCEPT MOTOR SKILL, V61, P515, DOI 10.2466/pms.1985.61.2.515
   Whorf BL, 2012, LANGUAGE THOUGHT REA, P2
   Young AW, 2002, FACIAL EXPRESSIONS E
NR 57
TC 0
Z9 0
U1 6
U2 7
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 0340-0727
EI 1430-2772
J9 PSYCHOL RES-PSYCH FO
JI Psychol. Res.-Psychol. Forsch.
PD SEP
PY 2020
VL 84
IS 6
BP 1485
EP 1494
DI 10.1007/s00426-019-01160-y
PG 10
WC Psychology, Experimental
SC Psychology
GA MQ7PY
UT WOS:000553086800002
PM 30864002
DA 2021-02-24
ER

PT J
AU Ip, MHK
   Cutler, A
AF Ip, Martin Ho Kwan
   Cutler, Anne
TI Universals of listening: Equivalent prosodic entrainment in tone and
   non-tone languages
SO COGNITION
LA English
DT Article
DE Prosody; Prosodic entrainment; Focus; Speech perception;
   Cross-linguistic comparisons
ID MONITORING REACTION-TIME; LEXICAL ACCESS; SPEECH RATE; FOCUS; WORD;
   PERCEPTION; STRESS; INTONATION; ENGLISH; CONTEXT
AB In English and Dutch, listeners entrain to prosodic contours to predict where focus will fall in an utterance. Here, we ask whether this strategy is universally available, even in languages with very different phonological systems (e.g., tone versus non-tone languages). In a phoneme detection experiment, we examined whether prosodic entrainment also occurs in Mandarin Chinese, a tone language, where the use of various suprasegmental cues to lexical identity may take precedence over their use in salience. Consistent with the results from Germanic languages, response times were facilitated when preceding intonation predicted high stress on the target-bearing word, and the lexical tone of the target word (i.e., rising versus falling) did not affect the Mandarin listeners' response. Further, the extent to which prosodic entrainment was used to detect the target phoneme was the same in both English and Mandarin listeners. Nevertheless, native Mandarin speakers did not adopt an entrainment strategy when the sentences were presented in English, consistent with the suggestion that L2 listening may be strained by additional functional load from prosodic processing. These findings have implications for how universal and language-specific mechanisms interact in the perception of focus structure in everyday discourse.
C1 [Ip, Martin Ho Kwan; Cutler, Anne] Western Sydney Univ, MARCS Inst, Penrith, NSW, Australia.
   [Ip, Martin Ho Kwan; Cutler, Anne] ARC Ctr Excellence Dynam Language, Canberra, ACT, Australia.
RP Ip, MHK (corresponding author), Univ Penn, MindCORE, Integrated Language Sci & Technol ILST, 3401-C Walnut St,Suite 300, Philadelphia, PA 19104 USA.
EM mhkip@sas.upenn.edu
FU MARCS Institute; Australian Research Council Centre of Excellence for
   the Dynamics of LanguageAustralian Research Council [CE140100041]
FX Financial support was provided by the MARCS Institute and the Australian
   Research Council Centre of Excellence for the Dynamics of Language
   [CE140100041]. We are grateful to Jason Shaw, Jessie Nixon, Laurence
   Bruggeman, and Jeremy Zehr for their advice in our statistical analyses,
   Mark Antoniou and Chris Carignan for technical support and advice, Zhang
   Yong, Cheng Cheng, and Matthew Stansfield for assistance with
   participant recruitment, Ma Jiayi for help in translating the written
   instructions into Chinese, and Bob Ladd, Giuseppina Turco, and Yi Xu for
   helpful comments on the project. Portions of the data reported here were
   presented at INTERSPEECH 2017 in Stockholm, Sweden.
CR Akker Evelien, 2003, BILING-LANG COGN, V6, P81, DOI DOI 10.1017/S1366728903001056
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   Baese-Berk MM, 2014, PSYCHOL SCI, V25, P1546, DOI 10.1177/0956797614533705
   Balota DA, 2013, J EXP PSYCHOL LEARN, V39, P1563, DOI 10.1037/a0032186
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   BEACH CM, 1991, J MEM LANG, V30, P644, DOI 10.1016/0749-596X(91)90030-N
   Best C. T., 1995, SPEECH PERCEPTION LI, P167
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Birch S, 1995, LANG SPEECH, V38, P365, DOI 10.1177/002383099503800403
   BIRCH SL, 1995, J MEM LANG, V34, P232, DOI 10.1006/jmla.1995.1011
   BLICHER DL, 1990, J PHONETICS, V18, P37, DOI 10.1016/S0095-4470(19)30357-2
   BLUTNER R, 1988, J MEM LANG, V27, P359, DOI 10.1016/0749-596X(88)90061-7
   BOX GEP, 1964, J ROY STAT SOC B, V26, P211, DOI 10.1111/j.2517-6161.1964.tb00553.x
   Braun B, 2019, LANG SPEECH, V62, P751, DOI 10.1177/0023830918814279
   Braun B, 2010, LANG COGNITIVE PROC, V25, P1024, DOI 10.1080/01690960903036836
   Breen M, 2014, LANG COGN NEUROSCI, V29, P1132, DOI 10.1080/23273798.2014.894642
   Brent MR, 1996, COGNITION, V61, P93, DOI 10.1016/S0010-0277(96)00719-6
   Brown M, 2015, J EXP PSYCHOL HUMAN, V41, P306, DOI 10.1037/a0038689
   Brown M, 2011, PSYCHON B REV, V18, P1189, DOI 10.3758/s13423-011-0167-9
   Brunelliere A, 2019, LANG COGN NEUROSCI, V34, P29, DOI 10.1080/23273798.2018.1499945
   Chafe William, 1976, SUBJECT TOPIC, P27
   Chavez-Peon M., 2010, THESIS
   Chen YY, 2008, J PHONETICS, V36, P724, DOI 10.1016/j.wocn.2008.06.003
   Christiansen MH, 1998, LANG COGNITIVE PROC, V13, P221, DOI 10.1080/016909698386528
   Connell B, 2017, PHONOL PHONET, V24, P131, DOI 10.1515/9783110503524-005
   Connell K, 2018, LANG LEARN, V68, P635, DOI 10.1111/lang.12288
   CUTLER A, 1977, LANG SPEECH, V20, P1
   CUTLER A, 1976, PERCEPT PSYCHOPHYS, V20, P55, DOI 10.3758/BF03198706
   CUTLER A, 1979, COGNITION, V7, P49, DOI 10.1016/0010-0277(79)90010-6
   Cutler A, 2002, PSYCHOL SCI, V13, P258, DOI 10.1111/1467-9280.00447
   CUTLER A, 1981, PERCEPT PSYCHOPHYS, V29, P217, DOI 10.3758/BF03207288
   Dahan D, 2002, J MEM LANG, V47, P292, DOI 10.1016/S0749-596X(02)00001-3
   Davis MH, 2002, J EXP PSYCHOL HUMAN, V28, P218, DOI 10.1037//0096-1523.28.1.218
   de Jong K, 2004, J PHONETICS, V32, P493, DOI 10.1016/j.wocn.2004.05.002
   DiCanio C., 2018, J ACOUST SOC AM, V144, DOI [10.1121/1., DOI 10.1121/1]
   DiCanio C, 2018, J PHONETICS, V68, P50, DOI 10.1016/j.wocn.2018.03.001
   Dilley LC, 2008, J MEM LANG, V59, P294, DOI 10.1016/j.jml.2008.06.006
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Dilley LC, 2010, J MEM LANG, V63, P274, DOI 10.1016/j.jml.2010.06.003
   DILLEY LC, 2013, FRONTIERS LANGUAGE S, V4, P1, DOI DOI 10.3389/FPSYG.2013.01002
   Dwyer M., 2004, FRONTIERS INTERDISCI, V10, P151, DOI DOI 10.1017/CBO9781107415324.004
   Felix-Brasdefer JC, 2004, LANG LEARN, V54, P587, DOI 10.1111/j.1467-9922.2004.00281.x
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   FOWLER CA, 1987, J MEM LANG, V26, P489, DOI 10.1016/0749-596X(87)90136-7
   Fraundorf SH, 2010, J MEM LANG, V63, P367, DOI 10.1016/j.jml.2010.06.004
   Fu QJ, 1998, J ACOUST SOC AM, V104, P505, DOI 10.1121/1.423251
   Gandour J, 2003, BRAIN LANG, V84, P318, DOI 10.1016/S0093-934X(02)00505-9
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   Gotzner N., 2013, P 35 ANN C COGN SCI, P2434
   Grassmann S, 2007, J CHILD LANG, V34, P677, DOI 10.1017/S0305000907008021
   Grassmann S, 2010, J PRAGMATICS, V42, P3098, DOI 10.1016/j.pragma.2010.04.019
   GUSSENHOVEN C, 1983, J LINGUIST, V19, P377, DOI 10.1017/S0022226700007799
   Gussenhoven C., 2000, P 6 INT C SPOK LANG, P91
   Hayes Bruce, 1995, METRICAL STRESS THEO
   Heffner CC, 2013, LANG COGNITIVE PROC, V28, P1275, DOI 10.1080/01690965.2012.672229
   HOWELL P, 1993, J ACOUST SOC AM, V94, P2063, DOI 10.1121/1.407479
   Hsu CH, 2015, J PHONETICS, V51, P82, DOI 10.1016/j.wocn.2015.02.003
   Ife A., 2000, SPANISH APPL LINGUIS, V4, P55
   Ip M. H. K., 2018, P 17 AUSTR INT C SPE, P153
   Ip M. H. K., 2016, SPEECH PROSODY 2016, P330, DOI [10.21437/SpeechProsody.2016-68, DOI 10.21437/SPEECHPROSODY.2016-68]
   Johnson TA, 2004, COASTAL AQUIFER MANAGEMENT: MONITORING, MODELING, AND CASE STUDIES, P29
   JUSCZYK PW, 1993, J MEM LANG, V32, P402, DOI 10.1006/jmla.1993.1022
   Karlsson A, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1740
   Kember H, 2019, LANG SPEECH, DOI 10.1177/0023830919880217
   Kleinschmidt D. F., 2011, ACL HLT 2011, P10
   Kratovchil Paul, 1998, INTONATION SYSTEMS S, P417
   Kugler F, 2017, PHONOL PHONET, V24, P89, DOI 10.1515/9783110503524-004
   Kuijpers C, 1998, LANG SPEECH, V41, P87
   Kushch O, 2018, LANG COGN NEUROSCI, V33, P992, DOI 10.1080/23273798.2018.1435894
   Lai W, 2016, P SPEECH PROSODY, V8, P1124, DOI [10.13140/RG.2.1.1749.4165, DOI 10.21437/SPEECHPROSODY.2016-231]
   Laniran YO, 2003, J PHONETICS, V31, P203, DOI 10.1016/S0095-4470(02)00098-0
   Lee A., 2017, P M AC, V29, P60007, DOI [10.1121/2.0000441., DOI 10.1121/2.0000441]
   LEE L, 1993, PERCEPT PSYCHOPHYS, V53, P157, DOI 10.3758/BF03211726
   Lee YC, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01058
   Lehiste Ilde, 1970, SUPRASEGMENTALS
   Li XQ, 2012, NEUROPSYCHOLOGIA, V50, P1882, DOI 10.1016/j.neuropsychologia.2012.04.013
   Lieberman P., 1963, J ACOUST SOC AM, V32, P451, DOI [10.1121/1.1008005, DOI 10.1121/1.1008005]
   Lin CY, 2014, BILING-LANG COGN, V17, P316, DOI 10.1017/S1366728913000333
   Liu F, 2005, PHONETICA, V62, P70, DOI 10.1159/000090090
   Liu SY, 2004, LANG SPEECH, V47, P109, DOI 10.1177/00238309040470020101
   Lo S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01171
   Mattys S, 2000, J MEM LANG, V42, P571, DOI 10.1006/jmla.1999.2696
   Mattys SL, 2007, J EXP PSYCHOL HUMAN, V33, P960, DOI 10.1037/0096-1523.33.4.960
   Gomez DM, 2014, P NATL ACAD SCI USA, V111, P5837, DOI 10.1073/pnas.1318261111
   MCALLISTER J, 1991, LANG SPEECH, V34, P1
   McQueen JM, 1998, J MEM LANG, V39, P21, DOI 10.1006/jmla.1998.2568
   Mennen I, 2004, J PHONETICS, V32, P543, DOI 10.1016/j.wocn.2004.02.002
   Morrill TH, 2014, COGNITION, V131, P69, DOI 10.1016/j.cognition.2013.12.006
   Nazzi T, 2019, ANNU REV LINGUIST, V5, P25, DOI 10.1146/annurev-linguistics-011718-011919
   Nespor M., 2003, LINGUE LINGUAGGIO, V2, P203, DOI [10. 1418/ 10879, DOI 10.1418/10879]
   Nolan Francis, 2006, HDB ENGLISH LINGUIST, P433, DOI DOI 10.1002/9780470753002.CH19
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   Norris D, 1997, COGNITIVE PSYCHOL, V34, P191, DOI 10.1006/cogp.1997.0671
   Norris D, 2006, COGNITIVE PSYCHOL, V53, P146, DOI 10.1016/j.cogpsych.2006.03.001
   Ouyang IC, 2015, LANG COGN NEUROSCI, V30, P57, DOI 10.1080/01690965.2013.805795
   Pennington MC, 2000, MOD LANG J, V84, P372, DOI 10.1111/0026-7902.00075
   Pierrehumbert J., 1999, MIT ENCY COGNITIVE S, P679
   Pisoni D. B., 1987, NATO ADV SCI I SERIE, V39, P155
   RATCLIFF R, 1993, PSYCHOL BULL, V114, P510, DOI 10.1037/0033-2909.114.3.510
   Reed M., 2014, HDB ENGLISH PRONUNCI
   Remijsen B, 2002, PHONOL PHONET, V4-1, P585
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Samuel AG, 2001, PSYCHOL SCI, V12, P348, DOI 10.1111/1467-9280.00364
   Schneider W., 2002, E PRIME USERS GUIDE
   SEIDENBERG MS, 1982, COGNITIVE PSYCHOL, V14, P489, DOI 10.1016/0010-0285(82)90017-2
   Shaw JA, 2018, LAB PHONOL, V9, DOI 10.5334/labphon.87
   Sluijter AMC, 1996, J ACOUST SOC AM, V100, P2471, DOI 10.1121/1.417955
   Tremblay A, 2018, BILING-LANG COGN, V21, P640, DOI 10.1017/S136672891700030X
   Vallabha GK, 2007, P NATL ACAD SCI USA, V104, P13273, DOI 10.1073/pnas.0705369104
   Vanlancker-Sidtis D, 2003, APPL PSYCHOLINGUIST, V24, P45, DOI 10.1017/S0142716403000031
   Vitevitch MS, 1999, J MEM LANG, V40, P374, DOI 10.1006/jmla.1998.2618
   Weenink D, 2018, PRAAT DOING PHONETIC, P43
   WHALEN DH, 1992, PHONETICA, V49, P25, DOI 10.1159/000261901
   Xu Y, 1999, J PHONETICS, V27, P55, DOI 10.1006/jpho.1999.0086
   Xu Y, 2005, SPEECH COMMUN, V46, P220, DOI 10.1016/j.specom.2005.02.014
   Xu Y, 2012, LINGUIST REV, V29, P131, DOI 10.1515/tlr-2012-0006
   Yan MZ, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01985
   Yuan J., 2004, THESIS
   Yuan JH, 2011, J ACOUST SOC AM, V130, P4063, DOI 10.1121/1.3651818
   Zerbian S., 2017, INTONATION AFRICAN T, P89
NR 120
TC 0
Z9 0
U1 10
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD SEP
PY 2020
VL 202
AR 104311
DI 10.1016/j.cognition.2020.104311
PG 32
WC Psychology, Experimental
SC Psychology
GA MO2BT
UT WOS:000551338900012
PM 32502869
OA Green Published
DA 2021-02-24
ER

PT J
AU Lehet, M
   Holt, LL
AF Lehet, Matthew
   Holt, Lori L.
TI Nevertheless, it persists: Dimension-based statistical learning and
   normalization of speech impact different levels of perceptual processing
SO COGNITION
LA English
DT Article
DE Speech perception; Normalization; Dimension-based statistical learning;
   Perceptual learning
ID SPEAKING RATE; INDIVIDUAL-DIFFERENCES; SELECTIVE ADAPTATION; VISUAL
   RECALIBRATION; PRECEDING LIQUID; AUDITORY SPEECH; INFORMATION; CONTEXT;
   CUE; CATEGORIZATION
AB Speech is notoriously variable, with no simple mapping from acoustics to linguistically-meaningful units like words and phonemes. Empirical research on this theoretically central issue establishes at least two classes of perceptual phenomena that accommodate acoustic variability: normalization and perceptual learning. Intriguingly, perceptual learning is supported by learning across acoustic variability, but normalization is thought to counteract acoustic variability leaving open questions about how these two phenomena might interact. Here, we examine the joint impact of normalization and perceptual learning on how acoustic dimensions map to vowel categories. As listeners categorized nonwords as setch or satch, they experienced a shift in short-term distributional regularities across the vowels' acoustic dimensions. Introduction of this 'artificial accent' resulted in a shift in the contribution of vowel duration in categorization. Although this dimension-based statistical learning impacted the influence of vowel duration on vowel categorization, the duration of these very same vowels nonetheless maintained a consistent influence on categorization of a subsequent consonant via duration contrast, a form of normalization. Thus, vowel duration had a duplex role consistent with normalization and perceptual learning operating on distinct levels in the processing hierarchy. We posit that whereas normalization operates across auditory dimensions, dimension-based statistical learning impacts the connection weights among auditory dimensions and phonetic categories.
C1 [Lehet, Matthew; Holt, Lori L.] Carnegie Mellon Univ, Dept Psychol, Pittsburgh, PA 15232 USA.
   [Lehet, Matthew; Holt, Lori L.] Ctr Neural Basis Cognit, Pittsburgh, PA 15232 USA.
   [Holt, Lori L.] Carnegie Mellon Univ, Inst Neurosci, Pittsburgh, PA 15232 USA.
RP Holt, LL (corresponding author), Carnegie Mellon Univ, Dept Psychol, Pittsburgh, PA 15232 USA.; Holt, LL (corresponding author), Ctr Neural Basis Cognit, Pittsburgh, PA 15232 USA.; Holt, LL (corresponding author), Carnegie Mellon Univ, Inst Neurosci, Pittsburgh, PA 15232 USA.
EM loriholt@cmu.edu
OI Holt, Lori/0000-0002-8732-4977
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01DC004674,
   T32GM081760]
FX Research was supported by the National Institutes of Health
   (R01DC004674, T32GM081760). Thanks to Christi Gomez for support in
   testing human participants and Dr. Ran Liu for help generating stimuli
   and thoughtful discussions in motivating this work. Correspondence
   regarding this article should be addressed to Lori L. Holt, Department
   of Psychology, Carnegie Mellon University, 5000 Forbes Avenue,
   Pittsburgh, PA 15213, loriholt@cmu.edu.
CR Babel M, 2010, LANG SOC, V39, P437, DOI 10.1017/S0047404510000400
   Bates D., 2007, R PACKAGE VERSION, V2, P74
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Boersma P., 2013, PRAAT DOING PHONETIC
   Bosker H. R., 2015, NORMALIZATION SPEECH
   Bourguignon NJ, 2016, J EXP PSYCHOL HUMAN, V42, P1039, DOI 10.1037/xhp0000209
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   BROADBENT DE, 1956, NATURE, V178, P815, DOI 10.1038/178815b0
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   Dechovitz D., 1977, INFORM CONVEYED VOWE
   DENES P, 1955, J ACOUST SOC AM, V27, P761, DOI 10.1121/1.1908020
   DIEHL RL, 1989, J ACOUST SOC AM, V85, P2154, DOI 10.1121/1.397864
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fitch WT, 1999, J ACOUST SOC AM, V106, P1511, DOI 10.1121/1.427148
   Floccia C, 2006, J EXP PSYCHOL HUMAN, V32, P1276, DOI 10.1037/0096-1523.32.5.1276
   GARVIN PL, 1963, PHONETICA, V9, P193, DOI 10.1159/000258404
   GREENSPAN SL, 1988, J EXP PSYCHOL LEARN, V14, P421, DOI 10.1037/0278-7393.14.3.421
   Guediche S., 2014, CEREBRAL CORTEX
   Guediche S, 2016, J EXP PSYCHOL HUMAN, V42, P1048, DOI 10.1037/xhp0000196
   Hervais-Adelman A, 2008, J EXP PSYCHOL HUMAN, V34, P460, DOI 10.1037/0096-1523.34.2.460
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hillenbrand JM, 2000, J ACOUST SOC AM, V108, P3013, DOI 10.1121/1.1323463
   Holt LL, 2006, J ACOUST SOC AM, V119, P4016, DOI 10.1121/1.2195119
   Holt LL, 2000, J ACOUST SOC AM, V108, P710, DOI 10.1121/1.429604
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Huang JY, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00010
   Huang JY, 2009, J ACOUST SOC AM, V125, P3983, DOI 10.1121/1.3125342
   Hufnagle DG, 2013, J EXP CHILD PSYCHOL, V116, P728, DOI 10.1016/j.jecp.2013.05.008
   Idemaru K, 2014, J EXP PSYCHOL HUMAN, V40, P1009, DOI 10.1037/a0035269
   Idemaru K, 2012, J ACOUST SOC AM, V132, P3950, DOI 10.1121/1.4765076
   Idemaru K, 2011, J EXP PSYCHOL HUMAN, V37, P1939, DOI 10.1037/a0025641
   Joanisse MF, 2015, WIRES COGN SCI, V6, P235, DOI 10.1002/wcs.1340
   JOHNSON K, 1990, J ACOUST SOC AM, V88, P642, DOI 10.1121/1.399767
   Joos Martin, 1948, LANGUAGE, V24, P5, DOI DOI 10.2307/522229
   Kingston J, 2014, ATTEN PERCEPT PSYCHO, V76, P1437, DOI 10.3758/s13414-013-0593-z
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   KLUENDER KR, 1988, J PHONETICS, V16, P153, DOI 10.1016/S0095-4470(19)30480-2
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2008, COGNITION, V107, P54, DOI 10.1016/j.cognition.2007.07.013
   Kraljic T, 2008, PSYCHOL SCI, V19, P332, DOI 10.1111/j.1467-9280.2008.02090.x
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299
   Labov W., 2005, ATLAS N AM ENGLISH P
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   LADEFOGED P, 1989, J ACOUST SOC AM, V85, P2223, DOI 10.1121/1.397821
   Lee S, 1999, J ACOUST SOC AM, V105, P1455, DOI 10.1121/1.426686
   Lehet M, 2017, COGNITIVE SCI, V41, P885, DOI 10.1111/cogs.12413
   LIBERMAN AM, 1956, J EXP PSYCHOL, V52, P127, DOI 10.1037/h0041240
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   LINDBLOM B, 1990, NATO ADV SCI I D-BEH, V55, P403
   Liu R, 2015, J EXP PSYCHOL HUMAN, V41, P1783, DOI 10.1037/xhp0000092
   Lotto AJ, 1998, PERCEPT PSYCHOPHYS, V60, P602, DOI 10.3758/BF03206049
   Lotto AJ, 2006, PERCEPT PSYCHOPHYS, V68, P178, DOI 10.3758/BF03193667
   Magnuson J. S., 2011, COMPUTATIONAL MODELS, P1
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P407, DOI 10.3758/BF03204884
   Marr D., 1976, UNDERSTANDING COMPUT
   Maye J, 2008, COGNITIVE SCI, V32, P543, DOI 10.1080/03640210802035357
   McClelland J.L., 1986, PARALLEL DISTRIBUTED
   McClelland JL, 2006, TRENDS COGN SCI, V10, P363, DOI 10.1016/j.tics.2006.06.007
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2005, COGNITION, V95, pB15, DOI 10.1016/j.cognition.2004.07.005
   MILLER JD, 1989, J ACOUST SOC AM, V85, P2114, DOI 10.1121/1.397862
   MILLER JL, 1984, PHONETICA, V41, P215, DOI 10.1159/000261728
   MILLER JL, 1979, PERCEPT PSYCHOPHYS, V25, P457, DOI 10.3758/BF03213823
   MILLER JL, 1993, PERCEPT PSYCHOPHYS, V54, P205, DOI 10.3758/BF03211757
   MILLER JL, 1989, PERCEPT PSYCHOPHYS, V46, P505, DOI 10.3758/BF03208147
   MILLER JL, 1983, J ACOUST SOC AM, V73, P1751, DOI 10.1121/1.389399
   Mirman D, 2006, PSYCHON B REV, V13, P958, DOI 10.3758/BF03213909
   Newman RS, 1996, PERCEPT PSYCHOPHYS, V58, P540, DOI 10.3758/BF03213089
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Pellegrino F, 2011, LANGUAGE, V87, P539
   Perry TL, 2001, J ACOUST SOC AM, V109, P2988, DOI 10.1121/1.1370525
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Port R. F., 1982, ATTENTION
   Quene H, 2008, J ACOUST SOC AM, V123, P1104, DOI 10.1121/1.2821762
   Quene H, 2013, J ACOUST SOC AM, V133, pEL452, DOI 10.1121/1.4802892
   R Core Team, 2013, R LANG ENV STAT COMP
   RAPHAEL LJ, 1972, J ACOUST SOC AM, V51, P1296, DOI 10.1121/1.1912974
   Reinisch E, 2016, APPL PSYCHOLINGUIST, V37, P1397, DOI 10.1017/S0142716415000612
   Reinisch E, 2014, J EXP PSYCHOL HUMAN, V40, P539, DOI 10.1037/a0034409
   Samuel AG, 1997, COGNITIVE PSYCHOL, V32, P97, DOI 10.1006/cogp.1997.0646
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   Sawusch JR, 2000, PERCEPT PSYCHOPHYS, V62, P285, DOI 10.3758/BF03205549
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   SCHWAB EC, 1985, HUM FACTORS, V27, P395
   Sjerps MJ, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10365-z
   Stephens JDW, 2003, J ACOUST SOC AM, V114, P3036, DOI 10.1121/1.1627837
   Viswanathan N, 2009, PSYCHON B REV, V16, P74, DOI 10.3758/PBR.16.1.74
   Vroomen J, 2004, SPEECH COMMUN, V44, P55, DOI 10.1016/j.specom.2004.03.009
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
   Vroomen J, 2009, LANG SPEECH, V52, P341, DOI 10.1177/0023830909103178
   Wade T, 2005, PERCEPT PSYCHOPHYS, V67, P939, DOI 10.3758/BF03193621
   Wade T, 2005, J ACOUST SOC AM, V118, P1701, DOI 10.1121/1.1984839
   Zhang CC, 2016, J EXP PSYCHOL HUMAN, V42, P1252, DOI 10.1037/xhp0000216
   Zhang XJ, 2018, J EXP PSYCHOL HUMAN, V44, P1760, DOI 10.1037/xhp0000569
   Zhang XJ, 2014, J EXP PSYCHOL HUMAN, V40, P200, DOI 10.1037/a0033182
NR 99
TC 1
Z9 1
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD SEP
PY 2020
VL 202
AR 104328
DI 10.1016/j.cognition.2020.104328
PG 14
WC Psychology, Experimental
SC Psychology
GA MO2BT
UT WOS:000551338900023
PM 32502867
OA Other Gold
DA 2021-02-24
ER

PT J
AU Choi, D
   Batterink, LJ
   Black, AK
   Paller, KA
   Werker, JF
AF Choi, Dawoon
   Batterink, Laura J.
   Black, Alexis K.
   Paller, Ken A.
   Werker, Janet F.
TI Preverbal Infants Discover Statistical Word Patterns at Similar Rates as
   Adults: Evidence From Neural Entrainment
SO PSYCHOLOGICAL SCIENCE
LA English
DT Article
DE speech perception; language development; learning; infant development;
   open data; open materials; preregistered
ID COMPUTATION; TIME
AB The discovery of words in continuous speech is one of the first challenges faced by infants during language acquisition. This process is partially facilitated by statistical learning, the ability to discover and encode relevant patterns in the environment. Here, we used an electroencephalogram (EEG) index of neural entrainment to track 6-month-olds' (N= 25) segmentation of words from continuous speech. Infants' neural entrainment to embedded words increased logarithmically over the learning period, consistent with a perceptual shift from isolated syllables to wordlike units. Moreover, infants' neural entrainment during learning predicted postlearning behavioral measures of word discrimination (n= 18). Finally, the logarithmic increase in entrainment to words was comparable in infants and adults, suggesting that infants and adults follow similar learning trajectories when tracking probability information among speech sounds. Statistical-learning effects in infants and adults may reflect overlapping neural mechanisms, which emerge early in life and are maintained throughout the life span.
C1 [Choi, Dawoon; Werker, Janet F.] Univ British Columbia, Dept Psychol, 2136 West Mall, Vancouver, BC V6T 1Z4, Canada.
   [Batterink, Laura J.] Western Univ, Dept Psychol, London, ON, Canada.
   [Batterink, Laura J.] Western Univ, Brain & Mind Inst, Western Interdisciplinary Res Bldg,Room 6124, London, ON N6A 3K7, Canada.
   [Black, Alexis K.] Univ British Columbia, Sch Audiol & Speech Sci, Vancouver, BC, Canada.
   [Paller, Ken A.] Northwestern Univ, Dept Psychol, Evanston, IL 60208 USA.
RP Choi, D (corresponding author), Univ British Columbia, Dept Psychol, 2136 West Mall, Vancouver, BC V6T 1Z4, Canada.; Batterink, LJ (corresponding author), Western Univ, Brain & Mind Inst, Western Interdisciplinary Res Bldg,Room 6124, London, ON N6A 3K7, Canada.
EM dchoi@psych.ubc.ca; lbatter@uwo.ca
OI Paller, Ken/0000-0003-4415-4143; Werker, Janet F./0000-0002-1168-9013;
   Black, Alexis/0000-0001-6764-4319
FU Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR
   [RGPIN-2015-03967]; Canada Foundation for Innovation John R. Evans
   Leaders Fund [33096]
FX This research was funded by grants to J. F. Werker from the Natural
   Sciences and Engineering Research Council of Canada (RGPIN-2015-03967)
   and the Canada Foundation for Innovation John R. Evans Leaders Fund
   (33096).
CR Aslin RN, 1998, PSYCHOL SCI, V9, P321, DOI 10.1111/1467-9280.00063
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Batterink L, 2020, J COGNITIVE NEUROSCI, V32, P1735, DOI 10.1162/jocn_a_01581
   Batterink LJ, 2019, CORTEX, V115, P56, DOI 10.1016/j.cortex.2019.01.013
   Batterink LJ, 2017, CORTEX, V90, P31, DOI 10.1016/j.cortex.2017.02.004
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   Buiatti M, 2009, NEUROIMAGE, V44, P509, DOI 10.1016/j.neuroimage.2008.09.015
   Cirelli LK, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00229
   Dayan E, 2011, NEURON, V72, P443, DOI 10.1016/j.neuron.2011.10.008
   Dehaene-Lambertz G, 2004, J COGNITIVE NEUROSCI, V16, P1375, DOI 10.1162/0898929042304714
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Estes KG, 2007, PSYCHOL SCI, V18, P254, DOI 10.1111/j.1467-9280.2007.01885.x
   Estes KG, 2015, DEV PSYCHOL, V51, P1517, DOI 10.1037/a0039725
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Flo A, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12802
   Fujioka T, 2011, CLIN NEUROPHYSIOL, V122, P43, DOI 10.1016/j.clinph.2010.04.036
   HUNTER MA, 1983, DEV PSYCHOL, V19, P338, DOI 10.1037/0012-1649.19.3.338
   Jarosz AF, 2014, J PROBL SOLVING, V7, P2, DOI 10.7771/1932-6246.1167
   Kabdebon C, 2015, BRAIN LANG, V148, P25, DOI 10.1016/j.bandl.2015.03.005
   KARNI A, 1993, NATURE, V365, P250, DOI 10.1038/365250a0
   Klatt D. H., 1980, PERCEPTION PRODUCTIO, P243
   Lany J, 2018, J CHILD LANG, V45, P368, DOI 10.1017/S0305000917000253
   Mourad N, 2007, INT CONF ACOUST SPEE, P393
   Nozaradan S, 2011, J NEUROSCI, V31, P10234, DOI 10.1523/JNEUROSCI.0411-11.2011
   R Core Team, 2013, R LANG ENV STAT COMP
   Riecke L, 2018, CURR BIOL, V28, P161, DOI 10.1016/j.cub.2017.11.033
   Saffran JR, 2018, ANNU REV PSYCHOL, V69, P181, DOI 10.1146/annurev-psych-122216-011805
   Saffran JR, 2001, COGNITION, V81, P149, DOI 10.1016/S0010-0277(01)00132-9
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Saffran JR, 1997, PSYCHOL SCI, V8, P101, DOI 10.1111/j.1467-9280.1997.tb00690.x
   Schroeder CE, 2009, TRENDS NEUROSCI, V32, P9, DOI 10.1016/j.tins.2008.09.012
   Shi RS, 2001, PSYCHOL SCI, V12, P70, DOI 10.1111/1467-9280.00312
   Siegelman N, 2018, COGNITIVE SCI, V42, P692, DOI 10.1111/cogs.12556
   Swingley D, 2005, DEVELOPMENTAL SCI, V8, P432, DOI 10.1111/j.1467-7687.2005.00432.x
   Teinonen T, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-21
   Thiessen ED, 2016, WIRES COGN SCI, V7, P276, DOI 10.1002/wcs.1394
   Thut G, 2012, CURR BIOL, V22, pR658, DOI 10.1016/j.cub.2012.06.061
   Wagenmakers EJ, 2018, PSYCHON B REV, V25, P58, DOI [10.3758/s13423-017-1323-7, 10.3758/s13423-017-1343-3]
   Wilsch A, 2018, NEUROIMAGE, V172, P766, DOI 10.1016/j.neuroimage.2018.01.038
   Winter B, 2013, ARXIV 1308 5499
NR 41
TC 0
Z9 0
U1 3
U2 3
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0956-7976
EI 1467-9280
J9 PSYCHOL SCI
JI Psychol. Sci.
PD SEP
PY 2020
VL 31
IS 9
BP 1161
EP 1173
AR 0956797620933237
DI 10.1177/0956797620933237
EA AUG 2020
PG 13
WC Psychology, Multidisciplinary
SC Psychology
GA NS2SF
UT WOS:000564919700001
PM 32865487
DA 2021-02-24
ER

PT J
AU Xu, ZB
   Yuan, B
   Zhernovnykova, O
   Zelenska, L
AF Xu, Zhibin
   Yuan, Bo
   Zhernovnykova, Oksana
   Zelenska, Liudmyla
TI A comparative analysis of physiological and functional effectiveness of
   speech and music perception among musicians and non-musicians
SO INTERDISCIPLINARY SCIENCE REVIEWS
LA English
DT Article
DE Alpha range; cerebral hemispheres; musical perception; speech
   perception; symmetrical interactions; Ukrainian; Chinese; Slavic music
ID CORTICAL ENTRAINMENT; EEG; TRIAL; OSCILLATIONS; COMPONENTS; RESPONSES;
   TIME; ERP
AB The purpose of the study is to compare at the physiological and functional levels, the effectiveness of speech and music perception among musicians and non-musicians. The study was conducted in 2018 in Ningbo University in Zhejiang Province (China) on 235 students aged 20-21. The results showed that in the experimental group, when perceiving music, symmetrical hemisphere interaction parameters dominate (p <= 0.05), in both groups, right-hand parameters dominate in speech perception. The third group showed a difference in the depth of decrease in the amplitude of the alpha rhythm with respect to the resting state (p <= 0.03) in the low-frequency range when listening to a fragment of Slavic folklore. The interaction of the cerebral hemispheres determines a high result in the processing of music. The latter manifested itself when listening to Slavic music: the width of the alpha-1 range is wider when listening in comparison with the state of rest.
C1 [Xu, Zhibin] Ningbo Univ, Mus Acad, 818 Fenghua Rd, Ningbo, Peoples R China.
   [Yuan, Bo] Ningbo Univ, Coll Teacher Educ, Ningbo, Peoples R China.
   [Zhernovnykova, Oksana] HS Skovoroda Kharkiv Natl Pedag Univ, Dept Math, Kharkiv, Ukraine.
   [Zelenska, Liudmyla] HS Skovoroda Kharkiv Natl Pedag Univ, Higher Sch, Dept Gen Pedag & Pedag, Kharkiv, Ukraine.
RP Xu, ZB (corresponding author), Ningbo Univ, Mus Acad, 818 Fenghua Rd, Ningbo, Peoples R China.
EM zhibinxu10@yahoo.com
CR Alluri V, 2012, NEUROIMAGE, V59, P3677, DOI 10.1016/j.neuroimage.2011.11.019
   Beres AM, 2017, APPL PSYCHOPHYS BIOF, V42, P247, DOI 10.1007/s10484-017-9371-3
   Blankertz B, 2011, NEUROIMAGE, V56, P814, DOI 10.1016/j.neuroimage.2010.06.048
   Brattico P, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00159
   Burger B, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00183
   Burunat I, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00230
   Cong F., 2015, ADV SIGNAL PROCESSIN
   Cong FY, 2012, EUR SIGNAL PR CONF, P494
   Cong FY, 2013, J NEUROSCI METH, V212, P165, DOI 10.1016/j.jneumeth.2012.09.029
   Cong FY, 2012, J MED BIOL ENG, V32, P205, DOI 10.5405/jmbe.908
   Crosse MJ, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00604
   de Cheveigne A, 2019, NEUROIMAGE, V186, P728, DOI 10.1016/j.neuroimage.2018.11.026
   De Vos M, 2012, NEUROIMAGE, V63, P1196, DOI 10.1016/j.neuroimage.2012.07.055
   Debener S, 2012, PSYCHOPHYSIOLOGY, V49, P1617, DOI 10.1111/j.1469-8986.2012.01471.x
   Di Liberto GM, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0084-18.2018
   Di Liberto GM, 2018, NEUROIMAGE, V175, P70, DOI 10.1016/j.neuroimage.2018.03.072
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Ding N, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00311
   Ding N, 2014, NEUROIMAGE, V88, P41, DOI 10.1016/j.neuroimage.2013.10.054
   Doelling KB, 2015, P NATL ACAD SCI USA, V112, pE6233, DOI 10.1073/pnas.1508431112
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Enaizan O, 2018, HLTH TECHNOL, P1
   Escoffier N, 2015, NEUROIMAGE, V111, P267, DOI 10.1016/j.neuroimage.2015.02.024
   Farbood MM, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00998
   Gemma M. G., 2020, INTERDISCIPLINARY SC
   Hamada M, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1020-8
   Houa J. L., 2020, LIS 2020
   Jancke Lutz, 2015, Front Hum Neurosci, V9, P401, DOI 10.3389/fnhum.2015.00401
   Jin ZS, 2017, NEUROIMAGE-CLIN, V14, P602, DOI 10.1016/j.nicl.2017.02.024
   Joret ME, 2017, INT CONF DIGIT SIG
   Kaburlasos V. G., 2019, 2019 IEEE INT C FUZZ, P1
   Kimura D, 1983, Hum Neurobiol, V2, P147
   Koskinen M, 2013, HUM BRAIN MAPP, V34, P1477, DOI 10.1002/hbm.22004
   Kotik B. S., 1975, THESIS
   Lehne M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00079
   Litvinova N. A., 2020, INT SCI PRACT C ED H
   Miendlarzewska EA, 2014, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00279
   Mohan V. S., 2019, INT J RECENT TECHNOL, V8, DOI [10.35940/ijrte.B2650.098319, DOI 10.35940/IJRTE.B2650.098319]
   Mohsin AH, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1104-5
   Nikjeh DA, 2009, EAR HEARING, V30, P432, DOI 10.1097/AUD.0b013e3181a61bf2
   O'Sullivan JA, 2015, CEREB CORTEX, V25, P1697, DOI 10.1093/cercor/bht355
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Pereira DR, 2014, INT J PSYCHOPHYSIOL, V94, P311, DOI 10.1016/j.ijpsycho.2014.09.012
   Poikonen H, 2016, NEUROSCIENCE, V312, P58, DOI 10.1016/j.neuroscience.2015.10.061
   Rabelo CM, 2015, BRAZ J OTORHINOLAR, V81, P63, DOI 10.1016/j.bjorl.2014.11.003
   Rigoulot S, 2015, NEUROSCIENCE, V290, P175, DOI 10.1016/j.neuroscience.2015.01.033
   Rosen DS, 2020, NEUROIMAGE, V213, DOI 10.1016/j.neuroimage.2020.116632
   Sanju Himanshu Kumar, 2016, J Otol, V11, P63, DOI 10.1016/j.joto.2016.04.002
   Schon D, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00167
   SPELLACY F, 1970, J ACOUST SOC AM, V47, P574, DOI 10.1121/1.1911932
   Stober S., 2015, 16 INT SOC MUS INF R, P763
   Sturm I., 2014, NEUR MUS 5 DIJ
   Sturm I, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141281
   Tremblay KL, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00028
   Virtala P, 2018, MUSIC PERCEPT, V35, P315, DOI 10.1525/MP.2018.35.3.315
   Wong DDE, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00531
   Zhang JJ, 2019, NEUROPSYCHOLOGIA, V132, DOI 10.1016/j.neuropsychologia.2019.107118
NR 57
TC 0
Z9 0
U1 10
U2 10
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0308-0188
EI 1743-2790
J9 INTERDISCIPL SCI REV
JI Interdiscip. Sci. Rev.
PD OCT 1
PY 2020
VL 45
IS 4
BP 547
EP 563
DI 10.1080/03080188.2020.1808932
EA AUG 2020
PG 17
WC Multidisciplinary Sciences; Social Sciences, Interdisciplinary
SC Science & Technology - Other Topics; Social Sciences - Other Topics
GA PF9XT
UT WOS:000573994700001
DA 2021-02-24
ER

PT J
AU Schiller, NO
   Boutonnet, BPA
   Kloots, MLSD
   Meelen, M
   Ruijgrok, B
   Cheng, LLS
AF Schiller, Niels O.
   Boutonnet, Bastien P. -A.
   De Heer Kloots, Marianne L. S.
   Meelen, Marieke
   Ruijgrok, Bobby
   Cheng, Lisa L. -S.
TI (Not so) Great Expectations: Listening to Foreign-Accented Speech
   Reduces the Brain's Anticipatory Processes
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE prediction; speech perception; sentence comprehension; foreign-accented
   speech; Dutch; native vs; non-native speech processing
ID SEMANTIC MEMORY; PRIOR KNOWLEDGE; UPCOMING WORDS; LANGUAGE;
   COMPREHENSION; POTENTIALS; OBJECTS; INTEGRATION; PREDICTION;
   2ND-LANGUAGE
AB This study examines the effect of foreign-accented speech on the predictive ability of our brain. Listeners actively anticipate upcoming linguistic information in the speech signal so as to facilitate and reduce processing load. However, it is unclear whether or not listeners also do this when they are exposed to speech from non-native speakers. In the present study, we exposed native Dutch listeners to sentences produced by native and non-native speakers while measuring their brain activity using electroencephalography. We found that listeners' brain activity differed depending on whether they listened to native or non-native speech. However, participants' overall performance as measured by word recall rate was unaffected. We discussed the results in relation to previous findings as well as the automaticity of anticipation.
C1 [Schiller, Niels O.; Boutonnet, Bastien P. -A.; De Heer Kloots, Marianne L. S.; Meelen, Marieke; Ruijgrok, Bobby; Cheng, Lisa L. -S.] Leiden Univ, Leiden Univ Ctr Linguist, Leiden, Netherlands.
   [Schiller, Niels O.; Ruijgrok, Bobby; Cheng, Lisa L. -S.] Leiden Inst Brain & Cognit, Leiden, Netherlands.
   [De Heer Kloots, Marianne L. S.] Univ Amsterdam, Fac Sci, Amsterdam, Netherlands.
   [Meelen, Marieke] Univ Cambridge, Theoret & Appl Linguist, Cambridge, England.
RP Schiller, NO (corresponding author), Leiden Univ, Leiden Univ Ctr Linguist, Leiden, Netherlands.; Schiller, NO (corresponding author), Leiden Inst Brain & Cognit, Leiden, Netherlands.
EM n.o.schiller@hum.leidenuniv.nl
RI Schiller, Niels O./A-9481-2008
OI Schiller, Niels O./0000-0002-0392-7608; Cheng, Lisa/0000-0002-0350-5640;
   Ruijgrok, Bobby/0000-0001-5306-6415
FU European Union's Seventh Framework Programme for research, technological
   development and demonstration [613465]
FX BB was supported by the European Union's Seventh Framework Programme for
   research, technological development and demonstration under grant
   agreement no. 613465.
CR [Anonymous], 1994, J Clin Neurophysiol, V11, P111
   Bar M, 2003, J COGNITIVE NEUROSCI, V15, P600, DOI 10.1162/089892903321662976
   Bar M, 2004, NAT REV NEUROSCI, V5, P617, DOI 10.1038/nrn1476
   Bendixen A, 2014, CORTEX, V53, P9, DOI 10.1016/j.cortex.2014.01.001
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Boutonnet B, 2015, J NEUROSCI, V35, P9329, DOI 10.1523/JNEUROSCI.5111-14.2015
   Boutonnet B, 2013, J COGNITIVE NEUROSCI, V25, P1702, DOI 10.1162/jocn_a_00415
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477
   CONNOLLY JF, 1995, J CLIN EXP NEUROPSYC, V17, P548, DOI 10.1080/01688639508405145
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256
   D'Arcy RCN, 2004, HUM BRAIN MAPP, V22, P40, DOI 10.1002/hbm.20008
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504
   DeLong KA, 2016, NEUROPSYCHOLOGIA, V91, P380, DOI 10.1016/j.neuropsychologia.2016.09.004
   Diaz MT, 2007, BRAIN RES, V1146, P85, DOI 10.1016/j.brainres.2006.07.034
   Edmiston P., 2013, P 35 ANN C COGN SCI, P2243
   Edmiston P, 2017, J MEM LANG, V92, P281, DOI 10.1016/j.jml.2016.07.002
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660
   Foucart A, 2015, LANG COGN NEUROSCI, V30, P768, DOI 10.1080/23273798.2015.1016047
   Foucart A, 2014, J EXP PSYCHOL LEARN, V40, P1461, DOI 10.1037/a0036756
   Francken JC, 2015, NEUROSCI CONSCIOUS, DOI 10.1093/nc/niv003
   Francken JC, 2015, J COGNITIVE NEUROSCI, V27, P175, DOI 10.1162/jocn_a_00682
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   Goslin J, 2012, BRAIN LANG, V122, P92, DOI 10.1016/j.bandl.2012.04.017
   GRATTON G, 1983, ELECTROEN CLIN NEURO, V55, P468, DOI 10.1016/0013-4694(83)90135-9
   Groppe DM, 2010, BRAIN RES, V1361, P54, DOI 10.1016/j.brainres.2010.09.003
   Gut U., 2012, MULTILINGUAL CORPORA, P3
   Hagoort P, 2000, NEUROPSYCHOLOGIA, V38, P1518, DOI 10.1016/S0028-3932(00)00052-X
   Hanulikova A, 2012, J COGNITIVE NEUROSCI, V24, P878, DOI 10.1162/jocn_a_00103
   HOLCOMB PJ, 1993, PSYCHOPHYSIOLOGY, V30, P47, DOI 10.1111/j.1469-8986.1993.tb03204.x
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223
   Ito A, 2017, LANG COGN NEUROSCI, V32, P954, DOI 10.1080/23273798.2016.1242761
   Kok P, 2014, J COGNITIVE NEUROSCI, V26, P1546, DOI 10.1162/jocn_a_00562
   Kok P, 2012, CEREB CORTEX, V22, P2197, DOI 10.1093/cercor/bhr310
   Kok P, 2012, NEURON, V75, P265, DOI 10.1016/j.neuron.2012.04.034
   Kuperberg GR, 2011, J COGNITIVE NEUROSCI, V23, P1230, DOI 10.1162/jocn.2010.21452
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657
   Kutas M, 2000, TRENDS COGN SCI, V4, P463, DOI 10.1016/S1364-6613(00)01560-6
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0
   Kutas M., 1994, HDB PSYCHOLINGUISTIC, P83, DOI DOI 10.1016/8978-012369374-7/50018-3
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Leckey M., 2019, OXFORD HDB NEUROLING, P42
   Lev-Ari S, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01546
   Lupyan G, 2013, P NATL ACAD SCI USA, V110, P14196, DOI 10.1073/pnas.1303312110
   Martin CD, 2013, J MEM LANG, V69, P574, DOI 10.1016/j.jml.2013.08.001
   McGettigan C, 2012, NEUROPSYCHOLOGIA, V50, P762, DOI 10.1016/j.neuropsychologia.2012.01.010
   Nieuwland MS, 2018, ELIFE, V7, DOI 10.7554/eLife.33468
   Nissen SL, 2007, PHONETICA, V64, P201, DOI 10.1159/000121373
   Obleser J, 2007, J NEUROSCI, V27, P2283, DOI 10.1523/JNEUROSCI.4663-06.2007
   Otten M, 2007, BMC NEUROSCI, V8, DOI 10.1186/1471-2202-8-89
   Paczynski M, 2012, J MEM LANG, V67, P426, DOI 10.1016/j.jml.2012.07.003
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002
   Porretta V, 2017, J NEUROLINGUIST, V44, P54, DOI 10.1016/j.jneuroling.2017.03.002
   RIDING RJ, 1980, EDUC REV, V32, P259, DOI 10.1080/0013191800320303
   Romero-Rivas C, 2016, NEUROPSYCHOLOGIA, V85, P245, DOI 10.1016/j.neuropsychologia.2016.03.022
   Romero-Rivas C, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3389/fnhum.7015.00167, 10.3389/fnhum.2015.00167]
   Samaha J., 2016, BIORXIV PREPRINT, DOI [10.1101/076687v5, DOI 10.1101/076687V5]
   SanMiguel I, 2013, J NEUROSCI, V33, P8633, DOI 10.1523/JNEUROSCI.5821-12.2013
   Schiller NO, 2009, NEUROIMAGE, V44, P520, DOI 10.1016/j.neuroimage.2008.09.019
   Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   Strauss A, 2013, J COGNITIVE NEUROSCI, V25, P1383, DOI 10.1162/jocn_a_00389
   Summerfield C, 2014, NAT REV NEUROSCI, V15, P745, DOI 10.1038/nrn3838
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443
   van Berkum JJA, 2013, THEOR LINGUIST, V39, P75, DOI 10.1515/tl-2013-0004
   Van Petten C, 2006, BRAIN LANG, V97, P279, DOI 10.1016/j.bandl.2005.11.003
   Vandenbroucke ARE, 2016, CEREB CORTEX, V26, P1401, DOI 10.1093/cercor/bhu224
   Vinck M, 2011, NEUROIMAGE, V55, P1548, DOI 10.1016/j.neuroimage.2011.01.055
   Wade T, 2007, PHONETICA, V64, P122, DOI 10.1159/000107913
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Wester F, 2007, LANG SCI, V29, P477, DOI 10.1016/j.langsci.2006.12.029
   Witteman MJ, 2013, ATTEN PERCEPT PSYCHO, V75, P537, DOI 10.3758/s13414-012-0404-y
NR 72
TC 0
Z9 0
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD AUG 25
PY 2020
VL 11
AR 2143
DI 10.3389/fpsyg.2020.02143
PG 11
WC Psychology, Multidisciplinary
SC Psychology
GA NQ0DR
UT WOS:000570539900001
PM 32982877
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Lee, J
   Han, JH
   Lee, HJ
AF Lee, Jihyun
   Han, Ji-Hye
   Lee, Hyo-Jeong
TI Long-Term Musical Training Alters Auditory Cortical Activity to the
   Frequency Change
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE frequency change; spectral processing; musical training; N1; P2 auditory
   evoked potential; hemispheric asymmetry
ID GENOME-WIDE LINKAGE; SPEECH-PERCEPTION; ABSOLUTE PITCH; LANGUAGE
   EXPERIENCE; EVOKED-POTENTIALS; CONTINUOUS TONE; NON-MUSICIANS; CORTEX;
   BRAIN; NOISE
AB Objective: The ability to detect frequency variation is a fundamental skill necessary for speech perception. It is known that musical expertise is associated with a range of auditory perceptual skills, including discriminating frequency change, which suggests the neural encoding of spectral features can be enhanced by musical training. In this study, we measured auditory cortical responses to frequency change in musicians to examine the relationships between N1/P2 responses and behavioral performance/musical training. Methods: Behavioral and electrophysiological data were obtained from professional musicians and age-matched non-musician participants. Behavioral data included frequency discrimination detection thresholds for no threshold-equalizing noise (TEN), +5, 0, and -5 signal-to-noise ratio settings. Auditory-evoked responses were measured using a 64-channel electroencephalogram (EEG) system in response to frequency changes in ongoing pure tones consisting of 250 and 4,000 Hz, and the magnitudes of frequency change were 10%, 25% or 50% from the base frequencies. N1 and P2 amplitudes and latencies as well as dipole source activation in the left and right hemispheres were measured for each condition. Results: Compared to the non-musician group, behavioral thresholds in the musician group were lower for frequency discrimination in quiet conditions only. The scalp-recorded N1 amplitudes were modulated as a function of frequency change. P2 amplitudes in the musician group were larger than in the non-musician group. Dipole source analysis showed that P2 dipole activity to frequency changes was lateralized to the right hemisphere, with greater activity in the musician group regardless of the hemisphere side. Additionally, N1 amplitudes to frequency changes were positively related to behavioral thresholds for frequency discrimination while enhanced P2 amplitudes were associated with a longer duration of musical training. Conclusions: Our results demonstrate that auditory cortical potentials evoked by frequency change are related to behavioral thresholds for frequency discrimination in musicians. Larger P2 amplitudes in musicians compared to non-musicians reflects musical training-induced neural plasticity.
C1 [Lee, Jihyun; Han, Ji-Hye; Lee, Hyo-Jeong] Hallym Univ, Coll Med, Lab Brain & Cognit Sci Convergence Med, Anyang, South Korea.
   [Lee, Hyo-Jeong] Hallym Univ, Dept Otorhinolaryngol, Coll Med, Anyang, South Korea.
RP Lee, HJ (corresponding author), Hallym Univ, Coll Med, Lab Brain & Cognit Sci Convergence Med, Anyang, South Korea.; Lee, HJ (corresponding author), Hallym Univ, Dept Otorhinolaryngol, Coll Med, Anyang, South Korea.
EM hyojlee@hallym.ac.kr
RI Lee, Hyo-Jeong/AAK-7973-2020
OI Lee, Hyo-Jeong/0000-0003-2258-0803
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2020R1I1A1A0107091411,
   2019R1A2B5B01070129]; Center for Women in Science, Engineering and
   Technology (WISET) - Ministry of Science ICT and Future Planning of
   Korea (MSIP) under the Program for Returners into RD [WISET-2020-203];
   Hallym University Research Fund [HURF-2017-79]
FX This project was supported by Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (2020R1I1A1A0107091411 and 2019R1A2B5B01070129), the Center
   for Women in Science, Engineering and Technology (WISET) Grant funded by
   the Ministry of Science ICT and Future Planning of Korea (MSIP) under
   the Program for Returners into R&D (WISET-2020-203), and by the Hallym
   University Research Fund (HURF-2017-79).
CR Alain C, 2007, CEREB CORTEX, V17, P1074, DOI 10.1093/cercor/bhl018
   Albouy P, 2020, SCIENCE, V367, P1043, DOI 10.1126/science.aaz3468
   ALHO K, 1995, EAR HEARING, V16, P38, DOI 10.1097/00003446-199502000-00004
   Atienza M, 2002, LEARN MEMORY, V9, P138, DOI 10.1101/lm.46502
   Bell A, 2013, BEHAV ECOL, V24, P16, DOI 10.1093/beheco/ars148
   Bermudez P, 2009, CEREB CORTEX, V19, P1583, DOI 10.1093/cercor/bhn196
   Bidelman GM, 2018, HEARING RES, V367, P149, DOI 10.1016/j.heares.2018.05.018
   Bidelman GM, 2014, EUR J NEUROSCI, V40, P2662, DOI 10.1111/ejn.12627
   Boebinger D, 2015, J ACOUST SOC AM, V137, P378, DOI 10.1121/1.4904537
   Choi I, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00988
   Coffey EBJ, 2017, HEARING RES, V352, P49, DOI 10.1016/j.heares.2017.02.006
   Deguchi C, 2012, BRAIN RES, V1455, P75, DOI 10.1016/j.brainres.2012.03.034
   Dimitrijevic A, 2008, CLIN NEUROPHYSIOL, V119, P2111, DOI 10.1016/j.clinph.2008.06.002
   Dimitrijevic A, 2009, CLIN NEUROPHYSIOL, V120, P374, DOI 10.1016/j.clinph.2008.11.009
   Dochtermann NA, 2010, BEHAV ECOL, V21, P437, DOI 10.1093/beheco/arq021
   Drayna D, 2001, SCIENCE, V291, P1969, DOI 10.1126/science.291.5510.1969
   Fu QJ, 1998, J ACOUST SOC AM, V104, P3586, DOI 10.1121/1.423941
   Gaser C, 2003, J NEUROSCI, V23, P9240
   Gaudrain E, 2007, HEARING RES, V231, P32, DOI 10.1016/j.heares.2007.05.001
   Geiser E, 2009, CORTEX, V45, P93, DOI 10.1016/j.cortex.2007.09.010
   Gibson C, 2009, BRAIN COGNITION, V69, P162, DOI 10.1016/j.bandc.2008.07.009
   Gregersen PK, 1999, AM J HUM GENET, V65, P911, DOI 10.1086/302541
   Gregersen PK, 2001, AM J MED GENET, V98, P280, DOI 10.1002/1096-8628(20010122)98:3<280::AID-AJMG1083>3.0.CO;2-6
   Han JH, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00038
   Han JH, 2016, CLIN NEUROPHYSIOL, V127, P1603, DOI 10.1016/j.clinph.2015.10.049
   Hutka S, 2015, NEUROPSYCHOLOGIA, V71, P52, DOI 10.1016/j.neuropsychologia.2015.03.019
   Hyde KL, 2009, J NEUROSCI, V29, P3019, DOI 10.1523/JNEUROSCI.5118-08.2009
   Intartaglia B, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12575-1
   Johnsrude IS, 2000, BRAIN, V123, P155, DOI 10.1093/brain/123.1.155
   Jones SJ, 2001, CLIN NEUROPHYSIOL, V112, P965, DOI 10.1016/S1388-2457(01)00515-6
   Kliuchko M, 2015, NOISE HEALTH, V17, P350, DOI 10.4103/1463-1741.165065
   Koelsch S, 1999, NEUROREPORT, V10, P1309, DOI 10.1097/00001756-199904260-00029
   Kokoska S., 2000, CRC STANDARD PROBABI, P200
   Krizman J, 2017, BILING-LANG COGN, V20, P834, DOI 10.1017/S1366728916000444
   LAVIKAINEN J, 1995, EVOKED POTENTIAL, V96, P93, DOI 10.1016/0013-4694(94)00283-Q
   Liang C, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00464
   Logue DM, 2009, BEHAV ECOL, V20, P781, DOI 10.1093/beheco/arp061
   Madsen SMK, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46728-1
   Mankel K, 2018, P NATL ACAD SCI USA, V115, P13129, DOI 10.1073/pnas.1811793115
   Marques C, 2007, J COGNITIVE NEUROSCI, V19, P1453, DOI 10.1162/jocn.2007.19.9.1453
   Martin BA, 2000, J ACOUST SOC AM, V107, P2155, DOI 10.1121/1.428556
   Micheyl C, 2006, HEARING RES, V219, P36, DOI 10.1016/j.heares.2006.05.004
   Moore BCJ, 2008, JARO-J ASSOC RES OTO, V9, P399, DOI 10.1007/s10162-008-0143-x
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   NAATANEN R, 1993, PSYCHOPHYSIOLOGY, V30, P436, DOI 10.1111/j.1469-8986.1993.tb02067.x
   Nan Y, 2018, P NATL ACAD SCI USA, V115, pE6630, DOI 10.1073/pnas.1808412115
   Novitski N, 2004, COGNITIVE BRAIN RES, V20, P26, DOI 10.1016/j.cogbrainres.2003.12.011
   Oikkonen J, 2015, MOL PSYCHIATR, V20, P275, DOI 10.1038/mp.2014.8
   Okada BM, 2018, MEM COGNITION, V46, P1076, DOI 10.3758/s13421-018-0822-8
   Okamoto H, 2015, SCI REP-UK, V5, DOI 10.1038/srep18143
   Oxenham AJ, 2012, J NEUROSCI, V32, P13335, DOI 10.1523/JNEUROSCI.3815-12.2012
   Pantev C, 1998, AUDIOL NEURO-OTOL, V3, P183, DOI 10.1159/000013789
   Pantev C, 2001, NEUROREPORT, V12, P169, DOI 10.1097/00001756-200101220-00041
   Pantev C, 2011, NEUROSCI BIOBEHAV R, V35, P2140, DOI 10.1016/j.neubiorev.2011.06.010
   Parbery-Clark A, 2012, FRONT AGING NEUROSCI, V4, DOI 10.3389/fnagi.2012.00030
   Parbery-Clark A, 2011, EUR J NEUROSCI, V33, P549, DOI 10.1111/j.1460-9568.2010.07546.x
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Parbery-Clark A, 2009, J NEUROSCI, V29, P14100, DOI 10.1523/JNEUROSCI.3256-09.2009
   Peretz I, 2007, AM J HUM GENET, V81, P582, DOI 10.1086/521337
   Peretz I, 2015, PHILOS T R SOC B, V370, P68, DOI 10.1098/rstb.2014.0090
   Picton TW, 2011, HUMAN AUDITORY EVOKE
   Pratt H, 2009, CLIN NEUROPHYSIOL, V120, P360, DOI 10.1016/j.clinph.2008.10.158
   Pulli K, 2008, J MED GENET, V45, P451, DOI 10.1136/jmg.2007.056366
   ROSE JE, 1967, J NEUROPHYSIOL, V30, P769
   Ruggles DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086980
   Sankaran N, 2020, J NEUROSCI, V40, P2108, DOI 10.1523/JNEUROSCI.1399-19.2020
   Schellenberg EG, 2019, P NATL ACAD SCI USA, V116, P2783, DOI 10.1073/pnas.1821109116
   Schellenberg EG, 2015, ANN NY ACAD SCI, V1337, P170, DOI 10.1111/nyas.12627
   Schneider P, 2005, NAT NEUROSCI, V8, P1241, DOI 10.1038/nn1530
   Schneider P, 2002, NAT NEUROSCI, V5, P688, DOI 10.1038/nn871
   Seppanen M, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00043
   Shahin A, 2003, J NEUROSCI, V23, P5545
   Shahin A, 2004, NEUROREPORT, V15, P1917, DOI 10.1097/00001756-200408260-00017
   Shahin AJ, 2008, NEUROIMAGE, V41, P113, DOI 10.1016/j.neuroimage.2008.01.067
   Shahin AJ, 2007, CLIN NEUROPHYSIOL, V118, P209, DOI 10.1016/j.clinph.2006.09.019
   Stangor C., 2014, INTRO PSYCHOL, P709
   Strait DL, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00113
   Swaminathan S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27571-2
   Tervaniemi M, 2005, EXP BRAIN RES, V161, P1, DOI 10.1007/s00221-004-2044-5
   Theusch E, 2011, TWIN RES HUM GENET, V14, P173, DOI 10.1375/twin.14.2.173
   Theusch E, 2009, AM J HUM GENET, V85, P112, DOI 10.1016/j.ajhg.2009.06.010
   Tong YX, 2009, BRAIN RES, V1297, P80, DOI 10.1016/j.brainres.2009.07.089
   Tremblay K, 2001, EAR HEARING, V22, P79, DOI 10.1097/00003446-200104000-00001
   Tremblay Kelly L., 2007, Seminars in Hearing, V28, P120, DOI 10.1055/s-2007-973438
   Tremblay KL, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00028
   Tremblay KL, 2009, CLIN NEUROPHYSIOL, V120, P128, DOI 10.1016/j.clinph.2008.10.005
   Ukkola LT, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0005534
   Ukkola-Vuoti L, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0056356
   Vonck BMD, 2019, JARO-J ASSOC RES OTO, V20, P489, DOI 10.1007/s10162-019-00726-2
   Wagner M, 2013, BRAIN RES, V1522, P31, DOI 10.1016/j.brainres.2013.04.045
   Wisniewski MG, 2020, NEUROSCI LETT, V721, DOI 10.1016/j.neulet.2020.134781
   Won JH, 2007, JARO-J ASSOC RES OTO, V8, P384, DOI 10.1007/s10162-007-0085-8
   Won JH, 2011, JARO-J ASSOC RES OTO, V12, P375, DOI 10.1007/s10162-011-0257-4
   Yoo J, 2019, HEARING RES, V377, P189, DOI 10.1016/j.heares.2019.03.021
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
   Zatorre RJ, 2007, NAT REV NEUROSCI, V8, P547, DOI 10.1038/nrn2152
   Zendel BR, 2015, J COGNITIVE NEUROSCI, V27, P1044, DOI 10.1162/jocn_a_00758
   Zuk J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080546
NR 98
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD AUG 21
PY 2020
VL 14
AR 329
DI 10.3389/fnhum.2020.00329
PG 13
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA NO9ZA
UT WOS:000569842800001
PM 32973478
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Jiang, BE
   Clayards, M
   Sonderegger, M
AF Jiang, Bing'er
   Clayards, Meghan
   Sonderegger, Morgan
TI Individual and dialect differences in perceiving multiple cues: A tonal
   register contrast in two Chinese Wu dialects
SO LABORATORY PHONOLOGY
LA English
DT Article
DE Speech perception; cue weighting; individual variability; voice quality;
   Chinese Wu dialects
ID ATTENTIONAL MODULATION; PERCEPTION; CATEGORIZATION; VOICE; INFORMATION;
   PHONATION; BREATHY; F0
AB This study investigates how multiple cues contribute to multi-dimensional phonological contrasts at both the group level and the individual level, and how dialectal experience shapes listeners' perceptual strategies. We examine a tonal register contrast in two Chinese Wu dialects signaled by three cues: pitch height, voice quality, and pitch contour. We found that 1) at the group level, cue weights are context-specific, i.e., vary by tone, and some contrasts rely more heavily on multiple cues than others; 2) dialectal experience affects listeners' perceptual strategy: Shanghai listeners, with their own dialect having a smaller voice quality distinction, do not rely more on the cue even when listening to stimuli with a clear breathy-modal distinction, comparing to liashan listeners; 3) individuals' cue weights are correlated in a positive manner, meaning that some listeners show overall larger cue weights than others; larger variability is found when the contrast has more than one salient cue, in which case individuals have different options of choosing one cue over another as the primary cue and this can work against the positive correlation.
C1 [Jiang, Bing'er; Clayards, Meghan; Sonderegger, Morgan] McGill Univ, Linguist Dept, Montreal, PQ, Canada.
RP Jiang, BE (corresponding author), McGill Univ, Linguist Dept, Montreal, PQ, Canada.
EM binger.jiang@mail.mcgill.ca
FU SSHRCSocial Sciences and Humanities Research Council of Canada (SSHRC)
   [435-2017-0925, 430-2014-00018, 435-2016-0747]
FX We thank audiences at the 172nd meeting of the ASA, the 2017
   Montreal-Ottawa-Toronto Phonology Workshop, CLA 2017, and LabPhon 2018,
   as well as Jessamyn Schertz and several anonymous reviewers for their
   constructive comments. This work was supported by SSHRC grant
   435-2016-0747 to Meghan Clayards and SSHRC grants 435-2017-0925 and
   430-2014-00018 to Morgan Sonderegger.
CR Abramson A. S., 1985, PHONETIC LINGUISTICS, P25
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Brunelle M., 2011, P ICPHS 17 AUG 17 21, P372
   Brunelle M, 2009, J PHONETICS, V37, P79, DOI 10.1016/j.wocn.2008.09.003
   Bukmaier V, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00828
   CAO JF, 1992, J PHONETICS, V20, P77
   Chao Y. R., 1928, STUDIES MODERN WU DI
   Chao Y. R., 1930, MAITRE PHONETIQUE, V45, P24
   Chen YY, 2015, J INT PHON ASSOC, V45, P321, DOI 10.1017/S0025100315000043
   Chen Z. M., 2010, STUDIES LANGUAGE LIN, V30, P20
   Chen ZM, 2015, J CHINESE LINGUIST, V43, P90, DOI 10.1353/jcl.2015.0004
   Chung YJ, 2013, PSYCHOMETRIKA, V78, P685, DOI 10.1007/s11336-013-9328-2
   Clayards M, 2018, J ACOUST SOC AM, V144, pEL172, DOI 10.1121/1.5052025
   Coetzee AW, 2018, J PHONETICS, V66, P185, DOI 10.1016/j.wocn.2017.09.009
   Francis AL, 2008, J ACOUST SOC AM, V124, P1234, DOI 10.1121/1.2945161
   Gao J.-Y., 2016, PAPERS HIST PHONOLOG, V1, P166, DOI DOI 10.2218/PIHPH.1.2016.1698
   Gao J.-Y., 2011, P 17 INT C PHON SCI, P719
   Gao JY, 2020, LANG SPEECH, V63, P582, DOI 10.1177/0023830919873080
   Garellek M, 2013, J ACOUST SOC AM, V133, P1078, DOI 10.1121/1.4773259
   Garellek M, 2011, J INT PHON ASSOC, V41, P185, DOI 10.1017/S0025100311000193
   GORDON PC, 1993, COGNITIVE PSYCHOL, V25, P1, DOI 10.1006/cogp.1993.1001
   HAZAN V, 1991, PERCEPT PSYCHOPHYS, V49, P187, DOI 10.3758/BF03205038
   Hollien H, 1974, J PHONETICS, V2, P125
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Honorof DN, 2005, J ACOUST SOC AM, V117, P2193, DOI 10.1121/1.1841751
   Jiang Bao-Chun, 2016, Transl Perioper Pain Med, V1, P1
   Jolliffe I., 2011, PRINCIPAL COMPONENT
   Jongman A, 2016, J ACOUST SOC AM, V140, P3225, DOI DOI 10.1121/1.4970184
   Kapnoula EC, 2017, J EXP PSYCHOL HUMAN, V43, P1594, DOI 10.1037/xhp0000410
   Kawahara H, 2008, INT CONF ACOUST SPEE, P3933, DOI 10.1109/ICASSP.2008.4518514
   Kim D, 2019, LANG COGN NEUROSCI, V34, P769, DOI 10.1080/23273798.2019.1582787
   Kingston R, 2011, PUBLIC PASSION: RETHINKING THE GROUNDS FOR POLITICAL JUSTICE, P1
   Kirby JP, 2014, J PHONETICS, V43, P69, DOI 10.1016/j.wocn.2014.02.001
   Kong EJ, 2018, LANG SPEECH, V61, P384, DOI 10.1177/0023830917729840
   Kong EJ, 2016, J PHONETICS, V59, P40, DOI 10.1016/j.wocn.2016.08.006
   Kuang J., 2016, P SPEECH PROS 2016 B, P1061, DOI [10.21437/SpeechProsody.2016-218, DOI 10.21437/SPEECHPROSODY.2016-218]
   Kuang J., 2011, THESIS
   Kuang JJ, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P354
   Kuang JJ, 2013, PHONETICA, V70, P1, DOI 10.1159/000353853
   Lenth R, 2017, UNDERST STAT, V34, P216
   LISKER L, 1978, LANG SPEECH, V21, P375, DOI 10.1177/002383097802100413
   Mayo C, 2005, J ACOUST SOC AM, V118, P1730, DOI 10.1121/1.1979451
   Mayo C, 2004, J ACOUST SOC AM, V115, P3184, DOI 10.1121/1.1738838
   McAuliffe M, 2016, J ACOUST SOC AM, V140, P1727, DOI 10.1121/1.4962529
   Nicenboim B, 2016, LANG LINGUIST COMPAS, V10, P591, DOI 10.1111/lnc3.12207
   ODEN GC, 1978, PSYCHOL REV, V85, P172, DOI 10.1037/0033-295X.85.3.172
   Qian N. R., 1992, STUDIES CONT WU
   Raphael LJ, 2005, BLACKW HBK LINGUIST, P182, DOI 10.1002/9780470757024.ch8
   Ren N., 1992, THESIS
   Sadakata M, 2011, ACTA PSYCHOL, V138, P1, DOI 10.1016/j.actpsy.2011.03.007
   Schertz J, 2020, WIRES COGN SCI, V11, DOI 10.1002/wcs.1521
   Shultz AA, 2012, J ACOUST SOC AM, V132, pEL95, DOI 10.1121/1.4736711
   Vasishth S, 2018, J PHONETICS, V71, P147, DOI 10.1016/j.wocn.2018.07.008
   Wayland R, 2003, J PHONETICS, V31, P181, DOI 10.1016/S0095-4470(02)00086-4
   WHALEN DH, 1993, J ACOUST SOC AM, V93, P2152, DOI 10.1121/1.406678
   Xu B., 1988, DESCRIPTION URBAN SH
   Yip M.J., 1980, THESIS
   Yip Moira, 2002, TONE, DOI [10.1017/CBO9781139164559, DOI 10.1017/CBO9781139164559]
   Yonezawa T., 2005, P 2005 C NEW INT MUS, P121
   Yu ACL, 2019, ANNU REV LINGUIST, V5, P131, DOI 10.1146/annurev-linguistics-011516-033815
   Yu G., 1988, DIALECT, V3, P195
   Yu K. M., 2011, P ICPHS, P2240
   Zhang J., 2015, P 18 INT C PHON SCI
NR 64
TC 0
Z9 0
U1 0
U2 0
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD AUG 21
PY 2020
VL 11
IS 1
AR 11
DI 10.5334/labphon.266
PG 30
WC Linguistics; Language & Linguistics
SC Linguistics
GA NE2HK
UT WOS:000562418100001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Drouin, JR
   Theodore, RM
AF Drouin, Julia R.
   Theodore, Rachel M.
TI Leveraging interdisciplinary perspectives to optimize auditory training
   for cochlear implant users
SO LANGUAGE AND LINGUISTICS COMPASS
LA English
DT Article
ID INDIVIDUAL TALKER DIFFERENCES; SPOKEN WORD RECOGNITION; SPEECH
   RECOGNITION; FORMANT TRANSITIONS; PERCEPTION; ADULTS; CHILDREN; HEARING;
   NOISE; PERFORMANCE
AB This review examines the role of auditory training on speech adaptation for cochlear implant users. A current limitation of the existing evidence base is the failure to adequately account for wide variability in speech perception outcomes following implantation. While many preimplantation factors contribute to the variance observed in outcomes, formal auditory training has been proposed as a way to maximize speech comprehension benefits for cochlear implant users. We adopt an interdisciplinary perspective and focus on integrating the clinical rehabilitation literature with basic research examining perceptual learning of speech. We review findings on the role of auditory training for improving perception of degraded speech signals in normal hearing listeners, with emphasis on how lexically oriented training paradigms may facilitate speech comprehension when the acoustic input is diminished. We conclude with recommendations for future research that could foster translation of principles of speech learning in normal hearing listeners to aural rehabilitation protocols for cochlear implant patients.
C1 [Drouin, Julia R.; Theodore, Rachel M.] Univ Connecticut, Dept Speech Language & Hearing Sci, 2 Alethia Dr,U-1085, Storrs, CT 06269 USA.
   [Drouin, Julia R.; Theodore, Rachel M.] Univ Connecticut, Connecticut Inst Brain & Cognit Sci, 337 Mansfield Rd,Unit 1872, Storrs, CT 06269 USA.
RP Drouin, JR (corresponding author), Univ Connecticut, Dept Speech Language & Hearing Sci, 2 Alethia Dr,U-1085, Storrs, CT 06269 USA.; Drouin, JR (corresponding author), Univ Connecticut, Connecticut Inst Brain & Cognit Sci, 337 Mansfield Rd,Unit 1872, Storrs, CT 06269 USA.
EM julia.drouin@uconn.edu
OI Drouin, Julia/0000-0003-0798-3268
FU Division of Graduate EducationNational Science Foundation (NSF)NSF-
   Directorate for Education & Human Resources (EHR) [1144399]; National
   Institute on Deafness and Other Communication DisordersUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R21DC016141]
FX Division of Graduate Education, Grant/Award Number: 1144399; National
   Institute on Deafness and Other Communication Disorders, Grant/Award
   Number: R21DC016141
CR Allen JS, 2003, J ACOUST SOC AM, V113, P544, DOI 10.1121/1.1528172
   Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Baskent D, 2010, HEARING RES, V260, P54, DOI 10.1016/j.heares.2009.11.007
   Battmer R D, 1995, Ann Otol Rhinol Laryngol Suppl, V166, P185
   BUSBY P A, 1991, British Journal of Audiology, V25, P291, DOI 10.3109/03005369109076601
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   COLE RA, 1975, J ACOUST SOC AM, V58, P1280, DOI 10.1121/1.380810
   Conway CM, 2014, J SPEECH LANG HEAR R, V57, P2174, DOI 10.1044/2014_JSLHR-L-13-0236
   CRAIK FIM, 1972, J VERB LEARN VERB BE, V11, P671, DOI 10.1016/S0022-5371(72)80001-X
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   DAWSON PW, 1992, J SPEECH HEAR RES, V35, P401, DOI 10.1044/jshr.3502.401
   Dawson PW, 1997, EAR HEARING, V18, P488, DOI 10.1097/00003446-199712000-00007
   DEFILIPPO CL, 1978, J ACOUST SOC AM, V63, P1186, DOI 10.1121/1.381827
   DELATTRE PC, 1955, J ACOUST SOC AM, V27, P769, DOI 10.1121/1.1908024
   Dorman MF, 1997, J ACOUST SOC AM, V102, P2993, DOI 10.1121/1.420354
   Drouin JR, 2018, J ACOUST SOC AM, V144, P1089, DOI 10.1121/1.5047672
   Drouin JR, 2016, J ACOUST SOC AM, V140, pEL307, DOI 10.1121/1.4964468
   Farris-Trimble A, 2014, J EXP PSYCHOL HUMAN, V40, P308, DOI 10.1037/a0034353
   Faulkner A, 2000, J ACOUST SOC AM, V108, P1877, DOI 10.1121/1.1310667
   Finley CC, 2008, OTOL NEUROTOL, V29, P920, DOI 10.1097/MAO.0b013e318184f492
   Franks JJ, 2000, MEM COGNITION, V28, P1140, DOI 10.3758/BF03211815
   Friedland DR, 2003, OTOL NEUROTOL, V24, P582, DOI 10.1097/00129492-200307000-00009
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538
   Fu Qian-Jie, 2007, Trends Amplif, V11, P193, DOI 10.1177/1084713807301379
   Fu QJ, 2008, HEARING RES, V242, P198, DOI 10.1016/j.heares.2007.11.010
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P180, DOI 10.1007/s10162-005-5061-6
   Fu QJ, 2005, ACOUST RES LETT ONL, V6, P106, DOI 10.1121/1.1898345
   Fu QJ, 2002, J ACOUST SOC AM, V112, P1664, DOI 10.1121/1.1502901
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   GANTZ BJ, 1988, LARYNGOSCOPE, V98, P1100
   Goldstone RL, 1998, ANNU REV PSYCHOL, V49, P585, DOI 10.1146/annurev.psych.49.1.585
   GREENSPAN SL, 1988, J EXP PSYCHOL LEARN, V14, P421, DOI 10.1037/0278-7393.14.3.421
   Hedrick MS, 1997, J SPEECH LANG HEAR R, V40, P1445, DOI 10.1044/jslhr.4006.1445
   Helms J, 2004, ORL-J OTO-RHIN-LARYN, V66, P130, DOI 10.1159/000079332
   Hervais-Adelman A, 2008, J EXP PSYCHOL HUMAN, V34, P460, DOI 10.1037/0096-1523.34.2.460
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hu Y, 2008, J ACOUST SOC AM, V124, P498, DOI 10.1121/1.2924131
   Huyck JJ, 2017, J SPEECH LANG HEAR R, V60, P3334, DOI 10.1044/2017_JSLHR-H-16-0300
   Iverson P, 2006, J ACOUST SOC AM, V120, P3998, DOI 10.1121/1.2372453
   Jusczyk P.W., 2000, DISCOVERY SPOKEN LAN
   Kessler D. K., 1995, Annals of Otology Rhinology and Laryngology, V104, P283
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Levitt H, 1986, J Rehabil Res Dev, V23, P147
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LICKLIDER JCR, 1948, J ACOUST SOC AM, V20, P42, DOI 10.1121/1.1906346
   Loebach JL, 2008, J ACOUST SOC AM, V124, P552, DOI 10.1121/1.2931948
   Loebach JL, 2009, EAR HEARING, V30, P662, DOI 10.1097/AUD.0b013e3181b9c92d
   Loizou PC, 1998, IEEE SIGNAL PROC MAG, V15, P101, DOI 10.1109/79.708543
   Loizou PC, 1999, J ACOUST SOC AM, V106, P2097, DOI 10.1121/1.427954
   Loizou Philipos C, 2006, Adv Otorhinolaryngol, V64, P109, DOI 10.1159/000094648
   McClelland JL, 2006, TRENDS COGN SCI, V10, P363, DOI 10.1016/j.tics.2006.06.007
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2017, COGNITION, V169, P147, DOI 10.1016/j.cognition.2017.08.013
   MILLER JL, 1994, COGNITION, V50, P271, DOI 10.1016/0010-0277(94)90031-0
   Moberly AC, 2016, OTOL NEUROTOL, V37, P1522, DOI 10.1097/MAO.0000000000001211
   Moberly AC, 2014, J SPEECH LANG HEAR R, V57, P566, DOI 10.1044/2014_JSLHR-H-12-0323
   Most T, 2010, AM J OTOLARYNG, V31, P418, DOI 10.1016/j.amjoto.2009.07.002
   Neel AT, 2008, J SPEECH LANG HEAR R, V51, P574, DOI 10.1044/1092-4388(2008/041)
   Nelson PB, 2003, J ACOUST SOC AM, V113, P961, DOI 10.1121/1.1531983
   Newman RS, 2001, J ACOUST SOC AM, V109, P1181, DOI 10.1121/1.1348009
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Nittrouer S., 2016, PEDIAT COCHLEAR IMPL, P177, DOI [10.1007/978-1-4939-2788-3_11, 10.1121/1.4919316, DOI 10.1007/978-1-4939-2788-3_11]
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Parkin J. L., 1990, J OTOLARYNGOL-HEAD N, V101, P314
   Pelizzone N, 1999, EAR HEARING, V20, P228, DOI 10.1097/00003446-199906000-00005
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Pisoni David B, 2017, World J Otorhinolaryngol Head Neck Surg, V3, P240, DOI 10.1016/j.wjorl.2017.12.010
   Pisoni DB, 1999, VOLTA REV, V101, P111
   Prendergast S. G., 2002, HEARING J, V55, P30
   Rayes H, 2019, J SPEECH LANG HEAR R, V62, P1574, DOI 10.1044/2019_JSLHR-H-18-0252
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   Schramm D, 2002, OTOL NEUROTOL, V23, P698, DOI 10.1097/00129492-200209000-00016
   SCHWAB EC, 1985, HUM FACTORS, V27, P395
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sharma A, 2007, INT J AUDIOL, V46, P494, DOI 10.1080/14992020701524836
   SHEA JJ, 1990, LARYNGOSCOPE, V100, P223
   Skinner MW, 2002, EAR HEARING, V23, P207, DOI 10.1097/00003446-200206000-00005
   SPIVAK LG, 1990, J SPEECH HEAR RES, V33, P511, DOI 10.1044/jshr.3303.511
   STEVENS KN, 1974, J ACOUST SOC AM, V55, P653, DOI 10.1121/1.1914578
   STEVENS KN, 1978, J ACOUST SOC AM, V64, P1358, DOI 10.1121/1.382102
   Sweetow Robert, 2005, J Am Acad Audiol, V16, P494, DOI 10.3766/jaaa.16.7.9
   Sweetow Robert W, 2007, Trends Amplif, V11, P101, DOI 10.1177/1084713807301321
   Theodore RM, 2009, J ACOUST SOC AM, V125, P3974, DOI 10.1121/1.3106131
   TONG YC, 1988, J ACOUST SOC AM, V84, P951, DOI 10.1121/1.396664
   TYEMURRAY N, 1988, J SPEECH HEAR DISORD, V53, P226, DOI 10.1044/jshd.5303.226
   van Dijk JE, 1999, AUDIOLOGY, V38, P109
   Van Son R. J. V., 1997, P EUR 97 RHOD, P2135
   WALLEY AC, 1983, J ACOUST SOC AM, V73, P1011, DOI 10.1121/1.389149
   WALTZMAN SB, 1986, LARYNGOSCOPE, V96, P1083
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Wu JL, 2007, AUDIOL NEURO-OTOL, V12, P307, DOI 10.1159/000103211
NR 92
TC 0
Z9 0
U1 2
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1749-818X
J9 LANG LINGUIST COMPAS
JI Lang. Linguist. Compass
PD SEP
PY 2020
VL 14
IS 9
AR e12394
DI 10.1111/lnc3.12394
EA AUG 2020
PG 18
WC Language & Linguistics
SC Linguistics
GA NV9NA
UT WOS:000560191100001
DA 2021-02-24
ER

PT J
AU Mushtaq, F
   Wiggins, IM
   Kitterick, PT
   Anderson, CA
   Hartley, DEH
AF Mushtaq, Faizah
   Wiggins, Ian M.
   Kitterick, Padraig T.
   Anderson, Carly A.
   Hartley, Douglas E. H.
TI The Benefit of Cross-Modal Reorganization on Speech Perception in
   Pediatric Cochlear Implant Recipients Revealed Using Functional
   Near-Infrared Spectroscopy
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE cochlear implantation; neuroimaging; cross-modal plasticity; temporal
   cortex; auditory processing; visual speech; hearing loss; language
ID CONGENITALLY DEAF CATS; AUDITORY-CORTEX; CORTICAL ACTIVATION;
   AUDIOVISUAL INTERACTIONS; PLASTICITY; HEARING; CHILDREN; DEPRIVATION;
   LANGUAGE; RECOGNITION
AB Cochlear implants (CIs) are the most successful treatment for severe-to-profound deafness in children. However, speech outcomes with a CI often lag behind those of normally-hearing children. Some authors have attributed these deficits to the takeover of the auditory temporal cortex by vision following deafness, which has prompted some clinicians to discourage the rehabilitation of pediatric CI recipients using visual speech. We studied this cross-modal activity in the temporal cortex, along with responses to auditory speech and non-speech stimuli, in experienced CI users and normally-hearing controls of school-age, using functional near-infrared spectroscopy. Strikingly, CI users displayed significantly greater cortical responses to visual speech, compared with controls. Importantly, in the same regions, the processing of auditory speech, compared with non-speech stimuli, did not significantly differ between the groups. This suggests that visual and auditory speech are processed synergistically in the temporal cortex of children with CIs, and they should be encouraged, rather than discouraged, to use visual speech.
C1 [Mushtaq, Faizah; Wiggins, Ian M.; Kitterick, Padraig T.; Hartley, Douglas E. H.] Nottingham Biomed Res Ctr, Natl Inst Hlth Res, Nottingham, England.
   [Mushtaq, Faizah; Wiggins, Ian M.; Kitterick, Padraig T.; Anderson, Carly A.; Hartley, Douglas E. H.] Univ Nottingham, Sch Med, Div Clin Neurosci, Hearing Sci, Nottingham, England.
   [Hartley, Douglas E. H.] Nottingham Univ Hosp NHS Trust, Nottingham, England.
RP Mushtaq, F (corresponding author), Nottingham Biomed Res Ctr, Natl Inst Hlth Res, Nottingham, England.; Mushtaq, F (corresponding author), Univ Nottingham, Sch Med, Div Clin Neurosci, Hearing Sci, Nottingham, England.
EM faizah.mushtaq1@gmail.com
FU Action on Hearing Loss; Cochlear Europe Limited Ph.D. studentship [S41];
   National Institute for Health Research (NIHR)National Institute for
   Health Research (NIHR)
FX This work was joint funded by an Action on Hearing Loss and Cochlear
   Europe Limited Ph.D. studentship (grant reference: S41, awarded to FM).
   This article presents independent research supported by the National
   Institute for Health Research (NIHR). The funders had no role in study
   design, data collection, and analysis, decision to publish, or
   preparation of the manuscript.
CR Aasted CM, 2015, NEUROPHOTONICS, V2, DOI 10.1117/1.NPh.2.2.020801
   Akeroyd MA, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514560442
   Anderson CA, 2019, JARO-J ASSOC RES OTO, V20, P511, DOI 10.1007/s10162-019-00729-z
   Anderson CA, 2017, P NATL ACAD SCI USA, V114, P10256, DOI 10.1073/pnas.1704785114
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bernstein LE, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00034
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   British Society of Audiology, 2011, REC PROC PUR TON AIR
   Brown EC, 2014, CLIN NEUROPHYSIOL, V125, P1312, DOI 10.1016/j.clinph.2013.11.026
   Buckley KA, 2011, EAR HEARING, V32, P2, DOI [10.1097/AUD.0b013e3181e8534c, 10.1097/AUD.0b013e3181fa41bb]
   Butler BE, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00092
   Calhoun VD, 2004, NEUROIMAGE, V22, P252, DOI 10.1016/j.neuroimage.2003.12.029
   Campbell J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147793
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   Chen LC, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/4382656
   COCHRANE D, 1949, J AM STAT ASSOC, V44, P32, DOI 10.2307/2280349
   Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135
   Dale AM, 1999, HUM BRAIN MAPP, V8, P109, DOI 10.1002/(SICI)1097-0193(1999)8:2/3<109::AID-HBM7>3.0.CO;2-W
   De Ruiter AM, 2015, EAR HEARING, V36, P557, DOI 10.1097/AUD.0000000000000162
   Deshpande AK, 2016, EAR HEARING, V37, pE263, DOI 10.1097/AUD.0000000000000259
   Dewey RS, 2015, HEARING RES, V325, P55, DOI 10.1016/j.heares.2015.03.007
   Dimitrijevic A, 2016, EAR HEARING, V37, pE322, DOI 10.1097/AUD.0000000000000324
   Finney EM, 2001, NAT NEUROSCI, V4, P1171, DOI 10.1038/nn763
   Flowers KA, 2013, NEUROPSYCHOLOGY, V27, P256, DOI 10.1037/a0031664
   Friston KJ, 1998, NEUROIMAGE, V7, P30, DOI 10.1006/nimg.1997.0306
   Gordon KA, 2011, BRAIN TOPOGR, V24, P204, DOI 10.1007/s10548-011-0181-2
   Green KMJ, 2005, HEARING RES, V205, P184, DOI 10.1016/j.heares.2005.03.016
   Hall DA, 2005, J COGNITIVE NEUROSCI, V17, P939, DOI 10.1162/0898929054021175
   Hall JW, 2012, EAR HEARING, V33, P340, DOI 10.1097/AUD.0b013e31823fa4c3
   Han JH, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00124
   Harrison S., 2019, REP MED IMAG, V12, P31, DOI DOI 10.2147/rmi.s174633
   Holt RF, 2008, EAR HEARING, V29, P492, DOI 10.1097/AUD.0b013e31816c409f
   Huppert TJ, 2009, APPL OPTICS, V48, pD280, DOI 10.1364/AO.48.00D280
   Isaiah A, 2014, J NEUROSCI, V34, P11119, DOI 10.1523/JNEUROSCI.4767-13.2014
   Jasper H.H., 1958, ELECTROENCEPHALOGR C, V10, P367
   Kleiner M, 2007, PERCEPTION, V36, P14
   Klinke R, 2008, SPRACHE-STIMME-GEHOR, V32, P6, DOI 10.1055/s-2007-993137
   Klinke R, 2001, AUDIOL NEURO-OTOL, V6, P203, DOI 10.1159/000046833
   Kotak VC, 2005, J NEUROSCI, V25, P3908, DOI 10.1523/JNEUROSCI.5169-04.2005
   Kral A, 2000, CEREB CORTEX, V10, P714, DOI 10.1093/cercor/10.7.714
   Kral A, 2005, CEREB CORTEX, V15, P552, DOI 10.1093/cercor/bhh156
   Kral A, 2013, NEUROSCIENCE, V247, P117, DOI 10.1016/j.neuroscience.2013.05.021
   Kral A, 2009, HNO, V57, P9, DOI 10.1007/s00106-008-1877-9
   Kral A, 2002, CEREB CORTEX, V12, P797, DOI 10.1093/cercor/12.8.797
   Kral A, 2007, BRAIN RES REV, V56, P259, DOI 10.1016/j.brainresrev.2007.07.021
   Kral Andrej, 2006, Adv Otorhinolaryngol, V64, P89, DOI 10.1159/000094647
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   Land R, 2016, J NEUROSCI, V36, P6175, DOI 10.1523/JNEUROSCI.0046-16.2016
   Lawrence RJ, 2018, HEARING RES, V370, P53, DOI 10.1016/j.heares.2018.09.005
   Lee DS, 2001, NATURE, V409, P149, DOI 10.1038/35051653
   Lee HJ, 2007, CEREB CORTEX, V17, P909, DOI 10.1093/cercor/bhl001
   Li XR, 2010, BEHAV RES METHODS, V42, P212, DOI 10.3758/BRM.42.1.212
   Lindquist MA, 2007, HUM BRAIN MAPP, V28, P764, DOI 10.1002/hbm.20310
   Lindquist MA, 2009, NEUROIMAGE, V45, pS187, DOI 10.1016/j.neuroimage.2008.10.065
   Lyness CR, 2013, NEUROSCI BIOBEHAV R, V37, P2621, DOI 10.1016/j.neubiorev.2013.08.011
   McCrimmon A. W., 2012, J PSYCHOEDUCATIONAL, V31, P337, DOI DOI 10.1177/0734282912467756
   Molavi B, 2012, PHYSIOL MEAS, V33, P259, DOI 10.1088/0967-3334/33/2/259
   Murphy J, 2011, INT J PEDIATR OTORHI, V75, P489, DOI 10.1016/j.ijporl.2011.01.002
   Mushtaq F, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219927
   Naito Y, 2000, HEARING RES, V143, P139, DOI 10.1016/S0378-5955(00)00035-6
   Oba SI, 2011, EAR HEARING, V32, P573, DOI 10.1097/AUD.0b013e31820fc821
   Olds C, 2016, EAR HEARING, V37, pE160, DOI 10.1097/AUD.0000000000000258
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Plichta MM, 2007, NEUROIMAGE, V35, P625, DOI 10.1016/j.neuroimage.2006.11.028
   Pollonini L, 2014, HEARING RES, V309, P84, DOI 10.1016/j.heares.2013.11.007
   Porter HL, 2018, J SPEECH LANG HEAR R, V61, P1807, DOI 10.1044/2018_JSLHR-H-17-0403
   Purves D., 2004, NEUROSCIENCE
   Quaresima V, 2012, BRAIN LANG, V121, P79, DOI 10.1016/j.bandl.2011.03.009
   Quartz SR, 1997, BEHAV BRAIN SCI, V20, P537
   Robbins AM, 2004, ARCH OTOLARYNGOL, V130, P570
   ROSEN S, 1989, J SPEECH HEAR RES, V32, P93, DOI 10.1044/jshr.3201.93
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Rouger J, 2007, P NATL ACAD SCI USA, V104, P7295, DOI 10.1073/pnas.0609419104
   Saliba J, 2016, HEARING RES, V338, P64, DOI 10.1016/j.heares.2016.02.005
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   Scholkmann F, 2014, NEUROIMAGE, V85, P6, DOI 10.1016/j.neuroimage.2013.05.004
   Schroeter ML, 2004, NEUROIMAGE, V21, P283, DOI 10.1016/j.neuroimage.2003.09.054
   Schwartz JL, 2004, COGNITION, V93, pB69, DOI 10.1016/j.cognition.2004.01.006
   Sevy ABG, 2010, HEARING RES, V270, P39, DOI 10.1016/j.heares.2010.09.010
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sharma A, 2007, INT J AUDIOL, V46, P494, DOI 10.1080/14992020701524836
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   Shepherd RK, 1997, ACTA OTO-LARYNGOL, P28
   Steffener J, 2010, NEUROIMAGE, V49, P2113, DOI 10.1016/j.neuroimage.2009.11.014
   Stone MA, 2011, J ACOUST SOC AM, V130, P2874, DOI 10.1121/1.3641371
   Stoppelman N, 2013, BRAIN BEHAV, V3, P211, DOI 10.1002/brb3.129
   Strelnikov K, 2015, EUR J NEUROSCI, V41, P677, DOI 10.1111/ejn.12827
   Strelnikov K, 2009, SCAND J PSYCHOL, V50, P437, DOI 10.1111/j.1467-9450.2009.00741.x
   Strelnikov K, 2013, BRAIN, V136, P3682, DOI 10.1093/brain/awt274
   Svirsky MA, 2004, AUDIOL NEURO-OTOL, V9, P224, DOI 10.1159/000078392
   Tajudeen BA, 2010, OTOL NEUROTOL, V31, P1254, DOI 10.1097/MAO.0b013e3181f2f475
   TYLER RS, 1988, ARCH OTOLARYNGOL, V114, P1123
   Wechsler D., 2011, WECHSLER ABBREVIATED
   Wiggins IM, 2016, HEARING RES, V339, P142, DOI 10.1016/j.heares.2016.07.007
   Wijayasiri P, 2017, HEARING RES, V351, P55, DOI 10.1016/j.heares.2017.05.010
   Woodhouse L, 2009, INT J LANG COMM DIS, V44, P253, DOI 10.1080/13682820802090281
   Yamada T, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0050271
   Zhou X, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518786850
NR 99
TC 1
Z9 1
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD AUG 14
PY 2020
VL 14
AR 308
DI 10.3389/fnhum.2020.00308
PG 18
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA NJ7DL
UT WOS:000566203700001
PM 32922273
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Bakhtiar, M
   Shao, J
   Cheung, MN
   Zhang, CC
AF Bakhtiar, Mehdi
   Shao, Jing
   Cheung, Man Na
   Zhang, Caicai
TI Categorical perception of speech sounds in adults who stutter
SO CLINICAL LINGUISTICS & PHONETICS
LA English
DT Article; Early Access
DE stuttering; speech perception; categorical perception; identification;
   discrimination
ID CHILDREN; TONES; DISCRIMINATION
AB Stuttering is often attributed to the impaired speech production system, however, there is growing evidence implicating issues in speech perception. Our previous research showed that children who stutter have similar patterns but slower categorical perception (i.e. the ability to categorise different acoustic variations of the speech sounds into the same or different phonemic categories) compared to the children who do not stutter. This study aimed to extend our previous research to adults who stutter (AWS) using the same categorical perception paradigm. Fifteen AWS and 15 adults who do not stutter (A WNS) were recruited to complete identification and discrimination tasks involving acoustic variations of Cantonese speech sounds in four stimulus contexts: consonants (varying in voice onset times, VOTs), lexical tones, vowels and pure tones. The results showed similar categorical perception between the two groups in terms of the boundary position and width in the identification task and between-category benefits in the discrimination task. However, there were some trends for lower discrimination accuracy (overall d' scores) and slower discrimination of the between-category stimuli versus within-category stimuli for AWS than AWNS. These results partially confirm our previous finding on children in terms of a comparable pattern of categorical perception between the two groups, but slower processing speed to access the phoneme representations in speech perception among AWS than AWNS.
C1 [Bakhtiar, Mehdi; Cheung, Man Na; Zhang, Caicai] Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Hong Kong, Peoples R China.
   [Shao, Jing] Hong Kong Baptist Univ, Fac Arts, Dept English Language & Literature, Hong Kong, Peoples R China.
RP Bakhtiar, M (corresponding author), Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Hong Kong, Peoples R China.
EM m.bakhtiar@polyu.edu.hk
RI Zhang, Caicai/Q-6914-2018
OI Zhang, Caicai/0000-0002-7687-0518; Bakhtiar, Mehdi/0000-0001-6088-3106;
   SHAO, Jing/0000-0002-2500-2366
FU Departmental General Research Fund; Hong Kong Polytechnic UniversityHong
   Kong Polytechnic University [P0014009]
FX This project was supported by the Departmental General Research Fund
   granted to the first author from the Hong Kong Polytechnic University
   [project ID number: P0014009].
CR Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Bakhtiar M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216124
   Bakhtiar Mehdi, 2007, Indian J Med Sci, V61, P462
   Basu S, 2018, J FLUENCY DISORD, V57, P11, DOI 10.1016/j.jfludis.2018.07.001
   Bloodstein O., 1995, HDB STUTTERING
   Boersma P., 2014, MESQUITE MODULAR SYS, V5, P84
   Chen F, 2017, J CHILD LANG, V44, P1413, DOI 10.1017/S0305000916000581
   Civier O, 2010, J FLUENCY DISORD, V35, P246, DOI 10.1016/j.jfludis.2010.05.002
   Corbera S, 2005, NEUROLOGY, V65, P1246, DOI 10.1212/01.wnl.0000180969.03719.81
   Etchell AC, 2018, J FLUENCY DISORD, V55, P6, DOI 10.1016/j.jfludis.2017.03.007
   Hakim HB, 2004, J FLUENCY DISORD, V29, P179, DOI 10.1016/j.jfludis.2004.06.001
   Halag-Milo T, 2016, NEUROIMAGE-CLIN, V11, P328, DOI 10.1016/j.nicl.2016.02.017
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Jansson-Verkasalo E, 2014, J FLUENCY DISORD, V41, P1, DOI 10.1016/j.jfludis.2014.07.001
   Kaganovich N, 2010, DEV NEUROPSYCHOL, V35, P712, DOI 10.1080/87565641.2010.508549
   Levelt W. J., 1993, SPEAKING INTENTION A
   Liu HM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095587
   Max L, 2004, CONT ISSUES COMMUN S, V31, P105, DOI [10.1044/cicsd_31_S_105., DOI 10.1044/CICSD_31_S_105]
   Neef NE, 2012, J SPEECH LANG HEAR R, V55, P276, DOI 10.1044/1092-4388(2011/10-0224)
   Olander L, 2010, J SPEECH LANG HEAR R, V53, P876, DOI 10.1044/1092-4388(2009/09-0007)
   REICH A, 1981, J SPEECH HEAR RES, V24, P192, DOI 10.1044/jshr.2402.192
   Riley G. D., 1994, STUTTERING SEVERITY
   Sasisekaran J, 2006, J FLUENCY DISORD, V31, P1, DOI 10.1016/j.jfludis.2005.11.005
   Sasisekaran J, 2006, J FLUENCY DISORD, V31, P284, DOI 10.1016/j.jfludis.2006.08.001
   Sasisekaran J, 2013, INT J LANG COMM DIS, V48, P625, DOI 10.1111/1460-6984.12035
   WEBSTER WG, 1989, BRAIN LANG, V36, P286, DOI 10.1016/0093-934X(89)90066-7
   Zhang CC, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0183151
NR 28
TC 0
Z9 0
U1 0
U2 0
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0269-9206
EI 1464-5076
J9 CLIN LINGUIST PHONET
JI Clin. Linguist. Phon.
DI 10.1080/02699206.2020.1803407
EA AUG 2020
PG 17
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA NA3HE
UT WOS:000559703300001
PM 32787467
DA 2021-02-24
ER

PT J
AU Mertes, IB
   Johnson, KM
AF Mertes, Ian B.
   Johnson, Kristin M.
TI Lack of association between contralateral inhibition of otoacoustic
   emissions and vowel formant discrimination in noise
SO HEARING BALANCE AND COMMUNICATION
LA English
DT Article
DE Olivocochlear; MOC; contralateral suppression; formant discrimination
ID OLIVOCOCHLEAR REFLEX; SPEECH-PERCEPTION; NORMAL-HEARING; RECOGNITION;
   SUPPRESSION; EFFERENTS; INDIVIDUALS; HUMANS
AB Purpose The medial olivocochlear (MOC) reflex enhances neural encoding of signals in noise, and measurement of its function may hold clinical utility. Previous research on how the reflex aids speech-in-noise perception has been equivocal. Motivated by animal work, we examined associations between MOC reflex activity and formant discrimination in noise in humans to better understand how the MOC reflex contributes to audition. We hypothesised that participants with stronger MOC reflex activity would have better formant discrimination in noise abilities. Method Twenty-six normal-hearing listeners met all inclusion and exclusion criteria (mean age = 21.5 years), with data from 25 participants included in the final analysis. Transient-evoked otoacoustic emissions (TEOAEs) were measured in right ears. MOC reflex activity was assessed using a contralateral inhibition paradigm in which the change in TEOAE amplitude without versus with a contralateral MOC reflex elicitor was computed. Formant discrimination thresholds for a synthetic vowel /e/ were obtained in right ears using a two-alternative forced-choice procedure that adaptively varied the second formant frequency. Discrimination thresholds were obtained at three signal-to-noise ratios (SNRs). Results TEOAE amplitudes were significantly reduced in the presence of the reflex elicitor (p < .05). Discrimination thresholds decreased significantly with increasing SNR (p < .05 in all cases). No significant correlations were found between contralateral inhibition measures and discrimination thresholds at any SNR (p > .05 in all cases). Conclusion Contrary to hypothesis, no significant associations were found between contralateral inhibition and formant discrimination in noise performance. It is possible that the MOC reflex contributes to formant discrimination but not in a monotonic fashion. Future work should consider investigating how the MOC reflex contributes to other perceptual properties to better characterise the functional relevance of the MOC reflex.
C1 [Mertes, Ian B.; Johnson, Kristin M.] Univ Illinois, Dept Speech & Hearing Sci, Champaign, IL 61820 USA.
RP Mertes, IB (corresponding author), Univ Illinois, Dept Speech & Hearing Sci, Champaign, IL 61820 USA.
EM imertes@illinois.edu
OI Johnson, Kristin/0000-0002-0702-828X; Mertes, Ian/0000-0002-8754-2122
FU Office of the Vice Chancellor for Research at the University of Illinois
   at Urbana-Champaign
FX This work was supported by the Office of the Vice Chancellor for
   Research at the University of Illinois at Urbana-Champaign under an
   Arnold O. Beckman award.
CR Backus BC, 2007, JARO-J ASSOC RES OTO, V8, P484, DOI 10.1007/s10162-007-0100-0
   Cole RA, 1996, INT CONF ACOUST SPEE, P853, DOI 10.1109/ICASSP.1996.543255
   COLLET L, 1990, HEARING RES, V43, P251, DOI 10.1016/0378-5955(90)90232-E
   de Boer J, 2008, J NEUROSCI, V28, P4929, DOI 10.1523/JNEUROSCI.0902-08.2008
   Giraud AL, 1997, NEUROREPORT, V8, P1779, DOI 10.1097/00001756-199705060-00042
   Goodman SS, 2017, ARLAS AUDITORY RES L
   Hienz RD, 1998, HEARING RES, V116, P10, DOI 10.1016/S0378-5955(97)00197-4
   Hillenbrand JM, 2000, J ACOUST SOC AM, V108, P3013, DOI 10.1121/1.1323463
   Hood Linda J, 2003, J Am Acad Audiol, V14, P302
   Kalaiah MK, 2017, HEARING BALANC COMMU, V15, P84, DOI 10.1080/21695717.2017.1311504
   KAWASE T, 1993, J NEUROPHYSIOL, V70, P2533
   KEMP DT, 1978, J ACOUST SOC AM, V64, P1386, DOI 10.1121/1.382104
   Kewley-Port D, 2001, J ACOUST SOC AM, V110, P2141, DOI 10.1121/1.1400737
   Khalfa S, 1998, EUR J NEUROSCI, V10, P2731, DOI 10.1046/j.1460-9568.1998.00286.x
   KLATT DH, 1980, J ACOUST SOC AM, V67, P971, DOI 10.1121/1.383940
   Kumar UA, 2004, EAR HEARING, V25, P142, DOI 10.1097/01.AUD.0000120363.56591.E6
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Liu C, 2004, J ACOUST SOC AM, V116, P3119, DOI 10.1121/1.1802671
   Liu C., 2012, J ACOUST SOC AM, V132, pEL250
   Lopez-Poveda EA, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00197
   Mertes IB, 2020, INT J AUDIOL, V59, P140, DOI 10.1080/14992027.2019.1673491
   Mertes IB, 2020, J ACOUST SOC AM, V147, pEL235, DOI 10.1121/10.0000886
   Mertes IB, 2019, J ACOUST SOC AM, V145, P1529, DOI 10.1121/1.5094766
   Mertes IB, 2018, HEARING RES, V365, P100, DOI 10.1016/j.heares.2018.05.007
   Mishra SK, 2016, J ACOUST SOC AM, V140, P1060, DOI 10.1121/1.4960550
   Morlet T, 2019, INT J AUDIOL, V58, P213, DOI 10.1080/14992027.2018.1551632
   Murdin L, 2008, AUDIOL MED, V6, P238, DOI DOI 10.1080/16513860802499957
   Prabhu P, 2017, HEARING BALANC COMMU, V15, P72, DOI 10.1080/21695717.2017.1311503
   PRIEVE BA, 1993, J ACOUST SOC AM, V93, P3308, DOI 10.1121/1.405715
   Ralli M, 2017, HEARING BALANC COMMU, V15, P260, DOI 10.1080/21695717.2017.1380968
   Stuart A, 2012, J AM ACAD AUDIOL, V23, P686, DOI 10.3766/jaaa.23.9.3
   Tokgoz-Yilmaz S, 2013, AURIS NASUS LARYNX, V40, P521, DOI 10.1016/j.anl.2013.04.003
   VANTASELL DJ, 1987, J ACOUST SOC AM, V81, P1586, DOI 10.1121/1.394511
   Vinay, 2008, HEARING RES, V240, P93, DOI 10.1016/j.heares.2008.03.002
   Wagner W, 2008, ACTA OTO-LARYNGOL, V128, P53, DOI 10.1080/00016480701361954
   Yashaswini L, 2019, AM J AUDIOL, V28, P508, DOI 10.1044/2019_AJA-IND50-18-0098
NR 36
TC 0
Z9 0
U1 0
U2 0
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2169-5717
EI 2169-5725
J9 HEARING BALANC COMMU
JI Hearing Balanc. Commun.
PD OCT 1
PY 2020
VL 18
IS 4
SI SI
BP 250
EP 255
DI 10.1080/21695717.2020.1807257
EA AUG 2020
PG 6
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA PG6GV
UT WOS:000562870500001
DA 2021-02-24
ER

PT J
AU Hahn, LE
   Benders, T
   Snijders, TM
   Fikkert, P
AF Hahn, Laura E.
   Benders, Titia
   Snijders, Tineke M.
   Fikkert, Paula
TI Six-month-old infants recognize phrases in song and speech
SO INFANCY
LA English
DT Article
DE prosody; song; phrase; head-turn preference paradigm
ID PROSODY; LANGUAGE; PERCEPTION; SEGMENTATION; MOTHERS; MELODY; MUSIC;
   PITCH; SENSITIVITY; SEQUENCES
AB Infants exploit acoustic boundaries to perceptually organize phrases in speech. This prosodic parsing ability is well-attested and is a cornerstone to the development of speech perception and grammar. However, infants also receive linguistic input in child songs. This study provides evidence that infants parse songs into meaningful phrasal units and replicates previous research for speech. Six-month-old Dutch infants (n = 80) were tested in the song or speech modality in the head-turn preference procedure. First, infants were familiarized to two versions of the same word sequence: One version represented a well-formed unit, and the other contained a phrase boundary halfway through. At test, infants were presented two passages, each containing one version of the familiarized sequence. The results for speech replicated the previously observed preference for the passage containing the well-formed sequence, but only in a more fine-grained analysis. The preference for well-formed phrases was also observed in the song modality, indicating that infants recognize phrase structure in song. There were acoustic differences between stimuli of the current and previous studies, suggesting that infants are flexible in their processing of boundary cues while also providing a possible explanation for differences in effect sizes.
C1 [Hahn, Laura E.; Fikkert, Paula] Radboud Univ Nijmegen, Ctr Language Studies, Postbus 9103, NL-6500 HD Nijmegen, Netherlands.
   [Hahn, Laura E.] Int Max Planck Res Sch Language Sci, Nijmegen, Netherlands.
   [Benders, Titia] Macquarie Univ, Dept Linguist, Sydney, NSW, Australia.
   [Snijders, Tineke M.] Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
   [Snijders, Tineke M.] Radboud Univ Nijmegen, Ctr Cognit Neuroimaging, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
RP Hahn, LE (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies, Postbus 9103, NL-6500 HD Nijmegen, Netherlands.
EM l.hahn@let.ru.nl
OI Hahn, Laura/0000-0002-3559-5687; Benders, Titia/0000-0003-0143-2182;
   Fikkert, Paula/0000-0001-7317-2100
CR Baayen RH, 1995, CELEX LEXICAL DATABA
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bergelson E, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12715
   Bergeson TR, 2002, PSYCHOL SCI, V13, P72, DOI 10.1111/1467-9280.00413
   Boersma P., 2014, PRAAT DOING PHONETIC
   Brentari D, 2011, LANG SPEECH, V54, P49, DOI 10.1177/0023830910388011
   Carvalho A. D, 2018, DEV PROSODY 1 LANGUA, P17, DOI DOI 10.1075/TILAR.23.02CAR
   Cirelli L. K, 2019, J COGNITIVE NEUROSCI, V24, P1275, DOI [10.1162/jocn, DOI 10.1162/JOCN]
   Cirelli LK, 2018, ANN NY ACAD SCI, V1423, P66, DOI 10.1111/nyas.13580
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Conway CM, 2009, CURR DIR PSYCHOL SCI, V18, P275, DOI 10.1111/j.1467-8721.2009.01651.x
   Corbeil M, 2016, INFANCY, V21, P373, DOI 10.1111/infa.12114
   Corbeil M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00372
   Costa-Giomi E, 2014, MUSIC PERCEPT, V32, P160, DOI 10.1525/MP.2014.32.2.160
   Cristia A, 2013, LANG LINGUIST COMPAS, V7, P157, DOI 10.1111/lnc3.12015
   Csibra G, 2016, DEV PSYCHOL, V52, P521, DOI 10.1037/dev0000083
   Custodero LA, 2003, J APPL DEV PSYCHOL, V24, P553, DOI 10.1016/j.appdev.2003.08.005
   Custodero LA, 2008, EARLY CHILD DEV CARE, V178, P15, DOI 10.1080/03004430600601115
   De Carvalho A, 2017, COGNITION, V163, P67, DOI 10.1016/j.cognition.2017.02.018
   de Diego-Balaguer R, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00044
   Delavenne A, 2013, INFANT BEHAV DEV, V36, P1, DOI 10.1016/j.infbeh.2012.10.004
   DEUTSCH D, 1981, PSYCHOL REV, V88, P503, DOI 10.1037/0033-295X.88.6.503
   Drake C, 2000, COGNITION, V77, P251, DOI 10.1016/S0010-0277(00)00106-2
   Endress AD, 2010, COGNITIVE PSYCHOL, V61, P177, DOI 10.1016/j.cogpsych.2010.05.001
   Falk S, 2017, COGNITION, V163, P80, DOI 10.1016/j.cognition.2017.02.017
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Francois C, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12798-2
   Frazier L, 2006, TRENDS COGN SCI, V10, P244, DOI 10.1016/j.tics.2006.04.002
   Golinkoff RM, 2015, CURR DIR PSYCHOL SCI, V24, P339, DOI 10.1177/0963721415595345
   Gordon RL, 2015, ANN NY ACAD SCI, V1337, P16, DOI 10.1111/nyas.12683
   Hahn LE, 2018, INFANT BEHAV DEV, V52, P130, DOI 10.1016/j.infbeh.2018.07.002
   Hawthorne Kara E., 2013, Journal of the Acoustical Society of America, V134, DOI 10.1121/1.4831067
   Hawthorne K, 2015, J MEM LANG, V82, P105, DOI 10.1016/j.jml.2015.03.005
   Hawthorne K, 2014, COGNITION, V133, P420, DOI 10.1016/j.cognition.2014.07.013
   Hedges L.V., 1985, STAT METHODS METAANA
   Heffner CC, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01962
   Hochmann JR, 2016, LANG LEARN, V66, P13, DOI 10.1111/lang.12202
   Ilari B, 2005, EARLY CHILD DEV CARE, V175, P647, DOI 10.1080/0300443042000302573
   Johnson EK, 2008, INFANCY, V13, P440, DOI 10.1080/15250000802329321
   Johnson EK, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0083546
   Jusczyk P. W, 2003, AM INFANTS PERCEPTIO
   JUSCZYK PW, 1993, J EXP PSYCHOL HUMAN, V19, P627, DOI 10.1037/0096-1523.19.3.627
   JUSCZYK PW, 1992, COGNITIVE PSYCHOL, V24, P252, DOI 10.1016/0010-0285(92)90009-Q
   KRUMHANSL CL, 1990, PSYCHOL SCI, V1, P70, DOI 10.1111/j.1467-9280.1990.tb00070.x
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   Lakens D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00863
   Langus A, 2012, J MEM LANG, V66, P285, DOI 10.1016/j.jml.2011.09.004
   Lebedeva GC, 2010, INFANT BEHAV DEV, V33, P419, DOI 10.1016/j.infbeh.2010.04.006
   Lehrdahl F., 1985, GENERATIVE THEORY TO
   Leong V, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144411
   Longhi E, 2009, PSYCHOL MUSIC, V37, P195, DOI 10.1177/0305735608097042
   MANDEL DR, 1994, COGNITION, V53, P155, DOI 10.1016/0010-0277(94)90069-8
   Mehr SA, 2019, SCIENCE, V366, P970, DOI 10.1126/science.aax0868
   Meints K., 2008, LINCOLN INFANT LAB P, P1
   Merrill J, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00076
   Morgan J., 1996, SIGNAL SYNTAX BOOTST
   Nakata T, 2004, INFANT BEHAV DEV, V27, P455, DOI 10.1016/j.infbeh.2004.03.002
   Nazzi T, 2000, INFANCY, V1, P123, DOI 10.1207/S15327078IN0101_11
   Nespor M, 2007, STUD GENERAT GRAMM, V28, P1
   Politimou N, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00948
   R Development Core Team, 2012, R LANG ENV STAT COMP
   Richards S, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9020033
   Schon D, 2010, NEUROIMAGE, V51, P450, DOI 10.1016/j.neuroimage.2010.02.023
   Seidl A, 2008, DEVELOPMENTAL SCI, V11, P596, DOI 10.1111/j.1467-7687.2008.00704.x
   Seidl A, 2007, J MEM LANG, V57, P24, DOI 10.1016/j.jml.2006.10.004
   Seidl A, 2006, DEVELOPMENTAL SCI, V9, P565, DOI 10.1111/j.1467-7687.2006.00534.x
   ShattuckHufnagel S, 1996, J PSYCHOLINGUIST RES, V25, P193, DOI 10.1007/BF01708572
   Shenfield T., 2003, PSYCHOL MUSIC, V31, P365, DOI DOI 10.1177/03057356030314002
   Shukla M, 2011, P NATL ACAD SCI USA, V108, P6038, DOI 10.1073/pnas.1017617108
   Snijders TM, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10010039
   Soderstrom M, 2005, INFANT BEHAV DEV, V28, P87, DOI 10.1016/j.infbeh.2004.07.001
   Soderstrom M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080646
   Suppanen E, 2019, INFANT BEHAV DEV, V57, DOI 10.1016/j.infbeh.2019.101346
   Thiessen ED, 2009, ANN NY ACAD SCI, V1169, P225, DOI 10.1111/j.1749-6632.2009.04547.x
   Trainor LJ, 1997, INFANT BEHAV DEV, V20, P383, DOI 10.1016/S0163-6383(97)90009-6
   Trainor LJ, 2000, PERCEPT PSYCHOPHYS, V62, P333, DOI 10.3758/BF03205553
   Trehub S.E., 1998, ADV INFANCY RES, V12, P43
   Trehub SE, 2006, COGNITION, V100, P73, DOI 10.1016/j.cognition.2005.11.006
   Trehub SE, 1997, DEV PSYCHOL, V33, P500, DOI 10.1037/0012-1649.33.3.500
   TREHUB SE, 1993, INFANT BEHAV DEV, V16, P193, DOI 10.1016/0163-6383(93)80017-3
   Tsang CD, 2017, CHILD DEV, V88, P1207, DOI 10.1111/cdev.12647
   Volkova A, 2006, DEVELOPMENTAL SCI, V9, P583, DOI 10.1111/j.1467-7687.2006.00536.x
   Wagner M, 2010, LANG COGNITIVE PROC, V25, P905, DOI 10.1080/01690961003589492
   Wellmann C, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00580
   Zink I., 2002, N CDIS LIJSTEN COMMU
NR 85
TC 0
Z9 0
U1 3
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1525-0008
EI 1532-7078
J9 INFANCY
JI Infancy
PD SEP
PY 2020
VL 25
IS 5
BP 699
EP 718
DI 10.1111/infa.12357
EA AUG 2020
PG 20
WC Psychology, Developmental
SC Psychology
GA NF2FM
UT WOS:000558975500001
PM 32794372
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Jasmin, K
   Dick, F
   Stewart, L
   Tierney, AT
AF Jasmin, Kyle
   Dick, Frederic
   Stewart, Lauren
   Tierney, Adam Taylor
TI Altered functional connectivity during speech perception in congenital
   amusia
SO ELIFE
LA English
DT Article
ID TONE-DEAFNESS; LEXICAL STRESS; PITCH; BRAIN; DISCRIMINATION; NETWORKS;
   MEMORY; STIMULATION; DISORDER; LANGUAGE
AB Individuals with congenital amusia have a lifelong history of unreliable pitch processing. Accordingly, they downweight pitch cues during speech perception and instead rely on other dimensions such as duration. We investigated the neural basis for this strategy. During fMRI, individuals with amusia (N = 15) and controls (N = 15) read sentences where a comma indicated a grammatical phrase boundary. They then heard two sentences spoken that differed only in pitch and/or duration cues and selected the best match for the written sentence. Prominent reductions in functional connectivity were detected in the amusia group between left prefrontal language-related regions and right hemisphere pitch-related regions, which reflected the between-group differences in cue weights in the same groups of listeners. Connectivity differences between these regions were not present during a control task. Our results indicate that the reliability of perceptual dimensions is linked with functional connectivity between frontal and perceptual regions and suggest a compensatory mechanism.
C1 [Jasmin, Kyle; Dick, Frederic; Tierney, Adam Taylor] Birkbeck Univ London, Dept Psychol Sci, London, England.
   [Jasmin, Kyle] UCL, UCL Inst Cognit Neurosci, London, England.
   [Dick, Frederic] UCL, Dept Expt Psychol, London, England.
   [Stewart, Lauren] Goldsmiths Univ London, Dept Psychol, London, England.
RP Jasmin, K (corresponding author), Birkbeck Univ London, Dept Psychol Sci, London, England.; Jasmin, K (corresponding author), UCL, UCL Inst Cognit Neurosci, London, England.
EM kyle.jasmin.11@ucl.ac.uk
OI Dick, Frederic/0000-0002-2933-3912
FU Wellcome [109719/15/Z]; Leverhulme TrustLeverhulme Trust [ECF-2017-151];
   Society for Education, Music and Psychology Research
FX Wellcome 109719/15/Z Adam Taylor Tierneyr Leverhulme Trust ECF-2017-151
   Kyle Jasminr Society for Education, Music and Psychology Research Kyle
   Jasminr The funders had no role in study design, data collection and
   interpretation, or the decision to submit the work for publication.
CR Albouy P, 2019, HUM BRAIN MAPP, V40, P855, DOI 10.1002/hbm.24416
   Albouy P, 2013, BRAIN, V136, P1639, DOI 10.1093/brain/awt082
   Beauchamp MS, 2010, FRONT SYST NEUROSCI, V4, DOI 10.3389/fnsys.2010.00025
   Berman RA, 2016, BRAIN, V139, P276, DOI 10.1093/brain/awv306
   Chen G, 2013, NEUROIMAGE, V73, P176, DOI 10.1016/j.neuroimage.2013.01.047
   Chen JL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00009
   Church JA, 2010, HUM BRAIN MAPP, V31, P852, DOI 10.1002/hbm.21036
   Cisler JM, 2014, NEUROIMAGE, V84, P1042, DOI 10.1016/j.neuroimage.2013.09.018
   Cole MW, 2010, NEUROIMAGE, V49, P3132, DOI 10.1016/j.neuroimage.2009.11.001
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   DEPIJPER JR, 1994, J ACOUST SOC AM, V96, P2037, DOI 10.1121/1.410145
   Fischl B, 2012, NEUROIMAGE, V62, P774, DOI 10.1016/j.neuroimage.2012.01.021
   FRICK RW, 1985, PSYCHOL BULL, V97, P412, DOI 10.1037/0033-2909.97.3.412
   Garcea FE, 2017, CURR BIOL, V27, P2684, DOI 10.1016/j.cub.2017.07.051
   Gotts SJ, 2012, BRAIN, V135, P2711, DOI 10.1093/brain/aws160
   Goulet GM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036860
   Hall DA, 1999, HUM BRAIN MAPP, V7, P213, DOI 10.1002/(SICI)1097-0193(1999)7:3<213::AID-HBM5>3.0.CO;2-N
   Hohmann A, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00009
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   Hutchins S, 2012, BRAIN LANG, V123, P234, DOI 10.1016/j.bandl.2012.09.011
   Hyde KL, 2006, BRAIN, V129, P2562, DOI 10.1093/brain/awl204
   Hyde KL, 2011, CEREB CORTEX, V21, P292, DOI 10.1093/cercor/bhq094
   Jasmin K, 2020, WELLCOME OPEN RES, V5, P4, DOI [10.12688/wellcomeopenres.15607.1, DOI 10.12688/WELLCOMEOPENRES.15607.1]
   Jasmin K, 2020, J EXP PSYCHOL GEN, V149, P914, DOI 10.1037/xge0000688
   Jasmin K, 2019, BRAIN, V142, P808, DOI 10.1093/brain/awz003
   Kawahara H, 2005, SPEECH SEPARATION BY HUMANS AND MACHINES, P167, DOI 10.1007/0-387-22794-6_11
   Lee YS, 2011, NEUROIMAGE, V57, P293, DOI 10.1016/j.neuroimage.2011.02.006
   Leveque Y, 2016, J NEUROPHYSIOL, V116, P88, DOI 10.1152/jn.00663.2015
   Liu F, 2015, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.01029
   Liu F, 2015, NEUROPSYCHOLOGIA, V66, P111, DOI 10.1016/j.neuropsychologia.2014.11.001
   Liu F, 2010, BRAIN, V133, P1682, DOI 10.1093/brain/awq089
   Lolli SL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01340
   Loui P, 2009, J NEUROSCI, V29, P10215, DOI 10.1523/JNEUROSCI.1701-09.2009
   Meoded A, 2015, NEUROIMAGE-CLIN, V7, P288, DOI 10.1016/j.nicl.2014.12.009
   Moreau P, 2013, BRAIN COGNITION, V81, P337, DOI 10.1016/j.bandc.2013.01.004
   Moreau P, 2009, ANN NY ACAD SCI, V1169, P191, DOI 10.1111/j.1749-6632.2009.04775.x
   Nath AR, 2011, J NEUROSCI, V31, P1704, DOI 10.1523/JNEUROSCI.4853-10.2011
   Norman-Haignere SV, 2016, J NEUROSCI, V36, P2986, DOI 10.1523/JNEUROSCI.2705-15.2016
   Patel AD, 2008, MUSIC PERCEPT, V25, P357, DOI 10.1525/MP.2008.25.4.357
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Peretz I, 2003, ANN NY ACAD SCI, V999, P58, DOI 10.1196/annals.1284.006
   Peretz I, 2002, NEURON, V33, P185, DOI 10.1016/S0896-6273(01)00580-3
   Peretz I, 2016, TRENDS COGN SCI, V20, P857, DOI 10.1016/j.tics.2016.09.002
   Peretz I, 2009, BRAIN, V132, P1277, DOI 10.1093/brain/awp055
   Power JD, 2012, NEUROIMAGE, V59, P2142, DOI 10.1016/j.neuroimage.2011.10.018
   Pralus A, 2019, NEUROPSYCHOLOGIA, V134, DOI [10.1016/j.neuropsychologia.2010.107234, 10.1016/j.neuropsychologia.2019.107234]
   Qin Z, 2017, APPL PSYCHOLINGUIST, V38, P541, DOI 10.1017/S0142716416000321
   Rissman J, 2004, NEUROIMAGE, V23, P752, DOI 10.1016/j.neuroimage.2004.06.035
   Rohe T, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0315-17.2018
   Song SB, 2015, J COGNITIVE NEUROSCI, V27, P1503, DOI 10.1162/jocn_a_00796
   Steel A, 2016, CORTEX, V74, P134, DOI 10.1016/j.cortex.2015.10.004
   Stoddard J, 2016, PSYCHOL MED, V46, P1509, DOI 10.1017/S0033291716000143
   STREETER LA, 1978, J ACOUST SOC AM, V64, P1582, DOI 10.1121/1.382142
   Tillmann B, 2016, BRAIN RES, V1640, P251, DOI 10.1016/j.brainres.2015.10.035
   Tillmann B, 2009, BRAIN COGNITION, V71, P259, DOI 10.1016/j.bandc.2009.08.003
   Warren JD, 2003, P NATL ACAD SCI USA, V100, P10038, DOI 10.1073/pnas.1730682100
   Watsky RE, 2018, SCHIZOPHR RES, V197, P219, DOI 10.1016/j.schres.2018.01.003
   Whiteford KL, 2018, CORTEX, V103, P164, DOI 10.1016/j.cortex.2018.03.012
   Williamson VJ, 2010, ADV COGN PSYCHOL, V6, P15, DOI 10.2478/v10053-008-0073-5
   Winter B, 2014, BIOESSAYS, V36, P960, DOI 10.1002/bies.201400028
   Yu VY, 2010, J PSYCHOLINGUIST RES, V39, P323, DOI 10.1007/s10936-009-9142-2
   Zendel BR, 2015, J NEUROSCI, V35, P3815, DOI 10.1523/JNEUROSCI.3766-14.2015
   Zhang YH, 2008, J ACOUST SOC AM, V123, P4498, DOI 10.1121/1.2902165
   Zhang YH, 2010, J PHONETICS, V38, P260, DOI 10.1016/j.wocn.2009.11.002
NR 64
TC 1
Z9 1
U1 1
U2 1
PU ELIFE SCIENCES PUBLICATIONS LTD
PI CAMBRIDGE
PA SHERATON HOUSE, CASTLE PARK, CAMBRIDGE, CB3 0AX, ENGLAND
SN 2050-084X
J9 ELIFE
JI eLife
PD AUG 7
PY 2020
VL 9
AR e53539
DI 10.7554/eLife.53539
PG 19
WC Biology
SC Life Sciences & Biomedicine - Other Topics
GA NG2BW
UT WOS:000563791400001
PM 32762842
OA DOAJ Gold, Green Accepted, Green Published
DA 2021-02-24
ER

PT J
AU Allison, TS
   Moritz, J
   Turk, P
   Stone-Roy, LM
AF Allison, Tyler S.
   Moritz, Joel, Jr.
   Turk, Philip
   Stone-Roy, Leslie M.
TI Lingual electrotactile discrimination ability is associated with the
   presence of specific connective tissue structures (papillae) on the
   tongue surface
SO PLOS ONE
LA English
DT Article
ID SENSORY-SUBSTITUTION DEVICES; FUNGIFORM PAPILLAE; 2-POINT
   DISCRIMINATION; NERVE-ENDINGS; MECHANORECEPTIVE AFFERENTS; VISION
   SUBSTITUTION; SPEECH-PERCEPTION; ORAL SENSATION; STIMULUS ARRAY; TASTE
AB Electrical stimulation of nerve endings in the tongue can be used to communicate information to users and has been shown to be highly effective in sensory substitution applications. The anterior tip of the tongue has very small somatosensory receptive fields, comparable to those of the finger tips, allowing for precise two-point discrimination and high tactile sensitivity. However, perception of electrotactile stimuli varies significantly between users, and across the tongue surface. Despite this, previous studies all used uniform electrode grids to stimulate a region of the dorsal-medial tongue surface. In an effort to customize electrode layouts for individual users, and thus improve efficacy for sensory substitution applications, we investigated whether specific neuroanatomical and physiological features of the tongue are associated with enhanced ability to perceive active electrodes. Specifically, the study described here was designed to test whether fungiform papillae density and/or propylthiouracil sensitivity are positively or negatively associated with perceived intensity and/or discrimination ability for lingual electrotactile stimuli. Fungiform papillae number and distribution were determined for 15 participants and they were exposed to patterns of electrotactile stimulation (ETS) and asked to report perceived intensity and perceived number of stimuli. Fungiform papillae number and distribution were then compared to ETS characteristics using comprehensive and rigorous statistical analyses. Our results indicate that fungiform papillae density is correlated with enhanced discrimination ability for electrical stimuli. In contrast, papillae density, on average, is not correlated with perceived intensity of active electrodes. However, results for at least one participant suggest that further research is warranted. Our data indicate that propylthiouracil taster status is not related to ETS perceived intensity or discrimination ability. These data indicate that individuals with higher fungiform papillae number and density in the anterior medial tongue region may be better able to use lingual ETS for sensory substitution.
C1 [Allison, Tyler S.; Stone-Roy, Leslie M.] Colorado State Univ, Dept Biomed Sci, Ft Collins, CO 80523 USA.
   [Moritz, Joel, Jr.] Colorado State Univ, Dept Mech Engn, Ft Collins, CO 80523 USA.
   [Moritz, Joel, Jr.] Sapien LLC, Ft Collins, CO USA.
   [Turk, Philip] Colorado State Univ, Dept Stat, Ft Collins, CO 80523 USA.
   [Turk, Philip] Atrium Hlth, Charlotte, NC USA.
RP Stone-Roy, LM (corresponding author), Colorado State Univ, Dept Biomed Sci, Ft Collins, CO 80523 USA.
EM Leslie.Stone-Roy@Colostate.edu
OI Stone-Roy, Leslie/0000-0002-9569-1072
FU College Research Council Award; Experiential Learning Grant (LSR) from
   College of Veterinary Medicine and Biomedical Sciences at CSU; Colorado
   Office of Economic Development and International Trade (OEDIT)
   [APP-152692]; City of Fort Collins; Colorado State University Libraries
   Open Access Research and Scholarship Fund
FX This research was funded in part by the College Research Council Award
   and Experiential Learning Grant (LSR) from College of Veterinary
   Medicine and Biomedical Sciences at CSU. Additionally, this research was
   funded by the Colorado Office of Economic Development and International
   Trade (OEDIT, APP-152692), https://choosecolorado.com/(LSR), as well as
   the City of Fort Collins which provided a match for the OEDIT funding.
   Publishing costs were supported by The Colorado State University
   Libraries Open Access Research and Scholarship Fund. The aforementioned
   funders had no role in study design, data collection and analysis,
   decision to publish, or preparation of the manuscript. Finally, Sapien
   LLC additionally matched the OEDIT funding and provided materials used
   in the study. Sapien LLC had a role in review of the manuscript and
   decision to publish.
CR Arnold G, 2017, MULTISENS RES, V30, P579, DOI 10.1163/22134808-00002561
   ASTBACK J, 1995, REGUL PEPTIDES, V59, P389, DOI 10.1016/0167-0115(95)00107-M
   Auer ET, 2007, NEUROREPORT, V18, P645, DOI 10.1097/WNR.0b013e3280d943b9
   BACH P, 1969, NATURE, V221, P963, DOI 10.1038/221963a0
   Bach-y-Rita P, 1998, J REHABIL RES DEV, V35, P427
   Bach-y-Rita P, 2003, TRENDS COGN SCI, V7, P541, DOI 10.1016/j.tics.2003.10.013
   Bach-y-Rita P, 2005, INTELLECTICA, V40, P115, DOI [10.1016/j.tics.2003.10.013, DOI 10.1016/J.TICS.2003.10.013]
   BACHYRITA P, 1967, ACTA NEUROL SCAND, V43, P417, DOI 10.1111/j.1600-0404.1967.tb05747.x
   Bangcuyo RG, 2017, EXP BRAIN RES, V235, P2679, DOI 10.1007/s00221-017-5003-7
   BARTOSHUK LM, 1994, PHYSIOL BEHAV, V56, P1165, DOI 10.1016/0031-9384(94)90361-1
   Bartoshuk LM, 2004, PHYSIOL BEHAV, V82, P109, DOI 10.1016/j.physbeh.2004.02.033
   Bubic A, 2010, LARGE SCALE BRAIN PL
   Caltenco HA, 2013, DISABIL REHABIL-ASSI, V8, P330, DOI 10.3109/17483107.2012.699991
   Barros CGC, 2010, NEUROSCI LETT, V476, P123, DOI 10.1016/j.neulet.2010.04.012
   Catanzaro D, 2013, APPETITE, V68, P124, DOI 10.1016/j.appet.2013.04.025
   Chebat DR, 2007, NEUROREPORT, V18, P1901, DOI 10.1097/WNR.0b013e3282f2a63
   Cheung SH, 2009, CURR BIOL, V19, P596, DOI 10.1016/j.cub.2009.02.063
   Cholewiak R W, 1986, J Rehabil Res Dev, V23, P20
   Danilov Yuri, 2005, Journal of Integrative Neuroscience, V4, P537, DOI 10.1142/S0219635205000914
   De Volder AG, 2001, NEUROIMAGE, V14, P129, DOI 10.1006/nimg.2001.0782
   Dehmel S, 2008, AM J AUDIOL, V17, pS193, DOI 10.1044/1059-0889(2008/07-0045)
   Dinehart ME, 2006, PHYSIOL BEHAV, V87, P304, DOI 10.1016/j.physbeh.2005.10.018
   Diot B, 2014, MULTISENS RES, V27, P313, DOI 10.1163/22134808-00002458
   Duffy VB, 2010, CHEMOSENS PERCEPT, V3, P137, DOI 10.1007/s12078-010-9079-8
   Duffy VB, 2004, PHYSIOL BEHAV, V82, P435, DOI 10.1016/j.physbeh.2004.04.060
   Essick GK, 2003, PHYSIOL BEHAV, V80, P289, DOI 10.1016/j.physbeh.2003.08.007
   FARBMAN AI, 1991, J COMP NEUROL, V304, P172, DOI 10.1002/cne.903040203
   Fu KMG, 2003, J NEUROSCI, V23, P7510
   Galvin K L, 1991, J Am Acad Audiol, V2, P214
   Glick H, 2017, HEARING RES, V343, P191, DOI 10.1016/j.heares.2016.08.012
   GREEN BG, 1993, CHEM SENSES, V18, P683, DOI 10.1093/chemse/18.6.683
   Haggard P, 2014, NEUROSCI BIOBEHAV R, V47, P469, DOI 10.1016/j.neubiorev.2014.09.015
   Hagura N, 2013, P ROY SOC B-BIOL SCI, V280, DOI 10.1098/rspb.2013.1680
   HALL MJ, 1975, NATURE, V253, P442, DOI 10.1038/253442a0
   Kaczmarek KA, 2011, SCI IRAN, V18, P1476, DOI 10.1016/j.scient.2011.08.020
   Karns CM, 2017, HEARING RES, V343, P72, DOI 10.1016/j.heares.2016.07.008
   KARRER T, 1991, PHYSIOL BEHAV, V49, P757, DOI 10.1016/0031-9384(91)90315-F
   Kim G, 2004, P ANN INT IEEE EMBS, V26, P4948
   Kim Y, 2015, IEEE T HAPTICS, V8, P298, DOI 10.1109/TOH.2015.2415213
   Kristjansson A, 2016, RESTOR NEUROL NEUROS, V34, P769, DOI 10.3233/RNN-160647
   Kupers R, 2014, NEUROSCI BIOBEHAV R, V41, P36, DOI 10.1016/j.neubiorev.2013.08.001
   LASS NJ, 1972, PERCEPT MOTOR SKILL, V35, P59, DOI 10.2466/pms.1972.35.1.59
   Lynch M P, 1988, J Rehabil Res Dev, V25, P41
   LYNCH MP, 1989, J SPEECH HEAR RES, V32, P331, DOI 10.1044/jshr.3202.331
   LYNCH MP, 1989, J SPEECH HEAR DISORD, V54, P57, DOI 10.1044/jshd.5401.57
   MAEYAMA T, 1989, AM J OTOLARYNG, V10, P342, DOI 10.1016/0196-0709(89)90110-5
   Maidenbaum S, 2014, RESTOR NEUROL NEUROS, V32, P813, DOI 10.3233/RNN-130351
   MILLER IJ, 1986, ANAT REC, V216, P474, DOI 10.1002/ar.1092160404
   MILLER IJ, 1990, PHYSIOL BEHAV, V47, P1213, DOI 10.1016/0031-9384(90)90374-D
   Miller Shawn L, 2002, Penn Dent J (Phila), V102, P6
   Mistretta CM, 2006, ARCH HISTOL CYTOL, V69, P199, DOI 10.1679/aohc.69.199
   Mistretta CM, 2019, INT J MOL SCI, V20, DOI 10.3390/ijms20061341
   Mistretta CM, 2017, ANNU REV PHYSIOL, V79, P335, DOI 10.1146/annurev-physiol-022516-034202
   Moayedi Y, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-28195-2
   Moritz JA, 2017, EVALUATION ELECT TON
   Moritz J, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00186
   Nau AC, 2015, NEURAL REGEN RES, V10, P1717, DOI 10.4103/1673-5374.169612
   Novich SD, 2015, EXP BRAIN RES, V233, P2777, DOI 10.1007/s00221-015-4346-1
   Nuessle TM, 2015, JOVE-J VIS EXP, DOI 10.3791/52860
   OLLER DK, 1980, J SPEECH HEAR RES, V23, P769, DOI 10.1044/jshr.2304.769
   Pagella P, 2014, CELL MOL LIFE SCI, V71, P2241, DOI 10.1007/s00018-013-1549-0
   Prescott J, 2000, CHEM SENSES, V25, P239, DOI 10.1093/chemse/25.3.239
   Reislev NL, 2016, BRAIN STRUCT FUNCT, V221, P2891, DOI 10.1007/s00429-015-1078-8
   Robineau F, 2007, IEEE T BIO-MED ENG, V54, P711, DOI 10.1109/TBME.2006.889180
   Rolls ET, 2008, PROG NEUROBIOL, V86, P216, DOI 10.1016/j.pneurobio.2008.09.001
   Roux FE, 2018, J PHYSIOL-LONDON, V596, P941, DOI 10.1113/JP275243
   Sadato N, 2005, NEUROSCIENTIST, V11, P577, DOI 10.1177/1073858405277314
   Sakamoto KW, 2010, FRONT PHYSIOL, V1, DOI 10.3389/fphys.2010.00136
   Sakamoto K, 2010, NEUROSCI RES, V66, P173, DOI 10.1016/j.neures.2009.10.013
   Shore SE, 2005, EUR J NEUROSCI, V21, P3334, DOI 10.1111/j.1460-9568.2005.04142.x
   SUEMUNE S, 1992, BRAIN RES, V586, P162, DOI 10.1016/0006-8993(92)91389-V
   Trulsson M, 2010, J NEUROPHYSIOL, V103, P1741, DOI 10.1152/jn.01146.2009
   Trulsson M, 1997, J NEUROPHYSIOL, V77, P737
   Tyler Mitchell, 2003, J Integr Neurosci, V2, P159, DOI 10.1142/S0219635203000263
   Tyler ME, 2009, IEEE ENG MED BIO, P559, DOI 10.1109/IEMBS.2009.5334556
   Vuillerme N, 2011, IEEE ENG MED BIO, P1323, DOI 10.1109/IEMBS.2011.6090311
   Vuillerme N, 2007, EXP BRAIN RES, V179, P409, DOI 10.1007/s00221-006-0800-4
   Vuillerme N, 2009, GAIT POSTURE, V30, P556, DOI 10.1016/j.gaitpost.2009.07.124
   Vuillerme N, 2009, PERVASIVE MOB COMPUT, V5, P268, DOI 10.1016/j.pmcj.2008.04.001
   Watanabe IS, 2013, MICROSCOPY-JPN, V62, P259, DOI 10.1093/jmicro/dfs068
   WHITEHEAD MC, 1985, AM J ANAT, V173, P185, DOI 10.1002/aja.1001730304
   Wildenberg JC, 2013, BRAIN CONNECT, V3, P87, DOI 10.1089/brain.2012.0123
   Wilson JA, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/4/045007
   Won SY, 2017, J APPL ORAL SCI, V25, P427, DOI 10.1590/1678-7757-2016-0462
   Wu C, 2015, CELL TISSUE RES, V361, P233, DOI 10.1007/s00441-014-2074-7
   Yamanaka T, 2016, NEUROREPORT, V27, P744, DOI 10.1097/WNR.0000000000000606
NR 86
TC 0
Z9 0
U1 0
U2 0
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD AUG 7
PY 2020
VL 15
IS 8
AR e0237142
DI 10.1371/journal.pone.0237142
PG 24
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA NC2FE
UT WOS:000561029000004
PM 32764778
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Basirat, A
   Schwartz, JL
   Moreau, C
AF Basirat, Anahita
   Schwartz, Jean-Luc
   Moreau, Caroline
TI Word segmentation based on prosody in Parkinson's Disease
SO CLINICAL LINGUISTICS & PHONETICS
LA English
DT Article; Early Access
DE Prosody; Parkinson's Disease; speech perception; word segmentation
ID HYPOKINETIC DYSARTHRIA; SPEECH; PERFORMANCE; IMPAIRMENT; SEQUENCES; MOCA
AB While Parkinson's Disease (PD) impacts the production of prosody and may lead to dysprosody, its effect on the perception of prosody is less clear. In the current study, we investigated how people with PD (PwPD) segment continuous speech using prosodic cues. We used phonemically identical and prosodically different sequences in French. Twenty-three PwPD and 30 controls took part in the study. PwPD showed similar performance to controls (mean difference in terms of correct responses = 2%, 95% confidence interval = [-4%; 8%]). Using Bayesian statistics, our data is 3.6 times more in favour of the null model compared to the alternative model (i.e. difference between PwPD and controls). It thus seems unlikely that PD impacts the perception of prosody systematically. Furthermore, the cognitive performance of PwPD predicted their performance in our segmentation task. This suggests interesting pathways for future research on the mechanisms underlying the impact of PD on speech processing. Clinically, our findings suggest that adequate evaluation of the cognitive capacity of PwPD would help speech and language therapists in assessing speech processing skills in PwPD and in managing their speech impairments.
C1 [Basirat, Anahita] Univ Lille, CNRS, UMR 9193, SCALab Sci Cognit & Sci Affect, Lille, France.
   [Schwartz, Jean-Luc] Univ Grenoble Alpes, CNRS, Grenoble INP, GIPSA Lab, Grenoble, France.
   [Moreau, Caroline] Univ Lille, UMR 1171, INSERM, CHU Lille,Neurol Dept,Expert Ctr Parkinsons Dis, Lille, France.
   [Moreau, Caroline] Univ Lille, INSERM, CHU Lille, U1172,LilNCog Lille Neurosci & Cognit, Lille, France.
RP Basirat, A (corresponding author), Fac Med Pole Format, Dept Orthophonie, F-59045 Lille, France.
EM anahita.basirat@univ-lille.fr
CR Basirat A., 2018, P 9 INT C SPEECH PRO, P809, DOI DOI 10.21437/SPEECHPROSODY.2018-163
   Basirat A, 2017, CLIN LINGUIST PHONET, V31, P478, DOI 10.1080/02699206.2017.1283708
   Dalrymple-Alford JC, 2010, NEUROLOGY, V75, P1717, DOI 10.1212/WNL.0b013e3181fc29c9
   DARKINS AW, 1988, BRAIN LANG, V34, P315, DOI 10.1016/0093-934X(88)90142-3
   Dirnberger G, 2013, J NEUROPSYCHOL, V7, P193, DOI 10.1111/jnp.12028
   Duffy J. R., 2013, MOTOR SPEECH DISORDE
   Grandjean D, 2021, EMOT REV, V13, P34, DOI 10.1177/1754073919898522
   Gray HA, 2010, NEUROPSYCHOLOGY, V24, P176, DOI 10.1037/a0018104
   Hargrove PM, 2013, CLIN LINGUIST PHONET, V27, P647, DOI 10.3109/02699206.2013.777121
   Harms Christopher, 2018, J Clin Transl Res, V3, P382
   Lloyd AJ, 1999, CORTEX, V35, P389, DOI 10.1016/S0010-9452(08)70807-4
   Lowit A, 2018, J COMMUN DISORD, V72, P26, DOI 10.1016/j.jcomdis.2018.02.005
   Ma JKY, 2010, J SPEECH LANG HEAR R, V53, P836, DOI 10.1044/1092-4388(2009/08-0216)
   Martens H, 2016, J PARKINSON DIS, V6, P219, DOI 10.3233/JPD-150678
   Mattys SL, 2011, J MEM LANG, V65, P145, DOI 10.1016/j.jml.2011.04.004
   Miller Nick, 2017, Pract Neurol, V17, P266, DOI 10.1136/practneurol-2017-001635
   Moreau C, 2019, MOVEMENT DISORD, V34, P1471, DOI 10.1002/mds.27791
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Ogane R, 2020, COGNITION, V197, DOI 10.1016/j.cognition.2019.104163
   Pell ID, 1996, CORTEX, V32, P693, DOI 10.1016/S0010-9452(96)80039-6
   Peron J, 2012, MOVEMENT DISORD, V27, P186, DOI 10.1002/mds.24025
   Rektorova I, 2016, PARKINSONISM RELAT D, V29, P90, DOI 10.1016/j.parkreldis.2016.05.018
   SCOTT S, 1984, J NEUROL NEUROSUR PS, V47, P840, DOI 10.1136/jnnp.47.8.840
   Skodda S, 2008, MOVEMENT DISORD, V23, P985, DOI 10.1002/mds.21996
   Spinelli E, 2007, LANG COGNITIVE PROC, V22, P828, DOI 10.1080/01690960601076472
   Spinelli E, 2010, ATTEN PERCEPT PSYCHO, V72, P775, DOI 10.3758/APP.72.3.775
   Strau<ss> A., 2015, FAAVSP 2015
   Thies T, 2020, NEUROPSYCHOLOGIA, V137, DOI 10.1016/j.neuropsychologia.2019.107306
NR 28
TC 0
Z9 0
U1 4
U2 4
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0269-9206
EI 1464-5076
J9 CLIN LINGUIST PHONET
JI Clin. Linguist. Phon.
DI 10.1080/02699206.2020.1797174
EA AUG 2020
PG 8
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA MU4PD
UT WOS:000555651000001
PM 32755289
DA 2021-02-24
ER

PT J
AU Wagner, L
   Geiling, L
   Hauth, C
   Hocke, T
   Plontke, S
   Rahne, T
AF Wagner, Luise
   Geiling, Lukas
   Hauth, Christopher
   Hocke, Thomas
   Plontke, Stefan
   Rahne, Torsten
TI Improved binaural speech reception thresholds through small symmetrical
   separation of speech and noise
SO PLOS ONE
LA English
DT Article
ID INTERAURAL LEVEL DIFFERENCES; COCHLEAR IMPLANT; HEARING-LOSS;
   INTELLIGIBILITY; STIMULATION; PERCEPTION; BENEFITS; MASKING; HEAD
AB Speech perception in noise is challenging and is improved by binaural hearing. Since signal processing of assistive hearing devices often modifies or masks the peripheral binaural head-shadow or better-ear effects, central binaural processing should be measured separately. In a prospective study, 10 listeners with normal hearing were tested with the German matrix sentence test in a set-up with two loudspeakers located at opposite angles in the horizontal plane with respect to S0N0. The speech reception threshold (SRT) was investigated depending on the separation angle between speech and noise. The lowest (best) SRT was obtained for a separation of target and interfering source from S(0)N(0)at an angle of about S +/- 60 degrees N -/+ 60 degrees. The derived normative curve was comparable to SRTs predicted by the binaural-speech-intelligibility-model. The systematic separation of signal and noise showed a significant improvement in speech intelligibility for normal-hearing people even for small separation angles. This experimental setting was verified. This study aimed to assess the effect of small sound source separation on binaural hearing and speech perception.
C1 [Wagner, Luise; Geiling, Lukas; Plontke, Stefan; Rahne, Torsten] Martin Luther Univ Halle Wittenberg, Univ Med Halle, Dept Otorhinolaryngol Head & Neck Surg, Halle, Germany.
   [Hauth, Christopher] Carl von Ossietzky Univ Oldenburg, Dept Med Phys & Cluster Excellence Hearing4All, Oldenburg, Germany.
   [Hocke, Thomas] Cochlear Deutschland GmbH & Co KG, Hannover, Germany.
RP Wagner, L (corresponding author), Martin Luther Univ Halle Wittenberg, Univ Med Halle, Dept Otorhinolaryngol Head & Neck Surg, Halle, Germany.
EM luise.wagner@uk-halle.de
RI Rahne, Torsten/AAD-1369-2021
FU Cochlear Deutschland GmbH Co. KG
FX TH is an employee of Cochlear Deutschland GmbH & Co. KG. The specific
   roles of all authors are articulated in the 'author contributions'
   section. The funders had no role in study design, data collection and
   analysis, decision to publish, or preparation of the manuscript.; The
   authors thank Mr. Baranowski and his staff for building the setup. We
   thank Jesko Verhey and Jan Hots (Otto-von-Guericke University Magdeburg)
   for assistance using the head simulator and Cochlear Deutschland GmbH &
   Co. KG for the financial support.
CR American national standard institute, 1997, METH CALC SPEECH INT
   Bernstein JGW, 2016, EAR HEARING, V37, P289, DOI 10.1097/AUD.0000000000000284
   Beutelmann R, 2010, J ACOUST SOC AM, V127, P2479, DOI 10.1121/1.3295575
   Brand T, 2002, J ACOUST SOC AM, V111, P2801, DOI 10.1121/1.1479152
   BRONKHORST AW, 1988, J ACOUST SOC AM, V83, P1508, DOI 10.1121/1.395906
   DUBNO JR, 1984, J ACOUST SOC AM, V76, P87, DOI 10.1121/1.391011
   DURLACH NI, 1963, J ACOUST SOC AM, V35, P1206, DOI 10.1121/1.1918675
   Freyman RL, 1999, J ACOUST SOC AM, V106, P3578, DOI 10.1121/1.428211
   Gabriel P, 2011, Z AUDIOL, V50, P50
   Hauth CF, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216517753547
   HELFER KS, 1990, J SPEECH HEAR RES, V33, P149, DOI 10.1044/jshr.3301.149
   Hey M, 2014, INT J AUDIOL, V53, P895, DOI 10.3109/14992027.2014.938368
   Hohmann V, 2002, ACTA ACUST UNITED AC, V88, P433
   Holube I, 1993, EXPT MODELLVORSTELLU
   Hoppe U, 2018, ACTA OTO-LARYNGOL, V138, P713, DOI 10.1080/00016489.2018.1444281
   Jones HG, 2016, EAR HEARING, V37, pE341, DOI 10.1097/AUD.0000000000000297
   Kraaijenga VJC, 2016, OTOL NEUROTOL, V37, P1300, DOI 10.1097/MAO.0000000000001185
   Kuehnel V, 1999, Z AUDIOL, V38, P4
   Laszig R, 2004, OTOL NEUROTOL, V25, P958, DOI 10.1097/00129492-200411000-00016
   Lingner A, 2016, JARO-J ASSOC RES OTO, V17, P461, DOI 10.1007/s10162-016-0575-7
   Litovsky R. Y., 2012, ACOUST TODAY, V8, P18
   Martin RL, 2012, J ACOUST SOC AM, V131, P378, DOI 10.1121/1.3669994
   Moore BCJ, 2016, J ACOUST SOC AM, V140, P2817, DOI 10.1121/1.4965299
   Neher T, 2017, HEARING RES, V353, P36, DOI 10.1016/j.heares.2017.07.014
   PLOMP R, 1981, ACUSTICA, V48, P325
   PLOMP R, 1978, J ACOUST SOC AM, V63, P533, DOI 10.1121/1.381753
   Potts WB, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216519831492
   Rader T, 2013, EAR HEARING, V34, P324, DOI 10.1097/AUD.0b013e318272f189
   Rennies J, 2014, J ACOUST SOC AM, V135, P1556, DOI 10.1121/1.4863197
   SHAW EAG, 1974, J ACOUST SOC AM, V56, P1848, DOI 10.1121/1.1903522
   Van Eeckhoutte M, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518805363
   van Hoesel RJM, 2012, HEARING RES, V288, P100, DOI 10.1016/j.heares.2011.11.014
   Weigerber T, 2019, HNO, V67, P265, DOI [10.1007/s00106-019-0635-530859252, DOI 10.1007/S00106-019-0635-530859252]
   Williges B, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216519858311
NR 34
TC 0
Z9 0
U1 0
U2 0
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD AUG 5
PY 2020
VL 15
IS 8
AR e0236469
DI 10.1371/journal.pone.0236469
PG 10
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA NB3DK
UT WOS:000560393300017
PM 32756594
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Gonzalez-Gomez, N
   O'Brien, F
   Harris, M
AF Gonzalez-Gomez, Nayeli
   O'Brien, Frances
   Harris, Margaret
TI The effects of prematurity and socioeconomic deprivation on early speech
   perception: A story of two different delays
SO DEVELOPMENTAL SCIENCE
LA English
DT Article; Early Access
DE phonetics; phonological acquisition; phonotactics; preterm infants;
   prosody; SES; speech perception
ID LOW-BIRTH-WEIGHT; NATIVE-LANGUAGE; PHONOTACTIC KNOWLEDGE; PHONETIC
   PERCEPTION; WORD SEGMENTATION; INFANTS SENSITIVITY; SCHOOL READINESS;
   PRETERM CHILDREN; 1ST YEAR; RECOGNITION
AB There is evidence showing that both maturational and environmental factors can impact on later language development. On the one hand, preterm birth has been found to increase the risk of deficits in the preschool and school years. Preterm children show poorer auditory discrimination, reading difficulties, poor vocabulary, less complex expressive language and lower receptive understanding than their matched controls. On the other hand, socioeconomic status (SES) indicators (i.e., income, education and occupation) have been found to be strongly related to linguistic abilities during the preschool and school years. However, there is very little information about how these factors result in lower linguistic abilities. The present study addresses this issue. To do so, we investigated early speech perception in full and preterm infants from families classed as high or low SES. Seventy-six infants were followed longitudinally at 7.5, 9, 10.5 and 12 months of age. At each test point, three studies explored infants' phonetic, prosodic and phonotactic development respectively. Results showed no significant differences between the phonetic or the phonotactic development of the preterm and the full-term infants. However, a time-lag between preterm and full-term developmental timing for prosody was found. Socioeconomic status did not have a significant effect on prosodic development. Nonetheless, phonetic and phonotactic development was affected by SES, infants from lower SES showed phonetic discrimination of non-native contrast and a preference for high-probability sequences later than their more advantaged peers. Overall these results suggest that different constraints apply to the acquisition of different phonological subcomponents.
C1 [Gonzalez-Gomez, Nayeli; Harris, Margaret] Oxford Brookes Univ, Dept Psychol, Oxford, England.
   [O'Brien, Frances] John Radcliffe Hosp, Oxford Univ Hosp, NHS, Oxford, England.
RP Gonzalez-Gomez, N (corresponding author), Oxford Brookes Univ, Dept Psychol Hlth & Profess Dev, Gipsy Lane, Oxford OX3 0BP, England.
EM ngonzalez-gomez@brookes.ac.uk
FU Leverhulme TrustLeverhulme Trust [ECF-2015-009]
FX Leverhulme Trust, Grant/Award Number: ECF-2015-009
CR Abboub N, 2016, BRAIN LANG, V162, P46, DOI 10.1016/j.bandl.2016.08.002
   ARMITAGE SE, 1980, SCIENCE, V208, P1173, DOI 10.1126/science.7375927
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bornstein MH, 1998, J CHILD LANG, V25, P367, DOI 10.1017/S0305000998003456
   Bosch L, 1997, COGNITION, V65, P33, DOI 10.1016/S0010-0277(97)00040-1
   Bosch L, 2011, PROG BRAIN RES, V189, P239, DOI 10.1016/B978-0-444-53884-0.00028-2
   Briscoe J, 1998, J SPEECH LANG HEAR R, V41, P654, DOI 10.1044/jslhr.4103.654
   Colombo J., 1993, INFANT COGNITION, V5
   Connell CM, 2002, J SCHOOL PSYCHOL, V40, P177, DOI 10.1016/S0022-4405(02)00090-0
   Councils I. S., 2011, NO MOR EXC IND RESP
   Crunelle D, 2003, FOLIA PHONIATR LOGO, V55, P115, DOI 10.1159/000070723
   Dehaene-Lambertz G, 2000, J COGNITIVE NEUROSCI, V12, P449, DOI 10.1162/089892900562264
   Estes KG, 2011, INFANCY, V16, P180, DOI 10.1111/j.1532-7078.2010.00046.x
   Evans MA, 2008, CAN PSYCHOL, V49, P89, DOI 10.1037/0708-5591.49.2.89
   FARRINGTON DP, 1991, J AM ACAD CHILD PSY, V30, P369, DOI 10.1097/00004583-199105000-00003
   Fernald A, 2013, DEVELOPMENTAL SCI, V16, P234, DOI 10.1111/desc.12019
   Field F., 2010, FDN YEARS PREVENTING
   Montiu MF, 2010, PSICOTHEMA, V22, P669
   Forget-Dubois N, 2009, CHILD DEV, V80, P736, DOI 10.1111/j.1467-8624.2009.01294.x
   FRIEDERICI AD, 1993, PERCEPT PSYCHOPHYS, V54, P287, DOI 10.3758/BF03205263
   Gasevic D, 2009, 2009 13TH ENTERPRISE DISTRIBUTED OBJECT COMPUTING CONFERENCE WORKSHOPS (EDOCW 2009), P1, DOI 10.1109/EDOCW.2009.5332026
   Gervain J, 2018, CURR OPIN BEHAV SCI, V21, P62, DOI 10.1016/j.cobeha.2018.02.004
   Gonzalez-Gomez N, 2013, J SPEECH LANG HEAR R, V56, P840, DOI 10.1044/1092-4388(2012/12-0138)
   Gonzalez-Gomez N, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0059601
   Gonzalez-Gomez N, 2012, DEVELOPMENTAL SCI, V15, P885, DOI 10.1111/j.1467-7687.2012.01186.x
   Granier-Deferre C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017304
   GRANIERDEFERRE C, 1985, ACTA OTO-LARYNGOL, P93
   GRIFFITHS SK, 1994, J ACOUST SOC AM, V96, P2055, DOI 10.1121/1.410147
   Grunau RE, 2002, ARCH PEDIAT ADOL MED, V156, P615, DOI 10.1001/archpedi.156.6.615
   GRUNAU RVE, 1990, BRIT J DISORD COMMUN, V25, P173
   Guarini A, 2010, J CHILD LANG, V37, P865, DOI 10.1017/S0305000909990109
   Guarini A, 2009, EARLY HUM DEV, V85, P639, DOI 10.1016/j.earlhumdev.2009.08.061
   HACK M, 1994, NEW ENGL J MED, V331, P753, DOI 10.1056/NEJM199409223311201
   HARRIS M, 1986, BRIT J DEV PSYCHOL, V4, P261, DOI 10.1111/j.2044-835X.1986.tb01017.x
   Harris M., 1984, FIRST LANG, V5, P89, DOI 10.1177/014272378400501401
   Hart B., 2003, AM EDUC, V27, P4
   Hart B., 1995, MEANINGFUL DIFFERENC
   Hartshorne M., 2006, I CAN TALK SERIES IS
   Herold B, 2008, DEV MED CHILD NEUROL, V50, P678, DOI 10.1111/j.1469-8749.2008.03055.x
   Hohle B, 2009, INFANT BEHAV DEV, V32, P262, DOI 10.1016/j.infbeh.2009.03.004
   Hoff E, 2003, CHILD DEV, V74, P1368, DOI 10.1111/1467-8624.00612
   Hoff E, 2003, MON PARENT, P147
   HOFFGINSBERG E, 1991, CHILD DEV, V62, P782, DOI 10.1111/j.1467-8624.1991.tb01569.x
   Hollinshead AB, 1975, 4 FACTOR INDEX SOCIA, P47
   Huttenlocher J, 1998, PREV MED, V27, P195, DOI 10.1006/pmed.1998.0301
   Jansson-Verkasalo E, 2004, FOLIA PHONIATR LOGO, V56, P108, DOI 10.1159/000076062
   Jansson-Verkasalo E, 2010, BMC NEUROSCI, V11, DOI 10.1186/1471-2202-11-88
   JUSCZYK PW, 1993, CHILD DEV, V64, P675, DOI 10.2307/1131210
   JUSCZYK PW, 1993, J MEM LANG, V32, P402, DOI 10.1006/jmla.1993.1022
   JUSCZYK PW, 1994, J MEM LANG, V33, P630, DOI 10.1006/jmla.1994.1030
   KarmiloffSmith A, 1997, DEV NEUROPSYCHOL, V13, P513, DOI 10.1080/87565649709540693
   Kooijman V, 2009, INFANCY, V14, P591, DOI 10.1080/15250000903263957
   Kostilainen K, 2020, INT J PSYCHOPHYSIOL, V148, P111, DOI 10.1016/j.ijpsycho.2019.10.009
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Kuhl PK, 2000, P NATL ACAD SCI USA, V97, P11850, DOI 10.1073/pnas.97.22.11850
   Law J., 2019, FRONTIERS ED, V4, P42, DOI [10.3389/feduc.2019.00042, DOI 10.3389/FEDUC.2019.00042]
   Law J, 2017, EARLY LANGUAGE DEV N
   Law J., 2017, CHILD LANGUAGE WELLB, P1
   Law J, 2009, J PUBLIC MENT HEALTH, V8, P4, DOI 10.1108/17465729200900002
   Lee V. E., 2002, INEQUALITY STARTING
   Locke A, 2002, INT J LANG COMM DIS, V37, P3, DOI 10.1080/13682820110089911
   Luoma L, 1998, DEV MED CHILD NEUROL, V40, P380
   Maggi S, 2010, J PAEDIATR CHILD H, V46, P627, DOI 10.1111/j.1440-1754.2010.01817.x
   Marmot M., 2010, MARMOT REV
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Mattys SL, 2001, COGNITION, V78, P91, DOI 10.1016/S0010-0277(00)00109-8
   McGillion M, 2017, J CHILD PSYCHOL PSYC, V58, P1122, DOI 10.1111/jcpp.12725
   McGillion ML, 2013, IEEE T AUTON MENT DE, V5, P240, DOI 10.1109/TAMD.2013.2275949
   Molnar M, 2014, INFANCY, V19, P326, DOI 10.1111/infa.12041
   Moon C, 2013, ACTA PAEDIATR, V102, P156, DOI 10.1111/apa.12098
   Mundy P, 2007, CHILD DEV, V78, P938, DOI 10.1111/j.1467-8624.2007.01042.x
   Nelson KE, 2011, FIRST LANG, V31, P164, DOI 10.1177/0142723710391887
   Neuman SB, 2008, EARLY CHILD RES Q, V23, P159, DOI 10.1016/j.ecresq.2007.11.001
   Oakes LM, 2019, BEHAV RES METHODS, V51, P1943, DOI 10.3758/s13428-019-01244-y
   Ortiz-Mantilia S, 2008, DEV PSYCHOBIOL, V50, P107, DOI 10.1002/dev.20278
   Pena M, 2010, P NATL ACAD SCI USA, V107, P3823, DOI 10.1073/pnas.0914326107
   Pinheiro J.C., 2000, MIXED EFFECTS MODELS, P3, DOI DOI 10.1007/0-387-22747-4_1
   Polka L, 2012, INFANCY, V17, P198, DOI 10.1111/j.1532-7078.2011.00075.x
   Pritchard VE, 2009, EARLY HUM DEV, V85, P215, DOI 10.1016/j.earlhumdev.2008.10.004
   QUERLEU D, 1981, J GYNECOL OBST BIO R, V10, P307
   Querleu D, 1988, Rev Fr Gynecol Obstet, V83, P43
   QUERLEU D, 1988, EUR J OBSTET GYN R B, V28, P191, DOI 10.1016/0028-2243(88)90030-5
   Ramey CT, 2004, MERRILL PALMER QUART, V50, P471, DOI 10.1353/mpq.2004.0034
   Ramon-Casas M, 2013, EARLY HUM DEV, V89, P55, DOI 10.1016/j.earlhumdev.2012.07.019
   Raviv T, 2004, EARLY CHILD RES Q, V19, P528, DOI 10.1016/j.ecresq.2004.10.007
   Ruben RJ, 2000, LARYNGOSCOPE, V110, P241, DOI 10.1097/00005537-200002010-00010
   RUTTER M, 1994, J CONSULT CLIN PSYCH, V62, P928, DOI 10.1037/0022-006X.62.5.928
   Sansavini A, 2010, EARLY HUM DEV, V86, P765, DOI 10.1016/j.earlhumdev.2010.08.014
   SCHWARZ UJ, 1978, ASTRON ASTROPHYS, V65, P345
   Sebastian-Galles N, 2002, J EXP PSYCHOL HUMAN, V28, P974, DOI 10.1037//0096-1523.28.4.974
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Tsuji S, 2014, DEV PSYCHOBIOL, V56, P179, DOI 10.1002/dev.21179
   Turkheimer E, 2003, PSYCHOL SCI, V14, P623, DOI 10.1046/j.0956-7976.2003.psci_1475.x
   VIGIL DC, 2005, CHILD LANG TEACH THE, V21, P107, DOI DOI 10.1191/0265659005CT284OA
   WALKER D, 1994, CHILD DEV, V65, P606, DOI 10.1111/j.1467-8624.1994.tb00771.x
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
NR 100
TC 0
Z9 0
U1 3
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
AR e13020
DI 10.1111/desc.13020
EA AUG 2020
PG 15
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA MU5EU
UT WOS:000555697300001
PM 32687657
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Yang, H
   Won, JH
   Choi, I
   Woo, J
AF Yang, Hyejin
   Won, Jong Ho
   Choi, Inyong
   Woo, Jihwan
TI A computational study to model the effect of electrode-to-auditory nerve
   fiber distance on spectral resolution in cochlear implant
SO PLOS ONE
LA English
DT Article
ID SPEECH-PERCEPTION; ELECTRICAL-STIMULATION; CONSONANT RECOGNITION; NEURON
   INTERFACE; NORMAL-HEARING; EXCITATION; SENSITIVITY; SIMULATION;
   PREDICTION; RESPONSES
AB Spectral ripple discrimination (SRD) has been widely used to evaluate the spectral resolution in cochlear implant (CI) recipients based on its strong correlation with speech perception performance. However, despite its usefulness for predicting speech perception outcomes, SRD performance exhibits large across-subject variabilities even among subjects implanted with the same CIs and sound processors. The potential factors of this observation include current spread, nerve survival, and CI mapping. Previous studies have found that the spectral resolution reduces with increasing distance of the stimulation electrode from the auditory nerve fibers (ANFs), attributable to increasing current spread. However, it remains unclear whether the spread of excitation is the only cause of the observation, or whether other factors such as temporal interaction also contribute to it. In this study, we used a computational model to investigate channel interaction upon non-simultaneous stimulation with respect to the electrode-ANF distance, and evaluated the SRD performance for five electrode-ANF distances. The SRD performance was determined based on the similarity between two neurograms in response to standard and inverted stimuli and used to evaluate the spectral resolution in the computational model. The spread of excitation was observed to increase with increasing electrode-ANF distance, consistent with previous findings. Additionally, the preceding pulses delivered from neighboring channels induced a channel interaction that either inhibited or facilitated the neural responses to subsequent pulses depending on the electrode-ANF distance. The SRD performance was also found to decrease with increasing electrode-ANF distance. The findings of this study suggest that variation of the neural responses (inhibition or facilitation) with the electrode-ANF distance in CI users may cause spectral smearing, and hence poor spectral resolution. A computational model such as that used in this study is a useful tool for understanding the neural factors related to CI outcomes, such as cannot be accomplished by behavioral studies alone.
C1 [Yang, Hyejin; Woo, Jihwan] Univ Ulsan, Sch Elect Engn, Dept Biomed Engn, Ulsan, South Korea.
   [Won, Jong Ho] US FDA, Div ENT Sleep Disordered Breathing Resp & Anesthe, Off Prod Evaluat & Qual, Ctr Devices & Radiol Hlth, Silver Spring, MD USA.
   [Choi, Inyong] Univ Iowa, Dept Commun Sci & Disorders, Iowa City, IA USA.
RP Woo, J (corresponding author), Univ Ulsan, Sch Elect Engn, Dept Biomed Engn, Ulsan, South Korea.
EM jhwoo@ulsan.ac.kr
OI Woo, Jihwan/0000-0003-2227-5948
FU National Research Foundation of Korea, Republic of KoreaNational
   Research Foundation of Korea [2017R1E1A1A01078409]
FX This work was supported by the National Research Foundation of Korea
   (2017R1E1A1A01078409), Republic of Korea.
CR Archer-Boyd AW, 2018, J ACOUST SOC AM, V144, P2983, DOI 10.1121/1.5079636
   Aronoff JM, 2013, J ACOUST SOC AM, V134, pEL217, DOI 10.1121/1.4813802
   Bruce IC, 2015, 38 ARO MIDW RES M
   Cartee LA, 2000, HEARING RES, V146, P143, DOI 10.1016/S0378-5955(00)00109-X
   Chatterjee M, 1998, J ACOUST SOC AM, V103, P2565, DOI 10.1121/1.422777
   Devries L, 2016, JARO-J ASSOC RES OTO, V17, P237, DOI 10.1007/s10162-016-0557-9
   Donaldson GS, 2000, J ACOUST SOC AM, V107, P1645, DOI 10.1121/1.428449
   Dynes SBC, 1996, THESIS
   Fox RF, 1997, BIOPHYS J, V72, P2068, DOI 10.1016/S0006-3495(97)78850-7
   FRANKENH.B, 1965, ACTA PHYSIOL SCAND, V63, P1, DOI 10.1111/j.1748-1716.1965.tb04037.x
   Fu QJ, 1998, J ACOUST SOC AM, V104, P3586, DOI 10.1121/1.423941
   Goldwyn JH, 2010, HEARING RES, V268, P93, DOI 10.1016/j.heares.2010.05.005
   Gordon KA, 2001, J OTOLARYNGOL, V30, P216, DOI 10.2310/7070.2001.20157
   HATSUSHIKA S, 1990, ANN OTO RHINOL LARYN, V99, P871, DOI 10.1177/000348949009901104
   Henry BA, 2005, J ACOUST SOC AM, V118, P1111, DOI 10.1121/1.1944567
   Henry BA, 2003, J ACOUST SOC AM, V113, P2861, DOI 10.1121/1.1561900
   Hines A, 2012, SPEECH COMMUN, V54, P306, DOI 10.1016/j.specom.2011.09.004
   Holden LK, 2016, OTOL NEUROTOL, V37, P1662, DOI 10.1097/MAO.0000000000001241
   Holden LK, 2013, EAR HEARING, V34, P342, DOI 10.1097/AUD.0b013e3182741aa7
   Jeon EK, 2015, J ACOUST SOC AM, V138, P2350, DOI 10.1121/1.4932020
   Kang S, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/934382
   Kral A, 1998, HEARING RES, V121, P11, DOI 10.1016/S0378-5955(98)00061-6
   Lazard DS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048739
   LIBERMAN MC, 1984, J COMP NEUROL, V223, P163, DOI 10.1002/cne.902230203
   Macherey O, 2008, JARO-J ASSOC RES OTO, V9, P241, DOI 10.1007/s10162-008-0112-4
   Marrinan MS, 2004, OTOL NEUROTOL, V25, P290, DOI 10.1097/00129492-200405000-00015
   McKay CM, 2001, J ACOUST SOC AM, V110, P1514, DOI 10.1121/1.1394222
   Miller CA, 2001, JARO-J ASSOC RES OTO, V2, P216, DOI 10.1007/s101620010083
   Miller CA, 2001, HEARING RES, V151, P79, DOI 10.1016/S0300-2977(00)00082-6
   Miller CA, 2008, JARO-J ASSOC RES OTO, V9, P122, DOI 10.1007/s10162-007-0108-5
   Mino H, 2004, IEEE T BIO-MED ENG, V51, P13, DOI 10.1109/TBME.2003.820383
   Mino H, 2002, ANN BIOMED ENG, V30, P578, DOI 10.1114/1.1475343
   NADOL JB, 1988, HEARING RES, V34, P253, DOI 10.1016/0378-5955(88)90006-8
   RATTAY F, 1993, IEEE T BIO-MED ENG, V40, P1201, DOI 10.1109/10.250575
   Rattay F, 2001, HEARING RES, V153, P64, DOI 10.1016/S0378-5955(00)00257-4
   Skinner MW, 2002, JARO-J ASSOC RES OTO, V3, P332, DOI 10.1007/s101620020013
   SUPIN AY, 1994, HEARING RES, V78, P31, DOI 10.1016/0378-5955(94)90041-8
   Taitelbaum-Swead R, 2005, INT J PEDIATR OTORHI, V69, P1675, DOI 10.1016/j.ijporl.2005.05.002
   Throckmorton CS, 1999, J ACOUST SOC AM, V105, P861, DOI 10.1121/1.426275
   Undurraga JA, 2012, HEARING RES, V290, P21, DOI 10.1016/j.heares.2012.05.003
   Vandali AE, 2000, EAR HEARING, V21, P608, DOI 10.1097/00003446-200012000-00008
   Wanna GB, 2014, LARYNGOSCOPE, V124, pS1, DOI 10.1002/lary.24728
   Wolfe J., 2017, COCHLEAR IMPLANTS AU
   Won JH, 2007, JARO-J ASSOC RES OTO, V8, P384, DOI 10.1007/s10162-007-0085-8
   Woo J, 2010, JARO-J ASSOC RES OTO, V11, P283, DOI 10.1007/s10162-009-0199-2
   Woo J, 2009, IEEE T BIO-MED ENG, V56, P2177, DOI 10.1109/TBME.2009.2023978
   Woo J, 2009, IEEE T BIO-MED ENG, V56, P1348, DOI 10.1109/TBME.2008.2005782
   Yang H, 2016, SPEECH COMMUN, V85, P19, DOI 10.1016/j.specom.2016.10.005
   Zhang F, 2007, JARO-J ASSOC RES OTO, V8, P356, DOI 10.1007/s10162-007-0086-7
   Zhou N, 2017, J ACOUST SOC AM, V141, pEL243, DOI 10.1121/1.4977235
NR 50
TC 0
Z9 0
U1 3
U2 3
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD AUG 3
PY 2020
VL 15
IS 8
AR e0236784
DI 10.1371/journal.pone.0236784
PG 20
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA NA7OS
UT WOS:000560006800031
PM 32745116
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Berezutskaya, J
   Baratin, C
   Freudenburg, ZV
   Ramsey, NF
AF Berezutskaya, Julia
   Baratin, Clarissa
   Freudenburg, Zachary, V
   Ramsey, Nicolas F.
TI High-density intracranial recordings reveal a distinct site in anterior
   dorsal precentral cortex that tracks perceived speech
SO HUMAN BRAIN MAPPING
LA English
DT Article
DE ECoG; motor cortex; speech perception
ID HUMAN SENSORIMOTOR CORTEX; MOTOR CORTEX; PREMOTOR CORTEX; CORTICAL
   ORGANIZATION; GAMMA-OSCILLATIONS; NEURAL RESPONSES; ACTIVATES MOTOR;
   ACTION WORDS; PERCEPTION; LANGUAGE
AB Various brain regions are implicated in speech processing, and the specific function of some of them is better understood than others. In particular, involvement of the dorsal precentral cortex (dPCC) in speech perception remains debated, and attribution of the function of this region is more or less restricted to motor processing. In this study, we investigated high-density intracranial responses to speech fragments of a feature film, aiming to determine whether dPCC is engaged in perception of continuous speech. Our findings show that dPCC exhibited preference to speech over other tested sounds. Moreover, the identified area was involved in tracking of speech auditory properties including speech spectral envelope, its rhythmic phrasal pattern and pitch contour. DPCC also showed the ability to filter out noise from the perceived speech. Comparing these results to data from motor experiments showed that the identified region had a distinct location in dPCC, anterior to the hand motor area and superior to the mouth articulator region. The present findings uncovered with high-density intracranial recordings help elucidate the functional specialization of PCC and demonstrate the unique role of its anterior dorsal region in continuous speech perception.
C1 [Berezutskaya, Julia; Baratin, Clarissa; Freudenburg, Zachary, V; Ramsey, Nicolas F.] Univ Med Ctr Utrecht, Brain Ctr, Dept Neurol & Neurosurg, Heidelberglaan 100, NL-3584 CX Utrecht, Netherlands.
   [Berezutskaya, Julia] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
   [Baratin, Clarissa] Univ Grenoble Alpes, Grenoble Inst Neurosci, Grenoble, France.
RP Berezutskaya, J (corresponding author), Univ Med Ctr Utrecht, Brain Ctr, Dept Neurol & Neurosurg, Heidelberglaan 100, NL-3584 CX Utrecht, Netherlands.
EM y.berezutskaya@umcutrecht.nl
FU H2020 European Research Council [ADV 320708]; Nederlandse Organisatie
   voor Wetenschappelijk OnderzoekNetherlands Organization for Scientific
   Research (NWO)European Commission; Netherlands Organisation for
   Scientific ResearchNetherlands Organization for Scientific Research
   (NWO); UMC Utrecht; European Research CouncilEuropean Research Council
   (ERC)European Commission
FX H2020 European Research Council, Grant/Award Number: Advanced iConnect
   Project Grant ADV 320708; Nederlandse Organisatie voor Wetenschappelijk
   Onderzoek, Grant/Award Number: Language in Interaction Project
   Gravitation Grant; UMC Utrecht; Netherlands Organisation for Scientific
   Research; European Research Council
CR Arai T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P2490, DOI 10.1109/ICSLP.1996.607318
   Assaneo MF, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aao3842
   Barsalou LW, 1999, BEHAV BRAIN SCI, V22, P577, DOI 10.1017/S0140525X99532147
   Barsalou LW, 2003, TRENDS COGN SCI, V7, P84, DOI 10.1016/S1364-6613(02)00029-3
   Begliomini C, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003388
   Bengtsson SL, 2009, CORTEX, V45, P62, DOI 10.1016/j.cortex.2008.07.002
   Berezutskaya J, 2017, J NEUROSCI, V37, P7906, DOI 10.1523/JNEUROSCI.0238-17.2017
   Bishop J, 2012, J ACOUST SOC AM, V132, P1100, DOI 10.1121/1.4714351
   Bleichner MG, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/6/066026
   Boersma P., 1993, P I PHONETIC SCI, V17, P97, DOI DOI 10.1371/JOURNAL.PONE.0069107
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Bouchard KE, 2013, NATURE, V495, P327, DOI 10.1038/nature11911
   Branco MP, 2018, J NEUROSCI METH, V301, P43, DOI 10.1016/j.jneumeth.2017.10.022
   Brennan J, 2016, LANG LINGUIST COMPAS, V10, P299, DOI 10.1111/lnc3.12198
   Brown S, 2008, CEREB CORTEX, V18, P837, DOI 10.1093/cercor/bhm131
   Brown S, 2009, BRAIN COGNITION, V70, P31, DOI 10.1016/j.bandc.2008.12.006
   Brugman H., 2004, LREC
   Callan DE, 2004, NEUROIMAGE, V22, P1182, DOI 10.1016/j.neuroimage.2004.03.006
   Callan DE, 2003, NEUROREPORT, V14, P2213, DOI 10.1097/00001756-200312020-00016
   Carey MJ, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1800, DOI 10.1109/ICSLP.1996.607979
   Chartier J, 2018, NEURON, V98, P1042, DOI 10.1016/j.neuron.2018.04.031
   Chen JL, 2006, NEUROIMAGE, V32, P1771, DOI 10.1016/j.neuroimage.2006.04.207
   Chen Y, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00376
   Cheung C, 2016, ELIFE, V5, DOI 10.7554/eLife.12577
   Chi T, 2005, J ACOUST SOC AM, V118, P887, DOI 10.1121/1.1945807
   Cogan GB, 2014, NATURE, V507, P94, DOI 10.1038/nature12935
   COLLIER R, 1975, J ACOUST SOC AM, V58, P249, DOI 10.1121/1.380654
   Crinion JT, 2003, BRAIN, V126, P1193, DOI 10.1093/brain/awg104
   Crone NE, 1998, BRAIN, V121, P2301, DOI 10.1093/brain/121.12.2301
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   Dalal SS, 2009, NEUROIMAGE, V45, P1289, DOI 10.1016/j.neuroimage.2009.01.017
   de Heer WA, 2017, J NEUROSCI, V37, P6539, DOI 10.1523/JNEUROSCI.3267-16.2017
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Dichter BK, 2018, CELL, V174, P21, DOI 10.1016/j.cell.2018.05.016
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   DIPELLEGRINO G, 1992, EXP BRAIN RES, V91, P176, DOI 10.1007/BF00230027
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   Duffau H, 2003, NEUROIMAGE, V20, P1903, DOI 10.1016/S1053-8119(03)00203-9
   Fischl B, 2012, NEUROIMAGE, V62, P774, DOI 10.1016/j.neuroimage.2012.01.021
   Floel A, 2003, EUR J NEUROSCI, V18, P704, DOI 10.1046/j.1460-9568.2003.02774.x
   Foti D, 2016, BRAIN LANG, V157, P63, DOI 10.1016/j.bandl.2016.05.001
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Glanz O, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-26801-x
   Hagoort P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00416
   Hamilton L. S., 2018, LANG COGN NEUROSCI, V35, P573
   Hauk O, 2004, NEURON, V41, P301, DOI 10.1016/S0896-6273(03)00838-9
   Heldner M, 2011, J ACOUST SOC AM, V130, P508, DOI 10.1121/1.3598457
   Hermes D, 2012, HUM BRAIN MAPP, V33, P1689, DOI 10.1002/hbm.21314
   Hermes D, 2010, J NEUROSCI METH, V185, P293, DOI 10.1016/j.jneumeth.2009.10.005
   Hevner K, 1937, AM J PSYCHOL, V49, P621, DOI 10.2307/1416385
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2009, J COGNITIVE NEUROSCI, V21, P1229, DOI 10.1162/jocn.2009.21189
   Honey CJ, 2012, J NEUROSCI, V32, P15277, DOI 10.1523/JNEUROSCI.1800-12.2012
   Jerbi K, 2009, HUM BRAIN MAPP, V30, P1758, DOI 10.1002/hbm.20750
   Jones E., 2001, SCIPY OPEN SOURCE SC
   Keitel A, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2004473
   Kitamura T., 1995, Journal of the Acoustical Society of Japan (E), V16, P283
   Kubanek J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053398
   Lachaux JP, 2007, HUM BRAIN MAPP, V28, P1368, DOI 10.1002/hbm.20352
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Mayka MA, 2006, NEUROIMAGE, V31, P1453, DOI 10.1016/j.neuroimage.2006.02.004
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Mottonen R, 2012, APHASIOLOGY, V26, P1103, DOI 10.1080/02687038.2011.619515
   Morillon B, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms6255
   Murakami T, 2011, NEUROPSYCHOLOGIA, V49, P2045, DOI 10.1016/j.neuropsychologia.2011.03.034
   Musch K, 2020, P NATL ACAD SCI USA, V117, P3203, DOI 10.1073/pnas.1910939117
   Oliphant TE, 2006, A GUIDE TO NUMPY
   Olthoff A, 2008, LARYNGOSCOPE, V118, P2091, DOI 10.1097/MLG.0b013e31817fd40f
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Raposo A, 2009, NEUROPSYCHOLOGIA, V47, P388, DOI 10.1016/j.neuropsychologia.2008.09.017
   Ray S, 2008, J NEUROSCI, V28, P11526, DOI 10.1523/JNEUROSCI.2848-08.2008
   Rizzolatti G, 2001, NEURON, V31, P889, DOI 10.1016/S0896-6273(01)00423-8
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Rogalsky C, 2009, CEREB CORTEX, V19, P786, DOI 10.1093/cercor/bhn126
   ROLAND PE, 1980, J NEUROPHYSIOL, V43, P118
   Roth B. J., 1992, J CLIN NEUROPHYSIOL, V9, P132
   Roussel P., 2019, ACOUSTIC CONTAMINATI
   Salari E, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50834-5
   Salo VC, 2019, DEV PSYCHOBIOL, V61, P390, DOI 10.1002/dev.21779
   Sato M, 2009, BRAIN LANG, V111, P1, DOI 10.1016/j.bandl.2009.03.002
   Schellekens W, 2018, NEUROIMAGE, V179, P337, DOI 10.1016/j.neuroimage.2018.06.062
   Schmidt CF, 2008, HUM BRAIN MAPP, V29, P46, DOI 10.1002/hbm.20372
   Scott SK, 2000, BRAIN, V123, P2400, DOI 10.1093/brain/123.12.2400
   Scott SK, 2009, NAT REV NEUROSCI, V10, P295, DOI 10.1038/nrn2603
   Seabold S., 2010, P 9 PYTH SCI C, DOI [DOI 10.25080/MAJORA-92BF1922-011, 10.25080/Majora-92bf1922-011]
   Shtyrov Y, 2014, P NATL ACAD SCI USA, V111, pE1918, DOI 10.1073/pnas.1323158111
   Siero JCW, 2014, NEUROIMAGE, V101, P177, DOI 10.1016/j.neuroimage.2014.07.002
   Simonyan K, 2011, NEUROSCIENTIST, V17, P197, DOI 10.1177/1073858410386727
   Skipper JI, 2006, ACTION TO LANGUAGE VIA THE MIRROR NEURON SYSTEM, P250, DOI 10.1017/CBO9780511541599.009
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   TERKEURS M, 1992, J ACOUST SOC AM, V91, P2872, DOI 10.1121/1.402950
   TERKEURS M, 1993, J ACOUST SOC AM, V93, P1547, DOI 10.1121/1.406813
   Thielscher A, 2002, NEUROIMAGE, V17, P1117, DOI 10.1006/nimg.2002.1282
   Tramo MJ, 2005, ANN NY ACAD SCI, V1060, P148, DOI 10.1196/annals.1360.011
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Wilson SM, 2008, CEREB CORTEX, V18, P230, DOI 10.1093/cercor/bhm049
   Wilson SM, 2006, NEUROIMAGE, V33, P316, DOI 10.1016/j.neuroimage.2006.05.032
   Yousry TA, 1997, BRAIN, V120, P141, DOI 10.1093/brain/120.1.141
   Zvonik E., 2003, 8 EUR C SPEECH COMM
NR 106
TC 0
Z9 0
U1 1
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1065-9471
EI 1097-0193
J9 HUM BRAIN MAPP
JI Hum. Brain Mapp.
PD NOV
PY 2020
VL 41
IS 16
BP 4587
EP 4609
DI 10.1002/hbm.25144
EA AUG 2020
PG 23
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA OL4UH
UT WOS:000554725900001
PM 32744403
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Junge, C
   Everaert, E
   Porto, L
   Fikkert, P
   de Klerk, M
   Keij, B
   Benders, T
AF Junge, Caroline
   Everaert, Emma
   Porto, Lyan
   Fikkert, Paula
   de Klerk, Maartje
   Keij, Brigitta
   Benders, Titia
TI Contrasting behavioral looking procedures: a case study on infant speech
   segmentation
SO INFANT BEHAVIOR & DEVELOPMENT
LA English
DT Article
DE Infant preference; Central fixation; Headturn preference procedure;
   Speech segmentation ability; Familiarity response
ID WORD SEGMENTATION; DIRECTED SPEECH; FAMILIAR WORDS; LANGUAGE;
   PERCEPTION; RECOGNITION; VOCABULARY; DETAIL; LISTEN
AB This paper compared three different procedures common in infant speech perception research: a headturn preference procedure (HPP) and a central-fixation (CF) procedure with either automated eye-tracking (CF-ET) or manual coding (CF-M). In theory, such procedures all measure the same underlying speech perception and learning mechanisms and the choice between them should ideally be irrelevant in unveiling infant preference. However, the ManyBabies study (ManyBabies Consortium, 2019), a cross-laboratory collaboration on infants' preference for child-directed speech, revealed that choice of procedure can modulate effect sizes. Here we examined whether procedure also modulates preference in paradigms that add a learning phase prior to test: a speech segmentation paradigm. Such paradigms are particularly important for studying the learning mechanisms infants can employ for language acquisition. We carried out the same familiarization-then-test experiment with the three different procedures (32 unique infants per procedure). Procedures were compared on various factors, such as overall effect, average looking time and drop-out rate. The key observations are that the HPP yielded a larger familiarity preference, but also reported larger drop-out rates. This raises questions about the generalizability of results. We argue that more collaborative research into different procedures in infant preference experiments is required in order to interpret the variation in infant preferences more accurately.
C1 [Junge, Caroline] Univ Utrecht, Dept Expt, Utrecht, Netherlands.
   [Junge, Caroline] Univ Utrecht, Dept Dev Psychol, Utrecht, Netherlands.
   [Everaert, Emma; de Klerk, Maartje; Keij, Brigitta] Univ Utrecht, Utrecht Inst Linguist OTS, Utrecht, Netherlands.
   [Porto, Lyan; Fikkert, Paula] Radboud Univ Nijmegen, Ctr Language Studies, Nijmegen, Netherlands.
   [Benders, Titia] Macquarie Univ, Dept Linguist, Sydney, NSW, Australia.
RP Junge, C (corresponding author), Univ Utrecht, Dept Expt, Utrecht, Netherlands.
EM C.M.M.Junge@uu.nl
OI Benders, Titia/0000-0003-0143-2182; de Klerk,
   Maartje/0000-0002-5466-6196
FU VENI grant from the Dutch Organization for Scientific Research
   (NWO)Netherlands Organization for Scientific Research (NWO)
   [016.154.051]
FX The authors would like to thank parents and infants for their
   cooperation. We thank Imme Lammertink and Maaike van Buren for
   assistance in the Headturn Preference Procedure Experiment; Charlotte
   Koevoets and Danique van Aalst for their assistance in the manual
   version of the Central Fixation Procedure, and Susanne Brouwer for
   lending her voice. We gratefully acknowledge Christina Bergmann for
   helping us with the meta-analyses. We also express thanks to the editor
   and anonymous reviewers for their constructive feedback. The first
   author was supported by a personal VENI grant (016.154.051) from the
   Dutch Organization for Scientific Research (NWO).
CR Aslin RN, 2007, DEVELOPMENTAL SCI, V10, P48, DOI 10.1111/j.1467-7687.2007.00563.x
   Aslin RN, 2012, INFANCY, V17, P126, DOI 10.1111/j.1532-7078.2011.00097.x
   Bacher LF, 2004, DEV PSYCHOBIOL, V44, P95, DOI 10.1002/dev.10162
   Bergmann C, 2018, CHILD DEV, V89, P1996, DOI 10.1111/cdev.13079
   Bergmann C, 2016, DEVELOPMENTAL SCI, V19, P901, DOI 10.1111/desc.12341
   Best C.T., 1998, INFANT BEHAV DEV, V21, P295, DOI [10.1016/S0163, DOI 10.1016/S0163, DOI 10.1016/S0163-6383(98)91508-9]
   Boersma P, 2015, PRAAT DOING PHONETIC
   COOPER RP, 1990, CHILD DEV, V61, P1584, DOI 10.1111/j.1467-8624.1990.tb02885.x
   Cristia A, 2016, INFANCY, V21, P648, DOI 10.1111/infa.12127
   Cristia A, 2014, CHILD DEV, V85, P1330, DOI 10.1111/cdev.12193
   Depaolis RA, 2014, J CHILD LANG, V41, P226, DOI 10.1017/S0305000912000566
   Dunst C., 2012, CELLREVIEWS, V5, P1
   FERNALD A, 1985, INFANT BEHAV DEV, V8, P181, DOI 10.1016/S0163-6383(85)80005-9
   Floccia C, 2016, COGNITION, V148, P1, DOI 10.1016/j.cognition.2015.12.004
   Frank MC, 2017, INFANCY, V22, P421, DOI 10.1111/infa.12182
   GOLDSTEIN H, 1986, BIOMETRIKA, V73, P43
   Goldstein H., 2011, MULTILEVEL STAT MODE, V922
   Gredeback G, 2010, DEV NEUROPSYCHOL, V35, P1, DOI 10.1080/87565640903325758
   Hessels RS, 2019, DEV COGN NEUROS-NETH, V40, DOI 10.1016/j.dcn.2019.100710
   Hessels RS, 2015, INFANCY, V20, P601, DOI 10.1111/infa.12093
   Houston DM, 2000, PSYCHON B REV, V7, P504, DOI 10.3758/BF03214363
   Junge C, 2014, BRAIN SCI, V4, P532, DOI 10.3390/brainsci4040532
   Junge C, 2012, DEVELOPMENTAL SCI, V15, P463, DOI 10.1111/j.1467-7687.2012.1144.x
   Jusczyk PW, 1999, COGNITIVE PSYCHOL, V39, P159, DOI 10.1006/cogp.1999.0716
   JUSCZYK PW, 1995, COGNITIVE PSYCHOL, V29, P1, DOI 10.1006/cogp.1995.1010
   Kooijman V, 2009, INFANCY, V14, P591, DOI 10.1080/15250000903263957
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   ManyBabies Consortium, 2019, ADV METHODS PRACTICE
   Marquis A, 2008, J ACOUST SOC AM, V123, pEL105, DOI 10.1121/1.2884082
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Meints K., 2008, LINCOLN INFANT LAB P
   MOON C, 1993, INFANT BEHAV DEV, V16, P495, DOI 10.1016/0163-6383(93)80007-U
   Nazzi T, 2000, J MEM LANG, V43, P1, DOI 10.1006/jmla.2000.2698
   Nazzi T, 2014, J CHILD LANG, V41, P600, DOI 10.1017/S0305000913000111
   Newman R, 2006, DEV PSYCHOL, V42, P643, DOI 10.1037/0012-1649.42.4.643
   Newman RS, 2016, J CHILD LANG, V43, P1158, DOI 10.1017/S0305000915000446
   Oakes LM, 2012, INFANCY, V17, P1, DOI 10.1111/j.1532-7078.2011.00101.x
   Quene H, 2008, J MEM LANG, V59, P413, DOI 10.1016/j.jml.2008.02.002
   Schreiner MS, 2017, COGNITION, V160, P98, DOI 10.1016/j.cognition.2016.12.003
   Shi R, 2008, DEVELOPMENTAL SCI, V11, P407, DOI 10.1111/j.1467-7687.2008.00685.x
   Shi RS, 2010, INFANCY, V15, P517, DOI 10.1111/j.1532-7078.2009.00022.x
   Singh L, 2012, DEVELOPMENTAL SCI, V15, P482, DOI 10.1111/j.1467-7687.2012.01141.x
   Sloetjes H, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P816
   Snijders T.A., 2011, INT ENCY STAT SCI, P879, DOI DOI 10.1007/978-3-642-04898-2_387
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Swingley D, 2005, DEVELOPMENTAL SCI, V8, P432, DOI 10.1111/j.1467-7687.2005.00432.x
   ter Schure SMM, 2016, INFANT BEHAV DEV, V43, P44, DOI 10.1016/j.infbeh.2016.01.002
   ter Schure S, 2014, INFANCY, V19, P476, DOI 10.1111/infa.12057
   Tsuji S, 2016, DEV PSYCHOL, V52, P379, DOI 10.1037/dev0000093
   van Heugten M, 2012, J SPEECH LANG HEAR R, V55, P554, DOI 10.1044/1092-4388(2011/10-0347)
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   Yoshida KA, 2010, INFANCY, V15, P420, DOI 10.1111/j.1532-7078.2009.00024.x
NR 52
TC 0
Z9 0
U1 1
U2 1
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0163-6383
EI 1879-0453
J9 INFANT BEHAV DEV
JI Infant Behav. Dev.
PD AUG
PY 2020
VL 60
AR 101448
DI 10.1016/j.infbeh.2020.101448
PG 13
WC Psychology, Developmental
SC Psychology
GA PG9KI
UT WOS:000600044900016
PM 32593957
DA 2021-02-24
ER

PT J
AU Ujiie, Y
   Kanazawa, S
   Yamaguchi, MK
AF Ujiie, Yuta
   Kanazawa, So
   Yamaguchi, Masami K.
TI Development of the multisensory perception of water in infancy
SO JOURNAL OF VISION
LA English
DT Article
DE multisensory; infant development; material perception
ID 5-MONTH-OLD INFANTS; SPEECH-PERCEPTION; 1ST YEAR; EXPERIENCE; OBJECTS;
   VISION
AB Material perception is facilitated by multisensory interactions that enable us to associate the visual properties of a material with its auditory properties. Such interactions develop during infancy and are assumed to depend on the familiarity of materials. Here, we aimed to pinpoint the age at which infants acquire multisensory interactions for the perception of water, which is a familiar material to them. We presented two side-by-side movies of pouring water and ice while providing the corresponding sounds of water and ice, as well as silence. We found that infants older than 5 months of age looked longer at the water movie when they heard the sound of water. Conversely, they did not look at the ice movie when they heard the sound of ice. These results indicate that at approximately 5 months of age, infants develop multisensory interactions between auditory and visual properties of water, but not of ice. The contrasting results between water and ice suggest that the development of multisensory material perception depends on the frequency of interactions with materials during infancy.
C1 [Ujiie, Yuta] Chuo Univ, Res & Dev Initiat, Bunkyo Ku, Tokyo, Japan.
   [Ujiie, Yuta] Japan Soc Promot Sci, Chiyoda Ku, Tokyo, Japan.
   [Ujiie, Yuta] Chukyo Univ, Grad Sch Psychol, Showa Ku, Nagoya, Aichi, Japan.
   [Kanazawa, So] Japan Womens Univ, Dept Psychol, Tama Ku, Kawasaki, Kanagawa, Japan.
   [Yamaguchi, Masami K.] Chuo Univ, Dept Psychol, Hachioji, Tokyo, Japan.
RP Ujiie, Y (corresponding author), Chukyo Univ, Grad Sch Psychol, Showa Ku, Nagoya, Aichi, Japan.
EM yuta.ujiie.160330@gmail.com
FU JST-RISTEXJapan Science & Technology Agency (JST);  [16H07207]; 
   [19K20650];  [19J00722];  [17H06343];  [18H05014]; Grants-in-Aid for
   Scientific ResearchMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [18H05014]
   Funding Source: KAKEN
FX Supported by the Grant-in-Aid for Research Activity Start-up program
   (grant no. 16H07207), Early-Career Scientists (grant no. 19K20650), and
   Grant-in-Aid for Japan Society for the Promotion of Science Fellowship
   Program (grant no. 19J00722). It was also supported in part by
   JST-RISTEX, as well as by a Grant-in-Aid for Scientific Research on
   Innovative Areas (17H06343, "Construction of the Face-Body Studies in
   Transcultural Conditions," and 18H05014, "SHITSUKAN Science and
   Technology").
CR Adelson EH, 2001, PROC SPIE, V4299, P1, DOI 10.1117/12.429489
   Arnott SR, 2008, NEUROIMAGE, V43, P368, DOI 10.1016/j.neuroimage.2008.07.033
   BAHRICK LE, 1992, J EXP CHILD PSYCHOL, V53, P180, DOI 10.1016/0022-0965(92)90048-B
   Bahrick LE, 2001, J EXP CHILD PSYCHOL, V79, P253, DOI 10.1006/jecp.2000.2588
   BAHRICK LE, 1988, CHILD DEV, V59, P197, DOI 10.2307/1130402
   BAHRICK LE, 1983, INFANT BEHAV DEV, V6, P429, DOI 10.1016/S0163-6383(83)90241-2
   Brookes H, 2001, INFANT CHILD DEV, V10, P75, DOI 10.1002/icd.249
   Coe S, 2011, NUTR BULL, V36, P259, DOI 10.1111/j.1467-3010.2011.01899.x
   Fujisaki W, 2015, VISION RES, V109, P185, DOI 10.1016/j.visres.2014.11.020
   Fujisaki W, 2014, J VISION, V14, DOI 10.1167/14.4.12
   Goda N, 2016, CURR BIOL, V26, P928, DOI 10.1016/j.cub.2016.02.003
   Goda N, 2014, J NEUROSCI, V34, P2660, DOI 10.1523/JNEUROSCI.2593-13.2014
   Hespos SJ, 2016, PSYCHOL SCI, V27, P244, DOI 10.1177/0956797615617897
   Hespos SJ, 2009, PSYCHOL SCI, V20, P603, DOI 10.1111/j.1467-9280.2009.02331.x
   Houix O, 2012, J EXP PSYCHOL-APPL, V18, P52, DOI 10.1037/a0026240
   Kawabe T, 2015, VISION RES, V109, P125, DOI 10.1016/j.visres.2014.07.003
   Kuhl PK, 2003, P NATL ACAD SCI USA, V100, P9096, DOI 10.1073/pnas.1532872100
   Lavender T, 2011, BMC PEDIATR, V11, DOI 10.1186/1471-2431-11-35
   Lewkowicz DJ, 2006, P NATL ACAD SCI USA, V103, P6771, DOI 10.1073/pnas.0602027103
   Motoyoshi I, 2007, NATURE, V447, P206, DOI 10.1038/nature05724
   Pascalis O, 2002, SCIENCE, V296, P1321, DOI 10.1126/science.1070223
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Putzar L, 2007, NAT NEUROSCI, V10, P1243, DOI 10.1038/nn1978
   Ujiie Y, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27153-2
   van Assen JJR, 2016, J VISION, V16, DOI 10.1167/16.15.12
   Wallace MT, 2004, J NEUROSCI, V24, P9580, DOI 10.1523/JNEUROSCI.2535-04.2004
   Werker JF, 2002, INFANT BEHAV DEV, V25, P121, DOI 10.1016/S0163-6383(02)00093-0
   Yang JL, 2015, CURR BIOL, V25, P3209, DOI 10.1016/j.cub.2015.10.053
   Yang JL, 2011, PERCEPTION, V40, P1491, DOI 10.1068/p6893
NR 29
TC 0
Z9 0
U1 0
U2 0
PU ASSOC RESEARCH VISION OPHTHALMOLOGY INC
PI ROCKVILLE
PA 12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA
SN 1534-7362
J9 J VISION
JI J. Vision
PD AUG
PY 2020
VL 20
IS 8
AR 5
DI 10.1167/jov.20.8.5
PG 7
WC Ophthalmology
SC Ophthalmology
GA NU5QA
UT WOS:000573694500019
PM 32749446
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Campbell, J
   Sharma, A
AF Campbell, Julia
   Sharma, Anu
TI Frontal Cortical Modulation of Temporal Visual Cross-Modal
   Re-organization in Adults with Hearing Loss
SO BRAIN SCIENCES
LA English
DT Article
DE sLORETA; high-density EEG; mild-moderate hearing loss; visual evoked
   potentials; speech perception; visual cross-modal re-organization;
   top-down modulation; frontal cortex; cognitive load; listening effort
ID AUDITORY-EVOKED POTENTIALS; OLDER-ADULTS; COGNITIVE DECLINE;
   SPEECH-PERCEPTION; BRAIN; CORTEX; PLASTICITY; ACTIVATION; DYNAMICS;
   STIMULI
AB Recent research has demonstrated frontal cortical involvement to co-occur with visual re-organization, suggestive of top-down modulation of cross-modal mechanisms. However, it is unclear whether top-down modulation of visual re-organization takes place in mild hearing loss, or is dependent upon greater degrees of hearing loss severity. Thus, the purpose of this study was to determine if frontal top-down modulation of visual cross-modal re-organization increased across hearing loss severity. We recorded visual evoked potentials (VEPs) in response to apparent motion stimuli in 17 adults with mild-moderate hearing loss using 128-channel high-density electroencephalography (EEG). Current density reconstructions (CDRs) were generated using sLORETA to visualize VEP generators in both groups. VEP latency and amplitude in frontal regions of interest (ROIs) were compared between groups and correlated with auditory behavioral measures. Activation of frontal networks in response to visual stimulation increased across mild to moderate hearing loss, with simultaneous activation of the temporal cortex. In addition, group differences in VEP latency and amplitude correlated with auditory behavioral measures. Overall, these findings support the hypothesis that frontal top-down modulation of visual cross-modal re-organization is dependent upon hearing loss severity.
C1 [Campbell, Julia] Univ Texas Austin, Cent Sensory Proc Lab, Dept Commun Sci & Disorders, 2504 Whitis Ave a1100, Austin, TX 78712 USA.
   [Sharma, Anu] Univ Colorado, Anu Sharma Brain & Behav Lab, Inst Cognit Sci, Dept Speech Language & Hearing Sci, 409 UCB,2501 Kittredge Loop Dr, Boulder, CO 80309 USA.
RP Sharma, A (corresponding author), Univ Colorado, Anu Sharma Brain & Behav Lab, Inst Cognit Sci, Dept Speech Language & Hearing Sci, 409 UCB,2501 Kittredge Loop Dr, Boulder, CO 80309 USA.
EM julia.campbell@austin.utexas.edu; anu.sharma@colorado.edu
FU NIH NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [F31D C011970]; HIRC
FX This research was supported by HIRC grant to A.S. and NIH NIDCD F31D
   C011970 to J.C.
CR Ahmadi M, 2018, VISION RES, V152, P101, DOI 10.1016/j.visres.2017.08.008
   Alhanbali S, 2017, EAR HEARING, V38, pE39, DOI 10.1097/AUD.0000000000000361
   Bavelier D, 2010, NAT NEUROSCI, V13, P1309, DOI 10.1038/nn1110-1309
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bertoli S, 2011, HEARING RES, V280, P58, DOI 10.1016/j.heares.2011.04.013
   Bertrand JA, 2012, EXP BRAIN RES, V216, P145, DOI 10.1007/s00221-011-2920-8
   Bidelman GM, 2019, BRAIN STRUCT FUNCT, V224, P2661, DOI 10.1007/s00429-019-01922-9
   Bosworth RG, 2002, BRAIN COGNITION, V49, P152, DOI 10.1006/brcg.2001.1497
   Buckley KA, 2011, EAR HEARING, V32, P2, DOI [10.1097/AUD.0b013e3181e8534c, 10.1097/AUD.0b013e3181fa41bb]
   Buckner RL, 2008, ANN NY ACAD SCI, V1124, P1, DOI 10.1196/annals.1440.011
   Campbell J, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00277
   Campbell J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147793
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   Campbell J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00071
   Cardin V, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00199
   Chen LC, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/4382656
   Deal JA, 2017, J GERONTOL A-BIOL, V72, P703, DOI 10.1093/gerona/glw069
   Debener S, 2008, PSYCHOPHYSIOLOGY, V45, P20, DOI 10.1111/j.1469-8986.2007.00610.x
   Debener S, 2006, TRENDS COGN SCI, V10, P558, DOI 10.1016/j.tics.2006.09.010
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Ding H, 2016, SCI REP-UK, V6, DOI 10.1038/srep23239
   Ding H, 2015, BRAIN, V138, P2750, DOI 10.1093/brain/awv165
   Doucet ME, 2006, BRAIN, V129, P3376, DOI 10.1093/brain/awl264
   Doucet ME, 2005, NEUROREPORT, V16, P1753, DOI 10.1097/01.wnr.0000185011.91197.58
   Eisner F, 2010, J NEUROSCI, V30, P7179, DOI 10.1523/JNEUROSCI.4040-09.2010
   Fine I, 2005, J COGNITIVE NEUROSCI, V17, P1621, DOI 10.1162/089892905774597173
   Finney EM, 2003, NEUROREPORT, V14, P1425, DOI 10.1097/00001756-200308060-00004
   Finney EM, 2001, NAT NEUROSCI, V4, P1171, DOI 10.1038/nn763
   Frey S, 2000, P NATL ACAD SCI USA, V97, P8723, DOI 10.1073/pnas.140543497
   Fuchs M, 2002, CLIN NEUROPHYSIOL, V113, P702, DOI 10.1016/S1388-2457(02)00030-5
   Gates GA, 2011, ARCH OTOLARYNGOL, V137, P390, DOI 10.1001/archoto.2011.28
   Gazzaley A, 2007, CEREB CORTEX, V17, pI125, DOI 10.1093/cercor/bhm113
   Gilley PM, 2008, BRAIN RES, V1239, P56, DOI 10.1016/j.brainres.2008.08.026
   Giraud AL, 2007, RESTOR NEUROL NEUROS, V25, P381
   Glick H, 2017, HEARING RES, V343, P191, DOI 10.1016/j.heares.2016.08.012
   Glick HA, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00093
   Goman AM, 2016, AM J PUBLIC HEALTH, V106, P1820, DOI 10.2105/AJPH.2016.303299
   Gonzalez GF, 2016, BRAIN COGNITION, V106, P42, DOI 10.1016/j.bandc.2016.05.001
   Grech R, 2008, J NEUROENG REHABIL, V5, DOI 10.1186/1743-0003-5-25
   Harkrider AW, 2009, EAR HEARING, V30, P31, DOI 10.1097/AUD.0b013e31818f359f
   Hine J, 2007, CLIN NEUROPHYSIOL, V118, P1274, DOI 10.1016/j.clinph.2007.03.012
   Humes LE, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00055
   Jorgensen LE, 2016, J AM ACAD AUDIOL, V27, P311, DOI 10.3766/jaaa.15006
   Joyce C, 2005, CLIN NEUROPHYSIOL, V116, P2613, DOI 10.1016/j.clinph.2005.07.005
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Kim MB, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148466
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P1131, DOI 10.1093/gerona/glr115
   Lomber SG, 2010, NAT NEUROSCI, V13, P1421, DOI 10.1038/nn.2653
   Makeig S, 2004, PLOS BIOL, V2, P747, DOI 10.1371/journal.pbio.0020176
   Makeig S, 1997, P NATL ACAD SCI USA, V94, P10979, DOI 10.1073/pnas.94.20.10979
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   Meredith MA, 2011, P NATL ACAD SCI USA, V108, P8856, DOI 10.1073/pnas.1018519108
   Mitchell TV, 2007, INT J AUDIOL, V46, P500, DOI 10.1080/14992020701383050
   NEVILLE HJ, 1987, BRAIN RES, V405, P268, DOI 10.1016/0006-8993(87)90296-4
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P5
   Peelle JE, 2018, EAR HEARING, V39, P204, DOI 10.1097/AUD.0000000000000494
   Peelle JE, 2016, TRENDS NEUROSCI, V39, P486, DOI 10.1016/j.tins.2016.05.001
   Peelle JE, 2011, J NEUROSCI, V31, P12638, DOI 10.1523/JNEUROSCI.2559-11.2011
   Price CN, 2019, NEUROSCIENCE, V423, P18, DOI 10.1016/j.neuroscience.2019.10.044
   Puschmann S, 2019, NEUROIMAGE, V196, P261, DOI 10.1016/j.neuroimage.2019.04.017
   Puschmann S, 2017, CORTEX, V86, P109, DOI 10.1016/j.cortex.2016.10.014
   Rosemann S, 2018, NEUROIMAGE, V175, P425, DOI 10.1016/j.neuroimage.2018.04.023
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   Savage CR, 2001, BRAIN, V124, P219, DOI 10.1093/brain/124.1.219
   Sharma A, 2016, BRAIN SCI, V6, DOI 10.3390/brainsci6010004
   Strelnikov K, 2013, BRAIN, V136, P3682, DOI 10.1093/brain/awt274
   Stropahl M, 2017, NEUROIMAGE-CLIN, V16, P514, DOI 10.1016/j.nicl.2017.09.001
   Stropahl M, 2015, NEUROIMAGE, V121, P159, DOI 10.1016/j.neuroimage.2015.07.062
   Uddin LQ, 2009, HUM BRAIN MAPP, V30, P625, DOI 10.1002/hbm.20531
   Vachon P, 2013, NEUROSCIENCE, V245, P50, DOI 10.1016/j.neuroscience.2013.04.004
   Wang C, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00015
   Wingfield A, 2015, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00035
   Woodhead ZVJ, 2014, CEREB CORTEX, V24, P817, DOI 10.1093/cercor/bhs365
NR 74
TC 0
Z9 0
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3425
J9 BRAIN SCI
JI Brain Sci.
PD AUG
PY 2020
VL 10
IS 8
AR 498
DI 10.3390/brainsci10080498
PG 16
WC Neurosciences
SC Neurosciences & Neurology
GA NG8DR
UT WOS:000564210700001
PM 32751543
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Winn, MB
   Moore, AN
AF Winn, Matthew B.
   Moore, Ashley N.
TI Perceptual weighting of acoustic cues for accommodating gender-related
   talker differences heard by listeners with normal hearing and with
   cochlear implants
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID VOCAL-TRACT LENGTH; SPEECH-PERCEPTION; FUNDAMENTAL-FREQUENCY; FORMANT
   FREQUENCIES; IDENTIFICATION; RECOGNITION; INFORMATION; DISCRIMINATION;
   CATEGORIZATION; VARIABILITY
AB Listeners must accommodate acoustic differences between vocal tracts and speaking styles of conversation partners-a process called normalization or accommodation. This study explores what acoustic cues are used to make this perceptual adjustment by listeners with normal hearing or with cochlear implants, when the acoustic variability is related to the talker's gender. A continuum between /?/ and /s/ was paired with naturally spoken vocalic contexts that were parametrically manipulated to vary by numerous cues for talker gender including fundamental frequency (F0), vocal tract length (formant spacing), and direct spectral contrast with the fricative. The goal was to examine relative contributions of these cues toward the tendency to have a lower-frequency acoustic boundary for fricatives spoken by men (found in numerous previous studies). Normal hearing listeners relied primarily on formant spacing and much less on F0. The CI listeners were individually variable, with the F0 cue emerging as the strongest cue on average.
C1 [Winn, Matthew B.] Univ Minnesota, Speech Language Hearing Sci, Minneapolis, MN 55455 USA.
   [Moore, Ashley N.] Univ Washington, Dept Speech & Hearing Sci, Seattle, WA 98105 USA.
RP Winn, MB (corresponding author), Univ Minnesota, Speech Language Hearing Sci, Minneapolis, MN 55455 USA.
EM mwinn@umn.edu
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA; NIH NIDCDUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01 DC017114]
FX This work was supported by National Institutes of Health Grant No. NIH
   NIDCD R01 DC017114 (Winn). Data collection and participant recruitment
   were assisted by Kate Teece, Heather Kreft, Moira McShane, Tiffany
   Mitchell, Josephine Lyou, Siuho Gong, Steven Gianakas, Emily Hugo, Paula
   Rodriguez, Hannah Matthys, and Lindsay Williams.
CR Abiru N, 2020, DIABETOL INT, V11, P1, DOI 10.1007/s13340-019-00415-8
   AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   [Anonymous], 2013, ROSSIYSKIY KARDIO S3, V4, P1, DOI DOI 10.1186/2049-1891-4-1
   [Anonymous], 2015, PHYSIOL MEAS, V36, pR1, DOI DOI 10.1097/AUD.0000000000000163
   [Anonymous], 2016, OTOL NEUROTOL, V37, pe82, DOI DOI 10.1097/AUD.0000000000000328
   Barreda S, 2017, J ACOUST SOC AM, V141, P4781, DOI 10.1121/1.4985192
   Barreda S, 2013, J ACOUST SOC AM, V133, P1065, DOI 10.1121/1.4773858
   Barreda S, 2012, J ACOUST SOC AM, V131, P466, DOI 10.1121/1.3662068
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Blood D, 2016, RENEWABLE ENERGY FOC, V17
   Boersma P., COMPUTER PROGRAM VER
   Boersma P., 2018, PRAAT DOING PHONETIC
   Boex C, 2003, J ACOUST SOC AM, V114, P2049, DOI 10.1121/1.1610451
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Campell N., 2014, P SPEECH PROS DUBL, P776
   Carredano Amores, 2016, ANUARIO ESTUDIOS ATL, V62, P1, DOI DOI 10.1016/J.WOCN.2015.11.004
   Chatterjee M, 1998, J ACOUST SOC AM, V103, P2565, DOI 10.1121/1.422777
   Chodroff E, 2020, ATTEN PERCEPT PSYCHO, V82, P2027, DOI 10.3758/s13414-019-01894-2
   Eklund I, 1997, PHONETICA, V54, P1, DOI 10.1159/000262207
   El Boghdady N, 2019, J ACOUST SOC AM, V145, P417, DOI 10.1121/1.5087693
   Fant G., 1966, SPEECH TRANSMISSION, V7, P22
   Fu QJ, 2005, J ACOUST SOC AM, V118, P1711, DOI 10.1121/1.1985024
   Fuller CD, 2014, JARO-J ASSOC RES OTO, V15, P1037, DOI 10.1007/s10162-014-0483-7
   Gaudrain E, 2018, EAR HEARING, V39, P226, DOI 10.1097/AUD.0000000000000480
   Gaudrain E, 2015, J ACOUST SOC AM, V137, P1298, DOI 10.1121/1.4908235
   Hedrick MS, 1997, J SPEECH LANG HEAR R, V40, P1445, DOI 10.1044/jslhr.4006.1445
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hillenbrand JM, 2009, ATTEN PERCEPT PSYCHO, V71, P1150, DOI 10.3758/APP.71.5.1150
   Holden LK, 2013, EAR HEARING, V34, P342, DOI 10.1097/AUD.0b013e3182741aa7
   Jaekel BN, 2017, J SPEECH LANG HEAR R, V60, P1398, DOI 10.1044/2016_JSLHR-H-15-0427
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   Kluender KR, 2003, SPEECH COMMUN, V41, P59, DOI 10.1016/S0167-6393(02)00093-6
   Kovacic D, 2009, J ACOUST SOC AM, V126, P762, DOI 10.1121/1.3158855
   Liberman M., 2013, LANGUAGE LOG    0816
   Lotto AJ, 1998, PERCEPT PSYCHOPHYS, V60, P602, DOI 10.3758/BF03206049
   Luo X, 2006, J ACOUST SOC AM, V120, P2260, DOI 10.1121/1.2336990
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P213, DOI 10.3758/BF03204377
   Maryn Y, 2009, J ACOUST SOC AM, V126, P2619, DOI 10.1121/1.3224706
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   MILLER JL, 1981, PHONETICA, V38, P159, DOI 10.1159/000260021
   Moberly AC, 2016, EAR HEARING, V37, P14, DOI 10.1097/AUD.0000000000000204
   Munson B, 2006, J ACOUST SOC AM, V119, P2427, DOI 10.1121/1.2173521
   Munson B, 2003, J ACOUST SOC AM, V113, P925, DOI 10.1121/1.1536630
   Munson B, 2011, J ACOUST SOC AM, V130, P2631, DOI 10.1121/1.3641410
   R Core Development Team, 2016, R LANG ENV STAT COMP
   Shannon RV, 2004, ACTA OTO-LARYNGOL, V124, P50, DOI 10.1080/03655230410017562
   Sjerps MJ, 2015, J EXP PSYCHOL HUMAN, V41, P710, DOI 10.1037/a0039028
   Skuk VG, 2014, J SPEECH LANG HEAR R, V57, P285, DOI 10.1044/1092-4388(2013/12-0314)
   Stilp CE, 2016, HEARING RES, V341, P168, DOI 10.1016/j.heares.2016.08.004
   Stilp CE, 2015, J ACOUST SOC AM, V137, P3466, DOI 10.1121/1.4921600
   vanDommelen WA, 1995, LANG SPEECH, V38, P267, DOI 10.1177/002383099503800304
   Winn M. B, 2019, ROUTLEDGE HDB PHONET, P164
   Winn MB, 2020, J ACOUST SOC AM, V147, P174, DOI 10.1121/10.0000566
   Winn MB, 2015, J ACOUST SOC AM, V137, P1430, DOI 10.1121/1.4908308
   Winn MB, 2012, J ACOUST SOC AM, V131, P1465, DOI 10.1121/1.3672705
   Zeng FG, 2002, J ACOUST SOC AM, V111, P377, DOI 10.1121/1.1423926
NR 57
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD AUG
PY 2020
VL 148
IS 2
BP 496
EP 510
DI 10.1121/10.0001672
PG 15
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA NA4CD
UT WOS:000559761500004
PM 32873011
DA 2021-02-24
ER

PT J
AU Kao, CE
   Zhang, Y
AF Kao, Chieh
   Zhang, Yang
TI Differential Neurobehavioral Effects of Cross-Modal Selective Priming on
   Phonetic and Emotional Prosodic Information in Late Second Language
   Learners
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID BEHAVIORAL EVIDENCE; FACIAL EXPRESSIONS; SPEECH; ERP; PERCEPTION;
   ACTIVATION; SEMANTICS; LANGUAGES; WORDS; 1ST
AB Purpose: Spoken language is inherently multimodal and multidimensional in natural settings, but very little is known about how second language (L2) learners undertake multilayered speech signals with both phonetic and affective cues. This study investigated how late L2 learners undertake parallel processing of linguistic and affective information in the speech signal at behavioral and neurophysiological levels.
   Method: Behavioral and event-related potential measures were taken in a selective cross-modal priming paradigm to examine how late L2 learners (N = 24, M-age = 25.54 years) assessed the congruency of phonetic (target vowel: /a/ or /i/) and emotional (target affect: happy or angry) information between the visual primes of facial pictures and the auditory targets of spoken syllables.
   Results: Behavioral accuracy data showed a significant congruency effect in affective (but not phonetic) priming. Unlike a previous report on monolingual first language (L1) users, the L2 users showed no facilitation in reaction time for congruency detection in either selective priming task. The neurophysiological results revealed a robust N400 response that was stronger in the phonetic condition but without clear lateralization and that the N400 effect was weaker in late L2 listeners than in monolingual L1 listeners. Following the N400, late L2 learners showed a weaker late positive response than the monolingual L1 users, particularly in the left central to posterior electrode regions.
   Conclusions: The results demonstrate distinct patterns of behavioral and neural processing of phonetic and affective information in L2 speech with reduced neural representations in both the N400 and the later processing stage, and they provide an impetus for further research on similarities and differences in L1 and L2 multisensory speech perception in bilingualism.
C1 [Kao, Chieh; Zhang, Yang] Univ Minnesota, Dept Speech Language Hearing Sci, Minneapolis, MN 55455 USA.
   [Zhang, Yang] Univ Minnesota, Ctr Neurobehav Dev, Minneapolis, MN 55455 USA.
RP Zhang, Y (corresponding author), Univ Minnesota, Dept Speech Language Hearing Sci, Minneapolis, MN 55455 USA.; Zhang, Y (corresponding author), Univ Minnesota, Ctr Neurobehav Dev, Minneapolis, MN 55455 USA.
EM zhanglab@umn.edu
RI Zhang, Yang/Q-1780-2015
OI Zhang, Yang/0000-0001-6777-3487; Kao, Chieh/0000-0003-0154-650X
FU University of Minnesota's Grand Challenges Exploratory Research Grant;
   Brain Imaging Research Project Award
FX This work was supported by the University of Minnesota's Grand
   Challenges Exploratory Research Grant and Brain Imaging Research Project
   Award. We thank Luke LeBeau and Erick Juarez for assisting with the data
   collection and Erin Diamond for the original data from native speakers
   of English for statistical comparison.
CR Aguado L, 2013, COGN AFFECT BEHAV NE, V13, P284, DOI 10.3758/s13415-012-0137-3
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Ben-David BM, 2016, J SPEECH LANG HEAR R, V59, P72, DOI 10.1044/2015_JSLHR-H-14-0323
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bhatara A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0156855
   Boersma P., 2018, PRAAT DOING PHONETIC
   Brattico E, 2010, BIOL PSYCHOL, V85, P393, DOI 10.1016/j.biopsycho.2010.08.014
   Brown DR, 2017, PSYCHOPHYSIOLOGY, V54, P1812, DOI 10.1111/psyp.12959
   Chen PY, 2015, CORTEX, V71, P34, DOI 10.1016/j.cortex.2015.06.002
   Chen XH, 2011, BIOL PSYCHOL, V86, P158, DOI 10.1016/j.biopsycho.2010.11.004
   Cooke M, 2008, J ACOUST SOC AM, V123, P414, DOI 10.1121/1.2804952
   Czerwon B, 2013, INT J PSYCHOPHYSIOL, V87, P28, DOI 10.1016/j.ijpsycho.2012.10.014
   Degner J, 2012, BILING-LANG COGN, V15, P181, DOI 10.1017/S1366728911000095
   Dehaene S, 1997, NEUROREPORT, V8, P3809, DOI 10.1097/00001756-199712010-00030
   Diamond E, 2016, NEUROPSYCHOLOGIA, V82, P110, DOI 10.1016/j.neuropsychologia.2016.01.019
   Donges US, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0041745
   FAZIO RH, 1986, J PERS SOC PSYCHOL, V50, P229, DOI 10.1037/0022-3514.50.2.229
   Gerdes ABM, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01351
   Goerlich KS, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019501
   Goldinger SD, 1998, PERCEPT PSYCHOPHYS, V60, P952, DOI 10.3758/BF03211931
   Grainger J, 2001, MEM COGNITION, V29, P53, DOI 10.3758/BF03195740
   Hahne A, 2001, J PSYCHOLINGUIST RES, V30, P251, DOI 10.1023/A:1010490917575
   Hahne A., 2001, BILING-LANG COGN, V4, P123, DOI DOI 10.1017/S1366728901000232
   Hayakawa S, 2016, TRENDS COGN SCI, V20, P791, DOI 10.1016/j.tics.2016.08.004
   Herring DR, 2011, EMOTION, V11, P794, DOI 10.1037/a0022804
   Hirata Y, 2010, J SPEECH LANG HEAR R, V53, P298, DOI 10.1044/1092-4388(2009/08-0243)
   HOLCOMB PJ, 1993, LANG COGNITIVE PROC, V8, P379, DOI 10.1080/01690969308407583
   HOLCOMB PJ, 1990, LANG COGNITIVE PROC, V5, P281, DOI 10.1080/01690969008407065
   Koso A, 2011, BRAIN RES, V1385, P217, DOI 10.1016/j.brainres.2011.02.008
   Kotz SA, 2007, BRAIN RES, V1151, P107, DOI 10.1016/j.brainres.2007.03.015
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Lei MM, 2018, JPN PSYCHOL RES, V60, P300, DOI 10.1111/jpr.12218
   Li W, 2008, J COGNITIVE NEUROSCI, V20, P95
   Llompart M, 2017, J EXP PSYCHOL HUMAN, V43, P1040, DOI 10.1037/xhp0000383
   Logeswaran N, 2009, NEUROSCI LETT, V455, P129, DOI 10.1016/j.neulet.2009.03.044
   Lucas M, 2000, PSYCHON B REV, V7, P618, DOI 10.3758/BF03212999
   Luce PA, 2000, PERCEPT PSYCHOPHYS, V62, P615, DOI 10.3758/BF03212113
   Martin CD, 2013, J MEM LANG, V69, P574, DOI 10.1016/j.jml.2013.08.001
   McLaughlin J, 2004, NAT NEUROSCI, V7, P703, DOI 10.1038/nn1264
   MEYER DE, 1971, J EXP PSYCHOL, V90, P227, DOI 10.1037/h0031564
   Min CS, 2011, COGNITION EMOTION, V25, P1376, DOI 10.1080/02699931.2010.544865
   MURPHY ST, 1993, J PERS SOC PSYCHOL, V64, P723, DOI 10.1037/0022-3514.64.5.723
   Navarra J, 2007, PSYCHOL RES-PSYCH FO, V71, P4, DOI 10.1007/s00426-005-0031-5
   Neely J. H., 2012, BASIC PROCESSES READ, P272
   Noppeney U, 2008, CEREB CORTEX, V18, P598, DOI 10.1093/cercor/bhm091
   Nygaard LC, 2008, J EXP PSYCHOL HUMAN, V34, P1017, DOI 10.1037/0096-1523.34.4.1017
   Ojima S, 2005, J COGNITIVE NEUROSCI, V17, P1212, DOI 10.1162/0898929055002436
   Paulmann S, 2008, BRAIN LANG, V105, P59, DOI 10.1016/j.bandl.2007.11.005
   Paulmann S, 2011, MOTIV EMOTION, V35, P192, DOI 10.1007/s11031-011-9206-0
   Paulmann S, 2010, COGN AFFECT BEHAV NE, V10, P230, DOI 10.3758/CABN.10.2.230
   Pell MD, 2011, COGNITION EMOTION, V25, P834, DOI 10.1080/02699931.2010.516915
   Pell MD, 2005, J NONVERBAL BEHAV, V29, P45, DOI 10.1007/s10919-004-0889-8
   Pratt H, 2013, HUM BRAIN MAPP, V34, P2863, DOI 10.1002/hbm.22111
   Riviello Maria Teresa, 2012, Cognitive Behavioural Systems (COST 2012). International Training School. Revised Selected Papers, P424, DOI 10.1007/978-3-642-34584-5_38
   Riviello M. T., 2011, 2 INT C COGN INF COG
   RUBIN J, 1994, MOD LANG J, V78, P199, DOI 10.2307/329010
   Schirmer A, 2005, COGNITIVE BRAIN RES, V24, P442, DOI 10.1016/j.cogbrainres.2005.02.022
   Schirmer A, 2002, COGNITIVE BRAIN RES, V14, P228, DOI 10.1016/S0926-6410(02)00108-8
   Schirmer A, 2003, J COGNITIVE NEUROSCI, V15, P1135, DOI 10.1162/089892903322598102
   Schneider TR, 2008, NEUROIMAGE, V42, P1244, DOI 10.1016/j.neuroimage.2008.05.033
   Schneider TR, 2008, EXP PSYCHOL, V55, P121, DOI 10.1027/1618-3169.55.2.121
   Schupp HT, 2000, PSYCHOPHYSIOLOGY, V37, P257, DOI 10.1017/S0048577200001530
   Schupp HT, 2003, PSYCHOL SCI, V14, P7, DOI 10.1111/1467-9280.01411
   Schwartz R, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047279
   Sebastian-Galles N, 2006, J COGNITIVE NEUROSCI, V18, P1277, DOI 10.1162/jocn.2006.18.8.1277
   Sianipar A, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144576
   Simpson AP, 2009, LANG LINGUIST COMPAS, V3, P621, DOI 10.1111/j.1749-818x.2009.00125.x
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964
   WeberFox CM, 1996, J COGNITIVE NEUROSCI, V8, P231, DOI 10.1162/jocn.1996.8.3.231
   Werheid K, 2005, INT J PSYCHOPHYSIOL, V55, P209, DOI 10.1016/j.ijpsycho.2004.07.006
   Wurm LH, 2001, COGNITION EMOTION, V15, P831, DOI 10.1080/02699930143000086
   Yi HG, 2013, J ACOUST SOC AM, V134, pEL387, DOI 10.1121/1.4822320
   Zhang Q, 2010, BRAIN RES, V1329, P142, DOI 10.1016/j.brainres.2010.03.021
NR 73
TC 1
Z9 1
U1 3
U2 4
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD AUG
PY 2020
VL 63
IS 8
BP 2508
EP 2521
DI 10.1044/2020_JSLHR-19-00329
PG 14
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA MZ3RR
UT WOS:000559039900002
PM 32658561
DA 2021-02-24
ER

PT J
AU Roup, CM
   Green, DE
   DeBacker, JR
AF Roup, Christina M.
   Green, Donna E.
   DeBacker, J. Riley
TI The Impact of Speech Recognition Testing on State Anxiety in Young,
   Middle-Age, and Older Adults
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID HEARING-LOSS; COGNITIVE ANXIETY; WORD-RECOGNITION; NOISE; HEALTH;
   DISABILITY; DEPRESSION; HANDICAP; LIFE; ASSOCIATION
AB Purpose: This study assessed state anxiety as a function of speech recognition testing using three clinical measures of speech in noise and one clinical measure of dichotic speech recognition.
   Method: Thirty young adults, 30 middle-age adults, and 25 older adults participated. State anxiety was measured pre- and post-speech recognition testing using the State-Trait Anxiety Inventory. Speech recognition was measured with the Revised Speech Perception in Noise Test, the Quick Speech-in-Noise Test, the Words-in-Noise Test, and the Dichotic Digits Test (DDT).
   Results: Speech recognition performance was as expected: Older adults performed significantly poorer on all measures as compared to the young adults and significantly poorer on the Revised Speech Perception in Noise Test, the Quick Speech-in-Noise Test, and the Words-in-Noise Test as compared to the middle-age adults. On average, State-Trait Anxiety Inventory scores increased posttesting, with the middle-age adults exhibiting significantly greater increases in state anxiety as compared to the young and older adults. Increases in state anxiety were significantly greater for the DDT relative to the speech-in-noise tests for the middle-age adults only. Poorer DDT recognition performance was associated with higher levels of state anxiety.
   Conclusions: Increases in state anxiety were observed after speech-in-noise and dichotic listening testing for all groups, with significant increases seen for the young and middle-age adults. Although the exact mechanisms could not be determined, multiple factors likely influenced the observed increases in state anxiety, including task difficulty, individual proficiency, and age.
C1 [Roup, Christina M.; Green, Donna E.; DeBacker, J. Riley] Ohio State Univ, Dept Speech & Hearing Sci, Columbus, OH 43210 USA.
RP Roup, CM (corresponding author), Ohio State Univ, Dept Speech & Hearing Sci, Columbus, OH 43210 USA.
EM roup.2@osu.edu
OI DeBacker, J. Riley/0000-0002-8217-9598
FU Division of Social and Behavioral Sciences at The Ohio State University
FX This article is dedicated to the memory of Kirsten E. Chiasson, who
   inspired the design of this study. Funding for this project was obtained
   from a Faculty Small Research Grant and an Undergraduate Research Grant
   from the Division of Social and Behavioral Sciences at The Ohio State
   University. The authors thank Emily Brown and Amy Custer for their
   assistance with data collection. Portions of data from this article were
   presented at the 2014 Hearing Across the Lifespan Conference in Lake
   Como, Italy, and the 2019 American Academy of Audiology Conference in
   Columbus, Ohio.
CR Agrawal Y, 2008, ARCH INTERN MED, V168, P1522, DOI 10.1001/archinte.168.14.1522
   ALPERT R, 1960, J ABNORM SOC PSYCH, V61, P207, DOI 10.1037/h0045464
   American National Standards Institute, 1987, S3391987R2012 ANSI
   American National Standards Institute, 2010, S362010 ANSI
   ANDERSSON G, 1995, PERCEPT MOTOR SKILL, V81, P552, DOI 10.2466/pms.1995.81.2.552
   [Anonymous], 2016, MEAS NAT WELL BEING
   Arslan Fatih, 2018, Ear Nose Throat J, V97, pE7
   Ball S., 1995, TEST ANXIETY THEORY, P107
   BARR RA, 1990, PSYCHOL AGING, V5, P597
   Basner M, 2014, LANCET, V383, P1325, DOI 10.1016/S0140-6736(13)61613-X
   Beck D L, 2018, HEARING REV, V25, P28
   Beutel M. E., 2016, PLOS ONE, V11, P1, DOI DOI 10.1371/J0URNAL.P0NE.0148054
   BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32
   Bilger RC., 1984, ASHA REPORTS, V14, P2
   Brammer AJ, 2012, NOISE HEALTH, V14, P281, DOI 10.4103/1463-1741.104894
   BROADBENT DE, 1956, Q J EXP PSYCHOL, V8, P145, DOI 10.1080/17470215608416814
   CATTELL RB, 1976, MULTIVAR BEHAV RES, V11, P27, DOI 10.1207/s15327906mbr1101_2
   Ciesla K, 2016, EUR ARCH OTO-RHINO-L, V273, P767, DOI 10.1007/s00405-015-3713-7
   Contrera KJ, 2017, J AGING HEALTH, V29, P172, DOI 10.1177/0898264316634571
   Cosh S, 2018, INT J GERIATR PSYCH, V33, P598, DOI 10.1002/gps.4827
   Cosh S, 2018, AGE AGEING, V47, P582, DOI 10.1093/ageing/afy062
   Department of Veterans Affairs, 1992, TON SPEECH MAT AUD P
   Department of Veterans Affairs, 2006, SPEECH REC ID MAT DI
   DUBNO JR, 1984, J ACOUST SOC AM, V76, P87, DOI 10.1121/1.391011
   Dubno JR, 1997, J SPEECH LANG HEAR R, V40, P444, DOI 10.1044/jslhr.4002.444
   EDSELL RD, 1976, J PSYCHOL, V92, P219, DOI 10.1080/00223980.1976.9921359
   ERIKSSONMANGOLD M, 1991, J PSYCHOSOM RES, V35, P729, DOI 10.1016/0022-3999(91)90124-7
   Erler Susan F, 2002, Am J Audiol, V11, P83, DOI 10.1044/1059-0889(2002/020)
   Ferrari S, 2019, J NERV MENT DIS, V207, P459, DOI 10.1097/NMD.0000000000000995
   Findlen UM, 2016, J AM ACAD AUDIOL, V27, P13, DOI 10.3766/jaaa.15017
   Finney D.J., 1952, STAT METHOD BIOL ASS
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Frisina DR, 1997, HEARING RES, V106, P95, DOI 10.1016/S0378-5955(97)00006-3
   GAUDRY E, 1975, MULTIVAR BEHAV RES, V10, P331, DOI 10.1207/s15327906mbr1003_6
   Gendolla GHE, 2006, INT J PSYCHOPHYSIOL, V62, P185, DOI 10.1016/j.ijpsycho.2006.04.002
   HART S G, 1988, P139
   Helfer KS, 2009, J AM ACAD AUDIOL, V20, P264, DOI 10.3766/jaaa.20.4.6
   HEMBREE R, 1988, REV EDUC RES, V58, P47, DOI 10.3102/00346543058001047
   Hetu R, 1996, SCAND AUDIOL, V25, P12
   IDLER EL, 1993, J GERONTOL, V48, pS289, DOI 10.1093/geronj/48.6.S289
   Jayakody DMP, 2018, MATURITAS, V110, P86, DOI 10.1016/j.maturitas.2018.02.002
   JERGER J, 1994, EAR HEARING, V15, P274, DOI 10.1097/00003446-199408000-00002
   Kelly-Campbell RJ, 2014, J COMMUN DISORD, V47, P47, DOI 10.1016/j.jcomdis.2014.01.005
   Kent B, 2007, INT J AUDIOL, V46, P328, DOI 10.1080/14992020701261389
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Kim SY, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182718
   Kim SH, 2006, SPEECH COMMUN, V48, P591, DOI 10.1016/j.specom.2005.09.004
   KIMURA D, 1961, CAN J PSYCHOLOGY, V15, P166, DOI 10.1037/h0083219
   KING K, 1992, SCAND AUDIOL, V21, P109, DOI 10.3109/01050399209045990
   Lawrence BJ, 2020, GERONTOLOGIST, V60, pE137, DOI 10.1093/geront/gnz009
   LAWTON MP, 1995, PSYCHOL AGING, V10, P469, DOI 10.1037/0882-7974.10.3.469
   Leigh-Paffenroth ED, 2011, J AM ACAD AUDIOL, V22, P393, DOI 10.3766/jaaa.22.7.2
   Mackersie CL, 2011, J AM ACAD AUDIOL, V22, P113, DOI 10.3766/jaaa.22.2.6
   McArdle R., 2009, PERSPECTIVES HEARING, V13, P4, DOI [10.1044/hhd13.1.4, DOI 10.1044/HHD13.1.4]
   Mehta KM, 2003, J AM GERIATR SOC, V51, P499, DOI 10.1046/j.1532-5415.2003.51158.x
   [National Council on Aging Senior Research Group an alliance between the National Council on Aging and Market Strategies Inc], 1999, CONS UNTR HEAR LOSS
   Oishi N, 2011, INT J AUDIOL, V50, P491, DOI 10.3109/14992027.2011.560904
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   PEKRUN R, 1992, APPL PSYCHOL-INT REV, V41, P359, DOI 10.1111/j.1464-0597.1992.tb00712.x
   Ross B, 2007, J NEUROSCI, V27, P11172, DOI 10.1523/JNEUROSCI.1813-07.2007
   Roup CM, 2006, J AM ACAD AUDIOL, V17, P230, DOI 10.3766/jaaa.17.4.2
   Roup CM, 2018, J AM ACAD AUDIOL, V29, P477, DOI 10.3766/jaaa.16111
   Roup CM, 2010, INT J AUDIOL, V49, P88, DOI 10.3109/14992020903280138
   Roup CM, 1998, AM J AUDIOL, V7, P55
   Sargent-Cox KA, 2014, INT PSYCHOGERIATR, V26, P135, DOI 10.1017/S1041610213001798
   SAUNDERS GH, 1989, EAR HEARING, V10, P200, DOI 10.1097/00003446-198906000-00011
   Schwarzer R., 1992, ADV TEST ANXIETY RES
   Sindhusake D, 2001, INT J EPIDEMIOL, V30, P1371, DOI 10.1093/ije/30.6.1371
   Southall K, 2010, INT J AUDIOL, V49, P804, DOI 10.3109/14992027.2010.498447
   Spielberger C. D., 1983, MANUAL STATE TRAIT A, DOI [10.1037/t06496-000, DOI 10.1037/T06496-000]
   Strouse A, 1999, J Am Acad Audiol, V10, P557
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Tillman T. W., 1966, EXPANDED TEST SPEECH, DOI [10.21236/AD0639638, DOI 10.21236/AD0639638]
   Tremblay KL, 2015, EAR HEARING, V36, pE290, DOI 10.1097/AUD.0000000000000195
   VandenLangenberg GM, 1998, AM J EPIDEMIOL, V148, P204, DOI 10.1093/oxfordjournals.aje.a009625
   VINEY LL, 1976, J PERS ASSESS, V40, P140, DOI 10.1207/s15327752jpa4002_5
   Vytal KE, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00093
   Watkins RE, 1998, INT J AGING HUM DEV, V46, P319, DOI 10.2190/0LU1-0UWE-2TLW-QVAP
   Wiley T L, 1998, J Am Acad Audiol, V9, P191
   Wiley T L, 1996, J Am Acad Audiol, V7, P260
   Wiley T L, 2000, J Am Acad Audiol, V11, P67
   Wilson R H, 1996, J Am Acad Audiol, V7, P1
   Wilson RH, 2003, J REHABIL RES DEV, V40, P321, DOI 10.1682/JRRD.2003.07.0321
   Wilson RH, 2007, J AM ACAD AUDIOL, V18, P813, DOI 10.3766/jaaa.18.10.2
   Yoo M, 2019, ARCH GERONTOL GERIAT, V83, P126, DOI 10.1016/j.archger.2019.04.004
   Zachariae R, 2000, SCAND AUDIOL, V29, P37, DOI 10.1080/010503900424589
   Zhao F, 1996, SCAND AUDIOL, V25, P91, DOI 10.3109/01050399609047989
   Zhao F, 1996, BRIT J AUDIOL, V30, P397, DOI 10.3109/03005369609078427
NR 88
TC 0
Z9 0
U1 2
U2 2
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD AUG
PY 2020
VL 63
IS 8
BP 2789
EP 2800
DI 10.1044/2020_JSLHR-19-00246
PG 12
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA MZ3RR
UT WOS:000559039900024
PM 32692585
DA 2021-02-24
ER

PT J
AU Rosemann, S
   Smith, D
   Dewenter, M
   Thiel, CM
AF Rosemann, Stephanie
   Smith, Dakota
   Dewenter, Marie
   Thiel, Christiane M.
TI Age-related hearing loss influences functional connectivity of auditory
   cortex for the McGurk illusion
SO CORTEX
LA English
DT Article
DE Hearing loss; McGurk illusion; Functional MRI; Functional connectivity
ID AUDIOVISUAL SPEECH-PERCEPTION; CROSS-MODAL REORGANIZATION; BRAIN
   ACTIVITY; SEEING-VOICES; OLDER-ADULTS; DEAF; INTEGRATION; PLASTICITY;
   NOISE; LIPS
AB Age-related hearing loss affects hearing at high frequencies and is associated with difficulties in understanding speech. Increased audio-visual integration has recently been found in age-related hearing impairment, the brain mechanisms that contribute to this effect are however unclear. We used functional magnetic resonance imaging in elderly subjects with normal hearing and mild to moderate uncompensated hearing loss. Audiovisual integration was studied using the McGurk task. In this task, an illusionary fused percept can occur if incongruent auditory and visual syllables are presented. The paradigm included unisensory stimuli (auditory only, visual only), congruent audio-visual and incongruent (McGurk) audio-visual stimuli. An illusionary precept was reported in over 60% of incongruent trials. These McGurk illusion rates were equal in both groups of elderly subjects and correlated positively with speech-in-noise perception and daily listening effort. Normal-hearing participants showed an increased neural response in left pre- and postcentral gyri and right middle frontal gyrus for incongruent stimuli (McGurk) compared to congruent audio-visual stimuli. Activation patterns were however not different between groups. Task-modulated functional connectivity differed between groups showing increased connectivity from auditory cortex to visual, parietal and frontal areas in hard of hearing participants as compared to normal-hearing participants when comparing incongruent stimuli (McGurk) with congruent audio-visual stimuli. These results suggest that changes in functional connectivity of auditory cortex rather than activation strength during processing of audio-visual McGurk stimuli accompany age-related hearing loss. (c) 2020 Elsevier Ltd. All rights reserved.
C1 [Rosemann, Stephanie; Smith, Dakota; Dewenter, Marie; Thiel, Christiane M.] Carl von Ossietzky Univ Oldenburg, Sch Med & Hlth Sci, Dept Psychol, Biol Psychol, D-26111 Oldenburg, Germany.
   [Rosemann, Stephanie; Thiel, Christiane M.] Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, Oldenburg, Germany.
RP Rosemann, S (corresponding author), Carl von Ossietzky Univ Oldenburg, Sch Med & Hlth Sci, Dept Psychol, Biol Psychol, D-26111 Oldenburg, Germany.
EM Stephanie.rosemann@uni-oldenburg.de; drsmith@bu.edu; mariemhdw@aol.com;
   Christiane.thiel@uol.de
OI Rosemann, Stephanie/0000-0003-2598-0538
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under
   Germany's Excellence Strategy e EXC 2177/1German Research Foundation
   (DFG) [390895286]; Neuroimaging Unit of the Carl von Ossietzky
   Universitat Oldenburg - German Research Foundation [3T MRI INST
   184/152-1 FUGG]
FX This work was funded by the Deutsche Forschungsgemeinschaft (DFG, German
   Research Foundation) under Germany's Excellence Strategy e EXC 2177/1
   -Project ID 390895286 and supported by the Neuroimaging Unit of the Carl
   von Ossietzky Universitat Oldenburg funded by grants from the German
   Research Foundation (3T MRI INST 184/152-1 FUGG).
CR Allman BL, 2009, P NATL ACAD SCI USA, V106, P5925, DOI 10.1073/pnas.0809483106
   Alsius A, 2018, MULTISENS RES, V31, P111, DOI 10.1163/22134808-00002565
   Armstrong NM, 2020, J GERONTOL A-BIOL, V75, P574, DOI 10.1093/gerona/gly268
   Auer ET, 2007, J SPEECH LANG HEAR R, V50, P1157, DOI 10.1044/1092-4388(2007/080)
   B_aumler G., 1984, FARBE WORT INTERFERE
   Baum Sarah H, 2017, Curr Behav Neurosci Rep, V4, P198, DOI 10.1007/s40473-017-0124-7
   Behler O., 2016, REPRESENTATION LEVEL, DOI [10.1016/j.neuroimage.2016.06.025., DOI 10.1016/J.NEUROIMAGE.2016.06.025]
   Benoit MM, 2010, HUM BRAIN MAPP, V31, P526, DOI 10.1002/hbm.20884
   Berding G, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128743
   Bernstein LE, 2008, NEUROIMAGE, V39, P423, DOI 10.1016/j.neuroimage.2007.08.035
   Bishop CW, 2009, J COGNITIVE NEUROSCI, V21, P1790, DOI 10.1162/jocn.2009.21118
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   Campbell J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00071
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155
   Chen LC, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-10792-2
   Chen LC, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/4382656
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Driver J, 2008, NEURON, V57, P11, DOI 10.1016/j.neuron.2007.12.013
   Erb J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00116
   Erickson LC, 2014, HUM BRAIN MAPP, V35, P5587, DOI 10.1002/hbm.22572
   Erickson LC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00534
   Friston KJ, 1997, NEUROIMAGE, V6, P218, DOI 10.1006/nimg.1997.0291
   Gau R, 2016, NEUROIMAGE, V124, P876, DOI 10.1016/j.neuroimage.2015.09.045
   Giordano BL, 2017, ELIFE, V6, DOI 10.7554/eLife.24763
   Grant KW, 1998, J ACOUST SOC AM, V103, P2677, DOI 10.1121/1.422788
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Guerreiro MJS, 2017, NEUROBIOL AGING, V56, P180, DOI 10.1016/j.neurobiolaging.2017.05.001
   Gurgel RK, 2014, OTOL NEUROTOL, V35, P775, DOI 10.1097/MAO.0000000000000313
   Helfer KS, 2008, EAR HEARING, V29, P87, DOI 10.1097/AUD.0b013e31815d638b
   Hervais-Adelman AG, 2012, LANG COGNITIVE PROC, V27, P1145, DOI 10.1080/01690965.2012.662280
   Humes LE, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00055
   Irwin J., 2017, LINGUIST COMPASS, V11, P77, DOI [10.1111/lnc3.12237, DOI 10.1111/LNC3.12237]
   Jacques C, 2019, HUM BRAIN MAPP, V40, P1403, DOI 10.1002/hbm.24455
   Jang I, 2016, 2016 IEEE NETSOFT CONFERENCE AND WORKSHOPS (NETSOFT), P11, DOI 10.1109/NETSOFT.2016.7502433
   Japee S, 2015, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00023
   Jones JA, 2003, NEUROREPORT, V14, P1129, DOI 10.1097/00001756-200306110-00006
   Kral A, 2016, LANCET NEUROL, V15, P610, DOI 10.1016/S1474-4422(16)00034-X
   Lambertz N, 2005, COGNITIVE BRAIN RES, V25, P884, DOI 10.1016/j.cogbrainres.2005.09.010
   Lazard DS, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms14872
   Lee HJ, 2007, BRAIN, V130, P2929, DOI 10.1093/brain/awm230
   Lee YS, 2016, HEARING RES, V333, P108, DOI 10.1016/j.heares.2015.12.008
   Lin FR, 2014, NEUROIMAGE, V90, P84, DOI 10.1016/j.neuroimage.2013.12.059
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Lin FR, 2011, NEUROPSYCHOLOGY, V25, P763, DOI 10.1037/a0024238
   Lomber SG, 2011, PROG BRAIN RES, V191, P251, DOI 10.1016/B978-0-444-53752-2.00001-1
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Merabet LB, 2010, NAT REV NEUROSCI, V11, P44, DOI 10.1038/nrn2758
   Moore DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107720
   Moradi S, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516653355
   Murakami T, 2018, J NEUROSCI, V38, P9679, DOI 10.1523/JNEUROSCI.3650-17.2018
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Nath AR, 2011, J NEUROSCI, V31, P1704, DOI 10.1523/JNEUROSCI.4853-10.2011
   Oldfield R. C., 1971, ASSESSMENT ANAL HAND, DOI [10.1016/0028-3932(71) 90067-4., DOI 10.1016/0028-3932(71)90067-4]
   Park H, 2016, ELIFE, V5, DOI 10.7554/eLife.14521
   Peelle JE, 2011, J NEUROSCI, V31, P12638, DOI 10.1523/JNEUROSCI.2559-11.2011
   Pronk M, 2019, J SPEECH LANG HEAR R, V62, P1167, DOI 10.1044/2018_JSLHR-H-ASCC7-18-0120
   Puschmann S, 2019, NEUROIMAGE, V196, P261, DOI 10.1016/j.neuroimage.2019.04.017
   Puschmann S, 2017, CORTEX, V86, P109, DOI 10.1016/j.cortex.2016.10.014
   Puschmann S, 2014, HEARING RES, V316, P28, DOI 10.1016/j.heares.2014.07.005
   Raizada RDS, 2007, NEURON, V56, P726, DOI 10.1016/j.neuron.2007.11.001
   Rajah MN, 2011, J NEUROSCI, V31, P17941, DOI 10.1523/JNEUROSCI.1690-11.2011
   Rettenbach R, 1999, J COGNITIVE NEUROSCI, V11, P560, DOI 10.1162/089892999563616
   Reuter-Lorenz PA, 2008, CURR DIR PSYCHOL SCI, V17, P177, DOI 10.1111/j.1467-8721.2008.00570.x
   Reynolds C.R., 2002, COMPREHENSIVE TRAIL
   Rosemann S, 2020, NEUROSCIENCE, V429, P134, DOI 10.1016/j.neuroscience.2019.12.046
   Rosemann S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38816-z
   Rosemann S, 2018, NEUROIMAGE, V175, P425, DOI 10.1016/j.neuroimage.2018.04.023
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   Schierholz I, 2015, HEARING RES, V328, P133, DOI 10.1016/j.heares.2015.08.009
   Schmidt K-H., 1992, WORTSCHATZTEST WST
   Schulte M., 2015, 18 JAHR DTSCH GES AU
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   SHEIKH J I, 1986, Clinical Gerontologist, V5, P165
   Shiell MM, 2015, J COGNITIVE NEUROSCI, V27, P150, DOI 10.1162/jocn_a_00683
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Smits M, 2012, ARCH PHYS MED REHAB, V93, pS4, DOI 10.1016/j.apmr.2011.02.023
   Song JJ, 2015, BRAIN STRUCT FUNCT, V220, P1109, DOI 10.1007/s00429-013-0704-6
   Stevenson RA, 2018, J EXP PSYCHOL HUMAN, V44, P106, DOI 10.1037/xhp0000424
   Stevenson RA, 2015, NEUROBIOL AGING, V36, P283, DOI 10.1016/j.neurobiolaging.2014.08.003
   Stevenson RA, 2012, J EXP PSYCHOL HUMAN, V38, P1517, DOI 10.1037/a0027339
   Strelcyk O, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216519864499
   Strelnikov K, 2015, EUR J NEUROSCI, V41, P677, DOI 10.1111/ejn.12827
   Stropahl M, 2017, NEUROIMAGE-CLIN, V16, P514, DOI 10.1016/j.nicl.2017.09.001
   Stropahl M, 2015, NEUROIMAGE, V121, P159, DOI 10.1016/j.neuroimage.2015.07.062
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Szycik GR, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00095
   Tyler LK, 2010, CEREB CORTEX, V20, P352, DOI 10.1093/cercor/bhp105
   von Gablenz P, 2015, HNO, V63, P195, DOI 10.1007/s00106-014-2949-7
   Wagener K, 1999, Z AUDIOL, V38, P86
   Wiersinga-Post E, 2010, NEUROREPORT, V21, P1146, DOI 10.1097/WNR.0b013e328340cc47
   Wilkinson D, 2004, NAT REV NEUROSCI, V5, P67, DOI 10.1038/nrn1302
   Wong PCM, 2010, EAR HEARING, V31, P471, DOI 10.1097/AUD.0b013e3181d709c2
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
NR 97
TC 2
Z9 2
U1 3
U2 5
PU ELSEVIER MASSON, CORP OFF
PI PARIS
PA 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE
SN 0010-9452
EI 1973-8102
J9 CORTEX
JI Cortex
PD AUG
PY 2020
VL 129
BP 266
EP 280
DI 10.1016/j.cortex.2020.04.022
PG 15
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA MR1LA
UT WOS:000553351700022
PM 32535378
DA 2021-02-24
ER

PT J
AU de Almeida, LR
   Pope, PA
   Hansen, PC
AF Rodrigues de Almeida, Lilian
   Pope, Paul A.
   Hansen, Peter C.
TI Task load modulates tDCS effects on brain network for phonological
   processing
SO COGNITIVE PROCESSING
LA English
DT Article
DE Phonological processing; Task load; LIFG; Language; fMRI; tDCS
ID DIRECT-CURRENT STIMULATION; INFERIOR FRONTAL GYRUS; SPEECH-PERCEPTION;
   EFFECTIVE CONNECTIVITY; FUNCTIONAL CONNECTIVITY; MOTION CORRECTION;
   PHONEMIC FLUENCY; PREMOTOR CORTEX; PARAMETRIC FMRI; LEXICAL ACCESS
AB Motor participation in phonological processing can be modulated by task nature across the speech perception to speech production range. The pars opercularis of the left inferior frontal gyrus (LIFG) would be increasingly active across this range, because of changing motor demands. Here, we investigated with simultaneous tDCS and fMRI whether the task load modulation of tDCS effects translates into predictable patterns of functional connectivity. Findings were analysed under the "multi-node framework", according to which task load and the network structure underlying cognitive functions are modulators of tDCS effects. In a within-subject study, participants (N = 20) performed categorical perception, lexical decision and word naming tasks [which differentially recruit the target of stimulation (LIFG)], which were repeatedly administered in three tDCS sessions (anodal, cathodal and sham). The LIFG, left superior temporal gyrus and their right homologues formed the target network subserving phonological processing. C-tDCS inhibition and A-tDCS excitation should increase with task load. Correspondingly, the larger the task load, the larger the relevance of the target for the task and smaller the room for compensation of C-tDCS inhibition by less relevant nodes. Functional connectivity analyses were performed with partial correlations, and network compensation globally inferred by comparing the relative number of significant connections each condition induced relative to sham. Overall, simultaneous tDCS and fMRI was adequate to show that motor participation in phonological processing is modulated by task nature. Network responses induced by C-tDCS across phonological processing tasks matched predictions. A-tDCS effects were attributed to optimisation of network efficiency.
C1 [Rodrigues de Almeida, Lilian; Pope, Paul A.; Hansen, Peter C.] Univ Birmingham, Sch Psychol, Birmingham B15 2TT, W Midlands, England.
RP de Almeida, LR (corresponding author), Univ Birmingham, Sch Psychol, Birmingham B15 2TT, W Midlands, England.
EM L.RodriguesDeAlmeida@bham.ac.uk
OI Hansen, Peter/0000-0002-4948-1007
CR Amunts K, 1999, J COMP NEUROL, V412, P319, DOI 10.1002/(SICI)1096-9861(19990920)412:2<319::AID-CNE10>3.0.CO;2-7
   Andersson JLR, 2007, TR07JA1
   Andersson JLR, 2007, TR07JA2
   ANNETT M, 1972, BRIT J PSYCHOL, V63, P343, DOI 10.1111/j.2044-8295.1972.tb01282.x
   Antal A, 2012, RESTOR NEUROL NEUROS, V30, P255, DOI 10.3233/RNN-2012-110208
   Antal A, 2011, NEUROIMAGE, V55, P590, DOI 10.1016/j.neuroimage.2010.11.085
   Baumgaertner A, 2013, HUM BRAIN MAPP, V34, P1293, DOI 10.1002/hbm.21512
   Baxter BS, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00691
   Beckmann CF, 2003, NEUROIMAGE, V20, P1052, DOI 10.1016/S1053-8119(03)00435-X
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bikson M, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00688
   Binder JR, 2003, J COGNITIVE NEUROSCI, V15, P372, DOI 10.1162/089892903321593108
   Blumstein SE, 2005, J COGNITIVE NEUROSCI, V17, P1353, DOI 10.1162/0898929054985473
   Braber N, 2005, BRAIN LANG, V92, P278, DOI 10.1016/j.bandl.2004.05.012
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Bullmore ET, 2011, ANNU REV CLIN PSYCHO, V7, P113, DOI 10.1146/annurev-clinpsy-040510-143934
   Burton H, 2003, J NEUROPHYSIOL, V90, P1965, DOI 10.1152/jn.00279.2003
   Burton MW, 2001, COGNITIVE SCI, V25, P695, DOI 10.1207/s15516709cog2505_4
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Cole M. W., 2011, Society for Neuroscience Abstract Viewer and Itinerary Planner, V41
   Cornelissen PL, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0005359
   Costanzo F, 2016, RESTOR NEUROL NEUROS, V34, P215, DOI 10.3233/RNN-150561
   Costanzo F, 2016, NEUROREPORT, V27, P295, DOI 10.1097/WNR.0000000000000536
   de Almeida LR, 2019, J NEUROSCI RES, V97, P1430, DOI 10.1002/jnr.24490
   Deng Y, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033337
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Dominguez A, 2014, INT J CLIN HLTH PSYC, V14, P240, DOI 10.1016/j.ijchp.2014.02.001
   Dunst B, 2014, INTELLIGENCE, V42, P22, DOI 10.1016/j.intell.2013.09.005
   Eickhoff SB, 2009, PHILOS T R SOC A, V367, P2399, DOI 10.1098/rsta.2008.0287
   Engstrom M, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00140
   Farahani FV, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00585
   Fiebach CJ, 2002, J COGNITIVE NEUROSCI, V14, P11, DOI 10.1162/089892902317205285
   FIEZ JA, 1995, J COGNITIVE NEUROSCI, V7, P357, DOI 10.1162/jocn.1995.7.3.357
   Fiori V, 2018, NEUROIMAGE, V181, P550, DOI 10.1016/j.neuroimage.2018.07.040
   FORSTER KI, 1973, J VERB LEARN VERB BE, V12, P627, DOI 10.1016/S0022-5371(73)80042-8
   Frazier JA, 2005, AM J PSYCHIAT, V162, P1256, DOI 10.1176/appi.ajp.162.7.1256
   Friston KJ, 2011, BRAIN CONNECT, V1, P13, DOI 10.1089/brain.2011.0008
   Fritsch B, 2010, NEURON, V66, P198, DOI 10.1016/j.neuron.2010.03.035
   Fuertinger S, 2015, PLOS BIOL, V13, DOI 10.1371/journal.pbio.1002209
   Goldstein JM, 2007, BIOL PSYCHIAT, V61, P935, DOI 10.1016/j.biopsych.2006.06.027
   Gur RC, 2000, BRAIN LANG, V74, P157, DOI 10.1006/brln.2000.2325
   Hartwigsen G, 2016, CEREB CORTEX, V26, P2590, DOI 10.1093/cercor/bhv092
   Hartwigsen G, 2013, P NATL ACAD SCI USA, V110, P16402, DOI 10.1073/pnas.1310190110
   Hartwigsen G, 2012, J NEUROSCI, V32, P16162, DOI 10.1523/JNEUROSCI.1010-12.2012
   Heim S, 2005, COGNITIVE BRAIN RES, V25, P982, DOI 10.1016/j.cogbrainres.2005.09.022
   Hickok G, 2009, PHYS LIFE REV, V6, P121, DOI 10.1016/j.plrev.2009.06.001
   Holland R, 2016, NEUROIMAGE, V140, P126, DOI 10.1016/j.neuroimage.2016.01.037
   Holland R, 2011, CURR BIOL, V21, P1403, DOI 10.1016/j.cub.2011.07.021
   Indefrey P, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00255
   Jacobson L, 2012, EXP BRAIN RES, V216, P1, DOI 10.1007/s00221-011-2891-9
   Jansma JM, 2004, SCHIZOPHR RES, V68, P159, DOI 10.1016/S0920-9964(03)00127-0
   Jenkinson M, 2002, NEUROIMAGE, V17, P825, DOI 10.1006/nimg.2002.1132
   Jenkinson M, 2001, MED IMAGE ANAL, V5, P143, DOI 10.1016/S1361-8415(01)00036-6
   Jenkinson M, 2012, NEUROIMAGE, V62, P782, DOI 10.1016/j.neuroimage.2011.09.015
   Johnstone T, 2006, HUM BRAIN MAPP, V27, P779, DOI 10.1002/hbm.20219
   Keuleers E., 2013, VWR USEFUL FUNCTIONS
   Keuleers E, 2010, BEHAV RES METHODS, V42, P627, DOI 10.3758/BRM.42.3.627
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Lakens D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00863
   Lee YS, 2012, J NEUROSCI, V32, P3942, DOI 10.1523/JNEUROSCI.3814-11.2012
   Leonard MK, 2014, TRENDS COGN SCI, V18, P472, DOI 10.1016/j.tics.2014.05.001
   Leuthardt EC, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00099
   Levy J, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006675
   Liakakis G, 2011, BEHAV BRAIN RES, V225, P341, DOI 10.1016/j.bbr.2011.06.022
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Liebenthal E, 2013, J NEUROSCI, V33, P15414, DOI 10.1523/JNEUROSCI.1511-13.2013
   Makris N, 2006, SCHIZOPHR RES, V83, P155, DOI 10.1016/j.schres.2005.11.020
   Mangia AL, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00601
   Marrelec G, 2006, NEUROIMAGE, V32, P228, DOI 10.1016/j.neuroimage.2005.12.057
   MARSHALL JC, 1973, J PSYCHOLINGUIST RES, V2, P175, DOI 10.1007/BF01067101
   McNorgan C, 2015, BRAIN LANG, V141, P110, DOI 10.1016/j.bandl.2014.12.002
   Meinzer M, 2013, J NEUROSCI, V33, P12470, DOI 10.1523/JNEUROSCI.5743-12.2013
   Meinzer M, 2012, J NEUROSCI, V32, P1859, DOI 10.1523/JNEUROSCI.4812-11.2012
   Meinzer M, 2009, J COGNITIVE NEUROSCI, V21, P2007, DOI 10.1162/jocn.2009.21219
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Moineau S, 2005, J SPEECH LANG HEAR R, V48, P884, DOI 10.1044/1092-4388(2005/061)
   Muller NG, 2003, NEUROIMAGE, V20, P1578, DOI 10.1016/S1053-8119(03)00416-6
   neuroConn GmbH, DC STIM MR
   Neurosynth, 2018, NEUROSYNTH SOFTWARE
   Nitsche MA, 2008, BRAIN STIMUL, V1, P206, DOI 10.1016/j.brs.2008.06.004
   Nosarti C, 2010, CEREB CORTEX, V20, P315, DOI 10.1093/cercor/bhp101
   Nozari N, 2014, BRAIN STIMUL, V7, P784, DOI 10.1016/j.brs.2014.07.035
   Nozari N, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0084338
   Okada K, 2006, NEUROREPORT, V17, P1293, DOI 10.1097/01.wnr.0000233091.82536.b2
   Okada K, 2006, BRAIN LANG, V98, P112, DOI 10.1016/j.bandl.2006.04.006
   Optoacoustics Ltd, FOMRI 3 NOIS CANC MI
   Pagnotta MF, 2015, IEEE ENG MED BIO, P6959, DOI 10.1109/EMBC.2015.7319993
   Patterson K, 1987, COGNITIVE NEUROPSYCH, P273
   Pinheiro J., 2017, NLME LINEAR NONLINEA, DOI DOI 10.5194/TC-10-2291-2016
   Pirulli C, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00226
   Pope PA, 2015, CEREB CORTEX, V25, P4551, DOI 10.1093/cercor/bhv094
   Pruim RHR, 2015, NEUROIMAGE, V112, P278, DOI 10.1016/j.neuroimage.2015.02.063
   Pruim RHR, 2015, NEUROIMAGE, V112, P267, DOI 10.1016/j.neuroimage.2015.02.064
   R Core Team, 2017, R LANG ENV STAT COMP
   Raizada RDS, 2007, NEURON, V56, P726, DOI 10.1016/j.neuron.2007.11.001
   Reynolds C., 2007, TEST IRREGULAR WORD
   Rodrigues de Almeida L, 2019, NEURAL CORRELATES EF, DOI DOI 10.1101/522847V2.FULL
   Rogers JC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00754
   Rombouts SARB, 1999, HIPPOCAMPUS, V9, P637, DOI 10.1002/(SICI)1098-1063(1999)9:6<637::AID-HIPO4>3.0.CO;2-V
   Ryali S, 2012, NEUROIMAGE, V59, P3852, DOI 10.1016/j.neuroimage.2011.11.054
   Sandberg CW, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00091
   Saur D, 2006, BRAIN, V129, P1371, DOI 10.1093/brain/awl090
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Schmidt H, 2009, HUM BRAIN MAPP, V30, P3609, DOI 10.1002/hbm.20783
   Smalle EHM, 2015, CEREB CORTEX, V25, P3690, DOI 10.1093/cercor/bhu218
   Smirni D, 2017, NEUROPSYCHOLOGIA, V102, P109, DOI 10.1016/j.neuropsychologia.2017.06.006
   Smith SM, 2002, HUM BRAIN MAPP, V17, P143, DOI 10.1002/hbm.10062
   Smith SM, 2004, NEUROIMAGE, V23, pS208, DOI 10.1016/j.neuroimage.2004.07.051
   Soares JM, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/j.fnins.2016.00515
   Sun YF, 2010, PEDIATR NEONATOL, V51, P89, DOI 10.1016/S1875-9572(10)60017-4
   Tomasi D, 2004, NEUROIMAGE, V23, P1414, DOI 10.1016/j.neuroimage.2004.07.065
   Torgesen J, 1999, TEST WORD READING EF
   Torres J, 2013, RESTOR NEUROL NEUROS, V31, P501, DOI 10.3233/RNN-130314
   Ulm L, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00550
   Vitali P, 2007, NEUROREHAB NEURAL RE, V21, P152, DOI 10.1177/1545968306294735
   Waldie KE, 2013, BRAIN SCI, V3, P1060, DOI 10.3390/brainsci3031060
   Wang S, 2019, CEREB CORTEX, V29, P4312, DOI 10.1093/cercor/bhy313
   Watkins K, 2004, J COGNITIVE NEUROSCI, V16, P978, DOI 10.1162/0898929041502616
   Wheat KL, 2010, J NEUROSCI, V30, P5229, DOI 10.1523/JNEUROSCI.4448-09.2010
   WILLIAMS EJ, 1949, AUST J SCI RES SER A, V2, P149, DOI 10.1071/CH9490149
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Woodhead ZVJ, 2014, CEREB CORTEX, V24, P817, DOI 10.1093/cercor/bhs365
   Woods AJ, 2016, CLIN NEUROPHYSIOL, V127, P1031, DOI 10.1016/j.clinph.2015.11.012
   Woolrich M, 2008, NEUROIMAGE, V41, P286, DOI 10.1016/j.neuroimage.2008.02.042
   Woolrich MW, 2009, NEUROIMAGE, V45, pS173, DOI 10.1016/j.neuroimage.2008.10.055
   Woolrich MW, 2004, NEUROIMAGE, V21, P1732, DOI 10.1016/j.neuroimage.2003.12.023
   Woolrich MW, 2001, NEUROIMAGE, V14, P1370, DOI 10.1006/nimg.2001.0931
   Xiao ZW, 2005, HUM BRAIN MAPP, V25, P212, DOI 10.1002/hbm.20105
   Yarkoni T, 2008, PSYCHON B REV, V15, P971, DOI 10.3758/PBR.15.5.971
   Yarkoni T, 2011, NAT METHODS, V8, P665, DOI [10.1038/NMETH.1635, 10.1038/nmeth.1635]
   Zhu LL, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162158
NR 131
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1612-4782
EI 1612-4790
J9 COGN PROCESS
JI Cogn. Process.
PD AUG
PY 2020
VL 21
IS 3
BP 341
EP 363
DI 10.1007/s10339-020-00964-w
PG 23
WC Psychology, Experimental
SC Psychology
GA MP0XC
UT WOS:000551935500003
PM 32152767
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU McAuley, JD
   Shen, Y
   Dec, S
   Kidd, GR
AF McAuley, J. Devin
   Shen, Yi
   Dec, Sarah
   Kidd, Gary R.
TI Altering the rhythm of target and background talkers differentially
   affects speech understanding
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Attention; Selective; Temporal Processing
ID COORDINATE RESPONSE MEASURE; LINGUISTIC CONTENT; CONCURRENT SOUNDS;
   VARIABLE ACCESS; RECOGNITION; ENTRAINMENT; PERCEPTION; ATTENTION;
   AMPLITUDE; TRACKING
AB Three experiments investigated listeners' ability to use speech rhythm to attend selectively to a single target talker presented in multi-talker babble (Experiments1and2) and in speech-shaped noise (Experiment3). Participants listened to spoken sentences of the form "Ready [Call sign] go to [Color] [Number] now" and reported the Color and Number spoken by a target talker (cued by the Call sign "Baron"). Experiment1altered the natural rhythm of the target talker and background talkers for two-talker and six-talker backgrounds. Experiment2considered parametric rhythm alterations over a wider range, altering the rhythm of either the target or the background talkers. Experiments1and2revealed that altering the rhythm of the target talker, while keeping the rhythm of the background intact, reduced listeners' ability to report the Color and Number spoken by the target talker. Conversely, altering the rhythm of the background talkers, while keeping the target rhythm intact, improved listeners ability to report the Color and Number spoken by the target talker. Experiment3, which embedded the target talker in speech-shaped noise rather than multi-talker babble, similarly reduced recognition of the target sentence with increased alteration of the target rhythm. This pattern of results favors a dynamic-attending theory-based selective-entrainment hypothesis over a disparity-based segregation hypothesis and an increased salience hypothesis.
C1 [McAuley, J. Devin; Dec, Sarah] Michigan State Univ, Dept Psychol, E Lansing, MI 48824 USA.
   [Shen, Yi; Kidd, Gary R.] Indiana Univ, Dept Speech & Hearing Sci, Bloomington, IN 47405 USA.
RP McAuley, JD (corresponding author), Michigan State Univ, Dept Psychol, E Lansing, MI 48824 USA.
EM dmcauley@msu.edu
FU NIDCD NIH HHSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R01DC013538] Funding Source:
   Medline
CR Aubanel V, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00430
   Baese-Berk MM, 2019, ATTEN PERCEPT PSYCHO, V81, P571, DOI 10.3758/s13414-018-1626-4
   Barnes R, 2000, COGNITIVE PSYCHOL, V41, P254, DOI 10.1006/cogp.2000.0738
   Bolia RS, 2000, J ACOUST SOC AM, V107, P1065, DOI 10.1121/1.428288
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   BREGMAN AS, 1985, PERCEPT PSYCHOPHYS, V37, P483, DOI 10.3758/BF03202881
   Calandruccio L, 2014, J AM ACAD AUDIOL, V25, P355, DOI 10.3766/jaaa.25.4.7
   Calandruccio L, 2010, J ACOUST SOC AM, V128, P860, DOI 10.1121/1.3458857
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Darwin CJ, 1975, HASKINS LAB STATUS R, V42-43, P103
   DAUER RM, 1983, J PHONETICS, V11, P51, DOI 10.1016/S0095-4470(19)30776-4
   Dilley LC, 2008, J MEM LANG, V59, P294, DOI 10.1016/j.jml.2008.06.006
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Eddins DA, 2012, J ACOUST SOC AM, V131, pEL177, DOI 10.1121/1.3678680
   Freyman RL, 2004, J ACOUST SOC AM, V115, P2246, DOI 10.1121/1.1689343
   Ghitza O, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00130
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Golumbic EMZ, 2012, BRAIN LANG, V122, P151, DOI 10.1016/j.bandl.2011.12.010
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Horton C, 2013, J NEUROPHYSIOL, V109, P3082, DOI 10.1152/jn.01026.2012
   HUGGINS AWF, 1972, J ACOUST SOC AM, V51, P1279, DOI 10.1121/1.1912972
   Humes LE, 2017, J SPEECH LANG HEAR R, V60, P741, DOI 10.1044/2016_JSLHR-H-16-0042
   Jones MR, 2002, PSYCHOL SCI, V13, P313, DOI 10.1111/1467-9280.00458
   JONES MR, 1989, PSYCHOL REV, V96, P459, DOI 10.1037/0033-295X.96.3.459
   JONES MR, 1981, J EXP PSYCHOL HUMAN, V7, P1059, DOI 10.1037/0096-1523.7.5.1059
   JONES MR, 1976, PSYCHOL REV, V83, P323, DOI 10.1037/0033-295X.83.5.323
   Kashino M., 1996, J ACOUST SOC AM, V99, P2596, DOI [10.1121/1.415287, DOI 10.1121/1.415287]
   Kidd Gary R., 2014, Journal of the Acoustical Society of America, V136, DOI 10.1121/1.4900367
   KIDD GR, 1989, J EXP PSYCHOL HUMAN, V15, P736, DOI 10.1037/0096-1523.15.4.736
   Large EW, 1999, PSYCHOL REV, V106, P119, DOI 10.1037/0033-295X.106.1.119
   MARIN CMH, 1991, J ACOUST SOC AM, V89, P341, DOI 10.1121/1.400469
   MCADAMS S, 1989, J ACOUST SOC AM, V86, P2148, DOI 10.1121/1.398475
   McAuley JD, 2006, J EXP PSYCHOL GEN, V135, P348, DOI 10.1037/0096-3445.135.3.348
   McAuley JD, 2003, J EXP PSYCHOL HUMAN, V29, P1102, DOI 10.1037/0096-1523.29.6.1102
   Middlebrooks J. C., 2017, AUDITORY SYSTEM COCK
   Miller JE, 2013, PSYCHOL SCI, V24, P11, DOI 10.1177/0956797612446707
   Morrill TH, 2014, COGNITION, V131, P69, DOI 10.1016/j.cognition.2013.12.006
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Richards VM, 2013, J ACOUST SOC AM, V134, pEL237, DOI 10.1121/1.4813591
   Riecke L, 2018, CURR BIOL, V28, P161, DOI 10.1016/j.cub.2017.11.033
   Rimmele J, 2012, HEARING RES, V289, P98, DOI 10.1016/j.heares.2012.04.006
   Rimmele J, 2011, J COGNITIVE NEUROSCI, V23, P1136, DOI 10.1162/jocn.2010.21437
   Rimmele JM, 2015, CORTEX, V68, P144, DOI 10.1016/j.cortex.2014.12.014
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Rosen S, 2013, J ACOUST SOC AM, V133, P2431, DOI 10.1121/1.4794379
   SMITH MR, 1989, J SPEECH HEAR RES, V32, P912, DOI 10.1044/jshr.3204.912
   Snyder JS, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00015
   Tilsen S, 2013, J ACOUST SOC AM, V134, P628, DOI 10.1121/1.4807565
   Van Engen KJ, 2007, J ACOUST SOC AM, V121, P519, DOI 10.1121/1.2400666
   Wang MY, 2018, J ACOUST SOC AM, V143, pEL255, DOI 10.1121/1.5030518
   Zeng FG, 2005, P NATL ACAD SCI USA, V102, P2293, DOI 10.1073/pnas.0406460102
   Zhong X, 2017, J ACOUST SOC AM, V141, P2882, DOI 10.1121/1.4981118
NR 56
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD AUG
PY 2020
VL 82
IS 6
BP 3222
EP 3233
DI 10.3758/s13414-020-02064-5
PG 12
WC Psychology; Psychology, Experimental
SC Psychology
GA MP1VO
UT WOS:000551999300033
PM 32458224
DA 2021-02-24
ER

PT J
AU Martin, AE
AF Martin, Andrea E.
TI A Compositional Neural Architecture for Language
SO JOURNAL OF COGNITIVE NEUROSCIENCE
LA English
DT Article
ID NEURONAL OSCILLATIONS; CORTICAL OSCILLATIONS; BRAIN OSCILLATIONS;
   BAYESIAN-INFERENCE; SPEECH-PERCEPTION; LEXICAL ACCESS; RETRIEVAL;
   BINDING; MODEL; COMPREHENSION
AB Hierarchical structure and compositionality imbue human language with unparalleled expressive power and set it apart from other perception-action systems. However, neither formal nor neurobiological models account for how these defining computational properties might arise in a physiological system. I attempt to reconcile hierarchy and compositionality with principles from cell assembly computation in neuroscience; the result is an emerging theory of how the brain could convert distributed perceptual representations into hierarchical structures across multiple timescales while representing interpretable incremental stages of (de)compositional meaning. The model's architecture-a multidimensional coordinate system based on neurophysiological models of sensory processing-proposes that a manifold of neural trajectories encodes sensory, motor, and abstract linguistic states. Gain modulation, including inhibition, tunes the path in the manifold in accordance with behavior and is how latent structure is inferred. As a consequence, predictive information about upcoming sensory input during production and comprehension is available without a separate operation. The proposed processing mechanism is synthesized from current models of neural entrainment to speech, concepts from systems neuroscience and category theory, and a symbolic-connectionist computational model that uses time and rhythm to structure information. I build on evidence from cognitive neuroscience and computational modeling that suggests a formal and mechanistic alignment between structure building and neural oscillations, and moves toward unifying basic insights from linguistics and psycholinguistics with the currency of neural computation.
C1 [Martin, Andrea E.] Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
   [Martin, Andrea E.] Radboud Univ Nijmegen, Donders Ctr Cognit Neuroimaging, Nijmegen, Netherlands.
RP Martin, AE (corresponding author), Max Planck Inst Psycholinguist, Language & Computat Neural Syst Grp, Wundtlaan 1, NL-6525 XD Nijmegen, Netherlands.
EM andrea.martin@mpi.nl
FU Max Planck Research Group "Language and Computation in Neural Systems";
   Netherlands Organization for Scientific ResearchNetherlands Organization
   for Scientific Research (NWO) [016, Vidi.188.029]
FX A. E. M. was supported by the Max Planck Research Group "Language and
   Computation in Neural Systems" and by the Netherlands Organization for
   Scientific Research (Grant 016. Vidi.188.029). The figures were created
   in collaboration with the graphic designer Robert Jan van Oosten
   (www.rjvanoosten.nl).
CR Aggelopoulos NC, 2015, NEUROSCI BIOBEHAV R, V55, P375, DOI 10.1016/j.neubiorev.2015.05.001
   Alday P. M., 2017, 24 ANN M COGN NEUR S
   AMARI S, 1991, NEURAL NETWORKS, V4, P443, DOI 10.1016/0893-6080(91)90040-C
   ANDERSEN RA, 1985, SCIENCE, V230, P456, DOI 10.1126/science.4048942
   ANDERSEN RA, 1983, J NEUROSCI, V3, P532
   Andersen RA, 1997, ANNU REV NEUROSCI, V20, P303, DOI 10.1146/annurev.neuro.20.1.303
   Anumanchipalli GK, 2019, NATURE, V568, P493, DOI 10.1038/s41586-019-1119-1
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Assaneo MF, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aao3842
   Baggio G, 2018, MEANING IN THE BRAIN
   Ballard D., 2015, BRAIN COMPUTATION HI
   Bastiaansen M, 2006, PROG BRAIN RES, V159, P179, DOI 10.1016/S0079-6123(06)59012-0
   Bastiaansen MCM, 2008, BRAIN LANG, V106, P15, DOI 10.1016/j.bandl.2007.10.006
   Bastiaansen MCM, 2005, J COGNITIVE NEUROSCI, V17, P530, DOI 10.1162/0898929053279469
   Beck JM, 2008, NEURON, V60, P1142, DOI 10.1016/j.neuron.2008.09.021
   Bever TG, 2010, BIOLINGUISTICS, V4, P174
   Blokpoel M, 2018, TOP COGN SCI, V10, P641, DOI 10.1111/tops.12282
   Boeckx C, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00282
   Bradley T. D., 2018, ARXIV180905923
   Brennan JR, 2020, PHILOS T R SOC B, V375, DOI 10.1098/rstb.2019.0305
   Bressler SL, 2001, TRENDS COGN SCI, V5, P26, DOI 10.1016/S1364-6613(00)01564-3
   Bressler SL, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00397
   Bucher D, 2006, J NEUROPHYSIOL, V95, P3617, DOI 10.1152/jn.00004.2006
   Buzsaki G., 2006, RHYTHMS BRAIN
   Buzsaki G., 2019, BRAIN INSIDE OUT
   Buzsaki G, 2015, NAT NEUROSCI, V18, P484, DOI 10.1038/nn.3952
   Buzsaki G, 2012, ANNU REV NEUROSCI, V35, P203, DOI 10.1146/annurev-neuro-062111-150444
   Buzsaki G, 2010, NEURON, V68, P362, DOI 10.1016/j.neuron.2010.09.023
   Carandini M, 2012, NAT REV NEUROSCI, V13, P51, DOI 10.1038/nrn3136
   Carrasco M, 2004, NAT NEUROSCI, V7, P308, DOI 10.1038/nn1194
   Chang EF, 2011, J COGNITIVE NEUROSCI, V23, P1437, DOI 10.1162/jocn.2010.21466
   Cheung C, 2016, ELIFE, V5, DOI 10.7554/eLife.12577
   Choi K, 2010, BIOCHEM RES TRENDS, P209
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Chomsky N., 1957, REV VERBAL BEHAV BF, V35, P26
   Cole SR, 2017, TRENDS COGN SCI, V21, P137, DOI 10.1016/j.tics.2016.12.008
   Cutter MG, 2020, J EXP PSYCHOL LEARN, V46, P1146, DOI 10.1037/xlm0000780
   DELL GS, 1986, PSYCHOL REV, V93, P283, DOI 10.1037/0033-295X.93.3.283
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Doumas L. A. A., 2012, OXFORD HDB THINKING, V19
   Doumas L. A. A., 2017, WE LEARN THINGS WE D
   Doumas LA, 2005, CAMBRIDGE HDB THINKI, P73, DOI DOI 10.1007/S13398-014-0173-7.2
   Doumas LAA, 2008, PSYCHOL REV, V115, P1, DOI 10.1037/0033-295X.115.1.1
   Doumas LAA, 2018, PSYCHOL LEARN MOTIV, V69, P165, DOI 10.1016/bs.plm.2018.10.002
   Embick D, 2015, LANG COGN NEUROSCI, V30, P357, DOI 10.1080/23273798.2014.980750
   Engel TA, 2019, CURR OPIN NEUROBIOL, V58, P181, DOI 10.1016/j.conb.2019.09.003
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   FERREIRA F, 1986, J MEM LANG, V25, P348, DOI 10.1016/0749-596X(86)90006-9
   FODOR JA, 1988, COGNITION, V28, P3, DOI 10.1016/0010-0277(88)90031-5
   Fox N. P., 2017, J ACOUST SOC AM, V141, P3571
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8
   Friederici AD, 2015, TRENDS COGN SCI, V19, P329, DOI 10.1016/j.tics.2015.03.012
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   Fries P, 2009, ANNU REV NEUROSCI, V32, P209, DOI 10.1146/annurev.neuro.051508.135603
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   Gallistel C.R., 1990, ORG LEARNING LEARNIN
   Gamez J, 2019, PLOS BIOL, V17, DOI 10.1371/journal.pbio.3000054
   Gershman SJ, 2010, CURR OPIN NEUROBIOL, V20, P251, DOI 10.1016/j.conb.2010.02.008
   Ghazanfar AA, 2006, TRENDS COGN SCI, V10, P278, DOI 10.1016/j.tics.2006.04.008
   Ghitza O, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00138
   Ghitza O, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00130
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Gwilliams L, 2018, J NEUROSCI, V38, P7585, DOI 10.1523/JNEUROSCI.0065-18.2018
   Haegens S, 2018, NEUROSCI BIOBEHAV R, V86, P150, DOI 10.1016/j.neubiorev.2017.12.002
   Haegens S, 2011, J NEUROSCI, V31, P5197, DOI 10.1523/JNEUROSCI.5199-10.2011
   Hagoort P, 2003, NEUROIMAGE, V20, pS18, DOI 10.1016/j.neuroimage.2003.09.013
   Hagoort P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00416
   Hald LA, 2006, BRAIN LANG, V96, P90, DOI 10.1016/j.bandl.2005.06.007
   Halgren M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20662-0
   HALLE M, 1962, IRE T INFORM THEOR, V8, P155, DOI 10.1109/TIT.1962.1057686
   HALLE M, 1962, WORD, V18, P54, DOI 10.1080/00437956.1962.11659765
   Hanslmayr S, 2014, NEUROIMAGE, V85, P648, DOI 10.1016/j.neuroimage.2013.05.121
   Hebb D. O., 1949, ORG BEHAV NEUROPSYCH
   Heffner CC, 2013, LANG COGNITIVE PROC, V28, P1275, DOI 10.1080/01690965.2012.672229
   Helmholtz H. V., 1867, HDB PHYSL OPTIK, V9
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   HOLLAND JH, 1986, INDUCTION PROCESSES
   Holyoak KJ, 2000, COGNITIVE DYNAMICS, P229
   HOOPER SL, 1989, SCIENCE, V244, P1587, DOI 10.1126/science.2740903
   Hornstein N., 1984, LOGIC GRAMMAR
   Hummel JE, 1997, PSYCHOL REV, V104, P427, DOI 10.1037/0033-295X.104.3.427
   Hummel JE, 2003, PSYCHOL REV, V110, P220, DOI 10.1037/0033-295X.110.2.220
   Hummel JE, 2011, CONNECT SCI, V23, P109, DOI 10.1080/09540091.2011.569880
   Jazayeri M, 2007, J VISION, V7, DOI 10.1167/7.12.7
   Jazayeri M, 2008, CURR OPIN NEUROBIOL, V18, P431, DOI 10.1016/j.conb.2008.09.004
   Jonas P., 2007, SCHOLARPEDIA, V2, P3286, DOI DOI 10.4249/SCHOLARPEDIA.3286
   Kaplan DM, 2011, SYNTHESE, V183, P339, DOI 10.1007/s11229-011-9970-0
   Kaplan DM, 2011, PHILOS SCI, V78, P601, DOI 10.1086/661755
   Kaufeld G, 2020, LANG COGN NEUROSCI, V35, P933, DOI 10.1080/23273798.2019.1701691
   Kaufeld G, 2020, J EXP PSYCHOL LEARN, V46, P549, DOI 10.1037/xlm0000744
   Keitel A, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002498
   Kempen G, 2014, NEUROINFORMATICS, V12, P111, DOI 10.1007/s12021-013-9191-4
   Kim D. O., 1986, AUDITORY FREQUENCY S, P281, DOI [10.1007/978-1-4613-2247-4_31, DOI 10.1007/978-1-4613-2247-4_31]
   Kracht M., 1992, LOGIC GROUP PREPRINT, V75
   Kratzer A, 1998, SEMANTICS GENERATIVE, V1185
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Lakatos P, 2007, NEURON, V53, P279, DOI 10.1016/j.neuron.2006.12.011
   Larson R. K., 2009, GRAMMAR SCI
   Lenneberg E. H., 1967, BIOL FDN LANGUAGE
   Leonard MK, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13619
   Ling S, 2009, VISION RES, V49, P1194, DOI 10.1016/j.visres.2008.05.025
   Lisman JE, 2013, NEURON, V77, P1002, DOI 10.1016/j.neuron.2013.03.007
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Ma WJ, 2006, NAT NEUROSCI, V9, P1432, DOI 10.1038/nn1790
   Ma WJ, 2012, TRENDS COGN SCI, V16, P511, DOI 10.1016/j.tics.2012.08.010
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676
   Marcus G., 2001, ALGEBRAIC MIND
   Marder E, 2012, NEURON, V76, P1, DOI 10.1016/j.neuron.2012.09.010
   MARSLENWILSON W, 1980, COGNITION, V8, P1, DOI 10.1016/0010-0277(80)90015-3
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X
   Martin AE, 2008, J MEM LANG, V58, P879, DOI 10.1016/j.jml.2007.06.010
   Martin AE, 2020, PHILOS T R SOC B, V375, DOI 10.1098/rstb.2019.0306
   Martin AE, 2019, CURR OPIN BEHAV SCI, V29, P77, DOI 10.1016/j.cobeha.2019.04.008
   Martin AE, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206616
   Martin AE, 2018, LANG COGN NEUROSCI, V33, P769, DOI 10.1080/23273798.2018.1427877
   Martin AE, 2017, LANG SPEECH, V60, P356, DOI 10.1177/0023830916650714
   Martin AE, 2017, PLOS BIOL, V15, DOI 10.1371/journal.pbio.2000663
   Martin AE, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00120
   Martin AE, 2011, J MEM LANG, V64, P327, DOI 10.1016/j.jml.2010.12.006
   Martin AE, 2009, J EXP PSYCHOL LEARN, V35, P1231, DOI 10.1037/a0016271
   Meyer L, 2020, LANG COGN NEUROSCI, V35, P1089, DOI 10.1080/23273798.2019.1693050
   Meyer L, 2018, EUR J NEUROSCI, V48, P2609, DOI 10.1111/ejn.13748
   Meyer L, 2017, CEREB CORTEX, V27, P4293, DOI 10.1093/cercor/bhw228
   Morillon B, 2009, J NEUROSCI, V29, P14803, DOI 10.1523/JNEUROSCI.3222-09.2009
   Murphy E., 2018, TALKING SPECIES PERS, P251
   Nelson MJ, 2017, P NATL ACAD SCI USA, V114, pE3669, DOI 10.1073/pnas.1701590114
   Nieuwland MS, 2007, J COGNITIVE NEUROSCI, V19, P228, DOI 10.1162/jocn.2007.19.2.228
   Nieuwland MS, 2006, J COGNITIVE NEUROSCI, V18, P1098, DOI 10.1162/jocn.2006.18.7.1098
   Nieuwland MS, 2012, COGNITION, V122, P102, DOI 10.1016/j.cognition.2011.09.001
   O'Flaherty W. D., 1981, RIG VEDA ANTHOLOGY O
   Obleser J, 2019, TRENDS COGN SCI, V23, P913, DOI 10.1016/j.tics.2019.08.004
   Obleser J, 2011, NEUROIMAGE, V56, P2310, DOI 10.1016/j.neuroimage.2011.03.035
   Olshausen B. A., 2014, COGNITIVE NEUROSCIEN, P295
   PARTEE B, 1975, LINGUIST INQ, V6, P203
   Partee B. B., 2012, MATH METHODS LINGUIS, V30
   Partee Barbara H., 1984, VARIETIES FORMAL SEM, V3, P281
   Pauls A., 2012, P 50 ANN M ASS COMP, V1, P959
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Phillips S, 2020, PHILOS T R SOC B, V375, DOI 10.1098/rstb.2019.0303
   Phillips S, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000858
   Piccinini G, 2007, PHILOS SCI, V74, P501, DOI 10.1086/522851
   Pikovsky A., 2007, SCHOLARPEDIA, V2, P1459, DOI DOI 10.4249/SCHOLARPEDIA.1459
   Poeppel D, 2011, LANG COGNITIVE PROC, V26, P935, DOI 10.1080/01690965.2010.493301
   Ramon y Cajal S., 1928, DEGENERATION REGENER
   Rimmele JM, 2018, TRENDS COGN SCI, V22, P870, DOI 10.1016/j.tics.2018.08.003
   Robins R. H., 2013, SHORT HIST LINGUISTI
   Rumelhart D. E., 1987, PARALLEL DISTRIBUTED, V1, P184
   Salinas E, 2001, Prog Brain Res, V130, P175
   Salinas E, 2001, NEUROSCIENTIST, V7, P430, DOI 10.1177/107385840100700512
   Salinas Emilio, 2000, Neuron, V27, P15, DOI 10.1016/S0896-6273(00)00004-0
   Schotter ER, 2012, ATTEN PERCEPT PSYCHO, V74, P5, DOI 10.3758/s13414-011-0219-2
   Schroeder CE, 2009, TRENDS NEUROSCI, V32, P9, DOI 10.1016/j.tins.2008.09.012
   Shastri L, 1999, APPL INTELL, V11, P79, DOI 10.1023/A:1008380614985
   Singer W, 1999, NEURON, V24, P49, DOI 10.1016/S0896-6273(00)80821-1
   Skipper JI, 2015, COGNITIVE NEUROSCIENCE OF NATURAL LANGUAGE USE, P101
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Smith EC, 2006, NATURE, V439, P978, DOI 10.1038/nature04485
   Spitzer B, 2017, ENEURO, V4, DOI 10.1523/ENEURO.0170-17.2017
   Sporns O, 2004, PLOS BIOL, V2, P1910, DOI 10.1371/journal.pbio.0020369
   Sternberg S, 1969, ACTA PSYCHOL, V30, P276, DOI 10.1016/0001-6918(69)90055-9
   Sturt P, 2003, J MEM LANG, V48, P542, DOI 10.1016/S0749-596X(02)00536-3
   Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788
   Tian X, 2015, J COGNITIVE NEUROSCI, V27, P352, DOI 10.1162/jocn_a_00692
   Tian X, 2013, J COGNITIVE NEUROSCI, V25, P1020, DOI 10.1162/jocn_a_00381
   van Alphen PM, 2006, J EXP PSYCHOL HUMAN, V32, P178, DOI 10.1037/0096-1523.32.1.178
   van Rooij I., 2019, COGNITION INTRACTABI
   van Rooij I, 2008, COGNITIVE SCI, V32, P939, DOI 10.1080/03640210801897856
   VanRullen R, 2003, TRENDS COGN SCI, V7, P207, DOI 10.1016/S1364-6613(03)00095-0
   Veldre A, 2018, J MEM LANG, V100, P1, DOI 10.1016/j.jml.2017.12.002
   von der Malsburg C, 1999, NEURON, V24, P95, DOI 10.1016/S0896-6273(00)80825-9
   VONDERMALSBURG C, 1995, CURR OPIN NEUROBIOL, V5, P520, DOI 10.1016/0959-4388(95)80014-X
   Vosse T, 2000, COGNITION, V75, P105, DOI 10.1016/S0010-0277(00)00063-9
   WEIMANN JM, 1994, CURR BIOL, V4, P896, DOI 10.1016/S0960-9822(00)00199-8
   Yuille A, 2006, TRENDS COGN SCI, V10, P301, DOI 10.1016/j.tics.2006.05.002
   ZIPSER D, 1988, NATURE, V331, P679, DOI 10.1038/331679a0
NR 180
TC 6
Z9 6
U1 7
U2 14
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0898-929X
EI 1530-8898
J9 J COGNITIVE NEUROSCI
JI J. Cogn. Neurosci.
PD AUG
PY 2020
VL 32
IS 8
BP 1407
EP 1427
DI 10.1162/jocn_a_01552
PG 21
WC Neurosciences; Psychology, Experimental
SC Neurosciences & Neurology; Psychology
GA MD9ZL
UT WOS:000544324200001
PM 32108553
OA Green Published
DA 2021-02-24
ER

PT J
AU Frost, RLA
   Jessop, A
   Durrant, S
   Peter, MS
   Bidgood, A
   Pine, JM
   Rowland, CF
   Monaghan, P
AF Frost, Rebecca L. A.
   Jessop, Andrew
   Durrant, Samantha
   Peter, Michelle S.
   Bidgood, Amy
   Pine, Julian M.
   Rowland, Caroline F.
   Monaghan, Padraic
TI Non-adjacent dependency learning in infancy, and its link to language
   development
SO COGNITIVE PSYCHOLOGY
LA English
DT Article
DE Language acquisition; Artificial grammar learning; Speech segmentation;
   Individual differences; Statistical learning; Vocabulary development
ID INDIVIDUAL-DIFFERENCES; WORD SEGMENTATION; SPEECH-PERCEPTION; PRIOR
   EXPERIENCE; VOCABULARY; CUES; HYPOTHESIS; PATTERNS; SKILLS
AB To acquire language, infants must learn how to identify words and linguistic structure in speech. Statistical learning has been suggested to assist both of these tasks. However, infants' capacity to use statistics to discover words and structure together remains unclear. Further, it is not yet known how infants' statistical learning ability relates to their language development. We trained 17-month-old infants on an artificial language comprising non-adjacent dependencies, and examined their looking times on tasks assessing sensitivity to words and structure using an eye-tracked head-turn-preference paradigm. We measured infants' vocabulary size using a Communicative Development Inventory (CDI) concurrently and at 19, 21, 24, 25, 27, and 30 months to relate performance to language development. Infants could segment the words from speech, demonstrated by a significant difference in looking times to words versus part-words. Infants' segmentation performance was significantly related to their vocabulary size (receptive and expressive) both currently, and over time (receptive until 24 months, expressive until 30 months), but was not related to the rate of vocabulary growth. The data also suggest infants may have developed sensitivity to generalised structure, indicating similar statistical learning mechanisms may contribute to the discovery of words and structure in speech, but this was not related to vocabulary size.
C1 [Frost, Rebecca L. A.; Jessop, Andrew; Rowland, Caroline F.] Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
   [Durrant, Samantha; Peter, Michelle S.; Pine, Julian M.; Rowland, Caroline F.] Univ Liverpool, Liverpool, Merseyside, England.
   [Bidgood, Amy] Univ Salford, Salford, Lancs, England.
   [Monaghan, Padraic] Univ Amsterdam, Amsterdam, Netherlands.
   [Monaghan, Padraic] Univ Lancaster, Lancaster, England.
RP Frost, RLA (corresponding author), Max Planck Inst Psycholinguist, Language Dev Dept, NL-6525 XD Nijmegen, Netherlands.
EM rebecca.frost@mpi.nl
RI Monaghan, Padraic/E-6812-2010
OI Monaghan, Padraic/0000-0003-3965-2682
FU International Centre for Language and Communicative Development (LuCiD)
   at Lancaster University; University of Liverpool - Economic and Social
   Research Council (UK) [ES/L008955/1]
FX This work was supported by the International Centre for Language and
   Communicative Development (LuCiD) at Lancaster University and the
   University of Liverpool, funded by the Economic and Social Research
   Council (UK) [ES/L008955/1].
CR Alcock K., 2020, UK COMMUNICATIVE DEV
   Aslin RN, 1998, PSYCHOL SCI, V9, P321, DOI 10.1111/1467-9280.00063
   Aslin RN, 1996, SIGNAL TO SYNTAX: BOOTSTRAPPING FROM SPEECH TO GRAMMAR IN EARLY ACQUISITION, P117
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bion RAH, 2013, COGNITION, V126, P39, DOI 10.1016/j.cognition.2012.08.008
   Black A. W., 1990, FESTIVAL SPEECH SYNT
   Bortfeld H, 2005, PSYCHOL SCI, V16, P298, DOI 10.1111/j.0956-7976.2005.01531.x
   Christiansen MH, 2012, LANG COGNITIVE PROC, V27, P231, DOI 10.1080/01690965.2011.606666
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Conway CM, 2010, COGNITION, V114, P356, DOI 10.1016/j.cognition.2009.10.009
   Cooper SR, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01482
   Cristia A, 2014, CHILD DEV, V85, P1330, DOI 10.1111/cdev.12193
   Endress AD, 2007, COGNITION, V105, P247, DOI 10.1016/j.cognition.2006.09.010
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   Frost R. L. A., 2019, P 41 ANN C COGN SCI
   Frost RLA, 2019, J EXP PSYCHOL LEARN, V45, P1883, DOI 10.1037/xlm0000683
   Frost RLA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169538
   Frost RLA, 2016, COGNITION, V147, P70, DOI 10.1016/j.cognition.2015.11.010
   Gerken L, 2006, COGNITION, V98, pB67, DOI 10.1016/j.cognition.2005.03.003
   Gerken L, 2010, COGNITION, V115, P362, DOI 10.1016/j.cognition.2010.01.006
   Gomez R, 2005, INFANCY, V7, P183, DOI 10.1207/s15327078in0702_4
   Gomez RL, 2006, PSYCHOL SCI, V17, P670, DOI 10.1111/j.1467-9280.2006.01764.x
   Gomez RL, 1999, COGNITION, V70, P109, DOI 10.1016/S0010-0277(99)00003-7
   Gomez RL, 2002, PSYCHOL SCI, V13, P431, DOI 10.1111/1467-9280.00476
   Houston-Price C, 2004, INFANT CHILD DEV, V13, P341, DOI 10.1002/icd.364
   Hunter M. A., 1988, ADV INFANCY RES, V5, P69, DOI DOI 10.1037/0012-1649.19.3.338
   Johnson EK, 2001, J MEM LANG, V44, P548, DOI 10.1006/jmla.2000.2755
   Johnson EK, 2009, DEVELOPMENTAL SCI, V12, P131, DOI 10.1111/j.1467-7687.2008.00740.x
   Junge C, 2012, DEVELOPMENTAL SCI, V15, P463, DOI 10.1111/j.1467-7687.2012.1144.x
   JUSCZYK PW, 1995, COGNITIVE PSYCHOL, V29, P1, DOI 10.1006/cogp.1995.1010
   Kidd E, 2018, INFANCY, V23, P770, DOI 10.1111/infa.12256
   Kidd E, 2016, CHILD DEV, V87, P184, DOI 10.1111/cdev.12461
   Kidd E, 2012, DEV PSYCHOL, V48, P171, DOI 10.1037/a0025405
   Lany J., 2019, J CHILD LANG, V13, P1
   Lany J, 2007, COGNITIVE SCI, V31, P481, DOI 10.1080/15326900701326584
   Lany J, 2014, CHILD DEV, V85, P1727, DOI 10.1111/cdev.12199
   Lany J, 2008, PSYCHOL SCI, V19, P1247, DOI 10.1111/j.1467-9280.2008.02233.x
   Lashley K. S., 1951, CEREBRAL MECH BEHAV, P112, DOI DOI 10.1093/RFS/HHQ153
   Luke SG, 2017, BEHAV RES METHODS, V49, P1494, DOI 10.3758/s13428-016-0809-y
   Marchetto E, 2015, J CHILD LANG, V42, P873, DOI 10.1017/S0305000914000452
   Marchetto E, 2013, COGNITIVE PSYCHOL, V67, P130, DOI 10.1016/j.cogpsych.2013.08.001
   Marcus GF, 1999, SCIENCE, V283, P77, DOI 10.1126/science.283.5398.77
   Meints K., 2001, TODDLER COMMUNICATIV
   Mirman D., 2014, GROWTH CURVE ANAL VI
   Misyak JB, 2010, TOP COGN SCI, V2, P138, DOI 10.1111/j.1756-8765.2009.01072.x
   Molfese DL, 2000, BRAIN LANG, V72, P238, DOI 10.1006/brln.2000.2287
   Molfese DL, 1997, DEV NEUROPSYCHOL, V13, P135, DOI 10.1080/87565649709540674
   Monaghan P, 2007, COGNITIVE PSYCHOL, V55, P259, DOI 10.1016/j.cogpsych.2006.12.001
   Monaghan P, 2017, TOP COGN SCI, V9, P21, DOI 10.1111/tops.12239
   Mueller JL, 2010, COGNITIVE SCI, V34, P338, DOI 10.1111/j.1551-6709.2009.01093.x
   Nakagawa S, 2017, J R SOC INTERFACE, V14, DOI 10.1098/rsif.2017.0213
   NELSON DGK, 1995, INFANT BEHAV DEV, V18, P111
   Newman R, 2006, DEV PSYCHOL, V42, P643, DOI 10.1037/0012-1649.42.4.643
   Newman RS, 2016, J CHILD LANG, V43, P1158, DOI 10.1017/S0305000915000446
   Newport EL, 2004, COGNITIVE PSYCHOL, V48, P127, DOI 10.1016/S0010-0285(03)00128-2
   Onnis L, 2005, J MEM LANG, V53, P225, DOI 10.1016/j.jml.2005.02.011
   Panter A. T., 1992, CONTEXT EFFECTS SOCI
   Pelucchi B, 2009, CHILD DEV, V80, P674, DOI 10.1111/j.1467-8624.2009.01290.x
   Pena M, 2002, SCIENCE, V298, P604, DOI 10.1126/science.1072901
   Perruchet P, 2004, J EXP PSYCHOL GEN, V133, P573, DOI 10.1037/0096-3445.133.4.573
   Peter MS, 2019, COGNITIVE PSYCHOL, V115, DOI 10.1016/j.cogpsych.2019.101238
   R Core Team, 2018, R LANG ENV STAT COMP
   Redington M, 1997, TRENDS COGN SCI, V1, P273, DOI 10.1016/S1364-6613(97)01081-4
   Rivera-Gaxiola M, 2005, NEUROREPORT, V16, P495, DOI 10.1097/00001756-200504040-00015
   Rogers T.T., 2018, P 42 ANN C COGN, P1856
   RUBENSTEIN H, 1973, COMMUNICATION LANGUA, P185
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Saffran JR, 1997, PSYCHOL SCI, V8, P101, DOI 10.1111/j.1467-9280.1997.tb00690.x
   Schwab JF, 2016, WIRES COGN SCI, V7, P264, DOI 10.1002/wcs.1393
   Singh L, 2012, DEVELOPMENTAL SCI, V15, P482, DOI 10.1111/j.1467-7687.2012.01141.x
   Thiessen ED, 2003, DEV PSYCHOL, V39, P706, DOI 10.1037/0012-1649.39.4.706
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
NR 74
TC 2
Z9 2
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0010-0285
EI 1095-5623
J9 COGNITIVE PSYCHOL
JI Cogn. Psychol.
PD AUG
PY 2020
VL 120
AR 101291
DI 10.1016/j.cogpsych.2020.101291
PG 19
WC Psychology; Psychology, Experimental
SC Psychology
GA LU2XF
UT WOS:000537623800004
PM 32197131
OA Green Accepted, Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Tang, M
   Huang, ZL
   Zhong, F
   Xiang, JL
   Wang, XD
AF Tang, Mi
   Huang, Zheng-Lan
   Zhong, Fei
   Xiang, Jing-Lan
   Wang, Xiao-Dong
TI One-week phonemic training rebuilds the memory traces of merged phonemes
   in merged speakers
SO BRAIN RESEARCH
LA English
DT Article
DE Phonemic merger; Mismatch negativity; Phonological training; Memory
   trace; Pre-attentive
ID MISMATCH NEGATIVITY MMN; LINGUISTIC EXPERIENCE; SPEECH-PERCEPTION;
   NOVELTY DETECTION; BRAIN RESPONSES; JAPANESE; PLASTICITY;
   REPRESENTATIONS; DISCRIMINATION; INFANTS
AB The phonemic merger is a unique phenomenon which is referred to as acoustically very different phonemes are recognized as the same phoneme. In our previous study, we demonstrated that the merged speakers had lost the ability to discriminate the merged phonemes pre-attentively, as revealed by their failure in mismatch negativity (MMN) elicitation in the oddball stream of the merged phonemes /n/-/l/. In this study, we investigated the recovery of the discrimination ability via phonemic training and found that the merged speakers regained the ability of discriminating merged phonemes pre-attentively, after a 7-day /n/-/l/ phonemic training, as revealed by the reactivation of MMN brain response to the /n/-/l/ phoneme categories. Our finding indicates that separate memory traces of merged phonemes could be rebuilt during the training process.
C1 [Tang, Mi; Huang, Zheng-Lan; Zhong, Fei; Xiang, Jing-Lan; Wang, Xiao-Dong] Southwest Univ, Fac Psychol, 2 Tiansheng Rd,PSY-105, Chongqing 400715, Peoples R China.
RP Wang, XD (corresponding author), Southwest Univ, Fac Psychol, 2 Tiansheng Rd,PSY-105, Chongqing 400715, Peoples R China.
EM wxd@mail.ustc.edu.cn
CR Brunelliere A, 2011, BRAIN LANG, V117, P45, DOI 10.1016/j.bandl.2010.12.004
   Calcus A, 2015, CLIN NEUROPHYSIOL, V126, P1727, DOI 10.1016/j.clinph.2014.11.020
   Ceponiene R, 2004, PSYCHOPHYSIOLOGY, V41, P130, DOI 10.1111/j.1469-8986.2003.00138.x
   Chechik G, 1998, NEURAL COMPUT, V10, P1759, DOI 10.1162/089976698300017124
   Cheour M, 1998, NAT NEUROSCI, V1, P351, DOI 10.1038/1561
   Cheour M, 2001, AUDIOL NEURO-OTOL, V6, P2, DOI 10.1159/000046804
   Colin C, 2009, BALKAN REGIONAL CONFERENCE ON ENGINEERING AND BUSINESS EDUCATION & ICEBE, VOLS I AND II, CONFERENCE PROCEEDINGS, P3
   Conrey B, 2005, BRAIN LANG, V95, P435, DOI 10.1016/j.bandl.2005.06.008
   COWAN N, 1993, J EXP PSYCHOL LEARN, V19, P909, DOI 10.1037/0278-7393.19.4.909
   Cutler A, 2005, SPEECH COMMUN, V47, P32, DOI 10.1016/j.specom.2005.02.001
   Dufour S, 2007, J ACOUST SOC AM, V121, pEL131, DOI 10.1121/1.2710742
   Froemke RC, 2007, NATURE, V450, P425, DOI 10.1038/nature06289
   Froyen D, 2010, FRONT INTEGR NEUROSC, V4, DOI 10.3389/fnint.2010.00009
   GOTO H, 1971, NEUROPSYCHOLOGIA, V9, P317, DOI 10.1016/0028-3932(71)90027-3
   Gu F, 2013, NEUROIMAGE, V83, P637, DOI 10.1016/j.neuroimage.2013.02.080
   Guo XT, 2018, NEUROSCIENCE, V372, P246, DOI 10.1016/j.neuroscience.2017.12.025
   Hazan V, 2005, SPEECH COMMUN, V47, P360, DOI 10.1016/j.specom.2005.04.007
   Hebb D. O., 1949, ORG BEHAV NEUROPSYCH
   Hill PR, 2004, NEUROREPORT, V15, P2195, DOI 10.1097/00001756-200410050-00010
   Horvath J, 2009, NEUROSCI LETT, V461, P262, DOI 10.1016/j.neulet.2009.06.035
   Iverson P, 2005, J ACOUST SOC AM, V118, P3267, DOI 10.1121/1.2062307
   Koelsch S, 1999, NEUROREPORT, V10, P1309, DOI 10.1097/00001756-199904260-00029
   Kuhl PK, 2014, P NATL ACAD SCI USA, V111, P11238, DOI 10.1073/pnas.1410963111
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   LIBET B, 1975, NATURE, V258, P155, DOI 10.1038/258155a0
   LOGAN JS, 1991, J ACOUST SOC AM, V89, P874, DOI 10.1121/1.1894649
   MIYAWAKI K, 1975, PERCEPT PSYCHOPHYS, V18, P331, DOI 10.3758/BF03211209
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 2005, PSYCHOPHYSIOLOGY, V42, P25, DOI 10.1111/j.1469-8986.2005.00256.x
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   NAATANEN R, 1982, BIOL PSYCHOL, V14, P53, DOI 10.1016/0301-0511(82)90017-5
   NAATANEN R, 1995, EAR HEARING, V16, P6
   Nan Y, 2018, P NATL ACAD SCI USA, V115, pE6630, DOI 10.1073/pnas.1808412115
   Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811
   Reetzke R, 2018, CURR BIOL, V28, P1419, DOI 10.1016/j.cub.2018.03.026
   Sakai M, 2018, APPL PSYCHOLINGUIST, V39, P187, DOI 10.1017/S0142716417000418
   Schroger E, 1998, NEUROREPORT, V9, P3355, DOI 10.1097/00001756-199810260-00003
   SEMLITSCH HV, 1986, PSYCHOPHYSIOLOGY, V23, P695, DOI 10.1111/j.1469-8986.1986.tb00696.x
   Shestakova A, 2003, CLIN NEUROPHYSIOL, V114, P1507, DOI 10.1016/S1388-2457(03)00134-2
   Tamminen H, 2015, INT J PSYCHOPHYSIOL, V97, P23, DOI 10.1016/j.ijpsycho.2015.04.020
   TEES RC, 1984, CAN J PSYCHOL, V38, P579, DOI 10.1037/h0080868
   TIITINEN H, 1994, NATURE, V372, P90, DOI 10.1038/372090a0
   Timm J, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00189
   Tremblay K, 1997, J ACOUST SOC AM, V102, P3762, DOI 10.1121/1.420139
   Wang XD, 2013, SCI REP-UK, V3, DOI 10.1038/srep03485
   Wang XD, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030027
   Wennekers T, 2006, J PHYSIOL-PARIS, V100, P16, DOI 10.1016/j.jphysparis.2006.09.007
   Winkler I, 1999, PSYCHOPHYSIOLOGY, V36, P638, DOI 10.1017/S0048577299981908
   Wu Y, 2019, BRAIN RES, V1724, DOI 10.1016/j.brainres.2019.146433
   Yu DH, 2004, NEURON, V42, P437, DOI 10.1016/S0896-6273(04)00217-X
   Yue JX, 2014, BRAIN LANG, V139, P10, DOI 10.1016/j.bandl.2014.09.007
   Zachau S, 2005, NEUROREPORT, V16, P2015, DOI 10.1097/00001756-200512190-00009
   Zhang Y, 2007, BILING-LANG COGN, V10, P147, DOI 10.1017/S1366728907002908
   Zhang Y, 2009, NEUROIMAGE, V46, P226, DOI 10.1016/j.neuroimage.2009.01.028
NR 55
TC 0
Z9 0
U1 2
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0006-8993
EI 1872-6240
J9 BRAIN RES
JI Brain Res.
PD AUG 1
PY 2020
VL 1740
AR 146848
DI 10.1016/j.brainres.2020.146848
PG 9
WC Neurosciences
SC Neurosciences & Neurology
GA LS1KR
UT WOS:000536151100004
PM 32330520
DA 2021-02-24
ER

PT J
AU Ungan, P
   Yagcioglu, S
   Ayik, E
AF Ungan, Pekcan
   Yagcioglu, Suha
   Ayik, Ece
TI Effects of aging on event-related potentials to single-cycle binaural
   beats and diotic amplitude modulation of a tone
SO BRAIN RESEARCH
LA English
DT Article
DE Temporal fine structure; Sound lateralization; Amplitude modulation;
   ERP-N1; Auditory cortex; Aging
ID AUDITORY-EVOKED-POTENTIALS; TEMPORAL FINE-STRUCTURE;
   AGE-RELATED-CHANGES; HEMISPHERIC-ASYMMETRY REDUCTION; STEADY-STATE
   RESPONSES; COCHLEAR HEARING-LOSS; INTERAURAL TIME; OLDER-ADULTS; NEURAL
   REPRESENTATION; SPEECH-PERCEPTION
AB Aim of the study is to determine whether the auditory processing of temporal fine structure (TFS) is affected with normal aging, even in the presence of normal audiometric hearing and fine cognitive state; and, if it is, to see whether a comparable effect is also observed in the processing of a diotic change in sound envelope. The event-related potentials (ERPs) to binaural beats (BBs), which are the responses of the binaural mechanisms processing TFS of a sound, and the ERPs to diotic amplitude modulation (AM) stimuli, which are the responses of the monaural mechanisms processing the changes in its envelope, were recorded from thirteen young university students and ten senior but active university professors, all with normal hearing in low frequencies. To obtain directly the specific BB responses without confounding monaural frequency change-evoked responses, we used single-cycle BB stimuli with temporary sub-threshold frequency shifts. BBs of a 250-Hz tone and diotic AM of the same tone with similar perceptual salience were presented with 2-second stimulus onset asynchrony. The N1 components of the ERPs to both stimuli displayed notable age-dependent changes in their scalp topography and significant amplitude reduction and latency prolongation in the elderly. These amplitude and latency changes were at similar rates for the two stimulus types, implying that the auditory TFS and envelope processing mechanisms are proportionally affected by physiological aging. These results may serve as control data in future studies investigating the effect of aging-associated cognitive pathologies on auditory TFS processing.
C1 [Ungan, Pekcan] Koc Univ, Sch Med, Dept Biophys, Istanbul, Turkey.
   [Yagcioglu, Suha] Hacettepe Univ, Fac Med, Dept Biophys, Ankara, Turkey.
   [Ayik, Ece] Koc Univ, Sch Sci & Engn, Istanbul, Turkey.
RP Ungan, P (corresponding author), Koc Univ, Sch Med, Dept Biophys, Istanbul, Turkey.
EM pekungan@gmail.com
RI Ungan, Pekcan/W-2038-2019
OI Ungan, Pekcan/0000-0001-6682-3446
FU Turkish Scientific and Technological Research Council, Ankara [114S492];
   Koc University, School of Medicine, IstanbulKoc University; Science
   Academy, Istanbul, Turkey
FX This work was funded by Turkish Scientific and Technological Research
   Council, Ankara (Project: 114S492) and supported by Koc University,
   School of Medicine, Istanbul; and also by Science Academy, Istanbul,
   Turkey. Suha Yagcioglu, one of the co-authors of this study, passed away
   before submission of the manuscript. In recognition of his immense
   contribution to the study, we keep his name in the author list.
CR Amenedo E, 1999, NEUROREPORT, V10, P2383, DOI 10.1097/00001756-199908020-00030
   Bahramali H, 1999, EXP AGING RES, V25, P69, DOI 10.1080/036107399244147
   Ben-David BM, 2012, HEARING RES, V290, P55, DOI 10.1016/j.heares.2012.04.022
   da Silva SRB, 2017, NEUROIMAGE-CLIN, V15, P15, DOI 10.1016/j.nicl.2017.04.001
   Boersma P., 2013, PRAAT DOING PHONETIC
   Cabeza R, 2002, PSYCHOL AGING, V17, P85, DOI 10.1037//0882-7974.17.1.85
   Cardin V, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00199
   DAVIS H, 1966, ELECTROEN CLIN NEURO, V21, P105, DOI 10.1016/0013-4694(66)90118-0
   Draganova R, 2008, CEREB CORTEX, V18, P1193, DOI 10.1093/cercor/bhm153
   DreebenIrimia O., 2013, PHYS THERAPY CLIN 7, P383
   Eckert MA, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00025
   Eddins AC, 2018, HEARING RES, V369, P79, DOI 10.1016/j.heares.2018.05.001
   Eddins AC, 2018, EAR HEARING, V39, P594, DOI 10.1097/AUD.0000000000000518
   Ewert SD, 2020, EUR J NEUROSCI, V51, P1265, DOI 10.1111/ejn.13846
   Fabiani M, 2006, J COGNITIVE NEUROSCI, V18, P637, DOI 10.1162/jocn.2006.18.4.637
   Fitzgibbons PJ, 2010, SPRINGER HANDB AUDIT, V34, P111, DOI 10.1007/978-1-4419-0993-0_5
   Fjell AM, 2001, BRAIN TOPOGR, V14, P25, DOI 10.1023/A:1012563605837
   Freigang C, 2015, CELL TISSUE RES, V361, P371, DOI 10.1007/s00441-015-2230-8
   Gao Y, 2007, BRAIN IMAGING BEHAV, V1, P93, DOI 10.1007/s11682-007-9009-9
   Geal-Dor M, 2006, CLIN NEUROPHYSIOL, V117, P1974, DOI 10.1016/j.clinph.2006.05.024
   Golob EJ, 2000, CLIN NEUROPHYSIOL, V111, P2234, DOI 10.1016/S1388-2457(00)00468-5
   GOODIN DS, 1978, BRAIN, V101, P635, DOI 10.1093/brain/101.4.635
   Grose JH, 2012, HEARING RES, V294, P49, DOI 10.1016/j.heares.2012.09.007
   Grose JH, 2012, EAR HEARING, V33, P199, DOI 10.1097/AUD.0b013e318230bbbd
   Grose JH, 2010, EAR HEARING, V31, P755, DOI 10.1097/AUD.0b013e3181e627e7
   Gutschalk A, 2005, J NEUROSCI, V25, P5382, DOI 10.1523/JNEUROSCI.0347-05.2005
   Harkrider AW, 2005, CLIN NEUROPHYSIOL, V116, P2153, DOI 10.1016/j.clinph.2005.05.016
   He NJ, 2007, J ACOUST SOC AM, V122, P467, DOI 10.1121/1.2741208
   He NJ, 1998, J ACOUST SOC AM, V103, P553, DOI 10.1121/1.421127
   HELFER KS, 1990, J SPEECH HEAR RES, V33, P149, DOI 10.1044/jshr.3301.149
   HINK RF, 1980, AUDIOLOGY, V19, P36
   Hopkins K, 2008, J ACOUST SOC AM, V123, P1140, DOI 10.1121/1.2824018
   Hopkins K, 2011, J ACOUST SOC AM, V130, P334, DOI 10.1121/1.3585848
   Iliadou Vassiliki, 2003, Ann Gen Hosp Psychiatry, V2, P12, DOI 10.1186/1475-2832-2-12
   IRAGUI VJ, 1993, PSYCHOPHYSIOLOGY, V30, P10, DOI 10.1111/j.1469-8986.1993.tb03200.x
   Karino S, 2006, J NEUROPHYSIOL, V96, P1927, DOI 10.1152/jn.00859.2005
   KNIGHT RT, 1988, ELECTROEN CLIN NEURO, V70, P499, DOI 10.1016/0013-4694(88)90148-4
   KODERA K, 1979, AUDIOLOGY, V18, P395
   Lee JY, 2015, J AUDIOL OTOL, V19, P7, DOI 10.7874/jao.2015.19.1.7
   LEHMANN D, 1980, ELECTROEN CLIN NEURO, V48, P609, DOI 10.1016/0013-4694(80)90419-8
   LICKLIDER JCR, 1950, J ACOUST SOC AM, V22, P468, DOI 10.1121/1.1906629
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   Rayleigh,, 1907, PHILOS MAG, V13, P214, DOI 10.1080/14786440709463595
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Martin JS, 2005, J REHABIL RES DEV, V42, P25, DOI 10.1682/JRRD.2004.12.0164
   Matilainen LE, 2010, CLIN NEUROPHYSIOL, V121, P902, DOI 10.1016/j.clinph.2010.01.007
   Moore BCJ, 2012, J ACOUST SOC AM, V131, P1003, DOI 10.1121/1.3672808
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Onofrj M, 2001, NEUROPHYSIOL CLIN, V31, P83, DOI 10.1016/S0987-7053(01)00248-9
   Ozmeral EJ, 2016, J NEUROPHYSIOL, V116, P2720, DOI 10.1152/jn.00560.2016
   PAPANICOLAOU AC, 1990, ARCH NEUROL-CHICAGO, V47, P33, DOI 10.1001/archneur.1990.00530010041016
   PAPANICOLAOU AC, 1984, NEUROBIOL AGING, V5, P291, DOI 10.1016/0197-4580(84)90005-8
   PEKKONEN E, 1995, NEUROREPORT, V6, P1803, DOI 10.1097/00001756-199509000-00023
   PERROTT DR, 1969, J ACOUST SOC AM, V46, P1477, DOI 10.1121/1.1911890
   PERROTT DR, 1977, J ACOUST SOC AM, V61, P1288, DOI 10.1121/1.381430
   Pichora-Fuller MK, 2003, INT J AUDIOL, V42, pS59
   PICTON TW, 1974, ELECTROEN CLIN NEURO, V36, P179, DOI 10.1016/0013-4694(74)90155-2
   PICTON TW, 1984, PSYCHOPHYSIOLOGY, V21, P312, DOI 10.1111/j.1469-8986.1984.tb02941.x
   Polich J, 1997, EVOKED POTENTIAL, V104, P244, DOI 10.1016/S0168-5597(97)96139-6
   Pratt H, 2010, HEARING RES, V262, P34, DOI 10.1016/j.heares.2010.01.013
   Pratt H, 2009, CLIN NEUROPHYSIOL, V120, P1514, DOI 10.1016/j.clinph.2009.06.014
   RADVANSKY GA, 2005, J GERONTOL B-PSYCHOL, V60, pP27
   Ross B, 2018, HEARING RES, V370, P22, DOI 10.1016/j.heares.2018.09.001
   Royall R., 1997, STAT EVIDENCE LIKELI
   Scherg M, 1989, J Cogn Neurosci, V1, P336, DOI 10.1162/jocn.1989.1.4.336
   Schiff S, 2008, CLIN NEUROPHYSIOL, V119, P1795, DOI 10.1016/j.clinph.2008.04.007
   Schwarz DWF, 2005, CLIN NEUROPHYSIOL, V116, P658, DOI 10.1016/j.clinph.2004.09.014
   Snell KB, 1997, J ACOUST SOC AM, V101, P2214, DOI 10.1121/1.418205
   Snyder JS, 2006, J COGNITIVE NEUROSCI, V18, P1, DOI 10.1162/089892906775250021
   Snyder JS, 2005, COGNITIVE BRAIN RES, V24, P492, DOI 10.1016/j.cogbrainres.2005.03.002
   Squires NK, 1999, CLIN NEUROPHYSIOL, V110, P564, DOI 10.1016/S1388-2457(99)00003-6
   Stewart GW, 1917, PHYS REV, V9, P502, DOI 10.1103/PhysRev.9.502
   Tenke CE, 2012, CLIN NEUROPHYSIOL, V123, P2328, DOI 10.1016/j.clinph.2012.06.005
   Tremblay KL, 2002, NEUROREPORT, V13, P1865, DOI 10.1097/00001756-200210280-00007
   Tun PA, 1998, PSYCHOL AGING, V13, P424, DOI 10.1037/0882-7974.13.3.424
   Ungan P, 2002, HEARING RES, V167, P81, DOI 10.1016/S0378-5955(02)00351-9
   UNGAN P, 1992, AUDIOLOGY, V31, P318
   Ungan P, 2001, CLIN NEUROPHYSIOL, V112, P485, DOI 10.1016/S1388-2457(00)00550-2
   Ungan P, 2019, EXP BRAIN RES, V237, P1931, DOI 10.1007/s00221-019-05562-7
   VandenLangenberg GM, 1998, AM J EPIDEMIOL, V148, P204, DOI 10.1093/oxfordjournals.aje.a009625
   VAUGHAN HG, 1970, ELECTROEN CLIN NEURO, V28, P360, DOI 10.1016/0013-4694(70)90228-2
   Wang MY, 2011, HEARING RES, V275, P139, DOI 10.1016/j.heares.2010.12.013
   WERNICK JS, 1968, J NEUROPHYSIOL, V31, P428
   Working Group on Speech Understanding and Aging, 1988, J ACOUST SOC AM, V83, P859, DOI DOI 10.1121/1.395965
NR 84
TC 1
Z9 1
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0006-8993
EI 1872-6240
J9 BRAIN RES
JI Brain Res.
PD AUG 1
PY 2020
VL 1740
AR 146849
DI 10.1016/j.brainres.2020.146849
PG 11
WC Neurosciences
SC Neurosciences & Neurology
GA LS1KR
UT WOS:000536151100005
PM 32330517
DA 2021-02-24
ER

PT J
AU Deschamps, I
   Courson, M
   Dick, AS
   Tremblay, P
AF Deschamps, Isabelle
   Courson, Melody
   Dick, Anthony Steven
   Tremblay, Pascale
TI The phonological loop: is speech special?
SO EXPERIMENTAL BRAIN RESEARCH
LA English
DT Article
DE Transcranial magnetic stimulation; Auditory working memory; Speech
   perception; Auditory discrimination; Inferior frontal gyrus;
   Supramarginal gyrus
ID VERBAL WORKING-MEMORY; SHORT-TERM-MEMORY; TRANSCRANIAL MAGNETIC
   STIMULATION; INFERIOR FRONTAL GYRUS; SUPRAMARGINAL GYRUS; UNATTENDED
   SPEECH; STATE-DEPENDENCY; WORD DECISIONS; PITCH MEMORY; FMRI
AB It has been proposed that the maintenance of phonological information in verbal working memory (vWM) is carried by a domain-specific short-term storage center-the phonological loop-which is composed of a phonological store and an articulatory rehearsal system. Several brain regions including the left posterior inferior frontal gyrus (pIFG) and anterior supramarginal gyri (aSMG) are thought to support these processes. However, recent behavioral evidence suggests that verbal and non-verbal auditory information may be processed as part of a unique domain general short-term storage center instead of through specialized subsystems such as the phonological loop. In the current study, we used a single-pulse transcranial magnetic stimulation (TMS)-delayed priming paradigm with speech (syllables) and acoustically complex non-speech sounds (bird songs) to examine whether the pIFG and aSMG are involved in the processing of verbal information or, alternatively, in the processing of any complex auditory information. Our results demonstrate that TMS delivered to both regions had an effect on performance for speech and non-speech stimuli, but the nature of the effect was different. That is, priming was reduced for the speech sounds because TMS facilitated the detection of different but not identical stimuli, and accuracy was decreased for non-speech sounds. Since TMS interfered with both speech and non-speech sounds, these findings support the existence of an auditory short-term storage center located within the dorsal auditory stream.
C1 [Deschamps, Isabelle; Courson, Melody; Tremblay, Pascale] Univ Laval, Fac Med, Dept Readaptat, 1050 Ave Med,Off 4109, Quebec City, PQ G1V 0A6, Canada.
   [Deschamps, Isabelle; Courson, Melody; Tremblay, Pascale] CERVO Brain Res Ctr, Quebec City, PQ, Canada.
   [Dick, Anthony Steven] Florida Int Univ, Miami, FL 33199 USA.
RP Tremblay, P (corresponding author), Univ Laval, Fac Med, Dept Readaptat, 1050 Ave Med,Off 4109, Quebec City, PQ G1V 0A6, Canada.; Tremblay, P (corresponding author), CERVO Brain Res Ctr, Quebec City, PQ, Canada.
EM Pascale.Tremblay@fmed.ulaval.ca
OI Tremblay, Pascale/0000-0001-7161-9255
FU Natural Sciences and Engineering Research Council of Canada
   (NSERC)Natural Sciences and Engineering Research Council of Canada
   (NSERC) [435774-2013]; Canadian foundation for innovationCanada
   Foundation for Innovation [31408]; "Fonds de Recherche du Quebec -
   Sante'' (FRQS)Fonds de la Recherche en Sante du Quebec [35016]; Brain
   Canada Foundation [3456]
FX We thank all the participants. This study was supported by grants from
   the Natural Sciences and Engineering Research Council of Canada (NSERC)
   (Grant No. 435774-2013) and from the Canadian foundation for innovation
   (Grant No. 31408) to P.T., who also holds a Career Awards from the
   ''Fonds de Recherche du Quebec - Sante'' (FRQS) (Grant No. 35016).
   Support for MRI data acquisition was provided by the "Centre integre en
   neuroimagerie et neurostimulation de Quebec" (CINQ) via a platform
   support grant from the Brain Canada Foundation (#3456). ID is currently
   a faculty at Georgian College in Ontario, Canada.
CR Aboitiz F, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00174
   Atkinson RC., 1968, PSYCHOL LEARN MOTIV, P89, DOI 10.1016/S0079-7421(08)60422-3
   Awh E, 1996, PSYCHOL SCI, V7, P25, DOI 10.1111/j.1467-9280.1996.tb00662.x
   Baddeley A, 2003, J COMMUN DISORD, V36, P189, DOI 10.1016/S0021-9924(03)00019-4
   Baddeley A. D, 1986, WORKING MEMORY
   Baddeley A. D., 1974, PSYCHOL LEARNING MOT
   BADDELEY AD, 1975, J VERB LEARN VERB BE, V14, P575, DOI 10.1016/S0022-5371(75)80045-4
   Baddeley A, 2010, CURR BIOL, V20, pR136, DOI 10.1016/j.cub.2009.12.014
   Baddeley A, 2012, ANNU REV PSYCHOL, V63, P1, DOI 10.1146/annurev-psych-120710-100422
   Barrouillet P, 2004, J EXP PSYCHOL GEN, V133, P83, DOI 10.1037/0096-3445.133.1.83
   Bergerbest D, 2004, J COGNITIVE NEUROSCI, V16, P966, DOI 10.1162/0898929041502760
   Boersma P., 2011, PRAAT DOING PHONETIC
   Buchsbaum BR, 2001, COGNITIVE SCI, V25, P663, DOI 10.1207/s15516709cog2505_2
   Buchsbaum BR, 2008, J COGNITIVE NEUROSCI, V20, P762, DOI 10.1162/jocn.2008.20501
   Buchsbaum BR, 2019, CORTEX, V112, P134, DOI 10.1016/j.cortex.2018.11.010
   Burton MW, 2005, NEUROIMAGE, V26, P647, DOI 10.1016/j.neuroimage.2005.02.024
   Burton MW, 2000, J COGNITIVE NEUROSCI, V12, P679, DOI 10.1162/089892900562309
   Caspers S, 2012, CEREB CORTEX, V12, P679
   Caspers S, 2008, BRAIN STRUCT FUNCT, V212, P481, DOI 10.1007/s00429-008-0195-z
   Cattaneo L, 2010, EXP BRAIN RES, V207, P165, DOI 10.1007/s00221-010-2454-5
   Cattaneo Z, 2008, EUR J NEUROSCI, V28, P1924, DOI 10.1111/j.1460-9568.2008.06466.x
   CHAO LL, 1995, EVOKED POTENTIAL, V96, P157, DOI 10.1016/0168-5597(94)00256-E
   Chen SHA, 2005, NEUROIMAGE, V24, P332, DOI 10.1016/j.neuroimage.2004.08.032
   Cowan N, 2001, BEHAV BRAIN SCI, V24, P87, DOI 10.1017/S0140525X01003922
   Deschamps I, 2014, NEUROPSYCHOLOGIA, V53, P39, DOI 10.1016/j.neuropsychologia.2013.10.015
   Devlin JT, 2003, J COGNITIVE NEUROSCI, V15, P71, DOI 10.1162/089892903321107837
   Fegen D, 2015, NEUROIMAGE, V105, P120, DOI 10.1016/j.neuroimage.2014.10.034
   Fiez JA, 1996, J NEUROSCI, V16, P808
   Gaab N, 2003, NEUROIMAGE, V19, P1417, DOI 10.1016/S1053-8119(03)00224-6
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   Gaskell MG, 2002, COGNITIVE PSYCHOL, V45, P220
   Gitelman DR, 2005, NEUROIMAGE, V26, P975, DOI 10.1016/j.neuroimage.2005.03.014
   Gough PM, 2005, J NEUROSCI, V25, P8010, DOI 10.1523/JNEUROSCI.2307-05.2005
   Gruber O, 2000, NEUROIMAGE, V5, pS407
   Hartwigsen G, 2016, CEREB CORTEX, V26, P2590, DOI 10.1093/cercor/bhv092
   Hartwigsen G, 2010, P NATL ACAD SCI USA, V107, P16494, DOI 10.1073/pnas.1008121107
   Hartwigsen G, 2010, NEUROPSYCHOLOGIA, V48, P3155, DOI 10.1016/j.neuropsychologia.2010.06.032
   Hasson U, 2018, COGNITION, V180, P135, DOI 10.1016/j.cognition.2018.06.018
   Henson R, 2000, SCIENCE, V287, P1269, DOI 10.1126/science.287.5456.1269
   Henson RNA, 2000, NEUROPSYCHOLOGIA, V38, P426, DOI 10.1016/S0028-3932(99)00098-6
   Herwig U, 2003, NEUROIMAGE, V20, P1032, DOI 10.1016/S1053-8119(03)00368-9
   Hickok G, 2003, J COGNITIVE NEUROSCI, V15, P673, DOI 10.1162/089892903322307393
   HITCH GJ, 1976, Q J EXP PSYCHOL, V28, P603, DOI 10.1080/14640747608400587
   Hutchins S, 2008, J EXP PSYCHOL HUMAN, V34, P693, DOI 10.1037/0096-1523.34.3.693
   Imm JH, 2008, NEUROREPORT, V19, P99, DOI 10.1097/WNR.0b013e3282f36f91
   Jacquemot C, 2006, TRENDS COGN SCI, V10, P480, DOI 10.1016/j.tics.2006.09.002
   JONES DM, 1993, J EXP PSYCHOL LEARN, V19, P369, DOI 10.1037/0278-7393.19.2.369
   Jones DM, 2007, Q J EXP PSYCHOL, V60, P505, DOI 10.1080/17470210601147598
   Kirschen MP, 2006, BEHAV NEUROL, V17, P187, DOI 10.1155/2006/469132
   Kirschen MP, 2010, BEHAV NEUROL, V23, P51, DOI [10.1155/2010/587450, 10.3233/BEN-2010-0266]
   Koelsch S, 2009, HUM BRAIN MAPP, V30, P859, DOI 10.1002/hbm.20550
   Kouider S, 2005, PSYCHOL SCI, V16, P617, DOI 10.1111/j.1467-9280.2005.01584.x
   Kumar S, 2016, J NEUROSCI, V36, P4492, DOI 10.1523/JNEUROSCI.4341-14.2016
   Liao DA, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00753
   LIGHT LL, 1995, J EXP PSYCHOL LEARN, V21, P327, DOI 10.1037/0278-7393.21.2.327
   Macken WJ, 2003, Q J EXP PSYCHOL-A, V56, P1279, DOI 10.1080/02724980245000052
   Macmillan N, 2004, DETECTION THEORY USE
   MACMILLAN NA, 1990, PSYCHOL BULL, V107, P401, DOI 10.1037/0033-2909.107.3.401
   Martin RC, 2005, CURR DIR PSYCHOL SCI, V14, P204, DOI 10.1111/j.0963-7214.2005.00365.x
   MARTIN RC, 1994, J MEM LANG, V33, P83, DOI 10.1006/jmla.1994.1005
   Martin RC, 2003, J NEUROLINGUIST, V16, P341, DOI 10.1016/S0911-6044(03)00025-3
   Martinkauppi S, 2000, CEREB CORTEX, V10, P889, DOI 10.1093/cercor/10.9.889
   Marvel CL, 2012, BRAIN LANG, V120, P42, DOI 10.1016/j.bandl.2011.08.005
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McDermott KB, 2003, NEUROPSYCHOLOGIA, V41, P293, DOI 10.1016/S0028-3932(02)00162-8
   Michon M, 2019, PROG BRAIN RES, V250, P345, DOI 10.1016/bs.pbr.2019.01.005
   Miniussi C, 2010, CORTEX, V46, P128, DOI 10.1016/j.cortex.2009.03.004
   Mottaghy FM, 2003, NEUROIMAGE, V18, P565, DOI 10.1016/S1053-8119(03)00010-7
   Nees MA, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01892
   Nixon P, 2004, J COGNITIVE NEUROSCI, V16, P289, DOI 10.1162/089892904322984571
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Othman E, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e02444
   PAULESU E, 1993, NATURE, V362, P342, DOI 10.1038/362342a0
   PECHMANN T, 1992, MEM COGNITION, V20, P314, DOI 10.3758/BF03199668
   Rodriguez-Jimenez R, 2009, BEHAV BRAIN RES, V205, P299, DOI 10.1016/j.bbr.2009.08.022
   Romei V, 2016, TRENDS NEUROSCI, V39, P782, DOI 10.1016/j.tins.2016.09.001
   Romero L, 2006, J COGNITIVE NEUROSCI, V18, P1147, DOI 10.1162/jocn.2006.18.7.1147
   Rossi S, 2009, CLIN NEUROPHYSIOL, V120, P2008, DOI 10.1016/j.clinph.2009.08.016
   ROSSINI PM, 1994, ELECTROEN CLIN NEURO, V91, P79, DOI 10.1016/0013-4694(94)90029-9
   Ruchkin DS, 1997, COGNITIVE BRAIN RES, V6, P95, DOI 10.1016/S0926-6410(97)00021-9
   RUECKL JG, 1990, J EXP PSYCHOL LEARN, V16, P374, DOI 10.1037/0278-7393.16.3.374
   SALAME P, 1986, B PSYCHONOMIC SOC, V24, P263
   SALAME P, 1989, Q J EXP PSYCHOL-A, V41, P107, DOI 10.1080/14640748908402355
   SALAME P, 1982, J VERB LEARN VERB BE, V21, P150, DOI 10.1016/S0022-5371(82)90521-7
   Schaal NK, 2015, CEREB CORTEX, V25, P2774, DOI 10.1093/cercor/bhu075
   Schaal NK, 2015, CORTEX, V64, P310, DOI 10.1016/j.cortex.2014.11.011
   Schaal NK, 2013, EUR J NEUROSCI, V38, P3513, DOI 10.1111/ejn.12344
   Schiller NO, 2003, COGNITIVE BRAIN RES, V17, P819, DOI 10.1016/S0926-6410(03)00204-0
   Schulze K, 2011, HUM BRAIN MAPP, V32, P771, DOI 10.1002/hbm.21060
   Shen J, 2015, NEUROSCIENCE, V289, P144, DOI 10.1016/j.neuroscience.2014.12.071
   Silvanto J, 2008, BRAIN TOPOGR, V21, P1, DOI 10.1007/s10548-008-0067-0
   Silvanto J, 2007, EUR J NEUROSCI, V25, P1874, DOI 10.1111/j.1460-9568.2007.05440.x
   Sliwinska MW, 2014, JOVE-J VIS EXP, DOI 10.3791/51735
   Stevens KN, 1972, SEGMENTS FEATURES AN
   Tremblay P, 2013, NEUROIMAGE, V66, P318, DOI 10.1016/j.neuroimage.2012.10.055
   Tremblay P, 2019, HUM BRAIN MAPP, V40, P226, DOI 10.1002/hbm.24367
   Vines BW, 2006, NEUROREPORT, V17, P1047, DOI 10.1097/01.wnr.0000223396.05070.a2
   Wassermann EM, 1998, EVOKED POTENTIAL, V108, P1, DOI 10.1016/S0168-5597(97)00096-8
   Weissgerber TL, 2015, PLOS BIOL, V13, DOI 10.1371/journal.pbio.1002128
   Wig GS, 2005, NAT NEUROSCI, V8, P1228, DOI 10.1038/nn1515
   ZATORRE RJ, 1994, J NEUROSCI, V14, P1908, DOI 10.1523/jneurosci.14-04-01908.1994
NR 102
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0014-4819
EI 1432-1106
J9 EXP BRAIN RES
JI Exp. Brain Res.
PD OCT
PY 2020
VL 238
IS 10
BP 2307
EP 2321
DI 10.1007/s00221-020-05886-9
EA JUL 2020
PG 15
WC Neurosciences
SC Neurosciences & Neurology
GA NM2CH
UT WOS:000554059300001
PM 32734355
DA 2021-02-24
ER

PT J
AU Zeng, FG
   Richardson, M
   Turner, K
AF Zeng, Fan-Gang
   Richardson, Matthew
   Turner, Katie
TI Tinnitus Does Not Interfere with Auditory and Speech Perception
SO JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE animal model; attention; auditory perception; neural noise; speech
   recognition; tinnitus
ID HEARING-LOSS; TEMPORAL RESOLUTION; GAP DETECTION; INTENSITY
   DISCRIMINATION; DETECTION DEFICITS; MECHANISMS; MASKING; NOISE;
   ATTENTION; LOUDNESS
AB Tinnitus is a sound heard by 15% of the general population in the absence of any external sound. Because external sounds can sometimes mask tinnitus, tinnitus is assumed to affect the perception of external sounds, leading to hypotheses such as "tinnitus filling in the temporal gap" in animal models and "tinnitus inducing hearing difficulty" in human subjects. Here we compared performance in temporal, spectral, intensive, masking and speech-in-noise perception tasks between 45 human listeners with chronic tinnitus (18 females and 27 males with a range of ages and degrees of hearing loss) and 27 young, normal-hearing listeners without tinnitus (11 females and 16 males). After controlling for age, hearing loss, and stimulus variables, we discovered that, contradictory to the widely held assumption, tinnitus does not interfere with the perception of external sounds in 32 of the 36 measures. We interpret the present result to reflect a bottom-up pathway for the external sound and a separate top-down pathway for tinnitus. We propose that these two perceptual pathways can be independently modulated by attention, which leads to the asymmetrical interaction between external and internal sounds, and several other puzzling tinnitus phenomena such as discrepancy in loudness between tinnitus rating and matching. The present results suggest not only a need for new theories involving attention and central noise in animal tinnitus models but also a shift in focus from treating tinnitus to managing its comorbid conditions when addressing complaints about hearing difficulty in individuals with tinnitus.
C1 [Zeng, Fan-Gang] Univ Calif Irvine, Ctr Hearing Res, Dept Anat & Neurobiol, Irvine, CA 92697 USA.
   Univ Calif Irvine, Ctr Hearing Res, Dept Biomed Engn, Irvine, CA 92697 USA.
   Univ Calif Irvine, Ctr Hearing Res, Dept Cognit Sci, Irvine, CA 92697 USA.
   Univ Calif Irvine, Ctr Hearing Res, Dept Otolaryngol Head & Neck Surg, Irvine, CA 92697 USA.
RP Zeng, FG (corresponding author), Univ Calif Irvine, Ctr Hearing Res, Dept Anat & Neurobiol, Irvine, CA 92697 USA.
EM fzeng@uci.edu
OI Zeng, Fan-Gang/0000-0002-4325-2780
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [5R01-DC-015587]
FX This work was supported in part by National Institutes of Health Grant
   5R01-DC-015587. We thank Hengji Chen for help with data collection in
   the overshoot experiment, and Omid Moshtaghi and Neil Saez for help with
   data collection in the temporal modulation and speech perception
   experiments. We also thank John Middlebrooks, Michelle Kapolowicz,
   Matthew Suh, Phillip Tran, Ruth Anne Eatock, Dan Sanes, and Brian C.J.
   Moore and an anonymous reviewer for comments on the manuscript.
CR An Yong-Hwi, 2014, Korean J Audiol, V18, P119, DOI 10.7874/kja.2014.18.3.119
   Andersson G, 2000, J SPEECH LANG HEAR R, V43, P1168, DOI 10.1044/jslhr.4305.1168
   Araneda R, 2015, RESTOR NEUROL NEUROS, V33, P67, DOI 10.3233/RNN-140433
   AXELSSON A, 1989, British Journal of Audiology, V23, P53, DOI 10.3109/03005368909077819
   BACON SP, 1992, J ACOUST SOC AM, V91, P2865, DOI 10.1121/1.402967
   Baguley D, 2013, LANCET, V382, P1600, DOI 10.1016/S0140-6736(13)60142-7
   Bellis TJ, 2008, BRAIN COGNITION, V66, P280, DOI 10.1016/j.bandc.2007.09.006
   Bernstein LR, 2016, J ACOUST SOC AM, V140, P3540, DOI 10.1121/1.4966113
   Boyen K, 2015, EAR HEARING, V36, pe138, DOI 10.1097/AUD.0000000000000156
   Brozoski T, 2019, NEUROSCIENCE, V407, P200, DOI 10.1016/j.neuroscience.2018.10.013
   Buzo BC, 2014, INT J AUDIOL, V53, P40, DOI 10.3109/14992027.2013.840931
   Campolo J, 2013, NOISE HEALTH, V15, P398, DOI 10.4103/1463-1741.121232
   CARLYON RP, 1984, J ACOUST SOC AM, V76, P1369, DOI 10.1121/1.391453
   Chen YC, 2015, ELIFE, V4, DOI 10.7554/eLife.06576
   Cohen J, 1969, STAT POWER ANAL BEHA
   COX RM, 1988, J ACOUST SOC AM, V84, P1100, DOI 10.1121/1.396697
   Dornhoffer John, 2006, Int Tinnitus J, V12, P9
   Dupuis K, 2015, AGING NEUROPSYCHOL C, V22, P413, DOI 10.1080/13825585.2014.968084
   Epp B, 2012, J ACOUST SOC AM, V132, pEL196, DOI 10.1121/1.4740462
   FELDMANN H, 1971, AUDIOLOGY, V10, P138
   Fournier P, 2013, HEARING RES, V295, P16, DOI 10.1016/j.heares.2012.05.011
   Furman AC, 2013, J NEUROPHYSIOL, V110, P577, DOI 10.1152/jn.00164.2013
   Sanches SGG, 2010, AUDIOL NEURO-OTOL, V15, P273, DOI 10.1159/000272939
   Gilles A, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00288
   GOODWIN PE, 1980, ACTA OTO-LARYNGOL, V90, P353, DOI 10.3109/00016488009131736
   Hallam RS, 2004, INT J AUDIOL, V43, P218, DOI 10.1080/14992020400050030
   Henry JA, 2005, J SPEECH LANG HEAR R, V48, P1204, DOI 10.1044/1092-4388(2005/084)
   Husain FT, 2015, BRAIN RES, V1620, P81, DOI 10.1016/j.brainres.2015.05.010
   Ibraheem OA, 2017, INT ARCH OTORHINOLAR, V21, P144, DOI [10.1055/s-0036-1583526., 10.1055/s-0036-1583526]
   Ivansic D, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00224
   Jacobson GP, 1996, HEARING RES, V97, P66
   Jagoda L, 2018, HEARING RES, V367, P48, DOI 10.1016/j.heares.2018.07.001
   Jain Chandni, 2014, Int Tinnitus J, V19, P28, DOI 10.5935/0946-5448.20140004
   Jain S, 2016, HEARING BALANC COMMU, V14, P8, DOI 10.3109/21695717.2016.1099885
   Jastreboff P J, 2000, J Am Acad Audiol, V11, P162
   JASTREBOFF PJ, 1990, NEUROSCI RES, V8, P221, DOI 10.1016/0168-0102(90)90031-9
   Jones PR, 2013, J ACOUST SOC AM, V133, P970, DOI 10.1121/1.4773864
   Kaltenbach JA, 2006, HEARING RES, V216, P224, DOI 10.1016/j.heares.2006.01.002
   LEEK MR, 1991, PERCEPT PSYCHOPHYS, V50, P205, DOI 10.3758/BF03206743
   Leger AC, 2012, HEARING RES, V294, P95, DOI 10.1016/j.heares.2012.10.002
   Li ZC, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01779
   LUCE RD, 1978, PERCEPT PSYCHOPHYS, V23, P363, DOI 10.3758/BF03204138
   McCormack A, 2016, HEARING RES, V337, P70, DOI 10.1016/j.heares.2016.05.009
   Mehdizade Gilani Vahid, 2013, Iran J Otorhinolaryngol, V25, P221
   Meikle M, 1984, J Laryngol Otol Suppl, V9, P17
   Meikle MB, 2012, EAR HEARING, V33, P153, DOI 10.1097/AUD.0b013e31822f67c0
   Mohrle D, 2019, NEUROSCIENCE, V407, P146, DOI 10.1016/j.neuroscience.2018.12.038
   Mohamad N, 2016, HEARING RES, V332, P199, DOI 10.1016/j.heares.2015.10.001
   Moon IJ, 2015, J NEUROSCI, V35, P14260, DOI 10.1523/JNEUROSCI.5091-14.2015
   MOORE BCJ, 1992, J ACOUST SOC AM, V91, P2881, DOI 10.1121/1.402925
   Moore BCJ, 2000, BRIT J AUDIOL, V34, P205, DOI 10.3109/03005364000000131
   Moore BCJ, 1996, EAR HEARING, V17, P133, DOI 10.1097/00003446-199604000-00007
   Moore BCJ, 2012, SPRINGER HANDB AUDIT, V44, P187, DOI 10.1007/978-1-4614-3728-4_9
   Moore BCJ, 2010, HEARING RES, V261, P51, DOI 10.1016/j.heares.2010.01.003
   Morse K, 2019, AM J AUDIOL, V28, P260, DOI 10.1044/2018_AJA-18-0074
   Muhlnickel W, 1998, P NATL ACAD SCI USA, V95, P10340, DOI 10.1073/pnas.95.17.10340
   Newman CW, 1996, ARCH OTOLARYNGOL, V122, P143
   Norena A, 2002, AUDIOL NEURO-OTOL, V7, P358, DOI 10.1159/000066156
   Okamoto H, 2010, P NATL ACAD SCI USA, V107, P1207, DOI 10.1073/pnas.0911268107
   Pan T, 2009, INT J AUDIOL, V48, P277, DOI 10.1080/14992020802581974
   Patuzzi RB, 2004, HEARING RES, V190, P87, DOI 10.1016/S0378-5955(03)00405-2
   Paul BT, 2017, HEARING RES, V344, P170, DOI 10.1016/j.heares.2016.11.010
   Penner M.J., 1995, INT TINNITUS J, V1, P79
   PENNER MJ, 1987, J SPEECH HEAR RES, V30, P147, DOI 10.1044/jshr.3002.147
   Reavis KM, 2012, JARO-J ASSOC RES OTO, V13, P561, DOI 10.1007/s10162-012-0331-6
   REED GF, 1960, ARCHIV OTOLARYNGOL, V71, P94
   Reynolds JH, 2009, NEURON, V61, P168, DOI 10.1016/j.neuron.2009.01.002
   Roberts LE, 2013, NEUROSCI BIOBEHAV R, V37, P1754, DOI 10.1016/j.neubiorev.2013.07.007
   Roberts LE, 2010, J NEUROSCI, V30, P14972, DOI 10.1523/JNEUROSCI.4028-10.2010
   Rossiter S, 2006, J SPEECH LANG HEAR R, V49, P150, DOI 10.1044/1092-4388(2006/012)
   SCHLAUCH RS, 1992, J ACOUST SOC AM, V92, P758, DOI 10.1121/1.403999
   Sedley W, 2016, TRENDS NEUROSCI, V39, P799, DOI 10.1016/j.tins.2016.10.004
   SHAILER MJ, 1987, J ACOUST SOC AM, V81, P1110, DOI 10.1121/1.394631
   Shore SE, 2019, NEURON, V103, P8, DOI 10.1016/j.neuron.2019.05.008
   Soalheiro M, 2012, J OCCUP MED TOXICOL, V7, DOI 10.1186/1745-6673-7-26
   Starr A, 1996, BRAIN, V119, P741, DOI 10.1093/brain/119.3.741
   Stevens C, 2007, INT J AUDIOL, V46, P208, DOI 10.1080/14992020601102329
   STOUFFER JL, 1990, J SPEECH HEAR DISORD, V55, P439, DOI 10.1044/jshd.5503.439
   STUDEBAKER GA, 1987, J ACOUST SOC AM, V81, P1130, DOI 10.1121/1.394633
   Tai YS, 2019, J AUDIOL OTOL, V23, P1, DOI 10.7874/jao.2018.00409
   Tai Y, 2018, JARO-J ASSOC RES OTO, V19, P211, DOI 10.1007/s10162-017-0647-3
   Tan CM, 2013, JARO-J ASSOC RES OTO, V14, P275, DOI 10.1007/s10162-013-0371-6
   Turner JG, 2006, BEHAV NEUROSCI, V120, P188, DOI 10.1037/0735-7044.120.1.188
   TYLER RS, 1983, J SPEECH HEAR DISORD, V48, P150, DOI 10.1044/jshd.4802.150
   Vernon J A, 1981, Ciba Found Symp, V85, P239
   Vielsmeier V, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00293
   VIEMEISTER NF, 1979, J ACOUST SOC AM, V66, P1364, DOI 10.1121/1.383531
   Weisz N, 2006, HEARING RES, V222, P108, DOI 10.1016/j.heares.2006.09.003
   Yang SC, 2011, P NATL ACAD SCI USA, V108, P14974, DOI 10.1073/pnas.1107998108
   Zeng FG, 2013, HEARING RES, V295, P172, DOI 10.1016/j.heares.2012.05.009
   Zeng FG, 2011, HEARING RES, V277, P61, DOI 10.1016/j.heares.2011.03.010
   Zeng FG, 2006, J SPEECH LANG HEAR R, V49, P367, DOI 10.1044/1092-4388(2006/029)
   Zeng FG, 2005, JARO-J ASSOC RES OTO, V6, P390, DOI 10.1007/s10162-005-0016-5
   Zeng FG, 2005, J NEUROPHYSIOL, V93, P3050, DOI 10.1152/jn.00985.2004
   Zeng FG, 2005, P NATL ACAD SCI USA, V102, P2293, DOI 10.1073/pnas.0406460102
   Zhang GW, 2018, NEURON, V97, P406, DOI 10.1016/j.neuron.2017.12.010
   ZWICKER E, 1965, J ACOUST SOC AM, V38, P132, DOI 10.1121/1.1909588
NR 97
TC 4
Z9 4
U1 1
U2 1
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
SN 0270-6474
EI 1529-2401
J9 J NEUROSCI
JI J. Neurosci.
PD JUL 29
PY 2020
VL 40
IS 31
BP 6007
EP 6017
DI 10.1523/JNEUROSCI.0396-20.2020
PG 11
WC Neurosciences
SC Neurosciences & Neurology
GA MS7EJ
UT WOS:000554438400008
PM 32554549
OA Green Published
DA 2021-02-24
ER

PT J
AU Dahmani, S
   Colotte, V
   Ouni, S
AF Dahmani, Sara
   Colotte, Vincent
   Ouni, Slim
TI Some consideration on expressive audiovisual speech corpus acquisition
   using a multimodal platform
SO LANGUAGE RESOURCES AND EVALUATION
LA English
DT Article
DE Expressive audiovisual speech; Facial expressions; Acted speech
ID FACIAL EXPRESSIONS; MOTION; ACCURACY; MOVEMENTS; AG500; MODEL; FACE
AB In this paper, we present a multimodal acquisition setup that combines different motion-capture systems. This system is mainly aimed for recording expressive audiovisual corpus in the context of audiovisual speech synthesis. When dealing with speech recording, the standard optical motion-capture systems fail in tracking the articulators finely, especially the inner mouth region, due to the disappearing of certain markers during the articulation. Also, some systems have limited frame rates and are not suitable for smooth speech tracking. In this work, we demonstrate how those limitations can be overcome by creating a heterogeneous system taking advantage of different tracking systems. In the scope of this work, we recorded a prototypical corpus using our combined system for a single subject. This corpus was used to validate our multimodal data acquisition protocol and to assess the quality of the expressiveness before recording a large corpus. We conducted two evaluations of the recorded data, the first one concerns the production aspect of speech and the second one focuses on the speech perception aspect (both evaluations concern visual and acoustic modalities). Production analysis allowed us to identify characteristics specific to each expressive context. This analysis showed that the expressive content of the recorded data is globally in line with what is commonly expected in the literature. The perceptual evaluation, conducted as a human emotion recognition task using different types of stimulus, confirmed that the different recorded emotions were well perceived.
C1 [Dahmani, Sara; Colotte, Vincent; Ouni, Slim] Univ Lorraine, CNRS, Inria, LORIA, F-54000 Nancy, France.
RP Ouni, S (corresponding author), Univ Lorraine, CNRS, Inria, LORIA, F-54000 Nancy, France.
EM Sara.Dahmani@loria.fr; Vincent.Colotte@loria.fr; Slim.Ouni@loria.fr
FU Region Lorraine (COREXP Project); Inria (ADT Plavis); Agence Nationale
   de la Recherche (EQUIPEX Ortolang)French National Research Agency (ANR)
FX This work was supported by Region Lorraine (COREXP Project), Inria (ADT
   Plavis) and the Agence Nationale de la Recherche (EQUIPEX Ortolang).
CR Bailly G, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON SPEECH SYNTHESIS, P27, DOI 10.1109/WSS.2002.1224365
   Bandini A., 2015, INTERSPEECH 2015
   Barbulescu A., 2015, THESIS
   Barra Chicote R., 2008, 2 INT WORKSH EM CORP
   Berry JJ, 2011, J SPEECH LANG HEAR R, V54, P1295, DOI 10.1044/1092-4388(2011/10-0226)
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bolinger D., 1978, INTONATION LANGUAGES
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cave C., 1996, P 4 INT C SPOK LANG
   Czyzewski A, 2017, J INTELL INF SYST, V49, P167, DOI 10.1007/s10844-016-0438-z
   Dutoit T, 2008, SPRINGER HDB SPEECH, P437
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   EKMAN P, 1986, MOTIV EMOTION, V10, P159, DOI 10.1007/BF00992253
   EKMAN P, 1976, ENVIRON PSYCH NONVER, V1, P56, DOI 10.1007/BF01115465
   Ekman P, 2002, FACIAL ACTION CODING, V1
   Feng YQ, 2014, J SPEECH LANG HEAR R, V57, P426, DOI 10.1044/2014_JSLHR-S-13-0007
   Fernandez-Lopez A, 2018, IMAGE VISION COMPUT, V78, P53, DOI 10.1016/j.imavis.2018.07.002
   Francois H., 2001, 7 EUR C SPEECH COMM
   Hess U, 2009, AFFECTIVE INFORMATION PROCESSING, P145, DOI 10.1007/978-1-84800-306-4_9
   HOLM S, 1979, SCAND J STAT, V6, P65
   Huron D, 2013, J ACOUST SOC AM, V133, P2947, DOI 10.1121/1.4798801
   Jiang J., 2002, J APPL SIGNAL PROCES, V11, P1174
   Jonathan B.C., 2008, LREC
   Katz W, 2014, INTERSPEECH, P1174
   Kawaler M, 2019, J INTELL INF SYST, V53, P381, DOI 10.1007/s10844-019-00547-y
   Keselman Leonid, 2017, P IEEE C COMP VIS PA, P1, DOI [10.1109/CVPRW.2017.167, DOI 10.1109/CVPRW.2017.167.]
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI [DOI 10.1109/CVPRW.2010.5543262, 10.1109/CVPRW.2010.5543262]
   Ma JY, 2006, IEEE T VIS COMPUT GR, V12, P266, DOI 10.1109/TVCG.2006.18
   Mattheyses W, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/169819
   Mefferd A, 2015, J SPEECH LANG HEAR R, V58, P576, DOI 10.1044/2015_JSLHR-S-14-0188
   Mehrabian A, 2008, COMMUN THEORY, P193
   Moore S., 1984, STANISLAVSKI SYSTEM
   MORTON ES, 1977, AM NAT, V111, P855, DOI 10.1086/283219
   MORTON ES, 1994, SOUND SYMBOLISM, P348, DOI DOI 10.1017/CBO9780511751806.023
   Nabi RL, 2002, COGNITION EMOTION, V16, P695, DOI 10.1080/02699930143000437
   Nunes AMB, 2013, INT J SCI COMMERCE H, V1, P107
   Ouni S., 2018, SPEECH COMMUNICATION, V96
   Ouni S., 2017, INT C AUD VIS SPEECH
   Ouni S., 2016, INTERSPEECH 2016
   Ouni S, 2016, J ACOUST SOC AM, V139, pEL234, DOI 10.1121/1.4954497
   Ouni S, 2013, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2013-16
   Paeschke A, 1999, P 14 INT C PHON SCI, V2, P929
   Paul Lamere, 2003, IEEE INT C AC SPEECH
   Pell MD, 2009, J PHONETICS, V37, P417, DOI 10.1016/j.wocn.2009.07.005
   Queneau R, 2018, EXERCISES IN STYLE
   Raymond Q., 1947, EXERCICES DE STYLE
   Schabus D, 2014, IEEE J-STSP, V8, P336, DOI 10.1109/JSTSP.2013.2281036
   SCHERER KR, 1986, PSYCHOL BULL, V99, P143, DOI 10.1037/0033-2909.99.2.143
   Stella M, 2013, INTERSPEECH, P1315
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Vatikiotis-Bateson E., 1993, J ACOUST SOC AM, V93, P2414, DOI DOI 10.1121/1.405928
   Volker Strom R.C., 2006, INTERSPEECH
   Walsh B, 2012, MOVEMENT DISORD, V27, P843, DOI 10.1002/mds.24888
   WIGGERS M, 1982, J NONVERBAL BEHAV, V7, P101, DOI 10.1007/BF00986872
   Yehia HC, 2002, J PHONETICS, V30, P555, DOI 10.1006/jpho.2002.0165
   Yunusova Y, 2009, J SPEECH LANG HEAR R, V52, P547, DOI 10.1044/1092-4388(2008/07-0218)
NR 56
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1574-020X
EI 1574-0218
J9 LANG RESOUR EVAL
JI Lang. Resour. Eval.
PD DEC
PY 2020
VL 54
IS 4
BP 943
EP 974
DI 10.1007/s10579-020-09500-w
EA JUL 2020
PG 32
WC Computer Science, Interdisciplinary Applications
SC Computer Science
GA OI3VA
UT WOS:000552599600001
DA 2021-02-24
ER

PT J
AU de Almeida, LR
   Pope, PA
   Hansen, PC
AF Rodrigues de Almeida, Lilian
   Pope, Paul A.
   Hansen, Peter C.
TI Motor theory modulated by task load: behavioural effects of tDCS over
   the LSTG on phonological processing
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Phonological processing; task load; LSTG; language; tDCS
ID DIRECT-CURRENT STIMULATION; INFERIOR FRONTAL GYRUS; SPEECH-PERCEPTION;
   LANGUAGE PRODUCTION; PREMOTOR CORTEX; SEX-DIFFERENCES; LEXICAL ACCESS;
   BROCAS AREA; DORSAL; FMRI
AB Previously we claimed that motoric participation in phonological processing is modulated by task nature, with tDCS responses showing the LIFG increasingly relevant from perception to production. Here we investigated if the claim for a changing and complementary interplay between the LIFG and the LSTG across the speech perception to speech production range holds. We sought the reversed pattern of behavioural responses while targeting the LSTG, considered decreasingly relevant across the range. The same speech perception and production tasks from our previous studies were administered during either anodal, cathodal or sham stimulation. A-tDCS facilitation and C-tDCS inhibition should decrease from perception to production, while facilitatory compensation of C-tDCS downregulation should increase. Overall, the expected reversed pattern was observed with the LSTG as target. For example, downregulation of the LSTG during word naming, considered of low relevance for the LSTG and of higher relevance for the LIFG, caused facilitation, suggesting compensation.
C1 [Rodrigues de Almeida, Lilian; Pope, Paul A.; Hansen, Peter C.] Univ Birmingham, Sch Psychol, Birmingham, W Midlands, England.
RP de Almeida, LR (corresponding author), Univ Birmingham, Sch Psychol, Birmingham, W Midlands, England.
EM l.rodriguesdealmeida@bham.ac.uk
OI Rodrigues de Almeida, Lilian/0000-0002-1498-2207
FU CoordenacAo de Aperfeicoamento de Pessoal de Nivel Superior (CAPES)
   (Brazil)/University of BirminghamCAPES
FX This work was supported by a postgraduate scholarship from CoordenacAo
   de Aperfeicoamento de Pessoal de Nivel Superior (CAPES)
   (Brazil)/University of Birmingham to L.R.A.
CR Ackermann H, 2004, BRAIN LANG, V89, P320, DOI 10.1016/S0093-934X(03)00347-X
   Ackermann H, 2010, BRAIN STRUCT FUNCT, V214, P419, DOI 10.1007/s00429-010-0257-x
   Adank P, 2012, BRAIN LANG, V122, P42, DOI 10.1016/j.bandl.2012.04.014
   Amunts K, 1999, J COMP NEUROL, V412, P319, DOI 10.1002/(SICI)1096-9861(19990920)412:2<319::AID-CNE10>3.0.CO;2-7
   ANNETT M, 1972, BRIT J PSYCHOL, V63, P343, DOI 10.1111/j.2044-8295.1972.tb01282.x
   Baayen RH, 1995, CELEX LEXICAL DATABA
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bestmann S, 2008, EXP BRAIN RES, V191, P383, DOI 10.1007/s00221-008-1601-8
   Bikson M, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00688
   Binder JR, 2003, J COGNITIVE NEUROSCI, V15, P372, DOI 10.1162/089892903321593108
   Blank SC, 2002, BRAIN, V125, P1829, DOI 10.1093/brain/awf191
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Burton MW, 2001, COGNITIVE SCI, V25, P695, DOI 10.1207/s15516709cog2505_4
   Carreiras M, 2007, J COGNITIVE NEUROSCI, V19, P433, DOI 10.1162/jocn.2007.19.3.433
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Cornelissen PL, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0005359
   de Almeida LR, 2019, J NEUROSCI RES, V97, P1430, DOI 10.1002/jnr.24490
   Di Lazzaro V, 2008, J PHYSIOL-LONDON, V586, P4481, DOI 10.1113/jphysiol.2008.159558
   Dominguez A, 2014, INT J CLIN HLTH PSYC, V14, P240, DOI 10.1016/j.ijchp.2014.02.001
   Eickhoff SB, 2009, PHILOS T R SOC A, V367, P2399, DOI 10.1098/rsta.2008.0287
   Fertonani A, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00131
   Fiebach CJ, 2002, J COGNITIVE NEUROSCI, V14, P11, DOI 10.1162/089892902317205285
   FIEZ JA, 1995, J COGNITIVE NEUROSCI, V7, P357, DOI 10.1162/jocn.1995.7.3.357
   FORSTER KI, 1973, J VERB LEARN VERB BE, V12, P627, DOI 10.1016/S0022-5371(73)80042-8
   Fritsch B, 2010, NEURON, V66, P198, DOI 10.1016/j.neuron.2010.03.035
   Fujiyama H, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00115
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Gow DW, 2012, BRAIN LANG, V121, P273, DOI 10.1016/j.bandl.2012.03.005
   Gur RC, 2000, BRAIN LANG, V74, P157, DOI 10.1006/brln.2000.2325
   Hanel PHP, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168354
   Hartwigsen G, 2016, CEREB CORTEX, V26, P2590, DOI 10.1093/cercor/bhv092
   Hartwigsen G, 2013, P NATL ACAD SCI USA, V110, P16402, DOI 10.1073/pnas.1310190110
   Hartwigsen G, 2012, J NEUROSCI, V32, P16162, DOI 10.1523/JNEUROSCI.1010-12.2012
   Heim S, 2005, COGNITIVE BRAIN RES, V25, P982, DOI 10.1016/j.cogbrainres.2005.09.022
   Heise KF, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00146
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2011, BRAIN LANG, V119, P214, DOI 10.1016/j.bandl.2011.08.001
   Indefrey P, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00255
   Jacobson L, 2012, EXP BRAIN RES, V216, P1, DOI 10.1007/s00221-011-2891-9
   Jager J, 2017, MONOGR SOC RES CHILD, V82, P13, DOI 10.1111/mono.12296
   Keuleers E., 2013, VWR USEFUL FUNCTIONS
   Keuleers E, 2010, BEHAV RES METHODS, V42, P627, DOI 10.3758/BRM.42.3.627
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Kuo MF, 2006, NEUROREPORT, V17, P1703, DOI 10.1097/01.wnr.0000239955.68319.c2
   Lang N, 2004, EXP BRAIN RES, V156, P439, DOI 10.1007/s00221-003-1800-2
   Lee YS, 2012, J NEUROSCI, V32, P3942, DOI 10.1523/JNEUROSCI.3814-11.2012
   Leonard MK, 2014, TRENDS COGN SCI, V18, P472, DOI 10.1016/j.tics.2014.05.001
   Leuthardt EC, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00099
   Levy J, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006675
   Liakakis G, 2011, BEHAV BRAIN RES, V225, P341, DOI 10.1016/j.bbr.2011.06.022
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Liebenthal E, 2013, J NEUROSCI, V33, P15414, DOI 10.1523/JNEUROSCI.1511-13.2013
   Mangia AL, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00601
   MARSHALL JC, 1973, J PSYCHOLINGUIST RES, V2, P175, DOI 10.1007/BF01067101
   McCauley S. M., 2011, P ANN M COGN SCI SOC, P33
   McNorgan C, 2015, BRAIN LANG, V141, P110, DOI 10.1016/j.bandl.2014.12.002
   Meinzer M, 2013, J NEUROSCI, V33, P12470, DOI 10.1523/JNEUROSCI.5743-12.2013
   Meinzer M, 2012, J NEUROSCI, V32, P1859, DOI 10.1523/JNEUROSCI.4812-11.2012
   Meinzer M, 2009, J COGNITIVE NEUROSCI, V21, P2007, DOI 10.1162/jocn.2009.21219
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Muller PA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0091065
   Nitsche MA, 2001, NEUROLOGY, V57, P1899, DOI 10.1212/WNL.57.10.1899
   Nitsche MA, 2000, J PHYSIOL-LONDON, V527, P633, DOI 10.1111/j.1469-7793.2000.t01-1-00633.x
   Nitsche MA, 2015, BRAIN STIMUL, V8, P666, DOI 10.1016/j.brs.2015.03.008
   Nitsche MA, 2008, BRAIN STIMUL, V1, P206, DOI 10.1016/j.brs.2008.06.004
   Nosarti C, 2010, CEREB CORTEX, V20, P315, DOI 10.1093/cercor/bhp101
   Nozari N, 2014, BRAIN STIMUL, V7, P784, DOI 10.1016/j.brs.2014.07.035
   Nozari N, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0084338
   Okada K, 2006, NEUROREPORT, V17, P1293, DOI 10.1097/01.wnr.0000233091.82536.b2
   Okada K, 2006, BRAIN LANG, V98, P112, DOI 10.1016/j.bandl.2006.04.006
   Pagnotta MF, 2015, IEEE ENG MED BIO, P6959, DOI 10.1109/EMBC.2015.7319993
   Patterson K, 1987, COGNITIVE NEUROPSYCH, P273
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   Pinheiro J., 2016, COMPUTER SOFTWARE, V3, P1, DOI DOI 10.1016/J.CR0PR0.2007.08.015
   Pirulli C, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00226
   Pope PA, 2015, CEREB CORTEX, V25, P4551, DOI 10.1093/cercor/bhv094
   R Core Team, 2016, R LANG ENV STAT COMP
   Raizada RDS, 2007, NEURON, V56, P726, DOI 10.1016/j.neuron.2007.11.001
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Reynolds C., 2007, TEST IRREGULAR WORD
   de Almeida LR, 2020, COGN PROCESS, V21, P341, DOI 10.1007/s10339-020-00964-w
   Rogers JC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00754
   Russell M, 2014, FRONT PSYCHIATRY, V5, DOI 10.3389/fpsyt.2014.00104
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Seymour PHK, 2003, BRIT J PSYCHOL, V94, P143, DOI 10.1348/000712603321661859
   Silvanto J, 2017, BRAIN COGNITION, V119, P32, DOI 10.1016/j.bandc.2017.09.007
   Smalle EHM, 2015, CEREB CORTEX, V25, P3690, DOI 10.1093/cercor/bhu218
   Standage D, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00236
   Stasenko A, 2013, LANG COGN, V5, P225, DOI 10.1515/langcog-2013-0016
   Sun YF, 2010, PEDIATR NEONATOL, V51, P89, DOI 10.1016/S1875-9572(10)60017-4
   Torgesen J, 1999, TEST WORD READING EF
   Turkeltaub PE, 2010, BRAIN LANG, V114, P1, DOI 10.1016/j.bandl.2010.03.008
   Vandermosten M, 2011, RES DEV DISABIL, V32, P593, DOI 10.1016/j.ridd.2010.12.015
   Vitali P, 2007, NEUROREHAB NEURAL RE, V21, P152, DOI 10.1177/1545968306294735
   Waldie KE, 2013, BRAIN SCI, V3, P1060, DOI 10.3390/brainsci3031060
   Warren JE, 2005, TRENDS NEUROSCI, V28, P636, DOI 10.1016/j.tins.2005.09.010
   Watkins K, 2004, J COGNITIVE NEUROSCI, V16, P978, DOI 10.1162/0898929041502616
   Wei JW, 2012, AMINO ACIDS, V42, P2031, DOI 10.1007/s00726-011-0924-0
   Wheat KL, 2010, J NEUROSCI, V30, P5229, DOI 10.1523/JNEUROSCI.4448-09.2010
   Whelan R, 2008, PSYCHOL REC, V58, P475, DOI 10.1007/BF03395630
   WILLIAMS EJ, 1949, AUST J SCI RES SER A, V2, P149, DOI 10.1071/CH9490149
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Wise RJS, 1999, LANCET, V353, P1057, DOI 10.1016/S0140-6736(98)07491-1
   Woodhead ZVJ, 2014, CEREB CORTEX, V24, P817, DOI 10.1093/cercor/bhs365
   Xiao ZW, 2005, HUM BRAIN MAPP, V25, P212, DOI 10.1002/hbm.20105
   Yarkoni T, 2008, PSYCHON B REV, V15, P971, DOI 10.3758/PBR.15.5.971
NR 109
TC 0
Z9 0
U1 3
U2 3
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PD DEC 30
PY 2020
VL 36
IS 1
BP 99
EP 118
DI 10.1080/23273798.2020.1799046
EA JUL 2020
PG 20
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA PP2XI
UT WOS:000552548100001
DA 2021-02-24
ER

PT J
AU Niepel, D
   Krishna, B
   Siegel, ER
   Draganova, R
   Preissl, H
   Govindan, RB
   Eswaran, H
AF Niepel, Dorothea
   Krishna, Bhargavi
   Siegel, Eric R.
   Draganova, Rossitza
   Preissl, Hubert
   Govindan, Rathinaswamy B.
   Eswaran, Hari
TI A pilot study: Auditory steady-state responses (ASSR) can be measured in
   human fetuses using fetal magnetoencephalography (fMEG)
SO PLOS ONE
LA English
DT Article
ID BEHAVIORAL STATES; FREQUENCY; SOUND; RECORDINGS; POTENTIALS; SIGNATURES;
   NEWBORNS; AWAKE; AMFR
AB Background
   Auditory steady-state responses (ASSRs) are ongoing evoked brain responses to continuous auditory stimuli that play a role for auditory processing of complex sounds and speech perception. Transient auditory event-related responses (AERRs) have previously been recorded using fetal magnetoencephalography (fMEG) but involve different neurological pathways. Previous studies in children and adults demonstrated that the cortical components of the ASSR are significantly affected by state of consciousness and by maturational changes in neonates and young infants. To our knowledge, this is the first study to investigate ASSRs in human fetuses.
   Methods
   47 fMEG sessions were conducted with 24 healthy pregnant women in three gestational age groups (30-32 weeks, 33-35 weeks and 36-39 weeks). The stimulation consisted of amplitude-modulated (AM) tones with a duration of one second, a carrier frequency (CF) of 500 Hz and a modulation frequency (MF) of 27 Hz or 42 Hz. Both tones were presented in a random order with equal probability adding up to 80-100 repetitions per tone. The ASSR across trials was quantified by assessing phase synchrony in the cortical signals at the stimulation frequency.
   Results and conclusion
   Ten out of 47 recordings were excluded due to technical problems or maternal movements. Analysis of the included 37 fetal recordings revealed a statistically significant response for the phase coherence between trials for the MF of 27 Hz but not for 42 Hz. An exploratory subgroup analysis moreover suggested an advantage in detectability for fetal behavioral state 2F (active asleep) compared to 1F (quiet asleep) detected using fetal heart rate. In conclusion, this pilot study is the first description of a method to detect human ASSRs in fetuses. The findings warrant further investigations of the developing fetal brain.
C1 [Niepel, Dorothea; Eswaran, Hari] Univ Arkansas Med Sci, Ob Gynecol Dept, SARA Res Ctr, Little Rock, AR 72205 USA.
   [Niepel, Dorothea] Univ Hosp Tubingen, Dept Internal Med 1, Tubingen, Germany.
   [Krishna, Bhargavi] Oak Ridge Natl Lab, Oak Ridge, TN USA.
   [Siegel, Eric R.] Univ Arkansas Med Sci, Dept Biostat, Little Rock, AR 72205 USA.
   [Draganova, Rossitza] Univ Tubingen, fMEG Ctr, Tubingen, Germany.
   [Draganova, Rossitza] Univ Duisburg Essen, Univ Clin Essen, Dept Neurol, Motor Lab, Essen, Germany.
   [Preissl, Hubert] Univ Tubingen, German Ctr Diabet Res DZD, Inst Diabet Res & Metab Dis, fMEG Ctr,Helmholtz Ctr Munich, Tubingen, Germany.
   [Govindan, Rathinaswamy B.] Natl Childrens Hosp, Div Fetal & Transit Med, Washington, DC USA.
RP Niepel, D (corresponding author), Univ Arkansas Med Sci, Ob Gynecol Dept, SARA Res Ctr, Little Rock, AR 72205 USA.; Niepel, D (corresponding author), Univ Hosp Tubingen, Dept Internal Med 1, Tubingen, Germany.
EM dorothea.niepel@med.uni-tuebingen.de
RI PreiSSl, Hubert/E-9070-2012
OI PreiSSl, Hubert/0000-0002-8859-4661; Siegel, Eric/0000-0001-9824-6612
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [1R01EB007826]
FX This study was partly funded by National Institutes of Health grant
   1R01EB007826. There was no additional external funding received for this
   study. The funders had no role in study design, data collection and
   analysis, decision to publish, or preparation of the manuscript.
CR Anderson AL, 2013, NEUROSCI BIOBEHAV R, V37, P2220, DOI 10.1016/j.neubiorev.2013.03.013
   AOYAGI M, 1994, ACTA OTO-LARYNGOL, P15
   Brandle J, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3339/fnhum.2015.00147, 10.3389/fnhum.2015.00147]
   COHEN LT, 1991, J ACOUST SOC AM, V90, P2467, DOI 10.1121/1.402050
   Cone-Wesson B., 2008, AUDITORY STEADY STAT, P109
   Dimitrijevic A., 2008, AUDITORY STEADY STAT, P83
   Dimitrijevic A., 2008, AUDITORY STEADY STAT, P229
   Draganova R, 2018, HEARING RES, V363, P70, DOI 10.1016/j.heares.2018.03.005
   Draganova R, 2007, EARLY HUM DEV, V83, P199, DOI 10.1016/j.earlhumdev.2006.05.018
   Engelien A, 2000, HEARING RES, V148, P153, DOI 10.1016/S0378-5955(00)00148-9
   Eswaran H, 2002, NEUROSCI LETT, V331, P128, DOI 10.1016/S0304-3940(02)00859-5
   Frank B, 2006, MED BIOL ENG COMPUT, V44, P179, DOI 10.1007/s11517-005-0015-z
   GALAMBOS R, 1981, P NATL ACAD SCI-BIOL, V78, P2643, DOI 10.1073/pnas.78.4.2643
   GERHARDT KJ, 1990, AM J OBSTET GYNECOL, V162, P282, DOI 10.1016/0002-9378(90)90866-6
   Hartkopf J, 2016, EARLY HUM DEV, V100, P61, DOI 10.1016/j.earlhumdev.2016.04.002
   Herdman AT, 2002, BRAIN TOPOGR, V15, P69, DOI 10.1023/A:1021470822922
   Holst M, 2005, CLIN NEUROPHYSIOL, V116, P1949, DOI 10.1016/j.clinph.2005.04.008
   Jardri R, 2008, NEUROIMAGE, V42, P10, DOI 10.1016/j.neuroimage.2008.04.247
   John MS, 2004, EAR HEARING, V25, P539, DOI 10.1097/01.AUD.0000148050.80749.AC
   John S. M., 2008, AUDITORY STEADY STAT, P11
   Kiefer I, 2008, AM J OBSTET GYNECOL, V199, DOI 10.1016/j.ajog.2008.04.014
   Kiefer-Schmidt I, 2013, J PERINAT MED, V41, P605, DOI 10.1515/jpm-2013-0022
   Lengle JM, 2001, CLIN NEUROPHYSIOL, V112, P785, DOI 10.1016/S1388-2457(01)00532-6
   LEVI EC, 1993, HEARING RES, V68, P42, DOI 10.1016/0378-5955(93)90063-7
   Linder K, 2014, DIABETOLOGIA, V57, P1192, DOI 10.1007/s00125-014-3217-9
   Lins OG, 1996, EAR HEARING, V17, P81, DOI 10.1097/00003446-199604000-00001
   Lowery CL, 2003, AM J OBSTET GYNECOL, V188, P1491, DOI 10.1067/mob.2003.367
   MAURIZI M, 1990, AUDIOLOGY, V29, P322
   Moore JK, 2007, INT J AUDIOL, V46, P460, DOI 10.1080/14992020701383019
   Morin EC, 2015, BJOG-INT J OBSTET GY, V122, P1184, DOI 10.1111/1471-0528.13347
   Muenssinger J, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00917
   Muenssinger J, 2013, DEVELOPMENTAL SCI, V16, P287, DOI 10.1111/desc.12025
   Muthukumaraswamy SD, 2013, FRONT HUM NEUROSCI, V7
   NIJHUIS JG, 1982, EARLY HUM DEV, V6, P177, DOI 10.1016/0378-3782(82)90106-2
   Pethe J, 2001, SCAND AUDIOL, V30, P152, DOI 10.1080/010503901300007371
   Picton TW, 2003, INT J AUDIOL, V42, P177, DOI 10.3109/14992020309101316
   PLOURDE G, 1990, ANESTH ANALG, V71, P460
   Preissl H, 2005, INT REV NEUROBIOL, V68, P1, DOI 10.1016/S0074-7742(05)68001-4
   Purcell D. W, 2008, AUDITORY STEADY STAT, P55
   QUERLEU D, 1988, EUR J OBSTET GYN R B, V28, P191, DOI 10.1016/0028-2243(88)90030-5
   Rance G., 2008, AUDITORY STEADY STAT, P161
   Rance G., 2008, AUDITORY STEADY STAT, P119
   Rickards F.W., 2008, AUDITORY STEADY STAT, P1
   RICKARDS FW, 1994, BRIT J AUDIOL, V28, P327, DOI 10.3109/03005369409077316
   Riquelme R, 2006, EAR HEARING, V27, P104, DOI 10.1097/01.aud.0000201857.99240.24
   Ross B, 2003, HEARING RES, V186, P57, DOI 10.1016/S0378-5955(03)00299-5
   Ross B, 2002, HEARING RES, V165, P68, DOI 10.1016/S0378-5955(02)00285-X
   Schleger F, 2014, DEV NEUROPSYCHOL, V39, P316, DOI 10.1080/87565641.2014.914212
   SCHMIDT W, 1985, EARLY HUM DEV, V12, P145, DOI 10.1016/0378-3782(85)90177-X
   Schneider U, 2008, J PERINAT MED, V36, P433, DOI 10.1515/JPM.2008.059
   Sonanini A, 2014, J PERINAT MED, V42, P307, DOI 10.1515/jpm-2013-0180
   STAPELLS DR, 1988, ELECTROEN CLIN NEURO, V71, P289, DOI 10.1016/0168-5597(88)90029-9
   SUZUKI T, 1984, AUDIOLOGY, V23, P599
   Vrba J, 2004, IEEE T BIO-MED ENG, V51, P1207, DOI 10.1109/TBME.2004.827265
   Wilson JD, 2008, IEEE T BIO-MED ENG, V55, P2190, DOI 10.1109/TBME.2008.923916
NR 55
TC 0
Z9 0
U1 0
U2 0
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD JUL 22
PY 2020
VL 15
IS 7
AR e0235310
DI 10.1371/journal.pone.0235310
PG 19
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA NX7SC
UT WOS:000575905100002
PM 32697776
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Johnson, K
AF Johnson, Keith
TI The Delta F method of vocal tract length normalization for vowels
SO LABORATORY PHONOLOGY
LA English
DT Article
DE Speech Perception; Talker Normalization; Vowel Normalization; Vocal
   Tract Length
ID CLASSIFICATION; PERCEPTION
AB Given the acoustic consequences of physiological differences between talkers, there is a practical need for effective and theoretically motivated procedures of vowel normalization to facilitate comparison of speech produced by people who differ by dialect or language. In addition, there is a question whether listeners might utilize a normalization procedure during speech perception. This paper reports the results of two studies that explore these questions-with particular focus on vocal tract length normalization. Drawing on research in speech engineering, where accurate estimates of vocal tract length are needed in some approaches to automatic speech recognition and speaker verification, a new model of vowel normalization is introduced. The model uses a direct measure of average formant spacing (the Delta F) which can be used to measure vocal tract length. The acoustic consequences of vocal tract length differences are removed from vowel measurements by scaling vowel formant measurements by Delta F. Study 1 found that this method is comparable to Nearey's (1978) uniform normalization method, while providing an explicit vocal tract length interpretation, and a rationalized unit of measure. Study 2 found that uniform normalization measures (which let each formant serve as a noisy estimator of Delta F) improve vowel classification even with only a couple of randomly selected vowel tokens. This suggests that vocal tract length normalization could be involved in speech perception.
C1 [Johnson, Keith] Univ Calif Berkeley, Dept Linguist, Berkeley, CA 94720 USA.
RP Johnson, K (corresponding author), Univ Calif Berkeley, Dept Linguist, Berkeley, CA 94720 USA.
EM keithjohnson@berkeley.edu
CR Adank P, 2004, J ACOUST SOC AM, V116, P3099, DOI 10.1121/1.1795335
   Barreda S, 2018, J ACOUST SOC AM, V144, P500, DOI 10.1121/1.5047742
   BLADON RAW, 1984, LANG COMMUN, V4, P59, DOI 10.1016/0271-5309(84)90019-3
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   DISNER SF, 1980, J ACOUST SOC AM, V67, P253, DOI 10.1121/1.383734
   Eide E, 1996, INT CONF ACOUST SPEE, P346, DOI 10.1109/ICASSP.1996.541103
   Fabricius AH, 2009, LANG VAR CHANGE, V21, P413, DOI 10.1017/S0954394509990160
   Fant G., 1960, ACOUSTIC THEORY SPEE
   FUJISAKI H, 1968, IEEE T ACOUST SPEECH, VAU16, P73, DOI 10.1109/TAU.1968.1161952
   GERSTMAN LJ, 1968, IEEE T ACOUST SPEECH, VAU16, P78, DOI 10.1109/TAU.1968.1161953
   HARRINGTON FH, 1979, BEHAVIOUR, V68, P207, DOI 10.1163/156853979X00322
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hindle D., 1978, LINGUISTIC VARIATION, P161
   JOHNSON K, 1990, J ACOUST SOC AM, V88, P642, DOI 10.1121/1.399767
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Johnson K, 2011, ACOUSTIC AUDITORY PH
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Johnson K., SPEAKER NORMALIZATIO
   Johnson K, 2005, BLACKW HBK LINGUIST, P363, DOI 10.1002/9780470757024.ch15
   KIRLIN RL, 1978, IEEE T ACOUST SPEECH, V26, P571, DOI 10.1109/TASSP.1978.1163151
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Lammert AC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0132193
   Lee L, 1998, IEEE T SPEECH AUDI P, V6, P49, DOI 10.1109/89.650310
   LOBANOV BM, 1971, J ACOUST SOC AM, V49, P606, DOI 10.1121/1.1912396
   Nearey Terrance Michael, 1978, PHONETIC FEATURE SYS
   NEAREY TM, 1986, J ACOUST SOC AM, V80, P1297, DOI 10.1121/1.394433
   NEAREY TM, 1989, J ACOUST SOC AM, V85, P2088, DOI 10.1121/1.397861
   Nordstrom P. E., 1975, P 8 INT C PHON SCI L
   PAIGE A, 1970, IEEE T ACOUST SPEECH, VAU18, P268, DOI 10.1109/TAU.1970.1162113
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Reby D, 2003, ANIM BEHAV, V65, P519, DOI 10.1006/anbe.2003.2078
   Strand EA, 1996, NATURAL LANGUAGE PROCESSING AND SPEECH TECHNOLOGY, P14
   STRANGE W, 1983, J ACOUST SOC AM, V74, P695, DOI 10.1121/1.389855
   VANLANCKER DR, 1989, J CLIN EXP NEUROPSYC, V11, P665, DOI 10.1080/01688638908400923
   WAKITA H, 1977, IEEE T ACOUST SPEECH, V25, P183, DOI 10.1109/TASSP.1977.1162929
   Watt D., 2002, LEEDS WORKING PAPERS, V9, P159
NR 36
TC 0
Z9 0
U1 1
U2 1
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD JUL 22
PY 2020
VL 11
IS 1
AR 10
DI 10.5334/labphon.196
PG 16
WC Linguistics; Language & Linguistics
SC Linguistics
GA MR1HM
UT WOS:000553342500001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Mandal, S
   Best, CT
   Shaw, J
   Cutler, A
AF Mandal, Sayantan
   Best, Catherine T.
   Shaw, Jason
   Cutler, Anne
TI Bilingual phonology in dichotic perception: A case study of Malayalam
   and English voicing
SO GLOSSA-A JOURNAL OF GENERAL LINGUISTICS
LA English
DT Article
DE dichotic listening; speech perception; voicing; distinctive feature
   theory; underspecification; perceptual assimilation
ID LANGUAGE; REPRESENTATION; STOPS
AB Listeners often experience cocktail-party situations, encountering multiple ongoing conversations while tracking just one. Capturing the words spoken under such conditions requires selective attention and processing, which involves using phonetic details to discern phonological structure. How do bilinguals accomplish this in L1-L2 competition? We addressed that question using a dichotic listening task with fluent Malayalam-English bilinguals, in which they were presented with synchronized nonce words, one in each language in separate ears, with competing onsets of a labial stop (Malayalam) and a labial fricative (English), both voiced or both voiceless. They were required to attend to the Malayalam or the English item, in separate blocks, and report the initial consonant they heard. We found that perceptual intrusions from the unattended to the attended language were influenced by voicing, with more intrusions on voiced than voiceless trials. This result supports our proposal for the feature specification of consonants in Malayalam-English bilinguals, which makes use of privative features, underspecification and the "standard approach" to laryngeal features, as against "laryngeal realism". Given this representational account, we observe that intrusions result from phonetic properties in the unattended signal being assimilated to the closest matching phonological category in the attended language, and are more likely for segments with a greater number of phonological feature specifications.
C1 [Mandal, Sayantan] Concordia Univ, Montreal, PQ, Canada.
   [Best, Catherine T.; Cutler, Anne] Western Sydney Univ, MARCS Inst, Sydney, NSW, Australia.
   [Shaw, Jason] Yale Univ, Dept Linguist, New Haven, CT USA.
   [Cutler, Anne] Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
   [Cutler, Anne] ARC Ctr Excellence Dynam Language, Canberra, ACT, Australia.
RP Mandal, S (corresponding author), Concordia Univ, Montreal, PQ, Canada.
EM sayantan.mandal@mail.concordia.ca
FU MARCS post-graduate scholarship
FX We thank participants at the Australian Linguistics Society meeting
   where parts of this work were presented, for their comments, as well as
   the Glossa Associate Editor and three anonymous reviewers, whose
   comments greatly improved the paper. This research was supported by a
   MARCS post-graduate scholarship to the first author.
CR Antoniou M, 2013, J ACOUST SOC AM, V133, P2397, DOI 10.1121/1.4792358
   Antoniou M, 2012, J PHONETICS, V40, P582, DOI 10.1016/j.wocn.2012.05.005
   Archangeli D., 1988, PHONOLOGY, V5, DOI [DOI 10.1017/S0952675700002268, 10.1017/S0952675700002268]
   Asher R. E., 1985, TAMIL
   Beckman J, 2013, J LINGUIST, V49, P259, DOI 10.1017/S0022226712000424
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best Catherine T. Jason A., 2015, INT 2015 DRESD GERM
   Best Catherine T. Jason A., 2015, 18 INT C PHON SCI GL
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bundgaard-Nielsen RL, 2011, STUD SECOND LANG ACQ, V33, P433, DOI 10.1017/S0272263111000040
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Faris MM, 2016, J ACOUST SOC AM, V139, pEL1, DOI 10.1121/1.4939608
   Golston C, 1996, LANGUAGE, V72, P713, DOI 10.2307/416100
   Grosjean F. M. J., 1988, LANG COGNITIVE PROC, V3, P233, DOI DOI 10.1080/01690968808402089
   Hall Alan T., 2001, DISTINCTIVE FEATURE, P1, DOI 10.1515/9783110886672.1
   Honeybone Patrick, 2005, INTERNAL ORG PHONOLO, P319, DOI DOI 10.1515/9783110890402
   Iverson G.K., 1999, LINGUISTISCHE BERICH, V178, P135
   Iverson GK, 2007, LANG SCI, V29, P247, DOI 10.1016/j.langsci.2006.12.012
   Iverson Gregory K., 2003, PHONOLOGY, V20, P43, DOI DOI 10.1017/S0952675703004469
   Jakobson Roman, 1949, IDENTIFICATION PHONE, DOI [10.1080/01050206.1949.10416304, DOI 10.1080/01050206.1949.10416304]
   Jessen M., 2002, PHONOLOGY, V19, P189, DOI [10.1017/S0952675702004311, DOI 10.1017/S0952675702004311]
   Kager R, 2007, VOICING DUTCH DEVOIC, P41, DOI [10.1075/cilt.286.03kag, DOI 10.1075/CILT.286, DOI 10.1075/CILT.286.03KAG]
   KEATING PA, 1984, LANGUAGE, V60, P286, DOI 10.2307/413642
   Kehrein W., 2004, PHONOLOGY, V21, P325, DOI DOI 10.1017/S0952675704000302
   KenstowIcz M., 1994, PHONOLOGY GENERATIVE
   KIMURA D, 1961, CAN J PSYCHOLOGY, V15, P166, DOI 10.1037/h0083219
   KIMURA D, 1961, CAN J PSYCHOLOGY, V15, P156, DOI 10.1037/h0083218
   Kimura D, 1967, CORTEX, V3, P163, DOI [DOI 10.1016/S0010-9452(67)80010-8, 10.1016/s0010-9452(67)80010-8]
   Lahiri A, 2010, J PHONETICS, V38, P44, DOI 10.1016/j.wocn.2010.01.002
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Lombardi Linda, 2018, LARYNGEAL FEATURES L, DOI [10.4324/9780429454929, DOI 10.4324/9780429454929]
   Maddieson Ian, 1984, PATTERNS SOUNDS, DOI [10.1017/CBO9780511753459, DOI 10.1017/CBO9780511753459]
   Petrova O, 2006, LINGUIST REV, V23, P1, DOI 10.1515/TLR.2006.001
   Salmons J. C., 1995, PHONOLOGY, V12, P369, DOI DOI 10.1017/S0952675700002566
   Shaw JA, 2018, LAB PHONOL, V9, DOI 10.5334/labphon.87
   Spivey MJ, 1999, PSYCHOL SCI, V10, P281, DOI 10.1111/1467-9280.00151
   Steriade D., 1995, HDB PHONOLOGICAL THE, P114, DOI 10.1111/b.9780631201267.1996.00006.x
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0
NR 40
TC 0
Z9 0
U1 0
U2 0
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 2397-1835
J9 GLOSSA-UK
JI Glossa
PD JUL 22
PY 2020
VL 5
IS 1
AR 73
DI 10.5334/gjgl.853
PG 17
WC Linguistics; Language & Linguistics
SC Linguistics
GA MO1HX
UT WOS:000551287200001
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Plass, J
   Brang, D
   Suzuki, S
   Grabowecky, M
AF Plass, John
   Brang, David
   Suzuki, Satoru
   Grabowecky, Marcia
TI Vision perceptually restores auditory spectral dynamics in speech
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
LA English
DT Article
DE audiovisual speech; speech perception; multisensory; spectrotemporal
ID SUPERIOR TEMPORAL SULCUS; MULTISENSORY INTEGRATION; INVERSE
   EFFECTIVENESS; AUDIOVISUAL SPEECH; CORTEX; SOUNDS; RECOGNITION;
   ASSOCIATION; PERCEPTION; MOTION
AB Visual speech facilitates auditory speech perception, but the visual cues responsible for these benefits and the information they provide remain unclear. Low-level models emphasize basic tempo-ral cues provided by mouth movements, but these impoverished signals may not fully account for the richness of auditory informa-tion provided by visual speech. High-level models posit interactions among abstract categorical (i.e., phonemes/visemes) or amodal (e.g., articulatory) speech representations, but require lossy remap-ping of speech signals onto abstracted representations. Because visible articulators shape the spectral content of speech, we hypoth-esized that the perceptual system might exploit natural correlations between midlevel visual (oral deformations) and auditory speech features (frequency modulations) to extract detailed spectrotempo-ral information from visual speech without employing high-level abstractions. Consistent with this hypothesis, we found that the time-frequency dynamics of oral resonances (formants) could be predicted with unexpectedly high precision from the changing shape of the mouth during speech. When isolated from other speech cues, speech-based shape deformations improved perceptual sensitivity for corresponding frequency modulations, suggesting that listeners could exploit this cross-modal correspondence to facil-itate perception. To test whether this type of correspondence could improve speech comprehension, we selectively degraded the spec-tral or temporal dimensions of auditory sentence spectrograms to assess how well visual speech facilitated comprehension under each degradation condition. Visual speech produced drastically larger en-hancements during spectral degradation, suggesting a condition -specific facilitation effect driven by cross-modal recovery of auditory speech spectra. The perceptual system may therefore use audiovi-sual correlations rooted in oral acoustics to extract detailed spectro-temporal information from visual speech.
C1 [Plass, John; Brang, David] Univ Michigan, Dept Psychol, Ann Arbor, MI 48109 USA.
   [Plass, John; Suzuki, Satoru; Grabowecky, Marcia] Northwestern Univ, Dept Psychol, Evanston, IL 60208 USA.
   [Suzuki, Satoru; Grabowecky, Marcia] Northwestern Univ, Interdept Neurosci Program, Chicago, IL 60611 USA.
RP Plass, J (corresponding author), Univ Michigan, Dept Psychol, Ann Arbor, MI 48109 USA.; Plass, J (corresponding author), Northwestern Univ, Dept Psychol, Evanston, IL 60208 USA.
EM jplass@umich.edu
OI Plass, John/0000-0002-7454-5922
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [T32 NS047987]
FX This research was supported by NIH Grant T32 NS047987.
CR Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009
   Arsenault JS, 2016, PSYCHON B REV, V23, P1231, DOI 10.3758/s13423-015-0988-z
   Assaneo MF, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aao3842
   BARNES CL, 1992, J COMP NEUROL, V318, P222, DOI 10.1002/cne.903180207
   Beauchamp M. S., 2016, NEUROBIOLOGY LANGUAG, P515, DOI DOI 10.1016/B978-0-12-407794-2.00093-6
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   BRAIDA LD, 1991, Q J EXP PSYCHOL-A, V43, P647, DOI 10.1080/14640749108400991
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Cheung C, 2016, ELIFE, V5, DOI 10.7554/eLife.12577
   Cotton J C, 1935, Science, V82, P592, DOI 10.1126/science.82.2138.592
   Crosse MJ, 2015, J NEUROSCI, V35, P14195, DOI 10.1523/JNEUROSCI.1829-15.2015
   Davis H, 1970, HEARING AND DEAFNESS
   Delattre Piere, 1951, PMLA, V66.5, P864
   Elliott TM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000302
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Eskelund K, 2011, EXP BRAIN RES, V208, P447, DOI 10.1007/s00221-010-2495-9
   Fant G., 1971, ACOUSTIC THEORY SPEE
   Fetsch CR, 2009, J NEUROSCI, V29, P15601, DOI 10.1523/JNEUROSCI.2574-09.2009
   Furl N, 2015, CEREB CORTEX, V25, P2876, DOI 10.1093/cercor/bhu083
   FURUI S, 1986, J ACOUST SOC AM, V80, P1016, DOI 10.1121/1.393842
   Ghazanfar AA, 2008, J NEUROSCI, V28, P4457, DOI 10.1523/JNEUROSCI.0541-08.2008
   Ghazanfar AA, 2009, BEHAV NEUROSCI, V123, P822, DOI 10.1037/a0016391
   Giese MA, 2003, NAT REV NEUROSCI, V4, P179, DOI 10.1038/nrn1057
   Golumbic EZ, 2013, J NEUROSCI, V33, P1417, DOI 10.1523/JNEUROSCI.3675-12.2013
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Green K. P., 1996, SPEECHREADING HUMANS, P55
   GREEN KP, 1998, HEARING EYE, V2, P3
   Hermansky H., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P480, DOI 10.1109/ICASSP.1989.266468
   Holdgraf CR, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13654
   Holmes NP, 2007, NEUROPSYCHOLOGIA, V45, P3340, DOI 10.1016/j.neuropsychologia.2007.05.025
   Holmes NP, 2009, BRAIN TOPOGR, V21, P168, DOI 10.1007/s10548-009-0097-2
   Hullett PW, 2016, J NEUROSCI, V36, P2014, DOI 10.1523/JNEUROSCI.1779-15.2016
   Irwin J, 2017, LANG LINGUIST COMPAS, V11, DOI 10.1111/lnc3.12237
   Jiang J., 2002, EURASIP J ADV SIG PR, V2002, DOI DOI 10.1155/S1110865702206046
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kim HW, 2018, MULTISENS RES, V31, P419, DOI 10.1163/22134808-00002581
   KUHN GM, 1975, J ACOUST SOC AM, V58, P428, DOI 10.1121/1.380687
   LINDBLOM BE, 1967, J ACOUST SOC AM, V42, P830, DOI 10.1121/1.1910655
   Liu C, 2008, J ACOUST SOC AM, V124, P1704, DOI 10.1121/1.2956468
   Luo H, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000445
   Ma WJ, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004638
   Magnotti JF, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005229
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MEREDITH MA, 1986, J NEUROPHYSIOL, V56, P640
   Paris T, 2013, BRAIN LANG, V126, P350, DOI 10.1016/j.bandl.2013.06.008
   Pisoni D. B., 1987, PSYCHOPHYSICS SPEECH, P155
   Plass J., 2020, SUPPLEMENTAL MAT VIS
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Prins N., 2009, PALAMEDES MATLAB ROU
   Puschmann S, 2019, NEUROIMAGE, V196, P261, DOI 10.1016/j.neuroimage.2019.04.017
   REPP BH, 1982, PSYCHOL BULL, V92, P81, DOI 10.1037/0033-2909.92.1.81
   Richie C., 2017, DATA AUDIOVISUAL DAT
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Rubin P., 1996, 1 ETRW SPEECH PROD M
   Santoro R, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003412
   Schroeder CE, 2008, TRENDS COGN SCI, V12, P106, DOI 10.1016/j.tics.2008.01.002
   SELTZER B, 1994, J COMP NEUROL, V343, P445, DOI 10.1002/cne.903430308
   Stein BE, 2008, NAT REV NEUROSCI, V9, P255, DOI 10.1038/nrn2331
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1992, PHILOS T ROY SOC B, V335, P71, DOI 10.1098/rstb.1992.0009
   SUMMERFIELD Q, 1984, Q J EXP PSYCHOL-A, V36, P51, DOI 10.1080/14640748408401503
   Suzuki S., 2005, FITTING MIND WORLD A, V2, P135, DOI DOI 10.1093/ACPROF:OSO/9780198529699.003.0006
   Sweeny TD, 2012, COGNITION, V124, P194, DOI 10.1016/j.cognition.2012.04.009
   Tian B, 2004, J NEUROPHYSIOL, V92, P2993, DOI 10.1152/jn.00472.2003
   Turkmani A., 2008, VISUAL ANAL VISEME D
   van Atteveldt N, 2014, NEURON, V81, P1240, DOI 10.1016/j.neuron.2014.02.044
   WATSON AB, 1983, PERCEPT PSYCHOPHYS, V33, P113, DOI 10.3758/BF03202828
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
   Zeng FG, 2005, P NATL ACAD SCI USA, V102, P2293, DOI 10.1073/pnas.0406460102
   Zhu LL, 2017, J NEUROSCI, V37, P2697, DOI 10.1523/JNEUROSCI.2914-16.2017
NR 72
TC 0
Z9 0
U1 0
U2 0
PU NATL ACAD SCIENCES
PI WASHINGTON
PA 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA
SN 0027-8424
J9 P NATL ACAD SCI USA
JI Proc. Natl. Acad. Sci. U. S. A.
PD JUL 21
PY 2020
VL 117
IS 29
BP 16920
EP 16927
DI 10.1073/pnas.2002887117
PG 8
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA MR0OL
UT WOS:000553292900009
PM 32632010
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Chung, WL
   Bidelman, GM
AF Chung, Wei-Lun
   Bidelman, Gavin M.
TI Mandarin-speaking preschoolers' pitch discrimination, prosodic and
   phonological awareness, and their relation to receptive vocabulary and
   reading abilities
SO READING AND WRITING
LA English
DT Article
DE Auditory perception; Suprasegmentals; Prosody; Vocabulary; Reading
ID AUDITORY-SENSITIVITY; LANGUAGE IMPAIRMENT; SPEECH-PERCEPTION; CHINESE;
   CHILDREN; SKILLS; TONE; STRESS; ACQUISITION; RHYTHM
AB Cross-linguistic studies have reported that prosodic pattern awareness (e.g., lexical stress and lexical tone) is more important to reading acquisition than phonological awareness. However, few longitudinal studies have been conducted to explore the relations between these variables. This study examined preschoolers' pitch discrimination, prosodic and phonological awareness, and their connection to receptive vocabulary in preschool and reading abilities in first grade. Findings reveal (1) children improve their pitch discrimination and prosodic awareness from preschool to fourth grade; (2) pitch interval discrimination (frequency separation between tones) contributes to receptive vocabulary whereas pitch contour discrimination (patterns of rising and falling pitch) predicts word reading; (3) phonological awareness accounts for more variability in receptive vocabulary than prosodic awareness; whereas the reverse was found for word reading and reading comprehension. Together, prosody and its acoustic cue (i.e., pitch) play a vital role in learning to read Mandarin.
C1 [Chung, Wei-Lun] Natl Taipei Univ Educ, Dept Educ, 134,Sec 2,Heping E Rd, Taipei 10671, Taiwan.
   [Bidelman, Gavin M.] Univ Memphis, Sch Commun Sci & Disorders, 4055 North Pk Loop, Memphis, TN 38152 USA.
   [Chung, Wei-Lun] Natl Taipei Univ Educ, Ctr Teacher Educ & Career Serv, Taipei, Taiwan.
   [Bidelman, Gavin M.] Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.
   [Bidelman, Gavin M.] Univ Tennessee, Hlth Sci Ctr, Dept Anat & Neurobiol, Memphis, TN USA.
RP Chung, WL (corresponding author), Natl Taipei Univ Educ, Dept Educ, 134,Sec 2,Heping E Rd, Taipei 10671, Taiwan.; Chung, WL (corresponding author), Natl Taipei Univ Educ, Ctr Teacher Educ & Career Serv, Taipei, Taiwan.
EM wwlchung@mail.ntue.edu.tw; gmbdlman@memphis.edu
RI Chung, Wei-Lun/G-4696-2012
OI CHUNG, WEI-LUN/0000-0002-4157-5631; Bidelman, Gavin
   M/0000-0002-1821-3261
FU NIH/NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R01DC016267, MOST
   107-2410-H-152-027]
FX G. M. B. was supported by NIH/NIDCD R01DC016267. W. L C. was supported
   by the Grant MOST 107-2410-H-152-027
CR Antoniou M, 2015, APPL PSYCHOLINGUIST, V36, P1493, DOI 10.1017/S0142716414000514
   Chao Y.R., 1948, MANDARIN PRIMER
   Cheung H, 2001, COGNITION, V81, P227, DOI 10.1016/S0010-0277(01)00136-6
   CHRISTOPHERSON LA, 1992, J SPEECH HEAR RES, V35, P929, DOI 10.1044/jshr.3504.929
   Chung WL, 2007, READ WRIT, V20, P441, DOI 10.1007/s11145-006-9037-7
   Chung WL, 2017, READ WRIT, V30, P1407, DOI 10.1007/s11145-017-9730-8
   Corriveau K, 2007, J SPEECH LANG HEAR R, V50, P647, DOI 10.1044/1092-4388(2007/046)
   Corriveau KH, 2009, CORTEX, V45, P119, DOI 10.1016/j.cortex.2007.09.008
   Cutler A, 1996, SIGNAL TO SYNTAX: BOOTSTRAPPING FROM SPEECH TO GRAMMAR IN EARLY ACQUISITION, P87
   CUTLER A, 1993, J PHONETICS, V21, P103, DOI 10.1016/S0095-4470(19)31323-3
   Duanmu S., 2007, PHONOLOGY STANDARD C
   Echols CH, 1996, SIGNAL TO SYNTAX: BOOTSTRAPPING FROM SPEECH TO GRAMMAR IN EARLY ACQUISITION, P151
   Elbro C, 1996, READ WRIT, V8, P453, DOI 10.1007/BF00577023
   Ference J, 2013, J EXP CHILD PSYCHOL, V116, P891, DOI 10.1016/j.jecp.2013.08.006
   Foxton JM, 2003, NAT NEUROSCI, V6, P343, DOI 10.1038/nn1035
   Frazier L, 2006, TRENDS COGN SCI, V10, P244, DOI 10.1016/j.tics.2006.04.002
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   Goswami U, 2013, J MEM LANG, V69, P1, DOI 10.1016/j.jml.2013.03.001
   Goswami U, 2010, READ WRIT, V23, P995, DOI 10.1007/s11145-009-9186-6
   Goswami U, 2011, J COGNITIVE NEUROSCI, V23, P325, DOI 10.1162/jocn.2010.21453
   Ho CSH, 1997, J PSYCHOLINGUIST RES, V26, P109, DOI 10.1023/A:1025016322316
   Holliman AJ, 2008, BRIT J DEV PSYCHOL, V26, P357, DOI 10.1348/026151007X241623
   Howie J.M., 1976, ACOUSTICAL STUDIES M
   Hu CF, 1998, SCI STUD READ, V2, P55, DOI DOI 10.1207/S1532799XSSR0201_3
   Hu CF, 2013, READ WRIT, V26, P163, DOI 10.1007/s11145-012-9360-0
   Huang HS, 2004, GRADED CHINESE CHARA
   Jarmulowicz L, 2007, J SPEECH LANG HEAR R, V50, P1593, DOI 10.1044/1092-4388(2007/107)
   JENSEN JK, 1993, PSYCHOL SCI, V4, P104, DOI 10.1111/j.1467-9280.1993.tb00469.x
   LI CN, 1977, J CHILD LANG, V4, P185, DOI 10.1017/S0305000900001598
   Lu L., 1998, PEABODY PICTURE VOCA
   McBride-Chang C., 2003, READING DEV CHINESE
   McBride-Chang C, 2008, SCI STUD READ, V12, P171, DOI 10.1080/10888430801917290
   MEHTA G, 1988, LANG SPEECH, V31, P135, DOI 10.1177/002383098803100203
   Meng YR, 2015, ELEMENTARY SCH READI
   Metsala JL, 1997, MEM COGNITION, V25, P47, DOI 10.3758/BF03197284
   Metsala JL, 1997, J EDUC PSYCHOL, V89, P159, DOI 10.1037/0022-0663.89.1.159
   Muter V, 1998, J EXP CHILD PSYCHOL, V71, P1
   Patel AD, 1998, BRAIN LANG, V61, P123, DOI 10.1006/brln.1997.1862
   Peretz I, 2003, NAT NEUROSCI, V6, P688, DOI 10.1038/nn1083
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   Reeves C, 2000, J EXP PSYCHOL LEARN, V26, P1638, DOI 10.1037//0278-7393.26.6.1638
   Siok WT, 2001, DEV PSYCHOL, V37, P886, DOI 10.1037//0012-1649.37.6.886
   So D, 1997, READ WRIT, V9, P1, DOI 10.1023/A:1007963513853
   STURGES PT, 1974, J EXP PSYCHOL, V102, P377, DOI 10.1037/h0035866
   Vihman M, 2007, LINGUISTICS, V45, P683, DOI 10.1515/LING.2007.021
   Wang HLS, 2016, PERCEPT MOTOR SKILL, V123, P365, DOI 10.1177/0031512516663164
   Wang HLS, 2012, READ WRIT, V25, P509, DOI 10.1007/s11145-010-9284-5
   Whalley K, 2006, J RES READ, V29, P288, DOI 10.1111/j.1467-9817.2006.00309.x
   Wong AMY, 2009, J SPEECH LANG HEAR R, V52, P1493, DOI 10.1044/1092-4388(2009/08-0170)
   Wood C, 1998, BRIT J DEV PSYCHOL, V16, P397, DOI 10.1111/j.2044-835X.1998.tb00760.x
   Wood C, 2009, AM SOC PUBLIC ADMIN, P73
   Zhang J., 2011, WRITING SYSTEMS RES, V3, P87, DOI [10.1093/wsr/wsr011, DOI 10.1093/WSR/WSR011]
   Zhang J, 2014, DEV PSYCHOL, V50, P1001, DOI 10.1037/a0035086
   Zhang JA, 2010, EDUC PSYCHOL REV, V22, P323, DOI 10.1007/s10648-010-9137-4
NR 54
TC 1
Z9 1
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0922-4777
EI 1573-0905
J9 READ WRIT
JI Read. Writ.
PD FEB
PY 2021
VL 34
IS 2
BP 337
EP 353
DI 10.1007/s11145-020-10075-9
EA JUL 2020
PG 17
WC Education & Educational Research; Psychology, Educational
SC Education & Educational Research; Psychology
GA QD0WJ
UT WOS:000550587100001
DA 2021-02-24
ER

PT J
AU Mahmud, MS
   Ahmed, F
   Al-Fahad, R
   Moinuddin, KA
   Yeasin, M
   Alain, C
   Bidelman, GM
AF Mahmud, Md Sultan
   Ahmed, Faruk
   Al-Fahad, Rakib
   Moinuddin, Kazi Ashraf
   Yeasin, Mohammed
   Alain, Claude
   Bidelman, Gavin M.
TI Decoding Hearing-Related Changes in Older Adults' Spatiotemporal Neural
   Processing of Speech Using Machine Learning
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE speech perception; aging; event-related potentials; hearing loss;
   machine learning; stability selection and control; support vector
   machine
ID AGE-RELATED-CHANGES; BOUNDARY-ELEMENT METHOD; AUDITORY-CORTEX;
   EVOKED-POTENTIALS; HUMAN BRAIN; PERCEPTION; NOISE; LATENCY; EEG;
   LATERALIZATION
AB Speech perception in noisy environments depends on complex interactions between sensory and cognitive systems. In older adults, such interactions may be affected, especially in those individuals who have more severe age-related hearing loss. Using a data-driven approach, we assessed the temporal (whenin time) and spatial (wherein the brain) characteristics of cortical speech-evoked responses that distinguish older adults with or without mild hearing loss. We performed source analyses to estimate cortical surface signals from the EEG recordings during a phoneme discrimination task conducted under clear and noise-degraded conditions. We computed source-level ERPs (i.e., mean activation within each ROI) from each of the 68 ROIs of the Desikan-Killiany (DK) atlas, averaged over a randomly chosen 100 trials without replacement to form feature vectors. We adopted a multivariate feature selection method called stability selection and control to choose features that are consistent over a range of model parameters. We use parameter optimized support vector machine (SVM) as a classifiers to investigate thetime courseandbrain regionsthat segregate groups and speech clarity. For clear speech perception, whole-brain data revealed a classification accuracy of 81.50% [area under the curve (AUC) 80.73%; F1-score 82.00%], distinguishing groups within similar to 60 ms after speech onset (i.e., as early as the P1 wave). We observed lower accuracy of 78.12% [AUC 77.64%; F1-score 78.00%] and delayed classification performance when speech was embedded in noise, with group segregation at 80 ms. Separate analysis using left (LH) and right hemisphere (RH) regions showed that LH speech activity was better at distinguishing hearing groups than activity measured in the RH. Moreover, stability selection analysis identified 12 brain regions (among 1428 total spatiotemporal features from 68 regions) where source activity segregated groups with >80% accuracy (clear speech); whereas 16 regions were critical for noise-degraded speech to achieve a comparable level of group segregation (78.7% accuracy). Our results identify critical time-courses and brain regions that distinguish mild hearing loss from normal hearing in older adults and confirm a larger number of active areas, particularly in RH, when processing noise-degraded speech information.
C1 [Mahmud, Md Sultan; Ahmed, Faruk; Al-Fahad, Rakib; Moinuddin, Kazi Ashraf; Yeasin, Mohammed] Univ Memphis, Dept Elect & Comp Engn, Memphis, TN 38152 USA.
   [Alain, Claude] Rotman Res Inst, Baycrest Ctr Geriatr Care, Toronto, ON, Canada.
   [Alain, Claude] Univ Toronto, Dept Psychol, Toronto, ON, Canada.
   [Alain, Claude] Univ Toronto, Inst Med Sci, Toronto, ON, Canada.
   [Bidelman, Gavin M.] Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.
   [Bidelman, Gavin M.] Univ Memphis, Sch Commun Sci & Disorders, Memphis, TN 38152 USA.
   [Bidelman, Gavin M.] Univ Tennessee, Hlth Sci Ctr, Dept Anat & Neurobiol, Memphis, TN 37996 USA.
RP Bidelman, GM (corresponding author), Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.; Bidelman, GM (corresponding author), Univ Memphis, Sch Commun Sci & Disorders, Memphis, TN 38152 USA.; Bidelman, GM (corresponding author), Univ Tennessee, Hlth Sci Ctr, Dept Anat & Neurobiol, Memphis, TN 37996 USA.
EM gmbdlman@memphis.edu
RI Al-Fahad, Rakib/ABB-9817-2020
OI Al-Fahad, Rakib/0000-0002-0124-7254
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC016267]; National Institute on
   AgingUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Aging (NIA)
   [R01DC016267]; Department of Electrical and Computer Engineering at the
   University of Memphis
FX This work was partially supported by the National Institute on Deafness
   and Other Communication Disorders and National Institute on Aging
   (R01DC016267) and Department of Electrical and Computer Engineering at
   the University of Memphis.
CR Agung K, 2006, J AM ACAD AUDIOL, V17, P559, DOI 10.3766/jaaa.17.8.3
   Al-Fahad R, 2020, J NEURAL ENG, V17, DOI 10.1088/1741-2552/ab6040
   Alain C, 2004, PSYCHOL AGING, V19, P125, DOI 10.1037/0882-7974.19.1.125
   Alain C, 2008, CLIN NEUROPHYSIOL, V119, P356, DOI 10.1016/j.clinph.2007.10.024
   Alain C, 2008, J COGNITIVE NEUROSCI, V20, P285, DOI 10.1162/jocn.2008.20014
   Alain C, 2018, HUM BRAIN MAPP, V39, P2695, DOI 10.1002/hbm.24031
   Alain C, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00008
   Alain C, 2009, CEREB CORTEX, V19, P305, DOI 10.1093/cercor/bhn082
   Anderson S, 2012, J NEUROSCI, V32, P14156, DOI 10.1523/JNEUROSCI.2176-12.2012
   Anderson S, 2010, J NEUROSCI, V30, P4922, DOI 10.1523/JNEUROSCI.0107-10.2010
   Bhasin M, 2004, BIOINFORMATICS, V20, P421, DOI 10.1093/bioinformatics/btg424
   Bidelman GM, 2019, HEARING RES, V382, DOI 10.1016/j.heares.2019.107795
   Bidelman GM, 2019, BRAIN STRUCT FUNCT, V224, P2661, DOI 10.1007/s00429-019-01922-9
   Bidelman GM, 2019, NEUROIMAGE, V201, DOI 10.1016/j.neuroimage.2019.116022
   Bidelman GM, 2017, HEARING RES, V351, P34, DOI 10.1016/j.heares.2017.05.008
   Bidelman GM, 2017, J NEUROSCI, V37, P3610, DOI 10.1523/JNEUROSCI.3700-16.2017
   Bidelman GM, 2016, NEUROIMAGE, V124, P581, DOI 10.1016/j.neuroimage.2015.09.020
   Bidelman GM, 2014, NEUROBIOL AGING, V35, P2526, DOI 10.1016/j.neurobiolaging.2014.05.006
   Billings CJ, 2015, EAR HEARING, V36, P710, DOI 10.1097/AUD.0000000000000191
   Billings CJ, 2013, JARO-J ASSOC RES OTO, V14, P891, DOI 10.1007/s10162-013-0415-y
   Blackwell DL, 2014, VITAL HLTH STAT, V10, P1
   Brette R, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002561
   Burkard Robert F, 2002, Am J Audiol, V11, P13, DOI 10.1044/1059-0889(2002/004)
   Burton MW, 2001, COGNITIVE SCI, V25, P695, DOI 10.1207/s15516709cog2505_4
   Cabeza R, 2002, PSYCHOL AGING, V17, P85, DOI 10.1037//0882-7974.17.1.85
   Casale S, 2008, 2008 Second IEEE International Conference on Semantic Computing (ICSC), P158, DOI 10.1109/ICSC.2008.43
   Caspary DA, 2006, HEARING RES, V216, P207, DOI 10.1016/j.heares.2006.03.005
   Caspary DM, 2008, J EXP BIOL, V211, P1781, DOI 10.1242/jeb.013581
   Crinion JT, 2003, BRAIN, V126, P1193, DOI 10.1093/brain/awg104
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Diaz MT, 2019, COGN AFFECT BEHAV NE, V19, P829, DOI 10.3758/s13415-018-00671-2
   Dimitrijevic A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-47643-1
   Ding N, 2013, J NEUROSCI, V33, P5728, DOI 10.1523/JNEUROSCI.5297-12.2013
   Du Y, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12241
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   DUBNO JR, 1992, J ACOUST SOC AM, V91, P2110, DOI 10.1121/1.403697
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Eggermont JJ, 1997, ACTA OTO-LARYNGOL, V117, P161, DOI 10.3109/00016489709117760
   Erb J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00116
   Erwin R J, 1987, Electroencephalogr Clin Neurophysiol Suppl, V40, P461
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   Frost JA, 1999, BRAIN, V122, P199, DOI 10.1093/brain/122.2.199
   Fuchs M, 1998, IEEE T BIO-MED ENG, V45, P980, DOI 10.1109/10.704867
   Fuchs M, 2002, CLIN NEUROPHYSIOL, V113, P702, DOI 10.1016/S1388-2457(02)00030-5
   Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906
   Gabrieli JDE, 1998, P NATL ACAD SCI USA, V95, P906, DOI 10.1073/pnas.95.3.906
   Ganis G, 2004, COGNITIVE BRAIN RES, V20, P226, DOI 10.1016/j.cogbrainres.2004.02.012
   Gates GA, 2005, LANCET, V366, P1111, DOI 10.1016/S0140-6736(05)67423-5
   GORDONSALANT S, 1993, J SPEECH HEAR RES, V36, P1276, DOI 10.1044/jshr.3606.1276
   Grady CL, 2008, ANN NY ACAD SCI, V1124, P127, DOI 10.1196/annals.1440.009
   Gramfort A, 2010, BIOMED ENG ONLINE, V9, DOI 10.1186/1475-925X-9-45
   Guediche S, 2014, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00126
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2014, LANG COGN NEUROSCI, V29, P2, DOI 10.1080/01690965.2013.834370
   Hsu C, 2003, PRACTICAL GUIDE SUPP
   Humes LE, 2013, ATTEN PERCEPT PSYCHO, V75, P508, DOI 10.3758/s13414-012-0406-9
   Humes LE, 2012, J AM ACAD AUDIOL, V23, P635, DOI 10.3766/jaaa.23.8.5
   Hutka SA, 2013, J ACOUST SOC AM, V133, P4177, DOI 10.1121/1.4802745
   Jang JH, 2010, CLIN EXP OTORHINOLAR, V3, P194, DOI 10.3342/ceo.2010.3.4.194
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Kim JR, 2012, OTOL NEUROTOL, V33, P1105, DOI 10.1097/MAO.0b013e3182659b1e
   Koerner TK, 2015, HEARING RES, V328, P113, DOI 10.1016/j.heares.2015.08.002
   KONKLE DF, 1977, J SPEECH HEAR RES, V20, P108, DOI 10.1044/jshr.2001.108
   Konrad-Martin D, 2012, J AM ACAD AUDIOL, V23, P18, DOI 10.3766/jaaa.23.1.3
   Kujawa SG, 2015, HEARING RES, V330, P191, DOI 10.1016/j.heares.2015.02.009
   Lemaitre G, 2017, J MACH LEARN RES, V18
   Liberman M Charles, 2017, F1000Res, V6, P927, DOI 10.12688/f1000research.11310.1
   LIEGEOISCHAUVEL C, 1994, ELECTROEN CLIN NEURO, V92, P204, DOI 10.1016/0168-5597(94)90064-7
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Mahmud MS, 2018, 2018 10TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE), P205, DOI 10.1109/ICECE.2018.8636698
   MAZZIOTTA JC, 1995, NEUROIMAGE, V2, P89, DOI 10.1006/nimg.1995.1012
   McGee T, 1996, EAR HEARING, V17, P419, DOI 10.1097/00003446-199610000-00008
   Meinshausen N, 2010, J R STAT SOC B, V72, P417, DOI 10.1111/j.1467-9868.2010.00740.x
   Michel CM, 2004, CLIN NEUROPHYSIOL, V115, P2195, DOI 10.1016/j.clinph.2004.06.001
   Moinuddin K. A., 2019, BRAINO
   Mudar RA, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00828
   Murray CJL, 2013, JAMA-J AM MED ASSOC, V310, P591, DOI 10.1001/jama.2013.13805
   Okada K, 2010, CEREB CORTEX, V20, P2486, DOI 10.1093/cercor/bhp318
   Oostenveld R, 2001, CLIN NEUROPHYSIOL, V112, P713, DOI 10.1016/S1388-2457(00)00527-7
   Park Y, 2011, EPILEPSIA, V52, P1761, DOI 10.1111/j.1528-1167.2011.03138.x
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P91
   Peelle JE, 2016, TRENDS NEUROSCI, V39, P486, DOI 10.1016/j.tins.2016.05.001
   Peelle JE, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00051
   Peelle JE, 2010, CEREB CORTEX, V20, P773, DOI 10.1093/cercor/bhp142
   Picton TW, 1999, AUDIOL NEURO-OTOL, V4, P64, DOI 10.1159/000013823
   Picton TW, 2000, CLIN NEUROPHYSIOL, V111, P53, DOI 10.1016/S1388-2457(99)00227-8
   Polat K, 2007, DIGIT SIGNAL PROCESS, V17, P694, DOI 10.1016/j.dsp.2006.10.008
   Presacco A, 2016, J NEUROPHYSIOL, V116, P2356, DOI 10.1152/jn.00373.2016
   Price CN, 2019, NEUROSCIENCE, V423, P18, DOI 10.1016/j.neuroscience.2019.10.044
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rauschecker JP, 2000, P NATL ACAD SCI USA, V97, P11800, DOI 10.1073/pnas.97.22.11800
   Roque L, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00749
   Ross B, 2009, NEUROIMAGE, V47, P678, DOI 10.1016/j.neuroimage.2009.04.051
   Saito T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118432
   Schneider BA, 2002, CAN J EXP PSYCHOL, V56, P139, DOI 10.1037/h0087392
   Schoof T, 2016, JARO-J ASSOC RES OTO, V17, P441, DOI 10.1007/s10162-016-0564-x
   Shtyrov Y, 1998, NEUROSCI LETT, V251, P141, DOI 10.1016/S0304-3940(98)00529-1
   Shtyrov Y, 1999, NEUROREPORT, V10, P2189, DOI 10.1097/00001756-199907130-00034
   Skeide MA, 2016, NAT REV NEUROSCI, V17, P323, DOI 10.1038/nrn.2016.23
   Snyder JS, 2005, COGNITIVE BRAIN RES, V24, P492, DOI 10.1016/j.cogbrainres.2005.03.002
   Song J, 2015, J NEUROSCI METH, V256, P9, DOI 10.1016/j.jneumeth.2015.08.015
   Strouse A, 1998, J ACOUST SOC AM, V104, P2385, DOI 10.1121/1.423748
   Tadel F, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/879716
   Tan X, 2012, FRONT HUM NEUROSCI, V6, DOI [10.3389/fnhum.2012.00305, 10.3389/fnhum.2012.00314]
   Tervaniemi M, 2003, BRAIN RES REV, V43, P231, DOI 10.1016/j.brainresrev.2003.08.004
   Tremblay K, 2001, EAR HEARING, V22, P79, DOI 10.1097/00003446-200104000-00001
   Tremblay KL, 2003, CLIN NEUROPHYSIOL, V114, P1332, DOI 10.1016/S1388-2457(03)00114-7
   Vaden KI, 2015, J NEUROSCI, V35, P3929, DOI 10.1523/JNEUROSCI.2908-14.2015
   VandenLangenberg GM, 1998, AM J EPIDEMIOL, V148, P204, DOI 10.1093/oxfordjournals.aje.a009625
   VANROOIJ JCGM, 1992, J ACOUST SOC AM, V91, P1028, DOI 10.1121/1.402628
   Vos T, 2015, LANCET, V386, P743, DOI 10.1016/S0140-6736(15)60692-4
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
   Wong PCM, 2004, J NEUROSCI, V24, P9153, DOI 10.1523/JNEUROSCI.2225-04.2004
   WOODS DL, 1986, ELECTROEN CLIN NEURO, V65, P297, DOI 10.1016/0168-5597(86)90008-0
   Yi HG, 2019, NEURON, V102, P1096, DOI 10.1016/j.neuron.2019.04.023
   Yin QY, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/2747431
   ZATORRE RJ, 1992, SCIENCE, V256, P846, DOI 10.1126/science.1589767
   Zendel BR, 2014, NEUROBIOL AGING, V35, P55, DOI 10.1016/j.neurobiolaging.2013.06.022
NR 119
TC 0
Z9 0
U1 3
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD JUL 16
PY 2020
VL 14
AR 748
DI 10.3389/fnins.2020.00748
PG 15
WC Neurosciences
SC Neurosciences & Neurology
GA MV9YL
UT WOS:000556704400001
PM 32765215
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Heinrich, A
   Knight, S
AF Heinrich, Antje
   Knight, Sarah
TI Reproducibility in Cognitive Hearing Research: Theoretical
   Considerations and Their Practical Application in Multi-Lab Studies
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE reproducibility; replication; retest reliability; multi-laboratory
   collaboration; cognitive hearing science; Stroop
ID SPEECH-PERCEPTION; STROOP TASK; RELIABILITY; NOISE; INTELLIGIBILITY;
   ASYMMETRY; STABILITY
AB In this article, we consider the issue of reproducibility within the field of cognitive hearing science. First, we examine how retest reliability can provide useful information for the generality of results and intervention effectiveness. Second, we provide an overview of retest reliability coefficients within three areas of cognitive hearing science (cognition, speech perception, and self-reported measures of communication) and show how the reporting of these coefficients differs between fields. We argue that practices surrounding the provision of retest coefficients are currently most rigorous in clinical assessment and that basic science research would benefit from adopting similar standards. Finally, based on a distinction between direct replications (which aim to keep materials as close to the original study as possible) and conceptual replications (which test the same purported mechanism using different materials), we discuss new initiatives which address the need for both. Using the example of the auditory Stroop task, we provide practical illustrations of how these theoretical issues can be addressed within the context of a multi-lab replication study. By illustrating how theoretical concepts can be put into practice in empirical research, we hope to encourage others to set up and participate in a wide variety of reproducibility-related studies.
C1 [Heinrich, Antje] Univ Manchester, Manchester Ctr Audiol & Deafness, Manchester, Lancs, England.
   [Knight, Sarah] Univ York, Dept Psychol, York, N Yorkshire, England.
RP Heinrich, A (corresponding author), Univ Manchester, Manchester Ctr Audiol & Deafness, Manchester, Lancs, England.
EM antje.heinrich@manchester.ac.uk
OI Heinrich, Antje/0000-0002-5940-622X
FU NIHR Manchester Biomedical Research CentreNational Institute for Health
   Research (NIHR)
FX AH was supported by the NIHR Manchester Biomedical Research Centre.
CR Aarts AA, 2015, SCIENCE, V349, DOI 10.1126/science.aac4716
   Aldridge VK, 2017, EUR PSYCHOL, V22, P207, DOI 10.1027/1016-9040/a000298
   Alexander A, 2012, PERSPECT PSYCHOL SCI, V7, P657, DOI 10.1177/1745691612462588
   Amitay S, 2002, BRAIN, V125, P2272, DOI 10.1093/brain/awf231
   Arlinger S, 2009, SCAND J PSYCHOL, V50, P371, DOI 10.1111/j.1467-9450.2009.00753.x
   Arsenault JS, 2016, PSYCHON B REV, V23, P1231, DOI 10.3758/s13423-015-0988-z
   Baker RJ, 2008, LATERALITY, V13, P1, DOI 10.1080/13576500701507861
   BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32
   Button KS, 2020, PSYCHOL LEARN TEACH-, V19, P77, DOI 10.1177/1475725719857659
   Casler K, 2013, COMPUT HUM BEHAV, V29, P2156, DOI 10.1016/j.chb.2013.05.009
   CAUSEY GD, 1983, J SPEECH HEAR DISORD, V48, P62, DOI 10.1044/jshd.4801.62
   Chelune GJ., 1993, NEUROPSYCHOLOGY, V7, P41, DOI [10.1037/0894-4105.7.1.41, DOI 10.1037/0894-4105.7.1.41]
   CICCHETTI DV, 1981, AM J MENT DEF, V86, P127
   Crump MJC, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057410
   CUTTING JE, 1974, PERCEPT PSYCHOPHYS, V16, P601, DOI 10.3758/BF03198592
   DUBNO JR, 1982, J SPEECH HEAR RES, V25, P135, DOI 10.1044/jshr.2501.135
   Ebersole CR, 2016, J EXP SOC PSYCHOL, V67, P68, DOI 10.1016/j.jesp.2015.10.012
   Gelman A, 2014, PERSPECT PSYCHOL SCI, V9, P641, DOI 10.1177/1745691614551642
   Goodman SN, 2016, SCI TRANSL MED, V8, DOI 10.1126/scitranslmed.aaf5027
   Gould Sandy J. J., 2015, HUMAN COMPUTATION, V2, P45, DOI DOI 10.15346/HC.V2I1.4
   GREEN EJ, 1981, PERCEPT PSYCHOPHYS, V30, P459, DOI 10.3758/BF03204842
   HAMERS JF, 1972, J VERB LEARN VERB BE, V11, P303, DOI 10.1016/S0022-5371(72)80091-4
   Hedge C, 2018, BEHAV RES METHODS, V50, P1166, DOI 10.3758/s13428-017-0935-1
   Heinrich A, 2008, Q J EXP PSYCHOL, V61, P735, DOI 10.1080/17470210701402372
   Heinrich A, 2011, Q J EXP PSYCHOL, V64, P186, DOI 10.1080/17470218.2010.492621
   Heinrich A, 2010, SPEECH COMMUN, V52, P1038, DOI 10.1016/j.specom.2010.09.009
   HEISE DR, 1969, AM SOCIOL REV, V34, P93, DOI 10.2307/2092790
   Hendrick C., 1991, REPLICATION RES SOCI
   Ioannidis JPA, 2014, TRENDS COGN SCI, V18, P235, DOI 10.1016/j.tics.2014.02.010
   Ioannidis JPA, 2005, PLOS MED, V2, P696, DOI 10.1371/journal.pmed.0020124
   JACOBSON NS, 1991, J CONSULT CLIN PSYCH, V59, P12, DOI 10.1037/0022-006X.59.1.12
   Janse E, 2012, AGING NEUROPSYCHOL C, V19, P741, DOI 10.1080/13825585.2011.652590
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Kirby J, 2018, J PHONETICS, V70, P70, DOI 10.1016/j.wocn.2018.05.005
   Klein R. A., 2018, ADV METHODS PRACT PS, V1, P443, DOI [10.1177/2515245918810225, DOI 10.1177/2515245918810225]
   Klein RA, 2014, J OPEN PSYCHOL DATA, V2, pe4, DOI DOI 10.5334/J0PD.AD
   Knight S, 2019, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02779
   Knight S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00230
   Lunner T, 2007, J AM ACAD AUDIOL, V18, P604, DOI 10.3766/jaaa.18.7.7
   MACLEOD CM, 1992, J EXP PSYCHOL GEN, V121, P12, DOI 10.1037/0096-3445.121.1.12
   MACLEOD CM, 1991, PSYCHOL BULL, V109, P163, DOI 10.1037/0033-2909.109.2.163
   MORGAN ALR, 1989, BRAIN LANG, V36, P592, DOI 10.1016/0093-934X(89)90088-6
   Nosek BA, 2020, PLOS BIOL, V18, DOI 10.1371/journal.pbio.3000691
   Nunnally J.C., 1970, INTRO PSYCHOL MEASUR
   Pashler H, 2012, PERSPECT PSYCHOL SCI, V7, P531, DOI 10.1177/1745691612463401
   Phaf RH, 2020, THEOR PSYCHOL, V30, P263, DOI 10.1177/0959354319898250
   PIETERS JM, 1981, CORTEX, V17, P369, DOI 10.1016/S0010-9452(81)80024-X
   PLATT JR, 1964, SCIENCE, V146, P347, DOI 10.1126/science.146.3642.347
   REGAN J, 1978, PERCEPT PSYCHOPHYS, V24, P130, DOI 10.3758/BF03199539
   Roberts KL, 2008, J COGNITIVE NEUROSCI, V20, P1063, DOI 10.1162/jocn.2008.20074
   ROSENTHAL R, 1979, PSYCHOL BULL, V86, P638, DOI 10.1037/0033-2909.86.3.638
   Rouder JN, 2014, PSYCHON B REV, V21, P301, DOI 10.3758/s13423-014-0595-4
   Sanborn AN, 2014, PSYCHON B REV, V21, P283, DOI 10.3758/s13423-013-0518-9
   Scheel A.M., 2020, PSYARXIV, DOI [10.31234/ osf.io/p6e9c, DOI 10.31234/OSF.IO/P6E9C]
   Schmidt S, 2009, REV GEN PSYCHOL, V13, P90, DOI 10.1037/a0015108
   Schneider BA, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00618
   Shilling VM, 2002, NEUROPSYCHOLOGIA, V40, P605, DOI 10.1016/S0028-3932(01)00157-9
   Simmons JP, 2011, PSYCHOL SCI, V22, P1359, DOI 10.1177/0956797611417632
   Sommers MS, 1999, PSYCHOL AGING, V14, P458, DOI 10.1037/0882-7974.14.3.458
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   STUDDERTKENNEDY M, 1970, J ACOUST SOC AM, V48, P579, DOI 10.1121/1.1912174
   Watson D, 2004, J RES PERS, V38, P319, DOI 10.1016/j.jrp.2004.03.001
   Whitton JP, 2017, CURR BIOL, V27, P3237, DOI 10.1016/j.cub.2017.09.014
   Yarkoni T, 2017, PERSPECT PSYCHOL SCI, V12, P1100, DOI 10.1177/1745691617693393
   Ziegler JC, 2005, P NATL ACAD SCI USA, V102, P14110, DOI 10.1073/pnas.0504446102
NR 66
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUL 16
PY 2020
VL 11
AR 1590
DI 10.3389/fpsyg.2020.01590
PG 9
WC Psychology, Multidisciplinary
SC Psychology
GA MV9HX
UT WOS:000556660800001
PM 32765364
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Shirley, B
   Ward, L
AF Shirley, Ben
   Ward, Lauren
TI Intelligibility versus comprehension: understanding quality of
   accessible next-generation audio broadcast
SO UNIVERSAL ACCESS IN THE INFORMATION SOCIETY
LA English
DT Article; Early Access
DE Broadcast; Accessibility; Hearing impairment
ID HEARING-LOSS; SPEECH-PERCEPTION; NATIONAL-HEALTH; NOISE; PREVALENCE;
   EXPOSURE; ADULTS
AB For traditional broadcasting formats, implementation of accessible audio strategies for hard of hearing people have used a binary, intelligibility-based approach. In this approach, sounds are categorized either as speech, contributing to comprehension of content, or non-speech, which can mask the speech and reduce intelligibility. Audio accessibility solutions have therefore focused on speech enhancement type methods, for which several useful standard objective measures of quality exist. Recent developments in next-generation broadcast audio formats, in particular the roll out of object-based audio, facilitate more in-depth personalisation of the audio experience based on user preferences and needs. Recent research has demonstrated that many non-speech sounds do not strictly behave as maskers but can be critical for comprehension of the narrative for some viewers. This complex relationship between speech, non-speech audio and the viewer necessitate a more holistic approach to understanding quality of experience of accessible media. This paper reviews previous work and outlines such an approach, discussing accessibility strategies using next-generation audio formats and their implications for developing effective assessments of quality.
C1 [Shirley, Ben; Ward, Lauren] Univ Salford, Manchester, Lancs, England.
RP Shirley, B (corresponding author), Univ Salford, Manchester, Lancs, England.
EM b.g.shirley@salford.ac.uk; L.Ward7@edu.salford.ac.uk
FU General Sir John Monash Foundation
FX Lauren Ward is funded by the General Sir John Monash Foundation.
CR Aazh H, 2015, INT J AUDIOL, V54, P152, DOI 10.3109/14992027.2014.967367
   Action on Hearing Loss, 2015, HEAR MATT REP
   Agrawal Y, 2008, ARCH INTERN MED, V168, P1522, DOI 10.1001/archinte.168.14.1522
   [Anonymous], 2016, D4 4 PIL B EV REC
   [Anonymous], 2018, TS101154 ETSI
   [Anonymous], 2016, RAPPORT ANN RELATIF
   [Anonymous], 2008, ANN SURV REP 2008
   [Anonymous], 2017, OFCOMS CODE TELEVISI
   [Anonymous], 2014, LOUDN NORM PERM MAX
   [Anonymous], 2018, BBC
   Armstrong M, 2011, 190 BBC WHP
   BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32
   BRONKHORST AW, 1992, J ACOUST SOC AM, V92, P3132, DOI 10.1121/1.404209
   Brown A., 2015, P ACM INT C INT EXP, P103
   Brown Andy, 2017, 2017 ACM INT C INT E, P3, DOI DOI 10.1145/3084289.3089915
   Bruckner W, 2011, JOINT RECOMMENDATION
   Carmichael AR, 2004, NEUROPSYCHOL REHABIL, V14, P241, DOI 10.1080/09602010343000192
   Cohen D., 2011, SOUND MATTERS
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   EBU, 2009, 3333 EBU EBU TECH
   Economics A, 2006, REPORT COOPERATIVE R
   Ellis K, 2014, MEDIA INT AUST, P53, DOI 10.1177/1329878X1415300107
   Emmett J, 1998, 104 AUD ENG CONV
   ERGA, 2016, 201612 ERGA
   ETSI, 2009, DIG VID BROADC DVB S
   Etsi T, 2009, ETSI TS, V101, P9
   FascinatE, 2010, 248138 FASCINATE EUR
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Gates GA, 2005, LANCET, V366, P1111, DOI 10.1016/S0140-6736(05)67423-5
   Geiger JT, 2015, EUR SIGNAL PR CONF, P869, DOI 10.1109/EUSIPCO.2015.7362507
   HOEG W., 2009, DIGITAL AUDIO BROADC
   Huckvale M., 2017, P 1 INT WORKSH CHALL
   Looms P, 2014, POLICY MARKETING STR, P43
   Maassen M., 2001, NOISE HEALTH, V4, P1
   Mapp P., 2016, P 141 AUD ENG SOC CO
   Mathers C.D, 1991, 91 NASA STI REC
   Musch H, 2008, P 125 AUD ENG SOC CO
   NorDig, 2009, NORD UN REQ INT REC
   Office for National Statistics, 2015, NAT POP PROJ 2014 BA
   Open IPTV Forum, 2011, OIPF REL 2 SPEC
   Palmer KT, 2002, OCCUP ENVIRON MED, V59, P634, DOI 10.1136/oem.59.9.634
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   Rabinowitz PM, 2000, AM FAM PHYSICIAN, V61, P2749
   Roth TN, 2011, EUR ARCH OTO-RHINO-L, V268, P1101, DOI 10.1007/s00405-011-1597-8
   Rumsey F, 2009, J AUDIO ENG SOC, V57, P353
   Sadhra S, 2002, ANN OCCUP HYG, V46, P455, DOI 10.1093/annhyg/mef051
   Shirley B, 2013, THESIS
   Shirley B., 2019, PERSONALIZATION OBJE
   Shirley B.G., 2004, AUD ENG SOC CONV
   Shirley B, 2007, J AUDIO ENG SOC, V55, P852
   Shirley B, 2017, J AUDIO ENG SOC, V65, P293, DOI 10.17743/jaes.2017.0005
   Shirley B, 2015, J AUDIO ENG SOC, V63, P245, DOI 10.17743/jaes.2015.0017
   Shirley BG, 2006, J TECHNOL DISABIL, V18, P31, DOI DOI 10.3233/TAD-2006-18105
   Slater J, 2010, BROADBAND SOLUTIONS
   Smith C, 2014, PERFORMING ARTS AND PUBLIC SPACE, PERFORMART '14, P200
   Tang Y, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010059
   Tang Y, 2016, J ACOUST SOC AM, V140, P1858, DOI 10.1121/1.4962484
   Torcoli M., 2016, AUD ENG SOC CONV
   Uhle C., 2008, AUD ENG SOC CONV
   Utray F, 2012, INT J DIGIT MULTIMED, V2012, DOI 10.1155/2012/294219
   Vermiglio AJ, 2012, J AM ACAD AUDIOL, V23, P779, DOI 10.3766/jaaa.23.10.4
   Vickers E, 2009, AUD ENG SOC CONV
   Ward L., 2018, 145 AUD ENG CONV
   Ward L., 2017, C ACC FILM TEL INT M
   Ward L., 2017, INTERSPEECH 2017
   Ward L, 2017, INTERSPEECH, P2958, DOI 10.21437/Interspeech.2017-500
   Woodcock J., 2016, AUD ENG SOC CONV
   Woodcock J, 2016, J AUDIO ENG SOC, V64, P380, DOI 10.17743/jaes.2016.0007
NR 68
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1615-5289
EI 1615-5297
J9 UNIVERSAL ACCESS INF
JI Univers. Access Inf. Soc.
DI 10.1007/s10209-020-00741-8
EA JUL 2020
PG 9
WC Computer Science, Cybernetics; Ergonomics
SC Computer Science; Engineering
GA MK4RT
UT WOS:000548776500001
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Failes, E
   Sommers, MS
   Jacoby, LL
AF Failes, Eric
   Sommers, Mitchell S.
   Jacoby, Larry L.
TI Blurring past and present: Using false memory to better understand false
   hearing in young and older adults
SO MEMORY & COGNITION
LA English
DT Article
DE False hearing; False memory; Speech perception; Context effects; Aging
ID SPEECH-PERCEPTION; AGE-DIFFERENCES; RECOLLECTION; DEMENTIA; CONTEXT;
   RECALL; WORDS
AB A number of recent studies have shown that older adults are more susceptible to context-based misperceptions in hearing (Rogers, Jacoby, & Sommers,Psychology and Aging, 27, 33-45,2012; Sommers, Morton, & Rogers,Remembering: Attributions, Processes, and Control in Human Memory [Essays in Honor of Larry Jacoby],pp. 269-284,2015) than are young adults. One explanation for these age-related increases in what we term false hearing is that older adults are less able than young individuals to inhibit a prepotent response favored by context. A similar explanation has been proposed for demonstrations of age-related increases in false memory (Jacoby, Bishara, Hessels, & Toth,Journal of Experimental Psychology: General, 134, 131-148,2005). The present study was designed to compare susceptibility to false hearing and false memory in a group of young and older adults. In Experiment 1, we replicated the findings of past studies demonstrating increased frequency of false hearing in older, relative to young, adults. In Experiment 2, we demonstrated older adults' increased susceptibility to false memory in the same sample. Importantly, we found that participants who were more prone to false hearing also tended to be more prone to false memory, supporting the idea that the two phenomena share a common mechanism. The results are discussed within the framework of a capture model, which differentiates between context-based responding resulting from failures of cognitive control and context-based guessing.
C1 [Failes, Eric; Sommers, Mitchell S.; Jacoby, Larry L.] Washington Univ, Dept Psychol & Brain Sci, 1 Brookings Dr,Campus Box 1125, St Louis, MO 63130 USA.
RP Failes, E (corresponding author), Washington Univ, Dept Psychol & Brain Sci, 1 Brookings Dr,Campus Box 1125, St Louis, MO 63130 USA.
EM e.failes@wustl.edu
OI Failes, Eric/0000-0003-1042-4344
FU National Institutes of Health (NIH)United States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USA [1
   R21AG041958-01A1]
FX This project was funded by the National Institutes of Health (NIH) [1
   R21AG041958-01A1].
CR ALBA JW, 1983, PSYCHOL BULL, V93, P203, DOI 10.1037/0033-2909.93.2.203
   Balota DA, 1999, COGNITIVE NEUROPSYCH, V16, P361, DOI 10.1080/026432999380834
   Balota DA, 2007, BEHAV RES METHODS, V39, P445, DOI 10.3758/BF03193014
   Bartlett F. C., 1932, REMEMBERING STUDY EX
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32
   Burkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   BUGELSKI BR, 1961, CAN J PSYCHOLOGY, V15, P205, DOI 10.1037/h0083443
   Butler KM, 2004, PSYCHON B REV, V11, P921, DOI 10.3758/BF03196722
   COHN NB, 1984, J CLIN PSYCHOL, V40, P1244, DOI 10.1002/1097-4679(198409)40:5<1244::AID-JCLP2270400521>3.0.CO;2-D
   Colombel F, 2016, PSYCHOL AGING, V31, P239, DOI 10.1037/pag0000086
   Coren S., 1978, SEEING IS DECEIVING
   DEESE J, 1959, J EXP PSYCHOL, V58, P17, DOI 10.1037/h0046671
   Dubno JR, 2000, J ACOUST SOC AM, V107, P538, DOI 10.1121/1.428322
   Hasher L, 1997, MEM COGNITION, V25, P286, DOI 10.3758/BF03211284
   Hasher Lynn, 1988, PSYCHOL LEARN MOTIV, V22, P193, DOI DOI 10.1016/S0079-7421(08)60041-9
   Hay JF, 1999, PSYCHOL AGING, V14, P122, DOI 10.1037/0882-7974.14.1.122
   HUTCHINSON KM, 1989, J GERONTOL, V44, pP36, DOI 10.1093/geronj/44.2.P36
   Jacoby LL, 2012, PSYCHOL AGING, V27, P22, DOI 10.1037/a0025924
   Jacoby LL, 2006, CURR DIR PSYCHOL SCI, V15, P49, DOI 10.1111/j.0963-7214.2006.00405.x
   Jacoby LL, 2005, J EXP PSYCHOL GEN, V134, P131, DOI 10.1037/0096-3445.134.2.131
   JACOBY LL, 1991, J MEM LANG, V30, P513, DOI 10.1016/0749-596X(91)90025-F
   Jacoby LL, 1999, COGNITIVE NEUROPSYCH, V16, P417, DOI 10.1080/026432999380861
   Jennings JM, 1997, PSYCHOL AGING, V12, P352, DOI 10.1037/0882-7974.12.2.352
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   McCabe DP, 2009, NEUROPSYCHOLOGIA, V47, P2164, DOI 10.1016/j.neuropsychologia.2008.11.025
   Millar PR, 2018, MEM COGNITION, V46, P1058, DOI 10.3758/s13421-018-0821-9
   Roediger HL, 2007, J EXP PSYCHOL LEARN, V33, P321, DOI 10.1037/0278-7393.33.2.321
   ROEDIGER HL, 1995, J EXP PSYCHOL LEARN, V21, P803, DOI 10.1037/0278-7393.21.4.803
   Rogers CS, 2012, PSYCHOL AGING, V27, P33, DOI 10.1037/a0026231
   Shipley WC, 1940, J PSYCHOL, V9, P371, DOI 10.1080/00223980.1940.9917704
   Sommers MS, 2003, PSYCHOL AGING, V18, P791, DOI 10.1037/0882-7974.18.4.791
   Sommers MS, 2015, REMEMBERING ATTRIBUT, P269
   TULVING E, 1985, CAN PSYCHOL, V26, P1, DOI 10.1037/h0080017
   Wheeler MA, 1997, PSYCHOL BULL, V121, P331, DOI 10.1037/0033-2909.121.3.331
NR 35
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0090-502X
EI 1532-5946
J9 MEM COGNITION
JI Mem. Cogn.
PD NOV
PY 2020
VL 48
IS 8
BP 1403
EP 1416
DI 10.3758/s13421-020-01068-8
EA JUL 2020
PG 14
WC Psychology, Experimental
SC Psychology
GA PE2GC
UT WOS:000548786900001
PM 32671592
DA 2021-02-24
ER

PT J
AU Foxe, JJ
   Del Bene, VA
   Ross, LA
   Ridgway, EM
   Francisco, AA
   Molholm, S
AF Foxe, John J.
   Del Bene, Victor A.
   Ross, Lars A.
   Ridgway, Elizabeth M.
   Francisco, Ana A.
   Molholm, Sophie
TI Multisensory Audiovisual Processing in Children With a Sensory
   Processing Disorder (II): Speech Integration Under Noisy Environmental
   Conditions
SO FRONTIERS IN INTEGRATIVE NEUROSCIENCE
LA English
DT Article
DE cross-modal; audiovisual; autism spectrum disorders; multisensory
   integration; ASD; sensory integration; SPD
ID AUTISM; CHILDHOOD; IMPAIRMENTS; ADAPTATION; DYNAMICS
AB Background: There exists a cohort of children and adults who exhibit an inordinately high degree of discomfort when experiencing what would be considered moderate and manageable levels of sensory input. That is, they show over-responsivity in the face of entirely typical sound, light, touch, taste, or smell inputs, and this occurs to such an extent that it interferes with their daily functioning and reaches clinical levels of dysfunction. What marks these individuals apart is that this sensory processing disorder (SPD) is observed in the absence of other symptom clusters that would result in a diagnosis of Autism, ADHD, or other neurodevelopmental disorders more typically associated with sensory processing difficulties. One major theory forwarded to account for these SPDs posits a deficit in multisensory integration, such that the various sensory inputs are not appropriately integrated into the central nervous system, leading to an overwhelming sensory-perceptual environment, and in turn to the sensory-defensive phenotype observed in these individuals.
   Methods: We tested whether children (6-16 years) with an over-responsive SPD phenotype (N= 12) integrated multisensory speech differently from age-matched typically-developing controls (TD:N= 12). Participants identified monosyllabic words while background noise level and sensory modality (auditory-alone, visual-alone, audiovisual) were varied in pseudorandom order. Improved word identification when speech was both seen and heard compared to when it was simply heard served to index multisensory speech integration.
   Results: School-aged children with an SPD show a deficit in the ability to benefit from the combination of both seen and heard speech inputs under noisy environmental conditions, suggesting that these children do not benefit from multisensory integrative processing to the same extent as their typically developing peers. In contrast, auditory-alone performance did not differ between the groups, signifying that this multisensory deficit is not simply due to impaired processing of auditorspeech.
   Conclusions: Children with an over-responsive SPD show a substantial reduction in their ability to benefit from complementary audiovisual speech, to enhance speech perception in a noisy environment. This has clear implications for performance in the classroom and other learning environments. Impaired multisensory integration may contribute to sensory over-reactivity that is the definitional of SPD.
C1 [Foxe, John J.; Molholm, Sophie] Univ Rochester, Sch Med & Dent, Ernest J Monte Inst Neurosci, Dept Neurosci,Cognit Neurophysiol Lab, Rochester, NY 14620 USA.
   [Foxe, John J.; Del Bene, Victor A.; Ross, Lars A.; Ridgway, Elizabeth M.; Francisco, Ana A.; Molholm, Sophie] Albert Einstein Coll Med, Dept Pediat, Cognit Neurophysiol Lab, Bronx, NY 10467 USA.
   [Foxe, John J.; Del Bene, Victor A.; Ross, Lars A.; Ridgway, Elizabeth M.; Francisco, Ana A.; Molholm, Sophie] Montefiore Med Ctr, 111 E 210th St, Bronx, NY 10467 USA.
   [Foxe, John J.; Molholm, Sophie] Albert Einstein Coll Med, Dominic P Purpura Dept Neurosci, Bronx, NY 10467 USA.
RP Foxe, JJ; Molholm, S (corresponding author), Univ Rochester, Sch Med & Dent, Ernest J Monte Inst Neurosci, Dept Neurosci,Cognit Neurophysiol Lab, Rochester, NY 14620 USA.; Foxe, JJ; Molholm, S (corresponding author), Albert Einstein Coll Med, Dept Pediat, Cognit Neurophysiol Lab, Bronx, NY 10467 USA.; Foxe, JJ; Molholm, S (corresponding author), Montefiore Med Ctr, 111 E 210th St, Bronx, NY 10467 USA.; Foxe, JJ; Molholm, S (corresponding author), Albert Einstein Coll Med, Dominic P Purpura Dept Neurosci, Bronx, NY 10467 USA.
EM john_foxe@urmc.rochester.edu; sophie.molholm@einstein.yu.edu
RI Del Bene, Victor/AAD-8017-2021
FU Henry Wallace Foundation; National Institute of Mental HealthUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute of Mental Health (NIMH)
   [RO1MH085322]; Eunice Kennedy Shriver National Institute of Child Health
   and Human DevelopmentUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [NICHD U54 HD090260]
FX This work was primarily supported by a series of pilot grants from the
   Henry Wallace Foundation to JF and SM. Additional support came from the
   National Institute of Mental Health (RO1MH085322). The Human Clinical
   Phenotyping Core, where the participants enrolled in this study were
   recruited and evaluated, is a facility of the Rose F. Kennedy
   Intellectual and Developmental Disabilities Research Center (RFK-IDDRC)
   which is funded by a center grant from the Eunice Kennedy Shriver
   National Institute of Child Health and Human Development (NICHD U54
   HD090260).
CR Andrade GN, 2016, TRANSL PSYCHIAT, V6, DOI 10.1038/tp.2016.63
   Andrade GN, 2015, EUR J NEUROSCI, V41, P923, DOI 10.1111/ejn.12849
   Beker S, 2018, NEUROSCI BIOBEHAV R, V84, P182, DOI 10.1016/j.neubiorev.2017.11.008
   Brandwein AB, 2013, CEREB CORTEX, V23, P1329, DOI 10.1093/cercor/bhs109
   Brandwein AB, 2011, CEREB CORTEX, V21, P1042, DOI 10.1093/cercor/bhq170
   Brett-Green BA, 2010, BRAIN RES, V1321, P67, DOI 10.1016/j.brainres.2010.01.043
   COLTHEART M, 1981, Q J EXP PSYCHOL-A, V33, P497, DOI 10.1080/14640748108400805
   Cuppini C, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00518
   Davies PL, 2007, AM J OCCUP THER, V61, P176, DOI 10.5014/ajot.61.2.176
   Davies PL, 2009, INT J PSYCHOPHYSIOL, V72, P187, DOI 10.1016/j.ijpsycho.2008.12.007
   ERBER NP, 1969, J SPEECH HEAR RES, V12, P423, DOI 10.1044/jshr.1202.423
   Foxe JJ, 2000, COGNITIVE BRAIN RES, V10, P77, DOI 10.1016/S0926-6410(00)00024-0
   Foxe JJ, 2005, NEUROREPORT, V16, P419, DOI 10.1097/00001756-200504040-00001
   Foxe JJ, 2015, CEREB CORTEX, V25, P298, DOI 10.1093/cercor/bht213
   Gingras G, 2009, J NEUROSCI, V29, P4897, DOI 10.1523/JNEUROSCI.4120-08.2009
   Hahn N, 2014, NEUROSCI BIOBEHAV R, V47, P384, DOI 10.1016/j.neubiorev.2014.09.007
   Irwin JR, 2011, CHILD DEV, V82, P1397, DOI 10.1111/j.1467-8624.2011.01619.x
   Kanakri SM, 2017, RES DEV DISABIL, V63, P85, DOI 10.1016/j.ridd.2017.02.004
   Kucera H., 1967, COMPUTATIONAL ANAL P
   Ma WJ, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004638
   MACLEOD A, 1987, British Journal of Audiology, V21, P131, DOI 10.3109/03005368709077786
   Mahoney JR, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01068
   Megevand P, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071608
   Miller LJ, 2009, FRONT INTEGR NEUROSC, V3, DOI 10.3389/neuro.07.022.2009
   Miller LJ, 2007, AM J OCCUP THER, V61, P161, DOI 10.5014/ajot.61.2.161
   Molholm S, 2002, COGNITIVE BRAIN RES, V14, P115, DOI 10.1016/S0926-6410(02)00066-6
   Molholm S, 2020, FRONT INTEGR NEUROSC, V14, DOI 10.3389/fnint.2020.00004
   O'Sullivan AE, 2019, EUR J NEUROSCI, V50, P3282, DOI 10.1111/ejn.14425
   Park WJ, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-17676-5
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Ross LA, 2007, SCHIZOPHR RES, V97, P173, DOI 10.1016/j.schres.2007.08.008
   Ross LA, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00185
   Ross LA, 2011, EUR J NEUROSCI, V33, P2329, DOI 10.1111/j.1460-9568.2011.07685.x
   Rowland BA, 2007, J NEUROSCI, V27, P5879, DOI 10.1523/JNEUROSCI.4986-06.2007
   Schoen SA, 2009, FRONT INTEGR NEUROSC, V3, DOI 10.3389/neuro.07.029.2009
   Senkowski D, 2008, NEUROIMAGE, V43, P379, DOI 10.1016/j.neuroimage.2008.06.046
   Senkowski D, 2007, NEUROIMAGE, V36, P877, DOI 10.1016/j.neuroimage.2007.01.053
   Senkowski D, 2011, NEUROIMAGE, V56, P2200, DOI 10.1016/j.neuroimage.2011.03.075
   Shaw LH, 2020, NEUROSCIENCE, V436, P122, DOI 10.1016/j.neuroscience.2020.04.013
   Smith EG, 2007, J CHILD PSYCHOL PSYC, V48, P813, DOI 10.1111/j.1469-7610.2007.01766.x
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Uppal N, 2016, J NEUROPHYSIOL, V115, P1605, DOI 10.1152/jn.01059.2015
   Wallace MT, 1996, J NEUROPHYSIOL, V76, P1246
NR 43
TC 0
Z9 0
U1 9
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5145
J9 FRONT INTEGR NEUROSC
JI Front. Integr. Neurosci.
PD JUL 14
PY 2020
VL 14
AR 39
DI 10.3389/fnint.2020.00039
PG 8
WC Behavioral Sciences; Neurosciences
SC Behavioral Sciences; Neurosciences & Neurology
GA MV6LX
UT WOS:000556468000001
PM 32765229
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Havy, M
   Zesiger, PE
AF Havy, Melanie
   Zesiger, Pascal E.
TI Bridging ears and eyes when learning spoken words: On the effects of
   bilingual experience at 30 months
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
DE audio-visual speech perception; bilingualism; language development;
   sensory format of lexical representations; word learning
ID VISUAL LANGUAGE DISCRIMINATION; SELECTIVE ATTENTION; AUDIOVISUAL SPEECH;
   TALKING FACE; INFANTS; MOUTH; RECOGNITION; PERCEPTION; CHILDREN; MEMORY
AB From the very first moments of their lives, infants selectively attend to the visible orofacial movements of their social partners and apply their exquisite speech perception skills to the service of lexical learning. Here we explore how early bilingual experience modulates children's ability to use visible speech as they form new lexical representations. Using a cross-modal word-learning task, bilingual children aged 30 months were tested on their ability to learn new lexical mappings in either the auditory or the visual modality. Lexical recognition was assessed either in the same modality as the one used at learning ('same modality' condition: auditory test after auditory learning, visual test after visual learning) or in the other modality ('cross-modality' condition: visual test after auditory learning, auditory test after visual learning). The results revealed that like their monolingual peers, bilingual children successfully learn new words in either the auditory or the visual modality and show cross-modal recognition of words following auditory learning. Interestingly, as opposed to monolinguals, they also demonstrate cross-modal recognition of words upon visual learning. Collectively, these findings indicate a bilingual edge in visual word learning, expressed in the capacity to form a recoverable cross-modal representation of visually learned words.
C1 [Havy, Melanie; Zesiger, Pascal E.] Univ Geneva, Fac Psychol & Educ Sci, Geneva, Switzerland.
RP Havy, M (corresponding author), Univ Geneva, FAPSE, Blvd Pont Arve 28, CH-1211 Geneva 4, Switzerland.
EM melanie.havy@gmail.com
FU SNSF grant [100014_159402]
FX This work was funded by a SNSF grant (100014_159402) to MH and PZ.
CR Albareda-Castellot B, 2011, DEVELOPMENTAL SCI, V14, P395, DOI 10.1111/j.1467-7687.2010.00989.x
   Altvater-Mackensen N, 2016, DEV PSYCHOL, V52, P191, DOI 10.1037/a0039964
   Ayneto A, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12446
   Baart M, 2014, COGNITION, V130, P31, DOI 10.1016/j.cognition.2013.09.006
   Becker TM, 2016, NEUROPSYCHOLOGIA, V85, P62, DOI 10.1016/j.neuropsychologia.2016.01.020
   Berger J., 1977, WAYS SEEING 1972
   Bialystok E, 2017, PSYCHOL BULL, V143, P233, DOI 10.1037/bul0000099
   Bidelman GM, 2019, BILING-LANG COGN, V22, P752, DOI 10.1017/S1366728918000408
   Bijeljac-Babic R., 2018, DEVENIR, V30, P31
   Birdsong D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00081
   Birules J., 2018, DEVELOPMENTAL SCI, V22
   Blom E, 2014, J EXP CHILD PSYCHOL, V128, P105, DOI 10.1016/j.jecp.2014.06.007
   Bosch L, 2001, INFANCY, V2, P29, DOI 10.1207/S15327078IN0201_3
   Brito NH, 2015, BILING-LANG COGN, V18, P670, DOI 10.1017/S1366728914000789
   Buchwald AB, 2009, LANG COGNITIVE PROC, V24, P580, DOI 10.1080/01690960802536357
   Burfin S, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01179
   Burns TC, 2007, APPL PSYCHOLINGUIST, V28, P455, DOI 10.1017/S0142716407070257
   Byers-Heinlein K, 2017, P NATL ACAD SCI USA, V114, P9032, DOI 10.1073/pnas.1703220114
   Byers-Heinlein K, 2013, BILING-LANG COGN, V16, P198, DOI 10.1017/S1366728912000417
   Canseco-Gonzalez E, 2010, LANG COGNITIVE PROC, V25, P669, DOI 10.1080/01690960903474912
   Choi D, 2018, MIND BRAIN EDUC, V12, P212, DOI 10.1111/mbe.12162
   Crivello C, 2016, J EXP CHILD PSYCHOL, V141, P121, DOI 10.1016/j.jecp.2015.08.004
   Danielson DK, 2017, COGNITIVE DEV, V42, P37, DOI 10.1016/j.cogdev.2017.02.004
   Davies R, 2009, INT J LANG COMM DIS, V44, P164, DOI 10.1080/13682820801997189
   de Boisferon AH, 2018, J EXP CHILD PSYCHOL, V172, P189, DOI 10.1016/j.jecp.2018.03.009
   de Boisferon AH, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12381
   DeAnda S, 2016, J SPEECH LANG HEAR R, V59, P1346, DOI 10.1044/2016_JSLHR-L-15-0234
   DeCoster J., 2001, TRANSFORMING RESTRUC
   Della Rosa PA, 2013, CORTEX, V49, P605, DOI 10.1016/j.cortex.2012.12.001
   Delle Luche C, 2015, INFANT BEHAV DEV, V40, P151, DOI 10.1016/j.infbeh.2015.05.005
   Emmorey K, 2008, PSYCHOL SCI, V19, P1201, DOI 10.1111/j.1467-9280.2008.02224.x
   Fennell C, 2014, INT J BEHAV DEV, V38, P309, DOI 10.1177/0165025414530631
   Fennell CT, 2010, CHILD DEV, V81, P1376, DOI 10.1111/j.1467-8624.2010.01479.x
   Fernald A, 2006, DEV PSYCHOL, V42, P98, DOI 10.1037/0012-1649.42.1.98
   Fort M, 2018, LANG LEARN, V68, P31, DOI 10.1111/lang.12273
   Fort M, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12659
   Geraci C, 2008, COGNITION, V106, P780, DOI 10.1016/j.cognition.2007.04.014
   Grieco-Calub Tina M., 2015, Journal of the Acoustical Society of America, V137, DOI 10.1121/1.4920629
   Hara A, 2016, LITERATOR, V37, DOI 10.4102/lit.v37i2.1287
   Havy M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02122
   Havy M, 2017, CHILD DEV, V88, P2043, DOI 10.1111/cdev.12715
   Havy M, 2016, INT J BEHAV DEV, V40, P41, DOI 10.1177/0165025415570646
   Heikkila J, 2017, J SPEECH LANG HEAR R, V60, P485, DOI 10.1044/2016_JSLHR-S-15-0071
   Hessels RS, 2019, DEV COGN NEUROS-NETH, V40, DOI 10.1016/j.dcn.2019.100710
   Hunnius S, 2004, INFANCY, V6, P231, DOI 10.1207/s15327078in0602_5
   Jerger S, 2017, J CHILD LANG, V44, P185, DOI 10.1017/S030500091500077X
   Jerger S, 2014, J EXP CHILD PSYCHOL, V126, P295, DOI 10.1016/j.jecp.2014.05.003
   Junker DA, 2002, AM J SPEECH-LANG PAT, V11, P381, DOI 10.1044/1058-0360(2002/042)
   Kehoe M, 2018, BILING-LANG COGN, V21, P710, DOI 10.1017/S1366728916001279
   Kern S., 2003, GLOSSA, V85, P48
   Kubicek C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089275
   Kuhl PK, 2003, P NATL ACAD SCI USA, V100, P9096, DOI 10.1073/pnas.1532872100
   KUHL PK, 1991, J EXP PSYCHOL HUMAN, V17, P829, DOI 10.1037/0096-1523.17.3.829
   Lalonde K, 2015, J SPEECH LANG HEAR R, V58, P135, DOI 10.1044/2014_JSLHR-H-13-0343
   Lewkowicz DJ, 2015, J EXP CHILD PSYCHOL, V130, P147, DOI 10.1016/j.jecp.2014.10.006
   Lewkowicz DJ, 2013, INT J BEHAV DEV, V37, P90, DOI 10.1177/0165025412467582
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Li P, 2014, CORTEX, V58, P301, DOI 10.1016/j.cortex.2014.05.001
   MacLeod AAN, 2011, INT J SPEECH-LANG PA, V13, P490, DOI 10.3109/17549507.2011.578658
   MARASSA LK, 1995, J SPEECH HEAR RES, V38, P1387, DOI 10.1044/jshr.3806.1387
   Marian V, 2018, BRAIN SCI, V8, DOI 10.3390/brainsci8050085
   Mercure E, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12701
   Mieszkowska K, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01358
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Morin-Lessard E, 2019, DEV PSYCHOL, V55, P1640, DOI 10.1037/dev0000750
   Paap KR, 2015, CORTEX, V69, P265, DOI 10.1016/j.cortex.2015.04.014
   Pejovic J, 2017, DEV PSYCHOL, V53, P581, DOI 10.1037/dev0000237
   Poarch GJ, 2015, DEV REV, V35, P113, DOI 10.1016/j.dr.2014.12.003
   Pons F, 2015, PSYCHOL SCI, V26, P490, DOI 10.1177/0956797614568320
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Ramon-Casas M, 2017, BILING-LANG COGN, V20, P649, DOI 10.1017/S1366728916001115
   Ramon-Casas M, 2009, COGNITIVE PSYCHOL, V59, P96, DOI 10.1016/j.cogpsych.2009.02.002
   Ronquest RE, 2010, ATTEN PERCEPT PSYCHO, V72, P1601, DOI 10.3758/APP.72.6.1601
   Ross LA, 2011, EUR J NEUROSCI, V33, P2329, DOI 10.1111/j.1460-9568.2011.07685.x
   Rvachew S., 2018, OXFORD RES ENCY LING, DOI DOI 10.1093/ACREFORE/9780199384655.001.0001/ACREFORE-9780199384655-E-41
   Samuel AG, 2014, J EXP PSYCHOL HUMAN, V40, P1479, DOI 10.1037/a0036656
   Schonberg C, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01429
   Schroeder SR, 2017, INT J BILINGUAL, V21, P754, DOI 10.1177/1367006916637288
   Sebastian-Galles N, 2012, PSYCHOL SCI, V23, P994, DOI 10.1177/0956797612436817
   Singh L, 2018, CHILD DEV, V89, pE183, DOI 10.1111/cdev.12747
   Singh L, 2015, CHILD DEV, V86, P294, DOI 10.1111/cdev.12271
   Soto-Faraco S, 2007, PERCEPT PSYCHOPHYS, V69, P218, DOI 10.3758/BF03193744
   Stoll C, 2018, J DEAF STUD DEAF EDU, V23, P62, DOI 10.1093/deafed/enx034
   Streri A, 2016, INFANCY, V21, P177, DOI 10.1111/infa.12104
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Teinonen T, 2008, COGNITION, V108, P850, DOI 10.1016/j.cognition.2008.05.009
   Tenenbaum EJ, 2015, J CHILD LANG, V42, P1173, DOI 10.1017/S0305000914000725
   Ter Schure S, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00525
   Thordardottir E, 2019, INT J BILINGUAL, V23, P236, DOI 10.1177/1367006917722418
   Tsang T, 2018, J EXP CHILD PSYCHOL, V169, P93, DOI 10.1016/j.jecp.2018.01.002
   Tye-Murray N, 2014, J SPEECH LANG HEAR R, V57, P556, DOI 10.1044/2013_JSLHR-H-12-0273
   Unsworth S., 2016, LIFESPAN PERSPECTIVE, P136, DOI DOI 10.1037/14939-007
   Vlach HA, 2013, COGNITION, V127, P375, DOI 10.1016/j.cognition.2013.02.015
   Von Holzen K, 2019, BILING-LANG COGN, V22, P476, DOI 10.1017/S1366728918000597
   Ward J, 2013, ANNU REV PSYCHOL, V64, P49, DOI 10.1146/annurev-psych-113011-143840
   Watson MR, 2017, CONSCIOUS COGN, V48, P212, DOI 10.1016/j.concog.2016.12.004
   Weatherhead D, 2017, COGNITION, V160, P103, DOI 10.1016/j.cognition.2017.01.002
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   Weikum WM, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00086
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Westermann G., 2017, EARLY WORD LEARNING
   Wewalaarachchi TD, 2017, J EXP CHILD PSYCHOL, V159, P16, DOI 10.1016/j.jecp.2017.01.009
   Yeung HH, 2013, PSYCHOL SCI, V24, P603, DOI 10.1177/0956797612458802
   Zeshan Ulrike, 2004, LINGUIST TYPOL, V8, P1, DOI [DOI 10.1515/LITY.2004.003, 10.1515/lity.2004.003.]
   Zheng Y, 2019, APPL PSYCHOLINGUIST, V40, P93, DOI 10.1017/S0142716418000462
NR 105
TC 0
Z9 0
U1 4
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD JAN
PY 2021
VL 24
IS 1
AR e13002
DI 10.1111/desc.13002
EA JUL 2020
PG 19
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA PI9LT
UT WOS:000545461700001
PM 32506622
DA 2021-02-24
ER

PT J
AU Kuchinsky, SE
   Eitel, MM
   Lange, RT
   French, LM
   Brickell, TA
   Lippa, SM
   Brungart, DS
AF Kuchinsky, Stefanie E.
   Eitel, Megan M.
   Lange, Rael T.
   French, Louis M.
   Brickell, Tracey A.
   Lippa, Sara M.
   Brungart, Douglas S.
TI Objective and Subjective Auditory Effects of Traumatic Brain Injury and
   Blast Exposure in Service Members and Veterans
SO FRONTIERS IN NEUROLOGY
LA English
DT Article
DE speech perception; hearing; tinnitus; traumatic brain injury; blast
   exposure; service members and veterans
ID SPEECH-PERCEPTION; HEARING-LOSS; TBI; DYSFUNCTION; ADULTS
AB Service members and veterans (SMVs) with a history of traumatic brain injury (TBI) or blast-related injury often report difficulties understanding speech in complex environments that are not captured by clinical tests of auditory function. Little is currently known about the relative contribution of other auditory, cognitive, and symptomological factors to these communication challenges. This study evaluated the influence of these factors on subjective and objective measures of hearing difficulties in SMVs with and without a history of TBI or blast exposure. Analyses included 212 U.S. SMVs who completed auditory and cognitive batteries and surveys of hearing and other symptoms as part of a larger longitudinal study of TBI. Objective speech recognition performance was predicted by TBI status, while subjective hearing complaints were predicted by blast exposure. Bothersome tinnitus was associated with a history of more severe TBI. Speech recognition performance deficits and tinnitus complaints were also associated with poorer cognitive function. Hearing complaints were predicted by high frequency hearing loss and reports of more severe PTSD symptoms. These results suggest that SMVs with a history of blast exposure and/or TBI experience communication deficits that go beyond what would be expected based on standard audiometric assessments of their injuries.
C1 [Kuchinsky, Stefanie E.; Eitel, Megan M.; Lange, Rael T.; French, Louis M.; Brickell, Tracey A.; Lippa, Sara M.; Brungart, Douglas S.] Walter Reed Natl Mil Med Ctr, Bethesda, MD 20814 USA.
   [Eitel, Megan M.; Lange, Rael T.; French, Louis M.; Brickell, Tracey A.; Lippa, Sara M.] Def & Vet Brain Injury Ctr, Silver Spring, MD USA.
   [Eitel, Megan M.] Henry M Jackson Fdn Adv Mil Med, Bethesda, MD USA.
   [Lange, Rael T.; French, Louis M.; Brickell, Tracey A.; Lippa, Sara M.] Natl Intrepid Ctr Excellence, Bethesda, MD USA.
   [Lange, Rael T.] Univ British Columbia, Dept Psychiat, Vancouver, BC, Canada.
   [Lange, Rael T.; Brickell, Tracey A.] Gen Dynam Informat Technol, Falls Church, VA USA.
   [French, Louis M.; Brickell, Tracey A.] Uniformed Serv Univ Hlth Sci, Dept Psychiat, Bethesda, MD 20814 USA.
RP Kuchinsky, SE (corresponding author), Walter Reed Natl Mil Med Ctr, Bethesda, MD 20814 USA.
EM stefanie.e.kuchinsky.civ@mail.mil
OI french, louis/0000-0002-9451-0604
FU Defense and Veterans Brain Injury Center (DVBIC) 15-Year Longitudinal
   TBI Study [Sec721 NDAA FY2007]
FX This work was supported by the Defense and Veterans Brain Injury Center
   (DVBIC) 15-Year Longitudinal TBI Study (Sec721 NDAA FY2007).
CR Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Alamgir H, 2016, MILITARY MED RES, V3, DOI 10.1186/s40779-016-0082-5
   American Psychiatric Association, 1994, DIAGN STAT MAN MENT, V4th
   Belanger HG, 2011, CLIN NEUROPSYCHOL, V25, P702, DOI 10.1080/13854046.2011.566892
   Bergemalm PO, 2005, INT J AUDIOL, V44, P39, DOI 10.1080/14992020400022546
   BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32
   Brungart DS, 2014, J ACOUST SOC AM, V136, P777, DOI 10.1121/1.4887440
   Cameron S, 2007, EAR HEARING, V28, P196, DOI 10.1097/AUD.0b013e318031267f
   Carlson KF, 2019, AM J AUDIOL, V28, P181, DOI 10.1044/2018_AJA-TTR17-18-0042
   Cave KM, 2007, MIL MED, V172, P726, DOI 10.7205/MILMED.172.7.726
   CDC-NIOSH, 2019, TOP OCC HEAR LOSS OH
   Chandler CDW, 2006, ASHA LEADER, V11, P8
   Conners K., 2002, CONNERS CONTINUOUS P
   Corrigan JD, 2007, J HEAD TRAUMA REHAB, V22, P318, DOI 10.1097/01.HTR.0000300227.67748.77
   Defense and Veterans Brain Injury Center (DVBIC), 2020, DOD WORLDW NUMB TBI
   Delis DC, 2001, DELIS KAPLAN EXECUTI
   Epidemiology Program Post-Deployment Health Group Office of Public Health Veterans Health Administration Department of Veterans Affairs, 2015, AN VA HLTH CAR UT OP
   Fausti SA, 2009, J REHABIL RES DEV, V46, P797, DOI 10.1682/JRRD.2008.09.0118
   Gieseler A, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00219
   Goldstein LE, 2012, SCI TRANSL MED, V4, DOI 10.1126/scitranslmed.3004862
   Gramacy RB, 2019, MONOMVN PACKAGE ESTI
   Henry JA, 2015, AM J AUDIOL, V24, P66, DOI 10.1044/2014_AJA-14-0042
   Hernandez LM, 1999, GULF WAR VETERANS ME
   Hoffman HJ, 2004, TINNITUS THEORY MANA, P16
   Hoge CW, 2008, NEW ENGL J MED, V358, P453, DOI 10.1056/NEJMoa072972
   Hoge CW, 2006, JAMA-J AM MED ASSOC, V295, P1023, DOI 10.1001/jama.295.9.1023
   Holmes S, 2009, J CLIN NURS, V18, P2927, DOI 10.1111/j.1365-2702.2009.02909.x
   Hoover EC, 2017, J AM ACAD AUDIOL, V28, P325, DOI 10.3766/jaaa.16051
   House AS, 1963, ESDTDR63403, V86, P1
   Kochkin S., 2005, IMPACT TREATED HEARI
   Krause MO, 2014, BRAIN INJURY, V28, P1473, DOI 10.3109/02699052.2014.920520
   Lange RT, 2020, J TRAUMA STRESS, V33, P318, DOI 10.1002/jts.22480
   Lange RT, 2020, NEUROPSYCHOL REHABIL, V30, P1762, DOI 10.1080/09602011.2019.1604385
   Lew HL, 2007, J REHABIL RES DEV, V44, P921, DOI 10.1682/JRRD.2007.09.0140
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P1131, DOI 10.1093/gerona/glr115
   Lippa SM, 2020, J NEUROTRAUM, V37, P608, DOI 10.1089/neu.2019.6696
   Lux WE, 2007, J REHABIL RES DEV, V44, P951, DOI 10.1682/JRRD.2007.01.0009
   Park T, 2008, J AM STAT ASSOC, V103, P681, DOI 10.1198/016214508000000337
   Phatak SA, 2019, EAR HEARING, V40, P426, DOI 10.1097/AUD.0000000000000635
   R Development Core Team, 2019, R LANG ENV STAT COMP
   Ramsay Ian S, 2018, Schizophr Res Cogn, V11, P1, DOI 10.1016/j.scog.2017.10.001
   REITAN R. M., 1958, PERCEPT MOT SKILLS, V8, P271
   ROSENHALL U, 1985, SCAND AUDIOL, V14, P187, DOI 10.3109/01050398509045940
   Rudner M, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/869726
   Santana MVD, 2017, MIL MED, V182, pE1885, DOI 10.7205/MILMED-D-17-00020
   Stern RA, 2003, NAB ADM SCORING INTE
   Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Trevis KJ, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01262
   Tulsky DS, 2016, J HEAD TRAUMA REHAB, V31, P40, DOI 10.1097/HTR.0000000000000131
   Weathers F. W., 2013, PTSD CHECKLIST DSM 5
   Wechsler D., 2008, WECHSLER ADULT INTEL
   Wilson RH, 2007, J SPEECH LANG HEAR R, V50, P844, DOI 10.1044/1092-4388(2007/059)
NR 52
TC 0
Z9 0
U1 2
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-2295
J9 FRONT NEUROL
JI Front. Neurol.
PD JUL 3
PY 2020
VL 11
AR 613
DI 10.3389/fneur.2020.00613
PG 9
WC Clinical Neurology; Neurosciences
SC Neurosciences & Neurology
GA MR8MB
UT WOS:000553843900001
PM 32719649
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Berezutskaya, J
   Freudenburg, ZV
   Guclu, U
   van Gerven, MAJ
   Ramsey, NF
AF Berezutskaya, Julia
   Freudenburg, Zachary V.
   Guclu, Umut
   van Gerven, Marcel A. J.
   Ramsey, Nick F.
TI Brain-optimized extraction of complex sound features that drive
   continuous auditory perception
SO PLOS COMPUTATIONAL BIOLOGY
LA English
DT Article
ID NEURAL-NETWORKS; SPEECH; CORTEX; HIERARCHY; MODELS; REPRESENTATION;
   ORGANIZATION; INFORMATION; WINDOWS; FMRI
AB Understanding how the human brain processes auditory input remains a challenge. Traditionally, a distinction between lower- and higher-level sound features is made, but their definition depends on a specific theoretical framework and might not match the neural representation of sound. Here, we postulate that constructing a data-driven neural model of auditory perception, with a minimum of theoretical assumptions about the relevant sound features, could provide an alternative approach and possibly a better match to the neural responses. We collected electrocorticography recordings from six patients who watched a long-duration feature film. The raw movie soundtrack was used to train an artificial neural network model to predict the associated neural responses. The model achieved high prediction accuracy and generalized well to a second dataset, where new participants watched a different film. The extracted bottom-up features captured acoustic properties that were specific to the type of sound and were associated with various response latency profiles and distinct cortical distributions. Specifically, several features encoded speech-related acoustic properties with some features exhibiting shorter latency profiles (associated with responses in posterior perisylvian cortex) and others exhibiting longer latency profiles (associated with responses in anterior perisylvian cortex). Our results support and extend the current view on speech perception by demonstrating the presence of temporal hierarchies in the perisylvian cortex and involvement of cortical sites outside of this region during audiovisual speech perception.
C1 [Berezutskaya, Julia; Freudenburg, Zachary V.; Ramsey, Nick F.] Univ Med Ctr Utrecht, Dept Neurol & Neurosurg, Brain Ctr, Utrecht, Netherlands.
   [Berezutskaya, Julia; Guclu, Umut; van Gerven, Marcel A. J.] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
RP Berezutskaya, J (corresponding author), Univ Med Ctr Utrecht, Dept Neurol & Neurosurg, Brain Ctr, Utrecht, Netherlands.; Berezutskaya, J (corresponding author), Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
EM y.berezutskaya-2@umcutrecht.nl
RI Guclu, Umut/AAX-6105-2020
OI Guclu, Umut/0000-0003-4753-159X; Berezutskaya, Julia/0000-0002-2005-8758
FU ERC-Advanced 'iConnect' project [ADV 320708]; 'Language in interaction'
   project (NWO Gravitation grant) [024.001.006]
FX This research was funded by the ERC-Advanced 'iConnect' project (grant
   ADV 320708), and the 'Language in interaction' project (NWO Gravitation
   grant 024.001.006). The funders had no role in study design, data
   collection and analysis, decision to publish, or preparation of the
   manuscript.
CR Baldassano C, 2017, NEURON, V95, P709, DOI 10.1016/j.neuron.2017.06.041
   Bendixen A, 2012, INT J PSYCHOPHYSIOL, V83, P120, DOI 10.1016/j.ijpsycho.2011.08.003
   Berezutskaya J, 2017, J NEUROSCI, V37, P7906, DOI 10.1523/JNEUROSCI.0238-17.2017
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Botvinick MM, 2008, TRENDS COGN SCI, V12, P201, DOI 10.1016/j.tics.2008.02.009
   Branco MP, 2018, J NEUROSCI METH, V301, P43, DOI 10.1016/j.jneumeth.2017.10.022
   Cate AD, 2012, NEUROIMAGE, V63, P1295, DOI 10.1016/j.neuroimage.2012.08.026
   Chi T, 2005, J ACOUST SOC AM, V118, P887, DOI 10.1121/1.1945807
   Cichy RM, 2016, SCI REP-UK, V6, DOI 10.1038/srep27755
   Crone NE, 1998, BRAIN, V121, P2301, DOI 10.1093/brain/121.12.2301
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010
   Elliott TM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000302
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   Giraud AL, 2000, J NEUROPHYSIOL, V84, P1588
   Grafton ST, 2007, HUM MOVEMENT SCI, V26, P590, DOI 10.1016/j.humov.2007.05.009
   GREENFIELD PM, 1991, BEHAV BRAIN SCI, V14, P531, DOI 10.1017/S0140525X00071235
   Guclu U, 2016, ADV NEURAL INFORM PR, V29, P2101
   Guclu U, 2015, J NEUROSCI, V35, P10005, DOI 10.1523/JNEUROSCI.5023-14.2015
   Hasson U, 2015, TRENDS COGN SCI, V19, P304, DOI 10.1016/j.tics.2015.04.006
   Haufe S, 2018, NEUROIMAGE, V179, P79, DOI 10.1016/j.neuroimage.2018.06.016
   Hermes D, 2012, HUM BRAIN MAPP, V33, P1689, DOI 10.1002/hbm.21314
   Hermes D, 2010, J NEUROSCI METH, V185, P293, DOI 10.1016/j.jneumeth.2009.10.005
   Honey CJ, 2012, NEURON, V76, P423, DOI 10.1016/j.neuron.2012.08.011
   Hullett PW, 2016, J NEUROSCI, V36, P2014, DOI 10.1523/JNEUROSCI.1779-15.2016
   Jain Shailee, 2018, ADV NEURAL INFORM PR, V31, P6628
   Kell AJE, 2018, NEURON, V98, P630, DOI 10.1016/j.neuron.2018.03.044
   Khaligh-Razavi SM, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003915
   Kietzmann TC, 2019, P NATL ACAD SCI USA, V116, P21854, DOI 10.1073/pnas.1905544116
   Kriegeskorte N, 2008, FRONT SYST NEUROSCI, V2, DOI 10.3389/neuro.06.004.2008
   Krueger D., 2016, ARXIV160601305
   Lerner Y, 2011, J NEUROSCI, V31, P2906, DOI 10.1523/JNEUROSCI.3684-10.2011
   Loeb GE, 1999, EXP BRAIN RES, V126, P1, DOI 10.1007/s002210050712
   Macmillan N, 2004, DETECTION THEORY USE
   Martin S, 2017, BIORXIV, DOI [10.1101/106617, DOI 10.1101/106617]
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Moutoussis K, 1997, P ROY SOC B-BIOL SCI, V264, P1407, DOI 10.1098/rspb.1997.0196
   Nakai T, 2018, IEEE SYS MAN CYBERN, P584, DOI 10.1109/SMC.2018.00108
   Nili H, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003553
   Overath T, 2008, J NEUROSCI, V28, P13268, DOI 10.1523/JNEUROSCI.4596-08.2008
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   Patterson R., 1987, M IOC SPEECH GROUP A
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Rauschecker JP, 1998, CURR OPIN NEUROBIOL, V8, P516, DOI 10.1016/S0959-4388(98)80040-8
   SanMiguel I, 2013, J NEUROSCI, V33, P8633, DOI 10.1523/JNEUROSCI.5821-12.2013
   Santoro R, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003412
   Schonwiesner M, 2009, P NATL ACAD SCI USA, V106, P14611, DOI 10.1073/pnas.0907682106
   Spoerer CJ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01551
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tokui S, 2015, ANN C NEUR INF PROC
   Torgerson WS, 1958, THEORY METHODS SCALI
   Wessinger CM, 2001, J COGNITIVE NEUROSCI, V13, P1, DOI 10.1162/089892901564108
   Woolley SMN, 2005, NAT NEUROSCI, V8, P1371, DOI 10.1038/nn1536
   Yamins DLK, 2016, NAT NEUROSCI, V19, P356, DOI 10.1038/nn.4244
NR 57
TC 1
Z9 1
U1 0
U2 0
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1553-734X
EI 1553-7358
J9 PLOS COMPUT BIOL
JI PLoS Comput. Biol.
PD JUL
PY 2020
VL 16
IS 7
AR e1007992
DI 10.1371/journal.pcbi.1007992
PG 34
WC Biochemical Research Methods; Mathematical & Computational Biology
SC Biochemistry & Molecular Biology; Mathematical & Computational Biology
GA MY0AE
UT WOS:000558078100026
PM 32614826
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Silva, CM
   Fernandes, C
   Rocha, C
   Pereira, T
AF Silva, Carla Matos
   Fernandes, Carolina
   Rocha, Clara
   Pereira, Telmo
TI Study of Acute and Sub-Acute Effects of Auditory Training on the Central
   Auditory Processing in Older Adults with Hearing Loss-A Pilot Study
SO INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH
LA English
DT Article
DE auditory training; auditory perception; elderly people; hearing loss
ID LARGE-SAMPLE; CANTAB
AB Background: Impairment in speech perception is a common feature of older adults. This study aimed at evaluating the acute and sub-acute (after three months) effects of auditory training on central auditory processing in older people with hearing loss. Methods: A nonrandomized study was conducted enrolling 15 older adults with hearing loss and an average age of 78.6 +/- 10.9 years. All participants underwent a baseline otoscopy, tympanogram, audiogram and speech-in-noise test with a signal-noise ratio (SNR) of 10 and 15 dB. Afterwards, auditory training intervention was implemented consisting of 10 training sessions over 5 weeks. Participants were divided into two groups: group 1 (G1) underwent auditory training based on a speech-in-noise test; group 2 (G2) underwent a filtered-speech test. Auditory processing was evaluated at baseline (T0) immediately after the intervention (T1) and 3 months after the intervention (T2). Results: Group 1 were quite efficient regardless of the SNR in the right ear with statistically significant differences from T0 to T1 (p= 0.003 andp= 0.006 for 10 dB and 15 dB, respectively) and T0 to T2 (p= 0.011 and 0.015 for 10 dB and 15 dB, respectively). As for the left ear, the increase of success was statistically significant for the SNR of 10 dB and 15 dB from T0 to T1 (p= 0.001 andp= 0.014, respectively) and from T0 to T2 (p= 0.016 andp= 0.003). In G2, there was a significant variation only from T0 for T1 in the left ear for an SNR of 10 dB (p= 0.001). Conclusion: Speech perception in noise significantly improved after auditory training in old adults.
C1 [Silva, Carla Matos] Inst Politecn Coimbra, ESTeSC Coimbra Hlth Sch, Dept Audiol, P-3046854 Coimbra, Portugal.
   [Silva, Carla Matos; Pereira, Telmo] Inst Politecn Coimbra, LABINSAUDE Lab Invest Ciencias Aplicadas Saude, ESTeSC, P-3046854 Coimbra, Portugal.
   [Silva, Carla Matos] Univ Lisbon, Ctr Linguist, Sch Arts & Humanities, P-1649004 Lisbon, Portugal.
   [Fernandes, Carolina] MiniSom, P-1050148 Lisbon, Portugal.
   [Rocha, Clara] Inst Politecn Coimbra, ESTeSC Coimbra Hlth Sch, Dept Ciencias Complementares, P-3046854 Coimbra, Portugal.
   [Rocha, Clara] Univ Coimbra, Inst Syst Engn & Comp Coimbra, INESC Coimbra, P-3000033 Coimbra, Portugal.
   [Pereira, Telmo] Politecn Coimbra, Dept Fisiol Clin, ESTeSC Coimbra Hlth Sch, P-3046854 Coimbra, Portugal.
RP Silva, CM (corresponding author), Inst Politecn Coimbra, ESTeSC Coimbra Hlth Sch, Dept Audiol, P-3046854 Coimbra, Portugal.; Silva, CM (corresponding author), Inst Politecn Coimbra, LABINSAUDE Lab Invest Ciencias Aplicadas Saude, ESTeSC, P-3046854 Coimbra, Portugal.; Silva, CM (corresponding author), Univ Lisbon, Ctr Linguist, Sch Arts & Humanities, P-1649004 Lisbon, Portugal.
EM carla@estescoimbra.pt; carol_sofia_fernandes@hotmail.com;
   ClaraPR@estescoimbra.pt; telmo@estescoimbra.pt
RI Rocha, Maria Clara/F-4729-2014; Pereira, Telmo/M-4626-2013
OI Rocha, Maria Clara/0000-0002-4724-1843; Pereira,
   Telmo/0000-0001-9119-7774; Matos Silva, Carla/0000-0002-6811-5694
FU European Regional Development Fund (ERDF) through the partnership
   agreement Portugal2020-Regional Operation Program CENTRO2020
   [CENTRO-01-0145-FEDER-023369]; QREN Project under the Program Mais
   Centro, Commission of the Central Region Coordination; European Union
   through the European Regional Development FundEuropean Commission
FX This research was funded by the European Regional Development Fund
   (ERDF) through the partnership agreement Portugal2020-Regional Operation
   Program CENTRO2020, under the project CENTRO-01-0145-FEDER-023369
   AGA@4life: AGA-Comprehensive Geriatric approach to promote an active and
   healthy aging-implementation of an integrated and multidisciplinary
   intervention program. Labinsaude: Co-funded by the QREN Project under
   the Program Mais Centro, Commission of the Central Region Coordination
   and the European Union through the European Regional Development Fund.
CR American Academy of Audiology (AAA, CLIN PRACT GUID
   American Speech-Language Hearing Association, 1996, AM J AUDIOL, V5, P41, DOI 10.1044/1059-0889.0502.41
   American Speech-Language-Association (ASHA), TECHNICAL REPORT
   Anderson S, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00097
   Baran J.A, 1999, CONT PERSPECTIVES HE, P377
   Bellis T., CENTRAL AUDITORY PRO
   Bellis T J, 1996, ASSESSMENT MANAGEMEN
   BIAP, 1997, BIAP RECN 02 1 AUD C
   Bocca E., 1963, CENTRAL HEARING PROC, P337
   Canul R, 2019, J COASTAL RES, P75, DOI 10.2112/SI92-009.1
   Caporali Sueli A., 2004, Rev. Bras. Otorrinolaringol., V70, P525, DOI 10.1590/S0034-72992004000400014
   Cruz Ana Carolina Almendra, 2013, Rev. CEFAC, V15, P1427, DOI 10.1590/S1516-18462013000600004
   Ferguson MA, 2015, FRONT PSYCHOL, V6, DOI [10.3389/fpsyg.2015.00556, 10.3389/fpg.2015.00556]
   Gil D., 2006, THESIS
   Hamlyn K, 2018, J AM ACAD AUDIOL, V29, P788, DOI 10.3766/jaaa.16152
   Heeke P, 2018, J AM ACAD AUDIOL, V29, P948, DOI 10.3766/jaaa.18005
   Keith R.W, 2000, DIAGNOSING CENTRAL A, P337
   Machado S.F., 2003, PROCESSAMENTO AUDITI
   Martin JS, 2005, J REHABIL RES DEV, V42, P25, DOI 10.1682/JRRD.2004.12.0164
   Martins J, 2017, THESIS
   Martins J, 2013, BATERIA TESTES PROCE
   McArdle Rachel A, 2005, J Am Acad Audiol, V16, P726, DOI 10.3766/jaaa.16.9.9
   Moore DR, 2010, PEDIATRICS, V126, pE382, DOI 10.1542/peds.2009-2826
   Morais AA, 2015, FRONT AGING NEUROSCI, V7, DOI 10.3389/fnagi.2015.00078
   Musiek F., 2007, AUDITORY SYSTEM ANAT
   Musiek F, 2001, AVALIACAO COMPORTAME, P343
   Neves Vera T. das, 2003, Rev. Bras. Otorrinolaringol., V69, P242, DOI 10.1590/S0034-72992003000200015
   Nunes C.L., 2015, PROCESSAMENTO AUDITI, P113
   Nunes C.L., 2015, PROCESSAMENTO AUDITI, P17
   Nunes C.L, 2015, PROCESSAMENTO AUDITI, P11
   Pereira L.D, 1993, TEMAS DESENVOLVIMENT, V12, P7
   Pereira LD, 2011, TESTES AUDITIVOS COM
   Pichora-Fuller M Kathleen, 2006, Trends Amplif, V10, P29, DOI 10.1177/108471380601000103
   Pujol R., 2016, VIAGEM AO MUNDO AUDI
   Rabelo CM, 2018, CLINICS, V73, DOI 10.6061/clinics/2018/e407
   Rivabem K., 2006, THESIS
   Robbins TW, 1998, J INT NEUROPSYCH SOC, V4, P474, DOI 10.1017/s1355617798455073
   ROBBINS TW, 1994, DEMENTIA, V5, P266, DOI 10.1159/000106735
   Ruschel Christine Vieira, 2007, Rev. soc. bras. fonoaudiol., V12, P95, DOI 10.1590/S1516-80342007000200005
   Schochat E, 2002, PRO-FONO REV ATUAL C, V14, P93
   Stephens D, 2003, Noise Health, V5, P55
   Sweetow RW, 2010, J AM ACAD AUDIOL, V21, P586, DOI 10.3766/jaaa.21.9.4
   Tiffin S, 2018, J AM ACAD AUDIOL, V29, P596, DOI 10.3766/jaaa.16159
   Tremblay KL, 2015, EAR HEARING, V36, pE290, DOI 10.1097/AUD.0000000000000195
   Veras Renato Peixoto, 2007, Rev. Bras. Otorrinolaringol., V73, P128, DOI 10.1590/S0034-72992007000100021
NR 45
TC 0
Z9 0
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1660-4601
J9 INT J ENV RES PUB HE
JI Int. J. Environ. Res. Public Health
PD JUL
PY 2020
VL 17
IS 14
AR 4944
DI 10.3390/ijerph17144944
PG 14
WC Environmental Sciences; Public, Environmental & Occupational Health
SC Environmental Sciences & Ecology; Public, Environmental & Occupational
   Health
GA MS3FM
UT WOS:000554166500001
PM 32659935
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Jennings, SG
   Chen, J
AF Jennings, Skyler G.
   Chen, Jessica
TI Masking of short tones in noise: Evidence for envelope-based, rather
   than energy-based detectiona)
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID AUDITORY FILTER SHAPES; MASKER LEVEL; NARROW-BAND;
   FREQUENCY-SELECTIVITY; AMPLITUDE-MODULATION; CONTRALATERAL PRECURSORS;
   TEMPORAL INTEGRATION; SIGNAL FREQUENCY; TIME-COURSE; OVERSHOOT
AB The "temporal effect" in simultaneous masking may be characterized by better probe detection thresholds for a short, tonal probe presented at the temporal center of a masker compared to at the onset of a masker. Energy-based models of masking have been used to interpret the temporal effect as evidence that the gain of the auditory system decreases during acoustic stimulation. This study shows that masking from temporal-envelope fluctuations of a precursor or from a temporal gap between stimuli violates the assumptions of energy-based models and complicates the interpretation of temporal effects in terms of a reduction in gain. Detection thresholds were measured for a 6-ms, 4000-Hz probe preceded by a narrowband precursor and presented 2-, 197-, or 392-ms after the onset of a narrowband masker. The delay between the precursor offset and masker onset ranged from -2 to 250 ms. Probe thresholds were elevated in the presence of precursors with fluctuating compared to flattened temporal envelopes and when a temporal gap was inserted between the precursor and masker. The results suggest that the interpretation and design of temporal-effect studies should consider the masking effects of temporal-envelope fluctuations. These findings are consistent with speech-perception experiments that show masking from temporal-envelope fluctuations.
C1 [Jennings, Skyler G.; Chen, Jessica] Univ Utah, Dept Commun Sci & Disorders, 390 South,1530 East,Behav Sci Bldg 1201, Salt Lake City, UT 84112 USA.
RP Jennings, SG (corresponding author), Univ Utah, Dept Commun Sci & Disorders, 390 South,1530 East,Behav Sci Bldg 1201, Salt Lake City, UT 84112 USA.
EM skyler.jennings@hsc.utah.edu
FU NIH/NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [K23 DC014752]
FX This work was supported by Grant No. K23 DC014752 from NIH/NIDCD (PI:
   S.G.J.). The authors thank Michael Simpson and Olivia Piper for
   assistance with data collection. Laurel Carney provided helpful comments
   on an earlier version of this manuscript.
CR American National Standards Institute, 2004, S362004 ANSI
   Backus BC, 2006, J ACOUST SOC AM, V119, P2889, DOI 10.1121/1.2169918
   Bacon SP, 2000, J ACOUST SOC AM, V108, P1811, DOI 10.1121/1.1290246
   BACON SP, 1989, J ACOUST SOC AM, V85, P2575, DOI 10.1121/1.397751
   Bacon SP, 2000, J ACOUST SOC AM, V107, P1589, DOI 10.1121/1.428443
   Bacon SP, 2004, J ACOUST SOC AM, V115, P1674, DOI 10.1121/1.1689344
   BACON SP, 1992, J ACOUST SOC AM, V91, P2865, DOI 10.1121/1.402967
   Bacon SP, 1999, J ACOUST SOC AM, V106, P341, DOI 10.1121/1.427060
   BACON SP, 1985, J ACOUST SOC AM, V78, P1231, DOI 10.1121/1.392891
   BACON SP, 1990, J ACOUST SOC AM, V88, P698, DOI 10.1121/1.399773
   BACON SP, 1991, Q J EXP PSYCHOL-A, V43, P373, DOI 10.1080/14640749108400978
   Bidelman GM, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01498
   Buss E, 2006, J ACOUST SOC AM, V120, P2777, DOI 10.1121/1.2354024
   CARLYON RP, 1992, J ACOUST SOC AM, V91, P1034, DOI 10.1121/1.402629
   Carney LH, 2018, JARO-J ASSOC RES OTO, V19, P331, DOI 10.1007/s10162-018-0669-5
   CHAMPLIN CA, 1989, J ACOUST SOC AM, V85, P2005, DOI 10.1121/1.397853
   Dau T, 1996, J ACOUST SOC AM, V99, P3615, DOI 10.1121/1.414959
   Dau T, 1997, J ACOUST SOC AM, V102, P2892, DOI 10.1121/1.420344
   Davidson SA, 2006, J ACOUST SOC AM, V119, P2258, DOI 10.1121/1.2177583
   Dean I, 2005, NAT NEUROSCI, V8, P1684, DOI 10.1038/nn1541
   Ewert SD, 2000, J ACOUST SOC AM, V108, P1181, DOI 10.1121/1.1288665
   Fletcher H, 1940, REV MOD PHYS, V12, P0047, DOI 10.1103/RevModPhys.12.47
   Fogerty D, 2016, J ACOUST SOC AM, V140, P1800, DOI 10.1121/1.4962494
   Gallun FJ, 2006, J ACOUST SOC AM, V119, P3919, DOI 10.1121/1.2200136
   GERKEN GM, 1990, J ACOUST SOC AM, V88, P767, DOI 10.1121/1.399726
   Glasberg BR, 2000, J ACOUST SOC AM, V108, P2318, DOI 10.1121/1.1315291
   GLASBERG BR, 1990, HEARING RES, V47, P103, DOI 10.1016/0378-5955(90)90170-T
   GREEN DM, 1983, AM PSYCHOL, V38, P133, DOI 10.1037/0003-066X.38.2.133
   Guinan JJ, 2006, EAR HEARING, V27, P589, DOI 10.1097/01.aud.0000240507.83072.e7
   Jennings SG, 2018, JARO-J ASSOC RES OTO, V19, P717, DOI 10.1007/s10162-018-00688-x
   Jennings SG, 2016, J ACOUST SOC AM, V140, P2481, DOI 10.1121/1.4964267
   Jennings SG, 2011, JARO-J ASSOC RES OTO, V12, P345, DOI 10.1007/s10162-011-0256-5
   Jepsen ML, 2011, J ACOUST SOC AM, V129, P262, DOI 10.1121/1.3518768
   JESTEADT W, 1982, J ACOUST SOC AM, V71, P950, DOI 10.1121/1.387576
   Kohlrausch A, 1997, ACUSTICA, V83, P659
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Liberman MC, 1998, J COMMUN DISORD, V31, P471, DOI 10.1016/S0021-9924(98)00019-7
   Mao JW, 2015, JARO-J ASSOC RES OTO, V16, P121, DOI 10.1007/s10162-014-0489-1
   Marrufo-Perez MI, 2019, HEARING RES, V377, P133, DOI 10.1016/j.heares.2019.03.017
   Marrufo-Perez MI, 2018, J NEUROSCI, V38, P4138, DOI 10.1523/JNEUROSCI.0024-18.2018
   MCFADDEN D, 1989, J ACOUST SOC AM, V85, P254, DOI 10.1121/1.397732
   MCFADDEN D, 1990, J ACOUST SOC AM, V87, P2634, DOI 10.1121/1.399056
   MOORE BCJ, 1982, J ACOUST SOC AM, V72, P1374, DOI 10.1121/1.388441
   NEFF DL, 1985, J ACOUST SOC AM, V78, P1966, DOI 10.1121/1.392653
   Oxenham AJ, 1997, J ACOUST SOC AM, V101, P3666, DOI 10.1121/1.418327
   Oxenham AJ, 2001, J ACOUST SOC AM, V109, P732, DOI 10.1121/1.1336501
   Oxenham AJ, 1998, J ACOUST SOC AM, V103, P1033, DOI 10.1121/1.421229
   PATTERSON RD, 1976, J ACOUST SOC AM, V59, P640, DOI 10.1121/1.380914
   PICKLES JO, 1984, HEARING RES, V14, P245, DOI 10.1016/0378-5955(84)90053-4
   Richards VM, 2019, J ACOUST SOC AM, V145, pEL442, DOI 10.1121/1.5109122
   RICHARDS VM, 1992, J ACOUST SOC AM, V91, P3424, DOI 10.1121/1.402831
   Robles L, 2001, PHYSIOL REV, V81, P1305
   Roverud E, 2010, J ACOUST SOC AM, V128, P1203, DOI 10.1121/1.3473695
   Savel S, 2003, J ACOUST SOC AM, V114, P580, DOI 10.1121/1.1592162
   Savel S, 2003, J ACOUST SOC AM, V114, P380, DOI 10.1121/1.1582442
   SCHMIDT S, 1991, J ACOUST SOC AM, V89, P1324, DOI 10.1121/1.400656
   SMITH RL, 1975, BIOL CYBERN, V17, P169, DOI 10.1007/BF00364166
   Stone MA, 2012, J ACOUST SOC AM, V132, P317, DOI 10.1121/1.4725766
   Strickland EA, 2005, J ACOUST SOC AM, V118, P3211, DOI 10.1121/1.2074787
   Strickland EA, 2004, J ACOUST SOC AM, V115, P2234, DOI 10.1121/1.1691036
   Strickland EA, 2001, J ACOUST SOC AM, V109, P2062, DOI 10.1121/1.1357811
   Strickland EA, 2008, J ACOUST SOC AM, V123, P946, DOI 10.1121/1.2821977
   Svec A, 2016, J ACOUST SOC AM, V139, P1195, DOI 10.1121/1.4944041
   Svec A, 2015, J ACOUST SOC AM, V137, P1336, DOI 10.1121/1.4908567
   Svec A, 2013, J ACOUST SOC AM, V134, P2866, DOI 10.1121/1.4818766
   VONKLITZING R, 1994, J ACOUST SOC AM, V95, P2192, DOI 10.1121/1.408679
   Watson CS, 2005, ACTA ACUST UNITED AC, V91, P502
   Wen B, 2009, J NEUROSCI, V29, P13797, DOI 10.1523/JNEUROSCI.5610-08.2009
   Wojtczak M, 2005, J ACOUST SOC AM, V118, P3198, DOI 10.1121/1.2042970
   Wojtczak M, 2011, JARO-J ASSOC RES OTO, V12, P361, DOI 10.1007/s10162-010-0251-2
   Wright BA, 1997, J ACOUST SOC AM, V101, P420, DOI 10.1121/1.417987
   ZWICKER E, 1965, J ACOUST SOC AM, V37, P653, DOI 10.1121/1.1909389
NR 72
TC 2
Z9 2
U1 0
U2 0
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JUL
PY 2020
VL 148
IS 1
BP 211
EP 221
DI 10.1121/10.0001569
PG 11
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA MQ7HU
UT WOS:000553064900002
PM 32752781
DA 2021-02-24
ER

PT J
AU Schiller, IS
   Morsomme, D
   Kob, M
   Remacle, A
AF Schiller, Isabel S.
   Morsomme, Dominique
   Kob, Malte
   Remacle, Angelique
TI Noise and a Speaker's Impaired Voice Quality Disrupt Spoken Language
   Processing in School-Aged Children: Evidence From Performance and
   Response Time Measures
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID AUDITORY WORKING-MEMORY; SPEECH-INTELLIGIBILITY; PASSAGE COMPREHENSION;
   NORMAL-HEARING; MODEL; PERCEPTION; REVERBERATION
AB Purpose: Our aim was to investigate isolated and combined effects of speech-shaped noise (SSN) and a speaker's impaired voice quality on spoken language processing in first-grade children.
   Method: In individual examinations, 53 typically developing children aged 5-6 years performed a speech perception task (phoneme discrimination) and a listening comprehension task (sentence-picture matching). Speech stimuli were randomly presented in a 2 x 2 factorial design with the factors noise (no added noise vs. SSN at 0- dB SNR) and voice quality (normal voice vs. impaired voice). Outcome measures were task performance and response time (RT).
   Results: SSN and impaired voice quality significantly lowered children's performance and increased RTs in the speech perception task, particularly when combined. Regarding listening comprehension, a significant interaction between noise and voice quality indicated that children's performance was hindered by SSN when the speaker's voice was impaired but not when it was normal. RTs in this task were unaffected by noise or voice quality.
   Conclusions: Results suggest that speech signal degradations caused by a speaker's impaired voice and background noise generate more processing errors and increased listening effort in young school-aged children. This finding is vital for classroom listening and highlights the importance of ensuring teachers' vocal health and adequate room acoustics.
C1 [Schiller, Isabel S.; Morsomme, Dominique; Remacle, Angelique] Univ Liege, Fac Psychol Speech Therapy & Educ Sci, Liege, Belgium.
   [Kob, Malte] Detmold Univ Mus, Erich Thienhaus Inst, Detmold, Germany.
   [Remacle, Angelique] Fund Sci Res FRS FNRS, Brussels, Belgium.
RP Schiller, IS (corresponding author), Univ Liege, Fac Psychol Speech Therapy & Educ Sci, Liege, Belgium.
EM isabel.schiller@uliege.be
OI Kob, Malte/0000-0002-9159-2712; Schiller, Isabel
   Sarah/0000-0003-2387-7625
FU Belgian University Foundation; University of LiegeUniversity of Liege
   [RD/DIR-vdu/2016.7166]; National Fund for Scientific Research
   (F.R.S.-FNRS), Brussels, BelgiumFonds de la Recherche Scientifique -
   FNRS
FX The authors would like to thank the participating schools for their
   assistance during the experiment. We also acknowledge the help of
   Florence Bastings, Louise Lemmens, and Aurelie Gillot in collecting the
   data. This study was published with the support of the Belgian
   University Foundation. Isabel S. Schiller was supported by a PhD grant
   from the University of Liege (Grant RD/DIR-vdu/2016.7166), and Angelique
   Remacle was supported by the National Fund for Scientific Research
   (F.R.S.-FNRS), Brussels, Belgium.
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   Anthony JL, 2005, CURR DIR PSYCHOL SCI, V14, P255, DOI 10.1111/j.0963-7214.2005.00376.x
   Ardoint M, 2010, HEARING RES, V260, P89, DOI 10.1016/j.heares.2009.12.002
   Astolfi A, 2012, J ACOUST SOC AM, V131, P247, DOI 10.1121/1.3662060
   Baayen RH, 2010, INT J PSYCHOL RES, V3, P12
   Balota DA, 2013, J EXP PSYCHOL LEARN, V39, P1563, DOI 10.1037/a0032186
   Barsties B, 2015, AURIS NASUS LARYNX, V42, P183, DOI 10.1016/j.anl.2014.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boersma P., 2017, PRAAT VERSION 6 0 29
   Bradley JS, 2008, J ACOUST SOC AM, V123, P2078, DOI 10.1121/1.2839285
   Brannstrom KJ, 2018, AM J AUDIOL, V27, P231, DOI 10.1044/2018_AJA-17-0061
   Brannstrom KJ, 2018, SPEECH LANG HEARING, V21, P1, DOI 10.1080/2050571X.2017.1309787
   Chui JCH, 2019, J VOICE, V33, DOI 10.1016/j.jvoice.2018.03.004
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   Cooke M, 2008, J ACOUST SOC AM, V123, P414, DOI 10.1121/1.2804952
   Crandell Carl C., 1996, AM J AUDIOL, V5, P47, DOI DOI 10.1044/1059-0889.0503.47
   Deutsches Institut fur Normung e.V, 2019, 1003202CDV IEC
   ELLIOTT LL, 1979, J ACOUST SOC AM, V66, P651, DOI 10.1121/1.383691
   Martins RHG, 2014, J VOICE, V28, DOI 10.1016/j.jvoice.2014.02.008
   Garnier M, 2014, COMPUT SPEECH LANG, V28, P580, DOI 10.1016/j.csl.2013.07.005
   HIRANO M, 1981, DISORDERS HUMAN COMM, P817
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   Houtgast T., 2002, PRESENT FUTURE SPEEC
   Howard CS, 2010, INT J AUDIOL, V49, P928, DOI 10.3109/14992027.2010.520036
   Ishikawa Keiko, 2020, J Voice, DOI 10.1016/j.jvoice.2019.12.022
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Jamieson Donald G, 2004, J Am Acad Audiol, V15, P508, DOI 10.3766/jaaa.15.7.5
   Johnson CE, 2000, J SPEECH LANG HEAR R, V43, P144, DOI 10.1044/jslhr.4301.144
   Khomsi A., 2001, ELO EVALUATION LANGU
   Klatte M, 2010, NOISE HEALTH, V12, P270, DOI 10.4103/1463-1741.70506
   Korkman M., 2007, NEPSY 2 EDITION NEPS
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Lo S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01171
   Lombard E., 1911, ANN MALADIES OREILLE, V37, P101
   Lyberg-Ahlander V, 2015, INT J SPEECH-LANG PA, V17, P577, DOI 10.3109/17549507.2015.1024172
   Lyberg-Ahlander V, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00871
   Lyberg-Ahlander V, 2015, INT J SPEECH-LANG PA, V17, P63, DOI 10.3109/17549507.2014.898098
   Macchi L., 2012, ELDP EPREUVE LILLOIS
   Maryn Y, 2010, J VOICE, V24, P540, DOI 10.1016/j.jvoice.2008.12.014
   Mathot S, 2012, BEHAV RES METHODS, V44, P314, DOI 10.3758/s13428-011-0168-7
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Mattys SL, 2009, COGNITIVE PSYCHOL, V59, P203, DOI 10.1016/j.cogpsych.2009.04.001
   McCreery RW, 2013, EAR HEARING, V34, P585, DOI 10.1097/AUD.0b013e31828576e2
   McGarrigle R, 2019, EAR HEARING, V40, P381, DOI 10.1097/AUD.0000000000000623
   McGarrigle R, 2017, J EXP CHILD PSYCHOL, V161, P95, DOI 10.1016/j.jecp.2017.04.006
   Medwetsky L, 2011, LANG SPEECH HEAR SER, V42, P286, DOI 10.1044/0161-1461(2011/10-0036)
   Morsomme D., 2011, VOCOLOGIE STEM STEMS, P9
   Morton V, 2001, Logoped Phoniatr Vocol, V26, P17, DOI 10.1080/140154301300109080
   Nirme J, 2019, LOGOP PHONIATR VOCO, V44, P79, DOI 10.1080/14015439.2018.1455894
   Osman H, 2014, J SPEECH LANG HEAR R, V57, P1503, DOI 10.1044/2014_JSLHR-H-13-0286
   Peng JX, 2016, ACTA ACUST UNITED AC, V102, P938, DOI 10.3813/AAA.919008
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Prodi N, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02166
   Prodi N, 2019, LANG SPEECH HEAR SER, V50, P196, DOI 10.1044/2018_LSHSS-18-0039
   Prodi N, 2015, J ACOUST SOC AM, V138, P2438, DOI 10.1121/1.4932053
   Quene H, 2004, SPEECH COMMUN, V43, P103, DOI [10.1016/j.specom.2004.02.004, 10.1016/j.specom 2004.02.004]
   R Core Team, 2019, R LANG ENV STAT COMP
   Rabiner DL, 2016, SCHOOL PSYCHOL REV, V45, P250, DOI 10.17105/SPR45-2.250-267
   Ratcliff R, 2004, PSYCHOL REV, V111, P159, DOI 10.1037/0033-295X.111.1.159
   Rogerson J, 2005, J VOICE, V19, P47, DOI 10.1016/j.jvoice.2004.02.007
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Sahlen B, 2018, LOGOP PHONIATR VOCO, V43, P47, DOI 10.1080/14015439.2017.1324914
   Schiller IS, 2020, LOGOP PHONIATR VOCO, V45, P143, DOI 10.1080/14015439.2019.1659410
   Schoentgen J, 2006, ACTA ACUST UNITED AC, V92, P667
   Schwartz L, 2009, MILTON AND MATERNAL MORTALITY, P141, DOI 10.1017/CBO9780511581175.007
   Silva LT, 2016, APPL ACOUST, V106, P2, DOI 10.1016/j.apacoust.2015.12.013
   Sullivan JR, 2015, J SPEECH LANG HEAR R, V58, P1043, DOI 10.1044/2015_JSLHR-H-14-0204
   Visentin C, 2018, J SPEECH LANG HEAR R, V61, P1497, DOI 10.1044/2018_JSLHR-H-17-0418
   von Lochow H, 2018, LOGOP PHONIATR VOCO, V43, P32, DOI 10.1080/14015439.2017.1307446
   von Mentzer CN, 2018, LOGOP PHONIATR VOCO, V43, P106, DOI 10.1080/14015439.2017.1380076
   Whelan R, 2008, PSYCHOL REC, V58, P475, DOI 10.1007/BF03395630
   Wingfield A, 2016, EAR HEARING, V37, p35S, DOI 10.1097/AUD.0000000000000310
   Zhang YX, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0053502
NR 73
TC 2
Z9 2
U1 1
U2 1
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD JUL
PY 2020
VL 63
IS 7
BP 2115
EP 2131
DI 10.1044/2020_JSLHR-19-00348
PG 17
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA MR0JC
UT WOS:000553279000006
PM 32569506
DA 2021-02-24
ER

PT J
AU Venezia, JH
   Leek, MR
   Lindeman, MP
AF Venezia, Jonathan H.
   Leek, Marjorie R.
   Lindeman, Michael P.
TI Suprathreshold Differences in Competing Speech Perception in Older
   Listeners With Normal and Impaired Hearing
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SEQUENTIAL STREAM SEGREGATION; MODULATION TRANSFER-FUNCTIONS;
   AGE-RELATED-CHANGES; GAP DETECTION; FUNDAMENTAL-FREQUENCY; SPATIAL
   SEPARATION; WORD RECOGNITION; MASKING RELEASE; NOISE; ADULTS
AB Purpose: Age-related declines in auditory temporal processing and cognition make older listeners vulnerable to interference from competing speech. This vulnerability may be increased in older listeners with sensorineural hearing loss due to additional effects of spectral distortion and accelerated cognitive decline. The goal of this study was to uncover differences between older hearing-impaired (OHI) listeners and older normal-hearing (ONH) listeners in the perceptual encoding of competing speech signals.
   Method: Age-matched groups of 10 OHI and 10 ONH listeners performed the coordinate response measure task with a synthetic female target talker and a male competing talker at a target-to-masker ratio of +3 dB. Individualized gain was provided to OHI listeners. Each listener completed 50 baseline and 800 "bubbles" trials in which randomly selected segments of the speech modulation power spectrum (MPS) were retained on each trial while the remainder was filtered out. Average performance was fixed at 50% correct by adapting the number of segments retained. Multinomial regression was used to estimate weights showing the regions of the MPS associated with performance (a "classification image" or CImg).
   Results: The CImg weights were significantly different between the groups in two MPS regions: a region encoding the shared phonetic content of the two talkers and a region encoding the competing (male) talker's voice. The OHI listeners demonstrated poorer encoding of the phonetic content and increased vulnerability to interference from the competing talker. Individual differences in CImg weights explained over 75% of the variance in baseline performance in the OHI listeners, whereas differences in high-frequency pure-tone thresholds explained only 10%.
   Conclusion: Suprathreshold deficits in the encoding of low- to mid-frequency (similar to 5-10 Hz) temporal modulations-which may reflect poorer "dip listening"-and auditory grouping at a perceptual and/or cognitive level are responsible for the relatively poor performance of OHI versus ONH listeners on a different-gender competing speech task.
C1 [Venezia, Jonathan H.; Leek, Marjorie R.; Lindeman, Michael P.] VA Loma Linda Healthcare Syst, Redlands, CA 92373 USA.
   [Venezia, Jonathan H.; Leek, Marjorie R.] Loma Linda Univ, Sch Med, Dept Otolaryngol Head & Neck Surg, Loma Linda, CA 92350 USA.
RP Venezia, JH (corresponding author), VA Loma Linda Healthcare Syst, Redlands, CA 92373 USA.; Venezia, JH (corresponding author), Loma Linda Univ, Sch Med, Dept Otolaryngol Head & Neck Surg, Loma Linda, CA 92350 USA.
EM jonathan.venezia@va.gov
OI Venezia, Jonathan/0000-0003-0901-5527
FU American Speech-Language-Hearing Foundation New Investigators Research
   Grant; U.S. Department of Veterans Affairs, Veterans Health
   Administration, Rehabilitation Research & Development Service AwardUS
   Department of Veterans Affairs [IK2RX002702]; Department of Veterans
   Affairs Rehabilitation Research & Development ServiceUS Department of
   Veterans Affairs [C4042L]
FX This work was supported by an American Speech-Language-Hearing
   Foundation New Investigators Research Grant awarded to J. H. V. During
   the investigation, J. H. V. received salary support from the U.S.
   Department of Veterans Affairs, Veterans Health Administration,
   Rehabilitation Research & Development Service Award IK2RX002702. This
   work was also supported by a Senior Research Career Scientist (awarded
   to M. R. L.; C4042L) from the Department of Veterans Affairs
   Rehabilitation Research & Development Service.
CR Agus TR, 2009, J ACOUST SOC AM, V125, P23, DOI 10.1121/1.3025915
   [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   Apoux F, 2010, J ACOUST SOC AM, V128, P2075, DOI 10.1121/1.3478845
   Apoux F, 2009, HEARING RES, V255, P99, DOI 10.1016/j.heares.2009.06.005
   Arbogast TL, 2002, J ACOUST SOC AM, V112, P2086, DOI 10.1121/1.1510141
   BACON SP, 1985, AUDIOLOGY, V24, P117
   Bacon SP, 1998, J SPEECH LANG HEAR R, V41, P549, DOI 10.1044/jslhr.4103.549
   Bernstein J. G., 2016, J ACOUST SOC AM, V139, P2121, DOI DOI 10.1121/1.4950313
   Bernstein JGW, 2009, J ACOUST SOC AM, V125, P3358, DOI 10.1121/1.3110132
   Best V, 2012, J ACOUST SOC AM, V131, P3103, DOI 10.1121/1.3693656
   Best V, 2010, EAR HEARING, V31, P213, DOI 10.1097/AUD.0b013e3181c34ba6
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bolia RS, 2000, J ACOUST SOC AM, V107, P1065, DOI 10.1121/1.428288
   Braver T. S., 2011, THE HANDBOOK OF AGIN, P319
   BRONKHORST AW, 1992, J ACOUST SOC AM, V92, P3132, DOI 10.1121/1.404209
   Campbell J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00071
   Chen F, 2014, J SPEECH LANG HEAR R, V57, P338, DOI 10.1044/1092-4388(2013/12-0324)
   Clopper CG, 2006, J AM ACAD AUDIOL, V17, P331, DOI 10.3766/jaaa.17.5.4
   Creel SC, 2011, LANG LINGUIST COMPAS, V5, P190, DOI 10.1111/j.1749-818x.2011.00276.x
   Dai LS, 2018, P NATL ACAD SCI USA, V115, pE3286, DOI 10.1073/pnas.1721226115
   Darwin CJ, 2003, J ACOUST SOC AM, V114, P2913, DOI 10.1121/1.1616924
   Desjardins JL, 2013, EAR HEARING, V34, P261, DOI 10.1097/AUD.0b013e31826d0ba4
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P2670, DOI 10.1121/1.409836
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P1053, DOI 10.1121/1.408467
   Du Y, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12241
   DUQUESNOY AJ, 1983, J ACOUST SOC AM, V74, P739, DOI 10.1121/1.389859
   Elliott TM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000302
   Fabiani M, 2012, PSYCHOPHYSIOLOGY, V49, P283, DOI 10.1111/j.1469-8986.2011.01331.x
   FESTEN JM, 1990, J ACOUST SOC AM, V88, P1725, DOI 10.1121/1.400247
   Fitzgibbons PJ, 2010, SPRINGER HANDB AUDIT, V34, P111, DOI 10.1007/978-1-4419-0993-0_5
   FITZGIBBONS PJ, 1982, J ACOUST SOC AM, V72, P761, DOI 10.1121/1.388256
   FLORENTINE M, 1988, J ACOUST SOC AM, V84, P195, DOI 10.1121/1.396964
   Fortunato S, 2016, ACTA OTORHINOLARYNGO, V36, P155, DOI 10.14639/0392-100X-993
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Fullgrabe C, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01268
   Gatehouse S, 2004, INT J AUDIOL, V43, P85, DOI 10.1080/14992020400050014
   Gifford RH, 2007, J SPEECH LANG HEAR R, V50, P857, DOI 10.1044/1092-4388(2007/060)
   GLASBERG BR, 1986, J ACOUST SOC AM, V79, P1020, DOI 10.1121/1.393374
   GLASBERG BR, 1987, J ACOUST SOC AM, V81, P1546, DOI 10.1121/1.394507
   Glyde H, 2013, EAR HEARING, V34, P15, DOI 10.1097/AUD.0b013e3182617f94
   Grant KW, 1998, J ACOUST SOC AM, V104, P1051, DOI 10.1121/1.423323
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   Grose JH, 1996, J SPEECH HEAR RES, V39, P1149, DOI 10.1044/jshr.3906.1149
   Grose JH, 2015, AM J AUDIOL, V24, P91, DOI 10.1044/2015_AJA-14-0053
   Helfer KS, 2015, AM J AUDIOL, V24, P80, DOI 10.1044/2015_AJA-14-0056
   Helfer KS, 2014, J ACOUST SOC AM, V136, P748, DOI 10.1121/1.4887463
   Hullett PW, 2016, J NEUROSCI, V36, P2014, DOI 10.1523/JNEUROSCI.1779-15.2016
   Humes LE, 2006, J ACOUST SOC AM, V120, P2926, DOI 10.1121/1.2354070
   Humes LE, 2009, SCAND J PSYCHOL, V50, P485, DOI 10.1111/j.1467-9450.2009.00740.x
   Kuchinsky SE, 2013, PSYCHOPHYSIOLOGY, V50, P23, DOI 10.1111/j.1469-8986.2012.01477.x
   Kwon BJ, 2001, J ACOUST SOC AM, V110, P1130, DOI 10.1121/1.1384909
   Lee JH, 2012, J ACOUST SOC AM, V132, P1700, DOI 10.1121/1.4740482
   Lin FR, 2011, ARCH INTERN MED, V171, P1851, DOI 10.1001/archinternmed.2011.506
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Loughrey DG, 2018, JAMA OTOLARYNGOL, V144, P115, DOI 10.1001/jamaoto.2017.2513
   Luke SG, 2017, BEHAV RES METHODS, V49, P1494, DOI 10.3758/s13428-016-0809-y
   Mackersie CL, 2011, J ACOUST SOC AM, V130, P1006, DOI 10.1121/1.3605548
   Mackersie CL, 2003, J SPEECH LANG HEAR R, V46, P912, DOI 10.1044/1092-4388(2003/071)
   Mackersie CL, 2001, J SPEECH LANG HEAR R, V44, P19, DOI 10.1044/1092-4388(2001/002)
   Marrone N, 2008, J ACOUST SOC AM, V124, P3064, DOI 10.1121/1.2980441
   McDowd J. M., 2000, HDB AGING COGNITION, P221
   Mehraei G, 2014, J ACOUST SOC AM, V136, P301, DOI 10.1121/1.4881918
   MOORE BCJ, 1992, BRIT J AUDIOL, V26, P229, DOI 10.3109/03005369209076641
   Moore BCJ, 2006, HEARING RES, V222, P16, DOI 10.1016/j.heares.2006.08.007
   Moore BCJ, 2016, ADV EXP MED BIOL, V894, P1, DOI 10.1007/978-3-319-25474-6_1
   Nelson PB, 1997, J SPEECH LANG HEAR R, V40, P1387, DOI 10.1044/jslhr.4006.1387
   Ng EHN, 2013, INT J AUDIOL, V52, P433, DOI 10.3109/14992027.2013.776181
   Norrix LW, 2015, AM J AUDIOL, V24, P487, DOI 10.1044/2015_AJA-15-0031
   Oxenham Andrew J, 2008, Trends Amplif, V12, P316, DOI 10.1177/1084713808325881
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   Patel A. D., 2010, 5 INT C SPEECH PROS
   Peelle JE, 2011, J NEUROSCI, V31, P12638, DOI 10.1523/JNEUROSCI.2559-11.2011
   Pichora-Fuller K, 2007, P INT S AUD AUD RES, V1, P291
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   PISONI DB, 1979, BRAIN BEHAV EVOLUT, V16, P330, DOI 10.1159/000121875
   Ponsot E., 2020, BIORXIV, DOI [10.1101/2020.01.03.894667, DOI 10.1101/2020.01.03.894667]
   Presacco A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0213899
   Prusa Z, 2017, IEEE-ACM T AUDIO SPE, V25, P1154, DOI 10.1109/TASLP.2017.2678166
   RANA SVS, 1980, TOXICOL LETT, V6, P163, DOI 10.1016/0378-4274(80)90185-X
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   Rose MM, 1997, J ACOUST SOC AM, V102, P1768, DOI 10.1121/1.420108
   Rossi-Katz J, 2009, J SPEECH LANG HEAR R, V52, P435, DOI 10.1044/1092-4388(2008/07-0243)
   Salthouse TA, 2000, BIOL PSYCHOL, V54, P35, DOI 10.1016/S0301-0511(00)00052-1
   Schneider BA, 2007, J AM ACAD AUDIOL, V18, P559, DOI 10.3766/jaaa.18.7.4
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Shen Y, 2014, J SPEECH LANG HEAR R, V57, P2280, DOI 10.1044/2014_JSLHR-H-13-0276
   Shinn-Cunningham Barbara G, 2008, Trends Amplif, V12, P283, DOI 10.1177/1084713808325306
   Singh NC, 2003, J ACOUST SOC AM, V114, P3394, DOI 10.1121/1.1624067
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Srinivasan NK, 2016, J ACOUST SOC AM, V140, pEL73, DOI 10.1121/1.4954386
   Stokes RC, 2019, PSYCHON B REV, V26, P1354, DOI 10.3758/s13423-019-01580-2
   Strouse A, 2000, BRIT J AUDIOL, V34, P141, DOI 10.3109/03005364000000124
   Stuart A, 1996, EAR HEARING, V17, P478, DOI 10.1097/00003446-199612000-00004
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Summers V, 1998, J SPEECH LANG HEAR R, V41, P1294, DOI 10.1044/jslhr.4106.1294
   TAKAHASHI GA, 1992, J SPEECH HEAR RES, V35, P1410, DOI 10.1044/jshr.3506.1410
   Tun PA, 2002, PSYCHOL AGING, V17, P453, DOI 10.1037//0882-7974.17.3.453
   Tun PA, 1999, J GERONTOL B-PSYCHOL, V54, pP317, DOI 10.1093/geronb/54B.5.P317
   TURNER CW, 1995, J ACOUST SOC AM, V97, P2568, DOI 10.1121/1.411911
   Vaden KI, 2016, EXP AGING RES, V42, P86, DOI 10.1080/0361073X.2016.1108784
   Venezia JH, 2019, J SPEECH LANG HEAR R, V62, P1051, DOI 10.1044/2018_JSLHR-H-18-0045
   Venezia JH, 2019, NEUROIMAGE, V186, P647, DOI 10.1016/j.neuroimage.2018.11.049
   Venezia JH, 2016, J ACOUST SOC AM, V140, P1072, DOI 10.1121/1.4960544
   Wayne RV, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00049
   WILSON RH, 1969, J ACOUST SOC AM, V46, P998, DOI 10.1121/1.1911820
NR 105
TC 0
Z9 0
U1 4
U2 4
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD JUL
PY 2020
VL 63
IS 7
BP 2141
EP 2161
DI 10.1044/2020_JSLHR-19-00324
PG 21
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA MR0JC
UT WOS:000553279000008
PM 32603618
DA 2021-02-24
ER

PT J
AU Wang, JR
   Zhu, YM
   Chen, Y
   Mamat, A
   Yu, M
   Zhang, J
   Dang, JW
AF Wang, Jianrong
   Zhu, Yumeng
   Chen, Yu
   Mamat, Abdilbar
   Yu, Mei
   Zhang, Ju
   Dang, Jianwu
TI An Eye-Tracking Study on Audiovisual Speech Perception Strategies
   Adopted by Normal-Hearing and Deaf Adults Under Different Language
   Familiarities
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID VISUAL-ATTENTION; LEXICAL TONES; COCHLEAR; INFORMATION; CHILDREN;
   SPEAKER; MOUTH; CUES
AB Purpose: The primary purpose of this study was to explore the audiovisual speech perception strategies.80.23.47 adopted by normal-hearing and deaf people in processing familiar and unfamiliar languages. Our primary hypothesis was that they would adopt different perception strategies due to different sensory experiences at an early age, limitations of the physical device, and the developmental gap of language, and others.
   Method: Thirty normal-hearing adults and 33 prelingually deaf adults participated in the study. They were asked to perform judgment and listening tasks while watching videos of a Uygur-Mandarin bilingual speaker in a familiar language (Standard Chinese) or an unfamiliar language (Modern Uygur) while their eye movements were recorded by eye-tracking technology.
   Results: Task had a slight influence on the distribution of selective attention, whereas subject and language had significant influences. To be specific, the normal-hearing and the d10eaf participants mainly gazed at the speaker's eyes and mouth, respectively, in the experiment; moreover, while the normal-hearing participants had to stare longer at the speaker's mouth when they confronted with the unfamiliar language Modern Uygur, the deaf participant did not change their attention allocation pattern when perceiving the two languages.
   Conclusions: Normal-hearing and deaf adults adopt different audiovisual speech perception strategies: Normalhearing adults mainly look at the eyes, and deaf adults mainly look at the mouth. Additionally, language and task can also modulate the speech perception strategy.
C1 [Wang, Jianrong; Zhu, Yumeng; Chen, Yu; Yu, Mei; Zhang, Ju; Dang, Jianwu] Tianjin Key Lab Cognit Comp & Applicat, Tianjin, Peoples R China.
   [Wang, Jianrong; Zhu, Yumeng; Yu, Mei; Zhang, Ju; Dang, Jianwu] Tianjin Univ, Coll Intelligence & Comp, Tianjin, Peoples R China.
   [Chen, Yu] Tianjin Univ Technol, Tech Coll Deaf, Tianjin, Peoples R China.
   [Mamat, Abdilbar] Hotan Teachers Coll, Inst Phys Educ, Hotan, Xinjiang, Peoples R China.
RP Chen, Y (corresponding author), Tianjin Key Lab Cognit Comp & Applicat, Tianjin, Peoples R China.; Chen, Y (corresponding author), Tianjin Univ Technol, Tech Coll Deaf, Tianjin, Peoples R China.
EM chenyu@tjut.edu.cn
FU National Social Science Fund of P. R. China "A study on the speech
   behavior and its neural mechanism of prelingually deaf adults" Grant
   [17BYY166]
FX This work was sponsored by the National Social Science Fund of P. R.
   China "A study on the speech behavior and its neural mechanism of
   prelingually deaf adults" Grant 17BYY166, 2017, awarded to Yu Chen. We
   also thank Tianjin University of Technology and all the students who
   participated in this research.
CR Argyle M., 1976, GAZE MUTUAL GAZE
   Barenholtz E, 2016, COGNITION, V147, P100, DOI 10.1016/j.cognition.2015.11.013
   Barone P, 2016, CORTEX, V83, P259, DOI 10.1016/j.cortex.2016.08.005
   Barone P, 2011, SPRINGER HANDB AUDIT, V39, P365, DOI 10.1007/978-1-4419-9434-9_15
   Burnham D, 2015, APPL PSYCHOLINGUIST, V36, P1459, DOI 10.1017/S0142716414000496
   Chen TH, 2008, J ACOUST SOC AM, V123, P2356, DOI 10.1121/1.2839004
   Chen Y., 2016, AS PAC SIGN INF PROC, DOI 10.1109/APSIPA.2016.7820806
   Chen Y., 2017, 2017 AS PAC SIGN INF, DOI 10.1109/APSIPA.2017.8282101
   Chen YC, 2009, J ACOUST SOC AM, V126, P858, DOI 10.1121/1.3158823
   Drijvers L, 2019, COGNITIVE SCI, V43, DOI 10.1111/cogs.12789
   Emery NJ, 2000, NEUROSCI BIOBEHAV R, V24, P581, DOI 10.1016/S0149-7634(00)00025-7
   Frischen A, 2007, PSYCHOL BULL, V133, P694, DOI 10.1037/0033-2909.133.4.694
   Fuster-Duran A., 1996, SPEECHREADING HUMANS, P135, DOI DOI 10.1007/978-3-662-13015-5_9
   Hardison DM, 1996, LANG LEARN, V46, P3, DOI 10.1111/j.1467-1770.1996.tb00640.x
   Haspelmath M., 2005, WORLD ATLAS LANGUAGE
   Hazan V, 2010, SPEECH COMMUN, V52, P996, DOI 10.1016/j.specom.2010.05.003
   Horn DL, 2005, EAR HEARING, V26, P389, DOI 10.1097/00003446-200508000-00003
   Hua Z., 2002, MULTILINGUAL MATTERS, V3, DOI 10.21832/9781853595899.
   Huyse A, 2013, EAR HEARING, V34, P110, DOI 10.1097/AUD.0b013e3182670993
   Krol ME, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194491
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Leybaert J., 2007, ENFANCE, V59, P245, DOI [10.3917/enf.593.0245, DOI 10.3917/ENF.593.0245]
   LI CN, 1977, J CHILD LANG, V4, P185, DOI 10.1017/S0305000900001598
   Liu Shaofeng, 2019, J Otol, V14, P57, DOI 10.1016/j.joto.2019.01.006
   Lusk LG, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00052
   Mastrantuono E, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01044
   Mixdorff H., 2005, P AUD VIS SPEECH PRO, P3
   Mixdorff H., 2005, P 9 EUR C SPEECH COM, P405
   Murray MM, 2016, TRENDS NEUROSCI, V39, P567, DOI 10.1016/j.tins.2016.05.003
   Navarra J, 2007, PSYCHOL RES-PSYCH FO, V71, P4, DOI 10.1007/s00426-005-0031-5
   Peng SC, 2017, J SPEECH LANG HEAR R, V60, P1223, DOI 10.1044/2016_JSLHR-S-16-0048
   Pimperton H, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00106
   Prieur J, 2020, BIOL REV, V95, P531, DOI 10.1111/brv.12576
   Ronnberg J., 1995, COMPENSATING PSYCHOL, P251
   Rossano F., 2013, HDB CONVERSATION ANA, P308, DOI DOI 10.1002/9781118325001.CH15
   Rouger J, 2007, P NATL ACAD SCI USA, V104, P7295, DOI 10.1073/pnas.0609419104
   Rouger J, 2008, BRAIN RES, V1188, P87, DOI 10.1016/j.brainres.2007.10.049
   Schurgin MW, 2014, J VISION, V14, DOI 10.1167/14.13.14
   SEKIYAMA K, 1993, J PHONETICS, V21, P427, DOI 10.1016/S0095-4470(19)30229-3
   Sekiyama K, 1997, PERCEPT PSYCHOPHYS, V59, P73, DOI 10.3758/BF03206849
   Sekiyama K, 2008, DEVELOPMENTAL SCI, V11, P306, DOI 10.1111/j.1467-7687.2008.00677.x
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Svirsky MA, 2004, AUDIOL NEURO-OTOL, V9, P224, DOI 10.1159/000078392
   Tang P, 2019, J SPEECH LANG HEAR R, V62, P1309, DOI 10.1044/2018_JSLHR-S-18-0304
   Vo MLH, 2012, J VISION, V12, DOI 10.1167/12.13.3
   Wang Y., 2007, P INT C AUD VIS SPEE
   Wang Y, 2008, J ACOUST SOC AM, V124, P1716, DOI 10.1121/1.2956483
   Wang Y, 2009, J PHONETICS, V37, P344, DOI 10.1016/j.wocn.2009.04.002
   Wei CG, 2004, HEARING RES, V197, P87, DOI 10.1016/j.heares.2004.06.002
   Wong PS, 2005, J SPEECH LANG HEAR R, V48, P1065, DOI 10.1044/1092-4388(2005/074)
   Worster E, 2018, LANG LEARN, V68, P159, DOI 10.1111/lang.12264
NR 51
TC 1
Z9 1
U1 1
U2 2
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD JUL
PY 2020
VL 63
IS 7
BP 2245
EP 2254
DI 10.1044/2020_JSLHR-19-00223
PG 10
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA MR0JC
UT WOS:000553279000015
PM 32579867
DA 2021-02-24
ER

PT J
AU Cabrera, L
   Gervain, J
AF Cabrera, Laurianne
   Gervain, Judit
TI Speech perception at birth: The brain encodes fast and slow temporal
   information
SO SCIENCE ADVANCES
LA English
DT Article
ID AUDITORY-CORTEX; FINE-STRUCTURE; LANGUAGE-ACQUISITION; MISMATCH
   NEGATIVITY; INFANTS; ENVELOPE; DISCRIMINATION; CUES; REPRESENTATION;
   RECOGNITION
AB Speech perception is constrained by auditory processing. Although at birth infants have an immature auditory system and limited language experience, they show remarkable speech perception skills. To assess neonates' ability to process the complex acoustic cues of speech, we combined near-infrared spectroscopy (NIRS) and electroencephalography (EEG) to measure brain responses to syllables differing in consonants. The syllables were presented in three conditions preserving (i) original temporal modulations of speech [both amplitude modulation (AM) and frequency modulation (FM)], (ii) both fast and slow AM, but not FM, or (iii) only the slowest AM (<8 Hz). EEG responses indicate that neonates can encode consonants in all conditions, even without the fast temporal modulations, similarly to adults. Yet, the fast and slow AM activate different neural areas, as shown by NIRS. Thus, the immature human brain is already able to decompose the acoustic components of speech, laying the foundations of language learning.
C1 [Cabrera, Laurianne; Gervain, Judit] Univ Paris, Integrat Neurosci & Cognit Ctr, CNRS, UFR Biomed, 45 Rue St Peres, F-75006 Paris, France.
   [Gervain, Judit] Univ Padua, 8 Via Venezia,8, I-35131 Padua, Italy.
RP Cabrera, L (corresponding author), Univ Paris, Integrat Neurosci & Cognit Ctr, CNRS, UFR Biomed, 45 Rue St Peres, F-75006 Paris, France.
EM laurianne.cabrera@parisdescartes.fr
OI Gervain, Judit/0000-0002-2125-6369
FU Emergence(s) Programme Grant from the City of Paris; Human Frontiers
   Science Program Young Investigator GrantHuman Frontier Science Program
   [RGY-0073-2014]; ERC Consolidator Grant "BabyRhythm" [773202]; ANRFrench
   National Research Agency (ANR) [17-CE28-008]
FX This work was supported by an Emergence(s) Programme Grant from the City
   of Paris, a Human Frontiers Science Program Young Investigator Grant
   (RGY-0073-2014), as well as the ERC Consolidator Grant "BabyRhythm" (no.
   773202) to J.G. L.C. is currently supported by ANR grant 17-CE28-008.
CR Abboub N, 2016, BRAIN LANG, V162, P46, DOI 10.1016/j.bandl.2016.08.002
   Abdala C, 2003, J ACOUST SOC AM, V114, P3239, DOI 10.1121/1.1625930
   Benavides-Varela S, 2017, DEV COGN NEUROS-NETH, V25, P198, DOI 10.1016/j.dcn.2017.03.003
   BERTONCINI J, 1987, J ACOUST SOC AM, V82, P31, DOI 10.1121/1.395570
   Bertoncini J, 2011, J ACOUST SOC AM, V129, P2761, DOI 10.1121/1.3571424
   Bouchon C, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140160
   Cabrera L, 2017, EAR HEARING, V38, P497, DOI 10.1097/AUD.0000000000000422
   Cabrera L, 2015, J SPEECH LANG HEAR R, V58, P1033, DOI 10.1044/2015_JSLHR-H-14-0121
   Cabrera L, 2013, J SPEECH LANG HEAR R, V56, P1733, DOI 10.1044/1092-4388(2013/12-0169)
   Dehaene-Lambertz G, 2001, NEUROREPORT, V12, P3155, DOI 10.1097/00001756-200110080-00034
   Dehaene-Lambertz G, 2000, J COGNITIVE NEUROSCI, V12, P449, DOI 10.1162/089892900562264
   Dehaene-Lambertz G, 1998, NEUROREPORT, V9, P1885, DOI 10.1097/00001756-199806010-00040
   Draganova R, 2018, HEARING RES, V363, P70, DOI 10.1016/j.heares.2018.03.005
   DRULLMAN R, 1995, J ACOUST SOC AM, V97, P585, DOI 10.1121/1.413112
   Gervain Judit, 2008, Proc Natl Acad Sci U S A, V105, P14222, DOI 10.1073/pnas.0806530105
   Giraud AL, 2000, J NEUROPHYSIOL, V84, P1588
   Gnansia D, 2009, J ACOUST SOC AM, V125, P4023, DOI 10.1121/1.3126344
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Liegeois-Chauvel C, 2004, CEREB CORTEX, V14, P731, DOI 10.1093/cercor/bhh033
   Mahmoudzadeh M, 2013, P NATL ACAD SCI USA, V110, P4846, DOI 10.1073/pnas.1212220110
   Martynova O, 2003, NEUROSCI LETT, V340, P75, DOI 10.1016/S0304-3940(02)01401-5
   May L, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00222
   MEHLER J, 1988, COGNITION, V29, P143, DOI 10.1016/0010-0277(88)90035-2
   MOON C, 1993, INFANT BEHAV DEV, V16, P495, DOI 10.1016/0163-6383(93)80007-U
   Moore JK, 2002, ANN OTO RHINOL LARYN, V111, P7
   Morr ML, 2002, EAR HEARING, V23, P118, DOI 10.1097/00003446-200204000-00005
   Mueller JL, 2012, P NATL ACAD SCI USA, V109, P15953, DOI 10.1073/pnas.1204319109
   Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058
   Poeppel D, 2001, COGNITIVE SCI, V25, P679, DOI 10.1016/S0364-0213(01)00050-7
   Poeppel D, 2014, CURR OPIN NEUROBIOL, V28, P142, DOI 10.1016/j.conb.2014.07.005
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Sato H, 2012, HUM BRAIN MAPP, V33, P2092, DOI 10.1002/hbm.21350
   Scott SK, 2006, J ACOUST SOC AM, V120, P1075, DOI 10.1121/1.2216725
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Telkemeyer S, 2009, J NEUROSCI, V29, P14726, DOI 10.1523/JNEUROSCI.1246-09.2009
   Varnet L, 2017, J ACOUST SOC AM, V142, P1976, DOI 10.1121/1.5006179
   Warner-Czyz AD, 2014, J ACOUST SOC AM, V135, P3017, DOI 10.1121/1.4870700
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Xu L, 2003, J ACOUST SOC AM, V114, P3024, DOI 10.1121/1.1623786
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
   Zeng FG, 2005, P NATL ACAD SCI USA, V102, P2293, DOI 10.1073/pnas.0406460102
NR 43
TC 0
Z9 0
U1 3
U2 3
PU AMER ASSOC ADVANCEMENT SCIENCE
PI WASHINGTON
PA 1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA
SN 2375-2548
J9 SCI ADV
JI Sci. Adv.
PD JUL
PY 2020
VL 6
IS 30
AR eaba7830
DI 10.1126/sciadv.aba7830
PG 9
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA MP5EV
UT WOS:000552228100028
PM 32832669
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Kim, D
   Clayards, M
   Kong, EJ
AF Kim, Donghyun
   Clayards, Meghan
   Kong, Eun Jong
TI Individual differences in perceptual adaptation to unfamiliar phonetic
   categories
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Speech perception; Perceptual learning; Cue weighting; Individual
   differences; Categorization gradiency; Cognitive abilities
ID SPEECH-PERCEPTION; SELECTIVE ATTENTION; INHIBITORY SKILL; RAPID
   ADAPTATION; WORKING-MEMORY; CUE WEIGHTS; RECOGNITION; EXPERIENCE;
   DURATION; ACCENT
AB The present study examines whether listeners flexibly adapt to unfamiliar speech patterns such as those encountered in foreign-accented English vowels, where the relative informativeness of primary (spectral quality) and secondary (duration) cues tends to be reversed (e.g., spectrally similar but exaggerated duration differences between bet and bat). This study further tests whether listeners' adaptive strategies are related to individual differences in phoneme categorization gradiency and cognitive abilities. Native English listeners (N = 36) listened to a continuum of vowels from /epsilon/ to /ae/ (as in head and had) varying in spectral and duration values to complete a perceptual adaptation task and a visual analog scaling (VAS) task. Participants also completed cognitive tasks examining executive function capacities. Results showed that listeners mostly used spectral quality to signal vowel category at baseline, but flexibly adapted by up-weighting reliance on duration when spectral quality became no longer diagnostic. In the VAS task, some listeners made more categorical responses while others made more gradient responses in vowel categorization, but these differences were not linked to their adaptive patterns. Results of cognitive tasks revealed that individual differences in inhibitory control correlated, to some degree, with the amount of adaptation. Together, these findings suggest that listeners flexibly adapt to unfamiliar speech categories using distributional information in the input and individual differences in cognitive abilities may influence their adaptability. (C) 2020 Elsevier Ltd. All rights reserved.
C1 [Kim, Donghyun] Univ Exeter, Dept Psychol, Exeter, Devon, England.
   [Clayards, Meghan] McGill Univ, Dept Linguist, Montreal, PQ, Canada.
   [Clayards, Meghan] McGill Univ, Sch Commun Sci & Disorders, Montreal, PQ, Canada.
   [Kong, Eun Jong] Korea Aerosp Univ, Dept English, Gyeonggido, South Korea.
RP Kim, D (corresponding author), Univ Exeter, Dept Psychol, Exeter, Devon, England.
EM d.kim2@exeter.ac.uk
OI Kim, Donghyun/0000-0003-1972-2508
FU Social Sciences and Humanities Research Council of CanadaSocial Sciences
   and Humanities Research Council of Canada (SSHRC) [435-2016-0747]
FX This work was supported by Social Sciences and Humanities Research
   Council of Canada [grant number 435-2016-0747] to Meghan Clayards. We
   thank Jessamyn Schertz, an anonymous reviewer, and the editor (Natasha
   Warner) for their helpful comments and suggestions. We also thank Morgan
   Sonderegger for helpful comments on an earlier version of this
   manuscript.
CR Adank P, 2010, PSYCHOL AGING, V25, P736, DOI 10.1037/a0020054
   Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Amer T, 2018, MEMORY, V26, P251, DOI 10.1080/09658211.2017.1347187
   Amer T, 2016, TRENDS COGN SCI, V20, P905, DOI 10.1016/j.tics.2016.10.002
   Azadpour M, 2015, J ACOUST SOC AM, V138, P44, DOI 10.1121/1.4922226
   Baddeley A, 2003, NAT REV NEUROSCI, V4, P829, DOI 10.1038/nrn1201
   Baese-Berk MM, 2013, J ACOUST SOC AM, V133, pEL174, DOI 10.1121/1.4789864
   Banks B, 2015, J ACOUST SOC AM, V137, P2015, DOI 10.1121/1.4916265
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beddor PS, 2018, LANGUAGE, V94, P931, DOI 10.1353/lan.2018.0051
   Bender AD, 2016, ATTEN PERCEPT PSYCHO, V78, P2420, DOI 10.3758/s13414-016-1158-8
   Bent T, 2016, J ACOUST SOC AM, V140, P3775, DOI 10.1121/1.4966677
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Cebrian J, 2006, J PHONETICS, V34, P372, DOI 10.1016/j.wocn.2005.08.003
   Chladkova K, 2017, J EXP PSYCHOL HUMAN, V43, P414, DOI 10.1037/xhp0000333
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Clayards M, 2018, J ACOUST SOC AM, V144, pEL172, DOI 10.1121/1.5052025
   Cohen R. A., 2014, NEUROPSYCHOLOGY ATTE, DOI [10.1007/978-0-387-72639-7, DOI 10.1007/978-0-387-72639-7]
   Colby S, 2018, J SPEECH LANG HEAR R, V61, P1, DOI 10.1044/2018_JSLHR-S-17-0392
   Conners CK, 2003, J ABNORM CHILD PSYCH, V31, P555, DOI 10.1023/A:1025457300409
   Darcy I, 2016, LANG LEARN, V66, P741, DOI 10.1111/lang.12161
   Diamond A, 2013, ANNU REV PSYCHOL, V64, P135, DOI 10.1146/annurev-psych-113011-143750
   Escudero P, 2009, J PHONETICS, V37, P452, DOI 10.1016/j.wocn.2009.07.006
   Ferguson SH, 2007, J SPEECH LANG HEAR R, V50, P1241, DOI 10.1044/1092-4388(2007/087)
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   Fox CJ, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0063885
   Francis AL, 2002, J EXP PSYCHOL HUMAN, V28, P349, DOI 10.1037//0096-1523.28.2.349
   Francis AL, 2000, PERCEPT PSYCHOPHYS, V62, P1668, DOI 10.3758/BF03212164
   Franken MK, 2017, INTERSPEECH, P655, DOI 10.21437/Interspeech.2017-122
   Friedman NP, 2017, CORTEX, V86, P186, DOI 10.1016/j.cortex.2016.04.023
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Gelman A, 2008, STAT MED, V27, P2865, DOI 10.1002/sim.3107
   Goldstone RL, 1998, ANNU REV PSYCHOL, V49, P585, DOI 10.1146/annurev.psych.49.1.585
   Harmon Z, 2019, COGNITION, V189, P76, DOI 10.1016/j.cognition.2019.03.011
   Hillenbrand JM, 2000, J ACOUST SOC AM, V108, P3013, DOI 10.1121/1.1323463
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Idemaru K, 2014, J EXP PSYCHOL HUMAN, V40, P1009, DOI 10.1037/a0035269
   Idemaru K, 2012, J ACOUST SOC AM, V132, P3950, DOI 10.1121/1.4765076
   Idemaru K, 2011, J EXP PSYCHOL HUMAN, V37, P1939, DOI 10.1037/a0025641
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Janse E, 2012, Q J EXP PSYCHOL, V65, P1563, DOI 10.1080/17470218.2012.658822
   Jongman SR, 2015, Q J EXP PSYCHOL, V68, P710, DOI 10.1080/17470218.2014.964736
   Kapnoula EC, 2017, J EXP PSYCHOL HUMAN, V43, P1594, DOI 10.1037/xhp0000410
   Kawahara H., 2009, P AS PAC SIGN INF PR, P111
   Kim Y. H., 2010, P 6 INT S ACQ 2 LANG
   Kleinschmidt D. F., 2015, P 37 ANN M COGN SCI, P1129
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kondaurova MV, 2010, J PHONETICS, V38, P569, DOI 10.1016/j.wocn.2010.08.003
   Kondaurova MV, 2008, J ACOUST SOC AM, V124, P3959, DOI 10.1121/1.2999341
   Kong E. J., 2011, P 17 INT C PHON SCI
   Kong EJ, 2016, J PHONETICS, V59, P40, DOI 10.1016/j.wocn.2016.08.006
   Kortte Kathleen Bechtold, 2002, Appl Neuropsychol, V9, P106, DOI 10.1207/S15324826AN0902_5
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Lehet M, 2017, COGNITIVE SCI, V41, P885, DOI 10.1111/cogs.12413
   Lev-Ari S, 2014, J PHONETICS, V47, P36, DOI 10.1016/j.wocn.2014.09.001
   Lev-Ari S, 2013, J PHONETICS, V41, P320, DOI 10.1016/j.wocn.2013.06.002
   Liu R, 2015, J EXP PSYCHOL HUMAN, V41, P1783, DOI 10.1037/xhp0000092
   MACLEOD CM, 1991, PSYCHOL BULL, V109, P163, DOI 10.1037/0033-2909.109.2.163
   MASSARO DW, 1983, SPEECH COMMUN, V2, P15, DOI 10.1016/0167-6393(83)90061-4
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001
   McMurray B, 2010, COGNITIVE PSYCHOL, V60, P1, DOI 10.1016/j.cogpsych.2009.06.003
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   Miyake A, 2012, CURR DIR PSYCHOL SCI, V21, P8, DOI 10.1177/0963721411429458
   Miyake Akira, 2000, Seminars in Speech and Language, V21, P169, DOI 10.1055/s-2000-7563
   Mueller ST, 2014, J NEUROSCI METH, V222, P250, DOI 10.1016/j.jneumeth.2013.10.024
   Munson B, 2017, CLIN LINGUIST PHONET, V31, P56, DOI 10.1080/02699206.2016.1233292
   Munson C.M., 2011, THESIS
   Newman RS, 2001, J ACOUST SOC AM, V109, P1181, DOI 10.1121/1.1348009
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Pichora-Fuller MK, 2008, INT J AUDIOL, V47, pS72, DOI 10.1080/14992020802307404
   R Core Team, 2017, R LANG ENV STAT COMP
   Schellinger SK, 2017, CLIN LINGUIST PHONET, V31, P80, DOI 10.1080/02699206.2016.1205665
   Schertz J, 2016, ATTEN PERCEPT PSYCHO, V78, P355, DOI 10.3758/s13414-015-0987-1
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   Schertz J, 2013, J PHONETICS, V41, P249, DOI 10.1016/j.wocn.2013.03.007
   Schneider W., 2002, E PRIME USERS GUIDE
   Schouten B, 2003, SPEECH COMMUN, V41, P71, DOI 10.1016/S0167-6393(02)00094-8
   Schreiber E., 2013, P M ACOUSTICS, V19
   Tamati TN, 2013, J AM ACAD AUDIOL, V24, P616, DOI 10.3766/jaaa.24.7.10
   Theodore RM, 2019, PSYCHON B REV, V26, P985, DOI 10.3758/s13423-018-1551-5
   Toscano JC, 2010, PSYCHOL SCI, V21, P1532, DOI 10.1177/0956797610384142
   Toscano JC, 2010, COGNITIVE SCI, V34, P434, DOI 10.1111/j.1551-6709.2009.01077.x
   Vandierendonck A, 2004, BRIT J PSYCHOL, V95, P57, DOI 10.1348/000712604322779460
   Weeks JC, 2016, PSYCHON B REV, V23, P1559, DOI 10.3758/s13423-016-1003-z
   Wickens CD., 2008, APPL ATTENTION THEOR
   Winn MB, 2013, J SPEECH LANG HEAR R, V56, P1097, DOI 10.1044/1092-4388(2012/12-0086)
   Yu ACL, 2014, J ACOUST SOC AM, V136, P382, DOI 10.1121/1.4883380
NR 91
TC 0
Z9 0
U1 4
U2 4
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD JUL
PY 2020
VL 81
AR 100984
DI 10.1016/j.wocn.2020.100984
PG 16
WC Linguistics; Language & Linguistics
SC Linguistics
GA MO6JQ
UT WOS:000551630100005
DA 2021-02-24
ER

PT J
AU White, L
   Benavides-Varela, S
   Mady, K
AF White, Laurence
   Benavides-Varela, Silvia
   Mady, Katalin
TI Are initial-consonant lengthening and final-vowel lengthening both
   universal word segmentation cues?
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Speech perception; Linguistic universals; Speech segmentation; Speech
   timing; Initial lengthening; Final lengthening
ID LEXICAL PROSODY; PERCEPTION; BOUNDARIES; DURATION; HOMOPHONE; PATTERNS;
   ENGLISH; STRESS; ACCESS
AB Speech segments are lengthened at the onsets and offsets of linguistic constituents. Final-syllable vowel lengthening is proposed to be a language-universal cue to word segmentation, but cross-linguistic investigations of the perception of initial consonant lengthening are lacking. We compared the use of word-initial consonant lengthening and word-final vowel lengthening by native speakers of English, Hungarian and Italian, using an artificial language learning task and varying vowel and consonant durations between subjects within each language group. Word-final vowel lengthening was only exploited for segmentation by English speakers; we interpret its non-universality as potentially due, at least in part, to language-specific functional loads on vowel duration, used for indicating lexical stress in Italian and vowel identity in Hungarian. By contrast, all three language groups used word-initial consonant lengthening to locate word boundaries, but did not benefit from lengthening of vowels in word-initial syllables. If domain-initial consonant timing effects are universal, it may be because they promote two related but separable processing requirements for the listener: (a) word segmentation, boosted by lengthening across the boundary; (b) lexical access, boosted by articulatory strengthening and lengthening of word onsets. (C) 2020 Elsevier Ltd. All rights reserved.
C1 [White, Laurence] Newcastle Univ, Sch Educ Commun & Language Sci, Newcastle Upon Tyne, Tyne & Wear, England.
   [Benavides-Varela, Silvia] Univ Padua, Dept Dev Psychol & Socialisat, Padua, Italy.
   [Mady, Katalin] MTA Res Inst Linguist, Budapest, Hungary.
RP White, L (corresponding author), Newcastle Univ, Speech & Language Sci, Sch Educ Commun & Language Sci, King George VI Bldg, Newcastle Upon Tyne NE1 7RU, Tyne & Wear, England.
EM laurence.white@newcastle.ac.uk
RI Benavides-Varela, Silvia/K-5734-2016; Benavides-Varela,
   Silvia/ABG-7474-2020
OI Benavides-Varela, Silvia/0000-0003-4818-7372; Benavides-Varela,
   Silvia/0000-0003-4818-7372
FU Experimental Psychology Society
FX We gratefully acknowledge the financial support of the Experimental
   Psychology Society for the completion of this research programme, and
   the help of the following researchers in data collection: Anna Kohari
   and Timea Vakula in Budapest; Francesca Burgio in Padua; Michaela Eneva,
   Rhian Gravell, Annabel Snell and Craig Young in Plymouth. We would like
   to thank Clare Press and Uwe Reichel for insightful discussions during
   the preparation of this manuscript and we are grateful to the editor and
   three anonymous reviewers for very constructive comments during its
   revision.
CR BEACH CM, 1991, J MEM LANG, V30, P644, DOI 10.1016/0749-596X(91)90030-N
   Benus S., 2014, COMPLEX VISIBLES OUT, P677
   BERKOVITS R, 1994, LANG SPEECH, V37, P237, DOI 10.1177/002383099403700302
   BERTINETTO PM, 1980, J PHONETICS, V8, P385, DOI 10.1016/S0095-4470(19)31495-0
   Bhatara A, 2013, J ACOUST SOC AM, V134, P3828, DOI 10.1121/1.4823848
   Bion RAH, 2011, LANG SPEECH, V54, P123, DOI 10.1177/0023830910388018
   Cho TH, 2007, J PHONETICS, V35, P210, DOI 10.1016/j.wocn.2006.03.003
   Cho T, 2017, J PHONETICS, V64, P71, DOI 10.1016/j.wocn.2016.12.003
   Chung S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196885
   Content A, 2001, J MEM LANG, V45, P177, DOI 10.1006/jmla.2000.2775
   Cooper W. E., 1980, SYNTAX SPEECH
   CUTLER A, 1986, LANG SPEECH, V29, P201, DOI 10.1177/002383098602900302
   Cutler A., 1987, Computer Speech and Language, V2, P133, DOI 10.1016/0885-2308(87)90004-0
   Cutler A, 1996, SIGNAL TO SYNTAX: BOOTSTRAPPING FROM SPEECH TO GRAMMAR IN EARLY ACQUISITION, P87
   Cutler A, 2001, LANG SPEECH, V44, P171, DOI 10.1177/00238309010440020301
   Cutler A., 1990, PAPERS LAB PHONOLOGY, V1, P208
   D'Imperio Mariapaola, 1999, PHONOLOGY, V16, P1, DOI DOI 10.1017/S0952675799003681
   de la Mora DM, 2013, ATTEN PERCEPT PSYCHO, V75, P92, DOI 10.3758/s13414-012-0371-3
   Dilley L, 1996, J PHONETICS, V24, P423, DOI 10.1006/jpho.1996.0023
   DImperio M., 2003, PAPERS LAB PHONOLOGY, VVI, P130
   Dingemanse M, 2015, TRENDS COGN SCI, V19, P603, DOI 10.1016/j.tics.2015.07.013
   Dutoit T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1393, DOI 10.1109/ICSLP.1996.607874
   Elordieta Gorka, 2014, PROSODIC TYPOLOGY, P405, DOI [10.1093/acprof:oso/9780199567300.003.0014, DOI 10.1093/ACPROF:OSO/9780199567300.003.0014]
   Farnetani E., 1996, P 1 ESCA WORKSH SPEE, P9
   Fery C., 2011, INTONATIONAL PHRASIN, P11, DOI DOI 10.1075/HSM.10.03FER
   FLASH T, 1985, J NEUROSCI, V5, P1688, DOI 10.1523/jneurosci.05-07-01688.1985
   Fletcher Janet, 2010, HDB PHONETIC SCI, P521, DOI [10.1002/9781444317251.ch15, DOI 10.1002/9781444317251.CH15, 10.1002/9781444317251.ch15.]
   Fonagy I., 1958, NYELVTUDOMANYI ERTEK, V18, P1
   Fougeron C, 1997, J ACOUST SOC AM, V101, P3728, DOI 10.1121/1.418332
   FOURAKIS M, 1988, LANG SPEECH, V31, P283, DOI 10.1177/002383098803100304
   Frost RLA, 2017, J EXP PSYCHOL HUMAN, V43, P466, DOI 10.1037/xhp0000325
   Giegerich Heinz J., 1992, ENGLISH PHONOLOGY IN
   Gout A, 2004, J MEM LANG, V51, P548, DOI 10.1016/j.jml.2004.07.002
   GOW DW, 1995, J EXP PSYCHOL HUMAN, V21, P344, DOI 10.1037/0096-1523.21.2.344
   GUSSENHOVEN C, 1992, J PHONETICS, V20, P283, DOI 10.1016/S0095-4470(19)30636-9
   Gussenhoven C., 2002, 1 INT C SPEECH PROS, P7
   Gussenhoven C, 2016, TOP COGN SCI, V8, P425, DOI 10.1111/tops.12197
   Hall KC, 2018, LINGUIST VANGUARD, V4, DOI 10.1515/lingvan-2017-0027
   Hay JSF, 2007, PERCEPT PSYCHOPHYS, V69, P113, DOI 10.3758/BF03194458
   Hinton VA, 1996, J PHONETICS, V24, P337, DOI 10.1006/jpho.1996.0018
   Hockey B. A., 1999, P 14 INT C PHON SCI, P313
   HOGAN N, 1984, J NEUROSCI, V4, P2745
   HOOPER JB, 1972, LANGUAGE, V48, P525, DOI 10.2307/412031
   Houlihan K., 1975, THESIS
   Iversen JR, 2008, J ACOUST SOC AM, V124, P2263, DOI 10.1121/1.2973189
   JUSCZYK PW, 1995, COGNITIVE PSYCHOL, V29, P1, DOI 10.1006/cogp.1995.1010
   Keating P., 2003, PAPERS LAB PHONOLOGY, P143, DOI DOI 10.1121/1.380986
   Kim S, 2012, STUD SECOND LANG ACQ, V34, P415, DOI 10.1017/S0272263112000137
   Kim S, 2012, J PHONETICS, V40, P443, DOI 10.1016/j.wocn.2012.02.005
   Klatt D.H., 1975, J PHONETICS, V3, P129
   KLATT DH, 1976, J ACOUST SOC AM, V59, P1208, DOI 10.1121/1.380986
   MARSLENWILSON WD, 1992, Q J EXP PSYCHOL-A, V45, P73, DOI 10.1080/14640749208401316
   Mattys SL, 2005, J EXP PSYCHOL GEN, V134, P477, DOI 10.1037/0096-3445.134.4.477
   Mattys SL, 2001, J EXP PSYCHOL HUMAN, V27, P644, DOI 10.1037//0096-1523.27.3.644
   McCarthy John J., 1994, NELS, V24, P333, DOI DOI 10.7282/T3Z03663
   Mitterer H, 2016, J PHONETICS, V54, P68, DOI 10.1016/j.wocn.2015.09.002
   Molnar M, 2016, COGNITION, V152, P150, DOI 10.1016/j.cognition.2016.03.023
   MOON SJ, 1994, J ACOUST SOC AM, V96, P40, DOI 10.1121/1.410492
   MORTON J, 1976, PSYCHOL REV, V83, P405, DOI 10.1037/0033-295X.83.5.405
   NELSON WL, 1983, BIOL CYBERN, V46, P135, DOI 10.1007/BF00339982
   Nespor M, 2008, LINGUE LINGUAGGIO, V7, P139, DOI 10.1418/28093
   Nespor M, 2007, STUD GENERAT GRAMM, V28, P1
   Newman RS, 2011, J MEM LANG, V64, P460, DOI 10.1016/j.jml.2010.11.004
   OLLER DK, 1973, J ACOUST SOC AM, V54, P1235, DOI 10.1121/1.1914393
   Ordin M, 2017, MEM COGNITION, V45, P863, DOI 10.3758/s13421-017-0700-9
   Pena M, 2011, J EXP PSYCHOL LEARN, V37, P1199, DOI 10.1037/a0023944
   Peperkamp S, 2002, PHONOL PHON, V4-1, P203
   PRICE PJ, 1991, J ACOUST SOC AM, V90, P2956, DOI 10.1121/1.401770
   QUENE H, 1993, J ACOUST SOC AM, V94, P2027, DOI 10.1121/1.407504
   Rogers D., 2004, J INT PHON ASSOC, V34, P117, DOI DOI 10.1017/S0025100304001628
   Saffran JR, 1996, J MEM LANG, V35, P606, DOI 10.1006/jmla.1996.0032
   Saffran JR, 2002, J MEM LANG, V47, P172, DOI 10.1006/jmla.2001.2839
   Shatzman KB, 2006, PERCEPT PSYCHOPHYS, V68, P1, DOI 10.3758/BF03193651
   Shukla M, 2007, COGNITIVE PSYCHOL, V54, P1, DOI 10.1016/j.cogpsych.2006.04.002
   Steffman J, 2019, J PHONETICS, V74, P114, DOI 10.1016/j.wocn.2019.03.002
   Szalontai A., 2016, P 12 C PHON PHON GER, P215
   Szende T., 1994, J INT PHON ASSOC, V24, P91, DOI [10.1017/S0025100300005090, DOI 10.1017/S0025100300005090]
   Tagliapietra L, 2010, J MEM LANG, V63, P306, DOI 10.1016/j.jml.2010.05.001
   Tyler MD, 2009, J ACOUST SOC AM, V126, P367, DOI 10.1121/1.3129127
   Vaissiere J., 1983, PROSODY MODELS MEASU, P53, DOI [10.1007/978-3-642-69103-45, DOI 10.1007/978-3-642-69103-4_5]
   VAYRA M, 1992, PHONETICA, V49, P48, DOI 10.1159/000261902
   White L., 2002, ENGLISH SPEECH TIMIN
   White L., 2008, P 4 INT C SPEECH PRO, P363
   White L, 2015, J ACOUST SOC AM, V138, P1214, DOI 10.1121/1.4927409
   White L, 2014, SPEECH COMMUN, V63-64, P38, DOI 10.1016/j.specom.2014.04.003
   White Laurence, 2009, PHONETICS PHONOLOGY, P137
   WIGHTMAN CW, 1992, J ACOUST SOC AM, V91, P1707, DOI 10.1121/1.402450
   Woodrow H, 1909, ARCH PSYCHOL, V14, P1
   Zanjani BR, 2015, JUNDISHAPUR J NAT PH, V10
NR 89
TC 0
Z9 0
U1 1
U2 1
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD JUL
PY 2020
VL 81
AR 100982
DI 10.1016/j.wocn.2020.100982
PG 14
WC Linguistics; Language & Linguistics
SC Linguistics
GA MO6JQ
UT WOS:000551630100004
DA 2021-02-24
ER

PT J
AU Nelson, LH
   Anderson, K
   Whicker, J
   Barrett, T
   Munoz, K
   White, K
AF Nelson, Lauri H.
   Anderson, Karen
   Whicker, John
   Barrett, Tyson
   Munoz, Karen
   White, Karl
TI Classroom Listening Experiences of Students Who Are Deaf or Hard of
   Hearing Using Listening Inventory For Education-Revised
SO LANGUAGE SPEECH AND HEARING SERVICES IN SCHOOLS
LA English
DT Article
ID SPEECH-PERCEPTION; CHILDREN; ACOUSTICS; NOISE; SCHOOL; FATIGUE
AB Purpose: This study examined classroom listening experiences reported by students who are deaf or hard of hearing using the Listening Inventory For Education- Revised (LIFE-R).
   Method: Retrospective electronic survey responses from 3,584 school-age participants were analyzed using descriptive statistics to report student perceptions of listening difficulty in various classroom scenarios, including the strategies students used when they did not hear or understand. Stratified data were used to explore potential differences between grades and across degree of hearing loss or type of hearing technology.
   Results: Average student listening appraisal ratings for 15 classroom, school, and social scenarios was 5.7 based on a 10-point Likert scale (0 = difficult, 10 = easy), highlighting listening difficulties encountered during the school day. This finding can be considered in context with the average rating of 7.2 reported from a previous study of students with typical hearing using the LIFE-R. The greatest difficulties were reported when trying to listen when other students in the class were making noise and in hearing the comments of other classmates. Average listening difficulty was greater for respondents in Grades 3-6 than those in Grades 7-12. Listening difficulty also generally increased relative to degree of hearing loss. When unable to hear, some students took proactive steps to improve their listening access; some reported they did nothing.
   Conclusions: Students who are deaf or hard of hearing can face challenges in hearing and understanding throughout the school day. A functional tool to evaluate and monitor student experiences, such as the LIFE-R, can provide information to make necessary and effective adjustments to classroom instruction and the listening environment.
C1 [Nelson, Lauri H.; Whicker, John; Barrett, Tyson; Munoz, Karen; White, Karl] Utah State Univ, Logan, UT 84322 USA.
   [Anderson, Karen] Supporting Success Children Hearing Loss, Tampa, FL USA.
RP Nelson, LH (corresponding author), Utah State Univ, Logan, UT 84322 USA.
EM lauri.nelson@usu.edu
RI Whicker, John J./AAL-7539-2020
CR American National Standards Institute, 2010, S12602010 ANSIASA 1
   American Speech-Language-Hearing Association, 2015, CLASSR AC
   American Speech-Language-Hearing Association, 2004, AM NAT STAND CLASSR
   Anderson K. L., 2011, LISTENING INVENTORY
   Anderson KL, 2004, LANG SPEECH HEAR SER, V35, P169, DOI 10.1044/0161-1461(2004/017)
   Bess FH, 1999, VOLTA REV, V101, P1
   Canning D., 2012, ESSEX STUDY OPTIMIZE
   Cole P, 2015, MR. EMERSON'S REVOLUTION, P3, DOI 10.11647/OBP.0065.01
   Collins J., 2013, COMMUNIQUE, V41, P4
   Crandell C. C., 2005, SOUND FIELD AMPLIFIC
   CRANDELL CC, 1994, VOLTA REV, V96, P291
   Dockrell JE, 2004, J ACOUST SOC AM, V115, P2964, DOI 10.1121/1.1652610
   Feilner M., 2016, AUTOMATIC DIRECTIONA
   Hicks CB, 2002, J SPEECH LANG HEAR R, V45, P573, DOI 10.1044/1092-4388(2002/046)
   Hornsby BWY, 2017, AM J AUDIOL, V26, P393, DOI 10.1044/2017_AJA-17-0007
   Iglehart F, 2016, AM J AUDIOL, V25, P100, DOI 10.1044/2016_AJA-15-0064
   Knecht Heather A, 2002, Am J Audiol, V11, P65, DOI 10.1044/1059-0889(2002/009)
   Krijger S, 2018, INT J PEDIATR OTORHI, V107, P62, DOI 10.1016/j.ijporl.2018.01.018
   Larsen JB, 2008, LANG SPEECH HEAR SER, V39, P451, DOI 10.1044/0161-1461(2008/07-0032)
   Leibold LJ, 2013, EAR HEARING, V34, P575, DOI 10.1097/AUD.0b013e3182857742
   McKellin WH, 2011, J SOCIOLING, V15, P65, DOI 10.1111/j.1467-9841.2010.00467.x
   Nelson LH, 2017, INT J AUDIOL, V56, P164, DOI 10.1080/14992027.2016.1244866
   Nelson LH, 2013, LANG SPEECH HEAR SER, V44, P239, DOI 10.1044/0161-1461(2013/12-0038)
   Nelson P., 2010, ASHA LEADER, V15, P16
   Nelson P. B., 2009, J ACOUST SOC AM, V126, P2192, DOI [10.1121/1.3248571, DOI 10.1121/1.3248571]
   Neuman AC, 2010, EAR HEARING, V31, P336, DOI 10.1097/AUD.0b013e3181d3d514
   Schafer EC, 2013, J ED AUDIOLOGY, V19, P58
   Seep B., 2000, CLASSROOM ACOUSTICS
   Shield BM, 2008, J ACOUST SOC AM, V123, P133, DOI 10.1121/1.2812596
   U.S. Department of Education Office of Special Education Programs, 2017, IND DIS ED ACT IDEA
   Vander Ghinst M, 2019, J NEUROSCI, V39, P2938, DOI 10.1523/JNEUROSCI.1732-18.2019
   WOLFE J, 2013, J ED AUDIOL, V19, P65
   Wolfe J., 2016, HEARING J, V69, P14, DOI [10.1097/01, DOI 10.1097/01.HJ.0000503459.97846.5D]
   Yang W, 2009, J ACOUST SOC AM, V125, P922, DOI 10.1121/1.3058900
NR 34
TC 1
Z9 1
U1 3
U2 3
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 0161-1461
EI 1558-9129
J9 LANG SPEECH HEAR SER
JI Lang. Speech Hear. Serv. Sch.
PD JUL
PY 2020
VL 51
IS 3
BP 720
EP 733
DI 10.1044/2020_LSHSS-19-00087
PG 14
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA MO4HM
UT WOS:000551489000015
PM 32392436
DA 2021-02-24
ER

PT J
AU Erkens, J
   Schulte, M
   Vormann, M
   Herrmann, CS
AF Erkens, Jules
   Schulte, Michael
   Vormann, Matthias
   Herrmann, Christoph S.
TI Lacking Effects of Envelope Transcranial Alternating Current Stimulation
   Indicate the Need to Revise Envelope Transcranial Alternating Current
   Stimulation Methods
SO NEUROSCIENCE INSIGHTS
LA English
DT Article
DE Cortical entrainment; speech perception; speech envelope; transcranial
   electric stimulation
ID HUMAN AUDITORY-CORTEX; CORTICAL ENTRAINMENT; NEURAL ENTRAINMENT; PHASE
   ENTRAINMENT; EEG OSCILLATIONS; OLDER-ADULTS; SPEECH; RESPONSES;
   COMPREHENSION; ATTENTION
AB In recent years, several studies have reported beneficial effects of transcranial alternating current stimulation (tACS) in experiments regarding sound and speech perception. A new development in this field is envelope-tACS: The goal of this method is to improve cortical entrainment to the speech signal by stimulating with a waveform based on the speech envelope. One challenge of this stimulation method is timing; the electrical stimulation needs to be phase-aligned with the naturally occurring cortical entrainment to the auditory stimuli. Due to individual differences in anatomy and processing speed, the optimal time-lag between presentation of sound and applying envelope-tACS varies between participants. To better investigate the effects of envelope-tACS, we performed a speech comprehension task with a larger amount of time-lags than previous experiments, as well as an equal amount of sham conditions. No significant difference between optimal stimulation time-lag condition and best sham condition was found. Further investigation of the data revealed a significant difference between the positive and negative half-cycles of the stimulation conditions but not for sham. However, we also found a significant learning effect over the course of the experiment which was of comparable size to the effects of envelope-tACS found in previous auditory tACS studies. In this article, we discuss possible explanations for why our findings did not match up with those of previous studies and the issues that come with researching and developing envelope-tACS.
C1 [Erkens, Jules; Herrmann, Christoph S.] Carl von Ossietzky Univ Oldenburg, European Med Sch, Cluster Excellence Hearing4All, Expt Psychol Lab,Dept Psychol, Ammerlander Heerstr 114-118, D-26131 Oldenburg, Germany.
   [Schulte, Michael; Vormann, Matthias] Horzentrum Oldenburg GmbH, Oldenburg, Germany.
   [Herrmann, Christoph S.] Carl von Ossietzky Univ Oldenburg, Res Ctr Neurosensory Sci, Oldenburg, Germany.
RP Erkens, J (corresponding author), Carl von Ossietzky Univ Oldenburg, European Med Sch, Cluster Excellence Hearing4All, Expt Psychol Lab,Dept Psychol, Ammerlander Heerstr 114-118, D-26131 Oldenburg, Germany.
EM jules.erkens@uni-oldenburg.de
OI Erkens, Jules/0000-0001-5994-5795
FU BMBF grantFederal Ministry of Education & Research (BMBF) [V5IKM035]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This
   research was part of the mEEGaHStim project and funded by the BMBF grant
   (grant no. V5IKM035).
CR Abrams DA, 2008, J NEUROSCI, V28, P3958, DOI 10.1523/JNEUROSCI.0187-08.2008
   Ahn S, 2019, NEUROIMAGE, V186, P126, DOI 10.1016/j.neuroimage.2018.10.056
   Aiken SJ, 2008, EAR HEARING, V29, P139, DOI 10.1097/AUD.0b013e31816453dc
   Antal A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00317
   Asamoah B, 2019, BRAIN STIMUL, V12, P1001, DOI 10.1016/j.brs.2019.03.011
   Asamoah B, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-018-08183-w
   Baltus A, 2018, BRAIN STIMUL, V11, P118, DOI 10.1016/j.brs.2017.10.008
   Baltzell LS, 2016, BRAIN RES, V1644, P203, DOI 10.1016/j.brainres.2016.05.029
   Besle J, 2011, J NEUROSCI, V31, P3176, DOI 10.1523/JNEUROSCI.4518-10.2011
   Brand T, 2002, J ACOUST SOC AM, V111, P2801, DOI 10.1121/1.1479152
   Brunoni AR, 2011, INT J NEUROPSYCHOPH, V14, P1133, DOI 10.1017/S1461145710001690
   Dallmer-Zerbe I, 2020, BRAIN TOPOGR, V33, P191, DOI 10.1007/s10548-020-00752-x
   Datta Abhishek, 2012, Front Psychiatry, V3, P91, DOI 10.3389/fpsyt.2012.00091
   Di Liberto GM, 2017, HEARING RES, V348, P70, DOI 10.1016/j.heares.2017.02.015
   Ding N, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00311
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Ding N, 2012, J NEUROPHYSIOL, V107, P78, DOI 10.1152/jn.00297.2011
   Fitzgibbons PJ, 2001, J ACOUST SOC AM, V109, P2955, DOI 10.1121/1.1371760
   Frohlich F, 2010, NEURON, V67, P129, DOI 10.1016/j.neuron.2010.06.005
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Gordon-Salant S, 2006, J ACOUST SOC AM, V119, P2455, DOI 10.1121/1.2171527
   Heimrath K, 2016, FRONT CELL NEUROSCI, V10, DOI 10.3389/fncel.2016.00053
   Henry MJ, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15801
   Herrmann B, 2013, J NEUROPHYSIOL, V109, P2086, DOI 10.1152/jn.00907.2012
   Herrmann C. S., 2017, CURR BEHAV NEUROSCI, V4, P128, DOI [10.1007/s40473-017-0114-9, DOI 10.1007/S40473-017-0114-9]
   Herrmann CS, 2016, INT J PSYCHOPHYSIOL, V103, P12, DOI 10.1016/j.ijpsycho.2015.02.003
   Herrmann CS, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00279
   Hertrich I, 2012, PSYCHOPHYSIOLOGY, V49, P322, DOI 10.1111/j.1469-8986.2011.01314.x
   Hornsby BWY, 2013, EAR HEARING, V34, P523, DOI 10.1097/AUD.0b013e31828003d8
   Kadir S, 2020, IEEE T NEUR SYS REH, V28, P23, DOI 10.1109/TNSRE.2019.2939671
   Kasten FH, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13417-6
   Kasten FH, 2019, BRAIN TOPOGR, V32, P1013, DOI 10.1007/s10548-019-00727-7
   Kasten FH, 2018, NEUROIMAGE, V179, P134, DOI 10.1016/j.neuroimage.2018.05.068
   Kasten FH, 2016, FRONT HUM NEUROSCI, V10, DOI [10.3389/fnhum.2016.00135, 10.3389/fnhum.2016.00245]
   Keshavarzi M, 2020, NEUROIMAGE, V210, DOI 10.1016/j.neuroimage.2020.116557
   Kochkin S., 2000, HEAR J, V53, P39, DOI [10.1097/00025572-200002000-00004, DOI 10.1097/00025572-200002000-00004]
   Krause B, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00025
   Kubanek J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053398
   Lafon B, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01045-x
   Liu AL, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07233-7
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   McAuley JD, 2006, J EXP PSYCHOL GEN, V135, P348, DOI 10.1037/0096-3445.135.3.348
   Mellin JM, 2018, EUR PSYCHIAT, V51, P25, DOI 10.1016/j.eurpsy.2018.01.004
   Millman RE, 2015, J COGNITIVE NEUROSCI, V27, P533, DOI 10.1162/jocn_a_00719
   Moliadze V, 2019, BRAIN STIMUL, V12, P1464, DOI 10.1016/j.brs.2019.06.021
   Naatanen R, 1999, PSYCHOL BULL, V125, P826, DOI 10.1037/0033-2909.125.6.826
   Nakazono H, 2020, BRAIN STIMUL, V13, P343, DOI 10.1016/j.brs.2019.10.022
   Neuling T, 2012, NEUROIMAGE, V63, P771, DOI 10.1016/j.neuroimage.2012.07.024
   Neuling T, 2017, NEUROIMAGE, V147, P960, DOI 10.1016/j.neuroimage.2016.11.022
   Neuling T, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00161
   Neuling Toralf, 2012, Front Psychiatry, V3, P83
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Peelle JE, 2010, CEREB CORTEX, V20, P773, DOI 10.1093/cercor/bhp142
   Petersen EB, 2017, J NEUROPHYSIOL, V117, P18, DOI 10.1152/jn.00527.2016
   Petersen EB, 2016, INT J AUDIOL, V55, P254, DOI 10.3109/14992027.2015.1125533
   Power AJ, 2012, EUR J NEUROSCI, V35, P1497, DOI 10.1111/j.1460-9568.2012.08060.x
   Priori A, 2015, FRONTIERS CLIN RES T, DOI [10.3389/978-2-88919-287-8., DOI 10.3389/978-2-88919-287-8]
   Riecke L, 2018, ACTA ACUST UNITED AC, V104, P883, DOI 10.3813/AAA.919235
   Riecke L, 2018, CURR BIOL, V28, P161, DOI 10.1016/j.cub.2017.11.033
   Riecke L, 2015, CURR BIOL, V25, P3196, DOI 10.1016/j.cub.2015.10.045
   Riecke L, 2015, BRAIN STIMUL, V8, P777, DOI 10.1016/j.brs.2015.04.004
   Rufener KS, 2016, INT J PSYCHOPHYSIOL, V101, P18, DOI 10.1016/j.ijpsycho.2016.01.002
   Ruhnau P, 2018, BRAIN STIMUL, V11, P241, DOI 10.1016/j.brs.2017.09.015
   Salvari V, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01052
   Sarampalis A, 2009, J SPEECH LANG HEAR R, V52, P1230, DOI 10.1044/1092-4388(2009/08-0111)
   Schneider BA, 2005, PSYCHOL AGING, V20, P261, DOI 10.1037/0882-7974.20.2.261
   Schneider BA, 2002, CAN J EXP PSYCHOL, V56, P139, DOI 10.1037/h0087392
   Schutter DJLG, 2016, NEUROPSYCHOLOGIA, V86, P110, DOI 10.1016/j.neuropsychologia.2016.04.011
   Sejnowski TJ, 2006, J NEUROSCI, V26, P1673, DOI 10.1523/JNEUROSCI.3737-05d.2006
   Stecher HI, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00984
   Stecher HI, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00257
   Steinschneider M, 2013, HEARING RES, V305, P57, DOI 10.1016/j.heares.2013.05.013
   Stephens GJ, 2013, J NEUROPHYSIOL, V110, P2019, DOI 10.1152/jn.00268.2013
   Tavakoli AV, 2017, FRONT CELL NEUROSCI, V11, DOI 10.3389/fncel.2017.00214
   ten Oever S, 2016, FRONT CELL NEUROSCI, V10, DOI 10.3389/fncel.2016.00240
   Thut G, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00170
   Voroslakos M, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-02928-3
   Vosskuhl J, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00211
   Wagner K., 2001, Z AUDIOL, V1, P4
   Wagner S, 2014, J NEURAL ENG, V11, DOI 10.1088/1741-2560/11/1/016002
   Wagner S, 2016, SIAM J APPL MATH, V76, P2154, DOI 10.1137/15M1026481
   Wang XQ, 2003, SPEECH COMMUN, V41, P107, DOI 10.1016/S0167-6393(02)00097-3
   WILLIAMS EJ, 1949, AUST J SCI RES SER A, V2, P149, DOI 10.1071/CH9490149
   Wilsch A, 2018, NEUROIMAGE, V172, P766, DOI 10.1016/j.neuroimage.2018.01.038
   Witkowski M, 2016, NEUROIMAGE, V140, P89, DOI 10.1016/j.neuroimage.2015.10.024
   Wostmann M, 2018, BRAIN STIMUL, V11, P752, DOI 10.1016/j.brs.2018.04.006
   Wostmann M, 2017, LANG COGN NEUROSCI, V32, P855, DOI 10.1080/23273798.2016.1262051
   Zeng FG, 1999, NEUROREPORT, V10, P3429, DOI 10.1097/00001756-199911080-00031
   Zoefel B, 2020, J COGNITIVE NEUROSCI, V32, P226, DOI 10.1162/jocn_a_01490
   Zoefel B, 2018, CURR BIOL, V28, P401, DOI 10.1016/j.cub.2017.11.071
   Zoefel B, 2016, NEUROIMAGE, V124, P16, DOI 10.1016/j.neuroimage.2015.08.054
NR 92
TC 1
Z9 1
U1 1
U2 1
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
EI 2633-1055
J9 NEUROSCI INSIGHTS
JI Neurosci. Insights
PD JUL
PY 2020
VL 15
AR 2633105520936623
DI 10.1177/2633105520936623
PG 11
WC Neurosciences
SC Neurosciences & Neurology
GA MP1SN
UT WOS:000551991400001
PM 32685924
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Quam, C
   Cardinal, H
   Gallegos, C
   Bodner, T
AF Quam, Carolyn
   Cardinal, Holly
   Gallegos, Celeste
   Bodner, Todd
TI Sound discrimination and explicit mapping of sounds to meanings in
   preschoolers with and without developmental language disorder
SO INTERNATIONAL JOURNAL OF SPEECH-LANGUAGE PATHOLOGY
LA English
DT Article; Early Access
DE developmental language disorder; specific language impairment;
   developmental disorders; speech perception; preschoolers; language
   development
ID SPEECH-PERCEPTION; WORKING-MEMORY; CHILDREN; IMPAIRMENT; DEFICITS;
   DURATION; QUALITY; CUES
AB Purpose:To investigate links between sound discrimination and explicit sound-meaning mapping by preschoolers with and without developmental language disorder (DLD). Method:We tested 26 children with DLD and 26 age- and gender-matched peers with typical language development (TLD). Inclusion was determined via results of standardised assessments of language and cognitive skills and a hearing screening. Children completed two computerised tasks designed to assess pitch and duration discrimination and explicit mapping of pitch- and duration-contrasting sounds to objects. Result:Children with TLD more successfully mapped pitch categories to meanings than children with DLD. Children with TLD also showed significantly better overall sound discrimination than children with DLD. Sound-discrimination scores were marginally associated with overall sound-meaning mapping in multivariate analyses of covariance (MANCOVAs). Correlation tests indicated significant associations between discrimination and mapping, with moderate to large effect sizes. Thus, significant sound-discrimination differences between the groups may contribute to differences in sound-meaning-mapping accuracy. Conclusion:Children with DLD had more difficulty mapping sound categories to meanings than TLD peers. We discuss possible explanations for this finding and implications for theoretical accounts of the aetiology of DLD.
C1 [Quam, Carolyn] Portland State Univ, Dept Speech & Hearing Sci, POB 751, Portland, OR 97207 USA.
   [Quam, Carolyn; Cardinal, Holly; Gallegos, Celeste] Univ Arizona, Dept Speech Language & Hearing Sci, Tucson, AZ USA.
   [Quam, Carolyn] Univ Arizona, Dept Psychol, Tucson, AZ USA.
   [Bodner, Todd] Portland State Univ, Dept Psychol, Portland, OR 97207 USA.
RP Quam, C (corresponding author), Portland State Univ, Dept Speech & Hearing Sci, POB 751, Portland, OR 97207 USA.
EM cquam@pdx.edu
OI Quam, Carolyn/0000-0003-2607-8597
FU NIH/NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [K99-R00 DC013795]
FX This research was supported by NIH/NIDCD [K99-R00 DC013795] to CQ.
CR Basu M, 2010, DEVELOPMENTAL SCI, V13, P77, DOI 10.1111/j.1467-7687.2009.00849.x
   Beyer T., 2009, FIRST LANG, V29, P208, DOI [10.1177/0142723708101678, DOI 10.1177/0142723708101678]
   Bishop DVM, 2017, J CHILD PSYCHOL PSYC, V58, P1068, DOI 10.1111/jcpp.12721
   Bodner TE, 2018, PSYCHOL METHODS, V23, P125, DOI 10.1037/met0000158
   Boersma Paul, 2008, PRAAT DOING PHONETIC
   Coady JA, 2007, J SPEECH LANG HEAR R, V50, P41, DOI 10.1044/1092-4388(2007/004)
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Creel SC, 2012, J EXP CHILD PSYCHOL, V113, P487, DOI 10.1016/j.jecp.2012.07.007
   Curt Dudley-Marling, 2009, LANG ARTS, V86, P362
   Dailey NS, 2013, J COMMUN DISORD, V46, P330, DOI 10.1016/j.jcomdis.2013.05.001
   Dawson J., 2005, STRUCTURED PHOTOGRAP
   Dietrich C, 2007, P NATL ACAD SCI USA, V104, P16027, DOI 10.1073/pnas.0705270104
   Dunn D. M., 2007, PEABODY PICTURE VOCA
   ELLIOTT LL, 1988, J SPEECH HEAR DISORD, V53, P467, DOI 10.1044/jshd.5304.467
   Evans JL, 2002, J SPEECH LANG HEAR R, V45, P494, DOI 10.1044/1092-4388(2002/039)
   Goldman D., 2000, GOLDMAN FRISTOE TEST
   Greenslade KJ, 2009, LANG SPEECH HEAR SER, V40, P150, DOI 10.1044/0161-1461(2008/07-0049)
   Hart B., 2003, AM EDUC, V27, P4
   Hedenius M, 2011, RES DEV DISABIL, V32, P2362, DOI 10.1016/j.ridd.2011.07.026
   Hoff E, 2013, DEV PSYCHOL, V49, P4, DOI 10.1037/a0027238
   Kaufman A.S., 2004, KAUFMAN ASSESSMENT B
   KLATT DH, 1990, J ACOUST SOC AM, V87, P820, DOI 10.1121/1.398894
   KRAUSE SE, 1982, J ACOUST SOC AM, V71, P990, DOI 10.1121/1.387580
   Leonard LB, 2007, J SPEECH LANG HEAR R, V50, P408, DOI 10.1044/1092-4388(2007/029)
   Leonard LB, 1997, J SPEECH LANG HEAR R, V40, P741, DOI 10.1044/jslhr.4004.741
   Lum J.A.G., 2013, TOP LANG DISORD, V37, P85
   Mainela-Arnold E, 2010, J SPEECH LANG HEAR R, V53, P1742, DOI 10.1044/1092-4388(2010/08-0198)
   Nittrouer S, 1996, J SPEECH HEAR RES, V39, P278, DOI 10.1044/jshr.3902.278
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   PETERSON GE, 1960, J ACOUST SOC AM, V32, P693, DOI 10.1121/1.1908183
   Quam C, 2012, CHILD DEV, V83, P236, DOI 10.1111/j.1467-8624.2011.01700.x
   Quam C, 2010, J MEM LANG, V62, P135, DOI 10.1016/j.jml.2009.09.003
   R Core Team, 2017, R LANG ENV STAT COMP
   Rice M, 2019, 2019 RES S ASHA CONV
   Romeo RR, 2018, PSYCHOL SCI, V29, P700, DOI 10.1177/0956797617742725
   Rowe ML, 2012, CHILD DEV, V83, P1762, DOI 10.1111/j.1467-8624.2012.01805.x
   Schwartz RG, 2013, CLIN LINGUIST PHONET, V27, P339, DOI 10.3109/02699206.2013.763386
   Spaulding TJ, 2008, J SPEECH LANG HEAR R, V51, P16, DOI 10.1044/1092-4388(2008/002)
   Tallal P, 1996, SCIENCE, V271, P81, DOI 10.1126/science.271.5245.81
   Tomblin JB, 1997, J SPEECH LANG HEAR R, V40, P1245, DOI 10.1044/jslhr.4006.1245
   Tuomainen O, 2015, CLIN LINGUIST PHONET, V29, P557, DOI 10.3109/02699206.2015.1036464
   Ullman MT, 2005, CORTEX, V41, P399, DOI 10.1016/S0010-9452(08)70276-4
   Weenink D., 2009, INTERSPEECH, V10, P2059
   Wright BA, 1997, NATURE, V387, P176, DOI 10.1038/387176a0
   Zuk J, 2018, J SPEECH LANG HEAR R, V61, P583, DOI 10.1044/2017_JSLHR-S-16-0106
   ZWICKER E, 1961, J ACOUST SOC AM, V33, P248, DOI 10.1121/1.1908630
NR 46
TC 0
Z9 0
U1 0
U2 0
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1754-9507
EI 1754-9515
J9 INT J SPEECH-LANG PA
JI Int. J. Speech-Lang. Pathol.
DI 10.1080/17549507.2020.1750701
EA JUL 2020
PG 12
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA MG9ZZ
UT WOS:000546392200001
PM 32619107
DA 2021-02-24
ER

PT J
AU Zheng, Y
   Samuel, AG
AF Zheng, Yi
   Samuel, Arthur G.
TI The Relationship Between Phonemic Category Boundary Changes and
   Perceptual Adjustments to Natural Accents
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION
LA English
DT Article
DE accent; phonemic category; recalibration; selective adaptation; speech
ID SPEECH-PERCEPTION; FOREIGN ACCENT; ADAPTATION; ENGLISH; FAMILIARITY;
   EXPERIENCE; RECOGNIZE; TALKER; TIME
AB People often experience difficulties when they first hear a novel accent. Prior research has shown that relatively fast natural accent accommodation can occur. However, there has been little investigation of the underlying perceptual mechanism that drives the learning. The current study examines whether phonemic boundary changes play a central role in natural accent accommodation. Two well-established boundary shifting phenomena were used here-recalibration and selective adaptation-to index the flexibility of phonemic category boundaries. Natural accent accommodation was measured with a task in which listeners heard accented words and nonwords before and after listening to English sentences produced by one of two native Mandarin Chinese speakers with moderate accents. In two experiments, participants completed recalibration, selective adaptation, and natural accent accommodation tasks focusing on a consonant contrast that is difficult for native Chinese speakers to produce. We found that: (a) On the accent accommodation task, participants showed an increased endorsement of accented/ mispronounced words after exposure to a speaker's accented speech, indicating a potential relaxation of criteria in the word recognition process; (b) There was no strong link between recalibrating phonemic boundaries and natural accent accommodation; (c) There was no significant correlation between recalibration and selective adaptation. These results suggest that recalibration of phonemic boundaries does not play a central role in natural accent accommodation. Instead, there is some evidence suggesting that natural accent accommodation involves a relaxation of phonemic categorization criteria.
C1 [Zheng, Yi; Samuel, Arthur G.] SUNY Stony Brook, Dept Psychol, Stony Brook, NY 11794 USA.
   [Samuel, Arthur G.] Basque Ctr Cognit Brain & Language, Gipuzkoa, Spain.
   [Samuel, Arthur G.] Basque Fdn Sci, Ikerbasque, Bilbao, Spain.
RP Zheng, Y (corresponding author), SUNY Stony Brook, Dept Psychol, Stony Brook, NY 11794 USA.
EM yizheng.psychology@gmail.com
OI , Arthur Gary Samuel/0000-0001-8552-2710
FU Ministerio de Ciencia E InnovacionInstituto de Salud Carlos IIISpanish
   GovernmentEuropean Commission [PSI2017-82563-P]; Centro de Excelencia
   Severo Ochoa [SEV-20150490]; Basque Government through the BERC
   2018-2021 programBasque Government; National Science FoundationNational
   Science Foundation (NSF) [IBSS-1519908]
FX Support was provided by Ministerio de Ciencia E Innovacion, Grant
   PSI2017-82563-P, Centro de Excelencia Severo Ochoa, Grant SEV-20150490,
   by the Basque Government through the BERC 2018-2021 program, and by the
   National Science Foundation under Grant IBSS-1519908. We thank Antonio
   Freitas, Richard Gerrig, and Marie Huffman for their constructive
   suggestions. We also thank James M. McQueen for valuable comments on a
   previous version of the paper.
CR Baese-Berk MM, 2013, J ACOUST SOC AM, V133, pEL174, DOI 10.1121/1.4789864
   Bamford J, 1979, SPEECH HEARING TESTS, P148
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Brannen K, 2002, CAN J LING/REV CAN L, V47, P1
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Cutler A, 2004, J ACOUST SOC AM, V116, P3668, DOI 10.1121/1.1810292
   Dahan D, 2008, COGNITION, V108, P710, DOI 10.1016/j.cognition.2008.06.003
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   Eisner F, 2006, J ACOUST SOC AM, V119, P1950, DOI 10.1121/1.2178721
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   Eisner F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00148
   Fan J, 2003, NEUROIMAGE, V18, P42, DOI 10.1006/nimg.2002.1319
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   Floccia C, 2006, J EXP PSYCHOL HUMAN, V32, P1276, DOI 10.1037/0096-1523.32.5.1276
   GASS S, 1984, LANG LEARN, V34, P65, DOI 10.1111/j.1467-1770.1984.tb00996.x
   Gordon-Salant S, 2010, J ACOUST SOC AM, V128, pE200, DOI 10.1121/1.3486199
   Hancin-Bhatt B. J., 1994, THESIS
   Hanulikova A, 2012, ATTEN PERCEPT PSYCHO, V74, P613, DOI 10.3758/s13414-011-0259-7
   Hanulikova A, 2012, J COGNITIVE NEUROSCI, V24, P878, DOI 10.1162/jocn_a_00103
   Hedge C, 2018, BEHAV RES METHODS, V50, P1166, DOI 10.3758/s13428-017-0935-1
   Humphrey A. D., 2012, 53 ANN M PSYCH SOC M
   Ishida M, 2016, COGNITION, V151, P68, DOI 10.1016/j.cognition.2016.03.008
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   Jongman A., 2003, P 15 INT C PHON SCI, P1561
   Keye D, 2009, PSYCHOL RES-PSYCH FO, V73, P762, DOI 10.1007/s00426-008-0188-9
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kousaie S, 2012, BRAIN RES, V1446, P71, DOI 10.1016/j.brainres.2012.01.052
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2008, COGNITION, V107, P54, DOI 10.1016/j.cognition.2007.07.013
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   Maye J, 2008, COGNITIVE SCI, V32, P543, DOI 10.1080/03640210802035357
   Mitterer H, 2009, PLOS ONE, V4, pA146, DOI 10.1371/journal.pone.0007785
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Paap KR, 2013, COGNITIVE PSYCHOL, V66, P232, DOI 10.1016/j.cogpsych.2012.12.002
   Porretta V, 2016, J PHONETICS, V58, P1, DOI 10.1016/j.wocn.2016.05.006
   Reinisch E, 2014, J EXP PSYCHOL HUMAN, V40, P539, DOI 10.1037/a0034409
   Reinisch E, 2012, J ACOUST SOC AM, V132, P1165, DOI 10.1121/1.4730884
   Rogers CL, 2005, J SPEECH LANG HEAR R, V48, P306, DOI 10.1044/1092-4388(2005/021)
   Romero-Rivas C, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3389/fnhum.7015.00167, 10.3389/fnhum.2015.00167]
   Saltzman D, 2018, PSYCHON B REV, V25, P718, DOI 10.3758/s13423-017-1376-7
   SAMUEL AG, 1986, COGNITIVE PSYCHOL, V18, P452, DOI 10.1016/0010-0285(86)90007-1
   Samuel AG, 2015, J MEM LANG, V81, P51, DOI 10.1016/j.jml.2015.01.003
   Schmale R, 2012, DEVELOPMENTAL SCI, V15, P732, DOI 10.1111/j.1467-7687.2012.01175.x
   Schmitz J, 2018, LANG COGN NEUROSCI, V33, P527, DOI 10.1080/23273798.2017.1390142
   Stins JF, 2005, CHILD NEUROPSYCHOL, V11, P191, DOI 10.1080/092970490911351
   Sumner M, 2011, COGNITION, V119, P131, DOI 10.1016/j.cognition.2010.10.018
   Wade T, 2007, PHONETICA, V64, P122, DOI 10.1159/000107913
   Weber A, 2014, J PHONETICS, V46, P34, DOI 10.1016/j.wocn.2014.05.002
   White KS, 2011, DEVELOPMENTAL SCI, V14, P372, DOI 10.1111/j.1467-7687.2010.00986.x
   Witteman MJ, 2013, ATTEN PERCEPT PSYCHO, V75, P537, DOI 10.3758/s13414-012-0404-y
   Xie X, 2018, LANG COGN NEUROSCI, V33, P196, DOI 10.1080/23273798.2017.1369551
   Xie X, 2017, J MEM LANG, V97, P30, DOI 10.1016/j.jml.2017.07.005
   Xie X, 2017, J EXP PSYCHOL HUMAN, V43, P206, DOI 10.1037/xhp0000285
   Zhang XJ, 2014, J EXP PSYCHOL HUMAN, V40, P200, DOI 10.1037/a0033182
   Zheng Y, 2019, APPL PSYCHOLINGUIST, V40, P93, DOI 10.1017/S0142716418000462
   Zheng Y, 2017, ATTEN PERCEPT PSYCHO, V79, P1841, DOI 10.3758/s13414-017-1329-2
NR 58
TC 1
Z9 1
U1 0
U2 1
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0278-7393
EI 1939-1285
J9 J EXP PSYCHOL LEARN
JI J. Exp. Psychol.-Learn. Mem. Cogn.
PD JUL
PY 2020
VL 46
IS 7
BP 1270
EP 1292
DI 10.1037/xlm0000788
PG 23
WC Psychology; Psychology, Experimental
SC Psychology
GA MH3JN
UT WOS:000546628300004
PM 31633368
OA Bronze
DA 2021-02-24
ER

PT J
AU Bavin, EL
   Sarant, J
   Hackworth, NJ
   Bennetts, SK
   Buzhardt, J
   Jia, F
   Button, E
   Busby, P
   Leigh, G
   Peterson, C
AF BAVIN, Edith L.
   SARANT, Julia
   HACKWORTH, Naomi. J.
   BENNETTS, Shannon K.
   BUZHARDT, Jay
   JIA, Fan
   BUTTON, Elizabeth
   BUSBY, Peter
   LEIGH, Greg
   PETERSON, Candy
TI Modelling the early expressive communicative trajectories of
   infants/toddlers with early cochlear implants
SO JOURNAL OF CHILD LANGUAGE
LA English
DT Article
DE cochlear implants; progressive early communicative development
ID EARLY VOCABULARY DEVELOPMENT; LANGUAGE-DEVELOPMENT; SPOKEN LANGUAGE;
   DEAF-CHILDREN; INDIVIDUAL-DIFFERENCES; PRESCHOOL-CHILDREN;
   SPEECH-PERCEPTION; AGE; ENVIRONMENT; INFANTS
AB For children with normal hearing (NH), early communication skills predict vocabulary, a precursor to grammar. Growth in early communication skills of infants with cochlear implants (CIs) was investigated using the Early Communication Indicator (ECI), a play-based observation measure. Multilevel linear growth modelling on data from six ECI sessions held at three-monthly intervals revealed significant growth overall, with a non-significant slower growth rate than that of children with NH (comparison age centred at 18 months). Analyses of gesture use and of nonword vocalisations revealed the CI group used significantly more of each, with more rapid growth. In contrast, the CI group used significantly fewer single words and multiword utterances, and with slower growth. Maternal education and time to achieve consistent CI use impacted significantly on growth for the CI sample. The results indicate that progression to vocabulary by young CI users can be supported by encouraging their use of prelinguistic communication.
C1 [BAVIN, Edith L.; BUTTON, Elizabeth] La Trobe Univ, Sch Psychol & Publ Hlth, Melbourne, Vic 3083, Australia.
   [BAVIN, Edith L.; HACKWORTH, Naomi. J.; BENNETTS, Shannon K.] Murdoch Childrens Res Inst, Melbourne, Vic, Australia.
   [SARANT, Julia; BUSBY, Peter] Univ Melbourne, Dept Audiol & Speech Pathol, Melbourne, Vic, Australia.
   [HACKWORTH, Naomi. J.] Parenting Res Ctr, Melbourne, Vic, Australia.
   [HACKWORTH, Naomi. J.; BENNETTS, Shannon K.] La Trobe Univ, Judith Lumley Ctr, Melbourne, Vic, Australia.
   [BUZHARDT, Jay] Univ Kansas, Juniper Gardens Childrens Project, Lawrence, KS 66045 USA.
   [LEIGH, Greg] Royal Inst Deaf & Blind Children, RIDBC Renwick Ctr, Sydney, NSW, Australia.
   [LEIGH, Greg] Macquarie Univ, Fac Human Sci, Sydney, NSW, Australia.
   [PETERSON, Candy] Univ Queensland, Sch Psychol, Brisbane, Qld, Australia.
   [JIA, Fan] Univ Calif, Dept Psychol, Merced, CA USA.
RP Bavin, EL (corresponding author), La Trobe Univ, Sch Psychol & Publ Hlth, Melbourne, Vic 3083, Australia.; Bavin, EL (corresponding author), Murdoch Childrens Res Inst, Melbourne, Vic, Australia.
EM e.bavin@latrobe.edu.au
RI LEIGH, GREGORY/G-7476-2013
OI LEIGH, GREGORY/0000-0001-7564-7317
CR ACREDOLO L, 1988, CHILD DEV, V59, P450, DOI 10.1111/j.1467-8624.1988.tb01480.x
   [Anonymous], 1984, MONOGR, V25, P21
   [Anonymous], 2016, EVIDENCE, V8, pe1000
   Artieres F, 2009, OTOL NEUROTOL, V30, P736, DOI 10.1097/MAO.0b013e3181b2367b
   Bates E, 1999, CARN S COGN, P29
   Bavin EL, 2018, INT J LANG COMM DIS, V53, P788, DOI 10.1111/1460-6984.12383
   Carta J. J., 2010, USING IGDIS TOOLS MO
   Ching TYC, 2017, PEDIATRICS, V140, DOI 10.1542/peds.2016-4274
   Colletti L, 2009, ACTA OTO-LARYNGOL, V129, P361, DOI 10.1080/00016480802495453
   Cuda D, 2014, INT J PEDIATR OTORHI, V78, P1327, DOI 10.1016/j.ijporl.2014.05.021
   Curran PJ, 2010, J COGN DEV, V11, P121, DOI 10.1080/15248371003699969
   Dale PS, 2015, J COMMUN DISORD, V57, P106, DOI 10.1016/j.jcomdis.2015.07.004
   Dettman SJ, 2007, EAR HEARING, V28, p11S, DOI 10.1097/AUD.0b013e31803153f8
   Duchesne L, 2009, J DEAF STUD DEAF EDU, V14, P465, DOI 10.1093/deafed/enp010
   Fagan MK, 2014, J EXP CHILD PSYCHOL, V126, P328, DOI 10.1016/j.jecp.2014.05.005
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   Fernald A, 2013, DEVELOPMENTAL SCI, V16, P234, DOI 10.1111/desc.12019
   Geers AE, 2013, J SPEECH LANG HEAR R, V56, P643, DOI 10.1044/1092-4388(2012/11-0347)
   Geers AE, 2009, J DEAF STUD DEAF EDU, V14, P371, DOI 10.1093/deafed/enn046
   Goldin-Meadow S, 2007, CHILD DEV, V78, P741, DOI 10.1111/j.1467-8624.2007.01029.x
   Goldin-Meadow Susan, 2015, Perspect Lang Learn Educ, V22, P50
   Goldin-Meadow S, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0295
   Greenwood C. R., 2011, J EARLY INTERVENTION, V32, P310
   Greenwood CR, 2006, J EARLY INTERVENTION, V28, P178, DOI 10.1177/105381510602800306
   Greenwood CR, 2013, EARLY CHILD RES Q, V28, P540, DOI 10.1016/j.ecresq.2013.02.006
   Hackworth NJ, 2017, PREV SCI, V18, P337, DOI 10.1007/s11121-017-0753-9
   Hoff E, 2003, CHILD DEV, V74, P1368, DOI 10.1111/1467-8624.00612
   Holt RF, 2008, EAR HEARING, V29, P492, DOI 10.1097/AUD.0b013e31816c409f
   Houston DM, 2010, OTOL NEUROTOL, V31, P1248, DOI 10.1097/MAO.0b013e3181f1cc6a
   Iverson JM, 2005, PSYCHOL SCI, V16, P367, DOI 10.1111/j.0956-7976.2005.01542.x
   Kuhl PK, 1996, J ACOUST SOC AM, V100, P2425, DOI 10.1121/1.417951
   Leigh J, 2013, OTOL NEUROTOL, V34, P443, DOI 10.1097/MAO.0b013e3182814d2c
   Levine D, 2016, OTOL NEUROTOL, V37, pE56, DOI 10.1097/MAO.0000000000000908
   McKean C, 2017, PEDIATRICS, V139, DOI 10.1542/peds.2016-1684
   Muthen LK., 1998, MPLUS USERS GUIDE, VSeventh
   Nicholson JM, 2016, BMC PEDIATR, V16, DOI 10.1186/s12887-016-0610-1
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Pisoni DB, 1999, VOLTA REV, V101, P111
   R Core Team, 2017, R LANG ENV STAT COMP
   Ramirez-Inscoe J, 2011, EAR HEARING, V32, P690, DOI 10.1097/AUD.0b013e31821f0538
   Raudenbush SW, 2002, MULT APPL BK SER, P25
   Reilly S, 2007, PEDIATRICS, V120, pE1441, DOI 10.1542/peds.2007-0045
   Rescorla L., 2013, LATE TALKERS RES PRA
   Roberts MY, 2018, J DEAF STUD DEAF EDU, V23, P95, DOI 10.1093/deafed/enx041
   Rowe ML, 2012, CHILD DEV, V83, P1762, DOI 10.1111/j.1467-8624.2012.01805.x
   Rowe ML, 2012, CHILD DEV, V83, P508, DOI 10.1111/j.1467-8624.2011.01710.x
   Rowe ML, 2009, DEVELOPMENTAL SCI, V12, P182, DOI 10.1111/j.1467-7687.2008.00764.x
   Sarant J, 2014, EAR HEARING, V35, P396, DOI 10.1097/AUD.0000000000000022
   STOELGAMMON C, 1986, J SPEECH HEAR DISORD, V51, P33, DOI 10.1044/jshd.5101.33
   Szagun G, 2001, AUDIOL NEURO-OTOL, V6, P288, DOI 10.1159/000046134
   Szagun G, 2012, J SPEECH LANG HEAR R, V55, P1640, DOI 10.1044/1092-4388(2012/11-0119)
   Tomblin JB, 2007, INT J AUDIOL, V46, P512, DOI 10.1080/14992020701383043
   Ukoumunne OC, 2012, CHILD CARE HLTH DEV, V38, P341, DOI 10.1111/j.1365-2214.2011.01234.x
   Valimaa T, 2018, INT J LANG COMM DIS, V53, P3, DOI 10.1111/1460-6984.12322
   Volterra V., 2006, ADV SIGN LANGUAGE DE, P46
   von Hapsburg D, 2006, J SPEECH LANG HEAR R, V49, P809, DOI 10.1044/1092-4388(2006/057)
   Walker D., 2010, USING IGDIS MONITORI, P39
   Werker JF, 2005, TRENDS COGN SCI, V9, P519, DOI 10.1016/j.tics.2005.09.003
   Wu Z, 2014, FIRST LANG, V34, P72, DOI 10.1177/0142723714521925
NR 59
TC 0
Z9 0
U1 2
U2 5
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0305-0009
EI 1469-7602
J9 J CHILD LANG
JI J. Child Lang.
PD JUL
PY 2020
VL 47
IS 4
BP 796
EP 816
AR PII S0305000919000941
DI 10.1017/S0305000919000941
PG 21
WC Psychology, Developmental; Linguistics; Psychology, Experimental
SC Psychology; Linguistics
GA MD8SR
UT WOS:000544238600004
PM 32178756
DA 2021-02-24
ER

PT J
AU Henrikson, B
   Seidl, A
   Soderstrom, M
AF Henrikson, Brenna
   Seidl, Amanda
   Soderstrom, Melanie
TI Perception of sibilant-liquid phonotactic frequency in full-term and
   preterm infants
SO JOURNAL OF CHILD LANGUAGE
LA English
DT Article
DE infant speech perception; phonotactics; preterm infants
ID SPEECH-PERCEPTION; LANGUAGE-DEVELOPMENT; WORD SEGMENTATION; PATTERNS;
   SENSITIVITY; KNOWLEDGE; PREDICTS; DETAIL; BIRTH
AB We examined full-term and preterm infants' perception of frequent and infrequent phonotactic pairings involving sibilants and liquids. Infants were tested on their preference for syllables with onsets involving /s/ or /?/ followed by /l/ or /r/ using the Headturn Preference Procedure. Full-term infants preferred the frequent to the infrequent phonotactic pairings at 9 months, but not at either younger or older ages. Evidence was inconclusive regarding a possible difference between full-term and preterm samples; however, limitations on the preterm sample size limited our power to detect differences. Preference for the frequent pairing was not related to later vocabulary development.
C1 [Henrikson, Brenna; Soderstrom, Melanie] Univ Manitoba, Winnipeg, MB, Canada.
   [Seidl, Amanda] Purdue Univ, W Lafayette, IN 47907 USA.
RP Soderstrom, M (corresponding author), Univ Manitoba, Dept Psychol, 66 Chancellors Cir, Winnipeg, MB R3T 2N2, Canada.
EM M_Soderstrom@umanitoba.ca
OI Soderstrom, Melanie/0000-0003-3212-5775
FU University of Manitoba; Children's Hospital Research Institute of
   Manitoba; NSERCNatural Sciences and Engineering Research Council of
   Canada (NSERC) [371683-2010]
FX We would like to thank the participating families and the members of the
   Baby Language Lab, especially Lindsay Bacala, Robin O'Hagan, Jacquelyn
   Klassen, Alex Holt, and Laurisa Adams. We would also like to thank
   Manitoba Health for their assistance with participant recruitment. The
   results and conclusions are those of the authors and no official
   endorsement by Manitoba Health is intended or should be inferred. This
   research was funded by the University of Manitoba, an operating grant
   from the Children's Hospital Research Institute of Manitoba, and NSERC
   Discovery grant 371683-2010 to the second author. A portion of this
   research is reported as part of an unpublished Master's thesis by the
   first author.
CR Abrams R M, 2000, J Perinatol, V20, pS31
   [Anonymous], 2018, DEV COGN NEUROSCI, V21, DOI 10.1016/S1878-9293(18)30129-4
   Barre N, 2011, J PEDIATR-US, V158, P766, DOI 10.1016/j.jpeds.2010.10.032
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bayley N., 2006, BSID SCALES INFANT T
   Cristia A, 2011, J ACOUST SOC AM, V129, P3271, DOI 10.1121/1.3562562
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Estes KG, 2016, J EXP CHILD PSYCHOL, V146, P34, DOI 10.1016/j.jecp.2016.01.012
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   Foster-Cohen S, 2007, J CHILD LANG, V34, P655, DOI 10.1017/S0305000907008070
   Foster-Cohen SH, 2010, J DEV BEHAV PEDIATR, V31, P658, DOI 10.1097/DBP.0b013e3181e5ab7e
   FRIEDERICI AD, 1993, PERCEPT PSYCHOPHYS, V54, P287, DOI 10.3758/BF03205263
   Gonzalez-Gomez N, 2012, DEVELOPMENTAL SCI, V15, P885, DOI 10.1111/j.1467-7687.2012.01186.x
   GRIFFITHS SK, 1994, J ACOUST SOC AM, V96, P2055, DOI 10.1121/1.410147
   Herold B, 2008, DEV MED CHILD NEUROL, V50, P678, DOI 10.1111/j.1469-8749.2008.03055.x
   JUSCZYK PW, 1993, J MEM LANG, V32, P402, DOI 10.1006/jmla.1993.1022
   JUSCZYK PW, 1994, J MEM LANG, V33, P630, DOI 10.1006/jmla.1994.1030
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Li FF, 2009, J PHONETICS, V37, P111, DOI 10.1016/j.wocn.2008.10.001
   Mattys SL, 1999, COGNITIVE PSYCHOL, V38, P465, DOI 10.1006/cogp.1999.0721
   Mattys SL, 2001, J EXP PSYCHOL HUMAN, V27, P644, DOI 10.1037//0096-1523.27.3.644
   NELSON DGK, 1995, INFANT BEHAV DEV, V18, P111
   Newman R, 2006, DEV PSYCHOL, V42, P643, DOI 10.1037/0012-1649.42.4.643
   Nittrouer S, 2001, J ACOUST SOC AM, V110, P1598, DOI 10.1121/1.1379078
   Pena M, 2012, J NEUROSCI, V32, P11159, DOI 10.1523/JNEUROSCI.6516-11.2012
   Pena M, 2010, P NATL ACAD SCI USA, V107, P3823, DOI 10.1073/pnas.0914326107
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Singh L, 2012, DEVELOPMENTAL SCI, V15, P482, DOI 10.1111/j.1467-7687.2012.01141.x
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Vitevitch MS, 2004, BEHAV RES METH INS C, V36, P481, DOI 10.3758/BF03195594
   Vouloumanos A, 2007, DEVELOPMENTAL SCI, V10, P159, DOI 10.1111/j.1467-7687.2007.00549.x
   Werker JF, 2012, CURR DIR PSYCHOL SCI, V21, P221, DOI 10.1177/0963721412449459
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   White KS, 2008, J MEM LANG, V59, P114, DOI 10.1016/j.jml.2008.03.001
NR 35
TC 0
Z9 0
U1 2
U2 2
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0305-0009
EI 1469-7602
J9 J CHILD LANG
JI J. Child Lang.
PD JUL
PY 2020
VL 47
IS 4
BP 893
EP 907
AR PII S0305000919000825
DI 10.1017/S0305000919000825
PG 15
WC Psychology, Developmental; Linguistics; Psychology, Experimental
SC Psychology; Linguistics
GA MD8SR
UT WOS:000544238600009
PM 31852556
DA 2021-02-24
ER

PT J
AU Michaelis, K
   Erickson, LC
   Fama, ME
   Skipper-Kallal, LM
   Xing, SH
   Lacey, EH
   Anbari, Z
   Norato, G
   Rauschecker, JP
   Turkeltaub, PE
AF Michaelis, Kelly
   Erickson, Laura C.
   Fama, Mackenzie E.
   Skipper-Kallal, Laura M.
   Xing, Shihui
   Lacey, Elizabeth H.
   Anbari, Zainab
   Norato, Gina
   Rauschecker, Josef P.
   Turkeltaub, Peter E.
TI Effects of age and left hemisphere lesions on audiovisual integration of
   speech
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Supramarginal gyrus; Planum temporale; Lesion symptom mapping; McGurk
   effect; Audiovisual integration
ID AUDITORY-VISUAL SPEECH; LEFT PLANUM TEMPORALE; BRAIN-DAMAGE; HEARING
   LIPS; PERCEPTION; INFORMATION; DEFICIT; CORTEX; WINDOW; FUSION
AB Neuroimaging studies have implicated left temporal lobe regions in audiovisual integration of speech and inferior parietal regions in temporal binding of incoming signals. However, it remains unclear which regions are necessary for audiovisual integration, especially when the auditory and visual signals are offset in time. Aging also influences integration, but the nature of this influence is unresolved. We used a McGurk task to test audiovisual integration and sensitivity to the timing of audiovisual signals in two older adult groups: left hemisphere stroke survivors and controls. We observed a positive relationship between age and audiovisual speech integration in both groups, and an interaction indicating that lesions reduce sensitivity to timing offsets between signals. Lesion-symptom mapping demonstrated that damage to the left supramarginal gyrus and planum temporale reduces temporal acuity in audiovisual speech perception. This suggests that a process mediated by these structures identifies asynchronous audiovisual signals that should not be integrated.
C1 [Michaelis, Kelly; Erickson, Laura C.; Fama, Mackenzie E.; Skipper-Kallal, Laura M.; Xing, Shihui; Lacey, Elizabeth H.; Anbari, Zainab; Turkeltaub, Peter E.] Georgetown Univ, Med Ctr, Neurol Dept, Washington, DC 20007 USA.
   [Michaelis, Kelly; Erickson, Laura C.; Fama, Mackenzie E.; Skipper-Kallal, Laura M.; Xing, Shihui; Lacey, Elizabeth H.; Anbari, Zainab; Turkeltaub, Peter E.] Georgetown Univ, Med Ctr, Ctr Brain Plast & Recovery, Washington, DC 20007 USA.
   [Erickson, Laura C.; Rauschecker, Josef P.] Georgetown Univ, Med Ctr, Neurosci Dept, Washington, DC 20007 USA.
   [Fama, Mackenzie E.] Towson Univ, Dept Speech Language Pathol & Audiol, Towson, MD USA.
   [Xing, Shihui] Sun Yat Sen Univ, Dept Neurol, Affiliated Hosp 1, Guangzhou, Peoples R China.
   [Lacey, Elizabeth H.; Turkeltaub, Peter E.] MedStar Natl Rehabil Hosp, Res Div, Washington, DC USA.
   [Norato, Gina] NINDS, Clin Trials Unit, NIH, Bldg 36,Rm 4D04, Bethesda, MD 20892 USA.
RP Turkeltaub, PE (corresponding author), 4000 Reservoir Rd NW,Bldg D,Suite 165, Washington, DC 20057 USA.
EM turkeltp@georgetown.edu
OI Rauschecker, Josef P./0000-0003-4353-9084
FU National Science Foundation (NSF) Graduate Research Fellowship (United
   States)National Science Foundation (NSF) [DGE-0903443, DGE-1444316,
   1444316]; Achievement Rewards for College Scientists Metropolitan
   Washington Chapter, United States (ARCS/MWC) 2015-2016; National
   Institutes of Health, United StatesUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USA [KL2TR000102,
   R01DC014960, 2RO1 EY018923-03A1, 2 R56 NS052494-06A1, RO1 DC014989];
   Vernon Family Trust, United States; National Science Foundation, United
   StatesNational Science Foundation (NSF) [OISE-0730255]; Tinnitus
   Research Consortium
FX This work was supported by a National Science Foundation (NSF) Graduate
   Research Fellowship (United States, grant numbers DGE-0903443 and
   DGE-1444316 to LCE, and 1444316 to KM); the Achievement Rewards for
   College Scientists Metropolitan Washington Chapter, United States
   (ARCS/MWC) 2015-2016 Noama Wheeler Scholar (to LCE); National Institutes
   of Health, United States (grant numbers KL2TR000102 and R01DC014960 to
   PET, 2RO1 EY018923-03A1 to JPR, 2 R56 NS052494-06A1 to JPR, RO1 DC014989
   to JPR); the Vernon Family Trust, United States (to PET); National
   Science Foundation, United States (grant number OISE-0730255 to JPR);
   and Tinnitus Research Consortium (to JPR).
CR Adank P, 2012, HUM BRAIN MAPP, V33, P360, DOI 10.1002/hbm.21218
   Alm M, 2013, J ACOUST SOC AM, V134, P3001, DOI 10.1121/1.4820798
   Andersen TS, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00435
   Andersen TS, 2004, COGNITIVE BRAIN RES, V21, P301, DOI 10.1016/j.cogbrainres.2004.06.004
   Avants BB, 2011, NEUROIMAGE, V54, P2033, DOI 10.1016/j.neuroimage.2010.09.025
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Baum Sarah H, 2017, Curr Behav Neurosci Rep, V4, P198, DOI 10.1007/s40473-017-0124-7
   Baum SH, 2012, NEUROIMAGE, V62, P1825, DOI 10.1016/j.neuroimage.2012.05.034
   Beauchamp MS, 2010, J NEUROSCI, V30, P2414, DOI 10.1523/JNEUROSCI.4865-09.2010
   Bedard G, 2016, EXP BRAIN RES, V234, P331, DOI 10.1007/s00221-015-4466-7
   Benoit MM, 2010, HUM BRAIN MAPP, V31, P526, DOI 10.1002/hbm.20884
   Bernstein LE, 2008, NEUROIMAGE, V39, P423, DOI 10.1016/j.neuroimage.2007.08.035
   Binder JR, 1996, BRAIN, V119, P1239, DOI 10.1093/brain/119.4.1239
   Bolognini N, 2013, NEUROSCI BIOBEHAV R, V37, P269, DOI 10.1016/j.neubiorev.2012.12.006
   Bornkessel-Schlesewsky I, 2015, TRENDS COGN SCI, V19, P142, DOI 10.1016/j.tics.2014.12.008
   Brown VA, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0207160
   Burnham D., 2013, AUDITORY VISUAL SPEE, DOI [10.1007/978-3-662-13015-5_7., DOI 10.1007/978-3-662-13015-5_7]
   Calvert G., 2004, HDB MULTISENSORY PRO
   CAMPBELL R, 1990, NEUROPSYCHOLOGIA, V28, P787, DOI 10.1016/0028-3932(90)90003-7
   Champoux F, 2006, NEUROREPORT, V17, P1607, DOI 10.1097/01.wnr.0000236856.93586.94
   Cienkowski KM, 2002, EAR HEARING, V23, P439, DOI 10.1097/00003446-200210000-00006
   Colin C, 2005, EUR J COGN PSYCHOL, V17, P541, DOI 10.1080/09541440440000168
   DeMarco AT, 2018, HUM BRAIN MAPP, V39, P4169, DOI 10.1002/hbm.24289
   Diederich A, 2008, NEUROPSYCHOLOGIA, V46, P2556, DOI 10.1016/j.neuropsychologia.2008.03.026
   EFRON R, 1963, BRAIN, V86, P403, DOI 10.1093/brain/86.3.403
   Erickson LC, 2014, HUM BRAIN MAPP, V35, P5587, DOI 10.1002/hbm.22572
   Erickson LC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00534
   Freeman ED, 2013, CORTEX, V49, P2875, DOI 10.1016/j.cortex.2013.03.006
   Fridriksson J, 2009, STROKE, V40, P853, DOI 10.1161/STROKEAHA.108.532499
   Ghaleh M, 2018, CORTEX, V99, P346, DOI 10.1016/j.cortex.2017.12.010
   Gordon-Salant S, 2017, J ACOUST SOC AM, V142, P151, DOI 10.1121/1.4992026
   Grajny K, 2016, J NEUROPSYCH CLIN N, V28, P292, DOI 10.1176/appi.neuropsych.16010004
   GREEN KP, 1991, PERCEPT PSYCHOPHYS, V50, P524, DOI 10.3758/BF03207536
   Griffiths TD, 2002, TRENDS NEUROSCI, V25, P348, DOI 10.1016/S0166-2236(02)02191-4
   Hamilton RH, 2006, BRAIN LANG, V98, P66, DOI 10.1016/j.bandl.2006.02.001
   Hessler D, 2012, APHASIOLOGY, V26, P83, DOI 10.1080/02687038.2011.608840
   Hickok G, 2018, CORTEX, V103, P360, DOI 10.1016/j.cortex.2018.03.030
   Hickok G, 2009, J NEUROPHYSIOL, V101, P2725, DOI 10.1152/jn.91099.2008
   Huyse A, 2014, J ACOUST SOC AM, V136, P1918, DOI 10.1121/1.4894685
   Kimberg DY, 2007, J COGNITIVE NEUROSCI, V19, P1067, DOI 10.1162/jocn.2007.19.7.1067
   Macaluso E, 2004, NEUROIMAGE, V21, P725, DOI 10.1016/j.neuroimage.2003.09.049
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   Mah YH, 2014, BRAIN, V137, P2522, DOI 10.1093/brain/awu164
   Marques LM, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00533
   Matchin W, 2014, J COGNITIVE NEUROSCI, V26, P606, DOI 10.1162/jocn_a_00515
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Miller LM, 2005, J NEUROSCI, V25, P5884, DOI 10.1523/JNEUROSCI.0896-05.2005
   Mirman D., 2016, PERMUTATION BASED CL
   Mozolic J. L., 2012, MULTISENSORY INTEGRA
   Munhall KG, 1996, PERCEPT PSYCHOPHYS, V58, P351, DOI 10.3758/BF03206811
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058
   Nicholson KG, 2002, NEUROCASE, V8, P314, DOI 10.1076/neur.8.3.314.16195
   Peelle JE, 2016, TRENDS NEUROSCI, V39, P486, DOI 10.1016/j.tins.2016.05.001
   Peiffer AM, 2009, HUM BRAIN MAPP, V30, P228, DOI 10.1002/hbm.20497
   Pekkola J, 2006, HUM BRAIN MAPP, V27, P471, DOI 10.1002/hbm.20190
   Powers AR, 2012, J NEUROSCI, V32, P6263, DOI 10.1523/JNEUROSCI.6138-11.2012
   Powers AR, 2009, J NEUROSCI, V29, P12265, DOI 10.1523/JNEUROSCI.3501-09.2009
   Profant O, 2014, NEUROSCIENCE, V260, P87, DOI 10.1016/j.neuroscience.2013.12.010
   Rauschecker JP, 2011, HEARING RES, V271, P16, DOI 10.1016/j.heares.2010.09.001
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rorden C, 2012, NEUROIMAGE, V61, P957, DOI 10.1016/j.neuroimage.2012.03.020
   SAMS M, 1991, NEUROSCI LETT, V127, P141, DOI 10.1016/0304-3940(91)90914-F
   Sams M, 1998, SPEECH COMMUN, V26, P75, DOI 10.1016/S0167-6393(98)00051-X
   Schirmer A, 2004, COGNITIVE BRAIN RES, V21, P269, DOI 10.1016/j.cogbrainres.2004.04.003
   Schmid G, 2009, CLIN LINGUIST PHONET, V23, P208, DOI 10.1080/02699200802399913
   Sekiyama K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00323
   Setti A, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00575
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Skipper JI, 2007, BRAIN LANG, V101, P260, DOI 10.1016/j.bandl.2007.02.008
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   SOROKER N, 1995, NEUROPSYCHOLOGIA, V33, P461, DOI 10.1016/0028-3932(94)00130-H
   Stevenson RA, 2018, J EXP PSYCHOL HUMAN, V44, P106, DOI 10.1037/xhp0000424
   Stevenson RA, 2015, NEUROBIOL AGING, V36, P283, DOI 10.1016/j.neurobiolaging.2014.08.003
   Stevenson RA, 2012, J EXP PSYCHOL HUMAN, V38, P1517, DOI 10.1037/a0027339
   Stevenson RA, 2011, NEUROIMAGE, V55, P1339, DOI 10.1016/j.neuroimage.2010.12.063
   Stevenson RA, 2010, NEUROIMAGE, V49, P3308, DOI 10.1016/j.neuroimage.2009.12.001
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SWISHER L, 1972, NEUROPSYCHOLOGIA, V10, P137, DOI 10.1016/0028-3932(72)90053-X
   Szycik GR, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00095
   Tye-Murray N, 2016, PSYCHOL AGING, V31, P380, DOI 10.1037/pag0000094
   Tye-Murray N, 2010, EAR HEARING, V31, P636, DOI 10.1097/AUD.0b013e3181ddf7ff
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Vroomen J, 2010, ATTEN PERCEPT PSYCHO, V72, P871, DOI 10.3758/APP.72.4.871
   Wiener M, 2010, NEUROPSYCHOLOGIA, V48, P3967, DOI 10.1016/j.neuropsychologia.2010.09.014
   Wiener M, 2010, NEUROIMAGE, V49, P1728, DOI 10.1016/j.neuroimage.2009.09.064
   Wiener M, 2010, J COGNITIVE NEUROSCI, V22, P23, DOI 10.1162/jocn.2009.21191
   Wiersinga-Post E, 2010, NEUROREPORT, V21, P1146, DOI 10.1097/WNR.0b013e328340cc47
   Wilson SM, 2017, LANG COGN NEUROSCI, V32, P891, DOI 10.1080/23273798.2016.1248984
   Xing SH, 2016, BRAIN, V139, P227, DOI 10.1093/brain/awv323
   Xu YS, 2006, HUM BRAIN MAPP, V27, P173, DOI 10.1002/hbm.20176
   Youse KM, 2004, BRAIN INJURY, V18, P825, DOI 10.1080/02699000410001671784
   Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015
   Zhang YS, 2014, HUM BRAIN MAPP, V35, P5861, DOI 10.1002/hbm.22590
NR 94
TC 0
Z9 0
U1 5
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD JUL
PY 2020
VL 206
AR 104812
DI 10.1016/j.bandl.2020.104812
PG 12
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA LU2XC
UT WOS:000537623500006
PM 32447050
DA 2021-02-24
ER

PT J
AU Peng, JX
   Lau, SK
   Zhao, YZ
AF Peng, Jianxin
   Lau, Siu-Kit
   Zhao, Yuezhe
TI Comparative study of acoustical indices and speech perception of
   students in two primary school classrooms with an acoustical treatment
SO APPLIED ACOUSTICS
LA English
DT Article
DE Classroom acoustics; Reverberation time; Early-to-late sound ratio;
   Speech transmission index; Speech intelligibility; Speech perception
ID INTELLIGIBILITY; REVERBERATION; CHILDREN; NOISE
AB Objective acoustical indices and subjective speech perception of students were investigated and compared in two different classrooms before and after an acoustical treatment. The treatment in the present study refers to the installation of sound absorption materials on the ceilings in two primary school classrooms. The results showed that the reverberation time after acoustical treatment was reduced, while the early-to-late sound ratio and the speech transmission index were improved. The subjective speech intelligibility in classrooms was also enhanced. Subjective survey showed that most of the students preferred learning in the classrooms after acoustical treatment. They reported that higher concentration is because the speeches of the teachers were much clear in the treated classroom. However, subjective speech perception of the students has some discrepancies between the two classrooms. The perception of the students in Classroom A was better than that in Classroom B. Sixty-two percent (61.9%) of the students prefer to study in the classroom A after acoustical treatment, but only 46.3% of the students prefer to study in the Classroom B. Results show that exceeding low-frequency reverberation in the classroom may significantly mask speech signals and have effect on the student's speech perception in classroom, even though the traditional criteria of RT and C-50 at mid-frequencies are similar. (C) 2020 Elsevier Ltd. All rights reserved.
C1 [Peng, Jianxin] South China Univ Technol, Sch Phys & Optoelect, Guangzhou, Peoples R China.
   [Peng, Jianxin; Zhao, Yuezhe] South China Univ Technol, State Key Lab Subtrop Bldg Sci, Guangzhou, Peoples R China.
   [Lau, Siu-Kit] Natl Univ Singapore, Sch Design & Environm, Dept Architecture, Singapore, Singapore.
RP Lau, SK (corresponding author), Natl Univ Singapore, Sch Design & Environm, Dept Architecture, Singapore, Singapore.
EM slau@nus.edu.sg
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [11674104, 11374106]; Opening Project of the
   State Key Laboratory of Subtropical Building Science, South China
   University of Technology, China [2019ZB18]
FX The authors thank the school and teachers that participated in the
   study. Special thanks are given to the students who participated in the
   questionnaire survey and subjective evaluation of Chinese speech
   intelligibility. This work is supported by the National Natural Science
   Foundation of China (Grant No. 11674104, 11374106) and Opening Project
   of the State Key Laboratory of Subtropical Building Science, South China
   University of Technology, China (Grant No. 2019ZB18).
CR Astolfi A, 2012, J ACOUST SOC AM, V131, P247, DOI 10.1121/1.3662060
   Bradley JS, 2008, J ACOUST SOC AM, V123, P2078, DOI 10.1121/1.2839285
   Crandell CC, 1999, VOLTA REV, V101, P33
   Johnson CE, 2000, J SPEECH LANG HEAR R, V43, P144, DOI 10.1044/jslhr.4301.144
   Kanakri SM, 2017, ENVIRON BEHAV, V49, P847, DOI 10.1177/0013916516669389
   NEUMAN AC, 1983, J ACOUST SOC AM, V73, P2145, DOI 10.1121/1.389538
   Peng JX, 2018, ARCH ACOUST, V43, P123, DOI 10.24425/118087
   Peng J, 2018, APPL ACOUST, V131, P1, DOI 10.1016/j.apacoust.2017.10.012
   Peng JX, 2015, J ACOUST SOC AM, V137, P85, DOI 10.1121/1.4904519
   Peng JX, 2015, APPL ACOUST, V89, P42, DOI 10.1016/j.apacoust.2014.09.005
   Picard M, 2001, AUDIOLOGY, V40, P221
   Wu SJ, 2014, ACTA ACUST UNITED AC, V100, P1067, DOI 10.3813/AAA.918786
   Wu ZJ, 1964, ACTA ACUST, V1, P33
   YACULLO WS, 1987, AUDIOLOGY, V26, P235
   Yang W, 2009, J ACOUST SOC AM, V125, P922, DOI 10.1121/1.3058900
NR 15
TC 0
Z9 0
U1 3
U2 8
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0003-682X
EI 1872-910X
J9 APPL ACOUST
JI Appl. Acoust.
PD JUL
PY 2020
VL 164
AR 107297
DI 10.1016/j.apacoust.2020.107297
PG 6
WC Acoustics
SC Acoustics
GA KZ9VE
UT WOS:000523606100030
DA 2021-02-24
ER

PT J
AU Kumar, VG
   Dutta, S
   Talwar, S
   Roy, D
   Banerjee, A
AF Kumar, Vinodh G.
   Dutta, Shrey
   Talwar, Siddharth
   Roy, Dipanjan
   Banerjee, Arpan
TI Biophysical mechanisms governing large-scale brain network dynamics
   underlying individual-specific variability of perception
SO EUROPEAN JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE EEG; global coherence; large-scale networks; McGurk effect;
   multisensory; perception; source connectivity; variability
ID SUPERIOR TEMPORAL SULCUS; AUDIOVISUAL INTEGRATION; VISUAL AREAS; MODEL;
   COHERENCE; OSCILLATIONS; CONNECTIONS; TRACKING; HEARING; MACAQUE
AB Perception necessitates interaction among neuronal ensembles, the dynamics of which can be conceptualized as the emergent behavior of coupled dynamical systems. Here, we propose a detailed neurobiologically realistic model that captures the neural mechanisms of inter-individual variability observed in cross-modal speech perception. From raw EEG signals recorded from human participants when they were presented with speech vocalizations of McGurk-incongruent and congruent audio-visual (AV) stimuli, we computed the global coherence metric to capture the neural variability of large-scale networks. We identified that participants' McGurk susceptibility was negatively correlated to their alpha band global coherence. The proposed biophysical model conceptualized the global coherence dynamics emerge from coupling between the interacting neural masses-representing the sensory-specific auditory/visual areas and modality nonspecific associative/integrative regions. Subsequently, we could predict that an extremely weak direct AV coupling results in a decrease in alpha band global coherence-mimicking the cortical dynamics of participants with higher McGurk susceptibility. Source connectivity analysis also showed decreased connectivity between sensory-specific regions in participants more susceptible to McGurk effect, thus establishing an empirical validation to the prediction. Overall, our study provides an outline to link variability in structural and functional connectivity metrics to variability of performance that can be useful for several perception and action task paradigms.
C1 [Kumar, Vinodh G.; Dutta, Shrey; Talwar, Siddharth; Roy, Dipanjan; Banerjee, Arpan] Natl Brain Res Ctr, Cognit Brain Dynam Lab, NH-8, Gurgaon 122052, Haryana, India.
RP Roy, D; Banerjee, A (corresponding author), Natl Brain Res Ctr, Cognit Brain Dynam Lab, NH-8, Gurgaon 122052, Haryana, India.
EM dipanjan.nbrc@gov.in; arpan@nbrc.ac.in
OI Roy, Dipanjan/0000-0002-1669-1083
FU Department of Biotechnology, Government of IndiaDepartment of
   Biotechnology (DBT) India [BT/RLF/Re-entry/07/2014,
   BT/RLF/Re-entry/31/2011, BT/07/IYBA/2013]; Department of Science and
   Technology (DST) Ministry of Science and Technology, Government of India
   [SR/CSRI/21/2016]
FX Department of Biotechnology, Government of India, Grant/Award Number:
   BT/RLF/Re-entry/07/2014, BT/RLF/Re-entry/31/2011 and BT/07/IYBA/2013;
   Department of Science and Technology (DST) Ministry of Science and
   Technology, Government of India, Grant/Award Number: SR/CSRI/21/2016
CR Baddeley A, 2010, CURR BIOL, V20, pR136, DOI 10.1016/j.cub.2009.12.014
   Bastos AM, 2015, NEUROIMAGE, V108, P460, DOI 10.1016/j.neuroimage.2014.12.081
   Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038
   Beauchamp MS, 2015, TRENDS COGN SCI, V19, P489, DOI 10.1016/j.tics.2015.07.002
   Beauchamp MS, 2010, J NEUROSCI, V30, P2414, DOI 10.1523/JNEUROSCI.4865-09.2010
   Becker R, 2015, PLOS COMPUT BIOL, V11, DOI 10.1371/journal.pcbi.1004352
   Benoit MM, 2010, HUM BRAIN MAPP, V31, P526, DOI 10.1002/hbm.20884
   Bhatt MB, 2016, NEUROIMAGE, V133, P224, DOI 10.1016/j.neuroimage.2016.02.078
   Bizley J. K., 2011, NEURAL BASEMULTISE, P31, DOI [10.1201/b11092-5, DOI 10.1201/B11092-5]
   BRESSLER SL, 1995, BRAIN RES REV, V20, P288, DOI 10.1016/0165-0173(94)00016-I
   Bressler SL, 2001, TRENDS COGN SCI, V5, P26, DOI 10.1016/S1364-6613(00)01564-3
   Bressler SL, 2010, TRENDS COGN SCI, V14, P277, DOI 10.1016/j.tics.2010.04.004
   Brown HR, 2012, NEUROIMAGE, V63, P223, DOI 10.1016/j.neuroimage.2012.06.044
   Cimenser A, 2011, P NATL ACAD SCI USA, V108, P8832, DOI 10.1073/pnas.1017041108
   Cuppini C, 2017, EUR J NEUROSCI, V46, P2481, DOI 10.1111/ejn.13725
   David O, 2003, NEUROIMAGE, V20, P1743, DOI 10.1016/j.neuroimage.2003.07.015
   Deco G, 2007, P NATL ACAD SCI USA, V104, P20073, DOI 10.1073/pnas.0709794104
   Deco G, 2010, P NATL ACAD SCI USA, V107, P7545, DOI 10.1073/pnas.1002333107
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Doesburg SM, 2008, EXP BRAIN RES, V185, P11, DOI 10.1007/s00221-007-1127-5
   Engel A. K., 2011, NEURAL BASEMULTISE, P115
   Falchier A, 2002, J NEUROSCI, V22, P5749
   Freyer F, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002634
   Fries P, 2015, NEURON, V88, P220, DOI 10.1016/j.neuron.2015.09.034
   Gilson M, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1004762
   Gold C, 2006, J NEUROPHYSIOL, V95, P3113, DOI 10.1152/jn.00979.2005
   Gross J, 2001, P NATL ACAD SCI USA, V98, P694, DOI 10.1073/pnas.98.2.694
   Halder T, 2019, ENEURO, V6, DOI 10.1523/ENEURO.0170-19.2019
   Haxby JV, 2000, TRENDS COGN SCI, V4, P223, DOI 10.1016/S1364-6613(00)01482-0
   HINDMARSH JL, 1984, PROC R SOC SER B-BIO, V221, P87, DOI 10.1098/rspb.1984.0024
   JANSEN BH, 1995, BIOL CYBERN, V73, P357, DOI 10.1007/s004220050191
   Kayser C, 2008, CEREB CORTEX, V18, P1560, DOI 10.1093/cercor/bhm187
   Kayser C, 2009, FRONT INTEGR NEUROSC, V3, DOI 10.3389/neuro.07.007.2009
   Keil J, 2018, NEUROSCIENTIST, V24, P609, DOI 10.1177/1073858418755352
   Keil J, 2012, CEREB CORTEX, V22, P221, DOI 10.1093/cercor/bhr125
   Kirschstein T, 2009, CLIN EEG NEUROSCI, V40, P146, DOI 10.1177/155005940904000305
   Klimesch W, 1999, BRAIN RES REV, V29, P169, DOI 10.1016/S0165-0173(98)00056-3
   Kording KP, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000943
   Kumar GV, 2018, MULTISENS RES, V31, P481, DOI 10.1163/22134808-00002574
   Kumar GV, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01558
   Li Q, 2019, FRONT COMPUT NEUROSC, V13, DOI 10.3389/fncom.2019.00059
   Litvak V, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00670
   LOPESDAS.FH, 1974, KYBERNETIK, V15, P27, DOI 10.1007/BF00270757
   Ma WJ, 2008, CURR OPIN NEUROBIOL, V18, P217, DOI 10.1016/j.conb.2008.07.004
   MacDonald J, 2000, PERCEPTION, V29, P1155, DOI 10.1068/p3020
   Maier JX, 2008, CURR BIOL, V18, P963, DOI 10.1016/j.cub.2008.05.043
   Markov NT, 2013, SCIENCE, V342, P578, DOI 10.1126/science.1238406
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mitra PP, 2008, OBSERVED BRAIN DYNAM
   Moreno-Bote R, 2007, J NEUROPHYSIOL, V98, P1125, DOI 10.1152/jn.00116.2007
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Nath AR, 2011, J NEUROSCI, V31, P1704, DOI 10.1523/JNEUROSCI.4853-10.2011
   Onojima T, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005928
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Pinotsis DA, 2014, NEUROIMAGE, V92, P143, DOI 10.1016/j.neuroimage.2014.01.047
   Puce A, 2003, PHILOS T R SOC B, V358, P435, DOI 10.1098/rstb.2002.1221
   Railo H, 2011, CONSCIOUS COGN, V20, P972, DOI 10.1016/j.concog.2011.03.019
   Rockland KS, 2003, INT J PSYCHOPHYSIOL, V50, P19, DOI 10.1016/S0167-8760(03)00121-1
   Rosen S., 2011, SIGNALS SYSTEMS SPEE
   Roy D, 2014, BRAIN CONNECT, V4, P791, DOI 10.1089/brain.2014.0252
   Sauseng P, 2005, INT J PSYCHOPHYSIOL, V57, P97, DOI 10.1016/j.ijpsycho.2005.03.018
   Saxe R, 2006, CURR OPIN NEUROBIOL, V16, P235, DOI 10.1016/j.conb.2006.03.001
   Shaw Alexander D, 2021, Cereb Cortex, V31, P1837, DOI 10.1093/cercor/bhz024
   Spiegler A, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002298
   Stefanescu RA, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000219
   Strand J, 2014, J SPEECH LANG HEAR R, V57, P2322, DOI 10.1044/2014_JSLHR-H-14-0059
   Thakur B, 2016, SCI REP-UK, V6, DOI 10.1038/srep31280
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Ursino M, 2017, FRONT COMPUT NEUROSC, V11, DOI 10.3389/fncom.2017.00089
   Varela F, 2001, NAT REV NEUROSCI, V2, P229, DOI 10.1038/35067550
   Wallace MT, 2004, P NATL ACAD SCI USA, V101, P2167, DOI 10.1073/pnas.0305697101
   Wasserman L., 2005, ALL NONPARAMETRIC ST
   Williams PE, 2004, J NEUROSCI, V24, P8278, DOI 10.1523/JNEUROSCI.2716-04.2004
   WILSON HR, 1972, BIOPHYS J, V12, P1, DOI 10.1016/S0006-3495(72)86068-5
   YETERIAN EH, 1989, J COMP NEUROL, V282, P80, DOI 10.1002/cne.902820107
NR 75
TC 1
Z9 1
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0953-816X
EI 1460-9568
J9 EUR J NEUROSCI
JI Eur. J. Neurosci.
PD OCT
PY 2020
VL 52
IS 7
BP 3746
EP 3762
DI 10.1111/ejn.14747
EA JUN 2020
PG 17
WC Neurosciences
SC Neurosciences & Neurology
GA OD2SS
UT WOS:000543861700001
PM 32304122
DA 2021-02-24
ER

PT J
AU Huang, YB
   Wang, Y
   Zhang, QY
   Zhang, WZ
   Fan, MH
AF Huang, Yi-bo
   Wang, Yong
   Zhang, Qiu-yu
   Zhang, Wei-zhao
   Fan, Man-hong
TI Multi-format speech BioHashing based on spectrogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech content authentication; BioHashing; Spectrogram; Henon map;
   Comparative difference method
ID DISCRETE-WAVELET-TRANSFORM; NONNEGATIVE MATRIX; AUTHENTICATION; AUDIO;
   BIOMETRICS; ALGORITHM; HASH
AB In order to solve the security problem of speech perception hash authentication, the application scope of speech authentication algorithm, and improve the robustness, discrimination and real-time authentication in the process of authentication, a multi-format speech BioHashing algorithm based on spectrogram is proposed. Firstly, the speech signal to be processed is converted into spectrogram and feature extraction is carried out by two-dimensional discrete cosine transform. Then, the dimensionality of the eigenvector is reduced by non-negative matrix factorization, and generation of BioHashing sequences by inner product of reduced dimension eigenvectors and orthogonal normalized random matrices. Finally, the BioHashing is encrypted by equal-length scrambling using Henon chaotic map. The algorithm also validates the unidirectionality of BioHashing with trapdoor by comparative difference method. The experimental results show that the proposed algorithm has the characteristics of good security, strong robustness, high real-time performance and wide application range.
C1 [Huang, Yi-bo; Wang, Yong; Zhang, Wei-zhao; Fan, Man-hong] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
   [Zhang, Qiu-yu] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
RP Huang, YB (corresponding author), Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
EM huang_yibo@foxmail.com
RI Yong, Wang/AAW-8984-2020
OI Yong, Wang/0000-0002-8326-2924; Huang, Yibo/0000-0003-1667-3114
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61862041]; Youth Science and Technology Fund
   of Gansu Province of China [1606RJYA274]
FX This work is supported by the National Natural Science Foundation of
   China(No.61862041), Youth Science and Technology Fund of Gansu Province
   of China(No.1606RJYA274).
CR Alpar O, 2018, APPL INTELL, V48, P1189, DOI 10.1007/s10489-017-1009-x
   Amin R, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0258-7
   Awais A, 2018, INT C ART INT BIG DA, P2018
   Chen N, 2010, IET COMMUN, V4, P1722, DOI 10.1049/iet-com.2009.0749
   Chen N, 2010, ETRI J, V32, P345, DOI 10.4218/etrij.10.0209.0309
   Frackowiak M, 2019, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD009027.pub3
   Hammad M, 2019, MULTIMED TOOLS APPL, V78, P1857, DOI 10.1007/s11042-018-6300-2
   Huang Y-B, 2018, IJ NETW SECUR, V20, P206
   Huang Y-B, 2017, J SOFTW ENG, V11, P22, DOI [10.3923/jse.2017.22.31, DOI 10.3923/JSE.2017.22.31]
   Jiang Q, 2018, J AMB INTEL HUM COMP, V9, P1061, DOI 10.1007/s12652-017-0516-2
   Jiao YH, 2009, IEEE SIGNAL PROC LET, V16, P818, DOI 10.1109/LSP.2009.2025827
   Jin Z, 2018, IEEE T INF FOREN SEC, V13, P393, DOI 10.1109/TIFS.2017.2753172
   Kanak A, 2017, IET BIOMETRICS, V6, P457, DOI 10.1049/iet-bmt.2016.0148
   Kaur H, 2019, PATTERN RECOGN LETT, V126, P31, DOI 10.1016/j.patrec.2018.02.016
   Kim HG, 2016, CLUSTER COMPUT, V19, P315, DOI 10.1007/s10586-015-0523-z
   Kumari S, 2017, FUTURE GENER COMP SY, V68, P320, DOI 10.1016/j.future.2016.10.004
   Lacharme P, 2013, IET BIOMETRICS, V2, P130, DOI 10.1049/iet-bmt.2012.0041
   Li JF, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P363, DOI 10.1109/CIS.2015.94
   Li JF, 2015, CHINESE J ELECTRON, V24, P579, DOI 10.1049/cje.2015.07.024
   Liu J, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040700
   Lotia P, 2013, IJRCCT, V2, P579
   Lumini A, 2007, PATTERN RECOGN, V40, P1057, DOI 10.1016/j.patcog.2006.05.030
   Plapous C, 2018, MULTIMED TOOLS APPL, V77, P5929, DOI 10.1007/s11042-017-4505-4
   Qian Q, 2018, TELECOMMUN SYST, V67, P635, DOI 10.1007/s11235-017-0360-x
   Qiuyu Z, 2018, INT J INF COMMUN TEC, V12, P31, DOI DOI 10.1504/IJICT.2018.089021
   Qiuyu Zhang, 2017, 2017 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD), P1295, DOI 10.1109/FSKD.2017.8392951
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Siddavatam I, 2019, STUD COMPUT INTELL, V771, P293, DOI 10.1007/978-981-10-8797-4_31
   Teoh ABJ, 2008, PATTERN RECOGN, V41, P2034, DOI 10.1016/j.patcog.2007.12.002
   Wang NF, 2019, J VIB ENG TECHNOL, V7, P311, DOI 10.1007/s42417-019-00126-z
   Wodecki J, 2019, MECH SYST SIGNAL PR, V130, P585, DOI 10.1016/j.ymssp.2019.05.020
   Xie L, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P294
   Xie L, 2016, MULTIMED TOOLS APPL, V75, P9185, DOI 10.1007/s11042-016-3432-0
   Yenigalla P, 2018, INTERSPEECH, P3688, DOI 10.21437/Interspeech.2018-1811
   Zhang C, 2017, INFORM SCIENCES, V409, P56, DOI 10.1016/j.ins.2017.05.006
   Zhang Q, 2019, INT J NETW SECUR, V21, P259
   Zhang Q-Y, 2018, J INF HIDING MULTIME, V9, P1452
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P21653, DOI 10.1007/s11042-018-5613-5
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P1555, DOI 10.1007/s11042-017-4381-y
   Zhang Qiuyu, 2018, Journal of Huazhong University of Science and Technology (Natural Science Edition), V46, P58, DOI 10.13245/j.hust.180311
   Zhang Qiuyu, 2017, Journal of Huazhong University of Science and Technology (Natural Science Edition), V45, P33, DOI 10.13245/j.hust.170907
   Zhang Qiuyu, 2016, Journal of Huazhong University of Science and Technology (Natural Science Edition), V44, P127, DOI 10.13245/j.hust.161222
   [张秋余 Zhang Qiuyu], 2016, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V39, P77
   ZHANG QY, 2015, J INFORM HIDING MULT, V6, P311
   Zhang XM, 2018, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: IOT AND SMART CITY (ICIT 2018), P110, DOI 10.1145/3301551.3301600
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 46
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24889
EP 24909
DI 10.1007/s11042-020-09211-y
EA JUN 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000543615200003
DA 2021-02-24
ER

PT J
AU Yoshimura, Y
   Hasegawa, C
   Ikeda, T
   Saito, DN
   Hiraishi, H
   Takahashi, T
   Kumazaki, H
   Kikuchi, M
AF Yoshimura, Yuko
   Hasegawa, Chiaki
   Ikeda, Takashi
   Saito, Daisuke N.
   Hiraishi, Hirotoshi
   Takahashi, Tetsuya
   Kumazaki, Hirokazu
   Kikuchi, Mitsuru
TI The maturation of the P1m component in response to voice from infancy to
   3 years of age: A longitudinal study in young children
SO BRAIN AND BEHAVIOR
LA English
DT Article
DE auditory-evoked field (AEF); magnetoencephalography (MEG); young
   children
ID AUDITORY-EVOKED FIELDS; EVENT-RELATED POTENTIALS; HEMISPHERIC-ASYMMETRY;
   DEVELOPMENTAL-CHANGES; LANGUAGE-DEVELOPMENT; SPEECH-PERCEPTION; BRAIN
   RESPONSES; SYSTEM ACTIVITY; FULL-TERM; IMPAIRMENT
AB Introduction In the early development of human infants and toddlers, remarkable changes in brain cortical function for auditory processing have been reported. Knowing the maturational trajectory of auditory cortex responses to human voice in typically developing young children is crucial for identifying voice processing abnormalities in children at risk for neurodevelopmental disorders and language impairment. An early prominent positive component in the cerebral auditory response in newborns has been reported in previous electroencephalography and magnetoencephalography (MEG) studies. However, it is not clear whether this prominent component in infants less than 1 year of age corresponds to the auditory P1m component that has been reported in young children over 2 years of age. Methods To test the hypothesis that the early prominent positive component in infants aged 0 years is an immature manifestation of P1m that we previously reported in children over 2 years of age, we performed a longitudinal MEG study that focused on this early component and examined the maturational changes over three years starting from age 0. Five infants participated in this 3-year longitudinal study. Results This research revealed that the early prominent component in infants aged 3 month corresponded to the auditory P1m component in young children over 2 years old, which we had previously reported to be related to language development and/or autism spectrum disorders. Conclusion Our data revealed the development of the auditory-evoked field in the left and right hemispheres from 0- to 3-year-old children. These results contribute to the elucidation of the development of brain functions in infants.
C1 [Yoshimura, Yuko] Kanazawa Univ, Inst Human & Social Sci, Kakuma Machi, Kanazawa, Ishikawa 9201192, Japan.
   [Yoshimura, Yuko; Hasegawa, Chiaki; Ikeda, Takashi; Saito, Daisuke N.; Kumazaki, Hirokazu; Kikuchi, Mitsuru] Kanazawa Univ, Res Ctr Child Mental Dev, Kanazawa, Ishikawa, Japan.
   [Hiraishi, Hirotoshi] Hamamatsu Univ Sch Med, Inst Med Photon Res, Hamamatsu, Shizuoka, Japan.
   [Takahashi, Tetsuya] Univ Fukui, Hlth Adm Ctr, Fukui, Japan.
   [Kikuchi, Mitsuru] Kanazawa Univ, Inst Med Pharmaceut & Hlth Sci, Kanazawa, Ishikawa, Japan.
RP Yoshimura, Y (corresponding author), Kanazawa Univ, Inst Human & Social Sci, Kakuma Machi, Kanazawa, Ishikawa 9201192, Japan.
EM yukuchen@staff.kanazawa-u.ac.jp
OI Yoshimura, Yuko/0000-0001-9226-4561
FU Center of Innovation Program of the Japan Science and Technology Agency,
   JST, JSPS KAKENHI [JP18H05067, JP16K10247]
FX This study was supported by the Center of Innovation Program of the
   Japan Science and Technology Agency, JST, JSPS KAKENHI Grant Number
   JP18H05067, JP16K10247.
CR Anderson JA, 2007, J COAT TECHNOL RES, V4, P43, DOI 10.1007/s11998-007-9008-1
   Boto E, 2018, NATURE, V555, P657, DOI 10.1038/nature26147
   Breier JI, 2003, NEUROPSYCHOLOGY, V17, P610, DOI 10.1037/0894-4105.17.4.610
   Cardy JEO, 2008, INT J PSYCHOPHYSIOL, V68, P170, DOI 10.1016/j.ijpsycho.2007.10.015
   Cardy JEO, 2005, NEUROREPORT, V16, P329, DOI 10.1097/00001756-200503150-00005
   Cardy JEO, 2004, NEUROREPORT, V15, P1867, DOI 10.1097/00001756-200408260-00006
   Ceponiene R, 2003, P NATL ACAD SCI USA, V100, P5567, DOI 10.1073/pnas.0835631100
   Choudhury N, 2011, CLIN NEUROPHYSIOL, V122, P320, DOI 10.1016/j.clinph.2010.05.035
   Cook H. M., 1990, SENTENCE FINAL PARTI
   Cunningham J, 2000, EAR HEARING, V21, P554, DOI 10.1097/00003446-200012000-00003
   Edgar JC, 2015, FRONT NEUROANAT, V9, DOI 10.3389/fnana.2015.00131
   EGGERMONT JJ, 1988, HEARING RES, V33, P35, DOI 10.1016/0378-5955(88)90019-6
   Friederici AD, 2005, TRENDS COGN SCI, V9, P481, DOI 10.1016/j.tics.2005.08.008
   Gilley PM, 2005, CLIN NEUROPHYSIOL, V116, P648, DOI 10.1016/j.clinph.2004.09.009
   Hasegawa C, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00566
   Heim S, 2003, EUR J NEUROSCI, V17, P1715, DOI 10.1046/j.1460-9568.2003.02596.x
   Heim S, 2000, NEUROPSYCHOLOGIA, V38, P1749, DOI 10.1016/S0028-3932(00)00075-0
   Helenius P, 2014, BRAIN LANG, V130, P11, DOI 10.1016/j.bandl.2014.01.005
   HERSCHKOWITZ N, 1988, BIOL NEONATE, V54, P1
   Holst M, 2005, CLIN NEUROPHYSIOL, V116, P1949, DOI 10.1016/j.clinph.2005.04.008
   Huotilainen M, 2003, NEUROREPORT, V14, P1871, DOI 10.1097/00001756-200310060-00023
   Imada T, 2006, NEUROREPORT, V17, P957, DOI 10.1097/01.wnr.0000223387.51704.89
   Jing HK, 2006, BRAIN DEV-JPN, V28, P247, DOI 10.1016/j.braindev.2005.09.002
   Johnson BW, 2010, CLIN NEUROPHYSIOL, V121, P340, DOI 10.1016/j.clinph.2009.10.017
   Kajikawa S, 2004, J CHILD LANG, V31, P215, DOI 10.1017/S0305000903005968
   Kuhl PK, 2014, P NATL ACAD SCI USA, V111, P11238, DOI 10.1073/pnas.1410963111
   Kuhl PK, 2010, NEURON, V67, P713, DOI 10.1016/j.neuron.2010.08.038
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   KURTZBERG D, 1982, ANN NY ACAD SCI, V388, P557, DOI 10.1111/j.1749-6632.1982.tb50816.x
   KURTZBERG D, 1984, DEV MED CHILD NEUROL, V26, P466
   Kushnerenko E, 2002, NEUROREPORT, V13, P1843, DOI 10.1097/00001756-200210280-00002
   Lippe S, 2009, NEUROSCIENCE, V164, P1108, DOI 10.1016/j.neuroscience.2009.07.066
   Lutter WJ, 2006, CLIN NEUROPHYSIOL, V117, P522, DOI 10.1016/j.clinph.2005.11.003
   McArthur G, 2002, NEUROREPORT, V13, P1079, DOI 10.1097/00001756-200206120-00021
   Menning H, 2005, EXP BRAIN RES, V164, P41, DOI 10.1007/s00221-004-2212-7
   Mody M, 2008, NEUROREPORT, V19, P1567, DOI 10.1097/WNR.0b013e328311ca04
   Oades RD, 1997, PSYCHOPHYSIOLOGY, V34, P677, DOI 10.1111/j.1469-8986.1997.tb02143.x
   OHLRICH ES, 1978, ELECTROEN CLIN NEURO, V44, P411
   Onitsuka T, 2000, CLIN NEUROPHYSIOL, V111, P237, DOI 10.1016/S1388-2457(99)00241-2
   Ortiz-Mantilla S, 2013, DEV MED CHILD NEUROL, V55, P781, DOI 10.1111/dmcn.12207
   PAETAU R, 1995, J CLIN NEUROPHYSIOL, V12, P177, DOI 10.1097/00004691-199503000-00008
   Paul I, 2006, NEUROPSYCHOLOGIA, V44, P785, DOI 10.1016/j.neuropsychologia.2005.07.011
   Paul I, 2006, EUR J NEUROSCI, V24, P2945, DOI 10.1111/j.1460-9568.2006.05153.x
   Pihko E, 2008, INT J PSYCHOPHYSIOL, V68, P161, DOI 10.1016/j.ijpsycho.2007.10.016
   Pihko E, 2007, CEREB CORTEX, V17, P849, DOI 10.1093/cercor/bhk037
   Ponton C, 2002, CLIN NEUROPHYSIOL, V113, P407, DOI 10.1016/S1388-2457(01)00733-7
   Ponton CW, 2000, CLIN NEUROPHYSIOL, V111, P220, DOI 10.1016/S1388-2457(99)00236-9
   Roberts TPL, 2010, AUTISM RES, V3, P8, DOI 10.1002/aur.111
   Sharma A, 1997, EVOKED POTENTIAL, V104, P540, DOI 10.1016/S0168-5597(97)00050-6
   Squires T., 2009, PRAGMATICS, V4, P1
   Tavabi K, 2007, EUR J NEUROSCI, V25, P3155, DOI 10.1111/j.1460-9568.2007.05572.x
   Tomasello M, 2003, DEV PSYCHOL, V39, P906, DOI 10.1037/0012-1649.39.5.906
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Wakai RT, 2007, CLIN NEUROPHYSIOL, V118, P1480, DOI 10.1016/j.clinph.2007.04.003
   Wehner DT, 2007, NEUROPSYCHOLOGIA, V45, P3251, DOI 10.1016/j.neuropsychologia.2007.06.018
   Wunderlich JL, 2006, HEARING RES, V212, P212, DOI 10.1016/j.heares.2005.11.008
   Wunderlich JL, 2006, HEARING RES, V212, P185, DOI 10.1016/j.heares.2005.11.010
   Yoshimura Y, 2016, AUTISM RES, V9, P1216, DOI 10.1002/aur.1604
   Yoshimura Y, 2014, NEUROIMAGE, V101, P440, DOI 10.1016/j.neuroimage.2014.07.034
   Yoshimura Y, 2013, MOL AUTISM, V4, DOI 10.1186/2040-2392-4-38
   Yoshimura Y, 2012, EUR J NEUROSCI, V35, P644, DOI 10.1111/j.1460-9568.2012.07998.x
NR 61
TC 0
Z9 0
U1 2
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN, NJ 07030 USA
SN 2162-3279
J9 BRAIN BEHAV
JI Brain Behav.
PD AUG
PY 2020
VL 10
IS 8
AR e01706
DI 10.1002/brb3.1706
EA JUN 2020
PG 14
WC Behavioral Sciences; Neurosciences
SC Behavioral Sciences; Neurosciences & Neurology
GA NL5SM
UT WOS:000541928100001
PM 32573987
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Ahn, JH
   Oh, SH
   Jang, H
   Lee, JB
   Chung, JW
AF Ahn, Joong Ho
   Oh, Seung-Ha
   Jang, Hyunsook
   Lee, Jung-Bok
   Chung, Jong Woo
TI Impact of hearing loss on the performance of auditory processing
   measured by questionnaires in Korean adolescents
SO SCIENTIFIC REPORTS
LA English
DT Article
ID SPEECH-PERCEPTION; NOISE; DISORDER; CHILDREN; PREVALENCE; COCHLEAR
AB Increasing use of personal listening devices has been accompanied by increase in the prevalence of hearing loss (HL) among youth in Korea, as in other countries. Auditory processing disorder (APD) is one of the main factors affecting academic achievement at school. This study aimed to investigate the prevalence of HL in students attending general middle- and high schools and compare the findings with the APD survey results. From June 1 to December 31, 2016, Korean adolescents (n=2,791) in the first years of middle- and high school underwent audiometric testing and otologic examination and completed questionnaires on APD. The survey was sponsored by the Korean Society of Otolaryngology-Head and Neck Surgery and the Korean Otology Society. The prevalence of speech-frequency hearing loss (SFHL) and high-frequency hearing loss (HFHL) in the poorer ear was 11.6% and 10.3%, respectively, among Korean adolescents. We analysed data from the Scale of Auditory Behaviors, Fisher's Auditory Problems Checklist, and KNISE-Auditory Behavioral Checklist and compared these with the results of hearing tests. We observed positive correlations among the APD questionnaire results and mean hearing levels. This study suggested that hearing loss, especially bilateral high-frequency hearing loss, may affect central auditory processing.
C1 [Ahn, Joong Ho; Chung, Jong Woo] Univ Ulsan, Coll Med, Asan Med Ctr, Dept Otorhinolaryngol Head & Neck Surg, Seoul, South Korea.
   [Oh, Seung-Ha] Seoul Natl Univ, Dept Otorhinolaryngol Head & Neck Surg, Seoul Natl Univ Hosp, Coll Med, Seoul, South Korea.
   [Jang, Hyunsook] Hallym Univ, Div Speech Pathol & Audiol, Res Inst Audiol & Speech Pathol, Coll Nat Sci, Chunchon, South Korea.
   [Lee, Jung-Bok] Univ Ulsan, Coll Med, Asan Med Ctr, Dept Biostat, Seoul, South Korea.
RP Chung, JW (corresponding author), Univ Ulsan, Coll Med, Asan Med Ctr, Dept Otorhinolaryngol Head & Neck Surg, Seoul, South Korea.
EM jwchung@amc.seoul.kr
FU Korean Society of Otorhinolaryngology-Head and Neck Surgery
   [2016KORL0645]; Korean Otological Society
FX This study was funded by the Korean Society of Otorhinolaryngology-Head
   and Neck Surgery, grant number: 2016KORL0645. URL:
   http://www.korl.or.kr/.The study also received funding from the Korean
   Otological Society, grant number: N/A. URL:
   http://www.otologicalsociety.or.kr/.The funders had no role in study
   design, data collection and analysis, decision to publish, or
   preparation of the manuscript.
CR American Academy of Audiology Clinical Practice Guidelines Pediatric Amplification, 2013, AAA PEDIAT AMPL GUID
   [Anonymous], 1999, THESIS
   Bamiou DE, 2001, ARCH DIS CHILD, V85, P361, DOI 10.1136/adc.85.5.361
   Bellis T J, 1999, J Am Acad Audiol, V10, P319
   Bellis Teri James, 2015, Handb Clin Neurol, V129, P537, DOI 10.1016/B978-0-444-62630-1.00030-5
   BOOTHROYD A, 1988, J ACOUST SOC AM, V84, P101, DOI 10.1121/1.396976
   Catts H.W., 1996, AM J AUDIOL, V5, P41, DOI DOI 10.1044/POLICY.TR1996-00241
   Cone BK, 2010, EAR HEARING, V31, P202, DOI 10.1097/AUD.0b013e3181c62263
   de Wit E, 2016, J SPEECH LANG HEAR R, V59, P384, DOI 10.1044/2015_JSLHR-H-15-0118
   ELLIOTT LL, 1995, J SPEECH HEAR RES, V38, P1363, DOI 10.1044/jshr.3806.1363
   FIFER RC, 1983, EAR HEARING, V4, P300, DOI 10.1097/00003446-198311000-00007
   Fisher's L.F., 1976, LF FISH AUD PROBL CH
   Flanagan S, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518756533
   Hong SM, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0159981
   Jang H, 2012, MANUAL KNISE AUDITOR
   Jun HJ, 2015, LARYNGOSCOPE, V125, P690, DOI 10.1002/lary.24913
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Keith R W, 2000, J Am Acad Audiol, V11, P438
   Kelley KS, 2018, AM J AUDIOL, V27, P156, DOI 10.1044/2017_AJA-17-0032
   Lagace J, 2010, AM J AUDIOL, V19, P17, DOI 10.1044/1059-0889(2010/09-0022)
   Lount SA, 2017, J SPEECH LANG HEAR R, V60, P121, DOI 10.1044/2016_JSLHR-L-15-0131
   Machado Márcia Salgado, 2018, Dement. neuropsychol., V12, P314, DOI 10.1590/1980-57642018dn12-030013
   MILTENBERGER GE, 1978, ARCH OTOLARYNGOL, V104, P11
   Moore BCJ, 1996, EAR HEARING, V17, P133, DOI 10.1097/00003446-199604000-00007
   Moore DR, 2018, J AM ACAD AUDIOL, V29, P364, DOI 10.3766/jaaa.16130
   Moore DR, 2018, EAR HEARING, V39, P617, DOI 10.1097/AUD.0000000000000582
   MUSIEK FE, 1987, AUDIOLOGY, V26, P79
   Musiek Frank E, 2005, Am J Audiol, V14, P128, DOI 10.1044/1059-0889(2005/014)
   Neijenhuis KAM, 2001, AUDIOLOGY, V40, P69
   Rashid SKMU, 2018, INT J PEDIATR OTORHI, V114, P51, DOI 10.1016/j.ijporl.2018.07.054
   Rhee J, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0209254
   Sardone R, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00619
   Shargorodsky J, 2010, JAMA-J AM MED ASSOC, V304, P772, DOI 10.1001/jama.2010.1124
   SPEAKS C, 1985, J SPEECH HEAR RES, V28, P16, DOI 10.1044/jshr.2801.16
   장현숙, 2016, [The Journal of Inclusive Education, 통합교육연구], V11, P167
NR 35
TC 1
Z9 1
U1 0
U2 0
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD JUN 22
PY 2020
VL 10
IS 1
AR 10118
DI 10.1038/s41598-020-67033-2
PG 8
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA MD4VK
UT WOS:000543969500019
PM 32572114
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Kang, Y
   Schertz, J
AF Kang, Yoonjung
   Schertz, Jessamyn
TI The influence of perceived L2 sound categories in on-line adaptation and
   implications for loanword phonology
SO NATURAL LANGUAGE & LINGUISTIC THEORY
LA English
DT Article; Early Access
DE Loanwords; Cross-language perception; Korean; English
ID KOREAN STOPS; PERCEPTION; ENGLISH; 1ST; IDENTIFICATION; PRESERVATION;
   EXPERIENCE; CONTRAST; JAPANESE; VOWELS
AB Some propose that loanword adaptation is at its core non-native perception of foreign input (Boersma and Hamann2009; Peperkamp et al.2008; Silverman1992). It has also been noted, however, that cross-language correspondences in loanwords are far more consistent than expected based on on-line perception by naive monolinguals. There is also evidence that cross-language perception itself differs depending on adapters' experience with the source language (henceforth, L2) (Bundgaard-Nielsen et al.2011; Kwon2017; Nomura and Ishikawa2018). These findings suggest that cross-language perception is mediated by adapters' knowledge of L2 sound structure, rather than a simple function of native language (L1) perception applied to L2 acoustic signals. The current study presents a direct test of the influence of L1 vs. L2 perceptual strategies on cross-language speech perception through a series of phonetic categorization experiments in three language modes: L1, L2, and L2L1 (cross-language). Results point to a distinct influence of listener's L2 knowledge on cross-language perception: L2L1 mapping was well explained by listeners' L2 perceptual strategies, and for those listeners who showed different perceptual patterns for L1 and L2, cross-language perception more closely mirrored L2 than L1 perception. By demonstrating that perceived L2 phonological categories shape cross-language perception, the study suggests a way to reconcile the perceptual view of loanword adaptation with the phonological regularity of established loanwords.
C1 [Kang, Yoonjung] Univ Toronto Scarborough, Ctr French & Linguist, Toronto, ON, Canada.
   [Kang, Yoonjung; Schertz, Jessamyn] Univ Toronto, Dept Linguist, Toronto, ON, Canada.
   [Schertz, Jessamyn] Univ Toronto Mississauga, Dept Language Studies, Mississauga, ON, Canada.
RP Kang, Y (corresponding author), Univ Toronto Scarborough, Ctr French & Linguist, Toronto, ON, Canada.; Kang, Y (corresponding author), Univ Toronto, Dept Linguist, Toronto, ON, Canada.
FU SSHRCSocial Sciences and Humanities Research Council of Canada (SSHRC)
   [435-2013-2092]
FX This research was supported by SSHRC Grant #435-2013-2092 to Yoonjung
   Kang. The authors would like to thank Dr. Sungwoo Han, Yunyan Luo, and
   Yuanyang Song for their assistance with data collection. The paper
   benefited from the comments from the associate editor, the reviewers,
   and the audience at the 2016 Annual Meeting on Phonology at USC and the
   Workshop on the Phonetics and Phonology in Loanword Adaptation held at
   Cologne in 2017.
CR Ahn S, 2017, LANG LEARN, V67, P694, DOI 10.1111/lang.12252
   [Anonymous], 2016, R A LANG ENV STAT CO
   Bates Douglas, 2017, LME4 PACKAGE VERSION
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P, 2009, AMST STUD THEORY HIS, V307, P11
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Bundgaard-Nielsen RL, 2011, STUD SECOND LANG ACQ, V33, P433, DOI 10.1017/S0272263111000040
   Chang CB, 2015, SEGMENT IN PHONETICS AND PHONOLOGY, P199
   Cho TH, 2002, J PHONETICS, V30, P193, DOI 10.1006/jpho.2001.0153
   de Jong Kenneth, 2012, LANG VAR CHANGE, V3, P88
   De Rosario-Martinez Helios, 2015, PHIA PACKAGE VERSION
   Dohlus K., 2005, ZAS PAPERS LINGUISTI, V42, P117
   Dupoux E, 1999, J EXP PSYCHOL HUMAN, V25, P1568, DOI 10.1037/0096-1523.25.6.1568
   Eun-Jong Kong, 2013, [Phonetics and Speech Sciences, 말소리와 음성과학], V5, P81, DOI 10.13064/KSSS.2013.5.4.081
   Glover GH, 2012, MAGN RESON IMAGING, V30, P1, DOI 10.1016/j.mri.2011.07.019
   Hamann Silke, 2016, LINGUISTICS AMSTERDA, V9, P56
   Haugen E, 1950, LANGUAGE, V26, P210, DOI 10.2307/410058
   Heffernan K, 2007, J EAST ASIAN LINGUIS, V16, P61, DOI 10.1007/s10831-006-9007-8
   Holliday JJ, 2016, PHONETICA, V73, P33, DOI 10.1159/000443312
   Ito C, 2014, NAT LANG LINGUIST TH, V32, P537, DOI 10.1007/s11049-013-9211-y
   Ito Chiyuki, 2006, MIT WORKING PAPERS L, V52, P65
   Kang Y., 2008, HARVARD STUDIES KORE, V12, P179
   Kang Y, 2008, LANG LINGUIST COMPAS, V2, P103, DOI 10.1111/j.1749-818x.2007.00040.x
   Kang YJ, 2014, J PHONETICS, V45, P76, DOI 10.1016/j.wocn.2014.03.005
   Kang Y, 2012, CATALAN J LINGUIST, V11, P41
   Kang YJ, 2010, PHONOLOGY, V27, P225, DOI 10.1017/S0952675710000114
   Kang Yoonjung, 2011, COMPANION PHONOLOGY, P2258, DOI [DOI 10.1002/9781444335262.WBCTP0095, DOI 10.1002/9781444335262]
   Kang Yoonjung, 2003, PHONOLOGY, V20, P219, DOI DOI 10.1017/S0952675703004524
   Kenstowicz M, 2007, LANG SCI, V29, P316, DOI 10.1016/j.langsci.2006.12.023
   Kenstowicz Michael, 2005, P 1 EUR C KOR LING
   Kim Hyoju, 2016, CONTEXTUAL DISTRIBUT, V22, P245
   Kwon H, 2017, J PHONETICS, V60, P1, DOI 10.1016/j.wocn.2016.10.001
   LaCharite D, 2005, LINGUIST INQ, V36, P223, DOI 10.1162/0024389053710666
   Lee CH, 2009, APPL PHYS EXPRESS, V2, DOI 10.1143/APEX.2.032402
   Levy ES, 2009, J ACOUST SOC AM, V125, P1138, DOI 10.1121/1.3050256
   Mira Oh, 2017, [The Linguistic Association of Korea Journal, 언어학], V25, P121, DOI 10.24303/lakdoi.2017.25.2.121
   Nomura J, 2018, INT J BILINGUAL, V22, P69, DOI 10.1177/1367006916654997
   Oh Mira, 2009, SIMON FRASER U WORKI, V2
   Paradis C, 1997, J LINGUIST, V33, P379, DOI 10.1017/S0022226797006786
   Park H, 2008, J PHONETICS, V36, P704, DOI 10.1016/j.wocn.2008.06.002
   Peperkamp S, 2008, PHONOLOGY, V25, P129, DOI 10.1017/S0952675708001425
   Schertz Jessamyn, 2014, THESIS
   Schmid MS, 2013, WIRES COGN SCI, V4, P117, DOI 10.1002/wcs.1218
   Schmidt AM, 1996, J ACOUST SOC AM, V99, P3201, DOI 10.1121/1.414804
   Silva D. J., 2006, PHONOLOGY, V23, P287, DOI DOI 10.1017/S0952675706000911
   Silverman Daniel, 1992, PHONOLOGY, V9, P289, DOI DOI 10.1017/S0952675700001627
   Smith J., 2006, JAPANESE KOREAN LING, V14, P63
   Smith Jennifer L., 2009, PHONOLOGICAL ARGUMEN, P177
   Steriade D., 2001, PHONOLOGY PERCEPTIBI
   Strange W, 2011, J PHONETICS, V39, P456, DOI 10.1016/j.wocn.2010.09.001
   Tice M., 2012, PAGUETTES BASTRIES N, V2012, P72
   Vendelin I, 2006, LINGUA, V116, P996, DOI 10.1016/j.lingua.2005.07.005
   Yun S., 2016, THESIS
NR 54
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0167-806X
EI 1573-0859
J9 NAT LANG LINGUIST TH
JI Nat. Lang. Linguist. Theory
DI 10.1007/s11049-020-09477-9
EA JUN 2020
PG 24
WC Linguistics; Language & Linguistics
SC Linguistics
GA MA7IP
UT WOS:000542086500001
DA 2021-02-24
ER

PT J
AU Emmendorfer, AK
   Correia, JM
   Jansma, BM
   Kotz, SA
   Bonte, M
AF Emmendorfer, Alexandra K.
   Correia, Joao M.
   Jansma, Bernadette M.
   Kotz, Sonja A.
   Bonte, Milene
TI ERP mismatch response to phonological and temporal regularities in
   speech
SO SCIENTIFIC REPORTS
LA English
DT Article
ID PHONOTACTIC PROBABILITY; DEVELOPMENTAL DYSLEXIA; CORTICAL OSCILLATIONS;
   BRAIN POTENTIALS; VOCABULARY SIZE; LEXICAL STRESS; PERCEPTION; CUES;
   CHILDREN; METER
AB Predictions of our sensory environment facilitate perception across domains. During speech perception, formal and temporal predictions may be made for phonotactic probability and syllable stress patterns, respectively, contributing to the efficient processing of speech input. The current experiment employed a passive EEG oddball paradigm to probe the neurophysiological processes underlying temporal and formal predictions simultaneously. The component of interest, the mismatch negativity (MMN), is considered a marker for experience-dependent change detection, where its timing and amplitude are indicative of the perceptual system's sensitivity to presented stimuli. We hypothesized that more predictable stimuli (i.e. high phonotactic probability and first syllable stress) would facilitate change detection, indexed by shorter peak latencies or greater peak amplitudes of the MMN. This hypothesis was confirmed for phonotactic probability: high phonotactic probability deviants elicited an earlier MMN than low phonotactic probability deviants. We do not observe a significant modulation of the MMN to variations in syllable stress. Our findings confirm that speech perception is shaped by formal and temporal predictability. This paradigm may be useful to investigate the contribution of implicit processing of statistical regularities during (a)typical language development.
C1 [Emmendorfer, Alexandra K.; Correia, Joao M.; Jansma, Bernadette M.; Bonte, Milene] Maastricht Univ, Fac Psychol & Neurosci, Dept Cognit Neurosci, Maastricht, Netherlands.
   [Emmendorfer, Alexandra K.; Correia, Joao M.; Jansma, Bernadette M.; Bonte, Milene] Maastricht Univ, Fac Psychol & Neurosci, Maastricht Brain Imaging Ctr, Maastricht, Netherlands.
   [Emmendorfer, Alexandra K.; Kotz, Sonja A.] Maastricht Univ, Fac Psychol & Neurosci, Dept Neuropsychol & Psychopharmacol, Maastricht, Netherlands.
   [Correia, Joao M.] Univ Algarve, Dept Psychol, Ctr Biomed Res CBMR, Faro, Portugal.
RP Emmendorfer, AK (corresponding author), Maastricht Univ, Fac Psychol & Neurosci, Dept Cognit Neurosci, Maastricht, Netherlands.; Emmendorfer, AK (corresponding author), Maastricht Univ, Fac Psychol & Neurosci, Maastricht Brain Imaging Ctr, Maastricht, Netherlands.; Emmendorfer, AK (corresponding author), Maastricht Univ, Fac Psychol & Neurosci, Dept Neuropsychol & Psychopharmacol, Maastricht, Netherlands.
EM a.emmendorfer@maastrichtuniversity.nl
RI Emmendorfer, Alexandra/AAE-8174-2021
OI Jansma, Bernadette M./0000-0002-2925-0244
FU Maastricht University; Netherlands Organization for Scientific Research
   (Vidi-Grant)Netherlands Organization for Scientific Research (NWO)
   [452-16-004]
FX This research was supported by Maastricht University (Grant to BMJ to
   support women in higher academic positions) and The Netherlands
   Organization for Scientific Research (Vidi-Grant 452-16-004 to MB). The
   authors would like to thank Anna Bolhuis, Joelle Schroen, Helena
   Votterl, and Manli Zhang for their assistance with data collection.
CR AALTONEN O, 1987, BIOL PSYCHOL, V24, P197, DOI 10.1016/0301-0511(87)90002-0
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Auer ET, 2005, BLACKW HBK LINGUIST, P610, DOI 10.1002/9780470757024.ch25
   Baayen R., 2001, WEBCELEX
   Blomert L, 2011, NEUROIMAGE, V57, P695, DOI 10.1016/j.neuroimage.2010.11.003
   Boersma P., 2013, PRAAT DOING PHONETIC
   Bonte ML, 2007, NEUROPSYCHOLOGIA, V45, P1427, DOI 10.1016/j.neuropsychologia.2006.11.009
   Bonte ML, 2005, CLIN NEUROPHYSIOL, V116, P2765, DOI 10.1016/j.clinph.2005.08.012
   Cramer AOJ, 2016, PSYCHON B REV, V23, P640, DOI 10.3758/s13423-015-0913-5
   Cutler A, 2005, LEXICAL STRESS
   Delorme A, 2007, NEUROIMAGE, V34, P1443, DOI 10.1016/j.neuroimage.2006.11.004
   Edwards J, 2004, J SPEECH LANG HEAR R, V47, P421, DOI 10.1044/1092-4388(2004/034)
   Engel AK, 2001, NAT REV NEUROSCI, V2, P704, DOI 10.1038/35094565
   Friston KJ, 2012, INT J PSYCHOPHYSIOL, V83, P248, DOI 10.1016/j.ijpsycho.2011.11.014
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Honbolygo F, 2004, NEUROSCI LETT, V363, P84, DOI 10.1016/j.neulet.2004.03.057
   Honbolygo F, 2013, INT J PSYCHOPHYSIOL, V87, P165, DOI 10.1016/j.ijpsycho.2012.12.005
   Jusczyk PW, 1999, COGNITIVE PSYCHOL, V39, P159, DOI 10.1006/cogp.1999.0716
   Kassambara A., 2019, RSTATIX PIPE FRIENDL
   Kotz S. A., 2016, NEUROBIOLOGY LANGUAG, P717, DOI [10.1016/B978-0-12-407794-2.00057-2, DOI 10.1016/B978-0-12-407794-2.00057-2]
   Kotz SA, 2010, TRENDS COGN SCI, V14, P392, DOI 10.1016/j.tics.2010.06.005
   Ladanyi E, 2020, WIRES COGN SCI, V11, DOI 10.1002/wcs.1528
   Lallier M, 2017, CLIN PSYCHOL SCI, V5, P379, DOI 10.1177/2167702616670119
   Luce PA, 2001, LANG COGNITIVE PROC, V16, P565, DOI 10.1080/01690960143000137
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1
   Mattys SL, 2001, COGNITION, V78, P91, DOI 10.1016/S0010-0277(00)00109-8
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Munson B, 2005, J SPEECH LANG HEAR R, V48, P1033, DOI 10.1044/1092-4388(2005/072)
   Munson B, 2005, J SPEECH LANG HEAR R, V48, P61, DOI 10.1044/1092-4388(2005/006)
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9
   Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037/0096-1523.24.3.756
   Noordenbos MW, 2013, NEUROREPORT, V24, P746, DOI 10.1097/WNR.0b013e328364b67c
   Port RF, 2003, J PHONETICS, V31, P599, DOI 10.1016/j.wocn.2003.08.001
   Pulvermuller F, 2003, NEUROIMAGE, V20, P159, DOI 10.1016/S1053-8119(03)00261-1
   R Core Team, 2013, R LANG ENV STAT COMP
   Rago A, 2014, RES DEV DISABIL, V35, P192, DOI 10.1016/j.ridd.2013.10.006
   Ramus F, 2003, CURR OPIN NEUROBIOL, V13, P212, DOI 10.1016/S0959-4388(03)00035-7
   Ramus F, 2001, NATURE, V412, P393, DOI 10.1038/35086683
   Reichle ME, 2010, TRENDS COGN SCI, V14, P180, DOI 10.1016/j.tics.2010.01.008
   Rothermich K, 2012, NEUROPSYCHOLOGIA, V50, P232, DOI 10.1016/j.neuropsychologia.2011.10.025
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Schmidt-Kassow M, 2009, J COGNITIVE NEUROSCI, V21, P1693, DOI 10.1162/jocn.2008.21153
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   Snowling M., 2000, DYSLEXIA
   Storkel HL, 2006, J SPEECH LANG HEAR R, V49, P1175, DOI 10.1044/1092-4388(2006/085)
   Storkel HL, 2011, LANG COGNITIVE PROC, V26, P191, DOI 10.1080/01690961003787609
   Storkel HL, 2009, J CHILD LANG, V36, P291, DOI 10.1017/S030500090800891X
   Thiessen ED, 2003, DEV PSYCHOL, V39, P706, DOI 10.1037/0012-1649.39.4.706
   Thomson JM, 2008, J PHYSIOL-PARIS, V102, P120, DOI 10.1016/j.jphysparis.2008.03.007
   Thorn ASC, 2005, J EXP PSYCHOL LEARN, V31, P729, DOI 10.1037/0278-7393.31.4.729
   Tong XH, 2014, BRAIN LANG, V138, P61, DOI 10.1016/j.bandl.2014.09.004
   van Atteveldt NM, 2007, CEREB CORTEX, V17, P962, DOI 10.1093/cercor/bhl007
   Vitevitch MS, 1997, LANG SPEECH, V40, P47, DOI 10.1177/002383099704000103
   Vitevitch MS, 1999, J MEM LANG, V40, P374, DOI 10.1006/jmla.1998.2618
   Vitevitch MS, 2005, J MEM LANG, V52, P193, DOI 10.1016/j.jml.2004.10.003
   Vitevitch MS, 1998, PSYCHOL SCI, V9, P325, DOI 10.1111/1467-9280.00064
   Weber C, 2004, COGNITIVE BRAIN RES, V18, P149, DOI 10.1016/j.cogbrainres.2003.10.001
   Ylinen S, 2009, INT J PSYCHOPHYSIOL, V73, P362, DOI 10.1016/j.ijpsycho.2009.05.013
   Zora H, 2015, NEUROREPORT, V26, P791, DOI 10.1097/WNR.0000000000000426
NR 61
TC 0
Z9 0
U1 0
U2 0
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD JUN 18
PY 2020
VL 10
IS 1
AR 9917
DI 10.1038/s41598-020-66824-x
PG 12
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA MD4WZ
UT WOS:000543973600048
PM 32555256
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Kilpatrick, A
   Kawahara, S
   Bundgaard-Nielsen, R
   Baker, B
   Fletcher, J
AF Kilpatrick, Alexander
   Kawahara, Shigeto
   Bundgaard-Nielsen, Rikke
   Baker, Brett
   Fletcher, Janet
TI Japanese Perceptual Epenthesis is Modulated by Transitional Probability
SO LANGUAGE AND SPEECH
LA English
DT Article; Early Access
DE Perceptual epenthesis; transitional probability; surprisal; entropy;
   Japanese
ID REDUNDANCY; DURATION; VOWELS
AB Perceptual epenthesis is the perception of illusory vowels in consonantal sequences that violate native phonotactics. The consensus has been that each language has a single, predictable candidate for perceptual epenthesis, that vowel which is most minimal (i.e., shortest and/or quietest). However, recent studies have shown that alternate epenthetic vowels can be perceived when the perceptual epenthesis of the minimal vowel would violate native co-occurrence restrictions. We propose a potential explanation for these observed patterns: speech perception, and thus also vowel perceptual epenthesis, is modulated by transitional probability whereby epenthetic vowels must conform to the language specific expectations of the listener. To test this explanation, we present two experiments examining perceptual epenthesis of two Japanese vowels-/u/ and /i/-against their transitional probability in CV sequences. In Experiment 1, Japanese listeners assigned VCCV tokens to VCuCV and VCiCV categories. In Experiment 2, participants discriminated VCCV tokens from VCuCV and VCiCV tokens. The results show that sequences where /i/ is transitionally probable are more likely to elicit /i/ perceptual epenthesis.
C1 [Kilpatrick, Alexander; Baker, Brett; Fletcher, Janet] Univ Melbourne, Melbourne, Vic, Australia.
   [Kilpatrick, Alexander] Nagoya Univ Business & Commerce, Sagamine 4-4, Nagoya, Aichi, Japan.
   [Kawahara, Shigeto] Keio Univ, Tokyo 108, Japan.
   [Bundgaard-Nielsen, Rikke] Univ Newcastle, Newcastle Upon Tyne, Tyne & Wear, England.
   [Bundgaard-Nielsen, Rikke] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Sydney, NSW, Australia.
RP Kilpatrick, A (corresponding author), Nagoya Univ Business & Commerce, Sagamine 4-4, Nagoya, Aichi, Japan.
EM kilpatrickalex1@gmail.com
OI Kilpatrick, Alexander/0000-0003-3134-3797; Kilpatrick,
   Alex/0000-0003-4313-1126
CR Arai T., 2001, P SPRING M AC SOC JP, V1, P361
   Aylett M, 2004, LANG SPEECH, V47, P31, DOI 10.1177/00238309040470010201
   Aylett M, 2006, J ACOUST SOC AM, V119, P3048, DOI 10.1121/1.2188331
   Bell A, 2009, J MEM LANG, V60, P92, DOI 10.1016/j.jml.2008.06.003
   Best C. T., 1994, DEV SPEECH PERCEPT, V167, P224
   BEST CT, 1995, INFANT BEHAV DEV, V18, P339, DOI 10.1016/0163-6383(95)90022-5
   Bonatti L. L., 2010, PSYSCOPE X BUILD 77
   Campbell N., 1992, SPEECH PERCEPTION PR, P403
   Campbell Nick, 1999, J PHONETIC SOC JAPAN, V3, P29
   Cohen Priva U., 2012, THESIS
   Cutler A, 2009, J ACOUST SOC AM, V125, P1693, DOI 10.1121/1.3075556
   Dupoux E, 1999, J EXP PSYCHOL HUMAN, V25, P1568, DOI 10.1037/0096-1523.25.6.1568
   Dupoux E, 2011, J MEM LANG, V64, P199, DOI 10.1016/j.jml.2010.12.004
   Durvasula K, 2018, LAB PHONOL, V9, DOI 10.5334/labphon.57
   Durvasula K, 2015, PHONOLOGY, V32, P385, DOI 10.1017/S0952675715000263
   Fujimoto M, 2015, HANDB JAPAN LANG, V2, P167
   Guevara-Rukoz A, 2017, J ACOUST SOC AM, V142, pEL211, DOI 10.1121/1.4998138
   Hume Elizabeth, 2016, PHONOLOGICAL STUDIES, V19, P107
   ITO J, 1989, NAT LANG LINGUIST TH, V7, P217, DOI 10.1007/BF00138077
   Kawahara S., 2004, P NELS, P295
   Kilpatrick A., 2018, 17 AUSTR INT C SPEEC
   Kilpatrick A., 2016, 16 AUSTR INT C SPEEC
   Kilpatrick AJ, 2019, APPL PSYCHOLINGUIST, V40, P585, DOI 10.1017/S0142716418000711
   Kubozono H, 2015, HANDB JAPAN LANG, V2, P313
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Maekawa K., 1989, NIHON GO ONSEI ON IN, P135
   Maekawa K., 2003, ISCA IEEE WORKSH SPO, P7
   Maekawa K, 2005, STUD GENERA GRAMMAR, V84, P205
   Mattingley W., 2015, P 18 INT C PHON SCI
   Monahan P. J., 2009, JAP KOR LING, V17, P391
   Nishi K, 2008, J ACOUST SOC AM, V124, P576, DOI 10.1121/1.2931949
   Priva UC, 2015, LAB PHONOL, V6, P243, DOI 10.1515/lp-2015-0008
   Sagisaka Y., 1984, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part A, VJ67A, P629
   Shannon C. E., 1948, THESIS
   Shaw J, 2018, LINGUIST VANGUARD, V4, DOI 10.1515/lingvan-2018-0042
   Shaw JA, 2019, LANG SPEECH, V62, P80, DOI 10.1177/0023830917737331
   Shaw JA, 2018, J PHONETICS, V66, P100, DOI 10.1016/j.wocn.2017.09.007
   Tsuchida A., 1997, THESIS
   WERKER JF, 1984, J ACOUST SOC AM, V75, P1866, DOI 10.1121/1.390988
   Whang J, 2018, J ACOUST SOC AM, V143, P1159, DOI 10.1121/1.5024893
   Zipf C. K., 1948, HUMAN BEHAV PRINCIPL
NR 41
TC 0
Z9 0
U1 0
U2 0
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
AR 0023830920930042
DI 10.1177/0023830920930042
EA JUN 2020
PG 21
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA MB2DK
UT WOS:000542414900001
PM 32539534
DA 2021-02-24
ER

PT J
AU Wanrooij, K
   Raijmakers, MEJ
AF Wanrooij, Karin
   Raijmakers, Maartje E. J.
TI Evidence for immature perception in adolescents: Adults process reduced
   speech better and faster than 16-year olds
SO LANGUAGE ACQUISITION
LA English
DT Article
ID SPOKEN WORD RECOGNITION; SEMANTIC CONTEXT; YOUNG-CHILDREN; INFANTS;
   REPRESENTATION; RESTORATION; UNITS
AB Previous work suggests that adolescents are still refining acoustic-phonetic cue use in clear-speech perception. This study shows adolescents' immature perception of reduced speech, in which speech sounds are naturally deleted and merged within and across words. German adults and 16-year-olds listened to either German reduced or unreduced (few or full cues) part- and full phrases (without and with context) in a phrase-intelligibility task. As expected, adolescents had lower scores when adequate perception required flexible acoustic-phonetic cue use most, i.e., when hearing reduced speech without context. Participants also listened to reduced and unreduced words and pseudowords (no context) in a lexical decision task. Here, 16-year-olds had poorer and slower responses than adults overall and particularly when hearing pseudowords. Explanations for the age effects are discussed. We conclude that experience continues to refine linguistic representations, at least until adulthood.
C1 [Wanrooij, Karin] Leiden Univ, Leiden, Netherlands.
   [Raijmakers, Maartje E. J.] Vrije Univ Amsterdam, Amsterdam, Netherlands.
RP Wanrooij, K (corresponding author), Leiden Univ, Educ Sci, NL-2333 AK Leiden, Netherlands.
EM karin.wanrooij@hotmail.com
OI Raijmakers, Maartje/0000-0003-1843-6462
FU Nationaal Regieorgaan Onderwijsonderzoek' (Netherlands Initiative for
   Education Research) [405-16-382]
FX This work was supported by the 'Nationaal Regieorgaan
   Onderwijsonderzoek' (Netherlands Initiative for Education Research)
   [grant 405-16-382 awarded to the first author].
CR Andringa S, 2012, LANG LEARN, V62, P49, DOI 10.1111/j.1467-9922.2012.00706.x
   ANDRUSKI JE, 1994, COGNITION, V52, P163, DOI 10.1016/0010-0277(94)90042-6
   BEST CT, 1995, INFANT BEHAV DEV, V18, P339, DOI 10.1016/0163-6383(95)90022-5
   Boersma Paul, 1998, PRAAT DOING PHONETIC
   Boersma Paul., 1998, LOT DISSERTATION SER
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Brown J.D., 2006, PERSPECTIVES TEACHIN
   Brown J. D., 1986, RELC J, V17, P59, DOI DOI 10.1177/003368828601700204
   Buckler H, 2018, J PHONETICS, V66, P45, DOI 10.1016/j.wocn.2017.09.004
   Bybee J., 1999, FUNCTIONALISM FORMAL, P211, DOI DOI 10.1075/SLCS.41.12BYB
   COLE RA, 1980, J VERB LEARN VERB BE, V19, P297, DOI 10.1016/S0022-5371(80)90239-X
   Connine CM, 2008, PERCEPT PSYCHOPHYS, V70, P403, DOI 10.3758/PP.70.3.403
   Crone EA, 2017, TRENDS COGN SCI, V21, P205, DOI 10.1016/j.tics.2017.01.003
   Darcy I, 2009, PHONOL PHONET, V14, P265
   Diamond A, 2013, ANNU REV PSYCHOL, V64, P135, DOI 10.1146/annurev-psych-113011-143750
   Drijvers L, 2016, BRAIN LANG, V153, P27, DOI 10.1016/j.bandl.2016.01.003
   ELLIOTT LL, 1979, J ACOUST SOC AM, V66, P651, DOI 10.1121/1.383691
   Erickson LC, 2017, CURR DIR PSYCHOL SCI, V26, P451, DOI 10.1177/0963721417709087
   Ernestus M, 2002, BRAIN LANG, V81, P162, DOI 10.1006/brln.2001.2514
   Ernestus M, 2011, J PHONETICS, V39, P253, DOI 10.1016/S0095-4470(11)00055-6
   Ernestus M, 2017, DUTCH J APPL LINGUIS, V6, P1, DOI 10.1075/dujal.6.1.01ern
   Ernestus Mirjam., 2000, THESIS
   Fernald A, 1998, PSYCHOL SCI, V9, P228, DOI 10.1111/1467-9280.00044
   Fernald A, 2006, DEV PSYCHOL, V42, P98, DOI 10.1037/0012-1649.42.1.98
   Fernald A, 2001, CHILD DEV, V72, P1003, DOI 10.1111/1467-8624.00331
   Field J., 2003, ELT J, V57, P325, DOI DOI 10.1093/ELT/57.4.325
   FLEGE JE, 1986, PHONETICA, V43, P155, DOI 10.1159/000261768
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   HENRICHSEN LE, 1984, LANG LEARN, V34, P103, DOI 10.1111/j.1467-1770.1984.tb00343.x
   HIRSHPASEK K, 1987, COGNITION, V26, P269, DOI 10.1016/S0010-0277(87)80002-1
   Holley-Wilcox P., 1977, M MIDW PSYCH ASS
   Huizinga M, 2006, NEUROPSYCHOLOGIA, V44, P2017, DOI 10.1016/j.neuropsychologia.2006.01.010
   Hurtado N, 2008, DEVELOPMENTAL SCI, V11, pF31, DOI 10.1111/j.1467-7687.2008.00768.x
   IPDS, 1996, KIEL CORP SPONT SPEE, V2
   IPDS, 1997, KIEL CORP SPONT SPEE, V3
   IPDS (Institut fur Phonetik und digitale Sprachverarbeitung der Christian-Albrechts-Universitat zu Kiel), 1995, KIEL CORP SPONT SPEE, V1
   Janse E, 2011, J PHONETICS, V39, P330, DOI 10.1016/j.wocn.2011.03.005
   Johnson TA, 2004, COASTAL AQUIFER MANAGEMENT: MONITORING, MODELING, AND CASE STUDIES, P29
   JUSCZYK PW, 1987, DEV PSYCHOL, V23, P648, DOI 10.1037/0012-1649.23.5.648
   JUSCZYK PW, 1992, COGNITIVE PSYCHOL, V24, P252, DOI 10.1016/0010-0285(92)90009-Q
   KAIL R, 1991, PSYCHOL BULL, V109, P490, DOI 10.1037/0033-2909.109.3.490
   Kapnoula EC, 2017, J EXP PSYCHOL HUMAN, V43, P1594, DOI 10.1037/xhp0000410
   Karmiloff-Smith A, 2006, COGN AFFECT BEHAV NE, V6, P9, DOI 10.3758/CABN.6.1.9
   Kohler K., 1998, ZAS WORKING PAPERS L, V11, P21
   Kohler K. J., 2001, J INT PHON ASSOC, V31, P1
   KOHLER KJ, 1990, NATO ADV SCI I D-BEH, V55, P69
   Kong EJ, 2016, J PHONETICS, V59, P40, DOI 10.1016/j.wocn.2016.08.006
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   MacDonald MC, 2002, PSYCHOL REV, V109, P35, DOI 10.1037//0033-295X.109.1.35
   Maekawa K, 2005, STUD GENERA GRAMMAR, V84, P205
   Marchman VA, 2010, J CHILD LANG, V37, P817, DOI 10.1017/S0305000909990055
   MARSLENWILSON W, 1990, ACL MIT NAT, P148
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X
   Mattys SL, 2005, J EXP PSYCHOL GEN, V134, P477, DOI 10.1037/0096-3445.134.4.477
   Mayo LH, 1997, J SPEECH LANG HEAR R, V40, P686, DOI 10.1044/jslhr.4003.686
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McCusker Leo X., 1979, M SW PSYCH ASS APR
   MCCUSKER LX, 1981, PSYCHOL BULL, V89, P217, DOI 10.1037/0033-2909.89.2.217
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B, 2018, DEV PSYCHOL, V54, P1472, DOI 10.1037/dev0000542
   Metsala JL, 1998, WORD RECOGNITION IN BEGINNING LITERACY, P89
   Mitterer H, 2006, COGNITIVE SCI, V30, P451, DOI 10.1207/s15516709cog0000_57
   Mitterer H, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00249
   Mitterer H, 2011, J PHONETICS, V39, P298, DOI 10.1016/j.wocn.2010.11.009
   Mitterer Holger., 2008, P ISCA TUT RES WORKS
   Miyake A, 2000, COGNITIVE PSYCHOL, V41, P49, DOI 10.1006/cogp.1999.0734
   Morano Lisa, 2015, P 18 INT C PHON SCI
   Myers J, 1996, J CHILD LANG, V23, P1, DOI 10.1017/S0305000900010072
   Nazzi T, 2000, J MEM LANG, V43, P1, DOI 10.1006/jmla.2000.2698
   Newman RS, 2006, PERCEPT PSYCHOPHYS, V68, P625, DOI 10.3758/BF03208764
   Newman RS, 2004, APPL PSYCHOLINGUIST, V25, P481, DOI 10.1017/s0142716404001237
   Newton C, 2002, J CHILD LANG, V29, P275, DOI 10.1017/S0305000902005044
   Niebuhr O, 2011, J PHONETICS, V39, P319, DOI 10.1016/j.wocn.2010.12.003
   Nittrouer S, 1997, J ACOUST SOC AM, V101, P2253, DOI 10.1121/1.418207
   Nittrouer S, 2000, PERCEPT PSYCHOPHYS, V62, P266, DOI 10.3758/BF03205548
   NITTROUER S, 1990, J ACOUST SOC AM, V87, P2705, DOI 10.1121/1.399061
   Norris R. W., 1995, ENGLISH TEACHING FOR, V33, P47
   Pitt MA, 2011, J PHONETICS, V39, P304, DOI 10.1016/j.wocn.2010.07.004
   Poelmans Petra., 2003, THESIS
   Ranbom LJ, 2007, J MEM LANG, V57, P273, DOI 10.1016/j.jml.2007.04.001
   Rigler H, 2015, DEV PSYCHOL, V51, P1690, DOI 10.1037/dev0000044
   Rosenthal R., 1991, METAANALYTIC PROCEDU
   Sekerina IA, 2007, J EXP CHILD PSYCHOL, V98, P20, DOI 10.1016/j.jecp.2007.04.005
   Shockey L., 2003, SOUND PATTERNS SPOKE
   Skoruppa K, 2013, INFANCY, V18, P1007, DOI 10.1111/infa.12020
   Skoruppa K, 2013, CHILD DEV, V84, P313, DOI 10.1111/j.1467-8624.2012.01845.x
   Smiljanic R, 2013, J SPEECH LANG HEAR R, V56, P1085, DOI 10.1044/1092-4388(2012/12-0097)
   Smiljanic R, 2009, LANG LINGUIST COMPAS, V3, P236, DOI 10.1111/j.1749-818x.2008.00112.x
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Taitelbaum-Swead R, 2016, CLIN LINGUIST PHONET, V30, P531, DOI 10.3109/02699206.2016.1151938
   Ten Bosch Louis, 2016, ERRORS HUMANS MACHIN
   Teruaki Osamu Takizawa, 1994, INT C SPOK LANG PROC
   Thompson J, 2007, CLIN LINGUIST PHONET, V21, P895, DOI 10.1080/02699200701600221
   Tomasello M., 1992, 1 VERBS CASE STUDY E
   Tomasello M, 2009, CAMB HB LANG LINGUIS, P69
   Torreira F., 2011, LAB PHONOLOGY, V2, P331, DOI DOI 10.1515/LABPHON.2011.012
   Tucker BV, 2011, J PHONETICS, V39, P312, DOI 10.1016/j.wocn.2010.12.001
   van de Ven M, 2011, MEM COGNITION, V39, P1301, DOI 10.3758/s13421-011-0103-2
   van der Feest SVH, 2019, J PHONETICS, V73, P158, DOI 10.1016/j.wocn.2019.01.003
   WALLEY AC, 1988, COGNITIVE DEV, V3, P137, DOI 10.1016/0885-2014(88)90016-0
   Walley AC., 2003, READING WRITING, V16, P5, DOI [DOI 10.1023/A:1021789804977, 10.1023/A:1021789804977]
   Wanrooij Karin, HAMA REDUCED PRONUNC
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Werner LA, 2007, J COMMUN DISORD, V40, P275, DOI 10.1016/j.jcomdis.2007.03.004
   Wong SWL, 2017, TESOL QUART, V51, P7, DOI 10.1002/tesq.273
   Zukowski A, 2011, LANG ACQUIS, V18, P211, DOI 10.1080/10489223.2011.605043
NR 108
TC 0
Z9 0
U1 1
U2 1
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1048-9223
EI 1532-7817
J9 LANG ACQUIS
JI Lang. Acquisition
PD OCT 1
PY 2020
VL 27
IS 4
BP 434
EP 459
DI 10.1080/10489223.2020.1769627
EA JUN 2020
PG 26
WC Linguistics; Language & Linguistics
SC Linguistics
GA NT6PK
UT WOS:000547643200001
OA Bronze
DA 2021-02-24
ER

PT J
AU Baldwin, DA
   Kosie, JE
AF Baldwin, Dare A.
   Kosie, Jessica E.
TI How Does the Mind Render Streaming Experience as Events?
SO TOPICS IN COGNITIVE SCIENCE
LA English
DT Article; Early Access
DE Event processing; Event segmentation; Information optimization;
   Learning; Predictive learning
ID SPEECH-PERCEPTION; DIRECTED SPEECH; INFANTS ABILITY; MOTHERS SPEECH;
   SEGMENTATION; MEMORY; LANGUAGE; PREDICTION; SEQUENCES; INFERENCE
AB Events-the experiences we think we are having and recall having had-are constructed; they are not what actually occurs. What occurs is ongoing dynamic, multidimensional, sensory flow, which is somehow transformed via psychological processes into structured, describable, memorable units of experience. But what is the nature of the redescription processes that fluently render dynamic sensory streams as event representations? How do such processes cope with the ubiquitous novelty and variability that characterize sensory experience? How are event-rendering skills acquired and how do event representations change with development? This review considers emerging answers to these questions, beginning with evidence that an implicit tendency to monitor predictability structure via statistical learning is key to event rendering. That is, one way that the experience of bounded events (e.g., actions within behavior, words within speech) arises is with the detection of "troughs" in sensory predictability. Interestingly, such troughs in predictability are often predictable; these regions of predictable-unpredictability provide articulation points to demarcate one event from another in representations derived from the actual streaming information. In our information-optimization account, a fluent event-processor predicts such troughs and selectively attends to them-while suppressing attention to other regions-as sensory streams unfold. In this way, usage of attentional resources is optimized for efficient sampling of the most relevant, information-rich portions of the unfolding flow of sensation. Such findings point to the development of event-processing fluency-whether in action, language, or other domains-depending crucially on rapid and continual cognitive reorganization. As knowledge of predictability grows, attention is adaptively redeployed. Accordingly, event experiences undergo continuous alteration.
C1 [Baldwin, Dare A.; Kosie, Jessica E.] Univ Oregon, Dept Psychol, Eugene, OR 97403 USA.
RP Baldwin, DA (corresponding author), Univ Oregon, Dept Psychol, Eugene, OR 97403 USA.
EM baldwin@uoregon.edu
CR Alexander WH, 2017, J COGNITIVE NEUROSCI, V29, P1674, DOI 10.1162/jocn_a_01138
   Ambrosini E, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067916
   Asch S. E., 1952, SOCIAL PSYCHOL
   Astheimer LB, 2011, NEUROPSYCHOLOGIA, V49, P3512, DOI 10.1016/j.neuropsychologia.2011.08.014
   AVRAHAMI J, 1994, COGNITION, V53, P239, DOI 10.1016/0010-0277(94)90050-7
   Bailey HR, 2013, NEUROPSYCHOLOGIA, V51, P2294, DOI 10.1016/j.neuropsychologia.2013.06.022
   Baldassano C, 2017, NEURON, V95, P709, DOI 10.1016/j.neuron.2017.06.041
   Baldwin D, 2005, DEVELOPMENT OF SOCIAL COGNITION AND COMMUNICATION, P117
   Baldwin D., 2012, NAVIGATING SOCIAL WO, P170
   Baldwin D., 2011, ANN REV M OFF NAC RE
   Baldwin D. A., 2002, EVOLUTION LANGUAGE O, P285, DOI [10.1075/tsl.53.15bal, DOI 10.1075/TSL.53.15BAL]
   Baldwin DA, 1999, EARLY SOCIAL COGNITION, P215
   Baldwin DA, 2001, CHILD DEV, V72, P708, DOI 10.1111/1467-8624.00310
   Baldwin DA, 2001, TRENDS COGN SCI, V5, P171, DOI 10.1016/S1364-6613(00)01615-6
   Baldwin DA, 1996, CHILD DEV, V67, P3135, DOI 10.1111/j.1467-8624.1996.tb01906.x
   Baldwin D, 2008, COGNITION, V106, P1382, DOI 10.1016/j.cognition.2007.07.005
   Baldwin D, 2013, SOCIAL PERCEPTION: DETECTION AND INTERPRETATION OF ANIMACY, AGENCY, AND INTENTION, P309
   Barrett LF, 2017, SOC COGN AFFECT NEUR, V12, P1, DOI 10.1093/scan/nsw154
   Barrett LF, 2015, NAT REV NEUROSCI, V16, P419, DOI 10.1038/nrn3950
   Belardinelli A, 2018, COGNITION, V176, P65, DOI 10.1016/j.cognition.2018.03.007
   Bilkey DK, 2019, TOP COGN SCI, DOI 10.1111/tops.12470
   Brand RJ, 2008, DEVELOPMENTAL SCI, V11, P853, DOI 10.1111/j.1467-7687.2008.00734.x
   Brand RJ, 2007, INFANCY, V11, P321, DOI 10.1111/j.1532-7078.2007.tb00230.x
   Brand RJ, 2013, IEEE T AUTON MENT DE, V5, P192, DOI 10.1109/TAMD.2013.2273057
   Brand RJ, 2002, DEVELOPMENTAL SCI, V5, P72, DOI 10.1111/1467-7687.00211
   BRANSFORD JD, 1971, COGNITIVE PSYCHOL, V2, P331, DOI 10.1016/0010-0285(71)90019-3
   Braver T.S., 2007, VARIATION WORKING ME, P76, DOI DOI 10.1093/ACPROF:OSO/9780195168648.003.0004
   Brunec IK, 2018, TRENDS COGN SCI, V22, P637, DOI 10.1016/j.tics.2018.03.013
   Buchsbaum D, 2015, COGNITIVE PSYCHOL, V76, P30, DOI 10.1016/j.cogpsych.2014.10.001
   Cassimatis NL, 2006, AI MAG, V27, P45
   Chekaf M, 2016, COGNITION, V155, P96, DOI 10.1016/j.cognition.2016.05.024
   Chen C., 2019, ARXIV190209006
   Christiansen MH, 2019, TOP COGN SCI, V11, P468, DOI 10.1111/tops.12332
   Christiansen MH, 2016, BEHAV BRAIN SCI, V39, DOI 10.1017/S0140525X1500031X
   Clewett D, 2017, CURR OPIN BEHAV SCI, V17, P186, DOI 10.1016/j.cobeha.2017.08.013
   COOPER RP, 1990, CHILD DEV, V61, P1584, DOI 10.1111/j.1467-8624.1990.tb02885.x
   Craig AD, 2002, NAT REV NEUROSCI, V3, P655, DOI 10.1038/nrn894
   Diamond A, 2013, ANNU REV PSYCHOL, V64, P135, DOI 10.1146/annurev-psych-113011-143750
   Eisenberg ML, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0146-z
   Elsner B, 2020, TOP COGN SCI, DOI [10.1111/tops.12494, DOI 10.1111/T0PS.12494]
   FERNALD A, 1989, CHILD DEV, V60, P1497, DOI 10.2307/1130938
   FERNALD A, 1985, INFANT BEHAV DEV, V8, P181, DOI 10.1016/S0163-6383(85)80005-9
   FERNALD A, 1984, DEV PSYCHOL, V20, P104, DOI 10.1037/0012-1649.20.1.104
   FERNALD A, 1991, DEV PSYCHOL, V27, P209, DOI 10.1037/0012-1649.27.2.209
   Fitzgerald S, 2011, ELLY PETERSON: MOTHER OF THE MODERATES, P3
   Friston KJ, 2009, TRENDS COGN SCI, V13, P293, DOI 10.1016/j.tics.2009.04.005
   Frost R, 2015, TRENDS COGN SCI, V19, P117, DOI 10.1016/j.tics.2014.12.010
   Gentner D, 2010, COGNITIVE SCI, V34, P752, DOI 10.1111/j.1551-6709.2010.01114.x
   Gold DA, 2017, COGN RES, V2, DOI 10.1186/s41235-016-0043-2
   Goldinger SD, 2012, CURR DIR PSYCHOL SCI, V21, P90, DOI 10.1177/0963721412436811
   Gopnik A., 1997, WORDS THOUGHTS THEOR, V1
   Gopnik A, 2012, SCIENCE, V337, P1623, DOI 10.1126/science.1223416
   Haber RN, 2000, PSYCHOL PUBLIC POL L, V6, P1057, DOI 10.1037/1076-8971.6.4.1057
   Hard BM, 2019, MEM COGNITION, V47, P17, DOI 10.3758/s13421-018-0847-z
   Hard BM, 2011, J EXP PSYCHOL GEN, V140, P586, DOI 10.1037/a0024310
   Hartshorne JK, 2019, COLLABRA-PSYCHOL, V5, DOI 10.1525/collabra.181
   Heider Fritz., 1958, PSYCHOL INTERPERSONA
   Hensch TK, 2016, SCI AM, V314, P64
   Hensch TK, 2005, NAT REV NEUROSCI, V6, P877, DOI 10.1038/nrn1787
   Hespos SJ, 2010, NEURAL NETWORKS, V23, P1026, DOI 10.1016/j.neunet.2010.07.010
   Hespos SJ, 2009, DEV PSYCHOL, V45, P575, DOI 10.1037/a0014145
   Hommel B, 2001, BEHAV BRAIN SCI, V24, P849, DOI 10.1017/S0140525X01000103
   Jackson I, 2009, DEVELOPMENTAL SCI, V12, P670, DOI 10.1111/j.1467-7687.2008.00805.x
   Johnson-Laird PN, 2010, P NATL ACAD SCI USA, V107, P18243, DOI 10.1073/pnas.1012933107
   JUSCZYK PW, 1992, COGNITIVE PSYCHOL, V24, P252, DOI 10.1016/0010-0285(92)90009-Q
   Kanakogi Y, 2011, NAT COMMUN, V2, DOI 10.1038/ncomms1342
   Kelly DJ, 2007, PSYCHOL SCI, V18, P1084, DOI 10.1111/j.1467-9280.2007.02029.x
   Kidd C, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036399
   Kirkham NZ, 2002, COGNITION, V83, pB35, DOI 10.1016/S0010-0277(02)00004-5
   Kosie J. E., 2018, P 20 ANN M COGN SCI
   Kosie J. E., 2019, THESIS
   Kosie JE, 2019, COGN RES, V4, DOI 10.1186/s41235-019-0157-4
   Kosie JE, 2019, COGNITION, V182, P31, DOI 10.1016/j.cognition.2018.09.004
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kurby CA, 2008, TRENDS COGN SCI, V12, P72, DOI 10.1016/j.tics.2007.11.004
   Kurby CA, 2011, MEM COGNITION, V39, P75, DOI 10.3758/s13421-010-0027-2
   Legare CH, 2012, CHILD DEV, V83, P173, DOI 10.1111/j.1467-8624.2011.01691.x
   Legare CH, 2010, CHILD DEV, V81, P929, DOI 10.1111/j.1467-8624.2010.01443.x
   Lenneberg EH, 1967, HOSP PRACT, V2, P59, DOI [DOI 10.1080/21548331.1967.11707799, 10.1080/21548331.1967.11707799]
   Levine D, 2019, DEV PSYCHOBIOL, V61, P376, DOI 10.1002/dev.21804
   LOFTUS EF, 1989, J EXP PSYCHOL GEN, V118, P100, DOI 10.1037/0096-3445.118.1.100
   LOFTUS EF, 1980, J APPL PSYCHOL, V65, P9, DOI 10.1037/0021-9010.65.1.9
   Lohmann J., 2019, VISION, V3, P15
   Loucks J, 2012, CHILD DEV, V83, P801, DOI 10.1111/j.1467-8624.2012.01735.x
   Loucks J, 2012, DEVELOPMENTAL SCI, V15, P123, DOI 10.1111/j.1467-7687.2011.01099.x
   Loucks J, 2009, COGNITION, V111, P84, DOI 10.1016/j.cognition.2008.12.010
   Matheson H, 2013, J EXP CHILD PSYCHOL, V114, P161, DOI 10.1016/j.jecp.2012.09.003
   McGatlin Kristen C, 2019, Open Psychol, V1, P94, DOI 10.1515/psych-2018-0007
   Meyer M, 2011, IEEE T AUTON MENT DE, V3, P154, DOI 10.1109/TAMD.2010.2103941
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   Mondloch CJ, 1999, PSYCHOL SCI, V10, P419, DOI 10.1111/1467-9280.00179
   Monroy CD, 2017, J EXP CHILD PSYCHOL, V157, P14, DOI 10.1016/j.jecp.2016.12.004
   Moses L.J., 2010, SELF SOCIAL REGULATI, P218, DOI DOI 10.1093/ACPROF:OSO/9780195327694.001.0001
   Nagai Y, 2019, PHILOS T R SOC B, V374, DOI 10.1098/rstb.2018.0030
   Newport E. L., 2006, ENCY COGNITIVE SCI, P737
   Newport E. L., 2001, LANGUAGE BRAIN COGNI, P481, DOI DOI 10.1067/MHN.2001.115372
   NEWTSON D, 1976, J EXP SOC PSYCHOL, V12, P436, DOI 10.1016/0022-1031(76)90076-7
   NEWTSON D, 1973, J PERS SOC PSYCHOL, V28, P28, DOI 10.1037/h0035584
   NEWTSON D, 1977, J PERS SOC PSYCHOL, V35, P847, DOI 10.1037/0022-3514.35.12.847
   Nomikou I, 2011, IEEE T AUTON MENT DE, V3, P113, DOI 10.1109/TAMD.2011.2140113
   Olofson EL, 2011, COGNITION, V118, P258, DOI 10.1016/j.cognition.2010.11.012
   Pace A, 2020, INFANT BEHAV DEV, V58, DOI 10.1016/j.infbeh.2020.101425
   PEGG JE, 1992, INFANT BEHAV DEV, V15, P325, DOI 10.1016/0163-6383(92)80003-D
   Piantadosi ST, 2014, DEVELOPMENTAL SCI, V17, P321, DOI 10.1111/desc.12083
   Pollak SD, 2009, COGNITION, V110, P242, DOI 10.1016/j.cognition.2008.10.010
   Radvansky GA, 2011, WIRES COGN SCI, V2, P608, DOI 10.1002/wcs.133
   Reynolds JR, 2007, COGNITIVE SCI, V31, P613, DOI 10.1080/15326900701399913
   Richmond LL, 2017, TRENDS COGN SCI, V21, P962, DOI 10.1016/j.tics.2017.08.005
   Roseberry S, 2011, PSYCHOL SCI, V22, P1422, DOI 10.1177/0956797611422074
   Ross R., 2017, BIENN M COGN DEV SOC
   Saffran J.R., 2007, BLACKWELL HDB LANGUA, P68, DOI [DOI 10.1002/9780470757833.CH4, 10.1002/9780470757833.ch4]
   Saffran JR, 2018, ANNU REV PSYCHOL, V69, P181, DOI 10.1146/annurev-psych-122216-011805
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Saffran JR, 2003, INFANCY, V4, P273, DOI 10.1207/S15327078IN0402_07
   Sage KD, 2014, VIS COGN, V22, P1092, DOI 10.1080/13506285.2014.962123
   Sage KD, 2011, SOC DEV, V20, P825, DOI 10.1111/j.1467-9507.2011.00624.x
   Sargent JQ, 2013, COGNITION, V129, P241, DOI 10.1016/j.cognition.2013.07.002
   Saylor MM, 2007, J COGN DEV, V8, P113, DOI 10.1207/s15327647jcd0801_6
   Schapiro AC, 2013, NAT NEUROSCI, V16, P486, DOI 10.1038/nn.3331
   Schulz L, 2012, TRENDS COGN SCI, V16, P382, DOI 10.1016/j.tics.2012.06.004
   Seth AK, 2013, TRENDS COGN SCI, V17, P565, DOI 10.1016/j.tics.2013.09.007
   Sethi AK, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2011.00395
   Shin YS, 2020, TOP COGN SCI, DOI 10.1111/tops.12505
   Shneidman L, 2016, DEVELOPMENTAL SCI, V19, P372, DOI 10.1111/desc.12318
   Shneidman L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110891
   Simons DJ, 1999, PERCEPTION, V28, P1059, DOI 10.1068/p2952
   Smith ME, 2020, COGNITION, V196, DOI 10.1016/j.cognition.2019.104159
   Sommerville JA, 2005, COGNITION, V96, pB1, DOI 10.1016/j.cognition.2004.07.004
   Sommerville JA, 2005, COGNITION, V95, P1, DOI 10.1016/j.cognition.2003.12.004
   Sonne T, 2017, SCAND J PSYCHOL, V58, P107, DOI 10.1111/sjop.12351
   Sonne T, 2016, CONSCIOUS COGN, V41, P72, DOI 10.1016/j.concog.2016.02.006
   Stahl AE, 2017, COGNITION, V163, P1, DOI 10.1016/j.cognition.2017.02.008
   Stahl AE, 2015, SCIENCE, V348, P91, DOI 10.1126/science.aaa3799
   Stahl AE, 2014, CHILD DEV, V85, P1821, DOI 10.1111/cdev.12247
   Stawarczyk David, 2021, Top Cogn Sci, V13, P164, DOI 10.1111/tops.12450
   Swallow KM, 2008, PSYCHON B REV, V15, P116, DOI 10.3758/PBR.15.1.116
   Swallow KM, 2018, COGNITION, V177, P249, DOI 10.1016/j.cognition.2018.04.019
   Tanaka Y., IMPLICIT MEASU UNPUB
   Tsujimoto S, 2008, NEUROSCIENTIST, V14, P345, DOI 10.1177/1073858408316002
   Vassena E, 2019, COGN AFFECT BEHAV NE, V19, P619, DOI 10.3758/s13415-018-00685-w
   Vouloumanos A, 2007, DEVELOPMENTAL SCI, V10, P159, DOI 10.1111/j.1467-7687.2007.00549.x
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Williamson RA, 2014, J EXP CHILD PSYCHOL, V118, P119, DOI 10.1016/j.jecp.2013.08.005
   Woodward AL, 1998, COGNITION, V69, P1, DOI 10.1016/S0010-0277(98)00058-4
   Woodward AL, 2000, PSYCHOL SCI, V11, P73, DOI 10.1111/1467-9280.00218
   Zacks JM, 2007, PSYCHOL BULL, V133, P273, DOI 10.1037/0033-2909.133.2.273
   Zacks JM, 2006, PSYCHOL AGING, V21, P466, DOI 10.1037/0882-7974.21.3.466
   Zacks JM, 2016, CORTEX, V74, P233, DOI 10.1016/j.cortex.2015.11.002
   Zacks JM, 2011, J COGNITIVE NEUROSCI, V23, P4057, DOI 10.1162/jocn_a_00078
   Zacks JM, 2001, PSYCHOL BULL, V127, P3, DOI 10.1037//0033-2909.127.1.3
   Zacks JM, 2001, J EXP PSYCHOL GEN, V130, P29, DOI 10.1037//0096-3445.130.1.29
   Zelazo PD, 2015, DEV REV, V38, P55, DOI 10.1016/j.dr.2015.07.001
NR 153
TC 3
Z9 3
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1756-8757
EI 1756-8765
J9 TOP COGN SCI
JI Top. Cogn. Sci.
DI 10.1111/tops.12502
EA JUN 2020
PG 27
WC Psychology, Experimental
SC Psychology
GA LX1UL
UT WOS:000539623600001
PM 32529736
DA 2021-02-24
ER

PT J
AU Peterson, AJ
   Heil, P
AF Peterson, Adam J.
   Heil, Peter
TI Phase Locking of Auditory Nerve Fibers: The Role of Lowpass Filtering by
   Hair Cells
SO JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE auditory nerve; Boltzmann function; lowpass filter; modeling; phase
   locking; ribbon synapse
ID GUINEA-PIG COCHLEA; PHENOMENOLOGICAL MODEL; MECHANOELECTRICAL
   TRANSDUCTION; RECEPTOR POTENTIALS; BIOPHYSICAL MODEL; SPEECH-PERCEPTION;
   BASILAR-MEMBRANE; HEARING ONSET; CA2+ INFLUX; INNER
AB Phase locking of auditory-nerve-fiber (ANF) responses to the temporal fine structure of acoustic stimuli, a hallmark of the auditory system's temporal precision, is important for many aspects of hearing. Previous work has shown that phase-locked period histograms are often well described by exponential transfer functions relating instantaneous stimulus pressure to instantaneous spike rate, with no observed clipping of the histograms. The operating points and slopes of these functions change with stimulus level. The mechanism underlying this apparent gain control is unclear but is distinct from mechanical compression, is independent of refractoriness and spike-rate adaptation, and is apparently instantaneous. Here we show that these findings can be accounted for by a model consisting of a static Boltzmann transducer function yielding a clipped output, followed by a lowpass filter and a static exponential transfer function. Using responses to tones of ANFs from cats of both sexes, we show that, for a given ANF, the period histograms obtained at all stimulus levels for a given stimulus frequency can be described using one set of level-independent model parameters. The model also accounts for changes in the maximum and minimum instantaneous spike rates with changes in stimulus level. Notably, the estimated cutoff frequency is lower for low- than for high-spontaneous-rate ANFs, implying a synapse-specific contribution to lowpass filtering. These findings advance our understanding of ANF phase locking by highlighting the role of peripheral filtering mechanisms in shaping responses of individual ANFs.
C1 [Peterson, Adam J.; Heil, Peter] Leibniz Inst Neurobiol, D-39118 Magdeburg, Germany.
   [Heil, Peter] Ctr Behav Brain Sci, D-39106 Magdeburg, Germany.
RP Heil, P (corresponding author), Leibniz Inst Neurobiol, D-39118 Magdeburg, Germany.; Heil, P (corresponding author), Ctr Behav Brain Sci, D-39106 Magdeburg, Germany.
EM peter.heil@lin-magdeburg.de
OI Heil, Peter/0000-0001-7861-5927
FU Deutsche Forschungsgemeinschaft Priority Program 1608 "Ultrafast and
   temporally precise information processing: normal and dysfunctional
   hearing" [He1721/11-2]; Deutsche ForschungsgemeinschaftGerman Research
   Foundation (DFG) [He1721/5-1, He1721/5-2]
FX This work was supported by Deutsche Forschungsgemeinschaft Priority
   Program 1608 "Ultrafast and temporally precise information processing:
   normal and dysfunctional hearing" (He1721/11-2) to P.H. P.H. was also
   supported by Deutsche Forschungsgemeinschaft Grants He1721/5-1 and
   He1721/5-2. Data collection was done in the laboratory of Dexter R.F.
   Irvine (Monash University, Clayton, Victoria, Australia). We thank
   Dexter R.F. Irvine and Mel Brown for help with data collection; and
   Laurel Carney for suggesting the idea pursued in this study.
CR Altoe A, 2018, HEARING RES, V364, P68, DOI 10.1016/j.heares.2018.03.029
   Ashida G, 2013, FRONT COMPUT NEUROSC, V7, DOI 10.3389/fncom.2013.00151
   Ashida G, 2010, SPR SER COMPUT NEURO, V7, P59, DOI 10.1007/978-1-4419-5675-0_4
   Avissar M, 2013, J NEUROSCI, V33, P7681, DOI 10.1523/JNEUROSCI.3405-12.2013
   Berry MJ, 1998, J NEUROSCI, V18, P2200
   Borst A, 2007, THEOR BIOL MED MODEL, V4, DOI 10.1186/1742-4682-4-7
   Bruce IC, 2018, HEARING RES, V360, P40, DOI 10.1016/j.heares.2017.12.016
   CARNEY LH, 1993, J ACOUST SOC AM, V93, P401, DOI 10.1121/1.405620
   Cheatham MA, 1998, J ACOUST SOC AM, V104, P356, DOI 10.1121/1.423245
   CODY AR, 1989, HEARING RES, V41, P89, DOI 10.1016/0378-5955(89)90002-6
   COLBURN HS, 1973, J ACOUST SOC AM, V54, P1458, DOI 10.1121/1.1914445
   Cooper NP, 1998, J PHYSIOL-LONDON, V509, P277, DOI 10.1111/j.1469-7793.1998.277bo.x
   Corey DP, 2017, SPRINGER HANDB AUDIT, V62, P75, DOI 10.1007/978-3-319-52073-5_4
   DALLOS P, 1986, HEARING RES, V22, P185, DOI 10.1016/0378-5955(86)90095-X
   DALLOS P, 1985, J NEUROSCI, V5, P1591
   DALLOS P, 1990, J ACOUST SOC AM, V87, P1636, DOI 10.1121/1.399411
   DALLOS P, 1989, J ACOUST SOC AM, V86, P1790, DOI 10.1121/1.398611
   Dreyer A, 2006, J NEUROPHYSIOL, V96, P2327, DOI 10.1152/jn.00326.2006
   Fettiplace R, 2014, PHYSIOL REV, V94, P951, DOI 10.1152/physrev.00038.2013
   Frank T, 2009, P NATL ACAD SCI USA, V106, P4483, DOI 10.1073/pnas.0813213106
   Grothe B, 2010, PHYSIOL REV, V90, P983, DOI 10.1152/physrev.00026.2009
   Guinan JJ, 2012, HEARING RES, V292, P35, DOI 10.1016/j.heares.2012.08.005
   Heil P, 2007, J NEUROSCI, V27, P8457, DOI 10.1523/JNEUROSCI.1512-07.2007
   Heil P, 2019, HEARING RES, V381, DOI 10.1016/j.heares.2019.107783
   Heil P, 2017, SYNAPSE, V71, P5, DOI 10.1002/syn.21925
   Heil P, 2015, CELL TISSUE RES, V361, P129, DOI 10.1007/s00441-015-2177-9
   Heil P, 2011, J NEUROSCI, V31, P15424, DOI 10.1523/JNEUROSCI.1638-11.2011
   Heil Peter, 2010, Front Synaptic Neurosci, V2, P148, DOI 10.3389/fnsyn.2010.00148
   Horst JW, 2018, HEARING RES, V367, P195, DOI 10.1016/j.heares.2018.06.007
   Huet A, 2018, J NEUROSCI, V38, P5727, DOI 10.1523/JNEUROSCI.3103-17.2018
   Jia SP, 2007, J NEUROSCI, V27, P1006, DOI 10.1523/JNEUROSCI.5452-06.2007
   JOHNSON DH, 1980, J ACOUST SOC AM, V68, P1115, DOI 10.1121/1.384982
   JOHNSON DH, 1983, J ACOUST SOC AM, V74, P493, DOI 10.1121/1.389815
   Johnson DH, 1974, THESIS
   Johnson SL, 2015, ELIFE, V4, DOI 10.7554/eLife.08177
   Johnson SL, 2011, NEURON, V70, P1143, DOI 10.1016/j.neuron.2011.04.024
   Joris PX, 2004, PHYSIOL REV, V84, P541, DOI 10.1152/physrev.00029.2003
   JORIS PX, 1994, J NEUROPHYSIOL, V71, P1022
   Khanna SM, 1999, HEARING RES, V135, P89, DOI 10.1016/S0378-5955(99)00095-7
   KIANG NYS, 1990, HEARING RES, V49, P1
   KIDD RC, 1990, HEARING RES, V49, P181, DOI 10.1016/0378-5955(90)90104-W
   LIBERMAN MC, 1982, SCIENCE, V216, P1239, DOI 10.1126/science.7079757
   Lopez-Poveda EA, 2006, JARO-J ASSOC RES OTO, V7, P218, DOI 10.1007/s10162-006-0037-8
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Louage DHG, 2004, J NEUROPHYSIOL, V91, P2051, DOI 10.1152/jn.00816.2003
   Meddis R, 2006, J ACOUST SOC AM, V119, P406, DOI 10.1121/1.2139628
   Meenderink SWF, 2011, AIP CONF PROC, V1403, DOI 10.1063/1.3658060
   Meyer AC, 2009, NAT NEUROSCI, V12, P444, DOI 10.1038/nn.2293
   Moore BCJ, 2008, JARO-J ASSOC RES OTO, V9, P399, DOI 10.1007/s10162-008-0143-x
   Mountain DC, 1999, HEARING RES, V132, P1, DOI 10.1016/S0378-5955(99)00013-1
   Ohn TL, 2016, P NATL ACAD SCI USA, V113, pE4716, DOI 10.1073/pnas.1605737113
   PALMER AR, 1986, HEARING RES, V24, P1, DOI 10.1016/0378-5955(86)90002-X
   PATUZZI R, 1983, J ACOUST SOC AM, V74, P1734, DOI 10.1121/1.390282
   Patuzzi R, 1998, HEARING RES, V125, P1, DOI 10.1016/S0378-5955(98)00125-7
   PATUZZI RB, 1987, HEARING RES, V30, P83, DOI 10.1016/0378-5955(87)90186-9
   Peterson AJ, 2019, J NEUROSCI, V39, P4077, DOI 10.1523/JNEUROSCI.1801-18.2019
   Peterson AJ, 2018, HEARING RES, V370, P248, DOI 10.1016/j.heares.2018.08.007
   Peterson AJ, 2018, HEARING RES, V363, P1, DOI 10.1016/j.heares.2017.09.005
   Peterson AJ, 2014, J NEUROSCI, V34, P15097, DOI 10.1523/JNEUROSCI.0903-14.2014
   Peterson AJ, 2020, MATLABCODE MODEL PHA
   Platzer J, 2000, CELL, V102, P89, DOI 10.1016/S0092-8674(00)00013-1
   Rhode WS, 1996, AUDIT NEUROSCI, V3, P101
   Robles L, 2001, PHYSIOL REV, V81, P1305
   RUSSELL IJ, 1986, HEARING RES, V22, P199, DOI 10.1016/0378-5955(86)90096-1
   RUSSELL IJ, 1983, J PHYSIOL-LONDON, V338, P179, DOI 10.1113/jphysiol.1983.sp014668
   RUSSELL IJ, 1978, J PHYSIOL-LONDON, V284, P261, DOI 10.1113/jphysiol.1978.sp012540
   RUSSELL IJ, 1986, NATURE, V321, P517, DOI 10.1038/321517a0
   Sumner CJ, 2002, J ACOUST SOC AM, V111, P2178, DOI 10.1121/1.1453451
   Temchin AN, 2010, JARO-J ASSOC RES OTO, V11, P297, DOI 10.1007/s10162-009-0197-4
   van Hemmen JL, 2013, BIOL CYBERN, V107, P385, DOI 10.1007/s00422-013-0561-7
   Verschooten E, 2019, HEARING RES, V377, P109, DOI 10.1016/j.heares.2019.03.011
   Vincent PFY, 2017, J NEUROSCI, V37, P2960, DOI 10.1523/JNEUROSCI.2374-16.2017
   WEISS TF, 1988, HEARING RES, V33, P175, DOI 10.1016/0378-5955(88)90030-5
   Wong AB, 2014, EMBO J, V33, P247, DOI 10.1002/embj.201387110
   Wong AB, 2013, J NEUROSCI, V33, P10661, DOI 10.1523/JNEUROSCI.1215-13.2013
   Wu JJS, 2016, J NEUROSCI, V36, P10584, DOI 10.1523/JNEUROSCI.1187-16.2016
   YOUNG ED, 1986, J ACOUST SOC AM, V79, P426, DOI 10.1121/1.393530
   Zeddies DG, 2004, J ACOUST SOC AM, V116, P426, DOI 10.1121/1.1755237
   Zhang XD, 2001, J ACOUST SOC AM, V109, P648, DOI 10.1121/1.1336503
   Zilany MSA, 2009, J ACOUST SOC AM, V126, P2390, DOI 10.1121/1.3238250
NR 80
TC 0
Z9 0
U1 0
U2 3
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
SN 0270-6474
EI 1529-2401
J9 J NEUROSCI
JI J. Neurosci.
PD JUN 10
PY 2020
VL 40
IS 24
BP 4700
EP 4714
DI 10.1523/JNEUROSCI.2269-19.2020
PG 15
WC Neurosciences
SC Neurosciences & Neurology
GA LY6WC
UT WOS:000540668500006
PM 32376778
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Cheng, LH
   Wang, CH
   Lu, RH
   Chen, YF
AF Cheng, Lin-Hua
   Wang, Chih-Hung
   Lu, Rou-Huei
   Chen, Yu-Fu
TI Evaluating the Function of the Media Olivocochlear Bundle in Patients
   With Bilateral Tinnitus
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID PRODUCT OTOACOUSTIC EMISSIONS; EFFERENT AUDITORY-SYSTEM;
   SPEECH-PERCEPTION; CONTRALATERAL SUPPRESSION; NORMAL-HEARING; NOISE;
   RECOGNITION; REFLEX; AGE; INTELLIGIBILITY
AB Purpose: No study has investigated the effects of contralateral noise (CN) on speech-in-noise perception (SINP) in listeners with tinnitus. The mechanisms underlying the involvement of medial olivocochlear (MOC) reflex with SINP remain to be elucidated. This study aimed to investigate the MOC function in patients with bilateral tinnitus by measuring distortion product otoacoustic emission and SINP.
   Method: Eighteen patients with bilateral tinnitus (one male and 17 females; age: M +/- SD = 45.61 +/- 10.18 years) and 19 listeners without tinnitus (six males and 13 females; age: M +/- SD = 34.11 +/- 8.35 years) were recruited for the study. Each subject underwent distortion product otoacoustic emission measurement and the SINP test for both ears. The effects of CN on these two measurements were compared between tinnitus ears (TEs) and no-tinnitus ears (NTEs).
   Results: The presence of CN significantly reduced distortion product (DP) amplitudes and improved SINP for TEs, and the amounts of DP suppression and SINP improvement were similar to those in NTEs. Improvement of SINP was positively correlated with DP suppression at 6185 Hz for NTEs and at 1640 Hz for TEs.
   Conclusions: The results of this study suggest that the amounts of DP suppression and SINP improvement were similar between listeners with and without tinnitus. For both ear groups, the MOC reflex was involved with SINP at specific frequencies. Any clinical test outcomes with regard to the MOC bundle in patients with tinnitus should be interpreted with caution until further studies are conducted.
C1 [Cheng, Lin-Hua; Chen, Yu-Fu] Natl Taipei Univ Nursing & Hlth Sci, Dept Speech Language Pathol & Audiol, Taipei, Taiwan.
   [Wang, Chih-Hung] Natl Def Med Ctr, Grad Inst Med Sci, Taipei, Taiwan.
   [Wang, Chih-Hung; Lu, Rou-Huei] Taichung Armed Forces Gen Hosp, Taichung, Taiwan.
RP Chen, YF (corresponding author), Natl Taipei Univ Nursing & Hlth Sci, Dept Speech Language Pathol & Audiol, Taipei, Taiwan.
EM yufuchen@ntunhs.edu.tw
CR Abdala C, 1999, J ACOUST SOC AM, V105, P2392, DOI 10.1121/1.426844
   Abdala C, 2009, J ACOUST SOC AM, V125, P1584, DOI 10.1121/1.3068442
   Attias J, 1996, ACTA OTO-LARYNGOL, V116, P534, DOI 10.3109/00016489609137885
   Baguley DM, 2003, J ROY SOC MED, V96, P582, DOI 10.1258/jrsm.96.12.582
   Bhagat SP, 2004, HEARING RES, V193, P51, DOI 10.1016/j.heares.2004.04.005
   Buzo Byanka Cagnacci, 2017, Audiol., Commun. Res., V22, pe1693, DOI 10.1590/2317-6431-2016-1693
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Dallos P, 2008, CURR OPIN NEUROBIOL, V18, P370, DOI 10.1016/j.conb.2008.08.016
   de Boer J, 2008, J NEUROSCI, V28, P4929, DOI 10.1523/JNEUROSCI.0902-08.2008
   DIRKS DD, 1982, J SPEECH HEAR DISORD, V47, P114, DOI 10.1044/jshd.4702.114
   DUBNO JR, 1984, J ACOUST SOC AM, V76, P87, DOI 10.1121/1.391011
   Feeney MP, 2003, J SPEECH LANG HEAR R, V46, P128, DOI 10.1044/1092-4388(2003/010)
   Feeney MP, 2001, EAR HEARING, V22, P316, DOI 10.1097/00003446-200108000-00006
   Fernandes Luciene da Cruz, 2009, Braz. j. otorhinolaryngol., V75, P414, DOI 10.1590/S1808-86942009000300017
   Geven LI, 2011, OTOL NEUROTOL, V32, P315, DOI 10.1097/MAO.0b013e3181fcf180
   Giraud AL, 1997, NEUROREPORT, V8, P1779, DOI 10.1097/00001756-199705060-00042
   Gkoritsa E., 2014, JHS, V4, P9
   GREENHOUSE SW, 1959, PSYCHOMETRIKA, V24, P95, DOI 10.1007/BF02289823
   Huang CY, 2007, ORL-J OTO-RHIN-LARYN, V69, P25, DOI 10.1159/000096713
   JASTREBOFF PJ, 1990, NEUROSCI RES, V8, P221, DOI 10.1016/0168-0102(90)90031-9
   Kim S, 2006, SPEECH COMMUN, V48, P855, DOI 10.1016/j.specom.2006.03.004
   Knudson IM, 2014, J NEUROPHYSIOL, V112, P3197, DOI 10.1152/jn.00576.2014
   Kumar UA, 2004, EAR HEARING, V25, P142, DOI 10.1097/01.AUD.0000120363.56591.E6
   Lind O, 1996, SCAND AUDIOL, V25, P167, DOI 10.3109/01050399609048000
   Maison SF, 2000, J NEUROSCI, V20, P4701, DOI 10.1523/JNEUROSCI.20-12-04701.2000
   Mertes IB, 2019, J ACOUST SOC AM, V145, P1529, DOI 10.1121/1.5094766
   Mertes IB, 2016, J ACOUST SOC AM, V140, P2027, DOI 10.1121/1.4962666
   Mishra S., 2014, PLOS ONE, V9, P1, DOI DOI 10.1371/J0URNAL.P0NE.0085756
   Mishra SK, 2013, EAR HEARING, V34, P789, DOI 10.1097/AUD.0b013e3182944c04
   Modh D, 2014, NOISE HEALTH, V16, P69, DOI 10.4103/1463-1741.132078
   Mukari SZMS, 2008, AUDIOL NEURO-OTOL, V13, P328, DOI 10.1159/000128978
   Muller J, 2005, J ACOUST SOC AM, V118, P3747, DOI 10.1121/1.2109127
   Paglialonga A, 2010, AURIS NASUS LARYNX, V37, P291, DOI 10.1016/j.anl.2009.09.009
   RASMUSSEN GL, 1946, J COMP NEUROL, V84, P141, DOI 10.1002/cne.900840204
   REITER ER, 1995, J NEUROPHYSIOL, V73, P506
   Riga M, 2007, OTOL NEUROTOL, V28, P185, DOI 10.1097/MAO.0b013e31802e2a14
   Riga M, 2017, INT J AUDIOL, V56, P589, DOI 10.1080/14992027.2017.1305516
   Ryu IS, 2012, OTOL NEUROTOL, V33, P1472, DOI 10.1097/MAO.0b013e31826dbcc4
   Serra Lucieny Silva Martins, 2015, Int Tinnitus J, V19, P52, DOI 10.5935/0946-5448.20150009
   Stuart A, 2012, J AM ACAD AUDIOL, V23, P686, DOI 10.3766/jaaa.23.9.3
   SZIKLAI I, 1993, ACTA OTO-LARYNGOL, V113, P326, DOI 10.3109/00016489309135818
   Tokgoz-Yilmaz S, 2007, J LARYNGOL OTOL, V121, P1029, DOI 10.1017/S0022215107006883
   Wagner W, 2008, ACTA OTO-LARYNGOL, V128, P53, DOI 10.1080/00016480701361954
   Wilson RH, 2012, J AM ACAD AUDIOL, V23, P590, DOI 10.3766/jaaa.23.7.9
   Yost W. A., 2013, FUNDAMENTALS HEARING
   Zeng FG, 2000, HEARING RES, V142, P102, DOI 10.1016/S0378-5955(00)00011-3
NR 46
TC 0
Z9 0
U1 0
U2 0
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD JUN
PY 2020
VL 63
IS 6
BP 1969
EP 1978
DI 10.1044/2020_JSLHR-19-00080
PG 10
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA ND2UH
UT WOS:000561759600024
PM 32511051
DA 2021-02-24
ER

PT J
AU Lo, CY
   Looi, V
   Thompson, WF
   McMahon, CM
AF Lo, Chi Yhun
   Looi, Valerie
   Thompson, William Forde
   McMahon, Catherine M.
TI Music Training for Children With Sensorineural Hearing Loss Improves
   Speech-in-Noise Perception
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID PRELINGUALLY-DEAFENED CHILDREN; COCHLEAR IMPLANT RECIPIENTS; SPECTRAL
   RESOLUTION; BRAIN PLASTICITY; YOUNG-CHILDREN; SENTENCE TEST; PROSODY;
   BENEFITS; DISCRIMINATION; RECOGNITION
AB Purpose: A growing body of evidence suggests that longterm music training provides benefits to auditory abilities for typical-hearing adults and children. The purpose of this study was to evaluate how music training may provide perceptual benefits (such as speech-in-noise, spectral resolution, and prosody) for children with hearing loss.
   Method: Fourteen children aged 6-9 years with prelingual sensorineural hearing loss using bilateral cochlear implants, bilateral hearing aids, or bimodal configuration participated in a 12-week music training program, with nine participants completing the full testing requirements of the music training. Activities included weekly group-based music therapy and take-home music apps three times a week. The design was a pseudorandomized, longitudinal study (half the cohort was wait-listed, initially serving as a passive control group prior to music training). The test battery consisted of tasks related to music perception, music appreciation, and speech perception. As a comparison, 16 age-matched children with typical hearing also completed this test battery, but without participation in the music training.
   Results: There were no changes for any outcomes for the passive control group. After music training, perception of speech-in-noise, question/statement prosody, musical timbre, and spectral resolution improved significantly, as did measures of music appreciation. There were no benefits for emotional prosody or pitch perception.
   Conclusion: The findings suggest even a modest amount of music training has benefits for music and speech outcomes. These preliminary results provide further evidence that music training is a suitable complementary means of habilitation to improve the outcomes for children with hearing loss.
C1 [Lo, Chi Yhun; McMahon, Catherine M.] Macquarie Univ, Dept Linguist, Sydney, NSW, Australia.
   [Lo, Chi Yhun; McMahon, Catherine M.] HEARing CRC, Melbourne, Vic, Australia.
   [Lo, Chi Yhun; Thompson, William Forde] ARC Ctr Excellence Cognit & Disorders, Sydney, NSW, Australia.
   [Looi, Valerie] RIDBC Serv, SCIC Cochlear Implant Program, Sydney, NSW, Australia.
   [Thompson, William Forde] Macquarie Univ, Dept Psychol, Sydney, NSW, Australia.
RP Lo, CY (corresponding author), Macquarie Univ, Dept Linguist, Sydney, NSW, Australia.; Lo, CY (corresponding author), HEARing CRC, Melbourne, Vic, Australia.; Lo, CY (corresponding author), ARC Ctr Excellence Cognit & Disorders, Sydney, NSW, Australia.
EM chi.lo@mq.edu.au
OI McMahon, Catherine/0000-0001-7312-6593; Thompson,
   William/0000-0002-4256-1338; Lo, Chi Yhun/0000-0001-7695-3148
FU Macquarie University Research Enhancement Fund; HEARing CRC under the
   Australian Government's Cooperative Research Centres (CRC)
   ProgramAustralian GovernmentDepartment of Industry, Innovation and
   ScienceCooperative Research Centres (CRC) Programme
FX This study was supported by the Macquarie University Research
   Enhancement Fund and the financial support of The HEARing CRC,
   established under the Australian Government's Cooperative Research
   Centres (CRC) Program. The CRC Program supports industry-led
   collaborations between industry, researchers, and the community. We are
   grateful to the considerable efforts of the children and their families.
   The authors thank Eudora Low and Nordoff-Robbins Music Therapy Australia
   for facilitating the music therapy sessions, Peter Humburg for
   statistical advice, Denielle Plara and Roisin McDonnell for their
   research assistance, Rachelle Hassarati and the Sydney Cochlear Implant
   Centre for clinical assistance, Socorro Amos and the Royal Institute for
   Deaf and Blind Children as well as Alison King and Hearing Australia for
   recruitment assistance, and Robert Cowan for additional comments.
CR Abdi S, 2001, INT J PEDIATR OTORHI, V59, P105, DOI 10.1016/S0165-5876(01)00460-8
   Angulo-Perkins A, 2014, CORTEX, V59, P126, DOI 10.1016/j.cortex.2014.07.013
   Aronoff JM, 2013, J ACOUST SOC AM, V134, pEL217, DOI 10.1121/1.4813802
   Azadpour M, 2012, JARO-J ASSOC RES OTO, V13, P145, DOI 10.1007/s10162-011-0294-z
   Blamey PJ, 2001, J SPEECH LANG HEAR R, V44, P264, DOI 10.1044/1092-4388(2001/022)
   Bregman AS., 1994, AUDITORY SCENE ANAL
   Brown RM, 2012, MEM COGNITION, V40, P567, DOI 10.3758/s13421-011-0177-x
   Chatterjee M, 2008, HEARING RES, V235, P143, DOI 10.1016/j.heares.2007.11.004
   Chatterjee M, 2015, HEARING RES, V322, P151, DOI 10.1016/j.heares.2014.10.003
   Chen JKC, 2010, PEDIATRICS, V125, pE793, DOI 10.1542/peds.2008-3620
   Chen-Hafteck L, 2011, MUSIC EDUC RES, V13, P93, DOI 10.1080/14613808.2011.553279
   Cheng XT, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518759214
   Chin SB, 2012, J COMMUN DISORD, V45, P355, DOI 10.1016/j.jcomdis.2012.05.003
   Ching TYC, 2015, AM J AUDIOL, V24, P345, DOI 10.1044/2015_AJA-15-0007
   Coffey EBJ, 2017, HEARING RES, V352, P49, DOI 10.1016/j.heares.2017.02.006
   Davies Merren G., 2001, Australian and New Zealand Journal of Audiology, V23, P52, DOI 10.1375/audi.23.1.52.31096
   Dawson PW, 2013, EAR HEARING, V34, P592, DOI 10.1097/AUD.0b013e31828576fb
   de Jong MAM, 2018, EAR HEARING, V39, P475, DOI 10.1097/AUD.0000000000000499
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Drennan WR, 2015, INT J AUDIOL, V54, P114, DOI 10.3109/14992027.2014.948219
   Eiser C, 2001, Health Technol Assess, V5, P1
   Fu QJ, 2015, J SPEECH LANG HEAR R, V58, P163, DOI 10.1044/2014_JSLHR-H-14-0127
   Fuller CD, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518765379
   Galvin JJ, 2007, EAR HEARING, V28, P302, DOI 10.1097/01.aud.0000261689.35445.20
   George EM, 2011, NEUROPSYCHOLOGIA, V49, P1083, DOI 10.1016/j.neuropsychologia.2011.02.001
   Gfeller K, 1998, J Am Acad Audiol, V9, P1
   Gfeller K, 2016, EUR ANN OTORHINOLARY, V133, pS50, DOI 10.1016/j.anorl.2016.01.010
   Gfeller K, 2008, J AM ACAD AUDIOL, V19, P120, DOI 10.3766/jaaa.19.2.3
   Gfeller K, 2011, MUSIC THER PERSPECT, V29, P39, DOI 10.1093/mtp/29.1.39
   Good A, 2017, EAR HEARING, V38, P455, DOI 10.1097/AUD.0000000000000402
   Hausen M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00566
   Herholz SC, 2012, NEURON, V76, P486, DOI 10.1016/j.neuron.2012.10.011
   Holt CM, 2013, INT J AUDIOL, V52, P808, DOI 10.3109/14992027.2013.832416
   Horn DL, 2017, J ACOUST SOC AM, V141, P613, DOI 10.1121/1.4974203
   Innes-Brown H, 2013, J AM ACAD AUDIOL, V24, P789, DOI 10.3766/jaaa.24.9.4
   Jokovic A, 2004, QUAL LIFE RES, V13, P1297, DOI 10.1023/B:QURE.0000037480.65972.eb
   Jung KH, 2012, AUDIOL NEURO-OTOL, V17, P189, DOI 10.1159/000336407
   Kang R, 2009, EAR HEARING, V30, P411, DOI 10.1097/AUD.0b013e3181a61bc0
   Kirby BJ, 2015, J ACOUST SOC AM, V138, pEL465, DOI 10.1121/1.4935081
   Kral A, 2007, BRAIN RES REV, V56, P259, DOI 10.1016/j.brainresrev.2007.07.021
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Lamont A., 1998, PSYCHOL MUSIC, V26, p7?25, DOI DOI 10.1177/0305735698261003
   Landsberger DM, 2018, EAR HEARING, V39, P60, DOI 10.1097/AUD.0000000000000463
   Lawler M, 2017, EAR HEARING, V38, P760, DOI 10.1097/AUD.0000000000000496
   Linnavalli T, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27126-5
   Lo CY, 2015, BEHAV NEUROL, V2015, DOI 10.1155/2015/352869
   Looi V., 2018, 34 WORLD C AUD CAP S
   Looi V, 2007, EAR HEARING, V28, p59S, DOI 10.1097/AUD.0b013e31803150cb
   Looi V, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01002
   Looi Valerie, 2012, Seminars in Hearing, V33, P361, DOI 10.1055/s-0032-1329225
   Looi Valerie, 2012, Seminars in Hearing, V33, P307, DOI 10.1055/s-0032-1329222
   MACKENZIE C., 1991, BRIT J MUSIC EDUC, V8, P15, DOI DOI 10.1017/S0265051700008032
   Music Sales Group, 2018, MUSICFIRST JUN
   Neuman AC, 2010, EAR HEARING, V31, P336, DOI 10.1097/AUD.0b013e3181d3d514
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Nittrouer S, 2014, J COMMUN DISORD, V52, P111, DOI 10.1016/j.jcomdis.2014.09.003
   Nordoff P, 2007, CREATIVE MUSIC THERA
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Patil K, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002759
   Peppe S, 2003, CLIN LINGUIST PHONET, V17, P345, DOI 10.1080/0269920031000079994
   Peretz I, 2015, PHILOS T R SOC B, V370, P68, DOI 10.1098/rstb.2014.0090
   Petersen B, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00007
   Rauscher FH, 2011, MUSIC PERCEPT, V29, P215, DOI 10.1525/MP.2011.29.2.215
   Santoro R, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003412
   Schafer Erin C, 2006, Am J Audiol, V15, P114, DOI 10.1044/1059-0889(2006/015)
   Schafer EC, 2012, EAR HEARING, V33, pE32, DOI 10.1097/AUD.0b013e318258c616
   Schorr EA, 2009, J SPEECH LANG HEAR R, V52, P141, DOI 10.1044/1092-4388(2008/07-0213)
   Shams L, 2008, TRENDS COGN SCI, V12, P411, DOI 10.1016/j.tics.2008.07.006
   Slater J, 2015, BEHAV BRAIN RES, V291, P244, DOI 10.1016/j.bbr.2015.05.026
   Thompson WF, 2001, PSYCHOL SCI, V12, P248, DOI 10.1111/1467-9280.00345
   Thompson WF, 2004, EMOTION, V4, P46, DOI 10.1037/1528-3542.4.1.46
   Thompson WF, 2012, P NATL ACAD SCI USA, V109, P19027, DOI 10.1073/pnas.1210344109
   Torppa R, 2018, MUSIC PERCEPT, V36, P156, DOI 10.1525/MP.2018.36.2.156
   Torppa R, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01389
   Trehub SE, 2009, ANN NY ACAD SCI, V1169, P534, DOI 10.1111/j.1749-6632.2009.04554.x
   Turner CW, 1999, J SPEECH LANG HEAR R, V42, P773, DOI 10.1044/jslhr.4204.773
   Valente DL, 2012, J ACOUST SOC AM, V131, P232, DOI 10.1121/1.3662059
   Vasuki PRM, 2017, CLIN NEUROPHYSIOL, V128, P1270, DOI 10.1016/j.clinph.2017.04.010
   Volkova Anna, 2013, Cochlear Implants Int, V14, P80, DOI 10.1179/1754762812Y.0000000004
   Vongpaisal Tara, 2016, Front Psychol, V7, P835, DOI 10.3389/fpsyg.2016.00835
   Wan CY, 2010, NEUROSCIENTIST, V16, P566, DOI 10.1177/1073858410377805
   White-Schwoch T, 2013, J NEUROSCI, V33, P17667, DOI 10.1523/JNEUROSCI.2560-13.2013
   Won JH, 2007, JARO-J ASSOC RES OTO, V8, P384, DOI 10.1007/s10162-007-0085-8
   Won JH, 2010, EAR HEARING, V31, P796, DOI 10.1097/AUD.0b013e3181e8b7bd
   Wright R, 2012, J AM ACAD AUDIOL, V23, P350, DOI 10.3766/jaaa.23.5.6
   Xu L, 2009, HEARING RES, V255, P129, DOI 10.1016/j.heares.2009.06.011
NR 87
TC 2
Z9 2
U1 3
U2 3
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD JUN
PY 2020
VL 63
IS 6
BP 1990
EP 2015
DI 10.1044/2020_JSLHR-19-00391
PG 26
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA ND2UH
UT WOS:000561759600026
PM 32543961
DA 2021-02-24
ER

PT J
AU Randazzo, M
   Priefer, R
   Smith, PJ
   Nagler, A
   Avery, T
   Froud, K
AF Randazzo, Melissa
   Priefer, Ryan
   Smith, Paul J.
   Nagler, Amanda
   Avery, Trey
   Froud, Karen
TI Neural Correlates of Modality-Sensitive Deviance Detection in the
   Audiovisual Oddball Paradigm
SO BRAIN SCIENCES
LA English
DT Article
DE audiovisual; McGurk effect; fusion; mismatch negativity; N1
ID EVENT-RELATED POTENTIALS; MISMATCH NEGATIVITY; SPEECH-PERCEPTION; VISUAL
   SPEECH; SEEING-VOICES; HEARING-LIPS; FUSION; CORTEX
AB The McGurk effect, an incongruent pairing of visual /ga/-acoustic /ba/, creates a fusion illusion /da/ and is the cornerstone of research in audiovisual speech perception. Combination illusions occur given reversal of the input modalities-auditory /ga/-visual /ba/, and percept /bga/. A robust literature shows that fusion illusions in an oddball paradigm evoke a mismatch negativity (MMN) in the auditory cortex, in absence of changes to acoustic stimuli. We compared fusion and combination illusions in a passive oddball paradigm to further examine the influence of visual and auditory aspects of incongruent speech stimuli on the audiovisual MMN. Participants viewed videos under two audiovisual illusion conditions: fusion with visual aspect of the stimulus changing, and combination with auditory aspect of the stimulus changing, as well as two unimodal auditory- and visual-only conditions. Fusion and combination deviants exerted similar influence in generating congruency predictions with significant differences between standards and deviants in the N100 time window. Presence of the MMN in early and late time windows differentiated fusion from combination deviants. When the visual signal changes, a new percept is created, but when the visual is held constant and the auditory changes, the response is suppressed, evoking a later MMN. In alignment with models of predictive processing in audiovisual speech perception, we interpreted our results to indicate that visual information can both predict and suppress auditory speech perception.
C1 [Randazzo, Melissa; Priefer, Ryan; Nagler, Amanda] Adelphi Univ, Dept Commun Sci & Disorders, Garden City, NY 11530 USA.
   [Smith, Paul J.; Avery, Trey; Froud, Karen] Columbia Univ, Teachers Coll, Dept Biobehav Sci, Neurosci & Educ, New York, NY 10027 USA.
RP Randazzo, M (corresponding author), Adelphi Univ, Dept Commun Sci & Disorders, Garden City, NY 11530 USA.
EM mrandazzo@adelphi.edu; rpriefer@adelphi.edu; pjs2194@tc.columbia.edu;
   amandanagler@mail.adelphi.edu; psa2111@tc.columbia.edu;
   kf2119@tc.columbia.edu
OI Randazzo, Melissa/0000-0003-3055-2503; , Ryan/0000-0003-3343-0288
CR Abbott NT, 2018, J NEUROPHYSIOL, V120, P2988, DOI 10.1152/jn.00262.2018
   Alsius A, 2018, MULTISENS RES, V31, P111, DOI 10.1163/22134808-00002565
   Altieri N., 2014, FRONT PSYCHOL, V5, P1, DOI DOI 10.3389/FPSYG.2014.00257
   Arditi A, 2005, INVEST OPHTH VIS SCI, V46, P2225, DOI 10.1167/iovs.04-1198
   Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009
   Baart M, 2017, EUR J NEUROSCI, V46, P2578, DOI 10.1111/ejn.13734
   Baum SH, 2012, NEUROIMAGE, V62, P1825, DOI 10.1016/j.neuroimage.2012.05.034
   Bhat J, 2015, J NEUROPHYSIOL, V113, P1437, DOI 10.1152/jn.00200.2014
   Bhat J, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00173
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Cienkowski KM, 2002, EAR HEARING, V23, P439, DOI 10.1097/00003446-200210000-00006
   Colin C, 2002, EUR J COGN PSYCHOL, V14, P475, DOI 10.1080/09541440143000203
   Colin C, 2002, CLIN NEUROPHYSIOL, V113, P495, DOI 10.1016/S1388-2457(02)00024-X
   Crowley KE, 2004, CLIN NEUROPHYSIOL, V115, P732, DOI 10.1016/j.clinph.2003.11.021
   den Ouden HEM, 2010, J NEUROSCI, V30, P3210, DOI 10.1523/JNEUROSCI.4458-09.2010
   Eg R, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00736
   Ferree T., 1999, INT J BIOELECTROMAGN, V1, P4
   Friston KJ, 2009, TRENDS COGN SCI, V13, P293, DOI 10.1016/j.tics.2009.04.005
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   GARCIALARREA L, 1992, NEUROPSYCHOLOGIA, V30, P723, DOI 10.1016/0028-3932(92)90042-K
   Grant KW, 2004, SPEECH COMMUN, V44, P43, DOI 10.1016/j.specom.2004.06.004
   Green KP, 1997, J SPEECH LANG HEAR R, V40, P646, DOI 10.1044/jslhr.4003.646
   Hessler D, 2013, BRAIN LANG, V124, P213, DOI 10.1016/j.bandl.2012.12.006
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2018, CORTEX, V103, P360, DOI 10.1016/j.cortex.2018.03.030
   Hofmann-Shen C, 2020, NEUROIMAGE, V207, DOI 10.1016/j.neuroimage.2019.116432
   Irwin J, 2018, MULTISENS RES, V31, P39, DOI 10.1163/22134808-00002580
   Irwin J, 2017, BRAIN SCI, V7, DOI 10.3390/brainsci7060060
   Karas PJ, 2019, ELIFE, V8, DOI 10.7554/eLife.48116
   Kislyuk DS, 2008, J COGNITIVE NEUROSCI, V20, P2175, DOI 10.1162/jocn.2008.20152
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Moran RJ, 2013, J NEUROSCI, V33, P8227, DOI 10.1523/JNEUROSCI.4255-12.2013
   Fernandez LM, 2017, HUM BRAIN MAPP, V38, P5691, DOI 10.1002/hbm.23758
   Mottonen R, 2002, COGNITIVE BRAIN RES, V13, P417, DOI 10.1016/S0926-6410(02)00053-8
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   NAATANEN R, 1993, PSYCHOPHYSIOLOGY, V30, P436, DOI 10.1111/j.1469-8986.1993.tb02067.x
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Paavilainen P, 2003, NEUROSCI LETT, V349, P79, DOI 10.1016/S0304-3940(03)00787-0
   Pilling M, 2009, J SPEECH LANG HEAR R, V52, P1073, DOI [10.1044/1092-4388, 10.1044/1092-4388(2009/07-0276)]
   Pratt H, 2015, BRAIN BEHAV, V5, DOI 10.1002/brb3.407
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rinne T, 2000, NEUROIMAGE, V12, P14, DOI 10.1006/nimg.2000.0591
   RITTER W, 1992, ELECTROEN CLIN NEURO, V83, P306, DOI 10.1016/0013-4694(92)90090-5
   Romero YR, 2015, J NEUROPHYSIOL, V113, P2342, DOI 10.1152/jn.00783.2014
   Saint-Amour D, 2007, NEUROPSYCHOLOGIA, V45, P587, DOI 10.1016/j.neuropsychologia.2006.03.036
   SAMS M, 1991, NEUROSCI LETT, V127, P141, DOI 10.1016/0304-3940(91)90914-F
   Schwartz JL, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003743
   Schwartz JL, 2010, J ACOUST SOC AM, V127, P1584, DOI 10.1121/1.3293001
   Shahin AJ, 2018, J NEUROSCI, V38, P1835, DOI 10.1523/JNEUROSCI.1566-17.2017
   Smith E, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073148
   Strand J, 2014, J SPEECH LANG HEAR R, V57, P2322, DOI 10.1044/2014_JSLHR-H-14-0059
   Tiippana K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00725
   Tremblay KL, 2003, EAR HEARING, V24, P225, DOI 10.1097/01.AUD.0000069229.84883.03
   Tse CY, 2015, J COGNITIVE NEUROSCI, V27, P1723, DOI 10.1162/jocn_a_00812
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   van Wassenhove V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00388
   Venezia JH, 2016, ATTEN PERCEPT PSYCHO, V78, P583, DOI 10.3758/s13414-015-1026-y
   Vroomen J, 2010, ATTEN PERCEPT PSYCHO, V72, P871, DOI 10.3758/APP.72.4.871
   Wacongne C, 2012, J NEUROSCI, V32, P3665, DOI 10.1523/JNEUROSCI.5003-11.2012
   WILLIAMS SB, 1949, J OPT SOC AM, V39, P782, DOI 10.1364/JOSA.39.000782
   Wilson AH, 2016, J SPEECH LANG HEAR R, V59, P601, DOI 10.1044/2016_JSLHR-S-15-0092
NR 65
TC 0
Z9 0
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3425
J9 BRAIN SCI
JI Brain Sci.
PD JUN
PY 2020
VL 10
IS 6
AR 328
DI 10.3390/brainsci10060328
PG 17
WC Neurosciences
SC Neurosciences & Neurology
GA MO5QJ
UT WOS:000551580000001
PM 32481538
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Svirsky, MA
   Neuman, AC
   Neukam, JD
   Lavender, A
   Miller, MK
   Aaron, KA
   Skarzynski, PH
   Cywka, KB
   Skarzynski, H
   Truy, E
   Seldran, F
   Hermann, R
   Govaerts, P
   De Ceulaer, G
   Bergeron, F
   Hotton, M
   Moran, M
   Dowell, RC
   Goffi-Gomez, MVS
   Magalhaes, ATD
   Santarelli, R
   Scimemi, P
AF Svirsky, Mario A.
   Neuman, Arlene C.
   Neukam, Jonathan D.
   Lavender, Annette
   Miller, Margaret K.
   Aaron, Ksenia A.
   Skarzynski, Piotr H.
   Cywka, Katarzyna B.
   Skarzynski, Henryk
   Truy, Eric
   Seldran, Fabien
   Hermann, Ruben
   Govaerts, Paul
   De Ceulaer, Geert
   Bergeron, Francois
   Hotton, Matthieu
   Moran, Michelle
   Dowell, Richard C.
   Schmidt Goffi-Gomez, Maria Valeria
   de Matos Magalhaes, Ana Tereza
   Santarelli, Rosamaria
   Scimemi, Pietro
TI Speech Perception Changes in the Acoustically Aided, Nonimplanted Ear
   after Cochlear Implantation: A Multicenter Study
SO JOURNAL OF CLINICAL MEDICINE
LA English
DT Article
DE cochlear implants; hearing aid; bimodal; speech perception; auditory
   neglect; deafness; multicenter
ID ONSET AUDITORY DEPRIVATION; USE HEARING-AIDS; ASYMMETRIC HEARING;
   RECOGNITION; STIMULATION; BENEFITS; CONJUNCTION; ADULTS; INFORMATION;
   LISTENERS
AB In recent years there has been an increasing percentage of cochlear implant (CI) users who have usable residual hearing in the contralateral, nonimplanted ear, typically aided by acoustic amplification. This raises the issue of the extent to which the signal presented through the cochlear implant may influence how listeners process information in the acoustically stimulated ear. This multicenter retrospective study examined pre- to postoperative changes in speech perception in the nonimplanted ear, the implanted ear, and both together. Results in the latter two conditions showed the expected increases, but speech perception in the nonimplanted ear showed a modest yet meaningful decrease that could not be completely explained by changes in unaided thresholds, hearing aid malfunction, or several other demographic variables. Decreases in speech perception in the nonimplanted ear were more likely in individuals who had better levels of speech perception in the implanted ear, and in those who had better speech perception in the implanted than in the nonimplanted ear. This raises the possibility that, in some cases, bimodal listeners may rely on the higher quality signal provided by the implant and may disregard or even neglect the input provided by the nonimplanted ear.
C1 [Svirsky, Mario A.; Neuman, Arlene C.; Neukam, Jonathan D.] NYU, Grossman Sch Med, Dept Otolaryngol Head & Neck Surg, New York, NY 10016 USA.
   [Svirsky, Mario A.] NYU, Grossman Sch Med, Neurosci Inst, New York, NY 10016 USA.
   [Svirsky, Mario A.] NYU, Ctr Neural Sci, New York, NY 10003 USA.
   [Lavender, Annette] Cochlear Amer, Denver, CO 80124 USA.
   [Miller, Margaret K.] Boys Town Natl Res Hosp, Human Auditory Dev Lab, Omaha, NE 68131 USA.
   [Aaron, Ksenia A.] Stanford Med, Otolaryngol Head & Neck Surg, Stanford, CA 94305 USA.
   [Skarzynski, Piotr H.] World Hearing Ctr, Inst Physiol & Pathol Hearing, Dept Teleaudiol & Screening, PL-02042 Warsaw, Poland.
   [Skarzynski, Piotr H.] Med Univ Warsaw, Heart Failure & Cardiac Rehabil Dept, PL-02091 Warsaw, Poland.
   [Skarzynski, Piotr H.] Inst Sensory Organs, PL-05830 Warsaw, Poland.
   [Cywka, Katarzyna B.; Skarzynski, Henryk] Inst Physiol & Pathol Hearing, World Hearing Ctr, Dept Otorhinolaryngosurg, PL-02042 Warsaw, Poland.
   [Truy, Eric; Hermann, Ruben] Lyon Neurosci Res Ctr, Equipe IMPACT, INSERM U1028, F-69000 Lyon, France.
   [Truy, Eric; Hermann, Ruben] Lyon Neurosci Res Ctr, Equipe IMPACT, CNRS UMR5292, F-69000 Lyon, France.
   [Seldran, Fabien] Medel France, F-06160 Antibes, France.
   [Govaerts, Paul; De Ceulaer, Geert] Oorgroep, Herentalsebaan 75, B-2100 Antwerp, Belgium.
   [Bergeron, Francois; Hotton, Matthieu] Univ Laval, 1050 Ave Med, Quebec City, PQ G1V 0A6, Canada.
   [Moran, Michelle; Dowell, Richard C.] Univ Melbourne, Melbourne, Vic 3053, Australia.
   [Moran, Michelle; Dowell, Richard C.] Royal Victorian Eye & Ear Hosp, East Melbourne, Vic 3002, Australia.
   [Moran, Michelle; Dowell, Richard C.] HEARing Cooperat Res Ctr, Melbourne, Vic 3053, Australia.
   [Schmidt Goffi-Gomez, Maria Valeria; de Matos Magalhaes, Ana Tereza] Univ Sao Paulo, Hosp Clin, Fac Med, Av Dr Eneas de Carvalho Aguiar 255, BR-05403000 Sao Paulo, Brazil.
   [Santarelli, Rosamaria; Scimemi, Pietro] Univ Padua, Sch Med & Surg, Dept Neurosci, I-35128 Padua, Italy.
   [Santarelli, Rosamaria; Scimemi, Pietro] Santi Giovanni & Paolo Hosp, Otorhinolaryngol & Audiol Unit, I-30126 Venice, Italy.
RP Svirsky, MA (corresponding author), NYU, Grossman Sch Med, Dept Otolaryngol Head & Neck Surg, New York, NY 10016 USA.; Svirsky, MA (corresponding author), NYU, Grossman Sch Med, Neurosci Inst, New York, NY 10016 USA.; Svirsky, MA (corresponding author), NYU, Ctr Neural Sci, New York, NY 10003 USA.
EM mario.svirsky@nyulangone.org; arlene.neuman@gmail.com;
   jonathan.neukam@nyulangone.org; annettezeman@gmail.com;
   margaret.miller@boystown.org; ksenia.prosolovich@gmail.com;
   p.skarzynski@ifps.org.pl; k.cywka@ifps.org.pl; h.skarzynski@ifps.org.pl;
   eric.truy@chu-lyon.fr; fabien.Seldran@medel.com; rubenhermann@gmail.com;
   dr.govaerts@eargroup.net; deceulaer@eargroup.net;
   francois.bergeron@rea.ulaval.ca; mathieu.hotton.1@ulaval.ca;
   mmoran@unimelb.edu.au; rcd@unimelb.edu.au; goffigomez@uol.com.br;
   anatereza32@gmail.com; rosamaria.santarelli@gmail.com;
   pietro.scimemi@unipd.it
RI Skarzynski, Piotr H./A-9642-2012; Dowell, Richard/AAX-7046-2020;
   Scimemi, Pietro/T-5390-2017; Svirsky, Mario/A-4160-2008
OI Skarzynski, Piotr H./0000-0002-4978-1915; Scimemi,
   Pietro/0000-0001-5273-1938; Svirsky, Mario/0000-0002-9238-0682; Miller,
   Margaret/0000-0002-5095-5927; Hotton, Mathieu/0000-0001-7837-0552;
   Skarzynski, Henryk/0000-0001-7141-9851; De Ceulaer,
   Geert/0000-0003-2639-2578; Neuman, Arlene/0000-0002-8688-0867; Govaerts,
   Paul/0000-0002-9519-9002; Bergeron, Francois/0000-0001-7656-7749
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R01-DC011329, R01-DC03937]
FX This research was funded by NIH grants R01-DC011329 (Principal
   Investigators: Svirsky and Neuman) and R01-DC03937 (Principal
   Investigator: Svirsky).
CR Armstrong M, 1997, AM J OTOL, V18, pS140
   Arndt S, 2017, HNO, V65, P98, DOI 10.1007/s00106-016-0297-5
   Benfante H., 1966, AUDIOMETRIE VOCALE
   Bergeron F., 1998, CAN J REHABIL, V11, P182
   Boothroyd A, 1985, SENTENCE TEST SPEECH
   Bosman AJ, 1995, AUDIOLOGY, V34, P260
   Carney E, 2007, J SPEECH LANG HEAR R, V50, P1203, DOI 10.1044/1092-4388(2007/084)
   Ching T.Y., 2005, HEAR J, V58, P32, DOI DOI 10.1097/01.HJ.0000286404.64930.A8
   Ching TYC, 2004, EAR HEARING, V25, P9, DOI 10.1097/01.AUD.0000111261.84611.C8
   Costa MJ, 2000, PRO-FONO REV ATUAL C, V12, P9
   Cutugno F., 2000, AUDIOMETRIA VOCALE, VIV
   DOOLEY GJ, 1993, ARCH OTOLARYNGOL, V119, P55
   Dorman MF, 2008, AUDIOL NEURO-OTOL, V13, P105, DOI 10.1159/000111782
   Dorman MF, 2015, HEARING RES, V322, P107, DOI 10.1016/j.heares.2014.09.010
   Dunn CC, 2005, J SPEECH LANG HEAR R, V48, P668, DOI 10.1044/1092-4388(2005/046)
   Firszt JB, 2008, J REHABIL RES DEV, V45, P749, DOI 10.1682/JRRD.2007.08.0120
   Firszt JB, 2018, EAR HEARING, V39, P845, DOI 10.1097/AUD.0000000000000548
   Gifford RH, 2007, J SPEECH LANG HEAR R, V50, P835, DOI 10.1044/1092-4388(2007/058)
   Gifford RH, 2010, EAR HEARING, V31, P186, DOI 10.1097/AUD.0b013e3181c6b831
   Gordon K, 2019, HEARING RES, V380, P60, DOI 10.1016/j.heares.2019.05.011
   Gordon K, 2015, PEDIATRICS, V136, P141, DOI 10.1542/peds.2014-3520
   Hamzavi J, 2004, INT J AUDIOL, V43, P61, DOI 10.1080/14992020400050010
   Illg A, 2014, OTOL NEUROTOL, V35, pE240, DOI 10.1097/MAO.0000000000000529
   Kong YY, 2011, J SPEECH LANG HEAR R, V54, P959, DOI 10.1044/1092-4388(2010/10-0197)
   Kong YY, 2005, J ACOUST SOC AM, V117, P1351, DOI 10.1121/1.1857526
   Kral A, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00093
   Lafon J.-C., 1964, TEST PHONETIQUE MESU
   Landsberger DM, 2015, EAR HEARING, V36, pE207, DOI 10.1097/AUD.0000000000000163
   Litovsky RY, 2006, INT J AUDIOL, V45, pS78, DOI 10.1080/14992020600782956
   Luntz M, 2005, ACTA OTO-LARYNGOL, V125, P863, DOI 10.1080/00016480510035395
   Mertens G, 2017, EAR HEARING, V38, P117, DOI 10.1097/AUD.0000000000000359
   Mitchell RE, 2006, J DEAF STUD DEAF EDU, V11, P112, DOI 10.1093/deafed/enj004
   Mok M, 2006, J SPEECH LANG HEAR R, V49, P338, DOI 10.1044/1092-4388(2006/027)
   Morera C, 2005, ACTA OTO-LARYNGOL, V125, P596, DOI 10.1080/00016480510027493
   Neuman AC, 1996, EAR HEARING, V17, pS3, DOI 10.1097/00003446-199617031-00002
   Neuman AC, 2019, EAR HEARING, V40, P621, DOI 10.1097/AUD.0000000000000638
   Neuman AC, 2013, EAR HEARING, V34, P553, DOI 10.1097/AUD.0b013e31828e86e8
   PETERSON GE, 1962, J SPEECH HEAR DISORD, V27, P62, DOI 10.1044/jshd.2701.62
   Pika E., 2015, NOWA AUDIOFONOL, V4, P67, DOI [10.17431/895188, DOI 10.17431/895188]
   Pruszewicz A, 1994, Otolaryngol Pol, V48, P50
   SILMAN S, 1984, J ACOUST SOC AM, V76, P1357, DOI 10.1121/1.391451
   Sladen DP, 2018, OTOL NEUROTOL, V39, P576, DOI 10.1097/MAO.0000000000001763
   Spahr AJ, 2012, EAR HEARING, V33, P112, DOI 10.1097/AUD.0b013e31822c2549
   Svirsky M.A., 2011, ASS RES OTOLARYNGOL, P167
   Thompson NJ, 2020, OTOLARYNG HEAD NECK, V162, P933, DOI 10.1177/0194599820911716
   van Loon MC, 2017, OTOL NEUROTOL, V38, pE100, DOI 10.1097/MAO.0000000000001418
   WALTZMAN SB, 1992, AM J OTOL, V13, P308
   Wojnowski Waldemar, 2006, Otolaryngol Pol, V60, P385
   Zhang T, 2010, EAR HEARING, V31, P63, DOI 10.1097/AUD.0b013e3181b7190c
NR 49
TC 0
Z9 0
U1 1
U2 2
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2077-0383
J9 J CLIN MED
JI J. Clin. Med.
PD JUN
PY 2020
VL 9
IS 6
AR 1758
DI 10.3390/jcm9061758
PG 15
WC Medicine, General & Internal
SC General & Internal Medicine
GA ML2LF
UT WOS:000549303300001
PM 32517138
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Barreda, S
AF Barreda, Santiago
TI VOWEL NORMALIZATION AS PERCEPTUAL CONSTANCY
SO LANGUAGE
LA English
DT Article
DE vowel normalization; speech perception; variation; vowel quality;
   sociolinguistics
ID VOCAL-TRACT LENGTH; APPARENT VISUAL SIZE; GLOTTAL-PULSE RATE;
   FUNDAMENTAL-FREQUENCY; TALKER VARIABILITY; OBJECT FAMILIARITY;
   FORMANT-FREQUENCY; SPEAKER SIZE; SPEECH; INFORMATION
AB This study investigates how listeners associate acoustically different vowels with a single linguistic vowel quality. Listeners were asked to identify vowel sounds as /ae/ or /Lambda/ and to indicate the size of the speaker that produced them. Results indicate that perceived vowel quality trades off with the perception of speaker size: different vowels can sound the same, and the same vowel can sound different when a different speaker is perceived. These findings suggest that vowel normalization is broadly similar to perceptual constancy in other domains, and that social, indexical, and linguistic information play an important role in determining even the most fundamental units of linguistic representation.
C1 [Barreda, Santiago] Univ Calif Davis, Davis, CA 95616 USA.
RP Barreda, S (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.
EM sbarreda@ucdavis.edu
CR Assmann PF, 2008, J ACOUST SOC AM, V124, P3203, DOI 10.1121/1.2980456
   ASSMANN PF, 1982, J ACOUST SOC AM, V71, P975, DOI 10.1121/1.387579
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Barreda S, 2018, J ACOUST SOC AM, V144, P500, DOI 10.1121/1.5047742
   Barreda S, 2018, J ACOUST SOC AM, V143, pEL361, DOI 10.1121/1.5037614
   Barreda S, 2017, J ACOUST SOC AM, V141, P4781, DOI 10.1121/1.4985192
   Barreda S, 2013, J ACOUST SOC AM, V133, P1065, DOI 10.1121/1.4773858
   Barreda S, 2012, J ACOUST SOC AM, V132, P3453, DOI 10.1121/1.4747011
   Barreda S, 2012, J ACOUST SOC AM, V131, P466, DOI 10.1121/1.3662068
   Barreda Santiago, 2013, THESIS U ALBERTA ALB, DOI DOI 10.7939/R34Q7QZ5N
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Bristow D, 2009, J COGNITIVE NEUROSCI, V21, P905, DOI 10.1162/jocn.2009.21076
   BROADBENT DE, 1956, NATURE, V178, P815, DOI 10.1038/178815b0
   Charlton BD, 2008, J ACOUST SOC AM, V123, P2936, DOI 10.1121/1.2896758
   Charlton BD, 2007, BIOL LETTERS, V3, P382, DOI 10.1098/rsbl.2007.0244
   Charlton BD, 2012, ANIM BEHAV, V84, P1565, DOI 10.1016/j.anbehav.2012.09.034
   D'Onofrio A, 2019, LANG VAR CHANGE, V31, P193, DOI 10.1017/S0954394519000085
   Fant G., 1966, SPEECH TRANSMISSION, V7, P22
   Fant Gunnar, 1975, STL QPSR, V16, P1
   Fitch WT, 1999, J ACOUST SOC AM, V106, P1511, DOI 10.1121/1.427148
   FOWLER CA, 1980, PHONETICA, V37, P306, DOI 10.1159/000260000
   Fryar C., 2012, VITAL HLTH STAT, V11
   Gelman A, 2005, ANN STAT, V33, P1, DOI 10.1214/009053604000001048
   Gick B, 2009, NATURE, V462, P502, DOI 10.1038/nature08572
   GLASBERG BR, 1990, HEARING RES, V47, P103, DOI 10.1016/0378-5955(90)90170-T
   Glidden CM, 2004, ACOUST RES LETT ONL, V5, P132, DOI 10.1121/1.1764472
   GOGEL WC, 1969, Q J EXP PSYCHOL, V21, P239, DOI 10.1080/14640746908400218
   Granzier JJM, 2012, I-PERCEPTION, V3, P190, DOI 10.1068/i0461
   Hilbert D., 2005, PHILOS TOPICS, V33, P141
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hillenbrand JM, 2009, ATTEN PERCEPT PSYCHO, V71, P1150, DOI 10.3758/APP.71.5.1150
   Holway AH, 1941, AM J PSYCHOL, V54, P21, DOI 10.2307/1417790
   Irino T, 2002, SPEECH COMMUN, V36, P181, DOI 10.1016/S0167-6393(00)00085-6
   Johnson C, 2018, IMPLEMENTING EFFECTIVE BEHAVIOR INTERVENTION PLANS: 8 STEPS TO SUCCESS, P65
   JOHNSON K, 1990, J ACOUST SOC AM, V88, P642, DOI 10.1121/1.399767
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Johnson K, 2005, BLACKW HBK LINGUIST, P363, DOI 10.1002/9780470757024.ch15
   Joos Martin, 1948, LANGUAGE MONOGRAPH, V23, DOI [10.2307/522229, DOI 10.2307/522229]
   Kaiser P. K., 1996, HUMAN COLOR VISION
   KUHL PK, 1983, INFANT BEHAV DEV, V6, P263, DOI 10.1016/S0163-6383(83)80036-8
   KUHL PK, 1979, J ACOUST SOC AM, V66, P1668, DOI 10.1121/1.383639
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Lammert AC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0132193
   Lee S, 1999, J ACOUST SOC AM, V105, P1455, DOI 10.1121/1.426686
   Lloyd RJ, 1890, SOME RES NATURE VOWE
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   Martin A, 2015, J EXP PSYCHOL HUMAN, V41, P283, DOI 10.1037/xhp0000027
   MARTIN CS, 1989, J EXP PSYCHOL LEARN, V15, P676, DOI 10.1037/0278-7393.15.4.676
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MILLER JD, 1989, J ACOUST SOC AM, V85, P2114, DOI 10.1121/1.397862
   MULLENNIX JW, 1989, J ACOUST SOC AM, V85, P365, DOI 10.1121/1.397688
   Nearey Terrance M., 2007, EXPT APPROACHES PHON, P246
   Nearey Terrance M., 1983, J ACOUST SOC AM S1, V74, pS17, DOI [10.1121/1.2020835, DOI 10.1121/1.2020835]
   Nearey Terrance Michael, 1978, PHONETIC FEATURE SYS
   NEAREY TM, 1989, J ACOUST SOC AM, V85, P2088, DOI 10.1121/1.397861
   Nordstrom Per-Erik, 1975, P 8 INT C PHON SCI I
   Nusbaum H.C., 1997, TALKER VARIABILITY S, P109
   Nusbaum HC, 1992, SPEECH PERCEPTION PR, P113
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Patterson RD, 2014, SPRINGER HANDB AUDIT, V50, P417, DOI 10.1007/978-1-4614-9102-6_23
   PETERSON GE, 1961, J SPEECH HEAR RES, V4, P10, DOI 10.1044/jshr.0401.10
   PICKENS J, 1994, DEV PSYCHOL, V30, P537, DOI 10.1037/0012-1649.30.4.537
   Pietraszewski D, 2017, P ROY SOC B-BIOL SCI, V284, DOI 10.1098/rspb.2017.0656
   Pisanski K, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-10470-3
   Pisanski K, 2011, J ACOUST SOC AM, V129, P2201, DOI 10.1121/1.3552866
   Plummer M, 2003, P 3 INT WORKSH DISTR
   Podesva RJ, 2015, LANG VAR CHANGE, V27, P157, DOI 10.1017/S095439451500006X
   Purcell DW, 2006, J ACOUST SOC AM, V120, P966, DOI 10.1121/1.2217714
   R Core Team, 2018, R LANG ENV STAT COMP
   RAKERD B, 1985, J ACOUST SOC AM, V77, P296, DOI 10.1121/1.392393
   Reby D, 2005, P ROY SOC B-BIOL SCI, V272, P941, DOI 10.1098/rspb.2004.2954
   Reby D, 2003, ADV STUD BEHAV, V33, P231, DOI 10.1016/S0065-3454(03)33005-0
   Reby D, 2003, ANIM BEHAV, V65, P519, DOI 10.1006/anbe.2003.2078
   Reby D, 2012, ANIM COGN, V15, P265, DOI 10.1007/s10071-011-0451-0
   SLATER A, 1990, J EXP CHILD PSYCHOL, V49, P314, DOI 10.1016/0022-0965(90)90061-C
   SLATER A, 1985, PERCEPTION, V14, P337, DOI 10.1068/p140337
   Smith DRR, 2007, J ACOUST SOC AM, V122, P3628, DOI 10.1121/1.2799507
   Smith DRR, 2014, ACTA PSYCHOL, V148, P81, DOI 10.1016/j.actpsy.2014.01.010
   Smith DRR, 2005, J ACOUST SOC AM, V118, P3177, DOI 10.1121/1.2047107
   Smith DRR, 2005, J ACOUST SOC AM, V117, P305, DOI 10.1121/1.1828637
   Sperandio I, 2015, MULTISENS RES, V28, P253, DOI 10.1163/22134808-00002483
   Story BH, 2018, J ACOUST SOC AM, V143, P3079, DOI 10.1121/1.5038264
   SUSSMAN HM, 1986, BRAIN LANG, V28, P12, DOI 10.1016/0093-934X(86)90087-8
   SYRDAL AK, 1986, J ACOUST SOC AM, V79, P1086, DOI 10.1121/1.393381
   Taylor AM, 2010, ANIM BEHAV, V79, P205, DOI 10.1016/j.anbehav.2009.10.030
   Turner RE, 2009, J ACOUST SOC AM, V125, P2374, DOI 10.1121/1.3079772
   WAKITA H, 1977, IEEE T ACOUST SPEECH, V25, P183, DOI 10.1109/TASSP.1977.1162929
   Winer Ethan, 2012, AUDIO EXPERT EVERYTH
   Wong PCM, 2004, J COGNITIVE NEUROSCI, V16, P1173, DOI 10.1162/0898929041920522
   ZEIGLER HP, 1957, AM J PSYCHOL, V70, P106, DOI 10.2307/1419238
   Zellou G, 2018, LAB PHONOL, V9, DOI 10.5334/labphon.118
   Zhang Caicai, 2012, TON ASP LANG 3 INT S
NR 92
TC 0
Z9 0
U1 1
U2 1
PU LINGUISTIC SOC AMER
PI WASHINGTON
PA 1325 18TH ST NW, SUITE 211, WASHINGTON, DC 20036-6501 USA
SN 0097-8507
EI 1535-0665
J9 LANGUAGE
JI Language
PD JUN
PY 2020
VL 96
IS 2
BP 224
EP 254
DI 10.1353/lan.2020.0018
PG 31
WC Linguistics; Language & Linguistics
SC Linguistics
GA MC1AO
UT WOS:000543029200009
OA Bronze
DA 2021-02-24
ER

PT J
AU Georgiou, GP
AF Georgiou, Georgios P.
TI Discrimination of Uncategorized-Categorized and
   Uncategorized-Uncategorized Greek consonantal contrasts by Russian
   speakers
SO TOPICS IN LINGUISTICS
LA English
DT Article
DE reaction times; uncategorized-categorized assimilation;
   uncategorized-uncategorized assimilation; discrimination accuracy; Greek
   consonants; Russian speakers
ID PERCEPTUAL ASSIMILATION; SPEECH-PERCEPTION; JAPANESE ADULTS; EXPERIENCE
AB The purpose of this study is to investigate the discriminability of two different assimilation types, the Uncategorized-Categorized (UC) and the Uncategorized-Uncategorized assimilation (UU) (Best and Tyler, 2007), as reflected in the discrimination accuracy and reaction times towards non-native contrasts by Russian speakers. The discriminability of these assimilation types varies in the literature. To this purpose, the same Russian speakers who evaluated Greek consonantal contrasts as UC and UU types in an assimilation test of a previous study completed an AXB discrimination test in this study to detect the discriminability of these assimilation types. The findings demonstrated that most of the UU non-overlapping (UU-N) types, and specifically those with focalized-focalized responses, were more accurately discriminated and had faster RTs than the UC non-overlapping (UC-N) type. However, one UU-N type with clustered-clustered responses did not differ in terms of discrimination accuracy and reaction times with the UC-N type. It is suggested that despite having the same overlapping parameters (non-overlapping), UU types might be more discriminable than UC types with respect to consonants. Also, similarity of uncategorized phones with other assimilated phones (e.g., focalized, clustered, dispersed) might shape the UC-UU type relationship. Finally, it is assumed that the discriminability of UC-UU types might be consonant-specific.
C1 [Georgiou, Georgios P.] Peoples Friendship Univ Russia, RUDN Univ, Moscow, Russia.
   [Georgiou, Georgios P.] Univ Nicosia, Nicosia, Cyprus.
RP Georgiou, GP (corresponding author), Sotiriou Tsangari 3C, Oroklini, Cyprus.; Georgiou, GP (corresponding author), RUDN Univ, Miklukho Maklaya St 6, Moscow 117198, Russia.
EM georgiou.georgos@hotmail.com
OI Georgiou, Georgios/0000-0002-7192-2649
FU RUDN University Program 5-100
FX The publication has been prepared with the support of the "RUDN
   University Program 5-100".
CR Al Mahmoud MS, 2013, STUD SECOND LANG LE, V3, P261
   Antoniou M, 2012, J PHONETICS, V40, P582, DOI 10.1016/j.wocn.2012.05.005
   Best C., 2007, LANGUAGE EXPERIENCE, P301
   Best C., 1995, SPEECH PERCEPTION LI, P171
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   BEST CT, 1992, J PHONETICS, V20, P305, DOI 10.1016/S0095-4470(19)30637-0
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Boersma Paul, 2019, PRAAT DOING PHONETIC
   Escudero P., 2009, PHONOLOGY PERCEPTION, P151
   Faris MM, 2018, J PHONETICS, V70, P1, DOI 10.1016/j.wocn.2018.05.003
   Faris MM, 2016, J ACOUST SOC AM, V139, pEL1, DOI 10.1121/1.4939608
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J.E., 2005, ORIGINS DEV SPEECH L
   Flege James, 2002, INTEGRATED VIEW LANG, P217
   Georgiou G. P., 2019, PERCEPTUAL REA UNPUB
   Georgiou GP, 2019, LANG SCI, V72, P1, DOI 10.1016/j.langsci.2018.12.001
   Georgiou GP, 2018, SPEECH COMMUN, V102, P68, DOI 10.1016/j.specom.2018.07.003
   Georgiou GP., 2019, J EXPT PHONETICS, V28, P229
   Guion SG, 2000, J ACOUST SOC AM, V107, P2711, DOI 10.1121/1.428657
   Harnsberger JD, 2001, J ACOUST SOC AM, V110, P489, DOI 10.1121/1.1371758
   McClelland JL, 2002, PHYSIOL BEHAV, V77, P657, DOI 10.1016/S0031-9384(02)00916-2
   MIYAWAKI K, 1975, PERCEPT PSYCHOPHYS, V18, P331, DOI 10.3758/BF03211209
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   POLKA L, 1992, PERCEPT PSYCHOPHYS, V52, P37, DOI 10.3758/BF03206758
   POLKA L, 1991, J ACOUST SOC AM, V89, P2961, DOI 10.1121/1.400734
   Posner M. I., 1969, PSYCHOL LEARN MOTIV, P44
   POSNER MI, 1967, PSYCHOL REV, V74, P392, DOI 10.1037/h0024913
   Schneider L., 2011, P INTERSPEECH, P2221
   Tyler MD, 2014, PHONETICA, V71, P4, DOI 10.1159/000356237
NR 29
TC 5
Z9 5
U1 0
U2 0
PU SCIENDO
PI WARSAW
PA BOGUMILA ZUGA 32A, WARSAW, MAZOVIA, POLAND
SN 1337-7590
EI 2199-6504
J9 TOP LINGUIST
JI Top. Linguist.
PD JUN
PY 2020
VL 21
IS 1
BP 74
EP 82
DI 10.2478/topling-2020-0005
PG 9
WC Language & Linguistics
SC Linguistics
GA MC6NP
UT WOS:000543401500005
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Borghini, G
   Hazan, V
AF Borghini, Giulia
   Hazan, Valerie
TI Effects of acoustic and semantic cues on listening effort during native
   and non-native speech perception
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID CLEAR SPEECH; CONVERSATIONAL SPEECH; PROCESSING LOAD; INTELLIGIBILITY;
   RECOGNITION; PROFICIENCY; NOISE; REVERBERATION; PUPILLOMETRY; DIFFICULTY
AB Relative to native listeners, non-native listeners who are immersed in a second language environment experience increased listening effort and a reduced ability to successfully perform an additional task while listening. Previous research demonstrated that listeners can exploit a variety of intelligibility-enhancing cues to cope with adverse listening conditions. However, little is known about the implications of those speech perception strategies for listening effort. The current research aims to investigate by means of pupillometry how listening effort is modulated in native and non-native listeners by the availability of semantic context and acoustic enhancements during the comprehension of spoken sentences. For this purpose, semantic plausibility and speaking style were manipulated both separately and in combination during a speech perception task in noise. The signal to noise ratio was individually adjusted for each participant in order to target 50% intelligibility level. Behavioural results indicated that native and non-native listeners were equally able to fruitfully exploit both semantic and acoustic cues to aid their comprehension. Pupil data indicated that listening effort was reduced for both groups of listeners when acoustic enhancements were available, while the presence of a plausible semantic context did not lead to a reduction in listening effort.
C1 [Borghini, Giulia; Hazan, Valerie] UCL, Dept Speech Hearing & Phonet Sci, Fac Brain Sci, London WC1N1PF, England.
   [Borghini, Giulia] Ist Italiano Tecnol, Cognit Mot & Neurosci Unit, Ctr Human Technol, Via E Melen 83, I-16152 Genoa, Italy.
RP Borghini, G (corresponding author), UCL, Dept Speech Hearing & Phonet Sci, Fac Brain Sci, London WC1N1PF, England.
EM giulia.borghini.13@ucl.ac.uk
FU Economic and Social Research CouncilUK Research & Innovation
   (UKRI)Economic & Social Research Council (ESRC) [ES/J500185/1]
FX This work was supported by the Economic and Social Research Council
   (Grant No. ES/J500185/1). The authors would like to thank Outi Tuomainen
   for her statistical support.
CR Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   BENNUN Y, 1986, BRAIN LANG, V28, P1, DOI 10.1016/0093-934X(86)90086-6
   Borghini G, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00152
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Bradlow AR, 2002, J ACOUST SOC AM, V112, P272, DOI 10.1121/1.1487837
   Calandruccio L, 2012, J SPEECH LANG HEAR R, V55, P1342, DOI 10.1044/1092-4388(2012/11-0260)
   Chapman LR, 2015, J SPEECH LANG HEAR R, V58, P1508, DOI 10.1044/2015_JSLHR-L-14-0287
   Drager KDR, 2001, J SPEECH LANG HEAR R, V44, P1052, DOI 10.1044/1092-4388(2001/083)
   ELSHTAIN EL, 1968, PSYCHON SCI, V12, P143
   Elston-Guttler KE, 2009, J COGNITIVE NEUROSCI, V21, P180, DOI 10.1162/jocn.2009.21015
   Ferguson SH, 2004, J ACOUST SOC AM, V116, P2365, DOI 10.1121/1.1788730
   Francis AL, 2018, J SPEECH LANG HEAR R, V61, P1815, DOI 10.1044/2018_JSLHR-H-17-0254
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Grynpas J., 2011, INT C PHON SCI
   Hahne A, 2001, J PSYCHOLINGUIST RES, V30, P251, DOI 10.1023/A:1010490917575
   Hazan V, 2012, J ACOUST SOC AM, V132, pEL371, DOI 10.1121/1.4757698
   JUST MA, 1993, CAN J EXP PSYCHOL, V47, P310, DOI 10.1037/h0078820
   Koch X, 2016, J ACOUST SOC AM, V139, P1618, DOI 10.1121/1.4944032
   Kramer SE, 2013, LANG COGNITIVE PROC, V28, P426, DOI 10.1080/01690965.2011.642267
   Kuchinsky SE, 2013, PSYCHOPHYSIOLOGY, V50, P23, DOI 10.1111/j.1469-8986.2012.01477.x
   Kuipers Jan Rouke, 2011, Front Hum Neurosci, V5, P61, DOI 10.3389/fnhum.2011.00061
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Li P, 2014, BILING-LANG COGN, V17, P673, DOI 10.1017/S1366728913000606
   Marion V, 2007, J SPEECH LANG HEAR R, V50, P940, DOI 10.1044/1092-4388(2007/067)
   Mattys SL, 2010, SPEECH COMMUN, V52, P887, DOI 10.1016/j.specom.2010.01.005
   Mayo LH, 1997, J SPEECH LANG HEAR R, V40, P686, DOI 10.1044/jslhr.4003.686
   PAYTON KL, 1994, J ACOUST SOC AM, V95, P1581, DOI 10.1121/1.408545
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Piquado T, 2010, PSYCHOPHYSIOLOGY, V47, P560, DOI 10.1111/j.1469-8986.2009.00947.x
   R Core Team, 2017, R LANG ENV STAT COMP
   RICHER F, 1985, PSYCHOPHYSIOLOGY, V22, P204, DOI 10.1111/j.1469-8986.1985.tb01587.x
   Ronnberg J, 2019, INT J AUDIOL, V58, P247, DOI 10.1080/14992027.2018.1551631
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   SCHLUROFF M, 1982, BRAIN LANG, V17, P133, DOI 10.1016/0093-934X(82)90010-4
   Schmidtke J, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00137
   Simantiraki O, 2018, INTERSPEECH, P2267, DOI 10.21437/Interspeech.2018-1358
   Smiljanic R, 2011, J ACOUST SOC AM, V130, P4020, DOI 10.1121/1.3652882
   Smiljanic R, 2009, LANG LINGUIST COMPAS, V3, P236, DOI 10.1111/j.1749-818x.2008.00112.x
   Song J, 2018, COGNITION, V179, P163, DOI 10.1016/j.cognition.2018.06.001
   SRResearch, 2009, EYELINK 1000 US MAN
   TAKATA Y, 1990, J ACOUST SOC AM, V88, P663, DOI 10.1121/1.399769
   Van Engen KJ, 2014, J SPEECH LANG HEAR R, V57, P1908, DOI 10.1044/JSLHR-H-13-0076
   Wendt D, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00345
   Wingfield A, 2007, J AM ACAD AUDIOL, V18, P548, DOI 10.3766/jaaa.18.7.3
   Winn MB, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518800869
   Winn MB, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516669723
   Zekveld AA, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518777174
   Zekveld AA, 2014, PSYCHOPHYSIOLOGY, V51, P277, DOI 10.1111/psyp.12151
   Zekveld AA, 2011, EAR HEARING, V32, pE16, DOI 10.1097/AUD.0b013e318228036a
   Zekveld AA, 2010, EAR HEARING, V31, P480, DOI 10.1097/AUD.0b013e3181d4f251
   2007, J ALLERGY CLIN IMM S, V5
NR 54
TC 0
Z9 0
U1 3
U2 4
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JUN
PY 2020
VL 147
IS 6
BP 3783
EP 3794
DI 10.1121/10.0001126
PG 12
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA MA3PR
UT WOS:000541829800001
PM 32611155
DA 2021-02-24
ER

PT J
AU Avivi-Reich, M
   Fifield, B
   Schneider, BA
AF Avivi-Reich, Meital
   Fifield, Brendan
   Schneider, Bruce A.
TI Can the diffuseness of sound sources in an auditory scene alter speech
   perception?
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Hearing; Scene perception
ID SPATIAL SEPARATION; ENERGETIC MASKING; INFORMATIONAL MASKING; AGE;
   REVERBERATION; COMPREHENSION; RELEASE; YOUNGER; ADULTS; TARGET
AB When amplification is used, sound sources are often presented over multiple loudspeakers, which can alter their timbre, and introduce comb-filtering effects. Increasing the diffuseness of a sound by presenting it over spatially separated loudspeakers might affect the listeners' ability to form a coherent auditory image of it, alter its perceived spatial position, and may even affect the extent to which it competes for the listener's attention. In addition, it can lead to comb-filtering effects that can alter the spectral profiles of sounds arriving at the ears. It is important to understand how these changes affect speech perception. In this study, young adults were asked to repeat nonsense sentences presented in either noise, babble, or speech. Participants were divided into two groups: (1) A Compact-Target Timbre group where the target sentences were presented over a single loudspeaker (compact target), while the masker was either presented over three loudspeakers (diffuse) or over a single loudspeaker (compact); (2) A Diffuse-Target Timbre group, where the target sentences were diffuse while the masker was either compact or diffuse. Timbre had no significant effect in the absence of a timbre contrast between target and masker. However, when there was a timbre contrast, the signal-to-noise ratios needed for 50% correct recognition of the target speech were higher (worse) when the masker was compact, and lower (better) when the target was compact. These results were consistent with the expected effects from comb filtering, and could also reflect a tendency for attention to be drawn towards compact sound sources.
C1 [Avivi-Reich, Meital; Fifield, Brendan; Schneider, Bruce A.] Univ Toronto Mississauga, Dept Psychol, 3359 Mississauga Rd N, Mississauga, ON L5L 1C6, Canada.
   [Avivi-Reich, Meital] CUNY Brooklyn Coll, Commun Arts Sci & Disorders, Brooklyn, NY 11210 USA.
RP Schneider, BA (corresponding author), Univ Toronto Mississauga, Dept Psychol, 3359 Mississauga Rd N, Mississauga, ON L5L 1C6, Canada.
EM bruce.Schneider@utoronto.ca
FU Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR [RGPIN
   9952-13] Funding Source: Medline
CR Arbogast TL, 2002, J ACOUST SOC AM, V112, P2086, DOI 10.1121/1.1510141
   Avivi-Reich M, 2018, ATTEN PERCEPT PSYCHO, V80, P242, DOI 10.3758/s13414-017-1423-5
   Avivi-Reich M, 2015, J SPEECH LANG HEAR R, V58, P1570, DOI 10.1044/2015_JSLHR-H-14-0177
   Avivi-Reich M, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00021
   Ben-David BM, 2012, HEARING RES, V290, P55, DOI 10.1016/j.heares.2012.04.022
   BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   Brown JI, 1981, NELSON DENNY READING
   Brungart DS, 2001, J ACOUST SOC AM, V110, P2527, DOI 10.1121/1.1408946
   Brungart DS, 2002, J ACOUST SOC AM, V112, P664, DOI 10.1121/1.1490592
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   Durlach NI, 2003, J ACOUST SOC AM, V113, P2984, DOI 10.1121/1.1570435
   Ezzatian P, 2010, SPEECH COMMUN, V52, P919, DOI 10.1016/j.specom.2010.04.001
   Franconeri SL, 2003, PERCEPT PSYCHOPHYS, V65, P999, DOI 10.3758/BF03194829
   Freyman RL, 2004, J ACOUST SOC AM, V115, P2246, DOI 10.1121/1.1689343
   Freyman RL, 1999, J ACOUST SOC AM, V106, P3578, DOI 10.1121/1.428211
   Helfer KS, 1997, J SPEECH LANG HEAR R, V40, P432, DOI 10.1044/jslhr.4002.432
   Humes LE, 2006, J ACOUST SOC AM, V120, P2926, DOI 10.1121/1.2354070
   Kidd Gerald Jr., 2008, V29, P143
   Lavandier M, 2008, J ACOUST SOC AM, V123, P2237, DOI 10.1121/1.2871943
   Li L, 2004, J EXP PSYCHOL HUMAN, V30, P1077, DOI 10.1037/0096-1523.30.6.1077
   Mattys S, 2013, SPEECH RECOGNITION A
   MERSHON DH, 1975, PERCEPT PSYCHOPHYS, V18, P409, DOI 10.3758/BF03204113
   Rakerd B, 2006, J ACOUST SOC AM, V119, P1597, DOI 10.1121/1.2161438
   Raven J. C, 1965, MILL HILL VOCABULARY
   Schneider BA, 2007, J AM ACAD AUDIOL, V18, P559, DOI 10.3766/jaaa.18.7.4
   Schneider BA, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00474
   Schneider BA, 2010, SPRINGER HANDB AUDIT, V34, P167, DOI 10.1007/978-1-4419-0993-0_7
   Vongpoisal T, 2007, J SPEECH LANG HEAR R, V50, P1139, DOI 10.1044/1092-4388(2007/079)
   Yang ZG, 2007, SPEECH COMMUN, V49, P892, DOI 10.1016/j.specom.2007.05.005
NR 30
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD JUN
PY 2020
VL 82
IS 3
BP 1443
EP 1458
DI 10.3758/s13414-019-01808-2
PG 16
WC Psychology; Psychology, Experimental
SC Psychology
GA LZ3FP
UT WOS:000541113500040
PM 31410762
OA Bronze
DA 2021-02-24
ER

PT J
AU Han, JH
   Yi, DW
   Lee, J
   Chang, WD
   Lee, HJ
AF Han, Ji-Hye
   Yi, Dong-Woon
   Lee, Jihyun
   Chang, Won-Du
   Lee, Hyo-Jeong
TI Development of a Smartphone-Based Digits-in-Noise Test in Korean: a
   Hearing Screening Tool for Speech Perception in Noise
SO JOURNAL OF KOREAN MEDICAL SCIENCE
LA English
DT Article
DE Digit-in-Noise; Speech-in-Noise; Hearing Screening; Smartphone; Korean
ID AUDITORY PROCESSING DISORDER; TRIPLET TEST; VALIDATION; IMPACT
AB Background: The digits-in-noise (DiN) test is a speech-in-noise test to measure speech recognition threshold in noise adaptively. Herein, we aimed to develop the Korean version of the DiN test to provide a useful hearing screening tool for clinical as well as research purposes.
   Method: Spoken monosyllabic digits from 0 to 9 were recorded by a female speaker. The test list was constructed such that each digit was placed in three different positions. An optimization procedure was conducted to equate the audibility of each digit. After the optimization, the smartphone application for the Korean DiN (K-DiN) test was developed. For the adaptive measurement procedure, 180 new DiN triplets separated into six lists of 30 were created. Mean speech recognition threshold values for each list and session were measured to examine the test-retest and training effects of the test materials. In addition, speech recognition threshold values measured by different devices were compared to determine whether the speech recognition threshold levels differed.
   Results: Optimization results showed that the mean speech recognition threshold and slope were -11.55 dB signal-to-noise ratio and 10.21%/dB, respectively, which are comparable to levels shown in different-language versions of the DiN test. The results of the test-retest and training effects revealed no significant differences among the test sessions and lists. Additionally, the mean speech recognition threshold values measured by four different devices were not different, indicating the reliability of the test materials.
   Conclusion: We believe this study is the first to attempt to develop a K-DiN test. Our results indicate that this test can be used as a potentially reliable hearing screening tool.
C1 [Han, Ji-Hye; Yi, Dong-Woon; Lee, Jihyun; Lee, Hyo-Jeong] Hallym Univ, Lab Brain & Cognit Sci Convergence Med, Coll Med, Anyang, South Korea.
   [Chang, Won-Du] Pukyong Natl Univ, Dept Comp Engn, Busan, South Korea.
   [Lee, Hyo-Jeong] Hallym Univ, Sacred Heart Hosp, Dept Otorhinolaryngol Head & Neck Surg, Coll Med, 22 Gwanpyeong Ro 170 Boon Gil, Anyang 14068, South Korea.
RP Lee, HJ (corresponding author), Hallym Univ, Sacred Heart Hosp, Dept Otorhinolaryngol Head & Neck Surg, Coll Med, 22 Gwanpyeong Ro 170 Boon Gil, Anyang 14068, South Korea.
EM hyojlee@hallym.ac.kr
RI Lee, Hyo-Jeong/AAK-7973-2020
OI Lee, Hyo-Jeong/0000-0003-2258-0803; Lee, Jihyun/0000-0002-8693-2217;
   Han, Ji-Hye/0000-0001-9886-7590; Chang, Won-Du/0000-0002-7437-4211
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2017R1D1A1B03030613,
   2019R1A2B5B01070129]; Center for Women in Science, Engineering and
   Technology (WISET) - Ministry of Science ICT & Future Planning of Korea
   (MSIP) under the Program for Returners into RD [WISET-2019-252]; Hallym
   University Research Fund [HURF-2017-79]
FX This project was supported by Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (2017R1D1A1B03030613 & 2019R1A2B5B01070129), the Center for
   Women in Science, Engineering and Technology (WISET) Grant funded by the
   Ministry of Science ICT & Future Planning of Korea (MSIP) under the
   Program for Returners into R&D (WISET-2019-252), and by the Hallym
   University Research Fund (HURF-2017-79).
CR Belleville S, 2003, NEUROPSYCHOLOGY, V17, P69, DOI 10.1037//0894-4105.17.1.69
   Colgan S, 2012, ACAD PEDIATR, V12, P171, DOI 10.1016/j.acap.2012.02.002
   Curhan G, 2016, SPRINGER HANDB AUDIT, V56, P21, DOI 10.1007/978-3-319-33036-5_2
   Dimitrijevic A, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00088
   Doge J, 2017, OTOL NEUROTOL, V38, pE563, DOI 10.1097/MAO.0000000000001520
   Heine C, 2008, J SCHOOL HEALTH, V78, P405, DOI 10.1111/j.1746-1561.2008.00321.x
   Jansen S, 2010, INT J AUDIOL, V49, P378, DOI 10.3109/14992020903431272
   Lagace J, 2010, AM J AUDIOL, V19, P17, DOI 10.1044/1059-0889(2010/09-0022)
   Lee SJ, 2016, COGN BEHAV NEUROL, V29, P68, DOI 10.1097/WNN.0000000000000092
   Moore DR, 2010, PEDIATRICS, V126, pE382, DOI 10.1542/peds.2009-2826
   Potgieter JM, 2016, INT J AUDIOL, V55, P405, DOI 10.3109/14992027.2016.1172269
   Smits C, 2004, INT J AUDIOL, V43, P15, DOI 10.1080/14992020400050004
   Smits C, 2013, J ACOUST SOC AM, V133, P1693, DOI 10.1121/1.4789933
   Vlaming MSMG, 2014, EAR HEARING, V35, P667, DOI 10.1097/AUD.0000000000000073
   Ziegler JC, 2009, DEVELOPMENTAL SCI, V12, P732, DOI 10.1111/j.1467-7687.2009.00817.x
   Zokoll MA, 2012, INT J AUDIOL, V51, P697, DOI 10.3109/14992027.2012.690078
NR 16
TC 0
Z9 0
U1 0
U2 0
PU KOREAN ACAD MEDICAL SCIENCES
PI SEOUL
PA 302 75 DONG DU ICHON, DONG YONGSAN KU, SEOUL 140 031, SOUTH KOREA
SN 1011-8934
EI 1598-6357
J9 J KOREAN MED SCI
JI J. Korean Med. Sci.
PD JUN 1
PY 2020
VL 35
IS 21
AR e163
DI 10.3346/jkms.2020.35.e163
PG 11
WC Medicine, General & Internal
SC General & Internal Medicine
GA LY0TY
UT WOS:000540237800004
PM 32476302
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Domingo, Y
   Holmes, E
   Johnsrude, IS
AF Domingo, Ysabel
   Holmes, Emma
   Johnsrude, Ingrid S.
TI The Benefit to Speech Intelligibility of Hearing a Familiar Voice
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-APPLIED
LA English
DT Article
DE speech perception; speech intelligibility; speech in noise; perceptual
   organization; voice familiarity
ID INFORMATIONAL MASKING; TALKER FAMILIARITY; COMPETING SPEECH; SPATIAL
   RELEASE; PERCEPTION; ATTENTION; AGE; RECOGNITION; FREQUENCY; LANGUAGE
AB Previous experience with a voice can help listeners understand speech when a competing talker is present. Using the coordinate-response measure task (Bolia, Nelson. Ericson, & Simpson. 2000), Johnsrude et al. (2013) demonstrated that speech is more intelligible when either the target or competing (masking) talker is a long-term spouse than when both talkers are unfamiliar (termed familiar-target and familiar-masker benefits, respectively). To better understand how familiarity improves intelligibility, we measured the familiar-target and familiar-masker benefits in older and younger spouses using a more challenging matrix task, and compared the benefits listeners gain from spouses' and friends' voices. On each trial. participants heard two sentences from the Boston University Gerald (Kidd. Best, & Mason, 2008) corpus ("< name > < verb > < number > < adjective > < noun >") and reported words from the sentence beginning with a target name word. A familiar-masker benefit was not observed, but all groups showed a robust familiar-target benefit and its magnitude did not differ between spouses and friends. The familiar-target benefit was not influenced by relationship length (in the range of 1.5-52 years). Together. these results imply that the familiar-target benefit can develop from various types of relationships and has already reached a plateau around 1.5 years after meeting a new friend.
C1 [Domingo, Ysabel; Holmes, Emma; Johnsrude, Ingrid S.] Univ Western Ontario, Brain & Mind Inst, Dept Psychol, Room 4115,Western Interdisciplinary Res Bldg, London, ON N6A 3K7, Canada.
   [Johnsrude, Ingrid S.] Univ Western Ontario, Sch Commun Sci & Disorders, London, ON, Canada.
   [Holmes, Emma] UCL, Wellcome Ctr Neuroimaging, Inst Neurol, London, England.
RP Domingo, Y (corresponding author), Univ Western Ontario, Brain & Mind Inst, Dept Psychol, Room 4115,Western Interdisciplinary Res Bldg, London, ON N6A 3K7, Canada.
EM bdomingo@uwo.ca
RI Johnsrude, Ingrid S/G-4694-2011
OI Johnsrude, Ingrid S/0000-0002-7810-1333; Holmes,
   Emma/0000-0002-0314-6588; Domingo, Ysabel/0000-0002-8688-2600
FU Canadian Institutes of Health ResearchCanadian Institutes of Health
   Research (CIHR) [MOP 133450]; Natural Sciences and Engineering Research
   Council of CanadaNatural Sciences and Engineering Research Council of
   Canada (NSERC)CGIAR [327429-2012]
FX This work was supported by funding from the Canadian Institutes of
   Health Research (Operating Grant: MOP 133450) and the Natural Sciences
   and Engineering Research Council of Canada (Discovery Grant:
   327429-2012).
CR Alain C, 1999, PSYCHOL AGING, V14, P507, DOI 10.1037/0882-7974.14.3.507
   Assmann P. F., 1999, P 14 INT C PHON SCI, P179
   Badri R, 2011, J ACOUST SOC AM, V129, P852, DOI 10.1121/1.3523476
   Best V, 2013, JARO-J ASSOC RES OTO, V14, P603, DOI 10.1007/s10162-013-0392-1
   Boersma P., 2013, PRAAT DOING PHONETIC
   Bolia RS, 2000, J ACOUST SOC AM, V107, P1065, DOI 10.1121/1.428288
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   Brungart DS, 2001, J ACOUST SOC AM, V110, P2527, DOI 10.1121/1.1408946
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   CARABELLESE C, 1993, J AM GERIATR SOC, V41, P401, DOI 10.1111/j.1532-5415.1993.tb06948.x
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Darwin CJ, 2003, J ACOUST SOC AM, V114, P2913, DOI 10.1121/1.1616924
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   DUBNO JR, 1984, J ACOUST SOC AM, V76, P87, DOI 10.1121/1.391011
   Durlach N, 2006, J ACOUST SOC AM, V120, P1787, DOI 10.1121/1.2335426
   Durlach NI, 2003, J ACOUST SOC AM, V114, P368, DOI 10.1121/1.1577562
   Durlach NI, 2003, J ACOUST SOC AM, V113, P2984, DOI 10.1121/1.1570435
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   GASS S, 1984, LANG LEARN, V34, P65, DOI 10.1111/j.1467-1770.1984.tb00996.x
   Glyde H, 2015, J ACOUST SOC AM, V138, P3311, DOI 10.1121/1.4934732
   Godefroy O, 2010, EXP AGING RES, V36, P169, DOI 10.1080/03610731003613615
   Helfer KS, 2008, EAR HEARING, V29, P87, DOI 10.1097/AUD.0b013e31815d638b
   Holmes E., 2019, PSYARXIV, DOI [10.31234/osf.io/2ebrs, DOI 10.31234/OSF.IO/2EBRS]
   Holmes E, 2018, PSYCHOL SCI, V29, P1575, DOI 10.1177/0956797618779083
   Huyck JJ, 2012, J ACOUST SOC AM, V131, pEL236, DOI 10.1121/1.3685511
   Johnsrude IS, 2013, PSYCHOL SCI, V24, P1995, DOI 10.1177/0956797613482467
   Kidd Gerald Jr., 2008, V29, P143
   Kidd G, 2008, J ACOUST SOC AM, V124, P3793, DOI 10.1121/1.2998980
   Kitterick PT, 2010, J ACOUST SOC AM, V127, P2498, DOI 10.1121/1.3327507
   Kreitewolf J, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01584
   Lee I. A., 2013, CALCULATION TEST DIF
   Levi SV, 2011, J ACOUST SOC AM, V130, P4053, DOI 10.1121/1.3651816
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Newman RS, 2007, J PHONETICS, V35, P85, DOI 10.1016/j.wocn.2005.10.004
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Souza P, 2013, J AM ACAD AUDIOL, V24, P689, DOI 10.3766/jaaa.24.8.6
   Summers V, 1998, J SPEECH LANG HEAR R, V41, P1294, DOI 10.1044/jslhr.4106.1294
   Tun PA, 2002, PSYCHOL AGING, V17, P453, DOI 10.1037//0882-7974.17.3.453
   Van Engen KJ, 2007, J ACOUST SOC AM, V121, P519, DOI 10.1121/1.2400666
   Yonan CA, 2000, PSYCHOL AGING, V15, P88, DOI 10.1037/0882-7974.15.1.88
NR 42
TC 1
Z9 1
U1 3
U2 3
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 1076-898X
EI 1939-2192
J9 J EXP PSYCHOL-APPL
JI J. Exp. Psychol.-Appl.
PD JUN
PY 2020
VL 26
IS 2
BP 236
EP 247
DI 10.1037/xap0000247
PG 12
WC Psychology, Applied
SC Psychology
GA LV5HQ
UT WOS:000538466400003
PM 31524431
DA 2021-02-24
ER

PT J
AU Steber, S
   Rossi, S
AF Steber, Sarah
   Rossi, Sonja
TI So young, yet so mature? Electrophysiological and vascular correlates of
   phonotactic processing in 18-month-olds
SO DEVELOPMENTAL COGNITIVE NEUROSCIENCE
LA English
DT Article
DE Phonotactics; Language acquisition; N400; Vocabulary spurt;
   Event-related brain potentials (ERPs); Functional near-infrared
   spectroscopy (fNIRS)
ID NEAR-INFRARED SPECTROSCOPY; CEREBRAL-BLOOD-FLOW; SPEECH-PERCEPTION;
   BRAIN-DEVELOPMENT; DEVELOPMENTAL-CHANGES; LANGUAGE; INFANTS; WORDS;
   FMRI; LATERALIZATION
AB The present study investigated neural correlates of implicit phonotactic processing in 18-month-old children that just reached an important step in language development: the vocabulary spurt. Pseudowords, either phonotactically legal or illegal with respect to their native language, were acoustically presented to monolingually German raised infants. Neural activity was simultaneously assessed by means of electroencephalography (EEG) and functional near-infrared spectroscopy ((NIPS). The former method excellently tracks fast processing mechanisms, whereas the latter reveals brain areas recruited. Results of the present study indicate that 18-month-olds recognize the linguistic properties of their native language based on phonotactics. This manifested in an increased N400 for legal compared to illegal pseudowords in the EEG conforming to adult-like mechanisms. Unfortunately, fNIRS findings did not support this discrimination ability. Possible methodological and brain maturational reasons might explain this null finding. This study provides evidence for the advantage of a multi-methodological approach in order to get a clear picture on neural language development.
C1 [Steber, Sarah; Rossi, Sonja] Med Univ Innsbruck, Dept Hearing Speech & Voice Disorders, ICONE Innsbruck Cognit Neurosci, Anichstr 35, A-6020 Innsbruck, Austria.
   [Steber, Sarah] Univ Innsbruck, Dept Psychol, A-6020 Innsbruck, Austria.
RP Rossi, S (corresponding author), Med Univ Innsbruck, Dept Hearing Speech & Voice Disorders, ICONE Innsbruck Cognit Neurosci, Anichstr 35, A-6020 Innsbruck, Austria.
EM sarah.steber@tirol-kliniken.at; sonja.rossi@i-med.ac.at
RI Rossi, Sonja/D-1453-2016
OI Rossi, Sonja/0000-0002-3278-8993
CR Aarabi A, 2017, NEUROIMAGE, V155, P25, DOI 10.1016/j.neuroimage.2017.04.048
   Altvater-Mackensen N, 2018, DEV COGN NEUROS-NETH, V34, P130, DOI 10.1016/j.dcn.2018.10.002
   Altvater-Mackensen N, 2016, NEUROIMAGE, V133, P14, DOI 10.1016/j.neuroimage.2016.02.061
   [Anonymous], 1991, J CLIN NEUROPHYSIOL, V8, P200, DOI 10.1097/00004691-199104000-00007
   Benavides-Varela S, 2012, P NATL ACAD SCI USA, V109, P17908, DOI 10.1073/pnas.1205413109
   Boynton GM, 2012, NEUROIMAGE, V62, P975, DOI 10.1016/j.neuroimage.2012.01.082
   Brauer J, 2008, NEUROIMAGE, V41, P1484, DOI 10.1016/j.neuroimage.2008.03.027
   Brauer J, 2007, J COGNITIVE NEUROSCI, V19, P1609, DOI 10.1162/jocn.2007.19.10.1609
   Brigadoi S, 2014, NEUROIMAGE, V85, P181, DOI 10.1016/j.neuroimage.2013.04.082
   Cao M, 2017, TRENDS NEUROSCI, V40, P494, DOI 10.1016/j.tins.2017.06.003
   Cope M, 1989, Adv Exp Med Biol, V248, P33
   Cristia A, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0058906
   Cutler A, 1996, SIGNAL TO SYNTAX: BOOTSTRAPPING FROM SPEECH TO GRAMMAR IN EARLY ACQUISITION, P87
   de Roever I, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00371
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   Di Lorenzo R, 2019, NEUROIMAGE, V200, P511, DOI 10.1016/j.neuroimage.2019.06.056
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Estes KG, 2011, INFANCY, V16, P180, DOI 10.1111/j.1532-7078.2010.00046.x
   FOX PT, 1986, P NATL ACAD SCI USA, V83, P1140, DOI 10.1073/pnas.83.4.1140
   FRIEDERICI AD, 1993, PERCEPT PSYCHOPHYS, V54, P287, DOI 10.3758/BF03205263
   Friederici AD, 2004, BRAIN LANG, V89, P267, DOI 10.1016/S0093-934X(03)00351-1
   Friedrich M, 2006, PSYCHOPHYSIOLOGY, V43, P1, DOI 10.1111/j.1469-8986.2006.00381.x
   Friedrich M, 2005, NEUROREPORT, V16, P653, DOI 10.1097/00001756-200504250-00028
   Friedrich M, 2004, J COGNITIVE NEUROSCI, V16, P1465, DOI 10.1162/0898929042304705
   Friedrich M, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12357
   Friedrich M, 2011, J COGNITIVE NEUROSCI, V23, P3228, DOI 10.1162/jocn_a_00002
   Friedrich M, 2010, BRAIN LANG, V114, P66, DOI 10.1016/j.bandl.2009.07.004
   Gandour J, 2004, NEUROIMAGE, V23, P344, DOI 10.1016/j.neuroimage.2004.06.004
   Ganger J, 2004, DEV PSYCHOL, V40, P621, DOI 10.1037/0012-1649.40.4.621
   Gao W, 2014, J NEUROSCI, V34, P11288, DOI 10.1523/JNEUROSCI.5072-13.2014
   Gao W, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025278
   Garnica Olga K., 1977, TALKING CHILDREN LAN, P63
   GOLDFIELD BA, 1990, J CHILD LANG, V17, P171, DOI 10.1017/S0305000900013167
   Gonzalez-Gomez N, 2013, J SPEECH LANG HEAR R, V56, P840, DOI 10.1044/1092-4388(2012/12-0138)
   Gow DW, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086212
   Goyet L, 2010, BRAIN RES, V1332, P75, DOI 10.1016/j.brainres.2010.03.047
   GREENHOUSE SW, 1959, PSYCHOMETRIKA, V24, P95, DOI 10.1007/BF02289823
   Grossmann T, 2010, NEURON, V65, P852, DOI 10.1016/j.neuron.2010.03.001
   Hanulikova A., 2009, SOME ASPECTS SPEECH, P331
   Harris JJ, 2011, DEV COGN NEUROS-NETH, V1, P199, DOI 10.1016/j.dcn.2011.04.001
   Holland SK, 2001, NEUROIMAGE, V14, P837, DOI 10.1006/nimg.2001.0875
   Huang H, 2006, NEUROIMAGE, V33, P27, DOI 10.1016/j.neuroimage.2006.06.009
   Huettel SA, 2009, FUNCTIONAL MAGNETIC
   Huppert TJ, 2006, NEUROIMAGE, V29, P368, DOI 10.1016/j.neuroimage.2005.08.065
   Issard C, 2018, DEV COGN NEUROS-NETH, V33, P182, DOI 10.1016/j.dcn.2018.01.009
   Johnson MH, 2001, NAT REV NEUROSCI, V2, P475, DOI 10.1038/35081509
   Junge C, 2012, NEUROPSYCHOLOGIA, V50, P3702, DOI 10.1016/j.neuropsychologia.2012.10.012
   Jusczyk PW, 1999, TRENDS COGN SCI, V3, P323, DOI 10.1016/S1364-6613(99)01363-7
   JUSCZYK PW, 1993, J MEM LANG, V32, P402, DOI 10.1006/jmla.1993.1022
   Kabdebon C, 2014, NEUROIMAGE, V99, P342, DOI 10.1016/j.neuroimage.2014.05.046
   Kleinschmidt A, 1996, J CEREBR BLOOD F MET, V16, P817, DOI 10.1097/00004647-199609000-00006
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Knickmeyer RC, 2008, J NEUROSCI, V28, P12176, DOI 10.1523/JNEUROSCI.3479-08.2008
   Koch SP, 2006, J NEUROSCI, V26, P4940, DOI 10.1523/JNEUROSCI.3989-05.2006
   Kooijman V, 2005, COGNITIVE BRAIN RES, V24, P109, DOI 10.1016/j.cogbrainres.2004.12.009
   Kooijman V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00025
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Liu HX, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0111175, 10.1371/journal.pone.0110887]
   Lloyd-Fox S, 2010, NEUROSCI BIOBEHAV R, V34, P269, DOI 10.1016/j.neubiorev.2009.07.008
   Logothetis NK, 2004, ANNU REV PHYSIOL, V66, P735, DOI 10.1146/annurev.physiol.66.082602.092845
   Luders E, 2010, J NEUROSCI, V30, P10985, DOI 10.1523/JNEUROSCI.5122-09.2010
   Mattys SL, 2001, COGNITION, V78, P91, DOI 10.1016/S0010-0277(00)00109-8
   Menyuk P., 2014, EARLY LANGUAGE DEV F, DOI [10.4324/9781315806242, DOI 10.4324/9781315806242]
   Minagawa-Kawai Y, 2007, J NEUROSCI, V27, P315, DOI 10.1523/JNEUROSCI.1984-06.2007
   Minagawa-Kawai Y, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00170
   Minagawa-Kawai Y, 2011, DEV COGN NEUROS-NETH, V1, P217, DOI 10.1016/j.dcn.2011.03.005
   Obrig H, 2003, J CEREBR BLOOD F MET, V23, P1, DOI 10.1097/01.WCB.0000043472.45775.29
   Obrig H, 2017, DEV COGN NEUROS-NETH, V25, P185, DOI 10.1016/j.dcn.2016.09.001
   Okamoto M, 2004, NEUROIMAGE, V21, P99, DOI 10.1016/j.neuroimage.2003.08.026
   Parise E, 2012, PSYCHOL SCI, V23, P728, DOI 10.1177/0956797612438734
   Perani D, 2011, P NATL ACAD SCI USA, V108, P16056, DOI 10.1073/pnas.1102991108
   Perkins JM, 1996, APHASIOLOGY, V10, P343, DOI 10.1080/02687039608248416
   Qiu AQ, 2015, ANNU REV PSYCHOL, V66, P853, DOI 10.1146/annurev-psych-010814-015340
   Rama P, 2013, BRAIN LANG, V125, P1, DOI 10.1016/j.bandl.2013.01.009
   Rossi S, 2012, BRAIN LANG, V121, P152, DOI 10.1016/j.bandl.2011.03.008
   Rossi S, 2011, J COGNITIVE NEUROSCI, V23, P1752, DOI 10.1162/jocn.2010.21547
   Schmithorst VJ, 2015, HUM BRAIN MAPP, V36, P1, DOI 10.1002/hbm.22608
   Scholkmann F, 2010, PHYSIOL MEAS, V31, P649, DOI 10.1088/0967-3334/31/5/004
   Schweizer TA, 2012, CORTEX, V48, P991, DOI 10.1016/j.cortex.2011.04.009
   Sebastian-Galles N, 2007, DEVELOPMENTAL SCI, V10, P713, DOI 10.1111/j.1467-7687.2007.00649.x
   Shultz S, 2014, DEVELOPMENTAL SCI, V17, P766, DOI 10.1111/desc.12151
   Soderstrom M, 2007, DEV REV, V27, P501, DOI 10.1016/j.dr.2007.06.002
   Steinbrink J, 2006, MAGN RESON IMAGING, V24, P495, DOI 10.1016/j.mri.2005.12.034
   Stocco A, 2014, BRAIN LANG, V137, P50, DOI 10.1016/j.bandl.2014.07.005
   Strangman G, 2002, NEUROIMAGE, V17, P719, DOI 10.1006/nimg.2002.1227
   Szaflarski JP, 2006, HUM BRAIN MAPP, V27, P202, DOI 10.1002/hbm.20177
   Telkemeyer S, 2009, J NEUROSCI, V29, P14726, DOI 10.1523/JNEUROSCI.1246-09.2009
   Thierry G, 2003, NEUROREPORT, V14, P2307, DOI 10.1097/00001756-200312190-00004
   Torkildsen JV, 2008, J COGNITIVE NEUROSCI, V20, P1266, DOI 10.1162/jocn.2008.20087
   Torkildsen JV, 2007, BRAIN LANG, V102, P243, DOI 10.1016/j.bandl.2006.11.010
   Torkildsen JV, 2009, BRAIN LANG, V108, P73, DOI 10.1016/j.bandl.2008.09.005
   Trask R. L., 2004, DICT PHONETICS PHONO, DOI [10.4324/9780203695111, DOI 10.4324/9780203695111]
   Uludag K, 2004, NEUROIMAGE, V23, P148, DOI 10.1016/j.neuroimage.2004.05.013
   Vaden KI, 2011, J COGNITIVE NEUROSCI, V23, P2665, DOI 10.1162/jocn.2011.21620
   Vasung L, 2019, NEUROIMAGE, V187, P226, DOI 10.1016/j.neuroimage.2018.07.041
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Werker JF, 2005, TRENDS COGN SCI, V9, P519, DOI 10.1016/j.tics.2005.09.003
   WERKER JF, 1983, CAN J PSYCHOL, V37, P278, DOI 10.1037/h0080725
   Woumans E, 2015, BILING-LANG COGN, V18, P568, DOI 10.1017/S136672891400087X
   Yin WY, 2019, NEUROIMAGE, V189, P715, DOI 10.1016/j.neuroimage.2019.01.025
   ZATORRE RJ, 1992, SCIENCE, V256, P846, DOI 10.1126/science.1589767
NR 102
TC 0
Z9 0
U1 1
U2 1
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1878-9293
EI 1878-9307
J9 DEV COGN NEUROS-NETH
JI Dev. Cogn. Neurosci.
PD JUN
PY 2020
VL 43
AR 100784
DI 10.1016/j.dcn.2020.100784
PG 9
WC Psychology, Developmental; Neurosciences
SC Psychology; Neurosciences & Neurology
GA LV0YM
UT WOS:000538169600007
PM 32510350
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Fullgrabe, C
   Moody, M
   Moore, BCJ
AF Fullgrabe, Christian
   Moody, Matthew
   Moore, Brian C. J.
TI No evidence for a link between noise exposure and auditory temporal
   processing for young adults with normal audiograms
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID FREQUENCY DIFFERENCE LIMENS; SPEECH-PERCEPTION; NORMAL-HEARING; COCHLEAR
AB The link between lifetime noise exposure and temporal processing abilities was investigated for 45 normal-hearing participants, recruited from a population of undergraduate students, aged 18 to 23 years. A self-report instrument was employed to assess the amount of neuropathic noise (here defined as sounds with levels exceeding approximately 80 dBA) each participant had been exposed to and sensitivity to temporal-fine-structure and temporal-envelope information was determined using frequency discrimination and envelope irregularity detection tasks, respectively. Despite sizable individual variability in all measures, correlations between noise exposure and the ability to process temporal cues were small and non-significant.
C1 [Fullgrabe, Christian; Moody, Matthew] Loughborough Univ, Sch Sport Exercise & Hlth Sci, Ashby Rd, Loughborough LE11 3TU, Leics, England.
   [Moore, Brian C. J.] Univ Cambridge, Dept Psychol, Downing St, Cambridge CB2 3EB, England.
RP Fullgrabe, C (corresponding author), Loughborough Univ, Sch Sport Exercise & Hlth Sci, Ashby Rd, Loughborough LE11 3TU, Leics, England.
EM c.fullgrabe@lboro.ac.uk; matthewdmoody@btinternet.com; bcjm@cam.ac.uk
RI Fullgrabe, Christian/I-6331-2012
OI Fullgrabe, Christian/0000-0001-9127-8136; Moore,
   Brian/0000-0001-7071-0671
CR Bharadwaj HM, 2015, J NEUROSCI, V35, P2161, DOI 10.1523/JNEUROSCI.3915-14.2015
   Bramhall N, 2019, HEARING RES, V377, P88, DOI 10.1016/j.heares.2019.02.016
   Carney LH, 2018, JARO-J ASSOC RES OTO, V19, P331, DOI 10.1007/s10162-018-0669-5
   Dobie RA, 2017, INT J AUDIOL, V56, P74, DOI 10.1080/14992027.2016.1255359
   Fullgrabe C, 2009, J ACOUST SOC AM, V125, P1277, DOI 10.1121/1.3075591
   Furman AC, 2013, J NEUROPHYSIOL, V110, P577, DOI 10.1152/jn.00164.2013
   GLASBERG BR, 1990, HEARING RES, V47, P103, DOI 10.1016/0378-5955(90)90170-T
   Grose JH, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517737417
   Guest H, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518803213
   Guest H, 2018, HEARING RES, V364, P142, DOI 10.1016/j.heares.2018.03.008
   Kujawa SG, 2009, J NEUROSCI, V29, P14077, DOI 10.1523/JNEUROSCI.2845-09.2009
   Kumar UA, 2012, NOISE HEALTH, V14, P100, DOI 10.4103/1463-1741.97252
   Liberman MC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162726
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Micheyl C, 2012, HEARING RES, V292, P1, DOI 10.1016/j.heares.2012.07.004
   Moore B. C. J., 2012, INTRO PSYCHOL HEARIN, P1
   Moore BCJ, 2000, BRIT J AUDIOL, V34, P205, DOI 10.3109/03005364000000131
   Moore BCJ, 2019, J ACOUST SOC AM, V146, P1696, DOI 10.1121/1.5126515
   Moore BCJ, 2019, J ACOUST SOC AM, V146, P1207, DOI 10.1121/1.5122794
   Moore BCJ, 2019, J ACOUST SOC AM, V145, P2861, DOI 10.1121/1.5100620
   Moore BCJ, 2014, AUDITORY PROCESSING OF TEMPORAL FINE STRUCTURE: EFFECTS OF AGE AND HEARING LOSS, P1
   Moore BCJ, 2012, J ACOUST SOC AM, V132, P1542, DOI 10.1121/1.4739444
   Oberfeld D, 2016, ELIFE, V5, DOI 10.7554/eLife.16747
   Oxenham AJ, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516686768
   Parthasarathy A, 2020, ELIFE, V9, DOI 10.7554/eLife.51419
   PASSCHIE.W, 1974, J ACOUST SOC AM, V56, P1585, DOI 10.1121/1.1903482
   Plack CJ, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514550621
   Prendergast G, 2017, HEARING RES, V356, P74, DOI 10.1016/j.heares.2017.10.007
   Ruggles D, 2011, P NATL ACAD SCI USA, V108, P15516, DOI 10.1073/pnas.1108912108
   Sek A, 2012, INT J AUDIOL, V51, P58, DOI 10.3109/14992027.2011.605808
   Stone MA, 2011, J ACOUST SOC AM, V130, P2162, DOI 10.1121/1.3625237
   Valero MD, 2017, HEARING RES, V353, P213, DOI 10.1016/j.heares.2017.07.003
   Verschooten E, 2019, HEARING RES, V377, P109, DOI 10.1016/j.heares.2019.03.011
   Yeend I, 2017, HEARING RES, V353, P224, DOI 10.1016/j.heares.2017.07.006
NR 34
TC 0
Z9 0
U1 1
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JUN
PY 2020
VL 147
IS 6
BP EL465
EP EL470
DI 10.1121/10.0001346
PG 6
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA LV0FX
UT WOS:000538121300003
PM 32611153
OA Bronze
DA 2021-02-24
ER

PT J
AU Morett, LM
AF Morett, Laura M.
TI The Influence of Tonal and Atonal Bilingualism on Children's Lexical and
   Non-Lexical Tone Perception
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Cross-linguistic speech perception; child bilingualism; lexical tone;
   pitch processing; word learning
ID SPOKEN WORD RECOGNITION; CATEGORICAL PERCEPTION; LANGUAGE EXPERIENCE;
   LINGUISTIC EXPERIENCE; EMOTIONAL INTONATION; MANDARIN CHINESE; ABSOLUTE
   PITCH; 1ST YEAR; SPEECH; AMERICAN
AB This study examined how bilingualism in an atonal language, in addition to a tonal language, influences lexical and non-lexical tone perception and word learning during childhood. Forty children aged 5;3-7;2, bilingual either in English and Mandarin or English and another atonal language, were tested on Mandarin lexical tone discrimination, level-pitch sine-wave tone discrimination, and learning of novel words differing minimally in Mandarin lexical tone. Mandarin-English bilingual children discriminated between and learned novel words differing minimally in Mandarin lexical tone more accurately than their atonal-English bilingual peers. However, Mandarin-English and atonal-English bilingual children discriminated between level-pitch sine-wave tones with similar accuracy. Moreover, atonal-English bilingual children showed a tendency to perceive differing Mandarin lexical and level-pitch sine-wave tones as identical, whereas their Mandarin-English peers showed no such tendency. These results indicate that bilingualism in a tonal language in addition to an atonal language-but not bilingualism in two atonal languages-allows for continued sensitivity to lexical tone beyond infancy. Moreover, they suggest that although tonal-atonal bilingualism does not enhance sensitivity to differences in pitch between sine-wave tones beyond infancy any more effectively than atonal-atonal bilingualism, it protects against the development of biases to perceive differing lexical and non-lexical tones as identical. Together, the results indicate that, beyond infancy, tonal-atonal bilinguals process lexical tones using different cognitive mechanisms than atonal-atonal bilinguals, but that both groups process level-pitch non-lexical tone using the same cognitive mechanisms.
C1 [Morett, Laura M.] Univ Alabama, Box 870240, Tuscaloosa, AL 35401 USA.
RP Morett, LM (corresponding author), Univ Alabama, Box 870240, Tuscaloosa, AL 35401 USA.
EM lmorett@ua.edu
RI Morett, Laura/H-9616-2019
OI Morett, Laura/0000-0002-1251-7213
FU East Asia and Pacific Summer Institutes (EAPSI) Fellowship - US National
   Science Foundation; East Asia and Pacific Summer Institutes (EAPSI)
   Fellowship - National Research Foundation of Singapore; Singapore
   Children's Foundation; National Defense Science and Engineering Graduate
   (NDSEG) Fellowship - US Department of Defense, Air Force Office of
   Scientific Research [32 CFR 168a]; Perlino Award of the Department of
   Psychology at UCSC
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This
   research was supported by an East Asia and Pacific Summer Institutes
   (EAPSI) Fellowship to the author (co-funded by the US National Science
   Foundation and the National Research Foundation of Singapore) and a
   grant from the Singapore Children's Foundation to Tan Seok Hui. The
   preparation of this manuscript was additionally supported by a National
   Defense Science and Engineering Graduate (NDSEG) Fellowship (32 CFR
   168a) funded by the US Department of Defense, Air Force Office of
   Scientific Research), and by the Perlino Award of the Department of
   Psychology at UCSC, both to the author.
CR Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bent T, 2006, J EXP PSYCHOL HUMAN, V32, P97, DOI 10.1037/0096-1523.32.1.97
   Bidelman GM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0060676
   Bidelman GM, 2011, BRAIN COGNITION, V77, P1, DOI 10.1016/j.bandc.2011.07.006
   Bidelman GM, 2011, J COGNITIVE NEUROSCI, V23, P425, DOI 10.1162/jocn.2009.21362
   BLICHER DL, 1990, J PHONETICS, V18, P37, DOI 10.1016/S0095-4470(19)30357-2
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Burnham D., 1996, PAN ASIATIC LINGUIST, P47
   BURNS EM, 1980, J ACOUST SOC AM, V68, P1886, DOI 10.1121/1.385179
   Chandrasekaran B, 2007, BRAIN RES, V1128, P148, DOI 10.1016/j.brainres.2006.10.064
   Chandrasekaran B, 2009, BRAIN LANG, V108, P1, DOI 10.1016/j.bandl.2008.02.001
   Chao Y. R., 1965, GRAMMAR SPOKEN CHINE
   Chao Y. R., 1948, MANDARIN PRIMER, V26
   Chen A, 2016, INFANT CHILD DEV, V25, P426, DOI 10.1002/icd.1944
   Ciocca V., 2003, J MULTILINGUAL COMMU, V1, P141, DOI [10.1080/1476967031000090971, DOI 10.1080/1476967031000090971]
   Creel SC, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12503
   Delogu F, 2010, EUR J COGN PSYCHOL, V22, P46, DOI 10.1080/09541440802708136
   Delogu Franco, 2006, Cogn Process, V7, P203, DOI 10.1007/s10339-006-0146-7
   Deutsch D, 2006, J ACOUST SOC AM, V119, P719, DOI 10.1121/1.2151799
   Deutsch D, 2009, J ACOUST SOC AM, V125, P2398, DOI 10.1121/1.3081389
   Elman J. L., 1997, RETHINKING INNATENES
   Estes KG, 2015, CHILD DEV, V86, P1371, DOI 10.1111/cdev.12392
   Feng A.W., 2007, BILINGUAL ED CHINA P
   Francis AL, 2003, PERCEPT PSYCHOPHYS, V65, P1029, DOI 10.3758/BF03194832
   Fromkin V.A., 1978, TONE LINGUISTIC SURV
   Gandour J, 1998, NEUROREPORT, V9, P2115, DOI 10.1097/00001756-199806220-00038
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   GANDOUR J, 1984, J CHINESE LINGUIST, V12, P235
   Giuliano RJ, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00146
   Green D. M., 1966, SIGNAL DETECTION THE
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Harrison P, 2000, LINGUA, V110, P581, DOI 10.1016/S0024-3841(00)00003-6
   Hay JF, 2015, CHILD DEV, V86, P10, DOI 10.1111/cdev.12269
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hsieh L, 2001, BRAIN LANG, V76, P227, DOI 10.1006/brln.2000.2382
   Hutka S, 2015, NEUROPSYCHOLOGIA, V71, P52, DOI 10.1016/j.neuropsychologia.2015.03.019
   Jiang CM, 2010, NEUROPSYCHOLOGIA, V48, P2630, DOI 10.1016/j.neuropsychologia.2010.05.009
   Klein D, 2001, NEUROIMAGE, V13, P646, DOI 10.1006/nimg.2000.0738
   KLUENDER KR, 1987, SCIENCE, V237, P1195, DOI 10.1126/science.3629235
   KUHL PK, 1981, J ACOUST SOC AM, V70, P340, DOI 10.1121/1.386782
   Lee CY, 2008, J ACOUST SOC AM, V124, P3235, DOI 10.1121/1.2990713
   Lee CY, 2012, NEUROPSYCHOLOGIA, V50, P3228, DOI 10.1016/j.neuropsychologia.2012.08.025
   Lee KYS, 2002, LANG SPEECH, V45, P387
   Lee YS, 1996, J PSYCHOLINGUIST RES, V25, P527, DOI 10.1007/BF01758181
   LIBERMAN AM, 1989, SCIENCE, V243, P489, DOI 10.1126/science.2643163
   Liu F, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030374
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Liu SY, 2004, LANG SPEECH, V47, P109, DOI 10.1177/00238309040470020101
   Macmillan N, 2004, DETECTION THEORY USE
   Malins JG, 2012, NEUROPSYCHOLOGIA, V50, P2032, DOI 10.1016/j.neuropsychologia.2012.05.002
   Malins JG, 2010, J MEM LANG, V62, P407, DOI 10.1016/j.jml.2010.02.004
   MASSARO DW, 1985, J CHINESE LINGUIST, V13, P267
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Nan Y, 2010, BRAIN, V133, P2635, DOI 10.1093/brain/awq178
   Oh YM, 2013, INTERSPEECH, P3031
   Peng G, 2010, J PHONETICS, V38, P616, DOI 10.1016/j.wocn.2010.09.003
   Pfordresher PQ, 2009, ATTEN PERCEPT PSYCHO, V71, P1385, DOI 10.3758/APP.71.6.1385
   Quam C, 2010, J MEM LANG, V62, P135, DOI 10.1016/j.jml.2009.09.003
   R Core Team, 2015, R LANG ENV STAT COMP
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Singh L, 2018, CHILD DEV, V89, pe397, DOI 10.1111/cdev.12852
   Singh L, 2017, J CHILD LANG, V44, P924, DOI 10.1017/S0305000916000325
   Singh L, 2016, CHILD DEV, V87, P834, DOI 10.1111/cdev.12512
   Singh L, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00667
   Singh L, 2015, COGNITION, V142, P1, DOI 10.1016/j.cognition.2015.05.010
   Singh L, 2014, DEVELOPMENTAL SCI, V17, P94, DOI 10.1111/desc.12097
   Singh L, 2012, COGNITION, V124, P128, DOI 10.1016/j.cognition.2012.05.008
   STAGRAY JR, 1993, J CHINESE LINGUIST, V21, P143
   Surendran D., 2004, P SPEECH PROS 2004 N, P99
   TANNER WP, 1964, J ACOUST SOC AM, V36, P1465, DOI 10.1121/1.1919226
   Tervaniemi M, 1999, NEUROIMAGE, V9, P330, DOI 10.1006/nimg.1999.0405
   Tervaniemi M, 2000, HUM BRAIN MAPP, V10, P74, DOI 10.1002/(SICI)1097-0193(200006)10:2<74::AID-HBM30>3.3.CO;2-U
   Tillmann B, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00120
   TOMPKING CA, 1985, J SPEECH HEAR RES, V28, P527, DOI 10.1044/jshr.2804.527
   Tsao FM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00558
   Wang Y, 2003, J COGNITIVE NEUROSCI, V15, P1019, DOI 10.1162/089892903770007407
   Wang Y, 2001, BRAIN LANG, V78, P332, DOI 10.1006/brln.2001.2474
   Wang Y, 1999, J ACOUST SOC AM, V106, P3649, DOI 10.1121/1.428217
   Werker JF, 2008, TRENDS COGN SCI, V12, P144, DOI 10.1016/j.tics.2008.01.008
   Wewalaarachchi TD, 2017, J EXP CHILD PSYCHOL, V159, P16, DOI 10.1016/j.jecp.2017.01.009
   Wildgruber D, 2002, NEUROIMAGE, V15, P856, DOI 10.1006/nimg.2001.0998
   Wong PCM, 2007, HUM BRAIN MAPP, V28, P995, DOI 10.1002/hbm.20330
   Wong PCM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033424
   Wong PS, 2005, J SPEECH LANG HEAR R, V48, P1065, DOI 10.1044/1092-4388(2005/074)
   Wong PS, 2018, J SPEECH LANG HEAR R, V61, P1070, DOI 10.1044/2018_JSLHR-S-17-0288
   Xi J, 2010, NEUROSCIENCE, V170, P223, DOI 10.1016/j.neuroscience.2010.06.077
   Xu Y, 1999, J PHONETICS, V27, P55, DOI 10.1006/jpho.1999.0086
   Xu YS, 2006, J ACOUST SOC AM, V120, P1063, DOI 10.1121/1.2213572
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
NR 92
TC 1
Z9 1
U1 1
U2 5
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD JUN
PY 2020
VL 63
IS 2
BP 221
EP 241
DI 10.1177/0023830919834679
PG 21
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA LU4XP
UT WOS:000537760600002
PM 30859898
OA Bronze
DA 2021-02-24
ER

PT J
AU Morini, G
   Newman, RS
AF Morini, Giovanna
   Newman, Rochelle S.
TI Monolingual and Bilingual Word Recognition and Word Learning in
   Background Noise
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Bilingualism; word learning; word recognition; listening in noise
ID SPEECH-PERCEPTION; LEXICAL ACCESS; ACQUISITION; ADULTS; AGE; VOCABULARY;
   MASKING; LISTEN
AB The question of whether bilingualism leads to advantages or disadvantages in linguistic abilities has been debated for many years. It is unclear whether growing up with one versus two languages is related to variations in the ability to process speech in the presence of background noise. We present findings from a word recognition and a word learning task with monolingual and bilingual adults. Bilinguals appear to be less accurate than monolinguals at identifying familiar words in the presence of white noise. However, the bilingual "disadvantage" identified during word recognition is not present when listeners were asked to acquire novel word-object relations that were trained either in noise or in quiet. This work suggests that linguistic experience and the demands associated with the type of task both play a role in the ability for listeners to process speech in noise.
C1 [Morini, Giovanna] Univ Delaware, Commun Sci & Disorders Program, Newark, DE 19713 USA.
   [Newman, Rochelle S.] Univ Maryland, Dept Hearing & Speech Sci, College Pk, MD 20742 USA.
RP Morini, G (corresponding author), Univ Delaware, Commun Sci & Disorders Program, Newark, DE 19713 USA.
EM gmorini@udel.edu
FU National Science FoundationNational Science Foundation (NSF)
   [BCS-1322565];  [NIH T32 DC000046-17]; NATIONAL INSTITUTE ON DEAFNESS
   AND OTHER COMMUNICATION DISORDERSUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute on Deafness & Other Communication Disorders (NIDCD)
   [T32DC000046, T32DC000046, T32DC000046, T32DC000046, T32DC000046,
   T32DC000046, T32DC000046] Funding Source: NIH RePORTER
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported in part by a Dissertation Improvement Grant (#BCS-1322565)
   from the National Science Foundation, and by a University of Maryland
   Center for Comparative and Evolutionary Biology of Hearing Training
   Grant (NIH T32 DC000046-17).
CR Barcroft J., 2008, ESTUDIOS LINGUISTICA, V26, P53
   Barcroft J, 2010, APPL LINGUIST, V31, P623, DOI 10.1093/applin/amq017
   Beaman CP, 2005, APPL COGNITIVE PSYCH, V19, P1041, DOI 10.1002/acp.1134
   Bialystok E, 2008, J EXP PSYCHOL LEARN, V34, P859, DOI 10.1037/0278-7393.34.4.859
   Bialystok Ellen, 2009, Psychol Sci Public Interest, V10, P89, DOI 10.1177/1529100610387084
   Bradlow AR, 2002, J ACOUST SOC AM, V112, P272, DOI 10.1121/1.1487837
   CARHART R, 1969, J ACOUST SOC AM, V45, P694, DOI 10.1121/1.1911445
   COHEN J, 1993, BEHAV RES METH INSTR, V25, P257, DOI 10.3758/BF03204507
   Crowder R., 1976, PRINCIPLES LEARNING
   Ecke P, 2004, SW J LINGUISTICS, V23, P33
   Florentine M., 1985, P AC SOC JAP
   Florentine M, 1985, P INT 85, V85, P1021
   Florentine M, 1984, J ACOUST SOC AM, V75, pS84, DOI [10.1121/ 1.2021645, DOI 10.1121/1.2021645]
   Gaskell MG, 2003, COGNITION, V89, P105, DOI 10.1016/S0010-0277(03)00070-2
   Gollan TH, 2007, J INT NEUROPSYCH SOC, V13, P197, DOI 10.1017/S1355617707070038
   Gollan TH, 2005, MEM COGNITION, V33, P1220, DOI 10.3758/BF03193224
   Grondin R, 2009, J MEM LANG, V60, P1, DOI 10.1016/j.jml.2008.09.001
   Grosjean F., 1997, TUTORIALS BILINGUALI, P225
   Gupta P, 2003, Q J EXP PSYCHOL-A, V56, P1213, DOI 10.1080/02724980343000071
   Gupta P., 1995, THESIS
   Hilchey MD, 2011, PSYCHON B REV, V18, P625, DOI 10.3758/s13423-011-0116-7
   Hirsh IJ, 1952, J SPEECH HEAR DISORD, V17, P321, DOI 10.1044/jshd.1703.321
   Ingle S., 1986, SECOND LANG RES, V2, P160
   Ivanova I, 2008, ACTA PSYCHOL, V127, P277, DOI 10.1016/j.actpsy.2007.06.003
   Johnstone PM, 2006, J ACOUST SOC AM, V120, P2177, DOI 10.1121/1.2225416
   Kaushanskaya M, 2012, PSYCHON B REV, V19, P935, DOI 10.3758/s13423-012-0271-5
   Kaushanskaya M, 2012, BILING-LANG COGN, V15, P470, DOI 10.1017/S1366728911000472
   Kaushanskaya M, 2009, PSYCHON B REV, V16, P705, DOI 10.3758/PBR.16.4.705
   Krizman J, 2017, BILING-LANG COGN, V20, P834, DOI 10.1017/S1366728916000444
   Leach L, 2007, COGNITIVE PSYCHOL, V55, P306, DOI 10.1016/j.cogpsych.2007.01.001
   MacKay IRA, 2004, APPL PSYCHOLINGUIST, V25, P373, DOI 10.1017/S0142716404001171
   Marion V, 2007, J SPEECH LANG HEAR R, V50, P940, DOI 10.1044/1092-4388(2007/067)
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Mayo LH, 1997, J SPEECH LANG HEAR R, V40, P686, DOI 10.1044/jslhr.4003.686
   Meador D, 2000, BILING-LANG COGN, V3, P55, DOI DOI 10.1017/S1366728900000134
   PAPAGNO C, 1995, Q J EXP PSYCHOL-A, V48, P98, DOI 10.1080/14640749508401378
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   Postman L., 1976, RECALL RECOGNITION
   Roberts M., 2002, APHASIOLOGY, V16, P635, DOI DOI 10.1080/02687030244000220
   Rogers CL, 2006, APPL PSYCHOLINGUIST, V27, P465, DOI 10.1017/S014271640606036X
   Schmitt N, 1998, LANG LEARN, V48, P281, DOI 10.1111/1467-9922.00042
   Storkel HL, 2006, J SPEECH LANG HEAR R, V49, P1175, DOI 10.1044/1092-4388(2006/085)
   Tabri D, 2011, INT J LANG COMM DIS, V46, P411, DOI 10.3109/13682822.2010.519372
   Van Hell J. G., 1998, BILING-LANG COGN, V1, P193, DOI [10.1017/S1366728998000352, DOI 10.1017/S1366728998000352]
   WICKENS DD, 1963, J VERB LEARN VERB BE, V2, P440, DOI 10.1016/S0022-5371(63)80045-6
NR 45
TC 0
Z9 0
U1 0
U2 5
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD JUN
PY 2020
VL 63
IS 2
BP 381
EP 403
DI 10.1177/0023830919846158
PG 23
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA LU4XP
UT WOS:000537760600008
PM 31106697
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Viswanathan, N
   Olmstead, AJ
   Aivar, MP
AF Viswanathan, Navin
   Olmstead, Annie J.
   Aivar, M. Pilar
TI The Use of Vowel Length in Making Voicing Judgments by Native Listeners
   of English and Spanish: Implications for Rate Normalization
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Speech perception; speech rate; bilingual; Spanish; English
ID SPEAKING-RATE; ONSET TIME; CUE-INTEGRATION; CROSS-LANGUAGE; DURATION;
   SPEECH; COARTICULATION; PERCEPTION; CONTEXT; VARIABILITY
AB Among other characteristics, voiced and voiceless consonants differ in voice onset time (VOT; Lisker & Abramson, 1964). In addition, in English, voiced consonants are typically followed by longer vowels than their unvoiced counterparts (Allen & Miller, 1999). In Spanish, this relationship is less systematic (Zimmerman & Sapon, 1958). In two experiments, we investigated perceptual sensitivities of English and Spanish native speakers to following vowel length (VL) in categorizing syllables that ranged from a prevoiced bilabial stop [ba] to a long-lag bilabial stop [pa]. According to our results, English speakers show sensitivity to following vowels with VLs falling within an English-typical range (Experiment 1), but not when vowels are shorter and in a Spanish-typical range (Experiment 2). Interestingly, Spanish native speakers do not show sensitivity to following VL in either condition. These results suggest that VOT-VL tradeoffs in perception reflect phonological sensitivities of listeners and are not reducible to speech rate compensation.
C1 [Viswanathan, Navin; Olmstead, Annie J.] Penn State Univ, Dept Commun Sci & Disorders, University Pk, PA 16802 USA.
   [Viswanathan, Navin; Olmstead, Annie J.] Univ Kansas, Dept Speech Language Hearing, Lawrence, KS 66045 USA.
   [Viswanathan, Navin] Haskins Labs Inc, New Haven, CT USA.
   [Aivar, M. Pilar] Univ Autonoma Madrid, Fac Psicol, Madrid, Spain.
RP Viswanathan, N (corresponding author), Penn State Univ, Dept Commun Sci & Disorders, University Pk, PA 16802 USA.
EM navin@psu.edu
RI Aivar, M Pilar/B-2590-2009
OI Aivar, M Pilar/0000-0002-3049-1192
FU NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R15DC011875-01, BCS-1431105,
   FFI2009-13416-C02-02]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: Research
   was supported by NIDCD grant R15DC011875-01, and BCS-1431105 to NV, and
   FFI2009-13416-C02-02 to MPA. The collaboration between both teams was
   possible thanks to a UAM/Banco Santander Inter-University Cooperation
   Project. Correspondence concerning this article should be addressed to
   Navin Viswanathan, Communication Sciences & Disorders, The Pennsylvania
   State University, University Park, PA, 16802, USA. E-mail: navin@psu.edu
CR ABRAMSON AS, 1977, PHONETICA, V34, P295, DOI 10.1159/000259888
   Allen JS, 1999, J ACOUST SOC AM, V106, P2031, DOI 10.1121/1.427949
   Barton M. A., 1981, ETS RES REPORT SERIE, V1981, P1, DOI DOI 10.1002/J.2333-8504.1981.TB01255.X
   Birdsong D, 2006, APPL PSYCHOLINGUIST, V27, P46, DOI 10.1017/S0142716406220034
   Birdsong D, 2014, APPL LINGUIST, V35, P374, DOI 10.1093/applin/amu031
   Boucher VJ, 2002, PERCEPT PSYCHOPHYS, V64, P121, DOI 10.3758/BF03194561
   CHEN M, 1970, PHONETICA, V22, P129, DOI 10.1159/000259312
   de Jong K, 2004, J PHONETICS, V32, P493, DOI 10.1016/j.wocn.2004.05.002
   DEJONG K, 1991, PHONETICA, V48, P1, DOI 10.1159/000261868
   FLEGE JE, 1986, PHONETICA, V43, P155, DOI 10.1159/000261768
   FOWLER CA, 1980, J PHONETICS, V8, P113, DOI 10.1016/S0095-4470(19)31446-9
   Grabe E, 2002, PHONOL PHONET, V4-1, P515
   Hammond RM, 2001, SOUNDS SPANISH ANAL
   HOUSE AS, 1953, J ACOUST SOC AM, V25, P105, DOI 10.1121/1.1906982
   JASP Team, 2018, JASP VERS 0 9 COMP S
   Kessinger RH, 1997, J PHONETICS, V25, P143, DOI 10.1006/jpho.1996.0039
   Kessinger RH, 1998, J PHONETICS, V26, P117, DOI 10.1006/jpho.1997.0069
   KLATT DH, 1976, J ACOUST SOC AM, V59, P1208, DOI 10.1121/1.380986
   Lee M. D., 2014, BAYESIAN COGNITIVE M
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   LISKER L, 1957, LANGUAGE, V33, P42, DOI 10.2307/410949
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   LISKER L, 1975, J ACOUST SOC AM, V57, P1547, DOI 10.1121/1.380602
   Magloire J, 1999, PHONETICA, V56, P158, DOI 10.1159/000028449
   MANN VA, 1981, J ACOUST SOC AM, V69, P548, DOI 10.1121/1.385483
   McMurray B, 2008, PSYCHON B REV, V15, P1064, DOI 10.3758/PBR.15.6.1064
   Miller J. L., 1981, PERSPECTIVES STUDY S, P39
   MILLER JL, 1988, J EXP PSYCHOL HUMAN, V14, P369, DOI 10.1037/0096-1523.14.3.369
   MILLER JL, 1989, PERCEPT PSYCHOPHYS, V46, P505, DOI 10.3758/BF03208147
   Nakai S, 2016, LAB PHONOL, V7, DOI 10.5334/labphon.49
   Newman RS, 1996, PERCEPT PSYCHOPHYS, V58, P540, DOI 10.3758/BF03213089
   Olmstead A. J., 2013, 54 ANN M PSYCH SOC T
   Olmstead AJ, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00475
   Port R. F., 1977, HASKINS LAB STATUS R, V52, P59
   Raphael LJ, 2005, BLACKW HBK LINGUIST, P182, DOI 10.1002/9780470757024.ch8
   Remez RE, 2011, J ACOUST SOC AM, V130, P2173, DOI 10.1121/1.3631667
   Stoel-Gammon C., 1999, P 14 INT C PHON SCI
   Strange W, 2007, J ACOUST SOC AM, V122, P1111, DOI 10.1121/1.2749716
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   Toscano JC, 2015, LANG COGN NEUROSCI, V30, P529, DOI 10.1080/23273798.2014.946427
   Toscano JC, 2012, ATTEN PERCEPT PSYCHO, V74, P1284, DOI 10.3758/s13414-012-0306-z
   Utman JA, 1998, J ACOUST SOC AM, V103, P1640, DOI 10.1121/1.421297
   Viswanathan N, 2014, J EXP PSYCHOL HUMAN, V40, P1228, DOI 10.1037/a0036214
   Viswanathan N, 2010, J EXP PSYCHOL HUMAN, V36, P1005, DOI 10.1037/a0018391
   WAYLAND SC, 1994, J ACOUST SOC AM, V95, P2694, DOI 10.1121/1.409838
   ZIMMERMAN SA, 1958, J ACOUST SOC AM, V30, P152, DOI 10.1121/1.1909521
NR 46
TC 0
Z9 0
U1 0
U2 2
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD JUN
PY 2020
VL 63
IS 2
BP 436
EP 452
DI 10.1177/0023830919851529
PG 17
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA LU4XP
UT WOS:000537760600010
PM 31122129
OA Bronze
DA 2021-02-24
ER

PT J
AU Lee-Kim, SI
AF Lee-Kim, Sang-Im
TI Stop Laryngeal Distinctions Driven by Contrastive Effects of Neighboring
   Tones
SO LANGUAGE AND SPEECH
LA English
DT Article; Early Access
DE extrinsic context; contrastive effects; stop perception; tone; second
   language experience
ID PERCEPTUAL NORMALIZATION; LEXICAL TONE; KOREAN STOPS; SPEECH-PERCEPTION;
   PRECEDING LIQUID; COMPENSATION; CANTONESE; CONTEXT; COARTICULATION;
   LANGUAGE
AB This study examined contrastive effects of neighboring tones that give rise to a systematic asymmetry in stop perception. Korean-speaking learners of Mandarin Chinese and naive listeners labeled voiceless unaspirated stops preceded or followed by low or high extrinsic tonal context (e.g., ma(LO).pa vs. ma(HI).pa) either as lenis (associated with a low F0 at the vowel onset) or as fortis stops (with a high F0). Further, the target tone itself varied between level and rising (e.g., ma(LO).pa(LEV) vs. ma(LO).pa(RIS)). Both groups of listeners showed significant contrastive effects of extrinsic context. Specifically, more lenis responses were elicited in a high tone context than in a low one, and vice versa. This indicates that the onset F0 of a stop is perceived lower in a high tone context, which, in turn, provides positive evidence for lenis stops. This effect was more clearly pronounced for the level than for the contour tone target and also for the preceding than for the following context irrespective of linguistic experience. Despite qualitative similarities, learners showed larger effects for all F0 variables, indicating that the degree of context effects may be enhanced by one's phonetic knowledge, namely sensitivity to F0 cues along with the processing of consecutive tones acquired through learning a tone language.
C1 [Lee-Kim, Sang-Im] Natl Chiao Tung Univ, Hsinchu, Taiwan.
RP Lee-Kim, SI (corresponding author), Natl Chiao Tung Univ, Dept Foreign Languages & Literatures, Humanities 3, Hsinchu 300, Taiwan.
EM sangimleekim@nctu.edu.tw
OI LEE-KIM, SANG-IM/0000-0003-1631-3792
FU Ministry of Science and Technology, TaiwanMinistry of Science and
   Technology, Taiwan [MOST107-2410-H-009-016-MY3]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by a research grant MOST107-2410-H-009-016-MY3 from
   Ministry of Science and Technology, Taiwan.
CR Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Belotel-Grenie A., 1994, 3 INT C SPOK LANG PR
   Boersma P., 2018, PRAAT DOING PHONETIC
   Chao Yuen Ren, 1968, GRAMMAR SPOKEN CHINE
   Cho TH, 2002, J PHONETICS, V30, P193, DOI 10.1006/jpho.2001.0153
   Cho TH, 2001, J PHONETICS, V29, P155, DOI 10.1006/jpho.2001.0131
   Cumming R, 2011, J PHONETICS, V39, P375, DOI 10.1016/j.wocn.2011.01.004
   Cutler A, 1997, PERCEPT PSYCHOPHYS, V59, P165, DOI 10.3758/BF03211886
   Davis MJ, 2010, J DATA SCI, V8, P61, DOI DOI 10.6339/JDS.2010.08(1).563
   Fowler CA, 2006, PERCEPT PSYCHOPHYS, V68, P161, DOI 10.3758/BF03193666
   FOX RA, 1990, J CHINESE LINGUIST, V18, P261
   Francis AL, 2006, J ACOUST SOC AM, V119, P1712, DOI 10.1121/1.2149768
   Francis AL, 2008, J PHONETICS, V36, P268, DOI 10.1016/j.wocn.2007.06.005
   Gordon M, 2001, STUD LANG, V25, P423, DOI 10.1075/sl.25.3.03gor
   Guion S. G., 2007, LANGUAGE EXPERIENCE, P57, DOI [DOI 10.1075/LLLT.17.09GUI, 10.1075/lllt.17.09gui]
   Halle Morris, 1956, ROMAN JAKOBSON ESSAY, P52
   Han J.-I., 1996, THESIS
   Henry MJ, 2009, J EXP PSYCHOL HUMAN, V35, P551, DOI 10.1037/0096-1523.35.2.551
   Huang JY, 2009, J ACOUST SOC AM, V125, P3983, DOI 10.1121/1.3125342
   KAGAYA R, 1974, J PHON, V2, P161
   Kang KH, 2008, J ACOUST SOC AM, V124, P3909, DOI 10.1121/1.2988292
   Kang S, 2016, SPEECH COMMUN, V77, P84, DOI 10.1016/j.specom.2015.12.005
   Kang YJ, 2014, J PHONETICS, V45, P76, DOI 10.1016/j.wocn.2014.03.005
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Kim M., 2004, 8 INT C SPOK LANG PR
   Kingston J, 2014, ATTEN PERCEPT PSYCHO, V76, P1437, DOI 10.3758/s13414-013-0593-z
   Kingston J, 2011, LANG SPEECH, V54, P499, DOI 10.1177/0023830911404959
   Ko Mi-Sook, 2000, CWUNGKWUK ENE YENKWU, V12, P235
   Kuang JJ, 2017, J ACOUST SOC AM, V142, P1693, DOI 10.1121/1.5003649
   Lee H, 2013, J PHONETICS, V41, P117, DOI 10.1016/j.wocn.2012.12.002
   Lee H, 2012, J INT PHON ASSOC, V42, P145, DOI 10.1017/S0025100312000035
   Lee-Kim S.-I., 2020, LANGUAGE LINGUISTICS, V21, P84
   Lehiste I., 1976, J PHONETICS, V4, P113
   Lin T., 1984, ZHONGGUO YUYAN XUEBA, V2, P59
   Liu HM, 2000, CLIN LINGUIST PHONET, V14, P447
   Lotto AJ, 1998, PERCEPT PSYCHOPHYS, V60, P602, DOI 10.3758/BF03206049
   Luo X, 2014, J ACOUST SOC AM, V136, pEL109, DOI 10.1121/1.4885483
   Maeng Joooeck, 2008, CWUNGKWUKHAK YENKWU, V44, P73
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P407, DOI 10.3758/BF03204884
   MANN VA, 1986, COGNITION, V24, P169, DOI 10.1016/S0010-0277(86)80001-4
   Mitterer H, 2006, PERCEPT PSYCHOPHYS, V68, P1227, DOI 10.3758/BF03193723
   Moore CB, 1997, J ACOUST SOC AM, V102, P1864, DOI 10.1121/1.420092
   Peng G, 2012, J SPEECH LANG HEAR R, V55, P579, DOI 10.1044/1092-4388(2011/11-0025)
   Qin Z, 2016, LANG SPEECH, V59, P318, DOI 10.1177/0023830915590191
   R Development Core Team, 2016, R LANG ENV STAT COMP
   Rochet B. L., 1991, Canadian Acoustics, V19, P105
   Rysling A., 2017, THESIS
   Rysling A, 2019, ATTEN PERCEPT PSYCHO, V81, P1127, DOI 10.3758/s13414-019-01720-9
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   Silva D. J., 2006, PHONOLOGY, V23, P287, DOI DOI 10.1017/S0952675706000911
   Silva D. J., 1992, THESIS
   Sjerps MJ, 2018, J EXP PSYCHOL HUMAN, V44, P914, DOI 10.1037/xhp0000504
   Sjerps MJ, 2013, J PHONETICS, V41, P145, DOI 10.1016/j.wocn.2013.01.005
   Smits R, 2001, J EXP PSYCHOL HUMAN, V27, P1145, DOI 10.1037/0096-1523.27.5.1145
   Viswanathan N, 2010, J EXP PSYCHOL HUMAN, V36, P1005, DOI 10.1037/a0018391
   WHALEN DH, 1989, PERCEPT PSYCHOPHYS, V46, P284, DOI 10.3758/BF03208093
   Wong PCM, 2003, J SPEECH LANG HEAR R, V46, P413, DOI 10.1044/1092-4388(2003/034)
   Ye Y, 1999, LANG COGNITIVE PROC, V14, P609, DOI 10.1080/016909699386202
   Yu Alan C. L., 2010, LAB PHONOLOGY, V10, P151, DOI DOI 10.1515/9783110224917.2.151
   Zhang CC, 2016, J EXP PSYCHOL HUMAN, V42, P1252, DOI 10.1037/xhp0000216
   Zhang CC, 2012, J ACOUST SOC AM, V132, P1088, DOI 10.1121/1.4731470
   Zhang H., 2018, HAN INT S PHON COGN
   Zhang J., 2001, THESIS
   Zhang J, 2010, PHONOLOGY, V27, P153, DOI 10.1017/S0952675710000060
   Zhang KL, 2017, J ACOUST SOC AM, V141, P38, DOI 10.1121/1.4973414
NR 65
TC 0
Z9 0
U1 2
U2 2
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
AR 0023830920922897
DI 10.1177/0023830920922897
EA JUN 2020
PG 25
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA LT6FQ
UT WOS:000537165000001
PM 32476568
DA 2021-02-24
ER

PT J
AU Ma, FY
   Ai, HY
   Xiao, T
   Guo, TM
   Pae, HK
AF Ma, Fengyang
   Ai, Haiyang
   Xiao, Ting
   Guo, Taomei
   Pae, Hye K.
TI Speech perception in a second language: Hearing is believing-seeing is
   not
SO QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY
LA English
DT Article
DE Second language; semantic judgement; face; accent; speech perception
ID LANGUAGE ACTIVATION; ENGLISH BILINGUALS; FOREIGN ACCENT; TRANSLATION;
   IDENTITY; LEXICON; FACES; TIME
AB This study examined the effects of the speaker's face and accent on second language (L2) speech perception. Forty-two Chinese speakers of English immersed in the L2 environment were instructed to perform a cross-modal semantic judgement task. They saw an Asian or Caucasian face on the screen and heard word pairs in L2 in a native English accent or a Chinese accent, and were asked to judge whether the word pairs were related to each other in meaning or not. Results showed that for words presented in the native accent, there was a semantic effect in both reaction time and accuracy, irrespective of the face shown. For words presented in the non-native accent, the RT data showed a semantic effect, whereas the accuracy revealed a reversed semantic effect. The speed-accuracy trade-off suggests a relatively weak semantic effect. These patterns were not modulated by the faces accompanying the word pairs. These results suggest that the cue of accent plays an important role during bilinguals' speech perception in L2, such that non-native accent hampers speech perception, even when it matches bilinguals' first language. In contrast, bilinguals do not seem to depend on the social indexical cue of the face when it is not reliable. The present findings hold implications for the Bilingual Model of Lexical Access (BIMOLA) of bilingual speech perception and the monolingual models of social speech perception.
C1 [Ma, Fengyang; Ai, Haiyang; Xiao, Ting; Pae, Hye K.] Univ Cincinnati, Sch Educ, 610N Teachers Coll,2610 McMicken Circle, Cincinnati, OH 45221 USA.
   [Guo, Taomei] Beijing Normal Univ, State Key Lab Cognit Neurosci & Learning, Beijing 100875, Peoples R China.
   [Guo, Taomei] Beijing Normal Univ, IDG McGovern Inst Brain Res, Beijing 100875, Peoples R China.
   [Guo, Taomei] Beijing Normal Univ, Ctr Collaborat & Innovat Brain & Learning Sci, Beijing, Peoples R China.
RP Ma, FY (corresponding author), Univ Cincinnati, Sch Educ, 610N Teachers Coll,2610 McMicken Circle, Cincinnati, OH 45221 USA.; Guo, TM (corresponding author), Beijing Normal Univ, State Key Lab Cognit Neurosci & Learning, Beijing 100875, Peoples R China.; Guo, TM (corresponding author), Beijing Normal Univ, IDG McGovern Inst Brain Res, Beijing 100875, Peoples R China.
EM guotm@bnu.edu.cn; fengyang.ma@uc.edu
FU College of Education, Criminal Justice, and Human Services, University
   of Cincinnati; Faculty Development Research Grant from the University
   Research Council, University of Cincinnati; National Natural Science
   Foundation of ChinaNational Natural Science Foundation of China (NSFC)
   [31871097]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: The study
   was supported by the Faculty Incentive Award from College of Education,
   Criminal Justice, and Human Services, University of Cincinnati and the
   Faculty Development Research Grant from the University Research Council,
   University of Cincinnati awarded to Fengyang Ma, and the National
   Natural Science Foundation of China (31871097) to Taomei Guo.
CR Balota DA, 2007, BEHAV RES METHODS, V39, P445, DOI 10.3758/BF03193014
   Barker BA, 2015, APPL PSYCHOLINGUIST, V36, P1111, DOI 10.1017/S0142716414000058
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Benjamin Munson, 2010, LAB PHONOLOGY, V1, P157, DOI DOI 10.1515/LABPHON.2010.008
   Bent T, 2003, J ACOUST SOC AM, V114, P1600, DOI 10.1121/1.1603234
   Bent T, 2014, J CHILD LANG, V41, P1334, DOI 10.1017/S0305000913000457
   Colome A, 2001, J MEM LANG, V45, P721
   Creel SC, 2016, J EXP CHILD PSYCHOL, V146, P156, DOI 10.1016/j.jecp.2016.01.018
   Declerck M, 2018, PSYCHON B REV, V25, P704, DOI 10.3758/s13423-017-1374-9
   Faust M, 2003, COGNITIVE BRAIN RES, V17, P585, DOI 10.1016/S0926-6410(03)00172-1
   Fu GY, 2015, VISION RES, V113, P104, DOI 10.1016/j.visres.2015.05.011
   Grainger J, 2017, ACTA PSYCHOL, V178, P12, DOI 10.1016/j.actpsy.2017.05.004
   Grosjean F., 1997, TUTORIALS BILINGUALI, P225
   Grosjean F. M. J., 1988, LANG COGNITIVE PROC, V3, P233, DOI DOI 10.1080/01690968808402089
   Guion SG, 2000, APPL PSYCHOLINGUIST, V21, P205, DOI 10.1017/S0142716400002034
   Guo TM, 2006, NEUROREPORT, V17, P1757, DOI 10.1097/01.wnr.0000246327.89308.a5
   Guo TM, 2012, J EXP PSYCHOL LEARN, V38, P1165, DOI 10.1037/a0028076
   Hartsuiker R. J., 2015, ATTENTION VISION LAN, P129
   Hartsuiker R. J., 2009, AMLAP 2009 C BARC SP
   Hoshino N, 2008, COGNITION, V106, P501, DOI 10.1016/j.cognition.2007.02.001
   Imai S., 2003, 15 ICPHS BARCELONA, P845
   Jared D, 2013, BILING-LANG COGN, V16, P383, DOI 10.1017/S1366728912000685
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Johnson K, 2006, J PHONETICS, V34, P485, DOI 10.1016/j.wocn.2005.08.004
   Kang O, 2009, J LANG SOC PSYCHOL, V28, P441, DOI 10.1177/0261927X09341950
   Kojima T, 2003, AURIS NASUS LARYNX, V30, P369, DOI 10.1016/j.anl.2003.07.007
   Kuera H., 1967, COMPUTATIONAL ANAL P
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Li YQ, 2013, BRAIN LANG, V127, P452, DOI 10.1016/j.bandl.2013.09.005
   Lippi-Green R., 1997, ENGLISH ACCENT LANGU, V2nd ed.
   Ma F, 2017, J NEUROLINGUIST, V41, P50, DOI 10.1016/j.jneuroling.2016.09.006
   Major RC, 2002, TESOL QUART, V36, P173, DOI 10.2307/3588329
   Martin CD, 2016, SCI REP-UK, V6, DOI 10.1038/srep26171
   McGowan KB, 2015, LANG SPEECH, V58, P502, DOI 10.1177/0023830914565191
   Molnar M, 2015, J MEM LANG, V81, P91, DOI 10.1016/j.jml.2015.01.002
   Munro MJ, 1995, LANG SPEECH, V38, P289, DOI 10.1177/002383099503800305
   Nelson DL, 2004, BEHAV RES METH INS C, V36, P402, DOI 10.3758/BF03195588
   Peng ZE, 2016, J ACOUST SOC AM, V139, P2772, DOI 10.1121/1.4948564
   Roychoudhuri KS, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fps7g.2016.01516
   RUBIN DL, 1992, RES HIGH EDUC, V33, P511, DOI 10.1007/BF00973770
   Sumner M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01015
   Thierry G, 2007, P NATL ACAD SCI USA, V104, P12530, DOI 10.1073/pnas.0609927104
   Trude AM, 2013, J MEM LANG, V69, P349, DOI 10.1016/j.jml.2013.05.002
   Woumans E, 2015, PSYCHOL SCI, V26, P1343, DOI 10.1177/0956797615589330
   Wu YJ, 2010, J NEUROSCI, V30, P7646, DOI 10.1523/JNEUROSCI.1602-10.2010
   Zhang S, 2013, P NATL ACAD SCI USA, V110, P11272, DOI 10.1073/pnas.1304435110
NR 47
TC 0
Z9 0
U1 3
U2 3
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1747-0218
EI 1747-0226
J9 Q J EXP PSYCHOL
JI Q. J. Exp. Psychol.
PD JUN
PY 2020
VL 73
IS 6
BP 881
EP 890
DI 10.1177/1747021820911362
PG 10
WC Psychology, Biological; Physiology; Psychology; Psychology, Experimental
SC Psychology; Physiology
GA LT5CX
UT WOS:000537089800005
PM 32075498
DA 2021-02-24
ER

PT J
AU Weible, AP
   Yavorska, I
   Wehr, M
AF Weible, Aldis P.
   Yavorska, Iryna
   Wehr, Michael
TI A Cortico-Collicular Amplification Mechanism for Gap Detection
SO CEREBRAL CORTEX
LA English
DT Article
DE auditory cortex; inferior colliculus; neural computation; speech
   perception; temporal processing
ID PRIMARY AUDITORY-CORTEX; INFERIOR COLLICULUS; ACOUSTIC STARTLE; TEMPORAL
   ACUITY; DETECTION THRESHOLDS; SOUND DURATION; PREPULSE INHIBITION;
   REFLEX INHIBITION; ACROSS-FREQUENCY; ONSET RESPONSES
AB Auditory cortex (AC) is necessary for the detection of brief gaps in ongoing sounds, but not for the detection of longer gaps or other stimuli such as tones or noise. It remains unclear why this is so, and what is special about brief gaps in particular. Here, we used both optogenetic suppression and conventional lesions to show that the cortical dependence of brief gap detection hinges specifically on gap termination. We then identified a cortico-collicular gap detection circuit that amplifies cortical gap termination responses before projecting to inferior colliculus (IC) to impact behavior. We found that gaps evoked off-responses and on-responses in cortical neurons, which temporally overlapped for brief gaps, but not long gaps. This overlap specifically enhanced cortical responses to brief gaps, whereas IC neurons preferred longer gaps. Optogenetic suppression of AC reduced collicular responses specifically to brief gaps, indicating that under normal conditions, the enhanced cortical representation of brief gaps amplifies collicular gap responses. Together these mechanisms explain how and why AC contributes to the behavioral detection of brief gaps, which are critical cues for speech perception, perceptual grouping, and auditory scene analysis.
C1 [Weible, Aldis P.; Yavorska, Iryna; Wehr, Michael] 1254 Univ Oregon, Inst Neurosci, Dept Psychol, Eugene, OR 97403 USA.
RP Wehr, M (corresponding author), 1254 Univ Oregon, Inst Neurosci, Dept Psychol, Eugene, OR 97403 USA.
EM wehr@uoregon.edu
FU National Institutes of Health National Institute on Deafness and Other
   Communication DisordersUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01 DC-015828]
FX National Institutes of Health National Institute on Deafness and Other
   Communication Disorders (R01 DC-015828).
CR Allen PD, 2008, HEARING RES, V246, P52, DOI 10.1016/j.heares.2008.09.009
   Anderson LA, 2016, J NEUROSCI, V36, P1977, DOI 10.1523/JNEUROSCI.1652-15.2016
   Bajo VM, 2013, FRONT NEURAL CIRCUIT, V6, DOI 10.3389/fncir.2012.00114
   Bajo VM, 2010, FRONT NEUROANAT, V4, DOI 10.3389/fnana.2010.00018
   Bajo VM, 2010, NAT NEUROSCI, V13, P253, DOI 10.1038/nn.2466
   Barsz K, 1998, HEARING RES, V115, P13, DOI 10.1016/S0378-5955(97)00173-1
   Bhatara A, 2013, J AUTISM DEV DISORD, V43, P2312, DOI 10.1007/s10803-013-1778-y
   Bowen GP, 2003, CEREB CORTEX, V13, P815, DOI 10.1093/cercor/13.8.815
   BRUGGE JF, 1973, J NEUROPHYSIOL, V36, P1138
   Buss S, 1985, TIME RESOLUTION AUDI
   BUUNEN TJF, 1979, J ACOUST SOC AM, V65, P534, DOI 10.1121/1.382312
   CASSEDAY JH, 1994, SCIENCE, V264, P847, DOI 10.1126/science.8171341
   Christianson GB, 2011, J NEUROSCI, V31, P12837, DOI 10.1523/JNEUROSCI.2863-11.2011
   DAVIS M, 1977, J COMP PHYSIOL PSYCH, V91, P549, DOI 10.1037/h0077345
   EGGERMONT JJ, 1995, J ACOUST SOC AM, V98, P911, DOI 10.1121/1.413517
   Eggermont JJ, 1999, J NEUROPHYSIOL, V81, P2570
   Eggermont JJ, 2000, J NEUROPHYSIOL, V84, P1453
   EGGERMONT JJ, 1995, NEUROREPORT, V6, P1645, DOI 10.1097/00001756-199508000-00014
   Ehrlich D, 1997, J NEUROPHYSIOL, V77, P2360
   Finlayson PG, 2002, JARO-J ASSOC RES OTO, V3, P321, DOI 10.1007/s101620020038
   Finlayson PG, 1999, HEARING RES, V131, P177, DOI 10.1016/S0378-5955(99)00032-5
   Fishman YI, 2009, HEARING RES, V254, P64, DOI 10.1016/j.heares.2009.04.010
   Formby C, 1998, J ACOUST SOC AM, V103, P3554, DOI 10.1121/1.423084
   FORREST TG, 1987, J ACOUST SOC AM, V82, P1933, DOI 10.1121/1.395689
   Fuzessery ZM, 1999, HEARING RES, V137, P137, DOI 10.1016/S0378-5955(99)00133-1
   GORDONSALANT S, 1993, J SPEECH HEAR RES, V36, P1276, DOI 10.1044/jshr.3606.1276
   Green D. M., 1966, SIGNAL DETECTION THE
   He JF, 1997, J NEUROSCI, V17, P2615
   He JF, 2001, J NEUROSCI, V21, P8672
   Iliadou V, 2017, J AM ACAD AUDIOL, V28, P463, DOI 10.3766/jaaa.16075
   Ison JR, 2007, JARO-J ASSOC RES OTO, V8, P539, DOI 10.1007/s10162-007-0098-3
   ISON JR, 1982, J COMP PHYSIOL PSYCH, V96, P945, DOI 10.1037/0735-7036.96.6.945
   ISON JR, 1991, BEHAV NEUROSCI, V105, P33, DOI 10.1037/0735-7044.105.1.33
   ISON JR, 1983, PERCEPT PSYCHOPHYS, V34, P84, DOI 10.3758/BF03205900
   Kelly JB, 1996, BEHAV NEUROSCI, V110, P542, DOI 10.1037/0735-7044.110.3.542
   Kirby AE, 2012, JARO-J ASSOC RES OTO, V13, P67, DOI 10.1007/s10162-011-0293-0
   Koch M, 1999, PROG NEUROBIOL, V59, P107, DOI 10.1016/S0301-0082(98)00098-7
   Kopp-Scheinpflug C, 2018, TRENDS NEUROSCI, V41, P712, DOI 10.1016/j.tins.2018.08.009
   Kopp-Scheinpflug C, 2011, NEURON, V71, P911, DOI 10.1016/j.neuron.2011.06.028
   Kuwada S, 1999, J NEUROSCI, V19, P2273
   Lauer AM, 2017, NEUROSCI BIOBEHAV R, V77, P194, DOI 10.1016/j.neubiorev.2017.03.009
   LEITNER DS, 1985, PHYSIOL BEHAV, V34, P65, DOI 10.1016/0031-9384(85)90079-4
   Li L, 1998, PHYSIOL BEHAV, V65, P133, DOI 10.1016/S0031-9384(98)00143-7
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Liu YC, 2010, BEHAV BRAIN RES, V215, P28, DOI 10.1016/j.bbr.2010.06.013
   Masini CV, 2012, BRAIN RES, V1443, P18, DOI 10.1016/j.brainres.2012.01.002
   MATHEWS MV, 1965, J ACOUST SOC AM, V38, P1055, DOI 10.1121/1.1909839
   McArthur G M, 2001, Dyslexia, V7, P150
   Nakamoto KT, 2008, J NEUROPHYSIOL, V99, P2347, DOI 10.1152/jn.01326.2007
   Oxenham AJ, 1997, J ACOUST SOC AM, V102, P1779, DOI 10.1121/1.420086
   PARHAM K, 1990, BEHAV NEUROSCI, V104, P831, DOI 10.1037/0735-7044.104.6.831
   Paxinos G., 2001, MOUSE BRAIN STEREOTA
   Phillips DP, 2010, J AM ACAD AUDIOL, V21, P404, DOI 10.3766/jaaa.21.6.5
   Phillips DP, 1997, J ACOUST SOC AM, V101, P3694, DOI 10.1121/1.419376
   Phillips DP, 2004, PERCEPTION, V33, P371, DOI 10.1068/p5116
   Phillips DP, 2002, HEARING RES, V167, P192, DOI 10.1016/S0378-5955(02)00393-3
   PLOMP R, 1964, J ACOUST SOC AM, V36, P277, DOI 10.1121/1.1918946
   Qin L, 2007, J NEUROPHYSIOL, V97, P3421, DOI 10.1152/jn.00184.2007
   Radziwon KE, 2009, J COMP PHYSIOL A, V195, P961, DOI 10.1007/s00359-009-0472-1
   Recanzone GH, 2000, HEARING RES, V150, P104, DOI 10.1016/S0378-5955(00)00194-5
   Recanzone GH, 2011, HEARING RES, V271, P115, DOI 10.1016/j.heares.2010.03.084
   Schofield BR, 2010, NEUROSCIENCE, V166, P231, DOI 10.1016/j.neuroscience.2009.12.008
   Schofield BR, 2009, BRAIN RES BULL, V80, P163, DOI 10.1016/j.brainresbull.2009.06.015
   Scholl B, 2010, NEURON, V65, P412, DOI 10.1016/j.neuron.2010.01.020
   Snell KB, 2000, J ACOUST SOC AM, V107, P1615, DOI 10.1121/1.428446
   Snell KB, 1997, J ACOUST SOC AM, V101, P2214, DOI 10.1121/1.418205
   Strouse A, 1998, J ACOUST SOC AM, V104, P2385, DOI 10.1121/1.423748
   Suga N, 2012, NEUROSCI BIOBEHAV R, V36, P969, DOI 10.1016/j.neubiorev.2011.11.006
   Swetter BJ, 2010, BEHAV NEUROSCI, V124, P370, DOI 10.1037/a0019519
   Threlkeld SW, 2008, NEUROREPORT, V19, P893, DOI 10.1097/WNR.0b013e3283013d7e
   Walton JP, 2008, JARO-J ASSOC RES OTO, V9, P90, DOI 10.1007/s10162-007-0101-z
   Walton JP, 1997, J COMP PHYSIOL A, V181, P161, DOI 10.1007/s003590050103
   Weibe AP, 2014, J NEUROSCI, V34, P15437, DOI 10.1523/JNEUROSCI.3408-14.2014
   Weible AP, 2014, CURR BIOL, V24, P1447, DOI 10.1016/j.cub.2014.05.031
   Winer J. A., 2005, INFERIOR COLLICULUS
   Winer JA, 1998, J COMP NEUROL, V400, P147
   Yu H, 2016, FRONT BEHAV NEUROSCI, V10, DOI 10.3389/fnbeh.2016.00158
NR 77
TC 3
Z9 3
U1 0
U2 0
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 1047-3211
EI 1460-2199
J9 CEREB CORTEX
JI Cereb. Cortex
PD JUN
PY 2020
VL 30
IS 6
BP 3590
EP 3607
DI 10.1093/cercor/bhz328
PG 18
WC Neurosciences
SC Neurosciences & Neurology
GA LR7XY
UT WOS:000535911100010
PM 32055848
DA 2021-02-24
ER

PT J
AU Nyberg, J
   Hagberg, E
   Havstam, C
AF Nyberg, Jill
   Hagberg, Emilie
   Havstam, Christina
TI "She Sounds Like a Small Child or Perhaps She has Problems"-Peers'
   Descriptions of Speech in 7-Year-Olds Born With Cleft Palate
SO CLEFT PALATE-CRANIOFACIAL JOURNAL
LA English
DT Article
DE speech perception; nasality; articulation; psychosocial adjustment
ID FACIAL APPEARANCE; LIP; PERCEPTIONS; TEACHERS; ADULTS; DISORDERS;
   PARENTS
AB Objective:
   The aim of this study was to explore how 7-year-olds describe speech in children born with cleft palate in their own words and to investigate whether they perceive signs of velopharyngeal incompetence (VPI) and articulation errors, and if so, which terminology they use.
   Methods/Participants:
   Twenty 7-year-olds participated in 6 focus group interviews where they listened to 8 speech samples with different types of cleft speech characteristics and described what they heard. The same speech samples had been assessed by speech-language pathologists and comprised normal speech, different degrees of VPI, oral articulation disorders, and glottal articulation. The interviews were analyzed with qualitative content analysis.
   Results:
   The analysis resulted in 4 interlinked categories: descriptions of speech, thoughts on personal traits, consequences for communication, and emotional reactions and associations. Each category contains 4 to 5 subcategories with the children's descriptions and reflections. Glottal articulation and severe signs of VPI caused the most negative emotional reactions and were described as sounding scary and incomprehensible and the children speculated on the risk of social rejection of the speakers. Retracted oral articulation was also noted and described but with a vocabulary similar to the professionals. Minor signs of VPI were not noted.
   Conclusions:
   Seven-year-olds are direct and straightforward in their reactions to cleft palate speech characteristics. More pronounced signs of VPI and articulatory difficulties, also minor ones, are noted. Clinically, articulatory impairments may be more important to treat than minor signs of VPI.
C1 [Nyberg, Jill; Hagberg, Emilie] Karolinska Inst, Dept Clin Intervent & Technol, Div Speech & Language Pathol, Stockholm, Sweden.
   [Hagberg, Emilie] Karolinska Univ Hosp, Patient Area Craniofacial Disorders & Funct Area, Stockholm Craniofacial Team, Stockholm, Sweden.
   [Havstam, Christina] Sahlgrens Univ Hosp, Div Speech Language Pathol, Gothenburg, Sweden.
   [Havstam, Christina] Univ Gothenburg, Inst Neurosci & Physiol, Speech Language Pathol Unit, Sahlgrenska Acad, Gothenburg, Sweden.
RP Nyberg, J (corresponding author), Karolinska Inst, Karolinska Univ Hosp, Dept Clin Sci Intervent & Technol, Div Speech & Language Pathol,CLINTEC, F67, S-14186 Stockholm, Sweden.
EM jill.nyberg@ki.se
OI Havstam, Christina/0000-0003-0015-9364
FU Karolinska InstitutetKarolinska Institutet; Stiftelsen Majblomman;
   Magnus Bergwalls Stiftelse
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: Financial
   support was received from the Karolinska Institutet, Stiftelsen
   Majblomman, and Magnus Bergwalls Stiftelse for the research, authorship,
   and/or publication of this article.
CR Allard ER, 2008, J COMMUN DISORD, V41, P108, DOI 10.1016/j.jcomdis.2007.05.002
   Brunnegard K, 2009, INT J LANG COMM DIS, V44, P656, DOI 10.1080/13682820802295203
   Dagenais PA, 2006, CLIN LINGUIST PHONET, V20, P141, DOI 10.1080/02699200400026843
   Elo S, 2008, J ADV NURS, V62, P107, DOI 10.1111/j.1365-2648.2007.04569.x
   Feragen KB, 2017, CLEFT PALATE-CRAN J, V54, P153, DOI 10.1597/14-242
   Feragen KB, 2009, CLEFT PALATE-CRAN J, V46, P65, DOI 10.1597/07-124.1
   Franck AL, 2003, J FLUENCY DISORD, V28, P1, DOI 10.1016/S0094-730X(03)00002-0
   Frederickson MS, 2006, CLEFT PALATE-CRAN J, V43, P179, DOI 10.1597/04-086.1
   Havneskold L, 2002, UTVECKLINGSPSYKOLOGI, P377
   Havstam C, 2011, CLEFT PALATE-CRAN J, V48, P717, DOI 10.1597/10-033
   Heary CM, 2002, J PEDIATR PSYCHOL, V27, P47, DOI 10.1093/jpepsy/27.1.47
   Hsieh HF, 2005, QUAL HEALTH RES, V15, P1277, DOI 10.1177/1049732305276687
   Hunt O, 2006, CLEFT PALATE-CRAN J, V43, P598, DOI 10.1597/05-080
   Hwang P, 2011, UTVECKLINGSPSYKOLOGI
   Krippendorff K., 2013, CONTENT ANAL INTRO I
   Krueger R, 2009, FOCUS GROUPS PRATICA
   Kuehn D., 2000, CLEFT PALATE-CRAN J, V37, P1, DOI DOI 10.1597/1545-1569_2000_037_0348_saliit_2.3.co_2
   Kvale S, 2010, KVALITATIVA FORSKNIN
   Lagerheim B, 1988, ATT UTVECKLAS MED HA
   LASS NJ, 1991, FOLIA PHONIATR, V43, P29, DOI 10.1159/000266098
   Lee A, 2017, CLEFT PALATE-CRAN J, V54, P262, DOI 10.1597/15-088
   Lohmander A, 2015, SVANTE SVENSKT ARTIK
   Marcusson A, 2002, SCAND J PLAST RECONS, V36, P16, DOI 10.1080/028443102753478327
   Millard T, 2001, CLEFT PALATE-CRAN J, V38, P68, DOI 10.1597/1545-1569(2001)038<0068:DCCFAA>2.0.CO;2
   Nelson PA, 2009, CLEFT PALATE-CRAN J, V46, P245, DOI 10.1597/08-121.1
   Nyberg J, 2016, CLEFT PALATE-CRAN J, V53, P516, DOI 10.1597/15-140
   Overby M, 2007, LANG SPEECH HEAR SER, V38, P327, DOI 10.1044/0161-1461(2007/035)
   Patton MQ, 2002, QUALITATIVE RES EVAL, V3rd
   Peterson-Sweeney Kathleen, 2005, J Pediatr Health Care, V19, P104, DOI 10.1016/j.pedhc.2004.08.006
   Pope A, 2016, CLEFT PALATE-CRAN J, V53, P325
   RICHMAN LC, 1978, CLEFT PALATE J, V15, P360
   Semb G, 2005, CLEFT PALATE-CRAN J, V42, P83, DOI 10.1597/02-119.4.1
   Sharif MO, 2013, CLEFT PALATE-CRAN J, V50, P297, DOI 10.1597/12-054
   Shute R., 2010, CLIN CHILD PSYCHOL P, V16, P317
   SIRIS, 2018, SKOLV INT RES OCH KV
   Stock NM, 2019, CLEFT PALATE-CRAN J, V56, P204, DOI 10.1177/1055665618770191
   Witt PD, 1997, PLAST RECONSTR SURG, V100, P1655, DOI 10.1097/00006534-199712000-00003
NR 37
TC 0
Z9 0
U1 0
U2 0
PU ALLIANCE COMMUNICATIONS GROUP DIVISION ALLEN PRESS
PI LAWRENCE
PA 810 EAST 10TH STREET, LAWRENCE, KS 66044 USA
SN 1055-6656
EI 1545-1569
J9 CLEFT PALATE-CRAN J
JI Cleft Palate-Craniofac. J.
PD JUN
PY 2020
VL 57
IS 6
BP 707
EP 714
DI 10.1177/1055665619890785
PG 8
WC Dentistry, Oral Surgery & Medicine; Surgery
SC Dentistry, Oral Surgery & Medicine; Surgery
GA LR8IC
UT WOS:000535938900006
PM 31818136
DA 2021-02-24
ER

PT J
AU Kennedy-Higgins, D
   Devlin, JT
   Nuttall, HE
   Adank, P
AF Kennedy-Higgins, Dan
   Devlin, Joseph T.
   Nuttall, Helen E.
   Adank, Patti
TI The Causal Role of Left and Right Superior Temporal Gyri in Speech
   Perception in Noise: A Transcranial Magnetic Stimulation Study
SO JOURNAL OF COGNITIVE NEUROSCIENCE
LA English
DT Article
ID INTELLIGIBLE SPEECH; FUNCTIONAL NEUROANATOMY; RECEPTION THRESHOLD;
   PREMOTOR CORTEX; COMPREHENSION; FMRI; TMS; CONSEQUENCES; ORGANIZATION;
   MULTIVARIATE
AB Successful perception of speech in everyday listening conditions requires effective listening strategies to overcome common acoustic distortions, such as background noise. Convergent evidence from neuroimaging and clinical studies identify activation within the temporal lobes as key to successful speech perception. However, current neurobiological models disagree on whether the left temporal lobe is sufficient for successful speech perception or whether bilateral processing is required. We addressed this issue using TMS to selectively disrupt processing in either the left or right superior temporal gyrus (STG) of healthy participants to test whether the left temporal lobe is sufficient or whether both left and right STG are essential. Participants repeated keywords from sentences presented in background noise in a speech reception threshold task while receiving online repetitive TMS separately to the left STG, right STG, or vertex or while receiving no TMS. Results show an equal drop in performance following application of TMS to either left or right STG during the task. A separate group of participants performed a visual discrimination threshold task to control for the confounding side effects of TMS. Results show no effect of TMS on the control task, supporting the notion that the results of Experiment 1 can be attributed to modulation of cortical functioning in STG rather than to side effects associated with online TMS. These results indicate that successful speech perception in everyday listening conditions requires both left and right STG and thus have ramifications for our understanding of the neural organization of spoken language processing.
C1 [Kennedy-Higgins, Dan; Devlin, Joseph T.; Adank, Patti] UCL, London, England.
   [Kennedy-Higgins, Dan] Kings Coll London, London, England.
   [Nuttall, Helen E.] Univ Lancaster, Lancaster, England.
RP Kennedy-Higgins, D (corresponding author), Kings Coll London, Dept Psychol, Guys Campus, London SE1 1UL, England.
EM daniel.kennedy-higgins@kcl.ac.uk
OI Nuttall, Helen/0000-0001-8497-5603; Kennedy-Higgins,
   Dan/0000-0002-7499-8833
FU University College London
FX This work was funded by an internal grant awarded to D. K.-H. from
   University College London. We thank Stuart Rosen for providing the
   speech materials used in Experiment 1, Steve Nevard for invaluable
   technical support, and all the individuals who participated in the two
   experiments.
CR Adank P, 2017, LANG COGN NEUROSCI, V32, P900, DOI 10.1080/23273798.2016.1257816
   Adank P, 2012, NEUROIMAGE, V63, P1601, DOI 10.1016/j.neuroimage.2012.07.027
   Alba-Ferrara L, 2012, BRAIN STIMUL, V5, P347, DOI 10.1016/j.brs.2011.06.004
   AMASSIAN VE, 1989, ELECTROEN CLIN NEURO, V74, P458, DOI 10.1016/0168-5597(89)90036-1
   Andoh J, 2011, J COGNITIVE NEUROSCI, V23, P349, DOI 10.1162/jocn.2010.21449
   [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   Baddley A., 1992, SPEECH CAPACITY LANG
   Beauchamp MS, 2010, J NEUROSCI, V30, P2414, DOI 10.1523/JNEUROSCI.4865-09.2010
   Bestelmeyer PEG, 2011, CURR BIOL, V21, pR838, DOI 10.1016/j.cub.2011.08.046
   Binder JR, 1997, J NEUROSCI, V17, P353
   Boersma P., 2014, PRAAT DOING PHONETIC
   BUCHMAN AS, 1986, J NEUROL NEUROSUR PS, V49, P489, DOI 10.1136/jnnp.49.5.489
   Bueti D, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002481
   Colenbrander A., 2002, VISUAL STANDARDS ASP
   COUNTER SA, 1991, ELECTROEN CLIN NEURO, V78, P173, DOI 10.1016/0013-4694(91)90031-X
   de Graaf TA, 2011, NEUROSCI BIOBEHAV R, V35, P871, DOI 10.1016/j.neubiorev.2010.10.006
   Drager B, 2004, EUR J NEUROSCI, V20, P1681, DOI 10.1111/j.1460-9568.2004.03623.x
   Duecker F, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00210
   Evans S, 2014, CEREB CORTEX, V24, P2350, DOI 10.1093/cercor/bht083
   Evans S, 2017, LANG COGN NEUROSCI, V32, P829, DOI 10.1080/23273798.2016.1272703
   Evans S, 2016, J COGNITIVE NEUROSCI, V28, P483, DOI 10.1162/jocn_a_00913
   Friederici AD, 2010, HUM BRAIN MAPP, V31, P448, DOI 10.1002/hbm.20878
   GLASS GV, 1972, REV EDUC RES, V42, P237, DOI 10.2307/1169991
   Harris KC, 2009, J NEUROSCI, V29, P6078, DOI 10.1523/JNEUROSCI.0412-09.2009
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Hickok G, 2008, BRAIN LANG, V107, P179, DOI 10.1016/j.bandl.2008.09.006
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2009, PHYS LIFE REV, V6, P121, DOI 10.1016/j.plrev.2009.06.001
   Killion M. C., 2004, HEAR REV, V11, P14
   Krieger-Redwood K, 2013, J COGNITIVE NEUROSCI, V25, P2179, DOI 10.1162/jocn_a_00463
   Lix LM, 1996, REV EDUC RES, V66, P579, DOI 10.2307/1170654
   McGettigan C, 2012, J COGNITIVE NEUROSCI, V24, P636, DOI 10.1162/jocn_a_00161
   MCGLONE J, 1984, BRAIN LANG, V22, P150, DOI 10.1016/0093-934X(84)90084-1
   McShefferty D, 2015, TRENDS HEAR, V19, DOI 10.1177/2331216515572316
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Narain C, 2003, CEREB CORTEX, V13, P1362, DOI 10.1093/cercor/bhg083
   O'Shea J, 2007, NEURON, V54, P479, DOI 10.1016/j.neuron.2007.04.021
   Obleser J, 2008, J NEUROSCI, V28, P8116, DOI 10.1523/JNEUROSCI.1290-08.2008
   Okada K, 2010, CEREB CORTEX, V20, P2486, DOI 10.1093/cercor/bhp318
   Pascual-Leone A, 1999, PHILOS T R SOC B, V354, P1229, DOI 10.1098/rstb.1999.0476
   Paus T, 2005, PHILOS T R SOC B, V360, P1109, DOI 10.1098/rstb.2005.1652
   Pelli D. G., 1988, CLIN VIS SCI
   Pelli DG, 2013, VISION RES, V90, P10, DOI 10.1016/j.visres.2013.04.015
   Pitcher D, 2014, J NEUROSCI, V34, P9173, DOI 10.1523/JNEUROSCI.5038-13.2014
   PLOMP R, 1979, J ACOUST SOC AM, V66, P1333, DOI 10.1121/1.383554
   PLOMP R, 1979, AUDIOLOGY, V18, P43
   Price CJ, 2002, TRENDS COGN SCI, V6, P416, DOI 10.1016/S1364-6613(02)01976-9
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rosen S, 2013, J ACOUST SOC AM, V133, P2431, DOI 10.1121/1.4794379
   Rosen S, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0024672
   Rossi S, 2009, CLIN NEUROPHYSIOL, V120, P2008, DOI 10.1016/j.clinph.2009.08.016
   Sack AT, 2006, CURR OPIN NEUROBIOL, V16, P593, DOI 10.1016/j.conb.2006.06.016
   Schonfeldt-Lecuona C, 2005, BRAIN TOPOGR, V17, P253, DOI 10.1007/s10548-005-6033-1
   Schoof T, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00307
   Scott SK, 2000, BRAIN, V123, P2400, DOI 10.1093/brain/123.12.2400
   Silvanto J, 2008, NEUROIMAGE, V39, P549, DOI 10.1016/j.neuroimage.2007.09.008
   Slevc R., 2015, HDB CLIN NEUROLOGY, V129, P573
   Stewart LM, 2001, NEUROPSYCHOLOGIA, V39, P415, DOI 10.1016/S0028-3932(00)00130-5
   Stokes MG, 2013, J NEUROPHYSIOL, V109, P437, DOI 10.1152/jn.00510.2012
   Thielscher A, 2004, CLIN NEUROPHYSIOL, V115, P1697, DOI 10.1016/j.clinph.2004.02.019
   Wassermann EM, 1998, EVOKED POTENTIAL, V108, P1, DOI 10.1016/S0168-5597(97)00096-8
   Wong PCM, 2008, J SPEECH LANG HEAR R, V51, P1026, DOI 10.1044/1092-4388(2008/075)
   Zekveld AA, 2006, NEUROIMAGE, V32, P1826, DOI 10.1016/j.neuroimage.2006.04.199
NR 63
TC 1
Z9 1
U1 1
U2 5
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0898-929X
EI 1530-8898
J9 J COGNITIVE NEUROSCI
JI J. Cogn. Neurosci.
PD JUN
PY 2020
VL 32
IS 6
BP 1092
EP 1103
DI 10.1162/jocn_a_01521
PG 12
WC Neurosciences; Psychology, Experimental
SC Neurosciences & Neurology; Psychology
GA LL9LJ
UT WOS:000531875200006
PM 31933438
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Feldman, JI
   Dunham, K
   Conrad, JG
   Simon, DM
   Cassidy, M
   Liu, YP
   Tu, A
   Broderick, N
   Wallace, MT
   Woynaroski, TG
AF Feldman, Jacob, I
   Dunham, Kacie
   Conrad, Julie G.
   Simon, David M.
   Cassidy, Margaret
   Liu, Yupeng
   Tu, Alexander
   Broderick, Neill
   Wallace, Mark T.
   Woynaroski, Tiffany G.
TI Plasticity of temporal binding in children with autism spectrum
   disorder: A single case experimental design perceptual training study
SO RESEARCH IN AUTISM SPECTRUM DISORDERS
LA English
DT Article
DE Autism; Multisensory integration; Perceptual training; Audiovisual;
   Plasticity
ID SPEECH-PERCEPTION; YOUNG-CHILDREN; INTEGRATION; COMMUNICATION; WINDOW;
   SYNCHRONY
AB Background: Many children with autism spectrum disorder (ASD) demonstrate atypical responses to multisensory stimuli. These disruptions, which are frequently seen in response to audiovisual speech, may produce cascading effects on the broader development of children with ASD. Perceptual training has been shown to enhance multisensory speech perception in typically developed adults. This study was the first to examine the effects of perceptual training on audiovisual speech perception in children with ASD.
   Method: A multiple baseline across participants design was utilized with four 7- to 13-year-old children with ASD. The dependent variable, which was probed outside the training task each day using a simultaneity judgment task in baseline, intervention, and maintenance conditions, was audiovisual temporal binding window (TBW), an index of multisensory temporal acuity. During perceptual training, participants completed the same simultaneity judgment task with feedback on their accuracy after each trial in easy-, medium-, and hard-difficulty blocks.
   Results: A functional relation between the multisensory perceptual training program and TBW size was not observed. Of the three participants who were entered into training, one participant demonstrated a strong effect, characterized by a fairly immediate change in TBW trend. The two remaining participants demonstrated a less clear response (i.e., longer latency to effect, lack of functional independence). The first participant to enter the training condition demonstrated some maintenance of a narrower TBW post-training.
   Conclusions: Results indicate TBWs in children with ASD may be malleable, but additional research is needed and may entail further adaptation to the multisensory perceptual training paradigm.
C1 [Feldman, Jacob, I] Vanderbilt Univ, Dept Hearing & Speech Sci, MCE 8310 South Tower,1215 21st Ave South, Nashville, TN 37232 USA.
   [Dunham, Kacie; Simon, David M.; Wallace, Mark T.; Woynaroski, Tiffany G.] Vanderbilt Univ, Vanderbilt Brain Inst, 465 21st Ave South, Nashville, TN USA.
   [Dunham, Kacie; Simon, David M.] Vanderbilt Univ, Neurosci Grad Program, 221 Kirkland Hall, Nashville, TN 37235 USA.
   [Conrad, Julie G.; Cassidy, Margaret; Liu, Yupeng; Tu, Alexander] Vanderbilt Univ, Neurosci Undergrad Program, 221 Kirkland Hall, Nashville, TN 37235 USA.
   [Conrad, Julie G.] Univ Illinois, Coll Med, Chicago, IL USA.
   [Simon, David M.] AxialHealthcare, Nashville, TN USA.
   [Tu, Alexander] Univ Nebraska Med Ctr, Coll Med, Omaha, NE USA.
   [Broderick, Neill] Vanderbilt Univ, Med Ctr, Dept Pediat, Nashville, TN 37232 USA.
   [Broderick, Neill; Wallace, Mark T.; Woynaroski, Tiffany G.] Vanderbilt Univ, Med Ctr, Vanderbilt Kennedy Ctr, Nashville, TN USA.
   [Wallace, Mark T.; Woynaroski, Tiffany G.] Vanderbilt Univ, Dept Hearing & Speech Sci, Med Ctr, Nashville, TN USA.
   [Wallace, Mark T.] Vanderbilt Univ, Dept Psychol, Nashville, TN 37240 USA.
   [Wallace, Mark T.] Vanderbilt Univ, Dept Psychiat & Behav Sci, Med Ctr, Nashville, TN USA.
   [Wallace, Mark T.] Vanderbilt Univ, Dept Pharmacol, Nashville, TN USA.
RP Feldman, JI (corresponding author), Vanderbilt Univ, Dept Hearing & Speech Sci, MCE 8310 South Tower,1215 21st Ave South, Nashville, TN 37232 USA.
EM jacob.i.feldman@vanderbilt.edu; tiffany.g.woynaroski@vumc.org
RI Feldman, Jacob/K-8212-2019
OI Feldman, Jacob/0000-0002-5723-5834
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [T32 MH064913]; NIH/NCATSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Center for Advancing Translational Sciences (NCATS)
   [UL1 TR000445];  [NIHU54 HD083211];  [NIH/NCATSKL2TR000446]; 
   [NIH/NIDCD1R21 DC016144]
FX This work was supported by NIHU54 HD083211 (PI: Neul),
   NIH/NCATSKL2TR000446 (PI: Woynaroski), NIH/NIDCD1R21 DC016144 (PI:
   Woynaroski), NIH T32 MH064913 (PI: Winder), and NIH/NCATS UL1 TR000445
   (PI: Bernard). The authors would like to thank the families who
   participated in our study, as well as the thoughtful comments from our
   reviewers that led to a vastly improved manuscript.
CR Aldred C, 2004, J CHILD PSYCHOL PSYC, V45, P1420, DOI 10.1111/j.1469-7610.2004.00338.x
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   American Psychiatric Association, 2000, DIAGN STAT MAN MENT, V4th
   Bahrick L. E, 2012, NEW HDB MULTISENSORY, P657
   Baranek GT, 2006, J CHILD PSYCHOL PSYC, V47, P591, DOI 10.1111/j.1469-7610.2005.01546.x
   Baum SH, 2015, PROG NEUROBIOL, V134, P140, DOI 10.1016/j.pneurobio.2015.09.007
   Ben-Sasson A, 2009, J AUTISM DEV DISORD, V39, P1, DOI 10.1007/s10803-008-0593-3
   Cascio CJ, 2016, AUTISM RES, V9, P920, DOI 10.1002/aur.1612
   Damiano-Goodwin CR, 2018, DEV COGN NEUROS-NETH, V29, P41, DOI 10.1016/j.dcn.2017.08.005
   De Niear MA, 2018, NEUROBIOL LEARN MEM, V147, P9, DOI 10.1016/j.nlm.2017.10.016
   De Niear MA, 2016, EXP BRAIN RES, V234, P3269, DOI 10.1007/s00221-016-4724-3
   Feldman JI, 2018, NEUROSCI BIOBEHAV R, V95, P220, DOI 10.1016/j.neubiorev.2018.09.020
   Feldman JI, 2019, J AUTISM DEV DISORD, V49, P397, DOI 10.1007/s10803-018-3667-x
   Gast D. L., 2018, SINGLE CASE RES METH
   Grzadzinski R, 2016, J AUTISM DEV DISORD, V46, P2464, DOI 10.1007/s10803-016-2782-9
   Harris PA, 2009, J BIOMED INFORM, V42, P377, DOI 10.1016/j.jbi.2008.08.010
   Hillock-Dunn A, 2012, DEVELOPMENTAL SCI, V15, P688, DOI 10.1111/j.1467-7687.2012.01171.x
   Horner RH, 2005, EXCEPT CHILDREN, V71, P165, DOI 10.1177/001440290507100203
   Irwin J, 2015, CLIN LINGUIST PHONET, V29, P76, DOI 10.3109/02699206.2014.966395
   Kazdin A. E., 2011, DATA EVALUATIONSINGL, P284
   Kratochwill T.R., 2014, SINGLE CASE INTERVEN, P91, DOI [10.1037/14376-004, DOI 10.1037/14376-004]
   Lord C., 2012, AUTISM DIAGNOSTIC 1
   Megnin O, 2012, AUTISM RES, V5, P39, DOI 10.1002/aur.231
   Mongillo EA, 2008, J AUTISM DEV DISORD, V38, P1349, DOI 10.1007/s10803-007-0521-y
   Murray MM, 2016, TRENDS NEUROSCI, V39, P567, DOI 10.1016/j.tins.2016.05.003
   Noel JP, 2017, AUTISM RES, V10, P121, DOI 10.1002/aur.1633
   Patten Elena, 2014, Autism Res Treat, V2014, P678346, DOI 10.1155/2014/678346
   Powers AR, 2009, J NEUROSCI, V29, P12265, DOI 10.1523/JNEUROSCI.3501-09.2009
   Quinto L, 2010, ATTEN PERCEPT PSYCHO, V72, P1450, DOI 10.3758/APP.72.6.1450
   R Core Team, 2017, R LANG ENV STAT COMP
   Righi G, 2018, AUTISM RES, V11, P645, DOI 10.1002/aur.1918
   Roid G. H., 2013, LEITER INT PERFORMAN
   Sandbank M, 2014, TOP EARLY CHILD SPEC, V34, P133, DOI 10.1177/0271121414528052
   Setti A, 2014, NEUROPSYCHOLOGIA, V61, P259, DOI 10.1016/j.neuropsychologia.2014.06.027
   Smith E, 2017, RES AUTISM SPECT DIS, V39, P11, DOI 10.1016/j.rasd.2017.04.001
   Smith JD, 2012, PSYCHOL METHODS, V17, P510, DOI 10.1037/a0029312
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Surig R, 2018, MULTISENS RES, V31, P556, DOI 10.1163/22134808-00002611
   TATE R, 2016, ARCH SCI PSYCHOL, V4, P10, DOI DOI 10.1037/ARC0000027
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   Williams JHG, 2004, RES DEV DISABIL, V25, P559, DOI 10.1016/j.ridd.2004.01.008
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
   Yoder P.J., 2018, OBSERVATIONAL MEASUR
NR 43
TC 2
Z9 2
U1 1
U2 7
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1750-9467
EI 1878-0237
J9 RES AUTISM SPECT DIS
JI Res. Autism Spectr. Disord.
PD JUN
PY 2020
VL 74
AR 101555
DI 10.1016/j.rasd.2020.101555
PG 13
WC Education, Special; Psychology, Developmental; Psychiatry;
   Rehabilitation
SC Education & Educational Research; Psychology; Psychiatry; Rehabilitation
GA LK4ZL
UT WOS:000530875200003
PM 32440308
DA 2021-02-24
ER

PT J
AU Fourtassi, A
   Frank, MC
AF Fourtassi, Abdellah
   Frank, Michael C.
TI How optimal is word recognition under multimodal uncertainty?
SO COGNITION
LA English
DT Article
DE Language understanding; Audio-visual processing; Word learning; Speech
   perception; Computational modeling
ID SPOKEN LANGUAGE COMPREHENSION; EYE-MOVEMENTS; SPEECH; CATEGORIES;
   INFORMATION; SIMILARITY; CONSTRAINTS; PERCEPTION; LISTEN; MEMORY
AB Identifying a spoken word in a referential context requires both the ability to integrate multimodal input and the ability to reason under uncertainty. How do these tasks interact with one another? We study how adults identify novel words under joint uncertainty in the auditory and visual modalities, and we propose an ideal observer model of how cues in these modalities are combined optimally. Model predictions are tested in four experiments where recognition is made under various sources of uncertainty. We found that participants use both auditory and visual cues to recognize novel words. When the signal is not distorted with environmental noise, participants weight the auditory and visual cues optimally, that is, according to the relative reliability of each modality. In contrast, when one modality has noise added to it, human perceivers systematically prefer the unperturbed modality to a greater extent than the optimal model does. This work extends the literature on perceptual cue combination to the case of word recognition in a referential context. In addition, this context offers a link to the study of multimodal information in word meaning learning.
C1 [Fourtassi, Abdellah; Frank, Michael C.] Stanford Univ, Dept Psychol, 50 Serra Mall,Jordan Hall,Bldg 420, Stanford, CA 94301 USA.
RP Fourtassi, A (corresponding author), Stanford Univ, Dept Psychol, 50 Serra Mall,Jordan Hall,Bldg 420, Stanford, CA 94301 USA.
EM abdellah.fourtassi@gmail.com
FU Fyssen Foundation
FX This work was supported by a post-doctoral grant from the Fyssen
   Foundation.
CR Anderson J., 1990, ADAPTIVE CHARACTER T
   Bankieris KR, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-11341-7
   Barnhart WR, 2018, ACTA PSYCHOL, V182, P154, DOI 10.1016/j.actpsy.2017.11.017
   Bates D. M., 1988, NONLINEAR REGRESSION
   Bejjanki VR, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019812
   Bergelson E., 2012, P NATL ACAD SCI, V109
   Bloom P., 2000, CHILDREN LEARN MEANI
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155
   Chater N, 2006, TRENDS COGN SCI, V10, P335, DOI 10.1016/j.tics.2006.05.006
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Coady J. A., 2003, J CHILD LANGUAGE, V30
   COLAVITA FB, 1974, PERCEPT PSYCHOPHYS, V16, P409, DOI 10.3758/BF03203962
   Creel SC, 2012, DEVELOPMENTAL SCI, V15, P697, DOI 10.1111/j.1467-7687.2012.01173.x
   Dautriche I, 2017, COGNITIVE SCI, V41, P2149, DOI 10.1111/cogs.12453
   Dingemanse M, 2015, TRENDS COGN SCI, V19, P603, DOI 10.1016/j.tics.2015.07.013
   Dupoux E, 2018, COGNITION, V173, P43, DOI 10.1016/j.cognition.2017.11.008
   EBERHARD KM, 1995, J PSYCHOLINGUIST RES, V24, P409, DOI 10.1007/BF02143160
   Edmiston P, 2015, COGNITION, V143, P93, DOI 10.1016/j.cognition.2015.06.008
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Feldman NH, 2009, PSYCHOL REV, V116, P752, DOI 10.1037/a0017196
   Fourtassi A, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P1
   Freedman D., 2001, SCIENCE, V291
   Geisler Wilson S., 2003, VISUAL NEUROSCIENCES, V10, P825
   Greenberg J. H., 1957, ESSAYS LINGUISTICS
   Harwath D., 2016, ADV NEURAL INFORM PR, P1858
   Havy M, 2016, COGNITION, V156, P41, DOI 10.1016/j.cognition.2016.07.011
   Hillenbrand J., 1995, J ACOUSTICAL SOC AM, V97
   Hirst R. J., 2018, NEUROSCI BIOBEHAV R, V94, P94
   Hofer M., 2017, P 39 ANN M COGN SCI
   Kleinschmidt D. F., 2015, PSYCHOL REV, V148
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007
   Kronrod Y., 2016, PSYCHONOMIC B REV, V23
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Landau B., 1988, COGNITIVE DEV, V3
   Lupyan G, 2012, J EXP PSYCHOL GEN, V141, P170, DOI 10.1037/a0024904
   MacDonald G, 2018, INTERAM RES CON COM, P40
   Markman E. M., 1991, PERSPECTIVES LANGUAG
   Marr D., 1982, VISION
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Mattys SL, 2011, J MEM LANG, V65, P145, DOI 10.1016/j.jml.2011.04.004
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Medina T., 2011, P NATL ACAD SCI, V108
   MERRIMAN WE, 1991, CHILD DEV, V62, P1288, DOI 10.1111/j.1467-8624.1991.tb01606.x
   Monaghan P, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0299
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Pajak B., 2016, J EXPT PSYCHOL LEARN, V42
   Peelle JE, 2018, EAR HEARING, V39, P204, DOI 10.1097/AUD.0000000000000494
   Pinker S., 1989, LEARNABILITY COGNITI
   QUINN PC, 1993, PERCEPTION, V22, P463, DOI 10.1068/p220463
   Rahnev D, 2018, BEHAV BRAIN SCI, V41, DOI 10.1017/S0140525X18000936
   Reber R, 1998, PSYCHOL SCI, V9, P45, DOI 10.1111/1467-9280.00008
   Robinson C. W., 2010, WILEY INTERDISCIPLIN, V1
   Ronnberg J, 2010, NOISE HEALTH, V12, P263, DOI 10.4103/1463-1741.70505
   Roy B. C., 2015, P NATL ACAD SCI, V112
   Saussure F., 1916, COURSE GEN LINGUISTI
   Schwarz N, 2004, J CONSUM PSYCHOL, V14, P332, DOI 10.1207/s15327663jcp1404_2
   Sloutsky V., 2003, CHILD DEV, V74
   Sloutsky VM, 2004, J EXP PSYCHOL GEN, V133, P166, DOI 10.1037/0096-3445.133.2.166
   Smith L, 2008, COGNITION, V106, P1558, DOI 10.1016/j.cognition.2007.06.010
   Spivey MJ, 2002, COGNITIVE PSYCHOL, V45, P447, DOI 10.1016/S0010-0285(02)00503-0
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Suanda S. H., 2014, J EXPT CHILD PSYCHOL, V126
   Swingley D, 2007, DEV PSYCHOL, V43, P454, DOI 10.1037/0012-1649.43.2.454
   Swingley D, 2016, DEV PSYCHOL, V52, P1011, DOI 10.1037/dev0000114
   Tamariz M., 2008, MENTAL LEXICON, V3
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788
   Tincoff R, 1999, PSYCHOL SCI, V10, P172, DOI 10.1111/1467-9280.00127
   Vlach HA, 2013, COGNITION, V127, P375, DOI 10.1016/j.cognition.2013.02.015
   Vouloumanos A, 2008, COGNITION, V107, P729, DOI 10.1016/j.cognition.2007.08.007
   Vouloumanos A, 2014, TRENDS COGN SCI, V18, P642, DOI 10.1016/j.tics.2014.10.001
   Vroomen J., 2004, SPEECH COMMUNICATION, V44
   Waxman S., 2009, TRENDS COGNITIVE SCI, V13
   Waxman SR, 1995, COGNITIVE PSYCHOL, V29, P257, DOI 10.1006/cogp.1995.1016
   White K., 2008, J MEMORY LANGUAGE, V59
   Yeung HH, 2009, COGNITION, V113, P234, DOI 10.1016/j.cognition.2009.08.010
   Yoshida K., 2009, DEV SCI, V12
   Yurovsky D, 2017, PSYCHOL SCI, V28, P132, DOI 10.1177/0956797616668557
   Yurovsky D, 2015, COGNITION, V145, P53, DOI 10.1016/j.cognition.2015.07.013
NR 80
TC 0
Z9 0
U1 2
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD JUN
PY 2020
VL 199
AR 104092
DI 10.1016/j.cognition.2019.104092
PG 15
WC Psychology, Experimental
SC Psychology
GA LB2IG
UT WOS:000524456800008
PM 32135386
DA 2021-02-24
ER

PT J
AU Parker, AN
   Wallis, GM
   Obergrussberger, R
   Siebeck, UE
AF Parker, Amira N.
   Wallis, Guy M.
   Obergrussberger, Rainer
   Siebeck, Ulrike E.
TI Categorical face perception in fish: How a fish brain warps reality to
   dissociate "same" from "different"
SO JOURNAL OF COMPARATIVE NEUROLOGY
LA English
DT Article
DE categorical perception; discrimination learning; face perception; fish
   visual perception; Pomacentrus amboinensis; visual discrimination
ID SPEECH-PERCEPTION; SOUND FREQUENCY; DISCRIMINATION; RECOGNITION; COLOR;
   LANGUAGE; CONTEXT; CORTEX; MONKEY; CATEGORIZATION
AB Categorical perception (CP) is the phenomenon by which a smoothly varying stimulus property undergoes a nonlinear transformation during processing in the brain. Consequently, the stimuli are perceived as belonging to distinct categories separated by a sharp boundary. Originally thought to be largely innate, the discovery of CP in tasks such as novel image discrimination has piqued the interest of cognitive scientists because it provides compelling evidence that learning can shape a category's perceptual boundaries. CP has been particularly closely studied in human face perception. In nonprimates, there is evidence for CP for sound and color discrimination, but not for image or face discrimination. Here, we investigate the potential for learned CP in a lower vertebrate, the damselfish Pomacentrus amboinensis. Specifically, we tested whether the ability of these fish to discriminate complex facial patterns tracked categorical rather than metric differences in the stimuli. We first trained the fish to discriminate sets of two facial patterns. Next, we morphed between these patterns and determined the just noticeable difference (JND) between a morph and original image. Finally, we tested for CP by analyzing the discrimination ability of the fish for pairs of JND stimuli along the spectrum of morphs between two original images. Discrimination performance was significant for the image pair straddling the boundary between categories, and chance for equivalent stimulus pairs on either side, thus producing the classic "category boundary" effect. Our results reveal how perception can be influenced in a top-down manner even in the absence of a visual cortex.
C1 [Parker, Amira N.; Obergrussberger, Rainer; Siebeck, Ulrike E.] Univ Queensland, Sch Biomed Sci, Brisbane, Qld 4072, Australia.
   [Wallis, Guy M.] Univ Queensland, Sch Human Movement & Nutr Sci, Brisbane, Qld, Australia.
RP Siebeck, UE (corresponding author), Univ Queensland, Sch Biomed Sci, Brisbane, Qld 4072, Australia.
EM u.siebeck@uq.edu.au
RI Siebeck, Ulrike/J-6190-2014
OI Siebeck, Ulrike/0000-0003-2024-1568
FU Australian Research CouncilAustralian Research Council [DP140100431,
   FT100100020]
FX Australian Research Council, Grant/Award Number: DP140100431 and
   FT100100020
CR Altmann CF, 2014, NEUROPSYCHOLOGIA, V64, P13, DOI 10.1016/j.neuropsychologia.2014.09.006
   Angeli A, 2008, Q J EXP PSYCHOL, V61, P690, DOI 10.1080/17470210701399305
   Baugh AT, 2008, P NATL ACAD SCI USA, V105, P8985, DOI 10.1073/pnas.0802201105
   BEALE JM, 1995, COGNITION, V57, P217, DOI 10.1016/0010-0277(95)00669-X
   Beckers GJL, 2011, HUM BIOL, V83, P191, DOI 10.3378/027.083.0204
   Benard J, 2006, ANIM COGN, V9, P257, DOI 10.1007/s10071-006-0032-9
   Bidelman GM, 2015, NEUROIMAGE, V120, P191, DOI 10.1016/j.neuroimage.2015.06.087
   Bidelman GM, 2014, EUR J NEUROSCI, V40, P2662, DOI 10.1111/ejn.12627
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Bogale BA, 2011, BEHAV PROCESS, V86, P109, DOI 10.1016/j.beproc.2010.10.002
   Bulthoff I, 2000, PERCEPTION, V29, P57
   Bulthoff I, 2004, VIS COGN, V11, P823, DOI 10.1080/13506280444000012
   Casey MC, 2012, NEURAL NETWORKS, V33, P114, DOI 10.1016/j.neunet.2012.05.001
   Cloutier J, 2007, EUR J SOC PSYCHOL, V37, P1298, DOI 10.1002/ejsp.433
   Coulon M, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004441
   Davies IRL, 2007, SPAN J PSYCHOL, V10, P471
   EHRET G, 1981, NATURWISSENSCHAFTEN, V68, P208, DOI 10.1007/BF01047208
   Ehret G, 2001, J EVOL BIOCHEM PHYS+, V37, P562, DOI 10.1023/A:1014042915818
   EHRET G, 1992, ANIM BEHAV, V43, P409, DOI 10.1016/S0003-3472(05)80101-0
   Fiorentini C, 2009, VIS COGN, V17, P373, DOI 10.1080/13506280701821019
   Franklin AC, 2003, PERCEPTION, V32, P87
   Freedman DJ, 2008, NEUROSCI BIOBEHAV R, V32, P311, DOI 10.1016/j.neubiorev.2007.07.011
   Fuss T, 2017, ZOOLOGY, V123, P16, DOI 10.1016/j.zool.2017.05.006
   Gaissert N, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043062
   Goldstone RL, 2010, WIRES COGN SCI, V1, P69, DOI 10.1002/wcs.26
   Gottfried JA, 2009, CURR OPIN NEUROBIOL, V19, P422, DOI 10.1016/j.conb.2009.07.012
   Grimsley JMS, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017460
   Harnad Stevan, 1987, CATEGORICAL PERCEPTI
   Karoubi N, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174044
   Kendrick KM, 2001, NATURE, V414, P165, DOI 10.1038/35102669
   Kostarakos K, 2012, J NEUROSCI, V32, P9601, DOI 10.1523/JNEUROSCI.1170-12.2012
   KUHL PK, 1976, J ACOUST SOC AM, V60, pS81, DOI 10.1121/1.2003550
   Lachlan RF, 2015, P NATL ACAD SCI USA, V112, P1892, DOI 10.1073/pnas.1410844112
   Levin DT, 2000, PERCEPT PSYCHOPHYS, V62, P386, DOI 10.3758/BF03205558
   Levy DF, 2020, CEREB CORTEX, V30, P618, DOI 10.1093/cercor/bhz112
   Li XL, 2020, NEUROREPORT, V31, P359, DOI 10.1097/WNR.0000000000001414
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   Liu RC, 2006, EUR J NEUROSCI, V23, P3087, DOI 10.1111/j.1460-9568.2006.04840.x
   Maki SL, 2001, NEUROREPORT, V12, P3425, DOI 10.1097/00001756-200111160-00010
   Martin-Malivel J, 2007, BEHAV NEUROSCI, V121, P1145, DOI 10.1037/0735-7044.121.6.1145
   Mokeichev A, 2010, P NATL ACAD SCI USA, V107, P16726, DOI 10.1073/pnas.1005446107
   NELSON DA, 1989, SCIENCE, V244, P976, DOI 10.1126/science.2727689
   Newport C, 2018, ANIM BEHAV, V145, P39, DOI 10.1016/j.anbehav.2018.09.002
   Newport C, 2016, SCI REP-UK, V6, DOI 10.1038/srep27523
   Newport C, 2013, ANIM BEHAV, V86, P1265, DOI 10.1016/j.anbehav.2013.09.031
   Obergrussberger R., 2006, THESIS
   Ozgen E, 2004, PERCEPTION, V33, P66
   Parker A., 2020, UQESPACE, DOI [10.14264/uql.2020.641, DOI 10.14264/UQL.2020.641]
   Pasko L, 2010, ZOO BIOL, V29, P767, DOI 10.1002/zoo.20307
   PASTORE RE, 1976, J ACOUST SOC AM, V59, pS24, DOI 10.1121/1.2002505
   Pessoa VF, 1997, BEHAV BRAIN RES, V89, P285, DOI 10.1016/S0166-4328(97)00079-X
   Pollack GS, 1999, BIOESSAYS, V21, P295, DOI 10.1002/(SICI)1521-1878(199904)21:4&lt;295::AID-BIES5&gt;3.0.CO;2-U
   RAGNEMALM I, 1993, PATTERN RECOGN LETT, V14, P883, DOI 10.1016/0167-8655(93)90152-4
   ROSCH E, 1976, COGNITIVE PSYCHOL, V8, P382, DOI 10.1016/0010-0285(76)90013-X
   Schluessel V, 2012, ANIM COGN, V15, P525, DOI 10.1007/s10071-012-0480-3
   Siebeck UE, 2009, J EXP BIOL, V212, P2112, DOI 10.1242/jeb.028936
   Siebeck UE, 2010, CURR BIOL, V20, P407, DOI 10.1016/j.cub.2009.12.047
   Sigala R, 2011, J NEUROPHYSIOL, V105, P2740, DOI 10.1152/jn.00882.2010
   Stolten K, 2014, LANG SPEECH, V57, P425, DOI 10.1177/0023830913508760
   Suzuki A, 2004, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P1303
   Sweeny TD, 2012, VISION RES, V64, P26, DOI 10.1016/j.visres.2012.05.008
   Thompson RKR, 2000, COGNITIVE SCI, V24, P363
   Tibbetts EA, 2002, P ROY SOC B-BIOL SCI, V269, P1423, DOI 10.1098/rspb.2002.2031
   WEARY DM, 1989, J COMP PSYCHOL, V103, P320, DOI 10.1037/0735-7036.103.4.320
   Webster MA, 2004, NATURE, V428, P557, DOI 10.1038/nature02420
   Wu H, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00436
   Wyttenbach RA, 1996, SCIENCE, V273, P1542, DOI 10.1126/science.273.5281.1542
   Wyzisk K, 2007, VISUAL NEUROSCI, V24, P291, DOI 10.1017/S095252380707023X
   Yu MX, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-14104-6
   Zheng HY, 2012, LANG COGNITIVE PROC, V27, P184, DOI 10.1080/01690965.2010.520493
NR 70
TC 0
Z9 0
U1 1
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0021-9967
EI 1096-9861
J9 J COMP NEUROL
JI J. Comp. Neurol.
PD DEC 1
PY 2020
VL 528
IS 17
SI SI
BP 2919
EP 2928
DI 10.1002/cne.24947
EA MAY 2020
PG 10
WC Neurosciences; Zoology
SC Neurosciences & Neurology; Zoology
GA NW9PV
UT WOS:000536056200001
PM 32406088
DA 2021-02-24
ER

PT J
AU Eslick, CJ
   le Roux, M
   Geertsema, S
   Pottas, L
AF Eslick, Casey J.
   le Roux, Mia
   Geertsema, Salome
   Pottas, Lidia
TI Phonological awareness and speech perception: Skills of Grade 1 English
   second language learners
SO READING & WRITING-JOURNAL OF THE READING ASSOCIATION OF SOUTH AFRICA
LA English
DT Article
DE language of instruction; literacy; multilingualism; phonological
   awareness; second language; speech perception
ID LANGUAGE; RECOGNITION; CHILDREN
AB Background: Literacy achievement of learners is a concern in many developing countries, particularly for English second language (EL2) learners with inadequate language development. It is important to investigate foundational phonological awareness (PA), as well as speech perception skills to guide the development of effective intervention for EL2 learners to facilitate optimal literacy acquisition.
   Objectives: The study aimed to describe the PA and speech perception in noise skills of South African Grade 1, EL2 participants, learning in an English first language (EL1) context, to inform evidence-based support during literacy acquisition for EL2 learners.
   Method: A cross-sectional, descriptive design was employed. Twenty-five EL1 participants provided normative results for the Phonological Awareness Test - 2 and South African English Digits-in-Noise Test, enabling between-group comparisons with 25 matched EL2 participants for quantitative data analysis. Demographic and background information was obtained using parental questionnaires.
   Results: The EL2 learners presented with PA skills below those of EL1 learners in all subtests. Though the speech perception in noise skills of EL2 learners were within the normative range for their age, their skills are also lower in comparison to EL1 learners.
   Conclusion: The findings support the inclusion of explicit PA instruction for rhyming, segmentation, isolation, deletion, substitution, and blending for EL2 literacy acquisition. Developing speech perception in noise skills is necessary to facilitate PA and phoneme-grapheme knowledge. This can enable decoding for early EL2 literacy acquisition.
C1 [Eslick, Casey J.; le Roux, Mia; Geertsema, Salome; Pottas, Lidia] Univ Pretoria, Fac Humanities, Speech Language Pathol & Audiol, Pretoria, South Africa.
RP Eslick, CJ (corresponding author), Univ Pretoria, Fac Humanities, Speech Language Pathol & Audiol, Pretoria, South Africa.
EM cjeslick10@gmail.com
OI Eslick, Casey Jane/0000-0003-2297-4466; Le Roux,
   Mia/0000-0001-7739-4907; Geertsema, Salome/0000-0002-0856-0737; Pottas,
   Lidia/0000-0002-9549-4714
CR Alcock KJ, 2018, J LEARN DISABIL-US, V51, P463, DOI 10.1177/0022219417728051
   Alexander M.C., 2018, 11 LANGUAGES S AFRIC
   Callaghan G, 2012, AUST J EARLY CHILD, V37, P13, DOI 10.1177/183693911203700103
   Cassady JC, 2008, READ PSYCHOL, V29, P508, DOI 10.1080/02702710802271966
   Chung KKH, 2013, J RES READ, V36, P202, DOI 10.1111/j.1467-9817.2011.01500.x
   Cilliers Liezel, 2018, Reading & Writing, V9, P1, DOI 10.4102/rw.v9i1.167
   de Witt M, 2016, AUST J EARLY CHILD, V41, P106, DOI 10.1177/183693911604100114
   Department on Innovation Industry Science and Research, 2011, CLOUD COMP OPP CHALL, P1
   Eslick C.J., 2018, THESIS, P1
   Gauthier S.V., 1998, KLST 2 KINDERGARTEN
   Goldstein H, 2017, J SPEECH LANG HEAR R, V60, P89, DOI 10.1044/2016_JSLHR-L-15-0451
   Hay I, 2012, AUST J EARLY CHILD, V37, P24, DOI 10.1177/183693911203700104
   Howie S.J., 2012, PIRLS 2011 PROGR INT, P1
   Kaandorp MW, 2016, INT J AUDIOL, V55, P157, DOI 10.3109/14992027.2015.1104735
   Krizman J, 2017, BILING-LANG COGN, V20, P834, DOI 10.1017/S1366728916000444
   Lagace J, 2011, INT J AUDIOL, V50, P385, DOI 10.3109/14992027.2011.553204
   le Roux M, 2017, S AFR J COMMUN DISOR, V64, DOI 10.4102/sajcd.v64i1.164
   Lewis D, 2010, EAR HEARING, V31, P761, DOI 10.1097/AUD.0b013e3181e5d188
   Malda M, 2014, LEARN INDIVID DIFFER, V30, P34, DOI 10.1016/j.lindif.2013.11.008
   Mealings K. T., 2015, J ED PEDIAT REHABILI, V1, P1
   Methula N., 2016, DIGITS IN NOISE TEST
   Millett-Gallant A, 2017, INTERD DISABIL STUD, P1
   Nyaga SK, 2015, STELLENBOSCH PAP LIN, V44, P175, DOI 10.5774/44-0-172
   Obralic A., 2016, INT J LEARNING DEV, V6, P53
   Ouellette GP, 2013, J RES READ, V36, P29, DOI 10.1111/j.1467-9817.2010.01486.x
   Potgieter JM, 2018, EAR HEARING, V39, P656, DOI 10.1097/AUD.0000000000000522
   Potgieter JM, 2016, INT J AUDIOL, V55, P405, DOI 10.3109/14992027.2016.1172269
   Preston J, 2010, J SPEECH LANG HEAR R, V53, P44, DOI 10.1044/1092-4388(2009/09-0021)
   Probert T, 2016, READ WRIT-J READ ASS, V7, DOI 10.4102/rw.v7i1.84
   Robertson C., 2007, PHONOLOGICAL AWARENE
   Robertson C., 2007, PEOPLES ASEAN GOVT A, P1
   Smits C, 2013, J ACOUST SOC AM, V133, P1693, DOI 10.1121/1.4789933
   Snyman ME, 2016, READ WRIT-J READ ASS, V7, DOI 10.4102/rw.v7i1.85
   Swanepoel D, 2014, INT J AUDIOL, V53, P841, DOI 10.3109/14992027.2014.920965
   Taylor S, 2016, ECON EDUC REV, V50, P75, DOI 10.1016/j.econedurev.2016.01.003
   Webb MYL, 2014, J SPEECH LANG HEAR R, V57, P131, DOI 10.1044/1092-4388(2013/12-0106)
   Webb V, 2010, LANG LEARN J, V38, P273, DOI 10.1080/09571730903208389
   Wildschut Zelda, 2016, SAJCE, V6, P1, DOI 10.4102/sajce.v6i1.340
   Willenberg Ingrid, 2007, S Afr J Commun Disord, V54, P20
NR 39
TC 0
Z9 0
U1 1
U2 1
PU AOSIS
PI CAPE TOWN
PA POSTNET SUITE 55, PRIVATE BAG X22, TYGERVALLEY, CAPE TOWN, 00000, SOUTH
   AFRICA
SN 2079-8245
EI 2308-1422
J9 READ WRIT-J READ ASS
JI Read. Writ.-J. Read. Assoc. S. Afr.
PD MAY 27
PY 2020
VL 11
IS 1
AR a263
DI 10.4102/rw.v11i1.263
PG 10
WC Education & Educational Research
SC Education & Educational Research
GA LV8ZP
UT WOS:000538732100001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Virtala, P
   Talola, S
   Partanen, E
   Kujala, T
AF Virtala, P.
   Talola, S.
   Partanen, E.
   Kujala, T.
TI Poor neural and perceptual phoneme discrimination during acoustic
   variation in dyslexia
SO SCIENTIFIC REPORTS
LA English
DT Article
ID MISMATCH NEGATIVITY; AUDITORY-DISCRIMINATION; DEVELOPMENTAL DYSLEXIA;
   SPEECH-PERCEPTION; LANGUAGE; CHILDREN; DEFICIT; BRAIN; REPRESENTATIONS;
   DYSFUNCTION
AB Whereas natural acoustic variation in speech does not compromise phoneme discrimination in healthy adults, it was hypothesized to be a challenge for developmental dyslexics. We investigated dyslexics' neural and perceptual discrimination of native language phonemes during acoustic variation. Dyslexics and non-dyslexics heard /ae/ and /i/ phonemes in a context with f(o) variation and then in a context without it. Mismatch negativity (MMN) and P3a responses to phoneme changes were recorded with electroencephalogram to compare groups during ignore and attentive listening. Perceptual phoneme discrimination in the variable context was evaluated with hit-ratios and reaction times. MMN/N2bs were diminished in dyslexics in the variable context. Hit-ratios were smaller in dyslexics than controls. MMNs did not differ between groups in the context without variation. These results suggest that even distinctive vowels are challenging to discriminate for dyslexics when the context resembles natural variability of speech. This most likely reflects poor categorical perception of phonemes in dyslexics. Difficulties to detect linguistically relevant invariant information during acoustic variation in speech may contribute to dyslexics' deficits in forming native language phoneme representations during infancy. Future studies should acknowledge that simple experimental paradigms with repetitive stimuli can be insensitive to dyslexics' speech processing deficits.
C1 [Virtala, P.; Talola, S.; Partanen, E.; Kujala, T.] Univ Helsinki, Fac Med, Dept Psychol & Logoped, Cognit Brain Res Unit, Helsinki, Finland.
   [Virtala, P.; Talola, S.; Partanen, E.; Kujala, T.] Univ Helsinki, Inst Behav Sci, Cognit Brain Res Unit, Helsinki, Finland.
   [Partanen, E.] Aarhus Univ, Ctr Funct Integrat Neurosci CFIN, Dept Clin Med, Aarhus, Denmark.
RP Virtala, P (corresponding author), Univ Helsinki, Fac Med, Dept Psychol & Logoped, Cognit Brain Res Unit, Helsinki, Finland.; Virtala, P (corresponding author), Univ Helsinki, Inst Behav Sci, Cognit Brain Res Unit, Helsinki, Finland.
EM paula.virtala@helsinki.fi
OI Kujala, Teija/0000-0002-8814-605X; Virtala, Paula
   Maarit/0000-0001-5864-6478
FU Finnish Cultural FoundationFinnish Cultural Foundation; Academy of
   FinlandAcademy of FinlandEuropean Commission [276414, 316970]; Jane and
   Aatos Erkko Foundation
FX Ms. Sanna Talola, research assistants Ms. Taru Kakonen, Ms. Iina
   Ala-Kurikka, Ms. Irina Iljin, Ms. Eliisa Lehto, Mr. Tuomas Mansikka, Mr.
   Teemu Valkonen and research intern Mr. Lari Linden have collected the
   data in the present study. The authors have received funding from the
   Finnish Cultural Foundation, the Academy of Finland (grant numbers
   276414 and 316970) and from Jane and Aatos Erkko Foundation.
CR Ahissar M, 2007, TRENDS COGN SCI, V11, P458, DOI 10.1016/j.tics.2007.08.015
   Alho K, 1998, PSYCHOPHYSIOLOGY, V35, P211, DOI 10.1111/1469-8986.3520211
   Baldeweg T, 1999, ANN NEUROL, V45, P495, DOI 10.1002/1531-8249(199904)45:4<495::AID-ANA11>3.0.CO;2-M
   Bishop DVM, 2007, PSYCHOL BULL, V133, P651, DOI 10.1037/0033-2909.133.4.651
   Bitz U, 2007, NEUROREPORT, V18, P911, DOI 10.1097/WNR.0b013e32810f2e25
   BOERSMA P., 2013, DOING PHONETICS COMP
   Boets B, 2013, SCIENCE, V342, P1251, DOI 10.1126/science.1244333
   Bogliotti C, 2008, J EXP CHILD PSYCHOL, V101, P137, DOI 10.1016/j.jecp.2008.03.006
   Corbera S, 2006, NEUROREPORT, V17, P1051, DOI 10.1097/01.wnr.0000221846.43126.a6
   Dehaene-Lambertz G, 2001, NEUROREPORT, V12, P3155, DOI 10.1097/00001756-200110080-00034
   Fosker T, 2004, NEUROSCI LETT, V357, P171, DOI 10.1016/j.neulet.2003.12.084
   Gabay Y, 2015, CORTEX, V73, P131, DOI 10.1016/j.cortex.2015.08.008
   Gabay Y, 2015, J SPEECH LANG HEAR R, V58, P934, DOI 10.1044/2015_JSLHR-L-14-0324
   Galaburda AM, 2006, NAT NEUROSCI, V9, P1213, DOI 10.1038/nn1772
   Giraud AL, 2013, CURR OPIN NEUROBIOL, V23, P37, DOI 10.1016/j.conb.2012.09.003
   GODFREY JJ, 1981, J EXP CHILD PSYCHOL, V32, P401, DOI 10.1016/0022-0965(81)90105-3
   Hamalainen JA, 2013, J LEARN DISABIL-US, V46, P413, DOI 10.1177/0022219411436213
   Harmony T, 2000, COGNITIVE BRAIN RES, V9, P53, DOI 10.1016/S0926-6410(99)00044-0
   Hoonhorst I, 2009, J EXP CHILD PSYCHOL, V104, P353, DOI 10.1016/j.jecp.2009.07.005
   Horvath J, 2008, BIOL PSYCHOL, V79, P139, DOI 10.1016/j.biopsycho.2008.04.001
   Ille N, 2002, J CLIN NEUROPHYSIOL, V19, P113, DOI 10.1097/00004691-200203000-00002
   Kere J, 2014, BIOCHEM BIOPH RES CO, V452, P236, DOI 10.1016/j.bbrc.2014.07.102
   Kere J, 2011, WIRES COGN SCI, V2, P441, DOI 10.1002/wcs.138
   Kessler RC, 2005, PSYCHOL MED, V35, P245, DOI 10.1017/S0033291704002892
   Kimppa L., 2018, SCI REP, V8, P1
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kujala T, 2006, CLIN NEUROPHYSIOL, V117, P885, DOI 10.1016/j.clinph.2006.01.002
   Kujala T, 2003, EUR J NEUROSCI, V17, P1323, DOI 10.1046/j.1460-9568.2003.02559.x
   Kujala T, 2000, PSYCHOPHYSIOLOGY, V37, P262
   Kujala T, 2006, EUR J NEUROSCI, V24, P2420, DOI 10.1111/j.1460-9568.2006.05100.x
   Kujala T, 2001, NEUROSCI BIOBEHAV R, V25, P535, DOI 10.1016/S0149-7634(01)00032-X
   Kujala T, 2007, J PSYCHOPHYSIOL, V21, P239, DOI 10.1027/0269-8803.21.34.239
   Kujala T, 2007, BIOL PSYCHOL, V74, P1, DOI 10.1016/j.biopsycho.2006.06.001
   Kujala T, 2017, DEV COGN NEUROS-NETH, V28, P65, DOI 10.1016/j.dcn.2017.10.005
   Laasonen M, 2010, J LEARN DISABIL-US, V43, P3, DOI 10.1177/0022219409335216
   Lachmann T, 2005, INT J PSYCHOPHYSIOL, V56, P105, DOI 10.1016/j.ijpsycho.2004.11.005
   Lefly DL, 2000, J LEARN DISABIL-US, V33, P286, DOI 10.1177/002221940003300306
   Lovio R, 2010, BRAIN RES, V1335, P53, DOI 10.1016/j.brainres.2010.03.097
   Lum JAG, 2013, RES DEV DISABIL, V34, P3460, DOI 10.1016/j.ridd.2013.07.017
   Lyon GR, 2003, ANN DYSLEXIA, V53, P1, DOI 10.1007/s11881-003-0001-9
   Maurer U, 2009, BIOL PSYCHIAT, V66, P341, DOI 10.1016/j.biopsych.2009.02.031
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   NAATANEN R, 1982, BIOL PSYCHOL, V14, P53, DOI 10.1016/0301-0511(82)90017-5
   Naatanen R, 2001, PSYCHOPHYSIOLOGY, V38, P1, DOI 10.1017/S0048577201000208
   Naatanen R, 2011, PSYCHOPHYSIOLOGY, V48, P4, DOI 10.1111/j.1469-8986.2010.01114.x
   Nagarajan S, 1999, P NATL ACAD SCI USA, V96, P6483, DOI 10.1073/pnas.96.11.6483
   Nevala J., 2006, JA KIRJOITTAMISTAITO
   Noordenbos MW, 2012, NEUROPSYCHOLOGIA, V50, P2010, DOI 10.1016/j.neuropsychologia.2012.04.026
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   Perrachione TK, 2016, NEURON, V92, P1383, DOI 10.1016/j.neuron.2016.11.020
   Peterson RL, 2015, ANNU REV CLIN PSYCHO, V11, P283, DOI 10.1146/annurev-clinpsy-032814-112842
   Peterson RL, 2012, LANCET, V379, P1997, DOI 10.1016/S0140-6736(12)60198-6
   Schaadt G, 2019, CLIN NEUROPHYSIOL, V130, P1329, DOI 10.1016/j.clinph.2019.05.018
   Schulte-Korne G, 2001, INT J PSYCHOPHYSIOL, V40, P77, DOI 10.1016/S0167-8760(00)00152-5
   Serniclaes W., 2003, CURR PSYCHOL LETT BE, V1
   Serniclaes W., 2018, JSM COMMUN DISORD, V2, P1010
   Shaywitz SE, 1998, NEW ENGL J MED, V338, P307, DOI 10.1056/NEJM199801293380507
   Shestakova A, 2002, NEUROREPORT, V13, P1813, DOI 10.1097/00001756-200210070-00025
   van Zuijen TL, 2012, NEUROSCI LETT, V528, P31, DOI 10.1016/j.neulet.2012.08.058
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   Virtala P, 2018, BIOL PSYCHOL, V132, P217, DOI 10.1016/j.biopsycho.2018.01.002
   WERKER JF, 1987, CAN J PSYCHOL, V41, P48, DOI 10.1037/h0084150
   Wiik K., 1965, FINNISH ENGLISH VOWE
   Zhang YJ, 2012, J CHILD PSYCHOL PSYC, V53, P874, DOI 10.1111/j.1469-7610.2012.02528.x
NR 64
TC 2
Z9 2
U1 0
U2 1
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD MAY 26
PY 2020
VL 10
IS 1
AR 8646
DI 10.1038/s41598-020-65490-3
PG 11
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA LY4AO
UT WOS:000540471500002
PM 32457322
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU McFayden, TC
   Baskin, P
   Stephens, JDW
   He, SM
AF McFayden, Tyler C.
   Baskin, Paola
   Stephens, Joseph D. W.
   He, Shuman
TI Cortical Auditory Event-Related Potentials and Categorical Perception of
   Voice Onset Time in Children With an Auditory Neuropathy Spectrum
   Disorder
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE auditory neuropathy spectrum disorders; voice onset time; auditory
   event-related response; speech perception; categorical perception
ID EVOKED-POTENTIALS; SPEECH-PERCEPTION; CROSS-LANGUAGE; WORKING-MEMORY;
   NOISE; REPRESENTATION; CORTEX; INDIVIDUALS; RESPONSES; FEATURES
AB Objective: This study evaluated cortical encoding of voice onset time (VOT) in quiet and noise, and their potential associations with the behavioral categorical perception of VOT in children with auditory neuropathy spectrum disorder (ANSD). Design: Subjects were 11 children with ANSD ranging in age between 6.4 and 16.2 years. The stimulus was an /aba/-/apa/ vowel-consonant-vowel continuum comprising eight tokens with VOTs ranging from 0 ms (voiced endpoint) to 88 ms (voiceless endpoint). For speech in noise, speech tokens were mixed with the speech-shaped noise from the Hearing In Noise Test at a signal-to-noise ratio (SNR) of +5 dB. Speech-evoked auditory event-related potentials (ERPs) and behavioral categorization perception of VOT were measured in quiet in all subjects, and at an SNR of +5 dB in seven subjects. The stimuli were presented at 35 dB SL (re: pure tone average) or 115 dB SPL if this limit was less than 35 dB SL. In addition to the onset response, the auditory change complex (ACC) elicited by VOT was recorded in eight subjects. Results: Speech evoked ERPs recorded in all subjects consisted of a vertex positive peak (i.e., P1), followed by a trough occurring approximately 100 ms later (i.e., N2). For results measured in quiet, there was no significant difference in categorical boundaries estimated using ERP measures and behavioral procedures. Categorical boundaries estimated in quiet using both ERP and behavioral measures closely correlated with the most-recently measured Phonetically Balanced Kindergarten (PBK) scores. Adding a competing background noise did not affect categorical boundaries estimated using either behavioral or ERP procedures in three subjects. For the other four subjects, categorical boundaries estimated in noise using behavioral measures were prolonged. However, adding background noise only increased categorical boundaries measured using ERPs in three out of these four subjects. Conclusions: VCV continuum can be used to evaluate behavioral identification and the neural encoding of VOT in children with ANSD. In quiet, categorical boundaries of VOT estimated using behavioral measures and ERP recordings are closely associated with speech recognition performance in children with ANSD. Underlying mechanisms for excessive speech perception deficits in noise may vary for individual patients with ANSD.
C1 [McFayden, Tyler C.] Virginia Polytech Inst & State Univ, Dept Psychol, Blacksburg, VA 24061 USA.
   [Baskin, Paola] Univ Calif San Diego, Sch Med, Dept Anesthesiol, San Diego, CA 92103 USA.
   [Stephens, Joseph D. W.] North Carolina Agr & Tech State Univ, Dept Psychol, Greensboro, NC USA.
   [He, Shuman] Ohio State Univ, Wexner Med Ctr, Dept Otolaryngol Head & Neck Surg, Columbus, OH 43210 USA.
   [He, Shuman] Nationwide Childrens Hosp, Dept Audiol, Columbus, OH 43205 USA.
RP He, SM (corresponding author), Ohio State Univ, Wexner Med Ctr, Dept Otolaryngol Head & Neck Surg, Columbus, OH 43210 USA.; He, SM (corresponding author), Nationwide Childrens Hosp, Dept Audiol, Columbus, OH 43205 USA.
EM shuman.he@osumc.edu
OI McFayden, Tyler/0000-0001-8942-1562
FU Junior Faculty Career Development Award from School of Medicine, The
   University of North Carolina at Chapel Hill; National Institute on
   Deafness and Other Communication Disorders (NIDCD)United States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01DC017846]
FX This work was supported by the Junior Faculty Career Development Award
   from School of Medicine, The University of North Carolina at Chapel
   Hill, and the R01 grant from National Institute on Deafness and Other
   Communication Disorders (NIDCD; R01DC017846 for supporting SH's effort
   on this project and for the publication cost of this article).
CR Alain C, 2009, EUR J NEUROSCI, V30, P132, DOI 10.1111/j.1460-9568.2009.06792.x
   Apeksha K, 2019, EUR ARCH OTO-RHINO-L, V276, P1633, DOI 10.1007/s00405-019-05405-9
   ATAL BS, 1971, J ACOUST SOC AM, V50, P637, DOI 10.1121/1.1912679
   Baltzell LS, 2014, CLIN NEUROPHYSIOL, V125, P370, DOI 10.1016/j.clinph.2013.08.003
   Berlin CI, 2010, INT J AUDIOL, V49, P30, DOI 10.3109/14992020903160892
   Bielecki I, 2012, INT J PEDIATR OTORHI, V76, P1668, DOI 10.1016/j.ijporl.2012.08.001
   Billings CJ, 2013, JARO-J ASSOC RES OTO, V14, P891, DOI 10.1007/s10162-013-0415-y
   Billings CJ, 2011, EAR HEARING, V32, P53, DOI 10.1097/AUD.0b013e3181ec5c46
   Billings CJ, 2009, HEARING RES, V254, P15, DOI 10.1016/j.heares.2009.04.002
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Ceponiene R, 1998, EVOKED POTENTIAL, V108, P345, DOI 10.1016/S0168-5597(97)00081-6
   Dimitrijevic A, 2013, CLIN NEUROPHYSIOL, V124, P1204, DOI 10.1016/j.clinph.2012.11.014
   Elangovan S, 2008, EAR HEARING, V29, P761, DOI 10.1097/AUD.0b013e318185ddd2
   Elangovan S, 2011, NEUROSCI LETT, V490, P140, DOI 10.1016/j.neulet.2010.12.044
   Frye RE, 2007, J COGNITIVE NEUROSCI, V19, P1476, DOI 10.1162/jocn.2007.19.9.1476
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Gilley PM, 2005, CLIN NEUROPHYSIOL, V116, P648, DOI 10.1016/j.clinph.2004.09.009
   He S, 2015, EAR HEARING, V36, P289, DOI 10.1097/AUD.0000000000000119
   Horev N, 2007, EAR HEARING, V28, P111, DOI 10.1097/01.aud.0000250021.69163.96
   Kaplan-Neeman R, 2006, J ACOUST SOC AM, V120, P926, DOI 10.1121/1.2217567
   King KA, 2008, CLIN NEUROPHYSIOL, V119, P2855, DOI 10.1016/j.clinph.2008.09.015
   Kraus N, 2003, SPEECH COMMUN, V41, P35, DOI 10.1016/S0167-6393(02)00091-2
   KRAUS N, 1984, LARYNGOSCOPE, V94, P400
   Kraus N, 2000, JARO-J ASSOC RES OTO, V1, P33, DOI 10.1007/s101620010004
   Kuruvilla-Mathew A, 2015, INT J AUDIOL, V54, P852, DOI 10.3109/14992027.2015.1055838
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   LISKER L, 1975, J ACOUST SOC AM, V57, P1547, DOI 10.1121/1.380602
   MacCutcheon D, 2019, J SPEECH LANG HEAR R, V62, P3741, DOI 10.1044/2019_JSLHR-S-19-0012
   Madden C, 2002, ARCH OTOLARYNGOL, V128, P1026, DOI 10.1001/archotol.128.9.1026
   Martin BA, 2008, EAR HEARING, V29, P285, DOI 10.1097/AUD.0b013e3181662c0e
   McCreery RW, 2017, INT J AUDIOL, V56, P306, DOI 10.1080/14992027.2016.1266703
   McCullagh J., 2012, AUDIOL MED, V10, P114, DOI DOI 10.3109/1651386x.2012.707354
   Michalewski HJ, 2005, CLIN NEUROPHYSIOL, V116, P669, DOI 10.1016/j.clinph.2004.09.027
   MORRONGIELLO BA, 1984, J EXP CHILD PSYCHOL, V37, P231, DOI 10.1016/0022-0965(84)90002-X
   Nilsson J. M., 1996, DEV HEARING NOISE TE
   Papesh MA, 2015, CLIN NEUROPHYSIOL, V126, P1319, DOI 10.1016/j.clinph.2014.10.017
   Parbery-Clark A, 2011, EUR J NEUROSCI, V33, P549, DOI 10.1111/j.1460-9568.2010.07546.x
   Pelosi S, 2012, OTOL NEUROTOL, V33, P1502, DOI 10.1097/MAO.0b013e31826bec1e
   PHILLIPS DP, 1992, CEREB CORTEX, V2, P134, DOI 10.1093/cercor/2.2.134
   PHILLIPS DP, 1986, J ACOUST SOC AM, V80, P177, DOI 10.1121/1.394178
   PHILLIPS DP, 1985, HEARING RES, V19, P253, DOI 10.1016/0378-5955(85)90145-5
   PHILLIPS DP, 1990, BEHAV BRAIN RES, V37, P197, DOI 10.1016/0166-4328(90)90132-X
   Rance G, 1999, EAR HEARING, V20, P238, DOI 10.1097/00003446-199906000-00006
   Rance G, 2007, EAR HEARING, V28, P351, DOI 10.1097/AUD.0b013e3180479404
   Rance Gary, 2005, Trends Amplif, V9, P1, DOI 10.1177/108471380500900102
   Rance G, 2008, BRAIN, V131, P2002, DOI 10.1093/brain/awn104
   Roman S, 2004, NEUROREPORT, V15, P601, DOI 10.1097/00001756-200403220-00006
   Roush P, 2011, AM J AUDIOL, V20, P159, DOI 10.1044/1059-0889(2011/10-0032)
   Shallop Jon K., 2002, Seminars in Hearing, V23, P215, DOI 10.1055/s-2002-34474
   Sharma A, 2000, J ACOUST SOC AM, V108, P3030, DOI 10.1121/1.1320474
   Sharma A, 1999, J ACOUST SOC AM, V106, P1078, DOI 10.1121/1.428048
   Sharma A, 2000, J ACOUST SOC AM, V107, P2697, DOI 10.1121/1.428655
   SINEX DG, 1991, J ACOUST SOC AM, V90, P2441, DOI 10.1121/1.402048
   SINEX DG, 1989, J ACOUST SOC AM, V85, P1995, DOI 10.1121/1.397852
   SINEX DG, 1994, J ACOUST SOC AM, V95, P897, DOI 10.1121/1.408400
   STARR A, 1991, BRAIN, V114, P1157, DOI 10.1093/brain/114.3.1157
   Starr Arnold, 2015, Handb Clin Neurol, V129, P495, DOI 10.1016/B978-0-444-62630-1.00028-7
   Steinschneider M, 1999, J NEUROPHYSIOL, V82, P2346
   Steinschneider M, 2005, CEREB CORTEX, V15, P170, DOI 10.1093/cercor/bhh120
   Steinschneider M, 2003, J ACOUST SOC AM, V114, P307, DOI 10.1121/1.1582449
   Steinschneider M, 2013, HEARING RES, V305, P57, DOI 10.1016/j.heares.2013.05.013
   Stephens JDW, 2011, SPEECH COMMUN, V53, P877, DOI 10.1016/j.specom.2011.02.007
   STEVENS KN, 1974, J ACOUST SOC AM, V55, P653, DOI 10.1121/1.1914578
   Stiles DJ, 2012, J SPEECH LANG HEAR R, V55, P764, DOI 10.1044/1092-4388(2011/10-0264)
   Sullivan JR, 2015, J SPEECH LANG HEAR R, V58, P1043, DOI 10.1044/2015_JSLHR-H-14-0204
   Teagle HFB, 2010, EAR HEARING, V31, P325, DOI 10.1097/AUD.0b013e3181ce693b
   Tremblay KL, 2003, EAR HEARING, V24, P225, DOI 10.1097/01.AUD.0000069229.84883.03
   Vlastarakos PV, 2008, INT J PEDIATR OTORHI, V72, P1135, DOI 10.1016/j.ijporl.2008.04.004
   Whiting KA, 1998, EAR HEARING, V19, P218, DOI 10.1097/00003446-199806000-00005
   Zeng F. G., 2001, AUDITORY NEUROPATHY, P141
   Zeng FG, 2006, J SPEECH LANG HEAR R, V49, P367, DOI 10.1044/1092-4388(2006/029)
   Zeng FG, 2005, J NEUROPHYSIOL, V93, P3050, DOI 10.1152/jn.00985.2004
   Zeng FG, 1999, NEUROREPORT, V10, P3429, DOI 10.1097/00001756-199911080-00031
NR 74
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD MAY 25
PY 2020
VL 14
AR 184
DI 10.3389/fnhum.2020.00184
PG 16
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA LZ3LE
UT WOS:000541128900001
PM 32523521
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Meng, YX
   Zhang, J
   Liu, S
   Wu, CG
AF Meng, Yaxuan
   Zhang, Juan
   Liu, Shun
   Wu, Chenggang
TI Influence of different acoustic cues in L1 lexical tone on the
   perception of L2 lexical stress using principal component analysis: an
   ERP study
SO EXPERIMENTAL BRAIN RESEARCH
LA English
DT Article
DE Component analysis; MMN; Prosodic transfer; Phonetics
ID MISMATCH NEGATIVITY MMN; CANTONESE; SPEECH; ATTENTION; LEARNERS;
   LANGUAGE; MATRIX; MODEL
AB Previous studies have widely explored the prosodic transfer from L1 to L2 during speech perception across stress languages. However, few if any studies have investigated the transfer from L1 tonal language to L2 stress language and the relative roles of different acoustic cues underlying the transfer. Therefore, the current study was conducted to compare the perception of English lexical stress between Mandarin and Cantonese speakers who learn English as a foreign language. The event-related potential measurements and the principal component analysis were conducted for the two groups to explore the roles of different acoustic cues in the perception of English speech. The results demonstrated that compared with the Mandarin group, the Cantonese speakers relied more on pitch information and the reliance holds even when all the three cues varied simultaneously. Therefore, it was concluded that prosodic transfer from L1 lexical tone to L2 lexical stress occurred at the acoustic level, and the native linguistic background shaped the manner how speakers perceived the L2 speech.
C1 [Meng, Yaxuan; Zhang, Juan; Wu, Chenggang] Univ Macau, Fac Educ, Taipa, Macao, Peoples R China.
   [Meng, Yaxuan] Univ Oxford, Fac Linguist Philol & Phonet, Oxford, England.
   [Zhang, Juan; Wu, Chenggang] Univ Macau, Ctr Cognit & Brain Sci, Taipa, Macao, Peoples R China.
   [Liu, Shun] Univ Macau, Fac Sci & Technol, Taipa, Macao, Peoples R China.
RP Meng, YX (corresponding author), Univ Macau, Fac Educ, Taipa, Macao, Peoples R China.; Meng, YX (corresponding author), Univ Oxford, Fac Linguist Philol & Phonet, Oxford, England.
EM myaxuan112@gmail.com
RI Wu, Chenggang/J-2449-2019
OI Wu, Chenggang/0000-0003-3837-3841
FU University of Macau [MYRG2017-00217-FED, MYRG2016-00193-FED,
   MYRG2015-00221-FED]
FX This study was supported by research grants MYRG2017-00217-FED,
   MYRG2016-00193-FED, and MYRG2015-00221-FED from the University of Macau.
CR Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996
   Barachant A, 2013, NEUROCOMPUTING, V112, P172, DOI 10.1016/j.neucom.2012.12.039
   Chandrasekaran B, 2010, J ACOUST SOC AM, V128, P456, DOI 10.1121/1.3445785
   Congedo M, 2015, AIP CONF PROC, V1641, P495, DOI 10.1063/1.4906015
   Cutler A, 2001, LANG SPEECH, V44, P171, DOI 10.1177/00238309010440020301
   Dai Mengyu, 2019, ARXIV190405449
   Davenport Mike, 2013, INTRO PHONETICS PHON
   Dupoux E, 2008, COGNITION, V106, P682, DOI 10.1016/j.cognition.2007.04.001
   EADY SJ, 1982, LANG SPEECH, V25, P29, DOI 10.1177/002383098202500103
   El Karoui N, 2008, ANN STAT, V36, P2757, DOI 10.1214/07-AOS581
   Escera C, 2002, COGNITIVE BRAIN RES, V14, P325, DOI 10.1016/S0926-6410(02)00135-0
   Evans AC, 2013, NEUROIMAGE, V80, P489, DOI 10.1016/j.neuroimage.2013.05.054
   Francis AL, 2000, PERCEPT PSYCHOPHYS, V62, P1668, DOI 10.3758/BF03212164
   Friedrich CK, 2004, COGNITIVE BRAIN RES, V20, P300, DOI 10.1016/j.cogbrainres.2004.03.007
   FRY DB, 1958, LANG SPEECH, V1, P126, DOI 10.1177/002383095800100207
   Fu CL, 2008, NUCLEIC ACIDS RES, V36, DOI 10.1093/nar/gkn167
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   Gow DW, 2003, PERCEPT PSYCHOPHYS, V65, P575, DOI 10.3758/BF03194584
   Gu F, 2013, NEUROIMAGE, V83, P637, DOI 10.1016/j.neuroimage.2013.02.080
   Gut U., 2009, INTRO ENGLISH PHONET
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Huang YZ, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00368
   Khouw E, 2007, J PHONETICS, V35, P104, DOI 10.1016/j.wocn.2005.10.003
   Kim DH, 2005, PHYS REV E, V72, DOI 10.1103/PhysRevE.72.046133
   Laloux L, 1999, PHYS REV LETT, V83, P1467, DOI 10.1103/PhysRevLett.83.1467
   Lee YS, 1996, J PSYCHOLINGUIST RES, V25, P527, DOI 10.1007/BF01758181
   Lemhofer K, 2012, BEHAV RES METHODS, V44, P325, DOI 10.3758/s13428-011-0146-0
   Liu QY, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/5/056012
   Liu SY, 2004, LANG SPEECH, V47, P109, DOI 10.1177/00238309040470020101
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McQueen J., 2007, OXFORD HDB PSYCHOLIN, P37, DOI DOI 10.1093/0XF0RDHB/9780198568971.013.0003
   McQueen J. M, 2005, HDB COGNITION, P255, DOI DOI 10.4135/9781848608177.N11
   Moakher M, 2006, VISUALIZATION AND PROCESSING OF TENSOR FIELDS, P285, DOI 10.1007/3-540-31272-2_17
   Moakher M, 2005, SIAM J MATRIX ANAL A, V26, P735, DOI 10.1137/S0895479803436937
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 2004, CLIN NEUROPHYSIOL, V115, P140, DOI 10.1016/j.clinph.2003.04.001
   Nguyen TAT, 2008, J PHONETICS, V36, P158, DOI 10.1016/j.wocn.2007.09.001
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Pennec X, 2006, J MATH IMAGING VIS, V25, P127, DOI 10.1007/s10851-006-6228-4
   Plerou V, 1999, PHYS REV LETT, V83, P1471, DOI 10.1103/PhysRevLett.83.1471
   Rasier L, 2007, NOUVEAUX CAHIERS LIN, V28, P41
   Tong XH, 2014, BRAIN LANG, V138, P61, DOI 10.1016/j.bandl.2014.09.004
   Tsang YK, 2011, NEUROSCI LETT, V487, P268, DOI 10.1016/j.neulet.2010.10.035
   Ueyama M, 2000, PROSODIC TRANSFER AC
   Wang Q, 2008, SPEECH PROSODY 2008, V2008, P135
   WIGNER EP, 1955, PHYS REV, V98, P145, DOI 10.1103/PhysRev.98.145
   Yu VY, 2010, J PSYCHOLINGUIST RES, V39, P323, DOI 10.1007/s10936-009-9142-2
   Zhang J, 2018, EDUC PSYCHOL-UK, V38, P617, DOI 10.1080/01443410.2017.1380169
NR 48
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0014-4819
EI 1432-1106
J9 EXP BRAIN RES
JI Exp. Brain Res.
PD JUN
PY 2020
VL 238
IS 6
BP 1489
EP 1498
DI 10.1007/s00221-020-05823-w
EA MAY 2020
PG 10
WC Neurosciences
SC Neurosciences & Neurology
GA LX9WH
UT WOS:000534430000001
PM 32435921
DA 2021-02-24
ER

PT J
AU Toro-Campos, R
   Algarin, C
   Peirano, P
   Pena, M
   Murguia-Peniche, T
   Wu, SS
   Uauy, R
AF Toro-Campos, Rosario
   Algarin, Cecilia
   Peirano, Patricio
   Pena, Marcela
   Murguia-Peniche, Teresa
   Wu, Steven S.
   Uauy, Ricardo
TI Effect of feeding mode on infant growth and cognitive function: study
   protocol of the Chilean infant Nutrition randomized controlled Trial
   (ChiNuT)
SO BMC PEDIATRICS
LA English
DT Article
DE Infant formula; Milk fat globule membrane; MFGM; growth and development;
   Clinical trials; Breast feeding; Chile
ID FAT-GLOBULE-MEMBRANE; COMMUNICATIVE DEVELOPMENT INVENTORY; UNTIL 12 MO;
   BODY-COMPOSITION; ELECTROPHYSIOLOGICAL EVIDENCE; LANGUAGE-ACQUISITION;
   SPEECH-PERCEPTION; MILK; FORMULA; AGE
AB BackgroundA central aim for pediatric nutrition is to develop infant formula compositionally closer to human milk. Milk fat globule membranes (MFGM) have shown to have functional components that are found in human milk, suggesting that addition of bovine sources of MFGM (bMFGM) to infant formula may promote beneficial outcomes potentially helping to narrow the gap between infants who receive human breast milk or infant formula. The objective of the current study is to determine how the addition of bMFGM in infant formula and consumption in early infancy affects physical growth and brain development when compared to infants fed with a standard formula and a reference group of infants fed with mother's own milk.MethodsSingle center, double-blind, and parallel randomized controlled trial. Planned participant enrollment includes: infants exclusively receiving breast milk (n=200; human milk reference group; HM) and infants whose mothers chose to initiate exclusive infant formula feeding before 4months of age (n=340). The latter were randomized to receive one of two study formulas until 12months of age: 1) cow's milk based infant formula that had docosahexaenoic (DHA) (17mg/100kcal) and arachidonic acid (ARA) (25mg/100kcal); 1.9g protein/100kcal; 1.2mg Fe/100kcal (Standard formula; SF) or 2) a similar infant formula with an added source of bovine MFGM (whey protein-lipid concentrate (Experimental formula; EF). Primary outcomes will be: 1) Physical growth (Body weight, length, and head circumference) at 730days of age; and 2) Cognitive development (Auditory Event-Related Potential) at 730days of age. Data will be analyzed for all participants allocated to each study feeding group.DiscussionThe results of this study will complement the knowledge regarding addition of bMFGM in infant formula including support of healthy growth and improvement of neurodevelopmental outcomes.Trial registrationNCT02626143, registered on December 10th 2015.
C1 [Toro-Campos, Rosario; Algarin, Cecilia; Peirano, Patricio; Uauy, Ricardo] Univ Chile, Inst Nutr & Food Technol INTA, Av El Libano 5524, Santiago, Chile.
   [Pena, Marcela] Pontific Catholic Univ, Psychol Dept, Santiago, Chile.
   [Murguia-Peniche, Teresa; Wu, Steven S.] Mead Johnson Nutr, Med Affairs, Evansville, IN USA.
RP Toro-Campos, R (corresponding author), Univ Chile, Inst Nutr & Food Technol INTA, Av El Libano 5524, Santiago, Chile.
EM rosario.toro@inta.uchile.cl
FU Mead Johnson Nutrition Company, LLC; Mead Johnson Nutrition
FX This work was supported by the study sponsor, Mead Johnson Nutrition &
   Company, LLC. Mead Johnson Nutrition developed and provided all study
   formulas, however was not involved in any other stage of the project
   (i.e. study design, data collection, data analysis or interpretation of
   the results), except for the review of the final manuscript. Grant that
   requires acknowledgement: the project was funded by Mead Johnson
   Nutrition.
CR Albers CA, 2007, J PSYCHOEDUC ASSESS, V25, P180, DOI 10.1177/0734282906297199
   [Anonymous], 2011, GUIA PRACT CLIN TRAS
   [Anonymous], 2003, REP SCI COMM FOOD RE
   Baker SS, 1999, PEDIATRICS, V104, P119
   Ben-Shlomo Y, 2002, INT J EPIDEMIOL, V31, P285, DOI 10.1093/ije/31.2.285
   Billeaud C, 2014, CLIN MED INSIGHTS-PE, V8, P51, DOI 10.4137/CMPed.S16962
   Binns C, 2016, ASIA-PAC J PUBLIC HE, V28, P7, DOI 10.1177/1010539515624964
   Bode MM, 2014, J DEV BEHAV PEDIATR, V35, P570, DOI 10.1097/DBP.0000000000000110
   Brenna JT, 2007, AM J CLIN NUTR, V85, P1457
   Choudhury N, 2011, CLIN NEUROPHYSIOL, V122, P320, DOI 10.1016/j.clinph.2010.05.035
   Christophe A, 2001, INFANCY, V2, P385, DOI 10.1207/S15327078IN0203_6
   CONRADIE JD, 1980, S AFR MED J, V57, P282
   Corvalan C, 2014, ESTUDIO EVALUACION I
   de Onis M, 2009, ARCH PEDIATRIE, V16, P47, DOI 10.1016/j.arcped.2008.10.010
   Dehaene-Lambertz G, 2001, NEUROREPORT, V12, P3155, DOI 10.1097/00001756-200110080-00034
   Department of Statistics and Health Information (DEIS), 2016, NAC INSCR 2 ED MADR
   Devakumar D, 2015, PEERJ, V3, DOI 10.7717/peerj.785
   Ellis KJ, 2007, AM J CLIN NUTR, V85, P90
   Farkas C, 2007, 1060778 FONDECYT
   Farkas C, 2011, UNIV PSYCHOL, V10, P245
   FOMON SJ, 1982, AM J CLIN NUTR, V35, P1169, DOI 10.1093/ajcn/35.5.1169
   Gervain J, 2010, ANNU REV PSYCHOL, V61, P191, DOI 10.1146/annurev.psych.093008.100408
   Gervain Judit, 2008, Proc Natl Acad Sci U S A, V105, P14222, DOI 10.1073/pnas.0806530105
   Heilmann J, 2005, AM J SPEECH-LANG PAT, V14, P40, DOI 10.1044/1058-0360(2005/006)
   Iniguez G, 2006, J CLIN ENDOCR METAB, V91, P4645, DOI 10.1210/jc.2006-0844
   Insana SP, 2010, SLEEP MED, V11, P191, DOI 10.1016/j.sleep.2009.08.010
   Kabdebon C, 2015, BRAIN LANG, V148, P25, DOI 10.1016/j.bandl.2015.03.005
   Kain J, 2009, OBESITY, V17, P1603, DOI 10.1038/oby.2009.37
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Liu HN, 2014, J NUTR, V144, P1903, DOI 10.3945/jn.114.199828
   Martin CR, 2016, NUTRIENTS, V8, DOI 10.3390/nu8050279
   Meltzer LJ, 2012, SLEEP, V35, P159, DOI 10.5665/sleep.1608
   Ministry of Health, 2016, VIG EST NUTR POBL BA
   Oshida K, 2003, PEDIATR RES, V53, P589, DOI 10.1203/01.PDR.0000054654.73826.AC
   Palmano K, 2015, NUTRIENTS, V7, P3891, DOI 10.3390/nu7053891
   Pena M, 2012, J NEUROSCI, V32, P11159, DOI 10.1523/JNEUROSCI.6516-11.2012
   Quinn PC, 2010, DEVELOPMENTAL SCI, V13, P499, DOI 10.1111/j.1467-7687.2009.00903.x
   Raiten DJ, 1998, ASSESSMENT NUTR REQU, P2116
   Riva V, 2018, CEREB CORTEX, V28, P2100, DOI 10.1093/cercor/bhx115
   Rosqvist F, 2015, AM J CLIN NUTR, V102, P20, DOI 10.3945/ajcn.115.107045
   Sadeh A, 2004, PEDIATRICS, V113, pE570, DOI 10.1542/peds.113.6.e570
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   So K, 2007, J SLEEP RES, V16, P181, DOI 10.1111/j.1365-2869.2007.00582.x
   Tam N, 2011, CLIN J SPORT MED, V21, P218, DOI 10.1097/JSM.0b013e31820eb8d7
   Ten Bruggencate SJ, 2016, J NUTR, V146, P249, DOI 10.3945/jn.115.214098
   Timby N, 2017, ADV NUTR, V8, P351, DOI 10.3945/an.116.014142
   Timby N, 2015, J PEDIATR GASTR NUTR, V60, P384, DOI 10.1097/MPG.0000000000000624
   Timby N, 2014, PEDIATR RES, V76, P394, DOI 10.1038/pr.2014.110
   Timby N, 2014, AM J CLIN NUTR, V99, P860, DOI 10.3945/ajcn.113.064295
   Uauy R, 2008, ANN MED, V40, P11, DOI 10.1080/07853890701704683
   Uauy R, 2011, AM J CLIN NUTR, V94, p1759S, DOI 10.3945/ajcn.110.000562
   Urlando A, 2003, PEDIATR RES, V53, P486, DOI 10.1203/01.PDR.0000049669.74793.E3
   Wang B, 2007, AM J CLIN NUTR, V85, P561
   WERKER JF, 1988, DEV PSYCHOL, V24, P672, DOI 10.1037/0012-1649.24.5.672
   Werker JF, 1998, DEV PSYCHOL, V34, P1289, DOI 10.1037/0012-1649.34.6.1289
   WHO (World Health Organisation), 2001, REP EXP CONS OPT DUR
   World Health Organization, 2017, TRACK PROGR BREASTF
   World Health Organization/UNICEF, 2003, GLOB STRAT INF YOUNG
   World Health Organization (WHO), 2011, CHILD GROWTH STAND
   World Health Organization (WHO); United Nations Children's Fund (UNICEF), 2009, WHO CHILD GROWTH STA
NR 61
TC 0
Z9 0
U1 0
U2 0
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
EI 1471-2431
J9 BMC PEDIATR
JI BMC Pediatr.
PD MAY 18
PY 2020
VL 20
IS 1
DI 10.1186/s12887-020-02087-9
PG 11
WC Pediatrics
SC Pediatrics
GA LT0JY
UT WOS:000536764500002
PM 32423392
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Drozdzowicz, A
AF Drozdzowicz, Anna
TI Bringing back the voice: on the auditory objects of speech perception
SO SYNTHESE
LA English
DT Article; Early Access
DE Speech perception; Voice perception; Auditory objects
ID CORTICAL REPRESENTATION; HEARING; TALKER; RECOGNITION; INFORMATION;
   ORGANIZATION; EVOLUTION; SPEAKER
AB When you hear a person speaking in a familiar language you perceive the speech sounds uttered and the voice that produces them. How are speech sounds and voice related in a typical auditory experience of hearing speech in a particular voice? And how to conceive of the objects of such experiences? I propose a conception of auditory objects of speech perception as temporally structured mereologically complex individuals. A common experience is that speech sounds and the voice that produces them appear united. I argue that the metaphysical underpinnings of the experienced unity of speech sounds and voices can be explained in terms of the mereological view on sounds and their sources. I also propose a psychological explanation (the Voice Shaping Speech model) of how we form and individuate the auditory objects of experiences of listening to speech in a particular voice. Voice characteristics enable determining the identity of auditory objects of speech sound perception by making some features of the speech signal stable and predictable.
C1 [Drozdzowicz, Anna] Univ Oslo, Dept Philosophy Class Hist Arts & Ideas, POB 1020, N-0315 Oslo, Norway.
   [Drozdzowicz, Anna] Inst Philosophy, Sch Adv Studies, London, England.
RP Drozdzowicz, A (corresponding author), Univ Oslo, Dept Philosophy Class Hist Arts & Ideas, POB 1020, N-0315 Oslo, Norway.; Drozdzowicz, A (corresponding author), Inst Philosophy, Sch Adv Studies, London, England.
EM anna.drozdzowicz@gmail.com
FU Mobility Grant Fellowship Programme (FRICON) - Research Council of
   Norway; Marie Sklodowska-Curie Actions [275251]
FX This work was supported by and developed as part of the Mobility Grant
   Fellowship Programme (FRICON) funded by The Research Council of Norway
   and the Marie Sklodowska-Curie Actions (Project Number: 275251).
CR Adank P, 2009, J ACOUST SOC AM, V126, P2649, DOI 10.1121/1.3216914
   ASSAL G, 1981, BRAIN LANG, V13, P223, DOI 10.1016/0093-934X(81)90092-4
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   Baumann O, 2010, PSYCHOL RES-PSYCH FO, V74, P110, DOI 10.1007/s00426-008-0185-z
   Bayne T, 2009, PHILOS QUART, V59, P385, DOI 10.1111/j.1467-9213.2009.631.x
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Bendixen A, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00060
   Bizley JK, 2013, NAT REV NEUROSCI, V14, P693, DOI 10.1038/nrn3565
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   Brogaard B, 2018, SYNTHESE, V195, P2967, DOI 10.1007/s11229-016-1178-x
   Burton R. L, 2015, ASME 20 NATL C P
   Campanella S, 2007, TRENDS COGN SCI, V11, P535, DOI 10.1016/j.tics.2007.10.001
   Cutler A., 2010, LAB PHONOLOGY, V10, P91
   de Cheveigne A, 2005, SPR HDB AUD, V24, P169
   Di Bona E, 2017, PHILOS STUD, V174, P2629, DOI 10.1007/s11098-016-0802-4
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Drozdzowicz A., 2019, INQUIRY, P1, DOI [10.1080/0020174X.2019.1612774, DOI 10.1080/0020174X.2019.1612774]
   Elhilali M, 2009, NEURON, V61, P317, DOI 10.1016/j.neuron.2008.12.005
   Fitch WT, 2000, TRENDS COGN SCI, V4, P258, DOI 10.1016/S1364-6613(00)01494-7
   Fowler CA, 2003, J MEM LANG, V49, P396, DOI 10.1016/S0749-596X(03)00072-X
   FOWLER CA, 1984, PERCEPT PSYCHOPHYS, V36, P359, DOI 10.3758/BF03202790
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Ghazanfar AA, 2008, CURR BIOL, V18, pR457, DOI 10.1016/j.cub.2008.03.030
   Gick B, 2009, NATURE, V462, P502, DOI 10.1038/nature08572
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Griffiths TD, 2004, NAT REV NEUROSCI, V5, P887, DOI 10.1038/nrn1538
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Holt LL, 2008, CURR DIR PSYCHOL SCI, V17, P42, DOI 10.1111/j.1467-8721.2008.00545.x
   Hosoda M, 2010, J MANAGE PSYCHOL, V25, P113, DOI 10.1108/02683941011019339
   Kaganovich N, 2006, BRAIN RES, V1114, P161, DOI 10.1016/j.brainres.2006.07.049
   Kent RD, 1977, JORNAL PHONETICS, V5, P15
   Kiebel SJ, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000209
   Kreitewolf J, 2014, NEUROIMAGE, V91, P375, DOI 10.1016/j.neuroimage.2014.01.005
   Kriegstein KV, 2004, NEUROIMAGE, V22, P948, DOI 10.1016/j.neuroimage.2004.02.020
   Kulvicki J., 2008, PHILOS IMPRINT, V8, P1
   Kulvicki J., 2014, PERCEPTION ITS MODAL, P205
   Laing EJC, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00203
   Latinus M, 2011, CURR BIOL, V21, pR143, DOI 10.1016/j.cub.2010.12.033
   Lavner Y, 2000, SPEECH COMMUN, V30, P9, DOI 10.1016/S0167-6393(99)00028-X
   Leddington J, 2014, CONSCIOUSNESS INSIDE, P321
   Leddington JP, 2019, ANALYSIS-UK, V79, P621, DOI 10.1093/analys/any075
   Lev-Ari S, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01546
   Lev-Ari S, 2010, J EXP SOC PSYCHOL, V46, P1093, DOI 10.1016/j.jesp.2010.05.025
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Micheyl C, 2003, J COGNITIVE NEUROSCI, V15, P747, DOI 10.1162/089892903322307456
   Moore BCJ, 2008, JARO-J ASSOC RES OTO, V9, P399, DOI 10.1007/s10162-008-0143-x
   Mulac A, 1996, HEALTH COMMUN, V8, P199, DOI 10.1207/s15327027hc0803_2
   NEAREY TM, 1989, J ACOUST SOC AM, V85, P2088, DOI 10.1121/1.397861
   Neuner F, 2000, BRAIN COGNITION, V44, P342, DOI 10.1006/brcg.1999.1196
   Nudds M, 2010, REV PHILOS PSYCHOL, V1, P105, DOI 10.1007/s13164-009-0003-6
   NYGAARD LC, 1995, HDB PERCEPTION COGNI
   Nygaard LC, 2005, LINGUISTIC PARALINGU
   O'Callaghan C, 2015, HDB PHILOS PERCEPTIO, P475
   O'Callaghan C., 2017, VISION PHILOS ESSAYS
   O'Callaghan C, 2011, PHILOS QUART, V61, P783, DOI 10.1111/j.1467-9213.2011.704.x
   O'Callaghan C, 2008, PHILOS COMPASS, V3, P803, DOI 10.1111/j.1747-9991.2008.00145.x
   OCallaghan C., 2016, STANFORD ENCY PHILOS
   OCallaghan Casey, 2011, P ARISTOTELIAN SOC, P375, DOI [10.1111/j.1467-9264.2011.00315.x, DOI 10.1111/j.1467-9264.2011.00315.x]
   Overath T, 2007, PLOS BIOL, V5, P2723, DOI 10.1371/journal.pbio.0050288
   Owren MJ, 2007, PERCEPT PSYCHOPHYS, V69, P930, DOI 10.3758/BF03193930
   Pasnau R, 1999, PHILOS QUART, V49, P309, DOI 10.1111/1467-9213.00144
   Pisoni DB, 2005, BLACKW HBK LINGUIST, P1, DOI 10.1002/9780470757024
   Pisoni DB, 2007, OXFORD HDB PSYCHOLIN, P3
   Plack C.J., 2014, THE SENSE OF HEARING
   Plack Christopher J., 1995, P123, DOI 10.1016/B978-012505626-7/50006-6
   Rakic T, 2011, J PERS SOC PSYCHOL, V100, P16, DOI 10.1037/a0021522
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   Scharenborg O, 2007, SPEECH COMMUN, V49, P336, DOI 10.1016/j.specom.2007.01.009
   Schweinberger SR, 2014, WIRES COGN SCI, V5, P15, DOI 10.1002/wcs.1261
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Shinn-Cunningham BG, 2008, TRENDS COGN SCI, V12, P182, DOI 10.1016/j.tics.2008.02.003
   Siegel S, 2010, CONTENTS PERCEPTION
   Skrzypulec B, 2020, ERKENNTNIS, V85, P467, DOI 10.1007/s10670-018-0036-2
   Smith BC, 2009, SOUNDS NEW ESSAYS PE
   Spencer C, 1999, TELEGRAPH
   Stevens K. N., 1974, VENTILATORY PHONATOR
   Teufel C, 2010, TRENDS COGN SCI, V14, P376, DOI 10.1016/j.tics.2010.05.005
   von Kriegstein K, 2010, J NEUROSCI, V30, P629, DOI 10.1523/JNEUROSCI.2742-09.2010
   Winkler I, 2012, PHILOS T R SOC B, V367, P1001, DOI 10.1098/rstb.2011.0359
   Yeung HH, 2013, PSYCHOL SCI, V24, P603, DOI 10.1177/0956797612458802
   Young N, 2018, PHILOS STUD, V175, P2931, DOI 10.1007/s11098-017-0988-0
   Zhang CC, 2016, NEUROIMAGE, V124, P536, DOI 10.1016/j.neuroimage.2015.08.064
NR 87
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0039-7857
EI 1573-0964
J9 SYNTHESE
JI Synthese
DI 10.1007/s11229-020-02687-z
EA MAY 2020
PG 27
WC History & Philosophy Of Science; Philosophy
SC History & Philosophy of Science; Philosophy
GA LO7LE
UT WOS:000533808700003
OA Other Gold
DA 2021-02-24
ER

PT J
AU Mitchell, BL
   Cuellar-Partida, G
   Grasby, KL
   Campos, AI
   Strike, LT
   Hwang, LD
   Okbay, A
   Thompson, PM
   Medland, SE
   Martin, NG
   Wright, MJ
   Renteria, ME
AF Mitchell, Brittany L.
   Cuellar-Partida, Gabriel
   Grasby, Katrina L.
   Campos, Adrian, I
   Strike, Lachlan T.
   Hwang, Liang-Dar
   Okbay, Aysu
   Thompson, Paul M.
   Medland, Sarah E.
   Martin, Nicholas G.
   Wright, Margaret J.
   Renteria, Miguel E.
TI Educational attainment polygenic scores are associated with cortical
   total surface area and regions important for language and memory
SO NEUROIMAGE
LA English
DT Article
DE Educational attainment; Brain structure; Polygenic scores; Intelligence;
   Broca's area
ID HUMAN CEREBRAL-CORTEX; BRAIN VOLUME; BROCAS AREA; STRUCTURAL
   DIFFERENCES; GENETIC INFLUENCES; SPEECH-PERCEPTION; WORKING-MEMORY;
   INTELLIGENCE; IQ; THICKNESS
AB It is well established that higher cognitive ability is associated with larger brain size. However, individual variation in intelligence exists despite brain size and recent studies have shown that a simple unifactorial view of the neurobiology underpinning cognitive ability is probably unrealistic. Educational attainment (EA) is often used as a proxy for cognitive ability since it is easily measured, resulting in large sample sizes and, consequently, sufficient statistical power to detect small associations. This study investigates the association between three global (total surface area (TSA), intra-cranial volume (ICV) and average cortical thickness) and 34 regional cortical measures with educational attainment using a polygenic scoring (PGS) approach. Analyses were conducted on two independent target samples of young twin adults with neuroimaging data, from Australia (N = 1097) and the USA (N = 723), and found that higher EA-PGS were significantly associated with larger global brain size measures, ICV and TSA (R-2 = 0.006 and 0.016 respectively, p < 0.001) but not average thickness. At the regional level, we identified seven cortical regions-in the frontal and temporal lobes-that showed variation in surface area and average cortical thickness over-and-above the global effect. These regions have been robustly implicated in language, memory, visual recognition and cognitive processing. Additionally, we demonstrate that these identified brain regions partly mediate the association between EA-PGS and cognitive test performance. Altogether, these findings advance our understanding of the neurobiology that underpins educational attainment and cognitive ability, providing focus points for future research.
C1 [Mitchell, Brittany L.; Grasby, Katrina L.; Campos, Adrian, I; Medland, Sarah E.; Martin, Nicholas G.; Renteria, Miguel E.] QIMR Berghofer Med Res Inst, Dept Genet & Computat Biol, Brisbane, Qld, Australia.
   [Mitchell, Brittany L.; Martin, Nicholas G.; Renteria, Miguel E.] Queensland Univ Technol, Sch Biomed Sci, Inst Hlth & Biomed Innovat, Brisbane, Qld, Australia.
   [Cuellar-Partida, Gabriel; Hwang, Liang-Dar] Univ Queensland, Diamantina Inst, Brisbane, Qld, Australia.
   [Strike, Lachlan T.; Wright, Margaret J.] Univ Queensland, Queensland Brain Inst, Brisbane, Qld, Australia.
   [Campos, Adrian, I] Univ Queensland, Fac Med, Brisbane, Qld, Australia.
   [Okbay, Aysu] Vrije Univ Amsterdam, Sch Business & Econ, Dept Econ, Amsterdam, Netherlands.
   [Thompson, Paul M.] Univ Southern Calif, Keck Sch Med, Imaging Genet Ctr, Mark & Mary Stevens Inst Neuroimaging & Informat, Los Angeles, CA 90007 USA.
   [Wright, Margaret J.] Univ Queensland, Ctr Adv Imaging, Brisbane, Qld, Australia.
RP Mitchell, BL (corresponding author), QIMR Berghofer Med Res Inst, Dept Genet & Computat Biol, Brisbane, Qld, Australia.
EM Brittany.mitchell@qimrberghofer.edu.au
RI Wright, Margaret Jane/A-4560-2016; Medland, Sarah/AAT-7595-2020; Strike,
   Lachlan T/R-3902-2018; Renteria, Miguel E./M-6671-2017; Grasby,
   Katrina/M-7536-2016
OI Wright, Margaret Jane/0000-0001-7133-4970; Medland,
   Sarah/0000-0003-1382-380X; Strike, Lachlan T/0000-0003-2885-5898;
   Renteria, Miguel E./0000-0003-4626-7248; Grasby,
   Katrina/0000-0001-8539-0228
FU Queensland University of Technology through a QUT Postgraduate Research
   Scholarship; Australian National Health & Medical Research Council
   (NHMRC) through a NHMRC-ARC Dementia Research Development
   FellowshipNational Health and Medical Research Council of Australia
   [GNT1102821]; Australian Research Council (ARC), through a NHMRC-ARC
   Dementia Research Development FellowshipAustralian Research Council
   [GNT1102821]; NIHUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [U54 EB020403];
   National Institute of Child Health and Human DevelopmentUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH Eunice Kennedy Shriver National Institute of Child Health &
   Human Development (NICHD) [R01 HD050735]; Australian National Health and
   Medical Research CouncilNational Health and Medical Research Council of
   Australia [NHMRC 486682, 1009064]; 16 NIH Institutes and CentresUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USA [1U54MH091657]
FX BLM is grateful for support from Queensland University of Technology
   through a QUT Postgraduate Research Scholarship. MER thanks the support
   of the Australian National Health & Medical Research Council (NHMRC) and
   the Australian Research Council (ARC), through a NHMRC-ARC Dementia
   Research Development Fellowship (GNT1102821). PMT was supported in part
   by NIH grant U54 EB020403.; We are very grateful to the twins for their
   generosity of time and willingness to participate in these studies and
   thank the many research assistants and support staff who helped with
   data collection and processing. The QTIM study was supported by the
   National Institute of Child Health and Human Development (R01 HD050735),
   and the Australian National Health and Medical Research Council (NHMRC
   486682, 1009064).; Data were provided [in part] by the Human Connectome
   Project, WUMinn Consortium (Principal Investigators: David Van Essen and
   Kamil Ugurbil; 1U54MH091657) funded by the 16 NIH Institutes and Centres
   that support the NIH Blueprint for Neuroscience Research; and by the
   McDonnell Center for Systems Neuroscience at Washington University.
CR Abegaz F, 2019, BRIEF BIOINFORM, V20, P2200, DOI 10.1093/bib/bby081
   Aydogan G., 2012, BIORXIV
   Balsamo LM, 2006, NEUROIMAGE, V31, P1306, DOI 10.1016/j.neuroimage.2006.01.027
   Basten U, 2015, INTELLIGENCE, V51, P10, DOI 10.1016/j.intell.2015.04.009
   Belsky DW, 2018, P NATL ACAD SCI USA, V115, pE7275, DOI 10.1073/pnas.1801238115
   Belsky DW, 2016, PSYCHOL SCI, V27, P957, DOI 10.1177/0956797616643070
   Belyk M, 2017, NEUROIMAGE, V156, P240, DOI 10.1016/j.neuroimage.2017.04.020
   Blokland GAM, 2014, NEUROIMAGE, V86, P392, DOI 10.1016/j.neuroimage.2013.10.006
   Brinch CN, 2012, P NATL ACAD SCI USA, V109, P425, DOI 10.1073/pnas.1106077109
   Brouwer RM, 2014, HUM BRAIN MAPP, V35, P3760, DOI 10.1002/hbm.22435
   Cesarini D, 2017, NPJ SCI LEARN, V2, DOI 10.1038/s41539-017-0005-6
   Chiang MC, 2009, J NEUROSCI, V29, P2212, DOI 10.1523/JNEUROSCI.4184-08.2009
   Colodro-Conde L, 2018, MOL PSYCHIATR, V23, P1590, DOI 10.1038/mp.2017.130
   Cox SR, 2019, INTELLIGENCE, V76, DOI 10.1016/j.intell.2019.101376
   Cox SR, 2018, BRAIN STRUCT FUNCT, V223, P509, DOI 10.1007/s00429-017-1505-0
   Deary IJ, 2007, INTELLIGENCE, V35, P451, DOI 10.1016/j.intell.2006.09.003
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Diemer MA, 2013, ANAL SOC ISS PUB POL, V13, P77, DOI 10.1111/asap.12001
   Dubois J, 2018, PHILOS T R SOC B, V373, DOI 10.1098/rstb.2017.0284
   Elliott M.L., 2018, CEREBR CORTEX
   Fischl B, 1999, HUM BRAIN MAPP, V8, P272, DOI 10.1002/(SICI)1097-0193(1999)8:4<272::AID-HBM10>3.0.CO;2-4
   Fischl B, 2000, P NATL ACAD SCI USA, V97, P11050, DOI 10.1073/pnas.200033797
   Fjell AM, 2016, CEREB CORTEX, V26, P1272, DOI 10.1093/cercor/bhv102
   Flinker A, 2015, P NATL ACAD SCI USA, V112, P2871, DOI 10.1073/pnas.1414491112
   Foley SF, 2017, BIOL PSYCHIAT, V81, P154, DOI 10.1016/j.biopsych.2016.02.033
   Frangou S, 2004, NEUROIMAGE, V23, P800, DOI 10.1016/j.neuroimage.2004.05.027
   French L, 2015, JAMA PSYCHIAT, V72, P1002, DOI 10.1001/jamapsychiatry.2015.1131
   Ge T., 2018, CEREB CORTEX
   Glascher J, 2010, P NATL ACAD SCI USA, V107, P4705, DOI 10.1073/pnas.0910397107
   Glasser MF, 2013, NEUROIMAGE, V80, P105, DOI 10.1016/j.neuroimage.2013.04.127
   Grasby K.L., 2020, SCIENCE
   Hayes A.F., 2013, INTRO MEDIATION MODE
   Hayes AF, 2013, PSYCHOL SCI, V24, P1918, DOI 10.1177/0956797613480187
   Hein G, 2008, J COGNITIVE NEUROSCI, V20, P2125, DOI 10.1162/jocn.2008.20148
   Imada T, 2006, NEUROREPORT, V17, P957, DOI 10.1097/01.wnr.0000223387.51704.89
   Jackson DN., 1998, MULTIDIMENSIONAL APT
   Jansen P.R., 2019, 613489 BIORXIV
   Jha SC, 2019, CEREB CORTEX, V29, P1139, DOI 10.1093/cercor/bhy020
   Jung RE, 2007, BEHAV BRAIN SCI, V30, P135, DOI 10.1017/S0140525X07001185
   Kanwisher N, 2006, PHILOS T R SOC B, V361, P2109, DOI 10.1098/rstb.2006.1934
   KAUFMAN AS, 1976, J CONSULT CLIN PSYCH, V44, P739, DOI 10.1037/0022-006X.44.5.739
   Knol MJ, 2019, AGING-US, V11, P1440, DOI 10.18632/aging.101844
   Koenis MMG, 2018, HUM BRAIN MAPP, V39, P822, DOI 10.1002/hbm.23885
   Krapohl E, 2016, MOL PSYCHIATR, V21, P437, DOI 10.1038/mp.2015.2
   Lee JJ, 2018, NAT GENET, V50, P1112, DOI 10.1038/s41588-018-0147-3
   Lemery-Chalfant K, 2013, DEV PSYCHOPATHOL, V25, P51, DOI 10.1017/S0954579412000892
   Lenroot RK, 2009, HUM BRAIN MAPP, V30, P163, DOI 10.1002/hbm.20494
   Liu HX, 2019, SOC SCI RES, V82, P137, DOI 10.1016/j.ssresearch.2019.04.008
   MacLullich AMJ, 2002, NEUROLOGY, V59, P169, DOI 10.1212/WNL.59.2.169
   Matloff W.J., 2019, ALCOHOL
   McCandliss BD, 2003, TRENDS COGN SCI, V7, P293, DOI 10.1016/S1364-6613(03)00134-7
   McDaniel MA, 2005, INTELLIGENCE, V33, P337, DOI 10.1016/j.intell.2004.11.005
   McMillan J, 2009, J SOCIOL, V45, P123, DOI 10.1177/1440783309103342
   Mei LL, 2015, NEUROIMAGE, V110, P3, DOI 10.1016/j.neuroimage.2015.01.030
   Musso M, 2003, NAT NEUROSCI, V6, P774, DOI 10.1038/nn1077
   Nave G, 2019, PSYCHOL SCI, V30, P43, DOI 10.1177/0956797618808470
   Neubauer AC, 2009, NEUROSCI BIOBEHAV R, V33, P1004, DOI 10.1016/j.neubiorev.2009.04.001
   Noble KG, 2015, NAT NEUROSCI, V18, P773, DOI 10.1038/nn.3983
   Nyholt D., 2004, MATRIX SPECTRAL DECO
   Panizzon MS, 2009, CEREB CORTEX, V19, P2728, DOI 10.1093/cercor/bhp026
   Pietschnig J, 2015, NEUROSCI BIOBEHAV R, V57, P411, DOI 10.1016/j.neubiorev.2015.09.017
   Plomin R, 2018, NAT REV GENET, V19, P148, DOI 10.1038/nrg.2017.104
   Posthuma D, 2002, NAT NEUROSCI, V5, P83, DOI 10.1038/nn0202-83
   Price AL, 2006, NAT GENET, V38, P904, DOI 10.1038/ng1847
   Price AL, 2010, NAT REV GENET, V11, P459, DOI 10.1038/nrg2813
   Protzko J, 2016, INTELLIGENCE, V56, P65, DOI 10.1016/j.intell.2016.02.008
   Purcell S, 2007, AM J HUM GENET, V81, P559, DOI 10.1086/519795
   Reiss AL, 1996, BRAIN, V119, P1763, DOI 10.1093/brain/119.5.1763
   Rietveld CA, 2014, P NATL ACAD SCI USA, V111, P13790, DOI 10.1073/pnas.1404623111
   Rimol LM, 2010, BIOL PSYCHIAT, V67, P493, DOI 10.1016/j.biopsych.2009.09.032
   Ritchie SJ, 2018, NEUROBIOL AGING, V62, P146, DOI 10.1016/j.neurobiolaging.2017.10.005
   Rushton JP, 2009, INT J NEUROSCI, V119, P691, DOI 10.1080/00207450802325843
   Sabb FW, 2007, NEUROIMAGE, V37, P311, DOI 10.1016/j.neuroimage.2007.04.050
   Santarnecchi E, 2016, SPAN J PSYCHOL, V19, DOI 10.1017/sjp.2016.89
   Santarnecchi E, 2014, HUM BRAIN MAPP, V35, P4566, DOI 10.1002/hbm.22495
   Savage JE, 2018, NAT GENET, V50, P912, DOI 10.1038/s41588-018-0152-6
   Schmitt J.E., 1991, DYNAMIC ASS CORTICAL
   Schnack HG, 2015, CEREB CORTEX, V25, P1608, DOI 10.1093/cercor/bht357
   Shaw P, 2006, NATURE, V440, P676, DOI 10.1038/nature04513
   Sobel M.E., 1982, SOCIOL METHODOL, V13, P290, DOI [10.2307/270723, DOI 10.2307/270723]
   Somerville LH, 2018, NEUROIMAGE, V183, P456, DOI 10.1016/j.neuroimage.2018.08.050
   Strike LT, 2019, CEREB CORTEX, V29, P952, DOI 10.1093/cercor/bhy002
   Sugrue LP, 2019, JAMA-J AM MED ASSOC, V321, P1820, DOI 10.1001/jama.2019.3893
   Tan LH, 2011, P NATL ACAD SCI USA, V108, P2540, DOI 10.1073/pnas.0909623108
   Thompson PM, 2014, BRAIN IMAGING BEHAV, V8, P153, DOI 10.1007/s11682-013-9269-5
   Thompson PM, 2001, NAT NEUROSCI, V4, P1253, DOI 10.1038/nn758
   van den Heuvel MP, 2009, J NEUROSCI, V29, P7619, DOI 10.1523/JNEUROSCI.1443-09.2009
   Van Essen DC, 2012, NEUROIMAGE, V62, P2222, DOI 10.1016/j.neuroimage.2012.02.018
   Van Essen DC, 2013, NEUROIMAGE, V80, P62, DOI 10.1016/j.neuroimage.2013.05.041
   Vuoksimaa E, 2018, BRAIN STRUCT FUNCT, V223, P3487, DOI 10.1007/s00429-018-1675-4
   Vuoksimaa E, 2016, NEUROIMAGE, V129, P356, DOI 10.1016/j.neuroimage.2016.01.049
   Vuoksimaa E, 2015, CEREB CORTEX, V25, P2127, DOI 10.1093/cercor/bhu018
   Walhovd KB, 2016, P NATL ACAD SCI USA, V113, P9357, DOI 10.1073/pnas.1524259113
   Wang LQ, 2011, NEUROSCI LETT, V488, P275, DOI 10.1016/j.neulet.2010.11.046
   Watkins K, 2004, J COGNITIVE NEUROSCI, V16, P978, DOI 10.1162/0898929041502616
   Weintraub S, 2014, J INT NEUROPSYCH SOC, V20, P567, DOI 10.1017/S1355617714000320
   Wen W., 2016, SCI REP, V6, P45
   Wilke M, 2003, NEUROIMAGE, V20, P202, DOI 10.1016/S1053-8119(03)00199-X
   WILLERMAN L, 1991, INTELLIGENCE, V15, P223, DOI 10.1016/0160-2896(91)90031-8
   Winkler AM, 2010, NEUROIMAGE, V53, P1135, DOI 10.1016/j.neuroimage.2009.12.028
   Wright MJ, 2004, AUST J PSYCHOL, V56, P65, DOI 10.1080/00049530410001734865
   Yang J, 2014, NAT GENET, V46, P100, DOI 10.1038/ng.2876
   Yang JA, 2011, AM J HUM GENET, V88, P76, DOI 10.1016/j.ajhg.2010.11.011
NR 103
TC 0
Z9 0
U1 3
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD MAY 15
PY 2020
VL 212
AR 116691
DI 10.1016/j.neuroimage.2020.116691
PG 13
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA LC4UF
UT WOS:000525320500007
PM 32126298
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Alves, UK
   Brisolara, LB
AF Alves, Ubirata Kickhofel
   Brisolara, Luciene Bassols
TI Listening to accented speech in Brazilian Portuguese: On the role of
   fricative voicing and vowel duration in the identification of /s/ - /z/
   minimal pairs produced by speakers of L1 Spanish
SO JOURNAL OF PORTUGUESE LINGUISTICS
LA English
DT Article
DE Laboratory Phonology; Brazilian Portuguese; speech perception; L2 speech
   intelligibility; acoustic-articulatory gestures
ID PERCEPTION
AB This article reports the results of two experiments investigating the combined role of vowel length and length of fricative voicing in the identification, by Brazilians, of minimal pairs such as casa /z/ - caca /s/ produced by speakers of Spanish (L1). In Experiment 1, stimuli were manipulated so that length of voicing in the fricative was tested in two levels (100% or 0% of voicing) and vowel length was tested in four levels (25%, 50%, 75% and 100% of the length of the total vowel). In Experiment 2, voicing length was tested in three levels (25%, 50% and 75% of voicing), combined with the four levels of vowel length (25%, 50%, 75% and 100% of the length of the total vowel). Both experiments were run on TP Software (Rauber et al. 2012), and forty Brazilian listeners with no experience with Spanish took part in both tasks. The results show an interaction between the two cues, especially in the stimuli with no full voicing in the fricative. These findings provide additional evidence to the gradient status of speech in production and perceptual phenomena (Albano 2001; Albano 2012; Perozzo 2017), besides shedding light on the teaching of Brazilian Portuguese as an Additional Language.
C1 [Alves, Ubirata Kickhofel] Univ Fed Rio Grande do Sul, Porto Alegre, RS, Brazil.
   [Brisolara, Luciene Bassols] Univ Fed Rio Grande, Porto Alegre, RS, Brazil.
RP Alves, UK (corresponding author), Univ Fed Rio Grande do Sul, Porto Alegre, RS, Brazil.
EM ukalves@gmail.com
CR Akerberg M. A., 2004, PORTUGUES FALANTES E, P115
   ALARCOS LLORACH Emilio, 1965, FONOLOGIA ESPANOLA
   Albano E., 2017, FONOLOGIA FONOLOGIAS, P169
   Albano E. C., 2012, REV ABRALIN ASS BRAS, V11, P1, DOI 10.5380/rabl.v11i1.32462
   Albano E. C., 2001, GESTO SUAS BORDAS ES
   ALBUQUERQUE J. I. A., 2019, THESIS
   Almeida A., 2013, FONETICA COM MUSICA
   Alves U. K., 2018, REV LETRAS, V37, P58
   Alves U. K., 2018, DIACRITICA, V32, P437, DOI [10.21814/diacritica.449, DOI 10.21814/DIACRITICA.449]
   Alves U. K., 2017, CURTINDO SONS BRASIL
   Alves U. K., 2018, CONCEITO DUAS LINGUA, P117
   Alves U. K., 2015, RETRATO PORTUGUES CO, P75
   Alves U. K., 2016, REV GEL, V13, P107, DOI [10.21165/gel.v13i1.837, DOI 10.21165/GEL.V13I1.837]
   Alves U. K., 2015, VERSALETE, V3, P374
   Antoniou M., 2018, LISTENING BILINGUAL, P43, DOI [10.1002/9781118835722.ch3, DOI 10.1002/9781118835722.CH3]
   Berti L., 2012, REV DA ABRALIN, V11, P139, DOI [10.5380/rabl.v11i1.32465, DOI 10.5380/RABL.V11I1.32465]
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Browman Catherine, 1986, PHONOLOGY YB, V3, P219, DOI DOI 10.1017/S0952675700000658
   BROWMAN CP, 1992, PHONETICA, V49, P155, DOI 10.1159/000261913
   CHEN M, 1970, PHONETICA, V22, P129, DOI 10.1159/000259312
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Cristofaro-Silva T., 2017, FONETICA FONOLOGIA P
   Cuetara Priede J., 2004, THESIS
   Derwing T., 2015, FONETICA FONOLOGIA A, P14
   Derwing T.M., 2015, PRONUNCIATION FUNDAM, DOI [10.1075/lllt.42, DOI 10.1075/LLLT.42]
   Ernestus M., 2006, LAB PHONOLOGY, V8, P27, DOI DOI 10.1515/9783110197211.1.27
   Escudero P., 2009, PHONOLOGY PERCEPTION, P151
   ESCUDERO P., 2005, THESIS, P348
   Ferreira-Goncalves G., 2017, GRADUS REV BRASILEIR, V2, P73
   Ferreira-Goncalves G., 2013, DINAMICA MOVIMENTOS, P37
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2003, PHONETICS PHONOLOGY, P319, DOI DOI 10.1515/9783110895094.319
   FOWLER CA, 1980, J PHONETICS, V8, P113, DOI 10.1016/S0095-4470(19)31446-9
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   Gibson J., 1979, ECOLOGICAL APPROACH
   Gibson James J., 1966, SENSES CONSIDERED PE
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Hualde Jose Ignacio, 2010, INTRO LINGUISTICA HI, DOI [10.1017/CBO9780511808821, DOI 10.1017/CB09780511808821]
   JACKSON F, 1977, PERCEPTION
   Jackson F., 2010, COMPANION EPISTEMOLO, P702
   Keating P., 1985, PHONETIC LINGUISTICS, P115
   KenstowIcz M., 1994, PHONOLOGY GENERATIVE
   Kupske F. F., 2017, FORUM LINGUISTICO, V14, P2771, DOI [10.5007/1984-8412.2017v14n4p2771, DOI 10.5007/1984-8412.2017V14N4P2771]
   Ladefoged Peter, 2010, COURSE PHONETICS
   Lehet M, 2017, COGNITIVE SCI, V41, P885, DOI 10.1111/cogs.12413
   Levis J. M., 2018, INTELLIGIBILITY ORAL, DOI [10.1017/9781108241564, DOI 10.1017/9781108241564]
   Levis JM, 2005, TESOL QUART, V39, P369, DOI 10.2307/3588485
   Martinez Celdran E., 2003, SONIDO COMUNICACION
   Meneses F, 2015, PHONETICA, V72, P121, DOI 10.1159/000439599
   Motta-Avila C., 2017, THESIS
   Munro MJ, 2015, BLACKW HBK LINGUIST, P377
   Navarro Tomas Tomas, 2004, MANUAL PRONUNCIACION
   Nishida G., 2014, REV GEL, V11, P142
   Nishida G., 2012, THESIS
   Oliveira Rodrigo Magalhaes, 2016, THESIS
   PERISSINOTTO G. S. A., 1975, FONOLOGIA ESPANOL HA
   Perozzo R. V., 2017, THESIS
   PORT RF, 1985, J PHONETICS, V13, P455, DOI 10.1016/S0095-4470(19)30797-1
   Rauber A. S., 2012, TP PERCEPTION TESTS
   Real Academia Espanola (RAE), 2011, NUEV GRAM LENG ESP F
   RIBEIRO Rafaella Sudario, 2017, THESIS
   Roos L., 2010, FONETICA LUDICA BRIN
   SCHMITT Bruna Koch, 2014, LETRONICA, V7, P765
   SEARA I. C., 2015, CONHECER FONETICA FO
   SHAW JA, 2018, LAB PHONOLOGY, V9, DOI DOI 10.5334/LABPH0N.87
   Shimizu S, 2014, AUTOPHAGY: CANCER, OTHER PATHOLOGIES, INFLAMMATION, IMMUNITY, INFECTION, AND AGING, VOL 2: ROLE IN GENERAL DISEASES, P49, DOI 10.1016/B978-0-12-405877-4.00003-2
   Shultz AA, 2012, J ACOUST SOC AM, V132, pEL95, DOI 10.1121/1.4736711
   Silva A. H. P., 2014, JEITINHO BRASILEIRO, P33
   Silveira R, 2011, REV ESTUD LING, V19, P167
   SOBRAL C. da S., 2006, PORTUGUESE LANGUAGE, V1, P1
   Strange W., 1995, SPEECH PERCEPTION LI, P3
   VAQUERO DE RAMIREZ M., 2003, ESPANOL AM 1 PRONUNC
   ZIMMER Marcia, 2012, REV DA ABRALIN, V11, P221
NR 74
TC 0
Z9 0
U1 0
U2 0
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 2397-5563
J9 J PORT LINGUIST
JI J. Port. Linguist.
PD MAY 13
PY 2020
VL 19
AR 6
DI 10.5334/jpl.237
PG 23
WC Language & Linguistics
SC Linguistics
GA LO5DF
UT WOS:000533647500001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Mowad, TG
   Willett, AE
   Mahmoudian, M
   Lipin, M
   Heinecke, A
   Maguire, AM
   Bennett, J
   Ashtari, M
AF Mowad, Theresa G.
   Willett, Aimee E.
   Mahmoudian, Mani
   Lipin, Mikhail
   Heinecke, Armin
   Maguire, Albert M.
   Bennett, Jean
   Ashtari, Manzar
TI Compensatory Cross-Modal Plasticity Persists After Sight Restoration
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE low vision; sight restoration; RPE65 gene; cross-modal plasticity;
   auditory; resting state functional connectivity; functional magnetic
   resonance imaging
ID COCHLEAR IMPLANT USERS; PRIMARY VISUAL-CORTEX; FUNCTIONAL CONNECTIVITY;
   AUDITORY-CORTEX; GENE-THERAPY; TACTILE DISCRIMINATION;
   SPEECH-PERCEPTION; OCCIPITAL CORTEX; BLIND HUMANS; RPE65
AB Sensory deprivation prompts extensive structural and functional reorganizations of the cortex resulting in the occupation of space for the lost sense by the intact sensory systems. This process, known as cross-modal plasticity, has been widely studied in individuals with vision or hearing loss. However, little is known on the neuroplastic changes in restoring the deprived sense. Some reports consider the cross-modal functionality maladaptive to the return of the original sense, and others view this as a critical process in maintaining the neurons of the deprived sense active and operational. These controversial views have been challenged in both auditory and vision restoration reports for decades. Recently with the approval of Luxturna as the first retinal gene therapy (GT) drug to reverse blindness, there is a renewed interest for the crucial role of cross-modal plasticity on sight restoration. Employing a battery of task and resting state functional magnetic resonance imaging (rsfMRI), in comparison to a group of sighted controls, we tracked the functional changes in response to auditory and visual stimuli and at rest, in a group of patients with biallelic mutations in the RPE65 gene ("RPE65 patients") before and 3 years after GT. While the sighted controls did not present any evidence for auditory cross-modal plasticity, robust responses to the auditory stimuli were found in occipital cortex of the RPE65 patients overlapping visual responses and significantly elevated 3 years after GT. The rsfMRI results showed significant connectivity between the auditory and visual areas for both groups albeit attenuated in patients at baseline but enhanced 3 years after GT. Taken together, these findings demonstrate that (1) RPE65 patients present with an auditory cross-modal component; (2) visual and non-visual responses of the visual cortex are considerably enhanced after vision restoration; and (3) auditory cross-modal functions did not adversely affect the success of vision restitution. We hypothesize that following GT, to meet the demand for the newly established retinal signals, remaining or dormant visual neurons are revived or unmasked for greater participation. These neurons or a subset of these neurons respond to both the visual and non-visual demands and further strengthen connectivity between the auditory and visual cortices.
C1 [Mowad, Theresa G.; Lipin, Mikhail; Maguire, Albert M.; Bennett, Jean; Ashtari, Manzar] Univ Penn, Ctr Adv Retinal & Ocular Therapeut, Dept Ophthalmol, Philadelphia, PA 19104 USA.
   [Willett, Aimee E.] Edward Via Coll Osteopath Med, Blacksburg, VA USA.
   [Mahmoudian, Mani] Green Clin, N York, ON, Canada.
   [Heinecke, Armin] Maastricht Univ, Dept Cognit Neurosci, Maastricht, Netherlands.
   [Maguire, Albert M.; Bennett, Jean; Ashtari, Manzar] Univ Penn, Scheie Eye Inst, FM Kirby Ctr Mol Ophthalmol, Dept Ophthalmol, Philadelphia, PA 19104 USA.
   [Maguire, Albert M.; Bennett, Jean] Childrens Hosp Philadelphia, Ctr Cellular & Mol Therapeut, Philadelphia, PA 19104 USA.
   [Ashtari, Manzar] Univ Penn, Dept Radiol, Philadelphia, PA 19104 USA.
RP Ashtari, M (corresponding author), Univ Penn, Ctr Adv Retinal & Ocular Therapeut, Dept Ophthalmol, Philadelphia, PA 19104 USA.; Ashtari, M (corresponding author), Univ Penn, Scheie Eye Inst, FM Kirby Ctr Mol Ophthalmol, Dept Ophthalmol, Philadelphia, PA 19104 USA.; Ashtari, M (corresponding author), Univ Penn, Dept Radiol, Philadelphia, PA 19104 USA.
EM ashtari@pennmedicine.upenn.edu
FU Center for Advanced Retinal and Ocular Therapetics (CAROT) at University
   of Pennsylvania Perelman School of Medicine; Foundation Fighting
   BlindnessEuropean Commission; Paul and Evanina Mackall Foundation Trust
   at the Scheie Eye Institute; F.M. Kirby Foundation;  [R01EY025287-01A1]
FX This study was supported by R01EY025287-01A1 and Center for Advanced
   Retinal and Ocular Therapetics (CAROT) at University of Pennsylvania
   Perelman School of Medicine. This study was also funded in part by the
   Foundation Fighting Blindness - sponsored CHOP-PENN Pediatric Center for
   Retinal Degenerations, the Paul and Evanina Mackall Foundation Trust at
   the Scheie Eye Institute, and the F.M. Kirby Foundation.
CR Almeida J, 2015, PSYCHOL SCI, V26, P1771, DOI 10.1177/0956797615598970
   Amedi A, 2007, NAT NEUROSCI, V10, P687, DOI 10.1038/nn1912
   Amedi A, 2010, RESTOR NEUROL NEUROS, V28, P143, DOI [10.3233/RNN-2010-0497, 10.3233/RNN-2010-0503]
   Anderson CA, 2017, P NATL ACAD SCI USA, V114, P10256, DOI 10.1073/pnas.1704785114
   Ashtari M, 2017, OPHTHALMOLOGY, V124, P873, DOI 10.1016/j.ophtha.2017.01.029
   Ashtari M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086068
   Ashtari M, 2011, J CLIN INVEST, V121, P2160, DOI 10.1172/JCI57377
   Barone P, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0060093
   Bavelier D, 2002, NAT REV NEUROSCI, V3, P443, DOI 10.1038/nrn848
   Bedny M, 2011, P NATL ACAD SCI USA, V108, P4429, DOI 10.1073/pnas.1014818108
   Bedny M, 2010, CURR BIOL, V20, P1900, DOI 10.1016/j.cub.2010.09.044
   Beer AL, 2011, EXP BRAIN RES, V213, P299, DOI 10.1007/s00221-011-2715-y
   Bennett J, 2016, LANCET, V388, P661, DOI 10.1016/S0140-6736(16)30371-3
   Bennett J, 2012, SCI TRANSL MED, V4, DOI 10.1126/scitranslmed.3002865
   BISWAL B, 1995, MAGNET RESON MED, V34, P537, DOI 10.1002/mrm.1910340409
   Bola M, 2016, J NEUROSCI, V36, P3633, DOI 10.1523/JNEUROSCI.0106-16.2016
   Bonino D, 2008, ARCH ITAL BIOL, V146, P133
   Bowne SJ, 2011, EUR J HUM GENET, V19, P1074, DOI 10.1038/ejhg.2011.86
   Buckley KA, 2011, EAR HEARING, V32, P2, DOI [10.1097/AUD.0b013e3181e8534c, 10.1097/AUD.0b013e3181fa41bb]
   Burton H, 2003, J NEUROSCI, V23, P4005
   Burton H, 2002, J NEUROPHYSIOL, V88, P3359, DOI 10.1152/jn.00129.2002
   Butler BE, 2017, HEARING RES, V343, P118, DOI 10.1016/j.heares.2016.06.003
   Calhoun VD, 2003, NEUROIMAGE, V20, P1661, DOI 10.1016/S1053-8119(03)00411-7
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   Cattaneo Z, 2014, EXP BRAIN RES, V232, P2767, DOI 10.1007/s00221-014-3960-7
   Cecere R, 2014, NEUROPSYCHOLOGIA, V56, P350, DOI 10.1016/j.neuropsychologia.2014.02.008
   Chen LC, 2017, NEUROIMAGE, V146, P600, DOI 10.1016/j.neuroimage.2016.09.033
   Chen Zhiye, 2013, Nan Fang Yi Ke Da Xue Xue Bao, V33, P338
   Collignon O, 2007, CEREB CORTEX, V17, P457, DOI 10.1093/cercor/bhj162
   Collignon O, 2013, BRAIN, V136, P2769, DOI 10.1093/brain/awt176
   Collignon O, 2011, PROG BRAIN RES, V191, P211, DOI 10.1016/B978-0-444-53752-2.00003-5
   Collignon O, 2011, P NATL ACAD SCI USA, V108, P4435, DOI 10.1073/pnas.1013928108
   Collignon O, 2009, EXP BRAIN RES, V192, P343, DOI 10.1007/s00221-008-1553-z
   den Hollander AI, 2008, PROG RETIN EYE RES, V27, P391, DOI 10.1016/j.preteyeres.2008.05.003
   Dewey RS, 2015, HEARING RES, V325, P55, DOI 10.1016/j.heares.2015.03.007
   Dormal G, 2016, NEUROIMAGE, V134, P630, DOI 10.1016/j.neuroimage.2016.04.027
   Dormal G, 2015, J NEUROPHYSIOL, V113, P1727, DOI 10.1152/jn.00420.2014
   Doucet ME, 2006, BRAIN, V129, P3376, DOI 10.1093/brain/awl264
   Eckert MA, 2008, HUM BRAIN MAPP, V29, P848, DOI 10.1002/hbm.20560
   Falchier A, 2002, J NEUROSCI, V22, P5749
   Fischl B, 1999, NEUROIMAGE, V9, P195, DOI 10.1006/nimg.1998.0396
   FISHMAN MC, 1973, VISION RES, V13, P1415, DOI 10.1016/0042-6989(73)90002-3
   Frasnelli J, 2011, PROG BRAIN RES, V191, P233, DOI 10.1016/B978-0-444-53752-2.00002-3
   Friston KJ, 1998, NEUROIMAGE, V7, P30, DOI 10.1006/nimg.1997.0306
   Genovese CR, 2002, NEUROIMAGE, V15, P870, DOI 10.1006/nimg.2001.1037
   Giraud AL, 2001, BRAIN, V124, P1307, DOI 10.1093/brain/124.7.1307
   Glick H, 2017, HEARING RES, V343, P191, DOI 10.1016/j.heares.2016.08.012
   Goebel R, 2006, HUM BRAIN MAPP, V27, P392, DOI 10.1002/hbm.20249
   Gougoux F, 2005, PLOS BIOL, V3, P324, DOI 10.1371/journal.pbio.0030027
   Gougoux F, 2009, NEUROPSYCHOLOGIA, V47, P2967, DOI 10.1016/j.neuropsychologia.2009.06.027
   Goyal MS, 2006, NEUROREPORT, V17, P1381, DOI 10.1097/01.wnr.0000227990.23046.fe
   Green MF, 2005, J COGNITIVE NEUROSCI, V17, P13, DOI 10.1162/0898929052880011
   Guerreiro MJS, 2016, CURR BIOL, V26, P3096, DOI 10.1016/j.cub.2016.08.069
   Heimler B, 2014, NEUROSCIENCE, V283, P44, DOI 10.1016/j.neuroscience.2014.08.003
   INNOCENTI GM, 1988, J COMP NEUROL, V272, P242, DOI 10.1002/cne.902720207
   Iraji A, 2016, NEUROIMAGE-CLIN, V12, P100, DOI 10.1016/j.nicl.2016.06.012
   Iurilli G, 2012, NEURON, V73, P814, DOI 10.1016/j.neuron.2011.12.026
   Jiang F, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00324
   Jin MH, 2005, CELL, V122, P449, DOI 10.1016/j.cell.2005.06.042
   Klinge C, 2010, J NEUROSCI, V30, P12798, DOI 10.1523/JNEUROSCI.2384-10.2010
   Kral A, 2019, ANNU REV NEUROSCI, V42, P47, DOI 10.1146/annurev-neuro-080317-061513
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   Kriegeskorte N, 2001, NEUROIMAGE, V14, P329, DOI 10.1006/nimg.2001.0831
   Kumaran N, 2017, BRIT J OPHTHALMOL, V101, P1147, DOI 10.1136/bjophthalmol-2016-309975
   Kupers R, 2014, NEUROSCI BIOBEHAV R, V41, P36, DOI 10.1016/j.neubiorev.2013.08.001
   Land R, 2016, J NEUROSCI, V36, P6175, DOI 10.1523/JNEUROSCI.0046-16.2016
   Legge GE, 2016, ANNU REV VIS SCI, V2, P321, DOI 10.1146/annurev-vision-111815-114344
   Leo A, 2012, NEURAL PLAST, V2012, DOI 10.1155/2012/720278
   Lewald J, 2007, NEUROPSYCHOLOGIA, V45, P1215, DOI 10.1016/j.neuropsychologia.2006.10.006
   Lowe MJ, 1998, NEUROIMAGE, V7, P119, DOI 10.1006/nimg.1997.0315
   Lyness CR, 2013, NEUROSCI BIOBEHAV R, V37, P2621, DOI 10.1016/j.neubiorev.2013.08.011
   Maguire AM, 2008, NEW ENGL J MED, V358, P2240, DOI 10.1056/NEJMoa0802315
   Merabet L, 2004, NEURON, V42, P173, DOI 10.1016/S0896-6273(04)00147-3
   Merabet LB, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003046
   Moiseyev G, 2005, P NATL ACAD SCI USA, V102, P12413, DOI 10.1073/pnas.0503460102
   Noppeney U, 2003, BRAIN, V126, P1620, DOI 10.1093/brain/awg152
   Oh SH, 2003, ACTA OTO-LARYNGOL, V123, P148, DOI 10.1080/0036554021000028111
   Pasqualotto A, 2013, BEHAV BRAIN SCI, V36, P559, DOI 10.1017/S0140525X13000496
   Pelland M, 2017, NEUROIMAGE, V147, P532, DOI 10.1016/j.neuroimage.2016.12.053
   Pietrini P, 2004, P NATL ACAD SCI USA, V101, P5658, DOI 10.1073/pnas.0400707101
   Ptito M, 2008, EXP BRAIN RES, V187, P41, DOI 10.1007/s00221-008-1273-4
   Raz N, 2005, CEREB CORTEX, V15, P1459, DOI 10.1093/cercor/bhi026
   Redmond TM, 1998, NAT GENET, V20, P344, DOI 10.1038/3813
   Redmond TM, 2005, P NATL ACAD SCI USA, V102, P13658, DOI 10.1073/pnas.0504167102
   Reich L, 2011, CURR BIOL, V21, P363, DOI 10.1016/j.cub.2011.01.040
   Renier L, 2014, NEUROSCI BIOBEHAV R, V41, P53, DOI 10.1016/j.neubiorev.2013.01.025
   Rockland KS, 2003, INT J PSYCHOPHYSIOL, V50, P19, DOI 10.1016/S0167-8760(03)00121-1
   Roder B, 1999, NATURE, V400, P162, DOI 10.1038/22106
   Roder B, 2002, EUR J NEUROSCI, V16, P930, DOI 10.1046/j.1460-9568.2002.02147.x
   Roder B, 2013, P NATL ACAD SCI USA, V110, P16760, DOI 10.1073/pnas.1309963110
   Rouger J, 2012, HUM BRAIN MAPP, V33, P1929, DOI 10.1002/hbm.21331
   Sabel BA, 2018, RESTOR NEUROL NEUROS, V36, P767, DOI 10.3233/RNN-180880
   Sadato N, 2004, NEUROSCI LETT, V359, P49, DOI 10.1016/j.neulet.2004.02.005
   Sadato N, 2002, NEUROIMAGE, V16, P389, DOI 10.1006/nimg.2002.1111
   Sadato N, 1996, NATURE, V380, P526, DOI 10.1038/380526a0
   Saenz M, 2008, J NEUROSCI, V28, P5141, DOI 10.1523/JNEUROSCI.0803-08.2008
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   Sharma A, 2007, INT J AUDIOL, V46, P494, DOI 10.1080/14992020701524836
   Sharma A, 2015, INT J PSYCHOPHYSIOL, V95, P135, DOI 10.1016/j.ijpsycho.2014.04.007
   Strelnikov K, 2013, BRAIN, V136, P3682, DOI 10.1093/brain/awt274
   Stropahl M, 2015, NEUROIMAGE, V121, P159, DOI 10.1016/j.neuroimage.2015.07.062
   Viola FC, 2011, PSYCHOPHYSIOLOGY, V48, P1470, DOI 10.1111/j.1469-8986.2011.01224.x
   Voss P, 2004, CURR BIOL, V14, P1734, DOI 10.1016/j.cub.2004.09.051
   Voss P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00664
   Watkins KE, 2013, J NEUROSCI, V33, P18242, DOI 10.1523/JNEUROSCI.2546-13.2013
   Weeks R, 2000, J NEUROSCI, V20, P2664
   Weissenbacher A, 2009, NEUROIMAGE, V47, P1408, DOI 10.1016/j.neuroimage.2009.05.005
   Wilson BS, 2008, HEARING RES, V242, P3, DOI 10.1016/j.heares.2008.06.005
   Zangaladze A, 1999, NATURE, V401, P587
NR 109
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD MAY 12
PY 2020
VL 14
AR 291
DI 10.3389/fnins.2020.00291
PG 16
WC Neurosciences
SC Neurosciences & Neurology
GA LT5IQ
UT WOS:000537104700001
PM 32477041
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Birules, J
   Bosch, L
   Pons, F
   Lewkowicz, DJ
AF Birules, Joan
   Bosch, Laura
   Pons, Ferran
   Lewkowicz, David J.
TI Highly proficient L2 speakers still need to attend to a talker's mouth
   when processing L2 speech
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Audiovisual speech perception; selective attention; face perception;
   second-language perception; non-native speech processing
ID SELECTIVE ATTENTION; GAZE BEHAVIOR; HEARING LIPS; LANGUAGE; INFANTS;
   IDENTIFICATION; 2ND-LANGUAGE; INFORMATION; PERCEPTION; CHILDREN
AB Adults attend to a talker's mouth whenever confronted with challenging speech processing situations. We investigated whether L2 speakers also attend more to the mouth and whether their proficiency level modulates such attention. First, in Experiment 1, we presented native speakers of English and Spanish with videos of a talker speaking in their native and non-native language while measuring eye-gaze to the talker's face. As predicted, participants attended more to the talker's mouth in response to non-native than native speech. Then, Experiment 2 explored whether language proficiency affects attention to the talker's eyes and mouth when perceiving non-native, second-language speech. Results indicated that non-native speakers attended more to the mouth than native speakers, regardless of their level of L2 expertise. These results not only confirm that attention to a talker's mouth increases whenever speech-processing becomes more challenging, but crucially, they show that this is also true in highly competent L2 speakers.
C1 [Birules, Joan; Bosch, Laura; Pons, Ferran] Univ Barcelona, Dept Cognit Dev & Educ Psychol, Barcelona, Spain.
   [Lewkowicz, David J.] Haskins Labs Inc, New Haven, CT USA.
RP Birules, J (corresponding author), Univ Barcelona, Dept Cognit Dev & Educ Psychol, Barcelona, Spain.
EM joanbirules@gmail.com
RI Birules, Joan/AAY-2457-2020; Galceran, Laura Bosch/D-5520-2012; Pons,
   Ferran/A-1156-2013
OI Birules, Joan/0000-0001-9708-4922; Galceran, Laura
   Bosch/0000-0002-6536-4855; Pons, Ferran/0000-0001-5919-8590
FU Spanish Ministerio de Ciencia e InnovacionInstituto de Salud Carlos
   IIISpanish Government [PSI2014-55105-P, PGC2018-097487-B-100]; National
   Science FoundationNational Science Foundation (NSF) [BCS-1946115]
FX This work was supported by the Spanish Ministerio de Ciencia e
   Innovacion, [grant number PSI2014-55105-P] and [grant number
   PGC2018-097487-B-100] to FP and LB and by the National Science
   Foundation, [grant number BCS-1946115] to DJL.
CR Arnold P, 2001, BRIT J PSYCHOL, V92, P339, DOI 10.1348/000712601162220
   Barenholtz E, 2016, COGNITION, V147, P100, DOI 10.1016/j.cognition.2015.11.013
   Bernstein LE, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00034
   Birmingham E, 2009, ANN NY ACAD SCI, V1156, P118, DOI 10.1111/j.1749-6632.2009.04468.x
   Birules J, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12755
   Borghini G, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00152
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Buchan JN, 2007, SOC NEUROSCI-UK, V2, P1, DOI 10.1080/17470910601043644
   Buchan JN, 2008, BRAIN RES, V1242, P162, DOI 10.1016/j.brainres.2008.06.083
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Cotton J C, 1935, Science, V82, P592, DOI 10.1126/science.82.2138.592
   Cutler A, 2008, J ACOUST SOC AM, V124, P1264, DOI 10.1121/1.2946707
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Heikkila J, 2018, CHILD LANG TEACH THE, V34, P269, DOI 10.1177/0265659018793697
   Hyltenstam K, 2000, STUD LINGUISTICA, V54, P150, DOI 10.1111/1467-9582.00056
   Imafuku M, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12825
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Lansing IR, 2003, PERCEPT PSYCHOPHYS, V65, P536, DOI 10.3758/BF03194581
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Lusk LG, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00052
   MACLEOD A, 1987, British Journal of Audiology, V21, P131, DOI 10.3109/03005368709077786
   Mattys SL, 2010, SPEECH COMMUN, V52, P887, DOI 10.1016/j.specom.2010.01.005
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   McClelland JL, 2002, PHYSIOL BEHAV, V77, P657, DOI 10.1016/S0031-9384(02)00916-2
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MEREDITH MA, 1986, J NEUROPHYSIOL, V56, P640
   Navarra J, 2007, PSYCHOL RES-PSYCH FO, V71, P4, DOI 10.1007/s00426-005-0031-5
   Pallier C, 1997, COGNITION, V64, pB9, DOI 10.1016/S0010-0277(97)00030-9
   Pons F, 2018, LANG LEARN, V68, P180, DOI 10.1111/lang.12276
   Pons F, 2015, PSYCHOL SCI, V26, P490, DOI 10.1177/0956797614568320
   REISBERG D, 1978, ACTA PSYCHOL, V42, P331, DOI 10.1016/0001-6918(78)90007-0
   Reisberg D, 1987, HEARING EYE PSYCHOL, P97
   Risberg A., 1978, STL QPSR, V4, P1
   SANDERS DA, 1971, J SPEECH HEAR RES, V14, P154, DOI 10.1044/jshr.1401.154
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1979, PHONETICA, V36, P314, DOI 10.1159/000259969
   Tenenbaum EJ, 2015, J CHILD LANG, V42, P1173, DOI 10.1017/S0305000914000725
   Thompson LA, 2004, EXP AGING RES, V30, P241, DOI 10.1080/03610730490447877
   Tsang T, 2018, J EXP CHILD PSYCHOL, V169, P93, DOI 10.1016/j.jecp.2018.01.002
   Vatikiotis-Bateson E, 1998, PERCEPT PSYCHOPHYS, V60, P926, DOI 10.3758/BF03211929
   Vo MLH, 2012, J VISION, V12, DOI 10.1167/12.13.3
   Yarbus A. L., 1967, EYE MOVEMENTS VISION
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
   Young GS, 2009, DEVELOPMENTAL SCI, V12, P798, DOI 10.1111/j.1467-7687.2009.00833.x
NR 44
TC 1
Z9 1
U1 0
U2 4
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PD DEC 1
PY 2020
VL 35
IS 10
BP 1314
EP 1325
DI 10.1080/23273798.2020.1762905
EA MAY 2020
PG 12
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA OV7AH
UT WOS:000533746600001
DA 2021-02-24
ER

PT J
AU Nenadic, F
   Tucker, BV
AF Nenadic, Filip
   Tucker, Benjamin V.
TI Computational modelling of an auditory lexical decision experiment using
   jTRACE and TISK
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Spoken word recognition; auditory lexical decision task; computational
   modelling; TRACE; TISK
ID SPOKEN-WORD RECOGNITION; REACTION-TIME SEQUENCES; SPEECH-PERCEPTION;
   NEIGHBORHOOD ACTIVATION; HUMAN PARTICIPANTS; TRACE MODEL; ACCESS;
   REPRESENTATION; COMPETITION; LANGUAGE
AB We present a series of computational simulations of the auditory lexical decision task using the jTRACE and TISK models of spoken word recognition. Simulation 1 replicates high accuracy in word recognition and similar performance of these models using the small, default dictionary. Simulation 2 expands the set of words and phonemes, leading to issues in representing certain phonemes in jTRACE. Simulation 3 expands the lexicon of competitors and we find that TISK struggles to select the target word as the winner. Finally, Simulation 4 shows that the decision criteria employed leads to many false positives when pseudowords are presented to the model. None of the model estimates of the time cycle when the winner should be selected predicted participant response latency in the auditory lexical decision task. We discuss these findings and offer suggestions as to what a contemporary model of spoken word recognition should be able to do.
C1 [Nenadic, Filip; Tucker, Benjamin V.] Univ Alberta, Dept Linguist, Edmonton, AB, Canada.
RP Nenadic, F (corresponding author), Univ Alberta, Dept Linguist, Edmonton, AB, Canada.
EM nenadic@ualberta.ca
RI Tucker, Benjamin V./AAQ-5029-2020
OI Tucker, Benjamin V./0000-0001-8965-7890
FU Social Sciences and Humanities Research Council of CanadaSocial Sciences
   and Humanities Research Council of Canada (SSHRC) [435-2014-0678]
FX This project was funded by the Social Sciences and Humanities Research
   Council of Canada [grant number 435-2014-0678].
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   ANDRUSKI JE, 1994, COGNITION, V52, P163, DOI 10.1016/0010-0277(94)90042-6
   Arnold D, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174623
   Baayen H, 2017, J MEM LANG, V94, P206, DOI 10.1016/j.jml.2016.11.006
   Baayen RH, 2019, COMPLEXITY, DOI 10.1155/2019/4895891
   Balling LW, 2008, LANG COGNITIVE PROC, V23, P1159, DOI 10.1080/01690960802201010
   Balota DA, 2007, BEHAV RES METHODS, V39, P445, DOI 10.3758/BF03193014
   Balota DA, 2012, CUR ISS PSYCHOL LANG, P90
   Brysbaert M, 2014, BEHAV RES METHODS, V46, P904, DOI 10.3758/s13428-013-0403-5
   Chan KY, 2009, J EXP PSYCHOL HUMAN, V35, P1934, DOI 10.1037/a0016902
   Chawla M., 2019, WHAT IS ROLE COMPUTA, DOI [10.31234/osf.io/m79fw, DOI 10.31234/0SF.I0/M79FW]
   Dahan D, 2001, LANG COGNITIVE PROC, V16, P507, DOI 10.1080/01690960143000074
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750
   Davies M, 2009, INT J CORPUS LINGUIS, V14, P159, DOI 10.1075/ijcl.14.2.02dav
   Ernestus M, 2011, J PHONETICS, V39, P253, DOI 10.1016/S0095-4470(11)00055-6
   Ernestus M, 2015, Q J EXP PSYCHOL, V68, P1469, DOI 10.1080/17470218.2014.984730
   Ernestus Mirjam, 2007, P 16 INT C PHON SCI, P773
   Ferrand L, 2018, BEHAV RES METHODS, V50, P1285, DOI 10.3758/s13428-017-0943-1
   Ferrand L, 2010, BEHAV RES METHODS, V42, P488, DOI 10.3758/BRM.42.2.488
   FORSTER KI, 1976, MEM COGNITION, V4, P53, DOI 10.3758/BF03213255
   Frauenfelder UH, 1998, SCI PSYCH S, P101
   FRAUENFELDER UH, 1990, ACL MIT NAT, P50
   FRAUENFELDER UH, 2000, P WORKSH SPOK WORD A, P79
   Gaskell MG, 2008, J EXP PSYCHOL GEN, V137, P282, DOI 10.1037/0096-3445.137.2.282
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   Gaskell MG, 2002, COGNITIVE PSYCHOL, V45, P220
   Goh WD, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00976
   Goldinger SD, 2003, J PHONETICS, V31, P305, DOI 10.1016/S0095-4470(03)00030-5
   Goldinger SD, 1996, LANG COGNITIVE PROC, V11, P559, DOI 10.1080/016909696386944
   Goldstein R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01683
   Grossberg S, 2000, PSYCHOL REV, V107, P735, DOI 10.1037//0033-295X.107.4.735
   Grossberg S, 1997, J EXP PSYCHOL HUMAN, V23, P481, DOI 10.1037/0096-1523.23.2.481
   Hannagan T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00563
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Jusczyk PW, 2002, EAR HEARING, V23, P2, DOI 10.1097/00003446-200202000-00002
   Kemps RJJK, 2005, LANG COGNITIVE PROC, V20, P43, DOI 10.1080/01690960444000223
   Keuleers E, 2015, Q J EXP PSYCHOL, V68, P1665, DOI 10.1080/17470218.2015.1022560
   Keuleers E, 2012, BEHAV RES METHODS, V44, P287, DOI 10.3758/s13428-011-0118-4
   Kuperman V, 2015, Q J EXP PSYCHOL, V68, P1693, DOI 10.1080/17470218.2014.989865
   Luce PA, 2000, PERCEPT PSYCHOPHYS, V62, P615, DOI 10.3758/BF03212113
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   LUCE PA, 1986, PERCEPT PSYCHOPHYS, V39, P155, DOI 10.3758/BF03212485
   Magnuson J. S., 2012, CAMBRIDGE HDB PSYCHO, P76, DOI DOI 10.1017/CB09781139029377.008
   Magnuson J. S., 2018, P COGNITIVE SCI SOC, P732
   Magnuson JS, 2020, COGNITIVE SCI, V44, DOI 10.1111/cogs.12823
   Magnuson JS, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00369
   Marslen-Wilson W., 1988, LANG COGNITIVE PROC, V3, P1, DOI [10.1080/01690968808402079, DOI 10.1080/01690968808402079]
   MARSLENWILSON W, 1980, COGNITION, V8, P1, DOI 10.1016/0010-0277(80)90015-3
   MARSLENWILSON W, 1994, PSYCHOL REV, V101, P653, DOI 10.1037/0033-295X.101.4.653
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X
   Mayor J, 2014, J MEM LANG, V71, P89, DOI 10.1016/j.jml.2013.09.009
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2009, J MEM LANG, V60, P65, DOI 10.1016/j.jml.2008.07.002
   McQueen J., 2007, OXFORD HDB PSYCHOLIN, P37, DOI DOI 10.1093/0XF0RDHB/9780198568971.013.0003
   McRae K, 2005, BEHAV RES METHODS, V37, P547, DOI 10.3758/BF03192726
   Mirman D, 2008, COGNITIVE SCI, V32, P398, DOI 10.1080/03640210701864063
   Morrison G., 2013, VOWEL INHERENT SPECT, P9, DOI DOI 10.1007/978-3-642-14209-3_2
   MORTON J, 1969, PSYCHOL REV, V76, P165, DOI 10.1037/h0027366
   NEAREY TM, 1986, J ACOUST SOC AM, V80, P1297, DOI 10.1121/1.394433
   Nenadic F, 2018, INTERSPEECH, P3772, DOI 10.21437/Interspeech.2018-2081
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   NORRIS D, 1995, J EXP PSYCHOL LEARN, V21, P1209, DOI 10.1037/0278-7393.21.5.1209
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Protopapas A, 1999, PSYCHOL BULL, V125, P410, DOI 10.1037/0033-2909.125.4.410
   R Core Team, 2018, R LANG ENV STAT COMP
   Sajin SM, 2014, J MEM LANG, V70, P13, DOI 10.1016/j.jml.2013.09.006
   Salverda AP, 2003, COGNITION, V90, P51, DOI 10.1016/S0010-0277(03)00139-2
   Sauval K, 2018, ACTA PSYCHOL, V182, P212, DOI 10.1016/j.actpsy.2017.12.002
   Scharenborg O, 2005, COGNITIVE SCI, V29, P867, DOI 10.1207/s15516709cog0000_37
   Scharenborg O., 2009, PROC INT 2009 BRIGHT, P1675
   Scharenborg O, 2010, PRAGMAT COGN, V18, P136, DOI 10.1075/pc.18.1.06sch
   Scharenborg O, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1473
   Schneider W, 2012, E PRIME REFERENCE GU
   Shuai L, 2017, BEHAV RES METHODS, V49, P230, DOI 10.3758/s13428-015-0690-0
   Smith AC, 2017, J MEM LANG, V93, P276, DOI 10.1016/j.jml.2016.08.005
   Strauss TJ, 2007, BEHAV RES METHODS, V39, P19, DOI 10.3758/BF03192840
   TAFT M, 1975, J VERB LEARN VERB BE, V14, P638, DOI 10.1016/S0022-5371(75)80051-X
   ten Bosch L, 2018, INTERSPEECH, P971
   ten Bosch L, 2014, INTERSPEECH, P462
   ten Bosch L, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1576
   ten Bosch L., 2015, 18 INT C PHON SCI GL
   Tucker BV, 2019, BEHAV RES METHODS, V51, P1187, DOI 10.3758/s13428-018-1056-1
   Tucker BV, 2016, MENT LEX, V11, P375, DOI 10.1075/ml.11.3.03tuc
   Tucker BV, 2011, J PHONETICS, V39, P312, DOI 10.1016/j.wocn.2010.12.001
   Ventura P, 2004, LANG COGNITIVE PROC, V19, P57, DOI 10.1080/01690960344000134
   Vitevitch M. S., 2018, OXFORD HDB PSYCHOLIN, P30, DOI [10.1093/oxfordhb/9780198786825.013.2, DOI 10.1093/OXFORDHB/9780198786825.013.2]
   Warriner AB, 2013, BEHAV RES METHODS, V45, P1191, DOI 10.3758/s13428-012-0314-x
   Weber A, 2012, WIRES COGN SCI, V3, P387, DOI 10.1002/wcs.1178
   Weide Robert, 2005, CARNEGIE MELLON PRON
   You H, 2018, BEHAV RES METHODS, V50, P871, DOI 10.3758/s13428-017-1012-5
NR 92
TC 0
Z9 0
U1 0
U2 1
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PD DEC 1
PY 2020
VL 35
IS 10
BP 1326
EP 1354
DI 10.1080/23273798.2020.1764600
EA MAY 2020
PG 29
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA OV7AH
UT WOS:000533745100001
DA 2021-02-24
ER

PT J
AU Cibelli, E
AF Cibelli, Emily
TI Articulatory and perceptual cues to non-native phoneme perception:
   Cross-modal training for early learners
SO SECOND LANGUAGE RESEARCH
LA English
DT Article; Early Access
DE articulatory training; cross-modal transfer; English; Hindi; non-native
   perception; speech perception; stop contrasts
ID R-VERTICAL-BAR; INDIVIDUAL-DIFFERENCES; JAPANESE LISTENERS;
   SPEECH-PERCEPTION; AMERICAN-ENGLISH; LANGUAGE; DISCRIMINATION;
   ACQUISITION; SOUNDS; ADULTS
AB Non-native phoneme perception can be challenging for adult learners. This article explores two routes to strengthening early representations of non-native targets: perceptual training, which focuses on auditory discrimination of novel contrasts, and articulatory training, which highlights the articulatory gestures of non-native categories. Of particular interest is whether cross-modal transfer from production to perception is beneficial to improving discrimination. A longitudinal experiment integrating both training types found that articulatory training did not improve discrimination once perceptual learning had taken place. However, a follow-up experiment found an equivalent benefit for perceptual and articulatory training when each was presented as the only learning style to separate groups of learners. These findings suggest that articulatory learning can 'cross over' to assist acquisition in the perceptual domain, and may play a key role for second language (L2) learners struggling with both perception and production of novel phoneme categories.
C1 [Cibelli, Emily] Northwestern Univ, Evanston, IL 60208 USA.
RP Cibelli, E (corresponding author), Northwestern Univ, Dept Linguist, 2016 Sheridan Rd, Evanston, IL 60208 USA.
EM emily.cibelli@gmail.com
FU NSFNational Science Foundation (NSF) [DGE-1106400]; Phi Beta Kappa
   Northern California Association
FX The author disclosed receipt of the following financial support for the
   research, authorship, and/or publication of this article: This project
   was supported by NSF Grant DGE-1106400 and funding from the Phi Beta
   Kappa Northern California Association.
CR AkahaneYamada R, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P606, DOI 10.1109/ICSLP.1996.607434
   Baayen R.H., 2008, ANAL LINGUISTIC DATA
   Baese-Berk MM, 2010, THESIS
   Bailey TM, 2005, J MEM LANG, V52, P339, DOI 10.1016/j.jml.2004.12.003
   Baker W, 2002, PROC ANN BUCLD, P36
   Bates D, 2015, PARSIMONIOUS MIXED M
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Best C. T., 1995, SPEECH PERCEPTION LI, P167
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   BEST CT, 2009, J ACOUST SOC AM, V125, P2758, DOI DOI 10.1121/1.4784648
   Boersma Paul, 2019, PRAAT DOING PHONETIC
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P977, DOI 10.3758/BF03206911
   CATFORD JC, 1970, MOD LANG J, V54, P477, DOI 10.2307/321767
   Cibelli E, 2020, PHONETICA, V77, P1, DOI 10.1159/000495728
   Davidson L, 2016, J PHONETICS, V54, P35, DOI 10.1016/j.wocn.2015.09.003
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014
   Diaz B, 2008, P NATL ACAD SCI USA, V105, P16083, DOI 10.1073/pnas.0805022105
   Earle FS, 2015, J EXP PSYCHOL HUMAN, V41, P1680, DOI 10.1037/xhp0000113
   Earle FS, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01192
   Escudero P, 2011, J ACOUST SOC AM, V130, pEL206, DOI 10.1121/1.3629144
   Faytak M, 2016, J ACOUST SOC AM, V140, P3340
   Fenn KM, 2003, NATURE, V425, P614, DOI 10.1038/nature01951
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   Fowler C. A., 1989, ECOL PSYCHOL, V1, P145
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   Fowler CA, 2008, PSYCHON B REV, V15, P458, DOI 10.3758/PBR.15.2.458
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Goldstein L., 2003, PHONETICS PHONOLOGY, P159
   Golestani N, 2004, NEUROIMAGE, V21, P494, DOI 10.1016/j.neuroimage.2003.09.071
   Golestani N, 2014, INT J BILINGUAL, V18, P6, DOI 10.1177/1367006912456585
   Lacabex EG, 2008, ILHA DESTERRO, V55, P173
   Goudbeek M, 2008, SPEECH COMMUN, V50, P109, DOI 10.1016/j.specom.2007.07.003
   Guion SG, 2000, J ACOUST SOC AM, V107, P2711, DOI 10.1121/1.428657
   Gulian M., 2007, P 15 INT C PHON SCI, P1893
   Hattori K, 2009, J ACOUST SOC AM, V125, P469, DOI 10.1121/1.3021295
   Hayes-Harb R, 2007, SECOND LANG RES, V23, P65, DOI 10.1177/0267658307071601
   Hazan V, 2005, SPEECH COMMUN, V47, P360, DOI 10.1016/j.specom.2005.04.007
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   HOMBERT JM, 1979, LANGUAGE, V55, P37, DOI 10.2307/412518
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Iverson P, 2009, J ACOUST SOC AM, V126, P866, DOI 10.1121/1.3148196
   JAMIESON DG, 1986, PERCEPT PSYCHOPHYS, V40, P205, DOI 10.3758/BF03211500
   Jia G, 2006, J ACOUST SOC AM, V119, P1118, DOI 10.1121/1.2151806
   Kartushina N, 2015, J ACOUST SOC AM, V138, P817, DOI 10.1121/1.4926561
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2014, P NATL ACAD SCI USA, V111, P11238, DOI 10.1073/pnas.1410963111
   Kuhl PK, 2000, P NATL ACAD SCI USA, V97, P11850, DOI 10.1073/pnas.97.22.11850
   Lai YH, 2009, LANG COGNITIVE PROC, V24, P1265, DOI 10.1080/01690960802113850
   Lametti DR, 2012, J NEUROSCI, V32, P9351, DOI 10.1523/JNEUROSCI.0404-12.2012
   Levy ES, 2010, J ACOUST SOC AM, V128, P1290, DOI 10.1121/1.3466879
   Lim SJ, 2011, COGNITIVE SCI, V35, P1390, DOI 10.1111/j.1551-6709.2011.01192.x
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   Lord G, 2005, HISPANIA-J DEV INTER, V88, P557, DOI 10.2307/20063159
   Macmillan N, 2004, DETECTION THEORY USE
   Mathot S, 2012, BEHAV RES METHODS, V44, P314, DOI 10.3758/s13428-011-0168-7
   Matsui JK, 1995, LANGUAGE LAB, V32, P169
   McCandliss BD, 2002, COGN AFFECT BEHAV NE, V2, P89, DOI 10.3758/CABN.2.2.89
   Olson DJ, 2014, HISPANIA-J DEV INTER, V97, P47, DOI 10.1353/hpn.2014.0030
   Pederson E, 2010, J ACOUST SOC AM, V127, pEL54, DOI 10.1121/1.3292286
   Pegg JE, 1997, J ACOUST SOC AM, V102, P3742, DOI 10.1121/1.420137
   PIMSLEUR P, 1963, MOD LANG J, V47, P199
   Protopapas A, 2000, P 2 INT WORKSH INT S, P31
   Pruitt JS, 2006, J ACOUST SOC AM, V119, P1684, DOI 10.1121/1.2161427
   Pruitt JSJ, 1995, THESIS
   R Core Team, 2018, R LANG ENV STAT COMP
   Sadakata M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01318
   Sadakata M, 2013, J ACOUST SOC AM, V134, P1324, DOI 10.1121/1.4812767
   Saito K, 2012, LANG LEARN, V62, P595, DOI 10.1111/j.1467-9922.2011.00639.x
   SCHIEFER L, 1986, PHONETICA, V43, P43, DOI 10.1159/000261760
   SCHNEIDERMAN E, 1988, LANG LEARN, V38, P1, DOI 10.1111/j.1467-1770.1988.tb00399.x
   Seitz AR, 2003, NATURE, V422, P36, DOI 10.1038/422036a
   SHELDON A, 1982, APPL PSYCHOLINGUIST, V3, P243, DOI 10.1017/S0142716400001417
   Song JH, 2008, J COGNITIVE NEUROSCI, V20, P1892, DOI 10.1162/jocn.2008.20131
   Studdert-Kennedy M., 2003, LANGUAGE EVOLUTION S, P235, DOI [10.1093/acprof:oso/9780199244843.003.0013, DOI 10.1093/ACPROF:OSO/9780199244843.003.0013]
   TEES RC, 1984, CAN J PSYCHOL, V38, P579, DOI 10.1037/h0080868
   TERRACE HS, 1963, J EXP ANAL BEHAV, V6, P1, DOI 10.1901/jeab.1963.6-1
   Tremblay S, 2003, NATURE, V423, P866, DOI 10.1038/nature01710
   Tsui HML, 2012, THESIS
   Vlahou E, 2011, J EXPT PSYCHOL GEN, V141, P1
   Wang XC, 2013, MOD LANG J, V97, P144, DOI 10.1111/j.1540-4781.2013.01386.x
   Wang Y, 2003, J ACOUST SOC AM, V113, P1033, DOI 10.1121/1.1531176
   Wang Y, 1999, J ACOUST SOC AM, V106, P3649, DOI 10.1121/1.428217
   Wilson C, 2014, J MEM LANG, V77, P1, DOI 10.1016/j.jml.2014.08.001
   Wilson I, 2014, ACOUST SCI TECHNOL, V35, P285, DOI 10.1250/ast.35.285
   Wright Beverly A., 2015, Journal of the Acoustical Society of America, V137, DOI 10.1121/1.4920675
   Zampini M., 1998, TEXAS PAPERS FOREIGN, V3, P85
NR 90
TC 0
Z9 0
U1 2
U2 3
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0267-6583
EI 1477-0326
J9 SECOND LANG RES
JI Second Lang. Res.
AR 0267658320921217
DI 10.1177/0267658320921217
EA MAY 2020
PG 31
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA LN3AH
UT WOS:000532814200001
DA 2021-02-24
ER

PT J
AU Chen, S
   Zhu, YQ
   Wayland, R
   Yang, YK
AF Chen, Si
   Zhu, Yiqing
   Wayland, Ratree
   Yang, Yike
TI How musical experience affects tone perception efficiency by musicians
   of tonal and non-tonal speakers?
SO PLOS ONE
LA English
DT Article
ID CATEGORICAL PERCEPTION; SPEECH-PERCEPTION; LANGUAGE EXPERIENCE; LEXICAL
   TONES; STEADY-STATE; PITCH; DISCRIMINATION; MANDARIN; IDENTIFICATION;
   ENGLISH
AB Purpose
   To investigate if, regardless of language background (tonal or non-tonal), musicians may show stronger CP than non-musicians; To examine if native speakers of English (English or non-tonal musicians henceforth) or Mandarin Chinese (Mandarin or tonal musicians henceforth) can better accommodate multiple functions of the same acoustic cue and if musicians' sensitivity to pitch of lexical tones comes at the cost of slower processing.
   Method
   English and Mandarin Musicians and non-musicians performed a categorical identification and a discrimination task on rising and falling continua of fundamental frequency on two vowels with 9 duration values.
   Results
   Non-tonal musicians exhibited significantly stronger categorical perception of pitch contour than non-tonal non-musicians. However, tonal musicians did not consistently perceive the two types of pitch directions more categorically than tonal non-musicians. Both tonal and non-tonal musicians also benefited more from increasing stimulus duration in processing pitch changes than non-musicians and they generally require less time for pitch processing. Musicians were also more sensitive to intrinsic F0 in pitch perception and differences of pitch types.
   Conclusion
   The effect of musical training strengthens categorical perception more consistently in non-tonal speakers than tonal speakers. Overall, musicians benefit more from increased stimulus duration, due perhaps to their greater sensitivity to temporal information, thus allowing them to be better at forming a more robust auditory representation and matching sounds to internalized memory templates. Musicians also attended more to acoustic details such as intrinsic F0 and pitch types in pitch processing, and yet, overall, their categorization of pitch was not compromised by traces of these acoustic details from their auditory short-term working memory. These findings may lead to a better understanding of pitch perception deficits in special populations, particularly among individuals diagnosed with autism spectrum disorder (ASD).
C1 [Chen, Si; Yang, Yike] Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Kowloon, Hong Kong, Peoples R China.
   [Chen, Si] Peking Univ, Hong Kong Polytech Univ, Res Ctr Chinese Linguist, Hong Kong, Peoples R China.
   [Zhu, Yiqing; Wayland, Ratree] Univ Florida, Dept Linguist, Gainesville, FL USA.
RP Chen, S (corresponding author), Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Kowloon, Hong Kong, Peoples R China.; Chen, S (corresponding author), Peking Univ, Hong Kong Polytech Univ, Res Ctr Chinese Linguist, Hong Kong, Peoples R China.
EM sarah.chen@polyu.edu.hk
RI ; Chen, Si/B-8601-2015
OI Yang, Yike/0000-0002-2297-6878; Chen, Si/0000-0003-3581-9561
FU Research Grants Council of the Hong Kong Special Administrative
   RegionHong Kong Research Grants Council; Hong Kong Polytechnic
   UniversityHong Kong Polytechnic University [1-ZVHJ, 1-ZZJP, G-YBGK]; 
   [25602816]
FX This work was supported by the Research Grants Council of the Hong Kong
   Special Administrative Region; Funding scheme: Early Career Scheme
   (grant number: 25602816)
   (http://www.ugc.edu.hk/eng/rgc/about/term/rgc.htm), Fund for ECS Project
   Rated 3.5 CRG (grant number: G-YBGK) Grant of the Hong Kong Polytechnic
   University (grant number: 1-ZVHJ; 1-ZZJP). The funders had no role in
   study design, data collection and analysis, decision to publish, or
   preparation of the manuscript.
CR Abramson Arthur S., 1979, FRONTIERS SPEECH COM, P127
   ABRAMSON AS, 1978, LANG SPEECH, V21, P319, DOI 10.1177/002383097802100406
   ADES AE, 1977, PSYCHOL REV, V84, P524, DOI 10.1037/0033-295X.84.6.524
   Alexander J. A., 2005, 9 EUR C SPEECH COMM
   Altmann CF, 2014, NEUROPSYCHOLOGIA, V64, P13, DOI 10.1016/j.neuropsychologia.2014.09.006
   Apfelbaum KS, 2014, LANG COGN NEUROSCI, V29, P1070, DOI 10.1080/01690965.2013.824995
   Bates D., 2015, J STAT SOFTWARE
   Behne D, 2006, J ACOUST SOC AM, V120, P3168
   Belotel-Grenie A., 1995, 13 INT C PHON SCI IC, P400
   Belotel-Grenie A., 1994, 3 INT C SPOK LANG PR
   Bidelman GM, 2017, NEUROSCIENCE, V348, P107, DOI 10.1016/j.neuroscience.2017.02.015
   Bidelman GM, 2011, BRAIN COGNITION, V77, P1, DOI 10.1016/j.bandc.2011.07.006
   BLICHER DL, 1990, J PHONETICS, V18, P37, DOI 10.1016/S0095-4470(19)30357-2
   Brownell MD, 2002, J MUSIC THER, V39, P117, DOI 10.1093/jmt/39.2.117
   Burnham D, 2007, LANGUAGE EXPERIENCE
   Burnham D, 2002, P 9 INT C SPEECH SCI, P2
   Burnham D, 2015, PSYCHOL MUSIC, V43, P881, DOI 10.1177/0305735614546359
   Casserly ED, 2010, WIRES COGN SCI, V1, P629, DOI 10.1002/wcs.63
   Chen S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0180656
   Cui A, 2019, J ACOUST SOC AM, V146, P4086, DOI 10.1121/1.5134442
   EIMAS PD, 1963, LANG SPEECH, V6, P206, DOI 10.1177/002383096300600403
   Francis AL, 2003, PERCEPT PSYCHOPHYS, V65, P1029, DOI 10.3758/BF03194832
   Fujisaki H., 1970, Annual Report of the Engineering Research Institute, Faculty of Engineering, University of Tokyo, V29, P207
   George EM, 2011, NEUROPSYCHOLOGIA, V49, P1083, DOI 10.1016/j.neuropsychologia.2011.02.001
   Gottfried T. L., 2000, J ACOUST SOC AM, V108, P2604, DOI DOI 10.1121/1.4743698
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   HEALY AF, 1982, J EXP PSYCHOL HUMAN, V8, P68, DOI 10.1037/0096-1523.8.1.68
   Janse E, 2003, PRODUCTION PERCEPTIO
   Jiang J, 2015, J AUTISM DEV DISORD, V45, P2067, DOI 10.1007/s10803-015-2370-4
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Krishnan A, 2004, HEARING RES, V189, P1, DOI 10.1016/S0378-5955(03)00402-7
   Lee CY, 2008, J ACOUST SOC AM, V124, P3235, DOI 10.1121/1.2990713
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   Liberman AM, 1996, SPEECH SPECIAL CODE
   Liu SY, 2004, LANG SPEECH, V47, P109, DOI 10.1177/00238309040470020101
   LOCKE S, 1973, Cortex, V9, P355
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   Medina D, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e01315
   Mirman D, 2004, J ACOUST SOC AM, V116, P1198, DOI 10.1121/1.1766020
   MOULINES E, 1995, SPEECH COMMUN, V16, P175, DOI 10.1016/0167-6393(94)00054-E
   Nan Y, 2018, P NATL ACAD SCI USA
   Ortega-Llebaria M, 2017, BILING-LANG COGN, V20, P367, DOI 10.1017/S1366728915000723
   Patel AD, 2007, TRENDS COGN SCI, V11, P369, DOI 10.1016/j.tics.2007.08.003
   Peng G, 2010, J PHONETICS, V38, P616, DOI 10.1016/j.wocn.2010.09.003
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   PISONI DB, 1975, MEM COGNITION, V3, P7, DOI 10.3758/BF03198202
   PISONI DB, 1976, J ACOUST SOC AM, V59, pS39, DOI 10.1121/1.2002669
   Pisoni DB, 1971, NATURE CATEGORICAL P
   POLLACK I, 1971, PSYCHON SCI, V24, P299
   Prom-on S, 2009, J ACOUST SOC AM, V125, P405, DOI 10.1121/1.3037222
   RAZ I, 1977, J ACOUST SOC AM, V62, pS60, DOI 10.1121/1.2016288
   REPP BH, 1979, J EXP PSYCHOL HUMAN, V5, P129, DOI 10.1037/0096-1523.5.1.129
   Repp BH., 1984, SPEECH LANG ADV BASI, V10, P243, DOI DOI 10.1016/B978-0-12-608610-2.50012-1
   Sares AG, 2018, J SPEECH LANG HEAR R, V61, P496, DOI 10.1044/2017_JSLHR-S-17-0207
   Shen GN, 2016, J ACOUST SOC AM, V140, P4396, DOI 10.1121/1.4971765
   SIEGEL JA, 1977, PERCEPT PSYCHOPHYS, V21, P399, DOI 10.3758/BF03199493
   STOLL G, 1984, SPEECH COMMUN, V3, P137, DOI 10.1016/0167-6393(84)90035-9
   Tseng C. Y., 1981, THESIS
   Verde MF, 2006, PERCEPT PSYCHOPHYS, V68, P643, DOI 10.3758/BF03208765
   WANG WSY, 1976, ANN NY ACAD SCI, V280, P61, DOI 10.1111/j.1749-6632.1976.tb25472.x
   Wang XY, 2017, SCI REP-UK, V7, P1, DOI 10.1038/srep43254
   Wang YN, 2011, STAT BIOPHARM RES, V3, P1, DOI 10.1198/sbr.2011.09051
   Wang YP, 2017, SCI ROBOT, V2, DOI 10.1126/scirobotics.aan8072
   Wayland R, 2010, J PHONETICS, V38, P654, DOI 10.1016/j.wocn.2010.10.001
   WHALEN DH, 1992, PHONETICA, V49, P25, DOI 10.1159/000261901
   WHALEN DH, 1995, J PHONETICS, V23, P349, DOI 10.1016/S0095-4470(95)80165-0
   Wong PCM, 2007, APPL PSYCHOLINGUIST, V28, P565, DOI 10.1017/S0142716407070312
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   WOOD CC, 1976, J ACOUST SOC AM, V60, P1381, DOI 10.1121/1.381231
   Wu H, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00436
   Xu L, 2002, J ACOUST SOC AM, V112, P247, DOI 10.1121/1.1487843
   Xu Y, 2002, J ACOUST SOC AM, V111, P1399, DOI 10.1121/1.1445789
   Xu YS, 2006, J ACOUST SOC AM, V120, P1063, DOI 10.1121/1.2213572
   Yu AC, 2014, 4 INT S TON ASP LANG
   Zhang J, 2005, PSYCHOMETRIKA, V70, P203, DOI 10.1007/s11336-003-1119-8
   Zhao TC, 2015, J ACOUST SOC AM, V138, pEL133, DOI 10.1121/1.4927632
   Zhao TC, 2015, J ACOUST SOC AM, V137, P1452, DOI 10.1121/1.4913457
NR 77
TC 0
Z9 0
U1 3
U2 3
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD MAY 8
PY 2020
VL 15
IS 5
AR e0232514
DI 10.1371/journal.pone.0232514
PG 32
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA LU0QJ
UT WOS:000537468300015
PM 32384088
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Saa, JD
   Christen, A
   Martini, S
   Pasley, BN
   Knight, RT
   Giraud, AL
AF Saa, Jaime Delgado
   Christen, Andy
   Martini, Stephanie
   Pasley, Brian N.
   Knight, Robert T.
   Giraud, Anne-Lise
TI Using Coherence-based spectro-spatial filters for stimulus features
   prediction from electro-corticographic recordings
SO SCIENTIFIC REPORTS
LA English
DT Article
ID BRAIN-COMPUTER INTERFACES; ELECTROCORTICOGRAPHIC SIGNALS; CORTICAL
   ENTRAINMENT; MOVEMENT DIRECTION; CHANNEL SELECTION; HAND MOVEMENT; EEG
   SIGNALS; SPEECH; CLASSIFICATION; COMMUNICATION
AB The traditional approach in neuroscience relies on encoding models where brain responses are related to different stimuli in order to establish dependencies. In decoding tasks, on the contrary, brain responses are used to predict the stimuli, and traditionally, the signals are assumed stationary within trials, which is rarely the case for natural stimuli. We hypothesize that a decoding model assuming each experimental trial as a realization of a random process more likely reflects the statistical properties of the undergoing process compared to the assumption of stationarity. Here, we propose a Coherence-based spectro-spatial filter that allows for reconstructing stimulus features from brain signal's features. The proposed method extracts common patterns between features of the brain signals and the stimuli that produced them. These patterns, originating from different recording electrodes are combined, forming a spatial filter that produces a unified prediction of the presented stimulus. This approach takes into account frequency, phase, and spatial distribution of brain features, hence avoiding the need to predefine specific frequency bands of interest or phase relationships between stimulus and brain responses manually. Furthermore, the model does not require the tuning of hyper-parameters, reducing significantly the computational load attached to it. Using three different cognitive tasks (motor movements, speech perception, and speech production), we show that the proposed method consistently improves stimulus feature predictions in terms of correlation (group averages of 0.74 for motor movements, 0.84 for speech perception, and 0.74 for speech production) in comparison with other methods based on regularized multivariate regression, probabilistic graphical models and artificial neural networks. Furthermore, the model parameters revealed those anatomical regions and spectral components that were discriminant in the different cognitive tasks. This novel method does not only provide a useful tool to address fundamental neuroscience questions, but could also be applied to neuroprosthetics.
C1 [Saa, Jaime Delgado; Christen, Andy; Martini, Stephanie; Giraud, Anne-Lise] Univ Geneva, Auditory Language Grp, Geneva, Switzerland.
   [Pasley, Brian N.; Knight, Robert T.] Univ Calif Berkeley, Knight Lab, Berkeley, CA 94720 USA.
   [Saa, Jaime Delgado] Univ Norte, BSPAI Lab, Barranquilla, Colombia.
RP Saa, JD (corresponding author), Univ Geneva, Auditory Language Grp, Geneva, Switzerland.; Saa, JD (corresponding author), Univ Norte, BSPAI Lab, Barranquilla, Colombia.
EM jaime.delgado@gmail.com
RI martin, stephanie/AAX-9088-2020
OI Giraud, Anne-Lise/0000-0002-1261-3555
FU Swiss National FundsSwiss National Science Foundation (SNSF) [ALG
   320030_163040]; NINDSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   of Neurological Disorders & Stroke (NINDS) [R3723115]
FX This work was performed thanks for the Swiss National Funds project
   grant to ALG 320030_163040, and to the EU FET-BrainCom project and NINDS
   R3723115. The authors thanks Dr. Gerwin Schalk and Dr. Kai Miller for
   providing access to the data-sets used in this work.
CR Aho K, 2014, ECOLOGY, V95, P631, DOI 10.1890/13-1452.1
   Akbari H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37359-z
   Ang KK, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00039
   Angrick M, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab0c59
   Uriguen JA, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/3/031001
   Anumanchipalli GK, 2019, NATURE, V568, P493, DOI 10.1038/s41586-019-1119-1
   Ball T, 2009, J NEURAL ENG, V6, DOI 10.1088/1741-2560/6/1/016006
   Belkacem A. N., 2018, IEEE T NEURAL SYSTEM
   Birbaumer N, 2007, J PHYSIOL-LONDON, V579, P621, DOI 10.1113/jphysiol.2006.125633
   Birbaumer N, 2006, PSYCHOPHYSIOLOGY, V43, P517, DOI 10.1111/j.1469-8986.2006.00456.x
   Blankertz B, 2008, IEEE SIGNAL PROC MAG, V25, P41, DOI 10.1109/MSP.2008.4408441
   Broderick MP, 2018, CURR BIOL, V28, P803, DOI 10.1016/j.cub.2018.01.080
   Cohen MX, 2017, J NEUROSCI METH, V278, P1, DOI 10.1016/j.jneumeth.2016.12.016
   Crosse MJ, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00604
   Crosse MJ, 2015, J NEUROSCI, V35, P14195, DOI 10.1523/JNEUROSCI.1829-15.2015
   Dahne S, 2014, NEUROIMAGE, V86, P111, DOI 10.1016/j.neuroimage.2013.07.079
   de Cheveigne A, 2018, NEUROIMAGE, V172, P206, DOI 10.1016/j.neuroimage.2018.01.033
   Delgado Saa J., 2016, ARXIV161208642
   Delgado Saa J, 2014, THESIS
   Delgado Saa J. F, 2018, IMPLEMENTATION COHER
   Saa JFD, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/3/036017
   DELGADO SJ, 2013, NEURAL SYSTEMS REHAB, V21, P716
   Delisle-Rodriguez D, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab08c8
   DELISLERODRIGUEZ D, 2017, SENSORS BASEL, V17, DOI DOI 10.3390/S17122725
   Di Liberto GM, 2018, NEUROIMAGE, V166, P247, DOI 10.1016/j.neuroimage.2017.10.066
   Di Liberto GM, 2017, HEARING RES, V348, P70, DOI 10.1016/j.heares.2017.02.015
   Dornhege G, 2007, BRAIN COMPUTER INTER
   Ebisuzaki W, 1997, J CLIMATE, V10, P2147, DOI 10.1175/1520-0442(1997)010<2147:AMTETS>2.0.CO;2
   Fiedler L, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa66dd
   Flamary R, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00029
   Frigo M, 2005, P IEEE, V93, P216, DOI 10.1109/JPROC.2004.840301
   Ghaemi A, 2017, BIOMED SIGNAL PROCES, V33, P109, DOI 10.1016/j.bspc.2016.11.018
   Ghitza O, 2013, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00340
   Golumbic EZ, 2013, J NEUROSCI, V33, P1417, DOI 10.1523/JNEUROSCI.3675-12.2013
   Gurve D, 2019, J NEURAL ENG
   Hammer J, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00200
   Handy TC., 2005, EVENT RELATED POTENT
   Hasan BAS, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/2/025013
   Hashimoto Y, 2013, CLIN NEUROPHYSIOL, V124, P2153, DOI 10.1016/j.clinph.2013.05.006
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Holdgraf CR, 2017, FRONT SYST NEUROSCI, V11, DOI 10.3389/fnsys.2017.00061
   Hyafil A, 2015, TRENDS NEUROSCI, V38, P725, DOI 10.1016/j.tins.2015.09.001
   Isik L., 2017, NEUROIMAGE
   Jerbi K, 2007, P NATL ACAD SCI USA, V104, P7676, DOI 10.1073/pnas.0609632104
   Kubanek J, 2009, J NEURAL ENG, V6, DOI 10.1088/1741-2560/6/6/066001
   Kuo CH, 2020, J NEUROSURG, V132, P1358, DOI 10.3171/2019.1.JNS181840
   Leuthardt EC, 2006, IEEE T NEUR SYS REH, V14, P194, DOI 10.1109/TNSRE.2006.875536
   LIN LI, 1989, BIOMETRICS, V45, P255, DOI 10.2307/2532051
   Lotte F, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aab2f2
   Ma T, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa5d5f
   Manning JR, 2009, J NEUROSCI, V29, P13613, DOI 10.1523/JNEUROSCI.2041-09.2009
   Martin AB, 2019, J NEUROSCI, V39, P333, DOI 10.1523/JNEUROSCI.1889-18.2018
   Martin SLO, 2016, SCI REP-UK, V6, DOI 10.1038/srep39273
   Miller KJ, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002655
   Milstein D, 2017, ADV NEURAL INFORM PR, P868
   Mina R. T., 2006, BIOMEDICAL ENG, V2-5
   Moses DA, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10994-4
   Moses DA, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aaab6f
   Murphy K, 2013, NEUROIMAGE, V80, P349, DOI 10.1016/j.neuroimage.2013.04.001
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Pefkou M, 2017, J NEUROSCI, V37, P7930, DOI 10.1523/JNEUROSCI.2882-16.2017
   Petre Stoica R. M, 2005, SPECTRAL ANAL SIGNAL
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   Pfurtscheller G, 2003, CLIN NEUROPHYSIOL, V114, P1226, DOI 10.1016/S1388-2457(03)00067-1
   Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946
   Rickert J, 2005, J NEUROSCI, V25, P8815, DOI 10.1523/JNEUROSCI.0816-05.2005
   Saa JFD, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/2/026020
   Schalk G, 2008, J NEURAL ENG, V5, P75, DOI 10.1088/1741-2560/5/1/008
   Schalk G, 2007, J NEURAL ENG, V4, P264, DOI 10.1088/1741-2560/4/3/012
   Schirrmeister RT, 2017, HUM BRAIN MAPP, V38, P5391, DOI 10.1002/hbm.23730
   Shahid S, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/2/025014
   Sitaram R, 2007, COMPUTATIONAL INTELL
   Smith SJM, 2005, J NEUROL NEUROSUR PS, V76, P2, DOI 10.1136/jnnp.2005.069245
   Stavisky SD, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/3/036009
   Sullivan O, 2017, FRONT HUM NEUROSCI, V10, P679
   Vaidya M, 2018, J NEUROPHYSIOL, V119, P1291, DOI 10.1152/jn.00982.2016
   Waldert S, 2008, J NEUROSCI, V28, P1000, DOI 10.1523/JNEUROSCI.5171-07.2008
   Waldert S, 2009, J PHYSIOL-PARIS, V103, P244, DOI 10.1016/j.jphysparis.2009.08.007
   Wang J, 2018, BIOMED SIGNAL PROCES, V46, P10, DOI 10.1016/j.bspc.2018.06.008
   Wang Z, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00127
   Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3
   Wong DDE, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00531
   Wu DR, 2018, IEEE T FUZZY SYST, V26, P771, DOI 10.1109/TFUZZ.2017.2688423
   Xie KH, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-13608-5
   Xie ZQ, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aa9dbe
   Yger F, 2017, IEEE T NEUR SYS REH, V25, P1753, DOI 10.1109/TNSRE.2016.2627016
   Yu TY, 2015, IEEE T NEUR SYS REH, V23, P1068, DOI 10.1109/TNSRE.2015.2413943
   Zeiler M.D, 2012, ARXIV12125701
   Zhou SM, 2008, INFORM SCIENCES, V178, P1629, DOI 10.1016/j.ins.2007.11.012
NR 89
TC 1
Z9 1
U1 3
U2 4
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD MAY 6
PY 2020
VL 10
IS 1
AR 7637
DI 10.1038/s41598-020-63303-1
PG 14
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA LP0PL
UT WOS:000534024000004
PM 32376909
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Smith, MR
   Yevoo, P
   Sadahiro, M
   Readhead, B
   Kidd, B
   Dudley, JT
   Morishita, H
AF Smith, Milo R.
   Yevoo, Priscilla
   Sadahiro, Masato
   Readhead, Ben
   Kidd, Brian
   Dudley, Joel T.
   Morishita, Hirofumi
TI Systematic Analysis of Environmental Chemicals That Dysregulate Critical
   Period Plasticity-Related Gene Expression Reveals Common Pathways That
   Mimic Immune Response to Pathogen
SO NEURAL PLASTICITY
LA English
DT Article
ID ENRICHMENT ANALYSIS; SPEECH-PERCEPTION; EXPOSURE; CHILDREN; AUTISM;
   MOUSE; ACTIVATION; MICROBIOTA; MICROGLIA
AB The tens of thousands of industrial and synthetic chemicals released into the environment have an unknown but potentially significant capacity to interfere with neurodevelopment. Consequently, there is an urgent need for systematic approaches that can identify disruptive chemicals. Little is known about the impact of environmental chemicals on critical periods of developmental neuroplasticity, in large part, due to the challenge of screening thousands of chemicals. Using an integrative bioinformatics approach, we systematically scanned 2001 environmental chemicals and identified 50 chemicals that consistently dysregulate two transcriptional signatures of critical period plasticity. These chemicals included pesticides (e.g., pyridaben), antimicrobials (e.g., bacitracin), metals (e.g., mercury), anesthetics (e.g., halothane), and other chemicals and mixtures (e.g., vehicle emissions). Application of a chemogenomic enrichment analysis and hierarchical clustering across these diverse chemicals identified two clusters of chemicals with one that mimicked an immune response to pathogen, implicating inflammatory pathways and microglia as a common chemically induced neuropathological process. Thus, we established an integrative bioinformatics approach to systematically scan thousands of environmental chemicals for their ability to dysregulate molecular signatures relevant to critical periods of development.
C1 [Smith, Milo R.; Yevoo, Priscilla; Sadahiro, Masato; Morishita, Hirofumi] Icahn Sch Med Mt Sinai, Dept Psychiat, 1 Gustave L Levy Pl, New York, NY 10029 USA.
   [Smith, Milo R.; Kidd, Brian; Dudley, Joel T.] Icahn Sch Med Mt Sinai, Dept Genet & Genom Sci, 1 Gustave L Levy Pl, New York, NY 10029 USA.
   [Smith, Milo R.; Yevoo, Priscilla; Sadahiro, Masato; Morishita, Hirofumi] Icahn Sch Med Mt Sinai, Nash Family Dept Neurosci, 1 Gustave L Levy Pl, New York, NY 10029 USA.
   [Smith, Milo R.; Yevoo, Priscilla; Sadahiro, Masato; Morishita, Hirofumi] Icahn Sch Med Mt Sinai, Dept Ophthalmol, 1 Gustave L Levy Pl, New York, NY 10029 USA.
   [Smith, Milo R.; Readhead, Ben; Kidd, Brian; Dudley, Joel T.] Icahn Sch Med Mt Sinai, Inst Next Generat Healthcare, 1 Gustave L Levy Pl, New York, NY 10029 USA.
   [Smith, Milo R.; Yevoo, Priscilla; Sadahiro, Masato; Morishita, Hirofumi] Icahn Sch Med Mt Sinai, Friedman Brain Inst, 1 Gustave L Levy Pl, New York, NY 10029 USA.
   [Smith, Milo R.; Yevoo, Priscilla; Sadahiro, Masato; Morishita, Hirofumi] Icahn Sch Med Mt Sinai, Mindich Child Hlth Dr Dev Inst, 1 Gustave L Levy Pl, New York, NY 10029 USA.
   [Readhead, Ben] Biodesign Inst, ASU Banner Neurodegenerat Dis Res Ctr, Bldg A,1001 S McAllister Ave, Tempe, AZ 85281 USA.
RP Morishita, H (corresponding author), Icahn Sch Med Mt Sinai, Dept Psychiat, 1 Gustave L Levy Pl, New York, NY 10029 USA.; Dudley, JT (corresponding author), Icahn Sch Med Mt Sinai, Dept Genet & Genom Sci, 1 Gustave L Levy Pl, New York, NY 10029 USA.; Morishita, H (corresponding author), Icahn Sch Med Mt Sinai, Nash Family Dept Neurosci, 1 Gustave L Levy Pl, New York, NY 10029 USA.; Morishita, H (corresponding author), Icahn Sch Med Mt Sinai, Dept Ophthalmol, 1 Gustave L Levy Pl, New York, NY 10029 USA.; Dudley, JT (corresponding author), Icahn Sch Med Mt Sinai, Inst Next Generat Healthcare, 1 Gustave L Levy Pl, New York, NY 10029 USA.; Morishita, H (corresponding author), Icahn Sch Med Mt Sinai, Friedman Brain Inst, 1 Gustave L Levy Pl, New York, NY 10029 USA.; Morishita, H (corresponding author), Icahn Sch Med Mt Sinai, Mindich Child Hlth Dr Dev Inst, 1 Gustave L Levy Pl, New York, NY 10029 USA.
EM joel.dudley@gmail.com; hirofumi.morishita@mssm.edu
RI Morishita, Hirofumi/J-9619-2015
OI Morishita, Hirofumi/0000-0002-1045-1337
FU National Institute of Child Health and Human
   Development-Interdisciplinary Training in Systems and Developmental
   Biology and Birth Defects [T32H-D0-75735]; Mindich Child Health and
   Development Institute Pilot Fund; Knights Templar Eye Foundation; March
   of DimesMarch of Dimes; Whitehall Foundation; Harris Family Foundation;
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [P30-ES-023515,
   R01-DK-098242, U54-CA189201, R56-AG058469, R01-EY-024918, R01-EY-026053,
   R21 MH106919]
FX This work was funded by a Traineeship, National Institute of Child
   Health and Human Development-Interdisciplinary Training in Systems and
   Developmental Biology and Birth Defects Grant T32H-D0-75735 (to M.R.S.);
   the Mindich Child Health and Development Institute Pilot Fund (to J.T.D.
   and H.M.); the Knights Templar Eye Foundation (to H.M.); the March of
   Dimes (to H.M.); the Whitehall Foundation (to H.M.); the Harris Family
   Foundation (to J.T.D.); and the National Institutes of Health Grants
   P30-ES-023515 (to J.T.D. and H.M.), R01-DK-098242, U54-CA189201, and
   R56-AG058469 (to J.T.D.), and R01-EY-024918, R01-EY-026053, and R21
   MH106919 (to H.M.).
CR Banks WA, 1995, NEUROIMMUNOMODULAT, V2, P241, DOI 10.1159/000097202
   Barton MD, 2000, NUTR RES REV, V13, P279, DOI 10.1079/095442200108729106
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bennett ML, 2016, P NATL ACAD SCI USA, V113, pE1738, DOI 10.1073/pnas.1525528113
   Bercik P, 2011, GASTROENTEROLOGY, V141, P599, DOI 10.1053/j.gastro.2011.04.052
   Bonn M., 2016, HYPERGEA HYPERGEOMET
   Boyle CA, 2011, PEDIATRICS, V127, P1034, DOI 10.1542/peds.2010-2989
   Bruce AJ, 1996, NAT MED, V2, P788, DOI 10.1038/nm0796-788
   Chemistry Abstracts Service (CAS), 2018, CAS REGISTRY GOLD ST
   Chen EY, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-128
   Davidson PW, 2004, PEDIATRICS, V113, P1023
   Davis AP, 2015, NUCLEIC ACIDS RES, V43, pD914, DOI 10.1093/nar/gku935
   Dewey CE, 1999, SWINE HEALTH PROD, V7, P19
   Eduati F, 2015, NAT BIOTECHNOL, V33, P933, DOI 10.1038/nbt.3299
   Fox SE, 2010, CHILD DEV, V81, P28, DOI 10.1111/j.1467-8624.2009.01380.x
   Fung TC, 2017, NAT NEUROSCI, V20, P145, DOI 10.1038/nn.4476
   Gordon JA, 1996, J NEUROSCI, V16, P3274
   Hodos RA, 2016, WIRES SYST BIOL MED, V8, P186, DOI 10.1002/wsbm.1337
   Huang ZJ, 1999, CELL, V98, P739, DOI 10.1016/S0092-8674(00)81509-3
   JOHNSON JS, 1989, COGNITIVE PSYCHOL, V21, P60, DOI 10.1016/0010-0285(89)90003-0
   Kalogeraki E, 2014, J NEUROSCI, V34, P15476, DOI 10.1523/JNEUROSCI.2678-14.2014
   Kelly EA, 2014, FRONT NEUROANAT, V8, DOI 10.3389/fnana.2014.00117
   Kuno R, 2005, J NEUROIMMUNOL, V162, P89, DOI 10.1016/j.jneuroim.2005.01.015
   Lamb J, 2006, SCIENCE, V313, P1929, DOI 10.1126/science.1132939
   Landrigan PJ, 2012, ENVIRON HEALTH PERSP, V120, pA258, DOI 10.1289/ehp.1104285
   Laskin DL, 2001, TOXICOLOGY, V160, P111, DOI 10.1016/S0300-483X(00)00437-6
   LeBlanc JJ, 2011, NEURAL PLAST, V2011, DOI 10.1155/2011/921680
   Levelt CN, 2012, ANNU REV NEUROSCI, V35, P309, DOI 10.1146/annurev-neuro-061010-113813
   Lewis TL, 2005, DEV PSYCHOBIOL, V46, P163, DOI 10.1002/dev.20055
   Markell D., 2010, WASH U J LAW POLICY, V32, P333
   Mav D, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191105
   Medine AE, 2005, DEV BRAIN RES, V157, P107, DOI 10.1016/j.devbrainres.2005.03.012
   Morishita H, 2010, SCIENCE, V330, P1238, DOI 10.1126/science.1195320
   Nabel Elisa M, 2013, Front Psychiatry, V4, P146, DOI 10.3389/fpsyt.2013.00146
   Nelson CA, 2007, SCIENCE, V318, P1937, DOI 10.1126/science.1143921
   Nikolopoulos TP, 1999, LARYNGOSCOPE, V109, P595, DOI 10.1097/00005537-199904000-00014
   Pearson BL, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11173
   Rajamani KT, 2013, AUTISM RES, V6, P248, DOI 10.1002/aur.1287
   Rice D, 2000, ENVIRON HEALTH PERSP, V108, P511, DOI 10.2307/3454543
   Schorr EA, 2005, P NATL ACAD SCI USA, V102, P18748, DOI 10.1073/pnas.0508862102
   Sipe GO, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms10905
   Smith MR, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34592-4
   Smith Milo R, 2016, eNeuro, V3, DOI 10.1523/ENEURO.0240-16.2016
   Smyth GK, 2005, STAT BIOL HEALTH, P397, DOI 10.1007/0-387-29362-0_23
   Sriram K, 2006, FASEB J, V20, P670, DOI 10.1096/fj.05-5106com
   Subramanian A, 2005, P NATL ACAD SCI USA, V102, P15545, DOI 10.1073/pnas.0506580102
   Takesian AE, 2013, PROG BRAIN RES, V207, P3, DOI 10.1016/B978-0-444-63327-9.00001-1
   Umemori J, 2015, INT J DEV NEUROSCI, V44, P55, DOI 10.1016/j.ijdevneu.2015.05.006
   Volk HE, 2011, ENVIRON HEALTH PERSP, V119, P873, DOI 10.1289/ehp.1002835
   Wang BS, 2010, NEURON, V65, P246, DOI 10.1016/j.neuron.2010.01.002
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   Windham GC, 2006, ENVIRON HEALTH PERSP, V114, P1438, DOI 10.1289/ehp.9120
NR 52
TC 0
Z9 0
U1 0
U2 0
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 2090-5904
EI 1687-5443
J9 NEURAL PLAST
JI Neural. Plast.
PD MAY 5
PY 2020
VL 2020
AR 1673897
DI 10.1155/2020/1673897
PG 10
WC Neurosciences
SC Neurosciences & Neurology
GA LS3FF
UT WOS:000536272500001
PM 32454811
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Maurer, D
   Ghloum, JK
   Gibson, LC
   Watson, MR
   Chen, LM
   Akins, K
   Enns, JT
   Hensch, TK
   Werker, JF
AF Maurer, Daphne
   Ghloum, Julian K.
   Gibson, Laura C.
   Watson, Marcus R.
   Chen, Lawrence M.
   Akins, Kathleen
   Enns, James T.
   Hensch, Takao K.
   Werker, Janet F.
TI Reduced perceptual narrowing in synesthesia
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
LA English
DT Article
DE synesthesia; perceptual narrowing; speech perception; face processing;
   pruning
ID LANGUAGE SPEECH-PERCEPTION; GRAPHEME-COLOR; STRUCTURAL CONNECTIVITY;
   VISUAL-CORTEX; 1ST YEAR; SYNAESTHESIA; PREVALENCE; SENSITIVITY; INFANTS;
   FACES
AB Synesthesia is a neurologic trait in which specific inducers, such as sounds, automatically elicit additional idiosyncratic percepts, such as color (thus "colored hearing"). One explanation for this trait-and the one tested here-is that synesthesia results from unusually weak pruning of cortical synaptic hyperconnectivity during early perceptual development. We tested the prediction from this hypothesis that synesthetes would be superior at making discriminations from nonnative categories that are normally weakened by experience-dependent pruning during a critical period early in development-namely, discrimination among nonnative phonemes (Hindi retroflex /da/ and dental /da/), among chimpanzee faces, and among inverted human faces. Like the superiority of 6-mo-old infants over older infants, the synesthetic groups were significantly better than control groups at making all the nonnative discriminations across five samples and three testing sites. The consistent superiority of the synesthetic groups in making discriminations that are normally eliminated during infancy suggests that residual cortical connectivity in synesthesia supports changes in perception that extend beyond the specific synesthetic percepts, consistent with the incomplete pruning hypothesis.
C1 [Maurer, Daphne; Ghloum, Julian K.; Gibson, Laura C.] McMaster Univ, Dept Psychol Neurosci & Behav, Hamilton, ON L8S 4K1, Canada.
   [Watson, Marcus R.; Chen, Lawrence M.; Enns, James T.; Werker, Janet F.] Univ British Columbia, Dept Psychol, Vancouver, BC V6T 1Z4, Canada.
   [Akins, Kathleen] Simon Fraser Univ, Dept Philosophy, Burnaby, BC V5A 1S6, Canada.
   [Hensch, Takao K.] Harvard Univ, Ctr Brain Sci, Dept Mol Cellular Biol, Cambridge, MA 02138 USA.
   [Hensch, Takao K.; Werker, Janet F.] Canadian Inst Adv Res, Toronto, ON M5G 1M1, Canada.
   [Hensch, Takao K.] Univ Tokyo, Int Res Ctr Neurointelligence, Inst Adv Study, Bunkyo Ku, Tokyo 1130033, Japan.
RP Maurer, D (corresponding author), McMaster Univ, Dept Psychol Neurosci & Behav, Hamilton, ON L8S 4K1, Canada.
EM maurer@mcmaster.ca
RI Enns, James/O-7583-2017
OI Enns, James/0000-0002-3676-8316; Werker, Janet F./0000-0002-1168-9013;
   Chen, Lawrence/0000-0001-9238-3288
FU Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR [9797,
   RGPIN-2015-03967]
FX We thank Dr. Lisa Parr for providing the photographs of chimp faces used
   to create the chimp stimulus set, Iqra Ashfaq and Sally Stafford for
   help in recruiting and testing participants, and Savannah Nijeboer and
   Jacqueline Cloake for help with manuscript preparation. This research
   was supported by grants from the Natural Sciences and Engineering
   Research Council of Canada (9797, to D.M. and RGPIN-2015-03967, to
   J.F.W.).
CR Anzures G, 2012, J EXP CHILD PSYCHOL, V112, P484, DOI 10.1016/j.jecp.2012.04.005
   Asher JE, 2009, AM J HUM GENET, V84, P279, DOI 10.1016/j.ajhg.2009.01.012
   Banissy MJ, 2012, COGN NEUROSCI-UK, V3, P29, DOI 10.1080/17588928.2011.594499
   Banissy MJ, 2009, EXP BRAIN RES, V198, P261, DOI 10.1007/s00221-009-1810-9
   Bankieris KR, 2017, PSYCHON B REV, V24, P935, DOI 10.3758/s13423-016-1162-y
   Bankieris KR, 2016, I-PERCEPTION, V7, DOI 10.1177/2041669516658488
   Barnett KJ, 2008, NEUROIMAGE, V43, P605, DOI 10.1016/j.neuroimage.2008.07.028
   Bate S, 2019, J EXP PSYCHOL HUMAN, V45, P363, DOI 10.1037/xhp0000607
   Bedny M, 2012, BRAIN LANG, V122, P162, DOI 10.1016/j.bandl.2011.10.005
   Belanova E, 2018, CORTEX, V108, P92, DOI 10.1016/j.cortex.2018.07.008
   Bor D, 2014, SCI REP-UK, V4, DOI 10.1038/srep07089
   Brauchli C, 2018, HUM BRAIN MAPP, V39, P522, DOI 10.1002/hbm.23861
   Butler BE, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00092
   Cashon CH, 2015, ADV CHILD DEV BEHAV, V48, P117, DOI 10.1016/bs.acdb.2014.11.008
   Cecchetti L, 2016, FRONT SYST NEUROSCI, V10, DOI 10.3389/fnsys.2016.00089
   Dahl CD, 2014, SCI REP-UK, V4, DOI 10.1038/srep06654
   Dovern A, 2012, J NEUROSCI, V32, P7614, DOI 10.1523/JNEUROSCI.5401-11.2012
   Eagleman DM, 2007, J NEUROSCI METH, V159, P139, DOI 10.1016/j.jneumeth.2006.07.012
   Fresa RO, 2019, CONSCIOUS COGN, V73, DOI 10.1016/j.concog.2019.102764
   Friendly RH, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00718
   Grossenbacher PG, 2001, TRENDS COGN SCI, V5, P36, DOI 10.1016/S1364-6613(00)01571-0
   Hanggi J, 2011, J NEUROSCI, V31, P5816, DOI 10.1523/JNEUROSCI.0964-10.2011
   Hancock P., 2013, OXFORD HDB SYNESTHES, P84
   Hannon EE, 2005, P NATL ACAD SCI USA, V102, P12639, DOI 10.1073/pnas.0504254102
   Hayes-Harb R, 2007, SECOND LANG RES, V23, P65, DOI 10.1177/0267658307071601
   Hensch TK, 2005, NAT REV NEUROSCI, V6, P877, DOI 10.1038/nrn1787
   Heron-Delaney M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019858
   Hubbard EM, 2011, J NEUROPSYCHOL, V5, P152, DOI 10.1111/j.1748-6653.2011.02014.x
   Hupe JM, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00103
   Jancke L, 2009, EUR J NEUROSCI, V29, P1287, DOI 10.1111/j.1460-9568.2009.06673.x
   Kim C.Y., 2013, OXFORD HDB SYNESTHES, P283
   Maurer D, 2002, TRENDS COGN SCI, V6, P255, DOI 10.1016/S1364-6613(02)01903-4
   Maurer D., 2013, OXFORD HDB SYNESTHES, P46, DOI DOI 10.1093/OXFORDHB/9780199603329.013.0003
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   Maurer D, 2012, DEV PSYCHOBIOL, V54, P224, DOI 10.1002/dev.21022
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Maye J, 2001, PROC ANN BUCLD, P480
   Maye J, 2008, DEVELOPMENTAL SCI, V11, P122, DOI 10.1111/j.1467-7687.2007.00653.x
   McErlean ABJ, 2016, COGN NEUROPSYCHOL, V33, P378, DOI 10.1080/02643294.2016.1261820
   Mondloch CJ, 2002, PERCEPTION, V31, P553, DOI 10.1068/p3339
   Neufeld J, 2012, NEUROPSYCHOLOGIA, V50, P1471, DOI 10.1016/j.neuropsychologia.2012.02.032
   Pascalis O, 2002, SCIENCE, V296, P1321, DOI 10.1126/science.1070223
   Pascalis O, 2014, CHILD DEV PERSPECT, V8, P65, DOI 10.1111/cdep.12064
   Robbins RA, 2010, DEV PSYCHOBIOL, V52, P775, DOI 10.1002/dev.20473
   Rothen N, 2013, J NEUROSCI METH, V215, P156, DOI 10.1016/j.jneumeth.2013.02.009
   Rouw R, 2007, NAT NEUROSCI, V10, P792, DOI 10.1038/nn1906
   Rouw R, 2016, NEUROPSYCHOLOGIA, V88, P35, DOI 10.1016/j.neuropsychologia.2016.01.006
   Rouw R, 2010, J NEUROSCI, V30, P6205, DOI 10.1523/JNEUROSCI.3444-09.2010
   Sadato N, 1996, NATURE, V380, P526, DOI 10.1038/380526a0
   Scott LS, 2009, PSYCHOL SCI, V20, P676, DOI 10.1111/j.1467-9280.2009.02348.x
   Shriki O, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1004959
   Simner J., 2013, OXFORD HDB SYNESTHES, DOI [10.1093/oxfordhb/9780199603329.001.0001, DOI 10.1093/OXFORDHB/9780199603329.001.0001]
   Simner J, 2006, PERCEPTION, V35, P1024, DOI 10.1068/p5469
   Simpson EA, 2011, INFANCY, V16, P318, DOI 10.1111/j.1532-7078.2010.00052.x
   Sinke C, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00021
   Slater A, 2010, CHILD DEV PERSPECT, V4, P205, DOI 10.1111/j.1750-8606.2010.00147.x
   Spector F, 2009, DEV PSYCHOL, V45, P175, DOI 10.1037/a0014171
   Takesian AE, 2013, PROG BRAIN RES, V207, P3, DOI 10.1016/B978-0-444-63327-9.00001-1
   Tilot AK, 2018, P NATL ACAD SCI USA, V115, P3168, DOI 10.1073/pnas.1715492115
   Tomson SN, 2011, BEHAV BRAIN RES, V223, P48, DOI 10.1016/j.bbr.2011.03.071
   van Leeuwen TM, 2019, PHILOS T R SOC B, V374, DOI 10.1098/rstb.2019.0024
   van Praag CDG, 2016, NEUROPSYCHOLOGIA, V88, P5, DOI 10.1016/j.neuropsychologia.2016.04.016
   Voss P, 2016, FRONT SYST NEUROSCI, V10, DOI [10.3389/fnsys.2016.00062, 10.3389/fnsys.2010.00062]
   Ward J, 2019, MEMORY, V27, P1299, DOI 10.1080/09658211.2019.1646771
   Ward J, 2018, CORTEX, V107, P121, DOI 10.1016/j.cortex.2017.10.008
   Ward J, 2018, CONSCIOUS COGN, V61, P79, DOI 10.1016/j.concog.2018.03.012
   Ward J, 2017, SCI REP-UK, V7, DOI 10.1038/srep41155
   Watson MR, 2017, CONSCIOUS COGN, V48, P212, DOI 10.1016/j.concog.2016.12.004
   Watson MR, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00098
   Weiss PH, 2009, BRAIN, V132, P65, DOI 10.1093/brain/awn304
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1988, DEV PSYCHOL, V24, P672, DOI 10.1037/0012-1649.24.5.672
   Witthoft N, 2006, CORTEX, V42, P175, DOI 10.1016/S0010-9452(08)70342-3
   Witthoft N, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118996
   Yoshida KA, 2010, INFANCY, V15, P420, DOI 10.1111/j.1532-7078.2009.00024.x
   Zamm A, 2013, NEUROIMAGE, V74, P359, DOI 10.1016/j.neuroimage.2013.02.024
NR 77
TC 1
Z9 1
U1 15
U2 17
PU NATL ACAD SCIENCES
PI WASHINGTON
PA 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA
SN 0027-8424
J9 P NATL ACAD SCI USA
JI Proc. Natl. Acad. Sci. U. S. A.
PD MAY 5
PY 2020
VL 117
IS 18
BP 10089
EP 10096
DI 10.1073/pnas.1914668117
PG 8
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA LK7UR
UT WOS:000531067600060
PM 32321833
OA Bronze, Green Published
DA 2021-02-24
ER

PT J
AU Mehta, A
   Luck, JM
AF Mehta, Anita
   Luck, Jean-marc
TI HEARINGS AND MISHEARINGS: DECRYPTING THE SPOKEN WORD
SO ADVANCES IN COMPLEX SYSTEMS
LA English
DT Article
DE Speech recognition; mishearings; combinatorial optimization
ID SPIN-GLASS; LOCALIZATION; MODELS
AB We propose a model of the speech perception of individual words in the presence of mishearings. This phenomenological approach is based on concepts used in linguistics, and provides a formalism that is universal across languages. We put forward an efficient two-parameter form for the word length distribution, and introduce a simple representation of mishearings, which we use in our subsequent modeling of word recognition. In a context-free scenario, word recognition often occurs via anticipation when, part-way into a word, we can correctly guess its full form. We give a quantitative estimate of this anticipation threshold when no mishearings occur, in terms of model parameters. As might be expected, the whole anticipation effect disappears when there are sufficiently many mishearings. Our global approach to the problem of speech perception is in the spirit of an optimization problem. We show for instance that speech perception is easy when the word length is less than a threshold, to be identified with a static transition, and hard otherwise. We extend this to the dynamics of word recognition, proposing an intuitive approach highlighting the distinction between individual, isolated mishearings and clusters of contiguous mishearings. At least in some parameter range, a dynamical transition is manifest well before the static transition is reached, as is the case for many other examples of complex systems.
C1 [Mehta, Anita] Univ Oxford, Ctr Linguist & Philol, Walton St, Oxford OX1 2HG, England.
   [Luck, Jean-marc] Univ Paris Saclay, CNRS, CEA, Inst Phys Theor, F-91191 Gif Sur Yvette, France.
RP Luck, JM (corresponding author), Univ Paris Saclay, CNRS, CEA, Inst Phys Theor, F-91191 Gif Sur Yvette, France.
EM anita.mehta@ling-phil.ox.ac.uk; jean-marc.luck@ipht.fr
FU Leverhulme TrustLeverhulme Trust
FX We are grateful to Peter Stadler for having pointed us towards the
   Leipzig Corpora Collection, and to Aditi Lahiri and Henning Reetz for
   having made us aware of the CELEX database. AM warmly thanks the
   Leverhulme Trust for the Visiting Professorship that funded this
   research, as well as the Faculty of Linguistics, Philology and Phonetics
   at the University of Oxford, for their hospitality.
CR Abrahams E., 2010, 50 YEARS ANDERSON LO
   Altmann E. G., 2016, CREATIVITY UNIVERSAL
   BAAYEN RH, 1995, CELEX DATABASE
   Baxter R.J., 1982, EXACTLY SOLVED MODEL
   BINDER K, 1986, REV MOD PHYS, V58, P801, DOI 10.1103/RevModPhys.58.801
   Blythe RA, 2015, EUR PHYS J B, V88, DOI 10.1140/epjb/e2015-60347-3
   Cancho RFI, 2001, P ROY SOC B-BIOL SCI, V268, P2261, DOI 10.1098/rspb.2001.1800
   Castellani T, 2005, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2005/05/P05012
   CORRAL A, 2020, ENTROPY-SWITZ, V22, DOI DOI 10.3390/e22020224
   Crisanti A., 1992, SPRINGER SERIES SOLI
   Eckart T., 2013, BUILDING USING COMP
   Eroglu S, 2013, PHYSICA A, V392, P2775, DOI 10.1016/j.physa.2013.02.012
   Garey M.R., 1979, COMPUTERS INTRACTABI
   Grzybek P., 2007, TEXT SPEECH LANGUAGE
   Gussenhoven C., 2011, UNDERSTANDING PHONOL
   HAVLIN S, 1987, ADV PHYS, V36, P695, DOI 10.1080/00018738700101072
   Hayes B., 2009, INTRO PHONOLOGY
   KIRKPATRICK TR, 1987, PHYS REV B, V36, P5388, DOI 10.1103/PhysRevB.36.5388
   Klemm K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034780
   KRAMER B, 1993, REP PROG PHYS, V56, P1469, DOI 10.1088/0034-4885/56/12/001
   Krzakala F, 2007, P NATL ACAD SCI USA, V104, P10318, DOI 10.1073/pnas.0703685104
   Kwapien J, 2012, PHYS REP, V515, P115, DOI 10.1016/j.physrep.2012.01.007
   Ladefoged Peter, 1975, COURSE PHONETICS
   LAHIRI A, 1991, COGNITION, V38, P245, DOI 10.1016/0010-0277(91)90008-R
   Lahiri A., 2011, OXFORD HDB LAB PHONO
   Lahiri A, 2010, J PHONETICS, V38, P44, DOI 10.1016/j.wocn.2010.01.002
   MARINARI E, 1994, J PHYS A-MATH GEN, V27, P7647, DOI 10.1088/0305-4470/27/23/011
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   Mehta A, 2008, P NATL ACAD SCI USA, V105, P8244, DOI 10.1073/pnas.0711733105
   Mezard M., 1987, SPIN GLASS THEORY
   Monasson R, 1999, NATURE, V400, P133
   PALADIN G, 1987, PHYS REP, V156, P147, DOI 10.1016/0370-1573(87)90110-4
   Ruml W, 1996, J OPTIMIZ THEORY APP, V89, P251, DOI 10.1007/BF02192530
   Segev M, 2013, NAT PHOTONICS, V7, P197, DOI [10.1038/NPHOTON.2013.30, 10.1038/nphoton.2013.30]
   Sigurd B, 2004, STUD LINGUISTICA, V58, P37, DOI 10.1111/j.0039-3193.2004.00109.x
   STANLEY HE, 1988, NATURE, V335, P405, DOI 10.1038/335405a0
   Stauffer D., 1992, INTRO PERCOLATION TH
   van Rossum MCW, 1999, REV MOD PHYS, V71, P313, DOI 10.1103/RevModPhys.71.313
NR 38
TC 1
Z9 1
U1 1
U2 1
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0219-5259
EI 1793-6802
J9 ADV COMPLEX SYST
JI Adv. Complex Syst.
PD MAY
PY 2020
VL 23
IS 3
AR 2050008
DI 10.1142/S0219525920500083
PG 21
WC Mathematics, Interdisciplinary Applications; Multidisciplinary Sciences
SC Mathematics; Science & Technology - Other Topics
GA PG7QP
UT WOS:000599926000003
DA 2021-02-24
ER

PT J
AU Campbell, J
   Nielsen, M
   LaBrec, A
   Bean, C
AF Campbell, Julia
   Nielsen, Mashhood
   LaBrec, Alison
   Bean, Connor
TI Sensory Inhibition Is Related to Variable Speech Perception in Noise in
   Adults With Normal Hearing
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID INDIVIDUAL-DIFFERENCES; COCHLEAR SYNAPTOPATHY; P50; BRAIN; AMPLITUDE;
   DEFICITS; ATTENTION; RESPONSES; LATENCY
AB Purpose: Speech perception in noise (SPiN) varies widely in individuals with normal hearing, which may be attributed to factors that are not reflected in the audiogram, such as inhibition. However, inhibition is involved at both sensory and cognitive stages of auditory perception, and while inhibition at the cognitive level has been shown to be a significant factor in SPiN processes, it is unknown whether sensory inhibition may also contribute to SPiN variability. Therefore, the goal of this study was to evaluate sensory inhibition in adults with normal hearing and mild SPiN impairment.
   Method: Cortical auditory evoked potentials (CAEPs) were recorded in 49 adults via high-density electroencephalography using an auditory gating paradigm. Participants were categorized according to a median signal-to-noise ratio (SNR) loss of 1.5 dB: typical SNR loss <= 1.5 dB (n = 32), mild SNR loss > 1.5 dB (n = 17). CAEP gating responses were compared and correlated with SNR loss and extended high-frequency thresholds. Current density reconstructions were performed to qualitatively observe underlying cortical inhibitory networks in each group.
   Results: In comparison to adults with typical SPiN ability, adults with mild SPiN impairment showed an absence of the gating response. A CAEP gating component (P2) reflected decreased sensory inhibition and correlated with increased SNR loss. Extended high-frequency thresholds were also found to correlate with SNR loss, but not gating function. An atypical cortical inhibitory network was observed in the mild SNR loss group, with reduced frontal and absent prefrontal activation.
   Conclusion: Sensory inhibition appears to be atypical and related to SPiN deficits in adults with mild impairment. In addition, cortical inhibitory networks appear to be incomplete, with a possible compensatory parietal network. Further research is needed to delineate between types or levels of central inhibitory mechanisms and their contribution to SPiN processes.
C1 [Campbell, Julia; Nielsen, Mashhood; LaBrec, Alison; Bean, Connor] Univ Texas Austin, Dept Commun Sci & Disorders, Cent Sensory Proc Lab, Austin, TX 78712 USA.
RP Campbell, J (corresponding author), Univ Texas Austin, Dept Commun Sci & Disorders, Cent Sensory Proc Lab, Austin, TX 78712 USA.
EM Julia.Campbell@Austin.UTexas.EDU
FU Hearing Health Foundation Emerging Research Grant; Les Paul Foundation;
   Texas Speech-Language-Hearing Foundation Lear Ashmore Research Fund
FX This work was supported by the Hearing Health Foundation Emerging
   Research Grant (2016) through the Les Paul Foundation and the Texas
   Speech-Language-Hearing Foundation Lear Ashmore Research Fund (2016),
   both awarded to J. C. The authors would like to thank Craig Champlin for
   his invaluable comments on the article and overall assistance on the
   research design.
CR Ambrosini A, 2001, NEUROSCI LETT, V306, P132, DOI 10.1016/S0304-3940(01)01871-7
   American National Standards Institute, 2010, S362010 ANSIASA
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bharadwaj HM, 2015, J NEUROSCI, V35, P2161, DOI 10.1523/JNEUROSCI.3915-14.2015
   Boutros NN, 2013, CLIN NEUROPHYSIOL, V124, P675, DOI 10.1016/j.clinph.2012.10.007
   Boutros NN, 2011, BIOL PSYCHIAT, V69, P883, DOI 10.1016/j.biopsych.2010.12.011
   Boutros NN, 2005, CLIN NEUROPHYSIOL, V116, P1967, DOI 10.1016/j.clinph.2005.04.017
   Campbell J, 2019, AM J AUDIOL, V28, P209, DOI 10.1044/2019_AJA-TTR17-18-0036
   Campbell J, 2018, AUDIOL RES, V8, P27, DOI 10.4081/audiores.2018.214
   Campbell J, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00277
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   Campbell J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00071
   Cheng CH, 2015, BRAIN COGNITION, V101, P64, DOI 10.1016/j.bandc.2015.10.004
   Coffey EBJ, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00479
   Cope TE, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01958-7
   Dalecki A, 2015, INT J PSYCHOPHYSIOL, V96, P149, DOI 10.1016/j.ijpsycho.2015.04.011
   Dalecki A, 2011, PSYCHOPHYSIOLOGY, V48, P1692, DOI 10.1111/j.1469-8986.2011.01262.x
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Delorme A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030135
   Demily C, 2016, PSYCHIAT RES, V246, P738, DOI 10.1016/j.psychres.2016.07.066
   Dryden A, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517744675
   Eggermont JJ, 2017, HEARING RES, V352, P12, DOI 10.1016/j.heares.2016.10.015
   Etymotic Research, 2006, QUICKSIN SPEECH IN N, DOI [10.1186/1743-0003-5-25, DOI 10.1186/1743-0003-5-25]
   Fuchs M, 2002, CLIN NEUROPHYSIOL, V113, P702, DOI 10.1016/S1388-2457(02)00030-5
   Fuerst DR, 2007, PSYCHOPHYSIOLOGY, V44, P620, DOI 10.1111/j.1469-8986.2007.00524.x
   Gilley PM, 2008, BRAIN RES, V1239, P56, DOI 10.1016/j.brainres.2008.08.026
   Golubic SJ, 2017, HUM BRAIN MAPP, V38, P5180, DOI 10.1002/hbm.23724
   Grech R, 2008, J NEUROENG REHABIL, V5, DOI 10.1186/1743-0003-5-25
   Grunwald T, 2003, BIOL PSYCHIAT, V53, P511, DOI 10.1016/S0006-3223(02)01673-6
   Hamilton HK, 2018, AM J PSYCHIAT, V175, P275, DOI 10.1176/appi.ajp.2017.16111203
   Helfer KS, 2015, J ACOUST SOC AM, V138, P363, DOI 10.1121/1.4923155
   Hixson SM, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152264
   Hurst R, 2013, PHARMACOL THERAPEUT, V137, P22, DOI 10.1016/j.pharmthera.2012.08.012
   Janse E, 2012, AGING NEUROPSYCHOL C, V19, P741, DOI 10.1080/13825585.2011.652590
   Javitt DC, 2015, AM J PSYCHIAT, V172, P17, DOI 10.1176/appi.ajp.2014.13121691
   Jones LA, 2016, BRAIN COGNITION, V102, P33, DOI 10.1016/j.bandc.2015.12.005
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Killion Mead C., 2002, Seminars in Hearing, V23, P57, DOI 10.1055/s-2002-24976
   KNIGHT RT, 1989, BRAIN RES, V504, P338, DOI 10.1016/0006-8993(89)91381-4
   Knight RT, 1999, ACTA PSYCHOL, V101, P159, DOI 10.1016/S0001-6918(99)00004-9
   Knight S, 2019, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02779
   Knight S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00230
   Knott VJ, 2010, NEUROSCIENCE, V170, P816, DOI 10.1016/j.neuroscience.2010.07.012
   Knott V, 2013, J PSYCHOPHARMACOL, V27, P790, DOI 10.1177/0269881113490449
   Knott V, 2009, NEUROIMAGE, V44, P992, DOI 10.1016/j.neuroimage.2008.10.002
   Knudsen EI, 2007, ANNU REV NEUROSCI, V30, P57, DOI 10.1146/annurev.neuro.30.051606.094256
   Kobel M, 2017, HEARING RES, V349, P148, DOI 10.1016/j.heares.2016.12.008
   Kohl S, 2013, J PSYCHIATR RES, V47, P445, DOI 10.1016/j.jpsychires.2012.11.018
   Korzyukov O, 2007, NEUROIMAGE, V35, P814, DOI 10.1016/j.neuroimage.2006.12.011
   Lamminmaki S, 2014, EAR HEARING, V35, P461, DOI 10.1097/AUD.0000000000000033
   Liberman MC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162726
   Lijffijt M, 2009, PSYCHOPHYSIOLOGY, V46, P1059, DOI 10.1111/j.1469-8986.2009.00845.x
   Makeig S, 2004, PLOS BIOL, V2, P747, DOI 10.1371/journal.pbio.0020176
   Makeig S, 1997, P NATL ACAD SCI USA, V94, P10979, DOI 10.1073/pnas.94.20.10979
   Mayer AR, 2009, NEUROIMAGE, V44, P182, DOI 10.1016/j.neuroimage.2008.08.025
   Mehraei G, 2016, J NEUROSCI, V36, P3755, DOI 10.1523/JNEUROSCI.4460-15.2016
   Moore DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107720
   Musiek FE, 2017, J AM ACAD AUDIOL, V28, P655, DOI 10.3766/jaaa.16061
   Papesh MA, 2019, J NEUROTRAUM, V36, P702, DOI 10.1089/neu.2018.5801
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P5
   Patterson JV, 2008, PSYCHIAT RES, V158, P226, DOI 10.1016/j.psychres.2007.02.009
   Paul BT, 2017, J ACOUST SOC AM, V142, pEL434, DOI 10.1121/1.5009603
   Peelle JE, 2018, EAR HEARING, V39, P204, DOI 10.1097/AUD.0000000000000494
   Ruggles D, 2011, P NATL ACAD SCI USA, V108, P15516, DOI 10.1073/pnas.1108912108
   Shinn-Cunningham B, 2017, J SPEECH LANG HEAR R, V60, P2976, DOI 10.1044/2017_JSLHR-H-17-0080
   Smith DM, 2013, CLIN NEUROPHYSIOL, V124, P1329, DOI 10.1016/j.clinph.2013.02.004
   Tremblay KL, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00028
   Van Tricht MJ, 2015, WORLD J BIOL PSYCHIA, V16, P12, DOI 10.3109/15622975.2012.680911
   Veneman CE, 2013, EAR HEARING, V34, P288, DOI 10.1097/AUD.0b013e31826d0b81
   Vlcek P, 2014, NEUROPSYCH DIS TREAT, V10, P1309, DOI 10.2147/NDT.S64219
   Yeend I, 2019, EAR HEARING, V40, P458, DOI 10.1097/AUD.0000000000000640
NR 71
TC 1
Z9 1
U1 7
U2 7
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD MAY
PY 2020
VL 63
IS 5
BP 1595
EP 1607
DI 10.1044/2020_JSLHR-19-00261
PG 13
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA ND2XF
UT WOS:000561767400022
PM 32402215
DA 2021-02-24
ER

PT J
AU Bhide, A
   Ortega-Llebaria, M
   Fraundorf, SH
   Perfetti, CA
AF Bhide, Adeetee
   Ortega-Llebaria, Marta
   Fraundorf, Scott H.
   Perfetti, Charles A.
TI The contribution of orthographic input, phonological skills, and rise
   time discrimination to the learning of non-native phonemic contrasts
SO APPLIED PSYCHOLINGUISTICS
LA English
DT Article
DE dental/retroflex contrasts; L1 interference; non-native contrasts;
   orthographic facilitation; phonological awareness; rise time
   discrimination
ID SPEECH-PERCEPTION; LANGUAGE; WORDS; LEARNERS; ADULTS; FORMS;
   FACILITATION; INFORMATION; ABILITY
AB Although learning second language phonology is a difficult task, orthographic input may support the learning of difficult sound contrasts through a process known as orthographic facilitation. We extended this research by examining the effects of orthographic input together with individual differences in three different phonological learning processes, namely, the production of, perception of, and memorization of words containing three Marathi phonemic contrasts (i.e., [k-k(h)], [d-d], and [t-t]) by native English speakers. Moreover, because the [d-d] and [t-t] contrasts were particularly challenging in previous auditory training studies (e.g., Polka, 1991), we used cross-modal training in order to enhance learning by pairing auditory perception tasks with visual orthographic information, the amplification of relevant acoustic cues, and proprioceptive descriptions to the articulation of target phonemes. Results showed significant learning from the pre- to the posttest across tasks and contrasts, supporting the effectiveness of cross-modal training. Furthermore, incongruent orthographic input could inhibit perception, and orthographic input generally supported memory for word pronunciations. Moreover, individual differences regarding phonological skills and nonspeech auditory discrimination predicted participants' success in different phonological learning processes. These results provide a detailed picture of the complexity between different aspects of second language phonological learning and cross-modal training.
C1 [Bhide, Adeetee; Ortega-Llebaria, Marta; Fraundorf, Scott H.; Perfetti, Charles A.] Univ Pittsburgh, Pittsburgh, PA 15260 USA.
RP Bhide, A (corresponding author), Univ Pittsburgh, Pittsburgh, PA 15260 USA.
EM arbhide89@gmail.com
FU NSF PSLC Grant [SBE08-36012]; Andrew Mellon Predoctoral Fellowship
FX This research partially fulfills the dissertation requirements for A.B.
   We would like to thank A.B.'s committee members, Natasha Tokowicz and
   Julie Fiez, for their assistance. We would also like to thank Austin
   Marcus, Sonali Agrawal, and Aarya Wadke for their assistance running
   participants. Kimberly Muth assisted with participant payment. We would
   also like to thank Aarya Wadke, Sonali Agrawal, Austin Marcus, Paula
   Pascual, and Elena Cimino for their help editing the sound files. Sonali
   Agrawal and Aarya Wadke also helped with coding the data. Soniya Gadgil,
   Shalaka Fadnis, and Aarya Wadke helped pilot the study. Sound recordings
   were generously provided by Sudheer Apte, Dnyanada Bhide, Rajeev Bhide,
   Shirish Kher, Uma Kher, Punit Marathe, and Soniya Gadgil. Melinda Fricke
   assisted with Praat. Lori Holt and Casey Roark provided theoretical
   guidance. Many people gave useful feedback at the SSSR conference. This
   research was supported by NSF PSLC Grant SBE08-36012 and the Andrew
   Mellon Predoctoral Fellowship (awarded to A.B.).
CR Ahmad D, 2005, YALE J CRIT, V18, P1, DOI 10.1353/yale.2005.0002
   Altman D., 1991, PRACTICAL STAT MED R
   [Anonymous], 2012, REV DROIT UNION EURO, V1, P9, DOI DOI 10.4312/ALA.1.2.9-24
   Bassetti B., 2007, COGNITION LEARNING T
   Bassetti B, 2015, APPL PSYCHOLINGUIST, V36, P67, DOI 10.1017/S0142716414000435
   Bassetti B, 2006, WRIT LANG LIT, V9, P95, DOI 10.1075/wll.9.1.07bas
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best C. T., 1991, SR107108 HASK LAB
   Best C. T., 2007, 2 LANGUAGE SPEECH LE
   Bhatia T. K., 2008, COLLOQUIAL HINDI COM
   Bhide A., 2019, HDB LITERACY AKSHARA
   Bhide A., 2014, WRIT SYST RES, V6, P73, DOI [10.1080/17586801.2013.855619, DOI 10.1080/17586801.2013.855619]
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bolozky S., 1997, PHONOLOGIES ASIA AFR, P287
   Brown K. E., 2015, THESIS
   BURNHAM DK, 1986, APPL PSYCHOLINGUIST, V7, P207, DOI 10.1017/S0142716400007542
   Chambre SJ, 2017, READ WRIT, V30, P1137, DOI 10.1007/s11145-016-9715-z
   Chung I., 2007, THESIS
   Chung W.-L., 2017, 24 ANN C SOC SCI STU
   Cibelli E. S., 2015, THESIS
   Cutler A, 2015, APPL PSYCHOLINGUIST, V36, P115, DOI 10.1017/S0142716414000459
   Defior S., 2017, READING ACQUISITION, P270, DOI [10.1017/9781316155752.011, DOI 10.1017/9781316155752.011]
   Ehri L. C., 2017, 24 ANN C SOC SCI STU
   EHRI LC, 1980, APPL PSYCHOLINGUIST, V1, P371, DOI 10.1017/S0142716400009802
   Escudero P, 2008, J PHONETICS, V36, P345, DOI 10.1016/j.wocn.2007.11.002
   Escudero P, 2015, APPL PSYCHOLINGUIST, V36, P7, DOI 10.1017/S014271641400040X
   Escudero P, 2014, BILING-LANG COGN, V17, P384, DOI 10.1017/S1366728913000436
   Gabay Y, 2015, CORTEX, V73, P131, DOI 10.1016/j.cortex.2015.08.008
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Goswami U, 2011, DEVELOPMENTAL SCI, V14, P34, DOI 10.1111/j.1467-7687.2010.00955.x
   Guion S. G., 2007, LANGUAGE EXPERIENCE, P57, DOI [DOI 10.1075/LLLT.17.09GUI, 10.1075/lllt.17.09gui]
   Gussmann Edmund, 2007, PHONOLOGY POLISH
   Hamann Silke, 2003, THESIS
   Hanulikova A, 2010, J INT PHON ASSOC, V40, P373, DOI 10.1017/S0025100310000162
   Hayes-Harb R, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00785
   Hayes-Harb R, 2010, LANG SPEECH, V53, P367, DOI 10.1177/0023830910371460
   Huss M, 2011, CORTEX, V47, P674, DOI 10.1016/j.cortex.2010.07.010
   Jackson J. L., 2016, THESIS
   JAMIESON DG, 1986, PERCEPT PSYCHOPHYS, V40, P205, DOI 10.3758/BF03211500
   Jiang ZH, 2017, 2017 INTERNATIONAL CONFERENCE ON FRONTIERS IN EDUCATIONAL TECHNOLOGIES AND MANAGEMENT SCIENCES (FETMS 2017), P24
   Jubenville K, 2014, J EXP CHILD PSYCHOL, V126, P245, DOI 10.1016/j.jecp.2014.05.002
   KINGSTON J, 1994, LANGUAGE, V70, P419, DOI 10.2307/416481
   Landerl K., 2017, READING ACQUISITION, P299
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   LLAMZON TA, 1966, ANTHROPOL LINGUIST, V8, P30
   MacWhinney B, 2005, HDB BILINGUALISM PSY, P49
   MacWhinney B., 2012, ROUTLEDGE HDB 2 LANG, P221, DOI [10.4324/9780203808184.ch13., DOI 10.4324/9780203808184.CH13, 10.4324/9780203808184.ch13]
   McCandliss BD, 2002, COGN AFFECT BEHAV NE, V2, P89, DOI 10.3758/CABN.2.2.89
   McCullagh M., 2011, COMPANION LATIN LANG, P81, DOI [10.1002/9781444343397.ch6, DOI 10.1002/9781444343397.CH6]
   Melby-Lervag M, 2011, J RES READ, V34, P114, DOI 10.1111/j.1467-9817.2010.01477.x
   Meng Z., 1998, YUYIN YANJIU YU DUIW, P322
   Miles K. P., 2016, J COLL READING LEARN, V46, P99, DOI [10.1080/10790195.2015.1125818, DOI 10.1080/10790195.2015.1125818]
   OLSON R, 1989, J LEARN DISABIL, V22, P339, DOI 10.1177/002221948902200604
   Perfetti Charles A., 2002, PRECURSORS FUNCTIONA, P189, DOI DOI 10.1075/SWLL.11.14PER
   Phillips A. M., 2011, THESIS
   POLKA L, 1991, J ACOUST SOC AM, V89, P2961, DOI 10.1121/1.400734
   Rakhlin N. V., 2017, READING ACQUISITION, P393, DOI [10.1017/9781316155752.016, DOI 10.1017/9781316155752.016]
   Ricketts J, 2009, Q J EXP PSYCHOL, V62, P1948, DOI 10.1080/17470210802696104
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Showalter CE, 2015, APPL PSYCHOLINGUIST, V36, P23, DOI 10.1017/S0142716414000411
   Showalter CE, 2013, SECOND LANG RES, V29, P185, DOI 10.1177/0267658313480154
   Singh L, 2018, CHILD DEV, V89, pe397, DOI 10.1111/cdev.12852
   Slevc LR, 2006, PSYCHOL SCI, V17, P675, DOI 10.1111/j.1467-9280.2006.01765.x
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   TEES RC, 1984, CAN J PSYCHOL, V38, P579, DOI 10.1037/h0080868
   Tokowicz N., 2004, BILING-LANG COGN, V7, P255, DOI DOI 10.1017/S1366728904001634
   Verma R., 2003, P WORKSH SPOK LANG P
   Vlahou EL, 2012, J EXP PSYCHOL GEN, V141, P363, DOI 10.1037/a0025014
   Wade-Woolley L., 2000, SCI STUD READ, V4, P295, DOI DOI 10.1207/S1532799XSSR0404_3
   Walker D. C., 1984, PRONUNCIATION CANADI
   WERKER JF, 1983, CAN J PSYCHOL, V37, P278, DOI 10.1037/h0080725
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
   WERKER JF, 1989, AM SCI, V77, P54
   Ye J., 1997, WAIGUO XUESHENG HANY
   Young-Scholten M, 2002, INTEGRATED VIEW LANG, P263
   Young-Scholten M, 2015, APPL PSYCHOLINGUIST, V36, P93, DOI 10.1017/S0142716414000447
   Young-Scholten Martha, 1997, NEW SOUNDS, P351
NR 78
TC 0
Z9 0
U1 0
U2 0
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0142-7164
EI 1469-1817
J9 APPL PSYCHOLINGUIST
JI Appl. Psycholinguist.
PD MAY
PY 2020
VL 41
IS 3
BP 481
EP 516
AR PII S0142716419000511
DI 10.1017/S0142716419000511
PG 36
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA MX6OY
UT WOS:000557842000001
DA 2021-02-24
ER

PT J
AU Boll-Avetisyan, N
   Bhatara, A
   Hohle, B
AF Boll-Avetisyan, Natalie
   Bhatara, Anjali
   Hoehle, Barbara
TI Processing of Rhythm in Speech and Music in Adult Dyslexia
SO BRAIN SCIENCES
LA English
DT Article
DE developmental dyslexia; Iambic; Trochaic Law; rhythmic grouping;
   musicality; speech perception; rhythm perception
ID DEVELOPMENTAL DYSLEXIA; INDIVIDUAL-DIFFERENCES; METRICAL STRESS; POOR
   READERS; CHILDREN; PERCEPTION; SENSITIVITY; DURATION; ABILITY; AWARENESS
AB Recent studies have suggested that musical rhythm perception ability can affect the phonological system. The most prevalent causal account for developmental dyslexia is the phonological deficit hypothesis. As rhythm is a subpart of phonology, we hypothesized that reading deficits in dyslexia are associated with rhythm processing in speech and in music. In a rhythmic grouping task, adults with diagnosed dyslexia and age-matched controls listened to speech streams with syllables alternating in intensity, duration, or neither, and indicated whether they perceived a strong-weak or weak-strong rhythm pattern. Additionally, their reading and musical rhythm abilities were measured. Results showed that adults with dyslexia had lower musical rhythm abilities than adults without dyslexia. Moreover, lower musical rhythm ability was associated with lower reading ability in dyslexia. However, speech grouping by adults with dyslexia was not impaired when musical rhythm perception ability was controlled: like adults without dyslexia, they showed consistent preferences. However, rhythmic grouping was predicted by musical rhythm perception ability, irrespective of dyslexia. The results suggest associations among musical rhythm perception ability, speech rhythm perception, and reading ability. This highlights the importance of considering individual variability to better understand dyslexia and raises the possibility that musical rhythm perception ability is a key to phonological and reading acquisition.
C1 [Boll-Avetisyan, Natalie; Hoehle, Barbara] Univ Potsdam, Fac Human Sci, Res Focus Cognit Sci, SFB1287, Karl Liebknecht Str 24-25, D-14476 Potsdam, Germany.
   [Bhatara, Anjali] Univ Paris, Integrat Neurosci & Cognit Ctr, CNRS, UMR 8002, 45 Rue St Peres, F-75270 Paris, France.
RP Boll-Avetisyan, N (corresponding author), Univ Potsdam, Fac Human Sci, Res Focus Cognit Sci, SFB1287, Karl Liebknecht Str 24-25, D-14476 Potsdam, Germany.
EM nboll@uni-potsdam.de; bhatara@gmail.com; hoehle@uni-potsdam.de
OI Boll-Avetisyan, Natalie/0000-0001-5446-946X; Hohle,
   Barbara/0000-0002-9240-6117
FU Agence Nationale de la Recherche-Deutsche ForschungsgemeinschaftFrench
   National Research Agency (ANR) [09-FASHS-018, HO 1960/14-1, HO
   1960/15-1, ANR-13-FRAL-0010]; Deutsche Forschungsgemeinschaft (DFG,
   German Research Foundation)German Research Foundation (DFG)
   [317633480-SFB 1287]
FX This research was funded by two Agence Nationale de la
   Recherche-Deutsche Forschungsgemeinschaft grants (#09-FASHS-018 and HO
   1960/14-1 to Barbara Hohle and Thierry Nazzi, and HO 1960/15-1 and
   ANR-13-FRAL-0010 to Ranka Bijeljac-Babic and Barbara Hohle), and
   partially funded by the Deutsche Forschungsgemeinschaft (DFG, German
   Research Foundation)-project number 317633480-SFB 1287, Project C03.
CR Abboub N, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00292
   Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Baayen R.H., 2008, ANAL LINGUISTIC DATA
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beckman M. E., 1986, PHONOLOGY YB, V3, P255, DOI [DOI 10.1017/S095267570000066X, 10.1017/S095267570000066X]
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Bhatara A, 2016, COGNITIVE SCI, V40, P1816, DOI 10.1111/cogs.12300
   Bhatara A, 2013, J ACOUST SOC AM, V134, P3828, DOI 10.1121/1.4823848
   Bhide A, 2013, MIND BRAIN EDUC, V7, P113, DOI 10.1111/mbe.12016
   Bion RAH, 2011, LANG SPEECH, V54, P123, DOI 10.1177/0023830910388018
   Bishop DVM, 2004, PSYCHOL BULL, V130, P858, DOI 10.1037/0033-2909.130.6.858
   Bishop-Liebler P, 2014, DYSLEXIA, V20, P261, DOI 10.1002/dys.1479
   Boll-Avetisyan N, 2020, BILING-LANG COGN, V23, P1070, DOI 10.1017/S1366728920000140
   Boll-Avetisyan N, 2017, LAB PHONOL, V8, DOI 10.5334/labphon.91
   Boll-Avetisyan N, 2016, BILING-LANG COGN, V19, P971, DOI 10.1017/S1366728915000425
   Bolton T. L., 1894, AM J PSYCHOL, V6, P145, DOI DOI 10.2307/1410948
   Chan AS, 1998, NATURE, V396, P128, DOI 10.1038/24075
   Colling LJ, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00360
   Crowhurst MJ, 2014, PHONOLOGY, V31, P51, DOI 10.1017/S0952675714000037
   Cunitz K., 2016, THESIS
   de Bree E, 2008, PROC ANN BUCLD, P60
   de la Mora DM, 2013, ATTEN PERCEPT PSYCHO, V75, P92, DOI 10.3758/s13414-012-0371-3
   Dupoux E, 1997, J MEM LANG, V36, P406, DOI 10.1006/jmla.1996.2500
   Dupoux E, 2001, J ACOUST SOC AM, V110, P1606, DOI 10.1121/1.1380437
   Fox J, 2006, SOCIOL METHODOL, V36, P225, DOI 10.1111/j.1467-9531.2006.00180.x
   Frost RLA, 2017, J EXP PSYCHOL HUMAN, V43, P466, DOI 10.1037/xhp0000325
   Goswami U, 2019, LANG LINGUIST COMPAS, V13, DOI 10.1111/lnc3.12328
   Goswami U, 2015, NAT REV NEUROSCI, V16, P43, DOI 10.1038/nrn3836
   Goswami U, 2013, J MEM LANG, V69, P1, DOI 10.1016/j.jml.2013.03.001
   Goswami U, 2013, CORTEX, V49, P1363, DOI 10.1016/j.cortex.2012.05.005
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Goswami U, 2010, READ WRIT, V23, P995, DOI 10.1007/s11145-009-9186-6
   Hamalainen JA, 2013, J LEARN DISABIL-US, V46, P413, DOI 10.1177/0022219411436213
   Hay JF, 2012, INFANCY, V17, P610, DOI 10.1111/j.1532-7078.2011.00110.x
   Hayes Bruce, 1995, METRICAL STRESS THEO
   Ho YC, 2003, NEUROPSYCHOLOGY, V17, P439, DOI 10.1037/0894-4105.17.3.439
   Holliman AJ, 2008, BRIT J DEV PSYCHOL, V26, P357, DOI 10.1348/026151007X241623
   Holliman AJ, 2010, EDUC PSYCHOL-UK, V30, P247, DOI 10.1080/01443410903560922
   Hulme C, 2016, CURR OPIN PEDIATR, V28, P731, DOI 10.1097/MOP.0000000000000411
   Huss M, 2011, CORTEX, V47, P674, DOI 10.1016/j.cortex.2010.07.010
   Iversen JR, 2008, J ACOUST SOC AM, V124, P2263, DOI 10.1121/1.2973189
   KLATT DH, 1976, J ACOUST SOC AM, V59, P1208, DOI 10.1121/1.380986
   Langus A, 2016, J EXP PSYCHOL LEARN, V42, P1127, DOI 10.1037/xlm0000226
   Lee HY, 2015, PSYCHOL REP, V116, P13, DOI 10.2466/15.28.PR0.116k15w8
   Leong V, 2011, J MEM LANG, V64, P59, DOI 10.1016/j.jml.2010.09.003
   Lerdahl F, 1983, GENERATIVE THEORY TO
   Levitin DJ, 2012, NEURON, V73, P633, DOI 10.1016/j.neuron.2012.01.017
   LIBERMAN M, 1977, LINGUIST INQ, V8, P249
   Molinaro N, 2016, HUM BRAIN MAPP, V37, P2767, DOI 10.1002/hbm.23206
   Moll K., 2010, SLRT
   Mottieir G, 1951, FOLIA PHONIATR, V3, P170, DOI 10.1159/000262507
   Narmour E., 1990, ANAL COGNITION BASIC
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   Patel AD, 2007, TRENDS COGN SCI, V11, P369, DOI 10.1016/j.tics.2007.08.003
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Petermann F., 2012, WAIS
   Power AJ, 2016, BRAIN LANG, V160, P1, DOI 10.1016/j.bandl.2016.06.006
   Power AJ, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00777
   Power AJ, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00216
   Protopapas A, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0090
   R Core Team, R LANG ENV STAT COMP
   Ramus F, 2003, CURR OPIN NEUROBIOL, V13, P212, DOI 10.1016/S0959-4388(03)00035-7
   Ramus F, 2008, Q J EXP PSYCHOL, V61, P129, DOI 10.1080/17470210701508822
   Rawlings JO, 2001, APPL REGRESSION ANAL
   Rice CC, 1992, THESIS
   Saito S, 2001, MEMORY, V9, P313, DOI 10.1080/09658210143000164
   Selkirk Elizabeth, 1984, PHONOLOGY SYNTAX REL
   Snowling M., 2000, DYSLEXIA
   Snowling M J, 2001, Dyslexia, V7, P37
   Strait D, 2011, MUSIC PERCEPT, V29, P133, DOI 10.1525/MP.2011.29.2.133
   Thomson JM, 2008, J PHYSIOL-PARIS, V102, P120, DOI 10.1016/j.jphysparis.2008.03.007
   Thomson JM, 2006, J RES READ, V29, P334, DOI 10.1111/j.1467-9817.2006.00312.x
   Thomson JM, 2013, READ WRIT, V26, P139, DOI 10.1007/s11145-012-9359-6
   TODD N, 1985, MUSIC PERCEPT, V3, P33
   Toro JM, 2015, BIOL LETTERS, V11, DOI 10.1098/rsbl.2015.0374
   Venables W. N, 2002, MODERN APPL STAT S
   Wallentin M, 2010, LEARN INDIVID DIFFER, V20, P188, DOI 10.1016/j.lindif.2010.02.004
   Westfall J., PANGEA POWER ANAL GE
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3_1
   Winter B, LINEAR MODELS LINEAR
   Wood C, 1998, BRIT J DEV PSYCHOL, V16, P397, DOI 10.1111/j.2044-835X.1998.tb00760.x
   Wood C, 2006, J RES READ, V29, P270, DOI 10.1111/j.1467-9817.2006.00308.x
   Woodrow H, 1951, HDB EXPT PSYCHOL, P1224
   Woodrow H, 1909, ARCH PSYCHOL, V14, P1
NR 84
TC 1
Z9 1
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3425
J9 BRAIN SCI
JI Brain Sci.
PD MAY
PY 2020
VL 10
IS 5
AR 261
DI 10.3390/brainsci10050261
PG 26
WC Neurosciences
SC Neurosciences & Neurology
GA LZ2CN
UT WOS:000541036100047
PM 32365799
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Idemaru, K
   Holt, LL
AF Idemaru, Kaori
   Holt, Lori L.
TI Generalization of dimension-based statistical learning
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Statistical learning; Dimension-based learning; Cue
   weighting; Generalization
ID INDIVIDUAL-DIFFERENCES; PHONOLOGICAL ABSTRACTION; VISUAL RECALIBRATION;
   SPEECH-PERCEPTION; PHONEMES; SPECIFICITY; INPUT
AB Recent research demonstrates that the relationship between an acoustic dimension and speech categories is not static. Rather, it is influenced by the evolving distribution of dimensional regularity experienced across time, and specific to experienced individual sounds. Three studies examine the nature of this perceptual, dimension-based statistical learning of artificially accented [b] and [p] speech categories in online word recognition by testing generalization of learning across contexts, and testing the effect of a larger word list across which learning is induced. The results indicate that whereas learning of accented [b] and [p] generalizes across contexts, generalization to contexts not experienced in the accent is weaker even for the same speech categories [b] and [p] spoken by the same speaker. The results support a rich model of speech representation that is sensitive to context-dependent variation in the way the acoustic dimensions are related to speech categories.
C1 [Idemaru, Kaori] Univ Oregon, Dept East Asian Languages & Literatures, Eugene, OR 97403 USA.
   [Holt, Lori L.] Carnegie Mellon Univ, Dept Psychol, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.
   [Holt, Lori L.] Carnegie Mellon Univ, Neurosci Inst, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.
RP Idemaru, K (corresponding author), Univ Oregon, Dept East Asian Languages & Literatures, Eugene, OR 97403 USA.
EM idemaru@uoregon.edu
FU National Science FoundationNational Science Foundation (NSF) [0746067]
   Funding Source: Medline; NIH HHSUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USA [R01DC004674,
   R01DC004674] Funding Source: Medline
CR Abramson A. S., 1985, PHONETIC LINGUISTICS, P25
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   BRESLOW NE, 1993, J AM STAT ASSOC, V88, P9, DOI 10.1080/01621459.1993.10594284
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Cutler A, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2056
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   HAGGARD M, 1970, J ACOUST SOC AM, V47, P613, DOI 10.1121/1.1911936
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   Idemaru K, 2014, J EXP PSYCHOL HUMAN, V40, P1009, DOI 10.1037/a0035269
   Idemaru K, 2013, J ACOUST SOC AM, V133, P4232, DOI 10.1121/1.4802905
   Idemaru K, 2012, J ACOUST SOC AM, V132, P3950, DOI 10.1121/1.4765076
   Idemaru K, 2011, J EXP PSYCHOL HUMAN, V37, P1939, DOI 10.1037/a0025641
   Idemaru K, 2008, J INT PHON ASSOC, V38, P167, DOI 10.1017/S0025100308003459
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Kong EJ, 2016, J PHONETICS, V59, P40, DOI 10.1016/j.wocn.2016.08.006
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   Lehet M, 2017, COGNITIVE SCI, V41, P885, DOI 10.1111/cogs.12413
   Liu R, 2015, J EXP PSYCHOL HUMAN, V41, P1783, DOI 10.1037/xhp0000092
   Lotto A.J., 2004, SOUND SENSE 50 YEARS, P181
   Maye J, 2001, PROC ANN BUCLD, P480
   McMurray B, 2005, COGNITION, V95, pB15, DOI 10.1016/j.cognition.2004.07.005
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   Meunier CL, 2017, FRONT ENV SCI-SWITZ, V5, DOI 10.3389/fenvs.2017.00018
   Mitterer H, 2018, J MEM LANG, V98, P77, DOI 10.1016/j.jml.2017.09.005
   Mitterer H, 2016, J PHONETICS, V56, P110, DOI 10.1016/j.wocn.2016.03.001
   Mitterer H, 2013, COGNITION, V129, P356, DOI 10.1016/j.cognition.2013.07.011
   NITTROUER S, 1992, J PHONETICS, V20, P351, DOI 10.1016/S0095-4470(19)30639-4
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Nusbaum HC, 1992, SPEECH PERCEPTION PR, P113
   R Core Team, 2016, R LANG ENV STAT COMP
   Reinisch E, 2016, J PHONETICS, V55, P96, DOI 10.1016/j.wocn.2015.12.004
   Reinisch E, 2014, J PHONETICS, V45, P91, DOI 10.1016/j.wocn.2014.04.002
   Reinisch E, 2014, J EXP PSYCHOL HUMAN, V40, P539, DOI 10.1037/a0034409
   Schertz J, 2016, ATTEN PERCEPT PSYCHO, V78, P355, DOI 10.3758/s13414-015-0987-1
   Theodore RM, 2015, J ACOUST SOC AM, V138, P1068, DOI 10.1121/1.4927489
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
   WHALEN DH, 1993, J ACOUST SOC AM, V93, P2152, DOI 10.1121/1.406678
   Zhang XJ, 2018, J EXP PSYCHOL HUMAN, V44, P1760, DOI 10.1037/xhp0000569
NR 41
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2020
VL 82
IS 4
BP 1744
EP 1762
DI 10.3758/s13414-019-01956-5
PG 19
WC Psychology; Psychology, Experimental
SC Psychology
GA LY5OH
UT WOS:000540578400018
PM 31907842
OA Bronze
DA 2021-02-24
ER

PT J
AU Chodroff, E
   Wilson, C
AF Chodroff, Eleanor
   Wilson, Colin
TI Acoustic-phonetic and auditory mechanisms of adaptation in the
   perception of sibilant fricatives
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Perceptual learning; Audition
ID S-VERTICAL-BAR; SPEECH-PERCEPTION; CONTRAST ENHANCEMENT; LISTENER
   SENSITIVITY; SELECTIVE ADAPTATION; SPECTRAL PROPERTIES; PRECEDING
   LIQUID; INVARIANT CUES; COMPENSATION; SPOKEN
AB Listeners are highly proficient at adapting to contextual variation when perceiving speech. In the present study, we examined the effects of brief speech and nonspeech contexts on the perception of sibilant fricatives. We explored three theoretically motivated accounts of contextual adaptation, based on phonetic cue calibration, phonetic covariation, and auditory contrast. Under thecue calibrationaccount, listeners adapt by estimating a talker-specific average for each phonetic cue or dimension; under thecue covariationaccount, listeners adapt by exploiting consistencies in how the realization of speech sounds varies across talkers; under theauditory contrastaccount, adaptation results from (partial) masking of spectral components that are shared by adjacent stimuli. The spectral center of gravity, a phonetic cue to fricative identity, was manipulated for several types of context sound: /z/-initial syllables, /v/-initial syllables, and white noise matched in long-term average spectrum (LTAS) to the /z/-initial stimuli. Listeners' perception of the /s/-/?/ contrast was significantly influenced by /z/-initial syllables and LTAS-matched white noise stimuli, but not by /v/-initial syllables. No significant difference in adaptation was observed between exposure to /z/-initial syllables and matched white noise stimuli, and speech did not have a considerable advantage over noise when the two were presented consecutively within a context. The pattern of findings is most consistent with the auditory contrast account of short-term perceptual adaptation. The cue covariation account makes accurate predictions for speech contexts, but not for nonspeech contexts or for the absence of a speech-versus-nonspeech difference.
C1 [Chodroff, Eleanor] Univ York, Dept Language & Linguist Sci, York YO10 5DD, N Yorkshire, England.
   [Wilson, Colin] Johns Hopkins Univ, Dept Cognit Sci, 3400 N Charles St, Baltimore, MD 21218 USA.
RP Chodroff, E (corresponding author), Univ York, Dept Language & Linguist Sci, York YO10 5DD, N Yorkshire, England.
EM eleanor.chodroff@york.ac.uk
CR Ainsworth WA, 1975, AUDITORY ANAL PERCEP, P103, DOI DOI 10.1016/B978-0-12-248550-3.50011-8
   Alexander JM, 2010, J ACOUST SOC AM, V128, P3597, DOI 10.1121/1.3500693
   Ali AMA, 2001, J ACOUST SOC AM, V109, P2217, DOI 10.1121/1.1357814
   Allen JS, 2004, J ACOUST SOC AM, V115, P3171, DOI 10.1121/1.1701898
   [Anonymous], 2015, THESIS
   ASSMANN PF, 1982, J ACOUST SOC AM, V71, P975, DOI 10.1121/1.387579
   Blacklock Oliver, 2004, THESIS
   BLAKEMORE C, 1969, J PHYSIOL-LONDON, V203, P237, DOI 10.1113/jphysiol.1969.sp008862
   Burkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   BYRD D, 1992, J ACOUST SOC AM, V92, P593, DOI 10.1121/1.404271
   Chladkova K., 2015, P 18 INT C PHON SCI
   Chladkova K, 2017, J EXP PSYCHOL HUMAN, V43, P414, DOI 10.1037/xhp0000333
   Chodroff E, 2017, J PHONETICS, V61, P30, DOI 10.1016/j.wocn.2017.01.001
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Cleland TA, 2006, BMC NEUROSCI, V7, DOI 10.1186/1471-2202-7-7
   COLE RA, 1974, PERCEPT PSYCHOPHYS, V15, P101, DOI 10.3758/BF03205836
   COWAN N, 1984, PSYCHOL BULL, V96, P341, DOI 10.1037/0033-2909.96.2.341
   DELATTRE PC, 1955, J ACOUST SOC AM, V27, P769, DOI 10.1121/1.1908024
   Dias JW, 2016, J PHONETICS, V56, P75, DOI 10.1016/j.wocn.2016.02.004
   Diehl R. L., 1989, ECOL PSYCHOL, V1, P121, DOI [10.1207/s15326969-co0102_2, DOI 10.1207/S15326969-CO0102_2, DOI 10.1207/s15326969eco0102_2]
   Durvasula K, 2018, P 2017 ANN M PHON
   Eisner F, 2006, J ACOUST SOC AM, V119, P1950, DOI 10.1121/1.2178721
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   Flipsen P, 1999, J SPEECH LANG HEAR R, V42, P663, DOI 10.1044/jslhr.4203.663
   FORREST K, 1988, J ACOUST SOC AM, V84, P115, DOI 10.1121/1.396977
   Fuchs S., 2010, TURBULENT SOUNDS INT, P281, DOI DOI 10.1515/9783110226584.281
   HARRIS KS, 1958, LANG SPEECH, V1, P1
   Hess RF, 1998, VISION RES, V38, P783, DOI 10.1016/S0042-6989(97)00333-7
   Hoffman MD, 2014, J MACH LEARN RES, V15, P1593
   Holt LL, 2005, PSYCHOL SCI, V16, P305, DOI 10.1111/j.0956-7976.2005.01532.x
   Holt LL, 2006, J ACOUST SOC AM, V120, P2801, DOI 10.1121/1.2354071
   Houtgast T, 1974, FACTS MODELS HEARING, P258
   HUGHES GW, 1956, J ACOUST SOC AM, V28, P303, DOI 10.1121/1.1908271
   Jakobson R., 1951, PRELIMINARIES SPEECH
   Johnson K, 1997, OHIO STATE U WORKING, V50, P115
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   Kingston J, 2014, ATTEN PERCEPT PSYCHO, V76, P1437, DOI 10.3758/s13414-013-0593-z
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kluender KR, 2003, SPEECH COMMUN, V41, P59, DOI 10.1016/S0167-6393(02)00093-6
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2008, PSYCHOL SCI, V19, P332, DOI 10.1111/j.1467-9280.2008.02090.x
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Laing EJC, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00203
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Liu L., 2018, THESIS
   Liu LD, 2018, COGNITION, V174, P55, DOI 10.1016/j.cognition.2018.01.003
   LOBANOV BM, 1971, J ACOUST SOC AM, V49, P606, DOI 10.1121/1.1912396
   Lotto AJ, 1998, PERCEPT PSYCHOPHYS, V60, P602, DOI 10.3758/BF03206049
   Maniwa K, 2009, J ACOUST SOC AM, V125, P3962, DOI 10.1121/1.2990715
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P407, DOI 10.3758/BF03204884
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P213, DOI 10.3758/BF03204377
   MARSLENWILSON W, 1994, PSYCHOL REV, V101, P653, DOI 10.1037/0033-295X.101.4.653
   Maye J, 2008, COGNITIVE SCI, V32, P543, DOI 10.1080/03640210802035357
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   MILLER JL, 1986, PHONETICA, V43, P106, DOI 10.1159/000261764
   Mitterer H, 2006, PHONETICA, V63, P209, DOI 10.1159/000097306
   Mitterer H, 2016, J PHONETICS, V56, P110, DOI 10.1016/j.wocn.2016.03.001
   MOORE BCJ, 1981, J ACOUST SOC AM, V70, P1003, DOI 10.1121/1.386950
   Nearey Terrance M., 2007, EXPT APPROACHES PHON, P246
   Nearey Terrance Michael, 1978, PHONETIC FEATURE SYS
   Nees MA, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01892
   Neisser U., 1967, COGNITIVE PSYCHOL
   Newman RS, 2001, J ACOUST SOC AM, V109, P1181, DOI 10.1121/1.1348009
   Nolan F., 1983, PHONETIC BASES SPEAK
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   PANTLE A, 1968, SCIENCE, V162, P1146, DOI 10.1126/science.162.3858.1146-a
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Reidy PF, 2016, J ACOUST SOC AM, V140, P2518, DOI 10.1121/1.4964510
   Reinisch E, 2014, J PHONETICS, V45, P91, DOI 10.1016/j.wocn.2014.04.002
   ROBERTS M, 1981, PERCEPT PSYCHOPHYS, V30, P309, DOI 10.3758/BF03206144
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   Seidl-Friedman A, 1999, AM ENGLISH SPOKEN LE
   Sjerps MJ, 2011, ATTEN PERCEPT PSYCHO, V73, P1195, DOI 10.3758/s13414-011-0096-8
   SOLI SD, 1981, J ACOUST SOC AM, V70, P976, DOI 10.1121/1.387032
   Stelmachowicz PG, 2001, J ACOUST SOC AM, V110, P2183, DOI 10.1121/1.1400757
   STEVENS KN, 1978, J ACOUST SOC AM, V64, P1358, DOI 10.1121/1.382102
   STEVENS KN, 1989, LANGUAGE, V65, P81, DOI 10.2307/414843
   Stilp CE, 2017, J ACOUST SOC AM, V141, pEL153, DOI 10.1121/1.4974769
   Stilp CE, 2015, J ACOUST SOC AM, V137, P3466, DOI 10.1121/1.4921600
   Strand EA, 1996, NATURAL LANGUAGE PROCESSING AND SPEECH TECHNOLOGY, P14
   STRANGE W, 1976, J ACOUST SOC AM, V60, P213, DOI 10.1121/1.381066
   SUMMERFIELD Q, 1987, J ACOUST SOC AM, V81, P700, DOI 10.1121/1.394838
   Theodore RM, 2010, J ACOUST SOC AM, V128, P2090, DOI 10.1121/1.3467771
   TRAUNMULLER H, 1990, J ACOUST SOC AM, V88, P97, DOI 10.1121/1.399849
   Trude AM, 2012, LANG COGNITIVE PROC, V27, P979, DOI 10.1080/01690965.2011.597153
   Vasishth S, 2018, J PHONETICS, V71, P147, DOI 10.1016/j.wocn.2018.07.008
   WATKINS AJ, 1991, J ACOUST SOC AM, V90, P2942, DOI 10.1121/1.401769
   WATKINS AJ, 1994, J ACOUST SOC AM, V96, P1263, DOI 10.1121/1.410275
   Watkins AJ, 1996, J ACOUST SOC AM, V99, P3749, DOI 10.1121/1.414981
   Winn M, 2014, PRAAT SCRIPT CREATE
   Wright Richard, 2004, PHONETICALLY BASED P, P34, DOI DOI 10.1017/CBO9780511486401.002
   Yang J, 2003, SPEECH COMMUN, V39, P33, DOI 10.1016/S0167-6393(02)00057-2
   Yu ACL, 2019, LAB PHONOL, V10, DOI 10.5334/labphon.97
NR 97
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2020
VL 82
IS 4
BP 2027
EP 2048
DI 10.3758/s13414-019-01894-2
PG 22
WC Psychology; Psychology, Experimental
SC Psychology
GA LY5OH
UT WOS:000540578400038
PM 31875314
OA Green Published, Other Gold, Green Accepted
DA 2021-02-24
ER

PT J
AU Zaltz, Y
   Bugannim, Y
   Zechoval, D
   Kishon-Rabin, L
   Perez, R
AF Zaltz, Yael
   Bugannim, Yossi
   Zechoval, Doreen
   Kishon-Rabin, Liat
   Perez, Ronen
TI Listening in Noise Remains a Significant Challenge for Cochlear Implant
   Users: Evidence from Early Deafened and Those with Progressive Hearing
   Loss Compared to Peers with Normal Hearing
SO JOURNAL OF CLINICAL MEDICINE
LA English
DT Article
DE Cochlear implant; hearing impairment; speech-in-noise; speech
   recognition; prelingually deafened; postlingually deafened; congenital
   hearing loss; progressive hearing loss; top-down processing; bottom-up
   processing
ID SPEECH-PERCEPTION; WORKING-MEMORY; CHILDREN; AGE; PERFORMANCE; LANGUAGE;
   SKILLS; RECOGNITION; COGNITION; ADULTS
AB Cochlear implants (CIs) are the state-of-the-art therapy for individualswith severe to profound hearing loss, providing them with good functional hearing. Nevertheless, speech understanding in background noise remains a significant challenge. The purposes of this study were to: (1) conduct a novelwithin-study comparison of speech-in-noise performance across ages in different populations of CI and normal hearing (NH) listeners using an adaptive sentence-in-noise test, and (2) examine the relative contribution of sensory information and cognitive-linguistic factors to performance. Forty CI users (mean age 20 years) were divided into "early-implanted" <4 years (n = 16) and "late-implanted" >6 years (n = 11), all prelingually deafened, and "progressively deafened" (n = 13). The control group comprised 136 NH subjects (80 children, 56 adults). Testing included the Hebrew Matrix test, word recognition in quiet, and linguistic and cognitive tests. Results show poorer performance in noise for CI users across populations and ages compared to NH peers, and age at implantation and word recognition in quiet were found to be contributing factors. For those recognizing 50% or more of the words in quiet (n = 27), non-verbal intelligence and receptive vocabulary explained 63% of the variance in noise. This information helps delineate the relative contribution of top-down and bottom-up skills for speech recognition in noise and can help set expectations in CI counseling.
C1 [Zaltz, Yael; Bugannim, Yossi; Zechoval, Doreen; Kishon-Rabin, Liat] Tel Aviv Univ, Sackler Fac Med, Steyer Sch Hlth Profess, Dept Commun Disorders, IL-6997801 Tel Aviv, Israel.
   [Perez, Ronen] Hebrew Univ Jerusalem, Med Sch, Shaare Zedek Med Ctr, Dept Otolaryngol & Head & Neck Surg, IL-9190501 Jerusalem, Israel.
RP Zaltz, Y (corresponding author), Tel Aviv Univ, Sackler Fac Med, Steyer Sch Hlth Profess, Dept Commun Disorders, IL-6997801 Tel Aviv, Israel.
EM yaelzaltz@gmail.com; yossi.bugannim@gmail.com;
   doreen.zechoval@gmail.com; lrabin@tauex.tau.ac.il; perezro@inter.net.il
OI Kishon-Rabin, Liat/0000-0002-0516-6603; Zaltz, Yael/0000-0003-0927-0528;
   bugannim, yossi/0000-0003-0475-9674
CR Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Anderson S, 2010, J AM ACAD AUDIOL, V21, P575, DOI 10.3766/jaaa.21.9.3
   AuBuchon AM, 2019, J SPEECH LANG HEAR R, V62, P1016, DOI 10.1044/2018_JSLHR-H-18-0201
   AuBuchon AM, 2015, EAR HEARING, V36, P733, DOI 10.1097/AUD.0000000000000189
   Best V, 2007, J ACOUST SOC AM, V121, P1070, DOI 10.1121/1.2407738
   BOOTHROYD A, 1968, J ACOUST SOC AM, V43, P362, DOI 10.1121/1.1910787
   Boothroyd A, 1997, SCAND AUDIOL, V26, P9
   Brand T, 2002, J ACOUST SOC AM, V111, P2801, DOI 10.1121/1.1479152
   Bugannim Y, 2019, OTOL NEUROTOL, V40, pE316, DOI 10.1097/MAO.0000000000002128
   Caldwell A, 2013, J SPEECH LANG HEAR R, V56, P13, DOI 10.1044/1092-4388(2012/11-0338)
   Cejas I, 2018, EAR HEARING, V39, P1187, DOI 10.1097/AUD.0000000000000578
   Chandramouli SH, 2019, J SPEECH LANG HEAR R, V62, P1033, DOI 10.1044/2018_JSLHR-H-18-0125
   Ching TYC, 2018, INT J AUDIOL, V57, pS70, DOI 10.1080/14992027.2017.1346307
   Ching TYC, 2011, J ACOUST SOC AM, V129, P368, DOI 10.1121/1.3523295
   Choi JE, 2017, EAR HEARING, V38, P426, DOI 10.1097/AUD.0000000000000401
   Cusumano C, 2017, OTOL NEUROTOL, V38, P334, DOI 10.1097/MAO.0000000000001322
   Davidson LS, 2019, J SPEECH LANG HEAR R, V62, P3620, DOI 10.1044/2019_JSLHR-H-18-0255
   Davidson Lisa S, 2011, Ear Hear, V32, p19S, DOI 10.1097/AUD.0b013e3181ffdb8b
   de Boer J, 2008, J NEUROSCI, V28, P4929, DOI 10.1523/JNEUROSCI.0902-08.2008
   DeThorne LS, 2004, AM J SPEECH-LANG PAT, V13, P275, DOI 10.1044/1058-0360(2004/029)
   Dettman S, 2004, ARCH OTOLARYNGOL, V130, P612, DOI 10.1001/archotol.130.5.612
   Drennan WR, 2008, J REHABIL RES DEV, V45, P779, DOI 10.1682/JRRD.2007.08.0118
   Eisenberg LS, 2016, OTOL NEUROTOL, V37, pE75, DOI 10.1097/MAO.0000000000000910
   Friedmann DR, 2015, LARYNGOSCOPE, V125, P1952, DOI 10.1002/lary.25293
   Fu QJ, 2008, HEARING RES, V242, P198, DOI 10.1016/j.heares.2007.11.010
   Galvin KL, 2007, EAR HEARING, V28, P470, DOI 10.1097/AUD.0b013e31806dc194
   Geers A, 2003, EAR HEARING, V24, p24S, DOI 10.1097/01.AUD.0000051687.99218.0F
   Geers AE, 2004, ARCH OTOLARYNGOL, V130, P634, DOI 10.1001/archotol.130.5.634
   Geers Ann E, 2011, Ear Hear, V32, p49S, DOI 10.1097/AUD.0b013e3181fa41fa
   Gifford RH, 2008, AUDIOL NEURO-OTOL, V13, P193, DOI 10.1159/000113510
   Gifford RH, 2011, J AM ACAD AUDIOL, V22, P623, DOI 10.3766/jaaa.22.9.7
   Goldsworthy RL, 2019, J SPEECH LANG HEAR R, V62, P758, DOI 10.1044/2018_JSLHR-H-17-0389
   Hey M, 2016, EUR ARCH OTO-RHINO-L, V273, P4011, DOI 10.1007/s00405-016-4130-2
   Hicks CB, 2002, J SPEECH LANG HEAR R, V45, P573, DOI 10.1044/1092-4388(2002/046)
   Hoppe U, 2018, ACTA OTO-LARYNGOL, V138, P713, DOI 10.1080/00016489.2018.1444281
   Hua H, 2017, J SPEECH LANG HEAR R, V60, P2752, DOI 10.1044/2017_JSLHR-H-16-0276
   Johnson C, 2010, J SPEECH LANG HEAR R, V53, P237, DOI 10.1044/1092-4388(2009/08-0139)
   Kave G, 2005, J CLIN EXP NEUROPSYC, V27, P690, DOI 10.1080/13803390490918499
   Khan S, 2005, AUDIOL NEURO-OTOL, V10, P117, DOI 10.1159/000083367
   Kim JS, 2013, INT J PEDIATR OTORHI, V77, P162, DOI 10.1016/j.ijporl.2012.10.010
   Kishon-Rabin L., 2018, HDB COMMUNICATION DI
   Kishon-Rabin Liat, 2004, Journal of Basic and Clinical Physiology and Pharmacology, V15, P41
   Kollmeier B, 2015, INT J AUDIOL, V54, P3, DOI 10.3109/14992027.2015.1020971
   Kos MI, 2009, INT J PEDIATR OTORHI, V73, P189, DOI 10.1016/j.ijporl.2008.10.009
   Kraaijenga VJC, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00054
   Kral A, 2019, ANNU REV NEUROSCI, V42, P47, DOI 10.1146/annurev-neuro-080317-061513
   Kral A, 2016, LANCET NEUROL, V15, P610, DOI 10.1016/S1474-4422(16)00034-X
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   Kronenberger WG, 2014, J DEAF STUD DEAF EDU, V19, P456, DOI 10.1093/deafed/enu011
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Lunner T, 2009, SCAND J PSYCHOL, V50, P395, DOI 10.1111/j.1467-9450.2009.00742.x
   Manrique M, 2004, ACTA OTO-LARYNGOL, V124, P55, DOI 10.1080/03655230410017148
   Mishra SK, 2018, EAR HEARING, V39, P48, DOI 10.1097/AUD.0000000000000462
   Moberly AC, 2016, OTOL NEUROTOL, V37, P1522, DOI 10.1097/MAO.0000000000001211
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Nittrouer S, 2013, INT J PEDIATR OTORHI, V77, P1886, DOI 10.1016/j.ijporl.2013.09.001
   O'Donoghue G, 2013, NEW ENGL J MED, V369, P1190, DOI 10.1056/NEJMp1310111
   O'Neill ER, 2019, J ACOUST SOC AM, V146, P195, DOI 10.1121/1.5116009
   Perez R., 2013, ENCY OTOLARYNGOLOGY
   Pisoni David B, 2011, Ear Hear, V32, p60S, DOI 10.1097/AUD.0b013e3181ffd58e
   Raven J., 1998, RAVEN MANUAL
   Robbins AM, 2004, ARCH OTOLARYNGOL, V130, P570
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Rubinstein Jay T, 2004, Curr Opin Otolaryngol Head Neck Surg, V12, P444, DOI 10.1097/01.moo.0000134452.24819.c0
   Rudner M, 2008, INT J AUDIOL, V47, pS91, DOI 10.1080/14992020802304393
   Santarelli R, 2008, AUDIOL NEURO-OTOL, V13, P257, DOI 10.1159/000115435
   Shpak T, 2009, INT J AUDIOL, V48, P775, DOI 10.3109/14992020903045184
   Song JH, 2011, J COGNITIVE NEUROSCI, V23, P2268, DOI 10.1162/jocn.2010.21556
   Spehar B, 2015, J SPEECH LANG HEAR R, V58, P1093, DOI 10.1044/2015_JSLHR-H-14-0360
   Stenfelt S, 2009, SCAND J PSYCHOL, V50, P385, DOI 10.1111/j.1467-9450.2009.00748.x
   Svirsky MA, 2004, AUDIOL NEURO-OTOL, V9, P224, DOI 10.1159/000078392
   Tombaugh TN, 2004, ARCH CLIN NEUROPSYCH, V19, P203, DOI 10.1016/S0887-6177(03)00039-8
   Uziel AS, 2007, OTOL NEUROTOL, V28, P615, DOI 10.1097/01.mao.0000281802.59444.02
   van Wieringen A, 2015, HEARING RES, V322, P171, DOI 10.1016/j.heares.2014.09.002
   Wechsler D., 1991, WECHSLER INTELLIGENC
   Wilson BS, 2008, HEARING RES, V242, P3, DOI 10.1016/j.heares.2008.06.005
   Wolfe J, 2007, OTOL NEUROTOL, V28, P589, DOI 10.1097/MAO.0b013e318067bd24
   Zaltz Y, 2018, JARO-J ASSOC RES OTO, V19, P193, DOI 10.1007/s10162-017-0653-5
   Zeitler DM, 2008, OTOL NEUROTOL, V29, P314, DOI 10.1097/MAO.0b013e3181662cb5
   Zeitler DM, 2012, ARCH PEDIAT ADOL MED, V166, P35, DOI 10.1001/archpediatrics.2011.574
NR 80
TC 0
Z9 0
U1 2
U2 2
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2077-0383
J9 J CLIN MED
JI J. Clin. Med.
PD MAY
PY 2020
VL 9
IS 5
AR 1381
DI 10.3390/jcm9051381
PG 18
WC Medicine, General & Internal
SC General & Internal Medicine
GA LY0OO
UT WOS:000540223800138
PM 32397101
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Wang, LC
   Liu, D
   Chung, KKH
   Chu, SY
AF Wang, Li-Chih
   Liu, Duo
   Chung, Kevin Kien-Hoa
   Chu, Szu-Yin
TI The link between auditory temporal processing and knowledge of the
   phonological coding system in learning to read Chinese
SO LEARNING AND INDIVIDUAL DIFFERENCES
LA English
DT Article
DE Auditory temporal processing; Knowledge of the phonological coding
   system; Phonological processing; Chinese reading
ID SHORT-TERM-MEMORY; MORPHOLOGICAL AWARENESS; SPEECH-PERCEPTION;
   WORKING-MEMORY; DUAL-ROUTE; DYSLEXIA; CHILDREN; ABILITIES; DEFICIT;
   SKILLS
AB This paper investigates the importance of the phonological coding system (PCS) by examining the possible moderation effect of knowledge of the PCS on the predictiveness of auditory temporal processing (ATP) for Chinese character reading. Eighty typically developing Chinese children in the first and second grades in Taiwan were recruited, and various cognitive and literacy ability tasks were administered. The results revealed that knowledge of the PCS served as a significant moderator of the association between ATP and Chinese character reading, that is, the significant prediction from ATP to Chinese character reading was observed only in those with high knowledge of the PCS but not those with low knowledge of the PCS. Additionally, we further demonstrated diverse ability levels in phonological processing as it contributes to Chinese character reading among individuals with higher and lower knowledge of the PCS. Specifically, ATP as well as phonological awareness significantly predicted Chinese character reading for those with high knowledge of the PCS, while only verbal short-term memory served as a significant predictor of Chinese character reading for those with low knowledge of the PCS. Our results show that individuals with different levels of knowledge of the PCS may demonstrate different ability levels in phonological processing in their Chinese character reading, which suggests that the need for teaching approaches suited to students with diverse learning experiences should be acknowledged.
C1 [Wang, Li-Chih; Liu, Duo] Educ Univ Hong Kong, Dept Special Educ & Counselling, Hong Kong, Peoples R China.
   [Chung, Kevin Kien-Hoa] Educ Univ Hong Kong, Dept Early Childhood Educ, Hong Kong, Peoples R China.
   [Chu, Szu-Yin] Natl Tsing Hua Univ, Dept Special Educ, Hsinchu, Taiwan.
   [Wang, Li-Chih; Liu, Duo] Educ Univ Hong Kong, Integrated Ctr Wellbeing, Hong Kong, Peoples R China.
   [Wang, Li-Chih; Liu, Duo; Chung, Kevin Kien-Hoa] Educ Univ Hong Kong, Ctr Child & Family Sci, Hong Kong, Peoples R China.
RP Wang, LC (corresponding author), Educ Univ Hong Kong, Dept Special Educ & Counselling, Hong Kong, Peoples R China.; Wang, LC (corresponding author), Educ Univ Hong Kong, Integrated Ctr Wellbeing, Hong Kong, Peoples R China.; Wang, LC (corresponding author), Educ Univ Hong Kong, Ctr Child & Family Sci, Hong Kong, Peoples R China.
EM wanglca@eduhk.hk; duoliu@eduhk.hk; kevin@eduhk.hk; chusy@mx.nthu.edu.tw
OI Chung, Kevin K H/0000-0002-8105-7361; WANG, Li-Chih/0000-0002-4011-7305;
   LIU, Duo/0000-0002-2352-2616
FU Internal Research Grant of The Education University of Hong Kong
   [RG32/2016-2017R]
FX This work was supported by the Internal Research Grant of The Education
   University of Hong Kong (RG32/2016-2017R).
CR Alloway TP, 2006, CHILD DEV, V77, P1698, DOI 10.1111/j.1467-8624.2006.00968.x
   Boets B, 2006, BRAIN LANG, V97, P64, DOI 10.1016/j.bandl.2005.07.026
   BOWEY JA, 1991, APPL PSYCHOLINGUIST, V12, P91, DOI 10.1017/S0142716400009395
   BRADY S, 1986, ANN DYSLEXIA, V36, P138, DOI 10.1007/BF02648026
   BRUCK M, 1992, DEV PSYCHOL, V28, P874, DOI 10.1037/0012-1649.28.5.874
   Cain K, 2004, J EDUC PSYCHOL, V96, P31, DOI 10.1037/0022-0663.96.1.31
   CARAVOLAS M, 1993, J EXP CHILD PSYCHOL, V55, P1, DOI 10.1006/jecp.1993.1001
   Catts HW, 2002, J LEARN DISABIL-US, V35, P509
   Chen J. H., 2006, RAVENS PROGR MATRICE
   CHEN MJ, 1991, INT J BEHAV DEV, V14, P429, DOI 10.1177/016502549101400405
   Cheung H, 2001, COGNITION, V81, P227, DOI 10.1016/S0010-0277(01)00136-6
   Chung K. K. H., 2002, ED PSYCHOL, V22, P149, DOI DOI 10.1080/01443410120115238
   Chung KKH, 2008, ANN DYSLEXIA, V58, P15, DOI 10.1007/s11881-008-0015-4
   Coltheart M, 2001, PSYCHOL REV, V108, P204, DOI 10.1037//0033-295X.108.1.204
   Farmer ME, 1995, PSYCHON B REV, V2, P460, DOI 10.3758/BF03210983
   Hayes A. F., 2018, INTRO MEDIATION MODE
   Hayes AF, 2009, BEHAV RES METHODS, V41, P924, DOI 10.3758/BRM.41.3.924
   Ho C.S.-H., 2010, OXFORD HDB CHINESE P, P109
   Ho CSH, 1999, LEARN INDIVID DIFFER, V11, P173, DOI 10.1016/S1041-6080(00)80004-7
   Hsuan C. H., 2012, B SPECIAL ED, V37, P53
   Huang D, 2018, EUR J NEUROSCI, V47, P662, DOI 10.1111/ejn.13657
   Huang H. S., 2001, CHINESE CHARACTER RE
   HUANG H. S., 1997, B SPECIAL ED REHABIL, V5, P125
   Huang HS, 1997, INT J BEHAV DEV, V20, P249, DOI 10.1080/016502597385324
   Huang S. S., 2003, DIAGNOSE TEST PRIMAR
   HUE CW, 1988, MEM COGNITION, V16, P196, DOI 10.3758/BF03197752
   Jenkins JR, 2003, J EDUC PSYCHOL, V95, P719, DOI 10.1037/0022-0663.95.4.719
   Kail R, 1999, APPL PSYCHOLINGUIST, V20, P303, DOI 10.1017/S0142716499002076
   Kibby MY, 2009, CHILD NEUROPSYCHOL, V15, P485, DOI 10.1080/09297040902748218
   Klein R. M., 2002, READING WRITING INTE, V15, P207, DOI [10.1023/A:1013828723016, DOI 10.1023/A:1013828723016]
   Landerl K, 2010, LEARN INDIVID DIFFER, V20, P393, DOI 10.1016/j.lindif.2010.03.008
   Lee J. R., 2007, B SPECIAL ED, V32, P1, DOI DOI 10.6172/BSE200712.3204001
   Lee J.-R., 2009, B ED PSYCHOL, V41, P111
   LEE JR, 2006, LANGUAGE LINGUISTICS, V7, P573
   LILLIEFORS HW, 1967, J AM STAT ASSOC, V62, P399, DOI 10.2307/2283970
   Lin D, 2010, PSYCHOL SCI, V21, P1117, DOI 10.1177/0956797610375447
   Liu D, 2015, SCI STUD READ, V19, P307, DOI 10.1080/10888438.2015.1030749
   Liu PD, 2010, J EDUC PSYCHOL, V102, P62, DOI 10.1037/a0016933
   McBride-Chang C, 2000, J EDUC PSYCHOL, V92, P50, DOI 10.1037/0022-0663.92.1.50
   McBride-Chang C, 2004, J EXP CHILD PSYCHOL, V89, P93, DOI 10.1016/j.jecp.2004.05.001
   McBrideChang C, 1996, CHILD DEV, V67, P1836, DOI 10.2307/1131735
   Meng XZ, 2005, DYSLEXIA, V11, P292, DOI 10.1002/dys.309
   Murphy CFB, 2010, BRAZ J MED BIOL RES, V43, P359, DOI [10.1590/S0100-879X2010007500016, 10.1590/S0100-879X2010000400007]
   Murti B., 2013, DESIGN SAMPLE SIZE Q
   Protopapas A, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0090
   Rahmani E., 2015, AUDITORY VESTIBULAR, V24, P98
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   Ramus F, 2001, NATURE, V412, P393, DOI 10.1038/35086683
   Rey V, 2002, BRAIN LANG, V80, P576, DOI 10.1006/brln.2001.2618
   Riding R., 2013, COGNITIVE STYLES LEA
   Shu H, 2008, DEVELOPMENTAL SCI, V11, P171, DOI 10.1111/j.1467-7687.2007.00654.x
   Steinbrink C, 2014, CHILD DEV, V85, P1711, DOI 10.1111/cdev.12208
   Strehlow U, 2006, EUR CHILD ADOLES PSY, V15, P19, DOI 10.1007/s00787-006-0500-4
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   TALLAL P, 1984, APPL PSYCHOLINGUIST, V5, P167, DOI 10.1017/S0142716400004963
   Tallal P., 2000, SPEECH LANGUAGE IMPA, P131
   Tallal P, 2006, TRENDS NEUROSCI, V29, P382, DOI 10.1016/j.tins.2006.06.003
   Tong XL, 2009, SCI STUD READ, V13, P426, DOI 10.1080/10888430903162910
   Tractenberg RE, 2002, J LEARN DISABIL-US, V35, P407, DOI 10.1177/00222194020350050201
   TREIMAN R, 1991, PHONOLOGICAL PROCESSES IN LITERACY, P67
   TUNMER WE, 1982, APPL PSYCHOLINGUIST, V3, P299, DOI 10.1017/S0142716400004240
   Tzeng S. J., 2009, J EDUC PSYCHOL, V30, P53
   WADSWORTH SJ, 1995, INTELLIGENCE, V20, P145, DOI 10.1016/0160-2896(95)90030-6
   WAGNER RK, 1987, PSYCHOL BULL, V101, P192, DOI 10.1037/0033-2909.101.2.192
   Wang HLS, 2016, PERCEPT MOTOR SKILL, V123, P365, DOI 10.1177/0031512516663164
   Wang LC, 2018, READ WRIT, V31, P1645, DOI 10.1007/s11145-018-9857-2
   Wang LC, 2018, J LEARN DISABIL-US, V51, P302, DOI 10.1177/0022219416680798
   Wang LC, 2014, RES DEV DISABIL, V35, P2702, DOI 10.1016/j.ridd.2014.07.001
   Weisberg J, 2012, PHILOS COMPASS, V7, P597, DOI 10.1111/j.1747-9991.2012.00504.x
   Yin WG, 2003, ANN DYSLEXIA, V53, P255, DOI 10.1007/s11881-003-0012-6
   Zhang J, 2014, DEV PSYCHOL, V50, P1001, DOI 10.1037/a0035086
   Zhang ML, 2018, RES DEV DISABIL, V74, P146, DOI 10.1016/j.ridd.2018.01.005
   Zhang Y. Z., 2008, J EDUC PSYCHOL, V31, P179
NR 73
TC 0
Z9 0
U1 2
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1041-6080
EI 1873-3425
J9 LEARN INDIVID DIFFER
JI Learn. Individ. Differ.
PD MAY
PY 2020
VL 80
AR 101883
DI 10.1016/j.lindif.2020.101883
PG 8
WC Psychology, Educational
SC Psychology
GA LU2EE
UT WOS:000537572200010
DA 2021-02-24
ER

PT J
AU Narayan, CR
AF Narayan, Chandan R.
TI An acoustic perspective on 45 years of infant speech perception. II.
   Vowels and suprasegmentals
SO LANGUAGE AND LINGUISTICS COMPASS
LA English
DT Article
ID 1ST YEAR; PHONETIC PERCEPTION; TONE PERCEPTION; DISCRIMINATION;
   DURATION; EXPERIENCE; LENGTH; SENSITIVITY; CONTRASTS; JAPANESE
AB In this two-part review we examine the major results from infant consonant (Part 1), vowel, and suprasegmental (Part 2) discrimination research over the past 45 years from an acoustic perspective-an exegesis of the developmental perception literature that appeals to both acoustic aspects of speech contrasts and historically relevant typological facts about sound systems of the world's languages. We argue that infants' speech discrimination abilities are best viewed through a lens that considers both synchronic and diachronic aspects of the particular speech contrast. The key to this approach is the notion that acoustic-perceptual salience, or the relative separation of speech categories along perceptually relevant acoustic dimensions and corresponding discrimination performance in adults, is reflected in both infant's perceptual performance and patterns observed in phonological typology and history. The present review highlights challenges offered by four decades of literature, identifies broad patterns in infant vowel perception according to the acoustic properties of speech contrasts, and offers linguistically motivated explanations and directions for future research into the nature of young infants' discrimination abilities.
C1 [Narayan, Chandan R.] York Univ, Dept Languages Literatures & Linguist, Speech & Psycholinguist Lab, Toronto, ON, Canada.
RP Narayan, CR (corresponding author), York Univ, Dept Languages Literatures & Linguist, Speech & Psycholinguist Lab, Toronto, ON, Canada.
EM chandann@yorku.ca
OI Narayan, Chandan/0000-0003-0782-3467
CR Aslin R. N., 1980, CHILD PHONOLOGY, V2, P67
   Aslin RN, 2002, J ACOUST SOC AM, V112, P1257, DOI 10.1121/1.1501904
   Barreda S, 2012, J ACOUST SOC AM, V131, P466, DOI 10.1121/1.3662068
   BEST CT, 2000, INT C INF STUD BRIGH
   Bohn OS, 2001, J ACOUST SOC AM, V110, P504, DOI 10.1121/1.1380415
   Booij G., 1995, PHONOLOGY DUTCH
   Bosch L, 2003, LANG SPEECH, V46, P217, DOI 10.1177/00238309030460020801
   BURNHAM DK, 1986, APPL PSYCHOLINGUIST, V7, P207, DOI 10.1017/S0142716400007542
   Desjardins R. N., 1998, CAN ACOUST, V26, P96
   EILERS RE, 1984, J CHILD LANG, V11, P313, DOI 10.1017/S0305000900005791
   Fant G., 1964, P 5 INT C PHON SCI M, P120
   Francis AL, 2008, J PHONETICS, V36, P268, DOI 10.1016/j.wocn.2007.06.005
   HENRY FM, 1948, J EXP PSYCHOL, V38, P734, DOI 10.1037/h0058552
   Hirata Y, 2004, J PHONETICS, V32, P565, DOI 10.1016/j.wocn.2004.02.004
   Khouw E, 2007, J PHONETICS, V35, P104, DOI 10.1016/j.wocn.2005.10.003
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   Kuronen M., 2001, WORKING PAPERS LUND, P94
   Lehiste Ilde, 1970, SUPRASEGMENTALS
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Maddieson I., 1984, PATTERNS SOUNDS
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   MILLER RL, 1953, J ACOUST SOC AM, V25, P114, DOI 10.1121/1.1906983
   Mok PPK, 2013, LANG VAR CHANGE, V25, P341, DOI 10.1017/S0954394513000161
   Molis M. R., 2005, J ACOUST SOC AM, V111, P2433
   Mugitani R, 2009, DEV PSYCHOL, V45, P236, DOI 10.1037/a0014043
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Nittrouer S, 2001, J ACOUST SOC AM, V110, P1598, DOI 10.1121/1.1379078
   Patzold M., 1997, ARBEITSBERICHTE I PH, P215
   PETERSON GE, 1960, J ACOUST SOC AM, V32, P693, DOI 10.1121/1.1908183
   Polka L, 1996, J ACOUST SOC AM, V100, P577, DOI 10.1121/1.415884
   Polka L, 2003, SPEECH COMMUN, V41, P221, DOI 10.1016/S0167-6393(02)00105-X
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Polka L, 2011, J PHONETICS, V39, P467, DOI 10.1016/j.wocn.2010.08.007
   RUHM HB, 1966, J SPEECH HEAR RES, V9, P371, DOI 10.1044/jshr.0903.371
   Sato Y, 2010, DEV PSYCHOL, V46, P106, DOI 10.1037/a0016718
   Sebastian-Galles N, 2009, DEVELOPMENTAL SCI, V12, P874, DOI 10.1111/j.1467-7687.2009.00829.x
   Stott LH, 1935, J EXP PSYCHOL, V18, P741, DOI 10.1037/h0057714
   SWOBODA PJ, 1976, CHILD DEV, V47, P459, DOI 10.2307/1128802
   TREHUB SE, 1973, DEV PSYCHOL, V9, P91, DOI 10.1037/h0034999
   Vaissiere J., 2011, P 17 INT C PHON SCI, P52
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wurm Stephen A. Benjamin K., 1987, LANGUAGE ATLAS CHINA
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
NR 45
TC 1
Z9 1
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1749-818X
J9 LANG LINGUIST COMPAS
JI Lang. Linguist. Compass
PD MAY
PY 2020
VL 14
IS 5
AR e12369
DI 10.1111/lnc3.12369
PG 12
WC Language & Linguistics
SC Linguistics
GA LL9SA
UT WOS:000531894200001
DA 2021-02-24
ER

PT J
AU Alegria, J
   Carrillo, MS
   Rueda, MI
   Dominguez, AB
AF Alegria, Jesus
   Carrillo, Maria-Soledad
   Rueda, Mercedes, I
   Dominguez, Ana-Belen
TI Reading sentences in Spanish: some similarities and differences between
   children with dyslexia and those with deafness
SO ANALES DE PSICOLOGIA
LA English
DT Article
DE dyslexia; deafness; cochlear implant; reading; key-word-strategy
ID INDIVIDUAL-DIFFERENCES; SPEECH-PERCEPTION; ORAL DEAF; HEARING;
   CONSEQUENCES; PHONOLOGY; LITERACY; LANGUAGE; WORDS
AB The present study compares the strategies to read sentences used by Spanish-speaking children with dyslexia (n = 107) and cochlear-implanted children with deafness (n = 61). The results show that children with deafness, but not with dyslexia, adopt the key-word-strategy (KWS), which consists of identifying some content words of the sentence while ignoring the function words. Furthermore, it appeared that the KWS was associated with poor syntactic ability. Moreover, when Dyslexic and Deaf Groups were carefully matched at reading level with normally developing children (Control Group, n = 785) all of the differences between dyslexics and normally developing children disappeared. Children with hearing loss however were still slow at dealing with function words and consequently maintained their tendency to use the KWS. These results exclude the hypothesis that the KWS is a broadly used procedure to compensate for reading deficits but seems, rather, to depend on poor syntactic ability.
C1 [Alegria, Jesus] Univ Libre Bruxelles, Brussels, Belgium.
   [Carrillo, Maria-Soledad] Univ Murcia, Murcia, Spain.
   [Rueda, Mercedes, I; Dominguez, Ana-Belen] Univ Salamanca, Salamanca, Spain.
RP Dominguez, AB (corresponding author), Univ Salamanca, Fac Educ, Paseo Canalejas 169, E-37008 Salamanca, Spain.
EM abd@usal.es
RI Gutierrez, Ana Belen Dominguez/M-9809-2015
OI Gutierrez, Ana Belen Dominguez/0000-0002-2423-507X
FU Ministerio de Ciencia, Innovacion y Universidades [PGC2018-094565-B-I00]
FX Ministerio de Ciencia, Innovacion y Universidades (Proyecto
   PGC2018-094565-B-I00).
CR Aaron PG, 1998, READ WRIT, V10, P1, DOI 10.1023/A:1007917929226
   Cantiani C, 2015, DEV NEUROPSYCHOL, V40, P291, DOI 10.1080/87565641.2015.1072536
   Cantiani C, 2013, NEUROPSYCHOLOGIA, V51, P1595, DOI 10.1016/j.neuropsychologia.2013.04.009
   Cuadro A., 2009, EVALUACION NIVEL LEC
   CUNNINGHAM AE, 1991, J EDUC PSYCHOL, V83, P264, DOI 10.1037/0022-0663.83.2.264
   Delage H, 2018, CLIN LINGUIST PHONET, V32, P758, DOI 10.1080/02699206.2018.1437222
   Dominguez AB, 2016, J DEAF STUD DEAF EDU, V21, P280, DOI 10.1093/deafed/enw026
   Dominguez AB, 2014, RES DEV DISABIL, V35, P1439, DOI 10.1016/j.ridd.2014.03.039
   Dominguez AB, 2010, J DEAF STUD DEAF EDU, V15, P136, DOI 10.1093/deafed/enp033
   Gaustad Martha Gonter, 2004, J Deaf Stud Deaf Educ, V9, P269
   Geers A, 2008, INT J AUDIOL, V47, pS21, DOI 10.1080/14992020802339167
   Geers Ann E, 2011, Ear Hear, V32, p49S, DOI 10.1097/AUD.0b013e3181fa41fa
   Hammer A., 2010, THESIS
   Herman R., 2016, OXFORD HDB DEAF STUD, P344
   Herman R, 2019, READ RES QUART, V54, P553, DOI 10.1002/rrq.244
   King C., 1985, READING AND DEAFNESS
   Le Normand MT, 2014, LINGUA, V139, P26, DOI 10.1016/j.lingua.2013.02.012
   Marin J., 1999, TEST COLECTIVO EFICA
   Marschark M., 2010, OXFORD HDB DEAF STUD, V2, P127
   Miller P, 2005, AM ANN DEAF, V150, P305, DOI 10.1353/aad.2005.0031
   Miller P, 2007, J DEAF STUD DEAF EDU, V12, P184, DOI 10.1093/deafed/enl031
   Mohammed T, 2006, CLIN LINGUIST PHONET, V20, P621, DOI 10.1080/02699200500266745
   Moreno-Perez FJ, 2015, J DEAF STUD DEAF EDU, V20, P374, DOI 10.1093/deafed/env030
   Niederberger N., 2007, ENFANCE, V59, P254, DOI [10.3917/enf.593.0254, DOI 10.3917/ENF.593.0254]
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   Paul P. V., 1998, LITERACY DEAFNESS DE
   Perfetti C. A., 1977, COGNITIVE PROCESS, P141
   PERFETTI CA, 1979, MEM COGNITION, V7, P273, DOI 10.3758/BF03197600
   Rodriguez J. M., 1997, REV PSICOLOGIA LENGU, V2, P117
   Roy P, 2015, RES DEV DISABIL, V36, P277, DOI 10.1016/j.ridd.2014.10.012
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   STANOVICH KE, 1980, READ RES QUART, V16, P32, DOI 10.2307/747348
   STANOVICH KE, 1986, READ RES QUART, V21, P360, DOI 10.1598/RRQ.21.4.1
   STANOVICH KE, 1992, MEM COGNITION, V20, P51, DOI 10.3758/BF03208254
   Stockseth Danzak Robin, 2002, Rev. signos, V35, P271, DOI 10.4067/S0718-09342002005100017
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   WERKER JF, 1987, CAN J PSYCHOL, V41, P48, DOI 10.1037/h0084150
   Wiseheart R, 2009, ANN DYSLEXIA, V59, P151, DOI 10.1007/s11881-009-0028-7
NR 38
TC 0
Z9 0
U1 0
U2 0
PU UNIV MURCIA
PI MURCIA
PA SOC ESPANOLA HISTORIA AGRARIA, CAMPUS ESPINARDO, MURCIA, 30100, SPAIN
SN 0212-9728
EI 1695-2294
J9 AN PSICOL-SPAIN
JI An. Psicol.
PD MAY-SEP
PY 2020
VL 36
IS 2
BP 295
EP 303
DI 10.6018/analesps.396841
PG 9
WC Psychology; Psychology, Multidisciplinary
SC Psychology
GA LD5NJ
UT WOS:000526076300012
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Bruggeman, L
   Cutler, A
AF Bruggeman, Laurence
   Cutler, Anne
TI No L1 privilege in talker adaptation
SO BILINGUALISM-LANGUAGE AND COGNITION
LA English
DT Article
DE perceptual learning; native language; second language; immersion;
   emigrants
ID SPEECH-PERCEPTION; PHONOLOGICAL ABSTRACTION; RECOGNITION; COMPETITION;
   DYNAMICS; ACCENT
AB As a rule, listening is easier in first (L1) than second languages (L2); difficult L2 listening can challenge even highly proficient users. We here examine one particular listening function, adaptation to novel talkers, in such a high-proficiency population: Dutch emigrants to Australia, predominantly using English outside the family, but all also retaining L1 proficiency. Using lexically-guided perceptual learning (Norris, McQueen & Cutler, 2003), we investigated these listeners' adaptation to an ambiguous speech sound, in parallel experiments in both their L1 and their L2. A control study established that perceptual learning outcomes were unaffected by the procedural measures required for this double comparison. The emigrants showed equivalent proficiency in tests in both languages, robust perceptual adaptation in their L2, English, but no adaptation in L1. We propose that adaptation to novel talkers is a language-specific skill requiring regular novel practice; a limited set of known (family) interlocutors cannot meet this requirement.
C1 [Bruggeman, Laurence] Western Sydney Univ, ARC Ctr Excellence Dynam Language, MARCS Inst Brain Behav & Dev, Sydney, NSW, Australia.
   [Cutler, Anne] Western Sydney Univ, ARC Ctr Excellence Dynam Language, MARCS Inst Brain Behav & Dev, Max Planck Inst Psychoiinguist, Sydney, NSW, Australia.
RP Bruggeman, L (corresponding author), Western Sydney Univ, ARC Ctr Excellence Dynam Language, MARCS Inst Brain Behav & Dev, Sydney, NSW, Australia.
EM l.bruggeman@westernsydney.edu.au
OI Bruggeman, Laurence/0000-0002-5036-7666
FU MARCS Institute doctoral fellowship
FX Financial support was provided by a MARCS Institute doctoral fellowship
   to the first author. We thank Vincent Hoofs for assistance with data
   collection, and Sammie Tarenskeen and Anne Dwyer for recording the
   stimuli.
CR Baayen RH, 1995, CELEX LEXICAL DATABA
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boersma P., 2013, PRAAT DOING PHONETIC
   Borrie SA, 2012, LANG COGNITIVE PROC, V27, P1039, DOI 10.1080/01690965.2011.610596
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Broersma M, 2011, Q J EXP PSYCHOL, V64, P74, DOI 10.1080/17470218.2010.499174
   Burchfield LA, 2017, INTERSPEECH, P576, DOI 10.21437/Interspeech.2017-618
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Clyne M, 1997, DUTCH OVERSEAS, P34
   Collins B., 2003, PHONETICS ENGLISH DU
   Cutler A, 2018, P 17 AUSTR INT C SPE, P33
   Dahan D, 2008, COGNITION, V108, P710, DOI 10.1016/j.cognition.2008.06.003
   Drozdova P, 2016, BILING-LANG COGN, V19, P914, DOI 10.1017/S136672891600002X
   Eisner F, 2006, J ACOUST SOC AM, V119, P1950, DOI 10.1121/1.2178721
   Evans BG, 2004, J ACOUST SOC AM, V115, P352, DOI 10.1121/1.1635413
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Lemhofer K, 2012, BEHAV RES METHODS, V44, P325, DOI 10.3758/s13428-011-0146-0
   MathWorks, 2013, MATLAB
   Maye J, 2008, COGNITIVE SCI, V32, P543, DOI 10.1080/03640210802035357
   McQueen JM, 2012, LANG LEARN DEV, V8, P317, DOI 10.1080/15475441.2011.641887
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   Mitterer H, 2013, J MEM LANG, V69, P527, DOI 10.1016/j.jml.2013.07.002
   Mitterer H, 2011, COGNITIVE SCI, V35, P184, DOI 10.1111/j.1551-6709.2010.01140.x
   Mitterer H, 2009, PLOS ONE, V4, pA146, DOI 10.1371/journal.pone.0007785
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Ockey GJ, 2016, APPL LINGUIST, V37, P693, DOI 10.1093/applin/amu060
   R Core Team, 2018, R LANG ENV STAT COMP
   Ramscar M, 2014, TOP COGN SCI, V6, P5, DOI 10.1111/tops.12078
   Reinisch E, 2013, J EXP PSYCHOL HUMAN, V39, P75, DOI 10.1037/a0027979
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   REPP BH, 1981, B PSYCHONOMIC SOC, V18, P12
   Scharenborg O, 2015, ATTEN PERCEPT PSYCHO, V77, P493, DOI 10.3758/s13414-014-0792-2
   Scharenborg O, 2013, ATTEN PERCEPT PSYCHO, V75, P525, DOI 10.3758/s13414-013-0422-4
   Schuhmann KS, 2014, THESIS
   Sebastian-Galles N, 2005, J MEM LANG, V52, P240, DOI 10.1016/j.jml.2004.11.001
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Trude AM, 2013, J MEM LANG, V69, P349, DOI 10.1016/j.jml.2013.05.002
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0
   Witteman MJ, 2013, ATTEN PERCEPT PSYCHO, V75, P537, DOI 10.3758/s13414-012-0404-y
NR 44
TC 4
Z9 4
U1 0
U2 1
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 1366-7289
EI 1469-1841
J9 BILING-LANG COGN
JI Biling.-Lang. Cogn.
PD MAY
PY 2020
VL 23
IS 3
BP 681
EP 693
AR PII S1366728919000646
DI 10.1017/S1366728919000646
PG 13
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA LD2JL
UT WOS:000525857800017
DA 2021-02-24
ER

PT J
AU Iacozza, S
   Meyer, AS
   Lev-Ari, S
AF Iacozza, Sara
   Meyer, Antje S.
   Lev-Ari, Shiri
TI How In-Group Bias Influences the Level of Detail of Speaker-Specific
   Information Encoded in Novel Lexical Representations
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION
LA English
DT Article
DE in-group bias; word learning; indexical information; social identity;
   lexical representations
ID SPEECH-PERCEPTION; SELF; MEMORY; CATEGORIZATION; INTEGRATION; LANGUAGE;
   GENDER; FACES; RACE
AB An important issue in theories of word learning is how abstract or context-specific representations of novel words are. One aspect of this broad issue is how well learners maintain information about the source of novel words. We investigated whether listeners' source memory was better for words learned from members of their in-group (students of their own university) than it is for words learned from members of an out-group (students from another institution). In the first session, participants saw 6 faces and learned which of the depicted students attended either their own or a different university. In the second session, they learned competing labels (e.g., citrus-peller and citrus-schiller; in English, lemon peeler and lemon stripper) for novel gadgets, produced by the in-group and out-group speakers. Participants were then tested for source memory of these labels and for the strength of their in-group bias, that is, for how much they preferentially process in-group over out-group information. Analyses of source memory accuracy demonstrated an interaction between speaker group membership status and participants' in-group bias: Stronger in-group bias was associated with less accurate source memory for out-group labels than in-group labels. These results add to the growing body of evidence on the importance of social variables for adult word learning.
C1 [Iacozza, Sara; Meyer, Antje S.; Lev-Ari, Shiri] Max Planck Inst Psycholinguist, POB 310, NL-6500 AH Nijmegen, Netherlands.
   [Iacozza, Sara] Int Max Planck Res Sch Language Sci, Nijmegen, Netherlands.
   [Meyer, Antje S.] Radboud Univ Nijmegen, Donders Inst Brain Cognit Behav, Nijmegen, Netherlands.
   [Lev-Ari, Shiri] Royal Holloway Univ London, Dept Psychol, London, England.
RP Iacozza, S (corresponding author), Max Planck Inst Psycholinguist, POB 310, NL-6500 AH Nijmegen, Netherlands.
EM sara.iacozza@mpi.nl
OI Iacozza, Sara/0000-0002-4633-2508
CR ARON A, 1991, J PERS SOC PSYCHOL, V60, P241, DOI 10.1037/0022-3514.60.2.241
   Bargh JA, 2012, TRENDS COGN SCI, V16, P593, DOI 10.1016/j.tics.2012.10.002
   Bates D, 2015, PARSIMONIOUS MIXED M
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Cadinu MR, 1996, J PERS SOC PSYCHOL, V70, P661, DOI 10.1037/0022-3514.70.4.661
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234
   Drager K, 2016, AWARENESS CONTROL SO, P1, DOI DOI 10.1017/CBO9781139680448.003
   Enock F, 2018, ACTA PSYCHOL, V182, P107, DOI 10.1016/j.actpsy.2017.11.011
   FRABLE DES, 1985, J PERS SOC PSYCHOL, V49, P459, DOI 10.1037/0022-3514.49.2.459
   Garrod S, 2014, LANG COGN NEUROSCI, V29, P46, DOI 10.1080/01690965.2013.852229
   Goldinger S. D., 2007, 16 INT C PHON SCI, P49
   Greenstein M, 2016, EXP PSYCHOL, V63, P150, DOI 10.1027/1618-3169/a000322
   GREENWALD AG, 1995, PSYCHOL REV, V102, P4, DOI 10.1037/0033-295X.102.1.4
   Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Hugenberg K, 2010, PSYCHOL REV, V117, P1168, DOI 10.1037/a0020463
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Jones CR, 2010, PERS SOC PSYCHOL B, V36, P1073, DOI 10.1177/0146167210375817
   JUDD CM, 1988, J PERS SOC PSYCHOL, V54, P778, DOI 10.1037/0022-3514.54.5.778
   Keuleers E, 2010, BEHAV RES METHODS, V42, P643, DOI 10.3758/BRM.42.3.643
   Kinzler KD, 2011, DEVELOPMENTAL SCI, V14, P106, DOI 10.1111/j.1467-7687.2010.00965.x
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299
   Lev-Ari S, 2012, DISCOURSE PROCESS, V49, P523, DOI 10.1080/0163853X.2012.698493
   LimeSurvey Project Team, 2015, LIMESURVEY OP SOURC
   Ma DS, 2015, BEHAV RES METHODS, V47, P1122, DOI 10.3758/s13428-014-0532-5
   Martin CD, 2016, LANG COGN NEUROSCI, V31, P375, DOI 10.1080/23273798.2015.1100750
   Meissner CA, 2005, APPL COGNITIVE PSYCH, V19, P545, DOI 10.1002/acp.1097
   Moradi Z, 2015, PSYCHON B REV, V22, P1255, DOI 10.3758/s13423-014-0798-8
   Munster K, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02267
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007
   R Core Team, 2013, R LANG ENV STAT COMP
   Stolte M, 2017, Q J EXP PSYCHOL, V70, P1011, DOI 10.1080/17470218.2015.1101477
   Sui J, 2015, TRENDS COGN SCI, V19, P719, DOI 10.1016/j.tics.2015.08.015
   Sumner M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01015
   Symons CS, 1997, PSYCHOL BULL, V121, P371, DOI 10.1037/0033-2909.121.3.371
   Van Bavel JJ, 2012, PERS SOC PSYCHOL B, V38, P1566, DOI 10.1177/0146167212455829
   Van Bavel JJ, 2008, PSYCHOL SCI, V19, P1131, DOI 10.1111/j.1467-9280.2008.02214.x
   Van Berkum JJA, 2008, J COGNITIVE NEUROSCI, V20, P580, DOI 10.1162/jocn.2008.20054
   Walker A., 2011, LAB PHONOLOGY, V2, P219, DOI DOI 10.1515/LABPHON.2011.007
   WILDER DA, 1990, J PERS SOC PSYCHOL, V59, P1202, DOI 10.1037/0022-3514.59.6.1202
NR 42
TC 2
Z9 2
U1 1
U2 8
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0278-7393
EI 1939-1285
J9 J EXP PSYCHOL LEARN
JI J. Exp. Psychol.-Learn. Mem. Cogn.
PD MAY
PY 2020
VL 46
IS 5
BP 894
EP 906
DI 10.1037/xlm0000765
PG 13
WC Psychology; Psychology, Experimental
SC Psychology
GA LC5VQ
UT WOS:000525399900005
PM 31621359
OA Green Published
DA 2021-02-24
ER

PT J
AU Tierney, A
   Rosen, S
   Dick, F
AF Tierney, Adam
   Rosen, Stuart
   Dick, Fred
TI Speech-in-Speech Perception, Nonverbal Selective Attention, and Musical
   Training
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION
LA English
DT Article
DE selective attention; speech; cocktail party; musicians; executive
   function
ID FUNDAMENTAL-FREQUENCY; AUDITORY-RHYTHM; NON-MUSICIANS; OLDER-ADULTS;
   BRAIN-STEM; HEARING; NOISE; EXPERTISE; LISTENERS; MASKING
AB Speech is more difficult to understand when it is presented concurrently with a distractor speech stream. One source of this difficulty is that competing speech can act as an attentional lure, requiring listeners to exert attentional control to ensure that attention does not drift away from the target. Stronger attentional control may enable listeners to more successfully ignore distracting speech, and so individual differences in selective attention may be one factor driving the ability to perceive speech in complex environments. However, the lack of a paradigm for measuring nonverbal sustained selective attention to sound has made this hypothesis difficult to test. Here we find that individuals who are better able to attend to a stream of tones and respond to occasional repeated sequences while ignoring a distractor tone stream are also better able to perceive speech masked by a single distractor talker. We also find that participants who have undergone more musical training show better performance on both verbal and nonverbal selective attention tasks, and this musician advantage is greater in older participants. This suggests that one source of a potential musician advantage for speech perception in complex environments may be experience or skill in directing and maintaining attention to a single auditory object.
C1 [Tierney, Adam; Dick, Fred] Univ London, Dept Psychol Sci, Birkbeck Coll, Malet St, London WC1E 7HX, England.
   [Rosen, Stuart; Dick, Fred] UCL, Div Psychol & Language Sci, London, England.
RP Tierney, A (corresponding author), Univ London, Dept Psychol Sci, Birkbeck Coll, Malet St, London WC1E 7HX, England.
EM a.tierney@bbk.ac.uk
OI Rosen, Stuart/0000-0002-9376-2148
CR Amer T, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071630
   Barnes R, 2000, COGNITIVE PSYCHOL, V41, P254, DOI 10.1006/cogp.2000.0738
   Baskent D, 2016, J ACOUST SOC AM, V139, pEL51, DOI 10.1121/1.4942628
   Ben-Pazi H, 2006, NEUROPSYCHOLOGIA, V44, P412, DOI 10.1016/j.neuropsychologia.2005.05.022
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bharadwaj HM, 2015, J NEUROSCI, V35, P2161, DOI 10.1523/JNEUROSCI.3915-14.2015
   Bialystok E, 2009, J EXP PSYCHOL HUMAN, V35, P565, DOI 10.1037/a0012735
   Bidelman GM, 2015, J NEUROSCI, V35, P1240, DOI 10.1523/JNEUROSCI.3292-14.2015
   Birkett EE, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0042820
   Boebinger D, 2015, J ACOUST SOC AM, V137, P378, DOI 10.1121/1.4904537
   Boersma Paul, 2019, PRAAT DOING PHONETIC
   Bolger D, 2013, ACTA PSYCHOL, V142, P238, DOI 10.1016/j.actpsy.2012.11.012
   Bolia RS, 2000, J ACOUST SOC AM, V107, P1065, DOI 10.1121/1.428288
   Brochard R, 2013, COGNITION, V127, P214, DOI 10.1016/j.cognition.2013.01.007
   Brungart DS, 2006, J ACOUST SOC AM, V120, P4007, DOI 10.1121/1.2363929
   Brungart DS, 2001, J ACOUST SOC AM, V110, P2527, DOI 10.1121/1.1408946
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980
   Carey D, 2015, COGNITION, V137, P81, DOI 10.1016/j.cognition.2014.12.005
   Chapin HL, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00224
   Clayton KK, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157638
   Coffey EBJ, 2017, HEARING RES, V352, P49, DOI 10.1016/j.heares.2017.02.006
   Corrigall KA, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00282
   Corrigall KA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00222
   D'Souza AA, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0095-6
   Dai LS, 2018, P NATL ACAD SCI USA, V115, pE3286, DOI 10.1073/pnas.1721226115
   Darwin CJ, 2003, J ACOUST SOC AM, V114, P2913, DOI 10.1121/1.1616924
   Deroche MLD, 2017, J ACOUST SOC AM, V142, P1739, DOI 10.1121/1.5005496
   Dhamani I, 2013, SCI REP-UK, V3, DOI 10.1038/srep01297
   Dick FK, 2017, J NEUROSCI, V37, P12187, DOI 10.1523/JNEUROSCI.1436-17.2017
   Du Y, 2017, P NATL ACAD SCI USA, V114, P13579, DOI 10.1073/pnas.1712223114
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Fuller CD, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00179
   Gatehouse Stuart, 2008, Trends Amplif, V12, P145, DOI 10.1177/1084713808317395
   Germine L, 2012, PSYCHON B REV, V19, P847, DOI 10.3758/s13423-012-0296-9
   Gordon-Salant S, 2004, J ACOUST SOC AM, V115, P1808, DOI 10.1121/1.1645249
   Gosling SD, 2004, AM PSYCHOL, V59, P93, DOI 10.1037/0003-066X.59.2.93
   GREEN EJ, 1981, PERCEPT PSYCHOPHYS, V30, P459, DOI 10.3758/BF03204842
   Grose JH, 1996, J SPEECH HEAR RES, V39, P1149, DOI 10.1044/jshr.3906.1149
   HAUTUS MJ, 1995, BEHAV RES METH INS C, V27, P46, DOI 10.3758/BF03203619
   Heinrich A, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00576
   Heinrich A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00782
   Holochwost SJ, 2017, PSYCHOL AESTHET CREA, V11, P147, DOI 10.1037/aca0000112
   Holt LL, 2018, HEARING RES, V366, P50, DOI 10.1016/j.heares.2018.06.014
   Iversen J.R., 2008, P 10 INT C MUS PERC, V10, P465, DOI DOI 10.1016/J.HEARES.2007.10.007
   Kidd Gerald Jr., 2008, V29, P143
   Kitterick PT, 2010, J ACOUST SOC AM, V127, P2498, DOI 10.1121/1.3327507
   Large E. W., 1994, Connection Science, V6, P177, DOI 10.1080/09540099408915723
   Lee JH, 2012, J ACOUST SOC AM, V132, P1700, DOI 10.1121/1.4740482
   Mackersie CL, 2001, J SPEECH LANG HEAR R, V44, P19, DOI 10.1044/1092-4388(2001/002)
   Madsen SMK, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12937-9
   McAuley JD, 2003, J EXP PSYCHOL HUMAN, V29, P1102, DOI 10.1037/0096-1523.29.6.1102
   Meha-Bettison K, 2018, INT J AUDIOL, V57, P40, DOI 10.1080/14992027.2017.1380850
   Micheyl C, 2006, HEARING RES, V219, P36, DOI 10.1016/j.heares.2006.05.004
   Miller JE, 2013, PSYCHOL SCI, V24, P11, DOI 10.1177/0956797612446707
   Miyake A, 2000, COGNITIVE PSYCHOL, V41, P49, DOI 10.1006/cogp.1999.0734
   Morse-Fortier C, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517739427
   Moussard A, 2016, BRAIN RES, V1642, P146, DOI 10.1016/j.brainres.2016.03.028
   Neher T, 2011, J ACOUST SOC AM, V130, P1542, DOI 10.1121/1.3608122
   Neher T, 2009, INT J AUDIOL, V48, P758, DOI 10.3109/14992020903079332
   Oberfeld D, 2016, ELIFE, V5, DOI 10.7554/eLife.16747
   Oxenham AJ, 2003, J ACOUST SOC AM, V114, P1543, DOI 10.1121/1.1598197
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Pitcher TM, 2002, HUM MOVEMENT SCI, V21, P919, DOI 10.1016/S0167-9457(02)00167-7
   Repp BH, 2010, HUM MOVEMENT SCI, V29, P200, DOI 10.1016/j.humov.2009.08.002
   Robertson I H, 1996, J Int Neuropsychol Soc, V2, P525
   Rodrigues AC, 2013, BRAIN COGNITION, V82, P229, DOI 10.1016/j.bandc.2013.04.009
   Ruggles D, 2012, CURR BIOL, V22, P1417, DOI 10.1016/j.cub.2012.05.025
   Ruggles DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086980
   Schoof T, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00307
   Schroeder SR, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/4058620
   Sharma M, 2014, J SPEECH LANG HEAR R, V57, P2308, DOI 10.1044/2014_JSLHR-H-13-0226
   Shinn-Cunningham BG, 2008, TRENDS COGN SCI, V12, P182, DOI 10.1016/j.tics.2008.02.003
   Shinn-Cunningham Barbara G, 2008, Trends Amplif, V12, P283, DOI 10.1177/1084713808325306
   Slater J, 2017, EUR J NEUROSCI, V45, P952, DOI 10.1111/ejn.13535
   Slater J, 2016, COGN PROCESS, V17, P79, DOI 10.1007/s10339-015-0740-7
   Slevc LR, 2016, COGNITION, V152, P199, DOI 10.1016/j.cognition.2016.03.017
   Stone MA, 2012, J ACOUST SOC AM, V132, P317, DOI 10.1121/1.4725766
   Strait D, 2011, MUSIC PERCEPT, V29, P133, DOI 10.1525/MP.2011.29.2.133
   Swaminathan J, 2015, SCI REP-UK, V5, DOI 10.1038/srep11628
   Tervaniemi M, 2005, EXP BRAIN RES, V161, P1, DOI 10.1007/s00221-004-2044-5
   Tervaniemi M, 2009, EUR J NEUROSCI, V30, P1636, DOI 10.1111/j.1460-9568.2009.06955.x
   Tierney AT, 2013, BRAIN LANG, V124, P225, DOI 10.1016/j.bandl.2012.12.014
   Toplak ME, 2005, PERCEPT MOTOR SKILL, V100, P659, DOI 10.2466/PMS.100.3.659-675
   Travis F, 2011, CONSCIOUS COGN, V20, P1256, DOI 10.1016/j.concog.2011.03.020
   Vasuki PRM, 2016, HEARING RES, V342, P112, DOI 10.1016/j.heares.2016.10.008
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Yeend I, 2017, HEARING RES, V353, P224, DOI 10.1016/j.heares.2017.07.006
   Zendel BR, 2019, NEUROBIOL AGING, V81, P102, DOI 10.1016/j.neurobiolaging.2019.05.015
   Zendel BR, 2014, NEUROBIOL AGING, V35, P55, DOI 10.1016/j.neurobiolaging.2013.06.022
   Zendel BR, 2013, J COGNITIVE NEUROSCI, V25, P503, DOI 10.1162/jocn_a_00329
   Zendel BR, 2012, PSYCHOL AGING, V27, P410, DOI 10.1037/a0024816
   Zuk J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099868
NR 95
TC 3
Z9 3
U1 4
U2 11
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0278-7393
EI 1939-1285
J9 J EXP PSYCHOL LEARN
JI J. Exp. Psychol.-Learn. Mem. Cogn.
PD MAY
PY 2020
VL 46
IS 5
BP 968
EP 979
DI 10.1037/xlm0000767
PG 12
WC Psychology; Psychology, Experimental
SC Psychology
GA LC5VQ
UT WOS:000525399900009
PM 31580123
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Hendrickson, K
   Spinelli, J
   Walker, E
AF Hendrickson, Kristi
   Spinelli, Jessica
   Walker, Elizabeth
TI Cognitive processes underlying spoken word recognition during soft
   speech
SO COGNITION
LA English
DT Article
DE Speech perception; Spoken word recognition; Soft speech; Lexical
   competition; Adverse listening conditions
ID TIME-COURSE; COCHLEAR IMPLANTS; LISTENING EFFORT; ADULTS; INTEGRATION;
   PERCEPTION; CHILDREN; LANGUAGE; LEVEL; NOISE
AB In two eye-tracking experiments using the Visual World Paradigm, we examined how listeners recognize words when faced with speech at lower intensities (40, 50, and 65 dBA). After hearing the target word, participants (n = 32) clicked the corresponding picture from a display of four images - a target (e.g., money), a cohort competitor (e.g., mother), a rhyme competitor (e.g., honey) and an unrelated item (e.g., whistle) - while their eye-movements were tracked. For slightly soft speech (50 dBA), listeners demonstrated an increase in cohort activation, whereas for rhyme competitors, activation started later and was sustained longer in processing. For very soft speech (40 dBA), listeners waited until later in processing to activate potential words, as illustrated by a decrease in activation for cohorts, and an increase in activation for rhymes. Further, the extent to which words were considered depended on word length (mono- vs. bi-syllabic words), and speech-extrinsic factors such as the surrounding listening environment. These results advance current theories of spoken word recognition by considering a range of speech levels more typical of everyday listening environments. From an applied perspective, these results motivate models of how individuals who are hard of hearing approach the task of recognizing spoken words.
C1 [Hendrickson, Kristi; Spinelli, Jessica; Walker, Elizabeth] Univ Iowa, Dept Commun Sci & Disorders, 250 Hawkins Dr, Iowa City, IA 52242 USA.
   [Hendrickson, Kristi] Univ Iowa, Dept Psychol & Brain Sci, 250 Hawkins Dr, Iowa City, IA 52242 USA.
RP Hendrickson, K (corresponding author), Univ Iowa, Dept Commun Sci & Disorders, 250 Hawkins Dr, Iowa City, IA 52242 USA.
EM hendrickson@uiowa.edu; jessica-spinelli@uiowa.edu;
   elizabeth-walker@uiowa.edu
OI Hendrickson, Kristi/0000-0001-8843-6615
FU Iowa Center for Research by Undergraduates (ICRU)
FX This research was supported by the Iowa Center for Research by
   Undergraduates (ICRU) awarded to the 2nd author. We thank Kathryn Gabel,
   Lindsey Meyer, and Lyndi Roecker for assistance with data collection.
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Apfelbaum KS, 2011, PSYCHON B REV, V18, P141, DOI 10.3758/s13423-010-0039-8
   Ben-David BM, 2011, J SPEECH LANG HEAR R, V54, P243, DOI 10.1044/1092-4388(2010/09-0233)
   Bjork R. A., 1994, METACOGNITION KNOWIN, P185
   Boersma Paul, 2019, PRAAT DOING PHONETIC
   Brouwer S, 2016, J PSYCHOLINGUIST RES, V45, P1151, DOI 10.1007/s10936-015-9396-9
   Brouwer S, 2014, J ACOUST SOC AM, V136, pEL26, DOI 10.1121/1.4881322
   Brouwer S, 2012, LANG COGNITIVE PROC, V27, P539, DOI 10.1080/01690965.2011.555268
   Clopper CG, 2014, LAB PHONOL, V5, P69, DOI 10.1515/lp-2014-0004
   COOPER RM, 1974, COGNITIVE PSYCHOL, V6, P84, DOI 10.1016/0010-0285(74)90005-X
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750
   Dahan D., 2006, HDB PSYCHOLINGUISTIC, P249, DOI DOI 10.1016/B978-012369374-7/50009-2
   Davidson LS, 2006, EAR HEARING, V27, P493, DOI 10.1097/01.aud.0000234635.48564.ce
   Farris-Trimble A., 2013, J SPEECH LANGUAGE HE, V56
   Farris-Trimble A, 2014, J EXP PSYCHOL HUMAN, V40, P308, DOI 10.1037/a0034353
   Fraser S, 2010, J SPEECH LANG HEAR R, V53, P18, DOI 10.1044/1092-4388(2009/08-0140)
   Frauenfelder UH, 2001, LANG COGNITIVE PROC, V16, P583, DOI 10.1080/01690960143000146
   Gosselin PA, 2011, J SPEECH LANG HEAR R, V54, P944, DOI 10.1044/1092-4388(2010/10-0069)
   Hicks CB, 2002, J SPEECH LANG HEAR R, V45, P573, DOI 10.1044/1092-4388(2002/046)
   Holden LK, 2013, EAR HEARING, V34, P342, DOI 10.1097/AUD.0b013e3182741aa7
   Holden LK, 2011, INT J AUDIOL, V50, P255, DOI 10.3109/14992027.2010.533200
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Luce PA, 1998, PERCEPT PSYCHOPHYS, V60, P484, DOI 10.3758/BF03206868
   MARSLENWILSON W, 1989, J EXP PSYCHOL HUMAN, V15, P576, DOI 10.1037/0096-1523.15.3.576
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B., 2019, DO YOU DEAL UNCERTAI
   McMurray B, 2017, COGNITION, V169, P147, DOI 10.1016/j.cognition.2017.08.013
   McMurray B, 2016, EAR HEARING, V37, pe37, DOI 10.1097/AUD.0000000000000207
   McMurray B, 2010, COGNITIVE PSYCHOL, V60, P1, DOI 10.1016/j.cogpsych.2009.06.003
   McMurray B, 2009, J MEM LANG, V60, P65, DOI 10.1016/j.jml.2008.07.002
   McQueen JM, 2012, J ACOUST SOC AM, V131, P509, DOI 10.1121/1.3664087
   Moberly AC, 2016, OTOL NEUROTOL, V37, P1522, DOI 10.1097/MAO.0000000000001211
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Olsen W. O., 1998, AM J AUDIOL, V7, P21, DOI DOI 10.1044/1059-0889(1998/012)
   Pearsons K. S., 1977, SPEECH LEVELS VARIOU
   Peng SC, 2012, TRENDS AMPLIF, V16, P67, DOI 10.1177/1084713812451159
   R Core Team, 2014, R LANG ENV STAT COMP
   Scharenborg O, 2018, J EXP PSYCHOL LEARN, V44, P233, DOI 10.1037/xlm0000441
   Seedorff M, 2018, J MEM LANG, V102, P55, DOI 10.1016/j.jml.2018.05.004
   Simmons E., 2018, P 40 ANN C COGN SCI, P1064
   Skinner MW, 1997, J ACOUST SOC AM, V101, P3766, DOI 10.1121/1.418383
   Smith F., 2018, AC SOC AM ANN M BA C
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   van der Feest SVH, 2019, J PHONETICS, V73, P158, DOI 10.1016/j.wocn.2019.01.003
   Weber A, 2012, WIRES COGN SCI, V3, P387, DOI 10.1002/wcs.1178
   Winn MB, 2015, J ACOUST SOC AM, V137, P1430, DOI 10.1121/1.4908308
   Wu YH, 2016, EAR HEARING, V37, P660, DOI 10.1097/AUD.0000000000000335
   Zekveld AA, 2010, EAR HEARING, V31, P480, DOI 10.1097/AUD.0b013e3181d4f251
NR 51
TC 1
Z9 1
U1 4
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD MAY
PY 2020
VL 198
AR 104196
DI 10.1016/j.cognition.2020.104196
PG 15
WC Psychology, Experimental
SC Psychology
GA LB2IE
UT WOS:000524456500005
PM 32004934
DA 2021-02-24
ER

PT J
AU Son, G
AF Son, Gayeon
TI Korean-speaking children's perceptual development in multidimensional
   acoustic space
SO JOURNAL OF CHILD LANGUAGE
LA English
DT Article
DE stop contrasts; speech perception; F0
ID SPOKEN WORD RECOGNITION; VOICE ONSET TIME; LEXICAL TONE;
   FUNDAMENTAL-FREQUENCY; SPEECH-PERCEPTION; STOPS; ACQUISITION; INFANTS;
   CONSONANTS; VOWEL
AB This study investigated how Korean toddlers' perception of stop categories develops in the acoustic dimensions of VOT and F0. To examine the developmental trajectory of VOT and F0 in toddlers' perceptual space, a perceptual identification test with natural and synthesized sound stimuli was conducted with 58 Korean monolingual children (aged 2-4 years). The results revealed that toddlers' perceptual mapping functions on VOT mainly in the high-pitch environment, resulting in more successful perceptual accuracy in fortis or aspirated stops than in lenis stops. F0 development is correlated with the perceptual distinction of lenis from aspirated stops, but no consistent categorical perception for F0 was found before four years of age. The findings suggest that multi-parametric control in perceptual development guides an acquisition ordering of Korean stop phonemes and that tonal development is significantly related to the acquisition of Korean phonemic contrasts.
C1 [Son, Gayeon] Univ Penn, Dept Linguist, Philadelphia, PA 19104 USA.
   [Son, Gayeon] Kwangwoon Univ, Dept English Language & Literature, Seoul, South Korea.
RP Son, G (corresponding author), Dept English Language & Literature, 20 Kwangwoon Ro, Seoul 01897, South Korea.
EM gson@kw.ac.kr
FU Kwangwoon University
FX This study was based on Chapter 3 and Chapter 4 of the author's
   dissertation (Son, 2017). I would like to thank Mark Liberman and Daniel
   Swingley for discussions about the experiment. I am grateful to Melanie
   Soderstrom and two anonymous reviewers for their helpful suggestions.
   The present research has been conducted under a Research Grant of
   Kwangwoon University in 2018.
CR [Anonymous], 2018, CANC DISCOV, V8, pOF6
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boersma P, 2015, PRAAT DOING PHONETIC
   Cho T, 1999, J PHONETICS, V27, P207, DOI 10.1006/jpho.1999.0094
   Cho T., 1996, THESIS
   Cho TH, 2002, J PHONETICS, V30, P193, DOI 10.1006/jpho.2001.0153
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   HAN JI, 1992, CLS, V28, P206
   HAN MS, 1970, PHONETICA, V22, P112, DOI 10.1159/000259311
   Hanson HM, 2009, J ACOUST SOC AM, V125, P425, DOI 10.1121/1.3021306
   Hardcastle W. J., 1973, J PHONETICS, V1, P263
   Haudricourt A.-G., 1954, J ASIATIQUE, V142, P69
   Hay JF, 2015, CHILD DEV, V86, P10, DOI 10.1111/cdev.12269
   HIROSE H, 1974, J PHONETICS, V2, P145
   HOMBERT JM, 1979, LANGUAGE, V55, P37, DOI 10.2307/412518
   HOUSE AS, 1953, J ACOUST SOC AM, V25, P105, DOI 10.1121/1.1906982
   Jakobson R., 1968, CHILD LANGUAGE APHAS
   Jun Sun-Ah, 1996, UCLA WORKING PAPERS, V92, P97
   KAGAYA R, 1974, J PHON, V2, P161
   Kang KH, 2008, J ACOUST SOC AM, V124, P3909, DOI 10.1121/1.2988292
   Kang YJ, 2014, J PHONETICS, V45, P76, DOI 10.1016/j.wocn.2014.03.005
   KEATING P, 1983, J PHONETICS, V11, P277, DOI 10.1016/S0095-4470(19)30827-7
   Kewley-Port D., 1974, J PHONET, V2, P195, DOI [10.1016/s0095- 4470(19)31270-7, DOI 10.1016/S0095-4470(19)31270-7]
   KIM CW, 1970, PHONETICA, V21, P107, DOI 10.1159/000259293
   Kim M.S., 1994, THESIS
   Kim M, 2009, J ACOUST SOC AM, V125, P3950, DOI 10.1121/1.3123402
   Ko E.-S., 2018, P 1 HAN INT S PHON C, P30
   Kochetov A, 2017, CAN J LING/REV CAN L, V62, P18, DOI 10.1017/cnj.2016.39
   Kong EJ, 2018, LANG SPEECH, V61, P384, DOI 10.1177/0023830917729840
   Kong EJ, 2011, J PHONETICS, V39, P196, DOI 10.1016/j.wocn.2011.02.002
   KRUMHANSL CL, 1990, PSYCHOL SCI, V1, P70, DOI 10.1111/j.1467-9280.1990.tb00070.x
   Lee S, 2008, KOREAN LINGUIST, V14, P21, DOI 10.1075/kl.14.02sl
   LI CN, 1977, J CHILD LANG, V4, P185, DOI 10.1017/S0305000900001598
   Logan J. S., 1992, THESIS
   Lombardi L., 1991, THESIS
   Metsala JL, 1997, J EDUC PSYCHOL, V89, P159, DOI 10.1037/0022-0663.89.1.159
   NELSON DGK, 1989, J CHILD LANG, V16, P55, DOI 10.1017/S030500090001343X
   Pae Soyeong, 2004, Communication Sciences and Disorders, V9, P45
   R Development Core Team, 2011, R LANG ENV STAT COMP
   Raudenbush SW, 2002, MULT APPL BK SER, P25
   Shuai L., 2012, J ACOUST SOC AM, V131, P3309
   Silva D. J., 2006, PHONOLOGY, V23, P287, DOI DOI 10.1017/S0952675706000911
   Singh L., 2016, FRONT PSYCHOL, V7, pe00667
   Singh L, 2016, J PHONETICS, V55, P109, DOI 10.1016/j.wocn.2015.12.005
   Singh L, 2014, DEVELOPMENTAL SCI, V17, P94, DOI 10.1111/desc.12097
   Singh L, 2012, COGNITION, V124, P128, DOI 10.1016/j.cognition.2012.05.008
   Snijders T, 1999, MULTILEVEL ANAL
   Son G., 2017, THESIS
   STEVENS KN, 1974, J ACOUST SOC AM, V55, P653, DOI 10.1121/1.1914578
   Swingley D, 1999, COGNITION, V71, P73, DOI 10.1016/S0010-0277(99)00021-9
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Swingley D, 2002, PSYCHOL SCI, V13, P480, DOI 10.1111/1467-9280.00485
   Swingley D, 2009, PHILOS T R SOC B, V364, P3617, DOI 10.1098/rstb.2009.0107
   TRAINOR LJ, 1992, J EXP PSYCHOL HUMAN, V18, P394, DOI 10.1037/0096-1523.18.2.394
   TSE JKP, 1978, J CHILD LANG, V5, P191, DOI 10.1017/S0305000900007418
   Tuaycharoen P., 1977, THESIS
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Winn MB, 2013, J SPEECH LANG HEAR R, V56, P1097, DOI 10.1044/1092-4388(2012/12-0086)
   Wright J., 2007, THESIS
NR 59
TC 0
Z9 0
U1 1
U2 6
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0305-0009
EI 1469-7602
J9 J CHILD LANG
JI J. Child Lang.
PD MAY
PY 2020
VL 47
IS 3
BP 579
EP 599
AR PII S0305000919000692
DI 10.1017/S0305000919000692
PG 21
WC Psychology, Developmental; Linguistics; Psychology, Experimental
SC Psychology; Linguistics
GA LB9HZ
UT WOS:000524941100004
PM 31722761
DA 2021-02-24
ER

PT J
AU Jasmin, K
   Dick, F
   Holt, LL
   Tierney, A
AF Jasmin, Kyle
   Dick, Fred
   Holt, Lori L.
   Tierney, Adam
TI Tailored Perception: Individuals' Speech and Music Perception Strategies
   Fit Their Perceptual Abilities
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-GENERAL
LA English
DT Article
DE amusia; duration; music; pitch; speech
ID VOICE ONSET TIME; CONGENITAL AMUSIA; ACOUSTIC CUES;
   FUNDAMENTAL-FREQUENCY; LANGUAGE IMPAIRMENT; SELECTIVE ATTENTION; PITCH
   STRUCTURE; BRAIN; CATEGORIZATION; INFORMATION
AB Perception involves integration of multiple dimensions that often serve overlapping, redundant functions, for example, pitch, duration, and amplitude in speech. Individuals tend to prioritize these dimensions differently (stable, individualized perceptual strategies), but the reason for this has remained unclear. Here we show that perceptual strategies relate to perceptual abilities. In a speech cue weighting experiment (trial N = 990), we first demonstrate that individuals with a severe deficit for pitch perception (congenital amusics; N = 11) categorize linguistic stimuli similarly to controls (N = 11) when the main distinguishing cue is duration, which they perceive normally. In contrast, in a prosodic task where pitch cues are the main distinguishing factor, we show that amusics place less importance on pitch and instead rely more on duration cues- even when pitch differences in the stimuli are large enough for amusics to discern. In a second experiment testing musical and prosodic phrase interpretation (N = 16 amusics; 15 controls), we found that relying on duration allowed amusics to overcome their pitch deficits to perceive speech and music successfully. We conclude that auditory signals, because of their redundant nature, are robust to impairments for specific dimensions, and that optimal speech and music perception strategies depend not only on invariant acoustic dimensions (the physical signal), but on perceptual dimensions whose precision varies across individuals. Computational models of speech perception (indeed, all types of perception involving redundant cues e.g., vision and touch) should therefore aim to account for the precision of perceptual dimensions and characterize individuals as well as groups.
C1 [Jasmin, Kyle; Dick, Fred; Tierney, Adam] Birkbeck Univ London, Dept Psychol Sci, Malet St, London WC1E 7HX, England.
   [Jasmin, Kyle] UCL, Inst Cognit Neurosci, London, England.
   [Dick, Fred] UCL, Dept Expt Psychol, London, England.
   [Holt, Lori L.] Carnegie Mellon Univ, Dept Psychol, Pittsburgh, PA 15213 USA.
RP Jasmin, K (corresponding author), Birkbeck Univ London, Dept Psychol Sci, Malet St, London WC1E 7HX, England.
EM k.jasmin@bbk.ac.uk
FU Wellcome TrustWellcome TrustEuropean Commission [109719/Z/15/Z];
   Leverhulme TrustLeverhulme Trust; Reg and Molly Buck Award from SEMPRE
FX Kyle Jasmin, Fred Dick, and Adam Tierney developed the study concept.
   All authors contributed to the design. Kyle Jasmin performed testing,
   data collection, and data analysis and drafted the manuscript. Fred
   Dick, Adam Tierney, and Lori Holt provided critical revisions. All
   authors approved the final version of the manuscript for submission. We
   thank Stuart Rosen, Marcus Pearce, Laura Staum-Casasanto, Alex Martin,
   Aniruddh Patel, Clare Press, and Lauren Stewart for helpful comments and
   discussion. We also thank all our participants. The work was funded by a
   Wellcome Trust Seed Award 109719/Z/15/Z to Adam Tierney, a Reg and Molly
   Buck Award from SEMPRE to Kyle Jasmin, and a Leverhulme Trust Early
   Career Fellowship to Kyle Jasmin. The data that support the findings of
   this study are available in the Birkbeck data repository (BiRD).; This
   article has been published under the terms of the Creative Commons
   Attribution License (http://creativecommons.org/licenses/by/3.0/), which
   permits unrestricted use, distribution, and reproduction in any medium,
   provided the original author and source are credited. Copyright for this
   article is retained by the author(s). Author(s) grant(s) the American
   Psychological Association the exclusive right to publish the article and
   identify itself as the original publisher.
CR Anwyl-Irvine A., 2019, BEHAV RES METHODS, DOI [10.1101/438242, DOI 10.1101/438242]
   Aydelott J, 2012, LANG COGNITIVE PROC, V27, P1108, DOI 10.1080/01690965.2011.589735
   Ayotte J, 2002, BRAIN, V125, P238, DOI 10.1093/brain/awf028
   Bavin EL, 2010, LANG SPEECH, V53, P31, DOI 10.1177/0023830909349151
   Bella SD, 2009, J ACOUST SOC AM, V126, P414, DOI 10.1121/1.3132504
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   Bentrovato S, 2003, J PSYCHOLINGUIST RES, V32, P417, DOI 10.1023/A:1024899513147
   Beskow J., 2006, 9 INT C SPOK LANG PR
   Boebinger D, 2015, J ACOUST SOC AM, V137, P378, DOI 10.1121/1.4904537
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Boets B, 2008, BRAIN LANG, V106, P29, DOI 10.1016/j.bandl.2007.12.004
   BOLTZ M, 1989, J EXP PSYCHOL HUMAN, V15, P749, DOI 10.1037/0096-1523.15.4.749
   BOLTZ M, 1989, PERCEPT PSYCHOPHYS, V46, P9, DOI 10.3758/BF03208069
   Breen M, 2010, LANG COGNITIVE PROC, V25, P1044, DOI 10.1080/01690965.2010.504378
   Brochard R, 2003, PSYCHOL SCI, V14, P362, DOI 10.1111/1467-9280.24441
   Chandrasekaran B, 2012, J NEUROPHYSIOL, V107, P1325, DOI 10.1152/jn.00923.2011
   Chandrasekaran B, 2010, J ACOUST SOC AM, V128, P456, DOI 10.1121/1.3445785
   Chrabaszcz A, 2014, J SPEECH LANG HEAR R, V57, P1468, DOI 10.1044/2014_JSLHR-L-13-0279
   CONNINE CM, 1987, J EXP PSYCHOL HUMAN, V13, P291, DOI 10.1037/0096-1523.13.2.291
   Del Giudice M, 2007, DEV PSYCHOL, V43, P796, DOI 10.1037/0012-1649.43.3.796
   DEPIJPER JR, 1994, J ACOUST SOC AM, V96, P2037, DOI 10.1121/1.410145
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   Ellis RJ, 2009, J EXP PSYCHOL HUMAN, V35, P264, DOI 10.1037/a0013482
   Elman Jeffrey L, 2009, Cogn Sci, V33, P547
   FEAR BD, 1995, J ACOUST SOC AM, V97, P1893, DOI 10.1121/1.412063
   Feldman H, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00215
   Flecha-Garcia ML, 2010, SPEECH COMMUN, V52, P542, DOI 10.1016/j.specom.2009.12.003
   Francis AL, 2000, PERCEPT PSYCHOPHYS, V62, P1668, DOI 10.3758/BF03212164
   Francis AL, 2008, J ACOUST SOC AM, V124, P1234, DOI 10.1121/1.2945161
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Gordon E., 2002, PRIMARY MEASURES MUS
   Goulet GM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036860
   Grassi M, 2009, BEHAV RES METHODS, V41, P20, DOI 10.3758/BRM.41.1.20
   HAGGARD M, 1970, J ACOUST SOC AM, V47, P613, DOI 10.1121/1.1911936
   Hannon EE, 2004, J EXP PSYCHOL HUMAN, V30, P956, DOI 10.1037/0096-1523.30.5.956
   HAZAN V, 1991, PERCEPT PSYCHOPHYS, V49, P187, DOI 10.3758/BF03205038
   Hebets EA, 2016, P ROY SOC B-BIOL SCI, V283, DOI 10.1098/rspb.2015.2889
   Helbig HB, 2007, EXP BRAIN RES, V179, P595, DOI 10.1007/s00221-006-0814-y
   Holt LL, 2008, CURR DIR PSYCHOL SCI, V17, P42, DOI 10.1111/j.1467-8721.2008.00545.x
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Holt LL, 2018, HEARING RES, V366, P50, DOI 10.1016/j.heares.2018.06.014
   Hutchins S, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00236
   Hyde KL, 2004, PSYCHOL SCI, V15, P356, DOI 10.1111/j.0956-7976.2004.00683.x
   Idemaru K, 2014, J EXP PSYCHOL HUMAN, V40, P1009, DOI 10.1037/a0035269
   Idemaru K, 2013, J ACOUST SOC AM, V133, P4232, DOI 10.1121/1.4802905
   Idemaru K, 2012, J ACOUST SOC AM, V132, P3950, DOI 10.1121/1.4765076
   Idemaru K, 2011, J EXP PSYCHOL HUMAN, V37, P1939, DOI 10.1037/a0025641
   Jiang CM, 2010, NEUROPSYCHOLOGIA, V48, P2630, DOI 10.1016/j.neuropsychologia.2010.05.009
   JUSCZYK PW, 1993, J EXP PSYCHOL HUMAN, V19, P627, DOI 10.1037/0096-1523.19.3.627
   Kachlicka M, 2019, BRAIN LANG, V192, P15, DOI 10.1016/j.bandl.2019.02.004
   Karlin JE, 1942, PSYCHOMETRIKA, V7, P251, DOI 10.1007/BF02288628
   Kawahara H, 2005, SPEECH SEPARATION BY HUMANS AND MACHINES, P167, DOI 10.1007/0-387-22794-6_11
   Kidd GR, 2007, J ACOUST SOC AM, V122, P418, DOI 10.1121/1.2743154
   Kim D, 2018, J PHONETICS, V67, P1, DOI 10.1016/j.wocn.2017.11.003
   Kjelgaard MM, 1999, J MEM LANG, V40, P153, DOI 10.1006/jmla.1998.2620
   Kong EJ, 2016, J PHONETICS, V59, P40, DOI 10.1016/j.wocn.2016.08.006
   Krahmer E, 2007, J MEM LANG, V57, P396, DOI 10.1016/j.jml.2007.06.005
   Lerdahl F., 1985, GENERATIVE THEORY TO
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Lim SJ, 2011, COGNITIVE SCI, V35, P1390, DOI 10.1111/j.1551-6709.2011.01192.x
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   LISKER L, 1957, LANGUAGE, V33, P42, DOI 10.2307/410949
   Liu F, 2015, NEUROPSYCHOLOGIA, V66, P111, DOI 10.1016/j.neuropsychologia.2014.11.001
   Liu F, 2010, BRAIN, V133, P1682, DOI 10.1093/brain/awq089
   Liu R, 2015, J EXP PSYCHOL HUMAN, V41, P1783, DOI 10.1037/xhp0000092
   Loui P, 2008, CURR BIOL, V18, pR331, DOI 10.1016/j.cub.2008.02.045
   Lu YY, 2009, SPEECH COMMUN, V51, P1253, DOI 10.1016/j.specom.2009.07.002
   Lutfi RA, 2007, J ACOUST SOC AM, V122, P1017, DOI 10.1121/1.2751269
   Marco EJ, 2011, PEDIATR RES, V69, p48R, DOI [10.1203/PDR.0b013e3182130c54, 10.1109/SPL.2011.5782616]
   MASSARO DW, 1976, J ACOUST SOC AM, V60, P704, DOI 10.1121/1.381143
   MASSARO DW, 1977, PERCEPT PSYCHOPHYS, V22, P373, DOI 10.3758/BF03199703
   MASSARO DW, 1993, J EXP PSYCHOL GEN, V122, P115, DOI 10.1037/0096-3445.122.1.115
   Mattys SL, 2000, PERCEPT PSYCHOPHYS, V62, P253, DOI 10.3758/BF03205547
   Mayo C, 2004, J ACOUST SOC AM, V115, P3184, DOI 10.1121/1.1738838
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   McMurray B, 2008, J EXP PSYCHOL HUMAN, V34, P1609, DOI 10.1037/a0011747
   Moreau P, 2013, BRAIN COGNITION, V81, P337, DOI 10.1016/j.bandc.2013.01.004
   Nan Y, 2010, BRAIN, V133, P2635, DOI 10.1093/brain/awq178
   O'Connor K, 2012, NEUROSCI BIOBEHAV R, V36, P836, DOI 10.1016/j.neubiorev.2011.11.008
   Omigie D, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00109
   PALMER C, 1987, J EXP PSYCHOL HUMAN, V13, P116, DOI 10.1037/0096-1523.13.1.116
   Patel AD, 2005, BRAIN COGNITION, V59, P310, DOI 10.1016/j.bandc.2004.10.003
   Patel AD, 2008, MUSIC PERCEPT, V25, P357, DOI 10.1525/MP.2008.25.4.357
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Peretz I, 2005, ANN NEUROL, V58, P478, DOI 10.1002/ana.20606
   Peretz I, 2003, ANN NY ACAD SCI, V999, P58, DOI 10.1196/annals.1284.006
   Peretz I, 2002, NEURON, V33, P185, DOI 10.1016/S0896-6273(01)00580-3
   Peretz I, 2017, EUR J HUM GENET, V25, P625, DOI 10.1038/ejhg.2017.15
   Peretz I, 2009, BRAIN, V132, P1277, DOI 10.1093/brain/awp055
   Phillips-Silver J, 2011, NEUROPSYCHOLOGIA, V49, P961, DOI 10.1016/j.neuropsychologia.2011.02.002
   Price CJ, 2002, TRENDS COGN SCI, V6, P416, DOI 10.1016/S1364-6613(02)01976-9
   Prince JB, 2018, J EXP PSYCHOL HUMAN, V44, P1356, DOI 10.1037/xhp0000542
   Prince JB, 2017, PSYCHOL RES-PSYCH FO, V81, P255, DOI 10.1007/s00426-015-0737-y
   Prince JB, 2014, J EXP PSYCHOL HUMAN, V40, P2073, DOI 10.1037/a0037730
   Prince JB, 2011, Q J EXP PSYCHOL, V64, P2125, DOI 10.1080/17470218.2011.573080
   Prince JB, 2009, MEM COGNITION, V37, P368, DOI 10.3758/MC.37.3.368
   R Core Team, 2018, R LANG ENV STAT COMP
   Ramus F, 2013, BRAIN, V136, P630, DOI 10.1093/brain/aws356
   RICCIO CA, 1994, J AM ACAD CHILD PSY, V33, P849, DOI 10.1097/00004583-199407000-00011
   Rosen S, 2003, J PHONETICS, V31, P509, DOI 10.1016/S0095-4470(03)00046-9
   Schaffrath Helmut, 1995, ESSEN FOLKSONG COLLE
   Schertz J, 2016, ATTEN PERCEPT PSYCHO, V78, P355, DOI 10.3758/s13414-015-0987-1
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   Sluijter AMC, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P630, DOI 10.1109/ICSLP.1996.607440
   STANKOV L, 1980, J EDUC PSYCHOL, V72, P21, DOI 10.1037/0022-0663.72.1.21
   STREETER LA, 1978, J ACOUST SOC AM, V64, P1582, DOI 10.1121/1.382142
   Surprenant AM, 2001, J ACOUST SOC AM, V110, P2085, DOI 10.1121/1.1404973
   Tierney AT, 2011, P NATL ACAD SCI USA, V108, P15510, DOI 10.1073/pnas.1103882108
   Tillmann B, 2016, NEUROPSYCHOLOGIA, V85, P10, DOI 10.1016/j.neuropsychologia.2016.02.027
   Toscano JC, 2010, COGNITIVE SCI, V34, P434, DOI 10.1111/j.1551-6709.2009.01077.x
   Utman JA, 2000, PERCEPT PSYCHOPHYS, V62, P1297, DOI 10.3758/BF03212131
   Vuvan DT, 2015, CORTEX, V69, P186, DOI 10.1016/j.cortex.2015.05.002
   Wallentin M, 2010, LEARN INDIVID DIFFER, V20, P188, DOI 10.1016/j.lindif.2010.02.004
   WATSON C S, 1982, Journal of the Acoustical Society of America, V71, pS73
   Watson Charles S., 2002, Seminars in Hearing, V23, P83, DOI 10.1055/s-2002-24978
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487
   Winn MB, 2013, J SPEECH LANG HEAR R, V56, P1097, DOI 10.1044/1092-4388(2012/12-0086)
   Winter B, 2014, BIOESSAYS, V36, P960, DOI 10.1002/bies.201400028
   Wu Y. C., 2018, P COGN SCI SOC
   Yu ACL, 2019, ANNU REV LINGUIST, V5, P131, DOI 10.1146/annurev-linguistics-011516-033815
   Zhang XJ, 2018, J EXP PSYCHOL HUMAN, V44, P1760, DOI 10.1037/xhp0000569
NR 122
TC 5
Z9 5
U1 1
U2 2
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0096-3445
EI 1939-2222
J9 J EXP PSYCHOL GEN
JI J. Exp. Psychol.-Gen.
PD MAY
PY 2020
VL 149
IS 5
BP 914
EP 934
DI 10.1037/xge0000688
PG 21
WC Psychology, Experimental
SC Psychology
GA LA6LC
UT WOS:000524056500007
PM 31589067
OA Green Published, Other Gold, Green Accepted
DA 2021-02-24
ER

PT J
AU Cruz, M
   Butler, J
   Severino, C
   Filipe, M
   Frota, S
AF Cruz, Marisa
   Butler, Joseph
   Severino, Catia
   Filipe, Marisa
   Frota, Sonia
TI Eyes or mouth? Exploring eye gaze patterns and their relation with early
   stress perception in European Portuguese
SO JOURNAL OF PORTUGUESE LINGUISTICS
LA English
DT Article
DE eye gaze; language development; infant stress perception; European
   Portuguese
ID VISUAL LANGUAGE DISCRIMINATION; SELECTIVE ATTENTION; INFANT PERCEPTION;
   SPEECH-PERCEPTION; AUDIOVISUAL SPEECH; BRAIN RESPONSES; FACE; TALKING;
   BILINGUALISM; BEHAVIOR
AB Previous research has shown that eye gaze patterns relate to language development, with more attention to the mouth signaling ongoing acquisition. We examined infants' eye gaze in a stress perception experiment, in which European Portuguese (EP) learning infants showed a preference for the iambic stress pattern. Specifically, we asked whether there was a relation between eye gaze patterns and the preferred stress pattern. Eye gaze patterns of 25 monolingual typically developing infants aged 5-6 months old were examined using eye-tracking. Our results show that, although an interaction between looks to the area of interest (face, eyes, mouth, and arm) and stress preference was not found, eye gaze to the mouth region (and to the face) was modulated by the stress pattern, with more attention to the mouth in infants that do not show an iambic preference. These findings add further support for infants' use of eye gaze in early language development. They also highlight the need for multimodal approaches for a better understanding of language development. In the particular case of the challenging topic of the acquisition of stress in European Portuguese, they provide converging evidence for an advantage of iambic stress in early development. (195 words).
C1 [Cruz, Marisa; Butler, Joseph; Severino, Catia; Filipe, Marisa; Frota, Sonia] Univ Lisbon, Ctr Linguist, Sch Arts & Humanities, Lisbon, Portugal.
RP Cruz, M (corresponding author), Univ Lisbon, Ctr Linguist, Sch Arts & Humanities, Lisbon, Portugal.
EM marisasousacruz@gmail.com
FU FCT - Fundacao para a Ciencia e a TecnologiaPortuguese Foundation for
   Science and Technology [PTDC/MHCLIN/3901/2014, PTDC/LLT-LIN/29338/2017]
FX A special acknowledgement is due to all infants and their families for
   participating in this study. This research was developed within the
   projects Horizon21 - Early Language Development in Down Syndrome
   (PTDC/MHCLIN/3901/2014) and PLOs - Predictors of Language Outcomes
   (PTDC/LLT-LIN/29338/2017), both funded by FCT - Fundacao para a Ciencia
   e a Tecnologia.
CR Amso D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085701
   Annaz D, 2009, J EXP CHILD PSYCHOL, V102, P456, DOI 10.1016/j.jecp.2008.11.005
   Atkinson J, 2012, DEV MED CHILD NEUROL, V54, P589, DOI 10.1111/j.1469-8749.2012.04294.x
   Ayneto A, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12446
   Bhatara A., 2018, DEV PROSODY 1 LANGUA, V23, P37, DOI [10.1075/tilar.23.03bha, DOI 10.1075/TILAR.23.03BHA]
   Birules J, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12755
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   de Boisferon AH, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12381
   Di Giorgio E, 2012, J EXP CHILD PSYCHOL, V113, P66, DOI 10.1016/j.jecp.2012.04.012
   Fort M, 2018, LANG LEARN, V68, P31, DOI 10.1111/lang.12273
   Frank MC, 2009, COGNITION, V110, P160, DOI 10.1016/j.cognition.2008.11.010
   Friederici AD, 2007, CURR BIOL, V17, P1208, DOI 10.1016/j.cub.2007.06.011
   Frota S., TRANSLATED PERMISSIO
   Frota S., EUROPEAN PORTU UNPUB
   Frota S., 2003, COMMUNICATION SYMBOL
   Frota S, 2016, FIRST LANG, V36, P525, DOI 10.1177/0142723716648867
   Gliga T, 2009, INFANCY, V14, P550, DOI 10.1080/15250000903144199
   Hohle B, 2009, INFANT BEHAV DEV, V32, P262, DOI 10.1016/j.infbeh.2009.03.004
   Irwin JR, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00397
   Johnels JA, 2014, J SPEECH LANG HEAR R, V57, P2246, DOI 10.1044/2014_JSLHR-L-13-0268
   JOHNSON MH, 1991, COGNITION, V40, P1, DOI 10.1016/0010-0277(91)90045-6
   Jones W, 2013, NATURE, V504, P427, DOI 10.1038/nature12715
   JUSCZYK PW, 1993, CHILD DEV, V64, P675, DOI 10.2307/1131210
   Kuhl PK, 2014, P NATL ACAD SCI USA, V111, P11238, DOI 10.1073/pnas.1410963111
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Leppanen JM, 2016, CHILD DEV PERSPECT, V10, P161, DOI 10.1111/cdep.12180
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Lewkowicz DJ, 2010, DEV PSYCHOL, V46, P66, DOI 10.1037/a0015579
   Lu S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02486
   MACKAIN K, 1983, SCIENCE, V219, P1347, DOI 10.1126/science.6828865
   Morin-Lessard E, 2019, DEV PSYCHOL, V55, P1640, DOI 10.1037/dev0000750
   Munhalll KG, 2012, CURR BIOL, V22, pR190, DOI 10.1016/j.cub.2012.02.026
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Pejovic J., INT J UNPUB
   Pejovic J., 2019, THESIS
   Pons F, 2015, PSYCHOL SCI, V26, P490, DOI 10.1177/0956797614568320
   Pons F, 2014, ACTA PSYCHOL, V149, P142, DOI 10.1016/j.actpsy.2013.12.013
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Rosenblum LD, 1997, PERCEPT PSYCHOPHYS, V59, P347, DOI 10.3758/BF03211902
   Rosset DB, 2008, J AUTISM DEV DISORD, V38, P919, DOI 10.1007/s10803-007-0465-2
   Sebastian-Galles N, 2012, PSYCHOL SCI, V23, P994, DOI 10.1177/0956797612436817
   Tenenbaum EJ, 2015, J CHILD LANG, V42, P1173, DOI 10.1017/S0305000914000725
   Tenenbaum EJ, 2013, INFANCY, V18, P534, DOI 10.1111/j.1532-7078.2012.00135.x
   Tsang T, 2018, J EXP CHILD PSYCHOL, V169, P93, DOI 10.1016/j.jecp.2018.01.002
   van der Geest JN, 2002, J CHILD PSYCHOL PSYC, V43, P669, DOI 10.1111/1469-7610.00055
   Weber C, 2004, COGNITIVE BRAIN RES, V18, P149, DOI 10.1016/j.cogbrainres.2003.10.001
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   Wetherby A. M., 2003, CSBS MANUAL COMMUNIC, DOI [10.1037/t11527-000, DOI 10.1037/T11527-000]
   Young GS, 2009, DEVELOPMENTAL SCI, V12, P798, DOI 10.1111/j.1467-7687.2009.00833.x
NR 49
TC 1
Z9 1
U1 0
U2 0
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 2397-5563
J9 J PORT LINGUIST
JI J. Port. Linguist.
PD APR 30
PY 2020
VL 19
AR 4
DI 10.5334/jpl.240
PG 13
WC Language & Linguistics
SC Linguistics
GA LO5CV
UT WOS:000533646500001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Liang, C
   Wenstrup, LH
   Samy, RN
   Xiang, J
   Zhang, FW
AF Liang, Chun
   Wenstrup, Lisa H.
   Samy, Ravi N.
   Xiang, Jing
   Zhang, Fawen
TI The Effect of Side of Implantation on the Cortical Processing of
   Frequency Changes in Adult Cochlear Implant Users
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE cochlear implant; frequency change detection; acoustic change complex;
   standardized low-resolution brain electromagnetic tomography (sLORETA);
   temporal lobe; frontal lobe
ID AUDITORY-EVOKED POTENTIALS; NEUROPATHY SPECTRUM DISORDER; SENSORINEURAL
   HEARING-LOSS; SPEECH-PERCEPTION; ELECTROMAGNETIC TOMOGRAPHY;
   HEMISPHERIC-ASYMMETRY; PITCH DISCRIMINATION; PREFRONTAL CORTEX; ACOUSTIC
   CHANGE; PERFORMANCE
AB Cochlear implants (CI) are widely used in children and adults to restore hearing function. However, CI outcomes are vary widely. The affected factors have not been well understood. It is well known that the right and left hemispheres play different roles in auditory perception in adult normal hearing listeners. It is unknown how the implantation side may affect the outcomes of CIs. In this study, the effect of the implantation side on how the brain processes frequency changes within a sound was examined in 12 right-handed adult CI users. The outcomes of CIs were assessed with behaviorally measured frequency change detection threshold (FCDT), which has been reported to significantly affect CI speech performance. The brain activation and regions were also examined using acoustic change complex (ACC, a type of cortical potential evoked by acoustic changes within a stimulus), on which the waveform analysis and the standardized low-resolution brain electromagnetic tomography (sLORETA) were performed. CI users showed activation in the temporal lobe and non-temporal areas, such as the frontal lobe. Right-ear CIs could more efficiently activate the contralateral hemisphere compared to left-ear CIs. For right-ear CIs, the increased activation in the contralateral temporal lobe together with the decreased activation in the contralateral frontal lobe was correlated with good performance of frequency change detection (lower FCDTs). Such a trend was not found in left-ear CIs. These results suggest that the implantation side may significantly affect neuroplasticity patterns in adults.
C1 [Liang, Chun; Zhang, Fawen] Univ Cincinnati, Dept Commun Sci & Disorders, Cincinnati, OH 45221 USA.
   [Liang, Chun] Southern Med Univ, Affiliated Shenzhen Matern & Child Healthcare Hos, Child Psychiat & Rehabil, Shenzhen, Peoples R China.
   [Wenstrup, Lisa H.; Samy, Ravi N.] Univ Cincinnati, Dept Otolaryngol Head & Neck Surg, Cincinnati, OH USA.
   [Xiang, Jing] Cincinnati Childrens Hosp Med Ctr, Dept Pediat, Cincinnati, OH 45229 USA.
RP Liang, C; Zhang, FW (corresponding author), Univ Cincinnati, Dept Commun Sci & Disorders, Cincinnati, OH 45221 USA.; Liang, C (corresponding author), Southern Med Univ, Affiliated Shenzhen Matern & Child Healthcare Hos, Child Psychiat & Rehabil, Shenzhen, Peoples R China.
EM Fawen.Zhang@uc.edu
FU University Research Council (URC) grant at the University of Cincinnati;
   Center for Clinical and Translational Science and Training (CCTST);
   National Institute of Health R15 grant [NIH 1 R15 DC016463-01]
FX This research was partially supported by the University Research Council
   (URC) grant at the University of Cincinnati, the Center for Clinical and
   Translational Science and Training (CCTST) grant, and the National
   Institute of Health R15 grant (NIH 1 R15 DC016463-01) to FZ. This
   project is also a part of the dissertation work of CL at the University
   of Cincinnati. The content is solely the responsibility of the authors
   and does not necessarily represent the official views of the National
   Institutes of Health and other funding agencies.
CR Abbas PJ, 2015, HEARING RES, V322, P67, DOI 10.1016/j.heares.2014.10.011
   Blamey P, 2013, AUDIOL NEURO-OTOL, V18, P36, DOI 10.1159/000343189
   Brown CJ, 2015, EAR HEARING, V36, P723, DOI 10.1097/AUD.0000000000000206
   Campbell J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00071
   Cannon RL, 2012, CLIN EEG NEUROSCI, V43, P257, DOI 10.1177/1550059412449780
   Debener S, 2008, PSYCHOPHYSIOLOGY, V45, P20, DOI 10.1111/j.1469-8986.2007.00610.x
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dimitrijevic A, 2008, CLIN NEUROPHYSIOL, V119, P2111, DOI 10.1016/j.clinph.2008.06.002
   Doeller CF, 2003, NEUROIMAGE, V20, P1270, DOI 10.1016/S1053-8119(03)00389-6
   Eugene AR, 2014, BRAIN-BROAD RES ARTI, V5, P26
   Finley CC, 2008, OTOL NEUROTOL, V29, P920, DOI 10.1097/MAO.0b013e318184f492
   Francart T, 2008, J NEUROSCI METH, V172, P283, DOI 10.1016/j.jneumeth.2008.04.020
   Friesen LM, 2006, EAR HEARING, V27, P678, DOI 10.1097/01.aud.0000240620.63453.c3
   Fulbright Angela N. C., 2017, Seminars in Hearing, V38, P298, DOI 10.1055/s-0037-1606325
   Gelfer MP, 2013, J VOICE, V27, P556, DOI 10.1016/j.jvoice.2012.11.008
   Gifford RH, 2014, INT J AUDIOL, V53, P159, DOI 10.3109/14992027.2013.851800
   Gilley PM, 2006, CLIN NEUROPHYSIOL, V117, P1772, DOI 10.1016/j.clinph.2006.04.018
   Giraud AL, 2001, BRAIN, V124, P1307, DOI 10.1093/brain/124.7.1307
   Goldsworthy RL, 2015, JARO-J ASSOC RES OTO, V16, P797, DOI 10.1007/s10162-015-0541-9
   Gordon KA, 2010, OTOL NEUROTOL, V31, P1293, DOI 10.1097/MAO.0b013e3181e8f965
   Grech R, 2008, J NEUROENG REHABIL, V5, DOI 10.1186/1743-0003-5-25
   Green KMJ, 2005, HEARING RES, V205, P184, DOI 10.1016/j.heares.2005.03.016
   He S, 2015, EAR HEARING, V36, P289, DOI 10.1097/AUD.0000000000000119
   He SM, 2012, INT J AUDIOL, V51, P771, DOI 10.3109/14992027.2012.699198
   Henkin Y, 2014, LARYNGOSCOPE, V124, P1937, DOI 10.1002/lary.24635
   HERZOG H, 1991, J COMPUT ASSIST TOMO, V15, P369, DOI 10.1097/00004728-199105000-00005
   Hine J, 2007, CLIN NEUROPHYSIOL, V118, P1274, DOI 10.1016/j.clinph.2007.03.012
   Holden LK, 2013, EAR HEARING, V34, P342, DOI 10.1097/AUD.0b013e3182741aa7
   Hoppe U, 2001, SCAND AUDIOL, V30, P119, DOI 10.1080/010503901300112239
   Hyde KL, 2008, NEUROPSYCHOLOGIA, V46, P632, DOI 10.1016/j.neuropsychologia.2007.09.004
   Itoh K, 2012, EUR J NEUROSCI, V36, P3580, DOI 10.1111/j.1460-9568.2012.08278.x
   Johnsrude IS, 2000, BRAIN, V123, P155, DOI 10.1093/brain/123.1.155
   Kenway B, 2015, OTOL NEUROTOL, V36, P1472, DOI 10.1097/MAO.0000000000000845
   Kim JR, 2015, J AUDIOL OTOL, V19, P120, DOI 10.7874/jao.2015.19.3.120
   Kraaijenga VJC, 2018, CLIN OTOLARYNGOL, V43, P440, DOI 10.1111/coa.12988
   Lazard DS, 2012, EUR ANN OTORHINOLARY, V129, P98, DOI 10.1016/j.anorl.2011.06.001
   Lazard DS, 2010, ACTA OTO-LARYNGOL, V130, P1267, DOI 10.3109/00016481003769972
   Lee J, 2010, AUDIOL NEURO-OTOL, V15, P323, DOI 10.1159/000289571
   Liang C, 2018, AUDIOL NEURO-OTOL, V23, P152, DOI 10.1159/000492170
   Liang C, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00464
   Liegeois-Chauvel C., 2001, COGNITIVE NEUROSCIEN, p[152, 117]
   Limb CJ, 2014, HEARING RES, V308, P13, DOI 10.1016/j.heares.2013.04.009
   Lister JJ, 2011, INT J AUDIOL, V50, P211, DOI 10.3109/14992027.2010.526967
   Maehara T, 1999, Radiat Med, V17, P145
   Molholm S, 2005, CEREB CORTEX, V15, P545, DOI 10.1093/cercor/bhh155
   Nash-Kille A, 2014, CLIN NEUROPHYSIOL, V125, P1459, DOI 10.1016/j.clinph.2013.11.017
   Okamoto H, 2009, CEREB CORTEX, V19, P2290, DOI 10.1093/cercor/bhn245
   Opitz B, 2002, NEUROIMAGE, V15, P167, DOI 10.1006/nimg.2001.0970
   Ostroff JM, 1998, EAR HEARING, V19, P290, DOI 10.1097/00003446-199808000-00004
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P5
   PFINGST BE, 1994, HEARING RES, V78, P197, DOI 10.1016/0378-5955(94)90026-4
   Pisoni DB, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00493
   Plummer C, 2010, CLIN NEUROPHYSIOL, V121, P1726, DOI 10.1016/j.clinph.2010.04.002
   Ponton CW, 1996, EAR HEARING, V17, P430, DOI 10.1097/00003446-199610000-00009
   Pratt H, 2009, CLIN NEUROPHYSIOL, V120, P360, DOI 10.1016/j.clinph.2008.10.158
   PROVINS KA, 1975, NEUROPSYCHOLOGIA, V13, P207, DOI 10.1016/0028-3932(75)90029-9
   ROBIN DA, 1990, BRAIN LANG, V39, P539, DOI 10.1016/0093-934X(90)90161-9
   Sandmann P, 2009, BRAIN, V132, P1967, DOI 10.1093/brain/awp034
   Schonwiesner M, 2005, EUR J NEUROSCI, V22, P1521, DOI 10.1111/j.1460-9568.2005.04315.x
   Schonwiesner M, 2007, J NEUROPHYSIOL, V97, P2075, DOI 10.1152/jn.01083.2006
   SIDTIS JJ, 1988, BRAIN LANG, V34, P235, DOI 10.1016/0093-934X(88)90135-6
   Song JJ, 2013, HEARING RES, V299, P1, DOI 10.1016/j.heares.2013.02.001
   Talja S, 2015, BRAIN TOPOGR, V28, P445, DOI 10.1007/s10548-013-0307-9
   Wagner M, 2004, BRAIN TOPOGR, V16, P277
   Won JH, 2014, J ACOUST SOC AM, V136, P2714, DOI 10.1121/1.4895702
   Wong DDE, 2009, IEEE T BIO-MED ENG, V56, P2851, DOI 10.1109/TBME.2009.2029239
   Worrell GA, 2000, BRAIN TOPOGR, V12, P273, DOI 10.1023/A:1023407521772
   ZATORRE RJ, 1988, J ACOUST SOC AM, V84, P566, DOI 10.1121/1.396834
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
   Zhang FW, 2019, HEARING RES, V379, P12, DOI 10.1016/j.heares.2019.04.007
   Zhang FW, 2011, BRAIN RES, V1400, P42, DOI 10.1016/j.brainres.2011.05.036
   Zhang FW, 2009, J AM ACAD AUDIOL, V20, P397, DOI 10.3766/jaaa.20.7.2
NR 73
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD APR 29
PY 2020
VL 14
AR 368
DI 10.3389/fnins.2020.00368
PG 12
WC Neurosciences
SC Neurosciences & Neurology
GA LR2PN
UT WOS:000535537800001
PM 32410947
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Pike, M
   Biagio-de Jager, L
   le Roux, T
   Hofmeyr, LM
AF Pike, Meghan
   Biagio-de Jager, Leigh
   le Roux, Talita
   Hofmeyr, Louis M.
TI Short-Term Test-Retest Reliability of Electrically Evoked Cortical
   Auditory Potentials in Adult Cochlear Implant Recipients
SO FRONTIERS IN NEUROLOGY
LA English
DT Article
DE cochlear implant; test-retest reliability; cortical auditory evoked
   potentials; late latency auditory evoked potentials; electrical evoked
   responses; aided
ID INTRACLASS CORRELATION-COEFFICIENTS; SPEECH-PERCEPTION; REPLICABILITY;
   THRESHOLD; ATTENTION; RESPONSES; CHILDREN; AUDITION; P300; DEAF
AB Background: Late latency auditory evoked potentials (LLAEPs) provide objective evidence of an individual's central auditory processing abilities. Electrically evoked cortical auditory evoked potentials (eCAEPs) are a type of LLAEP that provides an objective measure of aided speech perception and auditory processing abilities in cochlear implant (CI) recipients.
   Aim: To determine the short-term test-retest reliability of eCAEPs in adult CI recipients.
   Design: An explorative, within-subject repeated measures research design was employed.
   Study Sample: The study sample included 12 post-lingually deafened, unilaterally implanted adult CI recipients with at least 9 months of CI experience.
   Method: eCAEPs representing basal, medial and apical cochlear regions were recorded in the implanted ears of each participant. Measurements were repeated 7 days after the initial assessment.
   Results: No significant differences between either median latencies or amplitudes at test and retest sessions (p > 0.05) were found when results for apical, medial and basal electrodes were averaged together. Mean intraclass correlation coefficient (ICC) scores averaged across basal, medial and apical cochlear stimulus regions indicated that both consistency and agreement were statistically significant and ranged from moderate to good (ICC = 0.58-0.86, p < 0.05). ICC confidence intervals did demonstrate considerable individual variability in both latency and amplitudes.
   Conclusion: eCAEP latencies and amplitudes demonstrated moderate to good short-term test-retest reliability. However, confidence intervals indicated individual variability in measurement consistency which is likely linked to attention and listening effort required from the CI recipients.
C1 [Pike, Meghan; Biagio-de Jager, Leigh; le Roux, Talita; Hofmeyr, Louis M.] Univ Pretoria, Dept Speech Language Pathol & Audiol, Pretoria, South Africa.
RP Hofmeyr, LM (corresponding author), Univ Pretoria, Dept Speech Language Pathol & Audiol, Pretoria, South Africa.
EM louishofmeyr@icloud.com
RI de Jager, Leigh Biagio/ABC-8240-2020
OI de Jager, Leigh Biagio/0000-0002-5095-8626; le Roux,
   Talita/0000-0002-7900-9600
CR Angel R, 2016, THESIS
   Arfin WN, 2017, SAMPLE SIZE CALCULAT
   Billings Curtis J., 2013, Seminars in Hearing, V34, P257, DOI 10.1055/s-0033-1356638
   British Society of Audiology, 2016, BSA CORT ERA GUID CO
   Brown CJ, 2008, EAR HEARING, V29, P704, DOI 10.1097/AUD.0b013e31817a98af
   Crowley KE, 2004, CLIN NEUROPHYSIOL, V115, P732, DOI 10.1016/j.clinph.2003.11.021
   Czarniak LJ, 2011, INDEPENDENT STUDIES
   Damen GWJA, 2006, ANN OTO RHINOL LARYN, V115, P542, DOI 10.1177/000348940611500709
   Eggermont JJ, 1997, ACTA OTO-LARYNGOL, V117, P161, DOI 10.3109/00016489709117760
   Firszt Jill B., 2002, Ear and Hearing, V23, P502, DOI 10.1097/00003446-200212000-00002
   Fritz JB, 2007, CURR OPIN NEUROBIOL, V17, P437, DOI 10.1016/j.conb.2007.07.011
   Gilley PM, 2006, CLIN NEUROPHYSIOL, V117, P1772, DOI 10.1016/j.clinph.2006.04.018
   Glista Danielle, 2012, Int J Otolaryngol, V2012, P982894, DOI 10.1155/2012/982894
   Groenen PAP, 1996, ACTA OTO-LARYNGOL, V116, P785, DOI 10.3109/00016489609137926
   Hall J., 2015, EHANDBOOK AUDITORY E
   Hyde M, 1997, AUDIOL NEURO-OTOL, V2, P281, DOI 10.1159/000259253
   Interacoustics, 2018, ECL ADD INF
   Katz J, 2015, HDB CLIN AUDIOLOGY
   Katz J, 2009, HDB CLIN AUDIOLOGY
   Kelly AS, 2005, CLIN NEUROPHYSIOL, V116, P1235, DOI 10.1016/j.clinph.2005.02.011
   Kileny PR, 1997, OTOLARYNG HEAD NECK, V117, P161, DOI 10.1016/S0194-5998(97)70169-4
   Kilney P, 1987, EAR HEARING, V8, P63, DOI [10.1097/00003446-198704000-00008, DOI 10.1097/00003446-198704000-00008]
   Kim JR, 2009, EAR HEARING, V30, P320, DOI 10.1097/AUD.0b013e31819c42b7
   Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012
   KRAUS N, 1993, HEARING RES, V65, P118, DOI 10.1016/0378-5955(93)90206-G
   Laerd Statistics, 2015, STAT TUT SOFTW GUID
   Lightfoot G, 2006, EAR HEARING, V27, P443, DOI 10.1097/01.aud.0000233902.53432.48
   Lightfoot Guy, 2016, Seminars in Hearing, V37, P1, DOI 10.1055/s-0035-1570334
   Martin BA, 2008, EAR HEARING, V29, P285, DOI 10.1097/AUD.0b013e3181662c0e
   McClaskey CM, 2018, J SPEECH LANG HEAR R, V61, P2422, DOI 10.1044/2018_JSLHR-H-18-0097
   MICCO AG, 1995, AM J OTOL, V16, P514
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Noble W, 2008, INT J AUDIOL, V47, P505, DOI 10.1080/14992020802070770
   PEKKONEN E, 1995, EVOKED POTENTIAL, V96, P546, DOI 10.1016/0013-4694(95)00148-R
   Perez AP, 2017, INT ARCH OTORHINOLAR, V21, P134, DOI 10.1055/s-0036-1583527
   Picton TW, 2000, PSYCHOPHYSIOLOGY, V37, P127, DOI 10.1111/1469-8986.3720127
   Qin SS, 2019, QUAL LIFE RES, V28, P1029, DOI 10.1007/s11136-018-2076-0
   QUITTNER AL, 1994, PSYCHOL SCI, V5, P347, DOI 10.1111/j.1467-9280.1994.tb00284.x
   RAPIN I, 1967, NEUROLOGY, V17, P881, DOI 10.1212/WNL.17.9.881
   Sharma A, 2002, NEUROREPORT, V13, P1365, DOI 10.1097/00001756-200207190-00030
   Smith LB, 1998, DEV PSYCHOL, V34, P840, DOI 10.1037/0012-1649.34.5.840
   Swanepoel Felicity, 2019, Journal of Environmental Assessment Policy and Management, V21, P1950009, DOI 10.1142/S1464333219500091
   Tremblay KL, 2003, EAR HEARING, V24, P225, DOI 10.1097/01.AUD.0000069229.84883.03
   Virtanen J, 1998, EVOKED POTENTIAL, V108, P291, DOI 10.1016/S0168-5597(98)00006-9
   Walter SD, 1998, STAT MED, V17, P101, DOI 10.1002/(SICI)1097-0258(19980115)17:1<101::AID-SIM727>3.0.CO;2-E
NR 45
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-2295
J9 FRONT NEUROL
JI Front. Neurol.
PD APR 28
PY 2020
VL 11
AR 305
DI 10.3389/fneur.2020.00305
PG 8
WC Clinical Neurology; Neurosciences
SC Neurosciences & Neurology
GA LO1TF
UT WOS:000533409700001
PM 32411080
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Kan, RTY
AF Kan, Rachel T. Y.
TI Phonological Production in Young Speakers of Cantonese as a Heritage
   Language
SO LANGUAGE AND SPEECH
LA English
DT Article; Early Access
DE heritage speakers; accent ratings; Cantonese; phonological production
ID FOREIGN ACCENT; SPEECH-PERCEPTION; PRONUNCIATION; ENGLISH; ACQUISITION;
   ATTRITION; COMPREHENSIBILITY; INTELLIGIBILITY; BILINGUALS; AGE
AB This study investigates the phonological production of 50 heritage speakers of Cantonese aged 5-11 in the USA. They were compared to 12 majority language speaker peers in Hong Kong via ratings from first language adult speakers. Overall, the heritage speakers were rated as less native-like and less comprehensible than the children in Hong Kong, although they received higher scores from raters speaking the same variety of Cantonese (i.e., Guangzhou Cantonese, vs. Hong Kong Cantonese). None of the tested language background factors, including age of testing, had a predictive effect on the heritage speakers' scores. The results illustrate the divergence and heterogeneity of heritage phonology compared to homeland varieties.
C1 [Kan, Rachel T. Y.] Univ Essex, Colchester, Essex, England.
RP Kan, RTY (corresponding author), Hong Kong Polytech Univ, Hung Hom, Kowloon, Hong Kong, Peoples R China.
EM rachel.kan@polyu.edu.hk
OI Kan, Rachel/0000-0003-3893-4549
FU Funds for Women Graduates; ESSEXLab
FX The author disclosed receipt of the following financial support for the
   research, authorship, and/or publication of this article: This work was
   supported by Funds for Women Graduates and ESSEXLab.
CR Abercrombie David, 1967, ELEMENTS GEN PHONETI
   Ahn S, 2017, LANG LEARN, V67, P694, DOI 10.1111/lang.12252
   Au T. K., 2002, PSYCHOL SCI, V13, P379
   Au TKF, 2008, J MEM LANG, V58, P998, DOI 10.1016/j.jml.2007.11.001
   BARRIE MIKE, 2003, TORONTO WORKING PAPE, V20, P1
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bauer R., 1997, MODERN CANTONESE PHO
   Cantonese Pronunciation Electronic Dictionary Team (Research Institute for the Humanities Chinese University of Hong Kong, 1999, CHIN TALK SYLL CANT
   Chambers J. K., 2002, J SOCIOLING, P117, DOI [10.1111/1467-9481.00180, DOI 10.1111/1467-9481.00180]
   Chan Alice Y. W., 2000, LANG CULT CURRIC, V13, P67, DOI DOI 10.1080/07908310008666590
   Chang Charles, 2016, HERITAGE LANGUAGE J, V13, P134
   Chang CB, 2012, J PHONETICS, V40, P249, DOI 10.1016/j.wocn.2011.10.007
   Chang CB, 2011, J ACOUST SOC AM, V129, P3964, DOI 10.1121/1.3569736
   Cheung Winnie H. Y., 2009, P 35 ANN M BERK LING, V35, P72, DOI [10.3765/bls.v35i1.3599, DOI 10.3765/BLS.V35I1.3599]
   Chow S., 2002, THESIS
   De Leeuw E, 2010, BILING-LANG COGN, V13, P33, DOI 10.1017/S1366728909990289
   Derwing TM, 2009, LANG TEACHING, V42, P476, DOI 10.1017/S026144480800551X
   Deterding D., 2008, ENGL WORLD-WIDE, V29, P148, DOI DOI 10.1075/EWW.29.2.03DET
   Ding P. S., 2010, MARGINAL DIALECTS SC, P198
   Duanmu S., 2011, BLACKWELL COMPANION, V5, P2151
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   FLEGE JE, 1992, J ACOUST SOC AM, V91, P370, DOI 10.1121/1.402780
   Flege JE, 1999, SEC LANG ACQ RES, P101
   Flores C., 2016, HERITAGE LANGUAGE J, V13, P161, DOI DOI 10.1177/
   Fry D. B., 1968, MANUAL OF PHONETICS
   Godson L., 2004, HERITAGE LANGUAGE J, V2, P1
   Harding L., 2013, ENCY APPL LINGUISTIC
   HASHIMOTO A, 1972, PHONOLOGY CANTONESE
   Hopp H, 2013, APPL PSYCHOLINGUIST, V34, P361, DOI 10.1017/S0142716411000737
   Hung T. T. N., 2003, WORLD ENGLISH, V19, P337
   Isaacs T, 2012, STUD SECOND LANG ACQ, V34, P475, DOI 10.1017/S0272263112000150
   Jenkins J, 2002, APPL LINGUIST, V23, P83, DOI 10.1093/applin/23.1.83
   Jenkins J., 2000, PHONOLOGY ENGLISH IN
   Jusczyk PW, 1999, COGNITIVE PSYCHOL, V39, P159, DOI 10.1006/cogp.1999.0716
   Kan RTY, 2019, J PHONETICS, V73, P40, DOI 10.1016/j.wocn.2018.12.004
   Kao D, 1971, STRUCTURE SYLLABLE C
   Khattab G, 2013, LINGUISTICS, V51, P439, DOI 10.1515/ling-2013-0017
   Khattab G, 2009, CAMB HB LANG LINGUIS, P142
   Knightly LM, 2003, J ACOUST SOC AM, V114, P465, DOI 10.1121/1.1577560
   KUHL PK, 1985, NEONATE COGNITION BL, P231
   Kupisch T., 2014, HERITAGE LANGUAGE J, V11, P123
   Kupisch T, 2014, J FR LANG STUD, V24, P347, DOI 10.1017/S0959269513000197
   Kupisch T, 2013, LINGUIST APPROACH BI, V3, P150, DOI 10.1075/lab.3.2.02kup
   Law C., 2006, THESIS
   Lefcheck JS, 2016, METHODS ECOL EVOL, V7, P573, DOI 10.1111/2041-210X.12512
   Leung M. H. B., PRODUCTION LOW LEVEL
   Lippi-Green R., 1997, ENGLISH ACCENT LANGU, V2nd ed.
   Liu S., 2000, BILING-LANG COGN, V3, P131, DOI DOI 10.1017/S1366728900000225
   Major RC, 2007, STUD SECOND LANG ACQ, V29, P539, DOI 10.1017/S0272263107070428
   Major RC, 2010, INT J BILINGUAL, V14, P163, DOI 10.1177/1367006910363063
   Matthews S., 2001, CANTONESE COMPREHENS
   Mayer M., 1969, FROG ARE YOU
   Mok P. K. P., 2010, SPEECH PROSODY, P1
   Montrul S., 2013, HERITAGE LANGUAGE J, V10, P153
   Munro MJ, 1999, LANG LEARN, V49, P285, DOI 10.1111/0023-8333.49.s1.8
   Munro MJ, 2011, LANG TEACHING, V44, P316, DOI 10.1017/S0261444811000103
   Oh JS, 2003, COGNITION, V86, pB53, DOI 10.1016/S0010-0277(02)00175-0
   Ou J., 2012, THESIS
   R Core Team, 2016, R LANG ENV STAT COMP
   Rao R., 2015, HERITAGE LANGUAGE J, V12, P48, DOI DOI 10.1093/APPLIN/AMR040
   Ronquest R., 2013, SEL P 15 HISP LING S, P157
   Saadah E., 2011, THESIS
   Sancier ML, 1997, J PHONETICS, V25, P421, DOI 10.1006/jpho.1997.0051
   Schmid MS, 2014, LANG TEST, V31, P367, DOI 10.1177/0265532214526175
   Smith L. E., 1985, WORLD ENGLISH, V4, P333, DOI DOI 10.1111/J.1467-971X.1985.TB00423.X
   Smith U., 2000, IRAL-INT REV APPL LI, V38, P229
   So K. L. C., 2000, THESIS
   Sorace A., 2004, BILING-LANG COGN, V7, P143, DOI [10.1017/S1366728904001543, DOI 10.1017/S1366728904001543]
   Stangen I., 2015, TRANSFER EFFECTS MUL, P87
   Stoehr A., 2017, BILINGUALISM LANGUAG
   Taylor L, 2011, J ENGL ACAD PURP, V10, P89, DOI 10.1016/j.jeap.2011.03.002
   THOMPSON I, 1991, LANG LEARN, V41, P177, DOI 10.1111/j.1467-1770.1991.tb00683.x
   Tse H., 2016, ASIA PACIFIC LANGUAG, V2, P124, DOI [10.1075/aplv.2.2.02tse, DOI 10.1075/APLV.2.2.02TSE]
   U.S. Census Bureau, 2015, AM COMM SURV ACS DET
   Unsworth S, 2013, BILING-LANG COGN, V16, P86, DOI 10.1017/S1366728912000284
   Valde's G., 2001, HERITAGE LANGUAGES A, P37
   Wee LH, 2008, WORLD ENGLISH, V27, P480, DOI 10.1111/j.1467-971X.2008.00580.x
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wu W., 2006, THESIS
NR 79
TC 0
Z9 0
U1 1
U2 1
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
AR 0023830920910460
DI 10.1177/0023830920910460
EA APR 2020
PG 25
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA LN4SZ
UT WOS:000532930500001
PM 32339077
DA 2021-02-24
ER

PT J
AU Zhou, HL
   Wang, NY
   Zheng, NH
   Yu, GZ
   Meng, QL
AF Zhou, Huali
   Wang, Ningyuan
   Zheng, Nengheng
   Yu, Guangzheng
   Meng, Qinglin
TI A New Approach for Noise Suppression in Cochlear Implants: A
   Single-Channel Noise Reduction Algorithm(1)
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE cochlear implant; noise reduction; cocktail party problem; monaural;
   speech in noise; intelligibility; Nurotron; eVoice
ID SPEECH ENHANCEMENT; RECOGNITION; PERCEPTION; IMPROVE
AB The cochlea "translates" the in-air vibrational acoustic "language" into the spikes of neural "language" that are then transmitted to the brain for auditory understanding and/or perception. During this intracochlear "translation" process, high resolution in time-frequency-intensity domains guarantees the high quality of the input neural information for the brain, which is vital for our outstanding hearing abilities. However, cochlear implants (CIs) have coarse artificial coding and interfaces, and CI users experience more challenges in common acoustic environments than their normal-hearing (NH) peers. Noise from sound sources that a listener has no interest in may be neglected by NH listeners, but they may distract a CI user. We discuss the CI noise-suppression techniques and introduce noise management for a new implant system. The monaural signal-to-noise ratio estimation-based noise suppression algorithm "eVoice," which is incorporated in the processors of Nurotron(R) Enduro(TM), was evaluated in two speech perception experiments. The results show that speech intelligibility in stationary speech-shaped noise can be significantly improved with eVoice. Similar results have been observed in other CI devices with single-channel noise reduction techniques. Specifically, the mean speech reception threshold decrease in the present study was 2.2 dB. The Nurotron society already has more than 10,000 users, and eVoice is a start for noise management in the new system. Future steps on non-stationary-noise suppression, spatial-source separation, bilateral hearing, microphone configuration, and environment specification are warranted. The existing evidence, including our research, suggests that noise-suppression techniques should be applied in CI systems. The artificial hearing of CI listeners requires more advanced signal processing techniques to reduce brain effort and increase intelligibility in noisy settings.
C1 [Zhou, Huali; Yu, Guangzheng; Meng, Qinglin] South China Univ Technol, Sch Phys & Optoelect, Acoust Lab, Guangzhou, Peoples R China.
   [Wang, Ningyuan] Nurotron Biotechnol Inc, Hangzhou, Peoples R China.
   [Zheng, Nengheng] Shenzhen Univ, Coll Elect & Informat Engn, Guangdong Key Lab Intelligent Informat Proc, Shenzhen, Peoples R China.
RP Yu, GZ; Meng, QL (corresponding author), South China Univ Technol, Sch Phys & Optoelect, Acoust Lab, Guangzhou, Peoples R China.
EM scgzyu@scut.edu.cn; mengqinglin@scut.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [11704129, 11574090, 61771320]; Natural
   Science Foundation of Guangdong, ChinaNational Natural Science
   Foundation of Guangdong Province [2020A1515010386, 2018B030311025];
   Shenzhen Science and Innovation Funds [JCYJ 20170302145906843]
FX This work was supported by the National Natural Science Foundation of
   China (11704129, 11574090, and 61771320), Natural Science Foundation of
   Guangdong, China (2020A1515010386 and 2018B030311025), and Shenzhen
   Science and Innovation Funds (JCYJ 20170302145906843).
CR Berenstein CK, 2008, EAR HEARING, V29, P250, DOI 10.1097/AUD.0b013e3181645336
   Bianco MJ, 2019, J ACOUST SOC AM, V146, P3590, DOI 10.1121/1.5133944
   Bonham BH, 2008, HEARING RES, V242, P141, DOI 10.1016/j.heares.2008.03.006
   Buechner A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095542
   Buechner A, 2010, OTOL NEUROTOL, V31, P1386, DOI 10.1097/MAO.0b013e3181f1cdc6
   Chen F, 2015, EAR HEARING, V36, P61, DOI 10.1097/AUD.0000000000000074
   Chung K, 2004, ACOUST RES LETT ONL, V5, P56, DOI 10.1121/1.1666869
   Dawson PW, 2011, EAR HEARING, V32, P382, DOI 10.1097/AUD.0b013e318201c200
   Dhanasingh A, 2017, HEARING RES, V356, P93, DOI 10.1016/j.heares.2017.10.005
   Emily Fu Foundation, 2019, MSP
   Fu QJ, 2011, J ACOUST SOC AM, V129, pEL267, DOI 10.1121/1.3590739
   Gao N, 2016, ACTA OTO-LARYNGOL, V136, P68, DOI 10.3109/00016489.2015.1086022
   Goehring T, 2019, J ACOUST SOC AM, V146, P705, DOI 10.1121/1.5119226
   Gong SY, 2019, IEEE WORK APPL SIG, P254, DOI 10.1109/WASPAA.2019.8937212
   Hagen Rudolf, 2020, Cochlear Implants Int, V21, P53, DOI 10.1080/14670100.2019.1664529
   Hersbach AA, 2012, EAR HEARING, V33, pE13, DOI 10.1097/AUD.0b013e31824b9e21
   Holden Laura K, 2013, Cochlear Implants Int, V14, P276, DOI 10.1179/1754762813Y.0000000034
   Hu Y, 2007, J ACOUST SOC AM, V122, pEL128, DOI 10.1121/1.2772401
   Jeschke M, 2015, HEARING RES, V322, P224, DOI 10.1016/j.heares.2015.01.005
   Kam ACS, 2012, CLIN EXP OTORHINOLAR, V5, pS89, DOI 10.3342/ceo.2012.5.S1.S89
   Kasturi K, 2007, EAR HEARING, V28, P402, DOI 10.1097/AUD.0b013e31804793c4
   Kral A, 2019, ANNU REV NEUROSCI, V42, P47, DOI 10.1146/annurev-neuro-080317-061513
   Lai YH, 2018, EAR HEARING, V39, P795, DOI 10.1097/AUD.0000000000000537
   Li X, 2012, J ACOUST SOC AM, V132, P3387, DOI 10.1121/1.4756827
   Loizou P., 2007, SPEECH ENHANCEMENT T
   Loizou PC, 1999, IEEE ENG MED BIOL, V18, P34, DOI 10.1109/51.765187
   Loizou Philipos C, 2006, Adv Otorhinolaryngol, V64, P109, DOI 10.1159/000094648
   Martin R, 2001, IEEE T SPEECH AUDI P, V9, P504, DOI 10.1109/89.928915
   Mauger SJ, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/6/065007
   Mauger SJ, 2012, J ACOUST SOC AM, V131, P327, DOI 10.1121/1.3665990
   Mc Laughlin M, 2012, IEEE T NEUR SYS REH, V20, P443, DOI 10.1109/TNSRE.2012.2186982
   MCAULAY RJ, 1980, IEEE T ACOUST SPEECH, V28, P137, DOI 10.1109/TASSP.1980.1163394
   Meng QL, 2019, HEARING RES, V374, P58, DOI 10.1016/j.heares.2019.01.011
   Meng QL, 2016, J ACOUST SOC AM, V139, P301, DOI 10.1121/1.4939707
   Middlebrooks JC, 2007, JARO-J ASSOC RES OTO, V8, P258, DOI 10.1007/s10162-007-0070-2
   Moberly AC, 2019, J SPEECH LANG HEAR R, V62, P2895, DOI 10.1044/2019_JSLHR-H-18-0472
   Moore B. C. J., 2007, COCHLEAR HEARING LOS
   Nie KB, 2005, IEEE T BIO-MED ENG, V52, P64, DOI 10.1109/TBME.2004.839799
   Nogueira W, 2019, IEEE SIGNAL PROC MAG, V36, P115, DOI 10.1109/MSP.2018.2874059
   Ping Lichuan, 2017, Cochlear Implants Int, V18, P240, DOI 10.1080/14670100.2017.1339492
   Rangachari S, 2006, SPEECH COMMUN, V48, P220, DOI 10.1016/j.specom.2005.08.005
   Rebscher S, 2018, J INT ADV OTOL, V14, P392, DOI 10.5152/iao.2018.6285
   Ren CC, 2018, INT J PEDIATR OTORHI, V113, P124, DOI 10.1016/j.ijporl.2018.07.039
   Rubinstein Jay T, 2004, Curr Opin Otolaryngol Head Neck Surg, V12, P444, DOI 10.1097/01.moo.0000134452.24819.c0
   Shannon RV, 2014, SPRINGER HANDB AUDIT, V50, P533, DOI 10.1007/978-1-4614-9102-6_28
   Tamati T. N., 2019, J AM ACAD AUDIOL, DOI [10.3766/jaaa18106, DOI 10.3766/JAAA18106]
   Van Hoesel R., 2007, J ACOUST SOC AM, V123, DOI [10.1121/1.2942439, DOI 10.1121/1.2942439]
   Wang DM, 2018, J ACOUST SOC AM, V143, P2244, DOI 10.1121/1.5031112
   Wang N., 2017, 2017 C IMPL AUD PROS
   WILSON BS, 1991, NATURE, V352, P236, DOI 10.1038/352236a0
   Wong LLN, 2007, EAR HEARING, V28, p70S, DOI 10.1097/AUD.0b013e31803154d0
   Wouters J, 2015, IEEE SIGNAL PROC MAG, V32, P67, DOI 10.1109/MSP.2014.2371671
   Xi X, 2012, INT J AUDIOL, V51, P399, DOI 10.3109/14992027.2011.642011
   Xu YC, 2019, IEEE T BIO-MED ENG, V66, P573, DOI 10.1109/TBME.2018.2850753
   Yang LP, 2005, J ACOUST SOC AM, V117, P1001, DOI 10.1121/1.1852873
   Zeng Fan-Gang, 2004, Trends Amplif, V8, P1, DOI 10.1177/108471380400800102
   Zeng FG, 2015, HEARING RES, V322, P188, DOI 10.1016/j.heares.2014.09.013
   Zeng Fan-Gang, 2008, IEEE Rev Biomed Eng, V1, P115, DOI 10.1109/RBME.2008.2008250
   Zierhofer C. M., 2003, Patent, Patent No. [EP1207938B1, 1207938]
NR 59
TC 0
Z9 0
U1 3
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD APR 21
PY 2020
VL 14
AR 301
DI 10.3389/fnins.2020.00301
PG 12
WC Neurosciences
SC Neurosciences & Neurology
GA LL6BN
UT WOS:000531642900001
PM 32372902
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Ullas, S
   Formisano, E
   Eisner, F
   Cutler, A
AF Ullas, Shruti
   Formisano, Elia
   Eisner, Frank
   Cutler, Anne
TI Audiovisual and lexical cues do not additively enhance perceptual
   adaptation
SO PSYCHONOMIC BULLETIN & REVIEW
LA English
DT Article
DE Recalibration; Perceptual retuning; Lipreading; Lexical; Audiovisual
ID SELECTIVE ADAPTATION; SPEECH-PERCEPTION; PHONETIC CATEGORIZATION; VISUAL
   RECALIBRATION; AUDITORY SPEECH; INFORMATION
AB When listeners experience difficulty in understanding a speaker, lexical and audiovisual (or lipreading) information can be a helpful source of guidance. These two types of information embedded in speech can also guide perceptual adjustment, also known as recalibration or perceptual retuning. With retuning or recalibration, listeners can use these contextual cues to temporarily or permanently reconfigure internal representations of phoneme categories to adjust to and understand novel interlocutors more easily. These two types of perceptual learning, previously investigated in large part separately, are highly similar in allowing listeners to use speech-external information to make phoneme boundary adjustments. This study explored whether the two sources may work in conjunction to induce adaptation, thus emulating real life, in which listeners are indeed likely to encounter both types of cue together. Listeners who received combined audiovisual and lexical cues showed perceptual learning effects similar to listeners who only received audiovisual cues, while listeners who received only lexical cues showed weaker effects compared with the two other groups. The combination of cues did not lead to additive retuning or recalibration effects, suggesting that lexical and audiovisual cues operate differently with regard to how listeners use them for reshaping perceptual categories. Reaction times did not significantly differ across the three conditions, so none of the forms of adjustment were either aided or hindered by processing time differences. Mechanisms underlying these forms of perceptual learning may diverge in numerous ways despite similarities in experimental applications.
C1 [Ullas, Shruti; Formisano, Elia] Maastricht Univ, Fac Psychol & Neurosci, Dept Cognit Neurosci, NL-6200 MD Maastricht, Netherlands.
   [Eisner, Frank] Radboud Univ Nijmegen, Donders Ctr Cognit, NL-6500 AH Nijmegen, Netherlands.
   [Cutler, Anne] Western Sydney Univ, MARCS Inst, Penrith, NSW 2751, Australia.
   [Cutler, Anne] Western Sydney Univ, ARC Ctr Excellence Dynam Language, Penrith, NSW 2751, Australia.
RP Ullas, S (corresponding author), Maastricht Univ, Fac Psychol & Neurosci, Dept Cognit Neurosci, NL-6200 MD Maastricht, Netherlands.
EM shruti.ullas@maastrichtuniversity.nl
OI Ullas, Shruti/0000-0002-0056-651X; Formisano, Elia/0000-0001-5008-2460
FU Language in Interaction, within the Netherlands Organization for
   Scientific Research (NWO) Gravitation programNetherlands Organization
   for Scientific Research (NWO)
FX This project was funded by Language in Interaction, within the
   Netherlands Organization for Scientific Research (NWO) Gravitation
   program.
CR Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Brancazio L, 2004, J EXP PSYCHOL HUMAN, V30, P445, DOI 10.1037/0096-1523.30.3.445
   Brancazio L, 2003, PERCEPT PSYCHOPHYS, V65, P591, DOI 10.3758/BF03194585
   Bruggeman L, 2020, BILING-LANG COGN, V23, P681, DOI 10.1017/S1366728919000646
   Cutler A., 2010, LAB PHONOLOGY, V10, P91
   Duyck W, 2004, BEHAV RES METH INS C, V36, P488, DOI 10.3758/BF03195595
   Eisner F, 2006, J ACOUST SOC AM, V119, P1950, DOI 10.1121/1.2178721
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   GREEN KP, 1989, PERCEPT PSYCHOPHYS, V45, P34, DOI 10.3758/BF03208030
   Jesse A., 2000, INTERPRETING, V5, P95, DOI [DOI 10.1075/INTP.5.2.04JES, 10.1075/intp.5.2.04jes]
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Kraljic T, 2009, ATTEN PERCEPT PSYCHO, V71, P481, DOI [10.3758/APP, DOI 10.3758/APP]
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Luttke CS, 2018, ROY SOC OPEN SCI, V5, DOI 10.1098/rsos.170909
   MACLEOD A, 1987, British Journal of Audiology, V21, P131, DOI 10.3109/03005368709077786
   Massaro D. W., 2007, OXFORD HDB PSYCHOLIN, P19, DOI [10.1093/oxfordhb/9780198568971.013.0002, DOI 10.1093/0XF0RDHB/9780198568971.013.0002]
   MASSARO DW, 1993, SPEECH COMMUN, V13, P127, DOI 10.1016/0167-6393(93)90064-R
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MCQUEEN JM, 1991, J EXP PSYCHOL HUMAN, V17, P433, DOI 10.1037/0096-1523.17.2.433
   Mitterer H, 2017, ATTEN PERCEPT PSYCHO, V79, P660, DOI 10.3758/s13414-016-1249-6
   Mitterer H, 2013, COGNITION, V129, P356, DOI 10.1016/j.cognition.2013.07.011
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Ostrand R, 2016, COGNITION, V151, P96, DOI 10.1016/j.cognition.2016.02.019
   Reinisch E, 2014, J EXP PSYCHOL HUMAN, V40, P539, DOI 10.1037/a0034409
   ROBERTS M, 1981, PERCEPT PSYCHOPHYS, V30, P309, DOI 10.3758/BF03206144
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   Rosenblum LD, 2010, SEE WHAT SAYING EXTR
   SALDANA HM, 1994, J ACOUST SOC AM, V95, P3658, DOI 10.1121/1.409935
   Samuel AG, 2014, J EXP PSYCHOL HUMAN, V40, P1479, DOI 10.1037/a0036656
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   van der Zande P, 2013, J ACOUST SOC AM, V134, P562, DOI 10.1121/1.4807814
   van Linden S, 2007, J EXP PSYCHOL HUMAN, V33, P1483, DOI 10.1037/0096-1523.33.6.1483
   Vroomen J, 2004, SPEECH COMMUN, V44, P55, DOI 10.1016/j.specom.2004.03.009
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
   Weber A, 2012, WIRES COGN SCI, V3, P387, DOI 10.1002/wcs.1178
NR 37
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1069-9384
EI 1531-5320
J9 PSYCHON B REV
JI Psychon. Bull. Rev.
PD AUG
PY 2020
VL 27
IS 4
BP 707
EP 715
DI 10.3758/s13423-020-01728-5
EA APR 2020
PG 9
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA MU9JE
UT WOS:000528157600002
PM 32319002
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Pieniak, M
   Lachowicz-Tabaczek, K
   Masalski, M
   Hummel, T
   Oleszkiewicz, A
AF Pieniak, Michal
   Lachowicz-Tabaczek, Kinga
   Masalski, Marcin
   Hummel, Thomas
   Oleszkiewicz, Anna
TI Self-rated sensory performance in profoundly deaf individuals. Do deaf
   people share the conviction about sensory compensation?
SO JOURNAL OF SENSORY STUDIES
LA English
DT Article
ID HEARING SIGNERS; CONGENITALLY DEAF; ATTENTION; SMELL; DISCRIMINATION;
   PERSONALITY; ASSESSMENTS; OBJECTS; VISION; MEMORY
AB Sensory deficits in one modality lead to functional changes of brain structures. Neural reorganization may result in sensory compensation and enhanced performance in sensory sensitivity tests. Many studies investigated how deafness affects functioning of the intact senses. Overall, their results remain inconclusive, mainly due to the statistically underpowered conclusions. A limited number of studies have focused on deaf people's convictions on their sensory abilities. This study compared a large sample of profoundly deaf subjects (n = 74) with hearing individuals (n = 100) in terms of their convictions about own sensory performance. First, participants were screened with speech perception tests. Then, they were asked to rate their own sensory sensitivity using two reference categories: (1) other people and (2) their usual sensitivity. Results show that majority of deaf individuals rated their intact senses (i.e., vision, smell, taste, and touch) as more sensitive than hearing controls. Furthermore, on the day of testing deaf individuals reported increased performance of the intact senses as referred to the usual performance. Explanations of the positive self-evaluations of sensory abilities focus on the common belief among deaf people about sensory compensation and on using self-enhancement strategies.
   Practical applications Reported study introduces important knowledge about positive self-views on sensory sensitivity of deaf individuals. Although these positive self-views are unlikely to reflect the actual sensory performance, presented results are of high significance for the sensory scientists. Functional aspects of self-views in domain of sensory sensitivity should guide educational programs and product design targeted to deaf individuals.
C1 [Pieniak, Michal; Lachowicz-Tabaczek, Kinga; Oleszkiewicz, Anna] Univ Wroclaw, Inst Psychol, Ul Dawida 1, PL-50527 Wroclaw, Poland.
   [Hummel, Thomas; Oleszkiewicz, Anna] Tech Univ Dresden, Dept Otorhinolaryngol, Taste & Smell Clin, Dresden, Germany.
   [Masalski, Marcin] Wroclaw Med Univ, Dept & Clin Otolaryngol Head & Neck Surg, Wroclaw, Poland.
   [Masalski, Marcin] Wroclaw Univ Sci & Technol, Dept Biomed Engn, Wroclaw, Poland.
RP Oleszkiewicz, A (corresponding author), Univ Wroclaw, Inst Psychol, Ul Dawida 1, PL-50527 Wroclaw, Poland.
EM ania.oleszkiewicz@gmail.com
OI Pieniak, Michal/0000-0002-2991-7109; Lachowicz-Tabaczek,
   Kinga/0000-0002-4366-5550; Oleszkiewicz, Anna/0000-0003-2217-1858;
   Masalski, Marcin/0000-0001-8086-1465
FU Narodowe Centrum NaukiNational Science Center, PolandNational Science
   Centre, Poland [2017/25/B/HS6/00561]; Polish Ministry of Science and
   Higher EducationMinistry of Science and Higher Education, Poland
   [626/STYP/12/2017]
FX Narodowe Centrum Nauki, Grant/Award Number: #2017/25/B/HS6/00561; Polish
   Ministry of Science and Higher Education, Grant/Award Number:
   #626/STYP/12/2017
CR Arnold P, 1998, J PSYCHOLINGUIST RES, V27, P481, DOI 10.1023/A:1023277220438
   Arnold P, 2001, J PSYCHOLINGUIST RES, V30, P185, DOI 10.1023/A:1010329912848
   BACKMAN L, 1992, PSYCHOL BULL, V112, P259, DOI 10.1037/0033-2909.112.2.259
   Bavelier D, 2006, TRENDS COGN SCI, V10, P512, DOI 10.1016/j.tics.2006.09.006
   Beaulieu-Lefebvre M, 2011, BRAIN RES BULL, V84, P206, DOI 10.1016/j.brainresbull.2010.12.014
   Bittencourt AG, 2012, INT ARCH OTORHINOLAR, V16, P387, DOI 10.7162/S1809-97772012000300014
   Bolognini N, 2012, J COGNITIVE NEUROSCI, V24, P276, DOI 10.1162/jocn_a_00135
   Bosworth RG, 2002, BRAIN COGNITION, V49, P152, DOI 10.1006/brcg.2001.1497
   BROSS M, 1979, PERCEPT MOTOR SKILL, V48, P187, DOI 10.2466/pms.1979.48.1.187
   Brown JD, 2012, PERS SOC PSYCHOL B, V38, P209, DOI 10.1177/0146167211432763
   Cavazzana A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202969
   Ciesla K, 2016, EUR ARCH OTO-RHINO-L, V273, P767, DOI 10.1007/s00405-015-3713-7
   Dewey RS, 2015, HEARING RES, V325, P55, DOI 10.1016/j.heares.2015.03.007
   DIEKMANN H, 1994, HNO, V42, P264
   Dufner M, 2019, PERS SOC PSYCHOL REV, V23, P48, DOI 10.1177/1088868318756467
   Ekstrom I, 2019, CHEM SENSES, V44, P105, DOI 10.1093/chemse/bjy079
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Ferdenzi C, 2010, J VISUAL IMPAIR BLIN, V104, P55, DOI 10.1177/0145482X1010400109
   Fornazieri MA, 2019, PHYSIOL BEHAV, V198, P84, DOI 10.1016/j.physbeh.2018.10.011
   Groyecka A, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00778
   Guducu C, 2019, NEUROSCI LETT, V707, DOI 10.1016/j.neulet.2019.134283
   Guducu C, 2016, CHEMOSENS PERCEPT, V9, P8, DOI 10.1007/s12078-015-9199-2
   Haehner A, 2007, MOVEMENT DISORD, V22, P839, DOI 10.1002/mds.21413
   Heimler B, 2014, EXP BRAIN RES, V232, P1335, DOI 10.1007/s00221-014-3852-x
   Hoppe U, 2015, OTOL NEUROTOL, V36, P1001, DOI 10.1097/MAO.0000000000000730
   Jambor E, 2005, J DEAF STUD DEAF EDU, V10, P63, DOI 10.1093/deafed/eni004
   Karns CM, 2012, J NEUROSCI, V32, P9626, DOI 10.1523/JNEUROSCI.6488-11.2012
   Knaapila A, 2008, LARYNGOSCOPE, V118, P2212, DOI 10.1097/MLG.0b013e3181826e43
   Knowles KK, 2016, Q J EXP PSYCHOL, V69, P1657, DOI 10.1080/17470218.2015.1091484
   Kollndorfer K, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00627
   Larsson M, 2000, J GERONTOL B-PSYCHOL, V55, pP304, DOI 10.1093/geronb/55.5.P304
   Lee SJ, 1999, PERS INDIV DIFFER, V26, P701, DOI 10.1016/S0191-8869(98)00178-0
   Lin MY, 2004, J AM GERIATR SOC, V52, P1996, DOI 10.1111/j.1532-5415.2004.52554.x
   LOKE WH, 1991, B PSYCHONOMIC SOC, V29, P437
   Masalski M, 2014, J MED INTERNET RES, V16, DOI 10.2196/jmir.2798
   Masalski M, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2222
   McCullough S, 1997, J Deaf Stud Deaf Educ, V2, P212
   McIlroy G, 2011, J DEAF STUD DEAF EDU, V16, P494, DOI 10.1093/deafed/enr017
   Megreya AM, 2017, SCI REPORTS, V7, P1
   Merabet LB, 2010, NAT REV NEUROSCI, V11, P44, DOI 10.1038/nrn2758
   Mussweiler T, 2003, PSYCHOL REV, V110, P472, DOI 10.1037/0033-295X.110.3.472
   NEWPORT EL, 1990, COGNITIVE SCI, V14, P11, DOI 10.1016/0364-0213(90)90024-Q
   Ohre B., 2011, INT J MENTAL HLTH DE, V1, P3
   Oleszkiewicz A, 2020, PHILOS T R SOC B, V375, DOI 10.1098/rstb.2019.0265
   Ozimek E, 2009, SPEECH COMMUN, V51, P307, DOI 10.1016/j.specom.2008.09.007
   Papagno C, 2016, EXP BRAIN RES, V234, P627, DOI 10.1007/s00221-015-4488-1
   Parasnis I, 2003, J SPEECH LANG HEAR R, V46, P1166, DOI 10.1044/1092-4388(2003/091)
   Pisanski K, 2014, J EXP PSYCHOL HUMAN, V40, P1316, DOI 10.1037/a0036956
   Proksch J, 2002, J COGNITIVE NEUROSCI, V14, P687, DOI 10.1162/08989290260138591
   Pruszewicz A., 1994, POLISH OTOLARYNGOLOG
   Rettenbach R, 1999, J COGNITIVE NEUROSCI, V11, P560, DOI 10.1162/089892999563616
   Schwenn O, 2002, KLIN MONATSBL AUGENH, V219, P649, DOI 10.1055/s-2002-35167
   Sharp A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192993
   Smits C, 2004, INT J AUDIOL, V43, P15, DOI 10.1080/14992020400050004
   Sorokowska A, 2019, PSYCHOL RES-PSYCH FO, V83, P1595, DOI 10.1007/s00426-018-1035-2
   Sorokowska A, 2016, CHEM SENSES, V41, P55, DOI 10.1093/chemse/bjw081
   Sorokowska A, 2013, J NONVERBAL BEHAV, V37, P153, DOI 10.1007/s10919-013-0152-2
   Sorokowska A, 2013, PERS INDIV DIFFER, V55, P175, DOI 10.1016/j.paid.2013.02.026
   Sorokowska A, 2012, EUR J PERSONALITY, V26, P496, DOI 10.1002/per.848
   Stevenson RJ, 2010, CHEM SENSES, V35, P3, DOI 10.1093/chemse/bjp083
   Stivalet P, 1998, COGNITIVE BRAIN RES, V6, P227, DOI 10.1016/S0926-6410(97)00026-8
   TAYLOR SE, 1988, PSYCHOL BULL, V103, P193, DOI 10.1037/0033-2909.103.2.193
   Tranchant P, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00507
   Voss P, 2010, WIRES COGN SCI, V1, P308, DOI 10.1002/wcs.13
NR 64
TC 2
Z9 2
U1 0
U2 0
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0887-8250
EI 1745-459X
J9 J SENS STUD
JI J. Sens. Stud.
PD AUG
PY 2020
VL 35
IS 4
AR e12572
DI 10.1111/joss.12572
EA APR 2020
PG 10
WC Food Science & Technology
SC Food Science & Technology
GA NB3LH
UT WOS:000526805700001
OA Other Gold
DA 2021-02-24
ER

PT J
AU Scheerer, NE
   Shafai, F
   Stevenson, RA
   Iarocci, G
AF Scheerer, Nichole E.
   Shafai, Fakhri
   Stevenson, Ryan A.
   Iarocci, Grace
TI Affective Prosody Perception and the Relation to Social Competence in
   Autistic and Typically Developing Children
SO JOURNAL OF ABNORMAL CHILD PSYCHOLOGY
LA English
DT Article
DE Autism Spectrum Disorder; ASD; Speech Perception; Affective Prosody;
   Emotion; Communication; Social Skills
ID EMOTION RECOGNITION; SPECTRUM QUOTIENT; LANGUAGE; SPEECH; VOICE; FACE;
   REPRESENTATION; ADOLESCENTS; ATTENTION; FAMILIAR
AB Individuals diagnosed with autism spectrum disorder (ASD) have difficulty perceiving and expressing emotions. Since prosodic changes in speech (i.e. changes in intonation, stress, rhythm, etc.) are crucial for extracting information about the emotional state of a speaker, an inability to perceive and interpret these prosodic changes may be related to impairments in social communication. This study used non-verbal emotional voice-clips to examine the ability of autistic and typically-developing children (7-13 years old) to extract affect from changes in prosody. This research also explored whether difficulty extracting affective intent from changes in prosody may be related to social competence. Autistic (n = 26) and typically-developing (n = 26) children accurately matched emotional voice-clips to emotion words, suggesting autistic children can accurately extract the affective meaning conveyed by changes in prosody. Autistic children were less accurate at matching the voice-clips to emotional faces, suggesting that autistic children may struggle to make use of prosodic information in a social context. Across both autistic and typically-developing children, prosody-face matching accuracy was found to predict overall social competence, as well as social inferencing abilities, suggesting that the inability to utilize affective information derived from a speaker's voice may interfere with effective social communication.
C1 [Scheerer, Nichole E.; Iarocci, Grace] Simon Fraser Univ, Dept Psychol, 8888 Univ Dr, Burnaby, BC V5A 1S6, Canada.
   [Scheerer, Nichole E.; Shafai, Fakhri; Stevenson, Ryan A.] Univ Western Ontario, Brain & Mind Inst, Western Interdisciplinary Res Bldg, London, ON N6A 3K7, Canada.
   [Scheerer, Nichole E.; Shafai, Fakhri; Stevenson, Ryan A.] Univ Western Ontario, Dept Psychol, Social Sci Ctr, 1151 Richmond St, London, ON N6A 3K7, Canada.
RP Scheerer, NE (corresponding author), Simon Fraser Univ, Dept Psychol, 8888 Univ Dr, Burnaby, BC V5A 1S6, Canada.; Scheerer, NE (corresponding author), Univ Western Ontario, Brain & Mind Inst, Western Interdisciplinary Res Bldg, London, ON N6A 3K7, Canada.; Scheerer, NE (corresponding author), Univ Western Ontario, Dept Psychol, Social Sci Ctr, 1151 Richmond St, London, ON N6A 3K7, Canada.
EM nikkischeerer@gmail.com
FU Natural Science and Engineering Research Council of Canada
   (NSERC)Natural Sciences and Engineering Research Council of Canada
   (NSERC); NSERCNatural Sciences and Engineering Research Council of
   Canada (NSERC); BrainsCAN Postdoctoral Fellowship at Western University
   - Canada First Research Excellence Fund (CFREF); NSERCNatural Sciences
   and Engineering Research Council of Canada (NSERC) [RGPIN2017-04656];
   SSHRC Insight Grant [435-2017-0936]; University of Western Ontario
   Faculty DevelopmentResearch Fund; Canadian Foundation for
   InnovationCanada Foundation for Innovation [37497]
FX We would like to acknowledge and thank the families who participated in
   this research, as well as the research assistants in the Autism and
   Developmental Disorders Lab who helped collect and analyze this data, in
   particular Hannah Visser and Troy Boucher. This work was supported by a
   grant from the Natural Science and Engineering Research Council of
   Canada (NSERC) awarded to Grace Iarocci and a NSERC Post-doctoral award
   to Nichole Scheerer. Nichole Scheerer is also the recipient of a
   BrainsCAN Postdoctoral Fellowship at Western University, funded by the
   Canada First Research Excellence Fund (CFREF). Ryan Stevenson is funded
   by an NSERC Discovery Grant (RGPIN2017-04656), a SSHRC Insight Grant
   (435-2017-0936), the University of Western Ontario Faculty
   DevelopmentResearch Fund, and the John R. Evans Leaders Fund from the
   Canadian Foundation for Innovation (Project#37497)
CR Auyeung B, 2008, J AUTISM DEV DISORD, V38, P1230, DOI 10.1007/s10803-007-0504-z
   Balconi M, 2007, RES DEV DISABIL, V28, P409, DOI 10.1016/j.ridd.2006.05.001
   Baron-Cohen S, 2006, J AUTISM DEV DISORD, V36, P343, DOI 10.1007/s10803-006-0073-6
   Bebko JM, 2006, J CHILD PSYCHOL PSYC, V47, P88, DOI 10.1111/j.1469-7610.2005.01443.x
   Belin P, 2008, BEHAV RES METHODS, V40, P531, DOI 10.3758/BRM.40.2.531
   Boucher J, 1998, J CHILD PSYCHOL PSYC, V39, P171, DOI 10.1111/1469-7610.00311
   Boucher J, 2000, J CHILD PSYCHOL PSYC, V41, P847, DOI 10.1111/1469-7610.00672
   BOUCHER J, 1992, J CHILD PSYCHOL PSYC, V33, P843, DOI 10.1111/j.1469-7610.1992.tb01960.x
   Brandwein AB, 2013, CEREB CORTEX, V23, P1329, DOI 10.1093/cercor/bhs109
   Brennand R, 2011, RES AUTISM SPECT DIS, V5, P1567, DOI 10.1016/j.rasd.2011.03.002
   Charbonneau G, 2013, NEUROPSYCHOLOGIA, V51, P1002, DOI 10.1016/j.neuropsychologia.2013.02.009
   Chevallier C, 2011, NEUROPSYCHOLOGIA, V49, P507, DOI 10.1016/j.neuropsychologia.2010.11.042
   COOPER RP, 1994, CHILD DEV, V65, P1663, DOI 10.1111/j.1467-8624.1994.tb00841.x
   de Boer-Schellekens L, 2013, NEUROPSYCHOLOGIA, V51, P3004, DOI 10.1016/j.neuropsychologia.2013.10.005
   Durkin K, 2007, CHILD DEV, V78, P1441, DOI 10.1111/j.1467-8624.2007.01076.x
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   FERNALD A, 1993, CHILD DEV, V64, P657, DOI 10.2307/1131209
   Gebauer L, 2014, NEUROIMAGE-CLIN, V6, P370, DOI 10.1016/j.nicl.2014.08.025
   Goeleven E, 2008, COGNITION EMOTION, V22, P1094, DOI 10.1080/02699930701626582
   Golan O, 2006, J AUTISM DEV DISORD, V36, P169, DOI 10.1007/s10803-005-0057-y
   Heaton P, 2012, PSYCHOL MED, V42, P2453, DOI 10.1017/S0033291712000621
   HOBSON RP, 1988, PSYCHOL MED, V18, P911, DOI 10.1017/S0033291700009843
   Johnston KHS, 2017, J AUTISM DEV DISORD, V47, P3778, DOI 10.1007/s10803-017-3056-x
   Kenny L, 2016, AUTISM, V20, P442, DOI 10.1177/1362361315588200
   KLIN A, 1991, J AUTISM DEV DISORD, V21, P29, DOI 10.1007/BF02206995
   KUHL PK, 1994, CURR OPIN NEUROBIOL, V4, P812, DOI 10.1016/0959-4388(94)90128-7
   Kuhl PK, 2005, DEVELOPMENTAL SCI, V8, pF1, DOI 10.1111/j.1467-7687.2004.00384.x
   Le Sourn-Bissaoui S, 2013, J COMMUN DISORD, V46, P309, DOI 10.1016/j.jcomdis.2013.03.002
   LOVELAND KA, 1986, J AUTISM DEV DISORD, V16, P335, DOI 10.1007/BF01531663
   Loveland KA, 1997, DEV PSYCHOPATHOL, V9, P579, DOI 10.1017/S0954579497001351
   LOVELAND KA, 1995, DEV PSYCHOPATHOL, V7, P409, DOI 10.1017/S095457940000660X
   Lundqvist D., 1998, KAROLINSKA DIRECTED, V91, P630, DOI DOI 10.1080/02699930701626582
   McCann J, 2003, INT J LANG COMM DIS, V38, P325, DOI 10.1080/1368282031000154204
   McCann J, 2007, INT J LANG COMM DIS, V42, P682, DOI 10.1080/13682820601170102
   Paul R, 2005, J AUTISM DEV DISORD, V35, P205, DOI 10.1007/s10803-004-1999-1
   Pennington BF, 1991, ROCH S DEV PSYCH MOD, P117
   Peppe S, 2007, J SPEECH LANG HEAR R, V50, P1015, DOI 10.1044/1092-4388(2007/071)
   PRIOR M, 1990, J CHILD PSYCHOL PSYC, V31, P587, DOI 10.1111/j.1469-7610.1990.tb00799.x
   Rosenblau G, 2017, SOC COGN AFFECT NEUR, V12, P224, DOI 10.1093/scan/nsw118
   Rutherford MD, 2002, J AUTISM DEV DISORD, V32, P189, DOI 10.1023/A:1015497629971
   Saint-Georges C, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0078103
   Shanker S. G., 2004, PHILOS PSYCHIAT PSYC, V11, P219
   Sinclair J., 2013, AUTONOMY CRITICAL J, V1
   Stevens K. N., 1983, SPEECH HEARING IMPAI, P35
   Stevenson RA, 2018, AUTISM, V22, P609, DOI 10.1177/1362361317704413
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Stewart ME, 2013, AUTISM, V17, P6, DOI 10.1177/1362361311424572
   Tanaka JW, 2016, J AUTISM DEV DISORD, V46, P1538, DOI 10.1007/s10803-013-1976-7
   Volkmar F. R., 2005, HDB AUTISM PERVASIVE, P5, DOI DOI 10.1002/9780470939345.CH1
   Wechsler D, 2011, WASI 2 WECHSLER ABBR
   West MJ, 2018, J AUTISM DEV DISORD, V48, P2611, DOI 10.1007/s10803-018-3522-0
   Yager J, 2013, AUTISM RES, V6, P631, DOI 10.1002/aur.1331
NR 52
TC 1
Z9 1
U1 5
U2 9
PU SPRINGER/PLENUM PUBLISHERS
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0091-0627
EI 1573-2835
J9 J ABNORM CHILD PSYCH
JI J. Abnorm. Child Psychol.
PD JUL
PY 2020
VL 48
IS 7
BP 965
EP 975
DI 10.1007/s10802-020-00644-5
EA APR 2020
PG 11
WC Psychology, Clinical; Psychology, Developmental
SC Psychology
GA LZ5CF
UT WOS:000526329100001
PM 32285352
DA 2021-02-24
ER

PT J
AU Lee, SY
   Shim, YJ
   Han, JH
   Song, JJ
   Koo, JW
   Ha Oh, S
   Lee, S
   Oh, DY
   Choi, BY
AF Lee, Sang-Yeon
   Shim, Ye Ji
   Han, Jin-Hee
   Song, Jae-Jin
   Koo, Ja-Won
   Ha Oh, Seung
   Lee, Seungmin
   Oh, Doo-Yi
   Choi, Byung Yoon
TI The molecular etiology of deafness and auditory performance in the
   postlingually deafened cochlear implantees
SO SCIENTIFIC REPORTS
LA English
DT Article
ID HEARING-LOSS; IMPLANTATION; AGE; MUTATIONS; PHENOTYPE; CHILDREN; SIZE
AB Recent advances in molecular genetic testing (MGT) have improved identification of genetic aetiology of candidates for cochlear implantation (CI). However, whether genetic information increases CI outcome predictability in post-lingual deafness remains unclear. Therefore, we evaluated the outcomes of CI with respect to genetic aetiology and clinical predictors by comparing the data of study subjects; those with an identified genetic aetiology (GD group), and those without identifiable variants (GUD group). First, we identified the genetic aetiology in 21 of 40 subjects and also observed genetic etiologic heterogeneity. The GD group demonstrated significantly greater improvement in speech perception scores over a 1-year period than did the GUD group. Further, inverse correlation between deafness duration and the 1-year improvement in speech perception scores was tighter in the GD group than in the GUD group. The weak correlation between deafness duration and CI outcomes in the GUD group might suggest the pathophysiology underlying GUD already significantly involves the cortex, leading to lesser sensitivity to further cortex issues such as deafness duration. Under our MGT protocol, the correlation between deafness duration and CI outcomes were found to rely on the presence of identifiable genetic aetiology, strongly advocating early CI in individual with proven genetic aetiologies.
C1 [Lee, Sang-Yeon; Han, Jin-Hee; Song, Jae-Jin; Koo, Ja-Won; Lee, Seungmin; Oh, Doo-Yi; Choi, Byung Yoon] Seoul Natl Univ, Dept Otorhinolaryngol Head & Neck Surg, Bundang Hosp, Seongnam, South Korea.
   [Shim, Ye Ji] Seoul Natl Univ Hosp, Healthcare Syst Gangnam Ctr, Dept Otorhinolaryngol Head & Neck Surg, Seoul, South Korea.
   [Ha Oh, Seung] Seoul Natl Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg, Seoul, South Korea.
RP Choi, BY (corresponding author), Seoul Natl Univ, Dept Otorhinolaryngol Head & Neck Surg, Bundang Hosp, Seongnam, South Korea.
EM choiby@snubh.org
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2017R1D1A1B03034401]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (2017R1D1A1B03034401 to D.Y. Oh). The manuscript was edited
   for proper English language, grammar, punctuation, spelling, and overall
   style by the highly qualified native English-speaking editors at
   EMENDOLOGY (submission code:190509-04).
CR Anderson CA, 2017, P NATL ACAD SCI USA, V114, P10256, DOI 10.1073/pnas.1704785114
   Asthagiri AR, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0046132
   Battelino S, 2016, EUR ARCH OTO-RHINO-L, V273, P1151, DOI 10.1007/s00405-015-3671-0
   Beyea JA, 2016, OTOL NEUROTOL, V37, P1238, DOI 10.1097/MAO.0000000000001162
   Blamey P, 2013, AUDIOL NEURO-OTOL, V18, P36, DOI 10.1159/000343189
   Carlson ML, 2012, OTOL NEUROTOL, V33, P853, DOI 10.1097/MAO.0b013e318254fba5
   Chang MY, 2018, BMC MED GENET, V19, DOI 10.1186/s12881-018-0541-9
   Chang MY, 2015, MEDICINE, V94, DOI 10.1097/MD.0000000000001996
   Choi BY, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068692
   Entwisle Lavin K., 2018, Seminars in Hearing, V39, P390, DOI 10.1055/s-0038-1670705
   Eppsteiner RW, 2012, HEARING RES, V292, P51, DOI 10.1016/j.heares.2012.08.007
   Eshraghi AA, 2017, ACTA OTO-LARYNGOL, V137, P384, DOI 10.1080/00016489.2016.1256499
   Frisina RD, 2016, AGING-US, V8, P2081, DOI 10.18632/aging.101045
   Halliday D, 2017, J MED GENET, V54, P657, DOI 10.1136/jmedgenet-2017-104519
   Han KH, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-16676-9
   Kim BG, 2013, JAMA OTOLARYNGOL, V139, P604, DOI 10.1001/jamaoto.2013.3195
   Kim BJ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0165680
   Kim H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-36404-1
   Lazard DS, 2014, HEARING RES, V307, P136, DOI 10.1016/j.heares.2013.08.006
   Lazard DS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048739
   Lee Sang-Yeon, 2020, Clin Exp Otorhinolaryngol, V13, P113, DOI 10.21053/ceo.2019.00990
   Lee SY, 2019, INT J MOL SCI, V20, DOI 10.3390/ijms20174174
   Lesicko AMH, 2017, HEARING RES, V343, P4, DOI 10.1016/j.heares.2016.05.018
   Libe-Philippot B, 2017, P NATL ACAD SCI USA, V114, P7765, DOI 10.1073/pnas.1703408114
   Mahmoud AF, 2014, OTOL NEUROTOL, V35, pE286, DOI 10.1097/MAO.0000000000000581
   Maxwell SE, 2000, PSYCHOL METHODS, V5, P434, DOI 10.1037/1082-989X.5.4.434
   Michalski N, 2019, ANNU REV NEUROSCI, V42, P67, DOI 10.1146/annurev-neuro-070918-050428
   Miyagawa M, 2015, ANN OTOLOGY S, V124s, P193
   Miyagawa M, 2016, OTOL NEUROTOL, V37, pE126, DOI 10.1097/MAO.0000000000000936
   Miyagawa M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0075793
   Nagy I, 2004, J MED GENET, V41, DOI 10.1136/jmg.2003.012286
   Olds C, 2016, EAR HEARING, V37, pE160, DOI 10.1097/AUD.0000000000000258
   Pan BF, 2013, NEURON, V79, P504, DOI 10.1016/j.neuron.2013.06.019
   Park G, 2013, BMC GENOMICS, V14, DOI 10.1186/1471-2164-14-191
   Park JH, 2017, EAR HEARING, V38, pE316, DOI 10.1097/AUD.0000000000000437
   Park JH, 2014, ORPHANET J RARE DIS, V9, DOI 10.1186/s13023-014-0167-8
   Parzefall T, 2018, WIEN KLIN WOCHENSCHR, V130, P299, DOI 10.1007/s00508-017-1230-y
   Shearer AE, 2017, HEARING RES, V348, P138, DOI 10.1016/j.heares.2017.02.008
   Street VA, 2005, AM J MED GENET A, V139A, P86, DOI 10.1002/ajmg.a.30980
   Tolisano AM, 2019, OTOL NEUROTOL, V40, pE381, DOI 10.1097/MAO.0000000000002165
   Tsukada K, 2010, CLIN GENET, V78, P464, DOI 10.1111/j.1399-0004.2010.01407.x
   Vermeire K, 2006, OTOL NEUROTOL, V27, P44, DOI 10.1097/01.mao.0000187240.33712.01
   Weegerink NJD, 2011, JARO-J ASSOC RES OTO, V12, P753, DOI 10.1007/s10162-011-0282-3
   Willaredt MA, 2014, HEARING RES, V312, P9, DOI 10.1016/j.heares.2014.02.004
   Wu CC, 2015, MEDICINE, V94, DOI 10.1097/MD.0000000000001073
   Wu CC, 2011, LARYNGOSCOPE, V121, P1287, DOI 10.1002/lary.21751
NR 46
TC 3
Z9 3
U1 0
U2 0
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD APR 1
PY 2020
VL 10
IS 1
AR 5768
DI 10.1038/s41598-020-62647-y
PG 12
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA NF7HJ
UT WOS:000563465100003
PM 32238869
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Fostick, L
   Taitelbaum-Swead, R
   Kreitler, S
   Zokraut, S
   Billig, M
AF Fostick, Leah
   Taitelbaum-Swead, Riki
   Kreitler, Shulamith
   Zokraut, Shelly
   Billig, Miriam
TI Auditory Training to Improve Speech Perception and Self-Efficacy in
   Aging Adults
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID AGE-RELATED-CHANGES; QUALITY-OF-LIFE; TIME-COMPRESSED SPEECH;
   HEARING-LOSS; OLDER-ADULTS; TEMPORAL-ORDER; RECOGNITION PERFORMANCE; GAP
   DETECTION; PROCESSING DEFICITS; ELDERLY LISTENERS
AB Purpose: Difficulty in understanding spoken speech is a common complaint among aging adults, even when hearing impairment is absent. Correlational studies point to a relationship between age, auditory temporal processing (ATP), and speech perception but cannot demonstrate causality unlike training studies. In the current study, we test (a) the causal relationship between a spatial-temporal ATP task (temporal order judgment [TOO and speech perception among aging adults using a training design and (b) whether improvement in aging adult speech perception is accompanied by improved self-efficacy.
   Method: Eighty-two participants aged 60-83 years were randomly assigned to a group receiving (a) ATP training (TOJ) over 14 days, (b) non-ATP training (intensity discrimination) over 14 days, or (c) no training.
   Results: The data showed that TOJ training elicited improvement in all speech perception tests, which was accompanied by increased self-efficacy. Neither improvement in speech perception nor self-efficacy was evident following non-ATP training or no training.
   Conclusions: There was no generalization of the improvement resulting from TOJ training to intensity discrimination or generalization of improvement resulting from intensity discrimination training to speech perception. These findings imply that the effect of TOJ training on speech perception is specific and such improvement is not simply the product of generally improved auditory perception. It provides support for the idea that temporal properties of speech are indeed crucial for speech perception. Clinically, the findings suggest that aging adults can be trained to improve their speech perception, specifically through computer-based auditory training, and this may improve perceived self-efficacy.
C1 [Fostick, Leah; Taitelbaum-Swead, Riki] Ariel Univ, Dept Commun Disorders, Ariel, Israel.
   [Kreitler, Shulamith] Tel Aviv Univ, Sch Psychol Sci, Tel Aviv, Israel.
   [Zokraut, Shelly] Ariel Univ, Dept Hlth Syst Management, Ariel, Israel.
   [Billig, Miriam] Ariel Univ, Dept Sociol & Anthropol, Ariel, Israel.
   [Billig, Miriam] Eastern R&D Ctr, Ariel, Israel.
RP Fostick, L (corresponding author), Ariel Univ, Dept Commun Disorders, Ariel, Israel.
EM leah.fostick@ariel.ac.il
RI Fostick, Leah/E-6115-2017
OI Fostick, Leah/0000-0003-3594-6229
FU Israeli Ministry of Science and TechnologyMinistry of Science,
   Technology and Space (MOST), Israel; Eastern RD Center
FX This study was funded by the Israeli Ministry of Science and Technology
   and supported by the Eastern R&D Center. The authors would like to thank
   Shira Chana Bienstock for her thorough editorial review of this article.
CR Alain C, 2008, CLIN NEUROPHYSIOL, V119, P356, DOI 10.1016/j.clinph.2007.10.024
   Alain C, 2014, HEARING RES, V308, P162, DOI 10.1016/j.heares.2013.06.008
   Amitay S, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009816
   Anderson S, 2014, NEUROPSYCHOLOGIA, V62, P286, DOI 10.1016/j.neuropsychologia.2014.07.034
   Anderson S, 2013, HEARING RES, V300, P18, DOI 10.1016/j.heares.2013.03.006
   Babkoff H, 2017, EUR J AGEING, V14, P269, DOI 10.1007/s10433-017-0410-y
   Bainbridge KE, 2014, ANNU REV PUBL HEALTH, V35, P139, DOI 10.1146/annurev-publhealth-032013-182510
   Bakeman R, 2005, BEHAV RES METHODS, V37, P379, DOI 10.3758/BF03192707
   Banai K, 2014, J ACOUST SOC AM, V136, P1908, DOI 10.1121/1.4895684
   Ben-Artzi E., 2011, AUDIOLOGY RES, V1, DOI [10.4081/audiores.2011.8, DOI 10.4081/AUDI0RES.2011.E6]
   Bergeson T. R., 2001, Canadian Acoustics, V29, P3
   Bidelman GM, 2015, J NEUROSCI, V35, P1240, DOI 10.1523/JNEUROSCI.3292-14.2015
   BOOTHROYD A, 1984, J SPEECH HEAR RES, V27, P134, DOI 10.1044/jshr.2701.134
   Burk MH, 2008, J SPEECH LANG HEAR R, V51, P759, DOI 10.1044/1092-4388(2008/054)
   Burk MH, 2007, J SPEECH LANG HEAR R, V50, P25, DOI 10.1044/1092-4388(2007/003)
   Burk MH, 2006, EAR HEARING, V27, P263, DOI 10.1097/01.aud.0000215980.21158.a2
   Carter A, 2017, J FLUENCY DISORD, V54, P14, DOI 10.1016/j.jfludis.2017.09.004
   Chermak G. D., 2007, HDB CENTRAL AUDITORY
   Ciorba A, 2012, CLIN INTERV AGING, V7, P159, DOI 10.2147/CIA.S26059
   Cruickshanks KJ, 2003, ARCH OTOLARYNGOL, V129, P1041, DOI 10.1001/archotol.129.10.1041
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014
   Divenyi PL, 1997, EAR HEARING, V18, P189, DOI 10.1097/00003446-199706000-00002
   Dupoux E, 1997, J EXP PSYCHOL HUMAN, V23, P914, DOI 10.1037/0096-1523.23.3.914
   Elion O, 2015, BRAIN RES, V1609, P54, DOI 10.1016/j.brainres.2015.03.020
   Ezzatian P, 2015, EAR HEARING, V36, P482, DOI 10.1097/AUD.0000000000000139
   Fink M, 2005, RESTOR NEUROL NEUROS, V23, P281
   Fitzgibbons PJ, 2010, SPRINGER HANDB AUDIT, V34, P111, DOI 10.1007/978-1-4419-0993-0_5
   Fogerty D, 2012, J ACOUST SOC AM, V131, pEL499, DOI 10.1121/1.4722172
   Fogerty D, 2010, J ACOUST SOC AM, V127, P2509, DOI 10.1121/1.3316291
   Fostick L, 2019, PSYCHOL RES-PSYCH FO, V83, P968, DOI 10.1007/s00426-017-0915-1
   Fostick L, 2014, J EXP PSYCHOL HUMAN, V40, P1799, DOI 10.1037/a0037527
   Fostick Leah, 2014, Journal of Basic and Clinical Physiology and Pharmacology, V25, P307, DOI 10.1515/jbcpp-2014-0036
   Fostick L, 2014, J SPEECH LANG HEAR R, V57, P1078, DOI 10.1044/1092-4388(2013/13-0031)
   Fostick Leah, 2013, Journal of Basic and Clinical Physiology and Pharmacology, V24, P191, DOI 10.1515/jbcpp-2013-0049
   Fostick Leah, 2013, Journal of Basic and Clinical Physiology and Pharmacology, V24, P175, DOI 10.1515/jbcpp-2013-0048
   Frtusova JB, 2013, PSYCHOL AGING, V28, P481, DOI 10.1037/a0031243
   Fu Qian-Jie, 2004, Cochlear Implants Int, V5 Suppl 1, P84, DOI 10.1179/cim.2004.5.Supplement-1.84
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Gabay Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176488
   Golomb JD, 2007, J ACOUST SOC AM, V121, P1701, DOI 10.1121/1.2436635
   Gordon-Salant S, 2006, J ACOUST SOC AM, V119, P2455, DOI 10.1121/1.2171527
   Gordon-Salant S, 2005, J REHABIL RES DEV, V42, P9, DOI 10.1682/JRRD.2005.01.0006
   Gordon-Salant S, 2008, J ACOUST SOC AM, V124, P3249, DOI 10.1121/1.2982409
   GORDONSALANT S, 1995, J SPEECH HEAR RES, V38, P1150, DOI 10.1044/jshr.3805.1150
   Grimes DA, 2005, LANCET, V366, P172, DOI 10.1016/S0140-6736(05)66875-4
   Grose JH, 2006, J ACOUST SOC AM, V119, P2305, DOI 10.1121/1.2172169
   Grossman M, 2002, NEUROIMAGE, V15, P302, DOI 10.1006/nimg.2001.0971
   Heinrich A, 2006, J ACOUST SOC AM, V119, P2316, DOI 10.1121/1.2173524
   Henshaw H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0062836
   Henshaw H, 2012, J MED INTERNET RES, V14, P211, DOI 10.2196/jmir.2036
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Humes LE, 2014, J ACOUST SOC AM, V136, pEL224, DOI 10.1121/1.4890663
   Humes LE, 2013, ATTEN PERCEPT PSYCHO, V75, P508, DOI 10.3758/s13414-012-0406-9
   Humes LE, 2010, HEARING RES, V264, P30, DOI 10.1016/j.heares.2009.09.010
   Humes LE, 2009, EAR HEARING, V30, P613, DOI 10.1097/AUD.0b013e3181b00d90
   Karawani H, 2016, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.02066
   KARNI A, 1993, NATURE, V365, P250, DOI 10.1038/365250a0
   Karni A, 1996, COGNITIVE BRAIN RES, V5, P39, DOI 10.1016/S0926-6410(96)00039-0
   Kolman J., 1998, GOOD CLIN PRACTICE S, DOI [10.1002/0470842520, DOI 10.1002/0470842520]
   Kraus Nina, 2014, Hear J, V67, P3
   Kreitler S, 2007, PSYCHO-ONCOLOGY, V16, P329, DOI 10.1002/pon.1063
   Lee FS, 2005, EAR HEARING, V26, P1, DOI 10.1097/00003446-200502000-00001
   Li-Korotky HS, 2012, GERONTOLOGIST, V52, P265, DOI 10.1093/geront/gnr159
   Manheim M, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518778651
   McArthur GM, 2008, COGNITION, V107, P946, DOI 10.1016/j.cognition.2007.12.005
   MOORE BCJ, 1992, J ACOUST SOC AM, V92, P1923, DOI 10.1121/1.405240
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Olze H, 2016, AUDIOL NEURO-OTOL, V21, P43, DOI 10.1159/000448354
   Ostroff JM, 2003, HEARING RES, V181, P1, DOI 10.1016/S0378-5955(03)00113-8
   Pallier C, 1998, MEM COGNITION, V26, P844, DOI 10.3758/BF03211403
   Parbery-Clark A, 2012, NEUROBIOL AGING, V33, DOI 10.1016/j.neurobiolaging.2011.12.015
   Parbery-Clark A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018082
   Pichora-Fuller MK, 2008, INT J AUDIOL, V47, pS72, DOI 10.1080/14992020802307404
   Pichora-Fuller MK, 2006, J ACOUST SOC AM, V119, P1143, DOI 10.1121/1.2149837
   Price C, 2005, TRENDS COGN SCI, V9, P271, DOI 10.1016/j.tics.2005.03.009
   Rabbitt P, 2004, J GERONTOL B-PSYCHOL, V59, pP84, DOI 10.1093/geronb/59.2.P84
   Reynolds CA, 2005, DEV PSYCHOL, V41, P3, DOI 10.1037/0012-1649.41.1.3
   Roth DAE, 2005, LEARN MEMORY, V12, P159, DOI 10.1101/87505
   Roth DAE, 2015, J ACOUST SOC AM, V138, P2627, DOI 10.1121/1.4932552
   Saija JD, 2014, JARO-J ASSOC RES OTO, V15, P139, DOI 10.1007/s10162-013-0422-z
   Schneider B, 1998, CAN J EXP PSYCHOL, V52, P184, DOI 10.1037/h0087291
   Schneider BA, 2000, PSYCHOL AGING, V15, P110, DOI 10.1037/0882-7974.15.1.110
   Schneider BA, 2005, PSYCHOL AGING, V20, P261, DOI 10.1037/0882-7974.20.2.261
   SCHNEIDER BA, 1994, J ACOUST SOC AM, V95, P980, DOI 10.1121/1.408403
   Schneider BA, 2002, CAN J EXP PSYCHOL, V56, P139, DOI 10.1037/h0087392
   Schneider BA, 2010, SPRINGER HANDB AUDIT, V34, P167, DOI 10.1007/978-1-4419-0993-0_7
   Schneider Bruce A., 2001, Seminars in Hearing, V22, P227, DOI 10.1055/s-2001-15628
   Schwarzer R., 1995, MEASURES HLTH PSYCHO, V1, P35, DOI [10.1037/t00393-000, DOI 10.1037/T00393-000]
   Segal O., 1999, DASH DIBUR VESHMIA, V21, P85
   Snell KB, 2000, J ACOUST SOC AM, V107, P1615, DOI 10.1121/1.428446
   Snell KB, 1997, J ACOUST SOC AM, V101, P2214, DOI 10.1121/1.418205
   Sommers MS, 2011, EAR HEARING, V32, P775, DOI 10.1097/AUD.0b013e3182234cf6
   Speers Amanda, 2015, Cochlear Implants Int, V16 Suppl 1, pS3, DOI 10.1179/1467010014Z.000000000222
   Stecker GC, 2006, J REHABIL RES DEV, V43, P537, DOI 10.1682/JRRD.2005.11.0171
   Strehlow U, 2006, EUR CHILD ADOLES PSY, V15, P19, DOI 10.1007/s00787-006-0500-4
   Sung YK, 2016, J AGING HEALTH, V28, P979, DOI 10.1177/0898264315614570
   Szymaszek A, 2006, NEUROSCI LETT, V403, P190, DOI 10.1016/j.neulet.2006.04.062
   Szymaszek A, 2009, COGN NEUROPSYCHOL, V26, P135, DOI 10.1080/02643290802504742
   Taitelbaum-Swead R, 2017, INT J PEDIATR OTORHI, V92, P146, DOI 10.1016/j.ijporl.2016.11.022
   Taitelbaum-Swead R, 2016, FOLIA PHONIATR LOGO, V68, P16, DOI 10.1159/000444749
   Taitelbaum-Swead R, 2016, CLIN LINGUIST PHONET, V30, P531, DOI 10.3109/02699206.2016.1151938
   Tun PA, 2012, AM J AUDIOL, V21, P344, DOI 10.1044/1059-0889(2012/12-0030)
   VANROOIJ JCGM, 1992, J ACOUST SOC AM, V91, P1028, DOI 10.1121/1.402628
   Veuillet E, 2007, BRAIN, V130, P2915, DOI 10.1093/brain/awm235
   Wingfield A., 2000, HDB AGING COGNITION, P359
   Working Group on Speech Understanding and Aging, 1988, J ACOUST SOC AM, V83, P859, DOI DOI 10.1121/1.395965
   Zendel BR, 2013, J COGNITIVE NEUROSCI, V25, P503, DOI 10.1162/jocn_a_00329
NR 107
TC 0
Z9 0
U1 4
U2 5
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD APR
PY 2020
VL 63
IS 4
BP 1270
EP 1281
DI 10.1044/2019_JSLHR-19-00355
PG 12
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA ND2UP
UT WOS:000561760500025
PM 32182434
DA 2021-02-24
ER

PT J
AU Adibpour, P
   Lebenberg, J
   Kabdebon, C
   Dehaene-Lambertz, G
   Dubois, J
AF Adibpour, Parvaneh
   Lebenberg, Jessica
   Kabdebon, Claire
   Dehaene-Lambertz, Ghislaine
   Dubois, Jessica
TI Anatomo-functional correlates of auditory development in infancy
SO DEVELOPMENTAL COGNITIVE NEUROSCIENCE
LA English
DT Article
DE Auditory development; MRI; DTI; EEG; Auditory evoked potentials; Corpus
   callosum; Inter-hemispheric connectivity; Perisylvian cortical regions;
   Language network; Speech lateralization; Brain asymmetries;
   Microstructure; Tractography
ID WHITE-MATTER; EVOKED-POTENTIALS; STRUCTURAL ASYMMETRIES; CORTICAL
   RESPONSES; SPEECH-PERCEPTION; MATURATION; BRAIN; SEQUENCE; SYSTEM;
   DISCRIMINATION
AB Infant brain development incorporates several intermingled mechanisms leading to intense and asynchronous maturation across cerebral networks and functional modalities. Combining electroencephalography (EEG) and diffusion magnetic resonance imaging (MRI), previous studies in the visual modality showed that the functional maturation of the event-related potentials (ERP) during the first postnatal semester relates to structural changes in the corresponding white matter pathways. Here investigated similar issues in the auditory modality. We measured ERPs to syllables in 1- to 6-month-old infants and related them to the maturational properties of underlying neural substrates measured with diffusion tensor imaging (DTI). We first observed a decrease in the latency of the auditory P2, and in the diffusivities in the auditory tracts and perisylvian regions with age. Secondly, we highlighted some of the early functional and structural substrates of lateralization. Contralateral responses to monoaural syllables were stronger and faster than ipsilateral responses, particularly in the left hemisphere. Besides, the acoustic radiations, arcuate fasciculus, middle temporal and angular gyri showed DTI asymmetries with a more complex and advanced microstructure in the left hemisphere, whereas the reverse was observed for the inferior frontal and superior temporal gyri. Finally, after accounting for the age-related variance, we correlated the inter-individual variability in P2 responses and in the microstructural properties of callosal fibers and inferior frontal regions. This study combining dedicated EEG and MRI approaches in infants highlights the complex relation between the functional responses to auditory stimuli and the maturational properties of the corresponding neural network.
C1 [Adibpour, Parvaneh; Lebenberg, Jessica; Kabdebon, Claire; Dehaene-Lambertz, Ghislaine; Dubois, Jessica] NeuroSpin Ctr, Cognit Neuroimaging Unit U992, Gif Sur Yvette, France.
   [Lebenberg, Jessica] CEA DRF Inst Joliot, UNATI, Gif Sur Yvette, France.
   [Dubois, Jessica] Univ Paris, INSERM, NeuroDiderot, F-75019 Paris, France.
RP Adibpour, P (corresponding author), NeuroSpin Ctr, Cognit Neuroimaging Unit U992, Gif Sur Yvette, France.
EM p.adibpour@gmail.com
RI Dubois, Jessica/P-2461-2014
OI Adibpour, Parvaneh/0000-0002-6896-6261
FU Fondation de FranceFondation de France; Fyssen Foundation; European
   UnionEuropean Commission [695710, 785907, 720270, 604102]; IdEx
   Universite de Paris [ANR-18-IDEX-0001]
FX The authors thank Froncois Leroy for his help with the MRI analyses,
   Giovanna. Santoro and the medical team of UNIACT at Neurospin, who
   helped to carry out the experiments, as well as all the infants and
   their parents who participated in this study. This research was
   supported by grants from the Fondation de France (call Neurodevelopment
   2012), the Fyssen Foundation (2009) and the European Union's Horizon
   2020 Research and Innovation Programme under Grant Agreement No. 695710,
   No. 785907 (HBP SGA2), No. 720270 (HBP SGA1) and No. 604102 (HBP ramp-up
   phase). This study contributed to the IdEx Universite de Paris,
   ANR-18-IDEX-0001. The funders had no role in study design, data
   collection and analysis, decision to publish, or preparation of the
   manuscript.
CR Adibpour P., 2018, BRAIN STRUCT FUNCT, P1
   Adibpour P, 2018, NAT HUM BEHAV, V2, P67, DOI 10.1038/s41562-017-0249-4
   Anderson B, 1999, NEUROPSY NEUROPSY BE, V12, P247
   Andoh J, 2015, J NEUROSCI, V35, P14602, DOI 10.1523/JNEUROSCI.2333-15.2015
   Ball G, 2013, P NATL ACAD SCI USA, V110, P9541, DOI 10.1073/pnas.1301652110
   BARNET AB, 1975, ELECTROEN CLIN NEURO, V39, P29, DOI 10.1016/0013-4694(75)90124-8
   Basirat A, 2014, COGNITION, V132, P137, DOI 10.1016/j.cognition.2014.03.013
   Batalle D., 2019, NEUROIMAGE
   Behrens TEJ, 2007, NEUROIMAGE, V34, P144, DOI 10.1016/j.neuroimage.2006.09.018
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   Bristow D, 2009, J COGNITIVE NEUROSCI, V21, P905, DOI 10.1162/jocn.2009.21076
   BRODY BA, 1987, J NEUROPATH EXP NEUR, V46, P283, DOI 10.1097/00005072-198705000-00005
   Buxhoeveden DR, 2001, BRAIN BEHAV EVOLUT, V57, P349, DOI 10.1159/000047253
   Dehaene-Lambertz G, 2001, NEUROREPORT, V12, P3155, DOI 10.1097/00001756-200110080-00034
   Dehaene-Lambertz G, 2010, BRAIN LANG, V114, P53, DOI 10.1016/j.bandl.2009.09.003
   Dehaene-Lambertz G, 2000, J COGNITIVE NEUROSCI, V12, P449, DOI 10.1162/089892900562264
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dubois J, 2014, NEUROSCIENCE, V276, P48, DOI 10.1016/j.neuroscience.2013.12.044
   Dubois J, 2006, NEUROIMAGE, V30, P1121, DOI 10.1016/j.neuroimage.2005.11.022
   Dubois J, 2010, NEUROIMAGE, V52, P32, DOI 10.1016/j.neuroimage.2010.03.054
   Dubois J, 2009, CEREB CORTEX, V19, P414, DOI 10.1093/cercor/bhn097
   Dubois J., 2019, NEUROIMAGE
   Dubois J, 2008, J NEUROSCI, V28, P1943, DOI 10.1523/JNEUROSCI.5145-07.2008
   Dubois Jessica, 2016, Brain Plast, V2, P49, DOI 10.3233/BPL-160031
   Dubois J, 2016, CEREB CORTEX, V26, P2283, DOI 10.1093/cercor/bhv082
   Dubois J, 2014, MAGN RESON IMAGING, V32, P981, DOI 10.1016/j.mri.2014.05.007
   Duclap D., 2012, 29 ESMRMB LISB PORT
   Flechsig P.E., 1920, ANATOMIE MENSCHLICHE, V1
   Fukutomi H., 2018, NEUROIMAGE
   Glasel H, 2011, NEUROIMAGE, V58, P716, DOI 10.1016/j.neuroimage.2011.06.016
   Gotts SJ, 2013, P NATL ACAD SCI USA, V110, pE3435, DOI 10.1073/pnas.1302581110
   Hua K, 2008, NEUROIMAGE, V39, P336, DOI 10.1016/j.neuroimage.2007.07.053
   Hugdahl K, 2016, NEUROPSYCHOLOGIA, V93, P466, DOI 10.1016/j.neuropsychologia.2015.12.011
   Huppi PS, 1998, PEDIATR RES, V44, P584
   Huttenlocher PR, 1997, J COMP NEUROL, V387, P167, DOI 10.1002/(SICI)1096-9861(19971020)387:2<167::AID-CNE1>3.0.CO;2-Z
   Imada T, 2006, NEUROREPORT, V17, P957, DOI 10.1097/01.wnr.0000223387.51704.89
   Kabdebon C, 2014, NEUROIMAGE, V99, P342, DOI 10.1016/j.neuroimage.2014.05.046
   KURTZBERG D, 1984, DEV MED CHILD NEUROL, V26, P466
   Kushnerenko E, 2002, NEUROREPORT, V13, P1843, DOI 10.1097/00001756-200210280-00002
   Lebenberg J, 2019, NEUROIMAGE, V185, P641, DOI 10.1016/j.neuroimage.2018.07.022
   Lebenberg J., 2019, BRAIN STRUCT FUNCT, P1
   Lebenberg J., 2015, BIOM IM ISBI 2015 12
   Leroy F, 2011, J NEUROSCI, V31, P1500, DOI 10.1523/JNEUROSCI.4141-10.2011
   Li G, 2015, J NEUROSCI, V35, P9150, DOI 10.1523/JNEUROSCI.4107-14.2015
   Lippe S, 2009, FRONT HUM NEUROSCI, V3, DOI 10.3389/neuro.09.048.2009
   Mahmoudzadeh M, 2013, P NATL ACAD SCI USA, V110, P4846, DOI 10.1073/pnas.1212220110
   McCulloch DL, 1999, VISION RES, V39, P3673, DOI 10.1016/S0042-6989(99)00091-7
   MILNER B, 1968, SCIENCE, V161, P184, DOI 10.1126/science.161.3837.184
   Monson BB, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0380-17.2017
   NOVAK GP, 1989, ELECTROEN CLIN NEURO, V73, P295, DOI 10.1016/0013-4694(89)90108-9
   Ortiz-Mantilla S, 2012, NEUROIMAGE, V59, P3275, DOI 10.1016/j.neuroimage.2011.11.048
   Ouyang M., 2019, NEUROIMAGE
   Perani D, 2011, P NATL ACAD SCI USA, V108, P16056, DOI 10.1073/pnas.1102991108
   Pollmann S, 2002, NEUROPSYCHOLOGY, V16, P56, DOI 10.1037//0894-4105.16.1.56
   Ponton CW, 2000, CLIN NEUROPHYSIOL, V111, P220, DOI 10.1016/S1388-2457(99)00236-9
   Price D, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15671
   Roberts TPL, 2009, NEUROREPORT, V20, P1586, DOI 10.1097/WNR.0b013e3283306854
   Rolland C., 2019, IEEE ISBI VEN IT
   Shafer VL, 2015, INT J PSYCHOPHYSIOL, V95, P77, DOI 10.1016/j.ijpsycho.2014.08.1390
   Shultz S, 2014, DEVELOPMENTAL SCI, V17, P766, DOI 10.1111/desc.12151
   Song SK, 2005, NEUROIMAGE, V26, P132, DOI 10.1016/j.neuroimage.2005.01.028
   Song SK, 2003, NEUROIMAGE, V20, P1714, DOI 10.1016/j.neuroimage.2003.07.005
   Sowell ER, 2003, NAT NEUROSCI, V6, P309, DOI 10.1038/nn1008
   Sparks R., 1968, CORTEX, V4, P3, DOI DOI 10.1016/S0010-9452(68)80009-7
   Tadel F, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/879716
   Thomas JL, 2000, J NEUROSCI RES, V59, P471, DOI 10.1002/(SICI)1097-4547(20000215)59:4<471::AID-JNR1>3.0.CO;2-3
   Westerhausen R, 2009, CEREB CORTEX, V19, P1322, DOI 10.1093/cercor/bhn173
   Wunderlich JL, 2006, HEARING RES, V212, P212, DOI 10.1016/j.heares.2005.11.008
   Yakovlev Lecours, 1967, MYELOGENETIC CYCLES
   Yakovlev P.I., 1967, REGIONAL DEV BRAIN E
NR 71
TC 1
Z9 1
U1 2
U2 2
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1878-9293
EI 1878-9307
J9 DEV COGN NEUROS-NETH
JI Dev. Cogn. Neurosci.
PD APR
PY 2020
VL 42
AR 100752
DI 10.1016/j.dcn.2019.100752
PG 12
WC Psychology, Developmental; Neurosciences
SC Psychology; Neurosciences & Neurology
GA LR5UQ
UT WOS:000535760200002
PM 32072930
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Schertz, J
   Carbonell, K
   Lotto, AJ
AF Schertz, Jessamyn
   Carbonell, Kathy
   Lotto, Andrew J.
TI Language Specificity in Phonetic Cue Weighting: Monolingual and
   Bilingual Perception of the Stop Voicing Contrast in English and Spanish
SO PHONETICA
LA English
DT Article
ID INDIVIDUAL-DIFFERENCES; SPEECH-PERCEPTION; ONSET-TIME; CATEGORIZATION;
   COVARIATION; REALIZATION; CONSONANTS; FREQUENCY; DURATION; FEATURES
AB Background/Aims: This work examines the perception of the stop voicing contrast in Spanish and English along four acoustic dimensions, comparing monolingual and bilingual listeners. Our primary goals are to test the extent to which cue-weighting strategies are language-specific in monolinguals, and whether this language specificity extends to bilingual listeners. Methods: Participants categorized sounds varying in voice onset time (VOT, the primary cue to the contrast) and three secondary cues: fundamental frequency at vowel onset, first formant (F1) onset frequency, and stop closure duration. Listeners heard acoustically identical target stimuli, within language-specific carrier phrases, in English and Spanish modes. Results: While all listener groups used all cues, monolingual English listeners relied more on F1, and less on closure duration, than monolingual Spanish listeners, indicating language specificity in cue use. Early bilingual listeners used the three secondary cues similarly in English and Spanish, despite showing language-specific VOT boundaries. Conclusion: While our findings reinforce previous work demonstrating language-specific phonetic representations in bilinguals in terms of VOT boundary, they suggest that this specificity may not extend straightforwardly to cue-weighting strategies.
C1 [Schertz, Jessamyn] Univ Toronto Mississauga, Dept Language Studies, 3359 Mississauga Rd North, Mississauga, ON L5L 1C6, Canada.
   [Schertz, Jessamyn] Univ Toronto, Dept Linguist, Toronto, ON, Canada.
   [Carbonell, Kathy; Lotto, Andrew J.] Univ Florida, Dept Speech Language & Hearing Sci, Gainesville, FL USA.
RP Schertz, J (corresponding author), Univ Toronto Mississauga, Dept Language Studies, 3359 Mississauga Rd North, Mississauga, ON L5L 1C6, Canada.
EM jessamyn.schertz@utoronto.ca
OI Schertz, Jessamyn/0000-0003-2492-8498
FU NSF DDRIG grant [BCS-1324668]
FX The authors would like to thank Miquel Simonet and Natasha Warner for
   helpful discussion on previous versions of the work on monolinguals, and
   to Yamile Diaz for help with stimulus creation and pilot participant
   running. We are grateful to Carolyn O'Meara and the Seminario de Lenguas
   Indigenas at the Universidad Nacional Autonoma de Mexico for providing
   space to run the experiments. Finally, thanks to Sally Rios Kuri
   (Mexico) and Nicole DelCampo (Florida) for help running the experiments.
   This work was supported by NSF DDRIG grant #BCS-1324668.
CR Abramson A. S., 1985, PHONETIC LINGUISTICS, P25
   Antoniou M, 2012, J PHONETICS, V40, P582, DOI 10.1016/j.wocn.2012.05.005
   Benki J R, 2005, P 4 INT S BIL, P204
   Boersma P., 2014, PRAAT DOING PHONETIC
   BRADLOW AR, 1995, J ACOUST SOC AM, V97, P1916, DOI 10.1121/1.412064
   CARAMAZZA A, 1973, J ACOUST SOC AM, V54, P421, DOI 10.1121/1.1913594
   Chodroff E, 2017, J PHONETICS, V61, P30, DOI 10.1016/j.wocn.2017.01.001
   Clayards M, 2018, J ACOUST SOC AM, V144, pEL172, DOI 10.1121/1.5052025
   Clayards M, 2018, PHONETICA, V75, P1, DOI 10.1159/000448809
   CRYSTAL TH, 1988, J PHONETICS, V16, P285, DOI 10.1016/S0095-4470(19)30503-0
   DeRosario-Martinez H., 2015, PACKAGE PHIA
   DIEHL RL, 1990, ADV SPEECH HEARING L, V1, P243
   Dmitrieva O, 2015, J PHONETICS, V49, P77, DOI 10.1016/j.wocn.2014.12.005
   ELMAN JL, 1977, J ACOUST SOC AM, V62, P971, DOI 10.1121/1.381591
   Escudero P, 2009, J PHONETICS, V37, P452, DOI 10.1016/j.wocn.2009.07.006
   Eun-Jong Kong, 2013, [Phonetics and Speech Sciences, 말소리와 음성과학], V5, P81, DOI 10.13064/KSSS.2013.5.4.081
   Francis AL, 2008, J ACOUST SOC AM, V124, P1234, DOI 10.1121/1.2945161
   Garcia-Sierra A, 2012, BRAIN LANG, V121, P194, DOI 10.1016/j.bandl.2012.03.008
   Gonzales K, 2013, PSYCHOL SCI, V24, P2135, DOI 10.1177/0956797613486485
   Green K.P., 1997, J ACOUST SOC AM, V102, P3136, DOI DOI 10.1121/1.420648
   HAGGARD M, 1970, J ACOUST SOC AM, V47, P613, DOI 10.1121/1.1911936
   Harris J., 1969, SPANISH PHONOLOGY
   HAZAN V, 1991, PERCEPT PSYCHOPHYS, V49, P187, DOI 10.3758/BF03205038
   HAZAN VL, 1993, LANG SPEECH, V36, P17, DOI 10.1177/002383099303600102
   Holt LL, 2001, J ACOUST SOC AM, V109, P764, DOI 10.1121/1.1339825
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Idemaru K, 2012, J ACOUST SOC AM, V132, P3950, DOI 10.1121/1.4765076
   Johnson CE., 2002, INT J BILINGUAL, V6, P271, DOI DOI 10.1177/13670069020060030401
   Kapnoula EC, 2017, J EXP PSYCHOL HUMAN, V43, P1594, DOI 10.1037/xhp0000410
   Kim D, 2017, LINGUIST VANGUARD, V3, DOI 10.1515/lingvan-2016-0025
   KINGSTON J, 1994, LANGUAGE, V70, P419, DOI 10.2307/416481
   Kingston J., 1995, PHONOLOGY PHONETIC E, VIV, P7
   Kingston J, 2008, J PHONETICS, V36, P28, DOI 10.1016/j.wocn.2007.02.001
   KLUENDER KR, 1994, J ACOUST SOC AM, V95, P1044, DOI 10.1121/1.408466
   KLUENDER KR, 1991, J ACOUST SOC AM, V90, P83, DOI 10.1121/1.402285
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   LISKER L, 1957, LANGUAGE, V33, P42, DOI 10.2307/410949
   LISKER L, 1977, LANG SPEECH, V20, P209, DOI 10.1177/002383097702000303
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Llanos F, 2013, J ACOUST SOC AM, V134, P2213, DOI 10.1121/1.4817845
   LOFQVIST A, 1989, J ACOUST SOC AM, V85, P1314
   Mercier J, 2014, BILING-LANG COGN, V17, P89, DOI 10.1017/S1366728913000084
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Nearey TM, 1997, J ACOUST SOC AM, V101, P3241, DOI 10.1121/1.418290
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   R Core Team, 2013, R LANG ENV STAT COMP
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   Schertz Jessamyn, 2014, THESIS
   Simonet M, 2012, P INT
   Stilp CE, 2010, P NATL ACAD SCI USA, V107, P21914, DOI 10.1073/pnas.1009020107
   WILLIAMS L, 1977, PERCEPT PSYCHOPHYS, V21, P289, DOI 10.3758/BF03199477
   Zampini M. L., 2001, ONE MIND 2 LANGUAGES, P23
NR 52
TC 2
Z9 2
U1 2
U2 2
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 0031-8388
EI 1423-0321
J9 PHONETICA
JI Phonetica
PD APR
PY 2020
VL 77
IS 3
BP 186
EP 208
DI 10.1159/000497278
PG 23
WC Acoustics; Audiology & Speech-Language Pathology; Linguistics; Language
   & Linguistics
SC Acoustics; Audiology & Speech-Language Pathology; Linguistics
GA LO1PR
UT WOS:000533400500002
PM 31018217
DA 2021-02-24
ER

PT J
AU Ghahraman, MA
   Ashrafi, M
   Mohammadkhani, G
   Jalaie, S
AF Ghahraman, Mansoureh Adel
   Ashrafi, Majid
   Mohammadkhani, Ghassem
   Jalaie, Shohreh
TI Effects of aging on spatial hearing
SO AGING CLINICAL AND EXPERIMENTAL RESEARCH
LA English
DT Article
DE Spatial hearing; Speech perception in noise; Aging
ID SPEECH-IN-NOISE; RETEST RELIABILITY; SOUND LOCALIZATION; OLDER-ADULTS;
   LATERALIZATION; PERCEPTION; QUALITIES; ABILITIES; MASKING
AB Background Aging has several effects on auditory processing with the most important effect known as speech perception impairment in noise. Aims The aim of the present study was to investigate the effects of aging on spatial hearing using quick speech in noise (QSIN) and binaural masking level difference (BMLD) tests and speech, spatial, and qualities of hearing scale (SSQ) questionnaire. Methods The study was carried out on 34 elderly people, aged 60-75 years, with normal peripheral hearing and 34 young participants, aged 18-25 years. Using SSQ questionnaire and QSIN and BMLD tests, the spatial auditory processing ability was compared between the two groups. Results Comparison of mean scores using independent t test showed that there was a significant difference in the mean scores of QSIN, BMLD tests and SSQ questionnaire between the two groups (p < 0.001). Sex was not found to have any effect on the results (p > 0.05). Discussion Structural and neurochemical changes that occur in different parts of the central nervous system by aging affect various aspects of spatial auditory processing, such as localization, the precedence effect, and speech perception in noise. Conclusions Lower scores of older adults with normal hearing in SSQ questionnaire and behavioral tests, compared with younger participants, may be considered as their weak performance in spatial auditory processing. The results of the present study reconfirm the effects of aging on spatial auditory processing, such as localization and speech perception in noise.
C1 [Ghahraman, Mansoureh Adel; Ashrafi, Majid; Mohammadkhani, Ghassem] Univ Tehran Med Sci, Sch Rehabil, Dept Audiol, Tehran, Iran.
   [Jalaie, Shohreh] Univ Tehran Med Sci, Sch Rehabil, Biostat, Tehran, Iran.
RP Mohammadkhani, G (corresponding author), Univ Tehran Med Sci, Sch Rehabil, Dept Audiol, Tehran, Iran.
EM mohamadkhani@tums.ac.ir
OI Adel Ghahraman, Mansoureh/0000-0002-7118-6231
CR Abel SM, 2000, J ACOUST SOC AM, V108, P743, DOI 10.1121/1.429607
   Allen K, 2008, J ACOUST SOC AM, V123, P1562, DOI 10.1121/1.2831774
   Anderson S, 2012, J NEUROSCI, V32, P14156, DOI 10.1523/JNEUROSCI.2176-12.2012
   Anderson S, 2010, TRENDS AMPLIF, V14, P73, DOI 10.1177/1084713810380227
   Arbogast TL, 2005, J ACOUST SOC AM, V117, P2169, DOI 10.1121/1.1861598
   Atcherson Samuel R., 2015, Seminars in Hearing, V36, P150, DOI 10.1055/s-0035-1555118
   Bear M. F., 2007, NEUROSCIENCE EXPLORI
   Besser J, 2015, EAR HEARING, V36, P24, DOI 10.1097/AUD.0000000000000096
   Cameron S, 2007, EAR HEARING, V28, P196, DOI 10.1097/AUD.0b013e318031267f
   Cameron S, 2011, J AM ACAD AUDIOL, V22, P697, DOI 10.3766/jaaa.22.10.7
   Choi JE, 2017, EAR HEARING, V38, P426, DOI 10.1097/AUD.0000000000000401
   Cox LC, 2008, J AM ACAD AUDIOL, V19, P293, DOI 10.3766/jaaa.19.4.3
   Creavin ST, 2016, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD011145.pub2
   Delphi M, 2017, IRAN J MED SCI, V42, P437
   Duncan KR, 2006, CAN J SPEECH-LANG PA, V30, P86
   Gallun FJ, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00252
   Galvin Karyn L, 2013, Cochlear Implants Int, V14, P135, DOI 10.1179/1754762812Y.0000000014
   GROSE JP, 1994, J SPEECH HEAR RES, V37, P422, DOI 10.1044/jshr.3702.422
   Heidari A, 2018, J AUDIOL OTOL, V22, P134, DOI 10.7874/jao.2017.00304
   Katz J, 2015, HDB CLIN AUDIOLOGY
   King AJ, 2007, CURR BIOL, V17, pR236, DOI 10.1016/j.cub.2007.01.046
   Konig R, 2005, AUDITORY CORTEX: SYNTHESIS OF HUMAN AND ANIMAL RESEARCH, P361
   Kubo T, 1998, ACTA OTO-LARYNGOL, P63
   Langers DRM, 2007, NEUROIMAGE, V34, P264, DOI 10.1016/j.neuroimage.2006.09.002
   Lotfi Yones, 2016, Acta Med Iran, V54, P756
   Lotfi Y, 2016, J AUDIOL OTOL, V20, P102, DOI 10.7874/jao.2016.20.2.102
   Lovett RES, 2012, J SPEECH LANG HEAR R, V55, P865, DOI 10.1044/1092-4388(2011/11-0096)
   Martin JS, 2005, J REHABIL RES DEV, V42, P25, DOI 10.1682/JRRD.2004.12.0164
   Musiek FE, 2007, HDB CENTRAL AUDITORY
   Noble W, 2006, INT J AUDIOL, V45, P172, DOI 10.1080/14992020500376933
   Noble W, 2009, OTOL NEUROTOL, V30, P921, DOI 10.1097/MAO.0b013e3181b76b3b
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Palomaki KJ, 2005, COGNITIVE BRAIN RES, V24, P364, DOI 10.1016/j.cogbrainres.2005.02.013
   Peelle JE, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00051
   Pichora-Fuller MK, 2012, AM J AUDIOL, V21, P351, DOI 10.1044/1059-0889(2012/12-0025)
   Pickles J.O., 2008, INTRO PHYSL HEARING
   Reeder RM, 2015, AUDIOL NEURO-OTOL, V20, P31, DOI 10.1159/000380745
   Scott SK, 2005, CURR OPIN NEUROBIOL, V15, P197, DOI 10.1016/j.conb.2005.03.009
   Shayanmehr S, 2015, AUDITORY VESTIB RES, V24, P234
   Singh G, 2010, INT J AUDIOL, V49, P733, DOI 10.3109/14992027.2010.491097
   Song PL, 2011, CHINESE MED J-PEKING, V124, P4269, DOI 10.3760/cma.j.issn.0366-6999.2011.24.026
   Tyler RS, 2009, EAR HEARING, V30, P466, DOI 10.1097/AUD.0b013e3181a61efe
   Van Yper LN, 2015, CLIN NEUROPHYSIOL, V126, P772, DOI 10.1016/j.clinph.2014.07.032
   Yalcinkaya F, 2008, TURKISH J PEDIATR, V50, P34
NR 44
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1594-0667
EI 1720-8319
J9 AGING CLIN EXP RES
JI Aging Clin. Exp. Res.
PD APR
PY 2020
VL 32
IS 4
BP 733
EP 739
DI 10.1007/s40520-019-01233-3
PG 7
WC Geriatrics & Gerontology
SC Geriatrics & Gerontology
GA LF3PJ
UT WOS:000527332400021
PM 31203530
DA 2021-02-24
ER

PT J
AU Stringer, L
   Iverson, P
AF Stringer, Louise
   Iverson, Paul
TI Non-native speech recognition sentences: A new materials set for
   non-native speech perception research
SO BEHAVIOR RESEARCH METHODS
LA English
DT Article
DE L2 speech perception; Stimulus set
ID IN-NOISE RECOGNITION; ENGLISH; INTELLIGIBILITY; REVERBERATION;
   LISTENERS; JAPANESE; BRAIN; NORMS; CUES
AB Research into non-native (L2) speech perception has increased the need for specialized experimental materials. The Non-Native Speech Recognition (NNSR) sentences are a new large-scale set of speech recognition materials for research with L2 speakers of English at CEFR level B1 (North, Ortega, & Sheehan, 2010) and above. The set comprises 439 triplets of sentences in three related conditions: semantically predictable, neutral, and anomalous. The sentences were created by combining a strongly or weakly contextually constrained sentence frame with a congruent or anomalous final keyword, and they were matched on a number of factors during development, to maintain consistency across conditions. This article describes the development process of the NNSR sentences, along with results of speech-in-noise intelligibility testing for L2 and native English speakers. Suggestions for the sentences' application in a range of investigations and experimental designs are also discussed.
C1 [Stringer, Louise; Iverson, Paul] UCL, Dept Speech Hearing & Phonet Sci, London, England.
   [Stringer, Louise] Univ York, Acad Support Off, York, N Yorkshire, England.
RP Stringer, L (corresponding author), UCL, Dept Speech Hearing & Phonet Sci, London, England.; Stringer, L (corresponding author), Univ York, Acad Support Off, York, N Yorkshire, England.
EM louise.stringer@york.ac.uk
FU FP7 People: Marie-Curie Actions [FP7-PEOPLE-2011-290000] Funding Source:
   Medline
CR Balota DA, 2007, BEHAV RES METHODS, V39, P445, DOI 10.3758/BF03193014
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   Block CK, 2010, BEHAV RES METHODS, V42, P665, DOI 10.3758/BRM.42.3.665
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Calandruccio L, 2012, J SPEECH LANG HEAR R, V55, P1342, DOI 10.1044/1092-4388(2012/11-0260)
   Cooke M, 2008, J ACOUST SOC AM, V123, P414, DOI 10.1121/1.2804952
   Crandell Carl C., 1996, AM J AUDIOL, V5, P47, DOI DOI 10.1044/1059-0889.0503.47
   Iverson P, 2012, APPL PSYCHOLINGUIST, V33, P145, DOI 10.1017/S0142716411000300
   Iverson P, 2009, J ACOUST SOC AM, V126, P866, DOI 10.1121/1.3148196
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0
   Marian V, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043230
   Mayo LH, 1997, J SPEECH LANG HEAR R, V40, P686, DOI 10.1044/jslhr.4003.686
   NABELEK AK, 1984, J ACOUST SOC AM, V75, P632
   North B, 2010, EAQUALS CORE INVENTO
   Nye P, 1974, HASKINS LAB STAT REP, V37, P169
   Pinet M, 2011, J ACOUST SOC AM, V130, P1653, DOI 10.1121/1.3613698
   R Core Team, 2013, R LANG ENV STAT COMP
   Rimikis S, 2013, J SPEECH LANG HEAR R, V56, P792, DOI 10.1044/1092-4388(2012/12-0178)
   Shi LF, 2014, INT J AUDIOL, V53, P30, DOI 10.3109/14992027.2013.825052
   Shi LF, 2012, J SPEECH LANG HEAR R, V55, P219, DOI 10.1044/1092-4388(2011/10-0240)
   Shinohara Y, 2013, J ACOUST SOC AM, V133, P3333, DOI [10.1121/1.4800136, DOI 10.1121/1.4800136]
   Smayda KE, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152773
   Stringer L., J SPEECH LANGUAGE HE
   TAKATA Y, 1990, J ACOUST SOC AM, V88, P663, DOI 10.1121/1.399769
   University of Cambridge ESOL Examinations, 2012, VOC LIST PREL ENGL T
   Van Engen KJ, 2014, J SPEECH LANG HEAR R, V57, P1908, DOI 10.1044/JSLHR-H-13-0076
   WILSON M, 1988, BEHAV RES METH INSTR, V20, P6, DOI 10.3758/BF03202594
   Ylinen S, 2010, J COGNITIVE NEUROSCI, V22, P1319, DOI 10.1162/jocn.2009.21272
NR 31
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1554-351X
EI 1554-3528
J9 BEHAV RES METHODS
JI Behav. Res. Methods
PD APR
PY 2020
VL 52
IS 2
BP 561
EP 571
DI 10.3758/s13428-019-01251-z
PG 11
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA LB9NX
UT WOS:000524956600008
PM 31012064
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU McGowan, KB
   Babel, AM
AF McGowan, Kevin B.
   Babel, Anna M.
TI Perceiving isn't believing: Divergence in levels of sociolinguistic
   awareness
SO LANGUAGE IN SOCIETY
LA English
DT Article
ID SUBCATEGORICAL PHONETIC MISMATCHES; SEXUAL ORIENTATION; TIME-COURSE;
   PERCEPTION; SPEECH; INFORMATION; LANGUAGE; IDENTITY
AB The influence of social knowledge on speech perception is a question of interest to a range of disciplines of language research. This study combines experimental and qualitative approaches to investigate whether the various methodological and disciplinary threads of research on this topic are truly investigating the same phenomenon to provide converging evidence in our understanding of social listening. This study investigates listeners' perceptions of Spanish and Quechua speakers speaking Spanish in the context of a contact zone between these two languages and their speakers in central Bolivia. The results of a pair of matched-guise vowel discrimination tasks and subsequent interviews demonstrate that what people perceive, as measured by experimental tasks, is not necessarily what they believe they hear, as reported in narrative responses to interview prompts. Multiple methodological approaches must be employed in order to fully understand the way that we perceive language at diverging levels of sociolinguistic awareness. (Perception, sociophonetics, sociolinguistics, awareness, Andean Spanish)
C1 [McGowan, Kevin B.] Univ Kentucky, 1669 Patterson Off Tower, Lexington, KY 40506 USA.
   Ohio State Univ, Columbus, OH 43210 USA.
RP McGowan, KB (corresponding author), Univ Kentucky, 1669 Patterson Off Tower, Lexington, KY 40506 USA.
EM kbmcgowan@uky.edu
CR Ahmad R, 2011, LANG SOC, V40, P259, DOI 10.1017/S0047404511000182
   Arrizabalaga Carlos, 2006, ACT 1 C INT U NAV PA
   Babel A., 2018, ANDES AMAZON LANGUAG
   Babel A., 2016, AWARENESS CONTROL SO
   Babel AM, 2014, J SOCIOLING, V18, P604, DOI 10.1111/josl.12101
   Babel Anna M., 2010, CONTACT CONTRAST VAL
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Baugh J., 2003, BLACK LINGUISTICS LA, P155
   Beddor PS, 2018, LANGUAGE, V94, P931, DOI 10.1353/lan.2018.0051
   Beddor PS, 2013, J ACOUST SOC AM, V133, P2350, DOI 10.1121/1.4794366
   Beddor Patrice Speeter, 2015, OXFORD HDB LINGUISTI, P503
   Beddor PS, 2002, J PHONETICS, V30, P591, DOI 10.1006/jpho.2002.0177
   Bucholtz M, 2005, DISCOURSE STUD, V7, P585, DOI 10.1177/1461445605054407
   Bucholtz Mary, 2010, WHITE KIDS LANGUAGE
   Calder Jeremy, 2019, J LINGUISTIC ANTHR
   Campbell-Kibler K, 2008, LANG SOC, V37, P637, DOI 10.1017/S0047404508080974
   Campbell-Kibler K, 2011, AM SPEECH, V86, P52, DOI 10.1215/00031283-1277510
   Campbell-Kibler K, 2010, LANG VAR CHANGE, V22, P423, DOI 10.1017/S0954394510000177
   Campbell-Kibler K, 2009, LANG VAR CHANGE, V21, P135, DOI 10.1017/S0954394509000052
   D'Onofrio A, 2018, LANG VAR CHANGE, V30, P261, DOI 10.1017/S095439451800008X
   D'Onofrio A, 2015, J SOCIOLING, V19, P241, DOI 10.1111/josl.12115
   De la Cadena M., 2000, INDIGENOUS MESTIZOS
   Docherty GJ, 2014, LINGUA, V142, P42, DOI 10.1016/j.lingua.2013.01.011
   Drager K, 2009, SOCIOPHONETIC ETHNOG
   Drager K, 2010, LANG LINGUIST COMPAS, V4, P473, DOI 10.1111/j.1749-818x.2010.00210.x
   FRY DB, 1962, LANG SPEECH, V5, P171, DOI 10.1177/002383096200500401
   Gnevsheva K, 2017, INT J BILINGUAL, V21, P213, DOI 10.1177/1367006915616197
   Hall-Lew L, 2010, AM SPEECH, V85, P91, DOI 10.1215/00031283-2010-004
   Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Hillewaert S, 2015, J LINGUIST ANTHROPOL, V25, P195, DOI 10.1111/jola.12079
   Howard R., 2007, LINDEROS LENGUA IDEO
   Irvine JT, 2000, REGIMES LANGUAGE IDE, P35, DOI DOI 10.1017/S0047404502222186
   Jaffe A., 2012, ORTHOGRAPHY SOCIAL A
   Kraljic T, 2008, PSYCHOL SCI, V19, P332, DOI 10.1111/j.1467-9280.2008.02090.x
   Labov W, 2011, J SOCIOLING, V15, P431, DOI 10.1111/j.1467-9841.2011.00504.x
   Labov William, 2006, SOCIAL STRATIFICATIO
   Labov William, 1972, SOCIOLINGUISTIC PATT
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   LAHIRI A, 1991, COGNITION, V38, P245, DOI 10.1016/0010-0277(91)90008-R
   Levon E, 2014, J ENGL LINGUIST, V42, P185, DOI 10.1177/0075424214531487
   Lucy John A., 1993, REFLEXIVE LANGUAGE R, P9
   Mack S, 2012, J PHONETICS, V40, P198, DOI 10.1016/j.wocn.2011.10.002
   MANNHEIM B, 1986, WORD, V37, P45, DOI 10.1080/00437956.1986.11435766
   May Janet, 1976, HASKINS LAB STATUS R, V48, P67
   McGowan KB, 2015, LANG SPEECH, V58, P502, DOI 10.1177/0023830914565191
   Meek BA, 2006, LANG SOC, V35, P93, DOI 10.1017/S0047404506060040
   MENDOZADENTON N, 2008, HOMEGIRLS SYMBOLIC P
   Munson B, 2007, LANG SPEECH, V50, P125, DOI 10.1177/00238309070500010601
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Niedzielski N., 2003, FOLK LINGUISTICS
   Nikolas Coupland, 2004, METALANGUAGE SOCIAL, P15, DOI DOI 10.1515/9783110907377.15
   O'Rourke Erin, 2010, P 4 C LAB APPR SPAN
   Pasquale M, 2009, IMPACT, V25, P245
   PISONI DB, 1975, MEM COGNITION, V3, P7, DOI 10.3758/BF03198202
   Preston Dennis, 1996, LANG AWARE, V5, P40, DOI DOI 10.1080/09658416.1996.9959890
   R Core Team, 2016, R LANG ENV STAT COMP
   Rickford JR, 2016, LANGUAGE, V92, P948, DOI 10.1353/lan.2016.0078
   Rickford John R., 1994, SOCIOLINGUISTIC PERS, P235
   Rosa J, 2017, LANG SOC, V46, P621, DOI 10.1017/S0047404517000562
   Schilling-Estes N, 1998, LANG SOC, V27, P53, DOI 10.1017/S0047404598001031
   Silverstein M., 1979, ELEMENTS PARASESSION, P193
   Silverstein Michael, 1981, SOCIOLINGUISTIC WORK, V84, P1
   Stephenson Marcia, 1999, GENDER MODERNITY AND
   Strand EA, 1996, NATURAL LANGUAGE PROCESSING AND SPEECH TECHNOLOGY, P14
   Sumner M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01015
   WHALEN DH, 1991, PERCEPT PSYCHOPHYS, V50, P351, DOI 10.3758/BF03212227
   WHALEN DH, 1984, PERCEPT PSYCHOPHYS, V35, P49, DOI 10.3758/BF03205924
   Woolard Kathryn A., 1998, LANGUAGE IDEOLOGIES, P3, DOI DOI 10.1017/S0047404501221058
   ZAVALA V, 2011, LINGUIST EDUC, V22, P393, DOI DOI 10.1016/J.LINGED.2011.08.004
NR 70
TC 1
Z9 1
U1 1
U2 2
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0047-4045
EI 1469-8013
J9 LANG SOC
JI Lang. Soc.
PD APR
PY 2020
VL 49
IS 2
BP 231
EP 256
AR PII S0047404519000782
DI 10.1017/S0047404519000782
PG 26
WC Linguistics; Sociology
SC Linguistics; Sociology
GA LD2JE
UT WOS:000525857100003
DA 2021-02-24
ER

PT J
AU Gabay, Y
   Gabay, S
   Schiff, R
   Henik, A
AF Gabay, Yafit
   Gabay, Shai
   Schiff, Rachel
   Henik, Avishai
TI Visual and Auditory Interference Control of Attention in Developmental
   Dyslexia
SO JOURNAL OF THE INTERNATIONAL NEUROPSYCHOLOGICAL SOCIETY
LA English
DT Article
DE Adults; Developmental dyslexia; Inhibition; Interference control;
   Selective attention; Sensory modality; Simon task
ID SELECTIVE ATTENTION; EXECUTIVE FUNCTIONS; SPEECH-PERCEPTION;
   VISUOSPATIAL ATTENTION; COGNITIVE DEFICITS; READING-DISABILITY; LINE
   BISECTION; ADULTS; CATEGORIZATION; CHILDREN
AB An accumulating body of evidence highlights the contribution of general cognitive processes, such as attention, to language-related skills. Objective: The purpose of the present study was to explore how interference control (a subcomponent of selective attention) is affected in developmental dyslexia (DD) by means of control over simple stimulus-response mappings. Furthermore, we aimed to examine interference control in adults with DD across sensory modalities. Methods: The performance of 14 dyslexic adults and 14 matched controls was compared on visual/auditory Simon tasks, in which conflict was presented in terms of an incongruent mapping between the location of a visual/auditory stimulus and the appropriate motor response. Results: In the auditory task, dyslexic participants exhibited larger Simon effect costs; namely, they showed disproportionately larger reaction times (RTs)/errors costs when the auditory stimulus and response were incongruent relative to RT/errors costs of non-impaired readers. In the visual Simon task, both groups presented Simon effect costs to the same extent. Conclusion: These results indicate that the ability to control auditory selective attention is carried out less effectively in those with DD compared with visually controlled processing. The implications of this impaired process for the language-related skills of individuals with DD are discussed.
C1 [Gabay, Yafit] Univ Haifa, Dept Special Educ, IL-31905 Haifa, Israel.
   [Gabay, Yafit] Univ Haifa, Edmond J Safra Brain Res Ctr Study Learning Disab, IL-31905 Haifa, Israel.
   [Gabay, Shai] Univ Haifa, Dept Psychol, IL-31905 Haifa, Israel.
   [Gabay, Shai] Univ Haifa, Inst Informat Proc & Decis Making, IL-31905 Haifa, Israel.
   [Schiff, Rachel] Bar Ilan Univ, Sch Educ, IL-5290002 Ramat Gan, Israel.
   [Schiff, Rachel] Bar Ilan Univ, Haddad Ctr Res Dyslexia & Learning Disabil, IL-5290002 Ramat Gan, Israel.
   [Henik, Avishai] Ben Gurion Univ Negev, Dept Psychol, IL-653 Beer Sheva, Israel.
   [Henik, Avishai] Ben Gurion Univ Negev, Zlotowski Ctr Neurosci, IL-653 Beer Sheva, Israel.
RP Gabay, Y (corresponding author), Univ Haifa, Dept Special Educ, IL-31905 Haifa, Israel.
EM ygabay@edu.haifa.ac.il
OI Gabay, Yafit/0000-0002-7899-3044
CR American Psychiatric Association, 2000, DIAGN STAT MAN MENT, V4th
   [Anonymous], 2005, REPORTS INT ARBITRAL, V27, P35
   [Anonymous], 2008, OFF J EUR UNION, V51, P16
   Astheimer L, 2014, DEV COGN NEUROS-NETH, V7, P1, DOI 10.1016/j.dcn.2013.10.005
   Beidas H, 2013, READ WRIT, V26, P1487, DOI 10.1007/s11145-013-9428-5
   Ben-Artzi E, 2005, NEUROPSYCHOLOGIA, V43, P714, DOI 10.1016/j.neuropsychologia.2004.08.004
   BRADY S, 1983, J EXP CHILD PSYCHOL, V35, P345, DOI 10.1016/0022-0965(83)90087-5
   Brosnan M, 2002, NEUROPSYCHOLOGIA, V40, P2144, DOI 10.1016/S0028-3932(02)00046-5
   Buchholz J, 2008, DYSLEXIA, V14, P247, DOI 10.1002/dys.356
   Castel AD, 2007, NEUROPSYCHOLOGY, V21, P170, DOI 10.1037/0894-4105.21.2.170
   de Jong CGW, 2009, J ABNORM CHILD PSYCH, V37, P1007, DOI 10.1007/s10802-009-9328-y
   Demonet JF, 2004, LANCET, V363, P1451, DOI 10.1016/S0140-6736(04)16106-0
   DENCKLA MB, 1976, NEUROPSYCHOLOGIA, V14, P471, DOI 10.1016/0028-3932(76)90075-0
   Diamond A, 2013, ANNU REV PSYCHOL, V64, P135, DOI 10.1146/annurev-psych-113011-143750
   Dufor O, 2007, NEUROIMAGE, V34, P1692, DOI 10.1016/j.neuroimage.2006.10.034
   Everatt J., 1997, DYSLEXIA, V3, P222, DOI DOI 10.1002/(SICI)1099-0909(199712)3:4<222::AID-DYS12>3.0.CO;2-P
   Faccioli C, 2008, CHILD NEUROPSYCHOL, V14, P277, DOI 10.1080/09297040701290040
   Facoetti A, 2003, COGNITIVE BRAIN RES, V16, P185, DOI 10.1016/S0926-6410(02)00270-7
   Farmer ME, 1995, PSYCHON B REV, V2, P460, DOI 10.3758/BF03210983
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Francis AL, 2002, J EXP PSYCHOL HUMAN, V28, P349, DOI 10.1037//0096-1523.28.2.349
   Gabay Y, 2015, CORTEX, V73, P131, DOI 10.1016/j.cortex.2015.08.008
   Gabay Y, 2015, BRAIN LANG, V150, P143, DOI 10.1016/j.bandl.2015.09.005
   Gabay Y, 2015, NEUROPSYCHOLOGY, V29, P844, DOI 10.1037/neu0000194
   Gabay Y, 2015, J SPEECH LANG HEAR R, V58, P934, DOI 10.1044/2015_JSLHR-L-14-0324
   Gabay Y, 2013, ARCH CLIN NEUROPSYCH, V28, P829, DOI 10.1093/arclin/act076
   Gabay Y, 2012, NEUROPSYCHOLOGIA, V50, P2435, DOI 10.1016/j.neuropsychologia.2012.06.014
   Goldfarb L, 2013, NEUROPSYCHOLOGY, V27, P725, DOI 10.1037/a0034422
   GOLDSTONE R, 1994, J EXP PSYCHOL GEN, V123, P178, DOI 10.1037/0096-3445.123.2.178
   Gomes H, 2007, J CLIN EXP NEUROPSYC, V29, P660, DOI 10.1080/13803390600920455
   Hasker W, 2011, RELIG STUD, V47, P117, DOI 10.1017/S0034412510000582
   Helland T, 2000, CHILD NEUROPSYCHOL, V6, P37, DOI 10.1076/0929-7049(200003)6:1;1-B;FT037
   Holt L. L., 1998, CHICAGO LINGUISTIC S, P253
   Holt LL, 2018, HEARING RES, V366, P50, DOI 10.1016/j.heares.2018.06.014
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   Homack S, 2004, ARCH CLIN NEUROPSYCH, V19, P725, DOI 10.1016/j.acn.2003.09.003
   HOMMEL B, 1994, PSYCHOL RES-PSYCH FO, V56, P179, DOI 10.1007/BF00419705
   International Dyslexia Association, 2002, DEF DYSL
   Lehmann A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085442
   Lehto JE, 2003, BRIT J DEV PSYCHOL, V21, P59, DOI 10.1348/026151003321164627
   LU CH, 1995, PSYCHON B REV, V2, P174, DOI 10.3758/BF03210959
   Milne RD, 2003, NEUROPSYCHOLOGY, V17, P362, DOI 10.1037/0894-4105.17.3.362
   Miyake A, 2000, COGNITIVE PSYCHOL, V41, P49, DOI 10.1006/cogp.1999.0734
   Mullane JC, 2009, CHILD NEUROPSYCHOL, V15, P321, DOI 10.1080/09297040802348028
   Neill W. Trammell, 1995, P207, DOI 10.1016/B978-012208930-5/50008-8
   Nicolson RI, 2019, FRONT BEHAV NEUROSCI, V13, DOI 10.3389/fnbeh.2019.00112
   NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39
   Pennington BF, 2006, COGNITION, V101, P385, DOI 10.1016/j.cognition.2006.04.008
   Protopapas A, 2007, COGNITIVE PSYCHOL, V54, P251, DOI 10.1016/j.cogpsych.2006.07.003
   RATCLIFF R, 1979, PSYCHOL BULL, V86, P446, DOI 10.1037/0033-2909.86.3.446
   Raveh M, 2008, SCI STUD READ, V12, P221, DOI 10.1080/10888430801917068
   Reetzke R, 2016, J EXP CHILD PSYCHOL, V142, P48, DOI 10.1016/j.jecp.2015.09.018
   Reiter A, 2005, DYSLEXIA, V11, P116, DOI 10.1002/dys.289
   Romberg AR, 2010, WIRES COGN SCI, V1, P906, DOI 10.1002/wcs.78
   Schiff R., 2009, NONWORD READIN UNPUB
   Schiff R., 2009, SINGLE WORD RE UNPUB
   Schmid JM, 2011, INT J DISABIL DEV ED, V58, P19, DOI 10.1080/1034912X.2011.547343
   Shany M., 2006, ALEPH TAPH TEST DIAG
   Sireteanu R., 2005, VISION RES, V45, P3075
   Snowling M., 2000, DYSLEXIA
   SNOWLING MJ, 2000, SPEECH LANGUAGE IMPA, P245
   Stein J, 1997, TRENDS NEUROSCI, V20, P147, DOI 10.1016/S0166-2236(96)01005-3
   Stoel-Gammon C, 2011, J CHILD LANG, V38, P1, DOI 10.1017/S0305000910000425
   Toscano JC, 2010, COGNITIVE SCI, V34, P434, DOI 10.1111/j.1551-6709.2009.01077.x
   Valdois S, 2004, DYSLEXIA, V10, P339, DOI 10.1002/dys.284
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   Vidyasagar TR, 2010, TRENDS COGN SCI, V14, P57, DOI 10.1016/j.tics.2009.12.003
   Wang SM, 2015, CHILD NEUROPSYCHOL, V21, P418, DOI 10.1080/09297049.2014.918594
   Wechsler D., 1997, WAIS 3 ADM SCORING M
   Weiss DJ, 2010, LANG COGNITIVE PROC, V25, P402, DOI 10.1080/01690960903212254
   Willcutt EG, 2001, J ABNORM PSYCHOL, V110, P157, DOI 10.1037//0021-843X.1001.1.157
   Yoncheva Y, 2014, NEUROIMAGE, V97, P262, DOI 10.1016/j.neuroimage.2014.04.006
   Ziegler JC, 2009, DEVELOPMENTAL SCI, V12, P732, DOI 10.1111/j.1467-7687.2009.00817.x
NR 73
TC 1
Z9 1
U1 1
U2 8
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 1355-6177
EI 1469-7661
J9 J INT NEUROPSYCH SOC
JI J. Int. Neuropsychol. Soc.
PD APR
PY 2020
VL 26
IS 4
BP 407
EP 417
AR PII S135561771900122X
DI 10.1017/S135561771900122X
PG 11
WC Clinical Neurology; Neurosciences; Psychiatry; Psychology
SC Neurosciences & Neurology; Psychiatry; Psychology
GA LB9JS
UT WOS:000524945600006
PM 32238215
DA 2021-02-24
ER

PT J
AU Stevenage, SV
   Symons, AE
   Fletcher, A
   Coen, C
AF Stevenage, Sarah, V
   Symons, Ashley E.
   Fletcher, Abi
   Coen, Chantelle
TI Sorting through the impact of familiarity when processing vocal
   identity: Results from a voice sorting task
SO QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY
LA English
DT Article
DE Familiarity; vocal identity processing; voice sorting task
ID PERSONALLY KNOWN FACES; LONG-TERM-MEMORY; SPEECH-PERCEPTION; CATEGORICAL
   PERCEPTION; UNIFIED ACCOUNT; RECOGNITION; IDENTIFICATION;
   DISCRIMINATION; CATEGORIZATION; INFORMATION
AB The present article reports on one experiment designed to examine the importance of familiarity when processing vocal identity. A voice sorting task was used with participants who were either personally familiar or unfamiliar with three speakers. The results suggested that familiarity supported both an ability to tell different instances of the same voice together, and to tell similar instances of different voices apart. In addition, the results suggested differences between the three speakers in terms of the extent to which they were confusable, underlining the importance of vocal characteristics and stimulus selection within behavioural tasks. The results are discussed with reference to existing debates regarding the nature of stored representations as familiarity develops, and the difficulty when processing voices over faces more generally.
C1 [Stevenage, Sarah, V; Symons, Ashley E.; Fletcher, Abi; Coen, Chantelle] Univ Southampton, Sch Psychol, Southampton SO17 1BJ, Hants, England.
RP Stevenage, SV (corresponding author), Univ Southampton, Sch Psychol, Southampton SO17 1BJ, Hants, England.
EM svs1@soton.ac.uk
OI Stevenage, Sarah/0000-0003-4155-2939; Symons, Ashley/0000-0001-5980-6752
FU EPSRCUK Research & Innovation (UKRI)Engineering & Physical Sciences
   Research Council (EPSRC) [EP/R030839/1]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by funding from the EPSRC (grant number EP/R030839/1)
   awarded to the first author.
CR Andics A, 2010, NEUROIMAGE, V52, P1528, DOI 10.1016/j.neuroimage.2010.05.048
   Andrews S, 2015, Q J EXP PSYCHOL, V68, P2041, DOI 10.1080/17470218.2014.1003949
   Barsics C, 2011, CONSCIOUS COGN, V20, P303, DOI 10.1016/j.concog.2010.03.008
   Baumann O, 2010, PSYCHOL RES-PSYCH FO, V74, P110, DOI 10.1007/s00426-008-0185-z
   BEALE JM, 1995, COGNITION, V57, P217, DOI 10.1016/0010-0277(95)00669-X
   Belin P, 2003, NEUROREPORT, V14, P2105, DOI 10.1097/00001756-200311140-00019
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Bethmann A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047626
   BORNSTEIN MH, 1987, CATEGORICAL PERCEPTI, P535
   Bredart S, 2009, EUR J COGN PSYCHOL, V21, P1013, DOI 10.1080/09541440802591821
   BRUCE V, 1994, Q J EXP PSYCHOL-A, V47, P5, DOI 10.1080/14640749408401141
   Bulthoff I, 2017, VIS COGN, V25, P611, DOI 10.1080/13506285.2017.1290729
   Burton AM, 2013, Q J EXP PSYCHOL, V66, P1467, DOI 10.1080/17470218.2013.800125
   Burton AM, 2004, PERCEPTION, V33, P747, DOI 10.1068/p3458
   Carbon CC, 2008, PERCEPTION, V37, P801, DOI 10.1068/p5789
   Cook S, 1997, APPL COGNITIVE PSYCH, V11, P95
   Ellis HD, 1997, BRIT J PSYCHOL, V88, P143, DOI 10.1111/j.2044-8295.1997.tb02625.x
   Gainotti G, 2011, NEUROPSYCHOLOGIA, V49, P2273, DOI 10.1016/j.neuropsychologia.2011.04.027
   GOLDSTONE R, 1994, J EXP PSYCHOL GEN, V123, P178, DOI 10.1037/0096-3445.123.2.178
   Hanley JR, 1998, Q J EXP PSYCHOL-A, V51, P179, DOI 10.1080/713755751
   Hargreaves R., 1971, MR TICKLE
   Jenkins R, 2011, COGNITION, V121, P313, DOI 10.1016/j.cognition.2011.08.001
   Johnsrude IS, 2013, PSYCHOL SCI, V24, P1995, DOI 10.1177/0956797613482467
   Kreiman J., 2011, FDN VOICE STUDIES IN
   Kreiman J, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2357
   Kreitewolf J, 2014, NEUROIMAGE, V91, P375, DOI 10.1016/j.neuroimage.2014.01.005
   Kriegstein KV, 2004, NEUROIMAGE, V22, P948, DOI 10.1016/j.neuroimage.2004.02.020
   Latinus M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00175
   Lavan N., 2018, MANY VOICES DID YOU
   Lavan N, 2020, BRIT J PSYCHOL, V111, P556, DOI 10.1111/bjop.12416
   Lavan N, 2019, Q J EXP PSYCHOL, V72, P2240, DOI 10.1177/1747021819836890
   Lavan N, 2019, PSYCHON B REV, V26, P90, DOI 10.3758/s13423-018-1497-7
   Lavan N, 2016, J EXP PSYCHOL GEN, V145, P1604, DOI 10.1037/xge0000223
   Leopold DA, 2001, NAT NEUROSCI, V4, P89, DOI 10.1038/82947
   Levi SV, 2011, J ACOUST SOC AM, V130, P4053, DOI 10.1121/1.3651816
   Lewis MB, 1999, VIS COGN, V6, P1
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   Livingston KR, 1998, J EXP PSYCHOL LEARN, V24, P732, DOI 10.1037/0278-7393.24.3.732
   Megreya AM, 2006, MEM COGNITION, V34, P865, DOI 10.3758/BF03193433
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   PAPCUN G, 1989, J ACOUST SOC AM, V85, P913, DOI 10.1121/1.397564
   Pinheiro AP, 2016, BRAIN LANG, V153, P38, DOI 10.1016/j.bandl.2015.12.003
   Gonzalez IQ, 2011, BRAIN RES, V1407, P13, DOI 10.1016/j.brainres.2011.03.029
   Ramon M, 2011, PERCEPTION, V40, P437, DOI 10.1068/p6794
   READ D, 1995, J EXP PSYCHOL-APPL, V1, P6, DOI 10.1037/1076-898X.1.1.6
   Redfern AS, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517731115
   SASLOVE H, 1980, J APPL PSYCHOL, V65, P111, DOI 10.1037/0021-9010.65.1.111
   Schweinberger SR, 2001, NEUROPSYCHOLOGIA, V39, P921, DOI 10.1016/S0028-3932(01)00023-9
   Schweinberger SR, 1997, Q J EXP PSYCHOL-A, V50, P498, DOI 10.1080/027249897391991
   Schweinberger SR, 2007, Q J EXP PSYCHOL, V60, P1446, DOI 10.1080/17470210601063589
   Schweinberger SR, 2014, WIRES COGN SCI, V5, P15, DOI 10.1002/wcs.1261
   Schyns PG, 1997, J EXP PSYCHOL LEARN, V23, P681, DOI 10.1037/0278-7393.23.3.681
   Souza P, 2013, J AM ACAD AUDIOL, V24, P689, DOI 10.3766/jaaa.24.8.6
   Stevenage SV, 2018, NEUROPSYCHOLOGIA, V116, P162, DOI 10.1016/j.neuropsychologia.2017.07.005
   Stevenage SV, 2013, PSYCHOL RES-PSYCH FO, V77, P167, DOI 10.1007/s00426-012-0450-z
   Stevenage SV, 2012, J COGN PSYCHOL, V24, P647, DOI 10.1080/20445911.2012.675321
   Stevenage SV, 2012, J COGN PSYCHOL, V24, P409, DOI 10.1080/20445911.2011.642859
   Stevenage SV, 1998, BRIT J PSYCHOL, V89, P39, DOI 10.1111/j.2044-8295.1998.tb02672.x
   Tong F, 1999, J EXP PSYCHOL HUMAN, V25, P1016, DOI 10.1037/0096-1523.25.4.1016
   VALENTINE T, 1991, Q J EXP PSYCHOL-A, V43, P161, DOI 10.1080/14640749108400966
   VANLANCKER D, 1987, NEUROPSYCHOLOGIA, V25, P829, DOI 10.1016/0028-3932(87)90120-5
   von Kriegstein K, 2003, COGNITIVE BRAIN RES, V17, P48, DOI 10.1016/S0926-6410(03)00079-X
   Warren JD, 2006, NEUROIMAGE, V31, P1389, DOI 10.1016/j.neuroimage.2006.01.034
   Wiese H, 2019, PSYCHOL SCI, V30, P261, DOI 10.1177/0956797618813572
   YARMEY AD, 1992, APPL COGNITIVE PSYCH, V6, P367, DOI 10.1002/acp.2350060502
   Young AW, 2017, CURR DIR PSYCHOL SCI, V26, P212, DOI 10.1177/0963721416688114
   Zhou XM, 2016, PERCEPTION, V45, P1426, DOI 10.1177/0301006616662046
NR 67
TC 3
Z9 3
U1 2
U2 3
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1747-0218
EI 1747-0226
J9 Q J EXP PSYCHOL
JI Q. J. Exp. Psychol.
PD APR
PY 2020
VL 73
IS 4
BP 519
EP 536
DI 10.1177/1747021819888064
PG 18
WC Psychology, Biological; Physiology; Psychology; Psychology, Experimental
SC Psychology; Physiology
GA LB2ZW
UT WOS:000524508100004
PM 31658884
OA Other Gold, Green Accepted, Green Published
DA 2021-02-24
ER

PT J
AU Leung, KKW
   Wang, Y
AF Leung, Keith K. W.
   Wang, Yue
TI Production-perception relationship of Mandarin tones as revealed by
   critical perceptual cues
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH-PERCEPTION
AB The relationship of lexical tone production and perception has not been well studied. Using Mandarin tone, this research tests the hypothesis that a production-perception link is revealed by critical perceptual cues. The critical status of perceptual tonal cues was determined by perceptual cue weights, showing fundamental frequency (F0) contour as being more critical than height. Then, tone production features were examined for critical F0 contour (slope, curvature, turning-point location) and non-critical F0 height (mean, onset) cues. A production-perception correlation was found for F0 contour but not height cues, suggesting that critical perceptual cues dictate the relationship between production and perception.
C1 [Leung, Keith K. W.; Wang, Yue] Simon Fraser Univ, Dept Linguist, Language & Brain Lab, 8888 Univ Dr, Burnaby, BC V5A 1S6, Canada.
RP Leung, KKW (corresponding author), Simon Fraser Univ, Dept Linguist, Language & Brain Lab, 8888 Univ Dr, Burnaby, BC V5A 1S6, Canada.
EM kwl23@sfu.ca; yuew@sfu.ca
FU NSERC of CanadaNatural Sciences and Engineering Research Council of
   Canada (NSERC) [2017-05978]
FX We thank the attendees of the 176th ASA Meeting and 2018 Acoustics Week
   of CAA in Victoria, Canada for their valuable feedback, SFU Language and
   Brain Lab members Anisa Dhanji, Joanna Xie, and Dahai Zhang for their
   assistance. This project was supported by a Discovery Grant from NSERC
   of Canada (Grant No. 2017-05978).
CR [Anonymous], 1982, AN U MURCIA, VXXXIX, P1, DOI DOI 10.1159/000261647
   Beddor P. S., 2015, P 18 INT C PHON SCI, p[1041, 1]
   Boersma P., 2018, PRAAT DOING PHONETIC
   Chang D, 2016, J ACOUST SOC AM, V139, P2432, DOI 10.1121/1.4947497
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Francis AL, 2008, J PHONETICS, V36, P268, DOI 10.1016/j.wocn.2007.06.005
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   Guion S. G., 2007, LANGUAGE EXPERIENCE, P57, DOI [DOI 10.1075/LLLT.17.09GUI, 10.1075/lllt.17.09gui]
   JOHNSON K, 1993, LANGUAGE, V69, P505, DOI 10.2307/416697
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   Jongman A, 2017, J ACOUST SOC AM, V142, pEL163, DOI 10.1121/1.4995526
   MASSARO DW, 1985, J CHINESE LINGUIST, V13, P267
   Moore CB, 1997, J ACOUST SOC AM, V102, P1864, DOI 10.1121/1.420092
   Newman RS, 2003, J ACOUST SOC AM, V113, P2850, DOI 10.1121/1.1567280
   SHEN XNS, 1993, J ACOUST SOC AM, V93, P2241, DOI 10.1121/1.406688
   Shih C, 2015, J PHONETICS, V51, P6, DOI 10.1016/j.wocn.2015.02.002
   Shultz AA, 2012, J ACOUST SOC AM, V132, pEL95, DOI 10.1121/1.4736711
   Tupper P., 2018, J ACOUST SOC AM, V144, P1725, DOI [10.1121/1.5067655, DOI 10.1121/1.5067655]
   Wang Y, 2003, J ACOUST SOC AM, V113, P1033, DOI 10.1121/1.1531176
NR 20
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD APR
PY 2020
VL 147
IS 4
BP EL301
EP EL306
DI 10.1121/10.0000963
PG 6
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA LA8VS
UT WOS:000524220200001
PM 32359262
OA Bronze
DA 2021-02-24
ER

PT J
AU der Nederlanden, CMV
   Zaragoza, C
   Rubio-Garcia, A
   Clarkson, E
   Snyder, JS
AF der Nederlanden, Christina M. Vanden Bosch
   Zaragoza, Che'Renee
   Rubio-Garcia, Angie
   Clarkson, Evan
   Snyder, Joel S.
TI Change detection in complex auditory scenes is predicted by auditory
   memory, pitch perception, and years of musical training
SO PSYCHOLOGICAL RESEARCH-PSYCHOLOGISCHE FORSCHUNG
LA English
DT Article
ID CHANGE DEAFNESS; SPEECH-PERCEPTION; ATTENTIONAL BIAS; ENHANCED MEMORY;
   VOCAL MELODIES; MUSICIANS; EXPERTISE; SOUND; ASSOCIATION; EXPERIENCE
AB Our world is a sonically busy place and we use both acoustic information and experience-based knowledge to make sense of the sounds arriving at our ears. The knowledge we gain through experience has the potential to shape what sounds are prioritized in a complex scene. There are many examples of how visual expertise influences how we perceive objects in visual scenes, but few studies examine how auditory expertise is associated with attentional biases toward familiar real-world sounds in complex scenes. In the current study, we investigated whether musical expertise is associated with the ability to detect changes to real-world sounds in complex auditory scenes, and whether any such benefit is specific to musical instrument sounds. We also examined whether change detection is better for human-generated sounds in general or only communicative human sounds. We found that musicians had less change deafness overall. All listeners were better at detecting human communicative sounds compared to human non-communicative sounds, but this benefit was driven by speech sounds and sounds that were vocally generated. Musical listening skill, speech-in-noise, and executive function abilities were used to predict rates of change deafness. Auditory memory, musical training, fine-grained pitch processing, and an interaction between training and pitch processing accounted for 45.8% of the variance in change deafness. To better understand perceptual and cognitive expertise, it may be more important to measure various auditory skills and relate them to each other, as opposed to comparing experts to non-experts.
C1 [der Nederlanden, Christina M. Vanden Bosch; Zaragoza, Che'Renee; Rubio-Garcia, Angie; Clarkson, Evan; Snyder, Joel S.] Univ Nevada, Dept Psychol, Las Vegas, NV 89154 USA.
   [der Nederlanden, Christina M. Vanden Bosch] Western Univ, Brain & Mind Inst, 1151 Richmond St, London, ON N6A 3K7, Canada.
RP der Nederlanden, CMV (corresponding author), Univ Nevada, Dept Psychol, Las Vegas, NV 89154 USA.; der Nederlanden, CMV (corresponding author), Western Univ, Brain & Mind Inst, 1151 Richmond St, London, ON N6A 3K7, Canada.
EM cdernede@uwo.ca; joel.snyder@unlv.edu
FU Army Research Office [W911NF-12-1-0256]; Barrick Graduate Fellowship
   from the University of Nevada Las Vegas
FX This research is supported by a grant awarded to J.S.S. from the Army
   Research Office, award number W911NF-12-1-0256 and the Barrick Graduate
   Fellowship awarded to C.M.V.B.d.N from the University of Nevada Las
   Vegas.
CR Agres K., 2008, 30 ANN C COGN SCI SO
   Alain C, 2000, FRONT BIOSCI-LANDMRK, V5, pD202, DOI 10.2741/Alain
   Bialystok E, 2009, J EXP PSYCHOL HUMAN, V35, P565, DOI 10.1037/a0012735
   Bidelman GM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0060676
   BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32
   Bishop L, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01123
   Boebinger D, 2015, J ACOUST SOC AM, V137, P378, DOI 10.1121/1.4904537
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   Carey D, 2015, COGNITION, V137, P81, DOI 10.1016/j.cognition.2014.12.005
   Chartrand JP, 2008, BRAIN RES, V1220, P191, DOI 10.1016/j.brainres.2008.01.014
   Chartrand JP, 2007, NEUROREPORT, V18, P335, DOI 10.1097/WNR.0b013e328013cea9
   Cohen MA, 2011, PSYCHON B REV, V18, P586, DOI 10.3758/s13423-011-0074-0
   Corrigall KA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00222
   Corrigall KA, 2011, MUSIC PERCEPT, V29, P147, DOI 10.1525/MP.2011.29.2.147
   Cousineau D, 2005, TUTOR QUANT METHODS, V1, P42, DOI 10.20982/tqmp.01.1.p042
   Darlington R. B., 1990, REGRESSION LINEAR MO
   De Meo R, 2016, CURR BIOL, V26, pR519, DOI 10.1016/j.cub.2016.05.024
   Demany L, 2008, PSYCHOL SCI, V19, P85, DOI 10.1111/j.1467-9280.2008.02050.x
   der Nederlanden CMVB, 2016, DEV PSYCHOL, V52, P1867, DOI 10.1037/dev0000211
   Dickerson K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01125
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Eramudugolla R, 2005, CURR BIOL, V15, P1108, DOI 10.1016/j.cub.2005.05.051
   Fenn KM, 2011, Q J EXP PSYCHOL, V64, P1442, DOI 10.1080/17470218.2011.570353
   Flaugnacco E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138715
   Forgeard M, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003566
   Gaser C, 2003, ANN NY ACAD SCI, V999, P514, DOI 10.1196/annals.1284.062
   Gaser C, 2003, J NEUROSCI, V23, P9240
   Grahn JA, 2009, J NEUROSCI, V29, P7540, DOI 10.1523/JNEUROSCI.2018-08.2009
   Gregg MK, 2008, J EXP PSYCHOL HUMAN, V34, P974, DOI 10.1037/0096-1523.34.4.974
   Gregg MK, 2017, ATTEN PERCEPT PSYCHO, V79, P2564, DOI 10.3758/s13414-017-1416-4
   Gregg MK, 2014, NEUROPSYCHOLOGIA, V61, P19, DOI 10.1016/j.neuropsychologia.2014.06.007
   Gregg MK, 2009, ATTEN PERCEPT PSYCHO, V71, P607, DOI 10.3758/APP.71.3.607
   Hayes AF, 2015, MULTIVAR BEHAV RES, V50, P1, DOI 10.1080/00273171.2014.962683
   Irsik VC, 2016, J EXP PSYCHOL HUMAN, V42, P1806, DOI 10.1037/xhp0000266
   Jakobson LS, 2003, MUSIC PERCEPT, V20, P307, DOI 10.1525/mp.2003.20.3.307
   Jones BT, 2006, PSYCHOL ADDICT BEHAV, V20, P171, DOI 10.1037/0893-164X.20.2.171
   Kikuchi Y, 2009, CHILD DEV, V80, P1421, DOI 10.1111/j.1467-8624.2009.01342.x
   Krishnan S, 2013, HEARING RES, V300, P46, DOI 10.1016/j.heares.2013.03.003
   LaPointe MRP, 2016, CAN J EXP PSYCHOL, V70, P219, DOI 10.1037/cep0000077
   Law LNC, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0052508
   Loui P, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00111
   Madsen SMK, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12937-9
   Magne C, 2006, J COGNITIVE NEUROSCI, V18, P199, DOI 10.1162/089892906775783660
   Marie C, 2012, PSYCHOMUSICOLOGY, V22, P97, DOI DOI 10.1037/A0030858
   Micheyl C, 2006, HEARING RES, V219, P36, DOI 10.1016/j.heares.2006.05.004
   Neuhoff JG, 2018, Q J EXP PSYCHOL, V71, P1100, DOI 10.1080/17470218.2017.1310266
   Neuhoff JG, 2014, PERCEPTION, V43, P219, DOI 10.1068/p7665
   New J, 2007, P NATL ACAD SCI USA, V104, P16598, DOI 10.1073/pnas.0703913104
   Oxenham AJ, 2003, J ACOUST SOC AM, V114, P1543, DOI 10.1121/1.1598197
   Pantev C, 2001, NEUROREPORT, V12, P169, DOI 10.1097/00001756-200101220-00041
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Pasinski AC, 2016, PSYCHON B REV, V23, P1553, DOI 10.3758/s13423-015-0998-x
   Ruggles DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086980
   Schellenberg EG, 2015, ANN NY ACAD SCI, V1337, P170, DOI 10.1111/nyas.12627
   Schellenberg EG, 2011, BRIT J PSYCHOL, V102, P283, DOI 10.1111/j.2044-8295.2010.02000.x
   Schon D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Shahin A, 2004, NEUROREPORT, V15, P1917, DOI 10.1097/00001756-200408260-00017
   Shen JH, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00857
   Sherwin JS, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0115629
   Shinn-Cunningham BG, 2008, TRENDS COGN SCI, V12, P182, DOI 10.1016/j.tics.2008.02.003
   Shultz S, 2014, DEVELOPMENTAL SCI, V17, P766, DOI 10.1111/desc.12151
   Shultz S, 2010, LANG LEARN DEV, V6, P241, DOI 10.1080/15475440903507830
   Simons DJ, 2000, VIS COGN, V7, P1, DOI 10.1080/135062800394658
   Slevc LR, 2016, COGNITION, V152, P199, DOI 10.1016/j.cognition.2016.03.017
   Snyder JS, 2017, ANN NY ACAD SCI, V1396, P39, DOI 10.1111/nyas.13317
   Snyder JS, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00015
   Snyder JS, 2011, ATTEN PERCEPT PSYCHO, V73, P1993, DOI 10.3758/s13414-011-0189-4
   Swaminathan J, 2015, SCI REP-UK, V5, DOI 10.1038/srep11628
   Swaminathan S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27571-2
   Swaminathan S, 2018, J EXP PSYCHOL LEARN, V44, P992, DOI 10.1037/xlm0000493
   Weiss MW, 2015, Q J EXP PSYCHOL, V68, P866, DOI 10.1080/17470218.2015.1020818
   Weiss MW, 2015, DEV PSYCHOL, V51, P370, DOI 10.1037/a0038784
   Weiss MW, 2012, PSYCHOL SCI, V23, P1074, DOI 10.1177/0956797612442552
   Werner S, 2000, VIS COGN, V7, P163, DOI 10.1080/135062800394748
   Whisman MA, 2005, J FAM PSYCHOL, V19, P111, DOI 10.1037/0893-3200.19.1.111
   Wilson RH, 2012, J AM ACAD AUDIOL, V23, P590, DOI 10.3766/jaaa.23.7.9
   Zendel BR, 2014, NEUROBIOL AGING, V35, P55, DOI 10.1016/j.neurobiolaging.2013.06.022
   Zendel BR, 2012, PSYCHOL AGING, V27, P410, DOI 10.1037/a0024816
   Zendel BR, 2009, J COGNITIVE NEUROSCI, V21, P1488, DOI 10.1162/jocn.2009.21140
   Zentner M, 2017, ANN NY ACAD SCI, V1400, P33, DOI 10.1111/nyas.13410
NR 80
TC 1
Z9 1
U1 3
U2 13
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 0340-0727
EI 1430-2772
J9 PSYCHOL RES-PSYCH FO
JI Psychol. Res.-Psychol. Forsch.
PD APR
PY 2020
VL 84
IS 3
BP 585
EP 601
DI 10.1007/s00426-018-1072-x
PG 17
WC Psychology, Experimental
SC Psychology
GA KY5WS
UT WOS:000522644500004
PM 30120544
DA 2021-02-24
ER

PT J
AU Noe, C
   Fischer-Baum, S
AF Noe, Colin
   Fischer-Baum, Simon
TI Early lexical influences on sublexical processing in speech perception:
   Evidence from electrophysiology
SO COGNITION
LA English
DT Article
DE Speech perception; N100 ERP; Ganong effect; TRACE; Feedback
ID GRANGER CAUSALITY ANALYSIS; PHONETIC CATEGORIZATION; PHONEMIC
   RESTORATION; CATEGORICAL PERCEPTION; SENTENCE CONTEXT; AUDITORY-CORTEX;
   TRACE MODEL; INFORMATION; FEEDBACK; ERP
AB Contextual information influences how we perceive speech, but it remains unclear at which level of processing contextual information merges with acoustic information. Theories differ on whether early stages of speech processing, like sublexical processing during which articulatory features and portions of speech sounds are identified, are strictly feed-forward or are influenced by semantic and lexical context. In the current study, we investigate the time-course of lexical context effects on judgments about the individual sounds we perceive by recording electroencephalography as an online measure of speech processing while subjects engage in a lexically biasing phoneme categorization task. We find that lexical context modulates the amplitude of the N100, an ERP component linked with sublexical processes in speech perception. We demonstrate that these results can be modeled in an interactive speech perception model and are not well fit by any established feed-forward mechanisms of lexical bias. These results support interactive speech perception theories over feed-forward theories in which sublexical speech perception processes are only driven by bottom-up information.
C1 [Noe, Colin; Fischer-Baum, Simon] Rice Univ, Dept Psychol Sci, Houston, TX USA.
RP Noe, C (corresponding author), BRC Suite 780R,6500 S Main St, Houston, TX 77030 USA.
EM cmn2@rice.edu
FU National Science FoundationNational Science Foundation (NSF) [1250104,
   1752751]
FX This project was supported by the National Science Foundation under
   grant no. 1250104 to C.N. and grant no. 1752751 to S.F-B. Jake Johnston,
   Georgia Jenkins, Ruthie Seleznick, Serena Brandler, and Talia Liu
   assisted in stimulus preparation and data collection. We would like to
   thank James Magnuson for his help in developing the TRACE simulations.
   We would also like to thank Bob McMurray and Joe Toscano for help with
   stimulus splicing techniques and study conceptualization.
CR ANDRUSKI JE, 1994, COGNITION, V52, P163, DOI 10.1016/0010-0277(94)90042-6
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   BURTON MW, 1995, J EXP PSYCHOL HUMAN, V21, P1230, DOI 10.1037/0096-1523.21.5.1230
   BURTON MW, 1989, J EXP PSYCHOL HUMAN, V15, P567, DOI 10.1037/0096-1523.15.3.567
   Cairns P, 1997, COGNITIVE PSYCHOL, V33, P111, DOI 10.1006/cogp.1997.0649
   Cairns P., 1995, CONNECTIONIST MODELS, P289
   CHATER N, 1990, COGNITION, V34, P93, DOI 10.1016/0010-0277(90)90033-G
   Cibelli ES, 2015, BRAIN LANG, V147, P66, DOI 10.1016/j.bandl.2015.05.005
   CONNINE CM, 1987, PHONETICA, V44, P133, DOI 10.1159/000261790
   CONNINE CM, 1987, J EXP PSYCHOL HUMAN, V13, P291, DOI 10.1037/0096-1523.13.2.291
   Cousineau D, 2005, TUTOR QUANT METHODS, V1, P42, DOI 10.20982/tqmp.01.1.p042
   Davis C, 2008, BRAIN RES, V1242, P151, DOI 10.1016/j.brainres.2008.04.077
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   ELMAN JL, 1988, J MEM LANG, V27, P143, DOI 10.1016/0749-596X(88)90071-X
   Fox NP, 2016, J EXP PSYCHOL HUMAN, V42, P730, DOI 10.1037/a0039965
   FOX RA, 1984, J EXP PSYCHOL HUMAN, V10, P526, DOI 10.1037/0096-1523.10.4.526
   Frauenfelder U. H., 1998, SIMULATING TIME COUR
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Getz L., 2019, PSYCHOL SCI
   Gow DW, 2015, J MEM LANG, V82, P41, DOI 10.1016/j.jml.2015.03.004
   Gow DW, 2008, NEUROIMAGE, V43, P614, DOI 10.1016/j.neuroimage.2008.07.027
   Groppe DM, 2010, BRAIN RES, V1361, P54, DOI 10.1016/j.brainres.2010.09.003
   Hannagan T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00563
   Hirshorn EA, 2016, P NATL ACAD SCI USA, V113, P8162, DOI 10.1073/pnas.1604126113
   Hoonhorst I, 2009, CLIN NEUROPHYSIOL, V120, P897, DOI 10.1016/j.clinph.2009.02.174
   Horev N, 2007, EAR HEARING, V28, P111, DOI 10.1097/01.aud.0000250021.69163.96
   Hornickel J, 2009, AUDIOL NEURO-OTOL, V14, P198, DOI 10.1159/000188533
   Hullett PW, 2016, J NEUROSCI, V36, P2014, DOI 10.1523/JNEUROSCI.1779-15.2016
   Hutchison ER, 2008, NEUROIMAGE, V40, P342, DOI 10.1016/j.neuroimage.2007.10.064
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Kingston J, 2016, J EXP PSYCHOL HUMAN, V42, P1969, DOI 10.1037/xhp0000269
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   Leonard MK, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13619
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1
   Luck SJ, 2017, PSYCHOPHYSIOLOGY, V54, P146, DOI 10.1111/psyp.12639
   Magnuson JS, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00369
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   Martin BA, 1999, EAR HEARING, V20, P33, DOI 10.1097/00003446-199902000-00004
   McClelland JL, 2006, TRENDS COGN SCI, V10, P363, DOI 10.1016/j.tics.2006.06.007
   McClelland JL, 2014, COGNITIVE SCI, V38, P1139, DOI 10.1111/cogs.12146
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   MCQUEEN JM, 1991, J EXP PSYCHOL HUMAN, V17, P433, DOI 10.1037/0096-1523.17.2.433
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Myers EB, 2008, CEREB CORTEX, V18, P278, DOI 10.1093/cercor/bhm053
   Newman RS, 1997, J EXP PSYCHOL HUMAN, V23, P873, DOI 10.1037/0096-1523.23.3.873
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Norris D, 2016, LANG COGN NEUROSCI, V31, P4, DOI 10.1080/23273798.2015.1081703
   Obleser J, 2004, PSYCHOPHYSIOLOGY, V41, P783, DOI 10.1111/j.1469-8986.2004.00204.x
   Obleser J, 2004, J COGNITIVE NEUROSCI, V16, P31, DOI 10.1162/089892904322755539
   Obleser J, 2003, NEUROIMAGE, V20, P1839, DOI 10.1016/j.neuroimage.2003.07.019
   ODEN GC, 1978, PSYCHOL REV, V85, P172, DOI 10.1037/0033-295X.85.3.172
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   PITT MA, 1993, J EXP PSYCHOL HUMAN, V19, P699, DOI 10.1037/0096-1523.19.4.699
   PITT MA, 1995, J EXP PSYCHOL LEARN, V21, P1037, DOI 10.1037/0278-7393.21.4.1037
   PITT MA, 1995, COGNITIVE PSYCHOL, V29, P149, DOI 10.1006/cogp.1995.1014
   Pylyshyn Z. W., 1984, COMPUTATION COGNITIO, P41
   Rabovsky M, 2018, NAT HUM BEHAV, V2, P693, DOI 10.1038/s41562-018-0406-4
   Rumelhart D. E., 1976, INTERACTIVE MODEL RE
   SAMUEL AG, 1981, J EXP PSYCHOL GEN, V110, P474, DOI 10.1037/0096-3445.110.4.474
   Sanders LD, 2003, COGNITIVE BRAIN RES, V15, P228, DOI 10.1016/S0926-6410(02)00195-7
   Schreiber K. E., 2017, THESIS
   Sharma A, 1999, J ACOUST SOC AM, V106, P1078, DOI 10.1121/1.428048
   Sidaras SK, 2009, J ACOUST SOC AM, V125, P3306, DOI 10.1121/1.3101452
   Sivonen P, 2006, BRAIN RES, V1121, P177, DOI 10.1016/j.brainres.2006.08.123
   STEINSCHNEIDER M, 1995, BRAIN LANG, V48, P326, DOI 10.1006/brln.1995.1015
   Steinschneider M, 2013, HEARING RES, V305, P57, DOI 10.1016/j.heares.2013.05.013
   Strauss T. J., 2006, J ACOUST SOC AM, V119, P3245
   Strauss TJ, 2007, BEHAV RES METHODS, V39, P19, DOI 10.3758/BF03192840
   Toscano J. C., 2010, CONTINUOUS PERCEPTIO
   Trebuchon-Da Fonseca A, 2005, NEUROIMAGE, V27, P1, DOI 10.1016/j.neuroimage.2004.12.064
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Yi HG, 2019, NEURON, V102, P1096, DOI 10.1016/j.neuron.2019.04.023
   Zaehle T, 2007, BEHAV BRAIN FUNCT, V3, DOI 10.1186/1744-9081-3-63
NR 81
TC 1
Z9 1
U1 5
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD APR
PY 2020
VL 197
AR 104162
DI 10.1016/j.cognition.2019.104162
PG 14
WC Psychology, Experimental
SC Psychology
GA KQ4HS
UT WOS:000516886300008
PM 31901875
DA 2021-02-24
ER

PT J
AU Ogane, R
   Schwartz, JL
   Ito, T
AF Ogane, Rintaro
   Schwartz, Jean-Luc
   Ito, Takayuki
TI Orofacial somatosensory inputs modulate word segmentation in lexical
   decision
SO COGNITION
LA English
DT Article
DE Lexical access; Articulatory knowledge; Speech perception; Speech
   production; Perceptuo-motor interaction; Multisensory interactions
ID PERCEPTUAL ORGANIZATION; HEARING LIPS; SPEECH; INTEGRATION; FRENCH;
   RECOGNITION; INFORMATION; CORTEX
AB There is accumulating evidence that articulatory/motor knowledge plays a role in phonetic processing, such as the recent finding that orofacial somatosensory inputs may influence phoneme categorization. We here show that somatosensory inputs also contribute at a higher level of the speech perception chain, that is, in the context of word segmentation and lexical decision. We carried out an auditory identification test using a set of French phrases consisting of a definite article "la" followed by a noun, which may be segmented differently according to the placement of accents within the phrase. Somatosensory stimulation was applied to the facial skin at various positions within the acoustic utterances corresponding to these phrases, which had been recorded with neutral accent, that is, with all syllables given similar emphasis. We found that lexical decisions reflecting word segmentation were significantly and systematically biased depending on the timing of somatosensory stimulation. This bias was not induced when somatosensory stimulation was applied to the skin other than on the face. These results provide evidence that the orofacial somatosensory system contributes to lexical perception in situations that would be disambiguated by different articulatory movements, and suggests that articulatory/motor knowledge might be involved in speech segmentation.
C1 [Ogane, Rintaro; Schwartz, Jean-Luc; Ito, Takayuki] Univ Grenoble Alpes, GIPSA Lab, Grenoble INP, CNRS, F-38000 Grenoble, France.
   [Ito, Takayuki] Haskins Labs Inc, 300 George St, New Haven, CT 06511 USA.
RP Ogane, R (corresponding author), Univ Grenoble Alpes, GIPSA Lab, Grenoble INP, CNRS, 11 Rue Math,Grenoble Campus,BP46, F-38402 St Martin Dheres, France.
EM rintaro.ogane@gipsa-lab.grenoble-inp.fr
OI Ito, Takayuki/0000-0002-3265-360X
FU European Research Council under the European Community's Seventh
   Framework Program (FP7/2007-2013 Grant) [339152]; National Institute on
   Deafness and Other Communication DisordersUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01-DC017439];  [ANR-15-IDEX-02]
FX This work was supported by the European Research Council under the
   European Community's Seventh Framework Program (FP7/2007-2013 Grant
   Agreement no. 339152). This work was supported by grant ANR-15-IDEX-02
   CDP NeuroCoG, and National Institute on Deafness and Other Communication
   Disorders Grant R01-DC017439.
CR Aboitiz F, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00174
   Adank P, 2010, PSYCHOL SCI, V21, P1903, DOI 10.1177/0956797610389192
   Basirat A, 2012, PHILOS T R SOC B, V367, P965, DOI 10.1098/rstb.2011.0374
   Borrie SA, 2015, J SPEECH LANG HEAR R, V58, P1708, DOI 10.1044/2015_JSLHR-S-15-0163
   Connor NP, 1998, EXP BRAIN RES, V123, P235, DOI 10.1007/s002210050565
   D'Ausilio A, 2011, NEUROPSYCHOLOGIA, V49, P3670, DOI 10.1016/j.neuropsychologia.2011.09.022
   Dohen M, 2004, SPEECH COMMUN, V44, P155, DOI 10.1016/j.specom.2004.10.009
   ERBER NP, 1969, J SPEECH HEAR RES, V12, P423, DOI 10.1044/jshr.1202.423
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Fort M, 2013, LANG COGNITIVE PROC, V28, P1207, DOI 10.1080/01690965.2012.701758
   Fougeron C, 2001, J PHONETICS, V29, P109, DOI 10.1006/jpho.2000.0114
   Gick B, 2009, NATURE, V462, P502, DOI 10.1038/nature08572
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Grabski K, 2013, J NEUROLINGUIST, V26, P384, DOI 10.1016/j.jneuroling.2012.11.003
   Hothorn T, 2008, BIOMETRICAL J, V50, P346, DOI 10.1002/bimj.200810425
   Ito T, 2007, NEUROREPORT, V18, P907, DOI 10.1097/WNR.0b013e32810f2dfb
   Ito T, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01198
   Ito T, 2013, J SPEECH LANG HEAR R, V56, pS1875, DOI 10.1044/1092-4388(2013/12-0226)
   Ito T, 2012, J NEUROPHYSIOL, V107, P442, DOI 10.1152/jn.00029.2011
   Ito T, 2010, J NEUROPHYSIOL, V104, P1230, DOI 10.1152/jn.00199.2010
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   JOHANSSON RS, 1988, EXP BRAIN RES, V72, P209, DOI 10.1007/BF00248519
   Kroliczak G, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00930
   Lametti DR, 2014, J NEUROSCI, V34, P10339, DOI 10.1523/JNEUROSCI.0108-14.2014
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mitchel AD, 2014, LANG COGN NEUROSCI, V29, P771, DOI 10.1080/01690965.2013.791703
   Mottonen R, 2005, NEUROIMAGE, V24, P731, DOI 10.1016/j.neuroimage.2004.10.011
   Munhall KG, 1996, PERCEPT PSYCHOPHYS, V58, P351, DOI 10.3758/BF03206811
   Noiray A, 2011, J ACOUST SOC AM, V129, P340, DOI 10.1121/1.3518452
   NORDIN M, 1989, ACTA PHYSIOL SCAND, V135, P149, DOI 10.1111/j.1748-1716.1989.tb08562.x
   Ogane R., 2019, P INT C PHON SCI ICP
   Pinheiro J, 2019, NLME LINEAR NONLINEA
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   R Core Team, 2019, R LANG ENV STAT COMP
   REMEZ RE, 1994, PSYCHOL REV, V101, P129, DOI 10.1037/0033-295X.101.1.129
   Sato M, 2011, CORTEX, V47, P1001, DOI 10.1016/j.cortex.2011.03.009
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   Sell AJ, 2009, MEM COGNITION, V37, P889, DOI 10.3758/MC.37.6.889
   Shiller DM, 2009, J ACOUST SOC AM, V125, P1103, DOI 10.1121/1.3058638
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Spinelli E, 2007, LANG COGNITIVE PROC, V22, P828, DOI 10.1080/01690960601076472
   Spinelli E, 2010, ATTEN PERCEPT PSYCHO, V72, P775, DOI 10.3758/APP.72.3.775
   STAL P, 1990, ARCH ORAL BIOL, V35, P449, DOI 10.1016/0003-9969(90)90208-R
   Stokes RC, 2019, PSYCHON B REV, V26, P1354, DOI 10.3758/s13423-019-01580-2
   Strau<ss> A., 2015, FAAVSP 2015
   Strauss A, 2017, LANG COGN NEUROSCI, V32, P562, DOI 10.1080/23273798.2016.1253852
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Tremblay P, 2011, NEUROIMAGE, V57, P1561, DOI 10.1016/j.neuroimage.2011.05.067
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   Vatikiotis-Bateson E., 1999, AVSP 99, P118
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
NR 55
TC 2
Z9 2
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD APR
PY 2020
VL 197
AR 104163
DI 10.1016/j.cognition.2019.104163
PG 8
WC Psychology, Experimental
SC Psychology
GA KQ4HS
UT WOS:000516886300006
PM 31891832
DA 2021-02-24
ER

PT J
AU Samuel, AG
AF Samuel, Arthur G.
TI Psycholinguists should resist the allure of linguistic units as
   perceptual units
SO JOURNAL OF MEMORY AND LANGUAGE
LA English
DT Article
DE Perceptual units; Linguistic units; Selective adaptation in speech
ID SELECTIVE ADAPTATION; SPEECH-PERCEPTION; VISUAL RECALIBRATION; AUDITORY
   SPEECH; STOP; IDENTIFICATION; INFORMATION; PLACE; ARTICULATION;
   RECOGNITION
AB The current study has empirical, methodological, and theoretical components. It draws heavily on two recent papers: Bowers et al. (2016) (JML, 87, 71-83) used results from selective adaptation experiments to argue that phonemes play a critical role in speech perception. Mitterer et al. (2018) (JML, 98, 77-92) responded with their own adaptation experiments to advocate instead for allophones. These studies are part of a renewed use of the selective adaptation paradigm. Empirically, the current study reports results that demonstrate that the Bowers et al. findings were artifactual. Methodologically, the renewed use of adaptation in the field is a positive development, but many recent studies suffer from a lack of knowledge of prior adaptation findings. As the use of selective adaptation grows, it will be important to draw on the considerable existing knowledge base (this literature is also relevant to the currently popular research on phonetic recalibration). Theoretically, for a half century there has been a recurring effort to demonstrate the psychological reality of various linguistic units, such as the phoneme or the allophone. The evidence is that listeners will use essentially any pattern that has been experienced often enough, not just the units that are well-suited to linguistic descriptions of language. Thus, rather than trying to identify any special perceptual status for linguistic units, psycholinguists should focus their efforts on more productive issues.
C1 [Samuel, Arthur G.] Basque Ctr Cognit Brain & Language, Donostia San Sebastian, Spain.
   [Samuel, Arthur G.] Basque Fdn Sci, Ikerbasque, Bilbao, Spain.
   [Samuel, Arthur G.] SUNY Stony Brook, Dept Psychol, Stony Brook, NY 11794 USA.
RP Samuel, AG (corresponding author), SUNY Stony Brook, Dept Psychol, Stony Brook, NY 11794 USA.
EM a.samuel@bcbl.eu
OI , Arthur Gary Samuel/0000-0001-8552-2710
FU Economic and Social Research Council (UK)UK Research & Innovation
   (UKRI)Economic & Social Research Council (ESRC) [ES/R006288/1];
   Ministerio de Ciencia E Innovacion (Spain)Spanish Government
   [PSI2017-82563-P]; Ayuda Centro de Excelencia Severo Ochoa (Spain)
   [SEV-2015-0490]
FX Support provided by Economic and Social Research Council (UK) Grant
   #ES/R006288/1, Ministerio de Ciencia E Innovacion (Spain) Grant
   #PSI2017-82563-P and by Ayuda Centro de Excelencia Severo Ochoa (Spain)
   SEV-2015-0490.
CR ADES AE, 1974, PERCEPT PSYCHOPHYS, V16, P61, DOI 10.3758/BF03203251
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Bowers JS, 2016, J MEM LANG, V87, P71, DOI 10.1016/j.jml.2015.11.002
   Brennan JR, 2016, BRAIN LANG, V157, P81, DOI 10.1016/j.bandl.2016.04.008
   Chomsky Noam, 1957, SYNTACTIC STRUCTURES
   Chomsky Noam, 1965, ASPECTS THEORY SYNTA, V11
   DIEHL R, 1976, PERCEPT PSYCHOPHYS, V19, P267, DOI 10.3758/BF03204180
   DIEHL RL, 1978, J EXP PSYCHOL HUMAN, V4, P599, DOI 10.1037/0096-1523.4.4.599
   DIEHL RL, 1981, PSYCHOL BULL, V89, P1
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   Elman Jeffrey L, 2009, Cogn Sci, V33, P547
   Fodor JA., 1974, PSYCHOL LANGUAGE INT
   FOSS DJ, 1973, J VERB LEARN VERB BE, V12, P246, DOI 10.1016/S0022-5371(73)80069-6
   GANONG WF, 1978, PERCEPT PSYCHOPHYS, V24, P71, DOI 10.3758/BF03202976
   Goldinger SD, 2003, J PHONETICS, V31, P305, DOI 10.1016/S0095-4470(03)00030-5
   Grossberg S, 1997, J EXP PSYCHOL HUMAN, V23, P481, DOI 10.1037/0096-1523.23.2.481
   KAT D, 1984, J EXP PSYCHOL HUMAN, V10, P512, DOI 10.1037/0096-1523.10.4.512
   Kazanina N, 2018, PSYCHON B REV, V25, P560, DOI 10.3758/s13423-017-1362-0
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MCNEILL D, 1973, J VERB LEARN VERB BE, V12, P419, DOI 10.1016/S0022-5371(73)80020-9
   Mitterer H, 2018, J MEM LANG, V98, P77, DOI 10.1016/j.jml.2017.09.005
   Mitterer H, 2017, LANG COGN NEUROSCI, V32, P1133, DOI 10.1080/23273798.2017.1286361
   Mitterer H, 2013, J MEM LANG, V69, P527, DOI 10.1016/j.jml.2013.07.002
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   Reinisch E, 2014, J PHONETICS, V45, P91, DOI 10.1016/j.wocn.2014.04.002
   SAMUEL AG, 1984, J ACOUST SOC AM, V76, P1652, DOI 10.1121/1.391612
   SAMUEL AG, 1979, J EXP PSYCHOL HUMAN, V5, P563, DOI 10.1037/h0078136
   SAMUEL AG, 1986, COGNITIVE PSYCHOL, V18, P452, DOI 10.1016/0010-0285(86)90007-1
   Samuel AG, 2001, PSYCHOL SCI, V12, P348, DOI 10.1111/1467-9280.00364
   Samuel AG, 1996, J EXP PSYCHOL HUMAN, V22, P676
   SAMUEL AG, 1989, PERCEPT PSYCHOPHYS, V45, P485, DOI 10.3758/BF03208055
   Samuel AG, 1997, COGNITIVE PSYCHOL, V32, P97, DOI 10.1006/cogp.1997.0646
   Samuel AG, 2016, COGNITIVE PSYCHOL, V88, P88, DOI 10.1016/j.cogpsych.2016.06.007
   SAVIN HB, 1970, J VERB LEARN VERB BE, V9, P295, DOI 10.1016/S0022-5371(70)80064-0
   SAWUSCH JR, 1977, PERCEPT PSYCHOPHYS, V22, P417, DOI 10.3758/BF03199507
   SAWUSCH JR, 1977, J ACOUST SOC AM, V62, P738, DOI 10.1121/1.381545
   SAWUSCH JR, 1978, PERCEPT PSYCHOPHYS, V23, P125, DOI 10.3758/BF03208292
   Schuhmann KS, 2014, THESIS
   SPROAT R, 1993, J PHONETICS, V21, P291, DOI 10.1016/S0095-4470(19)31340-3
   Sumner M, 2007, J EXP PSYCHOL LEARN, V33, P769, DOI 10.1037/0278-7393.33.4.769
   Toscano JC, 2013, PSYCHON B REV, V20, P981, DOI 10.3758/s13423-013-0417-0
   Vroomen J, 2004, SPEECH COMMUN, V44, P55, DOI 10.1016/j.specom.2004.03.009
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   WOLF CG, 1978, PERCEPT PSYCHOPHYS, V24, P315, DOI 10.3758/BF03204248
NR 49
TC 1
Z9 1
U1 2
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0749-596X
EI 1096-0821
J9 J MEM LANG
JI J. Mem. Lang.
PD APR
PY 2020
VL 111
AR 104070
DI 10.1016/j.jml.2019.104070
PG 12
WC Linguistics; Psychology; Psychology, Experimental
SC Linguistics; Psychology
GA KM3IW
UT WOS:000514015700007
DA 2021-02-24
ER

PT J
AU Firestone, GM
   McGuire, K
   Liang, C
   Zhang, NH
   Blankenship, CM
   Xiang, J
   Zhang, FW
AF Firestone, Gabrielle M.
   McGuire, Kelli
   Liang, Chun
   Zhang, Nanhua
   Blankenship, Chelsea M.
   Xiang, Jing
   Zhang, Fawen
TI A Preliminary Study of the Effects of Attentive Music Listening on
   Cochlear Implant Users' Speech Perception, Quality of Life, and
   Behavioral and Objective Measures of Frequency Change Detection
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE cochlear implant; music training; frequency change detection;
   electroencephalogram; cortical auditory evoked potential
ID NORMAL-HEARING; CORTICAL PLASTICITY; CHANGE COMPLEX; PITCH;
   DISCRIMINATION; MISMATCH; RECIPIENTS; BENEFITS
AB Introduction
   Most cochlear implant (CI) users have difficulty in listening tasks that rely strongly on perception of frequency changes (e.g., speech perception in noise, musical melody perception, etc.). Some previous studies using behavioral or subjective assessments have shown that short-term music training can benefit CI users' perception of music and speech. Electroencephalographic (EEG) recordings may reveal the neural basis for music training benefits in CI users. Objective
   To examine the effects of short-term music training on CI hearing outcomes using a comprehensive test battery of subjective evaluation, behavioral tests, and EEG measures. Design
   Twelve adult CI users were recruited for a home-based music training program that focused on attentive listening to music genres and materials that have an emphasis on melody. The participants used a music streaming program (i.e., Pandora) downloaded onto personal electronic devices for training. The participants attentively listened to music through a direct audio cable or through Bluetooth streaming. The training schedule was 40 min/session/day, 5 days/week, for either 4 or 8 weeks. The pre-training and post-training tests included: hearing thresholds, Speech, Spatial and Qualities of Hearing Scale (SSQ12) questionnaire, psychoacoustic tests of frequency change detection threshold (FCDT), speech recognition tests (CNC words, AzBio sentences, and QuickSIN), and EEG responses to tones that contained different magnitudes of frequency changes. Results
   All participants except one finished the 4- or 8-week training, resulting in a dropout rate of 8.33%. Eleven participants performed all tests except for two who did not participate in EEG tests. Results showed a significant improvement in the FCDTs as well as performance on CNC and QuickSIN after training (p < 0.05), but no significant improvement in SSQ scores (p > 0.05). Results of the EEG tests showed larger post-training cortical auditory evoked potentials (CAEPs) in seven of the nine participants, suggesting a better cortical processing of both stimulus onset and within-stimulus frequency changes. Conclusion
   These preliminary data suggest that extensive, focused music listening can improve frequency perception and speech perception in CI users. Further studies that include a larger sample size and control groups are warranted to determine the efficacy of short-term music training in CI users.
C1 [Firestone, Gabrielle M.; McGuire, Kelli; Liang, Chun; Blankenship, Chelsea M.; Zhang, Fawen] Univ Cincinnati, Dept Commun Sci & Disorders, Cincinnati, OH 45221 USA.
   [Zhang, Nanhua] Cincinnati Childrens Hosp Med Ctr, Div Biostat & Epidemiol, Cincinnati, OH 45229 USA.
   [Zhang, Nanhua] Univ Cincinnati, Coll Med, Dept Pediat, Cincinnati, OH USA.
   [Xiang, Jing] Cincinnati Childrens Hosp Med Ctr, Dept Pediat & Neurol, Cincinnati, OH 45229 USA.
RP Zhang, FW (corresponding author), Univ Cincinnati, Dept Commun Sci & Disorders, Cincinnati, OH 45221 USA.
EM Fawen.Zhang@uc.edu
OI Zhang, Nanhua/0000-0001-5796-3404
FU University Research Council (URC-Office of Research Collaborative
   Grants: Track 1-PILOT Program) at the University of Cincinnati; National
   Institute of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [NIH 1 R15
   DC016463-01]
FX This research was partially supported by the University Research Council
   (URC-Office of Research Collaborative Grants: Track 1-PILOT Program) at
   the University of Cincinnati, and the National Institute of Health (NIH
   1 R15 DC016463-01 to FZ). The content is solely the responsibility of
   the authors and does not necessarily represent the official views of the
   National Institutes of Health.
CR Baskent D, 2016, J ACOUST SOC AM, V139, pEL51, DOI 10.1121/1.4942628
   Besson M, 2007, RESTOR NEUROL NEUROS, V25, P399
   Bidelman GM, 2018, J AM ACAD AUDIOL, V29, P164, DOI 10.3766/jaaa.16167
   Brown CJ, 2017, EAR HEARING, V38, pE74, DOI 10.1097/AUD.0000000000000375
   Cheng XT, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518759214
   Cousineau M, 2010, HEARING RES, V269, P34, DOI 10.1016/j.heares.2010.07.007
   Cullington HE, 2008, J ACOUST SOC AM, V123, P450, DOI 10.1121/1.2805617
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Di Nardo W, 2010, J LARYNGOL OTOL, V124, P828, DOI 10.1017/S0022215110000320
   Dimitrijevic A, 2008, CLIN NEUROPHYSIOL, V119, P2111, DOI 10.1016/j.clinph.2008.06.002
   Driscoll Virginia, 2015, Cochlear Implants Int, V16, P137, DOI 10.1179/1754762814Y.0000000103
   Friesen LM, 2006, EAR HEARING, V27, P678, DOI 10.1097/01.aud.0000240620.63453.c3
   Fu Qian-Jie, 2007, Trends Amplif, V11, P193, DOI 10.1177/1084713807301379
   Fu QJ, 2015, J SPEECH LANG HEAR R, V58, P163, DOI 10.1044/2014_JSLHR-H-14-0127
   Fuller CD, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518765379
   Fuller CD, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00179
   Galvin JJ, 2009, ANN NY ACAD SCI, V1169, P518, DOI 10.1111/j.1749-6632.2009.04551.x
   Gfeller K, 2016, EUR ANN OTORHINOLARY, V133, pS50, DOI 10.1016/j.anorl.2016.01.010
   Gfeller Kate, 2015, Cochlear Implants Int, V16 Suppl 3, pS22, DOI 10.1179/1467010015Z.000000000269
   Gifford RH, 2015, OTOL NEUROTOL, V36, P1331, DOI 10.1097/MAO.0000000000000804
   Good A, 2017, EAR HEARING, V38, P455, DOI 10.1097/AUD.0000000000000402
   He SM, 2012, INT J AUDIOL, V51, P771, DOI 10.3109/14992027.2012.699198
   Hutter E, 2015, Cochlear Implants Int, V16 Suppl 3, pS13, DOI 10.1179/1467010015Z.000000000261
   Irvine DRF, 2018, HEARING RES, V362, P61, DOI 10.1016/j.heares.2017.10.011
   Itoh K, 2012, EUR J NEUROSCI, V36, P3580, DOI 10.1111/j.1460-9568.2012.08278.x
   Jain C, 2015, AUDIOL RES, V5, P5, DOI 10.4081/audiores.2015.111
   Jancke L, 2018, NEUROREPORT, V29, P594, DOI 10.1097/WNR.0000000000001019
   Jiam NT, 2019, JARO-J ASSOC RES OTO, V20, P247, DOI 10.1007/s10162-018-00704-0
   Kenway B, 2015, OTOL NEUROTOL, V36, P1472, DOI 10.1097/MAO.0000000000000845
   Kim JR, 2015, J AUDIOL OTOL, V19, P120, DOI 10.7874/jao.2015.19.3.120
   Kraus N, 2009, ANN NY ACAD SCI, V1169, P543, DOI 10.1111/j.1749-6632.2009.04549.x
   Lappe C, 2008, J NEUROSCI, V28, P9632, DOI 10.1523/JNEUROSCI.2254-08.2008
   Lappe C, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00260
   Lehmann A, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00451
   Liang C, 2018, AUDIOL NEURO-OTOL, V23, P152, DOI 10.1159/000492170
   Liang C, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00464
   Limb CJ, 2014, HEARING RES, V308, P13, DOI 10.1016/j.heares.2013.04.009
   Limb Charles J, 2006, Curr Opin Otolaryngol Head Neck Surg, V14, P337, DOI 10.1097/01.moo.0000244192.59184.bd
   Lo CY, 2015, BEHAV NEUROL, V2015, DOI 10.1155/2015/352869
   Looi V, 2010, INT J AUDIOL, V49, P116, DOI 10.3109/14992020903405987
   Martin BA, 2007, J AM ACAD AUDIOL, V18, P126, DOI 10.3766/jaaa.18.2.5
   Mathew R, 2017, HEARING RES, V354, P86, DOI 10.1016/j.heares.2017.07.008
   McDermott JH, 2008, CURR OPIN NEUROBIOL, V18, P452, DOI 10.1016/j.conb.2008.09.005
   Moore DR, 2003, LEARN MEMORY, V10, P83, DOI 10.1101/lm.59703
   Nan Y, 2018, P NATL ACAD SCI USA, V115, pE6630, DOI 10.1073/pnas.1808412115
   Noble W, 2013, INT J AUDIOL, V52, P409, DOI 10.3109/14992027.2013.781278
   Oxenham Andrew J, 2008, Trends Amplif, V12, P316, DOI 10.1177/1084713808325881
   Oxenham AJ, 2013, ACOUST SCI TECHNOL, V34, P388, DOI 10.1250/ast.34.388
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Petersen B, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00007
   Petersen B, 2009, ANN NY ACAD SCI, V1169, P437, DOI 10.1111/j.1749-6632.2009.04796.x
   Pisoni David B, 2017, World J Otorhinolaryngol Head Neck Surg, V3, P240, DOI 10.1016/j.wjorl.2017.12.010
   Riss D, 2011, OTOL NEUROTOL, V32, P1094, DOI 10.1097/MAO.0b013e31822a97f4
   Roman S, 2005, HEARING RES, V201, P10, DOI 10.1016/j.heares.2004.08.021
   SHAFFER JP, 1995, ANNU REV PSYCHOL, V46, P561, DOI 10.1146/annurev.ps.46.020195.003021
   Smith L, 2017, OTOL NEUROTOL, V38, pE262, DOI 10.1097/MAO.0000000000001447
   Spahr AJ, 2012, EAR HEARING, V33, P112, DOI 10.1097/AUD.0b013e31822c2549
   Turgeon Christine, 2015, Cochlear Implants Int, V16, P88, DOI 10.1179/1754762814Y.0000000091
   Vuust P, 2012, NEUROPSYCHOLOGIA, V50, P1432, DOI 10.1016/j.neuropsychologia.2012.02.028
   Wilson RH, 2007, J SPEECH LANG HEAR R, V50, P844, DOI 10.1044/1092-4388(2007/059)
   Zhang FW, 2019, HEARING RES, V379, P12, DOI 10.1016/j.heares.2019.04.007
   Zhang FW, 2009, J AM ACAD AUDIOL, V20, P397, DOI 10.3766/jaaa.20.7.2
NR 63
TC 0
Z9 0
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD MAR 31
PY 2020
VL 14
AR 110
DI 10.3389/fnhum.2020.00110
PG 12
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA LE5QV
UT WOS:000526774500001
PM 32296318
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Mokari, PG
   Gafos, A
   Williams, D
AF Mokari, Payam Ghaffarvand
   Gafos, Adamantios
   Williams, Daniel
TI Perceptuomotor compatibility effects in vowels: Beyond phonemic identity
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE speech perception; speech production; psycholinguistics
ID S-R COMPATIBILITY; SPEECH-PERCEPTION; MOTOR THEORY; STIMULUS;
   REPRESENTATIONS; SIMILARITY; MODEL
AB Perceptuomotor compatibility between phonemically identical spoken and perceived syllables has been found to speed up response times (RTs) in speech production tasks. However, research on compatibility effects between perceived and produced stimuli at the subphonemic level is limited. Using a cue-distractor task, we investigated the effects of phonemic and subphonemic congruency in pairs of vowels. On each trial, a visual cue prompted individuals to produce a response vowel, and after the visual cue appeared a distractor vowel was auditorily presented while speakers were planning to produce the response vowel. The results revealed effects on RTs due to phonemic congruency (same vs. different vowels) between the response and distractor vowels, which resemble effects previously seen for consonants. Beyond phonemic congruency, we assessed how RTs are modulated as a function of the degree of subphonemic similarity between the response and distractor vowels. Higher similarity between the response and distractor in terms of phonological distance-defined by number of mismatching phonological features-resulted in faster RTs. However, the exact patterns of RTs varied across response-distractor vowel pairs. We discuss how different assumptions about phonological feature representations may account for the different patterns observed in RTs across response-distractor pairs. Our findings on the effects of perceived stimuli on produced speech at a more detailed level of representation than phonemic identity necessitate a more direct and specific formulation of the perception-production link. Additionally, these results extend previously reported perceptuomotor interactions mainly involving consonants to vowels.
C1 [Mokari, Payam Ghaffarvand; Gafos, Adamantios; Williams, Daniel] Univ Potsdam, Dept Linguist, Potsdam, Germany.
   [Gafos, Adamantios] Yale Univ, Haskins Labs, New Haven, CT USA.
RP Mokari, PG (corresponding author), Univ Potsdam, Dept Linguist, Potsdam, Germany.
EM payam.mokari@uni-potsdam.de; gafos@uni-potsdam.de;
   daniel.williams@uni-potsdam.de
OI Ghaffarvand Mokari, Payam/0000-0002-1816-2783; Gafos,
   Adamantios/0000-0002-4905-7118
FU Projekt DEAL
FX Open Access funding provided by Projekt DEAL.
CR Adank P, 2018, ATTEN PERCEPT PSYCHO, V80, P1290, DOI 10.3758/s13414-018-1501-3
   Audacity Team, 2019, AUD R FREE AUD ED RE
   Bailey TM, 2005, J MEM LANG, V52, P339, DOI 10.1016/j.jml.2004.12.003
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Boersma Paul, 2019, PRAAT DOING PHONETIC
   Bohland JW, 2010, J COGNITIVE NEUROSCI, V22, P1504, DOI 10.1162/jocn.2009.21306
   Brass M, 2001, ACTA PSYCHOL, V106, P3, DOI 10.1016/S0001-6918(00)00024-X
   Brysbaert Marc, 2018, J Cogn, V1, P9, DOI 10.5334/joc.10
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   DELL GS, 1993, COGNITIVE SCI, V17, P149, DOI 10.1016/0364-0213(93)90010-6
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   FITTS PM, 1954, J EXP PSYCHOL, V48, P483, DOI 10.1037/h0054967
   FITTS PM, 1953, J EXP PSYCHOL, V46, P199, DOI 10.1037/h0062827
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   Frisch SA, 2004, NAT LANG LINGUIST TH, V22, P179, DOI 10.1023/B:NALA.0000005557.78535.3c
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Galantucci B, 2009, ATTEN PERCEPT PSYCHO, V71, P1138, DOI 10.3758/APP.71.5.1138
   Gelman A., 2007, DATA ANAL USING REGR
   Grabski K, 2013, J NEUROLINGUIST, V26, P384, DOI 10.1016/j.jneuroling.2012.11.003
   Hommel B, 2001, BEHAV BRAIN SCI, V24, P849, DOI 10.1017/S0140525X01000103
   Kerzel D, 2000, J EXP PSYCHOL HUMAN, V26, P634, DOI 10.1037//0096-1523.26.2.634
   Klein E, 2015, 18 INT C PHON SCI IC
   Kleiner M, 2007, PERCEPTION, V36, P14
   KORNBLUM S, 1990, PSYCHOL REV, V97, P253, DOI 10.1037/0033-295X.97.2.253
   LADEFOGED P, 1980, LANGUAGE, V56, P485, DOI 10.2307/414446
   Lahiri A, 2010, J PHONETICS, V38, P44, DOI 10.1016/j.wocn.2010.01.002
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Mitterer H, 2008, COGNITION, V109, P168, DOI 10.1016/j.cognition.2008.08.002
   Monaghan P, 2010, MENT LEX, V5, P281, DOI 10.1075/ml.5.3.02mon
   Obleser J, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00232
   Ohala JJ, 1996, J ACOUST SOC AM, V99, P1718, DOI 10.1121/1.414696
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   Roelofs A, 1997, COGNITION, V64, P249, DOI 10.1016/S0010-0277(97)00027-9
   Roon KD, 2016, J MEM LANG, V89, P222, DOI 10.1016/j.jml.2016.01.005
   Roon KD, 2015, PSYCHON B REV, V22, P242, DOI 10.3758/s13423-014-0666-6
   Scharinger M, 2016, BRAIN LANG, V163, P42, DOI 10.1016/j.bandl.2016.09.002
   Schepens J, 2020, COGNITION, V194, DOI 10.1016/j.cognition.2019.104056
   Strange W, 2013, VOWEL INHERENT SPECT, P87
   Sturmer B, 2000, J EXP PSYCHOL HUMAN, V26, P1746, DOI 10.1037//0096-1523.26.6.1746
   Tobin S, 2018, J ACOUST SOC AM, V144, pEL528, DOI 10.1121/1.5082984
   Viviani P, 2002, ATTENTION PERFORM, V19, P406
   Wilson C., 2009, SIMPLIFYING SU UNPUB
NR 42
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD JUL
PY 2020
VL 82
IS 5
BP 2751
EP 2764
DI 10.3758/s13414-020-02014-1
EA MAR 2020
PG 14
WC Psychology; Psychology, Experimental
SC Psychology
GA MH4PQ
UT WOS:000522897500002
PM 32236835
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Olasagasti, I
   Giraud, AL
AF Olasagasti, Itsaso
   Giraud, Anne-Lise
TI Integrating prediction errors at two time scales permits rapid
   recalibration of speech sound categories
SO ELIFE
LA English
DT Article
ID VISUAL RECALIBRATION; COGNITIVE-DISSONANCE; AUDIOVISUAL SPEECH; BAYESIAN
   BRAIN; PERCEPTION; ORGANIZATION; INFORMATION; ADAPTATION; PLASTICITY;
   PREFERENCE
AB Speech perception presumably arises from internal models of how specific sensory features are associated with speech sounds. These features change constantly (e.g. different speakers, articulation modes etc.), and listeners need to recalibrate their internal models by appropriately weighing new versus old evidence. Models of speech recalibration classically ignore this volatility. The effect of volatility in tasks where sensory cues were associated with arbitrary experimenter-defined categories were well described by models that continuously adapt the learning rate while keeping a single representation of the category. Using neurocomputational modelling we show that recalibration of natural speech sound categories is better described by representing the latter at different time scales. We illustrate our proposal by modeling fast recalibration of speech sounds after experiencing the McGurk effect. We propose that working representations of speech categories are driven both by their current environment and their long-term memory representations.
C1 [Olasagasti, Itsaso; Giraud, Anne-Lise] Univ Geneva, Dept Basic Neurosci, Geneva, Switzerland.
RP Olasagasti, I (corresponding author), Univ Geneva, Dept Basic Neurosci, Geneva, Switzerland.
EM itsaso.olasagasti@gmail.com
FU Swiss National Science FoundationSwiss National Science Foundation
   (SNSF)European Commission [320030B_182855]
FX Swiss National Science Foundation 320030B_182855 Anne-Lise Giraud; The
   funders had no role in study design, data collection and interpretation,
   or the decision to submit the work for publication.
CR Akrami A, 2018, NATURE, V554, P368, DOI 10.1038/nature25510
   Baart M, 2010, NEUROSCI LETT, V471, P100, DOI 10.1016/j.neulet.2010.01.019
   Badre D, 2008, TRENDS COGN SCI, V12, P193, DOI 10.1016/j.tics.2008.02.004
   Barascud N, 2016, P NATL ACAD SCI USA, V113, pE616, DOI 10.1073/pnas.1508523113
   Behrens TEJ, 2007, NAT NEUROSCI, V10, P1214, DOI 10.1038/nn1954
   Benna MK, 2016, NAT NEUROSCI, V19, P1697, DOI 10.1038/nn.4401
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155
   Chevillet M, 2011, J NEUROSCI, V31, P9345, DOI 10.1523/JNEUROSCI.1448-11.2011
   Clarke CM, 2005, P ISCA WORKSH PLAST
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Colosio M, 2017, J NEUROSCI, V37, P5074, DOI 10.1523/JNEUROSCI.3209-16.2017
   Coppin G, 2010, PSYCHOL SCI, V21, P489, DOI 10.1177/0956797610364115
   Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1
   Friston KJ, 2010, BIOL CYBERN, V102, P227, DOI 10.1007/s00422-010-0364-z
   Friston KJ, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000081
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   Gabay Y, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0198146
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Gelman A., 2003, CHAPMAN HALL CRC TEX
   Gilbert CD, 2001, NEURON, V31, P681, DOI 10.1016/S0896-6273(01)00424-X
   Heald SLM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00781
   Idemaru K, 2014, J EXP PSYCHOL HUMAN, V40, P1009, DOI 10.1037/a0035269
   Iigaya K, 2016, ELIFE, V5, DOI 10.7554/eLife.18073
   Izuma K, 2010, P NATL ACAD SCI USA, V107, P22014, DOI 10.1073/pnas.1011879108
   Jaffe-Dax S, 2017, ELIFE, V6, DOI 10.7554/eLife.20557
   Kiebel SJ, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000209
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007
   Koechlin E, 2003, SCIENCE, V302, P1181, DOI 10.1126/science.1088545
   Koechlin E, 2007, TRENDS COGN SCI, V11, P229, DOI 10.1016/j.tics.2007.04.005
   Koechlin E, 2006, NEURON, V50, P963, DOI 10.1016/j.neuron.2006.05.017
   Lametti DR, 2014, J NEUROSCI, V34, P10339, DOI 10.1523/JNEUROSCI.0108-14.2014
   Lancia L, 2013, LAB PHONOL, V4, P221, DOI 10.1515/lp-2013-0009
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   Lieder I, 2019, NAT NEUROSCI, V22, P256, DOI 10.1038/s41593-018-0308-9
   Luttke CS, 2018, ROY SOC OPEN SCI, V5, DOI 10.1098/rsos.170909
   Luttke CS, 2016, SCI REP-UK, V6, DOI 10.1038/srep32891
   Luttke CS, 2016, J COGNITIVE NEUROSCI, V28, P1, DOI 10.1162/jocn_a_00874
   Luu L, 2018, ELIFE, V7, DOI [10.7554/elife.33334, 10.7554/eLife.33334]
   Maddox WT, 2014, BILING-LANG COGN, V17, P709, DOI 10.1017/S1366728913000783
   Magnotti JF, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005229
   Mathys C, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00039
   Mathys CD, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00825
   McMurray B, 2009, DEVELOPMENTAL SCI, V12, P369, DOI 10.1111/j.1467-7687.2009.00822.x
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   Mirman D, 2006, PSYCHON B REV, V13, P958, DOI 10.3758/BF03213909
   Myers EB, 2014, J MEM LANG, V76, P80, DOI 10.1016/j.jml.2014.06.007
   Nasir SM, 2009, P NATL ACAD SCI USA, V106, P20470, DOI 10.1073/pnas.0907032106
   Nassar MR, 2010, J NEUROSCI, V30, P12366, DOI 10.1523/JNEUROSCI.0822-10.2010
   Olasagasti I., 2020, RECALIBRATION SPEECH
   Olasagasti I, 2015, CORTEX, V68, P61, DOI 10.1016/j.cortex.2015.04.008
   Otten M, 2017, BRAIN COGNITION, V112, P69, DOI 10.1016/j.bandc.2016.05.002
   Patri JF, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005942
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580
   Reinisch E, 2014, J PHONETICS, V45, P91, DOI 10.1016/j.wocn.2014.04.002
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   Schwiedrzik CM, 2014, CEREB CORTEX, V24, P1152, DOI 10.1093/cercor/bhs396
   Scott BB, 2017, NEURON, V95, P385, DOI 10.1016/j.neuron.2017.06.013
   Summerfield C, 2006, SCIENCE, V314, P1311, DOI 10.1126/science.1132028
   Summerfield C, 2011, NEURON, V71, P725, DOI 10.1016/j.neuron.2011.06.022
   Tsunada J, 2019, ELIFE, V8, DOI 10.7554/eLife.46770
   Vallabha GK, 2007, P NATL ACAD SCI USA, V104, P13273, DOI 10.1073/pnas.0705369104
   Vallabha GK, 2007, COGN AFFECT BEHAV NE, V7, P53, DOI 10.3758/CABN.7.1.53
   Varnet L, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00865
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
   Wilson RC, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003150
   Zeithamova D, 2008, J NEUROSCI, V28, P13194, DOI 10.1523/JNEUROSCI.2915-08.2008
NR 69
TC 1
Z9 1
U1 0
U2 0
PU ELIFE SCIENCES PUBLICATIONS LTD
PI CAMBRIDGE
PA SHERATON HOUSE, CASTLE PARK, CAMBRIDGE, CB3 0AX, ENGLAND
SN 2050-084X
J9 ELIFE
JI eLife
PD MAR 30
PY 2020
VL 9
AR e44516
DI 10.7554/eLife.44516
PG 22
WC Biology
SC Life Sciences & Biomedicine - Other Topics
GA LQ7KR
UT WOS:000535178900001
PM 32223894
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Bosker, HR
   Sjerps, MJ
   Reinisch, E
AF Bosker, Hans Rutger
   Sjerps, Matthias J.
   Reinisch, Eva
TI Temporal contrast effects in human speech perception are immune to
   selective attention
SO SCIENTIFIC REPORTS
LA English
DT Article
ID SPEAKING RATE; AUDITORY-CORTEX; GAIN-CONTROL; TRACKING; IDENTIFICATION;
   REPRESENTATION; NORMALIZATION; OSCILLATIONS; INFORMATION; MECHANISMS
AB Two fundamental properties of perception are selective attention and perceptual contrast, but how these two processes interact remains unknown. Does an attended stimulus history exert a larger contrastive influence on the perception of a following target than unattended stimuli? Dutch listeners categorized target sounds with a reduced prefix "ge-" marking tense (e.g., ambiguous between gegaan-gaan "gone-go"). In 'single talker' Experiments 1-2, participants perceived the reduced syllable (reporting gegaan) when the target was heard after a fast sentence, but not after a slow sentence (reporting gaan). In 'selective attention' Experiments 3-5, participants listened to two simultaneous sentences from two different talkers, followed by the same target sounds, with instructions to attend only one of the two talkers. Critically, the speech rates of attended and unattended talkers were found to equally influence target perception - even when participants could watch the attended talker speak. In fact, participants' target perception in 'selective attention' Experiments 3-5 did not differ from participants who were explicitly instructed to divide their attention equally across the two talkers (Experiment 6). This suggests that contrast effects of speech rate are immune to selective attention, largely operating prior to attentional stream segregation in the auditory processing hierarchy.
C1 [Bosker, Hans Rutger; Sjerps, Matthias J.] Max Planck Inst Psycholinguist, POB 310, NL-6500 AH Nijmegen, Netherlands.
   [Bosker, Hans Rutger; Sjerps, Matthias J.] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
   [Reinisch, Eva] Ludwig Maximilian Univ Munich, Inst Phonet & Speech Proc, Munich, Germany.
   [Reinisch, Eva] Austrian Acad Sci, Acoust Res Inst, Vienna, Austria.
RP Bosker, HR (corresponding author), Max Planck Inst Psycholinguist, POB 310, NL-6500 AH Nijmegen, Netherlands.; Bosker, HR (corresponding author), Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
EM HansRutger.Bosker@mpi.nl
RI Sjerps, Matthias/H-9022-2013
OI Sjerps, Matthias/0000-0003-3098-7152; Bosker, Hans
   Rutger/0000-0002-2628-7738
FU Dutch Government; German Research CouncilGerman Research Foundation
   (DFG) [RE 3047/1-1]; European CommissionEuropean CommissionEuropean
   Commission Joint Research Centre [FP7-623072]
FX Authors were supported by a Gravitation grant from the Dutch Government
   to the Language in Interaction Consortium (H.R.B.); Emmy-Noether
   Fellowship RE 3047/1-1 by the German Research Council (E.R.); and
   European Commission grant FP7-623072 (M.J.S.). We thank Martin Cooke,
   James McQueen, and Andrew Oxenham for helpful discussions about the
   outcomes of this study. We would like to thank Zina Al-Jibouri, Ingeborg
   Roete, Rosemarije Weterings, Annelies van Wijngaarden, and Merel Wolf
   for the (video-)recordings, and Sanne van Eck, Milou Huijsmans, Esther
   de Kerf, and Jeonga Kim for help with testing participants.
CR Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Baese-Berk M. M., 2013, ABSTRACTS PSYCHONOMI, V18, P191
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Bosker HR, 2020, ATTEN PERCEPT PSYCHO, V82, P1318, DOI 10.3758/s13414-019-01824-2
   Bosker HR, 2018, LANG COGN NEUROSCI, V33, P955, DOI 10.1080/23273798.2018.1439179
   Bosker HR, 2017, J EXP PSYCHOL LEARN, V43, P1225, DOI 10.1037/xlm0000381
   Bosker HR, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01063
   Bosker HR, 2017, J MEM LANG, V94, P166, DOI 10.1016/j.jml.2016.12.002
   Bosker HR, 2017, ATTEN PERCEPT PSYCHO, V79, P333, DOI 10.3758/s13414-016-1206-4
   Bronkhorst AW, 2000, ACUSTICA, V86, P117
   Carlile S, 2015, SCI REP-UK, V5, DOI 10.1038/srep08662
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Feng L, 2018, J EXP PSYCHOL HUMAN, V44, P1447, DOI 10.1037/xhp0000546
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Golumbic EZ, 2013, J NEUROSCI, V33, P1417, DOI 10.1523/JNEUROSCI.3675-12.2013
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Gonzalez-Franco M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04201-x
   Heffner CC, 2013, LANG COGNITIVE PROC, V28, P1275, DOI 10.1080/01690965.2012.672229
   Itatani N, 2014, P NATL ACAD SCI USA, V111, P10738, DOI 10.1073/pnas.1321487111
   JOHNSON K, 1990, J ACOUST SOC AM, V88, P642, DOI 10.1121/1.399767
   Kaufeld G., J EXPT PSYCHOL LEARN
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Khaw MW, 2017, P NATL ACAD SCI USA, V114, P12696, DOI 10.1073/pnas.1715293114
   Kosem A, 2018, CURR BIOL, V28, P2867, DOI 10.1016/j.cub.2018.07.023
   Lachter J, 2004, PSYCHOL REV, V111, P880, DOI [10.1037/0033-295X.111.4.880, 10.1037/0033-295x.111.4.880]
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Makov S, 2017, J NEUROSCI, V37, P7772, DOI 10.1523/JNEUROSCI.0168-17.2017
   Maslowski M, 2019, J ACOUST SOC AM, V146, P179, DOI 10.1121/1.5116004
   Maslowski M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203571
   Maslowski M, 2019, J EXP PSYCHOL LEARN, V45, P128, DOI 10.1037/xlm0000579
   Mattys SL, 2009, COGNITIVE PSYCHOL, V59, P203, DOI 10.1016/j.cogpsych.2009.04.001
   McDermott JH, 2009, CURR BIOL, V19, pR1024, DOI 10.1016/j.cub.2009.09.005
   Mesgarani N, 2014, P NATL ACAD SCI USA, V111, P6792, DOI 10.1073/pnas.1318017111
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   MILLER JL, 1979, PERCEPT PSYCHOPHYS, V25, P457, DOI 10.3758/BF03213823
   Newman RS, 2009, J PHONETICS, V37, P46, DOI 10.1016/j.wocn.2008.09.001
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Phillips WA, 2015, NEUROSCI BIOBEHAV R, V52, P1, DOI 10.1016/j.neubiorev.2015.02.010
   PICKETT JM, 1960, LANG SPEECH, V3, P11, DOI 10.1177/002383096000300103
   Pitt MA, 2016, ATTEN PERCEPT PSYCHO, V78, P334, DOI 10.3758/s13414-015-0981-7
   Pluymaekers M, 2005, J ACOUST SOC AM, V118, P2561, DOI 10.1121/1.2011150
   Pomper U, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04475-1
   Quene H, 2008, J MEM LANG, V59, P413, DOI 10.1016/j.jml.2008.02.002
   R Development Core Team, 2012, R LANG ENV STAT COMP
   Rabinowitz NC, 2011, NEURON, V70, P1178, DOI 10.1016/j.neuron.2011.04.030
   Reinisch E, 2016, APPL PSYCHOLINGUIST, V37, P1397, DOI 10.1017/S0142716415000612
   Reinisch E, 2016, ATTEN PERCEPT PSYCHO, V78, P1203, DOI 10.3758/s13414-016-1067-x
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   Reinisch E, 2011, LANG SPEECH, V54, P147, DOI 10.1177/0023830910397489
   Reinisch E, 2011, J EXP PSYCHOL HUMAN, V37, P978, DOI 10.1037/a0021923
   Rimmele JM, 2015, CORTEX, V68, P144, DOI 10.1016/j.cortex.2014.12.014
   Sjerps MJ, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10365-z
   Stilp C, 2020, WIRES COGN SCI, V11, DOI 10.1002/wcs.1517
   Tian Y, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24535-4
   Toscano JC, 2015, LANG COGN NEUROSCI, V30, P529, DOI 10.1080/23273798.2014.946427
   Wade T, 2005, PERCEPT PSYCHOPHYS, V67, P939, DOI 10.3758/BF03193621
   Wang D. L., 2006, COMPUTATIONAL AUDITO
   Welch TE, 2009, J ACOUST SOC AM, V126, P2779, DOI 10.1121/1.3212923
   WOLDORFF MG, 1993, P NATL ACAD SCI USA, V90, P8722, DOI 10.1073/pnas.90.18.8722
NR 61
TC 0
Z9 0
U1 0
U2 0
PU NATURE RESEARCH
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD MAR 27
PY 2020
VL 10
IS 1
AR 5607
DI 10.1038/s41598-020-62613-8
PG 11
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA NB3IF
UT WOS:000560407700001
PM 32221376
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Amiri, M
   Jarollahi, F
   Jalaie, S
   Sameni, SJ
AF Amiri, Marzieh
   Jarollahi, Farnoush
   Jalaie, Shohreh
   Sameni, Seyyed Jalal
TI A New Speech-in-Noise Test for Measuring Informational Masking in Speech
   Perception Among Elderly Listeners
SO CUREUS
LA English
DT Article
DE informational masking; perceptual masking; elderly; speech recognition
ID OLDER-ADULTS; SPATIAL RELEASE; HEARING; AGE
AB Introduction
   Elderly listeners have reported concerns about speech perception in noisy environments. This partly occurs because of their increased informational masking (IM). This study aimed to develop a Persian coordinate response measure (CRM) corpus and a novel speech-in-noise test for measuring IM.
   Material and methods
   A cross-sectional validation study was conducted in two parts. Part one was the determination of the validity and reliability of the Persian CRM corpus. Part two consisted of measuring the IM at five signal-to-noise ratio (SNR; -6,-3, 0, +3, and +6) in two conditions: one with the target and masker speaker of the same sex and one with the target and masker speaker of different sexes. In each condition, the IM measurements were performed at a 45 degrees separation angle of target and maskers and as a co-location of the speakers. A group of young listeners aged 20 to 40 years and a group of elderly listeners aged 60 to 75 years were recruited (50 study participants in part one and 47 in part two). The study was conducted from July 2018 to March 2019 at the Iran University Medical Sciences audiology clinic. Content validity ratio, content validity index, impact score, Spearman's test, and Mann-Whitney's test were used for statistical analysis.
   Results
   The Persian CRM corpus showed acceptable validity and reliability in each group (p < 0.001). The results suggested that in both azimuth locations and at SNRs of 0, -3, and -6, the IM amount in the elderly group was significantly higher (p < 0.003) than in the young group at conditions of target and masker speakers of opposite-sex. However, in cases where both target and masker speakers were of the same sex, a significant difference was observed at an SNR of 0 in angular separation and SNRs of +3 and 0 at co-located situations (p < 0.001).
   Conclusion
   A validated Persian CRM corpus has been collected for use in IM measurement studies. Overall, the IM of elderly listeners was higher than younger listeners in low-cue situations such as lower SNR. Therefore, a novel speech-in-noise test for measuring IM was validated to use in speech perception studies in the elderly population.
C1 [Amiri, Marzieh; Sameni, Seyyed Jalal] Iran Univ Med Sci, Sch Rehabil Sci, Audiol, Tehran, Iran.
   [Jarollahi, Farnoush] Iran Univ Med Sci, Audiol Dept, Tehran, Iran.
   [Jalaie, Shohreh] Univ Tehran Med Sci, Sch Rehabil Sci, Physiotherapy, Tehran, Iran.
RP Jarollahi, F (corresponding author), Iran Univ Med Sci, Audiol Dept, Tehran, Iran.
EM jarollahi.f@iums.ac.ir
RI Amiri, Marzieh/ABE-3305-2020; Jarollahi, Farnoush/ABA-4707-2020; Amiri,
   Marzieh/S-8271-2017
OI Jarollahi, Farnoush/0000-0002-0850-3433; Amiri,
   Marzieh/0000-0001-8787-1260
FU IUMS, Tehran, Iran [97-46-13657]
FX This study was part of a Ph.D. dissertation approved by IUMS, Tehran,
   Iran (Contract number 97-46-13657).We would like to acknowledge all
   participants as well as the respected officials of the speech-pathology
   Department of IUMS for their cooperation in conducting this research.
CR Alipour AA, 2007, J PSYCHOLOGICAL SCI, V22, P117
   Ansari NN, 2010, APPL NEUROPSYCHOL, V17, P190, DOI 10.1080/09084282.2010.499773
   Bolia RS, 2000, J ACOUST SOC AM, V107, P1065, DOI 10.1121/1.428288
   Brungart DS, 2001, J ACOUST SOC AM, V110, P2527, DOI 10.1121/1.1408946
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Calcus A, 2015, J ACOUST SOC AM, V137, pEL496, DOI 10.1121/1.4922012
   Dai B, 2017, J ACOUST SOC AM, V141, pEL249, DOI 10.1121/1.4977590
   Dubno JR, 2008, J SPEECH LANG HEAR R, V51, P539, DOI 10.1044/1092-4388(2008/039)
   Durlach NI, 2003, J ACOUST SOC AM, V113, P2984, DOI 10.1121/1.1570435
   Glyde H, 2013, J ACOUST SOC AM, V134, P2937, DOI 10.1121/1.4817930
   Glyde H, 2013, J ACOUST SOC AM, V134, pEL147, DOI 10.1121/1.4812441
   Glyde H, 2011, TRENDS AMPLIF, V15, P116, DOI 10.1177/1084713811424885
   Goossens T, 2017, HEARING RES, V344, P109, DOI 10.1016/j.heares.2016.11.004
   Heidari A, 2018, J AUDIOL OTOL, V22, P134, DOI 10.7874/jao.2017.00304
   Helfer KS, 2008, EAR HEARING, V29, P87, DOI 10.1097/AUD.0b013e31815d638b
   Helfer KS, 2016, J ACOUST SOC AM, V140, P3844, DOI 10.1121/1.4967297
   Helfer KS, 2014, J ACOUST SOC AM, V136, P748, DOI 10.1121/1.4887463
   Humes LE, 2006, J ACOUST SOC AM, V120, P2926, DOI 10.1121/1.2354070
   Lin G, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00124
   Rajan R, 2008, NEUROSCIENCE, V154, P784, DOI 10.1016/j.neuroscience.2008.03.067
   Sharma S., 2017, INT J RES MED SCI, V5, P13, DOI [10.18203/2320-6012.ijrms20164525, DOI 10.18203/2320-6012.IJRMS20164525]
   Shojaei Elahe, 2016, Med J Islam Repub Iran, V30, P342
   Smith G. E., 2003, CLIN INTERPRETATION
   Strouse A, 1998, J ACOUST SOC AM, V104, P2385, DOI 10.1121/1.423748
   Swaminathan J, 2015, SCI REP-UK, V5, DOI 10.1038/srep11628
   Terwee CB, 2007, J CLIN EPIDEMIOL, V60, P34, DOI 10.1016/j.jclinepi.2006.03.012
   Ueda K, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-01831-z
   Wightman FL, 2010, J ACOUST SOC AM, V128, P270, DOI 10.1121/1.3436536
   Wilson RH, 2007, J SPEECH LANG HEAR R, V50, P844, DOI 10.1044/1092-4388(2007/059)
   Yost WA, 2017, J ACOUST SOC AM, V141, P2473, DOI 10.1121/1.4979981
NR 30
TC 0
Z9 0
U1 0
U2 0
PU CUREUS INC
PI PALO ALTO
PA PO BOX 61002, PALO ALTO, CA 94306 USA
EI 2168-8184
J9 CUREUS
JI Cureus
PD MAR 21
PY 2020
VL 12
IS 3
AR e7356
DI 10.7759/cureus.7356
PG 14
WC Medicine, General & Internal
SC General & Internal Medicine
GA KW5PC
UT WOS:000521216200009
PM 32328368
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Smith, EG
   Condy, E
   Anderson, A
   Thurm, A
   Manwaring, SS
   Swineford, L
   Gandjbakhche, A
   Redcay, E
AF Smith, Elizabeth G.
   Condy, Emma
   Anderson, Afrouz
   Thurm, Audrey
   Manwaring, Stacy S.
   Swineford, Lauren
   Gandjbakhche, Amir
   Redcay, Elizabeth
TI Functional near-infrared spectroscopy in toddlers: Neural
   differentiation of communicative cues and relation to future language
   abilities
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
DE brain development; fNIRS; gesture; language; speech; toddler
ID CEREBRAL SPECIALIZATION; SPEECH-PERCEPTION; BRAIN RESPONSES; GESTURE;
   WORDS; CHILDREN; CLASSIFICATION
AB The toddler and preschool years are a time of significant development in both expressive and receptive communication abilities. However, little is known about the neurobiological underpinnings of language development during this period, likely due to difficulties acquiring functional neuroimaging data. Functional near-infrared spectroscopy (fNIRS) is a motion-tolerant neuroimaging technique that assesses cortical brain activity and can be used in very young children. Here, we use fNIRS during perception of communicative and noncommunicative speech and gestures in typically developing 2- and 3-year-olds (Study 1, n = 15, n = 12 respectively) and in a sample of 2-year-olds with both fNIRS data collected at age 2 and language outcome data at age 3 (Study 2, n = 18). In Study 1, 2- and 3-year-olds differentiated between communicative and noncommunicative stimuli as well as between speech and gestures in the left lateral frontal region. However, 2-year-olds showed different patterns of activation from 3-year-olds in right medial frontal regions. In Study 2, which included two toddlers identified with early language delays along with 16 typically developing toddlers, neural differentiation of communicative stimuli in the right medial frontal region at age 2 predicted receptive language at age 3. Specifically, after accounting for variance related to verbal ability at age 2, increased neural activation for communicative gestures (vs. both communicative speech and noncommunicative gestures) at age 2 predicted higher receptive language scores at age 3. These results are discussed in the context of the underlying mechanisms of toddler language development and use of fNIRS in prediction of language outcomes.
C1 [Smith, Elizabeth G.; Redcay, Elizabeth] Univ Maryland, College Pk, MD 20742 USA.
   [Smith, Elizabeth G.; Condy, Emma; Anderson, Afrouz; Gandjbakhche, Amir] NICHHD, Bethesda, MD 20892 USA.
   [Thurm, Audrey] NIMH, Bethesda, MD 20892 USA.
   [Manwaring, Stacy S.] Univ Utah, Salt Lake City, UT USA.
   [Swineford, Lauren] Washington State Univ, Spokane, WA USA.
RP Smith, EG (corresponding author), Univ Maryland, Dept Human Dev & Quantitat Methodol, 3304 Benjamin Bldg, College Pk, MD 20740 USA.
EM esmith23@umd.edu
OI Smith, Elizabeth/0000-0003-4661-0050
FU National Institutes of Health Intramural Research ProgramUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USA [11-M-0144, ZIAMH002868, NCT01339767]; National Institute of
   Mental HealthUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute of Mental Health
   (NIMH); National Institute of Child Health and Human DevelopmentUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH Eunice Kennedy Shriver National Institute of Child
   Health & Human Development (NICHD)
FX National Institutes of Health Intramural Research Program -Protocol
   11-M-0144, Grant/Award Number: ZIAMH002868, NCT01339767; National
   Institute of Mental Health; National Institute of Child Health and Human
   Development
CR Andric M, 2013, NEUROPSYCHOLOGIA, V51, P1619, DOI 10.1016/j.neuropsychologia.2013.03.022
   Arredondo MM, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12377
   Ayaz H., 2010, FUNCTIONAL NEAR INFR
   Ayaz H, 2011, JOVE-J VIS EXP, DOI 10.3791/3443
   Ayaz H, 2010, IEEE ENG MED BIO, P6567, DOI 10.1109/IEMBS.2010.5627113
   Ayaz Hasan, 2005, ANAL SOFTWARE STIMUL
   Bakker M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00059
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bates E, 2002, DEV PSYCHOBIOL, V40, P293, DOI 10.1002/dev.10034
   Bogler C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0101729
   Conboy BT, 2006, DEVELOPMENTAL SCI, V9, pF1, DOI 10.1111/j.1467-7687.2005.00453.x
   Corbetta M, 2008, NEURON, V58, P306, DOI 10.1016/j.neuron.2008.04.017
   Cui X, 2010, NEUROIMAGE, V49, P3039, DOI 10.1016/j.neuroimage.2009.11.050
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   Dick AS, 2012, DEVELOPMENTAL SCI, V15, P165, DOI 10.1111/j.1467-7687.2011.01100.x
   Fava E, 2014, BRAIN SCI, V4, P471, DOI 10.3390/brainsci4030471
   Friedrich M, 2005, J COGNITIVE NEUROSCI, V17, P1785, DOI 10.1162/089892905774589172
   Goldin-Meadow Susan, 2015, Perspect Lang Learn Educ, V22, P50
   Gredeback G, 2010, SOC NEUROSCI-UK, V5, P441, DOI 10.1080/17470910903523327
   Grossmann T, 2013, DEV COGN NEUROS-NETH, V6, P155, DOI 10.1016/j.dcn.2013.09.004
   Grossmann T, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00201
   Hostetter AB, 2011, PSYCHOL BULL, V137, P297, DOI 10.1037/a0022128
   Huppert TJ, 2016, NEUROPHOTONICS, V3, DOI 10.1117/1.NPh.3.1.010401
   Issard C, 2018, DEV COGN NEUROS-NETH, V33, P182, DOI 10.1016/j.dcn.2018.01.009
   Johnson MH, 2011, DEV COGN NEUROS-NETH, V1, P7, DOI 10.1016/j.dcn.2010.07.003
   Konrad K, 2005, NEUROIMAGE, V28, P429, DOI 10.1016/j.neuroimage.2005.06.065
   Kristensen LB, 2013, CEREB CORTEX, V23, P1836, DOI 10.1093/cercor/bhs164
   Kuhl PK, 2010, NEURON, V67, P713, DOI 10.1016/j.neuron.2010.08.038
   Lloyd-Fox S, 2017, DEV COGN NEUROS-NETH, V25, P92, DOI 10.1016/j.dcn.2016.11.005
   Lloyd-Fox S, 2011, J COGNITIVE NEUROSCI, V23, P2521, DOI 10.1162/jocn.2010.21598
   Lloyd-Fox S, 2009, CHILD DEV, V80, P986, DOI 10.1111/j.1467-8624.2009.01312.x
   MILLS DL, 1993, J COGNITIVE NEUROSCI, V5, P317, DOI 10.1162/jocn.1993.5.3.317
   Mills DL, 2004, J COGNITIVE NEUROSCI, V16, P1452, DOI 10.1162/0898929042304697
   Mills DL, 1997, DEV NEUROPSYCHOL, V13, P397, DOI 10.1080/87565649709540685
   Monden Y, 2015, NEUROIMAGE-CLIN, V9, P1, DOI 10.1016/j.nicl.2015.06.011
   Moriguchi Y, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00867
   Mullen E., 1995, MULLEN SCALES EARLY
   Naseer N, 2013, NEUROSCI LETT, V553, P84, DOI 10.1016/j.neulet.2013.08.021
   Ramirez-Esparza N, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01008
   Redcay E, 2008, DEVELOPMENTAL SCI, V11, P237, DOI 10.1111/j.1467-7687.2008.00674.x
   Redcay E, 2016, HUM BRAIN MAPP, V37, P3444, DOI 10.1002/hbm.23251
   Sheehan EA, 2007, BRAIN LANG, V101, P246, DOI 10.1016/j.bandl.2006.11.008
   Shin J, 2016, SCI REP-UK, V6, DOI 10.1038/srep36203
   Soltanlou M, 2017, COGN AFFECT BEHAV NE, V17, P724, DOI 10.3758/s13415-017-0508-x
   Straube B, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0051207
   Sulpizio S, 2018, INFANT BEHAV DEV, V52, P89, DOI 10.1016/j.infbeh.2018.05.009
   Taga G, 2018, NEUROIMAGE, V178, P519, DOI 10.1016/j.neuroimage.2018.05.075
   Woodward AL, 2002, COGNITIVE DEV, V17, P1061, DOI 10.1016/S0885-2014(02)00074-6
   Xu J, 2009, P NATL ACAD SCI USA, V106, P20664, DOI 10.1073/pnas.0909197106
NR 49
TC 0
Z9 0
U1 1
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD NOV
PY 2020
VL 23
IS 6
AR e12948
DI 10.1111/desc.12948
EA MAR 2020
PG 12
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA OU2MM
UT WOS:000520777800001
PM 32048419
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Higgen, FL
   Heine, C
   Krawinkel, L
   Goschl, F
   Engel, AK
   Hummel, FC
   Xue, G
   Gerloff, C
AF Higgen, Focko L.
   Heine, Charlotte
   Krawinkel, Lutz
   Goeschl, Florian
   Engel, Andreas K.
   Hummel, Friedhelm C.
   Xue, Gui
   Gerloff, Christian
TI Crossmodal Congruency Enhances Performance of Healthy Older Adults in
   Visual-Tactile Pattern Matching
SO FRONTIERS IN AGING NEUROSCIENCE
LA English
DT Article
DE aging; elderly; integration; multisensory; rehabilitation
ID AUDIOVISUAL TEMPORAL DISCRIMINATION; MULTISENSORY INTEGRATION; 2-POINT
   DISCRIMINATION; SELECTIVE ATTENTION; SPEECH-PERCEPTION; AGE; VISION;
   HEARING; TOUCH; CORRESPONDENCES
AB One of the pivotal challenges of aging is to maintain independence in the activities of daily life. In order to adapt to changes in the environment, it is crucial to continuously process and accurately combine simultaneous input from different sensory systems, i.e., crossmodal or multisensory integration. With aging, performance decreases in multiple domains, affecting bottom-up sensory processing as well as top-down control. However, whether this decline leads to impairments in crossmodal interactions remains an unresolved question. While some researchers propose that crossmodal interactions degrade with age, others suggest that they are conserved or even gain compensatory importance. To address this question, we compared the behavioral performance of older and young participants in a well-established crossmodal matching task, requiring the evaluation of congruency in simultaneously presented visual and tactile patterns. Older participants performed significantly worse than young controls in the crossmodal task when being stimulated at their individual unimodal visual and tactile perception thresholds. Performance increased with adjustment of stimulus intensities. This improvement was driven by better detection of congruent stimulus pairs, while the detection of incongruent pairs was not significantly enhanced. These results indicate that age-related impairments lead to poor performance in complex crossmodal scenarios and demanding cognitive tasks. Crossmodal congruency effects attenuate the difficulties of older adults in visuotactile pattern matching and might be an important factor to drive the benefits of older adults demonstrated in various crossmodal integration scenarios. Congruency effects might, therefore, be used to develop strategies for cognitive training and neurological rehabilitation.
C1 [Higgen, Focko L.; Heine, Charlotte; Krawinkel, Lutz; Gerloff, Christian] Univ Med Ctr Hamburg Eppendorf, Dept Neurol, Hamburg, Germany.
   [Goeschl, Florian; Engel, Andreas K.] Univ Med Ctr Hamburg Eppendorf, Dept Neurophysiol & Pathophysbl, Hamburg, Germany.
   [Hummel, Friedhelm C.] EPFL, Swiss Fed Inst Technol, Brain Mind Inst, Defitech Chair Clin Neuroengn, Geneva, Switzerland.
   [Hummel, Friedhelm C.] EPFL, Swiss Fed Inst Technol, Ctr Neuroprosthet, Geneva, Switzerland.
   [Hummel, Friedhelm C.] EPFL Valais, Swiss Fed Inst Technol Valais, Clinicpe Romande Readaptat, Defitech Chair Clin Neuroengn,Brain Mind Inst, Sion, Switzerland.
   [Hummel, Friedhelm C.] EPFL Valais, Swiss Fed Inst Technol Valais, Clinicpe Romande Readaptat, Ctr Neuroprosthet, Sion, Switzerland.
   [Hummel, Friedhelm C.] Univ Geneva, Med Sch, Clin Neurosci, Geneva, Switzerland.
   [Xue, Gui] Beijing Normal Univ, State Key Lab Cognit Neurosci & Learning, Beijing, Peoples R China.
RP Higgen, FL (corresponding author), Univ Med Ctr Hamburg Eppendorf, Dept Neurol, Hamburg, Germany.
EM f.higgen@uke.de
FU German Research Foundation (DFG)German Research Foundation (DFG);
   National Science Foundation of China (NSFC)National Natural Science
   Foundation of China (NSFC) [SFB TRR169/A3/B1/B4]; German Research
   Foundation (DFG)German Research Foundation (DFG) [SFB 936/A3/C1/Z1]
FX This work was supported by the German Research Foundation (DFG) and the
   National Science Foundation of China (NSFC) in project Crossmodal
   Learning, SFB TRR169/A3/B1/B4 and by the German Research Foundation
   (DFG) in project SFB 936/A3/C1/Z1.
CR Anguera JA, 2012, CLIN NEUROPHYSIOL, V123, P730, DOI 10.1016/j.clinph.2011.08.024
   Beer AL, 2004, COGN AFFECT BEHAV NE, V4, P230, DOI 10.3758/CABN.4.2.230
   Benjamini Y, 2001, ANN STAT, V29, P1165
   BIRREN JE, 1995, ANNU REV PSYCHOL, V46, P329, DOI 10.1146/annurev.ps.46.020195.001553
   Brunetti R, 2018, ATTEN PERCEPT PSYCHO, V80, P527, DOI 10.3758/s13414-017-1445-z
   Brunetti R, 2017, J EXP PSYCHOL HUMAN, V43, P819, DOI 10.1037/xhp0000348
   Calvert G., 2004, HDB MULTISENSORY PRO
   Calvert GA, 2001, CEREB CORTEX, V11, P1110, DOI 10.1093/cercor/11.12.1110
   CERELLA J, 1985, PSYCHOL BULL, V98, P67, DOI 10.1037/0033-2909.98.1.67
   Cienkowski KM, 2002, EAR HEARING, V23, P439, DOI 10.1097/00003446-200210000-00006
   CROSBY PM, 1989, MICROSURG, V10, P134, DOI 10.1002/micr.1920100214
   Davis A, 2016, GERONTOLOGIST, V56, pS256, DOI 10.1093/geront/gnw033
   DELLON ES, 1995, J HAND SURG-BRIT EUR, V20B, P44, DOI 10.1016/S0266-7681(05)80015-4
   Diaconescu AO, 2013, NEUROIMAGE, V65, P152, DOI 10.1016/j.neuroimage.2012.09.057
   Diederich A, 2008, NEUROPSYCHOLOGIA, V46, P2556, DOI 10.1016/j.neuropsychologia.2008.03.026
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Fraser S, 2013, WIRES COGN SCI, V4, P623, DOI 10.1002/wcs.1252
   Freiherr J, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00863
   Frings C, 2010, BRAIN RES, V1354, P113, DOI 10.1016/j.brainres.2010.07.058
   Fruhstorfer H, 2001, EUR J PAIN-LONDON, V5, P341, DOI 10.1053/eujp.2001.0250
   Gallace A., 2014, TOUCH FUTURE SENSE T
   Garcia-Perez MA, 1998, VISION RES, V38, P1861, DOI 10.1016/S0042-6989(97)00340-4
   Gazzaley A, 2005, NAT NEUROSCI, V8, P1298, DOI 10.1038/nn1543
   Goschl F, 2015, NEUROIMAGE, V116, P177, DOI 10.1016/j.neuroimage.2015.03.067
   Goschl F, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0106896
   Guerreiro MJS, 2014, J COGNITIVE NEUROSCI, V26, P2827, DOI 10.1162/jocn_a_00685
   Hairston WD, 2003, EXP BRAIN RES, V152, P404, DOI 10.1007/s00221-003-1646-7
   Hein G, 2004, PSYCHOL AGING, V19, P416, DOI 10.1037/0882-7974.19.3.416
   Higgen F. L., 2019, BIORXIV PREPRINT, DOI [10.1101/673491, DOI 10.1101/673491]
   Holmes NP, 2005, CURR BIOL, V15, pR762, DOI 10.1016/j.cub.2005.08.058
   Hugenschmidt CE, 2009, BRAIN TOPOGR, V21, P241, DOI 10.1007/s10548-009-0098-1
   Hugenschmidt CE, 2009, NEUROREPORT, V20, P349, DOI 10.1097/WNR.0b013e328323ab07
   Humes LE, 2009, ATTEN PERCEPT PSYCHO, V71, P860, DOI 10.3758/APP.71.4.860
   Hummel FC, 2006, PROG BRAIN RES, V159, P223, DOI 10.1016/S0079-6123(06)59015-6
   Jackson GR, 2003, NEUROL CLIN, V21, P709, DOI 10.1016/S0733-8619(02)00107-X
   KAERNBACH C, 1991, PERCEPT PSYCHOPHYS, V49, P227, DOI 10.3758/BF03214307
   Kalbe E, 2004, INT J GERIATR PSYCH, V19, P136, DOI 10.1002/gps.1042
   Kalina RE, 1997, WESTERN J MED, V167, P253
   KENSHALO DR, 1986, J GERONTOL, V41, P732, DOI 10.1093/geronj/41.6.732
   Laurienti PJ, 2006, NEUROBIOL AGING, V27, P1155, DOI 10.1016/j.neurobiolaging.2005.05.024
   Lee JH, 2009, LECT NOTES COMPUT SC, V5763, P128
   List A., 2012, J VIS, V12, P1320, DOI [10.1167/12.9.1320, DOI 10.1167/12.9.1320]
   Mahoney JR, 2011, BRAIN RES, V1426, P43, DOI 10.1016/j.brainres.2011.09.017
   Mancini D. J., 2018, FRACTURES ELDERLY GU, P65
   McGovern DP, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00250
   MEREDITH MA, 1983, SCIENCE, V221, P389, DOI 10.1126/science.6867718
   MEREDITH MA, 1986, J NEUROPHYSIOL, V56, P640
   MILLER J, 1986, PERCEPT PSYCHOPHYS, V40, P331, DOI 10.3758/BF03203025
   MILLER J, 1982, COGNITIVE PSYCHOL, V14, P247, DOI 10.1016/0010-0285(82)90010-X
   Misselhorn J, 2016, NEUROPSYCHOLOGIA, V88, P113, DOI 10.1016/j.neuropsychologia.2015.07.022
   Mozolic J. L., 2012, FRONTIERS NEUROSCIEN, P381
   Oie KS, 2002, COGNITIVE BRAIN RES, V14, P164, DOI 10.1016/S0926-6410(02)00071-X
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Peiffer AM, 2007, NEUROREPORT, V18, P1077, DOI 10.1097/WNR.0b013e3281e72ae7
   Poliakoff E, 2006, NEUROPSYCHOLOGIA, V44, P507, DOI 10.1016/j.neuropsychologia.2005.07.004
   Poliakoff E, 2006, NEUROSCI LETT, V396, P207, DOI 10.1016/j.neulet.2005.11.034
   Poole D, 2015, MULTISENS RES, V28, P227, DOI 10.1163/22134808-00002475
   R Core Team, 2017, R LANG ENV STAT COMP
   Rolke R, 2006, EUR J PAIN, V10, P77, DOI 10.1016/j.ejpain.2005.02.003
   Salthouse TA, 2000, BIOL PSYCHOL, V54, P35, DOI 10.1016/S0301-0511(00)00052-1
   Schiffman SS, 1997, JAMA-J AM MED ASSOC, V278, P1357, DOI 10.1001/jama.278.16.1357
   Setti A, 2014, NEUROPSYCHOLOGIA, V61, P259, DOI 10.1016/j.neuropsychologia.2014.06.027
   Setti A, 2011, NEUROREPORT, V22, P554, DOI 10.1097/WNR.0b013e328348c731
   Shore DI, 2005, EXP BRAIN RES, V166, P509, DOI 10.1007/s00221-005-2391-x
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   Spence C., 2012, MULTISENSORY DEV, P63
   Spence C., 2008, HAPTIC RENDERING FDN, P21, DOI DOI 10.1201/B10636-4
   Spence C, 2007, ACOUST SCI TECHNOL, V28, P61, DOI 10.1250/ast.28.61
   Spence C, 2004, COGN AFFECT BEHAV NE, V4, P148, DOI 10.3758/CABN.4.2.148
   Spence C, 2013, CONSCIOUS COGN, V22, P245, DOI 10.1016/j.concog.2012.12.006
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Stephen JM, 2010, NEUROSCI LETT, V484, P76, DOI 10.1016/j.neulet.2010.08.023
   STINE EAL, 1990, J GERONTOL, V45, pP1, DOI 10.1093/geronj/45.1.P1
   Tipper SP, 1998, NEUROREPORT, V9, P1741, DOI 10.1097/00001756-199806010-00013
   TREUTWEIN B, 1995, VISION RES, V35, P2503, DOI 10.1016/0042-6989(95)00016-S
   Venkatesan UM, 2018, J INT NEUROPSYCH SOC, V24, P486, DOI 10.1017/S1355617717001291
   Verhaeghen P, 1998, PSYCHOL AGING, V13, P120, DOI 10.1037/0882-7974.13.1.120
   Voytek B, 2015, BIOL PSYCHIAT, V77, P1089, DOI 10.1016/j.biopsych.2015.04.016
   Wang P, 2019, NEUROIMAGE, V196, P114, DOI 10.1016/j.neuroimage.2019.04.001
   WATSON AB, 1983, PERCEPT PSYCHOPHYS, V33, P113, DOI 10.3758/BF03202828
   WETHERILL GB, 1965, BRIT J MATH STAT PSY, V18, P1, DOI 10.1111/j.2044-8317.1965.tb00689.x
   Wickremaratchi MM, 2006, POSTGRAD MED J, V82, P301, DOI 10.1136/pgmj.2005.039651
NR 82
TC 3
Z9 3
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1663-4365
J9 FRONT AGING NEUROSCI
JI Front. Aging Neurosci.
PD MAR 17
PY 2020
VL 12
AR 74
DI 10.3389/fnagi.2020.00074
PG 12
WC Geriatrics & Gerontology; Neurosciences
SC Geriatrics & Gerontology; Neurosciences & Neurology
GA LC7XT
UT WOS:000525547400001
PM 32256341
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Patri, JF
   Ostry, DJ
   Diard, J
   Schwartz, JL
   Trudeau-Fisette, P
   Savariaux, C
   Perrier, P
AF Patri, Jean-Francois
   Ostry, David J.
   Diard, Julien
   Schwartz, Jean-Luc
   Trudeau-Fisette, Pamela
   Savariaux, Christophe
   Perrier, Pascal
TI Speakers are able to categorize vowels based on tongue somatosensation
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
LA English
DT Article
DE speech production; somatosensory feedback; categorical perception
ID NORMAL-HEARING; SPEECH SOUNDS; HAND
AB Auditory speech perception enables listeners to access phonological categories from speech sounds. During speech production and speech motor learning, speakers' experience matched auditory and somatosensory input. Accordingly, access to phonetic units might also be provided by somatosensory information. The present study assessed whether humans can identify vowels using somatosensory feedback, without auditory feedback. A tongue-positioning task was used in which participants were required to achieve different tongue postures within the /e, epsilon, a/ articulatory range, in a procedure that was totally non speech like, involving distorted visual feedback of tongue shape. Tongue postures were measured using electromagnetic articulography. At the end of each tongue-positioning trial, subjects were required to whisper the corresponding vocal tract configuration with masked auditory feedback and to identify the vowel associated with the reached tongue posture. Masked auditory feedback ensured that vowel categorization was based on somatosensory feedback rather than auditory feedback. A separate group of subjects was required to auditorily classify the whispered sounds. In addition, we modeled the link between vowel categories and tongue postures in normal speech production with a Bayesian classifier based on the tongue postures recorded from the same speakers for several repetitions of the /e, epsilon, a/ vowels during a separate speech production task. Overall, our results indicate that vowel categorization is possible with somatosensory feedback alone, with an accuracy that is similar to the accuracy of the auditory perception of whispered sounds, and in congruence with normal speech articulation, as accounted for by the Bayesian classifier.
C1 [Patri, Jean-Francois; Schwartz, Jean-Luc; Savariaux, Christophe; Perrier, Pascal] Univ Grenoble Alpes, Grenoble INP, GIPSA Lab, CNRS,UMR 5216, F-38000 Grenoble, France.
   [Patri, Jean-Francois] Fdn Ist Italiano Tecnol, Cognit Mot & Neurosci Unit, I-16152 Genoa, Italy.
   [Ostry, David J.] McGill Univ, Dept Psychol, Montreal, PQ H3A 1G1, Canada.
   [Ostry, David J.] Haskins Labs Inc, New Haven, CT 06511 USA.
   [Diard, Julien] Univ Grenoble Alpes, Lab Psychol & Neurocognit LPNC, CNRS, UMR 5105, F-38000 Grenoble, France.
   [Trudeau-Fisette, Pamela] Univ Quebec Montreal, Ctr Res Brain Language & Mus, Lab Phonet, Montreal, PQ H2X 1L7, Canada.
RP Perrier, P (corresponding author), Univ Grenoble Alpes, Grenoble INP, GIPSA Lab, CNRS,UMR 5216, F-38000 Grenoble, France.
EM Pascal.Perrier@grenoble-inp.fr
RI Perrier, Pascal/AAQ-2687-2020
OI Perrier, Pascal/0000-0003-2192-4176; Diard, Julien/0000-0003-0673-477X
FU European Research Council under the European Community's Seventh
   Framework Program (FP7/2007-2013 grant) [339152]; European Union's
   Horizon 2020 research and innovation program under the Marie
   Sklokodowska-Curie grant [754490]; National Institute on Deafness and
   Other Communication DisordersUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC017439];
   NeuroCoG "IDEX Universite Grenoble Alpes: universite de l'innovation"
   [ANR-15-IDEX-02]
FX The research leading to these results has received funding from the
   European Research Council under the European Community's Seventh
   Framework Program (FP7/2007-2 013 grant agreement 339152, "Speech
   Unit(e)s"; principal investigator, Jean-Luc Schwartz), from the European
   Union's Horizon 2020 research and innovation program under the Marie
   Sklokodowska-Curie grant agreement 754490 (MultIscale precision
   therapies for NeuroDEvelopmental Disorders [MINDED] Program), and from
   the National Institute on Deafness and Other Communication Disorders
   grant R01DC017439. It was also supported by NeuroCoG "IDEX Universite
   Grenoble Alpes: universite de l'innovation" in the framework of the
   "Investissements d'avenir" program (ANR-15-IDEX-02). The funders had no
   role in study design, data collection and analysis, decision to publish,
   or preparation of the manuscript.
CR BERNSTEIN LE, 1991, J ACOUST SOC AM, V90, P2971, DOI 10.1121/1.401771
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Ernst MD, 2004, STAT SCI, V19, P676, DOI 10.1214/088342304000000396
   FOWLER CA, 1991, J EXP PSYCHOL HUMAN, V17, P816, DOI 10.1037/0096-1523.17.3.816
   GAY T, 1981, J ACOUST SOC AM, V69, P802, DOI 10.1121/1.385591
   Gick B, 2009, NATURE, V462, P502, DOI 10.1038/nature08572
   Guenther FH, 2006, BRAIN LANG, V96, P280, DOI 10.1016/j.bandl.2005.06.001
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158
   Houde JF, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00082
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   Keating P, 1990, PAPERS LAB PHONOLOGY, P451, DOI DOI 10.1017/CBO9780511627736
   Kroger BJ, 2009, SPEECH COMMUN, V51, P793, DOI 10.1016/j.specom.2008.08.002
   Ladefoged Peter, 1996, SOUNDS WORLDS LANGUA
   LEDERMAN SJ, 1987, COGNITIVE PSYCHOL, V19, P342, DOI 10.1016/0010-0285(87)90008-9
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   Nasir SM, 2006, CURR BIOL, V16, P1918, DOI 10.1016/j.cub.2006.07.069
   Parrell B, 2019, PLOS COMPUT BIOL, V15, DOI 10.1371/journal.pcbi.1007321
   Patri JF, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005942
   Perkell JS, 2000, J PHONETICS, V28, P233, DOI 10.1006/jpho.2000.0116
   PISONI DB, 1979, BRAIN BEHAV EVOLUT, V16, P330, DOI 10.1159/000121875
   Recasens D., 2005, J INT PHON ASSOC, V35, DOI [DOI 10.1017/S0025100305001878, 10.1017/S0025100305001878]
   Robert-Ribes J, 1998, J ACOUST SOC AM, V103, P3677, DOI 10.1121/1.423069
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   SAVARIAUX C, 1995, J ACOUST SOC AM, V98, P2428, DOI 10.1121/1.413277
   Tian X, 2015, J COGNITIVE NEUROSCI, V27, P352, DOI 10.1162/jocn_a_00692
   Tian X, 2013, J COGNITIVE NEUROSCI, V25, P1020, DOI 10.1162/jocn_a_00381
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   Tremblay S, 2003, NATURE, V423, P866, DOI 10.1038/nature01710
   Wolpert DM, 1998, TRENDS COGN SCI, V2, P338, DOI 10.1016/S1364-6613(98)01221-2
NR 29
TC 1
Z9 1
U1 2
U2 4
PU NATL ACAD SCIENCES
PI WASHINGTON
PA 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA
SN 0027-8424
J9 P NATL ACAD SCI USA
JI Proc. Natl. Acad. Sci. U. S. A.
PD MAR 17
PY 2020
VL 117
IS 11
BP 6255
EP 6263
DI 10.1073/pnas.1911142117
PG 9
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA KU9AG
UT WOS:000520011000091
PM 32123070
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Szabo, IE
AF Szabo, Ildiko Emese
TI A computational model of phonotactic acquisition Predictability of
   exceptional patterns in Hungarian
SO LINGUISTIC VARIATION
LA English
DT Article
DE phonotactics; exceptionality; functional load; perception; Hungarian
ID SPEECH-PERCEPTION; FUNCTIONAL LOAD; SOUND CHANGE; 1ST YEAR; CONSTRAINTS
AB This paper presents a model that connects phonotactic exceptionality to perceptibility, more specifically to functional load and acoustic detail. I identify two patterns in exceptionality: lexical exceptions and phonotactic vacillation, where the former is restricted to specific lexical items, while the latter affects two contrastive sound categories as a whole. Through the example of Hungarian word-final phonotactics, the Model of Perceptual Categorization associates these two patterns with different functional load and acoustic properties of contrasts, that lead to two categorizational malfunctions. On the one hand, phonotactic vacillation is a result of a frequent failure to categorize ambiguous tokens: low functional load coinciding with little acoustic difference. On the other hand, lexical exceptions are systematic categorizational mistakes brought about by salient categories - in this case distributional generalizations are hindered by interference from mislabeled tokens.
C1 [Szabo, Ildiko Emese] NYU, 10 Washington Pl, New York, NY 10003 USA.
RP Szabo, IE (corresponding author), NYU, 10 Washington Pl, New York, NY 10003 USA.
EM ildi.szabo@nyu.edu
CR Anttila A, 2002, NAT LANG LINGUIST TH, V20, P1, DOI 10.1023/A:1014245408622
   Blevins J, 2009, DIACHRONICA, V26, P143, DOI 10.1075/dia.26.2.01ble
   Boersma P., 2010, PRAAT DOING PHONETIC
   Boersma Paul, 2016, HARMONIC GRAMMAR HAR
   Bybee J., 2001, PHONOLOGY LANGUAGE U, DOI [10.1017/CBO9780511612886, DOI 10.1017/CBO9780511612886, 10.1017/CB09780511612886]
   CEDERGREN HJ, 1974, LANGUAGE, V50, P333, DOI 10.2307/412441
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Clements George N., 1995, HDB PHONOLOGICAL THE, P245
   FELDMAN N, 2007, P 29 ANN C COGN SCI
   Gervain J, 2010, ANNU REV PSYCHOL, V61, P191, DOI 10.1146/annurev.psych.093008.100408
   Gouskova Maria, 2003, THESIS
   Halacsy P, 2004, P 4 INT C LANG RES E, P203
   Hayes B, 2009, LANGUAGE, V85, P822
   Hayes Bruce, 1995, METRICAL STRESS THEO
   Hockett C. F., 1955, MANUAL PHONOLOGY
   It Junko, 1999, HDB JAPANESE LINGUIS, P62
   Kaplan A, 2011, J LINGUIST, V47, P631, DOI 10.1017/S0022226711000053
   KAY P, 1979, LANG SOC, V8, P151, DOI 10.1017/S0047404500007429
   Kaye J., 1990, J LINGUIST, V7, P255
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   Mady Katalin, 2010, P SOC CROSSR SPEECH
   Mady Katalin, 2007, P INT C PHON SCI
   Martin A, 2013, COGNITIVE SCI, V37, P103, DOI 10.1111/j.1551-6709.2012.01267.x
   Martinet A, 1952, WORD, V8, P1
   Martinet Andre, 1968, PHONETICS LINGUISTIC, P464
   McCarthy John, 1993, YB MORPHOLOGY, P79, DOI DOI 10.1007/978-94-017-3712-8_4
   Mielke J., 2008, EMERGENCE DISTINCTIV
   Nadasdy A., 1994, STRUKTURALIS MAGYAR, V2, P42
   OHALA JJ, 1993, SPEECH COMMUN, V13, P155, DOI 10.1016/0167-6393(93)90067-U
   Ohala John, 1981, PAPERS PARASESSION L, P178
   Pater J, 2009, COGNITIVE SCI, V33, P999, DOI 10.1111/j.1551-6709.2009.01047.x
   Pater Joe, 1994, TORONTO WORKING PAPE, V13
   Pater Joe, 2000, PHONOLOGY, V17, P237, DOI DOI 10.1017/S0952675700003900
   Pater Joe, 2004, C RED EL NOV DAT PHO
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Prince Alan, 1993, OPTIMALITY THEORY CO
   Pulleyblank Douglas, 2003, WCCFL 22, V22, P398
   SANKOFF D, 1979, LANG SOC, V8, P189, DOI 10.1017/S0047404500007430
   Sankoff D., 1978, LINGUISTIC VARIATION, P71
   Siptar Peter, 2000, PHONOLOGY HUNGARIAN
   Steriade D., 1999, UCLA WORKING PAPERS, V2, P25
   STUDDERTKENNEDY M, 1970, PSYCHOL REV, V77, P234, DOI 10.1037/h0029078
   Szabo Ildiko Emese, 2015, THESIS
   Torkenczy Miklos, 2006, THESIS
   TRUBETZKOY N, 1939, PRINCIPLES PHONOLOGY
   Wedel A, 2013, LANG SPEECH, V56, P395, DOI 10.1177/0023830913489096
   Wedel A, 2013, COGNITION, V128, P179, DOI 10.1016/j.cognition.2013.03.002
   Wedel Andrew, 2004, THESIS
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   White James, 2014, 65 WORKSH LEARN BIAS
   Zipf G.K., 1949, HUMAN BEHAV PRINCIPL
NR 51
TC 0
Z9 0
U1 0
U2 0
PU JOHN BENJAMINS PUBLISHING CO
PI AMSTERDAM
PA PO BOX 36224, 1020 ME AMSTERDAM, NETHERLANDS
SN 2211-6834
EI 2211-6842
J9 LINGUIST VAR
JI Linguist. Var.
PD MAR 16
PY 2020
VL 20
IS 1
BP 3
EP 32
DI 10.1075/lv.16011.sza
PG 30
WC Language & Linguistics
SC Linguistics
GA KW0FR
UT WOS:000520849500002
DA 2021-02-24
ER

PT J
AU Schwering, SC
   MacDonald, MC
AF Schwering, Steven C.
   MacDonald, Maryellen C.
TI Verbal Working Memory as Emergent from Language Comprehension and
   Production
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE working memory; language comprehension; language production; serial
   order; long-term memory; lexical representations
ID SHORT-TERM-MEMORY; IMMEDIATE SERIAL-RECALL; LONG-TERM; NONWORD
   REPETITION; WORD-FREQUENCY; PHONOLOGICAL SIMILARITY;
   INDIVIDUAL-DIFFERENCES; SELECTIVE IMPAIRMENT; SPEECH-PERCEPTION; DEEP
   DYSPHASIA
AB This article reviews current models of verbal working memory and considers the role of language comprehension and long-term memory in the ability to maintain and order verbal information for short periods of time. While all models of verbal working memory posit some interaction with long-term memory, few have considered the character of these long-term representations or how they might affect performance on verbal working memory tasks. Similarly, few models have considered how comprehension processes and production processes might affect performance in verbal working memory tasks. Modern theories of comprehension emphasize that people learn a vast web of correlated information about the language and the world and must activate that information from long-term memory to cope with the demands of language input. To date, there has been little consideration in theories of verbal working memory for how this rich input from comprehension would affect the nature of temporary memory. There has also been relatively little attention to the degree to which language production processes naturally manage serial order of verbal information. The authors argue for an emergent model of verbal working memory supported by a rich, distributed long-term memory for language. On this view, comprehension processes provide encoding in verbal working memory tasks, and production processes maintenance, serial ordering, and recall. Moreover, the computational capacity to maintain and order information varies with language experience. Implications for theories of working memory, comprehension, and production are considered.
C1 [Schwering, Steven C.; MacDonald, Maryellen C.] Univ Wisconsin Madison, Dept Psychol, Madison, WI 53706 USA.
RP MacDonald, MC (corresponding author), Univ Wisconsin Madison, Dept Psychol, Madison, WI 53706 USA.
EM mcmacdonald@wisc.edu
FU NSFNational Science Foundation (NSF) [1849236]
FX Preparation of this work was supported by NSF Grant number 1849236.
CR Aben B, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00301
   Acheson DJ, 2011, J COGNITIVE NEUROSCI, V23, P1358, DOI 10.1162/jocn.2010.21519
   Acheson DJ, 2011, J EXP PSYCHOL LEARN, V37, P44, DOI 10.1037/a0021205
   Acheson DJ, 2010, J EXP PSYCHOL LEARN, V36, P17, DOI 10.1037/a0017679
   Acheson DJ, 2009, J MEM LANG, V60, P329, DOI 10.1016/j.jml.2008.12.002
   Acheson DJ, 2009, PSYCHOL BULL, V135, P50, DOI 10.1037/a0014411
   Allen J, 1999, CARN S COGN, P115
   Allen R, 2006, J MEM LANG, V55, P64, DOI 10.1016/j.jml.2006.02.002
   Allen RJ, 2018, Q J EXP PSYCHOL, V71, P2571, DOI 10.1177/1747021817746929
   ALLPORT DA, 1981, PHILOS T ROY SOC B, V295, P397, DOI 10.1098/rstb.1981.0148
   Almeida R. G. D., 2018, CONCEPTS MODULES LAN
   Altmann GTM, 2009, COGNITIVE SCI, V33, P583, DOI 10.1111/j.1551-6709.2009.01022.x
   Anderson ND, 2019, J MEM LANG, V106, P135, DOI 10.1016/j.jml.2019.03.002
   Anderson ND, 2018, P NATL ACAD SCI USA, V115, P3617, DOI 10.1073/pnas.1721107115
   Archibald LMD, 2006, J SPEECH LANG HEAR R, V49, P970, DOI 10.1044/1092-4388(2006/070)
   Arnon I, 2010, J MEM LANG, V62, P67, DOI 10.1016/j.jml.2009.09.005
   Attout L, 2019, HUM BRAIN MAPP, V40, P1541, DOI 10.1002/hbm.24466
   Attout L, 2012, APHASIOLOGY, V26, P355, DOI 10.1080/02687038.2011.604303
   Baayen RH, 2016, LANG COGN NEUROSCI, V31, P106, DOI 10.1080/23273798.2015.1065336
   Babyonyshev M, 1999, LANGUAGE, V75, P423, DOI 10.2307/417056
   BADDELEY A, 1984, Q J EXP PSYCHOL-A, V36, P233, DOI 10.1080/14640748408402157
   Baddeley A, 2000, TRENDS COGN SCI, V4, P417, DOI 10.1016/S1364-6613(00)01538-2
   Baddeley AD, 2009, J MEM LANG, V61, P438, DOI 10.1016/j.jml.2009.05.004
   BADDELEY AD, 1970, J VERB LEARN VERB BE, V9, P176, DOI 10.1016/S0022-5371(70)80048-2
   BADDELEY AD, 1966, Q J EXP PSYCHOL, V18, P302, DOI 10.1080/14640746608400047
   BADDELEY AD, 1975, J VERB LEARN VERB BE, V14, P575, DOI 10.1016/S0022-5371(75)80045-4
   Baddeley A, 2010, CURR BIOL, V20, pR136, DOI 10.1016/j.cub.2009.12.014
   Barthel M, 2019, COGNITIVE SCI, V43, DOI 10.1111/cogs.12768
   BASSO A, 1982, NEUROPSYCHOLOGIA, V20, P263, DOI 10.1016/0028-3932(82)90101-4
   BOCK JK, 1986, J EXP PSYCHOL LEARN, V12, P575, DOI 10.1037/0278-7393.12.4.575
   BOCK JK, 1986, COGNITIVE PSYCHOL, V18, P355, DOI 10.1016/0010-0285(86)90004-6
   BOCK K, 1987, J MEM LANG, V26, P119, DOI 10.1016/0749-596X(87)90120-3
   Boiteau TW, 2014, J EXP PSYCHOL GEN, V143, P295, DOI 10.1037/a0031858
   Botvinick M, 2005, J EXP PSYCHOL LEARN, V31, P351, DOI 10.1037/0278-7393.31.2.351
   Botvinick MM, 2009, PSYCHOL REV, V116, P998, DOI 10.1037/a0017113
   Botvinick MM, 2006, PSYCHOL REV, V113, P201, DOI 10.1037/0033-295X.113.2.201
   Brener R, 1940, J EXP PSYCHOL, V26, P467, DOI 10.1037/h0061096
   Buchsbaum BR, 2019, CORTEX, V112, P134, DOI 10.1016/j.cortex.2018.11.010
   Bybee J, 2005, LINGUIST REV, V22, P381, DOI 10.1515/tlir.2005.22.2-4.381
   Caplan D, 2013, PSYCHON B REV, V20, P243, DOI 10.3758/s13423-012-0369-9
   Casalini C, 2007, CORTEX, V43, P769, DOI 10.1016/S0010-9452(08)70505-7
   CASSIDY KW, 1991, J MEM LANG, V30, P348, DOI 10.1016/0749-596X(91)90041-H
   CAVE CB, 1992, HIPPOCAMPUS, V2, P151, DOI 10.1002/hipo.450020207
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234
   Chang F, 2000, J PSYCHOLINGUIST RES, V29, P217, DOI 10.1023/A:1005101313330
   Christiansen MH, 1998, LANG COGNITIVE PROC, V13, P221, DOI 10.1080/016909698386528
   Christiansen MH, 2016, TOP COGN SCI, V8, P610, DOI 10.1111/tops.12164
   Clarkson L, 2017, MEMORY, V25, P391, DOI 10.1080/09658211.2016.1179330
   COLTHEART V, 1993, MEM COGNITION, V21, P539, DOI 10.3758/BF03197185
   CONNINE CM, 1987, J EXP PSYCHOL HUMAN, V13, P291, DOI 10.1037/0096-1523.13.2.291
   COWAN N, 1993, MEM COGNITION, V21, P162, DOI 10.3758/BF03202728
   Cowan N, 2017, PSYCHON B REV, V24, P1158, DOI 10.3758/s13423-016-1191-6
   Cowan N, 2008, PROG BRAIN RES, V169, P323, DOI 10.1016/S0079-6123(07)00020-9
   CRAIK FIM, 1972, J VERB LEARN VERB BE, V11, P671, DOI 10.1016/S0022-5371(72)80001-X
   CROWDER RG, 1993, MEM COGNITION, V21, P142, DOI 10.3758/BF03202725
   DANEMAN M, 1980, J VERB LEARN VERB BE, V19, P450, DOI 10.1016/S0022-5371(80)90312-6
   Dapretto M, 1999, NEURON, V24, P427, DOI 10.1016/S0896-6273(00)80855-7
   De Ruiter JP, 2006, LANGUAGE, V82, P515, DOI 10.1353/lan.2006.0130
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394
   Dell GS, 1997, PSYCHOL REV, V104, P801, DOI 10.1037/0033-295X.104.4.801
   DELL GS, 1986, PSYCHOL REV, V93, P283, DOI 10.1037/0033-295X.93.3.283
   DELL GS, 1981, J VERB LEARN VERB BE, V20, P611, DOI 10.1016/S0022-5371(81)90202-4
   Dell GS, 1997, PSYCHOL REV, V104, P123, DOI 10.1037/0033-295X.104.1.123
   Dell GS, 2000, J EXP PSYCHOL LEARN, V26, P1355, DOI 10.1037//0278-7393.26.6.1355
   DELL GS, 1984, J EXP PSYCHOL LEARN, V10, P222, DOI 10.1037/0278-7393.10.2.222
   Demberg V, 2008, COGNITION, V109, P193, DOI 10.1016/j.cognition.2008.07.008
   Dikker S, 2010, PSYCHOL SCI, V21, P629, DOI 10.1177/0956797610367751
   Duff MC, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00069
   Ebbinghaus H., 1885, MEMORY CONTRIBUTION
   Edwards J, 2004, J SPEECH LANG HEAR R, V47, P421, DOI 10.1044/1092-4388(2004/034)
   ELLIS AW, 1980, J VERB LEARN VERB BE, V19, P624, DOI 10.1016/S0022-5371(80)90672-6
   ELMAN JL, 1991, MACH LEARN, V7, P195, DOI 10.1007/BF00114844
   EPSTEIN W, 1962, AM J PSYCHOL, V75, P121, DOI 10.2307/1419550
   EPSTEIN W, 1961, AM J PSYCHOL, V74, P80, DOI 10.2307/1419827
   Estes KG, 2007, J SPEECH LANG HEAR R, V50, P177, DOI 10.1044/1092-4388(2007/015)
   Farmer TA, 2006, P NATL ACAD SCI USA, V103, P12203, DOI 10.1073/pnas.0602173103
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x
   Fedorenko E, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00335
   Fedorenko E, 2011, P NATL ACAD SCI USA, V108, P16428, DOI 10.1073/pnas.1112937108
   Fine AB, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077661
   Fischer-Baum S, 2018, PSYCHOL LEARN MOTIV, V68, P31, DOI 10.1016/bs.plm.2018.08.002
   Fischer-Baum S, 2015, J EXP PSYCHOL LEARN, V41, P1426, DOI 10.1037/xlm0000102
   Forster K. I., 1985, LANG COGNITIVE PROC, V1, P87, DOI DOI 10.1080/01690968508402073
   Frank MC, 2014, COGNITIVE PSYCHOL, V75, P80, DOI 10.1016/j.cogpsych.2014.08.002
   FRAZIER L, 1987, ATTENTION PERFORM, P559
   Gathercole SE, 1999, J EXP PSYCHOL LEARN, V25, P84, DOI 10.1037/0278-7393.25.1.84
   Gennari SP, 2012, COGNITIVE PSYCHOL, V65, P141, DOI 10.1016/j.cogpsych.2012.03.002
   Gibson E, 1998, COGNITION, V68, P1, DOI 10.1016/S0010-0277(98)00034-1
   Glaser YG, 2013, BRAIN LANG, V126, P314, DOI 10.1016/j.bandl.2013.06.006
   Graves WW, 2010, NEUROIMAGE, V53, P638, DOI 10.1016/j.neuroimage.2010.06.055
   Grodner D, 2005, COGNITIVE SCI, V29, P261, DOI 10.1207/s15516709cog0000_7
   Guerrette MC, 2018, MEM COGNITION, V46, P1389, DOI 10.3758/s13421-018-0844-2
   Guidali G, 2019, CORTEX, V119, P89, DOI 10.1016/j.cortex.2019.04.009
   Gupta P, 2009, J MEM LANG, V61, P481, DOI 10.1016/j.jml.2009.08.001
   Hannula DE, 2006, J NEUROSCI, V26, P8352, DOI 10.1523/JNEUROSCI.5222-05.2006
   Hartley T, 1996, J MEM LANG, V35, P1, DOI 10.1006/jmla.1996.0001
   Hartley T, 2016, COGNITIVE PSYCHOL, V87, P135, DOI 10.1016/j.cogpsych.2016.05.001
   Hasson U, 2015, TRENDS COGN SCI, V19, P304, DOI 10.1016/j.tics.2015.04.006
   Hebb D. O., 1961, BRAIN MECH LEARN, P37, DOI DOI 10.5962/BHL.TITLE.7220
   Henson R, 2003, Q J EXP PSYCHOL-A, V56, P1307, DOI 10.1080/02724980244000747
   Hepner CR, 2019, J MEM LANG, V106, P172, DOI 10.1016/j.jml.2019.03.003
   HINTON GE, 1991, PSYCHOL REV, V98, P74, DOI 10.1037/0033-295X.98.1.74
   Hoffman P, 2009, NEUROPSYCHOLOGIA, V47, P747, DOI 10.1016/j.neuropsychologia.2008.12.001
   Howard D, 2005, COGN NEUROPSYCHOL, V22, P42, DOI 10.1080/02643290342000582
   Hsiao YL, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01015
   Hughes RW, 2016, J MEM LANG, V90, P126, DOI 10.1016/j.jml.2016.04.006
   HULME C, 1989, J EXP CHILD PSYCHOL, V47, P72, DOI 10.1016/0022-0965(89)90063-5
   Hulme C, 1997, J EXP PSYCHOL LEARN, V23, P1217, DOI 10.1037/0278-7393.23.5.1217
   Hurlstone MJ, 2014, PSYCHOL BULL, V140, P339, DOI 10.1037/a0034221
   Ingvalson EM, 2015, J ACOUST SOC AM, V137, P3477, DOI 10.1121/1.4921601
   Jacquemot C, 2006, COGN NEUROPSYCHOL, V23, P949, DOI 10.1080/02643290600625749
   Jefferies E, 2005, COGN NEUROPSYCHOL, V22, P183, DOI 10.1080/02643290442000068
   Joanisse MF, 2015, WIRES COGN SCI, V6, P235, DOI 10.1002/wcs.1340
   Joanisse MF, 2003, BRAIN LANG, V86, P40, DOI 10.1016/S0093-934X(02)00533-3
   Jones DM, 2004, J EXP PSYCHOL LEARN, V30, P656, DOI 10.1037/0278-7393.30.3.656
   Jones DM, 2018, CURR DIR PSYCHOL SCI, V27, P351, DOI 10.1177/0963721418765796
   Jones G, 2020, COGNITION, V198, DOI 10.1016/j.cognition.2020.104200
   Jones G, 2015, COGNITION, V144, P1, DOI 10.1016/j.cognition.2015.07.009
   Jones T, 2018, J MEM LANG, V100, P98, DOI 10.1016/j.jml.2018.02.001
   JUST MA, 1992, PSYCHOL REV, V99, P122, DOI 10.1037/0033-295X.99.1.122
   Kaiser E, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00156
   Kalm K, 2014, J NEUROSCI, V34, P6879, DOI 10.1523/JNEUROSCI.4104-13.2014
   Kemper S, 2011, AGING NEUROPSYCHOL C, V18, P257, DOI 10.1080/13825585.2010.527317
   Klem M, 2015, DEVELOPMENTAL SCI, V18, P146, DOI 10.1111/desc.12202
   KOLERS PA, 1984, J VERB LEARN VERB BE, V23, P425, DOI 10.1016/S0022-5371(84)90282-2
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299
   Leminen A, 2019, CORTEX, V116, P4, DOI 10.1016/j.cortex.2018.08.016
   Levelt W. J., 1993, SPEAKING INTENTION A
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1
   Levinson SC, 2016, TRENDS COGN SCI, V20, P6, DOI 10.1016/j.tics.2015.10.010
   Lewandowsky S, 2000, PSYCHOL RES-PSYCH FO, V63, P163, DOI 10.1007/PL00008175
   Lewis RL, 2006, TRENDS COGN SCI, V10, P447, DOI 10.1016/j.tics.2006.08.007
   LOMBARDI L, 1992, J MEM LANG, V31, P713, DOI 10.1016/0749-596X(92)90036-W
   MacDonald M. C., 2018, OXFORD HDB PSYCHOLIN, P171
   MacDonald M. C., 2006, HDB PSYCHOLINGUISTIC, P581, DOI DOI 10.1016/B978-012369374-7/50016-X
   MacDonald MC, 2016, CURR DIR PSYCHOL SCI, V25, P47, DOI 10.1177/0963721415620776
   MacDonald MC, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00226
   MacDonald MC, 2002, PSYCHOL REV, V109, P35, DOI 10.1037//0033-295X.109.1.35
   MACDONALD MC, 1994, LANG COGNITIVE PROC, V9, P157, DOI 10.1080/01690969408402115
   Macken B, 2014, J EXP PSYCHOL LEARN, V40, P1257, DOI 10.1037/a0036845
   Majerus S, 2008, NEUROIMAGE, V42, P1698, DOI 10.1016/j.neuroimage.2008.06.003
   Majerus S, 2006, NEUROIMAGE, V32, P880, DOI 10.1016/j.neuroimage.2006.03.048
   Majerus S, 2004, J MEM LANG, V51, P297, DOI 10.1016/j.jml.2004.05.002
   Majerus S, 2007, COGN NEUROPSYCHOL, V24, P131, DOI 10.1080/02643290600989376
   Majerus S, 2019, CORTEX, V112, P122, DOI 10.1016/j.cortex.2018.04.016
   Majerus S, 2015, NEUROPSYCHOLOGIA, V77, P165, DOI 10.1016/j.neuropsychologia.2015.08.010
   Majerus S, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00357
   Majerus S, 2011, J MEM LANG, V64, P181, DOI 10.1016/j.jml.2010.10.003
   Majerus S, 2009, INTERACTIONS BETWEEN SHORT-TERM AND LONG-TERM MEMORY IN THE VERBAL DOMAIN, P244
   MARTIN N, 1994, BRAIN LANG, V47, P609, DOI 10.1006/brln.1994.1061
   MARTIN N, 1992, BRAIN LANG, V43, P240, DOI 10.1016/0093-934X(92)90130-7
   Martin N, 1997, COGNITIVE NEUROPSYCH, V14, P641
   Martin N, 1996, BRAIN LANG, V52, P83, DOI 10.1006/brln.1996.0005
   Martin R., 1994, NEUROPSYCHOLOGY, V8, P506, DOI [10.1037/0894-4105.8.4.506, DOI 10.1037/0894-4105.8.4.506]
   MARTIN RC, 1992, COGNITIVE NEUROPSYCH, V9, P509, DOI 10.1080/02643299208252070
   Martin RC, 2004, BRAIN LANG, V89, P76, DOI 10.1016/S0093-934X(03)00300-6
   MARTIN RC, 1994, J MEM LANG, V33, P83, DOI 10.1006/jmla.1994.1005
   MARTIN RC, 1987, BRAIN LANG, V32, P159, DOI 10.1016/0093-934X(87)90122-2
   Martin RC, 2001, MEMORY, V9, P261, DOI 10.1080/09658210143000173
   Martin RC, 1999, J MEM LANG, V41, P3, DOI 10.1006/jmla.1999.2637
   Mayberry MR, 2009, COGNITIVE SCI, V33, P449, DOI 10.1111/j.1551-6709.2009.01019.x
   McCauley SM, 2014, MENT LEX, V9, P419, DOI 10.1075/ml.9.3.03mcc
   McClelland JL, 2010, TRENDS COGN SCI, V14, P348, DOI 10.1016/j.tics.2010.06.002
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MILLER GA, 1950, AM J PSYCHOL, V63, P176, DOI 10.2307/1418920
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   Monaghan P., 2017, NEUROCOMPUTATIONAL M, P69
   Montag JL, 2017, COLLABRA-PSYCHOL, V3, DOI 10.1525/collabra.94
   MURDOCK BB, 1962, J EXP PSYCHOL, V64, P482, DOI 10.1037/h0045106
   Norris D, 2017, PSYCHOL BULL, V143, P992, DOI 10.1037/bul0000108
   Nozari N, 2017, CURR DIR PSYCHOL SCI, V26, P403, DOI 10.1177/0963721417702419
   Nozari N, 2016, PSYCHON B REV, V23, P1942, DOI 10.3758/s13423-016-1068-8
   Nozari N, 2013, NEUROPSYCHOLOGIA, V51, P2770, DOI 10.1016/j.neuropsychologia.2013.08.019
   Nozari N, 2012, J EXP PSYCHOL LEARN, V38, P1084, DOI 10.1037/a0026933
   Nygaard LC, 2009, COGNITION, V112, P181, DOI 10.1016/j.cognition.2009.04.001
   Oberauer K, 2016, PSYCHOL BULL, V142, P758, DOI 10.1037/bul0000046
   Oberauer K, 2015, MEM COGNITION, V43, P852, DOI 10.3758/s13421-015-0512-8
   Page MPA, 2009, PHILOS T R SOC B, V364, P3737, DOI 10.1098/rstb.2009.0173
   Page MPA, 2013, J MEM LANG, V69, P506, DOI 10.1016/j.jml.2013.07.001
   Page MPA, 2007, J MEM LANG, V56, P49, DOI 10.1016/j.jml.2006.09.002
   PATTERSON K, 1994, J COGNITIVE NEUROSCI, V6, P57, DOI 10.1162/jocn.1994.6.1.57
   PENFIELD W, 1958, ARCH NEURO PSYCHIATR, V79, P475, DOI 10.1001/archneurpsyc.1958.02340050003001
   Pereira F, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-03068-4
   Perham N, 2009, Q J EXP PSYCHOL, V62, P1285, DOI 10.1080/17470210802635599
   Pickering MJ, 2008, PSYCHOL BULL, V134, P427, DOI 10.1037/0033-2909.134.3.427
   Plaut DC, 1999, CARN S COGN, P381
   Plaut DC, 1996, PSYCHOL REV, V103, P56, DOI 10.1037/0033-295X.103.1.56
   Poirier M, 1996, CAN J EXP PSYCHOL, V50, P408, DOI 10.1037/1196-1961.50.4.408
   Poirier M, 2015, MEM COGNITION, V43, P489, DOI 10.3758/s13421-014-0470-6
   Postle BR, 2006, NEUROSCIENCE, V139, P23, DOI 10.1016/j.neuroscience.2005.06.005
   Potter MC, 1998, J MEM LANG, V38, P265, DOI 10.1006/jmla.1997.2546
   Ramscar M, 2016, LANG SCI, V53, P58, DOI 10.1016/j.langsci.2015.08.002
   Roodenrys S, 2002, J EXP PSYCHOL LEARN, V28, P1019, DOI 10.1037//0278-7393.28.6.1019
   Roodenrys S, 2002, J EXP PSYCHOL LEARN, V28, P29, DOI 10.1037//0278-7393.28.1.29
   Rosenbaum DA, 2007, HUM MOVEMENT SCI, V26, P525, DOI 10.1016/j.humov.2007.04.001
   Rubin RD, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00742
   Rueckl JG, 1997, J MEM LANG, V36, P382, DOI 10.1006/jmla.1996.2489
   Saint-Aubin J, 1999, INT J PSYCHOL, V34, P347, DOI 10.1080/002075999399675
   Savill N, 2019, J EXP PSYCHOL LEARN, V45, P1815, DOI 10.1037/xlm0000675
   Savill N, 2018, MEM COGNITION, V46, P426, DOI 10.3758/s13421-017-0775-3
   Savill NJ, 2019, CORTEX, V112, P5, DOI 10.1016/j.cortex.2018.07.021
   Schmidtke DS, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00080
   SCOVILLE WB, 1957, J NEUROL NEUROSUR PS, V20, P11, DOI 10.1136/jnnp.20.1.11
   Seidenberg MS, 2018, TOP LANG DISORD, V38, P66, DOI 10.1097/TLD.0000000000000144
   SEIDENBERG MS, 1979, J EXP PSYCHOL-HUM L, V5, P546, DOI 10.1037/0278-7393.5.6.546
   SEIDENBERG MS, 1989, PSYCHOL REV, V96, P523, DOI 10.1037/0033-295X.96.4.523
   Seidenberg MS, 1997, SCIENCE, V275, P1599, DOI 10.1126/science.275.5306.1599
   SEIDENBERG MS, 1982, COGNITIVE PSYCHOL, V14, P489, DOI 10.1016/0010-0285(82)90017-2
   Seidenberg MS, 2000, TRENDS COGN SCI, V4, P353, DOI 10.1016/S1364-6613(00)01515-1
   SHALLICE T, 1977, NEUROPSYCHOLOGIA, V15, P729, DOI 10.1016/0028-3932(77)90002-1
   SHALLICE T, 1970, Q J EXP PSYCHOL, V22, P261, DOI 10.1080/00335557043000203
   SHALLICE T, 1974, NEUROPSYCHOLOGIA, V12, P553, DOI 10.1016/0028-3932(74)90087-6
   Shallice T, 2019, CORTEX, V112, P107, DOI 10.1016/j.cortex.2018.10.004
   Siegelman M, 2019, NEUROSCIENCE, V413, P219, DOI 10.1016/j.neuroscience.2019.06.003
   Silveri MC, 2003, CORTEX, V39, P913, DOI 10.1016/S0010-9452(08)70870-0
   Solomon ES, 2004, COGNITIVE PSYCHOL, V49, P1, DOI 10.1016/j.cogpsych.2003.10.001
   Soveri A, 2017, PSYCHON B REV, V24, P1077, DOI 10.3758/s13423-016-1217-0
   Staub A, 2010, COGNITION, V116, P71, DOI 10.1016/j.cognition.2010.04.002
   Stivers T, 2009, P NATL ACAD SCI USA, V106, P10587, DOI 10.1073/pnas.0903616106
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   Stuart GP, 2009, INTERACTIONS BETWEEN SHORT-TERM AND LONG-TERM MEMORY IN THE VERBAL DOMAIN, P157
   Szewczyk JM, 2018, COGNITION, V179, P23, DOI 10.1016/j.cognition.2018.06.002
   Szmalec A, 2009, Q J EXP PSYCHOL, V62, P435, DOI 10.1080/17470210802386375
   Tanida Y, 2019, MEMORY, V27, P507, DOI 10.1080/09658211.2018.1532008
   Tanida Y, 2015, MEM COGNITION, V43, P500, DOI 10.3758/s13421-014-0482-2
   Thorn ASC, 2005, J EXP PSYCHOL LEARN, V31, P729, DOI 10.1037/0278-7393.31.4.729
   Torreira F, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00284
   Ueno T, 2014, J COGNITIVE NEUROSCI, V26, P433, DOI 10.1162/jocn_a_00467
   Ueno T, 2011, NEURON, V72, P385, DOI 10.1016/j.neuron.2011.09.013
   VALLAR G, 1984, COGNITIVE NEUROPSYCH, V1, P121, DOI 10.1080/02643298408252018
   Van de Cavey J, 2016, COGNITION, V146, P172, DOI 10.1016/j.cognition.2015.09.013
   Van Dyke JA, 2012, LANG LINGUIST COMPAS, V6, P193, DOI 10.1002/lnc3.330
   Walker I, 1999, J EXP PSYCHOL LEARN, V25, P1256, DOI 10.1037/0278-7393.25.5.1256
   WARRINGTON EK, 1972, Q J EXP PSYCHOL, V24, P30, DOI 10.1080/14640747208400265
   WARRINGTON EK, 1969, BRAIN, V92, P885, DOI 10.1093/brain/92.4.885
   WARRINGTON EK, 1971, NEUROPSYCHOLOGIA, V9, P377, DOI 10.1016/0028-3932(71)90002-9
   WATKINS OC, 1977, J EXP PSYCHOL-HUM L, V3, P712, DOI 10.1037/0278-7393.3.6.712
   WEINER EJ, 1983, J LINGUIST, V19, P29, DOI 10.1017/S0022226700007441
   Willits JA, 2015, COGNITIVE PSYCHOL, V78, P1, DOI 10.1016/j.cogpsych.2015.02.002
   Willits JA, 2014, COGNITION, V132, P429, DOI 10.1016/j.cognition.2014.05.004
   Yue QH, 2019, CEREB CORTEX, V29, P1398, DOI 10.1093/cercor/bhy037
   Yuzawa M, 2006, COGNITIVE DEV, V21, P146, DOI 10.1016/j.cogdev.2006.01.003
   Zakarias L, 2019, J SPEECH LANG HEAR R, V62, P1979, DOI 10.1044/2018_JSLHR-L-18-0057
NR 243
TC 4
Z9 4
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD MAR 12
PY 2020
VL 14
AR 68
DI 10.3389/fnhum.2020.00068
PG 19
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA LC7DJ
UT WOS:000525492600001
PM 32226368
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Goriot, C
   McQueen, JM
   Unsworth, S
   van Hout, R
   Broersma, M
AF Goriot, Claire
   McQueen, James M.
   Unsworth, Sharon
   van Hout, Roeland
   Broersma, Mirjam
TI Perception of English phonetic contrasts by Dutch children: How
   bilingual are early-English learners?
SO PLOS ONE
LA English
DT Article
ID SPEECH-PERCEPTION; LANGUAGE-ACQUISITION; 1ST YEAR; ADULTS; 2ND-LANGUAGE;
   DISCRIMINATION
AB The aim of this study was to investigate whether early-English education benefits the perception of English phonetic contrasts that are known to be perceptually confusable for Dutch native speakers, comparing Dutch pupils who were enrolled in an early-English programme at school from the age of four with pupils in a mainstream programme with English instruction from the age of 11, and English-Dutch early bilingual children. Children were 4-5-year-olds (start of primary school), 8-9-year-olds, or 11-12-year-olds (end of primary school). Children were tested on four contrasts that varied in difficulty: /b/-/s/ (easy), /k/-/g/ (intermediate), /f/-/theta/ (difficult), /epsilon/-/ae/ (very difficult). Bilingual children outperformed the two other groups on all contrasts except /b/-/s/. Early-English pupils did not outperform mainstream pupils on any of the contrasts. This shows that early-English education as it is currently implemented is not beneficial for pupils' perception of non-native contrasts.
C1 [Goriot, Claire; Unsworth, Sharon; van Hout, Roeland; Broersma, Mirjam] Radboud Univ Nijmegen, Ctr Language Studies, Nijmegen, Netherlands.
   [McQueen, James M.] Radboud Univ Nijmegen, Ctr Cognit, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
   [McQueen, James M.] Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
   [Goriot, Claire] Wageningen Univ & Res, Fac Social Sci Educ & Learning Sci, Wageningen, Netherlands.
RP Goriot, C (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies, Nijmegen, Netherlands.; Goriot, C (corresponding author), Wageningen Univ & Res, Fac Social Sci Educ & Learning Sci, Wageningen, Netherlands.
EM clairegoriot@gmail.com
OI Goriot, Claire/0000-0001-9088-3908
FU Radboud University Centre for Language Studies; EPNuffic (currently
   Nuffic); Netherlands Organisation for Scientific Research
   NWO-VidiNetherlands Organization for Scientific Research (NWO)
   [276-89-006]
FX The present research was supported by a doctoral fellowship from Radboud
   University Centre for Language Studies awarded to the first author
   (C.G.), with additional support from EPNuffic (currently Nuffic; no
   grant number available), and the Netherlands Organisation for Scientific
   Research NWO-Vidi (to M.B.) grant number 276-89-006. The funders had no
   role in study design, data collection and analysis, decision to publish,
   or preparation of the manuscript.
CR Aoyama K, 2004, J PHONETICS, V32, P233, DOI 10.1016/S0095-4470(03)00036-6
   Baker W, 2008, LANG SPEECH, V51, P317, DOI 10.1177/0023830908099068
   Best C., 1995, SPEECH PERCEPTION LI, P171
   BEST CT, 1993, NATO ADV SCI INST SE, V69, P289
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bodde M, 2008, CONTENT ACTIVITIES O
   Bohn O.-S., 2007, LANGUAGE EXPERIENCE
   Bosch L, 2003, LANG SPEECH, V46, P217, DOI 10.1177/00238309030460020801
   Bosch L, 2003, P 15 INT C PHON SCI, P1987
   Broersma M, 2005, J ACOUST SOC AM, V117, P3890, DOI 10.1121/1.1906060
   Burns TC, 2007, APPL PSYCHOLINGUIST, V28, P455, DOI 10.1017/S0142716407070257
   Choi J, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.160660
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Cutler A, 2004, J ACOUST SOC AM, V116, P3668, DOI 10.1121/1.1810292
   Cutler A, 2012, NATIVE LISTENING LAN
   Darcy I, 2012, J PHONETICS, V40, P568, DOI 10.1016/j.wocn.2012.05.001
   de Graaff R, 2015, LEVENDE TALEN TIJDSC, V16, P3
   Dunn L., 2007, PPVT 4 MANUAL
   Dunn LM, 2005, PEABODY PICTURE VOCA
   Flege JE, 1996, J ACOUST SOC AM, V99, P1161, DOI 10.1121/1.414884
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   Geurts B, 2013, ARNHEM
   Goriot C, 2018, J EXP CHILD PSYCHOL, V173, P168, DOI 10.1016/j.jecp.2018.03.019
   GOTO H, 1971, NEUROPSYCHOLOGIA, V9, P317, DOI 10.1016/0028-3932(71)90027-3
   Gussenhoven C, 2011, UNDERSTANDING PHONOL, P1
   Gussenhoven C., 1999, HDB INT PHONETIC ASS, P74
   Hamann SR, 2015, P 18 INT C PHON SCI
   Hanulikova A, 2012, ATTEN PERCEPT PSYCHO, V74, P613, DOI 10.3758/s13414-011-0259-7
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   Jenniskens T, 2017, ZICHT VROEG VREEMDET
   Johnson K, 2010, J PHONETICS, V38, P127, DOI 10.1016/j.wocn.2009.11.001
   Jost LB, 2015, NEUROPSYCHOLOGIA, V72, P94, DOI 10.1016/j.neuropsychologia.2015.04.029
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kuppens AH, 2010, LEARN MEDIA TECHNOL, V35, P65, DOI 10.1080/17439880903561876
   Lee AH, 2016, LANG LEARN, V66, P809, DOI 10.1111/lang.12167
   Levis JM, 2016, TESOL QUART, V50, P894, DOI 10.1002/tesq.272
   Lobo VR, 2013, TEACHING L2 ENGLISH
   MacMillan NA, 1991, DETECTION THEORY USE
   McCarthy KM, 2014, CHILD DEV, V85, P1965, DOI 10.1111/cdev.12275
   Munoz C., 2008, IRAL-INT REV APPL LI, V46, P197, DOI DOI 10.1515/IRAL.2008.009
   Saito K, 2013, LANG LEARN, V63, P499, DOI 10.1111/lang.12015
   Sebastian-Galles N, 2009, DEVELOPMENTAL SCI, V12, P874, DOI 10.1111/j.1467-7687.2009.00829.x
   Singleton D., 2004, LANGUAGE ACQUISITION
   Strange W., 1995, PHONETICA, V56, P105
   Sundara M, 2008, COGNITION, V106, P234, DOI 10.1016/j.cognition.2007.01.011
   Thijs A, 2011, ENSCHEDE
   Tsukada K, 2005, J PHONETICS, V33, P263, DOI 10.1016/j.wocn.2004.10.002
   Unsworth S, 2015, APPL LINGUIST, V36, P527, DOI 10.1093/applin/amt052
   van Bezooijen R, 1994, NIEUWE TAALGIDS, V87, P145
   van der Leij A, 2010, READ WRIT, V23, P415, DOI 10.1007/s11145-009-9207-5
   Walley AC, 1999, J PHONETICS, V27, P307, DOI 10.1006/jpho.1999.0098
   Wechsler D., 2008, WECHSLER NONVERBAL S
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wester F, 2007, LANG SCI, V29, P477, DOI 10.1016/j.langsci.2006.12.029
   Zhou W., 2015, ASSESSING BIRTH LANG
NR 55
TC 0
Z9 0
U1 0
U2 0
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD MAR 11
PY 2020
VL 15
IS 3
AR e0229902
DI 10.1371/journal.pone.0229902
PG 21
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA LQ8YS
UT WOS:000535284700045
PM 32160213
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Dobbels, B
   Lucieer, F
   Mertens, G
   Gilles, A
   Moyaert, J
   van de Heyning, P
   Guinand, N
   Fornos, AP
   Herssens, N
   Hallemans, A
   Vereeck, L
   Vanderveken, O
   Van Rompaey, V
   van de Berg, R
AF Dobbels, Bieke
   Lucieer, Florence
   Mertens, Griet
   Gilles, Annick
   Moyaert, Julie
   van de Heyning, Paul
   Guinand, Nils
   Fornos, Angelica Perez
   Herssens, Nolan
   Hallemans, Ann
   Vereeck, Luc
   Vanderveken, Olivier
   Van Rompaey, Vincent
   van de Berg, Raymond
TI Prospective cohort study on the predictors of fall risk in 119 patients
   with bilateral vestibulopathy
SO PLOS ONE
LA English
DT Article
ID QUALITY-OF-LIFE; MYOGENIC POTENTIALS; HYPOFUNCTION
AB Objectives
   To identify predictive factors for falls in patients with bilateral vestibulopathy (BV). Specific variables contributing to the general work-up of a vestibular patient were compared between BV patients experiencing falls and those who did not.
   Design
   Prospective multi-centric cohort study.
   Setting
   Department of Otorhinolaryngology & Head and Neck Surgery at two tertiary referral centers: Antwerp University Hospital and Maastricht University Medical Center.
   Participants
   In total, 119 BV patients were included. BV diagnosis was defined in accordance with the diagnostic BV criteria, established by the Barany Society in 2017.
   Main outcome measures
   Patients were divided into fallers and non-fallers, depending on the experience of one or more falls in the preceding 12 months. Residual vestibular function on caloric testing, rotatory chair testing, video head impulse test (vHIT) and cervical vestibular evoked myogenic potentials (cVEMP) was evaluated as a predictive factor for falls. Furthermore, hearing function (speech perception in noise (SPIN)), sound localization performance, etiology, disease duration, sport practice, scores on the Dizziness Handicap Inventory (DHI) and the Oscillopsia Severity Questionnaire (OSQ) were compared between fallers and non-fallers.
   Results
   Forty-five (39%) patients reported falls. In a sub-analysis in the patients recruited at UZA (n = 69), 20% experienced three or more falls and three patients (4%) suffered from severe fall-related injuries. The DHI score and the OSQ score were significantly higher in fallers. Residual vestibular function, SPIN, sound localization performance, etiology, disease duration, age and sport practice did not differ between fallers and non-fallers.
   Conclusions
   Falls and (severe) fall-related injuries are frequent among BV patients. A DHI score > 47 and an OSQ score > 27.5 might be indicative for BV patients at risk for falls, with a sensitivity of 70% and specificity of 60%. Residual vestibular function captured by single vestibular tests (vHIT, calorics, rotatory chair, cVEMP) or by overall vestibular function defined as the number of impaired vestibular sensors are not suitable to distinguish fallers and non-fallers in a BV population.
C1 [Dobbels, Bieke; Mertens, Griet; Gilles, Annick; van de Heyning, Paul; Vanderveken, Olivier; Van Rompaey, Vincent] Univ Antwerp, Fac Med & Hlth Sci, Antwerp, Belgium.
   [Dobbels, Bieke; Mertens, Griet; Gilles, Annick; Moyaert, Julie; van de Heyning, Paul; Vanderveken, Olivier; Van Rompaey, Vincent] Antwerp Univ Hosp, Dept Otorhinolaryngol & Head & Neck Surg, Edegem, Belgium.
   [Lucieer, Florence; van de Berg, Raymond] Maastricht Univ, Fac Hlth Med & Life Sci, Sch Mental Hlth & Neurosci,Med Ctr, Dept Otorhinolaryngol & Head & Neck Surg,Div Bala, Maastricht, Netherlands.
   [Guinand, Nils; Fornos, Angelica Perez] Geneva Univ Hosp, Dept Clin Neurosci, Serv Otorhinolaryngol Head & Neck Surg, Geneva, Switzerland.
   [Herssens, Nolan; Hallemans, Ann; Vereeck, Luc] Univ Antwerp, Dept Rehabil Sci & Physiotherapy Movant, Fac Med & Hlth Sci, Antwerp, Belgium.
   [Herssens, Nolan; Hallemans, Ann; Vereeck, Luc] Univ Antwerp, Multidisciplinary Motor Ctr Antwerp M2OCEAN, Antwerp, Belgium.
   [van de Berg, Raymond] Tomsk State Res Univ, Fac Phys, Tomsk, Russia.
RP Dobbels, B (corresponding author), Univ Antwerp, Fac Med & Hlth Sci, Antwerp, Belgium.; Dobbels, B (corresponding author), Antwerp Univ Hosp, Dept Otorhinolaryngol & Head & Neck Surg, Edegem, Belgium.
EM bieke.dobbels@uza.be
RI Hallemans, Ann/D-4266-2011; Mertens, Griet/M-3882-2016; Van Rompaey,
   Vincent/L-2450-2014; Perez Fornos, A/M-3296-2014; Herssens,
   Nolan/AAA-1903-2019; Guinand, Nils/O-4763-2019; Herssens,
   Nolan/AAC-1197-2021; Vereeck, Luc/D-8835-2017
OI Hallemans, Ann/0000-0003-4101-5279; Mertens, Griet/0000-0001-8621-0292;
   Van Rompaey, Vincent/0000-0003-0912-7780; Perez Fornos,
   A/0000-0003-3911-8826; Herssens, Nolan/0000-0003-0074-5814; Guinand,
   Nils/0000-0001-6004-8768; Vereeck, Luc/0000-0001-5294-161X
FU MED-EL
FX The Antwerp University Hospital, Maastricht University Medical Center,
   and Geneva University Hospitals have received research and travel grants
   from MED-EL. The funder had no role in study design, data collection and
   analysis, decision to publish, or preparation of the manuscript.
CR Agrawal Y, 2013, J NEUROL, V260, P876, DOI 10.1007/s00415-012-6724-y
   COLEBATCH JG, 1994, J NEUROL NEUROSUR PS, V57, P190, DOI 10.1136/jnnp.57.2.190
   De Belder J, 2018, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00735
   Fujimoto C, 2009, J NEUROL, V256, P1488, DOI 10.1007/s00415-009-5147-x
   Guinand N, 2012, ANN OTO RHINOL LARYN, V121, P471, DOI 10.1177/000348941212100708
   Guyot JP, 2019, CURR OPIN NEUROL, V32, P145, DOI 10.1097/WCO.0000000000000639
   Hall CD, 2016, J NEUROL PHYS THER, V40, P124, DOI 10.1097/NPT.0000000000000120
   Hallemans A, 2017, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00404
   Herdman SJ, 2000, AM J OTOL, V21, P847
   Hermann R, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00555
   Jacobson G P, 2000, J Am Acad Audiol, V11, P76
   Lucieer F, 2016, FRONT NEUROL, V7, DOI 10.3389/fneur.2016.00026
   Lucieer F, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00352
   MacDougall HG, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0061488
   McCall Andrew A, 2011, Front Neurol, V2, P88, DOI 10.3389/fneur.2011.00088
   Mertens G, 2016, CLIN OTOLARYNGOL, V41, P511, DOI 10.1111/coa.12555
   Schlick C, 2015, J VESTIBUL RES-EQUIL, V25, P241, DOI 10.3233/VES-150564
   Schniepp R, 2017, J NEUROL, V264, P277, DOI 10.1007/s00415-016-8342-6
   SNAITH RP, 1990, BRIT J GEN PRACT, V40, P305
   Strupp M, 2017, J VESTIBUL RES-EQUIL, V27, P177, DOI 10.3233/VES-170619
   Sun DQ, 2014, JAMA OTOLARYNGOL, V140, P527, DOI 10.1001/jamaoto.2014.490
   Tamber AL, 2009, HEALTH QUAL LIFE OUT, V7, DOI 10.1186/1477-7525-7-101
   Tarnutzer AA, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00244
   THOMSON DB, 1991, EXP BRAIN RES, V85, P364
   van de Berg R, 2015, ORL J OTO-RHINO-LARY, V77, P197, DOI 10.1159/000433549
   Van der Stappen A, 2000, ACTA OTO-LARYNGOL, V120, P724, DOI 10.1080/000164800750000243
   van Wieringen A, 2008, INT J AUDIOL, V47, P348, DOI 10.1080/14992020801895144
   Vanspauwen R, 2011, OTOL NEUROTOL, V32, P497, DOI 10.1097/MAO.0b013e31820d94d0
   Ward BK, 2013, JAMA OTOLARYNGOL, V139, P803, DOI 10.1001/jamaoto.2013.3913
   World Health Organization, 2007, WHO GLOB REP FALLP
   Zingler VC, 2007, ANN NEUROL, V61, P524, DOI 10.1002/ana.21105
NR 31
TC 3
Z9 3
U1 2
U2 2
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD MAR 9
PY 2020
VL 15
IS 3
AR e0228768
DI 10.1371/journal.pone.0228768
PG 17
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA LQ8UT
UT WOS:000535274400004
PM 32150553
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Pratihari, J
AF Pratihari, Jhanja
TI Psychoacoustic Measures and Speech Perception of Compressed Rate of
   Sentences in Noise in Individuals with Congenital and Acquired Blindness
SO JOURNAL OF EVOLUTION OF MEDICAL AND DENTAL SCIENCES-JEMDS
LA English
DT Article
DE Congenital Blindness; Acquired Blindness; Psychoacoustic Measures;
   Speech Perception
ID DISCRIMINATION; HEAR
AB BACKGROUND
   Without visual information, blind speakers rely solely on the auditory signal to recover phonological information. We wanted to measure the psychoacoustic measures and perception of compressed speech in noise in individuals with congenital and acquired blindness and correlate the temporal resolution and frequency resolution ability with individuals with normal sight.
   METHODS
   The clinical group (age range-12-20 years) contains two subgroups-congenital blindness and acquired blindness, with normal hearing each containing 15 participants. 15 participants with normal vision were selected as controls. To measure the temporal processing ability each participant was asked to perform Gap detection test. Similarly, difference limen frequency was estimated from pitch discrimination of pure tones. The task for speech perception of compressed sentences was done at different rate of compression at different SNRs.
   RESULTS
   Results indicated that there was significant difference in gap detection threshold between congenital blinds and normal sighted participants as well as between acquired blinds and normal sighted participants. There was significant difference in frequency discrimination scores between blind listeners and normal sighted participants. The sentence perception score was better in those participants who have congenital blindness than acquired blindness followed by normal sighted participants in each experimental condition.
   CONCLUSIONS
   From the investigation, it can be concluded that the psychoacoustic measures are better in individuals with blindness than individuals with normal sight. speech perception deteriorates with an increase in noise in both normal sighted individuals and individuals with blindness. Effect of noise is more for individuals with normal sight than blind listeners.
C1 [Pratihari, Jhanja] Samvaad Inst Speech & Hearing, Dept Audiol & Speech & Language Pathol, Bengaluru, Karnataka, India.
RP Pratihari, J (corresponding author), 430 United Ellysium, Bangalore 560067, Karnataka, India.
EM jhanja.pratihari690@gmail.com
CR Collignon O, 2013, BRAIN, V136, P2769, DOI 10.1093/brain/awt176
   Gougoux F, 2004, NATURE, V430, P309, DOI 10.1038/430309a
   Hugdahl K, 2004, COGNITIVE BRAIN RES, V19, P28, DOI 10.1016/j.cogbrainres.2003.10.015
   LUCAS SA, 1984, INT J REHABIL RES, V7, P74, DOI 10.1097/00004356-198403000-00016
   MILLER L, 1992, J VISUAL IMPAIR BLIN, V86, P206
   NIEMEYER W, 1981, AUDIOLOGY, V20, P510
   Stankov L., 1978, APPLIED PSYCHOL MEAS, V2, P491, DOI 10.1177/014662167800200403
   STARLINGER I, 1981, AUDIOLOGY, V20, P503
   Stevens AA, 2009, BEHAV BRAIN RES, V196, P134, DOI 10.1016/j.bbr.2008.07.041
NR 9
TC 0
Z9 0
U1 0
U2 0
PU JOURNAL EVOLUTION MEDICAL & DENTAL SCIENCES
PI KARNATAKA
PA C/O AKSHANTALA ENTERPRISES, NO 65, 1ST FL, SAHUKAR CHENNIAH RD, MYSORE,
   KARNATAKA, 570 009, INDIA
SN 2278-4748
EI 2278-4802
J9 J EVOL MED DENT SCI-
JI J. Evol. Med. Dent. Sci.-JEMDS
PD MAR 9
PY 2020
VL 9
IS 10
BP 749
EP 752
DI 10.14260/jemds/2020/163
PG 4
WC Medicine, General & Internal
SC General & Internal Medicine
GA LC5SS
UT WOS:000525391000010
OA Bronze
DA 2021-02-24
ER

PT J
AU Boros, M
   Gabor, A
   Szabo, D
   Bozsik, A
   Gacsi, M
   Szalay, F
   Farago, T
   Andics, A
AF Boros, Marianna
   Gabor, Anna
   Szabo, Dora
   Bozsik, Anett
   Gacsi, Marta
   Szalay, Ferenc
   Farago, Tamas
   Andics, Attila
TI Repetition enhancement to voice identities in the dog brain
SO SCIENTIFIC REPORTS
LA English
DT Article
ID NEURAL MECHANISMS; SPEECH-PERCEPTION; CIRCULAR ANALYSIS; FMRI;
   SUPPRESSION; AREAS; COMMUNICATION; FACE
AB In the human speech signal, cues of speech sounds and voice identities are conflated, but they are processed separately in the human brain. The processing of speech sounds and voice identities is typically performed by non-primary auditory regions in humans and non-human primates. Additionally, these processes exhibit functional asymmetry in humans, indicating the involvement of distinct mechanisms. Behavioural studies indicate analogue side biases in dogs, but neural evidence for this functional dissociation is missing. In two experiments, using an fMRI adaptation paradigm, we presented awake dogs with natural human speech that either varied in segmental (change in speech sound) or suprasegmental (change in voice identity) content. In auditory regions, we found a repetition enhancement effect for voice identity processing in a secondary auditory region - the caudal ectosylvian gyrus. The same region did not show repetition effects for speech sounds, nor did the primary auditory cortex exhibit sensitivity to changes either in the segmental or in the suprasegmental content. Furthermore, we did not find evidence for functional asymmetry neither in the processing of speech sounds or voice identities. Our results in dogs corroborate former human and non-human primate evidence on the role of secondary auditory regions in the processing of suprasegmental cues, suggesting similar neural sensitivity to the identity of the vocalizer across the mammalian order.
C1 [Boros, Marianna; Gabor, Anna; Bozsik, Anett; Andics, Attila] Eotvos Lorand Univ, MTA ELTE Lendulef Neuroethol Commun Res Grp, Pazmany Peter Setany 1-C, H-1117 Budapest, Hungary.
   [Boros, Marianna; Gabor, Anna; Szabo, Dora; Gacsi, Marta; Andics, Attila] Eotvos Lorand Univ, Dept Ethol, Pazmany Peter Setany 1-C, H-1117 Budapest, Hungary.
   [Gacsi, Marta] Eotvos Lorand Univ, MTA ELTE Comparat Ethol Res Grp, Pazmany Peter Setany 1-C, H-1117 Budapest, Hungary.
   [Szalay, Ferenc] Univ Vet Med, Dept Anat & Histol, Istvan Utca 2, H-1078 Budapest, Hungary.
   [Bozsik, Anett; Farago, Tamas] Univ Vet Med, Istvan Utca 2, H-1078 Budapest, Hungary.
RP Boros, M; Andics, A (corresponding author), Eotvos Lorand Univ, MTA ELTE Lendulef Neuroethol Commun Res Grp, Pazmany Peter Setany 1-C, H-1117 Budapest, Hungary.; Boros, M; Andics, A (corresponding author), Eotvos Lorand Univ, Dept Ethol, Pazmany Peter Setany 1-C, H-1117 Budapest, Hungary.
EM marianna.cs.boros@gmail.com; attila.andics@gmail.com
RI Farago, Tamas/A-5386-2009
OI Farago, Tamas/0000-0001-5987-2629; Gacsi, Marta/0000-0003-3080-7545
FU Hungarian Academy of SciencesHungarian Academy of Sciences [F01/031,
   LP2017-13/2017]; Bolyai Research ScholarshipHungarian Academy of
   Sciences; Eotvos Lorand University; Hungarian Scientific Research Fund
   (NKFI) [PD 116181]; European Research Council (ERC) under the European
   Union's Horizon 2020 research and innovation programEuropean Research
   Council (ERC) [680040]; National Research, Development, and Innovation
   Office [K115862]; Office for Research Groups Attached to Universities
   and Other Institutions of the Hungarian Academy of Sciences [460002];
   National Excellence Program of the Ministry of Human Capacities
   [UNKP-18-3-IV-ELTE-391]
FX This project was funded by the Hungarian Academy of Sciences [a grant to
   the MTA-ELTE Comparative Ethology Research Group (F01/031), a grant to
   the MTA-ELTE "Lendulet" Neuroethology of Communication Research Group
   (LP2017-13/2017) and a Bolyai Research Scholarship to AA], the Eotvos
   Lorand University, the Hungarian Scientific Research Fund (NKFI PD
   116181), the European Research Council (ERC) under the European Union's
   Horizon 2020 research and innovation program (Grant Agreement No.
   680040) and the National Research, Development, and Innovation Office
   (K115862). FT was funded by the Premium Postdoctoral Scholarship
   (460002) of the Office for Research Groups Attached to Universities and
   Other Institutions of the Hungarian Academy of Sciences. AG was
   supported through the National Excellence Program of the Ministry of
   Human Capacities (UNKP-18-3-IV-ELTE-391). We thank Gabor Rudas and the
   MR Research Centre of the Semmelweis University Budapest; and Rita Baji
   and all owners for training the dogs.
CR ADAMS CL, 1987, DEV NEUROPSYCHOL, V3, P175, DOI 10.1080/87565648709540375
   Andics A, 2016, SCIENCE, V353, P1030, DOI 10.1126/science.aaf3777
   Andics A, 2014, CURR BIOL, V24, P574, DOI 10.1016/j.cub.2014.01.058
   Andics A, 2013, NEUROIMAGE, V69, P277, DOI 10.1016/j.neuroimage.2012.12.033
   Andics A, 2010, NEUROIMAGE, V52, P1528, DOI 10.1016/j.neuroimage.2010.05.048
   Belin P, 2003, NEUROREPORT, V14, P2105, DOI 10.1097/00001756-200311140-00019
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Belin P, 2018, HEARING RES, V366, P65, DOI 10.1016/j.heares.2018.04.010
   Bergerbest D, 2004, J COGNITIVE NEUROSCI, V16, P966, DOI 10.1162/0898929041502760
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   Boros M, 2016, NEUROIMAGE, V128, P316, DOI 10.1016/j.neuroimage.2016.01.014
   Campanella S, 2007, TRENDS COGN SCI, V11, P535, DOI 10.1016/j.tics.2007.10.001
   Chan A., 2014, CEREB CORTEX, V24
   Czeibert K., 2019, BIOL FUTUR, V70
   Dehaene-Lambertz G, 2005, NEUROIMAGE, V24, P21, DOI 10.1016/j.neuroimage.2004.09.039
   Dehaene-Lambertz G, 2006, HUM BRAIN MAPP, V27, P360, DOI 10.1002/hbm.20250
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Epstein RA, 2008, J NEUROPHYSIOL, V99, P2877, DOI 10.1152/jn.90376.2008
   Fischer J, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-14
   Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318
   Fukuzawa M, 2005, J COMP PSYCHOL, V119, P117, DOI 10.1037/0735-7036.119.1.117
   Golestani N, 2004, NEUROIMAGE, V21, P494, DOI 10.1016/j.neuroimage.2003.09.071
   Grill-Spector K, 2001, ACTA PSYCHOL, V107, P293, DOI 10.1016/S0001-6918(01)00019-1
   Henson R, 2000, SCIENCE, V287, P1269, DOI 10.1126/science.287.5456.1269
   Henson RNA, 2003, PROG NEUROBIOL, V70, P53, DOI 10.1016/S0301-0082(03)00086-8
   Joly O, 2012, NEUROIMAGE, V62, P1376, DOI 10.1016/j.neuroimage.2012.05.070
   Kanwisher N, 1997, J NEUROSCI, V17, P4302
   Kleiner M, 2007, PERCEPTION, V36, P14
   Kriegeskorte N, 2010, J CEREBR BLOOD F MET, V30, P1551, DOI 10.1038/jcbfm.2010.86
   Kriegeskorte N, 2009, NAT NEUROSCI, V12, P535, DOI 10.1038/nn.2303
   Kriengwatana B, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01543
   Latinus M, 2013, CURR BIOL, V23, P1075, DOI 10.1016/j.cub.2013.04.055
   Liebenthal E, 2005, CEREB CORTEX, V15, P1621, DOI 10.1093/cercor/bhi040
   McGettigan C, 2012, J COGNITIVE NEUROSCI, V24, P636, DOI 10.1162/jocn_a_00161
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Molnar C, 2009, BEHAV PROCESS, V82, P198, DOI 10.1016/j.beproc.2009.06.011
   Muller NG, 2013, CEREB CORTEX, V23, P315, DOI 10.1093/cercor/bhs009
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Obleser J, 2007, CEREB CORTEX, V17, P2251, DOI 10.1093/cercor/bhl133
   Obleser J, 2006, HUM BRAIN MAPP, V27, P562, DOI 10.1002/hbm.20201
   Obleser J, 2009, TRENDS COGN SCI, V13, P14, DOI 10.1016/j.tics.2008.09.005
   Okada K, 2018, J COGNITIVE NEUROSCI, V30, P1549, DOI 10.1162/jocn_a_01287
   Okada K, 2010, CEREB CORTEX, V20, P2486, DOI 10.1093/cercor/bhp318
   Peelle JE, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00051
   Perrodin C, 2015, TRENDS COGN SCI, V19, P783, DOI 10.1016/j.tics.2015.09.002
   Perrodin C, 2011, CURR BIOL, V21, P1408, DOI 10.1016/j.cub.2011.07.028
   Peter P, 2014, APPL ANIM BEHAV SCI, V159, P62, DOI 10.1016/j.applanim.2014.08.003
   Petkov CI, 2008, NAT NEUROSCI, V11, P367, DOI 10.1038/nn2043
   Petkov CI, 2009, NEUROSCIENTIST, V15, P419, DOI 10.1177/1073858408326430
   Prichard A, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00737
   Ratcliffe VF, 2014, CURR BIOL, V24, DOI 10.1016/j.cub.2014.10.030
   Rauschecker JP, 2011, HEARING RES, V271, P16, DOI 10.1016/j.heares.2010.09.001
   Reby D, 2006, J ACOUST SOC AM, V120, P4080, DOI 10.1121/1.2358006
   Reinholz-Trojan A, 2012, BEHAV PROCESS, V91, P202, DOI 10.1016/j.beproc.2012.07.001
   Rendall D, 1998, J ACOUST SOC AM, V103, P602, DOI 10.1121/1.421104
   Sadagopan S, 2015, SCI REP-UK, V5, DOI 10.1038/srep10950
   Schall S., 2010, J COGNITIVE NEUROSCI, V27, P280
   Segaert K, 2013, NEUROPSYCHOLOGIA, V51, P59, DOI 10.1016/j.neuropsychologia.2012.11.006
   Siniscalchi M, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003349
   Szwed M, 2014, J COGNITIVE NEUROSCI, V26, P459, DOI 10.1162/jocn_a_00499
   Szwed M, 2011, NEUROIMAGE, V56, P330, DOI 10.1016/j.neuroimage.2011.01.073
   Taylor AM, 2010, J ZOOL, V280, P221, DOI 10.1111/j.1469-7998.2009.00661.x
   Vaden KI, 2010, NEUROIMAGE, V49, P1018, DOI 10.1016/j.neuroimage.2009.07.063
   Zaske R, 2017, CORTEX, V94, P100, DOI 10.1016/j.cortex.2017.06.005
NR 64
TC 0
Z9 0
U1 0
U2 0
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD MAR 4
PY 2020
VL 10
IS 1
AR 3989
DI 10.1038/s41598-020-60395-7
PG 9
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA NF4MC
UT WOS:000563271000020
PM 32132562
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Katiri, R
   Hall, DA
   Buggy, N
   Hogan, N
   Horobin, A
   van de Heyning, P
   Firszt, JB
   Bruce, IA
   Kitterick, PT
AF Katiri, Roulla
   Hall, Deborah A.
   Buggy, Nora
   Hogan, Nicholas
   Horobin, Adele
   van de Heyning, Paul
   Firszt, Jill B.
   Bruce, Iain A.
   Kitterick, Padraig T.
TI Core Rehabilitation Outcome Set for Single Sided Deafness (CROSSSD)
   study: protocol for an international consensus on outcome measures for
   single sided deafness interventions using a modified Delphi survey
SO TRIALS
LA English
DT Article
DE Consensus methods; Core outcome set; Delphi technique; Single-sided
   deafness
ID BONE-ANCHORED HEARING; QUALITY-OF-LIFE; COCHLEAR IMPLANTATION;
   UNILATERAL DEAFNESS; DIRECTIONAL HEARING; CONDUCTION DEVICES; BINAURAL
   HEARING; CLINICAL-TRIALS; LOCALIZATION; TINNITUS
AB Background Single-sided deafness (SSD) describes the presence of a unilateral severe to profound sensorineural hearing loss. SSD disrupts spatial hearing and understanding speech in background noise. It has functional, psychological and social consequences. Potential options for rehabilitation include hearing aids and auditory implants. Benefits and harms of these interventions are documented inconsistently in the literature, using a variety of outcomes ranging from tests of speech perception to quality of life questionnaires. It is therefore difficult to compare interventions when rehabilitating SSD. The Core Rehabilitation Outcome Set for Single Sided Deafness (CROSSSD) study is an international initiative that aims to develop a minimum set of core outcomes for use in future trials of SSD interventions. Methods/design The CROSSSD study adopts an international two-round online modified Delphi survey followed by a stakeholder consensus meeting to identify a patient-centred core outcome domain set for SSD based on what is considered critical and important for assessing whether an intervention for SSD has worked. Discussion The resulting core outcome domain set will act as a minimum standard for reporting in future clinical trials and could have further applications in guiding the use of outcome measures in clinical practice. Standardisation will facilitate comparison of research findings.
C1 [Katiri, Roulla; Hall, Deborah A.; Buggy, Nora; Hogan, Nicholas; Horobin, Adele; Kitterick, Padraig T.] Natl Inst Hlth Res NIHR Nottingham Biomed Res Ctr, Ropewalk House,113 Ropewalk, Nottingham NG1 5DU, England.
   [Katiri, Roulla] Mater Misericordiae Univ Hosp, Dept Audiol, Dublin D07 R2WY, Ireland.
   [Katiri, Roulla; Hall, Deborah A.; Kitterick, Padraig T.] Univ Nottingham, Sch Med, Div Clin Neurosci, Hearing Sci, Nottingham NG7 2UH, England.
   [Hall, Deborah A.] Univ Nottingham Malaysia, Jalan Broga, Semenyih 43500, Selangor Darul, Malaysia.
   [Horobin, Adele; Kitterick, Padraig T.] Nottingham Univ Hosp NHS Trust, Queens Med Ctr, Derby Rd, Nottingham NG7 2UH, England.
   [van de Heyning, Paul] Antwerp Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg, Antwerp, Belgium.
   [van de Heyning, Paul] Univ Antwerp, Expt Lab Translat Neurosci & Dentootolaryngol, Fac Med & Hlth Sci, Antwerp, Belgium.
   [Firszt, Jill B.] Washington Univ, Sch Med, St Louis, MO USA.
   [Bruce, Iain A.] Manchester Univ Hosp NHS Fdn Trust, Manchester Acad Hlth Sci Ctr, Oxford Rd, Manchester M13 9WL, Lancs, England.
   [Bruce, Iain A.] Univ Manchester, Fac Biol Med & Hlth, Div Infect Immun & Resp Med, Oxford Rd, Manchester M13 9PL, Lancs, England.
RP Kitterick, PT (corresponding author), Natl Inst Hlth Res NIHR Nottingham Biomed Res Ctr, Ropewalk House,113 Ropewalk, Nottingham NG1 5DU, England.; Kitterick, PT (corresponding author), Univ Nottingham, Sch Med, Div Clin Neurosci, Hearing Sci, Nottingham NG7 2UH, England.
EM padraig.kitterick@nottingham.ac.uk
RI Van de Heyning, Paul/I-8278-2017
OI Van de Heyning, Paul/0000-0002-8424-3717; Katiri,
   Roulla/0000-0001-7098-8024; Kitterick, Padraig/0000-0001-8383-5318;
   Bruce, Iain/0000-0003-0831-4760; Hall, Deborah/0000-0002-3804-1452
FU National Institute for Health Research (NIHR) Nottingham Biomedical
   Research Centre (BRC) [BRC-1215-20003]; Graham Fraser Foundation; Oticon
   Medical(TM)
FX The main body of work for this project is funded by the National
   Institute for Health Research (NIHR) Nottingham Biomedical Research
   Centre (BRC), funding reference number BRC-1215-20003. Additional grants
   obtained are as follows: Graham Fraser Foundation Travel Grant to attend
   the 15th International Conference on Cochlear Implants and Other
   Implantable Auditory Technology (Ci2018.org), where the study was first
   launched. Oticon Medical (TM) provided funding to purchase the
   DelphiManager software from the COMET Initiative, University of
   Liverpool. DAH is an NIHR Senior Investigator. The funding bodies had no
   role in the study design and implementation, writing of the report, or
   the decision to submit the report for publication.
CR Agterberg MJH, 2012, HEARING RES, V286, P9, DOI 10.1016/j.heares.2012.02.012
   Alkhaffaf B, 2017, TRIALS, V18, DOI 10.1186/s13063-017-2100-7
   Arndt S, 2017, HNO, V65, P586, DOI 10.1007/s00106-016-0294-8
   Arndt S, 2011, OTOL NEUROTOL, V32, P39, DOI 10.1097/MAO.0b013e3181fcf271
   Baguley DM, 2006, CLIN OTOLARYNGOL, V31, P6, DOI 10.1111/j.1749-4486.2006.01137.x
   Blackwood B, 2015, TRIALS, V16, DOI 10.1186/s13063-015-0905-9
   Boers M, 2014, J CLIN EPIDEMIOL, V67, P745, DOI 10.1016/j.jclinepi.2013.11.013
   Bosman AJ, 2003, ACTA OTO-LARYNGOL, V123, P258, DOI 10.1080/000164580310001105
   Brookes ST, 2016, TRIALS, V17, DOI 10.1186/s13063-016-1479-x
   Bruce I, 2015, HEALTH TECHNOL ASSES, V19, P1, DOI 10.3310/hta19680
   Carlsson PI, 2011, INT J AUDIOL, V50, P139, DOI 10.3109/14992027.2010.533705
   Chan AW, 2013, BMJ-BRIT MED J, V346, DOI 10.1136/bmj.e7586
   Clarke M, 2016, SYST REV, V5, DOI 10.1186/s13643-016-0188-6
   Clarke M, 2007, TRIALS, V8, DOI 10.1186/1745-6215-8-39
   COMET, DELPHIMANAGER
   Core Outcome Measures in Effectiveness Trials (COMET), GLOSS COR OUTC SET C
   Core Outcome Measures in Effectiveness Trials (COMET), TIPS DES ACC COR OUT
   Core Outcome Measures in Effectiveness Trials (COMET), CONS OUTC MEAS INT S
   Core Outcome Measures in Effectiveness Trials (COMET), EV PART EXP CONS M
   Daniels RL, 2000, AM J OTOL, V21, P173, DOI 10.1016/S0196-0709(00)80005-8
   de Heyning PV, 2008, ANN OTO RHINOL LARYN, V117, P645, DOI 10.1177/000348940811700903
   Desmet JBJ, 2012, OTOL NEUROTOL, V33, P1018, DOI 10.1097/MAO.0b013e31825e79ba
   Doge J, 2017, OTOL NEUROTOL, V38, pE563, DOI 10.1097/MAO.0000000000001520
   Dworkin RH, 2005, PAIN, V113, P9, DOI 10.1016/j.pain.2004.09.012
   Dwyer NY, 2014, EAR HEARING, V35, P126, DOI 10.1097/AUD.0b013e3182a3648b
   Fackrell K, 2017, TRIALS, V18, DOI 10.1186/s13063-017-2123-0
   Firszt JB, 2012, OTOL NEUROTOL, V33, P1339, DOI 10.1097/MAO.0b013e318268d52d
   Gandhi GY, 2008, JAMA-J AM MED ASSOC, V299, P2543, DOI 10.1001/jama.299.21.2543
   Gargon E, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099111
   GIOLAS TG, 1967, J SPEECH HEAR DISORD, V32, P336, DOI 10.1044/jshd.3204.336
   Gorgon E, 2019, J CLIN EPIDEMIOL, V108, P110, DOI 10.1016/j.jclinepi.2018.12.010
   Grantham DW, 2012, EAR HEARING, V33, P595, DOI 10.1097/AUD.0b013e3182503e5e
   Grossmann W, 2016, OTOL NEUROTOL, V37, P658, DOI 10.1097/MAO.0000000000001043
   Guyatt GH, 2011, J CLIN EPIDEMIOL, V64, P1283, DOI 10.1016/j.jclinepi.2011.01.012
   Hall DA, 2018, SYSTEMATIC REV OUTCO
   Hall DA, 2019, OTOL NEUROTOL, V40, pE474, DOI 10.1097/MAO.0000000000001937
   Hall DA, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216518824827
   Hall DA, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518814384
   Hall DA, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0201378
   HARFORD E, 1965, J SPEECH HEAR DISORD, V30, P121, DOI 10.1044/jshd.3002.121
   Harkonen K, 2017, EUR ARCH OTO-RHINO-L, V274, P3599, DOI 10.1007/s00405-017-4690-9
   Harkonen K, 2015, ORL J OTO-RHINO-LARY, V77, P339, DOI 10.1159/000439176
   Harman NL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129514
   Harman NL, 2013, TRIALS, V14, DOI 10.1186/1745-6215-14-70
   Hawley ML, 2004, J ACOUST SOC AM, V115, P833, DOI 10.1121/1.1639908
   Holder JT, 2017, AM J OTOLARYNG, V38, P226, DOI 10.1016/j.amjoto.2017.01.020
   Hoth Sebastian, 2016, Cochlear Implants Int, V17, P190
   Indeyeva YA, 2015, AM J OTOLARYNG, V36, P810, DOI 10.1016/j.amjoto.2015.06.003
   Jacob R, 2011, HNO, V59, P453, DOI 10.1007/s00106-011-2321-0
   Keeley T, 2016, TRIALS, V17, DOI 10.1186/s13063-016-1356-7
   Keeney S, 2001, INT J NURS STUD, V38, P195, DOI 10.1016/S0020-7489(00)00044-4
   Kirkham JJ, 2017, PLOS MED, V14, DOI 10.1371/journal.pmed.1002447
   Kirkham JJ, 2016, PLOS MED, V13, DOI 10.1371/journal.pmed.1002148
   Kirkham JJ, 2015, TRIALS, V16, DOI 10.1186/s13063-015-0913-9
   Kirwan John R, 2005, J Rheumatol, V32, P2250
   Kitterick PT, 2015, AUDIOL NEURO-OTOL, V20, P79, DOI 10.1159/000380753
   Kitterick PT, 2016, EAR HEARING, V37, P495, DOI 10.1097/AUD.0000000000000313
   Krempaska S, 2014, EUR ARCH OTO-RHINO-L, V271, P1395, DOI 10.1007/s00405-013-2565-2
   Laske RD, 2015, OTOL NEUROTOL, V36, P1151, DOI 10.1097/MAO.0000000000000791
   Leterme G, 2015, AUDIOL NEURO-OTOL, V20, P251, DOI 10.1159/000381329
   LEVITT H, 1967, J ACOUST SOC AM, V42, P820, DOI 10.1121/1.1910654
   Lin LM, 2006, OTOL NEUROTOL, V27, P172, DOI 10.1097/01.mao.0000196421.30275.73
   Linstrom CJ, 2009, LARYNGOSCOPE, V119, P713, DOI 10.1002/lary.20164
   Lucas L, 2018, INT J AUDIOL, V57, P21, DOI 10.1080/14992027.2017.1398420
   Mease PJ, 2008, ARTHRIT RHEUM-ARTHR, V59, P952, DOI 10.1002/art.23826
   Mertens G, 2016, HEARING RES, V331, P1, DOI 10.1016/j.heares.2015.09.016
   Mertens G, 2013, OTOL NEUROTOL, V34, P662, DOI 10.1097/MAO.0b013e31828779f0
   MILLER AB, 1981, CANCER, V47, P207, DOI 10.1002/1097-0142(19810101)47:1<207::AID-CNCR2820470134>3.0.CO;2-6
   Moher D, 2010, BMJ-BRIT MED J, V340, DOI [10.1136/bmj.c869, 10.1016/j.jclinepi.2010.03.004]
   Moore BCJ, 2013, INT J AUDIOL, V52, P678, DOI 10.3109/14992027.2013.809483
   Newman CW, 2008, OTOL NEUROTOL, V29, P1123, DOI 10.1097/MAO.0b013e31817dad20
   Niparko JK, 2003, OTOL NEUROTOL, V24, P73, DOI 10.1097/00129492-200301000-00015
   Peters JPM, 2015, LARYNGOSCOPE, V125, P218, DOI 10.1002/lary.24865
   Pfiffner F, 2011, EAR HEARING, V32, P40, DOI 10.1097/AUD.0b013e3181ecd002
   Popelka Gerald R., 2010, Seminars in Hearing, V31, P393, DOI 10.1055/s-0030-1268037
   Punte AK, 2013, HEARING RES, V295, P24, DOI 10.1016/j.heares.2012.08.003
   Punte Andrea Kleine, 2011, Cochlear Implants Int, V12 Suppl 1, pS26, DOI 10.1179/146701011X13001035752336
   Ryu NG, 2015, EUR ARCH OTO-RHINO-L, V272, P2213, DOI 10.1007/s00405-014-3133-0
   Saliba I, 2011, AURIS NASUS LARYNX, V38, P570, DOI 10.1016/j.anl.2011.01.008
   Schafer EC, 2013, J ACAD REHABIL AUDIO, V46, P62
   Schmerber S, 2017, EUR ARCH OTO-RHINO-L, V274, P1835, DOI 10.1007/s00405-016-4228-6
   Schmitt J, 2015, J INVEST DERMATOL, V135, P24, DOI 10.1038/jid.2014.320
   Schreiber BE, 2010, LANCET, V375, P1203, DOI 10.1016/S0140-6736(09)62071-7
   Serrano-Aguilar P, 2009, SOC SCI MED, V69, P920, DOI 10.1016/j.socscimed.2009.07.005
   Sinha IP, 2012, TRIALS, V13, DOI 10.1186/1745-6215-13-103
   Sinha IP, 2011, PLOS MED, V8, DOI 10.1371/journal.pmed.1000393
   Sinha IP, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006276
   Smith Harriet, 2018, Res Involv Engagem, V4, P8, DOI 10.1186/s40900-018-0091-5
   Snapp HA, 2017, OTOL NEUROTOL, V38, P1397, DOI 10.1097/MAO.0000000000001614
   Snapp HA, 2017, OTOL NEUROTOL, V38, P11, DOI 10.1097/MAO.0000000000001269
   Song JJ, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00210
   Song JJ, 2013, HEARING RES, V299, P1, DOI 10.1016/j.heares.2013.02.001
   Staecker H, 2000, AM J OTOL, V21, P399, DOI 10.1016/S0196-0709(00)80051-4
   Tavora-Vieira D, 2015, EAR HEARING, V36, pE93, DOI 10.1097/AUD.0000000000000130
   Tavora-Vieira D, 2015, OTOL NEUROTOL, V36, P430, DOI 10.1097/MAO.0000000000000707
   Turk DC, 2004, ARTHRITIS RES THER, V6, P151, DOI 10.1186/ar1196
   van de Heyning P, 2016, J LARYNGOL OTOL, V130, pS40, DOI [10.1017/S0022215116002401, DOI 10.1017/S0022215116002401]
   Van de Heyning P, 2016, AUDIOL NEURO-OTOL, V21, P391, DOI 10.1159/000455058
   Vas V, 2017, TRENDS HEAR, V21, P1, DOI 10.1177/2331216517734088
   Wazen JJ, 2005, OTOLARYNG HEAD NECK, V132, P928, DOI 10.1016/j.otohns.2005.03.014
   Wazen JJ, 2003, OTOLARYNG HEAD NECK, V129, P248, DOI 10.1016/S0194-5998(03)00527-8
   WEBER BA, 1992, LARYNGOSCOPE, V102, P538, DOI 10.1288/00005537-199205000-00013
   Welsh LW, 2004, ANN OTO RHINOL LARYN, V113, P987, DOI 10.1177/000348940411301209
   Williamson P, 2012, COCHRANE DB SYST REV, DOI 10.1002/14651858.ED000041
   Williamson PR, 2012, TRIALS, V13, DOI 10.1186/1745-6215-13-132
   WILLIAMSON PR, 2017, TRIALS S3, V18, DOI DOI 10.1186/S13063-017-1978-4
   Wu QR, 2019, EUR ARCH OTO-RHINO-L, V276, P665, DOI 10.1007/s00405-018-5260-5
   Young Bridget, 2016, Res Involv Engagem, V2, P25, DOI 10.1186/s40900-016-0039-6
   Zwarenstein M, 2008, BRIT MED J, V337, DOI 10.1136/bmj.a2390
NR 109
TC 1
Z9 1
U1 4
U2 4
PU BMC
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
EI 1745-6215
J9 TRIALS
JI Trials
PD MAR 4
PY 2020
VL 21
IS 1
AR 238
DI 10.1186/s13063-020-4094-9
PG 14
WC Medicine, Research & Experimental
SC Research & Experimental Medicine
GA KU8AK
UT WOS:000519934000001
PM 32131880
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Rios-Lopez, P
   Molinaro, N
   Bourguignon, M
   Lallier, M
AF Rios-Lopez, Paula
   Molinaro, Nicola
   Bourguignon, Mathieu
   Lallier, Marie
TI Development of neural oscillatory activity in response to speech in
   children from 4 to 6 years old
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
DE coherence; language development; language lateralization; neural
   entrainment; reading acquisition; speech perception
ID STEADY-STATE RESPONSES; LANGUAGE LATERALIZATION; AUDITORY-CORTEX;
   CORTICAL ENTRAINMENT; HEMISPHERIC-ASYMMETRY; ATTENDED SPEECH; MOTOR
   CORTEX; ENVELOPE; DYSLEXIA; FMRI
AB Recent neurophysiological theories propose that the cerebral hemispheres collaborate to resolve the complex temporal nature of speech, such that left-hemisphere (or bilateral) gamma-band oscillatory activity would specialize in coding information at fast rates (phonemic information), whereas right-hemisphere delta- and theta-band activity would code for speech's slow temporal components (syllabic and prosodic information). Despite the relevance that neural entrainment to speech might have for reading acquisition and for core speech perception operations such as the perception of intelligible speech, no study had yet explored its development in young children. In the current study, speech-brain entrainment was recorded via EEG in a cohort of children at three different time points since they were 4-5 to 6-7 years of age. Our results showed that speech-brain entrainment occurred only at delta frequencies (0.5 Hz) at all testing times. The fact that, from the longitudinal perspective, coherence increased in bilateral temporal electrodes suggests that, contrary to previous hypotheses claiming for an innate right-hemispheric bias for processing prosodic information, at 7 years of age the low-frequency components of speech are processed in a bilateral manner. Lastly, delta speech-brain entrainment in the right hemisphere was related to an indirect measure of intelligibility, providing preliminary evidence that the entrainment phenomenon might support core linguistic operations since early childhood.
C1 [Rios-Lopez, Paula; Molinaro, Nicola; Bourguignon, Mathieu; Lallier, Marie] BCBL Basque Ctr Cognit Brain & Language, Donostia San Sebastian, Spain.
   [Molinaro, Nicola] Ikerbasque Basque Fdn Sci, Bilbao, Spain.
   [Bourguignon, Mathieu] Univ Libre Bruxelles, Lab Cartog Fonct Cerveau, Brussels, Belgium.
RP Rios-Lopez, P (corresponding author), BCBL Basque Ctr Cognit Brain & Language, Donostia San Sebastian, Spain.
EM p.rios@bcbl.eu
RI Molinaro, Nicola/D-2208-2014; Rios Lopez, Paula/H-7743-2015
OI Molinaro, Nicola/0000-0002-7549-6042; Rios Lopez,
   Paula/0000-0002-1969-3359
FU Spanish Ministry of Economy, Industry and Competitiveness
   [PSI2015-6533-P]; Basque GovernmentBasque Government [PI_2016_1_0014];
   Gipuzkoako Foru Aldundia [EXP.99/17]; Severo Ochoa Program
   [SEV-2015-049]
FX The research presented in this study was partially supported by: grant
   PSI2015-6533-P from the Spanish Ministry of Economy, Industry and
   Competitiveness to Dr. Marie Lallier; grant PI_2016_1_0014 from the
   Basque Government and grant EXP.99/17 from the Gipuzkoako Foru Aldundia
   to Dr. Nicola Molinaro; and grant SEV-2015-049 from the Severo Ochoa
   Program.
CR Abrams DA, 2008, J NEUROSCI, V28, P3958, DOI 10.1523/JNEUROSCI.0187-08.2008
   Abrams DA, 2009, J NEUROSCI, V29, P7686, DOI 10.1523/JNEUROSCI.5242-08.2009
   Anthony JL, 2005, CURR DIR PSYCHOL SCI, V14, P255, DOI 10.1111/j.0963-7214.2005.00376.x
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   BENNINGER C, 1984, ELECTROEN CLIN NEURO, V57, P1, DOI 10.1016/0013-4694(84)90002-6
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   Bortel R, 2007, SIGNAL PROCESS, V87, P1100, DOI 10.1016/j.sigpro.2006.10.003
   Bourguignon M, 2018, NEUROIMAGE, V169, P200, DOI 10.1016/j.neuroimage.2017.12.033
   Bourguignon M, 2013, HUM BRAIN MAPP, V34, P314, DOI 10.1002/hbm.21442
   Brown TT, 2005, CEREB CORTEX, V15, P275, DOI 10.1093/cercor/bhh129
   Carreiras M, 2009, NATURE, V461, P983, DOI 10.1038/nature08461
   Clumeck C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0092329
   Conway BA, 1995, J PHYSIOL-LONDON, V489, P917, DOI 10.1113/jphysiol.1995.sp021104
   Crosse MJ, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00604
   de Bruin A, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00522
   De Vos A, 2017, CORTEX, V93, P206, DOI 10.1016/j.cortex.2017.05.007
   Dehaene S, 2010, SCIENCE, V330, P1359, DOI 10.1126/science.1194140
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   Destoky F, 2019, NEUROIMAGE, V184, P201, DOI 10.1016/j.neuroimage.2018.09.006
   Di Liberto GM, 2018, NEUROIMAGE, V175, P70, DOI 10.1016/j.neuroimage.2018.03.072
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Ding N, 2014, NEUROIMAGE, V88, P41, DOI 10.1016/j.neuroimage.2013.10.054
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Ding N, 2012, J NEUROPHYSIOL, V107, P78, DOI 10.1152/jn.00297.2011
   Doelling KB, 2019, P NATL ACAD SCI USA, V116, P10113, DOI 10.1073/pnas.1816414116
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P1053, DOI 10.1121/1.408467
   Friederici AD, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020726
   Fuglsang SA, 2017, NEUROIMAGE, V156, P435, DOI 10.1016/j.neuroimage.2017.04.026
   Gaillard WD, 2003, HUM BRAIN MAPP, V18, P176, DOI 10.1002/hbm.10091
   Garcia TP, 2017, CURR NEUROL NEUROSCI, V17, DOI 10.1007/s11910-017-0723-4
   Gelman A., 2006, DATA ANAL USING REGR
   Ghinst MV, 2016, J NEUROSCI, V36, P1596, DOI 10.1523/JNEUROSCI.1730-15.2016
   Ghitza O, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00130
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Gross J, 2005, NEUROIMAGE, V26, P91, DOI 10.1016/j.neuroimage.2005.01.025
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Halliday DM, 1995, PROG BIOPHYS MOL BIO, V64, P237, DOI 10.1016/S0079-6107(96)00009-0
   Hamalainen JA, 2012, NEUROIMAGE, V59, P2952, DOI 10.1016/j.neuroimage.2011.09.075
   Holland SK, 2001, NEUROIMAGE, V14, P837, DOI 10.1006/nimg.2001.0875
   Homae F, 2006, NEUROSCI RES, V54, P276, DOI 10.1016/j.neures.2005.12.006
   Howard MF, 2012, NEUROIMAGE, V60, P2118, DOI 10.1016/j.neuroimage.2012.02.028
   Hull R, 2007, NEUROPSYCHOLOGIA, V45, P1987, DOI 10.1016/j.neuropsychologia.2007.03.002
   Hyvarinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722
   Kadis DS, 2011, J INT NEUROPSYCH SOC, V17, P896, DOI 10.1017/S1355617711000932
   Kalashnikova M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32150-6
   LAIRD NM, 1982, BIOMETRICS, V38, P963, DOI 10.2307/2529876
   Lallier M., 2018, READING DYSLEXIA, P141, DOI [DOI 10.1007/978-3-319-90805-2_8, 10.1007/978-3-319-90805-2_8]
   Lallier M, 2017, CLIN PSYCHOL SCI, V5, P379, DOI 10.1177/2167702616670119
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Lizarazu M, 2015, HUM BRAIN MAPP, V36, P4986, DOI 10.1002/hbm.22986
   Meyer L, 2018, J COGNITIVE NEUROSCI, V30, P1066, DOI 10.1162/jocn_a_01236
   Meyer L, 2017, CEREB CORTEX, V27, P4293, DOI 10.1093/cercor/bhw228
   Molinaro N, 2018, EUR J NEUROSCI, V48, P2642, DOI 10.1111/ejn.13811
   Molinaro N, 2016, HUM BRAIN MAPP, V37, P2767, DOI 10.1002/hbm.23206
   Morrell CH, 1998, BIOMETRICS, V54, P1560, DOI 10.2307/2533680
   Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058
   Nunez PL, 2000, BRAIN TOPOGR, V13, P79, DOI 10.1023/A:1026683200895
   Papanicolaou AC, 2006, NEUROIMAGE, V33, P326, DOI 10.1016/j.neuroimage.2006.06.020
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Peirce JW, 2009, FRONT NEUROINFORM, V2, DOI 10.3389/neuro.11.010.2008
   Pena M, 2003, P NATL ACAD SCI USA, V100, P11702, DOI 10.1073/pnas.1934290100
   Pena M, 2010, P NATL ACAD SCI USA, V107, P3823, DOI 10.1073/pnas.0914326107
   Perani D, 2011, P NATL ACAD SCI USA, V108, P16056, DOI 10.1073/pnas.1102991108
   Perez-Navarro J. J., 2018, 1 WORKSH PRED PROC D
   Picton T., 2011, EAR HEARING, V33, P301, DOI [10.1097/AUD.0b013e3182498db9, DOI 10.1097/AUD.0B013E3182498DB9]
   Pihko E, 2005, CLIN NEUROPHYSIOL, V116, P112, DOI 10.1016/j.clinph.2004.07.005
   Poelmans H, 2012, JARO-J ASSOC RES OTO, V13, P867, DOI 10.1007/s10162-012-0348-x
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Poeppel D, 2008, PHILOS T R SOC B, V363, P1071, DOI 10.1098/rstb.2007.2160
   Pohja M, 2005, NEUROIMAGE, V26, P764, DOI 10.1016/j.neuroimage.2005.02.031
   Pollok B, 2004, J PHYSIOL-LONDON, V554, P871, DOI 10.1113/jphysiol.2003.051235
   Power AJ, 2016, BRAIN LANG, V160, P1, DOI 10.1016/j.bandl.2016.06.006
   Power AJ, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00777
   R Core Team, 2017, R LANG ENV STAT COMP
   Ramus F, 2000, SCIENCE, V288, P349, DOI 10.1126/science.288.5464.349
   Ressel V, 2008, BRAIN LANG, V106, P167, DOI 10.1016/j.bandl.2008.01.004
   Salenius S, 1997, J NEUROPHYSIOL, V77, P3401
   Shahin AJ, 2010, J NEUROPHYSIOL, V103, P218, DOI 10.1152/jn.00402.2009
   Spironelli C, 2009, BIOL PSYCHOL, V80, P35, DOI 10.1016/j.biopsycho.2008.01.012
   Szaflarski JP, 2006, HUM BRAIN MAPP, V27, P202, DOI 10.1002/hbm.20177
   Telkemeyer S, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00062
   Telkemeyer S, 2009, J NEUROSCI, V29, P14726, DOI 10.1523/JNEUROSCI.1246-09.2009
   THATCHER RW, 1992, BRAIN COGNITION, V20, P24, DOI 10.1016/0278-2626(92)90060-Y
   van der Reijden CS, 2005, EAR HEARING, V26, P299, DOI 10.1097/00003446-200506000-00006
   Van Dun B, 2009, J ACOUST SOC AM, V126, P254, DOI 10.1121/1.3133872
   Vander Ghinst M, 2019, J NEUROSCI, V39, P2938, DOI 10.1523/JNEUROSCI.1732-18.2019
   Vanvooren S, 2014, J NEUROSCI, V34, P1523, DOI 10.1523/JNEUROSCI.3209-13.2014
   Vouloumanos A, 2007, DEVELOPMENTAL SCI, V10, P159, DOI 10.1111/j.1467-7687.2007.00549.x
   Wood AG, 2004, NEUROLOGY, V63, P1035, DOI 10.1212/01.WNL.0000140707.61952.CA
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
   Zuur AF, 2010, METHODS ECOL EVOL, V1, P3, DOI 10.1111/j.2041-210X.2009.00001.x
NR 97
TC 0
Z9 0
U1 2
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD NOV
PY 2020
VL 23
IS 6
AR e12947
DI 10.1111/desc.12947
EA MAR 2020
PG 16
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA OU2MM
UT WOS:000518215000001
PM 32043677
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Strand, JF
   Brown, VA
   Barbour, DL
AF Strand, Julia F.
   Brown, Violet A.
   Barbour, Dennis L.
TI Talking Points: A Modulating Circle Increases Listening Effort Without
   Improving Speech Recognition in Young Adults
SO PSYCHONOMIC BULLETIN & REVIEW
LA English
DT Article
DE spoken word recognition; speech perception; cross-modal attention
ID AUDIOVISUAL SPEECH; OLDER-ADULTS; INTELLIGIBILITY; INFORMATION; TASK
AB Speech recognition is improved when the acoustic input is accompanied by visual cues provided by a talking face (Erber in Journal of Speech and Hearing Research, 12(2), 423-425, 1969; Sumby & Pollack in The Journal of the Acoustical Society of America, 26(2), 212-215, 1954). One way that the visual signal facilitates speech recognition is by providing the listener with information about fine phonetic detail that complements information from the auditory signal. However, given that degraded face stimuli can still improve speech recognition accuracy (Munhall, Kroos, Jozan, & Vatikiotis-Bateson in Perception & Psychophysics, 66(4), 574-583, 2004), and static or moving shapes can improve speech detection accuracy (Bernstein, Auer, & Takayanagi in Speech Communication, 44(1-4), 5-18, 2004), aspects of the visual signal other than fine phonetic detail may also contribute to the perception of speech. In two experiments, we show that a modulating circle providing information about the onset, offset, and acoustic amplitude envelope of the speech does not improve recognition of spoken sentences (Experiment 1) or words (Experiment 2). Further, contrary to our hypothesis, the modulating circle increased listening effort despite subjective reports that it made the word recognition task seem easier to complete (Experiment 2). These results suggest that audiovisual speech processing, even when the visual stimulus only conveys temporal information about the acoustic signal, may be a cognitively demanding process.
C1 [Strand, Julia F.; Brown, Violet A.] Carleton Coll, Dept Psychol, Northfield, MN 55057 USA.
   [Barbour, Dennis L.] Washington Univ, Dept Biomed Engn, St Louis, MO 63110 USA.
RP Strand, JF (corresponding author), Carleton Coll, Dept Psychol, Northfield, MN 55057 USA.
EM jstrand@carleton.edu
CR Alhanbali S, 2019, EAR HEARING, V40, P1084, DOI 10.1097/AUD.0000000000000697
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bernstein LE, 2004, SPEECH COMMUN, V44, P5, DOI 10.1016/j.specom.2004.10.011
   Brown Violet A, 2019, J Cogn, V2, P44, DOI 10.5334/joc.89
   Brysbaert M, 2012, BEHAV RES METHODS, V44, P991, DOI 10.3758/s13428-012-0190-4
   DOWNS DW, 1982, J SPEECH HEAR DISORD, V47, P189, DOI 10.1044/jshd.4702.189
   ERBER NP, 1969, J SPEECH HEAR RES, V12, P423, DOI 10.1044/jshr.1202.423
   Gagne JP, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216516687287
   Gosselin PA, 2011, INT J AUDIOL, V50, P786, DOI 10.3109/14992027.2011.599870
   Grant KW, 2004, SPEECH COMMUN, V44, P43, DOI 10.1016/j.specom.2004.06.004
   Grant KW, 1996, J ACOUST SOC AM, V100, P2415, DOI 10.1121/1.417950
   Helfer KS, 2005, J ACOUST SOC AM, V117, P842, DOI 10.1121/1.1836832
   Jordan TR, 2000, LANG SPEECH, V43, P107, DOI 10.1177/00238309000430010401
   Kahneman D., 1973, ATTENTION EFFORT
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Kim J, 2004, SPEECH COMMUN, V44, P19, DOI 10.1016/j.specom.2004.09.008
   Koch I, 2018, PSYCHOL BULL, V144, P557, DOI 10.1037/bul0000144
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Munhall KG, 2004, PERCEPT PSYCHOPHYS, V66, P574, DOI 10.3758/BF03194902
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Picou EM, 2014, EAR HEARING, V35, P611, DOI 10.1097/AUD.0000000000000055
   RABBITT PMA, 1968, Q J EXP PSYCHOL, V20, P241, DOI 10.1080/14640746808400158
   Rosenblum LD, 1996, J SPEECH HEAR RES, V39, P1159, DOI 10.1044/jshr.3906.1159
   Sarampalis A, 2009, J SPEECH LANG HEAR R, V52, P1230, DOI 10.1044/1092-4388(2009/08-0111)
   Schwartz JL, 2004, COGNITION, V93, pB69, DOI 10.1016/j.cognition.2004.01.006
   Seeman S, 2015, J SPEECH LANG HEAR R, V58, P1781, DOI 10.1044/2015_JSLHR-H-14-0180
   Strand J. F., 2018, J SPEECH LANGUAGE HE
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1979, PHONETICA, V36, P314, DOI 10.1159/000259969
   Tye-Murray N, 2011, EAR HEARING, V32, P650, DOI 10.1097/AUD.0b013e31821a4578
   Van Engen KJ, 2014, J SPEECH LANG HEAR R, V57, P1908, DOI 10.1044/JSLHR-H-13-0076
NR 32
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1069-9384
EI 1531-5320
J9 PSYCHON B REV
JI Psychon. Bull. Rev.
PD JUN
PY 2020
VL 27
IS 3
BP 536
EP 543
DI 10.3758/s13423-020-01713-y
EA MAR 2020
PG 8
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA LY8PG
UT WOS:000518063700002
PM 32128719
DA 2021-02-24
ER

PT J
AU Larraza, S
   Molnar, M
   Samuel, AG
AF Larraza, Saioa
   Molnar, Monika
   Samuel, Arthur G.
TI Phonemic contrasts under construction? Evidence from Basque
SO INFANCY
LA English
DT Article
DE Basque sibilant consonants; bilingualism; habituation procedure;
   infants; phonemic discrimination
ID SPEECH-PERCEPTION; DEVELOPMENTAL-CHANGES; LANGUAGE-EXPERIENCE; 1ST YEAR;
   DISCRIMINATION; INFANTS; ACQUISITION; REORGANIZATION; ADULTS; STOP
AB Attunement theories of speech perception development suggest that native-language exposure is one of the main factors shaping infants' phonemic discrimination capacity within the second half of their first year. Here, we focus on the role of acoustic-perceptual salience and language-specific experience by assessing the discrimination of acoustically subtle Basque sibilant contrasts. We used the infant-controlled version of the habituation procedure to assess discrimination in 6- to 7-month and 11- to 12-month-old infants who varied in their amount of exposure to Basque and Spanish. We observed no significant variation in the infants' discrimination behavior as a function of their linguistic experience. Infants in both age-groups exhibited poor discrimination, consistent with Basque adults finding these contrasts more difficult than some others. Our findings are in agreement with previous research showing that perceptual discrimination of subtle speech sound contrasts may follow a different developmental trajectory, where increased native-language exposure seems to be a requisite.
C1 [Larraza, Saioa] Univ Basque Country, Vitoria, Spain.
   [Larraza, Saioa; Samuel, Arthur G.] BCBL Basque Ctr Cognit Brain & Language, San Sebastian, Spain.
   [Molnar, Monika] Univ Toronto, Dept Speech Language Pathol, Toronto, ON, Canada.
   [Molnar, Monika] Univ Toronto, Rehabil Sci Inst, Toronto, ON, Canada.
   [Samuel, Arthur G.] Ikerbasque, Basque Fdn Sci, Bilbao, Spain.
   [Samuel, Arthur G.] SUNY Stony Brook, Dept Psychol, New York, NY USA.
RP Larraza, S (corresponding author), Univ Basque Country, UPV EHU, Juan Ibanez Santo Domingo 1, Vitoria 01006, Basque Country, Spain.
EM saioa.larraza@ehu.eus
OI LARRAZA ARNANZ, SAIOA/0000-0002-2248-5112
FU Centro de Excelencia Severo Ochoa [SEV-2015-0490]; Ministerio de Ciencia
   e InnovacionInstituto de Salud Carlos IIISpanish GovernmentEuropean
   Commission [PSI2017-82563-P]
FX Centro de Excelencia Severo Ochoa, Grant/Award Number: SEV-2015-0490;
   Ministerio de Ciencia e Innovacion, Grant/Award Number: PSI2017-82563-P
CR Albareda-Castellot B, 2011, DEVELOPMENTAL SCI, V14, P395, DOI 10.1111/j.1467-7687.2010.00989.x
   Anderson JL, 2003, LANG SPEECH, V46, P155, DOI 10.1177/00238309030460020601
   Aslin RN, 2002, J ACOUST SOC AM, V112, P1257, DOI 10.1121/1.1501904
   Bates D, 2013, LINEAR MIXED EFFECTS
   Best C. T., 1995, SPEECH PERCEPTION LI, P167
   Best C. T., 1991, BIENN M SOC RES CHIL
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Burns TC, 2007, APPL PSYCHOLINGUIST, V28, P455, DOI 10.1017/S0142716407070257
   Cohen L. B, 2000, HABIT 2000 NEW PROGR
   EILERS RE, 1977, J SPEECH HEAR RES, V20, P766, DOI 10.1044/jshr.2004.766
   EILERS RE, 1977, J ACOUST SOC AM, V61, P1321, DOI 10.1121/1.381435
   Gervain J, 2010, ANNU REV PSYCHOL, V61, P191, DOI 10.1146/annurev.psych.093008.100408
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Larraza S, 2016, J EXP PSYCHOL LEARN, V42, P1774, DOI 10.1037/xlm0000252
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Molnar M, 2014, LANG LEARN, V64, P45, DOI 10.1111/lang.12069
   Morey R. D., 2015, PACKAGE BAYESFACTOR
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Polka L, 1996, J ACOUST SOC AM, V100, P577, DOI 10.1121/1.415884
   Polka L, 2001, J ACOUST SOC AM, V109, P2190, DOI 10.1121/1.1362689
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   R Development Core Team, 2012, R LANG ENV STAT COMP
   Saffran J, 2014, LANG LEARN, V64, P106, DOI 10.1111/lang.12057
   Samuel AG, 2015, J MEM LANG, V81, P51, DOI 10.1016/j.jml.2015.01.003
   Sato Y, 2010, DEV PSYCHOL, V46, P106, DOI 10.1037/a0016718
   Sundara M, 2008, COGNITION, V108, P232, DOI 10.1016/j.cognition.2007.12.013
   Sundara M, 2006, COGNITION, V100, P369, DOI 10.1016/j.cognition.2005.04.007
   Sundara M, 2018, COGNITION, V178, P57, DOI 10.1016/j.cognition.2018.05.009
   Tsao FM, 2006, J ACOUST SOC AM, V120, P2285, DOI 10.1121/1.2338290
   Tsushima T., 1994, P INT C SPOK LANG PR, P1695
   Werker JF, 2012, CURR DIR PSYCHOL SCI, V21, P221, DOI 10.1177/0963721412449459
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Werker JF, 1999, ANNU REV PSYCHOL, V50, P509, DOI 10.1146/annurev.psych.50.1.509
NR 35
TC 0
Z9 0
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1525-0008
EI 1532-7078
J9 INFANCY
JI Infancy
PD MAY
PY 2020
VL 25
IS 3
BP 304
EP 318
DI 10.1111/infa.12330
EA MAR 2020
PG 15
WC Psychology, Developmental
SC Psychology
GA MW3GV
UT WOS:000517764900001
PM 32749062
DA 2021-02-24
ER

PT J
AU Ahmmed, AU
   Mukherjee, D
AF Ahmmed, Ansar Uddin
   Mukherjee, Dipankar
TI Auditory processing and non-auditory factors associated with hyperacusis
   in children with auditory processing disorder (APD)
SO HEARING BALANCE AND COMMUNICATION
LA English
DT Article; Early Access
DE Hyperacusis; auditory processing disorder; anxiety; pragmatic language
   impairment; externalising behaviour; sensory processing disorder
ID DEFICIT HYPERACTIVITY DISORDER; SCHOOL-AGE-CHILDREN; LANGUAGE
   IMPAIRMENT; DIAGNOSIS; SYMPTOMS; SPEECH; DIFFICULTIES; PERCEPTION;
   PROFILES; BEHAVIOR
AB Purpose: Prevalence of hyperacusis in children presenting with listening difficulties (LiD) or developmental auditory processing disorder (APD) is uncertain. The relationships between hyperacusis, auditory profiles and non-auditory factors are unclear, information which is important in understanding and managing APD and hyperacusis. Method: A retrospective study of 282 children with APD (165 males and 117 females) aged 6-16 years. Hyperacusis was ascertained by parental response to question about 'oversensitivity to sounds'. Auditory and non-auditory features including anxiety, attention deficit hyperactivity disorder and oppositional defiant symptoms, language profile and non-verbal ability (NVIQ) were compared between those with and without hyperacusis. Results: Of the 282 children 200 (70.9%) had hyperacusis. There were no significant differences in age, NVIQ and auditory processing profiles between the two groups (p > .05). In addition to poor speech perception in noise 79% of children performed poorly mainly in temporal processing and/or dichotic listening tests. The hyperacusis group had significantly more anxiety, hyperactivity/impulsivity, oppositional defiant symptoms and pragmatic language impairment when analyzed separately. However, only anxiety and language impairment were significant in binary logistic regression analyses. Conclusions: The prevalence of hyperacusis is high in APD, but auditory processing profiles were similar in those with and without hyperacusis. The high prevalence of anxiety, externalising behaviour, pragmatic language impairment in those with hyperacusis noted in APD is similar to those reported in children with autism spectrum disorder and Williams syndrome. However, when shared variances are addressed only anxiety and language impairment predicted hyperacusis. Holistic auditory processing assessment is suggested in hyperacusis.
C1 [Ahmmed, Ansar Uddin; Mukherjee, Dipankar] Lancashire Teaching Hosp NHS Fdn Trust, Paediat Audiol, Preston, Lancs, England.
RP Ahmmed, AU (corresponding author), Lancashire Teaching Hosp NHS Fdn Trust, Paediat Audiol, Fulwood Clin, 4 Lytham Rd, Preston PR2 8JB, Lancs, England.
EM aahmmed@hotmail.co.uk
OI Ahmmed, Ansar/0000-0003-0236-7191
CR Adamson A., 2006, BRIT J OCCUPATIONAL, V69, P357, DOI DOI 10.1177/030802260606900803
   Ahmmed AU, 2016, INT J PEDIATR OTORHI, V84, P166, DOI 10.1016/j.ijporl.2016.03.014
   Ahmmed AU, 2014, EAR HEARING, V35, P295, DOI 10.1097/01.aud.0000441034.02052.0a
   Ahmmed AU, 2019, HEARING BALANC COMMU, DOI 10.1080/21695717.2019.1644862
   Ahmmed AU, 2017, INT J PEDIATR OTORHI, V101, P178, DOI 10.1016/j.ijporl.2017.08.010
   Ahn RR, 2004, AM J OCCUP THER, V58, P287, DOI 10.5014/ajot.58.3.287
   Alda JA, 2013, ACTAS ESP PSIQUIATRI, V41, P76
   American Academy of Audiology, 2010, GUID DIAGN TREATM MA
   [Anonymous], 2015, AB 5 15
   Arnir I, 2018, INT J PEDIATR OTORHI, V112, P39, DOI 10.1016/j.ijporl.2018.06.015
   ASHA (2005) American Speech-Language-Hearing Associatio, 2005, TECHNICAL REPORT
   Avni E, 2018, FRONT PSYCHIATRY, V9, DOI 10.3389/fpsyt.2018.00717
   Bishop D., 2003, CHILDRENS COMMUNICAT
   British Society of Audiology, 2018, POS STAT PRACT GUID
   Davies PL, 2007, AM J OCCUP THER, V61, P176, DOI 10.5014/ajot.61.2.176
   Dawes P, 2008, INT J PEDIATR OTORHI, V72, P483, DOI 10.1016/j.ijporl.2007.12.007
   Dawes P, 2010, ARCH DIS CHILD, V95, P432, DOI 10.1136/adc.2009.170118
   de Wit E, 2016, J SPEECH LANG HEAR R, V59, P384, DOI 10.1044/2015_JSLHR-H-15-0118
   DeBonis DA, 2015, AM J AUDIOL, V24, P124, DOI 10.1044/2015_AJA-14-0037
   Department for Education; Education Funding Agency, 2015, AC DES SCH PERF STAN
   Dunn W., 1999, SENSORY PROFILE
   Elsabbagh M, 2011, J INTELL DISABIL RES, V55, P563, DOI 10.1111/j.1365-2788.2011.01411.x
   Emanuel DC, 2011, AM J AUDIOL, V20, P48, DOI 10.1044/1059-0889(2011/10-0019)
   Fackrell K, 2019, LANCET, V393, P404, DOI 10.1016/S0140-6736(18)32616-3
   Fackrell K, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/290425
   Friberg J. C., 2010, J ED AUDIOLOGY, V16, P4
   Gioia GA., 2000, BEHAV RATING INVENTO
   John AE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00199
   Katzenell U, 2001, OTOL NEUROTOL, V22, P321, DOI 10.1097/00129492-200105000-00009
   Keith R.W., 2009, SCAN 3 TESTS AUDITOR
   Keith R.W., 2009, SCAN 3 C TESTS AUDIT
   Khalfa S, 2004, HEARING RES, V198, P87, DOI 10.1016/j.heares.2004.07.006
   Khalfa S, 2002, ORL-J OTO-RHIN-LARYN, V64, P436, DOI 10.1159/000067570
   Landalv D, 2013, NOISE HEALTH, V15, P347, DOI 10.4103/1463-1741.116584
   Lane SJ, 2010, FRONT INTEGR NEUROSC, V4, DOI 10.3389/fnint.2010.00008
   Lawson RP, 2015, SCI REP-UK, V5, DOI 10.1038/srep16157
   Miller LJ, 2009, FRONT INTEGR NEUROSC, V3, DOI 10.3389/neuro.07.022.2009
   Miller LJ, 2007, AM J OCCUP THER, V61, P135, DOI 10.5014/ajot.61.2.135
   Miller LJ, 2012, RES DEV DISABIL, V33, P804, DOI 10.1016/j.ridd.2011.12.005
   Moore DR, 2018, J AM ACAD AUDIOL, V29, P364, DOI 10.3766/jaaa.16130
   Moore DR, 2013, HEARING BALANC COMMU, V11, P160, DOI 10.3109/21695717.2013.821756
   Moore DR, 2010, PEDIATRICS, V126, pE382, DOI 10.1542/peds.2009-2826
   Myne S, 2018, INT J PEDIATR OTORHI, V107, P80, DOI 10.1016/j.ijporl.2018.01.004
   Philofsky A, 2007, AM J SPEECH-LANG PAT, V16, P368, DOI 10.1044/1058-0360(2007/040)
   Rashid SKMU, 2018, INT J PEDIATR OTORHI, V114, P51, DOI 10.1016/j.ijporl.2018.07.054
   Rodas NV, 2017, J AUTISM DEV DISORD, V47, P3479, DOI 10.1007/s10803-017-3265-3
   Rodgers J, 2016, AUTISM RES, V9, P1205, DOI 10.1002/aur.1603
   Rosing SN, 2016, BMJ OPEN, V6, DOI 10.1136/bmjopen-2015-010596
   Smits-Engelsman B, 2015, HUM MOVEMENT SCI, V42, P293, DOI 10.1016/j.humov.2015.03.010
   Spyridakou C, 2012, LARYNGOSCOPE, V122, P1609, DOI 10.1002/lary.23337
   Swanson JM, 1983, SANP 4 26 ITEM TEACH
   Timler GR, 2014, AM J SPEECH-LANG PAT, V23, P73, DOI 10.1044/1058-0360(2013/12-0164)
   Van Hulle CA, 2012, J CHILD PSYCHOL PSYC, V53, P64, DOI 10.1111/j.1469-7610.2011.02432.x
   Vermiglio A., 2018, PERSPECT ASHA INTERE, V6, P6, DOI DOI 10.1044/PERSP3.SIG6.6
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   Widen S E Olsen, 2004, Noise Health, V7, P29
   Wilson WJ, 2019, INT J AUDIOL, V58, P516, DOI 10.1080/14992027.2019.1600057
NR 57
TC 1
Z9 1
U1 0
U2 3
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2169-5717
EI 2169-5725
J9 HEARING BALANC COMMU
JI Hearing Balanc. Commun.
DI 10.1080/21695717.2020.1727216
EA MAR 2020
PG 12
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA KS9PA
UT WOS:000518640800001
DA 2021-02-24
ER

PT J
AU Rasamimanana, M
   Barbaroux, M
   Cole, P
   Besson, M
AF Rasamimanana, Maud
   Barbaroux, Mylene
   Cole, Pascale
   Besson, Mireille
TI Semantic compensation and novel word learning in university students
   with dyslexia
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Students with dyslexia; Skilled readers; Novel word learning; Error
   rate; Reaction times; N200 component; N400 component; Sustained frontal
   negativity; LPC
ID DEVELOPMENTAL DYSLEXIA; ELECTROPHYSIOLOGICAL EVIDENCE; MORPHOLOGICAL
   AWARENESS; SPEECH-PERCEPTION; BRAIN POTENTIALS; LEXICAL DECISION; IMAGE
   AGREEMENT; NAME AGREEMENT; CHILDREN; ADULTS
AB The aim of this experiment was to use behavioral and electrophysiological methods to compare university students with dyslexia and matched skilled readers in a novel word learning experiment that included phonological categorization tasks, a word learning phase and a test phase with matching and semantic tasks. Specifically, we aimed at disentangling two hypotheses. If phonological processing drives novel word learning and if phonological processing is impaired in students with dyslexia, they should perform lower than skilled readers not only in the phonological categorization tasks but also in the matching and semantic tasks. By contrast, if students with dyslexia use semantic knowledge to compensate for their phonological deficits, should be able to reach the same level of performance and show similar enhancements of the N200 and N400 components than skilled readers in the matching and semantic tasks. Results at both behavioral and electrophysiological levels showed that the phonological deficits evidenced in the phonological tasks did not impede students with dyslexia to learn the meaning of novel words, possibly because they mobilized more frontal resources than skilled readers. These results are discussed within a general framework of semantic compensation in adults with dyslexia.
C1 [Rasamimanana, Maud; Barbaroux, Mylene; Besson, Mireille] CNRS, Lab Neurosci Cognit, Paris, France.
   [Rasamimanana, Maud; Barbaroux, Mylene; Cole, Pascale; Besson, Mireille] Aix Marseille Univ, ILCB, Federat 3C, Marseille, France.
   [Cole, Pascale] CNRS, Lab Psychol Cognit, Paris, France.
RP Rasamimanana, M (corresponding author), CNRS, Lab Neurosci Cognit, Paris, France.; Rasamimanana, M (corresponding author), Aix Marseille Univ, ILCB, Federat 3C, Marseille, France.
EM maud.rasamimanana@univ-amu.fr
FU CNRSCentre National de la Recherche Scientifique (CNRS)European
   Commission; French government through the Labex BLRI [ANR-11-LABX0036];
   ILCB [ANR11-IDEX-0001-02]; French Ministry of Research and Education
FX We would like to thank all the students who participated in this
   experiment as well as Charles-Elie Dangremont for help in behavioral
   testing and Abdessadek El Ahmadi for precious advices related to
   statistical analyses. This work, carried out within the Laboratoire de
   Neurosciences Cognitives has benefitted from the support of the CNRS and
   from the French government through the Labex BLRI (ANR-11-LABX0036) and
   the ILCB, managed by the French National Agency for Research (ANR),
   under the program "Investissements d'Avenir" (ANR11-IDEX-0001-02).
   Myl.ene Barbaroux is supported by a doctoral fellowship from the French
   Ministry of Research and Education.
CR Ahissar M, 2006, NAT NEUROSCI, V9, P1558, DOI 10.1038/nn1800
   Alario FX, 1999, BEHAV RES METH INS C, V31, P531, DOI 10.3758/BF03200732
   American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU
   Angwin AJ, 2014, NEUROPSYCHOLOGIA, V59, P169, DOI 10.1016/j.neuropsychologia.2014.05.002
   Arnbak E., 2000, SCAND J EDUC RES, V44, P229, DOI DOI 10.1080/00313830050154485
   Bakker I, 2015, NEUROPSYCHOLOGIA, V79, P33, DOI 10.1016/j.neuropsychologia.2015.10.020
   Banai K, 2010, DYSLEXIA, V16, P240, DOI 10.1002/dys.407
   Batterink L, 2011, J COGNITIVE NEUROSCI, V23, P3181, DOI 10.1162/jocn_a_00013
   BENTIN S, 1985, ELECTROEN CLIN NEURO, V60, P343, DOI 10.1016/0013-4694(85)90008-2
   BESSON M, 1992, J COGNITIVE NEUROSCI, V4, P132, DOI 10.1162/jocn.1992.4.2.132
   Betjemann RS, 2008, CHILD DEV, V79, P1086, DOI 10.1111/j.1467-8624.2008.01177.x
   Boets B, 2007, BRAIN LANG, V101, P19, DOI 10.1016/j.bandl.2006.06.009
   Boets B, 2013, SCIENCE, V342, P1251, DOI 10.1126/science.1244333
   Borovsky A, 2012, LANG LEARN DEV, V8, P278, DOI 10.1080/15475441.2011.614893
   Borovsky A, 2010, COGNITION, V116, P289, DOI 10.1016/j.cognition.2010.05.004
   Carey S., 1978, LINGUISTIC THEORY PS, P264
   Cavalli E, 2018, J LEARN DISABIL-US, V51, P268, DOI 10.1177/0022219417704637
   Cavalli E, 2017, CORTEX, V92, P204, DOI 10.1016/j.cortex.2017.04.012
   Cavalli E, 2017, ANN DYSLEXIA, V67, P63, DOI 10.1007/s11881-016-0138-y
   Cavalli E, 2016, J COGNITIVE NEUROSCI, V28, P1228, DOI 10.1162/jocn_a_00959
   Cavalli E, 2016, RES DEV DISABIL, V51-52, P89, DOI 10.1016/j.ridd.2016.01.006
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256
   Cooper A, 2013, J ACOUST SOC AM, V134, pEL133, DOI 10.1121/1.4812435
   Cooper A, 2012, J ACOUST SOC AM, V131, P4756, DOI 10.1121/1.4714355
   Daikhin L, 2017, J SPEECH LANG HEAR R, V60, P471, DOI 10.1044/2016_JSLHR-H-16-0114
   Deacon SH, 2012, ANN DYSLEXIA, V62, P120, DOI 10.1007/s11881-012-0068-2
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dittinger E, 2018, EUR J NEUROSCI, V47, P1504, DOI 10.1111/ejn.13939
   Dittinger E, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00233
   Dittinger E, 2016, J COGNITIVE NEUROSCI, V28, P1584, DOI 10.1162/jocn_a_00997
   Elbro C, 1996, ANN DYSLEXIA, V46, P209, DOI 10.1007/BF02648177
   ELBRO C, 1994, ANN DYSLEXIA, V44, P205, DOI 10.1007/BF02648162
   Elbro C., 1989, BRAIN READING STRUCT, P279
   Francois C, 2017, NEUROPSYCHOLOGIA, V98, P56, DOI 10.1016/j.neuropsychologia.2016.10.006
   Haft SL, 2016, CURR OPIN BEHAV SCI, V10, P133, DOI 10.1016/j.cobeha.2016.06.005
   Hagoort P, 2014, CURR OPIN NEUROBIOL, V28, P136, DOI 10.1016/j.conb.2014.07.013
   Hebert M, 2018, ANN DYSLEXIA, V68, P15, DOI 10.1007/s11881-017-0153-7
   Hennessey NW, 2012, J RES READ, V35, P267, DOI 10.1111/j.1467-9817.2010.01458.x
   HOLCOMB PJ, 1990, LANG COGNITIVE PROC, V5, P281, DOI 10.1080/01690969008407065
   Jones MW, 2018, COGNITION, V177, P214, DOI 10.1016/j.cognition.2018.04.010
   Junge C, 2012, NEUROPSYCHOLOGIA, V50, P3702, DOI 10.1016/j.neuropsychologia.2012.10.012
   Kahta S, 2019, DYSLEXIA, V25, P142, DOI 10.1002/dys.1618
   Kimppa L, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-31211-0
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657
   KUTAS M, 1988, ELECTROEN CLIN NEURO, V69, P218, DOI 10.1016/0013-4694(88)90131-9
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0
   Law JM, 2018, APPL PSYCHOLINGUIST, V39, P483, DOI 10.1017/S0142716417000467
   Law JM, 2015, DYSLEXIA, V21, P254, DOI 10.1002/dys.1495
   Livingston LA, 2017, NEUROSCI BIOBEHAV R, V80, P729, DOI 10.1016/j.neubiorev.2017.06.005
   Martin J., 2013, APPL PSYCHOLINGUIST, P1
   Martin J, 2010, ANN DYSLEXIA, V60, P238, DOI 10.1007/s11881-010-0043-8
   Mestres-Misse A, 2007, CEREB CORTEX, V17, P1858, DOI 10.1093/cercor/bhl094
   MEYER DE, 1971, J EXP PSYCHOL, V90, P227, DOI 10.1037/h0031564
   NICOLSON RI, 1990, COGNITION, V35, P159, DOI 10.1016/0010-0277(90)90013-A
   Nieuwland MS, 2019, NEUROSCI BIOBEHAV R, V96, P367, DOI 10.1016/j.neubiorev.2018.11.019
   Nobre AD, 2016, EDUC PSYCHOL-UK, V36, P753, DOI 10.1080/01443410.2014.950948
   Noordenbos MW, 2012, NEUROPSYCHOLOGIA, V50, P2010, DOI 10.1016/j.neuropsychologia.2012.04.026
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   Oganian Y, 2012, NEUROPSYCHOLOGIA, V50, P1895, DOI 10.1016/j.neuropsychologia.2012.04.014
   PATTERSON K, 1994, J COGNITIVE NEUROSCI, V6, P57, DOI 10.1162/jocn.1994.6.1.57
   Perry C, 2019, PSYCHOL SCI, V30, P386, DOI 10.1177/0956797618823540
   Pritchard SC, 2012, J EXP PSYCHOL HUMAN, V38, P1268, DOI 10.1037/a0026703
   Quemart P, 2015, APPL PSYCHOLINGUIST, V36, P345, DOI 10.1017/S014271641300026X
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   Ramus F, 2003, CURR OPIN NEUROBIOL, V13, P212, DOI 10.1016/S0959-4388(03)00035-7
   Ramus F, 2008, Q J EXP PSYCHOL, V61, P129, DOI 10.1080/17470210701508822
   Raven J, 1998, MANUAL RAVENS PROGR
   Robichon F, 2002, BIOL PSYCHOL, V59, P29, DOI 10.1016/S0301-0511(01)00118-1
   Rodriguez-Fornells A, 2009, PHILOS T R SOC B, V364, P3711, DOI 10.1098/rstb.2009.0130
   Sadakata M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01318
   Saksida A, 2016, DEV PSYCHOL, V52, P1503, DOI 10.1037/dev0000184
   Savill N, 2017, NEUROPSYCHOLOGIA, V98, P85, DOI 10.1016/j.neuropsychologia.2016.03.006
   Schiff R., 2019, SIMULATION CAPILLARY, P1
   Schiff R, 2016, SCI STUD READ, V20, P140, DOI 10.1080/10888438.2015.1094074
   Schmalz X, 2017, ANN DYSLEXIA, V67, P147, DOI 10.1007/s11881-016-0136-0
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   Silva PB, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00430
   Smith-Spark JH, 2007, MEMORY, V15, P34, DOI 10.1080/09658210601043384
   SNODGRASS JG, 1980, J EXP PSYCHOL-HUM L, V6, P174, DOI 10.1037/0278-7393.6.2.174
   Sprenger-Charolles L., 2005, EUR REV APPL PSYCHOL, V55, P157, DOI DOI 10.1016/J.ERAP.2004.11.002
   Swanson HL, 2009, REV EDUC RES, V79, P1362, DOI 10.3102/0034654309350931
   Szenkovits G, 2016, FIRST LANG, V36, P316, DOI 10.1177/0142723716648841
   Thomson JM, 2010, READ WRIT, V23, P453, DOI 10.1007/s11145-009-9167-9
   Tremblay K, 1998, NEUROREPORT, V9, P3557, DOI 10.1097/00001756-199811160-00003
   Tyler MD, 2014, PHONETICA, V71, P4, DOI 10.1159/000356237
   van den Brink D, 2001, J COGNITIVE NEUROSCI, V13, P967, DOI 10.1162/089892901753165872
   van der Kleij SW, 2019, J EXP CHILD PSYCHOL, V178, P15, DOI 10.1016/j.jecp.2018.09.006
   van Rijthoven R, 2018, DYSLEXIA, V24, P309, DOI 10.1002/dys.1597
   Vandermosten M, 2019, SCI STUD READ, V23, P116, DOI 10.1080/10888438.2018.1473404
   Wagner AD, 1998, SCIENCE, V281, P1188, DOI 10.1126/science.281.5380.1188
   White S, 2006, DEVELOPMENTAL SCI, V9, P237, DOI 10.1111/j.1467-7687.2006.00483.x
   Wong PCM, 2007, APPL PSYCHOLINGUIST, V28, P565, DOI 10.1017/S0142716407070312
NR 93
TC 0
Z9 1
U1 2
U2 3
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD MAR 2
PY 2020
VL 139
AR 107358
DI 10.1016/j.neuropsychologia.2020.107358
PG 13
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA KS0BT
UT WOS:000517977400012
PM 31978401
DA 2021-02-24
ER

PT J
AU Giroud, J
   Trebuchon, A
   Schon, D
   Marquis, P
   Liegeois-Chauvel, C
   Poeppel, D
   Morillon, B
AF Giroud, Jeremy
   Trebuchon, Agnes
   Schon, Daniele
   Marquis, Patrick
   Liegeois-Chauvel, Catherine
   Poeppel, David
   Morillon, Benjamin
TI Asymmetric sampling in human auditory cortex reveals spectral processing
   hierarchy
SO PLOS BIOLOGY
LA English
DT Article
ID SPEECH-PERCEPTION; HEMISPHERIC-SPECIALIZATION; LATERALIZATION;
   OSCILLATIONS; ORGANIZATION; SENSITIVITY; MODULATION; PATHWAYS; LANGUAGE;
   RHYTHMS
AB Speech perception is mediated by both left and right auditory cortices but with differential sensitivity to specific acoustic information contained in the speech signal. A detailed description of this functional asymmetry is missing, and the underlying models are widely debated. We analyzed cortical responses from 96 epilepsy patients with electrode implantation in left or right primary, secondary, and/or association auditory cortex (AAC). We presented short acoustic transients to noninvasively estimate the dynamical properties of multiple functional regions along the auditory cortical hierarchy. We show remarkably similar bimodal spectral response profiles in left and right primary and secondary regions, with evoked activity composed of dynamics in the theta (around 4-8 Hz) and beta-gamma (around 15-40 Hz) ranges. Beyond these first cortical levels of auditory processing, a hemispheric asymmetry emerged, with delta and beta band (3/15 Hz) responsivity prevailing in the right hemisphere and theta and gamma band (6/40 Hz) activity prevailing in the left. This asymmetry is also present during syllables presentation, but the evoked responses in AAC are more heterogeneous, with the co-occurrence of alpha (around 10 Hz) and gamma (>25 Hz) activity bilaterally. These intracranial data provide a more fine-grained and nuanced characterization of cortical auditory processing in the 2 hemispheres, shedding light on the neural dynamics that potentially shape auditory and speech processing at different levels of the cortical hierarchy.
C1 [Giroud, Jeremy; Trebuchon, Agnes; Schon, Daniele; Marquis, Patrick; Liegeois-Chauvel, Catherine; Morillon, Benjamin] Aix Marseille Univ, INSERM, INS, Marseille, France.
   [Trebuchon, Agnes] Hop La Timone, APHM, Serv Neurophysiol Clin, Marseille, France.
   [Liegeois-Chauvel, Catherine] Cleveland Clin, Neurol Inst, Epilepsy Ctr, Cleveland, OH 44106 USA.
   [Poeppel, David] Max Planck Inst Empir Aesthet, Dept Neurosci, Frankfurt, Germany.
   [Poeppel, David] NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
   [Poeppel, David] NYU, Ctr Neural Sci, New York, NY 10003 USA.
RP Morillon, B (corresponding author), Aix Marseille Univ, INSERM, INS, Marseille, France.
EM bnmorillon@gmail.com
OI Morillon, Benjamin/0000-0002-0049-064X; Liegeois Chauvel,
   Catherine/0000-0002-9612-9110
FU Excellence Initiative of Aix-Marseille University (A.MIDEX); 
   [ANR-16CONV-0002];  [ANR-11-LABX-0036]
FX BM was supported by grants ANR-16CONV-0002 (ILCB) and ANR-11-LABX-0036
   (BLRI) and the Excellence Initiative of Aix-Marseille University
   (A.MIDEX). The funders had no role in study design, data collection and
   analysis, decision to publish, or preparation of the manuscript.
CR Abrams DA, 2008, J NEUROSCI, V28, P3958, DOI 10.1523/JNEUROSCI.0187-08.2008
   Alario FX, 1999, BEHAV RES METH INS C, V31, P531, DOI 10.3758/BF03200732
   Belin P, 1998, J COGNITIVE NEUROSCI, V10, P536, DOI 10.1162/089892998562834
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   Chait M, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00214
   Deco G, 2011, NAT REV NEUROSCI, V12, P43, DOI 10.1038/nrn2961
   Dorsaint-Pierre R, 2006, BRAIN, V129, P1164, DOI 10.1093/brain/awl055
   Flinker A, 2019, NAT HUM BEHAV, V3, P393, DOI 10.1038/s41562-019-0548-z
   Ghitza O, 2017, LANG COGN NEUROSCI, V32, P545, DOI 10.1080/23273798.2016.1232419
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Glasser MF, 2016, NATURE, V536, P171, DOI 10.1038/nature18933
   Gramfort A, 2014, NEUROIMAGE, V86, P446, DOI 10.1016/j.neuroimage.2013.10.027
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Harquel S, 2016, NEUROIMAGE, V135, P115, DOI 10.1016/j.neuroimage.2016.05.009
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hutsler J, 2003, TRENDS NEUROSCI, V26, P429, DOI 10.1016/S0166-2236(03)00198-X
   Hyafil A, 2015, ELIFE, V4, DOI 10.7554/eLife.06213
   Jamison HL, 2006, CEREB CORTEX, V16, P1266, DOI 10.1093/cercor/bhj068
   Keitel A, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2004473
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lehongre K, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00454
   Liegeois-Chauvel C, 1999, CEREB CORTEX, V9, P484, DOI 10.1093/cercor/9.5.484
   Liegeois-Chauvel C, 2004, CEREB CORTEX, V14, P731, DOI 10.1093/cercor/bhh033
   LIEGEOISCHAUVEL C, 1994, ELECTROEN CLIN NEURO, V92, P204, DOI 10.1016/0168-5597(94)90064-7
   LIEGEOISCHAUVEL C, 1991, BRAIN, V114, P139
   Luo H, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00170
   McGettigan C, 2012, TRENDS COGN SCI, V16, P269, DOI 10.1016/j.tics.2012.04.006
   Moerel M, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00225
   Morillon B, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00248
   Morillon B, 2010, P NATL ACAD SCI USA, V107, P18688, DOI 10.1073/pnas.1007189107
   Morosan P, 2001, NEUROIMAGE, V13, P684, DOI 10.1006/nimg.2000.0715
   Norman-Haignere S, 2015, NEURON, V88, P1281, DOI 10.1016/j.neuron.2015.11.035
   Obleser J, 2008, J NEUROSCI, V28, P8116, DOI 10.1523/JNEUROSCI.1290-08.2008
   Overath T, 2008, J NEUROSCI, V28, P13268, DOI 10.1523/JNEUROSCI.4596-08.2008
   Pedregosa F., 2011, J MACHINE LEARNING R
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Sammler D, 2015, CURR BIOL, V25, P3079, DOI 10.1016/j.cub.2015.10.009
   Sanders LD, 2007, NEUROPSYCHOLOGIA, V45, P1172, DOI 10.1016/j.neuropsychologia.2006.10.010
   Saoud H, 2012, J NEUROSCI, V32, P275, DOI 10.1523/JNEUROSCI.3970-11.2012
   Schonwiesner M, 2009, P NATL ACAD SCI USA, V106, P14611, DOI 10.1073/pnas.0907682106
   Schonwiesner M, 2005, EUR J NEUROSCI, V22, P1521, DOI 10.1111/j.1460-9568.2005.04315.x
   Schroeder CE, 2009, TRENDS NEUROSCI, V32, P9, DOI 10.1016/j.tins.2008.09.012
   Scott SK, 2013, BRAIN LANG, V127, P36, DOI 10.1016/j.bandl.2013.07.006
   TALAIRACH J, 1962, CONFIN NEUROL, V22, P328
   Teng XB, 2017, PLOS BIOL, V15, DOI 10.1371/journal.pbio.2000812
   Teng XB, 2016, SCI REP-UK, V6, DOI 10.1038/srep34390
   Thompson EC, 2016, SCI REP-UK, V6, DOI 10.1038/srep19737
   Trebuchon-Da Fonseca A, 2005, NEUROIMAGE, V27, P1, DOI 10.1016/j.neuroimage.2004.12.064
   Tzourio-Mazoyer N, 2017, CORTEX, V86, P314, DOI 10.1016/j.cortex.2016.05.013
   Ueda K, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-01831-z
   Womelsdorf T, 2014, NAT NEUROSCI, V17, P1031, DOI 10.1038/nn.3764
   Zaehle T, 2010, EXP BRAIN RES, V203, P629, DOI 10.1007/s00221-010-2265-8
   ZATORRE RJ, 1988, J ACOUST SOC AM, V84, P566, DOI 10.1121/1.396834
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
   Zatorre RJ, 2008, PHILOS T R SOC B, V363, P1087, DOI 10.1098/rstb.2007.2161
NR 57
TC 3
Z9 3
U1 1
U2 1
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1544-9173
EI 1545-7885
J9 PLOS BIOL
JI PLoS. Biol.
PD MAR
PY 2020
VL 18
IS 3
AR e3000207
DI 10.1371/journal.pbio.3000207
PG 20
WC Biochemistry & Molecular Biology; Biology
SC Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other
   Topics
GA MY3SQ
UT WOS:000558340000002
PM 32119667
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Pandza, NB
   Phillips, I
   Karuzis, VP
   O'Rourke, P
   Kuchinsky, SE
AF Pandza, Nick B.
   Phillips, Ian
   Karuzis, Valerie P.
   O'Rourke, Polly
   Kuchinsky, Stefanie E.
TI Neurostimulation and Pupillometry: New Directions for Learning and
   Research in Applied Linguistics
SO ANNUAL REVIEW OF APPLIED LINGUISTICS
LA English
DT Article
ID DIRECT-CURRENT STIMULATION; TRANSCRANIAL MAGNETIC STIMULATION;
   NERVE-STIMULATION; LOCUS-COERULEUS; HEARING IMPAIRMENT;
   SPEECH-PERCEPTION; ADAPTIVE GAIN; PITCH; PLASTICITY; PARADIGM
AB This paper begins by discussing new trends in the use of neurostimulation techniques in cognitive science and learning research, as well as the nascent research on their application in second language learning. To illustrate this, an experiment designed to investigate the impact of transcutaneous vagus nerve stimulation (tVNS), which is delivered via earbuds, on how learners process and learn Mandarin tones is reported. Pupillometry, which is an index of cognitive effort, is explained and illustrated as one way to assess the impact of tVNS. Participants in the study were native English speakers, naive to tone languages, pseudorandomly assigned to active or control conditions, while balancing for nonlinguistic pitch ability and musical experience. Their performance after tVNS was assessed using a range of more traditional language outcome measures, including accuracy and reaction times from lexical recognition and recall tasks and was triangulated with pupillometry during word-learning to help understand the mechanism through which tVNS operates. Findings are discussed in light of the literatures on lexical tone learning, cognitive effort, and neurostimulation, including specific benefits for learners of tone languages. Recommendations are made for future work on the increasingly popular area of neurostimulation for the field of applied linguistics in the 40th anniversary issue of ARAL.
C1 [Pandza, Nick B.; Phillips, Ian; Karuzis, Valerie P.; O'Rourke, Polly; Kuchinsky, Stefanie E.] Univ Maryland, Appl Res Lab Intelligence & Secur, College Pk, MD 20742 USA.
   [Pandza, Nick B.] Univ Maryland, Program Language Acquisit 2, College Pk, MD 20742 USA.
   [Karuzis, Valerie P.] Univ Maryland, Program Measurement Stat & Evaluat, College Pk, MD 20742 USA.
   [Kuchinsky, Stefanie E.] Walter Reed Natl Mil Med Ctr, Audiol & Speech Pathol Ctr, Bethesda, MD USA.
RP Pandza, NB (corresponding author), Univ Maryland, Appl Res Lab Intelligence & Secur, College Pk, MD 20742 USA.; Pandza, NB (corresponding author), Univ Maryland, Program Language Acquisit 2, College Pk, MD 20742 USA.
EM npandza@umd.edu
FU Naval Information Warfare Center and Defense Advanced Research Projects
   Agency [N66001-17-2-4009]
FX This material is based upon work supported by the Naval Information
   Warfare Center and Defense Advanced Research Projects Agency under
   Cooperative Agreement No. N66001-17-2-4009. The identification of
   specific products or scientific instrumentation is considered an
   integral part of the scientific endeavor and does not constitute
   endorsement or implied endorsement on the part of the author, DoD, or
   any component agency. The views expressed in this article are those of
   the author and do not reflect the official policy of the Department of
   Army/Navy/Air Force, Department of Defense, or U.S. Government.
CR Antoniou M, 2016, J ACOUST SOC AM, V139, P271, DOI 10.1121/1.4939736
   Aston-Jones G, 2005, ANNU REV NEUROSCI, V28, P403, DOI 10.1146/annurev.neuro.28.061604.135709
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bent T, 2006, J EXP PSYCHOL HUMAN, V32, P97, DOI 10.1037/0096-1523.32.1.97
   Borland MS, 2016, BRAIN STIMUL, V9, P117, DOI 10.1016/j.brs.2015.08.018
   Borland MS, 2018, NEUROSCIENCE, V369, P76, DOI 10.1016/j.neuroscience.2017.11.004
   Bowles AR, 2016, LANG LEARN, V66, P774, DOI 10.1111/lang.12159
   Brysbaert M, 2014, BEHAV RES METHODS, V46, P904, DOI 10.3758/s13428-013-0403-5
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Buell EP, 2018, BRAIN STIMUL, V11, P1218, DOI 10.1016/j.brs.2018.07.045
   Chandrasekaran B, 2010, J ACOUST SOC AM, V128, P456, DOI 10.1121/1.3445785
   Colflesh G., 2016, P ANN M COGN SCI SOC, P289
   DaSilva AF, 2015, FRONT NEUROANAT, V9, DOI 10.3389/fnana.2015.00089
   Dittinger E, 2016, J COGNITIVE NEUROSCI, V28, P1584, DOI 10.1162/jocn_a_00997
   Doughty CJ, 2003, LANG LEARN TECHNOL, V7, P50
   Eckstein MK, 2017, DEV COGN NEUROS-NETH, V25, P69, DOI 10.1016/j.dcn.2016.11.001
   Engineer ND, 2011, NATURE, V470, P101, DOI 10.1038/nature09656
   Finocchiaro C, 2006, NEUROCASE, V12, P317, DOI 10.1080/13554790601126203
   Follesa P, 2007, BRAIN RES, V1179, P28, DOI 10.1016/j.brainres.2007.08.045
   Frangos E, 2015, BRAIN STIMUL, V8, P624, DOI 10.1016/j.brs.2014.11.018
   George MS, 2010, NEUROPSYCHOPHARMACOL, V35, P301, DOI 10.1038/npp.2009.87
   Gilzenrat MS, 2010, COGN AFFECT BEHAV NE, V10, P252, DOI 10.3758/CABN.10.2.252
   Groves DA, 2005, NEUROSCI LETT, V379, P174, DOI 10.1016/j.neulet.2004.12.055
   Ingvalson EM, 2014, INT J BILINGUAL, V18, P35, DOI 10.1177/1367006912456586
   International guidelines for groin hernia management, 2018, REV HISPANOAM HERNIA, V22, P1, DOI DOI 10.1177/2331216518781746
   Jacobs HIL, 2015, NEUROBIOL AGING, V36, P1860, DOI 10.1016/j.neurobiolaging.2015.02.023
   Kilgard MP, 2012, TRENDS NEUROSCI, V35, P715, DOI 10.1016/j.tins.2012.09.002
   Klooster DCW, 2016, NEUROSCI BIOBEHAV R, V65, P113, DOI 10.1016/j.neubiorev.2016.02.016
   Kuchinsky S. E., AGING AUDITORY SYSTE
   Kuchinsky SE, 2013, PSYCHOPHYSIOLOGY, V50, P23, DOI 10.1111/j.1469-8986.2012.01477.x
   Kuipers Jan Rouke, 2011, Front Hum Neurosci, V5, P61, DOI 10.3389/fnhum.2011.00061
   Li M, 2017, STUD SECOND LANG ACQ, V39, P593, DOI 10.1017/S0272263116000358
   Loewenfeld IE, 1999, DOC OPHTHALMOL, V98, P3, DOI 10.1023/A:1002134106425
   Manta Stella, 2009, J Psychiatry Neurosci, V34, P272
   Marshall L, 2004, J NEUROSCI, V24, P9985, DOI 10.1523/JNEUROSCI.2725-04.2004
   Meinzer M, 2014, CORTEX, V50, P137, DOI 10.1016/j.cortex.2013.07.013
   Miniussi C, 2008, BRAIN STIMUL, V1, P326, DOI 10.1016/j.brs.2008.07.002
   Moslein/ Omlor, 2019, FINTECH HDB DIGITALI
   Mottaghy FM, 1999, NEUROLOGY, V53, P1806, DOI 10.1212/WNL.53.8.1806
   Moyer A, 2014, APPL LINGUIST, V35, P418, DOI 10.1093/applin/amu012
   Ohlenforst B, 2017, HEARING RES, V351, P68, DOI 10.1016/j.heares.2017.05.012
   Ohn SH, 2008, NEUROREPORT, V19, P43, DOI 10.1097/WNR.0b013e3282f2adfd
   Ollen Joy, 2006, THESIS
   Pascual-Leone A, 2000, CURR OPIN NEUROBIOL, V10, P232, DOI 10.1016/S0959-4388(00)00081-7
   Pelzl E., 2019, CHINESE 2 LANGUAGE, V54, P51
   Pelzl E, 2019, STUD SECOND LANG ACQ, V41, P59, DOI 10.1017/S0272263117000444
   Perrachione TK, 2011, J ACOUST SOC AM, V130, P461, DOI 10.1121/1.3593366
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Psychology Software Tools, 2012, E PRIM VERS 2 0 COMP
   R Core Team, 2019, R LANG ENV STAT COMP
   Reis J, 2008, BRAIN STIMUL, V1, P363, DOI 10.1016/j.brs.2008.08.001
   Sakai KL, 2002, NEURON, V35, P1177, DOI 10.1016/S0896-6273(02)00873-5
   Samuels ER, 2008, CURR NEUROPHARMACOL, V6, P235, DOI 10.2174/157015908785777229
   Schmidtke J, 2018, STUD SECOND LANG ACQ, V40, P529, DOI 10.1017/S0272263117000195
   Sebastian-Galles N, 2012, LANG LEARN, V62, P131, DOI 10.1111/j.1467-9922.2012.00709.x
   Soskuthy M., 2017, ARXIV170305339
   van der Wel P, 2018, PSYCHON B REV, V25, P2005, DOI 10.3758/s13423-018-1432-y
   van Rij J., 2019, TRENDS HEAR, V23, P1
   Vanderwal T, 2015, NEUROIMAGE, V122, P222, DOI 10.1016/j.neuroimage.2015.07.069
   Vonck K, 2014, NEUROSCI BIOBEHAV R, V45, P63, DOI 10.1016/j.neubiorev.2014.05.005
   Walsh V, 2003, BRADFORD BOOKS, P1
   Wong H, 1953, WORD, V9, P268, DOI 10.1080/00437956.1953.11659474
   Wong PCM, 2007, APPL PSYCHOLINGUIST, V28, P565, DOI 10.1017/S0142716407070312
   Wood SN., 2017, GEN ADDITIVE MODELS
   You DS, 2011, BRAIN LANG, V119, P1, DOI 10.1016/j.bandl.2011.05.002
NR 65
TC 0
Z9 0
U1 2
U2 2
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0267-1905
EI 1471-6356
J9 ANNU REV APPL LINGUI
JI Annu. Rev. Appl. Linguist.
PD MAR
PY 2020
VL 40
BP 56
EP 77
AR PII S0267190520000069
DI 10.1017/S0267190520000069
PG 22
WC Linguistics; Language & Linguistics
SC Linguistics
GA MD8RD
UT WOS:000544234500004
DA 2021-02-24
ER

PT J
AU Liu, LF
   Zhang, YX
   Zhou, Q
   Garrett, DD
   Lu, CM
   Chen, AT
   Qiu, J
   Ding, GS
AF Liu, Lanfang
   Zhang, Yuxuan
   Zhou, Qi
   Garrett, Douglas D.
   Lu, Chunming
   Chen, Antao
   Qiu, Jiang
   Ding, Guosheng
TI Auditory-Articulatory Neural Alignment between Listener and Speaker
   during Verbal Communication
SO CEREBRAL CORTEX
LA English
DT Article
DE auditory-articulatory interaction; interbrain neural coupling; speech
   comprehension
ID SPEECH-PERCEPTION; MOTOR CORTEX; LANGUAGE; FMRI; COMPREHENSION; LARYNX;
   AREAS
AB Whether auditory processing of speech relies on reference to the articulatory motor information of speaker remains elusive. Here, we addressed this issue under a two-brain framework. Functional magnetic resonance imaging was applied to record the brain activities of speakers when telling real-life stories and later of listeners when listening to the audio recordings of these stories. Based on between-brain seed-to-voxel correlation analyses, we revealed that neural dynamics in listeners' auditory temporal cortex are temporally coupled with the dynamics in the speaker's larynx/phonation area. Moreover, the coupling response in listener's left auditory temporal cortex follows the hierarchical organization for speech processing, with response lags in A1+, STG/STS, and MTG increasing linearly. Further, listeners showing greater coupling responses understand the speech better. When comprehension fails, such interbrain auditory-articulation coupling vanishes substantially. These findings suggest that a listener's auditory system and a speaker's articulatory system are inherently aligned during naturalistic verbal interaction, and such alignment is associated with high-level information transfer from the speaker to the listener. Our study provides reliable evidence supporting that references to the articulatory motor information of speaker facilitate speech comprehension under a naturalistic scene.
C1 [Liu, Lanfang; Zhang, Yuxuan; Zhou, Qi; Lu, Chunming; Ding, Guosheng] Beijing Normal Univ, IDG McGovern Inst Brain Res, State Key Lab Cognit Neurosci & Learning, Beijing 100875, Peoples R China.
   [Liu, Lanfang] Sun Yat Sen Univ, Dept Psychol, Guangzhou 510006, Peoples R China.
   [Garrett, Douglas D.] Max Planck Inst Human Dev, Max Planck UCL Ctr Computat Psychiat & Ageing Res, Lentzeallee 94, D-14195 Berlin, Germany.
   [Chen, Antao; Qiu, Jiang] Southwest Univ, Minist Educ, Key Lab Cognit & Personal SWU, Chongqing 400715, Peoples R China.
   [Chen, Antao; Qiu, Jiang] Southwest Univ, Dept Psychol, 2 Tiansheng St, Chongqing 400715, Peoples R China.
RP Qiu, J (corresponding author), Southwest Univ, Dept Psychol, 2 Tiansheng St, Chongqing 400715, Peoples R China.; Ding, GS (corresponding author), Beijing Normal Univ, State Key Lab Cognit Neurosci & Learning, 19 Xinjiekouwai St, Beijing 100875, Peoples R China.
EM qiuj318@swu.edu.cn; dinggsh@bnu.edu.cn
OI Garrett, Douglas/0000-0002-0629-7672
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [31571158, 31170969]; National Key Basic
   Research Program of ChinaNational Basic Research Program of China
   [2014CB846102]; Interdiscipline Research Funds of Beijing Normal
   University; Open Research Fund of the State Key Laboratory of Cognitive
   Neuroscience and Learning of Beijing Normal University [CNLYB1803]
FX National Natural Science Foundation of China (31571158 and 31170969);
   National Key Basic Research Program of China (2014CB846102);
   Interdiscipline Research Funds of Beijing Normal University and the Open
   Research Fund of the State Key Laboratory of Cognitive Neuroscience and
   Learning of Beijing Normal University (CNLYB1803).
CR Arsenault JS, 2016, PSYCHON B REV, V23, P1231, DOI 10.3758/s13423-015-0988-z
   Bassett DS, 2011, TRENDS COGN SCI, V15, P200, DOI 10.1016/j.tics.2011.03.006
   Behroozmand R, 2015, NEUROIMAGE, V109, P418, DOI 10.1016/j.neuroimage.2015.01.040
   Behzadi Y, 2007, NEUROIMAGE, V37, P90, DOI 10.1016/j.neuroimage.2007.04.042
   Brown S, 2008, CEREB CORTEX, V18, P837, DOI 10.1093/cercor/bhm131
   Brown S, 2009, BRAIN COGNITION, V70, P31, DOI 10.1016/j.bandc.2008.12.006
   Chen X, 2018, HUM BRAIN MAPP, V39, P300, DOI 10.1002/hbm.23843
   Christoffels IK, 2007, HUM BRAIN MAPP, V28, P868, DOI 10.1002/hbm.20315
   D'Ausilio A, 2011, BRAIN LANG, V118, P9, DOI 10.1016/j.bandl.2011.02.007
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Du Y, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12241
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Friston KJ, 1996, MAGNET RESON MED, V35, P346, DOI 10.1002/mrm.1910350312
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Ghinst MV, 2016, J NEUROSCI, V36, P1596, DOI 10.1523/JNEUROSCI.1730-15.2016
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Grabski K, 2012, HUM BRAIN MAPP, V33, P2306, DOI 10.1002/hbm.21363
   GROSS CG, 1994, CEREB CORTEX, V4, P455, DOI 10.1093/cercor/4.5.455
   Hasson U, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0366
   Hickok G, 2003, J COGNITIVE NEUROSCI, V15, P673, DOI 10.1162/089892903322307393
   Hickok G., 2014, MYTH MIRROR NEURONS
   Hickok G, 2009, J COGNITIVE NEUROSCI, V21, P1229, DOI 10.1162/jocn.2009.21189
   Humes LE, 2010, SPRINGER HANDB AUDIT, V34, P211, DOI 10.1007/978-1-4419-0993-0_8
   Humphries C, 2007, NEUROIMAGE, V36, P924, DOI 10.1016/j.neuroimage.2007.03.059
   ISSHIKI N, 1964, J SPEECH HEAR RES, V7, P17, DOI 10.1044/jshr.0701.17
   Jiang J, 2012, J NEUROSCI, V32, P16064, DOI 10.1523/JNEUROSCI.2926-12.2012
   Kuhlen AK, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00266
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Liu YC, 2017, SCI REP-UK, V7, DOI 10.1038/srep43293
   Magrassi L, 2015, P NATL ACAD SCI USA, V112, P1868, DOI 10.1073/pnas.1418162112
   Mashal N, 2009, LATERALITY, V14, P30, DOI 10.1080/13576500802049433
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Mottonen R, 2013, CEREB CORTEX, V23, P1190, DOI 10.1093/cercor/bhs110
   Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009
   Obleser J, 2007, CEREB CORTEX, V17, P2251, DOI 10.1093/cercor/bhl133
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Peelle JE, 2016, TRENDS NEUROSCI, V39, P486, DOI 10.1016/j.tins.2016.05.001
   Peelle JE, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00051
   Perez A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04464-4
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Price CJ, 2010, ANN NY ACAD SCI, V1191, P62, DOI 10.1111/j.1749-6632.2010.05444.x
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811
   Silbert LJ, 2014, P NATL ACAD SCI USA, V111, pE4687, DOI 10.1073/pnas.1323812111
   Smith SM, 2009, NEUROIMAGE, V44, P83, DOI 10.1016/j.neuroimage.2008.03.061
   Stasenko A, 2015, COGN NEUROPSYCHOL, V32, P38, DOI 10.1080/02643294.2015.1035702
   Stephens GJ, 2010, P NATL ACAD SCI USA, V107, P14425, DOI 10.1073/pnas.1008662107
   Turkeltaub PE, 2002, NEUROIMAGE, V16, P765, DOI 10.1006/nimg.2002.1131
   Turner C W, 1999, Am J Audiol, V8, P47, DOI 10.1044/1059-0889(1999/002)
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   Wechsler D., 1987, WMS R WECHSLER MEMOR
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Yan CG, 2016, NEUROINFORMATICS, V14, P339, DOI 10.1007/s12021-016-9299-4
NR 55
TC 0
Z9 0
U1 4
U2 11
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 1047-3211
EI 1460-2199
J9 CEREB CORTEX
JI Cereb. Cortex
PD MAR
PY 2020
VL 30
IS 3
BP 942
EP 951
DI 10.1093/cercor/bhz138
PG 10
WC Neurosciences
SC Neurosciences & Neurology
GA LR7TQ
UT WOS:000535899500008
PM 31318013
DA 2021-02-24
ER

PT J
AU Matchin, W
   Hickok, G
AF Matchin, William
   Hickok, Gregory
TI The Cortical Organization of Syntax
SO CEREBRAL CORTEX
LA English
DT Article
DE Syntax; Dual-Stream model; Broca's area; posterior temporal lobe;
   paragrammatism
ID ANTERIOR TEMPORAL CORTEX; THEMATIC CONCEPTUAL RELATIONS; INFERIOR
   FRONTAL-CORTEX; BROCAS AREA; SENTENCE COMPREHENSION; NEURAL BASIS;
   LANGUAGE COMPREHENSION; SEMANTIC DEMENTIA; LESION ANALYSIS;
   WORKING-MEMORY
AB Syntax, the structure of sentences, enables humans to express an infinite range of meanings through finite means. The neurobiology of syntax has been intensely studied but with little consensus. Two main candidate regions have been identified: the posterior inferior frontal gyrus (pIFG) and the posterior middle temporal gyrus (pMTG). Integrating research in linguistics, psycholinguistics, and neuroscience, we propose a neuroanatomical framework for syntax that attributes distinct syntactic computations to these regions in a unified model. The key theoretical advances are adopting a modern lexicalized view of syntax in which the lexicon and syntactic rules are intertwined, and recognizing a computational asymmetry in the role of syntax during comprehension and production. Our model postulates a hierarchical lexical-syntactic function to the pMTG, which interconnects previously identified speech perception and conceptual-semantic systems in the temporal and inferior parietal lobes, crucial for both sentence production and comprehension. These relational hierarchies are transformed via the pIFG into morpho-syntactic sequences, primarily tied to production. We show how this architecture provides a better account of the full range of data and is consistent with recent proposals regarding the organization of phonological processes in the brain.
C1 [Matchin, William] Univ South Carolina, Dept Commun Sci & Disorders, Columbia, SC 29208 USA.
   [Hickok, Gregory] Univ Calif Irvine, Dept Cognit Sci, Irvine, CA 92697 USA.
   [Hickok, Gregory] Univ Calif Irvine, Dept Language Sci, Irvine, CA 92697 USA.
RP Matchin, W (corresponding author), Discovery 1 Room 202D,915 Greene St, Columbia, SC 29208 USA.
EM matchin@mailbox.sc.edu
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [DC014664, DC012797]
FX M. was supported by the National Institutes of Health (grant DC012797 to
   Rachel Mayberry); G.H. was supported by the National Institutes of
   Health (grant DC014664).
CR Adger D, 2018, STUD GENERAT GRAMM, V129, P153, DOI 10.1515/9781501506925-157
   Alajouanine T., 1968, APHASIE LANGAGE PATH
   Amici S, 2007, J NEUROSCI, V27, P6282, DOI 10.1523/JNEUROSCI.1331-07.2007
   Baldo JV, 2007, NEUROPSYCHOLOGIA, V45, P229, DOI 10.1016/j.neuropsychologia.2006.07.014
   Baldo JV, 2013, CORTEX, V49, P658, DOI 10.1016/j.cortex.2012.03.001
   Bastiaanse R, 1996, APHASIOLOGY, V10, P561, DOI 10.1080/02687039608248437
   Bates E., 1989, CROSSLINGUISTIC STUD, P225
   Beckers GJL, 2012, NEUROREPORT, V23, P139, DOI 10.1097/WNR.0b013e32834f1765
   BELLUGI U, 1976, ANN NY ACAD SCI, V280, P514, DOI 10.1111/j.1749-6632.1976.tb25514.x
   Benson DF., 1996, APHASIA CLIN PERSPEC
   Berwick RC, 2016, WHY ONLY US: LANGUAGE AND EVOLUTION, P1
   Berwick RC, 2011, TRENDS COGN SCI, V15, P113, DOI 10.1016/j.tics.2011.01.002
   Binder JR, 2011, TRENDS COGN SCI, V15, P527, DOI 10.1016/j.tics.2011.10.001
   Binder JR, 2009, CEREB CORTEX, V19, P2767, DOI 10.1093/cercor/bhp055
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   Blank I, 2016, NEUROIMAGE, V127, P307, DOI 10.1016/j.neuroimage.2015.11.069
   Bock K., 1995, SPEECH LANGUAGE COMM
   Boeckx C, 2014, J NEUROLINGUIST, V32, P1, DOI 10.1016/j.jneuroling.2014.07.001
   Bohland JW, 2010, J COGNITIVE NEUROSCI, V22, P1504, DOI 10.1162/jocn.2009.21306
   Bolhuis Johan J., 2014, PLOS ONE BIOL, V12, P8
   Bonhage CE, 2015, CORTEX, V68, P33, DOI 10.1016/j.cortex.2015.04.011
   Bornkessel I, 2005, NEUROIMAGE, V26, P221, DOI 10.1016/j.neuroimage.2005.01.032
   Bornkessel-Schlesewsky I, 2015, TRENDS COGN SCI, V19, P142, DOI 10.1016/j.tics.2014.12.008
   Bornkessel-Schlesewsky I, 2013, BRAIN LANG, V125, P60, DOI 10.1016/j.bandl.2013.01.010
   Boylan C, 2017, BRAIN LANG, V169, P8, DOI 10.1016/j.bandl.2017.01.008
   Boylan C, 2015, NEUROPSYCHOLOGIA, V78, P130, DOI 10.1016/j.neuropsychologia.2015.10.007
   Bozic M, 2015, HUM BRAIN MAPP, V36, P1190, DOI 10.1002/hbm.22696
   Brennan JR, 2016, BRAIN LANG, V157, P81, DOI 10.1016/j.bandl.2016.04.008
   Bresnan Joan, 2001, LEXICAL FUNCTIONAL S
   BUTTERWORTH B, 1987, COGNITION, V26, P1, DOI 10.1016/0010-0277(87)90012-6
   Call J, 2008, TRENDS COGN SCI, V12, P187, DOI 10.1016/j.tics.2008.02.010
   Caplan D, 2000, HUM BRAIN MAPP, V9, P65
   CARAMAZZA A, 1976, BRAIN LANG, V3, P572, DOI 10.1016/0093-934X(76)90048-1
   Caramazza A., 2000, NEW COGNITIVE NEUROS, P1037
   Caramazza A., 1986, CLIN APHASIOL, V16, P291
   Carroll Lewis, 2000, LOOKING GLASS WHAT A
   Casilio M, 2019, AM J SPEECH-LANG PAT, V28, P550, DOI 10.1044/2018_AJSLP-18-0192
   Chang EF, 2018, J COGNITIVE NEUROSCI, V30, P411, DOI 10.1162/jocn_a_01215
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   CHERNIAK C, 1994, J NEUROSCI, V14, P2418
   Chklovskii DB, 2002, NEURON, V34, P341, DOI 10.1016/S0896-6273(02)00679-7
   Chklovskii DB, 2004, ANNU REV NEUROSCI, V27, P369, DOI 10.1146/annurev.neuro.27.070203.144226
   Chomsky N., 1981, LECT GOVT BINDING
   Chomsky N., 1994, BARE PHRASE STRUCTUR, V8
   Chomsky N., 1995, MINIMALIST PROGRAM
   Chomsky Noam, 1957, SYNTACTIC STRUCTURES
   Chomsky Noam, 1965, ASPECTS THEORY SYNTA, V11
   Cotelli M, 2007, NEUROPSYCHOLOGIA, V45, P3015, DOI 10.1016/j.neuropsychologia.2007.05.012
   Damasio AR, 1989, NEURAL COMPUT, V1, P123, DOI 10.1162/neco.1989.1.1.123
   Darwin C, 1871, DESCENT MAN SELECTIO
   de Waal FBM, 2008, ANNU REV PSYCHOL, V59, P279, DOI 10.1146/annurev.psych.59.103006.093625
   Del Prato P, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00524
   DELL GS, 1992, COGNITION, V42, P287, DOI 10.1016/0010-0277(92)90046-K
   Demberg V, 2013, COMPUT LINGUIST, V39, P1025, DOI 10.1162/COLI_a_00160
   den Ouden DB, 2019, HUM BRAIN MAPP, V40, P2153, DOI 10.1002/hbm.24514
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Dronkers NF, 2004, COGNITION, V92, P145, DOI 10.1016/j.cognition.2003.11.002
   Dronkers NF, 2009, ENCY NEUROSCIENCE, P343
   Dubois J, 2006, NEUROIMAGE, V30, P1121, DOI 10.1016/j.neuroimage.2005.11.022
   Dubois J, 2008, HUM BRAIN MAPP, V29, P14, DOI 10.1002/hbm.20363
   Embick D, 2015, LANG COGN NEUROSCI, V30, P357, DOI 10.1080/23273798.2014.980750
   Emmorey K, 2007, NEUROIMAGE, V36, P202, DOI 10.1016/j.neuroimage.2007.02.040
   Estes Z, 2011, PSYCHOL LEARN MOTIV, V54, P249, DOI 10.1016/B978-0-12-385527-5.00008-5
   Everaert MBH, 2015, TRENDS COGN SCI, V19, P729, DOI 10.1016/j.tics.2015.09.008
   Fedorenko E, 2018, BIORXIV
   Fedorenko E, 2012, CURR BIOL, V22, P2059, DOI 10.1016/j.cub.2012.09.011
   Fedorenko E, 2012, NEUROPSYCHOLOGIA, V50, P499, DOI 10.1016/j.neuropsychologia.2011.09.014
   Ferreira F, 2002, CURR DIR PSYCHOL SCI, V11, P11, DOI 10.1111/1467-8721.00158
   Fiebach CJ, 2005, HUM BRAIN MAPP, V24, P79, DOI 10.1002/hbm.20070
   Fitch WT, 2017, PSYCHON B REV, V24, P3, DOI 10.3758/s13423-017-1236-5
   FLETCHER PC, 1995, COGNITION, V57, P109, DOI 10.1016/0010-0277(95)00692-R
   Floel A, 2009, NEUROIMAGE, V47, P1974, DOI 10.1016/j.neuroimage.2009.05.046
   Frank R., 2002, PHRASE STRUCTURE COM
   Fridriksson J, 2007, BEHAV NEUROL, V18, P237, DOI 10.1155/2007/785280
   Fridriksson J, 2018, BRAIN, V141, P848, DOI 10.1093/brain/awx363
   Fridriksson J, 2015, CEREB CORTEX, V25, P4689, DOI 10.1093/cercor/bhu152
   Friederici A. D., 2017, LANGUAGE OUR BRAIN O
   Friederici AD, 2006, P NATL ACAD SCI USA, V103, P2458, DOI 10.1073/pnas.0509389103
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   Gage N, 2005, CORTEX, V41, P823, DOI 10.1016/S0010-9452(08)70301-0
   Garrett M. F., 1980, LANGUAGE PRODUCTION, V1, P177
   Gelfand JR, 2003, NEURON, V38, P831, DOI 10.1016/S0896-6273(03)00285-X
   Glasel H, 2011, NEUROIMAGE, V58, P716, DOI 10.1016/j.neuroimage.2011.06.016
   Goldberg A. E., 1995, CONSTRUCTIONS CONSTR
   GOODGLASS H, 1960, J SPEECH HEAR RES, V3, P257, DOI 10.1044/jshr.0303.257
   Goodglass H, 1992, CONDUCTION APHASIA, P39
   Goodglass H., 1968, DEV APPL PSYCHOLINGU
   Goodglass H., 1993, UNDERSTANDING APHASI
   Goucha T, 2015, NEUROIMAGE, V114, P294, DOI 10.1016/j.neuroimage.2015.04.011
   Grodzinsky Y, 2000, BEHAV BRAIN SCI, V23, P1, DOI 10.1017/S0140525X00002399
   Grodzinsky Y., 2006, BROCAS REGION
   Grodzinsky Y, 2008, TRENDS COGN SCI, V12, P474, DOI 10.1016/j.tics.2008.09.001
   Grossman M, 2005, CORTEX, V41, P764, DOI 10.1016/S0010-9452(08)70295-8
   Guenther FH, 2006, J COMMUN DISORD, V39, P350, DOI 10.1016/j.jcomdis.2006.06.013
   Guenther Frank H, 2015, Handb Clin Neurol, V129, P161, DOI 10.1016/B978-0-444-62630-1.00009-3
   Hagoort P, 2014, CURR OPIN NEUROBIOL, V28, P136, DOI 10.1016/j.conb.2014.07.013
   Hauser MD, 2002, SCIENCE, V298, P1569, DOI 10.1126/science.298.5598.1569
   Heim Irene, 1998, SEMANTICS GENERATIVE
   Henseler I, 2014, BRAIN, V137, P918, DOI 10.1093/brain/awt374
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2003, J COGNITIVE NEUROSCI, V15, P673, DOI 10.1162/089892903322307393
   Hickok G, 1996, NATURE, V381, P699, DOI 10.1038/381699a0
   Hickok G., 2014, MYTH MIRROR NEURONS
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2014, LANG COGN NEUROSCI, V29, P2, DOI 10.1080/01690965.2013.834370
   Hickok G, 2012, J COMMUN DISORD, V45, P393, DOI 10.1016/j.jcomdis.2012.06.004
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Hickok G, 2009, J NEUROPHYSIOL, V101, P2725, DOI 10.1152/jn.91099.2008
   Hill J, 2010, J NEUROSCI, V30, P2268, DOI 10.1523/JNEUROSCI.4682-09.2010
   Hodges JR, 2007, LANCET NEUROL, V6, P1004, DOI 10.1016/S1474-4422(07)70266-1
   HODGES JR, 1992, BRAIN, V115, P1783, DOI 10.1093/brain/115.6.1783
   Humphries C, 2006, J COGNITIVE NEUROSCI, V18, P665, DOI 10.1162/jocn.2006.18.4.665
   Humphries C, 2005, HUM BRAIN MAPP, V26, P128, DOI 10.1002/hbm.20148
   Humphries C, 2001, NEUROREPORT, V12, P1749, DOI 10.1097/00001756-200106130-00046
   Iacoboni M, 2009, ANNU REV PSYCHOL, V60, P653, DOI 10.1146/annurev.psych.60.110707.163604
   Idsardi W. E., 2013, CHALLENGES LINEARIZA, P31, DOI DOI 10.1515/9781614512431.31
   Indefrey P, 2004, COGNITION, V92, P101, DOI 10.1016/j.cognition.2002.06.001
   Indefrey P, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00255
   Jackendoff R., 2002, FDN LANGUAGE LANGUAG
   Jackendoff R, 2017, COGNITIVE SCI, V41, P185, DOI 10.1111/cogs.12324
   Jakobson R., 1956, FUNDAMENTALS LANGUAG
   Jakuszeit M, 2013, CORTEX, V49, P2861, DOI 10.1016/j.cortex.2013.05.014
   January D, 2009, J COGNITIVE NEUROSCI, V21, P2434, DOI 10.1162/jocn.2008.21179
   Johnson MA, 2013, LANG COGNITIVE PROC, V28, P1439, DOI 10.1080/01690965.2012.717632
   Joshi A. K., 1997, HDB FORMAL LANGUAGES, P69, DOI DOI 10.1007/978-3-642-59126-6_2
   Jurafsky D, 1996, COGNITIVE SCI, V20, P137, DOI 10.1016/S0364-0213(99)80005-6
   Kalenine S, 2009, NEUROIMAGE, V44, P1152, DOI 10.1016/j.neuroimage.2008.09.043
   KEMPEN G, 1983, COGNITION, V14, P185, DOI 10.1016/0010-0277(83)90029-X
   Kho KH, 2008, NEUROPSYCHOLOGIA, V46, P1170, DOI 10.1016/j.neuropsychologia.2007.10.014
   Kleist K., 1914, MUNCHEN MED WOCHEN, V6, P8
   Klima Edward, 1979, SIGNS LANGUAGE
   Kussmaul A., 1877, STORUNGEN SPRACHE VE
   Lau E, 2006, BRAIN LANG, V98, P74, DOI 10.1016/j.bandl.2006.02.003
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532
   Leaver AM, 2009, J NEUROSCI, V29, P2477, DOI 10.1523/JNEUROSCI.4921-08.2009
   Leonard MK, 2012, J NEUROSCI, V32, P9700, DOI 10.1523/JNEUROSCI.1002-12.2012
   Leroy F, 2015, P NATL ACAD SCI USA, V112, P1208, DOI 10.1073/pnas.1412389112
   Levelt W. J., 1993, SPEAKING INTENTION A
   Levelt WJ, 1989, SPEAKING INTENTION A
   Lewis GA, 2015, NEUROPSYCHOLOGIA, V68, P176, DOI 10.1016/j.neuropsychologia.2015.01.011
   Lewis R. L., 2000, ARCHITECTURES MECH L
   Lewis RL, 2006, TRENDS COGN SCI, V10, P447, DOI 10.1016/j.tics.2006.08.007
   Lewis RL, 2005, COGNITIVE SCI, V29, P375, DOI 10.1207/s15516709cog0000_25
   Lin EL, 2001, J EXP PSYCHOL GEN, V130, P3, DOI 10.1037/0096-3445.130.1.3
   LINEBARGER MC, 1983, COGNITION, V13, P361, DOI 10.1016/0010-0277(83)90015-X
   Love T, 2008, BRAIN LANG, V107, P203, DOI 10.1016/j.bandl.2007.11.004
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676
   MacSweeney M, 2006, HUM BRAIN MAPP, V27, P63, DOI 10.1002/hbm.20167
   MacSweeney M, 2002, BRAIN, V125, P1583, DOI 10.1093/brain/awf153
   Magnusdottir S, 2013, HUM BRAIN MAPP, V34, P2715, DOI 10.1002/hbm.22096
   Maguire EA, 1999, BRAIN, V122, P1839, DOI 10.1093/brain/122.10.1839
   Malyutina S, 2017, BRAIN LANG, V168, P57, DOI 10.1016/j.bandl.2017.01.006
   Martin A, 2001, CURR OPIN NEUROBIOL, V11, P194, DOI 10.1016/S0959-4388(00)00196-3
   Matchin W, OXFORD HDB EXPT SYNT
   Matchin W, 2017, 2017 M SOC NEUR LANG
   Matchin W., 2017, PSYCHONOM B REV, P1
   Matchin W, 2017, CORTEX, V88, P106, DOI 10.1016/j.cortex.2016.12.010
   Mayberry RI, 2011, BRAIN LANG, V119, P16, DOI 10.1016/j.bandl.2011.05.007
   Mayberry RI, 2002, NATURE, V417, P38, DOI 10.1038/417038a
   MAZOYER BM, 1993, J COGNITIVE NEUROSCI, V5, P467, DOI 10.1162/jocn.1993.5.4.467
   McElree B, 2003, J MEM LANG, V48, P67, DOI 10.1016/S0749-596X(02)00515-6
   MCELREE B, 1993, J MEM LANG, V32, P536, DOI 10.1006/jmla.1993.1028
   Meltzer-Asscher A, 2015, BRAIN LANG, V142, P65, DOI 10.1016/j.bandl.2014.12.005
   Mesulam MM, 2015, BRAIN, V138, P2423, DOI 10.1093/brain/awv154
   MESULAM MM, 1990, ANN NEUROL, V28, P597, DOI 10.1002/ana.410280502
   Meyer L., 2016, NEUROBIOLOGY LANGUAG, P597, DOI DOI 10.1016/B978-0-12-407794-2.00048-1
   MOHR JP, 1978, NEUROLOGY, V28, P311, DOI 10.1212/WNL.28.4.311
   Moses DA, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/5/056004
   Murphy E, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01515
   Nelson MJ, 2017, P NATL ACAD SCI USA, V114, pE3669, DOI 10.1073/pnas.1701590114
   Neville HJ, 1998, P NATL ACAD SCI USA, V95, P922, DOI 10.1073/pnas.95.3.922
   Newman AJ, 2015, P NATL ACAD SCI USA, V112, P11684, DOI 10.1073/pnas.1510527112
   Novick JM, 2010, LANG LINGUIST COMPAS, V4, P906, DOI 10.1111/j.1749-818x.2010.00244.x
   Novick JM, 2005, COGN AFFECT BEHAV NE, V5, P263, DOI 10.3758/CABN.5.3.263
   Okada K, 2006, NEUROREPORT, V17, P1293, DOI 10.1097/01.wnr.0000233091.82536.b2
   Okada K, 2010, CEREB CORTEX, V20, P2486, DOI 10.1093/cercor/bhp318
   Pallier C, 2011, P NATL ACAD SCI USA, V108, P2522, DOI 10.1073/pnas.1018711108
   Papathanasiou I, 2017, APHASIA RELATED NEUR
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   Patterson K, 2007, NAT REV NEUROSCI, V8, P976, DOI 10.1038/nrn2277
   Peelle JE, 2008, J NEUROLINGUIST, V21, P418, DOI 10.1016/j.jneuroling.2008.01.004
   Petersson KM, 2012, BRAIN LANG, V120, P83, DOI 10.1016/j.bandl.2010.08.003
   Petitto L., 1994, SIGNPOST, V7, P1
   Petitto LA, 2000, P NATL ACAD SCI USA, V97, P13961, DOI 10.1073/pnas.97.25.13961
   Pillay SB, 2017, NEUROLOGY, V88, P970, DOI 10.1212/WNL.0000000000003683
   Pinker S., 1999, WORDS RULES INGREDIE
   Piras F, 2007, NEUROREPORT, V18, P1455, DOI 10.1097/WNR.0b013e3282ef6fc9
   Poeppel D, 2005, TWENTY-FIRST CENTURY PSYCHOLINGUISTICS: FOUR CORNERSTONES, P103
   Poletiek FH, 2016, COGNITION, V151, P108, DOI 10.1016/j.cognition.2015.04.016
   Pollard C., 1994, HEAD DRIVEN PHRASE S
   Pylkkanen L., 2015, NEUROBIOLOGY LANGUAG, P621
   Race DS, 2012, NEUROPSYCHOLOGIA, V50, P1946, DOI 10.1016/j.neuropsychologia.2012.04.019
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rilling JK, 2008, NAT NEUROSCI, V11, P426, DOI 10.1038/nn2072
   Rimmele JM, 2018, TRENDS COGN SCI, V22, P870, DOI 10.1016/j.tics.2018.08.003
   Roelofs A, 2019, HUMAN LANGUAGE GENES
   Rogalsky C, 2008, BRAIN LANG, V107, P167, DOI 10.1016/j.bandl.2008.08.003
   Rogalsky C, 2018, J COGNITIVE NEUROSCI, V30, P234, DOI 10.1162/jocn_a_01200
   Rogalsky C, 2015, LANG COGN NEUROSCI, V30, P1326, DOI 10.1080/23273798.2015.1066831
   Rogalsky C, 2011, J NEUROSCI, V31, P3843, DOI 10.1523/JNEUROSCI.4515-10.2011
   Rogalsky C, 2011, J COGNITIVE NEUROSCI, V23, P1664, DOI 10.1162/jocn.2010.21530
   Rogalsky C, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.014.2008
   Rogalsky C, 2009, CEREB CORTEX, V19, P786, DOI 10.1093/cercor/bhn126
   Rong F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196381
   Roux FE, 2015, CORTEX, V71, P398, DOI 10.1016/j.cortex.2015.07.001
   Sandler W, 2006, SIGN LANGUAGE AND LINGUISTIC UNIVERSALS, P1, DOI 10.2277/ 0521483956
   Sapolsky D, 2010, NEUROLOGY, V75, P358, DOI 10.1212/WNL.0b013e3181ea15e8
   Schwartz MF, 2011, P NATL ACAD SCI USA, V108, P8520, DOI 10.1073/pnas.1014935108
   Seed A, 2010, CURR BIOL, V20, pR1032, DOI 10.1016/j.cub.2010.09.042
   Segawa JA, 2015, J COGNITIVE NEUROSCI, V27, P819, DOI 10.1162/jocn_a_00737
   SELNES OA, 1984, BRAIN LANG, V21, P72, DOI 10.1016/0093-934X(84)90037-3
   Shadmehr R, 2008, EXP BRAIN RES, V185, P359, DOI 10.1007/s00221-008-1280-5
   Simonyan K, 2014, CURR OPIN NEUROBIOL, V28, P15, DOI 10.1016/j.conb.2014.05.006
   Stokoe W. C., 1960, STUDIES LINGUISTICS, V8
   Stowe LA, 1998, NEUROREPORT, V9, P2995, DOI 10.1097/00001756-199809140-00014
   Tattersall Ian, 2004, Anatomical Record, V276B, P19, DOI 10.1002/ar.b.10041
   TERRACE HS, 1979, SCIENCE, V206, P891, DOI 10.1126/science.504995
   Thompson CK, 2007, J COGNITIVE NEUROSCI, V19, P1753, DOI 10.1162/jocn.2007.19.11.1753
   Thompson CK, 2010, J COGNITIVE NEUROSCI, V22, P1993, DOI 10.1162/jocn.2009.21334
   Thothathiri M, 2012, J COGNITIVE NEUROSCI, V24, P212, DOI 10.1162/jocn_a_00118
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   Tyler LK, 2005, NEUROPSYCHOLOGIA, V43, P1963, DOI 10.1016/j.neuropsychologia.2005.03.008
   Tyler LK, 2004, NEUROPSYCHOLOGIA, V42, P512, DOI 10.1016/j.neuropsychologia.2003.10.001
   Tyler LK, 2008, PHILOS T R SOC B, V363, P1037, DOI 10.1098/rstb.2007.2158
   Vandenberghe R, 2002, J COGNITIVE NEUROSCI, V14, P550, DOI 10.1162/08989290260045800
   von Humboldt W., 1836, LANGUAGE REPRODUCED, P1988
   Vosse T, 2000, COGNITION, V75, P105, DOI 10.1016/S0010-0277(00)00063-9
   Warneken F, 2007, PLOS BIOL, V5, P1414, DOI 10.1371/journal.pbio.0050184
   Wernicke C, 1874, BOSTON STUDIES PHILO, P34
   Wernicke C., 1900, GRUNDRISS PSYCHIAT
   Westerlund M, 2014, NEUROPSYCHOLOGIA, V57, P59, DOI 10.1016/j.neuropsychologia.2014.03.001
   Whiten A, 1999, NATURE, V399, P682, DOI 10.1038/21415
   Williams A, 2017, NEUROPSYCHOLOGIA, V100, P131, DOI 10.1016/j.neuropsychologia.2017.04.029
   Wilson SM, 2004, J COGNITIVE NEUROSCI, V16, P238, DOI 10.1162/089892904322984535
   Wilson SM, 2018, HUM BRAIN MAPP, V39, P3285, DOI 10.1002/hbm.24077
   Wilson SM, 2018, NEUROIMAGE, V171, P62, DOI 10.1016/j.neuroimage.2017.12.068
   Wilson SM, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192773
   Wilson SM, 2016, BRAIN, V139, P2994, DOI 10.1093/brain/aww218
   Wilson SM, 2014, J COGNITIVE NEUROSCI, V26, P970, DOI 10.1162/jocn_a_00550
   Wilson SM, 2011, NEURON, V72, P397, DOI 10.1016/j.neuron.2011.09.014
   Wilson SM, 2010, J NEUROSCI, V30, P16845, DOI 10.1523/JNEUROSCI.2547-10.2010
   Wilson SM, 2010, BRAIN, V133, P2069, DOI 10.1093/brain/awq129
   Wright P, 2012, J NEUROSCI, V32, P8149, DOI 10.1523/JNEUROSCI.0485-12.2012
   WULFECK B, 1991, J COGNITIVE NEUROSCI, V3, P258, DOI 10.1162/jocn.1991.3.3.258
   Yagata SA, 2017, APHASIOLOGY, V31, P951, DOI 10.1080/02687038.2016.1225276
   Yagmurlu K, 2016, J NEUROSURG, V124, P1396, DOI 10.3171/2015.5.JNS15455
   Yang C, 2013, P NATL ACAD SCI USA, V110, P6324, DOI 10.1073/pnas.1216803110
   Zaccarella E, 2017, CEREB CORTEX, V27, P411, DOI 10.1093/cercor/bhv234
   Zaccarella E, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01818
NR 253
TC 6
Z9 6
U1 2
U2 4
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 1047-3211
EI 1460-2199
J9 CEREB CORTEX
JI Cereb. Cortex
PD MAR
PY 2020
VL 30
IS 3
BP 1481
EP 1498
DI 10.1093/cercor/bhz180
PG 18
WC Neurosciences
SC Neurosciences & Neurology
GA LR7TQ
UT WOS:000535899500046
PM 31670779
DA 2021-02-24
ER

PT J
AU Cheng, Y
   Zhang, YF
   Wang, F
   Jia, GQ
   Zhou, J
   Shan, Y
   Sun, XD
   Yu, LP
   Merzenich, MM
   Recanzone, GH
   Yang, LF
   Zhou, XM
AF Cheng, Yuan
   Zhang, Yifan
   Wang, Fang
   Jia, Guoqiang
   Zhou, Jie
   Shan, Ye
   Sun, Xinde
   Yu, Liping
   Merzenich, Michael M.
   Recanzone, Gregg H.
   Yang, Lianfang
   Zhou, Xiaoming
TI Reversal of Age-Related Changes in Cortical Sound-Azimuth Selectivity
   with Training
SO CEREBRAL CORTEX
LA English
DT Article
DE aging; auditory training; cortical processing; inhibition; plasticity
ID PRIMARY AUDITORY-CORTEX; RECEPTIVE-FIELDS; SINGLE NEURONS; LOCALIZATION;
   PLASTICITY; REPRESENTATION; PARVALBUMIN; INTERNEURONS; EXPRESSION;
   MAGNITUDE
AB The compromised abilities to understand speech and localize sounds are two hallmark deficits in aged individuals. Earlier studies have shown that age-related deficits in cortical neural timing, which is clearly associated with speech perception, can be partially reversed with auditory training. However, whether training can reverse aged-related cortical changes in the domain of spatial processing has never been studied. In this study, we examined cortical spatial processing in similar to 21-month-old rats that were trained on a sound-azimuth discrimination task. We found that animals that experienced 1 month of training displayed sharper cortical sound-azimuth tuning when compared to the age-matched untrained controls. This training-induced remodeling in spatial tuning was paralleled by increases of cortical parvalbumin-labeled inhibitory interneurons. However, no measurable changes in cortical spatial processing were recorded in age-matched animals that were passively exposed to training sounds with no task demands. These results that demonstrate the effects of training on cortical spatial domain processing in the rodent model further support the notion that age-related changes in central neural process are, due to their plastic nature, reversible. Moreover, the results offer the encouraging possibility that behavioral training might be used to attenuate declines in auditory perception, which are commonly observed in older individuals.
C1 [Cheng, Yuan; Zhang, Yifan; Wang, Fang; Jia, Guoqiang; Zhou, Jie; Shan, Ye; Sun, Xinde; Yu, Liping; Zhou, Xiaoming] East China Normal Univ, Shanghai Key Lab Brain Funct Genom, Minist Educ, Key Lab Brain Funct Genom,Sch Life Sci, Shanghai 200062, Peoples R China.
   [Cheng, Yuan; Zhang, Yifan; Wang, Fang; Jia, Guoqiang; Zhou, Jie; Zhou, Xiaoming] New York Univ Shanghai, Inst Brain & Cognit Sci, East China Normal Univ, NYU, Shanghai 200062, Peoples R China.
   [Merzenich, Michael M.] Brain Plast Inst, San Francisco, CA 94108 USA.
   [Recanzone, Gregg H.] Univ Calif Davis, Ctr Neurosci, Davis, CA 95616 USA.
   [Recanzone, Gregg H.] Univ Calif Davis, Dept Neurobiol Physiol & Behav, Davis, CA 95616 USA.
   [Yang, Lianfang] Zhejiang Univ Finance & Econ, Dept Phys Educ, Hangzhou 310018, Peoples R China.
RP Zhou, XM (corresponding author), East China Normal Univ, Shanghai Key Lab Brain Funct Genom, Minist Educ, Key Lab Brain Funct Genom,Sch Life Sci, Shanghai 200062, Peoples R China.; Zhou, XM (corresponding author), New York Univ Shanghai, Inst Brain & Cognit Sci, East China Normal Univ, NYU, Shanghai 200062, Peoples R China.; Yang, LF (corresponding author), Zhejiang Univ Finance & Econ, Dept Phys Educ, Hangzhou 310018, Peoples R China.
EM ylf@zufe.edu.cn; xmzhou@bio.ecnu.edu.cn
CR Abel SM, 2000, J ACOUST SOC AM, V108, P743, DOI 10.1121/1.429607
   Ahveninen J, 2014, HEARING RES, V307, P86, DOI 10.1016/j.heares.2013.07.008
   Anderson Samira, 2013, Perspect Hear Hear Disord Res Res Diagn, V17, P37
   Anderson Samira, 2015, Seminars in Hearing, V36, P250, DOI 10.1055/s-0035-1564455
   Anderson S, 2014, NEUROPSYCHOLOGIA, V62, P286, DOI 10.1016/j.neuropsychologia.2014.07.034
   Anderson S, 2013, P NATL ACAD SCI USA, V110, P4357, DOI 10.1073/pnas.1213555110
   Anderson S, 2012, J NEUROSCI, V32, P14156, DOI 10.1523/JNEUROSCI.2176-12.2012
   Aydelott J, 2010, TRENDS AMPLIF, V14, P218, DOI 10.1177/1084713810393751
   Bao SW, 2004, NAT NEUROSCI, V7, P974, DOI 10.1038/nn1293
   Beitel RE, 2003, P NATL ACAD SCI USA, V100, P11070, DOI 10.1073/pnas.1334187100
   Blake DT, 2002, P NATL ACAD SCI USA, V99, P10114, DOI 10.1073/pnas.092278099
   Brecht EJ, 2017, NEUROBIOL AGING, V56, P87, DOI 10.1016/j.neurobiolaging.2017.04.003
   Briley PM, 2014, NEUROBIOL AGING, V35, P633, DOI 10.1016/j.neurobiolaging.2013.08.033
   Caspary DM, 2008, J EXP BIOL, V211, P1781, DOI 10.1242/jeb.013581
   Caspary DM, 2013, NEUROBIOL AGING, V34, P1486, DOI 10.1016/j.neurobiolaging.2012.11.009
   Cheng Y, 2017, P NATL ACAD SCI USA, V114, P6364, DOI 10.1073/pnas.1707086114
   Cisneros-Franco JM, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0051-18.2018
   de Villers-Sidani E, 2008, NAT NEUROSCI, V11, P957, DOI 10.1038/nn.2144
   de Villers-Sidani E, 2010, P NATL ACAD SCI USA, V107, P13900, DOI 10.1073/pnas.1007885107
   Desgent S, 2010, NEUROSCIENCE, V171, P1326, DOI 10.1016/j.neuroscience.2010.10.016
   DIAMOND DM, 1989, BEHAV NEUROSCI, V103, P471, DOI 10.1037/0735-7044.103.3.471
   DIAMOND DM, 1986, BRAIN RES, V372, P357, DOI 10.1016/0006-8993(86)91144-3
   Dobreva MS, 2011, J NEUROPHYSIOL, V105, P2471, DOI 10.1152/jn.00951.2010
   Engle JR, 2013, FRONT AGING NEUROSCI, V4, DOI [10.3389/fnagi.2012.00036, 10.3389/fnagi.2012.00010]
   Freigang C, 2015, CELL TISSUE RES, V361, P371, DOI 10.1007/s00441-015-2230-8
   Fritz J, 2003, NAT NEUROSCI, V6, P1216, DOI 10.1038/nn1141
   Groh JM, 2003, J COGNITIVE NEUROSCI, V15, P1217, DOI 10.1162/089892903322598166
   HEFFNER HE, 1990, J NEUROPHYSIOL, V64, P915
   JENKINS WM, 1984, J NEUROPHYSIOL, V52, P819
   Juarez-Salinas DL, 2010, J NEUROSCI, V30, P14795, DOI 10.1523/JNEUROSCI.3393-10.2010
   KAVANAGH GL, 1987, J NEUROPHYSIOL, V57, P1746
   Leong UC, 2011, NEUROBIOL AGING, V32, P168, DOI 10.1016/j.neurobiolaging.2009.01.006
   Li LY, 2015, CEREB CORTEX, V25, P1782, DOI 10.1093/cercor/bht417
   Liu X, 2019, CEREB CORTEX, V29, P3294, DOI 10.1093/cercor/bhy199
   Mahncke HW, 2006, PROG BRAIN RES, V157, P81, DOI 10.1016/S0079-6123(06)57006-2
   Malhotra S, 2008, J NEUROPHYSIOL, V99, P1628, DOI 10.1152/jn.01228.2007
   Miller LM, 2009, P NATL ACAD SCI USA, V106, P5931, DOI 10.1073/pnas.0901023106
   Mishra J, 2014, NEURON, V84, P1091, DOI 10.1016/j.neuron.2014.10.034
   Moore AK, 2013, J NEUROSCI, V33, P13713, DOI 10.1523/JNEUROSCI.0663-13.2013
   Nodal FR, 2010, J NEUROPHYSIOL, V103, P1209, DOI 10.1152/jn.00991.2009
   Ouda L, 2008, EXP GERONTOL, V43, P782, DOI 10.1016/j.exger.2008.04.001
   Ouda L, 2015, CELL TISSUE RES, V361, P337, DOI 10.1007/s00441-014-2107-2
   Ouellet L, 2014, FRONT NEUROANAT, V8, DOI 10.3389/fnana.2014.00040
   Paxinos G, 1998, RAT BRAIN IN STEREOTAXIC COORDINATES, FOURTH ED., pix
   Polley DB, 2007, J NEUROPHYSIOL, V97, P3621, DOI 10.1152/jn.01298.2006
   Polley DB, 2004, P NATL ACAD SCI USA, V101, P16351, DOI 10.1073/pnas.0407586101
   Polley DB, 2006, J NEUROSCI, V26, P4970, DOI 10.1523/JNEUROSCI.3771-05.2006
   Recanzone GH, 2000, J NEUROPHYSIOL, V83, P2723
   RECANZONE GH, 1993, J NEUROSCI, V13, P87
   Recanzone G, 2018, HEARING RES, V366, P99, DOI 10.1016/j.heares.2018.05.013
   Ross B, 2007, J NEUROSCI, V27, P11172, DOI 10.1523/JNEUROSCI.1813-07.2007
   Rutkowski RG, 2005, P NATL ACAD SCI USA, V102, P13664, DOI 10.1073/pnas.0506838102
   Schneider BA, 2002, CAN J EXP PSYCHOL, V56, P139, DOI 10.1037/h0087392
   Schoof T, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00307
   Schreiner CE, 2014, CURR OPIN NEUROBIOL, V24, P143, DOI 10.1016/j.conb.2013.11.009
   Smith AL, 2004, EUR J NEUROSCI, V19, P3059, DOI 10.1111/j.0953-816X.2004.03379.x
   Suta D, 2011, EXP GERONTOL, V46, P739, DOI 10.1016/j.exger.2011.05.004
   THOMPSON GC, 1983, BEHAV BRAIN RES, V8, P211, DOI 10.1016/0166-4328(83)90055-4
   Turner JG, 2005, J NEUROPHYSIOL, V94, P2738, DOI 10.1152/jn.00362.2005
   Voss P, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/1801979
   Whitton JP, 2014, P NATL ACAD SCI USA, V111, pE2606, DOI 10.1073/pnas.1322184111
   Witte RS, 2005, COGNITIVE BRAIN RES, V23, P171, DOI 10.1016/j.cogbrainres.2004.10.018
   Wood KC, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0170264
   Yu QL, 2016, CURR BIOL, V26, P3176, DOI 10.1016/j.cub.2016.09.034
   Zatorre RJ, 2001, J NEUROSCI, V21, P6321
   Zhang Y, 2013, J NEUROSCI, V33, P9693, DOI 10.1523/JNEUROSCI.0158-13.2013
   Zhou XM, 2007, P NATL ACAD SCI USA, V104, P15935, DOI 10.1073/pnas.0707348104
   Zhou XM, 2015, P NATL ACAD SCI USA, V112, P2233, DOI 10.1073/pnas.1416582111
   Zhou XM, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms1849
   Zhou XM, 2010, P NATL ACAD SCI USA, V107, P14839, DOI 10.1073/pnas.1009433107
   Zhou XM, 2009, NAT NEUROSCI, V12, P26, DOI 10.1038/nn.2239
   Zhou XM, 2002, J COMP PHYSIOL A, V188, P815, DOI 10.1007/s00359-002-0367-x
   Zhu XQ, 2016, CEREB CORTEX, V26, P334, DOI 10.1093/cercor/bhu258
   Zhu XQ, 2014, J NEUROSCI, V34, P5406, DOI 10.1523/JNEUROSCI.5310-13.2014
NR 74
TC 0
Z9 0
U1 4
U2 6
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 1047-3211
EI 1460-2199
J9 CEREB CORTEX
JI Cereb. Cortex
PD MAR
PY 2020
VL 30
IS 3
BP 1768
EP 1778
DI 10.1093/cercor/bhz201
PG 11
WC Neurosciences
SC Neurosciences & Neurology
GA LR7TQ
UT WOS:000535899500066
PM 31504260
DA 2021-02-24
ER

PT J
AU Wollman, I
   Arias, P
   Aucouturier, JJ
   Morillon, B
AF Wollman, Indiana
   Arias, Pablo
   Aucouturier, Jean-Julien
   Morillon, Benjamin
TI Neural entrainment to music is sensitive to melodic spectral complexity
SO JOURNAL OF NEUROPHYSIOLOGY
LA English
DT Article
DE arousal; auditory perception; EEG; emotion; neural oscillations;
   temporal envelope
ID AUDITORY-CORTEX; CORTICAL ENTRAINMENT; PHASE ENTRAINMENT;
   SPEECH-PERCEPTION; OSCILLATIONS; RESPONSES; PREDICTIONS; MODULATION;
   PATTERNS; TALK
AB During auditory perception, neural oscillations are known to entrain to acoustic dynamics but their role in the processing of auditory information remains unclear. As a complex temporal structure that can be parameterized acoustically, music is particularly suited to address this issue. In a combined behavioral and EEG experiment in human participants, we investigated the relative contribution of temporal (acoustic dynamics) and nontemporal (melodic spectral complexity) dimensions of stimulation on neural entrainment, a stimulus-brain coupling phenomenon operationally defined here as the temporal coherence between acoustical and neural dynamics. We first highlight that low-frequency neural oscillations robustly entrain to complex acoustic temporal modulations, which underscores the fine-grained nature of this coupling mechanism. We also reveal that enhancing melodic spectral complexity, in terms of pitch, harmony, and pitch variation, increases neural entrainment. Importantly, this manipulation enhances activity in the theta (5 Hz) range, a frequency-selective effect independent of the note rate of the melodies, which may reflect internal temporal constraints of the neural processes involved. Moreover, while both emotional arousal ratings and neural entrainment were positively modulated by spectral complexity, no direct relationship between arousal and neural entrainment was observed. Overall, these results indicate that neural entrainment to music is sensitive to the spectral content of auditory information and indexes an auditory level of processing that should be distinguished from higher-order emotional processing stages.
   NEW & NOTEWORTHY Low-frequency (<10 Hz) cortical neural oscillations are known to entrain to acoustic dynamics, the so-called neural entrainment phenomenon, but their functional implication in the processing of auditory information remains unclear. In a behavioral and EEG experiment capitalizing on parameterized musical textures, we disentangle the contribution of stimulus dynamics, melodic spectral complexity, and emotional judgments on neural entrainment and highlight their respective spatial and spectral neural signature.
C1 [Wollman, Indiana] McGill Univ, Montreal Neurol Inst, 3801 Rue Univ, Montreal, PQ H3A 2B4, Canada.
   [Wollman, Indiana] Philharmonie Paris, Cite Mus, Paris, France.
   [Arias, Pablo; Aucouturier, Jean-Julien] Sorbonne Univ, Inst Rech Coordinat Acoust Mus, CNRS, UMR 9912,STMS, Paris, France.
   [Morillon, Benjamin] Aix Marseille Univ, INSERM, Inst Neurosci Syst, Marseille, France.
RP Wollman, I (corresponding author), McGill Univ, Montreal Neurol Inst, 3801 Rue Univ, Montreal, PQ H3A 2B4, Canada.
EM indiana.wollman@mail.mcgill.ca
OI Morillon, Benjamin/0000-0002-0049-064X; Arias, Pablo/0000-0002-4868-120X
FU ERC CREAM [3355336]; ILCB [ANR-16-CONV-0002]; BLRI [ANR-11-LABX-0036];
   Excellence Initiative of Aix-Marseille University (A*MIDEX)French
   National Research Agency (ANR)
FX This work was supported by ERC CREAM (3355336) to J.I.A. Data were
   collected at the Centre Multidisciplinaire des Sciences Comportementales
   Sorbonne Universit6-INSEAD. B.M. is supported by grants ANR-16-CONV0002
   (ILCB), ANR-11-LABX-0036 (BLRI) and the Excellence Initiative of
   Aix-Marseille University (A*MIDEX).
CR Abrams DA, 2008, J NEUROSCI, V28, P3958, DOI 10.1523/JNEUROSCI.0187-08.2008
   Beller G., 2018, EBMS EMOTION BASED M
   Bonin TL, 2016, COGNITION, V154, P174, DOI 10.1016/j.cognition.2016.05.021
   Breska A, 2017, PLOS BIOL, V15, DOI 10.1371/journal.pbio.2001665
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Cravo AM, 2013, J NEUROSCI, V33, P4002, DOI 10.1523/JNEUROSCI.4675-12.2013
   Ding N, 2017, NEUROSCI BIOBEHAV R, V81, P181, DOI 10.1016/j.neubiorev.2017.02.011
   Ding N, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00311
   Ding N, 2014, NEUROIMAGE, V88, P41, DOI 10.1016/j.neuroimage.2013.10.054
   Doelling KB, 2019, P NATL ACAD SCI USA, V116, P10113, DOI 10.1073/pnas.1816414116
   Doelling KB, 2015, P NATL ACAD SCI USA, V112, pE6233, DOI 10.1073/pnas.1508431112
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Dorsen A, 2015, TDR-DRAMA REV-J PERF, V59, P133, DOI 10.1162/DRAM_a_00501
   Folta-Schoofs K, 2014, ACTA PSYCHOL, V147, P51, DOI 10.1016/j.actpsy.2013.10.001
   Gelman A., 2007, DATA ANAL USING REGR
   Ghinst MV, 2016, J NEUROSCI, V36, P1596, DOI 10.1523/JNEUROSCI.1730-15.2016
   Ghitza O, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00238
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Giroud J, 2019, BIORXIV581520, DOI [10.1101/581520, DOI 10.1101/581520]
   Gluth S, 2019, ELIFE, V8, DOI 10.7554/eLife.42607
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Haegens S, 2018, NEUROSCI BIOBEHAV R, V86, P150, DOI 10.1016/j.neubiorev.2017.12.002
   Henry MJ, 2012, P NATL ACAD SCI USA, V109, P20095, DOI 10.1073/pnas.1213390109
   Juslin PN, 2008, BEHAV BRAIN SCI, V31, P559, DOI 10.1017/S0140525X08005293
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Kosem A, 2017, LANG COGN NEUROSCI, V32, P536, DOI 10.1080/23273798.2016.1238495
   Lakatos P, 2013, NEURON, V77, P750, DOI 10.1016/j.neuron.2012.11.034
   Lepage KQ, 2017, J THEOR BIOL, V435, P106, DOI 10.1016/j.jtbi.2017.08.029
   Liegeois-Chauvel C, 2014, CORTEX, V60, P82, DOI 10.1016/j.cortex.2014.06.002
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Morillon B, 2017, P NATL ACAD SCI USA, V114, pE8913, DOI 10.1073/pnas.1705373114
   Morillon B, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00248
   Nobre AC, 2018, NAT REV NEUROSCI, V19, P34, DOI 10.1038/nrn.2017.141
   Patel AD, 2008, NATURE, V453, P726, DOI 10.1038/453726a
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Perez-Gonzalez D, 2014, FRONT INTEGR NEUROSC, V8, DOI 10.3389/fnint.2014.00019
   Poeppel D, 2008, PHILOS T R SOC B, V363, P1071, DOI 10.1098/rstb.2007.2160
   Riecke L, 2018, CURR BIOL, V28, P161, DOI 10.1016/j.cub.2017.11.033
   Rimmele JM, 2018, TRENDS COGN SCI, V22, P870, DOI 10.1016/j.tics.2018.08.003
   Salimpoor VN, 2015, TRENDS COGN SCI, V19, P86, DOI 10.1016/j.tics.2014.12.001
   Salimpoor VN, 2013, SCIENCE, V340, P216, DOI 10.1126/science.1231059
   Schroeder CE, 2009, TRENDS NEUROSCI, V32, P9, DOI 10.1016/j.tins.2008.09.012
   Shamma SA, 2011, TRENDS NEUROSCI, V34, P114, DOI 10.1016/j.tins.2010.11.002
   Smith PL, 2018, PSYCHON B REV, V25, P2083, DOI 10.3758/s13423-018-1451-8
   Steinmetzger K, 2017, NEUROPSYCHOLOGIA, V95, P173, DOI 10.1016/j.neuropsychologia.2016.12.003
   Tadel F, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/879716
   Teng XB, 2017, PLOS BIOL, V15, DOI 10.1371/journal.pbio.2000812
   Teng XB, 2016, SCI REP-UK, V6, DOI 10.1038/srep34390
   Tingley D, 2014, J STAT SOFTW, V59
   VanRullen R, 2016, TRENDS COGN SCI, V20, P723, DOI 10.1016/j.tics.2016.07.006
   ZATORRE RJ, 1994, J NEUROSCI, V14, P1908, DOI 10.1523/jneurosci.14-04-01908.1994
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
   Zoefel B, 2015, J NEUROSCI, V35, P1954, DOI 10.1523/JNEUROSCI.3484-14.2015
NR 57
TC 0
Z9 0
U1 2
U2 5
PU AMER PHYSIOLOGICAL SOC
PI BETHESDA
PA 9650 ROCKVILLE PIKE, BETHESDA, MD 20814 USA
SN 0022-3077
EI 1522-1598
J9 J NEUROPHYSIOL
JI J. Neurophysiol.
PD MAR
PY 2020
VL 123
IS 3
BP 1063
EP 1071
DI 10.1152/jn.00758.2018
PG 9
WC Neurosciences; Physiology
SC Neurosciences & Neurology; Physiology
GA LA8XU
UT WOS:000524225600018
PM 32023136
DA 2021-02-24
ER

PT J
AU Banai, K
   Nir, B
   Moav-Scheff, R
   Bar-Ziv, N
AF Banai, Karen
   Nir, Bracha
   Moav-Scheff, Ronny
   Bar-Ziv, Noga
TI A role for incidental auditory learning in auditory-visual word learning
   among kindergarten children
SO JOURNAL OF VISION
LA English
DT Article
DE incidental learning; anchoring; nonadjacent dependencies
ID TRAINING JAPANESE LISTENERS; PHONOTACTIC PROBABILITY;
   INDIVIDUAL-DIFFERENCES; NEIGHBORHOOD DENSITY; PHONOLOGICAL MEMORY;
   TALKER VARIABILITY; SPEECH-PERCEPTION; PHONETIC DETAIL; DEFICITS; HEBREW
AB This study focused on the potential role of incidental, auditory perceptual learning in among children learning new words. To this end, we examined how irrelevant auditory similarities across words, that provide no cues regarding their visual or conceptual attributes, influence pseudo-word learning in a name/picture matching paradigm. Two types of irrelevant auditory similarities were used: shared sequences of vowels or consonants. Learning word-to-picture associations in these two conditions was compared to a baseline condition in which items did not share either sequence. Kindergarten children readily learned items in all conditions, but auditory similarity interfered with learning (odds ratio, 1.12). Individual differences in reasoning and vocabulary did not account for the interference effect. These findings suggest that the sensory properties of words continue to influence language learning during the preschool years through rapid incidental learning, even if the effect is relatively small. Consistent with previous studies in the visual modality, we now suggest that incidental perceptual learning occurs in the auditory modality. Furthermore, the current findings suggest that this learning can interfere with word learning, highlighting the importance of the perceptual structure of words in real-world-like learning environments.
C1 [Banai, Karen; Nir, Bracha; Moav-Scheff, Ronny; Bar-Ziv, Noga] Univ Haifa, Dept Commun Sci & Disorders, Haifa, Israel.
RP Banai, K (corresponding author), Univ Haifa, Dept Commun Sci & Disorders, Haifa, Israel.
EM kbanai@research.haifa.ac.il
RI Banai, Karen/J-1448-2019
OI Banai, Karen/0000-0002-2990-0470
FU Israel Science FoundationIsrael Science Foundation [112/13]
FX Supported by the Israel Science Foundation (grant 112/13). Dorit Nesher
   helped with participant recruitment and data collection. Prof. Ayala
   Cohen and Dr. Etti Doveh from the Statistics Laboratory at the Technion
   helped with the statistical analysis. We thank Dr. Rama Novogrodsky for
   reading the manuscript.
CR Apfelbaum KS, 2013, DEV PSYCHOL, V49, P1348, DOI 10.1037/a0029839
   Arad M., 2006, ROOTS PATTERNS HEBRE, V63
   Baddeley A. D, 1986, WORKING MEMORY
   Badger JR, 2012, J EXP CHILD PSYCHOL, V113, P131, DOI 10.1016/j.jecp.2012.03.004
   Banai K, 2016, J EXP CHILD PSYCHOL, V142, P118, DOI 10.1016/j.jecp.2015.10.001
   Banai K, 2012, J EXP CHILD PSYCHOL, V112, P403, DOI 10.1016/j.jecp.2012.04.008
   Banai K, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019769
   Bent T, 2013, J ACOUST SOC AM, V133, P1677, DOI 10.1121/1.4776212
   BENTIN S, 1990, Q J EXP PSYCHOL-A, V42, P693, DOI 10.1080/14640749008401245
   Berman R. A., 2017, LEXICAL POLYCATEGORI, P343
   Berman R. A., 2003, LANGUAGE PROCESSING, P243
   Berman RA, 2000, METHODS FOR STUDYING LANGUAGE PRODUCTION, P69
   BERMAN RA, 1987, FOLIA LINGUIST, V21, P425
   Berman Ruth A., 1981, HEBREW COMPUTATIONAL, V18, P31
   Bick AS, 2010, J COGNITIVE NEUROSCI, V22, P1955, DOI 10.1162/jocn.2009.21357
   Bloom P, 2001, CURR BIOL, V11, pR5, DOI 10.1016/S0960-9822(00)00032-4
   Bloom P., 2000, CHILDREN LEARN MEANI
   Bonatti LL, 2005, PSYCHOL SCI, V16, P451, DOI 10.1111/j.0956-7976.2005.01556.x
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Brosseau-Lapre F, 2013, APPL PSYCHOLINGUIST, V34, P419, DOI 10.1017/S0142716411000750
   Chandrasekaran B, 2009, NEURON, V64, P311, DOI 10.1016/j.neuron.2009.10.006
   CLARK EV, 1984, LANGUAGE, V60, P542, DOI 10.2307/413991
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Clopper CG, 2004, J PHONETICS, V32, P111, DOI 10.1016/S0095-4470(03)00009-3
   Cohen Y, 2013, J COGNITIVE NEUROSCI, V25, P2047, DOI 10.1162/jocn_a_00453
   Conway CM, 2010, COGNITION, V114, P356, DOI 10.1016/j.cognition.2009.10.009
   CUNNINGHAM AE, 1991, J EDUC PSYCHOL, V83, P264, DOI 10.1037/0022-0663.83.2.264
   Delle Luche C, 2014, J MEM LANG, V72, P1, DOI 10.1016/j.jml.2013.12.001
   Deutsch A, 2005, LANG COGNITIVE PROC, V20, P341, DOI 10.1080/01690960444000115
   Emberson LL, 2013, COGNITION, V128, P82, DOI 10.1016/j.cognition.2012.12.006
   Fennell CT, 2003, LANG SPEECH, V46, P245, DOI 10.1177/00238309030460020901
   Ferman S, 2014, FOLIA PHONIATR LOGO, V66, P77, DOI 10.1159/000363135
   Frost R, 1997, J EXP PSYCHOL LEARN, V23, P829, DOI 10.1037/0278-7393.23.4.829
   Frost R, 2000, MEM COGNITION, V28, P1277, DOI 10.3758/BF03211828
   Frost RLA, 2016, COGNITION, V147, P70, DOI 10.1016/j.cognition.2015.11.010
   GATHERCOLE SE, 1990, J MEM LANG, V29, P336, DOI 10.1016/0749-596X(90)90004-J
   GIBSON EJ, 1971, COGNITIVE PSYCHOL, V2, P351, DOI 10.1016/0010-0285(71)90020-X
   Green C. S., 2018, STEVENS HDB EXPT PSY, V2, P755, DOI [10.1002/9781119170174, DOI 10.1002/9781119170174]
   Havy M, 2011, J EXP CHILD PSYCHOL, V108, P25, DOI 10.1016/j.jecp.2010.08.002
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   Hoonhorst I, 2011, SPEECH COMMUN, V53, P417, DOI 10.1016/j.specom.2010.11.005
   Hoover JR, 2010, J MEM LANG, V63, P100, DOI 10.1016/j.jml.2010.02.003
   Inoue T, 2011, RES DEV DISABIL, V32, P2748, DOI 10.1016/j.ridd.2011.05.035
   Kachergis G, 2017, COGNITIVE SCI, V41, P590, DOI 10.1111/cogs.12353
   Katzenberger I., 2009, KATZENBERGER LANGUAG
   Katzenberger I, 2014, LANG TEST, V31, P19, DOI 10.1177/0265532213491961
   Kidd E, 2016, CHILD DEV, V87, P184, DOI 10.1111/cdev.12461
   Kimel E, 2020, J EXP PSYCHOL LEARN, V46, P155, DOI 10.1037/xlm0000717
   Larsen JA, 2007, LANG SPEECH HEAR SER, V38, P201, DOI 10.1044/0161-1461(2007/021)
   Lim SJ, 2011, COGNITIVE SCI, V35, P1390, DOI 10.1111/j.1551-6709.2011.01192.x
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   MARTIN CS, 1989, J EXP PSYCHOL LEARN, V15, P676, DOI 10.1037/0278-7393.15.4.676
   McQueen JM, 1998, J MEM LANG, V39, P21, DOI 10.1006/jmla.1998.2568
   Merkx M, 2011, Q J EXP PSYCHOL, V64, P1200, DOI 10.1080/17470218.2010.538211
   Misyak JB, 2012, LANG LEARN, V62, P302, DOI 10.1111/j.1467-9922.2010.00626.x
   Moav-Scheff R, 2015, RES DEV DISABIL, V45-46, P384, DOI 10.1016/j.ridd.2015.08.010
   Montgomery JW, 1995, APPL PSYCHOLINGUIST, V16, P355, DOI 10.1017/S0142716400065991
   MORAIS J, 1986, COGNITION, V24, P45, DOI 10.1016/0010-0277(86)90004-1
   Nahum M, 2010, J NEUROSCI, V30, P1128, DOI 10.1523/JNEUROSCI.1781-09.2010
   Nespor M., 2003, LINGUE LINGUAGGIO, V2, P203, DOI [10. 1418/ 10879, DOI 10.1418/10879]
   Newport EL, 2004, COGNITIVE PSYCHOL, V48, P127, DOI 10.1016/S0010-0285(03)00128-2
   Newport EL, 2016, LANG COGN, V8, P447, DOI 10.1017/langcog.2016.20
   Nygaard LC, 2009, COGNITION, V112, P181, DOI 10.1016/j.cognition.2009.04.001
   Oganian Y, 2012, NEUROPSYCHOLOGIA, V50, P1895, DOI 10.1016/j.neuropsychologia.2012.04.014
   Protopapas A, 2017, COGNITION, V166, P251, DOI 10.1016/j.cognition.2017.05.030
   Ramscar M, 2013, PSYCHOL SCI, V24, P1017, DOI 10.1177/0956797612460691
   Ravid D, 2005, READ WRIT, V18, DOI [10.1007/s11145-005-1802-5, DOI 10.1007/S11145-005-1802-5]
   Ravid D., 2016, ACQUISITION DEV HEBR, DOI DOI 10.1075/TILAR.19.04RAV
   Ravid D., 2001, FIRST LANG, V21, P25, DOI DOI 10.1177/014272370102106102
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   Segal O, 2009, J CHILD LANG, V36, P629, DOI 10.1017/S030500090800915X
   Seroussi B., 2011, THESIS
   Shimron J., 2003, LANGUAGE PROCESSING, V28
   Sidaras SK, 2009, J ACOUST SOC AM, V125, P3306, DOI 10.1121/1.3101452
   Sloutsky VM, 2007, PSYCHOL SCI, V18, P179, DOI 10.1111/j.1467-9280.2007.01869.x
   Smith LB, 1996, COGNITION, V60, P143, DOI 10.1016/0010-0277(96)00709-3
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Storkel HL, 2001, J SPEECH LANG HEAR R, V44, P1321, DOI 10.1044/1092-4388(2001/103)
   Storkel HL, 2006, J SPEECH LANG HEAR R, V49, P1175, DOI 10.1044/1092-4388(2006/085)
   Storkel HL, 2014, J SPEECH LANG HEAR R, V57, P1708, DOI 10.1044/2014_JSLHR-L-13-0150
   Swingley D, 2008, CURR DIR PSYCHOL SCI, V17, P308, DOI 10.1111/j.1467-8721.2008.00596.x
   Swingley D, 2007, COGNITIVE PSYCHOL, V54, P99, DOI 10.1016/j.cogpsych.2006.05.001
   Tamminen J, 2012, COGNITION, V125, P107, DOI 10.1016/j.cognition.2012.06.014
   Tavor A., 2011, TAVOR EXPRESSIVE VOC
   Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788
   Thiessen E., 2015, HDB LANG EMERG, P396, DOI DOI 10.1002/978111834613
   Vlahou EL, 2012, J EXP PSYCHOL GEN, V141, P363, DOI 10.1037/a0025014
   Wechsler D., 1989, WECHSLER PRESCHOOL P
   WYSOCKI K, 1987, READ RES QUART, V22, P66, DOI 10.2307/747721
   Xu F, 2007, PSYCHOL REV, V114, P245, DOI 10.1037/0033-295X.114.2.245
NR 91
TC 0
Z9 0
U1 0
U2 0
PU ASSOC RESEARCH VISION OPHTHALMOLOGY INC
PI ROCKVILLE
PA 12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA
SN 1534-7362
J9 J VISION
JI J. Vision
PD MAR
PY 2020
VL 20
IS 3
AR 4
DI 10.1167/jov.20.3.4
PG 14
WC Ophthalmology
SC Ophthalmology
GA LD0QV
UT WOS:000525739000004
PM 32181860
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Erskine, ME
   Munson, B
   Edwards, JR
AF Erskine, Michelle E.
   Munson, Benjamin
   Edwards, Jan R.
TI Relationship between early phonological processing and later
   phonological awareness: Evidence from nonword repetition
SO APPLIED PSYCHOLINGUISTICS
LA English
DT Article
DE nonword repetition; phonological awareness; phonological processing;
   preschool-aged children
ID WORKING-MEMORY; PHONOTACTIC PROBABILITY; EMERGENT LITERACY;
   SPEECH-PERCEPTION; VOCABULARY SIZE; CHILDREN; LANGUAGE; PRESCHOOL;
   SKILLS; ACQUISITION
AB This study investigated whether individual differences in receptive vocabulary, speech perception and production, and nonword repetition at age 2 years, 4 months to 3 years, 4 months predicted phonological awareness 2 years later. One hundred twenty-one children were tested twice. During the first testing period (Time 1), children's receptive vocabulary, speech perception and production, and nonword repetition were measured. Nonword repetition accuracy in the present study was distinct from other widely used measures of nonword repetition in that it focused on narrow transcription of diphone sequences in each nonword that differed systematically in phonotactic probability. At the second testing period (Time 2), children's phonological awareness was measured. The best predictors of phonological awareness were a measure of speech production and a measure of phonological processing derived from performance on the nonword repetition task. The results of this study suggest that nonword repetition accuracy provides an implicit measure of phonological skills that are indicative of later phonological awareness at an age when children are too young to perform explicit phonological awareness tasks reliably.
C1 [Erskine, Michelle E.; Edwards, Jan R.] Univ Wisconsin, Madison, WI 53706 USA.
   [Erskine, Michelle E.; Edwards, Jan R.] Univ Maryland, College Pk, MD 20742 USA.
   [Munson, Benjamin] Univ Minnesota, Minneapolis, MN USA.
RP Erskine, ME (corresponding author), Univ Wisconsin, Madison, WI 53706 USA.; Erskine, ME (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM merskine@terpmail.umd.edu
OI Erskine, Michelle/0000-0003-1036-1013
FU NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R01 02932, T32 DC005359, 30
   HD03352]; National Science FoundationNational Science Foundation (NSF)
   [1449815]
FX This work was supported by NIDCD R01 02932 to Jan Edwards, Mary E.
   Beckman, and Benjamin Munson; NIDCD T32 DC005359 to Susan Ellis Weismer;
   and NICHD 30 HD03352 to the Waisman Center. This material is also based
   upon work supported by the National Science Foundation under Grant
   1449815. We are grateful to all of the children who participated in this
   study, their families, and community members who assisted with
   recruiting. We also thank Patrick Reidy, Tristan Mahr, and affiliate
   members of the Learning to Talk labs at the University of
   Wisconsin-Madison and the University of Minnesota and Mary E. Beckman at
   the Ohio State University for their contributions to this research.
CR Anderson JD, 2006, J FLUENCY DISORD, V31, P177, DOI 10.1016/j.jfludis.2006.05.001
   Anthony JL, 2004, J EDUC PSYCHOL, V96, P43, DOI 10.1037/0022-0663.96.1.43
   AVAAZ Innovations, 1995, SAILS SPEECH ASS INT
   Baddeley A, 2003, J COMMUN DISORD, V36, P189, DOI 10.1016/S0021-9924(03)00019-4
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Becker MA, 2000, ADV EXP MED BIOL, V486, P5
   Beckman M. A., 2011, P 17 INT C PHON SCI, P300
   BIRD J, 1995, J SPEECH HEAR RES, V38, P446, DOI 10.1044/jshr.3802.446
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Carroll JM, 2003, DEV PSYCHOL, V39, P913, DOI 10.1037/0012-1649.39.5.913
   CHANEY C, 1992, APPL PSYCHOLINGUIST, V13, P485, DOI 10.1017/S0142716400005774
   Cheung SY, 2003, J COMP FAM STUD, V34, P413, DOI 10.3138/jcfs.34.3.413
   Chiat S, 2007, J SPEECH LANG HEAR R, V50, P429, DOI 10.1044/1092-4388(2007/030)
   Chiat S, 2006, APPL PSYCHOLINGUIST, V27, P552, DOI 10.1017/S014271640623039X
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Dollaghan C, 1998, J SPEECH LANG HEAR R, V41, P1136, DOI 10.1044/jslhr.4105.1136
   Dunn M., 2007, PEABODY PICTURE VOCA
   Edwards J, 2004, J SPEECH LANG HEAR R, V47, P421, DOI 10.1044/1092-4388(2004/034)
   Edwards J, 1998, APPL PSYCHOLINGUIST, V19, P279, DOI 10.1017/S0142716400010079
   Edwards J, 2008, CLIN LINGUIST PHONET, V22, P937, DOI 10.1080/02699200802330223
   FERGUSON CA, 1975, LANGUAGE, V51, P419, DOI 10.2307/412864
   GATHERCOLE SE, 1993, DEV PSYCHOL, V29, P770, DOI 10.1037/0012-1649.29.4.770
   Gathercole SE, 2006, APPL PSYCHOLINGUIST, V27, P513, DOI 10.1017/S0142716406060383
   Goldman R, 2000, GOLDMAN FRISTOE TEST
   Goswami U., 1990, ESSAYS DEV PSYCHOL S
   Gray S, 2006, APPL PSYCHOLINGUIST, V27, P562, DOI 10.1017/S0142716406250392
   Gupta P, 2009, INTERACTIONS BETWEEN SHORT-TERM AND LONG-TERM MEMORY IN THE VERBAL DOMAIN, P108
   HOFFMAN PR, 1983, J SPEECH HEAR DISORD, V48, P210, DOI 10.1044/jshd.4802.210
   Juneja M, 2013, TRANSCULT STUD, P2
   Lewis BA, 2000, J COMMUN DISORD, V33, P11, DOI 10.1016/S0021-9924(99)00023-4
   Liberman I. Y., 1972, B ORTON SOC, V23, P65
   Lindblom Bjorn, 1992, PHONOLOGICAL DEV MOD, P131
   Lonigan CJ, 2000, DEV PSYCHOL, V36, P596, DOI [10.1037/0012-1649.36.5.596, 10.1037//0012-1649.36.5.596]
   McBride C., 2015, CHILDRENS LITERACY D
   McBride-Chang C, 2005, SCI STUD READ, V9, P117, DOI 10.1207/s1532799xssr0902_2
   MCBRIDECHANG C, 1995, J EDUC PSYCHOL, V87, P179, DOI 10.1037/0022-0663.87.2.179
   Metsala JL, 1999, J EDUC PSYCHOL, V91, P3, DOI 10.1037/0022-0663.91.1.3
   Metsala JL, 1998, WORD RECOGNITION IN BEGINNING LITERACY, P89
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Munson B, 2005, J SPEECH LANG HEAR R, V48, P1033, DOI 10.1044/1092-4388(2005/072)
   Munson B, 2005, TOP LANG DISORD, V25, P190, DOI 10.1097/00011363-200507000-00003
   Munson B, 2001, J SPEECH LANG HEAR R, V44, P778, DOI 10.1044/1092-4388(2001/061)
   Munson B, 2010, LAB PHONOLOGY, P381, DOI DOI 10.1515/9783110224917
   Nittrouer S, 2005, J COMMUN DISORD, V38, P29, DOI 10.1016/j.jcomdis.2004.03.006
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   PISONI DB, 1985, SPEECH COMMUN, V4, P75, DOI 10.1016/0167-6393(85)90037-8
   Raudenbush SW, 2000, J COMPUT GRAPH STAT, V9, P141, DOI 10.2307/1390617
   Roberts JE, 2005, J SPEECH LANG HEAR R, V48, P345, DOI 10.1044/1092-4388(2005/024)
   ROHL M, 1995, READ WRIT, V7, P327, DOI 10.1007/BF01027723
   Roth P, 2002, J EDUC RES, V95, P259, DOI 10.1080/00220670209596600
   Rvachew S, 2006, AM J SPEECH-LANG PAT, V15, P165, DOI 10.1044/1058-0360(2006/016)
   Rvachew S, 2006, J SPEECH LANG HEAR R, V49, P74, DOI 10.1044/1092-4388(2006/006)
   Rvachew S, 2003, AM J SPEECH-LANG PAT, V12, P463, DOI 10.1044/1058-0360(2003/092)
   RVACHEW S, 1989, J SPEECH HEAR DISORD, V54, P193, DOI 10.1044/jshd.5402.193
   Schneider W., 2012, E PRIME USERS GUIDE
   Shriberg LD, 2009, J SPEECH LANG HEAR R, V52, P1189, DOI 10.1044/1092-4388(2009/08-0047)
   SMITH CL, 1982, J EXP CHILD PSYCHOL, V34, P449, DOI 10.1016/0022-0965(82)90071-6
   Torgesen JK, 2001, J LEARN DISABIL-US, V34, P33, DOI 10.1177/002221940103400104
   Walley AC., 2003, READING WRITING, V16, P5, DOI [DOI 10.1023/A:1021789804977, 10.1023/A:1021789804977]
NR 59
TC 0
Z9 0
U1 1
U2 2
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0142-7164
EI 1469-1817
J9 APPL PSYCHOLINGUIST
JI Appl. Psycholinguist.
PD MAR
PY 2020
VL 41
IS 2
BP 319
EP 346
AR PII S0142716419000547
DI 10.1017/S0142716419000547
PG 28
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA LA8WS
UT WOS:000524222800004
DA 2021-02-24
ER

PT J
AU Jain, C
   Dwarakanath, VM
   Amritha, G
AF Jain, Chandni
   Dwarakanath, Vikas Mysore
   Amritha, G.
TI Suprathreshold Processing and Cocktail Party Listening in Younger and
   Older Adults with Normal Hearing
SO AGEING INTERNATIONAL
LA English
DT Article
DE Temporal processing; Spectral processing; Speech perception
ID TEMPORAL FINE-STRUCTURE; SPEECH RECOGNITION; AGE; PERCEPTION; BENEFIT
AB Present study aimed to investigate the effect of age and suprathreshold processing on cocktail party listening in individuals with normal hearing sensitivity. A total of 92 participants with normal hearing sensitivity were included in the study. They were divided into two groups based on their age. Fifty two young normal hearing adults in the age range of 20-40 years and 40 older normal hearing adults in the age range of 60-80 years. Tests administered included speech perception in noise test, spatial selective attention, gap detection thresholds, temporal modulation transfer function, inter-aural time difference, differential limen of frequency and ripple noise discrimination. Results showed that older adults performed poorer than younger adults in all the tests. Also, temporal cues showed a better relation with speech perception in noise compared to the spectral cues. This can be attributed to the disrupted neural synchrony which is due to poor frequency selectivity as observed through ripple noise discrimination. Individuals rely more on temporal cues due to poorer frequency resolution and phase locking mechanism and also on top down processes such as selective attention too. A degraded speech input would lead them to rely more on their higher cognition.
C1 [Jain, Chandni; Dwarakanath, Vikas Mysore; Amritha, G.] All India Inst Speech & Hearing, Dept Audiol, Mysore, Karnataka, India.
RP Dwarakanath, VM (corresponding author), All India Inst Speech & Hearing, Dept Audiol, Mysore, Karnataka, India.
EM vikasmdaud@gmail.com
CR [Anonymous], MATLAB STAT TOOLB 7
   Babkoff H, 2002, HEARING RES, V165, P117, DOI 10.1016/S0378-5955(02)00292-7
   Craik F. I. M., 1982, AGING COGNITIVE PROC, P191, DOI [10.1007/978-1-4684-4178-9_11., DOI 10.1007/978-1-4684-4178-9_11]
   DEMPSTER FN, 1991, INTELLIGENCE, V15, P157, DOI 10.1016/0160-2896(91)90028-C
   Dubno JR, 2002, J ACOUST SOC AM, V111, P2897, DOI 10.1121/1.1480421
   Finney D.J., 1952, STAT METHOD BIOL ASS
   GORDONSALANT S, 1993, J SPEECH HEAR RES, V36, P1276, DOI 10.1044/jshr.3606.1276
   Grassi M, 2009, BEHAV RES METHODS, V41, P20, DOI 10.3758/BRM.41.1.20
   GREEN DM, 1990, J ACOUST SOC AM, V87, P2662, DOI 10.1121/1.399058
   GREEN DM, 1993, J ACOUST SOC AM, V93, P2096, DOI 10.1121/1.406696
   Grose JH, 2010, EAR HEARING, V31, P755, DOI 10.1097/AUD.0b013e3181e627e7
   Grose JH, 2009, EAR HEARING, V30, P568, DOI 10.1097/AUD.0b013e3181ac128f
   Helfer KS, 2008, EAR HEARING, V29, P87, DOI 10.1097/AUD.0b013e31815d638b
   Helfer KS, 2009, J AM ACAD AUDIOL, V20, P264, DOI 10.3766/jaaa.20.4.6
   Hopkins K, 2008, J ACOUST SOC AM, V123, P1140, DOI 10.1121/1.2824018
   Huss M, 2005, J ACOUST SOC AM, V117, P3841, DOI 10.1121/1.1920167
   Kidd G, 2005, J ACOUST SOC AM, V118, P3804, DOI 10.1121/1.2109187
   Killion M. C., 2000, HEAR J, V53, P46
   METHI R, 2009, J INDIAN SPEECH HEAR, V23, P59
   Moore BCJ, 2008, JARO-J ASSOC RES OTO, V9, P399, DOI 10.1007/s10162-008-0143-x
   Ronnberg J, 2010, NOISE HEALTH, V12, P263, DOI 10.4103/1463-1741.70505
   Ruggles D, 2011, JARO-J ASSOC RES OTO, V12, P395, DOI 10.1007/s10162-010-0254-z
   Salthouse TA, 1996, PSYCHOL REV, V103, P403, DOI 10.1037/0033-295X.103.3.403
   Schneider BA, 2007, J AM ACAD AUDIOL, V18, P559, DOI 10.3766/jaaa.18.7.4
   Schoof T, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00307
   Soranzo A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00712
   Souza P, 2011, EAR HEARING, V32, P75, DOI 10.1097/AUD.0b013e3181eccfe9
   Zeng FG, 2005, P NATL ACAD SCI USA, V102, P2293, DOI 10.1073/pnas.0406460102
   Zurek P. M., 1993, ACOUSTICAL FACTORS A, P255
NR 29
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0163-5158
EI 1936-606X
J9 AGEING INT
JI Ageing Int.
PD MAR
PY 2020
VL 45
IS 1
BP 1
EP 17
DI 10.1007/s12126-019-09356-8
PG 17
WC Gerontology
SC Geriatrics & Gerontology
GA KY8QH
UT WOS:000522840500001
DA 2021-02-24
ER

PT J
AU Kato, M
   Baese-Berk, MM
AF Kato, Misaki
   Baese-Berk, Melissa Michaud
TI The effect of input prompts on the relationship between perception and
   production of non-native sounds
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Speech perception; Speech production; Second language acquisition
ID TRAINING JAPANESE LISTENERS; R-VERTICAL-BAR; SENSORIMOTOR ADAPTATION;
   INDIVIDUAL-DIFFERENCES; SPEECH-PERCEPTION; FOREIGN-LANGUAGE; NATIVE
   SPEAKERS; CUE USE; ENGLISH; ACQUISITION
AB One factor known to affect a second language learner's pronunciation accuracy of non-native sounds is their perception accuracy of the same sounds. However, it is not clear how stable the relationship between the two modalities is when production is cued by perception or other input sources, such as orthography, which is also known to affect production of non-native sounds. We examined whether the relationship between perception and production of non-native sounds varies as a result of different types of input prompts (auditory vs. orthographic) for production, and whether this effect of input prompts on the perception -production relationship varies in different non-native sound contrasts, namely, English /.I/ vs. Ill for native Japanese learners of English, and Japanese singleton vs. geminate consonants for native English learners of Japanese. The difference in the type of input prompt for production affected learners' perception-production relationship to a larger extent for the English contrast than for the Japanese contrast. This suggests that one factor that affects the relationship between perception and production of non-native sounds is the type of input prompt for production, and that this effect can vary for different non-native contrasts. (C) 2020 Elsevier Ltd. All rights reserved.
C1 [Kato, Misaki; Baese-Berk, Melissa Michaud] 1290 Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.
RP Kato, M (corresponding author), 1290 Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.
EM misaki@uoregon.edu
FU National Science Foundation (NSF) BCS grantNational Science Foundation
   (NSF) [1734166]
FX This work was supported by National Science Foundation (NSF) BCS grant
   1734166 to MMBB. The authors would like to thank Melissa Redford,
   Charlotte Vaughn, Vsevolod Kapatsinski, Taehong Cho, and three anonymous
   reviewers for providing comments on an earlier version of this
   manuscript. We also thank Maiko Hata and Kaori Idemaru for their help
   recruiting participants, and Cydnie Davenport for her assistance with
   acoustic analysis.
CR Akamatsu N., 2006, HDB ORTHOGRAPHY LITE, P481
   Baese-Berk MM, 2016, J MEM LANG, V89, P23, DOI 10.1016/j.jml.2015.10.008
   Baese-Berk MM, 2019, ATTEN PERCEPT PSYCHO, V81, P981, DOI 10.3758/s13414-019-01725-4
   Bassetti B, 2018, LANG SPEECH, V61, P577, DOI 10.1177/0023830918780141
   Bassetti B, 2017, J EXP PSYCHOL LEARN, V43, P1835, DOI 10.1037/xlm0000417
   Bassetti B, 2015, APPL PSYCHOLINGUIST, V36, P67, DOI 10.1017/S0142716414000435
   Bassetti B, 2015, APPL PSYCHOLINGUIST, V36, P1, DOI 10.1017/S0142716414000393
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P, 2015, PRAAT DOING PHONETIC
   Bohn O.-S., 1995, SPEECH PERCEPTION LI, P279
   BOHN OS, 1990, APPL PSYCHOLINGUIST, V11, P303, DOI 10.1017/S0142716400008912
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P977, DOI 10.3758/BF03206911
   Choi J, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00624
   COWAN N, 1984, PSYCHOL BULL, V96, P341, DOI 10.1037/0033-2909.96.2.341
   Cutler A, 2006, J PHONETICS, V34, P269, DOI 10.1016/j.wocn.2005.06.002
   Davidson L, 2010, J PHONETICS, V38, P272, DOI 10.1016/j.wocn.2010.01.001
   de Jong K, 2009, J PHONETICS, V37, P357, DOI 10.1016/j.wocn.2009.06.001
   Diehl R. L., 1989, ECOL PSYCHOL, V1, P121, DOI [10.1207/s15326969-co0102_2, DOI 10.1207/S15326969-CO0102_2, DOI 10.1207/s15326969eco0102_2]
   Eckman FR, 2004, STUD SECOND LANG ACQ, V26, P513, DOI 10.1071/S027226310404001X
   Erdener VD, 2005, LANG LEARN, V55, P191, DOI 10.1111/j.0023-8333.2005.00303.x
   Escudero P, 2014, COGNITION, V133, P408, DOI 10.1016/j.cognition.2014.07.002
   Field A, 2012, DISCOVERING STAT USI
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   FLEGE JE, 1995, LANG SPEECH, V38, P25, DOI 10.1177/002383099503800102
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   FLEGE JE, 1993, J ACOUST SOC AM, V93, P1589, DOI 10.1121/1.406818
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   Goetry V, 2005, APPL PSYCHOLINGUIST, V26, P285, DOI 10.1017/S0142716405050186
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   GOTO H, 1971, NEUROPSYCHOLOGIA, V9, P317, DOI 10.1016/0028-3932(71)90027-3
   HAN MS, 1992, PHONETICA, V49, P102, DOI 10.1159/000261906
   Hanulikova A, 2012, LANG LEARN, V62, P79, DOI 10.1111/j.1467-9922.2012.00707.x
   Hao YC, 2016, J PHONETICS, V54, P151, DOI 10.1016/j.wocn.2015.10.003
   Hardison DM, 2010, APPL PSYCHOLINGUIST, V31, P81, DOI 10.1017/S0142716409990178
   HAYES R, 2002, COYOTE PAPERS, V12, P28
   Heald SLM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00035
   Hirata Y, 2005, J ACOUST SOC AM, V118, P1647, DOI 10.1121/1.2000807
   Hirata Y, 2004, J ACOUST SOC AM, V116, P2384, DOI 10.1121/1.1783351
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213
   Houde JF, 2002, J SPEECH LANG HEAR R, V45, P295, DOI 10.1044/1092-4388(2002/023)
   Idemaru K, 2010, PHONETICA, V67, P25, DOI 10.1159/000319377
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   JOHNSON K, 1993, LANGUAGE, V69, P505, DOI 10.2307/416697
   Kartushina N, 2015, J ACOUST SOC AM, V138, P817, DOI 10.1121/1.4926561
   Katz L., 1992, ORTHOGRAPHY PHONOLOG, P67, DOI DOI 10.1016/S0166-4115(08)62789-2
   Kaye A. S, 2005, ENGL TODAY, V21, P43, DOI DOI 10.1017/S0266078405002063
   Kim S, 2012, STUD SECOND LANG ACQ, V34, P415, DOI 10.1017/S0272263112000137
   Kleemans T, 2014, INT J DISABIL DEV ED, V61, P306, DOI 10.1080/1034912X.2014.934017
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Llompart M, 2019, LANG SPEECH, V62, P594, DOI 10.1177/0023830918803978
   LOGAN JS, 1991, J ACOUST SOC AM, V89, P874, DOI 10.1121/1.1894649
   Lotto A. J., 2004, SOUND SENSE 501 YEAR
   McAllister R, 2002, J PHONETICS, V30, P229, DOI 10.1006/jpho.2002.0174
   MERMELSTEIN P, 1978, PERCEPT PSYCHOPHYS, V23, P331, DOI 10.3758/BF03199717
   Minagawa Y., 1996, ANN B RES I LOGOPEDI, V30, P23
   MIYAWAKI K, 1975, PERCEPT PSYCHOPHYS, V18, P331, DOI 10.3758/BF03211209
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007
   Oh GE, 2012, J PHONETICS, V40, P82, DOI 10.1016/j.wocn.2011.08.003
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720
   Parrell Benjamin, 2011, Lab Phonol, V2, P423
   Peperkamp S., 2011, P INTERSPEECH, V12, P161
   R Core Team, 2016, R LANG ENV STAT COMP
   Rafat Y, 2015, APPL PSYCHOLINGUIST, V36, P43, DOI 10.1017/S0142716414000423
   Ramuss F., 2010, LAB PHONOLOGY, V10, P311
   Redford MA, 2015, J PHONETICS, V53, P141, DOI 10.1016/j.wocn.2015.06.006
   ROSS AD, 1981, MASS AGR EXP ST RE B, P1
   Saito K, 2012, LANG LEARN, V62, P595, DOI 10.1111/j.1467-9922.2011.00639.x
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   Schneider W., 2002, E PRIME USERS GUIDE
   SHELDON A, 1982, APPL PSYCHOLINGUIST, V3, P243, DOI 10.1017/S0142716400001417
   Shin D., 2011, P INT C PHON SCI, P1822
   Steele J., 2005, 7 REN INT RES FRANC, P2
   STRANGE W, 1984, PERCEPT PSYCHOPHYS, V36, P131, DOI 10.3758/BF03202673
   Takagi N., 1993, THESIS
   Tateishi M., 2013, THESIS
   Tsukada K, 2018, SECOND LANG RES, V34, P179, DOI 10.1177/0267658317719494
   Tyler MD, 2009, J ACOUST SOC AM, V126, P367, DOI 10.1121/1.3129127
   Umemuro H., 2004, Universal Access in the Information Society, V3, P276, DOI 10.1007/s10209-004-0098-6
   Van den Bosch Antal, 1994, J QUANT LINGUIST, V1, P178, DOI [DOI 10.1080/09296179408590015, 10.1080/09296179408590015]
   Wanrooij K, 2013, J PHONETICS, V41, P307, DOI 10.1016/j.wocn.2013.03.005
   WHALEN DH, 1989, PERCEPT PSYCHOPHYS, V46, P284, DOI 10.3758/BF03208093
   Wong JWS, 2013, INTERSPEECH, P2112
   YAMADA RA, 1992, PERCEPT PSYCHOPHYS, V52, P376, DOI 10.3758/BF03206698
   YAMADA RA, 1995, SPEECH PERCEPTION LI, P305
NR 89
TC 0
Z9 0
U1 5
U2 9
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD MAR
PY 2020
VL 79
AR 100964
DI 10.1016/j.wocn.2020.100964
PG 20
WC Linguistics; Language & Linguistics
SC Linguistics
GA KX8RQ
UT WOS:000522142400003
DA 2021-02-24
ER

PT J
AU Micheli, C
   Schepers, IM
   Ozker, M
   Yoshor, D
   Beauchamp, MS
   Rieger, JW
AF Micheli, Cristiano
   Schepers, Inga M.
   Ozker, Muge
   Yoshor, Daniel
   Beauchamp, Michael S.
   Rieger, Jochem W.
TI Electrocorticography reveals continuous auditory and visual speech
   tracking in temporal and occipital cortex
SO EUROPEAN JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE audiovisual speech; clear speech; continuous speech; multisensory;
   naturalistic stimuli
ID SURFACE-BASED ANALYSIS; AUDIOVISUAL INTERACTIONS; INVERSE EFFECTIVENESS;
   OSCILLATIONS; INTEGRATION; RESPONSES; SYNCHRONIZATION; REPRESENTATION;
   PERCEPTION; MECHANISMS
AB During natural speech perception, humans must parse temporally continuous auditory and visual speech signals into sequences of words. However, most studies of speech perception present only single words or syllables. We used electrocorticography (subdural electrodes implanted on the brains of epileptic patients) to investigate the neural mechanisms for processing continuous audiovisual speech signals consisting of individual sentences. Using partial correlation analysis, we found that posterior superior temporal gyrus (pSTG) and medial occipital cortex tracked both the auditory and the visual speech envelopes. These same regions, as well as inferior temporal cortex, responded more strongly to a dynamic video of a talking face compared to auditory speech paired with a static face. Occipital cortex and pSTG carry temporal information about both auditory and visual speech dynamics. Visual speech tracking in pSTG may be a mechanism for enhancing perception of degraded auditory speech.
C1 [Micheli, Cristiano; Schepers, Inga M.; Rieger, Jochem W.] Carl von Ossietzky Univ Oldenburg, Dept Psychol, Oldenburg, Germany.
   [Micheli, Cristiano] Radboud Univ Nijmegen, Donders Ctr Cognit Neuroimaging, Nijmegen, Netherlands.
   [Schepers, Inga M.; Rieger, Jochem W.] Carl von Ossietzky Univ Oldenburg, Res Ctr Neurosensory Sci, Oldenburg, Germany.
   [Ozker, Muge; Yoshor, Daniel; Beauchamp, Michael S.] Baylor Coll Med, Dept Neurosurg, Houston, TX 77030 USA.
   [Yoshor, Daniel] Michael E DeBakey VA Med Ctr, Houston, TX USA.
RP Micheli, C (corresponding author), Carl von Ossietzky Univ Oldenburg, Dept Psychol, Oldenburg, Germany.; Micheli, C (corresponding author), Radboud Univ Nijmegen, Donders Ctr Cognit Neuroimaging, Nijmegen, Netherlands.
EM michelic72@gmail.com
RI Beauchamp, Michael/AAK-9813-2020
OI Beauchamp, Michael/0000-0002-7599-9934; Rieger,
   Jochem/0000-0003-0955-2306; Micheli, Cristiano/0000-0002-6294-5064;
   Schepers, Inga M./0000-0001-9460-8604
FU German Research Foundation (DFG)German Research Foundation (DFG)
   [SFB/TRR 31 A16]; NIHUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01NS065395];
   Veterans Administration Clinical Science Research and Development Merit
   [1I01CX00032501A1]; Veterans AffairsUS Department of Veterans Affairs
   [I01CX000325, I01CX000325, I01CX000325] Funding Source: NIH RePORTER
FX We would like to thank Virginie van Wassenhove for helpful scientific
   discussions and Susann Br_auer for support with the video recordings.
   This research was supported by grant number SFB/TRR 31 A16 from the
   German Research Foundation (DFG) to JWR and Veterans Administration
   Clinical Science Research and Development Merit Award Number
   1I01CX00032501A1 to DY and NIH R01NS065395 to MSB.
CR Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810
   Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009
   Ashburner J, 2009, NEUROIMAGE, V45, P333, DOI 10.1016/j.neuroimage.2008.12.008
   Baba K, 2004, AUST NZ J STAT, V46, P657, DOI 10.1111/j.1467-842X.2004.00360.x
   Bastiaansen M, 2010, J COGNITIVE NEUROSCI, V22, P1333, DOI 10.1162/jocn.2009.21283
   Beauchamp MS, 2004, NEURON, V41, P809, DOI 10.1016/S0896-6273(04)00070-4
   Bernstein LE, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00386
   Besle J, 2008, J NEUROSCI, V28, P14301, DOI 10.1523/JNEUROSCI.2875-08.2008
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Chandrasekaran C, 2013, P NATL ACAD SCI USA, V110, pE4668, DOI 10.1073/pnas.1312518110
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Crosse MJ, 2016, J NEUROSCI, V36, P9888, DOI 10.1523/JNEUROSCI.1396-16.2016
   Crosse MJ, 2015, J NEUROSCI, V35, P14195, DOI 10.1523/JNEUROSCI.1829-15.2015
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   Ding N., 2014, FRONT HUM NEUROSCI, V28, P8
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Engel AK, 2010, CURR OPIN NEUROBIOL, V20, P156, DOI 10.1016/j.conb.2010.02.015
   Fedorenko E, 2014, TRENDS COGN SCI, V18, P120, DOI 10.1016/j.tics.2013.12.006
   Fischl B, 1999, NEUROIMAGE, V9, P195, DOI 10.1006/nimg.1998.0396
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Hermes D, 2010, J NEUROSCI METH, V185, P293, DOI 10.1016/j.jneumeth.2009.10.005
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Holdgraf CR, 2017, FRONT SYST NEUROSCI, V11, DOI 10.3389/fnsys.2017.00061
   Holdgraf CR, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13654
   Jensen O, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00186
   Lachaux JP, 2012, PROG NEUROBIOL, V98, P279, DOI 10.1016/j.pneurobio.2012.06.008
   Lee H, 2011, J NEUROSCI, V31, P11338, DOI 10.1523/JNEUROSCI.6510-10.2011
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mercier MR, 2013, NEUROIMAGE, V79, P19, DOI 10.1016/j.neuroimage.2013.04.060
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Micheli C, 2015, NEUROIMAGE, V119, P417, DOI 10.1016/j.neuroimage.2015.06.043
   Mukamel R, 2005, SCIENCE, V309, P951, DOI 10.1126/science.1110913
   Murray MM, 2016, NEUROPSYCHOLOGIA, V83, P161, DOI 10.1016/j.neuropsychologia.2015.08.011
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Nath AR, 2011, J NEUROSCI, V31, P1704, DOI 10.1523/JNEUROSCI.4853-10.2011
   Noesselt T, 2007, J NEUROSCI, V27, P11431, DOI 10.1523/JNEUROSCI.2252-07.2007
   O'Sullivan AE, 2017, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00679
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Ozker M, 2017, J COGNITIVE NEUROSCI, V29, P1044, DOI 10.1162/jocn_a_01110
   Park H, 2016, ELIFE, V5, DOI 10.7554/eLife.14521
   Peelle JE, 2015, CORTEX, V68, P169, DOI 10.1016/j.cortex.2015.03.006
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Quandt F, 2012, NEUROIMAGE, V59, P3316, DOI 10.1016/j.neuroimage.2011.11.053
   Ray S, 2011, PLOS BIOL, V9, DOI 10.1371/journal.pbio.1000610
   Rhone AE, 2016, LANG COGN NEUROSCI, V31, P284, DOI 10.1080/23273798.2015.1101145
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Scheeringa R, 2016, P NATL ACAD SCI USA, V113, P6761, DOI 10.1073/pnas.1522577113
   Schepers IM, 2015, CEREB CORTEX, V25, P4103, DOI 10.1093/cercor/bhu127
   Schepers IM, 2013, NEUROIMAGE, V70, P101, DOI 10.1016/j.neuroimage.2012.11.066
   Schroeder CE, 2008, TRENDS COGN SCI, V12, P106, DOI 10.1016/j.tics.2008.01.002
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Siegel M, 2008, NEURON, V60, P709, DOI 10.1016/j.neuron.2008.09.010
   Skeide MA, 2016, NAT REV NEUROSCI, V17, P323, DOI 10.1038/nrn.2016.23
   Spitzer B, 2017, ENEURO, V4, DOI 10.1523/ENEURO.0170-17.2017
   Stein BE, 2008, NAT REV NEUROSCI, V9, P255, DOI 10.1038/nrn2331
   Stevenson RA, 2009, NEUROIMAGE, V44, P1210, DOI 10.1016/j.neuroimage.2008.09.034
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   THOMSON DJ, 1982, P IEEE, V70, P1055, DOI 10.1109/PROC.1982.12433
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Uno T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0122580
   van Kerkoerle T, 2014, P NATL ACAD SCI USA, V111, P14332, DOI 10.1073/pnas.1402773111
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Varela F, 2001, NAT REV NEUROSCI, V2, P229, DOI 10.1038/35067550
   Wang L, 2012, HUM BRAIN MAPP, V33, P2898, DOI 10.1002/hbm.21410
   Whittingstall K, 2009, NEURON, V64, P281, DOI 10.1016/j.neuron.2009.08.016
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Ye Z, 2017, NEUROSCIENCE, V356, P1, DOI 10.1016/j.neuroscience.2017.05.017
   Zhu LL, 2017, J NEUROSCI, V37, P2697, DOI 10.1523/JNEUROSCI.2914-16.2017
NR 72
TC 4
Z9 4
U1 1
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0953-816X
EI 1460-9568
J9 EUR J NEUROSCI
JI Eur. J. Neurosci.
PD MAR
PY 2020
VL 51
IS 5
BP 1364
EP 1376
DI 10.1111/ejn.13992
PG 13
WC Neurosciences
SC Neurosciences & Neurology
GA KV6TO
UT WOS:000520615000020
PM 29888819
DA 2021-02-24
ER

PT J
AU Kaufeld, G
   Ravenschlag, A
   Meyer, AS
   Martin, AE
   Bosker, HR
AF Kaufeld, Greta
   Ravenschlag, Anna
   Meyer, Antje S.
   Martin, Andrea E.
   Bosker, Hans Rutger
TI Knowledge-Based and Signal-Based Cues Are Weighted Flexibly During
   Spoken Language Comprehension
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION
LA English
DT Article
DE language comprehension; speech perception; cue integration; rate
   normalization
ID SPEECH RATE; PREDICTION; CONTEXT; WORDS; INTEGRATION; PERCEPTION;
   AGREEMENT; GENDER; TIME; SEGMENTATION
AB During spoken language comprehension, listeners make use of both knowledge-based and signal-based sources of information, but little is known about how cues from these distinct levels of representational hierarchy are weighted and integrated online. In an eye-tracking experiment using the visual world paradigm, we investigated the flexible weighting and integration of morphosyntactic gender marking (a knowledge-based cue) and contextual speech rate (a signal-based cue). We observed that participants used the morphosyntactic cue immediately to make predictions about upcoming referents, even in the presence of uncertainty about the cue's reliability. Moreover, we found speech rate normalization effects in participants' gaze patterns even in the presence of preceding morphosyntactic information. These results demonstrate that cues are weighted and integrated flexibly online, rather than adhering to a strict hierarchy. We further found rate normalization effects in the looking behavior of participants who showed a strong behavioral preference for the morphosyntactic gender cue. This indicates that rate normalization effects are robust and potentially automatic. We discuss these results in light of theories of cue integration and the two-stage model of acoustic context effects.
C1 [Kaufeld, Greta; Ravenschlag, Anna; Meyer, Antje S.; Martin, Andrea E.; Bosker, Hans Rutger] Max Planck Inst Psycholinguist, POB 310, NL-6500 AH Nijmegen, Netherlands.
   [Kaufeld, Greta] Int Max Planck Res Sch Language Sci, Nijmegen, Netherlands.
   [Meyer, Antje S.] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
RP Kaufeld, G; Bosker, HR (corresponding author), Max Planck Inst Psycholinguist, POB 310, NL-6500 AH Nijmegen, Netherlands.
EM greta.kaufeld@mpi.nl; hansrutger.bosker@mpi.nl
OI Kaufeld, Greta/0000-0003-0470-442X
CR Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   Dunabeitia JA, 2018, Q J EXP PSYCHOL, V71, P808, DOI 10.1080/17470218.2017.1310261
   Audacity Team, 2019, AUD R FREE AUD ED RE
   Baese-Berk MM, 2019, ATTEN PERCEPT PSYCHO, V81, P571, DOI 10.3758/s13414-018-1626-4
   Boersma Paul, 2012, PRAAT DOING PHONETIC
   Bosker HR, 2018, LANG COGN NEUROSCI, V33, P955, DOI 10.1080/23273798.2018.1439179
   Bosker HR, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01063
   Bosker HR, 2017, J MEM LANG, V94, P166, DOI 10.1016/j.jml.2016.12.002
   Bosker HR, 2017, ATTEN PERCEPT PSYCHO, V79, P333, DOI 10.3758/s13414-016-1206-4
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   Escudero P, 2009, J PHONETICS, V37, P452, DOI 10.1016/j.wocn.2009.07.006
   Fetsch CR, 2013, NAT REV NEUROSCI, V14, P429, DOI 10.1038/nrn3503
   GORDON PC, 1988, PERCEPT PSYCHOPHYS, V43, P137, DOI 10.3758/BF03214191
   Guerra E., 2018, AMLAP C ARCH MECH LA
   Heffner CC, 2015, J SPEECH LANG HEAR R, V58, P1341, DOI 10.1044/2015_JSLHR-H-14-0239
   Huettig F, 2019, BRAIN RES, V1706, P196, DOI 10.1016/j.brainres.2018.11.013
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Kochari AR, 2019, LANG COGN NEUROSCI, V34, P239, DOI 10.1080/23273798.2018.1524500
   LISKER L, 1967, LANG SPEECH, V10, P1, DOI 10.1177/002383096701000101
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   Martin AE, 2017, LANG SPEECH, V60, P356, DOI 10.1177/0023830916650714
   Martin AE, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00120
   Maslowski M, 2019, J EXP PSYCHOL LEARN, V45, P128, DOI 10.1037/xlm0000579
   MATIN E, 1993, PERCEPT PSYCHOPHYS, V53, P372, DOI 10.3758/BF03206780
   Mattys SL, 2005, J EXP PSYCHOL GEN, V134, P477, DOI 10.1037/0096-3445.134.4.477
   Mattys SL, 2007, J EXP PSYCHOL HUMAN, V33, P960, DOI 10.1037/0096-1523.33.4.960
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   McQueen JM, 1998, J MEM LANG, V39, P21, DOI 10.1006/jmla.1998.2568
   Mitterer H, 2018, LAB PHONOL, V9, DOI 10.5334/labphon.66
   Morrill T, 2015, PSYCHON B REV, V22, P1451, DOI 10.3758/s13423-015-0820-9
   Nieuwland MS, 2018, ELIFE, V7, DOI 10.7554/eLife.33468
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   R Core Team, 2012, R LANG ENV STAT COMP
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   Reinisch E, 2011, J EXP PSYCHOL HUMAN, V37, P978, DOI 10.1037/a0021923
   Schanz S. J., 2012, Society for Neuroscience Abstract Viewer and Itinerary Planner, V42
   Szewczyk JM, 2013, J MEM LANG, V68, P297, DOI 10.1016/j.jml.2012.12.002
   Toscano JC, 2015, LANG COGN NEUROSCI, V30, P529, DOI 10.1080/23273798.2014.946427
   Tuinman A, 2014, LANG SPEECH, V57, P68, DOI 10.1177/0023830913479106
   van Bergen G, 2018, J MEM LANG, V103, P191, DOI 10.1016/j.jml.2018.08.004
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443
   Wade T, 2005, PERCEPT PSYCHOPHYS, V67, P939, DOI 10.3758/BF03193621
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487
   Wicha NYY, 2003, NEUROSCI LETT, V346, P165, DOI 10.1016/S0304-3940(03)00599-8
NR 47
TC 10
Z9 10
U1 11
U2 15
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0278-7393
EI 1939-1285
J9 J EXP PSYCHOL LEARN
JI J. Exp. Psychol.-Learn. Mem. Cogn.
PD MAR
PY 2020
VL 46
IS 3
BP 549
EP 562
DI 10.1037/xlm0000744
PG 14
WC Psychology; Psychology, Experimental
SC Psychology
GA KQ1TC
UT WOS:000516711500012
PM 31343252
OA Green Published
DA 2021-02-24
ER

PT J
AU Yuan, Y
   Wayland, R
   Oh, Y
AF Yuan, Yi
   Wayland, Ratree
   Oh, Yonghee
TI Visual analog of the acoustic amplitude envelope benefits speech
   perception in noise
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID AUDIOVISUAL SPEECH; CUES
AB The nature of the visual input that integrates with the audio signal to yield speech processing advantages remains controversial. This study tests the hypothesis that the information extracted for audiovisual integration includes co-occurring suprasegmental dynamic changes in the acoustic and visual signal. English sentences embedded in multi-talker babble noise were presented to native English listeners in audio-only and audiovisual modalities. A significant intelligibility enhancement with the visual analogs congruent to the acoustic amplitude envelopes was observed. These results suggest that dynamic visual modulation provides speech rhythmic information that can be integrated online with the audio signal to enhance speech intelligibility. (C) 2020 Acoustical Society of America
C1 [Yuan, Yi; Oh, Yonghee] Univ Florida, Dept Speech Language & Hearing Sci, Gainesville, FL 32610 USA.
   [Wayland, Ratree] Univ Florida, Dept Linguist, Gainesville, FL 32611 USA.
RP Yuan, Y (corresponding author), Univ Florida, Dept Speech Language & Hearing Sci, Gainesville, FL 32610 USA.
EM yiyuan56@ufl.edu; ratree@ufl.edu; yoh@phhp.ufl.edu
RI Oh, Yonghee/AAC-3302-2021
CR Alm M, 2015, FRONT PSYCHOL, V6, DOI [10.3389/fpsyg.2015.01014, 10.3389/fpgyg.2015.01014]
   Alsius A, 2016, ATTEN PERCEPT PSYCHO, V78, P1472, DOI 10.3758/s13414-016-1109-4
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bernstein L. E., 2003, INT C AUD VIS SPEECH
   Bernstein LE, 2004, SPEECH COMMUN, V44, P5, DOI 10.1016/j.specom.2004.10.011
   Berthommier F, 2004, SPEECH COMMUN, V44, P31, DOI 10.1016/j.specom.2004.10.003
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155
   Crosse MJ, 2016, J NEUROSCI, V36, P9888, DOI 10.1523/JNEUROSCI.1396-16.2016
   Diehl R. L., 1989, ECOL PSYCHOL, V1, P121, DOI [10.1207/s15326969-co0102_2, DOI 10.1207/S15326969-CO0102_2, DOI 10.1207/s15326969eco0102_2]
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Grant KW, 2001, J ACOUST SOC AM, V109, P2272, DOI 10.1121/1.1362687
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   HELFER KS, 1990, J SPEECH HEAR RES, V33, P149, DOI 10.1044/jshr.3301.149
   Hollich G, 2005, CHILD DEV, V76, P598, DOI 10.1111/j.1467-8624.2005.00866.x
   IEEE, 1969, IEEE REC PRACT SPEEC
   Jaekl P, 2015, NEUROPSYCHOLOGIA, V75, P402, DOI 10.1016/j.neuropsychologia.2015.06.025
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Pichora-Fuller M Kathleen, 2006, Trends Amplif, V10, P29, DOI 10.1177/108471380601000103
   R Core Team, 2014, R LANG ENV STAT COMP
   RABBITT PMA, 1968, Q J EXP PSYCHOL, V20, P241, DOI 10.1080/14640746808400158
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1992, PHILOS T ROY SOC B, V335, P71, DOI 10.1098/rstb.1992.0009
   Yehia HC, 2002, J PHONETICS, V30, P555, DOI 10.1006/jpho.2002.0165
NR 27
TC 1
Z9 1
U1 0
U2 2
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD MAR
PY 2020
VL 147
IS 3
BP EL246
EP EL251
DI 10.1121/10.0000737
PG 6
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA KU7OB
UT WOS:000519901400002
PM 32237828
OA Bronze
DA 2021-02-24
ER

PT J
AU Moossavi, A
   Lotfi, Y
   Javanbakht, M
   Faghihzadeh, S
AF Moossavi, Abdollah
   Lotfi, Yones
   Javanbakht, Mohanna
   Faghihzadeh, Soghrat
TI Speech-evoked auditory brainstem response; electrophysiological evidence
   of upper brainstem facilitative role on sound lateralization in noise
SO NEUROLOGICAL SCIENCES
LA English
DT Article
DE Sound lateralization; Speech-evoked auditory brainstem response; Noise;
   Auditory efferent system
ID INFERIOR COLLICULUS; LOCALIZATION; PERCEPTION; ABR
AB Background and aim Sound lateralization/localization is one of the most important auditory processing abilities, which plays approved role in auditory streaming and speech perception in challenging situations like noisy places. In addition to the main role of lower brainstem centers like superior olivary complex in sound lateralization, efferent auditory system effects on improving auditory skills in everyday auditory challenging positions were revealed. This study evaluated noise effects on lateralization scores in correlation with an objective electrophysiologic test (Speech-ABR in noise), which objectively shows cumulative effects of the afferent and efferent auditory systems at the inferior colliculus and upper brainstem pathway. Method Fourteen normal-hearing subjects in the age range of 18 to 25 participated in this study. Lateralization scores in the quiet and noisy modes were evaluated. Speech-ABR in both ears for quiet mode and three different contralateral noise levels (SNR = + 5, 0, - 5) were recorded, too. Correlation of lateralization scores and Speech-ABR changes in noise was studied. Results Significant decrease of lateralization scores with latency increase and amplitude decrease of Speech-ABR transient peaks (V, A, O) was seen with noise presentation. A high positive correlation between lateralization decrease with latency increase of onset peaks (V, A) and amplitude decrease of transient peaks (V, A, O) was found in low signal-to-noise ratios. Conclusion The study revealed that in high challenging auditory situations like auditory lateralization in noise, upper brainstem centers and pathways play a facilitative role for main auditory lateralization centers in lower levels.
C1 [Moossavi, Abdollah] Iran Univ Med Sci, Sch Med, Dept Otolaryngol, Tehran, Iran.
   [Lotfi, Yones; Javanbakht, Mohanna] Univ Social Welf & Rehabil Sci, Dept Audiol, Tehran, Iran.
   [Faghihzadeh, Soghrat] Zanjan Univ Med Sci, Dept Biostat & Epidemiol, Zanjan, Iran.
RP Javanbakht, M (corresponding author), Univ Social Welf & Rehabil Sci, Dept Audiol, Tehran, Iran.
EM amoossavi@gmail.com; Yones1333@gmail.com; m.javanbakht@yahoo.com;
   s.faghihzadeh@zums.ac.ir
RI Javanbakht, Mohanna/AAK-6445-2020
OI Javanbakht, Mohanna/0000-0002-2876-3208; lotfi,
   yones/0000-0001-8563-312X
CR Andeol G, 2013, HEARING RES, V304, P20, DOI 10.1016/j.heares.2013.06.001
   Andeol G, 2011, J NEUROSCI, V31, P6759, DOI 10.1523/JNEUROSCI.0248-11.2011
   Anderson S, 2011, EAR HEARING, V32, P750, DOI 10.1097/AUD.0b013e31822229d3
   Anderson Samira, 2011, Seminars in Hearing, V32, P129, DOI 10.1055/s-0031-1277234
   Anderson S, 2010, HEARING RES, V270, P151, DOI 10.1016/j.heares.2010.08.001
   Banai K, 2005, J NEUROSCI, V25, P9850, DOI 10.1523/JNEUROSCI.2373-05.2005
   Banai K, 2008, CURRENT CONTROVERSIE, P269
   Banai K, 2007, INT J AUDIOL, V46, P524, DOI 10.1080/14992020701383035
   Bronkhorst AW, 2015, ATTEN PERCEPT PSYCHO, V77, P1465, DOI 10.3758/s13414-015-0882-9
   Burger RM, 2001, J NEUROSCI, V21, P4830, DOI 10.1523/JNEUROSCI.21-13-04830.2001
   Burkard R.F., 2007, AUDITORY EVOKED POTE
   Chandrasekaran B, 2009, NEURON, V64, P311, DOI 10.1016/j.neuron.2009.10.006
   Cunningham J, 2002, HEARING RES, V169, P97, DOI 10.1016/S0378-5955(02)00344-1
   Dunn C, 2018, QUEENSHIP POWER, P1, DOI 10.1007/978-3-319-75877-0_1
   Hall J.W., 2007, NEW HDB AUDITORY EVO
   JEFFRESS LA, 1948, J COMP PHYSIOL PSYCH, V41, P35, DOI 10.1037/h0061495
   Johnson KL, 2005, EAR HEARING, V26, P424, DOI 10.1097/01.aud.0000179687.71662.6e
   Kraus N., 2013, AUDITORY PROCESSING, V2, P159
   Kraus N, 2011, PHYS TODAY, V64, P40, DOI 10.1063/1.3603917
   Krizman J, 2014, BRAIN LANG, V128, P34, DOI 10.1016/j.bandl.2013.11.006
   Krizman J, 2012, P NATL ACAD SCI USA, V109, P7877, DOI 10.1073/pnas.1201575109
   Laroche C, 1994, CAN ACOUST, V22, P13
   Lewald J, 2018, HEAR RES
   Lotfi Y, 2019, MED HYPOTHESES, V132, DOI 10.1016/j.mehy.2019.109355
   Lotfi Y, 2016, J AUDIOL OTOL, V20, P102, DOI 10.7874/jao.2016.20.2.102
   MASTERTON RB, 1968, J NEUROPHYSIOL, V31, P96
   Moosavi A, 2014, IRJ, V12, P31
   Parbery-Clark A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018082
   Pickles J, 2013, INTRO PHYSL HEARING
   Pickles JO, 2008, INTRO PHYSL HEARING, P153
   Ramezani M, 2019, NEUROL SCI, V40, P121, DOI 10.1007/s10072-018-3594-9
   Roman N, 2003, J ACOUST SOC AM, V114, P2236, DOI 10.1121/1.1610463
   Russo N, 2004, CLIN NEUROPHYSIOL, V115, P2021, DOI 10.1016/j.clinph.2004.04.003
   Russo NM, 2008, CLIN NEUROPHYSIOL, V119, P1720, DOI 10.1016/j.clinph.2008.01.108
   Ryugo DK, 2011, SPRINGER HANDB AUDIT, V38, P1, DOI 10.1007/978-1-4419-7070-1_1
   Sanfins MD, 2017, BRAZ J OTORHINOLAR, V83, P112, DOI 10.1016/j.bjorl.2015.05.014
   Schnupp J., 2011, AUDITORY NEUROSCIENC
   Skoe E, 2017, NEUROSCIENCE, V349, P278, DOI 10.1016/j.neuroscience.2017.02.049
   Skoe E, 2015, CEREB CORTEX, V25, P1415, DOI 10.1093/cercor/bht311
   Skoe E, 2014, HEARING RES, V311, P36, DOI 10.1016/j.heares.2014.01.002
   Skoe E, 2010, EAR HEARING, V31, P302, DOI 10.1097/AUD.0b013e3181cdb272
   Strait DL, 2013, DEV COGN NEUROS-NETH, V6, P51, DOI 10.1016/j.dcn.2013.06.003
   Zakaria MN, 2016, NEUROL SCI, V37, P943, DOI 10.1007/s10072-016-2522-0
   Zhu MC, 2017, NEUROL SCI, V38, P1617, DOI 10.1007/s10072-017-3013-7
NR 44
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER-VERLAG ITALIA SRL
PI MILAN
PA VIA DECEMBRIO, 28, MILAN, 20137, ITALY
SN 1590-1874
EI 1590-3478
J9 NEUROL SCI
JI Neurol. Sci.
PD MAR
PY 2020
VL 41
IS 3
BP 611
EP 617
DI 10.1007/s10072-019-04102-z
PG 7
WC Clinical Neurology; Neurosciences
SC Neurosciences & Neurology
GA KT9ZJ
UT WOS:000519371600014
PM 31732889
DA 2021-02-24
ER

PT J
AU Houweling, T
   Becker, R
   Hervais-Adelman, A
AF Houweling, Thomas
   Becker, Robert
   Hervais-Adelman, Alexis
TI The noise-resilient brain: Resting-state oscillatory activity predicts
   words-in-noise recognition
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Resting-state; MEG; Speech perception; Words-in-noise; Oscillations;
   Power; Rapid auditory processing; Phoneme; STG; HCP
ID SPEECH RECOGNITION; HEARING IMPAIRMENT; PERCEPTION; CHILDREN;
   INTELLIGIBILITY; CONNECTIVITY; VARIABILITY; THRESHOLD; FREQUENCY;
   LANGUAGE
AB The role of neuronal oscillations in the processing of speech has recently come to prominence. Since resting-state (RS) brain activity has been shown to predict both task-related brain activation and behavioural performance, we set out to establish whether inter-individual differences in spectrally-resolved RS-MEG power are associated with variations in words-in-noise recognition in a sample of 88 participants made available by the Human Connectome Project. Positive associations with resilience to noise were observed with power in the range 21 and 29 Hz in a number of areas along the left temporal gyrus and temporo-parietal association areas peaking in left posterior superior temporal gyrus (pSTG). Significant associations were also found in the right posterior superior temporal gyrus in the frequency range 30-40 Hz. We propose that individual differences in words-in-noise performance are related to baseline excitability levels of the neural substrates of phonological processing.
C1 [Houweling, Thomas; Becker, Robert; Hervais-Adelman, Alexis] Univ Zurich, Dept Psychol, Neurolinguist, Binzmuhlestr 14,Box 5, CH-8050 Zurich, Switzerland.
RP Houweling, T (corresponding author), Univ Zurich, Dept Psychol, Neurolinguist, Binzmuhlestr 14,Box 5, CH-8050 Zurich, Switzerland.
EM thomas.houweling@uzh.ch
RI Hervais-Adelman, Alexis/P-7053-2019
OI Hervais-Adelman, Alexis/0000-0002-5232-626X
FU Swiss National Science FoundationSwiss National Science Foundation
   (SNSF)European Commission [PP_163726]
FX Research funded by the Swiss National Science Foundation (grant
   PP_163726 awarded to A.H-A).
CR Ashtari M, 2004, NEUROREPORT, V15, P389, DOI 10.1097/00001756-200403010-00001
   Baltus A, 2015, INT J PSYCHOPHYSIOL, V98, P1, DOI 10.1016/j.ijpsycho.2015.08.003
   Biswal BB, 2010, P NATL ACAD SCI USA, V107, P4734, DOI 10.1073/pnas.0911855107
   Blandy S, 2005, INT J AUDIOL, V44, P435, DOI 10.1080/14992020500189203
   Buzsaki G, 2004, SCIENCE, V304, P1926, DOI 10.1126/science.1099745
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Chobert J, 2012, NEUROPSYCHOLOGIA, V50, P2044, DOI 10.1016/j.neuropsychologia.2012.05.004
   Ciorba A, 2012, CLIN INTERV AGING, V7, P159, DOI 10.2147/CIA.S26059
   Cole MW, 2016, NAT NEUROSCI, V19, P1718, DOI 10.1038/nn.4406
   Dawes P, 2014, JARO-J ASSOC RES OTO, V15, P663, DOI 10.1007/s10162-014-0461-0
   DELATTRE PC, 1955, J ACOUST SOC AM, V27, P769, DOI 10.1121/1.1908024
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   DUBNO JR, 1984, J ACOUST SOC AM, V76, P87, DOI 10.1121/1.391011
   Dunn J.C., 1973, J CYBERNETICS, V3, P32, DOI [10.1080/01969727308546046, DOI 10.1080/01969727308546046]
   DUQUESNOY AJ, 1983, J ACOUST SOC AM, V74, P739, DOI 10.1121/1.389859
   FINDLAY RC, 1976, J SPEECH HEAR DISORD, V41, P374, DOI 10.1044/jshd.4103.374
   Fox MD, 2006, NAT NEUROSCI, V9, P23, DOI 10.1038/nn1616
   Fox MD, 2007, NEURON, V56, P171, DOI 10.1016/j.neuron.2007.08.023
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Frisina DR, 1997, HEARING RES, V106, P95, DOI 10.1016/S0378-5955(97)00006-3
   Fullgrabe C, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01268
   Gaab N, 2007, RESTOR NEUROL NEUROS, V25, P295
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Hancock R, 2017, TRENDS COGN SCI, V21, P434, DOI 10.1016/j.tics.2017.03.008
   Helfrich RF, 2014, CURR BIOL, V24, P333, DOI 10.1016/j.cub.2013.12.041
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   HUMES LE, 1994, J SPEECH HEAR RES, V37, P465, DOI 10.1044/jshr.3702.465
   Jerger J, 1992, J Am Acad Audiol, V3, P33
   KEWLEYPORT D, 1982, J ACOUST SOC AM, V72, P379, DOI 10.1121/1.388081
   Lakatos P, 2005, J NEUROPHYSIOL, V94, P1904, DOI 10.1152/jn.00263.2005
   Lehongre K, 2011, NEURON, V72, P1080, DOI 10.1016/j.neuron.2011.11.002
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Liebenthal E, 2005, CEREB CORTEX, V15, P1621, DOI 10.1093/cercor/bhi040
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   LUTMAN ME, 1991, ACTA OTO-LARYNGOL, P239
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Mennes M, 2011, NEUROIMAGE, V54, P2950, DOI 10.1016/j.neuroimage.2010.10.046
   Mennes M, 2010, NEUROIMAGE, V50, P1690, DOI 10.1016/j.neuroimage.2010.01.002
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   PLOMP R, 1986, J SPEECH HEAR RES, V29, P146, DOI 10.1044/jshr.2902.146
   PLOMP R, 1978, J ACOUST SOC AM, V63, P533, DOI 10.1121/1.381753
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Poeppel D, 2001, COGNITIVE SCI, V25, P679, DOI 10.1016/S0364-0213(01)00050-7
   Raschle NM, 2014, CEREB CORTEX, V24, P2489, DOI 10.1093/cercor/bht104
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Rosenberg MD, 2016, NAT NEUROSCI, V19, P165, DOI 10.1038/nn.4179
   Ross B, 2005, CEREB CORTEX, V15, P2029, DOI 10.1093/cercor/bhi078
   Rouleau N, 1996, J GERONTOL B-PSYCHOL, V51, pP356, DOI 10.1093/geronb/51B.6.P356
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Rufener KS, 2019, BRAIN STIMUL, V12, P930, DOI 10.1016/j.brs.2019.02.007
   Rufener KS, 2016, BRAIN STIMUL, V9, P562, DOI 10.1016/j.brs.2016.04.002
   Rufener KS, 2016, INT J PSYCHOPHYSIOL, V101, P18, DOI 10.1016/j.ijpsycho.2016.01.002
   Smith SM, 2015, NAT NEUROSCI, V18, P1565, DOI 10.1038/nn.4125
   Snowling M., 1998, CHILD ADOL MENT H-UK, V3, P4, DOI [10.1111/1475-3588.00201, DOI 10.1111/1475-3588.00201]
   Specht K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00549
   Sperry J L, 1997, J Am Acad Audiol, V8, P71
   Tavor I, 2016, SCIENCE, V352, P216, DOI 10.1126/science.aad8127
   TSCHOPP K, 1994, SCAND AUDIOL, V23, P241, DOI 10.3109/01050399409047515
   Turkeltaub PE, 2010, BRAIN LANG, V114, P1, DOI 10.1016/j.bandl.2010.03.008
   Van Den Heuvel MP, 2011, PSIQUIATR BIOL, V18, P28, DOI [10.1016/j.psiq.2011.05.001, DOI 10.1016/J.PSIQ.2011.05.001]
   Van Essen DC, 2013, NEUROIMAGE, V80, P62, DOI 10.1016/j.neuroimage.2013.05.041
   Vermiglio AJ, 2012, J AM ACAD AUDIOL, V23, P779, DOI 10.3766/jaaa.23.10.4
   Voytek B, 2015, J NEUROSCI, V35, P13257, DOI 10.1523/JNEUROSCI.2332-14.2015
   WEINSTEIN BE, 1982, J SPEECH HEAR RES, V25, P593, DOI 10.1044/jshr.2504.593
   Wilson RH, 2007, J AM ACAD AUDIOL, V18, P522
   Wilson Richard H, 2005, J Am Acad Audiol, V16, P622, DOI 10.3766/jaaa.16.8.11
   Wilson Richard H, 2003, J Am Acad Audiol, V14, P453
   Winkler AM, 2015, NEUROIMAGE, V123, P253, DOI 10.1016/j.neuroimage.2015.05.092
   WU-Minn Consortium Human Connectome Project, 2017, WU MINN HCP 1200 SUB
   Zekveld AA, 2013, J ACOUST SOC AM, V134, P2225, DOI 10.1121/1.4817926
NR 74
TC 0
Z9 0
U1 1
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD MAR
PY 2020
VL 202
AR 104727
DI 10.1016/j.bandl.2019.104727
PG 9
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA KM6AH
UT WOS:000514220400004
PM 31918321
OA Green Accepted, Green Published
DA 2021-02-24
ER

PT J
AU Kim, JY
AF Kim, Ji Young
TI Discrepancy between heritage speakers' use of suprasegmental cues in the
   perception and production of Spanish lexical stress
SO BILINGUALISM-LANGUAGE AND COGNITION
LA English
DT Article
DE heritage speakers; heritage language phonology; lexical stress;
   Spanish-English bilingualism; Spanish prosody; speech perception and
   production
ID SPEECH-PERCEPTION; FLUENCY CHARACTERISTICS; LEARNING INFANTS; ENGLISH;
   LANGUAGE; PROSODY; FRENCH; EXPERIENCE; LEARNERS; DISCRIMINATION
AB This study investigates Spanish heritage speakers' perception and production of Spanish lexical stress. Stress minimal pairs in various prosodic contexts were used to examine whether heritage speakers successfully identify the stress location despite varying suprasegmental cues (Experiment 1) and whether they use these cues in their production (Experiment 2). Heritage speakers' performance was compared to that of Spanish monolinguals and English L2 learners. In Experiment 1, the heritage speakers showed a clear advantage over the L2 learners and their performance was comparable to that of the monolinguals. In Experiment 2, both the heritage speakers and the L2 learners showed deviating patterns from the monolinguals; they produced a large overlap between paroxytones and oxytones, especially in duration. The discrepancy between heritage speakers' perception and production suggests that, while early exposure to heritage language is beneficial for the perception of heritage language speech sounds, this factor alone does not guarantee target-like production.
C1 [Kim, Ji Young] Univ Calif Los Angeles, Dept Spanish & Portuguese, Los Angeles, CA 90095 USA.
RP Kim, JY (corresponding author), Univ Calif Los Angeles, Dept Spanish & Portuguese, Los Angeles, CA 90095 USA.
EM jiyoungkim@ucla.edu
OI Kim, Ji Young/0000-0002-5708-6461
FU National Science FoundationNational Science Foundation (NSF)
   [BCS-1424329]
FX I would like to express my deepest appreciation to Jose Ignacio Hualde
   for his invaluable feedback, as well as the anonymous reviewers for
   their helpful comments and suggestions. I would also like to thank
   Eduardo Velazquez for his help and support in the data collection in
   Mexico and all my participants who not only willingly participated in
   the study, but also provided me with fresh new insights on heritage
   speakers. This research was supported by a grant from the National
   Science Foundation (BCS-1424329).
CR Abercrombie David, 1967, ELEMENTS GEN PHONETI
   Adam G, 2007, LANG ACQUIS, P12
   ADAMS C, 1979, ENGLISH SPEECH RHYTH
   Allen G., 1980, CHILD PHONOLOGY, P227, DOI DOI 10.1016/B978-0-12-770601-6.50017-6
   Allen George D., 1978, SYLLABLES SEGMENTS, P173
   [Anonymous], 2017, NATURAL GAS WORLD, V2, P29
   [Anonymous], 2015, LIVELY DISCUSSION J, V6, P30
   Arciuli J, 2017, J CHILD LANG, V44, P1274, DOI 10.1017/S0305000916000489
   Au TKF, 2008, J MEM LANG, V58, P998, DOI 10.1016/j.jml.2007.11.001
   Baker G. K., 2006, NEW PERSPECTIVES ROM, VII, P1, DOI DOI 10.1075/CILT.276.02BAK
   Ballard KJ, 2012, J SPEECH LANG HEAR R, V55, P1822, DOI 10.1044/1092-4388(2012/11-0257)
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beaudrie S.M., 2005, HERITAGE LANGUAGE J, V3, P1
   Beckman M. E., 1994, PHONOLOGICAL STRUCTU, P7, DOI DOI 10.1017/CBO9780511659461.002
   Boersma P, 2015, PRAAT DOING PHONETIC
   Campbell HJ, 1997, ENVIRONMENTAL ENGINEERING EDUCATION, P67
   Campbell R.N., 2000, HDB UNDERGRADUATE 2, P165
   Chang C, 2008, 44 ANN M CHIC LING S, P31
   Chang Charles, 2016, HERITAGE LANGUAGE J, V13, P134
   Chang CB, 2016, BILING-LANG COGN, V19, P791, DOI 10.1017/S1366728914000261
   Clopper C. G., 2002, PAPERS, V2, P1, DOI DOI 10.1044/1059-0889(2002/er01)
   Cooper N, 2002, LANG SPEECH, V45, P207, DOI 10.1177/00238309020450030101
   Curtin S, 2010, J EXP CHILD PSYCHOL, V105, P376, DOI 10.1016/j.jecp.2009.12.004
   Curtin S, 2009, J CHILD LANG, V36, P1157, DOI 10.1017/S0305000909009428
   CUTLER A, 1986, J MEM LANG, V25, P385, DOI 10.1016/0749-596X(86)90033-1
   CUTLER A, 1986, LANG SPEECH, V29, P201, DOI 10.1177/002383098602900302
   Cutler A, 2012, NATIVE LISTENING LAN
   D'Imperio M, 2005, PHONOL PHONET, V9, P59, DOI 10.1515/9783110197587.1.59
   Davis BL, 2000, CHILD DEV, V71, P1258, DOI 10.1111/1467-8624.00227
   DEBOYSSONBARDIES B, 1993, NATO ADV SCI INST SE, V69, P353
   DELATTRE P, 1966, IRAL-INT REV APPL LI, V4, P183, DOI 10.1515/iral.1966.4.1-4.183
   Echols C., 1992, LANG ACQUIS, V2, P189, DOI DOI 10.1207/S153278171A0203_1
   Echols CH, 1997, J MEM LANG, V36, P202, DOI 10.1006/jmla.1996.2483
   Estebas-Vilaplana E., 2007, ATLANTIS, V29, P39
   FEAR BD, 1995, J ACOUST SOC AM, V97, P1893, DOI 10.1121/1.412063
   Fuller JM, 2012, BILINGUAL PRETEENS C
   GERKEN L, 1994, J CHILD LANG, V21, P565, DOI 10.1017/S0305000900009466
   Godson L., 2004, HERITAGE LANGUAGE J, V2, P1
   Goldman J, 2011, P 12 ANN C INT SPEEC
   Gonzalez J., 2007, SAPIENS, V8, P123
   HAKUTA K, 1992, APPL LINGUIST, V13, P72, DOI 10.1093/applin/13.1.72
   Hirst D, 1998, INTONATION SYSTEMS S, P78
   HOCHBERG JG, 1988, LANGUAGE, V64, P683, DOI 10.2307/414564
   Hockey B. A., 1998, U PENNSYLVANIA WORKI, V5, P71
   Hohle B, 2009, INFANT BEHAV DEV, V32, P262, DOI 10.1016/j.infbeh.2009.03.004
   Hualde Jose Ignacio, 2005, SOUNDS SPANISH
   Hurtado A, 2004, J SOC ISSUES, V60, P137, DOI 10.1111/j.0022-4537.2004.00103.x
   Imada T, 2006, NEUROREPORT, V17, P957, DOI 10.1097/01.wnr.0000223387.51704.89
   JUSCZYK PW, 1993, CHILD DEV, V64, P675, DOI 10.2307/1131210
   KEHOE M, 1995, J SPEECH HEAR RES, V38, P338, DOI 10.1044/jshr.3802.338
   Kim JS, 2015, 2015 INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ARTIFICIAL INTELLIGENCE (CAAI 2015), P106
   KING RD, 1967, LANGUAGE, V43, P831, DOI 10.2307/411969
   Klatt D.H., 1975, J PHONETICS, V3, P129
   Knightly LM, 2003, J ACOUST SOC AM, V114, P465, DOI 10.1121/1.1577560
   KONDOBROWN K, 2004, J NATL COUNCIL LESS, V1, P1
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   Kuhl PK, 1996, J ACOUST SOC AM, V100, P2425, DOI 10.1121/1.417951
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Ladefoged P., 2001, COURSE PHONETICS
   Lehiste I, 1979, FRONTIERS SPEECH COM, P191
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Lieberman P., 1984, BIOL EVOLUTION LANGU
   Lleo Conxita Martin, 2004, LAB APPROACHES SPANI, P3
   Lord G, 2007, APPL LANGUAGE LEARNI, V17, P1
   Lynch A., 2003, HERITAGE LANGUAGE J, V1, P1
   Mampe B, 2009, CURR BIOL, V19, P1994, DOI 10.1016/j.cub.2009.09.064
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Menke M., 2010, STUDIES HISPANIC LUS, V3, P181
   Menn L., 1995, HDB CHILD LANGUAGE, P335
   Montrul S., 2008, INCOMPLETE ACQUISTIO
   Montrul S, 2011, STUD SECOND LANG ACQ, V33, P163, DOI 10.1017/S0272263110000720
   Montrul Silvina, 2012, EUROSLA YB, V12, P1, DOI DOI 10.1075/EUROSLA.12.03MON
   Murphy J., 2004, SYSTEM, V32, P61, DOI [10.1016/j.system.2003.06.001, DOI 10.1016/J.SYSTEM.2003.06.001]
   Navarro Tomas T, 1966, MANUAL PRONUNCIACION
   Nazzi T, 2000, J MEM LANG, V43, P1, DOI 10.1006/jmla.2000.2698
   O'Grady W, 2011, STUD SECOND LANG ACQ, V33, P223, DOI 10.1017/S0272263110000744
   Oh JS, 2003, COGNITION, V86, pB53, DOI 10.1016/S0010-0277(02)00175-0
   Ortega-Llebaria M., 2009, PHONETICS PHONOLOGY, P35, DOI DOI 10.1075/CILT.306.02ORT
   Ortega-Llebaria M., 2007, SEGMENTAL PROSODIC I, P155, DOI DOI 10.1075/CILT.282.11ORT
   Ortega-Llebaria M, 2013, J PHONETICS, V41, P186, DOI 10.1016/j.wocn.2013.01.006
   Ortega-Llebaria Marta, 2006, SEL P 2 C LAB APPR S, P104
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Polinsky M, 2007, LANG LINGUIST COMPAS, V1, DOI 10.1111/j.1749-818x.2007.00022.x
   POLLOCK KE, 1993, J PHONETICS, V21, P183, DOI 10.1016/S0095-4470(19)31332-4
   Pons F, 2010, INFANCY, V15, P223, DOI 10.1111/j.1532-7078.2009.00016.x
   Potowski K., 2004, SW J LINGUISTICS, V23, P87
   Prieto P, 2007, J PHONETICS, V35, P473, DOI 10.1016/j.wocn.2007.01.001
   Prieto P, 2012, SPEECH COMMUN, V54, P681, DOI 10.1016/j.specom.2011.12.001
   Quilis A., 1993, TRATADO FONOLOGIA FO
   Quilis A, 1983, ESTUDIOS DE FONETICA, P137
   R Core Team, 2017, R LANG ENV STAT COMP
   Ramus F, 1999, COGNITION, V73, P265, DOI 10.1016/S0010-0277(99)00058-X
   Rao Rajiv, 2010, SEL P 4 C LAB APPR S, P69
   Recasens D, 1999, COARTICULATION THEOR, P322
   Roark B, 2000, PROC ANN BUCLD, P597
   Robles-Puente S., 2014, THESIS
   Ronquest R, 2016, HERITAGE LANGUAGE J, V13, P275
   Rose Y, 2007, ANN M BERK LING SOC, V33, P323
   Saalfeld AK, 2009, THESIS
   Sato Y, 2010, DEV PSYCHOL, V46, P106, DOI 10.1037/a0016718
   Schwartz RG, 1996, J ACOUST SOC AM, V99, P3192, DOI 10.1121/1.414803
   Skoruppa K, 2013, LANG LEARN DEV, V9, P88, DOI 10.1080/15475441.2012.693881
   Skoruppa K, 2009, DEVELOPMENTAL SCI, V12, P914, DOI 10.1111/j.1467-7687.2009.00835.x
   Smith B.L., 1978, J PHONETICS, V6, P37
   Soto-Faraco S, 2001, J MEM LANG, V45, P412, DOI 10.1006/jmla.2000.2783
   Torreira F., 2014, P 7 INT C SPEECH PRO, P197
   Trofimovich P, 2006, STUD SECOND LANG ACQ, V28, P1, DOI 10.1017/S0272263106060013
   Trofimovich P, 2007, APPL PSYCHOLINGUIST, V28, P251, DOI 10.1017/S0142716407070130
   Turk AE, 1995, LANG SPEECH, V38, P143, DOI 10.1177/002383099503800202
   Tyler MD, 2009, J ACOUST SOC AM, V126, P367, DOI 10.1121/1.3129127
   Valde's G., 2001, HERITAGE LANGUAGES A, P37
   Vihman MM, 1998, CHILD DEV, V69, P935, DOI 10.2307/1132354
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1993, J PHONETICS, V21, P83, DOI 10.1016/S0095-4470(19)31322-1
   WIGHTMAN CW, 1992, J ACOUST SOC AM, V91, P1707, DOI 10.1121/1.402450
NR 116
TC 1
Z9 1
U1 0
U2 11
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 1366-7289
EI 1469-1841
J9 BILING-LANG COGN
JI Biling.-Lang. Cogn.
PD MAR
PY 2020
VL 23
IS 2
BP 233
EP 250
AR PII S1366728918001220
DI 10.1017/S1366728918001220
PG 18
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA KM8UT
UT WOS:000514418300001
DA 2021-02-24
ER

PT J
AU Chan, RKW
   Leung, JHC
AF Chan, Ricky K. W.
   Leung, Janny H. C.
TI WHY ARE LEXICAL TONES DIFFICULT TO LEARN? INSIGHTS FROM THE INCIDENTAL
   LEARNING OF TONE-SEGMENT CONNECTIONS
SO STUDIES IN SECOND LANGUAGE ACQUISITION
LA English
DT Article
ID SPOKEN WORD RECOGNITION; MANDARIN CHINESE TONES; HUMAN BRAIN-STEM;
   EXPLICIT KNOWLEDGE; LANGUAGE EXPERIENCE; MUSICAL EXPERIENCE;
   SPEECH-PERCEPTION; ABSOLUTE PITCH; IMPLICIT; SPEAKERS
AB L2 sounds present different kinds of challenges to learners at the phonetic, phonological, and lexical levels, but previous studies on L2 tone learning mostly focused on the phonetic and lexical levels. The present study employs an innovative technique to examine the role of prior tonal experience and musical training on forming novel abstract syllable-level tone categories. Eighty Cantonese and English musicians and nonmusicians completed two tasks: (a) AX tone discrimination and (b) incidental learning of artificial tone-segment connections (e.g., words beginning with an aspirated stop always carry a rising tone) with synthesized stimuli modeled on Thai. Although the four participant groups distinguished the target tones similarly well, Cantonese speakers showed abstract and implicit knowledge of the target tone-segment mappings after training but English speakers did not, regardless of their musical experience. This suggests that tone language experience, but not musical experience, is crucial for forming novel abstract syllable-level tone categories.
C1 [Chan, Ricky K. W.; Leung, Janny H. C.] Univ Hong Kong, Hong Kong, Peoples R China.
RP Chan, RKW (corresponding author), Univ Hong Kong, Speech Language & Cognit Lab, Sch English, Pokfulam Rd, Hong Kong, Peoples R China.
EM rickykwc@hku.hk
RI ; Leung, Janny Hiu Chi/A-8418-2010
OI Chan, Ricky KW/0000-0003-4977-8406; Leung, Janny Hiu
   Chi/0000-0002-7307-4292
FU Faculty of Arts and Social Sciences Research Fund, Lancaster University
   [SZA1435]; University of Hong KongUniversity of Hong Kong [201409176014]
FX We would like to thank Professor Susan Gass, the editor, and two
   anonymous reviewers for their constructive feedback on our work. We
   would also like to thank Scarlett Hao, Alision Lam, Sula Ross, and Bruce
   Wang for their research assistance, and Patchanok Kitikanan for her
   advice on the stimuli. Part of the data collection took place when the
   first author worked in Lancaster University, UK. The financial support
   from Faculty of Arts and Social Sciences Research Fund, Lancaster
   University (project code: SZA1435) and Small Project Funding, University
   of Hong Kong (project code: 201409176014) is gratefully acknowledged.
CR ALTMANN GTM, 1995, J EXP PSYCHOL LEARN, V21, P899, DOI 10.1037/0278-7393.21.4.899
   Andringa S, 2015, STUD SECOND LANG ACQ, V37, P185, DOI 10.1017/S027226311500008X
   [Anonymous], 2018, DEV COGN NEUROSCI, V21, DOI 10.1016/S1878-9293(18)30129-4
   [Anonymous], 2005, OBESITY RES, V27, p51S, DOI 10.1002/j.1550-8528.1998.tb00690.x
   Bates D., 2009, LME4 LINEAR MIXED EF
   Bauer R., 1997, MODERN CANTONESE PHO
   Best C.T., 1994, DEV SPEECH PERCEPTIO, P167
   Bidelman GM, 2011, BRAIN COGNITION, V77, P1, DOI 10.1016/j.bandc.2011.07.006
   Bowles AR, 2016, LANG LEARN, V66, P774, DOI 10.1111/lang.12159
   Bradley E. D., 2012, THESIS
   Chan RKW, 2018, APPL PSYCHOLINGUIST, V39, P37, DOI 10.1017/S0142716417000376
   Chan RKW, 2014, SECOND LANG RES, V30, P463, DOI 10.1177/0267658313510169
   Chandrasekaran B, 2010, J ACOUST SOC AM, V128, P456, DOI 10.1121/1.3445785
   Chang CB, 2015, J ACOUST SOC AM, V138, P3703, DOI 10.1121/1.4937612
   Dell GS, 2000, J EXP PSYCHOL LEARN, V26, P1355, DOI 10.1037//0278-7393.26.6.1355
   Deutsch D, 2004, MUSIC PERCEPT, V21, P339, DOI 10.1525/mp.2004.21.3.339
   Deutsch D, 2009, J ACOUST SOC AM, V125, P2398, DOI 10.1121/1.3081389
   Dienes Z, 2005, PSYCHOL RES-PSYCH FO, V69, P338, DOI 10.1007/s00426-004-0208-3
   Dienes Z, 2008, PROG BRAIN RES, V168, P49, DOI 10.1016/S0079-6123(07)68005-4
   Ettlinger M, 2016, COGNITIVE SCI, V40, P822, DOI 10.1111/cogs.12257
   Francis AL, 2008, J PHONETICS, V36, P268, DOI 10.1016/j.wocn.2007.06.005
   Gandour J, 2003, BRAIN LANG, V84, P318, DOI 10.1016/S0093-934X(02)00505-9
   Godfroid A, 2016, STUD SECOND LANG ACQ, V38, P177, DOI 10.1017/S0272263115000388
   Gomez RL, 1999, COGNITION, V70, P109, DOI 10.1016/S0010-0277(99)00003-7
   Gottfried T. L, 2007, LANGUAGE EXPERIENCE, P221, DOI DOI 10.1075/LLLT.17
   Graham CR, 2018, STUD SECOND LANG ACQ, V40, P3, DOI 10.1017/S0272263116000371
   Grey S., 2014, STUDIES 2 LANGUAGE A, V36, P1, DOI DOI 10.1017/S0272263113000363
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Hao YC, 2012, J PHONETICS, V40, P269, DOI 10.1016/j.wocn.2011.11.001
   Hulstijn J. H., 2011, ENCY APPL LINGUISTIC, P2632
   Jiang CM, 2010, NEUROPSYCHOLOGIA, V48, P2630, DOI 10.1016/j.neuropsychologia.2010.05.009
   Keating GD, 2015, STUD SECOND LANG ACQ, V37, P1, DOI 10.1017/S0272263114000187
   Krishnan A, 2005, COGNITIVE BRAIN RES, V25, P161, DOI 10.1016/j.cogbrainres.2005.05.004
   LEATHER J, 1987, SOUND PATTERNS 2 LAN, P59
   Lee CY, 2008, J ACOUST SOC AM, V124, P3235, DOI 10.1121/1.2990713
   Lee CY, 2011, J ACOUST SOC AM, V130, P526, DOI 10.1121/1.3596473
   Lee CY, 2009, J PHONETICS, V37, P1, DOI 10.1016/j.wocn.2008.08.001
   LEE L, 1993, PERCEPT PSYCHOPHYS, V53, P157, DOI 10.3758/BF03211726
   Lee WS, 2009, J INT PHON ASSOC, V39, P107, DOI 10.1017/S0025100308003599
   Leung JHC, 2014, STUD SECOND LANG ACQ, V36, P733, DOI 10.1017/S0272263114000333
   Leung JHC, 2012, LANG LEARN, V62, P634, DOI 10.1111/j.1467-9922.2011.00637.x
   Leung JHC, 2011, STUD SECOND LANG ACQ, V33, P33, DOI 10.1017/S0272263110000525
   MacMillan N. A., 2005, DETECTION THEORY USE
   Makowski D., 2018, J OPEN SOURCE SOFTW, V3, P470, DOI [10.21105/joss.00470, DOI 10.21105/J0SS.00470]
   Malins JG, 2012, NEUROPSYCHOLOGIA, V50, P2032, DOI 10.1016/j.neuropsychologia.2012.05.002
   Malins JG, 2010, J MEM LANG, V62, P407, DOI 10.1016/j.jml.2010.02.004
   Mok PKP, 2012, J ACOUST SOC AM, V132, P2711, DOI 10.1121/1.4747010
   Nan Y, 2010, BRAIN, V133, P2635, DOI 10.1093/brain/awq178
   Norman J, 1988, CHINESE
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Pelzl E, 2019, STUD SECOND LANG ACQ, V41, P59, DOI 10.1017/S0272263117000444
   Perrachione TK, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073372
   Perrachione TK, 2011, J ACOUST SOC AM, V130, P461, DOI 10.1121/1.3593366
   R Core Team, 2013, R FDN STAT COMP
   Reber AS, 1993, IMPLICIT LEARNING TA
   Rebuschat P, 2013, LANG LEARN, V63, P595, DOI 10.1111/lang.12010
   Rebuschat P, 2012, APPL PSYCHOLINGUIST, V33, P829, DOI 10.1017/S0142716411000580
   REPP BH, 1990, J PHONETICS, V18, P481, DOI 10.1016/S0095-4470(19)30410-3
   Rogers J, 2016, APPL PSYCHOLINGUIST, V37, P781, DOI 10.1017/S0142716415000247
   Sagart L., 1999, CROSS LINGUISTICS ST, P91
   Schmidt R., 2001, COGNITION 2 LANGUAGE, P3, DOI DOI 10.1017/CBO9781139524780.003
   Schmidt Richard D., 2010, P CLASIC 2010 SING D, P721
   SCHMIDT RW, 1990, APPL LINGUIST, V11, P129, DOI 10.1093/applin/11.2.129
   Scott RB, 2008, J EXP PSYCHOL LEARN, V34, P1264, DOI 10.1037/a0012943
   Sebastian-Galles N, 2012, LANG LEARN, V62, P131, DOI 10.1111/j.1467-9922.2012.00709.x
   Sladen G., 2009, CENTRAL THAI PHONOLO
   So CK, 2010, LANG SPEECH, V53, P273, DOI 10.1177/0023830909357156
   STAGRAY JR, 1993, J CHINESE LINGUIST, V21, P143
   Wang Y, 2004, APPL PSYCHOLINGUIST, V25, P449, DOI 10.1017/S0142716404001213
   Wang Y, 2001, BRAIN LANG, V78, P332, DOI 10.1006/brln.2001.2474
   Wang Y, 1999, J ACOUST SOC AM, V106, P3649, DOI 10.1121/1.428217
   Warker JA, 2006, J EXP PSYCHOL LEARN, V32, P387, DOI 10.1037/0278-7393.32.2.387
   Wayland R, 2010, J PHONETICS, V38, P654, DOI 10.1016/j.wocn.2010.10.001
   Wayland RP, 2004, LANG LEARN, V54, P681, DOI 10.1111/j.1467-9922.2004.00283.x
   Wells J.C., 2006, ENGLISH INTONATION I
   Wiener S, 2018, LANG SPEECH, V61, P632, DOI 10.1177/0023830918761762
   Williams JN, 2008, LINGUA, V118, P522, DOI 10.1016/j.lingua.2007.03.003
   Williams JN, 2009, NEW HANDBOOK OF SECOND LANGUAGE ACQUISITION, 2ND EDITION, P319
   Wong PCM, 2007, APPL PSYCHOLINGUIST, V28, P565, DOI 10.1017/S0142716407070312
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Wong PCM, 2002, BRAIN RES BULL, V59, P83, DOI 10.1016/S0361-9230(02)00860-2
   Xu YS, 2006, J ACOUST SOC AM, V120, P1063, DOI 10.1121/1.2213572
   Zhang Linjun, 2011, CHINESE TEACHING WOR, V25, P268
NR 83
TC 0
Z9 0
U1 2
U2 11
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0272-2631
EI 1470-1545
J9 STUD SECOND LANG ACQ
JI Stud. Second Lang. Acquis.
PD MAR
PY 2020
VL 42
IS 1
BP 33
EP 59
AR PII S0272263119000482
DI 10.1017/S0272263119000482
PG 27
WC Linguistics
SC Linguistics
GA KM5HN
UT WOS:000514167300002
DA 2021-02-24
ER

PT J
AU Alderton, R
AF Alderton, Roy
TI Speaker Gender and Salience in Sociolinguistic Speech Perception:
   goose-fronting in Standard Southern British English
SO JOURNAL OF ENGLISH LINGUISTICS
LA English
DT Article
DE gender; salience; sociophonetics; speech perception; visual priming
ID FORMANT FREQUENCIES; TALKER GENDER; VOWELS; IDENTIFICATION;
   PLEASANTNESS; EDUCATION; NORTHERN; DESIGN; FEMALE
AB Listeners' perceptions of sound changes may be influenced by priming them with social information about the speaker. It is not clear, however, whether this occurs for sociolinguistic variables that pass below the level of awareness. This article investigates whether visual speaker gender affects the perception of goose-fronting in Standard Southern British English, a sound change that is led by young women yet does not fulfil criteria for sociolinguistic salience. Participants from across the United Kingdom completed a word identification experiment based on a gender-ambiguous synthesized fleece-goose continuum while primed with an image of a man's or a woman's face. The study did not find a significant main effect of priming, but men identified fronter tokens as goose when primed with a woman's face. I argue that sociolinguistic priming effects may be over-stated and that future priming experiments should be designed with maximal statistical power where possible.
C1 [Alderton, Roy] Univ Sheffield, Linguist, Sheffield, S Yorkshire, England.
RP Alderton, R (corresponding author), Univ Sheffield, Sch English, Jessop West, 1 Upper Hanover St, Sheffield S3 7RA, S Yorkshire, England.
EM r.alderton@sheffield.ac.uk
OI Alderton, Roy/0000-0001-8538-8531
CR Alderton R., 2019, THESIS
   Alku P, 1999, CLIN NEUROPHYSIOL, V110, P1329, DOI 10.1016/S1388-2457(99)00088-7
   Altendorf Ulrike, 2017, HIST ENGLISH, V5, P169
   Assmann PF, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P889
   Baayen H, 2017, J MEM LANG, V94, P206, DOI 10.1016/j.jml.2016.11.006
   Baayen R.H., 2008, ANAL LINGUISTIC DATA
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beal JC, 2012, DIALECT ENGL, P1
   Bjelakovic A, 2017, ENGL LANG LINGUIST, V21, P501, DOI 10.1017/S1360674316000253
   Boersma P, 2015, PRAAT DOING PHONETIC
   Campbell-Kibler K, 2012, LINGUA, V122, P753, DOI 10.1016/j.lingua.2012.01.002
   Chang Yung-Hsiang Shawn, 2015, P INT C PHON SCI 18
   Chladkova Kateina, 2011, ICPHC REG SESS HONG, P476
   Chladkova K, 2017, LANG SPEECH, V60, P377, DOI 10.1177/0023830916650991
   D'onofrio A, 2018, LANG SOC, V47, P513, DOI 10.1017/S0047404518000581
   Deterding David, 1997, J INT PHON ASSOC, V27, P47, DOI [DOI 10.1017/S0025100300005417, 10.1017/S0025100300005417]
   Docherty G, 2018, TOP COGN SCI, V10, P759, DOI 10.1111/tops.12375
   Drager K, 2011, LANG SPEECH, V54, P99, DOI 10.1177/0023830910388017
   Drager Katie, 2015, LINGUISTIC VARIATION
   Eckert P, 2008, J SOCIOLING, V12, P453, DOI 10.1111/j.1467-9841.2008.00374.x
   Ferragne E, 2010, J INT PHON ASSOC, V40, P1, DOI 10.1017/S0025100309990247
   Flynn N, 2012, THESIS
   Foulkes P, 2006, J PHONETICS, V34, P409, DOI 10.1016/j.wocn.2005.08.002
   Fridland V, 2005, AM SPEECH, V80, P366, DOI 10.1215/00031283-80-4-366
   Fridland V, 2008, LANG VAR CHANGE, V20, P67, DOI 10.1017/S0954394508000069
   Fridland Valerie, 2004, LANG VAR CHANGE, V16, P1, DOI DOI 10.1017/S0954394504161012
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Haddican B, 2013, LANG VAR CHANGE, V25, P371, DOI 10.1017/S0954394513000197
   Harrington J, 2008, J ACOUST SOC AM, V123, P2825, DOI 10.1121/1.2897042
   Harrington J, 2011, J INT PHON ASSOC, V41, P137, DOI 10.1017/S0025100310000265
   Harrington Jonathan, 2007, P 16 INT C PHON SCI, P1473
   HAWKINS SARAH, 2005, J INT PHON ASSOC, V35, P183, DOI [DOI 10.1017/S0025100305002124, 10.1017/S0025100305002124]
   Hay J, 2010, LANG SPEECH, V53, P447, DOI 10.1177/0023830910372489
   Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   HENTON CG, 1989, LANG COMMUN, V9, P299, DOI 10.1016/0271-5309(89)90026-8
   Hillenbrand James M, 2005, J ACOUST SOC AM, V3, P1932
   Holmes-Elliott Sophie, 2015, LONDON CALLING ASSES
   Jaeger TF, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01115
   Jansen Sandra, 2018, SOCIOLINGUISTICS ENG, P297, DOI DOI 10.1057/978-1-137-56288-3_12
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Johnson K, 2006, J PHONETICS, V34, P485, DOI 10.1016/j.wocn.2005.08.004
   Juskan Marten, 2016, THESIS
   Kerswill P., 2002, LANGUAGE CHANGE INTE, P81, DOI DOI 10.1515/9783110892598.81
   Kickett-Tucker CS, 2015, INT J EQUITY HEALTH, V14, DOI 10.1186/s12939-015-0234-3
   Kirby J, 2018, J PHONETICS, V70, P70, DOI 10.1016/j.wocn.2018.05.005
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Labov W., 2001, PRINCIPLES LINGUISTI, V2
   Lawrence Daniel, 2015, BRIEF INTRO VO UNPUB
   Lawrence Daniel, 2017, THESIS
   Levon E, 2014, J ENGL LINGUIST, V42, P185, DOI 10.1177/0075424214531487
   Llamas C, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01163
   Love R, 2017, INT J CORPUS LINGUIS, V22, P319, DOI 10.1075/ijcl.22.3.02lov
   Munson B, 2017, LINGUISTICS, V55, P1073, DOI 10.1515/ling-2017-0021
   Munson B, 2011, J ACOUST SOC AM, V130, P2631, DOI 10.1121/1.3641410
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Przedlacka J., 2002, ESTUARY ENGLISH SOCI
   R Core Team, 2017, R LANG ENV STAT COMP
   Racz P., 2013, SALIENCE SOCIOLINGUI
   Roettger TB, 2019, LAB PHONOL, V10, DOI 10.5334/labphon.147
   Roettger TB, 2019, J PHONETICS, V73, P1, DOI 10.1016/j.wocn.2018.12.001
   Schleef E, 2017, J ENGL LINGUIST, V45, P28, DOI 10.1177/0075424216686149
   Simpson AP, 2009, LANG LINGUIST COMPAS, V3, P621, DOI 10.1111/j.1749-818x.2009.00125.x
   Skuk VG, 2014, J SPEECH LANG HEAR R, V57, P285, DOI 10.1044/1092-4388(2013/12-0314)
   Soskuthy M, 2018, TOP COGN SCI, V10, P787, DOI 10.1111/tops.12346
   Squires L, 2013, J SOCIOLING, V17, P200, DOI 10.1111/josl.12025
   Staum Casasanto L., 2008, P 30 ANN C COGN SCI, V30, P799
   Strand EA, 1996, NATURAL LANGUAGE PROCESSING AND SPEECH TECHNOLOGY, P14
   Strand EA, 1999, J LANG SOC PSYCHOL, V18, P86, DOI 10.1177/0261927X99018001006
   Tollfree Laura, 1999, URBAN VOICES ACCENT, P163
   Torbert B., 2004, THESIS
   Traunmuller Hartmut, 1995, FREQUENCY RANG UNPUB
   Trudgill P., 1986, DIALECTS CONTACT
   University of Stirling, 2013, PSYCH IM COLL STIRL
   Villarreal D, 2018, J ENGL LINGUIST, V46, P52, DOI 10.1177/0075424217753520
   Walker M, 2019, LAB PHONOL, V10, DOI 10.5334/labphon.90
   Wells J. C., 1982, ACCENTS ENGLISH
   Westfall J, 2014, J EXP PSYCHOL GEN, V143, P2020, DOI 10.1037/xge0000014
   Williams Ann, 1999, URBAN VOICES ACCENT, P141
   Williams D, 2014, J ACOUST SOC AM, V136, P2751, DOI 10.1121/1.4896471
   Winn MB, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00824
NR 85
TC 0
Z9 0
U1 0
U2 2
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0075-4242
EI 1552-5457
J9 J ENGL LINGUIST
JI J. Engl. Linguist.
PD MAR
PY 2020
VL 48
IS 1
BP 72
EP 96
DI 10.1177/0075424219896400
PG 25
WC Linguistics; Language & Linguistics
SC Linguistics
GA KJ1GV
UT WOS:000511806400003
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Bidelman, GM
   Bush, LC
   Boudreaux, AM
AF Bidelman, Gavin M.
   Bush, Lauren C.
   Boudreaux, Alex M.
TI Effects of Noise on the Behavioral and Neural Categorization of Speech
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE auditory event-related potentials (ERPs); categorical perception;
   speech-in-noise (SIN) perception; cocktail party effect; EEG
ID PRIMARY AUDITORY-CORTEX; CATEGORICAL PERCEPTION; LANGUAGE EXPERIENCE;
   BRAIN-STEM; BACKGROUND-NOISE; REPRESENTATION; RESPONSES; DISCRIMINATION;
   PHONEME; ORGANIZATION
AB We investigated whether the categorical perception (CP) of speech might also provide a mechanism that aids its perception in noise. We varied signal-to-noise ratio (SNR) [clear, 0 dB, -5 dB] while listeners classified an acoustic-phonetic continuum (/u/ to /a/). Noise-related changes in behavioral categorization were only observed at the lowest SNR. Event-related brain potentials (ERPs) differentiated category vs. category-ambiguous speech by the P2 wave (similar to 180-320 ms). Paralleling behavior, neural responses to speech with clear phonetic status (i.e., continuum endpoints) were robust to noise down to -5 dB SNR, whereas responses to ambiguous tokens declined with decreasing SNR. Results demonstrate that phonetic speech representations are more resistant to degradation than corresponding acoustic representations. Findings suggest the mere process of binning speech sounds into categories provides a robust mechanism to aid figure-ground speech perception by fortifying abstract categories from the acoustic signal and making the speech code more resistant to external interferences.
C1 [Bidelman, Gavin M.] Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.
   [Bidelman, Gavin M.; Bush, Lauren C.; Boudreaux, Alex M.] Univ Memphis, Sch Commun Sci & Disorders, Memphis, TN 38152 USA.
   [Bidelman, Gavin M.] Univ Tennessee, Dept Anat & Neurobiol, Hlth Sci Ctr, Memphis, TN 38163 USA.
RP Bidelman, GM (corresponding author), Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.; Bidelman, GM (corresponding author), Univ Memphis, Sch Commun Sci & Disorders, Memphis, TN 38152 USA.; Bidelman, GM (corresponding author), Univ Tennessee, Dept Anat & Neurobiol, Hlth Sci Ctr, Memphis, TN 38163 USA.
EM gmbdlman@memphis.edu
FU National Institute on Deafness and Other Communication Disorders of the
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC016267]
FX This work was supported by the National Institute on Deafness and Other
   Communication Disorders of the National Institutes of Health under award
   number R01DC016267 (GB).
CR Alain C, 2001, J EXP PSYCHOL HUMAN, V27, P1072, DOI 10.1037/0096-1523.27.5.1072
   Alain C, 2017, SCI REP-UK, V7, DOI 10.1038/srep40790
   Alain C, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00008
   Alain C, 2012, HEARING RES, V283, P126, DOI 10.1016/j.heares.2011.10.007
   Alain C, 2010, J COGNITIVE NEUROSCI, V22, P392, DOI 10.1162/jocn.2009.21279
   Alho J, 2016, NEUROIMAGE, V129, P214, DOI 10.1016/j.neuroimage.2016.01.016
   Altmann CF, 2014, NEUROPSYCHOLOGIA, V64, P13, DOI 10.1016/j.neuropsychologia.2014.09.006
   Bakdash JZ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00456
   Bar-Yosef O, 2007, FRONT COMPUT NEUROSC, V1, DOI [10.3389/neuro.10.003.2007, 10.3389/neuro.10/003.2007]
   Ben-David BM, 2011, PSYCHOPHYSIOLOGY, V48, P797, DOI 10.1111/j.1469-8986.2010.01139.x
   Best RM, 2019, J EXP PSYCHOL LEARN, V45, P1166, DOI 10.1037/xlm0000609
   Bidebnan GM, 2010, BRAIN RES, V1355, P112, DOI 10.1016/j.brainres.2010.07.100
   Bidelman GM, 2019, J ACOUST SOC AM, V146, P60, DOI 10.1121/1.5114822
   Bidelman GM, 2019, NEUROIMAGE, V201, DOI 10.1016/j.neuroimage.2019.116022
   Bidelman GM, 2018, HEARING RES, V367, P149, DOI 10.1016/j.heares.2018.05.018
   Bidelman GM, 2017, SPRINGER HANDB AUDIT, V61, P193, DOI 10.1007/978-3-319-47944-6_8
   Bidelman GM, 2018, J NEUROSCI METH, V293, P59, DOI 10.1016/j.jneumeth.2017.09.005
   Bidelman GM, 2017, EUR J NEUROSCI, V45, P690, DOI 10.1111/ejn.13526
   Bidelman GM, 2016, NEUROIMAGE, V124, P581, DOI 10.1016/j.neuroimage.2015.09.020
   Bidelman GM, 2015, NEUROIMAGE, V120, P191, DOI 10.1016/j.neuroimage.2015.06.087
   Bidelman GM, 2015, NEUROPSYCHOLOGIA, V68, P38, DOI 10.1016/j.neuropsychologia.2014.12.020
   Bidelman GM, 2015, J NEUROSCI, V35, P1240, DOI 10.1523/JNEUROSCI.3292-14.2015
   Bidelman GM, 2015, BRAIN LANG, V141, P62, DOI 10.1016/j.bandl.2014.11.003
   Bidelman GM, 2014, EUR J NEUROSCI, V40, P2662, DOI 10.1111/ejn.12627
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Billings CJ, 2013, JARO-J ASSOC RES OTO, V14, P891, DOI 10.1007/s10162-013-0415-y
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   Bizley JK, 2013, NAT REV NEUROSCI, V14, P693, DOI 10.1038/nrn3565
   Calcus A, 2016, J SPEECH LANG HEAR R, V59, P835, DOI 10.1044/2016_JSLHR-H-15-0076
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Chevillet MA, 2013, J NEUROSCI, V33, P5208, DOI 10.1523/JNEUROSCI.1870-12.2013
   DehaeneLambertz G, 1997, NEUROREPORT, V8, P919, DOI 10.1097/00001756-199703030-00021
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Du Y., 2014, P NATL ACAD SCI USA, V111, P1, DOI DOI 10.1073/pnas.1318738111
   Dykstra AR, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.7016.00472
   Gifford AM, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003715
   Goldstone RL, 2010, WIRES COGN SCI, V1, P69, DOI 10.1002/wcs.26
   Guenther FH, 2004, J SPEECH LANG HEAR R, V47, P46, DOI 10.1044/1092-4388(2004/005)
   Guenther FH, 1996, J ACOUST SOC AM, V100, P1111, DOI 10.1121/1.416296
   Gutschalk A, 2014, HEARING RES, V307, P98, DOI 10.1016/j.heares.2013.08.003
   Hakvoort B, 2016, J SPEECH LANG HEAR R, V59, P1448, DOI 10.1044/2016_JSLHR-L-15-0306
   Han JH, 2016, CLIN NEUROPHYSIOL, V127, P1603, DOI 10.1016/j.clinph.2015.10.049
   Hanley JR, 2011, PSYCHON B REV, V18, P355, DOI 10.3758/s13423-010-0043-z
   Harnad Stevan, 1987, CATEGORICAL PERCEPTI
   Helie S, 2017, BRAIN COGNITION, V116, P63, DOI 10.1016/j.bandc.2017.06.001
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Hu L, 2010, NEUROIMAGE, V50, P99, DOI 10.1016/j.neuroimage.2009.12.010
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Iverson P, 2000, PERCEPT PSYCHOPHYS, V62, P874, DOI 10.3758/BF03206929
   Jiang X, 2018, NEURON, V98, P405, DOI 10.1016/j.neuron.2018.03.014
   Joanisse MF, 2007, CEREB CORTEX, V17, P2084, DOI 10.1093/cercor/bhl124
   Joanisse MF, 2000, J EXP CHILD PSYCHOL, V77, P30, DOI 10.1006/jecp.1999.2553
   Kilian-Hutten N, 2011, J NEUROSCI, V31, P1715, DOI 10.1523/JNEUROSCI.4572-10.2011
   KNIGHT RT, 1989, BRAIN RES, V502, P109, DOI 10.1016/0006-8993(89)90466-6
   Kong EJ, 2016, J PHONETICS, V59, P40, DOI 10.1016/j.wocn.2016.08.006
   Krishnan A, 2009, NEUROREPORT, V20, P408, DOI 10.1097/WNR.0b013e3283263000
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Lavie N, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0205
   Leung AWS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068892
   Lewis GA, 2020, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01418
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Liebenthal E, 2010, CEREB CORTEX, V20, P2958, DOI 10.1093/cercor/bhq045
   Livingston KR, 1998, J EXP PSYCHOL LEARN, V24, P732, DOI 10.1037/0278-7393.24.3.732
   MASSARO DW, 1983, J EXP PSYCHOL HUMAN, V9, P753, DOI 10.1037/0096-1523.9.5.753
   MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037/0033-295X.85.3.207
   Micheyl C, 2005, NEURON, V48, P139, DOI 10.1016/j.neuron.2005.08.039
   Mody M, 1997, J EXP CHILD PSYCHOL, V64, P199, DOI 10.1006/jecp.1996.2343
   Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009
   Myers EB, 2008, CEREB CORTEX, V18, P278, DOI 10.1093/cercor/bhm053
   Myers EB, 2012, J COGNITIVE NEUROSCI, V24, P1695, DOI 10.1162/jocn_a_00243
   Neal A, 1997, PSYCHON B REV, V4, P24, DOI 10.3758/BF03210770
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   NOTHDURFT HC, 1991, VISION RES, V31, P1073, DOI 10.1016/0042-6989(91)90211-M
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Oostenveld R, 2001, CLIN NEUROPHYSIOL, V112, P713, DOI 10.1016/S1388-2457(00)00527-7
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Perez-Gay F., 2018, CATEGORY LEARNING CA, DOI [10.1371/journal.pone.0226000, DOI 10.1371/JOURNAL.PONE.0226000]
   PERRIN F, 1989, ELECTROEN CLIN NEURO, V72, P184, DOI 10.1016/0013-4694(89)90180-6
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Phillips C, 2000, J COGNITIVE NEUROSCI, V12, P1038, DOI 10.1162/08989290051137567
   Picton TW, 1999, AUDIOL NEURO-OTOL, V4, P64, DOI 10.1159/000013823
   Picton TW, 2000, CLIN NEUROPHYSIOL, V111, P53, DOI 10.1016/S1388-2457(99)00227-8
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   PISONI DB, 1987, COGNITION, V25, P21, DOI 10.1016/0010-0277(87)90003-5
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   PISONI DB, 1975, MEM COGNITION, V3, P7, DOI 10.3758/BF03198202
   Poeppel D, 2004, NEUROPSYCHOLOGIA, V42, P183, DOI 10.1016/j.neuropsychologia.2003.07.010
   Ponjavic-Conte KD, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053953
   R Core Team, 2018, R LANG ENV STAT COMP
   RECANZONE GH, 1993, J NEUROSCI, V13, P87
   Reetzke R, 2018, CURR BIOL, V28, P1419, DOI 10.1016/j.cub.2018.03.026
   Rogers JC, 2017, J COGNITIVE NEUROSCI, V29, P919, DOI 10.1162/jocn_a_01096
   Ross B, 2013, BMC NEUROSCI, V14, DOI 10.1186/1471-2202-14-151
   Ross B, 2009, HEARING RES, V248, P48, DOI 10.1016/j.heares.2008.11.012
   Scherg M, 2002, J CLIN NEUROPHYSIOL, V19, P91, DOI 10.1097/00004691-200203000-00001
   Schutt HH, 2016, VISION RES, V122, P105, DOI 10.1016/j.visres.2016.02.002
   Steinschneider M, 2003, J ACOUST SOC AM, V114, P307, DOI 10.1121/1.1582449
   Streiner DL, 2003, J PERS ASSESS, V80, P217, DOI 10.1207/S15327752JPA8003_01
   Toscano JC, 2018, BRAIN LANG, V184, P32, DOI 10.1016/j.bandl.2018.06.006
   Toscano JC, 2010, PSYCHOL SCI, V21, P1532, DOI 10.1177/0956797610384142
   Tremblay KL, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00028
   WERKER JF, 1987, CAN J PSYCHOL, V41, P48, DOI 10.1037/h0084150
   Xie X, 2015, J ACOUST SOC AM, V137, P419, DOI 10.1121/1.4904699
   Xu YS, 2006, J ACOUST SOC AM, V120, P1063, DOI 10.1121/1.2213572
   Yoo J, 2019, HEARING RES, V377, P189, DOI 10.1016/j.heares.2019.03.021
   Zendel BR, 2012, PSYCHOL AGING, V27, P410, DOI 10.1037/a0024816
   Zhang LJ, 2011, PLOS ONE, V6, DOI [10.1371/journal.pone.0020963, 10.1371/journal.pone.0026129, 10.1371/journal.pone.0022809, 10.1371/journal.pone.0028953, 10.1371/journal.pone.0026842]
NR 107
TC 0
Z9 0
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD FEB 27
PY 2020
VL 14
AR 153
DI 10.3389/fnins.2020.00153
PG 13
WC Neurosciences
SC Neurosciences & Neurology
GA LC0XV
UT WOS:000525054400001
PM 32180700
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Di Stadio, A
   Messineo, D
   Ralli, M
   Roccamatisi, D
   Musacchio, A
   Ricci, G
   Greco, A
AF Di Stadio, Arianna
   Messineo, Daniela
   Ralli, Massimo
   Roccamatisi, Dalila
   Musacchio, Angela
   Ricci, Giampietro
   Greco, Antonio
TI The impact of white matter hyperintensities on speech perception
SO NEUROLOGICAL SCIENCES
LA English
DT Article
DE White matter lesion; White matter hyperintensities; Magnetic resonance
   imaging; Speech understanding; Aging; Gliosis
ID COGNITIVE FUNCTION; HEARING-LOSS; RECOGNITION; LESIONS; LANGUAGE;
   PREVALENCE; LISTENERS; DISEASE; NOISE; MRI
AB Background The presence of white matter hyperintensities (WMHs) can impact on normal brain function by altering normal signal transmission and determining different symptoms. Aim To evaluate the relationship between the presence of brain WMHs and the scores of speech perception test (SPT) in a sample of normal-hearing patients under 70 years of age. Material and method Prospective study. One hundred eleven patients underwent audiological screening with pure tone audiometry (PTA), tympanometry, speech perception testing (SPT), and brain magnetic resonance imaging (MRI). T2 sequences were analyzed to identify the presence of WMH that, if identified, were scored using the Fazekas score. Statistical multiple regression analysis was performed to understand the relationship between PTA and SPT score; the Pearson's and Spearman's tests were used to evaluate the correlation between Fazekas scores and SPT. Chi-square test was used to analyze the difference between gender. Results The results of PTA were not predictive of the SPT score. A negative statistically significant correlation (Spearman's, p = 0.0001; Pearson's, p < 0.001) was identified between the Fazekas score and the results of SPT. No statistically significant differences were identified in the correlation of WMH and SPT between males and females. Conclusion Multiple WMHs in the brain can worsen word recognition in patients with normal auditory threshold; this may be related to the impact that these lesions have on the memory ability. Spread of lesions into the brain might reduce the brain capacity to remember words, despite the sound is correctly perceived by the ear.
C1 [Di Stadio, Arianna; Ricci, Giampietro] Univ Perugia, Otolaryngol Dept, Piazza Menghini 1, Perugia, Italy.
   [Messineo, Daniela] Univ Roma La Sapienza, Radiol Oncol & Anatomopathol Dept, Rome, Italy.
   [Ralli, Massimo; Musacchio, Angela; Greco, Antonio] Univ Roma La Sapienza, Organ Sense Dept, Rome, Italy.
   [Roccamatisi, Dalila] UTIU, Psychol Fac, Rome, Italy.
RP Di Stadio, A (corresponding author), Univ Perugia, Otolaryngol Dept, Piazza Menghini 1, Perugia, Italy.
EM ariannadistadio@hotmail.com
RI Di Stadio, Arianna/Q-2498-2017; Di Stadio, Arianna/O-8256-2019; DANIELA,
   MESSINEO/AAP-8097-2020
OI Di Stadio, Arianna/0000-0001-5510-3814; Di Stadio,
   Arianna/0000-0001-5510-3814; DANIELA, MESSINEO/0000-0003-3059-4439;
   Ralli, Massimo/0000-0001-8776-0421
CR Altamura C, 2016, J CLIN NEUROL, V12, P201, DOI 10.3988/jcn.2016.12.2.201
   Amos NE, 2007, J SPEECH LANG HEAR R, V50, P819, DOI 10.1044/1092-4388(2007/057)
   BRAFFMAN BH, 1988, AM J ROENTGENOL, V151, P559, DOI 10.2214/ajr.151.3.559
   Branco M, 2019, NEUROL SCI, V40, P1651, DOI 10.1007/s10072-019-03875-7
   Centonze D, 2010, CELL DEATH DIFFER, V17, P1083, DOI 10.1038/cdd.2009.179
   Centonze D, 2009, J NEUROSCI, V29, P3442, DOI 10.1523/JNEUROSCI.5804-08.2009
   Chang EF, 2015, J NEUROSURG, V122, P250, DOI 10.3171/2014.10.JNS132647
   Ciorba A, 2019, J CLIN NEUROSCI, V65, P6, DOI 10.1016/j.jocn.2019.04.037
   Datta G, 2017, BRAIN, V140, P2927, DOI 10.1093/brain/awx228
   de Leeuw FE, 2001, J NEUROL NEUROSUR PS, V70, P9, DOI 10.1136/jnnp.70.1.9
   Debette S, 2010, BRIT MED J, V341, DOI 10.1136/bmj.c3666
   Di Stadio A, 2018, AUDIOL NEURO-OTOL, V23, P238, DOI 10.1159/000493722
   Eckert MA, 2013, JARO-J ASSOC RES OTO, V14, P425, DOI 10.1007/s10162-013-0381-4
   Ellis RJ, 2013, INT J AUDIOL, V52, P14, DOI 10.3109/14992027.2012.721013
   FAZEKAS F, 1987, AM J ROENTGENOL, V149, P351, DOI 10.2214/ajr.149.2.351
   Fujishima M, 1995, Hypertens Res, V18, P111, DOI 10.1291/hypres.18.111
   Fusconi M, 2019, EUR ARCH OTO-RHINO-L, V276, P3043, DOI 10.1007/s00405-019-05593-4
   Goswami U, 2012, ENCY SCI LEARNING
   Hainsworth AH, 2017, STROKE, V48, P2799, DOI 10.1161/STROKEAHA.117.018101
   Katz Jack, 2014, HDB CLIN AUDIOLOGY
   Kim D, 2019, NEUROL SCI, V40, P2333, DOI 10.1007/s10072-019-03981-6
   Koeritzer MA, 2018, J SPEECH LANG HEAR R, V61, P740, DOI 10.1044/2017_JSLHR-H-17-0077
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Lyu BJ, 2019, P NATL ACAD SCI USA, V116, P21318, DOI 10.1073/pnas.1903402116
   MARSLENWILSON WD, 1981, PHILOS T R SOC B, V295, P317, DOI 10.1098/rstb.1981.0143
   Martin MG, 2014, EMBO REP, V15, P1036, DOI 10.15252/embr.201439225
   Merchant SN, 2010, SCHUKNECHTS PATHOLOG
   Moritz-Gasser S, 2013, NEUROPSYCHOLOGIA, V51, P1814, DOI 10.1016/j.neuropsychologia.2013.06.007
   Nishiyama R, 2017, MEMORY, V25, P1412, DOI 10.1080/09658211.2017.1310252
   Ortinski PI, 2010, NAT NEUROSCI, V13, P584, DOI 10.1038/nn.2535
   Popper AN, 1992, MAMMALIAN AUDITORY P
   Ramezani M, 2019, NEUROL SCI, V40, P121, DOI 10.1007/s10072-018-3594-9
   Rolheiser T, 2011, J NEUROSCI, V31, P16949, DOI 10.1523/JNEUROSCI.2725-11.2011
   Samson Y, 2001, REV NEUROL-FRANCE, V157, P837
   Sarbu N, 2016, RADIOGRAPHICS, V36, P1426, DOI 10.1148/rg.2016160031
   Seaquist ER, 2015, PSYCHOSOM MED, V77, P616, DOI 10.1097/PSY.0000000000000207
   Smirni D, 2018, NEUROL SCI, V39, P1391, DOI 10.1007/s10072-018-3433-z
   Trotta L, 2019, NEUROL SCI, V40, P1713, DOI 10.1007/s10072-019-03869-5
   Vernooij MW, 2007, NEW ENGL J MED, V357, P1821, DOI 10.1056/NEJMoa070972
   Wardlaw JM, 2015, J AM HEART ASSOC, V4, DOI 10.1161/JAHA.114.001140
   Woods DL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0113965
NR 41
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER-VERLAG ITALIA SRL
PI MILAN
PA VIA DECEMBRIO, 28, MILAN, 20137, ITALY
SN 1590-1874
EI 1590-3478
J9 NEUROL SCI
JI Neurol. Sci.
PD JUL
PY 2020
VL 41
IS 7
BP 1891
EP 1898
DI 10.1007/s10072-020-04295-8
EA FEB 2020
PG 8
WC Clinical Neurology; Neurosciences
SC Neurosciences & Neurology
GA MJ2EG
UT WOS:000516375400003
PM 32095945
DA 2021-02-24
ER

PT J
AU Gass, CS
   Patten, B
AF Gass, Carlton S.
   Patten, Brooke
TI Depressive symptoms as a factor in neuropsychological test performance:
   MMPI-2 and selected tests of the Halstead-Reitan/Halstead-Russell
   Battery
SO APPLIED NEUROPSYCHOLOGY-ADULT
LA English
DT Article; Early Access
DE Assessment; diagnosis; diagnosis; embeded measures; tests;
   psychopathology
ID COGNITIVE IMPAIRMENT; WORKING-MEMORY; VALIDITY; SENSITIVITY;
   ASSOCIATION; INVENTORY; ATTENTION; VARIABLES; SEVERITY; SCORES
AB The potential impact of depressive symptoms on neuropsychological test performance has been studied extensively yielding mixed results. Self-report depression inventories have been most often used, without a means to screen participants for response bias. Studies have also neglected to screen participants for incomplete effort in testing. In the present study, 48% of an initial sample of outpatient referrals (N = 247) failed to meet traditional validity criteria. The remaining participants were screened for cerebral pathology and then classified into high and low depressive symptom groups (ns = 46) using the median score on Scale D (Depression) of the MMPI-2. The "high depression" subjects scored over 70 T on the D scale (MN = 80 T). The "low depression" subjects scored below 65 T (MN = 58 T). Age, education, and estimated intelligence were equivalent across groups. Neuropsychological test performances were compared across eight tests: Revised Category Test, Trail Making Test, Part B, Tactual Performance Test (TPT), TPT Memory and Location, Reitan-Indiana Aphasia Screening Test, Seashore Rhythm Test, and the Speech Perception Test. A MANOVA revealed no main effect for group., F(8,69) = 1.05, n.s., and univariate analyses for each test also showed no intergroup differences. The results provide evidence that these neuropsychological tests are appropriately interpreted within a framework of brain-behavior relationships irrespective of an examinee's emotional status.
C1 [Gass, Carlton S.; Patten, Brooke] Tallahassee Mem Healthcare, Memory Disorders Clin, 1401 Centerville Rd, Tallahassee, FL 32308 USA.
RP Gass, CS (corresponding author), Tallahassee Mem Healthcare, Memory Disorders Clin, 1401 Centerville Rd, Tallahassee, FL 32308 USA.
EM carltongass@gmail.com
RI Gass, Carlton/AAO-5906-2020
CR Babikian T, 2006, CLIN NEUROPSYCHOL, V20, P145, DOI 10.1080/13854040590947362
   Baune BT, 2010, PSYCHIAT RES, V176, P183, DOI 10.1016/j.psychres.2008.12.001
   BECK AT, 1961, ARCH GEN PSYCHIAT, V4, P561, DOI 10.1001/archpsyc.1961.01710120031004
   Broglio SP, 2007, NEUROSURGERY, V60, P1050, DOI 10.1227/01.NEU.0000255479.90999.C0
   Burneo DCS, 2016, AUST PSYCHOL, V51, P389, DOI 10.1111/ap.12231
   Bush SS, 2005, ARCH CLIN NEUROPSYCH, V20, P419, DOI 10.1016/j.acn.2005.02.002
   Butterfield LC, 2010, NEUROPSYCHOLOGY, V24, P721, DOI 10.1037/a0019650
   CALSYN DA, 1982, PERCEPT MOTOR SKILL, V55, P1099, DOI 10.2466/pms.1982.55.3f.1099
   Chaytor N, 2007, J INT NEUROPSYCH SOC, V13, P377, DOI 10.1017/S1355617707070592
   De Jager CA, 2002, PSYCHOL MED, V32, P483, DOI 10.1017/S003329170200524X
   Den Hartog HM, 2003, PSYCHOL MED, V33, P1443, DOI 10.1017/S003329170300833X
   Fossati P, 1999, PSYCHIAT RES, V89, P171, DOI 10.1016/S0165-1781(99)00110-9
   Gass C. S., 2018, APA HDB PSYCHOPATHOL, V1, P200
   GASS CS, 1994, J CLIN PSYCHOL, V50, P586, DOI 10.1002/1097-4679(199407)50:4<586::AID-JCLP2270500414>3.0.CO;2-Z
   Gass CS, 1996, PSYCHOL ASSESSMENT, V8, P135, DOI 10.1037/1040-3590.8.2.135
   GASS CS, 1991, J CLIN PSYCHOL, V47, P100, DOI 10.1002/1097-4679(199101)47:1<100::AID-JCLP2270470116>3.0.CO;2-H
   Gorlyn M, 2006, J CLIN EXP NEUROPSYC, V28, P1145, DOI 10.1080/13803390500246944
   Hammar A, 2011, NORD J PSYCHIAT, V65, P74, DOI 10.3109/08039488.2010.494311
   Harvey PO, 2004, J PSYCHIATR RES, V38, P567, DOI 10.1016/j.jpsychires.2004.03.003
   Hoelzle JB, 2019, PSYCHOL ASSESSMENT, V31, P1174, DOI 10.1037/pas0000752
   Horton A.M., 2008, NEUROPSYCHOLOGY HDB, P251
   Kinsinger SW, 2010, NEUROPSYCHOLOGY, V24, P573, DOI 10.1037/a0019222
   Lim J, 2013, INT PSYCHOGERIATR, V25, P1543, DOI 10.1017/S1041610213000689
   McClintock SA, 2010, NEUROPSYCHOLOGY, V24, P9, DOI 10.1037/a0017336
   McDermott LM, 2009, J AFFECT DISORDERS, V119, P1, DOI 10.1016/j.jad.2009.04.022
   Nebes RD, 2000, PSYCHOL MED, V30, P679, DOI 10.1017/S0033291799001968
   Rapp MA, 2011, AM J GERIAT PSYCHIAT, V19, P357, DOI 10.1097/JGP.0b013e3181e898d0
   Reitan RM, 1997, NEUROPSYCHOL REV, V7, P3, DOI 10.1007/BF02876970
   Rohling ML, 2002, ARCH CLIN NEUROPSYCH, V17, P205, DOI 10.1016/S0887-6177(01)00109-3
   Ross SR, 2003, ARCH CLIN NEUROPSYCH, V18, P905, DOI 10.1016/S0887-6177(02)00169-5
   Ruocco AC, 2016, PSYCHOL ASSESSMENT, V28, P345, DOI 10.1037/a0039481
   Russell E. W., 2001, HALSTEAD RUSSELL NEU
   Russell E.W., 1993, HALSTEAD RUSSELL NEU
   Russell E. W., 2012, SCI FDN NEUROPSYCHOL
   Russell EW, 2005, ARCH CLIN NEUROPSYCH, V20, P479, DOI 10.1016/j.acn.2004.11.002
   Russell EW, 2004, ARCH CLIN NEUROPSYCH, V19, P1043, DOI 10.1016/j.acn.2003.12.006
   RUSSELL EW, 1987, J CONSULT CLIN PSYCH, V55, P898, DOI 10.1037/0022-006X.55.6.898
   Sarapas C, 2012, J ABNORM PSYCHOL, V121, P830, DOI 10.1037/a0028141
   Scafidi FA, 1999, ADOLESCENCE, V34, P61
   Snyder HR, 2013, PSYCHOL BULL, V139, P81, DOI 10.1037/a0028727
   Stenfors C.U.D., 2014, BMC PSYCHOL, V2, P3, DOI DOI 10.1186/2050-7283-2-3
   Suhr J. A., 2007, ASSESSMENT MALINGERE
   SWEET JJ, 1992, CLIN PSYCHOL REV, V12, P21, DOI 10.1016/0272-7358(92)90090-U
   Taylor D.J., 1990, PSYCHOL ASSESSMENT J, V2, P486
   Walker EM, 2010, PSYCHIAT ANN, V40, P29, DOI 10.3928/00485718-20091229-03
   Wechsler D., 2009, TEST PREMORBID FUNCT
   WIENS AN, 1977, J NERV MENT DIS, V164, P112, DOI 10.1097/00005053-197702000-00006
NR 47
TC 0
Z9 0
U1 1
U2 1
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-9095
EI 2327-9109
J9 APPL NEUROPSYCH-ADUL
JI Appl. Neuropsychol.-Adult
DI 10.1080/23279095.2020.1720687
EA FEB 2020
PG 6
WC Clinical Neurology; Psychology
SC Neurosciences & Neurology; Psychology
GA KN9WD
UT WOS:000515197100001
PM 32083959
DA 2021-02-24
ER

PT J
AU Abdollahi, FZ
   Delphi, M
   Delphi, V
AF Zamiri Abdollahi, Farzaneh
   Delphi, Maryam
   Delphi, Vafa
TI Spatial hearing and speech understanding in noise in elderly
SO HEARING BALANCE AND COMMUNICATION
LA English
DT Article; Early Access
DE Spatial hearing; elderly; speech perception in noise; self-assessment;
   hearing
ID OLDER-ADULTS; LISN; POPULATION; RELEASE; MASKING; HEALTH; TRENDS; LIFE;
   IRAN
AB Objectives: The aim of this study was to investigate spatial hearing in elderly with and without complaint about speech understanding in noise. Methods: Persian spatial hearing questionnaire (P-SHQ) was investigated in the elderly with and without speech understanding difficulty in noise and in normal young adults. ANOVA test was used for comparing results of the eight sub-characteristics of the P-SHQ among three groups. Results: Both elderly groups had lower performance in source localisation, understanding speech in noise with target and noise sources from the front, understanding speech in noise with spatially separate target and noise sources. There was a significant difference between the two elderly groups in understanding speech in noise with target and noise sources from the front. Conclusions: It shows that although the elderly have lower spatial performance than young adults, they still can benefit from the spatial separation of sound sources.
C1 [Zamiri Abdollahi, Farzaneh] Univ Tehran Med Sci, Audiol Dept, Sch Rehabil, Tehran, Iran.
   [Delphi, Maryam; Delphi, Vafa] Ahvaz Jundishapur Univ Med Sci, Musculoskeletal Rehabil Res Ctr, Ahwaz, Khuzestan, Iran.
RP Delphi, M (corresponding author), Ahvaz Jundishapur Univ Med Sci, Musculoskeletal Rehabil Res Ctr, Ahwaz, Khuzestan, Iran.
EM delphi.maryam1@gmail.com
RI delphi, maryam/O-8484-2017; Abdollahi, Farzaneh Zamiri/T-7448-2018
OI delphi, maryam/0000-0002-2179-778X; Abdollahi, Farzaneh
   Zamiri/0000-0002-9144-797X
FU Ahvaz Jundishapour University of Medical Sciences
   [IR.ajums.rec.1396.708.pht-9623]
FX This work was supported by the Grant from Ahvaz Jundishapour University
   of Medical Sciences with the number IR.ajums.rec.1396.708.pht-9623.
CR Abdollahi FZ, 2019, INDIAN J OTOLARYNGOL, V71, P182, DOI 10.1007/s12070-017-1114-5
   Afshar PF, 2016, GALEN MED J, V5, P1
   Anderson S, 2011, EAR HEARING, V32, P750, DOI 10.1097/AUD.0b013e31822229d3
   Atcherson Samuel R., 2015, Seminars in Hearing, V36, P150, DOI 10.1055/s-0035-1555118
   Besser J, 2015, EAR HEARING, V36, P24, DOI 10.1097/AUD.0000000000000096
   Boi R, 2012, GERIATR GERONTOL INT, V12, P440, DOI 10.1111/j.1447-0594.2011.00789.x
   Cameron S, 2007, EAR HEARING, V28, P196, DOI 10.1097/AUD.0b013e318031267f
   Cameron S, 2012, AUDIOL RES, V2, P86, DOI 10.4081/audiores.2012.e15
   Cameron S, 2011, J AM ACAD AUDIOL, V22, P697, DOI 10.3766/jaaa.22.10.7
   Ciorba A, 2012, CLIN INTERV AGING, V7, P159, DOI 10.2147/CIA.S26059
   Cohen SM, 2004, OTOLARYNG HEAD NECK, V131, P413, DOI 10.1016/j.otohns.2004.03.026
   Delphi Maryam, 2015, Med J Islam Repub Iran, V29, P231
   Garadat SN, 2009, J ACOUST SOC AM, V126, P2522, DOI 10.1121/1.3238242
   Gatehouse S, 2004, INT J AUDIOL, V43, P85, DOI 10.1080/14992020400050014
   Glyde H, 2013, J ACOUST SOC AM, V134, pEL147, DOI 10.1121/1.4812441
   Glyde H, 2011, TRENDS AMPLIF, V15, P116, DOI 10.1177/1084713811424885
   Izekenova AK, 2015, J RES MED SCI, V20, P250
   Lotfi Yones, 2016, Acta Med Iran, V54, P756
   Lotfi Y, 2016, J AUDIOL OTOL, V20, P102, DOI 10.7874/jao.2016.20.2.102
   Misurelli SM, 2012, J ACOUST SOC AM, V132, P380, DOI 10.1121/1.4725760
   MOOSSAVI A, 2017, AUDIT VESTIB RES, V26, P56
   Mousavi SM, 2015, IRAN J PUBLIC HEALTH, V44, P1717
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Noroozian M, 2012, IRAN J PSYCHIATRY BE, V6, P1
   Pichora-Fuller MK, 2003, INT J AUDIOL, V42, P67
   Rothpletz AM, 2012, J SPEECH LANG HEAR R, V55, P511, DOI 10.1044/1092-4388(2011/10-0205)
   Sander M, 2015, AGE AGEING, V44, P185, DOI 10.1093/ageing/afu189
   Sanderson WC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0121922
   Schwartz A, 2012, J ACOUST SOC AM, V132, P357, DOI 10.1121/1.4718637
   Shinn-Cunningham BG, 2005, P FOR AC CIT BUD
   Sprinzl GM, 2010, GERONTOLOGY, V56, P351, DOI 10.1159/000275062
   Stecker G. C., 2012, TRANSLATIONAL PERSPE, P383
   Stroud C, 2015, J ADOLESCENT HEALTH, V56, P127, DOI 10.1016/j.jadohealth.2014.11.012
   Tyler RS, 2009, EAR HEARING, V30, P466, DOI 10.1097/AUD.0b013e3181a61efe
   Wong LLN, 2012, DISABIL REHABIL, V34, P655, DOI 10.3109/09638288.2011.619614
   Abdollahi FZ, 2019, INDIAN J OTOLARYNGOL, V71, P1658, DOI 10.1007/s12070-019-01674-2
NR 36
TC 0
Z9 0
U1 0
U2 0
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2169-5717
EI 2169-5725
J9 HEARING BALANC COMMU
JI Hearing Balanc. Commun.
DI 10.1080/21695717.2020.1727215
EA FEB 2020
PG 5
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA KO2IY
UT WOS:000515374700001
DA 2021-02-24
ER

PT J
AU Stilp, CE
   Theodore, RM
AF Stilp, Christian E.
   Theodore, Rachel M.
TI Talker normalization is mediated by structured indexical information
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Categorization; Perceptual categorization and
   identification
ID STIMULUS VARIABILITY; SPEECH-PERCEPTION; RECOGNITION; INTEGRATION;
   STATISTICS; WORDS
AB Speech perception is challenged by indexical variability. A litany of studies on talker normalization have demonstrated that hearing multiple talkers incurs processing costs (e.g., lower accuracy, increased response time) compared to hearing a single talker. However, when reframing these studies in terms of stimulus structure, it is evident that past tests of multiple-talker (i.e., low structure) and single-talker (i.e., high structure) conditions are not representative of the graded nature of indexical variation in the environment. Here we tested the hypothesis that processing costs incurred by multiple-talker conditions would abate given increased stimulus structure. We tested this hypothesis by manipulating the degree to which talkers' voices differed acoustically (Experiment 1) and also the frequency with which talkers' voices changed (Experiment 2) in multiple-talker conditions. Listeners performed a speeded classification task for words containing vowels that varied in acoustic-phonemic ambiguity. In Experiment 1, response times progressively decreased as acoustic variability among talkers' voices decreased. In Experiment 2, blocking talkers within mixed-talker conditions led to more similar response times among single-talker and multiple-talker conditions. Neither result interacted with acoustic-phonemic ambiguity of the target vowels. Thus, the results showed that indexical structure mediated the processing costs incurred by hearing different talkers. This is consistent with the Efficient Coding Hypothesis, which proposes that sensory and perceptual processing are facilitated by stimulus structure. Defining the roles and limits of stimulus structure on speech perception is an important direction for future research.
C1 [Stilp, Christian E.] Univ Louisville, Dept Psychol & Brain Sci, 317 Life Sci Bldg, Louisville, KY 40292 USA.
   [Theodore, Rachel M.] Univ Connecticut, Dept Speech Language & Hearing Sci, 2 Alethia Dr,Unit 1085, Storrs, CT 06269 USA.
   [Theodore, Rachel M.] Univ Connecticut, Connecticut Inst Brain & Cognit Sci, 337 Mansfield Rd,Unit 1272, Storrs, CT 06269 USA.
RP Theodore, RM (corresponding author), Univ Connecticut, Dept Speech Language & Hearing Sci, 2 Alethia Dr,Unit 1085, Storrs, CT 06269 USA.; Theodore, RM (corresponding author), Univ Connecticut, Connecticut Inst Brain & Cognit Sci, 337 Mansfield Rd,Unit 1272, Storrs, CT 06269 USA.
EM rachel.theodore@uconn.edu
FU Connecticut Institute for the Brain and Cognitive Sciences; National
   Science Foundation (BCS)National Science Foundation (NSF) [1827591]
FX This research was supported by a seed grant to R.M.T. from the
   Connecticut Institute for the Brain and Cognitive Sciences and by
   National Science Foundation (BCS) grant 1827591 to R.M.T.
CR Assgari AA, 2019, J ACOUST SOC AM, V145, P1443, DOI 10.1121/1.5093638
   Assgari AA, 2015, J ACOUST SOC AM, V138, P3023, DOI 10.1121/1.4934559
   ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663
   Barlow H. B, 1961, SENS COMMUN, P53
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P206, DOI 10.3758/BF03206883
   Chodroff E, 2017, J PHONETICS, V61, P30, DOI 10.1016/j.wocn.2017.01.001
   Choi JY, 2019, COGNITION, V192, DOI 10.1016/j.cognition.2019.05.019
   Choi JY, 2018, ATTEN PERCEPT PSYCHO, V80, P784, DOI 10.3758/s13414-017-1395-5
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014
   Development Core Team R, 2016, R LANG ENV STAT COMP
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Geisler WS, 2008, ANNU REV PSYCHOL, V59, P167, DOI 10.1146/annurev.psych.58.110405.085632
   Gervain J, 2019, TRENDS NEUROSCI, V42, P56, DOI 10.1016/j.tins.2018.09.004
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kluender K. R, 2013, VOWEL INHERENT SPECT, P117
   Kluender K. R., 2019, ATTENTION PERCEPTION
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   McClelland JL, 2006, TRENDS COGN SCI, V10, P363, DOI 10.1016/j.tics.2006.06.007
   MULLENNIX JW, 1990, PERCEPT PSYCHOPHYS, V47, P379, DOI 10.3758/BF03210878
   Nusbaum HC, 1992, SPEECH PERCEPTION PR, P113
   NYGAARD LC, 1995, PERCEPT PSYCHOPHYS, V57, P989, DOI 10.3758/BF03205458
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Pisoni DB, 1997, TALKER VARIABILITY S, P9
   Simoncelli EP, 2003, CURR OPIN NEUROBIOL, V13, P144, DOI 10.1016/S0959-4388(03)00047-3
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   SOMMERS MS, 1994, J ACOUST SOC AM, V96, P1314, DOI 10.1121/1.411453
   Stilp CE, 2019, ATTEN PERCEPT PSYCHO, V81, P2037, DOI 10.3758/s13414-018-01659-3
   Stilp CE, 2010, P NATL ACAD SCI USA, V107, P12387, DOI 10.1073/pnas.0913625107
NR 35
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD JUL
PY 2020
VL 82
IS 5
BP 2237
EP 2243
DI 10.3758/s13414-020-01971-x
EA FEB 2020
PG 7
WC Psychology; Psychology, Experimental
SC Psychology
GA MH4PQ
UT WOS:000516310600002
PM 32077069
DA 2021-02-24
ER

PT J
AU Glick, HA
   Sharma, A
AF Glick, Hannah Anneli
   Sharma, Anu
TI Cortical Neuroplasticity and Cognitive Function in Early-Stage,
   Mild-Moderate Hearing Loss: Evidence of Neurocognitive Benefit From
   Hearing Aid Use
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE age-related hearing loss (ARHL); cortical visual evoked potentials
   (CVEPs); visual cross-modal re-organization; hearing aids; speech
   perception; cognition
ID INTERNATIONAL OUTCOME INVENTORY; CROSS-MODAL REORGANIZATION; VISUAL
   SPEECH-PERCEPTION; EVENT-RELATED POTENTIALS; WORKING-MEMORY;
   OLDER-ADULTS; AUDITORY-CORTEX; IOI-HA; INDIVIDUAL-DIFFERENCES; SELECTIVE
   ATTENTION
AB Age-related hearing loss (ARHL) is associated with cognitive decline as well as structural and functional brain changes. However, the mechanisms underlying neurocognitive deficits in ARHL are poorly understood and it is unclear whether clinical treatment with hearing aids may modify neurocognitive outcomes. To address these topics, cortical visual evoked potentials (CVEPs), cognitive function, and speech perception abilities were measured in 28 adults with untreated, mild-moderate ARHL and 13 age-matched normal hearing (NH) controls. The group of adults with ARHL were then fit with bilateral hearing aids and re-evaluated after 6 months of amplification use. At baseline, the ARHL group exhibited more extensive recruitment of auditory, frontal, and pre-frontal cortices during a visual motion processing task, providing evidence of cross-modal re-organization and compensatory cortical neuroplasticity. Further, more extensive cross-modal recruitment of the right auditory cortex was associated with greater degree of hearing loss, poorer speech perception in noise, and worse cognitive function. Following clinical treatment with hearing aids, a reversal in cross-modal re-organization of auditory cortex by vision was observed in the ARHL group, coinciding with gains in speech perception and cognitive performance. Thus, beyond the known benefits of hearing aid use on communication, outcomes from this study provide evidence that clinical intervention with well-fit amplification may promote more typical cortical organization and functioning and provide cognitive benefit.
C1 [Glick, Hannah Anneli; Sharma, Anu] Univ Colorado, Inst Cognit Sci, Brain & Behav Lab, Dept Speech Language & Hearing Sci,Ctr Neurosci, Boulder, CO 80309 USA.
RP Sharma, A (corresponding author), Univ Colorado, Inst Cognit Sci, Brain & Behav Lab, Dept Speech Language & Hearing Sci,Ctr Neurosci, Boulder, CO 80309 USA.
EM anu.sharma@colorado.edu
FU Hearing Industry Research Consortium
FX This research was supported by grant funding from the Hearing Industry
   Research Consortium.
CR Agrawal Y, 2008, ARCH INTERN MED, V168, P1522, DOI 10.1001/archinte.168.14.1522
   Anderson MC, 2018, J AM ACAD AUDIOL, V29, P118, DOI 10.3766/jaaa.16107
   Anderson S., 2019, HEARING J, V72, P10
   Anstey KJ, 1999, PSYCHOL AGING, V14, P605, DOI 10.1037/0882-7974.14.4.605
   Anstey KJ, 2001, GERONTOLOGY, V47, P289, DOI 10.1159/000052814
   Baltes PB, 1997, PSYCHOL AGING, V12, P12, DOI 10.1037/0882-7974.12.1.12
   Barnett M, 2017, LARYNGOSCOPE, V127, P1187, DOI 10.1002/lary.26234
   Bavelier D, 2002, NAT REV NEUROSCI, V3, P443, DOI 10.1038/nrn848
   Benedict RHB, 2017, MULT SCLER J, V23, P721, DOI 10.1177/1352458517690821
   Bertrand JA, 2012, EXP BRAIN RES, V216, P145, DOI 10.1007/s00221-011-2920-8
   Blazer D.G, 2016, HEARING HLTH CARE OL
   BROADBENT DE, 1954, J EXP PSYCHOL, V47, P191, DOI 10.1037/h0054182
   Buckley KA, 2011, EAR HEARING, V32, P2, DOI [10.1097/AUD.0b013e3181e8534c, 10.1097/AUD.0b013e3181fa41bb]
   Bucks RS, 2016, LARYNGOSCOPE, V126, P2367, DOI 10.1002/lary.25896
   Bush ALH, 2015, EAR HEARING, V36, P395, DOI 10.1097/AUD.0000000000000142
   Campbell J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147793
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   Cardon G, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00172
   Chen LC, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/4382656
   Chien W, 2012, ARCH INTERN MED, V172, P292, DOI 10.1001/archinternmed.2011.1408
   Cienkowski KM, 2002, EAR HEARING, V23, P439, DOI 10.1097/00003446-200210000-00006
   CLARK JW, 1960, J GERONTOL, V15, P183, DOI 10.1093/geronj/15.2.183
   Cox RM, 2002, INT J AUDIOL, V41, P30, DOI 10.3109/14992020209101309
   Cox RM, 2002, INT J AUDIOL, V41, P3, DOI 10.3109/14992020209101307
   Cox RM, 2001, EAR HEARING, V22, P151, DOI 10.1097/00003446-200104000-00008
   Cox RM, 1999, EAR HEARING, V20, P306, DOI 10.1097/00003446-199908000-00004
   Cox Robyn M, 2003, J Am Acad Audiol, V14, P403
   DANEMAN M, 1980, J VERB LEARN VERB BE, V19, P450, DOI 10.1016/S0022-5371(80)90312-6
   Davis A, 2007, HEALTH TECHNOL ASSES, V11, P1, DOI 10.3310/hta11420
   Deal JA, 2017, J GERONTOL A-BIOL, V72, P703, DOI 10.1093/gerona/glw069
   Deal JA, 2015, AM J EPIDEMIOL, V181, P680, DOI 10.1093/aje/kwu333
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Delorme A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030135
   Dillon H, 1997, J Am Acad Audiol, V8, P27
   Dillon H., 1999, J AM ACAD AUDIOL, V10, P67, DOI DOI 10.1097/00025572-199904000-00002
   Dorman MF, 2016, J SPEECH LANG HEAR R, V59, P1505, DOI 10.1044/2016_JSLHR-H-15-0312
   Doucet ME, 2006, BRAIN, V129, P3376, DOI 10.1093/brain/awl264
   Dupont P, 2003, EUR J NEUROSCI, V17, P1509, DOI 10.1046/j.1460-9568.2003.02571.x
   Dupuis K, 2015, AGING NEUROPSYCHOL C, V22, P413, DOI 10.1080/13825585.2014.968084
   Etymotic Research, 2001, QUICK SPEECH IN NOIS
   Fine I, 2005, J COGNITIVE NEUROSCI, V17, P1621, DOI 10.1162/089892905774597173
   Finney EM, 2003, NEUROREPORT, V14, P1425, DOI 10.1097/00001756-200308060-00004
   Ford AH, 2018, MATURITAS, V112, P1, DOI 10.1016/j.maturitas.2018.03.004
   Friedman NP, 2004, J EXP PSYCHOL GEN, V133, P101, DOI 10.1037/0096-3445.133.1.101
   Fuchs M, 2002, CLIN NEUROPHYSIOL, V113, P702, DOI 10.1016/S1388-2457(02)00030-5
   Gallacher J, 2012, NEUROLOGY, V79, P1583, DOI 10.1212/WNL.0b013e31826e263d
   Gates GA, 1996, ARCH OTOLARYNGOL, V122, P161
   Gates GA, 2010, COGN BEHAV NEUROL, V23, P218, DOI 10.1097/WNN.0b013e3181d748d7
   Gazzaley A, 2008, P NATL ACAD SCI USA, V105, P13122, DOI 10.1073/pnas.0806074105
   Gazzaley A, 2007, CEREB CORTEX, V17, pI125, DOI 10.1093/cercor/bhm113
   Glick H, 2017, HEARING RES, V343, P191, DOI 10.1016/j.heares.2016.08.012
   Grant KW, 2000, J ACOUST SOC AM, V107, P1000, DOI 10.1121/1.428280
   Grech R, 2008, J NEUROENG REHABIL, V5, DOI 10.1186/1743-0003-5-25
   Grigsby J, 2002, REHABIL PSYCHOL, V47, P291, DOI 10.1037//0090-5550.47.3.291
   GRIGSBY J, 1992, PERCEPT MOTOR SKILL, V74, P883, DOI 10.2466/PMS.74.3.883-892
   Grigsby J., 1996, BEHAV DYSCONTROL SCA
   GRIGSBY J, 2002, J CLIN GEROPSYCHOLOG, V8, P25, DOI DOI 10.1023/A:1013094023856
   Gussekloo J, 2005, AM J GERIAT PSYCHIAT, V13, P781, DOI 10.1176/appi.ajgp.13.9.781
   HACKLEY SA, 1990, PSYCHOPHYSIOLOGY, V27, P195, DOI 10.1111/j.1469-8986.1990.tb00370.x
   Hauthal N, 2013, ADV COGN PSYCHOL, V9, P53, DOI [10.2478/v10053-008-0131-z, 10.5709/acp-0131-z]
   Hofer SM, 2003, PSYCHOL AGING, V18, P285, DOI 10.1037/0882-7974.18.2.285
   Holder JT, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518755288
   Hong T, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147646
   Karawani H, 2018, NEUROPSYCHOLOGIA, V114, P203, DOI 10.1016/j.neuropsychologia.2018.04.041
   Karawani H, 2018, CLIN NEUROPHYSIOL, V129, P1254, DOI 10.1016/j.clinph.2018.03.024
   Kellermann T, 2012, J NEUROSCI, V32, P11453, DOI 10.1523/JNEUROSCI.0678-12.2012
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Klein K, 1999, BEHAV RES METH INS C, V31, P429, DOI 10.3758/BF03200722
   Kramer SE, 2002, INT J AUDIOL, V41, P36, DOI 10.3109/14992020209101310
   Lavie N, 2005, PSYCHON B REV, V12, P669, DOI 10.3758/BF03196756
   Lavie N, 2003, PERCEPT PSYCHOPHYS, V65, P202, DOI 10.3758/BF03194795
   LAVIE N, 1994, PERCEPT PSYCHOPHYS, V56, P183, DOI 10.3758/BF03213897
   LAVIE N, 1995, J EXP PSYCHOL HUMAN, V21, P451, DOI 10.1037/0096-1523.21.3.451
   Lavie N, 2004, J EXP PSYCHOL GEN, V133, P339, DOI 10.1037/0096-3445.133.3.339
   Lee DS, 2001, NATURE, V409, P149, DOI 10.1038/35051653
   Lee JY, 2008, J GERIATR PSYCH NEUR, V21, P104, DOI 10.1177/0891988708316855
   Lin FR, 2014, NEUROIMAGE, V90, P84, DOI 10.1016/j.neuroimage.2013.12.059
   Lin F. R., 2013, JAMA-J AM MED ASSOC, V25
   Lin FR, 2011, NEUROPSYCHOLOGY, V25, P763, DOI 10.1037/a0024238
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P1131, DOI 10.1093/gerona/glr115
   LINDENBERGER U, 1994, PSYCHOL AGING, V9, P339, DOI 10.1037/0882-7974.9.3.339
   Lindenberger U, 2009, PSYCHOL AGING, V24, P1, DOI 10.1037/a0014986
   Livingston G, 2017, LANCET, V390, P2673, DOI 10.1016/S0140-6736(17)31363-6
   Loughrey DG, 2018, JAMA OTOLARYNGOL, V144, P115, DOI 10.1001/jamaoto.2017.2513
   LUCK SJ, 1990, ELECTROEN CLIN NEURO, V75, P528, DOI 10.1016/0013-4694(90)90139-B
   MacDonald SWS, 2004, GERONTOLOGY, V50, P64, DOI 10.1159/000075557
   MACLEOD A, 1987, British Journal of Audiology, V21, P131, DOI 10.3109/03005368709077786
   MACLEOD A, 1990, British Journal of Audiology, V24, P29, DOI 10.3109/03005369009077840
   Makeig S, 1997, P NATL ACAD SCI USA, V94, P10979, DOI 10.1073/pnas.94.20.10979
   Mosnier I, 2015, JAMA OTOLARYNGOL, V141, P442, DOI 10.1001/jamaoto.2015.129
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   NEVILLE HJ, 1987, BRAIN RES, V405, P253, DOI 10.1016/0006-8993(87)90295-2
   Nkyekyer J, 2019, CLIN INTERV AGING, V14, P123, DOI 10.2147/CIA.S183905
   Noble W, 2002, INT J AUDIOL, V41, P27, DOI 10.3109/14992020209101308
   NORMAN DA, 1975, COGNITIVE PSYCHOL, V7, P44, DOI 10.1016/0010-0285(75)90004-3
   Obleser J, 2007, J NEUROSCI, V27, P2283, DOI 10.1523/JNEUROSCI.4663-06.2007
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P5
   PCAST, 2015, AG AM HEAR LOSS IMP
   Pichora-Fuller M Kathleen, 2006, Trends Amplif, V10, P29, DOI 10.1177/108471380601000103
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Rees G, 1997, SCIENCE, V278, P1616, DOI 10.1126/science.278.5343.1616
   RONNBERG J, 1989, J SPEECH HEAR RES, V32, P725, DOI 10.1044/jshr.3204.725
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   Rosemann S, 2018, NEUROIMAGE, V175, P425, DOI 10.1016/j.neuroimage.2018.04.023
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   Schneider J, 2010, AGE AGEING, V39, P458, DOI 10.1093/ageing/afq051
   Schwartz JL, 2004, COGNITION, V93, pB69, DOI 10.1016/j.cognition.2004.01.006
   Sharma A, 2016, OTOL NEUROTOL, V37, pE26, DOI 10.1097/MAO.0000000000000904
   Sharma A, 2015, INT J PSYCHOPHYSIOL, V95, P135, DOI 10.1016/j.ijpsycho.2014.04.007
   Smith A., 1982, SYMBOL DIGITS MODALI
   Smith SL, 2016, EAR HEARING, V37, pE360, DOI 10.1097/AUD.0000000000000329
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   Spahr AJ, 2012, EAR HEARING, V33, P112, DOI 10.1097/AUD.0b013e31822c2549
   Spence C., 2004, CROSSMODAL SPACE CRO, DOI [DOI 10.1093/ACPROF:OSO/9780198524861.001.0001, 10.1093/acprof:oso/9780198524861.001.0001]
   Stephens D, 2002, INT J AUDIOL, V41, P42, DOI 10.3109/14992020209101311
   Strelnikov K, 2013, BRAIN, V136, P3682, DOI 10.1093/brain/awt274
   Stropahl M, 2017, NEUROIMAGE-CLIN, V16, P514, DOI 10.1016/j.nicl.2017.09.001
   Stropahl M, 2015, NEUROIMAGE, V121, P159, DOI 10.1016/j.neuroimage.2015.07.062
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Thomson RS, 2017, LARYNGOSCOPE INVEST, V2, P69, DOI 10.1002/lio2.65
   Tun PA, 2012, AM J AUDIOL, V21, P344, DOI 10.1044/1059-0889(2012/12-0030)
   Turley-Ames KJ, 2003, J MEM LANG, V49, P446, DOI 10.1016/S0749-596X(03)00095-0
   Valentijn SAM, 2005, J AM GERIATR SOC, V53, P374, DOI 10.1111/j.1532-5415.2005.53152.x
   Wei JK, 2017, DEMENT GER COGN D EX, V7, P440, DOI 10.1159/000485178
   Wilson RH, 2007, J SPEECH LANG HEAR R, V50, P844, DOI 10.1044/1092-4388(2007/059)
   Wingfield A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00684
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
   Zanto TP, 2010, NEUROPSYCHOLOGIA, V48, P13, DOI 10.1016/j.neuropsychologia.2009.08.003
   Zheng YQ, 2017, NEUROL SCI, V38, P233, DOI 10.1007/s10072-016-2779-3
NR 132
TC 2
Z9 2
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD FEB 18
PY 2020
VL 14
AR 93
DI 10.3389/fnins.2020.00093
PG 22
WC Neurosciences
SC Neurosciences & Neurology
GA LG4GG
UT WOS:000528060800001
PM 32132893
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Han, JH
   Dimitrijevic, A
AF Han, Ji-Hye
   Dimitrijevic, Andrew
TI Acoustic Change Responses to Amplitude Modulation in Cochlear Implant
   Users: Relationships to Speech Perception
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE acoustic change complex; amplitude modulation; temporal modulation
   transfer function; cochlear implants; N1
ID AUDITORY-EVOKED-POTENTIALS; CORTICAL ACTIVITY; TEMPORAL CUES;
   BRAIN-STEM; RECOGNITION; FREQUENCY; DYNAMICS
AB Objectives
   The ability to understand speech is highly variable in people with cochlear implants (CIs) and to date, there are no objective measures that identify the root of this discrepancy. However, behavioral measures of temporal processing such as the temporal modulation transfer function (TMTF) has previously found to be related to vowel and consonant identification in CI users. The acoustic change complex (ACC) is a cortical auditory-evoked potential response that can be elicited by a "change" in an ongoing stimulus. In this study, the ACC elicited by amplitude modulation (AM) change was related to measures of speech perception as well as the amplitude detection threshold in CI users. Methods
   Ten CI users (mean age: 50 years old) participated in this study. All subjects participated in behavioral tests that included both speech and amplitude modulation detection to obtain a TMTF. CI users were categorized as "good" (n = 6) or "poor" (n = 4) based on their speech-in noise score (<50%). 64-channel electroencephalographic recordings were conducted while CI users passively listened to AM change sounds that were presented in a free field setting. The AM change stimulus was white noise with four different AM rates (4, 40, 100, and 300 Hz). Results
   Behavioral results show that AM detection thresholds in CI users were higher compared to the normal-hearing (NH) group for all AM rates. The electrophysiological data suggest that N1 responses were significantly decreased in amplitude and their latencies were increased in CI users compared to NH controls. In addition, the N1 latencies for the poor CI performers were delayed compared to the good CI performers. The N1 latency for 40 Hz AM was correlated with various speech perception measures. Conclusion
   Our data suggest that the ACC to AM change provides an objective index of speech perception abilities that can be used to explain some of the variation in speech perception observed among CI users.
C1 [Han, Ji-Hye; Dimitrijevic, Andrew] Cincinnati Childs Hosp Med Ctr, Commun Sci Res Ctr, Cincinnati, OH 45229 USA.
   [Han, Ji-Hye] Hallym Univ, Coll Med, Lab Brain & Cognit Sci Convergence Med, Chunchon, South Korea.
   [Dimitrijevic, Andrew] Univ Toronto, Fac Med, Dept Otolaryngol Head & Neck Surg, Sunnybrook Hlth Sci Ctr, Toronto, ON, Canada.
RP Dimitrijevic, A (corresponding author), Cincinnati Childs Hosp Med Ctr, Commun Sci Res Ctr, Cincinnati, OH 45229 USA.; Dimitrijevic, A (corresponding author), Univ Toronto, Fac Med, Dept Otolaryngol Head & Neck Surg, Sunnybrook Hlth Sci Ctr, Toronto, ON, Canada.
EM andrew.dimitrijevic@sunnybrook.ca
FU Cincinnati Children's Hospital Medical Center; National Research
   Foundation of South Korea (NRF) - Ministry of Education
   [2017R1D1A1B03030613]
FX This project was supported in part by the internal grant mechanism of
   Cincinnati Children's Hospital Medical Center and Basic Science Research
   Program through the National Research Foundation of South Korea (NRF)
   funded by the Ministry of Education (2017R1D1A1B03030613).
CR ABBAS PJ, 1991, HEARING RES, V51, P139, DOI 10.1016/0378-5955(91)90012-X
   Beynon A J, 2005, J Am Acad Audiol, V16, P42, DOI 10.3766/jaaa.16.1.5
   CAZALS Y, 1994, J ACOUST SOC AM, V96, P2048, DOI 10.1121/1.410146
   De Ruiter AM, 2015, EAR HEARING, V36, P557, DOI 10.1097/AUD.0000000000000162
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dimitrijevic A, 2008, CLIN NEUROPHYSIOL, V119, P2111, DOI 10.1016/j.clinph.2008.06.002
   Dimitrijevic A, 2013, CLIN NEUROPHYSIOL, V124, P1204, DOI 10.1016/j.clinph.2012.11.014
   Dimitrijevic A, 2011, CLIN NEUROPHYSIOL, V122, P594, DOI 10.1016/j.clinph.2010.08.005
   Dimitrijevic A, 2009, CLIN NEUROPHYSIOL, V120, P374, DOI 10.1016/j.clinph.2008.11.009
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P2670, DOI 10.1121/1.409836
   Edwards E, 2013, HEARING RES, V305, P113, DOI 10.1016/j.heares.2013.08.017
   Erb J, 2019, EAR HEARING, V40, P27, DOI 10.1097/AUD.0000000000000588
   Firszt Jill B., 2002, Ear and Hearing, V23, P516, DOI 10.1097/00003446-200212000-00003
   FITZGIBBONS PJ, 1982, J ACOUST SOC AM, V72, P761, DOI 10.1121/1.388256
   Friesen LM, 2006, EAR HEARING, V27, P678, DOI 10.1097/01.aud.0000240620.63453.c3
   Fu QJ, 2002, NEUROREPORT, V13, P1635, DOI 10.1097/00001756-200209160-00013
   Gransier R, 2020, EAR HEARING, V41, P591, DOI 10.1097/AUD.0000000000000783
   Groenen PAP, 1996, ACTA OTO-LARYNGOL, V116, P785, DOI 10.3109/00016489609137926
   Guiraud J, 2007, J NEUROSCI, V27, P7838, DOI 10.1523/JNEUROSCI.0154-07.2007
   Han JH, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00038
   Han JH, 2016, CLIN NEUROPHYSIOL, V127, P1603, DOI 10.1016/j.clinph.2015.10.049
   He SM, 2018, EAR HEARING, V39, P482, DOI 10.1097/AUD.0000000000000498
   HILLYARD SA, 1973, SCIENCE, V182, P177, DOI 10.1126/science.182.4108.177
   Hine J, 2007, CLIN NEUROPHYSIOL, V118, P1274, DOI 10.1016/j.clinph.2007.03.012
   Hirschfelder A, 2012, OTOL NEUROTOL, V33, P968, DOI 10.1097/MAO.0b013e31825e7c5d
   Hoppe U, 2001, SCAND AUDIOL, V30, P119, DOI 10.1080/010503901300112239
   Jo TG, 2017, RSC ADV, V7, P45400, DOI 10.1039/c7ra90093g
   Joris PX, 2004, PHYSIOL REV, V84, P541, DOI 10.1152/physrev.00029.2003
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Kelly AS, 2005, CLIN NEUROPHYSIOL, V116, P1235, DOI 10.1016/j.clinph.2005.02.011
   Kim JR, 2009, EAR HEARING, V30, P320, DOI 10.1097/AUD.0b013e31819c42b7
   Lazard DS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048739
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Luke R, 2015, HEARING RES, V324, P37, DOI 10.1016/j.heares.2015.02.006
   Lundin Karin, 2015, Cochlear Implants Int, V16, P254, DOI 10.1179/1754762815Y.0000000005
   Luo X, 2008, EAR HEARING, V29, P957, DOI 10.1097/AUD.0b013e3181888f61
   Martin BA, 1999, J SPEECH LANG HEAR R, V42, P271, DOI 10.1044/jslhr.4202.271
   Moberly AC, 2016, OTOL NEUROTOL, V37, P1522, DOI 10.1097/MAO.0000000000001211
   Nie K, 2006, EAR HEARING, V27, P208, DOI 10.1097/01.aud.0000202312.31837.25
   Pantev C, 2006, CEREB CORTEX, V16, P31, DOI 10.1093/cercor/bhi081
   PICTON TW, 1974, ELECTROEN CLIN NEURO, V36, P191, DOI 10.1016/0013-4694(74)90156-4
   Picton TW, 2003, INT J AUDIOL, V42, P177, DOI 10.3109/14992020309101316
   Roman S, 2004, NEUROREPORT, V15, P601, DOI 10.1097/00001756-200403220-00006
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Sandmann P, 2009, BRAIN, V132, P1967, DOI 10.1093/brain/awp034
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Small SA, 2012, EAR HEARING, V33, pE59, DOI 10.1097/AUD.0b013e31825f29be
   Stropahl M, 2017, HEARING RES, V343, P128, DOI 10.1016/j.heares.2016.07.005
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Tan C. T., 2017, P ANN INT C IEEE ENG
   Tavora-Vieira D, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193081
   Timm L, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0045375
   Tremblay K, 2007, J COMMUN DISORD, V40, P305, DOI 10.1016/j.jcomdis.2007.03.008
   Tremblay KL, 2003, EAR HEARING, V24, P225, DOI 10.1097/01.AUD.0000069229.84883.03
   VIEMEISTER NF, 1979, J ACOUST SOC AM, V66, P1364, DOI 10.1121/1.383531
   Waechter SM, 2018, HEARING RES, V359, P13, DOI 10.1016/j.heares.2017.12.005
   Won JH, 2011, J ACOUST SOC AM, V130, P376, DOI 10.1121/1.3592521
   Xu L, 2007, J ACOUST SOC AM, V122, P1758, DOI 10.1121/1.2767000
NR 58
TC 2
Z9 2
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD FEB 18
PY 2020
VL 14
AR 124
DI 10.3389/fnins.2020.00124
PG 11
WC Neurosciences
SC Neurosciences & Neurology
GA KT3TV
UT WOS:000518940300001
PM 32132897
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Shang, YY
   Hinkley, LB
   Cai, C
   Mizuiri, D
   Cheung, SW
   Nagarajan, SS
AF Shang, Yingying
   Hinkley, Leighton B.
   Cai, Chang
   Mizuiri, Danielle
   Cheung, Steven W.
   Nagarajan, Srikantan S.
TI Cross-modal plasticity in adult single-sided deafness revealed by alpha
   band resting-state functional connectivity
SO NEUROIMAGE
LA English
DT Article
DE Functional connectivity; Magnetoencephalography; Neuroimaging;
   Resting-state; Single-sided deafness
ID ACTIVATE AUDITORY-CORTEX; UNILATERAL HEARING-LOSS; CORTICAL
   REORGANIZATION; SPEECH-PERCEPTION; DEFAULT MODE; HUMAN BRAIN;
   PREVALENCE; STREAMS; FMRI; MECHANISMS
AB Single-sided deafness (SSD) or profound unilateral hearing loss is the condition where the transfer of acoustic information to the brain is restricted to one ear. SSD impairment is most evident under adverse acoustic environments with overlapping interference, which burdens cognitive resources. It is known that bilateral deafness induces cross-modal brain plasticity within visual cortical areas. Here we investigate whether similar cross-modal plasticity is observed in adult-onset SSD. In SSD patients (n = 29) and matched controls (n = 29) we estimated voxel level resting-state power and functional connectivity in the alpha band (8-12 Hz) from magnetoencephalography (MEG) data. We examined both global functional connectivity (mean functional connectivity of each voxel with the rest of the brain), and seeded functional connectivity of primary auditory cortices (Al), primary visual cortices (V1) and posterior cingulate cortex (PCC) of the default mode network (DMN). Power reduction was observed in left auditory cortex. Global functional connectivity showed reduction in frontal cortices and enhancement in visual cortex. Seeded functional connectivity of auditory cortices showed reduction in temporal, frontal and occipital regions, and enhancement in parietal cortex. Interestingly, seeded functional connectivity of visual cortices showed enhancement in visual cortices, inferior parietal lobe, post-central gyrus, and the precuneus, and reduction in auditory cortex. Seeded functional connectivity of PCC showed reduction in frontal cortical regions that are part of the DMN, attention, and working memory networks. Adult-onset SSD exhibited widespread cross-modal brain plasticity involving alterations in auditory, visual, attention, working memory and default mode networks.
C1 [Shang, Yingying] Peking Union Med Coll Hosp, Dept Otorhinolaryngol, Beijing 100730, Peoples R China.
   [Shang, Yingying; Cheung, Steven W.; Nagarajan, Srikantan S.] Univ Calif San Francisco, Dept Otolaryngol Head & Neck Surg, San Francisco, CA 94115 USA.
   [Hinkley, Leighton B.; Cai, Chang; Mizuiri, Danielle; Nagarajan, Srikantan S.] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 513 Parnassus Ave 5362, San Francisco, CA 94143 USA.
RP Shang, YY (corresponding author), Peking Union Med Coll Hosp, Dept Otorhinolaryngol, Beijing 100730, Peoples R China.; Nagarajan, SS (corresponding author), Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 513 Parnassus Ave 5362, San Francisco, CA 94143 USA.
EM yyingshang@aliyun.com; srikantan.nagarajan@ucsf.edu
FU Ministry of Education of ChinaMinistry of Education, China; Department
   of DefenseUnited States Department of Defense [W81XWH1310494,
   W81XWH1810741]; Hearing Research, Inc; Coleman Memorial Fund; NIHUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USA [R01EB022717, R01DC013979, R01NS100440, R01DC017696];
   Steven M. Bauer Research Fund;  [UCOP-MRP-17-454755]
FX This work was supported by Ministry of Education of China (Y.S.),
   Department of Defense grants W81XWH1310494 (S.W.C.) and W81XWH1810741
   (S.W.C.), Steven M. Bauer Research Fund (S.W.C.), Hearing Research, Inc
   (S.W.C.), Coleman Memorial Fund (S.W.C.), NIH grants R01EB022717
   (S.S.N), R01DC013979 (S.S.N), R01NS100440 (S.S.N) and R01DC017696
   (S.S.N), and UCOP-MRP-17-454755 (S.S.N).
CR Bilecen D, 2000, NEUROLOGY, V54, P765, DOI 10.1212/WNL.54.3.765
   BISWAL B, 1995, MAGNET RESON MED, V34, P537, DOI 10.1002/mrm.1910340409
   Burton H, 2013, OTOLARYNG HEAD NECK, V149, P492, DOI 10.1177/0194599813495179
   Burton H, 2012, BRAIN RES, V1454, P33, DOI 10.1016/j.brainres.2012.02.066
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   Chhatwal JP, 2013, NEUROLOGY, V81, P736, DOI 10.1212/WNL.0b013e3182a1aafe
   Dalal SS, 2008, NEUROIMAGE, V40, P1686, DOI 10.1016/j.neuroimage.2008.01.023
   Dalal SS, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/758973
   Ding H, 2015, BRAIN, V138, P2750, DOI 10.1093/brain/awv165
   Douglas SA, 2007, LARYNGOSCOPE, V117, P1648, DOI 10.1097/MLG.0b013e3180caa162
   Eklund A, 2016, P NATL ACAD SCI USA, V113, P7900, DOI 10.1073/pnas.1602413113
   Engel AK, 2013, NEURON, V80, P867, DOI 10.1016/j.neuron.2013.09.038
   Finney EM, 2003, NEUROREPORT, V14, P1425, DOI 10.1097/00001756-200308060-00004
   Finney EM, 2001, NAT NEUROSCI, V4, P1171, DOI 10.1038/nn763
   Firszt JB, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00108
   Fox MD, 2005, P NATL ACAD SCI USA, V102, P9673, DOI 10.1073/pnas.0504136102
   FRISTON KJ, 1993, J CEREBR BLOOD F MET, V13, P5, DOI 10.1038/jcbfm.1993.4
   Glick H, 2017, HEARING RES, V343, P191, DOI 10.1016/j.heares.2016.08.012
   Goldman RI, 2002, NEUROREPORT, V13, P2487, DOI 10.1097/00001756-200212200-00022
   Guggisberg AG, 2008, ANN NEUROL, V63, P193, DOI 10.1002/ana.21224
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hinkley LB, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3389/fnhum2015.00568, 10.3389/fnhum.2015.00568]
   Hinkley LBN, 2011, BIOL PSYCHIAT, V70, P1134, DOI 10.1016/j.biopsych.2011.06.029
   Hinkley LBN, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/neuro.09.073.2009
   Jun HJ, 2015, LARYNGOSCOPE, V125, P690, DOI 10.1002/lary.24913
   Kuo MF, 2015, NEUROSCI BULL, V31, P198, DOI 10.1007/s12264-014-1501-9
   Lara AH, 2015, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00173
   Leech R, 2014, BRAIN, V137, P12, DOI 10.1093/brain/awt162
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Liu B, 2015, AM J AUDIOL, V24, P145, DOI 10.1044/2015_AJA-13-0068
   Martino J, 2011, ANN NEUROL, V69, P521, DOI 10.1002/ana.22167
   Meredith MA, 2011, P NATL ACAD SCI USA, V108, P8856, DOI 10.1073/pnas.1018519108
   Mushiake H, 2006, NEURON, V50, P631, DOI 10.1016/j.neuron.2006.03.045
   Noble W, 2004, INT J AUDIOL, V43, P100, DOI 10.1080/14992020400050015
   Nolte G, 2004, CLIN NEUROPHYSIOL, V115, P2292, DOI 10.1016/j.clinph.2004.04.029
   Propst EJ, 2010, ARCH OTOLARYNGOL, V136, P22, DOI 10.1001/archoto.2009.208
   Pross SE, 2015, OTOL NEUROTOL, V36, P1443, DOI 10.1097/MAO.0000000000000821
   Qiao YF, 2019, NEUROIMAGE, V197, P608, DOI 10.1016/j.neuroimage.2019.05.031
   Raichle ME, 2001, P NATL ACAD SCI USA, V98, P676, DOI 10.1073/pnas.98.2.676
   Ranasinghe KG, 2014, NEUROIMAGE-CLIN, V5, P385, DOI 10.1016/j.nicl.2014.07.006
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rauschecker JP, 2000, P NATL ACAD SCI USA, V97, P11800, DOI 10.1073/pnas.97.22.11800
   Rigby PL, 1997, AM J OTOL, V18, P427
   Ross DS, 2010, EAR HEARING, V31, P126, DOI 10.1097/AUD.0b013e3181bb69db
   Scheffler K, 1998, CEREB CORTEX, V8, P156, DOI 10.1093/cercor/8.2.156
   Schmidt SA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076488
   Schmithorst VJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00164
   Schmithorst VJ, 2005, NEUROREPORT, V16, P463, DOI 10.1097/00001756-200504040-00009
   Sekihara K, 2001, IEEE T BIO-MED ENG, V48, P760, DOI 10.1109/10.930901
   Seydell-Greenwald A, 2014, NEURAL PLAST, V2014, DOI 10.1155/2014/145943
   Shang YY, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00474
   Shargorodsky J, 2010, JAMA-J AM MED ASSOC, V304, P772, DOI 10.1001/jama.2010.1124
   Sharma A, 2016, BRAIN SCI, V6, DOI 10.3390/brainsci6010004
   Shin MS, 2007, EAR HEARING, V28, p22S, DOI 10.1097/AUD.0b013e318031541b
   Strauss A, 2015, J NEUROSCI, V35, P3256, DOI 10.1523/JNEUROSCI.3357-14.2015
   Strauss A, 2014, NEUROIMAGE, V97, P387, DOI 10.1016/j.neuroimage.2014.04.005
   Tufarelli D, 2006, OTOL NEUROTOL, V27, P403, DOI 10.1097/00129492-200604000-00018
   Tyler LK, 2010, CEREB CORTEX, V20, P352, DOI 10.1093/cercor/bhp105
   Wang XC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096126
   Weisz N, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00073
   Wilsch A, 2015, CEREB CORTEX, V25, P1938, DOI 10.1093/cercor/bhu004
   Wostmann M, 2017, CEREB CORTEX, V27, P3307, DOI 10.1093/cercor/bhx074
   Wong PCM, 2010, EAR HEARING, V31, P471, DOI 10.1097/AUD.0b013e3181d709c2
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
   Zhang GY, 2016, NEUROSCIENCE, V313, P149, DOI 10.1016/j.neuroscience.2015.11.042
   Zhang GY, 2015, NEUROSCIENCE, V285, P333, DOI 10.1016/j.neuroscience.2014.11.034
   Zhang HY, 2010, RADIOLOGY, V256, P598, DOI 10.1148/radiol.10091701
NR 67
TC 1
Z9 1
U1 2
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD FEB 15
PY 2020
VL 207
AR 116376
DI 10.1016/j.neuroimage.2019.116376
PG 9
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA KG0WN
UT WOS:000509662600012
PM 31756519
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Sabic, E
   Henning, D
   Myuz, H
   Morrow, A
   Hout, MC
   MacDonald, JA
AF Sabic, Edin
   Henning, Daniel
   Myuz, Hunter
   Morrow, Audrey
   Hout, Michael C.
   MacDonald, Justin A.
TI Examining the Role of Eye Movements During Conversational Listening in
   Noise
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE hearing impairment (HI); eye gaze behavior; oculomotor; SNR
   (Signal-to-Noise Ratio); auditory - visual perception
ID SPEECH-PERCEPTION; VISUAL-ATTENTION; HEARING-LOSS; AUDIOVISUAL
   INTEGRATION; CUES; AGE; INTELLIGIBILITY; RECEPTION; COVERT; ADULTS
AB Speech comprehension is often thought of as an entirely auditory process, but both normal hearing and hearing-impaired individuals sometimes use visual attention to disambiguate speech, particularly when it is difficult to hear. Many studies have investigated how visual attention (or the lack thereof) impacts the perception of simple speech sounds such as isolated consonants, but there is a gap in the literature concerning visual attention during natural speech comprehension. This issue needs to be addressed, as individuals process sounds and words in everyday speech differently than when they are separated into individual elements with no competing sound sources or noise. Moreover, further research is needed to explore patterns of eye movements during speech comprehension - especially in the presence of noise - as such an investigation would allow us to better understand how people strategically use visual information while processing speech. To this end, we conducted an experiment to track eye-gaze behavior during a series of listening tasks as a function of the number of speakers, background noise intensity, and the presence or absence of simulated hearing impairment. Our specific aims were to discover how individuals might adapt their oculomotor behavior to compensate for the difficulty of the listening scenario, such as when listening in noisy environments or experiencing simulated hearing loss. Speech comprehension difficulty was manipulated by simulating hearing loss and varying background noise intensity. Results showed that eye movements were affected by the number of speakers, simulated hearing impairment, and the presence of noise. Further, findings showed that differing levels of signal-to-noise ratio (SNR) led to changes in eye-gaze behavior. Most notably, we found that the addition of visual information (i.e. videos vs. auditory information only) led to enhanced speech comprehension - highlighting the strategic usage of visual information during this process.
C1 [Sabic, Edin; Henning, Daniel; Myuz, Hunter; Morrow, Audrey; Hout, Michael C.; MacDonald, Justin A.] New Mexico State Univ, Dept Psychol, Hearing Enhancement & Augmented Real Lab, Las Cruces, NM 88003 USA.
RP Sabic, E (corresponding author), New Mexico State Univ, Dept Psychol, Hearing Enhancement & Augmented Real Lab, Las Cruces, NM 88003 USA.
EM sabic@nmsu.edu
OI Morrow, Audrey/0000-0001-9143-0708
FU National Institute on Deafness and Other Communication Disorders (NIDCD)
   of the National Institutes of HealthUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute on Deafness & Other Communication Disorders (NIDCD)
   [SC1DC016452]
FX Research reported in this publication was supported by the National
   Institute on Deafness and Other Communication Disorders (NIDCD) of the
   National Institutes of Health under award number SC1DC016452. 100% of
   this research project was funded with Federal Money. The content is
   solely the responsibility of the authors and does not necessarily
   represent the official views of the National Institutes of Health.
CR Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Altieri NA, 2011, J ACOUST SOC AM, V130, P1, DOI 10.1121/1.3593376
   Andersen TS, 2009, SPEECH COMMUN, V51, P184, DOI 10.1016/j.specom.2008.07.004
   Aparicio M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00426
   Arvin B, 2013, INDIAN J OTOLARYNGOL, V65, pS480, DOI 10.1007/s12070-011-0356-x
   Belopolsky AV, 2009, PSYCHOL SCI, V20, P1340, DOI 10.1111/j.1467-9280.2009.02445.x
   Bronkhorst AW, 2000, ACUSTICA, V86, P117
   Buchan JN, 2011, PERCEPTION, V40, P1164, DOI 10.1068/p6939
   Buchan JN, 2008, BRAIN RES, V1242, P162, DOI 10.1016/j.brainres.2008.06.083
   Chen TH, 2004, PERCEPT PSYCHOPHYS, V66, P820, DOI 10.3758/BF03194976
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   Desloge JG, 2010, J ACOUST SOC AM, V128, P342, DOI 10.1121/1.3436522
   Drennan WR, 2003, J ACOUST SOC AM, V114, P2178, DOI 10.1121/1.1609994
   Drullman R, 2000, J ACOUST SOC AM, V107, P2224, DOI 10.1121/1.428503
   Etymotic Research, 2001, QUICKSIN SPEECH NOIS
   Frischen A, 2007, PSYCHOL BULL, V133, P694, DOI 10.1037/0033-2909.133.4.694
   Frisina RD, 2009, ANN NY ACAD SCI, V1170, P708, DOI 10.1111/j.1749-6632.2009.03931.x
   Gailey L., 1987, HEARING EYE PSYCHOL, P115
   Gordon-Salant S, 2005, J REHABIL RES DEV, V42, P9, DOI 10.1682/JRRD.2005.01.0006
   Gurler D, 2015, ATTEN PERCEPT PSYCHO, V77, P1333, DOI 10.3758/s13414-014-0821-1
   Hout MC, 2015, J EXP PSYCHOL HUMAN, V41, P977, DOI 10.1037/xhp0000053
   Iversen JR, 2015, COGNITION, V134, P232, DOI 10.1016/j.cognition.2014.10.018
   JUST MA, 1976, COGNITIVE PSYCHOL, V8, P441, DOI 10.1016/0010-0285(76)90015-3
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Lee JY, 2015, J AUDIOL OTOL, V19, P7, DOI 10.7874/jao.2015.19.1.7
   Lewis D, 2010, EAR HEARING, V31, P761, DOI 10.1097/AUD.0b013e3181e5d188
   Lusk LG, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00052
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MORAY N, 1959, Q J EXP PSYCHOL, V11, P56, DOI 10.1080/17470215908416289
   Parasov Z., 2008, IUI 08, P1
   Pichora-Fuller MK, 2003, INT J AUDIOL, V42, pS59
   Pomper U, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04475-1
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   Riggio L, 1997, PERCEPT PSYCHOPHYS, V59, P885, DOI 10.3758/BF03205506
   Rosenblum LD, 1996, J SPEECH HEAR RES, V39, P1159, DOI 10.1044/jshr.3906.1159
   Stuart A, 2014, AM J AUDIOL, V23, P227, DOI 10.1044/2014_AJA-14-0005
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Taitelbaum-Swead R, 2016, FOLIA PHONIATR LOGO, V68, P16, DOI 10.1159/000444749
   Tas AC, 2016, J EXP PSYCHOL HUMAN, V42, P1121, DOI 10.1037/xhp0000212
   Tharpe AM, 2008, J AM ACAD AUDIOL, V19, P741, DOI 10.3766/jaaa.19.10.2
   Thomas SM, 2004, J EXP PSYCHOL HUMAN, V30, P873, DOI 10.1037/0096-1523.30.5.873
   Tiippana K, 2004, EUR J COGN PSYCHOL, V16, P457, DOI 10.1080/09541440340000268
   TREISMAN A, 1974, MEM COGNITION, V2, P641, DOI 10.3758/BF03198133
   TREISMAN AM, 1960, Q J EXP PSYCHOL, V12, P242, DOI 10.1080/17470216008416732
   Tye-Murray N, 2007, EAR HEARING, V28, P656, DOI 10.1097/AUD.0b013e31812f7185
   Vatikiotis-Bateson E, 1998, PERCEPT PSYCHOPHYS, V60, P926, DOI 10.3758/BF03211929
   Wendt D, 2015, TRENDS HEAR, V19, DOI 10.1177/2331216515584149
   Yamasoba T, 2013, HEARING RES, V303, P30, DOI 10.1016/j.heares.2013.01.021
NR 50
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD FEB 14
PY 2020
VL 11
AR 200
DI 10.3389/fpsyg.2020.00200
PG 11
WC Psychology, Multidisciplinary
SC Psychology
GA KR3NJ
UT WOS:000517524800001
PM 32116975
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Suarez-Coalla, P
   Martinez-Garcia, C
   Carnota, A
AF Suarez-Coalla, Paz
   Martinez-Garcia, Cristina
   Carnota, Andres
TI Reading in English as a Foreign Language by Spanish Children With
   Dyslexia
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE English as a foreign language; dyslexia; reading; Spanish; children
ID VISUAL WORD RECOGNITION; PHONOLOGICAL REPRESENTATIONS; DEVELOPMENTAL
   DYSLEXIA; SPEECH-PERCEPTION; LEARNING ENGLISH; SKILLS; ACQUISITION;
   DIFFICULTIES; LITERACY; READERS
AB It has been reported that children with dyslexia have difficulties with learning a second language. The English alphabetic code is opaque, and it has been stated that deep orthographies cause important problems in children with dyslexia. Considering the strong differences between the Spanish and English orthographic systems, we predicted English reading problems in Spanish-speaking children with dyslexia. The current study focused on English as a foreign language in a group of 22 Spanish children with dyslexia (8-12 year olds), compared to a control group matched for age, gender, grade, and socioeconomic status. The objective was to identify the main difficulties that Spanish-speaking children with dyslexia demonstrate during English reading, to develop specific teaching programs. Participants were given four tasks related to reading: discrimination of phonemes, visual lexical decision, reading aloud, and oral vs. written semantic classification. The results suggest that children with dyslexia demonstrate problems in using English grapheme-phoneme rules, forcing them to employ a lexical strategy to read English words. However, they also showed difficulties in developing orthographic representations of words. Finally, they also exhibited problems with oral language, demonstrating difficulties accessing semantic information from an auditory presentation.
C1 [Suarez-Coalla, Paz; Martinez-Garcia, Cristina; Carnota, Andres] Univ Oviedo, Dept Psychol, Oviedo, Spain.
RP Suarez-Coalla, P (corresponding author), Univ Oviedo, Dept Psychol, Oviedo, Spain.
EM suarezpaz@uniovi.es
RI Suarez-Coalla, Paz/N-2032-2019
OI Suarez-Coalla, Paz/0000-0001-9772-2680
FU Spanish GovernmentSpanish GovernmentEuropean Commission
   [PSI2015-64174-P]
FX This work was supported by the Spanish Government through the grant
   PSI2015-64174-P (MINECO).
CR Adams M., 1990, BEGINNING READ THINK
   Afonso O, 2020, J LEARN DISABIL-US, V53, P109, DOI 10.1177/0022219419876255
   Ahissar M, 2000, P NATL ACAD SCI USA, V97, P6832, DOI 10.1073/pnas.97.12.6832
   Alvarez-Canizo M, 2018, J CHILD LANG, V45, P858, DOI 10.1017/S0305000917000514
   AUGUST DA, 2001, NABE NEWS, V11, P42
   Baayen R.H., 2008, ANAL LINGUISTIC DATA
   Balota DA, 2007, BEHAV RES METHODS, V39, P445, DOI 10.3758/BF03193014
   Beattie RL, 2013, J LEARN DISABIL-US, V46, P200, DOI 10.1177/0022219412449421
   Boets B, 2006, BRAIN LANG, V97, P64, DOI 10.1016/j.bandl.2005.07.026
   Bonifacci P, 2017, DYSLEXIA, V23, P181, DOI 10.1002/dys.1553
   BOWEY JA, 1995, J EDUC PSYCHOL, V87, P476, DOI 10.1037/0022-0663.87.3.476
   BRUCK M, 1992, DEV PSYCHOL, V28, P874, DOI 10.1037/0012-1649.28.5.874
   Burani C, 2002, BRAIN LANG, V81, P568, DOI 10.1006/brln.2001.2548
   Cao F, 2006, J CHILD PSYCHOL PSYC, V47, P1041, DOI 10.1111/j.1469-7610.2006.01684.x
   Casalis S., 2015, WRITING SYSTEMS RES, V7, P186, DOI DOI 10.1080/17586801.2014.976165
   Catts H. W., 1999, SCI STUD READ, V3, P331, DOI DOI 10.1207/S1532799XSSR0304_2
   Chodkiewicz H., 1986, SPRAWNOSCI CZYTANIA
   Chung KKH, 2010, J LEARN DISABIL-US, V43, P195, DOI 10.1177/0022219409345018
   CISERO CA, 1995, CONTEMP EDUC PSYCHOL, V20, P275, DOI 10.1006/ceps.1995.1018
   Clements-Stephens AM, 2012, DEV COGN NEUROS-NETH, V2, pS99, DOI 10.1016/j.dcn.2011.06.001
   Coltheart M, 2001, PSYCHOL REV, V108, P204, DOI 10.1037//0033-295X.108.1.204
   COLTHEART M, 1994, J EXP PSYCHOL HUMAN, V20, P1197, DOI 10.1037/0096-1523.20.6.1197
   Comeau L, 1999, J EDUC PSYCHOL, V91, P29, DOI 10.1037/0022-0663.91.1.29
   Commissaire E., 2012, ORTHOGRAPHIC PHONOLO
   Constantinidou M, 2009, EDUC PSYCHOL-UK, V29, P171, DOI 10.1080/01443410802613483
   Crombie M A, 2000, Dyslexia, V6, P112
   Cuetos F., 2007, PROLEC R BATERIA EVA
   Cuetos F, 2018, SCI STUD READ, V22, P41, DOI 10.1080/10888438.2017.1359273
   Cuetos F, 2009, APPL PSYCHOLINGUIST, V30, P583, DOI 10.1017/S0142716409990038
   Cunningham AE, 2006, J EXP CHILD PSYCHOL, V95, P56, DOI 10.1016/j.jecp.2006.03.008
   DAFONTOURA HA, 1995, READ WRIT, V7, P139, DOI 10.1007/BF01026951
   Davies R, 2007, ANN DYSLEXIA, V57, P179, DOI 10.1007/s11881-007-0010-1
   Davies R, 2013, READ WRIT, V26, P721, DOI 10.1007/s11145-012-9388-1
   De Jong P.F., 2002, SCI STUD READ, V6, P51, DOI [DOI 10.1207/S1532799XSSR0601_03, 10.1207/S1532799XSSR0601_03]
   Dijkstra T, 2002, BILING-LANG COGN, V5, P175, DOI 10.1017/S1366728902003012
   Dufva M, 1999, APPL PSYCHOLINGUIST, V20, P329, DOI 10.1017/S014271649900301X
   DURGUNOGLU AY, 1993, J EDUC PSYCHOL, V85, P453, DOI 10.1037/0022-0663.85.3.453
   EHRI LC, 1995, READ WRIT, V7, P295, DOI 10.1007/BF03162082
   EHRI LC, 1979, CHILD DEV, V50, P675, DOI 10.2307/1128932
   EHRI LC, 1987, J READING BEHAV, V19, P5, DOI 10.1080/10862968709547585
   Ehri LC, 1998, WORD RECOGNITION IN BEGINNING LITERACY, P3
   Elbro C, 1996, READ WRIT, V8, P453, DOI 10.1007/BF00577023
   Elston-Guttler KE, 2005, J COGNITIVE NEUROSCI, V17, P1593, DOI 10.1162/089892905774597245
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   Geva E., 1997, SCI STUD READ, V1, P119, DOI [10.1207/s1532799xssr0102_2, DOI 10.1207/S1532799XSSR0102_2]
   Goswami U, 2002, ANN DYSLEXIA, V52, P141
   Goswami U, 2001, J MEM LANG, V45, P648, DOI 10.1006/jmla.2001.2790
   Goswami U., 1990, PHONOLOGICAL SKILLS
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Grainger J, 2003, BRAIN LANG, V87, P432, DOI 10.1016/S0093-934X(03)00145-7
   Helland T, 2005, DYSLEXIA, V11, P41, DOI 10.1002/dys.286
   Ho CSH, 2005, J PSYCHOLINGUIST RES, V34, P603, DOI 10.1007/s10936-005-9166-1
   HOGABOAM TW, 1978, J EDUC PSYCHOL, V70, P717, DOI 10.1037/0022-0663.70.5.717
   Huo SD, 2019, ADV SCI, V6, DOI 10.1002/advs.201900043
   Jared D, 2001, J MEM LANG, V44, P2, DOI 10.1006/jmla.2000.2747
   Kahn-Horwitz J, 2006, ANN DYSLEXIA, V56, P161, DOI 10.1007/s11881-006-0007-1
   Kyte CS, 2006, J EXP CHILD PSYCHOL, V93, P166, DOI 10.1016/j.jecp.2005.09.003
   Lallier M, 2018, PSYCHON B REV, V25, P386, DOI 10.3758/s13423-017-1273-0
   Lockiewicz M, 2016, LEARN INDIVID DIFFER, V51, P256, DOI 10.1016/j.lindif.2016.08.037
   Lund K, 1996, BEHAV RES METH INSTR, V28, P203, DOI 10.3758/BF03204766
   Lyon GR, 2003, ANN DYSLEXIA, V53, P1, DOI 10.1007/s11881-003-0001-9
   Maloney E, 2009, Q J EXP PSYCHOL, V62, P858, DOI 10.1080/17470210802578385
   MANIS FR, 1985, J EDUC PSYCHOL, V77, P78, DOI 10.1037/0022-0663.77.1.78
   Marks J., 2007, ENGLISH PRONUNCIATIO
   Martens VEG, 2008, J RES READ, V31, P40, DOI 10.1111/j.1467-9817.2007.00360.x
   Martinez-Garcia C, 2019, ANN DYSLEXIA, V69, P186, DOI 10.1007/s11881-019-00178-6
   Miller-Guron L, 2000, READ WRIT, V12, P41, DOI 10.1023/A:1008009703641
   MORAIS J, 1991, PHONOLOGICAL PROCESSES IN LITERACY, P5
   Nijakowska J., 2010, DYSLEXIA FOREIGN LAN
   Oren R, 2005, J NEUROLINGUIST, V18, P127, DOI 10.1016/j.jneuroling.2004.11.003
   Palladino P, 2013, DYSLEXIA, V19, P165, DOI 10.1002/dys.1456
   PERFETTI CA, 1987, MERRILL PALMER QUART, V33, P283
   Peterson RL, 2012, LANCET, V379, P1997, DOI 10.1016/S0140-6736(12)60198-6
   Protopapas A, 2007, BEHAV RES METHODS, V39, P859, DOI 10.3758/BF03192979
   R Core Team, 2016, R LANG ENV STAT COMP
   Ramos J. L., 2005, BATERIA EVALUACION P
   REITSMA P, 1983, J EXP CHILD PSYCHOL, V36, P321, DOI 10.1016/0022-0965(83)90036-X
   Reitsma P., 1989, READING WRITING DISO, P51
   Ricketts J, 2007, SCI STUD READ, V11, P235, DOI 10.1080/10888430701344306
   SCANLON DM, 2000, ANN M AM ED RES ASS
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   Serrano F, 2008, ANN DYSLEXIA, V58, P81, DOI 10.1007/s11881-008-0013-6
   Seymour PHK, 2003, BRIT J PSYCHOL, V94, P143, DOI 10.1348/000712603321661859
   Share DL, 1999, J EXP CHILD PSYCHOL, V72, P95, DOI 10.1006/jecp.1998.2481
   SHARE DL, 1995, COGNITION, V55, P151, DOI 10.1016/0010-0277(94)00645-2
   SIEGEL LS, 1995, PSYCHOL SCI, V6, P250, DOI 10.1111/j.1467-9280.1995.tb00601.x
   Snowling M., 2000, DYSLEXIA
   Soroli E, 2010, DYSLEXIA, V16, P318, DOI 10.1002/dys.415
   Sparks RL, 2012, READ WRIT, V25, P1599, DOI 10.1007/s11145-011-9335-6
   Sparks RL, 1999, J LEARN DISABIL, V32, P566, DOI 10.1177/002221949903200608
   STANOVICH KE, 1994, J EDUC PSYCHOL, V86, P24, DOI 10.1037/0022-0663.86.1.24
   Suarez-Coalla P, 2016, J RES READ, V39, P292, DOI 10.1111/1467-9817.12043
   Suarez-Coalla P, 2015, ANN DYSLEXIA, V65, P33, DOI 10.1007/s11881-015-0101-3
   Suarez-Coalla P, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01409
   Suarez-Coalla P, 2014, ANN DYSLEXIA, V64, P166, DOI 10.1007/s11881-014-0092-5
   Suarez-Coalla P, 2012, ANN DYSLEXIA, V62, P71, DOI 10.1007/s11881-011-0064-y
   Van Wijnendaele I, 2002, J EXP PSYCHOL HUMAN, V28, P616, DOI 10.1037//0096-1523.28.3.616
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   WAGNER RK, 1987, PSYCHOL BULL, V101, P192, DOI 10.1037/0033-2909.101.2.192
   Walley AC., 2003, READING WRITING, V16, P5, DOI [DOI 10.1023/A:1021789804977, 10.1023/A:1021789804977]
   Wang HC, 2013, SCI STUD READ, V17, P369, DOI 10.1080/10888438.2012.749879
   Wang HC, 2012, Q J EXP PSYCHOL, V65, P856, DOI 10.1080/17470218.2012.672996
   Wechsler D, 2001, WECHSLER INTELLIGENC
   WIMMER H, 1993, APPL PSYCHOLINGUIST, V14, P1, DOI 10.1017/S0142716400010122
   WIMMER H, 1994, COGNITION, V51, P91, DOI 10.1016/0010-0277(94)90010-8
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
NR 107
TC 0
Z9 0
U1 4
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD FEB 14
PY 2020
VL 11
AR 19
DI 10.3389/fpsyg.2020.00019
PG 13
WC Psychology, Multidisciplinary
SC Psychology
GA KR3MZ
UT WOS:000517523800001
PM 32116890
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Bye, P
AF Bye, Patrik
TI Expressive Sibilant Retraction in North Norwegian: morpheme or 'spoken
   gesture'?
SO GLOSSA-A JOURNAL OF GENERAL LINGUISTICS
LA English
DT Article
DE spoken gesture; iconicity; marginal contrast; North Germanic dialects;
   techniques of representation; metonymy
ID SPEECH-PERCEPTION; CUMMINGS,E.E.
AB North Norwegian has a contrast between /s/ and /s/ that is neutralized in word-initial position before a consonant, and an optional process of Expressive Sibilant Retraction (ESR), which changes /s/ to [s] in precisely the environment where the contrast is neutralized (Broch 1927). ESR appears ambiguous between a word formation process and a spoken gesture (Okrent 2002; Perlman et al. 2015). On the one hand, ESR exploits givens of phonological structure. On the other, treating it as a morphological process entails claiming that the spell-out of certain ("expressive") morphemes may take place after phonological processes have applied, or that the realization of these morphemes takes precedence to phonological constraints. I argue that ESR is a communicative (i.e. non-linguistic, or post-linguistic) spoken gesture that nonetheless exploits the suspension of phonological generalizations in a way that directs attention to its iconic function. I describe the varied interpretations that ESR has depending on whether it indexes an action/event, object, or state/property, and propose that these share a common semantic core. This gesture-based account of ESR is offered as a possible model for "expressive phonology" (e.g. Diffloth 1979) in other languages.
C1 [Bye, Patrik] Nord Univ, Bodo, Norway.
RP Bye, P (corresponding author), Nord Univ, Bodo, Norway.
EM patrik.bye@nord.no
CR Bavelas Janet, 2014, GESTURE CONVERSATION, P15, DOI 10.1075/z.188.02bav
   Benua Laura, 1999, U MARYLAND WORKING P, V8, P1
   Brekke Olga, 2000, SALTENDIALEKTEN GRAM
   Broch Olaf, 1927, FESTSKRIFT HJALMAR F, P1
   Bye Patrik, 2012, MORPHOLOGY PHONOLOGY, P427, DOI DOI 10.1093/ACPROF:OSO/9780199573721.003.0013
   Bye Patrik, 2013, NORDLYD, V40, P41, DOI [10.7557/12.2500, DOI 10.7557/12.2500]
   Christiansen Hallfrid, 1946, NORSKE DIALEKTER 2 3
   Christiansen Hallfrid, 1933, GIMSOY MALET FONOLOG
   CURETON RD, 1979, POETICS TODAY, V1, P213, DOI 10.2307/1772048
   CURETON RD, 1981, LANG STYLE, V14, P183
   Debras C, 2017, GESTURE, V16, P1, DOI 10.1075/gest.16.1.01deb
   Diffloth Gerard, 1979, STUDIES TAI MON KHME, P49
   Digonnet Rene, 2018, SENSORY PERCEPTIONS, P177, DOI [10.1007/978-3-319-91277-6_10, DOI 10.1007/978-3-319-91277-6_10]
   Dragoy Trond, 2001, NORD NORSKE DIALEKTO
   Ekman P., 1997, INNOVATIONS SOCIAL S, V10, P333, DOI [10.1080/13511610.1997.9968538, DOI 10.1080/13511610.1997.9968538]
   Elstad Kare, 1982, NORDNORSK SPRAKARV S, P9
   Endresen Rolf Theil, 1991, FONETIKK EI ELEMENTA
   Endresen Rolf Theil, 1985, NORSK LINGVISTISK TI, V3, P65
   Feist J, 2013, J PRAGMATICS, V45, P104, DOI 10.1016/j.pragma.2012.10.008
   Fillmore Charles John, 1970, READINGS ENGLISH TRA, P120
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   Fromkin V. A., 1978, TONE LINGUISTIC SURV, P5, DOI DOI 10.1353/LAN.1980.0007
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Haugen Einar, 1976, SCANDINAVIAN LANGUAG
   Haugen Einar, 1942, NORWEGIAN PUBLICATIO, V57, P879, DOI [10.2307/458776, DOI 10.2307/458776]
   Iversen Ragnvald, 1918, SYNTAKSEN TROMSO BYM
   Jahr Ernst Hakon, 1985, 6 INT C HIST LING PO, P290, DOI [10.1075/cilt.34.21jah, DOI 10.1075/CILT.34.21JAH]
   Jahr Ernst Hakon, 1996, NORDNORSKE DIALEKTAR
   Jakobson R., 1960, STYLE LANGUAGE, P350
   Johnsen SS, 2012, NORD J LINGUIST, V35, P197, DOI 10.1017/S0332586512000194
   Jones Daniel, 1967, OUTLINE ENGLISH PHON
   Kendon A, 2017, GESTURE, V16, P157, DOI 10.1075/gest.16.2.01ken
   Kendon Adam, 2004, GESTURE VISIBLE ACTI, DOI [10.1017/CBO9780511807572, DOI 10.1017/CBO9780511807572]
   Kristoffersen G., 2000, PHONOLOGY NORWEGIAN
   Larsen A. B., 1907, KRISTIANIA BYMAL VUL
   Levin B., 1993, ENGLISH VERB CLASSES
   McCarthy John J., 2008, DOING OPTIMALITY THE, DOI [10.1002/9781444301182, DOI 10.1002/9781444301182]
   Nesse Agnete, 2008, BYDIALEKT RIKSMAL ID
   Ochs Elinor, 1989, TEXT, V1, P7, DOI DOI 10.1515/TEXT.1.1989.9.1.7
   Okrent A., 2002, MODALITY STRUCTURE S, P175, DOI DOI 10.1017/CBO9780511486777.009
   Papazian Erik, 2005, NORSK TALEMAL LOKAL
   Paster M., 2006, THESIS
   Perlman M, 2015, COGNITIVE SCI, V39, P1348, DOI 10.1111/cogs.12190
   Poyatos Fernando, 1993, PARALANGUAGE LINGUIS, DOI [10.1075/CILT.92, DOI 10.1075/CILT.92]
   Poyatos Fernando, 2002, NONVERBAL COMMUNICAT, V2, DOI [10.1075/Z.NCAD2, DOI 10.1075/Z.NCAD2]
   Prince A., 2004, OPTIMALITY THEORY CO, DOI [10.1002/9780470759400, DOI 10.1002/9780470759400]
   Rummer R, 2014, EMOTION, V14, P246, DOI 10.1037/a0035752
   Sandoy Helge, 1996, TALEMAL
   Selkirk Elisabeth O., 2011, HDB PHONOLOGICAL THE, P550, DOI [DOI 10.1002/9781444343069.CH14, 10.1002/9781444343069.ch14]
   Shintel H, 2006, J MEM LANG, V55, P167, DOI 10.1016/j.jml.2006.03.002
   Sidhu DM, 2018, PSYCHON B REV, V25, P1619, DOI 10.3758/s13423-017-1361-1
   Simonsen HG, 2004, CLIN LINGUIST PHONET, V18, P605, DOI 10.1080/02699200410001703664
   Sivertsen Eva, 1967, FONOLOGI
   Skjekkeland Martin, 2005, DIALEKTAR NOREG TRAD
   STEVENS KN, 1989, LANGUAGE, V65, P81, DOI 10.2307/414843
   Trager G.L., 1958, STUD LINGUIST, V13, P1
   Vainio L, 2018, Q J EXP PSYCHOL, V71, P2129, DOI 10.1177/1747021817738732
NR 57
TC 0
Z9 0
U1 0
U2 0
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 2397-1835
J9 GLOSSA-UK
JI Glossa
PD FEB 13
PY 2020
VL 5
IS 1
AR 10
DI 10.5334/gjgl.850
PG 26
WC Linguistics; Language & Linguistics
SC Linguistics
GA KP9CN
UT WOS:000516526500001
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Villar-Rodriguez, E
   Palomar-Garcia, MA
   Hernandez, M
   Adrian-Ventura, J
   Olcina-Sempere, G
   Parcet, MA
   Avila, C
AF Villar-Rodriguez, Esteban
   Palomar-Garcia, Maria-Angeles
   Hernandez, Mireia
   Adrian-Ventura, Jesus
   Olcina-Sempere, Gustau
   Parcet, Maria-Antonia
   Avila, Cesar
TI Left-handed musicians show a higher probability of atypical cerebral
   dominance for language
SO HUMAN BRAIN MAPPING
LA English
DT Article
DE functional laterality; hemispheric language dominance; lateralization;
   left-handedness; musicians
ID SURFACE-BASED ANALYSIS; HESCHLS GYRUS; HEMISPHERIC-ASYMMETRY; CORTICAL
   THICKNESS; SPEECH-PERCEPTION; PLANUM TEMPORALE; FUNCTIONAL MRI; BROCAS
   AREA; LATERALIZATION; HEALTHY
AB Music processing and right hemispheric language lateralization share a common network in the right auditory cortex and its frontal connections. Given that the development of hemispheric language dominance takes place over several years, this study tested whether musicianship could increase the probability of observing right language dominance in left-handers. Using a classic fMRI language paradigm, results showed that atypical lateralization was more predominant in musicians (40%) than in nonmusicians (5%). Comparison of left-handers with typical left and atypical right lateralization revealed that: (a) atypical cases presented a thicker right pars triangularis and more gyrified left Heschl's gyrus; and (b) the right pars triangularis of atypical cases showed a stronger intra-hemispheric functional connectivity with the right angular gyrus, but a weaker interhemispheric functional connectivity with part of the left Broca's area. Thus, musicianship is the first known factor related to a higher prevalence of atypical language dominance in healthy left-handed individuals. We suggest that differences in the frontal and temporal cortex might act as shared predisposing factors to both musicianship and atypical language lateralization.
C1 [Villar-Rodriguez, Esteban; Palomar-Garcia, Maria-Angeles; Adrian-Ventura, Jesus; Olcina-Sempere, Gustau; Parcet, Maria-Antonia; Avila, Cesar] Jaume I Univ, Neuropsychol & Funct Neuroimaging Grp, Edificio Invest 2, Castellon De La Plana, Spain.
   [Hernandez, Mireia] Univ Barcelona, Inst Neurociencies, Cognit & Brain Plastic Grp, Dept Cognit Dev & Educ Psychol, Barcelona, Spain.
RP Villar-Rodriguez, E (corresponding author), Edificio Invest 2,Avda Sos Baynat S-N, E-12071 Castellon De La Plana, Spain.
EM esvillar@uji.es
RI Avila, Cesar/B-4370-2011; Palomar-Garcia, Maria-Angeles/T-4758-2017;
   Hernandez, Mireia/D-6812-2014; Adrian-Ventura, Jesus/AAQ-1748-2020
OI Avila, Cesar/0000-0002-5840-605X; Palomar-Garcia,
   Maria-Angeles/0000-0003-4745-9612; Hernandez,
   Mireia/0000-0001-6819-3636; Adrian-Ventura, Jesus/0000-0002-0912-5139;
   Olcina-Sempere, Gustau/0000-0001-8655-9945; Villar-Rodriguez,
   Esteban/0000-0001-9691-3776
FU Spanish Ministry of Economy and Competitiveness [PSI2016-78805-R];
   National FPUNational Health and Medical Research Council of Australia;
   Jaume I University; Ramon y Cajal Research Program of the Spanish
   Ministry of Science, Innovation, and Universities [RYC-2016-19477]
FX We thank all of our participants for their collaboration in this study,
   as well as the radiographers at the clinic ASCIRES-ERESA Campanar for
   their help during data acquisition. This work was supported by the
   Spanish Ministry of Economy and Competitiveness (PSI2016-78805-R).
   Authors E.V.-R. and J.A.-V. were supported by predoctoral graduate
   program grants (National FPU). Author M.-A.P.-G. was supported by a
   postdoctoral graduate program grant (Jaume I University). Author M.H.
   was supported by the Ramon y Cajal Research Program of the Spanish
   Ministry of Science, Innovation, and Universities (RYC-2016-19477).
CR AGGLETON JP, 1994, PSYCHOL MUSIC, V22, P148, DOI DOI 10.1177/0305735694222004
   Auer T., 2009, NEUROIMAGE, V47, pS102, DOI [10.1016/S1053-8119(09)70881-X, DOI 10.1016/S1053-8119(09)70881-X]
   Benner J, 2017, BRAIN STRUCT FUNCT, V222, P3587, DOI 10.1007/s00429-017-1419-x
   Bermudez P, 2009, CEREB CORTEX, V19, P1583, DOI 10.1093/cercor/bhn196
   Bohsali AA, 2015, BRAIN LANG, V141, P80, DOI 10.1016/j.bandl.2014.12.001
   Bradshaw AR, 2017, PEERJ, V5, DOI 10.7717/peerj.3557
   Broca P., 1861, B SOC ANAT PARIS, V6, P330, DOI DOI 10.1093/ACPROF:OSO/9780195177640.003.0018
   BRYDEN MP, 1977, NEUROPSYCHOLOGIA, V15, P617, DOI 10.1016/0028-3932(77)90067-7
   Brysbaert Marc, 2019, J Cogn, V2, P16, DOI 10.5334/joc.72
   Cai Q, 2010, CEREB CORTEX, V20, P1153, DOI 10.1093/cercor/bhp175
   Cai Q, 2008, J COGNITIVE NEUROSCI, V20, P672, DOI 10.1162/jocn.2008.20043
   CHI JG, 1977, ANN NEUROL, V1, P86, DOI 10.1002/ana.410010109
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   Dorsaint-Pierre R, 2006, BRAIN, V129, P1164, DOI 10.1093/brain/awl055
   Foster NEV, 2010, NEUROIMAGE, V53, P26, DOI 10.1016/j.neuroimage.2010.06.042
   Foundas AL, 1996, P NATL ACAD SCI USA, V93, P719, DOI 10.1073/pnas.93.2.719
   Friederici AD, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020726
   GESCHWIND N, 1968, SCIENCE, V161, P186, DOI 10.1126/science.161.3837.186
   Glasser MF, 2016, NATURE, V536, P171, DOI 10.1038/nature18933
   GOTESTAM KO, 1990, PERCEPT MOTOR SKILL, V70, P1323, DOI 10.2466/PMS.70.3.1323-1327
   Greve DN, 2013, J COGNITIVE NEUROSCI, V25, P1477, DOI 10.1162/jocn_a_00405
   Halwani GF, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00156
   Hill J, 2010, J NEUROSCI, V30, P2268, DOI 10.1523/JNEUROSCI.4682-09.2010
   Imada T, 2006, NEUROREPORT, V17, P957, DOI 10.1097/01.wnr.0000223387.51704.89
   Josse G, 2009, J NEUROSCI, V29, P13516, DOI 10.1523/JNEUROSCI.1680-09.2009
   Kasprian G, 2011, CEREB CORTEX, V21, P1076, DOI 10.1093/cercor/bhq179
   Keller SS, 2018, HUM BRAIN MAPP, V39, P3032, DOI 10.1002/hbm.24058
   Keller SS, 2011, J COGNITIVE NEUROSCI, V23, P2013, DOI 10.1162/jocn.2010.21563
   Kopiez R, 2006, NEUROPSYCHOLOGIA, V44, P1079, DOI 10.1016/j.neuropsychologia.2005.10.023
   Lancaster JL, 2000, HUM BRAIN MAPP, V10, P120, DOI 10.1002/1097-0193(200007)10:3<120::AID-HBM30>3.0.CO;2-8
   LANCASTER JL, 1997, NEUROIMAGE, V5, P633
   Li G, 2014, J NEUROSCI, V34, P4228, DOI 10.1523/JNEUROSCI.3976-13.2014
   Maldjian JA, 2003, NEUROIMAGE, V19, P1233, DOI 10.1016/S1053-8119(03)00169-1
   Mazoyer B, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0101165
   Muller RA, 1999, NEUROPSYCHOLOGIA, V37, P545, DOI 10.1016/S0028-3932(98)00109-2
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Palomar-Garcia MA, 2017, CEREB CORTEX, V27, P2768, DOI 10.1093/cercor/bhw120
   Pujol J, 1999, NEUROLOGY, V52, P1038, DOI 10.1212/WNL.52.5.1038
   Rodrigo-Mancho R., 1993, CATALNIA, V35, P41
   Rutten GJM, 2002, BRAIN LANG, V80, P421, DOI 10.1006/brln.2001.2600
   Sanjuan A, 2010, EUR RADIOL, V20, P2432, DOI 10.1007/s00330-010-1814-7
   Sanjuan A, 2010, NEURORADIOLOGY, V52, P407, DOI 10.1007/s00234-010-0667-8
   Schneider P, 2005, NAT NEUROSCI, V8, P1241, DOI 10.1038/nn1530
   Schremm A, 2018, BRAIN LANG, V176, P42, DOI 10.1016/j.bandl.2017.12.001
   Seghier ML, 2008, MAGN RESON IMAGING, V26, P594, DOI 10.1016/j.mri.2007.10.010
   Slater J, 2016, COGN PROCESS, V17, P79, DOI 10.1007/s10339-015-0740-7
   Smit EA, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0195831
   Sommer IEC, 2001, SCHIZOPHR RES, V52, P57, DOI 10.1016/S0920-9964(00)00180-8
   Springer JA, 1999, BRAIN, V122, P2033, DOI 10.1093/brain/122.11.2033
   Sreedharan RM, 2015, NEURORADIOLOGY, V57, P291, DOI 10.1007/s00234-014-1469-1
   Stewart CC, 2014, NEUROPSYCHOLOGIA, V60, P93, DOI 10.1016/j.neuropsychologia.2014.05.021
   Szaflarski JP, 2006, ANN NEUROL, V59, P796, DOI 10.1002/ana.20817
   Szaflarski JP, 2002, NEUROLOGY, V59, P238, DOI 10.1212/WNL.59.2.238
   Tzourio-Mazoyer N, 2015, BRAIN STRUCT FUNCT, V220, P1585, DOI 10.1007/s00429-014-0746-4
   Tzourio-Mazoyer N, 2018, BRAIN STRUCT FUNCT, V223, P1217, DOI 10.1007/s00429-017-1551-7
   Tzourio-Mazoyer N, 2017, CORTEX, V86, P314, DOI 10.1016/j.cortex.2016.05.013
   Van der Haegen L, 2016, NEUROPSYCHOLOGIA, V93, P482, DOI 10.1016/j.neuropsychologia.2015.10.032
   Vaquero L, 2018, NEUROIMAGE, V181, P252, DOI 10.1016/j.neuroimage.2018.06.054
   Vingerhoets G, 2019, PHYS LIFE REV, V30, P1, DOI 10.1016/j.plrev.2019.06.002
   WADA JA, 1975, ARCH NEUROL-CHICAGO, V32, P239, DOI 10.1001/archneur.1975.00490460055007
   Wernicke C., 1874, ARCH NEUROL-CHICAGO, V3, P2
   Wilke M, 2007, J NEUROSCI METH, V163, P128, DOI 10.1016/j.jneumeth.2007.01.026
   Yan CG, 2016, NEUROINFORMATICS, V14, P339, DOI 10.1007/s12021-016-9299-4
   Yan CG, 2010, FRONT SYST NEUROSCI, V4, DOI 10.3389/fnsys.2010.00013
   Zago L, 2017, HUM BRAIN MAPP, V38, P5871, DOI 10.1002/hbm.23770
NR 66
TC 1
Z9 1
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1065-9471
EI 1097-0193
J9 HUM BRAIN MAPP
JI Hum. Brain Mapp.
PD JUN 1
PY 2020
VL 41
IS 8
BP 2048
EP 2058
DI 10.1002/hbm.24929
EA FEB 2020
PG 11
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA LI9GA
UT WOS:000511606600001
PM 32034834
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Battistella, G
   Borghesani, V
   Henry, M
   Shwe, W
   Lauricella, M
   Miller, Z
   Deleon, J
   Miller, BL
   Dronkers, N
   Brambati, SM
   Seeley, WW
   Mandelli, ML
   Gorno-Tempini, ML
AF Battistella, Giovanni
   Borghesani, Valentina
   Henry, Maya
   Shwe, Wendy
   Lauricella, Michael
   Miller, Zachary
   Deleon, Jessica
   Miller, Bruce L.
   Dronkers, Nina
   Brambati, Simona M.
   Seeley, William W.
   Mandelli, Maria Luisa
   Gorno-Tempini, Maria Luisa
TI Task-Free Functional Language Networks: Reproducibility and Clinical
   Application
SO JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE functional connectivity; language networks; primary progressive aphasia;
   reproducibility; resting-state connectivity
ID PRIMARY PROGRESSIVE APHASIA; SENSORY-MOTOR INTEGRATION; TEMPORAL-LOBE;
   SPEECH PRODUCTION; SEMANTIC SYSTEM; RESTING BRAIN; CONNECTIVITY; FMRI;
   VARIANT; DORSAL
AB Intrinsic connectivity networks (ICNs) identified through task-free fMRI (tf-fMRI) offer the opportunity to investigate human brain circuits involved in language processes without requiring participants to perform challenging cognitive tasks. In this study, we assessed the ability of tf-fMRI to isolate reproducible networks critical for specific language functions and often damaged in primary progressive aphasia (PPA). First, we performed whole-brain seed-based correlation analyses on tf-fMRI data to identify ICNs anchored in regions known for articulatory, phonological, and semantic processes in healthy male and female controls (HCs). We then evaluated the reproducibility of these ICNs in an independent cohort of HCs, and recapitulated their functional relevance with a post hoc meta-analysis on task-based fMRI. Last, we investigated whether atrophy in these ICNs could inform the differential diagnosis of nonfluent/agrammatic, semantic, and logopenic PPA variants. The identified ICNs included a dorsal articulatory-phonological network involving inferior frontal and supramarginal regions; a ventral semantic network involving anterior middle temporal and angular gyri; a speech perception network involving superior temporal and sensorimotor regions; and a network between posterior inferior temporal and intraparietal regions likely linking visual, phonological, and attentional processes for written language. These ICNs were highly reproducible across independent groups and revealed areas consistent with those emerging from task-based meta-analysis. By comparing ICNs' spatial distribution in HCs with patients' atrophy patterns, we identified ICNs associated with each PPA variant. Our findings demonstrate the potential use of tf-fMRI to investigate the functional status of language networks in patients for whom activation studies can be methodologically challenging.
C1 [Battistella, Giovanni; Borghesani, Valentina; Henry, Maya; Shwe, Wendy; Lauricella, Michael; Miller, Zachary; Deleon, Jessica; Miller, Bruce L.; Seeley, William W.; Mandelli, Maria Luisa; Gorno-Tempini, Maria Luisa] Univ Calif San Francisco, Dept Neurol, Memory & Aging Ctr, San Francisco, CA 94158 USA.
   [Henry, Maya] Univ Texas Austin, Dept Commun Sci & Disorders, Austin, TX 78712 USA.
   [Dronkers, Nina] Univ Calif Berkeley, Dept Psychol, 3210 Tolman Hall, Berkeley, CA 94720 USA.
   [Brambati, Simona M.] Univ Montreal, Dept Psychol, Montreal, PQ H3T 1J4, Canada.
RP Battistella, G (corresponding author), Univ Calif San Francisco, Dept Neurol, Memory & Aging Ctr, San Francisco, CA 94158 USA.
EM Giovanni.battistella@ucsf.edu
RI Mandelli, Maria Luisa/AAL-2840-2020
OI Miller, Zachary/0000-0002-5991-3053; Henry, Maya/0000-0002-8745-6451;
   Deleon, Jessica/0000-0002-9779-0541
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [NINDS R01NS050915,
   NIDCD K24DC015544, NIDCD R03DC013403, NIDCD F32DC009145, NIDCD
   R01DC016291, NIA U01AG052943, NIA P50AG023501, NIA P01AG019724, NIA
   R01AG038791, NINDSU54NS092089]; Alzheimer's Disease Research Center of
   California [03-75271 DHS/ADP/ARCC]; Larry L. Hillblom Foundation; John
   Douglas French Alzheimer's Foundation; Koret Family Foundation;
   Consortium for Frontotemporal Dementia Research; McBean Family
   Foundation
FX The study was supported by Grants from the National Institutes of Health
   (NINDS R01NS050915, NIDCD K24DC015544, NIDCD R03DC013403, NIDCD
   F32DC009145, NIDCD R01DC016291, NIA U01AG052943, NIA P50AG023501, NIA
   P01AG019724, NIA R01AG038791, NINDSU54NS092089; Alzheimer's Disease
   Research Center of California (03-75271 DHS/ADP/ARCC); Larry L. Hillblom
   Foundation; John Douglas French Alzheimer's Foundation; Koret Family
   Foundation; Consortium for Frontotemporal Dementia Research; and McBean
   Family Foundation. We thank the patients and their families for the time
   and effort they dedicated to the research.
CR Amici S, 2007, J NEUROSCI, V27, P6282, DOI 10.1523/JNEUROSCI.1331-07.2007
   Ashburner J, 2007, NEUROIMAGE, V38, P95, DOI 10.1016/j.neuroimage.2007.07.007
   Battistella G, 2019, NEUROIMAGE-CLIN, V22, DOI 10.1016/j.nicl.2019.101797
   Binder JR, 2011, TRENDS COGN SCI, V15, P527, DOI 10.1016/j.tics.2011.10.001
   Binder JR, 2009, CEREB CORTEX, V19, P2767, DOI 10.1093/cercor/bhp055
   Binder JR, 2003, J COGNITIVE NEUROSCI, V15, P372, DOI 10.1162/089892903321593108
   Binder JR, 1997, J NEUROSCI, V17, P353
   Bolger DJ, 2008, NEUROPSYCHOLOGIA, V46, P3210, DOI 10.1016/j.neuropsychologia.2008.07.024
   Bonilha L, 2006, NEUROREPORT, V17, P1027, DOI 10.1097/01.wnr.0000223388.28834.50
   Booth JR, 2003, HUM BRAIN MAPP, V19, P155, DOI 10.1002/hbm.10111
   Broca P, 1861, B SOC ANTHROPOL PAR, V2, P235
   Buchel C, 1998, NATURE, V394, P274, DOI 10.1038/28389
   Buchsbaum BR, 2011, BRAIN LANG, V119, P119, DOI 10.1016/j.bandl.2010.12.001
   Butler RA, 2014, BRAIN, V137, P3248, DOI 10.1093/brain/awu286
   Catani M, 2013, BRAIN, V136, P2619, DOI 10.1093/brain/awt163
   Cheung C, 2016, ELIFE, V5, DOI 10.7554/eLife.12577
   Cohen L, 2004, NEUROIMAGE, V23, P1256, DOI 10.1016/j.neuroimage.2004.07.052
   Corbetta M, 2000, NAT NEUROSCI, V3, P292, DOI 10.1038/73009
   Damoiseaux JS, 2006, P NATL ACAD SCI USA, V103, P13848, DOI 10.1073/pnas.0601417103
   DeMarco AT, 2017, BRAIN LANG, V164, P118, DOI 10.1016/j.bandl.2016.10.001
   den Ouden DB, 2019, HUM BRAIN MAPP, V40, P2153, DOI 10.1002/hbm.24514
   Dronkers N, 2004, BRAIN, V127, P1461, DOI 10.1093/brain/awh233
   Dronkers NF, 2017, J INT NEUROPSYCH SOC, V23, P741, DOI 10.1017/S1355617717001126
   Fairhall SL, 2013, J NEUROSCI, V33, P10552, DOI 10.1523/JNEUROSCI.0051-13.2013
   Fedorenko E, 2014, TRENDS COGN SCI, V18, P120, DOI 10.1016/j.tics.2013.12.006
   Fox MD, 2007, NAT REV NEUROSCI, V8, P700, DOI 10.1038/nrn2201
   Fox MD, 2006, P NATL ACAD SCI USA, V103, P10046, DOI 10.1073/pnas.0604187103
   Friederici AD, 2006, P NATL ACAD SCI USA, V103, P2458, DOI 10.1073/pnas.0509389103
   Friederici AD, 2013, CURR OPIN NEUROBIOL, V23, P250, DOI 10.1016/j.conb.2012.10.002
   GALABURDA A, 1980, J COMP NEUROL, V190, P597, DOI 10.1002/cne.901900312
   Gesierich B, 2012, CEREB CORTEX, V22, P2217, DOI 10.1093/cercor/bhr286
   Gorno-Tempini ML, 2011, NEUROLOGY, V76, P1006, DOI 10.1212/WNL.0b013e31821103e6
   Gorno-Tempini ML, 2013, BRAIN LANG, V127, P105, DOI 10.1016/j.bandl.2013.10.008
   Gorno-Tempini ML, 2004, ANN NEUROL, V55, P335, DOI 10.1002/ana.10825
   Greicius MD, 2003, P NATL ACAD SCI USA, V100, P253, DOI 10.1073/pnas.0135058100
   Grossman M, 1996, J COGNITIVE NEUROSCI, V8, P135, DOI 10.1162/jocn.1996.8.2.135
   Grossman M, 2012, LANCET NEUROL, V11, P545, DOI 10.1016/S1474-4422(12)70099-6
   Hallquist MN, 2013, NEUROIMAGE, V82, P208, DOI 10.1016/j.neuroimage.2013.05.116
   Heim S, 2008, NEUROIMAGE, V40, P1362, DOI 10.1016/j.neuroimage.2008.01.009
   Henry ML, 2010, CURR OPIN NEUROL, V23, P633, DOI 10.1097/WCO.0b013e32833fb93e
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hillis AE, 2004, BRAIN, V127, P1479, DOI 10.1093/brain/awh172
   HODGES JR, 1992, BRAIN, V115, P1783, DOI 10.1093/brain/115.6.1783
   Houde JN, 2015, HDB SPEECH PRODUCTIO
   Humphries C, 2005, HUM BRAIN MAPP, V26, P128, DOI 10.1002/hbm.20148
   Hurley RS, 2015, J COGNITIVE NEUROSCI, V27, P464, DOI 10.1162/jocn_a_00722
   Kuperberg GR, 2008, HUM BRAIN MAPP, V29, P544, DOI 10.1002/hbm.20419
   La Joie R, 2012, J NEUROSCI, V32, P16265, DOI 10.1523/JNEUROSCI.2170-12.2012
   Louwersheimer E, 2016, J ALZHEIMERS DIS, V51, P581, DOI 10.3233/JAD-150812
   MacSweeney M, 2009, BRAIN, V132, P1928, DOI 10.1093/brain/awp129
   Maldjian JA, 2003, NEUROIMAGE, V19, P1233, DOI 10.1016/S1053-8119(03)00169-1
   Mandelli ML, 2016, BRAIN, V139, P2778, DOI 10.1093/brain/aww195
   Mandelli ML, 2014, J NEUROSCI, V34, P9754, DOI 10.1523/JNEUROSCI.3464-13.2014
   Matsuo K, 2012, J NEUROSCI METH, V205, P119, DOI 10.1016/j.jneumeth.2011.12.020
   Mechelli A, 2007, HUM BRAIN MAPP, V28, P205, DOI 10.1002/hbm.20272
   MESULAM MM, 1990, ANN NEUROL, V28, P597, DOI 10.1002/ana.410280502
   Milner A., 1995, VISUAL BRAIN ACTION
   Mottonen R, 2013, CEREB CORTEX, V23, P1190, DOI 10.1093/cercor/bhs110
   Montembeault M, 2019, CORTEX, V117, P284, DOI 10.1016/j.cortex.2019.03.018
   Mummery CJ, 1999, BRAIN, V122, P61, DOI 10.1093/brain/122.1.61
   Okada K, 2006, BRAIN LANG, V98, P112, DOI 10.1016/j.bandl.2006.04.006
   Ossenkoppele R, 2019, NEUROIMAGE-CLIN, V23, DOI 10.1016/j.nicl.2019.101848
   Ossenkoppele R, 2015, HUM BRAIN MAPP, V36, P4421, DOI 10.1002/hbm.22927
   Pa J, 2008, NEUROPSYCHOLOGIA, V46, P362, DOI 10.1016/j.neuropsychologia.2007.06.024
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Price CJ, 2000, J ANAT, V197, P335, DOI 10.1046/j.1469-7580.2000.19730335.x
   Price CJ, 2006, J MAGN RESON IMAGING, V23, P816, DOI 10.1002/jmri.20580
   Price CJ, 2006, NEUROIMAGE, V29, P643, DOI 10.1016/j.neuroimage.2005.07.044
   Price CJ, 1997, P ROY SOC B-BIOL SCI, V264, P1785, DOI 10.1098/rspb.1997.0247
   Purcell JJ, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00239
   Raichle ME, 2006, SCIENCE, V314, P1249, DOI 10.1126/science.1134405
   Ralph MAL, 2017, NAT REV NEUROSCI, V18, P42, DOI 10.1038/nrn.2016.150
   Ramanan SR, 2019, 767269 BIORXIV
   Satterthwaite TD, 2013, NEUROIMAGE, V64, P240, DOI 10.1016/j.neuroimage.2012.08.052
   Schwartz MF, 2012, BRAIN, V135, P3799, DOI 10.1093/brain/aws300
   Schwartz MF, 2009, BRAIN, V132, P3411, DOI 10.1093/brain/awp284
   Seeley WW, 2009, NEURON, V62, P42, DOI 10.1016/j.neuron.2009.03.024
   Seghier ML, 2010, J NEUROSCI, V30, P16809, DOI 10.1523/JNEUROSCI.3377-10.2010
   Shehzad Z, 2009, CEREB CORTEX, V19, P2209, DOI 10.1093/cercor/bhn256
   Simmons WK, 2010, CEREB CORTEX, V20, P813, DOI 10.1093/cercor/bhp149
   Smith SM, 2009, P NATL ACAD SCI USA, V106, P13040, DOI 10.1073/pnas.0905267106
   Tempini MLG, 1998, BRAIN, V121, P2103, DOI 10.1093/brain/121.11.2103
   Tomasi D, 2012, MOL PSYCHIATR, V17, P841, DOI 10.1038/mp.2011.177
   Turken AU, 2011, FRONT SYST NEUROSCI, V5, DOI 10.3389/fnsys.2011.00001
   Van Dijk KRA, 2010, J NEUROPHYSIOL, V103, P297, DOI 10.1152/jn.00783.2009
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Wilson SM, 2011, NEURON, V72, P397, DOI 10.1016/j.neuron.2011.09.014
   Wilson SM, 2009, BRAIN, V132, P71, DOI 10.1093/brain/awn300
   Yarkoni T, 2011, NAT METHODS, V8, P665, DOI [10.1038/NMETH.1635, 10.1038/nmeth.1635]
   Zhou J, 2010, BRAIN, V133, P1352, DOI 10.1093/brain/awq075
NR 91
TC 4
Z9 4
U1 0
U2 7
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
SN 0270-6474
EI 1529-2401
J9 J NEUROSCI
JI J. Neurosci.
PD FEB 5
PY 2020
VL 40
IS 6
BP 1311
EP 1320
DI 10.1523/JNEUROSCI.1485-19.2019
PG 10
WC Neurosciences
SC Neurosciences & Neurology
GA KK6WS
UT WOS:000512880800013
PM 31852732
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Turgeon, C
   Trudeau-Fisette, P
   Lepore, F
   Lippe, S
   Menard, L
AF Turgeon, Christine
   Trudeau-Fisette, Pamela
   Lepore, Franco
   Lippe, Sarah
   Menard, Lucie
TI Impact of visual and auditory deprivation on speech perception and
   production in adults
SO CLINICAL LINGUISTICS & PHONETICS
LA English
DT Article
DE Speech perception; speech production; visual impairment; auditory
   deprivation; cochlear implant
ID CONGENITALLY BLIND ADULTS; COCHLEAR IMPLANT USERS; FRENCH VOWELS; SOUND
   LOCALIZATION; HEARING STATUS; DEAF-CHILDREN; DISCRIMINATION;
   INDIVIDUALS; ABILITIES; ATTENTION
AB Speech perception relies on auditory and visual cues and there are strong links between speech perception and production. We aimed to evaluate the role of auditory and visual modalities on speech perception and production in adults with impaired hearing or sight versus those with normal hearing and sight. We examined speech perception and production of three isolated vowels (/i/, /y/, /u/), which were selected based on their different auditory and visual perceptual saliencies, in 12 deaf adults who used one or two cochlear implants (CIs), 14 congenitally blind adults, and 16 adults with normal sight and hearing. The results showed that the deaf adults who used a CI had worse vowel identification and discrimination perception and they also produced vowels that were less typical or precise than other participants. They had different tongue positions in speech production, which possibly partly explains the poorer quality of their spoken vowels. Blind individuals had larger lip openings and smaller lip protrusions for the rounded vowel and unrounded vowels, compared to the other participants, but they still produced vowels that were similar to those produced by the adults with normal sight and hearing. In summary, the deaf adults, even though they used CIs, had greater difficulty in producing accurate vowel targets than the blind adults, whereas the blind adults were still able to produce accurate vowel targets, even though they used different articulatory strategies.
C1 [Turgeon, Christine; Trudeau-Fisette, Pamela; Menard, Lucie] Univ Quebec Montreal, Dept Linguist, Montreal, PQ, Canada.
   [Lepore, Franco; Lippe, Sarah] Univ Montreal, Dept Psychol, Montreal, PQ, Canada.
RP Turgeon, C (corresponding author), Univ Quebec Montreal, Linguist, 320 Ste Catherine Est,5425 Gerry Boulet 306, Montreal, PQ H3C 3P8, Canada.
EM christineturgeon5@gmail.com
FU Insight Grant from the Social Sciences and Humanities Research Council
   of Canada; Natural Sciences and Engineering Research Council of
   CanadaNatural Sciences and Engineering Research Council of Canada
   (NSERC)CGIAR
FX This work was supported by an Insight Grant from the Social Sciences and
   Humanities Research Council of Canada and by a Discovery Grant from the
   Natural Sciences and Engineering Research Council of Canada awarded to
   L. Menard. We are grateful to Marlene Busko for copy-editing the paper.
CR Amadeo MB, 2019, NEUROIMAGE, V191, P140, DOI 10.1016/j.neuroimage.2019.01.073
   Bates D. M., 2012, LME4 LINEAR MIXED EF
   Bavelier D, 2000, J NEUROSCI, V20, DOI 10.1523/JNEUROSCI.20-17-j0001.2000
   Bavelier D, 2006, TRENDS COGN SCI, V10, P512, DOI 10.1016/j.tics.2006.09.006
   Boe Luis-Jean, 2007, EXPT APPROACHES PHON, P104
   Boersma P., 2014, GLOT INT, V5, P341
   Bosworth RG, 2002, BRAIN COGNITION, V49, P170, DOI 10.1006/brcg.2001.1498
   Bouchard MEG, 2007, CLIN LINGUIST PHONET, V21, P875, DOI 10.1080/02699200701653634
   BURLINGHAM D, 1961, PSYCHOANAL STUD CHIL, V16, P121
   Collignon O, 2009, EXP BRAIN RES, V192, P343, DOI 10.1007/s00221-008-1553-z
   Connor CM, 2006, EAR HEARING, V27, P628, DOI 10.1097/01.aud.0000240640.59205.42
   Dawson KM, 2016, CLIN LINGUIST PHONET, V30, P328, DOI 10.3109/02699206.2015.1099164
   Delvaux V, 2018, J PHONETICS, V67, P65, DOI 10.1016/j.wocn.2018.01.001
   Dietrich S, 2013, BMC NEUROSCI, V14, DOI 10.1186/1471-2202-14-74
   Dye MWG, 2010, RESTOR NEUROL NEUROS, V28, P181, DOI 10.3233/RNN-2010-0501
   Elstner W., 1983, LANG ACQUIS, P18
   Focker J, 2012, NEUROPSYCHOLOGIA, V50, P2056, DOI 10.1016/j.neuropsychologia.2012.05.006
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Garnham Carolyn, 2002, Ear and Hearing, V23, P540, DOI 10.1097/00003446-200212000-00005
   Gick B., 2013, CANADIAN ACOUSTICS, V41, P1
   Gougoux F, 2005, PLOS BIOL, V3, P324, DOI 10.1371/journal.pbio.0030027
   Gougoux F, 2004, NATURE, V430, P309, DOI 10.1038/430309a
   Habib MG, 2010, INT J PEDIATR OTORHI, V74, P855, DOI 10.1016/j.ijporl.2010.04.009
   Heimler B, 2014, NEUROSCIENCE, V283, P44, DOI 10.1016/j.neuroscience.2014.08.003
   Heming JE, 2005, BRAIN COGNITION, V59, P173, DOI 10.1016/j.bandc.2005.05.012
   Hirsch F., 2011, INT SEM SPEECH PROD
   Hughes ML, 2006, J ACOUST SOC AM, V119, P1527, DOI 10.1121/1.2163273
   Iverson JM, 2000, J NONVERBAL BEHAV, V24, P105, DOI 10.1023/A:1006605912965
   Lane H, 2005, J ACOUST SOC AM, V118, P1636, DOI 10.1121/1.2001527
   LANE H, 1991, J ACOUST SOC AM, V89, P859, DOI 10.1121/1.1894647
   Lane H, 2001, J SPEECH LANG HEAR R, V44, P552, DOI 10.1044/1092-4388(2001/043)
   Lansing CR, 1999, J SPEECH LANG HEAR R, V42, P526, DOI 10.1044/jslhr.4203.526
   Lejska M, 2004, J VOICE, V18, P209, DOI 10.1016/j.jvoice.2003.08.002
   Lessard N, 1998, NATURE, V395, P278
   Lewald J, 2002, NEUROPSYCHOLOGIA, V40, P1868, DOI 10.1016/S0028-3932(02)00071-4
   Lewis M. M., 1975, INFANT SPEECH STUDY
   Li M, 2005, CLIN LINGUIST PHONET, V19, P545, DOI 10.1080/02699200500113616
   LOKE WH, 1991, B PSYCHONOMIC SOC, V29, P437
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Menard L, 2002, J ACOUST SOC AM, V111, P1892, DOI 10.1121/1.1459467
   Menard L, 2007, J ACOUST SOC AM, V121, P3790, DOI 10.1121/1.2710963
   Menard L, 2016, FOLIA PHONIATR LOGO, V68, P232, DOI 10.1159/000470905
   Menard L, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0160088
   Menard L, 2015, FOLIA PHONIATR LOGO, V67, P83, DOI 10.1159/000434719
   Menard L, 2014, J SPEECH LANG HEAR R, V57, P793, DOI 10.1044/2014_JSLHR-S-12-0395
   Menard L, 2013, J ACOUST SOC AM, V134, P2975, DOI 10.1121/1.4818740
   Menard L, 2012, FOLIA PHONIATR LOGO, V64, P64, DOI 10.1159/000331997
   Menard L, 2009, J ACOUST SOC AM, V126, P1406, DOI 10.1121/1.3158930
   Merabet LB, 2010, NAT REV NEUROSCI, V11, P44, DOI 10.1038/nrn2758
   Mills A. E., 1983, LANGUAGE ACQUISITION
   Mills A. E., 1987, HEARING EYE PSYCHOL, P145
   MUCHNIK C, 1991, SCAND AUDIOL, V20, P19, DOI 10.3109/01050399109070785
   NEVILLE HJ, 1987, BRAIN RES, V405, P284, DOI 10.1016/0006-8993(87)90297-6
   NIEMEYER W, 1981, AUDIOLOGY, V20, P510
   Osberger MJ, 2000, ADV OTO-RHINO-LARYNG, V57, P421
   Perez-Pereira M, 1999, LANGUAGE DEV SOCIAL
   Perkell JS, 2004, J ACOUST SOC AM, V116, P2338, DOI 10.1121/1.1787524
   Peterson NR, 2010, RESTOR NEUROL NEUROS, V28, P237, DOI 10.3233/RNN-2010-0535
   Roder B, 1999, NATURE, V400, P162, DOI 10.1038/22106
   Ronnberg J., 1995, COMPENSATING PSYCHOL, P251
   Ruff S, 2017, ORL J OTO-RHINO-LARY, V79, P282, DOI 10.1159/000479819
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   Schwartz JL, 2002, PHONETICS PHONOLOGY, P255
   Serry TA, 1999, J SPEECH LANG HEAR R, V42, P141, DOI 10.1044/jslhr.4201.141
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1992, PHILOS T ROY SOC B, V335, P71, DOI 10.1098/rstb.1992.0009
   SUMMERFIELD Q, 1979, PHONETICA, V36, P314, DOI 10.1159/000259969
   Trudeau-Fisette P., 2013, P M AC, DOI [10.1121/1.4799432, DOI 10.1121/1.4799432]
   Turgeon C, 2017, INT J PEDIATR OTORHI, V101, P87, DOI 10.1016/j.ijporl.2017.07.022
   Turgeon C, 2015, CLIN LINGUIST PHONET, V29, P378, DOI 10.3109/02699206.2015.1007527
   Turgeon C, 2012, NEUROREPORT, V23, P385, DOI 10.1097/WNR.0b013e3283525af4
   Ubrig MT, 2011, J VOICE, V25, P692, DOI 10.1016/j.jvoice.2010.07.001
   Vick JC, 2001, J SPEECH LANG HEAR R, V44, P1257, DOI 10.1044/1092-4388(2001/098)
   Voss P, 2004, CURR BIOL, V14, P1734, DOI 10.1016/j.cub.2004.09.051
   Voss P, 2015, J NEUROSCI, V35, P6051, DOI 10.1523/JNEUROSCI.4544-14.2015
   Warren D.H., 1977, BLINDNESS EARLY CHIL
   Whalen DH, 2005, J SPEECH LANG HEAR R, V48, P543, DOI 10.1044/1092-4388(2005/037)
   Winn MB, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00824
   Woodhouse L, 2009, INT J LANG COMM DIS, V44, P253, DOI 10.1080/13682820802090281
   Zeszut S., 1998, THESIS
NR 80
TC 0
Z9 0
U1 0
U2 4
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0269-9206
EI 1464-5076
J9 CLIN LINGUIST PHONET
JI Clin. Linguist. Phon.
PD DEC 1
PY 2020
VL 34
IS 12
BP 1061
EP 1087
DI 10.1080/02699206.2020.1719207
EA FEB 2020
PG 27
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA OK4HK
UT WOS:000512505200001
PM 32013589
DA 2021-02-24
ER

PT J
AU Jung, J
   Houston, D
AF Jung, Jongmin
   Houston, Derek
TI The Relationship Between the Onset of Canonical Syllables and Speech
   Perception Skills in Children With Cochlear Implants
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID VOCAL DEVELOPMENT; YOUNG-CHILDREN; LANGUAGE-DEVELOPMENT; DEAF-CHILDREN;
   CONDITIONED ASSESSMENT; WORD RECOGNITION; SOCIAL FEEDBACK; INFANTS;
   VOCABULARY; HEARING
AB Purpose: The study sought to determine whether the onset of canonical vocalizations in children with cochlear implants (CIs) is related to speech perception skills and spoken vocabulary size at 24 months postactivation.
   Method: The vocal development in 13 young CI recipients (implanted by their third birthdays; mean age at activation = 20.62 months, SD = 8.92 months) was examined at every 3-month interval during the first 2 years of CI use. All children were enrolled in auditory-oral intervention programs. Families of these children used spoken English only. To determine the onset of canonical syllables, the first 50 utterances from 20-min adult-child interactions were analyzed during each session. The onset timing was determined when at least 20% of utterances included canonical syllables. As children's outcomes, we examined their Lexical Neighborhood Test scores and vocabulary size at 24 months postactivation.
   Results: Pearson correlation analysis showed that the onset timing of canonical syllables is significantly correlated with phonemic recognition skills and spoken vocabulary size at 24 months postactivation. Regression analyses also indicated that the onset timing of canonical syllables predicted phonemic recognition skills and spoken vocabulary size at 24 months postactivation.
   Conclusion: Monitoring vocal advancement during the earliest periods following cochlear implantation could be valuable as an early indicator of auditory-driven language development in young children with CIs. It remains to be studied which factors improve vocal development for young CI recipients.
C1 [Jung, Jongmin; Houston, Derek] Ohio State Univ, Dept Otolaryngol Head & Neck Surg, Columbus, OH 43210 USA.
   [Houston, Derek] Nationwide Childrens Hosp, Columbus, OH USA.
RP Jung, J (corresponding author), Ohio State Univ, Dept Otolaryngol Head & Neck Surg, Columbus, OH 43210 USA.
EM jongminjung169@gmail.com
OI Jung, Jongmin/0000-0001-9541-385X
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01DC007863];
   National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC007863]; Ertmer
FX This study was supported by a grant from the National Institutes of
   Health and the National Institute on Deafness and Other Communication
   Disorders (R01DC007863) awarded to David J. Ertmer. We give special
   thanks to Ertmer for the generous support for this study. We also
   appreciate Irina Castellanos for the insightful feedback on the article.
   This study was possible with the invaluable support from the staff of
   Child's Voice School (Wood Dale, IL), the St. Joseph Institute for the
   Deaf (Chesterfield, MO), the St. Joseph Institute for the Deaf
   (Indianapolis, IN), the Moog Center (Chesterfield, MO), and Ohio Valley
   Voice (Loveland, OH). We are also grateful for the effort of the
   research assistants who helped to collect, code, and analyze the data.
   Sincere appreciation is given to the children and parents who
   participated in the study.
CR Bass-Ringdahl SM, 2010, J DEAF STUD DEAF EDU, V15, P287, DOI 10.1093/deafed/enq013
   Bavin EL, 2018, INT J LANG COMM DIS, V53, P788, DOI 10.1111/1460-6984.12383
   BLOOM K, 1987, J CHILD LANG, V14, P211, DOI 10.1017/S0305000900012897
   Boons T, 2012, EAR HEARING, V33, P627, DOI 10.1097/AUD.0b013e3182503e47
   Bruderer AG, 2015, P NATL ACAD SCI USA, V112, P13531, DOI 10.1073/pnas.1508631112
   Castellanos Irina, 2014, Cochlear Implants Int, V15, P200, DOI 10.1179/1754762813Y.0000000043
   Connor CM, 2006, EAR HEARING, V27, P628, DOI 10.1097/01.aud.0000240640.59205.42
   Cristia A, 2016, INFANCY, V21, P648, DOI 10.1111/infa.12127
   D'Ausilio A, 2012, J NEUROLINGUIST, V25, P328, DOI 10.1016/j.jneuroling.2010.02.003
   DePaolis RA, 2011, INFANT BEHAV DEV, V34, P590, DOI 10.1016/j.infbeh.2011.06.005
   DesJardin JL, 2007, EAR HEARING, V28, P456, DOI 10.1097/AUD.0b013e31806dc1ab
   EILERS RE, 1993, INFANT BEHAV DEV, V16, P297, DOI 10.1016/0163-6383(93)80037-9
   Eisenberg LS, 2006, AUDIOL NEURO-OTOL, V11, P259, DOI 10.1159/000093302
   Ertmer DJ, 2008, VOLTA REV, V108, P59
   Ertmer DJ, 2007, J SPEECH LANG HEAR R, V50, P393, DOI 10.1044/1092-4388(2007/028)
   Ertmer DJ, 2013, AM J SPEECH-LANG PAT, V22, P591, DOI 10.1044/1058-0360(2013/12-0058)
   Ertmer DJ, 2012, AM J SPEECH-LANG PAT, V21, P313, DOI 10.1044/1058-0360(2012/11-0110)
   Ertmer DJ, 2012, J DEAF STUD DEAF EDU, V17, P116, DOI 10.1093/deafed/enr021
   Fagan MK, 2017, J SPEECH LANG HEAR R, V60, P2819, DOI 10.1044/2017_JSLHR-S-16-0005
   Fagan MK, 2015, J EXP CHILD PSYCHOL, V137, P125, DOI 10.1016/j.jecp.2015.04.005
   Fasolo M, 2008, CLIN LINGUIST PHONET, V22, P83, DOI 10.1080/02699200701600015
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   Fernald A, 2006, DEV PSYCHOL, V42, P98, DOI 10.1037/0012-1649.42.1.98
   Gilkerson J, 2018, PEDIATRICS, V142, DOI 10.1542/peds.2017-4276
   Goldstein MH, 2003, P NATL ACAD SCI USA, V100, P8030, DOI 10.1073/pnas.1332441100
   Goldstein MH, 2008, PSYCHOL SCI, V19, P515, DOI 10.1111/j.1467-9280.2008.02117.x
   Goldstein MH, 2010, INFANCY, V15, P362, DOI 10.1111/j.1532-7078.2009.00020.x
   Hart B., 1995, MEANINGFUL DIFFERENC
   Holt RF, 2008, EAR HEARING, V29, P492, DOI 10.1097/AUD.0b013e31816c409f
   Houston D. M., 2018, HDB COMMUNICATION DI, P43, DOI [10.1515/9781614514909-003, DOI 10.1515/9781614514909-003]
   Houston DM, 2007, INFANCY, V12, P119, DOI 10.1111/j.1532-7078.2007.tb00237.x
   Houston DM, 2012, DEVELOPMENTAL SCI, V15, P448, DOI 10.1111/j.1467-7687.2012.01140.x
   Houston DM, 2010, OTOL NEUROTOL, V31, P1248, DOI 10.1097/MAO.0b013e3181f1cc6a
   Hunter CR, 2017, J SPEECH LANG HEAR R, V60, P2321, DOI 10.1044/2017_JSLHR-H-16-0152
   Imada T, 2006, NEUROREPORT, V17, P957, DOI 10.1097/01.wnr.0000223387.51704.89
   Iyer SN, 2017, AM J SPEECH-LANG PAT, V26, P413, DOI 10.1044/2016_AJSLP-16-0073
   Iyer SN, 2016, CLIN LINGUIST PHONET, V30, P470, DOI 10.3109/02699206.2016.1147082
   JUSCZYK PW, 1995, COGNITIVE PSYCHOL, V29, P1, DOI 10.1006/cogp.1995.1010
   Kirk K. I., 1999, J AM ACAD AUDIOL, V10, P113
   KIRK KI, 1995, EAR HEARING, V16, P470, DOI 10.1097/00003446-199510000-00004
   Kishon-Rabin L, 2005, EAR HEARING, V26, p17S, DOI 10.1097/00003446-200508001-00004
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   Leigh J, 2013, OTOL NEUROTOL, V34, P443, DOI 10.1097/MAO.0b013e3182814d2c
   Lohmander A, 2017, ACTA PAEDIATR, V106, P935, DOI 10.1111/apa.13816
   LYNCH MP, 1989, APPL PSYCHOLINGUIST, V10, P315, DOI 10.1017/S0142716400008651
   Majorano M, 2014, LANG LEARN DEV, V10, P179, DOI 10.1080/15475441.2013.829740
   Marchman VA, 2008, DEVELOPMENTAL SCI, V11, pF9, DOI 10.1111/j.1467-7687.2008.00671.x
   McCathren RB, 1999, J SPEECH LANG HEAR R, V42, P915, DOI 10.1044/jslhr.4204.915
   McGillion M, 2017, CHILD DEV, V88, P156, DOI 10.1111/cdev.12671
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   McMurray B, 2005, COGNITION, V95, pB15, DOI 10.1016/j.cognition.2004.07.005
   Moeller MP, 2007, EAR HEARING, V28, P628, DOI 10.1097/AUD.0b013e31812564c9
   Nathani S, 2006, CLIN LINGUIST PHONET, V20, P351, DOI 10.1080/02699200500211451
   NELSON DGK, 1995, INFANT BEHAV DEV, V18, P111
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Oller D. K., 2000, EMERGENCE SPEECH CAP
   Oller DK, 1998, AM J MENT RETARD, V103, P249, DOI 10.1352/0895-8017(1998)103<0249:LOCBAP>2.0.CO;2
   OLLER DK, 1988, CHILD DEV, V59, P441, DOI 10.1111/j.1467-8624.1988.tb01479.x
   Oller DK, 1999, J COMMUN DISORD, V32, P223, DOI 10.1016/S0021-9924(99)00013-1
   Percy-Smith L, 2013, INT J PEDIATR OTORHI, V77, P184, DOI 10.1016/j.ijporl.2012.10.014
   Phan J, 2016, J AM ACAD AUDIOL, V27, P480, DOI 10.3766/jaaa.15088
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Ramirez-Esparza N, 2014, DEVELOPMENTAL SCI, V17, P880, DOI 10.1111/desc.12172
   Reynell JK, 1990, REYNELL DEV LANGUAGE
   Romeo RR, 2018, PSYCHOL SCI, V29, P700, DOI 10.1177/0956797617742725
   Schauwers K, 2004, OTOL NEUROTOL, V25, P263, DOI 10.1097/00129492-200405000-00011
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Stoel-Gammon C., 1989, FIRST LANG, V9, P207, DOI DOI 10.1177/014272378900900607
   Svirsky M. A., 2009, AUDIOL MED, V5, P293, DOI 10.1080/16513860701727847
   Thal D, 2007, AM J SPEECH-LANG PAT, V16, P54, DOI 10.1044/1058-0360(2007/007)
   Tomblin JB, 2005, J SPEECH LANG HEAR R, V48, P853, DOI 10.1044/1092-4388(2005/059)
   Torola H, 2012, CLIN LINGUIST PHONET, V26, P330, DOI 10.3109/02699206.2011.636499
   Uhler K, 2017, J AM ACAD AUDIOL, V28, P232, DOI 10.3766/jaaa.15123
   Uhler K, 2011, J AM ACAD AUDIOL, V22, P129, DOI 10.3766/jaaa.22.3.2
   Uhler KM, 2015, J AM ACAD AUDIOL, V26, P807, DOI 10.3766/jaaa.14093
   Valimaa TT, 2019, J SPEECH LANG HEAR R, V62, P1296, DOI 10.1044/2018_JSLHR-S-18-0260
   Vihman MM, 2014, LANG LEARN, V64, P121, DOI 10.1111/lang.12058
   VIHMAN MM, 1985, LANGUAGE, V61, P397, DOI 10.2307/414151
   VIHMAN MM, 1993, J PHONETICS, V21, P61, DOI 10.1016/S0095-4470(19)31321-X
   Walker EA, 2008, OTOL NEUROTOL, V29, P225, DOI 10.1097/mao.0b013e31815f6673
   Warlaumont AS, 2014, PSYCHOL SCI, V25, P1314, DOI 10.1177/0956797614531023
   Weisleder A, 2013, PSYCHOL SCI, V24, P2143, DOI 10.1177/0956797613488145
   Werker JF, 1997, EARLY DEV PARENTING, V6, P171, DOI 10.1002/(SICI)1099-0917(199709/12)6:3/4<171::AID-EDP156>3.3.CO;2-8
   WHITEHURST GJ, 1991, J SPEECH HEAR RES, V34, P1121, DOI 10.1044/jshr.3405.1121
NR 84
TC 2
Z9 2
U1 0
U2 0
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD FEB
PY 2020
VL 63
IS 2
BP 393
EP 404
DI 10.1044/2019_JSLHR-19-00158
PG 12
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA ND2WB
UT WOS:000561764300005
PM 32073331
OA Green Published
DA 2021-02-24
ER

PT J
AU Preston, JL
   Hitchcock, ER
   Leece, MC
AF Preston, Jonathan L.
   Hitchcock, Elaine R.
   Leece, Megan C.
TI Auditory Perception and Ultrasound Biofeedback Treatment Outcomes for
   Children With Residual /(sic)/ Distortions: A Randomized Controlled
   Trial
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SPEECH-PERCEPTION; VERTICAL-BAR; PHONOLOGICAL AWARENESS; PHONEMIC
   PERCEPTION; PERSISTENT; ARTICULATION; DISORDERS; SKILLS; IDENTIFICATION;
   GENETICS
AB Purpose: This study evaluated whether outcomes from treatment, which includes ultrasound visual feedback (UVF), would be more or less effective when combined with auditory perception training for children with residual /(sic)/ errors.
   Method: Children ages 8-16 years with /(sic)/ distortions participated in speech therapy that included real-time UVF of the tongue. Thirty-eight participants were randomized to speech therapy conditions that included a primary focus on articulation using UVF or a condition that included auditory perceptual training plus UVF (incorporating category goodness judgments and self-monitoring). Generalization of /(sic)/ production accuracy to untrained words was assessed before and after 14 hr of therapy. Additionally, the role of auditory perceptual acuity was explored using a synthetic /(sic)/-/w/ continuum.
   Results: There was no difference between the treatment groups in rate of improvement of /(sic)/ accuracy (increase of 34% for each group; p =.95, eta(2)(p) =.00). However, pretreatment auditory acuity was associated with treatment progress in both groups, with finer perceptual acuity corresponding to greater progress (p =.015, eta(2)(p) =.182).
   Conclusion: Similar gains in speech sound accuracy can be made with treatment that includes UVF with or without auditory perceptual training. Fine-grained perceptual acuity may be a prognostic indicator with treatment.
C1 [Preston, Jonathan L.; Leece, Megan C.] Syracuse Univ, Dept Commun Sci & Disorders, Syracuse, NY 13244 USA.
   [Hitchcock, Elaine R.] Montclair State Univ, Dept Commun Sci & Disorders, Montclair, NJ 07043 USA.
RP Preston, JL (corresponding author), Syracuse Univ, Dept Commun Sci & Disorders, Syracuse, NY 13244 USA.
EM jopresto@syr.edu
FU Syracuse University College of Arts and Sciences; Syracuse University
   Gerber Auditory Science Grant; National Institutes of Health
   GrantsUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R03DC013152, R15DC016426, R01DC013668]
FX This study was supported in part by Syracuse University College of Arts
   and Sciences, Syracuse University Gerber Auditory Science Grant (PI: J.
   Preston), and National Institutes of Health Grants R03DC013152 (PI: J.
   Preston), R15DC016426 (PI: J. Preston), and R01DC013668 (PI: D. Whalen).
   The content is solely the responsibility of the authors and does not
   necessarily represent the official views of the National Institutes of
   Health. Thanks to Tara McAllister and Jose Ortiz who, along with the
   second author, developed the Challenge Point Program software. Thanks to
   Tara McAllister for sharing the/I/-/w/continuum. Thanks to Tara
   McAllister and Sarah Hamilton-Dugan for sharing stimuli for category
   goodness training.
CR Adler-Bock M, 2007, AM J SPEECH-LANG PAT, V16, P128, DOI 10.1044/1058-0360(2007/017)
   [Anonymous], 2016, SPSS STAT WIND
   Bacsfalvi P., 2007, ADV SPEECH LANGUAGE, V9, P36, DOI DOI 10.1080/14417040601101037
   Bernhardt B, 2005, CAN J SPEECH-LANG PA, V29, P169
   Boersma P., 2018, PRAAT 6 0 37
   Bowers L., 2011, LINGUISYSTEMS ARTICU
   Byun TM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0172022
   Byun TM, 2016, LANGUAGE, V92, P141, DOI 10.1353/lan.2016.0000
   Byun TM, 2014, J SPEECH LANG HEAR R, V57, P2116, DOI 10.1044/2014_JSLHR-S-14-0034
   Cabbage KL, 2016, SPEECH COMMUN, V82, P14, DOI 10.1016/j.specom.2016.05.002
   Cleland J, 2019, J SPEECH LANG HEAR R, V62, P229, DOI 10.1044/2018_JSLHR-S-17-0360
   Cleland J, 2015, CLIN LINGUIST PHONET, V29, P575, DOI 10.3109/02699206.2015.1016188
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   Fawcett S., 2008, DOWN SYNDROME Q, V10, P4
   Flipsen P, 2015, SEMIN SPEECH LANG, V36, P217, DOI 10.1055/s-0035-1562905
   Goldman R, 2000, GOLDMAN FRISTOE TEST
   Gray S, 1992, LANG SPEECH HEAR SER, V23, P334, DOI DOI 10.1044/0161-1461.2304.334
   Guadagnoli MA, 2004, J MOTOR BEHAV, V36, P212, DOI 10.3200/JMBR.36.2.212-224
   Guenther FH, 2012, J NEUROLINGUIST, V25, P408, DOI 10.1016/j.jneuroling.2009.08.006
   Hearnshaw S, 2018, J COMMUN DISORD, V71, P61, DOI 10.1016/j.jcomdis.2017.12.004
   Hitchcock ER, 2019, SEMIN SPEECH LANG, V40, P124, DOI 10.1055/s-0039-1677763
   HOFFMAN PR, 1985, J SPEECH HEAR DISORD, V50, P46, DOI 10.1044/jshd.5001.46
   Jamieson D.G., 1992, J SPEECH LANGUAGE PA, V16, P201
   Karlsson HB, 2002, CLIN LINGUIST PHONET, V16, P403, DOI 10.1080/02699200210128954
   KOEGEL LK, 1986, J SPEECH HEAR DISORD, V51, P24, DOI 10.1044/jshd.5101.24
   KOEGEL RL, 1988, J SPEECH HEAR DISORD, V53, P392, DOI 10.1044/jshd.5304.392
   Maas E, 2008, AM J SPEECH-LANG PAT, V17, P277, DOI 10.1044/1058-0360(2008/025)
   Modha G, 2008, INT J LANG COMM DIS, V43, P323, DOI 10.1080/13682820701449943
   Nijland L, 2009, CLIN LINGUIST PHONET, V23, P222, DOI 10.1080/02699200802399947
   O'Connell Nathaniel S, 2017, J Biom Biostat, V8, P1, DOI 10.4172/2155-6180.1000334
   OHDE RN, 1988, J SPEECH HEAR RES, V31, P556, DOI 10.1044/jshr.3104.556
   Preston JL, 2018, J SPEECH LANG HEAR R, V61, DOI 10.1044/2018_JSLHR-S-17-0441
   Preston JL, 2017, AM J SPEECH-LANG PAT, V26, P1066, DOI 10.1044/2017_AJSLP-16-0232
   Preston JL, 2017, AM J SPEECH-LANG PAT, V26, P840, DOI 10.1044/2017_AJSLP-16-0155
   Preston JL, 2017, JOVE-J VIS EXP, DOI 10.3791/55123
   Preston JL, 2017, INT J LANG COMM DIS, V52, P80, DOI 10.1111/1460-6984.12259
   Preston JL, 2014, J SPEECH LANG HEAR R, V57, P2102, DOI 10.1044/2014_JSLHR-S-14-0031
   Jonathan LP, 2013, AM J SPEECH-LANG PAT, V22, P627, DOI 10.1044/1058-0360(2013/12-0139)
   RUSCELLO DM, 1979, J SPEECH HEAR DISORD, V44, P504, DOI 10.1044/jshd.4404.504
   Rvachew S, 2004, AM J SPEECH-LANG PAT, V13, P250, DOI 10.1044/1058-0360(2004/026)
   Rvachew S, 2003, AM J SPEECH-LANG PAT, V12, P463, DOI 10.1044/1058-0360(2003/092)
   RVACHEW S, 1994, J SPEECH HEAR RES, V37, P347, DOI 10.1044/jshr.3702.347
   Rvachew S, 1999, AM J SPEECH-LANG PAT, V8, P33, DOI 10.1044/1058-0360.0801.33
   Rvachew S., 2012, DEV PHONOLOGICAL DIS
   Schulz KF, 2010, BMC MED, V8, DOI 10.1186/1741-7015-8-18
   Senechal M, 2004, J EXP CHILD PSYCHOL, V89, P242, DOI 10.1016/j.jecp.2004.07.005
   Shiller DM, 2010, CAN J SPEECH-LANG PA, V34, P181
   Shriberg L D, 1994, Clin Commun Disord, V4, P38
   Shriberg LD, 2010, CLIN LINGUIST PHONET, V24, P795, DOI 10.3109/02699206.2010.503006
   Shriberg LD, 2005, J SPEECH LANG HEAR R, V48, P834, DOI 10.1044/1092-4388(2005/058)
   SHRIBERG LD, 1994, J SPEECH HEAR RES, V37, P1100, DOI 10.1044/jshr.3705.1100
   SHRIBERG LD, 1993, J SPEECH HEAR RES, V36, P105, DOI 10.1044/jshr.3601.105
   Shuster LI, 1998, J SPEECH LANG HEAR R, V41, P941, DOI 10.1044/jslhr.4104.941
   Sugden E, 2019, INT J LANG COMM DIS, V54, P705, DOI 10.1111/1460-6984.12478
   Van Riper C., 1996, SPEECH CORRECTION IN
   Wagner R. K., 2013, COMPREHENSIVE TEST P
   Wechsler D., 2011, WECHSLER ABBREVIATED
   Wiig E.H., 2013, CLIN EVALUATION LANG
   Wolfe V, 2003, AM J SPEECH-LANG PAT, V12, P282, DOI 10.1044/1058-0360(2003/074)
NR 59
TC 2
Z9 2
U1 1
U2 2
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD FEB
PY 2020
VL 63
IS 2
BP 444
EP 455
DI 10.1044/2019_JSLHR-19-00060
PG 12
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA ND2WB
UT WOS:000561764300009
PM 32097058
OA Green Published
DA 2021-02-24
ER

PT J
AU Wong, PS
   Cheng, MW
AF Wong, Puisan
   Cheng, Man Wai
TI On the Relationship Between General Auditory Sensitivity and Speech
   Perception: An Examination of Pitch and Lexical Tone Perception in 4-to
   6-Year-Old Children
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID LANGUAGE IMPAIRMENT; FREQUENCY DISCRIMINATION; DEVELOPMENTAL DYSLEXIA;
   PROCESSING DISORDER; READING DEVELOPMENT; INTERVENTIONS; RECOGNITION;
   LITERACY; DEFICITS; SKILLS
AB Purpose: Theoretical models and substantial research have proposed that general auditory sensitivity is a developmental foundation for speech perception and language acquisition. Nonetheless, controversies exist about the effectiveness of general auditory training in improving speech and language skills. This research investigated the relationships among general auditory sensitivity, phonemic speech perception, and word-level speech perception via the examination of pitch and lexical tone perception in children.
   Method: Forty-eight typically developing 4- to 6-yearold Cantonese-speaking children were tested on the discrimination of the pitch patterns of lexical tones in synthetic stimuli, discrimination of naturally produced lexical tones, and identification of lexical tone in familiar words.
   Results: The findings revealed that accurate lexical tone discrimination and identification did not necessarily entail the accurate discrimination of nonlinguistic stimuli that followed the pitch levels and pitch shapes of lexical tones. Although pitch discrimination and tone discrimination abilities were strongly correlated, accuracy in pitch discrimination was lower than that in tone discrimination, and nonspeech pitch discrimination ability did not precede linguistic tone discrimination in the developmental trajectory.
   Conclusions: Contradicting the theoretical models, the findings of this study suggest that general auditory sensitivity and speech perception may not be causally or hierarchically related. The finding that accuracy in pitch discrimination is lower than that in tone discrimination suggests that comparable nonlinguistic auditory perceptual ability may not be necessary for accurate speech perception and language learning. The results cast doubt on the use of nonlinguistic auditory perceptual training to improve children's speech, language, and literacy abilities.
C1 [Wong, Puisan; Cheng, Man Wai] Univ Hong Kong, Fac Educ, Div Speech & Hearing Sci, Pokfulam, Hong Kong, Peoples R China.
RP Wong, PS (corresponding author), Univ Hong Kong, Fac Educ, Div Speech & Hearing Sci, Pokfulam, Hong Kong, Peoples R China.
EM pswResearch@gmail.com
CR Bailey PJ, 2002, BRIT MED BULL, V63, P135, DOI 10.1093/bmb/63.1.135
   Boets B, 2011, RES DEV DISABIL, V32, P560, DOI 10.1016/j.ridd.2010.12.020
   Bradley E., 2012, CROSSLINGUISTIC PERC
   Cirrin FM, 2008, LANG SPEECH HEAR SER, V39, pS110, DOI 10.1044/0161-1461(2008/012)
   Corriveau K, 2007, J SPEECH LANG HEAR R, V50, P647, DOI 10.1044/1092-4388(2007/046)
   Corriveau KH, 2010, J LEARN DISABIL-US, V43, P369, DOI 10.1177/0022219410369071
   de Bree E, 2006, J RES READ, V29, P304, DOI 10.1111/j.1467-9817.2006.00310.x
   Farmer ME, 1995, PSYCHON B REV, V2, P460, DOI 10.3758/BF03210983
   Fey ME, 2011, LANG SPEECH HEAR SER, V42, P246, DOI 10.1044/0161-1461(2010/10-0013)
   Fu Q-J, 2000, ASIA PAC J SPEECH LA, V5, P45, DOI DOI 10.1179/136132800807547582
   Goswami U, 2000, Dyslexia, V6, P133, DOI 10.1002/(SICI)1099-0909(200004/06)6:2<133::AID-DYS160>3.0.CO;2-A
   Halliday LF, 2006, J RES READ, V29, P213, DOI 10.1111/j.1467-9817.2006.00286.x
   Hamalainen JA, 2013, J LEARN DISABIL-US, V46, P413, DOI 10.1177/0022219411436213
   Hill PR, 2005, J SPEECH LANG HEAR R, V48, P1136, DOI 10.1044/1092-4388(2005/080)
   Hong Kong Education and Manpower Bureau, 2006, CANT EXPR LANG SCAL
   Lee K. Y. S., 2012, CANTONESE TONE IDENT
   Lee KYS, 2010, ANN OTO RHINOL LARYN, V119, P258, DOI 10.1177/000348941011900409
   Levelt W. J. M., 1989, SPEAKING INTENTION A, V1
   Loo JHY, 2010, DEV MED CHILD NEUROL, V52, P708, DOI 10.1111/j.1469-8749.2010.03654.x
   LOOI V, 2015, COCHLEAR IMPLANTS IN, V16, P91, DOI DOI 10.1179/1467010015Z.000000000263
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   McArthur GM, 2008, COGNITION, V107, P946, DOI 10.1016/j.cognition.2007.12.005
   McArthur GM, 2005, BRAIN LANG, V94, P260, DOI 10.1016/j.bandl.2005.01.002
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   Menell P, 1999, J SPEECH LANG HEAR R, V42, P797, DOI 10.1044/jslhr.4204.797
   Meng XZ, 2005, DYSLEXIA, V11, P292, DOI 10.1002/dys.309
   Pasquini ES, 2007, SCI STUD READ, V11, P259, DOI 10.1080/10888430701344280
   Po Leung Kuk, 2012, CANTONESE ORAL LANGU
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   Rocheron I, 2002, NEUROREPORT, V13, P1683, DOI 10.1097/00001756-200209160-00023
   Rota-Donahue C, 2016, J AM ACAD AUDIOL, V27, P489, DOI 10.3766/jaaa.15122
   Scientific Learning Corporation, 1998, NAT FIELD TRIAL RES
   Shuai L, 2017, BEHAV RES METHODS, V49, P230, DOI 10.3758/s13428-015-0690-0
   Strehlow U, 2006, EUR CHILD ADOLES PSY, V15, P19, DOI 10.1007/s00787-006-0500-4
   Strong GK, 2011, J CHILD PSYCHOL PSYC, V52, P224, DOI 10.1111/j.1469-7610.2010.02329.x
   Tallal P, 2004, NAT REV NEUROSCI, V5, P721, DOI 10.1038/nrn1499
   Tallal P, 1996, SCIENCE, V271, P81, DOI 10.1126/science.271.5245.81
   Tallal P, 2003, CURR DIR PSYCHOL SCI, V12, P206, DOI 10.1046/j.0963-7214.2003.01263.x
   TALLAL P, 1993, ANN NY ACAD SCI, V682, P27, DOI 10.1111/j.1749-6632.1993.tb22957.x
   Tallal P., 2014, SPEECH LANGUAGE IMPA, P145
   Temple E, 2003, P NATL ACAD SCI USA, V100, P2860, DOI 10.1073/pnas.0030098100
   Thomson JM, 2013, READ WRIT, V26, P139, DOI 10.1007/s11145-012-9359-6
   Tyler LK, 2000, PSYCHON B REV, V7, P320, DOI 10.3758/BF03212988
   Wang HLS, 2016, PERCEPT MOTOR SKILL, V123, P365, DOI 10.1177/0031512516663164
   Wang S, 2013, ACTA OTO-LARYNGOL, V133, P47, DOI 10.3109/00016489.2012.705438
   Wang WQ, 2011, INT J AUDIOL, V50, P270, DOI 10.3109/14992027.2010.542490
   Weaver S. W., 1974, ELEM ENGL, V51, P1148
   Wong PS, 2018, J SPEECH LANG HEAR R, V61, P1070, DOI 10.1044/2018_JSLHR-S-17-0288
   Wong PS, 2018, J ACOUST SOC AM, V143, P765, DOI 10.1121/1.5021251
   Wong PS, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01450
   Xu Y, 2001, SPEECH COMMUN, V33, P319, DOI 10.1016/S0167-6393(00)00063-7
   Zhang JA, 2010, EDUC PSYCHOL REV, V22, P323, DOI 10.1007/s10648-010-9137-4
NR 52
TC 0
Z9 0
U1 0
U2 0
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD FEB
PY 2020
VL 63
IS 2
BP 487
EP 498
DI 10.1044/2019_JSLHR-19-00104
PG 12
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA ND2WB
UT WOS:000561764300012
PM 32073343
DA 2021-02-24
ER

PT J
AU Davies, B
   Rattanasone, NX
   Davis, A
   Demuth, K
AF Davies, Benjamin
   Rattanasone, Nan Xu
   Davis, Aleisha
   Demuth, Katherine
TI The Acquisition of Productive Plural Morphology by Children With Hearing
   Loss
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID COCHLEAR IMPLANTS; LANGUAGE-DEVELOPMENT; SENTENCE-POSITION;
   SPEECH-PERCEPTION; SKILLS; MILD; OUTCOMES; AMPLIFICATION; COMPREHENSION;
   PRESCHOOLERS
AB Purpose: Normal-hearing (NH) children acquire plural morphemes at different rates, with the segmental allomorphs /-s, -z/ (e.g., cat-s) being acquired before the syllabic allomorph /-ez/ (e.g., bus-es). Children with hearing loss (HL) have been reported to show delays in the production of plural morphology, raising the possibility that this might be due to challenges acquiring different types of lexical/morphological representations. This study therefore examined the comprehension of plural morphology by 3- to 7-year-olds with HL and compared this with performance by their NH peers. We also investigated comprehension as a function of wearing hearing aids (HAs) versus cochlear implants (Cls).
   Method: Participants included 129 NH children aged 3-5 years and 25 children with HL aged 3-7 years (13 with HAs, 12 with Cls). All participated in a novel word two-alternative forced-choice task presented on an iPad. The task tested comprehension of the segmental (e.g., teps, mubz) and syllabic (e.g., kosses) plural, as well as their singular counterparts (e.g., tep, mub, koss).
   Results: While the children with NH were above chance for all conditions, those with HL performed at chance. As a group, the performance of the children with HL did not improve with age. However, results suggest possible differences between children with HAs and those with CIs, where those with HAs appeared to be in the process of developing representations of consonant-vowel-consonant singulars.
   Conclusions: Results suggest that preschoolers with HL do not yet have a robust representation of plural morphology for words they have not heard before. However, those with HAs are beginning to access the singular/plural system as they get older.
C1 [Davies, Benjamin; Rattanasone, Nan Xu; Demuth, Katherine] Macquarie Univ, Dept Linguist, Sydney, NSW, Australia.
   [Davies, Benjamin; Rattanasone, Nan Xu; Demuth, Katherine] Macquarie Univ, ARC Ctr Excellence Cognit & Its Disorders, Sydney, NSW, Australia.
   [Davies, Benjamin; Rattanasone, Nan Xu; Davis, Aleisha; Demuth, Katherine] HEARing Cooperat Res Ctr, Melbourne, Vic, Australia.
   [Davis, Aleisha] Shepherd Ctr, Sydney, NSW, Australia.
RP Davies, B (corresponding author), Macquarie Univ, Dept Linguist, Sydney, NSW, Australia.; Davies, B (corresponding author), Macquarie Univ, ARC Ctr Excellence Cognit & Its Disorders, Sydney, NSW, Australia.; Davies, B (corresponding author), HEARing Cooperat Res Ctr, Melbourne, Vic, Australia.
EM ben.davies@mq.edu.au
OI Demuth, Katherine/0000-0003-3884-8886; Davies,
   Benjamin/0000-0002-4766-4942
FU Macquarie University; Australian Research Council Laureate
   FellowshipAustralian Research Council [FL130100014]; Australian Research
   Council Centre of Excellence in Cognition and Its DisordersAustralian
   Research Council [CE1101021]; HEARing Cooperative Research Centre, under
   the Australian Government's Cooperative Research Centres Program;
   HEARing Cooperative Research Centre
FX This research was partially funded by Macquarie University, the
   Australian Research Council Laureate Fellowship (FL130100014) awarded to
   Katherine Demuth, and the Australian Research Council Centre of
   Excellence in Cognition and Its Disorders (CE1101021). Financial support
   was also provided by the HEARing Cooperative Research Centre,
   established under the Australian Government's Cooperative Research
   Centres Program, which supports collaborations between industry,
   researchers, and the community. We thank Tracy Hopkins; Jim Hungerford;
   and the children, parents, and clinicians at The Shepherd Centre for
   their assistance with this project. We also thank Ivan Yuen, Isabel
   O'Keeffe, and others from the Child Language Lab at Macquarie University
   for their helpful feedback and Tamara Schembri and Peter Budziszewski
   from Toybox Labs for building the experimental app. We also thank Robert
   Cowan, Isabelle Boivert, and the financial support of the HEARing
   Cooperative Research Centre.
CR Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bergeson TR, 2003, VOLTA REV, V103, P347
   BERKO J, 1958, WORD, V14, P150, DOI 10.1080/00437956.1958.11659661
   Bishop D, 1989, TEST RECEPTION GRAMM
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Briscoe J, 2001, J CHILD PSYCHOL PSYC, V42, P329, DOI 10.1017/S0021963001007041
   Brown R., 1973, 1 LANGUAGE EARLY STA
   Budziszewski P., 2003, SERENITY ENGINE COMP
   Buss E, 2002, OTOL NEUROTOL, V23, P328, DOI 10.1097/00129492-200205000-00017
   Ching Teresa Y C, 2015, Perspect Hear Hear Disord Child, V25, P48
   Ching TYC, 2010, INT J SPEECH-LANG PA, V12, P124, DOI 10.3109/17549500903577022
   Davies B., 2019, LANGUAGE LEARN UNPUB
   Davies B, 2019, J EXP CHILD PSYCHOL, V185, P95, DOI 10.1016/j.jecp.2019.04.015
   Davies B, 2017, LANG LEARN DEV, V13, P38, DOI 10.1080/15475441.2016.1219257
   DAVIS JM, 1986, J SPEECH HEAR DISORD, V51, P53, DOI 10.1044/jshd.5101.53
   de Villiers J G, 1973, J Psycholinguist Res, V2, P267, DOI 10.1007/BF01067106
   Delage H, 2007, J SPEECH LANG HEAR R, V50, P1300, DOI 10.1044/1092-4388(2007/091)
   ELFENBEIN JL, 1994, J SPEECH HEAR RES, V37, P216, DOI 10.1044/jshr.3701.216
   Geers AE, 2003, EAR HEARING, V24, p46S, DOI 10.1097/01.AUD.0000051689.57380.1B
   GILBERTSON M, 1995, J SPEECH HEAR RES, V38, P630, DOI 10.1044/jshr.3803.630
   Gonzalez-Gomez N, 2017, J EXP CHILD PSYCHOL, V160, P33, DOI 10.1016/j.jecp.2017.02.010
   Harrington J., 1997, AUST J LINGUIST, V17, P155, DOI DOI 10.1080/07268609708599550
   Hart B., 1995, MEANINGFUL DIFFERENC
   Hoff E, 2003, CHILD DEV, V74, P1368, DOI 10.1111/1467-8624.00612
   Hoff E, 2002, CHILD DEV, V73, P418, DOI 10.1111/1467-8624.00415
   HOLM S, 1979, SCAND J STAT, V6, P65
   Holt CM, 2017, EAR HEARING, V38, pE101, DOI 10.1097/AUD.0000000000000362
   Holt CM, 2016, EAR HEARING, V37, pE256, DOI 10.1097/AUD.0000000000000253
   Hsieh L, 1999, J CHILD LANG, V26, P531, DOI 10.1017/S030500099900392X
   King AM, 2010, INT J AUDIOL, V49, pS64, DOI 10.3109/14992020903329422
   Koehlinger K, 2015, J SPEECH LANG HEAR R, V58, P396, DOI 10.1044/2015_JSLHR-L-14-0134
   Koehlinger KM, 2013, J SPEECH LANG HEAR R, V56, P1701, DOI 10.1044/1092-4388(2013/12-0188)
   Kouider S, 2006, LANG LEARN DEV, V2, P1, DOI 10.1207/s15473341lld0201_1
   Lederberg AR, 2000, CHILD DEV, V71, P1571, DOI 10.1111/1467-8624.00249
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Ling D., 1989, FDN SPOKEN LANGUAGE
   McGuckian M, 2007, INT J LANG COMM DIS, V42, P17, DOI 10.1080/13682820601171555
   McMurray B, 2016, EAR HEARING, V37, pe37, DOI 10.1097/AUD.0000000000000207
   Moeller MP, 2010, EAR HEARING, V31, P625, DOI 10.1097/AUD.0b013e3181df5cc2
   Nikolopoulos TP, 2004, ARCH OTOLARYNGOL, V130, P629, DOI 10.1001/archotol.130.5.629
   Nittrouer S, 2014, EAR HEARING, V35, P506, DOI 10.1097/AUD.0000000000000051
   Nott P, 2009, EAR HEARING, V30, P526, DOI 10.1097/AUD.0b013e3181a9ea14
   Penke M, 2016, LOGOP PHONIATR VOCO, V41, P9, DOI 10.3109/14015439.2014.940382
   Percy-Smith L, 2013, INT J PEDIATR OTORHI, V77, P184, DOI 10.1016/j.ijporl.2012.10.014
   Peterson Ann, 2003, J Am Acad Audiol, V14, P188
   Pittman AL, 2003, EAR HEARING, V24, P198, DOI 10.1097/01.AUD.0000069226.22983.80
   Pittman AL, 2003, J SPEECH LANG HEAR R, V46, P649, DOI 10.1044/1092-4388(2003/051)
   R Core Team, 2016, R LANG ENV STAT COMP
   Sarant JZ, 1997, AM J OTOL, V18, pS135
   SMIT AB, 1990, J SPEECH HEAR DISORD, V55, P779, DOI 10.1044/jshd.5504.779
   Song JY, 2009, J SPEECH LANG HEAR R, V52, P623, DOI 10.1044/1092-4388(2008/07-0258)
   Stelmachowicz PG, 2002, EAR HEARING, V23, P316, DOI 10.1097/00003446-200208000-00007
   Sundara M, 2011, J SPEECH LANG HEAR R, V54, P55, DOI 10.1044/1092-4388(2010/10-0056)
   Szagun G, 2001, AUDIOL NEURO-OTOL, V6, P288, DOI 10.1159/000046134
   Szagun G, 2000, AUDIOL NEURO-OTOL, V5, P39, DOI 10.1159/000013864
   The National Health and Medical Research Council, 2018, NAT STAT ETH COND HU
   Tomas E, 2017, J SPEECH LANG HEAR R, V60, P1316, DOI 10.1044/2016_JSLHR-L-16-0138
   Tomas E, 2015, INT J LANG COMM DIS, V50, P516, DOI 10.1111/1460-6984.12152
   Tomblin JB, 1999, J SPEECH LANG HEAR R, V42, P497, DOI 10.1044/jslhr.4202.497
   Vohr B, 2008, PEDIATRICS, V122, P535, DOI 10.1542/peds.2007-2028
   Wake M, 2004, EAR HEARING, V25, P1, DOI 10.1097/01.AUD.0000111262.12219.2F
   Weisleder A, 2013, PSYCHOL SCI, V24, P2143, DOI 10.1177/0956797613488145
   Xu RM, 2016, ANN APPL SPORT SCI, V4, P1, DOI 10.18869/acadpub.aassjournal.4.2.1
   Yoshinaga-Itano C, 2010, OTOL NEUROTOL, V31, P1268, DOI 10.1097/MAO.0b013e3181f1ce07
   Young GA, 2002, ANN OTO RHINOL LARYN, V111, P802, DOI 10.1177/000348940211100908
   Zapf J., 2007, FIRST LANG, V27, P53, DOI DOI 10.1177/0142723707070286
   Zimmerman I. L., 2011, PRESCHOOL LANGUAGE S
NR 68
TC 0
Z9 0
U1 0
U2 0
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD FEB
PY 2020
VL 63
IS 2
BP 552
EP 568
DI 10.1044/2019_JSLHR-19-00208
PG 17
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA ND2WB
UT WOS:000561764300016
PM 32004109
DA 2021-02-24
ER

PT J
AU Al-Fahad, R
   Yeasin, M
   Bidelman, GM
AF Al-Fahad, Rakib
   Yeasin, Mohammed
   Bidelman, Gavin M.
TI Decoding of single-trial EEG reveals unique states of functional brain
   connectivity that drive rapid speech categorization decisions
SO JOURNAL OF NEURAL ENGINEERING
LA English
DT Article
DE categorical speech perception; machine learning; speech processing;
   stability selection; functional connectivity
ID BOUNDARY-ELEMENT METHOD; AGE-RELATED-CHANGES; CATEGORICAL PERCEPTION;
   NEURAL ORGANIZATION; VARIABLE SELECTION; CEREBRAL-CORTEX;
   SEX-DIFFERENCES; REPRESENTATIONS; NETWORKS; REGIONS
AB Objective. Categorical perception (CP) is an inherent property of speech perception. The response time (RT) of listeners' perceptual speech identification is highly sensitive to individual differences. While the neural correlates of CP have been well studied in terms of the regional contributions of the brain to behavior, functional connectivity patterns that signify individual differences in listeners' speed (RT) for speech categorization is less clear. In this study, we introduce a novel approach to address these questions. Approach. We applied several computational approaches to the EEG, including graph mining, machine learning (i.e., support vector machine), and stability selection to investigate the unique brain states (functional neural connectivity) that predict the speed of listeners' behavioral decisions. Main results. We infer that (i) the listeners' perceptual speed is directly related to dynamic variations in their brain connectomics, (ii) global network assortativity and efficiency distinguished fast, medium, and slow RTs, (iii) the functional network underlying speeded decisions increases in negative assortativity (i.e., became disassortative) for slower RTs, (iv) slower categorical speech decisions cause excessive use of neural resources and more aberrant information flow within the CP circuitry, (v) slower responders tended to utilize functional brain networks excessively (or inappropriately) whereas fast responders (with lower global efficiency) utilized the same neural pathways but with more restricted organization. Significance. Findings show that neural classifiers (SVM) coupled with stability selection correctly classify behavioral RTs from functional connectivity alone with over 92% accuracy (AUC = 0.9). Our results corroborate previous studies by supporting the engagement of similar temporal (STG), parietal, motor, and prefrontal regions in CP using an entirely data-driven approach.
C1 [Al-Fahad, Rakib; Yeasin, Mohammed] Univ Memphis, Dept Elect & Comp Engn, Memphis, TN 38152 USA.
   [Yeasin, Mohammed; Bidelman, Gavin M.] Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.
   [Bidelman, Gavin M.] Univ Memphis, Sch Commun Sci & Disorders, Memphis, TN 38152 USA.
   [Bidelman, Gavin M.] Univ Tennessee, Hlth Sci Ctr, Dept Anat & Neurobiol, Memphis, TN 38163 USA.
RP Bidelman, GM (corresponding author), Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.; Bidelman, GM (corresponding author), Univ Memphis, Sch Commun Sci & Disorders, Memphis, TN 38152 USA.; Bidelman, GM (corresponding author), Univ Tennessee, Hlth Sci Ctr, Dept Anat & Neurobiol, Memphis, TN 38163 USA.
EM gmbdlman@memphis.edu
RI Al-Fahad, Rakib/ABB-9817-2020
OI Al-Fahad, Rakib/0000-0002-0124-7254; Bidelman, Gavin
   M/0000-0002-1821-3261
FU NIDCD NIH HHSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R01 DC016267] Funding Source:
   Medline
CR Acar ZA, 2013, BRAIN TOPOGR, V26, P378, DOI 10.1007/s10548-012-0274-6
   Acheson DJ, 2013, J COGNITIVE NEUROSCI, V25, P1664, DOI 10.1162/jocn_a_00430
   Al-Fahad R, 2019, IEEE ACCESS, V7, P146662, DOI [10.1109/ACCESS.2019.2946240, 10.1109/access.2019.2946240]
   Al-Fahad R, 2017, IEEE IJCNN, P1202, DOI 10.1109/IJCNN.2017.7965989
   Alho J, 2016, NEUROIMAGE, V129, P214, DOI 10.1016/j.neuroimage.2016.01.016
   Bach Francis R, 2008, P 25 INT C MACH LEAR, P33, DOI DOI 10.1145/1390156.1390161
   Bashivan P, 2017, IEEE IJCNN, P2943, DOI 10.1109/IJCNN.2017.7966220
   Bassett DS, 2006, NEUROSCIENTIST, V12, P512, DOI 10.1177/1073858406293182
   Bauer HU, 1996, NEURAL COMPUT, V8, P757, DOI 10.1162/neco.1996.8.4.757
   Betzel R F, 2018, NONASSORTATIVE COMMU
   Bidelman GM, 2019, NEUROIMAGE, V201, DOI 10.1016/j.neuroimage.2019.116022
   Bidelman GM, 2017, J NEUROSCI, V37, P3610, DOI 10.1523/JNEUROSCI.3700-16.2017
   Bidelman GM, 2017, EUR J NEUROSCI, V45, P690, DOI 10.1111/ejn.13526
   Bidelman GM, 2016, NEUROIMAGE, V124, P581, DOI 10.1016/j.neuroimage.2015.09.020
   Bidelman GM, 2015, NEUROIMAGE, V120, P191, DOI 10.1016/j.neuroimage.2015.06.087
   Bidelman GM, 2015, BRAIN LANG, V143, P32, DOI 10.1016/j.bandl.2015.02.002
   Bidelman GM, 2015, J NEUROSCI, V35, P1240, DOI 10.1523/JNEUROSCI.3292-14.2015
   Bidelman GM, 2014, NEUROBIOL AGING, V35, P2526, DOI 10.1016/j.neurobiolaging.2014.05.006
   Bidelman GM, 2014, EUR J NEUROSCI, V40, P2662, DOI 10.1111/ejn.12627
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   Blank SC, 2002, BRAIN, V125, P1829, DOI 10.1093/brain/awf191
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Bookheimer SY, 1995, HUM BRAIN MAPP, V3, P93, DOI 10.1002/hbm.460030206
   Bouton S, 2018, P NATL ACAD SCI USA, V115, pE1299, DOI 10.1073/pnas.1714279115
   Breiman L, 1999, TECHNICAL REPORT
   BRESSLER SL, 1995, BRAIN RES REV, V20, P288, DOI 10.1016/0165-0173(94)00016-I
   Brunner C, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00121
   Buhlmann P, 2002, ANN STAT, V30, P927
   Bullmore ET, 2009, NAT REV NEUROSCI, V10, P186, DOI 10.1038/nrn2575
   Calcus A, 2016, J SPEECH LANG HEAR R, V59, P835, DOI 10.1044/2016_JSLHR-H-15-0076
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Chen MM, 2014, IEEE TRANS COMPUT SO, V1, P46, DOI 10.1109/TCSS.2014.2307458
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Feng GY, 2018, CEREB CORTEX, V28, P3241, DOI 10.1093/cercor/bhx195
   Foster JG, 2010, P NATL ACAD SCI USA, V107, P10815, DOI 10.1073/pnas.0912671107
   Fries P, 2005, TRENDS COGN SCI, V9, P474, DOI 10.1016/j.tics.2005.08.011
   Frith CD, 1995, HUM BRAIN MAPP, V3, P153, DOI 10.1002/hbm.460030209
   Fuchs M, 1998, IEEE T BIO-MED ENG, V45, P980, DOI 10.1109/10.704867
   Fuchs M, 2002, CLIN NEUROPHYSIOL, V113, P702, DOI 10.1016/S1388-2457(02)00030-5
   Golestani N, 2004, NEUROIMAGE, V21, P494, DOI 10.1016/j.neuroimage.2003.09.071
   Golestani N, 2002, NEURON, V35, P997, DOI 10.1016/S0896-6273(02)00862-0
   Gramfort A, 2010, BIOMED ENG ONLINE, V9, DOI 10.1186/1475-925X-9-45
   Guenther FH, 1999, J ACOUST SOC AM, V106, P2900, DOI 10.1121/1.428112
   Guenther FH, 2004, J SPEECH LANG HEAR R, V47, P46, DOI 10.1044/1092-4388(2004/005)
   Guenther FH, 1996, J ACOUST SOC AM, V100, P1111, DOI 10.1121/1.416296
   Hakvoort B, 2016, J SPEECH LANG HEAR R, V59, P1448, DOI 10.1044/2016_JSLHR-L-15-0306
   Harnad Stevan, 1987, CATEGORICAL PERCEPTI
   Haufe S, 2013, NEUROIMAGE, V64, P120, DOI 10.1016/j.neuroimage.2012.09.036
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Honey CJ, 2007, P NATL ACAD SCI USA, V104, P10240, DOI 10.1073/pnas.0701519104
   HOWARD D, 1992, BRAIN, V115, P1769, DOI 10.1093/brain/115.6.1769
   Hwang HJ, 2013, INT J HUM-COMPUT INT, V29, P814, DOI 10.1080/10447318.2013.780869
   Ingalhalikar M, 2014, P NATL ACAD SCI USA, V111, P823, DOI 10.1073/pnas.1316909110
   James G, 2013, INTRO STAT LEARNING
   Lachaux JP, 1999, HUM BRAIN MAPP, V8, P194, DOI 10.1002/(SICI)1097-0193(1999)8:4<194::AID-HBM4>3.0.CO;2-C
   Lee YS, 2012, J NEUROSCI, V32, P3942, DOI 10.1523/JNEUROSCI.3814-11.2012
   Li W, 2016, COMPUT INTEL NEUROSC, V2016, P5
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Liebenthal E, 2010, CEREB CORTEX, V20, P2958, DOI 10.1093/cercor/bhq045
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   Lotte F, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aab2f2
   Lowry R., 2014, CONCEPTS APPL INFERE
   Luthra S, 2019, LANG COGN NEUROSCI, V34, P151, DOI 10.1080/23273798.2018.1531140
   MAZZIOTTA JC, 1995, NEUROIMAGE, V2, P89, DOI 10.1006/nimg.1995.1012
   Mechelli A, 2000, P ROY SOC B-BIOL SCI, V267, P1909, DOI 10.1098/rspb.2000.1229
   Meinshausen N, 2006, ANN STAT, V34, P1436, DOI 10.1214/009053606000000281
   Meinshausen N, 2010, J R STAT SOC B, V72, P417, DOI 10.1111/j.1467-9868.2010.00740.x
   Michel CM, 2004, CLIN NEUROPHYSIOL, V115, P2195, DOI 10.1016/j.clinph.2004.06.001
   Myers EB, 2009, PSYCHOL SCI, V20, P895, DOI 10.1111/j.1467-9280.2009.02380.x
   Newman MEJ, 2004, PHYS REV E, V69, DOI [10.1103/PhysRevE.69.066133, 10.1103/PhysRevE.69.026113]
   Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480
   Newman MEJ, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.208701
   Nolte G, 2004, CLIN NEUROPHYSIOL, V115, P2292, DOI 10.1016/j.clinph.2004.04.029
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Phillips C, 2001, COGNITIVE SCI, V25, P711, DOI 10.1016/S0364-0213(01)00049-0
   Picton TW, 2000, CLIN NEUROPHYSIOL, V111, P53, DOI 10.1016/S1388-2457(99)00227-8
   Piraveenan M, 2012, IEEE ACM T COMPUT BI, V9, P66, DOI 10.1109/TCBB.2010.80
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   PISONI DB, 1987, COGNITION, V25, P21, DOI 10.1016/0010-0277(87)90003-5
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   Prather JF, 2009, NAT NEUROSCI, V12, P221, DOI 10.1038/nn.2246
   Price CN, 2019, NEUROSCIENCE, V423, P18, DOI 10.1016/j.neuroscience.2019.10.044
   Reetzke R, 2018, CURR BIOL, V28, P1419, DOI 10.1016/j.cub.2018.03.026
   Rubinov M, 2010, NEUROIMAGE, V52, P1059, DOI 10.1016/j.neuroimage.2009.10.003
   Sakurai Y, 2008, BEHAV NEUROL, V19, P93, DOI 10.1155/2008/393912
   Salvador R, 2005, CEREB CORTEX, V15, P1332, DOI 10.1093/cercor/bhi016
   Shah RD, 2013, J R STAT SOC B, V75, P55, DOI 10.1111/j.1467-9868.2011.01034.x
   SHAYWITZ BA, 1995, NATURE, V373, P607, DOI 10.1038/373607a0
   Shirazi S Y, 2019, MORE RELIABLE EEG EL
   Song J, 2015, J NEUROSCI METH, V256, P9, DOI 10.1016/j.jneumeth.2015.08.015
   Stam CJ, 2014, INT J PSYCHOPHYSIOL, V92, P129, DOI 10.1016/j.ijpsycho.2014.04.001
   Tadel F, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/879716
   Temlyakov VN, 2000, ADV COMPUT MATH, V12, P213, DOI 10.1023/A:1018917218956
   Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   TONONI G, 1994, P NATL ACAD SCI USA, V91, P5033, DOI 10.1073/pnas.91.11.5033
   Toscano JC, 2018, BRAIN LANG, V184, P32, DOI 10.1016/j.bandl.2018.06.006
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang L, 2010, NEUROIMAGE, V50, P862, DOI 10.1016/j.neuroimage.2010.01.044
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Xia M, 2013, PLOS ONE
   Zhao P, 2006, J MACH LEARN RES, V7, P2541
   Zhou DL, 2009, NEUROIMAGE, V47, P1590, DOI 10.1016/j.neuroimage.2009.05.089
NR 106
TC 1
Z9 1
U1 0
U2 0
PU IOP PUBLISHING LTD
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 1741-2560
EI 1741-2552
J9 J NEURAL ENG
JI J. Neural Eng.
PD FEB
PY 2020
VL 17
IS 1
AR 016045
DI 10.1088/1741-2552/ab6040
PG 18
WC Engineering, Biomedical; Neurosciences
SC Engineering; Neurosciences & Neurology
GA LK4HD
UT WOS:000530820600002
PM 31822643
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Levy, DF
   Wilson, SM
AF Levy, Deborah F.
   Wilson, Stephen M.
TI Categorical Encoding of Vowels in Primary Auditory Cortex
SO CEREBRAL CORTEX
LA English
DT Article
DE auditory pathway; hierarchical processing; multivariate pattern
   analysis; speech perception
ID STEADY-STATE VOWELS; SPEECH-PERCEPTION; INDIVIDUAL-DIFFERENCES; NEURAL
   REPRESENTATION; PHONEME; VOICE; DISCRIMINATION; SOFTWARE; REGIONS;
   PATTERN
AB Speech perception involves mapping from a continuous and variable acoustic speech signal to discrete, linguistically meaningful units. However, it is unclear where in the auditory processing stream speech sound representations cease to be veridical (faithfully encoding precise acoustic properties) and become categorical (encoding sounds as linguistic categories). In this study, we used functional magnetic resonance imaging and multivariate pattern analysis to determine whether tonotopic primary auditory cortex (PAC), defined as tonotopic voxels falling within Heschl's gyrus, represents one class of speech sounds-vowels-veridically or categorically. For each of 15 participants, 4 individualized synthetic vowel stimuli were generated such that the vowels were equidistant in acoustic space, yet straddled a categorical boundary (with the first 2 vowels perceived as [I] and the last 2 perceived as [I]). Each participant's 4 vowels were then presented in a block design with an irrelevant but attention-demanding level change detection task. We found that in PAC bilaterally, neural discrimination between pairs of vowels that crossed the categorical boundary was more accurate than neural discrimination between equivalently spaced vowel pairs that fell within a category. These findings suggest that PAC does not represent vowel sounds veridically, but that encoding of vowels is shaped by linguistically relevant phonemic categories.
C1 [Levy, Deborah F.; Wilson, Stephen M.] Vanderbilt Univ, Med Ctr, Dept Hearing & Speech Sci, 1215 21st Ave S,MCE 8310, Nashville, TN 37232 USA.
RP Levy, DF (corresponding author), Vanderbilt Univ, Med Ctr, Dept Hearing & Speech Sci, 1215 21st Ave S,MCE 8310, Nashville, TN 37232 USA.
EM deborah.f.levy@vanderbilt.edu
OI Levy, Deborah/0000-0002-1389-2525; Wilson, Stephen/0000-0001-9884-2852
FU National Institute on Deafness and Other Communication Disorders at the
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01 DC013270]
FX National Institute on Deafness and Other Communication Disorders at the
   National Institutes of Health (R01 DC013270).
CR Alho J, 2016, NEUROIMAGE, V129, P214, DOI 10.1016/j.neuroimage.2016.01.016
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Boatman DF, 2005, J NEUROSCI, V25, P5475, DOI 10.1523/JNEUROSCI.0936-05.2005
   Bonte M, 2014, J NEUROSCI, V34, P4548, DOI 10.1523/JNEUROSCI.4339-13.2014
   Bouton S, 2018, P NATL ACAD SCI USA, V115, pE1299, DOI 10.1073/pnas.1714279115
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Chevillet MA, 2013, J NEUROSCI, V33, P5208, DOI 10.1523/JNEUROSCI.1870-12.2013
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   Crothers J, 1978, UNIVERSALS HUMAN LAN, V2, P93
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Dick F, 2012, J NEUROSCI, V32, P16095, DOI 10.1523/JNEUROSCI.1712-12.2012
   Dick FK, 2017, J NEUROSCI, V37, P12187, DOI 10.1523/JNEUROSCI.1436-17.2017
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   Evans S, 2015, CEREB CORTEX, V25, P4772, DOI 10.1093/cercor/bhv136
   Feng GY, 2018, CEREB CORTEX, V28, P3241, DOI 10.1093/cercor/bhx195
   Fisher JM, 2018, NEUROIMAGE, V178, P574, DOI 10.1016/j.neuroimage.2018.05.072
   Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318
   Fritz J, 2005, HEARING RES, V206, P159, DOI 10.1016/j.heares.2005.01.015
   Gerrits E, 2004, PERCEPT PSYCHOPHYS, V66, P363, DOI 10.3758/BF03194885
   Hackett Troy A, 2015, Handb Clin Neurol, V129, P27, DOI 10.1016/B978-0-444-62630-1.00002-0
   Hasson U, 2007, NEURON, V56, P1116, DOI 10.1016/j.neuron.2007.09.037
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   IVERSON P, 1995, J ACOUST SOC AM, V97, P553, DOI 10.1121/1.412280
   Joanisse MF, 2007, CEREB CORTEX, V17, P2084, DOI 10.1093/cercor/bhl124
   Kilian-Hutten N, 2011, J NEUROSCI, V31, P1715, DOI 10.1523/JNEUROSCI.4572-10.2011
   KLATT DH, 1980, J ACOUST SOC AM, V67, P971, DOI 10.1121/1.383940
   Kluender KR, 1998, J ACOUST SOC AM, V104, P3568, DOI 10.1121/1.423939
   Kong EJ, 2016, J PHONETICS, V59, P40, DOI 10.1016/j.wocn.2016.08.006
   Krishnan A, 2009, BRAIN LANG, V110, P135, DOI 10.1016/j.bandl.2009.03.005
   Lee YS, 2012, J NEUROSCI, V32, P3942, DOI 10.1523/JNEUROSCI.3814-11.2012
   Leonard MK, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13619
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Liebenthal E, 2005, CEREB CORTEX, V15, P1621, DOI 10.1093/cercor/bhi040
   LINDBLOM B., 1986, EXPT PHONOLOGY, P13
   Lopez-Zamora M, 2012, SCI STUD READ, V16, P443, DOI 10.1080/10888438.2011.588763
   Malberg B., 1968, MANUAL PHONETICS, P173
   MASSARO DW, 1989, COGNITIVE PSYCHOL, V21, P398, DOI 10.1016/0010-0285(89)90014-5
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Moerel M, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00225
   Myers EB, 2009, PSYCHOL SCI, V20, P895, DOI 10.1111/j.1467-9280.2009.02380.x
   Nelken I, 2008, FRONT NEUROSCI-SWITZ, V2, P107, DOI 10.3389/neuro.01.009.2008
   Nelken I, 2008, CURR OPIN NEUROBIOL, V18, P413, DOI 10.1016/j.conb.2008.08.014
   Niwa M, 2012, J NEUROSCI, V32, P3193, DOI 10.1523/JNEUROSCI.0767-11.2012
   Obleser J, 2007, CEREB CORTEX, V17, P2251, DOI 10.1093/cercor/bhl133
   Obleser J, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00232
   Ohl FW, 2001, NATURE, V412, P733, DOI 10.1038/35089076
   Oosterhof NN, 2016, FRONT NEUROINFORM, V10, DOI 10.3389/fninf.2016.00027
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   PISONI DB, 1987, COGNITION, V25, P21, DOI 10.1016/0010-0277(87)90003-5
   Polka L, 2011, J PHONETICS, V39, P467, DOI 10.1016/j.wocn.2010.08.007
   Raizada RDS, 2007, NEURON, V56, P726, DOI 10.1016/j.neuron.2007.11.001
   SACHS MB, 1979, J ACOUST SOC AM, V66, P470, DOI 10.1121/1.383098
   Saenz M, 2014, HEARING RES, V307, P42, DOI 10.1016/j.heares.2013.07.016
   SERENO MI, 1995, SCIENCE, V268, P889, DOI 10.1126/science.7754376
   Steinschneider M, 1999, J NEUROPHYSIOL, V82, P2346
   Steinschneider M, 2005, CEREB CORTEX, V15, P170, DOI 10.1093/cercor/bhh120
   Steinschneider M, 2003, J ACOUST SOC AM, V114, P307, DOI 10.1121/1.1582449
   Steinschneider M, 2013, SPRINGER HANDB AUDIT, V45, P151, DOI 10.1007/978-1-4614-2350-8_6
   Steinschneider M, 2011, CEREB CORTEX, V21, P2332, DOI 10.1093/cercor/bhr014
   Stelzer J, 2013, NEUROIMAGE, V65, P69, DOI 10.1016/j.neuroimage.2012.09.063
   Striem-Amit E, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017832
   Turkeltaub PE, 2010, BRAIN LANG, V114, P1, DOI 10.1016/j.bandl.2010.03.008
   Uppenkamp S, 2006, NEUROIMAGE, V31, P1284, DOI 10.1016/j.neuroimage.2006.01.004
   van Hessen AJ, 1999, PHONETICA, V56, P56, DOI 10.1159/000028441
   Versnel H, 1998, J ACOUST SOC AM, V103, P2502, DOI 10.1121/1.422771
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
   Wilson SM, 2018, NEUROIMAGE, V171, P62, DOI 10.1016/j.neuroimage.2017.12.068
   Worsley KJ, 2002, NEUROIMAGE, V15, P1, DOI 10.1006/nimg.2001.0933
   Young ED, 2008, PHILOS T R SOC B, V363, P923, DOI 10.1098/rstb.2007.2151
   Zevin JD, 2005, BEHAV BRAIN FUNCT, V1, DOI 10.1186/1744-9081-1-4
   Zevin JD, 2010, J NEUROSCI, V30, P1110, DOI 10.1523/JNEUROSCI.4599-09.2010
   Zhang QT, 2016, EUR J NEUROSCI, V43, P773, DOI 10.1111/ejn.13164
   Zhao TC, 2018, P NATL ACAD SCI USA, V115, P8716, DOI 10.1073/pnas.1800186115
NR 79
TC 3
Z9 3
U1 1
U2 2
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 1047-3211
EI 1460-2199
J9 CEREB CORTEX
JI Cereb. Cortex
PD FEB
PY 2020
VL 30
IS 2
BP 618
EP 627
DI 10.1093/cercor/bhz112
PG 10
WC Neurosciences
SC Neurosciences & Neurology
GA LJ8VZ
UT WOS:000530440700015
PM 31241149
OA Green Published
DA 2021-02-24
ER

PT J
AU Winskel, H
AF Winskel, Heather
TI Learning to Read in Multilingual Malaysia: A Focus on Bahasa Melayu,
   Tamil and Chinese
SO GEMA ONLINE JOURNAL OF LANGUAGE STUDIES
LA English
DT Article
DE Bahasa Melayu; Chinese; Learning to read; Malaysia; Tamil
ID CROSS-LANGUAGE TRANSFER; TEACH PHONEMIC AWARENESS; PHONOLOGICAL
   AWARENESS; MORPHOLOGICAL AWARENESS; YOUNG-CHILDREN; ORTHOGRAPHIC
   KNOWLEDGE; DEVELOPMENTAL DYSLEXIA; SPEECH-PERCEPTION; WORD RECOGNITION;
   LITERACY SKILLS
AB Learning to read fluently is an extremely important skill for all children to acquire. The current article focuses on learning to read in the most widely spoken languages of Malaysia, namely, the national language Bahasa Melayu, Tamil and Chinese. These three unrelated languages have quite distinct writing systems. Bahasa Melayu uses alphabetic Rumi or Roman script, Tamil has an alphasyllabary, and Chinese has a logographic or morphosyllabic writing system. Moreover, many of these children are learning to speak and read in more than one language. When we consider the task of these biscriptal learners, a complex picture emerges, as they may have to learn to map different phonological and orthographic systems. Furthermore, many children in Malaysia have the additional challenge of learning English as a second language. First, a brief review of the characteristics of the three main languages and their orthographies is given. Subsequently, research on phonological awareness, an important skill associated with success in reading, is reviewed. Initially, phonological awareness and reading in single language studies is examined prior to reviewing some research on bilingual learners. As these three languages have rich morphological systems, we will also briefly examine some research on morphological awareness and reading. A review of the literature reveals that children who speak a language with a similar orthography to a second language may have some advantage when learning to read that second language in comparison to children whose first and second languages and orthographies are unrelated.
C1 [Winskel, Heather] Southern Cross Univ, Psychol, Sch Hlth & Human Sci, Coffs Harbour, Australia.
RP Winskel, H (corresponding author), Southern Cross Univ, Psychol, Sch Hlth & Human Sci, Coffs Harbour, Australia.
EM heather.winskel@sc.eudu.au
CR Adams M. J., 1990, BEGINNING TO READ
   Baker C., 2006, FDN BILINGUAL ED BIL
   Barzillai M., 2018, 1 MONDAY, V23, DOI [10.5210/fm.v23i10.9437, DOI 10.5210/FM.V23I10.9437]
   Bhuvaneshwari B, 2014, SOUTH AND SOUTHEAST ASIAN PSYCHOLINGUISTICS, P192
   Bialystok E, 2005, J EDUC PSYCHOL, V97, P580, DOI 10.1037/0022-0663.97.4.580
   Bialystok E, 2003, APPL PSYCHOLINGUIST, V24, P27, DOI 10.1017/S014271640300002X
   BRADLEY L, 1983, NATURE, V301, P419, DOI 10.1038/301419a0
   Bright William, 2000, STUDIES LINGUISTIC S, V30, P63
   BRUCK M, 1995, J CHILD LANG, V22, P307, DOI 10.1017/S0305000900009806
   BYRNE B, 1993, J EDUC PSYCHOL, V85, P104, DOI 10.1037/0022-0663.85.1.104
   BYRNE B, 1995, J EDUC PSYCHOL, V87, P488, DOI 10.1037/0022-0663.87.3.488
   Byrne B, 2000, J EDUC PSYCHOL, V92, P659, DOI 10.1037//0022-0663.92.4.659
   CARAVOLAS M, 1993, J EXP CHILD PSYCHOL, V55, P1, DOI 10.1006/jecp.1993.1001
   Carlisle J. F., 1995, MORPHOLOGICAL ASPECT, P189, DOI DOI 10.4236/PSYCH.2014.58103
   Carlisle JF, 2000, READ WRIT, V12, P169, DOI 10.1023/A:1008131926604
   Chang LY, 2016, SCI STUD READ, V20, P64, DOI 10.1080/10888438.2015.1104688
   Cheung H, 2001, COGNITION, V81, P227, DOI 10.1016/S0010-0277(01)00136-6
   Chiappe P, 1999, J EDUC PSYCHOL, V91, P20, DOI 10.1037/0022-0663.91.1.20
   COSSU G, 1988, APPL PSYCHOLINGUIST, V9, P1, DOI 10.1017/S0142716400000424
   Daniels PT, 2018, SCI STUD READ, V22, P101, DOI 10.1080/10888438.2017.1379082
   de Souza GN, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02531
   DEMANRIQUE AMB, 1994, BRIT J EDUC PSYCHOL, V64, P429
   DURGUNOGLU AY, 1993, J EDUC PSYCHOL, V85, P453, DOI 10.1037/0022-0663.85.3.453
   Frost R, 2006, DEVELOPMENTAL SCI, V9, P439, DOI 10.1111/j.1467-7687.2006.00523.x
   Gafoor A., 2013, GURU J BEHAV SOCIAL, V1, P128
   Goswami U, 2003, TRENDS COGN SCI, V7, P534, DOI 10.1016/j.tics.2003.10.003
   Goswami U, 2000, Dyslexia, V6, P133, DOI 10.1002/(SICI)1099-0909(200004/06)6:2<133::AID-DYS160>3.0.CO;2-A
   Goswami U., 1999, LEARNING READ WRITE, P51
   Goswami U., 1990, PHONOLOGICAL SKILLS
   Gottardo A, 2001, J EDUC PSYCHOL, V93, P530, DOI 10.1037/0022-0663.93.3.530
   Gottardo A, 2016, APPL PSYCHOLINGUIST, V37, P1083, DOI 10.1017/S0142716415000508
   HANSEN J, 1994, CHILD DEV, V65, P938, DOI 10.2307/1131429
   HARRIS M, 1999, LEARNING READ WRITE
   Hatcher PJ, 2004, J CHILD PSYCHOL PSYC, V45, P338, DOI 10.1111/j.1469-7610.2004.00225.x
   Hindson B, 2005, J EDUC PSYCHOL, V97, P687, DOI 10.1037/0022-0663.97.4.687
   Ho CSH, 1997, READ RES QUART, V32, P276, DOI 10.1598/RRQ.32.3.3
   Hulme C, 2002, J EXP CHILD PSYCHOL, V82, P2, DOI 10.1006/jecp.2002.2670
   Jimenez Gonzalez J E, 2000, Span J Psychol, V3, P37
   Joshi RM, 2019, LIT STUD, V17, P3, DOI 10.1007/978-3-030-05977-4_1
   Karim Nik Safiah, 2004, TATABAHASA DEWAN
   Ku Y., 2003, READ WRIT, V16, P399, DOI [DOI 10.1023/A:1024227231216, 10.1023/A:1024227231216]
   Kuo LJ, 2006, EDUC PSYCHOL-US, V41, P161, DOI 10.1207/s15326985ep4103_3
   Lee JAC, 2017, READ WRIT Q, V33, P226, DOI 10.1080/10573569.2016.1165639
   Lee L.W., 2019, WRITING SYSTEMS RES, DOI [10.1080/17586801.2019.1662533, DOI 10.1080/17586801.2019.1662533]
   Lee LW, 2019, AUST J LEARN DIFFIC, V24, P163, DOI 10.1080/19404158.2019.1661261
   Lee LW, 2016, COMPUT ASSIST LANG L, V29, P1019, DOI 10.1080/09588221.2015.1129347
   Lee LW, 2011, DYSLEXIA, V17, P19, DOI 10.1002/dys.421
   Liow SJR, 1998, APPL PSYCHOLINGUIST, V19, P339, DOI 10.1017/S0142716400010213
   Liow SR, 2014, SOUTH AND SOUTHEAST ASIAN PSYCHOLINGUISTICS, P212
   Loizou M, 2003, J RES READ, V26, P3, DOI 10.1111/1467-9817.261002
   MACLEAN M, 1987, MERRILL PALMER QUART, V33, P255
   Mayer C, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.03054
   McBride-Chang C, 2003, J EDUC PSYCHOL, V95, P743, DOI 10.1037/0022-0663.95.4.743
   MCBRIDECHANG C, 1995, EDUC PSYCHOL, V30, P109, DOI 10.1207/s15326985ep3003_2
   Mishra R, 2007, J RES READ, V30, P23, DOI 10.1111/j.1467-9817.2006.00326.x
   Nag S, 2007, J RES READ, V30, P7, DOI 10.1111/j.1467-9817.2006.00329.x
   Nag S, 2019, LIT STUD, V17, P55, DOI 10.1007/978-3-030-05977-4_4
   Nagy W, 2003, J EDUC PSYCHOL, V95, P730, DOI 10.1037/0022-0663.95.4.730
   O'Brien BA, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02625
   O'Brien BA, 2019, READ WRIT, V32, P909, DOI 10.1007/s11145-018-9890-1
   Padakannaya P., 2002, 13 WORLD C APPL PSYC
   Pasquarella A, 2015, J EDUC PSYCHOL, V107, P96, DOI 10.1037/a0036966
   Perfetti C. A., 2008, LEARNING READ LANGUA, P13, DOI DOI 10.4324/9780203935668
   Rao C., 2017, J CULTURAL COGNITIVE, V1, P46
   Rickard L. S. J., 2004, READING WRITING INTE, V17, P7, DOI DOI 10.1023/B:READ.0000013833.79570.DE
   Salehuddin K., 2009, FIRST LANG, V29, P291, DOI DOI 10.1177/0142723709103187
   Salehuddin K, 2014, SOUTH AND SOUTHEAST ASIAN PSYCHOLINGUISTICS, P71
   Sarma VM, 2014, SOUTH AND SOUTHEAST ASIAN PSYCHOLINGUISTICS, P110
   Share D. L., 2016, WRIT SYST RES, V8, P17, DOI DOI 10.1080/17586801.2015.1016395
   Singson M, 2000, READ WRIT, V12, P219, DOI 10.1023/A:1008196330239
   SNOWLING M, 1986, J EXP CHILD PSYCHOL, V41, P489, DOI 10.1016/0022-0965(86)90006-8
   Snowling MJ, 2011, BRIT J EDUC PSYCHOL, V81, P1, DOI 10.1111/j.2044-8279.2010.02014.x
   STANOVICH KE, 1984, J EXP CHILD PSYCHOL, V38, P175, DOI 10.1016/0022-0965(84)90120-6
   Stuart-Smith J., 1999, INT J BILINGUAL, V3, P55, DOI DOI 10.1177/13670069990030010401
   StuartSmith J, 1997, EDUC REV, V49, P181, DOI 10.1080/0013191970490208
   TUNMER WE, 1985, J EDUC PSYCHOL, V77, P417, DOI 10.1037/0022-0663.77.4.417
   Vaid J, 2002, BRAIN LANG, V81, P679, DOI 10.1006/brln.2001.2556
   WAGNER RK, 1994, DEV PSYCHOL, V30, P73, DOI 10.1037/0012-1649.30.1.73
   Wang M, 2005, COGNITION, V97, P67, DOI 10.1016/j.cognition.2004.10.001
   Wang M, 2003, APPL PSYCHOLINGUIST, V24, P1, DOI 10.1017/S0142716403000018
   Wang M, 2006, J EDUC PSYCHOL, V98, P542, DOI 10.1037/0022-0663.98.3.542
   WIMMER H, 1994, COGNITION, V51, P91, DOI 10.1016/0010-0277(94)90010-8
   Winskel H, 2007, APPL PSYCHOLINGUIST, V28, P23, DOI 10.1017/S0142716407070026
   Winskel H, 2014, SOUTH AND SOUTHEAST ASIAN PSYCHOLINGUISTICS, P179
   Yu LL, 2017, TRENDS COGN SCI, V21, P721, DOI 10.1016/j.tics.2017.06.004
   Zhang DB, 2017, APPL PSYCHOLINGUIST, V38, P395, DOI 10.1017/S0142716416000278
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
NR 87
TC 1
Z9 1
U1 2
U2 2
PU PENERBIT UNIV KEBANGSAAN MALAYSIA
PI BANGI
PA PENERBIT UNIV KEBANGSAAN MALAYSIA, FAC ECONOMICS & MANAGEMENT, BANGI,
   SELANGOR 43600, MALAYSIA
SN 1675-8021
J9 GEMA ONLINE J LANG S
JI GEMA Online J. Lang. Stud.
PD FEB
PY 2020
VL 20
IS 1
BP 1
EP 15
DI 10.17576/gema-2020-2001-01
PG 15
WC Language & Linguistics
SC Linguistics
GA KS6GY
UT WOS:000518406500001
OA DOAJ Gold, Green Accepted
DA 2021-02-24
ER

PT J
AU Bosker, HR
   Cooke, M
AF Bosker, Hans Rutger
   Cooke, Martin
TI Enhanced amplitude modulations contribute to the Lombard intelligibility
   benefit: Evidence from the Nijmegen Corpus of Lombard Speech
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID THETA OSCILLATIONS; TALKER; RECOGNITION; PERCEPTION; TRACKING; SPEAKER;
   NOISE
AB Speakers adjust their voice when talking in noise, which is known as Lombard speech. These acoustic adjustments facilitate speech comprehension in noise relative to plain speech (i.e., speech produced in quiet). However, exactly which characteristics of Lombard speech drive this intelligibility benefit in noise remains unclear. This study assessed the contribution of enhanced amplitude modulations to the Lombard speech intelligibility benefit by demonstrating that (1) native speakers of Dutch in the Nijmegen Corpus of Lombard Speech produce more pronounced amplitude modulations in noise vs in quiet; (2) more enhanced amplitude modulations correlate positively with intelligibility in a speech-in-noise perception experiment; (3) transplanting the amplitude modulations from Lombard speech onto plain speech leads to an intelligibility improvement, suggesting that enhanced amplitude modulations in Lombard speech contribute towards intelligibility in noise. Results are discussed in light of recent neurobiological models of speech perception with reference to neural oscillators phase-locking to the amplitude modulations in speech, guiding the processing of speech.
C1 [Bosker, Hans Rutger] Max Planck Inst Psycholinguist, Psychol Language Dept, Wundtlaan 1,POB 310, NL-6500 AH Nijmegen, Netherlands.
   [Cooke, Martin] Univ Basque Country, Language & Speech Lab, Calle Justo Velez de Elorriaga 1, Vitoria 01006, Spain.
   [Bosker, Hans Rutger] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
   [Cooke, Martin] Basque Sci Fdn, Ikerbasque, Bilbao, Spain.
RP Bosker, HR (corresponding author), Max Planck Inst Psycholinguist, Psychol Language Dept, Wundtlaan 1,POB 310, NL-6500 AH Nijmegen, Netherlands.
EM HansRutger.Bosker@mpi.nl
FU Max Planck Society for the Advancement of Science, Munich, GermanyMax
   Planck Society; Basque Government Consolidados grant to the Language and
   Speech Laboratory at the University of the Basque Country
FX This research was supported by the Max Planck Society for the
   Advancement of Science, Munich, Germany (H.R.B.) and by funding from the
   Basque Government Consolidados grant to the Language and Speech
   Laboratory at the University of the Basque Country (M.C.). We would like
   to thank Chris-Jan Beerendonk for technical support, Esther Janse and
   Margret van Beuningen from the Centre for Language Studies, Radboud
   University, Nijmegen, for providing the audiometer, Rosemarije
   Weterings, Esther de Kerf, and Inge Pasman for their help in testing
   participants, the student-assistants of the Psychology of Language
   department of the Max Planck Institute for Psycholinguistics for their
   help in coding participants' responses, and Annelies van Wijngaarden who
   coordinated their efforts.
CR [Anonymous], 2015, Arthritis Rheumatol, V67 Suppl 10, P1, DOI 10.1002/art.39448
   [Anonymous], 2009, GMS HLTH TECHNOL ASS, V5, pDoc14, DOI DOI 10.1371/JOURNAL.PCBI.1000302
   [Anonymous], 2020, LANGUAGE ARCH
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Bosker H. R, 2017, P INT 2017 STOCKH
   Bosker HR, 2018, LANG COGN NEUROSCI, V33, P955, DOI 10.1080/23273798.2018.1439179
   Bosker HR, 2018, J ACOUST SOC AM, V143, DOI 10.1121/1.5024404
   Bosker HR, 2017, ATTEN PERCEPT PSYCHO, V79, P333, DOI 10.3758/s13414-016-1206-4
   Bradlow AR, 1996, SPEECH COMMUN, V20, P255, DOI 10.1016/S0167-6393(96)00063-5
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   Cooke M, 2014, J ACOUST SOC AM, V135, P874, DOI 10.1121/1.4861342
   Cooke M, 2014, COMPUT SPEECH LANG, V28, P543, DOI 10.1016/j.csl.2013.08.003
   Cooke M, 2013, SPEECH COMMUN, V55, P572, DOI 10.1016/j.specom.2013.01.001
   Ding N, 2017, NEUROSCI BIOBEHAV R, V81, P181, DOI 10.1016/j.neubiorev.2017.02.011
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   DREHER JJ, 1957, J ACOUST SOC AM, V29, P1320, DOI 10.1121/1.1908780
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P2670, DOI 10.1121/1.409836
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P1053, DOI 10.1121/1.408467
   Flinker A, 2019, NAT HUM BEHAV, V3, P393, DOI 10.1038/s41562-019-0548-z
   Garnier M, 2010, J SPEECH LANG HEAR R, V53, P588, DOI 10.1044/1092-4388(2009/08-0138)
   Ghitza O, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00238
   Ghitza O, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00130
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Godoy E, 2014, COMPUT SPEECH LANG, V28, P629, DOI 10.1016/j.csl.2013.09.007
   Golumbic EMZ, 2012, BRAIN LANG, V122, P151, DOI 10.1016/j.bandl.2011.12.010
   Golumbic EZ, 2013, J NEUROSCI, V33, P1417, DOI 10.1523/JNEUROSCI.3675-12.2013
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Hickok G., 2015, NEUROBIOLOGY LANGUAG, P463
   Hotchkin C, 2013, BIOL REV, V88, P809, DOI 10.1111/brv.12026
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Kosem A, 2018, CURR BIOL, V28, P2867, DOI 10.1016/j.cub.2018.07.023
   Koutsogiannaki M, 2016, INTERSPEECH, P2508, DOI 10.21437/Interspeech.2016-500
   Krause JC, 2009, J ACOUST SOC AM, V125, P3346, DOI 10.1121/1.3097491
   Kusumoto A, 2005, SPEECH COMMUN, V45, P101, DOI 10.1016/j.specom.2004.06.003
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735
   Lombard E., 1911, ANN MALADIES OREILLE, V37, P101
   Lu YY, 2009, SPEECH COMMUN, V51, P1253, DOI 10.1016/j.specom.2009.07.002
   Luke SG, 2017, BEHAV RES METHODS, V49, P1494, DOI 10.3758/s13428-016-0809-y
   Luo JH, 2015, SCI REP-UK, V5, DOI 10.1038/srep18556
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Pittman AL, 2001, J SPEECH LANG HEAR R, V44, P487, DOI 10.1044/1092-4388(2001/038)
   Pyrzynska K, 2019, SEP PURIF REV, V48, P65, DOI 10.1080/15422119.2018.1430589
   Quene H, 2008, J MEM LANG, V59, P413, DOI 10.1016/j.jml.2008.02.002
   R Development Core Team, 2012, R LANG ENV STAT COMP
   Saigusa J., 2019, P 19 INT C PHON SCI, P5
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464
   StephanWindecker, 2015, Rev Esp Cardiol (Engl Ed), V68, P144, DOI 10.1016/j.rec.2014.12.006
   VANSUMMERS W, 1988, J ACOUST SOC AM, V84, P917, DOI 10.1121/1.396660
   Varnet L, 2017, J ACOUST SOC AM, V142, P1976, DOI 10.1121/1.5006179
   Versfeld NJ, 2000, J ACOUST SOC AM, V107, P1671, DOI 10.1121/1.428451
NR 56
TC 1
Z9 1
U1 1
U2 2
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD FEB
PY 2020
VL 147
IS 2
BP 721
EP 730
DI 10.1121/10.0000646
PG 10
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA KS9JG
UT WOS:000518623900001
PM 32113258
DA 2021-02-24
ER

PT J
AU Lindenbeck, MJ
   Laback, B
   Majdak, P
   Srinivasan, S
AF Lindenbeck, Martin J.
   Laback, Bernhard
   Majdak, Piotr
   Srinivasan, Sridhar
TI Temporal-pitch sensitivity in electric hearing with amplitude modulation
   and inserted pulses with short inter-pulse intervals
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID COCHLEAR IMPLANTS; FUNDAMENTAL-FREQUENCY; RATE DISCRIMINATION;
   SPEECH-PERCEPTION; DELAY SENSITIVITY; TIME DIFFERENCES; FINE-STRUCTURE;
   STIMULATION; CUES; ENVELOPE
AB Listeners with cochlear implants (CIs) typically show poor sensitivity to the temporal-envelope pitch of high-rate pulse trains. Sensitivity to interaural time differences improves when adding pulses with short inter-pulse intervals (SIPIs) to high-rate pulse trains. In the current study, monaural temporal-pitch sensitivity with SIPI pulses was investigated for six CI listeners. Amplitude-modulated single-electrode stimuli, representing the coding of the fundamental frequency (F0) in the envelope of a high-rate carrier, were used. Two SIPI-insertion approaches, five modulation depths, two typical speech-F0s, and two carrier rates were tested. SIPI pulses were inserted either in every amplitude-modulation period (full-rate SIPI) to support the F0 cue or in every other amplitude-modulation period (half-rate SIPI) to circumvent a potential rate limitation at higher F0s. The results demonstrate that full-rate SIPI pulses improve temporal-pitch sensitivity across F0s and particularly at low modulation depths where envelope-pitch cues are weak. The half-rate SIPI pulses did not circumvent the limitation and further increased variability across listeners. Further, no effect of the carrier rate was found. Thus, the SIPI approach appears to be a promising approach to enhance CI listeners' access to temporal-envelope pitch cues at pulse rates used clinically.
C1 [Lindenbeck, Martin J.; Laback, Bernhard; Majdak, Piotr; Srinivasan, Sridhar] Austrian Acad Sci, Acoust Res Inst, Wohllebengasse 12-14, A-1040 Vienna, Austria.
RP Laback, B (corresponding author), Austrian Acad Sci, Acoust Res Inst, Wohllebengasse 12-14, A-1040 Vienna, Austria.
EM bernhard.laback@oeaw.ac.at
RI Lindenbeck, Martin J./AAN-4397-2020
OI Lindenbeck, Martin J./0000-0001-7779-4767
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01 DC 005775]; OeAD
   [MULT_DR 11/2017n]
FX We are grateful to our CI listeners for their patience and enthusiasm
   while conducting the tedious tests. We thank Michael Mihocic for
   experimental hardware and software support as well as him and Maike
   Ferber for assistance with collecting parts of the data. We thank the
   Institute of Ion Physics and Applied Physics of the
   Leopold-Franzens-University, Innsbruck, Austria, for providing the
   equipment for direct electric stimulation. We further thank the
   associate editor Joshua G. Bernstein and two anonymous reviewers for
   their fruitful comments on earlier versions of the manuscript. This
   study was supported by the National Institutes of Health, grant R01 DC
   005775. Additional support was provided by the OeAD, grant MULT_DR
   11/2017n.
CR [Anonymous], 1983, Phys Sportsmed, V11, P157, DOI 10.1080/00913847.1983.11708490
   [Anonymous], 2015, TELEMAT INFORM, V32, P67
   [Anonymous], 1989, J ACOUST SOC AM, V85, P1699, DOI [10.1121/1.397959, DOI 10.1121/1.397959]
   [Anonymous], 2014, DIABETES CARE, V35, pS14, DOI DOI 10.1097/AUD.0000000000000063
   Arora K, 2009, INT J AUDIOL, V48, P561, DOI 10.1080/14992020902858967
   Baumann U, 2004, EAR HEARING, V25, P275, DOI 10.1097/00003446-200406000-00008
   Buechel BD, 2018, JARO-J ASSOC RES OTO, V19, P681, DOI 10.1007/s10162-018-00693-0
   Carlyon RP, 2010, J ACOUST SOC AM, V127, P2997, DOI 10.1121/1.3372711
   Carlyon RP, 2002, J ACOUST SOC AM, V112, P621, DOI 10.1121/1.1488660
   Chatterjee M, 2011, J ACOUST SOC AM, V130, P1567, DOI 10.1121/1.3621445
   Chen J, 2018, J ACOUST SOC AM, V143, P864, DOI 10.1121/1.5023218
   Churchill TH, 2014, J ACOUST SOC AM, V136, P1246, DOI 10.1121/1.4892764
   Confidence Intervals from Normalized Data, 2008, TUTORIALS QUANTITATI, V4, P61, DOI DOI 10.20982/TQMP.04.2.P061
   Cooper N, 2006, TLS-TIMES LIT SUPPL, P21
   Cousineau D, 2005, TUTOR QUANT METHODS, V1, P42, DOI 10.20982/tqmp.01.1.p042
   Cutler A, 1997, LANG SPEECH, V40, P141, DOI 10.1177/002383099704000203
   Darwin CJ, 2005, SPR HDB AUD, V24, P278
   Dorman ME, 2004, AM SCI, V92, P436, DOI 10.1511/2004.5.436
   Egger K, 2017, J ACOUST SOC AM, V141, P3164, DOI 10.1121/1.4982888
   Francart T, 2015, INT J AUDIOL, V54, P424, DOI 10.3109/14992027.2014.989455
   Garofolo J., 1993, TIMIT ACOUSTIC PHONE
   Geurts L, 2001, J ACOUST SOC AM, V109, P713, DOI 10.1121/1.1340650
   Green T, 2005, J ACOUST SOC AM, V118, P375, DOI 10.1121/1.1925827
   Green T, 2004, J ACOUST SOC AM, V116, P2298, DOI 10.1121/1.1785611
   Green T, 2012, EAR HEARING, V33, P233, DOI 10.1097/AUD.0b013e318230fff8
   Hancock KE, 2017, JARO-J ASSOC RES OTO, V18, P771, DOI 10.1007/s10162-017-0638-4
   Hancock KE, 2012, J NEUROPHYSIOL, V108, P714, DOI 10.1152/jn.00269.2012
   Houtsma Adrianus J. M., 1995, P267, DOI 10.1016/B978-012505626-7/50010-8
   Hu HM, 2017, J ACOUST SOC AM, V141, P1862, DOI 10.1121/1.4977014
   Ihlefeld A, 2015, JARO-J ASSOC RES OTO, V16, P641, DOI 10.1007/s10162-015-0527-7
   International guidelines for groin hernia management, 2018, REV HISPANOAM HERNIA, V22, P1, DOI DOI 10.1177/2331216518781746
   JESTEADT W, 1980, PERCEPT PSYCHOPHYS, V28, P85, DOI 10.3758/BF03204321
   Kalathottukaren RT, 2015, INT J AUDIOL, V54, P444, DOI 10.3109/14992027.2014.997314
   Kirby AE, 2010, J NEUROPHYSIOL, V103, P531, DOI 10.1152/jn.00794.2009
   Klein SA, 2001, PERCEPT PSYCHOPHYS, V63, P1421, DOI 10.3758/BF03194552
   Kohler KJ, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1938, DOI 10.1109/ICSLP.1996.608014
   Kong YY, 2010, J ACOUST SOC AM, V127, P3114, DOI 10.1121/1.3372713
   Kong YY, 2009, J ACOUST SOC AM, V125, P1649, DOI 10.1121/1.3068457
   Kreft HA, 2010, J ACOUST SOC AM, V127, P656, DOI 10.1121/1.3282947
   Laback B, 2004, EAR HEARING, V25, P488, DOI 10.1097/01.aud.0000145124.85517.e8
   Laback B, 2008, P NATL ACAD SCI USA, V105, P814, DOI 10.1073/pnas.0709199105
   Laback B, 2007, J ACOUST SOC AM, V121, P2182, DOI 10.1121/1.2642280
   Laback B, 2011, J ACOUST SOC AM, V130, P1515, DOI 10.1121/1.3613704
   Landsberger DM, 2008, J ACOUST SOC AM, V124, pEL21, DOI 10.1121/1.2947624
   Laneau J, 2006, AUDIOL NEURO-OTOL, V11, P38, DOI 10.1159/000088853
   Loizou PC, 2000, J ACOUST SOC AM, V108, P790, DOI 10.1121/1.429612
   McKay CM, 2001, J ACOUST SOC AM, V110, P1514, DOI 10.1121/1.1394222
   MCKAY CM, 1995, J ACOUST SOC AM, V97, P1777, DOI 10.1121/1.412054
   MCKAY CM, 1994, J ACOUST SOC AM, V96, P2664, DOI 10.1121/1.411377
   McKay CM, 2010, JARO-J ASSOC RES OTO, V11, P101, DOI 10.1007/s10162-009-0188-5
   Mehta AH, 2017, JARO-J ASSOC RES OTO, V18, P789, DOI 10.1007/s10162-017-0632-x
   Milczynski M, 2012, HEARING RES, V285, P1, DOI 10.1016/j.heares.2012.02.006
   Milczynski M, 2009, J ACOUST SOC AM, V125, P2260, DOI 10.1121/1.3085642
   Miller SE, 2010, J ACOUST SOC AM, V128, P435, DOI 10.1121/1.3397384
   Monaghan JJM, 2016, J ACOUST SOC AM, V140, P1116, DOI 10.1121/1.4960572
   Moore BCJ, 2005, SPR HDB AUD, V24, P234
   Oxenham AJ, 2012, J NEUROSCI, V32, P13335, DOI 10.1523/JNEUROSCI.3815-12.2012
   Oxenham AJ, 2011, P NATL ACAD SCI USA, V108, P7629, DOI 10.1073/pnas.1015291108
   Pepiot E., 2014, SPEECH PROSODY, V7, P305, DOI DOI 10.21437/SpeechProsody.2014-48
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Pieper Sabrina H, 2019, Cochlear Implants Int, V20, P312, DOI 10.1080/14670100.2019.1656847
   Sayles M, 2008, NEURON, V58, P789, DOI 10.1016/j.neuron.2008.03.029
   Schouten JF, 1940, P K NED AKAD WETENSC, V43, P356
   SMITH ZM, 2014, J ACOUST SOC AM, V135, P2190, DOI DOI 10.1121/1.4877139
   Srinivasan S., 2017, J ACOUST SOC AM, V141, P3973, DOI [10.1121/1.4989062, DOI 10.1121/1.4989062]
   Srinivasan S, 2020, JARO-J ASSOC RES OTO, V21, P105, DOI 10.1007/s10162-020-00743-6
   Srinivasan S, 2018, JARO-J ASSOC RES OTO, V19, P301, DOI 10.1007/s10162-018-0659-7
   Stahl P, 2016, J ACOUST SOC AM, V139, P1578, DOI 10.1121/1.4944564
   Thakkar T, 2018, J ACOUST SOC AM, V143, P1428, DOI 10.1121/1.5026618
   TOWNSHEND B, 1987, J ACOUST SOC AM, V82, P106, DOI 10.1121/1.395554
   van Hoesel RJM, 2009, JARO-J ASSOC RES OTO, V10, P557, DOI 10.1007/s10162-009-0175-x
   van Hoesel RJM, 2003, J ACOUST SOC AM, V113, P1617, DOI 10.1121/1.1539520
   Vandali AE, 2005, J ACOUST SOC AM, V117, P3126, DOI 10.1121/1.1874632
   Vandali A, 2013, HEARING RES, V302, P32, DOI 10.1016/j.heares.2013.05.004
   Vandali AE, 2012, J ACOUST SOC AM, V132, P392, DOI 10.1121/1.4718452
   Vandali AE, 2011, J ACOUST SOC AM, V129, P4023, DOI 10.1121/1.3573988
   Vongphoe M, 2005, J ACOUST SOC AM, V118, P1055, DOI 10.1121/1.1944507
   Wilson BS, 2008, HEARING RES, V242, P3, DOI 10.1016/j.heares.2008.06.005
   Wilson BS, 1997, AM J OTOL, V18, pS30
   WILSON BS, 1991, NATURE, V352, P236, DOI 10.1038/352236a0
   Xu L, 2003, J ACOUST SOC AM, V114, P3024, DOI 10.1121/1.1623786
   Zierhofer C., 2003, U. S. Patent, Patent No. [6,594,525, 6594525]
   2016, LANCET ONCOL, V17, P1, DOI DOI 10.1007/S10162-015-0545-5
NR 83
TC 1
Z9 1
U1 0
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD FEB
PY 2020
VL 147
IS 2
BP 777
EP 793
DI 10.1121/10.0000610
PG 17
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA KS9IN
UT WOS:000518621800001
PM 32113255
OA Green Published
DA 2021-02-24
ER

PT J
AU Glennon, E
   Svirsky, MA
   Froemke, RC
AF Glennon, Erin
   Svirsky, Mario A.
   Froemke, Robert C.
TI Auditory cortical plasticity in cochlear implant users
SO CURRENT OPINION IN NEUROBIOLOGY
LA English
DT Article
ID CROSS-MODAL PLASTICITY; HEARING-LOSS; ELECTRICAL-STIMULATION;
   SPEECH-PERCEPTION; CORTEX; DEAFNESS; ADULT; PERFORMANCE; ADAPTATION;
   PITCH
AB Cochlear implants are one of the most successful neuroprosthetic devices that have been developed to date. Profoundly deaf patients can achieve speech perception after complete loss of sensory input. Despite the improvements many patients experience, there is still a large degree of outcome variability. It has been proposed that central plasticity may be a major factor in the different levels of benefit that patients experience. However, the neural mechanisms of how plasticity impacts cochlear implant learning and the degree of plasticity's influence remain unknown. Here, we review the human and animal research on three of the main ways that central plasticity affects cochlear implant outcomes.
C1 [Glennon, Erin; Svirsky, Mario A.; Froemke, Robert C.] NYU, Sch Med, Skirball Inst Bimol Med, New York, NY 10016 USA.
   [Glennon, Erin; Svirsky, Mario A.; Froemke, Robert C.] NYU, Sch Med, Inst Neurosci, New York, NY 10003 USA.
   [Glennon, Erin; Svirsky, Mario A.; Froemke, Robert C.] NYU, Sch Med, Dept Otolaryngol, New York, NY 10003 USA.
   [Glennon, Erin; Svirsky, Mario A.; Froemke, Robert C.] NYU, Sch Med, Dept Neurosci & Physiol, New York, NY 10003 USA.
   [Froemke, Robert C.] NYU, Ctr Neural Sci, New York, NY 10003 USA.
RP Svirsky, MA; Froemke, RC (corresponding author), NYU, Sch Med, Skirball Inst Bimol Med, New York, NY 10016 USA.; Svirsky, MA; Froemke, RC (corresponding author), NYU, Sch Med, Inst Neurosci, New York, NY 10003 USA.; Svirsky, MA; Froemke, RC (corresponding author), NYU, Sch Med, Dept Otolaryngol, New York, NY 10003 USA.; Svirsky, MA; Froemke, RC (corresponding author), NYU, Sch Med, Dept Neurosci & Physiol, New York, NY 10003 USA.; Froemke, RC (corresponding author), NYU, Ctr Neural Sci, New York, NY 10003 USA.
EM mario.svirsky@nyulangone.org; robert.froemke@med.nyu.edu
RI Svirsky, Mario/A-4160-2008
OI Svirsky, Mario/0000-0002-9238-0682; Froemke, Robert/0000-0002-1230-6811
FU Hirschl/Weill-Caulier Career Award; Sloan Research FellowshipAlfred P.
   Sloan Foundation; National Institutes of HealthUnited States Department
   of Health & Human ServicesNational Institutes of Health (NIH) - USA
   [T32-GM007308, F30-DC017351, R01-DC003937, R01-DC012557]; Cochlear
   Americas
FX We thank Douglas E. Hartley for supplying Figure 1 and Xiaoqin Wang for
   supplying Figure 2. This work was supported by a Hirschl/Weill-Caulier
   Career Award [to R.C.F.]; a Sloan Research Fellowship [to R.C.F.]; and
   the National Institutes of Health [grant number T32-GM007308 to E.G.,
   F30-DC017351 to E.G., R01-DC003937 to M.A.S., and R01-DC012557 to R.C.
   F.J. Partial support was also received from a research contract from
   Cochlear Americas to J. Thomas Roland, Jr., M.D.
CR Agamaite JA, 2015, J ACOUST SOC AM, V138, P2906, DOI 10.1121/1.4934268
   Allman BL, 2009, P NATL ACAD SCI USA, V106, P5925, DOI 10.1073/pnas.0809483106
   Anderson CA, 2017, P NATL ACAD SCI USA, V114, P10256, DOI 10.1073/pnas.1704785114
   Blamey P, 2013, AUDIOL NEURO-OTOL, V18, P36, DOI 10.1159/000343189
   Buckley KA, 2011, EAR HEARING, V32, P2, DOI [10.1097/AUD.0b013e3181e8534c, 10.1097/AUD.0b013e3181fa41bb]
   Campbell J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147793
   Chang SA, 2010, J AM ACAD AUDIOL, V21, P35, DOI 10.3766/jaaa.21.1.5
   Chen LC, 2017, NEUROIMAGE, V146, P600, DOI 10.1016/j.neuroimage.2016.09.033
   Chen LC, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/4382656
   Claussen AD, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0215407
   Corina DP, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00059
   Dewey RS, 2015, HEARING RES, V325, P55, DOI 10.1016/j.heares.2015.03.007
   Doucet ME, 2006, BRAIN, V129, P3376, DOI 10.1093/brain/awl264
   Fallon JB, 2014, EUR J NEUROSCI, V39, P811, DOI 10.1111/ejn.12445
   Fallon JB, 2009, J NEURAL ENG, V6, DOI 10.1088/1741-2560/6/6/065008
   Fu Qian-Jie, 2007, Trends Amplif, V11, P193, DOI 10.1177/1084713807301379
   Fu Qian-Jie, 2004, Cochlear Implants Int, V5 Suppl 1, P84, DOI 10.1179/cim.2004.5.Supplement-1.84
   Giraud AL, 2007, RESTOR NEUROL NEUROS, V25, P381
   Hamzavi J, 2003, ACTA OTO-LARYNGOL, V123, P493, DOI 10.1080/0036554021000028120
   Hartley DEH, 2010, J NEUROSCI METH, V190, P214, DOI 10.1016/j.jneumeth.2010.05.014
   Huetz C, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00065
   Isaiah A, 2014, J NEUROSCI, V34, P11119, DOI 10.1523/JNEUROSCI.4767-13.2014
   Johnson LA, 2017, J NEUROSCI, V37, P7008, DOI 10.1523/JNEUROSCI.0093-17.2017
   Johnson LA, 2016, J NEUROSCI, V36, P12468, DOI 10.1523/JNEUROSCI.1699-16.2016
   Johnson LA, 2012, HEARING RES, V290, P37, DOI 10.1016/j.heares.2012.05.002
   Keating P, 2016, ELIFE, V5, DOI 10.7554/eLife.12264
   Kim MB, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148466
   King J, 2016, J NEUROPHYSIOL, V116, P844, DOI 10.1152/jn.00048.2016
   KNUDSEN EI, 1989, J NEUROSCI, V9, P3297
   Krueger B, 2008, OTOL NEUROTOL, V29, P509, DOI 10.1097/MAO.0b013e318171972f
   Land R, 2018, NEUROSCIENCE, V375, P149, DOI 10.1016/j.neuroscience.2018.01.065
   Land R, 2016, J NEUROSCI, V36, P6175, DOI 10.1523/JNEUROSCI.0046-16.2016
   Lawler Carly A, 2015, Cochlear Implants Int, V16 Suppl 1, pS30, DOI 10.1179/1467010014Z.000000000230
   Lazard DS, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms14872
   LEAKE PA, 1991, HEARING RES, V54, P251, DOI 10.1016/0378-5955(91)90120-X
   Lee DS, 2001, NATURE, V409, P149, DOI 10.1038/35051653
   Lee HJ, 2007, CEREB CORTEX, V17, P909, DOI 10.1093/cercor/bhl001
   Liang MJ, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00510
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Linkenhoker BA, 2002, NATURE, V419, P293, DOI 10.1038/nature01002
   Lomber SG, 2010, NAT NEUROSCI, V13, P1421, DOI 10.1038/nn.2653
   McDermott H, 2009, AUDIOL NEURO-OTOL, V14, P2, DOI 10.1159/000206489
   McKay CM, 2016, ADV EXP MED BIOL, V894, P327, DOI 10.1007/978-3-319-25474-6_34
   MERZENICH MM, 1973, ANN OTO RHINOL LARYN, V82, P486, DOI 10.1177/000348947308200407
   Moore DR, 2009, NAT NEUROSCI, V12, P686, DOI 10.1038/nn.2326
   Mudry A, 2013, JAMA OTOLARYNGOL, V139, P446, DOI 10.1001/jamaoto.2013.293
   Norena AJ, 2003, J NEUROPHYSIOL, V90, P2387, DOI 10.1152/jn.00139.2003
   Nourski KV, 2013, JARO-J ASSOC RES OTO, V14, P435, DOI 10.1007/s10162-013-0382-3
   Petersen B, 2013, NEURAL PLAST, V2013, DOI 10.1155/2013/318521
   Pienkowski M, 2001, J ACOUST SOC AM, V109, P1496, DOI 10.1121/1.1354202
   Pinilla M, 2001, OTOLARYNG HEAD NECK, V124, P515, DOI 10.1067/mhn.2001.115370
   RAJAN R, 1993, J COMP NEUROL, V338, P17, DOI 10.1002/cne.903380104
   Reiss LAJ, 2014, NEUROSCIENCE, V256, P43, DOI 10.1016/j.neuroscience.2013.10.024
   Reiss LAJ, 2007, JARO-J ASSOC RES OTO, V8, P241, DOI 10.1007/s10162-007-0077-8
   Resnik J, 2017, ELIFE, V6, DOI 10.7554/eLife.21452
   Rouger J, 2012, HUM BRAIN MAPP, V33, P1929, DOI 10.1002/hbm.21331
   Ruffin CV, 2007, LARYNGOSCOPE, V117, P1183, DOI 10.1097/MLG.0b013e318058191a
   Ryugo DK, 2005, SCIENCE, V310, P1490, DOI 10.1126/science.1119419
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   Sasaki E, 2009, NATURE, V459, P523, DOI 10.1038/nature08090
   Scholl B, 2008, J NEUROPHYSIOL, V100, P646, DOI 10.1152/jn.90406.2008
   Strelnikov K, 2013, BRAIN, V136, P3682, DOI 10.1093/brain/awt274
   Svirsky MA, 2004, ACTA OTO-LARYNGOL, V124, P381, DOI 10.1080/00016480310000593
   Svirsky MA, 2001, ACTA OTO-LARYNGOL, V121, P262
   Svirsky MA, 2015, HEARING RES, V322, P163, DOI 10.1016/j.heares.2014.10.008
   Takesian AE, 2012, J NEUROPHYSIOL, V107, P937, DOI 10.1152/jn.00515.2011
   Tang LY, 2017, EAR HEARING, V38, P663, DOI 10.1097/AUD.0000000000000445
   Thomson RS, 2017, LARYNGOSCOPE INVEST, V2, P69, DOI 10.1002/lio2.65
   Vollmer M, 2017, J NEUROPHYSIOL, V117, P47, DOI 10.1152/jn.00392.2016
   von Trapp G, 2017, HEARING RES, V347, P3, DOI 10.1016/j.heares.2016.07.020
NR 70
TC 5
Z9 5
U1 1
U2 3
PU CURRENT BIOLOGY LTD
PI LONDON
PA 84 THEOBALDS RD, LONDON WC1X 8RR, ENGLAND
SN 0959-4388
EI 1873-6882
J9 CURR OPIN NEUROBIOL
JI Curr. Opin. Neurobiol.
PD FEB
PY 2020
VL 60
BP 108
EP 114
DI 10.1016/j.conb.2019.11.003
PG 7
WC Neurosciences
SC Neurosciences & Neurology
GA KM3KJ
UT WOS:000514019600014
PM 31864104
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Silva, DMR
   Rothe-Neves, R
   Melges, DB
AF Silva, Daniel M. R.
   Rothe-Neves, Rui
   Melges, Danilo B.
TI Long-latency event-related responses to vowels: N1-P2 decomposition by
   two-step principal component analysis
SO INTERNATIONAL JOURNAL OF PSYCHOPHYSIOLOGY
LA English
DT Article
DE Principal component analysis; Event-related potential; N1; P2; Speech
   perception; Categorization
ID AUDITORY-EVOKED POTENTIALS; CORTICAL REPRESENTATION; MISMATCH
   NEGATIVITY; GENERATOR PATTERNS; SPEECH-PERCEPTION; WAVE-FORMS;
   T-COMPLEX; N1; BRAIN; PCA
AB The N1-P2 complex of the auditory event-related potential (ERP) has been used to examine neural activity associated with speech sound perception. Since it is thought to reflect multiple generator processes, its functional significance is difficult to infer. In the present study, a temporospatial principal component analysis (PCA) was used to decompose the N1-P2 response into latent factors underlying covariance patterns in ERP data recorded during passive listening to pairs of successive vowels. In each trial, one of six sounds drawn from an /i/ - /e/ vowel continuum was followed either by an identical sound, a different token of the same vowel category, or a token from the other category. Responses were examined as to how they were modulated by within- and across-category vowel differences and by adaptation (repetition suppression) effects. Five PCA factors were identified as corresponding to three well-known N1 subcomponents and two P2 subcomponents. Results added evidence that the Ni peak reflects both generators that are sensitive to spectral information and generators that are not. For later latency ranges, different patterns of sensitivity to vowel quality were found, including category-related effects. Particularly, a subcomponent identified as the Tb wave showed release from adaptation in response to an /i/ followed by an /e/ sound. A P2 subcomponent varied linearly with spectral shape along the vowel continuum, while the other was stronger the closer the vowel was to the category boundary, suggesting separate processing of continuous and category-related information. Thus, the PCA-based decomposition of the N1-P2 complex was functionally meaningful, revealing distinct underlying processes at work during speech sound perception.
C1 [Silva, Daniel M. R.; Rothe-Neves, Rui] Univ Fed Minas Gerais, Fac Letters, Phonet Lab, Belo Horizonte, MG, Brazil.
   [Melges, Danilo B.] Univ Fed Minas Gerais, Dept Elect Engn, Grad Program Elect Engn, Belo Horizonte, MG, Brazil.
RP Rothe-Neves, R (corresponding author), Univ Fed Minas Gerais, Fac Letras, Av Presidente Antonio Carlos 6627,Campus Pampulha, BR-31270901 Belo Horizonte, MG, Brazil.
EM rothe-neves@ufmg.br
RI ROTHE-NEVES, RUI/V-6051-2018; Melges, Danilo Barbosa/C-8007-2013
OI ROTHE-NEVES, RUI/0000-0002-8896-8862; Rodrigues Silva, Daniel
   Marcio/0000-0001-7884-9205
FU National Council for Scientific and Technological Development (CNPq -
   Brazil)National Council for Scientific and Technological Development
   (CNPq) [312277/2015-6]; CNPq postdoctoral fellowship
FX This work was supported by the National Council for Scientific and
   Technological Development (CNPq - Brazil) under grant 312277/2015-6
   awarded to the second author. The first author was supported by a CNPq
   postdoctoral fellowship.
CR Agung K, 2006, J AM ACAD AUDIOL, V17, P559, DOI 10.3766/jaaa.17.8.3
   Ahveninen J, 2006, P NATL ACAD SCI USA, V103, P14608, DOI 10.1073/pnas.0510480103
   Altmann CF, 2008, CEREB CORTEX, V18, P1350, DOI 10.1093/cercor/bhm166
   Anderson John M., 1987, PRINCIPLES DEPENDENC
   Archangeli D., 1988, PHONOLOGY, V5, DOI [DOI 10.1017/S0952675700002268, 10.1017/S0952675700002268]
   Atcherson SR, 2006, BRAIN TOPOGR, V19, P11, DOI 10.1007/s10548-006-0008-8
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Barry RJ, 2013, INT J PSYCHOPHYSIOL, V89, P123, DOI 10.1016/j.ijpsycho.2013.06.012
   Barry RJ, 2011, INT J PSYCHOPHYSIOL, V79, P127, DOI 10.1016/j.ijpsycho.2010.09.010
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Boersma Paul, 2012, PRAAT DOING PHONETIC
   Budd TW, 1998, INT J PSYCHOPHYSIOL, V31, P51, DOI 10.1016/S0167-8760(98)00040-3
   CALABRESE A, 1995, LINGUIST INQ, V26, P373
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Crowley KE, 2004, CLIN NEUROPHYSIOL, V115, P732, DOI 10.1016/j.clinph.2003.11.021
   Dehaene-Lambertz G, 2005, NEUROIMAGE, V24, P21, DOI 10.1016/j.neuroimage.2004.09.039
   Diehl RL, 2008, PHILOS T R SOC B, V363, P965, DOI 10.1098/rstb.2007.2153
   Dien J, 2005, CLIN NEUROPHYSIOL, V116, P1808, DOI 10.1016/j.clinph.2004.11.025
   Dien J, 2004, PSYCHOPHYSIOLOGY, V41, P665, DOI 10.1111/j.1469-8986.2004.00193.x
   Dien J, 1997, J COGNITIVE NEUROSCI, V9, P799, DOI 10.1162/jocn.1997.9.6.799
   Dien J., 2005, EVENT RELATED POTENT, P189, DOI DOI 10.1212/01.WNL.0000217365.45426.9A
   Dien J, 2007, HUM BRAIN MAPP, V28, P742, DOI 10.1002/hbm.20304
   Dien J, 2012, DEV NEUROPSYCHOL, V37, P497, DOI 10.1080/87565641.2012.697503
   Dien J, 2010, J NEUROSCI METH, V187, P138, DOI 10.1016/j.jneumeth.2009.12.009
   Dien J, 2010, PSYCHOPHYSIOLOGY, V47, P170, DOI 10.1111/j.1469-8986.2009.00885.x
   Diesch E, 1996, BRAIN LANG, V53, P143, DOI 10.1006/brln.1996.0042
   Eggermont JJ, 2002, AUDIOL NEURO-OTOL, V7, P71, DOI 10.1159/000057656
   Escudero P, 2009, J ACOUST SOC AM, V126, P1379, DOI 10.1121/1.3180321
   Eulitz C, 2004, COGNITIVE BRAIN RES, V19, P82, DOI 10.1016/j.cogbrainres.2003.11.004
   Godey B, 2001, CLIN NEUROPHYSIOL, V112, P1850, DOI 10.1016/S1388-2457(01)00636-8
   GRATTON G, 1983, ELECTROEN CLIN NEURO, V55, P468, DOI 10.1016/0013-4694(83)90135-9
   Grau C, 2007, NEUROIMAGE, V36, P522, DOI 10.1016/j.neuroimage.2007.03.027
   Grill-Spector K, 2006, TRENDS COGN SCI, V10, P14, DOI 10.1016/j.tics.2005.11.006
   HARI R, 1982, ELECTROEN CLIN NEURO, V54, P561, DOI 10.1016/0013-4694(82)90041-4
   Harris J, 2000, NY TIMES BK REV, P18
   Harris John, 1994, ENGLISH SOUND STRUCT
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   Kayser J, 2006, CLIN NEUROPHYSIOL, V117, P348, DOI 10.1016/j.clinph.2005.08.034
   KEWLEYPORT D, 1989, J ACOUST SOC AM, V85, P1726, DOI 10.1121/1.397962
   Lahiri A, 2010, J PHONETICS, V38, P44, DOI 10.1016/j.wocn.2010.01.002
   Lange K, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00263
   Lange K, 2012, PSYCHOPHYSIOLOGY, V49, P1636, DOI 10.1111/j.1469-8986.2012.01460.x
   Lutkenhoner B, 1998, AUDIOL NEURO-OTOL, V3, P191, DOI 10.1159/000013790
   Maddieson I., 1984, PATTERNS SOUNDS
   Makeig S, 1997, P NATL ACAD SCI USA, V94, P10979, DOI 10.1073/pnas.94.20.10979
   Makela AM, 2003, NEUROSCI LETT, V353, P111, DOI 10.1016/j.neulet.2003.09.021
   Martin BA, 2008, EAR HEARING, V29, P285, DOI 10.1097/AUD.0b013e3181662c0e
   Massini-Cagliari G., 2016, HDB PORTUGUESE LINGU, P56, DOI [10. 1002/9781118791844.ch4., DOI 10.1002/9781118791844.CH4]
   Mateus Maria H., 2000, PHONOLOGY PORTUGUESE
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   MILLER GA, 1988, PSYCHOPHYSIOLOGY, V25, P241, DOI 10.1111/j.1469-8986.1988.tb00999.x
   Miller JL, 1997, LANG COGNITIVE PROC, V12, P865, DOI 10.1080/016909697386754
   MOLFESE DL, 1981, BRAIN LANG, V13, P333, DOI 10.1016/0093-934X(81)90099-7
   Monahan PJ, 2018, ANNU REV LINGUIST, V4, P21, DOI 10.1146/annurev-linguistics-011817-045537
   Naatanen R, 1999, PSYCHOL BULL, V125, P826, DOI 10.1037/0033-2909.125.6.826
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Naatanen R, 2011, PSYCHOPHYSIOLOGY, V48, P4, DOI 10.1111/j.1469-8986.2010.01114.x
   Nevins A, 2012, LET HOJE, V47, P228
   Obleser J, 2004, J COGNITIVE NEUROSCI, V16, P31, DOI 10.1162/089892904322755539
   Obleser J, 2003, COGNITIVE BRAIN RES, V15, P207, DOI 10.1016/S0926-6410(02)00193-3
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Picton TW, 1999, AUDIOL NEURO-OTOL, V4, P64, DOI 10.1159/000013823
   Picton TW, 2000, PSYCHOPHYSIOLOGY, V37, P127, DOI 10.1111/1469-8986.3720127
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   Polka L, 2003, SPEECH COMMUN, V41, P221, DOI 10.1016/S0167-6393(02)00105-X
   Polka L, 2011, J PHONETICS, V39, P467, DOI 10.1016/j.wocn.2010.08.007
   Ponton C, 2002, CLIN NEUROPHYSIOL, V113, P407, DOI 10.1016/S1388-2457(01)00733-7
   Rauber A. S., 2008, DIACRITICA CIENCIAS, V22, P229
   Roberts TPL, 2004, NEUROREPORT, V15, P1679, DOI 10.1097/01.wnr.0000134928.96937.10
   Silva DMR, 2020, LANG COGN NEUROSCI, V35, P163, DOI 10.1080/23273798.2019.1638948
   Ross B, 2013, BMC NEUROSCI, V14, DOI 10.1186/1471-2202-14-151
   Sanmiguel I, 2013, PSYCHOPHYSIOLOGY, V50, P334, DOI 10.1111/psyp.12024
   Scharinger M, 2016, NEUROIMAGE, V128, P293, DOI 10.1016/j.neuroimage.2016.01.003
   Scharinger M, 2011, J COGNITIVE NEUROSCI, V23, P3972, DOI 10.1162/jocn_a_00056
   Schwartz JL, 1997, J PHONETICS, V25, P255, DOI 10.1006/jpho.1997.0043
   Schwartz JL, 1997, J PHONETICS, V25, P233, DOI 10.1006/jpho.1997.0044
   Sharma A, 2000, J ACOUST SOC AM, V107, P2697, DOI 10.1121/1.428655
   Shestakova A, 2004, COGNITIVE BRAIN RES, V21, P342, DOI 10.1016/j.cogbrainres.2004.06.011
   Silva DMR, 2017, PSYCHOPHYSIOLOGY, V54, P591, DOI 10.1111/psyp.12824
   SILVA Daniel Márcio Rodrigues, 2016, DELTA, V32, P355, DOI 10.1590/0102-4450984064164376868
   Silva S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00681
   Tenke CE, 2008, INT J PSYCHOPHYSIOL, V67, P1, DOI 10.1016/j.ijpsycho.2007.09.001
   Tian X, 2018, NAT HUM BEHAV, V2, P225, DOI 10.1038/s41562-018-0305-8
   Tian X, 2013, J COGNITIVE NEUROSCI, V25, P1020, DOI 10.1162/jocn_a_00381
   TRAUNMULLER H, 1990, J ACOUST SOC AM, V88, P97, DOI 10.1121/1.399849
   Tremblay KL, 2003, EAR HEARING, V24, P225, DOI 10.1097/01.AUD.0000069229.84883.03
   van der Hulst H, 2016, LANG LINGUIST COMPAS, V10, P83, DOI 10.1111/lnc3.12158
   VERKINDT C, 1994, NEUROREPORT, V5, P1189, DOI 10.1097/00001756-199406020-00007
   Wagner M, 2017, J SPEECH LANG HEAR R, V60, P2105, DOI 10.1044/2017_JSLHR-H-16-0056
   Wagner M, 2016, NEUROSCI LETT, V614, P119, DOI 10.1016/j.neulet.2015.12.020
   Wagner M, 2013, BRAIN RES, V1522, P31, DOI 10.1016/j.brainres.2013.04.045
   Weenink D., 2009, INTERSPEECH, V10, P2059
   Winkler I, 1999, COGNITIVE BRAIN RES, V7, P357, DOI 10.1016/S0926-6410(98)00039-1
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   WOLPAW JR, 1977, ELECTROEN CLIN NEURO, V43, P99, DOI 10.1016/0013-4694(77)90200-0
   WOLPAW JR, 1975, ELECTROEN CLIN NEURO, V39, P609, DOI 10.1016/0013-4694(75)90073-5
   Woods DL, 1995, EEG CL N SU, P102
   Zhang FW, 2011, BRAIN RES, V1400, P42, DOI 10.1016/j.brainres.2011.05.036
NR 98
TC 0
Z9 0
U1 1
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8760
EI 1872-7697
J9 INT J PSYCHOPHYSIOL
JI Int. J. Psychophysiol.
PD FEB
PY 2020
VL 148
BP 93
EP 102
DI 10.1016/j.ijpsycho.2019.11.010
PG 10
WC Psychology, Biological; Neurosciences; Physiology; Psychology;
   Psychology, Experimental
SC Psychology; Neurosciences & Neurology; Physiology
GA KM3KO
UT WOS:000514020100010
PM 31863852
DA 2021-02-24
ER

PT J
AU Arnon, I
AF Arnon, Inbal
TI Do current statistical learning tasks capture stable individual
   differences in children? An investigation of task reliability across
   modality
SO BEHAVIOR RESEARCH METHODS
LA English
DT Article
DE Statistical learning; Individual differences; Reliability; Domain
   generality; Children
ID SPEECH-PERCEPTION; IMAGE AGREEMENT; NAME AGREEMENT; LANGUAGE; INFANCY;
   SEGMENTATION; ASSOCIATIONS; ACQUISITION; FAMILIARITY; PREDICTION
AB Do commonly used statistical-learning tasks capture stable individual differences in children? Infants, children, and adults are capable of using statistical learning (SL) to extract information about their environment. Although most studies have looked at group-level performance, a growing literature examines individual differences in SL and their relation to language-learning outcomes: Individuals who are better at SL are expected to show better linguistic abilities. Accordingly, studies have shown positive correlations between SL performance and language outcomes in both children and adults. However, these studies have often used tasks designed to explore group-level performance without modifying them, resulting in psychometric shortcomings that impact reliability in adults (Siegelman, Bogaerts, Christiansen, & Frost in Transactions of the Royal Society B, 372, 20160059, 2017a; Siegelman, Bogaerts, & Frost in Behavior Research Methods, 49, 418-432, 2017b). Even though similar measures are used to assess individual differences in children, no study to date has examined the reliability of these measures in development. This study examined the reliability of common SL measures in both children and adults. It assessed the reliability of three SL tasks (two auditory and one visual) twice (two months apart) in adults and children (mean age 8 years). Although the tasks showed moderate reliability in adults, they did not capture stable individual variation in children. None of the tasks were reliable across sessions, and all showed internal consistency measures well below psychometric standards. These findings raise significant concerns about the use of current SL measures to predict and explain individual differences in development. The article ends with a discussion of possible explanations for the difference in reliability between children and adults.
C1 [Arnon, Inbal] Hebrew Univ Jerusalem, Dept Psychol, Jerusalem, Israel.
RP Arnon, I (corresponding author), Hebrew Univ Jerusalem, Dept Psychol, Jerusalem, Israel.
EM Inbal.arnon@mail.huji.ac.il
OI Arnon, Inbal/0000-0001-8934-718X
CR Alario FX, 1999, BEHAV RES METH INS C, V31, P531, DOI 10.3758/BF03200732
   Arciuli J, 2012, COGNITIVE SCI, V36, P286, DOI 10.1111/j.1551-6709.2011.01200.x
   Arciuli J, 2011, DEVELOPMENTAL SCI, V14, P464, DOI 10.1111/j.1467-7687.2009.00937.x
   Batterink LJ, 2017, PSYCHOL SCI, V28, P921, DOI 10.1177/0956797617698226
   Batterink LJ, 2017, CORTEX, V90, P31, DOI 10.1016/j.cortex.2017.02.004
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bogaerts L, 2018, Q J EXP PSYCHOL, V71, P892, DOI 10.1080/17470218.2017.1307432
   Bulf H, 2011, COGNITION, V121, P127, DOI 10.1016/j.cognition.2011.06.010
   Conway CM, 2010, COGNITION, V114, P356, DOI 10.1016/j.cognition.2009.10.009
   Conway CM, 2005, J EXP PSYCHOL LEARN, V31, P24, DOI 10.1037/0278-7393.31.1.24
   Cristia A, 2014, CHILD DEV, V85, P1330, DOI 10.1111/cdev.12193
   Ellis EM, 2014, LANG LEARN DEV, V10, P36, DOI 10.1080/15475441.2013.799988
   Emberson LL, 2011, Q J EXP PSYCHOL, V64, P1021, DOI 10.1080/17470218.2010.538972
   Erickson L. C., 2016, COLLABRA, V2, P14, DOI DOI 10.1525/COLLABRA.41
   Erickson LC, 2015, DEV REV, V37, P66, DOI 10.1016/j.dr.2015.05.002
   Franco A, 2015, EXP PSYCHOL, V62, P346, DOI 10.1027/1618-3169/a000295
   Frost R, 2015, TRENDS COGN SCI, V19, P117, DOI 10.1016/j.tics.2014.12.010
   Frost R, 2013, PSYCHOL SCI, V24, P1243, DOI 10.1177/0956797612472207
   Gathercole S E, 1994, Memory, V2, P103, DOI 10.1080/09658219408258940
   Glicksohn A, 2013, PSYCHON B REV, V20, P1161, DOI 10.3758/s13423-013-0458-4
   Havron N, 2017, J CHILD LANG, V44, P1516, DOI 10.1017/S0305000916000623
   Isbilen E. S., 2017, P 39 ANN C COGN SCI, P564
   Karuza E. A., 2014, P COGN SCI SOC, V36, P725
   Kaufman A.S., 1994, INTELLIGENT TESTING
   Kidd E, 2016, CHILD DEV, V87, P184, DOI 10.1111/cdev.12461
   Kidd E, 2012, DEV PSYCHOL, V48, P171, DOI 10.1037/a0025405
   Kirkham NZ, 2002, COGNITION, V83, pB35, DOI 10.1016/S0010-0277(02)00004-5
   Lany J, 2018, J CHILD LANG, V45, P368, DOI 10.1017/S0305000917000253
   Mainela-Arnold E, 2014, J CHILD LANG, V41, P327, DOI 10.1017/S0305000912000736
   Maital SL, 2000, J CHILD LANG, V27, P43, DOI 10.1017/S0305000999004006
   Misyak JB, 2012, LANG LEARN, V62, P302, DOI 10.1111/j.1467-9922.2010.00626.x
   Misyak JB, 2010, TOP COGN SCI, V2, P138, DOI 10.1111/j.1756-8765.2009.01072.x
   Nemeth D, 2011, J GERONTOL B-PSYCHOL, V66, P15, DOI 10.1093/geronb/gby063
   Nunnally J.C., 1994, PSYCHOMETRIC THEORY, V3rd
   Potter CE, 2017, COGNITIVE SCI, V41, P913, DOI 10.1111/cogs.12473
   Raviv L, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12593
   Romberg AR, 2010, WIRES COGN SCI, V1, P906, DOI 10.1002/wcs.78
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Saffran JR, 1997, PSYCHOL SCI, V8, P101, DOI 10.1111/j.1467-9280.1997.tb00690.x
   Shafto CL, 2012, INFANCY, V17, P247, DOI 10.1111/j.1532-7078.2011.00085.x
   Shufaniya A, 2018, COGNITIVE SCI, V42, P3100, DOI 10.1111/cogs.12692
   Siegelman N, 2018, COGNITION, V177, P198, DOI 10.1016/j.cognition.2018.04.011
   Siegelman N, 2018, COGNITIVE SCI, V42, P692, DOI 10.1111/cogs.12556
   Siegelman N, 2017, BEHAV RES METHODS, V49, P418, DOI 10.3758/s13428-016-0719-z
   Siegelman N, 2017, PHILOS T R SOC B, V372, DOI 10.1098/rstb.2016.0059
   Siegelman N, 2015, J MEM LANG, V81, P105, DOI 10.1016/j.jml.2015.02.001
   SNODGRASS JG, 1980, J EXP PSYCHOL-HUM L, V6, P174, DOI 10.1037/0278-7393.6.2.174
   Southgate V, 2007, PSYCHOL SCI, V18, P587, DOI 10.1111/j.1467-9280.2007.01944.x
   Spencer M, 2015, READ WRIT, V28, P467, DOI 10.1007/s11145-014-9533-0
   Streiner DL, 2003, J PERS ASSESS, V80, P217, DOI 10.1207/S15327752JPA8003_01
   Torok B, 2017, J EXP PSYCHOL GEN, V146, P529, DOI 10.1037/xge0000288
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Turk-Browne NB, 2005, J EXP PSYCHOL GEN, V134, P552, DOI 10.1037/0096-3445.134.4.552
   West G, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12552
NR 54
TC 12
Z9 12
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1554-351X
EI 1554-3528
J9 BEHAV RES METHODS
JI Behav. Res. Methods
PD FEB
PY 2020
VL 52
IS 1
BP 68
EP 81
DI 10.3758/s13428-019-01205-5
PG 14
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA KK5JJ
UT WOS:000512777700001
PM 30756262
OA Bronze
DA 2021-02-24
ER

PT J
AU Rennig, J
   Wegner-Clemens, K
   Beauchamp, MS
AF Rennig, Johannes
   Wegner-Clemens, Kira
   Beauchamp, Michael S.
TI Face viewing behavior predicts multisensory gain during speech
   perception
SO PSYCHONOMIC BULLETIN & REVIEW
LA English
DT Article
DE Audiovisual; Face; Multisensory; Speech perception; Eye tracking
ID INDIVIDUAL-DIFFERENCES; SENTENCE RECOGNITION; EYE; MOUTH
AB Visual information from the face of an interlocutor complements auditory information from their voice, enhancing intelligibility. However, there are large individual differences in the ability to comprehend noisy audiovisual speech. Another axis of individual variability is the extent to which humans fixate the mouth or the eyes of a viewed face. We speculated that across a lifetime of face viewing, individuals who prefer to fixate the mouth of a viewed face might accumulate stronger associations between visual and auditory speech, resulting in improved comprehension of noisy audiovisual speech. To test this idea, we assessed interindividual variability in two tasks. Participants (n = 102) varied greatly in their ability to understand noisy audiovisual sentences (accuracy from 2-58%) and in the time they spent fixating the mouth of a talker enunciating clear audiovisual syllables (3-98% of total time). These two variables were positively correlated: a 10% increase in time spent fixating the mouth equated to a 5.6% increase in multisensory gain. This finding demonstrates an unexpected link, mediated by histories of visual exposure, between two fundamental human abilities: processing faces and understanding speech.
C1 [Rennig, Johannes; Wegner-Clemens, Kira; Beauchamp, Michael S.] Baylor Coll Med, Dept Neurosurg, 1 Baylor Plaza Suite S104, Houston, TX 77030 USA.
   [Rennig, Johannes; Wegner-Clemens, Kira; Beauchamp, Michael S.] Baylor Coll Med, Core Adv MRI, 1 Baylor Plaza Suite S104, Houston, TX 77030 USA.
RP Beauchamp, MS (corresponding author), Baylor Coll Med, Dept Neurosurg, 1 Baylor Plaza Suite S104, Houston, TX 77030 USA.; Beauchamp, MS (corresponding author), Baylor Coll Med, Core Adv MRI, 1 Baylor Plaza Suite S104, Houston, TX 77030 USA.
EM Michael.Beauchamp@bcm.edu
RI Beauchamp, Michael/AAK-9813-2020
OI Beauchamp, Michael/0000-0002-7599-9934; Wegner-Clemens,
   Kira/0000-0001-9521-755X
FU Deutsche ForschungsgemeinschaftGerman Research Foundation (DFG) [RE
   3693/1-1] Funding Source: Medline; NIH HHSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USA
   [R01NS065395] Funding Source: Medline; NINDS NIH HHSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute of Neurological Disorders & Stroke (NINDS)
   [R01 NS065395, U01 NS113339] Funding Source: Medline
CR Ahissar M, 2004, TRENDS COGN SCI, V8, P457, DOI 10.1016/j.tics.2004.08.011
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Bernstein LE, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00386
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Buchan JN, 2008, BRAIN RES, V1242, P162, DOI 10.1016/j.brainres.2008.06.083
   Grant KW, 1998, J ACOUST SOC AM, V103, P2677, DOI 10.1121/1.422788
   Gurler D, 2015, ATTEN PERCEPT PSYCHO, V77, P1333, DOI 10.3758/s13414-014-0821-1
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2018, CORTEX, V103, P360, DOI 10.1016/j.cortex.2018.03.030
   Kanan C, 2015, VISION RES, V108, P67, DOI 10.1016/j.visres.2015.01.013
   Mehoudar E, 2014, J VISION, V14, DOI 10.1167/14.7.6
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Peelle JE, 2015, CORTEX, V68, P169, DOI 10.1016/j.cortex.2015.03.006
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Pelphrey KA, 2005, CEREB CORTEX, V15, P1866, DOI 10.1093/cercor/bhi064
   Peterson MF, 2013, PSYCHOL SCI, V24, P1216, DOI 10.1177/0956797612471684
   Peterson MF, 2012, P NATL ACAD SCI USA, V109, pE3314, DOI 10.1073/pnas.1214269109
   Rennig J, 2018, NEUROIMAGE, V183, P25, DOI 10.1016/j.neuroimage.2018.08.008
   Roelfsema PR, 2010, TRENDS COGN SCI, V14, P64, DOI 10.1016/j.tics.2009.11.005
   Schurgin MW, 2014, J VISION, V14, DOI 10.1167/14.13.14
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Tye-Murray N, 2016, PSYCHOL AGING, V31, P380, DOI 10.1037/pag0000094
   Van Engen KJ, 2017, ATTEN PERCEPT PSYCHO, V79, P396, DOI 10.3758/s13414-016-1238-9
   Van Engen KJ, 2014, J SPEECH LANG HEAR R, V57, P1908, DOI 10.1044/JSLHR-H-13-0076
   Vatikiotis-Bateson E, 1998, PERCEPT PSYCHOPHYS, V60, P926, DOI 10.3758/BF03211929
   Yarbus A. L., 1967, EYE MOVEMENTS VISION
   Zhu LL, 2017, J NEUROSCI, V37, P2697, DOI 10.1523/JNEUROSCI.2914-16.2017
NR 28
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1069-9384
EI 1531-5320
J9 PSYCHON B REV
JI Psychon. Bull. Rev.
PD FEB
PY 2020
VL 27
IS 1
BP 70
EP 77
DI 10.3758/s13423-019-01665-y
PG 8
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA KJ2ZC
UT WOS:000511925500008
PM 31845209
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Loughrey, DG
   Pakhomov, SVS
   Lawlor, BA
AF Loughrey, David G.
   Pakhomov, Serguei V. S.
   Lawlor, Brian A.
TI Altered verbal fluency processes in older adults with age-related
   hearing loss
SO EXPERIMENTAL GERONTOLOGY
LA English
DT Article
DE Age-related hearing loss; Cognitive decline; Fluency; Executive
   function; Memory
ID COGNITIVE FUNCTION; DOPAMINERGIC MODULATION; DIAGNOSTIC UTILITY;
   TEMPORAL CORTEX; BRAIN VOLUME; MEMORY; PERFORMANCE; ALZHEIMERS; DECLINE;
   DISEASE
AB Epidemiological studies have linked age-related hearing loss (ARHL) with an increased risk of neurocognitive decline. Difficulties in speech perception with subsequent changes in brain morphometry, including regions important for lexical-semantic memory, are thought to be a possible mechanism for this relationship. This study investigated differences in automatic and executive lexical-semantic processes on verbal fluency tasks in individuals with acquired hearing loss. The primary outcomes were indices of automatic (clustering/word retrieval at start of task) and executive (switching/word retrieval after start of the task) processes from semantic and phonemic fluency tasks. To extract indices of clustering and switching, we used both manual and computerised methods. There were no differences between groups on indices of executive fluency processes or on any indices from the semantic fluency task. The hearing loss group demonstrated weaker automatic processes on the phonemic fluency task. Further research into differences in lexical-semantic processes with ARHL is warranted.
C1 [Loughrey, David G.; Lawlor, Brian A.] Trinity Coll Dublin, Global Brain Hlth Inst, Dublin, Ireland.
   [Loughrey, David G.; Lawlor, Brian A.] Univ Calif San Francisco, Global Brain Hlth Inst, San Francisco, CA 94143 USA.
   [Pakhomov, Serguei V. S.] Univ Minnesota, Inst Hlth Informat, Minneapolis, MN USA.
   [Lawlor, Brian A.] St James Hosp, Mercers Inst Successful Ageing, Dublin, Ireland.
   [Loughrey, David G.] Trinity Coll Dublin, Trinity Coll Inst Neurosci, Dublin, Ireland.
RP Loughrey, DG (corresponding author), Trinity Coll Dublin, Trinity Coll Inst Neurosci, Global Brain Hlth Inst, Room 0-60,Lloyd Bldg, Dublin 2, Ireland.
EM loughred@tcd.ie
FU Global Brain Health Institute; Chime; Irish Research CouncilIrish
   Research Council for Science, Engineering and Technology; Central
   Remedial Clinic; Atlantic Philanthropies; United States Alzheimer's
   Association [DNCFI-12-242985]
FX We thank the participants for their generous support of this study. DGL
   was supported by the Global Brain Health Institute, Chime, the Irish
   Research Council and the Central Remedial Clinic. Initial funding to
   establish the Global Brain Health Institute was provided by the Atlantic
   Philanthropies. SVSP's work on automated verbal fluency assessment was
   supported in part by a grant from the United States Alzheimer's
   Association (DNCFI-12-242985).
CR Andersson U, 2002, EUR J COGN PSYCHOL, V14, P335, DOI 10.1080/09541440143000096
   Andersson U, 1998, SCAND AUDIOL, V27, P93, DOI 10.1080/010503998420711
   Armstrong N.M., 2019, JAMA OTOLARYNGOL, DOI [10.1001/jamaoto.2019, DOI 10.1001/JAMAOTO.2019]
   Arnott WL, 2011, PARKINSONS DIS-US, V2011, DOI 10.4061/2011/157072
   Baldo JV, 2006, J INT NEUROPSYCH SOC, V12, P896, DOI 10.1017/S1355617706061078
   Bidelman GM, 2019, HEARING RES, V382, DOI 10.1016/j.heares.2019.107795
   Bidelman GM, 2019, BRAIN STRUCT FUNCT, V224, P2661, DOI 10.1007/s00429-019-01922-9
   BUYSSE DJ, 1989, PSYCHIAT RES, V28, P193, DOI 10.1016/0165-1781(89)90047-4
   Camarda C, 2018, CURR ALZHEIMER RES, V15, P679, DOI 10.2174/1567205015666180119110712
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   Campbell J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00071
   Canning SJD, 2004, NEUROLOGY, V62, P556, DOI 10.1212/WNL.62.4.556
   Cerhan JH, 2002, CLIN NEUROPSYCHOL, V16, P35, DOI 10.1076/clin.16.1.35.8326
   Clark David Glenn, 2016, Alzheimers Dement (Amst), V2, P113, DOI 10.1016/j.dadm.2016.02.001
   Classon E, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00241
   Classon E, 2013, J COMMUN DISORD, V46, P17, DOI 10.1016/j.jcomdis.2012.10.001
   COHEN S, 1983, J HEALTH SOC BEHAV, V24, P385, DOI 10.2307/2136404
   Conroy RM, 2010, PSYCHOL HEALTH MED, V15, P463, DOI 10.1080/13548506.2010.487103
   Cosetti MK, 2016, CLIN INTERV AGING, V11, P603, DOI 10.2147/CIA.S100255
   Cousins KAQ, 2014, MEM COGNITION, V42, P622, DOI 10.3758/s13421-013-0377-7
   Crawford J.R, 2005, EFFECTIVENESS REHABI, P233, DOI DOI 10.1093/ACPROF:OSO/9780198526544.003.0019
   Crawford JR, 2000, AGING NEUROPSYCHOL C, V7, P9, DOI 10.1076/anec.7.1.9.806
   Davey J, 2016, NEUROIMAGE, V137, P165, DOI 10.1016/j.neuroimage.2016.05.051
   De Jong Gierveld J., 2006, RES AGING, V28, P112
   Demetriou E, 2017, J INT NEUROPSYCH SOC, V23, P44, DOI 10.1017/S1355617716000825
   Donoghue O, 2018, AM J GERIAT PSYCHIAT, V26, P438, DOI 10.1016/j.jagp.2017.11.006
   Dubois B, 2016, ALZHEIMERS DEMENT, V12, P292, DOI 10.1016/j.jalz.2016.02.002
   Dupuis K, 2015, AGING NEUROPSYCHOL C, V22, P413, DOI 10.1080/13825585.2014.968084
   Er F, 2017, J CLIN NEUROSCI, V42, P186, DOI 10.1016/j.jocn.2017.03.021
   Gates GA, 2005, LANCET, V366, P1111, DOI 10.1016/S0140-6736(05)67423-5
   Gevonden M, 2014, JAMA PSYCHIAT, V71, P1364, DOI 10.1001/jamapsychiatry.2014.1325
   Gibbons LE, 2012, BRAIN IMAGING BEHAV, V6, P517, DOI 10.1007/s11682-012-9176-1
   Gillingham SM, 2018, FRONT AGING NEUROSCI, V10, DOI 10.3389/fnagi.2018.00351
   Giorgio A, 2019, NEUROIMAGE-CLIN, V22, DOI 10.1016/j.nicl.2019.101789
   Gold BT, 2006, J NEUROSCI, V26, P6523, DOI 10.1523/JNEUROSCI.0808-06.2006
   GROBER E, 1988, NEUROLOGY, V38, P900, DOI 10.1212/WNL.38.6.900
   Grossman M, 2002, NEUROPSYCHOLOGY, V16, P174, DOI 10.1037//0894-4105.16.2.174
   Henry JD, 2004, NEUROPSYCHOLOGY, V18, P284, DOI 10.1037/0894-4105.18.2.284
   Hills T., 2012, COGNITIVE SEARCH EVO
   Hills TT, 2015, TRENDS COGN SCI, V19, P46, DOI 10.1016/j.tics.2014.10.004
   Humes LE, 2019, INT J AUDIOL, V58, P12, DOI 10.1080/14992027.2018.1518598
   Husain FT, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00010
   Husain FT, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0026639
   Husain FT, 2011, BRAIN RES, V1369, P74, DOI 10.1016/j.brainres.2010.10.095
   Isovich E, 2001, EUR J NEUROSCI, V13, P1254, DOI 10.1046/j.0953-816x.2001.01492.x
   Jefferies E, 2013, CORTEX, V49, P611, DOI 10.1016/j.cortex.2012.10.008
   Kaplan E, 2001, BOSTON NAMING TEST
   Kemper S., 2008, HDB COGNITIVE AGING
   Kim N, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011933
   Kischka U, 1996, NEUROPSYCHOLOGIA, V34, P1107, DOI 10.1016/0028-3932(96)00024-3
   KOZORA E, 1995, CLIN NEUROPSYCHOL, V9, P313, DOI 10.1080/13854049508400495
   Lazard DS, 2010, NEUROIMAGE, V49, P3443, DOI 10.1016/j.neuroimage.2009.11.013
   Lazard DS, 2013, HUM BRAIN MAPP, V34, P1208, DOI 10.1002/hbm.21504
   LEZAK MD, 2004, NEUROPSYCHOLOGICAL A
   Li YY, 2013, CEREB CORTEX, V23, P1988, DOI 10.1093/cercor/bhs185
   Li ZZ, 2020, J MAGN RESON IMAGING, V51, P1045, DOI 10.1002/jmri.26961
   Lin FR, 2014, NEUROIMAGE, V90, P84, DOI 10.1016/j.neuroimage.2013.12.059
   Lin FR, 2011, NEUROPSYCHOLOGY, V25, P763, DOI 10.1037/a0024238
   Lin FR, 2011, ARCH NEUROL-CHICAGO, V68, P214, DOI 10.1001/archneurol.2010.362
   LINDENBERGER U, 1994, PSYCHOL AGING, V9, P339, DOI 10.1037/0882-7974.9.3.339
   Livingston G, 2017, LANCET, V390, P2673, DOI 10.1016/S0140-6736(17)31363-6
   Loring DW, 2003, HDB REY OSTERRIETH C, P313
   Loughrey D.G., 2018, THESIS
   Loughrey DG, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49023-1
   Loughrey DG, 2018, JAMA OTOLARYNGOL, V144, P115, DOI 10.1001/jamaoto.2017.2513
   Lubben J, 2006, GERONTOLOGIST, V46, P503, DOI 10.1093/geront/46.4.503
   Lyxell B, 2003, INT J AUDIOL, V42, pS86
   MARIN RS, 1991, PSYCHIAT RES, V38, P143, DOI 10.1016/0165-1781(91)90040-V
   Mayr U, 2002, NEUROPSYCHOLOGIA, V40, P562, DOI 10.1016/S0028-3932(01)00132-4
   McCoy SL, 2005, Q J EXP PSYCHOL-A, V58, P22, DOI 10.1080/02724980443000151
   MEADOR KJ, 1993, J CLIN EXP NEUROPSYC, V15, P832, DOI 10.1080/01688639308402599
   Mendez ME, 2019, J ALZHEIMERS DIS, V71, P377, DOI 10.3233/JAD-190397
   Mosnier I, 2015, JAMA OTOLARYNGOL, V141, P442, DOI 10.1001/jamaoto.2015.129
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Naylor CD, 2018, JAMA-J AM MED ASSOC, V320, P1099, DOI 10.1001/jama.2018.11103
   Nelson H., 1982, NATL ADULT READING T
   Pakhomov SVS, 2016, NEUROPSYCHOLOGIA, V89, P42, DOI 10.1016/j.neuropsychologia.2016.05.031
   Pakhomov SVS, 2014, CORTEX, V55, P97, DOI 10.1016/j.cortex.2013.05.009
   Panza F, 2015, NAT REV NEUROL, V11
   Papp Kathryn V, 2017, Alzheimers Dement (N Y), V3, P668, DOI 10.1016/j.trci.2017.10.004
   Pederzolli AS, 2008, COGN BEHAV NEUROL, V21, P134, DOI 10.1097/WNN.0b013e318185e6f2
   Peelle JE, 2011, J NEUROSCI, V31, P12638, DOI 10.1523/JNEUROSCI.2559-11.2011
   Peelle JE, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00051
   Peters N, 2005, AM J PSYCHIAT, V162, P2078, DOI 10.1176/appi.ajp.162.11.2078
   Qian ZJ, 2017, NEUROIMAGE-CLIN, V16, P205, DOI 10.1016/j.nicl.2017.07.021
   RADLOFF L S, 1977, Applied Psychological Measurement, V1, P385, DOI 10.1177/014662167700100306
   Raoux N, 2008, CORTEX, V44, P1188, DOI 10.1016/j.cortex.2007.08.019
   Robertson IH, 1997, NEUROPSYCHOLOGIA, V35, P747, DOI 10.1016/S0028-3932(97)00015-8
   Romero-Ortuno R, 2010, BMC GERIATR, V10, DOI 10.1186/1471-2318-10-57
   Ronnberg J, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00326
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2011, J SPEECH LANG HEAR R, V54, P705, DOI 10.1044/1092-4388(2010/09-0088)
   ROTH M, 1986, BRIT J PSYCHIAT, V149, P698, DOI 10.1192/bjp.149.6.698
   Rudner M, 2019, J SPEECH LANG HEAR R, V62, P1117, DOI 10.1044/2018_JSLHR-H-ASCC7-18-0142
   Rudner M, 2008, INT J AUDIOL, V47, pS91, DOI 10.1080/14992020802304393
   Ryan J., 2013, COMPUTERIZED ANAL VE
   Salthouse TA, 2003, J EXP PSYCHOL GEN, V132, P566, DOI 10.1037/0096-3445.132.4.566
   Schmidt CSM, 2019, NEUROIMAGE-CLIN, V23, DOI 10.1016/j.nicl.2019.101840
   Schmidt CSM, 2017, NEUROPSYCHOLOGIA, V99, P148, DOI 10.1016/j.neuropsychologia.2017.02.019
   Shao Z, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00772
   Teige C, 2018, CORTEX, V103, P329, DOI 10.1016/j.cortex.2018.03.024
   Tidey JW, 1996, BRAIN RES, V721, P140, DOI 10.1016/0006-8993(96)00159-X
   Troyer AK, 1998, J INT NEUROPSYCH SOC, V4, P137, DOI 10.1017/S1355617798001374
   Troyer AK, 1997, NEUROPSYCHOLOGY, V11, P138, DOI 10.1037/0894-4105.11.1.138
   Troyer AK, 1998, NEUROPSYCHOLOGIA, V36, P499, DOI 10.1016/S0028-3932(97)00152-8
   Tun PA, 2009, PSYCHOL AGING, V24, P761, DOI 10.1037/a0014802
   Vaughan RM, 2016, J INT NEUROPSYCH SOC, V22, P570, DOI 10.1017/S1355617716000291
   Ventry I M, 1983, ASHA, V25, P37
   Volter C, 2018, CLIN INTERV AGING, V13, P701, DOI 10.2147/CIA.S160517
   Vonberg I, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0115846
   Weakley A, 2013, ARCH CLIN NEUROPSYCH, V28, P721, DOI 10.1093/arclin/act058
   Wechsler D., 1997, ADM SCORING MANUAL
   Wingfield A, 2006, J NEUROPHYSIOL, V96, P2830, DOI 10.1152/jn.00628.2006
   World Health Organisation, 2016, GRADES OF HEARING IM
   World Health Organization-WHO, 2018, DEAFN HEAR LOSS
   Xu XM, 2019, NEURAL PLAST, V2019, DOI 10.1155/2019/8354849
   Xu XM, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00246
   Xu XM, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00133
   Yoon CW, 2013, NEUROLOGY, V80, P569, DOI 10.1212/WNL.0b013e3182815485
   Zhu ZW, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0056662
   ZIGMOND AS, 1983, ACTA PSYCHIAT SCAND, V67, P361, DOI 10.1111/j.1600-0447.1983.tb09716.x
NR 121
TC 3
Z9 3
U1 0
U2 5
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0531-5565
EI 1873-6815
J9 EXP GERONTOL
JI Exp. Gerontol.
PD FEB
PY 2020
VL 130
SI SI
AR 110794
DI 10.1016/j.exger.2019.110794
PG 10
WC Geriatrics & Gerontology
SC Geriatrics & Gerontology
GA KA4MN
UT WOS:000505771100002
PM 31790801
DA 2021-02-24
ER

PT J
AU Zoefel, B
   Allard, I
   Anil, M
   Davis, MH
AF Zoefel, Benedikt
   Allard, Isobella
   Anil, Megha
   Davis, Matthew H.
TI Perception of Rhythmic Speech Is Modulated by Focal Bilateral
   Transcranial Alternating Current Stimulation
SO JOURNAL OF COGNITIVE NEUROSCIENCE
LA English
DT Article; Proceedings Paper
CT Symposium on Oscillatory Mechanisms Underlying Human Perception and
   Attention at the 25th Annual Meeting of Cognitive-Neuroscience-Society
   (CNS)
CY MAR 24-27, 2018
CL Boston, MA
SP Cognit Neurosci Soc
ID ELECTRIC-STIMULATION; PHASE ENTRAINMENT; NEURONAL OSCILLATIONS; NEURAL
   ENTRAINMENT; VIVO MEASUREMENTS; RECOGNITION; RESPONSES; SAFETY; TACS
AB Several recent studies have used transcranial alternating current stimulation (tACS) to demonstrate a causal role of neural oscillatory activity in speech processing. In particular, it has been shown that the ability to understand speech in a multi-speaker scenario or background noise depends on the timing of speech presentation relative to simultaneously applied tACS. However, it is possible that tACS did not change actual speech perception but rather auditory stream segregation. In this study, we tested whether the phase relation between tACS and the rhythm of degraded words, presented in silence, modulates word report accuracy. We found strong evidence for a tACS-induced modulation of speech perception, but only if the stimulation was applied bilaterally using ring electrodes (not for unilateral left hemisphere stimulation with square electrodes). These results were only obtained when data were analyzed using a statistical approach that was identified as optimal in a previous simulation study. The effect was driven by a phasic disruption of word report scores. Our results suggest a causal role of neural entrainment for speech perception and emphasize the importance of optimizing stimulation protocols and statistical approaches for brain stimulation research.
C1 [Zoefel, Benedikt; Allard, Isobella; Anil, Megha; Davis, Matthew H.] Univ Cambridge, Cambridge, England.
RP Zoefel, B (corresponding author), Univ Cambridge, MRC Cognit & Brain Sci Unit, 15 Chaucer Rd, Cambridge CB2 7EF, England.
EM benedikt.zoefel@mrc-cbu.cam.ac.uk
FU German Academic Exchange Service (DAAD)Deutscher Akademischer Austausch
   Dienst (DAAD); European UnionEuropean Commission [743482]; Medical
   Research Council UKUK Research & Innovation (UKRI)Medical Research
   Council UK (MRC) [SUAG/008/RG91365]
FX The authors thank Prof. Axel Thielscher for helpful advice with the
   electrode configurations and Simon Strangeways for help with their
   illustration. This work was supported by a grant from the German
   Academic Exchange Service (DAAD), the European Union's Horizon 2020
   research and innovation program under the Marie Sklodowska-Curie Grant
   agreement number 743482, and the Medical Research Council UK (grant
   number SUAG/008/RG91365).
CR Antal A, 2017, CLIN NEUROPHYSIOL, V128, P1774, DOI 10.1016/j.clinph.2017.06.001
   Asamoah B, 2019, BRAIN STIMUL, V12, P1001, DOI 10.1016/j.brs.2019.03.011
   Asamoah B, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-018-08183-w
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Busch NA, 2009, J NEUROSCI, V29, P7869, DOI 10.1523/JNEUROSCI.0113-09.2009
   Buzsaki G, 2004, SCIENCE, V304, P1926, DOI 10.1126/science.1099745
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Cousineau D, 2005, TUTOR QUANT METHODS, V1, P42, DOI 10.20982/tqmp.01.1.p042
   Cummins F, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00364
   Datta A, 2009, BRAIN STIMUL, V2, P201, DOI 10.1016/j.brs.2009.03.005
   Ding N, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00311
   Fertonani A, 2015, CLIN NEUROPHYSIOL, V126, P2181, DOI 10.1016/j.clinph.2015.03.015
   Ghitza O, 2013, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00340
   Greinacher R, 2019, EUR J NEUROSCI, V50, P3380, DOI 10.1111/ejn.14497
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Haegens S, 2018, NEUROSCI BIOBEHAV R, V86, P150, DOI 10.1016/j.neubiorev.2017.12.002
   Heise KF, 2016, BRAIN STIMUL, V9, P700, DOI 10.1016/j.brs.2016.04.009
   Henry MJ, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15801
   Henry MJ, 2012, P NATL ACAD SCI USA, V109, P20095, DOI 10.1073/pnas.1213390109
   Herrmann CS, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00279
   Hickok G, 2015, PSYCHOL SCI, V26, P1006, DOI 10.1177/0956797615576533
   Huang Y, 2017, ELIFE, V6, DOI 10.7554/eLife.18834
   Kessler SK, 2012, BRAIN STIMUL, V5, P155, DOI 10.1016/j.brs.2011.02.007
   Kleinert ML, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00367
   Kosem A, 2018, CURR BIOL, V28, P2867, DOI 10.1016/j.cub.2018.07.023
   Krause MR, 2019, P NATL ACAD SCI USA, V116, P5747, DOI 10.1073/pnas.1815958116
   Lafon B, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01045-x
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735
   Ledgerwood A, 2018, P NATL ACAD SCI USA, V115, pE10516, DOI 10.1073/pnas.1812592115
   Macmillan N, 2004, DETECTION THEORY USE
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   MORTON J, 1976, PSYCHOL REV, V83, P405, DOI 10.1037/0033-295X.83.5.405
   Nakazono H, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162521
   Neuling Toralf, 2012, Front Psychiatry, V3, P83
   Ng BSW, 2012, J NEUROSCI, V32, P12268, DOI 10.1523/JNEUROSCI.1877-12.2012
   Nosek BA, 2018, P NATL ACAD SCI USA, V115, P2600, DOI 10.1073/pnas.1708274114
   Oganian Y., 2018, 388280 BIORXIV, DOI [10.1101/388280, DOI 10.1101/388280]
   Opitz A, 2017, P NATL ACAD SCI USA, V114, P5243, DOI 10.1073/pnas.1617024114
   Opitz A, 2016, SCI REP-UK, V6, DOI 10.1038/srep31236
   Peelle JE, 2018, CURR BIOL, V28, pR68, DOI 10.1016/j.cub.2017.12.005
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Petersen EB, 2017, J NEUROPHYSIOL, V117, P18, DOI 10.1152/jn.00527.2016
   Pikovsky A., 2008, SYNCHRONIZATION UNIV
   Presacco A, 2016, J NEUROPHYSIOL, V116, P2346, DOI 10.1152/jn.00372.2016
   Pressnitzer D, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00158
   Purcell DW, 2004, J ACOUST SOC AM, V116, P3581, DOI 10.1121/1.1798354
   Riecke L, 2018, ACTA ACUST UNITED AC, V104, P883, DOI 10.3813/AAA.919235
   Riecke L, 2018, CURR BIOL, V28, P161, DOI 10.1016/j.cub.2017.11.033
   Riecke L, 2015, CURR BIOL, V25, P3196, DOI 10.1016/j.cub.2015.10.045
   Ruhnau P, 2018, BRAIN STIMUL, V11, P241, DOI 10.1016/j.brs.2017.09.015
   Saturnino GB, 2015, NEUROIMAGE, V120, P25, DOI 10.1016/j.neuroimage.2015.06.067
   Saturnino GB, 2017, NEUROIMAGE, V163, P68, DOI 10.1016/j.neuroimage.2017.09.024
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sohoglu E, 2014, J EXP PSYCHOL HUMAN, V40, P186, DOI 10.1037/a0033206
   Turi Z, 2019, EUR J NEUROSCI, V50, P3261, DOI 10.1111/ejn.14403
   VanRullen R, 2012, CURR BIOL, V22, P995, DOI 10.1016/j.cub.2012.03.050
   Voroslakos M, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-02928-3
   Vosskuhl J, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00211
   Vosskuhl J, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00257
   WATSON AB, 1983, PERCEPT PSYCHOPHYS, V33, P113, DOI 10.3758/BF03202828
   Wilsch A, 2018, NEUROIMAGE, V172, P766, DOI 10.1016/j.neuroimage.2018.01.038
   Wittenberg MA, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00311
   Zoefel B, 2019, NEUROIMAGE, V202, DOI 10.1016/j.neuroimage.2019.116175
   Zoefel B, 2018, CURR BIOL, V28, pR1102, DOI 10.1016/j.cub.2018.07.048
   Zoefel B, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00095
   Zoefel B, 2018, CURR BIOL, V28, P401, DOI 10.1016/j.cub.2017.11.071
   Zoefel B, 2017, LANG COGN NEUROSCI, V32, P910, DOI 10.1080/23273798.2016.1247970
   Zoefel B, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3389/fnhum.2015.00651, 10.1038/NATURE11020]
   Zoefel B, 2015, J NEUROSCI, V35, P1954, DOI 10.1523/JNEUROSCI.3484-14.2015
NR 70
TC 5
Z9 5
U1 8
U2 12
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0898-929X
EI 1530-8898
J9 J COGNITIVE NEUROSCI
JI J. Cogn. Neurosci.
PD FEB
PY 2020
VL 32
IS 2
BP 226
EP 240
DI 10.1162/jocn_a_01490
PG 15
WC Neurosciences; Psychology, Experimental
SC Neurosciences & Neurology; Psychology
GA JZ1LQ
UT WOS:000504866700004
PM 31659922
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Escudero, P
   Kalashnikova, M
AF Escudero, Paola
   Kalashnikova, Marina
TI Infants use phonetic detail in speech perception and word learning when
   detail is easy to perceive
SO JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY
LA English
DT Article
DE Infancy; Speech perception; Word learning; Phonetic detail; Vowel
   minimal pairs; Acoustic properties
ID DIRECTED SPEECH; ACQUISITION; VOWELS; DISCRIMINATION; EXPERIENCE; CUES;
   RECOGNITION; VARIABILITY; CONSONANTS; CHILDREN
AB Infants successfully discriminate speech sound contrasts that belong to their native language's phonemic inventory in auditory-only paradigms, but they encounter difficulties in distinguishing the same contrasts in the context of word learning. These difficulties are usually attributed to the fact that infants' attention to the phonetic detail in novel words is attenuated when they must allocate additional cognitive resources demanded by word-learning tasks. The current study investigated 15-month-old infants' ability to distinguish novel words that differ by a single vowel in an auditory discrimination paradigm (Experiment 1) and a word-learning paradigm (Experiment 2). These experiments aimed to tease apart whether infants' performance is dependent solely on the specific acoustic properties of the target vowels or on the context of the task. Experiment 1 showed that infants were able to discriminate only a contrast marked by a large difference along a static dimension (the vowels' second formant), whereas they were not able to discriminate a contrast with a small phonetic distance between its vowels, due to the dynamic nature of the vowels. In Experiment 2, infants did not succeed at learning words containing the same contrast they were able to discriminate in Experiment 1. The current findings demonstrate that both the specific acoustic properties of vowels in infants' native language and the task presented continue to play a significant role in early speech perception well into the second year of life. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Escudero, Paola; Kalashnikova, Marina] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Penrith, NSW 2751, Australia.
   [Escudero, Paola] Australian Natl Univ, ARC Ctr Excellence Dynam Language, Canberra, ACT 2601, Australia.
   [Kalashnikova, Marina] Basque Ctr Cognit Brain & Language, Donostia San Sebastian 20009, Gipuzkoa, Spain.
RP Escudero, P (corresponding author), Western Sydney Univ, MARCS Inst Brain Behav & Dev, Penrith, NSW 2751, Australia.
EM paola.escudero@westernsydney.edu.au
OI Kalashnikova, Marina/0000-0002-7924-8687
FU Australian Research Council (ARC) Centre of Excellence for the Dynamics
   of LanguageAustralian Research Council [CE140100041]; ARCAustralian
   Research Council [FT160100514]; European Union's Horizon 2020 Marie
   Sklodowska-Curie individual fellowships European Comission [798908]
FX This work was supported by the Australian Research Council (ARC) Centre
   of Excellence for the Dynamics of Language (CE140100041), where the
   first author is chief investigator. The first author's work is supported
   by an ARC Future Fellowship (FT160100514). The second author receives
   support from the European Union's Horizon 2020 Marie Sklodowska-Curie
   individual fellowships European Comission (798908). We thank Nicole
   Traynor for assistance with data collection, Anne Dwyer for recording
   the stimuli, and James Whang for making Figs. 1 and 3. We also express
   our gratitude to our infant participants and their parents for their
   invaluable contributions and interest in the research.
CR [Anonymous], 1996, OBJECT DATABANK
   ASLIN RN, 1981, CHILD DEV, V52, P1135, DOI 10.1111/j.1467-8624.1981.tb03159.x
   Best C.T., 1994, DEV SPEECH PERCEPTIO, P167
   Boersma P., 2003, P 15 INT C PHON SCI, V1013
   Burnham D, 2002, SCIENCE, V296, P1435, DOI 10.1126/science.1069587
   BURNHAM DK, 1986, APPL PSYCHOLINGUIST, V7, P207, DOI 10.1017/S0142716400007542
   Cohen L.B, 2004, HABIT X NEW PROGRAM
   Curtin S, 2011, J PHONETICS, V39, P492, DOI 10.1016/j.wocn.2010.12.002
   Curtin S, 2009, DEVELOPMENTAL SCI, V12, P725, DOI 10.1111/j.1467-7687.2009.00814.x
   Dietrich C, 2007, P NATL ACAD SCI USA, V104, P16027, DOI 10.1073/pnas.0705270104
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Elvin J, 2016, J ACOUST SOC AM, V140, P576, DOI 10.1121/1.4952387
   Escudero P., 2010, LINGUISTICS ENTERPRI, P55
   Escudero P, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12640
   Escudero P, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01419
   Escudero P, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01059
   Escudero P, 2009, J ACOUST SOC AM, V126, P1379, DOI 10.1121/1.3180321
   Fennell CT, 2010, CHILD DEV, V81, P1376, DOI 10.1111/j.1467-8624.2010.01479.x
   Fennell CT, 2003, LANG SPEECH, V46, P245, DOI 10.1177/00238309030460020901
   Fikkert P, 2010, LAB PHONOL, V10, P227, DOI DOI 10.1515/9783110224917.3.227
   Galle ME, 2015, LANG LEARN DEV, V11, P66, DOI 10.1080/15475441.2014.895249
   Galle ME, 2014, PSYCHON B REV, V21, P884, DOI 10.3758/s13423-013-0569-y
   Gerrits E., 2001, DISSERTATION SERIES, V42
   Giezen MR, 2010, J SPEECH LANG HEAR R, V53, P1440, DOI 10.1044/1092-4388(2010/09-0252)
   Hay JF, 2015, CHILD DEV, V86, P10, DOI 10.1111/cdev.12269
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   IVERSON P, 1995, J ACOUST SOC AM, V97, P553, DOI 10.1121/1.412280
   Kalashnikova M, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.170306
   Kalashnikova M, 2016, DYSLEXIA, V22, P101, DOI 10.1002/dys.1525
   Kalashnikova M, 2015, BILING-LANG COGN, V18, P626, DOI 10.1017/S1366728914000364
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Liu LQ, 2016, INT J BILINGUAL, V20, P335, DOI 10.1177/1367006914566082
   McMurray B, 2018, DEV PSYCHOL, V54, P1472, DOI 10.1037/dev0000542
   McMurray B, 2013, COGNITION, V129, P362, DOI 10.1016/j.cognition.2013.07.015
   Miyazawa K, 2017, COGNITION, V166, P84, DOI 10.1016/j.cognition.2017.05.003
   Mulak KE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176762
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Nazzi T, 2005, COGNITION, V98, P13, DOI 10.1016/j.cognition.2004.10.005
   Nespor M., 2003, LINGUE LINGUAGGIO, V2, P203, DOI [10. 1418/ 10879, DOI 10.1418/10879]
   Nittrouer S, 2014, LANG SPEECH, V57, P487, DOI 10.1177/0023830913508075
   Pater J, 2004, LANGUAGE, V80, P384, DOI 10.1353/lan.2004.0141
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   Polka L, 2001, J ACOUST SOC AM, V109, P2190, DOI 10.1121/1.1362689
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Repp BH., 1984, SPEECH LANG ADV BASI, V10, P243, DOI DOI 10.1016/B978-0-12-608610-2.50012-1
   Rost GC, 2010, INFANCY, V15, P608, DOI 10.1111/j.1532-7078.2010.00033.x
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Sato Y, 2010, DEV PSYCHOL, V46, P106, DOI 10.1037/a0016718
   Singh L, 2004, J MEM LANG, V51, P173, DOI 10.1016/j.jml.2004.04.004
   Singh L, 2008, LANG LEARN DEV, V4, P157, DOI 10.1080/15475440801922131
   Singh L, 2018, CHILD DEV, V89, pE183, DOI 10.1111/cdev.12747
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Swingley D, 2002, J MEM LANG, V46, P39, DOI 10.1006/jmla.2001.2799
   Tsuji S, 2014, DEV PSYCHOBIOL, V56, P179, DOI 10.1002/dev.21179
   van Leussen JW, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01000
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Werker JF, 1998, DEV PSYCHOL, V34, P1289, DOI 10.1037/0012-1649.34.6.1289
   Werker JF, 2005, TRENDS COGN SCI, V9, P519, DOI 10.1016/j.tics.2005.09.003
   Werker JF, 2005, DEV PSYCHOBIOL, V46, P233, DOI 10.1002/dev.20060
   Werker JF, 1999, ANNU REV PSYCHOL, V50, P509, DOI 10.1146/annurev.psych.50.1.509
   Yildirim I, 2013, COGNITION, V126, P135, DOI 10.1016/j.cognition.2012.08.005
   Yoshida KA, 2009, DEVELOPMENTAL SCI, V12, P412, DOI 10.1111/j.1467-7687.2008.00789.x
NR 67
TC 1
Z9 1
U1 1
U2 12
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0022-0965
EI 1096-0457
J9 J EXP CHILD PSYCHOL
JI J. Exp. Child Psychol.
PD FEB
PY 2020
VL 190
AR 104714
DI 10.1016/j.jecp.2019.104714
PG 16
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA JU8TH
UT WOS:000501941900008
PM 31734323
DA 2021-02-24
ER

PT J
AU Peelle, JE
   Miller, RL
   Rogers, CS
   Spehar, B
   Sommers, MS
   Van Engen, KJ
AF Peelle, Jonathan E.
   Miller, Ryland L.
   Rogers, Chad S.
   Spehar, Brent
   Sommers, Mitchell S.
   Van Engen, Kristin J.
TI Completion norms for 3085 English sentence contexts
SO BEHAVIOR RESEARCH METHODS
LA English
DT Article
DE prediction; cloze probability; sentence processing; expectation;
   response entropy
ID SPEECH-PERCEPTION; WORD; INTEGRATION; AGE
AB In everyday language processing, sentence context affects how readers and listeners process upcoming words. In experimental situations, it can be useful to identify words that are predicted to greater or lesser degrees by the preceding context. Here we report completion norms for 3085 English sentences, collected online using a written cloze procedure in which participants were asked to provide their best guess for the word completing a sentence. Sentences varied between eight and ten words in length. At least 100 unique participants contributed to each sentence. All responses were reviewed by human raters to mitigate the influence of mis-spellings and typographical errors. The responses provide a range of predictability values for 13,438 unique target words, 6790 of which appear in more than one sentence context. We also provide entropy values based on the relative predictability of multiple responses. A searchable set of norms is available at . Finally, we provide the code used to collate and organize the responses to facilitate additional analyses and future research projects.
C1 [Peelle, Jonathan E.; Spehar, Brent] Washington Univ, Dept Otolaryngol, 660 South Euclid,Box 8115, St Louis, MO 63110 USA.
   [Miller, Ryland L.] Washington Univ, Dept Neurol, St Louis, MO 63110 USA.
   [Rogers, Chad S.] Union Coll, Dept Psychol, Schenectady, NY 12308 USA.
   [Sommers, Mitchell S.; Van Engen, Kristin J.] Washington Univ, Dept Psychol & Brain Sci, St Louis, MO 63110 USA.
RP Peelle, JE (corresponding author), Washington Univ, Dept Otolaryngol, 660 South Euclid,Box 8115, St Louis, MO 63110 USA.
EM jpeelle@wustl.edu
RI Peelle, Jonathan/AAA-8299-2020
OI Peelle, Jonathan/0000-0001-9194-854X
FU US National Institutes of HealthUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USA [R01DC014281]
FX This work was supported by R01DC014281 from the US National Institutes
   of Health. We thank Darcy Camp, Nisha Dhanik, Sophie Guiton, Nisha
   Patel, Hunter Patterson, Joseph Tang, Tracy Wang, and Rebecca Yang their
   help in creating and editing the original sentences. We thank Joseph
   Tang for assistance in online data collection, and Madeleine Homoly,
   Henry Greenstein, Ben Muller, Maddie Noyes, Michelle Pacheco, and Ari
   Zimmer for reviewing responses. We thank Andrew Weng for assistance
   creating the website.
CR BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32
   Blank H, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002577
   Block CK, 2010, BEHAV RES METHODS, V42, P665, DOI 10.3758/BRM.42.3.665
   BLOOM PA, 1980, MEM COGNITION, V8, P631, DOI 10.3758/BF03213783
   DeLong KA, 2016, NEUROPSYCHOLOGIA, V91, P380, DOI 10.1016/j.neuropsychologia.2016.09.004
   Federmeier KD, 2007, BRAIN RES, V1146, P75, DOI 10.1016/j.brainres.2006.06.101
   Hamberger MJ, 1996, BEHAV RES METH INSTR, V28, P102, DOI 10.3758/BF03203644
   HOWES D, 1954, J EXP PSYCHOL, V48, P106, DOI 10.1037/h0059478
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Lahar CJ, 2004, J GERONTOL B-PSYCHOL, V59, pP7, DOI 10.1093/geronb/59.1.P7
   Lash A, 2013, EXP AGING RES, V39, P235, DOI 10.1080/0361073X.2013.779175
   MORTON J, 1964, BRIT J PSYCHOL, V55, P165, DOI 10.1111/j.2044-8295.1964.tb02716.x
   Obleser J, 2007, J NEUROSCI, V27, P2283, DOI 10.1523/JNEUROSCI.4663-06.2007
   Quante L, 2018, PEERJ, V6, DOI 10.7717/peerj.5717
   Shannon C. E, 1951, PHILOS REV, V60, P398, DOI [DOI 10.2307/2181879, 10.2307/2181879]
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   Taylor WL, 1953, JOURNALISM QUART, V30, P415, DOI 10.1177/107769905303000401
   TREISMAN AM, 1965, NATURE, V206, P218, DOI 10.1038/206218a0
   Wlotko EW, 2012, PSYCHOL AGING, V27, P975, DOI 10.1037/a0029206
NR 19
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1554-351X
EI 1554-3528
J9 BEHAV RES METHODS
JI Behav. Res. Methods
PD AUG
PY 2020
VL 52
IS 4
BP 1795
EP 1799
DI 10.3758/s13428-020-01351-1
EA JAN 2020
PG 5
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA MZ5ZK
UT WOS:000515654600001
PM 31993960
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Ullas, S
   Formisano, E
   Eisner, F
   Cutler, A
AF Ullas, Shruti
   Formisano, Elia
   Eisner, Frank
   Cutler, Anne
TI Interleaved lexical and audiovisual information can retune phoneme
   boundaries
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Phoneme boundary; Recalibration; Perceptual retuning; Lexical;
   Audiovisual
ID SELECTIVE ADAPTATION; SPEECH-PERCEPTION; LIPREAD SPEECH; VISUAL
   RECALIBRATION; AUDITORY SPEECH; CATEGORIZATION
AB To adapt to situations in which speech perception is difficult, listeners can adjust boundaries between phoneme categories using perceptual learning. Such adjustments can draw on lexical information in surrounding speech, or on visual cues via speech-reading. In the present study, listeners proved they were able to flexibly adjust the boundary between two plosive/stop consonants, /p/-/t/, using both lexical and speech-reading information and given the same experimental design for both cue types. Videos of a speaker pronouncing pseudo-words and audio recordings of Dutch words were presented in alternating blocks of either stimulus type. Listeners were able to switch between cues to adjust phoneme boundaries, and resulting effects were comparable to results from listeners receiving only a single source of information. Overall, audiovisual cues (i.e., the videos) produced the stronger effects, commensurate with their applicability for adapting to noisy environments. Lexical cues were able to induce effects with fewer exposure stimuli and a changing phoneme bias, in a design unlike most prior studies of lexical retuning. While lexical retuning effects were relatively weaker compared to audiovisual recalibration, this discrepancy could reflect how lexical retuning may be more suitable for adapting to speakers than to environments. Nonetheless, the presence of the lexical retuning effects suggests that it may be invoked at a faster rate than previously seen. In general, this technique has further illuminated the robustness of adaptability in speech perception, and offers the potential to enable further comparisons across differing forms of perceptual learning.
C1 [Ullas, Shruti; Formisano, Elia] Maastricht Univ, Fac Psychol & Neurosci, Dept Cognit Neurosci, NL-6200 MD Maastricht, Netherlands.
   [Eisner, Frank] Radboud Univ Nijmegen, Donders Ctr Cognit, NL-6500 AH Nijmegen, Netherlands.
   [Cutler, Anne] Western Sydney Univ, MARCS Inst, Penrith, NSW 2751, Australia.
   [Cutler, Anne] Western Sydney Univ, ARC Ctr Excellence Dynam Language, Penrith, NSW 2751, Australia.
RP Ullas, S (corresponding author), Maastricht Univ, Fac Psychol & Neurosci, Dept Cognit Neurosci, NL-6200 MD Maastricht, Netherlands.
EM shruti.ullas@maastrichtuniversity.nl
OI Ullas, Shruti/0000-0002-0056-651X; Formisano, Elia/0000-0001-5008-2460
FU Netherlands Organization for Scientific Research gravity program
   Language in Interaction
FX We acknowledge financial support from the Netherlands Organization for
   Scientific Research gravity program Language in Interaction.
CR Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bruggeman L, 2020, BILING-LANG COGN, V23, P681, DOI 10.1017/S1366728919000646
   Cutler A., 2010, LAB PHONOLOGY, V10, P91
   Cutler A, 2012, DUTCH J APPL LINGUIS, V1, P169, DOI 10.1075/dujal.1.2.02cut
   Duyck W, 2004, BEHAV RES METH INS C, V36, P488, DOI 10.3758/BF03195595
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   Eisner F, 2006, J ACOUST SOC AM, V119, P1950, DOI 10.1121/1.2178721
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Keetels M, 2016, J PHONETICS, V56, P124, DOI 10.1016/j.wocn.2016.02.005
   Keetels M, 2015, COGNITION, V141, P121, DOI 10.1016/j.cognition.2015.04.019
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kraljic T, 2009, ATTEN PERCEPT PSYCHO, V71, P481, DOI [10.3758/APP, DOI 10.3758/APP]
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Luttke CS, 2018, ROY SOC OPEN SCI, V5, DOI 10.1098/rsos.170909
   MACLEOD A, 1987, British Journal of Audiology, V21, P131, DOI 10.3109/03005368709077786
   Massaro D. W., 2007, OXFORD HDB PSYCHOLIN, P19, DOI [10.1093/oxfordhb/9780198568971.013.0002, DOI 10.1093/0XF0RDHB/9780198568971.013.0002]
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MCQUEEN JM, 1991, J EXP PSYCHOL HUMAN, V17, P433, DOI 10.1037/0096-1523.17.2.433
   Mitchel AD, 2016, J PHONETICS, V56, P66, DOI 10.1016/j.wocn.2016.02.003
   Mitterer H, 2017, ATTEN PERCEPT PSYCHO, V79, P660, DOI 10.3758/s13414-016-1249-6
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   REPP BH, 1981, B PSYCHONOMIC SOC, V18, P12
   Samuel AG, 2001, PSYCHOL SCI, V12, P348, DOI 10.1111/1467-9280.00364
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   van Linden S, 2007, J EXP PSYCHOL HUMAN, V33, P1483, DOI 10.1037/0096-1523.33.6.1483
   Vroomen J, 2004, SPEECH COMMUN, V44, P55, DOI 10.1016/j.specom.2004.03.009
   Vroomen J., 2012, NEURAL BASEMULTISE, P363, DOI DOI 10.1201/9781439812174-24
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
   Vroomen J, 2009, LANG SPEECH, V52, P341, DOI 10.1177/0023830909103178
NR 30
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2020
VL 82
IS 4
BP 2018
EP 2026
DI 10.3758/s13414-019-01961-8
EA JAN 2020
PG 9
WC Psychology; Psychology, Experimental
SC Psychology
GA LY5OH
UT WOS:000508702000004
PM 31970708
OA Bronze
DA 2021-02-24
ER

PT J
AU Parthasarathy, A
   Hancock, KE
   Bennett, K
   DeGruttola, V
   Polley, DB
AF Parthasarathy, Aravindakshan
   Hancock, Kenneth E.
   Bennett, Kara
   DeGruttola, Victor
   Polley, Daniel B.
TI Bottom-up and top-down neural signatures of disordered multi-talker
   speech perception in adults with normal hearing
SO ELIFE
LA English
DT Article
ID TEMPORAL FINE-STRUCTURE; LISTENING EFFORT; AMPLITUDE-MODULATION;
   FREQUENCY-MODULATION; COCHLEAR NEUROPATHY; ABSOLUTE THRESHOLDS; IMPAIRED
   LISTENERS; CARRIER FREQUENCY; CODING FREQUENCY; AUDITORY-NERVE
AB In social settings, speech waveforms from nearby speakers mix together in our ear canals. Normally, the brain unmixes the attended speech stream from the chorus of background speakers using a combination of fast temporal processing and cognitive active listening mechanisms. Of >100,000 patient records,similar to 10% of adults visited our clinic because of reduced hearing, only to learn that their hearing was clinically normal and should not cause communication difficulties. We found that multi-talker speech intelligibility thresholds varied widely in normal hearing adults, but could be predicted from neural phase-locking to frequency modulation (FM) cues measured with ear canal EEG recordings. Combining neural temporal fine structure processing, pupil-indexed listening effort, and behavioral FM thresholds accounted for 78% of the variability in multi-talker speech intelligibility. The disordered bottom-up and top-down markers of poor multi-talker speech perception identified here could inform the design of next-generation clinical tests for hidden hearing disorders.
C1 [Parthasarathy, Aravindakshan; Hancock, Kenneth E.; Polley, Daniel B.] Massachusetts Eye & Ear Infirm, Eaton Peabody Labs, Boston, MA 02114 USA.
   [Parthasarathy, Aravindakshan; Hancock, Kenneth E.; Polley, Daniel B.] Harvard Med Sch, Dept Otolaryngol Head & Neck Surg, Boston, MA 02115 USA.
   [Bennett, Kara] Bennett Stat Consulting Inc, Ballston, AR USA.
   [DeGruttola, Victor] Harvard TH Chan Sch Publ Hlth, Dept Biostat, Boston, MA USA.
RP Parthasarathy, A (corresponding author), Massachusetts Eye & Ear Infirm, Eaton Peabody Labs, Boston, MA 02114 USA.; Parthasarathy, A (corresponding author), Harvard Med Sch, Dept Otolaryngol Head & Neck Surg, Boston, MA 02115 USA.
EM Aravindakshan_Parthasarathy@meei.harvard.edu
OI Polley, Daniel/0000-0002-5120-2409; Parthasarathy,
   Aravindakshan/0000-0002-4573-8004
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [P50-DC015857]
FX National Institutes of Health P50-DC015857 Daniel B Polley; The funders
   had no role in study design, data collection and interpretation, or the
   decision to submit the work for publication.
CR Auerbach BD, 2019, NEUROSCIENCE, V407, P93, DOI 10.1016/j.neuroscience.2018.09.036
   Bakay WMH, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06777-y
   Balaram P, 2019, NEUROSCIENCE, V407, P108, DOI 10.1016/j.neuroscience.2018.08.023
   Besser J, 2015, EAR HEARING, V36, P24, DOI 10.1097/AUD.0000000000000096
   Best V, 2009, JARO-J ASSOC RES OTO, V10, P142, DOI 10.1007/s10162-008-0146-7
   Bharadwaj HM, 2019, NEUROSCIENCE, V407, P53, DOI 10.1016/j.neuroscience.2019.02.031
   Bramhall N, 2019, HEARING RES, V377, P88, DOI 10.1016/j.heares.2019.02.016
   Buran B., 2019, ABR ANAL
   Buss E, 2004, EAR HEARING, V25, P242, DOI 10.1097/01.AUD.0000130796.73809.09
   Caspary DM, 2008, J EXP BIOL, V211, P1781, DOI 10.1242/jeb.013581
   Chambers AR, 2016, NEURON, V89, P867, DOI 10.1016/j.neuron.2015.12.041
   Deroche MLD, 2014, J ACOUST SOC AM, V135, P2873, DOI 10.1121/1.4870056
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Ding N, 2009, J NEUROPHYSIOL, V102, P2731, DOI 10.1152/jn.00523.2009
   DiNino M, 2019, J ACOUST SOC AM, V146, P3048, DOI [10.1121/1.5137563, DOI 10.1121/1.5137563]
   Divenyi P, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00144
   Enikolopov AG, 2018, NEURON, V99, P135, DOI 10.1016/j.neuron.2018.06.006
   FAUSTI SA, 1981, SCAND AUDIOL, V10, P21, DOI 10.3109/01050398109076158
   Fernandez KA, 2015, J NEUROSCI, V35, P7509, DOI 10.1523/JNEUROSCI.5138-14.2015
   Fettiplace R, 2017, COMPR PHYSIOL, V7, P1197, DOI 10.1002/cphy.c160049
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Furman AC, 2013, J NEUROPHYSIOL, V110, P577, DOI 10.1152/jn.00164.2013
   Garrett M, 2019, HEARING RES, V380, P150, DOI 10.1016/j.heares.2019.07.001
   Gatehouse S, 2014, INT J AUDIOL, V43, P85
   Ghitza O, 2001, J ACOUST SOC AM, V110, P1628, DOI 10.1121/1.1396325
   Gleich O, 2016, EXP GERONTOL, V84, P61, DOI 10.1016/j.exger.2016.08.011
   Gockel HE, 2015, JARO-J ASSOC RES OTO, V16, P747, DOI 10.1007/s10162-015-0533-9
   Goman AM, 2016, AM J PUBLIC HEALTH, V106, P1820, DOI 10.2105/AJPH.2016.303299
   Gordon-Salant S, 2016, EAR HEARING, V37, P593, DOI 10.1097/AUD.0000000000000316
   Guest H, 2019, HEARING RES, V375, P34, DOI 10.1016/j.heares.2019.01.018
   Guinan JJ, 2003, JARO-J ASSOC RES OTO, V4, P521, DOI 10.1007/s10162-002-3037-3
   Haywood NR, 2015, TRENDS HEAR, V19, DOI 10.1177/2331216515619039
   Henry KS, 2019, J NEUROSCI, V39, P6879, DOI 10.1523/JNEUROSCI.0038-19.2019
   Henry KS, 2013, HEARING RES, V303, P39, DOI 10.1016/j.heares.2013.01.014
   Hind SE, 2011, INT J AUDIOL, V50, P708, DOI 10.3109/14992027.2011.582049
   Hopkins K, 2008, J ACOUST SOC AM, V123, P1140, DOI 10.1121/1.2824018
   Hopkins K, 2009, J ACOUST SOC AM, V125, P442, DOI 10.1121/1.3037233
   Jasmin K, 2020, J EXP PSYCHOL GEN, V149, P914, DOI 10.1037/xge0000688
   Jin SH, 2010, J ACOUST SOC AM, V128, P881, DOI 10.1121/1.3458851
   Johannesen PT, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516641055
   Johnson TA, 2017, J AM ACAD AUDIOL, V28, P14, DOI 10.3766/jaaa.15070
   JORIS PX, 1992, J ACOUST SOC AM, V91, P215, DOI 10.1121/1.402757
   King A, 2019, J ACOUST SOC AM, V145, P2277, DOI 10.1121/1.5094344
   Koelewijn T, 2015, HEARING RES, V323, P81, DOI 10.1016/j.heares.2015.02.004
   Koelewijn T, 2012, EAR HEARING, V33, P291, DOI 10.1097/AUD.0b013e3182310019
   Kujawa SG, 2009, J NEUROSCI, V29, P14077, DOI 10.1523/JNEUROSCI.2845-09.2009
   Le Prell CG, 2013, J AM ACAD AUDIOL, V24, P725, DOI 10.3766/jaaa.24.8.9
   Leger AC, 2012, HEARING RES, V294, P95, DOI 10.1016/j.heares.2012.10.002
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Liberman MC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162726
   Lichtenhan JT, 2014, JARO-J ASSOC RES OTO, V15, P395, DOI 10.1007/s10162-014-0447-y
   Lim SJ, 2019, P NATL ACAD SCI USA, V116, P4671, DOI 10.1073/pnas.1811992116
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P582, DOI 10.1093/gerona/glr002
   Lopez-Poveda EA, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517730526
   Lopez-Poveda EA, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00124
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Lorenzi C, 2009, J ACOUST SOC AM, V125, P27, DOI 10.1121/1.2939125
   Lu K, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms13900
   Maddox RK, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0441-17.2018
   Makary CA, 2011, JARO-J ASSOC RES OTO, V12, P711, DOI 10.1007/s10162-011-0283-2
   Mandelblat-Cerf Y, 2014, ELIFE, V3, DOI 10.7554/eLife.02152
   McAlpine D, 2016, ADV EXP MED BIOL, V894, P197, DOI 10.1007/978-3-319-25474-6_21
   Mehraei G, 2014, J ACOUST SOC AM, V136, P301, DOI 10.1121/1.4881918
   Mehrparvar AH, 2011, NOISE HEALTH, V13, P402, DOI 10.4103/1463-1741.90295
   Mesgarani N, 2008, J ACOUST SOC AM, V123, P899, DOI 10.1121/1.2816572
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Michalka SW, 2015, NEURON, V87, P882, DOI 10.1016/j.neuron.2015.07.028
   Mohrle D, 2016, NEUROBIOL AGING, V44, P173, DOI 10.1016/j.neurobiolaging.2016.05.001
   Moore BCJ, 2002, J ACOUST SOC AM, V111, P327, DOI 10.1121/1.1424871
   Moore BCJ, 2014, AUDITORY PROCESSING OF TEMPORAL FINE STRUCTURE: EFFECTS OF AGE AND HEARING LOSS, P1, DOI 10.1142/9064
   MOORE BCJ, 1987, J ACOUST SOC AM, V82, P69, DOI 10.1121/1.395439
   Moore BCJ, 1996, J ACOUST SOC AM, V100, P2320, DOI 10.1121/1.417941
   MOORE BCJ, 1995, J ACOUST SOC AM, V97, P2468, DOI 10.1121/1.411967
   Moore BCJ, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216519853963
   Moore JM, 2019, NAT NEUROSCI, V22, P1469, DOI 10.1038/s41593-019-0458-4
   Narayan R, 2007, NAT NEUROSCI, V10, P1601, DOI 10.1038/nn2009
   Newman CW, 1996, ARCH OTOLARYNGOL, V122, P143
   O'Sullivan JA, 2015, CEREB CORTEX, V25, P1697, DOI 10.1093/cercor/bht355
   Ohlenforst B, 2017, EAR HEARING, V38, P267, DOI 10.1097/AUD.0000000000000396
   Paraouty N, 2018, J NEUROSCI, V38, P4123, DOI 10.1523/JNEUROSCI.2107-17.2018
   Paraouty N, 2016, J ACOUST SOC AM, V140, P121, DOI 10.1121/1.4955078
   Parthasarathy A, 2019, NEUROBIOL AGING, V73, P30, DOI 10.1016/j.neurobiolaging.2018.08.023
   Parthasarathy A, 2018, J NEUROSCI, V38, P7108, DOI 10.1523/JNEUROSCI.3240-17.2018
   Parthasarathy A, 2016, JARO-J ASSOC RES OTO, V17, P119, DOI 10.1007/s10162-016-0554-z
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   Peelle JE, 2018, EAR HEARING, V39, P204, DOI 10.1097/AUD.0000000000000494
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Presacco A, 2016, J NEUROPHYSIOL, V116, P2356, DOI 10.1152/jn.00373.2016
   Qin MK, 2003, J ACOUST SOC AM, V114, P446, DOI 10.1121/1.1579009
   Ross B, 2007, J NEUROSCI, V27, P11172, DOI 10.1523/JNEUROSCI.1813-07.2007
   Ruggles D, 2012, CURR BIOL, V22, P1417, DOI 10.1016/j.cub.2012.05.025
   Ruggles D, 2011, P NATL ACAD SCI USA, V108, P15516, DOI 10.1073/pnas.1108912108
   Sarro EC, 2008, CEREB CORTEX, V18, P2855, DOI 10.1093/cercor/bhn044
   SEK A, 1995, J ACOUST SOC AM, V97, P2479, DOI 10.1121/1.411968
   Shaheen LA, 2015, JARO-J ASSOC RES OTO, V16, P727, DOI 10.1007/s10162-015-0539-3
   Shamma SA, 2011, TRENDS NEUROSCI, V34, P114, DOI 10.1016/j.tins.2010.11.002
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   SHERA CA, 1993, J ACOUST SOC AM, V93, P3333, DOI 10.1121/1.405717
   Shinn-Cunningham B, 2017, SPRINGER HANDB AUDIT, V60, P7, DOI 10.1007/978-3-319-51662-2_2
   Song K, 2014, J NEUROSCI, V34, P4837, DOI 10.1523/JNEUROSCI.4856-13.2014
   Strelcyk O, 2009, J ACOUST SOC AM, V125, P3328, DOI 10.1121/1.3097469
   Teki S, 2013, ELIFE, V2, DOI 10.7554/eLife.00699
   Undurraga JA, 2016, JARO-J ASSOC RES OTO, V17, P591, DOI 10.1007/s10162-016-0584-6
   Valero MD, 2017, HEARING RES, V353, P213, DOI 10.1016/j.heares.2017.07.003
   Viana LM, 2015, HEARING RES, V327, P78, DOI 10.1016/j.heares.2015.04.014
   Wallaert N, 2018, J ACOUST SOC AM, V144, P720, DOI 10.1121/1.5049364
   Wang Y, 2018, EAR HEARING, V39, P573, DOI 10.1097/AUD.0000000000000512
   Whiteford KL, 2017, JARO-J ASSOC RES OTO, V18, P619, DOI 10.1007/s10162-017-0624-x
   Whiteford KL, 2015, J ACOUST SOC AM, V138, P3093, DOI 10.1121/1.4935018
   Whitton JP, 2017, CURR BIOL, V27, P3237, DOI 10.1016/j.cub.2017.09.014
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
   Winn MB, 2015, EAR HEARING, V36, pe153, DOI 10.1097/AUD.0000000000000145
   Wu PZ, 2019, NEUROSCIENCE, V407, P8, DOI 10.1016/j.neuroscience.2018.07.053
   Zekveld AA, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518777174
   Zekveld AA, 2014, NEUROIMAGE, V101, P76, DOI 10.1016/j.neuroimage.2014.06.069
   Zekveld AA, 2014, PSYCHOPHYSIOLOGY, V51, P277, DOI 10.1111/psyp.12151
   Zekveld AA, 2010, EAR HEARING, V31, P480, DOI 10.1097/AUD.0b013e3181d4f251
   Zeng FG, 2005, P NATL ACAD SCI USA, V102, P2293, DOI 10.1073/pnas.0406460102
NR 119
TC 9
Z9 9
U1 1
U2 4
PU ELIFE SCIENCES PUBLICATIONS LTD
PI CAMBRIDGE
PA SHERATON HOUSE, CASTLE PARK, CAMBRIDGE, CB3 0AX, ENGLAND
SN 2050-084X
J9 ELIFE
JI eLife
PD JAN 21
PY 2020
VL 9
AR e51419
DI 10.7554/eLife.51419
PG 22
WC Biology
SC Life Sciences & Biomedicine - Other Topics
GA KE5KE
UT WOS:000508593700001
PM 31961322
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Miranda, L
   Swerts, M
   Moraes, J
   Rilliard, A
AF Miranda, Luma
   Swerts, Marc
   Moraes, Joao
   Rilliard, Albert
TI The Role of the Auditory and Visual Modalities in the Perceptual
   Identification of Brazilian Portuguese Statements and Echo Questions
SO LANGUAGE AND SPEECH
LA English
DT Article; Early Access
DE Audiovisual perception; prosody; statement; echo question; Brazilian
   Portuguese
ID PROSODIC PROMINENCE; SPEECH; CUES
AB This paper presents the results of three perceptual experiments investigating the role of auditory and visual channels for the identification of statements and echo questions in Brazilian Portuguese. Ten Brazilian speakers (five male) were video-recorded (frontal view of the face) while they produced a sentence ("Como voce sabe"), either as a statement (meaning "As you know.") or as an echo question (meaning "As you know?"). Experiments were set up including the two different intonation contours. Stimuli were presented in conditions with clear and degraded audio as well as congruent and incongruent information from both channels. Results show that Brazilian listeners were able to distinguish statements and questions prosodically and visually, with auditory cues being dominant over visual ones. In noisy conditions, the visual channel improved the interpretation of prosodic cues robustly, while it degraded them in conditions where the visual information was incongruent with the auditory information. This study shows that auditory and visual information are integrated during speech perception, also when applied to prosodic patterns.
C1 [Miranda, Luma; Moraes, Joao; Rilliard, Albert] Univ Fed Rio de Janeiro, Lab Acoust Phonet, Rio De Janeiro, Brazil.
   [Swerts, Marc] Tilburg Univ, Dept Commun & Cognit, Tilburg, Netherlands.
   [Rilliard, Albert] Univ Paris Saclay, CNRS, LIMSI, St Aubin, France.
RP Miranda, L (corresponding author), Univ Fed Rio de Janeiro, Lab Acoust Phonet, Rio De Janeiro, Brazil.
EM lumah.miranda@gmail.com
RI da Silva Miranda, Luma/AAB-9155-2020
OI da Silva Miranda, Luma/0000-0002-5529-0338; swerts,
   marc/0000-0002-4367-641X
FU Brazilian Federal Agency for Support and Evaluation of Graduate
   Education-CAPESCAPES [88881.134778/2016-01]
FX This research has been funded by the scholarship 88881.134778/2016-01
   (awarded by the Brazilian Federal Agency for Support and Evaluation of
   Graduate Education-CAPES) through a PhD exchange program which allowed
   the first author to organize a research visit to Tilburg University
   (NL).
CR [Anonymous], 2016, VEG PROS VERS 14 VEG
   Arantes P., 2015, COURSES SPEECH PROSO, P98
   Barbosa P., 2013, P TOOLS RES AN SPEEC, P86
   Barkhuysen P, 2010, LANG SPEECH, V53, P3, DOI 10.1177/0023830909348993
   Benoit C, 1998, SPEECH COMMUN, V26, P117, DOI 10.1016/S0167-6393(98)00045-4
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Borras-Comes J., 2011, J LAB PHONOLOGY, V2, P355, DOI DOI 10.1515/LABPH0N.2011.013
   Cave C., 1996, P ICSLP 96, DOI 10.1109/ICSLP.1996.607235
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   Costa Maristela Julio, 2011, Rev. CEFAC, V13, P685, DOI 10.1590/s1516-18462010005000114
   Couto LR, 2017, REV ESTUD LING, V25, P1105, DOI 10.17851/2237-2083.25.3.1105-1142
   Sendra VC, 2013, J PRAGMATICS, V47, P1, DOI 10.1016/j.pragma.2012.08.008
   Cruz M., 2015, P 18 INT C PHON SCI
   Cruz M, 2017, LAB PHONOL, V8, DOI 10.5334/labphon.110
   Debras C, 2017, GESTURE, V16, P1, DOI 10.1075/gest.16.1.01deb
   Dohen M, 2009, LANG SPEECH, V52, P177, DOI 10.1177/0023830909103166
   Ekman P, 2002, FACIAL ACTION CODING
   FISHER CG, 1969, J SPEECH HEAR RES, V12, P379, DOI 10.1044/jshr.1202.379
   Fitzpatrick M, 2015, SPEECH COMMUN, V74, P37, DOI 10.1016/j.specom.2015.08.001
   Frota S, 2015, INTONATION ROMANCE, P235, DOI DOI 10.1093/ACPROF:OSO/9780199685332.003.0007
   Geronimo Miranda L., 2015, THESIS
   Gili Fivela B, 2018, STUDIES LAB PHONOLOG, V4, P83
   Graf HP, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P396, DOI 10.1109/AFGR.2002.1004186
   Granstrom B., 2002, P SPEECH PROS 2002 C, P347
   HADAR U, 1983, LANG SPEECH, V26, P117, DOI 10.1177/002383098302600202
   Hirst Daniel, 1993, TRAVAUX DE LINSTITUT, V15, P75
   House D., 2002, P 7 INT C SPOK LANG, P1957
   Husson F., 2017, EXPLORATORY MULTIVAR
   Kim J, 2011, PERCEPTION, V40, P853, DOI 10.1068/p6941
   KRAHMER E, 2002, P SPEECH PROS 2002 A, P443
   Krahmer E, 2007, J MEM LANG, V57, P396, DOI 10.1016/j.jml.2007.06.005
   Lambrecht Knud, 1994, INFORM STRUCTURE SEN
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   MASSARO DW, 1983, J EXP PSYCHOL HUMAN, V9, P753, DOI 10.1037/0096-1523.9.5.753
   Mauro Morais J, 2008, P SPEECH PROS 2008 C, P389
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Miranda L. S., 2019, P 19 INT C PHON SCI, P2941
   Moraes J. A., 2012, P 7 GSCP INT C SPEEC, P157
   Moraes Joao Antonio de, 1998, INTONATION SYSTEMS S, P179
   Nicholson KG, 2003, BRAIN COGNITION, V52, P382, DOI 10.1016/S0278-2626(03)00182-9
   Ouni S, 2007, EURASIP J AUDIO SPEE, DOI 10.1155/2007/47891
   Peres D. O., 2011, P 5 C LAB APPR ROM P, P136
   Pierrehumbert J., 1980, THESIS
   Qualtrics, 2019, QUALTRICS
   Rosenblum LD, 2005, BLACKW HBK LINGUIST, P51, DOI 10.1002/9780470757024.ch3
   Srinivasan RJ, 2003, LANG SPEECH, V46, P1, DOI 10.1177/00238309030460010201
   Steeneken H. J., 1988, 19883 IZF TNO I PERC
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Swerts M, 2008, J PHONETICS, V36, P219, DOI 10.1016/j.wocn.2007.05.001
   Torreira F, 2015, PHONETICA, V72, P20, DOI 10.1159/000381723
   Tubau S, 2015, LINGUIST REV, V32, P115, DOI 10.1515/tlr-2014-0016
   Vatikiotis-Bateson E., 2007, P AVSP 07 HILV NETH, P45
NR 52
TC 0
Z9 0
U1 0
U2 2
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
AR 0023830919898886
DI 10.1177/0023830919898886
EA JAN 2020
PG 21
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA KE4HJ
UT WOS:000508518100001
PM 31957542
DA 2021-02-24
ER

PT J
AU Wedekind, A
   Rajan, G
   Van Dun, B
   Tavora-Vieira, D
AF Wedekind, Andre
   Rajan, Gunesh
   Van Dun, Bram
   Tavora-Vieira, Dayse
TI Restoration of cortical symmetry and binaural function: Cortical
   auditory evoked responses in adult cochlear implant users with single
   sided deafness
SO PLOS ONE
LA English
DT Article
ID UNILATERAL DEAFNESS; HEARING-LOSS; POTENTIALS; CHILDREN; TINNITUS;
   RECOGNITION; DEPRIVATION; SENSITIVITY; PERCEPTION; OUTCOMES
AB Background
   Cochlear implantation for single-sided deafness (SSD) is the only treatment option with the potential to restore binaural hearing cues. Significant binaural benefit has been measured in adults by speech in noise and localisation tests, who receive a cochlear implant for SSD, however, little is known on the cortical changes that help provide this benefit. In the present study, detection of sound in the auditory cortex, speech testing and localisation was used to investigate the ability of a cochlear implant (CI) to restore auditory cortical latencies and improve binaural benefit in the adult SSD population.
   Methods
   Twenty-nine adults with acquired single-sided deafness who received a CI in adulthood were studied. Speech perception in noise was tested using the Bamford-Kowal-Bench speech-in-noise test, localisation ability was measured using the auditory speech sounds evaluation (AdE) localisation test and cortical auditory evoked responses, comparing N1-P2 latencies recorded from the normal hearing ear and cochlear implant were used to investigate the synchrony of the cortical pathway from the CI and normal hearing ear (NHe) with binaural hearing function.
   Results
   There was a significant improvement in speech perception in noise in all spatial configurations S0/N0 (Z =-3.066, p< 0.002), S0/NHE (Z =-4.031, p< 0.001), SCI/NHE (Z =-3.851, p< 0.001). Localization significantly improved when tested with the cochlear implant on (p< 0.001) with a shorter duration of deafness correlating to a greater improvement in localisation ability F(1:18) = 6.854; p = 0.017). There was no significant difference in N1-P2 latency recorded from the normal hearing ear and the CI.
   Conclusion
   Cortical auditory evoked response latencies recorded from the CI and NHe showed no significant difference, indicating that the detection of sound in the auditory cortex occurred simultaneously, providing the cortex with auditory information for binaural hearing.
C1 [Wedekind, Andre; Rajan, Gunesh; Tavora-Vieira, Dayse] Univ Western Australia, Otolaryngol Head & Neck Surg, Sch Surg, Perth, WA, Australia.
   [Wedekind, Andre; Tavora-Vieira, Dayse] Fiona Stanley Hosp, Perth, WA, Australia.
   [Rajan, Gunesh] Luzerner Kantonsspital, Dept Otolaryngol Head & Neck Surg, Luzern, Switzerland.
   [Van Dun, Bram] Natl Acoust Labs, Sydney, NSW, Australia.
RP Wedekind, A (corresponding author), Univ Western Australia, Otolaryngol Head & Neck Surg, Sch Surg, Perth, WA, Australia.; Wedekind, A (corresponding author), Fiona Stanley Hosp, Perth, WA, Australia.
EM andre.wedekind@gmail.com
OI Tavora-Vieira, Dayse/0000-0001-6249-7268
CR Arndt S, 2017, HNO, V65, P98, DOI 10.1007/s00106-016-0297-5
   Arndt S, 2011, OTOL NEUROTOL, V32, P39, DOI 10.1097/MAO.0b013e3181fcf271
   Arsenault MD, 1999, J ACOUST SOC AM, V105, P1821, DOI 10.1121/1.426720
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   Blamey P, 1996, Audiol Neurootol, V1, P293
   Boisvert I, 2012, NEUROREPORT, V23, P195, DOI 10.1097/WNR.0b013e32834fab4b
   Boisvert I, 2011, EAR HEARING, V32, P758, DOI 10.1097/AUD.0b013e3182234c45
   BRUGGE JF, 1988, HEARING RES, V34, P127, DOI 10.1016/0378-5955(88)90100-1
   Buechner A, 2010, OTOL NEUROTOL, V31, P1381, DOI 10.1097/MAO.0b013e3181e3d353
   Carter L, 2013, J AM ACAD AUDIOL, V24, P807, DOI 10.3766/jaaa.24.9.5
   de Heyning PV, 2008, ANN OTO RHINOL LARYN, V117, P645, DOI 10.1177/000348940811700903
   Dillon H, 2002, HEARING AIDS
   Firszt JB, 2012, OTOL NEUROTOL, V33, P1339, DOI 10.1097/MAO.0b013e318268d52d
   Francis HW, 2005, EAR HEARING, V26, p7S, DOI 10.1097/00003446-200508001-00003
   Friedland DR, 2003, OTOL NEUROTOL, V24, P582, DOI 10.1097/00129492-200307000-00009
   Friedmann DR, 2016, OTOL NEUROTOL, V37, pE154, DOI 10.1097/MAO.0000000000000951
   Gilley PM, 2005, CLIN NEUROPHYSIOL, V116, P648, DOI 10.1016/j.clinph.2004.09.009
   Golding M, 2009, DETECTION ADULT CORT
   Grantham DW, 2007, EAR HEARING, V28, P524, DOI 10.1097/AUD.0b013e31806dc21a
   Groenen PAP, 2001, SCAND AUDIOL, V30, P31, DOI 10.1080/010503901750069554
   Han JH, 2016, CLIN NEUROPHYSIOL, V127, P1603, DOI 10.1016/j.clinph.2015.10.049
   Hawley ML, 2004, J ACOUST SOC AM, V115, P833, DOI 10.1121/1.1639908
   Kelly AS, 2005, CLIN NEUROPHYSIOL, V116, P1235, DOI 10.1016/j.clinph.2005.02.011
   Kosaner J, 2018, INT J PEDIATR OTORHI, V108, P100, DOI 10.1016/j.ijporl.2018.02.033
   Kral A, 2015, AUDIOL NEURO-OTOL, V20, P7, DOI 10.1159/000380742
   Legris E, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204402
   Litovsky RY, 2018, HEARING RES
   Palau EM, 2010, ACTA OTORRINOLAR ESP, V61, P405, DOI 10.1016/j.otorri.2010.07.001
   Mertens G, 2017, EAR HEARING, V38, P117, DOI 10.1097/AUD.0000000000000359
   Pantev C, 2006, CEREB CORTEX, V16, P31, DOI 10.1093/cercor/bhi081
   Prejban DA, 2018, OTOL NEUROTOL, V39, pE803, DOI 10.1097/MAO.0000000000001963
   Punte Andrea Kleine, 2011, Cochlear Implants Int, V12 Suppl 1, pS26, DOI 10.1179/146701011X13001035752336
   Purdy SC, 2016, SEM HEAR
   Rahne T, 2016, OTOL NEUROTOL, V37, pE332, DOI 10.1097/MAO.0000000000000971
   Ramos A, 2012, ACTA OTORRINOLAR ESP, V63, P15, DOI 10.1016/j.otorri.2011.07.004
   Sandmann P, 2015, CLIN NEUROPHYSIOL, V126, P594, DOI 10.1016/j.clinph.2014.06.029
   Stelzig Yvonne, 2011, J Med Case Rep, V5, P343, DOI 10.1186/1752-1947-5-343
   Tavora-Vieira D, 2019, OTOLOGY NEUROTOLOGY
   Tavora-Vieira D, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193081
   Tavora-Vieira D, 2015, EAR HEARING, V36, pE93, DOI 10.1097/AUD.0000000000000130
   Tavora-Vieira D, 2015, OTOL NEUROTOL, V36, P430, DOI 10.1097/MAO.0000000000000707
   Tavora-Vieira D, 2015, OTOL NEUROTOL, V36, P235, DOI 10.1097/MAO.0000000000000677
   Tavora-Vieira D, 2013, NEUROREPORT, V24, P724, DOI 10.1097/WNR.0b013e3283642a93
   Timm L, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0045375
   Tong YX, 2009, BRAIN RES, V1297, P80, DOI 10.1016/j.brainres.2009.07.089
   Tremblay KL, 2009, CLIN NEUROPHYSIOL, V120, P128, DOI 10.1016/j.clinph.2008.10.005
   Tremblay KL, 2002, J SPEECH LANG HEAR R, V45, P564, DOI 10.1044/1092-4388(2002/045)
   Vermeire K, 2009, AUDIOL NEURO-OTOL, V14, P163, DOI 10.1159/000171478
NR 48
TC 0
Z9 0
U1 0
U2 1
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD JAN 14
PY 2020
VL 15
IS 1
AR e0227371
DI 10.1371/journal.pone.0227371
PG 15
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA LP5JP
UT WOS:000534354100017
PM 31935234
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Jenson, D
   Bowers, AL
   Hudock, D
   Saltuklaroglu, T
AF Jenson, David
   Bowers, Andrew L.
   Hudock, Daniel
   Saltuklaroglu, Tim
TI The Application of EEG Mu Rhythm Measures to Neurophysiological Research
   in Stuttering
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE stuttering; mu rhythm; sensorimotor integration; speech production;
   speech perception; working memory; internal models; basal ganglia
ID BETA-BAND OSCILLATIONS; NONWORD REPETITION; WORKING-MEMORY; SENSORIMOTOR
   INTEGRATION; PRESCHOOL-CHILDREN; INDIVIDUAL-DIFFERENCES; SOURCE
   LOCALIZATION; NEURONAL-ACTIVITY; PHONEME ELISION; PREMOTOR CORTEX
AB Deficits in basal ganglia-based inhibitory and timing circuits along with sensorimotor internal modeling mechanisms are thought to underlie stuttering. However, much remains to be learned regarding the precise manner how these deficits contribute to disrupting both speech and cognitive functions in those who stutter. Herein, we examine the suitability of electroencephalographic (EEG) mu rhythms for addressing these deficits. We review some previous findings of mu rhythm activity differentiating stuttering from non-stuttering individuals and present some new preliminary findings capturing stuttering-related deficits in working memory. Mu rhythms are characterized by spectral peaks in alpha (8-13 Hz) and beta (14-25 Hz) frequency bands (mu-alpha and mu-beta). They emanate from premotor/motor regions and are influenced by basal ganglia and sensorimotor function. More specifically, alpha peaks (mu-alpha) are sensitive to basal ganglia-based inhibitory signals and sensory-to-motor feedback. Beta peaks (mu-beta) are sensitive to changes in timing and capture motor-to-sensory (i.e., forward model) projections. Observing simultaneous changes in mu-alpha and mu-beta across the time-course of specific events provides a rich window for observing neurophysiological deficits associated with stuttering in both speech and cognitive tasks and can provide a better understanding of the functional relationship between these stuttering symptoms. We review how independent component analysis (ICA) can extract mu rhythms from raw EEG signals in speech production tasks, such that changes in alpha and beta power are mapped to myogenic activity from articulators. We review findings from speech production and auditory discrimination tasks demonstrating that mu-alpha and mu-beta are highly sensitive to capturing sensorimotor and basal ganglia deficits associated with stuttering with high temporal precision. Novel findings from a non-word repetition (working memory) task are also included. They show reduced mu-alpha suppression in a stuttering group compared to a typically fluent group. Finally, we review current limitations and directions for future research.
C1 [Jenson, David] Washington State Univ, Dept Speech & Hearing Sci, Elson S Floyd Coll Med, Spokane, WA USA.
   [Bowers, Andrew L.] Univ Arkansas, Epley Ctr Hlth Profess Commun Sci & Disorders, Fayetteville, AR 72701 USA.
   [Hudock, Daniel] Idaho State Univ, Dept Commun Sci & Disorders, Pocatello, ID 83209 USA.
   [Saltuklaroglu, Tim] Univ Tennessee, Hlth Sci Ctr, Dept Audiol & Speech Pathol, Coll Hlth Profess, Knoxville, TN 37996 USA.
RP Saltuklaroglu, T (corresponding author), Univ Tennessee, Hlth Sci Ctr, Dept Audiol & Speech Pathol, Coll Hlth Profess, Knoxville, TN 37996 USA.
EM tsaltukl@uthsc.edu
OI Jenson, David/0000-0001-5744-0910
FU National Institute on Deafness and Other Communication Disorders of the
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R21 DC014506-01]
FX Portions of this work were supported by the National Institute on
   Deafness and Other Communication Disorders of the National Institutes of
   Health (R21 DC014506-01 awarded to TS). The content is solely the
   responsibility of the authors and does not necessarily represent the
   official views of the National Institutes of Health.
CR Alho J, 2012, NEUROIMAGE, V60, P1937, DOI 10.1016/j.neuroimage.2012.02.011
   Alm PA, 2004, J COMMUN DISORD, V37, P325, DOI 10.1016/j.jcomdis.2004.03.001
   ARMSON J, 1994, J SPEECH HEAR RES, V37, P69, DOI 10.1044/jshr.3701.69
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Arnold HS, 2011, J COMMUN DISORD, V44, P276, DOI 10.1016/j.jcomdis.2010.12.003
   Baddeley A, 2012, ANNU REV PSYCHOL, V63, P1, DOI 10.1146/annurev-psych-120710-100422
   Belyk M, 2017, EUR J NEUROSCI, V45, P622, DOI 10.1111/ejn.13512
   Belyk M, 2015, EUR J NEUROSCI, V41, P275, DOI 10.1111/ejn.12765
   Bigdely-Shamlo N, 2015, FRONT NEUROINFORM, V9, DOI 10.3389/fninf.2015.00016
   Block S., 1996, AUSTR J HUMAN COMMUN, V24, P11, DOI DOI 10.3109/ASL2.1996.24.ISSUE-1.02
   Bonstrup M, 2015, FRONT AGING NEUROSCI, V7, DOI 10.3389/fnagi.2015.00193
   Bowers A, 2019, EXP BRAIN RES, V237, P705, DOI 10.1007/s00221-018-5447-4
   Bowers A, 2018, J FLUENCY DISORD, V58, P94, DOI 10.1016/j.jfludis.2018.08.006
   Bowers A, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0072024
   Bowers AL, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00366
   Brinkman L, 2014, J NEUROSCI, V34, P14783, DOI 10.1523/JNEUROSCI.2039-14.2014
   Brismar T, 2007, PHYSIOL BEHAV, V92, P141, DOI 10.1016/j.physbeh.2007.05.047
   Buchsbaum BR, 2019, CORTEX, V112, P134, DOI 10.1016/j.cortex.2018.11.010
   Byrd CT, 2018, SEMIN SPEECH LANG, V39, P458, DOI 10.1055/s-0038-1670669
   Byrd CT, 2017, J COMMUN DISORD, V69, P94, DOI 10.1016/j.jcomdis.2017.06.009
   Byrd CT, 2015, J FLUENCY DISORD, V44, P17, DOI 10.1016/j.jfludis.2015.01.004
   Byrd CT, 2012, J FLUENCY DISORD, V37, P188, DOI 10.1016/j.jfludis.2012.03.003
   Callan D, 2010, NEUROIMAGE, V51, P844, DOI 10.1016/j.neuroimage.2010.02.027
   Carlqvist H, 2005, MED BIOL ENG COMPUT, V43, P599, DOI 10.1007/BF02351033
   Caviness JN, 2016, EUR J NEUROL, V23, P387, DOI 10.1111/ene.12878
   Chang CY, 2020, IEEE T BIO-MED ENG, V67, P1114, DOI 10.1109/TBME.2019.2930186
   Chang SE, 2019, NEUROSCIENTIST, V25, P566, DOI 10.1177/1073858418803594
   Chang SE, 2013, BRAIN, V136, P3709, DOI 10.1093/brain/awt275
   Cheveigne A, 2019, NEUROIMAGE, V186, P728, DOI [10.1016/j.neuroimage.2018.11.026, DOI 10.1016/J.NEUROIMAGE.2018.11.026]
   Cheyne DO, 2013, EXP NEUROL, V245, P27, DOI 10.1016/j.expneurol.2012.08.030
   Choo AL, 2016, J COMMUN DISORD, V61, P29, DOI 10.1016/j.jcomdis.2016.03.003
   Chow HM, 2017, HUM BRAIN MAPP, V38, P3345, DOI 10.1002/hbm.23590
   Civier O, 2010, J FLUENCY DISORD, V35, P246, DOI 10.1016/j.jfludis.2010.05.002
   Coalson GA, 2019, CLIN LINGUIST PHONET, V33, P256, DOI 10.1080/02699206.2018.1504988
   Coalson GA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188111
   Cogan GB, 2014, NATURE, V507, P94, DOI 10.1038/nature12935
   Cohen MX, 2015, INT J PSYCHOPHYSIOL, V97, P245, DOI 10.1016/j.ijpsycho.2014.09.013
   Connery A, 2020, DISABIL REHABIL, V42, P2232, DOI 10.1080/09638288.2018.1555623
   Cuellar M, 2016, CLIN NEUROPHYSIOL, V127, P2625, DOI 10.1016/j.clinph.2016.04.027
   D'Esposito M, 2007, PHILOS T R SOC B, V362, P761, DOI 10.1098/rstb.2007.2086
   Daliri A, 2018, CORTEX, V99, P55, DOI 10.1016/j.cortex.2017.10.019
   Daliri A, 2015, BRAIN LANG, V150, P37, DOI 10.1016/j.bandl.2015.08.008
   Dalla Volta R, 2018, CORTEX, V100, P95, DOI 10.1016/j.cortex.2017.09.012
   Dayan E, 2011, NEURON, V72, P443, DOI 10.1016/j.neuron.2011.10.008
   Delorme A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030135
   Delorme A, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/130714
   Denis D, 2017, NEUROIMAGE, V146, P1102, DOI 10.1016/j.neuroimage.2016.10.022
   Devor A, 2007, J NEUROSCI, V27, P4452, DOI 10.1523/JNEUROSCI.0134-07.2007
   Dillon DG, 2007, APPL PREV PSYCHOL, V12, P99, DOI 10.1016/j.appsy.2007.09.004
   Doyon J, 2005, CURR OPIN NEUROBIOL, V15, P161, DOI 10.1016/j.conb.2005.03.004
   Eggers K, 2017, J SPEECH LANG HEAR R, V60, P3159, DOI 10.1044/2017_JSLHR-S-16-0096
   Eggers K, 2013, J FLUENCY DISORD, V38, P1, DOI 10.1016/j.jfludis.2012.10.001
   Eggers K, 2012, J SPEECH LANG HEAR R, V55, P946, DOI 10.1044/1092-4388(2011/10-0208)
   Eichorn N, 2018, J FLUENCY DISORD, V57, P37, DOI 10.1016/j.jfludis.2017.11.001
   Engel AK, 2010, CURR OPIN NEUROBIOL, V20, P156, DOI 10.1016/j.conb.2010.02.015
   Etchell AC, 2016, NEUROIMAGE, V125, P953, DOI 10.1016/j.neuroimage.2015.10.086
   Ferree TC, 2001, CLIN NEUROPHYSIOL, V112, P536, DOI 10.1016/S1388-2457(00)00533-2
   Fiorin Michele, 2019, Braz J Otorhinolaryngol, DOI 10.1016/j.bjorl.2019.08.005
   Fox NA, 2016, PSYCHOL BULL, V142, P291, DOI 10.1037/bul0000031
   Fujioka T, 2015, J NEUROSCI, V35, P15187, DOI 10.1523/JNEUROSCI.2397-15.2015
   GASTAUT HJ, 1954, ELECTROEN CLIN NEURO, V6, P433, DOI 10.1016/0013-4694(54)90058-9
   Gehrig J, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00169
   Goense J, 2012, NEURON, V76, P629, DOI 10.1016/j.neuron.2012.09.019
   Hari R, 1997, INT J PSYCHOPHYSIOL, V26, P51, DOI 10.1016/S0167-8760(97)00755-1
   Hari R, 2006, PROG BRAIN RES, V159, P253, DOI 10.1016/S0079-6123(06)59017-X
   Heald SLM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00035
   Herman AB, 2013, J NEUROSCI, V33, P5439, DOI 10.1523/JNEUROSCI.1472-12.2013
   Hickok G, 2003, J COGNITIVE NEUROSCI, V15, P673, DOI 10.1162/089892903322307393
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Hobson HM, 2016, CORTEX, V82, P290, DOI 10.1016/j.cortex.2016.03.019
   Houde JF, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00082
   Howell P., 2002, CURRENT ISSUES LINGU
   Jensen O, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00186
   Jenson D, 2019, NEUROBIOL LEARN MEM, V166, DOI 10.1016/j.nlm.2019.107098
   Jenson D, 2018, NEUROIMAGE-CLIN, V19, P690, DOI 10.1016/j.nicl.2018.05.026
   Jenson D, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00534
   Jenson D, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00656
   Jones SR, 2009, J NEUROPHYSIOL, V102, P3554, DOI 10.1152/jn.00535.2009
   Joos K, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00783
   Jurkiewicz MT, 2006, NEUROIMAGE, V32, P1281, DOI 10.1016/j.neuroimage.2006.06.005
   Kell CA, 2009, BRAIN, V132, P2747, DOI 10.1093/brain/awp185
   Kikuchi Y, 2011, NEUROIMAGE, V55, P891, DOI 10.1016/j.neuroimage.2010.12.083
   Kittilstved T, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00126
   Korik A, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00130
   Leske S, 2019, NEUROIMAGE, V189, P763, DOI 10.1016/j.neuroimage.2019.01.026
   Li T, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00381
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Loucks TMJ, 2006, NEUROSCI LETT, V402, P195, DOI 10.1016/j.neulet.2006.04.002
   Majerus S, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00357
   Mandel A, 2016, NEUROSCI LETT, V614, P99, DOI 10.1016/j.neulet.2015.12.054
   Markiewicz CJ, 2016, NEUROIMAGE, V141, P174, DOI 10.1016/j.neuroimage.2016.07.023
   Max L, 2004, CONT ISSUES COMMUN S, V31, P105, DOI [10.1044/cicsd_31_S_105., DOI 10.1044/CICSD_31_S_105]
   McFarland DJ, 2000, BRAIN TOPOGR, V12, P177, DOI 10.1023/A:1023437823106
   McGettigan C, 2011, J COGNITIVE NEUROSCI, V23, P961, DOI 10.1162/jocn.2010.21491
   Megevand P, 2014, J NEUROL NEUROSUR PS, V85, P38, DOI 10.1136/jnnp-2013-305515
   Mersov A, 2018, J FLUENCY DISORD, V55, P145, DOI 10.1016/j.jfludis.2017.05.003
   Mersov AM, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00443
   Mock JR, 2016, CLIN NEUROPHYSIOL, V127, P3093, DOI 10.1016/j.clinph.2016.06.005
   Myers J., 2018, IEEE INT C SYST MAN
   Namasivayam AK, 2011, J MOTOR BEHAV, V43, P477, DOI 10.1080/00222895.2011.628347
   Neef NE, 2012, J SPEECH LANG HEAR R, V55, P276, DOI 10.1044/1092-4388(2011/10-0224)
   Neumann K, 2005, J FLUENCY DISORD, V30, P23, DOI 10.1016/j.jfludis.2004.12.002
   Neuper C, 2001, INT J PSYCHOPHYSIOL, V43, P41, DOI 10.1016/S0167-8760(01)00178-7
   Neuper C, 2006, PROG BRAIN RES, V159, P211, DOI 10.1016/S0079-6123(06)59014-4
   Ning N, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168836
   Nystrom P, 2008, SOC NEUROSCI-UK, V3, P334, DOI 10.1080/17470910701563665
   Ofoe LC, 2018, J SPEECH LANG HEAR R, V61, P1626, DOI 10.1044/2018_JSLHR-S-17-0372
   Onton J, 2006, NEUROSCI BIOBEHAV R, V30, P808, DOI 10.1016/j.neubiorev.2006.06.007
   Palmer C, 2016, TRENDS COGN SCI, V20, P321, DOI 10.1016/j.tics.2016.03.007
   Papagiannopoulou EA, 2016, FRONT PEDIATR, V4, DOI 10.3389/fped.2016.00011
   Pelczarski KM, 2016, J COMMUN DISORD, V62, P54, DOI 10.1016/j.jcomdis.2016.05.006
   Perrachione TK, 2017, J SPEECH LANG HEAR R, V60, P1959, DOI 10.1044/2017_JSLHR-L-15-0446
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   Pineda JA, 2005, BRAIN RES REV, V50, P57, DOI 10.1016/j.brainresrev.2005.04.005
   POSTMA A, 1993, J SPEECH HEAR RES, V36, P472, DOI 10.1044/jshr.3603.472
   Preibisch C, 2003, NEUROIMAGE, V20, P1356, DOI 10.1016/S1053-8119(03)00376-8
   Riley G., 2009, STUTTERING SEVERITY
   RILEY GD, 1972, J SPEECH HEAR DISORD, V37, P314, DOI 10.1044/jshd.3703.314
   Ritter P, 2009, HUM BRAIN MAPP, V30, P1168, DOI 10.1002/hbm.20585
   Rizzolatti G, 1998, TRENDS NEUROSCI, V21, P188, DOI 10.1016/S0166-2236(98)01260-0
   Saltuklaroglu T, 2018, SOC NEUROBIOLOGY LAN
   Saltuklaroglu T, 2018, BRAIN LANG, V187, P41, DOI 10.1016/j.bandl.2018.09.005
   Saltuklaroglu T, 2017, NEUROIMAGE, V153, P232, DOI 10.1016/j.neuroimage.2017.04.022
   Schneider D, 2017, NEUROIMAGE, V162, P73, DOI 10.1016/j.neuroimage.2017.08.057
   Schroger E, 2015, EUR J NEUROSCI, V41, P641, DOI 10.1111/ejn.12816
   Sengupta R, 2017, PHYSIOL REP, V5, DOI 10.14814/phy2.13194
   Smith A, 2017, J SPEECH LANG HEAR R, V60, P2483, DOI 10.1044/2017_JSLHR-S-16-0343
   Smith A, 2012, J FLUENCY DISORD, V37, P344, DOI 10.1016/j.jfludis.2012.06.001
   Smith A, 2010, J FLUENCY DISORD, V35, P1, DOI 10.1016/j.jfludis.2009.12.001
   Sohrabpour A, 2015, CLIN NEUROPHYSIOL, V126, P472, DOI 10.1016/j.clinph.2014.05.038
   Song J, 2015, J NEUROSCI METH, V256, P9, DOI 10.1016/j.jneumeth.2015.08.015
   Spencer C, 2014, J FLUENCY DISORD, V41, P32, DOI 10.1016/j.jfludis.2014.06.001
   Stolk A, 2019, ELIFE, V8, DOI 10.7554/eLife.48065
   Stone JV, 2002, TRENDS COGN SCI, V6, P59, DOI 10.1016/S1364-6613(00)01813-1
   Szenkovits G, 2012, NEUROPSYCHOLOGIA, V50, P1380, DOI 10.1016/j.neuropsychologia.2012.02.023
   Tan HL, 2014, J NEUROSCI, V34, P5678, DOI 10.1523/JNEUROSCI.4739-13.2014
   Tan X, 2012, FRONT HUM NEUROSCI, V6, DOI [10.3389/fnhum.2012.00305, 10.3389/fnhum.2012.00314]
   Taniguchi M, 2000, NEUROIMAGE, V12, P298, DOI 10.1006/nimg.2000.0611
   Thornton D, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-36775-5
   Thornton D, 2018, BRAIN LANG, V187, P62, DOI 10.1016/j.bandl.2017.03.011
   Thorpe SG, 2016, CLIN NEUROPHYSIOL, V127, P254, DOI 10.1016/j.clinph.2015.03.004
   Tian X, 2016, CORTEX, V77, P1, DOI 10.1016/j.cortex.2016.01.002
   Tian X, 2013, J COGNITIVE NEUROSCI, V25, P1020, DOI 10.1162/jocn_a_00381
   Tian X, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00166
   TIIHONEN J, 1989, NEUROSCIENCE, V32, P793, DOI 10.1016/0306-4522(89)90299-6
   Torrecillos F, 2015, J NEUROSCI, V35, P12753, DOI 10.1523/JNEUROSCI.1090-15.2015
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   Usler E, 2015, J NEURODEV DISORD, V7, DOI 10.1186/1866-1955-7-4
   Vanhoutte S, 2016, NEUROPSYCHOLOGIA, V86, P93, DOI 10.1016/j.neuropsychologia.2016.04.018
   von Ellenrieder N, 2009, IEEE T BIO-MED ENG, V56, P587, DOI 10.1109/TBME.2009.2008445
   Winkler I, 2014, J NEURAL ENG, V11, DOI 10.1088/1741-2560/11/3/035013
   Xu JS, 2015, NEUROSCI BIOBEHAV R, V57, P264, DOI 10.1016/j.neubiorev.2015.08.018
   Yaruss JS, 2006, J FLUENCY DISORD, V31, P90, DOI 10.1016/j.jfludis.2006.02.002
NR 155
TC 1
Z9 1
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD JAN 10
PY 2020
VL 13
AR 458
DI 10.3389/fnhum.2019.00458
PG 21
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA KF5LA
UT WOS:000509282200001
PM 31998103
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU O'Sullivan, C
   Weible, AP
   Wehr, M
AF O'Sullivan, Conor
   Weible, Aldis P.
   Wehr, Michael
TI Disruption of Early or Late Epochs of Auditory Cortical Activity Impairs
   Speech Discrimination in Mice
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE consonant; speech - brain; speech perception; discrimination; auditory
   cortex; neural coding; spike time coding; optogenetic
ID CORTEX; PATTERNS; REPRESENTATION; PERCEPTION; ABLATION; SOUNDS
AB Speech evokes robust activity in auditory cortex, which contains information over a wide range of spatial and temporal scales. It remains unclear which components of these neural representations are causally involved in the perception and processing of speech sounds. Here we compared the relative importance of early and late speech-evoked activity for consonant discrimination. We trained mice to discriminate the initial consonants in spoken words, and then tested the effect of optogenetically suppressing different temporal windows of speech-evoked activity in auditory cortex. We found that both early and late suppression disrupted performance equivalently. These results suggest that mice are impaired at recognizing either type of disrupted representation because it differs from those learned in training.
C1 [O'Sullivan, Conor; Weible, Aldis P.; Wehr, Michael] Univ Oregon, Inst Neurosci, Eugene, OR 97403 USA.
   [O'Sullivan, Conor] Univ Oregon, Dept Biol, Eugene, OR 97403 USA.
   [Wehr, Michael] Univ Oregon, Dept Psychol, Eugene, OR 97403 USA.
RP Wehr, M (corresponding author), Univ Oregon, Inst Neurosci, Eugene, OR 97403 USA.; Wehr, M (corresponding author), Univ Oregon, Dept Psychol, Eugene, OR 97403 USA.
EM wehr@uoregon.edu
FU National Institutes of Health National Institute on Deafness and Other
   Communication DisordersUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01 DC-015828]
FX This work was supported by the National Institutes of Health National
   Institute on Deafness and Other Communication Disorders Grant R01
   DC-015828.
CR Centanni TM, 2014, NEUROSCIENCE, V258, P292, DOI 10.1016/j.neuroscience.2013.11.030
   Centanni TM, 2013, J NEUROPHYSIOL, V110, P177, DOI 10.1152/jn.00092.2013
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   CRANFORD JL, 1976, J NEUROPHYSIOL, V39, P143
   Engineer CT, 2008, NAT NEUROSCI, V11, P603, DOI 10.1038/nn.2109
   Flinker A, 2011, BRAIN LANG, V117, P103, DOI 10.1016/j.bandl.2010.09.009
   Floody OR, 2010, PHYSIOL BEHAV, V101, P260, DOI 10.1016/j.physbeh.2010.05.009
   Goshen I, 2011, CELL, V147, P678, DOI 10.1016/j.cell.2011.09.033
   Green D. M., 1966, SIGNAL DETECTION THE
   Hong YK, 2018, NATURE, V561, P542, DOI 10.1038/s41586-018-0527-y
   Ison JR, 2007, JARO-J ASSOC RES OTO, V8, P539, DOI 10.1007/s10162-007-0098-3
   Johnson KL, 2005, EAR HEARING, V26, P424, DOI 10.1097/01.aud.0000179687.71662.6e
   Kilgard M. P, 2015, ENCY COMPUTATIONAL N, P1, DOI [10.1007/978-1-4614-7320-6_433-2, DOI 10.1007/978-1-4614-7320-6_433-2]
   Kumar A, 2013, TRENDS NEUROSCI, V36, P579, DOI 10.1016/j.tins.2013.06.005
   Liebenthal E, 2005, CEREB CORTEX, V15, P1621, DOI 10.1093/cercor/bhi040
   Luria A. R, 2011, TRAUMATIC APHASIA IT
   Meier P, 2011, J VISION, V11, DOI 10.1167/11.3.22
   MICELI G, 1978, BRAIN LANG, V6, P47, DOI 10.1016/0093-934X(78)90042-1
   Moore AK, 2013, J NEUROSCI, V33, P13713, DOI 10.1523/JNEUROSCI.0663-13.2013
   O'Sullivan C, 2019, ENEURO, V6, DOI 10.1523/ENEURO.0340-19.2019
   Ohl FW, 1999, LEARN MEMORY, V6, P347
   Otchy TM, 2015, NATURE, V528, P358, DOI 10.1038/nature16442
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   Perez CA, 2013, CEREB CORTEX, V23, P670, DOI 10.1093/cercor/bhs045
   Porter BA, 2011, BEHAV BRAIN RES, V219, P68, DOI 10.1016/j.bbr.2010.12.015
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Redish D. A., 2008, MCLUST SPIKE SORTING
   Saunders JL, 2019, J ACOUST SOC AM, V145, P1168, DOI 10.1121/1.5091776
   Schnupp JWH, 2006, J NEUROSCI, V26, P4785, DOI 10.1523/JNEUROSCI.4330-05.2006
   Shetake JA, 2011, EUR J NEUROSCI, V34, P1823, DOI 10.1111/j.1460-9568.2011.07887.x
   Siegle JH, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa5eea
   TALLAL P, 1978, BRAIN LANG, V5, P13, DOI 10.1016/0093-934X(78)90003-2
   Tsunada J, 2016, NAT NEUROSCI, V19, P135, DOI 10.1038/nn.4195
   Tsunada J, 2011, J NEUROPHYSIOL, V105, P2634, DOI 10.1152/jn.00037.2011
   Weibe AP, 2014, J NEUROSCI, V34, P15437, DOI 10.1523/JNEUROSCI.3408-14.2014
NR 35
TC 0
Z9 0
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD JAN 10
PY 2020
VL 13
AR 1394
DI 10.3389/fnins.2019.01394
PG 11
WC Neurosciences
SC Neurosciences & Neurology
GA KF4VB
UT WOS:000509240600001
PM 31998064
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Ayasse, ND
   Wingfield, A
AF Ayasse, Nicolai D.
   Wingfield, Arthur
TI Anticipatory Baseline Pupil Diameter Is Sensitive to Differences in
   Hearing Thresholds
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE hearing acuity; pupil dilation; baseline pupil dilation; aging;
   listening effort
ID OLDER-ADULTS; LISTENING EFFORT; SPEECH-PERCEPTION; COGNITIVE EFFORT;
   ADAPTIVE GAIN; FATIGUE; SIZE; RECOGNITION; RESPONSES; DILATION
AB Task-evoked changes in pupil dilation have long been used as a physiological index of cognitive effort. Unlike this response, that is measured during or after an experimental trial, the baseline pupil dilation (BPD) is a measure taken prior to an experimental trial. As such, it is considered to reflect an individual's arousal level in anticipation of an experimental trial. We report data for 68 participants, ages 18 to 89, whose hearing acuity ranged from normal hearing to a moderate hearing loss, tested over a series 160 trials on an auditory sentence comprehension task. Results showed that BPDs progressively declined over the course of the experimental trials, with participants with poorer pure tone detection thresholds showing a steeper rate of decline than those with better thresholds. Data showed this slope difference to be due to participants with poorer hearing having larger BPDs than those with better hearing at the start of the experiment, but with their BPDs approaching that of the better hearing participants by the end of the 160 trials. A finding of increasing response accuracy over trials was seen as inconsistent with a fatigue or reduced task engagement account of the diminishing BPDs. Rather, the present results imply BPD as reflecting a heightened arousal level in poorer-hearing participants in anticipation of a task that demands accurate speech perception, a concern that dissipates over trials with task success. These data taken with others suggest that the baseline pupillary response may not reflect a single construct.
C1 [Ayasse, Nicolai D.; Wingfield, Arthur] Brandeis Univ, Volen Natl Ctr Complex Syst, Waltham, MA 02453 USA.
RP Wingfield, A (corresponding author), Brandeis Univ, Volen Natl Ctr Complex Syst, Waltham, MA 02453 USA.
EM wingfiel@brandeis.edu
OI Ayasse, Nicolai/0000-0003-0890-7742
FU NIH grant from the National Institute on Deafness and Other
   Communication Disorders [R01 DC06834]; NIHUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USA [T32
   GM084907]; Stephen J. Cloobeck Research Fund
FX This work was supported by NIH grant R01 DC06834 from the National
   Institute on Deafness and Other Communication Disorders. NA acknowledges
   support from NIH training grant T32 GM084907. We also gratefully
   acknowledge support from the Stephen J. Cloobeck Research Fund.
CR Allard ES, 2010, AGING NEUROPSYCHOL C, V17, P296, DOI 10.1080/13825580903265681
   ANTIKAINEN J, 1983, BIOL PSYCHOL, V17, P131, DOI 10.1016/0301-0511(83)90013-3
   Aston-Jones G, 2005, ANNU REV NEUROSCI, V28, P403, DOI 10.1146/annurev.neuro.28.061604.135709
   Ayasse ND, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518790907
   Ayasse ND, 2017, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00329
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Beatty J., 2000, HDB PSYCHOPHYSIOLOGY, V2, P142
   Bitsios P, 1996, AGE AGEING, V25, P432, DOI 10.1093/ageing/25.6.432
   Gilzenrat MS, 2010, COGN AFFECT BEHAV NE, V10, P252, DOI 10.3758/CABN.10.2.252
   Hasson D, 2009, INT J PSYCHOPHYSIOL, V74, P93, DOI 10.1016/j.ijpsycho.2009.07.009
   HESS EH, 1964, SCIENCE, V143, P1190, DOI 10.1126/science.143.3611.1190
   Hopstaken JF, 2015, PSYCHOPHYSIOLOGY, V52, P305, DOI 10.1111/psyp.12339
   Hornsby BWY, 2016, EAR HEARING, V37, p136S, DOI 10.1097/AUD.0000000000000289
   KAHNEMAN D, 1966, SCIENCE, V154, P1583, DOI 10.1126/science.154.3756.1583
   Kahneman D., 1973, ATTENTION EFFORT
   Kane MJ, 2007, J EXP PSYCHOL LEARN, V33, P615, DOI 10.1037/0278-7393.33.3.615
   Katz J, 2002, HDB CLIN AUDIOLOGY
   Kim M, 2000, J INT NEUROPSYCH SOC, V6, P348, DOI 10.1017/S135561770000309X
   Kinner VL, 2017, PSYCHOPHYSIOLOGY, V54, P508, DOI 10.1111/psyp.12816
   Koelewijn T, 2015, HEARING RES, V323, P81, DOI 10.1016/j.heares.2015.02.004
   Koelewijn T, 2012, EAR HEARING, V33, P291, DOI 10.1097/AUD.0b013e3182310019
   Kramer SE, 2016, EAR HEARING, V37, p126S, DOI 10.1097/AUD.0000000000000311
   Kuchinsky SE, 2014, PSYCHOPHYSIOLOGY, V51, P1046, DOI 10.1111/psyp.12242
   Kuchinsky SE, 2013, PSYCHOPHYSIOLOGY, V50, P23, DOI 10.1111/j.1469-8986.2012.01477.x
   Lempert KM, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126588
   McGinley MJ, 2015, NEURON, V87, P1143, DOI 10.1016/j.neuron.2015.09.012
   Murphy PR, 2011, PSYCHOPHYSIOLOGY, V48, P1531, DOI 10.1111/j.1469-8986.2011.01226.x
   Nachtegaal J, 2009, INT J AUDIOL, V48, P684, DOI 10.1080/14992020902962421
   Papesh MH, 2019, ATTEN PERCEPT PSYCHO, V81, P2635, DOI 10.3758/s13414-019-01777-6
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Piquado T, 2010, PSYCHOPHYSIOLOGY, V47, P560, DOI 10.1111/j.1469-8986.2009.00947.x
   Reilly J, 2019, BEHAV RES METHODS, V51, P865, DOI 10.3758/s13428-018-1134-4
   Rourke-Cullen T, 1995, J Am Acad Audiol, V6, P183
   Siegle GJ, 2008, PSYCHOPHYSIOLOGY, V45, P679, DOI 10.1111/j.1469-8986.2008.00681.x
   STENNETT RG, 1957, J EXP PSYCHOL, V54, P54, DOI 10.1037/h0043340
   van der Wel P, 2018, PSYCHON B REV, V25, P2005, DOI 10.3758/s13423-018-1432-y
   Wagner AE, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216519845596
   Wang Y, 2018, EAR HEARING, V39, P573, DOI 10.1097/AUD.0000000000000512
   Wang Y, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0153566
   Wendt D, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00345
   Winn MB, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518808962
   Winn MB, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518800869
   Winn MB, 2015, EAR HEARING, V36, pe153, DOI 10.1097/AUD.0000000000000145
   Yerkes RM, 1908, J COMP NEUROL PSYCHO, V18, P459, DOI 10.1002/cne.920180503
   Zekveld AA, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518777174
   Zekveld AA, 2014, NEUROIMAGE, V101, P76, DOI 10.1016/j.neuroimage.2014.06.069
   Zekveld AA, 2011, EAR HEARING, V32, P498, DOI 10.1097/AUD.0b013e31820512bb
   Zekveld AA, 2010, EAR HEARING, V31, P480, DOI 10.1097/AUD.0b013e3181d4f251
NR 48
TC 1
Z9 1
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JAN 10
PY 2020
VL 10
AR 2947
DI 10.3389/fpsyg.2019.02947
PG 7
WC Psychology, Multidisciplinary
SC Psychology
GA KF5AR
UT WOS:000509255200001
PM 31998196
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU MacCutcheon, D
   Fullgrabe, C
   Eccles, R
   van der Linde, J
   Panebianco, C
   Ljung, R
AF MacCutcheon, Douglas
   Fullgrabe, Christian
   Eccles, Renate
   van der Linde, Jeannie
   Panebianco, Clorinda
   Ljung, Robert
TI Investigating the Effect of One Year of Learning to Play a Musical
   Instrument on Speech-in-Noise Perception and Phonological Short-Term
   Memory in 5-to-7-Year-Old Children
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE speech in noise; phonological short-term memory; musical training;
   children; cognition
ID WORKING-MEMORY; INFORMATIONAL MASKING; SPATIAL RELEASE; CLASSROOM NOISE;
   INTELLIGIBILITY; HEARING; MASKER; RECOGNITION; PERFORMANCE; CHILDHOOD
AB The benefits in speech-in-noise perception, language and cognition brought about by extensive musical training in adults and children have been demonstrated in a number of cross-sectional studies. Therefore, this study aimed to investigate whether one year of school-delivered musical training, consisting of individual and group instrumental classes, was capable of producing advantages for speech-in-noise perception and phonological short-term memory in children tested in a simulated classroom environment. Forty-one children aged 5-7 years at the first measurement point participated in the study and either went to a music-focused or a sport-focused private school with an otherwise equivalent school curriculum. The children's ability to detect number and color words in noise was measured under a number of conditions including different masker types (speech-shaped noise, single-talker background) and under varying spatial combinations of target and masker (spatially collocated, spatially separated). Additionally, a cognitive factor essential to speech perception, namely phonological short-term memory, was assessed. Findings were unable to confirm that musical training of the frequency and duration administered was associated with a musicians' advantage for either speech in noise, under any of the masker or spatial conditions tested, or phonological short-term memory.
C1 [MacCutcheon, Douglas; Ljung, Robert] Hogskolan Gavle, Dept Bldg Energy & Environm Engn, Gavle, Sweden.
   [MacCutcheon, Douglas; Eccles, Renate; van der Linde, Jeannie; Panebianco, Clorinda] Univ Pretoria, Dept Mus, Pretoria, South Africa.
   [Fullgrabe, Christian] Loughborough Univ, Sch Sport Exercise & Hlth Sci, Loughborough, Leics, England.
   [Eccles, Renate; van der Linde, Jeannie] Univ Pretoria, Dept Speech Language Pathol & Audiol, Pretoria, South Africa.
RP MacCutcheon, D (corresponding author), Hogskolan Gavle, Dept Bldg Energy & Environm Engn, Gavle, Sweden.; MacCutcheon, D (corresponding author), Univ Pretoria, Dept Mus, Pretoria, South Africa.
EM Douglas.MacCutcheon@hig.se
RI Fullgrabe, Christian/I-6331-2012
OI Fullgrabe, Christian/0000-0001-9127-8136; MacCutcheon,
   Douglas/0000-0002-4947-4579; Eccles, Renata/0000-0003-0145-2634; van der
   Linde, Jeannie/0000-0002-8706-6605
FU Swedish Foundation for International Cooperation in Research and Higher
   Education [IB2017-7004]
FX The authors report grant funding from the Swedish Foundation for
   International Cooperation in Research and Higher Education (IB2017-7004)
   awarded to RL.
CR Baskent D, 2016, J ACOUST SOC AM, V139, pEL51, DOI 10.1121/1.4942628
   Benz S, 2016, FRONT PSYCHOL, V6, DOI [10.3389/fpsyg.2075.02023, 10.3389/fpsyg.2015.02023]
   Bidelman GM, 2014, EUR J NEUROSCI, V40, P2662, DOI 10.1111/ejn.12627
   Boebinger D, 2015, J ACOUST SOC AM, V137, P378, DOI 10.1121/1.4904537
   Bradley JS, 2008, J ACOUST SOC AM, V123, P2078, DOI 10.1121/1.2839285
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Chan AS, 1998, NATURE, V396, P128, DOI 10.1038/24075
   Corbin NE, 2016, EAR HEARING, V37, P55, DOI 10.1097/AUD.0000000000000201
   Corrigall KA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00222
   Cowan N, 1999, CHILD DEV, V70, P1082, DOI 10.1111/1467-8624.00080
   DiSarno N.J., 2002, TEACH EXCEPT CHILD, V34, DOI [10.1177/004005990203400603, DOI 10.1177/004005990203400603]
   Dockrell JE, 2012, J SPEECH LANG HEAR R, V55, P1163, DOI 10.1044/1092-4388(2011/11-0026)
   Dole M, 2012, NEUROPSYCHOLOGIA, V50, P1543, DOI 10.1016/j.neuropsychologia.2012.03.007
   Fels J, 2004, ACTA ACUST UNITED AC, V90, P918
   Fleming D, 2019, BRAIN COGNITION, V136, DOI 10.1016/j.bandc.2019.103592
   Franklin MS, 2008, PSYCHOL MUSIC, V36, P353, DOI 10.1177/0305735607086044
   Freyman RL, 1999, J ACOUST SOC AM, V106, P3578, DOI 10.1121/1.428211
   Fuller CD, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00179
   Hall JW, 2002, EAR HEARING, V23, P159, DOI 10.1097/00003446-200204000-00008
   Hawley ML, 2004, J ACOUST SOC AM, V115, P833, DOI 10.1121/1.1639908
   Johnstone PM, 2006, J ACOUST SOC AM, V120, P2177, DOI 10.1121/1.2225416
   Klatte M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00578
   Kraus N, 2014, J NEUROSCI, V34, P11913, DOI 10.1523/JNEUROSCI.1881-14.2014
   Lee YS, 2007, LEARN INSTR, V17, P336, DOI 10.1016/j.learninstruc.2007.02.010
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Litovsky RY, 2005, J ACOUST SOC AM, V117, P3091, DOI 10.1121/1.1873913
   Lorenzi C, 2000, J SPEECH LANG HEAR R, V43, P1367, DOI 10.1044/jslhr.4306.1367
   MacCutcheon D, 2019, J SPEECH LANG HEAR R, V62, P3741, DOI 10.1044/2019_JSLHR-S-19-0012
   MacCutcheon D, 2018, SCAND J PSYCHOL, V59, P567, DOI 10.1111/sjop.12466
   McCreery RW, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01093
   Myant M., 2008, ED CHILD PSYCHOL, V25, P83
   Nelson P, 2005, LANG SPEECH HEAR SER, V36, P219, DOI 10.1044/0161-1461(2005/022)
   Neuman AC, 2010, EAR HEARING, V31, P336, DOI 10.1097/AUD.0b013e3181d3d514
   Nutley SB, 2014, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00926
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Prodi N, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02166
   Purdy SC, 2009, INT J AUDIOL, V48, P843, DOI 10.3109/14992020903140910
   Renfrew C. E., 1980, ACTION PICTURE TEST
   Rhyner P.M., 2009, EMERGENT LITERACY LA
   Roden I, 2014, PSYCHOL MUSIC, V42, P284, DOI 10.1177/0305735612471239
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   Ruggles DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086980
   Schroder WH, 2011, HIST SOC RES, P11
   Semel E. M., 2003, CLIN EVALUATION LANG
   Shield B. M., 2003, Building Acoustics, V10, P97, DOI 10.1260/135101003768965960
   Shield BM, 2008, J ACOUST SOC AM, V123, P133, DOI 10.1121/1.2812596
   Slater J, 2015, BEHAV BRAIN RES, V291, P244, DOI 10.1016/j.bbr.2015.05.026
   Stone MA, 2012, J ACOUST SOC AM, V132, P317, DOI 10.1121/1.4725766
   Strait DL, 2014, CEREB CORTEX, V24, P2512, DOI 10.1093/cercor/bht103
   Strait DL, 2012, BRAIN LANG, V123, P191, DOI 10.1016/j.bandl.2012.09.001
   Swaminathan J, 2015, SCI REP-UK, V5, DOI 10.1038/srep11628
   Swaminathan S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27571-2
   Swanepoel D, 2014, INT J AUDIOL, V53, P841, DOI 10.3109/14992027.2014.920965
   Talamini F, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0186773
   Tallal P., 2014, SPEECH LANGUAGE IMPA
   Vickers D, 2016, ADV EXP MED BIOL, V894, P115, DOI 10.1007/978-3-319-25474-6_13
   Wightman F, 2006, J ACOUST SOC AM, V119, P3940, DOI 10.1121/1.2195121
   Wightman FL, 2005, J ACOUST SOC AM, V118, P3164, DOI 10.1121/1.2082567
   Zendel BR, 2019, NEUROBIOL AGING, V81, P102, DOI 10.1016/j.neurobiolaging.2019.05.015
NR 60
TC 0
Z9 0
U1 0
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JAN 10
PY 2020
VL 10
AR 2865
DI 10.3389/fpsyg.2019.02865
PG 9
WC Psychology, Multidisciplinary
SC Psychology
GA KF9RM
UT WOS:000509580200001
PM 31998174
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Lewis, GA
   Bidelman, GM
AF Lewis, Gwyneth A.
   Bidelman, Gavin M.
TI Autonomic Nervous System Correlates of Speech Categorization Revealed
   Through Pupillometry
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE pupillometry; categorical perception; speech-in-noise (SIN) perception;
   listening effort; eye behavior
ID SHORT-TERM-MEMORY; CATEGORICAL PERCEPTION; PROCESSING LOAD; LANGUAGE
   EXPERIENCE; NEURAL ORGANIZATION; PUPILLARY RESPONSES; HEARING
   IMPAIRMENT; LISTENING EFFORT; DISCRIMINATION; STIMULUS
AB Human perception requires the many-to-one mapping between continuous sensory elements and discrete categorical representations. This grouping operation underlies the phenomenon of categorical perception (CP)-the experience of perceiving discrete categories rather than gradual variations in signal input. Speech perception requires CP because acoustic cues do not share constant relations with perceptual-phonetic representations. Beyond facilitating perception of unmasked speech, we reasoned CP might also aid the extraction of target speech percepts from interfering sound sources (i.e., noise) by generating additional perceptual constancy and reducing listening effort. Specifically, we investigated how noise interference impacts cognitive load and perceptual identification of unambiguous (i.e., categorical) vs. ambiguous stimuli. Listeners classified a speech vowel continuum (/u/-/a/) at various signal-to-noise ratios (SNRs [unmasked, 0 and -5 dB]). Continuous recordings of pupil dilation measured processing effort, with larger, later dilations reflecting increased listening demand. Critical comparisons were between time-locked changes in eye data in response to unambiguous (i.e., continuum endpoints) tokens vs. ambiguous tokens (i.e., continuum midpoint). Unmasked speech elicited faster responses and sharper psychometric functions, which steadily declined in noise. Noise increased pupil dilation across stimulus conditions, but not straightforwardly. Noise-masked speech modulated peak pupil size (i.e., [0 and -5 dB] > unmasked). In contrast, peak dilation latency varied with both token and SNR. Interestingly, categorical tokens elicited earlier pupil dilation relative to ambiguous tokens. Our pupillary data suggest CP reconstructs auditory percepts under challenging listening conditions through interactions between stimulus salience and listeners' internalized effort and/or arousal.
C1 [Lewis, Gwyneth A.; Bidelman, Gavin M.] Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.
   [Lewis, Gwyneth A.; Bidelman, Gavin M.] Univ Memphis, Sch Commun Sci & Disorders, Memphis, TN 38152 USA.
   [Bidelman, Gavin M.] Univ Tennessee, Ctr Hlth Sci, Dept Anat & Neurobiol, Memphis, TN 38163 USA.
RP Bidelman, GM (corresponding author), Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.; Bidelman, GM (corresponding author), Univ Memphis, Sch Commun Sci & Disorders, Memphis, TN 38152 USA.; Bidelman, GM (corresponding author), Univ Tennessee, Ctr Hlth Sci, Dept Anat & Neurobiol, Memphis, TN 38163 USA.
EM gmbdlman@memphis.edu
FU National Institute on Deafness and Other Communication Disorders of the
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC016267];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC016267, R01DC016267, R01DC016267,
   R01DC016267] Funding Source: NIH RePORTER
FX This work was supported by the National Institute on Deafness and Other
   Communication Disorders of the National Institutes of Health under award
   number R01DC016267 (GB).
CR Altmann CF, 2014, NEUROPSYCHOLOGIA, V64, P13, DOI 10.1016/j.neuropsychologia.2014.09.006
   Andreassi J. L., 2000, PSYCHOPHYSIOLOGY HUM, P289
   Aston-Jones G, 2005, ANNU REV NEUROSCI, V28, P403, DOI 10.1146/annurev.neuro.28.061604.135709
   BEATTY J, 1982, PSYCHOL BULL, V91, P276, DOI 10.1037/0033-2909.91.2.276
   Ben-David BM, 2011, J SPEECH LANG HEAR R, V54, P243, DOI 10.1044/1092-4388(2010/09-0233)
   Berridge CW, 2003, BRAIN RES REV, V42, P33, DOI 10.1016/S0165-0173(03)00143-7
   Bidelman G. M, 2019, BIORXIV, DOI [10.1101/652842, DOI 10.1101/652842]
   Bidelman G. M., 2017, SPRINGER HDB AUDITOR, V61
   Bidelman GM, 2019, J ACOUST SOC AM, V146, P60, DOI 10.1121/1.5114822
   Bidelman GM, 2020, EAR HEARING, V41, P268, DOI 10.1097/AUD.0000000000000755
   Bidelman GM, 2017, EUR J NEUROSCI, V45, P690, DOI 10.1111/ejn.13526
   Bidelman GM, 2015, NEUROIMAGE, V120, P191, DOI 10.1016/j.neuroimage.2015.06.087
   Bidelman GM, 2015, BRAIN LANG, V141, P62, DOI 10.1016/j.bandl.2014.11.003
   Bidelman GM, 2014, EUR J NEUROSCI, V40, P2662, DOI 10.1111/ejn.12627
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Cousins KAQ, 2014, MEM COGNITION, V42, P622, DOI 10.3758/s13421-013-0377-7
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Eckstein MK, 2017, DEV COGN NEUROS-NETH, V25, P69, DOI 10.1016/j.dcn.2016.11.001
   Evans S, 2016, J COGNITIVE NEUROSCI, V28, P483, DOI 10.1162/jocn_a_00913
   Fan XF, 2011, IEEE T BIO-MED ENG, V58, P36, DOI 10.1109/TBME.2010.2080678
   GATEHOUSE S J G, 1990, British Journal of Audiology, V24, P63, DOI 10.3109/03005369009077843
   Goldstone RL, 2010, WIRES COGN SCI, V1, P69, DOI 10.1002/wcs.26
   Guenther FH, 2004, J SPEECH LANG HEAR R, V47, P46, DOI 10.1044/1092-4388(2004/005)
   Guenther FH, 1996, J ACOUST SOC AM, V100, P1111, DOI 10.1121/1.416296
   Harnad Stevan, 1987, CATEGORICAL PERCEPTI
   Heinrich A, 2008, Q J EXP PSYCHOL, V61, P735, DOI 10.1080/17470210701402372
   Helie S, 2017, BRAIN COGNITION, V116, P63, DOI 10.1016/j.bandc.2017.06.001
   HYONA J, 1995, Q J EXP PSYCHOL-A, V48, P598
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   KAHNEMAN D, 1966, SCIENCE, V154, P1583, DOI 10.1126/science.154.3756.1583
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Koelewijn T, 2014, HEARING RES, V312, P114, DOI 10.1016/j.heares.2014.03.010
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Liao HI, 2016, PSYCHON B REV, V23, P412, DOI 10.3758/s13423-015-0898-0
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Liebenthal E, 2010, CEREB CORTEX, V20, P2958, DOI 10.1093/cercor/bhq045
   Livingston KR, 1998, J EXP PSYCHOL LEARN, V24, P732, DOI 10.1037/0278-7393.24.3.732
   Lopez-Ornat S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02248
   Lotto A. J., 2016, NEUROBIOLOGY LANGUAG, P185
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McGarrigle R, 2017, J EXP CHILD PSYCHOL, V161, P95, DOI 10.1016/j.jecp.2017.04.006
   McMurray B, 2008, J EXP PSYCHOL HUMAN, V34, P1609, DOI 10.1037/a0011747
   Myers EB, 2012, J COGNITIVE NEUROSCI, V24, P1695, DOI 10.1162/jocn_a_00243
   Naylor G., 2018, APPL PUPILLOMETRY HE
   NOTHDURFT HC, 1991, VISION RES, V31, P1073, DOI 10.1016/0042-6989(91)90211-M
   Ohlenforst B, 2018, HEARING RES, V365, P90, DOI 10.1016/j.heares.2018.05.003
   Ohlenforst B, 2017, HEARING RES, V351, P68, DOI 10.1016/j.heares.2017.05.012
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Perez-Gay F., 2018, CATEGFORY LEARNING C
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   PISONI DB, 1987, COGNITION, V25, P21, DOI 10.1016/0010-0277(87)90003-5
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   PISONI DB, 1975, MEM COGNITION, V3, P7, DOI 10.3758/BF03198202
   Poeppel D, 2004, NEUROPSYCHOLOGIA, V42, P183, DOI 10.1016/j.neuropsychologia.2003.07.010
   RECANZONE GH, 1993, J NEUROSCI, V13, P87
   Renner LF, 2017, INTERSPEECH, P674, DOI 10.21437/Interspeech.2017-353
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Sara SJ, 2012, NEURON, V76, P130, DOI 10.1016/j.neuron.2012.09.011
   Scott SK, 2000, BRAIN, V123, P2400, DOI 10.1093/brain/123.12.2400
   Sharma A, 1999, J ACOUST SOC AM, V106, P1078, DOI 10.1121/1.428048
   Vogelzang M, 2016, LANG COGN NEUROSCI, V31, P876, DOI 10.1080/23273798.2016.1155718
   Wendt D, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00345
   Winn MB, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518800869
   Winn MB, 2015, EAR HEARING, V36, pe153, DOI 10.1097/AUD.0000000000000145
   Xu YS, 2006, J ACOUST SOC AM, V120, P1063, DOI 10.1121/1.2213572
   Yerkes RM, 1908, J COMP NEUROL PSYCHO, V18, P459, DOI 10.1002/cne.920180503
   Yoo J, 2019, HEARING RES, V377, P189, DOI 10.1016/j.heares.2019.03.021
   Zekveld AA, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518777174
   Zekveld AA, 2014, PSYCHOPHYSIOLOGY, V51, P277, DOI 10.1111/psyp.12151
   Zekveld AA, 2011, EAR HEARING, V32, P498, DOI 10.1097/AUD.0b013e31820512bb
   Zekveld AA, 2010, EAR HEARING, V31, P480, DOI 10.1097/AUD.0b013e3181d4f251
   Zhang LJ, 2011, PLOS ONE, V6, DOI [10.1371/journal.pone.0020963, 10.1371/journal.pone.0026129, 10.1371/journal.pone.0022809, 10.1371/journal.pone.0028953, 10.1371/journal.pone.0026842]
NR 75
TC 2
Z9 2
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD JAN 10
PY 2020
VL 13
AR 1418
DI 10.3389/fnins.2019.01418
PG 10
WC Neurosciences
SC Neurosciences & Neurology
GA KF4VJ
UT WOS:000509241400001
PM 31998068
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Luo, XX
   Kang, GL
   Guo, Y
   Yu, XC
   Zhou, XL
AF Luo, Xiaoxiao
   Kang, Guanlan
   Guo, Yu
   Yu, Xingcheng
   Zhou, Xiaolin
TI A value-driven McGurk effect: Value-associated faces enhance the
   influence of visual information on audiovisual speech perception and its
   eye movement pattern
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE McGurk effect; Reward association; Audiovisual speech perception; Eye
   movements; Signal detection analysis
ID HEARING-LIPS; INTEGRATION; ATTENTION; VOICES
AB This study investigates whether and how value-associated faces affect audiovisual speech perception and its eye movement pattern. Participants were asked to learn to associate particular faces with or without monetary reward in the training phase, and, in the subsequent test phase, to identify syllables that the talkers had said in video clips in which the talkers' faces had or had not been associated with reward. The syllables were either congruent or incongruent with the talkers' mouth movements. Crucially, in some cases, the incongruent syllables could elicit the McGurk effect. Results showed that the McGurk effect occurred more often for reward-associated faces than for non-reward-associated faces. Moreover, the signal detection analysis revealed that participants had lower criterion and higher discriminability for reward-associated faces than for non-reward-associated faces. Surprisingly, eye movement data showed that participants spent more time looking at and fixated more often on the extraoral (nose/cheek) area for reward-associated faces than for non-reward-associated faces, while the opposite pattern was observed on the oral (mouth) area. The correlation analysis demonstrated that, over participants, the more they looked at the extraoral area in the training phase because of reward, the larger the increase of McGurk proportion (and the less they looked at the oral area) in the test phase. These findings not only demonstrate that value-associated faces enhance the influence of visual information on audiovisual speech perception but also highlight the importance of the extraoral facial area in the value-driven McGurk effect.
C1 [Luo, Xiaoxiao; Kang, Guanlan; Zhou, Xiaolin] Peking Univ, Sch Psychol & Cognit Sci, Beijing 100871, Peoples R China.
   [Guo, Yu; Yu, Xingcheng; Zhou, Xiaolin] Zhejiang Normal Univ, Inst Psychol & Brain Sci, Jinhua 321004, Zhejiang, Peoples R China.
   [Zhou, Xiaolin] Peking Univ, Beijing Key Lab Behav & Mental Hlth, Beijing 100871, Peoples R China.
   [Zhou, Xiaolin] Shanghai Int Studies Univ, Inst Linguist, Shanghai 200083, Peoples R China.
   [Zhou, Xiaolin] Peking Univ, McGovern Inst Brain Res, PKU IDG, Beijing 100871, Peoples R China.
RP Zhou, XL (corresponding author), Peking Univ, Sch Psychol & Cognit Sci, Beijing 100871, Peoples R China.; Zhou, XL (corresponding author), Zhejiang Normal Univ, Inst Psychol & Brain Sci, Jinhua 321004, Zhejiang, Peoples R China.; Zhou, XL (corresponding author), Peking Univ, Beijing Key Lab Behav & Mental Hlth, Beijing 100871, Peoples R China.; Zhou, XL (corresponding author), Shanghai Int Studies Univ, Inst Linguist, Shanghai 200083, Peoples R China.; Zhou, XL (corresponding author), Peking Univ, McGovern Inst Brain Res, PKU IDG, Beijing 100871, Peoples R China.
EM xz104@pku.edu.cn
FU Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [31630034]; National Basic Research Program of
   ChinaNational Basic Research Program of China [2015CB856400]
FX We thank Miss Yueyuan Zheng, Miss Jiayi Li, and Miss Muhang Li for
   proofreading, and Mrs. Haining Bi for allowing us to use her face
   picture in this article. This work was supported by the Natural Science
   Foundation of China (Grant No. 31630034) and the National Basic Research
   Program of China (973 Program: 2015CB856400).
CR Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Alsius A, 2018, MULTISENS RES, V31, P111, DOI 10.1163/22134808-00002565
   Anderson BA, 2016, ATTEN PERCEPT PSYCHO, V78, P242, DOI 10.3758/s13414-015-1001-7
   Anderson BA, 2013, J VISION, V13, DOI 10.1167/13.3.7
   Anderson BA, 2011, P NATL ACAD SCI USA, V108, P10367, DOI 10.1073/pnas.1104047108
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Brancazio L, 2003, PERCEPT PSYCHOPHYS, V65, P591, DOI 10.3758/BF03194585
   Buchan JN, 2012, SEEING PERCEIVING, V25, P87, DOI 10.1163/187847611X620937
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Gurler D, 2015, ATTEN PERCEPT PSYCHO, V77, P1333, DOI 10.3758/s13414-014-0821-1
   Hisanaga S, 2016, SCI REP-UK, V6, DOI 10.1038/srep35265
   Jordan TR, 2011, ATTEN PERCEPT PSYCHO, V73, P2270, DOI 10.3758/s13414-011-0152-4
   Magnotti JF, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-36772-8
   Marques LM, 2016, LANG COGN NEUROSCI, V31, P1115, DOI 10.1080/23273798.2016.1190023
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Fernandez LM, 2017, HUM BRAIN MAPP, V38, P5691, DOI 10.1002/hbm.23758
   Pare M, 2003, PERCEPT PSYCHOPHYS, V65, P553, DOI 10.3758/BF03194582
   Peterson MF, 2012, P NATL ACAD SCI USA, V109, pE3314, DOI 10.1073/pnas.1214269109
   Pooresmaeili A, 2014, P NATL ACAD SCI USA, V111, P15244, DOI 10.1073/pnas.1408873111
   Raymond JE, 2009, PSYCHOL SCI, V20, P981, DOI 10.1111/j.1467-9280.2009.02391.x
   Rennig J., 2018, FACE VIEWING BEHAV P, P1, DOI [10.1101/331306, DOI 10.1101/331306]
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Seilheimer RL, 2014, CURR OPIN NEUROBIOL, V25, P38, DOI 10.1016/j.conb.2013.11.008
   Stanislaw H, 1999, BEHAV RES METH INS C, V31, P137, DOI 10.3758/BF03207704
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Thomas SM, 2004, J EXP PSYCHOL HUMAN, V30, P873, DOI 10.1037/0096-1523.30.5.873
   Tiippana K, 2004, EUR J COGN PSYCHOL, V16, P457, DOI 10.1080/09541440340000268
   WALKER S, 1995, PERCEPT PSYCHOPHYS, V57, P1124, DOI 10.3758/BF03208369
   Wang LH, 2014, J VISION, V14, DOI 10.1167/14.12.2
   Wang LH, 2013, J VISION, V13, DOI 10.1167/13.3.5
   Wilson AH, 2016, J SPEECH LANG HEAR R, V59, P601, DOI 10.1044/2016_JSLHR-S-15-0092
NR 34
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2020
VL 82
IS 4
BP 1928
EP 1941
DI 10.3758/s13414-019-01918-x
EA JAN 2020
PG 14
WC Psychology; Psychology, Experimental
SC Psychology
GA LY5OH
UT WOS:000505341300001
PM 31898072
OA Bronze
DA 2021-02-24
ER

PT S
AU Wu, DH
   Bulut, T
AF Wu, Denise H.
   Bulut, Talat
BE Federmeier, KD
   Huang, HW
TI The contribution of statistical learning to language and literacy
   acquisition
SO ADULT AND SECOND LANGUAGE LEARNING
SE Psychology of Learning and Motivation
LA English
DT Article; Book Chapter
ID SPELLING-SOUND CONSISTENCY; VISUAL WORD RECOGNITION; BRAIN POTENTIALS;
   DUAL-ROUTE; ENHANCED DISCRIMINABILITY; MATURATIONAL CONSTRAINTS;
   PHONETIC BOUNDARIES; CHINESE CHARACTERS; SPEECH-PERCEPTION; READING
   ALOUD
AB Acquisition and processing of written and spoken language is an impressive cognitive accomplishment considering the complexity of the tasks. While only humans seem to have evolved to the fullest extent the capacity that underpins these remarkable feats of development and civilization, the exact nature of such capacity has been subject to ongoing research. In this chapter, we focus on language competence and what makes it unique among the communication systems of different species. We then elaborate on the classical debate between nativist and environmentalist accounts of language acquisition, with reference to evidence for and against the critical period hypothesis. After introducing the regularity embedded in different languages and particularly in drastically different orthographies, we present behavioral and neurophysiological evidence for the sensitivity to systematic mapping between orthography and phonology. Because learning to read is to master such mapping, we assume that the ability to use statistical learning to appreciate the dependency among items would contribute to literacy acquisition. Empirical results from behavioral and neuroimaging experiments conducted in our and other laboratories provide support for the close link between statistical learning and literacy acquisition in native and foreign language. Such findings highlight the significance of domain-general statistical learning to domain-specific language acquisition, and point to an important direction for theories and practices of language education.
C1 [Wu, Denise H.] Natl Cent Univ, Inst Cognit Neurosci, Taoyuan, Taiwan.
   [Bulut, Talat] Istanbul Medipol Univ, Dept Speech & Language Therapy, Istanbul, Turkey.
RP Wu, DH (corresponding author), Natl Cent Univ, Inst Cognit Neurosci, Taoyuan, Taiwan.
EM denisewu@cc.ncu.edu.tw
CR Abla D, 2008, J COGNITIVE NEUROSCI, V20, P952, DOI 10.1162/jocn.2008.20058
   Abla D, 2009, NEUROSCI RES, V64, P185, DOI 10.1016/j.neures.2009.02.013
   ALTMANN GTM, 1995, J EXP PSYCHOL LEARN, V21, P899, DOI 10.1037/0278-7393.21.4.899
   Arciuli J, 2012, COGNITIVE SCI, V36, P286, DOI 10.1111/j.1551-6709.2011.01200.x
   Aslin RN, 1998, PSYCHOL SCI, V9, P321, DOI 10.1111/1467-9280.00063
   Berwick RC, 2013, TRENDS COGN SCI, V17, P89, DOI 10.1016/j.tics.2012.12.002
   BIRDSONG D, 2007, LANGUAGE EXPERIENCE, P99
   Bischoff-Grethe A, 2000, J NEUROSCI, V20, P1975
   Bishop DVM, 2006, CURR DIR PSYCHOL SCI, V15, P217, DOI 10.1111/j.1467-8721.2006.00439.x
   Bishop DVM, 2002, J COMMUN DISORD, V35, P311, DOI 10.1016/S0021-9924(02)00087-4
   Bogaerts L, 2016, PSYCHON B REV, V23, P1250, DOI 10.3758/s13423-015-0996-z
   Bolger DJ, 2008, HUM BRAIN MAPP, V29, P1416, DOI 10.1002/hbm.20476
   Bongaerts T, 2000, STUD LINGUISTICA, V54, P298, DOI 10.1111/1467-9582.00069
   Bulf H, 2011, COGNITION, V121, P127, DOI 10.1016/j.cognition.2011.06.010
   Cattinelli I, 2013, J NEUROLINGUIST, V26, P214, DOI 10.1016/j.jneuroling.2012.08.001
   Chen HY, 2016, NEUROIMAGE, V129, P105, DOI 10.1016/j.neuroimage.2016.01.009
   Christiansen MH, 2012, LANG COGNITIVE PROC, V27, P231, DOI 10.1080/01690965.2011.606666
   Christiansen MH, 2010, COGNITION, V116, P382, DOI 10.1016/j.cognition.2010.05.015
   Coltheart M, 2001, PSYCHOL REV, V108, P204, DOI 10.1037//0033-295X.108.1.204
   COLTHEART M, 1993, PSYCHOL REV, V100, P589, DOI 10.1037/0033-295X.100.4.589
   COLTHEART M, 1994, J EXP PSYCHOL HUMAN, V20, P1197, DOI 10.1037/0096-1523.20.6.1197
   Conway CM, 2010, COGNITION, V114, P356, DOI 10.1016/j.cognition.2009.10.009
   Conway CM, 2008, ANN NY ACAD SCI, V1145, P113, DOI 10.1196/annals.1416.009
   Conway CM, 2005, J EXP PSYCHOL LEARN, V31, P24, DOI 10.1037/0278-7393.31.1.24
   Cortese MJ, 2000, MEM COGNITION, V28, P1269, DOI 10.3758/BF03211827
   Creel SC, 2004, J EXP PSYCHOL LEARN, V30, P1119, DOI 10.1037/0278-7393.30.5.1119
   Cunillera T, 2006, BRAIN RES, V1123, P168, DOI 10.1016/j.brainres.2006.09.046
   CURTISS S, 1974, LANGUAGE, V50, P528, DOI 10.2307/412222
   Curtiss S., 1989, LINGUISTICS CAMBRIDG, V2, P96
   Daltrozzo J, 2017, BRAIN LANG, V166, P40, DOI 10.1016/j.bandl.2016.12.005
   Daltrozzo J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00437
   DEHAENE S, 2010, REAING BRAIN SCI EVO
   Dehaene S., 2004, MONKEY BRAIN HUMAN B, P133
   Dell GS, 2000, J EXP PSYCHOL LEARN, V26, P1355, DOI 10.1037//0278-7393.26.6.1355
   Eichenbaum H, 2013, TRENDS COGN SCI, V17, P81, DOI 10.1016/j.tics.2012.12.007
   Emberson LL, 2011, Q J EXP PSYCHOL, V64, P1021, DOI 10.1080/17470218.2010.538972
   Evans JL, 2009, J SPEECH LANG HEAR R, V52, P321, DOI 10.1044/1092-4388(2009/07-0189)
   Fiez JA, 1999, NEURON, V24, P205, DOI 10.1016/S0896-6273(00)80833-8
   Fiser J, 2001, PSYCHOL SCI, V12, P499, DOI 10.1111/1467-9280.00392
   Fitch WT, 2005, COGNITION, V97, P179, DOI 10.1016/j.cognition.2005.02.005
   Friederici AD, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017920
   FROMKIN V, 1974, BRAIN LANG, V1, P81, DOI 10.1016/0093-934X(74)90027-3
   FROST R, 1987, J EXP PSYCHOL HUMAN, V13, P104, DOI 10.1037/0096-1523.13.1.104
   Frost R, 2005, BL HBK DEV PSYCHOL, P272, DOI 10.1002/9780470757642.ch15
   Frost R, 2015, TRENDS COGN SCI, V19, P117, DOI 10.1016/j.tics.2014.12.010
   Frost R, 2013, PSYCHOL SCI, V24, P1243, DOI 10.1177/0956797612472207
   Gabriel A, 2015, APPL PSYCHOLINGUIST, V36, P747, DOI 10.1017/S0142716413000490
   Gabriel A, 2012, AM J SPEECH-LANG PAT, V21, P329, DOI 10.1044/1058-0360(2012/11-0044)
   Gabriel A, 2011, J INT NEUROPSYCH SOC, V17, P336, DOI 10.1017/S1355617710001724
   Gomez RL, 1999, COGNITION, V70, P109, DOI 10.1016/S0010-0277(99)00003-7
   Gomez RL, 2002, PSYCHOL SCI, V13, P431, DOI 10.1111/1467-9280.00476
   Haebig E, 2017, J CHILD PSYCHOL PSYC, V58, P1251, DOI 10.1111/jcpp.12734
   HAGOORT P, 1993, LANG COGNITIVE PROC, V8, P439, DOI 10.1080/01690969308407585
   Hakuta K, 2003, PSYCHOL SCI, V14, P31, DOI 10.1111/1467-9280.01415
   Hauser MD, 2002, SCIENCE, V298, P1569, DOI 10.1126/science.298.5598.1569
   Hedenius M, 2011, RES DEV DISABIL, V32, P2362, DOI 10.1016/j.ridd.2011.07.026
   HOCKETT CF, 1960, SCI AM, V203, P88, DOI 10.1038/scientificamerican0960-88
   Hsiao JHW, 2006, J PSYCHOLINGUIST RES, V35, P405, DOI 10.1007/s10936-006-9022-y
   Hsu CH, 2014, BRAIN LANG, V139, P1, DOI 10.1016/j.bandl.2014.09.008
   Hsu CH, 2011, BRAIN LANG, V117, P1, DOI 10.1016/j.bandl.2010.10.002
   Hsu HJ, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00175
   Huang C.-R., 1998, ACAD SINICA BALANCED
   Hung YH, 2014, J NEUROLINGUIST, V29, P42, DOI 10.1016/j.jneuroling.2013.12.003
   HYLTENSTAM K, 2003, HDB 2 LANGUAGE ACQUI, P539, DOI [DOI 10.1002/9780470756492.CH17, DOI 10.1002/9780470756492]
   JARED D, 1990, J MEM LANG, V29, P687, DOI 10.1016/0749-596X(90)90044-Z
   Jared D, 2002, J MEM LANG, V46, P723, DOI 10.1006/jmla.2001.2827
   Jared D, 1997, J MEM LANG, V36, P505, DOI 10.1006/jmla.1997.2496
   JONES PE, 1995, LANG COMMUN, V15, P261, DOI 10.1016/0271-5309(95)00007-D
   Jost E, 2015, BRAIN RES, V1597, P95, DOI 10.1016/j.brainres.2014.10.017
   Kaan E, 2000, LANG COGNITIVE PROC, V15, P159, DOI 10.1080/016909600386084
   Kareev Y, 2009, J EXP PSYCHOL LEARN, V35, P371, DOI 10.1037/a0014545
   Kemeny F, 2010, J CLIN EXP NEUROPSYC, V32, P249, DOI 10.1080/13803390902971131
   Kidd E, 2016, CHILD DEV, V87, P184, DOI 10.1111/cdev.12461
   Kidd E, 2012, DEV PSYCHOL, V48, P171, DOI 10.1037/a0025405
   Kirkham NZ, 2002, COGNITION, V83, pB35, DOI 10.1016/S0010-0277(02)00004-5
   Kooijman V, 2005, COGNITIVE BRAIN RES, V24, P109, DOI 10.1016/j.cogbrainres.2004.12.009
   KUHL PK, 1983, J ACOUST SOC AM, V73, P1003, DOI 10.1121/1.389148
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   KUHL PK, 1982, PERCEPT PSYCHOPHYS, V32, P542, DOI 10.3758/BF03204208
   KUHL PK, 1975, SCIENCE, V190, P69, DOI 10.1126/science.1166301
   KUHL PK, 2006, DEVELOPMENTAL SCI, V9, pF1, DOI DOI 10.1111/J.1467-7687.2006.00468.X
   Kuo WJ, 2004, NEUROIMAGE, V21, P1721, DOI 10.1016/j.neuroimage.2003.12.007
   Kuo WJ, 2003, NEUROIMAGE, V18, P720, DOI 10.1016/S1053-8119(03)00015-6
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Lee C.-Y., 2005, LANGUAGE LINGUISTICS, V6, P75
   Lee CY, 2004, NEUROIMAGE, V23, P1235, DOI 10.1016/j.neuroimage.2004.07.064
   Lenneberg EH, 1967, HOSP PRACT, V2, P59, DOI [DOI 10.1080/21548331.1967.11707799, 10.1080/21548331.1967.11707799]
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Lin YC, 2015, MEM COGNITION, V43, P538, DOI 10.3758/s13421-014-0495-x
   Liu YY, 2007, BEHAV RES METHODS, V39, P192, DOI 10.3758/BF03193147
   Lum JAG, 2012, CORTEX, V48, P1138, DOI 10.1016/j.cortex.2011.06.001
   Lum JAG, 2010, INT J LANG COMM DIS, V45, P96, DOI 10.3109/13682820902752285
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Maye J, 2008, DEVELOPMENTAL SCI, V11, P122, DOI 10.1111/j.1467-7687.2007.00653.x
   McNealy K, 2006, J NEUROSCI, V26, P7629, DOI 10.1523/JNEUROSCI.5501-05.2006
   MEHLER J, 2008, PERCEPT DECISION ACT, P251, DOI DOI 10.1002/9780470034989.CH20
   Misyak JB, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00031
   Misyak JB, 2012, LANG LEARN, V62, P302, DOI 10.1111/j.1467-9922.2010.00626.x
   Misyak JB, 2010, TOP COGN SCI, V2, P138, DOI 10.1111/j.1756-8765.2009.01072.x
   Mostofsky SH, 2000, J INT NEUROPSYCH SOC, V6, P752, DOI 10.1017/S1355617700677020
   Mueller JL, 2005, J COGNITIVE NEUROSCI, V17, P1229, DOI 10.1162/0898929055002463
   Nastase S, 2014, HUM BRAIN MAPP, V35, P1111, DOI 10.1002/hbm.22238
   NEVILLE H, 1991, J COGNITIVE NEUROSCI, V3, P151, DOI 10.1162/jocn.1991.3.2.151
   Newport EL, 2004, COGNITIVE PSYCHOL, V48, P127, DOI 10.1016/S0010-0285(03)00128-2
   NEWPORT EL, 1990, COGNITIVE SCI, V14, P11, DOI 10.1016/0364-0213(90)90024-Q
   Obeid R, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01245
   OSTERHOUT L, 1992, J MEM LANG, V31, P785, DOI 10.1016/0749-596X(92)90039-Z
   Pearce MT, 2010, NEUROIMAGE, V50, P302, DOI 10.1016/j.neuroimage.2009.12.019
   Perfetti CA, 2005, PSYCHOL REV, V112, P43, DOI 10.1037/0033-295X.112.1.43
   Phillips C, 2005, COGNITIVE BRAIN RES, V22, P407, DOI 10.1016/j.cogbrainres.2004.09.012
   Pinker S, 2005, COGNITION, V95, P201, DOI 10.1016/j.cognition.2004.08.004
   Plaut DC, 1996, PSYCHOL REV, V103, P56, DOI 10.1037/0033-295X.103.1.56
   Poldrack RA, 2005, J NEUROSCI, V25, P5356, DOI 10.1523/JNEUROSCI.3880-04.2005
   Pugh K.R., 2010, NEURAL BASIS READING, P281, DOI DOI 10.1093/ACPROF:OSO/9780195300369.003.0011
   REBER AS, 1967, J VERB LEARN VERB BE, V6, P855, DOI 10.1016/S0022-5371(67)80149-X
   Rivera-Gaxiola M, 2005, DEVELOPMENTAL SCI, V8, P162, DOI 10.1111/j.1467-7687.2005.00403.x
   Rueckl JG, 2015, P NATL ACAD SCI USA, V112, P15510, DOI 10.1073/pnas.1509321112
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Saffran JR, 1999, COGNITION, V70, P27, DOI 10.1016/S0010-0277(98)00075-4
   Sanders LD, 2003, COGNITIVE BRAIN RES, V15, P228, DOI 10.1016/S0926-6410(02)00195-7
   Sanders LD, 2002, NAT NEUROSCI, V5, P700, DOI 10.1038/nn873
   Schapiro AC, 2014, J COGNITIVE NEUROSCI, V26, P1736, DOI 10.1162/jocn_a_00578
   Siegelman N, 2015, J MEM LANG, V81, P105, DOI 10.1016/j.jml.2015.02.001
   Tabullo A, 2013, BRAIN RES, V1527, P149, DOI 10.1016/j.brainres.2013.05.022
   Teinonen T, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-21
   Turk-Browne NB, 2005, J EXP PSYCHOL GEN, V134, P552, DOI 10.1037/0096-3445.134.4.552
   Turk-Browne NB, 2010, J NEUROSCI, V30, P11177, DOI 10.1523/JNEUROSCI.0858-10.2010
   Turk-Browne NB, 2009, J COGNITIVE NEUROSCI, V21, P1934, DOI 10.1162/jocn.2009.21131
   Tzeng Y.-L., 2012, CONT ED RES Q, V20, P45
   Ullman MT, 2005, CORTEX, V41, P399, DOI 10.1016/S0010-9452(08)70276-4
   Ullman MT, 2004, COGNITION, V92, P231, DOI 10.1016/j.cognition.2003.10.008
   van Zuijen TL, 2006, J COGNITIVE NEUROSCI, V18, P1292, DOI 10.1162/jocn.2006.18.8.1292
   Warker JA, 2006, J EXP PSYCHOL LEARN, V32, P387, DOI 10.1037/0278-7393.32.2.387
   Weber-Fox C, 2001, J SPEECH LANG HEAR R, V44, P1338, DOI 10.1044/1092-4388(2001/104)
   WeberFox CM, 1996, J COGNITIVE NEUROSCI, V8, P231, DOI 10.1162/jocn.1996.8.3.231
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   Wu CY, 2012, NEUROIMAGE, V63, P381, DOI 10.1016/j.neuroimage.2012.06.047
   Wu DH, 2002, NEUROCASE, V8, P274, DOI 10.1093/neucas/8.4.274
   WU DH, VISUAL STAT LE UNPUB
   Yang JF, 2011, BRAIN LANG, V119, P68, DOI 10.1016/j.bandl.2011.03.004
   Yang JF, 2009, J MEM LANG, V61, P238, DOI 10.1016/j.jml.2009.05.001
   Yu AY, 2019, J NEUROLINGUIST, V50, P53, DOI 10.1016/j.jneuroling.2018.07.002
NR 143
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS LTD-ELSEVIER SCIENCE LTD
PI LONDON
PA 125 LONDON WALL, LONDON EC2Y 5AS, ENGLAND
SN 0079-7421
BN 978-0-12-820377-4
J9 PSYCHOL LEARN MOTIV
JI Psychol. Learn. Motiv.
PY 2020
VL 72
BP 283
EP 318
DI 10.1016/bs.plm.2020.02.001
PG 36
WC Psychology, Experimental
SC Psychology
GA BQ6ZN
UT WOS:000613905100009
DA 2021-02-24
ER

PT S
AU Brown-Schmidt, S
   Naveiras, M
   De Boeck, P
   Cho, SJ
AF Brown-Schmidt, Sarah
   Naveiras, Matthew
   De Boeck, Paul
   Cho, Sun-Joo
BE Federmeier, KD
   Schotter, ER
TI Statistical modeling of intensive categorical time-series eye-tracking
   data using dynamic generalized linear mixed-effect models with crossed
   random effects
SO GAZING TOWARD THE FUTURE: ADVANCES IN EYE MOVEMENT THEORY AND
   APPLICATIONS
SE Psychology of Learning and Motivation
LA English
DT Article; Book Chapter
ID SPOKEN LANGUAGE; PERSPECTIVE-TAKING; TEMPORAL DYNAMICS;
   SPEECH-PERCEPTION; COMPREHENSION; MOVEMENTS; DOMAINS; ADAPTATION;
   RESOLUTION; CHILDREN
AB Cognitive processes unfold over time as events are experienced, thus there is a need for dynamic measures of cognitive processes. In the field of psycholinguistics, eye-gaze has emerged as popular measure of the time-course of language processing. In this book chapter, we discuss two new analytic methods based on two published technical papers (Cho, Brown-Schmidt, & Lee, 2018; Cho, Brown-Schmidt, De Boeck, & Shen, 2020). Both analytic methods are applied to data collected in the visual-world eye-tracking paradigm (Tanenhaus, Spivey-Knowlton, Eberhard, & Sedivy, 1995). Specifically, we describe two applications of a dynamic generalized linear mixed-effects model (dGLMM) with crossed random effects (random person effects and random item effects) to intensive (many time points) time-series eye-tracking data. In the dGLMM, we consider two change processes, trend and autocorrelation. In addition, we present the dGLMM for two types of categorical eye-tracking data. In one application the eye-tracking measure is treated as binary, and in the other, the eye-tracking measure is initially treated as multi-categorical and then recoded as binary variables to model multinomial processing. We discuss how these analytic methods can be used to ask and answer novel questions about dynamic cognitive processes.
C1 [Brown-Schmidt, Sarah; Naveiras, Matthew; Cho, Sun-Joo] Vanderbilt Univ, 221 Kirkland Hall, Nashville, TN 37235 USA.
   [De Boeck, Paul] Ohio State Univ, Columbus, OH 43210 USA.
   [De Boeck, Paul] Katholieke Univ Leuven, Leuven, Belgium.
RP Brown-Schmidt, S (corresponding author), Vanderbilt Univ, 221 Kirkland Hall, Nashville, TN 37235 USA.
EM sarahbrownschmidt@gmail.com
FU National Science FoundationNational Science Foundation (NSF) [BCS
   1257029, BCS 1556700]
FX This work was supported in part by National Science Foundation SES
   1851690 to Sun-Joo Cho, Sarah Brown-Schmidt, and Paul De Boeck. The
   development of the two dGLMMs described here was based on data that were
   collected and analyzed with support from National Science Foundation BCS
   1257029 and BCS 1556700 to Sarah Brown-Schmidt.
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Arnold JE, 2004, PSYCHOL SCI, V15, P578, DOI 10.1111/j.0956-7976.2004.00723.x
   Arnold JE, 2008, COGNITION, V108, P69, DOI 10.1016/j.cognition.2008.01.001
   Baayen H, 2017, J MEM LANG, V94, P206, DOI 10.1016/j.jml.2016.11.006
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Barr DJ, 2008, J MEM LANG, V59, P457, DOI 10.1016/j.jml.2007.09.002
   Barr DJ, 2008, COGNITION, V109, P18, DOI 10.1016/j.cognition.2008.07.005
   Bates D., 2018, PACKAGE LME4 LINEAR
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Brown-Schmidt S, 2015, PSYCHON B REV, V22, P833, DOI 10.3758/s13423-014-0714-2
   Chambers CG, 2002, J MEM LANG, V47, P30, DOI 10.1006/jmla.2001.2832
   CHATFIELD C, 1984, ANAL TIME SERIES INT, DOI DOI 10.1007/978-1-4899-2921-1
   CHO SJ, 2020, SUPPLEMENTARY MAT MO
   Cho SJ, 2020, PSYCHOMETRIKA, V85, P154, DOI 10.1007/s11336-020-09694-6
   Cho SJ, 2018, PSYCHOMETRIKA, V83, P751, DOI 10.1007/s11336-018-9604-2
   CLARK HH, 1973, J VERB LEARN VERB BE, V12, P335, DOI 10.1016/S0022-5371(73)80014-3
   Cook T. D., 1979, QUASIEXPERIMENTATION
   COOPER RM, 1974, COGNITIVE PSYCHOL, V6, P84, DOI 10.1016/0010-0285(74)90005-X
   Creel SC, 2008, COGNITION, V106, P633, DOI 10.1016/j.cognition.2007.03.013
   Dahan D, 2001, LANG COGNITIVE PROC, V16, P507, DOI 10.1080/01690960143000074
   Dahan D, 2008, COGNITION, V108, P710, DOI 10.1016/j.cognition.2008.06.003
   Dahan D, 2007, J MEM LANG, V57, P483, DOI 10.1016/j.jml.2007.01.001
   De Boeck P, 2012, J STAT SOFTW, V48, P1
   EBERHARD KM, 1995, J PSYCHOLINGUIST RES, V24, P409, DOI 10.1007/BF02143160
   HALLETT PE, 1986, HDB PERCEPTION HUMAN, V1, P10
   Hanna JE, 2004, COGNITIVE SCI, V28, P105, DOI 10.1016/j.cogsci.2003.10.002
   Hanna JE, 2003, J MEM LANG, V49, P43, DOI 10.1016/S0749-596X(03)00022-6
   Heller D, 2008, COGNITION, V108, P831, DOI 10.1016/j.cognition.2008.04.008
   Heller D, 2014, J MEM LANG, V70, P53, DOI 10.1016/j.jml.2013.09.008
   HSIAO C, 2014, ANAL PANEL DATA 54, DOI DOI 10.1017/CB09781139839327
   Huettig F, 2006, ACTA PSYCHOL, V121, P65, DOI 10.1016/j.actpsy.2005.06.002
   Keysar B, 2003, COGNITION, V89, P25, DOI 10.1016/S0010-0277(03)00064-7
   Magnuson JS, 2007, COGNITIVE SCI, V31, P133, DOI 10.1080/03640210709336987
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001
   McMurray B, 2019, COGNITION, V191, DOI 10.1016/j.cognition.2019.06.012
   McMurray B, 2010, COGNITIVE PSYCHOL, V60, P1, DOI 10.1016/j.cogpsych.2009.06.003
   McMurray B, 2009, J MEM LANG, V60, P65, DOI 10.1016/j.jml.2008.07.002
   Mirman D, 2008, J MEM LANG, V59, P475, DOI 10.1016/j.jml.2007.11.006
   Nilsen ES, 2009, COGNITIVE PSYCHOL, V58, P220, DOI 10.1016/j.cogpsych.2008.07.002
   Nixon JS, 2016, J MEM LANG, V90, P103, DOI 10.1016/j.jml.2016.03.005
   Oleson JJ, 2017, STAT METHODS MED RES, V26, P2708, DOI 10.1177/0962280215607411
   PECHMANN T, 1989, LINGUISTICS, V27, P89, DOI 10.1515/ling.1989.27.1.89
   Quene H, 2004, SPEECH COMMUN, V43, P103, DOI [10.1016/j.specom.2004.02.004, 10.1016/j.specom 2004.02.004]
   Quene H, 2008, J MEM LANG, V59, P413, DOI 10.1016/j.jml.2008.02.002
   R Core Team, 2020, R LANG ENV STAT COMP
   Ryskin RA, 2017, J EXP PSYCHOL LEARN, V43, P781, DOI 10.1037/xlm0000341
   Ryskin RA, 2015, J EXP PSYCHOL GEN, V144, P898, DOI 10.1037/xge0000093
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Seedorff M, 2018, J MEM LANG, V102, P55, DOI 10.1016/j.jml.2018.05.004
   Snedeker J, 2008, J MEM LANG, V58, P574, DOI 10.1016/j.jml.2007.08.001
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Tooley KM, 2010, LANG LINGUIST COMPAS, V4, P925, DOI 10.1111/j.1749-818x.2010.00249.x
   Trude AM, 2012, LANG COGNITIVE PROC, V27, P979, DOI 10.1080/01690965.2011.597153
   van Rij J, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216519832483
NR 56
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS LTD-ELSEVIER SCIENCE LTD
PI LONDON
PA 125 LONDON WALL, LONDON EC2Y 5AS, ENGLAND
SN 0079-7421
BN 978-0-12-820698-0
J9 PSYCHOL LEARN MOTIV
JI Psychol. Learn. Motiv.
PY 2020
VL 73
BP 1
EP 31
DI 10.1016/bs.plm.2020.06.004
PG 31
WC Psychology, Experimental
SC Psychology
GA BQ6ZM
UT WOS:000613904400001
DA 2021-02-24
ER

PT J
AU Howson, PJ
   Monahan, PJ
AF Howson, Phil J.
   Monahan, Philip J.
TI A method for comparing perceptual distances and areas with
   multidimensional scaling
SO METHODSX
LA English
DT Article
DE Speech perception; Linguistics; Principle Coordinate Analysis
AB This paper presents a method for adding additional statistical comparisons to multidimensional scaling (MDS). The object of study in our work is perceptual distances between speech sound categories. Typically, MDS solutions do not receive inferential statistical treatment and their visualizations present average results across numerous participants. This is problematic because it ignores inter-participant variation. To account for this variance, we have devised a simple technique for adding statistical power to the traditional MDS solution so that the distances between objects and the areas occupied by groups of objects can be compared more reliably than visual inspection of an MDS plot. We provide a method for comparing distances between two objects and for comparing the area of three or more objects. This method can be paired with varying statistical analysis to suit the researcher's needs.
   Adds statistical power to multidimensional scaling.
   Compares distances between segments.
   Compares dispersion of groups of objects in multidimensional space. (C) 2020 The Author(s). Published by Elsevier B.V.
C1 [Howson, Phil J.] Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.
   [Howson, Phil J.; Monahan, Philip J.] Univ Toronto, Dept Linguist, Toronto, ON, Canada.
   [Monahan, Philip J.] Univ Toronto Scarborough, Ctr French Linguist, Toronto, ON, Canada.
   [Monahan, Philip J.] Univ Toronto Scarborough, Dept Psychol, Toronto, ON, Canada.
RP Howson, PJ (corresponding author), Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.; Howson, PJ (corresponding author), Univ Toronto, Dept Linguist, Toronto, ON, Canada.
EM philh@uoregon.edu; philip.monahan@utoronto.ca
OI Monahan, Philip/0000-0001-8637-1889
FU Social Sciences and Humanities Research Council (SSHRC) of CanadaSocial
   Sciences and Humanities Research Council of Canada (SSHRC)
   [771-2015-0048, IDG 430-15-00647]
FX This work was supported by the Social Sciences and Humanities Research
   Council (SSHRC) of Canada (#771-2015-0048) to Phil J. Howson and (IDG
   430-15-00647) to Philip J. Monahan.
CR Braden B., 1986, COLL MATH J, V17, P326, DOI [10.2307/2686282, DOI 10.2307/2686282]
   Cox T.F., 2001, MULTIDIMENSIONAL SCA
   CREELMAN CD, 1979, J EXP PSYCHOL HUMAN, V5, P146, DOI 10.1037/0096-1523.5.1.146
   GOWER JC, 1966, BIOMETRIKA, V53, P325, DOI 10.2307/2333639
   GOWER JC, 1986, J CLASSIF, V3, P5, DOI 10.1007/BF01896809
   Howson PJ, 2019, SPEECH COMMUN, V115, P15, DOI 10.1016/j.specom.2019.10.002
   Johnson K., 2008, QUANTITATIVE METHODS
   MacMillan NA, 1991, DETECTION THEORY USE
   MEAD A, 1992, STATISTICIAN, V41, P27, DOI 10.2307/2348634
   Meister A.L.F., 1769, NOVI COMM SOC REG SC, VI, P144
   PADGETT J, 2007, J SLAVIC LINGUISTICS, V15, P291
   R Development Core Team, 2017, R LANG ENV STAT COMP
   RAMSAY JO, 1969, PSYCHOMETRIKA, V34, P167, DOI 10.1007/BF02289342
   RATCLIFF R, 1993, PSYCHOL BULL, V114, P510, DOI 10.1037/0033-2909.114.3.510
   SHEPARD RN, 1980, SCIENCE, V210, P390, DOI 10.1126/science.210.4468.390
   SOLI SD, 1979, J ACOUST SOC AM, V66, P46, DOI 10.1121/1.382972
NR 16
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
EI 2215-0161
J9 METHODSX
JI MethodsX
PY 2020
VL 7
AR 100790
DI 10.1016/j.mex.2020.100790
PG 8
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA PS0YV
UT WOS:000607658800017
PM 32042601
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Pulvirenti, G
AF Pulvirenti, Giuliana
TI NATURALISING THE FACULTY OF LANGUAGE SOME REFLECTIONS ON THE ROLE OF
   MORPHOLOGICAL STRUCTURES AND DEVELOPMENTAL PROCESSES IN THE EVOLUTION OF
   PRIMATE VOCAL BEHAVIORS
SO RETI SAPERI LINGUAGGI-ITALIAN JOURNAL OF COGNITIVE SCIENCES
LA English
DT Article
DE Language Evolution; Primate Ontogeny; Vocal Development; Morphological
   Constraints; Heterochrony; Early Social Interactions
ID FACE RECOGNITION; NEONATAL CHIMPANZEES; SPEECH-PERCEPTION;
   PAN-TROGLODYTES; HUMAN NEWBORNS; ACQUISITION; INFANTS; PLASTICITY;
   IMITATION; ATTENTION
AB Language is a complex human trait made of several components at various levels of biological organization. Given such a complexity, a pluralistic approach to the study of the biological underpinnings of language is required. In this framework, the comparative analysis of primates' morphological structures and developmental processes may represent a fundamental tool in order to identify bodily constraints and heterocronic variations that may have favoured or precluded the emergence of language in the primate lineage.These aspects have been recognised among new Evo/Devo and embodied approaches to cognition (in contrast to genecentric, cerebrocentric and computational ones). In light of these considerations, selected data are compared and discussed in relation to the development of early socio-communicative skills and vocal behaviors of primate species.
C1 [Pulvirenti, Giuliana] Univ Messina, Dept Cognit Sci, Via Concez 6-8, I-98122 Messina, Italy.
RP Pulvirenti, G (corresponding author), Univ Messina, Dept Cognit Sci, Via Concez 6-8, I-98122 Messina, Italy.
EM giuliana.pulvirenti@unime.it
CR Aldridge MA, 1999, DEVELOPMENTAL SCI, V2, P42, DOI 10.1111/1467-7687.00052
   Balari S., 2013, COMPUTATIONAL PHENOT
   BARD KA, 1992, INFANT BEHAV DEV, V15, P43, DOI 10.1016/0163-6383(92)90005-Q
   Bard KA, 2007, ANIM COGN, V10, P233, DOI 10.1007/s10071-006-0062-3
   Behme C, 2008, PHILOS PSYCHOL, V21, P641, DOI 10.1080/09515080802412321
   Belin P, 2006, PHILOS T R SOC B, V361, P2091, DOI 10.1098/rstb.2006.1933
   Benitez-Burraco Antonio, 2014, Biology Theory, V9, P122, DOI 10.1007/s13752-014-0164-0
   Carroll SB, 2000, CELL, V101, P577, DOI 10.1016/S0092-8674(00)80868-5
   Chandrasekaran C, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002165
   Chow CP, 2015, P ROY SOC B-BIOL SCI, V282, DOI 10.1098/rspb.2015.0069
   Coulon M, 2013, INFANCY, V18, P782, DOI 10.1111/infa.12001
   de Boisferon AH, 2018, J EXP CHILD PSYCHOL, V172, P189, DOI 10.1016/j.jecp.2018.03.009
   Einspieler C, 2008, Z PSYCHOL, V216, P147, DOI 10.1027/0044-3409.216.3.147
   Fitch WT, 2018, ANNU REV LINGUIST, V4, P255, DOI 10.1146/annurev-linguistics-011817-045748
   Fitch WT, 2012, EVOL BIOL, V39, P613, DOI 10.1007/s11692-012-9162-y
   Fitch WT, 2010, EVOLUTION OF LANGUAGE, PROCEEDINGS, P137
   Gervain J, 2010, ANNU REV PSYCHOL, V61, P191, DOI 10.1146/annurev.psych.093008.100408
   Gomez-Robles A, 2015, P NATL ACAD SCI USA, V112, P14799, DOI 10.1073/pnas.1512646112
   Guasti M.T., 2007, ACQUISIZIONE LINGUAG
   HALLOCK MB, 1989, INT J BEHAV DEV, V12, P527, DOI 10.1177/016502548901200408
   Hata T., 2010, DONALD SCH J ULTRASO, V4, P233
   Heimbauer LA, 2011, CURR BIOL, V21, P1210, DOI 10.1016/j.cub.2011.06.007
   Hoistad M, 2009, FRONT NEUROANAT, V3, DOI 10.3389/neuro.05.009.2009
   HOPKINS WD, 1991, INT J PRIMATOL, V12, P559, DOI 10.1007/BF02547670
   Hopkins WD, 2007, ANIM BEHAV, V73, P281, DOI 10.1016/j.anbehav.2006.08.004
   Jessell T.M., 2006, NEUROSCIENCE PRINCIP
   Kano F, 2010, ANIM BEHAV, V79, P227, DOI 10.1016/j.anbehav.2009.11.003
   Kawai N., 2006, COGNITIVE DEV CHIMPA
   Koda H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071432
   Kojima S, 2003, PRIMATES, V44, P225, DOI 10.1007/s10329-002-0014-8
   Kojima S., 2006, COGNITIVE DEV CHIMPA
   Kugiumutzakis G., 1999, IMITATION INFANCY
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kurjak A, 2005, CROAT MED J, V46, P772
   Lameira AR, 2016, SCI REP-UK, V6, DOI 10.1038/srep30315
   Lattenkamp EZ, 2018, CURR OPIN BEHAV SCI, V21, P209, DOI 10.1016/j.cobeha.2018.04.007
   Leigh SR, 2004, AM J PRIMATOL, V62, P139, DOI 10.1002/ajp.20012
   Lewkowicz DJ, 2006, P NATL ACAD SCI USA, V103, P6771, DOI 10.1073/pnas.0602027103
   Lieberman Philip, 2006, EVOLUTIONARY BIOL LA
   Liu X., 2012, GENOME RES, P1
   Marchetto MC, 2019, ELIFE, V8, DOI 10.7554/eLife.37527
   Matsuzawa T, 2006, COGNITIVE DEV CHIMPA
   McNamara Kenneth J., 2012, Evolution Education and Outreach, V5, P203
   Meltzoff A.N., 1988, CHILD DEV, V54, P702
   Miller DJ, 2012, P NATL ACAD SCI USA, V109, P16480, DOI 10.1073/pnas.1117943109
   Minelli A., 2003, DEV ANIMAL FORM ONTO
   Mora-Bermudez F, 2016, ELIFE, V5, DOI 10.7554/eLife.18683
   Myowa-Yamakoshi M, 2004, DEVELOPMENTAL SCI, V7, P437, DOI 10.1111/j.1467-7687.2004.00364.x
   Nishimura T, 2006, J HUM EVOL, V51, P244, DOI 10.1016/j.jhevol.2006.03.005
   Noe A., 2009, OUT OUR HEADS WHY YO
   Otsuka Y, 2014, JPN PSYCHOL RES, V56, P76, DOI 10.1111/jpr.12024
   PASCALIS O, 1995, INFANT BEHAV DEV, V18, P79, DOI 10.1016/0163-6383(95)90009-8
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Pena M, 2003, P NATL ACAD SCI USA, V100, P11702, DOI 10.1073/pnas.1934290100
   Pennisi A, 2016, PERSP PRAGMAT PHILO, P1, DOI 10.1007/978-3-319-47688-9
   Ploeger A, 2011, WIRES COGN SCI, V2, P429, DOI 10.1002/wcs.137
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Ramus F, 2000, SCIENCE, V288, P349, DOI 10.1126/science.288.5464.349
   Sakai T., 2012, P R SOC B, V280
   Schel AM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076674
   Sherwood CC, 2017, ANNU REV ANTHROPOL, V46, P399, DOI 10.1146/annurev-anthro-102215-100009
   Simion F, 1998, J EXP PSYCHOL HUMAN, V24, P1399, DOI 10.1037/0096-1523.24.5.1399
   Simpson EA, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X16001965
   Sousa AMM, 2017, CELL, V170, P226, DOI 10.1016/j.cell.2017.06.036
   Sugita Y, 2008, P NATL ACAD SCI USA, V105, P394, DOI 10.1073/pnas.0706079105
   Takeshita H., 2016, FETAL DEV, P67, DOI [10.1007/978, DOI 10.1007/978]
   Takeshita H., 2006, COGNITIVE DEV CHIMPA
   Tomalski P, 2013, EUR J DEV PSYCHOL, V10, P611, DOI 10.1080/17405629.2012.728076
   Tomalski P, 2009, NEUROREPORT, V20, P1309, DOI 10.1097/WNR.0b013e32832f0acd
   Tomonaga M, 2004, JPN PSYCHOL RES, V46, P227, DOI 10.1111/j.1468-5584.2004.00254.x
   Vouloumanos A, 2010, CHILD DEV, V81, P517, DOI 10.1111/j.1467-8624.2009.01412.x
   West-Eberhard MJ, 2005, P NATL ACAD SCI USA, V102, P6543, DOI 10.1073/pnas.0501844102
   Young GS, 2009, DEVELOPMENTAL SCI, V12, P798, DOI 10.1111/j.1467-7687.2009.00833.x
NR 74
TC 0
Z9 0
U1 0
U2 0
PU SOC ED IL MULINO
PI BOLOGNA
PA STRADA MAGGIORE 37, 40125 BOLOGNA, ITALY
SN 1826-8889
EI 2279-7777
J9 RETI SAPERI LINGUAGG
JI Reti Saperi Linguaggi
PD JAN-JUN
PY 2020
VL 7
IS 1
BP 185
EP 203
DI 10.12832/98426
PG 19
WC Philosophy
SC Philosophy
GA OO9VQ
UT WOS:000587724000010
DA 2021-02-24
ER

PT J
AU Lopez-Beltran, P
   Carlson, MT
AF Lopez-Beltran, Priscila
   Carlson, Matthew T.
TI How usage-based approaches to language can contribute to a unified
   theory of heritage grammars
SO LINGUISTICS VANGUARD
LA English
DT Article
DE usage-based; heritage speakers; variation; experience; SLA; incomplete;
   heritage grammars; sociolinguistics
ID INCOMPLETE ACQUISITION; INDIVIDUAL-DIFFERENCES; SPEECH-PERCEPTION;
   SPEAKERS; SPANISH; COMPREHENSION; ATTAINMENT; EXPOSURE; MODEL
AB In this paper, we argue that usage-based approaches to grammar, which specify how linguistic experience leads to grammatical knowledge through the interplay of cognitive, linguistic and social factors, have a central role to play in contributing to a unified theory of heritage language acquisition and processing with much greater explanatory adequacy. We discuss how this approach (1) offers solutions to long- standing problems in the field of heritage language research, (2) links phenomena that have been explained under diverging theoretical perspectives and (3) leads to new hypotheses and testable predictions about what we can expect heritage speakers acquire from their input. We conclude that usage-based approaches are crucial to move away from deficit-oriented perspectives on heritage grammars by taking into consideration how variation in sociolinguistic experience gives rise to differences in how heritage speakers acquire and use their language.
C1 [Lopez-Beltran, Priscila] Penn State Univ, Dept Spanish Italian & Portuguese, 442 Burrowes Bldg, University Pk, PA 16082 USA.
   [Carlson, Matthew T.] Penn State Univ, University Pk, PA 16082 USA.
RP Lopez-Beltran, P (corresponding author), Penn State Univ, Dept Spanish Italian & Portuguese, 442 Burrowes Bldg, University Pk, PA 16082 USA.
EM pul57@psu.edu
CR Au TKF, 2002, PSYCHOL SCI, V13, P238, DOI 10.1111/1467-9280.00444
   Bayram F, 2019, STUD SECOND LANG ACQ, V41, P257, DOI 10.1017/S0272263119000287
   Beatty-Martinez AL, 2017, J MEM LANG, V95, P173, DOI 10.1016/j.jml.2017.04.002
   Benmamoun E, 2013, THEOR LINGUIST, V39, P129, DOI 10.1515/tl-2013-0009
   Bookhamer Kevin, 2013, THESIS
   Bybee J, 2006, LANGUAGE, V82, P711, DOI 10.1353/lan.2006.0186
   Bybee Joan L., 2013, OXFORD HDB CONSTRUCT, P49, DOI DOI 10.1093/OXFORDHB/9780195396683.013.0004
   Cacoullos Rena T., 2018, NEW MEXICO SPANISH E
   Carreira M, 2011, FOREIGN LANG ANN, V44, P40, DOI 10.1111/j.1944-9720.2010.01118.x
   Carreira Maria, 2004, HERITAGE LANGUAGE J, V2, P1
   Carroll SE, 2017, BILING-LANG COGN, V20, P3, DOI 10.1017/S1366728915000863
   Chang CB, 2012, J PHONETICS, V40, P249, DOI 10.1016/j.wocn.2011.10.007
   Cho Grace, 2000, BILINGUAL RES J, V24, P333, DOI DOI 10.1080/15235882.2000.10162773
   Cho Grace Kyung-Sook, 1997, LANG CULT CURRIC, V10, P106, DOI [10.1080/07908319709525244, DOI 10.1080/07908319709525244]
   Dabrowska E, 2008, J MEM LANG, V58, P931, DOI 10.1016/j.jml.2007.11.005
   Dabrowska E, 2006, LANG SCI, V28, P604, DOI 10.1016/j.langsci.2005.11.014
   Dabrowska E, 2012, LINGUIST APPROACH BI, V2, P219, DOI 10.1075/lab.2.3.01dab
   Dajbrowska E, 2008, LINGUISTICS, V46, P629, DOI 10.1515/LING.2008.021
   Dominguez L, 2019, STUD SECOND LANG ACQ, V41, P241, DOI 10.1017/S0272263119000160
   Dussias PE, 2007, BILING-LANG COGN, V10, P101, DOI 10.1017/S1366728906002847
   Erker D, 2016, LINGUA, V172, P131, DOI 10.1016/j.lingua.2015.10.011
   Felser C, 2020, BILING-LANG COGN, V23, P23, DOI 10.1017/S1366728919000397
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   Flores C, 2020, BILING-LANG COGN, V23, P25, DOI 10.1017/S1366728919000464
   Giancaspro David, 2017, THESIS
   Goldberg Adele, 2006, CONSTRUCTIONS WORK N
   Hall JK, 2006, APPL LINGUIST, V27, P220, DOI 10.1093/applin/aml013
   Hartanto A, 2016, COGNITION, V150, P10, DOI 10.1016/j.cognition.2016.01.016
   Hopper Paul J., 1979, SYNTAX SEMANTICS, P213
   Hopper Paul J., 1988, LINGUISTICS CONTEXT, P117
   Imada T, 2006, NEUROREPORT, V17, P957, DOI 10.1097/01.wnr.0000223387.51704.89
   Johns MA, 2019, INT J BILINGUAL, V23, P584, DOI 10.1177/1367006917752570
   Kam CLH, 2005, LANG LEARN DEV, V1, P151, DOI 10.1207/s15473341lld0102_3
   Keller F, 2000, PROCEEDINGS OF THE TWENTY-SECOND ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P747
   Kim JS, 2015, 2015 INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ARTIFICIAL INTELLIGENCE (CAAI 2015), P106
   Knightly LM, 2003, J ACOUST SOC AM, V114, P465, DOI 10.1121/1.1577560
   Kuhl P, 2008, ANNU REV NEUROSCI, V31, P511, DOI 10.1146/annurev.neuro.30.051606.094321
   Kupisch T, 2018, INT J BILINGUAL, V22, P564, DOI 10.1177/1367006916654355
   LaCasse Dora, 2018, THESIS
   LEGATE JA, 2007, LANGUAGE ACQUISITION, V0014
   Lukyanchenko A, 2011, PROC ANN BUCLD, P414
   Lynch Andrew, 1999, SUBJUNCTIVE MIAMI CU
   MacDonald MC, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00226
   MacDonald MC, 1999, CARN S COGN, P177
   Marrocco Mary Anne Wilkinson, 1972, THESIS
   Martin Butragueno Pedro, 2011, CORPUS SOCIOLINGUIST
   McCarty TL, 1997, TEACHING INDIGENOUS LANGUAGES, P85
   Meisel JM, 2020, BILING-LANG COGN, V23, P33, DOI 10.1017/S1366728919000452
   Montrul S., 2016, ACQUISITION HERITAGE
   Montrul S, 2014, BILING-LANG COGN, V17, P118, DOI 10.1017/S1366728913000114
   Montrul S, 2009, INT J BILINGUAL, V13, P239, DOI 10.1177/1367006909339816
   Montrul Silvina, 2007, SPANISH CONTACT POLI, P23, DOI 10.1075/impact.22.04mon
   Mora M., 2006, SPAN CONTEXT, V3, DOI [https://doi.org/10.1075/sic.3.2.04mor, DOI 10.1075/SIC.3.2.04MOR]
   Mora Marie T., 2005, SW J LINGUISTICS, V24, P127
   Flores CMM, 2015, LINGUA, V164, P251, DOI 10.1016/j.lingua.2014.09.008
   Ocampo Francisco A., 1989, SPANISH US SOCIOLING, P39
   Oh JS, 2010, J CHILD LANG, V37, P1123, DOI 10.1017/S0305000909990286
   Otheguy Ricardo, 2013, LING S ROM LANG NEW
   Perez-Cortes Silvia, 2016, THESIS
   Perez-Cortes Silvia, 2019, LANGUAGES, V81, P2, DOI [10.3390/languages4040081., DOI 10.3390/LANGUAGES4040081]
   Pires A, 2009, INT J BILINGUAL, V13, P211, DOI 10.1177/1367006909339806
   Polinsky M., 2008, HERITAGE LANGUAGE J, V6, P40, DOI DOI 10.1017/S1366728909990320
   Polinsky M, 2020, BILING-LANG COGN, V23, P4, DOI 10.1017/S1366728919000245
   Polinsky M, 2011, STUD SECOND LANG ACQ, V33, P305, DOI 10.1017/S027226311000077X
   Polinsky M, 2007, LANG LINGUIST COMPAS, V1, DOI 10.1111/j.1749-818x.2007.00022.x
   Poplack S, 2018, MANUALS ROMANCE LING, V18, P217, DOI 10.1515/9783110365955-009
   Putnam MT, 2013, LINGUIST APPROACH BI, V3, P478, DOI 10.1075/lab.3.4.04put
   Rothman J, 2009, INT J BILINGUAL, V13, P155, DOI 10.1177/1367006909339814
   Schmid MS, 2013, INT J BILINGUAL, V17, P675, DOI 10.1177/1367006912454619
   Seton Bregtje, 2016, CAMBRIDGE HDB LINGUI, P338, DOI DOI 10.1017/CB09781107425965.016
   Silva-Corvalan Carmen, 1994, LANG VAR CHANGE, V6, P255, DOI DOI 10.1017/S095439450000168X
   Sorace A, 2005, LINGUA, V115, P1497, DOI 10.1016/j.lingua.2004.07.002
   Street JA, 2010, LINGUA, V120, P2080, DOI 10.1016/j.lingua.2010.01.004
   Tamargo REG, 2016, J MEM LANG, V89, P138, DOI 10.1016/j.jml.2015.12.002
   TORRES CACOULLOS R., 2017, MOENIA, V23, P73
   Treffers-Daller J, 2011, INT J BILINGUAL, V15, P147, DOI 10.1177/1367006910381186
   Valdes Guadalupe, 2001, HDB HERITAGE COMMUNI, P41
   Valdes Kroff Jorge R., 2012, THESIS
   Villa DJ, 2009, SPAN CONTEXT, V6, P26, DOI 10.1075/sic.6.1.03vil
   Wiley T. G, 2010, BILINGUAL RES J, V24, piii, DOI [10.1080/15235882.2000.10162770, DOI 10.1080/15235882.2000.10162770]
   WILEY T. G., 2001, HERITAGE LANGUAGES A, P29
   Yang C, 2016, PRICE OF LINGUISTIC PRODUCTIVITY: HOW CHILDREN LEARN TO BREAK THE RULES OF LANGUAGE, P1, DOI 10.7551/mitpress/9780262035323.001.0001
NR 82
TC 0
Z9 0
U1 0
U2 0
PU WALTER DE GRUYTER GMBH
PI BERLIN
PA GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY
SN 2199-174X
J9 LINGUIST VANGUARD
JI Linguist. Vanguard
PD JAN
PY 2020
VL 6
IS 1
AR 20190072
DI 10.1515/lingvan-2019-0072
PG 12
WC Linguistics; Language & Linguistics
SC Linguistics
GA OO4MA
UT WOS:000587353600002
DA 2021-02-24
ER

PT J
AU Goncalves, AR
   Silveira, R
AF Goncalves, Alison Roberto
   Silveira, Rosane
TI ORTHOGRAPHIC EFFECTS IN SPEECH PERCEPTION: EVIDENCE FROM AN AUDITORY
   LEXICAL DECISION TASK WITH BRAZILIAN SPEAKERS OF ENGLISH
SO REVISTA DA ANPOLL
LA English
DT Article
DE Speech Perception; Orthography; Lexical Decision Task
ID LANGUAGE; WORDS; KNOWLEDGE
AB The present study investigated whether orthographic effects arise in a speech perception task performed by Brazilian speakers of English. The study employed an artificial lexicon that simulated opaque and transparent grapho-phonic English relations in nuclear position (e.g., deit, toud). Subjects were compelled to learn this new set of words through a repeated-exposure training paradigm in which they were initially introduced to phonological forms associated with their visual pairings, followed by associations to their orthographic representations. An auditory lexical decision task was taken after training. Results indicated that orthographic consistency did not affect subjects' latencies with the trained lexicon, although their reaction times were relatively longer with opaque items. However, orthography influenced latencies registered for untrained items in the task. We entertained that having to conduct lexical analysis with incoming unfamiliar auditory items compelled subjects to recruit orthography as a mechanism to aid lexical analysis. Orthographic recruitment was thus conceived as a strategic process that assists lexical decision in timed auditory tasks.
C1 [Goncalves, Alison Roberto] Univ Fed Parana, Curitiba, Parana, Brazil.
   [Silveira, Rosane] Univ Fed Santa Catarina, Florianopolis, SC, Brazil.
RP Goncalves, AR (corresponding author), Univ Fed Parana, Curitiba, Parana, Brazil.
EM arg@ufpr.br; rosanesilveira@hotmail.com
OI Silveira, Rosane/0000-0003-0329-0376; Roberto Goncalves,
   Alison/0000-0003-0959-7053
CR Bartolotti J, 2017, LANG LEARN, V67, P110, DOI 10.1111/lang.12200
   Bassetti B, 2015, APPL PSYCHOLINGUIST, V36, P1, DOI 10.1017/S0142716414000393
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Cutler A, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00018
   Cutler A, 2010, LANG SPEECH, V53, P307, DOI 10.1177/0023830910371445
   Damian MF, 2009, EUR J COGN PSYCHOL, V21, P581, DOI 10.1080/09541440801896007
   ESCUDERO P., 2011, OXFORD HDB LAB PHONO, P407
   Escudero P, 2008, J PHONETICS, V36, P345, DOI 10.1016/j.wocn.2007.11.002
   Escudero P, 2015, APPL PSYCHOLINGUIST, V36, P7, DOI 10.1017/S014271641400040X
   Escudero P, 2014, BILING-LANG COGN, V17, P384, DOI 10.1017/S1366728913000436
   Escudero P, 2010, LANG SPEECH, V53, P343, DOI 10.1177/0023830910371447
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   Goldinger SD, 1996, LANG COGNITIVE PROC, V11, P559, DOI 10.1080/016909696386944
   Goncalves Ana Claudia, 2017, THESIS
   Katz L, 2001, READ WRIT, V14, P297, DOI 10.1023/A:1011165407770
   Kolinsky R., 2015, OXFORD HDB READING, P377, DOI DOI 10.1093/OXFORDHB/9780199324576.013.29
   Kuhl PK, 2000, P NATL ACAD SCI USA, V97, P11850, DOI 10.1073/pnas.97.22.11850
   Lachaud CM, 2011, APPL PSYCHOLINGUIST, V32, P389, DOI 10.1017/S0142716410000457
   Marian V, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043230
   MARSLENWILSON W, 1989, J EXP PSYCHOL HUMAN, V15, P576, DOI 10.1037/0096-1523.15.3.576
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Pytlyk C., MODERN LANGUAGE J, V95, P541
   Qu QQ, 2019, MEM COGNITION, V47, P326, DOI 10.3758/s13421-018-0868-7
   Rastle K, 2011, J EXP PSYCHOL LEARN, V37, P1588, DOI 10.1037/a0024833
   Reis A, 1997, J INT NEUROPSYCH SOC, V3, P444, DOI 10.1017/S135561779700444X
   Salemyr M, 2015, APPL PSYCHOLINGUIST, P1
   Sanz C., 2015, IMPLICIT EXPLICIT LE, P301
   Simon E, 2010, LANG SCI, V32, P380, DOI 10.1016/j.langsci.2009.07.001
   Taft M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00140
   Tamminen J, 2015, COGNITIVE PSYCHOL, V79, P1, DOI 10.1016/j.cogpsych.2015.03.003
   Taylor JSH, 2017, J EXP PSYCHOL GEN, V146, P826, DOI 10.1037/xge0000301
   Van Assche E, 2016, J MEM LANG, V89, P37, DOI 10.1016/j.jml.2016.02.003
   Veivo O, 2013, BILING-LANG COGN, V16, P864, DOI 10.1017/S1366728912000600
   Vouloumanos A, 2007, DEVELOPMENTAL SCI, V10, P159, DOI 10.1111/j.1467-7687.2007.00549.x
   Werker J. F., 2013, OXFORD HDB DEV PSYCH, P909
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2018, APPL PSYCHOLINGUIST, V39, P703, DOI 10.1017/S0142716418000152
   Wong P. C. M, 2016, PLOS ONE, V11
   Yoncheva YN, 2013, BRAIN LANG, V124, P238, DOI 10.1016/j.bandl.2012.12.013
   Zhang L. J., 2009, LANGUAGE INVITATION, V4, P85
NR 40
TC 0
Z9 0
U1 0
U2 0
PU ASSOC NAC POS-GRADUACAO PESQUISA LETRAS & LINGUISTICA
PI BRASILIA
PA ASSOC NAC POS-GRADUACAO PESQUISA LETRAS & LINGUISTICA, BRASILIA, 00000,
   BRAZIL
SN 1414-7564
EI 1982-7830
J9 REV ANPOLL
JI Rev. Anpoll
PD JAN-MAY
PY 2020
VL 51
IS 1
BP 153
EP 169
DI 10.18309/anp.v1i51.1372
PG 17
WC Language & Linguistics
SC Linguistics
GA LN0DM
UT WOS:000532616400014
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Pan, X
   Bao, Y
   Zhu, YT
   Dai, HY
   Zhang, JF
AF Pan, Xiang
   Bao, Yue
   Zhu, Yiting
   Dai, Huangyu
   Zhang, Jiangfan
TI Deconvolved Conventional Beamforming and Adaptive Cubature Kalman Filter
   Based Distant Speech Perception System
SO IEEE ACCESS
LA English
DT Article
DE Adaptation models; Kalman filters; Tracking; Array signal processing;
   Speech enhancement; Direction-of-arrival estimation; Numerical models;
   Cubature Kalman filter; deconvolved conventional beamforming; improved
   current statistical motion model; maneuvering speech source; speech
   perception system
ID MANEUVERING TARGET TRACKING; MODEL
AB A spatial-temporal processing framework integrated of speech enhancement and speech tracking is proposed in this paper for distant speech perception. First, weak speech signals are enhanced by the deconvolved conventional beamforming (DCBF) with a microphone array. By virtue of the narrow beamwidth and low sidelobes of the DCBF, the competing sources can be effectively suppressed without introducing extra speech distortion. Second, with the accurate bearing provided by the DCBF, the Cubature Kalman filter can be utilized to track the speech source of interest. By introducing a scaling factor in the current statistical motion model, a new tracking algorithm is proposed which is suitable for both maneuvering and nonmaneuvering speech sources. The introduced scaling factor can be adaptively adjusted to improve the tracking performance of the proposed algorithm for different motion models. Numerical results show that the proposed algorithm can provide better tracking performance than the conventional one. In particular, the tracking root mean square error can be reduced by half for some cases.
C1 [Pan, Xiang; Bao, Yue; Zhu, Yiting; Dai, Huangyu] Zhejiang Univ, Sch Informat Sci & Elect Engn, Hangzhou 310027, Peoples R China.
   [Zhang, Jiangfan] Missouri Univ Sci & Technol, Dept Elect & Comp Engn, Rolla, MO 65401 USA.
RP Zhang, JF (corresponding author), Missouri Univ Sci & Technol, Dept Elect & Comp Engn, Rolla, MO 65401 USA.
EM jiangfanzhang@mst.edu
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41776108, 61571397, 61171148]; National Key
   Research Program of China [2017YFC0306901]; Cynthia Tang Endowment in
   Computer Engineering, Missouri University of Science and Technology,
   Rolla, MO, USA
FX The work of Xiang Pan, Yue Bao, and Yiting Zhu was supported in part by
   the National Natural Science Foundation of China under Grant 41776108,
   Grant 61571397, and Grant 61171148; and in part by the National Key
   Research Program of China under Grant 2017YFC0306901. The work of
   Jiangfan Zhang was supported in part by the Cynthia Tang Endowment in
   Computer Engineering, Missouri University of Science and Technology,
   Rolla, MO, USA.
CR Akca A, 2019, IFAC PAPERSONLINE, V52, P73, DOI 10.1016/j.ifacol.2019.06.013
   Arasaratnam I, 2009, IEEE T AUTOMAT CONTR, V54, P1254, DOI 10.1109/TAC.2009.2019800
   Blahut R. E., 2004, THEORY REMOTE IMAGE
   Chen SY, 2012, IEEE T IND ELECTRON, V59, P4409, DOI 10.1109/TIE.2011.2162714
   Daum F, 2005, IEEE AERO EL SYS MAG, V20, P57, DOI 10.1109/MAES.2005.1499276
   Eltoukhy M, 2020, IEEE ACCESS, V8, P94176, DOI 10.1109/ACCESS.2020.2995672
   Habets EAP, 2012, IEEE T AUDIO SPEECH, V20, P854, DOI 10.1109/TASL.2011.2166958
   Khoubrouy SA, 2016, IEEE SIGNAL PROC LET, V23, P1344, DOI 10.1109/LSP.2016.2592683
   Kumatani K, 2012, P APSIPA ANN SUMM C, P1
   Kumatani K, 2012, IEEE SIGNAL PROC MAG, V29, P127, DOI 10.1109/MSP.2012.2205285
   Leong PH, 2013, IEEE T AERO ELEC SYS, V49, P1161, DOI 10.1109/TAES.2013.6494405
   [李辉 Li Hui], 2006, [西北工业大学学报, Journal of Northwestern Polytechnical University], V24, P354
   Li XR, 2005, IEEE T AERO ELEC SYS, V41, P1255, DOI 10.1109/TAES.2005.1561886
   Li XR, 2003, IEEE T AERO ELEC SYS, V39, P1333, DOI 10.1109/TAES.2003.1261132
   Naylor PA, 2010, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-84996-056-4
   Nemer Elias, 2009, 2009 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), P177, DOI 10.1109/ASPAA.2009.5346518
   Niwa K, 2016, IEEE-ACM T AUDIO SPE, V24, P1785, DOI 10.1109/TASLP.2016.2585879
   O'Sullivan JA, 1998, IEEE T INFORM THEORY, V44, P2094, DOI 10.1109/18.720533
   Sadhu S, 2006, SIGNAL PROCESS, V86, P3769, DOI 10.1016/j.sigpro.2006.03.006
   Schwartz B, 2015, IEEE-ACM T AUDIO SPE, V23, P394, DOI 10.1109/TASLP.2014.2372342
   Swietojanski P, 2014, IEEE SIGNAL PROC LET, V21, P1120, DOI 10.1109/LSP.2014.2325781
   Visina R, 2018, IEEE T AERO ELEC SYS, V54, P1404, DOI 10.1109/TAES.2018.2793019
   WAX M, 1984, IEEE T ACOUST SPEECH, V32, P817, DOI 10.1109/TASSP.1984.1164400
   Wu K, 2017, IEEE-ACM T AUDIO SPE, V25, P1384, DOI 10.1109/TASLP.2017.2693566
   Xu LF, 2016, IEEE T AERO ELEC SYS, V52, P122, DOI 10.1109/TAES.2015.140423
   Yang TC, 2018, IEEE J OCEANIC ENG, V43, P160, DOI 10.1109/JOE.2017.2680818
   Zhang C, 2010, CONF REC ASILOMAR C, P1707, DOI 10.1109/ACSSC.2010.5757831
   [张卓然 Zhang Zhuoran], 2017, [计算机工程与应用, Computer Engineering and Application], V53, P124
   ZHOU H, 1984, J GUID CONTROL DYNAM, V7, P596, DOI 10.2514/3.19900
NR 29
TC 0
Z9 0
U1 2
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 187948
EP 187958
DI 10.1109/ACCESS.2020.3030814
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA OI8ZF
UT WOS:000583558800001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Yuan, H
   Segers, E
   Verhoeven, L
AF Yuan, Han
   Segers, Eliane
   Verhoeven, Ludo
TI Factors affecting L2 phonological awareness in Chinese-Dutch
SO WRITTEN LANGUAGE AND LITERACY
LA English
DT Article
DE phonological awareness; Chinese-Dutch children; speech decoding;
   language transfer
ID CROSS-LANGUAGE TRANSFER; DEVELOPMENTAL DYSLEXIA; SPEECH-PERCEPTION;
   LITERACY SKILLS; CHILDREN; ENGLISH; ACQUISITION; WORDS; REPRESENTATIONS;
   BILINGUALISM
AB The present study compared the relationship between Dutch phonological awareness (rhyme awareness, initial phoneme isolation), Dutch speech decoding and Dutch receptive vocabulary in two groups in different linguistic environments: 30 Mandarin Chinese-Dutch bilingual children and 24 monolingual Dutch peers. Chinese vocabulary and phonological awareness were taken into account in the bilingual group. Bilingual children scored below their Dutch monolingual counterparts on all Dutch tasks. In the bilingual group, Dutch rhyme awareness was predicted by Dutch speech decoding, both directly, and indirectly via Dutch receptive vocabulary. When adding Chinese proficiency to the model, Chinese rhyme awareness was found to mediate the relationship between Dutch speech decoding and Dutch rhyme awareness. It can thus be concluded that second language (L2) phonological awareness in Chinese-Dutch kindergartners is affected by their L2 speech and vocabulary level, on the one hand, and their level of phonological awareness in the first language (L1).
C1 [Yuan, Han] Radboud Univ Nijmegen, Behav Sci Inst, POB 9104, NL-6500 HE Nijmegen, Netherlands.
   [Segers, Eliane; Verhoeven, Ludo] Radboud Univ Nijmegen, Nijmegen, Netherlands.
   [Segers, Eliane] Univ Twente, Enschede, Netherlands.
   [Verhoeven, Ludo] Univ Curacao, Willemstad, Neth Antilles.
RP Yuan, H (corresponding author), Radboud Univ Nijmegen, Behav Sci Inst, POB 9104, NL-6500 HE Nijmegen, Netherlands.
EM H.yuan@pwo.ru.nl; e.segers@pwo.ru.nl; L.Verhoeven@pwo.ru.nl
FU China scholarship councilChina Scholarship Council [201608340056]
FX This research was supported by China scholarship council (201608340056).
CR Anthony JL, 2003, READ RES QUART, V38, P470, DOI 10.1598/RRQ.38.4.3
   Bialystok E, 2003, APPL PSYCHOLINGUIST, V24, P27, DOI 10.1017/S014271640300002X
   Bialystok E., 2001, BILINGUALISM DEV LAN
   Bialystok E, 2007, APPL PSYCHOLINGUIST, V28, P393, DOI 10.1017/S0142716407070208
   Boets B, 2008, BRAIN LANG, V106, P29, DOI 10.1016/j.bandl.2007.12.004
   Brown C., 2000, 2 LANGUAGE ACQUISITI, V1, P4
   Castles A, 2004, COGNITION, V91, P77, DOI 10.1016/S0010-0277(03)00164-1
   Chen X, 2004, J EDUC PSYCHOL, V96, P142, DOI 10.1037/0022-0663.96.1.142
   Chen X, 2010, J EDUC PSYCHOL, V102, P712, DOI 10.1037/a0018802
   Chiappe P, 2007, J EDUC PSYCHOL, V99, P154, DOI 10.1037/0022-0663.99.1.154
   CISERO CA, 1995, CONTEMP EDUC PSYCHOL, V20, P275, DOI 10.1006/ceps.1995.1018
   CUMMINS J, 1979, REV EDUC RES, V49, P222, DOI 10.3102/00346543049002222
   Cummins J., 1991, LANGUAGE PROCESSING, P70, DOI DOI 10.1017/CBO9780511620652.006
   de Graaff S, 2011, LEARN INSTR, V21, P163, DOI 10.1016/j.learninstruc.2010.02.001
   De Jong P.F., 2002, SCI STUD READ, V6, P51, DOI [DOI 10.1207/S1532799XSSR0601_03, 10.1207/S1532799XSSR0601_03]
   Dunn LM, 2005, PEABODY PICTURE VOCA
   DURGUNOGLU AY, 1993, J EDUC PSYCHOL, V85, P453, DOI 10.1037/0022-0663.85.3.453
   Duursma E, 2007, APPL PSYCHOLINGUIST, V28, P171, DOI 10.1017/S0142716406070093
   Elbro C, 1996, READ WRIT, V8, P453, DOI 10.1007/BF00577023
   Elbro C., 2002, PRECURSORS FUNCTIONA
   Furnes B, 2009, J RES READ, V32, P275, DOI 10.1111/j.1467-9817.2009.01393.x
   GOSWAMI U, 1993, ANN NY ACAD SCI, V682, P296, DOI 10.1111/j.1749-6632.1993.tb22977.x
   Gottardo A, 2001, J EDUC PSYCHOL, V93, P530, DOI 10.1037/0022-0663.93.3.530
   Hayes A.F., 2013, INTRO MEDIATION MODE
   Janssen C, 2017, BILING-LANG COGN, V20, P795, DOI 10.1017/S1366728916000523
   Janssen C, 2015, LANG LEARN, V65, P358, DOI 10.1111/lang.12102
   Janssen M, 2013, J RES READ, V36, P1, DOI 10.1111/j.1467-9817.2011.01480.x
   Jones G, 2016, COGNITION, V153, P79, DOI 10.1016/j.cognition.2016.04.017
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Li C., 1989, MANDARIN CHINESE FUN
   Marinova-Todd SH, 2010, CLIN LINGUIST PHONET, V24, P387, DOI 10.3109/02699200903532508
   McBride-Chang C, 2002, CHILD DEV, V73, P1392, DOI 10.1111/1467-8624.00479
   MERRIMAN WE, 1993, APPL PSYCHOLINGUIST, V14, P229, DOI 10.1017/S0142716400009565
   Metsala JL, 1998, WORD RECOGNITION IN BEGINNING LITERACY, P89
   Mills DL, 2004, J COGNITIVE NEUROSCI, V16, P1452, DOI 10.1162/0898929042304697
   Nathan L, 2004, J SPEECH LANG HEAR R, V47, P377, DOI 10.1044/1092-4388(2004/031)
   Patel TK, 2004, J EDUC PSYCHOL, V96, P785, DOI 10.1037/0022-0663.96.4.785
   Randazzo M, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00390
   Saiegh-Haddad E, 2008, READ WRIT, V21, P481, DOI 10.1007/s11145-007-9074-x
   Saiegh-Haddad E, 2019, J NEUROLINGUIST, V50, P17, DOI 10.1016/j.jneuroling.2017.11.001
   Schaars MMH, 2017, DYSLEXIA, V23, P141, DOI 10.1002/dys.1556
   Scheele AF, 2010, APPL PSYCHOLINGUIST, V31, P117, DOI 10.1017/S0142716409990191
   SCHMITT BH, 1994, J CONSUM RES, V21, P419, DOI 10.1086/209408
   Senechal M., 2006, HDB EARLY LITERACY R, V2, P173
   Shu H, 2008, DEVELOPMENTAL SCI, V11, P171, DOI 10.1111/j.1467-7687.2007.00654.x
   Siok WT, 2001, DEV PSYCHOL, V37, P886, DOI 10.1037//0012-1649.37.6.886
   STAHL SA, 1994, J EDUC PSYCHOL, V86, P221, DOI 10.1037/0022-0663.86.2.221
   Studdert-Kennedy M., 2002, READ WRIT, V15, P5, DOI DOI 10.1023/A:1013812219382
   Sutherland D, 2007, INT J LANG COMM DIS, V42, P229, DOI 10.1080/13682820600806672
   Swan D, 1997, J EXP CHILD PSYCHOL, V66, P18, DOI 10.1006/jecp.1997.2375
   Swingley D, 2009, PHILOS T R SOC B, V364, P3617, DOI 10.1098/rstb.2009.0107
   Taylor I., 2014, WRITING LITERACY CHI, V14
   TREIMAN R, 1991, PHONOLOGICAL PROCESSES IN LITERACY, P67
   van Goch MM, 2014, SCI STUD READ, V18, P155, DOI 10.1080/10888438.2013.827199
   Van Kuyk J. J., 1991, PEDAGOGISCHE STUDIEN, V68, P415
   Verhoeven L., 1995, TOETS TWEETALIGHEID
   Verhoeven L., 2001, TAALTOETS KINDEREN
   Verhoeven L., 2000, SCI STUD READ, V4, P313, DOI DOI 10.1207/S1532799XSSR0404_4
   Verhoeven L, 2007, APPL PSYCHOLINGUIST, V28, P425, DOI 10.1017/S0142716407070233
   Vihman MM, 2017, BRIT J PSYCHOL, V108, P1, DOI 10.1111/bjop.12207
   Vloedgraven J, 2009, LEARN INDIVID DIFFER, V19, P161, DOI 10.1016/j.lindif.2008.09.005
   Vloedgraven JMT, 2007, ANN DYSLEXIA, V57, P33, DOI 10.1007/s11881-007-0001-2
   Walley AC., 2003, READING WRITING, V16, P5, DOI [DOI 10.1023/A:1021789804977, 10.1023/A:1021789804977]
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
NR 64
TC 0
Z9 0
U1 2
U2 2
PU JOHN BENJAMINS PUBLISHING CO
PI AMSTERDAM
PA PO BOX 36224, 1020 ME AMSTERDAM, NETHERLANDS
SN 1387-6732
EI 1570-6001
J9 WRIT LANG LIT
JI Writ. Lang. Lit.
PY 2020
VL 23
IS 1
BP 109
EP 128
DI 10.1075/wll.00035.yua
PG 20
WC Language & Linguistics
SC Linguistics
GA OH3JI
UT WOS:000582464300005
DA 2021-02-24
ER

PT J
AU Guijo, LM
   Horiuti, MB
   Cardoso, ACV
AF Guijo, Laura Mochiatti
   Horiuti, Mirella Boaglio
   Vieira Cardoso, Ana Claudia
TI Content validation of an instrument to measure listening effort
SO CODAS
LA English
DT Article
DE Hearing; Listening Effort; Auditory Perception; Auditory Tests; Memory;
   Cognition
ID WORKING-MEMORY CAPACITY; CONTENT VALIDITY; SPEECH; HEALTH; NOISE
AB Purpose: To validate the content of an instrument to measure listening effort for hearing-impaired individuals. Method: This is a validation study, developed in two stages, which the Stage 1 is the planning and development of the first version of the instrument, and Stage 2 the investigation of the evidences of validity based on the content and development of the final version of the instrument to measure listening effort. Ten professionals with expertise in the field of audiology, with more than five years of clinical experience participated in this study. The instrument to be validated was composed of three parts: I - "speech perception of logatomes and listening effort"; II - "listening effort and working memory" and; III - "speech perception of meaningless sentences and working memory" and they were presented monoaurally, in quiet and in the signal-to-noise ratios + 5dB, 0dB and -5dB. It was conducted a descriptive analysis regarding the suggestions of the committee judge audiologists and the analysis of the individual and scale content validity index. Results: The results showed that parts I and III which constitute the proposed instrument reached a scale content validity index above 0.78, which means that the presented items did not need modification in their construct. Conclusion: The evidences of validity studied allowed relevant modifications and made this instrument adequate to its construct.
C1 [Guijo, Laura Mochiatti; Horiuti, Mirella Boaglio; Vieira Cardoso, Ana Claudia] Univ Estadual Paulista, Fac Filosofia & Ciencias, Dept Fonoaudiol, UNESP, Marilia, SP, Brazil.
   [Guijo, Laura Mochiatti] Univ Estadual Paulista UNESP, Fac Filosofia & Ciencias, Marilia, SP, Brazil.
   [Horiuti, Mirella Boaglio] Univ Fed Sao Paulo, Escola Paulista Med, EPM, UNIFESP,Programa Posgrad Ciencias Otorrinolaringo, Sao Paulo, SP, Brazil.
   [Vieira Cardoso, Ana Claudia] Univ Estadual Paulista, Fac Filosofia & Ciencias, Dept Fonoaudiol, Marilia, SP, Brazil.
RP Guijo, LM (corresponding author), Rua Guiro Shimabukuro 106,Bairro Parque Acacias, BR-17510050 Marilia, SP, Brazil.
EM lauramochiatti@gmail.com
CR Brannstrom K Jonas, 2018, J Am Acad Audiol, V29, P734, DOI 10.3766/jaaa.17024
   Alexandre NMC, 2011, CIENC SAUDE COLETIVA, V16, P3061, DOI 10.1590/S1413-81232011000800006
   Fraser S, 2010, J SPEECH LANG HEAR R, V53, P18, DOI 10.1044/1092-4388(2009/08-0140)
   Giangiacomo M.C.P.B., 2008, REV SOC BRAS FONOAUD, V13, P69
   Gosselin PA, 2010, CAN J SPEECH-LANG PA, V34, P43
   Grant JS, 1997, RES NURS HEALTH, V20, P269, DOI 10.1002/(SICI)1098-240X(199706)20:3<269::AID-NUR9>3.3.CO;2-3
   Haynes SN, 1995, PSYCHOL ASSESSMENT, V7, P238, DOI 10.1037/1040-3590.7.3.238
   Heinrich A, 2008, Q J EXP PSYCHOL, V61, P735, DOI 10.1080/17470210701402372
   Koelewijn T, 2012, EAR HEARING, V33, P291, DOI 10.1097/AUD.0b013e3182310019
   LYNN MR, 1986, NURS RES, V35, P382
   Ma WJ, 2014, NAT NEUROSCI, V17, P347, DOI 10.1038/nn.3655
   Mackersie CL, 2011, J AM ACAD AUDIOL, V22, P113, DOI 10.3766/jaaa.22.2.6
   McCoy SL, 2005, Q J EXP PSYCHOL-A, V58, P22, DOI 10.1080/02724980443000151
   McGarrigle R, 2014, INT J AUDIOL, V53, P433, DOI 10.3109/14992027.2014.890296
   Mokkink LB, 2010, J CLIN EPIDEMIOL, V63, P737, DOI 10.1016/j.jclinepi.2010.02.006
   Ng EHN, 2013, INT J AUDIOL, V52, P433, DOI 10.3109/14992027.2013.776181
   Pals C, 2013, J SPEECH LANG HEAR R, V56, P1075, DOI 10.1044/1092-4388(2012/12-0074)
   Peelle JE, 2018, EAR HEARING, V39, P204, DOI 10.1097/AUD.0000000000000494
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Picou EM, 2013, EAR HEARING, V34, pe52, DOI 10.1097/AUD.0b013e31827f0431
   Polit DF, 2006, RES NURS HEALTH, V29, P489, DOI 10.1002/nur.20147
   Polit DF, 2015, INT J NURS STUD, V52, P1746, DOI 10.1016/j.ijnurstu.2015.07.002
   Roach KE, 2006, PROCEEDINGS OF THE AMERICAN ACADEMY OF ORTHOTISTS AND PROSTHETISTS, pP8
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg N, 2011, AUDIOL RES, V1, P82, DOI 10.4081/audiores.2011.e22
   Rudner M, 2012, J AM ACAD AUDIOL, V23, P577, DOI 10.3766/jaaa.23.7.7
   Sarampalis A, 2009, J SPEECH LANG HEAR R, V52, P1230, DOI 10.1044/1092-4388(2009/08-0111)
   Wingfield A, 2016, EAR HEARING, V37, p35S, DOI 10.1097/AUD.0000000000000310
   Wu YH, 2014, EAR HEARING, V35, P623, DOI 10.1097/AUD.0000000000000079
NR 29
TC 0
Z9 0
U1 0
U2 0
PU SOC BRASILEIRA FONOAUDIOLOGIA
PI SAO PAULO SP
PA AL JAU, 684 7 ANDAR, SAO PAULO SP, 01420-001, BRAZIL
SN 2317-1782
J9 CODAS
JI CoDAS
PY 2020
VL 32
IS 5
AR e20180272
DI 10.1590/2317-1782/20202018272
PG 10
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA OC9SU
UT WOS:000579496300003
PM 33053080
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Chong, FY
   Cheoy, LP
   Mazlan, R
   Maamor, N
AF Chong, Foong Yen
   Cheoy, Lai Pheng
   Mazlan, Rafidah
   Maamor, Nashrah
TI Performance-intensity functions of Mandarin fricative-affricate nonsense
   word test: preliminary findings
SO SPEECH LANGUAGE AND HEARING
LA English
DT Article
DE Mandarin; speech perception test; fricatives; affricates;
   performance-intensity function
ID MONOSYLLABLE TEST MATERIAL; SPEECH AUDIOMETRY; HEARING; NOISE;
   VALIDATION; PERCEPTION; VARIABILITY; SPEAKERS; ADULTS
AB Purpose: Mandarin speech perception tests are scarce in Malaysia. Speech perception tests developed in other Mandarin-speaking countries are not suitable for local use due to colloquial and cultural differences. A previous study developed a digitally recorded nonsense word test that emphasizes Mandarin sibilant fricatives and affricates. However, no performance-intensity function has been established for the test. This study aimed to establish and compare the baseline performance-intensity function of the nonsense word lists between speaker genders.
   Method: Native Mandarin-speaking young adults with normal hearing (n=55) participated in this study. Test stimuli were two lists of nonsense words recorded from a male and a female speaker. Each list has 18 vowel-consonant-vowel nonsense words. During testing, each list was presented monaurally to participants via insert-earphones at seven intensity levels in 5dB-step decrements. The sequence of speaker genders and the nonsense words within each list was randomized. The identification scores of participants were measured.
   Results: A two-way repeated-measure ANOVA revealed that there is a significant interaction effect between speaker genders and intensity levels. Pairwise comparisons showed significant differences in identification scores between 0, 5, 15, and 20dBHL for nonsense words of both speaker genders. However, no significant difference was found between pairs of 20, 25, and 30dBHL. Different speaker gender lists yielded similar results.
   Conclusion: Performance-intensity function was developed for the Mandarin fricative-affricate nonsense word test. The test has the potential to be used as a speech audiometry test in local clinics.
C1 [Chong, Foong Yen; Cheoy, Lai Pheng; Mazlan, Rafidah; Maamor, Nashrah] Univ Kebangsaan Malaysia, Fac Hlth Sci, Ctr Rehabil & Special Needs, Audiol Programme, UKM KL Campus,Jalan Temerloh, Kuala Lumpur 53200, Malaysia.
RP Chong, FY (corresponding author), Univ Kebangsaan Malaysia, Fac Hlth Sci, Ctr Rehabil & Special Needs, Audiol Programme, UKM KL Campus,Jalan Temerloh, Kuala Lumpur 53200, Malaysia.
EM foongyen.chong@ukm.edu.my
RI Chong, Foong Yen/E-9144-2017
OI Chong, Foong Yen/0000-0003-4964-4694
FU Universiti Kebangsaan Malaysia [GGPM-2017-053]
FX This work was supported by Universiti Kebangsaan Malaysia: [Grant no.
   Geran Galakan Penyelidik Muda (GGPM-2017-053)].
CR American Speech-Language-Hearing Association, 1988, DET THRESH LEV SPEEC
   Boothroyd A, 2008, EAR HEARING, V29, P479, DOI 10.1097/AUD.0b013e318174f067
   Cheesman M. F., 1996, Canadian Acoustics, V24, P3
   Chen JY, 2011, INT J AUDIOL, V50, P354, DOI 10.3109/14992027.2011.555735
   Chong F. Y., 2016, THESIS
   Chong F. Y., 2018, MALAYSIAN J HLTH SCI, V16, P179
   Cook RD, 2000, TECHNOMETRICS, V42, P65, DOI 10.2307/1271434
   Department of Statistics Malaysia, 2018, CURR POP EST MAL 201
   Fidell L. S., 2007, EXPT DESIGNS USING A
   Frank T, 1993, Am J Audiol, V2, P33, DOI 10.1044/1059-0889.0201.33
   Fu QJ, 2011, J ACOUST SOC AM, V129, pEL267, DOI 10.1121/1.3590739
   Han DM, 2009, INT J AUDIOL, V48, P300, DOI 10.1080/14992020802607456
   Hu XJ, 2019, INT J SPEECH-LANG PA, V21, P404, DOI 10.1080/17549507.2018.1485741
   Huang L.M., 1992, B NATL TAIWAN NORMAL, V37, P363
   Ji F, 2011, ACTA OTO-LARYNGOL, V131, P1051, DOI 10.3109/00016489.2011.583267
   Ji F, 2011, ACTA OTO-LARYNGOL, V131, P962, DOI 10.3109/00016489.2011.574646
   Kuk F, 2010, EAR HEARING, V31, P779, DOI 10.1097/AUD.0b013e3181e97bfb
   Ladefoged Peter, 1975, COURSE PHONETICS
   Lai YH, 2009, LANG COGNITIVE PROC, V24, P1265, DOI 10.1080/01690960802113850
   Lee CY, 2012, J ACOUST SOC AM, V132, P1130, DOI 10.1121/1.4730883
   Lee S. I., 2011, P 17 INT C PHON SCI, P1178
   Lee WS, 2009, J INT PHON ASSOC, V39, P107, DOI 10.1017/S0025100308003599
   Lesimple C, 2018, SPEECH COMMUN, V99, P47, DOI 10.1016/j.specom.2018.02.007
   Li Rui., 2016, ADV LANGUAGE LIT STU, V7/3
   Li YX, 2017, INT J AUDIOL, V56, pS31, DOI 10.1080/14992027.2016.1204564
   Lim HW, 2018, CLIN LINGUIST PHONET, V32, P889, DOI 10.1080/02699206.2018.1459852
   Lim HW, 2015, CLIN LINGUIST PHONET, V29, P793, DOI 10.3109/02699206.2015.1048379
   Ma XR, 2013, HEARING BALANC COMMU, V11, P52, DOI 10.3109/21695717.2013.794592
   Martin T, 2015, CERAMICS-ART PERCEPT, P12
   Mayr S, 2007, TUTOR QUANT METHODS, V3, P51, DOI 10.20982/tqmp.03.2.p051
   McArdle R., 2015, HDB CLIN AUDIOLOGY 7, P61
   MILLER GA, 1951, J EXP PSYCHOL, V41, P329, DOI 10.1037/h0062491
   Munro M, 2008, BEHAV RES METHODS, V40, P147, DOI 10.3758/BRM.40.1.147
   Nissen SL, 2007, INT J AUDIOL, V46, P449, DOI 10.1080/14992020701361296
   Nissen SL, 2008, AM J AUDIOL, V17, P68, DOI 10.1044/1059-0889(2008/008)
   Nissen SL, 2005, INT J AUDIOL, V44, P379, DOI 10.1080/14992020500147615
   Nissen SL, 2005, INT J AUDIOL, V44, P391, DOI 10.1080/14992020500147672
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   Quar TK, 2017, INT J AUDIOL, V56, P92, DOI 10.1080/14992027.2016.1210828
   Schlauch R.S., 2015, HDB CLIN AUDIOLOGY, V7th, P29
   Tsai KS, 2009, EAR HEARING, V30, P90, DOI 10.1097/AUD.0b013e31818f28a6
   Tsao FM, 2006, J ACOUST SOC AM, V120, P2285, DOI 10.1121/1.2338290
   Tseng SC, 2004, 2004 International Symposium on Chinese Spoken Language Processing, Proceedings, P29
   Wang S, 2007, INT J AUDIOL, V46, P719, DOI 10.1080/14992020701558511
   Wang SJ, 2014, ACTA OTO-LARYNGOL, V134, P66, DOI 10.3109/00016489.2013.840923
   Wang X. M., 2016, COMMUNICATING ASIA F, P205
   Wang XM, 2010, J MULTILING MULTICUL, V31, P479, DOI 10.1080/01434632.2010.505656
   Wong LLN, 2008, INT J AUDIOL, V47, P391, DOI 10.1080/14992020701870239
   Wong LLN, 2008, INT J AUDIOL, V47, P393, DOI 10.1080/14992020701870221
   Wu WF, 2011, COMPUT BIOL MED, V41, P131, DOI 10.1016/j.compbiomed.2011.01.002
   Xi X, 2012, INT J AUDIOL, V51, P399, DOI 10.3109/14992027.2011.642011
   Yeo P. Y. H., 2011, THESIS
   Zee E., 1999, HDB INT PHONETIC ASS, P58
   Zhao XW, 2009, BEHAV RES METHODS, V41, P575, DOI 10.3758/BRM.41.2.575
   Zhu MM, 2012, ACTA OTO-LARYNGOL, V132, P855, DOI 10.3109/00016489.2011.653668
NR 55
TC 3
Z9 3
U1 1
U2 1
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 2050-571X
EI 2050-5728
J9 SPEECH LANG HEARING
JI Speech Lang. Hearing
PY 2020
VL 23
IS 3
BP 121
EP 132
DI 10.1080/2050571X.2019.1576364
PG 12
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA OE5WE
UT WOS:000580599700001
DA 2021-02-24
ER

PT J
AU Volter, C
   Gotze, L
   Haubitz, I
   Dazert, S
   Thomas, JP
AF Voelter, Christiane
   Goetze, Lisa
   Haubitz, Imme
   Dazert, Stefan
   Thomas, Jan Peter
TI Benefits of Cochlear Implantation in Middle-Aged and Older Adults
SO CLINICAL INTERVENTIONS IN AGING
LA English
DT Article
DE cochlear implantation; age-related hearing loss; benefit; outcome;
   cognitive domains; quality of life; depression
ID QUALITY-OF-LIFE; HEARING-LOSS; US ADULTS; HEALTH; PERFORMANCE;
   DEPRESSION; IMPAIRMENT; VALIDATION; IMPACT; TASKS
AB Introduction: Nowadays cochlear implantation (CI) is the treatment of choice in adults in case conventional hearing devices fail. Besides speech perception, an improvement in quality of life and in cognitive performance has been reported. Thereby, the study focused on the impact of age.
   Participants and Methods: Thirty middle-aged (MA) between 50 and 64 years and 41 older subjects (OA) aged 65 and older with bilateral severe hearing loss performed a comprehensive computer-based neurocognitive test battery (ALAcog) preand 12 months post-implantation. Besides, monosyllabic speech perception in quiet (Freiburg monosyllabic speech test), health-related quality of life (HR-QoL, Nijmegen Cochlear Implant Questionnaire) and depressive symptoms (GDS-15) have been assessed.
   Results: Both age groups significantly improved in all three categories after 12 months. No differences were evaluated between MA and OA regarding speech perception and HR-QoL preand post-operatively. In contrast, cognitive performance differed between the age groups: pre-operatively OA performed worse in most neurocognitive subdomains like work ing memory (p=0.04), inhibition (p=0.004), processing speed (p=0.003) and mental flexibility (p=0.01), post-operatively MA outperformed OA only in inhibition (p=0.01). Age only slightly influenced cognitive performance in MA, whereas in OA age per se tremendously impacted on working memory (p=0.04), inhibition (p=0.02), memory (p=0.04) and mental flexibility (p=0.01). Educational level also affected processing speed, mental flexibility (p=0.01) and working memory (p=0.01). This was more pronounced in OA. In both age groups, hearing status had a strong effect on attentional tasks (p=0.01). In MA, depressive symptoms were more influential on cognitive functioning and on HR-QoL than in OA. Improvement in quality of life (p=0.0002) and working memory (p=0.001) was greater for those with a higher pre-operative depression score.
   Conclusion: Speech perception and HR-QoL improved in hearing impaired, independently of age. Pre-operative differences in cognitive performance between OA and MA clearly attenuated 12 months after CI. Impact of comorbidities differed between age groups.
C1 [Voelter, Christiane; Goetze, Lisa; Haubitz, Imme; Dazert, Stefan; Thomas, Jan Peter] Ruhr Univ Bochum, Dept Otorhinolaryngol Head & Neck Surg, Kathol Klinikum, Bochum, Germany.
RP Volter, C (corresponding author), Ruhr Univ Bochum, Dept Otorhinolaryngol Head & Neck Surg, Kathol Klinikum, Bochum, Germany.
EM christiane.voelter@rub.de
FU DFG Open Access Publication Funds of the Ruhr-University Bochum
FX We are very thankful to Prof. Dr. Michael Falkenstein (Institute for
   Work, Learning and Aging, Bochum) and Ludger Blanke for providing the
   ALAcog assessment battery and helpful technical support. Furthermore, to
   Janine Muther and Robert Kappeler who helped with data collection and to
   all the patients, who participated in the study. We further appreciate
   the support by the DFG Open Access Publication Funds of the
   Ruhr-University Bochum.
CR Ambert-Dahan E, 2018, EUR ANN OTORHINOLARY, V135, P25, DOI 10.1016/j.anorl.2017.09.003
   Arvin B, 2013, INDIAN J OTOLARYNGOL, V65, pS480, DOI 10.1007/s12070-011-0356-x
   Besser J, 2018, HEARING RES, V369, P3, DOI 10.1016/j.heares.2018.06.008
   Bonsang E, 2012, J HEALTH ECON, V31, P490, DOI 10.1016/j.jhealeco.2012.03.005
   Brewster KK, 2018, AM J GERIAT PSYCHIAT, V26, P788, DOI 10.1016/j.jagp.2018.04.003
   Brickenkamp R, 1962, TEST D2 AUFMERKSAMKE
   Bruggemann P, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00226
   Chia EM, 2007, EAR HEARING, V28, P187, DOI 10.1097/AUD.0b013e31803126b6
   Ciorba A, 2012, CLIN INTERV AGING, V7, P159, DOI 10.2147/CIA.S26059
   Claes AJ, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00580
   Conway MA, 2005, J MEM LANG, V53, P594, DOI 10.1016/j.jml.2005.08.005
   Cosetti MK, 2016, CLIN INTERV AGING, V11, P603, DOI 10.2147/CIA.S100255
   Cosh S, 2018, INT J GERIATR PSYCH, V33, P1654, DOI 10.1002/gps.4968
   Davis A, 2016, GERONTOLOGIST, V56, pS256, DOI 10.1093/geront/gnw033
   Dawes P, 2015, PLOS ONE, V10, DOI [10.1371/journal. pone.011961626, DOI 10.1371/J0URNAL.P0NE.0119616]
   Dawes P, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2018-026246
   Dillon MT, 2013, JAMA OTOLARYNGOL, V139, P279, DOI 10.1001/jamaoto.2013.1814
   Dupuis K, 2016, CAN J AGING, V35, P298, DOI 10.1017/S0714980816000313
   Eisele M, 2015, BRIT J GEN PRACT, V65, pE716, DOI 10.3399/bjgp15X687337
   ERIKSEN BA, 1974, PERCEPT PSYCHOPHYS, V16, P143, DOI 10.3758/BF03203267
   Falkenstein M, 1999, ACTA PSYCHOL, V101, P267, DOI 10.1016/S0001-6918(99)00008-6
   Forli F, 2019, AUDIOL NEURO-OTOL, V24, P77, DOI 10.1159/000499176
   Helmstaedter C., 2001, VERBALER LERN MERKFA
   Hinderink JB, 2000, OTOLARYNG HEAD NECK, V123, P756, DOI 10.1067/mhn.2000.108203
   Hsu WT, 2016, MEDICINE, V95, DOI 10.1097/MD.0000000000005312
   Huber M, 2020, INT J AUDIOL, V59, P254, DOI 10.1080/14992027.2019.1687947
   Humes LE, 2016, EAR HEARING, V37, p52S, DOI 10.1097/AUD.0000000000000303
   Humes LE, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00055
   Jayakody DMP, 2017, OTOL NEUROTOL, V38, pE289, DOI 10.1097/MAO.0000000000001502
   Jolink C, 2016, Cochlear Implants Int, V17, P146, DOI 10.1080/14670100.2016.1162383
   Jorgensen LE, 2016, J AM ACAD AUDIOL, V27, P311, DOI 10.3766/jaaa.15006
   Keidser G, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517706395
   KIRCHNER WK, 1958, J EXP PSYCHOL, V55, P352, DOI 10.1037/h0043688
   Knopke S, 2019, OTOL NEUROTOL, V40, pE441, DOI 10.1097/MAO.0000000000002179
   Lally JW, 2019, CURR OPIN OTOLARYNGO, V27, P387, DOI 10.1097/MOO.0000000000000569
   Lawrence BJ, 2020, GERONTOLOGIST, V60, pE137, DOI 10.1093/geront/gnz009
   Lehrl S, 2005, MWT B MEHRFACH WORTS
   Lehto JE, 2003, BRIT J DEV PSYCHOL, V21, P59, DOI 10.1348/026151003321164627
   Lenarz M, 2012, LARYNGOSCOPE, V122, P1361, DOI 10.1002/lary.23232
   Lenarz T, 2017, AUDIOL NEURO-OTOL, V22, P61, DOI 10.1159/000477533
   Li CM, 2014, JAMA OTOLARYNGOL, V140, P293, DOI 10.1001/jamaoto.2014.42
   Lin FR, 2012, ARCH INTERN MED, V172, P369, DOI 10.1001/archinternmed.2011.728
   Livingston G, 2017, LANCET, V390, P2673, DOI 10.1016/S0140-6736(17)31363-6
   McRackan TR, 2018, LARYNGOSCOPE, V128, P982, DOI 10.1002/lary.26738
   Mick P, 2014, OTOLARYNG HEAD NECK, V150, P378, DOI 10.1177/0194599813518021
   Miyake A, 2000, COGNITIVE PSYCHOL, V41, P49, DOI 10.1006/cogp.1999.0734
   Moberly AC, 2018, LARYNGOSCOPE, V128, P959, DOI 10.1002/lary.26791
   Moberly AC, 2016, LARYNSCOPE INVESTIG, V1, P154, DOI 10.1002/lio2.38
   Mosnier I, 2015, JAMA OTOLARYNGOL, V141, P442, DOI 10.1001/jamaoto.2015.129
   Nagle S, 2012, WORK, V41, P3541, DOI 10.3233/WOR-2012-0633-3541
   [National Council on Aging Senior Research Group an alliance between the National Council on Aging and Market Strategies Inc], 1999, CONS UNTR HEAR LOSS
   Nguyen MF, 2017, J ALZHEIMERS DIS, V58, P123, DOI 10.3233/JAD-160793
   Nordvik O, 2018, BMC EAR NOSE THROAT, V18, DOI 10.1186/s12901-018-0051-6
   Olze H, 2012, LARYNGOSCOPE, V122, P196, DOI 10.1002/lary.22356
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Polku H, 2018, J GERONTOL B-PSYCHOL, V73, P543, DOI 10.1093/geronb/gbw045
   Pronk M, 2014, J AGING HEALTH, V26, P703, DOI 10.1177/0898264314529329
   Raymond M, 2021, OTOLARYNG HEAD NECK, V164, P49, DOI 10.1177/0194599820933255
   Regan J, 2019, TRIALS, V20, DOI 10.1186/s13063-018-2973-0
   REITAN R. M., 1958, PERCEPT MOT SKILLS, V8, P271
   Roca M, 2015, ACTAS ESP PSIQUIATRI, V43, P187
   RONNBERG J, 2008, INT J AUDIOL, V47, pS9, DOI DOI 10.1080/14992020802301167
   Rutherford BR, 2018, AM J PSYCHIAT, V175, P215, DOI 10.1176/appi.ajp.2017.17040423
   Salthouse TA, 2010, J INT NEUROPSYCH SOC, V16, P754, DOI 10.1017/S1355617710000706
   Salthouse TA, 2009, NEUROBIOL AGING, V30, P507, DOI 10.1016/j.neurobiolaging.2008.09.023
   Sarant J, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00789
   Singh-Manoux A, 2012, BRIT MED J, V344, DOI 10.1136/bmj.d7622
   Snyder HR, 2013, PSYCHOL BULL, V139, P81, DOI 10.1037/a0028727
   Sorrentino T, 2020, INT J AUDIOL, V59, P316, DOI 10.1080/14992027.2019.1696993
   Tambs K, 2004, PSYCHOSOM MED, V66, P776, DOI 10.1097/01.psy.0000133328.03596.fb
   THURSTONE LL, 1948, SCIENCE, V108, P585
   Tretbar K, 2019, HNO, V67, P36, DOI 10.1007/s00106-018-0576-4
   Turunen-Taheri SK, 2019, ACTA OTO-LARYNGOL, V139, P604, DOI 10.1080/00016489.2019.1607976
   Vasil KJ, 2020, J AM ACAD AUDIOL, V31, P292, DOI 10.3766/jaaa.19047
   Volter C, 2020, HNO, V68, P155, DOI 10.1007/s00106-019-00762-7
   Volter C, 2018, CLIN INTERV AGING, V13, P701, DOI 10.2147/CIA.S160517
   Volter C, 2017, CLIN INTERV AGING, V12, P1681, DOI 10.2147/CIA.S142541
   Wagener K., 1999, Z AUDIOL, V38, P4
   West JS, 2017, SOC SCI MED, V192, P94, DOI 10.1016/j.socscimed.2017.09.031
   Wild K, 2008, ALZHEIMERS DEMENT, V4, P428, DOI 10.1016/j.jalz.2008.07.003
   Wild-Wall N, 2008, BRAIN RES, V1211, P72, DOI 10.1016/j.brainres.2008.03.025
   YESAVAGE JA, 1983, J PSYCHIATR RES, V17, P37, DOI 10.1016/0022-3956(82)90033-4
NR 82
TC 0
Z9 0
U1 0
U2 0
PU DOVE MEDICAL PRESS LTD
PI ALBANY
PA PO BOX 300-008, ALBANY, AUCKLAND 0752, NEW ZEALAND
EI 1178-1998
J9 CLIN INTERV AGING
JI Clin. Interv. Aging
PY 2020
VL 15
BP 1555
EP 1568
DI 10.2147/CIA.S255363
PG 14
WC Geriatrics & Gerontology
SC Geriatrics & Gerontology
GA NO4UJ
UT WOS:000569479700001
PM 32982193
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Delgado-Pinheiro, EMC
   Bonbonati, JC
   dos Santos, FR
   Fabron, EMG
AF Carrit Delgado-Pinheiro, Eliane Maria
   Bonbonati, Jessica Caroline
   dos Santos, Flavia Rodrigues
   Gradim Fabron, Eliana Maria
TI Voice of hearing impaired children and adolescents and hearing peers:
   influence of speech auditory perception on vocal production
SO CODAS
LA English
DT Article
DE Cochlear Implants; Hearing Aids; Hearing loss; Speech Perception; Voice
   Quality
AB Purpose: To compare the acoustic and perceptual-auditory results of the hearing impaired children and adolescents with hearing pairs and to correlate these results with parents' reports regarding speech auditory perception. Method: The participants were divided into two groups: Group I, 20 hearing-impaired children and adolescents and Group II, 20 children and adolescents with normal hearing. Acoustic analysis of the vowel /a/ and perceptual-auditory assessment of the vowel /a/ and speech were performed. The speech auditory perception of the GI was assessed using the Infant-Toddler Meaningful Auditory Integration Scale and the Meaningful Auditory Integration Scale with adaptation for adolescent participants. The acoustic and perceptual-auditory voice results of the GI and GII were compared and these results were correlated with the performance in the auditory perception of the GI group. Results: The groups I and II presented similar results, differing statistically in the long-term frequency variation (vF(0)) and the long-term amplitude variation (vAm) parameters of the vowel /a/ and speech resonance parameter. It was found a negative correlation between auditory perception performance with jitter, vF(0) and general degree of vowel /a/. Conclusion: The vocal quality in GI was similar to their hearing peers in almost all the vocal parameters that were analyzed. The auditory perception influenced jitter, vF(0) and general degree of voice parameters, in which hearing-impaired children and adolescents who presented higher scores for auditory perception were also able to keep a more controlled vocal emission.
C1 [Carrit Delgado-Pinheiro, Eliane Maria; Bonbonati, Jessica Caroline; dos Santos, Flavia Rodrigues; Gradim Fabron, Eliana Maria] Univ Estadual Paulista Julio de Mesquita Filho UN, Dept Fonoaudiol, Av Hygino Muzzi Filho 737, BR-17525900 Marilia, SP, Brazil.
   [Carrit Delgado-Pinheiro, Eliane Maria; dos Santos, Flavia Rodrigues; Gradim Fabron, Eliana Maria] Univ Estadual Paulista Julio de Mesquita Filho UN, Marilia, SP, Brazil.
   [Bonbonati, Jessica Caroline] Univ Sao Paulo, Hosp Reabilitacao Anomalias Craniofaciais HRAC, Bauru, SP, Brazil.
RP dos Santos, FR (corresponding author), Univ Estadual Paulista Julio de Mesquita Filho UN, Dept Fonoaudiol, Av Hygino Muzzi Filho 737, BR-17525900 Marilia, SP, Brazil.
EM flavia.unesp@outlook.com
OI Rodrigues dos Santos, Flavia/0000-0002-5539-9501
FU Fundacao de Amparo a Pesquisa do Estado de Sao Paulo - FAPESPFundacao de
   Amparo a Pesquisa do Estado de Sao Paulo (FAPESP) [2015/20853-3]
FX Fundacao de Amparo a Pesquisa do Estado de Sao Paulo - FAPESP process
   no. 2015/20853-3.
CR Bicas Rafaela da Silva, 2017, Rev. CEFAC, V19, P465, DOI 10.1590/1982-0216201719412516
   Cappellari Viviane Michele, 2008, Braz J Otorhinolaryngol, V74, P265
   Castiquini EAT, 1998, THESIS
   Castiquini EAT, 2000, REV SOC BRAS FONOAUD, V4, P51
   Castiquini EAT, 1998, INFANT TODDLER MEANI
   Coelho AC, 2016, BRAZ J OTORHINOLAR, V82, P70, DOI 10.1016/j.bjorl.2015.11.002
   Coelho AC, 2015, INT J AUDIOL, V54, P417, DOI 10.3109/14992027.2014.998784
   Coelho Ana Cristina, 2012, J. Soc. Bras. Fonoaudiol., V24, P395, DOI 10.1590/S2179-64912012000400018
   Coelho Ana Cristina de Castro, 2009, Pró-Fono R. Atual. Cient., V21, P7, DOI 10.1590/S0104-56872009000100002
   Fabron EMG, 2017, DISTURBIOS COMUM, V29, P55, DOI [10.23925/2176-2724.2017v29i1p55-67, DOI 10.23925/2176-2724.2017V29I1P55-67]
   Holler T, 2010, ARCH OTOLARYNGOL, V136, P17, DOI 10.1001/archoto.2009.194
   Horga D, 2006, CLIN LINGUIST PHONET, V20, P211, DOI 10.1080/02699200400027015
   Jafari N, 2017, J VOICE, V31, DOI 10.1016/j.jvoice.2016.10.018
   Jafari N, 2016, J VOICE, V30, DOI 10.1016/j.jvoice.2015.10.006
   Joy JV, 2017, J VOICE, V31, DOI 10.1016/j.jvoice.2016.09.030
   Knight K, 2016, S AFR J COMMUN DISOR, V63, DOI 10.4102/sajcd.v63i1.142
   Lopes LW, 2012, J VOICE, V26, DOI 10.1016/j.jvoice.2012.05.008
   Maturo S, 2012, ARCH OTOLARYNGOL, V138, P956, DOI 10.1001/2013.jamaoto.104
   Tavares ELM, 2011, BRAZ J OTORHINOLAR, V77, P736, DOI 10.1590/S1808-86942011000600010
   Moret Adriane Lima Mortari, 2007, Pró-Fono R. Atual. Cient., V19, P295, DOI 10.1590/S0104-56872007000300008
   Natour YS, 2009, J VOICE, V23, P560, DOI 10.1016/j.jvoice.2008.01.005
   Novaes Beatriz C Albuquerque Caiuby, 2012, J Soc Bras Fonoaudiol, V24, P335
   Oates J, 2009, FOLIA PHONIATR LOGO, V61, P49, DOI 10.1159/000200768
   de Souza LBR, 2012, INT J PEDIATR OTORHI, V76, P1180, DOI 10.1016/j.ijporl.2012.04.029
   Cysneiros HRS, 2016, CODAS, V28, DOI 10.1590/2317-1782/20162015165
   Soltani M, 2014, J VOICE, V28, DOI 10.1016/j.jvoice.2013.10.012
   Souza Lourdes Bernadete Rocha de, 2013, Rev. CEFAC, V15, P616, DOI 10.1590/s1516-18462013005000027
   Spazzapan EA, 2018, THESIS
   Stathopoulos ET, 2011, J SPEECH LANG HEAR R, V54, P1011, DOI 10.1044/1092-4388(2010/10-0036)
   Van Lierde KM, 2005, INT J AUDIOL, V44, P452, DOI 10.1080/14992020500189146
   Yavas M, 2001, AVALIACAO FONOLOGICA
NR 31
TC 0
Z9 0
U1 1
U2 1
PU SOC BRASILEIRA FONOAUDIOLOGIA
PI SAO PAULO SP
PA AL JAU, 684 7 ANDAR, SAO PAULO SP, 01420-001, BRAZIL
SN 2317-1782
J9 CODAS
JI CoDAS
PY 2020
VL 32
IS 4
AR e20180227
DI 10.1590/2317-1782/20202018227
PG 7
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA NL2WO
UT WOS:000567282300003
PM 32756851
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU de Camargo, N
   Mendes, BCA
   Novas, BCDC
AF de Camargo, Natalia
   Andrade Mendes, Beatriz Castro
   de Albuquerque Caiuby Novas, Beatriz Cavalcanti
TI Relationship between hearing capacity and performance on tasks of speech
   perception in children with hearing loss
SO CODAS
LA English
DT Article
DE Speech Intelligibility; Speech Perception; Auditory Perception; Child;
   Hearing Loss; Hearing Aids
ID INTELLIGIBILITY INDEX; AMPLIFICATION; OUTCOMES
AB Purpose: To establish the relationship between the performance on word recognition tasks, using words with and without sense and degree, and the configuration of hearing loss, by using Speech Inteligibility Index (SII) values as indicators, in children with hearing loss. Methods: SII were established for 55 and 65 Decibel of Sound Pressure Level (dB SPL) input sounds of ten children presenting bilateral sensorineural hearing loss (SNHL), adapted with bilateral hearing aids, and who have oral language as the main mode of communication. The children were submitted to a word and nonsense-word repetition task of two or three intensity degrees. Their productions were analyzed according to the Word Association for Syllable Perception (WASP) Protocol. In the data analysis, the values of SII were compared with the results obtained in each analysis criterion. Results: Pertaining to the words, there was statistically significant difference between the two types of stimuli in 55 dBSPL. As for the performance of consonants and point of articulation, there was a statistically significant difference between stimuli types in 65 and 55 dB SPL, and between intensities 65 and 55 dB SPL in nonsense words. Conclusion: Overall, there was no regularity in the relationship between hearing ability and performance in speech perception tasks. The results suggest that performance in the nonsense words recognition tasks was more related to intelligibility index than to words with meaning, possibly because it limits semantic closure strategies by the subject.
C1 [de Camargo, Natalia; Andrade Mendes, Beatriz Castro; de Albuquerque Caiuby Novas, Beatriz Cavalcanti] Pontificia Univ Catolica Sao Paulo PUC SP, Ctr Audicao Crianca CeAC, Div Educ & Reabilitacao Disturbios Comunicacao De, Sao Paulo, SP, Brazil.
   [de Camargo, Natalia; Andrade Mendes, Beatriz Castro; de Albuquerque Caiuby Novas, Beatriz Cavalcanti] Pontificia Univ Catolica Sao Paulo PUC SP, Rua Prof Dr Neyde Apparecida Sollitto 435, BR-04022040 Sao Paulo, SP, Brazil.
RP de Camargo, N (corresponding author), Pontificia Univ Catolica Sao Paulo PUC SP, Rua Prof Dr Neyde Apparecida Sollitto 435, BR-04022040 Sao Paulo, SP, Brazil.
EM natalia.camargo@ymail.com
OI Cavalcanti de Albuquerque Caiuby Novaes, Beatriz/0000-0003-3982-0295;
   Camargo, Natalia/0000-0003-3113-6659; de Castro Andrade Mendes,
   Beatriz/0000-0003-2141-5582
FU CNPqNational Council for Scientific and Technological Development (CNPq)
   [117225/2009-6]; Capes - PUC-SPCAPES
FX CNPq - process number 117225/2009-6 and Capes - PUC-SP.
CR [Anonymous], 1997, S351997 ANSI
   ANSI, 1969, S351969 ANSI
   Bagatto M, 2014, PROTOCOL PROVISION A
   Bagatto M, 2016, J AM ACAD AUDIOL, V27, P188, DOI 10.3766/jaaa.15051
   Bagatto M, 2010, INT J AUDIOL, V49, pS70, DOI 10.3109/14992020903080751
   Bass-Ringdahl SM, 2010, J DEAF STUD DEAF EDU, V15, P287, DOI 10.1093/deafed/enq013
   Bellis T J, 1996, ASSESSMENT MANAGEMEN
   Bevilacqua MC, 1996, 11 ENC INT AUD AN MA, P187
   Bevilacqua MC, 1996, TOPICOS FONOAUDIOLOG, P411
   Blasca WQ, 1994, THESIS PONTIFICIA U
   Figueiredo RSL, 2013, THESIS
   Figueiredo RSL, 2016, DISTURB COMUN, V28, P501
   Fisher LD, 1993, BIOSTATISTICS
   Koch ME, 1999, BRINGING SOUND LIFE
   Figueiredo RDL, 2016, CODAS, V28, P687, DOI 10.1590/2317-1782/20162015228
   Markides A, 1987, SPEECH AUDIOMETRY, P155
   Martin RL, 2012, HEAR J, V65, P8, DOI [10.1097/01.HJ.0000415187.11161.5d, DOI 10.1097/01.HJ.0000415187.11161.5D]
   McCreery RW, 2011, AUDIBILITY PREDICTOR
   Moeller MP, 2009, AM J AUDIOL, V18, P14, DOI 10.1044/1059-0889(2008/08-0010)
   Neter J, 2005, APPL LINEAR STAT MOD
   Novaes BCAC, 2001, WORLD ASS SYLL UNPUB
   Novaes BCAC, 2009, TRATADO FONOAUDIOLOG, P202
   Padilha R., 2003, THESIS PONTIFICIA U
   Scollie S., 2007, DSL VERSION V5 0 DES
   Scollie SD, 2008, EAR HEARING, V29, P543, DOI 10.1097/AUD.0b013e3181734a02
   Seewald R., 2008, HEARING J, V61, P26, DOI DOI 10.1097/01.HJ.0000342436.70730.A8
   Seewald Richard, 2005, Trends Amplif, V9, P145, DOI 10.1177/108471380500900402
   Sininger YS, 2010, EAR HEARING, V31, P166, DOI 10.1097/AUD.0b013e3181c8e7b6
   Tomblin J Bruce, 2015, Ear Hear, V36 Suppl 1, p76S, DOI 10.1097/AUD.0000000000000219
NR 29
TC 0
Z9 0
U1 1
U2 1
PU SOC BRASILEIRA FONOAUDIOLOGIA
PI SAO PAULO SP
PA AL JAU, 684 7 ANDAR, SAO PAULO SP, 01420-001, BRAZIL
SN 2317-1782
J9 CODAS
JI CoDAS
PY 2020
VL 32
IS 1
AR e20180139
DI 10.1590/2317-1782/20192018139
PG 9
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA NL2TF
UT WOS:000567273600003
PM 32022219
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU de Matos, IL
   Ferreira, MC
   Mondelli, MFCG
AF de Matos, Izabella Lima
   Ferreira, Maria Carolina
   Capoani Garcia Mondelli, Maria Fernanda
TI Analysis of speech perception with amplification devices in subjects
   with ear malformation and unilateral hearing loss
SO CODAS
LA English
DT Article
DE Hearing aids; Congenital abnormalities; Bone conduction; Speech
   perception; Unilateral hearing loss
ID BONE-CONDUCTION HEARING; AID; DEAFNESS; ATRESIA; NOISE
AB Purpose: To verify the speech perception in subjects with ear malformation and unilateral hearing loss, fitted with two types of amplification as follows: conventional hearing aids and softband (band with vibrator bone). Method: The study included fifteen subjects of both sexes who presented congenital malformation of the middle or outer ear, diagnosed with unilateral conductive or mixed hearing loss, moderate to severe hearing loss, age range between 15 to 25 years and, prescription from a specialist doctor for hearing device fitting. We performed the speech perception assessment without amplification after the hearing aid and softband fitting, with the hearing aid linked to the bone vibrator (conventional) and the softband (band with the bone vibrator). The subjects were evaluated using the Hearing in Noise Test (HINT), in silence and in noise. Results: Seven subjects with unilateral ear malformation were evaluated, 57.1 % had impairment in the right ear and 42.9 % in the left ear. Regarding the type and the level of hearing loss, 71 % of all subjects included in the sample presented moderate conductive hearing loss. The assessment of speech perception was performed during silence, frontal noise, lateral noise and, during three specifics situations: no amplification, with conventional hearing aid and with the softband. The results with the amplification devices were positive in all evaluated conditions. Conclusion: Evaluated subjects presented improvement in speech perception, in silence, frontal noise and lateral noise situations, regardless of the type of amplification; however, the difference was not statistically significant.
C1 [de Matos, Izabella Lima; Ferreira, Maria Carolina; Capoani Garcia Mondelli, Maria Fernanda] Univ Sao Paulo, Dept Fonoaudiol, Fac Odontol, Bauru, SP, Brazil.
   [de Matos, Izabella Lima; Ferreira, Maria Carolina; Capoani Garcia Mondelli, Maria Fernanda] Univ Sao Paulo, Fac Odontol Bauru, Bauru, SP, Brazil.
RP Ferreira, MC (corresponding author), Alameda Doutor Octavio Pinheiro Brisolla 6-65, BR-17012059 Bauru, SP, Brazil.
EM mariaferreira@usp.br
RI Mondelli, Maria Fernanda CG/C-2354-2012; Ferreira, Maria
   Carolina/L-6141-2018
OI Mondelli, Maria Fernanda CG/0000-0001-7572-209X; Matos, Izabella
   Lima/0000-0002-4474-1156
FU Programa Institucional de Bolsas de Iniciacao Cientifica (PIBIC)National
   Council for Scientific and Technological Development (CNPq)
FX Programa Institucional de Bolsas de Iniciacao Cientifica (PIBIC).
CR [Anonymous], 1991, S313 ANSI
   [Anonymous], 2006, HINT PRO HEARING NOI
   Bevilacqua MC, 2008, INT J AUDIOL, V47, P364, DOI 10.1080/14992020701870205
   Campos PD, 2011, BRAZ J OTORHINOLAR, V77, P555, DOI 10.1590/S1808-86942011000500003
   Mondelli MFCG, 2016, BRAZ J OTORHINOLAR, V82, P427, DOI 10.1016/j.bjorl.2015.08.019
   Mondelli MFCG, 2016, INT ARCH OTORHINOLAR, V20, P34, DOI 10.1055/s-0035-1566155
   Dell'Aringa AHB, 2005, ARQ INT OTORRINOLARI, V9, P310, DOI DOI 10.5935/1808-8694.20130063
   Fuchsmann C, 2010, ACTA OTO-LARYNGOL, V130, P1343, DOI 10.3109/00016489.2010.499879
   Griffin AM, 2019, EAR HEARING, V40, P887, DOI 10.1097/AUD.0000000000000667
   Henriques Marília Oliveira, 2011, Rev. CEFAC, V13, P1040, DOI 10.1590/s1516-18462011005000024
   Keith RW, 1994, ACPT AUDITORY CONTIN
   Kim G, 2017, OTOL NEUROTOL, V38, P473, DOI 10.1097/MAO.0000000000001359
   Kulasegarah J, 2018, INT J PEDIATR OTORHI, V107, P176, DOI 10.1016/j.ijporl.2018.01.032
   Lourencone LFM, 2018, THESIS, DOI [10.11606/T.5.2018.tde-01112018-112945, DOI 10.11606/T.5.2018.TDE-01112018-112945]
   Mondelli Maria Fernanda Capoani Garcia, 2016, Audiol., Commun. Res., V21, pe1649, DOI 10.1590/2317-6431-2015-1649
   Paccola ECM, 2013, BRAZ J OTORHINOLAR, V79, P359, DOI 10.5935/1808-8694.20130063
   Ngui LX, 2018, J LARYNGOL OTOL, V132, P693, DOI 10.1017/S0022215118001123
   Pittman AL, 2019, EAR HEARING, V40, P1307, DOI 10.1097/AUD.0000000000000710
   Reinfeldt S, 2015, INT J AUDIOL, V54, P408, DOI 10.3109/14992027.2014.996826
   Saliba I, 2011, AURIS NASUS LARYNX, V38, P570, DOI 10.1016/j.anl.2011.01.008
   Snik A F, 1994, Ear Nose Throat J, V73, P115
   SNIK AFM, 1995, OTOLARYNG CLIN N AM, V28, P73
   Thadeu SH, 2013, REV IBEROAM DIAGN EV, V2, P117
   Vargas LM, 2016, REV STRICTO SENSU, V1, P12, DOI [10.24222/2525-3395.2016v1n1p012, DOI 10.24222/2525-3395.2016V1N1P012]
   Wang YB, 2018, INT J PEDIATR OTORHI, V104, P120, DOI 10.1016/j.ijporl.2017.11.010
   Wie OB, 2010, ANN OTO RHINOL LARYN, V119, P772
   Zhang LC, 2016, EUR ARCH OTO-RHINO-L, V273, P1697, DOI 10.1007/s00405-015-3727-1
NR 27
TC 0
Z9 0
U1 0
U2 0
PU SOC BRASILEIRA FONOAUDIOLOGIA
PI SAO PAULO SP
PA AL JAU, 684 7 ANDAR, SAO PAULO SP, 01420-001, BRAZIL
SN 2317-1782
J9 CODAS
JI CoDAS
PY 2020
VL 32
IS 4
AR e20190047
DI 10.1590/2317-1782/20202019047
PG 6
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA NL2WO
UT WOS:000567282300007
PM 32756855
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Theodore, RM
   Monto, NR
   Graham, S
AF Theodore, Rachel M.
   Monto, Nicholas R.
   Graham, Stephen
TI Individual Differences in Distributional Learning for Speech: What's
   Ideal for Ideal Observers?
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID LANGUAGE IMPAIRMENT; ACOUSTIC CHARACTERISTICS; TALKER DIFFERENCES;
   SPEAKING RATE; CHILDREN; PERCEPTION; DEFICITS; COMPREHENSION;
   SENSITIVITY; SYNTAX
AB Purpose: Speech perception is facilitated by listeners' ability to dynamically modify the mapping to speech sounds given systematic variation in speech input. For example, the degree to which listeners show categorical perception of speech input changes as a function of distributional variability in the input, with perception becoming less categorical as the input, becomes more variable. Here, we test the hypothesis that higher level receptive language ability is linked to the ability to adapt to low-level distributional cues in speech input.
   Method: Listeners (n = 58) completed a distributional learning task consisting of 2 blocks of phonetic categorization for words beginning with /g/ and /k/. In 1 block, the distributions of voice onset time values specifying /g/ and /k/ had narrow variances (i.e., minimal variability). In the other block, the distributions of voice onset times specifying /g/ and /k/ had wider variances (i.e., increased variability). In addition, all listeners completed an assessment battery for receptive language, nonverbal intelligence, and reading fluency.
   Results: As predicted by an ideal observer computational framework, the participants in aggregate showed identification responses that were more categorical for consistent compared to inconsistent input, indicative of distributional learning. However, the magnitude of learning across participants showed wide individual variability, which was predicted by receptive language ability but not by nonverbal intelligence or by reading fluency.
   Conclusion: The results suggest that individual differences in distributional learning for speech are linked, at least in part, to receptive language ability, reflecting a decreased ability among those with weaker receptive language to capitalize on consistent input distributions.
C1 [Theodore, Rachel M.; Monto, Nicholas R.; Graham, Stephen] Univ Connecticut, Dept Speech Language & Hearing Sci, Storrs, CT 06269 USA.
   [Theodore, Rachel M.; Monto, Nicholas R.; Graham, Stephen] Univ Connecticut, Connecticut Inst Brain & Cognit Sci, Storrs, CT 06269 USA.
RP Theodore, RM (corresponding author), Univ Connecticut, Dept Speech Language & Hearing Sci, Storrs, CT 06269 USA.; Theodore, RM (corresponding author), Univ Connecticut, Connecticut Inst Brain & Cognit Sci, Storrs, CT 06269 USA.
EM rachel.theodore@uconn.edu
FU National Institute on Deafness and Other Communication Disorders
   GrantUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R21DC016141]; Raymond H. Stetson
   Scholarship in Phonetics and Speech Science from the Acoustical Society
   of America
FX This work was supported by National Institute on Deafness and Other
   Communication Disorders Grant R21DC016141 to R. M. T. and by the Raymond
   H. Stetson Scholarship in Phonetics and Speech Science from the
   Acoustical Society of America to N. R. M. The views expressed here
   reflect those of the authors and not the National Institutes of Health
   or the National Institute on Deafness and Other Communication Disorders.
   A pilot study for this work was completed as a master's thesis by the
   third author under the direction of the first author. Portions of this
   study were presented at the 177th meeting of the Acoustical Society of
   America.
CR Allen JS, 2004, J ACOUST SOC AM, V115, P3171, DOI 10.1121/1.1701898
   Baese-Berk M., 2015, P 18 INT C PHON SCI, V0460, P1
   Bates D, 2014, PACKAGE LME4
   BIRD J, 1992, EUR J DISORDER COMM, V27, P289
   Bishop DVM, 2004, DEVELOPMENTAL SCI, V7, pF11, DOI 10.1111/j.1467-7687.2004.00356.x
   Brown L., 2010, TEST NONVERBAL INTEL
   BYRD D, 1992, J ACOUST SOC AM, V92, P593, DOI 10.1121/1.404271
   Cho T, 1999, J PHONETICS, V27, P207, DOI 10.1006/jpho.1999.0094
   Chodroff E, 2017, J PHONETICS, V61, P30, DOI 10.1016/j.wocn.2017.01.001
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Coady JA, 2005, J SPEECH LANG HEAR R, V48, P944, DOI 10.1044/1092-4388(2005/065)
   Coady JA, 2007, J SPEECH LANG HEAR R, V50, P41, DOI 10.1044/1092-4388(2007/004)
   Colby S, 2018, J SPEECH LANG HEAR R, V61, P1, DOI 10.1044/2018_JSLHR-S-17-0392
   Conway CM, 2010, COGNITION, V114, P356, DOI 10.1016/j.cognition.2009.10.009
   Dunn L. M., 1997, PEABODY PICTURE VOCA
   Earle FS, 2018, NEUROSCI LETT, V666, P58, DOI 10.1016/j.neulet.2017.12.030
   Fidler LJ, 2011, AM J SPEECH-LANG PAT, V20, P2, DOI 10.1044/1058-0360(2010/09-0096)
   Hall J, 2017, J SPEECH LANG HEAR R, V60, P3270, DOI 10.1044/2017_JSLHR-L-17-0013
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hsu HJ, 2014, DEVELOPMENTAL SCI, V17, P352, DOI 10.1111/desc.12125
   Joanisse MF, 1998, TRENDS COGN SCI, V2, P240, DOI 10.1016/S1364-6613(98)01186-3
   Joanisse MF, 2003, BRAIN LANG, V86, P40, DOI 10.1016/S0093-934X(02)00533-3
   Kleinschmidt D. F., 2016, P 38 ANN M COGN SCI
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Leonard LB, 2014, CHILDREN WITH SPECIFIC LANGUAGE IMPAIRMENT, 2ND EDITION, P1
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Lum JAG, 2014, CORTEX, V51, P1, DOI 10.1016/j.cortex.2013.10.011
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   McArthur GM, 2004, J SPEECH LANG HEAR R, V47, P527, DOI 10.1044/1092-4388(2004/041)
   MILLER JL, 1983, J ACOUST SOC AM, V73, P1751, DOI 10.1121/1.389399
   Misyak JB, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00031
   Misyak JB, 2012, LANG LEARN, V62, P302, DOI 10.1111/j.1467-9922.2010.00626.x
   MONTGOMERY JW, 1995, J SPEECH HEAR RES, V38, P187, DOI 10.1044/jshr.3801.187
   MORICE R, 1985, CORTEX, V21, P567, DOI 10.1016/S0010-9452(58)80005-2
   Newman RS, 2001, J ACOUST SOC AM, V109, P1181, DOI 10.1121/1.1348009
   Nittrouer S, 2011, J EXP CHILD PSYCHOL, V108, P762, DOI 10.1016/j.jecp.2010.10.012
   Nixon J. S., 2018, 9 INT C SPEECH PROS
   Nixon JS, 2016, J MEM LANG, V90, P103, DOI 10.1016/j.jml.2016.03.005
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   PICHENY MA, 1986, J SPEECH HEAR RES, V29, P434, DOI 10.1044/jshr.2904.434
   Robertson EK, 2009, DEVELOPMENTAL SCI, V12, P753, DOI 10.1111/j.1467-7687.2009.00806.x
   Saffran JR, 1999, COGNITION, V70, P27, DOI 10.1016/S0010-0277(98)00075-4
   Siegelman N, 2017, PHILOS T R SOC B, V372, DOI 10.1098/rstb.2016.0059
   Spaulding TJ, 2008, J SPEECH LANG HEAR R, V51, P16, DOI 10.1044/1092-4388(2008/002)
   Theodore RM, 2019, PSYCHON B REV, V26, P985, DOI 10.3758/s13423-018-1551-5
   Theodore RM, 2009, J ACOUST SOC AM, V125, P3974, DOI 10.1121/1.3106131
   Torgesen J. K., 2012, TEST WORD READING EF
   Toscano JC, 2010, COGNITIVE SCI, V34, P434, DOI 10.1111/j.1551-6709.2009.01077.x
   Ullman MT, 2005, CORTEX, V41, P399, DOI 10.1016/S0010-9452(08)70276-4
   VanderLely HKJ, 1996, BRAIN LANG, V52, P484, DOI 10.1006/brln.1996.0026
   vanderLely HKJ, 1996, LINGUA, V98, P243, DOI 10.1016/0024-3841(95)00044-5
   VOLAITIS LE, 1992, J ACOUST SOC AM, V92, P723, DOI 10.1121/1.403997
   Wanrooij K, 2013, J PHONETICS, V41, P307, DOI 10.1016/j.wocn.2013.03.005
   Ziegler JC, 2005, P NATL ACAD SCI USA, V102, P14110, DOI 10.1073/pnas.0504446102
NR 54
TC 2
Z9 2
U1 2
U2 2
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD JAN
PY 2020
VL 63
IS 1
BP 1
EP 13
DI 10.1044/2019_JSLHR-S-19-0152
PG 13
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA ND2VF
UT WOS:000561762100001
PM 31841364
OA Green Published
DA 2021-02-24
ER

PT J
AU Nittrouer, S
   Lowenstein, JH
   Antonelli, J
AF Nittrouer, Susan
   Lowenstein, Joanna H.
   Antonelli, Joseph
TI Parental Language Input to Children With Hearing Loss: Does It Matter in
   the End?
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SPEECH-PERCEPTION; OTITIS-MEDIA; SIMILARITY NEIGHBORHOODS; PHONOLOGICAL
   AWARENESS; REORGANIZATION; SENSITIVITY; EXPERIENCE; ABILITIES; EFFUSION;
   SKILLS
AB Purpose: Parental language input (PLI) has reliably been found to influence child language development for children at risk of language delay, but previous work has generally restricted observations to the preschool years. The current study examined whether PLI during the early years explains variability in the spoken language abilities of children with hearing loss at those young ages, as well as later in childhood.
   Participants: One hundred children participated: 34 with normal hearing, 24 with moderate losses who used hearing aids (HAs), and 42 with severe-to-profound losses who used cochlear implants (CIs). Mean socioeconomic status was middle class for all groups. Children with CIs generally received them early.
   Method: Samples of parent-child interactions were analyzed to characterize PU during the preschool years. Child language abilities (CLAs) were assessed at 48 months and 10 years of age.
   Results: No differences were observed across groups in how parents interacted with their children. Nonetheless, strong differences across groups were observed in the effects of PLI on CLAs at 48 months of age: Children with normal hearing were largely resilient to their parents' language styles. Children with HAs were most influenced by the amount of PLI. Children with CIs were most influenced by PLI that evoked child language and modeled more complex versions. When potential influences of preschool PLI on CLAs at 10 years of age were examined, those effects at preschool were replicated. When mediation analyses were performed, however, it was found that the influences of preschool PU on CLAs at 10 years of age were partially mediated by CLAs at preschool.
   Conclusion: PLI is critical to the long-term spoken language abilities of children with hearing loss, but the style of input that is most effective varies depending on the severity of risk for delay.
C1 [Nittrouer, Susan; Lowenstein, Joanna H.] Univ Florida, Dept Speech Language & Hearing Sci, Gainesville, FL 32611 USA.
   [Antonelli, Joseph] Univ Florida, Dept Stat, Gainesville, FL 32611 USA.
RP Nittrouer, S (corresponding author), Univ Florida, Dept Speech Language & Hearing Sci, Gainesville, FL 32611 USA.
EM snittrouer@ufl.edu
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01 DC006237, R01 DC015992]
FX This work was supported by National Institute on Deafness and Other
   Communication Disorders Grants R01 DC006237 and R01 DC015992 (awarded to
   Susan Nittrouer). The authors thank staff, students, and families who
   participated in the collection of these data.
CR Bowey JA, 2006, J EXP CHILD PSYCHOL, V95, P1, DOI 10.1016/j.jecp.2006.02.001
   Brownell R., 2000, EXPRESSIVE ONE WORD
   Caldwell A, 2013, J SPEECH LANG HEAR R, V56, P13, DOI 10.1044/1092-4388(2012/11-0338)
   Carrow-Woolfolk E., 1999, COMPREHENSIVE ASSESS
   CHARLESLUCE J, 1990, J CHILD LANG, V17, P205, DOI 10.1017/S0305000900013180
   Davidson K, 2014, J DEAF STUD DEAF EDU, V19, P238, DOI 10.1093/deafed/ent045
   de Boysson-Bardies B., 1986, PRECURSORS EARLY SPE, V44, P113
   DECASPER AJ, 1980, SCIENCE, V208, P1174, DOI 10.1126/science.7375928
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   FERGUSON CA, 1975, LANGUAGE, V51, P419, DOI 10.2307/412864
   Fey ME, 2004, J SPEECH LANG HEAR R, V47, P1301, DOI 10.1044/1092-4388(2004/098)
   FRIELPATTI S, 1990, J SPEECH HEAR RES, V33, P188, DOI 10.1044/jshr.3301.188
   GRAVEL JS, 1992, J SPEECH HEAR RES, V35, P588, DOI 10.1044/jshr.3503.588
   Hamdan FF, 2010, AM J HUM GENET, V87, P671, DOI 10.1016/j.ajhg.2010.09.017
   Hart B., 1995, MEANINGFUL DIFFERENC
   HESS RD, 1965, CHILD DEV, V36, P869, DOI 10.2307/1126930
   Hirsh IJ, 1952, J SPEECH HEAR DISORD, V17, P321, DOI 10.1044/jshd.1703.321
   Hurtado N, 2008, DEVELOPMENTAL SCI, V11, pF31, DOI 10.1111/j.1467-7687.2008.00768.x
   Huttenlocher J, 2010, COGNITIVE PSYCHOL, V61, P343, DOI 10.1016/j.cogpsych.2010.08.002
   Kent R. N., 1977, HDB BEHAVIORAL ASSES, P279
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Lai CSL, 2001, NATURE, V413, P519, DOI 10.1038/35097076
   Laosa L. M., 1982, FAMILIES LEARNING EN, P1
   Leslie L., 2006, QUALITATIVE READING, V4
   LIBERMAN IY, 1974, J EXP CHILD PSYCHOL, V18, P201, DOI 10.1016/0022-0965(74)90101-5
   MacKinnon DP, 2007, ANNU REV PSYCHOL, V58, P593, DOI 10.1146/annurev.psych.58.110405.085542
   Mahr T, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12685
   Mellon NK, 2015, PEDIATRICS, V136, P170, DOI 10.1542/peds.2014-1632
   Menn L., 1983, LANGUAGE PRODUCTION, P3
   Menn L., 1978, SYLLABLES SEGMENTS, P157
   Menyuk P., 1979, LANG ACQUIS, P49
   Metsala JL, 1998, WORD RECOGNITION IN BEGINNING LITERACY, P89
   Miller J. F., 2006, SYSTEMATIC ANAL LANG
   Mullen E., 1995, MULLEN SCALES EARLY
   Nittrouer S, 2005, J COMMUN DISORD, V38, P29, DOI 10.1016/j.jcomdis.2004.03.006
   Nittrouer S, 1996, J SPEECH HEAR RES, V39, P1059, DOI 10.1044/jshr.3905.1059
   Nittrouer S, 2002, LANG SPEECH HEAR SER, V33, P237, DOI 10.1044/0161-1461(2002/020)
   Nittrouer S., 2010, EARLY DEV CHILDREN H
   Nittrouer S, 2018, J SPEECH LANG HEAR R, V61, P2561, DOI 10.1044/2018_JSLHR-H-18-0047
   Nittrouer S, 2015, J SPEECH LANG HEAR R, V58, P1077, DOI 10.1044/2015_JSLHR-H-14-0263
   Nittrouer S, 2014, EAR HEARING, V35, P506, DOI 10.1097/AUD.0000000000000051
   Nittrouer S, 2013, INT J AUDIOL, V52, P513, DOI 10.3109/14992027.2013.792957
   Nittrouer S, 2012, INT J PEDIATR OTORHI, V76, P1148, DOI 10.1016/j.ijporl.2012.04.024
   NORMANJACKSON J, 1982, CHILD DEV, V53, P349, DOI 10.1111/j.1467-8624.1982.tb01323.x
   Nudel R, 2013, WIRES COGN SCI, V4, P547, DOI 10.1002/wcs.1247
   Onnis L, 2018, RES DEV DISABIL, V82, P132, DOI 10.1016/j.ridd.2018.06.015
   Quittner AL, 2013, J PEDIATR-US, V162, P343, DOI 10.1016/j.jpeds.2012.08.003
   Rathmann P., 1994, GOOD NIGHT GORILLA
   Reynell JK, 1990, REYNELL DEV LANGUAGE
   Roid G. H., 2002, LEITER INT PERFORMAN
   Schachter F. F., 1979, EVERYDAY MOTHER TALK
   STANOVICH KE, 1984, J EXP CHILD PSYCHOL, V38, P175, DOI 10.1016/0022-0965(84)90120-6
   Storkel HL, 2002, J CHILD LANG, V29, P251, DOI 10.1017/S0305000902005032
   Studdert-Kennedy M., 1987, LANGUAGE PERCEPTION, P67
   Swanson MR, 2019, AUTISM RES, V12, P1784, DOI 10.1002/aur.2163
   Szagun G, 2012, J SPEECH LANG HEAR R, V55, P1640, DOI 10.1044/1092-4388(2012/11-0119)
   UPDIKE C, 1992, ANN OTO RHINOL LARYN, V101, P530, DOI 10.1177/000348949210100615
   VIHMAN MM, 1989, LANG SPEECH, V32, P149, DOI 10.1177/002383098903200204
   VIHMAN MM, 1991, MODULARITY AND THE MOTOR THEORY OF SPEECH PERCEPTION, P69
   WAGNER RK, 1987, PSYCHOL BULL, V101, P192, DOI 10.1037/0033-2909.101.2.192
   Waterson N, 1971, J LINGUIST, V7, P179, DOI 10.1017/S0022226700002917
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wilcox K., 1999, CHILDRENS SPEECH INT
   Xu SQ, 2018, P NATL ACAD SCI USA, V115, P8799, DOI 10.1073/pnas.1721820115
   Zimmerman FJ, 2009, PEDIATRICS, V124, P342, DOI 10.1542/peds.2008-2267
   Zimmerman I. L., 2002, PRESCHOOL LANGUAGE S
NR 66
TC 1
Z9 1
U1 1
U2 1
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD JAN
PY 2020
VL 63
IS 1
BP 234
EP 258
DI 10.1044/2019_JSLHR-19-00123
PG 25
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA ND2VF
UT WOS:000561762100019
PM 31834998
OA Green Published
DA 2021-02-24
ER

PT J
AU Nagels, L
   Bastiaanse, R
   Baskent, D
   Wagner, A
AF Nagels, Leanne
   Bastiaanse, Roelien
   Baskent, Deniz
   Wagner, Anita
TI Individual Differences in Lexical Access Among Cochlear Implant Users
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SPOKEN-WORD RECOGNITION; NORMAL-HEARING; SPEECH RECOGNITION;
   NEIGHBORHOOD ACTIVATION; PERCEPTUAL RESTORATION; LISTENERS; ADULTS;
   MODEL; INTELLIGIBILITY; COMPETITION
AB Purpose: The current study investigates how individual differences in cochlear implant (CI) users' sensitivity to word-nonword differences, reflecting lexical uncertainty, relate to their reliance on sentential context for lexical access in processing continuous speech.
   Method: Fifteen CI users and 14 normal-hearing (NH) controls participated in an auditory lexical decision task (Experiment 1) and a visual-world paradigm task (Experiment 2). Experiment 1 tested participants' reliance on lexical statistics, and Experiment 2 studied how sentential context affects the time course and patterns of lexical competition leading to lexical access.
   Results: In Experiment 1, CI users had lower accuracy scores and longer reaction times than NH listeners, particularly for nonwords. In Experiment 2, CI users' lexical competition patterns were, on average, similar to those of NH listeners, but the patterns of individual CI users varied greatly. Individual CI users' word-nonword sensitivity (Experiment 1) explained differences in the reliance on sentential context to resolve lexical competition, whereas clinical speech perception scores explained competition with phonologically related words.
   Conclusions: The general analysis of CI users' lexical competition patterns showed merely quantitative differences with NH listeners in the time course of lexical competition, but our additional analysis revealed more qualitative differences in CI users' strategies to process speech. Individuals' word-nonword sensitivity explained different parts of individual variability than clinical speech perception scores. These results stress, particularly for heterogeneous clinical populations such as CI users, the importance of investigating individual differences in addition to group averages, as they can be informative for clinical rehabilitation.
C1 [Nagels, Leanne; Baskent, Deniz; Wagner, Anita] Univ Groningen, Univ Med Ctr Groningen, Dept Otorhinolaryngol Head & Neck Surg, Groningen, Netherlands.
   [Nagels, Leanne; Bastiaanse, Roelien] Univ Groningen, Ctr Language & Cognit Groningen, Groningen, Netherlands.
   [Bastiaanse, Roelien] Natl Res Univ Higher Sch Econ, Moscow, Russia.
   [Baskent, Deniz; Wagner, Anita] Univ Groningen, Res Sch Behav & Cognit Neurosci, Grad Sch Med Sci, Groningen, Netherlands.
RP Nagels, L (corresponding author), Univ Groningen, Univ Med Ctr Groningen, Dept Otorhinolaryngol Head & Neck Surg, Groningen, Netherlands.; Nagels, L (corresponding author), Univ Groningen, Ctr Language & Cognit Groningen, Groningen, Netherlands.
EM leanne.nagels@rug.nl
OI Nagels, Leanne/0000-0003-4853-969X
FU Marie Curie Intra-European Fellowship Grant [FP7-PEOPLE-2012-IEF
   332402]; MED-EL research grant; Vidi grant from the Netherlands
   Organisation for Scientific Research, Netherlands Organisation for
   Health Research and Development Grant [016.093.397]; Heinsius Houbolt
   Foundation; Russian Federation Government Grant through the Center for
   Language and Brain, National Research University Higher School of
   Economics [14.641.31.0004]; Center for Information Technology of the
   University of Groningen
FX This work was supported by Marie Curie Intra-European Fellowship Grant
   FP7-PEOPLE-2012-IEF 332402 and a MED-EL research grant, awarded to Anita
   Wagner; by a Vidi grant from the Netherlands Organisation for Scientific
   Research, Netherlands Organisation for Health Research and Development
   Grant 016.093.397, and funds from the Heinsius Houbolt Foundation,
   awarded to Deniz Baskent; and partially by Russian Federation Government
   Grant 14.641.31.0004 through the Center for Language and Brain, National
   Research University Higher School of Economics, awarded to Roelien
   Bastiaanse. The study is part of the research program "Healthy Ageing
   and Communication" of the Department of Otorhinolaryngology, University
   Medical Center Groningen. We would like to thank Frans Cornelissen
   (University Medical Center Groningen) for providing the eye tracker for
   this study and the Center for Information Technology of the University
   of Groningen for their support and for providing access to the Peregrine
   high-performance computing cluster. Furthermore, we are grateful to
   Paolo Toffanin for his technical support and advice.
CR Amichetti NM, 2018, EAR HEARING, V39, P101, DOI 10.1097/AUD.0000000000000469
   [Anonymous], 2012, MATLAB LANG TECHN CO
   Baskent D., 2016, SCI FDN AUDIOLOGY PE, P285
   Baskent D, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516670279
   Bates D, 2014, PACKAGE LME4
   Bhargava P, 2016, JARO-J ASSOC RES OTO, V17, P475, DOI 10.1007/s10162-016-0565-9
   Blamey P, 2013, AUDIOL NEURO-OTOL, V18, P36, DOI 10.1159/000343189
   BLUMSTEIN SE, 1991, BRAIN LANG, V40, P393, DOI 10.1016/0093-934X(91)90138-Q
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bosman AJ, 1995, AUDIOLOGY, V34, P260
   CHAMBERS SM, 1975, MEM COGNITION, V3, P549, DOI 10.3758/BF03197530
   Chatterjee M, 2008, HEARING RES, V235, P143, DOI 10.1016/j.heares.2007.11.004
   Cornelissen FW, 2002, BEHAV RES METH INS C, V34, P613, DOI 10.3758/BF03195489
   Dahan D, 2004, J EXP PSYCHOL LEARN, V30, P498, DOI 10.1037/0278-7393.30.2.498
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750
   Edwards J, 1996, J SPEECH HEAR RES, V39, P1263, DOI 10.1044/jshr.3906.1263
   Ellis AW., 1996, HUMAN COGNITIVE NEUR
   Farris-Trimble A, 2014, J EXP PSYCHOL HUMAN, V40, P308, DOI 10.1037/a0034353
   Fuller CD, 2014, JARO-J ASSOC RES OTO, V15, P1037, DOI 10.1007/s10162-014-0483-7
   Gaudrain E, 2018, EAR HEARING, V39, P226, DOI 10.1097/AUD.0000000000000480
   Goldinger SD, 1996, LANG COGNITIVE PROC, V11, P559, DOI 10.1080/016909696386944
   Holden LK, 2013, EAR HEARING, V34, P342, DOI 10.1097/AUD.0b013e3182741aa7
   Huang YT, 2017, COGNITION, V166, P184, DOI 10.1016/j.cognition.2017.05.029
   Huang YT, 2011, J CHILD LANG, V38, P644, DOI 10.1017/S0305000910000206
   Ishida M, 2016, COGNITION, V151, P68, DOI 10.1016/j.cognition.2016.03.008
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Keuleers E, 2010, BEHAV RES METHODS, V42, P643, DOI 10.3758/BRM.42.3.643
   KIRK KI, 1995, EAR HEARING, V16, P470, DOI 10.1097/00003446-199510000-00004
   Lazard DS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048739
   Luce P. A., 1986, NEIGHBORHOODS WORDS
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Lyxell B, 1998, SCAND J PSYCHOL, V39, P175, DOI 10.1111/1467-9450.393075
   Magnuson JS, 2007, COGNITIVE SCI, V31, P133, DOI 10.1080/03640210709336987
   MARSLENWILSON W, 1980, COGNITION, V8, P1, DOI 10.1016/0010-0277(80)90015-3
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Mattys SL, 2011, J MEM LANG, V65, P145, DOI 10.1016/j.jml.2011.04.004
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2017, COGNITION, V169, P147, DOI 10.1016/j.cognition.2017.08.013
   McMurray B, 2016, EAR HEARING, V37, pe37, DOI 10.1097/AUD.0000000000000207
   Mirman D., 2014, GROWTH CURVE ANAL VI
   Moberly AC, 2014, J SPEECH LANG HEAR R, V57, P566, DOI 10.1044/2014_JSLHR-H-12-0323
   NEELY JH, 1989, J EXP PSYCHOL LEARN, V15, P1003, DOI 10.1037/0278-7393.15.6.1003
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Peng SC, 2012, TRENDS AMPLIF, V16, P67, DOI 10.1177/1084713812451159
   Pichora-Fuller MK, 2008, INT J AUDIOL, V47, pS72, DOI 10.1080/14992020802307404
   Pisoni David B, 2017, World J Otorhinolaryngol Head Neck Surg, V3, P240, DOI 10.1016/j.wjorl.2017.12.010
   Pisoni DB, 2000, EAR HEARING, V21, P70, DOI 10.1097/00003446-200002000-00010
   R Core Team, 2013, R LANG ENV STAT COMP
   Rouger J, 2007, P NATL ACAD SCI USA, V104, P7295, DOI 10.1073/pnas.0609419104
   Saija JD, 2014, JARO-J ASSOC RES OTO, V15, P139, DOI 10.1007/s10162-013-0422-z
   SAMUEL AG, 1981, J EXP PSYCHOL GEN, V110, P474, DOI 10.1037/0096-3445.110.4.474
   Sommers MS, 1997, EAR HEARING, V18, P89, DOI 10.1097/00003446-199704000-00001
   Stickney GS, 2004, J ACOUST SOC AM, V116, P1081, DOI 10.1121/1.1772399
   TAFT M, 1986, COGNITION, V22, P259, DOI 10.1016/0010-0277(86)90017-X
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Verhage F., 1964, INTELLIGENCE AGE RES
   Vitevitch Michael S, 2004, J Multiling Commun Disord, V3, P64, DOI 10.1080/14769670400027332
   Vitevitch MS, 2000, VOLTA REV, V102, P283
   Vitevitch MS, 1998, PSYCHOL SCI, V9, P325, DOI 10.1111/1467-9280.00064
   Vitevitch MS, 1999, BRAIN LANG, V68, P306, DOI 10.1006/brln.1999.2116
   Wagner A. E., 2019, TRENDS HEAR, V23, P1
   Wagner A, 2016, ADV EXP MED BIOL, V894, P297, DOI 10.1007/978-3-319-25474-6_31
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Winn MB, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516669723
   Yee E, 2006, J EXP PSYCHOL LEARN, V32, P1, DOI 10.1037/0278-7393.32.1.1
   Zhang XJ, 2018, J MEM LANG, V100, P32, DOI 10.1016/j.jml.2018.01.002
   Zhou X, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0039011
NR 69
TC 0
Z9 1
U1 0
U2 0
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD JAN
PY 2020
VL 63
IS 1
BP 286
EP 304
DI 10.1044/2019_JSLHR-19-00192
PG 19
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA ND2VF
UT WOS:000561762100022
PM 31855606
OA Green Published
DA 2021-02-24
ER

PT J
AU Johnson, EK
   White, KS
AF Johnson, Elizabeth K.
   White, Katherine S.
TI Developmental sociolinguistics: Children's acquisition of language
   variation
SO WILEY INTERDISCIPLINARY REVIEWS-COGNITIVE SCIENCE
LA English
DT Article
DE children; language development; sociolinguistics; speech perception;
   speech production
ID TODDLERS PERCEPTION; AMERICAN ENGLISH; FOREIGN ACCENT; VARIABLE RULES;
   SPEECH; DIALECT; ADULT; COMPREHENSION; INFORMATION; RECOGNITION
AB Developmental sociolinguistics is a rapidly evolving interdisciplinary framework that builds upon theoretical and methodological contributions from multiple disciplines (i.e., sociolinguistics, language acquisition, the speech sciences, developmental psychology, and psycholinguistics). A core assumption of this framework is that language is by its very nature variable, and that much of this variability is informative, as it is (probabilistically) governed by a variety of factors-including linguistic context, social or cultural context, the relationship between speaker and addressee, a language user's geographic origin, and a language user's gender identity. It is becoming increasingly clear that consideration of these factors is absolutely essential to developing realistic and ecologically valid models of language development. Given the central importance of language in our social world, a more complete understanding of early social development will also require a deeper understanding of when and how language variation influences children's social inferences and behavior. As the cross-pollination between formerly disparate fields continues, we anticipate a paradigm shift in the way many language researchers conceptualize the challenge of early acquisition.
C1 [Johnson, Elizabeth K.] Univ Toronto, Dept Psychol, Toronto, ON, Canada.
   [White, Katherine S.] Univ Waterloo, Dept Psychol, Waterloo, ON, Canada.
RP Johnson, EK (corresponding author), Univ Toronto, Dept Psychol, Toronto, ON, Canada.; White, KS (corresponding author), Univ Waterloo, Dept Psychol, Waterloo, ON, Canada.
EM elizabeth.johnson@utoronto.ca; white@uwaterloo.ca
OI Johnson, Elizabeth Kay/0000-0002-9941-9949
FU Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR; Social
   Sciences and Humanities Research Council of CanadaSocial Sciences and
   Humanities Research Council of Canada (SSHRC)
FX Natural Sciences and Engineering Research Council of Canada; Social
   Sciences and Humanities Research Council of Canada
CR Adank P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00280
   Apfelbaum KS, 2011, COGNITIVE SCI, V35, P1105, DOI 10.1111/j.1551-6709.2011.01181.x
   Aslin RN, 1996, SIGNAL TO SYNTAX: BOOTSTRAPPING FROM SPEECH TO GRAMMAR IN EARLY ACQUISITION, P117
   Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001
   Babel M, 2010, LANG SOC, V39, P437, DOI 10.1017/S0047404510000400
   Barbu S, 2013, LINGUISTICS, V51, P381, DOI 10.1515/ling-2013-0015
   Bent T, 2015, J ACOUST SOC AM, V138, P3985, DOI 10.1121/1.4938228
   Best CT, 2009, PSYCHOL SCI, V20, P539, DOI 10.1111/j.1467-9280.2009.02327.x
   Bosch M, 2010, REG SCI URBAN ECON, V40, P11, DOI 10.1016/j.regsciurbeco.2009.11.001
   Brooks R, 2008, J CHILD LANG, V35, P207, DOI 10.1017/S030500090700829X
   Brown R., 1973, 1 LANGUAGE EARLY STA
   Buckler H, 2018, J PHONETICS, V66, P45, DOI 10.1016/j.wocn.2017.09.004
   Buckler H, 2017, J EXP CHILD PSYCHOL, V164, P87, DOI 10.1016/j.jecp.2017.06.017
   Byers-Heinlein K, 2010, PSYCHOL SCI, V21, P343, DOI 10.1177/0956797609360758
   Chen H, 2017, J ACOUST SOC AM, V142, P1707, DOI 10.1121/1.4995994
   Chevrot JP, 2011, LANG SCI, V33, P180, DOI 10.1016/j.langsci.2010.08.007
   Clopper Cynthia G, 2004, Lang Var Change, V16, P31
   Comeau L, 2007, J CHILD LANG, V34, P159, DOI 10.1017/S0305000906007690
   Corriveau KH, 2013, DEV PSYCHOL, V49, P470, DOI 10.1037/a0030604
   Craig HK, 2012, J SPEECH LANG HEAR R, V55, P1274, DOI 10.1044/1092-4388(2012/11-0055)
   Creel S. C., 2018, DEV SCI, V21
   Creel SC, 2016, J EXP CHILD PSYCHOL, V146, P156, DOI 10.1016/j.jecp.2016.01.018
   Curtin S, 2011, J PHONETICS, V39, P492, DOI 10.1016/j.wocn.2010.12.002
   DeJesus JM, 2017, J EXP CHILD PSYCHOL, V164, P178, DOI 10.1016/j.jecp.2017.07.005
   DePaolis RA, 2011, INFANT BEHAV DEV, V34, P590, DOI 10.1016/j.infbeh.2011.06.005
   Docherty GJ, 2013, LINGUISTICS, V51, P355, DOI 10.1515/ling-2013-0014
   Durrant S, 2015, J CHILD LANG, V42, P447, DOI 10.1017/S0305000914000063
   Edwards J, 2014, J SPEECH LANG HEAR R, V57, P1883, DOI 10.1044/2014_JSLHR-L-13-0228
   Evans BG, 2007, J ACOUST SOC AM, V121, P3814, DOI 10.1121/1.2722209
   Fennell C, 2014, INT J BEHAV DEV, V38, P309, DOI 10.1177/0165025414530631
   Floccia C, 2012, COGNITION, V124, P95, DOI 10.1016/j.cognition.2012.03.011
   Floccia C, 2009, INT J BEHAV DEV, V33, P366, DOI 10.1177/0165025409103871
   Foulkes P, 2005, LANGUAGE, V81, P177, DOI 10.1353/lan.2005.0018
   Foulkes P, 2006, J PHONETICS, V34, P409, DOI 10.1016/j.wocn.2005.08.002
   Fridland V, 2012, LINGUA, V122, P779, DOI 10.1016/j.lingua.2011.12.007
   Fuertes JN, 2012, EUR J SOC PSYCHOL, V42, P120, DOI 10.1002/ejsp.862
   Giles H., 1981, LANG SCI, V3, P91, DOI DOI 10.1016/S0388-0001(81)80015-0
   Goldinger S. D., 2007, 16 INT C PHON SCI, P49
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Gonzales K, 2018, COGNITIVE PSYCHOL, V106, P1, DOI 10.1016/j.cogpsych.2018.04.003
   Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014
   Houston DM, 2000, J EXP PSYCHOL HUMAN, V26, P1570, DOI 10.1037/0096-1523.26.5.1570
   Hwang HG, 2018, J CHILD LANG, V45, P1018, DOI 10.1017/S0305000917000587
   Johnson EK, 2016, ANNU REV LINGUIST, V2, P391, DOI 10.1146/annurev-linguistics-011415-040616
   Johnson EK, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0083546
   Jones Z, 2017, J PHONETICS, V60, P20, DOI 10.1016/j.wocn.2016.11.001
   Juscyzk P. W, 1997, DISCOVERY SPOKEN LAN
   JUSCZYK PW, 1995, COGNITIVE PSYCHOL, V29, P1, DOI 10.1006/cogp.1995.1010
   Kam CLH, 2005, LANG LEARN DEV, V1, P151, DOI 10.1207/s15473341lld0102_3
   Kam CLH, 2015, LANGUAGE, V91, P906, DOI 10.1353/lan.2015.0051
   Kam CLH, 2009, COGNITIVE PSYCHOL, V59, P30, DOI 10.1016/j.cogpsych.2009.01.001
   Kendall T, 2017, LANG VAR CHANGE, V29, P245, DOI 10.1017/S0954394517000084
   Kerswill P, 2000, LANG SOC, V29, P65, DOI 10.1017/S0047404500001020
   Kinzler KD, 2007, P NATL ACAD SCI USA, V104, P12577, DOI 10.1073/pnas.0705345104
   Kinzler KD, 2013, Q J EXP PSYCHOL, V66, P1146, DOI 10.1080/17470218.2012.731695
   Kinzler KD, 2009, SOC COGNITION, V27, P623, DOI 10.1521/soco.2009.27.4.623
   Kitamura C, 2013, CHILD DEV, V84, P1686, DOI 10.1111/cdev.12068
   Ko SJ, 2015, PSYCHOL SCI, V26, P3, DOI 10.1177/0956797614553009
   Kouider S, 2006, LANG LEARN DEV, V2, P1, DOI 10.1207/s15473341lld0201_1
   Kozlowski A., 2015, INKBLOT, V4, P12
   Labov W, 1972, ATLANTIC, P1
   Labov W, 1964, SOCIAL DIALECTS LANG, P77
   Labov William, 1990, LANG VAR CHANGE, V2, P205, DOI [10. 1017/S09543945 00000338, DOI 10.1017/S0954394500000338]
   Lahey M, 2014, LANG LEARN DEV, V10, P308, DOI 10.1080/15475441.2013.860813
   Masapollo M, 2016, DEVELOPMENTAL SCI, V19, P318, DOI 10.1111/desc.12298
   Merriman W E, 1989, Monogr Soc Res Child Dev, V54, P1
   Miller K, 2013, LANG VAR CHANGE, V25, P311, DOI 10.1017/S095439451300015X
   Nardy A, 2013, LINGUISTICS, V51, P255, DOI 10.1515/ling-2013-0011
   Nathan L, 1998, J CHILD LANG, V25, P343, DOI 10.1017/S0305000998003444
   Nazzi T, 2000, J MEM LANG, V43, P1, DOI 10.1006/jmla.2000.2698
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Nielsen M, 2017, J EXP CHILD PSYCHOL, V162, P31, DOI 10.1016/j.jecp.2017.04.017
   Paquette-Smith M, 2019, DEV PSYCHOL, V55, P809, DOI 10.1037/dev0000659
   Paquette-Smith M, 2016, LANG LEARN DEV, V12, P328, DOI 10.1080/15475441.2015.1112801
   Rakic T, 2011, J PERS SOC PSYCHOL, V100, P16, DOI 10.1037/a0021522
   Roberts J, 1997, J CHILD LANG, V24, P351, DOI 10.1017/S0305000997003073
   Roberts J. L, 1994, IRCS9609 U PENNS I R
   Rost GC, 2010, INFANCY, V15, P608, DOI 10.1111/j.1532-7078.2010.00033.x
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Samara A, 2017, COGNITIVE PSYCHOL, V94, P85, DOI 10.1016/j.cogpsych.2017.02.004
   Santelmann LM, 1998, COGNITION, V69, P105, DOI 10.1016/S0010-0277(98)00060-2
   Schmale R, 2010, P INT C IND POS IND, P1, DOI DOI 10.1109/IPIN.2010.5647630
   Schmale R, 2009, DEVELOPMENTAL SCI, V12, P583, DOI 10.1111/j.1467-7687.2009.00809.x
   SHATZ M, 1973, MONOGR SOC RES CHILD, V38, P1, DOI 10.2307/1165783
   Shin NL, 2016, J CHILD LANG, V43, P914, DOI 10.1017/S0305000915000380
   Shipley Kenneth G., 1991, LANG SPEECH HEAR SER, V22, P115, DOI DOI 10.1044/0161-1461.2203.115
   SHOCKEY L, 1980, PHONETICA, V37, P267, DOI 10.1159/000259996
   Singh L, 2004, J MEM LANG, V51, P173, DOI 10.1016/j.jml.2004.04.004
   Singleton JL, 2004, COGNITIVE PSYCHOL, V49, P370, DOI 10.1016/j.cogpsych.2004.05.001
   Slobin D. I., 1973, STUDIES CHILD LANGUA
   Smith J, 2007, LANG VAR CHANGE, V19, P63, DOI 10.1017/S0954394507070044
   Smith J, 2013, LINGUISTICS, V51, P285, DOI 10.1515/ling-2013-0012
   Smith J, 2009, LANG VAR CHANGE, V21, P69, DOI 10.1017/S0954394509000039
   Strand EA, 1999, J LANG SOC PSYCHOL, V18, P86, DOI 10.1177/0261927X99018001006
   Subiaul F, 2016, J EXP CHILD PSYCHOL, V141, P145, DOI 10.1016/j.jecp.2015.08.010
   Sumner M, 2015, TRENDS COGN SCI, V19, P238, DOI 10.1016/j.tics.2015.03.007
   Sumner M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01015
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   Tagliamonte SA, 2007, LANG SOC, V36, P649, DOI 10.1017/S0047404507070911
   Trudgill Peter, 1972, LANGUAGE SOC, V1, P179, DOI [10.1017/S0047404500000488, DOI 10.1017/S0047404500000488]
   Trudgill Peter, 1974, SOCIAL DIFFERENTIATI
   Van Berkum JJA, 2008, J COGNITIVE NEUROSCI, V20, P580, DOI 10.1162/jocn.2008.20054
   van der Feest SVH, 2016, LANG ACQUIS, V23, P89, DOI 10.1080/10489223.2015.1047096
   van Heugten M, 2017, J ACOUST SOC AM, V142, pEL196, DOI 10.1121/1.4997604
   van Heugten M, 2015, LANG LEARN DEV, V11, P41, DOI 10.1080/15475441.2013.879636
   van Heugten M, 2015, INFANCY, V20, P675, DOI 10.1111/infa.12094
   van Heugten M, 2009, DEVELOPMENTAL SCI, V12, P419, DOI 10.1111/j.1467-7687.2008.00788.x
   Wagner L, 2014, J CHILD LANG, V41, P1062, DOI 10.1017/S0305000913000330
   Washington JA, 1998, J SPEECH LANG HEAR R, V41, P618, DOI 10.1044/jslhr.4103.618
   Weatherhead D, 2018, COGNITION, V177, P87, DOI 10.1016/j.cognition.2018.04.004
   Weatherhead D, 2018, CHILD DEV, V89, P1613, DOI 10.1111/cdev.12797
   Weatherhead D, 2016, LANG LEARN DEV, V12, P92, DOI 10.1080/15475441.2015.1024835
   Weatherhead D, 2016, J EXP CHILD PSYCHOL, V143, P171, DOI 10.1016/j.jecp.2015.10.011
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   White KS, 2011, DEVELOPMENTAL SCI, V14, P372, DOI 10.1111/j.1467-7687.2010.00986.x
   Wolfram W. A, 1969, SOCIOLINGUISTIC DESC, V5
NR 117
TC 0
Z9 0
U1 3
U2 17
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1939-5078
EI 1939-5086
J9 WIRES COGN SCI
JI Wiley Interdiscip. Rev.-Cogn. Sci.
PD JAN-FEB
PY 2020
VL 11
IS 1
AR e1515
DI 10.1002/wcs.1515
PG 15
WC Psychology, Experimental
SC Psychology
GA NJ2GZ
UT WOS:000565865100002
PM 31454182
DA 2021-02-24
ER

PT J
AU Osawa, E
   Arai, T
   Hodoshima, N
AF Osawa, Eri
   Arai, Takayuki
   Hodoshima, Nao
TI Perception of Japanese length contrasts with reverberation by native and
   nonnative listeners
SO ACOUSTICAL SCIENCE AND TECHNOLOGY
LA English
DT Article
DE Speech perception; Reverberation; Length contrast; Japanese; Nonnative
   listener
ID OVERLAP-MASKING; VOWEL LENGTH; SPEECH; IDENTIFICATION; CONSONANTS;
   SPEAKERS
AB The perception of segmental duration is crucial for the distinction of Japanese length contrasts. However, the perceived duration may be changed in a long reverberation, which adds a "tail" to sounds, making them perceived as being longer. In addition, since lengthened sounds overlap the following sounds, the boundaries of phonemes would become blurred. In the current study, we investigated whether the effects of reverberation distort the distinction of Japanese length contrasts for native Japanese and English listeners. Stimuli were nonword pairs (/baba/-/babaa/, /ata/-/atta/, and /ama/-/amma/) varying in duration along the continuum. The logistic function was used to model the perception. In the distinction of vowel length contrast in the word-final position, even native listeners identified the stimulus with the shortest vowel duration as a long vowel word with reverberation. Regarding the perception of the geminate nasal, "geminate" responses increased with reverberation for native listeners, whereas the results for nonnative listeners indicated that "singleton" responses increased with reverberation. It is assumed that the difference could be attributed to the different prototypes of categories of Japanese between native and nonnative listeners. In addition, the results for nonnative listeners might be attributed to the difference in prosody between English and Japanese.
C1 [Osawa, Eri; Arai, Takayuki] Sophia Univ, Chiyoda Ku, 7-1 Kioi Cho, Tokyo 1028554, Japan.
   [Hodoshima, Nao] Tokai Univ, Minato Ku, 2-3-23 Takanawa, Tokyo 1088619, Japan.
RP Osawa, E (corresponding author), Sophia Univ, Chiyoda Ku, 7-1 Kioi Cho, Tokyo 1028554, Japan.
EM eri1989.16.11@gmail.com; arai@sophia.ac.jp
CR Arai T., 2016, P AUTUMN MEET ACOUST, P293
   Arai T, 2018, ACOUST SCI TECHNOL, V39, P252, DOI 10.1250/ast.39.252
   Boersma P., 2016, GLOT INT, V5, P341
   BOLT RH, 1949, J ACOUST SOC AM, V21, P577, DOI 10.1121/1.1906551
   Bradley JS, 2003, J ACOUST SOC AM, V113, P3233, DOI 10.1121/1.1570439
   Enomoto K., 1992, EDINBURGH WORKING PA, V3, P25
   Fujisaki H., 1977, IWANAMI COURSE JAPAN, P63
   Fujisaki H., 1975, AUDITORY ANAL PERCEP, P197, DOI DOI 10.1016/B978-0-12-248550-3.50017-9
   Hirata Y, 2004, PHONETICA, V61, P177, DOI 10.1159/000084157
   Hirata Y, 2007, J ACOUST SOC AM, V121, P3837, DOI 10.1121/1.2734401
   Hodoshima N, 2006, J ACOUST SOC AM, V119, P4055, DOI 10.1121/1.2198191
   Kato H., 2004, Physica Status Solidi C, P612, DOI 10.1002/pssb.200304189
   Kingston J, 2009, J PHONETICS, V37, P297, DOI 10.1016/j.wocn.2009.03.007
   Knudsen VO, 1929, J ACOUST SOC AM, V1, P56, DOI 10.1121/1.1901470
   Koumura T., 2017, P SPRING M AC SOC JP, P1499
   KREUL EJ, 1968, J SPEECH HEAR RES, V11, P536, DOI 10.1044/jshr.1103.536
   Kuhl P. K., 1995, SPEECH PERCEPTION LI, P121
   Masuda H, 2016, SPEECH COMMUN, V79, P74, DOI 10.1016/j.specom.2016.02.007
   Muroi K., 1995, SOPHIA LINGUIST, P41
   NABELEK AK, 1989, J ACOUST SOC AM, V86, P1259
   NABELEK AK, 1984, J ACOUST SOC AM, V75, P632
   Nakata Y., 2006, IEICE TECH REP, P21
   Ofuka E., 2005, J PHONETIC SOC JAPAN, V9, P59
   Oguma R., 2000, ED JAPANESE WORLD, P43
   Osawa E., 2016, J ACOUST SOC AM, V140, P3333
   Pisoni DB, 1995, SPEECH PERCEPTION LI, P433
   Spivey M., 2000, P CHICAGO LINGUISTIC, V34, P205
   TAKATA Y, 1990, J ACOUST SOC AM, V88, P663, DOI 10.1121/1.399769
   Toda T., 1998, STUDY LIT LANGUAGE L, V33, P65
   Uchida T., 1998, J PHONETIC SOC JAPAN, V2, P71
   Vance T. J., 2008, SOUND JAPANESE
   Watkins AJ, 2005, J ACOUST SOC AM, V118, P249, DOI 10.1121/1.1923369
   Yokoyama S., 1999, J I NOISE CONTROL EN, V23, P228
NR 33
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC JAPAN
PI TOKYO
PA NAKAURA 5TH-BLDG. 2F, 2-18-20 SOTOKANDA, CHIYODA-KU, TOKYO, 101-0021,
   JAPAN
SN 1346-3969
EI 1347-5177
J9 ACOUST SCI TECHNOL
JI Acoust. Sci. Technol.
PY 2020
VL 41
IS 5
BP 751
EP 760
DI 10.1250/ast.41.751
PG 10
WC Acoustics
SC Acoustics
GA NF0LZ
UT WOS:000562996400005
OA Bronze
DA 2021-02-24
ER

PT J
AU Duc, NT
   Lee, B
AF Duc, Nguyen Thanh
   Lee, Boreom
TI Decoding Brain Dynamics in Speech Perception Based on EEG Microstates
   Decomposed by Multivariate Gaussian Hidden Markov Model
SO IEEE ACCESS
LA English
DT Article
DE Speech perception; EEG microstate; source imaging; microstate functional
   connectivity; MGHMM
ID FUNCTIONAL CONNECTIVITY; CORTICAL DYNAMICS; NETWORK; STATES;
   PERFORMANCE; PATTERNS; CORTEX; PART; MEG
AB This study aims to reveal dynamic brain networks during speech perception. All male subjects were presented five English vowel [a], [e], [i], [o], and [u] stimuli. Brain dynamics were decoded using multivariate Gaussian hidden Markov model (MGHMM), which trained on spatiotemporal patterns of broadband multivariate event-related potential amplitudes to identify distinct broadband EEG microstates (MS), microstate source imaging, and microstate functional connectivity (mu FC). Obtained results showed fiuctuated cortical generators and mu FC in eight microstates throughout the perception. Microstate source imaging revealed involvements of bilateral (left-side dominance) posterior superior temporal cortex (TC), inferior frontal gyrus (IFG), and supramarginal regions in perception. Precentral cortex where primary motor cortex located was also significantly activated. These regions were early appeared at 96-151 ms (left-side dominance) and at 186-246 ms (left hemisphere only) after the stimuli onset. Results from fiFC revealed significant increases in delta (2.5-4.5 Hz), theta (4.5-8.5 Hz), alpha (12.5-14.5 Hz), beta (22.5-24.5 Hz), low gamma (30.5-32.5, 38.5-40.5 Hz) but decreases in high gamma (42.5-46.5 Hz) bands in perception. Increased FC were observed mainly at; (1) microstate segments 34-95 ms (MS2) and 96-151 ms (MS3) in early stages, (2) microstate intervals 186-246 ms (MS5) and 297-449 ms (MS6) in subsequent stages of perception. We found that stronger statistical FC differences in perception at TCs, with respect to left IFG (Broca' area), left TC, and precentral areas. Furthermore, by conducting a comparative protocol measuring FC distinction degree, we showed performance improvements of 8.01% (p-value D 0.0162), 14.41% (pvalue D 0.006) when compared MGHMM to well established Lehmann-based modified K-means, Atomize and Agglomerative Hierarchical Clustering and 8.791% (p-value D 0.0097) over the combination of Kmeans and sliding window methods, respectively. This study indicates the usefulness of EEG microstates to investigate broadband brain dynamics in speech perception. The current findings based on male subjects would be generalized more by future studies with a larger appropriate sample size including female subjects.
C1 [Duc, Nguyen Thanh; Lee, Boreom] Gwangju Inst Sci & Technol, Inst Integrated Technol, Dept Biomed Sci & Engn, Gwangju 61005, South Korea.
RP Lee, B (corresponding author), Gwangju Inst Sci & Technol, Inst Integrated Technol, Dept Biomed Sci & Engn, Gwangju 61005, South Korea.
EM leebr@gist.ac.kr
FU National Research Foundation of Korea (NRF) through the Basic Science
   Research Program - Ministry of Science and ICT [2020R1A2B5B01002297]
FX This work was supported by the National Research Foundation of Korea
   (NRF) through the Basic Science Research Program funded by the Ministry
   of Science and ICT under Grant 2020R1A2B5B01002297.
CR Allen EA, 2014, CEREB CORTEX, V24, P663, DOI 10.1093/cercor/bhs352
   Bastiaansen M, 2006, PROG BRAIN RES, V159, P179, DOI 10.1016/S0079-6123(06)59012-0
   Betzel RF, 2012, FRONT COMPUT NEUROSC, V6, DOI 10.3389/fncom.2012.00074
   Brauer J, 2013, BRAIN LANG, V127, P289, DOI 10.1016/j.bandl.2013.03.001
   Cabeza R, 2000, J COGNITIVE NEUROSCI, V12, P1, DOI 10.1162/08989290051137585
   Cacioppo S, 2015, J NEUROSCI METH, V256, P184, DOI 10.1016/j.jneumeth.2015.09.004
   Choleris E, 2018, NEUROSCI BIOBEHAV R, V85, P126, DOI 10.1016/j.neubiorev.2017.07.005
   Custo A, 2017, BRAIN CONNECT, V7, P671, DOI 10.1089/brain.2016.0476
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Desjardins ME, 2017, SLEEP, V40, DOI 10.1093/sleep/zsx024
   Diesch E, 1996, BRAIN LANG, V53, P143, DOI 10.1006/brln.1996.0042
   Dimitriadis SI, 2015, COGN NEURODYNAMICS, V9, P371, DOI 10.1007/s11571-015-9330-8
   Dimitriadis SI, 2013, NEUROIMAGE, V83, P307, DOI 10.1016/j.neuroimage.2013.06.036
   Dimitriadis SI, 2013, BRAIN TOPOGR, V26, P397, DOI 10.1007/s10548-013-0276-z
   Dimitriadis S. I., 2010, J NEUROSCI METH, V193, P55
   Dimitriadis SI, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00506
   Dimitriadis SI, 2012, NONLIN DYNAM PSYCHOL, V16, P5
   Dimitriadis SI, 2009, BRAIN TOPOGR, V22, P119, DOI 10.1007/s10548-008-0071-4
   Nguyen DT, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212582
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Hassan M, 2015, CORTEX, V73, P276, DOI 10.1016/j.cortex.2015.08.019
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hindriks R, 2016, NEUROIMAGE, V127, P242, DOI 10.1016/j.neuroimage.2015.11.055
   Hutchison RM, 2013, NEUROIMAGE, V80, P360, DOI 10.1016/j.neuroimage.2013.05.079
   Indefrey P, 2004, COGNITIVE NEUROSCIENCES III, THIRD EDITION, P759
   Jamal W, 2013, IEEE ENG MED BIO, P2539, DOI 10.1109/EMBC.2013.6610057
   Karamzadeh N, 2013, NEUROIMAGE, V66, P311, DOI 10.1016/j.neuroimage.2012.10.032
   Kim J, 2014, J NEURAL ENG, V11, DOI 10.1088/1741-2560/11/3/036010
   Koenig T, 2002, NEUROIMAGE, V16, P41, DOI 10.1006/nimg.2002.1070
   Leonardi N, 2013, NEUROIMAGE, V83, P937, DOI 10.1016/j.neuroimage.2013.07.019
   Mahyari AG, 2017, IEEE T BIO-MED ENG, V64, P225, DOI 10.1109/TBME.2016.2553960
   Mainy N, 2008, HUM BRAIN MAPP, V29, P1215, DOI 10.1002/hbm.20457
   Mheich A, 2015, J NEUROSCI METH, V242, P77, DOI 10.1016/j.jneumeth.2015.01.002
   Michel CM, 2018, NEUROIMAGE, V180, P577, DOI 10.1016/j.neuroimage.2017.11.062
   Murray MM, 2008, BRAIN TOPOGR, V20, P249, DOI 10.1007/s10548-008-0054-5
   Duc NT, 2020, NEUROINFORMATICS, V18, P71, DOI 10.1007/s12021-019-09419-w
   Duc NT, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab0169
   Nolte G, 2004, CLIN NEUROPHYSIOL, V115, P2292, DOI 10.1016/j.clinph.2004.04.029
   O'Neill GC, 2017, NEUROIMAGE, V146, P667, DOI 10.1016/j.neuroimage.2016.08.061
   Obleser J, 2009, TRENDS COGN SCI, V13, P14, DOI 10.1016/j.tics.2008.09.005
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Preti MG, 2017, NEUROIMAGE, V160, P41, DOI 10.1016/j.neuroimage.2016.12.061
   Qureshi MNI, 2018, IEEE T BIO-MED ENG, V65, P2168, DOI 10.1109/TBME.2017.2786251
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Schomers MR, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00435
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   Shakil S, 2016, NEUROIMAGE, V133, P111, DOI 10.1016/j.neuroimage.2016.02.074
   Stam CJ, 2007, HUM BRAIN MAPP, V28, P1178, DOI 10.1002/hbm.20346
   Strijkers K, 2016, LANG COGN NEUROSCI, V31, P484, DOI 10.1080/23273798.2015.1120878
   Tadel F, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/879716
   Vidaurre D, 2016, NEUROIMAGE, V126, P81, DOI 10.1016/j.neuroimage.2015.11.047
   von Wegner F, 2018, FRONT COMPUT NEUROSC, V12, DOI 10.3389/fncom.2018.00070
   Woolrich MW, 2013, NEUROIMAGE, V77, P77, DOI 10.1016/j.neuroimage.2013.03.036
   Zhang SQ, 2018, PROG NEURO-PSYCHOPH, V83, P76, DOI 10.1016/j.pnpbp.2018.01.006
NR 54
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 146770
EP 146784
DI 10.1109/ACCESS.2020.3015292
PG 15
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA ND7MD
UT WOS:000562086100001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Sharon, RA
   Narayanan, SS
   Sur, M
   Murthy, AH
AF Sharon, Rini A.
   Narayanan, Shrikanth S.
   Sur, Mriganka
   Murthy, A. Hema
TI Neural Speech Decoding During Audition, Imagination and Production
SO IEEE ACCESS
LA English
DT Article
DE Electroencephalography; Production; Protocols; Image segmentation; Brain
   modeling; Correlation; Image reconstruction; Assistive technology; brain
   computer interface; EEG; imagined speech; speech-EEG correlation; unit
   classification
ID BRAIN-COMPUTER INTERFACES; EEG SIGNALS
AB Interpretation of neural signals to a form that is as intelligible as speech facilitates the development of communication mediums for the otherwise speech/motor-impaired individuals. Speech perception, production, and imagination often constitute phases of human communication. The primary goal of this article is to analyze the similarity between these three phases by studying electroencephalogram(EEG) patterns across these modalities, in order to establish their usefulness for brain computer interfaces. Neural decoding of speech using such non-invasive techniques necessitates the optimal choice of signal analysis and translation protocols. By employing selection-by-exclusion based temporal modeling algorithms, we discover fundamental syllable-like units that reveal similar set of signal signatures across all the three phases. Significantly higher than chance accuracies are recorded for single trial multi-unit EEG classification using machine learning approaches over three datasets across 30 subjects. Repeatability and subject independence tests performed at every step of the analysis further strengthens the findings and holds promise for translating brain signals to speech non-invasively.
C1 [Sharon, Rini A.; Murthy, A. Hema] IIT Madras, Dept Comp Sci & Engn, Chennai 600036, Tamil Nadu, India.
   [Narayanan, Shrikanth S.] Univ Southern Calif, Viterbi Sch Engn, Los Angeles, CA 90007 USA.
   [Sur, Mriganka] MIT, Dept Brain & Cognit Sci, E25-618, Cambridge, MA 02139 USA.
RP Sharon, RA (corresponding author), IIT Madras, Dept Comp Sci & Engn, Chennai 600036, Tamil Nadu, India.
EM ee15d210@smail.iitm.ac.in
OI /0000-0003-2442-5671
CR Abdulkader SN, 2015, EGYPT INFORM J, V16, P213, DOI 10.1016/j.eij.2015.06.002
   Abdulla WH, 2003, TENCON IEEE REGION, P1576
   Acharya VJ, 2020, CLIN NEUROPHYS PRACT, V5, P10, DOI 10.1016/j.cnp.2019.11.001
   Al-Fahoum A. S., 2014, ISRN NEUROSCIENCE, V2014, P7, DOI DOI 10.1155/2014/730218
   Moctezuma LA, 2019, EXPERT SYST APPL, V118, P201, DOI 10.1016/j.eswa.2018.10.004
   Anumanchipalli GK, 2019, NATURE, V568, P493, DOI 10.1038/s41586-019-1119-1
   Ardila A., 2016, PSYCHOL NEUROSCI, V9, P340, DOI [10.1037/pne0000060, DOI 10.1037/PNE0000060]
   Bakhshali MA, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101899
   Biesmans W, 2015, IEEE ENG MED BIO, P5155, DOI 10.1109/EMBC.2015.7319552
   Brigham K, 2010, INT CONF BIOINFORM
   Brownsett SLE, 2010, CEREB CORTEX, V20, P517, DOI 10.1093/cercor/bhp120
   Burle B, 2015, INT J PSYCHOPHYSIOL, V97, P210, DOI 10.1016/j.ijpsycho.2015.05.004
   Chu Catherine J, 2015, Clin Neurophysiol, V126, P433, DOI 10.1016/j.clinph.2014.07.003
   Cincotti F, 2008, BRAIN RES BULL, V75, P796, DOI 10.1016/j.brainresbull.2008.01.007
   Cooney C., 2019, P 8 GRAZ BRAIN COMP, P338
   Correia JM, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00071
   Crosse MJ, 2015, J NEUROSCI, V35, P14195, DOI 10.1523/JNEUROSCI.1829-15.2015
   D'Zmura M, 2009, LECT NOTES COMPUT SC, V5610, P40, DOI 10.1007/978-3-642-02574-7_5
   Ding N, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00311
   FERNANDEZ T, 1995, ELECTROEN CLIN NEURO, V94, P175, DOI 10.1016/0013-4694(94)00262-J
   Gales M, 2007, FOUND TRENDS SIGNAL, V1, P195, DOI 10.1561/2000000004
   Garofalo J., 2007, CSR I WSJ0 COMPLETE
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Herff C, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01267
   Idrees BM, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P1130
   Jalil M, 2013, 2013 INTERNATIONAL CONFERENCE ON TECHNOLOGICAL ADVANCES IN ELECTRICAL, ELECTRONICS AND COMPUTER ENGINEERING (TAEECE), P208
   Jin J, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0049688
   Kevric J, 2017, BIOMED SIGNAL PROCES, V31, P398, DOI 10.1016/j.bspc.2016.09.007
   Kiernan J A, 2012, Epilepsy Res Treat, V2012, P176157, DOI 10.1155/2012/176157
   Leeb R, 2013, ARTIF INTELL MED, V59, P121, DOI 10.1016/j.artmed.2013.08.004
   Li JB, 2008, IEEE IJCNN, P2366, DOI 10.1109/IJCNN.2008.4634126
   Li Ming-Ai, 2009, Proceedings of the 2009 Fifth International Conference on Natural Computation (ICNC 2009), P139, DOI 10.1109/ICNC.2009.220
   Marrufo MV, 2001, COGNITIVE BRAIN RES, V12, P315
   Melnik A, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00150
   Millan JD, 2008, INT J PATTERN RECOGN, V22, P959
   Min B, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/2618265
   Moses DA, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10994-4
   O'Sullivan JA, 2015, CEREB CORTEX, V25, P1697, DOI 10.1093/cercor/bht355
   Panicker RC, 2011, IEEE T BIO-MED ENG, V58, P1781, DOI 10.1109/TBME.2011.2116018
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   Porbadnigk A., 2009, P INT C BIOINSP SYST
   Povey D., 2011, P IEEE WORKSH AUT SP, P1, DOI DOI 10.1017/CBO9781107415324.004
   Qureshi MNI, 2018, IEEE T BIO-MED ENG, V65, P2168, DOI 10.1109/TBME.2017.2786251
   Rosinova M, 2017, ELMAR PROC, P153, DOI 10.23919/ELMAR.2017.8124457
   Sadiq M. T., 2019, IEEE ACCESS, V7, P171431
   Saha P., 2019, ARXIV190405746
   SAKOE H, 1979, IEEE T ACOUST SPEECH, V27, P588, DOI 10.1109/TASSP.1979.1163310
   SALANSKY N, 1995, AM J EEG TECHNOL, V35, P98, DOI 10.1080/00029238.1995.11080508
   Sharma RK, 2019, PATHOG GLOB HEALTH, DOI [10.1080/20477724.2019.1685802, 10.1007/978-981-10-8234-4_1]
   Sharon R. A., 2020, P NAT C COMM NCC FEB, P1
   Shih JJ, 2012, MAYO CLIN PROC, V87, P268, DOI 10.1016/j.mayocp.2011.12.008
   Sun P., 2016, ARXIV161205369
   Waldert S, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00295
   Wang Y, 2010, ELECTRON LETT, V46, P1057, DOI 10.1049/el.2010.0923
   Wolpaw J., 2012, BRAIN COMPUTER INTER
   Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3
   Yang MD, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1121
   Zhao SN, 2015, INT CONF ACOUST SPEE, P992, DOI 10.1109/ICASSP.2015.7178118
NR 59
TC 1
Z9 1
U1 2
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 149714
EP 149729
DI 10.1109/ACCESS.2020.3016756
PG 16
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA ND7DO
UT WOS:000562063400001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Al-Salim, S
   Moeller, MP
   McGregor, KK
AF Al-Salim, Sarah
   Moeller, Mary Pat
   McGregor, Karla K.
TI Performance of Children With Hearing Loss on an Audiovisual Version of a
   Nonword Repetition Task
SO LANGUAGE SPEECH AND HEARING SERVICES IN SCHOOLS
LA English
DT Article
ID LANGUAGE IMPAIRMENT; COCHLEAR IMPLANTS; PHONOLOGICAL MEMORY;
   SPEECH-PERCEPTION; WORKING-MEMORY; IMITATION; LITERACY; SKILLS;
   DISCRIMINATION; AWARENESS
AB Purpose: The aims of this study were to (a) determine if a high-quality adaptation of an audiovisual nonword repetition task can be completed by children with wide-ranging hearing abilities and to (b) examine whether performance on that task is sensitive to child demographics, hearing status, language, working memory, and executive function abilities.
   Method: An audiovisual version of a nonword repetition task was adapted and administered to 100 school-aged children grouped by hearing status: 35 with normal hearing, 22 with mild bilateral hearing loss, 17 with unilateral hearing loss, and 26 cochlear implant users. Participants also completed measures of vocabulary, working memory, and executive function. A generalized linear mixed-effects model was used to analyze performance on the nonword repetition task.
   Results: All children were able to complete the nonword repetition task. Children with unilateral hearing loss and children with cochlear implants repeated nonwords with less accuracy than normal-hearing peers. After adjusting for the influence of vocabulary and working memory, main effects were found for syllable length and hearing status, but no interaction effect was observed.
   Conclusions: The audiovisual nonword repetition task captured individual differences in the performance of children with wide-ranging hearing abilities. The task could act as a useful tool to aid in identifying children with unilateral or mild bilateral hearing loss who have language impairments beyond those imposed by the hearing loss.
C1 [Al-Salim, Sarah; Moeller, Mary Pat; McGregor, Karla K.] Boys Town Natl Res Hosp, Ctr Childhood Deafness Language & Learning, Omaha, NE 68131 USA.
RP Al-Salim, S (corresponding author), Boys Town Natl Res Hosp, Ctr Childhood Deafness Language & Learning, Omaha, NE 68131 USA.
EM sarah.al-salimr@boystown.org
RI Al-Salim, Sarah/ABA-9646-2020
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [P30 DC004662, P20
   GM109023]
FX This research was supported by grants from the National Institutes of
   Health: P30 DC004662 (principal investigator, Michael P. Gorga) and P20
   GM109023 (principal investigator, Walt Jesteadt). We thank Kendra Schmid
   and Ryan McCreery for input and assistance with the statistical
   analyses. We also thank Barb Peterson for recruitment support; Sara
   Robinson, Kayla Samuelson, and Steph Tupper for testing participants;
   and Tom Creutz for programming assistance. We also thank Julia Evans,
   Lisa Goffman, and Andrew Oxenham, project external advisors, for their
   valuable input.
CR Alloway TP, 2004, J EXP CHILD PSYCHOL, V87, P85, DOI 10.1016/j.jecp.2003.10.002
   Alloway TP., 2007, AUTOMATED WORKING ME
   Archibald LMD, 2008, CAN J SPEECH-LANG PA, V32, P21
   Baddeley A, 2003, NAT REV NEUROSCI, V4, P829, DOI 10.1038/nrn1201
   Botting N, 2017, CHILD DEV, V88, P1689, DOI 10.1111/cdev.12659
   Briscoe J, 2001, J CHILD PSYCHOL PSYC, V42, P329, DOI 10.1017/S0021963001007041
   Burkholder-Juhasz RA, 2007, J DEAF STUD DEAF EDU, V12, P472, DOI 10.1093/deafed/enm031
   Campbell T, 1997, J SPEECH LANG HEAR R, V40, P519, DOI 10.1044/jslhr.4003.519
   Carter AK, 2002, CLIN LINGUIST PHONET, V16, P619, DOI 10.1080/02699200021000034958
   Casserly ED, 2013, OTOL NEUROTOL, V34, P460, DOI 10.1097/MAO.0b013e3182868340
   Cleary M, 2002, ANN OTO RHINOL LARYN, V111, P91
   Conti-Ramsden G, 2003, J SPEECH LANG HEAR R, V46, P1029, DOI 10.1044/1092-4388(2003/082)
   de Jong PF, 2000, J EXP CHILD PSYCHOL, V76, P275, DOI 10.1006/jecp.1999.2549
   Dillon C, 2004, ARCH OTOLARYNGOL, V130, P587, DOI 10.1001/archotol.130.5.587
   Dollaghan C, 1998, J SPEECH LANG HEAR R, V41, P1136, DOI 10.1044/jslhr.4105.1136
   Ead B, 2013, INT J PEDIATR OTORHI, V77, P1856, DOI 10.1016/j.ijporl.2013.08.028
   Edwards J, 2004, J SPEECH LANG HEAR R, V47, P421, DOI 10.1044/1092-4388(2004/034)
   Edwards J, 1998, APPL PSYCHOLINGUIST, V19, P279, DOI 10.1017/S0142716400010079
   Estes KG, 2007, J SPEECH LANG HEAR R, V50, P177, DOI 10.1044/1092-4388(2007/015)
   Figueras B, 2008, J DEAF STUD DEAF EDU, V13, P362, DOI 10.1093/deafed/enm067
   Fitzpatrick EM, 2019, J AM ACAD AUDIOL, V30, P93, DOI 10.3766/jaaa.17020
   Fitzpatrick EM, 2019, HEARING RES, V372, P42, DOI 10.1016/j.heares.2018.03.015
   Ganek H, 2012, OTOLARYNG CLIN N AM, V45, P173, DOI 10.1016/j.otc.2011.08.024
   Gathercole S E, 1994, Memory, V2, P103, DOI 10.1080/09658219408258940
   GATHERCOLE SE, 1991, BRIT J PSYCHOL, V82, P387, DOI 10.1111/j.2044-8295.1991.tb02407.x
   GATHERCOLE SE, 1990, J MEM LANG, V29, P336, DOI 10.1016/0749-596X(90)90004-J
   Geers AE, 2016, J SPEECH LANG HEAR R, V59, P155, DOI 10.1044/2015_JSLHR-H-14-0173
   Gershkoff-Stowe L, 2002, J MEM LANG, V46, P665, DOI 10.1006/jmla.2001.2830
   Gershon RC, 2013, NEUROLOGY, V80, pS2, DOI 10.1212/WNL.0b013e3182872e5f
   GILBERTSON M, 1995, J SPEECH HEAR RES, V38, P630, DOI 10.1044/jshr.3803.630
   Halliday LF, 2005, J SPEECH LANG HEAR R, V48, P1187, DOI 10.1044/1092-4388(2005/083)
   Hawker K, 2008, EAR HEARING, V29, P467, DOI 10.1097/AUD.0b013e318167b857
   Jerger S, 2017, INT J PEDIATR OTORHI, V94, P127, DOI 10.1016/j.ijporl.2017.01.009
   Klein KE, 2017, J SPEECH LANG HEAR R, V60, P2281, DOI 10.1044/2017_JSLHR-H-16-0086
   Lalonde K, 2016, J ACOUST SOC AM, V139, P1713, DOI 10.1121/1.4945590
   Lieu Judith E C, 2018, Curr Otorhinolaryngol Rep, V6, P74, DOI 10.1007/s40136-018-0185-5
   McGregor KK, 2013, INT J LANG COMM DIS, V48, P307, DOI 10.1111/1460-6984.12008
   Metsala JL, 1999, J EDUC PSYCHOL, V91, P3, DOI 10.1037/0022-0663.91.1.3
   Moeller MP, 2007, EAR HEARING, V28, P740, DOI 10.1097/AUD.0b013e318157f07f
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Nittrouer S, 2014, AM J SPEECH-LANG PAT, V23, P679, DOI 10.1044/2014_AJSLP-14-0040
   Ryan C. L., 2016, POPULATION CHARACTER, V2016, P20
   Shriberg LD, 2009, J SPEECH LANG HEAR R, V52, P1189, DOI 10.1044/1092-4388(2009/08-0047)
   SHRIBERG LD, 1994, J SPEECH HEAR RES, V37, P1100, DOI 10.1044/jshr.3705.1100
   Stiles DJ, 2012, J SPEECH LANG HEAR R, V55, P764, DOI 10.1044/1092-4388(2011/10-0264)
   Wake M, 2004, EAR HEARING, V25, P1, DOI 10.1097/01.AUD.0000111262.12219.2F
   Wake M, 2006, PEDIATRICS, V118, P1842, DOI 10.1542/peds.2005-3168
   Walker EA, 2017, AM J AUDIOL, V26, P38, DOI 10.1044/2016_AJA-16-0063
   WALLEY AC, 1990, PERCEPT PSYCHOPHYS, V47, P267, DOI 10.3758/BF03205001
   Wechsler D., 2011, WECHSLER ABBREVIATED
   Weismer SE, 2000, J SPEECH LANG HEAR R, V43, P865, DOI 10.1044/jslhr.4304.865
   Westfall P.H., 2011, MULTIPLE COMP MULTIP
NR 52
TC 3
Z9 3
U1 0
U2 1
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 0161-1461
EI 1558-9129
J9 LANG SPEECH HEAR SER
JI Lang. Speech Hear. Serv. Sch.
PD JAN
PY 2020
VL 51
IS 1
BP 42
EP 54
DI 10.1044/2019_LSHSS-OCHL-19-0016
PG 13
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA MO4GA
UT WOS:000551485200005
PM 31913807
OA Green Published
DA 2021-02-24
ER

PT J
AU Reynolds, G
   Werfel, KL
AF Reynolds, Gabriella
   Werfel, Krystal L.
TI Home Literacy Environment and Emergent Skills in Preschool Children With
   Hearing Loss
SO JOURNAL OF DEAF STUDIES AND DEAF EDUCATION
LA English
DT Article
ID PHONOLOGICAL AWARENESS INTERVENTION; LANGUAGE-DEVELOPMENT; COCHLEAR
   IMPLANTATION; VOCABULARY KNOWLEDGE; SPEECH-PERCEPTION; WORD RECOGNITION;
   PRINT KNOWLEDGE; YOUNG-CHILDREN; DEAF-CHILDREN; READING SKILL
AB Home literacy practices reported by parents of preschool children with hearing loss were compared to those reported by parents of their peers with typical hearing. Parents completed a questionnaire from Boudreau, D. (2005. Use of a parent questionnaire in emergent and early literacy assessment of preschool children. Language, Speech, and Hearing Services in Schools, 36, 33-47. doi:10.1044/0161-1461(2005/004)) assessing home literacy practices across areas such as parent facilitation of literacy and time spent reading per week. As part of a larger study, children completed language and emergent literacy assessments. Parents of both groups reported similar amounts of time spent reading to their children and scored similarly on report of parent facilitation of literacy, even though children with hearing loss scored lower on measures of emergent literacy. However, parents of children with typical hearing reported that their children had higher engagement and interest in books than children with hearing loss. Additionally, only child engagement with books was correlated with emergent literacy skills and only for children with hearing loss. The results suggest that parent facilitation of literacy alone is not correlated with emergent literacy scores; children must take an active role in their reading development. Children with hearing loss must be active participants during shared book reading. It is therefore essential to develop ways to actively engage children with hearing loss during reading activities.
C1 [Reynolds, Gabriella; Werfel, Krystal L.] Univ South Carolina, Columbia, SC 29208 USA.
RP Reynolds, G (corresponding author), 1224 Sumter St,Suite 300, Columbia, SC 29201 USA.
EM gir1@email.sc.edu
FU National Institute on Deafness and Other Communication Disorders of the
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R03DC014535]
FX National Institute on Deafness and Other Communication Disorders of the
   National Institutes of Health (R03DC014535 to K.L.W.).
CR Ambrose SE, 2012, J SPEECH LANG HEAR R, V55, P811, DOI 10.1044/1092-4388(2011/11-0086)
   Aram D, 2006, LANG SPEECH HEAR SER, V37, P209, DOI 10.1044/0161-1461(2006/023)
   Archbold S, 2008, INT J PEDIATR OTORHI, V72, P1471, DOI 10.1016/j.ijporl.2008.06.016
   ARNOLD DH, 1994, J EDUC PSYCHOL, V86, P235, DOI 10.1037/0022-0663.86.2.235
   Blom-Hoffman J, 2006, PSYCHOL SCHOOLS, V43, P71, DOI 10.1002/pits.20130
   Boudreau D, 2005, LANG SPEECH HEAR SER, V36, P33, DOI 10.1044/0161-1461(2005/004)
   Burgess S., 1997, EARLY CHILD DEV CARE, V127, P191, DOI DOI 10.1080/0300443971270116
   Carney AE, 1998, J SPEECH LANG HEAR R, V41, pS61, DOI 10.1044/jslhr.4101.s61
   Colin S, 2007, J CHILD PSYCHOL PSYC, V48, P139, DOI 10.1111/j.1469-7610.2006.01700.x
   Convertino C, 2014, J DEAF STUD DEAF EDU, V19, P471, DOI 10.1093/deafed/enu024
   Davidson Lisa S, 2014, Cochlear Implants Int, V15, P211, DOI 10.1179/1754762813Y.0000000051
   de Long PF, 2001, J SCHOOL PSYCHOL, V39, P389
   DesJardin JL, 2007, EAR HEARING, V28, P456, DOI 10.1097/AUD.0b013e31806dc1ab
   DesJardin JL, 2009, J DEAF STUD DEAF EDU, V14, P22, DOI 10.1093/deafed/enn011
   DesJardin JL, 2009, INT J AUDIOL, V48, P248, DOI 10.1080/14992020802607423
   Duncan GJ, 2007, DEV PSYCHOL, V43, P1428, DOI 10.1037/0012-1649.43.6.1428
   Dunn D. M., 2007, PEABODY PICTURE VOCA
   Dynia JM, 2014, TOP EARLY CHILD SPEC, V34, P142, DOI 10.1177/0271121414536784
   Easterbrooks SR, 2012, AM ANN DEAF, V157, P27, DOI 10.1353/aad.2012.1611
   Easterbrooks SR, 2008, VOLTA REV, V108, P91
   Ehrler D. J., 2008, PTONI PRIMARY TEST N
   El-Hakim H, 2001, INT J PEDIATR OTORHI, V59, P187, DOI 10.1016/S0165-5876(01)00481-5
   Evans MA, 2008, CAN PSYCHOL, V49, P89, DOI 10.1037/0708-5591.49.2.89
   Geers AE, 2003, EAR HEARING, V24, p59S, DOI 10.1097/01.AUD.0000051690.43989.5D
   Geers AE, 2003, EAR HEARING, V24, p46S, DOI 10.1097/01.AUD.0000051689.57380.1B
   Geers Ann E, 2011, Ear Hear, V32, p49S, DOI 10.1097/AUD.0b013e3181fa41fa
   Harris M, 1998, J Deaf Stud Deaf Educ, V3, P205
   Harris PA, 2009, J BIOMED INFORM, V42, P377, DOI 10.1016/j.jbi.2008.08.010
   HIEBERT EH, 1981, READ RES QUART, V16, P236, DOI 10.2307/747558
   Holt RF, 2005, EAR HEARING, V26, P132, DOI 10.1097/00003446-200504000-00003
   Hresko W. P., 1999, TEST EARLY LANGUAGE
   Invernizzi M., 2001, PALS PHONOLOGICAL AW
   Justice L. M., 2001, CHILD LANG TEACH THE, V17, P207, DOI DOI 10.1177/026565900101700303
   Justice LM, 2009, LANG SPEECH HEAR SER, V40, P67, DOI 10.1044/0161-1461(2008/07-0098)
   Justice LM, 2005, J RES READ, V28, P229, DOI 10.1111/j.1467-9817.2005.00267.x
   Justice LM, 2000, AM J SPEECH-LANG PAT, V9, P257, DOI 10.1044/1058-0360.0903.257
   Kaderavek JN, 2007, J EARLY CHILD LIT, V7, P49, DOI 10.1177/1468798407074835
   Kyle FE, 2010, J EXP CHILD PSYCHOL, V107, P229, DOI 10.1016/j.jecp.2010.04.011
   Leseman PPM, 1998, READ RES QUART, V33, P294, DOI 10.1598/RRQ.33.3.3
   Lund E, 2016, J DEAF STUD DEAF EDU, V21, P107, DOI 10.1093/deafed/env060
   Marchman VA, 2008, DEVELOPMENTAL SCI, V11, pF9, DOI 10.1111/j.1467-7687.2008.00671.x
   Marschark M, 2015, EXCEPT CHILDREN, V81, P350, DOI 10.1177/0014402914563700
   Martin N.A., 2011, EXPRESSIVE ONE WORD
   MASON JM, 1980, READ RES QUART, V15, P203, DOI 10.2307/747325
   Mayer C, 2018, J DEAF STUD DEAF EDU, V23, P1, DOI 10.1093/deafed/enx043
   Mayne AM, 1998, VOLTA REV, V100, P1
   Moeller MP, 2000, PEDIATRICS, V106, DOI 10.1542/peds.106.3.e43
   Most T, 2006, VOLTA REV, V106, P5
   National Early Literacy Panel, 2008, DEV EARL LIT REP NAT
   National Reading Panel (U.S.) & National Institute of Child Health and Human Development (U.S.), 2000, REP NAT READ PAN TEA
   Nicholas JG, 2007, J SPEECH LANG HEAR R, V50, P1048, DOI 10.1044/1092-4388(2007/073)
   Nott P, 2009, EAR HEARING, V30, P526, DOI 10.1097/AUD.0b013e3181a9ea14
   Paul PV, 2009, AM ANN DEAF, V154, P346, DOI 10.1353/aad.0.0110
   PAYNE AC, 1994, EARLY CHILD RES Q, V9, P427, DOI 10.1016/0885-2006(94)90018-3
   Piasta SB, 2012, CHILD DEV, V83, P810, DOI 10.1111/j.1467-8624.2012.01754.x
   Qi S, 2012, J DEAF STUD DEAF EDU, V17, P1, DOI 10.1093/deafed/enr028
   Roberts JE, 2005, J SPEECH LANG HEAR R, V48, P345, DOI 10.1044/1092-4388(2005/024)
   Runnion E, 2019, LANG SPEECH HEAR SER, V50, P16, DOI 10.1044/2018_LSHSS-18-0015
   Scarborough H. S., 2001, HDB RES EARLY LITERA
   Schuele CM, 2008, LANG SPEECH HEAR SER, V39, P3, DOI 10.1044/0161-1461(2008/002)
   Senechal M, 2006, SCI STUD READ, V10, P59, DOI 10.1207/s1532799xssr1001_4
   Senechal M, 2002, CHILD DEV, V73, P445, DOI 10.1111/1467-8624.00417
   Senechal M, 2008, REV EDUC RES, V78, P880, DOI 10.3102/0034654308320319
   Skibbe LE, 2008, EARLY EDUC DEV, V19, P68, DOI 10.1080/10409280701839015
   Spencer LJ, 2008, EAR HEARING, V29, P270, DOI 10.1097/01.aud.0000305158.84403.f7
   Spencer LJ, 2009, J DEAF STUD DEAF EDU, V14, P1, DOI 10.1093/deafed/enn013
   STAHL SA, 1994, J EDUC PSYCHOL, V86, P221, DOI 10.1037/0022-0663.86.2.221
   Sterne A, 2000, J CHILD PSYCHOL PSYC, V41, P609, DOI 10.1111/1469-7610.00648
   Stobbart C, 2008, J DEV PHYS DISABIL, V20, P139, DOI 10.1007/s10882-007-9085-1
   Svirsky MA, 2004, AUDIOL NEURO-OTOL, V9, P224, DOI 10.1159/000078392
   Swanwick R, 2007, J DEAF STUD DEAF EDU, V12, P385, DOI 10.1093/deafed/enm004
   van Kleeck A, 1997, J SPEECH LANG HEAR R, V40, P1261, DOI 10.1044/jslhr.4006.1261
   WAGNER RK, 1987, PSYCHOL BULL, V101, P192, DOI 10.1037/0033-2909.101.2.192
   Watson L, 2008, DEAF EDUC INT, V10, P22, DOI 10.1002/dei.235
   Werfel KL, 2017, LANG SPEECH HEAR SER, V48, P249, DOI 10.1044/2017_LSHSS-17-0023
   Werfel KL, 2015, COMMUN DISORD Q, V36, P107, DOI 10.1177/1525740114539002
   Whitehurst GJ, 1998, CHILD DEV, V69, P848, DOI 10.1111/j.1467-8624.1998.00848.x
   Williams Cheri, 2004, J Deaf Stud Deaf Educ, V9, P352, DOI 10.1093/deafed/enh045
   Ziolkowski RA, 2008, J EARLY INTERVENTION, V31, P67, DOI 10.1177/1053815108324808
NR 79
TC 0
Z9 0
U1 3
U2 7
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1081-4159
EI 1465-7325
J9 J DEAF STUD DEAF EDU
JI J. Deaf Stud. Deaf Educ.
PD JAN
PY 2020
VL 25
IS 1
BP 68
EP 79
DI 10.1093/deafed/enz025
PG 12
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA LU9FA
UT WOS:000538051300007
PM 31424544
OA Green Published
DA 2021-02-24
ER

PT J
AU Stumbrys, D
   Byckova, J
   Lesinskas, E
   Mataityte-Dirziene, J
   Norkuniene, J
AF Stumbrys, Daumantas
   Byckova, Jekaterina
   Lesinskas, Eugenijus
   Mataityte-Dirziene, Jurga
   Norkuniene, Jolita
TI Social Inequalities in Health: Outcomes of Children's Cochlear
   Implantation in Lithuania
SO SOCIALINE TEORIJA EMPIRIJA POLITIKA IR PRAKTIKA
LA English
DT Article
DE cochlear implants; deaf children; health inequality; Lithuania; speech
   perception
ID BOURDIEU; AGENCY; LIFE
AB The aim of this study was to evaluate the demographic, family, and educational differences in children's speech perception development after cochlear (hearing) implantation. The research was conducted in Vilnius University Hospital Santaros Klinikos during the years 2013-2018. Open-set speech perception in quiet surroundings were evaluated during hearing assessments (n=81). Information about different factor groups was collected according to the Nottingham Children's Implant Profile questionnaire. Three main factor groups were analysed: (a) demographic, (b) family, and (c) educational. A Bourdieu-based approach was adopted to analyse social inequalities of health of children with cochlear implants. Different factors were operationalized as different forms of capital. Our findings highlight the importance of family's social and cultural capital to children speech perception after cochlear implantation.
C1 [Stumbrys, Daumantas; Mataityte-Dirziene, Jurga] Vilnius Univ, Fac Philosophy, Vilnius, Lithuania.
   [Byckova, Jekaterina; Lesinskas, Eugenijus] Vilnius Univ, Fac Med, Vilnius, Lithuania.
   [Norkuniene, Jolita] Vilnius Gediminas Tech Univ, Fac Fundamental Sci, Dept Math Stat, Vilnius, Lithuania.
RP Stumbrys, D (corresponding author), Vilnius Univ, Fac Philosophy, Vilnius, Lithuania.
EM daumantas.stumbrys@fsf.vu.lt; jekaterina.byckova@gmail.com;
   eugenijus.lesinskas@santa.lt; jurga.mataityte-dirziene@fsf.vu.lt;
   jolita.norkuniene@vgtu.lt
OI Stumbrys, Daumantas/0000-0002-1324-5758
FU Research Council of LithuaniaResearch Council of Lithuania (LMTLT)
   [S-MIP17-111]
FX This research was funded by a grant (No. S-MIP17-111) from the Research
   Council of Lithuania. The empirical part of this paper is based on
   Jekaterina Byckova's doctoral dissertation The Functional Results and
   Prognostic Factors of Pediatric Cochlear Implantation, defended at
   Vilnius University in 2019. The authors would like to express their
   sincere gratitude to the families who agreed to participate in the
   study.
CR Abel T, 2012, SOC SCI MED, V74, P236, DOI 10.1016/j.socscimed.2011.10.028
   [Anonymous], 2008, CLOS GAP GEN HLTH EQ
   Bond M., 2009, EFFECTIVENESS COST E
   Bourdieu P, 1986, HDB THEORY RES SOCIO
   Bourdieu Pierre, 1984, DISTINCTION SOCIAL C
   Byckova J., 2012, SVEIKATOS MOKSLAI, V22, P140
   Carpiano RM, 2006, SOC SCI MED, V62, P165, DOI 10.1016/j.socscimed.2005.05.020
   Cockerham W. C., 2013, MED SOCIOLOGY MOVE N, P127
   EURO-CIU, 2017, EUR ASS COCHL IMPL U
   European Commission, 2013, HLTH IN EU FIN REP C
   European Commission, 2013, 328 SWD EUR COMM
   Geers AE, 2003, EAR HEARING, V24, p46S, DOI 10.1097/01.AUD.0000051689.57380.1B
   Geers Ann E, 2011, Ear Hear, V32, p84S, DOI 10.1097/AUD.0b013e3181ffd5b5
   Geers AE, 2009, J DEAF STUD DEAF EDU, V14, P371, DOI 10.1093/deafed/enn046
   Gretzinger S, 2010, MANAG REVUE, V21, P193, DOI 10.5771/0935-9915-2010-2-193
   Holt RF, 2013, OTOL NEUROTOL, V34, P388, DOI 10.1097/MAO.0b013e318277a0af
   Jasilionis D., 2015, LIETUVOS DEMOGRAFINI
   Korp P, 2010, SOCIOL COMPASS, V4, P800, DOI 10.1111/j.1751-9020.2010.00313.x
   Korp P, 2008, HEALTH SOCIOL REV, V17, P18, DOI 10.5172/hesr.451.17.1.18
   LR SAM, 2014, SVEIKATOS NETOLYGUMU
   MATAITYTEDIRZIENE, 2018, SOCIALINE TEORIJA EM, P132, DOI DOI 10.15388/STEPP.2018.17.11935
   McGovern P, 2015, SOCIOL HEALTH ILL, V37, P143, DOI 10.1111/1467-9566.12187
   Mikstiene V, 2016, BMC GENET, V17, DOI 10.1186/s12863-016-0354-9
   Mirowsky J, 2005, AGEING INT, V30, P27, DOI 10.1007/BF02681006
   Mueller V.T., 2013, ENCY AUTISM SPECTRUM
   Pinxten W, 2014, SOCIOL HEALTH ILL, V36, P1095, DOI 10.1111/1467-9566.12154
   Samuelsen Helle, 2004, Anthropol Med, V11, P27, DOI 10.1080/1364847042000204933
   Statistics Lithuania, 2019, OFF STAT PORT
   Tobey EA, 2013, INT J AUDIOL, V52, P219, DOI 10.3109/14992027.2012.759666
   Veenstra G, 2007, HEALTH PLACE, V13, P14, DOI 10.1016/j.healthplace.2005.09.011
   Veenstra G, 2014, SOCIOL HEALTH ILL, V36, P187, DOI 10.1111/1467-9566.12105
   Walther M., 2014, REPATRIATION FRANCE
NR 32
TC 0
Z9 0
U1 0
U2 1
PU VILNIUS UNIV
PI VILNIUS
PA UNIVERSITETO ST 3, VILNIUS, LT-01513, LITHUANIA
SN 1648-2425
EI 2345-0266
J9 SOC TEOR EMP POLIT P
JI Soc. Teor. Emp. Polit. Prakt.
PY 2020
IS 20
BP 67
EP 78
DI 10.15388/STEPP.2020.19
PG 12
WC Social Work
SC Social Work
GA LO2SK
UT WOS:000533479800005
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Yu, CWF
AF Yu, Chen-Wei Felix
TI Hearing faces and seeing accents? The factors behind the multisensory
   speech perception of native Mandarin speakers
SO CONCENTRIC-STUDIES IN LINGUISTICS
LA English
DT Article
DE the McGurk Effect; multisensory speech perception; reaction time;
   response types; cognitive effort
ID MCGURK; PROFICIENCY; SYLLABLES; CHINESE; TIME; LIPS
AB In this paper, the McGurk effect displayed by native Mandarin Speakers is examined in the light of reaction time (RT) and response types. Two within-subject factors, FACE and ACCENT, and one between-subject factor, English Proficiency, were incorporated in the experiment. The results showed that FACE and ACCENT, but not English Proficiency, had effects on the participants' RT and response types. When a foreign ACCENT was dubbed onto a familiar FACE, the RT was the longest, and the McGurk effect was most likely to be found. Other kinds of McGurk stimuli composition did not receive different RT but induced different response types. When the FACE was foreign, regardless of the ACCENT, the participants tended to respond with perceptive illusion. The author concluded that the expectations of the perceiver influenced the use of multisensory integration and thus the longer RT and the appearance of the McGurk effect.
C1 [Yu, Chen-Wei Felix] Kaohsiung Med Univ, Kaohsiung, Taiwan.
RP Yu, CWF (corresponding author), Kaohsiung Med Univ, Dept Psychol, Kaohsiung, Taiwan.
EM chenweifelix@gmail.com
CR Beauchamp Michael S., 2017, BEAUCHAMP MCGURKSTIM
   Bovo R, 2009, ACTA OTORHINOLARYNGO, V29, P203
   Burnham Denis, 1998, AVSP 98 INT C AUD VI
   Chen Yuchun, 2007, AVSP 2007 INT C AUD
   Fuster-Duran A., 1996, SPEECHREADING HUMANS, P135, DOI DOI 10.1007/978-3-662-13015-5_9
   Hirata Y, 2010, J SPEECH LANG HEAR R, V53, P298, DOI 10.1044/1092-4388(2009/08-0243)
   Kotz SA, 2004, J NEUROLINGUIST, V17, P215, DOI 10.1016/S0911-6044(03)00058-7
   Magnotti JF, 2015, EXP BRAIN RES, V233, P2581, DOI 10.1007/s00221-015-4324-7
   Marian Viorica, 2009, BILINGUAL MENTAL LEX, P52
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Munro MJ, 1995, LANG SPEECH, V38, P289, DOI 10.1177/002383099503800305
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Sams M, 1998, SPEECH COMMUN, V26, P75, DOI 10.1016/S0167-6393(98)00051-X
   Sekiyama K, 1997, PERCEPT PSYCHOPHYS, V59, P73, DOI 10.3758/BF03206849
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Sueyoshi A, 2005, LANG LEARN, V55, P661, DOI 10.1111/j.0023-8333.2005.00320.x
   Tona R, 2015, INT J PEDIATR OTORHI, V79, P2072, DOI 10.1016/j.ijporl.2015.09.016
   Tse CS, 2012, BILING-LANG COGN, V15, P663, DOI 10.1017/S1366728912000077
NR 18
TC 0
Z9 0
U1 0
U2 0
PU NATL TAIWAN NORMAL UNIV, COLL INT STUDIES & SOCIAL SCIENCES
PI TAIPEI
PA 162 HEPING EAST RD, SECTION 1, TAIPEI, 106, TAIWAN
SN 1810-7478
EI 2589-5230
J9 CONCENTRIC-STUD LING
JI Concentric-Stud. Linguist.
PY 2020
VL 46
IS 1
BP 1
EP 20
DI 10.1075/consl.00011.yu
PG 20
WC Language & Linguistics
SC Linguistics
GA LK7JU
UT WOS:000531039200001
DA 2021-02-24
ER

PT J
AU Yasin, I
   Drga, V
   Liu, FQ
   Demosthenous, A
   Meddis, R
AF Yasin, Ifat
   Drga, Vit
   Liu, Fangqi
   Demosthenous, Andreas
   Meddis, Ray
TI Optimizing Speech Recognition Using a Computational Model of Human
   Hearing: Effect of Noise Type and Efferent Time Constants
SO IEEE ACCESS
LA English
DT Article
DE Auditory; hearing; efferent; Medial OlivoCochlear (MOC); speech
   recognition; auditory model; time constant; SNR; amplitude-modulated
   noise
ID AMPLITUDE-MODULATION; OLIVOCOCHLEAR REFLEX; BASILAR-MEMBRANE;
   COMPUTER-MODEL; COCHLEAR GAIN; SUPPRESSION; MODERATE; STIMULATION;
   PERCEPTION; ACTIVATION
AB Physiological and psychophysical methods allow for an extended investigation of ascending (afferent) neural pathways from the ear to the brain in mammals, and their role in enhancing signals in noise. However, there is increased interest in descending (efferent) neural fibers in the mammalian auditory pathway. This efferent pathway operates via the olivocochlear system, modifying auditory processing by cochlear innervation and enhancing human ability to detect sounds in noisy backgrounds. Effective speech intelligibility may depend on a complex interaction between efferent time-constants and types of background noise. In this study, an auditory model with efferent-inspired processing provided the front-end to an automatic-speech-recognition system (ASR), used as a tool to evaluate speech recognition with changes in time-constants (50 to 2000 ms) and background noise type (unmodulated and modulated noise). With efferent activation, maximal speech recognition improvement (for both noise types) occurred for signal-to-noise ratios around 10 dB, characteristic of real-world speech-listening situations. Net speech improvement due to efferent activation (NSIEA) was smaller in modulated noise than in unmodulated noise. For unmodulated noise, NSIEA increased with increasing time-constant. For modulated noise, NSIEA increased for time-constants up to 200 ms but remained similar for longer time-constants, consistent with speech-envelope modulation times important to speech recognition in modulated noise. The model improves our understanding of the complex interactions involved in speech recognition in noise, and could be used to simulate the difficulties of speech perception in noise as a consequence of different types of hearing loss.
C1 [Yasin, Ifat; Drga, Vit] UCL, Dept Comp Sci, London WC1E 6EA, England.
   [Liu, Fangqi; Demosthenous, Andreas] UCL, Dept Elect & Elect Engn, London WC1E 7JE, England.
   [Meddis, Ray] Univ Essex, Dept Psychol, Colchester CO4 3SQ, Essex, England.
RP Yasin, I (corresponding author), UCL, Dept Comp Sci, London WC1E 6EA, England.
EM i.yasin@ucl.ac.uk
OI Demosthenous, Andreas/0000-0003-0623-963X
FU Engineering and Physical Sciences Research Council (EPSRC)UK Research &
   Innovation (UKRI)Engineering & Physical Sciences Research Council
   (EPSRC) [EP/R511638/1]
FX This work was supported by the Engineering and Physical Sciences
   Research Council (EPSRC) under Grant EP/R511638/1.
CR Abdala C, 2014, J ACOUST SOC AM, V135, P754, DOI 10.1121/1.4861841
   Aguilar E, 2015, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00251
   Backus BC, 2006, J ACOUST SOC AM, V119, P2889, DOI 10.1121/1.2169918
   Boothalingam S, 2014, NEUROSCI LETT, V580, P56, DOI 10.1016/j.neulet.2014.07.048
   Brown GJ, 2010, J ACOUST SOC AM, V127, P943, DOI 10.1121/1.3273893
   Butler BE, 2018, J NEUROSCI, V38, P4048, DOI 10.1523/JNEUROSCI.2858-17.2018
   Carney LH, 2018, JARO-J ASSOC RES OTO, V19, P331, DOI 10.1007/s10162-018-0669-5
   Clark NR, 2012, J ACOUST SOC AM, V132, P1535, DOI 10.1121/1.4742745
   Cooper NP, 2003, J PHYSIOL-LONDON, V548, P307, DOI 10.1113/jphysiol.2003.039081
   de Leon F, 2012, EUR SIGNAL PR CONF, P2005
   Drga V, 2016, ADV EXP MED BIOL, V894, P477, DOI 10.1007/978-3-319-25474-6_50
   Drullman R., 1994, J ACOUST SOC AM, V95, P3009
   Ferry RT, 2007, J ACOUST SOC AM, V122, P3519, DOI 10.1121/1.2799914
   Ghitza O., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P91, DOI 10.1109/ICASSP.1988.196518
   Giraud AL, 1997, NEUROREPORT, V8, P1779, DOI 10.1097/00001756-199705060-00042
   GOLDSTEIN JL, 1990, HEARING RES, V49, P39, DOI 10.1016/0378-5955(90)90094-6
   Greenberg S., 1996, P INT C SPOK LANG PR, V96, P24
   Guinan JJ, 1996, J ACOUST SOC AM, V100, P1680, DOI 10.1121/1.416066
   Guinan JJ, 2006, EAR HEARING, V27, P589, DOI 10.1097/01.aud.0000240507.83072.e7
   Holmberg M, 2007, SPEECH COMMUN, V49, P917, DOI 10.1016/j.specom.2007.05.009
   James AL, 2002, CLIN OTOLARYNGOL, V27, P106, DOI 10.1046/j.1365-2273.2002.00541.x
   Kanedera N, 1998, INT CONF ACOUST SPEE, P613, DOI 10.1109/ICASSP.1998.675339
   KAWASE T, 1993, J NEUROPHYSIOL, V70, P2533
   Leonard R., 1984, P IEEE ICASSP, V9, P328, DOI DOI 10.1109/ICASSP.1984.1172716
   LIBERMAN MC, 1988, J NEUROPHYSIOL, V60, P1779
   Lopez-Poveda EA, 2003, J ACOUST SOC AM, V114, P2112, DOI 10.1121/1.1605389
   Lopez-Poveda EA, 2001, J ACOUST SOC AM, V110, P3107, DOI 10.1121/1.1416197
   Lopez-Poveda EA, 2018, J ACOUST SOC AM, V143, P2217, DOI 10.1121/1.5031028
   Maison S, 2001, EAR HEARING, V22, P65, DOI 10.1097/00003446-200102000-00007
   Maison S, 1999, NEUROSCIENCE, V91, P133, DOI 10.1016/S0306-4522(98)00608-3
   Maison S, 1997, J NEUROPHYSIOL, V77, P1759
   Marian V, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00378
   Marrufo-Perez MI, 2018, JARO-J ASSOC RES OTO, V19, P147, DOI 10.1007/s10162-018-0656-x
   Maruthy S, 2017, JARO-J ASSOC RES OTO, V18, P635, DOI 10.1007/s10162-017-0623-y
   Meddis R, 2006, J ACOUST SOC AM, V119, P406, DOI 10.1121/1.2139628
   Meddis R, 2001, J ACOUST SOC AM, V109, P2852, DOI 10.1121/1.1370357
   Messing DP, 2009, SPEECH COMMUN, V51, P668, DOI 10.1016/j.specom.2009.02.002
   RASMUSSEN GL, 1946, J COMP NEUROL, V84, P141, DOI 10.1002/cne.900840204
   Robertson M, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2474
   Russell IJ, 1997, J ACOUST SOC AM, V102, P1734, DOI 10.1121/1.420083
   Schut H. H., 2016, VISION RES, V122
   Sumner CJ, 2002, J ACOUST SOC AM, V111, P2178, DOI 10.1121/1.1453451
   Tsai PY, 2011, 2011 IEEE INTERNATIONAL SOC CONFERENCE (SOCC), P48, DOI 10.1109/SOCC.2011.6085074
   Verhey JL, 2017, J ACOUST SOC AM, V142, pEL258, DOI 10.1121/1.5000796
   Verhey JL, 2017, HEARING RES, V350, P152, DOI 10.1016/j.heares.2017.04.018
   WARR WB, 1975, J COMP NEUROL, V161, P159, DOI 10.1002/cne.901610203
   WINSLOW RL, 1988, HEARING RES, V35, P165, DOI 10.1016/0378-5955(88)90116-5
   Wu YH, 2018, EAR HEARING, V39, P293, DOI 10.1097/AUD.0000000000000486
   Yasin I, 2018, J ACOUST SOC AM, V143, pEL112, DOI 10.1121/1.5023502
   Yasin I, 2014, J NEUROSCI, V34, P15319, DOI 10.1523/JNEUROSCI.1043-14.2014
   Young S., 2015, 679 U CAMBR DEP ENG
   Zeng FG, 2006, J SPEECH LANG HEAR R, V49, P367, DOI 10.1044/1092-4388(2006/029)
   Zhao WM, 2011, J HEMATOL ONCOL, V4, DOI 10.1186/1756-8722-4-4
NR 53
TC 2
Z9 2
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 56711
EP 56719
DI 10.1109/ACCESS.2020.2981885
PG 9
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA LF4TJ
UT WOS:000527411700074
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Aslan, F
   Yildirim, M
   Sennaroglu, G
AF Aslan, Filiz
   Yildirim, Mehtap
   Sennaroglu, Gonca
TI Cognitive and speech perception outcomes after cochlear implantation in
   Fabry disease
SO HEARING BALANCE AND COMMUNICATION
LA English
DT Article
DE Cochlear implantation; Fabry disease; cognitive assessment; speech
   perception
ID CLINICAL-MANIFESTATIONS; HEARING-LOSS; RECOGNITION; PREVALENCE; COHORT
AB Purpose: To study the audiological, rehabilitative and cognitive outcomes of cochlear implantation in patients with Fabry disease (FD).Method: This is a retrospective case study. Two adults with progressive hearing loss were followed up for over 3 years.Results: The patients had progressive hearing loss from the first decade of life. Preoperative evaluations indicated delays in speech perception and cognitive skills due to hearing loss. There was a significant increase in hearing thresholds and speech perception in both patients after the cochlear implantation. The cognitive skills and memory skills of the patient who started using the cochlear implant later in life continued to lag.Conclusion: In FD, hearing loss should be closely monitored and appropriate interventions should be selected early. Two patients from the same family showed the strong impact of early intervention on speech perception and cognitive skills. The study aimed to emphasize the necessity of speech perception and cognitive skills assessment during the follow-up of patients with FD.
C1 [Aslan, Filiz; Sennaroglu, Gonca] Hacettepe Univ, Dept Audiol, Ankara, Turkey.
   [Yildirim, Mehtap] Hacettepe Univ Hosp, Audiol & Speech Pathol Unit, Ankara, Turkey.
RP Aslan, F (corresponding author), Hacettepe Univ, Dept Audiol, Fac Hlth Sci, Ankara, Turkey.
EM filizasl@gmail.com
CR Barras FM, 2006, EUR ARCH OTO-RHINO-L, V263, P688, DOI 10.1007/s00405-006-0023-0
   Crosbie TW, 2009, J INHERIT METAB DIS, V32, P745, DOI 10.1007/s10545-009-1254-1
   Durankaya SM, 2014, J INT ADV OTOL, V10, P172, DOI 10.5152/iao.2014.118
   Eng CM, 2007, J INHERIT METAB DIS, V30, P184, DOI 10.1007/s10545-007-0521-2
   Eng CM, 2006, GENET MED, V8, P539, DOI 10.1097/01.gim.0000237866.70357.c6
   Germain Dominique P, 2002, BMC Med Genet, V3, P10, DOI 10.1186/1471-2350-3-10
   Hegemann S, 2006, EUR J CLIN INVEST, V36, P654, DOI 10.1111/j.1365-2362.2006.01702.x
   Hoffmann B, 2009, DTSCH ARZTEBL INT, V106, P440, DOI 10.3238/arztebl.2009.0440
   Huzmeli C, 2016, BIOCHEM GENET, V54, P448, DOI 10.1007/s10528-016-9731-3
   Karakas S, 2002, DEV NEUROPSYCHOL, V22, P423, DOI 10.1207/S15326942DN2202_1
   Laney DA, 2010, J INHERIT METAB DIS, V33, pS73, DOI 10.1007/s10545-009-9025-6
   Low M, 2007, INTERN MED J, V37, P436, DOI 10.1111/j.1445-5994.2007.01366.x
   MacDermot KD, 2001, J MED GENET, V38, P769, DOI 10.1136/jmg.38.11.769
   Masson C, 2004, JOINT BONE SPINE, V71, P381, DOI 10.1016/j.jbspin.2003.10.015
   Mehta A, 2004, EUR J CLIN INVEST, V34, P236, DOI 10.1111/j.1365-2362.2004.01309.x
   Meikle PJ, 1999, JAMA-J AM MED ASSOC, V281, P249, DOI 10.1001/jama.281.3.249
   Moberly AC, 2017, J SPEECH LANG HEAR R, V60, P1046, DOI 10.1044/2016_JSLHR-H-16-0119
   Okur I, 2013, GENE, V527, P42, DOI 10.1016/j.gene.2013.05.050
   Ozkara HA, 2004, BRAIN DEV-JPN, V26, P363, DOI 10.1016/S0387-7604(03)00195-5
   Palla A, 2007, J NEUROL, V254, P1433, DOI 10.1007/s00415-007-0575-y
   Peterson AM, 2011, SEMIN HEAR
   Raven J. C., 1983, MANUAL RAVENS PROGR
   Robinson K, 1996, ANN OTO RHINOL LARYN, V105, P415, DOI 10.1177/000348949610500601
   Sakurai Y, 2010, AURIS NASUS LARYNX, V37, P274, DOI 10.1016/j.anl.2009.08.005
   SCHACHERN PA, 1989, ANN OTO RHINOL LARYN, V98, P359, DOI 10.1177/000348948909800509
   Tuncbilek E, 2007, TURKISH J PEDIATR, V49, P353
   Yucel E, 2004, 7 EUR S PAED COCHL I
NR 27
TC 0
Z9 0
U1 3
U2 3
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2169-5717
EI 2169-5725
J9 HEARING BALANC COMMU
JI Hearing Balanc. Commun.
PY 2020
VL 18
IS 1
BP 61
EP 65
DI 10.1080/21695717.2019.1630978
PG 5
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA LI0EM
UT WOS:000529157800010
DA 2021-02-24
ER

PT J
AU Tandra, A
   Sakti, S
   Nakamura, S
AF Tandra, Andros
   Sakti, Sakriani
   Nakamura, Satoshi
TI Machine Speech Chain
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
LA English
DT Article
DE Speech processing; Data models; Machine learning; Task analysis;
   Training; Hidden Markov models; Speech chain; ASR; TTS; deep learning
ID RECOGNITION
AB Despite the close relationship between speech perception and production, research in automatic speech recognition (ASR) and text-to-speech synthesis (TTS) has progressed more or less independently without exerting much mutual influence. In human communication, on the other hand, a closed-loop speech chain mechanism with auditory feedback from the speaker's mouth to her ear is crucial. In this paper, we take a step further and develop a closed-loop machine speech chain model based on deep learning. The sequence-to-sequence model in closed-loop architecture allows us to train our model on the concatenation of both labeled and unlabeled data. While ASR transcribes the unlabeled speech features, TTS attempts to reconstruct the original speech waveform based on the text from ASR. In the opposite direction, ASR also attempts to reconstruct the original text transcription given the synthesized speech. To the best of our knowledge, this is the first deep learning framework that integrates human speech perception and production behaviors. Our experimental results show that the proposed approach significantly improved performance over that from separate systems that were only trained with labeled data.
C1 [Tandra, Andros; Sakti, Sakriani; Nakamura, Satoshi] Nara Inst Sci & Technol, Ctr Adv Intelligence, Project AIP, Ikoma 6300192, Japan.
   [Tandra, Andros; Sakti, Sakriani; Nakamura, Satoshi] RIKEN, Ikoma 6300192, Japan.
RP Tandra, A (corresponding author), Nara Inst Sci & Technol, Ctr Adv Intelligence, Project AIP, Ikoma 6300192, Japan.; Tandra, A (corresponding author), RIKEN, Ikoma 6300192, Japan.
EM andros.tjandra.ai6@is.naist.jp; ssakti@is.naist.jp;
   s-nakamura@is.naist.jp
OI Sakti, Sakriani/0000-0001-5509-8963
FU JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [JP17H06101,
   JP17K00237]; NII CRIS
FX This work was supported in part by JSPS KAKENHI under Grants JP17H06101
   and JP17K00237, and in part by NII CRIS Contract Research 2019.
CR Arik S. O., 2017, P INT C MACH LEARN, P195
   Bahdanau D., 2015, P 3 INT C LEARN REPR
   Bandanau D, 2016, INT CONF ACOUST SPEE, P4945, DOI 10.1109/ICASSP.2016.7472618
   Baskar M. K., 2019, P INTERSPEECH, P3790, DOI [10.21437/Interspeech.2019-3167, DOI 10.21437/INTERSPEECH.2019-3167]
   Bengio Y., 2013, ARXIV13083432
   Chan W, 2016, INT CONF ACOUST SPEE, P4960, DOI 10.1109/ICASSP.2016.7472621
   Cheng Y, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1965
   Cho K., 2014, ARXIV 1406 1078, DOI DOI 10.3115/V1/D14-1179
   Chorowski J., 2014, P NEUR INF PROC SYST
   Chung J., 2014, P NEUR INF PROC SYST
   DAVIS KH, 1952, J ACOUST SOC AM, V24, P637, DOI 10.1121/1.1906946
   Denes P. B., 1993, THE SPEECH CHAIN
   Dobie R, 2004, HEARING LOSS DETERMI
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   He D, 2016, P820
   Hinton G., 2012, NEURAL NETWORKS MACH
   Hinton Geoffrey, 2015, P NEUR INF PROC SYST
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   HOLMES JN, 1964, LANG SPEECH, V7, P127, DOI 10.1177/002383096400700301
   Hori T, 2019, INT CONF ACOUST SPEE, P6271, DOI 10.1109/ICASSP.2019.8683307
   Hunt AJ, 1996, INT CONF ACOUST SPEE, P373, DOI 10.1109/ICASSP.1996.541110
   Ito K., 2017, LJ SPEECH DATASET
   Jang E, 2017, P INT C LEARN REPR
   JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karita S, 2018, INTERSPEECH, P2
   Kim S, 2017, INT CONF ACOUST SPEE, P4835, DOI 10.1109/ICASSP.2017.7953075
   Kurata G., 2019, P INTERSPEECH, P1636
   Larsen A.B.L., 2016, INT C MACH LEARN, V48, P1558
   Li C., 2017, ARXIV170502304
   Luong M.-T., 2015, P1412, DOI DOI 10.18653/V1/D15-1166
   Maddison C. J., 2016, P INT C LEARN REPR
   Matejka P, 2011, INT CONF ACOUST SPEE, P4828
   McFee B., 2017, LIBROSA 0 5 0, DOI 10:5281/zenodo:293021
   Olive J. P., 1977, P ICASSP, P568, DOI DOI 10.1109/ICASSP.1977.1170350
   Oord A.v.d., 2016, ARXIV160903499
   Palaz D, 2015, INT CONF ACOUST SPEE, P4295, DOI 10.1109/ICASSP.2015.7178781
   Paszke A., 2019, P ADV NEUR INF PROC, V32, P8024
   PAUL DB, 1992, SPEECH AND NATURAL LANGUAGE, P357
   Povey D., 2011, P IEEE WORKSH AUT SP
   Ren Y., 2019, P 36 INT C MACH LEAR, V97, P5410
   Rosenberg A, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P996, DOI 10.1109/ASRU46091.2019.9003990
   Sagisaka Y., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P679, DOI 10.1109/ICASSP.1988.196677
   SAGISAKA Y, 1992, P ICSLP, P483
   Sainath TN, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86
   Sutskever I., 2014, P ADV NEUR INF PROC, P3104, DOI DOI 10.1007/S10107-014-0839-0
   Tjandra A, 2018, IEEE W SP LANG TECH, P648, DOI 10.1109/SLT.2018.8639528
   Tjandra A, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P309, DOI 10.1109/ASRU.2017.8268951
   TOKUDA K, 1995, INT CONF ACOUST SPEE, P660, DOI 10.1109/ICASSP.1995.479684
   Ueno S, 2019, INT CONF ACOUST SPEE, P6161, DOI 10.1109/ICASSP.2019.8682816
   Vintsyuk T. K., 1968, Cybernetics, V4, P52
   Wang YX, 2017, INTERSPEECH, P4006, DOI 10.21437/Interspeech.2017-1452
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   WILPON JG, 1990, IEEE T ACOUST SPEECH, V38, P1870, DOI 10.1109/29.103088
   Xu B., 2015, ARXIV150500853, V1505, P853
   Xu K., 2015, P2048, DOI DOI 10.1109/72.279181
   YOSHIMURA T, 1999, P EUR, P2347, DOI DOI 10.1093/IETISY/E90-D.3.692
   Yun Lei, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1695, DOI 10.1109/ICASSP.2014.6853887
   Zen HG, 2013, INT CONF ACOUST SPEE, P7962, DOI 10.1109/ICASSP.2013.6639215
   Zhu X., 2002, LEARNING LABELED UNL
   Zhu YK, 2018, INTERSPEECH, P3573, DOI 10.21437/Interspeech.2018-1158
NR 65
TC 1
Z9 1
U1 0
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2329-9290
EI 2329-9304
J9 IEEE-ACM T AUDIO SPE
JI IEEE-ACM Trans. Audio Speech Lang.
PY 2020
VL 28
BP 976
EP 989
DI 10.1109/TASLP.2020.2977776
PG 14
WC Acoustics; Engineering, Electrical & Electronic
SC Acoustics; Engineering
GA KY1UQ
UT WOS:000522357500003
OA Bronze
DA 2021-02-24
ER

PT J
AU Sakti, S
   Tjandra, A
   Nakamura, S
AF Sakti, Sakriani
   Tjandra, Andros
   Nakamura, Satoshi
TI A machine that learned to listen, speak, and listen while speaking
SO ACOUSTICAL SCIENCE AND TECHNOLOGY
LA English
DT Article
DE Speech chain; Speech recognition; Speech synthesis; Deep learning;
   Semi-supervised learning
AB In this paper, we introduce our recent machine speech chain frameworks based on deep learning that learned, not only to listen or speak but also listen while speaking. To the best of our knowledge, this is the first deep learning model that integrates human speech perception and production behaviors. Our experimental results show that the proposed approach significantly improved the performance more than separate systems that were only trained with labeled data.
C1 [Sakti, Sakriani; Tjandra, Andros; Nakamura, Satoshi] Nara Inst Sci & Technol, 8916-5 Takayama Cho, Ikoma 6300192, Japan.
   [Sakti, Sakriani; Tjandra, Andros; Nakamura, Satoshi] RIKEN, Ctr Adv Intelligence Project AIP, Chuo Ku, 1-4-1 Nihonbashi, Tokyo 1030027, Japan.
RP Sakti, S (corresponding author), Nara Inst Sci & Technol, 8916-5 Takayama Cho, Ikoma 6300192, Japan.; Sakti, S (corresponding author), RIKEN, Ctr Adv Intelligence Project AIP, Chuo Ku, 1-4-1 Nihonbashi, Tokyo 1030027, Japan.
EM ssakti@is.naist.jp; andros.tjandra.ai6@is.naist.jp;
   s-nakamura@is.naist.jp
FU JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [JP17H06101,
   JP17K00237]
FX Part of this work was supported by JSPS KAKENHI Grant Numbers JP17H06101
   and JP17K00237.
CR Bandanau D, 2016, INT CONF ACOUST SPEE, P4945, DOI 10.1109/ICASSP.2016.7472618
   Denes P., 1993, SPEECH CHAIN SER
   Tjandra A, 2018, INTERSPEECH, P887, DOI 10.21437/Interspeech.2018-1558
   Tjandra A, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P301, DOI 10.1109/ASRU.2017.8268950
   Wang YX, 2017, INTERSPEECH, P4006, DOI 10.21437/Interspeech.2017-1452
NR 5
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC JAPAN
PI TOKYO
PA NAKAURA 5TH-BLDG. 2F, 2-18-20 SOTOKANDA, CHIYODA-KU, TOKYO, 101-0021,
   JAPAN
SN 1346-3969
EI 1347-5177
J9 ACOUST SCI TECHNOL
JI Acoust. Sci. Technol.
PY 2020
VL 41
IS 1
BP 170
EP 172
DI 10.1250/ast.41.170
PG 3
WC Acoustics
SC Acoustics
GA KN0SG
UT WOS:000514548300028
OA Bronze
DA 2021-02-24
ER

PT J
AU Ingvalson, EM
   Lansford, KL
AF Ingvalson, Erin M.
   Lansford, Kaitlin L.
TI Older adults' perception of multiple speech types predicted by common
   cognitive factors
SO ACOUSTICAL SCIENCE AND TECHNOLOGY
LA English
DT Article
DE Foreign-accented speech; Dysarthric speech; Older adult speech
   perception
ID YOUNGER; VOCABULARY; SCORES
C1 [Ingvalson, Erin M.; Lansford, Kaitlin L.] Florida State Univ, Sch Commun Sci & Disorders, 201 W Bloxham St, Tallahassee, FL 32306 USA.
   [Ingvalson, Erin M.] Northwestern Univ, Feinberg Sch Med, Dept Otolaryngol Head & Neck Surg, 420 Super St, Chicago, IL 60611 USA.
RP Ingvalson, EM (corresponding author), Florida State Univ, Sch Commun Sci & Disorders, 201 W Bloxham St, Tallahassee, FL 32306 USA.; Ingvalson, EM (corresponding author), Northwestern Univ, Feinberg Sch Med, Dept Otolaryngol Head & Neck Surg, 420 Super St, Chicago, IL 60611 USA.
EM erin.ingvalson@cci.fsu.edu; kaitlin.lansford@cci.fsu.edu
CR Baese-Berk MM, 2013, J ACOUST SOC AM, V133, pEL174, DOI 10.1121/1.4789864
   Ellis E. J., 2015, FRONT PSYCHOL
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Heaton RK, 2014, J INT NEUROPSYCH SOC, V20, P588, DOI 10.1017/S1355617714000241
   Humes LE, 2007, J AM ACAD AUDIOL, V18, P590, DOI 10.3766/jaaa.18.7.6
   Ingvalson EM, 2017, J SPEECH LANG HEAR R, V60, P3632, DOI 10.1044/2017_JSLHR-H-17-0119
   Ingvalson EM, 2017, J ACOUST SOC AM, V141, P4652, DOI 10.1121/1.4986930
   JERGER J, 1991, EAR HEARING, V12, P103, DOI 10.1097/00003446-199104000-00004
   Lansford KL, 2014, J SPEECH LANG HEAR R, V57, P68, DOI 10.1044/1092-4388(2013/12-0263)
   Lunner T, 2007, J AM ACAD AUDIOL, V18, P604, DOI 10.3766/jaaa.18.7.7
   McAuliffe MJ, 2013, J ACOUST SOC AM, V134, P1358, DOI 10.1121/1.4812764
   RONNBERG J, 2003, INT J AUDIOL, V42, pS6
   Souza P., 2015, INT J AUDIOL, V15, P1
NR 13
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC JAPAN
PI TOKYO
PA NAKAURA 5TH-BLDG. 2F, 2-18-20 SOTOKANDA, CHIYODA-KU, TOKYO, 101-0021,
   JAPAN
SN 1346-3969
EI 1347-5177
J9 ACOUST SCI TECHNOL
JI Acoust. Sci. Technol.
PY 2020
VL 41
IS 1
BP 390
EP 393
DI 10.1250/ast.41.390
PG 4
WC Acoustics
SC Acoustics
GA KN0SG
UT WOS:000514548300074
OA Bronze
DA 2021-02-24
ER

PT J
AU Hui, CTJ
   Arai, T
AF Hui, C. T. Justine
   Arai, Takayuki
TI Effect of frequency discrimination abilities on music and speech
   perception: A summary of four short studies
SO ACOUSTICAL SCIENCE AND TECHNOLOGY
LA English
DT Article
DE Frequency discrimination; Speech perception; Interval recognition
ID CONGENITAL AMUSIA; IDENTIFICATION; YOUNG; PITCH
C1 [Hui, C. T. Justine; Arai, Takayuki] Sophia Univ, Grad Sch Sci & Technol, Chiyoda Ku, 7-1 Kioi Cho, Tokyo 1028554, Japan.
RP Hui, CTJ (corresponding author), Sophia Univ, Grad Sch Sci & Technol, Chiyoda Ku, 7-1 Kioi Cho, Tokyo 1028554, Japan.
EM justinehui@eagle.sophia.ac.jp; arai@sophia.ac.jp
OI Hui, Justine/0000-0003-1411-8328
CR Ayotte J, 2002, BRAIN, V125, P238, DOI 10.1093/brain/awf028
   Bunnell H. T., 2015, SIMPLIFIED VOWEL SYN
   Clinard CG, 2010, HEARING RES, V264, P48, DOI 10.1016/j.heares.2009.11.010
   Coughlin M, 1998, J ACOUST SOC AM, V104, P3597, DOI 10.1121/1.423942
   Cousineau M, 2015, NEUROPSYCHOLOGIA, V66, P293, DOI 10.1016/j.neuropsychologia.2014.11.031
   Fujisaki H., 1977, IWANAMI KOZA NIHONGO, P63
   Gordon-Salant S, 2005, J REHABIL RES DEV, V42, P9, DOI 10.1682/JRRD.2005.01.0006
   Hui CTJ, 2019, ACOUST SCI TECHNOL, V40, P105, DOI 10.1250/ast.40.105
   MOORE BCJ, 1992, J ACOUST SOC AM, V91, P2881, DOI 10.1121/1.402925
   Vongpoisal T, 2007, J SPEECH LANG HEAR R, V50, P1139, DOI 10.1044/1092-4388(2007/079)
NR 10
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC JAPAN
PI TOKYO
PA NAKAURA 5TH-BLDG. 2F, 2-18-20 SOTOKANDA, CHIYODA-KU, TOKYO, 101-0021,
   JAPAN
SN 1346-3969
EI 1347-5177
J9 ACOUST SCI TECHNOL
JI Acoust. Sci. Technol.
PY 2020
VL 41
IS 1
BP 408
EP 410
DI 10.1250/ast.41.408
PG 3
WC Acoustics
SC Acoustics
GA KN0SG
UT WOS:000514548300079
OA Bronze
DA 2021-02-24
ER

PT J
AU Sugiyama, Y
AF Sugiyama, Yukiko
TI Effects of signal degradation and speaker sex on recognizing Japanese
   disyllabic words
SO ACOUSTICAL SCIENCE AND TECHNOLOGY
LA English
DT Article
DE Japanese pitch accent; Acoustic correlates; Speech production; Speech
   perception
C1 [Sugiyama, Yukiko] Keio Univ, Fac Sci & Technol, Dept Foreign Languages & Liberal Arts, Kohoku Ku, 4-1-1 Hiyoshi, Yokohama, Kanagawa 2238521, Japan.
RP Sugiyama, Y (corresponding author), Keio Univ, Fac Sci & Technol, Dept Foreign Languages & Liberal Arts, Kohoku Ku, 4-1-1 Hiyoshi, Yokohama, Kanagawa 2238521, Japan.
EM yukiko@keio.jp
CR Amano S., 1999, NIHONGO NO GOITOKUSE
   Beckman ME, 1986, STRESS NON STRESS AC
   Boersma P., 2014, PRAAT DOING PHONETIC
   FRY DB, 1958, LANG SPEECH, V1, P126, DOI 10.1177/002383095800100207
   Fu Q-J, 2000, ASIA PAC J SPEECH LA, V5, P45, DOI DOI 10.1179/136132800807547582
   GLASBERG BR, 1990, HEARING RES, V47, P103, DOI 10.1016/0378-5955(90)90170-T
   Kawakami S., 2005, NIHONGO AKUSENTO RON
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Sugito M., 1998, NIHONGO ONSEI NO KEN
NR 9
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC JAPAN
PI TOKYO
PA NAKAURA 5TH-BLDG. 2F, 2-18-20 SOTOKANDA, CHIYODA-KU, TOKYO, 101-0021,
   JAPAN
SN 1346-3969
EI 1347-5177
J9 ACOUST SCI TECHNOL
JI Acoust. Sci. Technol.
PY 2020
VL 41
IS 1
BP 416
EP 417
DI 10.1250/ast.41.416
PG 2
WC Acoustics
SC Acoustics
GA KN0SG
UT WOS:000514548300082
OA Bronze
DA 2021-02-24
ER

PT J
AU Morise, M
   Yokomori, F
   Ozawa, K
AF Morise, Masanori
   Yokomori, Fumiya
   Ozawa, Kenji
TI Building a database for likability evaluation of uttered speech
SO ACOUSTICAL SCIENCE AND TECHNOLOGY
LA English
DT Article
DE Speech database; Likability; Linguistic information; Speech analysis;
   Speech perception
C1 [Morise, Masanori] Meiji Univ, Sch Interdisciplinary Math Sci, Nakano Ku, 4-21-1 Nakano, Tokyo 1648525, Japan.
   [Yokomori, Fumiya; Ozawa, Kenji] Univ Yamanashi, Fac Engn, 4-3-11 Takeda, Kofu, Yamanashi 4008511, Japan.
RP Morise, M (corresponding author), Meiji Univ, Sch Interdisciplinary Math Sci, Nakano Ku, 4-21-1 Nakano, Tokyo 1648525, Japan.
EM mmorise@meiji.ac.jp
FU JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [JP16H05899,
   JP16H01734]
FX This work was supported by JSPS KAKENHI Grant Numbers JP16H05899 and
   JP16H01734.
CR Jones BC, 2008, BIOL LETTERS, V4, P192, DOI 10.1098/rsbl.2007.0626
   Jurgens R, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00180
   KUREMATSU A, 1990, SPEECH COMMUN, V9, P357, DOI 10.1016/0167-6393(90)90011-W
   Mori H., 2003, Acoustical Science and Technology, V24, P376, DOI 10.1250/ast.24.376
   Morise M, 2017, INTERSPEECH, P2321, DOI 10.21437/Interspeech.2017-68
   Morise M, 2016, IEICE T INF SYST, VE99D, P1877, DOI 10.1587/transinf.2015EDP7457
   Tanaka H, 2015, IEICE T INF SYST, VE98D, P1536, DOI 10.1587/transinf.2014EDP7400
NR 7
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC JAPAN
PI TOKYO
PA NAKAURA 5TH-BLDG. 2F, 2-18-20 SOTOKANDA, CHIYODA-KU, TOKYO, 101-0021,
   JAPAN
SN 1346-3969
EI 1347-5177
J9 ACOUST SCI TECHNOL
JI Acoust. Sci. Technol.
PY 2020
VL 41
IS 1
BP 423
EP 424
DI 10.1250/ast.41.423
PG 2
WC Acoustics
SC Acoustics
GA KN0SG
UT WOS:000514548300085
OA Bronze
DA 2021-02-24
ER

PT J
AU Bae, Y
   Lee, SAS
   Velik, K
   Liu, YL
   Beck, C
   Fox, RA
AF Bae, Youkyung
   Lee, Sue Ann S.
   Velik, Karl
   Liu, Yilan
   Beck, Cailynn
   Fox, Robert Allen
TI Differences in nasalance and nasality perception between Texas South and
   Midland dialects
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID DIRECT MAGNITUDE ESTIMATION; EQUAL-APPEARING INTERVAL;
   SPEECH-PERCEPTION; VOWEL PERCEPTION; PORT AREA; ENGLISH; NASALIZATION;
   LISTENERS; VALIDITY; RATINGS
AB While previous research has primarily concerned the dialectal influence on speakers' production of oral-nasal balance, quantitatively represented by nasalance, information on cross-dialectal variation in nasality perception is limited. This study investigated the effects of speakers'/listeners' dialectal background on oral-nasal balance characteristics estimated by nasalance, as well as nasality perception measured by direct magnitude estimation with modulus. Represented by two geographically distinct regions, Texas South and Midland dialects were of special interest given that the two dialects lie at opposite ends of normal nasalance variation [Awan, Bressmann, Poburka, Roy, Sharp, and Watts. (2015). J. Speech Lang. Hear. Res. 58, 69-77]. Mean nasalance of various speech stimuli and direct magnitude estimation ratings on synthesized vowel stimuli with varying degrees of simulated nasalization were obtained from 62 participants (31 Texas South, 31 Midland). The results revealed that the two dialectal groups significantly differed in nasalance scores and nasality ratings, with Texas South exhibiting higher nasalance for standardized passage readings and assigning higher nasality ratings on the synthetic auditory stimuli than Midland. These findings indicate that, in addition to production variations of oral-nasal balance characteristics, perceptual variations of nasality exist at a dialectal level.
C1 [Bae, Youkyung; Velik, Karl; Beck, Cailynn; Fox, Robert Allen] Ohio State Univ, Dept Speech & Hearing Sci, 1070 Carmack Rd, Columbus, OH 43210 USA.
   [Lee, Sue Ann S.; Liu, Yilan] Texas Tech Univ, Hlth Sci Ctr, Dept Speech Language Hearing Sci, 3601 4th St,MS 6031, Lubbock, TX 79430 USA.
RP Bae, Y (corresponding author), Ohio State Univ, Dept Speech & Hearing Sci, 1070 Carmack Rd, Columbus, OH 43210 USA.
EM bae.180@osu.edu
OI Lee, Sue Ann/0000-0002-2970-0591
CR ABRAMSON AS, 1981, J ACOUST SOC AM, V70, P329, DOI 10.1121/1.386781
   Awan SN, 2015, J SPEECH LANG HEAR R, V58, P69, DOI 10.1044/2014_JSLHR-S-14-0077
   Awan SN, 2011, J SPEECH LANG HEAR R, V54, P1284, DOI 10.1044/1092-4388(2011/10-0201)
   Bae Y, 2007, CLEFT PALATE-CRAN J, V44, P506, DOI 10.1597/06-128.1
   Bae Y, 2018, CLEFT PALATE-CRAN J, V55, P45, DOI 10.1177/1055665617718826
   Bae Y, 2011, CLEFT PALATE-CRAN J, V48, P695, DOI 10.1597/09-158
   Beddor PS, 2018, LANGUAGE, V94, P931, DOI 10.1353/lan.2018.0051
   Bex T., 1999, STANDARD ENGLISH WID
   Brancamp TU, 2010, CLEFT PALATE-CRAN J, V47, P631, DOI 10.1597/09-106
   Brunelle M, 2009, J PHONETICS, V37, P79, DOI 10.1016/j.wocn.2008.09.003
   Bunnell H. T., 2015, LOW LEVEL SYNTHESIS
   Bunton K, 2015, CLEFT PALATE-CRAN J, V52, P110, DOI 10.1597/13-126
   Bunton K, 2012, CLEFT PALATE-CRAN J, V49, P741, DOI 10.1597/11-131
   Casserly ED, 2010, WIRES COGN SCI, V1, P629, DOI 10.1002/wcs.63
   Clopper CG, 2005, J ACOUST SOC AM, V118, P1661, DOI 10.1121/1.2000774
   Clopper CG, 2004, J PHONETICS, V32, P111, DOI 10.1016/S0095-4470(03)00009-3
   Clopper CG, 2006, SPEECH COMMUN, V48, P633, DOI 10.1016/j.specom.2005.09.010
   Drager K, 2010, LANG LINGUIST COMPAS, V4, P473, DOI 10.1111/j.1749-818x.2010.00210.x
   Drager K, 2011, LANG SPEECH, V54, P99, DOI 10.1177/0023830910388017
   Evans BG, 2007, J ACOUST SOC AM, V121, P3814, DOI 10.1121/1.2722209
   FOX RA, 1995, J ACOUST SOC AM, V97, P2540, DOI 10.1121/1.411974
   Fox RA, 2009, J ACOUST SOC AM, V126, P2603, DOI 10.1121/1.3212921
   Fridland V, 2012, LINGUA, V122, P779, DOI 10.1016/j.lingua.2011.12.007
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   GIDEON RA, 1987, J AM STAT ASSOC, V82, P656
   Hagiwara R, 1997, J ACOUST SOC AM, V102, P655, DOI 10.1121/1.419712
   HAWKINS S, 1985, J ACOUST SOC AM, V77, P1560, DOI 10.1121/1.391999
   HAWKS JW, 1994, J ACOUST SOC AM, V95, P1074, DOI 10.1121/1.410015
   Hinkle D.E., 2003, APPL STAT BEHAV SCI, V5th
   HOUSE AS, 1956, J SPEECH HEAR DISORD, V21, P218, DOI 10.1044/jshd.2102.218
   Jacewicz E, 2014, J SPEECH LANG HEAR R, V57, P389, DOI 10.1044/2014_JSLHR-S-12-0248
   Jacewicz E, 2012, J ACOUST SOC AM, V131, P1413, DOI 10.1121/1.3676603
   Jacewicz E, 2011, LANG VAR CHANGE, V23, P45, DOI 10.1017/S0954394510000219
   Kirby J, 2010, J ACOUST SOC AM, V127, P3749, DOI 10.1121/1.3327793
   Kummer A.W., 2005, MACKAY KUMMER SNAP T
   Kummer AW, 2008, CLEFT PALATE CRANIOF
   Labov W., 2006, ATLAS N AM ENGLISH P
   Lewis KE, 2000, CLEFT PALATE-CRAN J, V37, P584, DOI 10.1597/1545-1569(2000)037<0584:TEOVON>2.0.CO;2
   Linn M. D., 1998, HDB DIALECTS LANGUAG
   LINTZ LB, 1961, J SPEECH HEAR RES, V4, P381, DOI 10.1044/jshr.0404.381
   MACKAIN KS, 1981, APPL PSYCHOLINGUIST, V2, P369, DOI 10.1017/S0142716400009796
   Mayo R, 1996, CLEFT PALATE-CRAN J, V33, P143, DOI 10.1597/1545-1569(1996)033<0143:NANAVC>2.3.CO;2
   Munro MJ, 1999, J PHONETICS, V27, P385, DOI 10.1006/jpho.1999.0101
   SCHIAVETTI N, 1994, J SPEECH HEAR RES, V37, P46, DOI 10.1044/jshr.3701.46
   SEAVER EJ, 1991, J SPEECH HEAR RES, V34, P715, DOI 10.1044/jshr.3404.715
   Shriberg L. D., 2003, CLIN PHONETICS
   Shuttleworth R, 2008, OPER RES COMPUT SCI, V43, P487, DOI 10.1007/978-0-387-77778-8_22
   Stevens Kenneth N., 2000, ACOUSTIC PHONETICS
   Styler W., 2015, THESIS
   Styler W, 2017, J ACOUST SOC AM, V142, P2469, DOI 10.1121/1.5008854
   SVANTESSON JO, 2006, PHONOLOGY, V23, P309, DOI DOI 10.1017/S0952675706000923
   Thomas ER, 2002, AM SPEECH, V77, P115, DOI 10.1215/00031283-77-2-115
   Thorp EB, 2013, J SPEECH LANG HEAR R, V56, P1476, DOI 10.1044/1092-4388(2013/12-0239)
   Velik K, 2019, CLIN LINGUIST PHONET, V33, P587, DOI 10.1080/02699206.2019.1566402
   Watterson T, 2013, FOLIA PHONIATR LOGO, V65, P91, DOI 10.1159/000353809
   Wayland RP, 2004, LANG LEARN, V54, P681, DOI 10.1111/j.1467-9922.2004.00283.x
   Weismer G, 2002, J SPEECH LANG HEAR R, V45, P421, DOI 10.1044/1092-4388(2002/033)
   Whitehill TL, 2002, J SPEECH LANG HEAR R, V45, P80, DOI 10.1044/1092-4388(2002/006)
   Zellou G, 2017, J PHONETICS, V61, P13, DOI 10.1016/j.wocn.2016.12.002
   Zraick RI, 2000, J SPEECH LANG HEAR R, V43, P979, DOI 10.1044/jslhr.4304.979
NR 60
TC 1
Z9 1
U1 1
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JAN
PY 2020
VL 147
IS 1
BP 568
EP 578
DI 10.1121/10.0000543
PG 11
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA KO4ER
UT WOS:000515501700009
PM 32007026
OA Bronze
DA 2021-02-24
ER

PT J
AU Herd, W
AF Herd, Wendy
TI Sociophonetic voice onset time variation in Mississippi Englisha)
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEAKERS SEX-DIFFERENCES; SPEAKING RATE; AFRICAN-AMERICAN;
   SPEECH-PERCEPTION; CROSS-LANGUAGE; DIALECT; SPANISH; GENDER; FRENCH;
   STOPS
AB Differences in the way voice onset time (VOT) is used across languages to maintain stop voicing contrasts have been well-documented, but less research has focused on VOT variation within voicing categories. For example, native English speakers are generally reported to produce word-initial voiced stops with short positive VOTs, but within category differences connected to self-reported gender and ethnicity have been reported in one preliminary study, with male speakers prevoicing more than female speakers and with African American speakers prevoicing more than Caucasian American speakers. For the current study, native speakers of English from Mississippi were recorded reading three repetitions of a pseudo-randomized list of words designed to investigate the connections between gender, ethnicity, and prevoicing of word-initial voiced stops. Participants self-identified their gender and ethnicity in an open-ended language background survey completed after recordings. Significant ethnicity, but not gender, differences were found, with African American speakers prevoicing voiced stops far more than their Caucasian American counterparts. Presumably, this difference is linked, not to ethnicity, but to dialect. These findings suggest that dialectal differences play a role in the VOT variation of word-initial voiced stops and that prevoicing may be a heretofore unidentified characteristic of African American English.
C1 [Herd, Wendy] Mississippi State Univ, Dept English, 2004 Lee Hall, Mississippi State, MS 39762 USA.
RP Herd, W (corresponding author), Mississippi State Univ, Dept English, 2004 Lee Hall, Mississippi State, MS 39762 USA.
EM wherd@english.msstate.edu
OI Herd, Wendy/0000-0003-1766-7939
CR Allen JS, 2003, J ACOUST SOC AM, V113, P544, DOI 10.1121/1.1528172
   Ameijeiras-Alonso J., 2019, J STAT SOFTWARE
   [Anonymous], 2015, Arthritis Rheumatol, V67 Suppl 10, P1, DOI 10.1002/art.39448
   [Anonymous], 2013, PEDIATRICS, V133, pe54, DOI [10.1542/peds.2013-0819d, DOI 10.1121/1.4778281]
   [Anonymous], 1996, ICRP PUBL, V26, P23, DOI DOI 10.1017/S0025100300005302
   [Anonymous], 1986, MUSEUM HELVETICUM, V43, P155, DOI DOI 10.1159/000261768
   Baran J. A., 1977, J PHONETICS, V5, P339, DOI 10.1016/S0095-4470(19)31204-5
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Boucher VJ, 2002, PERCEPT PSYCHOPHYS, V64, P121, DOI 10.3758/BF03194561
   BYRD D, 1992, J ACOUST SOC AM, V92, P593, DOI 10.1121/1.404271
   BYRD D, 1994, SPEECH COMMUN, V15, P39, DOI 10.1016/0167-6393(94)90039-6
   Cho T, 1999, J PHONETICS, V27, P207, DOI 10.1006/jpho.1999.0094
   Clopper CG, 2015, J PHONETICS, V49, P1, DOI 10.1016/j.wocn.2014.10.002
   Craig HK, 2003, J SPEECH LANG HEAR R, V46, P623, DOI 10.1044/1092-4388(2003/049)
   Dmitrieva O, 2015, J PHONETICS, V49, P77, DOI 10.1016/j.wocn.2014.12.005
   EGAN JP, 1948, LARYNGOSCOPE, V58, P955, DOI 10.1288/00005537-194809000-00002
   FLEGE JE, 1987, J PHONETICS, V15, P67, DOI 10.1016/S0095-4470(19)30538-8
   HARTIGAN JA, 1985, ANN STAT, V13, P70, DOI 10.1214/aos/1176346577
   Hunnicutt L., 2016, U PENNSYLVANIA WORKI, V22, P215
   Jacewicz E, 2009, J INT PHON ASSOC, V39, P313, DOI 10.1017/S0025100309990156
   Jones T, 2015, AM SPEECH, V90, P403, DOI 10.1215/00031283-3442117
   Kessinger RH, 1997, J PHONETICS, V25, P143, DOI 10.1006/jpho.1996.0039
   Kessinger RH, 1998, J PHONETICS, V26, P117, DOI 10.1006/jpho.1997.0069
   Ladefoged P., 2001, COURSE PHONETICS
   LISKER L, 1967, LANG SPEECH, V10, P1, DOI 10.1177/002383096701000101
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   MacKay IRA, 2001, J ACOUST SOC AM, V110, P516, DOI 10.1121/1.1377287
   Magloire J, 1999, PHONETICA, V56, P158, DOI 10.1159/000028449
   McMurray B, 2013, COGNITION, V129, P362, DOI 10.1016/j.cognition.2013.07.015
   MILLER JL, 1986, PHONETICA, V43, P106, DOI 10.1159/000261764
   Morris RJ, 2008, J PHONETICS, V36, P308, DOI 10.1016/j.wocn.2007.06.003
   Oh E, 2011, J PHONETICS, V39, P59, DOI 10.1016/j.wocn.2010.11.002
   Perrachione TK, 2010, COGNITION, V114, P42, DOI 10.1016/j.cognition.2009.08.012
   Pollock K. E., 2001, COMMUNICATION DISORD, V23, P47, DOI [10.1177/152574010102300107, DOI 10.1177/152574010102300107]
   Ravizza SM, 2003, BRAIN COGNITION, V53, P301, DOI 10.1016/S0278-2626(03)00131-3
   RStudio Team, 2015, RSTUDIO INT DEV R VE
   Ryalls J, 1997, J SPEECH LANG HEAR R, V40, P642, DOI 10.1044/jslhr.4003.642
   Ryalls J., 2004, J MULTILINGUAL COMMU, V2, P61, DOI DOI 10.1080/1476967031000090980
   Smith B.L., 1978, GLOSSA, V12, P163
   SMITH BL, 1975, J ACOUST SOC AM, V58, pS61, DOI 10.1121/1.2002223
   Stewart J, 2018, J INT PHON ASSOC, V48, P173, DOI 10.1017/S002510031700024X
   Summerfield A. Q, 1975, SPEECH PERCEPTION, V4, P61
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   SWARTZ BL, 1992, PERCEPT MOTOR SKILL, V75, P983, DOI 10.2466/PMS.75.7.983-992
   Syrdal A. K., 1996, 4 INT C SPOK LANG P
   Thomas E. R., 2015, OXFORD HDB AFRICAN, P403, DOI [10.1093/oxfordhb/9780199795390.013.13, DOI 10.1093/OXFORDHB/9780199795390.013.13]
   Thomas ER, 2004, J SOCIOLING, V8, P54, DOI 10.1111/j.1467-9841.2004.00251.x
   United States Census Bureau, 2018, QUICK FACTS STARKV C
   United States Census Bureau, 2018, QUICK FACTS GREENV C
   van Alphen PM, 2004, J PHONETICS, V32, P455, DOI 10.1016/j.wocn.2004.05.001
   VOLAITIS LE, 1992, J ACOUST SOC AM, V92, P723, DOI 10.1121/1.403997
   Whalen DH, 2007, J PHONETICS, V35, P341, DOI 10.1016/j.wocn.2006.10.001
   Whiteside SP, 1998, PERCEPT MOTOR SKILL, V86, P651, DOI 10.2466/pms.1998.86.2.651
   Whiteside SP, 1997, PERCEPT MOTOR SKILL, V85, P459
   Whiteside SP, 2001, PHONETICA, V58, P196, DOI 10.1159/000056199
NR 56
TC 2
Z9 2
U1 0
U2 0
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JAN
PY 2020
VL 147
IS 1
BP 596
EP 605
DI 10.1121/10.0000545
PG 10
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA KO4ER
UT WOS:000515501700011
PM 32006957
OA Bronze
DA 2021-02-24
ER

PT J
AU Clopper, CG
   Dossey, E
AF Clopper, Cynthia G.
   Dossey, Ellen
TI Phonetic convergence to Southern American English: Acoustics and
   perception
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH-PERCEPTION; DIALECT; IMITATION; DURATION; GENDER
AB Phonetic convergence is linguistically and socially selective. The current study examined the constraints on this selectivity in convergence to Southern American English by non-Southern Americans in a word shadowing task. Participants were asked either to repeat the words after the model talker, to repeat the words after the model talker from Louisville, KY, or to imitate the way the model talker from Louisville, KY, said the words, in a between-subject design. Acoustic analysis of the participants' productions revealed significant phonetic convergence on word duration and back vowel fronting, but not on /a?/ monophthongization, across all three instruction conditions. These findings suggest social selectivity such that convergence on stereotyped variants is avoided, but convergence to a talker with a non-prestigious variety is not. A perceptual assessment of convergence confirmed the acoustic results, but also revealed significantly more convergence in the explicit imitation condition than in the two repetition conditions. These findings suggest that explicit instructions to imitate lead to greater convergence overall, but do not completely override social selectivity. A comparison of the acoustic and perceptual assessments of convergence indicates that they provide complementary insights into specific features and holistic patterns of convergence, respectively.
C1 [Clopper, Cynthia G.; Dossey, Ellen] Ohio State Univ, Dept Linguist, 1712 Neil Ave, Columbus, OH 43210 USA.
RP Clopper, CG (corresponding author), Ohio State Univ, Dept Linguist, 1712 Neil Ave, Columbus, OH 43210 USA.
EM clopper.1@osu.edu
CR [Anonymous], 2013, S AFR J ANAESTH ANAL, V19, pS1, DOI DOI 10.1121/1.4798469
   [Anonymous], 2013, ROSSIYSKIY KARDIO S3, V4, P1, DOI DOI 10.1186/2049-1891-4-1
   [Anonymous], 2017, EVOL PSYCHIAT, V82, P1, DOI DOI 10.18637/JSS.V082.I13
   [Anonymous], 2015, RIV STORICA ITAL, V6, P1, DOI DOI 10.3389/fpls.2015.00951
   Babel M, 2012, LANG SPEECH, V55, P231, DOI 10.1177/0023830911417695
   Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001
   Babel M, 2010, LANG SOC, V39, P437, DOI 10.1017/S0047404510000400
   Bates D., 2015, ARXIV150604967STAT
   Bonin F., 2013, P INT 2013
   BYRD D, 1994, SPEECH COMMUN, V15, P39, DOI 10.1016/0167-6393(94)90039-6
   Clopper C. G., 2002, 25 IND U SPEECH RES, P367
   Clopper CG, 2005, J ACOUST SOC AM, V118, P1661, DOI 10.1121/1.2000774
   Clopper CG, 2004, J PHONETICS, V32, P111, DOI 10.1016/S0095-4470(03)00009-3
   Clopper CG, 2015, J PHONETICS, V49, P1, DOI 10.1016/j.wocn.2014.10.002
   Clopper CG, 2012, J AUTISM DEV DISORD, V42, P740, DOI 10.1007/s10803-011-1305-y
   Clopper CG, 2011, J PHONETICS, V39, P237, DOI 10.1016/j.wocn.2011.02.006
   Cole J., 2011, PROCEEDINGS OF INTER, P969
   Delvaux V, 2007, PHONETICA, V64, P145, DOI 10.1159/000107914
   Fox RA, 2009, J ACOUST SOC AM, V126, P2603, DOI 10.1121/1.3212921
   Fridland V, 2008, LANG VAR CHANGE, V20, P67, DOI 10.1017/S0954394508000069
   German JS, 2013, J PHONETICS, V41, P228, DOI 10.1016/j.wocn.2013.03.001
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Gomez M. N., 2011, ARTE OFICIO ENSENAR, V2, P125, DOI DOI 10.1515/LABPHON.2011.004
   Harrington J, 2008, J ACOUST SOC AM, V123, P2825, DOI 10.1121/1.2897042
   Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Jacewicz E, 2007, AM SPEECH, V82, P367, DOI 10.1215/00031283-2007-024
   Jacewicz E, 2009, LANG VAR CHANGE, V21, P233, DOI 10.1017/S0954394509990093
   Kendall Tyler S., 2009, THESIS
   Labov William, 2006, ATLAS N AM ENGLISH
   Labov William, 1972, SOCIOLINGUISTIC PATT
   LUHMAN R, 1990, LANG SOC, V19, P331, DOI 10.1017/S0047404500014548
   Markham Duncan, 1999, FORENSIC LINGUIST, V6, P289, DOI DOI 10.1558/SLL.1999.6.2.289
   McCullough EA, 2019, CHILD DEV, V90, P1080, DOI 10.1111/cdev.12984
   Michalsky J, 2017, INTERSPEECH, P2253, DOI 10.21437/Interspeech.2017-1520
   Mitterer H, 2013, ATTEN PERCEPT PSYCHO, V75, P557, DOI 10.3758/s13414-012-0407-8
   Mitterer H, 2008, COGNITION, V109, P168, DOI 10.1016/j.cognition.2008.08.002
   Namy LL, 2002, J LANG SOC PSYCHOL, V21, P422, DOI 10.1177/026192702237958
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Niedzielski N., 2003, FOLK LINGUISTICS
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007
   Nguyen N, 2015, J PHONETICS, V53, P46, DOI 10.1016/j.wocn.2015.08.004
   Nolard N, 2004, BCCM NEWSLETTER, V16, P1, DOI DOI 10.1017/S0954394504161012
   Pardo J. S, 2010, EXPRESSING ONESELF E, P183
   Pardo JS, 2017, ATTEN PERCEPT PSYCHO, V79, P637, DOI 10.3758/s13414-016-1226-0
   Pardo JS, 2012, LANG LINGUIST COMPAS, V6, P753, DOI 10.1002/lnc3.367
   Pardo JS, 2013, J MEM LANG, V69, P183, DOI 10.1016/j.jml.2013.06.002
   Pardo JS, 2012, J PHONETICS, V40, P190, DOI 10.1016/j.wocn.2011.10.001
   Pardo JS, 2010, ATTEN PERCEPT PSYCHO, V72, P2254, DOI 10.3758/APP.72.8.2254
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720
   PETERSON GE, 1960, J ACOUST SOC AM, V32, P693, DOI 10.1121/1.1908183
   Preston D., 1998, LANGUAGE MYTHS, P139
   Sanker C., 2015, CORNELL WORKING PAPE, V2015, P60
   Scarborough R, 2013, J ACOUST SOC AM, V134, P3793, DOI 10.1121/1.4824120
   Shockley K, 2004, PERCEPT PSYCHOPHYS, V66, P422, DOI 10.3758/BF03194890
   Thomas E. R., 2001, ACOUSTIC ANAL VOWEL
   TRAUNMULLER H, 1990, J ACOUST SOC AM, V88, P97, DOI 10.1121/1.399849
   van Dommelen W. A., 2011, P 17 INT C PHON SCI, P599
   VV.AA, 2012, COMPOSITE MAT HDB CM, V3, P1, DOI DOI 10.1515/2152-2812.1105
   Yu ACL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0074746
   Yuan J, 2008, J ACOUST SOC AM, V124, P2078, DOI 10.1121/1.2968700
   2011, EUR J CARDIO-THORAC, V39, P18, DOI DOI 10.1016/J.WOCN.2010.10.007
NR 62
TC 1
Z9 1
U1 0
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JAN
PY 2020
VL 147
IS 1
BP 671
EP 683
DI 10.1121/10.0000555
PG 13
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA KO4ER
UT WOS:000515501700017
PM 32007019
OA Bronze
DA 2021-02-24
ER

PT J
AU Sarant, J
   Harris, D
   Busby, P
   Maruff, P
   Schembri, A
   Lemke, U
   Launer, S
AF Sarant, Julia
   Harris, David
   Busby, Peter
   Maruff, Paul
   Schembri, Adrian
   Lemke, Ulrike
   Launer, Stefan
TI The Effect of Hearing Aid Use on Cognition in Older Adults: Can We Delay
   Decline or Even Improve Cognitive Function?
SO JOURNAL OF CLINICAL MEDICINE
LA English
DT Article
DE hearing loss; cognitive decline; hearing aids; older adults; age;
   education; sex; speech perception
ID COGSTATE BRIEF BATTERY; SEX-DIFFERENCES; SENSORY LOSS; FOLLOW-UP;
   LONELINESS; IMPAIRMENT; DEPRESSION; HEALTH; DEMENTIA; GENDER
AB Hearing loss is a modifiable risk factor for dementia in older adults. Whether hearing aid use can delay the onset of cognitive decline is unknown. Participants in this study (aged 62-82 years) were assessed before and 18 months after hearing aid fitting on hearing, cognitive function, speech perception, quality of life, physical activity, loneliness, isolation, mood, and medical health. At baseline, multiple linear regression showed hearing loss and age predicted significantly poorer executive function performance, while tertiary education predicted significantly higher executive function and visual learning performance. At 18 months after hearing aid fitting, speech perception in quiet, self-reported listening disability and quality of life had significantly improved. Group mean scores across the cognitive test battery showed no significant decline, and executive function significantly improved. Reliable Change Index scores also showed either clinically significant improvement or stability in executive function for 97.3% of participants, and for females for working memory, visual attention and visual learning. Relative stability and clinically and statistically significant improvement in cognition were seen in this participant group after 18 months of hearing aid use, suggesting that treatment of hearing loss with hearing aids may delay cognitive decline. Given the small sample size, further follow up is required.
C1 [Sarant, Julia; Busby, Peter] Univ Melbourne, Dept Audiol & Speech Pathol, Melbourne, Vic 3010, Australia.
   [Harris, David] Univ Melbourne, Dept Econ, Melbourne, Vic 3010, Australia.
   [Maruff, Paul; Schembri, Adrian] CogState, Melbourne, Vic 3000, Australia.
   [Lemke, Ulrike; Launer, Stefan] Sonova AG, CH-8712 Zurich, Stafa, Switzerland.
RP Sarant, J (corresponding author), Univ Melbourne, Dept Audiol & Speech Pathol, Melbourne, Vic 3010, Australia.
EM jsarant@unimelb.edu.au; harris.d@unimelb.edu.au; pabusby@unimelb.edu.au;
   pmaruff@cogstate.com; aschembri@cogstate.com; Ulrike.Lemke@sonova.com;
   Stefan.Launer@sonova.com
RI Maruff, Paul/ABA-1673-2020; Maruff, Paul/AAD-2454-2021
OI Maruff, Paul/0000-0002-6947-9537; Harris, David/0000-0002-4237-6888;
   Sarant, Julia/0000-0002-6681-6665; Launer, Stefan/0000-0002-2030-6854
FU Sonova AG
FX This research was funded by a research grant from Sonova AG.
CR Access Economics, 2006, LIST HEAR EC IMP COS
   Albers MW, 2015, ALZHEIMERS DEMENT, V11, P70, DOI 10.1016/j.jalz.2014.04.514
   American Speech-Language-Hearing Association, 2011, AM SPEECH HEAR ASS A
   Amieva H, 2015, J AM GERIATR SOC, V63, P2099, DOI 10.1111/jgs.13649
   Arlinger S, 2003, INT J AUDIOL, V42, pS17
   Berkman LF, 2004, AM J EPIDEMIOL, V159, P167, DOI 10.1093/aje/kwh020
   Bjelland I, 2008, SOC SCI MED, V66, P1334, DOI 10.1016/j.socscimed.2007.12.019
   Chien W, 2012, ARCH INTERN MED, V172, P292, DOI 10.1001/archinternmed.2011.1408
   Chisolm TH, 2007, J AM ACAD AUDIOL, V18, P151, DOI 10.3766/jaaa.18.2.7
   Collie A, 2003, CLIN J SPORT MED, V13, P28, DOI 10.1097/00042752-200301000-00006
   Contrera KJ, 2017, LARYNGOSCOPE, V127, P1885, DOI 10.1002/lary.26424
   COX RM, 1995, EAR HEARING, V16, P176, DOI 10.1097/00003446-199504000-00005
   Craig CL, 2003, MED SCI SPORT EXER, V35, P1381, DOI 10.1249/01.MSS.0000078924.61453.FB
   Dawes P, 2015, INT J AUDIOL, V54, P838, DOI 10.3109/14992027.2015.1059503
   Dawes P, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119616
   Deal JA, 2015, AM J EPIDEMIOL, V181, P680, DOI 10.1093/aje/kwu333
   DEJONGGIERVELD J, 1985, APPL PSYCH MEAS, V9, P289, DOI 10.1177/014662168500900307
   Evans C., 1998, EVID-BASED MENT HEAL, V1, P70, DOI [10.1136/ebmh.1.3.70, DOI 10.1136/EBMH.1.3.70]
   Falleti MG, 2006, J CLIN EXP NEUROPSYC, V28, P1095, DOI 10.1080/13803390500205718
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Fulton Susan E., 2015, Seminars in Hearing, V36, P140, DOI 10.1055/s-0035-1555117
   Garstecki DC, 1999, J SPEECH LANG HEAR R, V42, P785, DOI 10.1044/jslhr.4204.785
   Gates GA, 2010, COGN BEHAV NEUROL, V23, P218, DOI 10.1097/WNN.0b013e3181d748d7
   Hallgren M, 2005, INT J AUDIOL, V44, P574, DOI 10.1080/14992020500190011
   Hawkley LC, 2010, ANN BEHAV MED, V40, P218, DOI 10.1007/s12160-010-9210-8
   Heine C, 2002, DISABIL REHABIL, V24, P763, DOI 10.1080/09638280210129162
   Helzner EP, 2005, J AM GERIATR SOC, V53, P2119, DOI 10.1111/j.1532-5415.2005.00525.x
   Hogan A, 2009, J AGING HEALTH, V21, P1098, DOI 10.1177/0898264309347821
   Horsman John, 2003, Health Qual Life Outcomes, V1, P54, DOI 10.1186/1477-7525-1-54
   Huang CQ, 2010, AGEING RES REV, V9, P131, DOI 10.1016/j.arr.2009.05.005
   Hull RH, 2010, AM J AUDIOL, V19, P9, DOI 10.1044/1059-0889(2010/08-0040)
   Jayakody DMP, 2018, CLIN OTOLARYNGOL, V43, P182, DOI 10.1111/coa.12937
   Kalluri S, 2012, AM J AUDIOL, V21, P338, DOI 10.1044/1059-0889(2012/12-0026)
   Keidser G, 2011, AUDIOL RES, V1, P88, DOI 10.4081/audiores.2011.e24
   Larson EB, 2008, LANCET, V372, P430, DOI 10.1016/S0140-6736(08)61003-X
   Lim YY, 2013, ARCH CLIN NEUROPSYCH, V28, P320, DOI 10.1093/arclin/act021
   Lim YY, 2013, J ALZHEIMERS DIS, V33, P675, DOI 10.3233/JAD-2012-121516
   Lim YY, 2012, J CLIN EXP NEUROPSYC, V34, P345, DOI 10.1080/13803395.2011.643227
   Lin FR, 2011, NEUROPSYCHOLOGY, V25, P763, DOI 10.1037/a0024238
   Lin FR, 2011, ARCH NEUROL-CHICAGO, V68, P214, DOI 10.1001/archneurol.2010.362
   Liu CM, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.8112
   Livingston G, 2017, LANCET, V390, P2673, DOI 10.1016/S0140-6736(17)31363-6
   Lorant V, 2003, AM J EPIDEMIOL, V157, P98, DOI 10.1093/aje/kwf182
   Loughrey DG, 2018, JAMA OTOLARYNGOL, V144, P115, DOI 10.1001/jamaoto.2017.2513
   Lubben J.E., 1988, J FAMILY COMMUNITY H, V11, P42, DOI DOI 10.1097/00003727-198811000-00008
   Maharani A, 2018, J AM GERIATR SOC, V66, P1130, DOI 10.1111/jgs.15363
   Mahmoudi E, 2019, J AM GERIATR SOC, V67, P2362, DOI 10.1111/jgs.16109
   Maruff Paul, 2013, BMC Psychol, V1, P30, DOI 10.1186/2050-7283-1-30
   Maruff P, 2009, ARCH CLIN NEUROPSYCH, V24, P165, DOI 10.1093/arclin/acp010
   Mener DJ, 2013, J AM GERIATR SOC, V61, P1627, DOI 10.1111/jgs.12429
   Mick P, 2018, CAN FAM PHYSICIAN, V64, pE33
   MULROW CD, 1992, J SPEECH HEAR RES, V35, P1402, DOI 10.1044/jshr.3506.1402
   Murphy DR, 2006, PSYCHOL AGING, V21, P49, DOI 10.1037/0882-7974.21.1.49
   Noble W, 1995, J Am Acad Audiol, V6, P129
   Osler M, 2019, EUR J EPIDEMIOL, V34, P125, DOI 10.1007/s10654-018-0452-2
   Prince M, 2015, WORLD ALZHEIMER REPO, P1
   Roberts RO, 2012, NEUROLOGY, V78, P342, DOI 10.1212/WNL.0b013e3182452862
   Rocca WA, 2014, MATURITAS, V79, P196, DOI 10.1016/j.maturitas.2014.05.008
   Ross CE, 2006, SOC SCI MED, V63, P1400, DOI 10.1016/j.socscimed.2006.03.013
   Sarant J, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00789
   Sindhusake D, 2001, INT J EPIDEMIOL, V30, P1371, DOI 10.1093/ije/30.6.1371
   Smeeth L, 2002, LANCET, V359, P1466, DOI 10.1016/S0140-6736(02)08433-7
   Staehelin K, 2011, EAR HEARING, V32, pE26, DOI 10.1097/AUD.0b013e3182291f94
   Takahashi G, 2007, J AM ACAD AUDIOL, V18, P323, DOI 10.3766/jaaa.18.4.6
   Taljaard DS, 2016, CLIN OTOLARYNGOL, V41, P718, DOI 10.1111/coa.12607
   ten Kate J, 2017, SOCIOL SPECTRUM, V37, P63, DOI 10.1080/02732173.2016.1274248
   Valentijn SAM, 2005, J AM GERIATR SOC, V53, P374, DOI 10.1111/j.1532-5415.2005.53152.x
   VandenLangenberg GM, 1998, AM J EPIDEMIOL, V148, P204, DOI 10.1093/oxfordjournals.aje.a009625
   VERSCHUURE J, 1992, AUDIOLOGY, V31, P205
   Weinstein BE, 2016, AM J AUDIOL, V25, P54, DOI 10.1044/2015_AJA-15-0055
   Westerman R, 2001, AUSTR DEFENCE FORCE, V2, P29
   ZIGMOND AS, 1983, ACTA PSYCHIAT SCAND, V67, P361, DOI 10.1111/j.1600-0447.1983.tb09716.x
NR 72
TC 5
Z9 5
U1 4
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2077-0383
J9 J CLIN MED
JI J. Clin. Med.
PD JAN
PY 2020
VL 9
IS 1
AR 254
DI 10.3390/jcm9010254
PG 23
WC Medicine, General & Internal
SC General & Internal Medicine
GA KO2OF
UT WOS:000515388400254
PM 31963547
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Winn, MB
AF Winn, Matthew B.
TI Accommodation of gender-related phonetic differences by listeners with
   cochlear implants and in a variety of vocoder simulations
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID ELECTRODE INSERTION DEPTH; NORMAL-HEARING LISTENERS; SPEECH RECOGNITION;
   SPECTRAL-RIPPLE; CHANNEL INTERACTION; PITCH PERCEPTION; TEMPORAL CUES;
   FREQUENCY; NOISE; DISCRIMINATION
AB Speech perception requires accommodation of a wide range of acoustic variability across talkers. A classic example is the perception of "sh" and "s" fricative sounds, which are categorized according to spectral details of the consonant itself, and also by the context of the voice producing it. Because women's and men's voices occupy different frequency ranges, a listener is required to make a corresponding adjustment of acoustic-phonetic category space for these phonemes when hearing different talkers. This pattern is commonplace in everyday speech communication, and yet might not be captured in accuracy scores for whole words, especially when word lists are spoken by a single talker. Phonetic accommodation for fricatives "s" and "sh" was measured in 20 cochlear implant (CI) users and in a variety of vocoder simulations, including those with noise carriers with and without peak picking, simulated spread of excitation, and pulsatile carriers. CI listeners showed strong phonetic accommodation as a group. Each vocoder produced phonetic accommodation except the 8-channel noise vocoder, despite its historically good match with CI users in word intelligibility. Phonetic accommodation is largely independent of linguistic factors and thus might offer information complementary to speech intelligibility tests which are partially affected by language processing.
C1 [Winn, Matthew B.] Univ Minnesota, Dept Speech & Hearing Sci, 164 Pillsbury Dr Southeast, Minneapolis, MN 55455 USA.
RP Winn, MB (corresponding author), Univ Minnesota, Dept Speech & Hearing Sci, 164 Pillsbury Dr Southeast, Minneapolis, MN 55455 USA.
EM mwinn@umn.edu
FU NIH-NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R03 DC014309, R01 DC 004786, R01
   DC003083, P30 HD03352]; University of Maryland Center for Comparative
   and Evolutionary Biology of Hearing Training Grant [T32 DC000046-17];
   NIH division of loan repaymentUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA
FX Data collection for this study was funded by NIH-NIDCD R01 DC 004786 (M.
   Chatterjee), R01 DC003083 (R. Litovsky), and NIH-NIDCD: R03 DC014309
   (M.B.W.). Additional support was provided by a core grant to the Waisman
   Center from the NIH-NICHD (Grant No. P30 HD03352). Data from the first
   seven CI listeners were collected with the support of the University of
   Maryland Center for Comparative and Evolutionary Biology of Hearing
   Training Grant T32 DC000046-17 (A. Popper). M.B.W. was also supported by
   the NIH division of loan repayment. Brianna Vandyke, Ashley Moore,
   Tiffany Mitchell, and Steven Gianakas assisted with data collection.
   Deniz Bakent, Ashley Moore, Tanvi Thakkar, and Alan Kan and three
   anonymous reviewers contributed helpful comments to an earlier version
   of this manuscript.
CR Aronoff JM, 2015, HEARING RES, V320, P24, DOI 10.1016/j.heares.2014.12.005
   Aronoff JM, 2013, J ACOUST SOC AM, V134, pEL217, DOI 10.1121/1.4813802
   Assmann PF, 1996, J ACOUST SOC AM, V100, P1141, DOI 10.1121/1.416299
   Baskent D, 2005, J ACOUST SOC AM, V117, P1405, DOI 10.1121/1.1856273
   Baskent D, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516670279
   Bates D., 2016, R PACKAGE VERSION, V1, P1, DOI DOI 10.2196/MEDINF0RM.4221
   Bierer JA, 2007, J ACOUST SOC AM, V121, P1642, DOI 10.1121/1.2436712
   Bingabr M, 2008, HEARING RES, V241, P73, DOI 10.1016/j.heares.2008.04.012
   Blamey P, 2013, AUDIOL NEURO-OTOL, V18, P36, DOI 10.1159/000343189
   BLUMSTEIN SE, 1979, J ACOUST SOC AM, V66, P1001, DOI 10.1121/1.383319
   Boersma P., 2011, PRAAT DOING PHONETIC
   Chatterjee M, 2008, HEARING RES, V235, P143, DOI 10.1016/j.heares.2007.11.004
   Crew JD, 2012, J ACOUST SOC AM, V132, pEL429, DOI 10.1121/1.4758770
   Deeks JM, 2004, J ACOUST SOC AM, V115, P1736, DOI 10.1121/1.1675814
   Devries L, 2016, JARO-J ASSOC RES OTO, V17, P237, DOI 10.1007/s10162-016-0557-9
   DiNino M, 2016, J ACOUST SOC AM, V140, P4404, DOI 10.1121/1.4971420
   Dorman MF, 1997, J ACOUST SOC AM, V102, P2993, DOI 10.1121/1.420354
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538
   Fu Q. J., 2004, JARO-J ASSOC RES OTO, V6, P19, DOI DOI 10.1007/S10162-004-5024-3
   Fu QJ, 2004, JARO-J ASSOC RES OTO, V5, P253, DOI 10.1007/s10162-004-4046-1
   Fuller CD, 2014, JARO-J ASSOC RES OTO, V15, P1037, DOI 10.1007/s10162-014-0483-7
   Gaudrain E, 2018, EAR HEARING, V39, P226, DOI 10.1097/AUD.0000000000000480
   Gianakas S., 2019, J ACOUST SOC AM, V141, P3839, DOI [10.1121/1.4988544, DOI 10.1121/1.4988544]
   Grange JA, 2017, J ACOUST SOC AM, V142, pEL484, DOI 10.1121/1.5009602
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052
   Holden LK, 2013, EAR HEARING, V34, P342, DOI 10.1097/AUD.0b013e3182741aa7
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Jones GL, 2013, J ACOUST SOC AM, V133, P425, DOI 10.1121/1.4768881
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   JONGMAN A, 1989, J ACOUST SOC AM, V85, P1718, DOI 10.1121/1.397961
   Kovacic D, 2009, J ACOUST SOC AM, V126, P762, DOI 10.1121/1.3158855
   Landsberger DM, 2015, EAR HEARING, V36, pE207, DOI 10.1097/AUD.0000000000000163
   Landsberger DM, 2012, HEARING RES, V284, P16, DOI 10.1016/j.heares.2011.12.009
   Laneau J, 2006, J ACOUST SOC AM, V119, P491, DOI 10.1121/1.2133391
   Litvak LM, 2007, J ACOUST SOC AM, V122, P982, DOI 10.1121/1.2749413
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P213, DOI 10.3758/BF03204377
   Maryn Y, 2009, J ACOUST SOC AM, V126, P2619, DOI 10.1121/1.3224706
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   Moberly AC, 2016, EAR HEARING, V37, P14, DOI 10.1097/AUD.0000000000000204
   Munson B, 2006, J ACOUST SOC AM, V119, P2427, DOI 10.1121/1.2173521
   Oxenham AJ, 2016, ADV EXP MED BIOL, V894, P125, DOI 10.1007/978-3-319-25474-6_14
   Oxenham AJ, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514553783
   Pals C, 2013, J SPEECH LANG HEAR R, V56, P1075, DOI 10.1044/1092-4388(2012/12-0074)
   Patro C, 2016, J ACOUST SOC AM, V140, P1336, DOI 10.1121/1.4961450
   PETERSON GE, 1962, J SPEECH HEAR DISORD, V27, P62, DOI 10.1044/jshd.2701.62
   R Core Team, 2016, R LANG ENV STAT COMP
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   Saberi K, 1999, NATURE, V398, P760, DOI 10.1038/19652
   Shannon RV, 1998, J ACOUST SOC AM, V104, P2467, DOI 10.1121/1.423774
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Shannon RV, 2004, ACTA OTO-LARYNGOL, V124, P50, DOI 10.1080/03655230410017562
   Skuk VG, 2014, J SPEECH LANG HEAR R, V57, P285, DOI 10.1044/1092-4388(2013/12-0314)
   Srinivasan AG, 2013, HEARING RES, V299, P29, DOI 10.1016/j.heares.2013.02.004
   Stafford RC, 2014, EAR HEARING, V35, P262, DOI 10.1097/AUD.0b013e3182a768e8
   Stilp CE, 2017, JARO-J ASSOC RES OTO, V18, P465, DOI 10.1007/s10162-017-0615-y
   Stilp CE, 2015, J ACOUST SOC AM, V137, P3466, DOI 10.1121/1.4921600
   Williges B, 2015, TRENDS HEAR, V19, DOI 10.1177/2331216515616940
   Winn M., 2019, P POD AC SOC AM SPRI
   Winn MB, 2016, EAR HEARING, V37, pE377, DOI 10.1097/AUD.0000000000000328
   Winn MB, 2015, J ACOUST SOC AM, V137, P1430, DOI 10.1121/1.4908308
   Winn MB, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00824
   Winn MB, 2012, J ACOUST SOC AM, V131, P1465, DOI 10.1121/1.3672705
   Won JH, 2007, JARO-J ASSOC RES OTO, V8, P384, DOI 10.1007/s10162-007-0085-8
   Xu L, 2005, J ACOUST SOC AM, V117, P3255, DOI 10.1121/1.1886405
   Zhou N, 2010, J ACOUST SOC AM, V128, P401, DOI 10.1121/1.3436558
NR 66
TC 1
Z9 1
U1 0
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JAN
PY 2020
VL 147
IS 1
BP 174
EP 190
DI 10.1121/10.0000566
PG 17
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA KO4DZ
UT WOS:000515499600001
PM 32006986
OA Green Published
DA 2021-02-24
ER

PT J
AU Miller, JD
   Watson, CS
   Leek, MR
   Wark, DJ
   Souza, PE
   Gordon-Salant, S
   Ahlstrom, JB
   Dubno, JR
AF Miller, James D.
   Watson, Charles S.
   Leek, Marjorie R.
   Wark, David J.
   Souza, Pamela E.
   Gordon-Salant, Sandra
   Ahlstrom, Jayne B.
   Dubno, Judy R.
TI Sentence perception in noise by hearing-aid users predicted by
   syllable-constituent perception and the use of context
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
AB Masked sentence perception by hearing-aid users is strongly correlated with three variables: (1) the ability to hear phonetic details as estimated by the identification of syllable constituents in quiet or in noise; (2) the ability to use situational context that is extrinsic to the speech signal; and (3) the ability to use inherent context provided by the speech signal itself. This approach is called "the syllable-constituent, contextual theory of speech perception" and is supported by the performance of 57 hearing-aid users in the identification of 109 syllable constituents presented in a background of 12-talker babble and the identification of words in naturally spoken sentences presented in the same babble. A simple mathematical model, inspired in large part by Boothroyd and Nittrouer [(1988). J. Acoust. Soc. Am. 84, 101-114] and Fletcher [Allen (1996) J. Acoust. Soc. Am. 99, 1825-1834], predicts sentence perception from listeners' abilities to recognize isolated syllable constituents and to benefit from context. When the identification accuracy of syllable constituents is greater than about 55%, individual differences in context utilization play a minor role in determining the sentence scores. As syllable-constituent scores fall below 55%, individual differences in context utilization play an increasingly greater role in determining sentence scores. Implications for hearing-aid design goals and fitting procedures are discussed.
C1 [Miller, James D.; Watson, Charles S.] Commun Disorders Technol Inc, Bloomington, IN 47408 USA.
   [Leek, Marjorie R.] VA Loma Linda Healthcare Syst, Loma Linda, CA 92357 USA.
   [Wark, David J.] Univ Memphis, Commun Sci & Disorders, Memphis, TN 38105 USA.
   [Souza, Pamela E.] Northwestern Univ, Commun Sci & Disorders, Evanston, IL 60208 USA.
   [Gordon-Salant, Sandra] Univ Maryland, Hearing & Speech Sci, College Pk, MD 20742 USA.
   [Ahlstrom, Jayne B.; Dubno, Judy R.] Med Univ South Carolina, Dept Otolaryngol Head & Neck Surg, Charleston, SC 29425 USA.
RP Miller, JD (corresponding author), Commun Disorders Technol Inc, Bloomington, IN 47408 USA.
EM jamdmill@indiana.edu
OI Gordon-Salant, Sandra/0000-0001-8037-9724
FU NIH-NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R21/33 DC011174]; VA
   Rehabilitation Research and Development Service Senior Research Career
   Scientist Award [C4942L]
FX This work was supported by NIH-NIDCD Grant No. R21/33 DC011174 entitled,
   "Multi-Site Study of Speech Perception Training for Hearing-Aid Users,"
   C.S.W., PI. M.R.L.'s participation in this project is supported by VA
   Rehabilitation Research and Development Service Senior Research Career
   Scientist Award #C4942L. The data were collected at the Medical
   University of South Carolina, J.R.D., Site PI; Northwestern University,
   P.E.S., Site PI; the University of Maryland, S.G.-S., Site PI; the
   University of Memphis, D.J.W., Site PI; and the VA Loma Linda Healthcare
   System, M.R.L., Site PI. The authors wish to acknowledge contributions
   to this paper and the multi-site study by Heather Belding, Holley-Marie
   Biggs, Megan Espinosa, Emily Franko-Tobin, Sara Fultz, Sarah Hall, Gary
   R. Kidd, Rachel Lieberman, Laura Mathews, Roy Sillings, Laura Taliferro,
   and Erin Wilbanks. Daniel Maki, CFO of CDT, Inc. and Professor Emeritus
   of Mathematics, made helpful suggestions concerning issues related to
   fitting the logistic functions to the data. Maki, Miller, and Watson are
   all stockholders in CDT, Inc. and may profit from sales of SPATS
   software.
CR Allen JB, 1996, J ACOUST SOC AM, V99, P1825, DOI 10.1121/1.415364
   BOOTHROYD A, 1988, J ACOUST SOC AM, V84, P101, DOI 10.1121/1.396976
   Bronkhorst AW, 2002, J ACOUST SOC AM, V111, P2874, DOI 10.1121/1.1458025
   BRONKHORST AW, 1993, J ACOUST SOC AM, V93, P499, DOI 10.1121/1.406844
   Brown K., 2006, ENCY LANGUAGE LINGUI, V12, P329
   Cutler A., 2015, NATIVE LISTENING LAN
   Feuerstein R., 1979, DYNAMIC ASSESSMENTS
   Labov William, 1997, NATL MAP REGIONAL DI
   Miller JD, 2017, J ACOUST SOC AM, V141, P2933, DOI 10.1121/1.4979703
   Miller James D., 2015, Seminars in Hearing, V36, P273, DOI 10.1055/s-0035-1564453
   Olsen W. O., 1998, AM J AUDIOL, V7, P21, DOI DOI 10.1044/1059-0889(1998/012)
   Pearsons K. S., 1977, SPEECH LEVELS VARIOU, P82
   Smeds K, 2015, J AM ACAD AUDIOL, V26, P183, DOI 10.3766/jaaa.26.2.7
   Sternberg RJ, 2002, DYNAMIC TESTING NATU
   Wilson RH, 2011, J AM ACAD AUDIOL, V22, P405, DOI 10.3766/jaaa.22.7.3
NR 15
TC 0
Z9 0
U1 0
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JAN
PY 2020
VL 147
IS 1
BP 273
EP 284
DI 10.1121/10.0000563
PG 12
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA KO4EF
UT WOS:000515500300004
PM 32006979
OA Green Published
DA 2021-02-24
ER

PT J
AU Wiener, S
AF Wiener, Seth
TI Second language learners develop non-native lexical processing biases
SO BILINGUALISM-LANGUAGE AND COGNITION
LA English
DT Article
DE consonants; vowels; lexicon; phonological bias; second language
   acquisition
ID SPOKEN WORD RECOGNITION; CONSONANT/VOWEL ASYMMETRY; PHONETIC
   SPECIFICITY; VOCALIC INFORMATION; SPEECH-PERCEPTION; VOWELS; MANDARIN;
   ENGLISH; TONE; ACQUISITION
AB Infants develop language-specific biases favoring either consonantal or vocalic information. These phonological biases affect various levels of spoken-language recognition in children and adults. This study explored whether adults who speak a second language (L2) apply phonological biases during L2 lexical processing, and whether the biases applied are those of the native language (L1), or those appropriate for the L2. Two word reconstruction experiments were carried out in English and Mandarin Chinese. L1 and L2 speakers of English demonstrated a consonantal bias by changing English vowels faster than consonants. L1 and L2 speakers of Mandarin demonstrated a vocalic bias by changing Mandarin consonants faster than vowels. Even relatively late L2 classroom learners whose L1 triggers a consonantal bias (English) exhibited a vocalic bias in their L2 (Mandarin). Lexically related processing biases are thus determined by the phonological and lexical characteristics of the stimuli being processed and not solely by listeners' L1.
C1 [Wiener, Seth] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
RP Wiener, S (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
EM sethw1@cmu.edu
OI Wiener, Seth/0000-0002-7383-3682
CR Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Babjack DL, 2015, BEHAV RES METHODS, V47, P649, DOI 10.3758/s13428-015-0608-x
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Basboll Hans, 2005, PHONOLOGY DANISH
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bonatti LL, 2005, PSYCHOL SCI, V16, P451, DOI 10.1111/j.0956-7976.2005.01556.x
   Bonatti LL, 2007, PSYCHOL SCI, V18, P924, DOI 10.1111/j.1467-9280.2007.02002.x
   Bosch L, 2003, LANG SPEECH, V46, P217, DOI 10.1177/00238309030460020801
   Bouchon C, 2015, DEVELOPMENTAL SCI, V18, P587, DOI 10.1111/desc.12242
   Chang CB, 2013, J PHONETICS, V41, P520, DOI 10.1016/j.wocn.2013.09.006
   Chang CB, 2012, J PHONETICS, V40, P249, DOI 10.1016/j.wocn.2011.10.007
   CONNINE CM, 1993, J MEM LANG, V32, P193, DOI 10.1006/jmla.1993.1011
   CONNINE CM, 1994, PERCEPT PSYCHOPHYS, V56, P624, DOI 10.3758/BF03208356
   Creel SC, 2006, J MEM LANG, V54, P1, DOI 10.1016/j.jml.2005.09.003
   Cutler A, 2002, J MEM LANG, V46, P296, DOI 10.1006/jmla.2001.2814
   Cutler A, 2000, MEM COGNITION, V28, P746, DOI 10.3758/BF03198409
   Cutler A, 2012, NATIVE LISTENING
   DeFrancis J., 1986, CHINESE LANGUAGE FAC
   DeKeyser R, 2010, FOREIGN LANG ANN, V43
   Delle Luche C, 2014, J MEM LANG, V72, P1, DOI 10.1016/j.jml.2013.12.001
   Duanmu S., 2007, PHONOLOGY STANDARD C
   Duanmu S., 2009, SYLLABLE STRUCTURE L
   Flege J. E., 2007, LAB PHONOLOGY, P353
   Flege James, 1995, SPEECH PERCEPTION LI, P229
   Flege James E., 1991, CROSSCURRENTS 2 LANG, V2, P249, DOI DOI 10.1075/LALD.2.15FLE
   Flege JE, 1999, J MEM LANG, V41, P78, DOI 10.1006/jmla.1999.2638
   Floccia C, 2014, J CHILD LANG, V41, P1085, DOI 10.1017/S0305000913000287
   Fu QJ, 1998, J ACOUST SOC AM, V104, P505, DOI 10.1121/1.423251
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   Gomez DM, 2018, LANG SPEECH, V61, P84, DOI 10.1177/0023830917706529
   GRONNUM N, 1998, J INT PHON ASSOC, V28, P99, DOI DOI 10.1017/S0025100300006290
   Havy M, 2016, INT J BEHAV DEV, V40, P41, DOI 10.1177/0165025415570646
   Havy M, 2014, LANG SPEECH, V57, P254, DOI 10.1177/0023830913507693
   Havy M, 2009, INFANCY, V14, P439, DOI 10.1080/15250000902996532
   Hernandez A, 2005, TRENDS COGN SCI, V9, P220, DOI 10.1016/j.tics.2005.03.003
   HO AT, 1976, PHONETICA, V33, P353, DOI 10.1159/000259792
   Hochmann JR, 2011, DEVELOPMENTAL SCI, V14, P1445, DOI 10.1111/j.1467-7687.2011.01089.x
   Hojen A, 2016, DEVELOPMENTAL SCI, V19, P41, DOI 10.1111/desc.12286
   Keidel JL, 2007, PSYCHOL SCI, V18, P922, DOI 10.1111/j.1467-9280.2007.02001.x
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   LEE L, 1993, PERCEPT PSYCHOPHYS, V53, P157, DOI 10.3758/BF03211726
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Linck JA, 2009, PSYCHOL SCI, V20, P1507, DOI 10.1111/j.1467-9280.2009.02480.x
   MacWhinney B, 2005, HDB BILINGUALISM PSY, P49
   Malins JG, 2012, NEUROPSYCHOLOGIA, V50, P2032, DOI 10.1016/j.neuropsychologia.2012.05.002
   Malins JG, 2010, J MEM LANG, V62, P407, DOI 10.1016/j.jml.2010.02.004
   Mani N, 2010, INFANCY, V15, P445, DOI 10.1111/j.1532-7078.2009.00027.x
   Marks EA, 2002, LINGUISTICS, V40, P421, DOI 10.1515/ling.2002.018
   MARSLENWILSON W, 1989, J EXP PSYCHOL HUMAN, V15, P576, DOI 10.1037/0096-1523.15.3.576
   MARSLENWILSON W, 1990, ACL MIT NAT, P148
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001
   McLoughlin I, 2010, IEEE T AUDIO SPEECH, V18, P117, DOI 10.1109/TASL.2009.2024381
   MCQUEEN JM, 1994, J EXP PSYCHOL LEARN, V20, P621, DOI 10.1037/0278-7393.20.3.621
   McQueen JM, 1999, J EXP PSYCHOL HUMAN, V25, P1363, DOI 10.1037/0096-1523.25.5.1363
   MEHLER J, 1981, J VERB LEARN VERB BE, V20, P298, DOI 10.1016/S0022-5371(81)90450-3
   Nazzi T, 2005, COGNITION, V98, P13, DOI 10.1016/j.cognition.2004.10.005
   Nazzi T, 2007, COGNITIVE DEV, V22, P271, DOI 10.1016/j.cogdev.2006.10.007
   Nazzi T, 2019, ANNU REV LINGUIST, V5, P25, DOI 10.1146/annurev-linguistics-011718-011919
   Nazzi T, 2017, CUR ISS PSYCHOL LANG, P37
   Nazzi T, 2016, CURR DIR PSYCHOL SCI, V25, P291, DOI 10.1177/0963721416655786
   Nazzi T, 2009, LANG SPEECH, V52, P463, DOI 10.1177/0023830909336584
   Nazzi T, 2009, J EXP CHILD PSYCHOL, V102, P522, DOI 10.1016/j.jecp.2008.05.003
   Nespor M., 2003, LINGUE LINGUAGGIO, V2, P203, DOI [10. 1418/ 10879, DOI 10.1418/10879]
   New B, 2008, PSYCHOL SCI, V19, P1223, DOI 10.1111/j.1467-9280.2008.02228.x
   Nguyen MN, 2010, PLOS ONE, V5, pe9907
   Nishibayashi LL, 2016, COGNITION, V155, P188, DOI 10.1016/j.cognition.2016.07.003
   Packard J.L., 2000, MORPHOLOGY CHINESE L
   Perani D, 1998, BRAIN, V121, P1841, DOI 10.1093/brain/121.10.1841
   Pharao N, 2011, INT C PHON SCI 2011
   Poltrock S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01211
   Poltrock S, 2015, J EXP CHILD PSYCHOL, V131, P135, DOI 10.1016/j.jecp.2014.11.011
   Psychology Software Tools, 2012, E PRIM 2 0
   Quene H, 2008, J MEM LANG, V59, P413, DOI 10.1016/j.jml.2008.02.002
   R Core Team, 2017, R LANG ENV STAT COMP
   REPP BH, 1990, J PHONETICS, V18, P481, DOI 10.1016/S0095-4470(19)30410-3
   Samuel AG, 2011, ANNU REV PSYCHOL, V62, P49, DOI 10.1146/annurev.psych.121208.131643
   Sebastian-Galles N, 2005, J MEM LANG, V52, P240, DOI 10.1016/j.jml.2004.11.001
   Sharp DJ, 2005, BRAIN LANG, V92, P309, DOI 10.1016/j.bandl.2004.07.002
   Shen GN, 2016, J ACOUST SOC AM, V140, P4396, DOI 10.1121/1.4971765
   SHILLCOCK R, 1990, ACL MIT NAT, P24
   Silverberg S, 2004, J MEM LANG, V51, P381, DOI 10.1016/j.jml.2004.05.003
   Singh L, 2015, COGNITION, V142, P1, DOI 10.1016/j.cognition.2015.05.010
   Sunderman G, 2009, APPL PSYCHOLINGUIST, V30, P79, DOI 10.1017/S0142716408090048
   Tokowicz N., 2004, BILING-LANG COGN, V7, P255, DOI DOI 10.1017/S1366728904001634
   Tong Y., 2008, LANG COGNITIVE PROC, V23, P698
   Toro JM, 2008, PERCEPT PSYCHOPHYS, V70, P1515, DOI 10.3758/PP.70.8.1515
   Toro JM, 2008, PSYCHOL SCI, V19, P137, DOI 10.1111/j.1467-9280.2008.02059.x
   vanOoijen B, 1996, MEM COGNITION, V24, P573, DOI 10.3758/BF03201084
   Vitevitch MS, 1999, J MEM LANG, V40, P374, DOI 10.1006/jmla.1998.2618
   Vitevitch MS, 1998, PSYCHOL SCI, V9, P325, DOI 10.1111/1467-9280.00064
   Wang Y, 2003, J COGNITIVE NEUROSCI, V15, P1019, DOI 10.1162/089892903770007407
   Wewalaarachchi TD, 2017, J EXP CHILD PSYCHOL, V159, P16, DOI 10.1016/j.jecp.2017.01.009
   Wiener S, 2016, LANG SPEECH, V59, P59, DOI 10.1177/0023830915578000
   Wiener S, 2015, LANG COGN NEUROSCI, V30, P1048, DOI 10.1080/23273798.2014.946934
   Xu Y, 1999, J PHONETICS, V27, P55, DOI 10.1006/jpho.1999.0086
   Yip M., 2002, TONE
   Zeng B, 2017, LANG SPEECH, V60, P562, DOI 10.1177/0023830916675897
   Zhao JJ, 2011, NEUROPSYCHOLOGIA, V49, P1761, DOI 10.1016/j.neuropsychologia.2011.02.054
   Zhou XL, 1995, LANG COGNITIVE PROC, V10, P545, DOI 10.1080/01690969508407114
   ZHOU XL, 1994, LANG COGNITIVE PROC, V9, P393, DOI 10.1080/01690969408402125
NR 100
TC 2
Z9 2
U1 1
U2 6
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 1366-7289
EI 1469-1841
J9 BILING-LANG COGN
JI Biling.-Lang. Cogn.
PD JAN
PY 2020
VL 23
IS 1
BP 119
EP 130
DI 10.1017/S1366728918001165
PG 12
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA KM2ES
UT WOS:000513935500026
DA 2021-02-24
ER

PT J
AU Theodore, RM
   Flanagan, EG
AF Theodore, Rachel M.
   Flanagan, Erin G.
TI Determinants of voice recognition in monolingual and bilingual listeners
SO BILINGUALISM-LANGUAGE AND COGNITION
LA English
DT Article
DE speech perception; voice processing; individual differences; bilinguals
ID LANGUAGE-FAMILIARITY; TALKER; ADVANTAGE; DISCRIMINATION; IDENTIFICATION;
   ADAPTATION; PERCEPTION; EXPERIENCE; ADULTS; EVEN
AB Recent findings demonstrate a bilingual advantage for voice processing in children, but the mechanism supporting this advantage is unknown. Here we examined whether a bilingual advantage for voice processing is observed in adults and, if so, if it reflects enhanced pitch perception or inhibitory control. Voice processing was assessed for monolingual and bilingual adults using an associative learning identification task and a discrimination task in English (a familiar language) and French (an unfamiliar language). Participants also completed pitch perception, flanker, and auditory Stroop tasks. Voice processing was improved for the familiar compared to the unfamiliar language and reflected individual differences in pitch perception (both tasks) and inhibitory control (identification task). However, no bilingual advantage was observed for either voice task, suggesting that the bilingual advantage for voice processing becomes attenuated during maturation, with performance in adulthood reflecting knowledge of linguistic structure in addition to general auditory and inhibitory control abilities.
C1 [Theodore, Rachel M.; Flanagan, Erin G.] Univ Connecticut, Dept Speech Language & Hearing Sci, Storrs, CT 06269 USA.
   [Theodore, Rachel M.] Univ Connecticut, Connecticut Inst Brain & Cognit Sci, Storrs, CT 06269 USA.
RP Theodore, RM (corresponding author), Univ Connecticut, Dept Speech Language & Hearing Sci, Storrs, CT 06269 USA.
EM rachel.theodore@uconn.edu
FU Connecticut Institute for the Brain and Cognitive Sciences
FX This study was funded by a seed grant from the Connecticut Institute for
   the Brain and Cognitive Sciences to R. Theodore. We express gratitude to
   Yinyin Gu for her assistance with experiment programming and data
   collection. We also thank Linda Polka, Xin Xie, and Alexis Johns for
   generously providing their stimuli for use in the current work.
CR Bates Douglas, 2014, PACKAGE LME4, P12, DOI DOI 10.18637/JSS.V067.I01
   Bialystok E, 2018, COGNITION, V170, P330, DOI 10.1016/j.cognition.2017.10.019
   Bialystok E, 2017, PSYCHOL BULL, V143, P233, DOI 10.1037/bul0000099
   Bradlow AR, 1999, J ACOUST SOC AM, V106, P2074, DOI 10.1121/1.427952
   Bregman MR, 2014, COGNITION, V130, P85, DOI 10.1016/j.cognition.2013.09.010
   Chodroff E, 2017, J PHONETICS, V61, P30, DOI 10.1016/j.wocn.2017.01.001
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Drouin JR, 2016, J ACOUST SOC AM, V140, pEL307, DOI 10.1121/1.4964468
   ERIKSEN BA, 1974, PERCEPT PSYCHOPHYS, V16, P143, DOI 10.3758/BF03203267
   Fecher N, 2018, J EXPT PSYCHOL LEARN
   Fecher N, 2018, J ACOUST SOC AM, V143, P2409, DOI 10.1121/1.5032199
   Fleming D, 2014, P NATL ACAD SCI USA, V111, P13795, DOI 10.1073/pnas.1401383111
   GOGGIN JP, 1991, MEM COGNITION, V19, P448, DOI 10.3758/BF03199567
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Johns A, 2016, THESIS
   Johnson EK, 2018, COGNITIVE SCI, V42, P633, DOI 10.1111/cogs.12520
   Johnson EK, 2011, DEVELOPMENTAL SCI, V14, P1002, DOI 10.1111/j.1467-7687.2011.01052.x
   Kadam MA, 2016, J ACOUST SOC AM, V139, pEL6, DOI 10.1121/1.4937488
   Koster O, 1997, FORENSIC LINGUIST, V4, P18, DOI DOI 10.1558/IJSLL.V4I1.18
   Levi SV, 2018, BILING-LANG COGN, V21, P523, DOI 10.1017/S1366728917000153
   Levi SV, 2013, J SPEECH LANG HEAR R, V56, P913, DOI 10.1044/1092-4388(2012/12-0095)
   Newman RS, 2001, J ACOUST SOC AM, V109, P1181, DOI 10.1121/1.1348009
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   Orena AJ, 2015, COGNITION, V143, P36, DOI 10.1016/j.cognition.2015.06.002
   Owren MJ, 2008, BEHAV RES METHODS, V40, P822, DOI 10.3758/BRM.40.3.822
   Paap KR, 2017, J COGN PSYCHOL, V29, P89, DOI 10.1080/20445911.2016.1248436
   Paap KR, 2013, COGNITIVE PSYCHOL, V66, P232, DOI 10.1016/j.cogpsych.2012.12.002
   Perrachione TK, 2007, NEUROPSYCHOLOGIA, V45, P1899, DOI 10.1016/j.neuropsychologia.2006.11.015
   Perrachione TK, 2011, SCIENCE, V333, P595, DOI 10.1126/science.1207327
   Skoe E, 2017, NEUROSCIENCE, V349, P278, DOI 10.1016/j.neuroscience.2017.02.049
   Sommers MS, 2003, PSYCHOL AGING, V18, P791, DOI 10.1037/0882-7974.18.4.791
   Sommers MS, 1999, PSYCHOL AGING, V14, P458, DOI 10.1037/0882-7974.14.3.458
   Sullivan KPH, 2000, FORENSIC LINGUIST, V17, P95
   Theodore RM, 2015, J ACOUST SOC AM, V138, P1068, DOI 10.1121/1.4927489
   Theodore RM, 2009, J ACOUST SOC AM, V125, P3974, DOI 10.1121/1.3106131
   Valji A, 2004, THESIS
   Wester M, 2012, SPEECH COMMUN, V54, P781, DOI 10.1016/j.specom.2012.01.006
   Winters SJ, 2008, J ACOUST SOC AM, V123, P4524, DOI 10.1121/1.2913046
   Xie X, 2015, J ACOUST SOC AM, V137, P419, DOI 10.1121/1.4904699
   Ye YY, 2017, BILING-LANG COGN, V20, P844, DOI 10.1017/S1366728916000481
NR 41
TC 0
Z9 0
U1 9
U2 12
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 1366-7289
EI 1469-1841
J9 BILING-LANG COGN
JI Biling.-Lang. Cogn.
PD JAN
PY 2020
VL 23
IS 1
BP 158
EP 170
DI 10.1017/S1366728919000075
PG 13
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA KM2ES
UT WOS:000513935500029
DA 2021-02-24
ER

PT J
AU Liu, C
   Cheung, SK
   Chung, KKH
   McBride, C
   Lam, CB
   Li, XM
AF Liu, Catrina
   Cheung, Sum Kwing
   Chung, Kevin Kien Hoa
   McBride, Catherine
   Lam, Chun Bun
   Li, Xiaomin
TI The roles of executive functioning and oral language skills in young
   Chinese children's arithmetic competence
SO LEARNING AND INDIVIDUAL DIFFERENCES
LA English
DT Article
DE Executive functioning; Oral language skills; Number-fact problems; Story
   problems
ID PHONOLOGICAL AWARENESS; INDIVIDUAL-DIFFERENCES; DEVELOPMENTAL-CHANGES;
   SPEECH-PERCEPTION; EARLY MATHEMATICS; COGNITIVE SKILLS; SCHOOL
   READINESS; WORKING-MEMORY; SPATIAL SKILLS; WORD-PROBLEMS
AB This study investigated the relative contributions of executive functioning (EF) and oral language skills to performance on number-fact and story problems in Chinese children. A total of 280 kindergarten children in Hong Kong participated in this study. Children were assessed on their EF, phonological awareness, morphological awareness, receptive vocabulary, performance on number-fact and story problems. Results of path analysis showed that when children's age and parental education were controlled, children's EF, phonological awareness, and morphological awareness were con-elates of performance on both number-fact and story problems, whereas receptive vocabulary was not. After further controlling for performance on number-fact problems, morphological awareness was the only variable under investigation that linked to performance on story problems. These findings underscore the importance of taking the development of EF and oral language skills into consideration when guiding children's arithmetic learning.
C1 [Liu, Catrina; Cheung, Sum Kwing; Chung, Kevin Kien Hoa; Lam, Chun Bun; Li, Xiaomin] Educ Univ Hong Kong, Dept Early Childhood Educ, Hong Kong, Peoples R China.
   [McBride, Catherine] Chinese Univ Hong Kong, Dept Psychol, Hong Kong, Peoples R China.
RP Chung, KKH (corresponding author), Educ Univ Hong Kong, Tai Po, B2-1F-35,10 Lo Ping Rd, Hong Kong, Peoples R China.
EM kevin@eduhk.hk
RI Chung, Kevin K H/AAE-3949-2020
OI Chung, Kevin K H/0000-0002-8105-7361; Cheung, Sum
   Kwing/0000-0001-7870-3118; LAM, Chun Bun/0000-0002-3195-7919; LIU,
   Catrina/0000-0003-2857-5343
FU Standing Committee on Language Education and Research (SCOLAR), Hong
   Kong, China [EDB(LE)/PR/EL/164/1]
FX The work described in this article was fully supported by a grant from
   the Standing Committee on Language Education and Research (SCOLAR), Hong
   Kong, China [EDB(LE)/P&R/EL/164/1] to Kevin Kien Hoa Chung.
CR Alloway TP, 2005, BRIT J DEV PSYCHOL, V23, P417, DOI 10.1348/026151005X26804
   Best JR, 2010, CHILD DEV, V81, P1641, DOI 10.1111/j.1467-8624.2010.01499.x
   Bjork IM, 2013, EUR J PSYCHOL EDUC, V28, P1345, DOI 10.1007/s10212-012-0169-7
   Bull R, 2001, DEV NEUROPSYCHOL, V19, P273, DOI 10.1207/S15326942DN1903_3
   Bull R, 1997, J EXP CHILD PSYCHOL, V65, P1, DOI 10.1006/jecp.1996.2358
   Calderon J, 2014, DEV NEUROPSYCHOL, V39, P365, DOI 10.1080/87565641.2014.916709
   Cameron CE, 2012, CHILD DEV, V83, P1229, DOI 10.1111/j.1467-8624.2012.01768.x
   Chan W. W. L., 2014, PSYCHOL NEUROSCI, V7, P583, DOI [10.3922/j.psns.2014.4.18, DOI 10.3922/J.PSNS.2014.4.18]
   Cheung H, 2010, J EDUC PSYCHOL, V102, P367, DOI 10.1037/a0017850
   Cheung SK, 2018, BRIT J DEV PSYCHOL, V36, P334, DOI 10.1111/bjdp.12222
   Cheung SK, 2017, EARLY EDUC DEV, V28, P572, DOI 10.1080/10409289.2016.1258932
   Chow JC, 2018, EARLY CHILD RES Q, V46, P179, DOI 10.1016/j.ecresq.2018.02.011
   Chung KKH, 2013, J RES READ, V36, P202, DOI 10.1111/j.1467-9817.2011.01500.x
   Chung KKH, 2011, J EDUC PSYCHOL, V103, P909, DOI 10.1037/a0024744
   Chung KKH, 2018, READ WRIT, V31, P155, DOI 10.1007/s11145-017-9779-4
   Davidson MC, 2006, NEUROPSYCHOLOGIA, V44, P2037, DOI 10.1016/j.neuropsychologia.2006.02.006
   De Smedt B, 2010, DEVELOPMENTAL SCI, V13, P508, DOI 10.1111/j.1467-7687.2009.00897.x
   Dehaene S., 2011, NUMBER SENSE MIND CR
   Diamond A, 2013, ANNU REV PSYCHOL, V64, P135, DOI 10.1146/annurev-psych-113011-143750
   Duncan GJ, 2007, DEV PSYCHOL, V43, P1428, DOI 10.1037/0012-1649.43.6.1428
   Dunn L. M., 1997, PEABODY PICTURE VOCA
   Espy KA, 2004, DEV NEUROPSYCHOL, V26, P465, DOI 10.1207/s15326942dn2601_6
   Fuchs LS, 2006, J EDUC PSYCHOL, V98, P29, DOI 10.1037/0022-0663.98.1.29
   Fuchs LS, 2014, J EDUC PSYCHOL, V106, P990, DOI 10.1037/a0036793
   Geary DC, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0054651
   GEARY DC, 1993, PSYCHOL BULL, V114, P345, DOI 10.1037/0033-2909.114.2.345
   Harvey HA, 2017, EARLY EDUC DEV, V28, P290, DOI 10.1080/10409289.2016.1218728
   Ho CSH, 1998, J EDUC PSYCHOL, V90, P536, DOI 10.1037/0022-0663.90.3.536
   Huntsinger CS, 1997, INT J BEHAV DEV, V21, P371, DOI 10.1080/016502597384929
   Jordan NC, 2003, J EXP CHILD PSYCHOL, V85, P103, DOI 10.1016/S0022-0965(03)00032-8
   Kilpatrick J., 2001, ADDING IT HELPING CH, P115
   Krajewski K, 2009, J EXP CHILD PSYCHOL, V103, P516, DOI 10.1016/j.jecp.2009.03.009
   Lan XZ, 2011, J EXP CHILD PSYCHOL, V108, P677, DOI 10.1016/j.jecp.2010.11.001
   Lee K, 2013, CHILD DEV, V84, P1933, DOI 10.1111/cdev.12096
   LeFevre JA, 2010, CHILD DEV, V81, P1753, DOI 10.1111/j.1467-8624.2010.01508.x
   Lesh R, 1983, ACQUISITION MATH CON, P263
   LEWIS AB, 1987, J EDUC PSYCHOL, V79, P363, DOI 10.1037/0022-0663.79.4.363
   Liu YY, 2016, LEARN INDIVID DIFFER, V47, P215, DOI 10.1016/j.lindif.2016.01.007
   LOGIE RH, 1987, J EXP PSYCHOL LEARN, V13, P310, DOI 10.1037/0278-7393.13.2.310
   Mayer R. E., 1996, NATURE MATH THINKING, P29
   McBride-Chang C, 2003, J EDUC PSYCHOL, V95, P743, DOI 10.1037/0022-0663.95.4.743
   McClelland MM, 2018, EARLY CHILD RES Q, V46, P142, DOI 10.1016/j.ecresq.2018.03.014
   Miller KF, 2005, HDB MATH COGNITION, P163
   Miyake A, 2000, COGNITIVE PSYCHOL, V41, P49, DOI 10.1006/cogp.1999.0734
   Miyake A, 2012, CURR DIR PSYCHOL SCI, V21, P8, DOI 10.1177/0963721411429458
   Moll K, 2015, LEARN INSTR, V38, P53, DOI 10.1016/j.learninstruc.2015.03.004
   Muthen BO, 1995, SOCIOL METHODOL, V25, P267, DOI 10.2307/271070
   Muthen LK., 1998, MPLUS USERS GUIDE, VSeventh
   Negen J, 2012, CHILD DEV, V83, P2019, DOI 10.1111/j.1467-8624.2012.01815.x
   Ng SSN, 2010, REV EDUC RES, V80, P180, DOI 10.3102/0034654310364764
   Ostad S., 1998, MATH COGNITION, V4, P1, DOI [10.1080/135467998387389, DOI 10.1080/135467998387389]
   Purpura DJ, 2017, J EXP CHILD PSYCHOL, V153, P15, DOI 10.1016/j.jecp.2016.08.010
   Purpura DJ, 2016, EARLY CHILD RES Q, V36, P259, DOI 10.1016/j.ecresq.2015.12.020
   Purpura DJ, 2014, J EXP CHILD PSYCHOL, V122, P104, DOI 10.1016/j.jecp.2013.12.009
   Purpura DJ, 2011, J EXP CHILD PSYCHOL, V110, P647, DOI 10.1016/j.jecp.2011.07.004
   Rivera SM, 2005, CEREB CORTEX, V15, P1779, DOI 10.1093/cercor/bhi055
   Sherman EMS, 2010, CHILD NEUROPSYCHOL, V16, P503, DOI 10.1080/09297041003679344
   Simmons F, 2008, EUR J COGN PSYCHOL, V20, P711, DOI 10.1080/09541440701614922
   Simmons FR, 2008, DYSLEXIA, V14, P77, DOI 10.1002/dys.341
   Tabachnick Barbara, 2007, USING MULTIVARIATE S, V5
   Vukovic RK, 2013, J EXP CHILD PSYCHOL, V115, P227, DOI 10.1016/j.jecp.2013.02.002
   Welsh JA, 2010, J EDUC PSYCHOL, V102, P43, DOI 10.1037/a0016738
   Willoughby MT, 2012, PSYCHOL ASSESSMENT, V24, P418, DOI 10.1037/a0025779
   Wong TTY, 2017, J EDUC PSYCHOL, V109, P520, DOI 10.1037/edu0000149
   Yang XJ, 2019, EDUC PSYCHOL-UK, V39, P678, DOI 10.1080/01443410.2018.1546831
   Zhang X, 2018, EARLY CHILD RES Q, V42, P55, DOI 10.1016/j.ecresq.2017.08.006
   Zhang X, 2016, EARLY CHILD RES Q, V36, P178, DOI 10.1016/j.ecresq.2015.12.010
   Zhang X, 2015, CONTEMP EDUC PSYCHOL, V41, P188, DOI 10.1016/j.cedpsych.2015.01.005
   Zhang X, 2014, CHILD DEV, V85, P1091, DOI 10.1111/cdev.12173
NR 69
TC 0
Z9 0
U1 2
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1041-6080
EI 1873-3425
J9 LEARN INDIVID DIFFER
JI Learn. Individ. Differ.
PD JAN
PY 2020
VL 77
AR 101810
DI 10.1016/j.lindif.2019.101810
PG 9
WC Psychology, Educational
SC Psychology
GA KM2YO
UT WOS:000513988900014
DA 2021-02-24
ER

PT J
AU Chowdhury, A
   Ross, A
AF Chowdhury, Anurag
   Ross, Arun
TI Fusing MFCC and LPC Features Using 1D Triplet CNN for Speaker
   Recognition in Severely Degraded Audio Signals
SO IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY
LA English
DT Article
DE Speaker recognition; Speech recognition; Noise measurement; Mel
   frequency cepstral coefficient; Speech processing; Feature extraction;
   Production; Speaker recognition; degraded audio; deep learning; MFCC;
   LPC; 1-D CNN; feature-level fusion
ID NOISE; IDENTIFICATION; SPEECH; MACHINES
AB Speaker recognition algorithms are negatively impacted by the quality of the input speech signal. In this work, we approach the problem of speaker recognition from severely degraded audio data by judiciously combining two commonly used features: Mel Frequency Cepstral Coefficients (MFCC) and Linear Predictive Coding (LPC). Our hypothesis rests on the observation that MFCC and LPC capture two distinct aspects of speech, viz., speech perception and speech production. A carefully crafted 1D Triplet Convolutional Neural Network (1D-Triplet-CNN) is used to combine these two features in a novel manner, thereby enhancing the performance of speaker recognition in challenging scenarios. Extensive evaluation on multiple datasets, different types of audio degradations, multi-lingual speech, varying length of audio samples, etc. convey the efficacy of the proposed approach over existing speaker recognition methods, including those based on iVector and xVector.
C1 [Chowdhury, Anurag; Ross, Arun] Michigan State Univ, Dept Comp Sci Engn, E Lansing, MI 48823 USA.
RP Chowdhury, A (corresponding author), Michigan State Univ, Dept Comp Sci Engn, E Lansing, MI 48823 USA.
EM chowdh51@cse.msu.edu; rossarun@cse.msu.edu
CR ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599
   Ben Milner, 2002, P INTERSPEECH, P2421
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
   Brookes M., 1997, VOICEBOX SPEECH PROC, V47
   Campbell WM, 2006, IEEE SIGNAL PROC LET, V13, P308, DOI 10.1109/LSP.2006.870086
   Chowdhury A, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P608, DOI 10.1109/BTAS.2017.8272748
   Cieri C., 2004, PHILADELPHIA LINGUIS
   Dehak N., 2009, THESIS
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Denes P. B., 1993, THE SPEECH CHAIN
   Erkelens J. S., 1996, AUTOREGRESSIVE MODEL
   Fisher W., 1986, P DARPA WORKSH SPEEC, P93
   Garcia-Romero D., 2011, INTERSPEECH 2011 12, P249
   Gibiansky A., 2017, P NIPS, P1
   Guo JX, 2017, J ACOUST SOC AM, V141, pEL420, DOI 10.1121/1.4979841
   Hamad M., 2011, THESIS
   Hansen JHL, 2015, IEEE SIGNAL PROC MAG, V32, P74, DOI 10.1109/MSP.2015.2462851
   Hansen JHL, 2009, IEEE T AUDIO SPEECH, V17, P366, DOI 10.1109/TASL.2008.2009019
   Hirsch H.-G., 2000, P ISCA ITRW ASR2000, P181
   JANKOWSKI C, 1990, INT CONF ACOUST SPEE, P109, DOI 10.1109/ICASSP.1990.115550
   Kingma D. P., 2014, ARXIV14126980, P1
   Klambauer Gunter, 2017, ARXIV170602515
   Krishnamurthy N, 2009, IEEE T AUDIO SPEECH, V17, P1394, DOI 10.1109/TASL.2009.2015084
   Liu YF, 2007, PROCEEDINGS OF THE 6TH INTERNATIONAL SYMPOSIUM ON COAL COMBUSTION, P772
   Matejka P, 2016, INT CONF ACOUST SPEE, P5100, DOI 10.1109/ICASSP.2016.7472649
   May T, 2012, IEEE T AUDIO SPEECH, V20, P108, DOI 10.1109/TASL.2011.2158309
   Ming J, 2007, IEEE T AUDIO SPEECH, V15, P1711, DOI 10.1109/TASL.2007.899278
   Muda L., 2010, J COMP, V2, P138, DOI DOI 10.5815/IJIGSP.2016.09.03
   Oord A.v.d., 2016, ARXIV160903499
   Paszke A., 2017, P 31 C NEUR INF PROC, p1~4, DOI DOI 10.1017/CBO9781107707221.009
   Povey D., 2011, P IEEE WORKSH AUT SP
   REYNOLDS DA, 1995, SPEECH COMMUN, V17, P91, DOI 10.1016/0167-6393(95)00009-D
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Richardson F. S., 2016, P INTERSPEECH, P1
   Richardson F, 2015, IEEE SIGNAL PROC LET, V22, P1671, DOI 10.1109/LSP.2015.2420092
   Sadjadi S. O., 2013, SPEECH LANGUAGE PROC
   Sadjadi SO, 2013, INT CONF ACOUST SPEE, P7214, DOI 10.1109/ICASSP.2013.6639063
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Snyder D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5329, DOI 10.1109/ICASSP.2018.8461375
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Zhang ZF, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0056-7
   Zhao XJ, 2014, IEEE-ACM T AUDIO SPE, V22, P836, DOI 10.1109/TASLP.2014.2308398
NR 43
TC 6
Z9 6
U1 1
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1556-6013
EI 1556-6021
J9 IEEE T INF FOREN SEC
JI IEEE Trans. Inf. Forensic Secur.
PY 2020
VL 15
BP 1616
EP 1629
DI 10.1109/TIFS.2019.2941773
PG 14
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
SC Computer Science; Engineering
GA KF8OZ
UT WOS:000509497700006
DA 2021-02-24
ER

PT J
AU Saloranta, A
   Alku, P
   Peltola, MS
AF Saloranta, Antti
   Alku, Paavo
   Peltola, Maija S.
TI y Listen-and-repeat training improves perception of second language
   vowel duration: Evidence from mismatch negativity (MMN) and N1 responses
   and behavioral discrimination
SO INTERNATIONAL JOURNAL OF PSYCHOPHYSIOLOGY
LA English
DT Article
DE Second language acquisition; Production training; Mismatch negativity;
   Event-related potential; EEG
ID R-VERTICAL-BAR; JAPANESE LISTENERS; SPEECH-PERCEPTION; FOREIGN-LANGUAGE;
   AUDITORY-CORTEX; NATIVE SPEAKERS; SOUND; PLASTICITY; LENGTH; CONTRASTS
AB The purpose of this study was to examine the efficacy of three days of listen-and-repeat training on the perception and production of vowel duration contrasts. Generalization to an untrained vowel and a non-linguistic sound was also examined. Twelve adults underwent four sessions of listen-and-repeat training over two days with the pseudoword contrast /tite/-/ti:te/. Generalization effects were examined with another vowel contrast, /tote/-/to:te/ and a sinusoidal tone pair as a non-linguistic stimulus. Learning effects were measured with psychophysiological (EEG) event-related potentials (mismatch negativity and N1), behavioral discrimination tasks and production tasks. The results showed clear improvement in all perception measurements for the trained stimuli. The effects also affected the untrained vowel by eliciting an N1 response, and affected the behavioral perception of the non-linguistic stimuli. The MMN response for the untrained linguistic stimuli, however, did not increase. These findings suggest that the training was able to increase the sensitivity of preattentive auditory duration discrimination, but that phoneme-specific spectral information may also be needed to shape the neural representation of phoneme categories.
C1 [Saloranta, Antti; Peltola, Maija S.] Univ Turku, Dept Future Technol, Koskenniemenkatu 4, Turku 20014, Finland.
   [Saloranta, Antti; Peltola, Maija S.] Univ Turku, Phonet & Learning Age & Bilingualism Lab LAB Lab, Koskenniemenkatu 4, Turku 20014, Finland.
   [Alku, Paavo] Aalto Univ, Dept Signal Proc & Acoust, POB 12200, Aalto 00076, Finland.
RP Saloranta, A (corresponding author), Univ Turku, Dept Future Technol, Koskenniemenkatu 4, Turku 20014, Finland.
EM antti.saloranta@utu.fi; paavo.alku@aalto.fi; maija.peltola@utu.fi
RI Alku, Paavo/E-2400-2012
OI Alku, Paavo/0000-0002-8173-9418; Saloranta, Antti/0000-0002-1302-3792
FU Alfred Kordelin Foundation [150420, 170356]; Turku University Foundation
   [12314]; University of Turku; Utuling doctoral program
FX The research was supported by Alfred Kordelin Foundation (grant numbers
   150420 and 170356), Turku University Foundation (grant number 12314),
   Utuling doctoral program and the University of Turku. The Lab 100
   language lab system was provided by Sanako Corporation.
CR Alku P, 1999, CLIN NEUROPHYSIOL, V110, P1329, DOI 10.1016/S1388-2457(99)00088-7
   Atienza M, 2004, J COGNITIVE NEUROSCI, V16, P53, DOI 10.1162/089892904322755557
   Augustaitis D., 1964, DAS LITAUISCHE PHONA
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bohn O.-S., 1995, SPEECH PERCEPTION LI, P279
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P977, DOI 10.3758/BF03206911
   Brattico E, 2003, NEUROREPORT, V14, P2489, DOI 10.1097/00001756-200312190-00039
   Chandrasekaran B, 2009, EAR HEARING, V30, P552, DOI 10.1097/AUD.0b013e3181a7e1c2
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   Hirata Y, 2007, J ACOUST SOC AM, V121, P3837, DOI 10.1121/1.2734401
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Jahi K., 2015, PROCEEDINGS OF THE 1
   Khatiwada R, 2009, J INT PHON ASSOC, V39, P373, DOI 10.1017/S0025100309990181
   Kirmse U, 2008, INT J PSYCHOPHYSIOL, V67, P131, DOI 10.1016/j.ijpsycho.2007.10.012
   Kujala T, 2007, BIOL PSYCHOL, V74, P1, DOI 10.1016/j.biopsycho.2006.06.001
   Kujala T, 2010, PROG NEUROBIOL, V91, P55, DOI 10.1016/j.pneurobio.2010.01.006
   Lee W-S., 2003, J INT PHON ASSOC, V33, P109, DOI DOI 10.1017/S0025100303001208
   Liegeois-Chauvel C, 1999, CEREB CORTEX, V9, P484, DOI 10.1093/cercor/9.5.484
   Maddieson I., 1984, PATTERNS SOUNDS
   Martinez-Celdran Eugenio, 2003, J INT PHON ASSOC, V33, P255, DOI DOI 10.1017/S0025100303001373
   Menning H, 2002, LEARN MEMORY, V9, P253, DOI 10.1101/lm.49402
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Naatanen R, 1992, ATTENTION BRAIN FUNC
   Nenonen S, 2005, BRAIN LANG, V92, P26, DOI 10.1016/j.bandl.2004.05.005
   Okuno T., 2014, THESIS
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Peltola MS, 2005, NEUROSCI LETT, V388, P121, DOI 10.1016/j.neulet.2005.06.037
   Saloranta A., 2015, PROCEEDINGS OF THE 1
   Saloranta A., 2017, LINGUIST LETTICA, V25, P67
   Smith C., 1993, J INT PHON ASSOC, V23, P73, DOI DOI 10.1017/S0025100300004874
   STRANGE W, 1984, PERCEPT PSYCHOPHYS, V36, P131, DOI 10.3758/BF03202673
   Taimi L., 2014, J LANG TEACH RES, V5, P1229, DOI [10.4304/fitr.5.6.1229-1235, DOI 10.4304/JLTR.5.6.1229-1235]
   Tajima K, 2008, J ACOUST SOC AM, V123, P397, DOI 10.1121/1.2804942
   Tamminen H., 2015, PROCEEDINGS OF THE 1
   Tamminen H, 2015, INT J PSYCHOPHYSIOL, V97, P23, DOI 10.1016/j.ijpsycho.2015.04.020
   Tremblay K, 2001, EAR HEARING, V22, P79, DOI 10.1097/00003446-200104000-00001
   Tremblay K, 1998, NEUROREPORT, V9, P3557, DOI 10.1097/00001756-199811160-00003
   Tremblay K, 1997, J ACOUST SOC AM, V102, P3762, DOI 10.1121/1.420139
   Winkler I, 1999, PSYCHOPHYSIOLOGY, V36, P638, DOI 10.1017/S0048577299981908
   Yanushevskaya I, 2015, J INT PHON ASSOC, V45, P221, DOI 10.1017/S0025100314000395
   Ylinen S, 2006, BRAIN RES, V1072, P175, DOI 10.1016/j.brainres.2005.12.004
   Ylinen S, 2005, LANG SPEECH, V48, P313, DOI 10.1177/00238309050480030401
   Ylinen S, 2005, NEUROREPORT, V16, P1857, DOI 10.1097/01.wnr.0000185959.11465.9b
NR 46
TC 0
Z9 0
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8760
EI 1872-7697
J9 INT J PSYCHOPHYSIOL
JI Int. J. Psychophysiol.
PD JAN
PY 2020
VL 147
BP 72
EP 82
DI 10.1016/j.ijpsycho.2019.11.005
PG 11
WC Psychology, Biological; Neurosciences; Physiology; Psychology;
   Psychology, Experimental
SC Psychology; Neurosciences & Neurology; Physiology
GA KK0XD
UT WOS:000512473800008
PM 31743699
DA 2021-02-24
ER

PT J
AU Charbonneau, G
   Bertone, A
   Veronneau, M
   Girard, S
   Pelland, M
   Mottron, L
   Lepore, F
   Collignon, O
AF Charbonneau, Genevieve
   Bertone, Armando
   Veronneau, Marie
   Girard, Simon
   Pelland, Maxime
   Mottron, Laurent
   Lepore, Franco
   Collignon, Olivier
TI Within- and Cross-Modal Integration and Attention in the Autism Spectrum
SO JOURNAL OF AUTISM AND DEVELOPMENTAL DISORDERS
LA English
DT Article
DE Autism spectrum; Sensory integration; Visual; Tactile
ID VISUAL-TACTILE INTERACTIONS; MULTISENSORY INTEGRATION; UNISENSORY
   INTEGRATION; SPEECH-PERCEPTION; YOUNG-CHILDREN; REACTION-TIME;
   FACILITATION; ABNORMALITIES; EXPRESSIONS; EXPERIENCE
AB Although impairment in sensory integration is suggested in the autism spectrum (AS), empirical evidences remain equivocal. We assessed the integration of low-level visual and tactile information within and across modalities in AS and typically developing (TD) individuals. TD individuals demonstrated increased redundancy gain for cross-modal relative to double tactile or visual stimulation, while AS individuals showed similar redundancy gain between cross-modal and double tactile conditions. We further observed that violation of the race model inequality for cross-modal conditions was observed over a wider proportion of the reaction times distribution in TD than AS individuals. Importantly, the reduced cross-modal integration in AS individuals was not related to atypical attentional shift between modalities. We conclude that AS individuals displays selective decrease of cross-modal integration of low-level information.
C1 [Charbonneau, Genevieve; Veronneau, Marie; Girard, Simon; Pelland, Maxime; Lepore, Franco] Univ Montreal, Ctr Rech Neuropsychol & Cognit CERNEC, Dept Psychol, Montreal, PQ, Canada.
   [Bertone, Armando] McGill Univ, Dept Educ & Counselling Psychol, Sch Appl Child Psychol, Montreal, PQ, Canada.
   [Bertone, Armando] Perceptual Neurosci Lab Autism & Dev PNLab, Montreal, PQ, Canada.
   [Mottron, Laurent] CETEDUM, Rivieres Des Prairies Hosp, Montreal, PQ, Canada.
   [Collignon, Olivier] Univ Louvain, Inst Psychol IPSY, Louvain La Neuve, Belgium.
   [Collignon, Olivier] Univ Louvain, Inst Neurosci IoNS, Louvain La Neuve, Belgium.
   [Collignon, Olivier] Univ Trento, Ctr Mind Brain Sci CIMeC, Mattarello, Italy.
   [Veronneau, Marie] Univ Quebec Montreal, Montreal, PQ, Canada.
   [Pelland, Maxime] Acadia Univ, Dept Psychol, Wolfville, NS, Canada.
RP Collignon, O (corresponding author), Univ Louvain, Inst Psychol IPSY, Louvain La Neuve, Belgium.; Collignon, O (corresponding author), Univ Louvain, Inst Neurosci IoNS, Louvain La Neuve, Belgium.; Collignon, O (corresponding author), Univ Trento, Ctr Mind Brain Sci CIMeC, Mattarello, Italy.
EM olivier.collignon@uclouvain.be
OI Pelland, Maxime/0000-0002-8620-6784
FU Supported by William Dawson Scholar [101012] Funding Source: Medline
CR Adolphs Ralph, 2002, Behav Cogn Neurosci Rev, V1, P21, DOI 10.1177/1534582302001001003
   Alvarado JC, 2007, J NEUROSCI, V27, P12775, DOI 10.1523/JNEUROSCI.3524-07.2007
   Alvarado JC, 2007, J NEUROPHYSIOL, V97, P3193, DOI 10.1152/jn.00018.2007
   Alvarado JC, 2008, BRAIN RES, V1242, P13, DOI 10.1016/j.brainres.2008.03.074
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   American Psychiatric Association, 2000, DIAGN STAT MAN MENT, V4th
   Badzakova-Trajkov G, 2005, NEUROPSYCHOLOGIA, V43, P473, DOI 10.1016/j.neuropsychologia.2004.06.016
   Bahrick LE, 2010, BLACKWELL HDB INFANT
   Bahrick LE, 2011, FRONTIERS NEURAL BAS
   Baum SH, 2015, PROG NEUROBIOL, V134, P140, DOI 10.1016/j.pneurobio.2015.09.007
   Bebko JM, 2006, J CHILD PSYCHOL PSYC, V47, P88, DOI 10.1111/j.1469-7610.2005.01443.x
   Behrmann M, 2006, TRENDS COGN SCI, V10, P258, DOI 10.1016/j.tics.2006.05.001
   Bonneh YS, 2008, COGN NEUROPSYCHOL, V25, P635, DOI 10.1080/02643290802106415
   Botvinick M, 2004, SCIENCE, V305, P782, DOI 10.1126/science.1101836
   Brandwein AB, 2015, J AUTISM DEV DISORD, V45, P230, DOI 10.1007/s10803-014-2212-9
   Brandwein AB, 2013, CEREB CORTEX, V23, P1329, DOI 10.1093/cercor/bhs109
   Brock J, 2002, DEV PSYCHOPATHOL, V14, P209, DOI 10.1017/S0954579402002018
   Cascio CJ, 2016, AUTISM RES, V9, P920, DOI 10.1002/aur.1612
   Cascio CJ, 2016, J AUTISM DEV DISORD, V46, P1528, DOI 10.1007/s10803-013-1961-1
   Cascio CJ, 2012, AUTISM, V16, P406, DOI 10.1177/1362361311430404
   Charbonneau G, 2013, J VISION, V13, DOI 10.1167/13.12.20
   Charbonneau G, 2013, NEUROPSYCHOLOGIA, V51, P1002, DOI 10.1016/j.neuropsychologia.2013.02.009
   Collignon O, 2013, CORTEX, V49, P1704, DOI 10.1016/j.cortex.2012.06.001
   Corballis MC, 1998, BRAIN, V121, P1795, DOI 10.1093/brain/121.9.1795
   COURCHESNE E, 1994, BEHAV NEUROSCI, V108, P848, DOI 10.1037/0735-7044.108.5.848
   Dakin S, 2005, NEURON, V48, P497, DOI 10.1016/j.neuron.2005.10.018
   Dawson G, 2004, DEVELOPMENTAL SCI, V7, P340, DOI 10.1111/j.1467-7687.2004.00352.x
   de Boer-Schellekens L, 2013, NEUROPSYCHOLOGIA, V51, P3004, DOI 10.1016/j.neuropsychologia.2013.10.005
   de Heering A, 2016, CURR BIOL, V26, P3101, DOI 10.1016/j.cub.2016.10.014
   Dunbar RIM, 2010, NEUROSCI BIOBEHAV R, V34, P260, DOI 10.1016/j.neubiorev.2008.07.001
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Field T, 2001, TOUCH
   Forster B, 2002, EXP BRAIN RES, V143, P480, DOI 10.1007/s00221-002-1017-9
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   Foxe JJ, 2015, CEREB CORTEX, V25, P298, DOI 10.1093/cercor/bht213
   FRITH U, 1994, COGNITION, V50, P115, DOI 10.1016/0010-0277(94)90024-8
   Gingras G, 2009, J NEUROSCI, V29, P4897, DOI 10.1523/JNEUROSCI.4120-08.2009
   Girard S, 2013, EXP BRAIN RES, V224, P275, DOI 10.1007/s00221-012-3308-0
   Girard S, 2011, EXP BRAIN RES, V214, P1, DOI 10.1007/s00221-010-2515-9
   Gondan M, 2004, PSYCHON B REV, V11, P307, DOI 10.3758/BF03196575
   Greenfield K, 2015, MOL AUTISM, V6, DOI 10.1186/s13229-015-0045-9
   Harrar V, 2014, CURR BIOL, V24, P531, DOI 10.1016/j.cub.2014.01.029
   HERSHENSON M, 1962, J EXP PSYCHOL, V63, P289, DOI 10.1037/h0039516
   Hertenstein MJ, 2006, EMOTION, V6, P528, DOI 10.1037/1528-3542.6.3.528
   Hertenstein MJ, 2002, HUM DEV, V45, P70, DOI 10.1159/000048154
   Iarocci G, 2006, J AUTISM DEV DISORD, V36, P77, DOI 10.1007/s10803-005-0044-3
   Iarocci G, 2004, J AUTISM DEV DISORD, V34, P257, DOI 10.1023/B:JADD.0000029548.84041.69
   Khan S, 2015, BRAIN, V138, P1394, DOI 10.1093/brain/awv043
   Kwakye LD, 2011, FRONT INTEGR NEUROSC, V4, DOI 10.3389/fnint.2010.00129
   Landry R, 2004, J CHILD PSYCHOL PSYC, V45, P1115, DOI 10.1111/j.1469-7610.2004.00304.x
   Laurienti PJ, 2006, NEUROBIOL AGING, V27, P1155, DOI 10.1016/j.neurobiolaging.2005.05.024
   Leekam SR, 2000, DEV PSYCHOL, V36, P261, DOI 10.1037/0012-1649.36.2.261
   Lord C, 2000, J AUTISM DEV DISORD, V30, P205, DOI 10.1023/A:1005592401947
   LORD C, 1994, J AUTISM DEV DISORD, V24, P659, DOI 10.1007/BF02172145
   Magnee MJCM, 2008, J CHILD PSYCHOL PSYC, V49, P995, DOI 10.1111/j.1469-7610.2008.01902.x
   Maitre NL, 2017, CURR BIOL, V27, P1048, DOI 10.1016/j.cub.2017.02.036
   Marco EJ, 2011, PEDIATR RES, V69, p48R, DOI [10.1203/PDR.0b013e3182130c54, 10.1109/SPL.2011.5782616]
   Miles E, 2011, Q J EXP PSYCHOL, V64, P871, DOI 10.1080/17470218.2010.514054
   MILLER J, 1986, PERCEPT PSYCHOPHYS, V40, P331, DOI 10.3758/BF03203025
   MILLER J, 1982, COGNITIVE PSYCHOL, V14, P247, DOI 10.1016/0010-0285(82)90010-X
   Miniussi C, 1998, J COGNITIVE NEUROSCI, V10, P216, DOI 10.1162/089892998562663
   Mongillo EA, 2008, J AUTISM DEV DISORD, V38, P1349, DOI 10.1007/s10803-007-0521-y
   Mottron L, 2006, J AUTISM DEV DISORD, V36, P1, DOI 10.1007/s10803-005-0048-z
   Murray MM, 2001, NEUROPSYCHOLOGIA, V39, P828, DOI 10.1016/S0028-3932(01)00004-5
   MYERS BJ, 1984, DEV REV, V4, P240, DOI 10.1016/S0273-2297(84)80007-6
   Noel JP, 2018, IEEE T COGN DEV SYST, V10, P973, DOI 10.1109/TCDS.2017.2778141
   Noel JP, 2018, EUR J NEUROSCI, V47, P1230, DOI 10.1111/ejn.13911
   Noel JP, 2018, AUTISM RES, V11, P194, DOI 10.1002/aur.1880
   Noel JP, 2017, AUTISM RES, V10, P121, DOI 10.1002/aur.1633
   Occelli V, 2013, RES AUTISM SPECT DIS, V7, P517, DOI 10.1016/j.rasd.2012.12.003
   ONeill M, 1997, J AUTISM DEV DISORD, V27, P283, DOI 10.1023/A:1025850431170
   Otto TU, 2012, CURR BIOL, V22, P1391, DOI 10.1016/j.cub.2012.05.031
   Paton B, 2012, J AUTISM DEV DISORD, V42, P1870, DOI 10.1007/s10803-011-1430-7
   Poole D, 2018, J EXP PSYCHOL GEN, V147, P1309, DOI 10.1037/xge0000425
   Poole D, 2015, J AUTISM DEV DISORD, V45, P3316, DOI 10.1007/s10803-015-2492-8
   Powers AR, 2016, SCI REP-UK, V6, DOI 10.1038/srep23374
   Powers AR, 2012, J NEUROSCI, V32, P6263, DOI 10.1523/JNEUROSCI.6138-11.2012
   Puts NAJ, 2017, AUTISM RES, V10, P608, DOI 10.1002/aur.1691
   RAAB DH, 1962, T NEW YORK ACAD SCI, V24, P574, DOI 10.1111/j.2164-0947.1962.tb01433.x
   Renner P, 2006, CHILD NEUROPSYCHOL, V12, P361, DOI 10.1080/09297040600770753
   REUTERLORENZ PA, 1995, J EXP PSYCHOL HUMAN, V21, P211, DOI 10.1037/0096-1523.21.2.211
   Rogers SJ, 2003, J AUTISM DEV DISORD, V33, P631, DOI 10.1023/B:JADD.0000006000.38991.a7
   Schutz-Bosbach S, 2009, CONSCIOUS COGN, V18, P2, DOI 10.1016/j.concog.2008.08.003
   Schutz-Bosbach S, 2006, CURR BIOL, V16, P1830, DOI 10.1016/j.cub.2006.07.048
   Senju A, 2004, J CHILD PSYCHOL PSYC, V45, P445, DOI 10.1111/j.1469-7610.2004.00236.x
   Shams L, 2000, NATURE, V408, P788, DOI 10.1038/35048669
   Simon DM, 2016, NEUROSCI BIOBEHAV R, V68, P848, DOI 10.1016/j.neubiorev.2016.07.016
   Spence C, 2001, PERCEPT PSYCHOPHYS, V63, P330, DOI 10.3758/BF03194473
   Stein B. E., 1993, MERGING SENSES
   Stein BE, 2014, NAT REV NEUROSCI, V15, P520, DOI 10.1038/nrn3742
   Stevenson RA, 2018, AUTISM, V22, P609, DOI 10.1177/1362361317704413
   Stevenson RA, 2016, AUTISM RES, V9, P720, DOI 10.1002/aur.1566
   Stevenson RA, 2014, J AUTISM DEV DISORD, V44, P1470, DOI 10.1007/s10803-013-1992-7
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Tavassoli T, 2016, AUTISM RES, V9, P616, DOI 10.1002/aur.1563
   Taylor N, 2010, J AUTISM DEV DISORD, V40, P1403, DOI 10.1007/s10803-010-1000-4
   Thye MD, 2018, DEV COGN NEUROS-NETH, V29, P151, DOI 10.1016/j.dcn.2017.04.010
   Todd JW, 1912, ARCH PSYCHOL, V3, P1
   Tomchek SD, 2007, AM J OCCUP THER, V61, P190, DOI 10.5014/ajot.61.2.190
   Townsend JT, 1978, COGNITIVE THEORY
   Ulrich R, 2007, BEHAV RES METHODS, V39, P291, DOI 10.3758/BF03193160
   van Atteveldt N, 2014, NEURON, V81, P1240, DOI 10.1016/j.neuron.2014.02.044
   WAINWRIGHTSHARP JA, 1993, J AUTISM DEV DISORD, V23, P1, DOI 10.1007/BF01066415
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   Williams DL, 2013, J AUTISM DEV DISORD, V43, P794, DOI 10.1007/s10803-012-1618-5
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
NR 106
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER/PLENUM PUBLISHERS
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0162-3257
EI 1573-3432
J9 J AUTISM DEV DISORD
JI J. Autism Dev. Disord.
PD JAN
PY 2020
VL 50
IS 1
BP 87
EP 100
DI 10.1007/s10803-019-04221-8
PG 14
WC Psychology, Developmental
SC Psychology
GA KJ4BP
UT WOS:000512003400008
PM 31538259
OA Green Published
DA 2021-02-24
ER

PT J
AU You, S
   Han, W
   Kim, S
   Maeng, S
   Seo, YJ
AF You, Sunghwa
   Han, Woojae
   Kim, Saea
   Maeng, Sanga
   Seo, Young Joon
TI Reliability and Validity of Self-Screening Tool for Hearing Loss in
   Older Adults
SO CLINICAL INTERVENTIONS IN AGING
LA English
DT Article
DE hearing screening; self-assessment; questionnaire; age-related hearing
   loss; older adults
ID SPEECH-PERCEPTION; AID; AGE
AB Objective: The present study aimed to identify the reliability and validity of a screening tool for the elderly who wish to check their level of hearing loss by themselves.
   Design: A total of 170 older adults with different hearing levels participated. The Self-Assessment for Hearing Screening of the Elderly-Revised (SHSE-R) consisted of 20 questions measured on a 5-point scale and developed in terms of characteristics of age-related hearing loss. For reliability, the subjects responded to SHSE-R twice with a three-week interval. They also took various subjective and objective hearing tests and a working memory test and filled out two other questionnaires for validation.
   Results: SHSE-R showed a high internal consistency and a high reliability when comparing test-retest scores. Its content validity was as high as 0.88-1. Convergent validity supported SHSE-R and its subcategories while showing either a positive or negative correlation with pure-tone average, word recognition scores, and otoacoustic emission tests. Construct validity was proved by a moderate negative correlation with the tests of speech in noise, speech with fast speed, and working memory. In criterion validity, a strong positive correlation existed between SHSE-R and the other questionnaires, except for a group with severe hearing loss. The factor analysis showed similar results to the original version of SHSE having three factors, although some items were interchanged.
   Conclusion: We confirmed that SHSE-R was well developed with both excellent internal consistency and test-retest reliability and valuable convergent, construct, and criterion validities, consequently making SHSE-R useful for self-checking hearing loss in the elderly.
C1 [You, Sunghwa; Han, Woojae; Kim, Saea] Hallym Univ, Coll Nat Sci, Lab Hearing & Technol, Chunchon, South Korea.
   [You, Sunghwa; Han, Woojae; Kim, Saea] Hallym Univ, Coll Nat Sci, Div Speech Pathol & Audiol, Chunchon, South Korea.
   [Han, Woojae] Hallym Univ, Coll Nat Sci, Res Inst Audiol & Speech Pathol, Chunchon, South Korea.
   [Maeng, Sanga; Seo, Young Joon] Yonsei Univ, Dept Otorhinolaryngol, Wonju Coll Med, Wonju, South Korea.
RP Han, W (corresponding author), 8603 Nat Sci Bd,1 Hallymdaehak Gil, Chunchon 24252, South Korea.
EM woojaehan@hallym.ac.kr
OI Han, Woojae/0000-0003-1623-9676
FU Hallym University Research Fund [HRF-201810-009]
FX This work was supported by Hallym University Research Fund
   (HRF-201810-009).
CR Arehart KH, 2013, EAR HEARING, V34, P251, DOI 10.1097/AUD.0b013e318271aa5e
   Davis A, 2003, INT J AUDIOL, V42, pS39
   DeVellis RF, 1991, APPL SOCIAL RES METH, V26
   HELFER KS, 1990, J SPEECH HEAR RES, V33, P149, DOI 10.1044/jshr.3301.149
   Jang H.S., 2008, KOR ACAD AUDIOL, V4, P161
   Kang Yeonwook, 2006, [Korean Journal of Psychology: General, 한국심리학회지:일반], V25, P1
   Kim G, 2016, CLIN INTERV AGING, V11, P787, DOI 10.2147/CIA.S107102
   KIM JS, 2000, KOREAN J SPEECH SCI, V7, P37
   Ku H., 2000, KOREAN J COMMUNICATI, V5, P1
   Li-Korotky HS, 2012, GERONTOLOGIST, V52, P265, DOI 10.1093/geront/gnr159
   Lim Ku Ho, 2010, Audiology and Speech Research, V6, P128
   Liu XZ, 2007, J PATHOL, V211, P188, DOI 10.1002/path.2102
   LYNN MR, 1986, NURS RES, V35, P382
   Nastase AS, 2015, DERIVE RMS VALUE PUL
   Pichora-Fuller M Kathleen, 2006, Trends Amplif, V10, P29, DOI 10.1177/108471380601000103
   Polit D., 1999, NURSING RES PRINCIPL
   Smith SL, 2011, INT J AUDIOL, V50, P417, DOI 10.3109/14992027.2011.553205
   You S, 2019, J AUDIOL OTOL
   Yu J, 2017, GERIATR GERONTOL INT, V17, P61, DOI 10.1111/ggi.12678
NR 19
TC 1
Z9 1
U1 0
U2 2
PU DOVE MEDICAL PRESS LTD
PI ALBANY
PA PO BOX 300-008, ALBANY, AUCKLAND 0752, NEW ZEALAND
EI 1178-1998
J9 CLIN INTERV AGING
JI Clin. Interv. Aging
PY 2020
VL 15
BP 75
EP 82
DI 10.2147/CIA.S238053
PG 8
WC Geriatrics & Gerontology
SC Geriatrics & Gerontology
GA KI1NH
UT WOS:000511114200001
PM 32021135
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT S
AU Kidd, E
   Donnelly, S
AF Kidd, Evan
   Donnelly, Seamus
BE Liberman, M
   Partee, BH
TI Individual Differences in First Language Acquisition
SO ANNUAL REVIEW OF LINGUISTICS, VOL 6
SE Annual Review of Linguistics
LA English
DT Article; Book Chapter
DE individual differences; first language acquisition; input; speech;
   vocabulary; grammar
ID CHILD-DIRECTED SPEECH; EARLY VOCABULARY DEVELOPMENT;
   SOCIOECONOMIC-STATUS; NONWORD-REPETITION; EXECUTIVE FUNCTION; WORD
   RECOGNITION; WORKING-MEMORY; PROCESSING EFFICIENCY; SYNTACTIC
   DEVELOPMENT; MOTHERS SPEECH
AB Humans vary in almost every dimension imaginable, and language is no exception. In this article, we review the past research that has focused on individual differences (IDs) in first language acquisition. We first consider how different theoretical traditions in language acquisition treat IDs, and we argue that a focus on IDs is important given its potential to reveal the developmental dynamics and architectural constraints of the linguistic system. We then review IDs research that has examined variation in children's linguistic input, early speech perception, and vocabulary and grammatical development. In each case, we observe systematic and meaningful variation, such that variation in one domain (e.g., early auditory and speech processing) has meaningful developmental consequences for development in higher-order domains (e.g., vocabulary). The research suggests a high degree of integration across the linguistic system, in which development across multiple linguistic domains is tightly coupled.
C1 [Kidd, Evan] Max Planck Inst Psycholinguist, NL-6500 AH Nijmegen, Netherlands.
   [Kidd, Evan; Donnelly, Seamus] Australian Natl Univ, Res Sch Psychol, Canberra, ACT 2601, Australia.
   [Kidd, Evan; Donnelly, Seamus] Australian Res Council Ctr Excellence Dynam Langu, Acton 2601, Australia.
RP Kidd, E (corresponding author), Max Planck Inst Psycholinguist, NL-6500 AH Nijmegen, Netherlands.; Kidd, E (corresponding author), Australian Natl Univ, Res Sch Psychol, Canberra, ACT 2601, Australia.; Kidd, E (corresponding author), Australian Res Council Ctr Excellence Dynam Langu, Acton 2601, Australia.
EM evan.kidd@mpi.nl
FU Australian Research CouncilAustralian Research Council [CE140100041]
FX Preparation of this manuscript was supported by the Australian Research
   Council (CE140100041).
CR ACREDOLO L, 1988, CHILD DEV, V59, P450, DOI 10.1111/j.1467-8624.1988.tb01480.x
   Arciuli J, 2018, CURR DIR PSYCHOL SCI, V27, P492, DOI 10.1177/0963721418779977
   Bartlema A, 2014, J MATH PSYCHOL, V59, P132, DOI 10.1016/j.jmp.2013.12.002
   Bates E, 1997, LANG COGNITIVE PROC, V12, P507
   Bates E., 1979, EMERGENCE SYMBOLS CO
   Bates E, 1988, 1 WORDS GRAMMAR INDI
   Bates E., 1995, HDB CHILD LANGUAGE, P96
   Bavin EL, 2008, J CHILD LANG, V35, P687, DOI 10.1017/S0305000908008726
   BELMONT L, 1973, SCIENCE, V182, P1096, DOI 10.1126/science.182.4117.1096
   Benasich AA, 2002, BEHAV BRAIN RES, V136, P31, DOI 10.1016/S0166-4328(02)00098-0
   Benasich AA, 2008, BEHAV BRAIN RES, V195, P215, DOI 10.1016/j.bbr.2008.08.049
   Bergelson E, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12724
   Bornstein MH, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aat7422
   Bornstein MH, 2016, DEV PSYCHOL, V52, P704, DOI 10.1037/dev0000111
   Bornstein MH, 2004, J CHILD LANG, V31, P855, DOI 10.1017/S0305000904006518
   Borsboom D, 2006, PSYCHOMETRIKA, V71, P425, DOI 10.1007/s11336-006-1447-6
   Borsboom D, 2009, DYNAMICS PROCESS METHODOLOGY IN THE SOCIAL AND DEVELOPMENTAL SCIENCES, P67, DOI 10.1007/978-0-387-95922-1_4
   Bouchard TJ, 2013, TWIN RES HUM GENET, V16, P923, DOI 10.1017/thg.2013.54
   Boyle W, 2013, LANG LEARN, V63, P211, DOI 10.1111/lang.12003
   Brichmann EI, 2018, DEVELOPMENTAL SCI, V22
   Brito NH, 2016, DEV COGN NEUROS-NETH, V19, P144, DOI 10.1016/j.dcn.2016.03.004
   Bruner J. S., 1983, CHILDRENS TALK LEARN
   Carlson SM, 2005, PSYCHOL SCI, V16, P609, DOI 10.1111/j.1467-9280.2005.01583.x
   Carpenter M, 1998, MONOGR SOC RES CHILD, V63, pV
   Cartmill EA, 2013, P NATL ACAD SCI USA, V110, P11278, DOI 10.1073/pnas.1309518110
   Chomsky N., 1986, KNOWLEDGE LANGUAGE I
   Chomsky N., 1980, LANGUAGE LEARNING DE, P35
   Chonchaiya W, 2013, DEVELOPMENTAL SCI, V16, P159, DOI 10.1111/desc.12012
   Choudhury N, 2011, CLIN NEUROPHYSIOL, V122, P320, DOI 10.1016/j.clinph.2010.05.035
   Colom R, 2009, INTELLIGENCE, V37, P124, DOI 10.1016/j.intell.2008.07.007
   Colonnesi C, 2010, DEV REV, V30, P352, DOI 10.1016/j.dr.2010.10.001
   Conboy BT, 2008, DEV PSYCHOL, V44, P1505, DOI 10.1037/a0012975
   COOPER RP, 1990, CHILD DEV, V61, P1584, DOI 10.1111/j.1467-8624.1990.tb02885.x
   Crain S., 2012, EMERGENCE MEANING
   Crain Stephen, 1998, INVESTIGATIONS UNIVE
   Cristia A., 2018, OSF PREPR, DOI [10.31219/OSF.IO/8PNHR, DOI 10.31219/0SF.I0/8PNHR]
   Cristia A, 2019, CHILD DEV, V90, P759, DOI 10.1111/cdev.12974
   Cristia A, 2014, CHILD DEV, V85, P1330, DOI 10.1111/cdev.12193
   CRONBACH LJ, 1957, AM PSYCHOL, V12, P671, DOI 10.1037/h0043943
   Dabrowska E, 2012, LINGUIST APPROACH BI, V2, P219, DOI 10.1075/lab.2.3.01dab
   Dale PS, 2015, J COMMUN DISORD, V57, P106, DOI 10.1016/j.jcomdis.2015.07.004
   Dale PS, 2000, J CHILD LANG, V27, P619, DOI 10.1017/S0305000900004281
   Darwin C., 1859, ORIGIN SPECIES
   de Abreu PMJE, 2012, J EDUC PSYCHOL, V104, P974, DOI 10.1037/a0028390
   DEBOYSSONBARDIES B, 1991, LANGUAGE, V67, P297, DOI 10.2307/415108
   DePaolis RA, 2011, INFANT BEHAV DEV, V34, P590, DOI 10.1016/j.infbeh.2011.06.005
   Dionne G, 2003, CHILD DEV, V74, P394, DOI 10.1111/1467-8624.7402005
   Dixon JA, 2007, CHILD DEV, V78, P190, DOI 10.1111/j.1467-8624.2007.00992.x
   Dollaghan CA, 1999, J SPEECH LANG HEAR R, V42, P1432, DOI 10.1044/jslhr.4206.1432
   ESTES WK, 1956, PSYCHOL BULL, V53, P134, DOI 10.1037/h0045156
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   Fenson Larry, 1994, Monographs of the Society for Research in Child Development, V59, P1
   Fernald A, 2006, DEV PSYCHOL, V42, P98, DOI 10.1037/0012-1649.42.1.98
   Filova B, 2013, CELLS TISSUES ORGANS, V197, P169, DOI 10.1159/000345567
   Frank MC, 2019, VARIABILITY CONSISTE
   Friederici AD, 2008, NEUROREPORT, V19, P283, DOI 10.1097/WNR.0b013e3282f5105a
   Friedman NP, 2008, J EXP PSYCHOL GEN, V137, P201, DOI 10.1037/0096-3445.137.2.201
   FURROW D, 1979, J CHILD LANG, V6, P423, DOI 10.1017/S0305000900002464
   Ganger J, 2004, DEV PSYCHOL, V40, P621, DOI 10.1037/0012-1649.40.4.621
   Garcia-Sierra A, 2016, INT J PSYCHOPHYSIOL, V110, P1, DOI 10.1016/j.ijpsycho.2016.10.004
   GATHERCOLE SE, 1992, DEV PSYCHOL, V28, P887, DOI 10.1037//0012-1649.28.5.887
   Gathercole SE, 2006, APPL PSYCHOLINGUIST, V27, P513, DOI 10.1017/S0142716406060383
   Gilkerson J, 2017, AM J SPEECH-LANG PAT, V26, P248, DOI 10.1044/2016_AJSLP-15-0169
   Gleitman Lelia, 1990, LANG ACQUIS, V1, P3, DOI DOI 10.1207/S15327817LA0101_2
   Golinkoff RM, 2015, CURR DIR PSYCHOL SCI, V24, P339, DOI 10.1177/0963721415595345
   Gooch D, 2016, J CHILD PSYCHOL PSYC, V57, P180, DOI 10.1111/jcpp.12458
   Goswami U, 2018, CURR DIR PSYCHOL SCI, V27, P56, DOI 10.1177/0963721417727520
   Hale M., 2008, PHONOLOGICAL ENTERPR
   Hamrick P, 2018, P NATL ACAD SCI USA, V115, P1487, DOI 10.1073/pnas.1713975115
   Hanlon HW, 1999, DEV NEUROPSYCHOL, V16, P479, DOI 10.1207/S15326942DN1603_27
   Hart B., 1995, MEANINGFUL DIFFERENC
   Hayiou-Thomas ME, 2006, J CHILD LANG, V33, P339, DOI 10.1017/S0305000906007331
   Hayiou-Thomas ME, 2012, DEVELOPMENTAL SCI, V15, P233, DOI 10.1111/j.1467-7687.2011.01119.x
   Hedge C, 2018, BEHAV RES METHODS, V50, P1166, DOI 10.3758/s13428-017-0935-1
   Henrich J, 2010, BEHAV BRAIN SCI, V33, P111, DOI 10.1017/S0140525X10000725
   Hirsh-Pasek K, 2015, PSYCHOL SCI, V26, P1071, DOI 10.1177/0956797615581493
   Hoareau M, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12803
   Hoff E, 2003, CHILD DEV, V74, P1368, DOI 10.1111/1467-8624.00612
   Hoff E, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12536
   Hoff-Ginsberg E, 1998, APPL PSYCHOLINGUIST, V19, P603, DOI 10.1017/S0142716400010389
   Huang YT, 2017, COGNITION, V159, P61, DOI 10.1016/j.cognition.2016.11.004
   Hurtado N, 2008, DEVELOPMENTAL SCI, V11, pF31, DOI 10.1111/j.1467-7687.2008.00768.x
   HUTTENLOCHER J, 1991, DEV PSYCHOL, V27, P236, DOI 10.1037/0012-1649.27.2.236
   Huttenlocher J, 2002, COGNITIVE PSYCHOL, V45, P337, DOI 10.1016/S0010-0285(02)00500-5
   Huttenlocher J, 2007, DEV PSYCHOL, V43, P1062, DOI 10.1037/0012-1649.43.5.1062
   Huttenlocher J, 2010, COGNITIVE PSYCHOL, V61, P343, DOI 10.1016/j.cogpsych.2010.08.002
   Iverson JM, 1999, COGNITIVE DEV, V14, P57, DOI 10.1016/S0885-2014(99)80018-5
   Iverson JM, 2005, PSYCHOL SCI, V16, P367, DOI 10.1111/j.0956-7976.2005.01542.x
   Jarrold C, 2006, NEUROSCIENCE, V139, P39, DOI 10.1016/j.neuroscience.2005.07.002
   Jones G, 2007, DEVELOPMENTAL SCI, V10, P853, DOI 10.1111/j.1467-7687.2007.00638.x
   Junge C, 2014, BRAIN SCI, V4, P532, DOI 10.3390/brainsci4040532
   JUSCZYK P. W., 1997, DISCOVERY SPOKEN LAN
   Justice LM, 2019, MATERN CHILD HLTH J, V23, P971, DOI 10.1007/s10995-018-02726-9
   Kaufman SB, 2010, COGNITION, V116, P321, DOI 10.1016/j.cognition.2010.05.011
   Khanna MM, 2010, Q J EXP PSYCHOL, V63, P160, DOI 10.1080/17470210902866664
   Kidd E, 2018, INFANCY, V23, P770, DOI 10.1111/infa.12256
   Kidd E, 2018, TRENDS COGN SCI, V22, P154, DOI 10.1016/j.tics.2017.11.006
   Kidd E, 2016, CHILD DEV, V87, P184, DOI 10.1111/cdev.12461
   Kidd E, 2013, TOP LANG DISORD, V33, P208, DOI 10.1097/TLD.0b013e31829d623e
   Kooijman V, 2005, COGNITIVE BRAIN RES, V24, P109, DOI 10.1016/j.cogbrainres.2004.12.009
   Kooijman V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00025
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhn LJ, 2014, CHILD DEV, V85, P1898, DOI 10.1111/cdev.12249
   Lany J, 2018, INFANCY, V23, P342, DOI 10.1111/infa.12228
   Lany J, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12569
   Lany J, 2014, CHILD DEV, V85, P1727, DOI 10.1111/cdev.12199
   LIEVEN EVM, 1992, J CHILD LANG, V19, P287, DOI 10.1017/S0305000900011429
   Lieven EVM., 1994, CROSSLINGUISTIC STUD, V5, P219
   Lieven EVM., 2009, LANG COGN, V8, P346
   Liu HM, 2003, DEVELOPMENTAL SCI, V6, pF1, DOI 10.1111/1467-7687.00275
   Mabbott DJ, 2006, NEUROIMAGE, V33, P936, DOI 10.1016/j.neuroimage.2006.07.024
   MacDonald MC, 2002, PSYCHOL REV, V109, P35, DOI 10.1037//0033-295X.109.1.35
   MacWhinney B, 1998, ANNU REV PSYCHOL, V49, P199, DOI 10.1146/annurev.psych.49.1.199
   Marchman VA, 2008, DEVELOPMENTAL SCI, V11, pF9, DOI 10.1111/j.1467-7687.2008.00671.x
   Mayor J, 2014, DEVELOPMENTAL SCI, V17, P412, DOI 10.1111/desc.12130
   Melby-Lervag M, 2012, PSYCHOL SCI, V23, P1092, DOI 10.1177/0956797612443833
   Meyer L, 2018, EUR J NEUROSCI, V48, P2609, DOI 10.1111/ejn.13748
   MOLFESE DL, 1985, INFANT BEHAV DEV, V8, P197, DOI 10.1016/S0163-6383(85)80006-0
   Molfese DL, 1997, DEV NEUROPSYCHOL, V13, P135, DOI 10.1080/87565649709540674
   Mollon JD, 2017, VISION RES, V141, P4, DOI 10.1016/j.visres.2017.11.001
   Morgan PL, 2015, CHILD DEV, V86, P1351, DOI 10.1111/cdev.12398
   Naigles LR, 1998, J CHILD LANG, V25, P95, DOI 10.1017/S0305000997003358
   NELSON K, 1973, MONOGR SOC RES CHILD, V149, P1
   Newman R, 2006, DEV PSYCHOL, V42, P643, DOI 10.1037/0012-1649.42.4.643
   Newman RS, 2016, J CHILD LANG, V43, P1158, DOI 10.1017/S0305000915000446
   Nunez MD, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00018
   O'Grady W., 2005, SYNTACTIC CARPENTRY
   PAYNE AC, 1994, EARLY CHILD RES Q, V9, P427, DOI 10.1016/0885-2006(94)90018-3
   PLUNKETT K, 1993, COGNITION, V48, P21, DOI 10.1016/0010-0277(93)90057-3
   Puglisi ML, 2017, SCI STUD READ, V21, P498, DOI 10.1080/10888438.2017.1346660
   Quinn S, 2018, DEV REV, V49, P121, DOI 10.1016/j.dr.2018.05.005
   Reber AS, 1993, IMPLICIT LEARNING TA
   Romeo RR, 2018, PSYCHOL SCI, V29, P700, DOI 10.1177/0956797617742725
   Rowe ML, 2008, J CHILD LANG, V35, P185, DOI 10.1017/S0305000907008343
   Rowe ML, 2012, CHILD DEV, V83, P1762, DOI 10.1111/j.1467-8624.2012.01805.x
   Rowe ML, 2012, CHILD DEV, V83, P508, DOI 10.1111/j.1467-8624.2011.01710.x
   Rowe Meredith L, 2008, First Lang, V28, P182
   Rowe ML, 2009, SCIENCE, V323, P951, DOI 10.1126/science.1167025
   Rowe ML, 2018, DEVELOPMENTAL SCI, V22
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Samuelsson S, 2005, J EDUC PSYCHOL, V97, P705, DOI 10.1037/0022-0663.97.4.705
   SCHIEFFELIN BB, 1986, ANNU REV ANTHROPOL, V15, P163, DOI 10.1146/annurev.an.15.100186.001115
   Shimpi PM, 2012, APPL PSYCHOLINGUIST, V33, P781, DOI 10.1017/S0142716411000567
   Shneidman LA, 2012, DEVELOPMENTAL SCI, V15, P659, DOI 10.1111/j.1467-7687.2012.01168.x
   Singh L, 2012, DEVELOPMENTAL SCI, V15, P482, DOI 10.1111/j.1467-7687.2012.01141.x
   Sperry DE, 2019, CHILD DEV, V90, P1303, DOI 10.1111/cdev.13072
   Stokes SF, 2013, TOP LANG DISORD, V33, P224, DOI 10.1097/TLD.0b013e31829d038c
   Stromswold K, 2001, LANGUAGE, V77, P647, DOI 10.1353/lan.2001.0247
   Szewczyk JM, 2018, COGNITION, V179, P23, DOI 10.1016/j.cognition.2018.06.002
   Tallal P, 2004, NAT REV NEUROSCI, V5, P721, DOI 10.1038/nrn1499
   Tamis-LeMonda CS, 2014, CURR DIR PSYCHOL SCI, V23, P121, DOI 10.1177/0963721414522813
   Thierry G, 2003, NEUROREPORT, V14, P2307, DOI 10.1097/00001756-200312190-00004
   Tomasello M, 2007, DEVELOPMENTAL SCI, V10, P121, DOI 10.1111/j.1467-7687.2007.00573.x
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   UNDERWOOD BJ, 1975, AM PSYCHOL, V30, P128, DOI 10.1037/h0076759
   Vasilyeva M, 2008, DEVELOPMENTAL SCI, V11, P84, DOI 10.1111/j.1467-7687.2007.00656.x
   Voorspoels W, 2018, PSYCHON B REV, V25, P271, DOI 10.3758/s13423-017-1245-4
   Westfall J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152719
   Wichman AL, 2006, PERS SOC PSYCHOL B, V32, P117, DOI 10.1177/0146167205279581
   Wilke M, 2003, NEUROREPORT, V14, P1887, DOI 10.1097/00001756-200310270-00001
   Willoughby MT, 2016, PSYCHOL ASSESSMENT, V28, P319, DOI 10.1037/pas0000152
   Woodard K, 2016, J EXP CHILD PSYCHOL, V141, P187, DOI 10.1016/j.jecp.2015.08.005
   Wundt WM, 1904, PRINCIPLES PHYSL PSY, V1
   Yang C, 2016, PRICE OF LINGUISTIC PRODUCTIVITY: HOW CHILDREN LEARN TO BREAK THE RULES OF LANGUAGE, P1, DOI 10.7551/mitpress/9780262035323.001.0001
   Yang C, 2017, NEUROSCI BIOBEHAV R, V81, P103, DOI 10.1016/j.neubiorev.2016.12.023
NR 165
TC 0
Z9 0
U1 5
U2 15
PU ANNUAL REVIEWS
PI PALO ALTO
PA 4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0897 USA
SN 2333-9691
J9 ANNU REV LINGUIST
PY 2020
VL 6
BP 319
EP 340
DI 10.1146/annurev-linguistics-011619-030326
PG 22
WC Linguistics; Language & Linguistics
SC Linguistics
GA BO3AZ
UT WOS:000509883100016
OA Green Published
DA 2021-02-24
ER

PT J
AU Kabakoff, H
   Go, G
   Levi, SV
AF Kabakoff, Heather
   Go, Gretchen
   Levi, Susannah V.
TI Training a non-native vowel contrast with a distributional learning
   paradigm results in improved perception and production
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Speech perception; Speech production; Second language acquisition;
   Phonemic contrasts; Distributional learning
ID AMERICAN ENGLISH ADULTS; R-VERTICAL-BAR; SPEECH-PERCEPTION; JAPANESE
   LISTENERS; DISCRIMINATION; FRENCH; ASSIMILATION; INFANTS; MODEL;
   SENSITIVITY
AB Previous distributional learning research suggests that adults can improve perception of a non-native contrast more efficiently when exposed to a bimodal than a unimodal distribution. Studies have also suggested that perceptual learning can transfer to production. The current study tested whether the addition of visual images to reinforce the contrast and active learning with feedback would result in learning in both conditions and would transfer to gains in production. Native English-speaking adults heard stimuli from a bimodal or unimodal /o-/oe/ continuum. No group differences were found on a discrimination task, possibly suggesting that the supports eliminated previously documented group differences. On an identification task, listeners in the bimodal group showed better performance than the unimodal group on the endpoint stimuli. Production results indicated that both groups showed increased Euclidean distance between the target vowels after training, suggesting that perceptual training improved production skills in both conditions. Contrary to expectations, degree of perception and production learning were not correlated. Together, these results suggest that a bimodal distribution may aid learning, but that adding images to reinforce the contrast and active learning to the training paradigm could mitigate disadvantages found previously for participants exposed to a unimodal distribution. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Kabakoff, Heather; Go, Gretchen; Levi, Susannah V.] NYU, 550 1St Ave, New York, NY 10012 USA.
RP Kabakoff, H (corresponding author), NYU, 550 1St Ave, New York, NY 10012 USA.
EM heather.kabakoff@nyu.edu
OI Levi, Susannah/0000-0002-3115-8981
FU NIDCD NIH HHSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [F31 DC018197] Funding Source:
   Medline
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   Baddeley A, 2000, TRENDS COGN SCI, V4, P417, DOI 10.1016/S1364-6613(00)01538-2
   Baese-Berk M. M, 2015, J MEM LANG, V89, P23
   Baese-Berk MM, 2010, THESIS
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Berch DB, 1998, BRAIN COGNITION, V38, P317, DOI 10.1006/brcg.1998.1039
   Best C. T., 1991, SR107108 HASK LAB
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Boersma Paul, 2019, PRAAT DOING PHONETIC
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P977, DOI 10.3758/BF03206911
   Campbell H, 2018, INT J SPEECH-LANG PA, V20, P635, DOI 10.1080/17549507.2017.1359334
   Corsi P.M., 1972, THESIS
   Earle FS, 2017, NEUROSCI LETT, V636, P77, DOI 10.1016/j.neulet.2016.10.044
   Escudero P., 2005, LINGUISTIC PERCEPTIO
   Escudero P, 2011, J ACOUST SOC AM, V130, pEL206, DOI 10.1121/1.3629144
   Flege J. E., 2003, PHONETICS PHONOLOGY, P319, DOI DOI 10.1515/9783110895094.319
   FRY DB, 1962, LANG SPEECH, V5, P171, DOI 10.1177/002383096200500401
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goudbeek M, 2008, SPEECH COMMUN, V50, P109, DOI 10.1016/j.specom.2007.07.003
   Gulian M., 2007, P 15 INT C PHON SCI, P1893
   Harmon Z, 2019, COGNITION, V189, P76, DOI 10.1016/j.cognition.2019.03.011
   Hayes R. L, 2003, THESIS
   Hayes-Harb R, 2007, SECOND LANG RES, V23, P65, DOI 10.1177/0267658307071601
   Jamieson D.G., 1992, J SPEECH LANGUAGE PA, V16, P201
   Kong EJ, 2016, J PHONETICS, V59, P40, DOI 10.1016/j.wocn.2016.08.006
   Kuhl P. K., 1995, SPEECH PERCEPTION LI, P121
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Labov W., 2006, ATLAS N AM ENGLISH P
   Lenth R, 2019, ESTIMATED MARGINAL M
   Levy ES, 2008, J PHONETICS, V36, P141, DOI 10.1016/j.wocn.2007.03.001
   Levy ES, 2009, J ACOUST SOC AM, V126, P2670, DOI 10.1121/1.3224715
   Levy ES, 2009, J ACOUST SOC AM, V125, P1138, DOI 10.1121/1.3050256
   Manis FR, 1997, J EXP CHILD PSYCHOL, V66, P211, DOI 10.1006/jecp.1997.2383
   MathWorks Inc, 2000, MATLAB VERS 6 1 COMP
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Maye J, 2001, PROC ANN BUCLD, P480
   Maye J, 2000, PROC ANN BUCLD, P522
   McBrideChang C, 1996, CHILD DEV, V67, P1836, DOI 10.2307/1131735
   McCandliss BD, 2002, COGN AFFECT BEHAV NE, V2, P89, DOI 10.3758/CABN.2.2.89
   McGregor KK, 2014, J SPEECH LANG HEAR R, V57, P1842, DOI 10.1044/2014_JSLHR-L-13-0273
   Mitterer H, 2008, COGNITION, V109, P168, DOI 10.1016/j.cognition.2008.08.002
   O'Brien GE, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34823-8
   POLKA L, 1995, J ACOUST SOC AM, V97, P1286, DOI 10.1121/1.412170
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Quene H, 2014, HQMISC PACKAGE R MIS
   Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063
   RStudio Team, 2017, RSTUDIO INT DEV R VE
   Rvachew S, 2004, AM J SPEECH-LANG PAT, V13, P250, DOI 10.1044/1058-0360(2004/026)
   RVACHEW S, 1994, J SPEECH HEAR RES, V37, P347, DOI 10.1044/jshr.3702.347
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Semel E. M., 2003, CLIN EVALUATION LANG
   Shockley K, 2004, PERCEPT PSYCHOPHYS, V66, P422, DOI 10.3758/BF03194890
   Strange W, 2009, J ACOUST SOC AM, V126, P1461, DOI 10.1121/1.3179666
   TREHUB SE, 1976, CHILD DEV, V47, P466, DOI 10.2307/1128803
   TREHUB SE, 1973, DEV PSYCHOL, V9, P91, DOI 10.1037/h0034999
   Wagenmakers EJ, 2007, PSYCHON B REV, V14, P779, DOI 10.3758/BF03194105
   Wanrooij K, 2015, FRONT PSYCHOL, V6, DOI [10.3389/fpsyg.2015.01341, 10.3389/fpg.21115.111341]
   Wechsler D., 2008, WECHSLER ADULT INTEL
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
NR 60
TC 0
Z9 0
U1 2
U2 3
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD JAN
PY 2020
VL 78
AR 100940
DI 10.1016/j.wocn.2019.100940
PG 17
WC Linguistics; Language & Linguistics
SC Linguistics
GA KH0BN
UT WOS:000510313500002
PM 32713984
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Moshgelani, F
   Parsa, V
   Allan, C
   Veeranna, SA
   Allen, P
AF Moshgelani, Farid
   Parsa, Vijay
   Allan, Chris
   Veeranna, Sangamanatha A.
   Allen, Prudence
TI Perceptual and Objective Assessment of Envelope Enhancement for Children
   With Auditory Processing Disorder
SO IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING
LA English
DT Article
DE Envelope enhancement; auditory processing disorder; speech
   intelligibility; hearing aid speech perception index; temporal
   processing
ID SPEECH-PERCEPTION; HEARING-AIDS; INDIVIDUALS; INTELLIGIBILITY; NOISE;
   QUALITY; QUIET; REVERBERANT; NEUROPATHY; LISTENERS
AB This paper evaluated the performance of an envelope enhancement (EE) algorithm subjectively by children with auditory processing disorder (APD), and objectively through computational models. Speech intelligibility data was collected from children with APD, for unprocessed and envelope-enhanced speech in the presence of stationary and non-stationary background noise at different signal to noise ratios (SNRs), both with and without noise reduction (NR) algorithms as a front-end to the EE algorithm. Furthermore, intrusive and non-intrusive objective speech intelligibility metrics were derived to predict the perceptual impact of this EE algorithm. Subjective data for stationary noise conditions revealed that the combination of NR and EE algorithms significantly improved the speech intelligibility scores at poor SNRs. In contrast, the same combination was ineffective in improving speech intelligibility in non-stationary noise conditions. Taken together, subjective results suggest that exaggerating the envelope cues improves speech identification scores for children with APD. However, the benefit obtained varies depending upon the type and level of the background noise. Both intrusive and non-intrusive objective speech intelligibility estimators exhibited good correlation with the subjective data, with the intrusive metric demonstrating better generalization capabilities. Implications of these results for hearing aid applications for children with APD is discussed.
C1 [Moshgelani, Farid; Parsa, Vijay] Western Univ, Dept Elect & Comp Engn, Natl Ctr Audiol, London, ON N6A 3K7, Canada.
   [Allan, Chris; Veeranna, Sangamanatha A.; Allen, Prudence] Western Univ, Natl Ctr Audiol, London, ON N6G 1H1, Canada.
RP Moshgelani, F (corresponding author), Western Univ, Dept Elect & Comp Engn, Natl Ctr Audiol, London, ON N6A 3K7, Canada.
FU Natural Sciences and Engineering Research Council (NSERC) of Canada
   Discovery GrantNatural Sciences and Engineering Research Council of
   Canada (NSERC)
FX The work of V. Parsa was supported by the Natural Sciences and
   Engineering Research Council (NSERC) of Canada Discovery Grant.
CR Allen P, 2014, INT J PEDIATR OTORHI, V78, P198, DOI 10.1016/j.ijporl.2013.10.048
   American Academy of Audiology, 2010, GUID DIAGN TREATM MA
   American Speech-Language-Hearing Association [ASHA], 2005, CENTR AUD PROC DIS
   ASHA, 1996, CENTR AUD PROC CURR
   BLAND JM, 1986, LANCET, V1, P307, DOI 10.1016/s0140-6736(86)90837-8
   Breithaupt C, 2008, INT CONF ACOUST SPEE, P4897, DOI 10.1109/ICASSP.2008.4518755
   Chen F, 2013, BIOMED SIGNAL PROCES, V8, P311, DOI 10.1016/j.bspc.2012.11.007
   Falk TH, 2015, IEEE SIGNAL PROC MAG, V32, P114, DOI 10.1109/MSP.2014.2358871
   Falk TH, 2010, IEEE T AUDIO SPEECH, V18, P1766, DOI 10.1109/TASL.2010.2052247
   Flanagan S, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518756533
   Hamacher V, 2005, EURASIP J APPL SIG P, V2005, P2915, DOI 10.1155/ASP.2005.2915
   Healy EW, 2017, J ACOUST SOC AM, V141, P4230, DOI 10.1121/1.4984271
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   Kates JM, 2014, SPEECH COMMUN, V65, P75, DOI 10.1016/j.specom.2014.06.002
   Kuhn M., 2013, APPL PREDICTIVE MODE
   Kuk Francis, 2011, Seminars in Hearing, V32, P189, DOI 10.1055/s-0031-1277241
   Loizou P., 2007, SPEECH ENHANCEMENT T
   Lucker J. R., 2013, AUDITORY PROCESSING, P33
   Moshgelani F, 2019, BIOMED SIGNAL PROCES, V47, P16, DOI 10.1016/j.bspc.2018.08.013
   Moshgelani F, 2017, IEEE GLOB CONF SIG, P447, DOI 10.1109/GlobalSIP.2017.8308682
   Narne VK, 2008, EAR HEARING, V29, P45
   Narne VK, 2009, INT J AUDIOL, V48, P700, DOI 10.1080/14992020902931574
   Narne VK, 2009, EAR HEARING, V30, P136, DOI 10.1097/AUD.0b013e3181926545
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Rance Gary, 2005, Trends Amplif, V9, P1, DOI 10.1177/108471380500900102
   Reynolds S., 2015, AM J OCCUP THER, V70, P1
   Schafer E. C., 2014, J ED AUDIOLOGY, V20, P1
   Shetty HN, 2017, NOISE HEALTH, V19, P174, DOI 10.4103/nah.NAH_10_16
   Shetty HN, 2016, J INT ADV OTOL, V12, P282, DOI 10.5152/iao.2016.2540
   Soli SD, 2018, INT J AUDIOL, V57, P323, DOI 10.1080/14992027.2017.1411623
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Taal CH, 2010, INT CONF ACOUST SPEE, P4214, DOI 10.1109/ICASSP.2010.5495701
NR 32
TC 0
Z9 0
U1 0
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1534-4320
EI 1558-0210
J9 IEEE T NEUR SYS REH
JI IEEE Trans. Neural Syst. Rehabil. Eng.
PD JAN
PY 2020
VL 28
IS 1
BP 143
EP 151
DI 10.1109/TNSRE.2019.2957230
PG 9
WC Engineering, Biomedical; Rehabilitation
SC Engineering; Rehabilitation
GA KE2FZ
UT WOS:000508375400015
PM 31804940
DA 2021-02-24
ER

PT J
AU Grabski, K
   Sato, M
AF Grabski, Krystyna
   Sato, Marc
TI Adaptive phonemic coding in the listening and speaking brain
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Speech perception; Speech production; Dorsal stream; fMRI adaptation;
   Repetition-suppression
ID SUPPLEMENTARY MOTOR AREA; REPETITION SUPPRESSION; AUDIOVISUAL SPEECH;
   PREMOTOR CORTEX; SELF-VOICE; AUDITORY-CORTEX; MIRROR NEURONS; NEURAL
   THEORY; FMRI; ADAPTATION
AB In order to determine the neural substrates of phonemic coding during both listening and speaking, we used a repetition suppression (RS) paradigm in which vowels were repeatedly perceived or produced while measuring BOLD activity with sparse sampling functional magnetic resonance imaging (fMRI). RS refers to the phenomenon that repeated stimuli or actions lead to decreased activity in specific neural populations associated with enhanced neural selectivity and information coding efficiency. Common suppressed BOLD responses during repeated vowel perception and production were observed in the inferior frontal gyri, the posterior part of the left middle temporal gyrus and superior temporal sulcus, the left intraprietal sulcus, as well as in the cingulate gyms and presupplementary motor area. By providing evidence for common adaptive neural changes in premotor and associative auditory and somatosensory brain areas, the observed RS effects suggest that phonemic coding is partly driven by shared sensorimotor regions in the listening and speaking brain.
C1 [Grabski, Krystyna; Sato, Marc] Aix Marseille Univ, CNRS, Lab Parole & Langage, Aix En Provence, France.
RP Sato, M (corresponding author), Aix Marseille Univ, CNRS, UMR 7309, Lab Parole & Langage, 5 Ave Pasteur, F-13100 Aix En Provence, France.
EM marc.sato@lpl-aix.fr
FU Grenoble-INP (BQR 'Modyc: Modelisation dynamique de l'activite
   cerebrale')
FX We thank Laurent Lamalle and Coriandre Vilain for their help in data
   acquisition. This study was supported by a research grant from
   Grenoble-INP (BQR 'Modyc: Modelisation dynamique de l'activite
   cerebrale') to M.S. and K.G.
CR Alario FX, 2006, BRAIN RES, V1076, P129, DOI 10.1016/j.brainres.2005.11.104
   Alho J, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00394
   Alho J, 2012, NEUROIMAGE, V60, P1937, DOI 10.1016/j.neuroimage.2012.02.011
   Aruffo C, 2012, PSYCHON B REV, V19, P66, DOI 10.3758/s13423-011-0176-8
   Auksztulewicz R, 2016, CORTEX, V80, P125, DOI 10.1016/j.cortex.2015.11.024
   Barron HC, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0355
   Birn RM, 1999, HUM BRAIN MAPP, V7, P106, DOI 10.1002/(SICI)1097-0193(1999)7:2<106::AID-HBM4>3.3.CO;2-F
   Bohland JW, 2006, NEUROIMAGE, V32, P821, DOI 10.1016/j.neuroimage.2006.04.173
   Bornkessel-Schlesewsky I, 2015, TRENDS COGN SCI, V19, P142, DOI 10.1016/j.tics.2014.12.008
   Bouchard KE, 2013, NATURE, V495, P327, DOI 10.1038/nature11911
   Callan D, 2010, NEUROIMAGE, V51, P844, DOI 10.1016/j.neuroimage.2010.02.027
   Catani M, 2005, ANN NEUROL, V57, P8, DOI 10.1002/ana.20319
   Celsis P, 1999, NEUROIMAGE, V9, P135, DOI 10.1006/nimg.1998.0389
   Chevillet MA, 2013, J NEUROSCI, V33, P5208, DOI 10.1523/JNEUROSCI.1870-12.2013
   Chong TTJ, 2008, CURR BIOL, V18, P1576, DOI 10.1016/j.cub.2008.08.068
   Christoffels IK, 2007, HUM BRAIN MAPP, V28, P868, DOI 10.1002/hbm.20315
   Desai R, 2008, J COGNITIVE NEUROSCI, V20, P1174, DOI 10.1162/jocn.2008.20081
   Dick AS, 2012, BRAIN, V135, P3529, DOI 10.1093/brain/aws222
   Dinstein I, 2007, J NEUROPHYSIOL, V98, P1415, DOI 10.1152/jn.00238.2007
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   Friston K, 2011, NEURON, V72, P488, DOI 10.1016/j.neuron.2011.10.018
   Friston KJ, 2012, COGN NEUROSCI-UK, V3, P238, DOI 10.1080/17588928.2012.691277
   Glascher J, 2008, CONTRAST WEIGH UNPUB
   Golfinopoulos E, 2011, NEUROIMAGE, V55, P1324, DOI 10.1016/j.neuroimage.2010.12.065
   Gotts SJ, 2012, COGN NEUROSCI-UK, V3, P227, DOI 10.1080/17588928.2012.670617
   Grabski K, 2013, BRAIN RES, V1515, P55, DOI 10.1016/j.brainres.2013.03.024
   Grabski K, 2013, J NEUROLINGUIST, V26, P384, DOI 10.1016/j.jneuroling.2012.11.003
   Grabski K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0049117
   Grabski K, 2012, HUM BRAIN MAPP, V33, P2306, DOI 10.1002/hbm.21363
   Gracco VL, 2005, NEUROIMAGE, V26, P294, DOI 10.1016/j.neuroimage.2005.01.033
   Grill-Spector K, 2006, TRENDS COGN SCI, V10, P14, DOI 10.1016/j.tics.2005.11.006
   Grill-Spector K, 2001, ACTA PSYCHOL, V107, P293, DOI 10.1016/S0001-6918(01)00019-1
   Grotheer M, 2016, CORTEX, V80, P113, DOI 10.1016/j.cortex.2015.11.027
   Guenther FH, 2012, J NEUROLINGUIST, V25, P408, DOI 10.1016/j.jneuroling.2009.08.006
   Hall DA, 1999, HUM BRAIN MAPP, V7, P213, DOI 10.1002/(SICI)1097-0193(1999)7:3<213::AID-HBM5>3.0.CO;2-N
   Hamilton AFD, 2009, HUM BRAIN MAPP, V30, P2898, DOI 10.1002/hbm.20717
   Hasson U, 2007, NEURON, V56, P1116, DOI 10.1016/j.neuron.2007.09.037
   Henson RN, 2012, COGN NEUROSCI-UK, V3, P240, DOI 10.1080/17588928.2012.689962
   Hertrich I, 2016, NEUROSCI BIOBEHAV R, V68, P602, DOI 10.1016/j.neubiorev.2016.06.030
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Houde JF, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00082
   Hupe JM, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00018
   Jacquemot C, 2003, J NEUROSCI, V23, P9541
   JEANNEROD M, 1994, BEHAV BRAIN SCI, V17, P187, DOI 10.1017/S0140525X00034026
   Joanisse MF, 2007, CEREB CORTEX, V17, P2084, DOI 10.1093/cercor/bhl124
   Jurgens U, 2002, NEUROSCI BIOBEHAV R, V26, P235, DOI 10.1016/S0149-7634(01)00068-9
   Kaplan JT, 2008, SOC COGN AFFECT NEUR, V3, P218, DOI 10.1093/scan/nsn014
   Kilner JM, 2009, J NEUROSCI, V29, P10153, DOI 10.1523/JNEUROSCI.2668-09.2009
   Ladefoged P., 2006, COURSE PHONETICS
   Larsson J, 2016, CORTEX, V80, P154, DOI 10.1016/j.cortex.2015.10.026
   Lawyer L, 2014, J NEUROLINGUIST, V27, P18, DOI 10.1016/j.jneuroling.2013.07.001
   Lee YS, 2012, J NEUROSCI, V32, P3942, DOI 10.1523/JNEUROSCI.3814-11.2012
   Liberman A. M., 2000, TRENDS COGN SCI, V3, P254
   Lima CF, 2016, TRENDS NEUROSCI, V39, P527, DOI 10.1016/j.tins.2016.06.003
   Mattingly I.G, 1988, AUDITORY FUNCTION NE, P775
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Murakami T, 2015, J NEUROSCI, V35, P1411, DOI 10.1523/JNEUROSCI.0246-14.2015
   Myers EB, 2012, J COGNITIVE NEUROSCI, V24, P1695, DOI 10.1162/jocn_a_00243
   Myers EB, 2009, PSYCHOL SCI, V20, P895, DOI 10.1111/j.1467-9280.2009.02380.x
   Nakamura K, 2001, NEUROPSYCHOLOGIA, V39, P1047, DOI 10.1016/S0028-3932(01)00037-9
   Neubert FX, 2014, NEURON, V81, P700, DOI 10.1016/j.neuron.2013.11.012
   Niziolek CA, 2013, J NEUROSCI, V33, P16110, DOI 10.1523/JNEUROSCI.2137-13.2013
   Noppeney U, 2006, HUM BRAIN MAPP, V27, P411, DOI 10.1002/hbm.20242
   Okada K, 2018, J COGNITIVE NEUROSCI, V30, P1549, DOI 10.1162/jocn_a_01287
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Peeva MG, 2010, NEUROIMAGE, V50, P626, DOI 10.1016/j.neuroimage.2009.12.065
   Perkell JS, 2012, J NEUROLINGUIST, V25, P382, DOI 10.1016/j.jneuroling.2010.02.011
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Raizada RDS, 2007, NEURON, V56, P726, DOI 10.1016/j.neuron.2007.11.001
   Rampinini AC, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-17314-0
   Rauschecker JP, 2011, HEARING RES, V271, P16, DOI 10.1016/j.heares.2010.09.001
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Riecker A, 2005, NEUROLOGY, V64, P700, DOI 10.1212/01.WNL.0000152156.90779.89
   Rizzolatti G, 2001, NAT REV NEUROSCI, V2, P661, DOI 10.1038/35090060
   Rosa C, 2008, BRAIN COGNITION, V68, P204, DOI 10.1016/j.bandc.2008.04.007
   Sato M, 2018, BRAIN LANG, V187, P92, DOI 10.1016/j.bandl.2018.01.008
   Sato M, 2015, J COGNITIVE NEUROSCI, V27, P334, DOI 10.1162/jocn_a_00711
   Sato M, 2009, BRAIN LANG, V111, P1, DOI 10.1016/j.bandl.2009.03.002
   Schomers MR, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00435
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   Schwartz JL, 1997, J PHONETICS, V25, P233, DOI 10.1006/jpho.1997.0044
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Thirion B, 2007, NEUROIMAGE, V35, P105, DOI 10.1016/j.neuroimage.2006.11.054
   Tourville JA, 2008, NEUROIMAGE, V39, P1429, DOI 10.1016/j.neuroimage.2007.09.054
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   Treille A, 2017, EXP BRAIN RES, V235, P2867, DOI 10.1007/s00221-017-5018-0
   Tremblay P, 2006, NEUROIMAGE, V33, P947, DOI 10.1016/j.neuroimage.2006.07.041
   Tremblay P, 2011, NEUROIMAGE, V57, P1561, DOI 10.1016/j.neuroimage.2011.05.067
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Vaden KI, 2010, NEUROIMAGE, V49, P1018, DOI 10.1016/j.neuroimage.2009.07.063
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Zheng ZZ, 2010, J COGNITIVE NEUROSCI, V22, P1770, DOI 10.1162/jocn.2009.21324
NR 94
TC 0
Z9 0
U1 1
U2 3
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD JAN
PY 2020
VL 136
AR 107267
DI 10.1016/j.neuropsychologia.2019.107267
PG 11
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA KB7RC
UT WOS:000506686700017
PM 31770550
DA 2021-02-24
ER

PT J
AU Nogueira, W
   Cosatti, G
   Schierholz, I
   Egger, M
   Mirkovic, B
   Buchner, A
AF Nogueira, Waldo
   Cosatti, Giulio
   Schierholz, Irina
   Egger, Maria
   Mirkovic, Bojana
   Buechner, Andreas
TI Toward Decoding Selective Attention From Single-Trial EEG Data in
   Cochlear Implant Users
SO IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
LA English
DT Article
DE Cochlear implant; selective attention; electroencephalography (EEG)
ID AUDITORY-EVOKED POTENTIALS; SPEECH RECOGNITION; NEURAL RESPONSES;
   SENTENCE TEST; ATTENUATION; PERCEPTION; ENVELOPE; ARTIFACT; BRAIN; NOISE
AB Previous results showed that it is possible to decode an attended speech source from EEG data via the reconstruction of the speech envelope in normal hearing (NH) listeners. However, so far it is unknown that how the performance of such a decoder is affected by the decrease in spectral resolution and the electrical artifacts introduced by a cochlear implant (CI) in users of these prostheses. NH listeners and bilateral CI users participated in the present study. Speeches from two audio books, one uttered by a male voice and one by a female voice, were presented to NH listeners and CI users. Participants were instructed to attend to one of the two speech streams presented dichotically while a 96-channel EEG was recorded. Speech envelope reconstruction from the EEG data was obtained by training decoders using a regularized least square estimation method. Decoding accuracy was defined as the percentage of accurately reconstructed trials for each subject. For NH listeners, the experiment was repeated using a vocoder to reduce spectral resolution and simulate speech perception with a CI in NH listeners. The results showed a decoding accuracy of 80.9% using the original sound files in NH listeners. The performance dropped to 73.2% in the vocoder condition and to 71.5 % in the group of CI users. In sum, although the accuracy drops when the spectral resolution becomes worse, the results show the feasibility to decode the attended sound source in NH listeners with a vocoder simulation, and even in CI users, albeit more training data are needed.
C1 [Nogueira, Waldo; Cosatti, Giulio; Schierholz, Irina; Egger, Maria; Buechner, Andreas] Hannover Med Sch, Dept Otolaryngol, Cluster Excellence Hearing4all, D-30625 Hannover, Germany.
   [Mirkovic, Bojana] Carl von Ossietzky Univ Oldenburg, Dept Psychol, Neuropsychol Lab, Cluster Excellence Hearing4all, Oldenburg, Germany.
RP Nogueira, W (corresponding author), Hannover Med Sch, Dept Otolaryngol, Cluster Excellence Hearing4all, D-30625 Hannover, Germany.
EM nogueiravazquez.waldo@mh-hannover.de
RI Mirkovic, Bojana/J-5945-2019
OI Mirkovic, Bojana/0000-0001-5912-3740; Nogueira,
   Waldo/0000-0001-7224-7617
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under
   Germany's Excellence StrategyGerman Research Foundation (DFG) [EXC
   2177/1, 390895286]
FX This work was supported by the Deutsche Forschungsgemeinschaft (DFG,
   German Research Foundation) under Germany's Excellence Strategy EXC
   2177/1-Project ID 390895286.
CR Aiken SJ, 2008, HEARING RES, V245, P35, DOI 10.1016/j.heares.2008.08.004
   Aroudi A, 2016, INT CONF ACOUST SPEE, P694, DOI 10.1109/ICASSP.2016.7471764
   Bleichner MG, 2015, PHYSIOL REP, V3, DOI 10.14814/phy2.12362
   Broderick MP, 2018, CURR BIOL, V28, P803, DOI 10.1016/j.cub.2018.01.080
   Bumler G., 1984, FARBE WORT INTERFERE
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Crosse MJ, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00604
   Das N, 2016, IEEE ENG MED BIO, P77, DOI 10.1109/EMBC.2016.7590644
   Debener S, 2015, SCI REP-UK, V5, DOI 10.1038/srep16743
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Ding N, 2014, NEUROIMAGE, V88, P41, DOI 10.1016/j.neuroimage.2013.10.054
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Fiedler L, 2016, IEEE ENG MED BIO, P5697, DOI 10.1109/EMBC.2016.7592020
   Fritz J, 2005, HEARING RES, V206, P159, DOI 10.1016/j.heares.2005.01.015
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P180, DOI 10.1007/s10162-005-5061-6
   Gilley PM, 2006, CLIN NEUROPHYSIOL, V117, P1772, DOI 10.1016/j.clinph.2006.04.018
   Golumbic EMZ, 2012, BRAIN LANG, V122, P151, DOI 10.1016/j.bandl.2011.12.010
   Hahlbrock K. H., 1970, SPRACHAUDIOMETRIE GR
   HochmairDesoyer I, 1997, AM J OTOL, V18, pS83
   Karns CM, 2015, DEV COGN NEUROS-NETH, V13, P53, DOI 10.1016/j.dcn.2015.03.001
   Kollmeier B, 1997, J ACOUST SOC AM, V102, P2412, DOI 10.1121/1.419624
   Kong YY, 2015, JARO-J ASSOC RES OTO, V16, P783, DOI 10.1007/s10162-015-0540-x
   Koskinen M, 2014, NEUROIMAGE, V100, P263, DOI 10.1016/j.neuroimage.2014.06.018
   Krueger B, 2008, OTOL NEUROTOL, V29, P509, DOI 10.1097/MAO.0b013e318171972f
   Lalor EC, 2010, EUR J NEUROSCI, V31, P189, DOI 10.1111/j.1460-9568.2009.07055.x
   Li XX, 2010, INT CONF BIOMED, P799, DOI 10.1109/BMEI.2010.5639942
   Loizou PC, 1998, IEEE SIGNAL PROC MAG, V15, P101, DOI 10.1109/79.708543
   Martin BA, 2007, J AM ACAD AUDIOL, V18, P126, DOI 10.3766/jaaa.18.2.5
   Mc Laughlin M, 2013, HEARING RES, V302, P84, DOI 10.1016/j.heares.2013.05.006
   Mc Laughlin M, 2012, IEEE T NEUR SYS REH, V20, P443, DOI 10.1109/TNSRE.2012.2186982
   Mirkovic B, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00349
   Mirkovic B, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/4/046007
   Nogueira W., 2016, P ITG S SPEECH COMM, P1
   O'Sullivan JA, 2015, CEREB CORTEX, V25, P1697, DOI 10.1093/cercor/bht355
   Ruggles D, 2012, CURR BIOL, V22, P1417, DOI 10.1016/j.cub.2012.05.025
   Salmelin R, 2007, CLIN NEUROPHYSIOL, V118, P237, DOI 10.1016/j.clinph.2006.07.316
   Sandmann P, 2009, BRAIN, V132, P1967, DOI 10.1093/brain/awp034
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Shannon RV, 2004, ACTA OTO-LARYNGOL, V124, P50, DOI 10.1080/03655230410017562
   Somers B, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aaac92
   Stothart G, 2016, NEUROBIOL AGING, V47, P23, DOI 10.1016/j.neurobiolaging.2016.06.022
   Tremblay K, 1998, NEUROREPORT, V9, P3557, DOI 10.1097/00001756-199811160-00003
   Van Dun B., 2014, P 8 INT S OBJ MEAS A
   Viola FC, 2011, PSYCHOPHYSIOLOGY, V48, P1470, DOI 10.1111/j.1469-8986.2011.01224.x
   Viola FC, 2012, HEARING RES, V284, P6, DOI 10.1016/j.heares.2011.12.010
   Wagner L, 2018, IEEE T NEUR SYS REH, V26, P392, DOI 10.1109/TNSRE.2018.2789780
   Wilson BS, 2008, HEARING RES, V242, P3, DOI 10.1016/j.heares.2008.06.005
   WILSON BS, 1991, NATURE, V352, P236, DOI 10.1038/352236a0
   WOODS DL, 1992, ELECTROEN CLIN NEURO, V84, P456, DOI 10.1016/0168-5597(92)90033-8
   Wouters J, 2015, IEEE SIGNAL PROC MAG, V32, P67, DOI 10.1109/MSP.2014.2371671
   Zeng Fan-Gang, 2008, IEEE Rev Biomed Eng, V1, P115, DOI 10.1109/RBME.2008.2008250
NR 51
TC 1
Z9 1
U1 2
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9294
EI 1558-2531
J9 IEEE T BIO-MED ENG
JI IEEE Trans. Biomed. Eng.
PD JAN
PY 2020
VL 67
IS 1
BP 38
EP 49
DI 10.1109/TBME.2019.2907638
PG 12
WC Engineering, Biomedical
SC Engineering
GA KA0YK
UT WOS:000505526300004
PM 30932825
DA 2021-02-24
ER

PT J
AU Lotfi, Y
   Samadi-Qaleh-Juqy, Z
   Moosavi, A
   Sadjedi, H
   Bakhshi, E
AF Lotfi, Yones
   Samadi-Qaleh-Juqy, Zhaleh
   Moosavi, Abdollah
   Sadjedi, Hamed
   Bakhshi, Enayatollah
TI The Effects of Spatial Auditory Training on Speech Perception in Noise
   in the Elderly
SO CRESCENT JOURNAL OF MEDICAL AND BIOLOGICAL SCIENCES
LA English
DT Article
DE Aging; Auditory training; Speech perception
ID MIDDLE LATENCY RESPONSE; AGE-RELATED-CHANGES; OLDER-ADULTS;
   HEARING-LOSS; PROCESSING DEFICITS; WORD-RECOGNITION; CHILDREN;
   REMEDIATION; SEPARATION; RELEASE
AB Objectives: Studies have shown that spatial processing disorders can be the reason for hearing impairment in the elderly but none of the auditory training programs has addressed it. This study investigated the effect of a novel auditory training on speech perception in noise among the elderly and its maintenance.
   Materials and Methods: The spatial versions of the Persian quick speech in noise (QuickSIN) test were developed and its face validity and reliability were evaluated. Thirty-six old subjects with normal hearing ability who expressed problem in speech perception were randomly divided into the study and control groups. The study group received 5 weeks of spatial auditory training. The spatial versions of the QuickSIN test, and Iranian version of the speech, spatial, and qualities of hearing scale (SSQ), as well as the middle latency response (MLR) test were done pre and post training. The same evaluations were carried out for the control group without training.
   Results: Test-retest reliability and face validity of the spatial versions of Persian QuickSIN test were confirmed. Signal to noise ratio for 50% correct score (SNR50) significantly decreased and spatial release from masking (SRM) and binaural interaction component of MLR percentage (BIC-MLR%) significantly increased. The average scores of SSQ improved in all the three domains. These changes, except for BIC-MLR and SNR50a had short-term maintenance.
   Conclusions: Spatial auditory training can improve speech perception in noise by enhancing the representation of binaural cues at the thalamocortical level. Spatial hearing evaluation and training are recommended to be incorporated into audiology services for serving the geriatric population.
C1 [Lotfi, Yones; Samadi-Qaleh-Juqy, Zhaleh] Univ Social Welf & Rehabil Sci, Dept Audiol, Tehran, Iran.
   [Moosavi, Abdollah] Iran Univ Med Sci, Sch Med, Dept Otolaryngol, Tehran, Iran.
   [Sadjedi, Hamed] Shahed Univ, Dept Elect Engn, Tehran, Iran.
   [Bakhshi, Enayatollah] Univ Social Welf & Rehabil Sci, Dept Biostat, Tehran, Iran.
RP Samadi-Qaleh-Juqy, Z (corresponding author), Univ Social Welf & Rehabil Sci, Dept Audiol, Tehran, Iran.
EM samadi.zh@gmail.com
RI Bakhshi, Enayatollah/D-8589-2017
FU University of Social Welfare and Rehabilitation
FX This study did not receive any grant from any funding agencies and was
   supported as a PhD thesis by the University of Social Welfare and
   Rehabilitation. We appreciate the cooperation of all the participants in
   this study.
CR Anderson S, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00097
   Arend J.M, 2016, P 29 TONM VDT INT CO
   Besser J, 2015, EAR HEARING, V36, P24, DOI 10.1097/AUD.0000000000000096
   Brodie A, 2018, EUR ARCH OTO-RHINO-L, V275, P2435, DOI 10.1007/s00405-018-5100-7
   Bronkhorst AW, 2015, ATTEN PERCEPT PSYCHO, V77, P1465, DOI 10.3758/s13414-015-0882-9
   Burk MH, 2006, EAR HEARING, V27, P263, DOI 10.1097/01.aud.0000215980.21158.a2
   Cameron S, 2011, J AM ACAD AUDIOL, V22, P678, DOI 10.3766/jaaa.22.10.6
   Divenyi PL, 1997, EAR HEARING, V18, P42, DOI 10.1097/00003446-199702000-00005
   Dobreva MS, 2011, J NEUROPHYSIOL, V105, P2471, DOI 10.1152/jn.00951.2010
   Dubno JR, 2008, J SPEECH LANG HEAR R, V51, P539, DOI 10.1044/1092-4388(2008/039)
   Ferguson MA, 2014, EAR HEARING, V35, pE110, DOI 10.1097/AUD.0000000000000020
   Foroughan M., 2008, ADV COGNITIVE SCI, V10, P29
   Freigang C, 2015, CELL TISSUE RES, V361, P371, DOI 10.1007/s00441-015-2230-8
   Furukawa S, 2006, HEARING RES, V212, P48, DOI 10.1016/j.heares.2005.10.009
   Gatehouse S, 2004, INT J AUDIOL, V43, P85, DOI 10.1080/14992020400050014
   Glyde H, 2014, J AM ACAD AUDIOL, V25, P549, DOI 10.3766/jaaa.25.6.5
   Glyde H, 2013, J ACOUST SOC AM, V134, pEL147, DOI 10.1121/1.4812441
   Glyde H, 2011, TRENDS AMPLIF, V15, P116, DOI 10.1177/1084713811424885
   Humes LE, 2014, J ACOUST SOC AM, V136, pEL224, DOI 10.1121/1.4890663
   Humes LE, 2009, EAR HEARING, V30, P613, DOI 10.1097/AUD.0b013e3181b00d90
   Kidd G, 1998, J ACOUST SOC AM, V104, P422, DOI 10.1121/1.423246
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Koehnke Janet, 2001, Seminars in Hearing, V22, P241, DOI 10.1055/s-2001-15629
   Kuchinsky SE, 2014, PSYCHOPHYSIOLOGY, V51, P1046, DOI 10.1111/psyp.12242
   Lotfi Yones, 2016, Acta Med Iran, V54, P756
   Martin JS, 2005, J REHABIL RES DEV, V42, P25, DOI 10.1682/JRRD.2004.12.0164
   Moossavi A, 2016, J REHABIL SCI RES, V3, P51, DOI [10.30476/JRSR.2016.41099, DOI 10.30476/JRSR.2016.41099]
   Murphy DR, 2006, PSYCHOL AGING, V21, P49, DOI 10.1037/0882-7974.21.1.49
   Neher T, 2009, INT J AUDIOL, V48, P758, DOI 10.3109/14992020903079332
   Oba SI, 2011, EAR HEARING, V32, P573, DOI 10.1097/AUD.0b013e31820fc821
   Pizarek R., 2013, PERSPECTIVES AURAL R, V20, P91, DOI DOI 10.1044/ARRI20.3.91
   Ralli M, 2019, AM J OTOLARYNG, V40, P1, DOI 10.1016/j.amjoto.2018.09.012
   Rimmele J, 2012, HEARING RES, V289, P98, DOI 10.1016/j.heares.2012.04.006
   Schochat E, 2010, BRAZ J MED BIOL RES, V43, P777, DOI 10.1590/S0100-879X2010000800011
   Shinn-Cunningham B, 2001, AUDIOL NEURO-OTOL, V6, P187, DOI 10.1159/000046830
   Skoe E, 2010, EAR HEARING, V31, P302, DOI 10.1097/AUD.0b013e3181cdb272
   Sweetow RW, 2006, J AM ACAD AUDIOL, V17, P538, DOI 10.3766/jaaa.17.8.2
   Sweetow RW, 2004, HEAR J, V57, DOI DOI 10.1097/01.HJ.0000292371.26838.91
   Tremblay KL, 2009, CLIN NEUROPHYSIOL, V120, P128, DOI 10.1016/j.clinph.2008.10.005
   Weihing J, 2014, J AM ACAD AUDIOL, V25, P324, DOI 10.3766/jaaa.25.4.4
   Weihing J, 2008, J AM ACAD AUDIOL, V19, P481, DOI 10.3766/jaaa.19.6.4
   Woods DL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0113965
NR 42
TC 0
Z9 0
U1 0
U2 1
PU ARAS PART MEDICAL INT PRESS
PI TABRIZ
PA NO 1, S SHAREATI ST, 5138815941, TABRIZ, 00000, IRAN
SN 2148-9696
J9 CRESCENT J MED BIOL
JI Crescent J. Med. Biol. Sci.
PD JAN
PY 2020
VL 7
IS 1
BP 40
EP 46
PG 7
WC Medicine, General & Internal
SC General & Internal Medicine
GA JZ1YU
UT WOS:000504900900007
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Kimel, E
   Ahissar, M
AF Kimel, Eva
   Ahissar, Merav
TI Benefits From Morphological Regularities in Dyslexia Are Task Dependent
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION
LA English
DT Article
DE morphology; vocabulary acquisition; reading; learning; dyslexia
ID DEVELOPMENTAL DYSLEXIA; LANGUAGE DEFICITS; SPEECH-PERCEPTION; COMPLEX
   WORDS; CHILDREN; VOCABULARY; AWARENESS; SENSITIVITY; HEBREW; MEMORY
AB Are difficulties of individuals with dyslexia (IDDs) reduced or enhanced in tasks where linguistic regularities typically facilitate performance, such as vocabulary acquisition and reading? If impaired short-term memory and poor phonological decoding pose the main impediments to IDDs, then they are expected to compensate for these difficulties with a greater reliance on linguistic regularities, to reduce online load. However, if reduced benefits from regularities pose the main bottleneck, IDDs might benefit less than good readers from regularities in spite of their online difficulties. To test that, we administered two experiments. In a novel paradigm of auditory vocabulary acquisition in Hebrew, novel words were presented either with or without familiar morphological structure. Participants with dyslexia showed a reduced recall benefit from familiar structure as compared with controls. However, their recognition was facilitated by morphological structure and did not significantly differ from controls'. In the second experiment, participants read novel words with and without familiar structure. Benefit from structure familiarity for IDDs was significantly smaller than for controls, in spite of IDDs' greater potential benefit from familiar structure due to their reduced overall accuracy. However, when asked to emphasize speed in reading. structure familiarity was found to be beneficial for IDDs, without compromising accuracy. These results imply that accumulative acquisition of sublexical regularities is less efficient in dyslexia, though in some tasks this knowledge is accessible and beneficial.
C1 [Kimel, Eva; Ahissar, Merav] Hebrew Univ Jerusalem, Edmond & Lily Safra Ctr Brain Sci, Edmond J Safra Campus, IL-9190401 Jerusalem, Israel.
   [Ahissar, Merav] Hebrew Univ Jerusalem, Dept Psychol, Jerusalem, Israel.
RP Kimel, E (corresponding author), Hebrew Univ Jerusalem, Edmond & Lily Safra Ctr Brain Sci, Edmond J Safra Campus, IL-9190401 Jerusalem, Israel.
EM eva.kelman@mail.huji.ac.il
OI Ahissar, Merav/0000-0001-7694-8111
FU German-Israeli Foundation for Scientific Research and
   DevelopmentGerman-Israeli Foundation for Scientific Research and
   Development [I-1303-105.4/2015]; Canadian Institutes of Health
   ResearchCanadian Institutes of Health Research (CIHR); International
   Development Research Center; Israeli Science FoundationIsrael Science
   Foundation; Azrieli Foundation [2425/15]; Israel Science
   FoundationIsrael Science Foundation [1650/17]; Edmond and Lily Safra
   Center for Brain Sciences
FX This work was supported by the German-Israeli Foundation for Scientific
   Research and Development (Grant I-1303-105.4/2015), the Canadian
   Institutes of Health Research, the International Development Research
   Center, the Israeli Science Foundation, and the Azrieli Foundation
   (Grant 2425/15), and a personal grant from the Israel Science Foundation
   (Grant 1650/17), awarded to Merav Ahissar. We thank The Edmond and Lily
   Safra Center for Brain Sciences for the postdoctoral fellowship granted
   to Eva Kimel.
CR Ahissar M, 2000, P NATL ACAD SCI USA, V97, P6832, DOI 10.1073/pnas.97.12.6832
   Ahissar M, 2007, TRENDS COGN SCI, V11, P458, DOI 10.1016/j.tics.2007.08.015
   Ahissar M, 2006, NAT NEUROSCI, V9, P1558, DOI 10.1038/nn1800
   Angelelli P, 2017, DYSLEXIA, V23, P387, DOI 10.1002/dys.1554
   ANGLIN JM, 1993, MONOGR SOC RES CHILD, V58, P1
   Banai K, 2006, CEREB CORTEX, V16, P1718, DOI 10.1093/cercor/bhj107
   Banai K, 2018, LANG COGN NEUROSCI, V33, P321, DOI 10.1080/23273798.2017.1408851
   Ben-Yehudah G, 2004, VISION RES, V44, P1047, DOI 10.1016/j.visres.2003.12.001
   Ben-Yehudah G, 2001, BRAIN, V124, P1381, DOI 10.1093/brain/124.7.1381
   BENDROR I, 1995, READ RES QUART, V30, P876, DOI 10.2307/748202
   BERKO J, 1958, WORD, V14, P150, DOI 10.1080/00437956.1958.11659661
   BERMAN RA, 1980, LINGUISTICS, V18, P677, DOI 10.1515/ling.1980.18.7-8.677
   BERMAN RA, 1981, J CHILD LANG, V8, P265, DOI 10.1017/S0305000900003184
   Boets B, 2013, SCIENCE, V342, P1251, DOI 10.1126/science.1244333
   Bowers PN, 2010, READ WRIT, V23, P515, DOI 10.1007/s11145-009-9172-z
   Burani C, 2008, COGNITION, V108, P243, DOI 10.1016/j.cognition.2007.12.010
   Cantiani C, 2013, NEUROPSYCHOLOGIA, V51, P1595, DOI 10.1016/j.neuropsychologia.2013.04.009
   Carlisle JF, 2000, READ WRIT, V12, P169, DOI 10.1023/A:1008131926604
   CARLISLE JF, 1993, APPL PSYCHOLINGUIST, V14, P177, DOI 10.1017/S0142716400009541
   Casalis S, 2004, ANN DYSLEXIA, V54, P114, DOI 10.1007/s11881-004-0006-z
   CATTS HW, 1986, J LEARN DISABIL, V19, P504, DOI 10.1177/002221948601900813
   Davies R, 2007, ANN DYSLEXIA, V57, P179, DOI 10.1007/s11881-007-0010-1
   Deutsch A, 1998, J EXP PSYCHOL LEARN, V24, P1238, DOI 10.1037/0278-7393.24.5.1238
   Deutsch A, 1996, J EXP CHILD PSYCHOL, V63, P386, DOI 10.1006/jecp.1996.0055
   Doron A, 2015, J VISION, V15, DOI 10.1167/15.14.13
   Elbro C, 1996, ANN DYSLEXIA, V46, P209, DOI 10.1007/BF02648177
   Forgeard M, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003566
   Frost R, 1997, J EXP PSYCHOL LEARN, V23, P829, DOI 10.1037/0278-7393.23.4.829
   Frost R, 2000, J EXP PSYCHOL LEARN, V26, P751, DOI 10.1037/0278-7393.26.3.751
   Gallagher A, 2000, J CHILD PSYCHOL PSYC, V41, P203, DOI 10.1111/1469-7610.00601
   GATHERCOLE SE, 1989, J MEM LANG, V28, P200, DOI 10.1016/0749-596X(89)90044-2
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Green D. M., 1966, SIGNAL DETECTION THE
   HELMHOLTZ H, 2000, TREATISE PHYSL OPTIC
   Hendriks AW, 1997, COGNITIVE NEUROPSYCH, V14, P321
   Hollingworth H. L, 1910, J PHILOS PSYCHOL SCI, V7, P461, DOI DOI 10.2307/2012819
   JACOBY LL, 1991, J MEM LANG, V30, P513, DOI 10.1016/0749-596X(91)90025-F
   Jaffe-Dax S, 2018, ELIFE, V7, DOI 10.7554/eLife.30018
   Jaffe-Dax S, 2017, ELIFE, V6, DOI 10.7554/eLife.20557
   Jaffe-Dax S, 2016, J VISION, V16, DOI 10.1167/16.9.10
   Jaffe-Dax S, 2015, J NEUROSCI, V35, P12116, DOI 10.1523/JNEUROSCI.1302-15.2015
   JENKINS JR, 1983, CONTEMP EDUC PSYCHOL, V8, P237, DOI 10.1016/0361-476X(83)90016-4
   Joanisse MF, 2000, J EXP CHILD PSYCHOL, V77, P30, DOI 10.1006/jecp.1999.2553
   Jones MW, 2018, COGNITION, V177, P214, DOI 10.1016/j.cognition.2018.04.010
   Kimel E., 2016, P 38 ANN C COGN SCI, P2866
   Kimel E., 2017, P 39 ANN C COGN SCI, P2419
   Kolan L, 2011, J MEM LANG, V65, P286, DOI 10.1016/j.jml.2011.06.004
   Kuo LJ, 2006, EDUC PSYCHOL-US, V41, P161, DOI 10.1207/s15326985ep4103_3
   Leikin M, 2006, J PSYCHOLINGUIST RES, V35, P471, DOI 10.1007/s10936-006-9025-8
   Lieder I, 2019, NAT NEUROSCI, V22, P256, DOI 10.1038/s41593-018-0308-9
   Lyon GR, 2003, ANN DYSLEXIA, V53, P1, DOI 10.1007/s11881-003-0001-9
   Lyytinen P, 2004, APPL PSYCHOLINGUIST, V25, P397, DOI 10.1017/S0142716404001183
   Mahony D, 2000, READ WRIT, V12, P191, DOI 10.1023/A:1008136012492
   MARSLENWILSON W, 1994, PSYCHOL REV, V101, P3, DOI 10.1037/0033-295X.101.1.3
   McAnally KI, 1996, P ROY SOC B-BIOL SCI, V263, P961, DOI 10.1098/rspb.1996.0142
   McBride-Chang C, 2008, APPL PSYCHOLINGUIST, V29, P437, DOI 10.1017/S014271640808020X
   Migo EM, 2012, CONSCIOUS COGN, V21, P1435, DOI 10.1016/j.concog.2012.04.014
   MILLER GA, 1987, SCI AM, V257, P94, DOI 10.1038/scientificamerican0987-94
   Nagy W, 2006, J EDUC PSYCHOL, V98, P134, DOI 10.1037/0022-0663.98.1.134
   Nagy W. E., 1985, 347 U ILL CTR STUD R
   Nagy W. E., 1984, 326 U ILL CTR STUD R
   NAGY WE, 1985, READ RES QUART, V20, P233, DOI 10.2307/747758
   NAGY WE, 1984, READ RES QUART, V19, P304, DOI 10.2307/747823
   O'Brien GE, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34823-8
   Oganian Y, 2012, NEUROPSYCHOLOGIA, V50, P1895, DOI 10.1016/j.neuropsychologia.2012.04.014
   Perrachione TK, 2016, NEURON, V92, P1383, DOI 10.1016/j.neuron.2016.11.020
   Perrachione TK, 2011, SCIENCE, V333, P595, DOI 10.1126/science.1207327
   Quemart P, 2017, ANN DYSLEXIA, V67, P85, DOI 10.1007/s11881-016-0133-3
   Quemart P, 2015, APPL PSYCHOLINGUIST, V36, P345, DOI 10.1017/S014271641300026X
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   Ramus F, 2008, Q J EXP PSYCHOL, V61, P129, DOI 10.1080/17470210701508822
   Ransby MJ, 2003, J LEARN DISABIL-US, V36, P538, DOI 10.1177/00222194030360060501
   Rastle K, 2008, LANG COGNITIVE PROC, V23, P942, DOI 10.1080/01690960802069730
   Ravid D., 2006, FIRST LANG, V26, P381, DOI [10.1177/0142723706064828, DOI 10.1177/0142723706064828]
   Rispens J, 2004, J NEUROLINGUIST, V17, P333, DOI 10.1016/j.jneuroling.2003.09.001
   Russeler J, 2003, J CLIN EXP NEUROPSYC, V25, P815, DOI 10.1076/jcen.25.6.815.16469
   SCARBOROUGH HS, 1990, CHILD DEV, V61, P1728, DOI 10.2307/1130834
   Schiff R, 2007, DYSLEXIA, V13, P110, DOI 10.1002/dys.322
   Schiff R, 2007, J PSYCHOLINGUIST RES, V36, P237, DOI 10.1007/s10936-006-9043-6
   Schiff R, 2013, J LEARN DISABIL-US, V46, P220, DOI 10.1177/0022219412449425
   Schwarzwald O. R., 2002, MODERN HEBREW MORPHO
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   Snowling M., 2000, DYSLEXIA
   SNOWLING MJ, 1981, PSYCHOL RES-PSYCH FO, V43, P219, DOI 10.1007/BF00309831
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   SPRING C, 1976, J SPEC EDUC, V10, P35, DOI 10.1177/002246697601000104
   Thiessen ED, 2013, PSYCHOL BULL, V139, P792, DOI 10.1037/a0030801
   Traficante D, 2011, LANG COGNITIVE PROC, V26, P777, DOI 10.1080/01690965.2010.496553
   van der Leij A, 1999, J LEARN DISABIL-US, V32, P417, DOI 10.1177/002221949903200507
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   VOGEL SA, 1977, J LEARN DISABIL-US, V10, P35, DOI 10.1177/002221947701000109
   Wechsler D., 1997, WAIS 3 ADM SCORING M
   WYSOCKI K, 1987, READ RES QUART, V22, P66, DOI 10.2307/747721
   Yonelinas AP, 2002, J MEM LANG, V46, P441, DOI 10.1006/jmla.2002.2864
NR 94
TC 3
Z9 3
U1 1
U2 5
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0278-7393
EI 1939-1285
J9 J EXP PSYCHOL LEARN
JI J. Exp. Psychol.-Learn. Mem. Cogn.
PD JAN
PY 2020
VL 46
IS 1
BP 155
EP 169
DI 10.1037/xlm0000717
PG 15
WC Psychology; Psychology, Experimental
SC Psychology
GA JW4AK
UT WOS:000502995700010
PM 31081654
DA 2021-02-24
ER

PT J
AU Bruneel, L
   Bettens, K
   De Bodt, M
   D'haeseleer, E
   Thijs, Z
   Roche, N
   Van Lierde, K
AF Bruneel, Laura
   Bettens, Kim
   De Bodt, Marc
   D'haeseleer, Evelien
   Thijs, Zoe
   Roche, Nathalie
   Van Lierde, Kristiane
TI Stages in the Development and Validation of a Belgian Dutch Outcome Tool
   for the Perceptual Evaluation of Speech in Patients With Cleft Palate
SO CLEFT PALATE-CRANIOFACIAL JOURNAL
LA English
DT Article
DE speech perception; articulation; nasality
ID QUALITY-OF-LIFE; VELOPHARYNGEAL CLOSURE FORCE; SCANDCLEFT
   RANDOMIZED-TRIALS; SEVERITY INDEX 2.0; NASAL AIR-FLOW; PRIMARY SURGERY;
   AUDIT PROTOCOL; LIP; RELIABILITY; CHILDREN
AB Objective: To develop and validate a Belgian Dutch outcome tool for the perceptual evaluation of speech in patients with cleft palate. Setting: Cleft palate team in a tertiary university hospital. Methods: The tool was based on the Cleft Audit Protocol for Speech-Augmented (John et al., 2006; Sell et al., 2009), with adaptations to some of the speech variables and the structured listening protocol. Following a preliminary listening experiment in phase 1, the tool was optimized. In the second phase, a listening experiment with 4 experienced listeners was set up to assess face validity, inter- and intrarater reliability and criterion validity. Results: Results of phase 1 indicated good to very good inter- and intrarater reliability for the majority of the speech variables, good discriminant validity, and varying sensitivity and specificity based on a comparison with nasalance values and the Nasality Severity Index 2.0 (criterion validity). Results of phase 2 showed good to very good interrater reliability for 5 of the 14 variables and good intrarater reliability in 3 of the 4 experienced listeners. Sensitivity and specificity were sufficient, except the specificity of the hypernasality judgments in comparison with the nasalance values of the oral text. Overall, listeners positively judged the face validity of the tool. Conclusion: The 2-phase evaluation indicated varying validity and reliability results. Future studies will aim to optimize validity and reliability of the developed tool based on adaptations to the listening protocol, the addition of speech variables, and the inclusion of a more elaborate training.
C1 [Bruneel, Laura; Bettens, Kim; De Bodt, Marc; D'haeseleer, Evelien; Thijs, Zoe; Van Lierde, Kristiane] Univ Ghent, Dept Rehabil Sci Language & Hearing Sci, Ghent, Belgium.
   [De Bodt, Marc] Antwerp Univ, Dept ENT Head & Neck Surg & Commun Disorders, Antwerp, Belgium.
   [Roche, Nathalie] Ghent Univ Hosp, Dept Plast & Reconstruct Surg, Ghent, Belgium.
   [Van Lierde, Kristiane] Univ Pretoria, Dept Speech Language Pathol & Audiol, Pretoria, South Africa.
RP Bruneel, L (corresponding author), Univ Ghent, Dept Rehabil Sci, C Heymanslaan 10 2P1, B-9000 Ghent, Belgium.
EM laubrune.bruneel@ugent.be
RI DE BODT, MARC/AAF-2724-2021; Roche, Nathalie/L-9874-2019
OI Roche, Nathalie/0000-0001-9241-8583; Bettens, Kim/0000-0001-5546-5997;
   D'haeseleer, Evelien/0000-0002-3956-5936; Thijs, Zoe/0000-0002-3421-1207
FU Research Foundation FlandersFWO
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by a PhD fellowship of the Research Foundation Flanders
   (L.B.).
CR Allori AC, 2017, CLEFT PALATE-CRAN J, V54, P540, DOI 10.1597/15-292
   Altman DG, 1990, PRACTICAL STAT MED R
   [Anonymous], 2006, PLOS CLIN TRIALS, V1, pe33, DOI 10.1371/journal.pctr.0010033
   Baylis A, 2015, CLEFT PALATE-CRAN J, V52, P660, DOI 10.1597/14-040
   Bettens K, 2018, J COMMUN DISORD, V76, P11, DOI 10.1016/j.jcomdis.2018.07.002
   Bettens K, 2017, LOGOP PHONIATR VOCO, V42, P133, DOI 10.1080/14015439.2016.1245781
   Bettens K, 2016, CLEFT PALATE-CRAN J, V53, pE60, DOI 10.1597/14-247
   BEUKELMAN DR, 1980, J COMMUN DISORD, V13, P33, DOI 10.1016/0021-9924(80)90019-2
   Boersma W, 2016, PRAAT DOING PHONETIC
   Borg G., 2001, PSYCHOLOGICA, V28, P15
   Brancamp TU, 2010, CLEFT PALATE-CRAN J, V47, P631, DOI 10.1597/09-106
   Breuls M, 2006, B-ENT, P71
   Britton L, 2014, CLEFT PALATE-CRAN J, V51, P431, DOI 10.1597/13-121
   BRONDSTED K, 1994, CLIN LINGUIST PHONET, V8, P109, DOI 10.3109/02699209408985300
   Bruneel L, 2019, INT J PEDIATR OTORHI, V120, P112, DOI 10.1016/j.ijporl.2019.02.018
   Bruneel L, 2019, INT J PEDIATR OTORHI, V119, P141, DOI 10.1016/j.ijporl.2019.01.026
   Bruneel L, 2017, INT J PEDIATR OTORHI, V98, P91, DOI 10.1016/j.ijporl.2017.04.049
   Brunnegard K, 2012, INT J LANG COMM DIS, V47, P556, DOI 10.1111/j.1460-6984.2012.00165.x
   Brunnegard K, 2009, INT J LANG COMM DIS, V44, P656, DOI 10.1080/13682820802295203
   Castick S, 2017, CLEFT PALATE-CRAN J, V54, P19, DOI 10.1597/15-164
   Chapman KL, 2008, CLEFT PALATE-CRAN J, V45, P297, DOI 10.1597/06-244
   Chapman Kathy L, 2016, Cleft Palate Craniofac J, V53, P93, DOI 10.1597/14-027
   Eckstein DA, 2011, PLAST RECONSTR SURG, V128, p518E, DOI 10.1097/PRS.0b013e31822b6a67
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Gooch JL, 2001, CLEFT PALATE-CRAN J, V38, P59, DOI 10.1597/1545-1569(2001)038<0059:ROLTOC>2.0.CO;2
   Hallgren Kevin A, 2012, Tutor Quant Methods Psychol, V8, P23
   Harding A, 1998, INT J LANG COMM DIS, V33, P329
   Harding A., 1997, CLEFT AUDIT PROTOCOL
   Henningsson G, 1997, T 8 INT C CLEFT PAL
   Henningsson G, 2008, CLEFT PALATE-CRAN J, V45, P1, DOI 10.1597/06-086.1
   Hutters B, 2004, CLEFT PALATE-CRAN J, V41, P544, DOI 10.1597/02-164.1
   John A, 2006, CLEFT PALATE-CRAN J, V43, P272, DOI 10.1597/04-141.1
   Kent R. D., 1996, AM J SPEECH LANG PAT, V5, P7, DOI [DOI 10.1044/1058-0360.0503.07, 10.1044/1058- 0360.0503.07]
   Keuning KHDM, 2004, FOLIA PHONIATR LOGO, V56, P157, DOI 10.1159/000076937
   Klassen AF, 2012, J PLAST RECONSTR AES, V65, P547, DOI 10.1016/j.bjps.2011.11.004
   Klinto K, 2014, CLEFT PALATE-CRAN J, V51, P274, DOI 10.1597/12-299
   Klinto K, 2011, INT J LANG COMM DIS, V46, P348, DOI 10.3109/13682822.2010.507615
   Kuehn DP, 2000, CLEFT PALATE-CRAN J, V37, P348, DOI 10.1597/1545-1569(2000)037<0348:SALIIT>2.3.CO;2
   Kuehn DP, 1998, J SPEECH LANG HEAR R, V41, P51, DOI 10.1044/jslhr.4101.51
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lohmander A, 2004, CLEFT PALATE-CRAN J, V41, P64, DOI 10.1597/02-136
   Lohmander A, 2009, CLEFT PALATE-CRAN J, V46, P347, DOI 10.1597/08-039.1
   Lohmander A, 2008, CLEFT PALATE-CRAN J, V45, P452, DOI 10.1597/07-190.1
   Lohmander A, 2008, CLEFT PALATE-CRAN J, V45, P32, DOI 10.1597/06-123.1
   Lohmander A, 2017, CLIN LINGUIST PHONET, V31, P589, DOI 10.1080/02699206.2017.1302510
   Lohmander A, 2017, J PLAST SURG HAND SU, V51, P27, DOI 10.1080/2000656X.2016.1254645
   Malmborn JO, 2018, CLEFT PALATE-CRAN J, V55, P1051, DOI 10.1177/1055665618765777
   McLeod S, 2012, J SPEECH LANG HEAR R, V55, P648, DOI 10.1044/1092-4388(2011/10-0130)
   MOON JB, 1994, CLEFT PALATE-CRAN J, V31, P356, DOI 10.1597/1545-1569(1994)031<0356:MOVCFD>2.3.CO;2
   Morris H, 2003, CLEFT PALATE-CRAN J, V40, P460, DOI 10.1597/1545-1569(2003)040<0460:PPALSO>2.0.CO;2
   Mossey PA, 2009, LANCET, V374, P1773, DOI 10.1016/S0140-6736(09)60695-4
   Norman G, 2008, BIOSTATISTICS BARE E, P46
   Pereira VJ, 2013, INT J LANG COMM DIS, V48, P640, DOI 10.1111/1460-6984.12036
   Peterson-Falzone SJ, 2001, CLEFT PALATE SPEECH
   Samoy K, 2015, INT J PEDIATR OTORHI, V79, P2213, DOI 10.1016/j.ijporl.2015.10.007
   Sell D, 1999, INT J LANG COMM DIS, V34, P17
   Sell D, 2005, INT J LANG COMM DIS, V40, P103, DOI 10.1080/13682820400016522
   Sell D, 2017, ORTHOD CRANIOFAC RES, V20, P27, DOI 10.1111/ocr.12186
   Sell D, 2015, ORTHOD CRANIOFAC RES, V18, P36, DOI 10.1111/ocr.12112
   Sell D, 2009, INT J LANG COMM DIS, V44, P529, DOI 10.1080/13682820802196815
   SHRIBERG LD, 1991, CLIN LINGUIST PHONET, V5, P225, DOI 10.3109/02699209108986113
   SHRIBERG LD, 1984, J SPEECH HEAR RES, V27, P456, DOI 10.1044/jshr.2703.456
   SHRIBERG LD, 1982, J SPEECH HEAR DISORD, V47, P256, DOI 10.1044/jshd.4703.256
   Shriberg LD, 1997, J SPEECH LANG HEAR R, V40, P708, DOI 10.1044/jslhr.4004.708
   Sitzman TJ, 2014, CLIN PLAST SURG, V41, P311, DOI 10.1016/j.cps.2013.12.001
   Slis I, 1991, LOGOP FONIATR, V63, P97
   Spruijt NE, 2018, J CRANIOFAC SURG, V29, P390, DOI 10.1097/SCS.0000000000004261
   Stevens S., 1975, SCIENCE, V188, P827
   Sweeney T, 2008, INT J LANG COMM DIS, V43, P265, DOI 10.1080/13682820701438177
   VANDEMARK DR, 1964, CLEFT PALATE J, V1, P232
   Vander Poorten V, 2006, B-ENT, P35
   Verhoeven J., 2005, J INT PHONETIC ASS, V35, P243, DOI [10.1017/S0025100305002173, DOI 10.1017/S0025100305002173]
   Watson ACH, 2001, MANAGEMENT CLEFT LIP
   Watterson Thomas, 1993, Journal of Communication Disorders, V26, P13, DOI 10.1016/0021-9924(93)90013-Z
   Whitehill TL, 2002, CLEFT PALATE-CRAN J, V39, P50, DOI 10.1597/1545-1569(2002)039<0050:AIISWC>2.0.CO;2
   Wild D, 2005, VALUE HEALTH, V8, P94, DOI 10.1111/j.1524-4733.2005.04054.x
   Willadsen E, 2017, J PLAST SURG HAND SU, V51, P38, DOI 10.1080/2000656X.2016.1254647
   Wong Riff KWY, 2017, BMJ OPEN, V7, pe015467
   Yamashita RP, 2018, CLEFT PALATE-CRAN J, V55, P1060, DOI 10.1177/1055665618767116
NR 79
TC 3
Z9 3
U1 0
U2 5
PU ALLIANCE COMMUNICATIONS GROUP DIVISION ALLEN PRESS
PI LAWRENCE
PA 810 EAST 10TH STREET, LAWRENCE, KS 66044 USA
SN 1055-6656
EI 1545-1569
J9 CLEFT PALATE-CRAN J
JI Cleft Palate-Craniofac. J.
PD JAN
PY 2020
VL 57
IS 1
BP 43
EP 54
DI 10.1177/1055665619862726
PG 12
WC Dentistry, Oral Surgery & Medicine; Surgery
SC Dentistry, Oral Surgery & Medicine; Surgery
GA JW0RE
UT WOS:000502766200006
PM 31311307
DA 2021-02-24
ER

PT J
AU Schepens, J
   van Hout, R
   Jaeger, TF
AF Schepens, Job
   van Hout, Roeland
   Jaeger, T. Florian
TI Big data suggest strong constraints of linguistic similarity on adult
   language learning
SO COGNITION
LA English
DT Article
DE Second language learning; Transfer; Phonological similarity; Accents;
   Speech production; Speech perception
ID R-VERTICAL-BAR; ENGLISH VOWELS; INDIVIDUAL-DIFFERENCES; PERCEPTUAL
   ADAPTATION; 2ND LANGUAGE; 2ND-LANGUAGE; ACQUISITION; AGE; ACCENTS;
   GERMAN
AB When adults learn new languages, their speech often remains noticeably non-native even after years of exposure. These non-native variants ('accents') can have far-reaching socio-economic consequences for learners. Many factors have been found to contribute to a learners' proficiency in the new language. Here we examine a factor that is outside of the control of the learner, linguistic similarities between the learner's native language (L1) and the new language (Ln). We analyze the (open access) speaking proficiencies of about 50,000 Ln learners of Dutch with 62 diverse L1s. We find that a learner's L1 accounts for 9-22% of the variance in Ln speaking proficiency. This corresponds to 28-69% of the variance explained by a model with controls for other factors known to affect language learning, such as education, age of acquisition and length of exposure. We also find that almost 80% of the effect of L1 can be explained by combining measures of phonological, morphological, and lexical similarity between the L1 and the Ln. These results highlight the constraints that a learner's native language imposes on language learning, and inform theories of L1-to-Ln transfer during Ln learning and use. As predicted by some proposals, we also find that L1-Ln phonological similarity is better captured when subcategorical properties (phonological features) are considered in the calculation of phonological similarities.
C1 [Schepens, Job] Free Univ Berlin, Ctr Cognit Neurosci, Berlin, Germany.
   [van Hout, Roeland] Radboud Univ Nijmegen, Ctr Language Studies, Nijmegen, Netherlands.
   [Jaeger, T. Florian] Univ Rochester, Dept Brain & Cognit Sci, Dept Comp Sci, Rochester, NY 14627 USA.
RP Schepens, J (corresponding author), Free Univ Berlin, Ctr Cognit Neurosci Berlin, Habelschwerdter Allee 45, D-14195 Berlin, Germany.
EM jobschepens@gmail.com
RI Jaeger, T. Florian/O-8224-2019; Schepens, Job/AAB-8753-2019
OI Jaeger, T. Florian/0000-0002-1158-7308; Schepens,
   Job/0000-0003-1271-2526
FU Fulbright Fellowship; NICHDUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [R01 HD075797]
FX The authors thank Steven Moran for the use of the PHOIBLE database and
   the secretary of the State Examination of Dutch as a Second Language for
   providing the data used in our study. Example elicitation instruments
   can be downloaded from
   https://www.hetcvte.nl/item/voorbeeldexamens_en.We thank Theo Bongaerts,
   Crystal Lee, Bozena Pajak, and, in particular, Xin Xie for valuable
   feedback. This study was partially supported by a Fulbright Fellowship
   awarded to JS to visit the Human Language Processing Lab at the
   University of Rochester, and by funding from NICHD R01 HD075797 to TFJ.
   The views expressed here are those of the authors, and do not
   necessarily reflect those of the funding agencies.
CR Adank P, 2009, J EXP PSYCHOL HUMAN, V35, P520, DOI 10.1037/a0013552
   Andringa S, 2012, LANG LEARN, V62, P49, DOI 10.1111/j.1467-9922.2012.00706.x
   Aoyama K, 2004, J PHONETICS, V32, P233, DOI 10.1016/S0095-4470(03)00036-6
   BAAYEN R, 1993, CELEX LEXICAL DATABA
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Babcock L, 2012, BILING-LANG COGN, V15, P820, DOI 10.1017/S1366728912000053
   Banks B, 2015, J ACOUST SOC AM, V137, P2015, DOI 10.1121/1.4916265
   Bardel C, 2007, SECOND LANG RES, V23, P459, DOI 10.1177/0267658307077080557
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Best C., 1995, SPEECH PERCEPTION LI, P171
   BEST CT, 1993, NATO ADV SCI INST SE, V69, P289
   Birdsong D, 2014, APPL LINGUIST, V35, P374, DOI 10.1093/applin/amu031
   Bohn O.-S, 2002, PHONETIC SIMILARITY
   Bohn O.-S., 1992, STUDIES 2 LANGUAGE A, V14, P131, DOI DOI 10.1017/S0272263100010792
   Bohnacker U, 2006, SECOND LANG RES, V22, P443, DOI 10.1191/0267658306sr275oa
   Boll-Avetisyan N, 2012, PHONOTACTICS ITS ACQ, P298
   Bongaerts T., 1997, STUDIES 2 LANGUAGE A, V19, P447, DOI DOI 10.1017/S0272263197004026
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   BRENNAN EM, 1981, J PSYCHOLINGUIST RES, V10, P487, DOI 10.1007/BF01076735
   Brown C., 2000, 2 LANGUAGE ACQUISITI, V1, P4
   Brown Cynthia, 1998, SECOND LANG RES, V14, P136, DOI DOI 10.1191/026765898669508401
   Burchill Z. J, 2017, COGNITIVE MODELING C, P20
   Cenoz J., 2001, CROSS LINGUISTIC INF
   Chang CB, 2015, SEGMENT IN PHONETICS AND PHONOLOGY, P199
   Chang W., 2012, S AM PHONOLOGICAL IN
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Cook V., 2013, 2 LANGUAGE LEARNING
   Croft W., 1990, TYPOLOGY UNIVERSALS
   Crothers JH, 1979, HDB PHONOLOGICAL DAT
   Cysouw M, 2012, SCIENCE, V335, DOI 10.1126/science.1208841
   DeKeyser R, 2012, LANG LEARN, V62, P189, DOI 10.1111/j.1467-9922.2012.00712.x
   Derwing T. M., 2008, PHONOLOGY 2 LANGUAGE, P347, DOI DOI 10.1075/SIBIL.36.17DER
   Dijkstra T, 2010, J MEM LANG, V62, P284, DOI 10.1016/j.jml.2009.12.003
   Dingemanse M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0078273
   Dunn M, 2011, NATURE, V473, P79, DOI 10.1038/nature09923
   Eckman FR, 2003, SECOND LANG RES, V19, P169, DOI 10.1191/0267658303sr2190a
   Escudero P., 2005, LINGUISTIC PERCEPTIO
   Escudero P, 2013, LANG COGNITIVE PROC, V28, P746, DOI 10.1080/01690965.2012.662279
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2003, PHONETICS PHONOLOGY, P319, DOI DOI 10.1515/9783110895094.319
   Flege JE, 2018, BILING-LANG COGN, V21, P919, DOI 10.1017/S136672891800010X
   FLEGE JE, 1981, TESOL QUART, V15, P443, DOI 10.2307/3586485
   Flege JE, 2003, SPEECH COMMUN, V40, P467, DOI 10.1016/S0167-6393(02)00128-0
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   FLEGE JE, 1993, J ACOUST SOC AM, V93, P1589, DOI 10.1121/1.406818
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   Flege JE, 1997, 2 LANGUAGE SPEECH ST, P11
   Fuertes JN, 2012, EUR J SOC PSYCHOL, V42, P120, DOI 10.1002/ejsp.862
   Gallagher G, 2012, LINGUA, V122, P107, DOI 10.1016/j.lingua.2011.11.002
   Gimson A. C., 1962, INTRO PRONUNCIATION
   Gluszek A, 2010, PERS SOC PSYCHOL REV, V14, P214, DOI 10.1177/1088868309359288
   Granena G, 2013, SECOND LANG RES, V29, P311, DOI 10.1177/0267658312461497
   Granger S., 2015, CAMBRIDGE HDB LEARNE
   Gray RD, 2003, NATURE, V426, P435, DOI 10.1038/nature02029
   Gray RD, 2017, P NATL ACAD SCI USA, V114, P7846, DOI 10.1073/pnas.1620746114
   HALLE MORRIS, 1973, LINGUIST INQ, V4, P451
   Hammarstrom H, 2016, J LANG EVOL, V1, P19, DOI 10.1093/jole/lzw002
   Haugen Einar, 1966, SOCIOLINGUISTICS, P50
   Hayes B., 2009, INTRO PHONOLOGY
   International Phonetic Association, 1999, HDB INT PHON ASS IPA
   Ionin Tania, 2002, SECOND LANG RES, V18, P95, DOI DOI 10.1191/0267658302SR1950A
   Iverson P, 2009, J ACOUST SOC AM, V126, P866, DOI 10.1121/1.3148196
   Jaeger Florian, 2011, LINGUIST TYPOL, V15, P281, DOI [10.1515/lity.2011.021, DOI 10.1515/LITY.2011.021]
   Jakobson R., 1968, CHILD LANGUAGE APHAS
   Jakobson R., 1931, TRAVAUX CERCLE LINGU, V4, P246
   Jakobson Roman, 1941, KINDERSPRACHE APHASI
   Jarvis S, 2000, LANG LEARN, V50, P245, DOI 10.1111/0023-8333.00118
   Jarvis S., 2015, CONTENT BASED LANGUA, P69, DOI [10.1007/978-3-319-11496-5_5, DOI 10.1007/978-3-319-11496-5_5]
   Jarvis S., 2008, CROSSLINGUISTIC INFL
   Ji LJ, 2004, J PERS SOC PSYCHOL, V87, P57, DOI 10.1037/0022-3514.87.1.57
   JOHNSON JS, 1989, COGNITIVE PSYCHOL, V21, P60, DOI 10.1016/0010-0285(89)90003-0
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   LaCross A, 2015, LANG COGN NEUROSCI, V30, P1033, DOI 10.1080/23273798.2014.915976
   Lado R., 1957, LINGUISTICS CULTURES
   Lenneberg E. H., 1967, BIOL FDN LANGUAGE, V68
   Lippi-Green R., 2012, ENGLISH ACCENT LANGU
   Ludeling A, 2017, LANG LEARN, V67, P96, DOI 10.1111/lang.12231
   Lupyan G, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0008559
   Luyckx K., 2007, TUSSEN TAAL SPELLING, P141
   Maddiedon I., 1990, WORKING PAPERS PHONE, V74, P104
   Maddieson I., 1984, PATTERNS SOUNDS
   MAJOR R. C., 1992, NEW SOUNDS, V90, P128
   MAJOR Roy C., 2008, PHONOLOGY 2 LANGUAGE, P63, DOI DOI 10.1075/SIBIL.36.05MAJ
   Mathesius Vilem, 1931, TRAVAUX CERCLE LINGU, V4, P148
   McWhorter John H., 2007, LANGUAGE INTERRUPTED
   Moran S., 2012, PHONETICS INFORM BAS
   Moran S, 2012, LANGUAGE, V88, P877, DOI 10.1353/lan.2012.0087
   Munro M., 2003, TESL CANADA J, V20, P38, DOI DOI 10.18806/TESL.V20I2.947
   Munro Murray J., 2008, PHONOLOGY 2 LANGUAGE, P193, DOI DOI 10.1075/SIBIL.36.10MUN
   Nettle D., 1999, LINGUISTIC DIVERSITY
   Odlin T, 2015, NEW PERSPECTIVES TRA
   Odlin T., 1989, LANGUAGE TRANSFER CR
   Odlin T, 2012, ENCY APPL LINGUISTIC, DOI [10.1002/9781405198431.wbea10292, DOI 10.1002/9781405198431.WBEA10292]
   Otwinowska-Kasztelanic A, 2009, INNOV LANG LEARN TEA, V3, P131, DOI 10.1080/17501220802283186
   Pajak B, 2012, INDUCTIVE INFERENCE
   Pajak B, 2016, LANG LEARN, V66, P900, DOI 10.1111/lang.12168
   Pajak B, 2014, J PHONETICS, V46, P147, DOI 10.1016/j.wocn.2014.07.001
   PICA T, 1983, LANG LEARN, V33, P465, DOI 10.1111/j.1467-1770.1983.tb00945.x
   Piske T, 2002, PHONETICA, V59, P49, DOI 10.1159/000056205
   Porretta V, 2016, J PHONETICS, V58, P1, DOI 10.1016/j.wocn.2016.05.006
   Porretta V, 2015, ATTEN PERCEPT PSYCHO, V77, P2438, DOI 10.3758/s13414-015-0916-3
   R Core Team, 2018, R LANG ENV STAT COMP
   Ringbom H., 2007, CROSS LINGUISTIC SIM
   Roever C, 2006, INT J APPL LINGUIST, V16, P242, DOI 10.1111/j.1473-4192.2006.00117.x
   Rothman J, 2015, BILING-LANG COGN, V18, P179, DOI 10.1017/S136672891300059X
   Schepens J, 2015, BRIDGING LINGUISTIC
   Schepens J, 2013, LANG DYN CHANG, V3, P218, DOI 10.1163/22105832-13030203
   Schepens Job, 2013, APPROACHES MEASURING, P199, DOI [10.1515/9783110305258.199, DOI 10.1515/9783110305258.199]
   Schepens JJ, 2016, LANG LEARN, V66, P224, DOI 10.1111/lang.12150
   Schumann J.H., 2004, NEUROBIOLOGY LEARNIN
   Skirgard H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0165934
   Stevens G, 1999, LANG SOC, V28, P555
   Stevens G, 2006, LANG LEARN, V56, P671, DOI 10.1111/j.1467-9922.2006.00392.x
   Strange W, 2007, J ACOUST SOC AM, V122, P1111, DOI 10.1121/1.2749716
   Thompson P, 2013, AUTOMATIC TREATMENT, V59
   Trudgill P., 2011, SOCIOLINGUISTIC TYPO
   Tsukada K, 2014, J SPEECH LANG HEAR R, V57, P805, DOI 10.1044/2014_JSLHR-S-12-0416
   van der Slik F, 2019, SECOND LANG RES, V35, P47, DOI 10.1177/0267658317691322
   Vanhove J, 2015, CROSSLINGUISTIC INFLUENCE AND CROSSLINGUISTIC INTERACTION IN MULTILINGUAL LANGUAGE LEARNING, P95
   Vanhove J, 2015, IRAL-INT REV APPL LI, V53, P1, DOI 10.1515/iral-2015-0001
   Vanhove J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0069172
   Wedel A, 2013, COGNITION, V128, P179, DOI 10.1016/j.cognition.2013.03.002
   Weinreich U., 1963, LANGUAGES CONTACT
   Wright R. A, 2013, REVISITING ROLE FEAT
   Xie X, 2018, J ACOUST SOC AM, V143, P2013, DOI 10.1121/1.5027410
NR 127
TC 2
Z9 2
U1 1
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD JAN
PY 2020
VL 194
AR 104056
DI 10.1016/j.cognition.2019.104056
PG 14
WC Psychology, Experimental
SC Psychology
GA JR6YF
UT WOS:000499767700012
PM 31733600
DA 2021-02-24
ER

PT J
AU Han, YQ
   Goudbeek, M
   Mos, M
   Swerts, M
AF Han, Yueqiao
   Goudbeek, Martijn
   Mos, Maria
   Swerts, Marc
TI Relative Contribution of Auditory and Visual Information to Mandarin
   Chinese Tone Identification by Native and Tone-naive Listeners
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Auditory-visual perception; McGurk effect; Mandarin Chinese tone
   identification; native and tone-naive participants; congruent and
   incongruent
ID SPEECH-PERCEPTION; NORMAL-HEARING; LEXICAL TONES; LANGUAGE; ENGLISH;
   INTELLIGIBILITY; RECOGNITION; CLEAR; PITCH; LIPS
AB Speech perception is a multisensory process: what we hear can be affected by what we see. For instance, the McGurk effect occurs when auditory speech is presented in synchrony with discrepant visual information. A large number of studies have targeted the McGurk effect at the segmental level of speech (mainly consonant perception), which tends to be visually salient (lip-reading based), while the present study aims to extend the existing body of literature to the suprasegmental level, that is, investigating a McGurk effect for the identification of tones in Mandarin Chinese. Previous studies have shown that visual information does play a role in Chinese tone perception, and that the different tones correlate with variable movements of the head and neck. We constructed various tone combinations of congruent and incongruent auditory-visual materials (10 syllables with 16 tone combinations each) and presented them to native speakers of Mandarin Chinese and speakers of tone-naive languages. In line with our previous work, we found that tone identification varies with individual tones, with tone 3 (the low-dipping tone) being the easiest one to identify, whereas tone 4 (the high-falling tone) was the most difficult one. We found that both groups of participants mainly relied on auditory input (instead of visual input), and that the auditory reliance for Chinese subjects was even stronger. The results did not show evidence for auditory-visual integration among native participants, while visual information is helpful for tone-naive participants. However, even for this group, visual information only marginally increases the accuracy in the tone identification task, and this increase depends on the tone in question.
C1 [Han, Yueqiao; Goudbeek, Martijn; Mos, Maria; Swerts, Marc] Tilburg Univ, Tilburg Sch Humanities & Digital Sci, Dept Commun & Cognit, POB 90153, NL-5000 LE Tilburg, Netherlands.
RP Han, YQ (corresponding author), Tilburg Univ, Tilburg Sch Humanities & Digital Sci, Dept Commun & Cognit, POB 90153, NL-5000 LE Tilburg, Netherlands.
EM y.han@uvt.nl
OI Han, Yueqiao/0000-0002-6217-137X; Mos, Maria/0000-0001-5161-2208;
   Goudbeek, Martijn/0000-0002-7787-4123; swerts, marc/0000-0002-4367-641X
FU China Scholarship Council (CSC)China Scholarship Council
FX The authors disclosed receipt of the following financial support for the
   research, authorship, and/or publication of this article: The first
   author received financial support from the China Scholarship Council
   (CSC).
CR Baayen R.H., 2008, ANAL LINGUISTIC DATA
   Bailly G., 2012, AUDIOVISUAL SPEECH P
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   BINNIE CA, 1974, J SPEECH HEAR RES, V17, P619, DOI 10.1044/jshr.1704.619
   Bovo R, 2009, ACTA OTORHINOLARYNGO, V29, P203
   Burnham D., 2001, 7 EUR C SPEECH COMM
   Burnham D., 2001, AVSP 2001 INT C AUD
   Burnham D., 1996, SPEECHREADING HUMANS, P103
   Burnham D, 2018, MULTISENS RES, V31, P79, DOI 10.1163/22134808-00002590
   Burnham Denis, 1998, AVSP 98 INT C AUD VI
   Campbell R., 1998, HEARING EYE
   Chen A, 2003, P EUR 2003 GEN, P97
   Chen TH, 2008, J ACOUST SOC AM, V123, P2356, DOI 10.1121/1.2839004
   COX RM, 1987, J ACOUST SOC AM, V81, P1598, DOI 10.1121/1.394512
   Cutler A, 1997, PERCEPT PSYCHOPHYS, V59, P165, DOI 10.3758/BF03211886
   de Gelder B., 1995, 4 EUR C SPEECH COMM
   Vanrell MD, 2013, LANG SPEECH, V56, P163, DOI 10.1177/0023830912443942
   Desai S, 2008, J ACOUST SOC AM, V123, P428, DOI 10.1121/1.2816573
   Ferguson SH, 2004, J ACOUST SOC AM, V116, P2365, DOI 10.1121/1.1788730
   Francis AL, 2008, J PHONETICS, V36, P268, DOI 10.1016/j.wocn.2007.06.005
   Fuster-Duran A., 1996, SPEECHREADING HUMANS, P135, DOI DOI 10.1007/978-3-662-13015-5_9
   GRANT KW, 1991, J ACOUST SOC AM, V89, P2952, DOI 10.1121/1.400733
   Grassegger H., 1995, P INT C PHON SCI STO, V4, P2
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Han Y., 2019, FRONTIERS COMMUNICAT, V4, P70
   Han YQ, 2019, PHONETICA, V76, P263, DOI 10.1159/000489174
   Hayashi Y., 1998, AVSP 98 INT C AUD VI
   Hirata Y, 2010, J SPEECH LANG HEAR R, V53, P298, DOI 10.1044/1092-4388(2009/08-0243)
   Jiang J., 2002, EURASIP J ADV SIG PR, V2002, DOI DOI 10.1155/S1110865702206046
   Krahmer E, 2007, J MEM LANG, V57, P396, DOI 10.1016/j.jml.2007.06.005
   Krishnan A, 2010, J NEUROLINGUIST, V23, P81, DOI 10.1016/j.jneuroling.2009.09.001
   Ladd DR, 1997, J PHONETICS, V25, P313, DOI 10.1006/jpho.1997.0046
   Magnotti JF, 2015, EXP BRAIN RES, V233, P2581, DOI 10.1007/s00221-015-4324-7
   Massaro D. W., 1998, PERCEIVING TALKING F
   Massaro DW, 1998, AM SCI, V86, P236, DOI 10.1511/1998.25.861
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mixdorff H., 2005, P 9 EUR C SPEECH COM, P405
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Psychology Software Tools Inc, 2016, E PRIM 3 0
   R Core Team, 2019, R LANG ENV STAT COMP
   Reid A, 2015, ATTEN PERCEPT PSYCHO, V77, P571, DOI 10.3758/s13414-014-0791-3
   Sekiyama K., 1994, Journal of the Acoustical Society of Japan (E), V15, P143
   Sekiyama K, 1997, PERCEPT PSYCHOPHYS, V59, P73, DOI 10.3758/BF03206849
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Sekiyama K, 2008, DEVELOPMENTAL SCI, V11, P306, DOI 10.1111/j.1467-7687.2008.00677.x
   Shaw J. A., 2014, INT SEM SPEECH PROD
   Smith D, 2012, J ACOUST SOC AM, V131, P1480, DOI 10.1121/1.3672703
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Vatikiotis-Bateson E., 2000, 9 IEEE INT WORKSH RO
   VATIKIOTISBATES.E, 1996, T TECHNICAL COMMITTE, P1
   Wang Y, 2003, J ACOUST SOC AM, V113, P1033, DOI 10.1121/1.1531176
   Xu Y, 2002, J ACOUST SOC AM, V111, P1399, DOI 10.1121/1.1445789
   Ye Y, 1999, LANG COGNITIVE PROC, V14, P609, DOI 10.1080/016909699386202
   Yehia HC, 2002, J PHONETICS, V30, P555, DOI 10.1006/jpho.2002.0165
NR 55
TC 0
Z9 0
U1 1
U2 4
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD DEC
PY 2020
VL 63
IS 4
BP 856
EP 876
AR 0023830919889995
DI 10.1177/0023830919889995
EA DEC 2019
PG 21
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA NV7ZU
UT WOS:000506779500001
PM 31888403
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Casaponsa, A
   Sohoglu, E
   Moore, DR
   Fullgrabe, C
   Molloy, K
   Amitay, S
AF Casaponsa, Aina
   Sohoglu, Ediz
   Moore, David R.
   Fullgrabe, Christian
   Molloy, Katharine
   Amitay, Sygal
TI Does training with amplitude modulated tones affect tone-vocoded speech
   perception?
SO PLOS ONE
LA English
DT Article
ID ENVELOPE CUES; TEMPORAL ENVELOPE; DEGRADED SPEECH; INTELLIGIBILITY;
   NOISE; RECOGNITION; INFORMATION; ADAPTATION; STIMULATION; CHILDREN
AB Temporal-envelope cues are essential for successful speech perception. We asked here whether training on stimuli containing temporal-envelope cues without speech content can improve the perception of spectrally-degraded (vocoded) speech in which the temporal-envelope (but not the temporal fine structure) is mainly preserved. Two groups of listeners were trained on different amplitude-modulation (AM) based tasks, either AM detection or AM-rate discrimination (21 blocks of 60 trials during two days, 1260 trials; frequency range: 4Hz, 8Hz, and 16Hz), while an additional control group did not undertake any training. Consonant identification in vocoded vowel-consonant-vowel stimuli was tested before and after training on the AM tasks (or at an equivalent time interval for the control group). Following training, only the trained groups showed a significant improvement in the perception of vocoded speech, but the improvement did not significantly differ from that observed for controls. Thus, we do not find convincing evidence that this amount of training with temporal-envelope cues without speech content provide significant benefit for vocoded speech intelligibility. Alternative training regimens using vocoded speech along the linguistic hierarchy should be explored.
C1 [Casaponsa, Aina; Sohoglu, Ediz; Moore, David R.; Fullgrabe, Christian; Molloy, Katharine; Amitay, Sygal] MRC, Inst Hearing Res, Nottingham, England.
   [Casaponsa, Aina] Univ Lancaster, Dept Linguist & English Language, Lancaster, England.
   [Sohoglu, Ediz] MRC, Cognit & Brain Sci Unit, Cambridge, England.
   [Moore, David R.] Cincinnati Childrens Hosp Med Ctr, Commun Sci Res Ctr, Cincinnati, OH 45229 USA.
   [Fullgrabe, Christian] Loughborough Univ, Sch Sport Exercise & Hlth Sci, Loughborough, Leics, England.
   [Molloy, Katharine] UCL, Ear Inst, London, England.
   [Amitay, Sygal] Nottingham Univ Hosp NHS Trust, Informat & Insight, Nottingham, England.
RP Casaponsa, A (corresponding author), MRC, Inst Hearing Res, Nottingham, England.; Casaponsa, A (corresponding author), Univ Lancaster, Dept Linguist & English Language, Lancaster, England.
EM a.casaponsa@lancaster.ac.uk
RI Fullgrabe, Christian/I-6331-2012; Casaponsa, Aina/D-1067-2019
OI Fullgrabe, Christian/0000-0001-9127-8136; Casaponsa,
   Aina/0000-0002-8398-1435; Moore, David/0000-0002-1567-1945
FU Medical Research Council (UK)UK Research & Innovation (UKRI)Medical
   Research Council UK (MRC) [U135097130]
FX The work was funded by the Medical Research Council (UK) Grant
   U135097130 as part of core funding to the Institute of Hearing Research.
   The funders had no role in study design, data collection and analysis,
   decision to publish, or preparation of the manuscript.
CR Amitay S, 2005, PERCEPT PSYCHOPHYS, V67, P691, DOI 10.3758/BF03193525
   Azadpour M, 2015, J ACOUST SOC AM, V138, P44, DOI 10.1121/1.4922226
   Barr DJ, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00328
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   CAZALS Y, 1994, J ACOUST SOC AM, V96, P2048, DOI 10.1121/1.410146
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   Dorman MF, 1997, J ACOUST SOC AM, V102, P2403, DOI 10.1121/1.419603
   DRULLMAN R, 1995, J ACOUST SOC AM, V97, P585, DOI 10.1121/1.413112
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P2670, DOI 10.1121/1.409836
   Erb J, 2013, J NEUROSCI, V33, P10688, DOI 10.1523/JNEUROSCI.4596-12.2013
   Erb J, 2012, NEUROPSYCHOLOGIA, V50, P2154, DOI 10.1016/j.neuropsychologia.2012.05.013
   Fitzgerald MB, 2011, J ACOUST SOC AM, V129, P898, DOI 10.1121/1.3531841
   Fitzgerald MB, 2005, J ACOUST SOC AM, V118, P3794, DOI 10.1121/1.2074687
   Fox J., 2011, R COMPANION APPL REG
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P180, DOI 10.1007/s10162-005-5061-6
   Fu QJ, 2000, J ACOUST SOC AM, V107, P589, DOI 10.1121/1.428325
   Fu QJ, 2002, NEUROREPORT, V13, P1635, DOI 10.1097/00001756-200209160-00013
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Fullgrabe C, 2009, J ACOUST SOC AM, V125, P1277, DOI 10.1121/1.3075591
   Fullgrabe C, 2006, HEARING RES, V211, P74, DOI 10.1016/j.heares.2005.09.001
   Greenberg S, 2003, J PHONETICS, V31, P465, DOI 10.1016/j.wocn.2003.09.005
   Hawkey DJC, 2004, NAT NEUROSCI, V7, P1055, DOI 10.1038/nn1315
   Hervais-Adelman A, 2008, J EXP PSYCHOL HUMAN, V34, P460, DOI 10.1037/0096-1523.34.2.460
   Hervais-Adelman AG, 2011, J EXP PSYCHOL HUMAN, V37, P283, DOI 10.1037/a0020772
   HOUTGAST T, 1985, J ACOUST SOC AM, V77, P1069, DOI 10.1121/1.392224
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   KUZNETSOVA V, 2013, LMERTEST TESTS RANDO, V2
   Lakshminarayanan K, 2007, RESTOR NEUROL NEUROS, V25, P263
   Leong V, 2014, J ACOUST SOC AM, V136, P366, DOI 10.1121/1.4883366
   Leong V, 2014, HEARING RES, V308, P141, DOI 10.1016/j.heares.2013.07.015
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Loebach JL, 2008, HEARING RES, V241, P87, DOI 10.1016/j.heares.2008.05.002
   Loebach JL, 2008, J ACOUST SOC AM, V123, P1126, DOI 10.1121/1.2823453
   Loebach JL, 2009, EAR HEARING, V30, P662, DOI 10.1097/AUD.0b013e3181b9c92d
   Lorenzi C, 2000, J SPEECH LANG HEAR R, V43, P1367, DOI 10.1044/jslhr.4306.1367
   Luo X, 2008, EAR HEARING, V29, P957, DOI 10.1097/AUD.0b013e3181888f61
   Maidment DW, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0121953
   McGettigan C, 2008, THESIS
   McGettigan C, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00018
   Merzenich MM, 1996, SCIENCE, V271, P77, DOI 10.1126/science.271.5245.77
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Molloy K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036929
   R Core Team, 2015, R LANG ENV STAT COMP
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Rouder JN, 2009, PSYCHON B REV, V16, P225, DOI 10.3758/PBR.16.2.225
   Sagi E, 2008, J ACOUST SOC AM, V123, P2848, DOI 10.1121/1.2897914
   Samuel AG, 2011, ANNU REV PSYCHOL, V62, P49, DOI 10.1146/annurev.psych.121208.131643
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Shannon RV, 2004, ACTA OTO-LARYNGOL, V124, P50, DOI 10.1080/03655230410017562
   Shannon RV, 2004, SPR HDB AUD, V20, P334
   Sohoglu E, 2016, P NATL ACAD SCI USA, V113, pE1747, DOI 10.1073/pnas.1523266113
   Sohoglu E, 2014, J EXP PSYCHOL HUMAN, V40, P186, DOI 10.1037/a0033206
   Souza P, 2009, J ACOUST SOC AM, V126, P792, DOI 10.1121/1.3158835
   Stacey PC, 2007, J ACOUST SOC AM, V121, P2923, DOI 10.1121/1.2713668
   Stone MA, 2008, J ACOUST SOC AM, V124, P2272, DOI 10.1121/1.2968678
   Stone MA, 2008, J ACOUST SOC AM, V123, P1063, DOI 10.1121/1.2821969
   Stone MA, 2010, J ACOUST SOC AM, V128, P2127, DOI 10.1121/1.3479546
   VANTASELL DJ, 1987, J ACOUST SOC AM, V82, P1152, DOI 10.1121/1.395251
   VIEMEISTER NF, 1979, J ACOUST SOC AM, V66, P1364, DOI 10.1121/1.383531
   Wechsler D, 1999, WASI WECHSLER ABBREV
   Whitmal NA, 2007, J ACOUST SOC AM, V122, P2376, DOI 10.1121/1.2773993
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1293, DOI 10.3758/BF03194544
   Won JH, 2011, J ACOUST SOC AM, V130, P376, DOI 10.1121/1.3592521
   Wright BA, 2005, LEARNING GEN 5 BASIC, P509
   Wright BA, 2009, PHILOS T R SOC B, V364, P301, DOI 10.1098/rstb.2008.0262
   Xu L, 2005, J ACOUST SOC AM, V117, P3255, DOI 10.1121/1.1886405
   Xu L, 2008, HEARING RES, V242, P132, DOI 10.1016/j.heares.2007.12.010
NR 69
TC 0
Z9 0
U1 0
U2 0
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD DEC 27
PY 2019
VL 14
IS 12
AR e0226288
DI 10.1371/journal.pone.0226288
PG 19
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA KN8IR
UT WOS:000515089200017
PM 31881550
OA DOAJ Gold, Green Published, Green Accepted
DA 2021-02-24
ER

PT J
AU Root-Gutteridge, H
   Ratcliffe, VF
   Korzeniowska, AT
   Reby, D
AF Root-Gutteridge, Holly
   Ratcliffe, Victoria F.
   Korzeniowska, Anna T.
   Reby, David
TI Dogs perceive and spontaneously normalize formant-related speaker and
   vowel differences in human speech sounds
SO BIOLOGY LETTERS
LA English
DT Article
DE speaker normalization; vowel perception; speaker discrimination; speech
   perception
ID TALKER IDENTITY; PERCEPTION; RECOGNITION; DISCRIMINATE; OWNERS; ROARS;
   WORD
AB Domesticated animals have been shown to recognize basic phonemic information from human speech sounds and to recognize familiar speakers from their voices. However, whether animals can spontaneously identify words across unfamiliar speakers (speaker normalization) or spontaneously discriminate between unfamiliar speakers across words remains to be investigated. Here, we assessed these abilities in domestic dogs using the habituation-dishabituation paradigm. We found that while dogs habituated to the presentation of a series of different short words from the same unfamiliar speaker, they significantly dishabituated to the presentation of a novel word from a new speaker of the same gender. This suggests that dogs spontaneously categorized the initial speaker across different words. Conversely, dogs who habituated to the same short word produced by different speakers of the same gender significantly dishabituated to a novel word, suggesting that they had spontaneously categorized the word across different speakers. Our results indicate that the ability to spontaneously recognize both the same phonemes across different speakers, and cues to identity across speech utterances from unfamiliar speakers, is present in domestic dogs and thus not a uniquely human trait.
C1 [Root-Gutteridge, Holly; Korzeniowska, Anna T.; Reby, David] Univ Sussex, Sch Psychol, Mammal Vocal Commun & Cognit Res Grp, Brighton BN1 9QH, E Sussex, England.
   [Ratcliffe, Victoria F.] Def Sci & Technol Lab, Salisbury SP4 0JQ, Wilts, England.
   [Reby, David] Univ Lyon St Etienne, CRNL, ENES, CNRS,UMR5292,INSERM,UMR S 1028, St Etienne, France.
RP Root-Gutteridge, H (corresponding author), Univ Sussex, Sch Psychol, Mammal Vocal Commun & Cognit Res Grp, Brighton BN1 9QH, E Sussex, England.
EM hollyrg@googlemail.com
RI Root-Gutteridge, Holly/H-7288-2013
OI Root-Gutteridge, Holly/0000-0001-9854-2948; Reby,
   David/0000-0001-9261-1711
FU Biotechnology and Biological Sciences Research Council (BBSRC)UK
   Research & Innovation (UKRI)Biotechnology and Biological Sciences
   Research Council (BBSRC) [BB/P00170X/1]; University of Lyon IDEXLYON
   project as part of the 'Programme Investissements d'avenir'French
   National Research Agency (ANR) [ANR-16-IDEX-0005]
FX This study was funded by Biotechnology and Biological Sciences Research
   Council (BBSRC grant no. BB/P00170X/1 'How Dogs Hear Us'). Professor
   Reby was also supported by the University of Lyon IDEXLYON project as
   part of the 'Programme Investissements d'avenir' (ANR-16-IDEX-0005).
CR Adachi I, 2007, ANIM COGN, V10, P17, DOI 10.1007/s10071-006-0025-8
   Bachorowski JA, 1999, J ACOUST SOC AM, V106, P1054, DOI 10.1121/1.427115
   Baru AV, 1975, AUDITORY ANAL PERCEP, P91
   Charlton BD, 2007, BIOL LETTERS, V3, P382, DOI 10.1098/rsbl.2007.0244
   Charlton BD, 2012, ANIM COGN, V15, P999, DOI 10.1007/s10071-012-0527-5
   CHILDERS DG, 1991, J ACOUST SOC AM, V90, P1841, DOI 10.1121/1.401664
   Coutellier L, 2006, ANTHROZOOS, V19, P278, DOI 10.2752/089279306785415529
   Fitch WT, 2003, SPR HDB AUD, V16, P65
   Fitch WT, 1999, J ACOUST SOC AM, V106, P1511, DOI 10.1121/1.427148
   Fukuzawa M, 2005, APPL ANIM BEHAV SCI, V91, P129, DOI 10.1016/j.applanim.2004.08.025
   Fukuzawa M, 2005, J COMP PSYCHOL, V119, P117, DOI 10.1037/0735-7036.119.1.117
   Kreiman J, 2011, FDN VOICE STUDIES IN, P156
   Kriengwatana B, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01543
   Kuhl P. K., 1988, HUMAN EVOL, V3, P19, DOI DOI 10.1007/BF02436589
   KUHL PK, 1983, INFANT BEHAV DEV, V6, P263, DOI 10.1016/S0163-6383(83)80036-8
   KUHL PK, 1975, SCIENCE, V190, P69, DOI 10.1126/science.1166301
   LIBERMAN AM, 1982, AM PSYCHOL, V37, P148, DOI 10.1037/0003-066X.37.2.148
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   MATTINGLY IG, 1972, AM SCI, V60, P327
   Molnar C, 2009, BEHAV PROCESS, V82, P198, DOI 10.1016/j.beproc.2009.06.011
   Ohms VR, 2010, P ROY SOC B-BIOL SCI, V277, P1003, DOI 10.1098/rspb.2009.1788
   Owren MJ, 2006, J ACOUST SOC AM, V119, P1727, DOI 10.1121/1.2161431
   Palacios V, 2015, BEHAVIOUR, V152, P593, DOI 10.1163/1568539X-00003244
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Reby D, 2001, ETHOLOGY, V107, P951, DOI 10.1046/j.1439-0310.2001.00732.x
   Root-Gutteridge H, 2019, DRYAD DIGITAL REPOSI
   Saito A, 2013, ANIM COGN, V16, P685, DOI 10.1007/s10071-013-0620-4
   Takagi S, 2019, ANIM COGN, V22, P901, DOI 10.1007/s10071-019-01265-2
   Thalmann O, 2013, SCIENCE, V342, P871, DOI 10.1126/science.1243650
   TITZE IR, 1989, J ACOUST SOC AM, V85, P1699, DOI 10.1121/1.397959
NR 31
TC 3
Z9 3
U1 3
U2 7
PU ROYAL SOC
PI LONDON
PA 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND
SN 1744-9561
EI 1744-957X
J9 BIOL LETTERS
JI Biol. Lett.
PD DEC 24
PY 2019
VL 15
IS 12
AR 20190555
DI 10.1098/rsbl.2019.0555
PG 5
WC Biology; Ecology; Evolutionary Biology
SC Life Sciences & Biomedicine - Other Topics; Environmental Sciences &
   Ecology; Evolutionary Biology
GA JT7GR
UT WOS:000501154600005
PM 31795850
OA Bronze, Green Accepted, Green Published
DA 2021-02-24
ER

PT J
AU Loughrey, DG
   Mihelj, E
   Lawlor, BA
AF Loughrey, David G.
   Mihelj, Ernest
   Lawlor, Brian A.
TI Age-related hearing loss associated with altered response efficiency and
   variability on a visual sustained attention task
SO AGING NEUROPSYCHOLOGY AND COGNITION
LA English
DT Article
DE Age-related hearing loss; cognitive decline; attention; cognitive load;
   neural arousal; executive functions
ID DEFICIT-HYPERACTIVITY-DISORDER; WORKING-MEMORY LOAD; OLDER-ADULTS;
   COGNITIVE FUNCTION; DEFICIT/HYPERACTIVITY DISORDER; SPEECH-PERCEPTION;
   LOCUS-COERULEUS; MOTOR CONTROL; DEFAULT-MODE; TERM-MEMORY
AB This study investigated the association between age-related hearing loss (ARHL) and differences in response efficiency and variability on a sustained attention task. The study population comprised 32 participants in a hearing loss group (HLG) and 34 controls without hearing loss (CG). Mean reaction time (RT) and accuracy were recorded to assess response efficiency. RT variability was decomposed to examine temporal aspects of variability associated with neural arousal and top-down executive control of vigilant attention. The HLG had a significantly longer mean RT, possibly reflecting a strategic approach to maintain accuracy. The HLG also demonstrated altered variability (indicative of greater decline in neural arousal) but maintained executive control that was significantly predictive of poorer response efficiency. Adults with ARHL may rely on higher-order attention networks to compensate for decline in both peripheral sensory function and in subcortical arousal systems which mediate lower-order automatic neurocognitive processes.
C1 [Loughrey, David G.; Lawlor, Brian A.] Trinity Coll Dublin, Global Brain Hlth Inst, Dublin, Ireland.
   [Loughrey, David G.; Lawlor, Brian A.] Univ Calif San Francisco, San Francisco, CA 94143 USA.
   [Mihelj, Ernest] Swiss Fed Inst Technol, Inst Human Movement Sci & Sport, Zurich, Switzerland.
   [Lawlor, Brian A.] St James Hosp, Mercers Inst Successful Ageing, Dublin, Ireland.
RP Loughrey, DG (corresponding author), Trinity Coll Dublin, Global Brain Hlth Inst, Dublin, Ireland.; Loughrey, DG (corresponding author), Univ Calif San Francisco, San Francisco, CA 94143 USA.
EM loughred@tcd.ie
FU Irish Research CouncilIrish Research Council for Science, Engineering
   and Technology
FX This work was supported by the Central Remedial Clinic;Irish Research
   Council; Chime.
CR Anstey KJ, 2007, NEUROPSYCHOLOGIA, V45, P1911, DOI 10.1016/j.neuropsychologia.2006.11.020
   Anticevic A, 2012, TRENDS COGN SCI, V16, P584, DOI 10.1016/j.tics.2012.10.008
   Baddeley AD, 2011, NEUROPSYCHOLOGIA, V49, P1393, DOI 10.1016/j.neuropsychologia.2010.12.042
   Bellgrove MA, 2005, NEUROPSYCHOLOGIA, V43, P1847, DOI 10.1016/j.neuropsychologia.2005.03.011
   Bidelman GM, 2014, NEUROBIOL AGING, V35, P2526, DOI 10.1016/j.neurobiolaging.2014.05.006
   Biederman J, 1999, BIOL PSYCHIAT, V46, P1234, DOI 10.1016/S0006-3223(99)00192-4
   Boyle PA, 2008, NEUROLOGY, V70, P1534, DOI 10.1212/01.wnl.0000304345.14212.38
   Bruce H, 2019, J GERONTOL B-PSYCHOL, V74, P275, DOI 10.1093/geronb/gbx047
   Budinger E, 2009, HEARING RES, V258, P16, DOI 10.1016/j.heares.2009.04.021
   Bunce D, 2007, NEUROPSYCHOLOGIA, V45, P2009, DOI 10.1016/j.neuropsychologia.2007.02.006
   BUYSSE DJ, 1989, PSYCHIAT RES, V28, P193, DOI 10.1016/0165-1781(89)90047-4
   Cabeza R, 2004, CEREB CORTEX, V14, P364, DOI 10.1093/cercor/bhg133
   Cabeza R, 2002, PSYCHOL AGING, V17, P85, DOI 10.1037//0882-7974.17.1.85
   Cabeza R, 2018, NAT REV NEUROSCI, V19, P701, DOI 10.1038/s41583-018-0068-2
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   Campbell J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00071
   Cappe C, 2009, HEARING RES, V258, P28, DOI 10.1016/j.heares.2009.04.017
   Carriere JSA, 2010, PSYCHOL AGING, V25, P569, DOI 10.1037/a0019363
   Castellanos FX, 2005, BIOL PSYCHIAT, V57, P1416, DOI 10.1016/j.biopsych.2004.12.005
   Chand GB, 2017, BRAIN CONNECT, V7, P401, DOI 10.1089/brain.2017.0509
   Classon E, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00241
   COHEN S, 1983, J HEALTH SOC BEHAV, V24, P385, DOI 10.2307/2136404
   Conroy RM, 2010, PSYCHOL HEALTH MED, V15, P463, DOI 10.1080/13548506.2010.487103
   Coull JT, 1998, PROG NEUROBIOL, V55, P343, DOI 10.1016/S0301-0082(98)00011-2
   Cousins KAQ, 2014, MEM COGNITION, V42, P622, DOI 10.3758/s13421-013-0377-7
   Crittenden B, 2015, ELIFE, V4, DOI 10.7554/eLife.06481
   Daselaar SM, 2003, BRAIN, V126, P43, DOI 10.1093/brain/awg005
   Daulatzai MA, 2016, NEUROTOX RES, V30, P295, DOI 10.1007/s12640-016-9643-3
   Dawes P, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119616
   Gierveld JD, 2006, RES AGING, V28, P582, DOI 10.1177/0164027506289723
   Deal JA, 2015, AM J EPIDEMIOL, V181, P680, DOI 10.1093/aje/kwu333
   Dennis N. A., 2011, THE HANDBOOK OF AGIN, P1
   Donoghue O, 2018, AM J GERIAT PSYCHIAT, V26, P438, DOI 10.1016/j.jagp.2017.11.006
   Dupuis K, 2015, AGING NEUROPSYCHOL C, V22, P413, DOI 10.1080/13825585.2014.968084
   Erb J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00116
   Fortenbaugh FC, 2017, ANN NY ACAD SCI, V1396, P70, DOI 10.1111/nyas.13318
   Fox MD, 2005, P NATL ACAD SCI USA, V102, P9673, DOI 10.1073/pnas.0504136102
   Gevonden M, 2014, JAMA PSYCHIAT, V71, P1364, DOI 10.1001/jamapsychiatry.2014.1325
   Gillingham SM, 2018, FRONT AGING NEUROSCI, V10, DOI 10.3389/fnagi.2018.00351
   Giroud N, 2017, HEARING RES, V353, P162, DOI 10.1016/j.heares.2017.06.012
   Grady C, 2012, NAT REV NEUROSCI, V13, P491, DOI 10.1038/nrn3256
   GRADY CL, 1994, J NEUROSCI, V14, P1450
   GROBER E, 1988, NEUROLOGY, V38, P900, DOI 10.1212/WNL.38.6.900
   Gutchess AH, 2005, J COGNITIVE NEUROSCI, V17, P84, DOI 10.1162/0898929052880048
   Harley C, 2009, GAIT POSTURE, V29, P428, DOI 10.1016/j.gaitpost.2008.10.063
   Haynes BI, 2017, J INT NEUROPSYCH SOC, V23, P431, DOI 10.1017/S1355617717000236
   Heald SLM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00035
   Hearne L, 2015, HUM BRAIN MAPP, V36, P2719, DOI 10.1002/hbm.22802
   HODDES E, 1972, PSYCHOPHYSIOLOGY, V9, P150
   Humes LE, 2007, J AM ACAD AUDIOL, V18, P590, DOI 10.3766/jaaa.18.7.6
   Johnson JK, 2007, J GERONTOL A-BIOL, V62, P1134, DOI 10.1093/gerona/62.10.1134
   Johnson KA, 2007, NEUROPSYCHOLOGIA, V45, P2234, DOI 10.1016/j.neuropsychologia.2007.02.019
   Johnson KA, 2007, NEUROPSYCHOLOGIA, V45, P630, DOI 10.1016/j.neuropsychologia.2006.03.034
   Joshi S, 2016, NEURON, V89, P221, DOI 10.1016/j.neuron.2015.11.028
   Kaplan E, 2001, BOSTON NAMING TEST
   Kelly AMC, 2008, NEUROIMAGE, V39, P527, DOI 10.1016/j.neuroimage.2007.08.008
   Klemen J, 2010, J COGNITIVE NEUROSCI, V22, P437, DOI 10.1162/jocn.2009.21204
   Koelewijn T, 2014, J ACOUST SOC AM, V135, P1596, DOI 10.1121/1.4863198
   Kuchinsky SE, 2016, EXP AGING RES, V42, P64, DOI 10.1080/0361073X.2016.1108712
   Langner R, 2013, PSYCHOL BULL, V139, P870, DOI 10.1037/a0030694
   LEZAK MD, 2004, NEUROPSYCHOLOGICAL A
   Lin FR, 2014, NEUROIMAGE, V90, P84, DOI 10.1016/j.neuroimage.2013.12.059
   Lin FR, 2014, AGING MENT HEALTH, V18, P671, DOI 10.1080/13607863.2014.915924
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Lin FR, 2012, ARCH INTERN MED, V172, P369, DOI 10.1001/archinternmed.2011.728
   Lin FR, 2011, NEUROPSYCHOLOGY, V25, P763, DOI 10.1037/a0024238
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P1131, DOI 10.1093/gerona/glr115
   Lin FR, 2011, ARCH NEUROL-CHICAGO, V68, P214, DOI 10.1001/archneurol.2010.362
   LINDENBERGER U, 1994, PSYCHOL AGING, V9, P339, DOI 10.1037/0882-7974.9.3.339
   Lindenberger U, 2000, PSYCHOL AGING, V15, P417, DOI 10.1037//0882-7974.15.3.417
   Livingston G, 2017, LANCET, V390, P2673, DOI 10.1016/S0140-6736(17)31363-6
   Lovden M, 2008, J GERONTOL B-PSYCHOL, V63, pP121
   Loring DW, 2003, HDB REY OSTERRIETH C, P313
   Loughrey D.G., 2018, THESIS
   Loughrey DG, 2020, EXP GERONTOL, V130, DOI 10.1016/j.exger.2019.110794
   Loughrey DG, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49023-1
   Loughrey DG, 2018, JAMA OTOLARYNGOL, V144, P115, DOI 10.1001/jamaoto.2017.2513
   Lubben J, 2006, GERONTOLOGIST, V46, P503, DOI 10.1093/geront/46.4.503
   Manly T, 2003, NEUROCASE, V9, P340, DOI 10.1076/neur.9.4.340.15553
   MARIN RS, 1991, PSYCHIAT RES, V38, P143, DOI 10.1016/0165-1781(91)90040-V
   McCoy SL, 2005, Q J EXP PSYCHOL-A, V58, P22, DOI 10.1080/02724980443000151
   McGarrigle R, 2017, PSYCHOPHYSIOLOGY, V54, P193, DOI 10.1111/psyp.12772
   MEADOR KJ, 1993, J CLIN EXP NEUROPSYC, V15, P832, DOI 10.1080/01688639308402599
   Mozolic JL, 2008, BMC NEUROL, V8, DOI 10.1186/1471-2377-8-35
   Murphy PR, 2014, HUM BRAIN MAPP, V35, P4140, DOI 10.1002/hbm.22466
   Murphy PR, 2011, PSYCHOPHYSIOLOGY, V48, P1531, DOI 10.1111/j.1469-8986.2011.01226.x
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Nelson H., 1982, NATL ADULT READING T
   Noesselt T, 2010, J NEUROSCI, V30, P13609, DOI 10.1523/JNEUROSCI.4524-09.2010
   Nunez A, 2007, ADV ANAT EMBRYOL CEL, V187, P1
   O'Halloran AM, 2014, J GERONTOL B-PSYCHOL, V69, P147, DOI 10.1093/geronb/gbt009
   O'Halloran AM, 2011, BMC GERIATR, V11, DOI 10.1186/1471-2318-11-85
   Panza F, 2015, NAT REV NEUROL, V11
   Park DC, 2004, P NATL ACAD SCI USA, V101, P13091, DOI 10.1073/pnas.0405148101
   Paus T, 2001, NAT REV NEUROSCI, V2, P417, DOI 10.1038/35077500
   Paus T, 1997, J COGNITIVE NEUROSCI, V9, P392, DOI 10.1162/jocn.1997.9.3.392
   Peelle JE, 2016, TRENDS NEUROSCI, V39, P486, DOI 10.1016/j.tins.2016.05.001
   Peelle JE, 2011, J NEUROSCI, V31, P12638, DOI 10.1523/JNEUROSCI.2559-11.2011
   RADLOFF L S, 1977, Applied Psychological Measurement, V1, P385, DOI 10.1177/014662167700100306
   Regenbogen C, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0052267
   Reuter-Lorenz PA, 2000, J COGNITIVE NEUROSCI, V12, P174, DOI 10.1162/089892900561814
   Robertson IH, 2014, NEUROBIOL AGING, V35, P1375, DOI 10.1016/j.neurobiolaging.2013.11.028
   Robertson IH, 2013, NEUROBIOL AGING, V34, P298, DOI 10.1016/j.neurobiolaging.2012.05.019
   Robertson IH, 1997, NEUROPSYCHOLOGIA, V35, P747, DOI 10.1016/S0028-3932(97)00015-8
   Romero-Ortuno R, 2010, BMC GERIATR, V10, DOI 10.1186/1471-2318-10-57
   Ronnberg J, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00326
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2011, J SPEECH LANG HEAR R, V54, P705, DOI 10.1044/1092-4388(2010/09-0088)
   Rosen AC, 2002, NEUROREPORT, V13, P2425, DOI 10.1097/00001756-200212200-00010
   ROTH M, 1986, BRIT J PSYCHIAT, V149, P698, DOI 10.1192/bjp.149.6.698
   Sonuga-Barke EJS, 2007, NEUROSCI BIOBEHAV R, V31, P977, DOI 10.1016/j.neubiorev.2007.02.005
   Sowell ER, 2003, NAT NEUROSCI, V6, P309, DOI 10.1038/nn1008
   Stern Y, 2012, LANCET NEUROL, V11, P1006, DOI 10.1016/S1474-4422(12)70191-6
   Stern Y, 2009, NEUROPSYCHOLOGIA, V47, P2015, DOI 10.1016/j.neuropsychologia.2009.03.004
   Stock AK, 2016, HUM BRAIN MAPP, V37, P4511, DOI 10.1002/hbm.23325
   Sturm W, 1999, NEUROPSYCHOLOGIA, V37, P797, DOI 10.1016/S0028-3932(98)00141-9
   Stuss DT, 2003, BRAIN, V126, P2363, DOI 10.1093/brain/awg237
   Townsend J. T., 1978, COGNITIVE THEORY, V3, P200
   Tun PA, 2009, PSYCHOL AGING, V24, P761, DOI 10.1037/a0014802
   Uchida Y, 2019, AURIS NASUS LARYNX, V46, P1, DOI 10.1016/j.anl.2018.08.010
   Van der Werf YD, 2002, BRAIN RES REV, V39, P107, DOI 10.1016/S0165-0173(02)00181-9
   Vaughan RM, 2016, J INT NEUROPSYCH SOC, V22, P570, DOI 10.1017/S1355617716000291
   Ventry I M, 1983, ASHA, V25, P37
   Viljanen A, 2009, J AM GERIATR SOC, V57, P2282, DOI 10.1111/j.1532-5415.2009.02553.x
   Walhovd KB, 2007, NEUROPSYCHOLOGIA, V45, P2277, DOI 10.1016/j.neuropsychologia.2007.02.022
   Wang X, 2014, PLOS ONE, V9, P5, DOI DOI 10.1371/J0URNAL.P0NE.0097265
   Wayne RV, 2015, AGEING RES REV, V23, P154, DOI 10.1016/j.arr.2015.06.002
   Wechsler DA, 1997, WECHSLER MEMORY SCAL
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
   Woollacott M, 2002, GAIT POSTURE, V16, P1, DOI 10.1016/S0966-6362(01)00156-4
   World Health Organization-WHO, 2018, DEAFN HEAR LOSS
   Xu XM, 2019, J MAGN RESON IMAGING, V50, P787, DOI 10.1002/jmri.26665
   Zekveld AA, 2011, EAR HEARING, V32, P498, DOI 10.1097/AUD.0b013e31820512bb
   Zhang YY, 2018, BRAIN BEHAV, V8, DOI 10.1002/brb3.912
   ZIGMOND AS, 1983, ACTA PSYCHIAT SCAND, V67, P361, DOI 10.1111/j.1600-0447.1983.tb09716.x
NR 135
TC 0
Z9 0
U1 0
U2 2
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1382-5585
EI 1744-4128
J9 AGING NEUROPSYCHOL C
JI Aging Neuropsychol. Cogn.
PD JAN 2
PY 2021
VL 28
IS 1
BP 1
EP 25
DI 10.1080/13825585.2019.1704393
EA DEC 2019
PG 25
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA PH5GL
UT WOS:000503961200001
PM 31868123
DA 2021-02-24
ER

PT J
AU Gao, X
   Yan, TT
   Tang, DL
   Huang, T
   Shu, H
   Nan, Y
   Zhang, YX
AF Gao, Xiang
   Yan, Ting-Ting
   Tang, Ding-Lan
   Huang, Ting
   Shu, Hua
   Nan, Yun
   Zhang, Yu-Xuan
TI What Makes Lexical Tone Special: A Reverse Accessing Model for Tonal
   Speech Perception
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE speech perception model; lexical tone; phonological processing; tonal
   language; Mandarin Chinese
ID SPOKEN WORD RECOGNITION; WORKING-MEMORY; MANDARIN; CHINESE; INFORMATION;
   ACTIVATION; ERP
AB Previous studies of tonal speech perception have generally suggested harder or later access to lexical tone than segmental information, but the mechanism underlying the lexical tone disadvantage is unclear. Using a speeded discrimination paradigm free of context information, we confirmed multiple lines of evidence for the lexical tone disadvantage as well as revealed a distinctive advantage of word and atonal syllable judgments over phoneme and lexical tone judgments. The results led us to propose a Reverse Accessing Model (RAM) for tonal speech perception. The RAM is an extension of the influential TRACE model, with two additional processing levels specialized for tonal speech: lexical tone and atonal syllable. Critically, information accessing is assumed to be in reverse order of information processing, and only information at the syllable level and up is maintained active for immediate use. We tested and confirmed the predictions of the RAM on discrimination of each type of phonological component under different stimulus conditions. The current results have thus demonstrated the capability of the RAM as a general framework for tonal speech perception to provide a united account for empirical observations as well as to generate testable predictions.
C1 [Gao, Xiang; Yan, Ting-Ting; Tang, Ding-Lan; Huang, Ting; Shu, Hua; Nan, Yun; Zhang, Yu-Xuan] Beijing Normal Univ, State Key Lab Cognit Neurosci & Learning, IDG McGovern Inst Brain Res, Beijing, Peoples R China.
RP Zhang, YX (corresponding author), Beijing Normal Univ, State Key Lab Cognit Neurosci & Learning, IDG McGovern Inst Brain Res, Beijing, Peoples R China.
EM zhangyuxuan@bnu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [31300935]; State Key Development Program for
   Basic Research of ChinaState Key Development Program for Basic Research
   of China [2014CB846101]
FX The study was supported by National Natural Science Foundation of China
   31300935 and State Key Development Program for Basic Research of China
   2014CB846101.
CR Baddeley A, 2003, NAT REV NEUROSCI, V4, P829, DOI 10.1038/nrn1201
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Brown-Schmidt S, 2004, J PSYCHOLINGUIST RES, V33, P103, DOI 10.1023/B:JOPR.0000017223.98667.10
   Casserly ED, 2010, WIRES COGN SCI, V1, P629, DOI 10.1002/wcs.63
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Chen TM, 2013, PSYCHON B REV, V20, P154, DOI 10.3758/s13423-012-0326-7
   Cutler A, 1997, PERCEPT PSYCHOPHYS, V59, P165, DOI 10.3758/BF03211886
   Hannagan T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00563
   Kleiner M, 2007, PERCEPTION, V36, P14
   Lia XQ, 2008, BRAIN RES, V1222, P192, DOI 10.1016/j.brainres.2008.05.031
   Liu SY, 2007, LANG COGNITIVE PROC, V22, P566, DOI 10.1080/01690960600989600
   MacGregor LJ, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms1715
   Malins JG, 2012, NEUROPSYCHOLOGIA, V50, P2032, DOI 10.1016/j.neuropsychologia.2012.05.002
   Malins JG, 2010, J MEM LANG, V62, P407, DOI 10.1016/j.jml.2010.02.004
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MELARA RD, 1990, J EXP PSYCHOL HUMAN, V16, P398, DOI 10.1037/0096-1523.16.2.398
   O'Seaghdha PG, 2010, COGNITION, V115, P282, DOI 10.1016/j.cognition.2010.01.001
   Oberauer K, 2013, COGNITIVE PSYCHOL, V66, P157, DOI 10.1016/j.cogpsych.2012.11.001
   REPP BH, 1990, J PHONETICS, V18, P481, DOI 10.1016/S0095-4470(19)30410-3
   Roll M, 2015, BRAIN LANG, V150, P14, DOI 10.1016/j.bandl.2015.07.009
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   Schirmer A, 2005, J COGNITIVE NEUROSCI, V17, P1, DOI 10.1162/0898929052880057
   Schremm A, 2018, BRAIN LANG, V176, P42, DOI 10.1016/j.bandl.2017.12.001
   Shuai L, 2017, BEHAV RES METHODS, V49, P230, DOI 10.3758/s13428-015-0690-0
   Shuai L, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00097
   Si XP, 2017, P NATL ACAD SCI USA, V114, P12303, DOI 10.1073/pnas.1710752114
   Soderstrom P, 2017, BRAIN LANG, V174, P119, DOI 10.1016/j.bandl.2017.08.004
   Soto-Faraco S, 2001, J MEM LANG, V45, P412, DOI 10.1006/jmla.2000.2783
   Taft M., 1992, LANGUAGE PROCESSING, V90, P151, DOI DOI 10.1016/S0166-4115(08)61891-9
   Tang W, 2016, NEUROPSYCHOLOGIA, V91, P247, DOI 10.1016/j.neuropsychologia.2016.08.003
   Tong YX, 2008, LANG COGNITIVE PROC, V23, P689, DOI 10.1080/01690960701728261
   Wewalaarachchi TD, 2020, J EXP CHILD PSYCHOL, V189, DOI 10.1016/j.jecp.2019.104698
   Wiener S, 2016, LANG SPEECH, V59, P59, DOI 10.1177/0023830915578000
   Ye Y, 1999, LANG COGNITIVE PROC, V14, P609, DOI 10.1080/016909699386202
   Yip MCW, 2002, PSYCHOL REP, V90, P338, DOI 10.2466/PR0.90.1.338-340
   Yu KK, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00729
NR 36
TC 1
Z9 1
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD DEC 18
PY 2019
VL 10
AR 2830
DI 10.3389/fpsyg.2019.02830
PG 15
WC Psychology, Multidisciplinary
SC Psychology
GA JZ3UZ
UT WOS:000505028100001
PM 31920863
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU O'Sullivan, J
   Herrero, J
   Smith, E
   Schevon, C
   McKhann, GM
   Sheth, SA
   Mehta, AD
   Mesgarani, N
AF O'Sullivan, James
   Herrero, Jose
   Smith, Elliot
   Schevon, Catherine
   McKhann, Guy M.
   Sheth, Sameer A.
   Mehta, Ashesh D.
   Mesgarani, Nima
TI Hierarchical Encoding of Attended Auditory Objects in Multi-talker
   Speech Perception
SO NEURON
LA English
DT Article
ID SPECTROTEMPORAL RECEPTIVE-FIELDS; TASK-RELATED PLASTICITY; CORTICAL
   REPRESENTATION; COCKTAIL PARTY; COMPLEX SOUNDS; HUMAN CORE; CORTEX;
   ORGANIZATION; EMERGENCE; FEATURES
AB Humans can easily focus on one speaker in a multi-talker acoustic environment, but how different areas of the human auditory cortex (AC) represent the acoustic components of mixed speech is unknown. We obtained invasive recordings from the primary and nonprimary AC in neurosurgical patients as they listened to multi-talker speech. We found that neural sites in the primary AC responded to individual speakers in the mixture and were relatively unchanged by attention. In contrast, neural sites in the nonprimary AC were less discerning of individual speakers but selectively represented the attended speaker. Moreover, the encoding of the attended speaker in the nonprimary AC was invariant to the degree of acoustic overlap with the unattended speaker. Finally, this emergent representation of attended speech in the nonprimary AC was linearly predictable from the primary AC responses. Our results reveal the neural computations underlying the hierarchical formation of auditory objects in human AC during multi-talker speech perception.
C1 [O'Sullivan, James; Mesgarani, Nima] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
   [Smith, Elliot; Schevon, Catherine; McKhann, Guy M.; Sheth, Sameer A.] Neurol Inst, Dept Neurol Surg, 710 W 168Th St, New York, NY 10032 USA.
   [Herrero, Jose; Mehta, Ashesh D.] Hofstra Northwell Sch Med, Dept Neurosurg, Manhasset, NY USA.
   [Herrero, Jose; Mehta, Ashesh D.] Feinstein Inst Med Res, Manhasset, NY USA.
   [Smith, Elliot] Univ Utah, Dept Neurosurg, Salt Lake City, UT USA.
   [Sheth, Sameer A.] Baylor Coll Med, Dept Neurosurg, Houston, TX 77030 USA.
RP Mesgarani, N (corresponding author), Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
EM nima@ee.columbia.edu
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [NIDCD-DC014279, S10 OD018211]; Pew
   Charitable Trusts, Pew Biomedical Scholars Program
FX This work was funded by a grant from the NIH, NIDCD-DC014279, S10
   OD018211, and the Pew Charitable Trusts, Pew Biomedical Scholars
   Program.
CR Akbari H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37359-z
   Atiani S, 2014, NEURON, V82, P486, DOI 10.1016/j.neuron.2014.02.029
   Atiani S, 2009, NEURON, V61, P467, DOI 10.1016/j.neuron.2008.12.027
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Bizley JK, 2013, NAT REV NEUROSCI, V14, P693, DOI 10.1038/nrn3565
   Bizley JK, 2013, CURR BIOL, V23, P620, DOI 10.1016/j.cub.2013.03.003
   Bizley JK, 2009, J NEUROSCI, V29, P2064, DOI 10.1523/JNEUROSCI.4755-08.2009
   Bouchard KE, 2013, NATURE, V495, P327, DOI 10.1038/nature11911
   Brodbeck C, 2018, CURR BIOL, V28, P3976, DOI 10.1016/j.cub.2018.10.042
   Broderick MP, 2018, CURR BIOL, V28, P803, DOI 10.1016/j.cub.2018.01.080
   Brungart DS, 2001, J ACOUST SOC AM, V110, P2527, DOI 10.1121/1.1408946
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Chi T, 2005, J ACOUST SOC AM, V118, P887, DOI 10.1121/1.1945807
   Clarke CA, 2012, POLICE ORGANIZATION AND TRAINING: INNOVATIONS IN RESEARCH AND PRACTICE, P11, DOI 10.1007/978-1-4614-0745-4_2
   David SV, 2012, P NATL ACAD SCI USA, V109, P2144, DOI 10.1073/pnas.1117717109
   de Heer WA, 2017, J NEUROSCI, V37, P6539, DOI 10.1523/JNEUROSCI.3267-16.2017
   De Martino F, 2015, CEREB CORTEX, V25, P3394, DOI 10.1093/cercor/bhu150
   Destrieux C, 2010, NEUROIMAGE, V53, P1, DOI 10.1016/j.neuroimage.2010.06.010
   Di Liberto GM, 2019, NEUROIMAGE, V196, P237, DOI 10.1016/j.neuroimage.2019.04.037
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Dykstra AR, 2012, NEUROIMAGE, V59, P3563, DOI 10.1016/j.neuroimage.2011.11.046
   Elhilali M, 2009, PLOS BIOL, V7, DOI 10.1371/journal.pbio.1000129
   Fedorenko E, 2016, P NATL ACAD SCI USA, V113, pE6256, DOI 10.1073/pnas.1612132113
   Fischl B, 2004, CEREB CORTEX, V14, P11, DOI 10.1093/cercor/bhg087
   Fischl B, 1999, NEUROIMAGE, V9, P195, DOI 10.1006/nimg.1998.0396
   Flinker A, 2019, NAT HUM BEHAV, V3, P393, DOI 10.1038/s41562-019-0548-z
   Fontolan L, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5694
   Fritz J, 2003, NAT NEUROSCI, V6, P1216, DOI 10.1038/nn1141
   Gibson J. J., 2014, ECOLOGICAL APPROACH
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Groppe DM, 2017, J NEUROSCI METH, V281, P40, DOI 10.1016/j.jneumeth.2017.01.022
   Hackett TA, 2001, J COMP NEUROL, V441, P197, DOI 10.1002/cne.1407
   Hackett TA, 2008, J AM ACAD AUDIOL, V19, P774, DOI 10.3766/jaaa.19.10.5
   Hamilton LS, 2018, CURR BIOL, V28, P1860, DOI 10.1016/j.cub.2018.04.033
   Han C, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aav6134
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hill KT, 2010, CEREB CORTEX, V20, P583, DOI 10.1093/cercor/bhp124
   Huth AG, 2016, NATURE, V532, P453, DOI 10.1038/nature17637
   Keller CJ, 2014, J NEUROSCI, V34, P9152, DOI 10.1523/JNEUROSCI.4289-13.2014
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Khalighinejad B, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10611-4
   Khalighinejad B, 2017, INT CONF ACOUST SPEE, P846, DOI 10.1109/ICASSP.2017.7952275
   Khodagholy D, 2015, NAT NEUROSCI, V18, P310, DOI 10.1038/nn.3905
   Kilian-Hutten N, 2011, J NEUROSCI, V31, P1715, DOI 10.1523/JNEUROSCI.4572-10.2011
   King AJ, 2009, NAT NEUROSCI, V12, P698, DOI 10.1038/nn.2308
   Krishnan L, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003985
   Leaver AM, 2010, J NEUROSCI, V30, P7604, DOI 10.1523/JNEUROSCI.0296-10.2010
   Lee AKC, 2014, HEARING RES, V307, P111, DOI 10.1016/j.heares.2013.06.010
   Leonard MK, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13619
   Leonard MK, 2015, J NEUROSCI, V35, P7203, DOI 10.1523/JNEUROSCI.4100-14.2015
   Linden JF, 2003, J NEUROPHYSIOL, V90, P2660, DOI 10.1152/jn.00751.2002
   Luo Y, 2019, IEEE-ACM T AUDIO SPE, V27, P1256, DOI 10.1109/TASLP.2019.2915167
   Mesgarani N., 2009, P INT 09, V9, P2983
   Mesgarani N, 2008, J ACOUST SOC AM, V123, P899, DOI 10.1121/1.2816572
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Mesgarani N, 2010, J COMPUT NEUROSCI, V28, P19, DOI 10.1007/s10827-009-0181-3
   Mesgarani N, 2009, J NEUROPHYSIOL, V102, P3329, DOI 10.1152/jn.91128.2008
   Miller LM, 2001, NEURON, V32, P151, DOI 10.1016/S0896-6273(01)00445-7
   Miller LM, 2002, J NEUROPHYSIOL, V87, P516, DOI 10.1152/jn.00395.2001
   Moerel M, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00225
   Molenberghs P, 2007, CEREB CORTEX, V17, P2703, DOI 10.1093/cercor/bhl179
   Morosan P, 2001, NEUROIMAGE, V13, P684, DOI 10.1006/nimg.2000.0715
   Nelson MJ, 2017, P NATL ACAD SCI USA, V114, pE3669, DOI 10.1073/pnas.1701590114
   Nourski KV, 2019, HEARING RES, V371, P53, DOI 10.1016/j.heares.2018.11.009
   Nourski KV, 2017, LARYNGOSCOPE INVEST, V2, P147, DOI 10.1002/lio2.73
   Nourski KV, 2017, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00691
   Nourski KV, 2015, INT J PSYCHOPHYSIOL, V95, P191, DOI 10.1016/j.ijpsycho.2014.03.006
   O'Sullivan J, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa7ab4
   O'Sullivan JA, 2015, J NEUROSCI, V35, P7256, DOI 10.1523/JNEUROSCI.4973-14.2015
   Obleser J, 2007, CEREB CORTEX, V17, P2251, DOI 10.1093/cercor/bhl133
   Papademetris Xenophon, 2006, Insight J, V2006, P209
   Patel P, 2018, CELL REP, V24, P2051, DOI 10.1016/j.celrep.2018.07.076
   Petkov CI, 2004, NAT NEUROSCI, V7, P658, DOI 10.1038/nn1256
   Power AJ, 2012, EUR J NEUROSCI, V35, P1497, DOI 10.1111/j.1460-9568.2012.08060.x
   Puschmann S., 2018, CEREB CORTEX
   Puvvada KC, 2017, J NEUROSCI, V37, P9189, DOI 10.1523/JNEUROSCI.0938-17.2017
   RADEMACHER J, 1993, CEREB CORTEX, V3, P313, DOI 10.1093/cercor/3.4.313
   Rasmussen G.L., 1964, NEUROL ASP AUDIT VES, V1, P5
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rauschecker JP, 1997, ACTA OTO-LARYNGOL, P34
   Salmi J, 2009, BRAIN RES, V1286, P155, DOI 10.1016/j.brainres.2009.06.083
   Santoro R, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003412
   Shamma S, 2008, PLOS BIOL, V6, P1141, DOI 10.1371/journal.pbio.0060155
   Shamma SA, 2011, TRENDS NEUROSCI, V34, P114, DOI 10.1016/j.tins.2010.11.002
   Shinn-Cunningham BG, 2008, TRENDS COGN SCI, V12, P182, DOI 10.1016/j.tics.2008.02.003
   Slee SJ, 2015, J NEUROSCI, V35, P13090, DOI 10.1523/JNEUROSCI.1671-15.2015
   Steinschneider M, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00240
   Steinschneider M, 2013, HEARING RES, V305, P57, DOI 10.1016/j.heares.2013.05.013
   Teki S, 2016, CEREB CORTEX, V26, P3669, DOI 10.1093/cercor/bhw173
   Thakur CS, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00309
   Theunissen FE, 2000, J NEUROSCI, V20, P2315
   Walker KMM, 2011, J NEUROSCI, V31, P14565, DOI 10.1523/JNEUROSCI.2074-11.2011
   Webster D.B., 2013, MAMMALIAN AUDITORY P
   Yi Luo, 2018, IEEE/ACM Transactions on Audio, Speech and Language Processing, V26, P787, DOI 10.1109/TASLP.2018.2795749
NR 96
TC 13
Z9 13
U1 3
U2 10
PU CELL PRESS
PI CAMBRIDGE
PA 50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA
SN 0896-6273
EI 1097-4199
J9 NEURON
JI Neuron
PD DEC 18
PY 2019
VL 104
IS 6
BP 1195
EP +
DI 10.1016/j.neuron.2019.09.007
PG 18
WC Neurosciences
SC Neurosciences & Neurology
GA JW9RM
UT WOS:000503383000018
PM 31648900
OA Bronze
DA 2021-02-24
ER

PT J
AU Sket, GM
   Overfeld, J
   Styner, M
   Gilmore, JH
   Entringer, S
   Wadhwa, PD
   Rasmussen, JM
   Buss, C
AF Sket, Georgina M.
   Overfeld, Judith
   Styner, Martin
   Gilmore, John H.
   Entringer, Sonja
   Wadhwa, Pathik D.
   Rasmussen, Jerod M.
   Buss, Claudia
TI Neonatal White Matter Maturation Is Associated With Infant Language
   Development
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE white matter development; infant language development; diffusion tensor
   imaging; receptive language development; neonatal neuroimaging
ID CORPUS-CALLOSUM; MATERNAL DEPRESSION; BRAIN CONNECTIVITY;
   SPEECH-PERCEPTION; SEX-DIFFERENCES; MICROSTRUCTURE; CHILDHOOD; EXPOSURE;
   CHILDREN; COMMUNICATION
AB Background While neonates have no sophisticated language skills, the neural basis for acquiring this function is assumed to already be present at birth. Receptive language is measurable by 6 months of age and meaningful speech production by 10-18 months of age. Fiber tracts supporting language processing include the corpus callosum (CC), which plays a key role in the hemispheric lateralization of language; the left arcuate fasciculus (AF), which is associated with syntactic processing; and the right AF, which plays a role in prosody and semantics. We examined if neonatal maturation of these fiber tracts is associated with receptive language development at 12 months of age. Methods Diffusion-weighted imaging (DWI) was performed in 86 infants at 26.6 +/- 12.2 days post-birth. Receptive language was assessed via the MacArthur-Bates Communicative Development Inventory at 12 months of age. Tract-based fractional anisotropy (FA) was determined using the NA-MIC atlas-based fiber analysis toolkit. Associations between neonatal regional FA, adjusted for gestational age at birth and age at scan, and language development at 12 months of age were tested using ANOVA models. Results After multiple comparisons correction, higher neonatal FA was positively associated with receptive language at 12 months of age within the genu (p < 0.001), rostrum (p < 0.001), and tapetum (p < 0.001) of the CC and the left fronto-parietal AF (p = 0.008). No significant clusters were found in the right AF. Conclusion Microstructural development of the CC and the AF in the newborn is associated with receptive language at 12 months of age, demonstrating that interindividual variation in white matter microstructure is relevant for later language development, and indicating that the neural foundation for language processing is laid well ahead of the majority of language acquisition. This suggests that some origins of impaired language development may lie in the intrauterine and potentially neonatal period of life. Understanding how interindividual differences in neonatal brain maturity relate to the acquisition of function, particularly during early development when the brain is in an unparalleled window of plasticity, is key to identifying opportunities for harnessing neuroplasticity in health and disease.
C1 [Sket, Georgina M.; Overfeld, Judith; Entringer, Sonja; Buss, Claudia] Charite Univ Med Berlin, Berlin Inst Hlth, Dept Med Psychol, Freie Univ Berlin,Humboldt Univ Berlin, Berlin, Germany.
   [Styner, Martin; Gilmore, John H.] Univ North Carolina Chapel Hill, Dept Psychiat, Chapel Hill, NC USA.
   [Entringer, Sonja; Wadhwa, Pathik D.; Rasmussen, Jerod M.; Buss, Claudia] Univ Calif Irvine, Dev Hlth & Dis Res Program, Orange, CA 92668 USA.
RP Buss, C (corresponding author), Charite Univ Med Berlin, Berlin Inst Hlth, Dept Med Psychol, Freie Univ Berlin,Humboldt Univ Berlin, Berlin, Germany.; Buss, C (corresponding author), Univ Calif Irvine, Dev Hlth & Dis Res Program, Orange, CA 92668 USA.
EM claudia.buss@charite.de
RI Entringer, Sonja/ABB-9405-2020; Buss, Claudia/ABC-3687-2020; Styner,
   Martin/AAS-9949-2020
OI Styner, Martin/0000-0002-8747-5118
FU U.S. Public Health Service (National Institutes of Health)United States
   Public Health ServiceUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01 MH-091351, R01
   MH-105538, R01 HD-060628, UG3 OD-O23349]
FX This research was supported by the U.S. Public Health Service (National
   Institutes of Health) grants R01 MH-091351, R01 MH-105538, R01
   HD-060628, and UG3 OD-O23349 (all to PW and CB).
CR ALAGHBANDRAD J, 1995, J AM ACAD CHILD PSY, V34, P1273, DOI 10.1097/00004583-199510000-00012
   Astington JW, 1999, DEV PSYCHOL, V35, P1311, DOI 10.1037/0012-1649.35.5.1311
   Azak S, 2012, INFANT BEHAV DEV, V35, P803, DOI 10.1016/j.infbeh.2012.07.017
   BENASICH AA, 1993, J AM ACAD CHILD PSY, V32, P585, DOI 10.1097/00004583-199305000-00015
   Bloom JS, 2005, NEUROPSYCHOL REV, V15, P59, DOI 10.1007/s11065-005-6252-y
   BRODY BA, 1987, J NEUROPATH EXP NEUR, V46, P283, DOI 10.1097/00005072-198705000-00005
   Caldwell B. M., 1984, HOME OBSERVATION MEA
   Catani M, 2008, CORTEX, V44, P1105, DOI 10.1016/j.cortex.2008.05.004
   Charman T, 2003, J CHILD LANG, V30, P213, DOI 10.1017/S0305000902005482
   Crump KS, 1998, RISK ANAL, V18, P701, DOI 10.1023/B:RIAN.0000005917.52151.e6
   Donahue M., 1986, HDB COGNITIVE SOCIAL, V1, P263
   Douet V, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00343
   Dubois J, 2014, NEUROSCIENCE, V276, P48, DOI 10.1016/j.neuroscience.2013.12.044
   Dubois J, 2008, HUM BRAIN MAPP, V29, P14, DOI 10.1002/hbm.20363
   Fensen L., 1993, MACARTHUR BATES COMM
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   Geng XJ, 2012, NEUROIMAGE, V61, P542, DOI 10.1016/j.neuroimage.2012.03.057
   Girault JB, 2019, HUM BRAIN MAPP, V40, P1195, DOI 10.1002/hbm.24439
   Graham AM, 2018, BIOL PSYCHIAT, V83, P109, DOI 10.1016/j.biopsych.2017.05.027
   GREENE T, 1990, ALCOHOL CLIN EXP RES, V14, P937, DOI 10.1111/j.1530-0277.1990.tb01842.x
   Heim CM, 2019, PSYCHONEUROENDOCRINO, V105, P123, DOI 10.1016/j.psyneuen.2018.12.011
   Hinkley LBN, 2016, J NEUROSCI, V36, P4522, DOI 10.1523/JNEUROSCI.3850-14.2016
   HUTTENLOCHER J, 1991, DEV PSYCHOL, V27, P236, DOI 10.1037/0012-1649.27.2.236
   Joshi S, 2004, NEUROIMAGE, V23, pS151, DOI 10.1016/j.neuroimage.2004.07.068
   Kaplan PS, 2014, INFANT BEHAV DEV, V37, P398, DOI 10.1016/j.infbeh.2014.05.008
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   Langer N, 2017, CEREB CORTEX, V27, P1027, DOI 10.1093/cercor/bhv281
   Laplante DP, 2004, PEDIATR RES, V56, P400, DOI 10.1203/01.PDR.0000136281.34035.44
   Lebel C, 2009, HUM BRAIN MAPP, V30, P3563, DOI 10.1002/hbm.20779
   Lewis BA, 2011, NEUROTOXICOL TERATOL, V33, P17, DOI 10.1016/j.ntt.2010.06.006
   Liu ZX, 2010, PROC SPIE, V7628, DOI 10.1117/12.844748
   Locke JL, 1997, BRAIN LANG, V58, P265, DOI 10.1006/brln.1997.1791
   Luders E, 2010, J NEUROSCI, V30, P10985, DOI 10.1523/JNEUROSCI.5122-09.2010
   Mahmoudzadeh M, 2013, P NATL ACAD SCI USA, V110, P4846, DOI 10.1073/pnas.1212220110
   Matthews M, 2015, J CHILD PSYCHOL PSYC, V56, P400, DOI 10.1111/jcpp.12335
   McGrath JM, 2008, INFANT BEHAV DEV, V31, P71, DOI 10.1016/j.infbeh.2007.07.001
   Mitchell S, 2006, J DEV BEHAV PEDIATR, V27, pS69, DOI 10.1097/00004703-200604002-00004
   Moog NK, 2017, NEUROSCIENCE, V342, P68, DOI 10.1016/j.neuroscience.2015.09.070
   Morrow CE, 2003, J DEV BEHAV PEDIATR, V24, P39, DOI 10.1097/00004703-200302000-00009
   O'Muircheartaigh J, 2013, J NEUROSCI, V33, P16170, DOI 10.1523/JNEUROSCI.1463-13.2013
   Oguz I, 2014, FRONT NEUROINFORM, V8, DOI 10.3389/fninf.2014.00004
   Peters BD, 2014, BIOL PSYCHIAT, V75, P248, DOI 10.1016/j.biopsych.2013.05.020
   Pineda RG, 2014, J PEDIATR-US, V164, P52, DOI 10.1016/j.jpeds.2013.08.047
   Pujol J, 2006, NEUROLOGY, V66, P339, DOI 10.1212/01.wnl.0000201049.66073.8d
   Qiu AQ, 2015, ANNU REV PSYCHOL, V66, P853, DOI 10.1146/annurev-psych-010814-015340
   RADLOFF L S, 1977, Applied Psychological Measurement, V1, P385, DOI 10.1177/014662167700100306
   Rasmussen JM, 2019, NEUROIMAGE, V185, P825, DOI 10.1016/j.neuroimage.2018.04.020
   Rasmussen JM, 2017, INT J DEV NEUROSCI, V56, P42, DOI 10.1016/j.ijdevneu.2016.12.004
   Rose J, 2009, DEV MED CHILD NEUROL, V51, P526, DOI 10.1111/j.1469-8749.2008.03231.x
   Rudolph MD, 2018, NAT NEUROSCI, V21, P765, DOI 10.1038/s41593-018-0128-y
   Schepanski S, 2018, FRONT IMMUNOL, V9, DOI 10.3389/fimmu.2018.02186
   SHAPIRO B K, 1990, Pediatrics, V85, P416
   Short SJ, 2013, NEUROIMAGE, V64, P156, DOI 10.1016/j.neuroimage.2012.09.021
   Skeide MA, 2016, CEREB CORTEX, V26, P2127, DOI 10.1093/cercor/bhv042
   Stjerna S, 2015, J NEUROSCI, V35, P4824, DOI 10.1523/JNEUROSCI.5162-14.2015
   Stoel-Gammon C., 1992, PHONOLOGICAL DEV MOD, P273
   Szeszko PR, 2003, NEUROREPORT, V14, P2469, DOI 10.1097/00001756-200312190-00035
   Thomason ME, 2011, ANNU REV CLIN PSYCHO, V7, P63, DOI 10.1146/annurev-clinpsy-032210-104507
   Torppa M, 2010, J LEARN DISABIL-US, V43, P308, DOI 10.1177/0022219410369096
   Totsika Vasiliki, 2004, Child Adolesc Ment Health, V9, P25, DOI 10.1046/j.1475-357X.2003.00073.x
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   van Kooij BJM, 2012, AM J NEURORADIOL, V33, P188, DOI 10.3174/ajnr.A2723
   Verde AR, 2014, FRONT NEUROINFORM, V7, DOI 10.3389/fninf.2013.00051
   Westerhausen R, 2004, COGNITIVE BRAIN RES, V21, P418, DOI 10.1016/j.cogbrainres.2004.07.002
   Wolff JJ, 2012, AM J PSYCHIAT, V169, P589, DOI 10.1176/appi.ajp.2011.11091447
   Wong HS, 2013, MATERN CHILD HLTH J, V17, P1689, DOI 10.1007/s10995-012-1183-8
   Xu M, 2018, ASIA JT CONF INF SEC, P42, DOI 10.1109/AsiaJCIS.2018.00016
   Yakovlev P., 1967, REGIONAL DEV BRAIN E, P3
   1955, J CONSULT PSYCHOL, V19, P319, DOI DOI 10.1037/H0039221
NR 69
TC 1
Z9 1
U1 1
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD DEC 17
PY 2019
VL 13
AR 434
DI 10.3389/fnhum.2019.00434
PG 11
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA JZ3JX
UT WOS:000504999300001
PM 31920593
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Price, CN
   Alain, C
   Bidelman, GM
AF Price, Caitlin N.
   Alain, Claude
   Bidelman, Gavin M.
TI Auditory-frontal Channeling in alpha and beta Bands is Altered by
   Age-related Hearing Loss and Relates to Speech Perception in Noise
SO NEUROSCIENCE
LA English
DT Article
DE cognitive aging; EEG; functional connectivity; time-frequency analysis;
   neural oscillations; speech processing
ID INHIBITORY CONTROL; COMPUTATIONAL PRINCIPLES; BRAIN OSCILLATIONS;
   ATTENTION; MEMORY; EEG; CORTEX; INFORMATION; RECOGNITION; MECHANISMS
AB Difficulty understanding speech-in-noise (SIN) is a pervasive problem faced by older adults particularly those with hearing loss. Previous studies have identified structural and functional changes in the brain that contribute to older adults' speech perception difficulties. Yet, many of these studies use neuroimaging techniques that evaluate only gross activation in isolated brain regions. Neural oscillations may provide further insight into the processes underlying SIN perception as well as the interaction between auditory cortex and prefrontal linguistic brain regions that mediate complex behaviors. We examined frequency-specific neural oscillations and functional connectivity of the EEG in older adults with and without hearing loss during an active SIN perception task. Brain-behavior correlations revealed listeners who were more resistant to the detrimental effects of noise also demonstrated greater modulation of alpha phase coherence between clean and noise-degraded speech, suggesting a desynchronization reflects release from inhibition and more flexible allocation of neural resources. Additionally, we found top-down beta connectivity between prefrontal and auditory cortices strengthened with poorer hearing thresholds despite minimal behavioral differences. This is consistent with the proposal that linguistic brain areas may be recruited to compensate for impoverished auditory inputs through increased top-down predictions to assist SIN perception. Overall, these results emphasize the importance of top-down signaling in low-frequency brain rhythms that help compensate for hearing-related declines and facilitate efficient SIN processing. (C) 2019 IBRO. Published by Elsevier Ltd. All rights reserved.
C1 [Price, Caitlin N.; Bidelman, Gavin M.] Univ Memphis, Sch Commun Sci & Disorders, 4055 North Pk Loop, Memphis, TN 38152 USA.
   [Bidelman, Gavin M.] Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.
   [Bidelman, Gavin M.] Univ Tennessee, Ctr Hlth Sci, Dept Anat & Neurobiol, Memphis, TN 38163 USA.
   [Alain, Claude] Rotman Res Inst, Baycrest Ctr Geriatr Care, Toronto, ON, Canada.
   [Alain, Claude] Univ Toronto, Dept Psychol, Toronto, ON, Canada.
   [Alain, Claude] Univ Toronto, Inst Med Sci, Toronto, ON, Canada.
RP Price, CN (corresponding author), Univ Memphis, Sch Commun Sci & Disorders, 4055 North Pk Loop, Memphis, TN 38152 USA.
EM cenelms@memphis.edu; gmbdlman@memphis.edu
OI Bidelman, Gavin M/0000-0002-1821-3261; Price,
   Caitlin/0000-0002-4079-6387
FU Canadian Institutes of Health ResearchCanadian Institutes of Health
   Research (CIHR) [MOP 106619]; Natural Sciences and Engineering Research
   Council of Canada (NSERC)Natural Sciences and Engineering Research
   Council of Canada (NSERC) [194536]; National Institutes of Health
   (NIDCD)United States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R01DC016267]; NATIONAL INSTITUTE
   ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC016267, R01DC016267] Funding Source: NIH RePORTER
FX This work was supported by grants from the Canadian Institutes of Health
   Research (MOP 106619) and the Natural Sciences and Engineering Research
   Council of Canada (NSERC, 194536) awarded to C.A, and the National
   Institutes of Health (NIDCD) R01DC016267 awarded to G.M.B. Requests for
   reprints and materials should be directed to G.M.B.
   [gmbdlman@memphis.edu].
CR Adrian ED, 1934, J PHYSIOL-LONDON, V81, P440, DOI 10.1113/jphysiol.1934.sp003147
   Alain C, 1999, PSYCHOL AGING, V14, P507, DOI 10.1037/0882-7974.14.3.507
   Alain C, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00008
   Bashivan P, 2014, EUR J NEUROSCI, V40, P3774, DOI 10.1111/ejn.12749
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Betzel RF, 2014, NEUROIMAGE, V102, P345, DOI 10.1016/j.neuroimage.2014.07.067
   Bidelman GM, 2019, HEARING RES, V382, DOI 10.1016/j.heares.2019.107795
   Bidelman GM, 2018, HEARING RES, V367, P149, DOI 10.1016/j.heares.2018.05.018
   Bidelman GM, 2017, NEUROSCIENCE, V348, P107, DOI 10.1016/j.neuroscience.2017.02.015
   Bidelman GM, 2016, NEUROIMAGE, V124, P581, DOI 10.1016/j.neuroimage.2015.09.020
   Bidelman GM, 2015, BRAIN LANG, V141, P62, DOI 10.1016/j.bandl.2014.11.003
   Bidelman GM, 2014, NEUROBIOL AGING, V35, P2526, DOI 10.1016/j.neurobiolaging.2014.05.006
   Bidelman GM, 2019, BRAIN STRUCT FUNCT
   Bilodeau-Mercure M, 2015, BRAIN STRUCT FUNCT, V220, P979, DOI 10.1007/s00429-013-0695-3
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   Brovelli A, 2004, P NATL ACAD SCI USA, V101, P9849, DOI 10.1073/pnas.0308538101
   Campbell J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00071
   Cardin V, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00199
   Caspary DM, 2008, J EXP BIOL, V211, P1781, DOI 10.1242/jeb.013581
   Chambers AR, 2016, NEURON, V89, P867, DOI 10.1016/j.neuron.2015.12.041
   Chao LL, 1997, CEREB CORTEX, V7, P63, DOI 10.1093/cercor/7.1.63
   Cope TE, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01958-7
   Crinion JT, 2003, BRAIN, V126, P1193, DOI 10.1093/brain/awg104
   Doeller CF, 2003, NEUROIMAGE, V20, P1270, DOI 10.1016/S1053-8119(03)00389-6
   Doppelmayr M, 2005, BRAIN RES BULL, V66, P171, DOI 10.1016/j.brainresbull.2005.04.007
   Du Y, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12241
   Dushanova J, 2016, INT J NEUROL RES, V3, P327
   Fabiani M, 2006, J COGNITIVE NEUROSCI, V18, P637, DOI 10.1162/jocn.2006.18.4.637
   Fontolan L, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5694
   Frisina DR, 1997, HEARING RES, V106, P95, DOI 10.1016/S0378-5955(97)00006-3
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   Garavan H, 1999, P NATL ACAD SCI USA, V96, P8301, DOI 10.1073/pnas.96.14.8301
   Gelfand S. A., 2009, ESSENTIALS AUDIOLOGY
   Giordano BL, 2017, ELIFE, V6, DOI 10.7554/eLife.24763
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Gosselin PA, 2011, J SPEECH LANG HEAR R, V54, P944, DOI 10.1044/1092-4388(2010/10-0069)
   Grady C, 2012, NAT REV NEUROSCI, V13, P491, DOI 10.1038/nrn3256
   HELFER KS, 1990, J SPEECH HEAR RES, V33, P149, DOI 10.1044/jshr.3301.149
   Hoechstetter K, 2004, BRAIN TOPOGR, V16, P233
   Humes L E, 1996, J Am Acad Audiol, V7, P161
   Kahneman D., 1973, ATTENTION EFFORT
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Klimesch W, 1997, NEUROSCI LETT, V238, P9, DOI 10.1016/S0304-3940(97)00771-4
   Klimesch W, 2007, BRAIN RES REV, V53, P63, DOI 10.1016/j.brainresrev.2006.06.003
   Klimesch W, 2012, TRENDS COGN SCI, V16, P606, DOI 10.1016/j.tics.2012.10.007
   LAVIE N, 1995, J EXP PSYCHOL HUMAN, V21, P451, DOI 10.1037/0096-1523.21.3.451
   Lavie N, 2004, J EXP PSYCHOL GEN, V133, P339, DOI 10.1037/0096-3445.133.3.339
   Lin FR, 2014, NEUROIMAGE, V90, P84, DOI 10.1016/j.neuroimage.2013.12.059
   Lobier M, 2014, NEUROIMAGE, V85, P853, DOI 10.1016/j.neuroimage.2013.08.056
   Lopez ME, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00125
   Mishra S, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00096
   Mishra S, 2013, J SPEECH LANG HEAR R, V56, P1120, DOI 10.1044/1092-4388(2012/12-0033)
   Morcom AM, 2018, J NEUROSCI, V38, P7303, DOI 10.1523/JNEUROSCI.1701-17.2018
   Nobukawa S, 2019, NEUROIMAGE, V188, P357, DOI 10.1016/j.neuroimage.2018.12.008
   Papp N, 1977, Biomed Sci Instrum, V13, P135
   Park DC, 2013, PERSPECT PSYCHOL SCI, V8, P62, DOI 10.1177/1745691612469034
   Petersen EB, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00177
   Pfurtscheller G, 2001, VISION RES, V41, P1257, DOI 10.1016/S0042-6989(00)00235-2
   Pichora-Fuller MK, 2012, AM J AUDIOL, V21, P351, DOI 10.1044/1059-0889(2012/12-0025)
   Picton TW, 1999, AUDIOL NEURO-OTOL, V4, P64, DOI 10.1159/000013823
   Picton TW, 2000, CLIN NEUROPHYSIOL, V111, P53, DOI 10.1016/S1388-2457(99)00227-8
   Proskovec AL, 2019, NEUROIMAGE, V184, P256, DOI 10.1016/j.neuroimage.2018.09.022
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580
   Rudner M, 2009, SCAND J PSYCHOL, V50, P405, DOI 10.1111/j.1467-9450.2009.00745.x
   Scherg M, 2002, J CLIN NEUROPHYSIOL, V19, P91, DOI 10.1097/00004691-200203000-00001
   SCHERG M, 1994, NEUROPHYSIOL CLIN, V24, P51, DOI 10.1016/S0987-7053(05)80405-8
   Schluchter MD, 1990, J STAT COMPUT SIMULA, V37
   Sedley W, 2016, ELIFE, V5, DOI 10.7554/eLife.11476
   Shahin AJ, 2009, BRAIN COGNITION, V70, P259, DOI 10.1016/j.bandc.2009.02.008
   Specht K, 2000, NEUROIMAGE, V11, pS292
   Sullivan EV, 2006, NEUROSCI BIOBEHAV R, V30, P749, DOI 10.1016/j.neubiorev.2006.06.002
   TallonBaudry C, 1996, J NEUROSCI, V16, P4240
   Tremblay KL, 2003, CLIN NEUROPHYSIOL, V114, P1332, DOI 10.1016/S1388-2457(03)00114-7
   Tyler LK, 2010, CEREB CORTEX, V20, P352, DOI 10.1093/cercor/bhp105
   von Stein A, 2000, INT J PSYCHOPHYSIOL, V38, P301, DOI 10.1016/S0167-8760(00)00172-0
   Wang LY, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00239
   Wang XJ, 2010, PHYSIOL REV, V90, P1195, DOI 10.1152/physrev.00035.2008
   Wayne RV, 2015, AGEING RES REV, V23, P154, DOI 10.1016/j.arr.2015.06.002
   Wong PCM, 2010, EAR HEARING, V31, P471, DOI 10.1097/AUD.0b013e3181d709c2
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
   Yellamsetty A, 2018, HEAR RES
   Zarahn E, 2007, NEUROBIOL AGING, V28, P784, DOI 10.1016/j.neurobiolaging.2006.03.002
   Zekveld AA, 2006, NEUROIMAGE, V32, P1826, DOI 10.1016/j.neuroimage.2006.04.199
   Zendel BR, 2014, NEUROBIOL AGING, V35, P55, DOI 10.1016/j.neurobiolaging.2013.06.022
NR 84
TC 3
Z9 3
U1 4
U2 19
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0306-4522
EI 1873-7544
J9 NEUROSCIENCE
JI Neuroscience
PD DEC 15
PY 2019
VL 423
BP 18
EP 28
DI 10.1016/j.neuroscience.2019.10.044
PG 11
WC Neurosciences
SC Neurosciences & Neurology
GA JS7RE
UT WOS:000500500300003
PM 31705894
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Dagan, G
   Shabtai, NR
   Rafaely, B
AF Dagan, Gal
   Shabtai, Noam R.
   Rafaely, Boaz
TI Spatial release from masking for binaural reproduction of speech in
   noise with varying spherical harmonics order
SO APPLIED ACOUSTICS
LA English
DT Article
DE Speech intelligibility; Binaural sound reproduction; Hearing in noise
   test; Ambisonics
ID INTELLIGIBILITY
AB Spatial release from masking (SRM) in the context of speech perception denotes the improvement of speech intelligibility in noise when the speech and the noise sources are spatially separated in space. A similar effect has been reported with binaural sound reproduction (BSR), in which speech and noise are simulated and reproduced using headphones. The effect of SRM on speech intelligibility using BSR has not yet been thoroughly studied for signals represented by different spherical harmonic (SH) orders. This may be important when speech corrupted by noise is delivered in spatial audio channels, such as Ambisonics and higher order Ambisonics. In this work, a hearing in noise test (HINT) is performed in which a female speaker and noise are binaurally reproduced using headphones under different SH orders and different signal to noise ratio (SNR) values. The results show that a first SH order is sufficient to achieve intelligibility that is as good as the highest SH order used in this work. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Dagan, Gal; Shabtai, Noam R.; Rafaely, Boaz] Ben Gurion Univ Negev, Dept Elect & Comp Engn, IL-8410501 Beer Sheva, Israel.
RP Rafaely, B (corresponding author), Ben Gurion Univ Negev, Dept Elect & Comp Engn, IL-8410501 Beer Sheva, Israel.
EM br@bgu.ac.il
CR ARFKEN G, 2001, MATH METHODS PHYS, P30401
   Arons B., 1992, J AM VOICE I O SOC, V12, P35
   Avni A, 2013, J ACOUST SOC AM, V133, P2711, DOI 10.1121/1.4795780
   Ben-Hur Z, 2018, APPL ACOUST, V134, P138, DOI 10.1016/j.apacoust.2018.01.016
   BRONKHORST AW, 1992, J ACOUST SOC AM, V92, P3132, DOI 10.1121/1.404209
   Bronkhorst AW, 2000, ACUSTICA, V86, P117
   Hollander M., 1973, NONPARAMETRIC STAT M
   Leonard R. G., 1993, TIDIGITS LDC93S10 WE
   Litovsky RY, 2012, ACOUSTICS TODAY, V8
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Noisternig M, 2012, ADV ENG SOFTW AES
   Rafaely B., 2015, FUNDAMENTALS SPHERIC
   Rafaely B, 2010, J ACOUST SOC AM, V127, P823, DOI 10.1121/1.3278605
   Shabtai NR, 2017, APPL ACOUST, V125, P173, DOI 10.1016/j.apacoust.2017.05.002
   Shabtai NR, 2015, J ACOUST SOC AM, V138, P3118, DOI 10.1121/1.4934960
   Shabtai NR, 2014, IEEE-ACM T AUDIO SPE, V22, P238, DOI 10.1109/TASLP.2013.2290499
   Smits C, 2004, INT J AUDIOL, V43, P15, DOI 10.1080/14992020400050004
   Smits C, 2011, J ACOUST SOC AM, V130, P2987, DOI 10.1121/1.3644909
   Wallis S, 2013, J QUANT LINGUIST, V20, P178, DOI 10.1080/09296174.2013.799918
NR 19
TC 1
Z9 1
U1 1
U2 9
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0003-682X
EI 1872-910X
J9 APPL ACOUST
JI Appl. Acoust.
PD DEC 15
PY 2019
VL 156
BP 258
EP 261
DI 10.1016/j.apacoust.2019.07.015
PG 4
WC Acoustics
SC Acoustics
GA JB1DV
UT WOS:000488301300026
DA 2021-02-24
ER

PT J
AU Ujiie, Y
   Wakabayashi, A
AF Ujiie, Yuta
   Wakabayashi, Akio
TI Intact lip-reading but weaker McGurk effect in individuals with high
   autistic traits
SO INTERNATIONAL JOURNAL OF DEVELOPMENTAL DISABILITIES
LA English
DT Article; Early Access
DE autism spectrum disorder; autism spectrum quotient; McGurk effect;
   lip-reading; individual differences
ID SPECTRUM QUOTIENT AQ; SPEECH-PERCEPTION; ASPERGER-SYNDROME; CHILDREN;
   INTEGRATION; ADULTS; RESPONSIVENESS; DISORDERS; PHENOTYPE; FREQUENCY
AB A weaker McGurk effect is observed in individuals with autism spectrum disorder (ASD); weaker integration is considered to be the key to understanding how low-order atypical processing leads to their maladaptive social behaviors. However, the mechanism for this weaker McGurk effect has not been fully understood. Here, we investigated (1) whether the weaker McGurk effect in individuals with high autistic traits is caused by poor lip-reading ability and (2) whether the hearing environment modifies the weaker McGurk effect in individuals with high autistic traits. To confirm them, we conducted two analogue studies among university students, based on the dimensional model of ASD. Results showed that individuals with high autistic traits have intact lip-reading ability as well as abilities to listen and recognize audiovisual congruent speech (Experiment 1). Furthermore, a weaker McGurk effect in individuals with high autistic traits, which appear under the without-noise condition, would disappear under the high noise condition (Experiments 1 and 2). Our findings suggest that high background noise might shift weight on the visual cue, thereby increasing the strength of the McGurk effect among individuals with high autistic traits.
C1 [Ujiie, Yuta] Chukyo Univ, Grad Sch Psychol, Nagoya, Aichi, Japan.
   [Ujiie, Yuta] Japan Soc Promot Sci, Tokyo, Japan.
   [Ujiie, Yuta] Chuo Univ, Res & Dev Initiat, Tokyo, Japan.
   [Wakabayashi, Akio] Chiba Univ, Fac Letters, Inage Ku, Chiba, Japan.
RP Ujiie, Y (corresponding author), Chukyo Univ, Grad Sch Psychol, Showa Ku, 101-2 Yagoto Honmachi, Nagoya, Aichi 4668666, Japan.
EM yuta.ujiie.160330@gmail.com
FU [19J00722];  [19K20650];  [16H06526 MEXT]; Grants-in-Aid for Scientific
   ResearchMinistry of Education, Culture, Sports, Science and Technology,
   Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for
   Scientific Research (KAKENHI) [19K20650, 19J00722] Funding Source: KAKEN
FX This study was supported by a Grant-in-Aid for the Japan Society for the
   Promotion of Science Fellows (Grant No 19J00722), Grant-in-Aid for
   Research Activity (Grant No. 19K20650), and Grant-in-Aid for Scientific
   research on Innovative Areas (Grant No.16H06526 MEXT).
CR American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   Austin EJ, 2005, PERS INDIV DIFFER, V38, P451, DOI 10.1016/j.paid.2004.04.022
   Baker AEZ, 2008, J AUTISM DEV DISORD, V38, P867, DOI 10.1007/s10803-007-0459-0
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Baron-Cohen S, 2001, J CHILD PSYCHOL PSYC, V42, P241, DOI 10.1111/1469-7610.00715
   BARONCOHEN S, 1986, BRIT J DEV PSYCHOL, V4, P113, DOI 10.1111/j.2044-835X.1986.tb01003.x
   Bebko JM, 2014, AUTISM RES, V7, P50, DOI 10.1002/aur.1343
   Crane L, 2009, AUTISM, V13, P215, DOI 10.1177/1362361309103794
   De Gelder B, 1991, EUROPEAN J COGNITIVE, V3, P69, DOI DOI 10.1080/09541449108406220
   Deruelle C, 2004, J AUTISM DEV DISORD, V34, P199, DOI 10.1023/B:JADD.0000022610.09668.4c
   Donohue SE, 2012, EXP BRAIN RES, V222, P377, DOI 10.1007/s00221-012-3223-4
   Dunn W, 1997, AM J OCCUP THER, V51, P25, DOI 10.5014/ajot.51.1.25
   Foss-Feig JH, 2012, RES AUTISM SPECT DIS, V6, P337, DOI 10.1016/j.rasd.2011.06.007
   FRITH U, 1991, AUTISM ASPERGERS SYN
   Haesen B, 2011, RES AUTISM SPECT DIS, V5, P701, DOI 10.1016/j.rasd.2010.11.006
   Happe F, 2006, J AUTISM DEV DISORD, V36, P5, DOI 10.1007/s10803-005-0039-0
   Hasegawa C, 2015, PSYCHIAT CLIN NEUROS, V69, P136, DOI 10.1111/pcn.12210
   Hoekstra RA, 2008, J AUTISM DEV DISORD, V38, P1555, DOI 10.1007/s10803-008-0538-x
   Hofvander B, 2009, BMC PSYCHIATRY, V9, DOI 10.1186/1471-244X-9-35
   Iarocci G, 2010, AUTISM, V14, P305, DOI 10.1177/1362361309353615
   Irwin JR, 2011, CHILD DEV, V82, P1397, DOI 10.1111/j.1467-8624.2011.01619.x
   Joseph RM, 2002, J CHILD PSYCHOL PSYC, V43, P1, DOI DOI 10.1111/1469-7610.00142
   Lau WYP, 2013, J AUTISM DEV DISORD, V43, P2807, DOI 10.1007/s10803-013-1827-6
   Magnotti JF, 2015, EXP BRAIN RES, V233, P2581, DOI 10.1007/s00221-015-4324-7
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   O'Connor K, 2012, NEUROSCI BIOBEHAV R, V36, P836, DOI 10.1016/j.neubiorev.2011.11.008
   Palmer CJ, 2013, NEUROPSYCHOLOGIA, V51, P1942, DOI 10.1016/j.neuropsychologia.2013.06.020
   Paton B, 2012, J AUTISM DEV DISORD, V42, P1870, DOI 10.1007/s10803-011-1430-7
   Reed P, 2011, PERS INDIV DIFFER, V51, P732, DOI 10.1016/j.paid.2011.06.016
   Saalasti S, 2012, J AUTISM DEV DISORD, V42, P1606, DOI 10.1007/s10803-011-1400-0
   Saalasti S, 2011, EXP BRAIN RES, V213, P283, DOI 10.1007/s00221-011-2751-7
   Sekiyama K., 1994, Journal of the Acoustical Society of Japan (E), V15, P143
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Sekiyama K, 2008, DEVELOPMENTAL SCI, V11, P306, DOI 10.1111/j.1467-7687.2008.00677.x
   Simmons DR, 2009, VISION RES, V49, P2705, DOI 10.1016/j.visres.2009.08.005
   Smith EG, 2007, J CHILD PSYCHOL PSYC, V48, P813, DOI 10.1111/j.1469-7610.2007.01766.x
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Stewart ME, 2008, COGNITION, V109, P157, DOI 10.1016/j.cognition.2008.07.010
   Taylor N, 2010, J AUTISM DEV DISORD, V40, P1403, DOI 10.1007/s10803-010-1000-4
   Tomchek SD, 2007, AM J OCCUP THER, V61, P190, DOI 10.5014/ajot.61.2.190
   Ujiie Y, 2015, LETT EVOL BEHAV SCI, V6, P9
   Ujiie Y, 2018, EXP BRAIN RES, V236, P973, DOI 10.1007/s00221-018-5188-4
   Ujiie Y, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00891
   Wakabayashi A, 2006, J AUTISM DEV DISORD, V36, P263, DOI 10.1007/s10803-005-0061-2
   Williams JHG, 2004, RES DEV DISABIL, V25, P559, DOI 10.1016/j.ridd.2004.01.008
   Woodbury-Smith MR, 2005, J AUTISM DEV DISORD, V35, P331, DOI 10.1007/s10803-005-3300-7
   Zhang J, 2019, J AUTISM DEV DISORD, V49, P34, DOI 10.1007/s10803-018-3680-0
NR 47
TC 0
Z9 0
U1 4
U2 9
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 2047-3869
EI 2047-3877
J9 INT J DEV DISABIL
JI Int. J. Dev. Disabil.
DI 10.1080/20473869.2019.1699350
EA DEC 2019
PG 9
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA JX1OX
UT WOS:000503513900001
DA 2021-02-24
ER

PT J
AU Kaufeld, G
   Naumann, W
   Meyer, AS
   Bosker, HR
   Martin, AE
AF Kaufeld, Greta
   Naumann, Wibke
   Meyer, Antje S.
   Bosker, Hans Rutger
   Martin, Andrea E.
TI Contextual speech rate influences morphosyntactic prediction and
   integration
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE language comprehension; speech perception; cue integration; morphology;
   speech rate normalisation
ID SPEAKING-RATE; GRAMMATICAL GENDER; PERCEPTUAL NORMALIZATION; LANGUAGE
   COMPREHENSION; SENTENCE COMPREHENSION; CUE-INTEGRATION; LEXICAL STATUS;
   INFORMATION; WORDS; TIME
AB Understanding spoken language requires the integration and weighting of multiple cues, and may call on cue integration mechanisms that have been studied in other areas of perception. In the current study, we used eye-tracking (visual-world paradigm) to examine how contextual speech rate (a lower-level, perceptual cue) and morphosyntactic knowledge (a higher-level, linguistic cue) are iteratively combined and integrated. Results indicate that participants used contextual rate information immediately, which we interpret as evidence of perceptual inference and the generation of predictions about upcoming morphosyntactic information. Additionally, we observed that early rate effects remained active in the presence of later conflicting lexical information. This result demonstrates that (1) contextual speech rate functions as a cue to morphosyntactic inferences, even in the presence of subsequent disambiguating information; and (2) listeners iteratively use multiple sources of information to draw inferences and generate predictions during speech comprehension. We discuss the implication of these demonstrations for theories of language processing.
C1 [Kaufeld, Greta; Naumann, Wibke; Meyer, Antje S.; Bosker, Hans Rutger; Martin, Andrea E.] Max Planck Inst Psycholinguist, Nijmegen, Netherlands.
   [Kaufeld, Greta] Int Max Planck Res Sch Language Sci, Nijmegen, Netherlands.
   [Meyer, Antje S.; Bosker, Hans Rutger; Martin, Andrea E.] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
RP Kaufeld, G (corresponding author), Max Planck Inst Psycholinguist, Nijmegen, Netherlands.; Kaufeld, G (corresponding author), Int Max Planck Res Sch Language Sci, Nijmegen, Netherlands.
EM greta.kaufeld@mpi.nl
OI Martin, Andrea E./0000-0002-3395-7234; Bosker, Hans
   Rutger/0000-0002-2628-7738; Kaufeld, Greta/0000-0003-0470-442X
FU Netherlands Organization for Scientific ResearchNetherlands Organization
   for Scientific Research (NWO) [016, Vidi.188.029]; Max Planck Research
   Group Award from the Max Planck GesellschaftMax Planck Society
FX AEM was funded by the Netherlands Organization for Scientific Research
   (grant 016.Vidi.188.029) and by a Max Planck Research Group Award from
   the Max Planck Gesellschaft.
CR Altmann GTM, 2011, ACTA PSYCHOL, V137, P190, DOI 10.1016/j.actpsy.2010.09.009
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   Dunabeitia JA, 2018, Q J EXP PSYCHOL, V71, P808, DOI 10.1080/17470218.2017.1310261
   Apfelbaum KS, 2014, LANG COGN NEUROSCI, V29, P1070, DOI 10.1080/01690965.2013.824995
   Audacity Team, 2019, AUD R FREE AUD ED RE
   Baese-Berk MM, 2019, ATTEN PERCEPT PSYCHO, V81, P571, DOI 10.3758/s13414-018-1626-4
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Bates E., 1987, MECH LANGUAGE ACQUIS, P157
   Bezanson J, 2017, SIAM REV, V59, P65, DOI 10.1137/141000671
   Boersma Paul, 2012, PRAAT DOING PHONETIC
   Bolte J, 2004, PERCEPT PSYCHOPHYS, V66, P1018, DOI 10.3758/BF03194992
   Bosker HR, 2018, LANG COGN NEUROSCI, V33, P955, DOI 10.1080/23273798.2018.1439179
   Bosker HR, 2017, J EXP PSYCHOL LEARN, V43, P1225, DOI 10.1037/xlm0000381
   Bosker HR, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01063
   Bosker HR, 2017, J MEM LANG, V94, P166, DOI 10.1016/j.jml.2016.12.002
   Bosker HR, 2017, ATTEN PERCEPT PSYCHO, V79, P333, DOI 10.3758/s13414-016-1206-4
   Brown M., 2012, P ANN M COGN SCI SOC, V34
   CARANDINI M, 1994, SCIENCE, V264, P1333, DOI 10.1126/science.8191289
   Carandini M, 2012, NAT REV NEUROSCI, V13, P51, DOI 10.1038/nrn3136
   Cho SJ, 2018, PSYCHOMETRIKA, V83, P751, DOI 10.1007/s11336-018-9604-2
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477
   CONNINE CM, 1987, J EXP PSYCHOL HUMAN, V13, P291, DOI 10.1037/0096-1523.13.2.291
   Dell GS, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0394
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660
   Federmeier KD, 2002, PSYCHOPHYSIOLOGY, V39, P133, DOI 10.1111/1469-8986.3920133
   Fetsch CR, 2013, NAT REV NEUROSCI, V14, P429, DOI 10.1038/nrn3503
   FOX RA, 1984, J EXP PSYCHOL HUMAN, V10, P526, DOI 10.1037/0096-1523.10.4.526
   Friederici AD, 1999, J PSYCHOLINGUIST RES, V28, P467, DOI 10.1023/A:1023264209610
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   GORDON PC, 1988, PERCEPT PSYCHOPHYS, V43, P137, DOI 10.3758/BF03214191
   Guerra E., 2018, AMLAP C ARCH MECH LA
   Gwilliams L, 2018, J NEUROSCI, V38, P7585, DOI 10.1523/JNEUROSCI.0065-18.2018
   Heffner CC, 2017, ATTEN PERCEPT PSYCHO, V79, P964, DOI 10.3758/s13414-016-1274-5
   Heffner CC, 2015, J SPEECH LANG HEAR R, V58, P1341, DOI 10.1044/2015_JSLHR-H-14-0239
   Hillert D., 1996, MORPHOLOGICAL CONSTR
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Kamide Y, 2003, J PSYCHOLINGUIST RES, V32, P37, DOI 10.1023/A:1021933015362
   Kaufeld G, 2020, J EXP PSYCHOL LEARN, V46, P549, DOI 10.1037/xlm0000744
   Kochari AR, 2019, LANG COGN NEUROSCI, V34, P239, DOI 10.1080/23273798.2018.1524500
   Landy M. S., 2011, SENSORY CUE INTEGRAT, P5, DOI DOI 10.1093/ACPROF:OSO/9780195387247.003.0001
   Laszlo S, 2009, J MEM LANG, V61, P326, DOI 10.1016/j.jml.2009.06.004
   Martin AE, 2017, LANG SPEECH, V60, P356, DOI 10.1177/0023830916650714
   Martin AE, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00120
   Maslowski M, 2019, J ACOUST SOC AM, V146, P179, DOI 10.1121/1.5116004
   Maslowski M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203571
   Maslowski M, 2019, J EXP PSYCHOL LEARN, V45, P128, DOI 10.1037/xlm0000579
   MATIN E, 1993, PERCEPT PSYCHOPHYS, V53, P372, DOI 10.3758/BF03206780
   Mattys SL, 2005, J EXP PSYCHOL GEN, V134, P477, DOI 10.1037/0096-3445.134.4.477
   Mattys SL, 2007, J EXP PSYCHOL HUMAN, V33, P960, DOI 10.1037/0096-1523.33.4.960
   McMurray B., 2011, DO FEATURES COME, P197, DOI DOI 10.1075/LFAB.6.08MCM
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   MILLER JL, 1988, J EXP PSYCHOL HUMAN, V14, P369, DOI 10.1037/0096-1523.14.3.369
   MILLER JL, 1983, J ACOUST SOC AM, V73, P1751, DOI 10.1121/1.389399
   Mitterer H, 2018, LAB PHONOL, V9, DOI 10.5334/labphon.66
   Morrill T, 2015, PSYCHON B REV, V22, P1451, DOI 10.3758/s13423-015-0820-9
   Newman RS, 2009, J PHONETICS, V37, P46, DOI 10.1016/j.wocn.2008.09.001
   Nieuwland MS, 2018, ELIFE, V7, DOI 10.7554/eLife.33468
   ODEN GC, 1978, PSYCHOL REV, V85, P172, DOI 10.1037/0033-295X.85.3.172
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002
   PICKETT JM, 1960, LANG SPEECH, V3, P11, DOI 10.1177/002383096000300103
   PITT MA, 1993, J EXP PSYCHOL HUMAN, V19, P699, DOI 10.1037/0096-1523.19.4.699
   Pitt MA, 2016, ATTEN PERCEPT PSYCHO, V78, P334, DOI 10.3758/s13414-015-0981-7
   Quene H., 2008, EXAMPLES MIXED EFFEC
   Rabagliati H, 2013, BEHAV BRAIN SCI, V36, P372, DOI 10.1017/S0140525X12002671
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   Reinisch E, 2011, J EXP PSYCHOL HUMAN, V37, P978, DOI 10.1037/a0021923
   Rohde H, 2012, J EXP PSYCHOL LEARN, V38, P967, DOI 10.1037/a0026786
   Rommers J, 2013, NEUROPSYCHOLOGIA, V51, P437, DOI 10.1016/j.neuropsychologia.2012.12.002
   Sawusch James R, 1974, J Phon, V2, P181
   Sawusch JR, 2000, PERCEPT PSYCHOPHYS, V62, P285, DOI 10.3758/BF03205549
   Szewczyk JM, 2013, J MEM LANG, V68, P297, DOI 10.1016/j.jml.2012.12.002
   Toscano JC, 2015, LANG COGN NEUROSCI, V30, P529, DOI 10.1080/23273798.2014.946427
   Toscano JC, 2012, ATTEN PERCEPT PSYCHO, V74, P1284, DOI 10.3758/s13414-012-0306-z
   van Alphen P, 2001, J EXP PSYCHOL HUMAN, V27, P1057, DOI 10.1037//0096-1523.27.5.1057
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443
   Wade T, 2005, PERCEPT PSYCHOPHYS, V67, P939, DOI 10.3758/BF03193621
   Wicha NYY, 2004, J COGNITIVE NEUROSCI, V16, P1272, DOI 10.1162/0898929041920487
   Wicha NYY, 2003, NEUROSCI LETT, V346, P165, DOI 10.1016/S0304-3940(03)00599-8
   Wicha NYY, 2003, CORTEX, V39, P483, DOI 10.1016/S0010-9452(08)70260-0
NR 83
TC 3
Z9 3
U1 2
U2 3
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PD SEP 3
PY 2020
VL 35
IS 7
SI SI
BP 933
EP 948
DI 10.1080/23273798.2019.1701691
EA DEC 2019
PG 16
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA NK3RP
UT WOS:000503306200001
OA Bronze, Green Published
DA 2021-02-24
ER

PT J
AU Castiglione, A
   Casa, M
   Gallo, S
   Sorrentino, F
   Dhima, S
   Cilia, D
   Lovo, E
   Gambin, M
   Previato, M
   Colombo, S
   Caserta, E
   Gheller, F
   Giacomelli, C
   Montino, S
   Limongi, F
   Brotto, D
   Gabelli, C
   Trevisi, P
   Bovo, R
   Martini, A
AF Castiglione, Alessandro
   Casa, Mariella
   Gallo, Samanta
   Sorrentino, Flavia
   Dhima, Sonila
   Cilia, Dalila
   Lovo, Elisa
   Gambin, Marta
   Previato, Maela
   Colombo, Simone
   Caserta, Ezio
   Gheller, Flavia
   Giacomelli, Cristina
   Montino, Silvia
   Limongi, Federica
   Brotto, Davide
   Gabelli, Carlo
   Trevisi, Patrizia
   Bovo, Roberto
   Martini, Alessandro
TI Correspondence Between Cognitive and Audiological Evaluations Among the
   Elderly: A Preliminary Report of an Audiological Screening Model of
   Subjects at Risk of Cognitive Decline With Slight to Moderate Hearing
   Loss
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE cognitive decline; hearing loss; Italian Matrix Sentence Test;
   logatomes; signal-to-noise ratio; slope; speech in noise; screening
ID MATRIX SENTENCE TEST; SPEECH-PERCEPTION; OLDER-ADULTS; PSYCHOMETRIC
   FUNCTIONS; ALZHEIMERS-DISEASE; LATE-LIFE; NOISE; AGE; IMPAIRMENT;
   DEMENTIA
AB Epidemiological studies show increasing prevalence rates of cognitive decline and hearing loss with age, particularly after the age of 65 years. These conditions are reported to be associated, although conclusive evidence of causality and implications is lacking. Nevertheless, audiological and cognitive assessment among elderly people is a key target for comprehensive and multidisciplinary evaluation of the subject's frailty status. To evaluate the use of tools for identifying older adults at risk of hearing loss and cognitive decline and to compare skills and abilities in terms of hearing and cognitive performances between older adults and young subjects, we performed a prospective cross-sectional study using supraliminal auditory tests. The relationship between cognitive assessment results and audiometric results was investigated, and reference ranges for different ages or stages of disease were determined. Patients older than 65 years with different degrees of hearing function were enrolled. Each subject underwent an extensive audiological assessment, including tonal and speech audiometry, Italian Matrix Sentence Test, and speech audiometry with logatomes in quiet. Cognitive function was screened and then verified by experienced clinicians using the Montreal Cognitive Assessment Score, the Geriatric Depression Scale, and further investigations in some. One hundred twenty-three subjects were finally enrolled during 2016-2019: 103 were >65 years of age and 20 were younger participants (as controls). Cognitive functions showed a correlation with the audiological results in post-lingual hearing-impaired patients, in particular in those affected by slight to moderate hearing loss and aged more than 70 years. Audiological testing can thus be useful in clinical assessment and identification of patients at risk of cognitive impairment. The study was limited by its sample size (CI 95%; CL 10%), strict dependence on language, and hearing threshold. Further investigations should be conducted to confirm the reported results and to verify similar screening models.
C1 [Castiglione, Alessandro; Cilia, Dalila; Lovo, Elisa; Gambin, Marta; Previato, Maela; Colombo, Simone; Gheller, Flavia; Giacomelli, Cristina; Montino, Silvia; Trevisi, Patrizia; Bovo, Roberto; Martini, Alessandro] Univ Padua, Dept Neurosci, Padua, Italy.
   [Castiglione, Alessandro; Gallo, Samanta; Sorrentino, Flavia; Dhima, Sonila; Caserta, Ezio; Brotto, Davide; Trevisi, Patrizia; Bovo, Roberto; Martini, Alessandro] Hosp Padua, Complex Operat Unit Otolaryngol, Padua, Italy.
   [Casa, Mariella; Gabelli, Carlo] Reg Ctr Study & Treatment Aging Brain, Dept Internal Med, Padua, Italy.
   [Limongi, Federica] CNR, Inst Neurosci, Padua, Italy.
RP Castiglione, A (corresponding author), Univ Padua, Dept Neurosci, Padua, Italy.; Castiglione, A (corresponding author), Hosp Padua, Complex Operat Unit Otolaryngol, Padua, Italy.
EM alessandro.castiglione@unipd.it
RI Limongi, Federica/AAO-3575-2020; Castiglione, Alessandro/G-7015-2011
OI GHELLER, FLAVIA/0000-0002-0244-8488; Castiglione,
   Alessandro/0000-0002-5776-0444
FU University of Padua; Azienda Ospedaliera di Padova; Cochlear Italia Srl;
   Amplifon SpA, as part of the main project PRIHTA-IDECO 2013
FX This study was conducted between 2016 and 2019 at the Clinic of
   Otorhinolaryngology of the University Hospital of Padua, as part of the
   PRIHTA-IDECO 2013 project. The research was funded by the University of
   Padua, the Azienda Ospedaliera di Padova, Cochlear Italia Srl, and
   Amplifon SpA, as part of the main project PRIHTA-IDECO 2013, approved by
   the local ethics committee in 2016.
CR Akeroyd MA, 2015, INT J AUDIOL, V54, P17, DOI 10.3109/14992027.2015.1030513
   Apoux F, 2001, HEARING RES, V153, P123, DOI 10.1016/S0378-5955(00)00265-3
   Bae S, 2018, ARCH GERONTOL GERIAT, V78, P45, DOI 10.1016/j.archger.2018.05.025
   Bernabei R, 2014, AGING CLIN EXP RES, V26, P567, DOI 10.1007/s40520-014-0266-3
   Bovo R, 2007, ANN OTO RHINOL LARYN, V116, P407, DOI 10.1177/000348940711600603
   Buss E, 2009, J ACOUST SOC AM, V125, P1050, DOI 10.1121/1.3050273
   Carrat R, 1992, Rev Laryngol Otol Rhinol (Bord), V113, P347
   Castiglione A, 2016, AUDIOL NEURO-OTOL, V21, P21, DOI 10.1159/000448350
   Chan TMV, 2019, ATTEN PERCEPT PSYCHO, V81, P253, DOI 10.3758/s13414-018-1586-8
   Chen ZJ, 2009, MEM COGNITION, V37, P829, DOI 10.3758/MC.37.6.829
   Ciorba A, 2011, J LARYNGOL OTOL, V125, P776, DOI 10.1017/S0022215111001101
   Conti S, 2015, NEUROL SCI, V36, P209, DOI 10.1007/s10072-014-1921-3
   Cosetti MK, 2016, CLIN INTERV AGING, V11, P603, DOI 10.2147/CIA.S100255
   Costa M, 2016, EUR J NEUROSCI, V44, P2084, DOI 10.1111/ejn.13302
   Davis DHJ, 2015, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD010775.pub2
   Deal JA, 2017, J GERONTOL A-BIOL, V72, P703, DOI 10.1093/gerona/glw069
   Ding XQ, 2016, NEUROIMAGE, V137, P45, DOI 10.1016/j.neuroimage.2016.05.014
   Dreschler WA, 2001, AUDIOLOGY, V40, P148
   Fortunato S, 2016, ACTA OTORHINOLARYNGO, V36, P155, DOI 10.14639/0392-100X-993
   Gallo S, 2019, HEARING BALANC COMMU, V17, P145, DOI 10.1080/21695717.2019.1603949
   Giau VV, 2019, INT J MOL SCI, V20, DOI 10.3390/ijms20061514
   Gobara A, 2016, I-PERCEPTION, V7, DOI 10.1177/2041669516684244
   Helfer KS, 2015, AM J AUDIOL, V24, P80, DOI 10.1044/2015_AJA-14-0056
   HERBST KG, 1980, BMJ-BRIT MED J, V281, P903, DOI 10.1136/bmj.281.6245.903
   Hewitt D, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00112
   Homans NC, 2017, LARYNGOSCOPE, V127, P725, DOI 10.1002/lary.26150
   Houben R, 2014, INT J AUDIOL, V53, P760, DOI 10.3109/14992027.2014.920111
   Jayakody DMP, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00125
   Jorgensen Lindsey E., 2015, Seminars in Hearing, V36, P162, DOI 10.1055/s-0035-1555119
   Kaernbach C, 2001, PERCEPT PSYCHOPHYS, V63, P1389, DOI 10.3758/BF03194550
   Kim Bong Jik, 2013, Korean J Audiol, V17, P54, DOI 10.7874/kja.2013.17.2.54
   KingSmith PE, 1997, VISION RES, V37, P1595, DOI 10.1016/S0042-6989(96)00310-0
   Kollmeier B, 2015, INT J AUDIOL, V54, P1, DOI 10.3109/14992027.2015.1074295
   Kostoff R. N., 2017, PREVENTION REVERSAL
   Kujawski S, 2018, FRONT AGING NEUROSCI, V10, DOI 10.3389/fnagi.2018.00421
   Limongi F, 2017, AGING CLIN EXP RES, V29, P361, DOI 10.1007/s40520-017-0748-1
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P582, DOI 10.1093/gerona/glr002
   Lin FR, 2011, ARCH NEUROL-CHICAGO, V68, P214, DOI 10.1001/archneurol.2010.362
   Livingston G, 2017, LANCET, V390, P2673, DOI 10.1016/S0140-6736(17)31363-6
   MacPherson A, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514537722
   MARTINI A, 1988, AUDIOLOGY, V27, P1
   Martini A, 2014, AUDIOL NEURO-OTOL, V19, P2, DOI 10.1159/000371593
   Meister H, 2017, HNO, V65, P189, DOI 10.1007/s00106-016-0229-4
   Meister H, 2013, AM J AUDIOL, V22, P310, DOI 10.1044/1059-0889(2012/12-0067)
   Moradi S, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514545406
   Muhler R, 2009, ORL-J OTO-RHIN-LARYN, V71, P14, DOI 10.1159/000165170
   Nguyen MF, 2017, J ALZHEIMERS DIS, V58, P123, DOI 10.3233/JAD-160793
   Panza F, 2015, NAT REV NEUROL, V11
   Parham K, 2017, ENT-EAR NOSE THROAT, V96, P462, DOI 10.1177/014556131709601206
   Peracino A, 2016, AUDIOL NEURO-OTOL, V21, P3, DOI 10.1159/000448346
   Pisoni DB, 1996, LANG COGNITIVE PROC, V11, P681, DOI 10.1080/016909696387097
   Pronk M, 2013, EAR HEARING, V34, P722, DOI 10.1097/AUD.0b013e3182994eee
   Puglisi GE, 2015, INT J AUDIOL, V54, P44, DOI 10.3109/14992027.2015.1061709
   Rooth Meredith Anderson, 2017, N C Med J, V78, P118, DOI 10.18043/ncm.78.2.118
   Rutherford BR, 2018, AM J PSYCHIAT, V175, P215, DOI 10.1176/appi.ajp.2017.17040423
   Santangelo G, 2015, NEUROL SCI, V36, P585, DOI 10.1007/s10072-014-1995-y
   Schubotz W, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0145610
   Shen J, 2016, AM J AUDIOL, V25, P319, DOI 10.1044/2016_AJA-16-0032
   Siciliano M, 2019, NEUROL SCI, V40, P691, DOI 10.1007/s10072-019-3700-7
   Stern Daniel, 2018, Harefuah, V157, P374
   Strauss A, 2015, J NEUROSCI, V35, P3256, DOI 10.1523/JNEUROSCI.3357-14.2015
   Sundstrom S, 2018, CLIN LINGUIST PHONET, V32, P950, DOI 10.1080/02699206.2018.1469671
   Taitelbaum-Swead R, 2016, FOLIA PHONIATR LOGO, V68, P16, DOI 10.1159/000444749
   Thomson RS, 2017, LARYNGOSCOPE INVEST, V2, P69, DOI 10.1002/lio2.65
   Uchida Y, 2019, AURIS NASUS LARYNX, V46, P1, DOI 10.1016/j.anl.2018.08.010
   Vos SJB, 2017, J ALZHEIMERS DIS, V58, P537, DOI 10.3233/JAD-161208
   Wagener KC, 2006, INT J AUDIOL, V45, P26, DOI 10.1080/14992020500243851
   Wayne RV, 2015, AGEING RES REV, V23, P154, DOI 10.1016/j.arr.2015.06.002
   Zanetti O, 1998, AGE AGEING, V27, P615, DOI 10.1093/ageing/27.5.615
NR 70
TC 0
Z9 0
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD DEC 10
PY 2019
VL 13
AR 1279
DI 10.3389/fnins.2019.01279
PG 11
WC Neurosciences
SC Neurosciences & Neurology
GA JY2JA
UT WOS:000504245600001
PM 31920475
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Wang, LC
AF Wang, Li-Chih
TI The Relationships Among Temporal Processing, Rapid Naming, and Oral
   Reading Fluency in Chinese Children With and Without Dyslexia
SO LEARNING DISABILITY QUARTERLY
LA English
DT Article
DE reading; thinking; cognition
ID SPEECH-PERCEPTION; PHONOLOGICAL AWARENESS; DEFICIT THEORY; DIFFICULTIES;
   SENSITIVITY; AUTOMATICITY; INFORMATION; PERFORMANCE; ATTENTION; PROFILES
AB The relationships among visual and auditory temporal processing, rapid naming, and oral reading fluency in Chinese children with and without dyslexia were examined. Primary school-aged Chinese children with dyslexia (N = 47) and chronological-age-matched controls (N = 47) were recruited. Temporal processing, rapid naming, oral reading fluency, Chinese character reading, and nonverbal IQ were assessed. There were significant correlations among visual and auditory temporal processing, rapid naming, and oral reading fluency. The patterns of the relationships among these measures differed between the children with and without dyslexia. The path analyses revealed that visual temporal processing had significant direct and indirect effects (through rapid naming) on oral reading fluency; only the children with dyslexia showed a significant direct effect of auditory temporal processing. These findings have research and educational implications for enhancing the reading abilities of Chinese children with dyslexia.
C1 [Wang, Li-Chih] Educ Univ Hong Kong, Tai Po, Hong Kong, Peoples R China.
RP Wang, LC (corresponding author), Educ Univ Hong Kong, Tai Po, Dept Special Educ & Counselling, 10 Lo Ping Rd, Hong Kong, Peoples R China.
EM wanglca@eduhk.hk
RI WANG, Li-Chih/H-8173-2019
OI WANG, Li-Chih/0000-0002-4011-7305
CR BEARDEN WO, 1982, J MARKETING RES, V19, P425, DOI 10.2307/3151716
   Benasich AA, 1996, INFANT BEHAV DEV, V19, P339, DOI 10.1016/S0163-6383(96)90033-8
   Boets B, 2008, BRAIN LANG, V106, P29, DOI 10.1016/j.bandl.2007.12.004
   Boets B, 2007, NEUROPSYCHOLOGIA, V45, P1608, DOI 10.1016/j.neuropsychologia.2007.01.009
   Booth JR, 2000, SCI STUD READ, V4, P101, DOI DOI 10.1207/S1532799XSSR0402_02
   Bretherton L, 2003, J EXP CHILD PSYCHOL, V84, P218, DOI 10.1016/S0022-0965(03)00023-7
   Catts HW, 2002, J LEARN DISABIL-US, V35, P509
   Caylak E, 2011, J PEDIATR NEUROL, V9, P151, DOI 10.3233/JPN-2011-0455
   Chen J. H., 2006, RAVENS PROGR MATRICE
   Chung KKH, 2008, ANN DYSLEXIA, V58, P15, DOI 10.1007/s11881-008-0015-4
   Chung KKH, 2010, DYSLEXIA, V16, P2, DOI 10.1002/dys.392
   DeFrancis J., 1989, VISIBLE SPEECH DIVER
   Ding Y, 2010, J LEARN DISABIL-US, V43, P48, DOI 10.1177/0022219409345016
   Donker M, 2016, LEARN INDIVID DIFFER, V47, P80, DOI 10.1016/j.lindif.2015.12.011
   Farmer ME, 1995, PSYCHON B REV, V2, P460, DOI 10.3758/BF03210983
   Fostick L, 2014, J EXP PSYCHOL HUMAN, V40, P1799, DOI 10.1037/a0037527
   Fuchs L. S., 2001, SCI STUD READ, V5, P239, DOI DOI 10.1207/S1532799XSSR0503_3
   Georgiou GK, 2008, READ WRIT, V21, P885, DOI 10.1007/s11145-007-9096-4
   Gooch D, 2019, CHILD DEV, V90, pE565, DOI 10.1111/cdev.13220
   GOSWAMI U, 1989, J READING BEHAV, V21, P413, DOI 10.1080/10862968909547687
   Hair JF, 2012, J ACAD MARKET SCI, V40, P414, DOI 10.1007/s11747-011-0261-6
   Hasbrouck J, 2006, READ TEACH, V59, P636, DOI 10.1598/RT.59.7.3
   Henseler J, 2009, ADV INT MARKETING, V20, P277, DOI 10.1108/S1474-7979(2009)0000020014
   Ho CSH, 2004, COGNITION, V91, P43, DOI 10.1016/S0010-0277(03)00163-X
   Holdnack J. A., 2016, WISC V ASSESSMENT IN, P373
   Hood M, 2004, DYSLEXIA, V10, P234, DOI 10.1002/dys.273
   Hooper D., 2008, ELECT J BUSINESS RES, V6, P1, DOI DOI 10.21427/D7CF7R
   Huang H. S., 2001, CHINESE CHARACTER RE
   Kail R, 1999, APPL PSYCHOLINGUIST, V20, P303, DOI 10.1017/S0142716499002076
   KAIL R, 1994, DEV PSYCHOL, V30, P949, DOI 10.1037/0012-1649.30.6.949
   Katzir T, 2008, J LEARN DISABIL-US, V41, P47, DOI 10.1177/0022219407311325
   Klauda SL, 2008, J EDUC PSYCHOL, V100, P310, DOI 10.1037/0022-0663.100.2.310
   Klein R. M., 2002, READING WRITING INTE, V15, P207, DOI [10.1023/A:1013828723016, DOI 10.1023/A:1013828723016]
   Klenberg L, 2001, DEV NEUROPSYCHOL, V20, P407, DOI 10.1207/S15326942DN2001_6
   LABERGE D, 1974, COGNITIVE PSYCHOL, V6, P293, DOI 10.1016/0010-0285(74)90015-2
   Lallier M, 2010, VISION RES, V50, P1855, DOI 10.1016/j.visres.2010.06.006
   Landerl K, 2009, J EXP CHILD PSYCHOL, V103, P309, DOI 10.1016/j.jecp.2009.03.006
   Langer N, 2015, CEREB CORTEX, V25, P1441, DOI 10.1093/cercor/bht330
   Lei L, 2011, J CHILD PSYCHOL PSYC, V52, P212, DOI 10.1111/j.1469-7610.2010.02311.x
   Li XS, 2009, COGNITIVE PSYCHOL, V58, P525, DOI 10.1016/j.cogpsych.2009.02.003
   Liu D, 2016, READ WRIT, V29, P1435, DOI 10.1007/s11145-016-9644-x
   Liu D, 2015, SCI STUD READ, V19, P307, DOI 10.1080/10888438.2015.1030749
   Lobier M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0058097
   Lyon GR, 2003, ANN DYSLEXIA, V53, P1, DOI 10.1007/s11881-003-0001-9
   McLean GMT, 2011, J EXP PSYCHOL HUMAN, V37, P1957, DOI 10.1037/a0024668
   Moll K, 2015, APPL PSYCHOLINGUIST, V36, P203, DOI 10.1017/S0142716413000209
   Norton ES, 2012, ANNU REV PSYCHOL, V63, P427, DOI 10.1146/annurev-psych-120710-100431
   O'Brien RM, 2007, QUAL QUANT, V41, P673, DOI 10.1007/s11135-006-9018-6
   Pan J, 2011, J EDUC PSYCHOL, V103, P897, DOI 10.1037/a0024344
   Peng P, 2017, EDUC PSYCHOL REV, V29, P513, DOI 10.1007/s10648-016-9366-2
   Phillips DP, 2010, J AM ACAD AUDIOL, V21, P404, DOI 10.3766/jaaa.21.6.5
   Pinto Joana Cecilia Baptista Ramalho, 2011, J. Soc. Bras. Fonoaudiol., V23, P21, DOI 10.1590/S2179-64912011000100007
   Poelmans H, 2011, RES DEV DISABIL, V32, P2810, DOI 10.1016/j.ridd.2011.05.025
   Powell D, 2007, J EXP CHILD PSYCHOL, V98, P46, DOI 10.1016/j.jecp.2007.04.003
   Ramus F, 2001, NATURE, V412, P393, DOI 10.1038/35086683
   Ramus F, 2012, COGN NEUROPSYCHOL, V29, P104, DOI 10.1080/02643294.2012.677420
   Rasinski T, 2006, READ TEACH, V59, P704, DOI 10.1598/RT.59.7.10
   Ravid D, 2007, J RES READ, V30, P140, DOI 10.1111/j.1467-9817.2007.00340.x
   RUDEL RG, 1978, BRAIN LANG, V6, P52, DOI 10.1016/0093-934X(78)90043-3
   Savage R, 2005, BRAIN LANG, V93, P152, DOI 10.1016/j.bandl.2004.09.005
   Snowling M., 1998, CHILD ADOL MENT H-UK, V3, P4, DOI [10.1111/1475-3588.00201, DOI 10.1111/1475-3588.00201]
   Stoodley CJ, 2006, NEUROSCI LETT, V399, P264, DOI 10.1016/j.neulet.2006.02.004
   Strehlow U, 2006, EUR CHILD ADOLES PSY, V15, P19, DOI 10.1007/s00787-006-0500-4
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Tallal P., 2014, SPEECH LANGUAGE IMPA, P145
   Tan LH, 2005, P NATL ACAD SCI USA, V102, P8781, DOI 10.1073/pnas.0503523102
   Waber DP, 2004, J LEARN DISABIL-US, V37, P451, DOI 10.1177/00222194040370050701
   WAGNER MM, 1995, FUTURE CHILD, V5, P90, DOI 10.2307/1602359
   Walker KMM, 2006, BRAIN RES, V1124, P126, DOI 10.1016/j.brainres.2006.09.080
   Wang LC, 2019, ANN DYSLEXIA, V69, P166, DOI 10.1007/s11881-019-00176-8
   Wang LC, 2018, READ WRIT, V31, P1645, DOI 10.1007/s11145-018-9857-2
   Wang LC, 2018, J LEARN DISABIL-US, V51, P302, DOI 10.1177/0022219416680798
   Wolf M, 1999, J EDUC PSYCHOL, V91, P415, DOI 10.1037/0022-0663.91.3.415
   WOLF M, 1986, CHILD DEV, V57, P988, DOI 10.1111/j.1467-8624.1986.tb00260.x
   Wolf M, 2000, J LEARN DISABIL-US, V33, P387, DOI 10.1177/002221940003300409
   Zhang JA, 2010, EDUC PSYCHOL REV, V22, P323, DOI 10.1007/s10648-010-9137-4
   Zhao J, 2017, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.02082
NR 77
TC 0
Z9 0
U1 3
U2 9
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0731-9487
EI 2168-376X
J9 LEARN DISABILITY Q
JI Learn. Disabil. Q.
PD AUG
PY 2020
VL 43
IS 3
BP 167
EP 178
AR 0731948719892075
DI 10.1177/0731948719892075
EA DEC 2019
PG 12
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA MP6UV
UT WOS:000501943900001
DA 2021-02-24
ER

PT J
AU de Leeuw, E
   Stockall, L
   Lazaridou-Chatzigoga, D
   Masip, CG
AF de Leeuw, Esther
   Stockall, Linnaea
   Lazaridou-Chatzigoga, Dimitra
   Gorba Masip, Celia
TI Illusory vowels in Spanish-English sequential bilinguals: Evidence that
   accurate L2 perception is neither necessary nor sufficient for accurate
   L2 production
SO SECOND LANGUAGE RESEARCH
LA English
DT Article; Early Access
DE age of L2 acquisition; English; executive control; grammatical
   proficiency; L2 use; phonotactic constraints; speech perception; speech
   production; Spanish
ID SPEECH-PERCEPTION; EXECUTIVE CONTROL; VERBAL FLUENCY; LANGUAGE;
   LISTENERS; ACQUISITION; PLASTICITY; JAPANESE; SOUNDS; UM
AB Spanish native speakers are known to pronounce onset /sC/ clusters in English with a prothetic vowel, as in esport for sport, due to their native language phonotactic constraints. We assessed whether accurate production of e.g. spi instead of espi was related to accurate perceptual discrimination of this contrast in second language (L2) speech of Spanish-English sequential bilinguals. A same-different discrimination task in stimulus pairs such as spi-espi assessed speech perception and a phonemic verbal fluency task elicited speech production. Logistic mixed model regressions revealed significant differences in accuracy between the bilinguals and the English monolinguals, although some bilinguals performed within the monolingual range. For the production task, but not for the perception task, bilinguals with more exposure to English and greater grammatical knowledge of English performed significantly more accurately than those with less exposure and lower grammatical knowledge. There was no significant correlation between production accuracy and perception accuracy. Through examining phonotactic constraints, these results expand a growing body of research into single sounds which suggests dissociations between L2 perception and production. In contrast to predictions made by L2 speech models, the findings indicate that accurate L2 perception is neither necessary nor sufficient for accurate L2 production, and instead are interpreted to indicate that the two capacities recruit different executive control mechanisms and are acquired - at least to a certain extent - independently in L2 acquisition.
C1 [de Leeuw, Esther; Stockall, Linnaea] Queen Mary Univ London, Mile End Rd, London E10 5JP, England.
   [Lazaridou-Chatzigoga, Dimitra] Humboldt Univ, Berlin, Germany.
   [Lazaridou-Chatzigoga, Dimitra] Univ Cambridge, Cambridge, England.
   [Gorba Masip, Celia] Univ Autonoma Barcelona, Barcelona, Spain.
RP de Leeuw, E (corresponding author), Queen Mary Univ London, Mile End Rd, London E10 5JP, England.
EM e.deleeuw@qmul.ac.uk
RI Gorba, Celia/AAC-3129-2021
OI de Leeuw, Esther/0000-0003-0751-7451
FU British Academy [SG112797]
FX The authors are particularly grateful to Professor Juana Gil Fernandez
   who welcomed us to Madrid, where we collected most of the data at her
   Laboratorio de Fonetica of the University of Madrid, and to Professor
   Fernando Sanchez Miret at the University of Salamanca. Without their
   help, we would never have been able to conduct this study. We are also
   grateful to Annette Zhao for part of the data analysis, all of the
   participants who took part in this study, and to the British Academy for
   funding the project (SG112797; PI: EdeL, co-investigator: LS).
CR Baker W., 2006, IRAL-INT REV APPL LI, V44, P231, DOI [10.1515/IRAL.2006.010, DOI 10.1515/IRAL.2006.010]
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Beach E. F., 2001, INT J BILINGUAL, V5, P221, DOI DOI 10.1177/13670069010050020501
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Bialystok E, 2008, J EXP PSYCHOL LEARN, V34, P859, DOI 10.1037/0278-7393.34.4.859
   Bialystok E, 2017, PSYCHOL BULL, V143, P233, DOI 10.1037/bul0000099
   Bialystok E, 2009, BILING-LANG COGN, V12, P3, DOI 10.1017/S1366728908003477
   Boersma P, 2010, PRAAT
   Cabrelli J, 2019, J PHONETICS, V73, P55, DOI 10.1016/j.wocn.2018.10.006
   Carlson MT, 2016, BILING-LANG COGN, V19, P939, DOI 10.1017/S1366728915000334
   Cheshire J, 2011, J SOCIOLING, V15, P151, DOI 10.1111/j.1467-9841.2011.00478.x
   Clark HH, 2002, COGNITION, V84, P73, DOI 10.1016/S0010-0277(02)00017-3
   Cuetos F, 2011, ICPHS 17 C P HONG KO
   De Leeuw E., 2007, J GER LINGUIST, V19, P85, DOI DOI 10.1017/S1470542707000049
   de Leeuw E, 2019, J PHONETICS, V75, P88, DOI 10.1016/j.wocn.2019.05.003
   de Leeuw E, 2016, BILING-LANG COGN, V19, P907, DOI 10.1017/S1366728916000201
   Dupoux E, 1999, J EXP PSYCHOL HUMAN, V25, P1568, DOI 10.1037/0096-1523.25.6.1568
   Escudero P., 2005, LINGUISTIC PERCEPTIO
   Flege J, 1995, SPEECH PERCEPTION LI, P233
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   Flege JE, 2003, SPEECH COMMUN, V40, P467, DOI 10.1016/S0167-6393(02)00128-0
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   Fowler CA, 1996, J ACOUST SOC AM, V99, P1730, DOI 10.1121/1.415237
   Freeman MR, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00702
   Gollan TH, 2002, NEUROPSYCHOLOGY, V16, P562, DOI 10.1037//0894-4105.16.4.562
   Grogan A, 2009, CEREB CORTEX, V19, P2690, DOI 10.1093/cercor/bhp023
   Grosjean F., 1998, BILING-LANG COGN, V1, P131, DOI DOI 10.1017/S136672899800025X
   Gullberg M, 2003, LANGUAGE HIST QUESTI
   Halle PA, 2008, J EXP PSYCHOL HUMAN, V34, P177, DOI 10.1037/0096-1523.34.1.177
   Hualde Jose Ignacio, 2005, SOUNDS SPANISH
   Kartushina N, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01246
   KivistoDeSouza Hanna, 2015, THESIS
   Klein-Braley C., 1985, LANG TEST, V2, P76, DOI DOI 10.1177/026553228500200108
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Llisterri J, 1995, P 13 INT C PHON SCI
   MACLAY H, 1959, WORD, V15, P19, DOI 10.1080/00437956.1959.11659682
   Martinez-Celdran Eugenio, 2003, J INT PHON ASSOC, V33, P255, DOI DOI 10.1017/S0025100303001373
   Mills L, 2014, THESIS
   Miyake A, 2000, COGNITIVE PSYCHOL, V41, P49, DOI 10.1006/cogp.1999.0734
   Morales Pech D, 2011, REV ELECT INVESTIGAC, V13, P1
   Navarro Tomas, 1918, MANUAL PRONUNCIACION
   Newcombe F., 1969, MISSILE WOUNDS BRAIN
   Ohala JJ, 1996, J ACOUST SOC AM, V99, P1718, DOI 10.1121/1.414696
   Parlato-Oliveira E, 2010, J ACOUST SOC AM, V127, P3738, DOI 10.1121/1.3327792
   Portocarrero JS, 2007, ARCH CLIN NEUROPSYCH, V22, P415, DOI 10.1016/j.acn.2007.01.015
   Powell J, 2016, WHY WE LOVE MUSIC MO
   R Core Team, 2019, R LANG ENV STAT COMP
   Raatz U, 1981, ED217735 ERIC
   Rubinstein JS, 2001, J EXP PSYCHOL HUMAN, V27, P763, DOI 10.1037//0096-1523.27.4.763
   Sandoval TC, 2010, BILING-LANG COGN, V13, P231, DOI 10.1017/S1366728909990514
   Sauzeon H, 2011, J ADULT DEV, V18, P144, DOI 10.1007/s10804-010-9107-6
   SHELDON A, 1982, APPL PSYCHOLINGUIST, V3, P243, DOI 10.1017/S0142716400001417
   SHRIBERG EE, 1993, PHONETICA, V50, P172, DOI 10.1159/000261937
   So CK, 2014, STUD SECOND LANG ACQ, V36, P195, DOI 10.1017/S0272263114000047
   So CK, 2010, LANG SPEECH, V53, P273, DOI 10.1177/0023830909357156
   Tree JEF, 2001, MEM COGNITION, V29, P320, DOI 10.3758/BF03194926
   Zampini M., 1998, TEXAS PAPERS FOREIGN, V3, P85
NR 60
TC 0
Z9 0
U1 1
U2 8
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0267-6583
EI 1477-0326
J9 SECOND LANG RES
JI Second Lang. Res.
AR 0267658319886623
DI 10.1177/0267658319886623
EA DEC 2019
PG 32
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA JT3NJ
UT WOS:000500899800001
DA 2021-02-24
ER

PT J
AU Portes, C
   German, JS
AF Portes, Cristel
   German, James S.
TI Implicit effects of regional cues on the interpretation of intonation by
   Corsican French listeners
SO LABORATORY PHONOLOGY
LA English
DT Article
DE Intonation; sociophonetics; speech perception; implicit social adaption;
   Corsican French
ID EXEMPLAR; PERCEPTION; GRAMMAR
AB It is now well documented for different varieties of English that the speech production and perception systems rapidly adapt to contextual social cues. This adaptation is sensitive not only to speaker social identity but also to implicit social cues, suggesting that the underlying mechanism is automatic rather than controlled. While it has recently been shown that the interpretation of intonation depends on segmental cues to sociolect within the same utterance, the present study explores whether it also depends on implicit contextual social cues. Starting from the observation that a specific type of intonational contour is used differently in Corsican French and Continental French, we tested whether Corsican French listeners interpret this contour differently depending on which dialectal region is evoked by a visual cue. The results are consistent with this hypothesis, thus providing evidence for implicit social adaption in a new domain of linguistic behavior, specifically, the prosody-meaning interface. We describe an exemplar-based model of our results demonstrating that such models can be readily extended to capture the effects found by the present study.
C1 [Portes, Cristel; German, James S.] Aix Marseille Univ, CNRS, LPL, Aix En Provence, France.
RP Portes, C (corresponding author), Aix Marseille Univ, CNRS, LPL, Aix En Provence, France.
EM cristel.portes@lpl-aix.fr
OI Portes, Cristel/0000-0002-1764-2945
FU A*MIDEX project - Investissements d'Avenir French Government
   programFrench National Research Agency (ANR) [ANR-11-IDEX-0001-02];
   Institute for Language Communication and the Brain [ANR-16-CONV-0002]
FX This study was made possible through support by the A*MIDEX project (no
   ANR-11-IDEX-0001-02) funded by the Investissements d'Avenir French
   Government program, managed by the French National Research Agency (ANR)
   and by the Institute for Language Communication and the Brain
   (ANR-16-CONV-0002). We are grateful to Susanne Gahl, Mirjam Ernestus,
   and Kip Wilson for their help in improving this paper, and to two
   anonymous reviewers for their careful and helpful comments. Thanks to
   Amandine Michelas and Oriana Reed-Collins for their help in carrying out
   the experiment, and to Leonardo Lancia for his advice on statistical
   design. A special thanks to the participants at the Universite de Corse
   for their willingness to participate, and to Jean-Michel Gea and Stella
   Medori for their hospitality and logistical assistance in Corte.
CR Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bod R, 2006, LINGUIST REV, V23, P291, DOI 10.1515/TLR.2006.012
   Bod R, 2009, COGNITIVE SCI, V33, P752, DOI 10.1111/j.1551-6709.2009.01031.x
   Boula de Mareuil P, 2016, LINGUE ISOLE ISOLE L, P3
   Boula de Mareuil P. B, 2012, JOURNEES ETUDE PAROL, V1, P609
   Bybee J, 2006, LANGUAGE, V82, P711, DOI 10.1353/lan.2006.0186
   Chang Y. S., 2015, P 18 INT C PHON SCI
   de Mareuil PB, 2012, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON SPEECH PROSODY, VOLS I AND II, P418
   Delais-Roussarie Elisabeth, 2015, INTONATION ROMANCE, P63, DOI [10.1093/acprof:oso/9780199685332.003.0003, DOI 10.1093/ACPROF:OSO/9780199685332.001.0001]
   Drager K, 2016, AWARENESS CONTROL SO, P1, DOI DOI 10.1017/CBO9781139680448.003
   Drager K., 2006, TE REO, V48, P55
   Drager K, 2011, LANG SPEECH, V54, P99, DOI 10.1177/0023830910388017
   Dufour S, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01200
   Filippi P. M., 1992, THESIS
   FLETCHER J, 2004, PROSODIC TYPOLOGY PH, P390, DOI DOI 10.1093/ACPROF:OSO/9780199249633.003.0014
   German J. S, 2017, C PHON PHON EUR 2017
   German JS, 2013, J PHONETICS, V41, P228, DOI 10.1016/j.wocn.2013.03.001
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Grabe E., 2004, REGIONAL VARIATION I, P9
   Grice M, OXFORD HDB LANGUAGE
   Hay J, 2010, LANG SPEECH, V53, P447, DOI 10.1177/0023830910372489
   Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Johnson K., 2007, EXPT APPROACHES PHON, P25
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Johnson K., 1997, OSU WORKING PAP LING, V50, P101
   Johnson K, 2006, J PHONETICS, V34, P485, DOI 10.1016/j.wocn.2005.08.004
   Jun S. A., 2002, PROBUS, V14, P147, DOI [10.1515/prbs.2002.002, DOI 10.1515/PRBS.2002.002]
   Jun SA, 2000, TEXT SPEECH LANG TEC, V15, P209
   Labov William, 1970, LANGUAGE POVERTY, P153
   Labov William, 1972, SOCIOLINGUISTIC PATT
   Ladd D. Robert, 2008, INTONATIONAL PHONOLO, DOI [10.1017/CBO9780511808814, DOI 10.1017/CBO9780511808814]
   Lawrence D, 2015, P 18 INT C PHON SCI
   Leach P, 1988, J INT PHON ASSOC, V18, P125, DOI [10.1017/S002510030000373X, DOI 10.1017/S002510030000373X]
   MARTIN P., 2009, INTONATION FRANCAIS
   McGowan KB, 2016, AWARENESS CONTROL SO, P25, DOI DOI 10.1017/CBO9781139680448.004
   Mendoza-Denton N, 2003, PROBABILISTIC LINGUISTICS, P97
   MERTENS P, 1992, INT J APPL LINGUISTI, V95, P145, DOI DOI 10.1075/ITL.95-96.07MER
   Michelas A, 2016, LANG SPEECH, V59, P266, DOI 10.1177/0023830915587337
   MILLER JD, 1989, J ACOUST SOC AM, V85, P2114, DOI 10.1121/1.397862
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Pierrehumbert JB, 2003, PROBABILISTIC LINGUISTICS, P177
   Portes C, 2015, VERBUM, V2
   Portes C., 2004, THESIS
   Portes C, 2014, J PRAGMATICS, V74, P15, DOI 10.1016/j.pragma.2014.08.013
   Post Brechtje, 2000, TONAL PHRASAL STRUCT
   R Core Team, 2017, R LANG ENV STAT COMP
   Racz P, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00051
   Sanchez K, 2015, J PHONETICS, V48, P76, DOI 10.1016/j.wocn.2014.10.004
   SANKOFF D, 1989, LANG VAR CHANGE, V1, P1
   Sichel-Bazin R, 2015, THESIS
   Strand EA, 1996, NATURAL LANGUAGE PROCESSING AND SPEECH TECHNOLOGY, P14
   Walker M, 2019, LAB PHONOL, V10, DOI 10.5334/labphon.90
   Walsh M, 2010, COGNITIVE SCI, V34, P537, DOI 10.1111/j.1551-6709.2010.01099.x
   Warren P, 2017, LAB PHONOL, V8, DOI 10.5334/labphon.92
   Wedel Andrew, 2004, THESIS
   Wedel AB, 2006, LINGUIST REV, V23, P247, DOI 10.1515/TLR.2006.010
NR 61
TC 1
Z9 1
U1 0
U2 0
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD DEC 4
PY 2019
VL 10
IS 1
AR 22
DI 10.5334/labphon.162
PG 26
WC Linguistics; Language & Linguistics
SC Linguistics
GA KE2NB
UT WOS:000508395300001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Knowland, VCP
   Fletcher, F
   Henderson, LM
   Walker, S
   Norbury, CF
   Gaskell, MG
AF Knowland, Victoria C. P.
   Fletcher, Fay
   Henderson, Lisa-Marie
   Walker, Sarah
   Norbury, Courtenay F.
   Gaskell, M. Gareth
TI Sleep Promotes Phonological Learning in Children Across Language and
   Autism Spectra
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID CATEGORICAL SPEECH-PERCEPTION; VIGILANCE TEST PVT; MEMORY CONSOLIDATION;
   IMPAIRMENT; DEFICITS; ADULTS; WORDS; SENSITIVITY; FREQUENCY; SPINDLES
AB Purpose: Establishing stable and flexible phonological representations is a key component of language development and one which is thought to vary across children with neurodevelopmental disorders affecting language acquisition. Sleep is understood to support the learning and generalization of new phonological mappings in adults, but this remains to be examined in children. This study therefore explored the time course of phonological learning in childhood and how it varies by structural language and autism symptomatology.
   Method: Seventy-seven 7- to 13-year-old children, 30 with high autism symptomatology, were included in the study; structural language ability varied across the sample. Children learned new phonological mappings based on synthesized speech tokens in the morning; performance was then charted via repetition (without feedback) over 24 hr and followed up 4 weeks later. On the night following learning, children's sleep was monitored with polysomnography.
   Results: A period of sleep but not wake was associated with improvement on the phonological learning task in childhood. Sleep was associated with improved performance for both trained items and novel items. Structural language ability predicted overall task performance, though language ability did not predict degree of change from one session to the next. By contrast, autism symptomatology did not explain task performance. With respect to sleep architecture, rapid eye movement features were associated with greater phonological generalization.
   Conclusions: Children's sleep was associated with improvement in performance on both trained and novel items. Phonological generalization was associated with brain activity during rapid eye movement sleep. This study furthers our understanding of individual differences in the acquisition of new phonological mappings and the role of sleep in this process over childhood.
C1 [Knowland, Victoria C. P.; Fletcher, Fay; Henderson, Lisa-Marie; Walker, Sarah; Gaskell, M. Gareth] Univ York, Dept Psychol, York, N Yorkshire, England.
   [Norbury, Courtenay F.] UCL, Div Psychol & Language Sci, London, England.
RP Knowland, VCP (corresponding author), Univ York, Dept Psychol, York, N Yorkshire, England.
EM Victoria.knowland@york.ac.uk
OI Norbury, Courtenay/0000-0002-5101-6120
FU Economic and Social Research CouncilUK Research & Innovation
   (UKRI)Economic & Social Research Council (ESRC) [ES/N009924/1]
FX This work was supported by an Economic and Social Research Council grant
   (reference: ES/N009924/1) awarded to Lisa Henderson, Gareth Gaskell, and
   Courtenay Norbury. We thank Alex Bettarini, Alex Bond, Lolly Hernandez,
   Natasha Thompson, Amanda Olsson, and Lois Perry for helping with data
   collection and the children, families, and schools who agreed to
   participate.
CR Achenbach T. M., 1983, MANUAL CHILD BEHAV C, P230
   American Academy of Sleep Medicine, 2016, AASM MANUAL SCORING
   Anthony JL, 2010, READ WRIT, V23, P969, DOI 10.1007/s11145-009-9185-7
   Audacity Team, 1999, AUD VERS 2 1 3
   Basner M, 2011, ACTA ASTRONAUT, V69, P949, DOI 10.1016/j.actaastro.2011.07.015
   Basner M, 2011, SLEEP, V34, P581, DOI 10.1093/sleep/34.5.581
   Bates D. M., 2012, LME4 LINEAR MIXED EF
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Batterink LJ, 2017, BRAIN LANG, V167, P83, DOI 10.1016/j.bandl.2015.09.003
   Batterink LJ, 2014, NEUROPSYCHOLOGIA, V65, P169, DOI 10.1016/j.neuropsychologia.2014.10.024
   Belsley D A, 1980, REGRESSION DIAGNOSTI, P292, DOI DOI 10.1002/0471725153
   Bishop D., 2003, CHILDRENS COMMUNICAT
   Bishop DVM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0037326
   Botting N, 2018, INT J DEV DISABIL, V64, P225, DOI 10.1080/20473869.2017.1283766
   Brysbaert M, 2014, BEHAV RES METHODS, V46, P904, DOI 10.3758/s13428-013-0403-5
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Coady JA, 2005, J SPEECH LANG HEAR R, V48, P944, DOI 10.1044/1092-4388(2005/065)
   Collet Gregory, 2012, Front Neurol, V3, P97, DOI 10.3389/fneur.2012.00097
   Constantino JN, 2007, J AUTISM DEV DISORD, V37, P1256, DOI 10.1007/s10803-006-0269-9
   Cox R, 2012, LEARN MEMORY, V19, P264, DOI 10.1101/lm.026252.112
   Crane L, 2016, AUTISM, V20, P153, DOI 10.1177/1362361315573636
   Diaz-Roman A, 2018, EVID-BASED MENT HEAL, V21, P146, DOI 10.1136/ebmental-2018-300037
   Diekelmann S, 2010, NAT REV NEUROSCI, V11, P114, DOI 10.1038/nrn2762
   Dominick KC, 2007, RES DEV DISABIL, V28, P145, DOI 10.1016/j.ridd.2006.02.003
   Dunn L.M., 2009, BRIT PICTURE VOCABUL
   DUVELLEROYHOMMET C, 1995, NEUROPEDIATRICS, V26, P14, DOI 10.1055/s-2007-979713
   Earle FS, 2018, NEUROSCI LETT, V666, P58, DOI 10.1016/j.neulet.2017.12.030
   Earle FS, 2017, NEUROSCI LETT, V636, P77, DOI 10.1016/j.neulet.2016.10.044
   Earle FS, 2015, J ACOUST SOC AM, V137, pEL91, DOI 10.1121/1.4903918
   Earle FS, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01192
   Eisner F, 2006, J ACOUST SOC AM, V119, P1950, DOI 10.1121/1.2178721
   Elliott C., 2011, BRIT ABILITY SCALES
   Elrod MG, 2015, J DEV BEHAV PEDIATR, V36, P166, DOI 10.1097/DBP.0000000000000140
   Fenn KM, 2013, COGNITION, V128, P280, DOI 10.1016/j.cognition.2013.04.007
   Fenn KM, 2003, NATURE, V425, P614, DOI 10.1038/nature01951
   Ferman S, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013648
   Fletcher F., 2019, DEV SCI
   Francis AL, 2000, PERCEPT PSYCHOPHYS, V62, P1668, DOI 10.3758/BF03212164
   Gagnon R. T., 1978, Proceedings of the 1978 IEEE International Conference on Acoustics, Speech and Signal Processing, P175
   Gilliam J. E., 2013, G AUTISM RATING SCAL
   Godbout R, 2000, NEUROREPORT, V11, P127, DOI 10.1097/00001756-200001170-00025
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   Henderson L, 2015, DEV PSYCHOL, V51, P406, DOI 10.1037/a0038786
   Henderson L, 2014, DEVELOPMENTAL SCI, V17, P858, DOI 10.1111/desc.12169
   Henderson LM, 2012, DEVELOPMENTAL SCI, V15, P674, DOI 10.1111/j.1467-7687.2012.01172.x
   Hervais-Adelman A, 2008, J EXP PSYCHOL HUMAN, V34, P460, DOI 10.1037/0096-1523.34.2.460
   Jarvinen-Pasley A, 2008, DEVELOPMENTAL SCI, V11, P109, DOI 10.1111/j.1467-7687.2007.00644.x
   Joanisse MF, 2004, CURR DIR PSYCHOL SCI, V13, P156, DOI 10.1111/j.0963-7214.2004.00297.x
   Joanisse MF, 2003, BRAIN LANG, V86, P40, DOI 10.1016/S0093-934X(02)00533-3
   Juneja M, 2013, TRANSCULT STUD, P2
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Knowland VCP, 2016, J SPEECH LANG HEAR R, V59, P1, DOI 10.1044/2015_JSLHR-S-14-0269
   Kuperman V, 2012, BEHAV RES METHODS, V44, P978, DOI 10.3758/s13428-012-0210-4
   Latchourmane C. V., 2017, NEURON, V95
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   Limoges E, 2005, BRAIN, V128, P1049, DOI 10.1093/brain/awh425
   Maillart C, 2004, J SPEECH LANG HEAR R, V47, P187, DOI 10.1044/1092-4388(2004/016)
   Marco EJ, 2011, PEDIATR RES, V69, p48R, DOI [10.1203/PDR.0b013e3182130c54, 10.1109/SPL.2011.5782616]
   Maski K, 2015, SLEEP, V38, P1955, DOI 10.5665/sleep.5248
   MathWorks, 2017, MATLAB REL 2017A
   McClelland JL, 2006, TRENDS COGN SCI, V10, P363, DOI 10.1016/j.tics.2006.06.007
   Mielke J., 2013, P M AC, V19
   MINES MA, 1978, LANG SPEECH, V21, P221, DOI 10.1177/002383097802100302
   Nieuwenhuis R, 2012, R J, V4, P38
   Norbury CF, 2010, NEUROPSYCHOLOGIA, V48, P4012, DOI 10.1016/j.neuropsychologia.2010.10.015
   Ohayon MM, 2004, SLEEP, V27, P1255, DOI 10.1093/sleep/27.7.1255
   Owens JA, 2000, SLEEP, V23, P1043
   Picard A, 1998, DEV MED CHILD NEUROL, V40, P595
   Plaisted KC, 2001, DEVELOPMENT OF AUTISM: PERSPECTIVES FROM THEORY AND RESEARCH, P149
   Psychology Software Tools, 2012, E PRIME 2 0
   R Core Team, 2017, R LANG ENV STAT COMP
   Robertson EK, 2009, DEVELOPMENTAL SCI, V12, P753, DOI 10.1111/j.1467-7687.2009.00806.x
   SCHWAB EC, 1985, HUM FACTORS, V27, P395
   Semel E, 2006, CLIN EVALUATION LANG
   Stackhouse J., 1997, CHILDRENS SPEECH LIT
   Staresina BP, 2015, NAT NEUROSCI, V18, P1679, DOI 10.1038/nn.4119
   Stark RE, 1996, J SPEECH HEAR RES, V39, P676, DOI 10.1044/jshr.3904.676
   Stewart ME, 2018, J AUTISM DEV DISORD, V48, P72, DOI 10.1007/s10803-017-3284-0
   Tamaki M, 2017, SLEEP, V40, pA85, DOI 10.1093/sleepj/zsx050.231
   Tessier S, 2015, INT J PSYCHOPHYSIOL, V97, P58, DOI 10.1016/j.ijpsycho.2015.05.003
   Trotti LM, 2017, SLEEP MED REV, V35, P76, DOI 10.1016/j.smrv.2016.08.005
   Tsanas A, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00181
   UCLA Statistical Consulting Group, INTR FEAT SAS SAS LE
   Vandewalle E, 2012, RES DEV DISABIL, V33, P635, DOI 10.1016/j.ridd.2011.11.005
   Vitevitch MS, 2004, BEHAV RES METH INS C, V36, P481, DOI 10.3758/BF03195594
   Wang XY, 2017, SCI REP-UK, V7, P1, DOI 10.1038/srep43254
   Wei YN, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006322
   Werchan DM, 2013, NEUROBIOL LEARN MEM, V100, P70, DOI 10.1016/j.nlm.2012.12.006
   Wickham H, 2016, GGPLOT2 ELEGANT GRAP
   Wilhelm I, 2013, NAT NEUROSCI, V16, P391, DOI 10.1038/nn.3343
   Williams D, 2008, PSYCHOL BULL, V134, P944, DOI 10.1037/a0013743
   Witteman MJ, 2015, LANG SPEECH, V58, P168, DOI 10.1177/0023830914528102
   Xie X., 2016, J ACOUST SOC AM, V140, P3342
   Xie X, 2018, LANG COGN NEUROSCI, V33, P196, DOI 10.1080/23273798.2017.1369551
   Ziegler JC, 2005, P NATL ACAD SCI USA, V102, P14110, DOI 10.1073/pnas.0504446102
   Ziegler JC, 2011, J EXP CHILD PSYCHOL, V110, P362, DOI 10.1016/j.jecp.2011.05.001
NR 97
TC 1
Z9 1
U1 4
U2 4
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD DEC
PY 2019
VL 62
IS 12
BP 4235
EP 4255
DI 10.1044/2019_JSLHR-S-19-0098
PG 21
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA ND2XY
UT WOS:000561769300001
PM 31770054
OA Green Published, Green Accepted, Other Gold
DA 2021-02-24
ER

PT J
AU Taitelbaum-Swead, R
   Kozol, Z
   Fostick, L
AF Taitelbaum-Swead, Riki
   Kozol, Zvi
   Fostick, Leah
TI Listening Effort Among Adults With and Without
   Attention-Deficit/Hyperactivity Disorder
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID WORKING-MEMORY CAPACITY; HEARING-AID USE; SPEECH-DISCRIMINATION;
   YOUNG-ADULTS; OLDER-ADULTS; ADHD; NOISE; TASK; PERFORMANCE; CHILDREN
AB Purpose: Few studies have assessed listening effort (LE)-the cognitive resources required to perceive speech-among populations with intact hearing but reduced availability of cognitive resources. Attention/deficit/hyperactivity disorder (ADHD) is theorized to restrict attention span, possibly making speech perception in adverse conditions more challenging. This study examined the effect of ADHD on LE among adults using a behavioral dual-task paradigm (DTP).
   Method: Thirty-nine normal-hearing adults (aged 21-27 years) participated: 19 with ADHD (ADHD group) and 20 without ADHD (control group). Baseline group differences were measured in visual and auditory attention as well as speech perception. LE using DTP was assessed as the performance difference on a visual-motor task versus a simultaneous auditory and visual-motor task.
   Results: Group differences in attention were confirmed by differences in visual attention (larger reaction times between congruent and incongruent conditions) and auditory attention (lower accuracy in the presence of distractors) among the ADHD group, compared to the controls. LE was greater among the ADHD group than the control group. Nevertheless, no group differences were found in speech perception.
   Conclusions: LE is increased among those with ADHD. As a DTP assumes limited cognitive capacity to allocate attentional resources, LE among those with ADHD may be increased because higher level cognitive processes are more taxed in this population. Studies on LE using a DTP should take into consideration mechanisms of selective and divided attention. Among young adults who need to continuously process great volumes of auditory and visual information, much more effort may be expended by those with ADHD than those without it. As a result, those with ADHD may be more prone to fatigue and irritability, similar to those who are engaged in more outwardly demanding tasks.
C1 [Taitelbaum-Swead, Riki; Fostick, Leah] Ariel Univ, Dept Commun Disorders, Ariel, Israel.
   [Taitelbaum-Swead, Riki] Meuhedet Hlth Serv, Tel Aviv, Israel.
   [Kozol, Zvi] Ariel Univ, Dept Physiotherapy, Ariel, Israel.
RP Taitelbaum-Swead, R (corresponding author), Ariel Univ, Dept Commun Disorders, Ariel, Israel.; Taitelbaum-Swead, R (corresponding author), Meuhedet Hlth Serv, Tel Aviv, Israel.
EM rikits@ariel.ac.il
RI Fostick, Leah/E-6115-2017
OI Fostick, Leah/0000-0003-3594-6229
CR American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   Arlinger S, 2009, SCAND J PSYCHOL, V50, P371, DOI 10.1111/j.1467-9450.2009.00753.x
   Biehl SC, 2015, ADHD-ATTEND DEFICIT, V7, P19, DOI 10.1007/s12402-014-0148-8
   Blomberg R, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01536
   BOOTHROYD A, 1968, J ACOUST SOC AM, V43, P362, DOI 10.1121/1.1910787
   Broadbent D.E., 1958, PERCEPTION COMMUNICA, P81, DOI [10.1016/B978-1-4832-0079-8.50007-4, DOI 10.1016/B978-1-4832-0079-8.50007-4, 10.1037/10037-005, DOI 10.1037/10037-005]
   Brown VA, 2019, LANG COGN NEUROSCI, V34, P628, DOI 10.1080/23273798.2018.1562084
   Childress AC, 2016, EXPERT OPIN PHARMACO, V17, P1171, DOI 10.1080/14656566.2016.1182986
   Corbett B, 1999, ARCH CLIN NEUROPSYCH, V14, P373, DOI 10.1016/S0887-6177(98)00037-7
   Desjardins JL, 2014, EAR HEARING, V35, P600, DOI 10.1097/AUD.0000000000000028
   DOWNS DW, 1978, J SPEECH HEAR RES, V21, P702, DOI 10.1044/jshr.2104.702
   DOWNS DW, 1982, J SPEECH HEAR DISORD, V47, P189, DOI 10.1044/jshd.4702.189
   Fostick L, 2017, J SPEECH LANG HEAR R, V60, P2124, DOI 10.1044/2017_JSLHR-H-16-0074
   Fraser S, 2010, J SPEECH LANG HEAR R, V53, P18, DOI 10.1044/1092-4388(2009/08-0140)
   Freyaldenhoven Melinda C, 2005, J Am Acad Audiol, V16, P677, DOI 10.3766/jaaa.16.9.5
   Gagne JP, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216516687287
   Gallun FJ, 2007, PERCEPT PSYCHOPHYS, V69, P757, DOI 10.3758/BF03193777
   Geffner D, 1996, CHILD PSYCHIAT HUM D, V26, P169, DOI 10.1007/BF02353358
   Goldman R., 1970, GOLDMAN FRISTOE WOOD
   Goodman DW, 2016, DRUG AGING, V33, P27, DOI 10.1007/s40266-015-0327-0
   Gosselin PA, 2010, CAN J SPEECH-LANG PA, V34, P43
   Gosselin PA, 2011, J SPEECH LANG HEAR R, V54, P944, DOI 10.1044/1092-4388(2010/10-0069)
   Hornsby BWY, 2013, EAR HEARING, V34, P523, DOI 10.1097/AUD.0b013e31828003d8
   Hughes Kathryn C, 2013, Cochlear Implants Int, V14, P121, DOI 10.1179/1754762812Y.0000000009
   Hughes SE, 2018, EAR HEARING, V39, P922, DOI 10.1097/AUD.0000000000000553
   JASKOWSKI P, 1993, PERCEPTION, V22, P681, DOI 10.1068/p220681
   Kieffer MJ, 2013, READ RES QUART, V48, P333, DOI 10.1002/rrq.54
   Kiessling J, 2003, INT J AUDIOL, V42, pS92
   Koelewijn T, 2018, HEARING RES, V367, P106, DOI 10.1016/j.heares.2018.07.011
   Koelewijn T, 2015, HEARING RES, V323, P81, DOI 10.1016/j.heares.2015.02.004
   LAM CM, 1991, REM SPEC EDUC, V12, P40, DOI 10.1177/074193259101200208
   Lucker JR, 1996, CHILD PSYCHIAT HUM D, V26, P181, DOI 10.1007/BF02353359
   McGarrigle R, 2014, INT J AUDIOL, V53, P433, DOI 10.3109/14992027.2014.890296
   McInnes A, 2003, J ABNORM CHILD PSYCH, V31, P427, DOI 10.1023/A:1023895602957
   Michalek AMP, 2014, INT J AUDIOL, V53, P145, DOI 10.3109/14992027.2013.866282
   Mishra S, 2013, J SPEECH LANG HEAR R, V56, P1120, DOI 10.1044/1092-4388(2012/12-0033)
   Mor B, 2015, J ATTEN DISORD, V19, P527, DOI 10.1177/1087054714527790
   NAVON D, 1979, PSYCHOL REV, V86, P214, DOI 10.1037/0033-295X.86.3.214
   Ng EHN, 2013, INT J AUDIOL, V52, P433, DOI 10.3109/14992027.2013.776181
   NORMAN DA, 1975, COGNITIVE PSYCHOL, V7, P44, DOI 10.1016/0010-0285(75)90004-3
   Pals C, 2013, J SPEECH LANG HEAR R, V56, P1075, DOI 10.1044/1092-4388(2012/12-0074)
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   Picou EM, 2014, EAR HEARING, V35, P611, DOI 10.1097/AUD.0000000000000055
   Polanczyk G, 2007, AM J PSYCHIAT, V164, P942, DOI 10.1176/appi.ajp.164.6.942
   RABBITT P, 1991, ACTA OTO-LARYNGOL, P167
   Ronnberg J, 2003, INT J AUDIOL, V42, pS68
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Rudner M, 2016, EAR HEARING, V37, p69S, DOI 10.1097/AUD.0000000000000302
   Rudner M, 2012, J AM ACAD AUDIOL, V23, P577, DOI 10.3766/jaaa.23.7.7
   Sarampalis A, 2009, J SPEECH LANG HEAR R, V52, P1230, DOI 10.1044/1092-4388(2009/08-0111)
   Seeman S, 2015, J SPEECH LANG HEAR R, V58, P1781, DOI 10.1044/2015_JSLHR-H-14-0180
   Silva KL, 2013, J ATTEN DISORD, V17, P483, DOI 10.1177/1087054711434155
   Soderlund G, 2007, J CHILD PSYCHOL PSYC, V48, P840, DOI 10.1111/j.1469-7610.2007.01749.x
   Soderlund GBW, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00034
   Soutschek A, 2013, ACTA PSYCHOL, V143, P71, DOI 10.1016/j.actpsy.2013.02.013
   Strauss DJ, 2017, COGN AFFECT BEHAV NE, V17, P809, DOI 10.3758/s13415-017-0513-0
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   Taitelbaum-Swead R, 2016, FOLIA PHONIATR LOGO, V68, P16, DOI 10.1159/000444749
   Tarver J, 2014, CHILD CARE HLTH DEV, V40, P762, DOI 10.1111/cch.12139
   Thomas R, 2015, PEDIATRICS, V135, pE994, DOI 10.1542/peds.2014-3482
   Tun PA, 2009, PSYCHOL AGING, V24, P761, DOI 10.1037/a0014802
   Vakil E., 2016, J ATTEN DISORD, V23, P1160
   Van Engen KJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00577
   van Mourik R, 2011, J CHILD PSYCHOL PSYC, V52, P265, DOI 10.1111/j.1469-7610.2010.02339.x
   Wassenberg R, 2010, J ATTEN DISORD, V13, P374, DOI 10.1177/1087054708326111
   Wechsler D., 1997, WAIS 3 WECHSLER ADUL
   Wendt D, 2018, HEARING RES, V369, P67, DOI 10.1016/j.heares.2018.05.006
   Wu YH, 2014, EAR HEARING, V35, P623, DOI 10.1097/AUD.0000000000000079
   Zekveld AA, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518777174
NR 70
TC 1
Z9 1
U1 1
U2 5
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD DEC
PY 2019
VL 62
IS 12
BP 4554
EP 4563
DI 10.1044/2019_JSLHR-H-19-0134
PG 10
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA ND2XY
UT WOS:000561769300024
PM 31747524
DA 2021-02-24
ER

PT J
AU De Keyser, K
   De Letter, M
   De Groote, E
   Santens, P
   Talsma, D
   Botteldooren, D
   Bockstael, A
AF De Keyser, Kim
   De Letter, Miet
   De Groote, Evelien
   Santens, Patrick
   Talsma, Durk
   Botteldooren, Dick
   Bockstael, Annelies
TI Systematic Audiological Assessment of Auditory Functioning in Patients
   With Parkinson's Disease
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID QUALITY-OF-LIFE; NONMOTOR SYMPTOMS; OTOACOUSTIC EMISSIONS; DOPAMINERGIC
   MEDICATION; HEARING IMPAIRMENT; SPEECH-PERCEPTION; INNER;
   DISCRIMINATION; POTENTIALS; PHYSIOLOGY
AB Purpose: Alterations in primary auditory functioning have been reported in patients with Parkinson's disease (PD). Despite the current findings, the pathophysiological mechanisms underlying these alterations remain unclear, and the effect of dopaminergic medication on auditory functioning in PD has been explored insufficiently. Therefore, this study aimed to systematically investigate primary auditory functioning in patients with PD by using both subjective and objective audiological measurements.
   Method: In this case-control study, 25 patients with PD and 25 age-, gender-, and education-matched healthy controls underwent an audiological test battery consisting of tonal audiometry, short increment sensitivity index, otoacoustic emissions (OAEs), and speech audiometry. Patients with PD were tested in the on- and off-medication states.
   Results: Increased OAE amplitudes were found when patients with PD were tested without dopaminergic medication. In addition, speech audiometry in silence and multitalker babble noise demonstrated higher phoneme scores for patients with PD in the off-medication condition. The results showed no differences in auditory functioning between patients with PD in the on-medication condition and healthy controls. No effect of disease stage or motor score was evident.
   Conclusions: This study provides evidence for a top-down involvement in auditory processing in PD at both central and peripheral levels. Most important, the increase in OAE amplitude in the off-medication condition in PD is hypothesized to be linked to a dysfunction of the olivocochlear efferent system, which is known to have an inhibitory effect on outer hair cell functioning. Future studies may clarify whether OAEs may facilitate an early diagnosis of PD.
C1 [De Keyser, Kim; De Letter, Miet; De Groote, Evelien] Univ Ghent, Dept Rehabil Sci, Ghent, Belgium.
   [Santens, Patrick] Ghent Univ Hosp, Dept Neurol, Ghent, Belgium.
   [Talsma, Durk] Univ Ghent, Dept Expt Psychol, Ghent, Belgium.
   [Botteldooren, Dick] Univ Ghent, Dept Informat Technol INTEC, Acoust Res Grp, Ghent, Belgium.
   [Bockstael, Annelies] Univ Montreal, Ecole Orthophonie & Audiol, Montreal, PQ, Canada.
RP De Keyser, K (corresponding author), Univ Ghent, Dept Rehabil Sci, Ghent, Belgium.
EM Kim.DeKeyser@UGent.be
FU PhD fellowship grant of the Fonds Wetenschappelijk Onderzoek-Vlaanderen
   (Research Foundation-Flanders)FWO
FX This work was supported by a PhD fellowship grant of the Fonds
   Wetenschappelijk Onderzoek-Vlaanderen (Research Foundation-Flanders).
   The funding source had no role in study design, data analysis, data
   interpretation, or writing of the report.
CR Abur D, 2018, J SPEECH LANG HEAR R, V61, P1487, DOI 10.1044/2018_JSLHR-H-17-0382
   Akil O, 2008, JARO-J ASSOC RES OTO, V9, P452, DOI 10.1007/s10162-008-0134-y
   Alain C, 2007, J AM ACAD AUDIOL, V18, P573, DOI 10.3766/jaaa.18.7.5
   Barone P, 2017, INT REV NEUROBIOL, V133, P499, DOI [10.1016/bs.im.2017.05.023, 10.1016/bs.irn.2017.05.023]
   BECK AT, 1961, ARCH GEN PSYCHIAT, V4, P561, DOI 10.1001/archpsyc.1961.01710120031004
   Bockstael A, 2015, NOISE HEALTH, V17, P198, DOI 10.4103/1463-1741.160688
   Braak H, 2003, NEUROBIOL AGING, V24, P197, DOI 10.1016/S0197-4580(02)00065-9
   Bronnick KS, 2010, NEUROBIOL AGING, V31, P104, DOI 10.1016/j.neurobiolaging.2008.02.021
   Celik M, 2000, PARKINSONISM RELAT D, V6, P95, DOI 10.1016/S1353-8020(99)00056-5
   Chaudhuri KR, 2006, LANCET NEUROL, V5, P235, DOI 10.1016/S1474-4422(06)70373-8
   Clark JP, 2014, J COMMUN DISORD, V51, P1, DOI 10.1016/j.jcomdis.2014.08.001
   Comi C, 2014, PARKINSONISM RELAT D, V20, P1329, DOI 10.1016/j.parkreldis.2014.10.010
   Cools R, 2001, CEREB CORTEX, V11, P1136, DOI 10.1093/cercor/11.12.1136
   Cools R, 2011, BIOL PSYCHIAT, V69, pE113, DOI 10.1016/j.biopsych.2011.03.028
   Darrow KN, 2006, J COMP NEUROL, V498, P403, DOI 10.1002/cne.21050
   De Groote E., 2019, CENTRAL AUDITORY PRO
   De Keyser K, 2016, J SPEECH LANG HEAR R, V59, P915, DOI 10.1044/2016_JSLHR-S-15-0197
   de Swart BJM, 2003, NEUROLOGY, V60, P498, DOI 10.1212/01.WNL.0000044480.95458.56
   Defer GL, 1999, MOVEMENT DISORD, V14, P572, DOI 10.1002/1531-8257(199907)14:4<572::AID-MDS1005>3.0.CO;2-C
   Folmer RL, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/2618587
   Fox C, 1997, AM J SPEECH-LANG PAT, V6, P85, DOI DOI 10.1044/1058-0360.0602.85
   Georgiev D, 2015, ACTA PSYCHOL, V156, P45, DOI 10.1016/j.actpsy.2015.02.001
   Goetz CG, 2007, MOVEMENT DISORD, V22, P41, DOI 10.1002/mds.21198
   Guehl D, 2008, NEUROPSYCHOLOGIA, V46, P2326, DOI 10.1016/j.neuropsychologia.2008.03.007
   Guinan JJ, 2006, EAR HEARING, V27, P589, DOI 10.1097/01.aud.0000240507.83072.e7
   Heald SLM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00035
   Ho AK, 2000, MOVEMENT DISORD, V15, P1125, DOI 10.1002/1531-8257(200011)15:6<1125::AID-MDS1010>3.0.CO;2-R
   HOEHN MM, 1967, NEUROLOGY, V17, P427, DOI 10.1212/WNL.17.5.427
   Jankovic J, 2008, J NEUROL NEUROSUR PS, V79, P368, DOI 10.1136/jnnp.2007.131045
   JERGER J, 1959, ARCHIV OTOLARYNGOL, V69, P200
   Keppler H, 2010, INT J AUDIOL, V49, P99, DOI 10.3109/14992020903300431
   Keppler H, 2010, CLIN NEUROPHYSIOL, V121, P359, DOI 10.1016/j.clinph.2009.11.003
   Knudson IM, 2014, J NEUROPHYSIOL, V112, P3197, DOI 10.1152/jn.00576.2014
   Kotz SA, 2009, CORTEX, V45, P982, DOI 10.1016/j.cortex.2009.02.010
   Kwan LC, 2011, PARKINSONS DIS-US, V2011, DOI 10.4061/2011/389767
   Lendvai B, 2011, NEUROCHEM INT, V59, P150, DOI 10.1016/j.neuint.2011.05.015
   Lewald J, 2004, COGNITIVE BRAIN RES, V21, P335, DOI 10.1016/j.cogbrainres.2004.06.008
   Meister H, 2017, HNO, V65, P189, DOI 10.1007/s00106-016-0229-4
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   NORTON S J, 1992, Seminars in Hearing, V13, P1, DOI 10.1055/s-0028-1085137
   Park A, 2009, J NEUROL, V256, pS293, DOI 10.1007/s00415-009-5240-1
   Pell ID, 1996, CORTEX, V32, P693, DOI 10.1016/S0010-9452(96)80039-6
   Pfeiffer RF, 2016, PARKINSONISM RELAT D, V22, pS119, DOI 10.1016/j.parkreldis.2015.09.004
   Pisani V, 2015, PARKINSONISM RELAT D, V21, P987, DOI 10.1016/j.parkreldis.2015.06.007
   Prakash KM, 2016, EUR J NEUROL, V23, P854, DOI 10.1111/ene.12950
   PUJOL R, 1994, BRIT J AUDIOL, V28, P185, DOI 10.3109/03005369409086567
   Pujol R, 1999, ANN NY ACAD SCI, V884, P249, DOI 10.1111/j.1749-6632.1999.tb08646.x
   Rietdijk CD, 2017, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00037
   Ruel J, 2001, EUR J NEUROSCI, V14, P977, DOI 10.1046/j.0953-816x.2001.01721.x
   Ruel J, 2007, HEARING RES, V227, P19, DOI 10.1016/j.heares.2006.08.017
   Schroder C, 2006, MOVEMENT DISORD, V21, P1774, DOI 10.1002/mds.21038
   Shalash AS, 2017, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00055
   Tomlinson CL, 2010, MOVEMENT DISORD, V25, P2649, DOI 10.1002/mds.23429
   Toro C, 2015, J NEUROSCI, V35, P16494, DOI 10.1523/JNEUROSCI.1691-15.2015
   Troche J, 2012, AM J SPEECH-LANG PAT, V21, P258, DOI 10.1044/1058-0360(2012/11-0007)
   Vitale C, 2016, PARKINSONISM RELAT D, V22, pS138, DOI 10.1016/j.parkreldis.2015.09.040
   Vitale C, 2012, MOVEMENT DISORD, V27, P1530, DOI 10.1002/mds.25149
   WHITEHEAD ML, 1994, IEEE ENG MED BIOL, V13, P210, DOI 10.1109/51.281681
   Yylmaz S, 2009, EUR ARCH OTO-RHINO-L, V266, P669, DOI 10.1007/s00405-009-0933-8
NR 59
TC 2
Z9 2
U1 3
U2 3
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD DEC
PY 2019
VL 62
IS 12
BP 4564
EP 4577
DI 10.1044/2019_JSLHR-H-19-0097
PG 14
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA ND2XY
UT WOS:000561769300025
PM 31770043
DA 2021-02-24
ER

PT J
AU Howson, PJ
   Monahan, PJ
AF Howson, Phil J.
   Monahan, Philip J.
TI Perceptual motivation for rhotics as a class
SO SPEECH COMMUNICATION
LA English
DT Article
DE Speech Perception; Phonetics-phonology; Rhotic Typology; Rhotics;
   Natural; Classes
ID VERTICAL-BAR; ULTRASOUND; COARTICULATION; PACKAGE; MODELS
AB Finding phonetic correlates of rhotics as a natural class has been elusive, leading to the suggestion that any class-based relationship between different rhotic categories is purely phonological in nature. This paper examines native English speakers' perception of three different non-native rhotics (i.e., /r (sic) RI) compared to non-native sounds from four other manners of articulation (stops, nasals, fricatives, and laterals). The results revealed that speakers cannot reliably discriminate between the rhotics examined here and that the perceptual distance between members of the class of rhotics is smaller than the other tested classes, aside from the comparison with laterals. The current results suggest that there is an acoustic-perceptual correlate to rhotics as a natural class and that their perception explains the relative rarity of large rhotic inventories cross-linguistically. The comparison with laterals also suggests why rhotics are often paired with laterals in inventories with two or more liquids.
C1 [Howson, Phil J.] Univ Oregon, Dept Linguist, 161 Straub Hall 1290, Eugene, OR 97403 USA.
   [Howson, Phil J.; Monahan, Philip J.] Univ Toronto, Dept Linguist, Toronto, ON, Canada.
   [Monahan, Philip J.] Univ Toronto Scarborough, Ctr French & Linguist, Toronto, ON, Canada.
   [Monahan, Philip J.] Univ Toronto Scarborough, Dept Psychol, Toronto, ON, Canada.
RP Howson, PJ (corresponding author), Univ Oregon, Dept Linguist, 161 Straub Hall 1290, Eugene, OR 97403 USA.; Howson, PJ (corresponding author), Univ Toronto, Dept Linguist, Toronto, ON, Canada.
EM philh@uoregon.edu
OI Monahan, Philip/0000-0001-8637-1889
FU Social Sciences and Humanities Research Council (SSHRC) of CanadaSocial
   Sciences and Humanities Research Council of Canada (SSHRC)
   [771-2015-0048, IDG 430-15-00647]
FX This work was supported by the Social Sciences and Humanities Research
   Council (SSHRC) of Canada (#771-2015-0048) to Phil J. Howson and (IDG
   430-15-00647) to Philip J. Monahan.
CR Al-Tamimi F., 2011, INSTRUMENTAL STUDIES, P163
   Al-Tamimi J, 2017, LAB PHONOL, V8, DOI 10.5334/labphon.19
   Alwan A, 1997, J ACOUST SOC AM, V101, P1078, DOI 10.1121/1.417972
   Azevedo M., 1981, HISPANIA, V64, P273
   Baltazani M., 2013, RHOTICS NEW DATA PER, P125
   Barbosa P. A., 2004, J INT PHON ASSOC, V34, P227, DOI DOI 10.1017/S0025100304001756
   Basumatati P., 2005, INTRO BORO LANGUAGE
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boyce SE, 2016, CLIN LINGUIST PHONET, V30, P174, DOI 10.3109/02699206.2015.1127999
   Braden B., 1986, COLL MATH J, V17, P326, DOI [10.2307/2686282, DOI 10.2307/2686282]
   Browman Catherine P, 1992, SR111 HASK LAB, V112, P23
   Carre R., 1992, Journal d'Acoustique, V5, P141
   Celata C., 2019, ROMANCE PHONETICS PH, P91
   Charrad M, 2014, J STAT SOFTW, V61, P1
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Cox T.F., 2001, MULTIDIMENSIONAL SCA
   Creelman C.D., 2004, J EXPER PSYCHOL HUM, V5, P146
   Cristofaro-Silva T., 1992, THESIS
   Davidson L, 2006, J ACOUST SOC AM, V120, P407, DOI 10.1121/1.2205133
   DELATTRE P, 1968, LINGUISTICS, P29
   DELATTRE P, 1971, PHONETICA, V23, P129, DOI 10.1159/000259336
   Dixon R.M.W., 1991, HDB AUSTR LANGUAGES, V2, P348
   DUNSTAN E, 1969, 12 NIGERIAN LANGUAGE
   Espy-Wilson CY, 2000, J ACOUST SOC AM, V108, P343, DOI 10.1121/1.429469
   Fant G., 1960, ACOUSTIC THEORY SPEE
   Flemming Edward, 2004, PHONETICALLY BASED P, P232, DOI DOI 10.1017/CBO9780511486401
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   Fujimura O, 1997, HDB PHONETIC SCI, P65
   Gu C, 2002, SPR S STAT
   Haden EF, 1955, LANGUAGE, V31, P504, DOI 10.2307/411363
   Hawkins S., 1994, ICSLP 94. 1994 International Conference on Spoken Language Processing, P57
   Heselwood B., 2009, LEEDS WORKING PAPERS, V14, P49
   HOCKING RR, 1983, TECHNOMETRICS, V25, P219, DOI 10.2307/1268603
   Howson P, 2017, J INT PHON ASSOC, V28, P1
   Howson P.J., 2018, THESIS
   Howson P, 2018, PHONETICA, V75, P132, DOI 10.1159/000481783
   Howson P, 2014, J INT PHON ASSOC, V44, P115, DOI 10.1017/S0025100313000339
   Johnson K., 2008, QUANTITATIVE METHODS
   Josephs Lewis S., 1975, PALAUAN REFERENCE GR
   Kaland C., 2017, LANG SPEECH, P1
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Ladefoged P., 2003, PHONETIC DATA ANAL I
   Ladefoged Peter, 1996, SOUNDS WORLDS LANGUA
   Lindau Mona, 1985, PHONETIC LINGUISTICS, P157
   MacMillan NA, 1991, DETECTION THEORY USE
   MacQueen J., 1967, P 5 BERK S MATH STAT, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Maddieson I., 1984, PATTERNS SOUNDS
   Mascaro J., 2003, DISTRIBUTION RHOTICS, P25
   Mateus Maria H., 2000, PHONOLOGY PORTUGUESE
   Moisik S. R., 2013, THESIS
   Narayanan S, 1999, J ACOUST SOC AM, V106, P1993, DOI 10.1121/1.427946
   Nolan F, 1983, CAMBRIDGE STUDIES SP
   OHALA JJ, 1990, J PHONETICS, V18, P153, DOI 10.1016/S0095-4470(19)30399-7
   Ohala John J., 1992, DIACHRONY SYNCHRONY, P309
   Proctor M., 2011, LAB PHONOL, V2, P451, DOI DOI 10.1515/LABPHON.2011.017
   Proctor Michael, 2009, THESIS
   R Development Core Team, 2018, R LANG ENV STAT COMP
   RATCLIFF R, 1993, PSYCHOL BULL, V114, P510, DOI 10.1037/0033-2909.114.3.510
   Recasens D, 1997, J ACOUST SOC AM, V102, P544, DOI 10.1121/1.419727
   Recasens D, 1999, J PHONETICS, V27, P143, DOI 10.1006/jpho.1999.0092
   Rennicke I., 2011, REV ESTUDOS LINGUIST, V1, P149
   Sagey E. C., 1986, THESIS
   SATTERTHWAITE FE, 1946, BIOMETRICS BULL, V2, P110, DOI 10.2307/3002019
   Schaarschmidt G., 1998, HIST PHONOLOGY UPPER
   Scobbie J.M., 2010, INTERFACES LINGUISTI, P257
   Silva A., 2003, P 15 INT C PHON SCI, P1863
   Silva A., 1999, ICPHS SAN FRANCISCO, P2211
   Sole M. J., 2007, EXPT APPROACHES PHON, P175
   SOLI SD, 1979, J ACOUST SOC AM, V66, P46, DOI 10.1121/1.382972
   Stevens K.N., 1989, ACOUSTIC PHONETICS
   Tabain M, 2018, J PHONETICS, V66, P63, DOI 10.1016/j.wocn.2017.09.006
   Thurgood G., 1999, ANCIENT CHAM MODERN
   Tiede M. K., 2004, J ACOUST SOC AM, V115, P2633, DOI DOI 10.1121/1.4784878
   TUKEY JW, 1949, BIOMETRICS, V5, P99, DOI 10.2307/3001913
   Velso J., 2015, OSLO STUDIES LANGUAG, P323
   Walsh-Dickey L., 1997, THESIS
   WERKER JF, 1985, PERCEPT PSYCHOPHYS, V37, P35, DOI 10.3758/BF03207136
   West P, 1999, J PHONETICS, V27, P405, DOI 10.1006/jpho.1999.0102
   WHALEN DH, 1990, J PHONETICS, V18, P3, DOI 10.1016/S0095-4470(19)30356-0
   Wickham H, 2016, GGPLOT2 ELEGANT GRAP
   Wiese Richard, 2001, R ATICS SOCIOLINGUIS, P11
   WURM SA, 1972, LANGUAGES AUSTR TASM
   Zhou XH, 2008, J ACOUST SOC AM, V123, P4466, DOI 10.1121/1.2902168
NR 83
TC 1
Z9 1
U1 1
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-6393
EI 1872-7182
J9 SPEECH COMMUN
JI Speech Commun.
PD DEC
PY 2019
VL 115
BP 15
EP 28
DI 10.1016/j.specom.2019.10.002
PG 14
WC Acoustics; Computer Science, Interdisciplinary Applications
SC Acoustics; Computer Science
GA LC4PF
UT WOS:000525305600002
OA Other Gold
DA 2021-02-24
ER

PT J
AU Zhou, X
   Innes-Brown, H
   McKay, CM
AF Zhou, Xin
   Innes-Brown, Hamish
   McKay, Colette M.
TI Audio-visual integration in cochlear implant listeners and the effect of
   age difference
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH-PERCEPTION; STATISTICAL FACILITATION; MULTISENSORY INTEGRATION;
   DEAF ADULTS; HEARING; USERS; RACE; REORGANIZATION; BRAIN
AB This study aimed to investigate differences in audio-visual (AV) integration between cochlear implant (CI) listeners and normal-hearing (NH) adults. A secondary aim was to investigate the effect of age differences by examining AV integration in groups of older and younger NH adults. Seventeen CI listeners, 13 similarly aged NH adults, and 16 younger NH adults were recruited. Two speech identification experiments were conducted to evaluate AV integration of speech cues. In the first experiment, reaction times in audio-alone (A-alone), visual-alone (V-alone), and AV conditions were measured during a speeded task in which participants were asked to identify a target sound /aSa/ among 11 alternatives. A race model was applied to evaluate AV integration. In the second experiment, identification accuracies were measured using a closed set of consonants and an open set of consonant-nucleus-consonant words. The authors quantified AV integration using a combination of a probability model and a cue integration model (which model participants' AV accuracy by assuming no or optimal integration, respectively). The results found that experienced CI listeners showed no better AV integration than their similarly aged NH adults. Further, there was no significant difference in AV integration between the younger and older NH adults. (C) 2019 Acoustical Society of America.
C1 [Zhou, Xin; Innes-Brown, Hamish; McKay, Colette M.] Bion Inst Australia, 384-388 East Melbourne, Melbourne, Vic 3002, Australia.
   [Zhou, Xin; Innes-Brown, Hamish; McKay, Colette M.] Univ Melbourne, Dept Med Bion, 384-388 East Melbourne, Melbourne, Vic 3002, Australia.
RP Zhou, X (corresponding author), Bion Inst Australia, 384-388 East Melbourne, Melbourne, Vic 3002, Australia.
EM xzhou353@wisc.edu
RI Zhou, Xin/AAU-7702-2020
OI zhou, xin/0000-0002-5285-947X
FU Melbourne UniversityUniversity of Melbourne; veski fellowship; Garnett
   Passe grant; Victorian Government through its Operational Infrastructure
   Support Program
FX The authors thank Ms. Renee Tsongas in the University of Melbourne for
   the speech video recording. The authors appreciate the support from all
   the research participants in Melbourne, Australia. This research was
   supported by a Melbourne University Ph.D. scholarship to X.Z., a veski
   fellowship, and a Garnett Passe grant to C.M.M. The Bionics Institute
   acknowledges the support it receives from the Victorian Government
   through its Operational Infrastructure Support Program.
CR Barone P, 2011, SPRINGER HANDB AUDIT, V39, P365, DOI 10.1007/978-1-4419-9434-9_15
   Baum Sarah H, 2017, Curr Behav Neurosci Rep, V4, P198, DOI 10.1007/s40473-017-0124-7
   Bernstein LE, 2000, PERCEPT PSYCHOPHYS, V62, P233, DOI 10.3758/BF03205546
   Bernstein LE, 2001, J SPEECH LANG HEAR R, V44, P5, DOI 10.1044/1092-4388(2001/001)
   BLAMEY P J, 1989, Journal of Rehabilitation Research and Development, V26, P15
   Brooks CJ, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00192
   Butera IM, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-29598-x
   Desai S, 2008, J ACOUST SOC AM, V123, P428, DOI 10.1121/1.2816573
   Dorman MF, 2016, J SPEECH LANG HEAR R, V59, P1505, DOI 10.1044/2016_JSLHR-H-15-0312
   Doucet ME, 2006, BRAIN, V129, P3376, DOI 10.1093/brain/awl264
   Kiesel A, 2007, BEHAV RES METHODS, V39, P539, DOI 10.3758/BF03193024
   Lazard DS, 2014, HEARING RES, V307, P136, DOI 10.1016/j.heares.2013.08.006
   Leiva A, 2015, PSYCHOL RES-PSYCH FO, V79, P401, DOI 10.1007/s00426-014-0573-5
   Macmillan N, 2004, DETECTION THEORY USE
   Magnotti JF, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202908
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MILLER J, 1982, COGNITIVE PSYCHOL, V14, P247, DOI 10.1016/0010-0285(82)90010-X
   Miller J, 2016, ATTEN PERCEPT PSYCHO, V78, P516, DOI 10.3758/s13414-015-1017-z
   PETERSON GE, 1962, J SPEECH HEAR DISORD, V27, P62, DOI 10.1044/jshd.2701.62
   RAAB DH, 1962, T NEW YORK ACAD SCI, V24, P574, DOI 10.1111/j.2164-0947.1962.tb01433.x
   Rouger J, 2007, P NATL ACAD SCI USA, V104, P7295, DOI 10.1073/pnas.0609419104
   Schierholz I, 2015, HEARING RES, V328, P133, DOI 10.1016/j.heares.2015.08.009
   Spehar BP, 2008, J ACOUST SOC AM, V123, P2858, DOI 10.1121/1.2890748
   Stevenson RA, 2017, EAR HEARING, V38, P521, DOI 10.1097/AUD.0000000000000435
   Stevenson RA, 2015, NEUROBIOL AGING, V36, P283, DOI 10.1016/j.neurobiolaging.2014.08.003
   Strelnikov K, 2009, SCAND J PSYCHOL, V50, P437, DOI 10.1111/j.1467-9450.2009.00741.x
   Stropahl M, 2017, PSYCHON B REV, V24, P863, DOI 10.3758/s13423-016-1148-9
   Stropahl M, 2017, HEARING RES, V343, P128, DOI 10.1016/j.heares.2016.07.005
   Tye-Murray N, 2016, PSYCHOL AGING, V31, P380, DOI 10.1037/pag0000094
   Tye-Murray N, 2010, EAR HEARING, V31, P636, DOI 10.1097/AUD.0b013e3181ddf7ff
   Ulrich R, 2007, BEHAV RES METHODS, V39, P291, DOI 10.3758/BF03193160
   Winneke AH, 2011, PSYCHOL AGING, V26, P427, DOI 10.1037/a0021683
NR 32
TC 1
Z9 1
U1 2
U2 4
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD DEC
PY 2019
VL 146
IS 6
BP 4144
EP 4154
DI 10.1121/1.5134783
PG 11
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA KG8ZS
UT WOS:000510240600019
PM 31893708
DA 2021-02-24
ER

PT J
AU Halliday, LF
   Rosen, S
   Tuomainen, O
   Calcus, A
AF Halliday, Lorna F.
   Rosen, Stuart
   Tuomainen, Outi
   Calcus, Axelle
TI Impaired frequency selectivity and sensitivity to temporal fine
   structure, but not envelope cues, in children with mild-to-moderate
   sensorineural hearing loss
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID MODULATION TRANSFER-FUNCTIONS; AMPLITUDE-MODULATION; SPEECH-PERCEPTION;
   READING-DISABILITY; CARRIER FREQUENCY; DISCRIMINATION; NOISE;
   PERFORMANCE; PLACE; LISTENERS
AB Psychophysical thresholds were measured for 8-16 year-old children with mild-to-moderate sensorineural hearing loss (MMHL; N 1/4 46) on a battery of auditory processing tasks that included measures designed to be dependent upon frequency selectivity and sensitivity to temporal fine structure (TFS) or envelope cues. Children with MMHL who wore hearing aids were tested in both unaided and aided conditions, and all were compared to a group of normally hearing (NH) age-matched controls. Children with MMHL performed more poorly than NH controls on tasks considered to be dependent upon frequency selectivity, sensitivity to TFS, and speech discrimination (/bA/-/dA/), but not on tasks measuring sensitivity to envelope cues. Auditory processing deficits remained regardless of age, were observed in both unaided and aided conditions, and could not be attributed to differences in nonverbal IQ or attention between groups. However, better auditory processing in children with MMHL was predicted by better audiometric thresholds and, for aided tasks only, higher levels of maternal education. These results suggest that, as for adults with MMHL, children with MMHL may show deficits in frequency selectivity and sensitivity to TFS, but sensitivity to the envelope may remain intact. (C) 2019 Author(s). All article content, except where otherwise noted, is licensed under a Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).
C1 [Halliday, Lorna F.; Rosen, Stuart; Tuomainen, Outi; Calcus, Axelle] UCL, Speech Hearing & Phonet Sci, Chandler House,2 Wakefield St, London WC1N 1PF, England.
   [Halliday, Lorna F.] Univ Cambridge, MRC, Cognit & Brain Sci Unit, 15 Chaucer Rd, Cambridge CB2 7EF, England.
   [Calcus, Axelle] Paris Sci & Lettres Res Univ, Ecole Normale Super, Lab Syst Perceptifs, CNRS UMR 8248, Paris, France.
RP Halliday, LF (corresponding author), UCL, Speech Hearing & Phonet Sci, Chandler House,2 Wakefield St, London WC1N 1PF, England.; Halliday, LF (corresponding author), Univ Cambridge, MRC, Cognit & Brain Sci Unit, 15 Chaucer Rd, Cambridge CB2 7EF, England.
EM lorna.halliday@mrc-cbu.cam.ac.uk
RI Tuomainen, Outi/H-8675-2019; Calcus, Axelle/AAS-8137-2020
OI Tuomainen, Outi/0000-0002-8654-2446; Rosen, Stuart/0000-0002-9376-2148
FU Economic and Social Research Council First Grants Award
   [RES-061-25-0440]; Medical Research Council Senior Fellowship in Hearing
   Research [MR/S002464/1]; People Programme (Marie Curie Actions) of the
   European Union's Seventh Framework Programme FP7/2007-2013/under REA
   Grant [FP7-607139]
FX The authors would like to thank Steve Nevard for his assistance with
   setting up the laboratory facilities, Michael Coleman for the
   development of the psychophysical testing software, and Paraic Scanlon
   for assistance with participant testing. Tim Schoof assisted in the
   preparation of Fig. 1. Thanks also to Brian Moore, Robert Carlyon, and
   Laurianne Cabrera for comments on an earlier draft of this manuscript.
   The authors are especially grateful to all the children who
   participated, along with their parents, as well as the Local Educational
   Authorities and schools who assisted with recruitment. This work was
   funded by an Economic and Social Research Council First Grants Award
   (RES-061-25-0440) and Medical Research Council Senior Fellowship in
   Hearing Research (MR/S002464/1) awarded to L.F.H., and by a People
   Programme (Marie Curie Actions) of the European Union's Seventh
   Framework Programme FP7/2007-2013/under REA Grant Agreement No.
   FP7-607139 (iCARE). L.F.H. conceived of, designed and coordinated the
   study, analysed the data, and drafted the manuscript. S.R. prepared a
   subset of the stimuli, and helped draft the manuscript. O.T. collected
   and analysed the data, and helped draft the manuscript. A.C. prepared
   the figures and commented on the manuscript. All authors gave final
   approval for publication.
CR BACON SP, 1992, J SPEECH HEAR RES, V35, P642, DOI 10.1044/jshr.3503.642
   Bacon SP, 2002, J SPEECH LANG HEAR R, V45, P392, DOI 10.1044/1092-4388(2002/031)
   Baker RJ, 2001, BRIT J AUDIOL, V35, P43, DOI 10.1080/03005364.2001.11742730
   Bernstein JGW, 2006, J ACOUST SOC AM, V120, P3929, DOI 10.1121/1.2372452
   Bishop DVM, 2010, J NEUROSCI, V30, P15578, DOI 10.1523/JNEUROSCI.2217-10.2010
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Breier JI, 2003, J SPEECH LANG HEAR R, V46, P31, DOI 10.1044/1092-4388(2003/003)
   British Society of Audiology, 2011, REC PROC PUR TON AIR
   Buran BN, 2014, J NEUROSCI, V34, P2276, DOI 10.1523/JNEUROSCI.0647-13.2014
   Calcus A, 2019, ELIFE, V8, DOI 10.7554/eLife.46965
   Caras ML, 2015, J NEUROSCI, V35, P10831, DOI 10.1523/JNEUROSCI.0837-15.2015
   Carney LH, 2002, ACTA ACUST UNITED AC, V88, P334
   Clark J G, 1981, ASHA, V23, P493
   Davies-Venn E, 2015, J ACOUST SOC AM, V138, P492, DOI 10.1121/1.4922700
   DAVIS A, 1997, HEALTH TECHNOL ASSES, V1, P1
   Dawes P, 2008, J SPEECH LANG HEAR R, V51, P1002, DOI 10.1044/1092-4388(2008/073)
   Ernst SMA, 2010, J ACOUST SOC AM, V128, P3642, DOI 10.1121/1.3506350
   Ferguson Melanie A., 2014, Seminars in Hearing, V35, P1, DOI 10.1055/s-0033-1363520
   Field A., 2013, DISCOVERING STAT USI
   Fortnum HM, 2001, BRIT MED J, V323, P536, DOI 10.1136/bmj.323.7312.536
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Fullgrabe C, 2003, HEARING RES, V178, P35, DOI 10.1016/S0378-5955(03)00027-3
   GLASBERG BR, 1986, J ACOUST SOC AM, V79, P1020, DOI 10.1121/1.393374
   GLASBERG BR, 1989, SCAND AUDIOL, P1
   Grose JH, 2016, J ACOUST SOC AM, V140, pEL184, DOI 10.1121/1.4960075
   HALL JW, 1994, J ACOUST SOC AM, V96, P150, DOI 10.1121/1.410474
   Halliday LF, 2006, BRAIN LANG, V97, P200, DOI 10.1016/j.bandl.2005.10.007
   Halliday LF, 2005, J SPEECH LANG HEAR R, V48, P1187, DOI 10.1044/1092-4388(2005/083)
   Halliday LF, 2017, J SPEECH LANG HEAR R, V60, P1551, DOI 10.1044/2016_JSLHR-L-16-0297
   Halliday LF, 2017, COGNITION, V166, P139, DOI 10.1016/j.cognition.2017.04.014
   HARRISON RV, 1979, ARCH OTO-RHINO-LARYN, V224, P71, DOI 10.1007/BF00455226
   Hartley DEH, 2002, J ACOUST SOC AM, V112, P2962, DOI 10.1121/1.1512701
   HAZAN V, 1991, PERCEPT PSYCHOPHYS, V49, P187, DOI 10.3758/BF03205038
   Hedrick MS, 2000, J SPEECH LANG HEAR R, V43, P1174, DOI 10.1044/jslhr.4305.1174
   Henry KS, 2016, J NEUROSCI, V36, P2227, DOI 10.1523/JNEUROSCI.3944-15.2016
   Henry KS, 2013, HEARING RES, V303, P39, DOI 10.1016/j.heares.2013.01.014
   Henry KS, 2012, NAT NEUROSCI, V15, P1362, DOI 10.1038/nn.3216
   Hirsh IJ, 1996, ANNU REV PSYCHOL, V47, P461, DOI 10.1146/annurev.psych.47.1.461
   Hopkins K, 2011, J ACOUST SOC AM, V130, P334, DOI 10.1121/1.3585848
   Hutcheson G., 1999, MULTIVARIATE SOCIAL
   Jenstad LM, 2005, J SPEECH LANG HEAR R, V48, P651, DOI 10.1044/1092-4388(2005/045)
   Jerger S, 2007, EAR HEARING, V28, P754, DOI 10.1097/AUD.0b013e318157f049
   Kale S, 2012, HEARING RES, V286, P64, DOI 10.1016/j.heares.2012.02.004
   Kale S, 2010, JARO-J ASSOC RES OTO, V11, P657, DOI 10.1007/s10162-010-0223-6
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Kujawa SG, 2009, J NEUROSCI, V29, P14077, DOI 10.1523/JNEUROSCI.2845-09.2009
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Lyzenga J, 1999, J ACOUST SOC AM, V105, P2792, DOI 10.1121/1.426896
   Miller RL, 1997, J ACOUST SOC AM, V101, P3602, DOI 10.1121/1.418321
   Moore B. C. J, 1986, AUDITORY FREQUENCY S, P407, DOI DOI 10.1007/978-1-4613-2247-4_44
   Moore B. C. J., 2007, COCHLEAR HEARING LOS
   MOORE BCJ, 1992, BRIT J AUDIOL, V26, P229, DOI 10.3109/03005369209076641
   Moore BCJ, 2002, J ACOUST SOC AM, V111, P327, DOI 10.1121/1.1424871
   Moore BCJ, 2014, AUDITORY PROCESSING OF TEMPORAL FINE STRUCTURE: EFFECTS OF AGE AND HEARING LOSS, P1, DOI 10.1142/9064
   Moore BCJ, 1996, J ACOUST SOC AM, V100, P2320, DOI 10.1121/1.417941
   Moore BCJ, 2004, HEARING RES, V188, P70, DOI 10.1016/S0378-5955(03)00347-2
   MOORE BCJ, 1995, J ACOUST SOC AM, V97, P2468, DOI 10.1121/1.411967
   Moore BCJ, 2001, J ACOUST SOC AM, V110, P1067, DOI 10.1121/1.1385177
   Moore BCJ, 1996, J ACOUST SOC AM, V100, P481, DOI 10.1121/1.415861
   Moore BCJ, 2008, JARO-J ASSOC RES OTO, V9, P399, DOI 10.1007/s10162-008-0143-x
   Moore BCJ, 2012, J ACOUST SOC AM, V132, P1542, DOI 10.1121/1.4739444
   Moore BCJ, 2011, HEARING RES, V276, P88, DOI 10.1016/j.heares.2011.01.003
   Moore DR, 2008, HEARING RES, V238, P147, DOI 10.1016/j.heares.2007.11.013
   Moore DR, 2011, EAR HEARING, V32, P269, DOI 10.1097/AUD.0b013e318201c468
   Moore DR, 2010, PEDIATRICS, V126, pE382, DOI 10.1542/peds.2009-2826
   Mowery TM, 2015, CEREB CORTEX, V25, P2083, DOI 10.1093/cercor/bhu013
   Oxenham AJ, 2009, J ACOUST SOC AM, V125, P2189, DOI 10.1121/1.3089220
   Oxenham AJ, 2009, J ACOUST SOC AM, V125, P457, DOI 10.1121/1.3021299
   Paraouty N, 2016, J ACOUST SOC AM, V140, P121, DOI 10.1121/1.4955078
   Rance G, 2004, EAR HEARING, V25, P34, DOI 10.1097/01.AUD.0000111259.59690.B8
   Roach NW, 2004, PERCEPTION, V33, P817, DOI 10.1068/p5207
   Rosen MJ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0041514
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   RUGGERO MA, 1994, AUDIOLOGY, V33, P131
   RUGGERO MA, 1991, J NEUROSCI, V11, P1057
   Schlittenlacher J, 2016, J ACOUST SOC AM, V140, P3487, DOI 10.1121/1.4966117
   Schoof T, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00307
   SEK A, 1995, J ACOUST SOC AM, V97, P2479, DOI 10.1121/1.411968
   Sek A, 2015, J ACOUST SOC AM, V138, P1143, DOI 10.1121/1.4928135
   SHAMMA SA, 1985, J ACOUST SOC AM, V78, P1622, DOI 10.1121/1.392800
   Shearer A.E., 1999, GENEREVIEWS, P1993
   Smith RJH, 2005, LANCET, V365, P879, DOI 10.1016/S0140-6736(05)71047-3
   Souza Pamela E, 2002, Trends Amplif, V6, P131, DOI 10.1177/108471380200600402
   Starr A., 2000, Journal of Basic and Clinical Physiology and Pharmacology, V11, P215
   STELMACHOWICZ PG, 1995, J ACOUST SOC AM, V98, P1388, DOI 10.1121/1.413474
   Stevens G, 2013, EUR J PUBLIC HEALTH, V23, P146, DOI 10.1093/eurpub/ckr176
   Sutcliffe P, 2005, J EXP CHILD PSYCHOL, V91, P249, DOI 10.1016/j.jecp.2005.03.004
   Swaminathan J, 2012, J NEUROSCI, V32, P1747, DOI 10.1523/JNEUROSCI.4493-11.2012
   Takesian AE, 2012, J NEUROPHYSIOL, V107, P937, DOI 10.1152/jn.00515.2011
   Thomas MSC, 2009, J SPEECH LANG HEAR R, V52, P336, DOI 10.1044/1092-4388(2009/07-0144)
   Thompson NC, 1999, J SPEECH LANG HEAR R, V42, P1061, DOI 10.1044/jslhr.4205.1061
   Tomblin J Bruce, 2015, Ear Hear, V36 Suppl 1, p76S, DOI 10.1097/AUD.0000000000000219
   Verschooten E, 2019, HEARING RES, V377, P109, DOI 10.1016/j.heares.2019.03.011
   von Trapp G, 2017, HEARING RES, V347, P3, DOI 10.1016/j.heares.2016.07.020
   Walch C, 2000, INT J PEDIATR OTORHI, V53, P31, DOI 10.1016/S0165-5876(00)00307-4
   Walker EA, 2015, J SPEECH LANG HEAR R, V58, P1611, DOI 10.1044/2015_JSLHR-H-15-0043
   Wallaert N, 2018, J ACOUST SOC AM, V144, P720, DOI 10.1121/1.5049364
   Wallaert N, 2017, J ACOUST SOC AM, V141, P971, DOI 10.1121/1.4976080
   Wechsler D, 1999, WASI WECHSLER ABBREV
   Werner LA, 1998, DEV AUDITORY SYSTEM, P12
   Whiteford KL, 2017, JARO-J ASSOC RES OTO, V18, P619, DOI 10.1007/s10162-017-0624-x
   WIER CC, 1977, J ACOUST SOC AM, V61, P178, DOI 10.1121/1.381251
   WOOLF NK, 1981, HEARING RES, V4, P335, DOI 10.1016/0378-5955(81)90017-4
   ZUREK PM, 1981, J SPEECH HEAR RES, V24, P108, DOI 10.1044/jshr.2401.108
   Zwicker E., 1952, ACUSTICA          S3, V2, P125
NR 106
TC 1
Z9 1
U1 0
U2 4
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD DEC
PY 2019
VL 146
IS 6
BP 4299
EP 4314
DI 10.1121/1.5134059
PG 16
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA KG8ZS
UT WOS:000510240600032
PM 31893709
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Li, JJW
   Ayala, S
   Harel, D
   Shiller, DM
   McAllister, T
AF Li, Joanne Jingwen
   Ayala, Samantha
   Harel, Daphna
   Shiller, Douglas M.
   McAllister, Tara
TI Individual predictors of response to biofeedback training for
   second-language production
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID ULTRASOUND VISUAL FEEDBACK; PERCEPTION-PRODUCTION LINK; NEURAL-NETWORK
   MODEL; R-VERTICAL-BAR; SPEECH-PERCEPTION; FOREIGN-LANGUAGE; VOCAL-TRACT;
   PHONOLOGICAL CONTRAST; ACQUISITION; SPEAKERS
AB While recent research suggests that visual biofeedback can facilitate speech production training in clinical populations and second language (L2) learners, individual learners' responsiveness to biofeedback is highly variable. This study investigated the hypothesis that the type of biofeedback provided, visual-acoustic versus ultrasound, could interact with individuals' acuity in auditory and somatosensory domains. Specifically, it was hypothesized that learners with lower acuity in a sensory domain would show greater learning in response to biofeedback targeting that domain. Production variability and phonological awareness were also investigated as predictors. Sixty female native speakers of English received 30min of training, randomly assigned to feature visual-acoustic or ultrasound biofeedback, for each of two Mandarin vowels. On average, participants showed a moderate magnitude of improvement (decrease in Euclidean distance from a native-speaker target) across both vowels and biofeedback conditions. The hypothesis of an interaction between sensory acuity and biofeedback type was not supported, but phonological awareness and production variability were predictive of learning gains, consistent with previous research. Specifically, high phonological awareness and low production variability post-training were associated with better outcomes, although these effects were mediated by vowel target. This line of research could have implications for personalized learning in both L2 pedagogy and clinical practice. (C) 2019 Acoustical Society of America.
C1 [Li, Joanne Jingwen; Ayala, Samantha; McAllister, Tara] NYU, Dept Commun Sci & Disorders, 665 Broadway,Suite 900, New York, NY 10012 USA.
   [Harel, Daphna] NYU, Dept Appl Stat Social Sci & Humanities, 246 Greene St,3rd Floor, New York, NY 10003 USA.
   [Shiller, Douglas M.] Univ Montreal, Ecole Orthophonie & Audiol, Case Postale 6128, Montreal, PQ H3C 3J7, Canada.
RP McAllister, T (corresponding author), NYU, Dept Commun Sci & Disorders, 665 Broadway,Suite 900, New York, NY 10012 USA.
EM tkm214@nyu.edu
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [NIDCD-R01DC013668,
   NIDCD-R01DC017476]
FX This work was supported by the National Institutes of Health (Grant Nos.
   NIDCD-R01DC013668 and NIDCD-R01DC017476). The authors gratefully thank
   the following individuals: Daniel Lametti and Mark Tiede for assistance
   with auditory stimulus generation, members of the Biofeedback
   Intervention Technology for Speech Lab (BITS Lab) at New York University
   (NYU) for assistance with data collection and analysis, and all
   participants for their time.
CR Adler-Bock M, 2007, AM J SPEECH-LANG PAT, V16, P128, DOI 10.1044/1058-0360(2007/017)
   Akahane-Yamada R., 1998, 5 INT C SPOK LANG PR
   Bacsfalvi P, 2011, CLIN LINGUIST PHONET, V25, P1034, DOI 10.3109/02699206.2011.618236
   Balter O., 2007, TMH QPSR, V20, P235
   Bernhardt B, 2005, CLIN LINGUIST PHONET, V19, P605, DOI 10.1080/02699200500114028
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best C. T, 2003, 15 INT C PHON SCI
   Bliss H., 2018, J 2 LANG PRONUNCIATI, V4, P127, DOI [10.1075/jslp.00006.bli, DOI 10.1075/jslp.00006.bli]
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Borrie SA, 2015, J SPEECH LANG HEAR R, V58, P1708, DOI 10.1044/2015_JSLHR-S-15-0163
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Byun TM, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00567
   Byun TM, 2014, J SPEECH LANG HEAR R, V57, P2116, DOI 10.1044/2014_JSLHR-S-14-0034
   Byun TM, 2012, AM J SPEECH-LANG PAT, V21, P207, DOI 10.1044/1058-0360(2012/11-0083)
   Byuna TM, 2017, J SPEECH LANG HEAR R, V60, P1175, DOI 10.1044/2016_JSLHR-S-16-0038
   Carey M., 2004, CALICO Journal, V21, P571
   CATFORD JC, 1970, MOD LANG J, V54, P477, DOI 10.2307/321767
   Chang CB, 2011, J ACOUST SOC AM, V129, P3964, DOI 10.1121/1.3569736
   Chen Y, 2001, CLIN LINGUIST PHONET, V15, P427
   Christiner M, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00482
   Dornyei Z., 1998, LANG TEACHING, V31, P117, DOI [10.1017/S026144480001315X, DOI 10.1017/S026144480001315X]
   Dowd A, 1998, LANG SPEECH, V41, P1, DOI 10.1177/002383099804100101
   Fitch WT, 1999, J ACOUST SOC AM, V106, P1511, DOI 10.1121/1.427148
   Fitch WT, 1997, J ACOUST SOC AM, V102, P1213, DOI 10.1121/1.421048
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   Franken MK, 2017, J ACOUST SOC AM, V142, P2007, DOI 10.1121/1.5006899
   FUCCI D, 1972, J SPEECH HEAR RES, V15, P179, DOI 10.1044/jshr.1501.179
   FUCCI DJ, 1971, PERCEPT MOTOR SKILL, V33, P711, DOI 10.2466/pms.1971.33.3.711
   Ghosh SS, 2010, J ACOUST SOC AM, V128, P3079, DOI 10.1121/1.3493430
   Gick B, 2008, PHONOLOGY 2 LANG ACQ, V36, P315
   Gilbert J. B., 2010, SPEAK OUT, V43, P3
   GUENTHER FH, 1994, BIOL CYBERN, V72, P43, DOI 10.1007/BF00206237
   Guenther FH, 2006, BRAIN LANG, V96, P280, DOI 10.1016/j.bandl.2005.06.001
   Guenther FH, 1998, PSYCHOL REV, V105, P611, DOI 10.1037/0033-295X.105.4.611-633
   GUENTHER FH, 1995, PSYCHOL REV, V102, P594, DOI 10.1037/0033-295X.102.3.594
   Guenther FH., 2016, NEURAL CONTROL SPEEC
   Halwani GF, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00156
   Hanulikova A, 2012, LANG LEARN, V62, P79, DOI 10.1111/j.1467-9922.2012.00707.x
   HARDCASTLE WJ, 1991, BRIT J DISORD COMMUN, V26, P41
   Hattori K., 2010, 2 LANG STUD ACQ LEAR
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158
   Hitchcock ER, 2017, AM J SPEECH-LANG PAT, V26, P1141, DOI 10.1044/2017_AJSLP-16-0122
   Hu CF, 2003, LANG LEARN, V53, P429, DOI 10.1111/1467-9922.00231
   Hu CF, 2010, J PSYCHOLINGUIST RES, V39, P305, DOI 10.1007/s10936-009-9143-1
   Hu XC, 2013, BRAIN LANG, V127, P366, DOI 10.1016/j.bandl.2012.11.006
   Hummel KM, 2009, APPL PSYCHOLINGUIST, V30, P225, DOI 10.1017/S0142716409090109
   Jacobs R, 1998, Clin Oral Investig, V2, P3, DOI 10.1007/s007840050035
   Kartushina N, 2016, J PHONETICS, V57, P21, DOI 10.1016/j.wocn.2016.05.001
   Kartushina N, 2015, J ACOUST SOC AM, V138, P817, DOI 10.1121/1.4926561
   Kartushina N, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01246
   Kawahara H, 2013, ASIAPAC SIGN INFO PR
   Kleber B., 2014, OXFORD HDB SINGING
   Kocjancico Antolik T. K, 2019, J 2 LANG PRONUNCIATI, V5, P72
   Lakens D, 2017, SOC PSYCHOL PERS SCI, V8, P355, DOI 10.1177/1948550617697177
   Lametti DR, 2012, J NEUROSCI, V32, P9351, DOI 10.1523/JNEUROSCI.0404-12.2012
   Lennes Mietta, 2003, COLLECT FORMANT DATA
   Levy ES, 2008, J PHONETICS, V36, P141, DOI 10.1016/j.wocn.2007.03.001
   McBrideChang C, 1996, CHILD DEV, V67, P1836, DOI 10.2307/1131735
   MCNUTT JC, 1977, J SPEECH HEAR RES, V20, P694, DOI 10.1044/jshr.2004.694
   Milovanov R, 2010, LEARN INDIVID DIFFER, V20, P56, DOI 10.1016/j.lindif.2009.11.003
   Mora JC, 2014, LANG AWARE, V23, P57, DOI 10.1080/09658416.2013.863898
   Nagle CL, 2018, LANG LEARN, V68, P234, DOI 10.1111/lang.12275
   Nasir SM, 2008, NAT NEUROSCI, V11, P1217, DOI 10.1038/nn.2193
   Newman RS, 2003, J ACOUST SOC AM, V113, P2850, DOI 10.1121/1.1567280
   Niziolek CA, 2013, J NEUROSCI, V33, P16110, DOI 10.1523/JNEUROSCI.2137-13.2013
   Nushi Kochaksaraie M., 2018, J TEACH LANG SKILLS, V36, P103
   Okuno T, 2016, LANG LEARN TECHNOL, V20, P61
   Olson DJ, 2014, LANG LEARN TECHNOL, V18, P173
   Peperkamp S, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P168
   Perkell JS, 2004, J SPEECH LANG HEAR R, V47, P1259, DOI 10.1044/1092-4388(2004/095)
   Perkell JS, 2004, J ACOUST SOC AM, V116, P2338, DOI 10.1121/1.1787524
   Perrachione TK, 2011, J ACOUST SOC AM, V130, P461, DOI 10.1121/1.3593366
   Posedel J, 2012, PSYCHOL MUSIC, V40, P508, DOI 10.1177/0305735611415145
   Preston JL, 2019, AM J SPEECH-LANG PAT, V28, P1167, DOI 10.1044/2019_AJSLP-18-0261
   Preston JL, 2018, J SPEECH LANG HEAR R, V61, DOI 10.1044/2018_JSLHR-S-17-0441
   Preston Jonathan L, 2016, Front Hum Neurosci, V10, P440, DOI 10.3389/fnhum.2016.00440
   Preston JL, 2014, J SPEECH LANG HEAR R, V57, P2102, DOI 10.1044/2014_JSLHR-S-14-0031
   Preston JL, 2014, APHASIOLOGY, V28, P278, DOI 10.1080/02687038.2013.852901
   R Core Team, 2015, R LANG ENV STAT COMP
   Reiterer S, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00334
   Rota G, 2009, TRENDS APPL LINGUIST, V1, P67
   Schmidt R, 1993, ANNU REV APPL LINGUI, V13, P206, DOI [10.1017/S0267190500002476, DOI 10.1017/S0267190500002476]
   SCHMIDT RW, 1990, APPL LINGUIST, V11, P129, DOI 10.1093/applin/11.2.129
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   Simmonds AJ, 2011, J NEUROPHYSIOL, V106, P470, DOI 10.1152/jn.00343.2011
   Slevc LR, 2006, PSYCHOL SCI, V17, P675, DOI 10.1111/j.1467-9280.2006.01765.x
   Steele CM, 2014, J TEXTURE STUD, V45, P317, DOI 10.1111/jtxs.12076
   Villacorta VM, 2007, J ACOUST SOC AM, V122, P2306, DOI 10.1121/1.2773966
   Wagner R. K., 2013, COMPREHENSIVE TEST P
   WATSON BU, 1993, J SPEECH HEAR RES, V36, P850, DOI 10.1044/jshr.3604.850
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3_1
   Wong JWS, 2013, INTERSPEECH, P2112
   Wong PCM, 2007, APPL PSYCHOLINGUIST, V28, P565, DOI 10.1017/S0142716407070312
   Wong PCM, 2017, NEUROPSYCHOLOGIA, V98, P192, DOI 10.1016/j.neuropsychologia.2016.10.002
   Zandipour M, 2006, P 7 INT SEM SPEECH P
NR 96
TC 0
Z9 0
U1 2
U2 2
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD DEC
PY 2019
VL 146
IS 6
BP 4625
EP 4643
DI 10.1121/1.5139423
PG 19
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA KG8ZS
UT WOS:000510240600061
PM 31893730
OA Green Published
DA 2021-02-24
ER

PT J
AU Hesling, I
   Labache, L
   Joliot, M
   Tzourio-Mazoyer, N
AF Hesling, Isabelle
   Labache, L.
   Joliot, M.
   Tzourio-Mazoyer, N.
TI Large-scale plurimodal networks common to listening to, producing and
   reading word lists: an fMRI study combining task-induced activation and
   intrinsic connectivity in 144 right-handers
SO BRAIN STRUCTURE & FUNCTION
LA English
DT Article
DE Word production; Word perception; Word reading; Hemispheric
   specialization; Resting state
ID SHORT-TERM-MEMORY; FUNCTIONAL-ANATOMY; SPEECH-PERCEPTION; PREFRONTAL
   CORTEX; LANGUAGE FUNCTION; MOTOR CORTEX; HUMAN BRAIN; AREAS; COMPONENTS;
   DORSAL
AB We aimed at identifying plurimodal large-scale networks for producing, listening to and reading word lists based on the combined analyses of task-induced activation and resting-state intrinsic connectivity in 144 healthy right-handers. In the first step, we identified the regions in each hemisphere showing joint activation and joint asymmetry during the three tasks. In the left hemisphere, 14 homotopic regions of interest (hROIs) located in the left Rolandic sulcus, precentral gyrus, cingulate gyrus, cuneus and inferior supramarginal gyrus (SMG) met this criterion, and 7 hROIs located in the right hemisphere were located in the preSMA, medial superior frontal gyrus, precuneus and superior temporal sulcus (STS). In a second step, we calculated the BOLD temporal correlations across these 21 hROIs at rest and conducted a hierarchical clustering analysis to unravel their network organization. Two networks were identified, including the WORD-LIST_CORE network that aggregated 14 motor, premotor and phonemic areas in the left hemisphere plus the right STS that corresponded to the posterior human voice area (pHVA). The present results revealed that word-list processing is based on left articulatory and storage areas supporting the action-perception cycle common not only to production and listening but also to reading. The inclusion of the right pHVA acting as a prosodic integrative area highlights the importance of prosody in the three modalities and reveals an intertwining across hemispheres between prosodic (pHVA) and phonemic (left SMG) processing. These results are consistent with the motor theory of speech postulating that articulatory gestures are the central motor units on which word perception, production, and reading develop and act together.
C1 [Hesling, Isabelle; Labache, L.; Joliot, M.; Tzourio-Mazoyer, N.] Univ Bordeaux, IMN, UMR 5293, F-33000 Bordeaux, France.
   [Hesling, Isabelle; Labache, L.; Joliot, M.; Tzourio-Mazoyer, N.] CNRS, IMN, UMR 5293, F-33000 Bordeaux, France.
   [Hesling, Isabelle; Labache, L.; Joliot, M.; Tzourio-Mazoyer, N.] CEA, GIN, IMN, UMR 5293, F-33000 Bordeaux, France.
   [Labache, L.] Univ Bordeaux, IMB, UMR 5251, F-33405 Talence, France.
   [Labache, L.] INRIA, CQFD, INRIA Bordeaux Sud Ouest, UMR 5251, F-33405 Talence, France.
   [Hesling, Isabelle] Univ Bordeaux, IMN, UMR 5293, Team GIN 5,CEA CNRS,Ctr Broca Nouvelle Aquitaine, 3eme Etage,146 Rue Leo Saignat,CS 61292,Case 28, F-33076 Bordeaux, France.
RP Hesling, I (corresponding author), Univ Bordeaux, IMN, UMR 5293, F-33000 Bordeaux, France.; Hesling, I (corresponding author), CNRS, IMN, UMR 5293, F-33000 Bordeaux, France.; Hesling, I (corresponding author), CEA, GIN, IMN, UMR 5293, F-33000 Bordeaux, France.; Hesling, I (corresponding author), Univ Bordeaux, IMN, UMR 5293, Team GIN 5,CEA CNRS,Ctr Broca Nouvelle Aquitaine, 3eme Etage,146 Rue Leo Saignat,CS 61292,Case 28, F-33076 Bordeaux, France.
EM isabelle.hesling@u-bordeaux.fr
RI LABACHE, Loic/AAQ-5157-2020
OI LABACHE, Loic/0000-0002-5733-0743
FU FLAG-ERA Human Brain Project [ANR-15-HBPR-0001-03-MULTI-LATERAL]
FX This work was supported by a grant from the FLAG-ERA Human Brain Project
   2015 (ANR-15-HBPR-0001-03-MULTI-LATERAL) awarded to NTM and MJ.
CR Amiez C, 2014, CEREB CORTEX, V24, P563, DOI 10.1093/cercor/bhs329
   [Anonymous], 1989, VERS 14
   Assaneo MF, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aao3842
   Baddeley A, 1998, PSYCHOL REV, V105, P158, DOI 10.1037/0033-295X.105.1.158
   Beaucousin V, 2007, CEREB CORTEX, V17, P339, DOI 10.1093/cercor/bhj151
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Belin P, 2002, COGNITIVE BRAIN RES, V13, P17, DOI 10.1016/S0926-6410(01)00084-2
   Bever T.G., 1971, CHILD LANGUAGE BOOK
   Binder JR, 1996, BRAIN, V119, P1239, DOI 10.1093/brain/119.4.1239
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   Bodin C, 2018, BRAIN STRUCT FUNCT, V223, P221, DOI 10.1007/s00429-017-1483-2
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   Bolger DJ, 2008, NEUROPSYCHOLOGIA, V46, P3210, DOI 10.1016/j.neuropsychologia.2008.07.024
   Booth JR, 2002, NEUROIMAGE, V16, P7, DOI 10.1006/nimg.2002.1081
   Booth JR, 2002, HUM BRAIN MAPP, V16, P251, DOI 10.1002/hbm.10054
   Brown S, 2008, CEREB CORTEX, V18, P837, DOI 10.1093/cercor/bhm131
   Brown S, 2009, BRAIN COGNITION, V70, P31, DOI 10.1016/j.bandc.2008.12.006
   Buchsbaum BR, 2001, COGNITIVE SCI, V25, P663, DOI 10.1207/s15516709cog2505_2
   Buchsbaum BR, 2011, BRAIN LANG, V119, P119, DOI 10.1016/j.bandl.2010.12.001
   Buckner RL, 2000, BRAIN, V123, P620, DOI 10.1093/brain/123.3.620
   Cason N, 2015, NEUROPSYCHOLOGY, V29, P102, DOI 10.1037/neu0000115
   Catani M, 2005, ANN NEUROL, V57, P8, DOI 10.1002/ana.20319
   Catts HW, 2005, J SPEECH LANG HEAR R, V48, P1378, DOI 10.1044/1092-4388(2005/096)
   Cavanna AE, 2006, BRAIN, V129, P564, DOI 10.1093/brain/awl004
   Chee MWL, 1999, HUM BRAIN MAPP, V7, P15, DOI 10.1002/(SICI)1097-0193(1999)7:1<15::AID-HBM2>3.0.CO;2-6
   Chein JM, 2001, CEREB CORTEX, V11, P1003, DOI 10.1093/cercor/11.11.1003
   Conant D, 2014, CURR OPIN NEUROBIOL, V24, P63, DOI 10.1016/j.conb.2013.08.015
   Corbetta M, 2011, ANNU REV NEUROSCI, V34, P569, DOI 10.1146/annurev-neuro-061010-113731
   CURTISS Susan, 1977, GENIE PSYCHOLINGUIST
   Danelli L, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01328
   DE SAUSSURE F., 1975, COURS LINGUISTIQUE G
   Dietz NAE, 2005, HUM BRAIN MAPP, V26, P81, DOI 10.1002/hbm.20122
   Dym RJ, 2011, RADIOLOGY, V261, P446, DOI 10.1148/radiol.11101344
   Flaugnacco E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138715
   Fodor J., 1983, MODULARITY MIND
   Fox PT, 2001, NEUROIMAGE, V13, P196, DOI 10.1006/nimg.2000.0659
   Fuster JM, 2001, NEURON, V30, P319, DOI 10.1016/S0896-6273(01)00285-9
   Fuster JM, 2014, P IEEE, V102, P417, DOI 10.1109/JPROC.2014.2306250
   Gazzaniga MS, 2000, BRAIN, V123, P1293, DOI 10.1093/brain/123.7.1293
   GERKEN L, 1990, DEV PSYCHOL, V26, P204
   Gillon GT, 2004, PHONOLOGICAL AWARENE
   Grabski K, 2012, HUM BRAIN MAPP, V33, P2306, DOI 10.1002/hbm.21363
   Gu ZG, 2014, BIOINFORMATICS, V30, P2811, DOI 10.1093/bioinformatics/btu393
   Hartwigsen G, 2016, CEREB CORTEX, V26, P2590, DOI 10.1093/cercor/bhv092
   Heim S, 2002, NEUROSCI LETT, V328, P101, DOI 10.1016/S0304-3940(02)00494-9
   Herbster AN, 1997, HUM BRAIN MAPP, V5, P84, DOI 10.1002/(SICI)1097-0193(1997)5:2<84::AID-HBM2>3.0.CO;2-I
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Iverson JM, 2010, J CHILD LANG, V37, P229, DOI 10.1017/S0305000909990432
   Joliot M, 2015, J NEUROSCI METH, V254, P46, DOI 10.1016/j.jneumeth.2015.07.013
   JUSCZYK PW, 1993, CHILD DEV, V64, P675, DOI 10.2307/1131210
   Kotz SA, 2007, BRAIN RES, V1151, P107, DOI 10.1016/j.brainres.2007.03.015
   Labache L, 2019, BRAIN STRUCT FUNCT, V224, P859, DOI 10.1007/s00429-018-1810-2
   Leroy F, 2015, P NATL ACAD SCI USA, V112, P1208, DOI 10.1073/pnas.1412389112
   Liberman AM, 2000, TRENDS COGN SCI, V4, P187, DOI 10.1016/S1364-6613(00)01471-6
   Liebenthal E, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00506
   LOCKE JL, 1990, J CHILD LANG, V17, P1, DOI 10.1017/S0305000900013076
   Malins JG, 2016, NEUROPSYCHOLOGIA, V91, P394, DOI 10.1016/j.neuropsychologia.2016.08.027
   Martin RC, 2005, CURR DIR PSYCHOL SCI, V14, P204, DOI 10.1111/j.0963-7214.2005.00365.x
   Mazoyer B, 2016, NEUROIMAGE, V124, P1225, DOI 10.1016/j.neuroimage.2015.02.071
   McNorgan C, 2014, CEREB CORTEX, V24, P2464, DOI 10.1093/cercor/bht100
   Mellet E, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00628
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Oller D. Kimbrough, 1983, PRODUCTION SPEECH, P91
   Paulesu E, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00830
   Pell MD, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027256
   Penfield W, 1959, SPEECH BRAIN MECH
   Pernet CR, 2015, NEUROIMAGE, V119, P164, DOI 10.1016/j.neuroimage.2015.06.050
   PITT MA, 1990, J EXP PSYCHOL HUMAN, V16, P564, DOI 10.1037/0096-1523.16.3.564
   Poeppel D, 2008, PHILOS T R SOC B, V363, P1071, DOI 10.1098/rstb.2007.2160
   Poldrack RA, 1999, NEUROIMAGE, V10, P15, DOI 10.1006/nimg.1999.0441
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Price CJ, 2010, ANN NY ACAD SCI, V1191, P62, DOI 10.1111/j.1749-6632.2010.05444.x
   Price CJ, 1996, BRAIN, V119, P919, DOI 10.1093/brain/119.3.919
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Pulvermuller F, 2016, NEUROBIOLOGY LANGUAG, P311
   Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811
   Rauschecker JP, 2000, P NATL ACAD SCI USA, V97, P11800, DOI 10.1073/pnas.97.22.11800
   Roncaglia-Denissen MP, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0056000
   Rueckl JG, 2015, P NATL ACAD SCI USA, V112, P15510, DOI 10.1073/pnas.1509321112
   Sammler D, 2015, CURR BIOL, V25, P3079, DOI 10.1016/j.cub.2015.10.009
   Schwartz MF, 2012, BRAIN, V135, P3799, DOI 10.1093/brain/aws300
   Schwartze M, 2011, BIOL PSYCHOL, V87, P146, DOI 10.1016/j.biopsycho.2011.02.021
   SIDTIS JJ, 1981, J NEUROSCI, V1, P323
   Smith EE, 1998, P NATL ACAD SCI USA, V95, P12061, DOI 10.1073/pnas.95.20.12061
   Thaut M., 2013, RHYTHM MUSIC BRAIN S
   Thaut M. H., 2014, CURR PHYS MED REHABI, V2, P106, DOI [10.1007/s40141-014-0049-y, DOI 10.1007/S40141-014-0049-Y]
   Toga AW, 2003, NAT REV NEUROSCI, V4, P37, DOI 10.1038/nrn1009
   TONKONOGY J, 1981, ARCH NEUROL-CHICAGO, V38, P486, DOI 10.1001/archneur.1981.00510080048005
   Tourville JA, 2008, NEUROIMAGE, V39, P1429, DOI 10.1016/j.neuroimage.2007.09.054
   Veroude K, 2010, BRAIN LANG, V113, P21, DOI 10.1016/j.bandl.2009.12.005
   Vigneau M, 2006, NEUROIMAGE, V30, P1414, DOI 10.1016/j.neuroimage.2005.11.002
   Vigneau M, 2011, NEUROIMAGE, V54, P577, DOI 10.1016/j.neuroimage.2010.07.036
   Wildgruber D, 1996, NEUROREPORT, V7, P2791, DOI 10.1097/00001756-199611040-00077
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Wilson SM, 2006, NEUROIMAGE, V33, P316, DOI 10.1016/j.neuroimage.2006.05.032
   Yue QH, 2019, CEREB CORTEX, V29, P1398, DOI 10.1093/cercor/bhy037
   Zago L, 2008, NEUROPSYCHOLOGIA, V46, P2403, DOI 10.1016/j.neuropsychologia.2008.03.001
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
NR 99
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1863-2653
EI 1863-2661
J9 BRAIN STRUCT FUNCT
JI Brain Struct. Funct.
PD DEC
PY 2019
VL 224
IS 9
BP 3075
EP 3094
DI 10.1007/s00429-019-01951-4
PG 20
WC Anatomy & Morphology; Neurosciences
SC Anatomy & Morphology; Neurosciences & Neurology
GA JY3OX
UT WOS:000504329400006
PM 31494717
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Uhrig, S
   Mittag, G
   Moller, S
   Voigt-Antons, JN
AF Uhrig, Stefan
   Mittag, Gabriel
   Moeller, Sebastian
   Voigt-Antons, Jan-Niklas
TI P300 indicates context-dependent change in speech quality beyond
   phonological change
SO JOURNAL OF NEURAL ENGINEERING
LA English
DT Article
DE electroencephalography; event-related potential; P300; oddball paradigm;
   speech perception; speech quality assessment; stimulus context
ID MENTAL FATIGUE; BRAIN; P3A; ATTENTION; LANGUAGE; FOCUS
AB Objective. Non-invasive physiological methods like electroencephalography (EEG) are increasingly employed to assess human information processing during exposure to multimedia signals. In the quality engineering field, previous research has promoted the utility of the P300 event-related brain potential (ERP) component for indicating variation in quality perception. The present study provides a starting point to test whether the P300 and its two subcomponents, P3a and P3b, are truly reflective of changes in the perceived quality of transmitted speech signals given the presence of other, quality-unrelated changes in acoustic stimulation. Approach. High-quality and degraded variants of spoken words were presented in a two-feature oddball task, which required participants to actively respond to rarely occurring 'target' stimuli within a series of frequent 'standard' stimuli, thereby eliciting ERP waveforms. Target presentations involved either single quality changes or concurrent double changes in quality and the initial phoneme. Main results. In case additional phonological change was present, only varying quality of standard stimuli caused significant modulations in P3a and P3b characteristics (N = 32). Thus, the formation of different short-term quality references exerted a persisting influence on the auditory processing of transmitted speech. Significance. The obtained results elucidate the importance of contextual and content-related influencing factors for proving the validity of the P300 as a psychophysiological indicator of speech quality change. Associated questions regarding the transfer of ERP-based quality assessment into more practically relevant measurement contexts are discussed.
C1 [Uhrig, Stefan; Mittag, Gabriel; Moeller, Sebastian; Voigt-Antons, Jan-Niklas] Tech Univ Berlin, Qual & Usabil Lab, D-10587 Berlin, Germany.
   [Moeller, Sebastian; Voigt-Antons, Jan-Niklas] German Res Ctr Artificial Intelligence DFKI, D-10559 Berlin, Germany.
RP Uhrig, S (corresponding author), Tech Univ Berlin, Qual & Usabil Lab, D-10587 Berlin, Germany.
EM stefan.uhrig@qu.tu-berlin.de
OI Voigt-Antons, Jan-Niklas/0000-0002-2786-9262; Uhrig,
   Stefan/0000-0002-9221-4617
FU Technische Universitat Berlin, Germany; Norwegian University of Science
   and Technology in Trondheim, Norway
FX This work was supported by the strategic partnership program between
   Technische Universitat Berlin, Germany, and the Norwegian University of
   Science and Technology in Trondheim, Norway.
CR Acqualagna L, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/2/026012
   Althen H, 2016, CLIN NEUROPHYSIOL, V127, P388, DOI 10.1016/j.clinph.2015.04.058
   [Anonymous], 2007, SUBJ EV CONV QUAL
   [Anonymous], 2015, G107 ITUT
   Antons JN, 2014, T-LAB SER TELECOMMUN, P109, DOI 10.1007/978-3-319-02681-7_8
   Antons JN, 2012, IEEE J-STSP, V6, P721, DOI 10.1109/JSTSP.2012.2191936
   Arndt S., 2016, ELECT IMAG, V2016, P1, DOI DOI 10.2352/ISSN.2470-1173.2016.16.HVEI-125
   Arndt S, 2014, IEEE J-STSP, V8, P366, DOI 10.1109/JSTSP.2014.2313026
   Avarvand FS, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa6d8b
   BACKS RW, 2000, ENG PSYCHOPHYSIOLOGY
   Blauert J, 2007, P 19 INT C AC ICA 20, P1205
   Boksem MAS, 2005, COGNITIVE BRAIN RES, V25, P107, DOI 10.1016/j.cogbrainres.2005.04.011
   Bosse S, 2018, IEEE T CIRC SYST VID, V28, P1694, DOI 10.1109/TCSVT.2017.2694807
   Comerchero MD, 1999, CLIN NEUROPHYSIOL, V110, P24, DOI 10.1016/S0168-5597(98)00033-1
   Comerchero MD, 1998, COGNITIVE BRAIN RES, V7, P41, DOI 10.1016/S0926-6410(98)00009-3
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Duncan CC, 2009, CLIN NEUROPHYSIOL, V120, P1883, DOI 10.1016/j.clinph.2009.07.045
   Egger S, 2014, T-LAB SER TELECOMMUN, P149, DOI 10.1007/978-3-319-02681-7_11
   Engelke U, 2017, IEEE J-STSP, V11, P6, DOI 10.1109/JSTSP.2016.2609843
   Fazel-Rezai Reza, 2012, Front Neuroeng, V5, P14, DOI 10.3389/fneng.2012.00014
   Fosker T, 2005, COGNITIVE BRAIN RES, V24, P467, DOI 10.1016/j.cogbrainres.2005.02.019
   Fosker T, 2004, NEUROSCI LETT, V357, P171, DOI 10.1016/j.neulet.2003.12.084
   Friedman D, 2001, NEUROSCI BIOBEHAV R, V25, P355, DOI 10.1016/S0149-7634(01)00019-7
   Garrido MI, 2009, CLIN NEUROPHYSIOL, V120, P453, DOI 10.1016/j.clinph.2008.11.029
   Gros L, 2004, ACTA ACUST UNITED AC, V90, P1037
   Halder S, 2010, CLIN NEUROPHYSIOL, V121, P516, DOI 10.1016/j.clinph.2009.11.087
   International Telecommunication Union, 2011, OBJ MEAS ACT SPEECH
   International Teleconununication Union, 1996, METH SUBJ DET TRANSM
   ITU-T Recommendation P.810, 1996, MOD NOIS REF UN MNRU
   Kappenman E. S., 2011, OXFORD HDB EVENT REL
   Katayama J, 1998, PSYCHOPHYSIOLOGY, V35, P23, DOI 10.1017/S0048577298961479
   Kayser J, 1998, PSYCHOPHYSIOLOGY, V35, P576, DOI 10.1017/S0048577298970214
   Kok A, 2001, PSYCHOPHYSIOLOGY, V38, P557, DOI 10.1017/S0048577201990559
   Kotchoubey B, 2001, NEUROSCI LETT, V310, P93, DOI 10.1016/S0304-3940(01)02057-2
   Kramer AF, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P704, DOI 10.1017/CBO9780511546396.030
   Le Callet P, 2013, EXPERIENCE MULTIMEDI
   Linden DEJ, 2005, NEUROSCIENTIST, V11, P563, DOI 10.1177/1073858405280524
   Maguire M, 2001, INT J HUM-COMPUT ST, V55, P453, DOI 10.1006/ijhc.2001.0486
   Martin B A, 2007, BASIC PRINCIPLES CLI, P482
   Moller S, 2011, P FOR AC 2011 EUR AC, P1205
   Moore TM, 2017, NEUROPSYCHOLOGIA, V106, P371, DOI 10.1016/j.neuropsychologia.2017.10.025
   Muller-Gass A, 2007, NEUROREPORT, V18, P1747, DOI 10.1097/WNR.0b013e3282f0ea16
   Nuwer MR, 1998, ELECTROEN CLIN NEURO, V106, P259, DOI 10.1016/S0013-4694(97)00106-5
   O'Donnell RD, 1986, HDB PERCEPTION PERFO, V2, P1
   Olejnik S, 2003, PSYCHOL METHODS, V8, P434, DOI 10.1037/1082-989X.8.4.434
   Pakarinen S, 2014, NEUROSCI LETT, V577, P28, DOI 10.1016/j.neulet.2014.06.004
   Pakarinen S, 2009, BIOL PSYCHOL, V82, P219, DOI 10.1016/j.biopsycho.2009.07.008
   Patterson RD, 2008, PHILOS T R SOC B, V363, P1023, DOI 10.1098/rstb.2007.2157
   Pizzagalli DA, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P56, DOI 10.1017/CBO9780511546396.003
   Polich J., 2012, OXFORD HDB EVENT REL, DOI [10.1093/oxfordhb/9780195374148.013.0089, DOI 10.1093/OXFORDHB/9780195374148.013.0089]
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   Porbadnigk AK, 2013, J NEURAL ENG, V10, DOI 10.1088/1741-2560/10/5/056003
   Porbadnigk AK, 2010, IEEE ENG MED BIO, P2690, DOI 10.1109/IEMBS.2010.5626549
   Pulvermuller F, 2006, PROG NEUROBIOL, V79, P49, DOI 10.1016/j.pneurobio.2006.04.004
   Raake A., 2006, SPEECH QUALITY VOIP
   Raake A, 2014, T-LAB SER TELECOMMUN, P11, DOI 10.1007/978-3-319-02681-7_2
   Reiter U, 2014, T-LAB SER TELECOMMUN, P55, DOI 10.1007/978-3-319-02681-7_4
   Scholler S, 2012, IEEE T IMAGE PROCESS, V21, P2619, DOI 10.1109/TIP.2012.2187672
   Shtyrov Y, 2008, CEREB CORTEX, V18, P29, DOI 10.1093/cercor/bhm028
   Sorokin A, 2010, BRAIN RES, V1327, P77, DOI 10.1016/j.brainres.2010.02.052
   Tibon R, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00555
   Uhrig S, 2018, 10 INT C QUAL MULT E, P1
   Uhrig S, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/aaf122
   Verleger R, 2005, J PSYCHOPHYSIOL, V19, P165, DOI 10.1027/0269-8803.19.3.165
   Waltermann M, 2010, ACTA ACUST UNITED AC, V96, P1090, DOI 10.3813/AAA.918370
   Walhovd KB, 2002, INT J PSYCHOPHYSIOL, V46, P29, DOI 10.1016/S0167-8760(02)00039-9
   Waltermann M, 2013, T LABS SERIES TELECO
   Wronka E, 2012, ACTA NEUROBIOL EXP, V72, P51
   Zang S, 2019, J NEURAL ENG, V16
   Zielinski S, 2008, J AUDIO ENG SOC, V56, P427
NR 70
TC 3
Z9 3
U1 1
U2 7
PU IOP PUBLISHING LTD
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 1741-2560
EI 1741-2552
J9 J NEURAL ENG
JI J. Neural Eng.
PD DEC
PY 2019
VL 16
IS 6
AR 066008
DI 10.1088/1741-2552/ab1673
PG 17
WC Engineering, Biomedical; Neurosciences
SC Engineering; Neurosciences & Neurology
GA JX5RN
UT WOS:000503792000006
PM 30952146
DA 2021-02-24
ER

PT J
AU Manca, AD
   Di Russo, F
   Sigona, F
   Grimaldi, M
AF Manca, Anna Dora
   Di Russo, Francesco
   Sigona, Francesco
   Grimaldi, Mirko
TI Electrophysiological evidence of phonemotopic representations of vowels
   in the primary and secondary auditory cortex
SO CORTEX
LA English
DT Article
DE N1; Primary auditory cortex; Superior temporal gyrus;
   Electroencephalography; Distinctive features
ID ORDERLY CORTICAL REPRESENTATION; TONOTOPIC ORGANIZATION;
   SPEECH-PERCEPTION; N1 WAVE; BRAIN; COMPONENT; EEG; MEG; LOCALIZATION;
   RECOGNITION
AB How the brain encodes the speech acoustic signal into phonological representations is a fundamental question for the neurobiology of language. Determining whether this process is characterized by tonotopic maps in primary or secondary auditory areas, with bilateral or leftward activity, remains a long-standing challenge. Magnetoencephalographic studies failed to show hierarchical and asymmetric hints for speech processing. We employed high-density electroencephalography to map the Salento Italian vowel system onto cortical sources using the N1 auditory evoked component. We found evidence that the N1 is characterized by hierarchical and asymmetrical indexes in primary and secondary auditory areas structuring vowel representations. Importantly, the N1 was characterized by early and late phases. The early N1 peaked at 125-135 msec and was localized in the primary auditory cortex; the late N1 peaked at 145-155 msec and was localized in the left superior temporal gyrus. We showed that early in the primary auditory cortex, the cortical spatial arrangements-along the lateral-medial and anterior-posterior gradients-are broadly warped by phonemotopic patterns according to the distinctive feature principle. These phonemotopic patterns are carefully refined in the superior temporal gyrus along the inferior-superior and anterior-posterior gradients. The dynamical and hierarchical interface between primary and secondary auditory areas and the interaction effects between Height and Place features generate the categorical representation of the Salento Italian vowels. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Manca, Anna Dora; Sigona, Francesco; Grimaldi, Mirko] Univ Salento, CRIL, Lecce, Italy.
   [Manca, Anna Dora; Sigona, Francesco; Grimaldi, Mirko] Lab Diffuso Ric Interdisciplinare Appl Med DReAM, Lecce, Italy.
   [Di Russo, Francesco] Univ Rome Foro Italico, Dipartimento Sci Motorie Umane & Salute, Rome, Italy.
   [Di Russo, Francesco] IRCCS Fdn Santa Lucia, Rome, Italy.
RP Grimaldi, M (corresponding author), Univ Salento, CRIL, Lecce, Italy.
EM mirko.grimaldi@unisalento.it
RI Sigona, Francesco/AAC-1064-2019
OI Sigona, Francesco/0000-0003-2939-0009
FU Italian Ministry of Education, University and ResearchMinistry of
   Education, Universities and Research (MIUR) [20128YAFKB006]
FX We wish to thank two anonymous reviewers for their stimulating comments
   on the manuscript permitting us to improve the interpretation of the
   data. MG is very grateful to Andrea Calabrese for illuminating
   discussions on many issues of this research: he taught him to generalize
   starting from complex data. We would like to thank also Philip Monahan,
   Elvira Brattico, and Giovanna Marotta for their useful comments on
   previous versions of the manuscript. This research was supported by the
   Italian Ministry of Education, University and Research. Grant. No.
   20128YAFKB006.
CR Ahlfors SP, 2010, BRAIN TOPOGR, V23, P227, DOI 10.1007/s10548-010-0154-x
   Baayen R.H., 2008, ANAL LINGUISTIC DATA
   Baillet S, 2017, NAT NEUROSCI, V20, P327, DOI 10.1038/nn.4504
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Bernal B, 2016, AIMS NEUROSCI, V3, P454, DOI 10.3934/Neuroscience.2016.4.454
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Bocker Koen B. E., 1994, Brain Topography, V7, P71, DOI 10.1007/BF01184839
   Boersma P., 2011, PRAAT DOING PHONETIC
   Brody RM, 2013, OTOL NEUROTOL, V34, P1226, DOI 10.1097/MAO.0b013e31829763c4
   CALABRESE A, 1995, LINGUIST INQ, V26, P373
   Cohen D., 2003, ENCY NEUROSCIENCE
   DEBOER B, 2001, ORIGINS VOWEL SYSTEM
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Embick D, 2015, LANG COGN NEUROSCI, V30, P357, DOI 10.1080/23273798.2014.980750
   Eulitz C, 2004, COGNITIVE BRAIN RES, V19, P82, DOI 10.1016/j.cogbrainres.2003.11.004
   Gage N, 1998, BRAIN RES, V814, P236, DOI 10.1016/S0006-8993(98)01058-0
   Grimaldi M, 2016, BIOLINGUISTIC INVEST, P80
   Grimaldi M, 2009, ROMANCE LANGUAGES LI, P89, DOI DOI 10.1353/LAN.2006.0021
   Grimaldi M, 2018, SOUNDS STRUCTURES VE, P66
   Grimaldi M, 2012, J NEUROLINGUIST, V25, P304, DOI 10.1016/j.jneuroling.2011.12.002
   HALLE M, 1962, IRE T INFORM THEOR, V8, P155, DOI 10.1109/TIT.1962.1057686
   Halle M, 2002, MEMORY SPEECH BACK P
   HARI R, 1980, EXP BRAIN RES, V40, P237, DOI 10.1007/BF00237543
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hothorn T, 2008, BIOMETRICAL J, V50, P346, DOI 10.1002/bimj.200810425
   Inui K, 2006, CEREB CORTEX, V16, P18, DOI 10.1093/cercor/bhi080
   Liu AK, 2002, HUM BRAIN MAPP, V16, P47, DOI 10.1002/hbm.10024
   Malmivuo J, 1997, IEEE T BIO-MED ENG, V44, P196, DOI 10.1109/10.554766
   Manca AD, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01413
   McDonald JJ, 2003, J COGNITIVE NEUROSCI, V15, P10, DOI 10.1162/089892903321107783
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Obleser J, 2004, BMC NEUROSCI, V5, DOI 10.1186/1471-2202-5-24
   Obleser J, 2004, J COGNITIVE NEUROSCI, V16, P31, DOI 10.1162/089892904322755539
   Obleser J, 2003, COGNITIVE BRAIN RES, V15, P207, DOI 10.1016/S0926-6410(02)00193-3
   Ohl FW, 1997, P NATL ACAD SCI USA, V94, P9440, DOI 10.1073/pnas.94.17.9440
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Peelle JE, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00309
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Picton T.W., 1978, ATTENTION PERFORM, P429
   Pinheiro J, 2000, LINEAR NONLINEAR MIX
   Poeppel D, 1997, NEUROSCI LETT, V221, P145, DOI 10.1016/S0304-3940(97)13325-0
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Poeppel D, 2011, LANG COGNITIVE PROC, V26, P935, DOI 10.1080/01690965.2010.493301
   R Core Team, 2015, R LANG ENV STAT COMP
   Rampinini AC, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-17314-0
   Roberts TPL, 2000, J CLIN NEUROPHYSIOL, V17, P114, DOI 10.1097/00004691-200003000-00002
   ROMANI GL, 1982, SCIENCE, V216, P1339, DOI 10.1126/science.7079770
   Saenz M, 2014, HEARING RES, V307, P42, DOI 10.1016/j.heares.2013.07.016
   Scharinger M, 2012, J SPEECH LANG HEAR R, V55, P903, DOI 10.1044/1092-4388(2011/11-0065)
   Scharinger M, 2011, J COGNITIVE NEUROSCI, V23, P3972, DOI 10.1162/jocn_a_00056
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   Scott SK, 2000, BRAIN, V123, P2400, DOI 10.1093/brain/123.12.2400
   Scott SK, 2013, BRAIN LANG, V127, P36, DOI 10.1016/j.bandl.2013.07.006
   Shestakova A, 2004, COGNITIVE BRAIN RES, V21, P342, DOI 10.1016/j.cogbrainres.2004.06.011
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Stevens KN, 2002, J ACOUST SOC AM, V111, P1872, DOI 10.1121/1.1458026
   Talavage TM, 2004, J NEUROPHYSIOL, V91, P1282, DOI 10.1152/jn.01125.2002
   Teder-Salejarvi WA, 2005, J COGNITIVE NEUROSCI, V17, P1396, DOI 10.1162/0898929054985383
   Teder-Salejarvi WA, 2002, COGNITIVE BRAIN RES, V14, P106, DOI 10.1016/S0926-6410(02)00065-4
   Teuber H.-L, 1967, BRAIN MECH UNDERLY, P204
   The MathWorks Inc, 2012, MATLAB STAT TOOLB RE
   Weinberger Norman M, 2015, Handb Clin Neurol, V129, P117, DOI 10.1016/B978-0-444-62630-1.00007-X
   Weise A, 2018, PSYCHOPHYSIOLOGY, V55, DOI 10.1111/psyp.13063
   WOLPAW JR, 1975, ELECTROEN CLIN NEURO, V39, P609, DOI 10.1016/0013-4694(75)90073-5
   WOOD CC, 1982, ELECTROEN CLIN NEURO, V54, P25, DOI 10.1016/0013-4694(82)90228-0
   Woods DL, 1995, EEG CL N SU, P102
NR 68
TC 1
Z9 1
U1 1
U2 1
PU ELSEVIER MASSON, CORP OFF
PI PARIS
PA 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE
SN 0010-9452
EI 1973-8102
J9 CORTEX
JI Cortex
PD DEC
PY 2019
VL 121
SI SI
BP 385
EP 398
DI 10.1016/j.cortex.2019.09.016
PG 14
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA JU5LE
UT WOS:000501715900029
PM 31678684
DA 2021-02-24
ER

PT J
AU Jenson, D
   Thornton, D
   Harkrider, AW
   Saltuklaroglu, T
AF Jenson, David
   Thornton, David
   Harkrider, Ashley W.
   Saltuklaroglu, Tim
TI Influences of cognitive load on sensorimotor contributions to working
   memory: An EEG investigation of mu rhythm activity during speech
   discrimination
SO NEUROBIOLOGY OF LEARNING AND MEMORY
LA English
DT Article
ID SHORT-TERM-MEMORY; PREMOTOR CORTEX; NEURAL OSCILLATIONS; AUDITORY
   ATTENTION; BAND OSCILLATIONS; DEGRADED SPEECH; SEX-DIFFERENCES; MOTOR
   SYSTEM; N-BACK; ALPHA
AB Sensorimotor activity during speech perception is highly variable and is thought to be related to the underlying cognitive processes recruited to meet task demands. The purpose of the current study was to evaluate the impact of cognitive load on sensorimotor-based attention and working memory processes during speech perception. Manipulations of set size and signal clarity were employed to alter cognitive load. Raw EEG data recorded from 42 subjects during accurate discrimination of CV syllable pairs were decomposed by Independent component analysis; identifying sensorimotor mu components from 37 subjects. Time-frequency analyses revealed event related desynchronization (ERD) across alpha and beta frequency bands during and following stimulus presentation in all conditions, reflecting working memory maintenance through covert articulatory rehearsal. No early attentional activity was observed, suggesting adaptation to tasks. However, modulation of late working memory activity was observed between degraded and non-degraded conditions. Weak and delayed alpha and beta ERD in degraded conditions were interpreted as evidence of delayed implementation of covert rehearsal due to the prolonged time necessary to extract a phonological representation from the auditory signal. Findings are interpreted within Analysis by Synthesis to characterize the multi-faceted and temporally distinct contributions of anterior sensorimotor regions to working memory in support of speech discrimination.
C1 [Jenson, David] Washington State Univ, Elson S Floyd Coll Med, Dept Speech & Hearing Sci, Spokane, WA USA.
   [Thornton, David] Gallaudet Univ, Dept Hearing Speech & Language Sci, Washington, DC 20002 USA.
   [Harkrider, Ashley W.; Saltuklaroglu, Tim] Univ Tennessee, Hlth Sci Ctr, Coll Hlth Profess, Dept Audiol & Speech Pathol, Knoxville, TN USA.
RP Jenson, D (corresponding author), 412 E Spokane Falls Blvd, Spokane, WA 99202 USA.
EM david.jenson@wsu.edu
OI Jenson, David/0000-0001-5744-0910
CR Acerbi L, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0170466
   Alho J, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00394
   Alho J, 2012, NEUROIMAGE, V60, P1937, DOI 10.1016/j.neuroimage.2012.02.011
   Alho K, 2015, BRAIN RES, V1626, P136, DOI 10.1016/j.brainres.2014.12.050
   Alho K, 2012, BRAIN RES, V1442, P47, DOI 10.1016/j.brainres.2012.01.007
   Alschuler DM, 2014, CLIN NEUROPHYSIOL, V125, P484, DOI 10.1016/j.clinph.2013.08.024
   Ardoint M, 2014, J ACOUST SOC AM, V136, pEL275, DOI 10.1121/1.4895096
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Baddeley A, 2003, J COMMUN DISORD, V36, P189, DOI 10.1016/S0021-9924(03)00019-4
   Behmer LP, 2014, BEHAV BRAIN RES, V260, P1, DOI 10.1016/j.bbr.2013.11.031
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bever TG, 2010, BIOLINGUISTICS, V4, P174
   Bickel S, 2012, NEUROIMAGE, V62, P1867, DOI 10.1016/j.neuroimage.2012.06.009
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   Bizovicar N, 2014, CLIN NEUROPHYSIOL, V125, P1689, DOI 10.1016/j.clinph.2013.12.108
   Bowers A, 2019, EXP BRAIN RES, V237, P705, DOI 10.1007/s00221-018-5447-4
   Bowers A, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0072024
   Bowers AL, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00366
   Brinkman L, 2014, J NEUROSCI, V34, P14783, DOI 10.1523/JNEUROSCI.2039-14.2014
   Brunner C., 2013, BIOMED TECH BERL
   Buchsbaum BR, 2005, NEURON, V48, P687, DOI 10.1016/j.neuron.2005.09.029
   Burton MW, 2000, J COGNITIVE NEUROSCI, V12, P679, DOI 10.1162/089892900562309
   Callan AM, 2006, NEUROREPORT, V17, P1353, DOI 10.1097/01.wnr.0000224774.66904.29
   Callan D, 2010, NEUROIMAGE, V51, P844, DOI 10.1016/j.neuroimage.2010.02.027
   Chiappe P, 2001, J EXP CHILD PSYCHOL, V80, P58, DOI 10.1006/jecp.2000.2624
   Cogan GB, 2014, NATURE, V507, P94, DOI 10.1038/nature12935
   Cope TE, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01958-7
   Cuellar M, 2016, CLIN NEUROPHYSIOL, V127, P2625, DOI 10.1016/j.clinph.2016.04.027
   D'Ausilio A, 2012, CORTEX, V48, P882, DOI 10.1016/j.cortex.2011.05.017
   Delorme A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030135
   Delval A, 2006, NEUROLOGY, V67, P1086, DOI 10.1212/01.wnl.0000237528.32932.9a
   Deng Y, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033337
   Erickson MA, 2017, BIOL PSYCHIAT-COGN N, V2, P272, DOI 10.1016/j.bpsc.2016.09.003
   Fowler CA, 2016, SPEECH MOTOR CONTROL, P1
   Frey JN, 2014, J NEUROSCI, V34, P6634, DOI 10.1523/JNEUROSCI.4813-13.2014
   Gao YY, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00034
   Gilbert G, 2010, J ACOUST SOC AM, V128, pEL294, DOI 10.1121/1.3501962
   Golumbic EMZ, 2012, BRAIN LANG, V122, P151, DOI 10.1016/j.bandl.2011.12.010
   Graimann B, 2006, PROG BRAIN RES, V159, P79, DOI 10.1016/S0079-6123(06)59006-5
   Greischar LL, 2004, CLIN NEUROPHYSIOL, V115, P710, DOI 10.1016/j.clinph.2003.10.028
   Gunji A, 2007, NEUROIMAGE, V34, P426, DOI 10.1016/j.neuroimage.2006.07.018
   Hari R, 2006, PROG BRAIN RES, V159, P253, DOI 10.1016/S0079-6123(06)59017-X
   Herman AB, 2013, J NEUROSCI, V33, P5439, DOI 10.1523/JNEUROSCI.1472-12.2013
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2003, J COGNITIVE NEUROSCI, V15, P673, DOI 10.1162/089892903322307393
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2011, BRAIN LANG, V119, P214, DOI 10.1016/j.bandl.2011.08.001
   Houde JF, 2015, CURR OPIN NEUROBIOL, V33, P174, DOI 10.1016/j.conb.2015.04.006
   Houde JF, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00082
   Jacquemot C, 2006, TRENDS COGN SCI, V10, P480, DOI 10.1016/j.tics.2006.09.002
   Jensen O, 2002, CEREB CORTEX, V12, P877, DOI 10.1093/cercor/12.8.877
   Jensen O, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00186
   Jenson D., 2014, P 2014 BIOM SCI ENG, P1
   Jenson D, 2018, NEUROIMAGE-CLIN, V19, P690, DOI 10.1016/j.nicl.2018.05.026
   Jenson D, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00534
   Jenson D, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00656
   Jones SR, 2010, J NEUROSCI, V30, P13760, DOI 10.1523/JNEUROSCI.2969-10.2010
   Jung TP, 2001, P IEEE, V89, P1107, DOI 10.1109/5.939827
   Kittilstved T, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00126
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Klimesch W, 2012, TRENDS COGN SCI, V16, P606, DOI 10.1016/j.tics.2012.10.007
   Kotz SA, 2010, BRAIN LANG, V112, P3, DOI 10.1016/j.bandl.2009.07.008
   Kumari V, 2011, CURR TOP BEHAV NEURO, V8, P141, DOI 10.1007/7854_2010_117
   Lee TW, 1999, NEURAL COMPUT, V11, P417, DOI 10.1162/089976699300016719
   LoCasto PC, 2004, J COGNITIVE NEUROSCI, V16, P1612, DOI 10.1162/0898929042568433
   Makeig S, 2004, TRENDS COGN SCI, V8, P204, DOI 10.1016/j.tics.2004.03.008
   McMahon CM, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00745
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Michels L, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010298
   Muller N, 2012, CEREB CORTEX, V22, P1604, DOI 10.1093/cercor/bhr232
   Nystrom P, 2008, SOC NEUROSCI-UK, V3, P334, DOI 10.1080/17470910701563665
   Obleser J, 2012, J NEUROSCI, V32, P12376, DOI 10.1523/JNEUROSCI.4908-11.2012
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Onton J, 2006, PROG BRAIN RES, V159, P99, DOI 10.1016/S0079-6123(06)59007-7
   Oostenveld R, 2002, HUM BRAIN MAPP, V17, P179, DOI 10.1002/hbm.10061
   Osnes B, 2011, NEUROIMAGE, V54, P2437, DOI 10.1016/j.neuroimage.2010.09.078
   Ostrand R, 2016, COGNITION, V151, P96, DOI 10.1016/j.cognition.2016.02.019
   Perry A, 2010, NEUROREPORT, V21, P1050, DOI 10.1097/WNR.0b013e32833fcb71
   Peschke C, 2012, NEUROIMAGE, V59, P788, DOI 10.1016/j.neuroimage.2011.07.025
   Pesonen M, 2007, BRAIN RES, V1138, P171, DOI 10.1016/j.brainres.2006.12.076
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   Pineda JA, 2005, BRAIN RES REV, V50, P57, DOI 10.1016/j.brainresrev.2005.04.005
   Popovich C, 2010, NEUROPSYCHOLOGIA, V48, P4102, DOI 10.1016/j.neuropsychologia.2010.10.016
   PRATT H, 1994, BRAIN LANG, V46, P353, DOI 10.1006/brln.1994.1019
   Proskovec AL, 2016, HUM BRAIN MAPP, V37, P2348, DOI 10.1002/hbm.23178
   de Miguel AR, 2015, OTOL NEUROTOL, V36, P720, DOI 10.1097/MAO.0000000000000658
   Rottschy C, 2012, NEUROIMAGE, V60, P830, DOI 10.1016/j.neuroimage.2011.11.050
   Saltuklaroglu T., 2018, BRAIN LANGUAGE
   Saltuklaroglu T, 2017, NEUROIMAGE, V153, P232, DOI 10.1016/j.neuroimage.2017.04.022
   Sato M, 2009, BRAIN LANG, V111, P1, DOI 10.1016/j.bandl.2009.03.002
   Scharinger C, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00006
   Schroeder CE, 2010, CURR OPIN NEUROBIOL, V20, P172, DOI 10.1016/j.conb.2010.02.010
   Sebastiani V, 2014, NEUROIMAGE, V102, P717, DOI 10.1016/j.neuroimage.2014.08.031
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Smalle EHM, 2015, CEREB CORTEX, V25, P3690, DOI 10.1093/cercor/bhu218
   Smith JO, 1999, IEEE T SPEECH AUDI P, V7, P697, DOI 10.1109/89.799695
   Sohoglu E, 2016, P NATL ACAD SCI USA, V113, pE1747, DOI 10.1073/pnas.1523266113
   Sohoglu E, 2014, J EXP PSYCHOL HUMAN, V40, P186, DOI 10.1037/a0033206
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   Stenner MP, 2014, J COGNITIVE NEUROSCI, V26, P2540, DOI 10.1162/jocn_a_00658
   Stevens K., 1967, MODELS PERCEPTION SP, P88
   Stone J., 2004, INDEPENDENT COMPONEN
   Tamura T, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00225
   Tan HL, 2016, J NEUROSCI, V36, P1516, DOI 10.1523/JNEUROSCI.3204-15.2016
   Tan HL, 2014, J NEUROSCI, V34, P5678, DOI 10.1523/JNEUROSCI.4739-13.2014
   Thornton D., 2017, BRAIN LANGUAGE
   Thornton D, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-36775-5
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   Tsoneva Tsvetomira, 2011, Annu Int Conf IEEE Eng Med Biol Soc, V2011, P3828, DOI 10.1109/IEMBS.2011.6090952
   van Diepen RM, 2017, EUR J NEUROSCI, V45, P1431, DOI 10.1111/ejn.13570
   van Ede F, 2011, J NEUROSCI, V31, P2016, DOI 10.1523/JNEUROSCI.5630-10.2011
   Venezia JH, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00157
   Wilsch A, 2016, BRAIN RES, V1640, P193, DOI 10.1016/j.brainres.2015.10.054
   Wilsch A, 2015, CEREB CORTEX, V25, P1938, DOI 10.1093/cercor/bhu004
   Wilson M, 2001, PSYCHON B REV, V8, P44, DOI 10.3758/BF03196138
   Wostmann M, 2017, CEREB CORTEX, V27, P3307, DOI 10.1093/cercor/bhx074
   Wostmann M, 2016, P NATL ACAD SCI USA, V113, P3873, DOI 10.1073/pnas.1523357113
NR 118
TC 3
Z9 3
U1 3
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1074-7427
EI 1095-9564
J9 NEUROBIOL LEARN MEM
JI Neurobiol. Learn. Mem.
PD DEC
PY 2019
VL 166
AR 107098
DI 10.1016/j.nlm.2019.107098
PG 12
WC Behavioral Sciences; Neurosciences; Psychology; Psychology,
   Multidisciplinary
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA JV2IA
UT WOS:000502191100015
PM 31634566
DA 2021-02-24
ER

PT J
AU Liu, LD
   Jaeger, TF
AF Liu, Linda
   Jaeger, T. Florian
TI Talker-Specific Pronunciation or Speech Error? Discounting (or not)
   Atypical Pronunciations During Speech Perception
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE
LA English
DT Article
DE speech perception; perceptual recalibration; causal inference; speech
   error; tongue twister
ID FOREIGN-ACCENTED SPEECH; SELECTIVE ADAPTATION; VISUAL RECALIBRATION;
   TONGUE; SLIPS; IDENTIFICATION; INFORMATION; ACTIVATION; DISFLUENCY;
   DETECTORS
AB Perceptual recalibration allows listeners to adapt to talker-specific pronunciations, such as atypical realizations of specific sounds. Such recalibration can facilitate robust speech recognition. However, indiscriminate recalibration following any atypically pronounced words also risks interpreting pronunciations as characteristic of a talker that are in reality because of incidental, short-lived factors (such as a speech error). We investigate whether the mechanisms underlying perceptual recalibration involve inferences about the causes for unexpected pronunciations. In 5 experiments, we ask whether perceptual recalibration is blocked if the atypical pronunciations of an unfamiliar talker can also be attributed to other incidental causes. We investigated 3 type of incidental causes for atypical pronunciations: the talker is intoxicated, the talker speaks unusually fast, or the atypical pronunciations occur only in the context of tongue twisters. In all 5 experiments, we find robust evidence for perceptual recalibration, but little evidence that the presence of incidental causes block perceptual recalibration. We discuss these results in light of other recent findings that incidental causes can block perceptual recalibration.
   Public Significance Statement
   This study investigates the mechanisms operating during human speech perception. The results suggest limits in the types of information that can be integrated during real-time processing of spoken language.
C1 [Liu, Linda; Jaeger, T. Florian] Univ Rochester, Dept Brain & Cognit Sci, Meliora Hall,Box 270268, Rochester, NY 14627 USA.
   [Jaeger, T. Florian] Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA.
RP Jaeger, TF (corresponding author), Univ Rochester, Dept Brain & Cognit Sci, Meliora Hall,Box 270268, Rochester, NY 14627 USA.
EM fjaeger@ur.rochester.edu
RI Jaeger, T. Florian/O-8224-2019
OI Jaeger, T. Florian/0000-0002-1158-7308
FU NIH R01 GrantUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [HD075797]; EUNICE KENNEDY SHRIVER
   NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH Eunice Kennedy Shriver National Institute of Child Health &
   Human Development (NICHD) [R01HD075797, R01HD075797] Funding Source: NIH
   RePORTER
FX The research presented here was funded by NIH R01 Grant HD075797 to T.
   Florian Jaeger. The views expressed here do not necessarily reflect
   those of the funding agency. The authors are grateful for particularly
   helpful feedback from John Alderete, Athanassios Protopapas, Arty
   Samuel, Rachel Theodore, and Xin Xie. Earlier presentations of this work
   benefitted from feedback from Ehsan Hogue, Crystal Lee, Michael K.
   Tanenhaus, Davy Temperley, Xin Xie, as well as members of the Human
   Language Processing lab at the University of Rochester. Additional
   online data are available at https://osf.io/ungba/.
CR Alderete J, 2019, LANG SPEECH, V62, P281, DOI 10.1177/0023830918765012
   Arnold JE, 2004, PSYCHOL SCI, V15, P578, DOI 10.1111/j.0956-7976.2004.00723.x
   Arnold JE, 2007, J EXP PSYCHOL LEARN, V33, P914, DOI 10.1037/0278-7393.33.5.914
   Baese-Berk MM, 2013, J ACOUST SOC AM, V133, pEL174, DOI 10.1121/1.4789864
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Bicknell K., 2019, LISTENERS CAN UNPUB
   Bowers JS, 2016, J MEM LANG, V87, P71, DOI 10.1016/j.jml.2015.11.002
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   BRESLOW NE, 1993, J AM STAT ASSOC, V88, P9, DOI 10.1080/01621459.1993.10594284
   Burchill Z, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199358
   Bushong W, 2017, P 39 ANN C COGN SCI, P1129
   Chin S. B., 1997, ALCOHOL SPEECH
   Choe Wook Kyung, 2012, Lab Phonol, V3, P5
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Clarke-Davidson CM, 2008, PERCEPT PSYCHOPHYS, V70, P604, DOI 10.3758/PP.70.4.604
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Cutler A., 2004, SPEECH LANGUAGE STUD, P37
   Dix S., 2018, INTEGRATION TO UNPUB
   Drouin JR, 2018, J ACOUST SOC AM, V144, P1089, DOI 10.1121/1.5047672
   Drouin JR, 2016, J ACOUST SOC AM, V140, pEL307, DOI 10.1121/1.4964468
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   Eisner F, 2006, J ACOUST SOC AM, V119, P1950, DOI 10.1121/1.2178721
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   FERBER R, 1991, J PSYCHOLINGUIST RES, V20, P105
   Frisch SA, 2002, J PHONETICS, V30, P139, DOI 10.1006/jpho.2002.0176
   FROMKIN VA, 1971, LANGUAGE, V47, P27, DOI 10.2307/412187
   GARNHAM A, 1981, LINGUISTICS, V19, P805, DOI 10.1515/ling.1981.19.7-8.805
   Goldrick M, 2006, LANG COGNITIVE PROC, V21, P649, DOI 10.1080/01690960500181332
   Goldstein L, 2007, COGNITION, V103, P386, DOI 10.1016/j.cognition.2006.05.010
   Grodner D. J., 2011, PROCESSING ACQUISITI, P239, DOI DOI 10.7551/MITPRESS/9780262015127.003.0010
   Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Heigl B, 2018, INFLUENCE ALCOHOL
   Jaeger Florian, 2011, LINGUIST TYPOL, V15, P281, DOI [10.1515/lity.2011.021, DOI 10.1515/LITY.2011.021]
   Jaeger T. F., 2019, STRONG EVIDENCE EXPE
   Jaeger TF, 2010, COGNITIVE PSYCHOL, V61, P23, DOI 10.1016/j.cogpsych.2010.02.002
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Kleinschmidt D. F., 2012, P 34 ANN M COGN SCI
   Kleinschmidt D. F., 2011, ACL HLT 2011, P10
   Kleinschmidt D. F., 2015, P 37 ANN M COGN SCI, P1129
   Kleinschmidt DF, 2016, PSYCHON B REV, V23, P678, DOI 10.3758/s13423-015-0943-z
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2008, PSYCHOL SCI, V19, P332, DOI 10.1111/j.1467-9280.2008.02090.x
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   Kraljic T, 2011, COGNITION, V121, P459, DOI 10.1016/j.cognition.2011.08.015
   Kurumada C., 2018, PROBABILISTIC UNPUB
   Lancia L, 2013, LAB PHONOL, V4, P221, DOI 10.1515/lp-2013-0009
   Levelt W. J., 1993, SPEAKING INTENTION A, V1
   Liu LD, 2018, COGNITION, V174, P55, DOI 10.1016/j.cognition.2018.01.003
   MACKAY DG, 1982, PSYCHOL REV, V89, P483, DOI 10.1037/0033-295X.89.5.483
   McGowan KB, 2015, LANG SPEECH, V58, P502, DOI 10.1177/0023830914565191
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McMillan CT, 2010, COGNITION, V117, P243, DOI 10.1016/j.cognition.2010.08.019
   McMurray B., 2012, FRICATIVE MAKER PRO
   Montero-Melis G., 2017, COGN SEMANT, V3, DOI [DOI 10.1163/23526416-00301002, https://doi.org/10.1163/23526416-00301002]
   Motley M. T., 1976, COMMUNICATION Q, V24, P28, DOI 10.1080/01463377609369216
   MOWREY RA, 1990, J ACOUST SOC AM, V88, P1299, DOI 10.1121/1.399706
   Munson C.M., 2011, THESIS
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Nooteboom S. G., 1980, ERRORS LINGUISTIC PE, P87
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Pogue A, 2016, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.02035
   Postma A, 2000, COGNITION, V77, P97, DOI 10.1016/S0010-0277(00)00090-1
   Pouplier M, 2007, LANG SPEECH, V50, P311, DOI 10.1177/00238309070500030201
   Reinisch E, 2014, J EXP PSYCHOL HUMAN, V40, P539, DOI 10.1037/a0034409
   Rohde H, 2018, PSYCHOL LEARN MOTIV, V68, P215, DOI 10.1016/bs.plm.2018.08.012
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   SAMUEL AG, 1986, COGNITIVE PSYCHOL, V18, P452, DOI 10.1016/0010-0285(86)90007-1
   SAMUEL AG, 1989, PERCEPT PSYCHOPHYS, V45, P485, DOI 10.3758/BF03208055
   Samuel AG, 1997, COGNITIVE PSYCHOL, V32, P97, DOI 10.1006/cogp.1997.0646
   Samuel AG, 2016, COGNITIVE PSYCHOL, V88, P88, DOI 10.1016/j.cogpsych.2016.06.007
   SEVALD CA, 1994, COGNITION, V53, P91, DOI 10.1016/0010-0277(94)90067-1
   Shattuck-Hufnagel S., 1983, PRODUCTION SPEECH, P109
   SHATTUCKHUFNAGEL S, 1979, J VERB LEARN VERB BE, V18, P41, DOI 10.1016/S0022-5371(79)90554-1
   Sidaras SK, 2009, J ACOUST SOC AM, V125, P3306, DOI 10.1121/1.3101452
   Tuomainen J, 2005, COGNITION, V96, pB13, DOI 10.1016/j.cognition.2004.10.004
   Tzeng CY, 2016, J EXP PSYCHOL HUMAN, V42, P1793, DOI 10.1037/xhp0000260
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
   Vroomen J, 2009, LANG SPEECH, V52, P341, DOI 10.1177/0023830909103178
   Wagenmakers EJ, 2007, PSYCHON B REV, V14, P779, DOI 10.3758/BF03194105
   Weatherholtz K, 2016, OXFORD RES ENCY LING, DOI [10.1093/acrefore/9780199384655.001.0001/acrefore-9780199384655-e-95, DOI 10.1093/ACREFORE/9780199384655.001.0001/ACREFORE-9780199384655-E-95]
   WIJNEN F, 1992, J MEM LANG, V31, P734, DOI 10.1016/0749-596X(92)90037-X
   Wilshire CE, 1999, LANG SPEECH, V42, P57, DOI 10.1177/00238309990420010301
   Xie X., 2019, CROSS TALKER GEN FOR
   Xie X, 2018, J ACOUST SOC AM, V143, P2013, DOI 10.1121/1.5027410
   Xie X, 2017, J EXP PSYCHOL HUMAN, V43, P206, DOI 10.1037/xhp0000285
   Zhang XJ, 2014, J EXP PSYCHOL HUMAN, V40, P200, DOI 10.1037/a0033182
NR 89
TC 1
Z9 1
U1 0
U2 8
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0096-1523
EI 1939-1277
J9 J EXP PSYCHOL HUMAN
JI J. Exp. Psychol.-Hum. Percept. Perform.
PD DEC
PY 2019
VL 45
IS 12
BP 1562
EP 1588
DI 10.1037/xhp0000693
PG 27
WC Psychology; Psychology, Experimental
SC Psychology
GA JP1WE
UT WOS:000498061500003
PM 31750716
OA Bronze, Green Accepted
DA 2021-02-24
ER

PT J
AU Ren, J
   Priva, UC
   Morgan, JL
AF Ren, Jie
   Priva, Uriel Cohen
   Morgan, James L.
TI Underspecification in toddlers' and adults' lexical representations
SO COGNITION
LA English
DT Article
DE Lexical representation; Developmental continuity; Mispronunciation
   processing; Phonological details; Underspecification
ID LANGUAGE SPEECH-PERCEPTION; SPOKEN WORD RECOGNITION; SIMILARITY
   NEIGHBORHOODS; PHONOLOGICAL VARIATION; LOCUS EQUATIONS; MENTAL LEXICON;
   PLACE; ASYMMETRIES; CATEGORIES; REPETITION
AB Recent research has shown that toddlers' lexical representations are phonologically detailed, quantitatively much like those of adults. Studies in this article explore whether toddlers' and adults' lexical representations are qualitatively similar. Psycholinguistic claims (Lahiri & Marslen-Wilson, 1991; Lahiri & Reetz, 2002, 2010) based on underspecification (Kiparsky, 1982 et seq.) predict asymmetrical judgments in lexical processing tasks; these have been supported in some psycholinguistic research showing that participants are more sensitive to noncoronal-to-coronal (pop -> top) than to coronal-to-noncoronal (top -> pop) changes or mispronunciations. Three experiments using on-line visual world procedures showed that 19-month-olds and adults displayed sensitivities to both noncoronal-to-coronal and coronal-to-noncoronal mispronunciations of familiar words. No hints of any asymmetries were observed for either age group. There thus appears to be considerable developmental continuity in the nature of early and mature lexical representations. Discrepancies between the current findings and those of previous studies appear to be due to methodological differences that cast doubt on the validity of claims of psycholinguistic support for lexical underspecification.
C1 [Ren, Jie; Priva, Uriel Cohen; Morgan, James L.] Brown Univ, Providence, RI 02912 USA.
RP Ren, J (corresponding author), Brown Univ, Dept Cognit Linguist & Psychol Sci, 190 Thayer St, Providence, RI 02906 USA.
EM Jie_Ren@Brown.Edu
OI Ren, Jie/0000-0002-7658-6752
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [HD32005]
FX This research was supported by NIH grant HD32005 awarded to James L.
   Morgan. The authors thank John Kingston for suggesting that we extend
   our work on mispronunciation processing to investigate possible
   asymmetries, Christopher Schmid for assistance with Bayesian statistical
   methods, and Holger Mitterer for providing details of his 2011 studies.
   We also thank Lori Rolfe for helping with participant recruiting and
   testing and Deanna Macris for recording the audio stimuli used in the
   studies reported here. A preliminary report of a portion of the data
   appeared in the 36th Proceeding of Boston University Conference on
   Language Development, Cascadilla Press. The data can be found in the
   following repository:
   https://data.mendeley.com/datasets/cm84nbrp9d/draft?a=4e669f00-3c65-4212
   -91a4-856edcf1de3a.
CR Anderson JL, 2003, LANG SPEECH, V46, P155, DOI 10.1177/00238309030460020601
   Archangeli D., 1988, PHONOLOGY, V5, DOI [DOI 10.1017/S0952675700002268, 10.1017/S0952675700002268]
   Arnold D, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174623
   Avery P., 1989, PHONOLOGY, V6, P179, DOI DOI 10.1017/S0952675700001007
   Baayen R. H., 2015, LANG COGN NEUROSCI, V31, P106, DOI DOI 10.1080/23273798.2015.1065336
   Baddeley A., 1974, PSYCHOL LEARN MOTIV, V8, P47, DOI [10.1016/S0079-7421(08)60452-1, DOI 10.1016/S0079-7421(08)60452-1]
   Bailey TM, 2002, COGNITIVE DEV, V17, P1265, DOI 10.1016/S0885-2014(02)00116-8
   Barton D., 1980, CHILD PHONOLOGY, V2, P97
   Barton D, 1976, CHILD LANGUAGE DEV, V11, P61
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   BIRD EKR, 1998, FIRST LANG, V18, P105, DOI DOI 10.1177/014272379801805204
   Bortfeld H, 2005, PSYCHOL SCI, V16, P298, DOI 10.1111/j.0956-7976.2005.01531.x
   Britt AE, 2014, ACTA PSYCHOL, V145, P128, DOI 10.1016/j.actpsy.2013.10.004
   CHARLESLUCE J, 1990, J CHILD LANG, V17, P205, DOI 10.1017/S0305000900013180
   CharlesLuce J, 1995, J CHILD LANG, V22, P727, DOI 10.1017/S0305000900010023
   Cohen Priva U., 2012, THESIS
   Connine CM, 1997, J MEM LANG, V37, P463, DOI 10.1006/jmla.1997.2535
   Cornell SA, 2013, J EXP PSYCHOL HUMAN, V39, P757, DOI 10.1037/a0030862
   Cornell SA, 2011, BRAIN RES, V1394, P79, DOI 10.1016/j.brainres.2011.04.001
   Dale PS, 1996, BEHAV RES METH INS C, V28, P125, DOI 10.3758/BF03203646
   Davies M, 2010, LIT LINGUIST COMPUT, V25, P447, DOI 10.1093/llc/fqq018
   Delbe C, 2006, P 28 ANN COGN SCI SO
   Dijkstra N, 2011, PROC ANN BUCLD, P170
   Dutilh G, 2011, COGNITIVE SCI, V35, P211, DOI 10.1111/j.1551-6709.2010.01147.x
   EILERS RE, 1976, J CHILD LANG, V3, P319, DOI 10.1017/S0305000900007212
   EIMAS PD, 1994, J EXP CHILD PSYCHOL, V58, P418, DOI 10.1006/jecp.1994.1043
   Erickson LC, 2014, J MEM LANG, V72, P49, DOI 10.1016/j.jml.2014.01.002
   Eulitz C, 2004, J COGNITIVE NEUROSCI, V16, P577, DOI 10.1162/089892904323057308
   Feldman NH, 2009, PSYCHOL REV, V116, P752, DOI 10.1037/a0017196
   Fennell C. T, 2010, INT C INF STUD BALT
   Fennell C. T, 2007, C CAN SOC BRAIN BEH
   FORBACH GB, 1974, MEM COGNITION, V2, P337, DOI 10.3758/BF03209005
   Friedrich Claudia K, 2006, Behav Brain Funct, V2, P36, DOI 10.1186/1744-9081-2-36
   Friedrich CK, 2008, J EXP PSYCHOL HUMAN, V34, P1545, DOI 10.1037/a0012481
   Garnica O. K, 1973, COGNITIVE DEV ACQUIS, P215
   Garrett S, 1996, CALLHOME SPANISH LEX
   Gaskell MG, 1996, J EXP PSYCHOL HUMAN, V22, P144, DOI 10.1037/0096-1523.22.1.144
   Gelman A., 2003, BAYESIAN DATA ANAL
   GNANADESIKAN A, 2004, CONSTRAINTS PHONOLOG, P73, DOI DOI 10.1017/CBO9780511486418.004
   Goldstone RL, 2001, J EXP PSYCHOL GEN, V130, P116, DOI 10.1037//0096-3445.130.1.116
   Jeffreys H., 1961, THEORY PROBABILITY
   KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572
   Kean M. L., 1975, THESIS
   Keating P. A, 1990, UCLA WORKING PAPERS, V74, P35
   Kilany Hanaa, 2002, EGYPTIAN C ARABIC LE
   Kiparsky Paul, 1982, STRUCTURE PHONOLOGIC, P131
   Klein M, 2015, CEREB CORTEX, V25, P1715, DOI 10.1093/cercor/bht350
   Kobayashi M., 1996, CALLHOME JAPANESE LE
   Kruschke J., 2010, DOING BAYESIAN DATA
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Lahiri A, 2002, PHONOL PHONET, V4-1, P637
   LAHIRI A, 1991, COGNITION, V38, P245, DOI 10.1016/0010-0277(91)90008-R
   Lahiri A, 1999, NONMISMATCHING UNPUB
   Lahiri A, 2010, J PHONETICS, V38, P44, DOI 10.1016/j.wocn.2010.01.002
   Maddieson I., 1984, PATTERNS SOUNDS
   Mani N, 2011, J CHILD LANG, V38, P606, DOI 10.1017/S0305000910000243
   Mareschal D, 2002, COGNITIVE SCI, V26, P377, DOI 10.1207/s15516709cog2603_8
   Mareschal D, 2000, DEV PSYCHOL, V36, P635, DOI [10.1037/0012-1649.36.5.635, 10.1037//0012-1649.36.5.635]
   MARSLENWILSON W, 1995, LANG COGNITIVE PROC, V10, P285, DOI 10.1080/01690969508407097
   Marsolek CJ, 2008, TRENDS COGN SCI, V12, P176, DOI 10.1016/j.tics.2008.02.005
   Mascaro J, 1976, THESIS
   Mayor J, 2014, J MEM LANG, V71, P89, DOI 10.1016/j.jml.2013.09.009
   McQueen JM, 2007, Q J EXP PSYCHOL, V60, P661, DOI 10.1080/17470210601183890
   Metsala JL, 1998, WORD RECOGNITION IN BEGINNING LITERACY, P89
   Meyer AS, 2007, PSYCHON B REV, V14, P710, DOI 10.3758/BF03196826
   MILBERG W, 1988, B PSYCHONOMIC SOC, V26, P305, DOI 10.3758/BF03337665
   Mitterer H, 2011, J EXP PSYCHOL HUMAN, V37, P496, DOI 10.1037/a0020989
   Morgan J. L, 2011, P 17 INT C PHON SCI
   Nazzi T, 2005, COGNITION, V98, P13, DOI 10.1016/j.cognition.2004.10.005
   Obleser J, 2004, J COGNITIVE NEUROSCI, V16, P31, DOI 10.1162/089892904322755539
   Pitt M., 2007, BUCKEYE CORPUS CONVE
   Polk TA, 2002, COGNITION, V82, pB75, DOI 10.1016/S0010-0277(01)00151-2
   QUINN PC, 1993, PERCEPTION, V22, P463, DOI 10.1068/p220463
   Ren J, 2017, P 39 ANN M COGN SCI, P1010
   Ren J, 2013, 83 ANN M LING SOC AM
   Roberts AC, 2013, MENT LEX, V8, P140, DOI 10.1075/ml.8.2.02rob
   ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P573, DOI 10.1016/0010-0285(75)90024-9
   RUGG MD, 1990, MEM COGNITION, V18, P367, DOI 10.3758/BF03197126
   Saffran JR, 2001, COGNITION, V81, P149, DOI 10.1016/S0010-0277(01)00132-9
   Salverda AP, 2010, J EXP PSYCHOL LEARN, V36, P1108, DOI 10.1037/a0019901
   Schvachkin N. K, 1973, STUDIES CHILD LANGUA, P91
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Storkel HL, 2002, J CHILD LANG, V29, P251, DOI 10.1017/S0305000902005032
   SUSSMAN HM, 1992, J SPEECH HEAR RES, V35, P769, DOI 10.1044/jshr.3504.769
   SUSSMAN HM, 1991, J ACOUST SOC AM, V90, P1309, DOI 10.1121/1.401923
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Swingley D, 2002, PSYCHOL SCI, V13, P480, DOI 10.1111/1467-9280.00485
   Tin S, 2014, TECHNICAL REPORT
   Tsuji S, 2016, DEV PSYCHOL, V52, P379, DOI 10.1037/dev0000093
   Tsuji S, 2015, COGNITION, V134, P252, DOI 10.1016/j.cognition.2014.10.009
   TULLER B, 1994, J EXP PSYCHOL HUMAN, V20, P3, DOI 10.1037/0096-1523.20.1.3
   van der Feest SVH, 2015, PHONOLOGY, V32, P207, DOI 10.1017/S0952675715000135
   VANORDEN GC, 1987, MEM COGNITION, V15, P181, DOI 10.3758/BF03197716
   WALLEY AC, 1993, DEV REV, V13, P286, DOI 10.1006/drev.1993.1015
   Walley AC, 2005, BLACKW HBK LINGUIST, P449, DOI 10.1002/9780470757024.ch18
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1988, DEV PSYCHOL, V24, P672, DOI 10.1037/0012-1649.24.5.672
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
   Wheat KL, 2010, J NEUROSCI, V30, P5229, DOI 10.1523/JNEUROSCI.4448-09.2010
   Wheeldon L, 2004, BRAIN LANG, V90, P401, DOI 10.1016/S0093-934X(03)00451-6
   White KS, 2008, J MEM LANG, V59, P114, DOI 10.1016/j.jml.2008.03.001
NR 101
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD DEC
PY 2019
VL 193
AR 103991
DI 10.1016/j.cognition.2019.06.003
PG 27
WC Psychology, Experimental
SC Psychology
GA JO0AX
UT WOS:000497251200003
PM 31525643
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Hale, M
   Kissock, M
AF Hale, Mark
   Kissock, Madelyn
TI The perception-prodution link and linguistic theory
SO LOQUENS
LA English
DT Article
DE perception; production; acquisition; features
AB Recent trends in infant (and adult) speech perception studies, especially in the psychological literature where much of the speech perception work is being and has been done, shows a growing focus on more integrated perception-production-sensorimotor (PPS) bases for perception (Werker & Gervain 2013). We look here at whether the results of such studies are significant for theoretical linguistics - specifically for the fundamental question of how the linguistic system is acquired. We examine a selection of recent experimental results, using Bruderer, Danielson, Kandhadai & Werker (2015) as the focal point.
C1 [Hale, Mark; Kissock, Madelyn] Concordia Univ, Montreal, PQ, Canada.
RP Hale, M (corresponding author), Concordia Univ, Montreal, PQ, Canada.
EM mark.hale@concordia.ca; madelyn.kissock@concordia.ca
CR Bruderer AG, 2015, P NATL ACAD SCI USA, V112, P13531, DOI 10.1073/pnas.1508631112
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Chomsky Noam, 1957, SYNTACTIC STRUCTURES
   Chomsky Noam, 1965, ASPECTS THEORY SYNTA, V11
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Hale L, 2007, CURR CLIN PRACT, P15, DOI 10.1007/978-1-59745-421-6_2
   Hale M., SYNTACTIC FEATURES L
   Hale M., 2008, PHONOLOGICAL ENTERPR
   Hale M., 1997, POPULATION APPROACH, P229
   Hickok G, 2012, J COMMUN DISORD, V45, P393, DOI 10.1016/j.jcomdis.2012.06.004
   HILL BP, 1990, J SPEECH HEAR DISORD, V55, P15, DOI 10.1044/jshd.5501.15
   Houston-Price C, 2004, INFANT CHILD DEV, V13, P341, DOI 10.1002/icd.364
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   Ji A., 2014, THESIS
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Lieberman P., 1988, SPEECH PHYSL SPEECH
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McMurray B, 2005, COGNITION, V95, pB15, DOI 10.1016/j.cognition.2004.07.005
   Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Sams M, 2005, COGNITIVE BRAIN RES, V23, P429, DOI 10.1016/j.cogbrainres.2004.11.006
   Werker J., 2013, OXFORD HDB DEV PSYCH, P909
   WERKER JF, 1984, J ACOUST SOC AM, V75, P1866, DOI 10.1121/1.390988
NR 26
TC 0
Z9 0
U1 0
U2 0
PU CONSEJO SUPERIOR INVESTIGACIONES CIENTIFICAS-CSIC
PI MADRID
PA VITRUVIO 8, 28006 MADRID, SPAIN
SN 2386-2637
J9 LOQUENS
JI Loquens
PD DEC
PY 2019
VL 6
IS 2
AR e066
DI 10.3989/loquens.2019.066
PG 11
WC Linguistics
SC Linguistics
GA VJ6DC
UT WOS:000612984000006
OA Other Gold
DA 2021-02-24
ER

PT J
AU Fostick, L
AF Fostick, Leah
TI Card playing enhances speech perception among aging adults: comparison
   with aging musicians
SO EUROPEAN JOURNAL OF AGEING
LA English
DT Article
DE Music; Leisure activity; Auditory processing; Speech perception
ID AGE-RELATED-CHANGES; ENGAGED LIFE-STYLE; COGNITIVE DECLINE;
   OLDER-ADULTS; STREAM SEGREGATION; LEISURE ACTIVITIES; BRAIN-STEM; RISK;
   BENEFIT; NOISE
AB Speech perception and auditory processing have been shown to be enhanced among aging musicians as compared to non-musicians. In the present study, the aim was to test whether these functions are also enhanced among those who are engaged in a non-musical mentally challenging leisure activity (card playing). Three groups of 23 aging adults, aged 60-80 years, were recruited for the study: Musicians, Card players, and Controls. Participants were matched for age, gender, Wechsler Adult Intelligence Scale-III Matrix Reasoning, and Digit Span scores. Their performance was measured using auditory spectral and spatial temporal order judgment tests, and four tasks of speech perception in conditions of: no background noise, background noise of speech frequencies, background noise of white noise, and 60% compressed speech. Musicians were better in auditory and speech perception than the other two groups. Card players were similar to Controls in auditory perception tasks, but were better in the speech perception tasks. Non-musician aging adults may be able to improve their speech perception ability by engaging in leisure activity requiring cognitive effort.
C1 [Fostick, Leah] Ariel Univ, Dept Commun Disorders, Ariel, Israel.
RP Fostick, L (corresponding author), Ariel Univ, Dept Commun Disorders, Ariel, Israel.
EM Leah.Fostick@ariel.ac.il
RI Fostick, Leah/E-6115-2017
OI Fostick, Leah/0000-0003-3594-6229
CR Aartsen MJ, 2002, J GERONTOL B-PSYCHOL, V57, pP153, DOI 10.1093/geronb/57.2.P153
   Alain C, 2007, J NEUROSCI, V27, P1308, DOI 10.1523/JNEUROSCI.5433-06.2007
   Alain C, 2008, CURR OPIN OTOLARYNGO, V16, P485, DOI 10.1097/MOO.0b013e32830e2096
   Amer T, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071630
   Babkoff H, 2017, EUR J AGEING, V14, P269, DOI 10.1007/s10433-017-0410-y
   Ball K, 2002, JAMA-J AM MED ASSOC, V288, P2271, DOI 10.1001/jama.288.18.2271
   Ball K, 2007, J GERONTOL B-PSYCHOL, V62, P19, DOI 10.1093/geronb/62.special_issue_1.19
   Barnes LL, 2004, NEUROLOGY, V63, P2322, DOI 10.1212/01.WNL.0000147473.04043.B3
   Bassuk SS, 1999, ANN INTERN MED, V131, P165, DOI 10.7326/0003-4819-131-3-199908030-00002
   Ben-David BM, 2016, HEARING RES, V341, P9, DOI 10.1016/j.heares.2016.07.016
   Ben-David BM, 2012, HEARING RES, V290, P55, DOI 10.1016/j.heares.2012.04.022
   Ben-David BM, 2011, J SPEECH LANG HEAR R, V54, P243, DOI 10.1044/1092-4388(2010/09-0233)
   Bidebnan GM, 2010, BRAIN RES, V1355, P112, DOI 10.1016/j.brainres.2010.07.100
   Bidelman GM, 2015, J NEUROSCI, V35, P1240, DOI 10.1523/JNEUROSCI.3292-14.2015
   BOOTHROYD A, 1968, J ACOUST SOC AM, V43, P362, DOI 10.1121/1.1910787
   Bosma H, 2002, Z GERONTOL GERIATR, V35, P575, DOI 10.1007/s00391-002-0080-y
   Carlyon RP, 2004, TRENDS COGN SCI, V8, P465, DOI 10.1016/j.tics.2004.08.008
   Cohen S, 2004, AM PSYCHOL, V59, P676, DOI 10.1037/0003-066X.59.8.676
   Coyle JT, 2003, NEW ENGL J MED, V348, P2489, DOI 10.1056/NEJMp030051
   Dartigues JF, 2013, BMJ OPEN, V3, DOI 10.1136/bmjopen-2013-002998
   Ezzatian P, 2015, EAR HEARING, V36, P482, DOI 10.1097/AUD.0000000000000139
   Fitzgibbons PJ, 2010, SPRINGER HANDB AUDIT, V34, P111, DOI 10.1007/978-1-4419-0993-0_5
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Fostick L, 2014, J SPEECH LANG HEAR R, V57, P1078, DOI 10.1044/1092-4388(2013/13-0031)
   Fostick Leah, 2013, Journal of Basic and Clinical Physiology and Pharmacology, V24, P191, DOI 10.1515/jbcpp-2013-0049
   Fostick Leah, 2013, Journal of Basic and Clinical Physiology and Pharmacology, V24, P175, DOI 10.1515/jbcpp-2013-0048
   Francois C, 2013, CEREB CORTEX, V23, P2038, DOI 10.1093/cercor/bhs180
   Getzmann S, 2015, NEUROBIOL AGING, V36, P3029, DOI 10.1016/j.neurobiolaging.2015.07.017
   Gow AJ, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01176
   Heinrich A., 2016, SOC INQ WELL BEING, V2, P51, DOI DOI 10.13165/SIIW-16-2-1-05
   Heinrich A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00782
   Heinrich A, 2011, Q J EXP PSYCHOL, V64, P186, DOI 10.1080/17470218.2010.492621
   Herholz SC, 2012, NEURON, V76, P486, DOI 10.1016/j.neuron.2012.10.011
   Hertzog Christopher, 2008, Psychol Sci Public Interest, V9, P1, DOI 10.1111/j.1539-6053.2009.01034.x
   Hultsch DF, 1999, PSYCHOL AGING, V14, P245, DOI 10.1037/0882-7974.14.2.245
   Humes LE, 2007, J AM ACAD AUDIOL, V18, P590, DOI 10.3766/jaaa.18.7.6
   Kraus N, 2014, J NEUROSCI, V34, P11913, DOI 10.1523/JNEUROSCI.1881-14.2014
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   O'Brien JL, 2015, BEHAV NEUROL, V2015, DOI 10.1155/2015/545917
   Parbery-Clark A, 2012, NEUROBIOL AGING, V33, DOI 10.1016/j.neurobiolaging.2011.12.015
   Parbery-Clark A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018082
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Parbery-Clark A, 2009, J NEUROSCI, V29, P14100, DOI 10.1523/JNEUROSCI.3256-09.2009
   Park DC, 2014, PSYCHOL SCI, V25, P103, DOI 10.1177/0956797613499592
   Pichora-Fuller MK, 2003, INT J AUDIOL, V42, pS26
   Rammsayer T, 2006, MUSIC PERCEPT, V24, P37, DOI 10.1525/mp.2006.24.1.37
   Schooler C, 2001, PSYCHOL AGING, V16, P466, DOI 10.1037//0882-7974.16.3.466
   Snyder JS, 2005, COGNITIVE BRAIN RES, V24, P492, DOI 10.1016/j.cogbrainres.2005.03.002
   Souza PE, 2007, J AM ACAD AUDIOL, V18, P54, DOI 10.3766/jaaa.18.1.5
   Stern C, 2010, INT J EVID-BASED HEA, V8, P2, DOI 10.1111/j.1744-1609.2010.00150.x
   Strait DL, 2009, ANN NY ACAD SCI, V1169, P209, DOI 10.1111/j.1749-6632.2009.04864.x
   Taitelbaum-Swead R, 2016, FOLIA PHONIATR LOGO, V68, P16, DOI 10.1159/000444749
   Verghese J, 2003, NEW ENGL J MED, V348, P2508, DOI 10.1056/NEJMoa022252
   Vinkers DJ, 2003, NEW ENGL J MED, V349, P1290, DOI 10.1056/NEJM200309253491316
   Wang JYJ, 2006, NEUROLOGY, V66, P911, DOI 10.1212/01.wnl.0000192165.99963.2a
   Wechsler D., 1997, WAIS 3 WECHSLER ADUL
   White-Schwoch T, 2013, J NEUROSCI, V33, P17667, DOI 10.1523/JNEUROSCI.2560-13.2013
   Willis SL, 2006, JAMA-J AM MED ASSOC, V296, P2805, DOI 10.1001/jama.296.23.2805
   Wilson RS, 2007, NEUROLOGY, V69, P1911, DOI 10.1212/01.wnl.0000271087.67782.cb
   Wilson RS, 2003, NEUROLOGY, V61, P812, DOI 10.1212/01.WNL.0000083989.44027.05
   Wilson RS, 2002, JAMA-J AM MED ASSOC, V287, P742, DOI 10.1001/jama.287.6.742
   Zendel BR, 2013, J COGNITIVE NEUROSCI, V25, P503, DOI 10.1162/jocn_a_00329
   Zunzunegui MV, 2003, J GERONTOL B-PSYCHOL, V58, pS93, DOI 10.1093/geronb/58.2.S93
NR 63
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1613-9372
EI 1613-9380
J9 EUR J AGEING
JI Eur. J. Ageing
PD DEC
PY 2019
VL 16
IS 4
BP 481
EP 489
DI 10.1007/s10433-019-00512-2
PG 9
WC Gerontology
SC Geriatrics & Gerontology
GA JN1KB
UT WOS:000496660800008
PM 31798372
OA Green Published
DA 2021-02-24
ER

PT J
AU Wu, Y
   Guo, XT
   Gao, Y
   Wang, ZX
   Wang, XD
AF Wu, Ying
   Guo, Xiaotao
   Gao, Ya
   Wang, Zhengxue
   Wang, Xiaodong
TI Meaning enhances discrimination of merged phonemes: A
   mismatch-negativity study
SO BRAIN RESEARCH
LA English
DT Article
DE Acoustic processing; Phonemic merger; Semantic information; Mismatch
   negativity; Idiom; Pre-attentive
ID SPOKEN WORD RECOGNITION; SPEECH-PERCEPTION; MEMORY TRACES; TOP-DOWN;
   BRAIN POTENTIALS; BOTTOM-UP; LANGUAGE; SOUND; MMN; CHINESE
AB The phonemic merger phenomena is characterized by the inability of distinguishing two acoustically different phonemes, such as /n/ and /l/. Previous studies suggested that the process that drives the phonemic merger is the lack of separated memory traces of phonemes. However, it is still unknown whether higher-level linguistic functions have an influence on the perception of merged phonemes. We designed a mismatch negativity (MMN) study to explore the influence of semantic information in the perception of the phonemic merger. The results showed that no robust MMN was elicited in an oddball stream of the syllables /niu2/ and /liu2/ in the group of merged speakers. We interpreted that the brain of the In/-/l/ merged speakers had almost lost the ability of early auditory discrimination of the phonemes /n/ and /l/. Interestingly, the same merged speakers regained the ability of discriminating /n/ and /l/ when the oddball contrast was placed in an idiom context. All in all, our results indicate that a context with a meaning, such as an idiom, facilitates the early acoustic processing of merged phonemes. This finding also gives additional evidence that not only the bottom-up analysis of the acoustic space, but also the top-down modulation of the functional significance of sounds could contribute to the early auditory discrimination of phonemes.
C1 [Wu, Ying; Gao, Ya; Wang, Zhengxue; Wang, Xiaodong] Southwest Univ, Fac Psychol, 2 Tiansheng Rd,PSY-105, Chongqing 400715, Peoples R China.
   [Guo, Xiaotao] Univ Sci & Technol China, Div Life Sci & Med, Affiliated Hosp USTC 1, Dept Otolaryngol Head & Neck Surg, Hefei, Anhui, Peoples R China.
RP Wang, XD (corresponding author), Southwest Univ, Fac Psychol, 2 Tiansheng Rd,PSY-105, Chongqing 400715, Peoples R China.
EM wxd@mail.ustc.edu.cn
FU Fundamental Research Funds for the Central UniversitiesFundamental
   Research Funds for the Central Universities [SWU 114103, SWU1509449]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities (SWU 114103, SWU1509449).
CR Amenedo E, 2000, EUR J NEUROSCI, V12, P2570, DOI 10.1046/j.1460-9568.2000.00114.x
   Best C.T., 1987, HASKINS LAB STATUS R, V14, P1
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Brunelliere A, 2011, BRAIN LANG, V117, P45, DOI 10.1016/j.bandl.2010.12.004
   Brunelliere A, 2009, COGNITION, V111, P390, DOI 10.1016/j.cognition.2009.02.013
   Ceponiene R, 2004, PSYCHOPHYSIOLOGY, V41, P130, DOI 10.1111/j.1469-8986.2003.00138.x
   Cheour M, 1998, NAT NEUROSCI, V1, P351, DOI 10.1038/1561
   Cheour M, 2001, AUDIOL NEURO-OTOL, V6, P2, DOI 10.1159/000046804
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256
   Conrey B, 2005, BRAIN LANG, V95, P435, DOI 10.1016/j.bandl.2005.06.008
   Diaz B, 2008, P NATL ACAD SCI USA, V105, P16083, DOI 10.1073/pnas.0805022105
   Ervast L, 2015, INT J PSYCHOPHYSIOL, V98, P413, DOI 10.1016/j.ijpsycho.2015.08.007
   [范若琳 Fan Ruolin], 2014, [心理学报, Acta Psychologica Sinica], V46, P569
   GREENHOUSE SW, 1959, PSYCHOMETRIKA, V24, P95, DOI 10.1007/BF02289823
   Gu F, 2012, PSYCHOPHYSIOLOGY, V49, P1353, DOI 10.1111/j.1469-8986.2012.01447.x
   Guo XT, 2018, NEUROSCIENCE, V372, P246, DOI 10.1016/j.neuroscience.2017.12.025
   Haenschel C, 2005, J NEUROSCI, V25, P10494, DOI 10.1523/JNEUROSCI.1227-05.2005
   Halliday LF, 2014, J NEURODEV DISORD, V6, DOI 10.1186/1866-1955-6-21
   Hill PR, 2004, NEUROREPORT, V15, P2195, DOI 10.1097/00001756-200410050-00010
   Hu JH, 2012, PSYCHOPHYSIOLOGY, V49, P1179, DOI 10.1111/j.1469-8986.2012.01406.x
   Huang XJ, 2014, NEUROPSYCHOLOGIA, V63, P165, DOI 10.1016/j.neuropsychologia.2014.08.015
   Kazanina N, 2006, P NATL ACAD SCI USA, V103, P11381, DOI 10.1073/pnas.0604821103
   Liu YN, 2006, BRAIN LANG, V96, P37, DOI 10.1016/j.bandl.2005.08.007
   Luo H, 2006, P NATL ACAD SCI USA, V103, P19558, DOI 10.1073/pnas.0607065104
   Lyu BJ, 2016, J NEUROSCI, V36, P10813, DOI 10.1523/JNEUROSCI.0583-16.2016
   Menning H, 2005, NEUROREPORT, V16, P77, DOI 10.1097/00001756-200501190-00018
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Misra M, 2003, PSYCHOPHYSIOLOGY, V40, P115, DOI 10.1111/1469-8986.00012
   MIYAWAKI K, 1975, PERCEPT PSYCHOPHYS, V18, P331, DOI 10.3758/BF03211209
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   NAATANEN R, 1979, BIOL PSYCHOL, V8, P81, DOI 10.1016/0301-0511(79)90053-X
   Naatanen R, 2005, PSYCHOPHYSIOLOGY, V42, P25, DOI 10.1111/j.1469-8986.2005.00256.x
   NAATANEN R, 1993, NEUROREPORT, V4, P503
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Naatanen R, 2001, PSYCHOPHYSIOLOGY, V38, P1, DOI 10.1017/S0048577201000208
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Partanen E, 2013, P NATL ACAD SCI USA, V110, P15145, DOI 10.1073/pnas.1302159110
   Pattamadilok C, 2014, BRAIN LANG, V137, P103, DOI 10.1016/j.bandl.2014.08.005
   Pulvermuller F, 2001, NEUROIMAGE, V14, P607, DOI 10.1006/nimg.2001.0864
   Pulvermuller F, 2003, NEUROIMAGE, V20, P159, DOI 10.1016/S1053-8119(03)00261-1
   Pulvermuller F, 2006, PROG NEUROBIOL, V79, P49, DOI 10.1016/j.pneurobio.2006.04.004
   Schroger E, 1998, COGNITIVE BRAIN RES, V7, P71, DOI 10.1016/S0926-6410(98)00013-5
   SEMLITSCH HV, 1986, PSYCHOPHYSIOLOGY, V23, P695, DOI 10.1111/j.1469-8986.1986.tb00696.x
   Shtyrov Y, 2004, EUR J NEUROSCI, V19, P1083, DOI 10.1111/j.0953-816X.2004.03126.x
   Shtyrov Y, 2011, NEUROIMAGE, V55, P658, DOI 10.1016/j.neuroimage.2010.12.002
   Shuai L, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00097
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   STRANGE W, 1984, PERCEPT PSYCHOPHYS, V36, P131, DOI 10.3758/BF03202673
   Tamminen H, 2015, INT J PSYCHOPHYSIOL, V97, P23, DOI 10.1016/j.ijpsycho.2015.04.020
   Tan LH, 2008, P NATL ACAD SCI USA, V105, P4004, DOI 10.1073/pnas.0800055105
   Tantibundhit C, 2015, SPEECH COMMUN, V72, P109, DOI 10.1016/j.specom.2015.05.005
   Wang J, 2014, NEUROIMAGE, V102, P637, DOI 10.1016/j.neuroimage.2014.08.030
   Whorf B.L., 2012, LANGUAGE THOUGHT REA
   Yue JX, 2014, BRAIN LANG, V139, P10, DOI 10.1016/j.bandl.2014.09.007
   Zachau S, 2005, NEUROREPORT, V16, P2015, DOI 10.1097/00001756-200512190-00009
   Zekveld AA, 2006, NEUROIMAGE, V32, P1826, DOI 10.1016/j.neuroimage.2006.04.199
   Zhou S, 2004, BRAIN TOPOGR, V17, P27, DOI 10.1023/B:BRAT.0000047334.48256.9f
NR 57
TC 1
Z9 1
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0006-8993
EI 1872-6240
J9 BRAIN RES
JI Brain Res.
PD DEC 1
PY 2019
VL 1724
AR 146433
DI 10.1016/j.brainres.2019.146433
PG 8
WC Neurosciences
SC Neurosciences & Neurology
GA JF8PO
UT WOS:000491646600009
PM 31491423
DA 2021-02-24
ER

PT J
AU Roark, CL
   Holt, LL
AF Roark, Casey L.
   Holt, Lori L.
TI Auditory information-integration category learning in young children and
   adults
SO JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY
LA English
DT Article
DE Category learning; Information integration; Development; Audition;
   Perception; Categorization
ID WORKING-MEMORY; PERCEPTUAL CATEGORIZATION; INDIVIDUAL-DIFFERENCES;
   EXECUTIVE FUNCTION; TASK INTERFERENCE; SPEECH-PERCEPTION; FRONTAL LOBES;
   SYSTEMS; DIMENSIONALITY; ATTENTION
AB Adults outperform children on category learning that requires selective attention to individual dimensions (rule-based categories) due to their more highly developed working memory abilities, but much less is known about developmental differences in learning categories that require integration across multiple dimensions (information-integration categories). The current study investigated auditory information-integration category learning in 5- to 7-year-old children (n = 34) and 18- to 25-year-old adults (n = 35). Adults generally outperformed children during learning. However, some children learned the categories well and used strategies similar to those of adults, as assessed through decision-bound computational models. The results demonstrate that information-integration learning ability continues to develop throughout at least middle childhood. These results have implications for the development of mechanisms that contribute to speech category learning. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Roark, Casey L.; Holt, Lori L.] Carnegie Mellon Univ, Dept Psychol, Pittsburgh, PA 15213 USA.
   [Roark, Casey L.; Holt, Lori L.] Carnegie Mellon Univ, Univ Pittsburgh, Ctr Neural Basis Cognit, Pittsburgh, PA 15213 USA.
RP Roark, CL (corresponding author), Carnegie Mellon Univ, Dept Psychol, Pittsburgh, PA 15213 USA.
EM casey.l.roark@gmail.com
RI Roark, Casey L./AAG-2083-2019
OI Roark, Casey/0000-0001-5642-8784
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01DC004674,
   T32-DC011499]; NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCESUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute of General Medical Sciences
   (NIGMS) [T32GM081760, T32GM081760, T32GM081760, T32GM081760] Funding
   Source: NIH RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [T32DC011499,
   T32DC011499, T32DC011499, T32DC011499, T32DC011499, T32DC011499] Funding
   Source: NIH RePORTER
FX This research was supported by the National Institutes of Health
   (R01DC004674 and T32-DC011499). Thanks go to Christi Gomez for support
   in testing human participants.
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   Ashby F.G, 1992, MULTIDIMENSIONAL MOD, P449
   Ashby FG, 2011, ANN NY ACAD SCI, V1224, P147, DOI 10.1111/j.1749-6632.2010.05874.x
   Ashby FG, 2010, NEUROBIOL LEARN MEM, V94, P1, DOI 10.1016/j.nlm.2010.03.001
   ASHBY FG, 1993, J MATH PSYCHOL, V37, P372, DOI 10.1006/jmps.1993.1023
   Ashby FG, 2003, MEM COGNITION, V31, P1114, DOI 10.3758/BF03196132
   Ashby FG, 1998, PSYCHOL REV, V105, P442, DOI 10.1037/0033-295X.105.3.442
   ASHBY FG, 1986, PSYCHOL REV, V93, P154, DOI 10.1037/0033-295X.93.2.154
   Casey BJ, 2004, DEVELOPMENTAL SCI, V7, P534, DOI 10.1111/j.1467-7687.2004.00377.x
   Chandrasekaran B, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00825
   Chandrasekaran B, 2014, PSYCHON B REV, V21, P488, DOI 10.3758/s13423-013-0501-5
   Dale PS, 1996, BEHAV RES METH INS C, V28, P125, DOI 10.3758/BF03203646
   DeCaro MS, 2008, COGNITION, V107, P284, DOI 10.1016/j.cognition.2007.07.001
   Deng W, 2015, DEV PSYCHOL, V51, P392, DOI 10.1037/a0038749
   Diamond A., 2002, PRINCIPLES FRONTAL L, P466, DOI DOI 10.1093/ACPROF:OSO/9780195134971.003.0029
   Filoteo JV, 2010, PSYCHOL SCI, V21, P415, DOI 10.1177/0956797610362646
   Filoteo JV, 2005, NEUROREPORT, V16, P111, DOI 10.1097/00001756-200502080-00007
   Finn AS, 2016, J EXP CHILD PSYCHOL, V142, P212, DOI 10.1016/j.jecp.2015.09.027
   Garner W., 1974, PROCESSING INFORM ST
   Godwin K. E, 2012, P 35 ANN M COGN SCI, P507
   Greenwood PM, 2007, NEUROPSYCHOLOGY, V21, P657, DOI 10.1037/0894-4105.21.6.657
   Greenwood PM, 2000, J INT NEUROPSYCH SOC, V6, P705, DOI 10.1017/S1355617700666092
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Huang-Pollock CL, 2011, J EXP CHILD PSYCHOL, V109, P321, DOI 10.1016/j.jecp.2011.02.002
   Idemaru K, 2013, J ACOUST SOC AM, V133, P4232, DOI 10.1121/1.4802905
   Kalish ML, 2017, J EXP PSYCHOL LEARN, V43, P503, DOI 10.1037/xlm0000323
   KEMLER DG, 1978, J EXP CHILD PSYCHOL, V26, P498, DOI 10.1016/0022-0965(78)90128-5
   Kloos H, 2008, J EXP PSYCHOL GEN, V137, P52, DOI 10.1037/0096-3445.137.1.52
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Lewandowsky S, 2012, J EXP PSYCHOL LEARN, V38, P881, DOI 10.1037/a0027298
   Lewandowsky S, 2011, J EXP PSYCHOL LEARN, V37, P720, DOI 10.1037/a0022639
   Maddox W. T., 2007, RES PROGR ALZHEIMERS, V3, P2
   Maddox WT, 2014, BILING-LANG COGN, V17, P709, DOI 10.1017/S1366728913000783
   Maddox WT, 2013, PSYCHOL AGING, V28, P1042, DOI 10.1037/a0034969
   Maddox WT, 2004, MEM COGNITION, V32, P582, DOI 10.3758/BF03195849
   Maddox WT, 2004, J EXP PSYCHOL LEARN, V30, P227, DOI 10.1037/0278-7393.30.1.227
   Miles SJ, 2014, ATTEN PERCEPT PSYCHO, V76, P1318, DOI 10.3758/s13414-014-0657-8
   Miles SJ, 2011, J EXP PSYCHOL LEARN, V37, P588, DOI 10.1037/a0022309
   Minda J. P, 2009, P 31 ANN C COGN SCI, P1518
   Minda JP, 2008, J EXP PSYCHOL LEARN, V34, P1518, DOI 10.1037/a0013355
   Miyake A, 1998, FOREIGN LANGUAGE LEARNING, P339
   NELSON DGK, 1984, J VERB LEARN VERB BE, V23, P734
   Newell BR, 2013, PSYCHOL SCI, V24, P386, DOI 10.1177/0956797612457387
   Newell BR, 2011, PSYCHOL LEARN MOTIV, V54, P167, DOI 10.1016/B978-0-12-385527-5.00006-1
   Newell BR, 2010, MEM COGNITION, V38, P563, DOI 10.3758/MC.38.5.563
   Nittrouer S, 2004, J ACOUST SOC AM, V115, P1777, DOI 10.1121/1.1651192
   Nittrouer S., 1993, J ACOUST SOC AM, V94, pS1865
   Nomura EM, 2007, CEREB CORTEX, V17, P37, DOI 10.1093/cercor/bhj122
   Plebanek DJ, 2017, PSYCHOL SCI, V28, P723, DOI 10.1177/0956797617693005
   Rabi R, 2017, PSYCHOL AGING, V32, P654, DOI 10.1037/pag0000190
   Rabi R, 2015, J EXP CHILD PSYCHOL, V131, P149, DOI 10.1016/j.jecp.2014.10.007
   Reetzke R, 2016, J EXP CHILD PSYCHOL, V142, P48, DOI 10.1016/j.jecp.2015.09.018
   Roark CL, 2018, ATTEN PERCEPT PSYCHO, V80, P1804, DOI 10.3758/s13414-018-1552-5
   ROARK CL, 2019, ATTEN PERCEPT PSYCHO, V81, P912, DOI DOI 10.3758/S13414-019-01688-6
   Scharinger M, 2013, MEM COGNITION, V41, P752, DOI 10.3758/s13421-013-0294-9
   Sloutsky VM, 2010, COGNITIVE SCI, V34, P1244, DOI 10.1111/j.1551-6709.2010.01129.x
   SMITH LB, 1978, COGNITIVE PSYCHOL, V10, P502, DOI 10.1016/0010-0285(78)90009-9
   Tharp IJ, 2009, COGNITION, V111, P410, DOI 10.1016/j.cognition.2008.10.003
   Tricomi E, 2008, NEUROIMAGE, V41, P1154, DOI 10.1016/j.neuroimage.2008.02.066
   Waldron EM, 2001, PSYCHON B REV, V8, P168, DOI 10.3758/BF03196154
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Yi HG, 2016, J ACOUST SOC AM, V140, P1332, DOI 10.1121/1.4961163
   Yi HG, 2016, CEREB CORTEX, V26, P1409, DOI 10.1093/cercor/bhu236
   Zeithamova D, 2007, MEM COGNITION, V35, P1380, DOI 10.3758/BF03193609
   Zeithamova D, 2006, MEM COGNITION, V34, P387, DOI 10.3758/BF03193416
   Zevin JD, 2012, DEV PSYCHOBIOL, V54, P632, DOI 10.1002/dev.20611
NR 66
TC 0
Z9 0
U1 1
U2 9
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0022-0965
EI 1096-0457
J9 J EXP CHILD PSYCHOL
JI J. Exp. Child Psychol.
PD DEC
PY 2019
VL 188
AR 104673
DI 10.1016/j.jecp.2019.104673
PG 16
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA JE4HK
UT WOS:000490654000007
PM 31430573
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Cabrera, L
   Bijeljac-Babic, R
   Bertoncini, J
AF Cabrera, Laurianne
   Bijeljac-Babic, Ranka
   Bertoncini, Josiane
TI The development of consonant and lexical-tone discrimination between 3
   and 6 years: Effect of language exposure
SO INTERNATIONAL JOURNAL OF BILINGUALISM
LA English
DT Article
DE Lexical tones; consonants; childhood; bilinguals; discrimination
ID FINE-STRUCTURE CUES; LINGUISTIC EXPERIENCE; PHONETIC PERCEPTION;
   SPEECH-PERCEPTION; 1ST YEAR; INFANTS; FRENCH; VOWEL; CHILDHOOD; CHINESE
AB Aims and objectives: The present study explored children's discrimination capacities for lexical tones and consonants between 3 and 6 years of age and the effect of native language on this ability. Recent studies in infants have shown a perceptual rebound for non-native listeners during the second year of life, but only for lexical tones. However, the later stages of development, and particularly when children start pre-school, are yet not clear. Design: Discrimination abilities of 134 children were measured in three age groups between 3 and 6 years using a behavioural task where children detected a change in lexical tones or consonants. Children were either French monolinguals, French bilinguals exposed to an Asian tone language or French bilinguals exposed to a second non-tone language at home. Data and analysis: Overall, results indicated that higher detection scores for consonants were observed from 4 to 5 years, while for lexical tones the highest scores were observed only at 5-6 years. Moreover, bilingual children exposed to an Asian tone language had higher scores for tones compared to monolingual French children. Interestingly, both bilingual groups, whether exposed to an Asian tone language or to a non-tone language, had better scores for tones than for French consonants, while monolinguals performed equally with both. Conclusions: Language exposure from an early age influences phonological development and bilingualism seems to enhance the perception of prosodic information. Originality: This study is the first to show a different developmental trajectory for consonant and lexical-tone discrimination between 3 and 6 years according to the native language.
C1 [Cabrera, Laurianne] UCL, Speech Hearing & Phonet Sci Dept, London, England.
   [Cabrera, Laurianne; Bijeljac-Babic, Ranka; Bertoncini, Josiane] Univ Paris 05, CNRS, Lab Psychol Percept, Paris, France.
   [Bijeljac-Babic, Ranka] Univ Poitiers, Poitiers, France.
RP Cabrera, L (corresponding author), Univ Paris 05, Lab Psychol Percept, 45 Rue St Peres, F-75006 Paris, France.
EM laurianne.cabrera@parisdescartes.fr
FU Agence Nationale de la RechercheFrench National Research Agency
   (ANR)European Commission [ANR-12-ISH2-0001-01]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: JB was
   supported by the Agence Nationale de la Recherche (ANR-12-ISH2-0001-01).
CR Abboub N, 2015, J EXP CHILD PSYCHOL, V132, P111, DOI 10.1016/j.jecp.2014.12.004
   Bent T, 2006, J EXP PSYCHOL HUMAN, V32, P97, DOI 10.1037/0096-1523.32.1.97
   BERTELSON P, 1989, EUROPEAN J COGNITIVE, V1, P239, DOI DOI 10.1080/09541448908403083
   Bertoncini J, 2009, J SPEECH LANG HEAR R, V52, P682, DOI 10.1044/1092-4388(2008/07-0273)
   Bijeljac-Babic R, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030843
   Burnham D, 2007, LANGUAGE EXPERIENCE, P259
   Burnham D., 1997, SE ASIAN LINGUISTIC, P29
   Burnham D, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02190
   Burnham D, 2011, J EXP CHILD PSYCHOL, V108, P693, DOI 10.1016/j.jecp.2010.07.008
   Burns TC, 2007, APPL PSYCHOLINGUIST, V28, P455, DOI 10.1017/S0142716407070257
   Cabrera L, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01290
   Cabrera L, 2014, J ACOUST SOC AM, V136, P877, DOI 10.1121/1.4887444
   Caramazza A., 1974, J PHONETICS, V2, P245
   Cho T, 1999, J PHONETICS, V27, P207, DOI 10.1006/jpho.1999.0094
   Collier R., 1975, STRUCTURE PROCESS SP, P107
   Eisenberg LS, 2004, INT CONGR SER, V1273, P364, DOI 10.1016/j.ics.2004.09.001
   GANDOUR J, 1981, J CHINESE LINGUIST, V9, P20
   GANDOUR JT, 1978, LANG SPEECH, V21, P1, DOI 10.1177/002383097802100101
   Grosjean Francois, 2010, BILINGUAL LIFE REALI
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Holt RF, 2012, INT J PEDIATR OTORHI, V76, P680, DOI 10.1016/j.ijporl.2012.02.020
   Khouw E, 2007, J PHONETICS, V35, P104, DOI 10.1016/j.wocn.2005.10.003
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Liu HM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095587
   Liu LQ, 2017, BILING-LANG COGN, V20, P561, DOI 10.1017/S1366728916000183
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Martinez A, 2008, OTOL NEUROTOL, V29, P183, DOI 10.1097/MAO.0b013e3181625114
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Nazzi T, 2016, CURR DIR PSYCHOL SCI, V25, P291, DOI 10.1177/0963721416655786
   Nooteboom S., 1997, HDB PHONETIC SCI, P640, DOI 10.1017/S0142716412000690
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   RYALLS J, 1992, J SPEECH HEAR RES, V35, P88, DOI 10.1044/jshr.3501.88
   Serniclaes W., 1987, THESIS
   Singh L, 2015, COGNITION, V142, P1, DOI 10.1016/j.cognition.2015.05.010
   Singh L, 2014, DEVELOPMENTAL SCI, V17, P94, DOI 10.1111/desc.12097
   Skoruppa K, 2009, DEVELOPMENTAL SCI, V12, P914, DOI 10.1111/j.1467-7687.2009.00835.x
   Sundara M, 2008, COGNITION, V108, P232, DOI 10.1016/j.cognition.2007.12.013
   VANCE TJ, 1976, PHONETICA, V33, P368, DOI 10.1159/000259793
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1983, CAN J PSYCHOL, V37, P278, DOI 10.1037/h0080725
   Yeung H. H., 2012, J MEM LANG, V68, P123
   Zhang S.M., 2012, THESIS
NR 45
TC 0
Z9 0
U1 0
U2 23
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1367-0069
EI 1756-6878
J9 INT J BILINGUAL
JI Int. J. Biling.
PD DEC
PY 2019
VL 23
IS 6
BP 1249
EP 1263
DI 10.1177/1367006918781077
PG 15
WC Linguistics; Language & Linguistics
SC Linguistics
GA IW9EQ
UT WOS:000485296700002
DA 2021-02-24
ER

PT J
AU Tsukada, K
   Kondo, M
AF Tsukada, Kimiko
   Kondo, Mariko
TI The Perception of Mandarin Lexical Tones by Native Speakers of Burmese
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Cross-language speech perception; phonation; Mandarin lexical tones;
   Burmese listeners; Australian English listeners
ID CATEGORICAL PERCEPTION; LANGUAGE EXPERIENCE; MUSICAL EXPERIENCE; CHINESE
   TONES; CANTONESE; ENGLISH; IDENTIFICATION; LISTENERS; LEARNERS; THAI
AB This study examines the perception of Mandarin lexical tones by native speakers of Burmese who use lexical tones in their first language (L1) but are naive to Mandarin. Unlike Mandarin tones, which are primarily cued by pitch, Burmese tones are cued by phonation type as well as pitch. The question of interest is whether Burmese listeners can utilize their L1 experience in processing unfamiliar Mandarin tones. Burmese listeners' discrimination accuracy was compared with that of Mandarin listeners and Australian English listeners. The Australian English group was included as a control group with a non-tonal background. Accuracy of perception of six tone pairs (T1-T2, T1-T3, T1-T4, T2-T3, T2-T4, T3-T4) was assessed in a discrimination test. Our main findings are 1) Mandarin listeners were more accurate than non-native listeners in discriminating all tone pairs, 2) Australian English listeners naive to Mandarin were more accurate than similarly naive Burmese listeners in discriminating all tone pairs except for T2-T4, and 3) Burmese listeners had the greatest trouble discriminating T2-T3 and T1-T2. Taken together, the results suggest that merely possessing lexical tones in L1 may not necessarily facilitate the perception of non-native tones, and that the active use of phonation type in encoding L1 tones may have played a role in Burmese listeners' less than optimal perception of Mandarin tones.
C1 [Tsukada, Kimiko] Macquarie Univ, Sydney, NSW 2109, Australia.
   [Kondo, Mariko] Waseda Univ, Tokyo, Japan.
RP Tsukada, K (corresponding author), Macquarie Univ, Sydney, NSW 2109, Australia.
EM kimiko.tsukada@gmail.com
OI Tsukada, Kimiko/0000-0001-6365-3322
FU 11th Hakuho Foundation Japanese Research Fellowship (2016-2017); 2018
   Endeavour Research Fellowship
FX This research was supported by the 11th Hakuho Foundation Japanese
   Research Fellowship (2016-2017) and the 2018 Endeavour Research
   Fellowship awarded to the first author.
CR Best C., 1995, SPEECH PERCEPTION LI, P171
   BLICHER DL, 1990, J PHONETICS, V18, P37, DOI 10.1016/S0095-4470(19)30357-2
   Bradley David, 1982, PAPERS SE ASIAN LING, V8, P117
   Brunelle M, 2016, LANG LINGUIST COMPAS, V10, P191, DOI 10.1111/lnc3.12182
   Burnham D., 2015, APPL PSYCHOLINGUIST, V36, P1459, DOI [10.1017/S0142716414000496, DOI 10.1017/S0142716414000496]
   CHANG CB, 2009, J SE ASIAN LINGUISTI, V1, P77
   Chang Charles, 2016, HERITAGE LANGUAGE J, V13, P134
   Chuang C. K., 1975, J ACOUSTICAL SOC JAP, V31, P369
   Cooper A, 2012, J ACOUST SOC AM, V131, P4756, DOI 10.1121/1.4714355
   Ding HW, 2011, ARCH ACOUST, V36, P509, DOI 10.2478/v10168-011-0036-6
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2007, LAB PHONOLOGY, P353
   Flege J. E., 2003, ISSUES CLIN LINGUIST, P19
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   Francis AL, 2008, J PHONETICS, V36, P268, DOI 10.1016/j.wocn.2007.06.005
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   Gandour J. T., 1978, TONE LINGUISTIC SURV, P41, DOI DOI 10.1016/B978-0-12-267350-4.50007-8
   Gao M, 2016, LINKOPING ELECT C P, V130, P33
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Hao YC, 2018, LANG SPEECH, V61, P135, DOI 10.1177/0023830917717759
   Hao YC, 2012, J PHONETICS, V40, P269, DOI 10.1016/j.wocn.2011.11.001
   Huang T, 2010, PHONETICA, V67, P243, DOI 10.1159/000327392
   Justin Watkins, 2001, J INT PHON ASSOC, V31, P291, DOI DOI 10.1017/S0025100301002122
   Khouw E, 2007, J PHONETICS, V35, P104, DOI 10.1016/j.wocn.2005.10.003
   KIRILOFF C, 1969, PHONETICA, V20, P63, DOI 10.1159/000259274
   LEATHER J, 1987, SOUND PATTERNS 2 LAN, P59
   Lee CY, 2008, J ACOUST SOC AM, V124, P3235, DOI 10.1121/1.2990713
   Lee YS, 1996, J PSYCHOLINGUIST RES, V25, P527, DOI 10.1007/BF01758181
   Li B, 2017, J PSYCHOLINGUIST RES, V46, P107, DOI 10.1007/s10936-016-9422-6
   Li M, 2017, STUD SECOND LANG ACQ, V39, P593, DOI 10.1017/S0272263116000358
   Li Y, 2016, ENGLISH LANGUAGE TEA, V9, P122, DOI [10.5539/elt.v9n1p122, DOI 10.5539/ELT.V9N1P122]
   Lin W. C. J., 1985, RELC J, V16, P31
   Liu SY, 2004, LANG SPEECH, V47, P109, DOI 10.1177/00238309040470020101
   Pelzl E, 2019, STUD SECOND LANG ACQ, V41, P59, DOI 10.1017/S0272263117000444
   Peng G, 2010, J PHONETICS, V38, P616, DOI 10.1016/j.wocn.2010.09.003
   Reid A, 2015, ATTEN PERCEPT PSYCHO, V77, P571, DOI 10.3758/s13414-014-0791-3
   Shen GN, 2016, J ACOUST SOC AM, V140, P4396, DOI 10.1121/1.4971765
   SHEN XNS, 1991, LANG SPEECH, V34, P145, DOI 10.1177/002383099103400202
   Smith S., 1997, USER MANUAL UAB SOFT
   Snodgrass J. G., 1985, HUMAN EXPT PSYCHOL
   So CK, 2010, LANG SPEECH, V53, P273, DOI 10.1177/0023830909357156
   STRANGE W, 1995, SPEECH PERCEPTION LI
   Strange W., 2008, PHONOLOGY 2 LANGUAGE, P153
   Thein Tun, 1982, PAPERS SE ASIAN LING, P77
   Tsukada  K., 2016, J 2 LANGUAGE PRONUNC, V2, P225, DOI DOI 10.1075/jslp.2.2.05tsu
   Tsukada  K., 2015, CHINESE 2 LANGUAGE R, V4, P141, DOI [10.1515/caslar-2015-0009, DOI 10.1515/CASLAR-2015-0009]
   Tsukada K, 2019, SECOND LANG RES, V35, P305, DOI 10.1177/0267658318775155
   WANG WSY, 1967, J SPEECH HEAR RES, V10, P629, DOI 10.1044/jshr.1003.629
   Wang XC, 2013, MOD LANG J, V97, P144, DOI 10.1111/j.1540-4781.2013.01386.x
   Wang Y, 1999, J ACOUST SOC AM, V106, P3649, DOI 10.1121/1.428217
   Wang Y, 2006, HANDBOOK OF EAST ASIAN PSYCHOLINGUISTICS, VOL 1: CHINESE, P250
   Watkins Justin, 2003, P 15 INT C PHON SCI, P1289
   Wayland R, 2003, APPL PSYCHOLINGUIST, V24, P113, DOI 10.1017/S0142716403000067
   Wayland RP, 2004, LANG LEARN, V54, P681, DOI 10.1111/j.1467-9922.2004.00283.x
   WHALEN DH, 1992, PHONETICA, V49, P25, DOI 10.1159/000261901
   Wheatley J. K., 2009, WORLDS MAJOR LANGUAG, P724
   Wong P, 2013, J ACOUST SOC AM, V133, P3649
   Wong PS, 2005, J SPEECH LANG HEAR R, V48, P1065, DOI 10.1044/1092-4388(2005/074)
   Wu XH, 2014, J PHONETICS, V46, P86, DOI 10.1016/j.wocn.2014.06.005
   Wu XH, 2012, APPL PSYCHOLINGUIST, V33, P623, DOI 10.1017/S0142716411000506
   Xu Y, 1997, J PHONETICS, V25, P61, DOI 10.1006/jpho.1996.0034
   YANG C, 2010, J CHINESE LANG TEACH, V45, P7
   Yang RX, 2015, J CHINESE LINGUIST, V43, P453, DOI 10.1353/jcl.2015.0035
   Zhang H, 2016, SECOND LANG RES, V32, DOI 10.1177/0267658316644293
   Zhao TC, 2015, J ACOUST SOC AM, V137, P1452, DOI 10.1121/1.4913457
NR 65
TC 2
Z9 2
U1 2
U2 18
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD DEC
PY 2019
VL 62
IS 4
BP 625
EP 640
DI 10.1177/0023830918806550
PG 16
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA IW9AZ
UT WOS:000485287000001
PM 30343621
DA 2021-02-24
ER

PT J
AU Baigorri, M
   Campanelli, L
   Levy, ES
AF Baigorri, Miriam
   Campanelli, Luca
   Levy, Erika S.
TI Perception of American-English Vowels by Early and Late Spanish-English
   Bilinguals
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Vowel perception; second language acquisition; bilingualism;
   American-English; Spanish
ID SPEECH-PERCEPTION; INTERLINGUAL IDENTIFICATION; LISTENERS PERCEPTION;
   LANGUAGE EXPERIENCE; NORMAL-HEARING; FRENCH; INTELLIGIBILITY; SPEAKERS;
   ASSIMILATION; ACQUISITION
AB Increasing numbers of Hispanic immigrants are entering the US and learning American-English (AE) as a second language (L2). Previous studies investigating the relationship between AE and Spanish vowels have revealed an advantage for early L2 learners for their accuracy of L2 vowel perception. Replicating and extending such previous research, this study examined the patterns with which early and late Spanish-English bilingual adults assimilated naturally-produced AE vowels to their native vowel inventory and the accuracy with which they discriminated the vowels. Twelve early Spanish-English bilingual, 12 late Spanish-English bilingual, and 10 monolingual listeners performed perceptual-assimilation and categorical-discrimination tasks involving AE /i,?,e,,AE,,o/. Early bilinguals demonstrated similar assimilation patterns to late bilinguals. Late bilinguals' discrimination was less accurate than early bilinguals' and AE monolinguals'. Certain contrasts, such as /AE-/, /-/, and /-AE/, were particularly difficult to discriminate for both bilingual groups. Consistent with previous research, findings suggest that early L2 learning heightens Spanish-English bilinguals' ability to perceive cross-language phonetic differences. However, even early bilinguals' native-vowel system continues to influence their L2 perception.
C1 [Baigorri, Miriam] Long Isl Univ, Brooklyn, NY USA.
   [Campanelli, Luca] CUNY, Grad Ctr, New York, NY USA.
   [Campanelli, Luca] Haskins Labs Inc, New Haven, CT USA.
   [Levy, Erika S.] Columbia Univ, Teachers Coll, New York, NY 10027 USA.
RP Baigorri, M (corresponding author), Long Isl Univ Brooklyn, Dept Commun Sci & Disorders, M242,1 Univ Plaza, Brooklyn, NY 11201 USA.
EM Miriam.baigorri@liu.edu
OI Campanelli, Luca/0000-0001-6035-0545
FU NICHD NIH HHSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R01 HD073288]
   Funding Source: Medline; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF
   CHILD HEALTH & HUMAN DEVELOPMENTUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH Eunice
   Kennedy Shriver National Institute of Child Health & Human Development
   (NICHD) [R01HD073288, R01HD073288] Funding Source: NIH RePORTER
CR Adachi T, 2006, ACOUST SCI TECHNOL, V27, P285, DOI 10.1250/ast.27.285
   Agha A, 2003, LANG COMMUN, V23, P231, DOI 10.1016/S0271-5309(03)00012-0
   Archila-Suerte P, 2012, BILING-LANG COGN, V15, P190, DOI 10.1017/S1366728911000125
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   BOHN OS, 1990, APPL PSYCHOLINGUIST, V11, P303, DOI 10.1017/S0142716400008912
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   BRADLOW AR, 1995, J ACOUST SOC AM, V97, P1916, DOI 10.1121/1.412064
   Broersma M, 2010, SPEECH COMMUN, V52, P980, DOI 10.1016/j.specom.2010.08.010
   Chladkova K, 2011, J ACOUST SOC AM, V130, pEL186, DOI 10.1121/1.3629135
   Escudero P, 2004, STUD SECOND LANG ACQ, V26, P551, DOI 10.1017/S0272226310400021
   Escudero P, 2014, J ACOUST SOC AM, V135, P1577, DOI 10.1121/1.4864477
   Escudero P, 2010, J ACOUST SOC AM, V128, pEL254, DOI 10.1121/1.3488794
   Ferguson SH, 2012, J SPEECH LANG HEAR R, V55, P779, DOI 10.1044/1092-4388(2011/10-0342)
   Flege JE, 2004, STUD SECOND LANG ACQ, V26, P1, DOI 10.1017/S0272263104261010
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   Flege JE, 2003, SPEECH COMMUN, V40, P467, DOI 10.1016/S0167-6393(02)00128-0
   FLEGE JE, 1994, J ACOUST SOC AM, V95, P3623, DOI 10.1121/1.409931
   FLEGE JE, 1991, Q J EXP PSYCHOL-A, V43, P701, DOI 10.1080/14640749108400993
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   Flege JE, 1988, HUMAN COMMUNICATION, P224
   FOX RA, 1995, J ACOUST SOC AM, V97, P2540, DOI 10.1121/1.411974
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   GOTTFRIED TL, 1984, J PHONETICS, V12, P91, DOI 10.1016/S0095-4470(19)30858-7
   Iverson P, 2007, J ACOUST SOC AM, V122, P2842, DOI 10.1121/1.2783198
   Iverson P, 2009, J ACOUST SOC AM, V126, P866, DOI 10.1121/1.3148196
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Jia G, 2006, J ACOUST SOC AM, V119, P1118, DOI 10.1121/1.2151806
   JOHNSON JS, 1989, COGNITIVE PSYCHOL, V21, P60, DOI 10.1016/0010-0285(89)90003-0
   KANGAS KA, 1990, J SPEECH HEAR DISORD, V55, P751, DOI 10.1044/jshd.5504.751
   Kewley-Port D, 2007, J ACOUST SOC AM, V122, P2365, DOI 10.1121/1.2773986
   Levy E. S., 2009, J ACOUST SOC AM, V125, P2772
   Levy E. S., 2010, AM SPEECH LANG HEAR
   Levy ES, 2008, J PHONETICS, V36, P141, DOI 10.1016/j.wocn.2007.03.001
   Levy ES, 2009, J ACOUST SOC AM, V126, P2670, DOI 10.1121/1.3224715
   Levy ES, 2009, J ACOUST SOC AM, V125, P1138, DOI 10.1121/1.3050256
   Long M., 1990, STUDIES 2 LANGUAGE A, V12, P251, DOI DOI 10.1017/S0272263100009165
   MACK M, 1989, PERCEPT PSYCHOPHYS, V46, P187, DOI 10.3758/BF03204982
   McAllister R, 2002, J PHONETICS, V30, P229, DOI 10.1006/jpho.2002.0174
   Morrison Geoffrey Stewart, 2008, Canadian Acoustics, V36, P17
   Morrison G. S., 2007, P 16 INT C PHON SCI, P1505
   Morrison GS, 2002, P N W LING C 2002, P29
   NEUMAN AC, 1983, J ACOUST SOC AM, V73, P2145, DOI 10.1121/1.389538
   Pallier C, 1997, COGNITION, V64, pB9, DOI 10.1016/S0010-0277(97)00030-9
   Piske T, 2002, PHONETICA, V59, P49, DOI 10.1159/000056205
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Fabra LR, 2012, J PHONETICS, V40, P491, DOI 10.1016/j.wocn.2012.01.001
   Rogers CL, 2006, APPL PSYCHOLINGUIST, V27, P465, DOI 10.1017/S014271640606036X
   Sebastian-Galles N, 1999, COGNITION, V72, P111, DOI 10.1016/S0010-0277(99)00024-4
   Shi LF, 2010, J SPEECH LANG HEAR R, V53, P821, DOI 10.1044/1092-4388(2010/09-0081)
   StataCorp, 2013, STATA STAT SOFTW REL
   Strange W, 2007, J ACOUST SOC AM, V122, P1111, DOI 10.1121/1.2749716
   Tagliaferri B., 2011, PARADIGM VERSION 1 0
   Ueda K., 2002, Acoustical Science and Technology, V23, P336, DOI 10.1250/ast.23.336
   *US BUR CENS, 2006, US HISP POP 2006
   von Hapsburg Deborah, 2004, J Am Acad Audiol, V15, P88, DOI 10.3766/jaaa.15.1.9
NR 56
TC 0
Z9 0
U1 2
U2 23
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD DEC
PY 2019
VL 62
IS 4
BP 681
EP 700
DI 10.1177/0023830918806933
PG 20
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA IW9AZ
UT WOS:000485287000004
PM 30354920
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Ortega-Llebaria, M
   Olson, DJ
   Tuninetti, A
AF Ortega-Llebaria, Marta
   Olson, Daniel J.
   Tuninetti, Alba
TI Explaining Cross-Language Asymmetries in Prosodic Processing: The
   Cue-Driven Window Length Hypothesis
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Speech perception; intonation; vowel reduction; English; Spanish
ID LEXICAL STRESS; SELECTIVE ATTENTION; SPOKEN LANGUAGE; SPEECH;
   INFORMATION; PERCEPTION; ENGLISH; INTEGRATION; DURATION; MEMORY
AB Cross-language studies have shown that English speakers use suprasegmental cues to lexical stress less consistently than speakers of Spanish and other Germanic languages ; accordingly, these studies have attributed this asymmetry to a possible trade-off between the use of vowel reduction and suprasegmental cues in lexical access. We put forward the hypothesis that this "cue trade-off" modulates intonation processing as well, so that English speakers make less use of suprasegmental cues in comparison to Spanish speakers when processing intonation in utterances causing processing asymmetries between these two languages. In three cross-language experiments comparing English and Spanish speakers' prediction of hypo-articulated utterances in focal sentences and reporting speech, we have provided evidence for our hypothesis and proposed a mechanism, the Cue-Driven Window Length model, which accounts for the observed cross-language processing asymmetries between English and Spanish at both lexical and utterance levels. Altogether, results from these experiments illustrated in detail how different types of low-level acoustic information (e.g., vowel reduction versus duration) interacted with higher-level expectations based on the speakers' knowledge of intonation providing support for our hypothesis. These interactions were coherent with an active model of speech perception that entailed real-time adjusting to feedback and to information from the context, challenging more traditional models that consider speech perception as a passive, bottom-up pattern-matching process.
C1 [Ortega-Llebaria, Marta] Univ Pittsburgh, 2816 Cathedral Learning, Pittsburgh, PA 15261 USA.
   [Olson, Daniel J.] Purdue Univ, W Lafayette, IN 47907 USA.
   [Tuninetti, Alba] Western Sydney Univ, Penrith, NSW, Australia.
   [Tuninetti, Alba] ARC Ctr Excellence Dynam Language, Acton, Australia.
RP Ortega-Llebaria, M (corresponding author), Univ Pittsburgh, 2816 Cathedral Learning, Pittsburgh, PA 15261 USA.
EM m.ortega.llebaria@gmail.com
OI Ortega-Llebaria, Marta/0000-0003-1637-3541; Olson,
   Daniel/0000-0002-7113-6699; Tuninetti, Alba/0000-0002-0087-7756
FU Central Research Development Fund Grant, University of Pittsburgh;
   Research Grant Competition, College of Liberal Arts, University of Texas
FX This work was supported by the Central Research Development Fund Grant,
   University of Pittsburgh and the Research Grant Competition, College of
   Liberal Arts, University of Texas awarded to the first author.
CR Bates D., 2014, R PACKAGE VERSION LME4 LINEAR MIXED EF LME4 LINEAR MIXED EF, DOI DOI 10.18637/JSS.V067.I01
   Beckman M. E., 1994, PHONOLOGICAL STRUCTU, P7, DOI DOI 10.1017/CBO9780511659461.002
   Beckman ME, 1986, STRESS NON STRESS AC
   Boersma P., 2012, DOING PHONETICS COMP, P52
   CANELLADA M. J., 1987, PRONUNCIACION ESPANO
   Cooper N, 2002, LANG SPEECH, V45, P207, DOI 10.1177/00238309020450030101
   Cutler A, 1997, LANG SPEECH, V40, P141, DOI 10.1177/002383099704000203
   CUTLER A, 1986, LANG SPEECH, V29, P201, DOI 10.1177/002383098602900302
   Cutler A, 2012, NATIVE LISTENING LAN
   Cutler A, 2005, BLACKW HBK LINGUIST, P264, DOI 10.1002/9780470757024.ch11
   Vanrell MDM, 2013, CATALAN J LINGUIST, V12, P253
   DELATTRE P, 1966, IRAL-INT REV APPL LI, V4, P183, DOI 10.1515/iral.1966.4.1-4.183
   Delforge Ann Marie, 2008, SEL P 3 C LAB APPR S, P107
   DEMANRIQUE AMB, 1983, J PHONETICS, V11, P117, DOI 10.1016/S0095-4470(19)30810-1
   Escera C, 2014, BRAIN TOPOGR, V27, P527, DOI 10.1007/s10548-013-0328-4
   Fant G., 1967, SPEECH TRANSMISSION, V8, P1
   Flege J. E., 1989, STUDIES 2 LANGUAGE A, V11, P35, DOI DOI 10.1017/S0272263100007828
   FRY DB, 1955, J ACOUST SOC AM, V27, P765, DOI 10.1121/1.1908022
   FRY DB, 1958, LANG SPEECH, V1, P126, DOI 10.1177/002383095800100207
   GALBRAITH GC, 1993, BIOL PSYCHOL, V37, P3, DOI 10.1016/0301-0511(93)90024-3
   GIARD MH, 1994, BRAIN RES, V633, P353, DOI 10.1016/0006-8993(94)91561-X
   Heald SLM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00035
   Hualde Jose Ignacio, 2005, SOUNDS SPANISH
   HUSS V, 1978, PHONETICA, V35, P86, DOI 10.1159/000259924
   JOLIOT M, 1994, P NATL ACAD SCI USA, V91, P11748, DOI 10.1073/pnas.91.24.11748
   Jusczyk P.W., 2000, DISCOVERY SPOKEN LAN
   Kilborn K, 1996, LANG COGNITIVE PROC, V11, P689
   Kubanek J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053398
   Ladd DR, 2008, CAMB STUD LINGUIST, V79, P1
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   LINDBLOM B, 1990, NATO ADV SCI I D-BEH, V55, P403
   Lipski John M., 1990, HISPANIC LINGUISTICS, V4, P1
   Marinis T, 2010, LANG LEARN LANG TEAC, V27, P139
   MARSLENWILSON W, 1980, COGNITION, V8, P1, DOI 10.1016/0010-0277(80)90015-3
   MASSARO DW, 1984, ANN NY ACAD SCI, V423, P372, DOI 10.1111/j.1749-6632.1984.tb23445.x
   MCCLELLAND JL, 1985, J EXP PSYCHOL GEN, V114, P159, DOI 10.1037/0096-3445.114.2.159
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   Mirman D, 2017, CUR ISS PSYCHOL LANG, P97
   Naatanen R, 1992, ATTENTION BRAIN FUNC
   Nadeu Marianna, 2013, THESIS
   Navarro-Tomas T., 1974, MANUAL PRONUNCIACION
   Navarro-Tomas T., 1974, MANUAL ENTONACION ES, V175
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Nusbaum N. S., 1992, AUDITORY PROCESSING, P339
   Ortega-Llebaria M, 2013, J PHONETICS, V41, P186, DOI 10.1016/j.wocn.2013.01.006
   Ortega-Llebaria Marta, 2006, SEL P 2 C LAB APPR S, P104
   Pierrehumbert J., 1980, THESIS
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   Poeppel D, 2011, LANG COGNITIVE PROC, V26, P935, DOI 10.1080/01690965.2010.493301
   Quene H, 1998, LANG SPEECH, V41, P185, DOI 10.1177/002383099804100203
   Ramus F, 1999, COGNITION, V73, P265, DOI 10.1016/S0010-0277(99)00058-X
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   SEIDENBERG MS, 1989, PSYCHOL REV, V96, P523, DOI 10.1037/0033-295X.96.4.523
   SINGER W, 1993, ANNU REV PHYSIOL, V55, P349, DOI 10.1146/annurev.ph.55.030193.002025
   Soto-Faraco S, 2001, J MEM LANG, V45, P412, DOI 10.1006/jmla.2000.2783
   Stevens K., 1967, MODELS PERCEPTION SP, P88
   Torreira F., 2014, P 7 INT C SPEECH PRO, P197
   Tyler MD, 2009, J ACOUST SOC AM, V126, P367, DOI 10.1121/1.3129127
   van Donselaar W, 2005, Q J EXP PSYCHOL-A, V58, P251, DOI 10.1080/02724980343000927
   VIEMEISTER NF, 1991, J ACOUST SOC AM, V90, P858, DOI 10.1121/1.401953
   White L., 2007, SEGMENTAL PROSODIC I, P237
   Yabe H, 1997, NEUROREPORT, V8, P1971, DOI 10.1097/00001756-199705260-00035
   Zubizarreta Maria Luisa, 1998, PROSODY FOCUS WORD O
NR 63
TC 0
Z9 0
U1 0
U2 6
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD DEC
PY 2019
VL 62
IS 4
BP 701
EP 736
DI 10.1177/0023830918808823
PG 36
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA IW9AZ
UT WOS:000485287000005
PM 30444184
DA 2021-02-24
ER

PT J
AU Guediche, S
   Zhu, YL
   Minicucci, D
   Blumstein, SE
AF Guediche, Sara
   Zhu, Yuli
   Minicucci, Domenic
   Blumstein, Sheila E.
TI Written sentence context effects on acoustic-phonetic perception: fMRI
   reveals cross-modal semantic-perceptual interactions
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Semantic context; Speech perception; Crossmodal integration; Functional
   magnetic resonance imaging
ID TEMPORAL CORTEX; SPOKEN LANGUAGE; DEGRADED SPEECH; DUAL-ROUTE;
   INFORMATION; INTEGRATION; WORDS; CATEGORIZATION; COMPREHENSION;
   RECOGNITION
AB This study examines cross-modality effects of a semantically-biased written sentence context on the perception of an acoustically-ambiguous word target identifying neural areas sensitive to interactions between sentential bias and phonetic ambiguity. Of interest is whether the locus or nature of the interactions resembles those previously demonstrated for auditory-only effects. FMRI results show significant interaction effects in right mid-middle temporal gyrus (RmMTG) and bilateral anterior superior temporal gyri (aSTG), regions along the ventral language comprehension stream that map sound onto meaning. These regions are more anterior than those previously identified for auditory-only effects; however, the same cross-over interaction pattern emerged implying similar underlying computations at play. The findings suggest that the mechanisms that integrate information across modality and across sentence and phonetic levels of processing recruit amodal areas where reading and spoken lexical and semantic access converge. Taken together, results support interactive accounts of speech and language processing.
C1 [Guediche, Sara; Minicucci, Domenic; Blumstein, Sheila E.] Brown Univ, Dept Cognit Linguist & Psychol Sci, Providence, RI 02912 USA.
   [Zhu, Yuli] Brown Univ, Neurosci Dept, Providence, RI 02912 USA.
   [Blumstein, Sheila E.] Brown Univ, Brown Inst Brain Sci, Providence, RI 02912 USA.
   [Guediche, Sara] BCBL Basque Ctr Cognit Brain & Language, Donostia San Sebastian, Spain.
   [Zhu, Yuli] NYU Langone Med Ctr, New York, NY USA.
   [Minicucci, Domenic] Massachusetts Gen Hosp, Athinoula A Martinos Ctr Biomed Imaging, Boston, MA 02114 USA.
RP Guediche, S (corresponding author), BCBL Basque Ctr Cognit Brain & Language, San Sebastian, Spain.
EM s.guediche@bcbl.eu
RI Guediche, Sara/B-3895-2017
OI Guediche, Sara/0000-0002-8331-1378
FU National Institutes of Health, NIDCDUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute on Deafness & Other Communication Disorders (NIDCD) [RO1
   DC006220]
FX This work was supported in part by the National Institutes of Health,
   NIDCD grant RO1 DC006220. The authors acknowledge the contributions of
   Paul Allopenna, John Mertus, and Efthymia Kapnoula. We would also like
   to thank Ping Li and reviewers Joe Toscano and an anonymous reviewer for
   their thoughtful feedback and comments on the manuscript. The content is
   solely the responsibility of the authors and does not necessarily
   represent the National Institute on Deafness and Other Communication
   Disorders or the National Institutes of Health.
CR Ahissar M, 2004, TRENDS COGN SCI, V8, P457, DOI 10.1016/j.tics.2004.08.011
   Badre D, 2004, NEURON, V41, P473, DOI 10.1016/S0896-6273(03)00851-1
   Bar M, 2006, P NATL ACAD SCI USA, V103, P449, DOI 10.1073/pnas.0507062103
   Bemis DK, 2013, CEREB CORTEX, V23, P1859, DOI 10.1093/cercor/bhs170
   Bertelson P., 1997, AUDIO VISUAL SPEECH
   Binder JR, 2009, CEREB CORTEX, V19, P2767, DOI 10.1093/cercor/bhp055
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   Binder JR, 2005, NEUROIMAGE, V27, P677, DOI 10.1016/j.neuroimage.2005.04.029
   Blumstein SE, 2005, J COGNITIVE NEUROSCI, V17, P1353, DOI 10.1162/0898929054985473
   Bonte M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05356-3
   Borsky S, 1998, J ACOUST SOC AM, V103, P2670, DOI 10.1121/1.422787
   BURTON MW, 1995, J EXP PSYCHOL HUMAN, V21, P1230, DOI 10.1037/0096-1523.21.5.1230
   Carreiras M, 2014, TRENDS COGN SCI, V18, P90, DOI 10.1016/j.tics.2013.11.005
   Chen YY, 2015, J COGNITIVE NEUROSCI, V27, P1738, DOI 10.1162/jocn_a_00815
   Clos M, 2014, HUM BRAIN MAPP, V35, P61, DOI 10.1002/hbm.22151
   Cohen L, 2004, NEUROIMAGE, V23, P1256, DOI 10.1016/j.neuroimage.2004.07.052
   COLTHEART M, 1993, PSYCHOL REV, V100, P589, DOI 10.1037/0033-295X.100.4.589
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   Davis MF, 2011, J OCCUP ENVIRON MED, V53, P190, DOI [10.1097/JOM.0b013e31820805d5, 10.1162/jocn_a_00084]
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Fiez JA, 1998, P NATL ACAD SCI USA, V95, P914, DOI 10.1073/pnas.95.3.914
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   Getz LM, 2019, PSYCHOL SCI, V30, P830, DOI 10.1177/0956797619841813
   Gow DW, 2016, LANG COGN NEUROSCI, V31, P841, DOI 10.1080/23273798.2015.1029498
   Guediche S, 2013, J COGNITIVE NEUROSCI, V25, P706, DOI 10.1162/jocn_a_00351
   Harm MW, 2004, PSYCHOL REV, V111, P662, DOI 10.1037/0033-295X.111.3.662
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Horowitz-Kraus T, 2015, BRAIN IMAGING BEHAV, V9, P19, DOI 10.1007/s11682-014-9341-9
   Jobard G, 2003, NEUROIMAGE, V20, P693, DOI 10.1016/S1053-8119(03)00343-4
   Keetels M, 2016, ATTEN PERCEPT PSYCHO, V78, P938, DOI 10.3758/s13414-015-1034-y
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532
   MacDonald J., 1976, PERCEPT PSYCHOPHYS, V24, P253
   Marinkovic K, 2003, NEURON, V38, P487, DOI 10.1016/S0896-6273(03)00197-1
   MASSARO DW, 1991, COGNITIVE PSYCHOL, V23, P558, DOI 10.1016/0010-0285(91)90006-A
   McQueen JM, 2006, TRENDS COGN SCI, V10, P533, DOI 10.1016/j.tics.2006.10.004
   Molinaro N, 2011, CORTEX, V47, P908, DOI 10.1016/j.cortex.2011.02.019
   MORTON J, 1969, PSYCHOL REV, V76, P165, DOI 10.1037/h0027366
   Myers EB, 2008, CEREB CORTEX, V18, P278, DOI 10.1093/cercor/bhm053
   Nahum M, 2008, PLOS BIOL, V6, P978, DOI 10.1371/journal.pbio.0060126
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   Peelle JE, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00051
   Plaut DC, 1996, PSYCHOL REV, V103, P56, DOI 10.1037/0033-295X.103.1.56
   Preston JL, 2016, PSYCHOL SCI, V27, P75, DOI 10.1177/0956797615611921
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Price CJ, 2011, TRENDS COGN SCI, V15, P246, DOI 10.1016/j.tics.2011.04.001
   Regev M, 2013, J NEUROSCI, V33, P15978, DOI 10.1523/JNEUROSCI.1580-13.2013
   Richardson F. M., 2011, J NEUROSCI, V31, P8349
   Robson H, 2014, BRAIN, V137, P931, DOI 10.1093/brain/awt373
   Rogers JC, 2017, J COGNITIVE NEUROSCI, V29, P919, DOI 10.1162/jocn_a_01096
   Rueckl JG, 2015, P NATL ACAD SCI USA, V112, P15510, DOI 10.1073/pnas.1509321112
   SHIPLEY T, 1964, SCIENCE, V145, P1328, DOI 10.1126/science.145.3638.1328
   Sohoglu E, 2016, P NATL ACAD SCI USA, V113, pE1747, DOI 10.1073/pnas.1523266113
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   Spitsyna G, 2006, J NEUROSCI, V26, P7328, DOI 10.1523/JNEUROSCI.0559-06.2006
   Toscano JC, 2010, PSYCHOL SCI, V21, P1532, DOI 10.1177/0956797610384142
   van Atteveldt N, 2004, NEURON, V43, P271, DOI 10.1016/j.neuron.2004.06.025
   Vandenberghe R, 2002, J COGNITIVE NEUROSCI, V14, P550, DOI 10.1162/08989290260045800
   Wild CJ, 2012, NEUROIMAGE, V60, P1490, DOI 10.1016/j.neuroimage.2012.01.035
NR 60
TC 1
Z9 1
U1 2
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD DEC
PY 2019
VL 199
AR 104698
DI 10.1016/j.bandl.2019.104698
PG 7
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA JQ2AN
UT WOS:000498754000006
PM 31586792
DA 2021-02-24
ER

PT J
AU Longcamp, M
   Hupe, JM
   Ruiz, M
   Vayssiere, N
   Sato, M
AF Longcamp, Marieke
   Hupe, Jean-Michel
   Ruiz, Mathieu
   Vayssiere, Nathalie
   Sato, Marc
TI Shared premotor activity in spoken and written communication
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Writing; Reading; Speech perception; Speech production; Perceptual-motor
   coupling; Ventral premotor cortex; Letters; Phonemes
ID SUPPLEMENTARY MOTOR AREA; AUDITORY-CORTEX; FUNCTIONAL-ORGANIZATION;
   FRONTAL-LOBE; SPEECH ACQUISITION; AUDIOVISUAL SPEECH; CORTICAL AREAS;
   VISUAL-CORTEX; NEURAL THEORY; BRAIN
AB The aim of the present study was to uncover a possible common neural organizing principle in spoken and written communication, through the coupling of perceptual and motor representations. In order to identify possible shared neural substrates for processing the basic units of spoken and written language, a sparse sampling fMRI acquisition protocol was performed on the same subjects in two experimental sessions with similar sets of letters being read and written and of phonemes being heard and orally produced. We found evidence of common premotor regions activated in spoken and written language, both in perception and in production. The location of those brain regions was confined to the left lateral and medial frontal cortices, at locations corresponding to the premotor cortex, inferior frontal cortex and supplementary motor area. Interestingly, the speaking and writing tasks also appeared to be controlled by largely overlapping networks, possibly indicating some domain general cognitive processing. Finally, the spatial distribution of individual activation peaks further showed more dorsal and more left-lateralized premotor activations in written than in spoken language.
C1 [Longcamp, Marieke] Aix Marseille Univ, LNC, CNRS, Marseille, France.
   [Hupe, Jean-Michel; Ruiz, Mathieu; Vayssiere, Nathalie] Univ Toulouse Paul Sabatier, CNRS, CerCo, Toulouse, France.
   [Vayssiere, Nathalie] Toulouse Mind & Brain Inst, Toulouse, France.
   [Sato, Marc] Aix Marseille Univ, CNRS, LPL, Aix En Provence, France.
RP Longcamp, M (corresponding author), Aix Marseille Univ, LNC, CNRS, Marseille, France.
EM marieke.longcamp@univ-amu.fr
OI Ruiz, Mathieu/0000-0003-3042-2733
FU French Ministry of ResearchMinistry of Research, FranceEuropean
   Commission [ANR-11-BSH2-0010 MULTIMEX]; Excellence Initiative of
   Aix-Marseille University (A*MIDEX)French National Research Agency (ANR);
    [ANR-16-CONV-0002];  [ANR-11-LABX-0036]
FX This work was supported by grants from the French Ministry of Research
   ANR-11-BSH2-0010 MULTIMEX to all authors and to grants ANR-16-CONV-0002
   (ILCB), ANR-11-LABX-0036 (BLRI) and the Excellence Initiative of
   Aix-Marseille University (A*MIDEX) to M.L. The authors thank the INSERM
   U1214 MRI technical platform for the MRI acquisitions.
CR Aboitiz F, 1997, BRAIN RES REV, V25, P381, DOI 10.1016/S0165-0173(97)00053-2
   Aboitiz Francisco, 2012, Front Evol Neurosci, V4, P2, DOI 10.3389/fnevo.2012.00002
   Alario FX, 2006, BRAIN RES, V1076, P129, DOI 10.1016/j.brainres.2005.11.104
   Alho J, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00394
   Alho J, 2012, NEUROIMAGE, V60, P1937, DOI 10.1016/j.neuroimage.2012.02.011
   Allen EA, 2012, NEURON, V74, P603, DOI 10.1016/j.neuron.2012.05.001
   ANDERSON SW, 1990, BRAIN, V113, P749, DOI 10.1093/brain/113.3.749
   ARGUIN M, 1995, J EXP PSYCHOL HUMAN, V21, P1199, DOI 10.1037/0096-1523.21.5.1199
   Birn RM, 1999, HUM BRAIN MAPP, V7, P106, DOI 10.1002/(SICI)1097-0193(1999)7:2<106::AID-HBM4>3.3.CO;2-F
   Boersma P., 2013, PRAAT DOING PHONETIC
   Bohland JW, 2006, NEUROIMAGE, V32, P821, DOI 10.1016/j.neuroimage.2006.04.173
   Bourguignon NJ, 2014, NEUROSCI BIOBEHAV R, V47, P431, DOI 10.1016/j.neubiorev.2014.09.008
   Bowers JS, 1998, J EXP PSYCHOL HUMAN, V24, P1705, DOI 10.1037/0096-1523.24.6.1705
   Brass M, 2005, TRENDS COGN SCI, V9, P314, DOI 10.1016/j.tics.2005.05.001
   Brown S, 2008, CEREB CORTEX, V18, P837, DOI 10.1093/cercor/bhm131
   Buccino G, 2001, EUR J NEUROSCI, V13, P400, DOI 10.1046/j.1460-9568.2001.01385.x
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155
   Castro-Caldas A, 1998, BRAIN, V121, P1053, DOI 10.1093/brain/121.6.1053
   Chevillet MA, 2013, J NEUROSCI, V33, P5208, DOI 10.1523/JNEUROSCI.1870-12.2013
   Cohen L, 2000, BRAIN, V123, P291, DOI 10.1093/brain/123.2.291
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   Danna J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00169
   Dehaene S, 2007, NEURON, V56, P384, DOI 10.1016/j.neuron.2007.10.004
   Dehaene S, 2010, SCIENCE, V330, P1359, DOI 10.1126/science.1194140
   Dick AS, 2019, CORTEX, V111, P148, DOI 10.1016/j.cortex.2018.10.015
   Dietz NAE, 2005, HUM BRAIN MAPP, V26, P81, DOI 10.1002/hbm.20122
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   Dufor O, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00781
   Duncan J, 2000, TRENDS NEUROSCI, V23, P475, DOI 10.1016/S0166-2236(00)01633-7
   Eickhoff SB, 2005, NEUROIMAGE, V25, P1325, DOI 10.1016/j.neuroimage.2004.12.034
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Fedorenko E, 2013, P NATL ACAD SCI USA, V110, P16616, DOI 10.1073/pnas.1315235110
   Flowers DL, 2004, NEUROIMAGE, V21, P829, DOI 10.1016/j.neuroimage.2003.10.002
   Geranmayeh F, 2014, J NEUROSCI, V34, P8728, DOI 10.1523/JNEUROSCI.0428-14.2014
   Glascher J., 2008, CONTRAST WEIGHTS FLE
   Golfinopoulos E, 2011, NEUROIMAGE, V55, P1324, DOI 10.1016/j.neuroimage.2010.12.065
   Grabski K, 2013, J NEUROLINGUIST, V26, P384, DOI 10.1016/j.jneuroling.2012.11.003
   Grabski K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0049117
   Grabski K, 2012, HUM BRAIN MAPP, V33, P2306, DOI 10.1002/hbm.21363
   Gracco VL, 2005, NEUROIMAGE, V26, P294, DOI 10.1016/j.neuroimage.2005.01.033
   Guenther FH, 2006, J COMMUN DISORD, V39, P350, DOI 10.1016/j.jcomdis.2006.06.013
   Guenther FH, 2012, J NEUROLINGUIST, V25, P408, DOI 10.1016/j.jneuroling.2009.08.006
   Hall DA, 1999, HUM BRAIN MAPP, V7, P213, DOI 10.1002/(SICI)1097-0193(1999)7:3<213::AID-HBM5>3.0.CO;2-N
   Hertrich I, 2016, NEUROSCI BIOBEHAV R, V68, P602, DOI 10.1016/j.neubiorev.2016.06.030
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Hikosaka O, 2002, CURR OPIN NEUROBIOL, V12, P217, DOI 10.1016/S0959-4388(02)00307-0
   Houde JF, 2002, J COGNITIVE NEUROSCI, V14, P1125, DOI 10.1162/089892902760807140
   Indovina I, 2005, SCIENCE, V308, P416, DOI 10.1126/science.1107961
   James KH, 2006, NEUROPSYCHOLOGIA, V44, P2937, DOI 10.1016/j.neuropsychologia.2006.06.026
   James KH, 2009, J EXP PSYCHOL GEN, V138, P416, DOI 10.1037/a0015836
   James KH, 2010, DEVELOPMENTAL SCI, V13, P279, DOI 10.1111/j.1467-7687.2009.00883.x
   Jancke L, 2004, EUR J NEUROSCI, V19, P2603, DOI 10.1111/j.0953-816X.2004.03350.x
   Jastorff J, 2010, J NEUROPHYSIOL, V104, P128, DOI 10.1152/jn.00254.2010
   Jobard G, 2003, NEUROIMAGE, V20, P693, DOI 10.1016/S1053-8119(03)00343-4
   Joseph JE, 2006, NEUROIMAGE, V32, P806, DOI 10.1016/j.neuroimage.2006.04.175
   Jurgens U, 2002, NEUROSCI BIOBEHAV R, V26, P235, DOI 10.1016/S0149-7634(01)00068-9
   Kiefer M, 2016, TRENDS NEUROSCI EDUC, V5, P77, DOI 10.1016/j.tine.2016.07.008
   Lancaster JL, 2000, HUM BRAIN MAPP, V10, P120, DOI 10.1002/1097-0193(200007)10:3<120::AID-HBM30>3.0.CO;2-8
   Li JX, 2016, J EXP PSYCHOL GEN, V145, P298, DOI 10.1037/xge0000134
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Lima CF, 2016, TRENDS NEUROSCI, V39, P527, DOI 10.1016/j.tins.2016.06.003
   Longcamp M, 2005, NEUROPSYCHOLOGIA, V43, P1801, DOI 10.1016/j.neuropsychologia.2005.01.020
   Longcamp M, 2005, ACTA PSYCHOL, V119, P67, DOI 10.1016/j.actpsy.2004.10.019
   Longcamp M, 2003, NEUROIMAGE, V19, P1492, DOI 10.1016/S1053-8119(03)00088-0
   Longcamp M, 2014, HUM BRAIN MAPP, V35, P6077, DOI 10.1002/hbm.22606
   Longcamp M, 2011, HUM BRAIN MAPP, V32, P1250, DOI 10.1002/hbm.21105
   MacNeilage PF, 1998, BEHAV BRAIN SCI, V21, P499, DOI 10.1017/S0140525X98001265
   Madec S, 2016, NEUROIMAGE, V132, P359, DOI 10.1016/j.neuroimage.2016.02.010
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Mottonen R, 2012, APHASIOLOGY, V26, P1103, DOI 10.1080/02687038.2011.619515
   Morosan P, 2001, NEUROIMAGE, V13, P684, DOI 10.1006/nimg.2000.0715
   Murakami T, 2015, J NEUROSCI, V35, P1411, DOI 10.1523/JNEUROSCI.0246-14.2015
   Nakamura K, 2012, P NATL ACAD SCI USA, V109, P20762, DOI 10.1073/pnas.1217749109
   Nakatsuka M, 2012, J COGNITIVE NEUROSCI, V24, P1138, DOI 10.1162/jocn_a_00205
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Osnes B, 2011, NEUROIMAGE, V54, P2437, DOI 10.1016/j.neuroimage.2010.09.078
   Papathanasiou I, 2004, EXP BRAIN RES, V154, P218, DOI 10.1007/s00221-003-1648-5
   Pattamadilok C, 2016, HUM BRAIN MAPP, V37, P1531, DOI 10.1002/hbm.23118
   Peeva MG, 2010, NEUROIMAGE, V50, P626, DOI 10.1016/j.neuroimage.2009.12.065
   Perrone-Bertolotti M, 2012, J NEUROSCI, V32, P17554, DOI 10.1523/JNEUROSCI.2982-12.2012
   Planton S, 2017, CORTEX, V88, P66, DOI 10.1016/j.cortex.2016.11.018
   Planton S, 2013, CORTEX, V49, P2772, DOI 10.1016/j.cortex.2013.05.011
   Polk TA, 2002, J COGNITIVE NEUROSCI, V14, P145, DOI 10.1162/089892902317236803
   Price CJ, 2010, ANN NY ACAD SCI, V1191, P62, DOI 10.1111/j.1749-6632.2010.05444.x
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Rademacher J, 2001, NEUROIMAGE, V13, P669, DOI 10.1006/nimg.2000.0714
   Raij T, 2000, NEURON, V28, P617, DOI 10.1016/S0896-6273(00)00138-0
   Rauschecker JP, 2011, HEARING RES, V271, P16, DOI 10.1016/j.heares.2010.09.001
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Riecker A, 2005, NEUROLOGY, V64, P700, DOI 10.1212/01.WNL.0000152156.90779.89
   Rilling JK, 2014, CURR OPIN NEUROBIOL, V28, P10, DOI 10.1016/j.conb.2014.04.002
   ROLAND PE, 1980, J NEUROPHYSIOL, V43, P118
   Rothlein D, 2014, NEUROIMAGE, V89, P331, DOI 10.1016/j.neuroimage.2013.11.054
   Roux FE, 2009, ANN NEUROL, V66, P537, DOI 10.1002/ana.21804
   Rueckl JG, 2015, P NATL ACAD SCI USA, V112, P15510, DOI 10.1073/pnas.1509321112
   Sathian K, 2002, BEHAV BRAIN RES, V135, P127, DOI 10.1016/S0166-4328(02)00141-9
   Sato M, 2015, J COGNITIVE NEUROSCI, V27, P334, DOI 10.1162/jocn_a_00711
   Sato M, 2009, BRAIN LANG, V111, P1, DOI 10.1016/j.bandl.2009.03.002
   Schomers MR, 2015, CEREB CORTEX, V25, P3894, DOI 10.1093/cercor/bhu274
   Schubotz RI, 2003, NEUROIMAGE, V20, P173, DOI 10.1016/S1053-8119(03)00218-0
   Schubotz RI, 2001, COGNITIVE BRAIN RES, V11, P97, DOI 10.1016/S0926-6410(00)00069-0
   Schubotz RI, 2010, NEUROIMAGE, V50, P396, DOI 10.1016/j.neuroimage.2009.12.069
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Soros P, 2006, NEUROIMAGE, V32, P376, DOI 10.1016/j.neuroimage.2006.02.046
   Sugihara G, 2006, NEUROIMAGE, V32, P1837, DOI 10.1016/j.neuroimage.2006.05.035
   TANJI J, 1994, NATURE, V371, P413, DOI 10.1038/371413a0
   Terumitsu M, 2006, NEUROREPORT, V17, P1091, DOI 10.1097/01.wnr.0000224778.97399.c4
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   Tremblay P, 2006, NEUROIMAGE, V33, P947, DOI 10.1016/j.neuroimage.2006.07.041
   Tremblay P, 2011, NEUROIMAGE, V57, P1561, DOI 10.1016/j.neuroimage.2011.05.067
   van Atteveldt N, 2004, NEURON, V43, P271, DOI 10.1016/j.neuron.2004.06.025
   van Atteveldt N, 2009, HEARING RES, V258, P152, DOI 10.1016/j.heares.2009.05.007
   VANGALEN GP, 1991, HUM MOVEMENT SCI, V10, P165, DOI 10.1016/0167-9457(91)90003-G
   von Kriegstein K., 2012, NEURAL BASEMULTISE
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   WORSLEY KJ, 1992, J CEREBR BLOOD F MET, V12, P900, DOI 10.1038/jcbfm.1992.127
   Xue G, 2006, NEUROIMAGE, V31, P1315, DOI 10.1016/j.neuroimage.2005.11.055
   Zangaladze A, 1999, NATURE, V401, P587
   Ziegler JC, 2000, Q J EXP PSYCHOL-A, V53, P671, DOI 10.1080/027249800410508
NR 127
TC 2
Z9 2
U1 3
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD DEC
PY 2019
VL 199
AR 104694
DI 10.1016/j.bandl.2019.104694
PG 14
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA JQ2AN
UT WOS:000498754000003
PM 31586790
DA 2021-02-24
ER

PT J
AU Ou, JH
   Law, SP
AF Ou, Jinghua
   Law, Sam-Po
TI Top-down and bottom-up mechanisms as reflected by beta and gamma
   oscillations in speech perception: An individual-difference approach
SO BRAIN AND LANGUAGE
LA English
DT Article
DE EEG; Beta oscillation; Gamma oscillation; Speech perception
ID VISUAL-CORTEX; RESPONSES; DISCRIMINATION; DYNAMICS; RHYTHMS; EEG
AB Recent neurophysiological studies have proposed distinct roles of beta and gamma oscillations in implementing top-down and bottom-up processes. The present study aims to test this hypothesis in the domain of speech perception. We examined beta and gamma oscillations elicited to a tone contrast in a passive oddball paradigm, and their relationships with discrimination sensitivity d' and RT from two groups of healthy adults who showed high and low discrimination sensitivity to the contrast. The low-sensitivity group showed a significant reduction in beta, which was further related to d'. Individual differences in RT were related to different frequency bands in the two groups, with a RT-beta correlation in the low-sensitivity group, and a RT-gamma relation in the high-sensitivity group. Based on these findings, we suggest that beta, implicated in top-down processing, reflects individual differences in phonological representations, and that gamma, involved in bottom-up processing, reflects individual differences in acoustic encoding.
C1 [Ou, Jinghua] Univ Chicago, Dept Linguist, 1115 E 58th St, Chicago, IL 60637 USA.
   [Law, Sam-Po] Univ Hong Kong, Unit Human Commun Dev & Informat Sci, Hong Kong, Peoples R China.
RP Ou, JH (corresponding author), Univ Chicago, Dept Linguist, 1115 E 58th St, Chicago, IL 60637 USA.
EM jou@uchicago.edu
FU Small Project Fund at the University of Hong Kong
FX Portions of this work was supported by a Small Project Fund at the
   University of Hong Kong [project titled "Neural correlates and cognitive
   capability associated with individual variations in tone perception and
   production in Cantonese - An event-related potential (ERP) study"]. We
   would like to thank the editor and two anonymous reviewers for their
   insightful suggestions which have appreciably improved the manuscript.
CR Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Bates D. M., 2012, LME4 LINEAR MIXED EF
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bidelman GM, 2015, BRAIN LANG, V141, P62, DOI 10.1016/j.bandl.2014.11.003
   Buschman TJ, 2007, SCIENCE, V315, P1860, DOI 10.1126/science.1138071
   Cope TE, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01958-7
   Coren S, 1989, SENSATION PERCEPTION
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Diaz B, 2008, P NATL ACAD SCI USA, V105, P16083, DOI 10.1073/pnas.0805022105
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Engel AK, 2010, CURR OPIN NEUROBIOL, V20, P156, DOI 10.1016/j.conb.2010.02.015
   Fontolan L, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5694
   Fries P, 2015, NEURON, V88, P220, DOI 10.1016/j.neuron.2015.09.034
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   Ghitza O, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00138
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Groppe DM, 2011, PSYCHOPHYSIOLOGY, V48, P1711, DOI 10.1111/j.1469-8986.2011.01273.x
   Iverson P, 1996, J ACOUST SOC AM, V99, P1130, DOI 10.1121/1.415234
   JOHNSON K, 1993, J ACOUST SOC AM, V94, P701, DOI 10.1121/1.406887
   KALCHER J, 1995, ELECTROEN CLIN NEURO, V94, P381, DOI 10.1016/0013-4694(95)00040-6
   Kloosterman NA, 2015, J NEUROPHYSIOL, V113, P1063, DOI 10.1152/jn.00338.2014
   KRANTZ DH, 1969, PSYCHOL REV, V76, P308, DOI 10.1037/h0027238
   Labov W., 1994, PRINCIPLES LANGUAGE
   Lewis AG, 2015, CORTEX, V68, P155, DOI 10.1016/j.cortex.2015.02.014
   Lo S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01171
   MacMillan NA, 1991, DETECTION THEORY USE
   Meyer L, 2018, EUR J NEUROSCI, V48, P2609, DOI 10.1111/ejn.13748
   Mielke J, 2016, LANGUAGE, V92, P101, DOI 10.1353/lan.2016.0019
   Ou JH, 2018, NEUROPSYCHOLOGIA, V121, P28, DOI 10.1016/j.neuropsychologia.2018.10.028
   Ou JH, 2017, ATTEN PERCEPT PSYCHO, V79, P945, DOI 10.3758/s13414-017-1283-z
   Ou JH, 2016, J ACOUST SOC AM, V139, P3226, DOI 10.1121/1.4954252
   Ou JH, 2015, PSYCHON B REV, V22, P1725, DOI 10.3758/s13423-015-0839-y
   Pefkou M, 2017, J NEUROSCI, V37, P7930, DOI 10.1523/JNEUROSCI.2882-16.2017
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   Power AJ, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00216
   R Development Core Team, 2019, R LANG ENV STAT COMP
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580
   Scharinger M, 2016, NEUROIMAGE, V128, P293, DOI 10.1016/j.neuroimage.2016.01.003
   Tallon-Baudry C, 1999, VISUAL NEUROSCI, V16, P449, DOI 10.1017/S0952523899163065
   TallonBaudry C, 1997, NEUROREPORT, V8, P1103, DOI 10.1097/00001756-199703240-00008
   Townsend J. T, 1992, COGNITION INFORM PRO, P105
   Wang XJ, 2010, PHYSIOL REV, V90, P1195, DOI 10.1152/physrev.00035.2008
   Weiss S, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00201
   Wostmann M, 2017, LANG COGN NEUROSCI, V32, P855, DOI 10.1080/23273798.2016.1262051
NR 45
TC 0
Z9 0
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD DEC
PY 2019
VL 199
AR 104700
DI 10.1016/j.bandl.2019.104700
PG 7
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA JQ2AN
UT WOS:000498754000007
PM 31586791
DA 2021-02-24
ER

PT J
AU De Stefano, P
   Pisani, F
   Cossu, G
AF De Stefano, Pia
   Pisani, Francesco
   Cossu, Giuseppe
TI Diverse Linguistic Development in Prelingually Deaf Children with
   Cochlear Implants
SO BEHAVIOURAL NEUROLOGY
LA English
DT Article
ID PHONOLOGICAL AWARENESS; LANGUAGE-ACQUISITION; SPEECH; SKILLS;
   PERFORMANCE; MUTATIONS; AGE
AB The advent of cochlear implants has enormously improved the quality of sensory perception in deaf children. Notwithstanding these advantages, the current literature shows a substantial variability in language proficiency among implanted children. This case series explores the variability of language acquisition in congenitally deaf children with cochlear implants. We report 4 prelingually deaf children (mean age = 10:5; SD = 1:08), affected by a genetically determined bilateral deafness, due to GJB2 gene mutation Cx26. Each implanted child underwent a systematic assessment of speech perception and production, as well as of lexical, morphologic, and syntactic skills in both comprehension and production. Notwithstanding similar clinical histories and similarly good postimplant pure-tone audiometry, two of the four children fared very poorly in speech audiometry, whereas the other two children gained very good results. We suggest that the language impairment detected in (some) implanted children may not be fully accounted for by pure auditory thresholds and that may be the outcome of concomitant damage to core components of the child's linguistic brain.
C1 [De Stefano, Pia] Geneva Univ Hosp, Dept Clin Neurosci, Neurol Unit, Geneva, Switzerland.
   [Pisani, Francesco] Univ Parma, Med & Surg Dept, Child Neuropsychiat Unit, Parma, Italy.
   [Cossu, Giuseppe] Med Ctr Phoniatr, Padua, Italy.
RP De Stefano, P (corresponding author), Geneva Univ Hosp, Dept Clin Neurosci, Neurol Unit, Geneva, Switzerland.
EM pia.destefano@hcuge.ch
RI Pisani, Francesco/K-3486-2018
OI De Stefano, Pia/0000-0002-7979-0994
CR Allen T., 1986, DEAF CHILDREN AM, P161, DOI DOI 10.1177/15257401050270010201
   Bishop D, 1989, TEST RECEPTION GRAMM
   Bitner-Glindzicz M, 2002, BRIT MED BULL, V63, P73, DOI 10.1093/bmb/63.1.73
   Bortolini U., 1995, PROVE VALUTAZIONE FO
   CHILOSI AM, 1995, TCGB TEST COMPRENSIO
   Cohn ES, 1999, AM J MED GENET, V89, P130, DOI 10.1002/(SICI)1096-8628(19990924)89:3<130::AID-AJMG3>3.3.CO;2-D
   Cossu G., 2008, TNP TEST NEUROPSICOL
   Cupples L, 2018, INT J AUDIOL, V57, pS55, DOI 10.1080/14992027.2017.1370140
   DAVIS J, 1974, J SPEECH HEAR RES, V17, P342, DOI 10.1044/jshr.1703.342
   Dunn L. M., 1997, PEABODY PICTURE VOCA
   Fry D. B., 1966, GENESIS LANGUAGE PSY, P187
   Fry D. B., 1975, GENESIS LANG, P137
   Geers A E, 1995, Ann Otol Rhinol Laryngol Suppl, V166, P328
   Geers AE, 2004, ARCH OTOLARYNGOL, V130, P634, DOI 10.1001/archotol.130.5.634
   Geers Ann E, 2006, Adv Otorhinolaryngol, V64, P50, DOI 10.1159/000094644
   Geers AE, 2009, J DEAF STUD DEAF EDU, V14, P371, DOI 10.1093/deafed/enn046
   Kaplan E., 1983, BOSTON NAMING TEST
   Leonard LB, 1998, CHILDREN SPECIFIC LA
   Levitt H, 1987, ASHA Monogr, P1
   Lichtert GF, 2006, J SPEECH LANG HEAR R, V49, P486, DOI 10.1044/1092-4388(2006/037)
   Logan LR, 2008, DEV MED CHILD NEUROL, V50, P99, DOI 10.1111/j.1469-8749.2007.02005.x
   Lustig LR, 2004, ARCH OTOLARYNGOL, V130, P541, DOI 10.1001/archotol.130.5.541
   Marschark M, 2018, J DEAF STUD DEAF EDU, V23, P187, DOI 10.1093/deafed/eny004
   Miyamoto RT, 1997, ACTA OTO-LARYNGOL, V117, P154, DOI 10.3109/00016489709117758
   MOOG J, 1985, VOLTA REV, V87, P259
   Moog JS, 1999, OTOLARYNG CLIN N AM, V32, P1127, DOI 10.1016/S0030-6665(05)70199-7
   Nittrouer S, 2014, EAR HEARING, V35, P506, DOI 10.1097/AUD.0000000000000051
   O'Donoghue GM, 2000, LANCET, V356, P466, DOI 10.1016/S0140-6736(00)02555-1
   Osberger M J, 1986, ASHA Monogr, P54
   Peixoto MC, 2013, INT J PEDIATR OTORHI, V77, P462, DOI 10.1016/j.ijporl.2012.12.005
   RAVEN JC, 1984, COLOURED PROGR MATRI
   Riva D, 2000, BRAIN LANG, V71, P267, DOI 10.1006/brln.1999.2166
   Soleymani Z, 2016, INT J PEDIATR OTORHI, V83, P16, DOI 10.1016/j.ijporl.2016.01.013
   Svirsky MA, 2000, PSYCHOL SCI, V11, P153, DOI 10.1111/1467-9280.00231
   Szagun G, 2001, AUDIOL NEURO-OTOL, V6, P288, DOI 10.1159/000046134
   Tobey EA, 2013, INT J AUDIOL, V52, P219, DOI 10.3109/14992027.2012.759666
   Umat C, 2018, INT J PEDIATR OTORHI, V107, P69, DOI 10.1016/j.ijporl.2018.01.031
   van der Lely HKJ, 2005, TRENDS COGN SCI, V9, P53, DOI 10.1016/j.tics.2004.12.002
   von Muenster K, 2014, INT J PEDIATR OTORHI, V78, P433, DOI 10.1016/j.ijporl.2013.12.009
   Wechsler D., 1992, WECHSLER INTELLIGENC
NR 40
TC 0
Z9 0
U1 0
U2 1
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 0953-4180
EI 1875-8584
J9 BEHAV NEUROL
JI Behav. Neurol.
PD NOV 21
PY 2019
VL 2019
AR 1630718
DI 10.1155/2019/1630718
PG 7
WC Clinical Neurology
SC Neurosciences & Neurology
GA JT4WT
UT WOS:000500992300001
PM 31871493
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Gfeller, K
   Driscoll, V
   Schwalje, A
AF Gfeller, Kate
   Driscoll, Virginia
   Schwalje, Adam
TI Adult Cochlear Implant Recipients' Perspectives on Experiences With
   Music in Everyday Life: A Multifaceted and Dynamic Phenomenon
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE cochlear implant; adults; music; problem solving; patient-centered
   research
ID LISTENING HABITS; PERCEPTION; USERS; APPRAISAL; PATIENT; APPRECIATION;
   ENGAGEMENT
AB Background Cochlear implants (CIs), which have been designed primarily to support spoken communication of persons with severe to profound hearing loss, are highly effective in supporting speech perception in quiet listening conditions. CI users as a group achieve significantly poorer perception and appraisal of music, and speech perception is compromised when background music is present, though outcomes vary considerably across recipients. A number of factors have been identified that contribute to variable music listening experiences, but many questions remain, particularly regarding experiences in everyday life from the perspective of CI users. Purpose The purpose of this study was twofold: The first aim was to explore the perspectives of adult CI recipients regarding two experiences with music in everyday life: purposeful music listening and background music that competes with spoken conversation. The second aim was to develop a framework of everyday music experiences based upon CI perspectives that could inform future rehabilitative practices and research initiatives. Methods Qualitative and patient-engaged research methodologies were used to emphasize the perspectives of the CI users. Participants included 40 experienced adult CI users ranging in age from 19 to 81 enrolled in 13 CI centers. Participants completed on-line semi-structured open-ended questionnaires regarding purposeful music listening and background music in conjunction with spoken communication. Responses were analyzed using an iterative inductive coding process consistent with grounded theory methodology. The interrelated themes that emerged from the data were then organized into a model synthesizing components from models on music response and self-management for persons with chronic health conditions. Outcomes Data analyses informed the development of a Dynamic Problem Solving Model for Management of Music Listening Environments adapted from Hill-Briggs (2003) Problem Solving Model of Chronic Illness Self-Management. Key findings were: (1) Music listening is a dynamic, multifaceted experience; satisfactory listening depended upon optimal combinations of factors; (2) Music listening is effortful, but the extent of satisfaction is influenced by expectations and self-management of the situation; (3) CI users have limited access to resources for optimizing music experiences. Many CI users would consider rehabilitation, but level of commitment and priorities differ across CI users.
C1 [Gfeller, Kate; Driscoll, Virginia] Univ Iowa, Coll Liberal Arts & Sci, Sch Mus, Iowa City, IA 52242 USA.
   [Gfeller, Kate] Univ Iowa, Coll Liberal Arts & Sci, Dept Commun Sci & Disorders, Iowa City, IA 52242 USA.
   [Gfeller, Kate; Driscoll, Virginia; Schwalje, Adam] Univ Iowa Hosp & Clin, Dept Otolaryngol, Iowa Cochlear Implant Clin Res Ctr, Iowa City, IA 52242 USA.
RP Gfeller, K (corresponding author), Univ Iowa, Coll Liberal Arts & Sci, Sch Mus, Iowa City, IA 52242 USA.; Gfeller, K (corresponding author), Univ Iowa, Coll Liberal Arts & Sci, Dept Commun Sci & Disorders, Iowa City, IA 52242 USA.; Gfeller, K (corresponding author), Univ Iowa Hosp & Clin, Dept Otolaryngol, Iowa Cochlear Implant Clin Res Ctr, Iowa City, IA 52242 USA.
EM kay-gfeller@uiowa.edu
OI Driscoll, Virginia/0000-0002-0971-6254
FU NIDCD, NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [2P50DC00242, 5T32DC000040-24];
   Office of the Provost, University of Iowa, Community Impact Grant
FX This study was supported by grants 2P50DC00242 and 5T32DC000040-24 from
   the NIDCD, NIH; Office of the Provost, University of Iowa, Community
   Impact Grant.
CR Attride-Stirling J., 2001, QUAL RES, V1, P385, DOI DOI 10.1177/146879410100100307
   Bandura A., 2010, ENCY HUMAN BEHAV, P1534, DOI DOI 10.1002/9780470479216.CORPSY0836
   Bartel Lee R, 2011, Cochlear Implants Int, V12, P27, DOI 10.1179/146701010X486435
   Baskent D, 2014, J ACOUST SOC AM, V135, pEL147, DOI 10.1121/1.4865261
   Bradley EH, 2007, HEALTH SERV RES, V42, P1758, DOI 10.1111/j.1475-6773.2006.00684.x
   Brodt M., 2015, PAT EXP J, V2, P43, DOI [10.35680/2372-0247.1057, DOI 10.35680/2372-0247.1057]
   Clancy C, 2010, SCI TRANSL MED, V2, DOI 10.1126/scitranslmed.3001235
   Collister LB, 2008, EMPIR MUSICOL REV, V3, P109, DOI 10.18061/1811/34102
   Creswell JW., 2014, CONCISE INTRO MIXED
   Domecq JP, 2014, BMC HEALTH SERV RES, V14, DOI 10.1186/1472-6963-14-89
   Drennan WR, 2015, INT J AUDIOL, V54, P114, DOI 10.3109/14992027.2014.948219
   Dritsakis Giorgos, 2017, Cochlear Implants Int, V18, P207, DOI 10.1080/14670100.2017.1303892
   Dunn C., 2018, CI2018 EMERGING ISSU
   Eskridge EN, 2012, J SPEECH LANG HEAR R, V55, P800, DOI 10.1044/1092-4388(2011/11-0124)
   Forsythe LP, 2017, J COMP EFFECT RES, V6, P231, DOI 10.2217/cer-2016-0062
   Frank L, 2014, JAMA-J AM MED ASSOC, V312, P1513, DOI 10.1001/jama.2014.11100
   Fujita S, 1999, ANN OTO RHINOL LARYN, V108, P634, DOI 10.1177/000348949910800702
   Fuller CD, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518765379
   GFELLER K, 1991, J SPEECH HEAR RES, V34, P916, DOI 10.1044/jshr.3404.916
   GFELLER K, 1992, J MUSIC THER, V29, P18, DOI 10.1093/jmt/29.1.18
   Gfeller K, 2005, EAR HEARING, V26, P237, DOI 10.1097/00003446-200506000-00001
   Gfeller K, 2003, J MUSIC THER, V40, DOI 10.1093/jmt/40.2.78
   Gfeller K, 2000, J Am Acad Audiol, V11, P390
   Gfeller K., 2009, 7 AS PAC S COCHL IMP, P35
   Gfeller K, 2008, J AM ACAD AUDIOL, V19, P120, DOI 10.3766/jaaa.19.2.3
   Gfeller K, 2012, ANN OTO RHINOL LARYN, V121, P782, DOI 10.1177/000348941212101203
   Gfeller Kate, 2002, Cochlear Implants Int, V3, P29, DOI 10.1179/cim.2002.3.1.29
   Gfeller K, 2010, J AM ACAD AUDIOL, V21, P28, DOI 10.3766/jaaa.21.1.4
   Gregory M., 2011, HEAR J, V64, P44
   Hargreaves David J., 2010, HDB MUSIC EMOTION TH, P515, DOI DOI 10.1093/ACPROF:OSO/9780199230143.003.0019
   Harris MS, 2016, LARYNSCOPE INVESTIG, V1, P42, DOI 10.1002/lio2.20
   Hickam D, 2013, PCORI METHODOLOGY RE
   Hill-Briggs F, 2003, ANN BEHAV MED, V25, P182, DOI 10.1207/S15324796ABM2503_04
   Hughes SE, 2018, EAR HEARING, V39, P922, DOI 10.1097/AUD.0000000000000553
   Krueger R., 2009, FOCUS GROUPS PRACTIC
   Lassaletta L, 2008, OTOLARYNG HEAD NECK, V138, P363, DOI 10.1016/j.otohns.2007.11.028
   Limb CJ, 2014, HEARING RES, V308, P13, DOI 10.1016/j.heares.2013.04.009
   Looi Valerie, 2012, Seminars in Hearing, V33, P307, DOI 10.1055/s-0032-1329222
   Looi V, 2010, INT J AUDIOL, V49, P116, DOI 10.3109/14992020903405987
   Mather MW, 2018, CLIN OTOLARYNGOL, V43, P1443, DOI 10.1111/coa.13200
   Migirov L, 2009, ANN OTO RHINOL LARYN, V118, P350, DOI 10.1177/000348940911800506
   Miles M. B., 2014, QUALITATIVE DATA ANA
   Mirza S, 2003, Cochlear Implants Int, V4, P85, DOI 10.1179/cim.2003.4.2.85
   Philips B, 2012, EUR ARCH OTO-RHINO-L, V269, P813, DOI 10.1007/s00405-011-1718-4
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Pijl S, 1995, Ann Otol Rhinol Laryngol Suppl, V166, P224
   Pisoni David B, 2017, World J Otorhinolaryngol Head Neck Surg, V3, P240, DOI 10.1016/j.wjorl.2017.12.010
   Plant Geoff, 2015, Seminars in Hearing, V36, P296, DOI 10.1055/s-0035-1564460
   Saldana J., 2013, CODING MANUAL QUALIT, V2nd ed
   Sarafino E, 2016, HLTH PSYCHOL BIOPSYC
   Savenye W. C., 1996, HDB RES ED COMMUNICA, P1171
   Sheridan S, 2017, ANN FAM MED, V15, P165, DOI 10.1370/afm.2042
   Sloboda J.A., 2010, HDB MUSIC EMOTION TH, P493
   Smith S.L., 2014, PERSPECT AURAL REHAB, V21, P24
   Smith Sherri L, 2006, Am J Audiol, V15, P46, DOI 10.1044/1059-0889(2006/006)
   Strauss A., 1994, HDB QUALITATIVE RES, P273, DOI DOI 10.1007/BF00988593
   Tates K, 2009, BMC MED RES METHODOL, V9, DOI 10.1186/1471-2288-9-15
   Wilhelm L. A., 2016, THESIS
   Wright R, 2012, J AM ACAD AUDIOL, V23, P350, DOI 10.3766/jaaa.23.5.6
   Young-Hyman D, 2016, DIABETES CARE, V39, P2126, DOI 10.2337/dc16-2053
NR 60
TC 3
Z9 3
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD NOV 21
PY 2019
VL 13
AR 1229
DI 10.3389/fnins.2019.01229
PG 19
WC Neurosciences
SC Neurosciences & Neurology
GA JT9KW
UT WOS:000501301200001
PM 31824240
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Lachowska, M
   Pastuszka, A
   Mikolajewska, L
   Kunert, P
   Niemczyk, K
AF Lachowska, Magdalena
   Pastuszka, Agnieszka
   Mikolajewska, Lidia
   Kunert, Przemyslaw
   Niemczyk, Kazimierz
TI Detailed insight in intraoperative eABR measurements to assist auditory
   brainstem implantation in a patient with neurofibromatosis type 2
SO ACTA NEUROLOGICA BELGICA
LA English
DT Article
DE Hearing loss; Evoked potentials; Neurofibromatosis; Cochlear nerve;
   Cochlear nucleus; Auditory brainstem implant
ID COCHLEAR NUCLEUS; ELECTRICAL-STIMULATION; LOUDNESS GROWTH; RESPONSES;
   ADULT
AB Auditory brainstem implant (ABI) is used to provide auditory sensations in patients with neurofibromatosis type 2 who lost their hearing due to a surgical removal of the tumor. ABI surgery, implant activation and follow-up sessions present unique challenges including the exact placement of the electrode pad in the lateral recess of the IVth ventricle, identification of electrodes that trigger non-auditory sensation and their deactivation which lowers the number of electrodes responsible for hearing, changes ofT- andC-levels across follow-up sessions. We present a complete procedure using an example case starting from the surgical part with the detailed description of intraoperative eABR measurement as a guidance for pad placement to the ABI activation and first fitting sessions with auditory sensation assessment. Since the first ABI electrode pad position presented non-satisfactory intraoperative eABR results it was decided to move the pad slightly which resulted in better eABR (more electrodes with auditory responses). The discussed patient demonstrated great auditory and speech perception results after the first ABI fitting (which included three sessions over 2 consecutive days). Repositioning of the ABI electrode pad during the surgery was carried out taking into account the intraoperative eABR results and this led to an overall positive outcome for the patient. The placement of ABI electrode pad is crucial for later auditory results. This study provides detailed insight in this very specialized procedure that is not performed in every clinic and adds to the knowledge of intraoperative navigation using eABR measurements during ABI surgery.
C1 [Lachowska, Magdalena; Pastuszka, Agnieszka; Mikolajewska, Lidia; Niemczyk, Kazimierz] Med Univ Warsaw, Dept Otolaryngol, Warsaw, Poland.
   [Kunert, Przemyslaw] Med Univ Warsaw, Dept Neurosurg, Warsaw, Poland.
RP Lachowska, M (corresponding author), Med Univ Warsaw, Dept Otolaryngol, Warsaw, Poland.
EM mlachowska@wum.edu.pl
CR Anwar A, 2017, INT J PEDIATR OTORHI, V101, P158, DOI 10.1016/j.ijporl.2017.08.007
   Barber SR, 2017, EAR HEARING, V38, pE343, DOI 10.1097/AUD.0000000000000448
   Behr R, 2014, OTOL NEUROTOL, V35, P1844, DOI 10.1097/MAO.0000000000000584
   Chatterjee M, 1999, J ACOUST SOC AM, V105, P850, DOI 10.1121/1.426274
   Colletti V, 2010, OTOL NEUROTOL, V31, P558, DOI 10.1097/MAO.0b013e3181db7055
   Deep NL, 2019, J NEUROL SURG PART B, V80, P203, DOI 10.1055/s-0039-1679891
   Frohne C, 2000, J LARYNGOL OTOL, V114, P11
   Galvin JJ, 2009, HEARING RES, V250, P46, DOI 10.1016/j.heares.2009.01.009
   Herrmann BS, 2015, EAR HEARING, V36, P368, DOI 10.1097/AUD.0000000000000126
   MOORE JK, 1987, HEARING RES, V29, P33, DOI 10.1016/0378-5955(87)90203-6
   Nevison B, 2002, EAR HEARING, V23, P170, DOI 10.1097/00003446-200206000-00002
   Nevison Barry, 2006, Adv Otorhinolaryngol, V64, P154, DOI 10.1159/000094650
   O'Driscoll M, 2011, EAR HEARING, V32, P286, DOI 10.1097/AUD.0b013e3181fc9d72
   Puram SV, 2015, J NEUROL SURG PART B, V76, P440, DOI 10.1055/s-0034-1544121
   Sanna M, 2012, OTOL NEUROTOL, V33, P154, DOI 10.1097/MAO.0b013e318241bc71
   Waring M D, 1995, Ann Otol Rhinol Laryngol Suppl, V166, P33
   Waring MD, 1998, EVOKED POTENTIAL, V108, P331, DOI 10.1016/S0168-5597(97)00072-5
   WARING MD, 1995, EVOKED POTENTIAL, V96, P338, DOI 10.1016/0168-5597(95)00022-K
   Waring MD, 1996, EVOKED POTENTIAL, V100, P538, DOI 10.1016/S0168-5597(96)96061-X
   Wong K, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00010
NR 20
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 0300-9009
EI 2240-2993
J9 ACTA NEUROL BELG
JI Acta Neurol. Belg.
PD DEC
PY 2020
VL 120
IS 6
BP 1371
EP 1378
DI 10.1007/s13760-019-01248-7
EA NOV 2019
PG 8
WC Clinical Neurology; Neurosciences
SC Neurosciences & Neurology
GA OM4MW
UT WOS:000575366600001
PM 31749088
DA 2021-02-24
ER

PT J
AU Zadeh, LM
   Silbert, NH
   Sternasty, K
   Swanepoel, D
   Hunter, LL
   Moore, DR
AF Zadeh, Lina Motlagh
   Silbert, Noah H.
   Sternasty, Katherine
   Swanepoel, De Wet
   Hunter, Lisa L.
   Moore, David R.
TI Extended high-frequency hearing enhances speech perception in noise
SO PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF
   AMERICA
LA English
DT Article
DE self-report; digits-in-noise test; pure-tone audiometry; listening in
   noise; high-frequency hearing
ID DIGIT TRIPLET TEST; RECOGNITION ABILITIES; THRESHOLDS; AUDIOMETRY;
   RECEPTION; INTELLIGIBILITY; VALIDATION; CHILDREN; ADULTS; LEVEL
AB Young healthy adults can hear tones up to at least 20 kHz. However, clinical audiometry, by which hearing loss is diagnosed, is limited at high frequencies to 8 kHz. Evidence suggests there is salient information at extended high frequencies (EHFs; 8 to 20 kHz) that may influence speech intelligibility, but whether that information is used in challenging listening conditions remains unknown. Difficulty understanding speech in noisy environments is the most common concern people have about their hearing and usually the first sign of age-related hearing loss. Digits-in-noise (DIN), a widely used test of speech-in-noise perception, can be sensitized for detection of high-frequency hearing loss by low-pass filtering the broadband masking noise. Here, we used standard and EHF audiometry, self-report, and successively higher cutoff frequency filters (2 to 8 kHz) in a DIN test to investigate contributions of higher-frequency hearing to speech-in-noise perception. Three surprising results were found. First, 74 of 116 "normally hearing," mostly younger adults had some hearing loss at frequencies above 8 kHz. Early EHF hearing loss may thus be an easily measured, preventive warning to protect hearing. Second, EHF hearing loss correlated with self-reported difficulty hearing in noise. Finally, even with the broadest filtered noise (<= 8 kHz), DIN hearing thresholds were significantly better (P < 0.0001) than those using broadband noise. Sound energy above 8 kHz thus contributes to speech perception in noise. People with "normal hearing" frequently report difficulty hearing in challenging environments. Our results suggest that one contribution to this difficulty is EHF hearing loss.
C1 [Zadeh, Lina Motlagh; Sternasty, Katherine; Hunter, Lisa L.; Moore, David R.] Cincinnati Childrens Hosp, Commun Sci Res Ctr, Cincinnati, OH 45229 USA.
   [Zadeh, Lina Motlagh; Silbert, Noah H.; Hunter, Lisa L.] Univ Cincinnati, Dept Commun Sci & Disorders, Cincinnati, OH 45267 USA.
   [Swanepoel, De Wet] Univ Pretoria, Dept Speech Language Pathol & Audiol, ZA-0002 Pretoria, South Africa.
   [Hunter, Lisa L.; Moore, David R.] Univ Cincinnati, Coll Med, Dept Otolaryngol, Cincinnati, OH 45267 USA.
   [Moore, David R.] Univ Manchester, Manchester Ctr Audiol & Deafness, Manchester M13 9PL, Lancs, England.
RP Zadeh, LM (corresponding author), Cincinnati Childrens Hosp, Commun Sci Res Ctr, Cincinnati, OH 45229 USA.; Zadeh, LM (corresponding author), Univ Cincinnati, Dept Commun Sci & Disorders, Cincinnati, OH 45267 USA.
EM lina.motlaghzadeh@cchmc.org
RI Zadeh, Lina Motlagh/AAH-3532-2020; Hunter, Lisa L./AAK-5594-2020
OI Motlagh Zadeh, Lina/0000-0001-7972-7138
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R21DC016241]; Cincinnati Children's
   Hospital Research Foundation; National Institute for Health Research
   (NIHR) Manchester Biomedical Research CenterNational Institute for
   Health Research (NIHR); NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R21DC016241]
   Funding Source: NIH RePORTER
FX This study was supported by NIH grant R21DC016241 and by the Cincinnati
   Children's Hospital Research Foundation. D.R.M. receives support from
   the National Institute for Health Research (NIHR) Manchester Biomedical
   Research Center. We thank Drs. Kevin Munro and Harvey Dillon for
   commenting on drafts of the paper.
CR Apoux F, 2004, J ACOUST SOC AM, V116, P1671, DOI 10.1121/1.1781329
   Badri R, 2011, J ACOUST SOC AM, V129, P852, DOI 10.1121/1.3523476
   Besser J, 2015, EAR HEARING, V36, P24, DOI 10.1097/AUD.0000000000000096
   Brattico E, 2005, CLIN NEUROPHYSIOL, V116, P190, DOI 10.1016/j.clinph.2004.07.030
   COLLINS MJ, 1981, AUDIOLOGY, V20, P347
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   GATES GA, 1990, EAR HEARING, V11, P247, DOI 10.1097/00003446-199008000-00001
   GATES GA, 1991, ACTA OTO-LARYNGOL, V111, P240, DOI 10.3109/00016489109137382
   Heinrich A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00782
   Hogan SCM, 2003, JARO, V4, P123, DOI 10.1007/s10162-002-3007-9
   Hunter LL, 1996, EAR HEARING, V17, P1, DOI 10.1097/00003446-199602000-00001
   International Organization for Standardization, 28961 ISODIS
   Jansen S, 2013, EAR HEARING, V34, P773, DOI 10.1097/AUD.0b013e318297920b
   Jansen S, 2010, INT J AUDIOL, V49, P378, DOI 10.3109/14992020903431272
   KIANG NYS, 1974, J ACOUST SOC AM, V55, P620, DOI 10.1121/1.1914572
   Killion M. C., 2000, HEAR J, V53, P46
   Knight KR, 2007, J CLIN ONCOL, V25, P1190, DOI 10.1200/JCO.2006.07.9723
   Koopmans WJA, 2018, EAR HEARING, V39, P1091, DOI 10.1097/AUD.0000000000000569
   Ladefoged P, 1993, COURSE PHONETICS
   Le Prell CG, 2013, J AM ACAD AUDIOL, V24, P725, DOI 10.3766/jaaa.24.8.9
   Lee FS, 2005, EAR HEARING, V26, P1, DOI 10.1097/00003446-200502000-00001
   Levy SC, 2015, EAR HEARING, V36, pE214, DOI 10.1097/AUD.0000000000000161
   Liberman M Charles, 2017, F1000Res, V6, P927, DOI 10.12688/f1000research.11310.1
   Liberman MC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162726
   Mahomed-Asmail F, 2016, EAR HEARING, V37, pe11, DOI 10.1097/AUD.0000000000000223
   Malica T., 2011, INT J ENG SCI, V4, P423
   Matthews LJ, 1997, J SPEECH LANG HEAR R, V40, P208, DOI 10.1044/jslhr.4001.208
   MILLER GA, 1951, J EXP PSYCHOL, V41, P329, DOI 10.1037/h0062491
   Moore B.C., 2012, INTRO PSYCHOL HEARIN
   Moore B. C. J., 2007, COCHLEAR HEARING LOS
   Moore BCJ, 2016, INT J AUDIOL, V55, P707, DOI 10.1080/14992027.2016.1204565
   Moore D., 2017, HEAR J, V70, P50
   Moore DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107720
   MOORE DR, 2018, HEAR J, V71, P32
   Musiek F. E., 2018, ASHA LEAD, V23, P6
   Ozimek E, 2009, SPEECH COMMUN, V51, P307, DOI 10.1016/j.specom.2008.09.007
   Paradise JL, 1997, PEDIATRICS, V99, P318, DOI 10.1542/peds.99.3.318
   Pienkowski M, 2017, EAR HEARING, V38, P135, DOI 10.1097/AUD.0000000000000388
   PLOMP R, 1986, J SPEECH HEAR RES, V29, P146, DOI 10.1044/jshr.2902.146
   Potgieter JM, 2016, INT J AUDIOL, V55, P405, DOI 10.3109/14992027.2016.1172269
   Puria S, 2016, OTOL NEUROTOL, V37, P160, DOI 10.1097/MAO.0000000000000941
   Ramkissoon Ishara, 2002, Am J Audiol, V11, P23, DOI 10.1044/1059-0889(2002/005)
   Rieke CC, 2017, EAR HEARING, V38, pE369, DOI 10.1097/AUD.0000000000000433
   Valiente AR, 2014, INT J AUDIOL, V53, P531, DOI 10.3109/14992027.2014.893375
   Valiente AR, 2016, ACTA OTORRINOLAR ESP, V67, P40, DOI 10.1016/j.otorri.2015.02.002
   RUDMIN F, 1987, Journal of Auditory Research, V27, P15
   Saunders G. H., 1989, BRIT J AUDIOL, V23, P358
   Schaette R, 2011, J NEUROSCI, V31, P13452, DOI 10.1523/JNEUROSCI.2156-11.2011
   Shaw GM, 1996, BRIT J AUDIOL, V30, P233, DOI 10.3109/03005369609076770
   Smith PA, 2011, INT J AUDIOL, V50, P610, DOI 10.3109/14992027.2011.585668
   Smits C, 2004, INT J AUDIOL, V43, P15, DOI 10.1080/14992020400050004
   Smits C, 2007, INT J AUDIOL, V46, P134, DOI 10.1080/14992020601102170
   Smits C, 2006, EAR HEARING, V27, P538, DOI 10.1097/01.aud.0000233917.72551.cf
   Smits C, 2016, INT J AUDIOL, V55, P358, DOI 10.3109/14992027.2015.1137362
   Smits C, 2013, J ACOUST SOC AM, V133, P1693, DOI 10.1121/1.4789933
   Stelmachowicz PG, 2004, ARCH OTOLARYNGOL, V130, P556, DOI 10.1001/archotol.130.5.556
   Summers V, 2013, J AM ACAD AUDIOL, V24, P274, DOI 10.3766/jaaa.24.4.4
   Swanepoel D, 2014, INT J AUDIOL, V53, P841, DOI 10.3109/14992027.2014.920965
   TREHUB SE, 1988, J EXP CHILD PSYCHOL, V46, P273, DOI 10.1016/0022-0965(88)90060-4
   Vermiglio AJ, 2012, J AM ACAD AUDIOL, V23, P779, DOI 10.3766/jaaa.23.10.4
   Vitela AD, 2015, J ACOUST SOC AM, V137, pEL65, DOI 10.1121/1.4903917
   Vlaming MSMG, 2014, EAR HEARING, V35, P667, DOI 10.1097/AUD.0000000000000073
   Wilson RH, 2005, J REHABIL RES DEV, V42, P499, DOI 10.1682/JRRD.2004.10.0134
   Wu PZ, 2019, NEUROSCIENCE, V407, P8, DOI 10.1016/j.neuroscience.2018.07.053
   Yoshinaga-Itano C, 2017, PEDIATRICS, V140, DOI 10.1542/peds.2016-2964
NR 65
TC 16
Z9 16
U1 1
U2 4
PU NATL ACAD SCIENCES
PI WASHINGTON
PA 2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA
SN 0027-8424
J9 P NATL ACAD SCI USA
JI Proc. Natl. Acad. Sci. U. S. A.
PD NOV 19
PY 2019
VL 116
IS 47
BP 23753
EP 23759
DI 10.1073/pnas.1903315116
PG 7
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA JQ0ZJ
UT WOS:000498683000056
PM 31685611
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Ronai, E
   Sun, YN
   Yu, ACL
   Xiang, M
AF Ronai, Eszter
   Sun, Yenan
   Yu, Alan C. L.
   Xiang, Ming
TI Integration of contextual-pragmatic and phonetic information in speech
   perception: An eye-tracking study
SO LABORATORY PHONOLOGY
LA English
DT Article
DE pragmatics; contrastive inference; speech perception; VOT; cue
   integration; eye-tracking
ID AMBIGUITY
AB Pragmatic information, such as inferences regarding upcoming coreference, has been shown to influence phonetic perception (Rohde & Ettlinger, 2012). Pragmatic information, however, comes in many forms. Using a Visual World Paradigm, tracking listeners' categorical responses and the time-course of information integration via eye movements, we investigated whether and how a different kind of pragmatic information, the contrastive function of prenominal adjectives (Sedivy, Tanenhaus, Chambers, & Carlson, 1999), can affect listeners' perception of voicing in initial plosives. Our results suggest that the pragmatic contrast inference did not affect the behavioral judgments on phonetic categorization, but it did have an (albeit limited) influence during the online processing of voice onset time (VOT). Our findings suggest that different kinds of higher-level pragmatic inferences are not uniform in how (successfully) they are integrated with low-level phonetic properties in real-time comprehension.
C1 [Ronai, Eszter; Sun, Yenan; Yu, Alan C. L.; Xiang, Ming] Univ Chicago, Dept Linguist, Chicago, IL 60637 USA.
RP Ronai, E (corresponding author), Univ Chicago, Dept Linguist, Chicago, IL 60637 USA.
EM ronai@uchicago.edu
CR Aparicio H., 2015, P SEMANTICS LINGUIST, V25, P413, DOI DOI 10.3765/SALT.V25I0.3128
   Boersma P., 2018, PRAAT DOING PHONETIC
   Brown-Schmidt S, 2017, LANG COGN NEUROSCI, V32, P1211, DOI 10.1080/23273798.2017.1325508
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Garvey C., 1974, LINGUIST INQ, V5, P459
   Grice H. Paul, 1975, SYNTAX SEMANTICS, V3, P41, DOI [10.1057/9780230005853_5., DOI 10.1111/J.1365-2664.2006.01229.X]
   HALLETT PE, 1986, HDB PERCEPTION HUMAN, V1, P10
   Isenberg D., 1980, J ACOUST SOC AM, V68, pS48, DOI DOI 10.1121/1.2004759
   Kawamoto A. H, 1988, LEXICAL AMBIGUITY RE, P195
   KAWAMOTO AH, 1993, J MEM LANG, V32, P474, DOI 10.1006/jmla.1993.1026
   Kingston J, 2016, J EXP PSYCHOL HUMAN, V42, P1969, DOI 10.1037/xhp0000269
   Kurczek J, 2013, J EXP PSYCHOL GEN, V142, P1346, DOI 10.1037/a0034026
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B, 2009, J MEM LANG, V60, P65, DOI 10.1016/j.jml.2008.07.002
   McMurray B, 2008, J EXP PSYCHOL HUMAN, V34, P1609, DOI 10.1037/a0011747
   MILLER JL, 1984, PERCEPT PSYCHOPHYS, V36, P329, DOI 10.3758/BF03202785
   Rohde H, 2012, J EXP PSYCHOL LEARN, V38, P967, DOI 10.1037/a0026786
   SAMUEL AG, 1981, J EXP PSYCHOL GEN, V110, P474, DOI 10.1037/0096-3445.110.4.474
   Sedivy J. C., 2005, APPROACHES STUDYING
   Sedivy JC, 1999, COGNITION, V71, P109, DOI 10.1016/S0010-0277(99)00025-6
   Sedivy JC, 2003, J PSYCHOLINGUIST RES, V32, P3, DOI 10.1023/A:1021928914454
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
NR 24
TC 0
Z9 0
U1 0
U2 2
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD NOV 19
PY 2019
VL 10
IS 1
AR 20
DI 10.5334/labphon.186
PG 15
WC Linguistics; Language & Linguistics
SC Linguistics
GA JO7II
UT WOS:000497749000001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Sorati, M
   Behne, DM
AF Sorati, Marzieh
   Behne, Dawn Marie
TI Musical Expertise Affects Audiovisual Speech Perception: Findings From
   Event-Related Potentials and Inter-trial Phase Coherence
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE speech perception; prediction; audiovisual; musical training;
   event-related potential (ERP); inter-trial phase coherence (ITPC);
   musicians; non-musicians
AB In audiovisual speech perception, visual information from a talker's face during mouth articulation is available before the onset of the corresponding audio speech, and thereby allows the perceiver to use visual information to predict the upcoming audio. This prediction from phonetically congruent visual information modulates audiovisual speech perception and leads to a decrease in N1 and P2 amplitudes and latencies compared to the perception of audio speech alone. Whether audiovisual experience, such as with musical training, influences this prediction is unclear, but if so, may explain some of the variations observed in previous research. The current study addresses whether audiovisual speech perception is affected by musical training, first assessing N1 and P2 event-related potentials (ERPs) and in addition, inter-trial phase coherence (ITPC). Musicians and non-musicians are presented the syllable, /ba/ in audio only (AO), video only (VO), and audiovisual (AV) conditions. With the predictory effect of mouth movement isolated from the AV speech (AV-VO), results showed that, compared to audio speech, both groups have a lower N1 latency and P2 amplitude and latency. Moreover, they also showed lower ITPCs in the delta, theta, and beta bands in audiovisual speech perception. However, musicians showed significant suppression of N1 amplitude and desynchronization in the alpha band in audiovisual speech, not present for nonmusicians. Collectively, the current findings indicate that early sensory processing can be modified by musical experience, which in turn can explain some of the variations in previous AV speech perception research.
C1 [Sorati, Marzieh; Behne, Dawn Marie] Norwegian Univ Sci & Technol, Dept Psychol, Trondheim, Norway.
RP Sorati, M (corresponding author), Norwegian Univ Sci & Technol, Dept Psychol, Trondheim, Norway.
EM marzieh.sorati@ntnu.no
CR Alain C, 2007, J AM ACAD AUDIOL, V18, P573, DOI 10.3766/jaaa.18.7.5
   Arnal Luc H, 2015, Handb Clin Neurol, V129, P85, DOI 10.1016/B978-0-444-62630-1.00005-6
   Arnal LH, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00225
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810
   Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009
   Baart M, 2016, PSYCHOPHYSIOLOGY, V53, P1295, DOI 10.1111/psyp.12683
   Baart M, 2014, NEUROPSYCHOLOGIA, V53, P115, DOI 10.1016/j.neuropsychologia.2013.11.011
   Bastiaansen MCM, 2001, INT J PSYCHOPHYSIOL, V43, P91, DOI 10.1016/S0167-8760(01)00181-7
   Bastiaansen MCM, 2001, CLIN NEUROPHYSIOL, V112, P393, DOI 10.1016/S1388-2457(00)00537-X
   Baumann S, 2008, J COGNITIVE NEUROSCI, V20, P2238, DOI 10.1162/jocn.2008.20157
   Beaton AA, 1997, BRAIN LANG, V60, P255, DOI 10.1006/brln.1997.1825
   Behne D., 2013, P M AC ICA2013, V19
   Behne D. M., 2017, AVSP, P100
   Besle J, 2004, EUR J NEUROSCI, V20, P2225, DOI 10.1111/j.1460-9568.2004.03670.x
   Besson M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00094
   Bianchi F, 2017, NEUROIMAGE, V163, P398, DOI 10.1016/j.neuroimage.2017.07.057
   Bidelman GM, 2017, NEUROSCIENCE, V348, P107, DOI 10.1016/j.neuroscience.2017.02.015
   Bidelman GM, 2016, EXP BRAIN RES, V234, P3037, DOI 10.1007/s00221-016-4705-6
   Bidelman GM, 2014, EUR J NEUROSCI, V40, P2662, DOI 10.1111/ejn.12627
   Bonte M, 2009, J NEUROSCI, V29, P1699, DOI 10.1523/JNEUROSCI.3694-08.2009
   Bosnyak DJ, 2004, CEREB CORTEX, V14, P1088, DOI 10.1093/cercor/bhh068
   Brandwein AB, 2011, CEREB CORTEX, V21, P1042, DOI 10.1093/cercor/bhq170
   Brown S, 2006, CEREB CORTEX, V16, P1157, DOI 10.1093/cercor/bhj057
   Buffalo EA, 2011, P NATL ACAD SCI USA, V108, P11262, DOI 10.1073/pnas.1011284108
   Busch NA, 2010, P NATL ACAD SCI USA, V107, P16048, DOI 10.1073/pnas.1004801107
   Calvert GA, 2001, CEREB CORTEX, V11, P1110, DOI 10.1093/cercor/11.12.1110
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Chen Y, 2007, CHINESE PHYS, V16, P6, DOI 10.1088/1009-1963/16/1/002
   Cohen MX, 2014, ISS CLIN COGN NEUROP, P1
   Costa-Faidella J, 2011, J NEUROSCI, V31, P18590, DOI 10.1523/JNEUROSCI.2599-11.2011
   D'Anselmo A, 2015, NEUROPSYCHOLOGIA, V71, P119, DOI 10.1016/j.neuropsychologia.2015.03.026
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Doelling KB, 2015, P NATL ACAD SCI USA, V112, pE6233, DOI 10.1073/pnas.1508431112
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Edwards E, 2009, J NEUROPHYSIOL, V102, P377, DOI 10.1152/jn.90954.2008
   Eggermont JJ, 2007, HEARING RES, V229, P69, DOI 10.1016/j.heares.2007.01.008
   Foxe JJ, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00154
   Fujioka T, 2009, ANN NY ACAD SCI, V1169, P89, DOI 10.1111/j.1749-6632.2009.04779.x
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Gisladottir RS, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00034
   Gruber WR, 2005, CEREB CORTEX, V15, P371, DOI 10.1093/cercor/bhh139
   Hanggi J, 2010, HUM BRAIN MAPP, V31, P1196, DOI 10.1002/hbm.20928
   Halwani GF, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00156
   Han Woojae, 2010, Audiology and Speech Research, V6, P121
   Haslinger B, 2004, HUM BRAIN MAPP, V22, P206, DOI 10.1002/hbm.20028
   Heald SLM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00781
   HILLYARD SA, 1973, SCIENCE, V182, P177, DOI 10.1126/science.182.4108.177
   Hsu YF, 2016, NEUROPSYCHOLOGIA, V84, P198, DOI 10.1016/j.neuropsychologia.2016.02.019
   Huhn Z, 2009, NEUROSCI LETT, V465, P204, DOI 10.1016/j.neulet.2009.08.077
   Jantzen MG, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00171
   Jicol C, 2018, EXP BRAIN RES, V236, P1869, DOI 10.1007/s00221-018-5269-4
   Kishon-Rabin Liat, 2001, Journal of Basic and Clinical Physiology and Pharmacology, V12, P125
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Klimesch W, 2012, TRENDS COGN SCI, V16, P606, DOI 10.1016/j.tics.2012.10.007
   Klucharev V, 2003, COGNITIVE BRAIN RES, V18, P65, DOI 10.1016/j.cogbrainres.2003.09.004
   Koerner TK, 2015, HEARING RES, V328, P113, DOI 10.1016/j.heares.2015.08.002
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Kreifelts B, 2007, NEUROIMAGE, V37, P1445, DOI 10.1016/j.neuroimage.2007.06.020
   Kuhnis J, 2014, J COGNITIVE NEUROSCI, V26, P2750, DOI 10.1162/jocn_a_00674
   Kuhnis J, 2013, NEUROPSYCHOLOGIA, V51, P1608, DOI 10.1016/j.neuropsychologia.2013.04.007
   Kuriki S, 2006, J NEUROSCI, V26, P4046, DOI 10.1523/JNEUROSCI.3907-05.2006
   Lakatos P, 2007, NEURON, V53, P279, DOI 10.1016/j.neuron.2006.12.011
   Lange J, 2013, NEUROIMAGE, V79, P111, DOI 10.1016/j.neuroimage.2013.04.064
   Lange K, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00263
   Lee H, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00868
   Lee H, 2011, P NATL ACAD SCI USA, V108, pE1441, DOI 10.1073/pnas.1115267108
   Liem F, 2012, NEUROREPORT, V23, P1026, DOI 10.1097/WNR.0b013e32835abc5c
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Lu Y, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090686
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1
   Luo H, 2005, NEUROIMAGE, V28, P59, DOI 10.1016/j.neuroimage.2005.05.040
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Meha-Bettison K, 2018, INT J AUDIOL, V57, P40, DOI 10.1080/14992027.2017.1380850
   MOLFESE DL, 1975, BRAIN LANG, V2, P356, DOI 10.1016/S0093-934X(75)80076-9
   Musacchia G, 2008, HEARING RES, V241, P34, DOI 10.1016/j.heares.2008.04.013
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   Naatanen R, 1999, PSYCHOL BULL, V125, P826, DOI 10.1037/0033-2909.125.6.826
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Naatanen R, 2011, PSYCHOPHYSIOLOGY, V48, P4, DOI 10.1111/j.1469-8986.2010.01114.x
   Noppeney U, 2018, ANN NY ACAD SCI, V1423, P102, DOI 10.1111/nyas.13615
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Ott CGM, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00195
   Overman AA, 2003, PERCEPT MOTOR SKILL, V97, P519, DOI 10.2466/PMS.97.6.519-532
   Pantev C, 2001, NEUROREPORT, V12, P169, DOI 10.1097/00001756-200101220-00041
   Paraskevopoulos E, 2012, J NEUROSCI, V32, P18196, DOI 10.1523/JNEUROSCI.1947-12.2012
   Parbery-Clark A, 2009, J NEUROSCI, V29, P14100, DOI 10.1523/JNEUROSCI.3256-09.2009
   Paris T, 2017, NEUROSCIENCE, V343, P157, DOI 10.1016/j.neuroscience.2016.09.023
   Paris T, 2016, CORTEX, V75, P220, DOI 10.1016/j.cortex.2015.03.010
   Paris T, 2016, J COGNITIVE NEUROSCI, V28, P158, DOI 10.1162/jocn_a_00885
   Paris T, 2013, BRAIN LANG, V126, P350, DOI 10.1016/j.bandl.2013.06.008
   Patel AD, 2007, TRENDS COGN SCI, V11, P369, DOI 10.1016/j.tics.2007.08.003
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Petrini K, 2011, NEUROIMAGE, V56, P1480, DOI 10.1016/j.neuroimage.2011.03.009
   Petrini K, 2009, EXP BRAIN RES, V198, P339, DOI 10.1007/s00221-009-1817-2
   Petrini K, 2009, COGNITION, V110, P432, DOI 10.1016/j.cognition.2008.11.015
   Pilling M, 2009, J SPEECH LANG HEAR R, V52, P1073, DOI [10.1044/1092-4388, 10.1044/1092-4388(2009/07-0276)]
   Poikonen H, 2018, EUR J NEUROSCI, V47, P433, DOI 10.1111/ejn.13838
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   Pratt H., 2014, OXFORD HDB EVENT REL, P89
   Proverbio AM, 2016, SCI REP-UK, V6, DOI 10.1038/srep30423
   Schon D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   Schwartz JL, 2004, COGNITION, V93, pB69, DOI 10.1016/j.cognition.2004.01.006
   Sekiyama K, 2003, NEUROSCI RES, V47, P277, DOI 10.1016/S0168-0102(03)00214-1
   Senkowski D, 2007, NEUROPSYCHOLOGIA, V45, P561, DOI 10.1016/j.neuropsychologia.2006.01.013
   Shahin A, 2003, J NEUROSCI, V23, P5545
   Shahin A, 2005, NEUROREPORT, V16, P1781, DOI 10.1097/01.wnr.0000185017.29316.63
   Shahin AJ, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00126
   Stefanics G, 2010, J NEUROSCI, V30, P13578, DOI 10.1523/JNEUROSCI.0703-10.2010
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964
   Stekelenburg JJ, 2012, FRONT INTEGR NEUROSC, V6, DOI 10.3389/fnint.2012.00026
   Strait DL, 2014, HEARING RES, V308, P109, DOI 10.1016/j.heares.2013.08.004
   Strait DL, 2012, CORTEX, V48, P360, DOI 10.1016/j.cortex.2011.03.015
   Strauss A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00350
   Talsma D, 2010, TRENDS COGN SCI, V14, P400, DOI 10.1016/j.tics.2010.06.008
   Tan A, 2016, BRAIN CONNECT, V6, P496, DOI 10.1089/brain.2016.0418
   Tervaniemi M, 2003, BRAIN RES REV, V43, P231, DOI 10.1016/j.brainresrev.2003.08.004
   Todorovic A, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0120288
   Trainor LJ, 2009, ANN NY ACAD SCI, V1169, P133, DOI 10.1111/j.1749-6632.2009.04589.x
   Tremblay KL, 2006, EAR HEARING, V27, P93, DOI 10.1097/01.aud.0000202288.21315.bd
   van Diepen RM, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20423-z
   van Ede F, 2014, NEUROIMAGE, V97, P134, DOI 10.1016/j.neuroimage.2014.04.047
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Vroomen J, 2010, J COGNITIVE NEUROSCI, V22, P1583, DOI 10.1162/jocn.2009.21308
   Wang Y, 2009, J PHONETICS, V37, P344, DOI 10.1016/j.wocn.2009.04.002
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
   Wilsch A, 2015, CEREB CORTEX, V25, P1938, DOI 10.1093/cercor/bhu004
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Woodman GF, 2010, ATTEN PERCEPT PSYCHO, V72, P2031, DOI 10.3758/APP.72.8.2031
   Yu LD, 2018, CLIN NEUROPHYSIOL, V129, P1374, DOI 10.1016/j.clinph.2018.04.599
   ZATORRE RJ, 1992, SCIENCE, V256, P846, DOI 10.1126/science.1589767
   Zatorre RJ, 2007, NAT REV NEUROSCI, V8, P547, DOI 10.1038/nrn2152
   Zhang CC, 2018, LANG COGN NEUROSCI, V33, P175, DOI 10.1080/23273798.2017.1376752
NR 134
TC 2
Z9 2
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD NOV 15
PY 2019
VL 10
AR 2562
DI 10.3389/fpsyg.2019.02562
PG 19
WC Psychology, Multidisciplinary
SC Psychology
GA VJ5JB
UT WOS:000606767800001
PM 31803107
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Dietrich, S
   Hertrich, I
   Seibold, VC
   Rolke, B
AF Dietrich, Susanne
   Hertrich, Ingo
   Seibold, Verena C.
   Rolke, Bettina
TI Discourse management during speech perception: A functional magnetic
   resonance imaging (fMRI) study
SO NEUROIMAGE
LA English
DT Article
DE Monitoring; Presupposition; Reference; Evaluation; Accommodation;
   Context-dependent
ID SUPPLEMENTARY MOTOR AREA; WORKING-MEMORY; PREFRONTAL CORTEX; LANGUAGE
   PATHWAYS; COGNITIVE FUNCTIONS; EPISODIC MEMORY; ANGULAR GYRUS; BRAIN;
   PRESUPPOSITION; COMPREHENSION
AB Discourse structures enable us to generate expectations based upon linguistic material that has already been introduced. We investigated how the required cognitive operations such as reference processing, identification of critical items, and eventual handling of violations correlate with neuronal activity within the language network of the brain. To this end, we conducted a functional magnetic resonance imaging (fMRI) study in which we manipulated spoken discourse coherence by using presuppositions (PSPs) that either correspond or fail to correspond to items in preceding context sentences. Definite and indefinite determiners were used as PSP triggers, referring to (non-) uniqueness or (non-) existence of an item. Discourse adequacy was tested by means of a behavioral rating during fMRI. Discourse violations yielded bilateral hemodynamic activation within the inferior frontal gyrus (IFG), the inferior parietal lobe including the angular gyrus (IPL/AG), the pre-supplementary motor area (pre-SMA), and the basal ganglia (BG). These findings illuminate cognitive aspects of PSP processing: (1) a reference process requiring working memory (IFG), (2) retrieval and integration of semantic/pragmatic information (IPL/AG), (3) cognitive control of inconsistency management (pre-SMA/BG) in terms of "successful" comprehension despite PSP violations at the surface. These results provide the first fMRI evidence needed to develop a functional neuroanatomical model for context-dependent sentence comprehension based on the example of PSP processing.
C1 [Dietrich, Susanne; Seibold, Verena C.; Rolke, Bettina] Univ Tubingen, Evolutionary Cognit, Tubingen, Germany.
   [Hertrich, Ingo] Univ Tubingen, Hertie Inst Clin Brain Res, Tubingen, Germany.
RP Dietrich, S (corresponding author), Univ Tubingen, Evolutionary Cognit, Tubingen, Germany.
EM s.dietrich@uni-tuebingen.de
RI Hertrich, Ingo/T-1154-2018
OI Hertrich, Ingo/0000-0001-8965-6249
CR Adank P, 2012, NEUROIMAGE, V63, P1601, DOI 10.1016/j.neuroimage.2012.07.027
   Adank P, 2012, BRAIN LANG, V122, P42, DOI 10.1016/j.bandl.2012.04.014
   Adank P, 2010, NEUROIMAGE, V49, P1124, DOI 10.1016/j.neuroimage.2009.07.032
   Alderson-Day B, 2015, PSYCHOL BULL, V141, P931, DOI 10.1037/bul0000021
   Alm PA, 2011, CLUTTERING: A HANDBOOK OF RESEARCH, INTERVENTION AND EDUCATION, P3
   Alonso-Ovalle L., 2011, P N E LING SOC C NEL, V39, P29
   Amunts K, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000489
   Anderson JE, 2005, BRAIN LANG, V94, P200, DOI 10.1016/j.bandl.2005.01.001
   Baddeley A, 2003, NAT REV NEUROSCI, V4, P829, DOI 10.1038/nrn1201
   Bajada CJ, 2015, CORTEX, V69, P141, DOI 10.1016/j.cortex.2015.05.011
   Beaver David I., 2007, OXFORD HDB LINGUISTI, P503, DOI 10.1093/oxfordhb/9780199247455.013.0017
   Binder JR, 2017, CURR NEUROL NEUROSCI, V17, DOI 10.1007/s11910-017-0764-8
   Binder JR, 2009, CEREB CORTEX, V19, P2767, DOI 10.1093/cercor/bhp055
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   Bonhage CE, 2014, J COGNITIVE NEUROSCI, V26, P1654, DOI 10.1162/jocn_a_00566
   Bornkessel-Schlesewsky I, 2008, BRAIN RES REV, V59, P55, DOI 10.1016/j.brainresrev.2008.05.003
   Brand M, 2009, PSYCHIAT RES-NEUROIM, V174, P32, DOI 10.1016/j.pscychresns.2009.03.008
   Brauer J, 2013, BRAIN LANG, V127, P289, DOI 10.1016/j.bandl.2013.03.001
   Brouwer H, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00758
   Burkhardt P, 2007, NEUROSCI LETT, V413, P115, DOI 10.1016/j.neulet.2006.11.038
   Camos V, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00900
   Chemla E, 2008, J SEMANT, V25, P141, DOI 10.1093/jos/ffm017
   Cheung VKM, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22144-9
   DeWitt I, 2013, BRAIN LANG, V127, P181, DOI 10.1016/j.bandl.2013.09.014
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Dick AS, 2014, NEUROSCIENTIST, V20, P453, DOI 10.1177/1073858413513502
   Dick AS, 2012, BRAIN, V135, P3529, DOI 10.1093/brain/aws222
   Dietrich S, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00361
   Dietrich S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0132196
   Dietrich S, 2008, NEUROREPORT, V19, P1751, DOI 10.1097/WNR.0b013e3283193e9e
   Domaneschi F, 2018, J PSYCHOLINGUIST RES, V47, P483, DOI 10.1007/s10936-017-9534-7
   Frey S, 2008, J NEUROSCI, V28, P11435, DOI 10.1523/JNEUROSCI.2388-08.2008
   Friederici AD, 2013, CURR OPIN NEUROBIOL, V23, P250, DOI 10.1016/j.conb.2012.10.002
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Friston KJ, 2006, NEUROIMAGE, V30, P1077, DOI 10.1016/j.neuroimage.2005.08.012
   Fuster JM, 2001, NEURON, V30, P319, DOI 10.1016/S0896-6273(01)00285-9
   Garrod S. C., 1982, J SEMANT, V1, P21, DOI [10.1093/jos/1.1.21, DOI 10.1093/JOS/1.1.21]
   Gauvin HS, 2016, NEUROIMAGE, V126, P96, DOI 10.1016/j.neuroimage.2015.11.037
   Geiger LS, 2018, BRAIN STRUCT FUNCT, V223, P3121, DOI 10.1007/s00429-018-1679-0
   Gennari SP, 2007, NEUROIMAGE, V35, P1278, DOI 10.1016/j.neuroimage.2007.01.015
   Geranmayeh F, 2017, BRAIN, V140, P1947, DOI 10.1093/brain/awx134
   Gerton BK, 2004, NEUROPSYCHOLOGIA, V42, P1781, DOI 10.1016/j.neuropsychologia.2004.04.023
   Giles H., 1991, CONTEXTS ACCOMMODATI, P1, DOI [10.1017/CBO9780511663673.001, DOI 10.1017/CBO9780511663673.001]
   Goucha T, 2015, NEUROIMAGE, V114, P294, DOI 10.1016/j.neuroimage.2015.04.011
   Grahn JA, 2008, PROG NEUROBIOL, V86, P141, DOI 10.1016/j.pneurobio.2008.09.004
   Grice H. Paul, 1975, SYNTAX SEMANTICS, V3, P41, DOI [10.1057/9780230005853_5., DOI 10.1111/J.1365-2664.2006.01229.X]
   Hassabis D, 2007, TRENDS COGN SCI, V11, P299, DOI 10.1016/j.tics.2007.05.001
   Heim Irene, 1982, THESIS
   Heim Irene, 1998, SEMANTICS GENERATIVE
   Hertrich I, 2016, NEUROSCI BIOBEHAV R, V68, P602, DOI 10.1016/j.neubiorev.2016.06.030
   Hertrich I, 2015, BRAIN LANG, V149, P1, DOI 10.1016/j.bandl.2015.06.005
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158
   Huang AS, 2016, DEV COGN NEUROS-NETH, V17, P1, DOI 10.1016/j.dcn.2015.10.007
   Jahanshahi M, 2015, NAT REV NEUROSCI, V16, P719, DOI 10.1038/nrn4038
   Kelly C, 2010, EUR J NEUROSCI, V32, P383, DOI 10.1111/j.1460-9568.2010.07279.x
   Kessler Y, 2015, PSYCHON B REV, V22, P1770, DOI 10.3758/s13423-015-0853-0
   Kim JH, 2010, NEUROIMAGE, V49, P2375, DOI 10.1016/j.neuroimage.2009.10.016
   Kirsten M, 2014, LANG COGN NEUROSCI, V29, P1147, DOI 10.1080/23273798.2014.899378
   Kotz SA, 2010, TRENDS COGN SCI, V14, P392, DOI 10.1016/j.tics.2010.06.005
   Krahmer E.J, 1998, PRESUPPOSITION ANAPH, P193
   Kummerer D, 2013, BRAIN, V136, P619, DOI 10.1093/brain/aws354
   Kuperberg GR, 2006, NEUROIMAGE, V33, P343, DOI 10.1016/j.neuroimage.2006.06.001
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Kwon YH, 2013, J PHYS THER SCI, V25, P1083, DOI 10.1589/jpts.25.1083
   Li Q, 2019, QUANT BIOL NEURONS C, V14
   Lima CF, 2016, TRENDS NEUROSCI, V39, P527, DOI 10.1016/j.tins.2016.06.003
   Mangold-Allwinn R, 1995, WORTER DINGE FLEXIBL, P19
   Mars RB, 2011, J NEUROSCI, V31, P4087, DOI 10.1523/JNEUROSCI.5102-10.2011
   Martin A, 2001, CURR OPIN NEUROBIOL, V11, P194, DOI 10.1016/S0959-4388(00)00196-3
   Masia V, 2017, J NEUROLINGUIST, V42, P31, DOI 10.1016/j.jneuroling.2016.11.005
   Matchin W, 2017, CORTEX, V88, P106, DOI 10.1016/j.cortex.2016.12.010
   Menenti L, 2009, J COGNITIVE NEUROSCI, V21, P2358, DOI 10.1162/jocn.2008.21163
   Miller EK, 2001, ANNU REV NEUROSCI, V24, P167, DOI 10.1146/annurev.neuro.24.1.167
   Mollo G, 2018, BRAIN LANG, V177, P23, DOI 10.1016/j.bandl.2018.01.001
   MORRIS N, 1990, BRIT J PSYCHOL, V81, P111, DOI 10.1111/j.2044-8295.1990.tb02349.x
   Napoli M, 2013, FOLIA LINGUIST, V47, P183, DOI 10.1515/flin.2013.008
   Nieuwland MS, 2012, NEUROIMAGE, V59, P3433, DOI 10.1016/j.neuroimage.2011.11.018
   Pallier C, 2011, P NATL ACAD SCI USA, V108, P2522, DOI 10.1073/pnas.1018711108
   Parker GJM, 2005, NEUROIMAGE, V24, P656, DOI 10.1016/j.neuroimage.2004.08.047
   Parola A, 2016, J NEUROLINGUIST, V39, P10, DOI 10.1016/j.jneuroling.2015.12.003
   Perrone-Bertolotti M, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00325
   Poldrack RA, 2007, SOC COGN AFFECT NEUR, V2, P67, DOI 10.1093/scan/nsm006
   Poldrack RA, 2009, SOC COGN AFFECT NEUR, V4, P208, DOI 10.1093/scan/nsp011
   Price AR, 2015, J NEUROSCI, V35, P3276, DOI 10.1523/JNEUROSCI.3446-14.2015
   Ptak R, 2004, NEUROCASE, V10, P52, DOI 10.1080/13554790490960495
   Raposo A, 2013, NEUROIMAGE, V83, P431, DOI 10.1016/j.neuroimage.2013.06.052
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Robertson DA, 2000, PSYCHOL SCI, V11, P255, DOI 10.1111/1467-9280.00251
   Rodriguez-Fornells A, 2009, PHILOS T R SOC B, V364, P3711, DOI 10.1098/rstb.2009.0130
   Rolke B, 2019, PROCESSING REF UNPUB
   Rong F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196381
   Rothermich K, 2013, NEUROIMAGE, V70, P89, DOI 10.1016/j.neuroimage.2012.12.013
   Saur D, 2010, NEUROIMAGE, V49, P3187, DOI 10.1016/j.neuroimage.2009.11.009
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Schlenker P, 2012, NAT LANG SEMANT, V20, P391, DOI 10.1007/s11050-012-9085-2
   Schwartze M, 2012, INT J PSYCHOPHYSIOL, V83, P200, DOI 10.1016/j.ijpsycho.2011.11.003
   Schwartze M, 2012, NEUROIMAGE, V60, P290, DOI 10.1016/j.neuroimage.2011.11.089
   Schwarz F., 2007, J SEMANT, V24, P373, DOI [10.1093/jos/ffm011, DOI 10.1093/JOS/FFM011]
   Schwarz F, 2017, J SEMANT, V34, P61, DOI 10.1093/jos/ffw005
   Schwarz F, 2016, ANNU REV LINGUIST, V2, P273, DOI 10.1146/annurev-linguistics-011415-040809
   Scott SK, 2004, J ACOUST SOC AM, V115, P813, DOI 10.1121/1.1639336
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   Seghier ML, 2013, NEUROSCIENTIST, V19, P43, DOI 10.1177/1073858412440596
   Simons M, 2003, PHILOS STUD, V112, P251, DOI 10.1023/A:1023004203043
   Singh R, 2016, COGNITIVE SCI, V40, P607, DOI 10.1111/cogs.12260
   Stalnaker R, 2002, LINGUIST PHILOS, V25, P701, DOI 10.1023/A:1020867916902
   Tettamanti M, 2008, NEUROIMAGE, V43, P358, DOI 10.1016/j.neuroimage.2008.08.004
   Thiebaut de Schotten M, 2012, CORTEX, V48, P82, DOI 10.1016/j.cortex.2011.10.001
   Tiemann S., 2011, P SINN BEDEUTUNG, V15, P581
   Tromp D, 2015, AGEING RES REV, V24, P232, DOI 10.1016/j.arr.2015.08.006
   Tulving Endel, 1995, P839
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Uddin LQ, 2010, CEREB CORTEX, V20, P2636, DOI 10.1093/cercor/bhq011
   Vagharchakian L, 2012, J NEUROSCI, V32, P9089, DOI 10.1523/JNEUROSCI.5685-11.2012
   van Berkum JJA, 1999, J COGNITIVE NEUROSCI, V11, P657, DOI 10.1162/089892999563724
   van Berkum JJA, 2003, COGNITIVE BRAIN RES, V17, P701, DOI 10.1016/S0926-6410(03)00196-4
   van Berkum JJA, 1999, J MEM LANG, V41, P147, DOI 10.1006/jmla.1999.2641
   Vassal F, 2014, BRIT J NEUROSURG, V28, P685, DOI 10.3109/02688697.2014.889810
   von Fintel K, 2008, PHILOS PERSPECT, V22, P137, DOI 10.1111/j.1520-8583.2008.00144.x
   Wiecki TV, 2013, PSYCHOL REV, V120, P329, DOI 10.1037/a0031542
   Zhang JX, 2003, NEUROIMAGE, V20, P1531, DOI 10.1016/j.neuroimage.2003.07.016
NR 124
TC 0
Z9 0
U1 2
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD NOV 15
PY 2019
VL 202
AR 116047
DI 10.1016/j.neuroimage.2019.116047
PG 16
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA JG1TX
UT WOS:000491861000031
PM 31349069
OA Other Gold
DA 2021-02-24
ER

PT J
AU Scott, TL
   Perrachione, TK
AF Scott, Terri L.
   Perrachione, Tyler K.
TI Common cortical architectures for phonological working memory identified
   in individual brains
SO NEUROIMAGE
LA English
DT Article
DE fMRI; Individual-subject analyses; Nonword discrimination; Nonword
   repetition; Phonological working memory; Pseudowords
ID SHORT-TERM-MEMORY; SENSORY-MOTOR INTEGRATION; SUPERIOR TEMPORAL GYRUS;
   NONWORD REPETITION; COMPREHENSION EVIDENCE; LANGUAGE-DEVELOPMENT;
   READING DEVELOPMENT; SPEECH-PERCEPTION; SPOKEN LANGUAGE; CHILDREN
AB Phonological working memory is the capacity to briefly maintain and recall representations of sounds important for speech and language and is believed to be critical for language and reading acquisition. Whether phonological working memory is supported by fronto-parietal brain regions associated with short-term memory storage or perisylvian brain structures implicated in speech perception and production is unclear, perhaps due to variability in stimuli, task demands, and individuals. We used fMRI to assess neurophysiological responses while individuals performed two tasks with closely matched stimuli but divergent task demands-nonword repetition and nonword discrimination-at two levels of phonological working memory load. Using analyses designed to address inter-subject variability, we found significant neural responses to the critical contrast of high vs. low phonological working memory load in both tasks in a set of regions closely resembling those involved in speech perception and production. Moreover, within those regions, the voxel-wise patterns of load-related activation were highly correlated between the two tasks. These results suggest that brain regions in the temporal and frontal lobes encapsulate the core neurocomputational components of phonological working memory; an architecture that becomes increasingly evident as neural responses are examined in successively finer-grained detail in individual participants.
C1 [Scott, Terri L.] Boston Univ, Grad Program Neurosci, Boston, MA 02215 USA.
   [Perrachione, Tyler K.] Boston Univ, Dept Speech Language & Hearing Sci, Boston, MA 02215 USA.
RP Perrachione, TK (corresponding author), 635 Commonwealth Ave, Boston, MA 02215 USA.
EM tkp@bu.edu
FU National Institute on Deafness and Other Communications Disorders at the
   National Institutes of Health [R03DC014045]; NARSAD Young Investigator
   GrantNARSAD; National Institute on Drug Abuse Computational Neuroscience
   Training Grant [T90DA032484]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R03DC014045,
   R03DC014045] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON DRUG
   ABUSEUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Drug Abuse
   (NIDA) [T90DA032484] Funding Source: NIH RePORTER
FX Research reported in this article was supported by the National
   Institute on Deafness and Other Communications Disorders at the National
   Institutes of Health under award number R03DC014045 and a NARSAD Young
   Investigator Grant to TP. TS was supported in part by the National
   Institute on Drug Abuse Computational Neuroscience Training Grant
   T90DA032484.
CR Acheson DJ, 2011, J COGNITIVE NEUROSCI, V23, P1358, DOI 10.1162/jocn.2010.21519
   Ackermann H, 2007, CEREBELLUM, V6, P202, DOI 10.1080/14734220701266742
   Adams AM, 1996, Q J EXP PSYCHOL-A, V49, P216, DOI 10.1080/027249896392874
   ADAMS AM, 1995, J SPEECH HEAR RES, V38, P403, DOI 10.1044/jshr.3802.403
   Adank P, 2010, NEUROIMAGE, V49, P1124, DOI 10.1016/j.neuroimage.2009.07.032
   Avants BB, 2008, MED IMAGE ANAL, V12, P26, DOI 10.1016/j.media.2007.06.004
   Awh E, 1996, PSYCHOL SCI, V7, P25, DOI 10.1111/j.1467-9280.1996.tb00662.x
   Baddeley A, 1998, PSYCHOL REV, V105, P158, DOI 10.1037/0033-295X.105.1.158
   Baddeley A, 2003, NAT REV NEUROSCI, V4, P829, DOI 10.1038/nrn1201
   Baddeley A. D, 1986, WORKING MEMORY
   BADDELEY AD, 1975, J VERB LEARN VERB BE, V14, P575, DOI 10.1016/S0022-5371(75)80045-4
   Baddeley A, 2010, CURR BIOL, V20, pR136, DOI 10.1016/j.cub.2009.12.014
   Barry JG, 2011, NEUROPSYCHOLOGIA, V49, P3636, DOI 10.1016/j.neuropsychologia.2011.09.018
   Basilakos A, 2018, CEREB CORTEX, V28, P1816, DOI 10.1093/cercor/bhx100
   BINDER JR, 1994, COGNITIVE BRAIN RES, V2, P31, DOI 10.1016/0926-6410(94)90018-3
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bowers A, 2018, J FLUENCY DISORD, V58, P94, DOI 10.1016/j.jfludis.2018.08.006
   Buchsbaum BR, 2005, NEURON, V48, P687, DOI 10.1016/j.neuron.2005.09.029
   Buchsbaum BR, 2001, COGNITIVE SCI, V25, P663, DOI 10.1207/s15516709cog2505_2
   Buchsbaum BR, 2011, BRAIN LANG, V119, P119, DOI 10.1016/j.bandl.2010.12.001
   Byrd CT, 2015, J FLUENCY DISORD, V44, P17, DOI 10.1016/j.jfludis.2015.01.004
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   Deen B, 2015, CEREB CORTEX, V25, P4596, DOI 10.1093/cercor/bhv111
   Dollaghan C, 1998, J SPEECH LANG HEAR R, V41, P1136, DOI 10.1044/jslhr.4105.1136
   Dufva M, 2001, READ WRIT, V14, P91, DOI 10.1023/A:1008186801932
   Eklund A, 2016, P NATL ACAD SCI USA, V113, P7900, DOI 10.1073/pnas.1602413113
   Epstein R, 1998, NATURE, V392, P598, DOI 10.1038/33402
   Estes KG, 2007, J SPEECH LANG HEAR R, V50, P177, DOI 10.1044/1092-4388(2007/015)
   Fedorenko E, 2013, P NATL ACAD SCI USA, V110, P16616, DOI 10.1073/pnas.1315235110
   Fedorenko E, 2012, CURR BIOL, V22, P2059, DOI 10.1016/j.cub.2012.09.011
   Fedorenko E, 2010, J NEUROPHYSIOL, V104, P1177, DOI 10.1152/jn.00032.2010
   Fegen D, 2015, NEUROIMAGE, V105, P120, DOI 10.1016/j.neuroimage.2014.10.034
   Fiez J.A, 2015, NEUROBIOLOGY LANGUAG, P855
   Fischl B, 2008, CEREB CORTEX, V18, P1973, DOI 10.1093/cercor/bhm225
   Frost MA, 2012, NEUROIMAGE, V59, P1369, DOI 10.1016/j.neuroimage.2011.08.035
   GAINOTTI G, 1982, ACTA NEUROL SCAND, V66, P652, DOI 10.1111/j.1600-0404.1982.tb04530.x
   Gathercole S E, 1994, Memory, V2, P103, DOI 10.1080/09658219408258940
   Gathercole S. E., 1996, CHILDRENS TEST NONWO
   Gathercole SE, 2006, J EXP CHILD PSYCHOL, V93, P265, DOI 10.1016/j.jecp.2005.08.003
   GATHERCOLE SE, 1993, EUR J PSYCHOL EDUC, V8, P259, DOI 10.1007/BF03174081
   Genon S, 2018, TRENDS COGN SCI, V22, P350, DOI 10.1016/j.tics.2018.01.010
   Gorgolewski Krzysztof, 2011, Front Neuroinform, V5, P13, DOI 10.3389/fninf.2011.00013
   Greve DN, 2009, NEUROIMAGE, V48, P63, DOI 10.1016/j.neuroimage.2009.06.060
   Hall DA, 1999, HUM BRAIN MAPP, V7, P213, DOI 10.1002/(SICI)1097-0193(1999)7:3<213::AID-HBM5>3.0.CO;2-N
   Haxby JV, 2001, SCIENCE, V293, P2425, DOI 10.1126/science.1063736
   Hickok G, 2008, BRAIN LANG, V107, P179, DOI 10.1016/j.bandl.2008.09.006
   Hickok G, 2009, J NEUROPHYSIOL, V101, P2725, DOI 10.1152/jn.91099.2008
   Jacquemot C, 2006, TRENDS COGN SCI, V10, P480, DOI 10.1016/j.tics.2006.09.002
   Jenkinson M, 2012, NEUROIMAGE, V62, P782, DOI 10.1016/j.neuroimage.2011.09.015
   Julian JB, 2012, NEUROIMAGE, V60, P2357, DOI 10.1016/j.neuroimage.2012.02.055
   Kanwisher N, 1997, J NEUROSCI, V17, P4302
   Kjelgaard MM, 2001, LANG COGNITIVE PROC, V16, P287, DOI 10.1080/01690960042000058
   Koenigs M, 2011, NEUROPSYCHOLOGIA, V49, P3612, DOI 10.1016/j.neuropsychologia.2011.09.013
   Kovelman I, 2012, CEREB CORTEX, V22, P754, DOI 10.1093/cercor/bhr094
   Kriegeskorte N, 2009, NAT NEUROSCI, V12, P535, DOI 10.1038/nn.2303
   Laird AR, 2005, NEUROINFORMATICS, V3, P65, DOI 10.1385/NI:3:1:065
   Lanfranchi S, 2009, CHILD NEUROPSYCHOL, V15, P397, DOI 10.1080/09297040902740652
   Leff AP, 2009, BRAIN, V132, P3401, DOI 10.1093/brain/awp273
   Lim SJ, 2015, J NEUROSCI, V35, P16094, DOI 10.1523/JNEUROSCI.2674-15.2015
   Mahowald K, 2016, NEUROIMAGE, V139, P74, DOI 10.1016/j.neuroimage.2016.05.073
   Majerus S, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00357
   Martin RC, 2005, CURR DIR PSYCHOL SCI, V14, P204, DOI 10.1111/j.0963-7214.2005.00365.x
   McGettigan C, 2011, J COGNITIVE NEUROSCI, V23, P961, DOI 10.1162/jocn.2010.21491
   Meyer F., 1991, 8 C REC FORM INT ART
   Michalka SW, 2015, NEURON, V87, P882, DOI 10.1016/j.neuron.2015.07.028
   Nieto-Castanon A, 2012, NEUROIMAGE, V63, P1646, DOI 10.1016/j.neuroimage.2012.06.065
   Noyce AL, 2017, J NEUROSCI, V37, P8755, DOI 10.1523/JNEUROSCI.0660-17.2017
   PAULESU E, 1993, NATURE, V362, P342, DOI 10.1038/362342a0
   Peelle JE, 2004, BRAIN LANG, V91, P315, DOI 10.1016/j.bandl.2004.05.007
   Peelle JE, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00309
   Peirce J.W, 2019, BEHAV RES METHODS, V162, P8
   Perrachione TK, 2017, J SPEECH LANG HEAR R, V60, P1959, DOI 10.1044/2017_JSLHR-L-15-0446
   Perrachione TK, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00055
   Peter B, 2011, J NEURODEV DISORD, V3, P39, DOI 10.1007/s11689-010-9065-0
   Peterburs J, 2019, BRAIN STRUCT FUNCT, V224, P485, DOI 10.1007/s00429-018-1784-0
   Pisoni A, 2019, BRAIN STRUCT FUNCT, V224, P2199, DOI 10.1007/s00429-019-01902-z
   Rogalsky C, 2015, NEUROPSYCHOLOGIA, V71, P18, DOI 10.1016/j.neuropsychologia.2015.03.012
   Rogalsky C, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.014.2008
   Salmon E, 1996, BRAIN, V119, P1617, DOI 10.1093/brain/119.5.1617
   Savill N, 2015, CORTEX, V63, P132, DOI 10.1016/j.cortex.2014.08.018
   Saxe R, 2003, NEUROIMAGE, V19, P1835, DOI 10.1016/S1053-8119(03)00230-1
   Siegel JS, 2014, HUM BRAIN MAPP, V35, P1981, DOI 10.1002/hbm.22307
   Smith EE, 1998, P NATL ACAD SCI USA, V95, P12061, DOI 10.1073/pnas.95.20.12061
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Strand F, 2008, BRAIN RES, V1212, P48, DOI 10.1016/j.brainres.2008.02.097
   Tahmasebi AM, 2012, CEREB CORTEX, V22, P1593, DOI 10.1093/cercor/bhr205
   TOOTELL RBH, 1995, J NEUROSCI, V15, P3215
   Vagharchakian L, 2012, J NEUROSCI, V32, P9089, DOI 10.1523/JNEUROSCI.5685-11.2012
   van der Schuit M, 2011, RES DEV DISABIL, V32, P1884, DOI 10.1016/j.ridd.2011.03.015
   Vitevitch MS, 2016, ANNU REV LINGUIST, V2, P75, DOI 10.1146/annurev-linguistics-030514-124832
   Vitevitch MS, 2004, BEHAV RES METH INS C, V36, P481, DOI 10.3758/BF03195594
   Vul E, 2010, FDN ISSUES HUMAN BRA
   Wagner R, 1999, COMPREHENSIVE TEST P
   Xie X, 2018, J COGNITIVE NEUROSCI, V30, P267, DOI 10.1162/jocn_a_01208
   Yarkoni T, 2011, NAT METHODS, V8, P665, DOI [10.1038/NMETH.1635, 10.1038/nmeth.1635]
   Yue QH, 2019, CEREB CORTEX, V29, P1398, DOI 10.1093/cercor/bhy037
NR 96
TC 1
Z9 1
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD NOV 15
PY 2019
VL 202
AR 116096
DI 10.1016/j.neuroimage.2019.116096
PG 15
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA JG1TX
UT WOS:000491861000020
PM 31415882
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Gheller, F
   Lovo, E
   Arsie, A
   Bovo, R
AF Gheller, Flavia
   Lovo, Elisa
   Arsie, Athena
   Bovo, Roberto
TI Classroom acoustics: Listening problems in children
SO BUILDING ACOUSTICS
LA English
DT Article
DE Classroom acoustics; listening skills in children; problems of speech
   perception
ID MATRIX SENTENCE TEST; SPEECH-PERCEPTION; NORMAL-HEARING; ROOM ACOUSTICS;
   OPEN PLAN; NOISE; INTELLIGIBILITY; REVERBERATION; SCHOOL; DISCRIMINATION
AB The acoustic quality of classrooms is crucial for children's listening skills and consequently for their learning. Listening abilities in kids are still developing, and an environment with inadequate acoustic characteristics may create additional problems in speech perception and phonetic recognition. Background noise or reverberation may cause auditory processing problems and greater cognitive effort. There are also other elements which can make difficulty in listening and understanding in noisy environments an even more serious problem, such as learning disabilities, mild to severe hearing loss or bilingualism. Therefore, it is important to improve the acoustic quality of the classrooms, taking into account the specific needs of children in terms of signal-to-noise ratio and reverberation time, in order to ensure a proper quality of listening. The aim of this work is to analyse, through the review of previous studies, the impact that the acoustic of classrooms has on children's listening skills and learning activities.
C1 [Gheller, Flavia; Lovo, Elisa; Arsie, Athena; Bovo, Roberto] Padova Univ Hosp, Sect Otolaryngol, Dept Neurosci DNS, Via Giuseppe De Leva, I-435128 Padua, Italy.
RP Gheller, F (corresponding author), Padova Univ Hosp, Sect Otolaryngol, Dept Neurosci DNS, Via Giuseppe De Leva, I-435128 Padua, Italy.
EM ghellerflavia@gmail.com
OI GHELLER, FLAVIA/0000-0002-0244-8488
CR American National Standards Institute/Acoustical Society of America, 2010, S12602010 ANSIASA
   Astolfi A, 2019, 23 INT C AC AACH 9 1
   Barnett DL, 1982, LANG SPEECH HEAR SER, V13, P138
   Bovo R, 2018, ACTA OTORHINOLARYNGO, V38, P536, DOI 10.14639/0392-100X-1846
   Bovo R, 2009, ACTA OTORHINOLARYNGO, V29, P203
   Bovo R, 2013, INT J OCCUP MED ENV, V26, P363, DOI 10.2478/s13382-013-0115-1
   Breitsprecher C., 2011, EFFECTS REVERBERATIO
   Cabral F, 2016, INT ARCH OTORHINOLAR, V20, P69, DOI 10.1055/s-0035-1559586
   Caldwell A, 2013, J SPEECH LANG HEAR R, V56, P13, DOI 10.1044/1092-4388(2012/11-0338)
   Cano S, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072154
   Ching TYC, 2018, INT J AUDIOL, V57, pS70, DOI 10.1080/14992027.2017.1346307
   Ching TYC, 2011, J ACOUST SOC AM, V129, P368, DOI 10.1121/1.3523295
   Crandell CC, 2000, LANG SPEECH HEAR SER, V31, P362, DOI 10.1044/0161-1461.3104.362
   Department for Education and Skills, 2003, BUILD B 93 AC DES SC
   Di Stadio A, 2018, AUDIOL NEURO-OTOL, V23, P238, DOI 10.1159/000493722
   Dockrell JE, 2004, J ACOUST SOC AM, V115, P2964, DOI 10.1121/1.1652610
   Edwards J, 2002, J SPEECH LANG HEAR R, V45, P231, DOI 10.1044/1092-4388(2002/018)
   ELLIOTT LL, 1989, J SPEECH HEAR RES, V32, P112, DOI 10.1044/jshr.3201.112
   Ertmer DJ, 2010, J SPEECH LANG HEAR R, V53, P1075, DOI 10.1044/1092-4388(2010/09-0250)
   Fabiano-Smith L, 2010, INT J BILING EDUC BI, V13, P81, DOI 10.1080/13670050902783528
   Finitzo T., 1988, AUDITORY DISORDERS S, V2, P221
   FINITZOHIEBER T, 1978, J SPEECH HEAR RES, V21, P440, DOI 10.1044/jshr.2103.440
   Gheller F, 2018, INT C EUR 2018 11 EU
   Goldstein BA, 2005, LANG SPEECH HEAR SER, V36, P201, DOI 10.1044/0161-1461(2005/021)
   Grant KW, 1998, J ACOUST SOC AM, V103, P2677, DOI 10.1121/1.422788
   Hazrati O, 2012, INT J AUDIOL, V51, P437, DOI 10.3109/14992027.2012.658972
   Heinrich A, 2008, Q J EXP PSYCHOL, V61, P735, DOI 10.1080/17470210701402372
   Hochmuth S, 2013, 11 EFAS C BUD 19 22
   Hodgson M, 2002, J ACOUST SOC AM, V111, P931, DOI 10.1121/1.1428264
   Hurtig A, 2016, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.02029
   Hwang JS, 2017, J AUDIOL OTOL, V21, P81, DOI 10.7874/jao.2017.21.2.81
   Iglehart F, 2016, AM J AUDIOL, V25, P100, DOI 10.1044/2016_AJA-15-0064
   Klatte M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00578
   Klatte M, 2010, NOISE HEALTH, V12, P270, DOI 10.4103/1463-1741.70506
   Klatte M, 2010, ENVIRON BEHAV, V42, P659, DOI 10.1177/0013916509336813
   Klatte Maria, 2007, Noise Health, V9, P64
   Kokkinakis K, 2011, J ACOUST SOC AM, V130, P1099, DOI 10.1121/1.3614539
   Kyzar BL., 1971, COMP INSTRUCTIONAL P
   Mealings K, 2016, 2 AUSTR AC SOC C BRI
   Mealings KT, 2015, J ACOUST SOC AM, V138, P2458, DOI 10.1121/1.4931903
   Nabelek A., 1994, HDB CLIN AUDIOL, V4, P624
   National Institute for Health and Care Excellence, 2009, COCHL IMPL CHILDR AD
   NEUMAN AC, 1983, J ACOUST SOC AM, V73, P2145, DOI 10.1121/1.389538
   Nicolosi L, 1996, TERMINOLOGY COMMUNIC
   Ozimek E, 2012, SPEECH COMMUN, V54, P1121, DOI 10.1016/j.specom.2012.06.001
   Peelle JE, 2018, EAR HEARING, V39, P204, DOI 10.1097/AUD.0000000000000494
   Picard M, 2001, AUDIOLOGY, V40, P221
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Picou EM, 2016, EAR HEARING, V37, P1, DOI 10.1097/AUD.0000000000000222
   Prodi N, 2019, LANG SPEECH HEAR SER, V50, P196, DOI 10.1044/2018_LSHSS-18-0039
   Prodi N, 2015, J ACOUST SOC AM, V138, P2438, DOI 10.1121/1.4932053
   Puglisi GE, 2018, J ACOUST SOC AM, V144, pEL144, DOI 10.1121/1.5051050
   Puglisi GE, 2015, INT J AUDIOL, V54, P44, DOI 10.3109/14992027.2015.1061709
   Rogers CL, 2006, APPL PSYCHOLINGUIST, V27, P465, DOI 10.1017/S014271640606036X
   Ronsse LM, 2013, J ACOUST SOC AM, V133, P1480, DOI 10.1121/1.4789356
   Sato H, 2008, J ACOUST SOC AM, V123, P2064, DOI 10.1121/1.2839283
   Shield B, 2010, NOISE HEALTH, V12, P225, DOI 10.4103/1463-1741.70501
   Stuart A, 2005, EAR HEARING, V26, P78, DOI 10.1097/00003446-200502000-00007
   SUSSMAN JE, 1989, J SPEECH HEAR RES, V32, P151, DOI 10.1044/jshr.3201.151
   Theelen-van den Hoek FL, 2014, INT J AUDIOL, V53, P817, DOI 10.3109/14992027.2014.922223
   van Reenen C, 2017, S AFR J COMMUN DISOR, V64, DOI 10.4102/sajcd.v64i1.550
   Visentin C, 2018, BUILD ENVIRON, V136, P38, DOI 10.1016/j.buildenv.2018.03.020
   WHO, 1999, GUIDELINES COMMUNITY
   WRIGHT PF, 1988, J PEDIATR-US, V113, P581, DOI 10.1016/S0022-3476(88)80659-0
   Yang W, 2009, J ACOUST SOC AM, V125, P922, DOI 10.1121/1.3058900
NR 65
TC 1
Z9 1
U1 0
U2 8
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1351-010X
EI 2059-8025
J9 BUILD ACOUST
JI Build. Acoustics
PD MAR
PY 2020
VL 27
IS 1
BP 47
EP 59
AR 1351010X19886035
DI 10.1177/1351010X19886035
EA NOV 2019
PG 13
WC Acoustics
SC Acoustics
GA KI3HJ
UT WOS:000497087800001
DA 2021-02-24
ER

PT J
AU Gold, R
   Segal, O
AF Gold, Rinat
   Segal, Osnat
TI The Bouba-Kiki Effect in Persons with Prelingual Auditory Deprivation
SO LANGUAGE LEARNING AND DEVELOPMENT
LA English
DT Article
ID SOUND-SYMBOLISM; SPEECH-PERCEPTION; HEARING-LOSS; SHAPE; LANGUAGE;
   INFANTS; CORRESPONDENCES; VOCALIZATIONS; STIMULATION; EXPERIENCE
AB The "bouba-kiki effect" refers to the correspondence between arbitrary visual and auditory stimuli. Previous studies have demonstrated that neurodevelopmental conditions and sensory impairment affect subjects' performance on the bouba-kiki task. This study examined the bouba-kiki effect in participants with severe-to-profound hearing loss. Sixteen participants with severe- to- profound hearing loss who were habilitated aurally and used oral language for everyday communication and 16 matched hearing peers were presented with the bouba-kiki task auditorily and orthographically. Verbal intelligence (Wechsler Adult Intelligence Scale - Third Edition) was determined for all participants and was similar in both groups. Our results demonstrate a reduced bouba-kiki effect in participants with severe-to-profound hearing loss compared to their hearing peers, though they performed above chance level. Moreover, the age at the first use of a hearing device was associated with participants' performance on the bouba-kiki task in adulthood. Better performance was shown in participants who used a hearing device at infancy before 23 months of age. These results support a relationship between early auditory or linguistic deprivation, and performance on the bouba-kiki task, and are discussed in the light of the role of a sensitive period on the development of the effect. This study is the first to show that prelingual deafness affects cross-modal auditory-visual correspondence resulting in reduced sound symbolism.
C1 [Gold, Rinat; Segal, Osnat] Tel Aviv Univ, Sackler Fac Med, Sch Hlth Profess, Dept Commun Disorders, Tel Aviv, Israel.
RP Gold, R (corresponding author), Tel Aviv Univ, Sackler Fac Med, Sch Hlth Profess, Dept Commun Disorders, Tel Aviv, Israel.
EM rinatyagold@gmail.com
CR Asano M, 2015, CORTEX, V63, P196, DOI 10.1016/j.cortex.2014.08.025
   Bavelier D, 2002, NAT REV NEUROSCI, V3, P443, DOI 10.1038/nrn848
   Bottini R., 2018, PSYARXIV, V3, DOI [10.31234/osf.io/vbm4t, DOI 10.31234/OSF.IO/VBM4T]
   Bremner AJ, 2013, COGNITION, V126, P165, DOI 10.1016/j.cognition.2012.09.007
   Cuskley C, 2017, PSYCHOL RES-PSYCH FO, V81, P119, DOI 10.1007/s00426-015-0709-2
   Davidson Lisa S, 2011, Ear Hear, V32, p19S, DOI 10.1097/AUD.0b013e3181ffdb8b
   De Saussure Ferdinand, 1959, COURSE GEN LINGUISTI
   Fernandez-Prieto I, 2015, INFANT BEHAV DEV, V38, P77, DOI 10.1016/j.infbeh.2014.12.008
   Fort M., 2013, INT CHILD PHON C JUN
   Fort M, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12659
   Fryer L, 2014, COGNITION, V132, P164, DOI 10.1016/j.cognition.2014.03.015
   Gogate LJ, 2010, PSYCHOL REV, V117, P496, DOI 10.1037/a0019049
   Gold R, 2017, RES DEV DISABIL, V71, P11, DOI 10.1016/j.ridd.2017.09.017
   Graven T, 2018, ACTA PSYCHOL, V188, P200, DOI 10.1016/j.actpsy.2018.05.011
   GREENOUGH WT, 1987, CHILD DEV, V58, P539, DOI 10.2307/1130197
   Hung SM, 2017, PSYCHOL SCI, V28, P263, DOI 10.1177/0956797616677313
   Imai M, 2008, COGNITION, V109, P54, DOI 10.1016/j.cognition.2008.07.015
   Kantartzis K, 2011, COGNITIVE SCI, V35, P575, DOI 10.1111/j.1551-6709.2010.01169.x
   Karns CM, 2012, J NEUROSCI, V32, P9626, DOI 10.1523/JNEUROSCI.6488-11.2012
   Kohler W., 1947, GESTALT PSYCHOL INTR
   Kral A, 2006, PROG BRAIN RES, V157, P283, DOI 10.1016/S0079-6123(06)57018-9
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   Kuhl PK, 1996, J ACOUST SOC AM, V100, P2425, DOI 10.1121/1.417951
   Leake PA, 2008, JARO-J ASSOC RES OTO, V9, P349, DOI 10.1007/s10162-008-0127-x
   Lewkowicz DJ, 2009, TRENDS COGN SCI, V13, P470, DOI 10.1016/j.tics.2009.08.004
   Li ZL, 2015, INT J CLIN EXP MED, V8, P569
   Linda Drijvers, 2015, P 37 ANN M COGN SCI, P602
   Ling D., 1989, FDN SPOKEN LANGUAGE
   MacSweeney M, 2015, BRAIN, V138, P2468, DOI 10.1093/brain/awv197
   Maurer D, 2006, DEVELOPMENTAL SCI, V9, P316, DOI 10.1111/j.1467-7687.2006.00495.x
   Miyazaki M, 2013, P 35 ANN C COGN SCI, P3080
   Moeller MP, 2007, EAR HEARING, V28, P628, DOI 10.1097/AUD.0b013e31812564c9
   Monaghan P, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0299
   Monaghan P, 2012, J EXP PSYCHOL LEARN, V38, P1152, DOI 10.1037/a0027747
   NEELY JH, 1977, J EXP PSYCHOL GEN, V106, P226, DOI 10.1037/0096-3445.106.3.226
   Nygaard LC, 2009, COGNITION, V112, P181, DOI 10.1016/j.cognition.2009.04.001
   Oberman LM, 2008, SOC NEUROSCI-UK, V3, P348, DOI 10.1080/17470910701563681
   Occelli V, 2013, PERCEPTION, V42, P233, DOI 10.1068/p7357
   OLLER DK, 1988, CHILD DEV, V59, P441, DOI 10.1111/j.1467-8624.1988.tb01479.x
   Ozturk O, 2013, J EXP CHILD PSYCHOL, V114, P173, DOI 10.1016/j.jecp.2012.05.004
   Parault SJ, 2008, CONTEMP EDUC PSYCHOL, V33, P647, DOI 10.1016/j.cedpsych.2007.07.003
   Parault SJ, 2006, J PSYCHOLINGUIST RES, V35, P329, DOI 10.1007/s10936-006-9018-7
   Pejovic J, 2017, DEV PSYCHOL, V53, P581, DOI 10.1037/dev0000237
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Ramachandran V, 2001, J CONSCIOUSNESS STUD, V8, P3
   Ramachandran VS, 2003, SCI AM, V288, P52, DOI 10.1038/scientificamerican0503-52
   ROGERS SK, 1975, PERCEPTION, V4, P105, DOI 10.1068/p040105
   Ryugo DK, 2005, SCIENCE, V310, P1490, DOI 10.1126/science.1119419
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   Sharma A, 2009, J COMMUN DISORD, V42, P272, DOI 10.1016/j.jcomdis.2009.03.003
   Spector F, 2009, DEV PSYCHOL, V45, P175, DOI 10.1037/a0014171
   Spence C, 2007, ACOUST SCI TECHNOL, V28, P61, DOI 10.1250/ast.28.61
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Svantesson JO, 2017, WIRES COGN SCI, V8, DOI 10.1002/wcs.1441
   Svirsky MA, 2004, AUDIOL NEURO-OTOL, V9, P224, DOI 10.1159/000078392
   Taya S, 2014, I-PERCEPTION, V5, P403
   Tomblin JB, 2005, J SPEECH LANG HEAR R, V48, P853, DOI 10.1044/1092-4388(2005/059)
   Wechsler D., 1997, WAIS 3 ADM SCORING M
   WERKER JF, 1992, ANNU REV NEUROSCI, V15, P377, DOI 10.1146/annurev.ne.15.030192.002113
   Westbury C, 2005, BRAIN LANG, V93, P10, DOI 10.1016/j.bandl.2004.07.006
   Xia S, 2017, NEURAL PLAST, V2017, DOI 10.1155/2017/8986362
NR 61
TC 1
Z9 1
U1 4
U2 5
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1547-5441
EI 1547-3341
J9 LANG LEARN DEV
JI Lang. Learn. Dev.
PD JAN 2
PY 2020
VL 16
IS 1
BP 49
EP 60
DI 10.1080/15475441.2019.1685386
EA NOV 2019
PG 12
WC Psychology, Developmental; Linguistics; Language & Linguistics;
   Psychology, Experimental
SC Psychology; Linguistics
GA KS9US
UT WOS:000495106900001
DA 2021-02-24
ER

PT J
AU Shim, HJ
   Go, G
   Lee, H
   Choi, SW
   Won, JH
AF Shim, Hyun Joon
   Go, Geurim
   Lee, Heirim
   Choi, Sung Won
   Won, Jong Ho
TI Influence of Visual Deprivation on Auditory Spectral Resolution,
   Temporal Resolution, and Speech Perception
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE early blindness; late blindness; visual deprivation; spectral
   resolution; temporal resolution; speech perception
ID EARLY-BLIND; FUNCTIONAL CONNECTIVITY; SENSITIVE PERIOD; CORTEX;
   MODULATION; PITCH; DISCRIMINATION; INDIVIDUALS; PLASTICITY; CHILDREN
AB We evaluated whether blind subjects have advantages in auditory spectral resolution, temporal resolution, and speech perception in noise compared with sighted subjects. We also compared psychoacoustic performance between early blind (EB) subjects and late blind (LB) subjects. Nineteen EB subjects, 16 LB subjects, and 20 sighted individuals were enrolled. All subjects were right-handed with normal and symmetric hearing thresholds and without cognitive impairments. Three psychoacoustic measurements of the subjects' right ears were performed via an inserted earphone to determine spectral-ripple discrimination (SRD), temporal modulation detection (TMD), and speech recognition threshold (SRT) in noisy conditions. Acoustic change complex (ACC) responses were recorded during passive listening to standard ripple-inverted ripple stimuli. EB subjects exhibited better SRD than did LB (p = 0.020) and sighted (p = 0.003) subjects. TMD was better in EB (p < 0.001) and LB (p = 0.007) subjects compared with sighted subjects. SRD was positively correlated with the duration of blindness (r = 0.386, p = 0.024). Acoustic change complex data for ripple noise change at the Cz and Fz electrodes showed trends toward significant correlations with the behavioral results. In conclusion, compared with sighted subjects, EB subjects showed advantages in terms of auditory spectral and temporal resolution, while LB subjects showed an advantage in temporal resolution exclusively. These findings suggest that it might take longer for auditory spectral resolution to functionally enhance following visual deprivation compared to temporal resolution. Alternatively, a critical period of very young age may be required for auditory spectral resolution to improve following visual deprivation.
C1 [Shim, Hyun Joon] Eulji Univ, Sch Med, Eulji Med Ctr, Dept Otorhinolaryngol & Head & Neck Surg, Seoul, South Korea.
   [Go, Geurim; Lee, Heirim; Choi, Sung Won] Duksung Womens Univ, Dept Psychol, Seoul, South Korea.
   [Won, Jong Ho] US FDA, Div ENT Sleep Disordered Breathing Resp & Anesthe, Off Prod Evaluat & Qual, Ctr Devices & Radiol Hlth, Silver Spring, MD USA.
RP Shim, HJ (corresponding author), Eulji Univ, Sch Med, Eulji Med Ctr, Dept Otorhinolaryngol & Head & Neck Surg, Seoul, South Korea.
EM eardoc11@naver.com
FU National Research Foundation of Korea (NRF) - Korean Government (MSIT)
   [NRF-2019R1H1A2039693, NRF-2017R1A2B1007431]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korean Government (MSIT) (NRF-2019R1H1A2039693
   and NRF-2017R1A2B1007431).
CR ALLEN P, 1994, J SPEECH HEAR RES, V37, P205, DOI 10.1044/jshr.3701.205
   Amadeo MB, 2019, NEUROIMAGE, V191, P140, DOI 10.1016/j.neuroimage.2019.01.073
   Amedi A, 2003, NAT NEUROSCI, V6, P758, DOI 10.1038/nn1072
   Arnaud L, 2018, NEUROPSYCHOLOGIA, V117, P261, DOI 10.1016/j.neuropsychologia.2018.06.009
   Asal SI, 2018, EGYPT J OTOLARYNGOL, V34, P68, DOI 10.4103/ejo.ejo_78_17
   Bao SW, 2004, NAT NEUROSCI, V7, P974, DOI 10.1038/nn1293
   Bedny M, 2012, BRAIN LANG, V122, P162, DOI 10.1016/j.bandl.2011.10.005
   Bedny M, 2010, CURR BIOL, V20, P1900, DOI 10.1016/j.cub.2010.09.044
   Beer AL, 2011, EXP BRAIN RES, V213, P299, DOI 10.1007/s00221-011-2715-y
   BLAGOSKLONOVA N, 1989, INT J PSYCHOPHYSIOL, V7, P148, DOI 10.1016/0167-8760(89)90094-9
   BYRNE D, 1994, J ACOUST SOC AM, V96, P2108, DOI 10.1121/1.410152
   Campus C, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37821-y
   Cappagli G, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00467
   Cappagli G, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12374
   Chabot N, 2008, NEUROSCI LETT, V433, P129, DOI 10.1016/j.neulet.2008.01.003
   Collignon O, 2013, BRAIN, V136, P2769, DOI 10.1093/brain/awt176
   Collignon O, 2011, P NATL ACAD SCI USA, V108, P4435, DOI 10.1073/pnas.1013928108
   DUBNO JR, 1995, J ACOUST SOC AM, V97, P1165, DOI 10.1121/1.413057
   Eggermont JJ, 2002, J NEUROPHYSIOL, V87, P305, DOI 10.1152/jn.00490.2001
   Fieger A, 2006, J COGNITIVE NEUROSCI, V18, P149, DOI 10.1162/089892906775783697
   Finocchietti S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01357
   Gori M, 2008, CURR BIOL, V18, P694, DOI 10.1016/j.cub.2008.04.036
   Gori M, 2014, BRAIN, V137, P288, DOI 10.1093/brain/awt311
   Gori M, 2010, CURR BIOL, V20, P223, DOI 10.1016/j.cub.2009.11.069
   Gougoux F, 2004, NATURE, V430, P309, DOI 10.1038/430309a
   Gougoux F, 2009, NEUROPSYCHOLOGIA, V47, P2967, DOI 10.1016/j.neuropsychologia.2009.06.027
   Hamilton RH, 2004, NEUROREPORT, V15, P803, DOI 10.1097/00001756-200404090-00012
   Hertrich I, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00530
   Hugdahl K, 2004, COGNITIVE BRAIN RES, V19, P28, DOI 10.1016/j.cogbrainres.2003.10.015
   Karlen SJ, 2006, NEUROSCIENCE, V142, P843, DOI 10.1016/j.neuroscience.2006.06.055
   Leclerc C, 2000, NEUROREPORT, V11, P545, DOI 10.1097/00001756-200002280-00024
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Lewald J, 2002, NEUROPSYCHOLOGIA, V40, P1868, DOI 10.1016/S0028-3932(02)00071-4
   Martin BA, 1999, EAR HEARING, V20, P33, DOI 10.1097/00003446-199902000-00004
   Moos Anja, 2007, P 16 INT C PHON SCI, P677
   MUCHNIK C, 1991, SCAND AUDIOL, V20, P19, DOI 10.3109/01050399109070785
   Oxenham AJ, 2003, EAR HEARING, V24, P352, DOI 10.1097/01.AUD.0000090470.73934.78
   Pascual-Leone A, 2005, ANNU REV NEUROSCI, V28, P377, DOI 10.1146/annurev.neuro.27.070203.144216
   Pelland M, 2017, NEUROIMAGE, V147, P532, DOI 10.1016/j.neuroimage.2016.12.053
   Peter V, 2014, J AM ACAD AUDIOL, V25, P210, DOI 10.3766/jaaa.25.2.9
   Postma A, 2008, PERCEPT PSYCHOPHYS, V70, P1197, DOI 10.3758/PP.70.7.1197
   Qin W, 2015, CEREB CORTEX, V25, P2507, DOI 10.1093/cercor/bhu051
   Roder B, 1999, NATURE, V400, P162, DOI 10.1038/22106
   Rokem A, 2009, NEUROPSYCHOLOGIA, V47, P843, DOI 10.1016/j.neuropsychologia.2008.12.017
   Schnupp JWH, 2006, J NEUROSCI, V26, P4785, DOI 10.1523/JNEUROSCI.4330-05.2006
   Schulze H, 1997, J COMP PHYSIOL A, V181, P651, DOI 10.1007/s003590050147
   Stevens AA, 2005, NEUROPSYCHOLOGIA, V43, P1901, DOI 10.1016/j.neuropsychologia.2005.03.007
   Tao Q, 2015, BRAIN TOPOGR, V28, P506, DOI 10.1007/s10548-013-0339-1
   Tremblay KL, 2003, EAR HEARING, V24, P225, DOI 10.1097/01.AUD.0000069229.84883.03
   Vashist P, 2017, INDIAN J OPHTHALMOL, V65, P92, DOI 10.4103/ijo.IJO_869_16
   Vercillo T, 2016, DEV PSYCHOL, V52, P847, DOI 10.1037/dev0000103
   Voss P, 2008, NEUROIMAGE, V40, P746, DOI 10.1016/j.neuroimage.2007.12.020
   Voss P, 2014, BRAIN, V137, P1224, DOI 10.1093/brain/awu030
   Voss P, 2012, CEREB CORTEX, V22, P2455, DOI 10.1093/cercor/bhr311
   Wan CY, 2010, NEUROPSYCHOLOGIA, V48, P344, DOI 10.1016/j.neuropsychologia.2009.08.016
   Wang DW, 2013, NEURAL PLAST, V2013, DOI 10.1155/2013/128236
   Won JH, 2007, JARO-J ASSOC RES OTO, V8, P384, DOI 10.1007/s10162-007-0085-8
   Won JH, 2011, J ACOUST SOC AM, V130, P376, DOI 10.1121/1.3592521
   Won JH, 2011, JARO-J ASSOC RES OTO, V12, P375, DOI 10.1007/s10162-011-0257-4
   Zwiers MP, 2001, J NEUROSCI, V21, part. no., DOI 10.1523/JNEUROSCI.21-09-j0002.2001
NR 60
TC 1
Z9 1
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD NOV 6
PY 2019
VL 13
AR 1200
DI 10.3389/fnins.2019.01200
PG 11
WC Neurosciences
SC Neurosciences & Neurology
GA JP8PQ
UT WOS:000498521400001
PM 31780886
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Venail, F
   Picot, MC
   Marin, G
   Falinower, S
   Samson, J
   Cizeron, G
   Balcon, M
   Blanc, D
   Bricaud, J
   Lorenzi, A
   Ceccato, JC
   Puel, JL
AF Venail, Frederic
   Picot, Marie C.
   Marin, Gregory
   Falinower, Sylvain
   Samson, Jacques
   Cizeron, Gilles
   Balcon, Maxime
   Blanc, Denis
   Bricaud, Jeremy
   Lorenzi, Antoine
   Ceccato, Jean-Charles
   Puel, Jean-Luc
TI Speech perception, real-ear measurements and self-perceived hearing
   impairment after remote and face-to-face programming of hearing aids: A
   randomized single-blind agreement study
SO JOURNAL OF TELEMEDICINE AND TELECARE
LA English
DT Article; Early Access
DE Remote programming; hearing aids; agreement study; teleaudiology
ID COCHLEAR IMPLANTS; TELEHEALTH; TELEMEDICINE; AUDIOLOGY; USERS;
   VARIABILITY; RELIABILITY; VALIDATION; ATTITUDES; HEALTH
AB Introduction Current literature does not provide strong evidence that remote programming of hearing aids is effective, despite its increasing use by audiologists. We tested speech perception outcomes, real-ear insertion gain, and changes in self-perceived hearing impairment after face-to-face and remote programming of hearing aids in a randomized multicentre, single-blind crossover study. Methods Adult experienced hearing aid users were enrolled during routine follow-up visits to audiology clinics. Hearing aids were programmed both face to face and remotely, then participants randomly received either the face-to-face or remote settings in a blinded manner and were evaluated 5 weeks later. Participants then received the other settings and were evaluated 5 weeks later. Results Data from 52 out of 60 participants were analysed. We found excellent concordance in performance of hearing aids programmed face to face and remotely for speech understanding in quiet (phonetically balanced kindergarten test - intraclass correlation coefficient of 0.92 (95% confidence interval: 0.87-0.95)), and good concordance in performance for speech understanding in noise (phonetically balanced kindergarten +5 dB signal-to-noise ratio - intraclass correlation coefficient of 0.71 (95% confidence interval: 0.55-0.82)). Face-to-face and remote programming took 10 minutes (+/- 2.9) and 10 minutes (+/- 2.8), respectively. Real-ear insertion gains were highly correlated for input sound at 50, 65 and 80 dB sound pressure levels. The programming type did not affect the abbreviated profile of hearing aid questionnaire scores. Conclusions In experienced hearing aid users, face-to-face and remote programming of hearing aids give similar results in terms of speech perception, with no increase in the time spent on patients' care and no difference in self-reported hearing benefit. ClinicalTrials.gov Identifier NCT02589561
C1 [Venail, Frederic; Balcon, Maxime; Lorenzi, Antoine] Univ Hosp Gui de Chauliac, ENT & Audiol Dept, Montpellier, France.
   [Venail, Frederic; Lorenzi, Antoine; Ceccato, Jean-Charles; Puel, Jean-Luc] INSERM, Inst Neurosci Montpellier, Auditory Disorders, Montpellier, France.
   [Picot, Marie C.; Marin, Gregory] Univ Montpellier, Biostat & Clin Res Unit, Montpellier, France.
   [Falinower, Sylvain; Samson, Jacques; Cizeron, Gilles] AudioProConnect Co, Paris, France.
   [Balcon, Maxime; Lorenzi, Antoine] Alliance Audit, Montpellier, France.
   [Blanc, Denis] Audit Conseil, Nimes, France.
   [Bricaud, Jeremy] Audit Conseil, Perpignan, France.
   [Ceccato, Jean-Charles; Puel, Jean-Luc] Univ Montpellier, CREFA, Audiol Dept, Montpellier, France.
   [Ceccato, Jean-Charles; Puel, Jean-Luc] Univ Montpellier, Hearing Aid Dispenser Format Ctr, CREFA, Montpellier, France.
RP Venail, F (corresponding author), CHU Gui de Chauliac, Serv ORL, 80 Ave Augustin Fliche, F-34295 Montpellier, France.
EM f-venail@chu-montpellier.fr
RI Venail, Frederic/AAG-5682-2020
OI Venail, Frederic/0000-0001-9919-2126
FU University Hospital of Montpellier
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This study
   was funded by the University Hospital of Montpellier and
   AudioProConnect.
CR BEATTIE RC, 1976, J SPEECH HEAR DISORD, V41, P464, DOI 10.1044/jshd.4104.464
   Bexelius C, 2008, J MED INTERNET RES, V10, DOI 10.2196/jmir.1065
   Campos Patrícia Danieli, 2012, J. Soc. Bras. Fonoaudiol., V24, P301, DOI 10.1590/S2179-64912012000400003
   Choi JM, 2007, TELEMED J E-HEALTH, V13, P501, DOI 10.1089/tmj.2007.0085
   COX RM, 1995, EAR HEARING, V16, P176, DOI 10.1097/00003446-199504000-00005
   Davis A, 2016, GERONTOLOGIST, V56, pS256, DOI 10.1093/geront/gnw033
   Eikelboom RH, 2005, J TELEMED TELECARE, V11, P22, DOI 10.1258/135763305775124920
   Eikelboom RH, 2016, AM J AUDIOL, V25, P295, DOI 10.1044/2016_AJA-16-0004
   Emmett SD, 2015, OTOL NEUROTOL, V36, P545, DOI 10.1097/MAO.0000000000000562
   ENGELBERG M, 1968, LARYNGOSCOPE, V78, P1582, DOI 10.1288/00005537-196809000-00009
   Ferrari DV, 2009, J TELEMED TELECARE, V15, P122, DOI 10.1258/jtt.2009.003005
   Givens Gregg D, 2003, Am J Audiol, V12, P59, DOI 10.1044/1059-0889(2003/011)
   Hawley Monica L., 2017, Seminars in Hearing, V38, P3, DOI 10.1055/s-0037-1598063
   Hughes ML, 2012, J SPEECH LANG HEAR R, V55, P1112, DOI 10.1044/1092-4388(2011/11-0237)
   Jacobs PG, 2014, J REHABIL RES DEV, V51, pVII, DOI 10.1682/JRRD.2014.04.0093
   Kochkin S., 2009, HEARING REV, V16, P12
   Kochkin S., 2012, HEAR REV, V19, P12
   Kokesh J, 2008, OTOLARYNG HEAD NECK, V139, P87, DOI 10.1016/j.otohns.2008.04.008
   Kottner J, 2011, INT J NURS STUD, V48, P661, DOI 10.1016/j.ijnurstu.2011.01.016
   Krumm M, 2008, J TELEMED TELECARE, V14, P102, DOI 10.1258/jtt.2007.070612
   Krumm M, 2007, J TELEMED TELECARE, V13, P406, DOI 10.1258/135763307783064395
   Kuzovkov V, 2014, ACTA OTO-LARYNGOL, V134, P709, DOI 10.3109/00016489.2014.892212
   Lancaster P, 2008, AM J AUDIOL, V17, P114, DOI 10.1044/1059-0889(2008/07-0008)
   Laplante-Levesque A, 2006, INT J AUDIOL, V45, P697, DOI 10.1080/14992020600944408
   Liao JJZ, 2015, INT J BIOSTAT, V11, P125, DOI 10.1515/ijb-2014-0030
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P582, DOI 10.1093/gerona/glr002
   Lupi AL., 1998, ESSAI ADAPTATION LAN
   Marone S, 2013, INT ARCH OTORHINOLAR, V16, P371
   Marriage J, 2004, INT J AUDIOL, V43, P198, DOI 10.1080/14992020400050028
   McElveen JT, 2010, OTOL NEUROTOL, V31, P1035, DOI 10.1097/MAO.0b013e3181d35d87
   Molini-Avejonas DR, 2015, J TELEMED TELECARE, V21, P367, DOI 10.1177/1357633X15583215
   Moore BCJ, 2001, BRIT J AUDIOL, V35, P339, DOI 10.1080/00305364.2001.11745252
   Nelson PB, 2012, J ACOUST SOC AM, V132, P2077
   Penteado SP, 2014, JMIR MED INF, V2, P169, DOI 10.2196/medinform.2769
   Penteado SP, 2012, INT ARCH OTORHINOLAR, V16, P371, DOI 10.7162/S1809-97772012000300012
   Polonenko MJ, 2010, INT J AUDIOL, V49, P550, DOI 10.3109/14992021003713122
   Pross SE, 2016, OTOL NEUROTOL, V37, P847, DOI 10.1097/MAO.0000000000001058
   Ramkumar V, 2013, J TELEMED TELECARE, V19, P233, DOI 10.1177/1357633X13494691
   Ramos A, 2009, ACTA OTO-LARYNGOL, V129, P533, DOI 10.1080/00016480802294369
   Reginato Tatiana Turtelli Poles, 2014, Audiol., Commun. Res., V19, P299, DOI 10.1590/S2317-643120140003000015
   Ribera John E., 2005, Seminars in Hearing, V26, P13, DOI 10.1055/s-2005-863790
   Samuel PA, 2014, CODAS, V26, P481, DOI 10.1590/2317-1782/20142014007
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420
   Singh G, 2014, INT J AUDIOL, V53, P850, DOI 10.3109/14992027.2014.921736
   Smith AC, 2006, J TELEMED TELECARE, V12, P76, DOI 10.1258/135763306779380138
   Swanepoel DW, 2010, TELEMED J E-HEALTH, V16, P182, DOI 10.1089/tmj.2009.0111
   Swanepoel D, 2010, INT J AUDIOL, V49, P195, DOI 10.3109/14992020903470783
   Swanepoel D, 2009, EUR ARCH OTO-RHINO-L, V266, P213, DOI 10.1007/s00405-008-0738-1
   Tao KFM, 2018, J SPEECH LANG HEAR R, V61, P1831, DOI 10.1044/2018_JSLHR-H-16-0397
   Vincent C, 2017, INT J AUDIOL, V56, P248, DOI 10.1080/14992027.2016.1263398
   Wesendahl Theo, 2003, Int Tinnitus J, V9, P56
NR 51
TC 1
Z9 1
U1 4
U2 13
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1357-633X
EI 1758-1109
J9 J TELEMED TELECARE
JI J. Telemed. Telecare
AR 1357633X19883543
DI 10.1177/1357633X19883543
EA NOV 2019
PG 15
WC Health Care Sciences & Services
SC Health Care Sciences & Services
GA JM7MY
UT WOS:000496395100001
PM 31694484
DA 2021-02-24
ER

PT J
AU Simon, M
   Fromont, LA
   Le Normand, MT
   Leybaert, J
AF Simon, Marie
   Fromont, Lauren A.
   Le Normand, Marie-Therese
   Leybaert, Jacqueline
TI Spelling, Reading Abilities and Speech Perception in Deaf Children with
   a Cochlear Implant
SO SCIENTIFIC STUDIES OF READING
LA English
DT Article
ID HARD-OF-HEARING; CUED SPEECH; PHONOLOGICAL AWARENESS; LITERACY OUTCOMES;
   STUDENTS; RECOGNITION; INFORMATION; ACHIEVEMENT; SYSTEMS; SKILLS
AB This study aims to compare word spelling outcomes for French-speaking deaf children with a cochlear implant (CI) with hearing children who matched for age, level of education and gender. A picture written naming task controlling for word frequency, word length, and phoneme-to-grapheme predictability was designed to analyze spelling productions. A generalized linear mixed model on the percentage of correct spelling revealed an effect of participant?s reading abilities, but no effect of hearing status. Word frequency and word length, but not phoneme-to-grapheme predictability, contributed to explaining the spelling variance. Deaf children with a CI made significantly less phonologically plausible errors and more phonologically unacceptable errors when compared to their hearing peers. Age at implantation and speech perception scores were related to deaf children?s errors. A good word spelling level can be achieved by deaf children with a CI, who nonetheless use less efficiently the phoneme-to-grapheme strategy than do hearing children.
C1 [Simon, Marie] Univ Montreal, Ctr Rech Neuropsychol & Cognit, Dept Psychol, Montreal, PQ, Canada.
   [Fromont, Lauren A.] Univ Montreal, Ecole Orthophonie & Audiol, Montreal, PQ, Canada.
   [Fromont, Lauren A.] CRBLM, Fac Med, Montreal, PQ, Canada.
   [Le Normand, Marie-Therese] Univ Paris 05, INSERM, Boulogne, Billancourt, France.
   [Le Normand, Marie-Therese] Univ Paris 05, Lab Psychopathol & Proc Sante, Boulogne, Billancourt, France.
   [Leybaert, Jacqueline] ULB, CRCN, B-1050 Brussels, Belgium.
RP Leybaert, J (corresponding author), ULB, CRCN, B-1050 Brussels, Belgium.
EM leybaert@ulb.ac.be
RI Le Normand, Marie-Therese/P-2026-2019
OI Le Normand, Marie-Therese/0000-0002-6952-5150
CR Aaron PG, 1998, READ WRIT, V10, P1, DOI 10.1023/A:1007917929226
   Apel K, 2015, J DEAF STUD DEAF EDU, V20, P125, DOI 10.1093/deafed/env002
   Arfe B, 2016, HEARING BALANC COMMU, V14, P103, DOI 10.1080/21695717.2016.1197619
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Bayard C, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00416
   Bertranrd D, 2010, ANN PSYCHOL, V110, P299
   Bouton S., 2014, WRITING DEV CHILDREN, P583, DOI [10.1093/acprof:oso/9780199827282.003.0005, DOI 10.1093/ACPROF:OSO/9780199827282.003.0005]
   Bowers L, 2014, VOLTA REV, V114, P29
   Caravolas M, 2004, EUR PSYCHOL, V9, P3, DOI 10.1027/1016-9040.9.1.3
   Colin S, 2013, RES DEV DISABIL, V34, P1781, DOI 10.1016/j.ridd.2013.02.001
   Colin S, 2010, Cochlear Implants Int, V11 Suppl 1, P278, DOI 10.1179/146701010X12671177989192
   Colombo L, 2012, READ WRIT, V25, P2021, DOI 10.1007/s11145-011-9343-6
   CORNETT RO, 1967, AM ANN DEAF, V112, P3
   Descourtieux C., 2003, TERMO TESTS RECEPTIO
   HANSON VL, 1991, J MEM LANG, V30, P319, DOI 10.1016/0749-596X(91)90039-M
   Harris M., 2016, OXFORD HDB DEAF STUD, P407, DOI DOI 10.1093/DEAFED/ENQ031
   Harris M, 2017, J SPEECH LANG HEAR R, V60, P701, DOI 10.1044/2016_JSLHR-H-15-0403
   Harris M, 2011, J DEAF STUD DEAF EDU, V16, P24, DOI 10.1093/deafed/enq031
   Hayes H, 2011, SCI STUD READ, V15, P522, DOI 10.1080/10888438.2010.528480
   Huyse A, 2013, EAR HEARING, V34, P110, DOI 10.1097/AUD.0b013e3182670993
   Khomsi A., 1999, EPREUVE EVALUATION C
   Kral A, 2013, NEUROSCIENCE, V247, P117, DOI 10.1016/j.neuroscience.2013.05.021
   Kral A, 2016, LANCET NEUROL, V15, P610, DOI 10.1016/S1474-4422(16)00034-X
   Kyle FE, 2006, J DEAF STUD DEAF EDU, V11, P273, DOI 10.1093/deafed/enj037
   Lee HJ, 2005, HEARING RES, V203, P2, DOI 10.1016/j.heares.2004.11.005
   Lee HJ, 2007, CEREB CORTEX, V17, P909, DOI 10.1093/cercor/bhl001
   LEYBAERT J, 1995, READ WRIT, V7, P89, DOI 10.1007/BF01026949
   Leybaert J, 2001, J EDUC PSYCHOL, V93, P554
   Leybaert J, 2000, J EXP CHILD PSYCHOL, V75, P291, DOI 10.1006/jecp.1999.2539
   Leybaert J., 2012, LECT PATHOLOGIES LAN, P75
   Leybaert J., 2009, LINEAS ACTUALES ESTU, P186
   Leybaert J, 2010, TRENDS AMPLIF, V14, P96, DOI 10.1177/1084713810375567
   Mayer C., 2010, OXFORD HDB DEAF STUD, V2, P144
   Mayer C, 2018, J DEAF STUD DEAF EDU, V23, P1, DOI 10.1093/deafed/enx043
   Mayer C, 2016, DEAF EDUC INT, V18, P71, DOI 10.1080/14643154.2016.1155346
   Mousty M., 1999, EUR REV APPL PSYCHOL, V49, P325
   Nittrouer S, 2014, EAR HEARING, V35, P506, DOI 10.1097/AUD.0000000000000051
   Ortega E., 2010, EMANULEX ELECT VERSI
   Perfetti Charles A., 2000, J DEAF STUD DEAF EDU, V5, P32, DOI [DOI 10.1093/DEAFED/5.1.32, 10.1093/deafed/5.1.32]
   Pisoni DB, 2003, EAR HEARING, V24, p106S, DOI 10.1097/01.AUD.0000051692.05140.8E
   Qi S, 2012, J DEAF STUD DEAF EDU, V17, P1, DOI 10.1093/deafed/enr028
   Quene H, 2008, J MEM LANG, V59, P413, DOI 10.1016/j.jml.2008.02.002
   Quick N, 2019, J DEAF STUD DEAF EDU, V24, P41, DOI 10.1093/deafed/eny029
   Rees R, 2013, DEAF EDUC INT, V15, P182, DOI 10.1179/1557069X13Y.0000000025
   Rogerson PA, 2001, GEOGR ANAL, V33, P215
   Rouger J, 2008, BRAIN RES, V1188, P87, DOI 10.1016/j.brainres.2007.10.049
   Roy P, 2015, RES DEV DISABIL, V36, P277, DOI 10.1016/j.ridd.2014.10.012
   Saefken B, 2014, ELECTRON J STAT, V8, P201, DOI 10.1214/14-EJS881
   Sutcliffe A., 1999, J DEAF STUD DEAF EDU, V4, P111, DOI [10.1093/deafed/4.2.111, DOI 10.1093/DEAFED/4.2.111]
   Tabachnick B. G., 2001, USING MULTIVARIATE S
   Team RC, 2016, R LANG ENV STAT COMP
   Trezek B. J, 2010, READING DEAFNESS THE
   Trezek BJ, 2017, J DEAF STUD DEAF EDU, V22, P349, DOI 10.1093/deafed/enx026
   Turgeon C, 2014, CLIN NEUROPHYSIOL, V125, P827, DOI 10.1016/j.clinph.2013.09.035
   VERONIS J, 1986, CAH PSYCHOL COGN, V6, P501
   Wieling M., 2015, MIXED EFFECTS REGRES
   Willems P., 2009, REV LOGOPEDIA FONIAT, V29, P174, DOI DOI 10.1016/S0214-4603(09)70026-9
   Williams C, 2015, REV EDUC RES, V85, P630, DOI 10.3102/0034654314564882
   Wilson BS, 2008, HEARING RES, V242, P3, DOI 10.1016/j.heares.2008.06.005
   Ziegler JC, 1996, BEHAV RES METH INSTR, V28, P504, DOI 10.3758/BF03200539
NR 62
TC 1
Z9 1
U1 1
U2 21
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1088-8438
EI 1532-799X
J9 SCI STUD READ
JI Sci. Stud. Read.
PD NOV 2
PY 2019
VL 23
IS 6
BP 494
EP 508
DI 10.1080/10888438.2019.1613407
PG 15
WC Education & Educational Research; Psychology, Educational
SC Education & Educational Research; Psychology
GA JH5DU
UT WOS:000492790100003
DA 2021-02-24
ER

PT J
AU Gianakas, SP
   Winn, MB
AF Gianakas, Steven P.
   Winn, Matthew B.
TI Lexical bias in word recognition by cochlear implant listeners
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH RECOGNITION; PHONETIC CATEGORIZATION; NORMAL-HEARING; VOWEL
   IDENTIFICATION; SPECTRAL RESOLUTION; PERCEPTION; CUES; USERS; CONTEXT;
   NOISE
AB When hearing an ambiguous speech sound, listeners show a tendency to perceive it as a phoneme that would complete a real word, rather than completing a nonsense/fake word. For example, a sound that could be heard as either /b/ or /g/ is perceived as /b/ when followed by _ack but perceived as /g/ when followed by "_ap." Because the target sound is acoustically identical across both environments, this effect demonstrates the influence of top-down lexical processing in speech perception. Degradations in the auditory signal were hypothesized to render speech stimuli more ambiguous, and therefore promote increased lexical bias. Stimuli included three speech continua that varied by spectral cues of varying speeds, including stop formant transitions (fast), fricative spectra (medium), and vowel formants (slow). Stimuli were presented to listeners with cochlear implants (CIs), and also to listeners with normal hearing with clear spectral quality, or with varying amounts of spectral degradation using a noise vocoder. Results indicated an increased lexical bias effect with degraded speech and for CI listeners, for whom the effect size was related to segment duration. This method can probe an individual's reliance on top-down processing even at the level of simple lexical/phonetic perception. (C) 2019 Acoustical Society of America.
C1 [Gianakas, Steven P.; Winn, Matthew B.] Univ Minnesota, Dept Speech Language Hearing Sci, 164 Pillsbury Dr SE, Minneapolis, MN 55455 USA.
RP Winn, MB (corresponding author), Univ Minnesota, Dept Speech Language Hearing Sci, 164 Pillsbury Dr SE, Minneapolis, MN 55455 USA.
EM mwinn@umn.edu
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R03 DC 014309]; American
   Speech-Language-Hearing Association Students Preparing for Academic and
   Research Careers Award; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R03DC014309,
   R03DC014309, R03DC014309, R03DC014309] Funding Source: NIH RePORTER
FX This work was supported by NIH Grant No. R03 DC 014309 to M.B.W. and the
   American Speech-Language-Hearing Association Students Preparing for
   Academic and Research Careers Award to S.P.G. We are grateful to Ashley
   N. Moore, David J. Audet, Jr., Tiffany Mitchell, and Josephine A. Lyou
   for their assistance with data collection and equipment setup. Stefan
   Frisch provided extra insight into the significance of this project. In
   addition, we are grateful to Matthew Fitzgerald, Ph.D. and the audiology
   team at Stanford Ear Institute as well as Kate Teece for their help in
   participant recruitment. Portions of this paper were presented as a
   poster at the 2016 fall meeting of the Acoustical Society of America
   (Honolulu, HI), AudiologyNOW! 2017 (Indianapolis, IN), and the
   Conference on Implantable Auditory Prostheses 2017 (Lake Tahoe, CA).
CR Abbas PJ, 2004, AUDIOL NEURO-OTOL, V9, P203, DOI 10.1159/000078390
   American National Standards Institute, 2004, S362004 ANSI
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32
   Bingabr M, 2008, HEARING RES, V241, P73, DOI 10.1016/j.heares.2008.04.012
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   BOOTHROYD A, 1988, J ACOUST SOC AM, V84, P101, DOI 10.1121/1.396976
   Borsky S, 1998, J ACOUST SOC AM, V103, P2670, DOI 10.1121/1.422787
   BURTON MW, 1995, J EXP PSYCHOL HUMAN, V21, P1230, DOI 10.1037/0096-1523.21.5.1230
   Chatterjee M, 1998, J ACOUST SOC AM, V103, P2565, DOI 10.1121/1.422777
   CONNINE CM, 1987, J MEM LANG, V26, P527, DOI 10.1016/0749-596X(87)90138-0
   Deeks JM, 2004, J ACOUST SOC AM, V115, P1736, DOI 10.1121/1.1675814
   Desai S, 2008, J ACOUST SOC AM, V123, P428, DOI 10.1121/1.2816573
   Donaldson GS, 2015, J ACOUST SOC AM, V138, P65, DOI 10.1121/1.4922173
   Evers V, 1998, J PHONETICS, V26, P345, DOI 10.1006/jpho.1998.0079
   Farris-Trimble A, 2014, J EXP PSYCHOL HUMAN, V40, P308, DOI 10.1037/a0034353
   Fishman KE, 1997, J SPEECH LANG HEAR R, V40, P1201, DOI 10.1044/jslhr.4005.1201
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538
   Frisch S, 2018, COMMUNICATION
   Fu QJ, 1998, J ACOUST SOC AM, V104, P2570, DOI 10.1121/1.423912
   Fu QJ, 2000, J ACOUST SOC AM, V107, P589, DOI 10.1121/1.428325
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Gilbert RC, 2014, J ACOUST SOC AM, V135, P389, DOI 10.1121/1.4838975
   GLASBERG BR, 1986, J ACOUST SOC AM, V79, P1020, DOI 10.1121/1.393374
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052
   Grieco-Calub TM, 2009, J SPEECH LANG HEAR R, V52, P1390, DOI 10.1044/1092-4388(2009/08-0154)
   JENKINS JJ, 1983, PERCEPT PSYCHOPHYS, V34, P441, DOI 10.3758/BF03203059
   Johnson K., 2003, ACOUSTIC AUDITORY PH
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Litvak LM, 2007, J ACOUST SOC AM, V122, P982, DOI 10.1121/1.2749413
   Loebach JL, 2010, J EXP PSYCHOL HUMAN, V36, P224, DOI 10.1037/a0017609
   Loizou PC, 2001, J ACOUST SOC AM, V110, P1619, DOI 10.1121/1.1388004
   Mattys SL, 2014, PSYCHOL AGING, V29, P150, DOI 10.1037/a0035387
   Mattys SL, 2011, J MEM LANG, V65, P145, DOI 10.1016/j.jml.2011.04.004
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2017, COGNITION, V169, P147, DOI 10.1016/j.cognition.2017.08.013
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   Moberly AC, 2016, EAR HEARING, V37, P14, DOI 10.1097/AUD.0000000000000204
   Munson B, 2003, J ACOUST SOC AM, V113, P925, DOI 10.1121/1.1536630
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Nusbaum H. C., 1984, RES SPEECH PERCEPTIO, V10, P357
   Patro C, 2016, J ACOUST SOC AM, V140, P1336, DOI 10.1121/1.4961450
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   R Core Team, 2016, R LANG ENV STAT COMP
   Schertz J, 2018, J ACOUST SOC AM, V143, pEL231, DOI 10.1121/1.5027512
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Smart J, 2015, J ACOUST SOC AM, V138, P1810
   Souza P, 2009, J ACOUST SOC AM, V126, P792, DOI 10.1121/1.3158835
   Stafford RC, 2014, EAR HEARING, V35, P262, DOI 10.1097/AUD.0b013e3182a768e8
   STRANGE W, 1983, J ACOUST SOC AM, V74, P695, DOI 10.1121/1.389855
   Svirsky MA, 2015, ACTA OTO-LARYNGOL, V135, P354, DOI 10.3109/00016489.2014.1002052
   Van Engen KJ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043753
   Vitevitch MS, 1997, LANG SPEECH, V40, P47, DOI 10.1177/002383099704000103
   Vitevitch MS, 2004, BEHAV RES METH INS C, V36, P481, DOI 10.3758/BF03195594
   Winn M., 2013, FRONTIERS PSYCH AUDI, V4, P1
   Winn MB, 2016, EAR HEARING, V37, pE377, DOI 10.1097/AUD.0000000000000328
   Winn MB, 2015, EAR HEARING, V36, pe153, DOI 10.1097/AUD.0000000000000145
   Winn MB, 2015, J ACOUST SOC AM, V137, P1430, DOI 10.1121/1.4908308
   Winn MB, 2012, J ACOUST SOC AM, V131, P1465, DOI 10.1121/1.3672705
   Xu L, 2005, J ACOUST SOC AM, V117, P3255, DOI 10.1121/1.1886405
NR 60
TC 0
Z9 0
U1 1
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD NOV
PY 2019
VL 146
IS 5
BP 3373
EP 3383
DI 10.1121/1.5132938
PG 11
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA KG8WP
UT WOS:000510232400031
PM 31795696
OA Green Published
DA 2021-02-24
ER

PT J
AU Domingo, Y
   Holmes, E
   Macpherson, E
   Johnsrude, IS
AF Domingo, Ysabel
   Holmes, Emma
   Macpherson, Ewan
   Johnsrude, Ingrid S.
TI Using spatial release from masking to estimate the magnitude of the
   familiar-voice intelligibility benefit
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH-PERCEPTION; COCKTAIL PARTY; TALKER FAMILIARITY; ENERGETIC
   MASKING; SEPARATION; HEARING; ATTENTION; IDENTIFICATION; FREQUENCY;
   LOCATION
AB The ability to segregate simultaneous speech streams is crucial for successful communication. Recent studies have demonstrated that participants can report 10%-20% more words spoken by naturally familiar (e.g., friends or spouses) than unfamiliar talkers in two-voice mixtures. This benefit is commensurate with one of the largest benefits to speech intelligibility currently known-that which is gained by spatially separating two talkers. However, because of differences in the methods of these previous studies, the relative benefits of spatial separation and voice familiarity are unclear. Here, the familiar-voice benefit and spatial release from masking are directly compared, and it is examined if and how these two cues interact with one another. Talkers were recorded while speaking sentences from a published closed-set "matrix" task, and then listeners were presented with three different sentences played simultaneously. Each target sentence was played at 0 degrees azimuth, and two masker sentences were symmetrically separated about the target. On average, participants reported 10%-30% more words correctly when the target sentence was spoken in a familiar than unfamiliar voice (collapsed over spatial separation conditions); it was found that participants gain a similar benefit from a familiar target as when an unfamiliar voice is separated from two symmetrical maskers by approximately 15 degrees azimuth. (C) 2019 Acoustical Society of America.
C1 [Domingo, Ysabel; Holmes, Emma; Johnsrude, Ingrid S.] Univ Western Ontario, Brain & Mind Inst, London, ON, Canada.
   [Macpherson, Ewan] Univ Western Ontario, Sch Commun Sci & Disorders, London, ON, Canada.
   [Domingo, Ysabel; Johnsrude, Ingrid S.] Univ Western Ontario, Dept Psychol, London, ON, Canada.
   [Holmes, Emma] UCL, UCL Queen Sq Inst Neurol, Wellcome Ctr Human Neuroimaging, London, England.
   [Macpherson, Ewan] Univ Western Ontario, Natl Ctr Audiol, London, ON, Canada.
RP Domingo, Y (corresponding author), Univ Western Ontario, Brain & Mind Inst, London, ON, Canada.
EM bdomingo@uwo.ca
RI Johnsrude, Ingrid S/G-4694-2011; Holmes, Emma/H-8494-2019
OI Johnsrude, Ingrid S/0000-0002-7810-1333; Holmes,
   Emma/0000-0002-0314-6588
FU Canadian Institutes of Health Research (CIHR)Canadian Institutes of
   Health Research (CIHR) [MOP 133450]; Natural Sciences and Engineering
   Research Council of Canada (NSERC)Natural Sciences and Engineering
   Research Council of Canada (NSERC) [327429-2012]
FX This work was supported by funding from the Canadian Institutes of
   Health Research (CIHR; Operating Grant No. MOP 133450) and the Natural
   Sciences and Engineering Research Council of Canada (NSERC; Discovery
   Grant No. 327429-2012). The authors declare that the research was
   conducted in the absence of any commercial or financial relationships
   that could be construed as a potential conflict of interest.
CR Algazi VR, 2001, IEEE WORKSH APPL SIG, DOI [DOI 10.1109/ASPAA.2001.969552, 10.1109/ASPAA.2001.969552]
   Arbogast TL, 2005, J ACOUST SOC AM, V117, P2169, DOI 10.1121/1.1861598
   Arbogast TL, 2002, J ACOUST SOC AM, V112, P2086, DOI 10.1121/1.1510141
   Best V, 2006, J ACOUST SOC AM, V120, P1506, DOI 10.1121/1.2234849
   Best V, 2011, J ACOUST SOC AM, V129, P1616, DOI 10.1121/1.3533733
   Bolia RS, 2000, J ACOUST SOC AM, V107, P1065, DOI 10.1121/1.428288
   BRONKHORST AW, 1992, J ACOUST SOC AM, V92, P3132, DOI 10.1121/1.404209
   Brungart DS, 2012, J ACOUST SOC AM, V132, P2545, DOI 10.1121/1.4747005
   Brungart DS, 2001, J ACOUST SOC AM, V110, P2527, DOI 10.1121/1.1408946
   Carlile S, 2014, ACOUST AUST, V42, P90
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Cusack R, 2004, J EXP PSYCHOL HUMAN, V30, P643, DOI 10.1037/0096-1523.30.4.643
   Darwin CJ, 2003, J ACOUST SOC AM, V114, P2913, DOI 10.1121/1.1616924
   Domingo Y, 2019, J EXP PSYCHOL APPL
   Fontaine M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01180
   Freyman RL, 1999, J ACOUST SOC AM, V106, P3578, DOI 10.1121/1.428211
   Glyde H, 2015, J ACOUST SOC AM, V138, P3311, DOI 10.1121/1.4934732
   Hawley ML, 2004, J ACOUST SOC AM, V115, P833, DOI 10.1121/1.1639908
   Holmes E, 2018, PSYCHOL SCI, V29, P1575, DOI 10.1177/0956797618779083
   Johnsrude IS, 2013, PSYCHOL SCI, V24, P1995, DOI 10.1177/0956797613482467
   Johnstone PM, 2006, J ACOUST SOC AM, V120, P2177, DOI 10.1121/1.2225416
   Jones GL, 2008, J ACOUST SOC AM, V124, P3818, DOI 10.1121/1.2996336
   Kidd G, 2010, J ACOUST SOC AM, V128, P1965, DOI 10.1121/1.3478781
   Kidd G, 2008, J ACOUST SOC AM, V124, P3793, DOI 10.1121/1.2998980
   Kitterick PT, 2010, J ACOUST SOC AM, V127, P2498, DOI 10.1121/1.3327507
   Kreitewolf J, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01584
   Levi SV, 2011, J ACOUST SOC AM, V130, P4053, DOI 10.1121/1.3651816
   Marrone N, 2008, J ACOUST SOC AM, V124, P1146, DOI 10.1121/1.2945710
   Newman RS, 2007, J PHONETICS, V35, P85, DOI 10.1016/j.wocn.2005.10.004
   Noble W, 2002, PERCEPT PSYCHOPHYS, V64, P1325, DOI 10.3758/BF03194775
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Singh G, 2008, J ACOUST SOC AM, V124, P1294, DOI 10.1121/1.2949399
   Singh PG, 1997, J ACOUST SOC AM, V102, P1943, DOI 10.1121/1.419688
   Souza P, 2013, J AM ACAD AUDIOL, V24, P689, DOI 10.3766/jaaa.24.8.6
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Wong PCM, 2004, J COGNITIVE NEUROSCI, V16, P1173, DOI 10.1162/0898929041920522
   Yonan CA, 2000, PSYCHOL AGING, V15, P88, DOI 10.1037/0882-7974.15.1.88
   Yost WA, 2017, J ACOUST SOC AM, V141, P2093, DOI 10.1121/1.4978614
NR 39
TC 0
Z9 0
U1 1
U2 4
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD NOV
PY 2019
VL 146
IS 5
BP 3487
EP 3494
DI 10.1121/1.5133628
PG 8
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA KG8WP
UT WOS:000510232400041
PM 31795686
OA Green Published
DA 2021-02-24
ER

PT J
AU Derrick, D
   Hansmann, D
   Theys, C
AF Derrick, Donald
   Hansmann, Doreen
   Theys, Catherine
TI Tri-modal speech: Audio-visual-tactile integration in speech perception
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID TEMPORAL WINDOW; NORMAL-HEARING; AIR-PRESSURE; FLOW
AB Speech perception is a multi-sensory experience. Visual information enhances [Sumby and Pollack (1954). J. Acoust. Soc. Am. 25, 212-215] and interferes [McGurk and MacDonald (1976). Nature 264, 746-748] with speech perception. Similarly, tactile information, transmitted by puffs of air arriving at the skin and aligned with speech audio, alters [Gick and Derrick (2009). Nature 462, 502-504] auditory speech perception in noise. It has also been shown that aero-tactile information influences visual speech perception when an auditory signal is absent [Derrick, Bicevskis, and Gick (2019a). Front. Commun. Lang. Sci. 3(61), 1-11]. However, researchers have not yet identified the combined influence of aero-tactile, visual, and auditory information on speech perception. The effects of matching and mismatching visual and tactile speech on two-way forced-choice auditory syllable-in-noise classification tasks were tested. The results showed that both visual and tactile information altered the signal-to-noise threshold for accurate identification of auditory signals. Similar to previous studies, the visual component has a strong influence on auditory syllable-in-noise identification, as evidenced by a 28.04 dB improvement in SNR between matching and mismatching visual stimulus presentations. In comparison, the tactile component had a small influence resulting in a 1.58 dB SNR match-mismatch range. The effects of both the audio and tactile information were shown to be additive. (C) 2019 Acoustical Society of America.
C1 [Derrick, Donald] Univ Canterbury, New Zealand Inst Language Brain & Behav, 20 Kirkwood Ave, Christchurch 8041, New Zealand.
   [Hansmann, Doreen; Theys, Catherine] Univ Canterbury, Sch Psychol Speech & Hearing, 20 Kirkwood Ave, Christchurch 8041, New Zealand.
RP Derrick, D (corresponding author), Univ Canterbury, New Zealand Inst Language Brain & Behav, 20 Kirkwood Ave, Christchurch 8041, New Zealand.
EM donald.derrick@canterbury.ac.nz
FU New Zealand Ministry of Business, Innovation, and Employment (MBIE)New
   Zealand Ministry of Business, Innovation and Employment (MBIE);
   University of Canterbury Marsden Support Fund grant
FX This research was supported by New Zealand Ministry of Business,
   Innovation, and Employment (MBIE) Grants "Aerotactile Enhancement in
   Speech Perception" and "Aerotactile Enhancement in Speech Perception
   -Phase II," and a University of Canterbury Marsden Support Fund grant to
   D.D. and C.T. (Co-PI's). Special thanks to John Chrisstoffels
   (University of Canterbury School of Fine Arts) for his cinematography,
   and to Claire Elliott for providing our stimuli. Special thanks to
   Jonathan Wiltshire for PsyToolBox support on Windows machines, and Scott
   Lloyd for his technical support of the air flow system.
CR Alcorn S., 1932, VOLTA REV, V34, P195
   [Anonymous], 2014, MATLAB STAT TOOLB RE
   Araya-Salas M, 2017, METHODS ECOL EVOL, V8, P184, DOI 10.1111/2041-210X.12624
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   BERNSTEIN LE, 1991, J ACOUST SOC AM, V90, P2971, DOI 10.1121/1.401771
   Bicevskis K, 2016, J ACOUST SOC AM, V140, P3531, DOI 10.1121/1.4965968
   Boersma Paul, 2019, PRAAT DOING PHONETIC
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   BROADBENT D, 1970, IEEE T EDUC, VE 13, P79, DOI 10.1109/TE.1970.4320569
   Derrick D., 2016, 5 JOINT M AC SOC AM
   Derrick D., 2014, P 15 ANN C INT SPEEC, P2580
   Derrick D., 2015, PCT patent, Patent No. [WO2015/122785A1, 2015122785]
   Derrick D., 2019, P 19 INT C PHON SCI, P3508
   Derrick D., 2019, FRONT COMMUN LANG SC, V3, P1
   Derrick D., 2015, CAN ACOUST, V43, P108
   Derrick D, 2019, J ACOUST SOC AM, V146, P1605, DOI 10.1121/1.5125131
   Derrick D, 2013, MULTISENS RES, V26, P405, DOI 10.1163/22134808-00002427
   Desai S, 2008, J ACOUST SOC AM, V123, P428, DOI 10.1121/1.2816573
   DIXON NF, 1980, PERCEPTION, V9, P719, DOI 10.1068/p090719
   DRAPER MH, 1960, BMJ-BRIT MED J, V1, P1837, DOI 10.1136/bmj.1.5189.1837
   ERBER NP, 1969, J SPEECH HEAR RES, V12, P423, DOI 10.1044/jshr.1202.423
   EWERTSEN HW, 1971, ACTA OTO-LARYNGOL, V72, P201, DOI 10.3109/00016487109122473
   Feldman JI, 2018, NEUROSCI BIOBEHAV R, V95, P220, DOI 10.1016/j.neubiorev.2018.09.020
   FFmpeg Developers, 2016, FFMPEG TOOL SOFW
   Gick B, 2008, J ACOUST SOC AM, V123, pEL72, DOI 10.1121/1.2884349
   Gick B, 2010, J ACOUST SOC AM, V128, pEL342, DOI 10.1121/1.3505759
   Gick B, 2009, NATURE, V462, P502, DOI 10.1038/nature08572
   Goldenberg D., 2015, P 18 INT C PHON SCI
   Goldenberg D., 2018, J ACOUST SOC AM, V144, P1801
   Huyse A, 2014, J ACOUST SOC AM, V136, P1918, DOI 10.1121/1.4894685
   Jansen S, 2010, INT J AUDIOL, V49, P378, DOI 10.3109/14992020903431272
   Kaganovich N, 2016, BRAIN LANG, V157, P14, DOI 10.1016/j.bandl.2016.04.010
   Kleiner M., 2007, PERC 30 EUR C VIS PE
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   LISKER L, 1967, LANG SPEECH, V10, P1, DOI 10.1177/002383096701000101
   LISKER L, 1957, LANGUAGE, V33, P42, DOI 10.2307/410949
   Massaro D. W., 1998, PERCEIVING TALKING F, V1
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Munhall KG, 1996, PERCEPT PSYCHOPHYS, V58, P351, DOI 10.3758/BF03206811
   Peelle JE, 2015, CORTEX, V68, P169, DOI 10.1016/j.cortex.2015.03.006
   PELLI D G, 1987, Investigative Ophthalmology and Visual Science, V28, P366
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   R Development Core Team, 2018, R LANG ENV STAT COMP
   Ross LA, 2011, EUR J NEUROSCI, V33, P2329, DOI 10.1111/j.1460-9568.2011.07685.x
   ROTHENBERG M, 1977, J ACOUST SOC AM, V62, P1003, DOI 10.1121/1.381610
   Sekiyama K, 2003, NEUROSCI RES, V47, P277, DOI 10.1016/S0168-0102(03)00214-1
   Sekiyama K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00323
   Smeele P.M.T., 1992, P INT C SPOK LANG PR, P65
   Smits C, 2004, INT J AUDIOL, V43, P15, DOI 10.1080/14992020400050004
   STATHOPOULOS ET, 1985, FOLIA PHONIATR, V37, P152, DOI 10.1159/000265794
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1992, PHILOS T ROY SOC B, V335, P71, DOI 10.1098/rstb.1992.0009
   TATHAM MAA, 1973, LANG SPEECH, V16, P336, DOI 10.1177/002383097301600404
   Tremblay C, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000742
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   van Wassenhove V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00388
   Venezia JH, 2016, ATTEN PERCEPT PSYCHO, V78, P583, DOI 10.3758/s13414-015-1026-y
   WATSON AB, 1983, PERCEPT PSYCHOPHYS, V33, P113, DOI 10.3758/BF03202828
NR 60
TC 0
Z9 0
U1 1
U2 3
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD NOV
PY 2019
VL 146
IS 5
BP 3495
EP 3504
DI 10.1121/1.5134064
PG 10
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA KG8WP
UT WOS:000510232400042
PM 31795693
DA 2021-02-24
ER

PT J
AU Kamerer, AM
   Kopun, JG
   Fultz, SE
   Allen, C
   Neely, ST
   Rasetshwane, DM
AF Kamerer, Aryn M.
   Kopun, Judy G.
   Fultz, Sara E.
   Allen, Carissa
   Neely, Stephen T.
   Rasetshwane, Daniel M.
TI Examining physiological and perceptual consequences of noise exposure
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID BRAIN-STEM RESPONSE; HIDDEN HEARING-LOSS; COCHLEAR SYNAPTOPATHY;
   GENDER-DIFFERENCES; SPEECH-PERCEPTION; AUDITORY FUNCTION; YOUNG-ADULTS;
   AGE; TINNITUS; HISTORY
AB The consequences of noise exposure on the auditory system are not entirely understood. In animals, noise exposure causes selective synaptopathy-an uncoupling of auditory nerve fibers from sensory cells-mostly in fibers that respond to high sound levels. Synaptopathy can be measured physiologically in animals, but a direct relationship between noise exposure and synaptopathy in humans has yet to be proven. Sources of variability, such as age, indirect measures of noise exposure, and comorbid auditory disorders, obfuscate attempts to find concrete relationships between noise exposure, synaptopathy, and perceptual consequences. This study adds to the ongoing effort by examining relationships between noise exposure, auditory brainstem response (ABR) amplitudes, and speech perception in adults of various ages and audiometric thresholds and a subset of younger adults with clinically normal hearing. Regression models including noise exposure, age, hearing thresholds, and sex as covariates were compared to find a best-fitting model of toneburst ABR wave I amplitude at two frequencies and word recognition performance in three listening conditions: background noise, time compression, and time compression with reverberation. The data suggest the possibility of detecting synaptopathy in younger adults using physiological measures, but that age and comorbid hearing disorders may hinder attempts to assess noise-induced synaptopathy. (C) 2019 Acoustical Society of America.
C1 [Kamerer, Aryn M.; Kopun, Judy G.; Fultz, Sara E.; Allen, Carissa; Neely, Stephen T.; Rasetshwane, Daniel M.] Boys Town Natl Res Hosp, Omaha, NE 68131 USA.
RP Kamerer, AM (corresponding author), Boys Town Natl Res Hosp, Omaha, NE 68131 USA.
EM aryn.kamerer@boystown.org
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [5R01DC016348-02, T32DC000013];
   NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCESUnited States Department
   of Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute of General Medical Sciences (NIGMS) [P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023, P20GM109023, P20GM109023, P20GM109023, P20GM109023,
   P20GM109023] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC016348, R01DC016348, T32DC000013, T32DC000013, R01DC016348,
   T32DC000013, T32DC000013, T32DC000013, T32DC000013, R01DC016348,
   T32DC000013, T32DC000013, T32DC000013] Funding Source: NIH RePORTER
FX This research was funded by NIH Grant Nos. 5R01DC016348-02 and
   T32DC000013.
CR [Anonymous], 1978, ASHA, V20, P297
   Berger E. H, 2015, NOISE NAVIGATOR
   Bharadwaj HM, 2015, J NEUROSCI, V35, P2161, DOI 10.1523/JNEUROSCI.3915-14.2015
   Bramhall N, 2019, HEARING RES, V377, P88, DOI 10.1016/j.heares.2019.02.016
   Bramhall N, 2015, J AM ACAD AUDIOL, V26, P509, DOI 10.3766/jaaa.14100
   Bramhall NF, 2018, EAR HEARING, V39, P881, DOI 10.1097/AUD.0000000000000544
   Bramhall NF, 2017, EAR HEARING, V38, pE1, DOI 10.1097/AUD.0000000000000370
   Clark JA, 1996, HEARING RES, V99, P119, DOI 10.1016/S0378-5955(96)00092-5
   DEHAN CP, 1990, LARYNGOSCOPE, V100, P18
   DOBIE RA, 1992, EAR HEARING, V13, P19, DOI 10.1097/00003446-199202000-00006
   Dobie RA, 2017, INT J AUDIOL, V56, P74, DOI 10.1080/14992027.2016.1255359
   DON M, 1993, J ACOUST SOC AM, V94, P2135, DOI 10.1121/1.407485
   DON M, 1978, J ACOUST SOC AM, V63, P1084, DOI 10.1121/1.381816
   Engdahl B, 1996, J ACOUST SOC AM, V99, P1573, DOI 10.1121/1.414733
   Fernandez KA, 2015, J NEUROSCI, V35, P7509, DOI 10.1523/JNEUROSCI.5138-14.2015
   Fulbright Angela N. C., 2017, Seminars in Hearing, V38, P298, DOI 10.1055/s-0037-1606325
   Furman AC, 2013, J NEUROPHYSIOL, V110, P577, DOI 10.1152/jn.00164.2013
   Gelfand S. A, 1982, J NEUROL NEUROSUR PS, V45, P1175
   Grinn SK, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00465
   Gromping U, 2015, J STAT SOFTW, V17, P1
   Grose JH, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517737417
   GUEST H, 2018, J ACOUST SOC AM, V144, P1935, DOI DOI 10.1121/1.5068467
   Guest H, 2018, HEARING RES, V364, P142, DOI 10.1016/j.heares.2018.03.008
   Hebbali A, 2018, OLSRR
   Hind SE, 2011, INT J AUDIOL, V50, P708, DOI 10.3109/14992027.2011.582049
   JERGER J, 1980, ARCH OTOLARYNGOL, V106, P387
   Johnson JW, 2004, ORGAN RES METHODS, V7, P238, DOI 10.1177/1094428104266510
   Kim S, 2015, COMMUN STAT APPL MET, V22, P665, DOI 10.5351/CSAM.2015.22.6.665
   Kohrman DC, 2020, CSH PERSPECT MED, V10, DOI 10.1101/cshperspect.a035493
   Konrad-Martin D, 2012, J AM ACAD AUDIOL, V23, P18, DOI 10.3766/jaaa.23.1.3
   Kujawa SG, 2015, HEARING RES, V330, P191, DOI 10.1016/j.heares.2015.02.009
   Kujawa SG, 2009, J NEUROSCI, V29, P14077, DOI 10.1523/JNEUROSCI.2845-09.2009
   Le Prell CG, 2019, INT J AUDIOL, V58, pS3, DOI 10.1080/14992027.2018.1534010
   Liberman LD, 2015, JARO-J ASSOC RES OTO, V16, P205, DOI 10.1007/s10162-015-0510-3
   Liberman MC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162726
   Lin HW, 2011, JARO-J ASSOC RES OTO, V12, P605, DOI 10.1007/s10162-011-0277-0
   Makary CA, 2011, JARO-J ASSOC RES OTO, V12, P711, DOI 10.1007/s10162-011-0283-2
   Marshall L, 2009, J ACOUST SOC AM, V125, P995, DOI 10.1121/1.3050304
   Miller JM, 1998, SCAND AUDIOL, V27, P53
   NEUBERGER M, 1992, AUDIOLOGY, V31, P45
   *NIH, 1990, NAT I HLTH CONS DEV
   NIOSH, 1998, OCC NOIS EXP REV CRI
   Noffsinger D, 1994, J Am Acad Audiol, V5, P231
   Occupational Safety and Health Administration (OSHA). US Department of Labor, 1983, FED REGISTER, P9738
   Pienkowski M, 2017, EAR HEARING, V38, P135, DOI 10.1097/AUD.0000000000000388
   Prendergast G, 2017, HEARING RES, V344, P68, DOI 10.1016/j.heares.2016.10.028
   R Core Team, 2018, R LANG ENV STAT COMP
   Ridley CL, 2018, EAR HEARING, V39, P829, DOI 10.1097/AUD.0000000000000543
   Schaette R, 2011, J NEUROSCI, V31, P13452, DOI 10.1523/JNEUROSCI.2156-11.2011
   Spankovich C, 2017, EAR HEARING, V38, P724, DOI 10.1097/AUD.0000000000000457
   Spehar BP, 2018, OTOL NEUROTOL, V39, P950, DOI 10.1097/MAO.0000000000001903
   Stamper GC, 2015, EAR HEARING, V36, P172, DOI 10.1097/AUD.0000000000000107
   Stapells D. R., 2000, J SPEECH LANGUAGE PA, V24, P74
   Stephens D, 2003, Noise Health, V5, P55
   Suzuki J, 2016, SCI REP-UK, V6, DOI 10.1038/srep24907
   Valderrama JT, 2018, HEARING RES, V365, P36, DOI 10.1016/j.heares.2018.06.003
   Viana LM, 2015, HEARING RES, V327, P78, DOI 10.1016/j.heares.2015.04.014
   Wan G, 2014, ELIFE, P1
   Yeend I, 2017, HEARING RES, V353, P224, DOI 10.1016/j.heares.2017.07.006
   YOST WA, 1978, BEHAV RES METH INSTR, V10, P671, DOI 10.3758/BF03205369
NR 60
TC 3
Z9 3
U1 1
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD NOV
PY 2019
VL 146
IS 5
BP 3947
EP 3959
DI 10.1121/1.5132291
PG 13
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA KG8WP
UT WOS:000510232400075
PM 31795718
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Weatherhead, D
   Friedman, O
   White, KS
AF Weatherhead, Drew
   Friedman, Ori
   White, Katherine S.
TI Preschoolers are sensitive to accent distance
SO JOURNAL OF CHILD LANGUAGE
LA English
DT Article
DE speech perception; perceptual distance; accent judgments
ID FOREIGN ACCENT; SPEECH; INTELLIGIBILITY; PERCEPTION; LANGUAGE; ENGLISH;
   CLASSIFICATION; JUDGMENTS; PROSODY; FRENCH
AB Can children tell how different a speaker's accent is from their own? In Experiment 1 (N = 84), four- and five-year-olds heard speakers with different accents and indicated where they thought each speaker lived relative to a reference point on a map that represented their current location. Five-year-olds generally placed speakers with stronger accents (as judged by adults) at more distant locations than speakers with weaker accents. In contrast, four-year-olds did not show differences in where they placed speakers with different accents. In Experiment 2 (N = 56), the same sentences were low-pass filtered so that only prosodic information remained. This time, children judged which of five possible aliens had produced each utterance, given a reference speaker. Children of both ages showed differences in which alien they chose based on accent, and generally rated speakers with foreign accents as more different from their native accent than speakers with regional accents. Together, the findings show that preschoolers perceive accent distance, that children may be sensitive to the distinction between foreign and regional accents, and that preschoolers likely use prosody to differentiate among accents.
C1 [Weatherhead, Drew] Univ British Columbia, Dept Psychol, 2329 West Mall, Vancouver, BC V6T 1Z4, Canada.
   [Friedman, Ori; White, Katherine S.] Univ Waterloo, Dept Psychol, Waterloo, ON, Canada.
RP Weatherhead, D (corresponding author), Univ British Columbia, Dept Psychol, 2329 West Mall, Vancouver, BC V6T 1Z4, Canada.
EM drew.weatherhead@psych.ubc.ca
RI Friedman, Ori/K-5429-2012
OI Friedman, Ori/0000-0003-2346-9787
FU Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR
FX The authors thank theWaterloo Region schools and day-care centers for
   allowing us to conduct our research, and thank the numerous families who
   participated. This research was supported by grants from the Natural
   Sciences and Engineering Research Council of Canada awarded to O.F. and
   K.S.W.
CR ANDERSONHSIEH J, 1992, LANG LEARN, V42, P529, DOI 10.1111/j.1467-1770.1992.tb01043.x
   Atagi E, 2016, APPL PSYCHOLINGUIST, V37, P241, DOI 10.1017/S014271641400054X
   Boersma P., 2018, PRAAT DOING PHONETIC
   BRENNAN EM, 1981, J PSYCHOLINGUIST RES, V10, P487, DOI 10.1007/BF01076735
   Carmichael L., 2000, THESIS
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Creel SC, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12524
   DeJesus JM, 2017, J EXP CHILD PSYCHOL, V164, P178, DOI 10.1016/j.jecp.2017.07.005
   FLEGE JE, 1995, J ACOUST SOC AM, V97, P3125, DOI 10.1121/1.413041
   FLEGE JE, 1984, J ACOUST SOC AM, V76, P692, DOI 10.1121/1.391256
   Floccia C, 2006, J EXP PSYCHOL HUMAN, V32, P1276, DOI 10.1037/0096-1523.32.5.1276
   Floccia C, 2009, INT J BEHAV DEV, V33, P366, DOI 10.1177/0165025409103871
   Girard F, 2008, BRIT J DEV PSYCHOL, V26, P409, DOI 10.1348/026151007X251712
   Goslin J, 2012, BRAIN LANG, V122, P92, DOI 10.1016/j.bandl.2012.04.017
   GROVER C, 1987, LANG SPEECH, V30, P277, DOI 10.1177/002383098703000307
   Hahn LD, 2004, TESOL QUART, V38, P201, DOI 10.2307/3588378
   Hendriks B, 2017, INT J APPL LINGUIST, V27, P44, DOI 10.1111/ijal.12101
   Jones Z, 2017, J PHONETICS, V60, P20, DOI 10.1016/j.wocn.2016.11.001
   Kang O, 2010, SPEECH PROS 2010 5 I
   Kang O, 2018, LANG LEARN, V68, P115, DOI 10.1111/lang.12270
   Kang O, 2010, MOD LANG J, V94, P554, DOI 10.1111/j.1540-4781.2010.01091.x
   Kinzler KD, 2007, P NATL ACAD SCI USA, V104, P12577, DOI 10.1073/pnas.0705345104
   Kinzler KD, 2013, Q J EXP PSYCHOL, V66, P1146, DOI 10.1080/17470218.2012.731695
   Kinzler KD, 2013, DEV PSYCHOL, V49, P655, DOI 10.1037/a0028740
   Kinzler KD, 2012, DEVELOPMENTAL SCI, V15, P131, DOI 10.1111/j.1467-7687.2011.01101.x
   Kinzler KD, 2011, DEVELOPMENTAL SCI, V14, P106, DOI 10.1111/j.1467-7687.2010.00965.x
   MUNRO MJ, 1995, LANG LEARN, V45, P73, DOI 10.1111/j.1467-1770.1995.tb00963.x
   MUNRO MJ, 1995, STUDIES 2 LANGUAGE A, V17, P17, DOI DOI 10.1017/S0272263100013735
   Munro Murray J., 2001, STUDIES 2 LANGUAGE A, V23, P451, DOI DOI 10.1111/LANG.12082
   Nejjari W, 2012, WORLD ENGLISH, V31, P248, DOI 10.1111/j.1467-971X.2012.01754.x
   Nesdale D, 1996, J LANG SOC PSYCHOL, V15, P133, DOI 10.1177/0261927X960152002
   RYAN EB, 1977, LANG SPEECH, V20, P267
   Shah A. P., 2003, Canadian Acoustics, V31, P42
   Trofimovich P, 2006, STUD SECOND LANG ACQ, V28, P1, DOI 10.1017/S0272263106060013
   Wagner L, 2014, J CHILD LANG, V41, P1062, DOI 10.1017/S0305000913000330
   Weatherhead D, 2018, CHILD DEV, V89, P1613, DOI 10.1111/cdev.12797
   Weatherhead D, 2016, J EXP CHILD PSYCHOL, V143, P171, DOI 10.1016/j.jecp.2015.10.011
   Weinberger S., 2014, SPEECH ACCENT ARCH
NR 38
TC 2
Z9 2
U1 2
U2 4
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0305-0009
EI 1469-7602
J9 J CHILD LANG
JI J. Child Lang.
PD NOV
PY 2019
VL 46
IS 6
BP 1058
EP 1072
DI 10.1017/S0305000919000369
PG 15
WC Psychology, Developmental; Linguistics; Psychology, Experimental
SC Psychology; Linguistics
GA KI1RG
UT WOS:000511124800002
PM 31405400
DA 2021-02-24
ER

PT J
AU Llompart, M
   Reinisch, E
AF Llompart, Miquel
   Reinisch, Eva
TI Robustness of phonolexical representations relates to phonetic
   flexibility for difficult second language sound contrasts
SO BILINGUALISM-LANGUAGE AND COGNITION
LA English
DT Article
DE second language learning; speech perception; lexical representations;
   phonetics; flexibility
ID LEXICAL ACCESS; LINGUISTIC EXPERIENCE; SPEECH; PERCEPTION;
   IDENTIFICATION; NEUTRALIZATION; VARIABILITY; COMPETITION; ADAPTATION;
   CATEGORIES
AB Listening to speech entails adapting to vast amounts of variability in the signal. The present study examined the relationship between flexibility for adaptation in a second language (L2) and robustness of L2 phonolexical representations. Phonolexical encoding and phonetic flexibility for German learners of English were assessed by means of a lexical decision task containing nonwords with sound substitutions and a distributional learning task, respectively. Performance was analyzed for an easy (/i/-/I/) and a difficult contrast (/epsilon/-/ae/, where /ae/ does not exist in German). Results showed that for /i/-/I/ listeners were quite accurate in lexical decision, and distributional learning consistently triggered shifts in categorization. For /epsilon/-/ae/, lexical decision performance was poor but individual participants' scores related to performance in distributional learning: the better learners were in their lexical decision, the smaller their categorization shift. This suggests that, for difficult L2 contrasts, rigidity at the phonetic level relates to better lexical performance.
C1 [Llompart, Miquel; Reinisch, Eva] Ludwig Maximilian Univ Munich, Munich, Germany.
RP Llompart, M (corresponding author), Ludwig Maximilian Univ Munich, Inst Phonet & Speech Proc, Schellingstr 3, D-80799 Munich, Germany.
EM M.Llompart@phonetik.uni-muenchen.de
RI Llompart, Miquel/ABF-3326-2020
OI Llompart, Miquel/0000-0002-2002-8778
FU German Research Foundation (DFG)German Research Foundation (DFG) [RE
   3047/1-1]
FX This project was funded by a grant from the German Research Foundation
   (DFG; grant nr. RE 3047/1-1) to the second author. This work is part of
   the first author's Ph.D. project. Parts of this work were presented at
   the 23rd Annual Conference on Architectures and Mechanisms for Language
   Processing, 2017, in Lancaster, UK. We would like to thank Rosa Franzke
   for her help with testing participants and Christopher Carignan for
   comments on a previous version of the manuscript.
CR Amengual M, 2016, APPL PSYCHOLINGUIST, V37, P1221, DOI 10.1017/S0142716415000557
   Aoyama K, 2004, J PHONETICS, V32, P233, DOI 10.1016/S0095-4470(03)00036-6
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P, 2010, RAAT DOING PHONETICS
   Bohn O.-S., 1992, STUDIES 2 LANGUAGE A, V14, P131, DOI DOI 10.1017/S0272263100010792
   BOHN OS, 1990, APPL PSYCHOLINGUIST, V11, P303, DOI 10.1017/S0142716400008912
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Broersma M., 2005, THESIS
   Broersma M, 2012, LANG COGNITIVE PROC, V27, P1205, DOI 10.1080/01690965.2012.660170
   Bruggeman L., 2016, THESIS
   Bundgaard-Nielsen RL, 2011, STUD SECOND LANG ACQ, V33, P433, DOI 10.1017/S0272263111000040
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Cook S. V., 2012, THESIS
   Cook SV, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01345
   Cook SV, 2015, MENT LEX, V10, P247, DOI 10.1075/ml.10.2.04coo
   Cooper A, 2015, ATTEN PERCEPT PSYCHO, V77, P1342, DOI 10.3758/s13414-015-0855-z
   Cutler A, 2006, J PHONETICS, V34, P269, DOI 10.1016/j.wocn.2005.06.002
   Cutler A, 2004, J ACOUST SOC AM, V116, P3668, DOI 10.1121/1.1810292
   Cutler A, 2015, APPL PSYCHOLINGUIST, V36, P115, DOI 10.1017/S0142716414000459
   Darcy I, 2013, MENT LEX, V8, P372, DOI 10.1075/ml.8.3.06dar
   Darcy I, 2012, SECOND LANG RES, V28, P5, DOI 10.1177/0267658311423455
   Diaz B, 2008, P NATL ACAD SCI USA, V105, P16083, DOI 10.1073/pnas.0805022105
   Diaz B, 2016, BILING-LANG COGN, V19, P955, DOI 10.1017/S1366728915000450
   Diaz B, 2012, LEARN INDIVID DIFFER, V22, P680, DOI 10.1016/j.lindif.2012.05.005
   Drozdova P, 2016, BILING-LANG COGN, V19, P914, DOI 10.1017/S136672891600002X
   Eger NA, 2019, STUD SECOND LANG ACQ, V41, P179, DOI 10.1017/S0272263117000377
   Eger NA, 2019, J EXP PSYCHOL LEARN, V45, P552, DOI 10.1037/xlm0000599
   Escudero P, 2008, J PHONETICS, V36, P345, DOI 10.1016/j.wocn.2007.11.002
   Escudero P, 2011, J ACOUST SOC AM, V130, pEL206, DOI 10.1121/1.3629144
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   FOURAKIS M, 1984, PHONETICA, V41, P140, DOI 10.1159/000261720
   Gathercole SE, 1997, DEV PSYCHOL, V33, P966, DOI 10.1037/0012-1649.33.6.966
   Gollan TH, 2008, J MEM LANG, V58, P787, DOI 10.1016/j.jml.2007.07.001
   GOTO H, 1971, NEUROPSYCHOLOGIA, V9, P317, DOI 10.1016/0028-3932(71)90027-3
   Hanulikova A, 2012, ATTEN PERCEPT PSYCHO, V74, P613, DOI 10.3758/s13414-011-0259-7
   Iverson P., 2007, J ACOUST SOC AM, V121, P3072, DOI [10.1121/1.4781875, DOI 10.1121/1.4781875]
   Kleinschmidt D. F., 2015, P 37 ANN M COGN SCI, P1129
   Koerner TK, 2017, BRAIN SCI, V7, DOI 10.3390/brainsci7030026
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Lametti DR, 2014, PSYCHOL SCI, V25, P1325, DOI 10.1177/0956797614529978
   Lancaster A., 2016, P LINGUISTIC SOC AM, V24, P1, DOI [10.3765/plsa.v1i0.3725, DOI 10.3765/PLSA.V1I0.3725]
   Llompart M, 2018, LANG SPEECH, V61, P430, DOI 10.1177/0023830917736019
   Llompart M, 2017, J EXP PSYCHOL HUMAN, V43, P1040, DOI 10.1037/xhp0000383
   MacMillan N. A., 2005, DETECTION THEORY USE
   Mitterer H, 2017, LANG COGN NEUROSCI, V32, P1133, DOI 10.1080/23273798.2017.1286361
   Munson C.M., 2011, THESIS
   Navarra J, 2005, J EXP PSYCHOL HUMAN, V31, P912, DOI 10.1037/0096-1523.31.5.912
   Noguchi M, 2018, LANG LEARN, V68, P147, DOI 10.1111/lang.12267
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Pallier C, 2001, PSYCHOL SCI, V12, P445, DOI 10.1111/1467-9280.00383
   Pallier C., 2002, COMPUTING DISCRIMINA
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Polka L, 2003, SPEECH COMMUN, V41, P221, DOI 10.1016/S0167-6393(02)00105-X
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Polka L, 2011, J PHONETICS, V39, P467, DOI 10.1016/j.wocn.2010.08.007
   PORT RF, 1985, J PHONETICS, V13, P455, DOI 10.1016/S0095-4470(19)30797-1
   Quene H, 2008, J MEM LANG, V59, P413, DOI 10.1016/j.jml.2008.02.002
   R Core Team, 2017, R LANG ENV STAT COMP
   Raudenbush SW, 2000, J COMPUT GRAPH STAT, V9, P141, DOI 10.2307/1390617
   Reinisch E, 2016, J PHONETICS, V55, P96, DOI 10.1016/j.wocn.2015.12.004
   Reinisch E, 2013, J EXP PSYCHOL HUMAN, V39, P75, DOI 10.1037/a0027979
   Samuel AG, 2015, J MEM LANG, V81, P51, DOI 10.1016/j.jml.2015.01.003
   Schuhmann KS, 2014, THESIS
   Sebastian-Galles N, 2005, J MEM LANG, V52, P240, DOI 10.1016/j.jml.2004.11.001
   SHELDON A, 1982, APPL PSYCHOLINGUIST, V3, P243, DOI 10.1017/S0142716400001417
   Sidaras SK, 2009, J ACOUST SOC AM, V125, P3306, DOI 10.1121/1.3101452
   Simon E, 2014, BILING-LANG COGN, V17, P3, DOI 10.1017/S1366728912000764
   Sjerps MJ, 2010, J EXP PSYCHOL HUMAN, V36, P195, DOI 10.1037/a0016803
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   Trubetzkoy N. S, 1977, GRUNDZUEGE PHONOLOGI
   van Heuven WJB, 2014, Q J EXP PSYCHOL, V67, P1176, DOI 10.1080/17470218.2013.850521
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0
   Weber A, 2014, J PHONETICS, V46, P34, DOI 10.1016/j.wocn.2014.05.002
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Witteman MJ, 2013, ATTEN PERCEPT PSYCHO, V75, P537, DOI 10.3758/s13414-012-0404-y
   Zipf G.K., 1949, HUMAN BEHAV PRINCIPL
NR 82
TC 3
Z9 3
U1 0
U2 0
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 1366-7289
EI 1469-1841
J9 BILING-LANG COGN
JI Biling.-Lang. Cogn.
PD NOV
PY 2019
VL 22
IS 5
BP 1085
EP 1100
DI 10.1017/S1366728918000925
PG 16
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA KH7WG
UT WOS:000510860000011
DA 2021-02-24
ER

PT J
AU Carlson, MT
AF Carlson, Matthew T.
TI Now you hear it, now you don't: Malleable illusory vowel effects in
   Spanish-English bilinguals
SO BILINGUALISM-LANGUAGE AND COGNITION
LA English
DT Article
DE bilingualism; phonotactics; speech perception; illusory vowel effects
ID PHONOTACTIC CONSTRAINTS; LANGUAGE CONTEXT; LEXICAL ACCESS; SPEECH;
   PERCEPTION; 2ND-LANGUAGE; EPENTHESIS; EXPERIENCE; CATEGORIZATION;
   INTERFERENCE
AB Spanish speakers tend to perceive an illusory [e] preceding word-initial [s]-consonant sequences, e.g., perceiving [stio] as [estio] (Cuetos, Halle, Dominguez & Segui, 2011), but this illusion is weaker for Spanish speakers who know English, which lacks the illusion (Carlson, Goldrick, Blasingame & Fink, 2016). The present study aimed to shed light on why this occurs by assessing how a brief interval spent using English impacts performance in Spanish auditory discrimination and lexical decision. Late Spanish-English bilinguals' pattern of responses largely matched that of monolinguals, but their response times revealed significant differences between monolinguals and bilinguals, and between bilinguals who had just completed tasks in English vs. Spanish. These results suggest that late bilinguals do not simply learn to perceive initial [s]-consonant sequences veridically, but that elements of both their phonotactic systems interact dynamically during speech perception, as listeners work to identify what it was they just heard.
C1 [Carlson, Matthew T.] Penn State Univ, University Pk, PA 16802 USA.
RP Carlson, MT (corresponding author), Penn State Univ, Dept Spanish Italian & Portuguese, University Pk, PA 16802 USA.
EM mtc173@psu.edu
FU National Science FoundationNational Science Foundation (NSF)
   [OISE-0968369]
FX The research reported here was funded through a grant from the National
   Science Foundation (OISE-0968369). I also gratefully acknowledge the
   help of Alex McAllister andManuel Pulido Azpiroz in the construction of
   stimuli, Teresa Bajo for providing lab space in Granada, and Giuli
   Dussias, Matt Goldrick, Mike Putnam, Katharina Schuhmann, and Frances
   Blanchette for their invaluable help and feedback.
CR Abrahamsson N, 1999, LANG LEARN, V49, P473, DOI 10.1111/0023-8333.00097
   ALTENBERG EP, 1983, J VERB LEARN VERB BE, V22, P174, DOI 10.1016/S0022-5371(83)90134-2
   Altenberg Evelyn P., 2005, IRAL-INT REV APPL LI, V43, P53, DOI DOI 10.1191/0267658305SR2500A
   Amengual M, 2012, BILING-LANG COGN, V15, P517, DOI 10.1017/S1366728911000460
   ANISFELD M, 1969, J VERB LEARN VERB BE, V8, P257, DOI 10.1016/S0022-5371(69)80072-1
   Antoniou M, 2011, J PHONETICS, V39, P558, DOI 10.1016/j.wocn.2011.03.001
   Antoniou M, 2010, J PHONETICS, V38, P640, DOI 10.1016/j.wocn.2010.09.005
   Apfelbaum KS, 2015, PSYCHON B REV, V22, P916, DOI 10.3758/s13423-014-0783-2
   Apfelbaum KS, 2014, LANG COGN NEUROSCI, V29, P1070, DOI 10.1080/01690965.2013.824995
   Athanasopoulos P, 2015, PSYCHOL SCI, V26, P518, DOI 10.1177/0956797614567509
   Balukas C, 2015, INT J BILINGUAL, V19, P423, DOI 10.1177/1367006913516035
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Bent T, 2003, J ACOUST SOC AM, V114, P1600, DOI 10.1121/1.1603234
   Berent I, 2007, COGNITION, V104, P591, DOI 10.1016/j.cognition.2006.05.015
   Berent I, 2012, MENT LEX, V7, P275, DOI 10.1075/ml.7.3.02ber
   Berent I, 2010, J EXP PSYCHOL HUMAN, V36, P212, DOI 10.1037/a0017638
   Berent I, 2009, PHONOLOGY, V26, P75, DOI 10.1017/S0952675709001729
   Boersma P., 2018, PRAAT DOING PHONETIC
   CARAMAZZA A, 1974, CAN J PSYCHOL, V28, P310, DOI 10.1037/h0081997
   Carlisle RS, 1999, LANG LEARN, V49, P59, DOI 10.1046/j.0266-8254.2003.03701.x-i1
   CARLISLE RS, 1991, APPL LINGUIST, V12, P76, DOI 10.1093/applin/12.1.76
   Carlson MT, 2018, LANG SPEECH, V61, P598, DOI 10.1177/0023830918767208
   Carlson MT, 2016, BILING-LANG COGN, V19, P939, DOI 10.1017/S1366728915000334
   Chang CB, 2016, BILING-LANG COGN, V19, P791, DOI 10.1017/S1366728914000261
   Chang CB, 2013, J PHONETICS, V41, P520, DOI 10.1016/j.wocn.2013.09.006
   Chang CB, 2012, J ACOUST SOC AM, V132, P2700, DOI 10.1121/1.4747615
   Chang CB, 2012, J PHONETICS, V40, P249, DOI 10.1016/j.wocn.2011.10.007
   COHEN SP, 1967, LANG SPEECH, V10, P159, DOI 10.1177/002383096701000302
   Cook Vivian, 2016, CAMBRIDGE HDB LINGUI
   COOK VJ, 1992, LANG LEARN, V42, P557, DOI 10.1111/j.1467-1770.1992.tb01044.x
   Cuetos F, 2011, P 17 INT C PHON SCI, P540
   Cuetos F, 2011, PSICOLOGICA, V32, P133
   Dahan D, 2008, COGNITION, V108, P710, DOI 10.1016/j.cognition.2008.06.003
   Daland R, 2015, OPEN LINGUIST, V1, P650, DOI 10.1515/opli-2015-0024
   Davidson L, 2012, J PHONETICS, V40, P234, DOI 10.1016/j.wocn.2011.11.005
   Davidson L, 2011, J EXP PSYCHOL HUMAN, V37, P270, DOI 10.1037/a0020988
   Dijkstra T., 1998, BILING-LANG COGN, V1, P51, DOI DOI 10.1017/S1366728998000121
   Dupoux E, 2001, LANG COGNITIVE PROC, V16, P491, DOI 10.1080/01690960143000191
   Dupoux E, 1997, J MEM LANG, V36, P406, DOI 10.1006/jmla.1996.2500
   Dupoux E, 1999, J EXP PSYCHOL HUMAN, V25, P1568, DOI 10.1037/0096-1523.25.6.1568
   Dupoux E, 2011, J MEM LANG, V64, P199, DOI 10.1016/j.jml.2010.12.004
   Durvasula K, 2015, PHONOLOGY, V32, P385, DOI 10.1017/S0952675715000263
   Elston-Guttler KE, 2009, J COGNITIVE NEUROSCI, V21, P180, DOI 10.1162/jocn.2009.21015
   Elston-Guttler KE, 2005, COGNITIVE BRAIN RES, V25, P57, DOI 10.1016/j.cogbrainres.2005.04.007
   English language Institute, 2001, MELICET GCVR US MAN
   Ernestus M, 2017, J PHONETICS, V62, P50, DOI 10.1016/j.wocn.2017.02.003
   Feldman NH, 2009, PSYCHOL REV, V116, P752, DOI 10.1037/a0017196
   Flege J. E., 2007, LAB PHONOLOGY, P353
   Flege J. E., 2003, PHONETICS PHONOLOGY, P319, DOI DOI 10.1515/9783110895094.319
   FLEGE JE, 1987, J PHONETICS, V15, P67, DOI 10.1016/S0095-4470(19)30538-8
   Fowler CA, 2008, J PHONETICS, V36, P649, DOI 10.1016/j.wocn.2008.04.001
   Freeman MR, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00702
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Gaskell MG, 2001, LANG COGNITIVE PROC, V16, P723, DOI 10.1080/01690960143000128
   Goldrick M, 2016, BILING-LANG COGN, V19, P857, DOI 10.1017/S1366728915000802
   Goldrick M, 2014, PSYCHOL SCI, V25, P1031, DOI 10.1177/0956797613520014
   Gonzales K, 2013, PSYCHOL SCI, V24, P2135, DOI 10.1177/0956797613486485
   GROSJEAN F, 1989, BRAIN LANG, V36, P3, DOI 10.1016/0093-934X(89)90048-5
   GROSJEAN F, 1994, PSYCHOL SCI, V5, P201, DOI 10.1111/j.1467-9280.1994.tb00501.x
   Hall JK, 2006, APPL LINGUIST, V27, P220, DOI 10.1093/applin/aml013
   Halle P. A, 2013, PSICOLINGUISTICA ESP, P31
   Halle PA, 2008, J EXP PSYCHOL HUMAN, V34, P177, DOI 10.1037/0096-1523.34.1.177
   Hanulikova A, 2012, ATTEN PERCEPT PSYCHO, V74, P613, DOI 10.3758/s13414-011-0259-7
   Hanulikova A, 2011, BILING-LANG COGN, V14, P506, DOI 10.1017/S1366728910000428
   Hartsuiker RJ, 2004, PSYCHOL SCI, V15, P409, DOI 10.1111/j.0956-7976.2004.00693.x
   Hay J, 2010, LANG SPEECH, V53, P447, DOI 10.1177/0023830910372489
   Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014
   Heald SLM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00035
   Kabak B, 2007, LANG SPEECH, V50, P23, DOI 10.1177/00238309070500010201
   Keuleers E, 2010, BEHAV RES METHODS, V42, P627, DOI 10.3758/BRM.42.3.627
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kraljic T, 2008, COGNITION, V107, P54, DOI 10.1016/j.cognition.2007.07.013
   KROLL J. F., 2014, OXFORD HDB LANGUAGE, P165, DOI DOI 10.1093/OXFORDHB/9780199735471.013.001
   Kroll JF, 2006, BILING-LANG COGN, V9, P119, DOI 10.1017/S1366728906002483
   Lauro J, 2017, J MEM LANG, V92, P217, DOI 10.1016/j.jml.2016.06.010
   Lentz TO, 2015, LANG SPEECH, V58, P387, DOI 10.1177/0023830914559572
   Li P, 2014, BILING-LANG COGN, V17, P673, DOI 10.1017/S1366728913000606
   Llanos F, 2017, LANG SPEECH, V60, P3, DOI 10.1177/0023830915623579
   Marian V, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043230
   Ministry of Education Culture and Sport of Spain, 2006, DIPL ESP COM LENG EX
   Molnar M, 2015, J MEM LANG, V81, P91, DOI 10.1016/j.jml.2015.01.002
   Namjoshi J., 2015, P 18 INT C PHON SCI
   Norris D, 2016, LANG COGN NEUROSCI, V31, P4, DOI 10.1080/23273798.2015.1081703
   Olson DJ, 2016, J INT PHON ASSOC, V46, P263, DOI 10.1017/S0025100315000468
   Olson DJ, 2016, APPL PSYCHOLINGUIST, V37, P725, DOI 10.1017/S0142716415000223
   Olson DJ, 2013, J PHONETICS, V41, P407, DOI 10.1016/j.wocn.2013.07.005
   Otheguy R, 2015, APPL LINGUIST REV, V6, P281, DOI 10.1515/applirev-2015-0014
   Parlato-Oliveira E, 2010, J ACOUST SOC AM, V127, P3738, DOI 10.1121/1.3327792
   Pitt MA, 1998, PERCEPT PSYCHOPHYS, V60, P941, DOI 10.3758/BF03211930
   Polivanov Evgenij D., 1931, TRAVAUX CERCLE LINGU, V4, P79
   R Core Team, 2016, R LANG ENV STAT COMP
   SAMUEL AG, 1981, J EXP PSYCHOL GEN, V110, P474, DOI 10.1037/0096-3445.110.4.474
   Samuel AG, 2015, J MEM LANG, V81, P51, DOI 10.1016/j.jml.2015.01.003
   Sancier ML, 1997, J PHONETICS, V25, P421, DOI 10.1006/jpho.1997.0051
   Simonet M, 2014, J PHONETICS, V43, P26, DOI 10.1016/j.wocn.2014.01.004
   Spinelli E, 2007, COGNITION, V104, P397, DOI 10.1016/j.cognition.2006.07.002
   Tice M, 2012, 86 ANN M LING SOC AM, P72
   Weber A, 2006, J ACOUST SOC AM, V119, P597, DOI 10.1121/1.2141003
NR 98
TC 1
Z9 1
U1 0
U2 4
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 1366-7289
EI 1469-1841
J9 BILING-LANG COGN
JI Biling.-Lang. Cogn.
PD NOV
PY 2019
VL 22
IS 5
BP 1101
EP 1122
DI 10.1017/S136672891800086X
PG 22
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA KH7WG
UT WOS:000510860000012
DA 2021-02-24
ER

PT J
AU Eger, NA
   Mitterer, H
   Reinisch, E
AF Eger, Nikola Anna
   Mitterer, Holger
   Reinisch, Eva
TI Learning a new sound pair in a second language: Italian learners and
   German glottal consonants
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Speech perception; Spoken word recognition; Speech production; Second
   language acquisition; Orthographic coding; Italian learners of German
ID SPOKEN-WORD RECOGNITION; R-VERTICAL-BAR; SPEECH-PERCEPTION;
   INDIVIDUAL-DIFFERENCES; JAPANESE LISTENERS; PHONOLOGICAL FORMS; ENGLISH
   LEARNERS; TIME-COURSE; LANGUAGE; ORTHOGRAPHY
AB The present study investigated Italian learners' production and perception of German /h/ and /?/ - two sounds that lack obvious linguistic counterparts in Italian. Critically, of these sounds only /h/ is explicitly known to learners from instruction and orthography. We therefore asked whether this awareness would lead to better acquisition of /h/ than /?/, and whether any differences would depend on the explicitness of the task. In production, learners of a medium proficiency level performed accurately in about 70% of the cases, with errors including sound deletions and substitutions. In spoken word recognition, two other learner groups of the same proficiency were hindered by sound deletions, but not by substitutions, although they were able to differentiate the sounds in an explicit goodness rating task. Overall, acquisition of /?/ was similar to /h/, despite lack of awareness for this sound. The results suggest that learners have established one combined "glottal category" to which both sounds map in speech processing, while they may be better implemented in production. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Eger, Nikola Anna; Reinisch, Eva] Ludwig Maximilian Univ Munich, Inst Phonet & Speech Proc, Schellingstr 3, D-80799 Munich, Germany.
   [Mitterer, Holger] Univ Malta, Dept Cognit Sci, Msida, Malta.
RP Eger, NA (corresponding author), Ludwig Maximilian Univ Munich, Inst Phonet & Speech Proc, Schellingstr 3, D-80799 Munich, Germany.
EM eger.nikola@outlook.de; holger.mitterer@um.edu.mt;
   evarei@phonetik.uni-muenchen.de
RI Eger, Nikola/ABB-5403-2020; Mitterer, Holger/D-1908-2010
OI Mitterer, Holger/0000-0003-4318-0032
FU German Research Council (DFG)German Research Foundation (DFG) [RE
   3047/1-1]
FX This work was funded by a grant from the German Research Council (DFG:
   grant nr. RE 3047/1-1) to Eva Reinisch, and was part of Nikola Eger's
   PhD project. Parts of the work were presented at the workshop
   Phonetik&Phonologie 2018, in Vienna, Austria. We would like to express
   special thanks to Thomas Geyer for the use of the eye-tracker at the
   Department of Psychology of the University of Munich. We would also like
   to thank Rosa Franzke who helped with recruiting and testing
   participants and with the annotation of the production data.
CR Akahane-Yamada R., 1998, 5 INT C SPOK LANG PR
   Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   [Anonymous], 2011, SR RES EXP BUILD 1 1
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bassetti B, 2017, J EXP PSYCHOL LEARN, V43, P1835, DOI 10.1037/xlm0000417
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Bertinetto Pier Marco, 2005, J INT PHON ASSOC, V35, P131, DOI DOI 10.1017/S0025100305002148
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bohn O.-S., 1992, STUDIES 2 LANGUAGE A, V14, P131, DOI DOI 10.1017/S0272263100010792
   Bohn O.-S., 1995, SPEECH PERCEPTION LI, P279
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Broersma M, 2005, J ACOUST SOC AM, V117, P3890, DOI 10.1121/1.1906060
   Broersma M, 2008, SYSTEM, V36, P22, DOI 10.1016/j.system.2007.11.003
   Brysbaert M, 2011, EXP PSYCHOL, V58, P412, DOI 10.1027/1618-3169/a000123
   Cebrian J., 2000, STUDIES 2 LANGUAGE A, V22, P1, DOI DOI 10.1017/S0272263100001017
   COOPER RM, 1974, COGNITIVE PSYCHOL, V6, P84, DOI 10.1016/0010-0285(74)90005-X
   Council of Europe, 2011, COMMON EUROPEAN FRAM
   Cutler A, 2006, J PHONETICS, V34, P269, DOI 10.1016/j.wocn.2005.06.002
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750
   de Groot F, 2016, J EXP PSYCHOL HUMAN, V42, P180, DOI 10.1037/xhp0000102
   Diaz B, 2012, LEARN INDIVID DIFFER, V22, P680, DOI 10.1016/j.lindif.2012.05.005
   Draxler Christoph, 2004, P 4 INT C LANG RES E, P559
   Eger N. A., 2015, P 18 INT C PHON SCI
   Eger NA, 2019, J EXP PSYCHOL LEARN, V45, P552, DOI 10.1037/xlm0000599
   Escudero P, 2008, J PHONETICS, V36, P345, DOI 10.1016/j.wocn.2007.11.002
   Escudero P, 2015, APPL PSYCHOLINGUIST, V36, P7, DOI 10.1017/S014271641400040X
   Fanciullo, 2002, DIALETTI ITALIANI ST, P629
   Faris MM, 2018, J PHONETICS, V70, P1, DOI 10.1016/j.wocn.2018.05.003
   Faris MM, 2016, J ACOUST SOC AM, V139, pEL1, DOI 10.1121/1.4939608
   Field A, 2012, DISCOVERING STAT USI
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2003, PHONETICS PHONOLOGY, P319, DOI DOI 10.1515/9783110895094.319
   FLEGE JE, 1987, J PHONETICS, V15, P67, DOI 10.1016/S0095-4470(19)30538-8
   Gluszek A, 2011, J LANG SOC PSYCHOL, V30, P28, DOI 10.1177/0261927X10387100
   Hattori K, 2009, J ACOUST SOC AM, V125, P469, DOI 10.1121/1.3021295
   Hayes-Harb R, 2010, LANG SPEECH, V53, P367, DOI 10.1177/0023830910371460
   Herd W, 2013, J ACOUST SOC AM, V133, P4247, DOI 10.1121/1.4802902
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Huettig F, 2007, J MEM LANG, V57, P460, DOI 10.1016/j.jml.2007.02.001
   Huettig F, 2011, ACTA PSYCHOL, V137, P151, DOI 10.1016/j.actpsy.2010.11.003
   Hughes A., 2012, ENGLISH ACCENTS DIAL
   Ingram JCL, 1997, J PHONETICS, V25, P343, DOI 10.1006/jpho.1997.0048
   Ingvalson EM, 2012, BILING-LANG COGN, V15, P255, DOI 10.1017/S1366728911000447
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Kartushina N, 2015, J ACOUST SOC AM, V138, P817, DOI 10.1121/1.4926561
   Kartushina N, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01246
   Kassaian Z., 2011, J LANG TEACHING RES, V2, P370, DOI [10.4304/jltr.2.2.370-376, DOI 10.4304/JLTR.2.2.370-376]
   Kisler T, 2017, COMPUT SPEECH LANG, V45, P326, DOI 10.1016/j.csl.2017.01.005
   Kohler K. J., 1995, EINFUHRUNG PHONETIK, V20
   KOHLER KJ, 1994, PHONETICA, V51, P38, DOI 10.1159/000261957
   Kramer M., 2009, PHONOLOGY ITALIAN
   Krieger-Redwood K, 2013, J COGNITIVE NEUROSCI, V25, P2179, DOI 10.1162/jocn_a_00463
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Llompart M, 2019, BILING-LANG COGN, V22, P1085, DOI 10.1017/S1366728918000925
   Llompart M, 2019, LANG SPEECH, V62, P594, DOI 10.1177/0023830918803978
   Llompart M, 2017, J EXP PSYCHOL HUMAN, V43, P1040, DOI 10.1037/xhp0000383
   Maddieson I., 1996, THE SOUNDS OF THE WO
   Magno-Caldognetto E. M., 1997, 5 EUR C SPEECH COMM, P779
   Mairano P, 2018, REV FR LING APPL, V23, P45
   MALECOT A, 1975, PHONETICA, V31, P51, DOI 10.1159/000259649
   Marotta G, 2008, STUD GENERAT GRAMM, V99, P235
   McAllister R, 2002, J PHONETICS, V30, P229, DOI 10.1006/jpho.2002.0174
   McQueen JM, 2012, LANG LEARN DEV, V8, P317, DOI 10.1080/15475441.2011.641887
   Mitterer H, 2018, J PHONETICS, V66, P28, DOI 10.1016/j.wocn.2017.09.003
   Mitterer H, 2015, J MEM LANG, V85, P116, DOI 10.1016/j.jml.2015.08.005
   MORAIS J, 1979, COGNITION, V7, P323, DOI 10.1016/0010-0277(79)90020-9
   MORSE PA, 1972, J EXP CHILD PSYCHOL, V14, P477, DOI 10.1016/0022-0965(72)90066-5
   Ohk B, 2006, DIZZJUNARJU GERMANIZ
   Pallier C, 2001, PSYCHOL SCI, V12, P445, DOI 10.1111/1467-9280.00383
   Pallier C, 1997, COGNITION, V64, pB9, DOI 10.1016/S0010-0277(97)00030-9
   Pattamadilok C, 2014, BRAIN LANG, V137, P103, DOI 10.1016/j.bandl.2014.08.005
   Patterson D, 2001, PHONETICA, V58, P254, DOI 10.1159/000046178
   Peperkamp S, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P168
   Pompino-Marshall B., 2010, ZAS PAPERS LINGUISTI, V52, P1
   R Core Team, 2017, R LANG ENV STAT COMP
   Raudenbush SW, 2000, J COMPUT GRAPH STAT, V9, P141, DOI 10.2307/1390617
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rose M., 2010, SEL P 2008 2 LANG RE, P181
   Scarpace D., 2014, CONCORDIA WORKING PA, V5, P580
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   Sebastian-Galles N, 2012, LANG LEARN, V62, P131, DOI 10.1111/j.1467-9922.2012.00709.x
   SHELDON A, 1982, APPL PSYCHOLINGUIST, V3, P243, DOI 10.1017/S0142716400001417
   Simonchyk A, 2018, LANG SPEECH, V61, P522, DOI 10.1177/0023830918761490
   Smith BL, 2009, J PHONETICS, V37, P257, DOI 10.1016/j.wocn.2009.03.001
   Spivey MJ, 1999, PSYCHOL SCI, V10, P281, DOI 10.1111/1467-9280.00151
   Stevens M., 2002, RADDOPPIAMENTO SINTA, P154
   Tsukada K, 2005, J PHONETICS, V33, P263, DOI 10.1016/j.wocn.2004.10.002
   van Santen J, 1999, P 14 INT C PHON SCI, P1757
   Virdis Maurizio, 1978, FONETICA DIALETTO SA
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0
   White EJ, 2017, BILING-LANG COGN, V20, P162, DOI 10.1017/S1366728915000620
   Wiese R., 1996, PHONOLOGY GERMAN
   Wong J. W. S., 2013, P INTERSPEECH, V14, P2113
   YAMADA RA, 1995, SPEECH PERCEPTION LI, P305
   Ziegler W, 2010, MENTALE SPRACHVERARB, V6, P257
   Zimmerer F., 2015, TRENDS PHONETICS PHO, P198
   Zimmerer F, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1922
NR 100
TC 1
Z9 1
U1 1
U2 4
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD NOV
PY 2019
VL 77
AR 100917
DI 10.1016/j.wocn.2019.100917
PG 24
WC Linguistics; Language & Linguistics
SC Linguistics
GA JY4GI
UT WOS:000504374900001
DA 2021-02-24
ER

PT J
AU Schonhuber, M
   Czeke, N
   Gampe, A
   Grijzenhout, J
AF Schoenhuber, Muna
   Czeke, Nathalie
   Gampe, Anja
   Grijzenhout, Janet
TI Infant perception of VOT and closure duration contrasts
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Infant speech perception; VOT; Closure duration; Perceptual
   reorganisation; German; Swiss German; Labial stops
ID VOICE ONSET TIME; NONNATIVE SPEECH CONTRASTS; CROSS-LANGUAGE; LINGUISTIC
   EXPERIENCE; PHONETIC DETAIL; FAMILIAL RISK; VOWEL LENGTH;
   DISCRIMINATION; GERMAN; ADULTS
AB Previous research suggests that infant perception of phonetic contrasts undergoes a reorganisation during the first year of life with universal sound discrimination from birth that adapts to the native phoneme contrasts around 12 months of age. This paper focuses on two closely related languages that crucially differ in the realisation of stop contrasts: (Standard High) German and Swiss German. The first employs a VOT contrast for tense/lax stops, the latter uses a length contrast to distinguish singletons and geminates.
   In a habituation paradigm, German and Swiss infants aged 7, 11 and 15 months were tested on their ability to discriminate (a) VOT contrasts and (b) closure duration contrasts for labial stops. Results show that German infants discriminated the VOT contrast at all ages. Swiss German infants discriminated the VOT contrast at 11 months only. At 7 months, neither German nor Swiss German children discriminated the closure duration contrast, whereas both groups were able to perceive the contrast at 11 and 15 months of age. Our findings contribute to clarifying the so far inconsistent picture of infant perception of length contrasts. We discuss the findings critically with regard to the different dimensions of VOT and closure duration. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Schoenhuber, Muna; Czeke, Nathalie; Grijzenhout, Janet] Univ Konstanz, D-78457 Constance, Germany.
   [Gampe, Anja] Univ Zurich, Ramistr 71, CH-8006 Zurich, Switzerland.
   [Grijzenhout, Janet] Leiden Univ, POB 9500, NL-2300 RA Leiden, Netherlands.
RP Schonhuber, M (corresponding author), Univ Konstanz, D-78457 Constance, Germany.
EM muna.schoenhuber@uni-konstanz.de; nathalie.czeke@uni-konstanz.de;
   a.gampe@psychologie.uzh.ch; j.grijzenhout@hum.leidenuniv.nl
OI Gampe, Anja/0000-0001-9812-9694
FU DFGGerman Research Foundation (DFG)European Commission; project D8 of
   the DFG-funded collaborative research centre Variation and Evolution in
   the Lexicon [SFB 471]; Young Scholar Fund of the University of Konstanz
FX We gratefully acknowledge funding from the DFG. The work presented here
   was done as part of project D8 of the DFG-funded collaborative research
   centre SFB 471 Variation and Evolution in the Lexicon. Further funding
   was provided by a grant of the Young Scholar Fund of the University of
   Konstanz awarded to the first author.
CR ABRAMSON A, 1991, P 12 INT C PHON SCI, P98
   Abramson AS, 2017, J PHONETICS, V63, P75, DOI 10.1016/j.wocn.2017.05.002
   Altvater-Mackensen N, 2010, LINGUA, V120, P1898, DOI 10.1016/j.lingua.2010.02.010
   Aoyama K, 2002, STUDIES LANGUAGE SCI, P121
   Aslin R. N., 1980, CHILD PHONOLOGY PERC, V2, P64
   ASLIN RN, 1980, CHILD DEV, V51, P107, DOI 10.2307/1129596
   ASLIN RN, 1981, CHILD DEV, V52, P1135, DOI 10.1111/j.1467-8624.1981.tb03159.x
   Benson RR, 2001, BRAIN LANG, V78, P364, DOI 10.1006/brln.2001.2484
   Best CC, 2003, LANG SPEECH, V46, P183, DOI 10.1177/00238309030460020701
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Blomert L, 2004, BRAIN LANG, V89, P21, DOI 10.1016/S0093-934X(03)00305-5
   Boersma P., 2007, DOING PHONETICS COMP
   BOHN OS, 1990, APPL PSYCHOLINGUIST, V11, P303, DOI 10.1017/S0142716400008912
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Braunschweiler N, 1997, LANG SPEECH, V40, P353, DOI 10.1177/002383099704000403
   Burns TC, 2007, APPL PSYCHOLINGUIST, V28, P455, DOI 10.1017/S0142716407070257
   Cheour M., 1998, NAT NEUROSCI, V1, P531
   Cho T, 1999, J PHONETICS, V27, P207, DOI 10.1006/jpho.1999.0094
   Cho T, 2019, J PHONETICS, V72, P52, DOI 10.1016/j.wocn.2018.11.002
   Cohen L. B., 2004, HABIT 10 NEW PROGRAM
   COHEN LB, 1992, DEV PSYCHOL, V28, P261, DOI 10.1037/0012-1649.28.2.261
   Conboy BT, 2008, DEV PSYCHOL, V44, P1505, DOI 10.1037/a0012975
   Danielson DK, 2017, COGNITIVE DEV, V42, P37, DOI 10.1016/j.cogdev.2017.02.004
   Dar M, 2018, J PHONETICS, V67, P49, DOI 10.1016/j.wocn.2017.12.002
   EILERS RE, 1979, CHILD DEV, V50, P14
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   ENSTROM DH, 1981, FOLIA PHONIATR, V33, P137
   Fennell CT, 2010, CHILD DEV, V81, P1376, DOI 10.1111/j.1467-8624.2010.01479.x
   Fennell CT, 2004, PROC ANN BUCLD, P165
   FERNALD A, 1987, INFANT BEHAV DEV, V10, P279, DOI 10.1016/0163-6383(87)90017-8
   FERNALD A, 1985, INFANT BEHAV DEV, V8, P181, DOI 10.1016/S0163-6383(85)80005-9
   Fikkert P, 2010, LAB PHONOL, V10, P227, DOI DOI 10.1515/9783110224917.3.227
   Fleischer Jurg, 2006, J INT PHON ASSOC, V36, P243, DOI DOI 10.1017/S0025100306002441
   Francis AL, 2006, J ACOUST SOC AM, V120, P2884, DOI 10.1121/1.2346131
   Fulop S., 1994, CALGARY WORKING PAPE, V16, P55
   Grice M., 2002, LINGUISTISCHE BERICH, V191, P267
   Grice Martine, 2005, PROSODIC TYPOLOGY PH, P55, DOI [DOI 10.1093/ACPROF:OSO/9780199249633.003.0003, 10.1093/acprof:oso/9780199249633.003.0003]
   Hollich G, 2005, SUPERCODER PROGRAM C
   Iverson Gregory K., 2003, PHONOLOGY, V20, P43, DOI DOI 10.1017/S0952675703004469
   Iverson P., 2001, SPEECH HEARING LANGU, V13, P1
   Jessen M., 2002, PHONOLOGY, V19, P189, DOI [10.1017/S0952675702004311, DOI 10.1017/S0952675702004311]
   Jessen M., 1998, PHONETICS PHONOLOGY
   KINGSTON J, 1994, LANGUAGE, V70, P419, DOI 10.2307/416481
   Kirby JP, 2018, J PHONETICS, V71, P326, DOI 10.1016/j.wocn.2018.09.009
   Kraehenmann A, 2001, PHONOLOGY, V18, P109
   KRAEHENMANN A, 2003, QUANTITY PROSODIC AS
   Kraehenmann A, 2008, J ACOUST SOC AM, V123, P4446, DOI 10.1121/1.2916699
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Kuhl PK, 2001, ANN NY ACAD SCI, V935, P136, DOI 10.1111/j.1749-6632.2001.tb03478.x
   Kuijpers CTL, 1996, J PHONETICS, V24, P367, DOI 10.1006/jpho.1996.0020
   Kunnari S., 2001, PSYCHOL LANGUAGE COM, V5, P13
   Ladd D. R., 2017, PHON PHON EUR COL GE
   Ladd DR, 2018, J PHONETICS, V71, P229, DOI 10.1016/j.wocn.2018.09.003
   Ladefoged Peter, 1996, SOUNDS WORLDS LANGUA
   Lahiri A, 2010, J PHONETICS, V38, P44, DOI 10.1016/j.wocn.2010.01.002
   LASKY RE, 1975, J EXP CHILD PSYCHOL, V20, P215, DOI 10.1016/0022-0965(75)90099-5
   Leppanen PHT, 2002, DEV NEUROPSYCHOL, V22, P407, DOI 10.1207/S15326942dn2201_4
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Mikuteit S., 2006, THESIS
   Mitleb F. M., 1981, THESIS
   Narayan C. R., 2013, ORIGINS SOUND CHANGE
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   PEGG JE, 1992, INFANT BEHAV DEV, V15, P325, DOI 10.1016/0163-6383(92)80003-D
   Pisoni D. B., 1982, Speech Technology, V1, P10
   Pisoni D. B., 1980, ICASSP 80 Proceedings. IEEE International Conference on Acoustics, Speech and Signal Processing, P572
   Pisoni D. B., 1981, J ACOUST SOC AM, V70, pS98, DOI [10.1121/1.2019150, DOI 10.1121/1.2019150]
   Pisoni David B, 1987, Comput Speech Lang, V2, P303, DOI 10.1016/0885-2308(87)90014-3
   Pohl K, 2010, REQUIREMENTS ENGINEERING: FUNDAMENTALS, PRINCIPLES, AND TECHNIQUES, P141
   Pohl M., 2011, THESIS
   Polka L, 1996, J ACOUST SOC AM, V100, P577, DOI 10.1121/1.415884
   Polka L, 2001, J ACOUST SOC AM, V109, P2190, DOI 10.1121/1.1362689
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Richardson U, 2003, DEV NEUROPSYCHOL, V23, P385, DOI 10.1207/S15326942DN2303_5
   Rivera-Gaxiola M, 2005, DEVELOPMENTAL SCI, V8, P162, DOI 10.1111/j.1467-7687.2005.00403.x
   Sato Y, 2012, DEV PSYCHOL, V48, P18, DOI 10.1037/a0025528
   Sato Y, 2010, DEV PSYCHOL, V46, P106, DOI 10.1037/a0016718
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   STREETER LA, 1976, NATURE, V259, P39, DOI 10.1038/259039a0
   Sundara M, 2018, COGNITION, V178, P57, DOI 10.1016/j.cognition.2018.05.009
   TREHUB SE, 1972, DEV PSYCHOL, V6, P74, DOI 10.1037/h0032197
   Tsao FM, 2006, J ACOUST SOC AM, V120, P2285, DOI 10.1121/1.2338290
   van Alphen PM, 2004, J PHONETICS, V32, P455, DOI 10.1016/j.wocn.2004.05.001
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1988, DEV PSYCHOL, V24, P672, DOI 10.1037/0012-1649.24.5.672
   Werker JF, 1998, DEV PSYCHOL, V34, P1289, DOI 10.1037/0012-1649.34.6.1289
   Willi U., 1996, Z DIALEKTOLOGIE LING, V92
   Zahner K., 2016, P 8 INT C SPEECH PRO, P562
NR 88
TC 0
Z9 0
U1 1
U2 1
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD NOV
PY 2019
VL 77
AR 100916
DI 10.1016/j.wocn.2019.100916
PG 21
WC Linguistics; Language & Linguistics
SC Linguistics
GA JY4GI
UT WOS:000504374900002
DA 2021-02-24
ER

PT J
AU Ramos-Favaretto, FS
   Fukushiro, AP
   Scarmagnani, RH
   Yamashita, RP
AF Ramos-Favaretto, Francine Santos
   Fukushiro, Ana Paula
   Scarmagnani, Rafaeli Higa
   Yamashita, Renata Paciello
TI Borg scale: a new method for hypernasality rating
SO CODAS
LA English
DT Article
DE Velopharyngeal Insufficiency; Cleft Palate; Speech Disorders; Speech
   Perception; Speech
ID DIRECT MAGNITUDE ESTIMATION; NASAL AIR-FLOW; CLEFT-PALATE; SPEECH
   OUTCOMES; VELOPHARYNGEAL FUNCTION; CHILDREN; INDIVIDUALS; RELIABILITY;
   JUDGMENTS; EMISSION
AB Purpose: To investigate the reliability in auditory-perceptual assessment of hypernasality of the Borg centiMax scale and the influence of the speech material on the reliability of two scales. Methods: Four experienced speech-language pathologists rated hypernasality of 80 audio recordings of patients with repaired cleft palate (40 single-word string and 40 sentences) using the 5-point ordinal scale and the Borg centiMax scale. Intra and inter-rater reliability were calculated for both scales and for both types of speech samples. The comparison between the agreement coefficients of the two speech samples was calculated using the Z test and between the scales was calculated by Spearman correlation coefficient, considering as significant p<0.05. Results: A very high and statistically significant correlation was found between the Borg centiMax scale and the ordinal scale for both speech samples. Intra- and inter-rater reliability was higher for Borg scale as compared to ordinal scale. Good to excellent intra-rater reliability was found for Borg scale for both speech samples. Poor to excellent intra-rater reliability was found for ordinal scale for both stimuli. Higher inter-rater reliability was demonstrated for Borg scale than ordinal scale for both speech samples. There was a significant difference between the single words string and sentences for intra- and inter-rater reliability using Borg scale, and for inter-rater reliability using ordinal scale. Conclusion: The Borg centiMax scale showed better intra and inter-rater reliability. Additionally, the speech material comprising of single words string showed better reliability in most of the comparisons for both scales.
C1 [Ramos-Favaretto, Francine Santos; Fukushiro, Ana Paula; Scarmagnani, Rafaeli Higa; Yamashita, Renata Paciello] Univ Sao Paulo, Hosp Reabilitacao Anomalias Craniofaciais, Lab Fisiol, Rua Silvio Marchione 3-20, BR-17012900 Bauru, SP, Brazil.
   [Fukushiro, Ana Paula] Univ Sao Paulo, Fac Odontol Bauru, Dept Fonoaudiol, Bauru, SP, Brazil.
RP Yamashita, RP (corresponding author), Univ Sao Paulo, Hosp Reabilitacao Anomalias Craniofaciais, Lab Fisiol, Rua Silvio Marchione 3-20, BR-17012900 Bauru, SP, Brazil.
EM rezeyama@usp.br
FU CAPESCAPES
FX CAPES - universial demand.
CR Baylis A, 2015, CLEFT PALATE-CRAN J, V52, P660, DOI 10.1597/14-040
   Borg E., 2007, THESIS
   Borg G., 2001, PSYCHOLOGICA, V28, P15
   Brancamp TU, 2010, CLEFT PALATE-CRAN J, V47, P631, DOI 10.1597/09-106
   Brandao GR, 2011, J CRANIOFAC SURG, V22, P1736, DOI 10.1097/SCS.0b013e31822e624f
   Brunnegard K, 2007, CLEFT PALATE-CRAN J, V44, P33, DOI 10.1597/05-164
   Brunnegard K, 2012, INT J LANG COMM DIS, V47, P556, DOI 10.1111/j.1460-6984.2012.00165.x
   Castick S, 2017, CLEFT PALATE-CRAN J, V54, P19, DOI 10.1597/15-164
   Cicchetti D. V., 1994, PSYCHOL ASSESS, V6, P284, DOI [10.1037/1040-3590.6.4.284, DOI 10.1037/1040-3590.6.4.284]
   Santos ACD, 2016, CODAS, V28, P141, DOI 10.1590/2317-1782/20162015163
   Dotevall H, 2002, CLEFT PALATE-CRAN J, V39, P409, DOI 10.1597/1545-1569(2002)039<0409:PEOSAV>2.0.CO;2
   Eadie TL, 2011, J SPEECH LANG HEAR R, V54, P430, DOI 10.1044/1092-4388(2010/09-0205)
   Ferlin Flávia, 2017, Audiol., Commun. Res., V22, pe1851, DOI 10.1590/2317-6431-2017-1851
   Gerlach Y, 2013, INT J OBESITY, V37, P341, DOI 10.1038/ijo.2012.49
   Griep MI, 1998, FOOD QUAL PREFER, V9, P67, DOI 10.1016/S0950-3293(97)00030-X
   Henningsson G, 2008, CLEFT PALATE-CRAN J, V45, P1, DOI 10.1597/06-086.1
   Karavatas SG, 2005, INTERNET J ALLIED HE, V3
   Kent R. D., 1996, AM J SPEECH LANG PAT, V5, P7, DOI [DOI 10.1044/1058-0360.0503.07, 10.1044/1058- 0360.0503.07]
   Lee A, 2009, CLIN LINGUIST PHONET, V23, P319, DOI 10.1080/02699200802688596
   de Medeiros MNL, 2016, CODAS, V28, P289, DOI 10.1590/2317-1782/20162015202
   Lohmander A, 2009, CLEFT PALATE-CRAN J, V46, P347, DOI 10.1597/08-039.1
   Lohmander A, 2017, J PLAST SURG HAND SU, V51, P27, DOI 10.1080/2000656X.2016.1254645
   Mukaka MM, 2012, MALAWI MED J, V24, P69
   Persson C, 2006, CLEFT PALATE-CRAN J, V43, P295, DOI 10.1597/04-071R1.1
   Scarmagnani RH, 2015, CODAS, V27, P267, DOI 10.1590/2317-1782/20152014145
   Stevens Stanley Smith, 1975, PSYCHOPHYSICS INTRO
   van Leer E, 2017, J VOICE, V31, pe19, DOI DOI 10.1016/J.JV0ICE.2016.09.023.PMID:27887811
   Watterson T, 2007, J COMMUN DISORD, V40, P503, DOI 10.1016/j.jcomdis.2007.02.002
   Whitehill TL, 2002, J SPEECH LANG HEAR R, V45, P80, DOI 10.1044/1092-4388(2002/006)
   Yamashita RP, 2018, CLEFT PALATE-CRAN J, V55, P1060, DOI 10.1177/1055665618767116
NR 30
TC 0
Z9 0
U1 0
U2 0
PU SOC BRASILEIRA FONOAUDIOLOGIA
PI SAO PAULO SP
PA AL JAU, 684 7 ANDAR, SAO PAULO SP, 01420-001, BRAZIL
SN 2317-1782
J9 CODAS
JI CoDAS
PD NOV
PY 2019
VL 31
IS 6
AR e20180296
DI 10.1590/2317-1782/20192018296
PG 8
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA JU8DS
UT WOS:000501901400009
PM 31800882
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU de Klerk, M
   Veen, D
   Wijnen, F
   de Bree, E
AF de Klerk, Maartje
   Veen, Duco
   Wijnen, Frank
   de Bree, Elise
TI A step forward: Bayesian hierarchical modelling as a tool in assessment
   of individual discrimination performance
SO INFANT BEHAVIOR & DEVELOPMENT
LA English
DT Article
DE Speech sound discrimination; Hybrid visual fixation; Individual
   analysis; Autoregressive error structure; Bayesian hierarchical modeling
ID SPEECH-PERCEPTION; LANGUAGE-DEVELOPMENT; PREDICTS; INFANCY; TIME
AB Individual assessment of infants' speech discrimination is of great value for studies of language development that seek to relate early and later skills, as well as for clinical work. The present study explored the applicability of the hybrid visual fixation paradigm (Houston et al., 2007) and the associated statistical analysis approach to assess individual discrimination of a native vowel contrast, /a:/- /e:/, in Dutch 6 to 10-month-old infants. Houston et al. found that 80% (8/10) of the 9-month-old infants successfully discriminated the contrast between pseudowords boodup - seepug. Using the same approach, we found that 12% (14/117) of the infants in our sample discriminated the highly salient /a:/-/e:/ contrast. This percentage was reduced to 3% (3/117) when we corrected for multiple testing. Bayesian hierarchical modeling indicated that 50% of the infants showed evidence of discrimination. Advantages of Bayesian hierarchical modeling are that 1) there is no need for a correction for multiple testing and 2) better estimates at the individual level are obtained. Thus, individual speech discrimination can be more accurately assessed using state of the art statistical approaches.
C1 [de Klerk, Maartje; Wijnen, Frank] Univ Utrecht, Utrecht Inst Linguist OTS UiL OTS, Trans 10, NL-3512 JK Utrecht, Netherlands.
   [Veen, Duco] Univ Utrecht, Dept Methodol & Stat, Padualaan 14, NL-3584 CH Utrecht, Netherlands.
   [de Bree, Elise] Univ Amsterdam, RICDE, POB 15780, NL-1001 NG Amsterdam, Netherlands.
RP de Klerk, M (corresponding author), Univ Utrecht, Utrecht Inst Linguist OTS UiL OTS, Trans 10, NL-3512 JK Utrecht, Netherlands.
EM m.k.a.deklerk@uu.nl
OI Wijnen, Frank/0000-0002-7196-6000; de Klerk,
   Maartje/0000-0002-5466-6196; de Bree, Elise/0000-0001-5258-7518; Veen,
   Duco/0000-0002-8352-7574
FU Netherlands Organization for Scientific Research (NWO)Netherlands
   Organization for Scientific Research (NWO) [360-70-270, VIDI-452-14-006]
FX We are grateful to the infants and their caregivers for participating.
   We would like to thank the student assistants Sule Kurtcebe, Tinka
   Versteegh, Lorijn Zaadnoordijk and Joleen Zuidema, who helped collecting
   data. We would like to thank Annemarie Kerkhoff for her help in the
   design of the experiment and Derek Houston for sharing some of his raw
   data with us (see Appendix A). This research was funded by The
   Netherlands Organization for Scientific Research (NWO). Grants nr.
   360-70-270, awarded to F.N.K. Wijnen and nr. VIDI-452-14-006, awarded to
   R. van de Schoot.
CR Altvater-Mackensen N, 2015, CHILD DEV, V86, P362, DOI 10.1111/cdev.12320
   Aslin RN, 2005, TRENDS COGN SCI, V9, P92, DOI 10.1016/j.tics.2005.01.003
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Colombo J, 2009, NEUROBIOL LEARN MEM, V92, P225, DOI 10.1016/j.nlm.2008.06.002
   Cristia A, 2016, INFANCY, V21, P648, DOI 10.1111/infa.12127
   Cristia A, 2014, CHILD DEV, V85, P1330, DOI 10.1111/cdev.12193
   Cristia A, 2011, J ACOUST SOC AM, V129, P3271, DOI 10.1121/1.3562562
   de Klerk M, 2019, LANG LEARN DEV, V15, P14, DOI 10.1080/15475441.2018.1497490
   Dijkstra N, 2011, PROC ANN BUCLD, P170
   Gelman A, 2000, COMPUTATION STAT, V15, P373, DOI 10.1007/s001800000040
   Gelman A., 2013, BAYESIAN DATA ANAL, V3
   Gelman A, 2006, TECHNOMETRICS, V48, P432, DOI 10.1198/004017005000000661
   Gelman A, 2012, J RES EDUC EFF, V5, P189, DOI 10.1080/19345747.2011.618213
   HORN DL, 2007, AUDIOL MED, V5, P232
   Houston DM, 2007, INFANCY, V12, P119, DOI 10.1111/j.1532-7078.2007.tb00237.x
   Houston-Price C, 2004, INFANT CHILD DEV, V13, P341, DOI 10.1002/icd.364
   Junge C, 2014, BRAIN SCI, V4, P532, DOI 10.3390/brainsci4040532
   Kruschke JK, 2013, J EXP PSYCHOL GEN, V142, P573, DOI 10.1037/a0029146
   Lee M. D., 2018, STEVENS HDB EXPT PSY, V5, P37
   Liu LQ, 2016, INT J BILINGUAL, V20, P335, DOI 10.1177/1367006914566082
   Liu LQ, 2015, INFANT BEHAV DEV, V38, P27, DOI 10.1016/j.infbeh.2014.12.004
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   Melvin SA, 2017, INFANCY, V22, P42, DOI 10.1111/infa.12145
   Molfese DL, 2000, BRAIN LANG, V72, P238, DOI 10.1006/brln.2000.2287
   Newman R, 2006, DEV PSYCHOL, V42, P643, DOI 10.1037/0012-1649.42.4.643
   Oakes LM, 2010, J COGN DEV, V11, P255, DOI 10.1080/15248371003699977
   Smits R, 2003, J ACOUST SOC AM, V113, P563, DOI 10.1121/1.1525287
   Sokolov E.N., 1963, PERCEPTION CONDITION
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Tsuji S, 2014, DEV PSYCHOBIOL, V56, P179, DOI 10.1002/dev.21179
NR 30
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0163-6383
EI 1879-0453
J9 INFANT BEHAV DEV
JI Infant Behav. Dev.
PD NOV
PY 2019
VL 57
AR 101345
DI 10.1016/j.infbeh.2019.101345
PG 14
WC Psychology, Developmental
SC Psychology
GA JS5VS
UT WOS:000500374700046
PM 31563856
OA Green Published
DA 2021-02-24
ER

PT J
AU Kalashnikova, M
   Goswami, U
   Burnham, D
AF Kalashnikova, Marina
   Goswami, Usha
   Burnham, Denis
TI Delayed development of phonological constancy in toddlers at family risk
   for dyslexia
SO INFANT BEHAVIOR & DEVELOPMENT
LA English
DT Article
ID EVENT-RELATED POTENTIALS; SPEECH-PERCEPTION; LANGUAGE-DEVELOPMENT;
   INFANTS SENSITIVITY; LITERACY SKILLS; GENETIC RISK; CHILDREN; DEFICITS;
   PATTERNS; DISCRIMINATION
AB Phonological constancy refers to infants' ability to disregard variations in the phonetic realisation of speech sounds that do not indicate lexical contrast, e.g., when listening to accented speech. In typically-developing infants, this ability develops between 15- and 19-months of age, coinciding with the consolidation of infants' native phonological competence and vocabulary growth. Here we investigated the developmental time course of phonological constancy in infants at family risk for developmental dyslexia, using a longitudinal design. Developmental dyslexia is a disorder affecting the acquisition of reading and spelling skills, and it also affects early auditory processing, speech perception, and lexical acquisition. Infants at-risk and not at-risk for dyslexia, based on a family history of dyslexia, participated when they were 15-, 19-, and 26-months of age. Phonological constancy was indexed by comparing at-risk and not at-risk infants' ability to recognise familiar words in two preferential looking tasks: (1) a task using words presented in their native accent, and (2) a task using words presented in a non-native accent. We expected a delay in phonological constancy for the at-risk infants. As predicted, in the non-native accent task, not at-risk infants recognised familiar words by 19 months, but at-risk infants did not. The control infants thus exhibited phonological constancy. By 26 months, at-risk toddlers did show successful word recognition in the native accent task. However, for the non-native accent task at 26 months, neither at-risk nor control infants showed familiar word recognition. These findings are discussed in terms of the impact of family risk for dyslexia on toddlers' consolidation of early phonological and lexical skills.
C1 [Kalashnikova, Marina] Basque Ctr Cognit Brain & Language, BCBL, Mikeletegi Pasealekua 69, Donostia San Sebastian 20009, Gipuzkoa, Spain.
   [Kalashnikova, Marina; Burnham, Denis] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Penrith, NSW, Australia.
   [Goswami, Usha] Univ Cambridge, Ctr Neurosci Educ, Cambridge, England.
RP Kalashnikova, M (corresponding author), Basque Ctr Cognit Brain & Language, BCBL, Mikeletegi Pasealekua 69, Donostia San Sebastian 20009, Gipuzkoa, Spain.
EM m.kalashnikova@bcbl.eu
OI Burnham, Denis/0000-0002-1980-3458; Goswami, Usha/0000-0001-7858-2336;
   Kalashnikova, Marina/0000-0002-7924-8687
FU Australian Research CouncilAustralian Research Council [DP110105123]
FX This research was supported by the Australian Research Council grant
   DP110105123, 'The Seeds of Literacy', to the 3rd and 2nd authors. We
   thank Maria Cristou-Ergos, Scott O'Loughlin, and Hana Zjakic for their
   assistance with participant recruitment, data collection, and data
   analyses. We also thank all the infants and their parents for their
   valuable time and interest in this research.
CR Bates D, 2005, FITTING LINEAR MIXED, V5, P27, DOI DOI 10.1159/000323281
   Beattie RL, 2013, J LEARN DISABIL-US, V46, P200, DOI 10.1177/0022219412449421
   Best C. T., 1994, DEV SPEECH PERCEPTIO, V167, P233
   Best CT, 2009, PSYCHOL SCI, V20, P539, DOI 10.1111/j.1467-9280.2009.02327.x
   Boada R, 2006, J EXP CHILD PSYCHOL, V95, P153, DOI 10.1016/j.jecp.2006.04.003
   Bogliotti C, 2008, J EXP CHILD PSYCHOL, V101, P137, DOI 10.1016/j.jecp.2008.03.006
   Brysbaert Marc, 2018, J Cogn, V1, P9, DOI 10.5334/joc.10
   Burnham D., 1998, ADV INFANCY RES, V12, P170
   Chandrasekaran B, 2009, NEURON, V64, P311, DOI 10.1016/j.neuron.2009.10.006
   Chen A, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00156
   Collet G, 2012, RES DEV DISABIL, V33, P1805, DOI 10.1016/j.ridd.2012.05.003
   Curtin S, 2011, J PHONETICS, V39, P492, DOI 10.1016/j.wocn.2010.12.002
   Di Liberto GM, 2018, NEUROIMAGE, V175, P70, DOI 10.1016/j.neuroimage.2018.03.072
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Fenson Larry, 1994, Monographs of the Society for Research in Child Development, V59, P1
   Fisher SE, 2002, NAT REV NEUROSCI, V3, P767, DOI 10.1038/nrn936
   Gallagher A, 2000, J CHILD PSYCHOL PSYC, V41, P203, DOI 10.1111/1469-7610.00601
   Gogate LJ, 2010, J EXP CHILD PSYCHOL, V105, P178, DOI 10.1016/j.jecp.2009.10.007
   Goswami U, 2002, P NATL ACAD SCI USA, V99, P10911, DOI 10.1073/pnas.122368599
   Goswami U, 2018, CURR DIR PSYCHOL SCI, V27, P56, DOI 10.1177/0963721417727520
   Goswami U, 2015, NAT REV NEUROSCI, V16, P43, DOI 10.1038/nrn3836
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Goswami U, 2011, DEVELOPMENTAL SCI, V14, P34, DOI 10.1111/j.1467-7687.2010.00955.x
   Goswami U, 2011, J COGNITIVE NEUROSCI, V23, P325, DOI 10.1162/jocn.2010.21453
   Guttorm TK, 2005, CORTEX, V41, P291, DOI 10.1016/S0010-9452(08)70267-3
   Guttorm TK, 2010, J LEARN DISABIL-US, V43, P391, DOI 10.1177/0022219409345005
   Hamalainen JA, 2008, CLIN NEUROPHYSIOL, V119, P100, DOI 10.1016/j.clinph.2007.09.064
   Hamalainen JA, 2013, J LEARN DISABIL-US, V46, P413, DOI 10.1177/0022219411436213
   Hulme C, 2007, J EXP CHILD PSYCHOL, V96, P150, DOI 10.1016/j.jecp.2006.09.002
   JUSCZYK PW, 1993, CHILD DEV, V64, P675, DOI 10.2307/1131210
   JUSCZYK PW, 1993, J MEM LANG, V32, P402, DOI 10.1006/jmla.1993.1022
   JUSCZYK PW, 1994, J MEM LANG, V33, P630, DOI 10.1006/jmla.1994.1030
   Kalashnikova M, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12487
   Kalashnikova M, 2016, DYSLEXIA, V22, P101, DOI 10.1002/dys.1525
   Koster C, 2005, J SPEECH LANG HEAR R, V48, P426, DOI 10.1044/1092-4388(2005/029)
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kuznetsova A, 2015, PROC CVPR IEEE, P28, DOI 10.1109/CVPR.2015.7298597
   Law JM, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12453
   Lehongre K, 2011, NEURON, V72, P1080, DOI 10.1016/j.neuron.2011.11.002
   Leppanen PHT, 2010, CORTEX, V46, P1362, DOI 10.1016/j.cortex.2010.06.003
   Litt RA, 2014, J MEM LANG, V71, P71, DOI 10.1016/j.jml.2013.10.005
   Litt RA, 2013, J EXP CHILD PSYCHOL, V115, P137, DOI 10.1016/j.jecp.2012.11.012
   Lyytinen H, 2004, ANN DYSLEXIA, V54, P184, DOI 10.1007/s11881-004-0010-3
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Moll K, 2013, SCI STUD READ, V17, P385, DOI 10.1080/10888438.2012.736439
   Mulak KE, 2013, CHILD DEV, V84, P2064, DOI 10.1111/cdev.12087
   Nazzi T, 2003, DEVELOPMENTAL SCI, V6, P136, DOI 10.1111/1467-7687.00263
   Noordenbos MW, 2012, RES DEV DISABIL, V33, P1469, DOI 10.1016/j.ridd.2012.03.021
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   Patrick P., 1999, URBAN JAMAICAN CREOL
   Pennington BF, 2001, CHILD DEV, V72, P816, DOI 10.1111/1467-8624.00317
   Plakas A, 2013, CORTEX, V49, P1034, DOI 10.1016/j.cortex.2012.02.013
   Poelmans H, 2011, RES DEV DISABIL, V32, P2810, DOI 10.1016/j.ridd.2011.05.025
   Power AJ, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00777
   Power AJ, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00216
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   Ramus F, 2013, BRAIN, V136, P630, DOI 10.1093/brain/aws356
   Richardson U, 2003, DEV NEUROPSYCHOL, V23, P385, DOI 10.1207/S15326942DN2303_5
   SCARBOROUGH HS, 1990, CHILD DEV, V61, P1728, DOI 10.2307/1130834
   Schmale R, 2012, DEVELOPMENTAL SCI, V15, P732, DOI 10.1111/j.1467-7687.2012.01175.x
   Schmale R, 2010, INFANCY, V15, P650, DOI 10.1111/j.1532-7078.2010.00032.x
   Schmale R, 2009, DEVELOPMENTAL SCI, V12, P583, DOI 10.1111/j.1467-7687.2009.00809.x
   Seidl A, 2012, FRONT PSYCHOL, V3, DOI [10.3389/fpsyg.2012.00448, 10.3389/fpsyg.2012.00479]
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Snowling M., 2000, DYSLEXIA
   Snowling MJ, 2016, PSYCHOL BULL, V142, P498, DOI 10.1037/bul0000037
   Snowling MJ, 2003, CHILD DEV, V74, P358, DOI 10.1111/1467-8624.7402003
   Soleimani F., 2014, BAYLEY SCALES INFANT
   Stefanics G, 2011, NEUROIMAGE, V57, P723, DOI 10.1016/j.neuroimage.2011.04.005
   Suranyi Z, 2009, READ WRIT, V22, P41, DOI 10.1007/s11145-007-9102-x
   Swan D, 1997, BRAIN LANG, V56, P334, DOI 10.1006/brln.1997.1855
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Swingley D, 2005, DEVELOPMENTAL SCI, V8, P432, DOI 10.1111/j.1467-7687.2005.00432.x
   Swingley D, 2007, COGNITIVE PSYCHOL, V54, P99, DOI 10.1016/j.cogpsych.2006.05.001
   Torppa M, 2010, J LEARN DISABIL-US, V43, P308, DOI 10.1177/0022219410369096
   Tsuji S, 2014, DEV PSYCHOBIOL, V56, P179, DOI 10.1002/dev.21179
   van Alphen P, 2004, DYSLEXIA, V10, P265, DOI 10.1002/dys.272
   van Bergen E, 2011, DYSLEXIA, V17, P2, DOI 10.1002/dys.423
   van der Leij A, 2013, DYSLEXIA, V19, P191, DOI 10.1002/dys.1463
   van Heugten M, 2015, LANG LEARN DEV, V11, P41, DOI 10.1080/15475441.2013.879636
   van Viersen S, 2017, J SPEECH LANG HEAR R, V60, P937, DOI 10.1044/2016_JSLHR-L-16-0031
   van Zuijen TL, 2013, DEVELOPMENTAL SCI, V16, P554, DOI 10.1111/desc.12049
   Wassink AB, 2006, J ACOUST SOC AM, V119, P2334, DOI 10.1121/1.2168414
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   Werker JF, 2005, DEV PSYCHOBIOL, V46, P233, DOI 10.1002/dev.20060
   WETHERFORD MJ, 1973, CHILD DEV, V44, P416, DOI 10.2307/1127994
   Yoshida KA, 2009, DEVELOPMENTAL SCI, V12, P412, DOI 10.1111/j.1467-7687.2008.00789.x
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
   Zoccolotti P, 2010, CORTEX, V46, P1211, DOI 10.1016/j.cortex.2010.09.003
NR 90
TC 3
Z9 3
U1 1
U2 6
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0163-6383
EI 1879-0453
J9 INFANT BEHAV DEV
JI Infant Behav. Dev.
PD NOV
PY 2019
VL 57
AR 101327
DI 10.1016/j.infbeh.2019.101327
PG 12
WC Psychology, Developmental
SC Psychology
GA JS5VS
UT WOS:000500374700009
PM 31207365
DA 2021-02-24
ER

PT J
AU Herrmann, B
   Buckland, C
   Johnsrude, IS
AF Herrmann, Bjorn
   Buckland, Chad
   Johnsrude, Ingrid S.
TI Neural signatures of temporal regularity processing in sounds differ
   between younger and older adults
SO NEUROBIOLOGY OF AGING
LA English
DT Article
DE Aging; Neural synchronization; Sustained activity; Amplitude modulation;
   Neural adaptation
ID AGE-RELATED-CHANGES; HEARING-LOSS; AUDITORY-CORTEX; AGING AFFECTS;
   CORTICAL OSCILLATIONS; LOUDNESS RECRUITMENT; SPEECH-PERCEPTION;
   EVOKED-RESPONSES; NOISE; ENTRAINMENT
AB Sensitivity to temporal regularity (e.g., recurring modulation in amplitude) is crucial for speech perception. Degradation of the auditory periphery due to aging and hearing loss may lead to increased responsiveness to sound in the auditory cortex, with potential consequences for the processing of temporal regularities. We used electroencephalography recorded from younger (19-33 years) and older adults (55-76 years) to investigate whether younger and older listeners differ in responsiveness to sound and sensitivity to amplitude modulation in sounds. Aging was associated with reduced adaptation in the auditory cortex, suggesting an age-related increase in responsiveness. Furthermore, neural synchronization in the auditory cortex to 4-Hz amplitude-modulated narrow-band noises was enhanced in similar to 30% of older individuals. Despite enhanced responsiveness and synchronization in the auditory cortex, sustained neural activity (likely involving auditory and higher-order regions) in response to amplitude modulation was absent in older people. Aging appears to be associated with over-responsiveness to amplitude modulation in the auditory cortex, but with diminished regularity sensitivity in higher-order areas. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Herrmann, Bjorn; Buckland, Chad; Johnsrude, Ingrid S.] Univ Western Ontario, Dept Psychol, London, ON, Canada.
   [Herrmann, Bjorn; Buckland, Chad; Johnsrude, Ingrid S.] Univ Western Ontario, Brain & Mind Inst, London, ON N6A 5B7, Canada.
   [Johnsrude, Ingrid S.] Univ Western Ontario, Sch Commun Sci & Disorders, London, ON, Canada.
RP Herrmann, B (corresponding author), Univ Western Ontario, Brain & Mind Inst, London, ON N6A 5B7, Canada.
EM herrmann.b@gmail.com
RI Herrmann, Bjorn/H-8000-2019; Johnsrude, Ingrid S/G-4694-2011
OI Herrmann, Bjorn/0000-0001-6362-3043; Johnsrude, Ingrid
   S/0000-0002-7810-1333
FU Canadian Institutes of Health ResearchCanadian Institutes of Health
   Research (CIHR) [MOP133450]; BrainsCAN postdoctoral fellowship (Canada
   First Research Excellence Fund [CFREF])
FX This research was supported by the Canadian Institutes of Health
   Research (MOP133450 to ISJ). BH was supported by a BrainsCAN
   postdoctoral fellowship (Canada First Research Excellence Fund [CFREF]).
CR Al-Salim SC, 2010, EAR HEARING, V31, P567, DOI 10.1097/AUD.0b013e3181da4d15
   Alain C, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00008
   Anderer P, 1996, ELECTROEN CLIN NEURO, V99, P458, DOI 10.1016/S0013-4694(96)96518-9
   Attwell D, 2001, J CEREBR BLOOD F MET, V21, P1133, DOI 10.1097/00004647-200110000-00001
   Auerbach BD, 2014, FRONT NEUROL, V5, DOI 10.3389/fneur.2014.00206
   Augustin M, 2013, FRONT COMPUT NEUROSC, V7, DOI 10.3389/fncom.2013.00009
   Bao JX, 2010, HEARING RES, V264, P93, DOI 10.1016/j.heares.2009.10.009
   Barascud N, 2016, P NATL ACAD SCI USA, V113, pE616, DOI 10.1073/pnas.1508523113
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bharadwaj HM, 2015, J NEUROSCI, V35, P2161, DOI 10.1523/JNEUROSCI.3915-14.2015
   Bharadwaj HM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00026
   Bidelman GM, 2017, J NEUROSCI, V37, P3610, DOI 10.1523/JNEUROSCI.3700-16.2017
   Bidelman GM, 2014, NEUROBIOL AGING, V35, P2526, DOI 10.1016/j.neurobiolaging.2014.05.006
   BSA, 2011, PUR TON AIR COND BON
   Cai SQ, 2009, JARO-J ASSOC RES OTO, V10, P5, DOI 10.1007/s10162-008-0142-y
   CANNON WB, 1949, SUPERSENSITIVITY DEN
   Caspary DM, 2008, J EXP BIOL, V211, P1781, DOI 10.1242/jeb.013581
   Chambers AR, 2016, NEURON, V89, P867, DOI 10.1016/j.neuron.2015.12.041
   de Villers-Sidani E, 2010, P NATL ACAD SCI USA, V107, P13900, DOI 10.1073/pnas.1007885107
   Epstein M.J., 2006, OXFORD HDB AUDITORY, P45
   Ernst SMA, 2012, J ACOUST SOC AM, V131, P4722, DOI 10.1121/1.3699233
   Feder K, 2015, HEALTH REP, V26, P18
   Gatehouse S, 2004, INT J AUDIOL, V43, P85, DOI 10.1080/14992020400050014
   Genovese CR, 2002, NEUROIMAGE, V15, P870, DOI 10.1006/nimg.2001.1037
   GERKEN GM, 1979, J ACOUST SOC AM, V66, P721, DOI 10.1121/1.383222
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Goman AM, 2016, AM J PUBLIC HEALTH, V106, P1820, DOI 10.2105/AJPH.2016.303299
   Goossens T, 2019, NEUROBIOL AGING, V74, P202, DOI 10.1016/j.neurobiolaging.2018.10.008
   Goossens T, 2018, HEARING RES, V370, P189, DOI 10.1016/j.heares.2018.07.012
   Goossens T, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00133
   Gutschalk A, 2002, NEUROIMAGE, V15, P207, DOI 10.1006/nimg.2001.0949
   HARI R, 1982, ELECTROEN CLIN NEURO, V54, P561, DOI 10.1016/0013-4694(82)90041-4
   HARRIS JD, 1953, PSYCHOL BULL, V50, P190, DOI 10.1037/h0061494
   Hebert S, 2013, J NEUROSCI, V33, P2356, DOI 10.1523/JNEUROSCI.3461-12.2013
   Heinz MG, 2005, JARO-J ASSOC RES OTO, V6, P91, DOI 10.1007/s10162-004-5043-0
   HELFER KS, 1990, J SPEECH HEAR RES, V33, P149, DOI 10.1044/jshr.3301.149
   Henry MJ, 2014, TIMING TIME PERCEPTI, V2, P62, DOI DOI 10.1163/22134468-00002011
   Henry MJ, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15801
   Herrmann B, 2018, J EXP PSYCHOL HUMAN, V44, P89, DOI 10.1037/xhp0000432
   Herrmann B, 2017, EUR J NEUROSCI, V45, P299, DOI 10.1111/ejn.13463
   Herrmann B, 2016, NEUROBIOL AGING, V45, P10, DOI 10.1016/j.neurobiolaging.2016.05.006
   Herrmann B, 2016, NEUROIMAGE, V124, P487, DOI 10.1016/j.neuroimage.2015.09.019
   Herrmann B, 2013, J NEUROSCI, V33, P15799, DOI 10.1523/JNEUROSCI.1434-13.2013
   Herrmann B, 2013, HEARING RES, V304, P128, DOI 10.1016/j.heares.2013.07.005
   Herrmann B, 2018, J NEUROSCI, V38, P5466, DOI 10.1523/JNEUROSCI.0346-18.2018
   Herrmann B, 2018, J NEUROSCI, V38, P1989, DOI 10.1523/JNEUROSCI.1489-17.2018
   Hughes LF, 2010, HEARING RES, V264, P79, DOI 10.1016/j.heares.2009.09.005
   Ingham NJ, 2005, J NEUROSCI, V25, P6187, DOI 10.1523/JNEUROSCI.0146-05.2005
   Keceli S, 2012, BMC NEUROSCI, V13, DOI 10.1186/1471-2202-13-7
   Keitel A, 2017, NEUROIMAGE, V147, P32, DOI 10.1016/j.neuroimage.2016.11.062
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Knipper L, 2013, PROG NEUROBIOL, V111, P17, DOI 10.1016/j.pneurobio.2013.08.002
   Kujawa SG, 2009, J NEUROSCI, V29, P14077, DOI 10.1523/JNEUROSCI.2845-09.2009
   Lachaux JP, 1999, HUM BRAIN MAPP, V8, P194, DOI 10.1002/(SICI)1097-0193(1999)8:4<194::AID-HBM4>3.0.CO;2-C
   Ladenbauer J, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002478
   LAFFONT F, 1989, Neurophysiologie Clinique, V19, P15, DOI 10.1016/S0987-7053(89)80081-4
   Lai J, 2017, NEUROBIOL AGING, V58, P191, DOI 10.1016/j.neurobiolaging.2017.06.013
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735
   Lakatos P, 2013, NEURON, V77, P750, DOI 10.1016/j.neuron.2012.11.034
   Larrabee M.G., 1949, Q REV BIOL, V24, P374
   Liberman MC, 2017, HEARING RES, V349, P138, DOI 10.1016/j.heares.2017.01.003
   Liberman MC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162726
   Llano DA, 2012, J NEUROSCI, V32, P16141, DOI 10.1523/JNEUROSCI.2499-12.2012
   Makeig S, 1996, ADV NEURAL INFORM PR
   Malmierca MS, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00111
   Marozeau J, 2007, J ACOUST SOC AM, V122, pEL81, DOI 10.1121/1.2761924
   Millman RE, 2017, J NEUROSCI, V37, P7727, DOI 10.1523/JNEUROSCI.2722-16.2017
   Mishra J, 2014, NEURON, V84, P1091, DOI 10.1016/j.neuron.2014.10.034
   Mohrle D, 2016, NEUROBIOL AGING, V44, P173, DOI 10.1016/j.neurobiolaging.2016.05.001
   Moore B. C. J., 2007, COCHLEAR HEARING LOS
   Moore BCJ, 1996, J ACOUST SOC AM, V100, P481, DOI 10.1121/1.415861
   MOORE BCJ, 1993, J ACOUST SOC AM, V94, P2050, DOI 10.1121/1.407478
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Nelken I, 2014, BIOL CYBERN, V108, P655, DOI 10.1007/s00422-014-0585-7
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Overton JA, 2016, J NEUROPHYSIOL, V115, P2911, DOI 10.1152/jn.01098.2015
   Oxenham AJ, 2003, EAR HEARING, V24, P352, DOI 10.1097/01.AUD.0000090470.73934.78
   Pantev C, 1996, EAR HEARING, V17, P255, DOI 10.1097/00003446-199606000-00008
   PANTEV C, 1994, ELECTROEN CLIN NEURO, V90, P82, DOI 10.1016/0013-4694(94)90115-5
   Parmentier FBR, 2010, EXP PSYCHOL, V57, P68, DOI 10.1027/1618-3169/a000009
   Parthasarathy A, 2019, NEUROBIOL AGING, V73, P30, DOI 10.1016/j.neurobiolaging.2018.08.023
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Pichora-Fuller MK, 2003, INT J AUDIOL, V42, pS26
   Picton TW, 2003, INT J AUDIOL, V42, P177, DOI 10.3109/14992020309101316
   Plack C.J., 2014, THE SENSE OF HEARING
   POPELAR J, 1987, HEARING RES, V26, P239, DOI 10.1016/0378-5955(87)90060-8
   Presacco A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0213899
   Presacco A, 2016, J NEUROPHYSIOL, V116, P2356, DOI 10.1152/jn.00373.2016
   Presacco A, 2016, J NEUROPHYSIOL, V116, P2346, DOI 10.1152/jn.00372.2016
   Purcell DW, 2004, J ACOUST SOC AM, V116, P3581, DOI 10.1121/1.1798354
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Rosenthal R, 2003, PSYCHOL METHODS, V8, P492, DOI 10.1037/1082-989X.8.4.492
   ROTH WT, 1976, ELECTROEN CLIN NEURO, V40, P623, DOI 10.1016/0013-4694(76)90137-1
   Salvi R, 2017, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00621
   SAMS M, 1993, J COGNITIVE NEUROSCI, V5, P363, DOI 10.1162/jocn.1993.5.3.363
   Schlittenlacher J, 2016, J ACOUST SOC AM, V140, P3487, DOI 10.1121/1.4966117
   Soros P, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-34
   Sohoglu E, 2016, ELIFE, V5, DOI 10.7554/eLife.19113
   Southwell R, 2017, PHILOS T R SOC B, V372, DOI 10.1098/rstb.2016.0105
   Stefanics G, 2010, J NEUROSCI, V30, P13578, DOI 10.1523/JNEUROSCI.0703-10.2010
   Steinberg JC, 1937, J ACOUST SOC AM, V9, P11, DOI 10.1121/1.1915905
   SYKA J, 1994, HEARING RES, V78, P158, DOI 10.1016/0378-5955(94)90021-3
   Takesian AE, 2012, J NEUROPHYSIOL, V107, P937, DOI 10.1152/jn.00515.2011
   Takesian AE, 2009, FUTUR NEUROL, V4, P331, DOI 10.2217/FNL.09.5
   Teki S, 2016, CEREB CORTEX, V26, P3669, DOI 10.1093/cercor/bhw173
   ten Oever S, 2017, J NEUROSCI, V37, P4903, DOI 10.1523/JNEUROSCI.3658-16.2017
   Tiitinen H, 2012, BMC NEUROSCI, V13, DOI 10.1186/1471-2202-13-157
   Tremblay KL, 2003, CLIN NEUROPHYSIOL, V114, P1332, DOI 10.1016/S1388-2457(03)00114-7
   Tyler RS, 2014, AM J AUDIOL, V23, P402, DOI 10.1044/2014_AJA-14-0010
   VandenLangenberg GM, 1998, AM J EPIDEMIOL, V148, P204, DOI 10.1093/oxfordjournals.aje.a009625
   Viana LM, 2015, HEARING RES, V327, P78, DOI 10.1016/j.heares.2015.04.014
   VILLCHUR E, 1974, J ACOUST SOC AM, V56, P1601, DOI 10.1121/1.1903484
   Walker JJ, 2013, AM FAM PHYSICIAN, V87, P41
   Zacharias N, 2012, PSYCHOPHYSIOLOGY, V49, P909, DOI 10.1111/j.1469-8986.2012.01370.x
   Zeng FG, 2013, HEARING RES, V295, P172, DOI 10.1016/j.heares.2012.05.009
NR 117
TC 5
Z9 5
U1 1
U2 2
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0197-4580
EI 1558-1497
J9 NEUROBIOL AGING
JI Neurobiol. Aging
PD NOV
PY 2019
VL 83
BP 73
EP 85
DI 10.1016/j.neurobiolaging.2019.08.028
PG 13
WC Geriatrics & Gerontology; Neurosciences
SC Geriatrics & Gerontology; Neurosciences & Neurology
GA JQ6VE
UT WOS:000499079800008
PM 31585369
DA 2021-02-24
ER

PT J
AU Ohashi, H
   Ito, T
AF Ohashi, Hiroki
   Ito, Takayuki
TI Recalibration of auditory perception of speech due to orofacial
   somatosensory inputs during speech motor adaptation
SO JOURNAL OF NEUROPHYSIOLOGY
LA English
DT Article
DE auditory-somatosensory integration; speech motor learning; speech
   perception; speech production; speech sound acquisition
ID SENSORIMOTOR ADAPTATION; FREQUENCY; CORTEX; FEEDBACK; REPRESENTATIONS;
   COMPENSATION; INTEGRATION; PLASTICITY; CONTRIBUTE
AB Speech motor control and learning rely on both somatosensory and auditory inputs. Somatosensory inputs associated with speech production can also affect the process of auditory perception of speech, and the somatosensory-auditory interaction may play a fundamental role in auditory perception of speech. In this report, we show that the somatosensory system contributes to perceptual recalibration. separate from its role in motor function. Subjects participated in speech motor adaptation to altered auditory feedback. Auditory perception of speech was assessed in phonemic identification tests before and after speech adaptation. To investigate a role of the somatosensory system in motor adaptation and subsequent perceptual change, we applied orofacial skin stretch in either a backward or forward direction during the auditory feedback alteration as a somatosensory modulation. We found that the somatosensory modulation did not affect the amount of adaptation at the end of training, although it changed the rate of adaptation. However, the perception following speech adaptation was altered depending on the direction of the somatosensory modulation. Somatosensory inflow rather than motor outflow thus drives changes to auditory perception of speech following speech adaptation. suggesting that somatosensory inputs play an important role in tuning of perceptual system.
   NEW & NOTEWORTHY This article reports that the somatosensory system works not equally with the motor system, but predominantly in the calibration of auditory perception of speech by speech production.
C1 [Ohashi, Hiroki] McGill Univ, Dept Psychol, Montreal, PQ, Canada.
   [Ohashi, Hiroki; Ito, Takayuki] Haskins Labs Inc, New Haven, CT USA.
   [Ito, Takayuki] Univ Grenoble Alpes, Ctr Natl Rech Sci, Grenoble Inst Technol, GIPSA Lab, St Martin Dheres, France.
RP Ito, T (corresponding author), Univ Grenoble Alpes, Grenoble INP, GIPSA Lab, CRNS, 11 Rue Math,Grenoble Campus BP46, F-38402 St Martin Dheres, France.
EM takayuki.ito@gipsa-lab.grenoble-inp.fr
OI Ito, Takayuki/0000-0002-3265-360X
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R21-DC-013915]; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R21DC013915, R56DC016274] Funding Source: NIH RePORTER
FX This study was supported by National Institute on Deafness and Other
   Communication Disorders Grant R21-DC-013915.
CR ANDERSEN N, 1974, GEOPHYSICS, V39, P69, DOI 10.1190/1.1440413
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Cai SQ, 2011, J NEUROSCI, V31, P16483, DOI 10.1523/JNEUROSCI.3653-11.2011
   Convento S, 2018, CURR BIOL, V28, P746, DOI 10.1016/j.cub.2018.01.021
   Crommett LE, 2017, J NEUROPHYSIOL, V117, P1352, DOI 10.1152/jn.00783.2016
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Foxe JJ, 2002, J NEUROPHYSIOL, V88, P540, DOI 10.1152/jn.2002.88.1.540
   Fu KMG, 2003, J NEUROSCI, V23, P7510
   Gick B, 2009, NATURE, V462, P502, DOI 10.1038/nature08572
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213
   Ito T, 2007, NEUROREPORT, V18, P907, DOI 10.1097/WNR.0b013e32810f2dfb
   Ito T, 2010, J NEUROPHYSIOL, V104, P1230, DOI 10.1152/jn.00199.2010
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   Katseff S, 2012, LANG SPEECH, V55, P295, DOI 10.1177/0023830911417802
   KLATT DH, 1980, J ACOUST SOC AM, V67, P971, DOI 10.1121/1.383940
   Lametti DR, 2014, J NEUROSCI, V34, P10339, DOI 10.1523/JNEUROSCI.0108-14.2014
   Lametti DR, 2012, J NEUROSCI, V32, P9351, DOI 10.1523/JNEUROSCI.0404-12.2012
   Lane H, 2007, J SPEECH LANG HEAR R, V50, P2, DOI 10.1044/1092-4388(2007/001)
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Maniwa K, 2009, J ACOUST SOC AM, V125, P3962, DOI 10.1121/1.2990715
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009
   Nasir SM, 2009, P NATL ACAD SCI USA, V106, P20470, DOI 10.1073/pnas.0907032106
   Niziolek CA, 2013, J NEUROSCI, V33, P16110, DOI 10.1523/JNEUROSCI.2137-13.2013
   Nordmark PF, 2012, J COGNITIVE NEUROSCI, V24, P2120, DOI 10.1162/jocn_a_00261
   Perez-Bellido A, 2018, CEREB CORTEX, V28, P3908, DOI 10.1093/cercor/bhx255
   Perkell JS, 2012, J NEUROLINGUIST, V25, P382, DOI 10.1016/j.jneuroling.2010.02.011
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Purcell DW, 2006, J ACOUST SOC AM, V120, P966, DOI 10.1121/1.2217714
   Ro T, 2013, CEREB CORTEX, V23, P1724, DOI 10.1093/cercor/bhs166
   Schuerman WL, 2017, J ACOUST SOC AM, V141, P2693, DOI 10.1121/1.4979791
   Schurmann M, 2006, NEUROIMAGE, V30, P1325, DOI 10.1016/j.neuroimage.2005.11.020
   Shen Y, 2012, J ACOUST SOC AM, V132, P957, DOI 10.1121/1.4733540
   Shiller DM, 2009, J ACOUST SOC AM, V125, P1103, DOI 10.1121/1.3058638
   Tremblay S, 2003, NATURE, V423, P866, DOI 10.1038/nature01710
   Villacorta VM, 2007, J ACOUST SOC AM, V122, P2306, DOI 10.1121/1.2773966
   Yau JM, 2009, CURR BIOL, V19, P561, DOI 10.1016/j.cub.2009.02.013
NR 40
TC 0
Z9 0
U1 0
U2 0
PU AMER PHYSIOLOGICAL SOC
PI BETHESDA
PA 9650 ROCKVILLE PIKE, BETHESDA, MD 20814 USA
SN 0022-3077
EI 1522-1598
J9 J NEUROPHYSIOL
JI J. Neurophysiol.
PD NOV
PY 2019
VL 122
IS 5
BP 2076
EP 2084
DI 10.1152/jn.00028.2019
PG 9
WC Neurosciences; Physiology
SC Neurosciences & Neurology; Physiology
GA JP3LY
UT WOS:000498170200022
PM 31509469
OA Green Published
DA 2021-02-24
ER

PT J
AU Jallu, AS
   Hussain, T
   Ul Hamid, W
   Pampori, RA
AF Jallu, Aleena Shafi
   Hussain, Tahir
   Ul Hamid, Waqar
   Pampori, Rafiq Ahmad
TI Prelingual Deafness: An Overview of Treatment Outcome
SO INDIAN JOURNAL OF OTOLARYNGOLOGY AND HEAD & NECK SURGERY
LA English
DT Article
DE SNHL; OAE; ASSR; BERA; HRCT; MRI; CAP; REELS; CLA
ID HEARING IMPAIRMENT; CHILDREN; LANGUAGE; PREVALENCE; AGE
AB Prelingually deaf child is one who is either born deaf or who lost his or her hearing early in childhood, before acquiring language. A child with subnormal hearing acuity suffers from consequences of hearing loss compounded by impaired speech development. The period from birth to 3 years of life is critical for the development of speech and language, therefore, there is need for early identification and assessment of hearing loss and early rehabilitation in children. 40 patients were evaluated clinically, radiologically and audiologically to assess the degree of patient's handicap. The modes of treatment included use of hearing aid in patients with moderate, moderately-severe, severe or profound HL and cochlear implantation in patients with profound HL. Each patient was followed for 18 months and results were calculated in terms of speech perception (CAP) and language (REELS) development of the patient. Out of the 40 patients, 60% (n = 24) were females and 40% (16) were males. 50% (n = 20) patients had PSNHL, 32.5% (n = 13) had SSNHL, 10% (n = 4) had MSSNHL and 7.5% (n = 3) had MSNHL. 30% (n = 12) of patients had significant radiological findings. Among the hearing aid users patients with PSNHL got no benefit at the end of 18 months whereas the patients with cochlear implantation had significant improvement. Also the patients managed at a younger age (<3 years) had a significantly better outcome then those managed later. Early identification of hearing loss, that is followed by immediate and appropriate intervention results in better language, speech, and social-emotional development when compared to children treated at a later age.
C1 [Jallu, Aleena Shafi; Hussain, Tahir; Ul Hamid, Waqar; Pampori, Rafiq Ahmad] Govt Med Coll Srinagar, Dept Otolaryngol Head & Neck Surg, Srinagar, Jammu & Kashmir, India.
   [Ul Hamid, Waqar] House 166a,Shah Anwar Colony Hyderpora, Srinagar 190018, Jammu & Kashmir, India.
RP Ul Hamid, W (corresponding author), Govt Med Coll Srinagar, Dept Otolaryngol Head & Neck Surg, Srinagar, Jammu & Kashmir, India.; Ul Hamid, W (corresponding author), House 166a,Shah Anwar Colony Hyderpora, Srinagar 190018, Jammu & Kashmir, India.
EM aleenajallu@gmail.com; thz47@yahoo.com; waqar_ul_hamid@yahoo.com;
   drrafiqahmad@rediffmail.com
CR Archbold S, 1995, Ann Otol Rhinol Laryngol Suppl, V166, P312
   Archbold S, 1998, BRIT J AUDIOL, V32, P7, DOI 10.3109/03005364000000045
   BALKANY T, 1993, NEW ENGL J MED, V328, P281, DOI 10.1056/NEJM199301283280412
   Bradham T, 2008, INT J PEDIATR OTORHI, V72, P1023, DOI 10.1016/j.ijporl.2008.03.005
   Brookhouser PE, 1996, PEDIATR CLIN N AM, V43, P1195, DOI 10.1016/S0031-3955(05)70514-9
   Browning GG, 2008, SCOTT BROWNS OTORHIN, P3629
   DAVIS JM, 1986, J SPEECH HEAR DISORD, V51, P53, DOI 10.1044/jshd.5101.53
   Drake R, 2000, J PAEDIATR CHILD H, V36, P240, DOI 10.1046/j.1440-1754.2000.00497.x
   FISHER NA, 1994, OTOLARYNG CLIN N AM, V27, P511
   Fortnum HM, 2001, BRIT MED J, V323, P536, DOI 10.1136/bmj.323.7312.536
   JACKLER RK, 1987, LARYNGOSCOPE, V97, P2
   KLUWIN T, 1993, DEAF STUDENTS LOCAL
   Mafong DD, 2002, LARYNGOSCOPE, V112, P1, DOI 10.1097/00005537-200201000-00001
   Mehl AL, 1998, PEDIATRICS, V101, DOI 10.1542/peds.101.1.e4
   Mhatre AN, 1996, OTOLARYNG CLIN N AM, V29, P421
   Moeller MP, 2007, EAR HEARING, V28, P740, DOI 10.1097/AUD.0b013e318157f07f
   Novaes Beatriz C Albuquerque Caiuby, 2012, J Soc Bras Fonoaudiol, V24, P335
   Pickett BP, 1999, OTOLARYNG CLIN N AM, V32, P1019, DOI 10.1016/S0030-6665(05)70192-4
   QUITTNER AL, 1994, PSYCHOL SCI, V5, P347, DOI 10.1111/j.1467-9280.1994.tb00284.x
   Rice ML, 1999, J SPEECH LANG HEAR R, V42, P943, DOI 10.1044/jslhr.4204.943
   Robbins AM, 2004, ARCH OTOLARYNGOL, V130, P570
   Svirsky MA, 2000, PSYCHOL SCI, V11, P153, DOI 10.1111/1467-9280.00231
   Tomblin JB, 1999, J SPEECH LANG HEAR R, V42, P497, DOI 10.1044/jslhr.4202.497
   Tye-Murray N, 1994, COCHLEAR IMPLANTS CH
   Vaccari C, 1997, J CHILD PSYCHOL PSYC, V38, P793, DOI 10.1111/j.1469-7610.1997.tb01597.x
   Wake M, 2005, ARCH DIS CHILD, V90, P238, DOI 10.1136/adc.2003.039354
   Walsh RM, 1999, ORL J OTO-RHINO-LARY, V61, P41, DOI 10.1159/000027637
NR 27
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER INDIA
PI NEW DELHI
PA 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001,
   INDIA
SN 2231-3796
EI 0973-7707
J9 INDIAN J OTOLARYNGOL
JI Indian J. Otolaryngol. Head Neck Surg.
PD NOV
PY 2019
VL 71
IS SUPPL 2
SU 2
SI SI
BP 1078
EP 1089
DI 10.1007/s12070-017-1181-7
PG 12
WC Surgery
SC Surgery
GA JL2ZH
UT WOS:000495399900012
PM 31750130
OA Green Published
DA 2021-02-24
ER

PT J
AU Arya, R
   Nandurkar, A
   Shah, M
   Verma, N
AF Arya, Richa
   Nandurkar, Aparna
   Shah, Meera
   Verma, Neha
TI Speech Perception Skills of Hindi Speaking Children with Pre-lingual
   Hearing Loss Using Hearing Aids and Cochlear Implants
SO INDIAN JOURNAL OF OTOLARYNGOLOGY AND HEAD & NECK SURGERY
LA English
DT Article
DE Hindi; Pattern perception; Sentence identification; Minimal pair
   identification; Bisyllabic word identification; Monosyllabic word
   identification
ID BENEFITS
AB Very few published studies have reported auditory speech perception in Hindi children with pre-lingual hearing loss. The study is aimed at comparing the speech perception skills of Hindi speaking children with pre-lingual severe to profound hearing loss using hearing aids and cochlear implants. Forty-three 6 to 8-year old children were included as participants, of which 22 were bilateral behind-the-ear hearing aid (HA) users and 21 were unilateral cochlear implant (CI) users. Speech perception was assessed through a forced-choice, picture-pointing task using recorded stimuli presented at 70 dB HL in the sound field. The skills assessed include: (a) pattern perception, (b) bisyllabic word identification, (c) monosyllabic word identification, (d) sentence identification and (e) minimal pair identification. Children using CI consistently performed significantly better than those with HA on all tasks. For the skills assessed, best performance was seen in pattern perception and poorest performance was seen in monosyllabic word identification. One participant from the CI group obtained ceiling scores for pattern perception and bisyllabic word identification. There was no statistically significant difference in the performance of 6 to 7 and 7 to 8-year-old children for any of the tasks. Children fitted with CI have better access to the cues important for perception of speech and hence perform consistently better than those using hearing aids. Recorded speech perception test can be used with children using cochlear implants and hearing aids.
C1 [Arya, Richa] Guru Gobind Singh Med Coll & Hosp, ENT Dept, Faridkot 151203, Punjab, India.
   [Nandurkar, Aparna; Shah, Meera; Verma, Neha] Ali Yavar Jung Natl Inst Speech & Hearing Disabil, Mumbai, Maharashtra, India.
RP Arya, R (corresponding author), Guru Gobind Singh Med Coll & Hosp, ENT Dept, Faridkot 151203, Punjab, India.
EM richaarya.512@gmail.com
CR American National Standards Institute, 1991, S311991 ANSI
   Anderson I, 2004, INT J PEDIATR OTORHI, V68, P425, DOI 10.1016/j.ijporl.2003.11.013
   [Anonymous], 1978, ASHA, V20, P297
   Bittencourt AG, 2012, BRAZ J OTORHINOLAR, V78, P124, DOI 10.1590/S1808-86942012000200019
   BOOTHROYD A, 1984, J SPEECH HEAR RES, V27, P134, DOI 10.1044/jshr.2701.134
   Boothroyd A, 1978, AUDITORY MANAGEMENT, P118
   Carhart R, 1965, INTRO AUDIOLOGY, P113
   Census of India, 2001, ABSTR SPEAK STRENGTH
   DOWELL RC, 1991, AM J OTOL, V12, P137
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   GEERS AE, 1991, AM J OTOL, V12, P116
   KIRK KI, 1995, EAR HEARING, V16, P470, DOI 10.1097/00003446-199510000-00004
   KISHONRABIN L, 2000, COCHLEAR IMPLANTS, P212
   KREUL EJ, 1969, J SPEECH HEAR RES, V12, P281, DOI 10.1044/jshr.1202.281
   Madell J, 2011, AUDIOLOGY
   MIYAMOTO RT, 1989, ANN OTO RHINOL LARYN, V98, P2, DOI 10.1177/00034894890980S801
   Moog J.S., 1990, EARLY SPEECH PERCEPT
   Most T, 2007, J DEAF STUD DEAF EDU, V12, P350, DOI 10.1093/deafed/enm012
   Oyer JJ, 1970, HEARING ASSESSMENT
   Parkinson JA, 1996, J AM ACAD AUDIOL, V7, P305
   Ranjan P, 2006, THESIS
   ROSS M, 1970, J SPEECH HEAR RES, V13, P44, DOI 10.1044/jshr.1301.44
   Snik AFM, 1997, AM J OTOL, V18, pS129
   SOMERS MN, 1991, AM J OTOL, V12, P174
   Svirsky MA, 1999, ANN OTO RHINOL LARYN, V108, P104
   Svirsky MA, 1991, ANN OTO RHINOL LARYN, V177, P104
   Zheng Y, 2009, EAR HEARING, V30, P600, DOI 10.1097/AUD.0b013e3181b4aba8
NR 27
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER INDIA
PI NEW DELHI
PA 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001,
   INDIA
SN 2231-3796
EI 0973-7707
J9 INDIAN J OTOLARYNGOL
JI Indian J. Otolaryngol. Head Neck Surg.
PD NOV
PY 2019
VL 71
IS SUPPL 2
SU 2
SI SI
BP 1241
EP 1247
DI 10.1007/s12070-018-1291-x
PG 7
WC Surgery
SC Surgery
GA JL2ZH
UT WOS:000495399900041
PM 31750159
OA Green Published
DA 2021-02-24
ER

PT J
AU Chiodo, L
   Mottron, L
   Majerus, S
AF Chiodo, Liliane
   Mottron, Laurent
   Majerus, Steve
TI Preservation of categorical perception for speech in autism with and
   without speech onset delay
SO AUTISM RESEARCH
LA English
DT Article
DE autism spectrum; categorical perception; speech onset delay; cognition;
   Bayesian models
ID SPECTRUM DISORDER; LANGUAGE; CHILDREN; DISCRIMINATION; SOUNDS;
   INDIVIDUALS; DEFICITS; ADULTS; LEVEL
AB Recent accounts of autistic perception, including Bayesian accounts, hypothesize a reduced influence of prior knowledge on perception across different domains in the autism spectrum (AS). The purpose of this study was to investigate the influence of prior linguistic knowledge, in the form of phonemic categorical knowledge, on speech perception in adults with AS condition. As phonemic categorical knowledge is shaped by language experience and abilities, we furthermore distinguished AS participants with (AS-SOD) or without a history of speech onset delay (AS-noSOD); the control group comprises typical individuals matched for age, nonverbal intelligence, and reading abilities. We also controlled for the influence of auditory-verbal short-term retention capacities by administering word list and nonword list repetition tasks. We did not observe any reduced influence of prior phonemic knowledge on the perception of speech stimuli nor did we observed any increased perceptual abilities for atypical variants of speech stimuli or nonspeech auditory stimuli, either between the two autistic groups or relative to the control group. Short-term memory abilities appeared to be superior in the AS-noSOD group relative to the AS-SOD and control groups, but this strength could be accounted for by their higher vocabulary knowledge. The preservation of categorical perception in verbal autistic adults observed in this study challenges models claiming a reduced influence of prior knowledge on perception across domains in the AS. Autism Res 2019. (c) 2019 International Society for Autism Research, Wiley Periodicals, Inc. Lay Summary A reduced influence of prior knowledge has been considered to characterize perceptual abilities in people with autism. In this article, we examine this claim by assessing nonlinguistic and linguistic auditory perception abilities in adults with autism, and by further distinguishing between autism with or without a history of delayed language development. We did not observe any reduced influence of prior language knowledge on the perception of speech stimuli nor did we observe any increased perceptual abilities for atypical variants of speech stimuli or nonspeech auditory stimuli, and this relative to a control group matched on age, nonverbal intellectual efficiency, and reading abilities. Our results challenge models claiming a reduced influence of prior knowledge on perception across domains in the AS.
C1 [Chiodo, Liliane; Majerus, Steve] Univ Liege, Psychol & Neurosci Cognit Res Unit, Pl Orateurs 1,Bat B33, B-4000 Liege, Belgium.
   [Mottron, Laurent] Univ Montreal, Dept Psychiat, Montreal, PQ, Canada.
   [Mottron, Laurent] CIUSSS NIM, Hop Riviere Des Prairies, Montreal, PQ, Canada.
   [Majerus, Steve] FNRS, FRS, Brussels, Belgium.
RP Chiodo, L (corresponding author), Univ Liege, Psychol & Neurosci Cognit Res Unit, Pl Orateurs 1,Bat B33, B-4000 Liege, Belgium.
EM lchiodo@uliege.be
CR Barbeau EB, 2013, J ABNORM PSYCHOL, V122, P295, DOI 10.1037/a0029984
   Boddaert N, 2004, AM J PSYCHIAT, V161, P2117, DOI 10.1176/appi.ajp.161.11.2117
   Bonnel A, 2003, J COGNITIVE NEUROSCI, V15, P226, DOI 10.1162/089892903321208169
   Bonnel A., 2006, J ACOUST SOC AM, V120, P3127, DOI [10.1121/1.4787689, DOI 10.1121/1.4787689]
   Bonnel A, 2010, NEUROPSYCHOLOGIA, V48, P2465, DOI 10.1016/j.neuropsychologia.2010.04.020
   Brock J, 2012, TRENDS COGN SCI, V16, P573, DOI 10.1016/j.tics.2012.10.005
   Caron MJ, 2006, BRAIN, V129, P1789, DOI 10.1093/brain/awl072
   Constantino JN, 2007, J AUTISM DEV DISORD, V37, P1256, DOI 10.1007/s10803-006-0269-9
   Courchesne V, 2019, J AUTISM DEV DISORD, V49, P845, DOI 10.1007/s10803-018-3786-4
   Dawson M, 2007, PSYCHOL SCI, V18, P657, DOI 10.1111/j.1467-9280.2007.01954.x
   Van de Cruys S, 2014, PSYCHOL REV, V121, P649, DOI 10.1037/a0037665
   DePape AMR, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0044084
   Dienes Z, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00781
   Dunn L. M., 1993, ECHELLE VOCABULAIRE
   Flagg EJ, 2005, NEUROSCI LETT, V386, P82, DOI 10.1016/j.neulet.2005.05.037
   Gervais H, 2004, NAT NEUROSCI, V7, P801, DOI 10.1038/nn1291
   Gliga T, 2015, CURR BIOL, V25, P1727, DOI 10.1016/j.cub.2015.05.011
   Happe F, 2006, J AUTISM DEV DISORD, V36, P5, DOI 10.1007/s10803-005-0039-0
   Heaton P, 2008, NEUROPSYCHOLOGIA, V46, P2095, DOI 10.1016/j.neuropsychologia.2008.02.006
   Jones CRG, 2009, NEUROPSYCHOLOGIA, V47, P2850, DOI 10.1016/j.neuropsychologia.2009.06.015
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kujala T, 2013, NEUROSCI BIOBEHAV R, V37, P697, DOI 10.1016/j.neubiorev.2013.01.006
   Lawson RP, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00302
   Lee M. D., 2014, BAYESIAN COGNITIVE M
   Lefavrais P., 1965, REV PSYCHOL APPL
   Lepisto T, 2009, BIOL PSYCHOL, V82, P301, DOI 10.1016/j.biopsycho.2009.09.004
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   LORD C, 1989, J AUTISM DEV DISORD, V19, P185, DOI 10.1007/BF02211841
   LORD C, 1994, J AUTISM DEV DISORD, V24, P659, DOI 10.1007/BF02172145
   MacMillan NA, 1991, DETECTION THEORY USE
   Majerus S., 2011, TRAITE NEUROPSYCHOLO
   Majerus S, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00357
   McBrideChang C, 1996, CHILD DEV, V67, P1836, DOI 10.2307/1131735
   Medina V, 2010, J PHONETICS, V38, P493, DOI 10.1016/j.wocn.2010.06.002
   Meilleur AAS, 2015, J AUTISM DEV DISORD, V45, P1354, DOI 10.1007/s10803-014-2296-2
   MORAIS J, 1986, COGNITION, V24, P45, DOI 10.1016/0010-0277(86)90004-1
   Mottron L, 2006, J AUTISM DEV DISORD, V36, P27, DOI 10.1007/s10803-005-0040-7
   Mottron L., 2018, ENCY AUTISM SPECTRUM, P2168
   Nader AM, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144645
   O'Connor K, 2012, NEUROSCI BIOBEHAV R, V36, P836, DOI 10.1016/j.neubiorev.2011.11.008
   Pell PJ, 2016, MOL AUTISM, V7, DOI 10.1186/s13229-016-0085-9
   Pellicano E, 2012, TRENDS COGN SCI, V16, P574, DOI 10.1016/j.tics.2012.10.004
   Raven J., 1998, RAVEN MANUAL
   Redcay E, 2008, BIOL PSYCHIAT, V64, P589, DOI 10.1016/j.biopsych.2008.05.020
   Samson F, 2006, J AUTISM DEV DISORD, V36, P65, DOI 10.1007/s10803-005-0043-4
   Samson F, 2015, J PSYCHIATR RES, V68, P285, DOI 10.1016/j.jpsychires.2015.05.011
   Sapey-Triomphe LA, 2018, J AUTISM DEV DISORD, V48, P3075, DOI 10.1007/s10803-018-3597-7
   Serniclaes W, 2001, J SPEECH LANG HEAR R, V44, P384, DOI 10.1044/1092-4388(2001/032)
   Serniclaes W, 2006, WRIT LANG LIT, V9, P135, DOI 10.1075/wll.9.1.09ser
   Soulieres I, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025372
   Soulieres I, 2009, HUM BRAIN MAPP, V30, P4082, DOI 10.1002/hbm.20831
   Stewart ME, 2018, J AUTISM DEV DISORD, V48, P72, DOI 10.1007/s10803-017-3284-0
   Teder-Salejarvi WA, 2005, COGNITIVE BRAIN RES, V23, P221, DOI 10.1016/j.cogbrainres.2004.10.021
   Tryfon A, 2018, BEHAV BRAIN RES, V338, P118, DOI 10.1016/j.bbr.2017.10.025
   Tubach J. L., 1990, CORPUS TRANSCRIPTION
   Van der Hallen R, 2017, AUTISM RES, V10, P1291, DOI 10.1002/aur.1767
   Wagenmakers EJ, 2018, PSYCHON B REV, V25, P58, DOI [10.3758/s13423-017-1323-7, 10.3758/s13423-017-1343-3]
   Wechsler D, 2011, WAIS 4 NOUVELLE VERS
   White S, 2006, COGN NEUROPSYCHOL, V23, P748, DOI 10.1080/02643290500438607
   Williams D, 2013, J AUTISM DEV DISORD, V43, P404, DOI 10.1007/s10803-012-1579-8
   Wodka EL, 2013, PEDIATRICS, V131, pE1128, DOI 10.1542/peds.2012-2221
   You RS, 2017, RES DEV DISABIL, V61, P158, DOI 10.1016/j.ridd.2016.12.009
   Zilbovicius M, 2000, AM J PSYCHIAT, V157, P1988, DOI 10.1176/appi.ajp.157.12.1988
NR 63
TC 2
Z9 2
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1939-3792
EI 1939-3806
J9 AUTISM RES
JI Autism Res.
PD NOV
PY 2019
VL 12
IS 11
BP 1609
EP 1622
DI 10.1002/aur.2134
PG 14
WC Behavioral Sciences; Psychology, Developmental
SC Behavioral Sciences; Psychology
GA JL2CG
UT WOS:000495338400004
PM 31157957
OA Green Published
DA 2021-02-24
ER

PT J
AU Fleming, D
   Belleville, S
   Peretz, I
   West, G
   Zendel, BR
AF Fleming, David
   Belleville, Sylvie
   Peretz, Isabelle
   West, Greg
   Zendel, Benjamin Rich
TI The effects of short-term musical training on the neural processing of
   speech-in-noise in older adults
SO BRAIN AND COGNITION
LA English
DT Article
DE Aging; Music-training; fMRI; Speech perception
ID CORTICAL MECHANISMS; AUDITORY-FEEDBACK; ACTIVATES MOTOR; PERCEPTION;
   NETWORKS; CORTEX; PLASTICITY; REPRESENTATIONS; DISSOCIATION; MUSICIANS
AB Experienced musicians outperform non-musicians in understanding speech-in-noise (SPIN). The benefits of lifelong musicianship endure into older age, where musicians experience smaller declines in their ability to understand speech in noisy environments. However, it is presently unknown whether commencing musical training in old age can also counteract age-related decline in speech perception, and whether such training induces changes in neural processing of speech. Here, we recruited older adult non-musicians and assigned them to receive a short course of piano or videogame training, or no training. Participants completed two sessions of functional Magnetic Resonance Imaging where they performed a SPIN task prior to and following training. While we found no direct benefit of musical training upon SPIN perception, an exploratory Region of Interest analysis revealed increased cortical responses to speech in left Middle Frontal and Supramarginal Gyri which correlated with changes in SPIN task performance in the group which received music training. These results suggest that short-term musical training in older adults may enhance neural encoding of speech, with the potential to reduce age-related decline in speech perception.
C1 [Fleming, David; Zendel, Benjamin Rich] Mem Univ Newfoundland, Fac Med, 230 Elizabeth Ave, St John, NF A1B 3V6, Canada.
   [Peretz, Isabelle; Zendel, Benjamin Rich] Int Lab Brain Mus & Sound Res, Montreal, PQ H3C 3J7, Canada.
   [Belleville, Sylvie; Zendel, Benjamin Rich] Inst Univ Geriatrie Montreal CRIUGM, Ctr Rech, Montreal, PQ H3W 1W4, Canada.
   [Belleville, Sylvie; Peretz, Isabelle; West, Greg] Univ Montreal, Dept Psychol, Montreal, PQ H3C 3J7, Canada.
   [Zendel, Benjamin Rich] Mem Univ Newfoundland, Aging Res Ctr Newfoundland & Labrador, Corner Brook, NF A2H 5G4, Canada.
   [Fleming, David] Univ Amsterdam, PPLE Coll, NL-1018 WB Amsterdam, Netherlands.
RP Zendel, BR (corresponding author), Mem Univ Newfoundland, Fac Med, 230 Elizabeth Ave, St John, NF A1B 3V6, Canada.; Fleming, D (corresponding author), Univ Amsterdam, PPLE Coll, NL-1018 WB Amsterdam, Netherlands.
EM dfleming@mun.ca; bzendel@mun.ca
FU Canada Research Chairs ProgramCanada Research Chairs; GRAMMY Foundation;
   Fondation Caroline Durant; Fonds de recherche du Quebec-Sante (FRQS);
   Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR;
   Natural Sciences and Engineering Research Council of Canada
   Collaborative Research and Training Experience Program in Auditory
   Cognitive Neuroscience (NSERC-CREATE-ACN)Natural Sciences and
   Engineering Research Council of Canada (NSERC)
FX Support for this research came from the Canada Research Chairs Program
   (IP & BRZ), the GRAMMY Foundation (BRZ), Fondation Caroline Durant (SB),
   Fonds de recherche du Quebec-Sante (FRQS) (BRZ), Natural Sciences and
   Engineering Research Council of Canada (SB), and Natural Sciences and
   Engineering Research Council of Canada Collaborative Research and
   Training Experience Program in Auditory Cognitive Neuroscience
   (NSERC-CREATE-ACN) (BRZ). The authors declare no competing financial
   interests.
CR Anderson S, 2013, P NATL ACAD SCI USA, V110, P4357, DOI 10.1073/pnas.1213555110
   Bangert M, 2006, NEUROIMAGE, V30, P917, DOI 10.1016/j.neuroimage.2005.10.044
   Belleville S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102710
   Belleville S, 2012, CURR GERIATR REP, V1, P104, DOI 10.1007/s13670-012-0014-5
   Belleville S, 2011, BRAIN, V134, P1623, DOI 10.1093/brain/awr037
   Bengtsson SL, 2009, CORTEX, V45, P62, DOI 10.1016/j.cortex.2008.07.002
   Bengtsson SL, 2006, NEUROIMAGE, V30, P272, DOI 10.1016/j.neuroimage.2005.09.019
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Catani M, 2005, ANN NEUROL, V57, P8, DOI 10.1002/ana.20319
   Coffey EBJ, 2017, HEARING RES, V352, P49, DOI 10.1016/j.heares.2017.02.006
   Constantinidis C, 2016, NAT REV NEUROSCI, V17, P438, DOI 10.1038/nrn.2016.43
   Diarra M, 2019, EXP BRAIN RES, V237, P723, DOI 10.1007/s00221-018-5453-6
   Dosenbach NUF, 2008, TRENDS COGN SCI, V12, P99, DOI 10.1016/j.tics.2008.01.001
   Dosenbach NUF, 2006, NEURON, V50, P799, DOI 10.1016/j.neuron.2006.04.031
   Du Y, 2017, P NATL ACAD SCI USA, V114, P13579, DOI 10.1073/pnas.1712223114
   Du Y, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12241
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   Ester EF, 2015, NEURON, V87, P893, DOI 10.1016/j.neuron.2015.07.013
   Fujioka T, 2006, BRAIN, V129, P2593, DOI 10.1093/brain/awl247
   Giordano BL, 2014, CORTEX, V58, P170, DOI 10.1016/j.cortex.2014.06.005
   Golfinopoulos E, 2011, NEUROIMAGE, V55, P1324, DOI 10.1016/j.neuroimage.2010.12.065
   Guillaume B, 2014, NEUROIMAGE, V94, P287, DOI 10.1016/j.neuroimage.2014.03.029
   Hall DA, 2000, MAGN RESON MED, V43, P601, DOI 10.1002/(SICI)1522-2594(200004)43:4<601::AID-MRM16>3.3.CO;2-I
   Hartwigsen G, 2010, P NATL ACAD SCI USA, V107, P16494, DOI 10.1073/pnas.1008121107
   Herholz SC, 2016, CEREB CORTEX, V26, P3125, DOI 10.1093/cercor/bhv138
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Kim C, 2015, NEUROSCI LETT, V595, P25, DOI 10.1016/j.neulet.2015.03.044
   Kleber B, 2017, NEUROIMAGE, V147, P97, DOI 10.1016/j.neuroimage.2016.11.059
   Kotz SA, 2010, TRENDS COGN SCI, V14, P392, DOI 10.1016/j.tics.2010.06.005
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Lappe C, 2008, J NEUROSCI, V28, P9632, DOI 10.1523/JNEUROSCI.2254-08.2008
   Lappe C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021493
   Ley A, 2012, J NEUROSCI, V32, P13273, DOI 10.1523/JNEUROSCI.0584-12.2012
   Lopez-Barroso D, 2015, NEUROIMAGE, V110, P182, DOI 10.1016/j.neuroimage.2014.12.085
   Moreno S, 2006, PSYCHOPHYSIOLOGY, V43, P287, DOI 10.1111/j.1469-8986.2006.00401.x
   Moreno S, 2015, CHILD DEV, V86, P394, DOI 10.1111/cdev.12297
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Pallesen KJ, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011120
   Parbery-Clark A, 2011, NEUROPSYCHOLOGIA, V49, P3338, DOI 10.1016/j.neuropsychologia.2011.08.007
   Parbery-Clark A, 2012, NEUROBIOL AGING, V33, DOI 10.1016/j.neurobiolaging.2011.12.015
   Parbery-Clark A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018082
   Patel AD, 2012, ANN NY ACAD SCI, V1252, P124, DOI 10.1111/j.1749-6632.2011.06426.x
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Schulze K, 2011, HUM BRAIN MAPP, V32, P771, DOI 10.1002/hbm.21060
   Slater J, 2015, BEHAV BRAIN RES, V291, P244, DOI 10.1016/j.bbr.2015.05.026
   Tierney A, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00855
   Tierney AT, 2015, P NATL ACAD SCI USA, V112, P10062, DOI 10.1073/pnas.1505114112
   Tourville JA, 2008, NEUROIMAGE, V39, P1429, DOI 10.1016/j.neuroimage.2007.09.054
   Vaillancourt H, 2005, INT J AUDIOL, V44, P358, DOI 10.1080/14992020500060875
   Vigneau M, 2006, NEUROIMAGE, V30, P1414, DOI 10.1016/j.neuroimage.2005.11.002
   Vigneau M, 2011, NEUROIMAGE, V54, P577, DOI 10.1016/j.neuroimage.2010.07.036
   Vogan VM, 2016, DEV COGN NEUROS-NETH, V17, P19, DOI 10.1016/j.dcn.2015.10.008
   West GL, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187779
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
   Zatorre RJ, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00544
   Zendel BR, 2019, NEUROBIOL AGING, V81, P102, DOI 10.1016/j.neurobiolaging.2019.05.015
   Zendel BR, 2016, NEUROBIOL AGING, V47, P10, DOI 10.1016/j.neurobiolaging.2016.06.023
   Zendel BR, 2015, J COGNITIVE NEUROSCI, V27, P1044, DOI 10.1162/jocn_a_00758
   Zendel BR, 2014, NEUROBIOL AGING, V35, P55, DOI 10.1016/j.neurobiolaging.2013.06.022
   Zendel BR, 2012, PSYCHOL AGING, V27, P410, DOI 10.1037/a0024816
NR 62
TC 2
Z9 2
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0278-2626
EI 1090-2147
J9 BRAIN COGNITION
JI Brain Cogn.
PD NOV
PY 2019
VL 136
AR 103592
DI 10.1016/j.bandc.2019.103592
PG 12
WC Neurosciences; Psychology, Experimental
SC Neurosciences & Neurology; Psychology
GA JJ3FV
UT WOS:000494047800004
PM 31404817
DA 2021-02-24
ER

PT J
AU Wegner-Clemens, K
   Rennig, J
   Magnotti, JF
   Beauchamp, MS
AF Wegner-Clemens, Kira
   Rennig, Johannes
   Magnotti, John F.
   Beauchamp, Michael S.
TI Using principal component analysis to characterize eye movement fixation
   patterns during face viewing
SO JOURNAL OF VISION
LA English
DT Article
DE face perception; principal component analysis; eye movements; speech
   perception; gender classification
ID AUDIOVISUAL SPEECH-PERCEPTION; INDIVIDUAL-DIFFERENCES; GAZE BEHAVIOR;
   RECOGNITION; METAANALYSIS; ALLOCATION; ATTENTION; LOOKING; TASKS
AB Human faces contain dozens of visual features, but viewers preferentially fixate just two of them: the eyes and the mouth. Face-viewing behavior is usually studied by manually drawing regions of interest (ROIs) on the eyes, mouth, and other facial features. ROI analyses are problematic as they require arbitrary experimenter decisions about the location and number of ROIs, and they discard data because all fixations within each ROI are treated identically and fixations outside of any ROI are ignored. We introduce a data-driven method that uses principal component analysis (PCA) to characterize human face-viewing behavior. All fixations are entered into a PCA, and the resulting eigenimages provide a quantitative measure of variability in face-viewing behavior. In fixation data from 41 participants viewing four face exemplars under three stimulus and task conditions, the first principal component (PC1) separated the eye and mouth regions of the face. PC1 scores varied widely across participants, revealing large individual differences in preference for eye or mouth fixation, and PC1 scores varied by condition, revealing the importance of behavioral task in determining fixation location. Linear mixed effects modeling of the PC1 scores demonstrated that task condition accounted for 41% of the variance, individual differences accounted for 28% of the variance, and stimulus exemplar for less than 1% of the variance. Fixation eigenimages provide a useful tool for investigating the relative importance of the different factors that drive human face-viewing behavior.
C1 [Wegner-Clemens, Kira; Rennig, Johannes; Magnotti, John F.; Beauchamp, Michael S.] Baylor Coll Med, Dept Neurosurg & Core Adv MRI, Houston, TX 77030 USA.
RP Beauchamp, MS (corresponding author), Baylor Coll Med, Dept Neurosurg & Core Adv MRI, Houston, TX 77030 USA.
EM michael.beauchamp@bcm.edu
RI Beauchamp, Michael/AAK-9813-2020
OI Beauchamp, Michael/0000-0002-7599-9934; Wegner-Clemens,
   Kira/0000-0001-9521-755X
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01NS065395];
   Deutsche ForschungsgemeinschaftGerman Research Foundation (DFG) [RE
   3693/1-1]; NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKEUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute of Neurological Disorders &
   Stroke (NINDS) [R01NS065395, R01NS065395, R01NS065395] Funding Source:
   NIH RePORTER
FX This work was supported by the National Institutes of Health
   (R01NS065395 to MSB) and the Deutsche Forschungsgemeinschaft (RE
   3693/1-1 to JR).
CR Armann R, 2009, ATTEN PERCEPT PSYCHO, V71, P1107, DOI 10.3758/APP.71.5.1107
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Buchan JN, 2007, SOC NEUROSCI-UK, V2, P1, DOI 10.1080/17470910601043644
   Buchan JN, 2008, BRAIN RES, V1242, P162, DOI 10.1016/j.brainres.2008.06.083
   Butler S, 2005, NEUROPSYCHOLOGIA, V43, P52, DOI 10.1016/j.neuropsychologia.2004.06.005
   Chita-Tegmark M, 2016, REV J AUTISM DEV DIS, V3, P209, DOI 10.1007/s40489-016-0077-x
   Chua HF, 2005, P NATL ACAD SCI USA, V102, P12629, DOI 10.1073/pnas.0506162102
   de Haas B, 2019, P NATL ACAD SCI USA, V116, P11687, DOI 10.1073/pnas.1820553116
   Drusch G., 2014, INT C APPL HUM FACT
   Everdell IT, 2007, PERCEPTION, V36, P1535, DOI 10.1068/p5852
   Fookes C., 2010, 10 INT C INF SCI SIG, P320
   Franchak JM, 2016, INFANCY, V21, P262, DOI 10.1111/infa.12119
   Frazier TW, 2017, J AM ACAD CHILD PSY, V56, P546, DOI 10.1016/j.jaac.2017.05.005
   Gobel F., 2018, SPAT BIG DAT MACH LE, P25
   Gurler D, 2015, ATTEN PERCEPT PSYCHO, V77, P1333, DOI 10.3758/s13414-014-0821-1
   Hsiao JHW, 2008, PSYCHOL SCI, V19, P998, DOI 10.1111/j.1467-9280.2008.02191.x
   Irwin J, 2018, MULTISENS RES, V31, P39, DOI 10.1163/22134808-00002580
   Kanan C, 2015, VISION RES, V108, P67, DOI 10.1016/j.visres.2015.01.013
   Klin A, 2002, ARCH GEN PSYCHIAT, V59, P809, DOI 10.1001/archpsyc.59.9.809
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   LATIMER CR, 1988, BEHAV RES METH INS C, V20, P437, DOI 10.3758/BF03202698
   Masciocchi CM, 2009, J VISION, V9, DOI 10.1167/9.11.25
   Mehoudar E, 2014, J VISION, V14, DOI 10.1167/14.7.6
   MERTENS I, 1993, NEUROPSYCHOLOGIA, V31, P989, DOI 10.1016/0028-3932(93)90154-R
   Mlouka M. B., 2009, IFMBE P, V26
   Naqshbandi K, 2016, IEEE SYS MAN CYBERN, P1239, DOI 10.1109/SMC.2016.7844411
   Nattyen HT, 2009, OPHTHALMOLOGY, V116, P355, DOI 10.1016/j.ophtha.2008.10.007
   Papagiannopoulou EA, 2014, SOC NEUROSCI-UK, V9, P610, DOI 10.1080/17470919.2014.934966
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Parkhurst DJ, 2004, EUR J NEUROSCI, V19, P783, DOI 10.1111/j.0953-816X.2003.03183.x
   Pearson A. M., 2003, ABSTRACTS PSYCHONOMI, V8, P84
   Perez-Moreno E, 2016, PSICOLOGICA, V37, P127
   Perlman SB, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0005952
   Peterson MF, 2016, J VISION, V16, DOI 10.1167/16.7.12
   Peterson MF, 2013, PSYCHOL SCI, V24, P1216, DOI 10.1177/0956797612471684
   Peterson MF, 2012, P NATL ACAD SCI USA, V109, pE3314, DOI 10.1073/pnas.1214269109
   Rayner K, 2007, VISION RES, V47, P2714, DOI 10.1016/j.visres.2007.05.007
   Rennig J., PSYCHONOMIC B REV
   Rennig J, 2018, NEUROIMAGE, V183, P25, DOI 10.1016/j.neuroimage.2018.08.008
   Royer J, 2018, COGNITION, V181, P12, DOI 10.1016/j.cognition.2018.08.004
   Saether L, 2009, VISION RES, V49, P2870, DOI 10.1016/j.visres.2009.09.001
   Santella A., 2004, EYE TRACK RES APPL E
   Schurgin MW, 2014, J VISION, V14, DOI 10.1167/14.13.14
   Schyns PG, 2002, PSYCHOL SCI, V13, P402, DOI 10.1111/1467-9280.00472
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Smith M. L., 2010, J VISION, V4, P909, DOI [10.1167/4.8.909, DOI 10.1167/4.8.909]
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Vatikiotis-Bateson E, 1998, PERCEPT PSYCHOPHYS, V60, P926, DOI 10.3758/BF03211929
   Vo MLH, 2012, J VISION, V12, DOI 10.1167/12.13.3
   Yarbus A. L., 1967, EYE MOVEMENTS VISION
NR 50
TC 2
Z9 2
U1 1
U2 3
PU ASSOC RESEARCH VISION OPHTHALMOLOGY INC
PI ROCKVILLE
PA 12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA
SN 1534-7362
J9 J VISION
JI J. Vision
PD NOV
PY 2019
VL 19
IS 13
AR 2
DI 10.1167/19.13.2
PG 15
WC Ophthalmology
SC Ophthalmology
GA JK8OF
UT WOS:000495098800002
PM 31689715
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

EF