---
output:
  bookdown::word_document2:
    toc: true
  bookdown::pdf_document2:
    keep_tex: true
  bookdown::html_document2: default
---

# 第九章 机器学习建模基础

&emsp;&emsp;机器学习（Machine Learning）是人工智能（Artificial Intelligence, AI）的一个重要分支，其主要目标是使计算机通过学习经验数据自动改进和发展。机器学习使计算机从数据中学习模式和规律，从而做出预测或决策，而无需显式地编程。机器学习主要分为2种主要类型，监督学习（Supervised Learning）和无监督学习（Unsupervised Learning）。

&emsp;&emsp;根据学习方式和目标任务的不同，它们各自解决不同类型的问题。监督学习是一种通过已标记的训练数据来训练模型，从而预测或估计新数据的输出。在监督学习中，训练数据包含了输入特征和相应的标签。模型学习从输入到标签之间的映射关系，以便对未知数据进行预测。监督学习的任务可以分为分类（Classification）任务即预测离散类别标签，如垃圾邮件检测、疾病诊断。典型算法包括支持向量机（SVM）、逻辑回归、决策树、随机森林等。回归（Regression）任务则是预测连续数值，如房价预测、销售预测。典型算法包括，线性回归、多项式回归、支持向量回归（SVR）等。

&emsp;&emsp;无监督学习使用未标记的数据，没有预先定义的输出，其目标是发现数据中的隐藏结构或模式。这种学习方法通常用于探索数据的内在关系，发现数据的聚类、降维或异常检测等特征。常见的无监督学习包括聚类分析（Clustering）和降维（Dimensionality Reduction）。聚类分析将数据集划分为不同的组（簇），使每个组内的数据点相似度最大化，而组间的相似度最小化。典型算法包括K均值聚类、层次聚类等。降维减少数据的特征维度，保留最重要的信息，以便更好地可视化和理解数据，同时降低计算复杂度。典型算法包括主成分分析（PCA）、因子分析、独立成分分析（ICA）等。

## 监督学习

&emsp;&emsp;下面将用一个二语语音研究的例子讲解如何使用支持向量机（SVM）和随机森林来对中国英语学习者的焦点语音实现进行自动评估。

&emsp;&emsp;传统的统计建模（如广义线性模型）在大多数先前研究中用于调查信息焦点的语音实现，这些研究检查整个数据集，并通过离散指标检测焦点类型的效果。通常，基于不同的声学测量构建几个模型，以测试不同焦点和语言组的效果，但很难得到全面的图景。而人类听众则逐一听取话语并据此作出判断。这个过程可以通过机器学习算法来模拟，这些算法输入一组特征并基于这些特征输出分类结果。

&emsp;&emsp;支持向量机（SVM）和随机森林模型被用于基于不同的声学测量集分类鼻音元音和口音元音。我们理解，计算感知与人类感知并不完全相同，但计算感知在语音研究中的优势在于它纯粹基于声学特征，因此可以剔除句法或词汇的影响。此外，与识别元音或辅音不同，仅仅给听众一些目标词并测试他们如何识别不同的焦点是困难的。机器学习算法可以在没有上下文的情况下识别不同的焦点，从而从感知的角度接近这个问题。
焦点是话语中提供信息的部分，与句子的背景信息形成对比。为了进一步解释焦点在话语中的作用，以下是具体例子：

(a) **广泛焦点（Broad Focus, BF）**
   - A: 你明天有什么计划？
   - B: 我想去纽约。

在这个例子中，B的整个回答都在提供新信息，因此整个句子是焦点。

(b) **狭窄焦点（Narrow Focus, NF）**
   - A: Karel想带你去哪里？
   - B: 他想带我去纽约。

在这个例子中，焦点是“纽约”，因为这是B回答A的问题“哪里”的特定信息。

(c) **纠正焦点（Corrective Focus, CF）**
   - A: 你妈妈想送你去芝加哥吗？
   - B: 不，她想送我去纽约。

&emsp;&emsp;在这个例子中，焦点也是“纽约”，但这次是为了纠正A的问题中的错误信息“芝加哥”。通过这些例子可以看出，焦点的范围和功能可以根据对话中的具体信息需求和信息状态有所不同。

&emsp;&emsp;不同语言的母语者使用不同语音手段（如音高重音分布、短语边界、音高范围和持续时间）来表达不同焦点条件下的意义。本研究采用两种机器学习模型，支持向量机（SVM）和随机森林（Random Forest），来探讨基于语音特征的不同类型信息焦点。我们还比较了美国英语母语者（AE）与低熟练度的中国英语学习者（CE1）和高熟练度的中国英语学习者（CE2）在分类准确性和不同语音特征排名方面的差异。此外，我们使用AE的语音数据训练了两个模型，并用CE1和CE2的数据进行测试，以模拟AE听者如何感知非母语者在不同信息焦点下的语音产出。

&emsp;&emsp;我们在本研究中使用了两种机器学习分类器，随机森林（RandomForests）和支持向量机（SVM）。随机森林是一种机器学习模型，由一组在数据的随机子集上训练和测试的决策树组成。在本研究中，我们在所有随机森林模型中使用了500棵树，如[9]所述。随机森林分类器检查每棵决策树的输出，并产生分类准确率。此外，随机森林分类器为每个模型提供了直接的特征重要性度量。本研究中使用了R语言中的randomForest包[10]来构建分类器。

&emsp;&emsp;然而，随机森林为了其可解释性在分类中牺牲了一些准确性。为了弥补这一点，我们使用了SVM，这在机器学习领域中整体表现良好。SVM通过找到最佳分离数据中不同类别的线来工作。当数据不是线性可分时，可以使用核函数来处理非线性关系。在本研究中，使用了“径向基函数”（radial）核。然而，使用核函数时我们无法得到特征权重。因此，我们主要依赖随机森林来指示每个语音特征的重要性。

&emsp;&emsp;此外，由于数据集相对较小（从机器学习的角度来看），我们使用了“10折交叉验证”，即对数据运行10次分析，每次使用不同的9/10数据作为“训练”集，剩余的1/10作为“测试”集。本研究中使用了R语言中的e1071包[11]来构建SVM分类器。

### 数据导入

```{r message=FALSE}
library(tidyverse)
setwd("~/Nutstore Files/310_Tutorial/LanguageDS-e")

```

```{r message=FALSE}




# install.packages('caTools')
library(caTools)
set.seed(123)

# 美国英语本族语者数据
datasetAE <- read_csv("data/ch9/datasetAE.CSV")
# 中国英语学习者大一
datasetCE1 = read_csv("data/ch9/datasetCE1.CSV")
# 中国英语学习者大三
datasetCE2 = read_csv("data/ch9/datasetCE2.CSV")


datasetAE$focus_type = as.factor(datasetAE$focus_type)
datasetCE1$focus_type = as.factor(datasetCE1$focus_type)
datasetCE2$focus_type = as.factor(datasetCE2$focus_type)



# install.packages('e1071')
library(e1071)

```


### 构建SVM模型

```{r }


svm_AE = svm(formula = focus_type ~ .,
                 data = datasetAE,
                 #regression or classification
                 type = 'C-classification', 
                 kernel = 'radial',
                 cost = "2",
                 cross = 10)

# 交叉验证（Cross Validation）是一种用于评估和验证机器学习模型性能的方法，通过将数据集划分为多个子集，交替进行训练和测试，以确保模型在不同的数据集上都具有良好的泛化能力。最常见的方法是K折交叉验证（K-Fold Cross Validation），将数据集划分为K个大小大致相同的子集，每个子集轮流作为验证集，其余子集作为训练集，重复K次后将结果平均，作为模型的最终性能评估指标。交叉验证可以充分利用数据，提高模型评估的可靠性，防止过拟合问题，是机器学习和数据挖掘中广泛应用的技术。

summary(svm_AE)

svm_AE$tot.accuracy

svm_AE$accuracies

```

### random forest

```{r }

library(randomForest)

set.seed(123)

#AE
RF_AE = randomForest(focus_type ~ .,
                    ntree = 500, 
                    data = datasetAE, 
                    importance = TRUE)
importance(RF_AE)   

varImpPlot(RF_AE, n.var= 5, main ="AE")

# 在构建随机森林的过程中，每棵决策树都是通过对原始训练数据进行有放回抽样（Bootstrap Sampling）得到的子样本训练出来的。剩下样本则没有被该树用于训练，这些样本就是袋外样本。利用那些没有进行训练的数据来进行预测。

RF_AE$confusion

```

&emsp;&emsp;为了模拟美国英语（AE）听众如何感知由中国英语（CE1和CE2）学习者发出的焦点目标词语，使用所有AE数据特征训练了一个支持向量机（SVM）模型，并分别使用两个中国英语学习者组的数据进行测试。

```{r }
#Cross langauge preception
#svm
y_predCE1 = predict(svm_AE, newdata = datasetCE1[-1])
y_predCE2 = predict(svm_AE, newdata = datasetCE2[-1])
#output the data
#install.packages("caret")

library(caret)

conf_ce1 = confusionMatrix(as.factor(datasetCE1$focus_type), y_predCE1)
conf_ce2 = confusionMatrix(as.factor(datasetCE2$focus_type), y_predCE2)

CE1.TEST = as.data.frame(conf_ce1$table)%>%
  group_by(Reference)%>%
  mutate(accuracy = Freq/sum(Freq),
         LANG = "CE1")

CE2.TEST = as.data.frame(conf_ce2$table)%>%
  group_by(Reference)%>%
  mutate(accuracy = Freq/sum(Freq),
         LANG = "CE2")

# 总体准确率在CE1和CE2两组中均高于随机水平，且两组之间的差异较小。在每个组内，BF类词汇相对容易分类，而NF和CF类词汇则较难分类，反映在较低的准确率上。

rbind(CE1.TEST, CE2.TEST)%>%
  filter(Prediction == Reference)


```

&emsp;&emsp;根据机器学习算法，仅基于目标词的语音特征对不同信息焦点进行分类的总体准确率并不高。这从感知的角度支持了目标词本身没有稳健的语音线索来区分广义、狭义和对比焦点的观点。然而，与持续时间相关的特征在重要性指数中的高排名与之前的文献一致。然而，目标词焦点中缺乏稳健的语音特征并不意味着语音信息不能足以建模信息焦点。相反，目标词以外的语音信息可能有助于区分不同的焦点。在文献[3]中，所有焦点后的词的f0峰值均低于这些词在中性焦点句子中的f0峰值。包含焦点后词的语音信息可能会提高分类准确率。

&emsp;&emsp;使用AE数据训练的SVM模型对第二语言学习者的发音进行分类，生成的准确率与对AE发音进行分类的结果相当。这表明尽管AE和CE之间存在语音差异，但两个CE组的目标词至少在SVM模型区分这些词的能力上与AE相当。两个CE组之间的差异非常小，表明英语水平并未改变CE学习者的焦点实现模式。


## 非监督学习


&emsp;&emsp;下面我们基于词频特征计算两个文本的文体风格特征并通过不同的非监督学习的方法对两个不同的文本进行分类。

### 文本数据预处理
```{r message=FALSE}
library(stylo)

# 导入文本数据
style.corpus <- load.corpus(files = "all", corpus.dir = "~/Nutstore Files/310_Tutorial/Language data science/data/ch6/detectives",
         encoding = "UTF-8")

# 对文本进行分词
tokenized.corpus <- txt.to.words.ext(style.corpus, 
                                     preserve.case = TRUE)

# 根据研究目的我们可以设置一个词表去除一些干扰词。比如我们想排除文本中高频专有名词的干扰。
#proper.noun = c("DEE","Judge","Dee","")

# clean.corpus = delete.stop.words(tokenized.corpus, 
#                                   stop.words = proper.noun)

# 一些研究认为代词对于计算文体风格有干扰，比如如果是一个大女主的小说，那么女性代词就会很多。但是这些不能代表作者风格，只能代表作品风格。
clean.corpus = delete.stop.words(tokenized.corpus,
                                  stop.words = stylo.pronouns(corpus.lang = "English"))



corpus.char.1 <- txt.to.features(clean.corpus, 
                                       ngram.size = 1, 
                                       features = "w")

# 将数据划分成1000个词一份
sliced.corpus.char.1 <- make.samples(corpus.char.1, 
                              sampling = "normal.sampling", 
                              sample.size = 1000)
# 提取词频特征
features1 <- make.frequency.list(sliced.corpus.char.1)

# 制作词频特征表
freqs1 <- make.table.of.frequencies(sliced.corpus.char.1, 
                                   features = features1)


# Culling
# 通过删选，用户可以指定特征在语料库中的出现比例，以决定其是否被纳入分析。在语料库中未达到指定比例的词语将被忽略。
culled.freqs1 <- perform.culling(freqs1, culling.level = 80)

```

### 文本聚类分析

```{r message=FALSE}
# 主成分分析
stylo(frequencies = culled.freqs1, 
      analysis.type = "PCR",
      custom.graph.title = "Judge Dee and Sherlock", 
      pca.visual.flavour = "technical", 
      write.png.file = TRUE, gui = FALSE)



# 显示两本书在第一第二主成分空间的分布
stylo(frequencies = culled.freqs1, 
      analysis.type = "PCR", 
      mfw.min = 100, mfw.max = 500,
      custom.graph.title = "Judge Dee and Sherlock", 
      write.png.file = FALSE, gui = FALSE)


# 显示不同高频词的权重loadings
stylo(frequencies = culled.freqs1, 
      analysis.type = "PCR", 
      custom.graph.title = "Judge Dee and Sherlock",
      pca.visual.flavour = "loadings", 
      write.png.file = FALSE, 
      gui = FALSE)

# cluster analysis
stylo(frequencies = culled.freqs1, 
      analysis.type = "CA", 
      write.png.file = FALSE,  
      custom.graph.title = "Judge Dee and Sherlock", 
      gui = FALSE)


```
