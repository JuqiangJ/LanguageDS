FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Morett, LM
   Fraundorf, SH
AF Morett, Laura M.
   Fraundorf, Scott H.
TI Listeners consider alternative speaker productions in discourse
   comprehension and memory: Evidence from beat gesture and pitch accenting
SO MEMORY & COGNITION
LA English
DT Article
DE Psycholinguistics; Discourse processing; Embodied cognition; Language
   comprehension
ID SPEECH-PERCEPTION; HAND GESTURES; FOCUS; INTONATION; PROSODY; RECALL;
   COMMUNICATION; WORDS
AB Cues to emphasis, such as beat gesture and contrastive pitch accenting, play an important role in constraining what comprehenders remember from a discourse. One possibility is that these cues are used in a purely bottom-up manner in which additional attention is devoted to emphasized material. Another possibility is that comprehenders use top-down expectations of what cues might be expected in the current communicative context, such that the absence of an expected cue may serve as an indicator that material is unimportant. We independently manipulated two cues conveying emphasis - beat gesture and contrastive pitch accenting - to examine how they affected memory for information in a discourse. When beat gesture was present in some cases (Experiment 1), contrastive pitch accenting facilitated memory when beat gesture was present but not when beat gesture was absent. By contrast, when beat gesture was never present (Experiment 2), contrastive pitch accenting facilitated memory even though stimuli were identical to those in which beat gesture was absent in Experiment 1. Together, these results indicate that which cues could be produced affects interpretation even when these cues are absent, indicating that top-down expectations influence cue integration, consistent with emerging data-explanation views of language processing.
C1 [Morett, Laura M.] Univ Alabama, Dept Educ Studies Psychol Res Methodol & Counseli, Tuscaloosa, AL 35401 USA.
   [Fraundorf, Scott H.] Univ Pittsburgh, Dept Psychol, Learning Res & Dev Ctr, Pittsburgh, PA 15260 USA.
RP Morett, LM (corresponding author), Univ Alabama, Dept Educ Studies Psychol Res Methodol & Counseli, Tuscaloosa, AL 35401 USA.
EM lmorett@ua.edu
RI Morett, Laura/H-9616-2019
OI Fraundorf, Scott/0000-0002-0738-476X; Morett, Laura/0000-0002-1251-7213
CR Allen JS, 2003, J ACOUST SOC AM, V113, P544, DOI 10.1121/1.1528172
   Almor A, 2008, LANG COGNITIVE PROC, V23, P201, DOI 10.1080/01690960701330936
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Bergen Leon, 2012, P COGSCI 2012, V2012, P120
   Biau E, 2015, CORTEX, V68, P76, DOI 10.1016/j.cortex.2014.11.018
   Biau E, 2013, BRAIN LANG, V124, P143, DOI 10.1016/j.bandl.2012.10.008
   BIRCH SL, 1995, J MEM LANG, V34, P232, DOI 10.1006/jmla.1995.1011
   Birch SL, 2000, DISCOURSE PROCESS, V30, P285, DOI 10.1207/S15326950dp3003_4
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Braun B, 2010, LANG COGNITIVE PROC, V25, P1024, DOI 10.1080/01690960903036836
   Brown G., 1983, PROSODY MODELS MEASU, P67, DOI DOI 10.1007/978-3-642-69103-4_6
   Chu MY, 2014, J EXP PSYCHOL GEN, V143, P694, DOI 10.1037/a0033861
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477
   COHEN RL, 1992, EUR J COGN PSYCHOL, V4, P113, DOI 10.1080/09541449208406246
   Conrey B, 2006, J ACOUST SOC AM, V119, P4065, DOI 10.1121/1.2195091
   Cook SW, 2009, COGNITION, V113, P98, DOI 10.1016/j.cognition.2009.06.006
   Degen J, 2016, COGNITIVE SCI, V40, P172, DOI 10.1111/cogs.12227
   Eckert Penelope, 2001, STYLE SOCIOLINGUISTI
   Esteve-Gibert N, 2015, INFANT BEHAV DEV, V38, P126, DOI 10.1016/j.infbeh.2014.12.016
   Esteve-Gibert N, 2013, J SPEECH LANG HEAR R, V56, P850, DOI 10.1044/1092-4388(2012/12-0049)
   Farmer TA, 2013, BEHAV BRAIN SCI, V36, P211, DOI 10.1017/S0140525X12002312
   Feyereisen P, 2006, EUR J COGN PSYCHOL, V18, P185, DOI 10.1080/09541440540000158
   Fraundorf S. H., 2014, COGTOOLBOX MATLAB
   Fraundorf SH, 2012, PSYCHOL AGING, V27, P88, DOI 10.1037/a0024138
   Fraundorf SH, 2010, J MEM LANG, V63, P367, DOI 10.1016/j.jml.2010.06.004
   GIVON T, 1992, LINGUISTICS, V30, P5, DOI 10.1515/ling.1992.30.1.5
   Gotzner N, 2019, LANG LINGUIST COMPAS, V13, DOI 10.1111/lnc3.12310
   Hirata Y, 2014, J SPEECH LANG HEAR R, V57, P2090, DOI 10.1044/2014_JSLHR-S-14-0049
   Hostetter AB, 2010, J MEM LANG, V63, P245, DOI 10.1016/j.jml.2010.04.003
   Husband EM, 2016, LANG COGN NEUROSCI, V31, P217, DOI 10.1080/23273798.2015.1083113
   Igualada A, 2017, J EXP CHILD PSYCHOL, V156, P99, DOI 10.1016/j.jecp.2016.11.017
   Ito K, 2008, J MEM LANG, V58, P541, DOI 10.1016/j.jml.2007.06.013
   Ito K, 2012, J MEM LANG, V66, P265, DOI 10.1016/j.jml.2011.09.002
   Kaland C., 2011, P 17 INT C PHON SCI, P1006
   Kamas EN, 1996, MEM COGNITION, V24, P687, DOI 10.3758/BF03201094
   Kamide Y, 2012, COGNITION, V124, P66, DOI 10.1016/j.cognition.2012.03.001
   Kamin L. J., 1969, PUNISHMENT AVERSIVE, P279
   Kleiner M, 2007, 30 EUR C VIS PERC EC
   Krahmer E, 2007, J MEM LANG, V57, P396, DOI 10.1016/j.jml.2007.06.005
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   Kurumada C, 2014, COGNITION, V133, P335, DOI 10.1016/j.cognition.2014.05.017
   Kushch O, 2016, P 8 INT C SPEECH PRO, V8, P922
   Kushch O, 2018, LANG COGN NEUROSCI, V33, P992, DOI 10.1080/23273798.2018.1435894
   Labov W., 2008, ATLAS N AM ENGLISH P
   Ladd DR, 2008, CAMB STUD LINGUIST, V79, P1
   Lee EK, 2017, BILING-LANG COGN, V20, P1063, DOI 10.1017/S1366728916000638
   Lee EK, 2016, PSYCHON B REV, V23, P1589, DOI 10.3758/s13423-016-1069-7
   Leonard T, 2011, LANG COGNITIVE PROC, V26, P1457, DOI 10.1080/01690965.2010.500218
   Levantinou E. I., 2016, P 3 EUR S MULT COMM, P32
   Llanes-Coromina J, 2018, J EXP CHILD PSYCHOL, V172, P168, DOI 10.1016/j.jecp.2018.02.004
   Loehr D, 2012, J LAB PHONOL, V3, P71, DOI [DOI 10.1515/lp-2012-0006, DOI 10.1515/LP-2012-0006]
   McNeill D., 2006, ENCY LANGUAGE LINGUI, P58, DOI DOI 10.1016/B0-08-044854-2/00798-7
   McNeill D., 1992, HAND MIND
   McNeill D., 2005, GESTURE THOUGHT
   Morett LM, 2014, MOD LANG J, V98, P834, DOI 10.1111/j.1540-4781.2014.12125.x
   Munson C. M, 2011, THESIS
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   Pierrehumbert J. B., 1990, INTENTIONS COMMUNICA, V271, P311
   REPP BH, 1982, PSYCHOL BULL, V92, P81, DOI 10.1037/0033-2909.92.1.81
   Rohde H, 2018, PSYCHOL LEARN MOTIV, V68, P215, DOI 10.1016/bs.plm.2018.08.012
   Roustan B., 2010, SPEECH PROSODY 2010
   Rusiewicz HL, 2014, SPEECH COMMUN, V57, P283, DOI 10.1016/j.specom.2013.06.004
   Rusiewicz HL, 2013, J SPEECH LANG HEAR R, V56, P458, DOI 10.1044/1092-4388(2012/11-0283)
   Sanford AJ, 2006, DISCOURSE PROCESS, V42, P99, DOI 10.1207/s15326950dp4202_1
   Schwarzschild Roger, 1999, NAT LANG SEMANT, V7, P141, DOI DOI 10.1023/A:1008370902407
   Shattuck-Hufnagel S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01514
   Shultz AA, 2012, J ACOUST SOC AM, V132, pEL95, DOI 10.1121/1.4736711
   So WC, 2012, LANG COGNITIVE PROC, V27, P665, DOI 10.1080/01690965.2011.573220
   So WC, 2009, COGNITIVE SCI, V33, P115, DOI 10.1111/j.1551-6709.2008.01006.x
   Spalek K, 2014, J MEM LANG, V70, P68, DOI 10.1016/j.jml.2013.09.001
   Steedman M, 2000, LINGUIST INQ, V31, P649, DOI 10.1162/002438900554505
   Sturt P, 2004, PSYCHON B REV, V11, P882, DOI 10.3758/BF03196716
   Sueyoshi A, 2005, LANG LEARN, V55, P661, DOI 10.1111/j.0023-8333.2005.00320.x
   Trude AM, 2012, LANG COGNITIVE PROC, V27, P979, DOI 10.1080/01690965.2011.597153
   Vila-Gimenez I, 2019, DEV PSYCHOL, V55, P250, DOI 10.1037/dev0000604
   Wang L, 2013, NEUROPSYCHOLOGIA, V51, P2847, DOI 10.1016/j.neuropsychologia.2013.09.027
   Watson DG, 2008, COGNITIVE SCI, V32, P1232, DOI 10.1080/03640210802138755
   Weber A, 2006, LANG SPEECH, V49, P367, DOI 10.1177/00238309060490030301
NR 79
TC 4
Z9 4
U1 1
U2 7
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0090-502X
EI 1532-5946
J9 MEM COGNITION
JI Mem. Cogn.
PD NOV
PY 2019
VL 47
IS 8
BP 1515
EP 1530
DI 10.3758/s13421-019-00945-1
PG 16
WC Psychology, Experimental
SC Psychology
GA JI8SW
UT WOS:000493734600006
PM 31215010
OA Bronze
DA 2021-02-24
ER

PT J
AU Aktan-Erciyes, A
   Goksun, T
AF Aktan-Erciyes, Asli
   Goksun, Tilbe
TI Early Event Understanding Predicts Later Verb Comprehension and Motion
   Event Lexicalization
SO DEVELOPMENTAL PSYCHOLOGY
LA English
DT Article
DE event conceptualization; verb learning; motion event lexicalization;
   relational words
ID LANGUAGE SPEECH-PERCEPTION; INDIVIDUAL-DIFFERENCES; INFANTS
   DISCRIMINATE; ENGLISH; MANNER; LEARN; PATH; CATEGORIZATION; FOUNDATIONS;
   EXPRESSION
AB Before infants produce words, they can discriminate changes in motion event components such as manner (how an action is performed) and path (trajectory of an action). Individual differences in nonlinguistic event categorization are related to children's later verb comprehension (Konishi, Stahl, Golinkoff, & Hirsh-Pasek, 2016). We asked: (a) Do infants learning Turkish, a verb-framed language, attend to both manner and path changes in motion events? (b) Is early detection of path and manner related to children's later verb comprehension and (c) how they describe motion events? Thirty-two Turkish-reared children were tested at three time points. At Time 1, infants (M-age = 14.5 months) were tested on their detection of changes in path and manner using the Preferential Looking Paradigm. At Time 2, children were tested on their receptive language skills (M-age = 22.07 months). At Time 3, children performed 3 tasks (M-age = 35.05 months): a verb comprehension task, an event description task depicting motion events with different path and manner combinations, and an expressive language task. The ability to detect changes in event components at Time 1 predicted verb comprehension abilities at Time 3, beyond general receptive and expressive vocabulary skills at Times 2 and 3. Infants who noticed changes in path and manner at Time 1 used fewer manner-only descriptions and more path-any descriptions (i.e., descriptions that included a path component with or without manner) in their speech at Time 3. These findings suggest that early detection of event components is associated not only with verb comprehension, but also with how children lexicalize event components in line with their native language.
C1 [Aktan-Erciyes, Asli; Goksun, Tilbe] Koc Univ, Dept Psychol, TR-34450 Istanbul, Turkey.
   [Aktan-Erciyes, Asli] Kadir Has Univ, Dept Psychol, Istanbul, Turkey.
RP Goksun, T (corresponding author), Koc Univ, Dept Psychol, TR-34450 Istanbul, Turkey.
EM tgoksun@ku.edu.tr
RI Goksun, Tilbe/ABI-5133-2020; AKTAN-ERCIYES, ASLI/AAG-1633-2019
OI Goksun, Tilbe/0000-0002-0190-7988; AKTAN-ERCIYES,
   ASLI/0000-0002-6531-6140
FU TUBITAK (The Scientific and Technological Research Council of Turkey)
   1001 GrantTurkiye Bilimsel ve Teknolojik Arastirma Kurumu (TUBITAK)
   [114K342]; James S. McDonnell Foundation Scholar Award [220020510]
FX This work was supported by TUBITAK (The Scientific and Technological
   Research Council of Turkey) 1001 Grant (114K342) and by a James S.
   McDonnell Foundation Scholar Award (Grant 220020510) to Tilbe Gok-sun.
   We thank everyone at Language and Cognition Lab in Koc University for
   their invaluable contributions to this project. Special thanks go to
   Eylul Turan, I.lkim Saricimen, Hazal Kartalkanat, Ece Kuraloglu, Irmak
   Celebioglu, Benay Baskurt, Aziz Tan Gurkan, and Idil Alaftar for their
   help in data transcriptions and coding. We thank Zeynep Aslan and Berna
   Uzundag for their feedback on a draft of this article. We are also
   grateful to the children and parents who participated in the study.
CR Akhavan N, 2017, LANG COGN NEUROSCI, V32, P792, DOI 10.1080/23273798.2016.1276607
   Aksu-Koc A., 2011, TURKCEDE ERKEN SOZCU
   Aktan-Erciyes A., 2019, ICPS BIENN C PAR
   Allen S, 2007, COGNITION, V102, P16, DOI 10.1016/j.cognition.2005.12.006
   Berument S. K., 2010, TURKISH EXPRESSIVE R
   Bowerman M., 2001, LANG ACQUIS, DOI [10.1017/CBO9780511620669, DOI 10.1017/CBO9780511620669]
   Brandone AC, 2007, CHILD DEV, V78, P1322, DOI 10.1111/j.1467-8624.2007.01068.x
   Candan A, 2012, COGNITIVE DEV, V27, P205, DOI 10.1016/j.cogdev.2011.12.001
   CHOI S, 1991, COGNITION, V41, P83, DOI 10.1016/0010-0277(91)90033-Z
   Fernald A, 2012, CHILD DEV, V83, P203, DOI 10.1111/j.1467-8624.2011.01692.x
   Fisher C, 1996, COGNITIVE PSYCHOL, V31, P41, DOI 10.1006/cogp.1996.0012
   Gentner D., 2001, LANG ACQUIS, P215, DOI DOI 10.1017/CBO9780511620669.010
   Gentner D, 1982, LANGUAGE DEV, P301
   Gentner D, 2010, CROSSLINGUISTIC APPROACHES TO THE PSYCHOLOGY OF LANGUAGE: RESEARCH IN THE TRADITION OF DAN ISAAC SLOBIN, P465
   Gleitman Lelia, 1990, LANG ACQUIS, V1, P3, DOI DOI 10.1207/S15327817LA0101_2
   Goksun T, 2008, J CHILD LANG, V35, P291, DOI 10.1017/S0305000907008471
   Goksun T, 2015, BRAIN LANG, V150, P1, DOI 10.1016/j.bandl.2015.07.012
   Goksun T, 2011, COGNITION, V121, P176, DOI 10.1016/j.cognition.2011.07.002
   Goksun T., 2017, TRENDS LANGUAGE ACQU, V21, DOI [https://doi.org/10.1075/tilar.21.12gok, DOI 10.1075/TILAR.21.12GOK]
   Goksun T, 2010, PERSPECT PSYCHOL SCI, V5, P33, DOI 10.1177/1745691609356783
   GOLINKOFF RM, 1987, J CHILD LANG, V14, P23, DOI 10.1017/S030500090001271X
   Golinkoff RM, 2008, TRENDS COGN SCI, V12, P397, DOI 10.1016/j.tics.2008.07.003
   Gullberg Marianne, 2008, FIRST LANG, V28, DOI DOI 10.1177/0142723707088074
   Hespos SJ, 2004, NATURE, V430, P453, DOI 10.1038/nature02634
   Hickmann M., 2006, SPACE LANGUAGES LING, P281, DOI [10.1075/TSL.66.17HIC, DOI 10.1075/TSL.66.17HIC]
   Hickmann M, 2009, J CHILD LANG, V36, P705, DOI 10.1017/S0305000908009215
   HOHENSTEIN J, 2004, WEAVING LEXICON
   Hohenstein JM, 2005, J COGN DEV, V6, P403, DOI 10.1207/s15327647jcd0603_5
   Hollich G., 2008, SUPERCODER PROGRAM C
   Ji Y., 2011, J FOREIGN LANGUAGES, V34, P2
   Karaduman A. N., 2015, INT C PSYCH SCI AMST
   Konishi H, 2016, J EXP CHILD PSYCHOL, V151, P18, DOI 10.1016/j.jecp.2016.03.012
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   Maguire MJ, 2010, COGNITION, V114, P299, DOI 10.1016/j.cognition.2009.10.002
   Mandler JM, 2012, COGNITIVE SCI, V36, P421, DOI 10.1111/j.1551-6709.2012.01241.x
   Matsuo A, 2012, J CHILD LANG, V39, P637, DOI 10.1017/S0305000911000213
   Naigles LR, 1996, COGNITION, V58, P221, DOI 10.1016/0010-0277(95)00681-8
   Nappa R, 2009, LANG LEARN DEV, V5, P203, DOI 10.1080/15475440903167528
   Ozcaliskan S, 1999, PROC ANN BUCLD, P541
   Ozcaliskan S, 2016, BILING-LANG COGN, V19, P644, DOI 10.1017/S1366728915000796
   Papafragou A, 2006, COGNITION, V98, pB75, DOI 10.1016/j.cognition.2005.05.005
   Papafragou A, 2010, LANG COGNITIVE PROC, V25, P224, DOI 10.1080/01690960903017000
   Pruden SM, 2013, CHILD DEV, V84, P331, DOI 10.1111/j.1467-8624.2012.01843.x
   Pruden SM, 2012, CHILD DEV, V83, P977, DOI 10.1111/j.1467-8624.2012.01737.x
   Pulverman R, 2008, COGNITION, V108, P825, DOI 10.1016/j.cognition.2008.04.009
   Pulverman R, 2013, CHILD DEV, V84, P241, DOI 10.1111/cdev.12030
   Roseberry S, 2014, CHILD DEV, V85, P956, DOI 10.1111/cdev.12166
   Song LL, 2016, J EXP CHILD PSYCHOL, V151, P77, DOI 10.1016/j.jecp.2016.01.004
   Talmy Leonard, 2000, COGNITIVE SEMANTICS, V1
   TALMY Leonard, 1985, LANGUAGE TYPOLOGY SY, P57, DOI DOI 10.1017/CB09780511618437
   TOMASELLO M, 1986, CHILD DEV, V57, P1454, DOI 10.1111/j.1467-8624.1986.tb00470.x
   Tsao FM, 2006, J ACOUST SOC AM, V120, P2285, DOI 10.1121/1.2338290
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1988, DEV PSYCHOL, V24, P672, DOI 10.1037/0012-1649.24.5.672
NR 55
TC 0
Z9 0
U1 2
U2 3
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0012-1649
EI 1939-0599
J9 DEV PSYCHOL
JI Dev. Psychol.
PD NOV
PY 2019
VL 55
IS 11
BP 2249
EP 2262
DI 10.1037/dev0000804
PG 14
WC Psychology, Developmental
SC Psychology
GA JH5BC
UT WOS:000492783100001
PM 31436456
DA 2021-02-24
ER

PT J
AU Imafuku, M
   Kanakogi, Y
   Butler, D
   Myowa, M
AF Imafuku, Masahiro
   Kanakogi, Yasuhiro
   Butler, David
   Myowa, Masako
TI Demystifying infant vocal imitation: The roles of mouth looking and
   speaker's gaze
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
DE audiovisual speech perception; eye contact; infants; language
   development; vocal imitation
ID AUDIOVISUAL SPEECH; SELECTIVE ATTENTION; JOINT ATTENTION; EYE CONTACT;
   INDIVIDUAL-DIFFERENCES; DEVELOPMENTAL-CHANGES; PHONETIC INFORMATION;
   BRAIN RESPONSES; PERCEPTION; LANGUAGE
AB Vocal imitation plays a fundamental role in human language acquisition from infancy. Little is known, however, about how infants imitate other's sounds. We focused on three factors: (a) whether infants receive information from upright faces, (b) the infant's observation of the speaker's mouth and (c) the speaker directing their gaze towards the infant. We recorded the eye movements of 6-month-olds who participated in experiments watching videos of a speaker producing vowel sounds. We found that an infants' tendency to vocally imitate such videos increased as a function of (a) seeing upright rather than inverted faces, (b) their increased looking towards the speaker's mouth and (c) whether the speaker directed their gaze towards, rather than away from infants. These latter findings are consistent with theories of motor resonance and natural pedagogy respectively. New light has been shed on the cues and underlying mechanisms linking infant speech perception and production.
C1 [Imafuku, Masahiro; Butler, David; Myowa, Masako] Kyoto Univ, Grad Sch Educ, Kyoto, Japan.
   [Imafuku, Masahiro] Musashino Univ, Fac Educ, Tokyo, Japan.
   [Kanakogi, Yasuhiro] Otemon Gakuin Univ, Dept Psychol, Osaka, Japan.
   [Butler, David] Inst Social Neurosci Psychol, Heidelberg, Vic, Australia.
RP Imafuku, M (corresponding author), Kyoto Univ, Grad Sch Educ, Kyoto, Japan.; Imafuku, M (corresponding author), Musashino Univ, Fac Educ, Tokyo, Japan.
EM masahiro.imafuku@gmail.com
FU Mayekawa Houonkai Foundation; Japan Society for the Promotion of
   ScienceMinistry of Education, Culture, Sports, Science and Technology,
   Japan (MEXT)Japan Society for the Promotion of Science [17H01016,
   17J07474, 24119005]; Center of Innovation Program
FX the Mayekawa Houonkai Foundation, Grant/Award Number: 2016, 2017 and
   2018; Japan Society for the Promotion of Science, Grant/Award Number:
   17H01016, 17J07474 and 24119005; Center of Innovation Program
CR Altvater-Mackensen N, 2016, NEUROIMAGE, V133, P14, DOI 10.1016/j.neuroimage.2016.02.061
   Altvater-Mackensen N, 2015, CHILD DEV, V86, P362, DOI 10.1111/cdev.12320
   Amodio DM, 2006, NAT REV NEUROSCI, V7, P268, DOI 10.1038/nrn1884
   Bahrick LE, 2000, DEV PSYCHOL, V36, P190, DOI 10.1037//0012-1649.36.2.190
   Bahrick LE, 2005, DEV PSYCHOL, V41, P541, DOI 10.1037/0012-1649.41.3.541
   Bahrick LE, 2002, DEV PSYCHOBIOL, V41, P352, DOI 10.1002/dev.10049
   Bernstein LE, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00386
   Best CT, 2016, ECOL PSYCHOL, V28, P216, DOI 10.1080/10407413.2016.1230372
   Bhatt RS, 2005, CHILD DEV, V76, P169, DOI 10.1111/j.1467-8624.2005.00837.x
   Bruderer AG, 2015, P NATL ACAD SCI USA, V112, P13531, DOI 10.1073/pnas.1508631112
   Burnham D, 2004, DEV PSYCHOBIOL, V45, P204, DOI 10.1002/dev.20032
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Chen X, 2004, DEVELOPMENTAL SCI, V7, P42, DOI 10.1111/j.1467-7687.2004.00321.x
   Coulon M, 2013, INFANCY, V18, P782, DOI 10.1111/infa.12001
   Csibra G, 2009, TRENDS COGN SCI, V13, P148, DOI 10.1016/j.tics.2009.01.005
   de Haan M, 2002, J COGNITIVE NEUROSCI, V14, P199, DOI 10.1162/089892902317236849
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   Dehaene-Lambertz G, 2006, TRENDS NEUROSCI, V29, P367, DOI 10.1016/j.tins.2006.05.011
   DePaolis RA, 2013, INFANT BEHAV DEV, V36, P642, DOI 10.1016/j.infbeh.2013.06.007
   DePaolis RA, 2011, INFANT BEHAV DEV, V34, P590, DOI 10.1016/j.infbeh.2011.06.005
   Desjardins RN, 2004, DEV PSYCHOBIOL, V45, P187, DOI 10.1002/dev.20033
   Eskelund K, 2015, NEUROPSYCHOLOGIA, V66, P48, DOI 10.1016/j.neuropsychologia.2014.10.021
   Gallay M, 2006, CHILD DEV, V77, P984, DOI 10.1111/j.1467-8624.2006.00914.x
   Gergely C, 2010, MIND LANG, V25, P141
   Gogate LJ, 1998, J EXP CHILD PSYCHOL, V69, P133, DOI 10.1006/jecp.1998.2438
   Grossmann T, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00201
   Hillairet de Boisferon A., 2016, DEVELOPMENTAL SCI, V20, pe12381
   Imada T, 2006, NEUROREPORT, V17, P957, DOI 10.1097/01.wnr.0000223387.51704.89
   Imafuku M, 2016, PSYCHOLOGIA, V59, P163
   Imafuku M, 2014, NEUROIMAGE, V103, P476, DOI 10.1016/j.neuroimage.2014.08.034
   Jordan TR, 1997, J EXP PSYCHOL HUMAN, V23, P388, DOI 10.1037/0096-1523.23.2.388
   Kanakogi Y, 2011, NAT COMMUN, V2, DOI 10.1038/ncomms1342
   Kubicek C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089275
   Kuhl PK, 2007, DEVELOPMENTAL SCI, V10, P110, DOI 10.1111/j.1467-7687.2007.00572.x
   Kuhl PK, 2014, P NATL ACAD SCI USA, V111, P11238, DOI 10.1073/pnas.1410963111
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Kuhl PK, 1996, J ACOUST SOC AM, V100, P2425, DOI 10.1121/1.417951
   Kushnerenko E, 2008, P NATL ACAD SCI USA, V105, P11442, DOI 10.1073/pnas.0804275105
   Kushnerenko E, 2013, EUR J NEUROSCI, V38, P3363, DOI 10.1111/ejn.12317
   LEGERSTEE M, 1990, INFANT BEHAV DEV, V13, P343, DOI 10.1016/0163-6383(90)90039-B
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Majorano M, 2014, LANG LEARN DEV, V10, P179, DOI 10.1080/15475441.2013.829740
   Mercado E, 2014, COMP COGN BEHAV REV, V9, DOI 10.3819/ccbr.2014.90002
   Moore C., 1995, JOINT ATTENTION ITS
   Morales M, 2000, J APPL DEV PSYCHOL, V21, P283, DOI 10.1016/S0193-3973(99)00040-4
   Mugitani R, 2008, INFANT BEHAV DEV, V31, P307, DOI 10.1016/j.infbeh.2007.12.002
   Mundy P, 1998, INFANT BEHAV DEV, V21, P469, DOI 10.1016/S0163-6383(98)90020-0
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Oakes LM, 2013, INFANCY, V18, P134, DOI 10.1111/j.1532-7078.2011.00107.x
   Ojanen V, 2005, NEUROIMAGE, V25, P333, DOI 10.1016/j.neuroimage.2004.12.001
   Oller DK, 1999, J COMMUN DISORD, V32, P223, DOI 10.1016/S0021-9924(99)00013-1
   Over H, 2012, J COMP PSYCHOL, V126, P182, DOI 10.1037/a0024555
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Patterson ML, 1999, INFANT BEHAV DEV, V22, P237, DOI 10.1016/S0163-6383(99)00003-X
   Pons F, 2015, PSYCHOL SCI, V26, P490, DOI 10.1177/0956797614568320
   Ramirez-Esparza N, 2014, DEVELOPMENTAL SCI, V17, P880, DOI 10.1111/desc.12172
   Rizzolatti G, 2001, NAT REV NEUROSCI, V2, P661, DOI 10.1038/35090060
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   RODGON MM, 1977, J GENET PSYCHOL, V131, P115, DOI 10.1080/00221325.1977.10533280
   Rosenblum LD, 1997, PERCEPT PSYCHOPHYS, V59, P347, DOI 10.3758/BF03211902
   Rosenblum LD, 2000, J EXP PSYCHOL HUMAN, V26, P806, DOI 10.1037//0096-1523.26.2.806
   Schmitz J, 2018, LANG COGN NEUROSCI, V33, P527, DOI 10.1080/23273798.2017.1390142
   Senju A, 2008, CURR BIOL, V18, P668, DOI 10.1016/j.cub.2008.03.059
   Senju A, 2009, TRENDS COGN SCI, V13, P127, DOI 10.1016/j.tics.2008.11.009
   Sommerville JA, 2005, COGNITION, V96, pB1, DOI 10.1016/j.cognition.2004.07.004
   Suddendorf T, 2013, DEV PSYCHOBIOL, V55, P52, DOI 10.1002/dev.21005
   Tenenbaum EJ, 2015, J CHILD LANG, V42, P1173, DOI 10.1017/S0305000914000725
   Tenenbaum EJ, 2013, INFANCY, V18, P534, DOI 10.1111/j.1532-7078.2012.00135.x
   TOMASELLO M, 1986, CHILD DEV, V57, P1454, DOI 10.1111/j.1467-8624.1986.tb00470.x
   Tomasello M., 1999, CULTURAL ORIGINS HUM
   Tsang T, 2018, J EXP CHILD PSYCHOL, V169, P93, DOI 10.1016/j.jecp.2018.01.002
   Turati C, 2004, INFANCY, V6, P275, DOI 10.1207/s15327078in0602_8
   Turati C., 2013, DEVELOPMENTAL SCI, V16, P1
   Wang Y, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00153
   Wang Y, 2011, J NEUROSCI, V31, P12001, DOI 10.1523/JNEUROSCI.0845-11.2011
   Wang Y, 2011, BIOL LETTERS, V7, P7, DOI 10.1098/rsbl.2010.0279
   Wass SV, 2013, BEHAV RES METHODS, V45, P229, DOI 10.3758/s13428-012-0245-6
   Watkins K, 2004, J COGNITIVE NEUROSCI, V16, P978, DOI 10.1162/0898929041502616
   Yeung HH, 2013, PSYCHOL SCI, V24, P603, DOI 10.1177/0956797612458802
   Young GS, 2009, DEVELOPMENTAL SCI, V12, P798, DOI 10.1111/j.1467-7687.2009.00833.x
NR 80
TC 2
Z9 2
U1 2
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD NOV
PY 2019
VL 22
IS 6
AR e12825
DI 10.1111/desc.12825
PG 12
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA JG8JM
UT WOS:000492324300015
PM 30980494
OA Bronze
DA 2021-02-24
ER

PT J
AU Vilain, A
   Dole, M
   Lovenbruck, H
   Pascalis, O
   Schwartz, JL
AF Vilain, Anne
   Dole, Marjorie
   Lovenbruck, Helene
   Pascalis, Olivier
   Schwartz, Jean-Luc
TI The role of production abilities in the perception of consonant category
   in infants
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
DE babbling; consonant place of articulation; infants; intersensory
   matching; perception-production link; phoneme categorization
ID SPEECH-PERCEPTION; AUDIOVISUAL SPEECH; 2-MONTH-OLD INFANTS; LOCUS
   EQUATIONS; MOTOR THEORY; DISCRIMINATION; INFORMATION; INVARIANCE; PLACE;
   REPRESENTATIONS
AB The influence of motor knowledge on speech perception is well established, but the functional role of the motor system is still poorly understood. The present study explores the hypothesis that speech production abilities may help infants discover phonetic categories in the speech stream, in spite of coarticulation effects. To this aim, we examined the influence of babbling abilities on consonant categorization in 6- and 9-month-old infants. Using an intersensory matching procedure, we investigated the infants' capacity to associate auditory information about a consonant in various vowel contexts with visual information about the same consonant, and to map auditory and visual information onto a common phoneme representation. Moreover, a parental questionnaire evaluated the infants' consonantal repertoire. In a first experiment using /b/-/d/ consonants, we found that infants who displayed babbling abilities and produced the /b/ and/or the /d/ consonants in repetitive sequences were able to correctly perform intersensory matching, while non-babblers were not. In a second experiment using the /v/-/z/ pair, which is as visually contrasted as the /b/-/d/ pair but which is usually not produced at the tested ages, no significant matching was observed, for any group of infants, babbling or not. These results demonstrate, for the first time, that the emergence of babbling could play a role in the extraction of vowel-independent representations for consonant place of articulation. They have important implications for speech perception theories, as they highlight the role of sensorimotor interactions in the development of phoneme representations during the first year of life.
C1 [Vilain, Anne; Dole, Marjorie; Schwartz, Jean-Luc] Univ Grenoble Alpes, Grenoble INP, CNRS, GIPSA Lab,Speech & Cognit Dept, Grenoble, France.
   [Lovenbruck, Helene; Pascalis, Olivier] Univ Savoie Mt Blanc, Univ Grenoble Alpes, CNRS, LPNC, Grenoble, France.
RP Schwartz, JL (corresponding author), Gipsa Lab, Dept Parole & Cognit, Domaine Univ, Grenoble, France.
EM jean-luc.schwartz@gipsa-lab.grenoble-inp.fr
FU FP7 Ideas: European Research Council [339152]; CDP NeuroCoG
   [ANR-15-IDEX-02]
FX FP7 Ideas: European Research Council, Grant/Award Number: 339152; CDP
   NeuroCoG, Grant/Award Number: ANR-15-IDEX-02
CR Beach EF, 2011, J SPEECH LANG HEAR R, V54, P658, DOI 10.1044/1092-4388(2010/08-0177)
   BENOI C, 1994, J SPEECH HEAR RES, V37, P1195, DOI 10.1044/jshr.3705.1195
   BERTONCINI J, 1988, J EXP PSYCHOL GEN, V117, P21, DOI 10.1037/0096-3445.117.1.21
   BINNIE CA, 1974, J SPEECH HEAR RES, V17, P619, DOI 10.1044/jshr.1704.619
   BLUMSTEIN SE, 1979, J ACOUST SOC AM, V66, P1001, DOI 10.1121/1.383319
   Bruderer AG, 2015, P NATL ACAD SCI USA, V112, P13531, DOI 10.1073/pnas.1508631112
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   Dehaene-Lambertz G, 2006, P NATL ACAD SCI USA, V103, P14240, DOI 10.1073/pnas.0606302103
   DePaolis RA, 2011, INFANT BEHAV DEV, V34, P590, DOI 10.1016/j.infbeh.2011.06.005
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   EILERS RE, 1975, J SPEECH HEAR RES, V18, P158, DOI 10.1044/jshr.1801.158
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Eimas PD, 1999, J ACOUST SOC AM, V105, P1901, DOI 10.1121/1.426726
   EIMAS PD, 1980, SCIENCE, V209, P1140, DOI 10.1126/science.7403875
   FISHER CG, 1968, J SPEECH HEAR RES, V11, P796, DOI 10.1044/jshr.1104.796
   FOWLER CA, 1991, MODULARITY AND THE MOTOR THEORY OF SPEECH PERCEPTION, P33
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Gentil M., 1981, TECHNICAL REPORT
   Grandchamp R., 2018, INNER SPEECH NEW VOI, P131, DOI 10.1093/oso/9780198796640.003.0006
   GRIESER D, 1989, DEV PSYCHOL, V25, P577, DOI 10.1037/0012-1649.25.4.577
   Hoareau M, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12803
   Hochmann JR, 2014, PSYCHOL SCI, V25, P2038, DOI 10.1177/0956797614547918
   HOLMBERG TL, 1977, J ACOUST SOC AM, V62, pS99, DOI 10.1121/1.2016488
   Imada T, 2006, NEUROREPORT, V17, P957, DOI 10.1097/01.wnr.0000223387.51704.89
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   JUSCZYK PW, 1987, DEV PSYCHOL, V23, P648, DOI 10.1037/0012-1649.23.5.648
   JUSCZYK PW, 1978, PERCEPT PSYCHOPHYS, V23, P105, DOI 10.3758/BF03208289
   JUSCZYK PW, 1978, PERCEPT PSYCHOPHYS, V24, P515, DOI 10.3758/BF03198777
   Kern S, 2009, BECOMING ELOQUENT: ADVANCES IN THE EMERGENCE OF LANGUAGE, HUMAN COGNITION, AND MODERN CULTURES, P205
   Kuhl PK, 2014, P NATL ACAD SCI USA, V111, P11238, DOI 10.1073/pnas.1410963111
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Kuhl PK, 1996, J ACOUST SOC AM, V100, P2425, DOI 10.1121/1.417951
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   KUHL PK, 1984, INFANT BEHAV DEV, V7, P361, DOI 10.1016/S0163-6383(84)80050-8
   Laurent R, 2017, PSYCHOL REV, V124, P572, DOI 10.1037/rev0000069
   LEVITT A, 1988, J EXP PSYCHOL HUMAN, V14, P361
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   LIBERMAN AM, 1957, J ACOUST SOC AM, V29, P117, DOI 10.1121/1.1908635
   Locke J. L., 1983, PHONOLOGICAL ACQUISI
   MACKAIN K, 1983, SCIENCE, V219, P1347, DOI 10.1126/science.6828865
   MacNeilage PF, 2001, CURR OPIN NEUROBIOL, V11, P696, DOI 10.1016/S0959-4388(01)00271-9
   Mahmoudzadeh M, 2013, P NATL ACAD SCI USA, V110, P4846, DOI 10.1073/pnas.1212220110
   Majorano M, 2014, LANG LEARN DEV, V10, P179, DOI 10.1080/15475441.2013.829740
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Mersad K, 2016, DEVELOPMENTAL SCI, V19, P710, DOI 10.1111/desc.12325
   Mottonen R, 2013, CEREB CORTEX, V23, P1190, DOI 10.1093/cercor/bhs110
   Mottonen R, 2005, NEUROIMAGE, V24, P731, DOI 10.1016/j.neuroimage.2004.10.011
   Ojanen V, 2005, NEUROIMAGE, V25, P333, DOI 10.1016/j.neuroimage.2004.12.001
   Patri JF, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005942
   Patterson ML, 2002, J EXP CHILD PSYCHOL, V81, P93, DOI 10.1006/jecp.2001.2644
   Patterson ML, 1999, INFANT BEHAV DEV, V22, P237, DOI 10.1016/S0163-6383(99)00003-X
   Perani D, 2011, P NATL ACAD SCI USA, V108, P16056, DOI 10.1073/pnas.1102991108
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Sato M, 2011, CORTEX, V47, P1001, DOI 10.1016/j.cortex.2011.03.009
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   Schwartz JL, 1997, J PHONETICS, V25, P255, DOI 10.1006/jpho.1997.0043
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Stevens K., 1967, MODELS PERCEPTION SP, P88
   STEVENS KN, 1978, J ACOUST SOC AM, V64, P1358, DOI 10.1121/1.382102
   STEVENS KN, 1980, J ACOUST SOC AM, V68, P836, DOI 10.1121/1.384823
   Summerfield Q., 1987, HEARING EYE PSYCHOL, P3, DOI DOI 10.2307/1423237
   Sussman HM, 1998, BEHAV BRAIN SCI, V21, P241, DOI 10.1017/S0140525X98001174
   SUSSMAN HM, 1993, J ACOUST SOC AM, V94, P1256, DOI 10.1121/1.408178
   SUSSMAN HM, 1991, J ACOUST SOC AM, V90, P1309, DOI 10.1121/1.401923
   VANSON N, 1994, J ACOUST SOC AM, V96, P1341, DOI 10.1121/1.411324
   Vilain A., 2019, PHONCAT
   WALDEN BE, 1977, J SPEECH HEAR RES, V20, P130, DOI 10.1044/jshr.2001.130
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Yeung HH, 2013, PSYCHOL SCI, V24, P603, DOI 10.1177/0956797612458802
NR 72
TC 2
Z9 2
U1 0
U2 6
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD NOV
PY 2019
VL 22
IS 6
AR e12830
DI 10.1111/desc.12830
PG 13
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA JG8JM
UT WOS:000492324300018
PM 30908771
DA 2021-02-24
ER

PT J
AU Sloos, M
   Garcia, AA
   Andersson, A
   Neijmeijer, M
AF Sloos, Marjoleine
   Garcia, Andrea Ariza
   Andersson, Alexandra
   Neijmeijer, Mathea
TI Accent-induced bias in linguistic transcriptions
SO LANGUAGE SCIENCES
LA English
DT Article
ID SPEECH-PERCEPTION; RELIABILITY
AB Many linguistic analyses rely on phonetic transcriptions. Two factors that might affect the accuracy of transcriptions are perceived accent and the listener's linguistic knowledge about that accent. This article focuses on the susceptibility of transcribers to such accent-induced bias, based on speaker's accent, transcriber's variety, and the transcriber's knowledge about the language variety they are transcribing. We offer a method to statistically detect accent-induced biases in linguistic transcriptions.
   This article investigates accent-induced bias in transcriptions of Reference French and Laurentian French (in Canada). In Reference French, high front vowels are phonologically tense /i y/, but they may be phonetically realised as lax [I y]. In Laurentian French, lax [I y] occur as allophones of /i y/. We compare transcriptions of different groups of coders: native speakers of Reference French, native speakers of Laurentian French, and advanced L2 learners of French who are native speakers of Dutch. Half of the Dutch group was informed about the native variety of the speakers and the other half was not.
   Results show that perceived accent among the native transcribers is a relatively strong predictor for transcribed sounds. In addition, the Dutch transcribers who were informed about the speaker's variety transcribed more lax vowels in Laurentian French and more tense vowels in Reference French than the Dutch transcribers who were not informed. Native transcribers also showed contextual effects related to the allophonic distribution of the vowels in Laurentian French. These results are indicative of accent-induced bias. The results are analysed in a predictive top-down model to explain the effect of prior experience and information about the language variety in speech perception. (C) 2018 The Authors. Published by Elsevier Ltd.
C1 [Sloos, Marjoleine] Netherlands Acad Sci, Fryske Akad, Amsterdam, Netherlands.
   [Sloos, Marjoleine; Garcia, Andrea Ariza; Andersson, Alexandra] Aarhus Univ, Aarhus, Denmark.
   [Neijmeijer, Mathea] Univ Maastricht, Maastricht, Netherlands.
RP Sloos, M (corresponding author), Netherlands Acad Sci, Fryske Akad, Amsterdam, Netherlands.; Sloos, M (corresponding author), Aarhus Univ, Aarhus, Denmark.
EM marj.sloos@gmail.com; andreariza.g@gmail.com;
   alexandra_andersson1992@hotmail.com; mathea92@gmail.com
RI Sloos, Marjoleine/E-1735-2016
OI Sloos, Marjoleine/0000-0001-5111-4647
FU DFF-MOBILEX mobility grant; European Commission under the Marie Curie
   Program FP7
FX This research has been made possible through a DFF-MOBILEX mobility
   grant awarded to the first author by the Danish Council for Independent
   Research with support from the European Commission under the Marie Curie
   Program FP7, which is gratefully acknowledged. This article benefitted
   much from discussions at the Interacting Minds Centre of Aarhus
   University and comments on a previous version by Jeroen van de Weijer.
   We also want to thank the audience of the 1st Frisian Humanities
   Conference 23-26 April 2018 for their feedback on this research.
CR Best Catherine T., 2007, LANGUAGE EXPERIENCE, V1334
   Boas Franz, 1889, AM ANTHROPOL, V2, P4
   Boersma P, DOING PHONETICS COMP
   Booij Geert, 1999, PHONOLOGY DUTCH
   Cole R. A., 1980, PERCEPTION PRODUCTIO, P133
   Cucchiarini C, 1996, CLIN LINGUIST PHONET, V10, P131, DOI 10.3109/02699209608985167
   Drager K, 2010, LANG LINGUIST COMPAS, V4, P473, DOI 10.1111/j.1749-818x.2010.00210.x
   Durand Jacques, 2009, PHONOLOGIE VARIATION, P19
   Enns JT, 2008, TRENDS COGN SCI, V12, P327, DOI 10.1016/j.tics.2008.06.001
   Escudero Paola, 2003, P 15 INT C PHON SCI
   Evans K., 2012, THESIS
   Flege JE, 1999, SEC LANG ACQ RES, P101
   Fodor J.A., 1983, MODULARITY MIND ESSA
   Hall-Lew L, 2012, LINGUA, V122, P794, DOI 10.1016/j.lingua.2011.12.005
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Kent R. D., 1996, AM J SPEECH LANG PAT, V5, P7, DOI [DOI 10.1044/1058-0360.0503.07, 10.1044/1058- 0360.0503.07]
   Kerswill P, 1990, LANG VAR CHANGE, V2, P255, DOI DOI 10.1017/S0954394500000363
   Kuhl P. K., 1995, SPEECH PERCEPTION LI, P121
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X
   Martin P, 2002, LINGUISTIQUE, V38, P71, DOI 10.3917/ling.382.0071
   McGurk Harry, 1976, HEARING LIPS SEEING, P746
   Munson B, 2012, AM J SPEECH-LANG PAT, V21, P124, DOI 10.1044/1058-0360(2011/11-0009)
   Munson B, 2010, CLIN LINGUIST PHONET, V24, P245, DOI 10.3109/02699200903532524
   Poliquin Gabriel Christophe, 2006, THESIS
   Rentzsch J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126775
   SHRIBERG LD, 1991, CLIN LINGUIST PHONET, V5, P225, DOI 10.3109/02699209108986113
   Sloos M, 2015, REV COGN LINGUIST, V13, P59, DOI 10.1075/rcl.13.1.03slo
   Sloos Marjoleine, 2015, OWN VARIETY BIAS I P, V6, DOI [10.1177/2041669515593018, DOI 10.1177/2041669515593018]
   Smith C., 1993, J INT PHON ASSOC, V23, P73, DOI DOI 10.1017/S0025100300004874
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   TRAUNMULLER H, 1990, J ACOUST SOC AM, V88, P97, DOI 10.1121/1.399849
   Walker Douglas C., 1984, PRONUNCIATION LAUREN
   WARREN RM, 1971, PERCEPT PSYCHOPHYS, V9, P358, DOI 10.3758/BF03212667
   Wester M, 2001, LANG SPEECH, V44, P377, DOI 10.1177/00238309010440030401
NR 35
TC 2
Z9 2
U1 1
U2 1
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0388-0001
EI 1873-5746
J9 LANG SCI
JI Lang. Sci.
PD NOV
PY 2019
VL 76
SI SI
AR 101176
DI 10.1016/j.langsci.2018.06.002
PG 13
WC Linguistics; Language & Linguistics
SC Linguistics
GA JF8IO
UT WOS:000491628400004
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Xu, F
AF Xu, Fei
TI Towards a Rational Constructivist Theory of Cognitive Development
SO PSYCHOLOGICAL REVIEW
LA English
DT Article
DE rational constructivism; cognitive development; learning mechanisms
ID CHILDRENS CAUSAL INFERENCES; LARGE-NUMBER DISCRIMINATION; OBJECT
   INDIVIDUATION; PROBABILISTIC MODELS; YOUNG-CHILDREN; INFANTS USE;
   SPATIAL REORIENTATION; SELF-EXPLANATIONS; SPEECH-PERCEPTION; GEOMETRIC
   MODULE
AB This article provides a synthesis and overview of a theory of cognitive development, rational constructivism. The basic tenets of this view are as follows: (a) Initial state: Human infants begin life with a set of proto-conceptual primitives. These early representations are not in the format of a language of thought. (b) Mature state: Human adults represent the world in terms of a set of domain-specific intuitive theories. (c) Three types of mechanisms account for learning, development, and conceptual change: language and symbol learning, Bayesian inductive learning, and constructive thinking. (d) The child is an active learner, and cognitive agency is part and parcel of development. I will discuss each of these tenets, and provide an overview of the kind of empirical evidence that supports this view. This is a non-Piagetian view though it is in the spirit of constructivist theories of development; this view emphasizes the utility of formal computational models in understanding learning and developmental change. Lastly, this view also has implications for the study of philosophy of mind and epistemology.
C1 [Xu, Fei] Univ Calif Berkeley, Berkeley, CA 94720 USA.
RP Xu, F (corresponding author), Univ Calif Berkeley, Dept Psychol, BWW 3336, Berkeley, CA 94720 USA.
EM fei_xu@berkeley.edu
FU NSFNational Science Foundation (NSF) [SMA-1640816]; LEGO Foundation
FX I have benefitted from many, many discussions with a great number of
   colleagues, collaborators, and students over the years. Special thanks
   go to Tyler Burge, Susan Carey, David Danks, Stephanie Denison, Kathryn
   Dewar, Mark Fedyk, Jerry Fodor, Susan Gelman, Lila Gleitman, Noah
   Goodman, Tom Griffiths, Todd Gureckis, Alison Gopnik, Charles Kemp, Alan
   Leslie, Tania Lombrozo, Tamar Kushnir, Eric Margolis, Amy Perfors,
   Steven Pinker, Azzurra Ruggeri, Brian Scholl, Laura Schulz, Zi L. Sim,
   Elizabeth Spelke, Joshua Tenenbaum, and Henry Wellman. This work was
   partially supported by an NSF grant (SMA-1640816) and a grant from the
   LEGO Foundation.
CR Anderson EM, 2018, COGNITION, V176, P74, DOI 10.1016/j.cognition.2018.03.008
   Anderson J., 1990, ADAPTIVE CHARACTER T
   Arts T, 2008, ERLANG '08: PROCEEDINGS OF THE 2008 SIGPLAN ERLANG WORKSHOP, P1
   Aslin RN, 1998, PSYCHOL SCI, V9, P321, DOI 10.1111/1467-9280.00063
   Astington JW, 1999, DEV PSYCHOL, V35, P1311, DOI 10.1037/0012-1649.35.5.1311
   AU TK, 1994, COGNITIVE PSYCHOL, V27, P71, DOI 10.1006/cogp.1994.1012
   Austin K, 2014, DEV PSYCHOL, V50, P2061, DOI 10.1037/a0037179
   Ayars A, 2017, COGNITION, V167, P11, DOI 10.1016/j.cognition.2017.01.007
   Baillargeon R, 2004, CURR DIR PSYCHOL SCI, V13, P89, DOI 10.1111/j.0963-7214.2004.00281.x
   BAILLARGEON R, 1985, COGNITION, V20, P191, DOI 10.1016/0010-0277(85)90008-3
   BAILLARGEON R, 1987, DEV PSYCHOL, V23, P655, DOI 10.1037/0012-1649.23.5.655
   Baillargeon R, 2008, PERSPECT PSYCHOL SCI, V3, P2, DOI 10.1111/j.1745-6916.2008.00056.x
   Baillargeon R, 2016, ANNU REV PSYCHOL, V67, P159, DOI 10.1146/annurev-psych-010213-115033
   Baker CL, 2009, COGNITION, V113, P329, DOI 10.1016/j.cognition.2009.07.005
   BALDWIN DA, 1989, CHILD DEV, V60, P381, DOI 10.2307/1130984
   Begus K, 2016, P NATL ACAD SCI USA, V113, P12397, DOI 10.1073/pnas.1603261113
   Begus K, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0108817
   BLOCK N, 1986, MIDWEST STUD PHILOS, V10, P615
   Bloom P., 2002, CHILDREN LEARN MEANI
   Bonatti L, 2002, COGNITIVE PSYCHOL, V44, P388, DOI 10.1006/cogp.2002.0779
   Bonawitz E, 2014, COGNITIVE PSYCHOL, V74, P35, DOI 10.1016/j.cogpsych.2014.06.003
   Bonawitz EB, 2012, COGNITIVE PSYCHOL, V64, P215, DOI 10.1016/j.cogpsych.2011.12.002
   Bonawitz EB, 2010, COGNITION, V115, P104, DOI 10.1016/j.cognition.2009.12.001
   Bramley N., 2018, P 40 ANN C COGN SCI, P1390
   Brannon EM, 2002, COGNITION, V83, P223, DOI 10.1016/S0010-0277(02)00005-7
   Bruner Jerome S., 1976, PLAY ITS ROLE DEV EV
   BRUNER JS, 1961, HARVARD EDUC REV, V31, P21
   Carey S, 2001, COGNITION, V80, P179, DOI 10.1016/S0010-0277(00)00154-2
   Carey S, 1996, PHILOS SCI, V63, P515, DOI 10.1086/289971
   Carey S., 1988, MIND LANG, V3, P167, DOI DOI 10.1111/J.1468-0017.1988.TB00141.X
   CAREY S, 1982, LANG ACQUIS, P347
   Carey S., 1985, CONCEPTUAL CHANGE CH
   Carey S., 1991, EPIGENESIST MIND ESS, P113
   Carey S, 2009, ORIGIN CONCEPTS, DOI [10.1093/acprof:oso/9780195367638.001.0001, DOI 10.1093/ACPROF:OSO/9780195367638.001.0001]
   Carey S, 2014, MIND LANG, V29, P133, DOI 10.1111/mila.12045
   Carruthers P, 2011, OPACITY MIND INTEGRA, DOI [10.1093/acprof:oso/9780199596195.001.0001, DOI 10.1093/ACPROF:OSO/9780199596195.001.0001]
   Carruthers P, 2016, REV PHILOS PSYCHOL, V7, P141, DOI 10.1007/s13164-015-0259-y
   Cesana-Arlotti N, 2018, SCIENCE, V359, P1263, DOI 10.1126/science.aao3539
   CHANDLER M, 1989, CHILD DEV, V60, P1263, DOI 10.2307/1130919
   Chater N., 2008, PROBABILISTIC MIND P, DOI [10.1093/acprof:oso/9780199216093.001.0001, DOI 10.1093/ACPROF:OSO/9780199216093.001.0001]
   Chen YC, 2016, PSYCHOL SCI, V27, P923, DOI 10.1177/0956797616628525
   Cheng K, 2005, PSYCHON B REV, V12, P1, DOI 10.3758/BF03196346
   CHENG K, 1986, COGNITION, V23, P149, DOI 10.1016/0010-0277(86)90041-7
   CHI MTH, 1989, COGNITIVE SCI, V13, P145, DOI 10.1016/0364-0213(89)90002-5
   CHI MTH, 1994, COGNITIVE SCI, V18, P439, DOI 10.1207/s15516709cog1803_3
   CHOMSKY N, 1987, LANGUAGE PROBLEMS KN
   Christie S, 2010, J COGN DEV, V11, P356, DOI 10.1080/15248371003700015
   Coenen A, 2015, COGNITIVE PSYCHOL, V79, P102, DOI 10.1016/j.cogpsych.2015.02.004
   COHEN LB, 1993, DEV PSYCHOL, V29, P421, DOI 10.1037/0012-1649.29.3.421
   Coughlin C, 2015, DEVELOPMENTAL SCI, V18, P957, DOI 10.1111/desc.12271
   DANKS D, 2014, UN MIND COGN REPR, P1, DOI DOI 10.7551/MITPRESS/9540.001.0001
   de Villiers J, 2007, LINGUA, V117, P1858, DOI 10.1016/j.lingua.2006.11.006
   Dehaene S., 1997, NUMBER SENSE
   Denison S., PERSPECTIVES PSYCHOL
   Denison S, 2014, DEV PSYCHOL, V50, P2009, DOI 10.1037/a0037158
   Denison S, 2014, COGNITION, V130, P335, DOI 10.1016/j.cognition.2013.12.001
   Denison S, 2013, DEV PSYCHOL, V49, P243, DOI 10.1037/a0028278
   Denison S, 2013, COGNITION, V126, P285, DOI 10.1016/j.cognition.2012.10.010
   Denison S, 2010, DEVELOPMENTAL SCI, V13, P798, DOI 10.1111/j.1467-7687.2009.00943.x
   Denison S, 2010, COGNITIVE SCI, V34, P885, DOI 10.1111/j.1551-6709.2010.01111.x
   Dewar K, 2009, PSYCHOL SCI, V20, P252, DOI 10.1111/j.1467-9280.2009.02278.x
   Dewar KM, 2010, PSYCHOL SCI, V21, P1871, DOI 10.1177/0956797610388810
   Diesendruck G, 2003, PSYCHOL SCI, V14, P164, DOI 10.1111/1467-9280.t01-1-01436
   Elman JL., 1996, RETHINKING INNATENES
   Fedyk M., ADV EXPT PHILOS SCI
   Fedyk M, 2018, REV PHILOS PSYCHOL, V9, P343, DOI 10.1007/s13164-017-0372-1
   Feigenson L, 2004, TRENDS COGN SCI, V8, P307, DOI 10.1016/j.tics.2004.05.002
   Feiman R, 2017, LANG LEARN DEV, V13, P430, DOI 10.1080/15475441.2017.1317253
   Feldman J, 2006, P NATL ACAD SCI USA, V103, P18014, DOI 10.1073/pnas.0608811103
   Feldman J, 2012, COGNITION, V123, P61, DOI 10.1016/j.cognition.2011.12.008
   Flavell J., 1963, DEV PSYCHOL JEAN PIA, DOI [10.1037/11449-000, DOI 10.1037/11449-000]
   Fodor J., 1980, LANGUAGE LEARNING DE, P142
   Fodor J., 1975, LANGUAGE THOUGHT
   FODOR JA, 1988, COGNITION, V28, P3, DOI 10.1016/0010-0277(88)90031-5
   Fodor JA., 1983, MODULARITY MIND, DOI [10.7551/mitpress/4737.001.0001, DOI 10.7551/MITPRESS/4737.001.0001]
   Frank MC, 2012, SCIENCE, V336, P998, DOI 10.1126/science.1218633
   Futo J, 2010, COGNITION, V117, P1, DOI 10.1016/j.cognition.2010.06.003
   Gallistel C.R., 1990, ORG LEARNING
   Gelman R., 1983, HDB CHILD PSYCHOL, V3, P167
   Gelman S., 2003, THE ESSENTIAL CHILD, DOI [10.1093/acprof:oso/9780195154061.001.0001, DOI 10.1093/ACPROF:OSO/9780195154061.001.0001]
   Gendler T. S., 2000, THOUGHT EXPT POWERS
   Gendler TS, 1998, BRIT J PHILOS SCI, V49, P397, DOI 10.1093/bjps/49.3.397
   GENTNER D, 1983, COGNITIVE SCI, V7, P155, DOI 10.1016/S0364-0213(83)80009-3
   Gentner D, 2017, TOP COGN SCI, V9, P672, DOI 10.1111/tops.12278
   Gergely G, 2003, TRENDS COGN SCI, V7, P287, DOI 10.1016/S1364-6613(03)00128-1
   Gergely G, 1999, EARLY SOCIAL COGNITION, P101
   Gergely G., 2006, ROOTS HUMAN SOCIALIT, P229
   Gergely G, 2012, ADV CHILD DEV BEHAV, V43, P59, DOI 10.1016/B978-0-12-397919-3.00003-4
   Gerken L, 2011, DEVELOPMENTAL SCI, V14, P972, DOI 10.1111/j.1467-7687.2011.01046.x
   Goodman Nelson, 1955, FACT FICTION FORECAS
   Gopnik A, 2000, CHILD DEV, V71, P1205, DOI 10.1111/1467-8624.00224
   Gopnik A, 2004, PSYCHOL REV, V111, P3, DOI 10.1037/0033-295X.111.1.3
   Gopnik A, 2004, TRENDS COGN SCI, V8, P371, DOI 10.1016/j.tics.2004.06.005
   Gopnik A, 1996, PHILOS SCI, V63, P485, DOI 10.1086/289970
   Gopnik A, 2001, DEV PSYCHOL, V37, P620, DOI 10.1037//0012-1649.37.5.620
   Gopnik A., 1997, WORDS THOUGHTS THEOR
   Gopnik A, 2015, WIRES COGN SCI, V6, P75, DOI 10.1002/wcs.1330
   Gopnik A, 2012, PSYCHOL BULL, V138, P1085, DOI 10.1037/a0028044
   Gordon P, 2004, SCIENCE, V306, P496, DOI 10.1126/science.1094492
   Goupil L, 2016, P NATL ACAD SCI USA, V113, P3492, DOI 10.1073/pnas.1515129113
   Griffiths TL, 2015, TOP COGN SCI, V7, P217, DOI 10.1111/tops.12142
   Griffiths TL, 2012, CURR DIR PSYCHOL SCI, V21, P263, DOI 10.1177/0963721412447619
   Griffiths TL, 2010, TRENDS COGN SCI, V14, P357, DOI 10.1016/j.tics.2010.05.004
   Gruber MJ, 2014, NEURON, V84, P486, DOI 10.1016/j.neuron.2014.08.060
   Gualtieri S, 2018, J EXP CHILD PSYCHOL, V174, P60, DOI 10.1016/j.jecp.2018.05.006
   Gupta A., 1980, J SYMBOLIC LOGIC, V48, P500
   Gureckis TM, 2012, PERSPECT PSYCHOL SCI, V7, P464, DOI 10.1177/1745691612454304
   Gweon H, 2011, SCIENCE, V332, P1524, DOI 10.1126/science.1204493
   Gweon H, 2010, P NATL ACAD SCI USA, V107, P9066, DOI 10.1073/pnas.1003095107
   Harris PL, 2006, CHILD DEV, V77, P505, DOI 10.1111/j.1467-8624.2006.00886.x
   Henderson L, 2010, PHILOS SCI, V77, P172, DOI 10.1086/651319
   Henik A, 2017, CURR DIR PSYCHOL SCI, V26, P45, DOI 10.1177/0963721416671323
   HERMER L, 1994, NATURE, V370, P57, DOI 10.1038/370057a0
   Hermer-Vazquez L, 1999, COGNITIVE PSYCHOL, V39, P3, DOI 10.1006/cogp.1998.0713
   Hermer-Vazquez L, 2001, COGNITION, V79, P263, DOI 10.1016/S0010-0277(00)00120-7
   HIRSCH JE, 1982, PHYS REV A, V25, P519, DOI 10.1103/PhysRevA.25.519
   Holyoak K. J., 2012, OXFORD HDB THINKING, P234, DOI [DOI 10.1093/OXFORDHB/9780199734689.001.0001, 10.1093/oxfordhb/9780199734689.001.0001]
   HOLYOAK KJ, 1989, COGNITIVE SCI, V13, P295, DOI 10.1207/s15516709cog1303_1
   Hood B, 2003, DEV PSYCHOL, V39, P61, DOI 10.1037//0012-1649.39.1.61
   Hood B, 2000, CHILD DEV, V71, P1540, DOI 10.1111/1467-8624.00247
   Hume D., 1999, ENQUIRY HUMAN UNDERS
   Inagaki K, 2004, TRENDS COGN SCI, V8, P356, DOI 10.1016/j.tics.2004.06.004
   Izard V, 2009, P NATL ACAD SCI USA, V106, P10382, DOI 10.1073/pnas.0812142106
   James William, 1981, PRINCIPLES PSYCHOL
   Jara-Ettinger J, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12459
   Johnson SC, 1998, COGNITIVE PSYCHOL, V37, P156, DOI 10.1006/cogp.1998.0695
   Johnson S, 1998, DEVELOPMENTAL SCI, V1, P233, DOI 10.1111/1467-7687.00036
   Jones M, 2011, BEHAV BRAIN SCI, V34, P169, DOI [10.1017/S0140525X10003134, 10.1017/S0140525X11001439]
   KAHNEMAN D, 1992, COGNITIVE PSYCHOL, V24, P175, DOI 10.1016/0010-0285(92)90007-O
   Karmiloff-Smith A., 1990, MODULARITY DEV PERSP
   Keen R, 2003, CURR DIR PSYCHOL SCI, V12, P79, DOI 10.1111/1467-8721.01234
   Keil FC, 2006, ANNU REV PSYCHOL, V57, P227, DOI 10.1146/annurev.psych.57.102904.190100
   KELLMAN PJ, 1983, COGNITIVE PSYCHOL, V15, P483, DOI 10.1016/0010-0285(83)90017-8
   Kemp C, 2008, P NATL ACAD SCI USA, V105, P10687, DOI 10.1073/pnas.0802631105
   Kemp C, 2007, DEVELOPMENTAL SCI, V10, P307, DOI 10.1111/j.1467-7687.2007.00585.x
   Kidd C, 2015, NEURON, V88, P449, DOI 10.1016/j.neuron.2015.09.010
   Kidd C, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036399
   Kirkham NZ, 2002, COGNITION, V83, pB35, DOI 10.1016/S0010-0277(02)00004-5
   Klahr D., 2000, EXPLORING SCI COGNIT
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007
   Knill DC, 1996, PERCEPTION BAYESIAN, DOI [10.1017/CBO9780511984037, DOI 10.1017/CBO9780511984037]
   Koenig MA, 2007, EPISTEME-J INDIV SOC, V4, P264, DOI 10.3366/E1742360007000081
   Kominsky JF, 2017, PSYCHOL SCI, V28, P1649, DOI 10.1177/0956797617719930
   Kovacs AM, 2010, SCIENCE, V330, P1830, DOI 10.1126/science.1190792
   KUHN D, 1989, PSYCHOL REV, V96, P674, DOI 10.1037/0033-295X.96.4.674
   Kushnir T, 2005, PSYCHOL SCI, V16, P678, DOI 10.1111/j.1467-9280.2005.01595.x
   Kushnir T, 2010, PSYCHOL SCI, V21, P1134, DOI 10.1177/0956797610376652
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   LANDAU B, 1988, COGNITIVE DEV, V3, P299, DOI 10.1016/0885-2014(88)90014-7
   Le Corre M, 2007, COGNITION, V105, P395, DOI 10.1016/j.cognition.2006.10.005
   Legare CH, 2012, CHILD DEV, V83, P173, DOI 10.1111/j.1467-8624.2011.01691.x
   Legare CH, 2010, CHILD DEV, V81, P929, DOI 10.1111/j.1467-8624.2010.01443.x
   LESLIE AM, 1987, COGNITION, V25, P265, DOI 10.1016/S0010-0277(87)80006-9
   Leslie AM, 1998, TRENDS COGN SCI, V2, P10, DOI 10.1016/S1364-6613(97)01113-3
   Leslie AM., 1994, MAPPING MIND DOMAIN, P119, DOI DOI 10.1017/CBO9780511752902.006
   Lieder F, 2017, PSYCHOL REV, V124, P762, DOI 10.1037/rev0000075
   Lipton JS, 2003, PSYCHOL SCI, V14, P396, DOI 10.1111/1467-9280.01453
   Liu S, 2017, SCIENCE, V358, P1038, DOI 10.1126/science.aag2132
   Locke John, 1975, ESSAY HUMAN UNDERSTA
   Lombrozo T., 2018, SCI IMAGINATION
   Lombrozo T, 2012, OXFORD HDB THINKING, P260, DOI DOI 10.1093/OXFORDHB/9780199734689.013.0014
   Lombrozo T, 2006, TRENDS COGN SCI, V10, P464, DOI 10.1016/j.tics.2006.08.004
   Lombrozo T, 2016, TRENDS COGN SCI, V20, P748, DOI 10.1016/j.tics.2016.08.001
   Marcovitch S, 2012, COGNITIVE DEV, V27, P323, DOI 10.1016/j.cogdev.2012.07.001
   Marcus GF, 2013, PSYCHOL SCI, V24, P2351, DOI 10.1177/0956797613495418
   Marcus GF, 1999, SCIENCE, V283, P77, DOI 10.1126/science.283.5398.77
   Markant DB, 2016, MIND BRAIN EDUC, V10, P142, DOI 10.1111/mbe.12117
   Markant DB, 2014, J EXP PSYCHOL GEN, V143, P94, DOI 10.1037/a0032108
   MARKMAN AB, 1993, COGNITIVE PSYCHOL, V25, P431, DOI 10.1006/cogp.1993.1011
   Markman E. M., 1989, MIT PRESS SERIES LEA
   Marr D., 1982, VISION
   McClelland JL, 2010, TRENDS COGN SCI, V14, P348, DOI 10.1016/j.tics.2010.06.002
   McCormack T, 2016, J EXP CHILD PSYCHOL, V141, P1, DOI 10.1016/j.jecp.2015.06.017
   McCrink K, 2004, PSYCHOL SCI, V15, P776, DOI 10.1111/j.0956-7976.2004.00755.x
   McCrink K, 2016, J EXP CHILD PSYCHOL, V142, P66, DOI 10.1016/j.jecp.2015.09.015
   McCrink K, 2010, COGNITION, V116, P204, DOI 10.1016/j.cognition.2010.05.003
   Meng Y., 2018, P 40 ANN C COGN SCI, P762
   Michotte A. E., 1946, PERCEPTION CAUSALITE
   Mitroff SR, 2004, PSYCHOL SCI, V15, P420, DOI 10.1111/j.0956-7976.2004.00695.x
   Muentener P, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034061
   Muentener P, 2010, COGNITIVE PSYCHOL, V61, P63, DOI 10.1016/j.cogpsych.2010.02.001
   Munakata Y, 1997, PSYCHOL REV, V104, P686, DOI 10.1037/0033-295X.104.4.686
   Nazzi T, 2001, COGNITION, V80, pB11, DOI 10.1016/S0010-0277(01)00112-3
   Newman GE, 2008, COGNITIVE PSYCHOL, V57, P262, DOI 10.1016/j.cogpsych.2008.02.003
   Nichols S, 2016, MIND LANG, V31, P530, DOI 10.1111/mila.12119
   Onishi KH, 2005, SCIENCE, V308, P255, DOI 10.1126/science.1107621
   Perfors A, 2011, COGNITION, V120, P302, DOI 10.1016/j.cognition.2010.11.015
   Perszyk DR, 2018, ANNU REV PSYCHOL, V69, P231, DOI 10.1146/annurev-psych-122216-011701
   Piaget J., 1954, CONSTRUCTION REALITY, DOI [10.1037/11168-000, DOI 10.1037/11168-000]
   Piantadosi S, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147734
   Piantadosi ST, 2018, INFANCY, V23, P310, DOI 10.1111/infa.12225
   Piantadosi ST, 2016, CURR DIR PSYCHOL SCI, V25, P54, DOI 10.1177/0963721415609581
   Piantadosi ST, 2012, COGNITION, V123, P199, DOI 10.1016/j.cognition.2011.11.005
   PINKER S, 1988, COGNITION, V28, P73, DOI 10.1016/0010-0277(88)90032-7
   Pinker S., 1984, LANGUAGE LEARNABILIT
   Pinker S., 1989, LEARNABILITY COGNITI
   Pyers JE, 2009, PSYCHOL SCI, V20, P805, DOI 10.1111/j.1467-9280.2009.02377.x
   Quine W.V., 1969, ONTOLOGICAL RELATIVI, P69
   Ratliff KR, 2008, COGNITIVE PSYCHOL, V56, P142, DOI 10.1016/j.cogpsych.2007.06.002
   Rhodes M, 2017, COGNITION, V167, P191, DOI 10.1016/j.cognition.2016.08.013
   ROSCH E, 1976, COGNITIVE PSYCHOL, V8, P382, DOI 10.1016/0010-0285(76)90013-X
   Rubio-Fernandez P, 2016, REV PHILOS PSYCHOL, V7, P835, DOI 10.1007/s13164-015-0290-z
   Ruffman T, 2002, CHILD DEV, V73, P734, DOI 10.1111/1467-8624.00435
   Ruggeri A, 2017, DEV PSYCHOL, V53, P1620, DOI 10.1037/dev0000340
   Ruggeri A, 2016, DEV PSYCHOL, V52, P2159, DOI 10.1037/dev0000240
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Sarnecka BW, 2008, COGNITION, V108, P662, DOI 10.1016/j.cognition.2008.05.007
   Sarnecka BW, 2007, COGNITIVE PSYCHOL, V55, P136, DOI 10.1016/j.cogpsych.2006.09.001
   Saxe G. B., 2015, CULTURE COGNITIVE DE, DOI [10.4324/9781315788968, DOI 10.4324/9781315788968]
   Schick B, 2007, CHILD DEV, V78, P376, DOI 10.1111/j.1467-8624.2007.01004.x
   Schlesinger M, 2012, COGNITIVE DEV, V27, P326, DOI 10.1016/j.cogdev.2012.07.002
   Scholl BJ, 1999, COGNITIVE PSYCHOL, V38, P259, DOI 10.1006/cogp.1998.0698
   Scholl BJ, 2001, COGNITION, V80, P159, DOI 10.1016/S0010-0277(00)00157-8
   Schulz L, 2012, TRENDS COGN SCI, V16, P382, DOI 10.1016/j.tics.2012.06.004
   Schulz LE, 2007, DEVELOPMENTAL SCI, V10, P322, DOI 10.1111/j.1467-7687.2007.00587.x
   Setoh P, 2016, P NATL ACAD SCI USA, V113, P13360, DOI 10.1073/pnas.1609203113
   Shafto P, 2012, PERSPECT PSYCHOL SCI, V7, P341, DOI 10.1177/1745691612448481
   SIEGLER RS, 1996, EMERGING MINDS PROCE
   Sim Z., 2017, P 39 ANN C COGN SCI, P1078
   Sim Z. L., 2015, P 374 ANN C COGN SCI, P2194
   Sim ZL, 2017, DEV PSYCHOL, V53, P642, DOI 10.1037/dev0000278
   Singer D, 2006, PLAY LEARNING PLAY M, DOI [10.1093/acprof:oso/9780195304381.001.0001, DOI 10.1093/ACPROF:OSO/9780195304381.001.0001]
   Slaughter V, 2003, COGNITIVE PSYCHOL, V46, P1, DOI 10.1016/S0010-0285(02)00504-2
   Sloutsky VM, 2009, TRENDS COGN SCI, V13, P331, DOI 10.1016/j.tics.2009.05.003
   SMITH C, 1985, COGNITION, V21, P177, DOI 10.1016/0010-0277(85)90025-3
   Smith LB, 2002, PSYCHOL SCI, V13, P13, DOI 10.1111/1467-9280.00403
   Sobel DM, 2004, COGNITIVE SCI, V28, P303, DOI 10.1016/j.cogsci.2003.11.001
   Spaepen E, 2011, P NATL ACAD SCI USA, V108, P3163, DOI 10.1073/pnas.1015975108
   SPELKE E, 1994, COGNITION, V50, P431, DOI 10.1016/0010-0277(94)90039-6
   Spelke E, 2010, COGNITIVE SCI, V34, P863, DOI 10.1111/j.1551-6709.2010.01110.x
   Spelke ES, 2017, LANG LEARN DEV, V13, P147, DOI 10.1080/15475441.2016.1263572
   Spelke ES, 2009, CHILD DEV PERSPECT, V3, P96, DOI 10.1111/j.1750-8606.2009.00085.x
   SPELKE ES, 1992, PSYCHOL REV, V99, P605, DOI 10.1037/0033-295X.99.4.605
   Spelke ES, 2001, COGNITION, V78, P45, DOI 10.1016/S0010-0277(00)00108-6
   SPELKE ES, 1990, COGNITIVE SCI, V14, P29, DOI 10.1016/0364-0213(90)90025-R
   SPELKE ES, 1991, J PIAGET SY, P133
   Stahl AE, 2015, SCIENCE, V348, P91, DOI 10.1126/science.aaa3799
   STRERI A, 1988, COGNITIVE PSYCHOL, V20, P1, DOI 10.1016/0010-0285(88)90022-9
   Surian L, 2010, DEVELOPMENTAL SCI, V13, P143, DOI 10.1111/j.1467-7687.2009.00873.x
   Teglas E, 2007, P NATL ACAD SCI USA, V104, P19156, DOI 10.1073/pnas.0700271104
   Teglas E, 2011, SCIENCE, V332, P1054, DOI 10.1126/science.1196404
   Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788
   Ullman TD, 2012, COGNITIVE DEV, V27, P455, DOI 10.1016/j.cogdev.2012.07.005
   Van de Walle GA, 2000, J COGN DEV, V1, P249, DOI 10.1207/S15327647JCD0103_1
   Virginia Slaughter, 1999, CHILDRENS UNDERSTAND, P71, DOI [10.1017/CBO9780511659881.005, DOI 10.1017/CBO9780511659881.005]
   VOSNIADOU S, 1994, COGNITIVE SCI, V18, P123, DOI 10.1016/0364-0213(94)90022-1
   Vouloumanos A, 2010, CHILD DEV, V81, P517, DOI 10.1111/j.1467-8624.2009.01412.x
   Vredenburgh C, 2016, COGNITIVE SCI, V40, P697, DOI 10.1111/cogs.12245
   Walker CM, 2017, PSYCHON B REV, V24, P1538, DOI 10.3758/s13423-016-1144-0
   Waxman SR, 2009, TRENDS COGN SCI, V13, P258, DOI 10.1016/j.tics.2009.03.006
   Weiss Y, 2002, NAT NEUROSCI, V5, P598, DOI 10.1038/nn858
   Welder AN, 2006, COGNITIVE PSYCHOL, V52, P57, DOI 10.1016/j.cogpsych.2005.05.003
   Wellman H.M., 1990, CHILDS THEORY MIND
   Wellman HM, 2016, INFANCY, V21, P668, DOI 10.1111/infa.12131
   Wellman HM, 2011, CHILD DEV PERSPECT, V5, P33, DOI 10.1111/j.1750-8606.2010.00154.x
   WELLMAN HM, 1992, ANNU REV PSYCHOL, V43, P337, DOI 10.1146/annurev.ps.43.020192.002005
   Wellman HM, 2001, CHILD DEV, V72, P655, DOI 10.1111/1467-8624.00304
   Wellman HM, 2014, MAKING MINDS THEORY, DOI [10.1093/acprof:oso/9780199334919.001.0001, DOI 10.1093/ACPROF:OSO/9780199334919.001.0001]
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WIGGINS D., 1980, SAMENESS SUBSTANCE
   Wilcox T, 1999, COGNITION, V72, P125, DOI 10.1016/S0010-0277(99)00035-9
   Wilcox T, 1998, COGNITIVE PSYCHOL, V37, P97, DOI 10.1006/cogp.1998.0690
   Wilcox T, 1998, DEVELOPMENTAL SCI, V1, P127, DOI 10.1111/1467-7687.00019
   Williams JJ, 2010, COGNITIVE SCI, V34, P776, DOI 10.1111/j.1551-6709.2010.01113.x
   Williams JJ, 2013, J EXP PSYCHOL GEN, V142, P1006, DOI 10.1037/a0030996
   WIMMER H, 1983, COGNITION, V13, P103, DOI 10.1016/0010-0277(83)90004-5
   Wood JN, 2005, DEVELOPMENTAL SCI, V8, P173, DOI 10.1111/j.1467-7687.2005.00404.x
   Woodward AL, 1998, COGNITION, V69, P1, DOI 10.1016/S0010-0277(98)00058-4
   Woodward JF, 2003, MAKING THINGS HAPPEN
   WYNN K, 1992, COGNITIVE PSYCHOL, V24, P220, DOI 10.1016/0010-0285(92)90008-P
   WYNN K, 1990, COGNITION, V36, P155, DOI 10.1016/0010-0277(90)90003-3
   Xu F, 1999, COGNITION, V70, P137, DOI 10.1016/S0010-0277(99)00007-4
   Xu F, 1996, COGNITIVE PSYCHOL, V30, P111, DOI 10.1006/cogp.1996.0005
   Xu F, 2005, PSYCHOL SCI, V16, P372, DOI 10.1111/j.0956-7976.2005.01543.x
   Xu F, 2004, COGNITIVE PSYCHOL, V49, P155, DOI 10.1016/j.cogpsych.2004.01.001
   Xu F, 2003, COGNITION, V89, pB15, DOI 10.1016/S0010-0277(03)00050-7
   Xu F, 2002, COGNITION, V85, P223, DOI 10.1016/S0010-0277(02)00109-9
   Xu F, 1997, MIND LANG, V12, P365, DOI 10.1111/1468-0017.00052
   Xu F, 1999, ACTA PSYCHOL, V102, P113, DOI 10.1016/S0001-6918(99)00029-3
   Xu F, 2000, COGNITION, V74, P285, DOI 10.1016/S0010-0277(99)00076-1
   Xu F, 2000, COGNITION, V74, pB1, DOI 10.1016/S0010-0277(99)00066-9
   Xu F., 2009, ORIGINS OBJECT KNOWL, P263, DOI DOI 10.1093/ACPROF:OSO/9780199216895.003.0011
   Xu F., 2007, INNATE MIND FDN FUTU, V3, P199
   Xu F, 2008, P NATL ACAD SCI USA, V105, P5012, DOI 10.1073/pnas.0704450105
   Xu F, 2007, PSYCHOL REV, V114, P245, DOI 10.1037/0033-295X.114.2.245
   Xu F, 2007, DEVELOPMENTAL SCI, V10, P288, DOI 10.1111/j.1467-7687.2007.00590.x
   Xu F, 2007, BRIT J DEV PSYCHOL, V25, P103, DOI 10.1348/026151005X90704
   Xu F, 2005, J COGN DEV, V6, P307, DOI 10.1207/s15327647jcd0603_1
   Xu F, 2013, CURR DIR PSYCHOL SCI, V22, P28, DOI 10.1177/0963721412469396
   Xu F, 2011, COGNITION, V120, P299, DOI 10.1016/j.cognition.2011.06.008
   Xu F, 2009, COGNITION, V112, P97, DOI 10.1016/j.cognition.2009.04.006
   2012, ADV CHILD DEV BEHAV, V43, P1
NR 293
TC 6
Z9 6
U1 8
U2 38
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0033-295X
EI 1939-1471
J9 PSYCHOL REV
JI Psychol. Rev.
PD NOV
PY 2019
VL 126
IS 6
BP 841
EP 864
DI 10.1037/rev0000153
PG 24
WC Psychology; Psychology, Multidisciplinary
SC Psychology
GA JF3KG
UT WOS:000491284600003
PM 31180701
OA Bronze
DA 2021-02-24
ER

PT J
AU Lorenz, D
   Tizon-Couto, D
AF Lorenz, David
   Tizon-Couto, David
TI Chunking or predicting - frequency information and reduction in the
   perception of multi-word sequences
SO COGNITIVE LINGUISTICS
LA English
DT Article
DE speech perception; phonetic reduction; chunking; frequency information;
   entrenchment
ID PHONOLOGICAL VARIATION; VARIANTS EVIDENCE; RECOGNITION; LANGUAGE;
   PREDICTABILITY; USAGE; CUES; REPRESENTATION; PROBABILITIES; POSITION
AB Frequently used linguistic structures become entrenched in memory; this is often assumed to make their consecutive parts more predictable, as well as fuse them into a single unit (chunking). High frequency moreover leads to a propensity for phonetic reduction. We present a word recognition experiment which tests how frequency information (string frequency, transitional probability) interacts with reduction in speech perception. Detection of the element to is tested in V-to-V-inf sequences in English (e.g., need to V-inf), where to can undergo reduction ("needa"). Results show that reduction impedes recognition, but this can be mitigated by the predictability of the item. Recognition generally benefits from surface frequency, while a modest chunking effect is found in delayed responses to reduced forms of high-frequency items. Transitional probability shows a facilitating effect on reduced but not on full forms. Reduced forms also pose more difficulty when the phonological context obscures the onset of to. We conclude that listeners draw on frequency information in a predictive manner to cope with reduction. High-frequency structures are not inevitably perceived as chunks, but depend on cues in the phonetic form - reduction leads to perceptual prominence of the whole over the parts and thus promotes a holistic access.
C1 [Lorenz, David] Univ Rostock, Inst Anglist Amerikanist, Rostock, Germany.
   [Tizon-Couto, David] Univ Vigo, Dept English French & German, Vigo, Spain.
RP Lorenz, D (corresponding author), Univ Rostock, Inst Anglist Amerikanist, Rostock, Germany.
EM david.lorenz2@uni-rostock.de; davidtizon@uvigo.es
RI Tizon-Couto, David/AAC-6307-2021
OI Tizon-Couto, David/0000-0003-0788-7954; Lorenz,
   David/0000-0002-7451-099X
FU Spanish Ministry of Economy and Competitiveness; European Regional
   Development FundEuropean Commission [FFI2016-77018-P, IJCI-2015-25843];
   Xunta de GaliciaXunta de GaliciaEuropean Commission [ED431C 2017/50];
   Wissenschaftliche Gesellschaft Freiburg
FX We are grateful to the Spanish Ministry of Economy and Competitiveness
   and the European Regional Development Fund (grant no. FFI2016-77018-P
   and grant no. IJCI-2015-25843) and Xunta de Galicia (grant no. ED431C
   2017/50) for generous financial support; and to Wissenschaftliche
   Gesellschaft Freiburg for a grant for participant compensations.
CR Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   Arnon I, 2013, LANG SPEECH, V56, P349, DOI 10.1177/0023830913484891
   Arnon I, 2010, J MEM LANG, V62, P67, DOI 10.1016/j.jml.2009.09.005
   Astheimer LB, 2011, NEUROPSYCHOLOGIA, V49, P3512, DOI 10.1016/j.neuropsychologia.2011.08.014
   Baayen H, 2017, J MEM LANG, V94, P206, DOI 10.1016/j.jml.2016.11.006
   Baayen RH, 2010, INT J PSYCHOL RES, V3, P12
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Barth D, 2017, CORPUS LINGUIST LING, V13, P203, DOI 10.1515/cllt-2014-0022
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beckner C, 2009, LANG LEARN, V59, P1
   Bell A, 2003, J ACOUST SOC AM, V113, P1001, DOI 10.1121/1.1534836
   Bell A, 2009, J MEM LANG, V60, P92, DOI 10.1016/j.jml.2008.06.003
   Blumenthal-Drame Alice, 2018, ENTRENCHMENT PSYCHOL, P129
   Blumenthal-Drame Alice, 2012, ENTRENCHMENT USAGE B
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Brand S, 2018, Q J EXP PSYCHOL, V71, P1240, DOI 10.1080/17470218.2017.1313282
   Breheny P, 2017, R J, V9, P56, DOI 10.32614/RJ-2017-046
   Brown M., 2012, P 34 ANN C COGN SCI, P1374
   Burki A, 2012, Q J EXP PSYCHOL, V65, P796, DOI 10.1080/17470218.2011.634915
   Burki A, 2011, J MEM LANG, V64, P424, DOI 10.1016/j.jml.2011.01.002
   Burki A, 2018, LANG COGN NEUROSCI, V33, P494, DOI 10.1080/23273798.2017.1388412
   Bushong Wednesday, 2017, P ANN C COGN SCI SOC, P186
   Bybee J, 2006, LANGUAGE, V82, P711, DOI 10.1353/lan.2006.0186
   Bybee Joan, 2002, STUDIES 2 LANGUAGE A, V24, P215, DOI DOI 10.1017/S0272263102002061
   Caldwell-Harris Catherine L, 2012, FREQUENCY EFFECTS LA, P165
   Connine CM, 2004, PSYCHON B REV, V11, P1084, DOI 10.3758/BF03196741
   CONNINE CM, 1993, J MEM LANG, V32, P193, DOI 10.1006/jmla.1993.1011
   Connine CM, 2008, PERCEPT PSYCHOPHYS, V70, P403, DOI 10.3758/PP.70.3.403
   Connine CM, 2006, LINGUIST REV, V23, P235, DOI 10.1515/TLR.2006.009
   Davies M., 2008, CORPUS CONT AM ENGLI
   Diessel H, 2007, NEW IDEAS PSYCHOL, V25, P108, DOI 10.1016/j.newideapsych.2007.02.002
   Divjak D, 2015, HANDB SPRACH KOMMUN, V39, P53
   Ellis N., 2009, EXPLORING LEXIS GRAM, P89, DOI DOI 10.1075/SCL.35.07ELL
   Ellis N. C, 2002, STUDIES 2 LANGUAGE A, V24, P143, DOI DOI 10.1017/S0272263102002024
   Ernestus M, 2002, BRAIN LANG, V81, P162, DOI 10.1006/brln.2001.2514
   Ernestus Mirjam, 2007, P 16 INT C PHON SCI, P773
   Fernandes T, 2007, PERCEPT PSYCHOPHYS, V69, P856, DOI 10.3758/BF03193922
   Franco A, 2012, ADV COGN PSYCHOL, V8, P144, DOI [10.5709/acp-0111-3, 10.2478/v10053-008-0111-3]
   Frank Stefan, 2017, LANG COGN NEUROSCI, V32, P1
   Gahl S, 2004, LANGUAGE, V80, P748, DOI 10.1353/lan.2004.0185
   Gradoville M, 2017, LINGUA, V199, P94, DOI 10.1016/j.lingua.2017.07.013
   Gregory M. L., 1999, CHICAGO LINGUISTICS, V35, P151
   Hall KC, 2018, LINGUIST VANGUARD, V4, DOI 10.1515/lingvan-2017-0027
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223
   Jurafsky D., 2000, FREQUENCY EMERGENCE, P229, DOI DOI 10.1075/TSL.45.13JUR
   Kampstra P, 2008, J STAT SOFTW, V28, P1, DOI DOI 10.18637/JSS.V028.C01
   KAPATSINSKI V, 2009, FORMULAIC LANGUAGE, V2, P499, DOI DOI 10.1075/TSL.83.14KAP
   Krause F, 2014, BEHAV RES METHODS, V46, P416, DOI 10.3758/s13428-013-0390-6
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299
   Langacker Ronald, 2000, USAGE BASED MODELS L, P1
   Langacker Ronald W., 1987, FDN COGNITIVE GRAMMA, V1
   LINDBLOM B, 1990, NATO ADV SCI I D-BEH, V55, P403
   London K., 2009, MODERN REGRESSION TE
   Lorenz D., 2017, CORPUS LINGUIST LING, DOI [10.1515/cllt-2015-0067, DOI 10.1515/CLLT-2015-0067]
   Lorenz David, 2013, NIHIN STUDIES
   MARSLENWILSON W, 1980, COGNITION, V8, P1, DOI 10.1016/0010-0277(80)90015-3
   Mathot S, 2012, BEHAV RES METHODS, V44, P314, DOI 10.3758/s13428-011-0168-7
   Mattys SL, 2005, J EXP PSYCHOL GEN, V134, P477, DOI 10.1037/0096-3445.134.4.477
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   McDonald SA, 2003, PSYCHOL SCI, V14, P648, DOI 10.1046/j.0956-7976.2003.psci_1480.x
   McQueen J. M., 2003, PHONETICS PHONOLOGY, P39, DOI DOI 10.1515/9783110895094.39
   Mitterer H, 2013, J EXP PSYCHOL LEARN, V39, P977, DOI 10.1037/a0029196
   Patterson D, 2003, PHONETICA, V60, P47, DOI 10.1159/000070454
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002
   Pitt MA, 2011, J PHONETICS, V39, P304, DOI 10.1016/j.wocn.2010.07.004
   Pitt MA, 2009, J EXP PSYCHOL HUMAN, V35, P896, DOI 10.1037/a0013160
   R Core Team, 2017, R LANG ENV STAT COMP
   Racine I, 2014, LANG COGN NEUROSCI, V29, P893, DOI 10.1080/01690965.2013.832784
   Ranbom LJ, 2007, J MEM LANG, V57, P273, DOI 10.1016/j.jml.2007.04.001
   Seyfarth S, 2014, COGNITION, V133, P140, DOI 10.1016/j.cognition.2014.06.013
   Simpson Gavin L, 2018, SCHOENBERG GGPLOT BA
   SIMPSON GB, 1989, J EXP PSYCHOL LEARN, V15, P88
   Sosa AV, 2002, BRAIN LANG, V83, P227, DOI 10.1016/S0093-934X(02)00032-9
   Tizon-Couto D, 2018, CORPORA, V13, P371, DOI 10.3366/cor.2018.0154
   Tremblay A, 2011, MENT LEX, V6, P302, DOI 10.1075/ml.6.2.04tre
   Tucker BV, 2011, J PHONETICS, V39, P312, DOI 10.1016/j.wocn.2010.12.001
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443
   van de Ven M, 2018, LANG SPEECH, V61, P358, DOI 10.1177/0023830917727774
   van Rij J., 2017, ITSADUG INTERPRETING
   Warner N, 2011, J ACOUST SOC AM, V130, P1606, DOI 10.1121/1.3621306
   Wickham H, 2016, GGPLOT2 ELEGANT GRAP
   Wood S., 2006, GEN ADDITIVE MODELS
   Wood SN, 2011, J R STAT SOC B, V73, P3, DOI 10.1111/j.1467-9868.2010.00749.x
   Zuur Alain F., 2009, P1
NR 84
TC 0
Z9 0
U1 2
U2 7
PU DE GRUYTER MOUTON
PI BERLIN
PA GENTHINER STRASSE 13, 10785 BERLIN, GERMANY
SN 0936-5907
EI 1613-3641
J9 COGN LINGUIST
JI Cogn. Linguist
PD NOV
PY 2019
VL 30
IS 4
BP 751
EP 784
DI 10.1515/cog-2017-0138
PG 34
WC Linguistics; Language & Linguistics
SC Linguistics
GA JF1JQ
UT WOS:000491143800005
OA Bronze
DA 2021-02-24
ER

PT J
AU de Medeiros-Santana, MNL
   Perry, JL
   Yaedu, RYF
   Trindade-Suedam, IK
   Yamashita, RP
AF Leite de Medeiros-Santana, Maria Natalia
   Perry, Jamie L.
   Faria Yaedu, Renato Yassutaka
   Trindade-Suedam, Ivy Kiemle
   Yamashita, Renata Paciello
TI Predictors of Velopharyngeal Dysfunction in Individuals With Cleft
   Palate Following Surgical Maxillary Advancement: Clinical and
   Tomographic Assessments
SO CLEFT PALATE-CRANIOFACIAL JOURNAL
LA English
DT Article
DE cleft palate; velopharyngeal insufficiency; speech perception;
   orthognathic surgery
ID FORT-I OSTEOTOMY; ORTHOGNATHIC SURGERY; LIP; SPEECH; INSUFFICIENCY;
   DISTRACTION; MORPHOLOGY; RESONANCE; OUTCOMES; CLOSURE
AB Objective: To investigate whether morphofunctional velopharyngeal aspects may be considered predictors of appearance or worsening of hypernasality in patients with cleft palate after surgical maxillary advancement (MA). Design: Prospective. Setting: National referral center for cleft lip and palate rehabilitation. Participants: Fifty-two patients with repaired cleft palate, skeletal class III malocclusion, and normal speech resonance completed speech audio recordings and cone-beam computed tomography examination before (T1) and, on average, 14 months after (T2) MA. Interventions: Hypernasality was rated by 3 experienced speech-language pathologists using a 4-point scale and morphofunctional aspects on a 3-point scale. Cone-beam computed tomography image measurements were performed using Amira and Dolphin 3D software. For each velopharyngeal morphofunctional aspect analyzed, patients were compared according to the absence (G1) and presence (G2) of postoperative hypernasality. Main Outcome Measures: Comparison of hypernasality scores between T1 and T2 and association between hypernasality and each velopharyngeal morphofunctional aspect. Results: Significant difference was observed between T1 and T2 for hypernasality ( P = .031) and between G1 and G2 ( P = .015) for velar mobility, with significant association between this variable and hypernasality on T2 (P = .041). Conclusions: Levator veli palatini mobility influenced the appearance of hypernasality after MA.
C1 [Leite de Medeiros-Santana, Maria Natalia; Yamashita, Renata Paciello] Univ Sao Paulo, Hosp Rehabil Craniofacial Anomalies, Lab Physiol, Bauru, SP, Brazil.
   [Perry, Jamie L.] East Carolina Univ, Coll Allied Hlth Sci, Dept Commun Sci & Disorders, Greenville, NC 27858 USA.
   [Faria Yaedu, Renato Yassutaka] Univ Sao Paulo, Hosp Rehabil Craniofacial Anomalies, Bauru Sch Dent, Dept Oral Surg, Bauru, SP, Brazil.
   [Trindade-Suedam, Ivy Kiemle] Univ Sao Paulo, Hosp Rehabil Craniofacial Anomalies, Bauru Sch Dent & Lab Physiol, Dept Biol Sci, Bauru, SP, Brazil.
RP de Medeiros-Santana, MNL (corresponding author), Univ Sao Paulo, Hosp Reabilitacao Anomalias Craniofaciais, Lab Fisiol, Rua Silvio March 3-20, BR-17012900 Bauru, SP, Brazil.
EM natalialeite@alumni.usp.br
RI Trindade-Suedam, Ivy K/F-3034-2012; de Medeiros-Santana, Maria Natalia
   Leite/F-1839-2013; Yamashita, Renata P/K-3942-2012
OI de Medeiros-Santana, Maria Natalia Leite/0000-0002-2728-6331; Yamashita,
   Renata P/0000-0001-7098-9502; Trindade-Suedam, Ivy/0000-0001-8582-0072
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior
   (CAPES-Ministry of Education of Brazil)CAPES [88881.131548/2016-01]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This study
   was supported by Coordenacao de Aperfeicoamento de Pessoal de Nivel
   Superior (CAPES-Ministry of Education of Brazil), process number
   88881.131548/2016-01.
CR Broome M, 2010, J CRANIOFAC SURG, V21, P1615, DOI 10.1097/SCS.0b013e3181ef2eed
   Chanchareonsook N, 2007, CLEFT PALATE-CRAN J, V44, P23, DOI 10.1597/05-003
   Chua HDP, 2010, INT J ORAL MAX SURG, V39, P633, DOI 10.1016/j.ijom.2010.03.011
   Daskalogiannakis J, 2009, CLEFT PALATE-CRAN J, V46, P498, DOI 10.1597/08-176.1
   Freitas JAD, 2012, J APPL ORAL SCI, V20, P673, DOI 10.1590/S1678-77572012000600014
   Faria AC, 2013, INT J ORAL MAX SURG, V42, P579, DOI 10.1016/j.ijom.2012.10.002
   Good PM, 2007, CLEFT PALATE-CRAN J, V44, P396, DOI 10.1597/06-075.1
   Heliovaara A, 2002, ACTA ODONTOL SCAND, V60, P141, DOI 10.1080/000163502753740142
   Janulewicz J, 2004, J ORAL MAXIL SURG, V62, P308, DOI 10.1016/j.joms.2003.08.014
   Karabekmez FE, 2015, CLEFT PALATE-CRAN J, V52, P311, DOI 10.1597/13-095
   Kim SK, 2012, ARCH PLAST SURG-APS, V39, P198, DOI 10.5999/aps.2012.39.3.198
   Kotlarek KJ, 2017, J CRANIOFAC SURG, V28, P833, DOI 10.1097/SCS.0000000000003373
   Kudo K, 2014, J ORAL MAX SURG MED, V26, P22, DOI 10.1016/j.ajoms.2013.07.006
   Kummer A, 2014, CLEFT PALATE-CRAN J, P182
   KUMMER AW, 1989, CLEFT PALATE J, V26, P193
   Lu Y, 2006, ANN PLAS SURG, V57, P50, DOI 10.1097/01.sap.0000208937.05684.38
   McComb RW, 2011, J ORAL MAXIL SURG, V69, P2226, DOI 10.1016/j.joms.2011.02.142
   Medeiros MNL, 2017, 5 S INT FISS OR AN R
   Nakamura N, 2003, CLEFT PALATE-CRAN J, V40, P46, DOI 10.1597/1545-1569(2003)040<0046:AACAOV>2.0.CO;2
   Nohara K, 2006, CLEFT PALATE-CRAN J, V43, P174, DOI 10.1597/04-170.1
   Pereira V, 2012, EFFECT MAXILLARY ADV
   Pereira V, 2013, CLEFT PALATE-CRAN J, V50, P25, DOI 10.1597/11-116
   Pereira VJ, 2013, INT J LANG COMM DIS, V48, P640, DOI 10.1111/1460-6984.12036
   Perry JL, 2016, CLEFT PALATE-CRAN J, V53, pE1, DOI 10.1597/14-015
   Perry JL, 2009, J CRANIOFAC SURG, V20, P1739, DOI 10.1097/SCS.0b013e3181b5cf46
   Phillips JH, 2005, PLAST RECONSTR SURG, V115, P681, DOI 10.1097/01.PRS.0000152433.29134.79
   Rocha DL, 2010, TRATADO FONOAUDIOLOG, P145
   da Silva AFR, 2017, CLEFT PALATE-CRAN J, V54, P517, DOI 10.1597/15-207
   Satoh K, 2005, INT J ORAL MAX SURG, V34, P122, DOI 10.1016/j.ijom.2004.05.002
   Satoh K, 2002, BRIT J ORAL MAX SURG, V40, P105, DOI 10.1054/bjom.2001.0749
   Scartezini GR, 2007, REV ODONTOL UNESP, V36, P267
   SCHENDEL SA, 1979, J MAXILLOFAC SURG, V7, P116, DOI 10.1016/S0301-0503(79)80023-5
   Smedberg E, 2014, CLEFT PALATE-CRAN J, V51, P334, DOI 10.1597/12-304
   SUBTELNY J D, 1957, Plast Reconstr Surg (1946), V19, P49, DOI 10.1097/00006534-195701000-00007
   Tarawneh AMA, 2018, J DENT DENT MED, V1, P1
   Trindade IEK, 2003, CLEFT PALATE-CRAN J, V40, P54, DOI 10.1597/1545-1569(2003)040<0054:EOOSOS>2.0.CO;2
   WITZEL MA, 1988, J ORAL MAXIL SURG, V46, pM32
   Wu Y, 2015, CLEFT PALATE-CRAN J, V52, P711, DOI 10.1597/14-146.1
   Yamashita Renata Paciello, 2012, Rev. CEFAC, V14, P603, DOI 10.1590/s1516-18462011005000040
NR 39
TC 2
Z9 2
U1 0
U2 5
PU ALLIANCE COMMUNICATIONS GROUP DIVISION ALLEN PRESS
PI LAWRENCE
PA 810 EAST 10TH STREET, LAWRENCE, KS 66044 USA
SN 1055-6656
EI 1545-1569
J9 CLEFT PALATE-CRAN J
JI Cleft Palate-Craniofac. J.
PD NOV
PY 2019
VL 56
IS 10
BP 1314
EP 1321
DI 10.1177/1055665619852562
PG 8
WC Dentistry, Oral Surgery & Medicine; Surgery
SC Dentistry, Oral Surgery & Medicine; Surgery
GA JE3BA
UT WOS:000490567600006
PM 31213072
DA 2021-02-24
ER

PT J
AU Menon, A
   Krishnan, S
   Shetty, V
AF Menon, Akash
   Krishnan, Shalini
   Shetty, Vikram
TI Development and Application of a Novel Patient-Reported Outcome Measure
   on QoL and Facial Aesthetics-A Study on South Indian Population
SO CLEFT PALATE-CRANIOFACIAL JOURNAL
LA English
DT Article
DE counseling; epidemiology; aesthetics; psychological assessment;
   psychosocial adjustment; quality of life; psychiatric conditions; speech
   disorders; speech perception
ID QUALITY-OF-LIFE; LIP AND/OR PALATE; ORTHOGNATHIC SURGERY PATIENTS;
   COMPLETE CLEFT-LIP; PSYCHOSOCIAL ADJUSTMENT; SELF-PERCEPTION;
   PSYCHOLOGICAL ADJUSTMENT; ADULTS BORN; ADOLESCENTS; SATISFACTION
AB Background: The goal of cleft therapy has progressed from simply correcting the deformity to uplifting the patient's quality of life (QoL). At the end of comprehensive treatment, a patient with cleft lip and palate (CLP) should report with satisfactory QoL scores in all domains such as aesthetics, speech, function, and psychology. Objective: To develop and validate a novel, disease-specific questionnaire designed in 2 regional languages to assess the QoL in young adult patients with CLP of South India following comprehensive treatment. Methods: A preliminary questionnaire was created from the literature review and patient interviews, considering regional sociodemographic conditions. The questionnaire was then validated by subject experts and pilot tested. The resultant tool was implemented on patients at treatment completion. Data collected were assimilated for statistical evaluation. Results: The questionnaire was deemed reliable (Cronbach alpha = .854 and test-retest reliability, kappa = 0.8) and was administered to 100 young adult patients with CLP (mean age: 22 years). A large majority (83%) of the population felt more confident about themselves, with positive responses to familial relations, social interaction, and self-image. About 25% of the patients faced problems with speech regularly, while a majority of patients did not face problems with chewing and swallowing. Nearly 60% of patients were fully satisfied with their facial appearance, while others had concerns about their lip and nose aesthetics. The results were descriptive of the local population. Conclusions: Most patients achieved satisfactory QoL in all domains following comprehensive multispeciality therapy. The novel tool is simple, reliable, and can be adapted to homogenous population groups.
C1 [Menon, Akash; Krishnan, Shalini; Shetty, Vikram] AB Shetty Mem Inst Dent Sci, Dept Oral & Maxillofacial Surg, Mangalore 575017, India.
   [Menon, Akash; Shetty, Vikram] Justice KS Hegde Charitable Hosp, Nitte Meenakshi Inst Craniofacial Surg, Mangalore, India.
RP Krishnan, S (corresponding author), AB Shetty Mem Inst Dent Sci, Dept Oral & Maxillofacial Surg, Mangalore 575017, India.
EM dr_shaluk@rediffmail.com
RI Shetty, Vikram/AAW-9729-2020; KRISHNAN, SHALINI/AAY-2236-2020
OI Shetty, Vikram/0000-0003-0685-1669; KRISHNAN,
   SHALINI/0000-0001-8629-8183; Menon, Akash/0000-0003-1116-6244
CR Anderson SL, 2008, J PERS SOC PSYCHOL, V95, P352, DOI 10.1037/0022-3514.95.2.352
   Babuccu O, 2003, AESTHET PLAST SURG, V27, P44, DOI 10.1007/s00266-002-1517-9
   Bennett M E, 1999, Int J Adult Orthodon Orthognath Surg, V14, P65
   Berger ZE, 2011, CLEFT PALATE-CRAN J, V48, P82, DOI 10.1597/08-094
   Berger ZE, 2009, CLEFT PALATE-CRAN J, V46, P435, DOI 10.1597/08-093.1
   BRODER HL, 1994, CLEFT PALATE-CRAN J, V31, P429, DOI 10.1597/1545-1569(1994)031<0429:EOVAIO>2.3.CO;2
   CANADY JW, 1995, CLEFT PALATE-CRAN J, V32, P120, DOI 10.1597/1545-1569(1995)032<0120:EEOPSO>2.3.CO;2
   Canfield MA, 2006, BIRTH DEFECTS RES A, V76, P747, DOI 10.1002/bdra.20294
   Cano SJ, 2009, PLAST RECONSTR SURG, V123, p98E, DOI 10.1097/PRS.0b013e31819565c1
   Eckstein DA, 2011, PLAST RECONSTR SURG, V128, p518E, DOI 10.1097/PRS.0b013e31822b6a67
   Edwards TC, 2005, CLEFT PALATE-CRAN J, V42, P19, DOI 10.1597/03-097.2.1
   Gkantidis N, 2013, J CRANIO MAXILL SURG, V41, pE105, DOI 10.1016/j.jcms.2012.11.034
   Harris DL, 2001, BRIT J PLAST SURG, V54, P223, DOI 10.1054/bjps.2001.3550
   Hasanzadeh N, 2014, J CRANIOFAC SURG, V25, P441, DOI 10.1097/SCS.0000000000000483
   HELLER A, 1981, CLIN PEDIATR, V20, P459, DOI 10.1177/000992288102000706
   Hunt O, 2005, EUR J ORTHODONT, V27, P274, DOI 10.1093/ejo/cji004
   JACOBSON A, 1984, ANGLE ORTHOD, V54, P18
   JACOBSON BN, 1986, AM J ORTHOD DENTOFAC, V90, P63, DOI 10.1016/0889-5406(86)90028-4
   KAPPSIMON KA, 1992, CLEFT PALATE-CRAN J, V29, P352, DOI 10.1597/1545-1569(1992)029<0352:SPSSAA>2.3.CO;2
   Khattak ZG, 2012, J CRANIO MAXILL SURG, V40, P243, DOI 10.1016/j.jcms.2011.04.004
   King N M, 1994, Quintessence Int, V25, P731
   Klassen AF, 2018, CAN MED ASSOC J, V190, pE455, DOI 10.1503/cmaj.170289
   Klassen AF, 2012, J PLAST RECONSTR AES, V65, P547, DOI 10.1016/j.bjps.2011.11.004
   Marcusson A, 2001, CLEFT PALATE-CRAN J, V38, P379, DOI 10.1597/1545-1569(2001)038<0379:QOLIAW>2.0.CO;2
   Mishra D, 2003, Indian J Pediatr, V70, P273, DOI 10.1007/BF02725598
   Mouradian W, 2006, SURG SHAPING CHILDRE, P141
   NOAR JH, 1991, CLEFT PALATE-CRAN J, V28, P279, DOI 10.1597/1545-1569(1991)028<0279:QSOAAC>2.3.CO;2
   Noor SNFM, 2007, CLEFT PALATE-CRAN J, V44, P292, DOI 10.1597/05-151
   Patrick DL, 2007, CLEFT PALATE-CRAN J, V44, P538, DOI 10.1597/06-072.1
   Pitak-Arnnop P, 2011, J CRANIO MAXILL SURG, V39, P319, DOI 10.1016/j.jcms.2010.07.007
   Ramstad T, 1995, SCAND J PLAST RECONS, V29, P329, DOI 10.3109/02844319509008968
   RICHMAN LC, 1980, J CLIN PSYCHOL, V36, P668, DOI 10.1002/1097-4679(198007)36:3<668::AID-JCLP2270360310>3.0.CO;2-L
   Riff KWYW, 2018, CLEFT PALATE-CRAN J, V55, P442, DOI 10.1177/1055665617732854
   Rustemeyer J, 2012, J CRANIO MAXILL SURG, V40, P400, DOI 10.1016/j.jcms.2011.07.009
   Sinko K, 2005, CLEFT PALATE-CRAN J, V42, P355, DOI 10.1597/03-142.1
   Speltz ML, 1997, CHILD DEV, V68, P12
   Springer IN, 2012, J CRANIO MAXILL SURG, V40, P773, DOI 10.1016/j.jcms.2012.02.007
   Stock NM, 2016, PSYCHOL HEALTH, V31, P777, DOI 10.1080/08870446.2016.1143944
   Stock NM, 2015, CLEFT PALATE-CRAN J, V52, P543, DOI 10.1597/14-178
   STRICKER G, 1979, AM J ORTHOD DENTOFAC, V76, P410, DOI 10.1016/0002-9416(79)90226-4
   Thomas PT, 1997, CLEFT PALATE-CRAN J, V34, P226, DOI 10.1597/1545-1569(1997)034<0226:SWFAAS>2.3.CO;2
   TOBIASEN JM, 1987, CLEFT PALATE J, V24, P323
   Topolski TD, 2005, CLEFT PALATE-CRAN J, V42, P25
   Turner SR, 1997, BRIT J PLAST SURG, V50, P1, DOI 10.1016/S0007-1226(97)91275-3
   Wehby GL, 2010, ORAL DIS, V16, P3, DOI 10.1111/j.1601-0825.2009.01588.x
   Yazdy MM, 2007, CLEFT PALATE-CRAN J, V44, P351, DOI 10.1597/06-233.1
NR 46
TC 0
Z9 0
U1 0
U2 5
PU ALLIANCE COMMUNICATIONS GROUP DIVISION ALLEN PRESS
PI LAWRENCE
PA 810 EAST 10TH STREET, LAWRENCE, KS 66044 USA
SN 1055-6656
EI 1545-1569
J9 CLEFT PALATE-CRAN J
JI Cleft Palate-Craniofac. J.
PD NOV
PY 2019
VL 56
IS 10
BP 1340
EP 1352
DI 10.1177/1055665619852571
PG 13
WC Dentistry, Oral Surgery & Medicine; Surgery
SC Dentistry, Oral Surgery & Medicine; Surgery
GA JE3BA
UT WOS:000490567600009
PM 31146577
DA 2021-02-24
ER

PT J
AU Luthra, S
   Fuhrmeister, P
   Molfese, PJ
   Guediche, S
   Blumstein, SE
   Myers, EB
AF Luthra, Sahil
   Fuhrmeister, Pamela
   Molfese, Peter J.
   Guediche, Sara
   Blumstein, Sheila E.
   Myers, Emily B.
TI Brain-behavior relationships in incidental learning of non-native
   phonetic categories
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Non-native phonetic perception; Implicit learning; Inferior frontal
   gyros
ID SPEECH; REGIONS; SOUNDS; FMRI; IDENTIFICATION; SENSITIVITY; ACQUISITION;
   COMPETITION; PERCEPTION; EXPOSURE
AB Research has implicated the left inferior frontal gyrus (LIFG) in mapping acoustic-phonetic input to sound category representations, both in native speech perception and non-native phonetic category learning. At issue is whether this sensitivity reflects access to phonetic category information per se or to explicit category labels, the latter often being required by experimental procedures. The current study employed an incidental learning paradigm designed to increase sensitivity to a difficult non-native phonetic contrast without inducing explicit awareness of the categorical nature of the stimuli. Functional MRI scans revealed frontal sensitivity to phonetic category structure both before and after learning. Additionally, individuals who succeeded most on the learning task showed the largest increases in frontal recruitment after learning. Overall, results suggest that processing novel phonetic category information entails a reliance on frontal brain regions, even in the absence of explicit category labels.
C1 [Luthra, Sahil; Myers, Emily B.] Univ Connecticut, Dept Psychol Sci, Storrs, CT 06269 USA.
   [Fuhrmeister, Pamela; Myers, Emily B.] Univ Connecticut, Dept Speech Language & Hearing Sci, Storrs, CT USA.
   [Molfese, Peter J.] NIH, Bldg 10, Bethesda, MD 20892 USA.
   [Guediche, Sara] Basque Ctr Cognit Brain & Language, San Sebastian, Spain.
   [Blumstein, Sheila E.] Brown Univ, Dept Cognit Linguist & Psychol Sci, Providence, RI 02912 USA.
   [Myers, Emily B.] Haskins Labs Inc, New Haven, CT USA.
RP Luthra, S (corresponding author), Univ Connecticut, Dept Psychol Sci, Storrs, CT 06269 USA.
EM sahil.luthra@uconn.edu; pamela.fuhrmeister@uconn.edu;
   peter.molfese@nih.gov; s.guediche@bcbl.eu; sheila_blumstein@brown.edu;
   emily.myers@uconn.edu
RI Guediche, Sara/B-3895-2017
OI Guediche, Sara/0000-0002-8331-1378; Luthra, Sahil/0000-0002-3517-2609;
   /0000-0002-9475-764X
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R01 DC013064]; NIH NIDCDUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01 DC006220]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC013064,
   R01DC013064] Funding Source: NIH RePORTER
FX This research was supported by NIH grant R01 DC013064 to EBM and NIH
   NIDCD Grant R01 DC006220 to SEB. The authors thank F. Sayako Earle for
   assistance with stimulus development; members of the Language and Brain
   lab for help with data collection and their feedback throughout the
   project; Elisa Medeiros for assistance with collection of fMRI data;
   Paul Taylor for assistance with neuroimaging analyses; and attendees of
   the 2016 Meeting of the Psychonomic Society and the 2017 Meeting of the
   Society for Neurobiology of Language for helpful feedback on this
   project. We also extend thanks to two anonymous reviewers for helpful
   feedback on a previous version of this manuscript.
CR Ahissar M, 2009, PHILOS T R SOC B, V364, P285, DOI 10.1098/rstb.2008.0253
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   BEST CT, 2007, LANGUAGE EXPERIENCE, V1334, P1
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   BLUMSTEIN SE, 1977, NEUROPSYCHOLOGIA, V15, P19, DOI 10.1016/0028-3932(77)90111-7
   Boersma P., 2018, PRAAT DOING PHONETIC
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Callan DE, 2004, NEUROIMAGE, V22, P1182, DOI 10.1016/j.neuroimage.2004.03.006
   Chandrasekaran B, 2014, PSYCHON B REV, V21, P488, DOI 10.3758/s13423-013-0501-5
   Chen G, 2014, NEUROIMAGE, V99, P571, DOI 10.1016/j.neuroimage.2014.06.027
   Chevillet MA, 2013, J NEUROSCI, V33, P5208, DOI 10.1523/JNEUROSCI.1870-12.2013
   Cox Robert W, 2017, Proc Natl Acad Sci U S A, V114, pE3370, DOI 10.1073/pnas.1614961114
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   Desai R, 2008, J COGNITIVE NEUROSCI, V20, P1174, DOI 10.1162/jocn.2008.20081
   Earle FS, 2015, J ACOUST SOC AM, V137, pEL91, DOI 10.1121/1.4903918
   Edmister WB, 1999, HUM BRAIN MAPP, V7, P89, DOI 10.1002/(SICI)1097-0193(1999)7:2<89::AID-HBM2>3.3.CO;2-E
   Eklund A, 2016, P NATL ACAD SCI USA, V113, P7900, DOI 10.1073/pnas.1602413113
   Fischl B, 2012, NEUROIMAGE, V62, P774, DOI 10.1016/j.neuroimage.2012.01.021
   Francis AL, 2002, J EXP PSYCHOL HUMAN, V28, P349, DOI 10.1037//0096-1523.28.2.349
   Fuhrmeister P, 2017, J ACOUST SOC AM, V142, pEL448, DOI 10.1121/1.5009688
   Gabay Y, 2015, CORTEX, V73, P131, DOI 10.1016/j.cortex.2015.08.008
   Golestani N, 2004, NEUROIMAGE, V21, P494, DOI 10.1016/j.neuroimage.2003.09.071
   Golestani N, 2009, BRAIN LANG, V109, P55, DOI 10.1016/j.bandl.2008.01.005
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Lee YS, 2012, J NEUROSCI, V32, P3942, DOI 10.1523/JNEUROSCI.3814-11.2012
   Leech R, 2009, J NEUROSCI, V29, P5234, DOI 10.1523/JNEUROSCI.5758-08.2009
   Liebenthal E, 2005, CEREB CORTEX, V15, P1621, DOI 10.1093/cercor/bhi040
   Lim SJ, 2019, P NATL ACAD SCI USA, V116, P4671, DOI 10.1073/pnas.1811992116
   Lim SJ, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00230
   Lim SJ, 2011, COGNITIVE SCI, V35, P1390, DOI 10.1111/j.1551-6709.2011.01192.x
   Macmillan N, 2004, DETECTION THEORY USE
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Myers EB, 2007, NEUROPSYCHOLOGIA, V45, P1463, DOI 10.1016/j.neuropsychologia.2006.11.005
   Myers EB, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00238
   Myers EB, 2012, J COGNITIVE NEUROSCI, V24, P1695, DOI 10.1162/jocn_a_00243
   Myers EB, 2009, PSYCHOL SCI, V20, P895, DOI 10.1111/j.1467-9280.2009.02380.x
   Pruitt J. S., 1990, J ACOUST SOC AM, V87, pS72
   Reetzke R, 2018, CURR BIOL, V28, P1419, DOI 10.1016/j.cub.2018.03.026
   Roark CL, 2018, ATTEN PERCEPT PSYCHO, V80, P1804, DOI 10.3758/s13414-018-1552-5
   Rogers JC, 2017, J COGNITIVE NEUROSCI, V29, P919, DOI 10.1162/jocn_a_01096
   Saad ZS, 2012, NEUROIMAGE, V62, P768, DOI 10.1016/j.neuroimage.2011.09.016
   Seitz A, 2005, TRENDS COGN SCI, V9, P329, DOI 10.1016/j.tics.2005.05.010
   STRANGE W, 1984, PERCEPT PSYCHOPHYS, V36, P131, DOI 10.3758/BF03202673
   Talairach J, 1988, 3 DIMENSIONAL PROPOR
   Tricomi E, 2006, J COGNITIVE NEUROSCI, V18, P1029, DOI 10.1162/jocn.2006.18.6.1029
   Vlahou EL, 2012, J EXP PSYCHOL GEN, V141, P363, DOI 10.1037/a0025014
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Wright BA, 2015, J ACOUST SOC AM, V138, P928, DOI 10.1121/1.4927411
   Xie X, 2018, J COGNITIVE NEUROSCI, V30, P267, DOI 10.1162/jocn_a_01208
   Yi HG, 2016, CEREB CORTEX, V26, P1409, DOI 10.1093/cercor/bhu236
   Zevin JD, 2005, BEHAV BRAIN FUNCT, V1, DOI 10.1186/1744-9081-1-4
   Zevin JD, 2010, J NEUROSCI, V30, P1110, DOI 10.1523/JNEUROSCI.4599-09.2010
NR 55
TC 0
Z9 0
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD NOV
PY 2019
VL 198
AR 104692
DI 10.1016/j.bandl.2019.104692
PG 12
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA JC3QK
UT WOS:000489193200004
PM 31522094
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Bidelman, GM
   Walker, B
AF Bidelman, Gavin M.
   Walker, Breya
TI Plasticity in auditory categorization is supported by differential
   engagement of the auditory-linguistic network
SO NEUROIMAGE
LA English
DT Article
DE Auditory event-related potentials (ERPs); Categorical perception (CP);
   Experience-dependent plasticity; Musical training; Functional brain
   connectivity
ID CATEGORICAL SPEECH-PERCEPTION; BRAIN-STEM; LANGUAGE EXPERIENCE; NEURAL
   ORGANIZATION; EVOKED POTENTIALS; BROCAS AREA; MUSICIANS; IDENTIFICATION;
   REPRESENTATION; CORTEX
AB To construct our perceptual world, the brain categorizes variable sensory cues into behaviorally-relevant groupings. Categorical representations are apparent within a distributed fronto-temporo-parietal brain network but how this neural circuitry is shaped by experience remains undefined. Here, we asked whether speech and music categories might be formed within different auditory-linguistic brain regions depending on listeners' auditory expertise. We recorded EEG in highly skilled (musicians) vs. less experienced (nonmusicians) perceivers as they rapidly categorized speech and musical sounds. Musicians showed perceptual enhancements across domains, yet source EEG data revealed a double dissociation in the neurobiological mechanisms supporting categorization between groups. Whereas musicians coded categories in primary auditory cortex (PAC), nonmusicians recruited non-auditory regions (e.g., inferior frontal gyrus, IFG) to generate category-level information. Functional connectivity confirmed nonmusicians' increased left IFG involvement reflects stronger routing of signal from PAC directed to IFG, presumably because sensory coding is insufficient to construct categories in less experienced listeners. Our findings establish auditory experience modulates specific engagement and inter-regional communication in the auditory-linguistic network supporting categorical perception. Whereas early canonical PAC representations are sufficient to generate categories in highly trained ears, less experienced perceivers broadcast information downstream to higher-order linguistic brain areas (IFG) to construct abstract sound labels.
C1 [Bidelman, Gavin M.; Walker, Breya] Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.
   [Bidelman, Gavin M.] Univ Memphis, Sch Commun Sci & Disorders, 4055 North Pk Loop, Memphis, TN 38152 USA.
   [Bidelman, Gavin M.] Univ Tennessee, Hlth Sci Ctr, Dept Anat & Neurobiol, Memphis, TN USA.
   [Walker, Breya] Univ Memphis, Dept Psychol, Memphis, TN 38152 USA.
   [Walker, Breya] Univ Memphis, Dept Math Sci, Memphis, TN 38152 USA.
   [Walker, Breya] FedEx Serv World Headquarters, Dept Customer Experience Business Intelligence &, Memphis, TN USA.
RP Bidelman, GM (corresponding author), Univ Memphis, Sch Commun Sci & Disorders, 4055 North Pk Loop, Memphis, TN 38152 USA.
EM gmbdlman@memphis.edu
FU GRAMMY Foundation(R); National Institutes of HealthUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USA [NIH/NIDCD R01DC016267]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC016267,
   R01DC016267, R01DC016267] Funding Source: NIH RePORTER
FX Requests for data and materials should be directed to G.M.B
   [gmbdlman@memphis.edu].This work was supported by the GRAMMY Foundation
   (R) and the National Institutes of Health (NIH/NIDCD R01DC016267)
   awarded to G.M.B.
CR Alain C, 2018, HUM BRAIN MAPP, V39, P2695, DOI 10.1002/hbm.24031
   Alain C, 2017, SCI REP-UK, V7, DOI 10.1038/srep40790
   Alain C, 2014, HEARING RES, V308, P162, DOI 10.1016/j.heares.2013.06.008
   Alho J, 2016, NEUROIMAGE, V129, P214, DOI 10.1016/j.neuroimage.2016.01.016
   Baumann S, 2008, J COGNITIVE NEUROSCI, V20, P2238, DOI 10.1162/jocn.2008.20157
   BERTRAND O, 1985, ELECTROEN CLIN NEURO, V62, P462, DOI 10.1016/0168-5597(85)90058-9
   Bidelman G. M, 2019, BIORXIV, DOI [10.1101/652842, DOI 10.1101/652842]
   Bidelman GM, 2019, J ACOUST SOC AM, V146, P60, DOI 10.1121/1.5114822
   Bidelman GM, 2018, HEARING RES, V367, P149, DOI 10.1016/j.heares.2018.05.018
   Bidelman GM, 2017, NEUROSCIENCE, V348, P107, DOI 10.1016/j.neuroscience.2017.02.015
   Bidelman GM, 2017, EUR J NEUROSCI, V45, P690, DOI 10.1111/ejn.13526
   Bidelman GM, 2016, NEUROIMAGE, V124, P581, DOI 10.1016/j.neuroimage.2015.09.020
   Bidelman GM, 2015, NEUROIMAGE, V120, P191, DOI 10.1016/j.neuroimage.2015.06.087
   Bidelman GM, 2015, J NEUROSCI, V35, P1240, DOI 10.1523/JNEUROSCI.3292-14.2015
   Bidelman GM, 2015, BRAIN LANG, V141, P62, DOI 10.1016/j.bandl.2014.11.003
   Bidelman GM, 2014, EUR J NEUROSCI, V40, P2662, DOI 10.1111/ejn.12627
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Bidelman GM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0060676
   Bidelman GM, 2011, BRAIN COGNITION, V77, P1, DOI 10.1016/j.bandc.2011.07.006
   Bidelman GM, 2011, J COGNITIVE NEUROSCI, V23, P425, DOI 10.1162/jocn.2009.21362
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   Bizley JK, 2013, NAT REV NEUROSCI, V14, P693, DOI 10.1038/nrn3565
   BLUMSTEIN SE, 1977, NEUROPSYCHOLOGIA, V15, P19, DOI 10.1016/0028-3932(77)90111-7
   Bouton S, 2018, P NATL ACAD SCI USA, V115, pE1299, DOI 10.1073/pnas.1714279115
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Brattico E, 2009, J COGNITIVE NEUROSCI, V21, P2230, DOI 10.1162/jocn.2008.21144
   BURNS EM, 1978, J ACOUST SOC AM, V63, P456, DOI 10.1121/1.381737
   BURNS EM, 1994, J ACOUST SOC AM, V96, P2704, DOI 10.1121/1.411447
   Calcus A, 2016, J SPEECH LANG HEAR R, V59, P835, DOI 10.1044/2016_JSLHR-H-15-0076
   Chandrasekaran B, 2009, BRAIN LANG, V108, P1, DOI 10.1016/j.bandl.2008.02.001
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Chevillet MA, 2013, J NEUROSCI, V33, P5208, DOI 10.1523/JNEUROSCI.1870-12.2013
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Dhamala M, 2008, NEUROIMAGE, V41, P354, DOI 10.1016/j.neuroimage.2008.02.020
   Di Liberto GM, 2018, NEUROIMAGE, V166, P247, DOI 10.1016/j.neuroimage.2017.10.066
   Dick F, 2011, CEREB CORTEX, V21, P938, DOI 10.1093/cercor/bhq166
   Du Y., 2014, P NATL ACAD SCI USA, V111, P1, DOI DOI 10.1073/pnas.1318738111
   Du Y, 2017, P NATL ACAD SCI USA, V114, P13579, DOI 10.1073/pnas.1712223114
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Elmer S, 2012, CEREB CORTEX, V22, P650, DOI 10.1093/cercor/bhr142
   Feng GY, 2018, CEREB CORTEX, V28, P3241, DOI 10.1093/cercor/bhx195
   Fonov V. S., 2009, NEUROIMAGE, V47, pS102, DOI DOI 10.1016/S1053-8119(09)70884-5
   Freedman DJ, 2001, SCIENCE, V291, P312, DOI 10.1126/science.291.5502.312
   Frey A, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9040091
   GEWEKE J, 1982, J AM STAT ASSOC, V77, P304, DOI 10.2307/2287238
   Giraud AL, 2004, CEREB CORTEX, V14, P247, DOI 10.1093/cercor/bhg124
   Golestani N, 2004, NEUROIMAGE, V21, P494, DOI 10.1016/j.neuroimage.2003.09.071
   Golestani N, 2002, NEURON, V35, P997, DOI 10.1016/S0896-6273(02)00862-0
   GRANGER CWJ, 1969, ECONOMETRICA, V37, P424, DOI 10.2307/1912791
   Guenther FH, 1996, J ACOUST SOC AM, V100, P1111, DOI 10.1121/1.416296
   Hakvoort B, 2016, J SPEECH LANG HEAR R, V59, P1448, DOI 10.1044/2016_JSLHR-L-15-0306
   Herholz SC, 2012, NEURON, V76, P486, DOI 10.1016/j.neuron.2012.10.011
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   HOWARD D, 1992, MUSIC PERCEPT, V10, P205
   Hutka S, 2015, NEUROPSYCHOLOGIA, V71, P52, DOI 10.1016/j.neuropsychologia.2015.03.019
   Iordanov T, 2016, BIO 2016
   Iordanov T, 2014, OHBM 2014
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Jiang X, 2018, NEURON, V98, P405, DOI 10.1016/j.neuron.2018.03.014
   Klein ME, 2011, NEUROPSYCHOLOGIA, V49, P878, DOI 10.1016/j.neuropsychologia.2011.01.008
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Kuhnis J, 2014, J COGNITIVE NEUROSCI, V26, P2750, DOI 10.1162/jocn_a_00674
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Lee YS, 2012, J NEUROSCI, V32, P3942, DOI 10.1523/JNEUROSCI.3814-11.2012
   LEHMANN D, 1980, ELECTROEN CLIN NEURO, V48, P609, DOI 10.1016/0013-4694(80)90419-8
   Liebenthal E, 2010, CEREB CORTEX, V20, P2958, DOI 10.1093/cercor/bhq045
   LOCKE S, 1973, Cortex, V9, P355
   Luthra S, 2019, LANG COGN NEUROSCI, V34, P151, DOI 10.1080/23273798.2018.1531140
   Mankel K, 2018, P NATL ACAD SCI USA, V115, P13129, DOI 10.1073/pnas.1811793115
   Marie C, 2011, J COGNITIVE NEUROSCI, V23, P2701, DOI 10.1162/jocn.2010.21585
   MAZZIOTTA JC, 1995, NEUROIMAGE, V2, P89, DOI 10.1006/nimg.1995.1012
   Messaoud-Galusi S, 2011, J SPEECH LANG HEAR R, V54, P1682, DOI 10.1044/1092-4388(2011/09-0261)
   Meyers EM, 2008, J NEUROPHYSIOL, V100, P1407, DOI 10.1152/jn.90248.2008
   Michel CM, 2004, CLIN NEUROPHYSIOL, V115, P2195, DOI 10.1016/j.clinph.2004.06.001
   Moon C, 2013, ACTA PAEDIATR, V102, P156, DOI 10.1111/apa.12098
   Moreno S, 2014, HEARING RES, V308, P84, DOI 10.1016/j.heares.2013.09.012
   Munte TF, 2002, NAT REV NEUROSCI, V3, P473, DOI 10.1038/nrn843
   Murray MM, 2008, BRAIN TOPOGR, V20, P249, DOI 10.1007/s10548-008-0054-5
   Musacchia G, 2008, HEARING RES, V241, P34, DOI 10.1016/j.heares.2008.04.013
   Myers EB, 2008, CEREB CORTEX, V18, P278, DOI 10.1093/cercor/bhm053
   Myers EB, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00238
   Myers EB, 2009, PSYCHOL SCI, V20, P895, DOI 10.1111/j.1467-9280.2009.02380.x
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Oostenveld R, 2001, CLIN NEUROPHYSIOL, V112, P713, DOI 10.1016/S1388-2457(00)00527-7
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Papoutsi M, 2009, CEREB CORTEX, V19, P2156, DOI 10.1093/cercor/bhn239
   Papp N, 1977, Biomed Sci Instrum, V13, P135
   Paraskevopoulos E, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-16592-y
   Parbery-Clark A, 2009, J NEUROSCI, V29, P14100, DOI 10.1523/JNEUROSCI.3256-09.2009
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P91
   Phillips C, 2001, COGNITIVE SCI, V25, P711, DOI 10.1016/S0364-0213(01)00049-0
   Picton TW, 1999, AUDIOL NEURO-OTOL, V4, P64, DOI 10.1159/000013823
   Picton TW, 2000, CLIN NEUROPHYSIOL, V111, P53, DOI 10.1016/S1388-2457(99)00227-8
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   PISONI DB, 1987, COGNITION, V25, P21, DOI 10.1016/0010-0277(87)90003-5
   Reinke KS, 2003, COGNITIVE BRAIN RES, V17, P781, DOI 10.1016/S0926-6410(03)00202-7
   ROZSYPAL AJ, 1985, J MATH PSYCHOL, V29, P271, DOI 10.1016/0022-2496(85)90009-4
   Schneider P, 2002, NAT NEUROSCI, V5, P688, DOI 10.1038/nn871
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   Seger CA, 2010, ANNU REV NEUROSCI, V33, P203, DOI 10.1146/annurev.neuro.051508.135546
   Seppanen M, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00043
   Shahin A, 2003, J NEUROSCI, V23, P5545
   Shahin AJ, 2009, NEUROIMAGE, V44, P1133, DOI 10.1016/j.neuroimage.2008.09.045
   SIEGEL JA, 1977, PERCEPT PSYCHOPHYS, V21, P143, DOI 10.3758/BF03198717
   Staeren N, 2009, CURR BIOL, V19, P498, DOI 10.1016/j.cub.2009.01.066
   Steinschneider M, 1999, J NEUROPHYSIOL, V82, P2346
   Steinschneider M, 2003, J ACOUST SOC AM, V114, P307, DOI 10.1121/1.1582449
   Strait DL, 2014, HEARING RES, V308, P109, DOI 10.1016/j.heares.2013.08.004
   SUGA N, 1989, J EXP BIOL, V146, P277
   Toscano JC, 2018, BRAIN LANG, V184, P32, DOI 10.1016/j.bandl.2018.06.006
   Weiss MW, 2015, J NEUROSCI, V35, P1687, DOI 10.1523/JNEUROSCI.3680-14.2015
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Xu YS, 2006, J ACOUST SOC AM, V120, P1063, DOI 10.1121/1.2213572
   Yi HG, 2016, J ACOUST SOC AM, V140, P1332, DOI 10.1121/1.4961163
   Yi HG, 2016, CEREB CORTEX, V26, P1409, DOI 10.1093/cercor/bhu236
   Yoo J, 2019, HEARING RES, V377, P189, DOI 10.1016/j.heares.2019.03.021
   Zatorre R, 2005, NATURE, V434, P312, DOI 10.1038/434312a
   ZATORRE RJ, 1983, J EXP PSYCHOL HUMAN, V9, P739, DOI 10.1037/0096-1523.9.5.739
   ZATORRE RJ, 1979, PERCEPT PSYCHOPHYS, V26, P384, DOI 10.3758/BF03204164
   Zendel BR, 2009, J COGNITIVE NEUROSCI, V21, P1488, DOI 10.1162/jocn.2009.21140
   Zoubrinetzky R, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151015
NR 123
TC 5
Z9 5
U1 4
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD NOV 1
PY 2019
VL 201
AR 116022
DI 10.1016/j.neuroimage.2019.116022
PG 10
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA JA3UX
UT WOS:000487755700010
PM 31310863
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Correia, AI
   Branco, P
   Martins, M
   Reis, AM
   Martins, N
   Castro, SL
   Lima, CF
AF Correia, Ana Isabel
   Branco, Paulo
   Martins, Marta
   Reis, Ana Mafalda
   Martins, Nuno
   Castro, Sao Luis
   Lima, Cesar F.
TI Resting-state connectivity reveals a role for sensorimotor systems in
   vocal emotional processing in children
SO NEUROIMAGE
LA English
DT Article
DE Emotion recognition; Individual differences; Resting-state functional
   connectivity; Sensorimotor system; Speech prosody
ID SUPPLEMENTARY MOTOR AREA; FRONTAL ASLANT TRACT; INDIVIDUAL-DIFFERENCES;
   NEURAL-NETWORK; WORKING-MEMORY; SPEECH; CORTEX; RECOGNITION;
   EXPRESSIONS; PERCEPTION
AB Voices are a primary source of emotional information in everyday interactions. Being able to process non-verbal vocal emotional cues, namely those embedded in speech prosody, impacts on our behaviour and communication. Extant research has delineated the role of temporal and inferior frontal brain regions for vocal emotional processing. A growing number of studies also suggest the involvement of the motor system, but little is known about such potential involvement. Using resting-state fMRI, we ask if the patterns of motor system intrinsic connectivity play a role in emotional prosody recognition in children. Fifty-five 8-year-old children completed an emotional prosody recognition task and a resting-state scan. Better performance in emotion recognition was predicted by a stronger connectivity between the inferior frontal gyrus (IFG) and motor regions including primary motor, lateral premotor and supplementary motor sites. This is mostly driven by the IFG pars triangularis and cannot be explained by differences in domain-general cognitive abilities. These findings indicate that individual differences in the engagement of sensorimotor systems, and in its coupling with inferior frontal regions, underpin variation in children's emotional speech perception skills. They suggest that sensorimotor and higher-order evaluative processes interact to aid emotion recognition, and have implications for models of vocal emotional communication.
C1 [Correia, Ana Isabel; Branco, Paulo; Martins, Marta; Castro, Sao Luis; Lima, Cesar F.] Univ Porto, Fac Psychol & Educ Sci, Porto, Portugal.
   [Branco, Paulo] Univ Porto, Fac Med, Porto, Portugal.
   [Reis, Ana Mafalda; Martins, Nuno] Unilabs Boavista, Porto, Portugal.
   [Correia, Ana Isabel; Lima, Cesar F.] IUL, ISCTE, Ave Forcas Armadas, P-1649026 Lisbon, Portugal.
   [Lima, Cesar F.] UCL, Inst Cognit Neurosci, London, England.
RP Lima, CF (corresponding author), IUL, ISCTE, Ave Forcas Armadas, P-1649026 Lisbon, Portugal.
EM cesar.lima@iscte-iul.pt
RI Correia, Ana/AAD-2166-2021; Castro, Sao Luis/E-5518-2017; Lima,
   Cesar/M-5069-2013
OI Reis, AlessanRSS/0000-0001-8486-7469; Correia, Ana
   Isabel/0000-0002-2493-0195; Castro, Sao Luis/0000-0002-1487-3596;
   Martins, Marta/0000-0002-4872-0539; Lima, Cesar/0000-0003-3058-7204
FU Portuguese Foundation for Science and TechnologyPortuguese Foundation
   for Science and Technology [CPUP UID/PSI/00050/2013, IF/00172/2015,
   PTDC/PSI-GER/28274/2017, SFRH/BD/86912/2012, SFRH/BD/99622/2014]; Bial
   FoundationBial Foundation [2014/304]; Unilabs - Boavista
FX This work was supported by the Portuguese Foundation for Science and
   Technology [CPUP UID/PSI/00050/2013; IF/00172/2015 and
   PTDC/PSI-GER/28274/2017 to C.F.L.; SFRH/BD/86912/2012 to P.B.;
   SFRH/BD/99622/2014 to M.M]; and the Bial Foundation [2014/304 to
   S.L.C.]. MRI-related costs were supported by Unilabs - Boavista.
CR Agnew ZK, 2011, J COGNITIVE NEUROSCI, V23, P4038, DOI 10.1162/jocn_a_00106
   Aguert M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083657
   Allgood R, 2015, BRIT J DEV PSYCHOL, V33, P398, DOI 10.1111/bjdp.12097
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   Andersson JLR, 2007, NONLINEAR REGISTRATI
   Angelides NH, 2017, SOC COGN AFFECT NEUR, V12, P1001, DOI 10.1093/scan/nsx031
   Baldo JV, 2006, NEUROPSYCHOLOGY, V20, P529, DOI 10.1037/0894-4105.20.5.529
   Banissy MJ, 2010, J NEUROSCI, V30, P13552, DOI 10.1523/JNEUROSCI.0786-10.2010
   Bestelmeyer PEG, 2014, J NEUROSCI, V34, P8098, DOI 10.1523/JNEUROSCI.4820-13.2014
   Blasi A, 2011, CURR BIOL, V21, P1220, DOI 10.1016/j.cub.2011.06.009
   Broce I, 2015, BRAIN LANG, V149, P66, DOI 10.1016/j.bandl.2015.06.006
   Bruck C, 2011, PHYS LIFE REV, V8, P383, DOI 10.1016/j.plrev.2011.10.002
   Budisavljevic S, 2017, NEUROIMAGE, V146, P419, DOI 10.1016/j.neuroimage.2016.10.051
   Castro SL, 2010, BEHAV RES METHODS, V42, P74, DOI 10.3758/BRM.42.1.74
   Catani M, 2012, CORTEX, V48, P273, DOI 10.1016/j.cortex.2011.12.001
   Chronaki G, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-26889-1
   Courtney SM, 1997, NATURE, V386, P608, DOI 10.1038/386608a0
   Curran PJ, 1996, PSYCHOL METHODS, V1, P16, DOI 10.1037//1082-989X.1.1.16
   Dall'Orso S, 2018, CEREB CORTEX, V28, P2507, DOI 10.1093/cercor/bhy050
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   Demopoulos C, 2016, J ABNORM CHILD PSYCH, V44, P913, DOI 10.1007/s10802-015-0082-z
   Dricu M, 2016, NEUROSCI BIOBEHAV R, V71, P810, DOI 10.1016/j.neubiorev.2016.10.020
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   Ethofer T, 2012, CEREB CORTEX, V22, P191, DOI 10.1093/cercor/bhr113
   Flom R, 2007, DEV PSYCHOL, V43, P238, DOI 10.1037/0012-1649.43.1.238
   Fonov V. S., 2009, NEUROIMAGE, V47, pS102, DOI DOI 10.1016/S1053-8119(09)70884-5
   Fonov V, 2011, NEUROIMAGE, V54, P313, DOI 10.1016/j.neuroimage.2010.07.033
   Fontaine D, 2002, NEUROSURGERY, V50, P297, DOI 10.1097/00006123-200202000-00011
   FRIED I, 1991, J NEUROSCI, V11, P3656
   Fruhholz S, 2015, NEUROIMAGE, V109, P27, DOI 10.1016/j.neuroimage.2015.01.016
   Fruehholz S, 2013, NEUROSCI BIOBEHAV R, V37, P2847, DOI 10.1016/j.neubiorev.2013.10.007
   Fruhholz S, 2013, NEUROSCI BIOBEHAV R, V37, P24, DOI 10.1016/j.neubiorev.2012.11.002
   Fruhholz S, 2012, NEUROIMAGE, V62, P1658, DOI 10.1016/j.neuroimage.2012.06.015
   Fruhholz S, 2016, NEUROSCI BIOBEHAV R, V68, P96, DOI 10.1016/j.neubiorev.2016.05.002
   Grahn JA, 2007, J COGNITIVE NEUROSCI, V19, P893, DOI 10.1162/jocn.2007.19.5.893
   Greve DN, 2009, NEUROIMAGE, V48, P63, DOI 10.1016/j.neuroimage.2009.06.060
   Grossmann T, 2005, NEUROREPORT, V16, P1825, DOI 10.1097/01.wnr.0000185964.34336.b1
   Hoekert M, 2010, BMC NEUROSCI, V11, DOI 10.1186/1471-2202-11-93
   Isaacowitz DM, 2007, PSYCHOL AGING, V22, P147, DOI 10.1037/0882-7974.22.1.147
   JASP Team, 2017, JASP VERS 0 8 5 COMP
   Jenkinson M, 2002, NEUROIMAGE, V17, P825, DOI 10.1006/nimg.2002.1132
   Jenkinson M, 2012, NEUROIMAGE, V62, P782, DOI 10.1016/j.neuroimage.2011.09.015
   KIRZINGER A, 1982, BRAIN RES, V233, P299, DOI 10.1016/0006-8993(82)91204-5
   Kotz SA, 2011, LANG LINGUIST COMPAS, V5, P108, DOI 10.1111/j.1749-818x.2010.00267.x
   Koyama MS, 2011, J NEUROSCI, V31, P8617, DOI 10.1523/JNEUROSCI.4865-10.2011
   Krishnan S, 2018, CEREB CORTEX, V28, P4063, DOI 10.1093/cercor/bhy208
   Kuhn M, 2008, J STAT SOFTW, V28, P1, DOI 10.18637/jss.v028.i05
   Lee MH, 2013, AM J NEURORADIOL, V34, P1866, DOI 10.3174/ajnr.A3263
   Leitman DI, 2011, FRONT HUM NEUROSCI, V5, DOI [10.3389/fnhum.2010.00019, 10.3389/fnhum.2011.00096]
   Leppanen JM, 2001, SCAND J PSYCHOL, V42, P429, DOI 10.1111/1467-9450.00255
   Lima CF, 2016, TRENDS NEUROSCI, V39, P527, DOI 10.1016/j.tins.2016.06.003
   Lima CF, 2015, CEREB CORTEX, V25, P4638, DOI 10.1093/cercor/bhv134
   Lima CF, 2013, J CLIN EXP NEUROPSYC, V35, P373, DOI 10.1080/13803395.2013.776518
   Lima CF, 2011, EMOTION, V11, P1021, DOI 10.1037/a0024521
   Mayka MA, 2006, NEUROIMAGE, V31, P1453, DOI 10.1016/j.neuroimage.2006.02.004
   McCarthy G, 1996, CEREB CORTEX, V6, P600, DOI 10.1093/cercor/6.4.600
   McClure EB, 2001, J NONVERBAL BEHAV, V25, P3, DOI 10.1023/A:1006753006870
   McGettigan C, 2015, CEREB CORTEX, V25, P246, DOI 10.1093/cercor/bht227
   Misaghi E, 2018, NEUROSCI LETT, V668, P37, DOI 10.1016/j.neulet.2018.01.009
   Mollo G, 2016, BRAIN COGNITION, V109, P112, DOI 10.1016/j.bandc.2016.07.003
   Morningstar M, 2018, NEUROSCI BIOBEHAV R, V90, P221, DOI 10.1016/j.neubiorev.2018.04.019
   MUAKKASSA KF, 1979, BRAIN RES, V177, P176, DOI 10.1016/0006-8993(79)90928-4
   Neves L, 2018, Q J EXP PSYCHOL, V71, P2355, DOI 10.1177/1747021817741800
   Niendam TA, 2012, COGN AFFECT BEHAV NE, V12, P241, DOI 10.3758/s13415-011-0083-5
   NOWICKI S, 1992, J GENET PSYCHOL, V153, P385
   O'Nions E, 2017, CURR BIOL, V27, P3049, DOI 10.1016/j.cub.2017.08.062
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Pell MD, 2015, BIOL PSYCHOL, V111, P14, DOI 10.1016/j.biopsycho.2015.08.008
   Pfeifer JH, 2008, NEUROIMAGE, V39, P2076, DOI 10.1016/j.neuroimage.2007.10.032
   Plante E, 2006, BRAIN LANG, V97, P332, DOI 10.1016/j.bandl.2005.12.004
   Pruim RHR, 2015, NEUROIMAGE, V112, P267, DOI 10.1016/j.neuroimage.2015.02.064
   Rayson H, 2016, DEV COGN NEUROS-NETH, V19, P279, DOI 10.1016/j.dcn.2016.05.003
   Rota G, 2011, BRAIN LANG, V117, P123, DOI 10.1016/j.bandl.2010.07.008
   Ruffman T, 2010, PSYCHOL AGING, V25, P492, DOI 10.1037/a0018247
   Sammler D, 2015, CURR BIOL, V25, P3079, DOI 10.1016/j.cub.2015.10.009
   Sauter DA, 2013, BRIT J DEV PSYCHOL, V31, P97, DOI 10.1111/j.2044-835X.2012.02081.x
   Schirmer A, 2006, TRENDS COGN SCI, V10, P24, DOI 10.1016/j.tics.2005.11.009
   Schirmer A, 2018, SOC COGN AFFECT NEUR, V13, P1, DOI 10.1093/scan/nsx142
   Schirmer A, 2017, TRENDS COGN SCI, V21, P216, DOI 10.1016/j.tics.2017.01.001
   Scott SK, 2004, J ACOUST SOC AM, V115, P813, DOI 10.1121/1.1639336
   Scott SK, 2010, HBK BEHAV NEUROSCI, V19, P187, DOI 10.1016/B978-0-12-374593-4.00019-X
   Scott SK, 2009, NAT REV NEUROSCI, V10, P295, DOI 10.1038/nrn2603
   Skeide MA, 2016, NAT REV NEUROSCI, V17, P323, DOI 10.1038/nrn.2016.23
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Smith SM, 2002, HUM BRAIN MAPP, V17, P143, DOI 10.1002/hbm.10062
   Soderstrom M, 2017, COGNITION EMOTION, V31, P298, DOI 10.1080/02699931.2015.1108904
   Supekar K, 2013, P NATL ACAD SCI USA, V110, P8230, DOI 10.1073/pnas.1222154110
   Tian X, 2016, CORTEX, V77, P1, DOI 10.1016/j.cortex.2016.01.002
   Vergani F, 2014, J NEUROL NEUROSUR PS, V85, P1377, DOI 10.1136/jnnp-2013-307492
   WAGNER HL, 1993, J NONVERBAL BEHAV, V17, P3, DOI 10.1007/BF00987006
   Warren JE, 2006, J NEUROSCI, V26, P13067, DOI 10.1523/JNEUROSCI.3907-06.2006
   Wechsler D., 2003, ESCALA INTELIGENCIA
   Westerberg H, 2007, PHYSIOL BEHAV, V92, P186, DOI 10.1016/j.physbeh.2007.05.041
   Winkler AM, 2014, NEUROIMAGE, V92, P381, DOI 10.1016/j.neuroimage.2014.01.060
   Zeharia N, 2012, P NATL ACAD SCI USA, V109, P18565, DOI 10.1073/pnas.1119125109
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
NR 96
TC 1
Z9 1
U1 4
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD NOV 1
PY 2019
VL 201
AR 116052
DI 10.1016/j.neuroimage.2019.116052
PG 10
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA JA3UX
UT WOS:000487755700040
PM 31351162
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Choi, JY
   Perrachione, TK
AF Choi, Ja Young
   Perrachione, Tyler K.
TI Time and information in perceptual adaptation to speech
SO COGNITION
LA English
DT Article
DE Speech perception; Phonetic variability; Categorization; Talker
   normalization; Adaptation
ID TALKER NORMALIZATION; SELECTIVE ATTENTION; VOWEL; PLASTICITY;
   IDENTIFICATION; REPRESENTATION; MECHANISMS; CONTINUITY; LOCATION;
   TRACKING
AB Perceptual adaptation to a talker enables listeners to efficiently resolve the many-to-many mapping between variable speech acoustics and abstract linguistic representations. However, models of speech perception have not delved into the variety or the quantity of information necessary for successful adaptation, nor how adaptation unfolds over time. In three experiments using speeded classification of spoken words, we explored how the quantity (duration), quality (phonetic detail), and temporal continuity of talker-specific context contribute to facilitating perceptual adaptation to speech. In single-and mixed-talker conditions, listeners identified phonetically-confusable target words in isolation or preceded by carrier phrases of varying lengths and phonetic content, spoken by the same talker as the target word. Word identification was always slower in mixed-talker conditions than single-talker ones. However, interference from talker variability decreased as the duration of preceding speech increased but was not affected by the amount of preceding talker-specific phonetic information. Furthermore, efficiency gains from adaptation depended on temporal continuity between preceding speech and the target word. These results suggest that perceptual adaptation to speech may be understood via models of auditory streaming, where perceptual continuity of an auditory object (e.g., a talker) facilitates allocation of attentional resources, resulting in more efficient perceptual processing.
C1 [Choi, Ja Young; Perrachione, Tyler K.] Boston Univ, Dept Speech Language & Hearing Sci, 635 Commonwealth Ave, Boston, MA 02215 USA.
   [Choi, Ja Young] Harvard Univ, Program Speech & Hearing Biosci & Technol, Cambridge, MA 02138 USA.
RP Perrachione, TK (corresponding author), Boston Univ, Dept Speech Language & Hearing Sci, 635 Commonwealth Ave, Boston, MA 02215 USA.
EM tkp@bu.edu
FU NIDCD of the National Institutes of HealthUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R03DC014045]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R03DC014045] Funding Source: NIH
   RePORTER
FX We thank Sara Dougherty, Elly Hu, Emily Thurston, Terri Scott, and
   Lauren Gustainis for their assistance, and Sung-Joo Lim and Barbara
   Shinn-Cunningham for helpful discussion. Research reported in this
   article was supported by the NIDCD of the National Institutes of Health
   under award number R03DC014045. The content is solely the responsibility
   of the authors and does not necessarily represent the official views of
   the National Institutes of Health.
CR Alain C, 2000, FRONT BIOSCI-LANDMRK, V5, pD202, DOI 10.2741/Alain
   Alho K, 2014, HEARING RES, V307, P29, DOI 10.1016/j.heares.2013.08.001
   Altmann CF, 2008, NEUROIMAGE, V41, P69, DOI 10.1016/j.neuroimage.2008.02.013
   ASSMANN PF, 1982, J ACOUST SOC AM, V71, P975, DOI 10.1121/1.387579
   Bachorowski JA, 1999, J ACOUST SOC AM, V106, P1054, DOI 10.1121/1.427115
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Belin P, 2003, NEUROREPORT, V14, P2105, DOI 10.1097/00001756-200311140-00019
   Best V, 2008, P NATL ACAD SCI USA, V105, P13174, DOI 10.1073/pnas.0803718105
   Best V, 2007, JARO-J ASSOC RES OTO, V8, P294, DOI 10.1007/s10162-007-0073-z
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bressler S, 2014, PSYCHOL RES-PSYCH FO, V78, P349, DOI 10.1007/s00426-014-0555-7
   Chandrasekaran B, 2011, J COGNITIVE NEUROSCI, V23, P2690, DOI 10.1162/jocn.2011.21631
   Choi JY, 2018, ATTEN PERCEPT PSYCHO, V80, P784, DOI 10.3758/s13414-017-1395-5
   Cusack R, 2004, J EXP PSYCHOL HUMAN, V30, P643, DOI 10.1037/0096-1523.30.4.643
   Cutler A, 2011, 17 M INT C PHON SCI
   Da Costa S, 2013, J NEUROSCI, V33, P1858, DOI 10.1523/JNEUROSCI.4405-12.2013
   Dahan D, 2008, COGNITION, V108, P710, DOI 10.1016/j.cognition.2008.06.003
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Duncan J, 2006, Q J EXP PSYCHOL, V59, P2, DOI 10.1080/17470210500260674
   Fairnie J, 2016, J EXP PSYCHOL HUMAN, V42, P930, DOI 10.1037/xhp0000204
   Francis AL, 2006, J ACOUST SOC AM, V119, P1712, DOI 10.1121/1.2149768
   Fritz J, 2003, NAT NEUROSCI, V6, P1216, DOI 10.1038/nn1141
   Fritz JB, 2007, CURR OPIN NEUROBIOL, V17, P437, DOI 10.1016/j.conb.2007.07.011
   Froemke RC, 2015, CURR OPIN NEUROBIOL, V35, P185, DOI 10.1016/j.conb.2015.10.003
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Golumbic EMZ, 2012, BRAIN LANG, V122, P151, DOI 10.1016/j.bandl.2011.12.010
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Green KP, 1997, PERCEPT PSYCHOPHYS, V59, P675, DOI 10.3758/BF03206015
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Jaaskelainen IP, 2007, TRENDS NEUROSCI, V30, P653, DOI 10.1016/j.tins.2007.09.003
   Jaramillo S, 2011, NAT NEUROSCI, V14, P246, DOI 10.1038/nn.2688
   JOHNSON K, 1990, J ACOUST SOC AM, V88, P642, DOI 10.1121/1.399767
   JOHNSON K, 1993, J ACOUST SOC AM, V94, P701, DOI 10.1121/1.406887
   Johnson K, 2005, BLACKW HBK LINGUIST, P363, DOI 10.1002/9780470757024.ch15
   Joos M., 1948, LANGUAGE MONOGRAPHS, V24, P136
   Kaganovich N, 2006, BRAIN RES, V1114, P161, DOI 10.1016/j.brainres.2006.07.049
   Kidd G, 2005, J ACOUST SOC AM, V118, P3804, DOI 10.1121/1.2109187
   Kleinschmidt D. F, 2018, LANG COGN NEUROSCI, P1
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Laing EJC, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00203
   Leather J, 1983, J PHONETICS
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Lim SJ, 2019, ATTEN PERCEPT PSYCHO, V81, P1167, DOI 10.3758/s13414-019-01684-w
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   Marr D., 1982, VISION COMPUTATIONAL
   McLennan CT, 2005, J EXP PSYCHOL LEARN, V31, P306, DOI 10.1037/0278-7393.31.2.306
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Morton JR, 2015, J ACOUST SOC AM, V137, P1443, DOI 10.1121/1.4913456
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   MULLENNIX JW, 1990, PERCEPT PSYCHOPHYS, V47, P379, DOI 10.3758/BF03210878
   NEAREY TM, 1989, J ACOUST SOC AM, V85, P2088, DOI 10.1121/1.397861
   Nusbaum H.C., 1997, TALKER VARIABILITY S, P109
   Nusbaum HC, 1992, SPEECH PERCEPTION PR, P113
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Perrachione TK, 2016, NEURON, V92, P1383, DOI 10.1016/j.neuron.2016.11.020
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Pisoni DB, 1997, TALKER VARIABILITY S, P9
   Shinn-Cunningham BG, 2008, TRENDS COGN SCI, V12, P182, DOI 10.1016/j.tics.2008.02.003
   Shinn-Cunningham Barbara G, 2008, Trends Amplif, V12, P283, DOI 10.1177/1084713808325306
   Sjerps MJ, 2011, NEUROPSYCHOLOGIA, V49, P3831, DOI 10.1016/j.neuropsychologia.2011.09.044
   Summerfield C, 2009, TRENDS COGN SCI, V13, P403, DOI 10.1016/j.tics.2009.06.003
   Todorovic A, 2012, J NEUROSCI, V32, P13389, DOI 10.1523/JNEUROSCI.2227-12.2012
   Trude AM, 2012, LANG COGNITIVE PROC, V27, P979, DOI 10.1080/01690965.2011.597153
   Winkler I, 2009, TRENDS COGNITIVE SCI, V13
   Wong PCM, 2004, J COGNITIVE NEUROSCI, V16, P1173, DOI 10.1162/0898929041920522
   Wong PCM, 2003, J SPEECH LANG HEAR R, V46, P413, DOI 10.1044/1092-4388(2003/034)
   Woods KJP, 2015, CURR BIOL, V25, P2238, DOI 10.1016/j.cub.2015.07.043
   Xie X, 2018, LANG COGN NEUROSCI, V33, P196, DOI 10.1080/23273798.2017.1369551
   Zhang CC, 2016, NEUROIMAGE, V124, P536, DOI 10.1016/j.neuroimage.2015.08.064
   Zhou XM, 2010, P NATL ACAD SCI USA, V107, P14839, DOI 10.1073/pnas.1009433107
NR 72
TC 4
Z9 4
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD NOV
PY 2019
VL 192
AR 103982
DI 10.1016/j.cognition.2019.05.019
PG 14
WC Psychology, Experimental
SC Psychology
GA IZ6BL
UT WOS:000487166700004
PM 31229740
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Konishi, H
   Brezack, N
   Golinkoff, RM
   Hirsh-Pasek, K
AF Konishi, Haruka
   Brezack, Natalie
   Golinkoff, Roberta Michnick
   Hirsh-Pasek, Kathy
TI Crossing to the other side: Language influences children's perception of
   event components
SO COGNITION
LA English
DT Article
DE Perception of events; Language and thought; Relational term learning
ID FACILITATE OBJECT CATEGORIZATION; SPEECH-PERCEPTION; MOTION EVENTS;
   INFANTS; WORDS; LABELS; MANNERS; SOUNDS; FORM
AB Infants appear to progress from universal to language-specific event perception. In Japanese, two different verbs describe a person crossing a bounded ground (e.g., street) versus an unbounded ground (e.g., field) while in English, the same verb - crossing - describes both events. Interestingly, Japanese and English 14-month-old infants form categories of Japanese ground distinctions in nonlinguistic events while by 20 months, only Japanese-reared infants retain this ability. Five experiments were conducted to investigate the role that language plays in children's ability to form categories of Japanese ground-path distinctions. Experiments la and 1b first replicated and extended prior research (Goksun et al., 2011) by showing that 14-month-old English-reared children formed categories of Japanese ground-path while 23-month-old children did not in the presence of general language. Experiment 2a paired a single novel word with different Japanese ground categories and found that language weakened 14-month-old infants' categorization abilities. Experiment 2b showed that labeling these event types differentially allowed 23-month-olds to recognize the Japanese ground-path distinctions that they otherwise would not have detected. To assess whether language uniquely encouraged categorization of Japanese ground-path in Experiment 2b, two different tones were paired with ground-path categories in Experiment 3. The results of Experiments 2b and 3 suggested that language but not tones encouraged ground path categorization. This study is among the first to show that language can be used to heighten and weaken children's categorization of "non-native" event components.
C1 [Konishi, Haruka] Missouri Western State Coll, St Joseph, MO 64507 USA.
   [Brezack, Natalie] Univ Chicago, Chicago, IL 60637 USA.
   [Golinkoff, Roberta Michnick] Univ Delaware, Newark, DE 19716 USA.
   [Hirsh-Pasek, Kathy] Temple Univ, Philadelphia, PA 19122 USA.
RP Konishi, H (corresponding author), Missouri Western State Univ, Dept Educ, Murphy Hall Off Q, St Joseph, MO 64507 USA.
EM hkonishi@missouriwestern.edu
FU NSFNational Science Foundation (NSF) [SBR9615391]; NIHUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USA [547208]; IESUS Department of Education [R305A100215]
FX This research was funded by grants to the third and fourth authors: From
   NSF (SBR9615391), NIH (547208), and IES (R305A100215).
CR Balaban MT, 1997, J EXP CHILD PSYCHOL, V64, P3, DOI 10.1006/jecp.1996.2332
   Booth AE, 2002, DEV PSYCHOL, V38, P948, DOI 10.1037//0012-1649.38.6.948
   Bornstein MH, 2010, INFANT BEHAV DEV, V33, P7, DOI 10.1016/j.infbeh.2009.10.003
   Boroditsky L, 2003, BRADFORD BOOKS, P61
   BOWERMAN M, 2001, LANG ACQUIS, P475, DOI DOI 10.1017/CBO9780511620669.018
   Casasola M, 2004, INFANCY, V6, P385, DOI 10.1207/s15327078in0603_4
   Casasola M, 2007, CHILD DEV, V78, P1818, DOI 10.1111/j.1467-8624.2007.01100.x
   Casasola M, 2009, DEV PSYCHOL, V45, P711, DOI 10.1037/a0015475
   CHOI S, 1991, COGNITION, V41, P83, DOI 10.1016/0010-0277(91)90033-Z
   Choi S, 2012, COGNITIVE SCI, V36, P102, DOI 10.1111/j.1551-6709.2011.01201.x
   Choi Soonja, 2006, FIRST LANG, V26, P207, DOI DOI 10.1177/0142723706060748
   FAGAN JF, 1984, INTELLIGENCE, V8, P339, DOI 10.1016/0160-2896(84)90016-3
   Fenson Larry, 1994, Monographs of the Society for Research in Child Development, V59, P1
   Ferguson B, 2016, COGNITION, V146, P185, DOI 10.1016/j.cognition.2015.09.020
   Ferry AL, 2010, CHILD DEV, V81, P472, DOI 10.1111/j.1467-8624.2009.01408.x
   Fisher C., 2002, STEVENS HDB EXPT PSY, V3, P445
   Fulkerson AL, 2003, INFANCY, V4, P349, DOI 10.1207/S15327078IN0403_03
   Fulkerson AL, 2007, COGNITION, V105, P218, DOI 10.1016/j.cognition.2006.09.005
   Gennari SP, 2002, COGNITION, V83, P49, DOI 10.1016/S0010-0277(01)00166-4
   Gentner D., 2001, LANG ACQUIS, P215, DOI DOI 10.1017/CBO9780511620669.010
   Gentner D., 1982, 257 CTR STUD READ
   Gentner D, 2010, CROSSLINGUISTIC APPROACHES TO THE PSYCHOLOGY OF LANGUAGE: RESEARCH IN THE TRADITION OF DAN ISAAC SLOBIN, P465
   Gleitman L, 2013, CAMBRIDGE HDB THINKI
   Goksun T, 2011, COGNITION, V121, P176, DOI 10.1016/j.cognition.2011.07.002
   Goksun T, 2010, PERSPECT PSYCHOL SCI, V5, P33, DOI 10.1177/1745691609356783
   Golinkoff R. M, 2006, ACTION MEETS WORDS C
   Golinkoff RM, 2002, DEV PSYCHOL, V38, P604, DOI 10.1037//0012-1649.38.4.604
   GOLINKOFF RM, 1987, J CHILD LANG, V14, P23, DOI 10.1017/S030500090001271X
   Golinkoff RM, 2008, TRENDS COGN SCI, V12, P397, DOI 10.1016/j.tics.2008.07.003
   Golinkoff RM, 2013, PERSPECT PSYCHOL SCI, V8, P316, DOI 10.1177/1745691613484936
   Gumperz J.J., 1996, RETHINKING LINGUISTI
   Hespos SJ, 2004, NATURE, V430, P453, DOI 10.1038/nature02634
   Hespos SJ, 2001, COGNITION, V78, P207, DOI 10.1016/S0010-0277(00)00118-9
   Hespos SJ, 2007, CATEGORIZATION SPATI, P233, DOI DOI 10.1075/HCP.20.13HES
   Hirsh-Pasek K., 2004, WEAVING LEXICON, P173
   Hollich G., 2008, SUPERCODER PROGRAM C
   Imai M, 2007, COGNITIVE SCI, V31, P385, DOI 10.1080/15326900701326436
   Katis D., 2010, MOTION DESCRIPTIONS
   Konishi H, 2016, J EXP CHILD PSYCHOL, V151, P18, DOI 10.1016/j.jecp.2016.03.012
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   LANDAU B, 1993, BEHAV BRAIN SCI, V16, P255, DOI 10.1017/S0140525X00029927
   Landau B., 2010, 84 ANN M LING SOC AM
   Levinson S. C., 1996, LANGUAGE SPACE, P109
   Li P, 2002, COGNITION, V83, P265, DOI 10.1016/S0010-0277(02)00009-4
   Li P, 2018, COGNITION, V170, P9, DOI 10.1016/j.cognition.2017.09.005
   Li P, 2009, COGNITIVE PSYCHOL, V58, P487, DOI 10.1016/j.cogpsych.2008.12.001
   Lucy J., 1996, RETHINKING LINGUISTI, P37
   Lucy John, 2001, LANG ACQUIS, P257, DOI DOI 10.1017/CBO9780511620669.011
   Lucy JA, 2003, BRADFORD BOOKS, P465
   Maguire MJ, 2010, COGNITION, V114, P299, DOI 10.1016/j.cognition.2009.10.002
   MAJID A, 2010, WORDS MIND WORDS CAP, P58, DOI DOI 10.1093/ACPR0F:0S0/9780195311129.003.0004
   Malt BC, 1999, J MEM LANG, V40, P230, DOI 10.1006/jmla.1998.2593
   Malt BC, 2010, WORDS MIND WORDS CAP
   MANDLER JM, 1992, PSYCHOL REV, V99, P587, DOI 10.1037/0033-295X.99.4.587
   McDonough L, 2003, COGNITIVE PSYCHOL, V46, P229, DOI 10.1016/S0010-0285(02)00514-5
   Muehleisen V, 1997, AMST STUD THEORY HIS, V150, P329
   Namy LL, 2001, INFANCY, V2, P73, DOI 10.1207/S15327078IN0201_5
   Nazzi T, 2001, COGNITION, V80, pB11, DOI 10.1016/S0010-0277(01)00112-3
   Papafragou A, 2008, COGNITION, V108, P155, DOI 10.1016/j.cognition.2008.02.007
   Pederson E, 1998, LANGUAGE, V74, P557, DOI 10.2307/417793
   Perry LK, 2013, FRONT BEHAV NEUROSCI, V7, DOI 10.3389/fnbeh.2013.00122
   Plunkett K, 2008, COGNITION, V106, P665, DOI 10.1016/j.cognition.2007.04.003
   Pruden SM, 2013, CHILD DEV, V84, P331, DOI 10.1111/j.1467-8624.2012.01843.x
   Pruden SM, 2012, CHILD DEV, V83, P977, DOI 10.1111/j.1467-8624.2012.01737.x
   Pulverman R, 2008, COGNITION, V108, P825, DOI 10.1016/j.cognition.2008.04.009
   Pulverman R, 2013, CHILD DEV, V84, P241, DOI 10.1111/cdev.12030
   Regier T., 2010, WORDS MIND WORDS CAP, P165, DOI DOI 10.1093/ACPROF:OSO/9780195311129.003.0009
   Robinson CW, 2007, INFANCY, V11, P233, DOI 10.1111/j.1532-7078.2007.tb00225.x
   Shafto CL, 2014, DEV PSYCHOL, V50, P794, DOI 10.1037/a0034253
   Slobin Dan I., 2001, LANG ACQUIS, P406, DOI DOI 10.1017/CBO9780511620669.016
   Talmy Leonard, 2000, COGNITIVE SEMANTICS, V2
   TALMY Leonard, 1985, LANGUAGE TYPOLOGY SY, P57, DOI DOI 10.1017/CB09780511618437
   Trueswell JC, 2010, J MEM LANG, V63, P64, DOI 10.1016/j.jml.2010.02.006
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Whorf B. L., 1956, LANGUAGE THOUGHT REA
   Woodward AL, 1999, CHILD DEV, V70, P65, DOI 10.1111/1467-8624.00006
NR 76
TC 0
Z9 0
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD NOV
PY 2019
VL 192
AR 104020
DI 10.1016/j.cognition.2019.104020
PG 13
WC Psychology, Experimental
SC Psychology
GA IZ6BL
UT WOS:000487166700018
PM 31352223
DA 2021-02-24
ER

PT J
AU Marrufo-Perez, MI
   Eustaquio-Martin, A
   Lopez-Poveda, EA
AF Marrufo-Perez, Miriam I.
   Eustaquio-Martin, Almudena
   Lopez-Poveda, Enrique A.
TI Speech predictability can hinder communication in difficult listening
   conditions
SO COGNITION
LA English
DT Article
DE Speech perception; Noise adaptation; Context effects; Intelligibility in
   noise; Word position; Sentence recognition
ID TIME-COURSE; RECEPTION THRESHOLDS; OLDER-ADULTS; NOISE; LANGUAGE;
   CONTEXT; HEARING; RECOGNITION; INTELLIGIBILITY; PREDICTION
AB In difficult listening situations, such as in noisy environments, one would expect speech intelligibility to improve over time thanks to noise adaptation and/or to speech predictability facilitating the recognition of upcoming words. We tested this possibility by presenting normal-hearing human listeners (N = 100; 70 women) with sentences and measuring word recognition as a function of word position in a sentence. Sentences were presented in quiet and in competition with various masker sounds at individualized levels where listeners had 50% probability of recognizing a full sentence. Contrary to expectations, recognition was best for the first word and gradually deteriorated with increasing word position along the sentence. The worsening in recognition was unlikely due to differences in word audibility or word type and was uncorrelated with age or working memory capacity. Using a probabilistic model of word recognition, we show that the worsening effect probably occurs because misunderstandings generate inaccurate predictions that outweigh the benefits from accurate predictions. Analyses also revealed that predictions overruled the potential benefits from noise adaptation. We conclude that although speech predictability can facilitate sentence recognition, it can also result in declines in word recognition as the sentence unfolds because of inaccuracies in prediction.
C1 [Marrufo-Perez, Miriam I.; Eustaquio-Martin, Almudena; Lopez-Poveda, Enrique A.] Univ Salamanca, Inst Neurociencias Castilla & Leon, Calle Pintor Fernando Gallego 1, Salamanca 37007, Spain.
   [Marrufo-Perez, Miriam I.; Eustaquio-Martin, Almudena; Lopez-Poveda, Enrique A.] Univ Salamanca, Inst Invest Biomed Salamanca, Salamanca 37007, Spain.
   [Lopez-Poveda, Enrique A.] Univ Salamanca, Fac Med, Dept Cirugia, Salamanca 37007, Spain.
RP Lopez-Poveda, EA (corresponding author), Univ Salamanca, Inst Neurociencias Castilla & Leon, Calle Pintor Fernando Gallego 1, Salamanca 37007, Spain.
EM ealopezpoveda@usal.es
RI Lopez-Poveda, Enrique A./B-1069-2017; Marrufo-Perez, Miriam
   I/AAA-1206-2019
OI Lopez-Poveda, Enrique A./0000-0002-6886-154X; Marrufo Perez,
   Miriam/0000-0002-8737-8107; Eustaquio-Martin,
   Almudena/0000-0003-2350-5709
FU University of Salamanca; Banco Santander; Spanish Ministry of Economy
   and Competitiveness [BFU201565376-P]; European Regional Development
   FundEuropean Commission
FX We thank Milagros J. Fumero, Patricia B. Lafuente, and Peter T.
   Johannesen for sharing their data, and Jose Manuel Gorospe for
   insightful discussions. We thank the two anonymous reviewers and the
   editor for their excellent comments on earlier versions of this
   manuscript. MIIVIP was supported by a doctoral contract of the
   University of Salamanca and Banco Santander. Work supported by grant
   BFU201565376-P from Spanish Ministry of Economy and Competitiveness and
   the European Regional Development Fund to EALP.
CR Altmann GTM, 2007, J MEM LANG, V57, P502, DOI 10.1016/j.jml.2006.12.004
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   ANSI, 1996, S3 6 SPEC AUD
   Aubanel V, 2014, INT J AUDIOL, V53, P633, DOI 10.3109/14992027.2014.907507
   Bell T S, 2001, J Am Acad Audiol, V12, P514
   Ben-David BM, 2016, HEARING RES, V341, P9, DOI 10.1016/j.heares.2016.07.016
   Ben-David BM, 2012, HEARING RES, V290, P55, DOI 10.1016/j.heares.2012.04.022
   BOOTHROYD A, 1988, J ACOUST SOC AM, V84, P101, DOI 10.1121/1.396976
   Boudewyn MA, 2015, COGN AFFECT BEHAV NE, V15, P607, DOI 10.3758/s13415-015-0340-0
   Cervera T, 2005, ACTA ACUST UNITED AC, V91, P132
   Cervera T, 2007, ACTA ACUST UNITED AC, V93, P1036
   Cervera T, 2015, J PSYCHOLINGUIST RES, V44, P819, DOI 10.1007/s10936-014-9321-7
   DANEMAN M, 1980, J VERB LEARN VERB BE, V19, P450, DOI 10.1016/S0022-5371(80)90312-6
   Dean I, 2005, NAT NEUROSCI, V8, P1684, DOI 10.1038/nn1541
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504
   Dubno JR, 2000, J ACOUST SOC AM, V107, P538, DOI 10.1121/1.428322
   Elosua MR, 1996, PSICOTHEMA, V8, P383
   Ezzatian P, 2012, LANG COGNITIVE PROC, V27, P1056, DOI 10.1080/01690965.2011.591934
   Federmeier KD, 2005, PSYCHOPHYSIOLOGY, V42, P133, DOI 10.1111/j.1469-8986.2005.00274.x
   Federmeier KD, 2002, PSYCHOPHYSIOLOGY, V39, P133, DOI 10.1111/1469-8986.3920133
   Fumero M. J., 2016, THESIS
   GARDNER WG, 1995, J ACOUST SOC AM, V97, P3907, DOI 10.1121/1.412407
   GLASBERG BR, 1989, SCAND AUDIOL, P1
   GRANDA AM, 1966, VISION RES, V6, P507, DOI 10.1016/0042-6989(66)90109-X
   Holube I., 2011, INT S AUD AUD RES IS
   Huarte A, 2008, INT J AUDIOL, V47, P369, DOI 10.1080/14992020801908269
   Johannesen P. T., 2016, TRENDS HEAR, V7, P20
   Johannesen PT, 2019, HEARING RES, V374, P35, DOI 10.1016/j.heares.2019.01.017
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Kamide Y, 2003, J MEM LANG, V49, P133, DOI 10.1016/S0749-596X(03)00023-8
   Kutas M, 2011, HANDBOOK OF PSYCHOLINGUISTIC AND COGNITIVE PROCESSES: PERSPECTIVES IN COMMUNICATION DISORDERS, P119
   Lafuente P. B., 2017, THESIS
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Lopez-Poveda EA, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517730526
   Marrufo-Perez MI, 2018, J NEUROSCI, V38, P4138, DOI 10.1523/JNEUROSCI.0024-18.2018
   Nieuwland MS, 2018, ELIFE, V7, DOI 10.7554/eLife.33468
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Pearsons K. S., 1977, 68012466 US EPA
   Peters RW, 1998, J ACOUST SOC AM, V103, P577, DOI 10.1121/1.421128
   Schoof T, 2015, J ACOUST SOC AM, V138, pEL181, DOI 10.1121/1.4929627
   Smeds K, 2015, J AM ACAD AUDIOL, V26, P183, DOI 10.3766/jaaa.26.2.7
   SPIEGEL MR, 2000, FORMULAS TABLAS MATE
   Van Berkum JJA, 2005, J EXP PSYCHOL LEARN, V31, P443, DOI 10.1037/0278-7393.31.3.443
   Van Petten C, 1999, J EXP PSYCHOL LEARN, V25, P394, DOI 10.1037/0278-7393.25.2.394
   Van Petten C, 2012, INT J PSYCHOPHYSIOL, V83, P176, DOI 10.1016/j.ijpsycho.2011.09.015
   Wicha NYY, 2003, NEUROSCI LETT, V346, P165, DOI 10.1016/S0304-3940(03)00599-8
NR 47
TC 1
Z9 1
U1 2
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD NOV
PY 2019
VL 192
AR 103992
DI 10.1016/j.cognition.2019.06.004
PG 13
WC Psychology, Experimental
SC Psychology
GA IZ6BL
UT WOS:000487166700016
PM 31254890
DA 2021-02-24
ER

PT J
AU Hui, CTJ
   Jain, S
   Watson, CI
AF Hui, C. T. Justine
   Jain, Sahil
   Watson, Catherine, I
TI Effects of sentence structure and word complexity on intelligibility in
   machine-to-human communications
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Dialogue design; Speech perception; Speech synthesis; Machine to human
   communications
ID PHONETIC COMPLEXITY; SPEECH
AB With the rise of robotics and artificial intelligence, good communication between humans and machines becomes more important. However, users with language and hearing disadvantages may find synthetic speech systems to be difficult to understand. In this study, we explore the types of sentence structure and level of word complexity that affect intelligibility of speech in unfamiliar context. Using semantically unpredictable sentences, we found that sentence with more complex syntax such as relative pronouns and question words are harder to comprehend, while on the word level, it is the shorter and simpler words that contribute to misunderstandings. We found that although word frequency affects how well a word is recognised, the effect from the occurring frequency is much less than the effect of how phonetically distinctive the word is. There was also evidence of significant difference between native speakers and non-native speakers on how well they could understand the sentences. These results may help us in designing better dialogue system for machine to human interactions, especially in the healthcare arena, where often users have disadvantages in language and hearing abilities. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Hui, C. T. Justine] Sophia Univ, Grad Sch Sci & Engn, Chiyoda Ku, 7-1 Kioi Cho, Tokyo 1028554, Japan.
   [Jain, Sahil; Watson, Catherine, I] Univ Auckland, Dept Elect & Comp Engn, Auckland 1010, New Zealand.
RP Hui, CTJ (corresponding author), Sophia Univ, Grad Sch Sci & Engn, Chiyoda Ku, 7-1 Kioi Cho, Tokyo 1028554, Japan.
EM justinehui@eagle.sophia.ac.jp
OI Hui, Justine/0000-0003-1411-8328
CR Adank P, 2010, PSYCHOL AGING, V25, P736, DOI 10.1037/a0020054
   Bartneck C, 2004, RO-MAN 2004: 13TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P591, DOI 10.1109/ROMAN.2004.1374827
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Bauer L., 2007, J INT PHON ASSOC, V37, P97, DOI DOI 10.1017/S0025100306002830
   Benoit C, 1996, SPEECH COMMUN, V18, P381, DOI 10.1016/0167-6393(96)00026-X
   Bose A, 2011, J NEUROLINGUIST, V24, P435, DOI 10.1016/j.jneuroling.2011.01.004
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Chen L.-m, 2015, COMPUT LINGUIST, P233
   Coalson GA, 2016, J FLUENCY DISORD, V47, P56, DOI 10.1016/j.jfludis.2015.10.002
   Davies M, 2010, LIT LINGUIST COMPUT, V25, P447, DOI 10.1093/llc/fqq018
   Edlund J, 2008, SPEECH COMMUN, V50, P630, DOI 10.1016/j.specom.2008.04.002
   Ferguson SH, 2010, J AM ACAD AUDIOL, V21, P153, DOI 10.3766/jaaa.21.3.3
   Fong T., 2001, P INT S ROB RES, P255, DOI DOI 10.1055/S-0031-1280784
   Francis A. L., 1999, International Journal of Speech Technology, V3, P15, DOI 10.1023/A:1009622725718
   Fraser M, 2007, BLIZZARD CHALLENGE 2
   Haley KL, 2014, APHASIOLOGY, V28, P320, DOI 10.1080/02687038.2013.855702
   Hazan V, 1998, SPEECH COMMUN, V24, P211, DOI 10.1016/S0167-6393(98)00011-9
   Hioka Y, 2017, P INT 2017, P1283
   Igic A, 2010, P 13 AUSTR INT C SPE, P189
   Jain S, 2015, THESIS
   Jakielski K. J., 1998, THESIS
   King S., 2016, P BLIZZ CHALL WORKSH
   King S, 2014, LOQUENS, V1, DOI 10.3989/loquens.2014.006
   LASS NJ, 1979, LANG SPEECH, V22, P297, DOI 10.1177/002383097902200401
   R Core Team, 2015, R LANG ENV STAT COMP
   Schroder M., 2003, International Journal of Speech Technology, V6, P365, DOI 10.1023/A:1025708916924
   Stoel-Gammon C, 2010, CLIN LINGUIST PHONET, V24, P271, DOI 10.3109/02699200903581059
   Watson C, 2013, P 8 ISCA SPEECH SYNT
   Wolters M., 2007, P INT C PHON SCI AUG, V16, P673
   Wolters M, 2007, P 6 ISCA WORKSH SPEE
NR 30
TC 0
Z9 0
U1 1
U2 18
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD NOV
PY 2019
VL 58
BP 203
EP 215
DI 10.1016/j.csl.2019.03.002
PG 13
WC Computer Science, Artificial Intelligence
SC Computer Science
GA IM0GC
UT WOS:000477663800010
DA 2021-02-24
ER

PT J
AU Saito, Y
   Takamichi, S
   Saruwatari, H
AF Saito, Yuki
   Takamichi, Shinnosuke
   Saruwatari, Hiroshi
TI Vocoder-free text-to-speech synthesis incorporating generative
   adversarial networks using low-/multi-frequency STFT amplitude spectra
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Vocoder-free text-to-speech; Training algorithm; STFT amplitude spectra;
   Generative adversarial networks; Frequency resolution; Frequency warping
AB This paper proposes novel training algorithms for vocoder-free text-to-speech (TTS) synthesis based on generative adversarial networks (GANs) that compensate for short-term Fourier transform (STFT) amplitude spectra in low/multi frequency resolution. Vocoder-free TTS using STFT amplitude spectra can avoid degradation of synthetic speech quality caused by the vocoder-based parameterization used in conventional TTS. Our previous work for the vocoder-based TTS proposed a method for incorporating the GAN-based distribution compensation into acoustic model training to improve synthetic speech quality. This paper extends the algorithm to the vocoder-free TTS and propose a GAN-based training algorithm using low-frequency-resolution amplitude spectra to overcome the difficulty in modeling complicated distribution of the high-dimensional spectra. In the proposed algorithm, amplitude spectra are transformed into low-frequency-resolution amplitude spectra by applying an average pooling function along with a frequency axis; then the GAN-based distribution compensation is performed in the low-frequency-resolution domain. Because the low-frequency-resolution amplitude spectra approximately emulate filter banks, the proposed algorithm is expected to improve synthetic speech quality by reducing differences in spectral envelopes of natural and synthetic speech. Furthermore, various frequency scales that are related to human speech perception (e.g., mel and inverse mel frequency scales) can be introduced to the proposed training algorithm by applying an frequency warping function to amplitude spectra. This paper also proposes a GAN-based training algorithm using multi-frequency-resolution amplitude spectra that uses both low- and original-frequency-resolution amplitude spectra to reduce the differences in not only spectral envelopes but also fine structures. Experimental results demonstrate that (1) GANs using low-frequency-resolution amplitude spectra improve speech quality and work robustly against the settings of the frequency resolution and hyperparameters, (2) in comparison among low-, original-, and multi-frequency-resolution amplitude spectra, the use of low-frequency-resolution ones work best improve the synthetic speech quality, and (3) the use of the inverse mel frequency scale for obtaining low-frequency-resolution amplitude spectra further improves synthetic speech quality. (C) 2019 The Authors. Published by Elsevier Ltd.
C1 [Saito, Yuki; Takamichi, Shinnosuke; Saruwatari, Hiroshi] Univ Tokyo, Grad Sch Informat Sci & Technol, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.
RP Saito, Y (corresponding author), Univ Tokyo, Grad Sch Informat Sci & Technol, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.
EM yuuki_saito@ipc.i.u-tokyo.ac.jp
OI Saito, Yuki/0000-0002-7967-2613
FU SECOM Science and Technology Foundation; JSPS KAKENHIMinistry of
   Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan
   Society for the Promotion of ScienceGrants-in-Aid for Scientific
   Research (KAKENHI) [18J22090]; MIC SCOPE [182103104]
FX Part of this work was supported by SECOM Science and Technology
   Foundation, and JSPS KAKENHI Grant Number 18J22090, and was executed
   under the Commissioned Research of MIC SCOPE (182103104).
CR Chen NX, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2097
   Dauphin Y. N., 2017, P INT C MACH LEARN, P933
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Glorot X., 2011, P 14 INT C ART INT S, P315, DOI DOI 10.1177/1753193410395357
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Inoue S., 2018, P ICASSP BRIGHT UK, P96
   Juvela L, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5679, DOI 10.1109/ICASSP.2018.8461852
   Kaneko T., 2018, P EUSIPCO, P2114
   Kaneko T, 2017, INTERSPEECH, P3389, DOI 10.21437/Interspeech.2017-962
   Kaneko T, 2017, INT CONF ACOUST SPEE, P4910, DOI 10.1109/ICASSP.2017.7953090
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Ling ZH, 2016, INT CONF ACOUST SPEE, P5595, DOI 10.1109/ICASSP.2016.7472748
   McAuley C. D. J., 2018, P ICLR WORKSH VANC C
   Mehri S., 2017, P ICLR TOUL FRANC
   Mirza M., 2014, ARXIV 1411 1784, DOI DOI 10.1017/CB09781139058452
   Morise M, 2016, IEICE T INF SYST, VE99D, P1877, DOI 10.1587/transinf.2015EDP7457
   Oord A. v. d., 2017, ARXIV171110433
   Oord A.v.d., 2016, ARXIV160903499
   Sagisaka Y., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P679, DOI 10.1109/ICASSP.1988.196677
   Sahidullah M, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2087
   Saito Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5299, DOI 10.1109/ICASSP.2018.8461714
   Saito Y, 2018, IEEE-ACM T AUDIO SPE, V26, P84, DOI 10.1109/TASLP.2017.2761547
   Saito Y, 2017, INT CONF ACOUST SPEE, P4900, DOI 10.1109/ICASSP.2017.7953088
   Sotelo J., 2017, P ICLR TOUL FRANC
   Takaki S, 2017, INTERSPEECH, P1128, DOI 10.21437/Interspeech.2017-488
   Takamichi S, 2016, IEEE-ACM T AUDIO SPE, V24, P755, DOI 10.1109/TASLP.2016.2522655
   Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344
   Toda T, 2016, INTERSPEECH, P1632, DOI 10.21437/Interspeech.2016-1066
   Tokuda K, 2013, P IEEE, V101, P1234, DOI 10.1109/JPROC.2013.2251852
   Wang DL, 2018, IEEE-ACM T AUDIO SPE, V26, P1702, DOI 10.1109/TASLP.2018.2842159
   Wu ZZ, 2016, IEEE-ACM T AUDIO SPE, V24, P1255, DOI 10.1109/TASLP.2016.2551865
   Wu ZZ, 2016, IEEE-ACM T AUDIO SPE, V24, P768, DOI 10.1109/TASLP.2016.2526653
   Xu Y, 2015, IEEE-ACM T AUDIO SPE, V23, P7, DOI 10.1109/TASLP.2014.2364452
   ZEN H, 2005, P INTERSPEECH, P93
   Zen HG, 2015, INT CONF ACOUST SPEE, P4470, DOI 10.1109/ICASSP.2015.7178816
   Zen HG, 2013, INT CONF ACOUST SPEE, P7962, DOI 10.1109/ICASSP.2013.6639215
   Zen H, 2009, SPEECH COMMUN, V51, P1039, DOI 10.1016/j.specom.2009.04.004
NR 40
TC 1
Z9 1
U1 1
U2 5
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD NOV
PY 2019
VL 58
BP 347
EP 363
DI 10.1016/j.csl.2019.05.008
PG 17
WC Computer Science, Artificial Intelligence
SC Computer Science
GA IM0GC
UT WOS:000477663800019
OA Other Gold
DA 2021-02-24
ER

PT J
AU Parrila, R
   Dudley, D
   Song, S
   Georgiou, GK
AF Parrila, Rauno
   Dudley, Dean
   Song, Shuang
   Georgiou, George K.
TI A meta-analysis of reading-level match dyslexia studies in consistent
   alphabetic orthographies
SO ANNALS OF DYSLEXIA
LA English
DT Article
DE Consistent orthographies; Developmental dyslexia; Meta-analysis;
   Reading-level match design
ID DOUBLE-DEFICIT HYPOTHESIS; DEVELOPMENTAL DYSLEXIA; PHONOLOGICAL
   AWARENESS; LANGUAGE IMPAIRMENT; SPEECH-PERCEPTION; ALLOPHONIC MODE;
   LITERACY SKILLS; CAUSAL LINK; ENGLISH; DISABILITY
AB We provide a meta-analytic review of all group-comparison studies that used reading-level match design, were conducted in highly consistent European orthographies, included children with dyslexia younger than 13 years of age as participants, and included measures of one or more of the potential causes of dyslexia. We identified 21 studies meeting these criteria that examined one or more of phonological awareness, rapid naming, verbal short-term memory, or auditory temporal processing. A random effects model analysis showed first that the groups were matched imperfectly and they differed significantly in word reading measures not used for matching. Second, there were no significant differences between the individuals with dyslexia and their reading-level-matched controls in rapid naming, phonological memory, and auditory temporal processing. Finally, the analyses for phonological awareness showed a significant effect for comparisons that involved manipulating phonemes but not for tasks that involved manipulating syllables. The results are compatible with phonological deficit theories of dyslexia, but this conclusion is qualified by observed differences in reading skills and sample selection concerns.
C1 [Parrila, Rauno; Dudley, Dean] Macquarie Univ, Dept Educ Studies, Sydney, NSW 2109, Australia.
   [Song, Shuang] Capital Normal Univ, Coll Teacher Educ, Beijing, Peoples R China.
   [Georgiou, George K.] Univ Alberta, Dept Educ Psychol, Edmonton, AB, Canada.
RP Parrila, R (corresponding author), Macquarie Univ, Dept Educ Studies, Sydney, NSW 2109, Australia.
EM rauno.parrila@mq.edu.au; dean.dudley@mq.edu.au; songsh326@gmail.com;
   georgiou@ualberta.ca
OI Parrila, Rauno/0000-0003-4250-8980; Dudley, Dean/0000-0001-5140-9533
CR Ahissar M, 2007, TRENDS COGN SCI, V11, P458, DOI 10.1016/j.tics.2007.08.015
   Babayigit S, 2007, J RES READ, V30, P394, DOI 10.1111/j.1467-9817.2007.00350.x
   BACKMAN J, 1983, READ RES QUART, V18, P466, DOI 10.2307/747381
   BACKMAN JE, 1984, PSYCHOL BULL, V96, P560, DOI 10.1037/0033-2909.96.3.560
   BADIAN NA, 1991, ANN DYSLEXIA, V41, P221, DOI 10.1007/BF02648088
   Bishop DVM, 2004, PSYCHOL BULL, V130, P858, DOI 10.1037/0033-2909.130.6.858
   Bosse ML, 2007, COGNITION, V104, P198, DOI 10.1016/j.cognition.2006.05.009
   BRADLEY L, 1978, NATURE, V271, P746, DOI 10.1038/271746a0
   Brizzolara D, 2006, COGN BEHAV NEUROL, V19, P141, DOI 10.1097/01.wnn.0000213902.59827.19
   BRYANT P, 1986, PSYCHOL BULL, V100, P101
   Bryant P. E., 1980, COGNITIVE PROCESS, P355
   Caravolas M, 2005, J EXP CHILD PSYCHOL, V92, P107, DOI 10.1016/j.jecp.2005.04.003
   Caravolas M, 2005, BL HBK DEV PSYCHOL, P336, DOI 10.1002/9780470757642.ch18
   Carrion-Castillo A, 2013, DYSLEXIA, V19, P214, DOI 10.1002/dys.1464
   Castles A, 2004, COGNITION, V91, P77, DOI 10.1016/S0010-0277(03)00164-1
   Catts H.W., 2017, THEORIES OF READING, P311
   Connor CM, 2017, THEORIES READING DEV, P507
   Constantinidou M, 2009, EDUC PSYCHOL-UK, V29, P171, DOI 10.1080/01443410802613483
   Cuetos F, 2018, SCI STUD READ, V22, P41, DOI 10.1080/10888438.2017.1359273
   Davies R, 2007, ANN DYSLEXIA, V57, P179, DOI 10.1007/s11881-007-0010-1
   Deacon S.H., 2008, SAGE HDB DYSLEXIA, P212, DOI DOI 10.4135/9780857020987.N11
   Diamanti V, 2018, SCI STUD READ, V22, P55, DOI 10.1080/10888438.2017.1338291
   Duval S, 2000, BIOMETRICS, V56, P455, DOI 10.1111/j.0006-341X.2000.00455.x
   Elliott J. G., 2014, THE DYSLEXIA DEBATE, DOI [10.1017/CBO9781139017824, DOI 10.1017/CB09781139017824]
   Ford D. H., 1992, DEV SYSTEMS THEORY I, p[xi, 259]
   Franceschini S, 2012, CURR BIOL, V22, P814, DOI 10.1016/j.cub.2012.03.013
   Gaab N, 2007, RESTOR NEUROL NEUROS, V25, P295
   Georgiou G.K., 2013, HDB LEARNING DISABIL, V2nd, P169
   Georgiou GK, 2008, J EDUC PSYCHOL, V100, P566, DOI 10.1037/0022-0663.100.3.566
   Georgiou GK, 2012, DYSLEXIA, V18, P110, DOI 10.1002/dys.1439
   Georgiou GK, 2012, READ WRIT, V25, P321, DOI 10.1007/s11145-010-9271-x
   Georgiou GK, 2010, CORTEX, V46, P1330, DOI 10.1016/j.cortex.2010.06.006
   Gonzalez JEJ, 1997, READ WRIT, V9, P23
   Goswami U, 2002, ANN DYSLEXIA, V52, P141
   GOSWAMI U, 1989, J READING BEHAV, V21, P413, DOI 10.1080/10862968909547687
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Goswami U, 2011, J COGNITIVE NEUROSCI, V23, P325, DOI 10.1162/jocn.2010.21453
   Gottlieb G., 2006, HDB CHILD PSYCHOL, V1, P210
   Gottlieb Gilbert, 1997, SYNTHESIZING NATURE
   GOTTLIEB MI, 1983, J DEV BEHAV PEDIATR, V4, P1, DOI 10.1097/00004703-198303000-00001
   GUSTAFSON S, 2001, SCI STUD READ, V5, P351, DOI DOI 10.1207/S1532799XSSR0504_03
   Hedges L.V., 1985, STAT METHODS METAANA
   Holopainen L, 2001, J LEARN DISABIL-US, V34, P401, DOI 10.1177/002221940103400502
   Huettig F, 2018, LANG COGN NEUROSCI, V33, P333, DOI 10.1080/23273798.2017.1348528
   JACKSON NE, 1989, J READING BEHAV, V21, P387, DOI 10.1080/10862968909547686
   Gonzalez JEJ, 2002, SPAN J PSYCHOL, V5, P3, DOI 10.1017/S1138741600005783
   Jimenez JE, 2005, APPL PSYCHOLINGUIST, V26, P267, DOI 10.1017/S0142716405050174
   Jimenez JE, 2009, J EXP CHILD PSYCHOL, V103, P167, DOI 10.1016/j.jecp.2009.02.004
   Katzir T., 2004, READ WRIT, V17, P739, DOI DOI 10.1007/S11145-004-2655-Z
   Kirby JR, 2010, READ RES QUART, V45, P341, DOI 10.1598/RRQ.45.3.4
   Laasonen M, 2002, BRAIN LANG, V80, P340, DOI 10.1006/brln.2001.2593
   Landerl K, 1997, COGNITION, V63, P315, DOI 10.1016/S0010-0277(97)00005-X
   Landerl K, 2000, APPL PSYCHOLINGUIST, V21, P243, DOI 10.1017/S0142716400002058
   Loizidou-Ieridou N, 2011, C P FREDERICK U, P357
   Lum JAG, 2013, RES DEV DISABIL, V34, P3460, DOI 10.1016/j.ridd.2013.07.017
   Lundberg I., 1990, SCAND J EDUC RES, V34, P231, DOI DOI 10.1080/0031383900340305
   Lyytinen H, 1998, CHILD NEUROPSYCHOLOG
   MAMEN M, 1986, PSYCHOL BULL, V100, P104, DOI 10.1037/0033-2909.100.1.104
   McBride-Chang C, 2015, OXFORD HDB CHINESE L
   Melby-Lervag M, 2012, PSYCHOL BULL, V138, P322, DOI 10.1037/a0026744
   Nicolson RI, 2001, TRENDS NEUROSCI, V24, P508, DOI 10.1016/S0166-2236(00)01896-8
   Nikolopoulos D, 2003, DYSLEXIA DIFFERENT L, P53
   Nikolopoulos D, 1999, THESIS
   Noordenbos MW, 2013, CLIN NEUROPHYSIOL, V124, P1151, DOI 10.1016/j.clinph.2012.12.044
   Papadopoulos TC, 2009, J LEARN DISABIL-US, V42, P528, DOI 10.1177/0022219409338745
   Parrila R., 2017, THEORIES READING DEV, P333, DOI [10.1075/swll.15.19par, DOI 10.1075/SWLL.15.19PAR]
   Paulesu E, 2001, SCIENCE, V291, P2165, DOI 10.1126/science.1057179
   Pennington BF, 2006, COGNITION, V101, P385, DOI 10.1016/j.cognition.2006.04.008
   Pennington BF, 2012, J ABNORM PSYCHOL, V121, P212, DOI 10.1037/a0025823
   PERFETTI CA, 1987, MERRILL PALMER QUART, V33, P283
   Protopapas A, 2018, BRAIN SCI, V8, DOI 10.3390/brainsci8040061
   Protopapas A, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0090
   Rothstein HR, 2005, PUBLICATION BIAS IN META-ANALYSIS: PREVENTION, ASSESSMENT AND ADJUSTMENTS, P1, DOI 10.1002/0470870168
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   Serrano F, 2008, ANN DYSLEXIA, V58, P81, DOI 10.1007/s11881-008-0013-6
   Seymour PHK, 2003, BRIT J PSYCHOL, V94, P143, DOI 10.1348/000712603321661859
   Seymour PHK, 1980, COGNITIVE PROCESS, P443
   Smythe I., 2004, INT BOOK DYSLEXIA, P1
   Snowling M., 2000, DYSLEXIA
   Soriano M, 2010, ADV LEARN BEHAV DISA, V23, P95, DOI 10.1108/S0735-004X(2010)0000023006
   STANOVICH KE, 1988, J LEARN DISABIL-US, V21, P590, DOI 10.1177/002221948802101003
   Stein J, 1997, TRENDS NEUROSCI, V20, P147, DOI 10.1016/S0166-2236(96)01005-3
   Suranyi Z, 2009, READ WRIT, V22, P41, DOI 10.1007/s11145-007-9102-x
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Talli I, 2016, RES DEV DISABIL, V49-50, P339, DOI 10.1016/j.ridd.2015.12.014
   Tobia V, 2014, READ RES QUART, V49, P437, DOI 10.1002/rrq.77
   Torppa M, 2013, READ WRIT, V26, P1353, DOI 10.1007/s11145-012-9423-2
   van Bergen E, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00346
   Van den Broeck W, 2012, COGNITIVE PSYCHOL, V65, P414, DOI 10.1016/j.cogpsych.2012.06.003
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   VELLUTINO FR, 1989, J READING BEHAV, V21, P361, DOI 10.1080/10862968909547685
   Vidyasagar TR, 2010, TRENDS COGN SCI, V14, P57, DOI 10.1016/j.tics.2009.12.003
   Wimmer H, 1996, J EXP CHILD PSYCHOL, V61, P80, DOI 10.1006/jecp.1996.0004
   WIMMER H, 1993, APPL PSYCHOLINGUIST, V14, P1, DOI 10.1017/S0142716400010122
   Wimmer H, 2010, DYSLEXIA, V16, P283, DOI 10.1002/dys.411
   Wolf M, 1999, J EDUC PSYCHOL, V91, P415, DOI 10.1037/0022-0663.91.3.415
   Ziegler JC, 2003, J EXP CHILD PSYCHOL, V86, P169, DOI 10.1016/S0022-0965(03)00139-5
   Zoubrinetzky R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099337
NR 98
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0736-9387
EI 1934-7243
J9 ANN DYSLEXIA
JI Ann. Dyslexia
PD APR
PY 2020
VL 70
IS 1
BP 1
EP 26
DI 10.1007/s11881-019-00187-5
EA OCT 2019
PG 26
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA LI2VP
UT WOS:000493333200001
PM 31664608
DA 2021-02-24
ER

PT J
AU Carbajal, MJ
   Peperkamp, S
AF Carbajal, Maria Julia
   Peperkamp, Sharon
TI Dual language input and the impact of language separation on early
   lexical development
SO INFANCY
LA English
DT Article
ID SHORT-FORM VERSIONS; VOCABULARY GROWTH; SPEECH-PERCEPTION; EXPOSURE;
   BILINGUALISM; CHILDREN; TODDLERS; INFANTS; MOTHERS
AB We examined properties of the input and the environment that characterize bilingual exposure in 11-month-old infants with a regular exposure to French and an additional language, and their possible effects on receptive vocabulary size. Using a diary method, we found that a majority of the families roughly followed a one-parent-one-language approach. Yet, the two languages co-occurred to various extents within the same half-hour both within and across speakers. We used exploratory correlation analyses to examine potential effects of the dual input on the size of infants' vocabularies. The results revealed some evidence for an impact of language separation by speakers.
C1 [Carbajal, Maria Julia; Peperkamp, Sharon] PSL Univ, Lab Sci Cognit & Psycholinguist, Dept Etud Cognit, ENS,EHESS,CNRS, Paris, France.
RP Carbajal, MJ (corresponding author), Ecole Normale Super, Lab Sci Cognit & Psycholinguist, Dept Etud Cognit, 29 Rue Ulm, F-75005 Paris, France.
EM carbajal.mjulia@gmail.com
RI peperkamp, sharon/V-6994-2017
OI peperkamp, sharon/0000-0001-5985-8878
FU Ecole des Neurosciences de Paris; Agence Nationale de la RechercheFrench
   National Research Agency (ANR)European Commission [ANR-17-CE28-0007-01,
   ANR-17-EURE-0017]
FX Ecole des Neurosciences de Paris; Agence Nationale de la Recherche,
   Grant/Award Number: ANR-17-CE28-0007-01 and ANR-17-EURE-0017
CR Barron-Hauwaert S., 2004, LANGUAGE STRATEGIES
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Bosch L, 2003, LANG SPEECH, V46, P217, DOI 10.1177/00238309030460020801
   Bosch L, 1997, COGNITION, V65, P33, DOI 10.1016/S0010-0277(97)00040-1
   Bosch L, 2014, INT J BEHAV DEV, V38, P317, DOI 10.1177/0165025414532559
   Bridges K, 2014, APPL PSYCHOLINGUIST, V35, P225, DOI 10.1017/S0142716412000379
   Byers-Heinlein K, 2013, BILING-LANG COGN, V16, P32, DOI 10.1017/S1366728912000120
   Cattani A, 2014, INT J LANG COMM DIS, V49, P649, DOI 10.1111/1460-6984.12082
   Clanche F, 2002, LANGUES REGIONALES L
   David A., 2008, INT J BILING EDUC BI, V11, P598, DOI [10.1080/13670050802149200, DOI 10.1080/13670050802149200]
   De Houwer A., 2003, 4 INT S BIL TEMP AZ
   De Houwer A., 2009, BILINGUAL 1 LANGUAGE
   De Houwer A, 2014, INPUT EXPERIENCE BIL, P37
   De Houwer A., 2011, APPL LINGUIST REV, V2, P221, DOI DOI 10.1515/9783110239331.221
   De Houwer A, 2007, APPL PSYCHOLINGUIST, V28, P411, DOI 10.1017/S0142716407070221
   De Houwer A, 2016, J MULTILING MULTICUL, V37, P680, DOI 10.1080/01434632.2015.1127929
   DeAnda S, 2016, J SPEECH LANG HEAR R, V59, P1346, DOI 10.1044/2016_JSLHR-L-15-0234
   Dehouwer A., 2018, BILINGUAL COGNITION, P127
   Dopke S., 2000, BILING-LANG COGN, V3, P209, DOI DOI 10.1017/S1366728900000341
   Fenson L, 2000, APPL PSYCHOLINGUIST, V21, P95, DOI 10.1017/S0142716400001053
   Fernald A, 2013, DEVELOPMENTAL SCI, V16, P234, DOI 10.1111/desc.12019
   Floccia C, 2018, MONOGRAPHS SOC RES C, V83
   Frota S., 2015, 2 JORN COM DES LING
   Garcia-Sierra A, 2011, J PHONETICS, V39, P546, DOI 10.1016/j.wocn.2011.07.002
   Gathercole VCM, 2014, INT J BEHAV DEV, V38, P359, DOI 10.1177/0165025414531676
   Gathercole VCM, 2009, BILING-LANG COGN, V12, P213, DOI 10.1017/S1366728909004015
   Gathercole Virginia C. Mueller, 2002, LANGUAGE LITERACY BI, P175
   Gollan TH, 2015, PSYCHON B REV, V22, P147, DOI 10.3758/s13423-014-0649-7
   Grosjean F., 2010, BILINGUAL
   Hoff E, 2006, DEV REV, V26, P55, DOI 10.1016/j.dr.2005.11.002
   Hoff E, 2002, CHILD DEV, V73, P418, DOI 10.1111/1467-8624.00415
   Hoff E., 2014, INPUT EXPERIENCE BIL, P119, DOI DOI 10.1075/TILAR.13.07HOF
   Hoff E, 2013, SEMIN SPEECH LANG, V34, P215, DOI 10.1055/s-0033-1353448
   Hoff E, 2012, J CHILD LANG, V39, P1, DOI 10.1017/S0305000910000759
   HULK A, 2000, BILINGUALISM LANGUAG, V0003
   HUTTENLOCHER J, 1991, DEV PSYCHOL, V27, P236, DOI 10.1037/0012-1649.27.2.236
   Jackson-Maldonado D, 2013, APPL PSYCHOLINGUIST, V34, P837, DOI 10.1017/S0142716412000045
   Juan-Garau M, 2001, J CHILD LANG, V28, P59, DOI 10.1017/S0305000900004591
   Kern S, 2010, APPROCHE NEUROPSYCHO, V22, P217
   Lyon J., 1996, BECOMING BILINGUAL L
   Marchman VA, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12425
   Muller N, 2001, BILING-LANG COGN, V4, P1, DOI DOI 10.1017/S1366728901000116
   Nakamura J, 2016, INT MULTILING RES J, V10, P308, DOI 10.1080/19313152.2016.1206800
   O'Toole C, 2017, INT J BILING EDUC BI, V20, P124, DOI 10.1080/13670050.2016.1179258
   Pearson BZ, 1997, APPL PSYCHOLINGUIST, V18, P41, DOI 10.1017/S0142716400009863
   Place S, 2016, BILING-LANG COGN, V19, P1023, DOI 10.1017/S1366728915000322
   Place S, 2011, CHILD DEV, V82, P1834, DOI 10.1111/j.1467-8624.2011.01660.x
   Poulin-Dubois D, 2013, INT J BILINGUAL, V17, P57, DOI 10.1177/1367006911431198
   R Core Team, 2017, R LANG ENV STAT COMP
   Ramirez-Esparza N, 2017, CHILD DEV, V88, P1216, DOI 10.1111/cdev.12648
   Ronjat J., 1913, DEV LANGAGE OBSERVE
   Silven M, 2014, INT J BEHAV DEV, V38, P323, DOI 10.1177/0165025414533748
   Sundara M, 2011, J PHONETICS, V39, P505, DOI 10.1016/j.wocn.2010.08.006
   Tamis-LeMonda CS, 2001, CHILD DEV, V72, P748, DOI 10.1111/1467-8624.00313
   Thordardottir E, 2011, INT J BILINGUAL, V15, P426, DOI 10.1177/1367006911403202
   Weisleder A, 2013, PSYCHOL SCI, V24, P2143, DOI 10.1177/0956797613488145
   Wong Fillmore L., 1991, EARLY CHILDHOOD RES, V6, P323, DOI DOI 10.1016/S0885-2006(05)80059-6
   Yamamoto Masayo, 2001, LANGUAGE USE INTERLI
NR 58
TC 0
Z9 0
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1525-0008
EI 1532-7078
J9 INFANCY
JI Infancy
PD JAN
PY 2020
VL 25
IS 1
BP 22
EP 45
DI 10.1111/infa.12315
EA OCT 2019
PG 24
WC Psychology, Developmental
SC Psychology
GA JZ7GP
UT WOS:000493079700001
PM 32749052
DA 2021-02-24
ER

PT J
AU Gaurav, V
   Sharma, S
   Singh, S
AF Gaurav, Vishal
   Sharma, Shalabh
   Singh, Satinder
TI Effects of Age at Cochlear Implantation on Auditory Outcomes in Cochlear
   Implant Recipient Children
SO INDIAN JOURNAL OF OTOLARYNGOLOGY AND HEAD & NECK SURGERY
LA English
DT Article
DE Cochlear implantation; Auditory perception outcome; Age at cochlear
   implantation; Categories of auditory performance; Meaningful auditory
   integration scale; Sensorineural hearing loss
ID CONGENITALLY DEAF-CHILDREN; SPEECH-PERCEPTION; PERFORMANCE
AB Cochlear implantation (CI) is used for rehabilitation of children with bilateral severe to profound sensorineural hearing loss. Recently, treatment of such children has been influenced by diagnostic technological advances. Infants and toddlers are now increasingly included for CI. The primary aim of this study was to determine the effects of 'age at CI' on CI outcome. The primary aim of this study was to determine the effects of 'age at CI' on CI outcome. In this prospective study at a tertiary care centre, we evaluated 50 cochlear implanted children from October 2011 to March 2013. The case group consists of 15 (30%) children who underwent CI at more than 5 years of age and control group consisted of 35 (70%) children who underwent CI at less than or equal to 5 years age. All patients received auditory and speech rehabilitation and we evaluated their auditory perception outcomes 1 year post CI, the children were assessed by categories of auditory performance (CAP) and meaningful auditory integration scale (MAIS) tests. There were significantly improved mean auditory perception outcomes (increase of 12.29% in CAP, and 14.05% in MAIS scores) at 1 year post CI in CI recipients of age group '5 years or less' in comparison to those who underwent CI at 'more than 5 years of age'. However, children of 'more than 5 years' age at CI, mean CAP and MAIS scores were still more than 80% of maximum achievable CAP and MAIS scores. In this study, CI recipient children who were implanted at less than or equal to 5 years of age were found to have significantly improved auditory perception outcome at 1 year post CI. Hence, it appears preferable to provide CI early. However, even in children who underwent CI at more than 5 years of age, there was substantial improvement in auditory perception outcomes and CI was still helpful in these children. Hence, knowledge of 'age at CI' can provide reasonable help in predicting the auditory perception outcome and optimal counselling of families of CI candidates.
C1 [Gaurav, Vishal; Sharma, Shalabh; Singh, Satinder] Sir Ganga Ram Hosp, New Delhi 110060, India.
RP Gaurav, V (corresponding author), Sir Ganga Ram Hosp, New Delhi 110060, India.
EM doctorvishalgaurav@gmail.com; drshalabh68@yahoo.co.in;
   satinders201@gmail.com
OI Gaurav, Vishal/0000-0002-2786-2319
CR Archbold S, 1995, Ann Otol Rhinol Laryngol Suppl, V166, P312
   Arisi E, 2010, OTOLARYNG HEAD NECK, V142, P804, DOI 10.1016/j.otohns.2010.02.016
   Blamey P, 1996, Audiol Neurootol, V1, P293
   Colletti V, 2005, LARYNGOSCOPE, V115, P445, DOI 10.1097/01.mlg.0000157838.61497.e7
   Connor CM, 2006, EAR HEARING, V27, P628, DOI 10.1097/01.aud.0000240640.59205.42
   Dowell RC, 1997, COCHLEAR IMPLANTATIO, P205
   Fisher RA, 1950, STAT METHODS RES WOR
   Government of India. Ministry of health and family welfare, 2009, 64692003CGHSRH GOV I
   Government of India. Ministry of social justice and empowerment, 2015, 4282014DDI GOV IND M
   Hammes DM, 2002, ANN OTO RHINOL LARYN, V111, P74, DOI 10.1177/00034894021110S516
   Holt RF, 2008, EAR HEARING, V29, P492, DOI 10.1097/AUD.0b013e31816c409f
   Miyamoto RT, 2008, ACTA OTO-LARYNGOL, V128, P373, DOI 10.1080/00016480701785012
   MIYAMOTO RT, 1994, LARYNGOSCOPE, V104, P1120
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Osberger MJ, 1998, AM J OTOL, V19, P152
   Roland JT, 2009, LARYNGOSCOPE, V119, P2205, DOI 10.1002/lary.20489
   Sarant JZ, 2001, EAR HEARING, V22, P18, DOI 10.1097/00003446-200102000-00003
   Tajudeen BA, 2010, OTOL NEUROTOL, V31, P1254, DOI 10.1097/MAO.0b013e3181f2f475
   TYEMURRAY N, 1995, J SPEECH HEAR RES, V38, P327, DOI 10.1044/jshr.3802.327
   Waltzman SB, 2005, PEDIATRICS, V116, pE487, DOI 10.1542/peds.2005-0282
   Waltzmann SB, 2002, OTOL NEUROTOL, V23, P333, DOI 10.1097/00129492-200205000-00018
   Zimmerman-Phillips S., 2001, INFANT TODDLER MEANI
NR 22
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER INDIA
PI NEW DELHI
PA 7TH FLOOR, VIJAYA BUILDING, 17, BARAKHAMBA ROAD, NEW DELHI, 110 001,
   INDIA
SN 2231-3796
EI 0973-7707
J9 INDIAN J OTOLARYNGOL
JI Indian J. Otolaryngol. Head Neck Surg.
PD MAR
PY 2020
VL 72
IS 1
BP 79
EP 85
DI 10.1007/s12070-019-01753-4
EA OCT 2019
PG 7
WC Surgery
SC Surgery
GA KU6OH
UT WOS:000492569800001
PM 32158661
DA 2021-02-24
ER

PT J
AU Reinisch, E
   Penney, J
AF Reinisch, Eva
   Penney, Joshua
TI The role of vowel length and glottalization in German learners'
   perception of the English coda stop voicing contrast
SO LABORATORY PHONOLOGY
LA English
DT Article
DE second language learning; speech perception; acoustic cues;
   glottalization; word-final stop voicing
ID WORD-FINAL ENGLISH; INCOMPLETE NEUTRALIZATION; DURATION; CUES; SPEAKERS;
   GLOTTALISATION; EXPERIENCE; CONSONANTS; PHONEME
AB In German, the voicing contrast in word-final stops is neutralized towards the voiceless sound. We tested how German learners of English use in perception two phonetic cues to this contrast in English: the duration of the vowel preceding the stop and the partial glottalization of this vowel. While a longer vowel cues the voiced sound of the contrast, glottalization enhances the voiceless sound, which should be 'easy' for learners as word-finally it is the default in German. We asked whether cueing the 'easy' sound would nevertheless affect learners' word identification. Learners categorized two English minimal pairs along vowel duration continua with either a fully modal vowel or the last 25% of the vowel glottalized. Learners gave more voiced-stop responses as vowel duration increased. They also used glottalization by giving fewer voiced-stop responses for the glottalized continua. A second experiment demonstrated that the glottalization was not merely perceived as a change in the vowel+closure duration ratio. When the glottalized portion of the vowels was set to silence learners gave even fewer voiced-stop responses than in the glottalized condition. Results suggest that learners can use a phonetic cue to a second language sound contrast even if it enhances the familiar 'easy' sound.
C1 [Reinisch, Eva] Ludwig Maximilians Univ Munchen, Inst Phonet & Speech Proc, Munich, Germany.
   [Reinisch, Eva] Austrian Acad Sci, Acoust Res Inst, Vienna, Austria.
   [Penney, Joshua] Macquarie Univ, Ctr Language Sci, Dept Linguist, Sydney, NSW, Australia.
RP Reinisch, E (corresponding author), Ludwig Maximilians Univ Munchen, Inst Phonet & Speech Proc, Munich, Germany.; Reinisch, E (corresponding author), Austrian Acad Sci, Acoust Res Inst, Vienna, Austria.
EM Eva.Reinisch@oeaw.ac.at
RI ; Reinisch, Eva/R-1646-2016
OI Penney, Joshua/0000-0001-5942-3508; Reinisch, Eva/0000-0002-1400-5473
FU German Research Foundation (DFG)German Research Foundation (DFG)
   [RE3047/1-1]; Australian Government Endeavour Research
   FellowshipAustralian GovernmentDepartment of Industry, Innovation and
   Science [6331_2018]; Linguistics in Open Access foundation
FX This project was funded by a grant from the German Research Foundation
   (DFG; grant nr. RE3047/1-1) to the first author and an Australian
   Government Endeavour Research Fellowship (6331_2018) to the second
   author. We would like to thank Rosa Hufschmidt for running the on-site
   participants and Christoph Draxler for help with the web experiment. We
   would like to thank Miquel Llompart for comments on an earlier version
   of the manuscript.; We also thank the Linguistics in Open Access
   foundation (https://www.lingoa.eu/) for financial support of open access
   publication of Laboratory Phonology.
CR Amengual M, 2016, APPL PSYCHOLINGUIST, V37, P1221, DOI 10.1017/S0142716415000557
   Baker W, 2010, BILING-LANG COGN, V13, P263, DOI 10.1017/S136672890999006X
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bent T, 2008, PHONETICA, V65, P131, DOI 10.1159/000144077
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bohn O.-S., 1992, STUDIES 2 LANGUAGE A, V14, P131, DOI DOI 10.1017/S0272263100010792
   Broersma M, 2005, J ACOUST SOC AM, V117, P3890, DOI 10.1121/1.1906060
   Brunner J., 2011, P 17 INT C PHON SCI, P376
   CHEN M, 1970, PHONETICA, V22, P129, DOI 10.1159/000259312
   Chong AJ, 2018, LAB PHONOL, V9, DOI 10.5334/labphon.70
   Cox F., 2011, P 17 INT C PHON SCI
   CROWTHER CS, 1992, J ACOUST SOC AM, V92, P711, DOI 10.1121/1.403996
   Darcy I, 2013, MENT LEX, V8, P372, DOI 10.1075/ml.8.3.06dar
   Diaz B, 2012, LEARN INDIVID DIFFER, V22, P680, DOI 10.1016/j.lindif.2012.05.005
   Docherty G., 1999, P 14 INT C PHON SCI, P1037
   Docherty G. J., 1992, TIMING VOICING BRIT, DOI [10.1515/9783110872637, DOI 10.1515/9783110872637]
   Draxler C., 2014, P LREC REYKJ IC, P235
   Eger NA, 2019, STUD SECOND LANG ACQ, V41, P179, DOI 10.1017/S0272263117000377
   Eger NA, 2019, J EXP PSYCHOL LEARN, V45, P552, DOI 10.1037/xlm0000599
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   FLEGE JE, 1989, J ACOUST SOC AM, V86, P1684, DOI 10.1121/1.398599
   FLEGE JE, 1981, LANG SPEECH, V24, P125, DOI 10.1177/002383098102400202
   FLEGE JE, 1989, J PHONETICS, V17, P299, DOI 10.1016/S0095-4470(19)30446-2
   FLEGE JE, 1987, J PHONETICS, V15, P203, DOI 10.1016/S0095-4470(19)30548-0
   FOURAKIS M, 1984, PHONETICA, V41, P140, DOI 10.1159/000261720
   FOWLER CA, 1992, J PHONETICS, V20, P143, DOI 10.1016/S0095-4470(19)30244-X
   Garellek M., 2011, UCLA WORKING PAPERS, V109, P31
   Garellek M, 2015, J ACOUST SOC AM, V137, P822, DOI 10.1121/1.4906155
   Gordeeva OB, 2013, J INT PHON ASSOC, V43, P249, DOI 10.1017/S0025100313000200
   Hayes-Harb R, 2008, J PHONETICS, V36, P664, DOI 10.1016/j.wocn.2008.04.002
   Hejna Misa, 2015, P 18 INT C PHON SCI
   Huffman MK, 2005, J PHONETICS, V33, P335, DOI 10.1016/j.wocn.2005.02.004
   Iverson P., 2007, J ACOUST SOC AM, V121, P3072, DOI [10.1121/1.4781875, DOI 10.1121/1.4781875]
   John T., 2007, P INT 2007 ANTW BELG, P986
   Keyser SJ, 2006, LANGUAGE, V82, P33, DOI 10.1353/lan.2006.0051
   KLATT DH, 1976, J ACOUST SOC AM, V59, P1208, DOI 10.1121/1.380986
   Kleber F, 2010, J PHONETICS, V38, P185, DOI 10.1016/j.wocn.2009.10.001
   Kohler K. J., 2000, P 5 SEM SPEECH PROD, P89
   Kohler K. J., 2001, TRAV CERCLE LING COP, V31, P174
   KOHLER KJ, 1977, ARBEITSBER I PHONET, V8, P30
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   Lisker L., 1974, GLOSSA, V8, P233
   Llompart M, 2019, LANG SPEECH, V62, P594, DOI 10.1177/0023830918803978
   Llompart M, 2017, J EXP PSYCHOL HUMAN, V43, P1040, DOI 10.1037/xhp0000383
   Malisz Z, 2013, LAB PHONOL, V4, P119, DOI 10.1515/lp-2013-0006
   MATHISEN AG, 1999, URBAN VOICES ACCENT, P107
   Mitterer H, 2017, LANG COGN NEUROSCI, V32, P1133, DOI 10.1080/23273798.2017.1286361
   Mitterer H, 2015, J MEM LANG, V85, P116, DOI 10.1016/j.jml.2015.08.005
   Nicenboim B, 2018, J PHONETICS, V70, P39, DOI 10.1016/j.wocn.2018.06.001
   O'Dell Michael, 1983, J ACOUST SOC AM, V73, pS31, DOI [10.1121/1.2020331, DOI 10.1121/1.2020331]
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Penney J., EFFECTS GLOTTA UNPUB
   Penney J, 2018, INTERSPEECH, P1422, DOI 10.21437/Interspeech.2018-1677
   Penney J, 2018, J PHONETICS, V66, P161, DOI 10.1016/j.wocn.2017.10.001
   Pierrehumbert J, 1995, VOCAL FOLD, P39
   Piroth HG, 2004, J PHONETICS, V32, P81, DOI 10.1016/S0095-4470(03)00008-1
   Pompino-Marshall B., 2010, ZAS PAPERS LINGUISTI, V52, P1
   PORT R, 1989, J PHONETICS, V17, P257, DOI 10.1016/S0095-4470(19)30444-9
   PORT RF, 1985, J PHONETICS, V13, P455, DOI 10.1016/S0095-4470(19)30797-1
   Port Robert, 1981, J ACOUSTICAL SOC S1, V70, pS13, DOI [10.1121/1.24018716, DOI 10.1121/1.2018716]
   R Core Team, 2018, R LANG ENV STAT COMP
   RAPHAEL LJ, 1981, PHONETICA, V38, P126, DOI 10.1159/000260019
   RAPHAEL LJ, 1975, J SPEECH HEAR RES, V18, P389, DOI 10.1044/jshr.1803.389
   RAPHAEL LJ, 1972, J ACOUST SOC AM, V51, P1296, DOI 10.1121/1.1912974
   Roach P. J., 1973, J INT PHON ASSOC, V3, P10, DOI [10.1017/S0025100300000633, DOI 10.1017/S0025100300000633]
   Roettger TB, 2014, J PHONETICS, V43, P11, DOI 10.1016/j.wocn.2014.01.002
   Sebastian-Galles N, 2005, TWENTY-FIRST CENTURY PSYCHOLINGUISTICS: FOUR CORNERSTONES, P279
   Sebastian-Galles N, 2005, J MEM LANG, V52, P240, DOI 10.1016/j.jml.2004.11.001
   Seyfarth S., 2015, P 18 INT C PHON SCI
   Smith BL, 2012, J PHONETICS, V40, P129, DOI 10.1016/j.wocn.2011.09.004
   Smith BL, 2009, J PHONETICS, V37, P257, DOI 10.1016/j.wocn.2009.03.001
   Tollfree Laura, 1999, URBAN VOICES ACCENT, P163
   WESTBURY JR, 1986, J LINGUIST, V22, P145, DOI 10.1017/S0022226700010598
   Wiese R., 1996, PHONOLOGY GERMAN
NR 77
TC 2
Z9 2
U1 0
U2 0
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD OCT 24
PY 2019
VL 10
IS 1
AR 18
DI 10.5334/labphon.176
PG 26
WC Linguistics; Language & Linguistics
SC Linguistics
GA JG6RD
UT WOS:000492197800001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Inceoglu, S
AF Inceoglu, Solene
TI Individual Differences in L2 Speech Perception: The Role of Phonological
   Memory and Lipreading Ability
SO MODERN LANGUAGE JOURNAL
LA English
DT Article
DE L2 speech perception; French; phonological memory; lipreading ability;
   psycholinguistics
ID SHORT-TERM-MEMORY; WORKING-MEMORY; VISUAL CUES; AUDIOVISUAL
   IDENTIFICATION; 2ND-LANGUAGE SPEECH; HEARING LIPS; COMPREHENSION;
   SPEAKERS; OLDER; CAPACITY
AB The current study investigated the effects of individual differences in lipreading ability, working memory (WM), and phonological short-term memory (PSTM) on second language (L2) speech perception. An L2 French vowel identification task was administered to 32 Australian English learners of French in audiovisual, audio-only, and visual-only conditions. Participants also completed tasks measuring their first language (L1) lipreading ability at the phoneme, word, and sentence level; a listening span task assessing their WM capacity; and a nonword repetition task assessing their PSTM. Overall, speech perception was significantly better in the audiovisual and audio-only conditions, and large individual variability was observed in the lipreading, WM, and PSTM tasks. Results revealed a significant effect of PSTM on vowel perception scores in all modalities of presentation, but no effect of WM capacity was found. In addition, lipreading ability at the word level was found to be a predictor of accurate L2 vowel perception in the visual modality.
C1 [Inceoglu, Solene] Australian Natl Univ, Sch Literature Languages & Linguist, Baldessin Precinct Bldg, Canberra, ACT 2601, Australia.
RP Inceoglu, S (corresponding author), Australian Natl Univ, Sch Literature Languages & Linguist, Baldessin Precinct Bldg, Canberra, ACT 2601, Australia.
EM Solene.Inceoglu@anu.edu.au
OI Inceoglu, Solene/0000-0002-9571-4684
FU College of Arts and Social Sciences at the Australian National
   University
FX This study was funded by a Research Development grant from the College
   of Arts and Social Sciences at the Australian National University. I am
   grateful to my participants and to Zilan (Connie) Wu and Teresa Neeman
   for assistance with statistical analyses. I would like to thank the
   Editor and two anonymous reviewers for their valuable comments and
   suggestions on the manuscript. Any remaining inadequacies are my own.
CR Aliaga-Garcia C, 2011, POZ STUD CONTEMP LIN, V47, P1, DOI 10.2478/psicl-2011-0002
   Alm M, 2009, J ACOUST SOC AM, V126, P377, DOI 10.1121/1.3129508
   Anderson S. L., 2012, THESIS
   Andersson U., 2001, J DEAF STUD DEAF EDU, V6, P103, DOI DOI 10.1093/DEAFED/6.2.103
   Arnold P, 2001, BRIT J PSYCHOL, V92, P339, DOI 10.1348/000712601162220
   Auer ET, 2007, J SPEECH LANG HEAR R, V50, P1157, DOI 10.1044/1092-4388(2007/080)
   Baddeley A, 1998, PSYCHOL REV, V105, P158, DOI 10.1037/0033-295X.105.1.158
   Baddeley A, 2003, NAT REV NEUROSCI, V4, P829, DOI 10.1038/nrn1201
   Baddeley A, 2000, TRENDS COGN SCI, V4, P417, DOI 10.1016/S1364-6613(00)01538-2
   Baddeley A., 1974, PSYCHOL LEARN MOTIV, V8, P47, DOI [10.1016/S0079-7421(08)60452-1, DOI 10.1016/S0079-7421(08)60452-1]
   Baddeley A.D., 2007, WORKING MEMORY THOUG
   Baddeley A. D, 1986, WORKING MEMORY
   BENOI C, 1994, J SPEECH HEAR RES, V37, P1195, DOI 10.1044/jshr.3705.1195
   BENOIT C, 1992, TALKING MACHINES THE, P485
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boothroyd A., 1985, RC110 CIT U NY
   Cedrus, 2015, SUPERLAB 5 0
   Cervino-Povedano E., 2010, ACHIEVEMENTS PERSPEC, P83
   Cheung H, 1996, DEV PSYCHOL, V32, P867, DOI 10.1037/0012-1649.32.5.867
   Coughlin CE, 2013, APPL PSYCHOLINGUIST, V34, P615, DOI 10.1017/S0142716411000890
   Council of Europe, 2001, COMM EUR FRAM REF LA
   DANEMAN M, 1980, J VERB LEARN VERB BE, V19, P450, DOI 10.1016/S0022-5371(80)90312-6
   DeKeyser R, 2012, LANG LEARN, V62, P189, DOI 10.1111/j.1467-9922.2012.00712.x
   Erdener D, 2013, J EXP CHILD PSYCHOL, V116, P120, DOI 10.1016/j.jecp.2013.03.003
   Feld JE, 2009, J SPEECH LANG HEAR R, V52, P1555, DOI 10.1044/1092-4388(2009/08-0137)
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   French LM, 2008, APPL PSYCHOLINGUIST, V29, P463, DOI 10.1017/S0142716408080211
   French LM, 2006, PHONOLOGICAL WORKING
   Gathercole SE, 2006, APPL PSYCHOLINGUIST, V27, P513, DOI 10.1017/S0142716406060383
   Grey S, 2015, MOD LANG J, V99, P137, DOI 10.1111/modl.12190
   Grey S, 2015, LEARN INDIVID DIFFER, V38, P44, DOI 10.1016/j.lindif.2015.01.019
   Hardison DM, 2003, APPL PSYCHOLINGUIST, V24, P495, DOI 10.1017/S0142716403000250
   Hazan V, 2006, J ACOUST SOC AM, V119, P1740, DOI 10.1121/1.2166611
   Hazan V, 2005, SPEECH COMMUN, V47, P360, DOI 10.1016/j.specom.2005.04.007
   Heikkila J, 2017, J SPEECH LANG HEAR R, V60, P485, DOI 10.1044/2016_JSLHR-S-15-0071
   Hirata Y, 2010, J SPEECH LANG HEAR R, V53, P298, DOI 10.1044/1092-4388(2009/08-0243)
   Inceoglu S., 2019, P 10 PRON 2 LANG LEA, P147
   Inceoglu S, 2016, APPL PSYCHOLINGUIST, V37, P1175, DOI 10.1017/S0142716415000533
   Irwin JR, 2006, PERCEPT PSYCHOPHYS, V68, P582, DOI 10.3758/BF03208760
   Isaacs T, 2011, APPL PSYCHOLINGUIST, V32, P113, DOI 10.1017/S0142716410000317
   Jesse A, 2010, PSYCHON B REV, V17, P323, DOI 10.3758/PBR.17.3.323
   Juffs A, 2011, LANG TEACHING, V44, P137, DOI 10.1017/S0261444810000509
   Kissling EM, 2014, CAN MOD LANG REV, V70, P532, DOI 10.3138/cmlr.2161
   Kondo A., 2012, JALT 2011 C P, P535
   Kormos J, 2008, BILING-LANG COGN, V11, P261, DOI 10.1017/S1366728908003416
   Kroll J.F., 2002, SECOND LANG RES, V18, P137, DOI DOI 10.1191/0267658302SR2010A
   Lengeris A, 2014, INTERSPEECH, P534
   Levy ES, 2008, J PHONETICS, V36, P141, DOI 10.1016/j.wocn.2007.03.001
   Lidestam B, 1999, SCAND AUDIOL, V28, P211, DOI 10.1080/010503999424644
   Linck JA, 2014, PSYCHON B REV, V21, P861, DOI 10.3758/s13423-013-0565-2
   LISKER L, 1992, LANG SPEECH, V35, P391, DOI 10.1177/002383099203500402
   Lyxell B, 2000, BRIT J EDUC PSYCHOL, V70, P505, DOI 10.1348/000709900158272
   MacKay IRA, 2001, PHONETICA, V58, P103, DOI 10.1159/000028490
   Mackey A, 2012, LANG LEARN, V62, P704, DOI 10.1111/j.1467-9922.2011.00649.x
   Mackey A, 2010, LANG LEARN, V60, P501, DOI 10.1111/j.1467-9922.2010.00565.x
   Masoura EV, 1999, INT J PSYCHOL, V34, P383, DOI 10.1080/002075999399738
   MASSARO D, 2003, EUROSPEECH, P2249
   Massaro D. W., 1998, PERCEIVING TALKING F
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mills A. E., 1987, HEARING EYE PSYCHOL, P145
   Nagle C., 2013, SEL P 2011 2 LANG RE, P148
   Navarra J, 2007, PSYCHOL RES-PSYCH FO, V71, P4, DOI 10.1007/s00426-005-0031-5
   O'Brien I, 2007, STUD SECOND LANG ACQ, V29, P557, DOI 10.1017/S027226310707043X
   O'Brien I, 2006, APPL PSYCHOLINGUIST, V27, P377, DOI 10.1017/S0142716406060322
   Pereira Y. I., 2013, THESIS
   Picou EM, 2011, J SPEECH LANG HEAR R, V54, P1416, DOI 10.1044/1092-4388(2011/10-0154)
   POLKA L, 1995, J ACOUST SOC AM, V97, P1286, DOI 10.1121/1.412170
   Reisberg D, 1987, HEARING EYE PSYCHOL, P97
   Revesz A, 2012, LANG LEARN, V62, P93, DOI 10.1111/j.1467-9922.2011.00690.x
   Robert-Ribes J, 1998, J ACOUST SOC AM, V103, P3677, DOI 10.1121/1.423069
   Robinson P., 2005, ANNU REV APPL LINGUI, V25, P46, DOI DOI 10.1017/S0267190505000036
   Rosenblum LD, 2005, BLACKW HBK LINGUIST, P51, DOI 10.1002/9780470757024.ch3
   Rosenblum LD, 1996, J SPEECH HEAR RES, V39, P1159, DOI 10.1044/jshr.3906.1159
   Safranova E., 2012, P 22 EUROSLA, P384
   Sagarra N, 2010, LINGUA, V120, P2022, DOI 10.1016/j.lingua.2010.02.004
   Sawyer M., 2001, COGNITION 2 LANGUAGE, p319e353, DOI DOI 10.1017/CBO9781139524780.013
   Sawyer M, 1992, STUDIES 2 LANGUAGE A, V14, P25, DOI DOI 10.1017/S0272263100010457
   Serafini EJ, 2016, STUD SECOND LANG ACQ, V38, P607, DOI 10.1017/S0272263115000327
   SERVICE E, 1993, J MEM LANG, V32, P608, DOI 10.1006/jmla.1993.1031
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   Speciale G, 2004, APPL PSYCHOLINGUIST, V25, P293, DOI 10.1017/S0142716404001146
   Stein B. E., 1993, MERGING SENSES
   Strand J, 2014, J SPEECH LANG HEAR R, V57, P2322, DOI 10.1044/2014_JSLHR-H-14-0059
   Strange W., 1992, SPEECH PERCEPTION PR, P198
   Sueyoshi A, 2005, LANG LEARN, V55, P661, DOI 10.1111/j.0023-8333.2005.00320.x
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1984, Q J EXP PSYCHOL-A, V36, P51, DOI 10.1080/14640748408401503
   Tye-Murray Nancy, 2007, Trends Amplif, V11, P233, DOI 10.1177/1084713807307409
   Tye-Murray N, 2008, INT J AUDIOL, V47, pS31, DOI 10.1080/14992020802301662
   Valkenier B, 2012, J SPEECH LANG HEAR R, V55, P1788, DOI 10.1044/1092-4388(2012/11-0227)
   Wang Y, 2008, J ACOUST SOC AM, V124, P1716, DOI 10.1121/1.2956483
   Wang Y, 2009, J PHONETICS, V37, P344, DOI 10.1016/j.wocn.2009.04.002
   Waters GS, 1996, Q J EXP PSYCHOL-A, V49, P51, DOI 10.1080/027249896392801
   Wen Z., 2016, WORKING MEMORY 2 LAN
   Williams J. N., 2012, ROUTLEDGE HDB 2 LANG, P427
   Williams JN, 2003, LANG LEARN, V53, P67, DOI 10.1111/1467-9922.00211
   Winke P, 2013, MOD LANG J, V97, P109, DOI 10.1111/j.1540-4781.2013.01428.x
NR 100
TC 1
Z9 1
U1 4
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0026-7902
EI 1540-4781
J9 MOD LANG J
JI Mod. Lang. J.
PD DEC
PY 2019
VL 103
IS 4
BP 782
EP 799
DI 10.1111/modl.12591
EA OCT 2019
PG 18
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA JO2EI
UT WOS:000492284200001
DA 2021-02-24
ER

PT J
AU Gokula, R
   Sharma, M
   Cupples, L
   Valderrama, JT
AF Gokula, Rakshita
   Sharma, Mridula
   Cupples, Linda
   Valderrama, Joaquin T.
TI Comorbidity of Auditory Processing, Attention, and Memory in Children
   With Word Reading Difficulties
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE word reading difficulty; auditory processing; cognition; digit memory;
   receptive language
ID FREQUENCY DISCRIMINATION; WORKING-MEMORY; LANGUAGE IMPAIRMENT; SELECTIVE
   ATTENTION; COGNITIVE-ABILITIES; BEHAVIORAL EVIDENCE; SPEECH-PERCEPTION;
   DEFICITS; DISORDER; DISABILITY
AB Objectives: To document the auditory processing, visual attention, digit memory, phonological processing, and receptive language abilities of individual children with identified word reading difficulties.
   Design: Twenty-five children with word reading difficulties and 28 control children with good word reading skills participated. All children were aged between 8 and 11 years, with normal hearing sensitivity and typical non-verbal intelligence. Both groups of children completed a test battery designed to assess their auditory processing, visual attention, digit memory, phonological processing, and receptive language.
   Results: When compared to children who were good readers, children with word reading difficulties obtained significantly lower average scores on tests of auditory processing, including the frequency pattern test, gaps in noise, frequency discrimination, Dichotic Digit difference Test, and Listening in Spatialized Noise. The two groups did not differ on the discrimination measures of sinusoidal amplitude modulation or iterated rippled noise. The results from children with word reading difficulties showed that 5 children (20%) had comorbid deficits in auditory processing, visual attention, and backward digit memory; whereas 12 children (48%) had comorbid auditory processing and visual attention deficits only, and 2 children (8%) had comorbid deficits in auditory processing and digit memory; the remaining children had only auditory processing, visual attention, or digit memory deficits.
   Conclusion: The current study highlights the general co-existence of auditory processing, memory, and visual attention deficits in children with word reading difficulties. It is also noteworthy, however, that only one fifth of the current cohort had deficits across all measured tasks. Hence, our results also show the significant individual variability inherent in children with word reading difficulties.
C1 [Gokula, Rakshita; Sharma, Mridula; Cupples, Linda; Valderrama, Joaquin T.] Macquarie Univ, Dept Linguist, Sydney, NSW, Australia.
   [Gokula, Rakshita; Sharma, Mridula; Valderrama, Joaquin T.] HEARing Cooperat Res Ctr, Melbourne, Vic, Australia.
   [Sharma, Mridula; Cupples, Linda] Macquarie Univ, Ctr Language Sci, Sydney, NSW, Australia.
   [Valderrama, Joaquin T.] Natl Acoust Labs, Sydney, NSW, Australia.
RP Gokula, R (corresponding author), Macquarie Univ, Dept Linguist, Sydney, NSW, Australia.; Gokula, R (corresponding author), HEARing Cooperat Res Ctr, Melbourne, Vic, Australia.
EM rakshita.gokula@gmail.com
OI Cupples, Linda/0000-0003-3659-1642; Sharma, Mridula/0000-0002-0448-6429
FU HEARing CRC under the Australian Government's Cooperative Research
   Centres (CRC) ProgramAustralian GovernmentDepartment of Industry,
   Innovation and ScienceCooperative Research Centres (CRC) Programme
FX The authors acknowledge the financial support of the HEARing CRC,
   established under the Australian Government's Cooperative Research
   Centres (CRC) Program. The CRC Program supports industry-led
   collaborations between industry, researchers and the community.
CR Adlard A, 1998, Q J EXP PSYCHOL-A, V51, P153
   Allen P, 2014, INT J PEDIATR OTORHI, V78, P198, DOI 10.1016/j.ijporl.2013.10.048
   American National Standards Institute, 1996, S361996 ANSI
   American Speech-Language-Hearing Association, 2005, CENTR AUD PROC DIS R, V25
   Australian Government: National Health and Medical Research Council, 2018, NAT STAT ETH COND HU
   Baddeley A., 1986, ADV PSYCHOL, P141, DOI [10.1016/s0166-4115(08)61202-9, DOI 10.1016/S0166-4115(08)61202-9]
   Badian NA, 1999, J LEARN DISABIL, V32, P138, DOI 10.1177/002221949903200204
   Baird G, 2011, DEV MED CHILD NEUROL, V53, P711, DOI 10.1111/j.1469-8749.2011.03936.x
   Banai K, 2004, AUDIOL NEURO-OTOL, V9, P328, DOI 10.1159/000081282
   Banai K, 2006, CEREB CORTEX, V16, P1718, DOI 10.1093/cercor/bhj107
   Barker MD, 2017, J AM ACAD AUDIOL, V28, P534, DOI 10.3766/jaaa.16054
   Benasich AA, 2002, DEV PSYCHOBIOL, V40, P278, DOI 10.1002/dev.10032
   Bradlow AR, 2003, J SPEECH LANG HEAR R, V46, P80, DOI 10.1044/1092-4388(2003/007)
   Cameron S, 2007, INT J AUDIOL, V46, P145, DOI 10.1080/14992020601164170
   Cameron S, 2016, J AM ACAD AUDIOL, V27, P470, DOI 10.3766/jaaa.15085
   Casco C, 1998, CORTEX, V34, P531, DOI 10.1016/S0010-9452(08)70512-4
   Casini L, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12530
   Catts H.W., 1996, AM J AUDIOL, V5, P41, DOI DOI 10.1044/POLICY.TR1996-00241
   Compton D L, 2001, Dyslexia, V7, P125, DOI 10.1002/dys.198
   Dawes P, 2009, EAR HEARING, V30, P675, DOI 10.1097/AUD.0b013e3181b34cc5
   Dhamani I, 2013, SCI REP-UK, V3, DOI 10.1038/srep01297
   Dillon H, 2012, J AM ACAD AUDIOL, V23, P97, DOI 10.3766/jaaa.23.2.4
   Dunn LM, 2007, PPVT 4 PEABODY PICTU
   FELTON RH, 1987, BRAIN LANG, V31, P171, DOI 10.1016/0093-934X(87)90067-8
   Fischer B, 2004, DYSLEXIA, V10, P105, DOI 10.1002/dys.268
   Franceschini S, 2012, CURR BIOL, V22, P814, DOI 10.1016/j.cub.2012.03.013
   Gibson LY, 2006, COGN NEUROPSYCHOL, V23, P621, DOI 10.1080/02643290500412545
   Goswami U, 2002, P NATL ACAD SCI USA, V99, P10911, DOI 10.1073/pnas.122368599
   Goswami U., 2001, HDB EARLY LITERACY R, P111
   Goswami U, 2015, NAT REV NEUROSCI, V16, P43, DOI 10.1038/nrn3836
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Goswami U, 2011, J COGNITIVE NEUROSCI, V23, P325, DOI 10.1162/jocn.2010.21453
   Grassi M, 2009, BEHAV RES METHODS, V41, P20, DOI 10.3758/BRM.41.1.20
   Gyldenkaerne P, 2014, J AM ACAD AUDIOL, V25, P676, DOI 10.3766/jaaa.25.7.6
   Halliday LF, 2006, BRAIN LANG, V97, P200, DOI 10.1016/j.bandl.2005.10.007
   Halliday LF, 2006, J RES READ, V29, P213, DOI 10.1111/j.1467-9817.2006.00286.x
   Hamalainen JA, 2009, APPL PSYCHOLINGUIST, V30, P511, DOI 10.1017/S0142716409090250
   Hamalainen JA, 2013, J LEARN DISABIL-US, V46, P413, DOI 10.1177/0022219411436213
   Hashimoto R, 2000, NEUROIMAGE, V12, P147, DOI 10.1006/nimg.2000.0603
   Huss M, 2011, CORTEX, V47, P674, DOI 10.1016/j.cortex.2010.07.010
   Iliadou V, 2009, INT J PEDIATR OTORHI, V73, P1029, DOI 10.1016/j.ijporl.2009.04.004
   Jerger J, 2000, J Am Acad Audiol, V11, P467
   Krishnan A, 2014, BRAIN LANG, V138, P51, DOI 10.1016/j.bandl.2014.09.005
   Landerl K, 2010, LEARN INDIVID DIFFER, V20, P393, DOI 10.1016/j.lindif.2010.03.008
   Leppanen PHT, 2010, CORTEX, V46, P1362, DOI 10.1016/j.cortex.2010.06.003
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Manly T, 2001, J CHILD PSYCHOL PSYC, V42, P1065, DOI 10.1111/1469-7610.00806
   Massa I, 2009, J PSYCHOEDUC ASSESS, V27, P426, DOI 10.1177/0734282908329108
   McArthur GM, 2008, COGNITION, V107, P946, DOI 10.1016/j.cognition.2007.12.005
   McArthur GM, 2012, SCI STUD READ, V16, P63, DOI 10.1080/10888438.2010.542526
   McArthur GM, 2004, J SPEECH LANG HEAR R, V47, P527, DOI 10.1044/1092-4388(2004/041)
   Medwetsky L., 2009, HDB CLIN AUDIOLOGY
   Metsala JL, 1999, J EDUC PSYCHOL, V91, P3, DOI 10.1037/0022-0663.91.1.3
   Moncrieff DW, 2008, DYSLEXIA, V14, P54, DOI 10.1002/dys.344
   Moore DR, 2008, HEARING RES, V238, P147, DOI 10.1016/j.heares.2007.11.013
   Moore DR, 2011, EAR HEARING, V32, P269, DOI 10.1097/AUD.0b013e318201c468
   Moore DR, 2010, PEDIATRICS, V126, pE382, DOI 10.1542/peds.2009-2826
   Moore DR, 2003, LEARN MEMORY, V10, P83, DOI 10.1101/lm.59703
   Musiek F. E., 2002, HEARING J, V55, P58, DOI DOI 10.1097/01.HJ.0000293280.99394.DD
   Muter V, 2004, DEV PSYCHOL, V40, P665, DOI 10.1037/0012-1649.40.5.665
   Ouellette GP, 2006, J EDUC PSYCHOL, V98, P554, DOI 10.1037/0022-0663.98.3.554
   Paul I, 2006, EUR J NEUROSCI, V24, P2945, DOI 10.1111/j.1460-9568.2006.05153.x
   Perfetti CA, 1996, READING COMPREHENSION DIFFICULTIES, P137
   Peter V, 2014, J AM ACAD AUDIOL, V25, P210, DOI 10.3766/jaaa.25.2.9
   Rabiner D, 2000, J AM ACAD CHILD PSY, V39, P859, DOI 10.1097/00004583-200007000-00014
   Ramus F, 2001, NATURE, V412, P393, DOI 10.1038/35086683
   Reid N, 2010, RE-AWAKENING LANGUAGES: THEORY AND PRACTICE IN THE REVITALISATION OF AUSTRALIA'S INDIGENOUS LANGUAGES, P293
   Rocheron I., 2002, CHILDREN, V13, P3
   Scarborough H. S., 2009, APPROACHING DIFFICUL, P23
   SCARBOROUGH HS, 1990, CHILD DEV, V61, P1728, DOI 10.2307/1130834
   Semel E, 2006, CLIN EVALUATION LANG
   Sharma M, 2006, CLIN NEUROPHYSIOL, V117, P1130, DOI 10.1016/j.clinph.2006.02.001
   Sharma M, 2019, EAR HEARING, V40, P243, DOI 10.1097/AUD.0000000000000608
   Sharma M, 2014, J SPEECH LANG HEAR R, V57, P2308, DOI 10.1044/2014_JSLHR-H-13-0226
   Sharma M, 2009, J SPEECH LANG HEAR R, V52, P706, DOI 10.1044/1092-4388(2008/07-0226)
   Shinn JB, 2009, J AM ACAD AUDIOL, V20, P229, DOI 10.3766/jaaa.20.4.3
   Skarzynski PH, 2015, ANN AGR ENV MED, V22, P90, DOI 10.5604/12321966.1141375
   Snowling MJ, 2018, PSYCHOL SCI, V29, P1270, DOI 10.1177/0956797618763090
   Stevens C, 2012, DEV COGN NEUROS-NETH, V2, pS30, DOI 10.1016/j.dcn.2011.11.001
   Swanson HL, 2009, J LEARN DISABIL-US, V42, P260, DOI 10.1177/0022219409331958
   SWANSON HL, 1993, J EXP CHILD PSYCHOL, V56, P87, DOI 10.1006/jecp.1993.1027
   SWANSON HL, 1989, J ABNORM CHILD PSYCH, V17, P145, DOI 10.1007/BF00913790
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   TALLAL P, 1984, APPL PSYCHOLINGUIST, V5, P167, DOI 10.1017/S0142716400004963
   Tomlin D, 2015, EAR HEARING, V36, P527, DOI 10.1097/AUD.0000000000000172
   Wagner R, 1999, COMPREHENSIVE TEST P
   WAGNER RK, 1987, PSYCHOL BULL, V101, P192, DOI 10.1037/0033-2909.101.2.192
   Walker MM, 2006, J COMMUN DISORD, V39, P442, DOI 10.1016/j.jcomdis.2005.12.006
   Walley AC., 2003, READING WRITING, V16, P5, DOI [DOI 10.1023/A:1021789804977, 10.1023/A:1021789804977]
   Wechsler D, 2006, WECHSLER NONVERBAL S
   Whitehurst GJ, 1998, CHILD DEV, V69, P848, DOI 10.1111/j.1467-8624.1998.00848.x
   Wible B, 2005, BRAIN, V128, P417, DOI 10.1093/brain/awh367
   Willcutt EG, 2005, DEV NEUROPSYCHOL, V27, P35, DOI 10.1207/s15326942dn2701_3
   Willcutt EG, 2000, J LEARN DISABIL, V33, P179, DOI 10.1177/002221940003300206
   Wilson WJ, 2013, J SPEECH LANG HEAR R, V56, P63, DOI 10.1044/1092-4388(2012/11-0352)
   Wise JC, 2007, J SPEECH LANG HEAR R, V50, P1093, DOI 10.1044/1092-4388(2007/076)
   Wright CM, 2009, DEV NEUROPSYCHOL, V34, P330, DOI 10.1080/87565640902801882
   Zaidan E, 2013, INT J AUDIOL, V52, P113, DOI 10.3109/14992027.2012.733421
   Ziegler JC, 2009, DEVELOPMENTAL SCI, V12, P732, DOI 10.1111/j.1467-7687.2009.00817.x
NR 99
TC 8
Z9 8
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD OCT 22
PY 2019
VL 10
AR 2383
DI 10.3389/fpsyg.2019.02383
PG 15
WC Psychology, Multidisciplinary
SC Psychology
GA JO4BR
UT WOS:000497525100001
PM 31695659
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Zettin, M
   Leopizzi, M
   Galetto, V
AF Zettin, Marina
   Leopizzi, Marzia
   Galetto, Valentina
TI How does language change after an intensive treatment on imitation?
SO NEUROPSYCHOLOGICAL REHABILITATION
LA English
DT Article
DE Imitation; Aphasia; Naming difficulties; Computer-based rehabilitation
ID SHORT-TERM; APHASIA THERAPY; MIRROR NEURONS; WORKING-MEMORY;
   SPEECH-PERCEPTION; GLOBAL COHERENCE; NAMING THERAPY; MOTOR DEFICITS;
   RECOVERY; ADULTS
AB The main aim of our study was to investigate the role of imitation in improving word-finding difficulties in a group of aphasic subjects. For this purpose, we designed software based on the computerised program described by Lee et al. (2010). Seven subjects with aphasia resulting from a brain injury were enrolled in the study. A battery of tests was administered to participants one month before the treatment (T0) and immediately before its beginning (T1) with the aim of detecting their language difficulties. In the period between T0 and T1 sessions, participants underwent traditional logopaedic and neuropsychological rehabilitation. The treatment lasted 45 days with 90-minute sessions per day and it was personalised in terms of difficulty for each of the subjects. During every session the task required participants to carefully observe and then imitate six actors while pronouncing aloud a series of words and sentences describing a set of items. The results showed a significant improvement in the whole sample and in all the analysed measures only between T1 and T2 (post-training evaluation), while, as expected, no improvement was registered between T0 and T1. Such outcomes are consistent with research showing the key role played by imitation in the word retrieval process following aphasia.
C1 [Zettin, Marina; Leopizzi, Marzia; Galetto, Valentina] Ctr Puzzle, Dept Psychol, Turin, Italy.
   [Zettin, Marina; Galetto, Valentina] Univ Turin, Brain Imaging Grp, Turin, Italy.
   [Galetto, Valentina] Ctr Hosp Univ Carremeau, Nimes, France.
RP Galetto, V (corresponding author), Ctr Puzzle, Dept Psychol, Turin, Italy.; Galetto, V (corresponding author), Univ Turin, Brain Imaging Grp, Turin, Italy.
EM valentinagaletto@virgilio.it
CR Altmann LJP, 2014, J SPEECH LANG HEAR R, V57, P439, DOI 10.1044/1092-4388(2013/12-0224)
   Arbib MA, 2010, BRAIN LANG, V112, P12, DOI 10.1016/j.bandl.2009.10.001
   Baddeley A, 2003, J COMMUN DISORD, V36, P189, DOI 10.1016/S0021-9924(03)00019-4
   BADDELEY A, 1987, ATTENTION PERFORM, P509
   BADDELEY A, 1988, J MEM LANG, V27, P586, DOI 10.1016/0749-596X(88)90028-9
   Barsalou LW, 2008, ANNU REV PSYCHOL, V59, P617, DOI 10.1146/annurev.psych.59.103006.093639
   Basso Anna, 2013, Handb Clin Neurol, V110, P325, DOI 10.1016/B978-0-444-52901-5.00027-7
   Basso A, 2011, BEHAV NEUROL, V24, P317, DOI [10.3233/BEN-2011-0342, 10.1155/2011/313480]
   Benowitz LI, 2010, NEUROBIOL DIS, V37, P259, DOI 10.1016/j.nbd.2009.11.009
   Bertinetto P. M., 2005, COLFIS CORPUS LESSIC
   Bhogal SK, 2003, STROKE, V34, P987, DOI 10.1161/01.STR.0000062343.64383.D0
   Bonifazi S, 2013, EUR J PHYS REHAB MED, V49, P473
   Buccino G, 2001, EUR J NEUROSCI, V13, P400, DOI 10.1046/j.1460-9568.2001.01385.x
   CARAMAZZA A, 1981, BRAIN LANG, V14, P235, DOI 10.1016/0093-934X(81)90078-X
   Caspari I, 1998, BRAIN COGNITION, V37, P205, DOI 10.1006/brcg.1997.0970
   Cherney LR, 2011, CURR NEUROL NEUROSCI, V11, P560, DOI 10.1007/s11910-011-0227-6
   Code C, 2003, NEUROPSYCHOL REHABIL, V13, P109, DOI 10.1080/09602010244000291
   Code C, 2011, INT J SPEECH-LANG PA, V13, P3, DOI 10.3109/17549507.2010.520090
   Code Chris, 2010, Seminars in Speech and Language, V31, P21, DOI 10.1055/s-0029-1244950
   Cook SW, 2013, CHILD DEV, V84, P1863, DOI 10.1111/cdev.12097
   Corballis MC, 2009, HUM MOVEMENT SCI, V28, P556, DOI 10.1016/j.humov.2009.07.003
   De Mauro T., 1980, GUIDA ALLUSO PAROLE
   Ertelt D, 2007, NEUROIMAGE, V36, pT164, DOI 10.1016/j.neuroimage.2007.03.043
   Ertelt D, 2012, NEURAL REGEN RES, V7, P2063, DOI 10.3969/j.issn.1673-5374.2012.26.008
   FADIGA L, 1995, J NEUROPHYSIOL, V73, P2608
   Faralli A, 2013, NEURAL PLAST, V2013, DOI 10.1155/2013/854597
   Ferguson NF, 2012, AM J SPEECH-LANG PAT, V21, pS126, DOI 10.1044/1058-0360(2012/11-0076)
   FOLSTEIN MF, 1983, ARCH GEN PSYCHIAT, V40, P812
   Franceschini M, 2012, NEUROREHAB NEURAL RE, V26, P456, DOI 10.1177/1545968311427406
   Friedmann N, 2002, BEHAV BRAIN SCI, V25, P756, DOI 10.1017/S0140525X02270132
   Gallese V, 2005, COGN NEUROPSYCHOL, V22, P455, DOI 10.1080/02643290442000310
   Gallese V, 1998, TRENDS COGN SCI, V2, P493, DOI 10.1016/S1364-6613(98)01262-5
   Gallese V, 2008, SOC NEUROSCI-UK, V3, P317, DOI 10.1080/17470910701563608
   Goodglass H., 1983, REVISED BOSTON NAMIN
   Hable R, 2013, 2013 IEEE 27TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P1, DOI 10.1109/WAINA.2013.46
   HANLON RE, 1990, BRAIN LANG, V38, P298, DOI 10.1016/0093-934X(90)90116-X
   Hickok G, 2010, LANG COGNITIVE PROC, V25, P749, DOI 10.1080/01690961003595572
   Hilari K, 2012, ARCH PHYS MED REHAB, V93, pS86, DOI 10.1016/j.apmr.2011.05.028
   Hillis A. E., 1994, LANGUAGE INTERVENTIO, P207
   HILLIS AE, 1991, BRAIN LANG, V40, P106, DOI 10.1016/0093-934X(91)90119-L
   Hornby TG, 2011, TOP STROKE REHABIL, V18, P293, DOI 10.1310/tsr1804-293
   HUBER W, 1983, J NEUROL NEUROSUR PS, V46, P691, DOI 10.1136/jnnp.46.7.691
   Huber W., 1993, APHASIA TREATMENT WO, P55
   Iacoboni M, 1999, SCIENCE, V286, P2526, DOI 10.1126/science.286.5449.2526
   Kaplan E., 1983, BOSTON NAMING TEST
   Kelly H, 2010, COCHRANE DB SYST REV, DOI [10.1002/14651858.CD000425.pub2, 10.1002/14651858.CD000425.pub3]
   Kertesz A., 1982, W APHASIA BATTERY TE
   Kleim JA, 2003, NEUROL RES, V25, P789, DOI 10.1179/016164103771953862
   Kurland J, 2014, AM J SPEECH-LANG PAT, V23, P259, DOI 10.1044/2014_AJSLP-13-0094
   Kurland J, 2014, SEMIN SPEECH LANG, V35, P3, DOI 10.1055/s-0033-1362989
   Le K, 2011, J SPEECH LANG HEAR R, V54, P118, DOI 10.1044/1092-4388(2010/09-0022)
   Lee J, 2010, APHASIOLOGY, V24, P449, DOI 10.1080/02687030802714157
   Lemmens R, 2013, HUM MOL GENET, V22, P2214, DOI 10.1093/hmg/ddt073
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   LILES BZ, 1993, J SPEECH HEAR RES, V36, P868, DOI 10.1044/jshr.3605.868
   Loban W., 1976, 18 NAT COUNC TEACH E
   Lorber B, 2009, NAT NEUROSCI, V12, P1407, DOI 10.1038/nn.2414
   Maher Lynn M, 2004, Top Stroke Rehabil, V11, P10
   Marangolo P, 2014, EXPERT REV NEUROTHER, V14, P75, DOI 10.1586/14737175.2014.864555
   Marangolo P, 2014, NEUROPSYCHOLOGIA, V53, P246, DOI 10.1016/j.neuropsychologia.2013.12.003
   Marangolo P, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038610
   Marangolo P, 2010, NEUROPSYCHOLOGIA, V48, P3824, DOI 10.1016/j.neuropsychologia.2010.09.025
   Marini A, 2005, J PSYCHOLINGUIST RES, V34, P439, DOI 10.1007/s10936-005-6203-z
   Marini A., 2004, ANALISI DISCORSO PAT
   Marini A, 2008, NEUROPSYCHOLOGIA, V46, P2816, DOI 10.1016/j.neuropsychologia.2008.05.013
   Marini A, 2011, NEUROPSYCHOLOGIA, V49, P2904, DOI 10.1016/j.neuropsychologia.2011.06.017
   Mengotti P, 2013, BRAIN, V136, P2602, DOI 10.1093/brain/awt194
   Moore JL, 2010, STROKE, V41, P129, DOI 10.1161/STROKEAHA.109.563247
   Mortley J, 2004, BRIT J GEN PRACT, V54, P856
   Murray LL, 2012, APHASIOLOGY, V26, P317, DOI 10.1080/02687038.2011.589894
   Nickels L, 2002, APHASIOLOGY, V16, P935, DOI 10.1080/02687030244000563
   Olness GS, 2006, APHASIOLOGY, V20, P175, DOI 10.1080/02687030500472710
   OSTRIN RK, 1986, BRAIN LANG, V28, P328, DOI 10.1016/0093-934X(86)90109-4
   Paek E. J., 2014, CLIN APH C ST SIM IS
   Palmer R, 2013, INT J LANG COMM DIS, V48, P508, DOI 10.1111/1460-6984.12024
   Pashek GV, 1997, J COMMUN DISORD, V30, P349, DOI 10.1016/S0021-9924(96)00079-2
   Pedersen PM, 2001, APHASIOLOGY, V15, P151, DOI 10.1080/02687040042000106
   Pulvermuller F, 2005, NAT REV NEUROSCI, V6, P576, DOI 10.1038/nrn1706
   Ramsberger G, 2007, AM J SPEECH-LANG PAT, V16, P343, DOI 10.1044/1058-0360(2007/038)
   RAYMER AM, 1993, APHASIOLOGY, V7, P27, DOI 10.1080/02687039308249498
   Raymer AM, 2006, J INT NEUROPSYCH SOC, V12, P867, DOI 10.1017/S1355617706061042
   Raymer AM, 2012, NEUROPSYCHOL REHABIL, V22, P235, DOI 10.1080/09602011.2011.618306
   Richards K, 2002, J REHABIL RES DEV, V39, P445
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Rizzolatti G, 1998, TRENDS NEUROSCI, V21, P188, DOI 10.1016/S0166-2236(98)01260-0
   Rizzolatti G, 1999, ARCH ITAL BIOL, V137, P85
   Rizzolatti G, 2002, CURR OPIN NEUROBIOL, V12, P149, DOI 10.1016/S0959-4388(02)00308-2
   Rizzolatti G., 2006, SO QUEL CHE FAI CERV
   Rizzolatti G., 2002, IMITATIVE MIND DEV E, P247, DOI DOI 10.1017/CB09780511489969.015
   Robey RR, 1998, J SPEECH LANG HEAR R, V41, P172, DOI 10.1044/jslhr.4101.172
   Robson J, 1998, J INT NEUROPSYCH SOC, V4, P675, DOI 10.1017/S1355617798466153
   Rodriguez-Fornells A, 2006, LANG LEARN, V56, P133, DOI 10.1111/j.1467-9922.2006.00359.x
   Rohde A, 2013, J EVAL CLIN PRACT, V19, P994, DOI 10.1111/jep.12023
   Rose M, 2008, APHASIOLOGY, V22, P20, DOI 10.1080/02687030600742020
   Rose ML, 2013, APHASIOLOGY, V27, P1090, DOI 10.1080/02687038.2013.805726
   SAFFRAN EM, 1975, BRAIN LANG, V2, P420, DOI 10.1016/S0093-934X(75)80081-2
   SALAME P, 1982, J VERB LEARN VERB BE, V21, P150, DOI 10.1016/S0022-5371(82)90521-7
   Sale P, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/457538
   Schlaug G, 2008, MUSIC PERCEPT, V25, P315, DOI 10.1525/MP.2008.25.4.315
   Sebkova L., 2016, J EXCEPTIONAL PEOPLE, V2, P67
   Shallice T., 1990, NEUROPSYCHOLOGICAL I, P11, DOI [10.1017/CBO9780511665547.003, DOI 10.1017/CBO9780511665547.003]
   Shehata GA, 2015, J AFFECT DISORDERS, V172, P312, DOI 10.1016/j.jad.2014.10.027
   Silveira Gabriela, 2015, Dement. neuropsychol., V9, P279, DOI [10.1590/1980-57642015dn93000011, 10.1590/1980-57642015DN93000011]
   Skipper JI, 2007, BRAIN LANG, V101, P260, DOI 10.1016/j.bandl.2007.02.008
   Small SL, 2012, DEV PSYCHOBIOL, V54, P293, DOI 10.1002/dev.20504
   Small SL, 2009, CURR NEUROL NEUROSCI, V9, P443, DOI 10.1007/s11910-009-0066-x
   Spencer KA, 2000, APHASIOLOGY, V14, P567, DOI 10.1080/026870300401324
   Tettamanti M, 2005, J COGNITIVE NEUROSCI, V17, P273, DOI 10.1162/0898929053124965
   THOMPSON CK, 1991, CLIN APHASIOLOGY, V20, P239
   van de Sandt-Koenderman WME, 2011, INT J SPEECH-LANG PA, V13, P21, DOI 10.3109/17549507.2010.502973
   Villardita C., 1994, W APHASIA BATTERY 1
   Wright HH, 2014, AGING NEUROPSYCHOL C, V21, P174, DOI 10.1080/13825585.2013.794894
   Wright HH, 2012, APHASIOLOGY, V26, P656, DOI 10.1080/02687038.2012.676855
   Wright HH, 2010, PROCD SOC BEHV, V6, P111, DOI 10.1016/j.sbspro.2010.08.056
   Wright HH, 2005, APHASIOLOGY, V19, P263, DOI 10.1080/02687030444000732
   ZURIF EB, 1979, J SPEECH HEAR RES, V22, P456, DOI 10.1044/jshr.2203.456
NR 117
TC 0
Z9 1
U1 1
U2 33
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0960-2011
EI 1464-0694
J9 NEUROPSYCHOL REHABIL
JI Neuropsychol. Rehabil.
PD OCT 21
PY 2019
VL 29
IS 9
BP 1332
EP 1358
DI 10.1080/09602011.2017.1406861
PG 27
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA IT5UV
UT WOS:000482933600002
PM 29322866
DA 2021-02-24
ER

PT J
AU Kim, Y
   Sidtis, JJ
   Sidtis, DV
AF Kim, Yoonji
   Sidtis, John J.
   Sidtis, Diana Van Lancker
TI Emotionally expressed voices are retained in memory following a single
   exposure
SO PLOS ONE
LA English
DT Article
ID CHANGE DEAFNESS; SPEECH-PERCEPTION; AMYGDALA ACTIVITY; FAMILIAR VOICES;
   RECOGNITION; AROUSAL; DISCRIMINATION; IDENTIFICATION; MECHANISMS;
   ATTENTION
AB Studies of voice recognition in biology suggest that long exposure may not satisfactorily represent the voice acquisition process. The current study proposes that humans can acquire a newly familiar voice from brief exposure to spontaneous speech, given a personally engaging context. Studies have shown that arousing and emotionally engaging experiences are more likely to be recorded and consolidated in memory. Yet it remains undemonstrated whether this advantage holds for voices. The present study examined the role of emotionally expressive context in the acquisition of voices following a single, 1-minute exposure by comparing recognition of voices experienced in engaging and neutral contexts at two retention intervals. Listeners were exposed to a series of emotionally nuanced and neutral videotaped narratives produced by performers, and tested on the recognition of excerpted voice samples, by indicating whether they had heard the voice before, immediately and after a one week delay. Excerpts were voices from exposed videotaped narratives, but utilized verbal material taken from a second (nonexposed) narrative provided by the same performer. Overall, participants were consistently able to distinguish between voices that were exposed during the video session and voices that were not exposed. Voices experienced in emotional, engaging contexts were significantly better recognized than those in neutral ones both immediately and after a one-week delay. Our findings provide the first evidence that new voices can be acquired rapidly from one-time exposure and that nuanced context facilitates initially inducting new voices into a repertory of personally familiar voices in long-term memory. The results converge with neurological evidence to suggest that cerebral processes differ for familiar and unfamiliar voices.
C1 [Kim, Yoonji; Sidtis, Diana Van Lancker] NYU, Dept Commun Sci & Disorders, New York, NY 10003 USA.
   [Kim, Yoonji; Sidtis, John J.; Sidtis, Diana Van Lancker] Rockland Psychiat Ctr, Nathan Kline Inst Psychiat Res, Geriatr Div, New York, NY 10962 USA.
   [Sidtis, John J.] NYU, Dept Psychiat, Langone Sch Med, 550 1St Ave, New York, NY 10016 USA.
RP Kim, Y (corresponding author), NYU, Dept Commun Sci & Disorders, New York, NY 10003 USA.; Kim, Y (corresponding author), Rockland Psychiat Ctr, Nathan Kline Inst Psychiat Res, Geriatr Div, New York, NY 10962 USA.
EM yjk375@nyu.edu
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01 DC 007558]
FX This work was supported by the National Institute on Deafness and Other
   Communication Disorders [grant number R01 DC 007558]. The funders had no
   role in study design, data collection and analysis, decision to publish,
   or preparation of the manuscript.
CR Aubin T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134513
   Baudouin JY, 2000, MEMORY, V8, P285, DOI 10.1080/09658210050117717
   Bee MA, 2002, P ROY SOC B-BIOL SCI, V269, P1443, DOI 10.1098/rspb.2002.2041
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   BRADLEY MM, 1992, J EXP PSYCHOL LEARN, V18, P379, DOI 10.1037/0278-7393.18.2.379
   BROWN R, 1977, COGNITION, V5, P73, DOI 10.1016/0010-0277(77)90018-X
   Cahill L, 1998, TRENDS NEUROSCI, V21, P294, DOI 10.1016/S0166-2236(97)01214-9
   Cahill L, 1996, P NATL ACAD SCI USA, V93, P8016, DOI 10.1073/pnas.93.15.8016
   CAHILL L, 1995, NATURE, V377, P295, DOI 10.1038/377295a0
   Cairney SA, 2018, CORTEX, V99, P39, DOI 10.1016/j.cortex.2017.10.005
   Canli T, 2000, J NEUROSCI, V20
   Charrier I, 2003, MAR MAMMAL SCI, V19, P161, DOI 10.1111/j.1748-7692.2003.tb01099.x
   Charrier I, 2002, J EXP BIOL, V205, P603
   Charrier I, 2001, NATURE, V412, P873, DOI 10.1038/35091136
   Cheney DL, 1999, ANIM BEHAV, V58, P67, DOI 10.1006/anbe.1999.1131
   Chu PC, 1990, J MARINE SYST, V1, P1, DOI 10.1016/0924-7963(90)90051-B
   COKER DA, 1987, HUM COMMUN RES, V13, P463, DOI 10.1111/j.1468-2958.1987.tb00115.x
   Davis M., 2000, AMYGDALA, V2, P213
   Dunsmoor JE, 2015, NATURE, V520, P345, DOI 10.1038/nature14106
   Fenn KM, 2011, Q J EXP PSYCHOL, V64, P1442, DOI 10.1080/17470218.2011.570353
   Finkenauer C, 1998, MEM COGNITION, V26, P516, DOI 10.3758/BF03201160
   Gainotti G, 2018, NEUROPSYCHOLOGIA, V116, P151, DOI 10.1016/j.neuropsychologia.2018.04.003
   Gaskell MG, 2014, PSYCHOL SCI, V25, P1457, DOI 10.1177/0956797614535937
   Genzel L, 2017, STUD NEUROSCI, P3, DOI 10.1007/978-3-319-45066-7_1
   GERARD HB, 1973, J PERS SOC PSYCHOL, V28, P151, DOI 10.1037/h0035573
   Gregg MK, 2008, J EXP PSYCHOL HUMAN, V34, P974, DOI 10.1037/0096-1523.34.4.974
   GUTHRIE ER, 1946, PSYCHOL BULL, V43, P1, DOI 10.1037/h0061712
   Hamann SB, 1999, NAT NEUROSCI, V2, P289, DOI 10.1038/6404
   HAMMERSLEY R, 1985, LAW HUMAN BEHAV, V9, P71, DOI 10.1007/BF01044290
   Holeckova I, 2006, BRAIN RES, V1082, P142, DOI 10.1016/j.brainres.2006.01.089
   Holmes E, 2018, PSYCHOL SCI, V29, P1575, DOI 10.1177/0956797618779083
   Hu P, 2006, PSYCHOL SCI, V17, P891, DOI 10.1111/j.1467-9280.2006.01799.x
   Insley SJ, 2001, ANIM BEHAV, V61, P129, DOI 10.1006/anbe.2000.1569
   Johnsrude IS, 2013, PSYCHOL SCI, V24, P1995, DOI 10.1177/0956797613482467
   Jouventin P, 1999, ANIM BEHAV, V57, P1175, DOI 10.1006/anbe.1999.1086
   KLEINSMITH LJ, 1963, J EXP PSYCHOL, V65, P190, DOI 10.1037/h0040288
   Kreiman J., 2011, FDN VOICE STUDIES IN
   Ladefoged Jenny, 1980, UCLA WORKING PAPERS, V49, P43
   Lang PJ, 1997, ATTENTION AND ORIENTING: SENSORY AND MOTIVATIONAL PROCESSES, P97
   Lattner S, 2005, HUM BRAIN MAPP, V24, P11, DOI 10.1002/hbm.20065
   Lavner Y, 2000, SPEECH COMMUN, V30, P9, DOI 10.1016/S0167-6393(99)00028-X
   LEGGE GE, 1984, J EXP PSYCHOL LEARN, V10, P298
   Maguinness C, 2018, NEUROPSYCHOLOGIA, V116, P179, DOI 10.1016/j.neuropsychologia.2018.03.039
   McGaugh JL, 2000, SCIENCE, V287, P248, DOI 10.1126/science.287.5451.248
   MORELAND RL, 1982, J EXP SOC PSYCHOL, V18, P395, DOI 10.1016/0022-1031(82)90062-2
   Neisser U, 1996, MEMORY, V4, P337, DOI 10.1080/096582196388898
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Payne JD, 2008, PSYCHOL SCI, V19, P781, DOI 10.1111/j.1467-9280.2008.02157.x
   Pennebaker JW, 2015, LINGUISTIC INQUIRY W
   Phelps EA, 2004, CURR OPIN NEUROBIOL, V14, P198, DOI 10.1016/j.conb.2004.03.015
   Reuterskiold C, 2013, CHILD LANG TEACH THE, V29, P219, DOI 10.1177/0265659012456859
   REUTERSKIOLD C, 1991, CORTEX, V27, P595, DOI 10.1016/S0010-9452(13)80008-1
   Schupp HT, 2006, PROG BRAIN RES, V156, P31, DOI 10.1016/S0079-6123(06)56002-9
   Schweinberger SR, 2001, NEUROPSYCHOLOGIA, V39, P921, DOI 10.1016/S0028-3932(01)00023-9
   Searby A, 2004, ANIM BEHAV, V67, P615, DOI 10.1016/j.anbehav.2003.03.012
   Stanislaw H, 1999, BEHAV RES METH INS C, V31, P137, DOI 10.3758/BF03207704
   Stevenage SV, 2018, NEUROPSYCHOLOGIA, V116, P162, DOI 10.1016/j.neuropsychologia.2017.07.005
   Stickgold R, 2013, NAT NEUROSCI, V16, P139, DOI 10.1038/nn.3303
   Talmi D, 2007, EMOTION, V7, P89, DOI 10.1037/1528-3542.7.1.89
   Talmi D, 2012, J MEM LANG, V66, P93, DOI 10.1016/j.jml.2011.07.009
   Tanaka YL, 2012, INT J NURS PRACT, V18, P38, DOI 10.1111/j.1440-172X.2012.02027.x
   Therien JM, 2004, DEV MED CHILD NEUROL, V46, P816, DOI 10.1017/S0012162204001434
   Van Lancker D, 2002, BRAIN LANG, V80, P121, DOI 10.1006/brln.2001.2564
   Van Lancker D R, 1982, Brain Cogn, V1, P185, DOI 10.1016/0278-2626(82)90016-1
   Van Lancker Sidtis D., 2018, OXFORD HDB VOICE PER
   VANLANCKER D, 1987, NEUROPSYCHOLOGIA, V25, P829, DOI 10.1016/0028-3932(87)90120-5
   VANLANCKER D, 1991, BRAIN COGNITION, V17, P64, DOI 10.1016/0278-2626(91)90067-I
   VanLancker D, 1997, BRAIN LANG, V57, P1, DOI 10.1006/brln.1997.1850
   VANLANCKER DR, 1988, CORTEX, V24, P195, DOI 10.1016/S0010-9452(88)80029-7
   Vitevitch MS, 2003, J EXP PSYCHOL HUMAN, V29, P333, DOI 10.1037/0096-1523.29.2.333
   von Kriegstein K, 2005, J COGNITIVE NEUROSCI, V17, P367, DOI 10.1162/0898929053279577
   Vuilleumier P, 2007, NEUROPSYCHOLOGIA, V45, P174, DOI 10.1016/j.neuropsychologia.2006.06.003
   Wenndt SJ, 2016, J ACOUST SOC AM, V140, P1172, DOI 10.1121/1.4958682
NR 73
TC 0
Z9 0
U1 1
U2 1
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD OCT 17
PY 2019
VL 14
IS 10
AR e0223948
DI 10.1371/journal.pone.0223948
PG 18
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA LM9KP
UT WOS:000532567300074
PM 31622405
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Pinget, AF
   Kager, R
   Van de Velde, H
AF Pinget, Anne-France
   Kager, Rene
   Van de Velde, Hans
TI Linking Variation in Perception and Production in Sound Change: Evidence
   from Dutch Obstruent Devoicing
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Speech production; speech perception; sound change; devoicing processes;
   obstruents
ID MID FRONT VOWELS; SPEECH-PERCEPTION; VERTICAL-BAR; SOUTHERN BRITISH;
   DISCRIMINATION; ACCENT; NORTHERN; CONTEXT
AB This study investigates the link between the perception and production in sound change in progress, both at the regional and the individual level. Two devoicing processes showing regional variation in Dutch are studied: the devoicing of initial labiodental fricatives and of initial bilabial stops. Five regions were selected, to represent different stages of change in progress. For each region, 20 participants took part in production (Study 1) and perception (Study 2) experiments. First, the results of the production tasks give additional insight in the regional and individual patterns of sound change. Second, the regional perceptual patterns in fricatives match the differences in production: perception is the most categorical in regions where the devoicing process is starting, and the least categorical in regions where the process of devoicing is almost completed. Finally, a clear link is observed between the production and perception systems undergoing sound change at the individual level. Changes in the perceptual system seem to precede changes in production. However, at the sound change completion, perception lags behind: individuals still perceive a contrast they no longer produce.
C1 [Pinget, Anne-France; Kager, Rene; Van de Velde, Hans] Univ Utrecht, Utrecht Inst Linguist OTS, Trans 10, NL-3512 JK Utrecht, Netherlands.
   [Van de Velde, Hans] Fryske Akad, Leeuwarden, Netherlands.
RP Pinget, AF (corresponding author), Univ Utrecht, Utrecht Inst Linguist OTS, Trans 10, NL-3512 JK Utrecht, Netherlands.
EM a.c.h.Pinget@uu.nl
RI Van de Velde, Hans/K-5575-2015
OI Van de Velde, Hans/0000-0003-2197-5555
FU Netherlands Organization for Scientific Research (NWO)Netherlands
   Organization for Scientific Research (NWO) [322-75-002]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by the Netherlands Organization for Scientific Research
   (NWO grant 322-75-002).
CR Adank P, 2007, J ACOUST SOC AM, V121, P1130, DOI 10.1121/1.2409492
   AINSWORTH WA, 1984, J PHONETICS, V12, P237, DOI 10.1016/S0095-4470(19)30880-0
   Auer Peter, 2005, PERSPECTIVES VARIATI, P7, DOI 10.1515/9783110909579.7
   Baayen R., 1995, CELEX2 LDC96L14
   BAILEY PJ, 1973, LANG SPEECH, V16, P189, DOI 10.1177/002383097301600301
   Beddor P., 2014, COMMUNICATION
   Beddor P. S., 2012, INITIATION SOUND CHA, P37, DOI DOI 10.1075/CILT.323.06BED
   BELLBERTI F, 1979, PHONETICA, V36, P373, DOI 10.1159/000259974
   Boersma P., 2014, MESQUITE MODULAR SYS, V5, P84
   Booij G., 1995, PHONOLOGY DUTCH
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Cassier L., 1986, MOMENTOPNAMEN SOCIOL, P59
   Chambers J. K., 2002, HDB LANGUAGE VARIATI, P349
   Cho TH, 2005, J PHONETICS, V33, P121, DOI 10.1016/j.wocn.2005.01.001
   Cohen A., 1961, FONOLOGIE NEDERLANDS
   Collins B., 1982, J INT PHON ASSOC, V12, P2, DOI [10.1017/S0025100300002358, DOI 10.1017/S0025100300002358]
   Debrock M., 1977, J PHONETICS, V5, P61
   Docherty Gerard, 2010, SOCIOPHONETICS STUDE, P58
   Donaldson B., 1983, DUTCH LINGUISTIC HIS, P3
   Evans BG, 2004, J ACOUST SOC AM, V115, P352, DOI 10.1121/1.1635413
   Evans BG, 2007, J ACOUST SOC AM, V121, P3814, DOI 10.1121/1.2722209
   Ferguson SH, 2014, J ACOUST SOC AM, V135, P3570, DOI 10.1121/1.4874596
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   FOX RA, 1982, PHONETICA, V39, P1, DOI 10.1159/000261647
   Fridland V, 2012, LINGUA, V122, P779, DOI 10.1016/j.lingua.2011.12.007
   Frieda EM, 2000, J SPEECH LANG HEAR R, V43, P129, DOI 10.1044/jslhr.4301.129
   FRY DB, 1962, LANG SPEECH, V5, P171, DOI 10.1177/002383096200500401
   Garrett Andrew, 2013, ORIGINS SOUND CHANGE, P51, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0003
   Geeraerts D, 1999, CONVERGENTIE DIVERGE
   Geeraerts Dirk, 2013, LANGUAGE SPACE INT H, V3, P532
   Goeman T., 2009, INT J SOCIOL LANG, V196/197, P31, DOI DOI 10.1515/IJSL.2009.016
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger Stephen D., 1997, TALKER VARIABILITY S, P33
   Goldstein L., 2003, PHONETICS PHONOLOGY, P159
   Goossens J., 1974, HISTORISCHE PHONOLOG
   Grosvald M., 2012, INITIATION SOUND CHA, P77, DOI DOI 10.1075/CILT.323.08GRO
   Grosvald M., 2009, THESIS
   Gussenhoven C., 1999, HDB INT PHONETIC ASS, P74
   Gussenhoven Carlos, 1983, N W EUROPEAN LANGUAG, V2, P55
   Harrington J, 2008, J ACOUST SOC AM, V123, P2825, DOI 10.1121/1.2897042
   Harrington Jonathan, 2012, SPEECH PLANNING DYNA, P39
   Hawkins S, 2003, J PHONETICS, V31, P373, DOI 10.1016/j.wocn.2003.09.006
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   HEALY AF, 1982, J EXP PSYCHOL HUMAN, V8, P68, DOI 10.1037/0096-1523.8.1.68
   Hommel B, 2001, BEHAV BRAIN SCI, V24, P849, DOI 10.1017/S0140525X01000103
   Iacoboni M, 2006, NAT REV NEUROSCI, V7, P942, DOI 10.1038/nrn2024
   JANSON T, 1983, LANGUAGE, V59, P18, DOI 10.2307/414059
   Janssens G., 2005, NEDERLANDS VROEGER N, P1
   Jassem W., 1979, FRONTIERS SPEECH COM, P77
   JOHNSON K, 1993, LANGUAGE, V69, P505, DOI 10.2307/416697
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   KEATING PA, 1984, LANGUAGE, V60, P286, DOI 10.2307/413642
   Kendall T, 2012, J PHONETICS, V40, P289, DOI 10.1016/j.wocn.2011.12.002
   Kissine M., 2005, U PENNSYLVANIA WORKI, V10
   Kissine M., 2003, LINGUISTICS NETHERLA, P93
   Kleber F., 2012, LANG SPEECH, V55, P1
   Kraljic T, 2008, COGNITION, V107, P54, DOI 10.1016/j.cognition.2007.07.013
   Labov W., 1991, LANG VAR CHANGE, V3, P33, DOI [10.1017/S0954394500000442, DOI 10.1017/S0954394500000442]
   Labov William, 1994, PRINCIPLES LANGUAGE, V1
   Liberman AM, 2000, TRENDS COGN SCI, V4, P187, DOI 10.1016/S1364-6613(00)01471-6
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   LINDBLOM BJORN, 1995, RIV LINGUISTICA, P75
   Matthew Gordon, 2002, J INT PHON ASSOC, V32, P141, DOI [DOI 10.1017/S0025100302001020, 10.1017/S0025100302001020]
   Mitterer H., 2009, RES STUFF
   Mitterer H, 2008, COGNITION, V109, P168, DOI 10.1016/j.cognition.2008.08.002
   Nakagawa S, 2017, J R SOC INTERFACE, V14, DOI 10.1098/rsif.2017.0213
   Nakai S., 1998, J ACOUST SOC AM, V103, P2041
   Newman R., 1997, THESIS
   Newman RS, 2003, J ACOUST SOC AM, V113, P2850, DOI 10.1121/1.1567280
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Ohala John, 1981, PAPERS PARASESSION L, P178
   PALIWAL KK, 1983, J PHONETICS, V11, P77, DOI 10.1016/S0095-4470(19)30778-8
   Perkell JS, 2004, J ACOUST SOC AM, V116, P2338, DOI 10.1121/1.1787524
   Pierrehumbert J., 2001, LENITION CONTRAST, V45
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Pinget A., 2015, THESIS
   Pinget A.-F., 2014, NEDERLANDSE TAALKUND, V19, P3
   Pinget A.-F., 2016, J LINGUISTIC GEOGRAP, V4, P65, DOI 10.1017/jlg.2016.13
   PISONI DB, 1975, MEM COGNITION, V3, P7, DOI 10.3758/BF03198202
   Pisoni DB, 1997, TALKER VARIABILITY S, P9
   REPP BH, 1981, PERCEPT PSYCHOPHYS, V30, P217, DOI 10.3758/BF03214276
   Repp BH., 1984, SPEECH LANG ADV BASI, V10, P243, DOI DOI 10.1016/B978-0-12-608610-2.50012-1
   Rietveld A.C.M., 2009, ALGEMENE FONETIEK
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Rojczyk A, 2011, SECOND LANG ACQUIS, V55, P37
   Sennema A., 2005, ZAS PAPERS LINGUISTI, V42, P33
   Slis I., 1989, LINGUISTICS NETHERLA, P123
   SLIS IH, 1969, LANG SPEECH, V12, P80, DOI 10.1177/002383096901200202
   Smakman Dirk., 2006, THESIS, P135
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   Taeldeman J., 2013, LANGUAGE SPACE INT H, V3, P129
   Thomas ER, 2000, J PHONETICS, V28, P1, DOI 10.1006/jpho.2000.0103
   van Alphen PM, 2004, J PHONETICS, V32, P455, DOI 10.1016/j.wocn.2004.05.001
   Van de Velde H., 1996, THESIS
   Van de Velde H, 2010, MULTILINGUA, V29, P385, DOI 10.1515/mult.2010.019
   Van de Velde Hans, 2002, LINGUISTICS NETHERLA, V19, P163
   VAN DE VELDE HANS, 1996, LANG VAR CHANGE, V8, P149, DOI DOI 10.1017/S0954394500001125
   van den Berg R, 1988, THESIS
   van der Harst S, 2011, THESIS
   Van der Harst S, 2014, LANG VAR CHANGE, V26, P247, DOI 10.1017/S0954394514000040
   van der Wal M., 1992, GESCHIEDENIS NEDERLA, P1
   van Son R, 2000, PROTOCOL OPLIJNEN FO
   Vandekerckhove Reinhild, 2009, INT J SOCIOL LANG, V196, P73, DOI DOI 10.1515/IJSL.2009.017
   VANDEVELDE H, 1999, ARTIKELEN DERDE SOCI, P451
   vanSon RJJH, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1529, DOI 10.1109/ICSLP.1996.607908
   Verhoeven J., 2007, NEDERLANDSE TAALKUND, V12, P139
   Ziliak Z., 2008, COMMUNICATION
   Zwaardemaker H., 1928, LEERBOEK PHONETIEK
NR 111
TC 2
Z9 2
U1 0
U2 1
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD SEP
PY 2020
VL 63
IS 3
BP 660
EP 685
AR 0023830919880206
DI 10.1177/0023830919880206
EA OCT 2019
PG 26
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA MX6CZ
UT WOS:000491603000001
PM 31623510
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Plesch, J
   Ernst, BP
   Strieth, S
   Rader, T
AF Plesch, Johannes
   Ernst, Benjamin P.
   Strieth, Sebastian
   Rader, Tobias
TI A psychoacoustic application for the adjustment of electrical hearing
   thresholds in cochlear implant patients
SO PLOS ONE
LA English
DT Article
ID SPEECH; RECOGNITION
AB Objective
   Fitting cochlear implants, especially the precise determination of electrical hearing thresholds, is a time-consuming and complex task for patients as well as audiologists. Aim of the study was to develop a method that enables cochlear implant (CI) patients to determine their electrical hearing thresholds precisely and independently. Applicability and impact of this method on speech perception in noise at soft speech levels were evaluated.
   Method
   An adaptive psychoacoustic procedure for precise hearing threshold determination (precT) was implemented using MatLab (MathWorks) and a graphical user interface was created. Sound signals were calibrated with a CIC4-Implant-Decoder. Study design: A prospective study including 15 experienced adult cochlear implant users was conducted. Electrical hearing thresholds were determined using the automated precT procedure (auto-precT). Speech perception in noise at 50 dB SPL presentation levels was measured for three conditions: (P1) T-levels kept at the previously established T-levels; (P2) T-levels set to the hearing thresholds determined using auto-precT application; (P3) T-levels set 10 cu below the values determined with auto-precT.
   Results
   All subjects were able to perform the auto-precT application independently. T-levels were altered on average by an absolute value of 10.5 cu using auto-precT. Median speech reception thresholds were significantly improved from 2.5 dB SNR (P1) to 1.6 dB SNR (P2, p = 0.02). Speech perception was lowest using the globally lowered T-levels, median 2.9 dB SNR (P3, not significant compared to P1 and P2).
   Conclusion
   The applicability of the developed auto-precT application was confirmed in the present clinical study. Patients benefited from adjusting previously established T-levels to the threshold levels determined by the auto-precT application. The integration of the application in the clinical fitting routine as well as a remote fitting software approach is recommended. Furthermore, future possibilities of auto-precT include the implementation of the application on tablets or smart phones.
C1 [Plesch, Johannes; Rader, Tobias] Univ Med Ctr, Dept Otolaryngol, Div Audiol Acoust, Mainz, Germany.
   [Ernst, Benjamin P.; Strieth, Sebastian] Univ Med Ctr, Dept Otolaryngol Head & Neck Surg, Mainz, Germany.
   [Rader, Tobias] Univ Munich LMU, Dept Otorhinolaryngol, Div Audiol, Munich, Germany.
RP Rader, T (corresponding author), Univ Med Ctr, Dept Otolaryngol, Div Audiol Acoust, Mainz, Germany.; Rader, T (corresponding author), Univ Munich LMU, Dept Otorhinolaryngol, Div Audiol, Munich, Germany.
EM tobias.rader@med.uni-muenchen.de
RI Rader, Tobias/N-4203-2017
OI Rader, Tobias/0000-0001-7250-2833
FU Cochlear Research and Development Limited Addlestone, United Kingdom;
   German Research FoundationGerman Research Foundation (DFG) [STR 1014]
FX This work was funded by Cochlear Research and Development Limited
   Addlestone, United Kingdom to TR. The study was designed in
   collaboration with Cochlear corporation. SS was supported by the German
   Research Foundation (grant STR 1014). The funders had no role in data
   collection and analysis, decision to publish, or preparation of the
   manuscript.
CR Arndt P, 1999, WITHIN SUBJECT COMP
   Bewley MS, 2013, MINING CLIN DATABASE
   Botros A, 2013, INT J AUDIOL, V52, P485, DOI 10.3109/14992027.2013.781277
   Busby PA, 2016, EAR HEARING, V37, P303, DOI 10.1097/AUD.0000000000000248
   Firszt JB, 2004, EAR HEARING, V25, P375, DOI 10.1097/01.AUD.0000134552.22205.EE
   Holden LK, 2011, INT J AUDIOL, V50, P255, DOI 10.3109/14992027.2010.533200
   Mewes A, 2017, JAHRESTAGUNG DTSCH G
   Plant K, 2005, EAR HEARING, V26, P651, DOI 10.1097/01.aud.0000188201.86799.01
   Rader T, 2018, INT J AUDIOL, V57, P502, DOI 10.1080/14992027.2017.1412519
   SKINNER MW, 1995, J SPEECH HEAR RES, V38, P677, DOI 10.1044/jshr.3803.677
   Skinner MW, 1999, J SPEECH LANG HEAR R, V42, P814, DOI 10.1044/jslhr.4204.814
   Skinner MW, 2002, EAR HEARING, V23, P207, DOI 10.1097/00003446-200206000-00005
   Vaerenberg B, 2014, SCI WORLD J, DOI 10.1155/2014/501738
   van Wieringen A, 2001, EAR HEARING, V22, P528, DOI 10.1097/00003446-200112000-00008
   Willeboer C, 2006, EAR HEARING, V27, P789, DOI 10.1097/01.aud.0000240811.67906.55
NR 15
TC 2
Z9 2
U1 0
U2 0
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD OCT 11
PY 2019
VL 14
IS 10
AR e0223625
DI 10.1371/journal.pone.0223625
PG 17
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA LM8DE
UT WOS:000532477400025
PM 31603927
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Tietze, FA
   Hundertmark, L
   Roy, M
   Zerr, M
   Sinke, C
   Wiswede, D
   Walter, M
   Munte, TF
   Szycik, GR
AF Tietze, Fabian-Alexander
   Hundertmark, Laura
   Roy, Mandy
   Zerr, Michael
   Sinke, Christopher
   Wiswede, Daniel
   Walter, Martin
   Muente, Thomas F.
   Szycik, Gregor R.
TI Auditory Deficits in Audiovisual Speech Perception in Adult Asperger's
   Syndrome: fMRI Study
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE Asperger's syndrome; autism; audiovisual; speech; multisensory; fMRI
ID AUTISM SPECTRUM DISORDERS; MULTISENSORY INTEGRATION; FUNCTIONING AUTISM;
   HEARING LIPS; NEURAL BASIS; CHILDREN; SCHIZOPHRENIA; PATTERNS; GAZE;
   DISCRIMINATION
AB Audiovisual (AV) integration deficits have been proposed to underlie difficulties in speech perception in Asperger's syndrome (AS). It is not known, if the AV deficits are related to alterations in sensory processing at the level of unisensory processing or at levels of conjoint multisensory processing. Functional Magnetic-resonance images (MRI) was performed in 16 adult subjects with AS and 16 healthy controls (HC) matched for age, gender, and verbal IQ as they were exposed to disyllabic AV congruent and AV incongruent nouns. A simple semantic categorization task was used to ensure subjects' attention to the stimuli. The left auditory cortex (BA41) showed stronger activation in HC than in subjects with AS with no interaction regarding AV congruency. This suggests that alterations in auditory processing in unimodal low-level areas underlie AV speech perception deficits in AS. Whether this is signaling a difficulty in the deployment of attention remains to be demonstrated.
C1 [Tietze, Fabian-Alexander; Hundertmark, Laura; Roy, Mandy; Sinke, Christopher; Szycik, Gregor R.] Hannover Med Sch, Dept Psychiat Social Psychiat & Psychotherapy, Hannover, Germany.
   [Roy, Mandy] Asklepios Clin North Ochsenzoll, Hamburg, Germany.
   [Zerr, Michael] Hannover Med Sch, Dept Psychosomat Med & Psychotherapy, Hannover, Germany.
   [Wiswede, Daniel; Muente, Thomas F.] Univ Lubeck, Inst Psychol 2, Lubeck, Germany.
   [Wiswede, Daniel; Muente, Thomas F.] Univ Lubeck, Dept Neurol, Lubeck, Germany.
   [Walter, Martin] Univ Tubingen, Dept Psychiat & Psychotherapy, Tubingen, Germany.
RP Szycik, GR (corresponding author), Hannover Med Sch, Dept Psychiat Social Psychiat & Psychotherapy, Hannover, Germany.
EM szycik.gregor@mh-hannover.de
FU German Research Foundation (DFG)German Research Foundation (DFG); Open
   Access Publication Fund of Hannover Medical School (MHH)
FX We acknowledge support by the German Research Foundation (DFG) and the
   Open Access Publication Fund of Hannover Medical School (MHH).
CR Alcantara JI, 2004, J CHILD PSYCHOL PSYC, V45, P1107, DOI 10.1111/j.1469-7610.2004.t01-1-00303.x
   American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU
   American Psychiatric Association, 2000, DIAGN STAT MAN MENT, V4th
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Baron-Cohen S, 2001, J CHILD PSYCHOL PSYC, V42, P241, DOI 10.1111/1469-7610.00715
   Baumgart F, 1999, NATURE, V400, P724, DOI 10.1038/23390
   Bebko JM, 2014, AUTISM RES, V7, P50, DOI 10.1002/aur.1343
   Bebko JM, 2006, J CHILD PSYCHOL PSYC, V47, P88, DOI 10.1111/j.1469-7610.2005.01443.x
   Beker S, 2018, NEUROSCI BIOBEHAV R, V84, P182, DOI 10.1016/j.neubiorev.2017.11.008
   Boynton GM, 1996, J NEUROSCI, V16, P4207, DOI 10.1523/jneurosci.16-13-04207.1996
   Brandwein AB, 2015, J AUTISM DEV DISORD, V45, P230, DOI 10.1007/s10803-014-2212-9
   Brandwein AB, 2013, CEREB CORTEX, V23, P1329, DOI 10.1093/cercor/bhs109
   Brefczynski-Lewis J, 2009, BRAIN TOPOGR, V21, P193, DOI 10.1007/s10548-009-0093-6
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Dalton KM, 2005, NAT NEUROSCI, V8, P519, DOI 10.1038/nn1421
   de Gelder B, 2003, SCHIZOPHR RES, V59, P211, DOI 10.1016/S0920-9964(01)00344-9
   De Gelder B, 1991, EUROPEAN J COGNITIVE, V3, P69, DOI DOI 10.1080/09541449108406220
   de Heer WA, 2017, J NEUROSCI, V37, P6539, DOI 10.1523/JNEUROSCI.3267-16.2017
   Diederich A, 2015, PSYCHOL REV, V122, P232, DOI 10.1037/a0038696
   Driver J, 1996, NATURE, V381, P66, DOI 10.1038/381066a0
   Feldman JI, 2018, NEUROSCI BIOBEHAV R, V95, P220, DOI 10.1016/j.neubiorev.2018.09.020
   Feldman JI, 2019, J AUTISM DEV DISORD, V49, P397, DOI 10.1007/s10803-018-3667-x
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   Foxe JJ, 2015, CEREB CORTEX, V25, P298, DOI 10.1093/cercor/bht213
   Gaschler-Markefski B., 2006, DYNAMICS SPEECH PROD, P355
   Genovese CR, 2002, NEUROIMAGE, V15, P870, DOI 10.1006/nimg.2001.1037
   Goebel R, 2006, HUM BRAIN MAPP, V27, P392, DOI 10.1002/hbm.20249
   Gondan M, 2005, PERCEPT PSYCHOPHYS, V67, P713, DOI 10.3758/BF03193527
   Hahn N, 2014, NEUROSCI BIOBEHAV R, V47, P384, DOI 10.1016/j.neubiorev.2014.09.007
   Hairston WD, 2003, J COGNITIVE NEUROSCI, V15, P20, DOI 10.1162/089892903321107792
   Hames EC, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00167
   Happe F, 2006, J AUTISM DEV DISORD, V36, P5, DOI 10.1007/s10803-005-0039-0
   Irwin JR, 2011, CHILD DEV, V82, P1397, DOI 10.1111/j.1467-8624.2011.01619.x
   Jones W, 2013, NATURE, V504, P427, DOI 10.1038/nature12715
   Klin A, 2002, ARCH GEN PSYCHIAT, V59, P809, DOI 10.1001/archpsyc.59.9.809
   Kujala T, 2010, CLIN NEUROPHYSIOL, V121, P1410, DOI 10.1016/j.clinph.2010.03.017
   Kwakye LD, 2011, FRONT INTEGR NEUROSC, V4, DOI 10.3389/fnint.2010.00129
   Lancaster JL, 2000, HUM BRAIN MAPP, V10, P120, DOI 10.1002/1097-0193(200007)10:3<120::AID-HBM30>3.0.CO;2-8
   Lee H, 2011, J NEUROSCI, V31, P11338, DOI 10.1523/JNEUROSCI.6510-10.2011
   LEHRL S, 1995, ACTA NEUROL SCAND, V91, P335, DOI 10.1111/j.1600-0404.1995.tb07018.x
   Lepisto T, 2009, BIOL PSYCHOL, V82, P301, DOI 10.1016/j.biopsycho.2009.09.004
   Marco EJ, 2011, PEDIATR RES, V69, p48R, DOI [10.1203/PDR.0b013e3182130c54, 10.1109/SPL.2011.5782616]
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Megnin O, 2012, AUTISM RES, V5, P39, DOI 10.1002/aur.231
   Mongillo EA, 2008, J AUTISM DEV DISORD, V38, P1349, DOI 10.1007/s10803-007-0521-y
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Nath AR, 2011, J NEUROSCI, V31, P1704, DOI 10.1523/JNEUROSCI.4853-10.2011
   Neufeld J, 2012, BRAIN RES, V1473, P78, DOI 10.1016/j.brainres.2012.07.011
   Neumann D, 2006, SOC COGN AFFECT NEUR, V1, P194, DOI 10.1093/scan/nsl030
   Norbury CF, 2009, J CHILD PSYCHOL PSYC, V50, P834, DOI 10.1111/j.1469-7610.2009.02073.x
   Pelphrey KA, 2005, BRAIN, V128, P1038, DOI 10.1093/brain/awh404
   Pelphrey KA, 2002, J AUTISM DEV DISORD, V32, P249, DOI 10.1023/A:1016374617369
   Pierce K, 2011, ARCH GEN PSYCHIAT, V68, P101, DOI 10.1001/archgenpsychiatry.2010.113
   Robertson CE, 2017, NAT REV NEUROSCI, V18, P671, DOI 10.1038/nrn.2017.112
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Ross LA, 2007, SCHIZOPHR RES, V97, P173, DOI 10.1016/j.schres.2007.08.008
   Russeler J, 2015, NEUROSCIENCE, V287, P55, DOI 10.1016/j.neuroscience.2014.12.023
   Russeler J, 2018, BRAIN IMAGING BEHAV, V12, P357, DOI 10.1007/s11682-017-9694-y
   Saalasti S, 2008, J AUTISM DEV DISORD, V38, P1574, DOI 10.1007/s10803-008-0540-3
   Saalasti S, 2012, J AUTISM DEV DISORD, V42, P1606, DOI 10.1007/s10803-011-1400-0
   Saalasti S, 2011, EXP BRAIN RES, V213, P283, DOI 10.1007/s00221-011-2751-7
   Schwartz JL, 2004, COGNITION, V93, pB69, DOI 10.1016/j.cognition.2004.01.006
   Sekiyama K, 2003, NEUROSCI RES, V47, P277, DOI 10.1016/S0168-0102(03)00214-1
   Sinke C, 2014, J NEUROPSYCHOL, V8, P94, DOI 10.1111/jnp.12006
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Stevenson RA, 2017, AUTISM RES, V10, P1280, DOI 10.1002/aur.1776
   Stevenson RA, 2014, J AUTISM DEV DISORD, V44, P1470, DOI 10.1007/s10803-013-1992-7
   Stevenson RA, 2011, NEUROIMAGE, V55, P1339, DOI 10.1016/j.neuroimage.2010.12.063
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Szycik GR, 2013, NEUROSCIENCE, V253, P274, DOI 10.1016/j.neuroscience.2013.08.041
   Szycik GR, 2009, SCHIZOPHR RES, V110, P111, DOI 10.1016/j.schres.2009.03.003
   Szycik GR, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00095
   Szycik GR, 2009, HUM BRAIN MAPP, V30, P1990, DOI 10.1002/hbm.20640
   Talairach J, 1988, CO PLANAR STEREOTACT
   Taylor N, 2010, J AUTISM DEV DISORD, V40, P1403, DOI 10.1007/s10803-010-1000-4
   Williams JHG, 2004, RES DEV DISABIL, V25, P559, DOI 10.1016/j.ridd.2004.01.008
   Williams LE, 2010, NEUROPSYCHOLOGIA, V48, P3128, DOI 10.1016/j.neuropsychologia.2010.06.028
   Wittchen H-U, 1997, ACHSE 1 PSYCHISCHE S
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
   Wright TM, 2003, CEREB CORTEX, V13, P1034, DOI 10.1093/cercor/13.10.1034
   Ye Z, 2017, NEUROSCIENCE, V356, P1, DOI 10.1016/j.neuroscience.2017.05.017
   Zhang J, 2019, J AUTISM DEV DISORD, V49, P34, DOI 10.1007/s10803-018-3680-0
NR 82
TC 1
Z9 1
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD OCT 10
PY 2019
VL 10
AR 2286
DI 10.3389/fpsyg.2019.02286
PG 9
WC Psychology, Multidisciplinary
SC Psychology
GA JN6BE
UT WOS:000496980600001
PM 31649597
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Feng, G
   Zhou, B
   Zhou, W
   Beauchamp, MS
   Magnotti, JF
AF Feng, Guo
   Zhou, Bin
   Zhou, Wen
   Beauchamp, Michael S.
   Magnotti, John F.
TI A Laboratory Study of the McGurk Effect in 324 Monozygotic and Dizygotic
   Twins
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE audiovisual fusion; multisensory integration; McGurk effect; twin
   studies; behavioral genetics
ID AUDIOVISUAL SPEECH INTEGRATION; INDIVIDUAL-DIFFERENCES; HEARING-LIPS;
   INTERINDIVIDUAL DIFFERENCES; SEEING-VOICES; PERCEPTION; SUSCEPTIBILITY;
   CHINESE; SCHIZOPHRENIA; SYLLABLES
AB Multisensory integration of information from the talker's voice and the talker's mouth facilitates human speech perception. A popular assay of audiovisual integration is the McGurk effect, an illusion in which incongruent visual speech information categorically changes the percept of auditory speech. There is substantial interindividual variability in susceptibility to the McGurk effect. To better understand possible sources of this variability, we examined the McGurk effect in 324 native Mandarin speakers, consisting of 73 monozygotic (MZ) and 89 dizygotic (DZ) twin pairs. When tested with 9 different McGurk stimuli, some participants never perceived the illusion and others always perceived it. Within participants, perception was similar across time (r = 0.55 at a 2-year retest in 150 participants) suggesting that McGurk susceptibility reflects a stable trait rather than short-term perceptual fluctuations. To examine the effects of shared genetics and prenatal environment, we compared McGurk susceptibility between MZ and DZ twins. Both twin types had significantly greater correlation than unrelated pairs (r = 0.28 for MZ twins and r = 0.21 for DZ twins) suggesting that the genes and environmental factors shared by twins contribute to individual differences in multisensory speech perception. Conversely, the existence of substantial differences within twin pairs (even MZ co-twins) and the overall low percentage of explained variance (5.5%) argues against a deterministic view of individual differences in multisensory integration.
C1 [Feng, Guo; Zhou, Bin; Zhou, Wen] Chinese Acad Sci, CAS Ctr Excellence Brain Sci & Intelligence Techn, Inst Psychol, CAS Key Lab Behav Sci, Beijing, Peoples R China.
   [Feng, Guo; Zhou, Bin; Zhou, Wen] Univ Chinese Acad Sci, Dept Psychol, Beijing, Peoples R China.
   [Feng, Guo] Southwest Jiaotong Univ, Psychol Res & Counseling Ctr, Chengdu, Sichuan, Peoples R China.
   [Beauchamp, Michael S.; Magnotti, John F.] Baylor Coll Med, Dept Neurosurg & Core Adv MRI, Houston, TX 77030 USA.
RP Zhou, W (corresponding author), Chinese Acad Sci, CAS Ctr Excellence Brain Sci & Intelligence Techn, Inst Psychol, CAS Key Lab Behav Sci, Beijing, Peoples R China.; Zhou, W (corresponding author), Univ Chinese Acad Sci, Dept Psychol, Beijing, Peoples R China.; Magnotti, JF (corresponding author), Baylor Coll Med, Dept Neurosurg & Core Adv MRI, Houston, TX 77030 USA.
EM zhouw@psych.ac.cn; magnotti@bcm.edu
RI Beauchamp, Michael/AAK-9813-2020
OI Beauchamp, Michael/0000-0002-7599-9934; Feng, Guo/0000-0002-8003-8345
FU Key Research Program of Frontier Sciences of the Chinese Academy of
   Sciences [QYZDB-SSW-SMC055]; National Natural Science Foundation of
   ChinaNational Natural Science Foundation of China (NSFC) [31671138];
   Beijing Twin Study project (BeTwiSt) of Institute of Psychology, Chinese
   Academy of Sciences; NIHUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01NS065395]; Gulf
   Coast Consortia, NLM Training Program in Biomedical Informatics (NLM)
   [T15LM007093]; NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND
   STROKEUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute of Neurological
   Disorders & Stroke (NINDS) [R01NS065395, R01NS065395, R01NS065395,
   R01NS065395] Funding Source: NIH RePORTER
FX This work was supported by the Key Research Program of Frontier Sciences
   of the Chinese Academy of Sciences (QYZDB-SSW-SMC055), the National
   Natural Science Foundation of China (31671138), and the Beijing Twin
   Study project (BeTwiSt) of Institute of Psychology, Chinese Academy of
   Sciences. MB was supported by NIH R01NS065395. JM was supported by a
   training fellowship from the Gulf Coast Consortia, NLM Training Program
   in Biomedical Informatics (NLM Grant No. T15LM007093). Portions of this
   work were presented at the International Multisensory Research Forum in
   2014 and 2016.
CR Aloufy S, 1996, BRAIN LANG, V53, P51, DOI 10.1006/brln.1996.0036
   Alsius A, 2018, MULTISENS RES, V31, P111, DOI 10.1163/22134808-00002565
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Beauchamp MS, 2018, MULTISENS RES, V31, P1, DOI 10.1163/22134808-00002598
   Bovo R, 2009, ACTA OTORHINOLARYNGO, V29, P203
   Brown VA, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0207160
   Burnham D, 2004, DEV PSYCHOBIOL, V45, P204, DOI 10.1002/dev.20032
   Burnham D., 1998, P AVSP 98 INT C AUD
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155
   Chen J, 2013, TWIN RES HUM GENET, V16, P91, DOI 10.1017/thg.2012.115
   Chen J, 2010, TWIN RES HUM GENET, V13, P194, DOI 10.1375/twin.13.2.194
   de Gelder B, 2003, SCHIZOPHR RES, V59, P211, DOI 10.1016/S0920-9964(01)00344-9
   Drayna D, 2001, SCIENCE, V291, P1969, DOI 10.1126/science.291.5510.1969
   Fuster-Duran A., 1996, SPEECHREADING HUMANS, P135, DOI DOI 10.1007/978-3-662-13015-5_9
   Gentilucci M, 2005, EXP BRAIN RES, V167, P66, DOI 10.1007/s00221-005-0008-z
   Grassegger H., 1995, P INT C PHON SCI STO
   GRIFFIN D, 1995, PSYCHOL BULL, V118, P430, DOI 10.1037/0033-2909.118.3.430
   Guiraud JA, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036428
   Gurler D, 2015, ATTEN PERCEPT PSYCHO, V77, P1333, DOI 10.3758/s13414-014-0821-1
   Hayiou-Thomas ME, 2012, DEVELOPMENTAL SCI, V15, P233, DOI 10.1111/j.1467-7687.2011.01119.x
   Hazan V., 2007, P AVSP 07 INT C AUD
   HUBERT HB, 1980, SCIENCE, V208, P607, DOI 10.1126/science.7189296
   Jiang JT, 2011, J EXP PSYCHOL HUMAN, V37, P1193, DOI 10.1037/a0023100
   Joseph J, 2015, TROUBLE WITH TWIN STUDIES: A REASSESSMENT OF TWIN RESEARCH IN THE SOCIAL AND BEHAVIORAL SCIENCES, P1
   MacDonald J, 2018, MULTISENS RES, V31, P7, DOI 10.1163/22134808-00002548
   Magnotti JF, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-36772-8
   Magnotti JF, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202908
   Magnotti JF, 2018, MULTISENS RES, V31, P19, DOI 10.1163/22134808-00002586
   Magnotti JF, 2015, EXP BRAIN RES, V233, P2581, DOI 10.1007/s00221-015-4324-7
   Magnotti JF, 2015, PSYCHON B REV, V22, P701, DOI 10.3758/s13423-014-0722-2
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Miller SM, 2010, P NATL ACAD SCI USA, V107, P2664, DOI 10.1073/pnas.0912149107
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Nath AR, 2011, J NEUROSCI, V31, P13963, DOI 10.1523/JNEUROSCI.2605-11.2011
   Pearl D, 2009, COMPR PSYCHIAT, V50, P186, DOI 10.1016/j.comppsych.2008.06.004
   Rogers SJ, 2005, J CHILD PSYCHOL PSYC, V46, P1255, DOI 10.1111/j.1469-7610.2005.01431.x
   Ross DE, 1998, AM J PSYCHIAT, V155, P1352, DOI 10.1176/ajp.155.10.1352
   Sams M, 1998, SPEECH COMMUN, V26, P75, DOI 10.1016/S0167-6393(98)00051-X
   Sekiyama K, 1997, PERCEPT PSYCHOPHYS, V59, P73, DOI 10.3758/BF03206849
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Shahin AJ, 2019, NEUROSCI LETT, V707, DOI 10.1016/j.neulet.2019.134322
   Shahin AJ, 2018, J NEUROSCI, V38, P1835, DOI 10.1523/JNEUROSCI.1566-17.2017
   Smith EG, 2007, J CHILD PSYCHOL PSYC, V48, P813, DOI 10.1111/j.1469-7610.2007.01766.x
   Stevenson RA, 2012, J EXP PSYCHOL HUMAN, V38, P1517, DOI 10.1037/a0027339
   Strand J, 2014, J SPEECH LANG HEAR R, V57, P2322, DOI 10.1044/2014_JSLHR-H-14-0059
   Traunmuller H, 2007, J PHONETICS, V35, P244, DOI 10.1016/j.wocn.2006.03.002
   Tremblay C, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000742
   Van Laarhoven T, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46084-0
   Zhu Q, 2010, CURR BIOL, V20, P137, DOI 10.1016/j.cub.2009.11.067
NR 49
TC 0
Z9 0
U1 2
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD OCT 4
PY 2019
VL 13
AR 1029
DI 10.3389/fnins.2019.01029
PG 8
WC Neurosciences
SC Neurosciences & Neurology
GA JO4TK
UT WOS:000497572300001
PM 31636529
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Trudeau-Fisette, P
   Ito, T
   Menard, L
AF Trudeau-Fisette, Pamela
   Ito, Takayuki
   Menard, Lucie
TI Auditory and Somatosensory Interaction in Speech Perception in Children
   and Adults
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE multisensory integration; speech perception; auditory and somatosensory
   feedback; adults; children; categorization; maturation
ID MULTISENSORY INTEGRATION; VISUAL-CORTEX; YOUNG-CHILDREN; NEURAL THEORY;
   HEARING LIPS; VOCAL-TRACT; DISCRIMINATION; INTENSITY; PERTURBATIONS;
   COORDINATION
AB Multisensory integration (MSI) allows us to link sensory cues from multiple sources and plays a crucial role in speech development. However, it is not clear whether humans have an innate ability or whether repeated sensory input while the brain is maturing leads to efficient integration of sensory information in speech. We investigated the integration of auditory and somatosensory information in speech processing in a bimodal perceptual task in 15 young adults (age 19-30) and 14 children (age 5-6). The participants were asked to identify if the perceived target was the sound /e/ or /o/. Half of the stimuli were presented under a unimodal condition with only auditory input. The other stimuli were presented under a bimodal condition with both auditory input and somatosensory input consisting of facial skin stretches provided by a robotic device, which mimics the articulation of the vowel /e/. The results indicate that the effect of somatosensory information on sound categorization was larger in adults than in children. This suggests that integration of auditory and somatosensory information evolves throughout the course of development.
C1 [Trudeau-Fisette, Pamela; Menard, Lucie] Univ Quebec Montreal, Lab Phonet, Montreal, PQ, Canada.
   [Trudeau-Fisette, Pamela; Menard, Lucie] Ctr Res Brain Language & Mus, Montreal, PQ, Canada.
   [Ito, Takayuki] Univ Grenoble Alpes, CNRS, Grenoble INP, GIPSA Lab, Grenoble, France.
   [Ito, Takayuki] Yale Univ, Haskins Lab, New Haven, CT USA.
RP Trudeau-Fisette, P (corresponding author), Univ Quebec Montreal, Lab Phonet, Montreal, PQ, Canada.; Trudeau-Fisette, P (corresponding author), Ctr Res Brain Language & Mus, Montreal, PQ, Canada.
EM ptrudeaufisette@gmail.com
OI Ito, Takayuki/0000-0002-3265-360X
FU Social Sciences and Humanities Research Council of Canada (Canadian
   Graduate Scholarships); Natural Sciences and Engineering Research
   Council of CanadaNatural Sciences and Engineering Research Council of
   Canada (NSERC)CGIAR; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R56DC016274]
   Funding Source: NIH RePORTER
FX This work was funded by the Social Sciences and Humanities Research
   Council of Canada (both Canadian Graduate Scholarships-a Doctoral
   program and an Insight grant) and the Natural Sciences and Engineering
   Research Council of Canada (a Discovery grant).
CR Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Arabin B, 2002, ULTRASOUND OBST GYN, V20, P425, DOI 10.1046/j.1469-0705.2002.00844.x
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Bahrick L.E., 2012, MULTISENSORY DEV, P183, DOI DOI 10.1093/ACPROF:OSO/9780199586059.003.0008
   Bahrick LE, 2000, DEV PSYCHOL, V36, P190, DOI 10.1037//0012-1649.36.2.190
   Barutchu A, 2010, J EXP CHILD PSYCHOL, V105, P38, DOI 10.1016/j.jecp.2009.08.005
   Barutchu A, 2009, DEVELOPMENTAL SCI, V12, P464, DOI 10.1111/j.1467-7687.2008.00782.x
   BIRCH HG, 1963, MONOGR SOC RES CHILD, V28, P1, DOI 10.2307/1165681
   Boe L.-J, 2007, P 16 INT C PHON SCI, P533
   Boe LJ, 2008, REV FR LING APPL, V13, P59
   BOWER TGR, 1970, PERCEPT PSYCHOPHYS, V8, P51, DOI 10.3758/BF03208933
   Bruderer AG, 2015, P NATL ACAD SCI USA, V112, P13531, DOI 10.1073/pnas.1508631112
   Burr D, 2011, NEURAL BASEMULTISE, P810
   Buss E, 2009, J ACOUST SOC AM, V125, P1050, DOI 10.1121/1.3050273
   DEMANY L, 1977, NATURE, V266, P718, DOI 10.1038/266718a0
   DePaolis RA, 2011, INFANT BEHAV DEV, V34, P590, DOI 10.1016/j.infbeh.2011.06.005
   Desjardins RN, 1997, J EXP CHILD PSYCHOL, V66, P85, DOI 10.1006/jecp.1997.2379
   Dette M, 1982, Stomatol DDR, V32, P269
   Dionne-Dostie E, 2015, BRAIN SCI, V5, P32, DOI 10.3390/brainsci5010032
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Feng YQ, 2011, J NEUROPHYSIOL, V106, P667, DOI 10.1152/jn.00638.2010
   Fitch WT, 1999, J ACOUST SOC AM, V106, P1511, DOI 10.1121/1.427148
   Foxe JJ, 2002, J NEUROPHYSIOL, V88, P540, DOI 10.1152/jn.2002.88.1.540
   Gick B, 2009, NATURE, V462, P502, DOI 10.1038/nature08572
   GISEL EG, 1988, OCCUP THER J RES, V8, P195, DOI 10.1177/153944928800800401
   Gori M, 2008, CURR BIOL, V18, P694, DOI 10.1016/j.cub.2008.04.036
   Guenther F.H., 2004, SPEECH MOTOR CONTROL, P29
   Guenther FH, 2012, J NEUROLINGUIST, V25, P408, DOI 10.1016/j.jneuroling.2009.08.006
   Guest S, 2002, EXP BRAIN RES, V146, P161, DOI 10.1007/s00221-002-1164-z
   HATWELL Y, 1987, INT J BEHAV DEV, V10, P509, DOI 10.1177/016502548701000409
   Hecht D, 2009, EXP BRAIN RES, V193, P307, DOI 10.1007/s00221-008-1626-z
   Hillock AR, 2011, NEUROPSYCHOLOGIA, V49, P461, DOI 10.1016/j.neuropsychologia.2010.11.041
   Holst-Wolf JM, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00436
   Horlyck S, 2012, SCI STUD READ, V16, P218, DOI 10.1080/10888438.2010.546460
   Hotting K, 2004, PSYCHOL SCI, V15, P60, DOI 10.1111/j.0963-7214.2004.01501010.x
   Ito T, 2007, NEUROREPORT, V18, P907, DOI 10.1097/WNR.0b013e32810f2dfb
   Ito T, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01198
   Ito T, 2010, J NEUROPHYSIOL, V104, P1230, DOI 10.1152/jn.00199.2010
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   JOHANSSON RS, 1988, EXP BRAIN RES, V72, P209, DOI 10.1007/BF00248519
   Jousmaki V, 1998, CURR BIOL, V8, pR190, DOI 10.1016/S0960-9822(98)70120-4
   Katseff S, 2012, LANG SPEECH, V55, P295, DOI 10.1177/0023830911417802
   Krakauer JW, 2006, PLOS BIOL, V4, P1798, DOI 10.1371/journal.pbio.0040316
   KRUEGER LE, 1970, PERCEPT PSYCHOPHYS, V7, P337, DOI 10.3758/BF03208659
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   KUMIN LB, 1984, PERCEPT MOTOR SKILL, V59, P123, DOI 10.2466/pms.1984.59.1.123
   Lametti DR, 2012, J NEUROSCI, V32, P9351, DOI 10.1523/JNEUROSCI.0404-12.2012
   Lecanuet J.-P, 1995, FETAL DEV PSYCHOBIOL, P512
   Macaluso E, 2000, SCIENCE, V289, P1206, DOI 10.1126/science.289.5482.1206
   MacDonald EN, 2010, J ACOUST SOC AM, V127, P1059, DOI 10.1121/1.3278606
   MacPherson A, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514537722
   Massaro DW, 1999, TRENDS COGN SCI, V3, P310, DOI 10.1016/S1364-6613(99)01360-1
   MASSARO DW, 1984, CHILD DEV, V55, P1777, DOI 10.1111/j.1467-8624.1984.tb00420.x
   McDonald E. T, 1967, S ORAL SENSATION PER, P202
   MCGURK H, 1980, DEV PSYCHOL, V16, P679
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Menard L, 2004, CAN J LING/REV CAN L, V49, P155, DOI 10.1353/cjl.2005.0003
   Mercier MR, 2013, NEUROIMAGE, V79, P19, DOI 10.1016/j.neuroimage.2013.04.060
   Misceo GF, 1999, PERCEPT PSYCHOPHYS, V61, P608
   Mishra J, 2007, J NEUROSCI, V27, P4120, DOI 10.1523/JNEUROSCI.4912-06.2007
   Molholm S, 2002, COGNITIVE BRAIN RES, V14, P115, DOI 10.1016/S0926-6410(02)00066-6
   Moore DR, 2008, HEARING RES, V238, P147, DOI 10.1016/j.heares.2007.11.013
   Nardini M, 2008, CURR BIOL, V18, P689, DOI 10.1016/j.cub.2008.04.021
   Nasir SM, 2006, CURR BIOL, V16, P1918, DOI 10.1016/j.cub.2006.07.069
   Neil PA, 2006, DEVELOPMENTAL SCI, V9, P454, DOI 10.1111/j.1467-7687.2006.00512.x
   Ogane R, 2017, 2017 SOC NEUR LANG C
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Perrier P., 1995, ZAS PAPERS LINGUSTIC, V40, P109
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Proske U, 2009, J PHYSIOL-LONDON, V587, P4139, DOI 10.1113/jphysiol.2009.175372
   Purcell DW, 2006, J ACOUST SOC AM, V120, P966, DOI 10.1121/1.2217714
   Raij T, 2010, EUR J NEUROSCI, V31, P1772, DOI 10.1111/j.1460-9568.2010.07213.x
   Rentschler I, 2004, BEHAV BRAIN RES, V149, P107, DOI 10.1016/S0166-4328(03)00194-3
   Robert-Ribes J, 1998, J ACOUST SOC AM, V103, P3677, DOI 10.1121/1.423069
   Ross LA, 2011, EUR J NEUROSCI, V33, P2329, DOI 10.1111/j.1460-9568.2011.07685.x
   Schurmann M, 2004, J ACOUST SOC AM, V115, P830, DOI 10.1121/1.1639909
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Spence C., 2004, HDB MULTISENSORY PRO, P3
   Stein B. E., 1993, MERGING SENSES
   Stein BE, 2014, NAT REV NEUROSCI, V15, P520, DOI 10.1038/nrn3742
   Stein BE, 1996, J COGNITIVE NEUROSCI, V8, P497, DOI 10.1162/jocn.1996.8.6.497
   Streri A, 2004, NEUROPSYCHOLOGIA, V42, P1365, DOI 10.1016/j.neuropsychologia.2004.02.012
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   Tremblay S, 2003, NATURE, V423, P866, DOI 10.1038/nature01710
   Trudeau-Fisette P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0180300
   Turgeon C., 2011, MESURE DEV CAPACITE
   Vihman MM, 1996, PHONOLOGICAL DEV ORI
   Villacorta VM, 2007, J ACOUST SOC AM, V122, P2306, DOI 10.1121/1.2773966
   Vorperian HK, 1999, INT J PEDIATR OTORHI, V49, P197, DOI 10.1016/S0165-5876(99)00208-6
   Walker-Andrews A, 1994, DEV INTERSENSORY PER, P39
   Werker JF, 2018, APPL PSYCHOLINGUIST, V39, P703, DOI 10.1017/S0142716418000152
   Yeung HH, 2013, PSYCHOL SCI, V24, P603, DOI 10.1177/0956797612458802
   Yu LP, 2010, J NEUROSCI, V30, P4904, DOI 10.1523/JNEUROSCI.5575-09.2010
NR 94
TC 0
Z9 0
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD OCT 4
PY 2019
VL 13
AR 344
DI 10.3389/fnhum.2019.00344
PG 11
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA JO3DB
UT WOS:000497460500001
PM 31636554
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Schelinski, S
   von Kriegstein, K
AF Schelinski, Stefanie
   von Kriegstein, Katharina
TI Brief Report: Speech-in-Noise Recognition and the Relation to Vocal
   Pitch Perception in Adults with Autism Spectrum Disorder and Typical
   Development
SO JOURNAL OF AUTISM AND DEVELOPMENTAL DISORDERS
LA English
DT Article
DE Autism spectrum disorder; Speech-in-noise; Pitch; F0; Auditory
   perception; Speech perception
ID CHILDREN; INTELLIGIBILITY; INDIVIDUALS; SEGREGATION; INTONATION;
   SEPARATION; ABILITIES; DEFICITS; HEARING; SIZE
AB We tested the ability to recognise speech-in-noise and its relation to the ability to discriminate vocal pitch in adults with high-functioning autism spectrum disorder (ASD) and typically developed adults (matched pairwise on age, sex, and IQ). Typically developed individuals understood speech in higher noise levels as compared to the ASD group. Within the control group but not within the ASD group, better speech-in-noise recognition abilities were significantly correlated with better vocal pitch discrimination abilities. Our results show that speech-in-noise recognition is restricted in people with ASD. We speculate that perceptual impairments such as difficulties in vocal pitch perception might be relevant in explaining these difficulties in ASD.
C1 [Schelinski, Stefanie; von Kriegstein, Katharina] Tech Univ Dresden, Fac Psychol, Chair Cognit & Clin Neurosci, Bamberger Str 7, D-01187 Dresden, Germany.
   [Schelinski, Stefanie; von Kriegstein, Katharina] Max Planck Inst Human Cognit & Brain Sci, Neural Mech Human Commun Grp, Stephanstr 1a, D-04103 Leipzig, Germany.
RP Schelinski, S (corresponding author), Tech Univ Dresden, Fac Psychol, Chair Cognit & Clin Neurosci, Bamberger Str 7, D-01187 Dresden, Germany.; Schelinski, S (corresponding author), Max Planck Inst Human Cognit & Brain Sci, Neural Mech Human Commun Grp, Stephanstr 1a, D-04103 Leipzig, Germany.
EM schelinski@cbs.mpg.de; katharina.von_kriegstein@tu-dresden.de
RI von Kriegstein, Katharina/C-3135-2008
OI von Kriegstein, Katharina/0000-0001-7989-5860
FU Max Planck Research Group Grant; European Research Council (ERC) under
   the European Union's Horizon 2020 research and innovation programme
   (SENSOCOM)European Research Council (ERC) [647051]
FX This work was funded by a Max Planck Research Group Grant and funding
   from the European Research Council (ERC) under the European Union's
   Horizon 2020 research and innovation programme (SENSOCOM, Grant
   Agreement No. 647051) to KvK.
CR Alcantara JI, 2004, J CHILD PSYCHOL PSYC, V45, P1107, DOI 10.1111/j.1469-7610.2004.t01-1-00303.x
   Anderson S, 2010, J AM ACAD AUDIOL, V21, P575, DOI 10.3766/jaaa.21.9.3
   ASSMANN PF, 1990, J ACOUST SOC AM, V88, P680, DOI 10.1121/1.399772
   Barker J, 2007, SPEECH COMMUN, V49, P402, DOI 10.1016/j.specom.2006.11.003
   Baum SH, 2015, PROG NEUROBIOL, V134, P140, DOI 10.1016/j.pneurobio.2015.09.007
   Bidelman GM, 2017, HEARING RES, V351, P34, DOI 10.1016/j.heares.2017.05.008
   BROKX JPL, 1982, J PHONETICS, V10, P23, DOI 10.1016/S0095-4470(19)30909-X
   Brown CA, 2010, HEARING RES, V266, P52, DOI 10.1016/j.heares.2009.08.011
   Brungart DS, 2001, J ACOUST SOC AM, V110, P2527, DOI 10.1121/1.1408946
   Carroll J, 2011, J ACOUST SOC AM, V130, P2054, DOI 10.1121/1.3631563
   De Gelder B, 1991, EUROPEAN J COGNITIVE, V3, P69, DOI DOI 10.1080/09541449108406220
   Demetriou EA, 2018, MOL PSYCHIATR, V23, P1198, DOI 10.1038/mp.2017.75
   Drullman R, 2004, J ACOUST SOC AM, V116, P3090, DOI 10.1121/1.1802535
   Dryden A, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517744675
   DUQUESNOY AJ, 1983, J ACOUST SOC AM, V74, P739, DOI 10.1121/1.389859
   DUQUESNOY AJ, 1983, J ACOUST SOC AM, V74, P1136, DOI 10.1121/1.390037
   FESTEN JM, 1990, J ACOUST SOC AM, V88, P1725, DOI 10.1121/1.400247
   Foxe JJ, 2015, CEREB CORTEX, V25, P298, DOI 10.1093/cercor/bht213
   GLASBERG BR, 1989, SCAND AUDIOL, P1
   Groen WB, 2009, J AUTISM DEV DISORD, V39, P742, DOI 10.1007/s10803-008-0682-3
   Hanson HM, 1999, J ACOUST SOC AM, V106, P1064, DOI 10.1121/1.427116
   Irwin JR, 2011, CHILD DEV, V82, P1397, DOI 10.1111/j.1467-8624.2011.01619.x
   Jiang J, 2015, J AUTISM DEV DISORD, V45, P2067, DOI 10.1007/s10803-015-2370-4
   KAERNBACH C, 1991, PERCEPT PSYCHOPHYS, V49, P227, DOI 10.3758/BF03214307
   Kanakri SM, 2017, RES DEV DISABIL, V63, P85, DOI 10.1016/j.ridd.2017.02.004
   Klatte M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00578
   Kreiman J., 2011, FDN VOICE STUDIES
   Kreitewolf J, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01584
   Lord C, 2000, J AUTISM DEV DISORD, V30, P205, DOI 10.1023/A:1005592401947
   LORD C, 1994, J AUTISM DEV DISORD, V24, P659, DOI 10.1007/BF02172145
   Mackersie CL, 2011, J AM ACAD AUDIOL, V22, P113, DOI 10.3766/jaaa.22.2.6
   McGarrigle R, 2017, J EXP CHILD PSYCHOL, V161, P95, DOI 10.1016/j.jecp.2017.04.006
   Picard M, 2001, AUDIOLOGY, V40, P221
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Schelinski S, 2019, J AUTISM DEV DISORD, V49, P68, DOI 10.1007/s10803-018-3681-z
   Schelinski S, 2017, AUTISM RES, V10, P155, DOI 10.1002/aur.1639
   Schelinski S, 2016, SOC COGN AFFECT NEUR, V11, P1812, DOI 10.1093/scan/nsw089
   Schelinski S, 2014, NEUROPSYCHOLOGIA, V65, P1, DOI 10.1016/j.neuropsychologia.2014.09.031
   Shield BM, 2008, J ACOUST SOC AM, V123, P133, DOI 10.1121/1.2812596
   Smith DRR, 2005, J ACOUST SOC AM, V118, P3177, DOI 10.1121/1.2047107
   Smith DRR, 2005, J ACOUST SOC AM, V117, P305, DOI 10.1121/1.1828637
   Smith EG, 2007, J CHILD PSYCHOL PSYC, V48, P813, DOI 10.1111/j.1469-7610.2007.01766.x
   Stiegler LN, 2010, FOCUS AUTISM DEV DIS, V25, P67, DOI 10.1177/1088357610364530
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Summers V, 1998, J SPEECH LANG HEAR R, V41, P1294, DOI 10.1044/jslhr.4106.1294
   Szalma JL, 2011, PSYCHOL BULL, V137, P682, DOI 10.1037/a0023987
   Tukey J. W., 1977, EXPLORATORY DATA ANA
   van der Kruk Y, 2017, REV J AUTISM DEV DIS, V4, P243, DOI 10.1007/s40489-017-0111-7
   van Laarhoven T, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12504
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
   Ziegler JC, 2009, DEVELOPMENTAL SCI, V12, P732, DOI 10.1111/j.1467-7687.2009.00817.x
NR 51
TC 2
Z9 2
U1 4
U2 9
PU SPRINGER/PLENUM PUBLISHERS
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0162-3257
EI 1573-3432
J9 J AUTISM DEV DISORD
JI J. Autism Dev. Disord.
PD JAN
PY 2020
VL 50
IS 1
BP 356
EP 363
DI 10.1007/s10803-019-04244-1
EA OCT 2019
PG 8
WC Psychology, Developmental
SC Psychology
GA KJ4BP
UT WOS:000489527000001
PM 31583624
DA 2021-02-24
ER

PT J
AU Shintani, N
   Saito, K
   Koizumi, R
AF Shintani, Natsuko
   Saito, Kazuya
   Koizumi, Rie
TI The relationship between multilingual raters' language background and
   their perceptions of accentedness and comprehensibility of second
   language speech
SO INTERNATIONAL JOURNAL OF BILINGUAL EDUCATION AND BILINGUALISM
LA English
DT Article
DE Multilingualism; foreign accent; speech perception; rater severity;
   second language pronunciation
ID EXPERIENCE; ENGLISH; INTELLIGIBILITY; PROFICIENCY; FAMILIARITY;
   JUDGMENTS
AB The purpose of this case study is twofold: it (1) explores multilingual raters' judgements regarding the accentedness and comprehensibility of second language speech and (2) examines how the raters' language backgrounds influence their judgements. In this study, six multilingual Singaporean raters judged the accentedness and comprehensibility of 50 unfamiliar accented speech samples produced by Japanese learners of English with different proficiency levels. In order to investigate rater judgement, the rating scores were subjected to a multifaceted Rasch analysis. A questionnaire and an interview elicited the raters' retrospective reports on their language backgrounds at three time points in their life (when they were 5, 11, and 21 years old). The results suggested that the raters' language backgrounds, notably the proficiency balance between multiple languages in early childhood, are related to their rating judgement.
C1 [Shintani, Natsuko] Univ Auckland, Fac Educ, Auckland, New Zealand.
   [Saito, Kazuya] Birkbeck Univ London, Dept Appl Linguist & Commun, London, England.
   [Koizumi, Rie] Juntendo Univ, Sch Med, English, Chiba, Japan.
RP Shintani, N (corresponding author), Univ Auckland, Fac Educ, Auckland, New Zealand.
EM n.shintani@auckland.ac.nz
OI Saito, Kazuya/0000-0002-4718-2943
FU Japan Society for the Promotion of Science KAKENHIMinistry of Education,
   Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for
   the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI)
   [26770202, 26370737]
FX This study was funded by the Japan Society for the Promotion of Science
   KAKENHI, Grant-in-Aid for Scientific Research [grant number 26770202],
   and [grant number 26370737] awarded to the second and third authors
   respectively.
CR Aman N., 2007, TEACH SSS 2006 PART
   Barkaoui K., 2013, COMPANION LANGUAGE A, VIII, P1301, DOI [10.1002/9781118411360.wbcla070, DOI 10.1002/9781118411360.WBCLA070]
   Boersma Paul, 2012, PRAAT DOING PHONETIC
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Carey MD, 2011, LANG TEST, V28, P201, DOI 10.1177/0265532210393704
   Cavallaro F, 2015, MULTILING MATTER, V156, P33
   de Bot K, 2007, BILING-LANG COGN, V10, P7, DOI 10.1017/S1366728906002732
   Derwing T.M., 1997, STUDIES 2 LANGUAGE A, V19, P1, DOI [10.1017/s0272263197001010, DOI 10.1017/S0272263197001010]
   Derwing TM, 2009, LANG TEACHING, V42, P476, DOI 10.1017/S026144480800551X
   Deterding D., 2000, ENGLISH LANGUAGE SIN, P1, DOI DOI 10.1111/J.1467-9922.2004.00282.X
   Engelhard G, 1998, EDUC PSYCHOL MEAS, V58, P179, DOI 10.1177/0013164498058002003
   GASS S, 1984, LANG LEARN, V34, P65, DOI 10.1111/j.1467-1770.1984.tb00996.x
   Grosjean F., 2004, HDB BILINGUALISM, P32
   Isaacs T, 2013, LANG ASSESS Q, V10, P135, DOI 10.1080/15434303.2013.769545
   Isaakidis T., 2004, INT J MULTILING, V1, P33, DOI DOI 10.1080/14790710408668177
   Jessner U., 2008, LANG TEACHING, V41, P15, DOI DOI 10.1017/S0261444807004739
   Kennedy S, 2008, CAN MOD LANG REV, V64, P459, DOI 10.3138/cmlr.64.3.459
   Kim YH, 2009, LANG TEST, V26, P187, DOI 10.1177/0265532208101010
   Lalwani AK, 2005, J GLOB MARK, V18, P143, DOI 10.1300/J042v18n03_07
   Linacre J., 2014, FACETS MANY FACET RA
   Linacre J. M., 2013, FACETS MANY FACET RA
   Linacre J. M., 1994, RASCH MEASUREMENT T, V8, P2360
   Lunz ME, 1998, QUANT METH SER, P47
   Mackay IRA, 2006, APPL PSYCHOLINGUIST, V27, P157, DOI 10.1017/S0142716406060231
   Major RC, 2002, TESOL QUART, V36, P173, DOI 10.2307/3588329
   Ministry of Home Affairs, 2014, 2014 POP BRIEF
   Ministry of Manpower, 2015, NUMB MANP
   Munro MJ, 2006, STUD SECOND LANG ACQ, V28, P111, DOI 10.1017/S0272263106060049
   Munro Murray J., 2008, PHONOLOGY 2 LANGUAGE, P193, DOI DOI 10.1075/SIBIL.36.10MUN
   Munro Murray J., 2001, STUDIES 2 LANGUAGE A, V23, P451, DOI DOI 10.1111/LANG.12082
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Saito K., 2011, BEGINNER INTER UNPUB
   Saito K, 2017, APPL LINGUIST, V38, P439, DOI 10.1093/applin/amv047
   Saito K, 2016, TESOL QUART, V50, P421, DOI 10.1002/tesq.234
   Tan C. H., 1992, YORK PAPERS LINGUIST, V16, P139
   Tan PKW, 2008, WORLD ENGLISH, V27, P465, DOI 10.1111/j.1467-971X.2008.00578.x
   Tan Y.-Y., 2012, INT J SOCIOL LANG, V2012, P1, DOI DOI 10.1515/ijsl-2012-0057
   THOMAS M, 1994, LANG LEARN, V44, P307, DOI 10.1111/j.1467-1770.1994.tb01104.x
   Trofimovich P, 2006, STUD SECOND LANG ACQ, V28, P1, DOI 10.1017/S0272263106060013
   Trofimovich P, 2012, BILING-LANG COGN, V15, P905, DOI 10.1017/S1366728912000168
   Weil S. A., 2001, J ACOUST SOC AM, V109, P2473, DOI DOI 10.1121/1.4744779
   Winke P, 2013, TESOL QUART, V47, P762, DOI 10.1002/tesq.73
   Winke P, 2013, LANG TEST, V30, P231, DOI 10.1177/0265532212456968
   Yeoh B., 2012, RAPID GROWTH SINGAPO
NR 44
TC 0
Z9 0
U1 4
U2 23
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1367-0050
EI 1747-7522
J9 INT J BILING EDUC BI
JI Int. J. Biling. Educ. Biling.
PD OCT 3
PY 2019
VL 22
IS 7
BP 849
EP 869
DI 10.1080/13670050.2017.1320967
PG 21
WC Education & Educational Research; Linguistics; Language & Linguistics
SC Education & Educational Research; Linguistics
GA IU5MG
UT WOS:000483631000005
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Wrembel, M
   Marecka, M
   Kopeckova, R
AF Wrembel, Magdalena
   Marecka, Marta
   Kopeckova, Romana
TI Extending perceptual assimilation model to L3 phonological acquisition
SO INTERNATIONAL JOURNAL OF MULTILINGUALISM
LA English
DT Article
DE Multilingualism; speech perception; L3 acquisition; Polish phonological
   categories; heritage speakers; L2/L3 learners
ID BILINGUAL ADVANTAGE; LANGUAGE; DISCRIMINATION
AB The scarcity of research on speech perception among multilingual speakers precludes a full understanding of phonological acquisition in the third language (L3). In this controlled case study, we investigate L3 phonological acquisition in the perceptual domain and test the predictions of Perceptual Assimilation Model- L2 (Best & Tyler, 2007) adopted for multilingual learners. We employed an AX discrimination task, testing categorical discrimination of Polish sibilants, and a cross-linguistic similarity task, testing perceptual distance between Polish, English and German vowels. We examined L3 Polish perception in 10 multilinguals (aged 14) with L1 German and L2 English who differed in terms of language status (heritage vs. non-heritage). Their perception tasks performance was analysed for accuracy and reaction time. The cross-linguistic similarity task demonstrated that multilinguals assimilate some L3 sounds to both L1 and L2 categories, with a preference for the latter. In the majority of cases multilinguals make a distinction between similar L1, L2 and L3 sounds. The AX results showed that even beginner L3 learners distinguish highly similar L3 sibilant pairs. Our data suggests that the PAM-L2 model could also be extended to L3 acquisition; however, beginner L3 learners seem more likely to perceive subtle acoustic differences in novel phonological contrasts.
C1 [Wrembel, Magdalena] Adam Mickiewicz Univ, Fac English, Niepodleglosci 4, PL-61874 Poznan, Poland.
   [Marecka, Marta] Jagiellonian Univ, Inst Psychol, Krakow, Poland.
   [Kopeckova, Romana] Univ Munster, English Dept, Munster, Germany.
RP Wrembel, M (corresponding author), Adam Mickiewicz Univ, Fac English, Niepodleglosci 4, PL-61874 Poznan, Poland.
EM magdala@wa.amu.edu.pl
RI Marecka, Marta/AAQ-6907-2020
OI Marecka, Marta/0000-0003-2873-9395; Kopeckova,
   Romana/0000-0001-5647-9784; Wrembel, Magdalena/0000-0001-7804-3199
CR Aliaga-Garcia C, 2011, ACHIEVEMENTS PERSPEC, P41
   Amaro JC, 2017, INT J BILINGUAL, V21, P698, DOI 10.1177/1367006916637287
   Antoniou M, 2015, BILING-LANG COGN, V18, P683, DOI 10.1017/S1366728914000777
   Bardel Camilla, 2012, 3 LANGUAGE ACQUISITI, P61, DOI DOI 10.1075/SIBIL.46.06BAR
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Blank CA, 2009, REV ESTUD LING, V17, P207
   Cabrelli Amaro J., 2012, 3 LANGUAGE ACQUISITI, P33
   Cenoz J, 2013, LANG TEACHING, V46, P71, DOI 10.1017/S0261444811000218
   Cercignani Fausto, 1979, CONSONANTS GERMAN SY
   Enomoto K., 1994, EDINBURGH WORKING PA, V5, P15
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flynn S, 2004, INT J MULTILING, V1, P3, DOI DOI 10.1080/14790710408668175
   Gut U., 2015, UNIVERSAL DIVERSE PA, P71
   Hammarberg B, 2005, INTRO READINGS L3, P11
   Kopeckova R, 2016, INT J MULTILING, V13, P426, DOI 10.1080/14790718.2016.1217603
   Kopeckova R, 2016, INT J MULTILING, V13, P410, DOI 10.1080/14790718.2016.1217605
   Lakens Daniel, 2013, Front Psychol, V4, P863, DOI 10.3389/fpsyg.2013.00863
   MacMillan NA, 1991, DETECTION THEORY USE
   Onishi H, 2016, INT J MULTILING, V13, P459, DOI 10.1080/14790718.2016.1217604
   Patihis L, 2015, INT J BILINGUAL, V19, P3, DOI 10.1177/1367006913476768
   Polinsky M, 2015, BILING-LANG COGN, V18, P163, DOI 10.1017/S1366728913000667
   Ringbom H., 1987, ROLE MOTHER TONGUE F
   Roach P., 2004, J INT PHON ASSOC, V34, P239, DOI DOI 10.1017/S0025100304001768
   Rothman J, 2011, SECOND LANG RES, V27, P107, DOI 10.1177/0267658310386439
   Slabakova R, 2017, INT J BILINGUAL, V21, P651, DOI 10.1177/1367006916655413
   Strange W., 2008, PHONOLOGY 2 LANGUAGE, P153
   Tremblay MC, 2012, J ACOUST SOC AM, V132, P3465, DOI 10.1121/1.4756955
   Westergaard M, 2017, INT J BILINGUAL, V21, P666, DOI 10.1177/1367006916648859
   Wrembel M, 2015, SEARCH NEW PERSPECTI
   Wrembel M, 2010, INT J MULTILING, V7, P75, DOI 10.1080/14790710902972263
   Zygis M., 2006, THESIS
NR 32
TC 1
Z9 1
U1 3
U2 8
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1479-0718
EI 1747-7530
J9 INT J MULTILING
JI Int. J. Multiling.
PD OCT 2
PY 2019
VL 16
IS 4
BP 513
EP 533
DI 10.1080/14790718.2019.1583233
PG 21
WC Education & Educational Research; Linguistics; Language & Linguistics
SC Education & Educational Research; Linguistics
GA JD4XG
UT WOS:000489982600008
DA 2021-02-24
ER

PT J
AU Lifshitz-Ben-Basat, A
   Fostick, L
AF Lifshitz-Ben-Basat, Adi
   Fostick, Leah
TI Music-related abilities among readers with dyslexia
SO ANNALS OF DYSLEXIA
LA English
DT Article
DE Dyslexia; Dyslexia and music; Pitch perception; Speech perception
ID AUDITORY FREQUENCY DISCRIMINATION; TEMPORAL PROCESSING DEFICIT;
   EVENT-RELATED POTENTIALS; DEVELOPMENTAL DYSLEXIA; SPEECH-PERCEPTION;
   CHANGE DEAFNESS; MEMORY DEFICITS; WORKING-MEMORY; PHONOLOGICAL
   AWARENESS; READING-DISABILITY
AB Research suggests that a central difficulty in dyslexia may be impaired rapid temporal processing. Good temporal processing is also needed for musical perception, which relies on the ability to detect rapid changes. Our study is the first to measure the perception of adults with and without dyslexia on all three dimensions of music (rhythm, pitch, and spectrum), as well as their capacity for auditory imagery and detection of slow changes, while controlling for working memory. Participants were undergraduate students, aged 20-35 years: 26 readers with dyslexia and 30 typical readers. Participants completed a battery of tests measuring aptitude for recognizing the similarity/difference in tone pitch or rhythm, spectral resolution, vividness/control of auditory imagination, the ability to detect slow changes in auditory stimuli, and working memory. As expected, readers with dyslexia showed poorer performance in pitch and rhythm than controls, but outperformed them in spectral perception. The data for each test was analyzed separately while controlling for the letter-number sequencing score. No differences between groups were found in slow-change detection or auditory imagery. Our results demonstrated that rapid temporal processing appears to be the main difficulty of readers with dyslexia, who demonstrated poorer performance when stimuli were presented quickly rather than slowly and better performance on a task when no temporal component was involved. These findings underscore the need for further study of temporal processing in readers with dyslexia. Remediation of temporal processing deficits may unmask the preserved or even superior abilities of people with dyslexia, leading to enhanced ability in all areas that utilize the temporal component.
C1 [Lifshitz-Ben-Basat, Adi; Fostick, Leah] Ariel Univ, Dept Commun Disorders, Ariel, Israel.
RP Lifshitz-Ben-Basat, A (corresponding author), Ariel Univ, Dept Commun Disorders, Ariel, Israel.
EM adilb@ariel.ac.il
RI Fostick, Leah/E-6115-2017
OI Fostick, Leah/0000-0003-3594-6229
CR Ahissar M, 2000, P NATL ACAD SCI USA, V97, P6832, DOI 10.1073/pnas.97.12.6832
   Alexander JD, 2008, J EXP PSYCHOL HUMAN, V34, P446, DOI 10.1037/0096-1523.34.2.446
   Anvari SH, 2002, J EXP CHILD PSYCHOL, V83, P111, DOI 10.1016/S0022-0965(02)00124-8
   Aronoff JM, 2013, J ACOUST SOC AM, V134, pEL217, DOI 10.1121/1.4813802
   Atterbury B. W., 1985, J RES MUSIC EDUC, V31, P259
   Ayotte J, 2002, BRAIN, V125, P238, DOI 10.1093/brain/awf028
   Baddeley AD, 2000, J EXP PSYCHOL GEN, V129, P126, DOI 10.1037//0096-3445.129.1.126
   Baldeweg T, 1999, ANN NEUROL, V45, P495, DOI 10.1002/1531-8249(199904)45:4<495::AID-ANA11>3.0.CO;2-M
   Banai K, 2004, AUDIOL NEURO-OTOL, V9, P328, DOI 10.1159/000081282
   Banai K, 2010, DYSLEXIA, V16, P240, DOI 10.1002/dys.407
   BARWICK J, 1989, BRIT J EDUC PSYCHOL, V59, P253, DOI 10.1111/j.2044-8279.1989.tb03097.x
   Beaman CP, 2015, Q J EXP PSYCHOL, V68, P1049, DOI 10.1080/17470218.2015.1034142
   BEAMAN CP, 2018, AUDITORY PERCEPTION, V1, P42
   Beaulieu C, 2005, NEUROIMAGE, V25, P1266, DOI 10.1016/j.neuroimage.2004.12.053
   Ben-Artzi E, 2005, NEUROPSYCHOLOGIA, V43, P714, DOI 10.1016/j.neuropsychologia.2004.08.004
   Benton A. L., 1978, DYSLEXIA APPRAISAL C
   Berent I, 2013, COGN NEUROPSYCHOL, V30, P285, DOI 10.1080/02643294.2013.863182
   Brunye TT, 2010, ACTA PSYCHOL, V135, P209, DOI 10.1016/j.actpsy.2010.06.008
   Deutsch GK, 2005, CORTEX, V41, P354, DOI 10.1016/S0010-9452(08)70272-7
   Dole M, 2014, NEUROPSYCHOLOGIA, V60, P103, DOI 10.1016/j.neuropsychologia.2014.05.016
   Douglas S., 1994, J RES READING, V17, P99, DOI DOI 10.1111/J.1467-9817.1994.TB00057.X
   Drennan WR, 2014, EAR HEARING, V35, pE92, DOI 10.1097/AUD.0000000000000009
   Emery L, 2007, PSYCHOL AGING, V22, P75, DOI 10.1037/0882-7974.22.1.75
   Farmer ME, 1995, PSYCHON B REV, V2, P460, DOI 10.3758/BF03210983
   FAWCETT AJ, 1996, DYSLEXIA SCREENING T
   Fenn KM, 2011, Q J EXP PSYCHOL, V64, P1442, DOI 10.1080/17470218.2011.570353
   Fisher C, 2015, DYSLEXIA, V21, P350, DOI 10.1002/dys.1504
   Flaugnacco E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138715
   Flaugnacco E, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00392
   Forgeard M, 2008, MUSIC PERCEPT, V25, P383, DOI 10.1525/MP.2008.25.4.383
   Fostick L, 2012, PSYCHOL RES, V2, P77
   Fostick L., 2012, PSYCHOL RES, V2, P308, DOI DOI 10.17265/2159-5542/2012.05.004
   Fostick L, 2014, J EXP PSYCHOL HUMAN, V40, P1799, DOI 10.1037/a0037527
   Foxton JM, 2003, NAT NEUROSCI, V6, P343, DOI 10.1038/nn1035
   Gaab N, 2007, RESTOR NEUROL NEUROS, V25, P295
   Garcia RB, 2014, BRIT J DEV PSYCHOL, V32, P17, DOI 10.1111/bjdp.12019
   Gathercole SE, 2005, J CHILD PSYCHOL PSYC, V46, P598, DOI 10.1111/j.1469-7610.2004.00379.x
   Gathercole SE, 2000, BRIT J EDUC PSYCHOL, V70, P177, DOI 10.1348/000709900158047
   GATHERCOLE SE, 1990, J MEM LANG, V29, P336, DOI 10.1016/0749-596X(90)90004-J
   Gonzalez GF, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0143914
   Gordon E. E., 1989, MANUAL ADV MEASURES
   Gori S, 2015, CEREB CORTEX, V25, P1685, DOI 10.1093/cercor/bhu234
   Goswami U, 2013, CORTEX, V49, P1363, DOI 10.1016/j.cortex.2012.05.005
   Gregg MK, 2008, J EXP PSYCHOL HUMAN, V34, P974, DOI 10.1037/0096-1523.34.4.974
   Halpern AR, 2012, ANN NY ACAD SCI, V1252, P200, DOI 10.1111/j.1749-6632.2011.06442.x
   Halpern AR, 2004, NEUROPSYCHOLOGIA, V42, P1281, DOI 10.1016/j.neuropsychologia.2003.12.017
   Halpern AR, 1999, CEREB CORTEX, V9, P697, DOI 10.1093/cercor/9.7.697
   Harris A. J., 1990, IMPROVE READING ABIL
   Hazan V, 2009, J SPEECH LANG HEAR R, V52, P1510, DOI 10.1044/1092-4388(2009/08-0220)
   Heim S, 2001, NEUROREPORT, V12, P507, DOI 10.1097/00001756-200103050-00016
   Herholz SC, 2012, J COGNITIVE NEUROSCI, V24, P1382, DOI 10.1162/jocn_a_00216
   Hoeft F, 2007, P NATL ACAD SCI USA, V104, P4234, DOI 10.1073/pnas.0609399104
   Hubbard TL, 2010, PSYCHOL BULL, V136, P302, DOI 10.1037/a0018436
   Huss M, 2011, CORTEX, V47, P674, DOI 10.1016/j.cortex.2010.07.010
   Jones JL, 2009, J COMMUN DISORD, V42, P226, DOI 10.1016/j.jcomdis.2009.01.001
   Kasirer A, 2017, DYSLEXIA, V23, P99, DOI 10.1002/dys.1550
   Keen AG, 2000, VISION RES, V40, P705, DOI 10.1016/S0042-6989(99)00208-4
   Kraemer DJM, 2005, NATURE, V434, P158, DOI 10.1038/434158a
   Kurby CA, 2009, COGNITION, V112, P457, DOI 10.1016/j.cognition.2009.05.007
   Laasonen M, 2009, J LEARN DISABIL-US, V42, P511, DOI 10.1177/0022219409345013
   Lamb S. J., 1993, ED PSYCHOL, V13, p19?27, DOI DOI 10.1080/0144341930130103
   Leaver AM, 2009, J NEUROSCI, V29, P2477, DOI 10.1523/JNEUROSCI.4921-08.2009
   Lee HY, 2015, PSYCHOL REP, V116, P13, DOI 10.2466/15.28.PR0.116k15w8
   Leong V, 2014, HEARING RES, V308, P141, DOI 10.1016/j.heares.2013.07.015
   Lohvansuu K, 2014, INT J PSYCHOPHYSIOL, V94, P298, DOI 10.1016/j.ijpsycho.2014.10.002
   LOVEGROVE WJ, 1980, SCIENCE, V210, P439, DOI 10.1126/science.7433985
   Mayringer H, 2000, J EXP CHILD PSYCHOL, V75, P116, DOI 10.1006/jecp.1999.2525
   Messaoud-Galusi S, 2011, J SPEECH LANG HEAR R, V54, P1682, DOI 10.1044/1092-4388(2011/09-0261)
   Meyler A, 2005, DYSLEXIA, V11, P93, DOI 10.1002/dys.294
   Mody M, 1997, J EXP CHILD PSYCHOL, V64, P199, DOI 10.1006/jecp.1996.2343
   Neuhoff JG, 2015, ATTEN PERCEPT PSYCHO, V77, P1189, DOI 10.3758/s13414-015-0871-z
   Neuhoff JG, 2014, PERCEPTION, V43, P219, DOI 10.1068/p7665
   Nicolson RI, 2001, TRENDS NEUROSCI, V24, P508, DOI 10.1016/S0166-2236(00)01896-8
   NICOLSON RI, 1990, COGNITION, V35, P159, DOI 10.1016/0010-0277(90)90013-A
   Noordenbos MW, 2012, NEUROPSYCHOLOGIA, V50, P2010, DOI 10.1016/j.neuropsychologia.2012.04.026
   Noordenbos MW, 2013, CLIN NEUROPHYSIOL, V124, P1151, DOI 10.1016/j.clinph.2012.12.044
   Oganian Y, 2012, NEUROPSYCHOLOGIA, V50, P1895, DOI 10.1016/j.neuropsychologia.2012.04.014
   Ortiz R, 2014, RES DEV DISABIL, V35, P2673, DOI 10.1016/j.ridd.2014.07.007
   Overy K, 2003, DYSLEXIA, V9, P18, DOI 10.1002/dys.233
   Pfordresher PQ, 2013, PSYCHON B REV, V20, P747, DOI 10.3758/s13423-013-0401-8
   REED MA, 1989, J EXP CHILD PSYCHOL, V48, P270, DOI 10.1016/0022-0965(89)90006-4
   Rensink RA, 1997, PSYCHOL SCI, V8, P368, DOI 10.1111/j.1467-9280.1997.tb00427.x
   Ronen M, 2018, ACTA PSYCHOL, V190, P1, DOI 10.1016/j.actpsy.2018.06.010
   Santos A, 2007, NEUROPSYCHOLOGIA, V45, P1080, DOI 10.1016/j.neuropsychologia.2006.09.010
   Schaadt G., 2016, DEVELOPMENTAL SCI, V19, P1010
   Schurmann M, 2002, NEUROIMAGE, V16, P434, DOI 10.1006/nimg.2002.1098
   SHALEM Z, 1998, DIAGNOSTIC BATTERY R
   SHAYWITZ SE, 1992, NEW ENGL J MED, V326, P145, DOI 10.1056/NEJM199201163260301
   Simons DJ, 2005, TRENDS COGN SCI, V9, P16, DOI 10.1016/j.tics.2004.11.006
   Simons DJ, 1998, PSYCHON B REV, V5, P644, DOI 10.3758/BF03208840
   Soemer A, 2015, PSYCHON B REV, V22, P1777, DOI 10.3758/s13423-015-0854-z
   Sprenger-Charolles L, 2011, SCI STUD READ, V15, P498, DOI 10.1080/10888438.2010.524463
   Stein J, 1997, TRENDS NEUROSCI, V20, P147, DOI 10.1016/S0166-2236(96)01005-3
   Stein J., 2001, SENSORIMOTOR BASIS D, P65
   Stoodley CJ, 2013, CEREBELLUM, V12, P267, DOI 10.1007/s12311-012-0407-1
   Stringham D. A., 2011, AUDEA, V16, P9
   Tafti MA, 2009, SOC BEHAV PERSONAL, V37, P1009, DOI 10.2224/sbp.2009.37.8.1009
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Temple E, 2000, P NATL ACAD SCI USA, V97, P13907, DOI 10.1073/pnas.240461697
   Thomson JM, 2008, J PHYSIOL-PARIS, V102, P120, DOI 10.1016/j.jphysparis.2008.03.007
   Thomson JM, 2006, J RES READ, V29, P334, DOI 10.1111/j.1467-9817.2006.00312.x
   Tierney A, 2013, PROG BRAIN RES, V207, P209, DOI 10.1016/B978-0-444-63327-9.00008-4
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   Vitevitch MS, 2003, J EXP PSYCHOL HUMAN, V29, P333, DOI 10.1037/0096-1523.29.2.333
   Wang ZK, 2014, DYSLEXIA, V20, P280, DOI 10.1002/dys.1475
   Wechsler D., 2008, WECHSLER ADULT INTEL
   Wijnen F, 2012, J SPEECH LANG HEAR R, V55, P1387, DOI 10.1044/1092-4388(2012/10-0302)
   Wolff P. H., 2002, READ WRIT, V15, P179, DOI [10.1023/A:1013880723925, DOI 10.1023/A:1013880723925]
   Wybrow DP, 2015, COGN NEUROPSYCHOL, V32, P1, DOI 10.1080/02643294.2014.998185
   Yoo SS, 2001, NEUROREPORT, V12, P3045, DOI 10.1097/00001756-200110080-00013
   Zatorre RJ, 1996, J COGNITIVE NEUROSCI, V8, P29, DOI 10.1162/jocn.1996.8.1.29
   Zatorre RJ, 2010, J COGNITIVE NEUROSCI, V22, P775, DOI 10.1162/jocn.2009.21239
   Zhao J, 2015, DYSLEXIA, V21, P304, DOI 10.1002/dys.1516
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
   Ziegler JC, 2012, BRAIN LANG, V120, P265, DOI 10.1016/j.bandl.2011.12.002
NR 115
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0736-9387
EI 1934-7243
J9 ANN DYSLEXIA
JI Ann. Dyslexia
PD OCT
PY 2019
VL 69
IS 3
BP 318
EP 334
DI 10.1007/s11881-019-00185-7
PG 17
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA KQ7SY
UT WOS:000517121700004
PM 31446571
DA 2021-02-24
ER

PT J
AU Cabrera, L
   Liu, HM
   Granjon, L
   Kao, C
   Tsao, FM
AF Cabrera, Laurianne
   Liu, Huei-Mei
   Granjon, Lionel
   Kao, Chieh
   Tsao, Feng-Ming
TI Discrimination and identification of lexical tones and consonants in
   Mandarin-speaking children using cochlear implants
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID PROFOUNDLY DEAF-CHILDREN; SPEECH-PERCEPTION; NORMAL-HEARING;
   FINE-STRUCTURE; LANGUAGE; RECOGNITION; AGE; INFORMATION; FRENCH; SKILLS
AB Mandarin-speaking adults using cochlear implants (CI) experience more difficulties in perceiving lexical tones than consonants. This problem may result from the fact that CIs provide relatively sufficient temporal envelope information for consonant perception in quiet environments, but do not convey the fine spectro-temporal information considered to be necessary for accurate pitch perception. Another possibility is that Mandarin speakers with post-lingual hearing loss have developed language-specific use of these acoustic cues, impeding lexical tone processing under CI conditions. To investigate this latter hypothesis, syllable discrimination and word identification abilities for Mandarin consonants (place and manner) and lexical-tone contrasts (tones 1 vs 3 and 1 vs 2) were measured in 15 Mandarin-speaking children using CIs and age-matched children with normal hearing (NH). In the discrimination task, only children using CIs exhibited significantly lower scores for consonant place contrasts compared to other contrasts, including lexical tones. In the word identification task, children using CIs showed lower performance for all contrasts compared to children with NH, but they both showed specific difficulties with tone 1 vs 2 contrasts. This study suggests that Mandarin-speaking children using CIs are able to discriminate and identify lexical tones and, perhaps more surprisingly, have more difficulties when discriminating consonants. (C) 2019 Acoustical Society of America.
C1 [Cabrera, Laurianne; Granjon, Lionel] Univ Paris 05, Integrat Neurosci & Cognit Ctr, 45 Rue St Peres, F-75006 Paris, France.
   [Liu, Huei-Mei] Natl Taiwan Normal Univ, Dept Special Educ, 162,Sect 1,Heping E Rd, Taipei 106, Taiwan.
   [Kao, Chieh; Tsao, Feng-Ming] Natl Taiwan Univ, Dept Psychol, 1,Sect 4,Roosevelt Rd, Taipei 10617, Taiwan.
   [Cabrera, Laurianne; Granjon, Lionel] CNRS, Integrat Neurosci & Cognit Ctr, 45 Rue St Peres, F-75006 Paris, France.
   [Liu, Huei-Mei] Natl Taiwan Normal Univ, Inst Res Excellence Learning Sci, 162,Sect 1,Heping E Rd, Taipei 106, Taiwan.
   [Kao, Chieh] Univ Minnesota Twin Cities, Dept Speech Language Hearing Sci, 115 Shevlin Hall,164 Pillsbury Dr Southeast, Minneapolis, MN 55455 USA.
   [Tsao, Feng-Ming] Natl Taiwan Univ, Imagining Ctr Integrated Body Mind & Culture Res, 1,Sec 4,Roosevelt Rd, Taipei 10617, Taiwan.
RP Tsao, FM (corresponding author), Natl Taiwan Univ, Dept Psychol, 1,Sect 4,Roosevelt Rd, Taipei 10617, Taiwan.
EM tsaosph@mail2000.com.tw
OI Kao, Chieh/0000-0003-0154-650X
FU Ministry of Science and Technology of TaiwanMinistry of Science and
   Technology, Taiwan [102-2923-H-002-001-MY3]; Agence Nationale de la
   Recherche of FranceFrench National Research Agency (ANR)
   [ANR-12-ISH2-0001-01]
FX The work of F.M.T. was supported by the Ministry of Science and
   Technology of Taiwan under Grant No. 102-2923-H-002-001-MY3. L.C. was
   supported by the Agence Nationale de la Recherche of France, under Grant
   No. ANR-12-ISH2-0001-01. We wish to thank Dr. Josiane Bertoncini, who
   initiated this research program and provided helpful comments on the
   manuscript. We also thank Dr. Aurore Gautreau, who helped to design the
   experiment, and Dr. Lorna Halliday for helpful comments on the
   manuscript. Finally, we give warm thanks to all the participants and
   schools and the NWL Foundation for the Hearing Impaired in Taiwan who
   took part in this research study.
CR Blamey PJ, 2001, J SPEECH LANG HEAR R, V44, P264, DOI 10.1044/1092-4388(2001/022)
   Bouton S, 2012, J SPEECH LANG HEAR R, V55, P139, DOI 10.1044/1092-4388(2011/10-0330)
   Brown L., 2010, TEST NONVERBAL INTEL
   Cabrera L, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01290
   Cabrera L, 2014, J ACOUST SOC AM, V136, P877, DOI 10.1121/1.4887444
   Ciocca V, 2002, J ACOUST SOC AM, V111, P2250, DOI 10.1121/1.1471897
   Collier R., 1975, STRUCTURE PROCESS SP, P107
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538
   Fu Q-J, 2000, ASIA PAC J SPEECH LA, V5, P45, DOI DOI 10.1179/136132800807547582
   GANDOUR J, 1981, J CHINESE LINGUIST, V9, P20
   GANDOUR JT, 1978, LANG SPEECH, V21, P1, DOI 10.1177/002383097802100101
   Geers A, 2003, EAR HEARING, V24, p24S, DOI 10.1097/01.AUD.0000051687.99218.0F
   Geers AE, 2003, EAR HEARING, V24, p59S, DOI 10.1097/01.AUD.0000051690.43989.5D
   Han DM, 2009, EAR HEARING, V30, P169, DOI 10.1097/AUD.0b013e31819342cf
   Havy M, 2013, J COMMUN DISORD, V46, P181, DOI 10.1016/j.jcomdis.2012.12.002
   He WS, 2012, PROCEEDINGS OF THE XI'AN 2012 INTERNATIONAL CONFERENCE OF SPORT SCIENCE & PHYSICAL EDUCATION, VOL I: SCIENCE AND INNOVATION IN SPORTS, P334
   Holt RF, 2012, INT J PEDIATR OTORHI, V76, P680, DOI 10.1016/j.ijporl.2012.02.020
   Khouw E, 2007, J PHONETICS, V35, P104, DOI 10.1016/j.wocn.2005.10.003
   KIRK KI, 1995, EAR HEARING, V16, P470, DOI 10.1097/00003446-199510000-00004
   Koning R, 2016, HEARING RES, V342, P13, DOI 10.1016/j.heares.2016.09.002
   Kuo YC, 2008, J ACOUST SOC AM, V123, P2815, DOI 10.1121/1.2896755
   Lammers MJW, 2015, LARYNGOSCOPE, V125, P985, DOI 10.1002/lary.25045
   Lee KYS, 2002, INT J PEDIATR OTORHI, V63, P137, DOI 10.1016/S0165-5876(02)00005-8
   Liu HM, 2007, DEV PSYCHOL, V43, P912, DOI 10.1037/0012-1649.43.4.912
   Liu QY, 2013, OTOL NEUROTOL, V34, P471, DOI 10.1097/MAO.0b013e318286836b
   Lu L., 1988, PEABODY PICTURE VOCA
   Lund E, 2016, J DEAF STUD DEAF EDU, V21, P107, DOI 10.1093/deafed/env060
   MacMillan NA, 1991, DETECTION THEORY USE
   Medina V., 2009, P 10 ANN C INT SPEEC
   Miyamoto RT, 2008, ACTA OTO-LARYNGOL, V128, P373, DOI 10.1080/00016480701785012
   Moore BCJ, 2008, JARO-J ASSOC RES OTO, V9, P399, DOI 10.1007/s10162-008-0143-x
   Nooteboom S., 1997, HDB PHONETIC SCI, P640, DOI 10.1017/S0142716412000690
   Peng SC, 2004, EAR HEARING, V25, P251, DOI 10.1097/01.AUD.0000130797.73809.40
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Sarant JZ, 2001, EAR HEARING, V22, P18, DOI 10.1097/00003446-200102000-00003
   Shannon RV, 2012, CURR OPIN NEUROL, V25, P61, DOI 10.1097/WCO.0b013e32834ef878
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   Stilp CE, 2013, J ACOUST SOC AM, V133, pEL136, DOI 10.1121/1.4776773
   Svirsky MA, 2000, PSYCHOL SCI, V11, P153, DOI 10.1111/1467-9280.00231
   Tomblin JB, 2005, J SPEECH LANG HEAR R, V48, P853, DOI 10.1044/1092-4388(2005/059)
   Tsao F.-M., 2008, CHINESE J PSYCHOL, V50, P111, DOI [10.6129/CJP.2008.5002.01, DOI 10.6129/CJP.2008.5002.01]
   Tsao FM, 2006, J ACOUST SOC AM, V120, P2285, DOI 10.1121/1.2338290
   Uhler K, 2011, J AM ACAD AUDIOL, V22, P129, DOI 10.3766/jaaa.22.3.2
   Valimaa T, 2018, INT J LANG COMM DIS, V53, P3, DOI 10.1111/1460-6984.12322
   VANCE TJ, 1976, PHONETICA, V33, P368, DOI 10.1159/000259793
   WHALEN DH, 1992, PHONETICA, V49, P25, DOI 10.1159/000261901
   Wong AOC, 2004, OTOLARYNG HEAD NECK, V130, P751, DOI 10.1016/j.otohns.2003.09.037
   Wong PS, 2005, J SPEECH LANG HEAR R, V48, P1065, DOI 10.1044/1092-4388(2005/074)
   Xu L, 2005, J ACOUST SOC AM, V117, P3255, DOI 10.1121/1.1886405
   Xu L, 2003, J ACOUST SOC AM, V114, P3024, DOI 10.1121/1.1623786
   Xu L, 2002, J ACOUST SOC AM, V112, P247, DOI 10.1121/1.1487843
   Yang Y. F., 1989, ACTA PSYCHOL SINICA, V34, P29
   Zeng FG, 2005, P NATL ACAD SCI USA, V102, P2293, DOI 10.1073/pnas.0406460102
   Zhou N, 2008, J ACOUST SOC AM, V123, P1653, DOI 10.1121/1.2832623
   Zhou N, 2013, OTOL NEUROTOL, V34, P499, DOI 10.1097/MAO.0b013e318287ca86
NR 57
TC 0
Z9 0
U1 1
U2 2
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD OCT
PY 2019
VL 146
IS 4
BP 2291
EP 2302
DI 10.1121/1.5126941
PG 12
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA KB9NN
UT WOS:000506814200030
PM 31671989
DA 2021-02-24
ER

PT J
AU Liu, C
   Chung, KKH
   Fung, WK
AF Liu, Catrina
   Chung, Kevin Kien Hoa
   Fung, Wing Kai
TI Bidirectional relationships between children's executive functioning,
   visual skills, and word reading ability during the transition from
   kindergarten to primary school
SO CONTEMPORARY EDUCATIONAL PSYCHOLOGY
LA English
DT Article
DE Executive functioning; Visual skills; Chinese word reading ability;
   English word reading ability; School transition
ID SELF-REGULATION; VISUOMOTOR INTEGRATION; PHONOLOGICAL AWARENESS;
   INHIBITORY CONTROL; SPEECH-PERCEPTION; SPATIAL SKILL; HONG-KONG;
   CHINESE; ENGLISH; ACQUISITION
AB This longitudinal study investigated the bidirectional relationships between executive functioning (EF), visual skills, Chinese and English word reading abilities in children transitioning to primary school. A total of 165 children in Hong Kong were followed from the third year of kindergarten (Time 1) (mean age: 62.80 months, SD: 3.74) to the first year of primary school (Time 2) (mean age: 77.25 months, SD: 4.60). Assessments for measuring EF, visual skills, phonological awareness, morphological awareness, and Chinese and English word reading were administered to the children at the two time points. Results of cross-lagged panel analyses revealed that after age, phonological awareness, and morphological awareness were controlled, EF and visual skills exhibited a bidirectional relationship. Furthermore, EF and word reading in Chinese or English reciprocally predicted each other during the school transition period after other skills were controlled. However, visual skills and word reading in Chinese or English did not predict each other. These findings highlight the close associations between EF and visual skills as well as the importance of EF in learning to read Chinese and English in kindergarten and early primary school.
C1 [Liu, Catrina; Chung, Kevin Kien Hoa; Fung, Wing Kai] Educ Univ Hong Kong, Dept Early Childhood Educ, Hong Kong, Peoples R China.
RP Chung, KKH (corresponding author), Educ Univ Hong Kong, Tai Po, B2-1F-35,10 Lo Ping Rd, Hong Kong, Peoples R China.
EM kevin@eduhk.hk; s1103585@s.eduhk.hk
RI Chung, Kevin K H/AAE-3949-2020
OI Chung, Kevin K H/0000-0002-8105-7361; LIU, Catrina/0000-0003-2857-5343
FU Research Grants Council of the Hong Kong Special Administrative Region,
   ChinaHong Kong Research Grants Council [EdUHK 840308, 841311]
FX The work described in this paper was partially supported by grants from
   the Research Grants Council of the Hong Kong Special Administrative
   Region, China (EdUHK 840308 and 841311) to Kevin Kien Hoa Chung.
CR Becker DR, 2014, EARLY CHILD RES Q, V29, P411, DOI 10.1016/j.ecresq.2014.04.014
   Blair C, 2007, CHILD DEV, V78, P647, DOI 10.1111/j.1467-8624.2007.01019.x
   Blair C, 2015, DEV PSYCHOL, V51, P459, DOI 10.1037/a0038813
   Blair C, 2015, ANNU REV PSYCHOL, V66, P711, DOI 10.1146/annurev-psych-010814-015221
   Blair C, 2008, MIND BRAIN EDUC, V2, P80, DOI 10.1111/j.1751-228X.2008.00036.x
   Cameron CE, 2015, DEV PSYCHOL, V51, P1529, DOI 10.1037/a0039740
   Cameron CE, 2012, CHILD DEV, V83, P1229, DOI 10.1111/j.1467-8624.2012.01768.x
   Chan WL, 2010, EARLY CHILD DEV CARE, V180, P973, DOI 10.1080/03004430802586130
   Chen X, 2009, READ WRIT, V22, P615, DOI 10.1007/s11145-008-9127-9
   Cheung H., 2003, READING DEV CHINESE, P3
   Cheung H, 2010, J EDUC PSYCHOL, V102, P367, DOI 10.1037/a0017850
   Cheung K.-H., 2002, J CHINESE LINGUISTIC, V18
   Chow BWY, 2010, J RES READ, V33, P284, DOI 10.1111/j.1467-9817.2009.01414.x
   Chow BWY, 2005, J EDUC PSYCHOL, V97, P81, DOI 10.1037/0022-0663.97.1.81
   Chung FHK, 2008, CLIN LINGUIST PHONET, V22, P379, DOI 10.1080/02699200701776757
   Chung KKH, 2017, EDUC PSYCHOL-UK, V37, P402, DOI 10.1080/01443410.2016.1179264
   Chung KKH, 2013, J RES READ, V36, P202, DOI 10.1111/j.1467-9817.2011.01500.x
   Chung KKH, 2011, J EDUC PSYCHOL, V103, P909, DOI 10.1037/a0024744
   Chung KKH, 2018, READ WRIT, V31, P155, DOI 10.1007/s11145-017-9779-4
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Cohen L, 2002, BRAIN, V125, P1054, DOI 10.1093/brain/awf094
   Cole DA, 2003, J ABNORM PSYCHOL, V112, P558, DOI 10.1037/0021-843X.112.4.558
   Dehaene S., 2009, READING BRAIN NEW SC
   Diamond A, 2013, ANNU REV PSYCHOL, V64, P135, DOI 10.1146/annurev-psych-113011-143750
   Dowsett SM, 2000, DEV PSYCHOBIOL, V36, P161, DOI 10.1002/(SICI)1098-2302(200003)36:2<161::AID-DEV7>3.0.CO;2-0
   Duncan GJ, 2007, DEV PSYCHOL, V43, P1428, DOI 10.1037/0012-1649.43.6.1428
   Ehri LC, 2005, SCI STUD READ, V9, P167, DOI 10.1207/s1532799xssr0902_4
   Ehri LC, 2014, SCI STUD READ, V18, P5, DOI 10.1080/10888438.2013.819356
   Floyer-Lea A, 2004, J NEUROPHYSIOL, V92, P2405, DOI 10.1152/jn.01092.2003
   Fuhs MW, 2014, DEV PSYCHOL, V50, P1698, DOI 10.1037/a0036633
   Gardner M. F., 1996, TEST VISUAL PERCEPTU
   Ho C. S.-H., 1999, ED CHILD PSYCHOL, V16, P4
   Ho C.S.H., 2003, READING DEV CHINESE, P51
   Ho CS-H., 2000, HONG KONG TEST SPECI
   Ho CSH, 1997, READ RES QUART, V32, P276, DOI 10.1598/RRQ.32.3.3
   Ho CSH, 1997, DEV PSYCHOL, V33, P946, DOI 10.1037/0012-1649.33.6.946
   Hu CF, 1998, SCI STUD READ, V2, P55, DOI DOI 10.1207/S1532799XSSR0201_3
   Hu LT, 1998, PSYCHOL METHODS, V3, P424, DOI 10.1037/1082-989X.3.4.424
   Kim H, 2016, AERA OPEN, V2, DOI 10.1177/2332858416675124
   Korkman M., 1998, NEPSY DEV NEUROPSYCH
   Lan XZ, 2011, J EXP CHILD PSYCHOL, V108, P677, DOI 10.1016/j.jecp.2010.11.001
   Law N, 1998, COGNITIVE PROCESSING, P113, DOI DOI 10.1007/978-94-015-9161-4_7
   Leung M. T, 2002, 9 M INT CLIN PHON LI
   Li H, 2012, J RES READ, V35, P287, DOI 10.1111/j.1467-9817.2010.01460.x
   Lin CY, 2018, READ WRIT, V31, P99, DOI 10.1007/s11145-017-9775-8
   Lin D, 2016, CONTEMP EDUC PSYCHOL, V46, P94, DOI 10.1016/j.cedpsych.2016.04.008
   Luo YC, 2013, SCI STUD READ, V17, P22, DOI 10.1080/10888438.2012.689790
   McBride C., 2016, CHILDRENS LITERACY D
   McBride-Chang C, 2000, J EDUC PSYCHOL, V92, P50, DOI 10.1037/0022-0663.92.1.50
   McBride-Chang C, 2002, CHILD DEV, V73, P1392, DOI 10.1111/1467-8624.00479
   Mcbride-Chang C., 2005, READ WRIT, V18, P99, DOI [DOI 10.1007/S11145-004-7343-5, 10.1007/s11145-004-7343-5]
   McBride-Chang C, 2011, J EXP CHILD PSYCHOL, V109, P256, DOI 10.1016/j.jecp.2010.12.003
   McClelland MM, 2007, DEV PSYCHOL, V43, P947, DOI 10.1037/0012-1649.43.4.947
   McClelland MM, 2018, EARLY CHILD RES Q, V46, P142, DOI 10.1016/j.ecresq.2018.03.014
   McClelland MM, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00599
   McKinnon RD, 2018, EARLY CHILD RES Q, V46, P152, DOI 10.1016/j.ecresq.2018.03.011
   Miyake A, 2000, COGNITIVE PSYCHOL, V41, P49, DOI 10.1006/cogp.1999.0734
   Muthen LK., 1998, MPLUS USERS GUIDE, VSeventh
   National Institute of Child Health and Human Development, 2000, NIH PUBLICATION, V00-4769
   Newcombe NS, 2010, MIND BRAIN EDUC, V4, P102, DOI 10.1111/j.1751-228X.2010.01089.x
   Rimm-Kaufman SE, 2000, J APPL DEV PSYCHOL, V21, P491, DOI 10.1016/S0193-3973(00)00051-4
   Schmitt SA, 2017, J EDUC PSYCHOL, V109, P1120, DOI 10.1037/edu0000193
   Selig J.P., 2012, HDB DEV RES METHODS, P265
   Shu H, 2003, CHILD DEV, V74, P27, DOI 10.1111/1467-8624.00519
   Siok WT, 2001, DEV PSYCHOL, V37, P886, DOI 10.1037//0012-1649.37.6.886
   Tabachnick B. G., 2006, INV WORKSH M W PSYCH
   Tan LH, 2001, NEUROIMAGE, V13, P836, DOI 10.1006/nimg.2001.0749
   Vygotsky LS, 1978, MIND SOC DEV HIGHER, P79, DOI [DOI 10.1525/AA.1979.81.4.02A00580, 10.1016/S0006-]
   Wechsler D., 1991, WECHSLER INTELLIGENC
   Welsh JA, 2010, J EDUC PSYCHOL, V102, P43, DOI 10.1037/a0016738
   Wong N. C., 2003, EARLY CHILD DEVELOPM, V173, P83, DOI DOI 10.1080/0300443022000022440
   Yang LY, 2013, EDUC PSYCHOL REV, V25, P115, DOI 10.1007/s10648-013-9217-3
   Zelazo P. D., 2010, HDB CHILDHOOD COGNIT, P574, DOI [DOI 10.1002/9780470996652.CH20, 10.1002/9781444325485.ch22.]
   Zelazo PD, 2012, CHILD DEV PERSPECT, V6, P354, DOI 10.1111/j.1750-8606.2012.00246.x
   Zhang, 2017, BIOMED RES INT, V8
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
NR 76
TC 5
Z9 5
U1 2
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0361-476X
EI 1090-2384
J9 CONTEMP EDUC PSYCHOL
JI Contemp. Educ. Psychol.
PD OCT
PY 2019
VL 59
AR 101779
DI 10.1016/j.cedpsych.2019.101779
PG 9
WC Psychology, Educational
SC Psychology
GA JW8TQ
UT WOS:000503319800002
DA 2021-02-24
ER

PT J
AU Byeon, H
AF Byeon, Haewon
TI Development Trends of Online-based Aural Rehabilitation Programs for
   Children with Cochlear Implant Coping with the Fourth Industrial
   Revolution and Implication in Speech-Language Pathology
SO INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS
LA English
DT Article
DE Cochlear implant; future promising technologies; smart diagnostics;
   Online-based aural rehabilitation
ID GAINS; USERS; AGE
AB The Korea Research Foundation selected the miniaturization and development of home care devices as the future promising technologies in the biotechnology (BT) area along with the Fourth Industrial Revolution. Accordingly, it is believed that there will be innovative changes in the rehabilitation field, including the development of smart diagnostics and treatment devices. Moreover, rehabilitation equipped with individualization, precision, miniaturization, portability, and accessibility is expected to draw attention. It has been continuously reported in the past decade that hearingimpaired toddlers who became able to hear speech through cochlear implantation and hearing rehabilitation before the age of 3, which is a critical period of language development, show a language development pattern similar to that of healthy toddlers. As a result, the need for developing language rehabilitation programs customized for patients wearing artificial cochlea has emerged. In other words, since the improved hearing ability owing to cochlear implant does not guarantee to promote speech perception and language development, intensive rehabilitation and education are needed for patients to recognize the heard speech as a meaningful language for communication. Nevertheless, a literature search on domestic and foreign cases revealed that there are insufficient language rehabilitation programs for cochlear implant patients as well as customized programs for them in the clinical coalface. This study examined the trend and marketability of online-based aural rehabilitation programs for patients wearing artificial cochlea and described the implications for language rehabilitation. This study suggested the following implications for developing a customized aural rehabilitation program. It is needed to secure and develop contents that can implement "a hand-held hospital" by using medical devices and mobile devices owned by consumers that transcend time and space. Also, it is necessary to develop a cochlear implant hearing rehabilitation training program suitable for native Korean speakers.
C1 [Byeon, Haewon] Honam Univ, Dept Speech Language Pathol, Gwangju, South Korea.
RP Byeon, H (corresponding author), Honam Univ, Dept Speech Language Pathol, Gwangju, South Korea.
FU Ministry of Education of the Republic of Korea; National Research
   Foundation of KoreaNational Research Foundation of Korea
   [NRF-2018R1D1A1B07041091, NRF-2019S1A5A8034211]
FX This work was supported by the Ministry of Education of the Republic of
   Korea and the National Research Foundation of Korea
   (NRF-2018R1D1A1B07041091 and NRF-2019S1A5A8034211).
CR American Speech-Language-Hearing Association, 2004, ASHA S24, V24, DOI 10.1044/policy.TR2004-00041
   [Anonymous], 2016, KOR NAT HLTH NUTR EX
   *APP ANN, 2016, APP ANN MOB APP FOR
   Barcroft J, 2016, J SPEECH LANG HEAR R, V59, P862, DOI 10.1044/2016_JSLHR-H-15-0170
   Bexelius C, 2008, J MED INTERNET RES, V10, DOI 10.2196/jmir.1065
   Dunn CC, 2008, EAR HEARING, V29, P352, DOI 10.1097/AUD.0b013e318167b870
   Ertmer DJ, 2007, VOLTA REV, V107, P85
   Feng GY, 2018, P NATL ACAD SCI USA, V115, pE1022, DOI 10.1073/pnas.1717603115
   Geers AE, 2003, EAR HEARING, V24, p46S, DOI 10.1097/01.AUD.0000051689.57380.1B
   유재형, 2014, Audiology and Speech Research, V10, P158
   Korea Research Foundation, 2017, 12 FUT TECHN REP
   Laplante-Levesque A, 2006, INT J AUDIOL, V45, P697, DOI 10.1080/14992020600944408
   Lee SH, 2016, 2016 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C), P307, DOI 10.1109/IS3C.2016.87
   Lee Youngmee, 2017, Audiology and Speech Research, V13, P50
   Li JN, 2017, EAR HEARING, V38, P647, DOI 10.1097/AUD.0000000000000441
   Lim Janghyun, 2012, [Journal of the Korean Association for Persons with Autism, 자폐성장애연구], V12, P93
   Lin FR, 2011, NEUROPSYCHOLOGY, V25, P763, DOI 10.1037/a0024238
   Nicholas JG, 2007, J SPEECH LANG HEAR R, V50, P1048, DOI 10.1044/1092-4388(2007/073)
   Olze H, 2012, LARYNGOSCOPE, V122, P196, DOI 10.1002/lary.22356
   Romanik S., 2008, AUDITORY SKILLS PROG
   황건우, 2016, [AAC Research & Practice, 보완대체의사소통연구], V4, P101, DOI 10.14818/aac.2016.6.4.1.101
   TAE-GYU LEE., 2017, [Asia-pacific Journal of Multimedia Services Convergent with Art, Humanities, and Sociology, 예술인문사회 융합 멀티미디어 논문지], V7, P865, DOI 10.14257/ajmahs.2017.10.15
   TechNavio, 2014, GLOB BIOR MARK 2015
   Tye-Murray N, 2019, FDN AURAL REHABILITA
   Tye-Murray N, 2016, J SPEECH LANG HEAR R, V59, P871, DOI 10.1044/2016_JSLHR-H-15-0171
   Vogenberg FR, 2018, AM HEALTH DRUG BENEF, V11, P48
NR 26
TC 0
Z9 0
U1 0
U2 0
PU SCIENCE & INFORMATION SAI ORGANIZATION LTD
PI WEST YORKSHIRE
PA 19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND
SN 2158-107X
EI 2156-5570
J9 INT J ADV COMPUT SC
JI Int. J. Adv. Comput. Sci. Appl.
PD OCT
PY 2019
VL 10
IS 10
BP 25
EP 31
PG 7
WC Computer Science, Theory & Methods
SC Computer Science
GA JS0JF
UT WOS:000499999700005
DA 2021-02-24
ER

PT J
AU Marchegiani, L
   Fafoutis, X
AF Marchegiani, Letizia
   Fafoutis, Xenofon
TI Word Spotting in Background Music: a Behavioural Study
SO COGNITIVE COMPUTATION
LA English
DT Article
DE Speech perception; Auditory attention; Word spotting; Cocktail party;
   Auditory masking; Music perception
ID SPEECH-INTELLIGIBILITY; NOISE; TEMPO
AB Introduction Speech intelligibility in realistic environments is directly correlated with the ability of focusing attention on the sounds of interest while discarding the background noise and other competing stimuli. This work investigates task-driven auditory attention in noisy environments. Specifically, this study focuses on the ability to successfully execute a word spotting task while speech perception has to cope with the presence of music playing in the background. Methods The executed behavioural experiments consider different types of songs and explore how their distinct characteristics (such as dynamics or presence of distortion sound effects) affect the subjects' task performance and, thus, the distribution of attention. Results Our results show that the ability of correctly separating the target sound from the background noise has a major impact on the performance of the subjects. Indeed, songs not presenting any distortion effect result in being more distracting than the ones with distortion, whose frequency spectrum envelop differentiates more from the one of the narrative. Furthermore, subjects performed the worst with songs characterised by high dynamics playing in the background, due to the unexpected changes capturing the attention of the listener.
C1 [Marchegiani, Letizia] Aalborg Univ, Dept Elect Syst, Fredrik Bajers Vej 7, DK-9220 Aalborg O, Denmark.
   [Fafoutis, Xenofon] Tech Univ Denmark, Dept Appl Math & Comp Sci, DK-2800 Lyngby, Denmark.
RP Marchegiani, L (corresponding author), Aalborg Univ, Dept Elect Syst, Fredrik Bajers Vej 7, DK-9220 Aalborg O, Denmark.
EM lm@es.aau.dk; xefa@dtu.dk
RI Fafoutis, Xenofon/L-8762-2016
OI Fafoutis, Xenofon/0000-0002-9871-0013; Marchegiani,
   Letizia/0000-0001-6782-6657
CR Abel A, 2014, COGN COMPUT, V6, P200, DOI 10.1007/s12559-013-9231-2
   Burgess TW, 2012, ADVENTURES REDDY FOX, P1
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Cooke M, 2008, J ACOUST SOC AM, V123, P414, DOI 10.1121/1.2804952
   Doborjeh ZG, 2018, COGN COMPUT, V10, P35, DOI 10.1007/s12559-017-9517-x
   Ferreri L, 2016, MUSIC PERCEPT, V34, P167, DOI 10.1525/MP.2016.34.2.167
   Fujita K, 2014, COGN COMPUT, V6, P145, DOI 10.1007/s12559-013-9240-1
   Gallent N, 2008, NAT BUILT ENVIRON SE, P143
   Golob EJ, 2017, ANN C COGN SCI SOC, V39
   Grange JA, 2017, J ACOUST SOC AM, V141, P3971, DOI [10.1121/1.4989050, DOI 10.1121/1.4989050]
   Guediche S, 2014, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00126
   Heinke D, 2011, COGN COMPUT, V3, P185, DOI 10.1007/s12559-010-9076-x
   Hiyoshi-Taniguchi K, 2015, COGN COMPUT, V7, P11, DOI 10.1007/s12559-013-9225-0
   Hussain A, 2017, P 1 INT WORKSH CHALL
   Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007
   Kallinen K, 2002, COMPUT HUM BEHAV, V18, P537, DOI 10.1016/S0747-5632(02)00005-5
   Kim Y. E., 2010, P INT SOC MUS INF RE, P255
   Lagrange M, 2010, INT CONF ACOUST SPEE, P405, DOI 10.1109/ICASSP.2010.5495783
   Lyon R. F., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P1282
   Maidhof C, 2011, J COGNITIVE NEUROSCI, V23, P2252, DOI 10.1162/jocn.2010.21542
   Marchegiani L., 2011, Proceedings of the 2011 Tenth International Conference on Machine Learning and Applications (ICMLA 2011), P183, DOI 10.1109/ICMLA.2011.143
   Marchegiani L, 2018, ENVIRONMENTS, V5, DOI 10.3390/environments5050056
   Marchegiani L, 2015, J ACOUST SOC AM, V138, P2206, DOI 10.1121/1.4930955
   Marchegiani L, 2013, LECT NOTES COMPUT SC, V8212, P15, DOI 10.1007/978-3-319-02714-2_2
   MAYFIELD C, 1989, PSYCHOL REP, V65, P1283, DOI 10.2466/pr0.1989.65.3f.1283
   Mitterer H, 2017, ATTEN PERCEPT PSYCHO, V79, P344, DOI 10.3758/s13414-016-1195-3
   North AC, 1999, SCAND J PSYCHOL, V40, P285, DOI 10.1111/1467-9450.404128
   PARENTE JA, 1976, PERCEPT MOTOR SKILL, V43, P337, DOI 10.2466/pms.1976.43.1.337
   Rabiner L. R., 1993, FUNDAMENTALS SPEECH
   Riche N., 2012, P ACCV NOV, P586
   Slater J, 2016, COGN PROCESS, V17, P79, DOI 10.1007/s10339-015-0740-7
   Stone MA, 2011, J ACOUST SOC AM, V130, P2874, DOI 10.1121/1.3641371
   Tu ZZ, 2016, COGN COMPUT, V8, P629, DOI 10.1007/s12559-016-9387-7
   Vazquez-Alvarez Y, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2173
   Wang DL, 2009, J ACOUST SOC AM, V125, P2336, DOI 10.1121/1.3083233
   Wang DL, 2005, SPEECH SEPARATION BY HUMANS AND MACHINES, P181, DOI 10.1007/0-387-22794-6_12
   WOLFE DE, 1983, J RES MUSIC EDUC, V31, P191, DOI 10.2307/3345172
NR 37
TC 2
Z9 2
U1 2
U2 4
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1866-9956
EI 1866-9964
J9 COGN COMPUT
JI Cogn. Comput.
PD OCT
PY 2019
VL 11
IS 5
BP 711
EP 718
DI 10.1007/s12559-019-09649-9
PG 8
WC Computer Science, Artificial Intelligence; Neurosciences
SC Computer Science; Neurosciences & Neurology
GA JL0SG
UT WOS:000495244800009
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Calcus, A
   Tuomainen, O
   Campos, A
   Rosen, S
   Halliday, LF
AF Calcus, Axelle
   Tuomainen, Outi
   Campos, Ana
   Rosen, Stuart
   Halliday, Lorna F.
TI Functional brain alterations following mild-to-moderate sensorineural
   hearing loss in children
SO ELIFE
LA English
DT Article
ID EVENT-RELATED POTENTIALS; MISMATCH NEGATIVITY MMN; SOUNDS VERTICAL-BAR;
   PASS NOISE MASKING; COCHLEAR IMPLANTATION; AUDITORY DEVELOPMENT;
   PROFOUND DEAFNESS; SPEECH-PERCEPTION; MATURATION; LANGUAGE
AB Auditory deprivation in the form of deafness during development leads to lasting changes in central auditory system function. However, less is known about the effects of mild-to-moderate sensorineural hearing loss (MMHL) during development. Here, we used a longitudinal design to examine late auditory evoked responses and mismatch responses to nonspeech and speech sounds for children with MMHL. At Time 1, younger children with MMHL (8-12 years; n = 23) showed age-appropriate mismatch negativities (MMNs) to sounds, but older children (12-16 years; n = 23) did not. Six years later, we re-tested a subset of the younger (now older) children with MMHL (n = 13). Children who had shown significant MMNs at Time 1 showed MMNs that were reduced and, for nonspeech, absent at Time 2. Our findings demonstrate that even a mild-to-moderate hearing loss during early-to-mid childhood can lead to changes in the neural processing of sounds in late childhood/adolescence.
C1 [Calcus, Axelle] PSL Univ, Lab Syst Perceptifs, Dept Etud Cognit, Ecole Normale Super,CNRS, Paris, France.
   [Calcus, Axelle; Tuomainen, Outi; Campos, Ana; Rosen, Stuart; Halliday, Lorna F.] UCL, Dept Speech Hearing & Phonet Sci, London, England.
   [Halliday, Lorna F.] Univ Cambridge, MRC Cognit & Brain Sci Unit, Cambridge, England.
RP Calcus, A (corresponding author), PSL Univ, Lab Syst Perceptifs, Dept Etud Cognit, Ecole Normale Super,CNRS, Paris, France.; Calcus, A (corresponding author), UCL, Dept Speech Hearing & Phonet Sci, London, England.
EM axelle.calcus@ens.fr
RI Tuomainen, Outi/H-8675-2019; Calcus, Axelle/AAS-8137-2020
OI Tuomainen, Outi/0000-0002-8654-2446; Calcus, Axelle/0000-0002-1240-1122;
   Halliday, Lorna/0000-0003-1883-7741; Rosen, Stuart/0000-0002-9376-2148
FU H2020 Marie Sklodowska-Curie Actions [FP7-607139]; ESRCUK Research &
   Innovation (UKRI)Economic & Social Research Council (ESRC)
   [RES-061-25-0440]
FX H2020 Marie Sklodowska-Curie Actions FP7-607139 Lorna F Halliday; ESRC
   RES-061-25-0440 Lorna F Halliday
CR Alain C, 2007, J AM ACAD AUDIOL, V18, P573, DOI 10.3766/jaaa.18.7.5
   ALHO K, 1995, EAR HEARING, V16, P38, DOI 10.1097/00003446-199502000-00004
   [Anonymous], 2008, GOLDWAVE DIGITAL AUD
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Berger C, 2017, J COMP NEUROL, V525, P3110, DOI 10.1002/cne.24267
   Billings CJ, 2007, AUDIOL NEURO-OTOL, V12, P234, DOI 10.1159/000101331
   Bishop DVM, 2007, DEVELOPMENTAL SCI, V10, P565, DOI 10.1111/j.1467-7687.2007.00619.x
   Bishop DVM, 2011, DEVELOPMENTAL SCI, V14, P402, DOI 10.1111/j.1467-7687.2010.00990.x
   Bishop DVM, 2010, J NEUROSCI, V30, P15578, DOI 10.1523/JNEUROSCI.2217-10.2010
   Bishop DVM, 2019, PSYCHOPHYSIOLOGY, V133, P697
   Boersma P., 2005, PRAAT DOING PHONETIC
   British Society of Audiology, 2011, REC PROC PUR TON AIR
   Butler BE, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00092
   Calcus A., 2019, MMHL
   Carew P, 2018, CHILD CARE HLTH DEV, V44, P71, DOI 10.1111/cch.12477
   Chao TK, 2002, HEARING RES, V174, P196, DOI 10.1016/S0378-5955(02)00694-9
   Cheour M, 2001, AUDIOL NEURO-OTOL, V6, P2, DOI 10.1159/000046804
   Dalebout S D, 2001, J Am Acad Audiol, V12, P245
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Eggermont JJ, 2002, AUDIOL NEURO-OTOL, V7, P71, DOI 10.1159/000057656
   Garrido MI, 2009, CLIN NEUROPHYSIOL, V120, P453, DOI 10.1016/j.clinph.2008.11.029
   Gomot M, 2000, NEUROREPORT, V11, P3109, DOI 10.1097/00001756-200009280-00014
   Gravel JS, 2006, EAR HEARING, V27, P353, DOI 10.1097/01.aud.0000224727.45342.e9
   Halliday LF, 2019, PSYARXIV
   Halliday LF, 2017, J SPEECH LANG HEAR R, V60, P1551, DOI 10.1044/2016_JSLHR-L-16-0297
   Halliday LF, 2017, COGNITION, V166, P139, DOI 10.1016/j.cognition.2017.04.014
   Isaacson JS, 2011, NEURON, V72, P231, DOI 10.1016/j.neuron.2011.09.027
   Jaaskelainen IP, 2004, P NATL ACAD SCI USA, V101, P6809, DOI 10.1073/pnas.0303760101
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Koravand A, 2013, CLIN NEUROPHYSIOL, V124, P1439, DOI 10.1016/j.clinph.2013.01.016
   Korpilahti P, 2001, BRAIN LANG, V76, P332, DOI 10.1006/brln.2000.2426
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   KRAUS N, 1993, ELECTROEN CLIN NEURO, V88, P123, DOI 10.1016/0168-5597(93)90063-U
   Liberman MC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142341
   Martin BA, 1999, J SPEECH LANG HEAR R, V42, P271, DOI 10.1044/jslhr.4202.271
   Martin BA, 1997, J ACOUST SOC AM, V101, P1585, DOI 10.1121/1.418146
   Martinez Amy S., 2013, Seminars in Hearing, V34, P278, DOI 10.1055/s-0033-1356640
   McGee T, 1997, EVOKED POTENTIAL, V104, P359, DOI 10.1016/S0168-5597(97)00024-5
   Mowery TM, 2017, CELL REP, V19, P2462, DOI 10.1016/j.celrep.2017.05.083
   Mowery TM, 2015, CEREB CORTEX, V25, P2083, DOI 10.1093/cercor/bhu013
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   NAATANEN R, 1990, BEHAV BRAIN SCI, V13, P201, DOI 10.1017/S0140525X00078407
   Naatanen R, 2017, HEARING RES, V353, P57, DOI 10.1016/j.heares.2017.07.007
   NADOL JB, 1989, ANN OTO RHINOL LARYN, V98, P411, DOI 10.1177/000348948909800602
   Nakagawa S, 2013, METHODS ECOL EVOL, V4, P133, DOI 10.1111/j.2041-210x.2012.00261.x
   Nash-Kille A, 2014, CLIN NEUROPHYSIOL, V125, P1459, DOI 10.1016/j.clinph.2013.11.017
   Neville HJ, 1998, P NATL ACAD SCI USA, V95, P922, DOI 10.1073/pnas.95.3.922
   Nunez P. L, 2006, ELECT FIELDS BRAIN N, DOI [10.1093/acprof:oso/9780195050387.001.0001, DOI 10.1093/ACPROF:OSO/9780195050387.001.0001]
   Oates P, 1997, J ACOUST SOC AM, V102, P3597, DOI 10.1121/1.420148
   Oates PA, 2002, EAR HEARING, V23, P399, DOI 10.1097/00003446-200210000-00002
   Papsin BC, 2007, NEW ENGL J MED, V357, P2380, DOI 10.1056/NEJMct0706268
   Patel Salil H, 2005, Int J Med Sci, V2, P147
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   Picton TW, 2000, AUDIOL NEURO-OTOL, V5, P111, DOI 10.1159/000013875
   Ponton CW, 2000, CLIN NEUROPHYSIOL, V111, P220, DOI 10.1016/S1388-2457(99)00236-9
   Ponton CW, 2001, AUDIOL NEURO-OTOL, V6, P363, DOI 10.1159/000046846
   Ponton CW, 1996, NEUROREPORT, V8, P61, DOI 10.1097/00001756-199612200-00013
   Ponton CW, 1996, EAR HEARING, V17, P430, DOI 10.1097/00003446-199610000-00009
   Ponton CW, 1999, SCAND AUDIOL, V28, P13
   Ponton CW, 2000, AUDIOL NEURO-OTOL, V5, P167, DOI 10.1159/000013878
   Rance G, 2002, EAR HEARING, V23, P239, DOI 10.1097/00003446-200206000-00008
   Rinne T, 2000, NEUROIMAGE, V12, P14, DOI 10.1006/nimg.2000.0591
   Rosen MJ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0041514
   Sanes DH, 2016, PERSPECT ASHA SPECIA, V1, p4 , DOI DOI 10.1044/PERSP1.SIG6.4
   Scherer MJ, 1996, DISABIL REHABIL, V18, P439, DOI 10.3109/09638289609165907
   SELDON HL, 1991, BRAIN RES, V551, P185, DOI 10.1016/0006-8993(91)90932-L
   Sharma A, 2005, HEARING RES, V203, P134, DOI 10.1016/j.heares.2004.12.010
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   Shepherd RK, 2001, AUDIOL NEURO-OTOL, V6, P305, DOI 10.1159/000046843
   Singh S, 2004, EAR HEARING, V25, P598, DOI 10.1097/00003446-200412000-00008
   Sussman E, 2008, HEARING RES, V236, P61, DOI 10.1016/j.heares.2007.12.001
   Takesian AE, 2012, J NEUROPHYSIOL, V107, P937, DOI 10.1152/jn.00515.2011
   Walker EA, 2013, LANG SPEECH HEAR SER, V44, P73, DOI 10.1044/0161-1461(2012/12-0005)
   Waltzman SB, 2005, PEDIATRICS, V116, pE487, DOI 10.1542/peds.2005-0282
   Wechsler D, 1999, WASI WECHSLER ABBREV
   Whiting KA, 1998, EAR HEARING, V19, P218, DOI 10.1097/00003446-199806000-00005
   Zhang Y, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00392
NR 77
TC 3
Z9 3
U1 2
U2 4
PU ELIFE SCIENCES PUBLICATIONS LTD
PI CAMBRIDGE
PA SHERATON HOUSE, CASTLE PARK, CAMBRIDGE, CB3 0AX, ENGLAND
SN 2050-084X
J9 ELIFE
JI eLife
PD OCT 1
PY 2019
VL 8
AR e46965
DI 10.7554/eLife.46965
PG 37
WC Biology
SC Life Sciences & Biomedicine - Other Topics
GA JL2RD
UT WOS:000495378600001
PM 31570117
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Ferreira, GC
   Torres, EMO
   Garcia, MV
   Santos, SN
   Costa, MJ
AF Ferreira, Geise Correa
   Ortiz Torres, Enma Mariangel
   Garcia, Michele Vargas
   Santos, Sineia Neujahr
   Costa, Maristela Julio
TI Bilingualism and speech recognition in silence and noise in adults
SO CODAS
LA English
DT Article
DE Bilingualism; Adult; Hearing Tests; Speech Perception; Speech
   Discrimination Tests
ID PERCEPTION; PERFORMANCE; ADVANTAGE; LISTENERS; HEARING; ENGLISH; AGE
AB Purpose: To compare the ability to recognize sentences in silence and in noise in monolingual normal-hearing Brazilian Portuguese speakers, and bilingual speakers of Brazilian Portuguese and German, and bilingual speakers of Brazilian Portuguese and Italian, as well as to analyze the influence of age of second language acquisition on the performance of bilinguals. Methods: 87 normal-hearing individuals aged between 18 and 55 years participated of this research. They were categorized into: Control Group. composed by 30 monolingual Brazilian Portuguese speakers: German Research Group, 31 simultaneous bilingual native speakers of Portuguese and speakers of German as a second language and; Italian Research Group. consisting of 26 successive bilinguals, native speakers of Portuguese and speakers of Italian as a second language. The Sentence List Test in Brazilian Portuguese was used to measure their Sentence Recognition Thresholds in Silence and Noise. Results: In silence. there were no statistically significant differences in performance when comparing the bilingual to the monolingual individuals, and when comparing the bilingual speakers among themselves. On the other hand, in noise, there was a significant difference between the bilingual groups and the monolingual one. However, them were no significant differences between the bilingual groups when their performance was compared. Conclusion: Bilingualism positively influenced the development of language and listening skills, which led the bilinguals to outperform in speech recognition in the presence of noise. Also, the period of a second language acquisition did not influence bilingual performance.
C1 [Ferreira, Geise Correa; Ortiz Torres, Enma Mariangel; Garcia, Michele Vargas; Santos, Sineia Neujahr; Costa, Maristela Julio] Univ Fed Santa Maria, Posgrad Disturbios Comunicacao Humana, Santa Maria, RS, Brazil.
   [Ferreira, Geise Correa; Ortiz Torres, Enma Mariangel; Garcia, Michele Vargas; Santos, Sineia Neujahr; Costa, Maristela Julio] Univ Fed Santa Maria, Santa Maria, RS, Brazil.
RP Ferreira, GC (corresponding author), Rua Floriano Peixoto 1750, BR-97015372 Santa Maria, RS, Brazil.
EM geisecorrea@gmail.com
RI , Maristela/J-9857-2015
OI , Maristela/0000-0002-8722-7077
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - CAPESCAPES
   [42002010017P9]
FX Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - CAPES;
   Process no. 42002010017P9.
CR Abello-Contesse C, 2009, ELT J, V63, P170, DOI 10.1093/elt/ccn072
   Blumenfeld HK, 2016, LINGUIST APPROACH BI, V6, P119, DOI 10.1075/lab.14030.blu
   Blumenfeld HK, 2011, COGNITION, V118, P245, DOI 10.1016/j.cognition.2010.10.012
   Christoffersen KOD, 2014, ARIZONA WORKING PAPE, V21, P20
   Costa MJ, 2000, PRO-FONO REV ATUAL C, V12, P9
   Costa MJ, 1998, LISTAS SENTENCAS POR
   Filippi R, 2012, BILING-LANG COGN, V15, P858, DOI 10.1017/S1366728911000708
   Freeman MR, 2017, J COGN PSYCHOL, V29, P783, DOI 10.1080/20445911.2017.1321553
   Galhardo Leonor, 2009, ARBS Annual Review of Biomedical Sciences, V11, P1
   Gresele AD, 2013, CODAS, V25, P506, DOI 10.1590/S2317-17822014000100003
   Gullifer JW, 2018, NEUROPSYCHOLOGIA, V117, P123, DOI 10.1016/j.neuropsychologia.2018.04.037
   Kousaie S, 2017, BRAIN COGNITION, V117, P49, DOI 10.1016/j.bandc.2017.06.003
   Krizman J, 2012, P NATL ACAD SCI USA, V109, P7877, DOI 10.1073/pnas.1201575109
   Kroll JF, 2013, J COGN PSYCHOL, V25, P497, DOI 10.1080/20445911.2013.799170
   Lewis M. P., 2018, ETHNOLOGUE LANGUAGES
   Mackey William F, 2000, CANADIAN J LINGUISTI, P26, DOI [DOI 10.1017/S0008413100019393, 10.1017/S0008413100019393]
   Onoda Raquel Mari, 2006, Braz J Otorhinolaryngol, V72, P737
   PEAL E, 1962, PSYCHOL MONOGR, V76, P1, DOI 10.1037/h0093840
   Raftari S, 2012, IRANIAN EFL J, V8, P68
   Rogers CL, 2006, APPL PSYCHOLINGUIST, V27, P465, DOI 10.1017/S014271640606036X
   Shi LF, 2010, J SPEECH LANG HEAR R, V53, P821, DOI 10.1044/1092-4388(2010/09-0081)
   Soncini Fabiana, 2006, Pró-Fono R. Atual. Cient., V18, P161, DOI 10.1590/S0104-56872006000200005
   Soveri A, 2011, BILING-LANG COGN, V14, P371, DOI 10.1017/S1366728910000118
   Stuart A, 2010, J AM ACAD AUDIOL, V21, P239, DOI 10.3766/jaaa.21.4.3
   Tabri D, 2011, INT J LANG COMM DIS, V46, P411, DOI 10.3109/13682822.2010.519372
   von Hapsburg D, 2002, J SPEECH LANG HEAR R, V45, P202, DOI 10.1044/1092-4388(2002/015)
   von Hapsburg Deborah, 2004, J Am Acad Audiol, V15, P88, DOI 10.3766/jaaa.15.1.9
   Weiss D, 2008, J AM ACAD AUDIOL, V19, P5, DOI 10.3766/jaaa.19.1.2
   Wong LLN, 2008, ACTA OTO-LARYNGOL, V128, P654, DOI 10.1080/00016480701642189
   Yang S, 2016, J EXP CHILD PSYCHOL, V146, P121, DOI 10.1016/j.jecp.2016.01.011
NR 30
TC 1
Z9 1
U1 0
U2 0
PU SOC BRASILEIRA FONOAUDIOLOGIA
PI SAO PAULO SP
PA AL JAU, 684 7 ANDAR, SAO PAULO SP, 01420-001, BRAZIL
SN 2317-1782
J9 CODAS
JI CoDAS
PD OCT
PY 2019
VL 31
IS 5
AR e20180217
DI 10.1590/2317-1782/20192018217
PG 6
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA JJ6QT
UT WOS:000494280600008
PM 31644717
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU O'Sullivan, AE
   Lim, CY
   Lalor, EC
AF O'Sullivan, Aisling E.
   Lim, Chantelle Y.
   Lalor, Edmund C.
TI Look at me when I'm talking to you: Selective attention at a
   multisensory cocktail party can be decoded using stimulus reconstruction
   and alpha power modulations
SO EUROPEAN JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE audiovisual speech; electroencephalography; envelope reconstruction;
   visual attention; visual speech
ID AUDITORY ATTENTION; SPATIOTEMPORAL DYNAMICS; SPEECH-PERCEPTION; ATTENDED
   SPEECH; TRACKING; INTEGRATION; INCREASES; REPRESENTATIONS; OSCILLATIONS;
   SUPPRESSION
AB Recent work using electroencephalography has applied stimulus reconstruction techniques to identify the attended speaker in a cocktail party environment. The success of these approaches has been primarily based on the ability to detect cortical tracking of the acoustic envelope at the scalp level. However, most studies have ignored the effects of visual input, which is almost always present in naturalistic scenarios. In this study, we investigated the effects of visual input on envelope-based cocktail party decoding in two multisensory cocktail party situations: (a) Congruent AV-facing the attended speaker while ignoring another speaker represented by the audio-only stream and (b) Incongruent AV (eavesdropping)-attending the audio-only speaker while looking at the unattended speaker. We trained and tested decoders for each condition separately and found that we can successfully decode attention to congruent audiovisual speech and can also decode attention when listeners were eavesdropping, i.e., looking at the face of the unattended talker. In addition to this, we found alpha power to be a reliable measure of attention to the visual speech. Using parieto-occipital alpha power, we found that we can distinguish whether subjects are attending or ignoring the speaker's face. Considering the practical applications of these methods, we demonstrate that with only six near-ear electrodes we can successfully determine the attended speech. This work extends the current framework for decoding attention to speech to more naturalistic scenarios, and in doing so provides additional neural measures which may be incorporated to improve decoding accuracy.
C1 [O'Sullivan, Aisling E.; Lalor, Edmund C.] Trinity Coll Dublin, Trinity Ctr Bioengn, Sch Engn, Dublin 2, Ireland.
   [O'Sullivan, Aisling E.; Lalor, Edmund C.] Trinity Coll Dublin, Trinity Coll Inst Neurosci, Dublin 2, Ireland.
   [Lim, Chantelle Y.; Lalor, Edmund C.] Univ Rochester, Dept Biomed Engn, Rochester, NY 14611 USA.
   [Lalor, Edmund C.] Univ Rochester, Del Monte Inst Neurosci, Dept Neurosci, Rochester, NY 14611 USA.
RP O'Sullivan, AE (corresponding author), Univ Rochester, 500 Joseph C Wilson Blvd,Box 270168, Rochester, NY 14611 USA.
EM aosulli4@ur.rochester.edu
OI O'Sullivan, Aisling E./0000-0002-4725-8864; Lalor,
   Edmund/0000-0002-2498-6631
CR Ahveninen J, 2013, J COGNITIVE NEUROSCI, V25, P1926, DOI 10.1162/jocn_a_00452
   Akram S, 2016, NEUROIMAGE, V124, P906, DOI 10.1016/j.neuroimage.2015.09.048
   Algazi VR, 2001, CIPIC HRTF DATABASE, P99, DOI [10.1155/S1463924601000141, DOI 10.1155/S1463924601000141]
   Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Bednar A, 2018, NEUROIMAGE, V181, P683, DOI 10.1016/j.neuroimage.2018.07.054
   Bernstein LE, 2008, NEUROIMAGE, V39, P423, DOI 10.1016/j.neuroimage.2007.08.035
   Besle J, 2004, EUR J NEUROSCI, V20, P2225, DOI 10.1111/j.1460-9568.2004.03670.x
   Bleichner MG, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00163
   Bleichner MG, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/6/066004
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Combrisson E, 2015, J NEUROSCI METH, V250, P126, DOI 10.1016/j.jneumeth.2015.01.010
   Crosse MJ, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00604
   Crosse MJ, 2016, J NEUROSCI, V36, P9888, DOI 10.1523/JNEUROSCI.1396-16.2016
   Crosse MJ, 2015, J NEUROSCI, V35, P14195, DOI 10.1523/JNEUROSCI.1829-15.2015
   Das N, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/5/056014
   Debener S, 2015, SCI REP-UK, V5, DOI 10.1038/srep16743
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Denk F, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518788219
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Ding N, 2012, J NEUROPHYSIOL, V107, P78, DOI 10.1152/jn.00297.2011
   Driver J, 1996, NATURE, V381, P66, DOI 10.1038/381066a0
   Feng WF, 2017, NEUROIMAGE, V150, P318, DOI 10.1016/j.neuroimage.2017.02.033
   Fiedler L, 2016, IEEE ENG MED BIO, P5697, DOI 10.1109/EMBC.2016.7592020
   Foxe JJ, 1998, NEUROREPORT, V9, P3929, DOI 10.1097/00001756-199812010-00030
   Foxe JJ, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00154
   Frey JN, 2014, J NEUROSCI, V34, P6634, DOI 10.1523/JNEUROSCI.4813-13.2014
   Fu KMG, 2001, COGNITIVE BRAIN RES, V12, P145, DOI 10.1016/S0926-6410(01)00034-9
   Fuglsang SA, 2017, NEUROIMAGE, V156, P435, DOI 10.1016/j.neuroimage.2017.04.026
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Gurler D, 2015, ATTEN PERCEPT PSYCHO, V77, P1333, DOI 10.3758/s13414-014-0821-1
   Haghighi M, 2017, IEEE T NEUR SYS REH, V25, P1970, DOI 10.1109/TNSRE.2017.2712419
   Haufe S, 2014, NEUROIMAGE, V87, P96, DOI 10.1016/j.neuroimage.2013.10.067
   Hauswald A, 2018, CURR BIOL, V28, P1453, DOI 10.1016/j.cub.2018.03.044
   Kelly SP, 2006, J NEUROPHYSIOL, V95, P3844, DOI 10.1152/jn.01234.2005
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Klimesch W, 2012, TRENDS COGN SCI, V16, P606, DOI 10.1016/j.tics.2012.10.007
   Mazaheri A, 2014, NEUROIMAGE, V87, P356, DOI 10.1016/j.neuroimage.2013.10.052
   McGettigan C, 2012, NEUROPSYCHOLOGIA, V50, P762, DOI 10.1016/j.neuropsychologia.2012.01.010
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Miller LM, 2005, J NEUROSCI, V25, P5884, DOI 10.1523/JNEUROSCI.0896-05.2005
   Miran S, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00262
   Mirkovic B, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00349
   Mirkovic B, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/4/046007
   Fernandez LM, 2015, NEUROIMAGE, V119, P272, DOI 10.1016/j.neuroimage.2015.06.052
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Narayanan AM, 2018, IEEE ENG MED BIO, P77, DOI 10.1109/EMBC.2018.8512212
   Nath AR, 2011, J NEUROSCI, V31, P1704, DOI 10.1523/JNEUROSCI.4853-10.2011
   O'Sullivan AE, 2017, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00679
   O'Sullivan J, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa7ab4
   O'Sullivan JA, 2015, CEREB CORTEX, V25, P1697, DOI 10.1093/cercor/bht355
   Ozker M, 2018, ELIFE, V7, DOI 10.7554/eLife.30387
   Peelle JE, 2015, CORTEX, V68, P169, DOI 10.1016/j.cortex.2015.03.006
   PFURTSCHELLER G, 1991, ELECTROEN CLIN NEURO, P58
   Puvvada KC, 2017, J NEUROSCI, V37, P9189, DOI 10.1523/JNEUROSCI.0938-17.2017
   Reisberg D, 1987, HEARING EYE PSYCHOL, P97
   Romei V, 2008, CEREB CORTEX, V18, P2010, DOI 10.1093/cercor/bhm229
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Schepers IM, 2015, CEREB CORTEX, V25, P4103, DOI 10.1093/cercor/bhu127
   Schroeder CE, 2008, TRENDS COGN SCI, V12, P106, DOI 10.1016/j.tics.2008.01.002
   Schwartz JL, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003743
   Sekiyama K, 2003, NEUROSCI RES, V47, P277, DOI 10.1016/S0168-0102(03)00214-1
   Shatzer H, 2018, EUR J NEUROSCI, V48, P2836, DOI 10.1111/ejn.13843
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1992, PHILOS T ROY SOC B, V335, P71, DOI 10.1098/rstb.1992.0009
   Talsma D, 2005, J COGNITIVE NEUROSCI, V17, P1098, DOI 10.1162/0898929054475172
   Talsma D, 2010, TRENDS COGN SCI, V14, P400, DOI 10.1016/j.tics.2010.06.008
   Van der Burg E, 2008, J EXP PSYCHOL HUMAN, V34, P1053, DOI 10.1037/0096-1523.34.5.1053
   Van der Burg E, 2009, NEUROSCI LETT, V450, P60, DOI 10.1016/j.neulet.2008.11.002
   Van Eyndhoven S, 2017, IEEE T BIO-MED ENG, V64, P1045, DOI 10.1109/TBME.2016.2587382
   Wostmann M, 2016, P NATL ACAD SCI USA, V113, P3873, DOI 10.1073/pnas.1523357113
   Worden MS, 2000, J NEUROSCI, V20
   Wright TM, 2003, CEREB CORTEX, V13, P1034, DOI 10.1093/cercor/13.10.1034
   Zhu LL, 2017, J NEUROSCI, V37, P2697, DOI 10.1523/JNEUROSCI.2914-16.2017
NR 76
TC 2
Z9 2
U1 2
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0953-816X
EI 1460-9568
J9 EUR J NEUROSCI
JI Eur. J. Neurosci.
PD OCT
PY 2019
VL 50
IS 8
BP 3282
EP 3295
DI 10.1111/ejn.14425
PG 14
WC Neurosciences
SC Neurosciences & Neurology
GA JH9VN
UT WOS:000493117100006
PM 31013361
DA 2021-02-24
ER

PT J
AU Park, Y
   Perkell, JS
   Matthies, ML
   Stepp, CE
AF Park, Yeonggwang
   Perkell, Joseph S.
   Matthies, Melanie L.
   Stepp, Cara E.
TI Categorization in the Perception of Breathy Voice Quality and Its
   Relation to Voice Production in Healthy Speakers
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID GLOTTAL CHARACTERISTICS; CATEGORICAL PERCEPTION; SPEECH-PERCEPTION;
   DISCRIMINATION; FEMALE; ACQUISITION; FRAMEWORK; RESPONSES; VALIDITY;
   FEEDBACK
AB Purpose: Previous studies of speech articulation have shown that individuals who can perceive smaller differences between similar-sounding phonemes showed larger contrasts in their productions of those phonemes. Here, a similar relationship was examined between the perception and production of breathy voice quality.
   Method: Twenty females with healthy voices were recruited to participate in both a voice production and a perception experiment. Each participant produced repetitions of a sustained vowel, and acoustic correlates of breathiness were calculated. Identification and discrimination tasks were performed with a series of synthetic stimuli along a breathiness continuum. Categorical boundary location and boundary width were obtained from the identification task as a measurement of perception of breathiness. Spearman's correlation analysis was performed to estimate associations between values of boundary location and width and the acoustic correlates of breathiness from the participants' voices.
   Results: Significant correlations between boundary width (r = -.53 to -.6) and some acoustic correlates were found, but no significant relationships were observed between boundary location and the acoustic correlates.
   Conclusions: Speakers with small boundary widths, which suggest higher perceptual precision in differentiating breathiness, had typical voices that were less breathy, as estimated with acoustic measures, compared to speakers with large boundary widths. Our findings may support a link between perception and production of breathy voice quality.
C1 [Park, Yeonggwang; Perkell, Joseph S.; Matthies, Melanie L.; Stepp, Cara E.] Boston Univ, Dept Speech Language & Hearing Sci, Boston, MA 02215 USA.
   [Perkell, Joseph S.] MIT, Elect Res Lab, Cambridge, MA 02139 USA.
   [Stepp, Cara E.] Boston Univ, Dept Biomed Engn, Boston, MA 02215 USA.
   [Stepp, Cara E.] Boston Univ, Dept Otolaryngol Head & Neck Surg, Sch Med, Boston, MA 02215 USA.
RP Park, Y (corresponding author), Boston Univ, Dept Speech Language & Hearing Sci, Boston, MA 02215 USA.
EM yppark@bu.edu
RI Stepp, Cara/AAQ-6425-2020
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [DC015570, DC015446]; NATIONAL INSTITUTE
   ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [P50DC015446, P50DC015446, P50DC015446] Funding Source: NIH RePORTER
FX This work was supported by Grants DC015570 (awarded to Cara E. Stepp)
   and DC015446 (awarded to Robert E. Hillman) from the National Institute
   on Deafness and Other Communication Disorders.
CR American Speech Language Hearing Association, 2005, GUID MAN PUR TON THR
   American Speech-Language-Hearing Association, 2002, CONS AUD PERC EV VOI
   Arai T, 2006, ACOUST SCI TECHNOL, V27, P298, DOI 10.1250/ast.27.298
   Belafsky PC, 2002, J VOICE, V16, P274, DOI 10.1016/S0892-1997(02)00097-8
   BEST CT, 1992, J PHONETICS, V20, P305, DOI 10.1016/S0095-4470(19)30637-0
   Burnett TA, 1998, J ACOUST SOC AM, V103, P3153, DOI 10.1121/1.423073
   Byun TM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0172022
   deGelder B, 1997, COGNITION EMOTION, V11, P1, DOI 10.1080/026999397380005
   Deliyski DD, 2005, J VOICE, V19, P176, DOI 10.1016/j.jvoice.2004.07.012
   Donath TM, 2002, J ACOUST SOC AM, V111, P357, DOI 10.1121/1.1424870
   Eddins DA, 2016, J VOICE, V30, DOI 10.1016/j.jvoice.2015.11.016
   Fant G., 1985, STL QPSR, V4, P1, DOI DOI 10.1016/0167-6393(89)90001-0
   FOX RA, 1982, PHONETICA, V39, P1, DOI 10.1159/000261647
   Franken MK, 2017, J ACOUST SOC AM, V142, P2007, DOI 10.1121/1.5006899
   Garrett R., 2013, THESIS
   Gerrits E, 2004, PERCEPT PSYCHOPHYS, V66, P363, DOI 10.3758/BF03194885
   Ghosh SS, 2010, J ACOUST SOC AM, V128, P3079, DOI 10.1121/1.3493430
   Gobl C, 2003, SPEECH COMMUN, V40, P189, DOI 10.1016/S0167-6393(02)00082-1
   Goldstone RL, 2010, WIRES COGN SCI, V1, P69, DOI 10.1002/wcs.26
   Goy H, 2013, J VOICE, V27, P545, DOI 10.1016/j.jvoice.2013.03.002
   Guenther F. H., 2002, Acoustical Science and Technology, V23, P213, DOI 10.1250/ast.23.213
   Guenther FH, 1999, J ACOUST SOC AM, V106, P2900, DOI 10.1121/1.428112
   Guenther FH., 2016, NEURAL CONTROL SPEEC
   Halle PA, 1999, J PHONETICS, V27, P281, DOI 10.1006/jpho.1999.0097
   Hanson HM, 1997, J ACOUST SOC AM, V101, P466, DOI 10.1121/1.417991
   Hanson HM, 1999, J ACOUST SOC AM, V106, P1064, DOI 10.1121/1.427116
   HILLENBRAND J, 1994, J SPEECH HEAR RES, V37, P769, DOI 10.1044/jshr.3704.769
   HILLMAN RE, 1989, J SPEECH HEAR RES, V32, P373, DOI 10.1044/jshr.3202.373
   HOFFMAN PR, 1985, J SPEECH HEAR DISORD, V50, P46, DOI 10.1044/jshd.5001.46
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213
   Ishikawa K, 2017, J SPEECH LANG HEAR R, V60, P1919, DOI 10.1044/2017_JSLHR-S-16-0012
   Jacobson BH, 1997, AM J SPEECH-LANG PAT, V6, P66, DOI [DOI 10.1044/1058-0360.0603.66, 10.1044/1058-0360.0603.66]
   Jones JA, 2000, J ACOUST SOC AM, V108, P1246, DOI 10.1121/1.1288414
   Kempster GB, 2009, AM J SPEECH-LANG PAT, V18, P124, DOI 10.1044/1058-0360(2008/08-0017)
   KLATT DH, 1990, J ACOUST SOC AM, V87, P820, DOI 10.1121/1.398894
   KLICH RJ, 1982, J SPEECH HEAR RES, V25, P574, DOI 10.1044/jshr.2504.574
   KREIMAN J, 1993, J SPEECH HEAR RES, V36, P21, DOI 10.1044/jshr.3601.21
   Kreiman J., 2016, UCLA VOICE SYNTHESIZ
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Labuschagne IB, 2016, ACOUST SCI TECHNOL, V37, P191, DOI 10.1250/ast.37.191
   Larson CR, 2001, J ACOUST SOC AM, V110, P2845, DOI 10.1121/1.1417527
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   Lombard E., 1911, ANN MALADIES OREILLE, V37, P101
   Newman RS, 2003, J ACOUST SOC AM, V113, P2850, DOI 10.1121/1.1567280
   Patel RR, 2018, AM J SPEECH-LANG PAT, V27, P887, DOI 10.1044/2018_AJSLP-17-0009
   Patel R, 2011, J SPEECH LANG HEAR R, V54, P1051, DOI 10.1044/1092-4388(2010/10-0162)
   Perkell JS, 2004, J ACOUST SOC AM, V116, P2338, DOI 10.1121/1.1787524
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   PISONI DB, 1974, J ACOUST SOC AM, V55, P328, DOI 10.1121/1.1914506
   Purcell DW, 2006, J ACOUST SOC AM, V119, P2288, DOI 10.1121/1.2173514
   Schober P, 2018, ANESTH ANALG, V126, P1763, DOI 10.1213/ANE.0000000000002864
   SHOJI K, 1992, LARYNGOSCOPE, V102, P267
   Shrivastav R, 2012, J ACOUST SOC AM, V131, P2261, DOI 10.1121/1.3681937
   Simpson A. P., 2009, FONETIK 2009 STOCKH
   Stepp CE, 2017, J SPEECH LANG HEAR R, V60, P1545, DOI 10.1044/2017_JSLHR-S-16-0282
   Tam K. H., 2018, VOIC FND 47 ANN S PH
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   Van Houtte E, 2011, J VOICE, V25, P202, DOI 10.1016/j.jvoice.2009.10.009
   Watts C. R., 2017, J VOICE, V31, pe1, DOI [10.1016/j.jvoice.2016.09.01, DOI 10.HTTPS://D0I.0RG/10.1016/J.JV0ICE.2016.09.012]
   Zraick RI, 2011, AM J SPEECH-LANG PAT, V20, P14, DOI 10.1044/1058-0360(2010/09-0105)
NR 60
TC 2
Z9 2
U1 0
U2 4
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD OCT
PY 2019
VL 62
IS 10
BP 3655
EP 3666
DI 10.1044/2019_JSLHR-S-19-0048
PG 12
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA JI2IS
UT WOS:000493287900002
PM 31525305
OA Green Published
DA 2021-02-24
ER

PT J
AU Masapollo, M
   Guenther, FH
AF Masapollo, Matthew
   Guenther, Frank H.
TI Engaging the Articulators Enhances Perception of Concordant Visible
   Speech Movements
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SENSORIMOTOR ADAPTATION; VOWEL; SENSITIVITY; INTEGRATION; FEEDBACK;
   MEMORY; SYSTEM; FACES; MODEL; BIAS
AB Purpose: This study aimed to test whether (and how) somatosensory feedback signals from the vocal tract affect concurrent unimodal visual speech perception.
   Method: Participants discriminated pairs of silent visual utterances of vowels under 3 experimental conditions: (a) normal (baseline) and while holding either (b) a bite block or (c) a lip tube in their mouths. To test the specificity of somatosensory-visual interactions during perception, we assessed discrimination of vowel contrasts optically distinguished based on their mandibular (English /epsilon/-/ae/) or labial (English /u/-French /u/) postures. In addition, we assessed perception of each contrast using dynamically articulating videos and static (single-frame) images of each gesture (at vowel midpoint).
   Results: Engaging the jaw selectively facilitated perception of the dynamic gestures optically distinct in terms of jaw height, whereas engaging the lips selectively facilitated perception of the dynamic gestures optically distinct in terms of their degree of lip compression and protrusion. Thus, participants perceived visible speech movements in relation to the configuration and shape of their own vocal tract (and possibly their ability to produce covert vowel production-like movements). In contrast, engaging the articulators had no effect when the speaking faces did not move, suggesting that the somatosensory inputs affected perception of time-varying kinematic information rather than changes in target (movement end point) mouth shapes.
   Conclusions: These findings suggest that orofacial somatosensory inputs associated with speech production prime premotor and somatosensory brain regions involved in the sensorimotor control of speech, thereby facilitating perception of concordant visible speech movement.
C1 [Masapollo, Matthew; Guenther, Frank H.] Boston Univ, Dept Speech Language & Hearing Sci, Boston, MA 02215 USA.
   [Guenther, Frank H.] Boston Univ, Dept Biomed Engn, Boston, MA 02215 USA.
RP Masapollo, M (corresponding author), Boston Univ, Dept Speech Language & Hearing Sci, Boston, MA 02215 USA.
EM mmasapol@bu.edu
FU National Institute on Deafness and Other Communication Disorders of the
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC002852];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC002852, R01DC002852, R01DC002852,
   R01DC002852] Funding Source: NIH RePORTER
FX Research reported in this publication was supported by the National
   Institute on Deafness and Other Communication Disorders of the National
   Institutes of Health Grant R01DC002852, awarded to Frank H. Guenther.
   The content is solely the responsibility of the authors and does not
   necessarily represent the official views of the National Institutes of
   Health. We are grateful to Barbara Holland and Farwa Faheem for
   assistance with subject recruitment, data collection, and analysis. This
   work benefited from helpful discussions with, or comments from, Julia
   Irwin, David Ostry, Linda Polka, Henny Yeung, Lauren Franklin, Christina
   Zhao, Janet Werker, and members of the audience at the 10th Annual
   Meeting of the Society for the Neurobiology of Language.
CR Abur D, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191839
   Best CT, 2016, ECOL PSYCHOL, V28, P216, DOI 10.1080/10407413.2016.1230372
   Boersma Paul, 2019, PRAAT DOING PHONETIC
   Bruderer AG, 2015, P NATL ACAD SCI USA, V112, P13531, DOI 10.1073/pnas.1508631112
   Cai SQ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0041830
   Calvert GA, 2003, J COGNITIVE NEUROSCI, V15, P57, DOI 10.1162/089892903321107828
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   Fowler C. A., 2004, HDB MULTISENSORY PRO, P189
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Galantucci B, 2009, ATTEN PERCEPT PSYCHO, V71, P1138, DOI 10.3758/APP.71.5.1138
   Golfinopoulos E, 2011, NEUROIMAGE, V55, P1324, DOI 10.1016/j.neuroimage.2010.12.065
   GRIER JB, 1971, PSYCHOL BULL, V75, P424, DOI 10.1037/h0031246
   Guenther FH., 2016, NEURAL CONTROL SPEEC
   Hickok G., 2016, DO CHINCHILLAS PIGE
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   Kuhl PK, 2014, P NATL ACAD SCI USA, V111, P11238, DOI 10.1073/pnas.1410963111
   MacDonald EN, 2012, CURR BIOL, V22, P113, DOI 10.1016/j.cub.2011.11.052
   MacLeod AAN, 2009, J PHONETICS, V37, P374, DOI 10.1016/j.wocn.2009.07.001
   MACMILLAN NA, 1988, J ACOUST SOC AM, V84, P1262, DOI 10.1121/1.396626
   Masapollo M, 2019, J EXP PSYCHOL HUMAN, V45, P285, DOI 10.1037/xhp0000603
   Masapollo M, 2018, J EXP PSYCHOL HUMAN, V44, P1103, DOI 10.1037/xhp0000518
   Masapollo M, 2017, COGNITION, V166, P358, DOI 10.1016/j.cognition.2017.06.001
   Matchin W, 2014, J COGNITIVE NEUROSCI, V26, P606, DOI 10.1162/jocn_a_00515
   Mollaei F, 2016, BRAIN RES, V1646, P269, DOI 10.1016/j.brainres.2016.06.013
   Nasir SM, 2006, CURR BIOL, V16, P1918, DOI 10.1016/j.cub.2006.07.069
   Noiray A., 2015, J ACOUST SOC AM, V129, P340
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   Rosenblum LD, 2005, BLACKW HBK LINGUIST, P51, DOI 10.1002/9780470757024.ch3
   Sams M, 2005, COGNITIVE BRAIN RES, V23, P429, DOI 10.1016/j.cogbrainres.2004.11.006
   Sato M, 2013, EXP BRAIN RES, V227, P275, DOI 10.1007/s00221-013-3510-8
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Stevens KN, 2002, J ACOUST SOC AM, V111, P1872, DOI 10.1121/1.1458026
   STEVENS KN, 1960, J ACOUST SOC AM, V32, P47, DOI 10.1121/1.1907874
   STRANGE W, 1989, J ACOUST SOC AM, V85, P2081, DOI 10.1121/1.397860
   Strange W, 2011, J PHONETICS, V39, P456, DOI 10.1016/j.wocn.2010.09.001
   Stuart A, 2002, J ACOUST SOC AM, V111, P2237, DOI 10.1121/1.1466868
   Sundara M, 2001, NEUROREPORT, V12, P1341, DOI 10.1097/00001756-200105250-00010
   Tremblay S, 2003, NATURE, V423, P866, DOI 10.1038/nature01710
   Villacorta VM, 2007, J ACOUST SOC AM, V122, P2306, DOI 10.1121/1.2773966
   Viswanathan N, 2014, J EXP PSYCHOL HUMAN, V40, P1228, DOI 10.1037/a0036214
   WERKER JF, 1984, J ACOUST SOC AM, V75, P1866, DOI 10.1121/1.390988
   WERKER JF, 1985, PERCEPT PSYCHOPHYS, V37, P35, DOI 10.3758/BF03207136
   Wise RJS, 1999, LANCET, V353, P1057, DOI 10.1016/S0140-6736(98)07491-1
   Yeung HH, 2013, PSYCHOL SCI, V24, P603, DOI 10.1177/0956797612458802
NR 47
TC 1
Z9 1
U1 1
U2 5
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD OCT
PY 2019
VL 62
IS 10
BP 3679
EP 3688
DI 10.1044/2019_JSLHR-S-19-0167
PG 10
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA JI2IS
UT WOS:000493287900004
PM 31577522
OA Green Published, Green Accepted
DA 2021-02-24
ER

PT J
AU Roepke, E
   Brosseau-Lapre, F
AF Roepke, Elizabeth
   Brosseau-Lapre, Francoise
TI Perception of Sibilants by Preschool Children With Overt and Covert
   Sound Contrasts
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID AUDITORY-DISCRIMINATION; SPEECH; ARTICULATION; CONSISTENCY; FRICATIVES;
   CATEGORIZATION; ACQUISITION; KNOWLEDGE; ENGLISH
AB Purpose: This study explores the role of overt and covert contrasts in speech perception by children with speech sound disorder (SSD).
   Method: Three groups of preschool-aged children (typically developing speech and language [TD], SSD with /s/similar to/integral/ contrast [SSD-contrast], and SSD with /s/similar to/integral/ collapse [SSD-collapse]) completed an identification task targeting /s/similar to/integral/ minimal pairs. The stimuli were produced by 3 sets of talkers: children with TD, children with SSD, and the participant himself/herself. We conducted a univariate general linear model to investigate differences in perception of tokens produced by different speakers and differences in perception between the groups of listeners.
   Results: The TD and SSD-contrast groups performed similarly when perceiving tokens produced by themselves or other children. The SSD-collapse group perceived all speakers more poorly than the other 2 groups of children, performing at chance for perception of their own speech. Children who produced a covert contrast did not perceive their own speech more accurately than children who produced no identifiable acoustic contrast.
   Conclusion: Preschool-aged children have not yet developed adultlike phonological representations. Collapsing phoneme production, even with a covert contrast, may indicate poor perception of the collapsed phonemes.
C1 [Roepke, Elizabeth; Brosseau-Lapre, Francoise] Purdue Univ, Dept Speech Language & Hearing Sci, W Lafayette, IN 47907 USA.
RP Roepke, E (corresponding author), Purdue Univ, Dept Speech Language & Hearing Sci, W Lafayette, IN 47907 USA.
EM john1973@purdue.edu
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA; NIDCDUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R21DC016142]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R21DC016142,
   R21DC016142, R21DC016142] Funding Source: NIH RePORTER
FX The work reported in this article was supported in part by a grant from
   the National Institutes of Health (awarded to Francoise Brosseau-Lapre,
   NIDCD Grant R21DC016142. We would like to thank the children and their
   parents who participated in the study. We acknowledge the contributions
   of the Purdue Child Phonology Laboratory personnel with data collection
   and data entry, and we would like to thank Krista Riegsecker for her
   assistance with acoustic analyses and Kathryn Bower for her assistance
   with transcription.
CR Audacity Team, 2019, AUD R FREE AUD ED RE
   AUNGST LF, 1964, J SPEECH HEAR DISORD, V29, P76, DOI 10.1044/jshd.2901.76
   Boersma Paul, 2012, PRAAT DOING PHONETIC
   BROEN PA, 1983, J SPEECH HEAR RES, V26, P601, DOI 10.1044/jshr.2604.601
   Dawson J., 2005, STRUCTURED PHOTOGRAP
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   Glaspey AM, 2010, CLIN LINGUIST PHONET, V24, P283, DOI 10.3109/02699200903581091
   Goldman R., 2015, GOLDMAN FRISTOE TEST, V3rd edition.
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   HOFFMAN PR, 1985, J SPEECH HEAR DISORD, V50, P46, DOI 10.1044/jshd.5001.46
   IBM Corp, 2017, IBM SPSS STAT WIND V
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   Kaufman A., 2004, KAUFMAN BRIEF INTELL, V2nd
   LAPKO LL, 1975, PERCEPT MOTOR SKILL, V40, P171, DOI 10.2466/pms.1975.40.1.171
   Li FF, 2009, J PHONETICS, V37, P111, DOI 10.1016/j.wocn.2008.10.001
   LOCKE JL, 1975, J SPEECH HEAR RES, V18, P176, DOI 10.1044/jshr.1801.176
   Lof G., 1997, CONT ISSUES COMMUNIC, V24, P62
   Nissen SL, 2005, J ACOUST SOC AM, V118, P2570, DOI 10.1121/1.2010407
   NITTROUER S, 1992, J PHONETICS, V20, P351, DOI 10.1016/S0095-4470(19)30639-4
   NITTROUER S, 1987, J SPEECH HEAR RES, V30, P319, DOI 10.1044/jshr.3003.319
   NITTROUER S, 1995, J ACOUST SOC AM, V97, P520, DOI 10.1121/1.412278
   OHDE RN, 1988, J SPEECH HEAR RES, V31, P556, DOI 10.1044/jshr.3104.556
   Preston JL, 2015, SEMIN SPEECH LANG, V36, P224, DOI 10.1055/s-0035-1562906
   Rvachew S, 2003, AM J SPEECH-LANG PAT, V12, P463, DOI 10.1044/1058-0360(2003/092)
   RVACHEW S, 1989, J SPEECH HEAR DISORD, V54, P193, DOI 10.1044/jshd.5402.193
   RVACHEW S, 1994, J SPEECH HEAR RES, V37, P347, DOI 10.1044/jshr.3702.347
   Schneider W., 2012, E PRIME USERS GUIDE
   Seidl A, 2018, J ACOUST SOC AM, V143, P858, DOI 10.1121/1.5021710
   Shuster LI, 1998, J SPEECH LANG HEAR R, V41, P941, DOI 10.1044/jslhr.4104.941
   SMIT AB, 1990, J SPEECH HEAR DISORD, V55, P779, DOI 10.1044/jshd.5504.779
   St Louis K.O., 2000, ORAL SPEECH MECH SCR
   Strombergsson S, 2014, CLIN LINGUIST PHONET, V28, P373, DOI 10.3109/02699206.2013.868928
   Sutherland D, 2005, LANG SPEECH HEAR SER, V36, P294, DOI 10.1044/0161-1461(2005/030)
   TYLER AA, 1991, APPL PSYCHOLINGUIST, V12, P453, DOI 10.1017/S0142716400005877
   TYLER AA, 1993, J SPEECH HEAR RES, V36, P746, DOI 10.1044/jshr.3604.746
   TYLER AA, 1990, J SPEECH HEAR DISORD, V55, P251, DOI 10.1044/jshd.5502.251
   Williams K, 2007, EXPRESSIVE VOCABULAR
   WOOLF G, 1971, J COMMUN DISORD, V3, P239, DOI 10.1016/0021-9924(71)90030-X
NR 38
TC 2
Z9 2
U1 0
U2 4
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD OCT
PY 2019
VL 62
IS 10
BP 3763
EP 3770
DI 10.1044/2019_JSLHR-S-19-0127
PG 8
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA JI2IS
UT WOS:000493287900011
PM 31589541
OA Green Published
DA 2021-02-24
ER

PT J
AU Isarangura, S
   Eddins, AC
   Ozmeral, EJ
   Eddins, DA
AF Isarangura, Sittiprapa
   Eddins, Ann C.
   Ozmeral, Erol J.
   Eddins, David A.
TI The Effects of Duration and Level on Spectral Modulation Perception
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID FREQUENCY-SELECTIVITY; PROFILE ANALYSIS; DISCRIMINATION; BANDWIDTH;
   TONES; MODEL; VOWEL; NOISE
AB Purpose: Spectral modulation detection is an increasingly common assay of suprathreshold auditory perception and has been correlated with speech perception performance. Here, the potential effects of stimulus duration and stimulus presentation level on spectral modulation detection were investigated.
   Method: Spectral modulation detection thresholds were measured as a function of modulation frequency in young, normal-hearing listeners. The standard stimulus was a bandpass noise, and signal stimuli were created by superimposing sinusoidal spectral modulation on the bandpass noise carrier. The modulation was sinusoidal on a log 2 frequency axis and a log(10) (dB) amplitude scale with a random starting phase (0-2rr radians). In 1 experiment, stimulus durations were 50, 100, 200, or 400 ms (at fixed level 81 dB SPL). In a 2nd experiment, stimuli were presented at sensation levels of 10, 20, 30, 40, and 60 dB SL (fixed at a duration of 400 ms).
   Results: Spectral modulation detection thresholds were similarly low for the 400- and 200-ms durations, increased slightly for the 100-ms duration, and increased markedly for the 50-ms duration. Thresholds were lowest for 40 dB SL; increased slightly for 20, 30, and 60 dB SL; and markedly higher for the 10-dB SL condition.
   Conclusions: The increase in thresholds for the shortest durations and lowest sensational levels is consistent with previous investigations of auditory spectral profile analysis. The effects of presentation level and stimulus duration are important considerations in the context of understanding potential relationships between the perception of spectral cues and speech perception, when designing investigations and interpreting data related to spectral envelope perception, and in the context of models of auditory perception. As examples, 2 simple models based on auditory nerve output that have been used to explain spectrotemporal modulation in previous investigations produced an output inconsistent with the present results.
   Plain language summary: Intensity variations across audio frequency lead to spectral shapes that are essential and sometimes signature features of various sounds in the environment, including speech. Here, we show how laboratory measures of spectral shape perception depend on presentation level and stimulus duration.
C1 [Isarangura, Sittiprapa; Eddins, Ann C.; Ozmeral, Erol J.; Eddins, David A.] Univ S Florida, Dept Commun Sci & Disorders, Tampa, FL 33620 USA.
RP Isarangura, S (corresponding author), Univ S Florida, Dept Commun Sci & Disorders, Tampa, FL 33620 USA.
EM sisarangura@mail.usf.edu
FU National Institute on AgingUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Aging (NIA) [P01 AG009524]; National Institute on Deafness and Other
   Communication DisordersUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01 DC015051];
   NATIONAL INSTITUTE ON AGINGUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Aging (NIA) [P01AG009524, P01AG009524, P01AG009524, P01AG009524,
   P01AG009524, P01AG009524, P01AG009524, P01AG009524, P01AG009524,
   P01AG009524, P01AG009524, P01AG009524, P01AG009524, P01AG009524,
   P01AG009524, P01AG009524, P01AG009524, P01AG009524, P01AG009524,
   P01AG009524, P01AG009524, P01AG009524, P01AG009524, P01AG009524,
   P01AG009524, P01AG009524, P01AG009524, P01AG009524, P01AG009524,
   P01AG009524, P01AG009524, P01AG009524, P01AG009524, P01AG009524] Funding
   Source: NIH RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC015051,
   R01DC015051] Funding Source: NIH RePORTER
FX The authors report that the work was funded in part by National
   Institute on Aging Grant P01 AG009524 and National Institute on Deafness
   and Other Communication Disorders Grant R01 DC015051 awarded to Gallun,
   Eddins, and Seitz and is in partial fulfillment of the PhD requirements
   of the first author. The authors would like to thank Katherine
   Palandrani and Mckenna Dyjak for their assistance with data collection
   and Frederick (Erick) Gallun, Aaron Seitz, and Eric Hoover for
   inspiration and discussion of the methods and results reported here.
CR Bernstein JGW, 2013, J AM ACAD AUDIOL, V24, P293, DOI 10.3766/jaaa.24.4.5
   DAI HP, 1993, J ACOUST SOC AM, V93, P957, DOI 10.1121/1.405456
   EDDINS DA, 1993, J ACOUST SOC AM, V93, P470, DOI 10.1121/1.405627
   Eddins DA, 1999, J ACOUST SOC AM, V105, P829, DOI 10.1121/1.426272
   Eddins DA, 2007, J ACOUST SOC AM, V121, P363, DOI 10.1121/1.2382347
   FLORENTINE M, 1987, J ACOUST SOC AM, V81, P1528, DOI 10.1121/1.394505
   FLORENTINE M, 1986, J ACOUST SOC AM, V79, P792, DOI 10.1121/1.393469
   Glasberg BR, 2000, J ACOUST SOC AM, V108, P2318, DOI 10.1121/1.1315291
   GREEN DM, 1984, J ACOUST SOC AM, V75, P1163, DOI 10.1121/1.390765
   JESTEADT W, 1977, J ACOUST SOC AM, V61, P169, DOI 10.1121/1.381278
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Magits S, 2019, HEARING RES, V371, P11, DOI 10.1016/j.heares.2018.10.017
   MASON CR, 1984, HEARING RES, V13, P269, DOI 10.1016/0378-5955(84)90080-7
   MOORE BCJ, 1987, HEARING RES, V28, P209, DOI 10.1016/0378-5955(87)90050-5
   Moore BCJ, 2004, HEARING RES, V188, P70, DOI 10.1016/S0378-5955(03)00347-2
   Ozmeral EJ, 2018, J SPEECH LANG HEAR R, V61, P2376, DOI 10.1044/2018_JSLHR-H-18-0056
   Qian JY, 2008, J ACOUST SOC AM, V123, P302, DOI 10.1121/1.2804698
   ROSEN S, 1992, J ACOUST SOC AM, V92, P773, DOI 10.1121/1.403946
   Saoji AA, 2009, J ACOUST SOC AM, V126, P955, DOI 10.1121/1.3179670
   Shamma SA, 2011, TRENDS NEUROSCI, V34, P114, DOI 10.1016/j.tins.2010.11.002
   SPIEGEL MF, 1982, J ACOUST SOC AM, V71, P1204, DOI 10.1121/1.387769
   SUMMERS V, 1994, J ACOUST SOC AM, V95, P3518, DOI 10.1121/1.409969
   VANVEEN TM, 1985, J ACOUST SOC AM, V77, P628, DOI 10.1121/1.391880
   VIEMEISTER NF, 1979, J ACOUST SOC AM, V66, P1364, DOI 10.1121/1.383531
   WRIGHT BA, 1994, J ACOUST SOC AM, V95, P931, DOI 10.1121/1.410010
   Zilany MSA, 2014, J ACOUST SOC AM, V135, P283, DOI 10.1121/1.4837815
   Zilany MSA, 2009, J ACOUST SOC AM, V126, P2390, DOI 10.1121/1.3238250
NR 27
TC 1
Z9 1
U1 1
U2 2
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD OCT
PY 2019
VL 62
IS 10
BP 3876
EP 3886
DI 10.1044/2019_JSLHR-H-18-0449
PG 11
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA JI2IS
UT WOS:000493287900019
PM 31638883
DA 2021-02-24
ER

PT J
AU McClaskey, CM
   Dias, JW
   Harris, KC
AF McClaskey, Carolyn M.
   Dias, James W.
   Harris, Kelly C.
TI Sustained envelope periodicity representations are associated with
   speech-in-noise performance in difficult listening conditions for
   younger and older adults
SO JOURNAL OF NEUROPHYSIOLOGY
LA English
DT Article
DE aging; auditory steady-state response; envelope following response;
   speech perception; temporal processing
ID STEADY-STATE RESPONSES; FREQUENCY-FOLLOWING RESPONSES; NORMAL-HEARING;
   AMPLITUDE; PERCEPTION; MODULATION; AGE; SOUNDS; RECOGNITION; POTENTIALS
AB Temporal modulations are an important part of speech signals. An accurate perception of these time-varying qualities of sound is necessary for successful communication. The current study investigates the relationship between sustained envelope encoding and speech-in-noise perception in a cohort of normalhearing younger (ages 18-30 yr, n = 22) and older adults (ages 55-90+ yr, n = 35) using the subcortical auditory steady-state response (ASSR). ASSRs were measured in response to the envelope of 400-ms amplitude-modulated (AM) tones with 3,000-Hz carrier frequencies and 80-Hz modulation frequencies. AM tones had modulation depths of 0, -4, and -8 dB relative to m = 1 (m = 1, 0.631, and 0.398, respectively). The robustness, strength at modulation frequency, and synchrony of subcortical envelope encoding were quantified via time-domain correlations, spectral amplitude, and phase-locking value, respectively. Speech-in-noise ability was quantified via the QuickSIN test in the 0- and 5-dB signal-to-noise (SNR) conditions. All ASSR metrics increased with increasing modulation depth and there were no effects of age group. ASSR metrics in response to shallow modulation depths predicted 0-dB speech scores. Results demonstrate that sustained amplitude envelope processing in the brainstem relates to speech-in-noise abilities, but primarily in difficult listening conditions at low SNRs. These findings furthermore highlight the utility of shallow modulation depths for studying temporal processing. The absence of age effects in these data demonstrate that individual differences in the robustness, strength, and specificity of subcortical envelope processing, and not age, predict speech-in-noise performance in the most difficult listening conditions.
   NEW & NOTEWORTHY Failure to correctly understand speech in the presence of background noise is a significant problem for many normal-hearing adults and may impede healthy communication. The relationship between sustained envelope encoding in the brainstem and speech-in-noise perception remains to be clarified. The present study demonstrates that the strength, specificity, and robustness of the brainstem's representations of sustained stimulus periodicity relates to speech-in-noise perception in older and younger normal-hearing adults, but only in highly challenging listening environments.
C1 [McClaskey, Carolyn M.; Dias, James W.; Harris, Kelly C.] Med Univ South Carolina, Hearing Res Program, Dept Otolaryngol Head & Neck Surg, 135 Rutledge Ave,MSC 550, Charleston, SC 29425 USA.
RP McClaskey, CM (corresponding author), Med Univ South Carolina, Hearing Res Program, Dept Otolaryngol Head & Neck Surg, 135 Rutledge Ave,MSC 550, Charleston, SC 29425 USA.
EM mcclaske@musc.edu
OI McClaskey, Carolyn/0000-0002-0942-6281
FU National Institutes of Health (NIH)United States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USA [R01 DC014467,
   R01 DC017619, P50 DC00422, T32 DC014435]; South Carolina Clinical and
   Translational Research Institute; NIHUnited States Department of Health
   & Human ServicesNational Institutes of Health (NIH) - USA [UL1RR029882];
   NIH Research Facilities Improvement ProgramUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USA [C06
   RR14516]; Medical University of South Carolina; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [P50DC000422, P50DC000422, P50DC000422, R01DC017619, P50DC000422,
   P50DC000422, P50DC000422, P50DC000422, T32DC014435, P50DC000422,
   P50DC000422, T32DC014435, P50DC000422, R01DC017619, T32DC014435,
   P50DC000422, T32DC014435, T32DC014435, P50DC000422, T32DC014435,
   R01DC014467, P50DC000422, P50DC000422, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422, R01DC014467, P50DC000422, P50DC000422,
   P50DC000422, P50DC000422] Funding Source: NIH RePORTER
FX This work was supported in part by National Institutes of Health (NIH)
   Grants R01 DC014467, R01 DC017619, P50 DC00422, and T32 DC014435. The
   project also received support from the South Carolina Clinical and
   Translational Research Institute with an academic home at the Medical
   University of South Carolina, supported by NIH Grant UL1RR029882. This
   investigation was conducted in a facility constructed with support from
   NIH Research Facilities Improvement Program Grant C06 RR14516.
CR Aiken SJ, 2008, HEARING RES, V245, P35, DOI 10.1016/j.heares.2008.08.004
   Anderson S, 2012, J NEUROSCI, V32, P14156, DOI 10.1523/JNEUROSCI.2176-12.2012
   Anderson S, 2011, EAR HEARING, V32, P750, DOI 10.1097/AUD.0b013e31822229d3
   Anderson S, 2010, J AM ACAD AUDIOL, V21, P575, DOI 10.3766/jaaa.21.9.3
   Anderson S, 2010, TRENDS AMPLIF, V14, P73, DOI 10.1177/1084713810380227
   Anderson S, 2010, J NEUROSCI, V30, P4922, DOI 10.1523/JNEUROSCI.0107-10.2010
   Assmann Peter, 2004, VVolume 18, P231
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bernstein LR, 2004, J ACOUST SOC AM, V116, P3062, DOI 10.1121/1.1791892
   Bharadwaj HM, 2015, J NEUROSCI, V35, P2161, DOI 10.1523/JNEUROSCI.3915-14.2015
   Bharadwaj HM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00026
   Bidebnan GM, 2010, BRAIN RES, V1355, P112, DOI 10.1016/j.brainres.2010.07.100
   Bidelman GM, 2015, HEARING RES, V323, P68, DOI 10.1016/j.heares.2015.01.011
   Boettcher FA, 2001, HEARING RES, V153, P32, DOI 10.1016/S0378-5955(00)00255-0
   CASPARY DM, 1995, EXP GERONTOL, V30, P349, DOI 10.1016/0531-5565(94)00052-5
   Chambers AR, 2016, NEURON, V89, P867, DOI 10.1016/j.neuron.2015.12.041
   Clinard CG, 2017, JARO-J ASSOC RES OTO, V18, P355, DOI 10.1007/s10162-016-0603-7
   Clinard CG, 2015, HEARING RES, V323, P91, DOI 10.1016/j.heares.2015.02.002
   Clinard CG, 2013, J AM ACAD AUDIOL, V24, P590, DOI 10.3766/jaaa.24.7.7
   Clinard CG, 2010, HEARING RES, V264, P48, DOI 10.1016/j.heares.2009.11.010
   Cohen MX, 2014, ISS CLIN COGN NEUROP, P1
   Delorme A, 2015, J NEUROSCI METH, V250, P3, DOI 10.1016/j.jneumeth.2014.10.003
   Dimitrijevic A, 2004, EAR HEARING, V25, P68, DOI 10.1097/01.AUD.0000111545.71693.48
   Dimitrijevic A, 2001, EAR HEARING, V22, P100, DOI 10.1097/00003446-200104000-00003
   Dimitrijevic A, 2016, EAR HEARING, V37, pE322, DOI 10.1097/AUD.0000000000000324
   Dobie RA, 1996, J ACOUST SOC AM, V100, P2236, DOI 10.1121/1.417933
   Dreyer A, 2006, J NEUROPHYSIOL, V96, P2327, DOI 10.1152/jn.00326.2006
   Ferrari SLP, 2004, J APPL STAT, V31, P799, DOI 10.1080/0266476042000214501
   Goossens T, 2018, HEARING RES, V370, P189, DOI 10.1016/j.heares.2018.07.012
   Grose JH, 2009, EAR HEARING, V30, P568, DOI 10.1097/AUD.0b013e3181ac128f
   Guest H, 2018, HEARING RES, V364, P142, DOI 10.1016/j.heares.2018.03.008
   Guest H, 2017, HEARING RES, V344, P265, DOI 10.1016/j.heares.2016.12.002
   Harris KC, 2017, NEUROBIOL AGING, V53, P150, DOI 10.1016/j.neurobiolaging.2017.01.008
   Hornickel J, 2009, P NATL ACAD SCI USA, V106, P13022, DOI 10.1073/pnas.0901123106
   Killion MC, 2006, J ACOUST SOC AM, V119, P1888, DOI 10.1121/1.2166610
   Lachaux JP, 1999, HUM BRAIN MAPP, V8, P194, DOI 10.1002/(SICI)1097-0193(1999)8:4<194::AID-HBM4>3.0.CO;2-C
   Leigh-Paffenroth ED, 2006, J AM ACAD AUDIOL, V17, P582, DOI 10.3766/jaaa.17.8.5
   Leigh-Paffenroth ED, 2011, INT J AUDIOL, V50, P86, DOI 10.3109/14992027.2010.532512
   Ospina R, 2012, COMPUT STAT DATA AN, V56, P1609, DOI 10.1016/j.csda.2011.10.005
   Ospina R, 2010, STAT PAP, V51, P111, DOI 10.1007/s00362-008-0125-4
   Parbery-Clark A, 2012, FRONT AGING NEUROSCI, V4, DOI 10.3389/fnagi.2012.00030
   Parbery-Clark A, 2012, NEUROBIOL AGING, V33, DOI 10.1016/j.neurobiolaging.2011.12.015
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Parbery-Clark A, 2009, J NEUROSCI, V29, P14100, DOI 10.1523/JNEUROSCI.3256-09.2009
   Parthasarathy A, 2019, NEUROSCIENCE, V407, P21, DOI 10.1016/j.neuroscience.2018.12.007
   Pereira TL, 2014, COMMUN STAT-SIMUL C, V43, P631, DOI 10.1080/03610918.2012.712183
   Picton T, 2013, EAR HEARING, V34, P385, DOI 10.1097/AUD.0b013e31827ada02
   PICTON TW, 1987, J ACOUST SOC AM, V82, P165, DOI 10.1121/1.395560
   Presacco A, 2016, J NEUROPHYSIOL, V116, P2346, DOI 10.1152/jn.00372.2016
   Purcell DW, 2004, J ACOUST SOC AM, V116, P3581, DOI 10.1121/1.1798354
   R Core Team, 2017, R LANG ENV STAT COMP
   Rance G, 2008, AUDITORY STEADY STAT
   REES A, 1986, HEARING RES, V23, P123, DOI 10.1016/0378-5955(86)90009-2
   Rigby RA, 2005, J R STAT SOC C-APPL, V54, P507, DOI 10.1111/j.1467-9876.2005.00510.x
   Ross B, 2000, J ACOUST SOC AM, V108, P679, DOI 10.1121/1.429600
   Schoof T, 2016, JARO-J ASSOC RES OTO, V17, P441, DOI 10.1007/s10162-016-0564-x
   Shaheen LA, 2015, JARO-J ASSOC RES OTO, V16, P727, DOI 10.1007/s10162-015-0539-3
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sheft S, 2012, EAR HEARING, V33, P709, DOI 10.1097/AUD.0b013e31825aab15
   Song JH, 2011, J COGNITIVE NEUROSCI, V23, P2268, DOI 10.1162/jocn.2010.21556
   Stasinopoulos DM, 2007, J STAT SOFTW, V23
   Stasinopoulos M, 2017, GAMLSS GEN ADDITIVE
   Strouse A, 1998, J ACOUST SOC AM, V104, P2385, DOI 10.1121/1.423748
   TallonBaudry C, 1996, J NEUROSCI, V16, P4240
   Wang Q, 2018, HEARING RES, V357, P25, DOI 10.1016/j.heares.2017.10.014
   Werff KRV, 2011, EAR HEARING, V32, P168, DOI 10.1097/AUD.0b013e3181f534b5
   Wilson RH, 2007, J SPEECH LANG HEAR R, V50, P844, DOI 10.1044/1092-4388(2007/059)
   WORDEN FG, 1968, ELECTROEN CLIN NEURO, V25, P42, DOI 10.1016/0013-4694(68)90085-0
NR 68
TC 2
Z9 2
U1 0
U2 1
PU AMER PHYSIOLOGICAL SOC
PI BETHESDA
PA 9650 ROCKVILLE PIKE, BETHESDA, MD 20814 USA
SN 0022-3077
EI 1522-1598
J9 J NEUROPHYSIOL
JI J. Neurophysiol.
PD OCT
PY 2019
VL 122
IS 4
BP 1685
EP 1696
DI 10.1152/jn.00845.2018
PG 12
WC Neurosciences; Physiology
SC Neurosciences & Neurology; Physiology
GA JF6AH
UT WOS:000491469500030
PM 31365323
OA Green Published
DA 2021-02-24
ER

PT J
AU Wu, YCZ
   Evans, BG
   Adank, P
AF Wu, Yuchunzi
   Evans, Bronwen G.
   Adank, Patti
TI Sensorimotor training modulates automatic imitation of visual speech
SO PSYCHONOMIC BULLETIN & REVIEW
LA English
DT Article
DE Automatic imitation; Speech perception; Speech production; Sensorimotor
   learning
ID EXPERIENCE; ACTIVATION; HUMANS; SYSTEM; HAND
AB The observation-execution links underlying automatic-imitation processes are suggested to result from associative sensorimotor experience of performing and watching the same actions. Past research supporting the associative sequence learning (ASL) model has demonstrated that sensorimotor training modulates automatic imitation of perceptually transparent manual actions, but ASL has been criticized for not being able to account for opaque actions, such as orofacial movements that include visual speech. To investigate whether the observation-execution links underlying opaque actions are as flexible as has been demonstrated for transparent actions, we tested whether sensorimotor training modulated the automatic imitation of visual speech. Automatic imitation was defined as a facilitation in response times for syllable articulation (ba or da) when in the presence of a compatible visual speech distractor, relative to when in the presence of an incompatible distractor. Participants received either mirror (say /ba/ when the speaker silently says /ba/, and likewise for /da/) or countermirror (say /da/ when the speaker silently says /ba/, and vice versa) training, and automatic imitation was measured before and after training. The automatic-imitation effect was enhanced following mirror training and reduced following countermirror training, suggesting that sensorimotor learning plays a critical role in linking speech perception and production, and that the links between these two systems remain flexible in adulthood. Additionally, as compared to manual movements, automatic imitation of speech was susceptible to mirror training but was relatively resilient to countermirror training. We propose that social factors and the multimodal nature of speech might account for the resilience to countermirror training of sensorimotor associations of speech actions.
C1 [Wu, Yuchunzi; Evans, Bronwen G.; Adank, Patti] UCL, Dept Speech Hearing & Phonet Sci, London, England.
RP Wu, YCZ (corresponding author), UCL, Dept Speech Hearing & Phonet Sci, London, England.
EM yuchunzi.wu.15@ucl.ac.uk
RI ARSLAN, Okan/AAA-3232-2020
OI Wu, Yuchunzi/0000-0002-3584-9392
FU China Scholarship CouncilChina Scholarship Council; BIAL FoundationBial
   Foundation [267/14]
FX This work was supported by a grant of the China Scholarship Council to
   the first author and by the BIAL Foundation under Grant No. 267/14 to
   P.A.
CR Adank P, 2018, ATTEN PERCEPT PSYCHO, V80, P1290, DOI 10.3758/s13414-018-1501-3
   Adank P, 2010, PSYCHOL SCI, V21, P1903, DOI 10.1177/0956797610389192
   Boersma P., 2018, PRAAT DOING PHONETIC
   Buccino G, 2004, NEURON, V42, P323, DOI 10.1016/S0896-6273(04)00181-3
   Carr L, 2003, P NATL ACAD SCI USA, V100, P5497, DOI 10.1073/pnas.0935845100
   Casile A, 2011, NEUROSCIENTIST, V17, P524, DOI 10.1177/1073858410392239
   Catmur C, 2013, NEUROSCI LETT, V540, P21, DOI 10.1016/j.neulet.2012.10.001
   Catmur C, 2009, PHILOS T R SOC B, V364, P2369, DOI 10.1098/rstb.2009.0048
   Cracco E, 2018, PSYCHOL BULL, V144, P453, DOI 10.1037/bul0000143
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Ferrari PF, 2017, NEUROSCIENCE, V358, P300, DOI 10.1016/j.neuroscience.2017.06.052
   Gallese V, 1996, BRAIN, V119, P593, DOI 10.1093/brain/119.2.593
   Hari R, 1998, P NATL ACAD SCI USA, V95, P15061, DOI 10.1073/pnas.95.25.15061
   Heyes C, 2005, COGNITIVE BRAIN RES, V22, P233, DOI 10.1016/j.cogbrainres.2004.09.009
   Heyes C, 2005, PERSPECTIVES IMITATI, P157
   Heyes C, 2011, PSYCHOL BULL, V137, P463, DOI 10.1037/a0022288
   Heyes C, 2010, NEUROSCI BIOBEHAV R, V34, P575, DOI 10.1016/j.neubiorev.2009.11.007
   Kerzel D, 2000, J EXP PSYCHOL HUMAN, V26, P634, DOI 10.1037//0096-1523.26.2.634
   Meltzoff Andrew N, 2002, IMITATIVE MIND DEV E, P19, DOI DOI 10.1017/CBO9780511489969.002
   Molenberghs P, 2012, NEUROSCI BIOBEHAV R, V36, P341, DOI 10.1016/j.neubiorev.2011.07.004
   Mukamel R, 2010, CURR BIOL, V20, P750, DOI 10.1016/j.cub.2010.02.045
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   Press C, 2007, P ROY SOC B-BIOL SCI, V274, P2509, DOI 10.1098/rspb.2007.0774
   Ray E, 2011, DEVELOPMENTAL SCI, V14, P92, DOI 10.1111/j.1467-7687.2010.00961.x
   Schmitz J, 2019, NEUROPSYCHOLOGIA, V128, P290, DOI 10.1016/j.neuropsychologia.2018.01.006
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Sturmer B, 2000, J EXP PSYCHOL HUMAN, V26, P1746, DOI 10.1037//0096-1523.26.6.1746
   Swaminathan S, 2013, BRAIN LANG, V126, P1, DOI 10.1016/j.bandl.2013.03.002
NR 28
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1069-9384
EI 1531-5320
J9 PSYCHON B REV
JI Psychon. Bull. Rev.
PD OCT
PY 2019
VL 26
IS 5
BP 1711
EP 1718
DI 10.3758/s13423-019-01623-8
PG 8
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA JF2FG
UT WOS:000491200700020
PM 31197755
OA Bronze
DA 2021-02-24
ER

PT J
AU Pinto, S
   Tremblay, P
   Basirat, A
   Sato, M
AF Pinto, Serge
   Tremblay, Pascale
   Basirat, Anahita
   Sato, Marc
TI The impact of when, what and how predictions on auditory speech
   perception
SO EXPERIMENTAL BRAIN RESEARCH
LA English
DT Article
DE Auditory speech perception; Audiovisual speech perception; Predictive
   coding; Predictive timing; EEG
ID ELECTROPHYSIOLOGICAL EVIDENCE; MULTISENSORY INTERACTIONS; VISUAL SPEECH;
   N1 WAVE; BRAIN; INFORMATION; TIME; INTEGRATION; KNOWLEDGE; FACILITATION
AB An impressive number of theoretical proposals and neurobiological studies argue that perceptual processing is not strictly feedforward but rather operates through an interplay between bottom-up sensory and top-down predictive mechanisms. The present EEG study aimed to further determine how prior knowledge on auditory syllables may impact speech perception. Prior knowledge was manipulated by presenting the participants with visual information indicative of the syllable onset (when), its phonetic content (what) and/or its articulatory features (how). While when and what predictions consisted of unnatural visual cues (i.e., a visual timeline and a visuo-orthographic cue), how prediction consisted of the visual movements of a speaker. During auditory speech perception, when and what predictions both attenuated the amplitude of N1/P2 auditory evoked potentials. Regarding how prediction, not only an amplitude decrease but also a latency facilitation of N1/P2 auditory evoked potentials were observed during audiovisual compared to unimodal speech perception. However, when and what predictability effects were then reduced or abolished, with only what prediction reducing P2 amplitude but increasing latency. Altogether, these results demonstrate the influence of when, what and how visually induced predictions at an early stage on cortical auditory speech processing. Crucially, they indicate a preponderant predictive role of the speaker's articulatory gestures during audiovisual speech perception, likely driven by attentional load and focus.
C1 [Pinto, Serge; Sato, Marc] Aix Marseille Univ, Lab Parole & Langage, UMR 7309, CNRS,LPL, 5 Ave Pasteur, F-13100 Aix En Provence, France.
   [Tremblay, Pascale] Univ Laval, Fac Med, Dept Readaptat, Quebec City, PQ, Canada.
   [Tremblay, Pascale] Cervo Brain Res Ctr, Quebec City, PQ, Canada.
   [Basirat, Anahita] Univ Lille, Sci Cognit & Sci Affect, SCALab, CNRS,CHU Lille,UMR 9193, Lille, France.
RP Sato, M (corresponding author), Aix Marseille Univ, Lab Parole & Langage, UMR 7309, CNRS,LPL, 5 Ave Pasteur, F-13100 Aix En Provence, France.
EM marc.sato@lpl-aix.fr
CR Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Alsius A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00727
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009
   Baart M, 2016, PSYCHOPHYSIOLOGY, V53, P1295, DOI 10.1111/psyp.12683
   Baart M, 2014, NEUROPSYCHOLOGIA, V53, P115, DOI 10.1016/j.neuropsychologia.2013.11.011
   Besle J, 2004, EUR J NEUROSCI, V20, P2225, DOI 10.1111/j.1460-9568.2004.03670.x
   Boersma P., 2013, PRAAT DOING PHONETIC
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477
   Clementz BA, 2002, AUDIOL NEURO-OTOL, V7, P303, DOI 10.1159/000064444
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Fodor J., 1983, MODULARITY MIND
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   Frtusova JB, 2013, PSYCHOL AGING, V28, P481, DOI 10.1037/a0031243
   Ganesh AC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01340
   GREGORY RL, 1980, PHILOS T ROY SOC B, V290, P181, DOI 10.1098/rstb.1980.0090
   Heilbron M, 2018, NEUROSCIENCE, V389, P54, DOI 10.1016/j.neuroscience.2017.07.061
   Klucharev V, 2003, COGNITIVE BRAIN RES, V18, P65, DOI 10.1016/j.cogbrainres.2003.09.004
   Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007
   Laine M, 2007, NEUROREPORT, V18, P1697, DOI 10.1097/WNR.0b013e3282f0d118
   Lange K, 2003, PSYCHOPHYSIOLOGY, V40, P806, DOI 10.1111/1469-8986.00081
   Lange K, 2006, J COGNITIVE NEUROSCI, V18, P715, DOI 10.1162/jocn.2006.18.5.715
   Lange K, 2006, EXP BRAIN RES, V173, P130, DOI 10.1007/s00221-006-0372-3
   Lange K, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00263
   Lange K, 2009, BRAIN COGNITION, V69, P127, DOI 10.1016/j.bandc.2008.06.004
   Massaro D. W., 1998, PERCEIVING TALKING F
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Neisser U., 1967, COGNITIVE PSYCHOL
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Paris T, 2017, NEUROSCIENCE, V343, P157, DOI 10.1016/j.neuroscience.2016.09.023
   Paris T, 2016, J COGNITIVE NEUROSCI, V28, P158, DOI 10.1162/jocn_a_00885
   Pilling M, 2009, J SPEECH LANG HEAR R, V52, P1073, DOI [10.1044/1092-4388, 10.1044/1092-4388(2009/07-0276)]
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580
   Roder B, 2007, RESTOR NEUROL NEUROS, V25, P311
   Rosenblum LD, 2016, ECOL PSYCHOL, V28, P262, DOI 10.1080/10407413.2016.1230373
   SCHAFER EWP, 1981, ELECTROEN CLIN NEURO, V52, P9, DOI 10.1016/0013-4694(81)90183-8
   SCHERG M, 1986, ELECTROEN CLIN NEURO, V65, P344, DOI 10.1016/0168-5597(86)90014-6
   Schwartz JL, 2014, PLOS COMPUTATIONAL B, V10, P7
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964
   Talsma D, 2015, FRONT INTEGR NEUROSC, V19, P9
   Treille A, 2018, NEUROPSYCHOLOGIA, V109, P126, DOI 10.1016/j.neuropsychologia.2017.12.024
   Treille A, 2017, EXP BRAIN RES, V235, P2867, DOI 10.1007/s00221-017-5018-0
   Treille A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00420
   Treille A, 2014, NEUROPSYCHOLOGIA, V57, P71, DOI 10.1016/j.neuropsychologia.2014.02.004
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   van Wassenhove V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00388
   VONHELMHOLTZ H, 1909, TREATISE PHYSL OPTIC
   Vroomen J, 2010, J COGNITIVE NEUROSCI, V22, P1583, DOI 10.1162/jocn.2009.21308
   Widmann A, 2004, PSYCHOPHYSIOLOGY, V41, P709, DOI 10.1111/j.1469-8986.2004.00208.x
   Winneke AH, 2011, PSYCHOL AGING, V26, P427, DOI 10.1037/a0021683
   Woods DL, 1995, EEG CL N SU, P102
NR 57
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0014-4819
EI 1432-1106
J9 EXP BRAIN RES
JI Exp. Brain Res.
PD DEC
PY 2019
VL 237
IS 12
BP 3143
EP 3153
DI 10.1007/s00221-019-05661-5
EA OCT 2019
PG 11
WC Neurosciences
SC Neurosciences & Neurology
GA JY3MM
UT WOS:000489506800001
PM 31576421
DA 2021-02-24
ER

PT J
AU Tichko, P
   Large, EW
AF Tichko, Parker
   Large, Edward W.
TI Modeling infants' perceptual narrowing to musical rhythms: neural
   oscillation and Hebbian plasticity
SO ANNALS OF THE NEW YORK ACADEMY OF SCIENCES
LA English
DT Article
DE infant development; perceptual narrowing; rhythm perception; music
   enculturation; neural oscillations; nonlinear oscillators
ID 1ST YEAR; NEURONAL ENTRAINMENT; ADULTS PERCEPTION; SPEECH-PERCEPTION;
   BEAT; METER; EXPERIENCE; COMPLEXITY; LANGUAGE
AB Previous research suggests that infants' perception of musical rhythm is fine-tuned to culture-specific rhythmic structures over the first postnatal year of human life. To date, however, little is known about the neurobiological principles that may underlie this process. In the current study, we used a dynamical systems model featuring neural oscillation and Hebbian plasticity to simulate infants' perceptual learning of culture-specific musical rhythms. First, we demonstrate that oscillatory activity in an untrained network reflects the rhythmic structure of either a Western or a Balkan training rhythm in a veridical fashion. Next, during a period of unsupervised learning, we show that the network learns the rhythmic structure of either a Western or a Balkan training rhythm through the self-organization of network connections. Finally, we demonstrate that the learned connections affect the networks' response to violations to the metrical structure of native and nonnative rhythms, a pattern of findings that mirrors the behavioral data on infants' perceptual narrowing to musical rhythms.
C1 [Tichko, Parker] Univ Connecticut, Dev Div, Dept Psychol Sci, Coll Liberal Arts & Sci, Storrs, CT 06269 USA.
   [Large, Edward W.] Univ Connecticut, Dept Psychol Sci, Percept Act Cognit PAC Div, Storrs, CT 06269 USA.
   [Large, Edward W.] Univ Connecticut, CESPA, Dept Psychol Sci, Storrs, CT 06269 USA.
   [Large, Edward W.] Univ Connecticut, Dept Phys, Storrs, CT 06269 USA.
RP Large, EW (corresponding author), Univ Connecticut, Percept Act Cognit PAC Div, Dept Psychol Sci, Coll Liberal Arts & Sci, 406 Babbidge Rd,Unit 1020, Storrs, CT 06269 USA.
EM edward.large@uconn.edu
OI Tichko, Parker/0000-0002-4958-8955
FU NSF IGERTNational Science Foundation (NSF) [DGE-1144399] Funding Source:
   Medline
CR Baker SA, 2006, LANG LEARN DEV, V2, P147, DOI 10.1207/s15473341lld0203_1
   Balas B, 2012, DEVELOPMENTAL SCI, V15, P579, DOI 10.1111/j.1467-7687.2012.01154.x
   Cirelli LK, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00229
   Flom R, 2014, DEV PSYCHOBIOL, V56, P1442, DOI 10.1002/dev.21238
   Friendly RH, 2014, DEV PSYCHOBIOL, V56, P228, DOI 10.1002/dev.21164
   Friendly RH, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00718
   Fujioka T, 2009, ANN NY ACAD SCI, V1169, P89, DOI 10.1111/j.1749-6632.2009.04779.x
   Gerry DW, 2010, DEVELOPMENTAL SCI, V13, P545, DOI 10.1111/j.1467-7687.2009.00912.x
   Gottlieb G, 2007, DEVELOPMENTAL SCI, V10, P1, DOI 10.1111/j.1467-7687.2007.00556.x
   Grahn JA, 2013, CEREB CORTEX, V23, P913, DOI 10.1093/cercor/bhs083
   Grahn JA, 2009, J NEUROSCI, V29, P7540, DOI 10.1523/JNEUROSCI.2018-08.2009
   GREENOUGH WT, 1987, CHILD DEV, V58, P539, DOI 10.2307/1130197
   Hannon EE, 2005, P NATL ACAD SCI USA, V102, P12639, DOI 10.1073/pnas.0504254102
   Hannon EE, 2005, COGNITIVE PSYCHOL, V50, P354, DOI 10.1016/j.cogpsych.2004.09.003
   Hannon EE, 2005, PSYCHOL SCI, V16, P48, DOI 10.1111/j.0956-7976.2005.00779.x
   Hannon EE, 2012, J EXP PSYCHOL HUMAN, V38, P543, DOI 10.1037/a0027225
   Hannon EE, 2012, ANN NY ACAD SCI, V1252, P92, DOI 10.1111/j.1749-6632.2012.06466.x
   Hannon EE, 2011, DEVELOPMENTAL SCI, V14, P865, DOI 10.1111/j.1467-7687.2011.01036.x
   Honing H, 2009, ANN NY ACAD SCI, V1169, P93, DOI 10.1111/j.1749-6632.2009.04761.x
   Hoppensteadt FC, 1996, BIOL CYBERN, V75, P129, DOI 10.1007/s004220050280
   Ilari B, 2015, J RES MUSIC EDUC, V62, P332, DOI 10.1177/0022429414555984
   Iversen JR, 2009, ANN NY ACAD SCI, V1169, P58, DOI 10.1111/j.1749-6632.2009.04579.x
   Jacoby N, 2017, CURR BIOL, V27, P359, DOI 10.1016/j.cub.2016.12.031
   Kim JC, 2019, PHYS REV E, V99, DOI 10.1103/PhysRevE.99.022421
   Kim JC, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00152
   Large EW, 2015, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00159
   Large EW, 2010, PHYSICA D, V239, P905, DOI 10.1016/j.physd.2009.11.015
   Large EW, 2009, ANN NY ACAD SCI, V1169, P46, DOI 10.1111/j.1749-6632.2009.04550.x
   Lewkowicz DJ, 2014, DEV PSYCHOBIOL, V56, P292, DOI 10.1002/dev.21197
   Lewkowicz DJ, 2006, P NATL ACAD SCI USA, V103, P6771, DOI 10.1073/pnas.0602027103
   LYNCH MP, 1990, PSYCHOL SCI, V1, P272, DOI 10.1111/j.1467-9280.1990.tb00213.x
   LYNCH MP, 1992, PERCEPT PSYCHOPHYS, V52, P599, DOI 10.3758/BF03211696
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   McAuley JD, 2006, J EXP PSYCHOL GEN, V135, P348, DOI 10.1037/0096-3445.135.3.348
   Miller DB, 2007, DEV PSYCHOBIOL, V49, P770, DOI 10.1002/dev.20269
   Nozaradan S, 2012, J NEUROSCI, V32, P17572, DOI 10.1523/JNEUROSCI.3203-12.2012
   Nozaradan S, 2011, J NEUROSCI, V31, P10234, DOI 10.1523/JNEUROSCI.0411-11.2011
   Palmer SB, 2012, CHILD DEV, V83, P543, DOI 10.1111/j.1467-8624.2011.01715.x
   Pascalis O, 2005, P NATL ACAD SCI USA, V102, P5297, DOI 10.1073/pnas.0406627102
   Pascalis O, 2002, SCIENCE, V296, P1321, DOI 10.1126/science.1070223
   Phillips-Silver J, 2005, SCIENCE, V308, P1430, DOI 10.1126/science.1110922
   Phillips-Silver J, 2007, COGNITION, V105, P533, DOI 10.1016/j.cognition.2006.11.006
   Polak R, 2018, MUSIC PERCEPT, V36, P1, DOI 10.1525/MP.2018.36.1.1
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Rimmele JM, 2018, TRENDS COGN SCI, V22, P870, DOI 10.1016/j.tics.2018.08.003
   Scott LS, 2009, PSYCHOL SCI, V20, P676, DOI 10.1111/j.1467-9280.2009.02348.x
   Snyder JS, 2005, COGNITIVE BRAIN RES, V24, P117, DOI 10.1016/j.cogbrainres.2004.12.014
   Soley G, 2010, DEV PSYCHOL, V46, P286, DOI 10.1037/a0017555
   Stefanics G, 2010, J NEUROSCI, V30, P13578, DOI 10.1523/JNEUROSCI.0703-10.2010
   Trehub SE, 2009, CORTEX, V45, P110, DOI 10.1016/j.cortex.2008.05.012
   Turvey MT, 2017, PSYCHON B REV, V24, P1597, DOI 10.3758/s13423-016-1223-2
   Ullal-Gupta S, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00048
   Van Geert P, 2003, HANDBOOK OF DEVELOPMENTAL PSYCHOLOGY, P640
   van Geert P., 1994, DYNAMIC SYSTEMS DEV
   VELASCO M. J., 2011, P 12 ANN C INT SOC M, P185
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Will U, 2007, NEUROSCI LETT, V424, P55, DOI 10.1016/j.neulet.2007.07.036
   Winkler I, 2009, P NATL ACAD SCI USA, V106, P2468, DOI 10.1073/pnas.0809035106
   Zentner M, 2010, P NATL ACAD SCI USA, V107, P5768, DOI 10.1073/pnas.1000121107
   Zhao TC, 2016, P NATL ACAD SCI USA, V113, P5212, DOI 10.1073/pnas.1603984113
NR 61
TC 3
Z9 3
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0077-8923
EI 1749-6632
J9 ANN NY ACAD SCI
JI Ann. N.Y. Acad. Sci.
PD OCT
PY 2019
VL 1453
IS 1
SI SI
BP 125
EP 139
DI 10.1111/nyas.14050
PG 15
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA JB1XN
UT WOS:000488353800010
PM 31021447
DA 2021-02-24
ER

PT J
AU Hong, T
   Wang, JJ
   Zhang, LJ
   Zhang, Y
   Shu, H
   Li, P
AF Hong, Tian
   Wang, Jiuju
   Zhang, Linjun
   Zhang, Yang
   Shu, Hua
   Li, Ping
TI Age-sensitive associations of segmental and suprasegmental perception
   with sentence-level language skills in Mandarin-speaking children with
   cochlear implants
SO RESEARCH IN DEVELOPMENTAL DISABILITIES
LA English
DT Article
DE Cochlear implant; Mandarin-speaking children; Speech perception;
   Sentence repetition
ID 1-YEAR FOLLOW-UP; SPEECH RECOGNITION; CATEGORICAL PERCEPTION; TONE
   PERCEPTION; LEXICAL TONES; ACQUISITION; CONSONANTS; PERFORMANCE;
   PERIODS; VOWELS
AB Background and aim: It remains unclear how recognition of segmental and suprasegmental phonemes contributes to sentence-level language processing skills in Mandarin-speaking children with cochlear implants (CIs). Our study examined the influence of implantation age on the recognition of consonants, lexical tones and sentences respectively, and more importantly, the contribution of phonological skills to sentence repetition accuracy in Mandarin-speaking children with CIs.
   Methods: The participants were three groups of prelingually deaf children who received cochlear implants at various ages and their age-matched controls with normal hearing. Three tasks were administered to assess their consonant perception, lexical tone recognition and language skills in open-set sentence repetition.
   Results: Children with CIs lagged behind NH peers in all the three tests, and performances on segmental, suprasegmental and sentence-level processing were differentially modulated by implantation age. Furthermore, performances on recognition of consonants and lexical tones were significant predictors of sentence repetition accuracy in the children with CIs.
   Conclusion: Overall, segmental and suprasegmental perception as well as sentence-level processing is impaired in Mandarin-speaking children with CIs compared with age-matched children with NH. In children with CIs recognition of segmental and suprasegmental phonemes at the lower level predicts sentence repetition accuracy at the higher level. More importantly, implantation age plays an important role in the development of phonological skills and higher-order language skills, suggesting that age-appropriate aural rehabilitation and speech intervention programs need to be developed in order to better help CI users who receive CIs at different ages.
C1 [Hong, Tian; Shu, Hua] Beijing Normal Univ, Natl Key Lab Cognit Neurosci & Learning & IRD, McGovern Inst Brain Res, Beijing, Peoples R China.
   [Wang, Jiuju] Peking Univ, Hosp 6, Beijing, Peoples R China.
   [Zhang, Linjun] Beijing Language & Culture Univ, Beijing Adv Innovat Ctr Language Resources, 15 Xueyuan Rd, Beijing 100083, Peoples R China.
   [Zhang, Linjun] Beijing Language & Culture Univ, Coll Adv Chinese Training, 15 Xueyuan Rd, Beijing 100083, Peoples R China.
   [Zhang, Yang] Univ Minnesota, Dept Speech Language Hearing Sci, Minneapolis, MN USA.
   [Zhang, Yang] Univ Minnesota, Ctr Neurobehav Dev, Minneapolis, MN USA.
   [Li, Ping] Penn State Univ, Dept Psychol, University Pk, PA 16802 USA.
   [Li, Ping] Penn State Univ, Ctr Brain Behav & Cognit, University Pk, PA 16802 USA.
RP Shu, H (corresponding author), Beijing Normal Univ, Natl Key Lab Cognit Neurosci & Learning & IRD, McGovern Inst Brain Res, Beijing, Peoples R China.; Zhang, LJ (corresponding author), Beijing Language & Culture Univ, Beijing Adv Innovat Ctr Language Resources, 15 Xueyuan Rd, Beijing 100083, Peoples R China.; Zhang, LJ (corresponding author), Beijing Language & Culture Univ, Coll Adv Chinese Training, 15 Xueyuan Rd, Beijing 100083, Peoples R China.
EM zhanglinjun75@gmail.com; shuhua@bnu.edu.cn
RI Zhang, Yang/Q-1780-2015
OI Zhang, Yang/0000-0001-6777-3487
FU Social Science Fund of Beijing [17YYA004]; Science Foundation of Beijing
   Language and Culture University (Fundamental Research Funds for the
   Central Universities) [18PT09]; Natural Science Foundation of
   ChinaNational Natural Science Foundation of China (NSFC) [31671126]
FX This research was supported by the Social Science Fund of Beijing
   (17YYA004), the Science Foundation of Beijing Language and Culture
   University (Fundamental Research Funds for the Central Universities)
   (18PT09) and Natural Science Foundation of China (31671126).
CR Bruer JT, 2001, CRITICAL THINKING CR, P3
   Coene M, 2011, LANG COGNITIVE PROC, V26, P1083, DOI 10.1080/01690965.2010.520540
   Eisenberg LS, 2006, AUDIOL NEURO-OTOL, V11, P259, DOI 10.1159/000093302
   Goswami U., 1990, PHONOLOGICAL SKILLS
   Han DM, 2009, EAR HEARING, V30, P169, DOI 10.1097/AUD.0b013e31819342cf
   Hua Z, 2000, J CHILD LANG, V27, P3, DOI 10.1017/S030500099900402X
   Klem M, 2015, DEVELOPMENTAL SCI, V18, P146, DOI 10.1111/desc.12202
   Koerner TK, 2018, HEARING RES, V370, P130, DOI 10.1016/j.heares.2018.10.009
   Lenneberg E. H., 1967, BIOL FDN LANGUAGE, V68
   LI CN, 1977, J CHILD LANG, V4, P185, DOI 10.1017/S0305000900001598
   Lin YS, 2003, ACTA OTO-LARYNGOL, V123, P1046, DOI 10.1080/00016480410016171
   Liu QY, 2013, OTOL NEUROTOL, V34, P471, DOI 10.1097/MAO.0b013e318286836b
   Miller SE, 2016, J SPEECH LANG HEAR R, V59, P90, DOI 10.1044/2015_JSLHR-H-15-0154
   Moog J.S., 1990, EARLY SPEECH PERCEPT
   NEVILLE HJ, 1992, CEREB CORTEX, V2, P244, DOI 10.1093/cercor/2.3.244
   Osberger MJ, 1998, AM J OTOL, V19, P152
   Patel A. D., 2010, PROC SPEECH PROSODY, P11
   Peng SC, 2004, EAR HEARING, V25, P251, DOI 10.1097/01.AUD.0000130797.73809.40
   Percy-Smith L, 2013, INT J PEDIATR OTORHI, V77, P184, DOI 10.1016/j.ijporl.2012.10.014
   Pinheiro J., 2016, COMPUTER SOFTWARE, V3, P1, DOI DOI 10.1016/J.CR0PR0.2007.08.015
   Polisenska K, 2015, INT J LANG COMM DIS, V50, P106, DOI 10.1111/1460-6984.12126
   R Core Team, 2014, R LANG ENV STAT COMP
   Robbins AM, 2004, ARCH OTOLARYNGOL, V130, P570
   Ruben RJ, 1997, ACTA OTO-LARYNGOL, V117, P202, DOI 10.3109/00016489709117769
   Sarant JZ, 2001, EAR HEARING, V22, P18, DOI 10.1097/00003446-200102000-00003
   Scovel T., 1988, TIME SPEAK PSYCHOLIN
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   SHEN XNS, 1991, LANG SPEECH, V34, P145, DOI 10.1177/002383099103400202
   Singh L, 2016, CHILD DEV, V87, P834, DOI 10.1111/cdev.12512
   Singh L, 2015, COGNITION, V142, P1, DOI 10.1016/j.cognition.2015.05.010
   Smith G. N., 2018, EAR HEARING
   To CKS, 2013, J SPEECH LANG HEAR R, V56, P103, DOI 10.1044/1092-4388(2012/11-0080)
   Wang JJ, 2013, J ACOUST SOC AM, V134, pEL91, DOI 10.1121/1.4811159
   Wang WQ, 2011, INT J AUDIOL, V50, P270, DOI 10.3109/14992027.2010.542490
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   Wewalaarachchi TD, 2017, J EXP CHILD PSYCHOL, V159, P16, DOI 10.1016/j.jecp.2017.01.009
   Wong P, 2013, J ACOUST SOC AM, V133, P434, DOI 10.1121/1.4768883
   Xi J, 2010, NEUROSCIENCE, V170, P223, DOI 10.1016/j.neuroscience.2010.06.077
   Xu GQ, 2013, NEUROPSYCHOLOGIA, V51, P550, DOI 10.1016/j.neuropsychologia.2012.12.006
   Xu L, 2011, ACTA OTO-LARYNGOL, V131, P395, DOI 10.3109/00016489.2010.536993
   Yu LD, 2015, J AUTISM DEV DISORD, V45, P3656, DOI 10.1007/s10803-015-2510-x
   Zhang Hua, 2005, Zhonghua Er Bi Yan Hou Tou Jing Wai Ke Za Zhi, V40, P774
   Zhang YJ, 2012, J CHILD PSYCHOL PSYC, V53, P874, DOI 10.1111/j.1469-7610.2012.02528.x
   Zheng Y, 2011, INT J PEDIATR OTORHI, V75, P1418, DOI 10.1016/j.ijporl.2011.08.005
   Zhou N, 2013, OTOL NEUROTOL, V34, P499, DOI 10.1097/MAO.0b013e318287ca86
   Zhu MM, 2011, INT J PEDIATR OTORHI, V75, P793, DOI 10.1016/j.ijporl.2011.03.009
   Zwolan TA, 2004, OTOL NEUROTOL, V25, P112, DOI 10.1097/00129492-200403000-00006
NR 47
TC 2
Z9 2
U1 1
U2 9
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0891-4222
J9 RES DEV DISABIL
JI Res. Dev. Disabil.
PD OCT
PY 2019
VL 93
AR 103453
DI 10.1016/j.ridd.2019.103453
PG 8
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA IY1FL
UT WOS:000486136900004
PM 31421305
DA 2021-02-24
ER

PT J
AU Porretta, V
   Kyrolainen, AJ
AF Porretta, Vincent
   Kyrolainen, Aki-Juhani
TI Influencing the Time and Space of Lexical Competition: The Effect of
   Gradient Foreign Accentedness
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION
LA English
DT Article
DE foreign accentedness; intelligibility; lexical competition; visual world
   eye-tracking
ID SPOKEN-WORD RECOGNITION; NEIGHBORHOOD ACTIVATION; SPEECH-PERCEPTION;
   BACKGROUND-NOISE; PROCESSING TIME; INFORMATION; ADAPTATION; LANGUAGE;
   TRACKING; MODEL
AB This article examines the influence of gradient foreign accentedness on lexical competition during spoken word recognition. Using native and Mandarin-accented English words ranging in degree of foreign accentedness, we investigate the effect of increased accentedness on (a) the size of the competitor space and (b) the strength and duration of competitor activation. Here, we analyze the number of misperceptions in a transcription task, as well as the time course of competitor activation in a Visual World Paradigm eye-tracking task. The transcription data show that as accentedness increases, the number of unique misperceptions increases. This indicates that greater accent strength induces the activation of many additional competitors within the competition space relative to native speech. The eye-tracking data further show that, as accentedness increases, looks to competitors (not produced in the transcription task) increase both in likelihood and duration. This indicates that greater accentedness boosts the strength of competitor activation as well as the duration of the competition process, even when comprehension is ultimately successful, suggesting strong and diffuse competition within the lexicon. The results provide evidence of changes in the underlying dynamics, which lead to the pervasive processing costs associated with foreign-accented speech that are commonly observed in behavioral data.
C1 [Porretta, Vincent] Univ Windsor, Dept Psychol, Chrysler Hall South,Room 173,401 Sunset Ave, Windsor, ON N9B 3P4, Canada.
   [Kyrolainen, Aki-Juhani] McMaster Univ, Dept Linguist & Languages, Hamilton, ON, Canada.
   [Kyrolainen, Aki-Juhani] Brock Univ, Dept Appl Linguist, St Catharines, ON, Canada.
RP Porretta, V (corresponding author), Univ Windsor, Dept Psychol, Chrysler Hall South,Room 173,401 Sunset Ave, Windsor, ON N9B 3P4, Canada.
EM porretta@uwindsor.ca
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Baayen H, 2017, J MEM LANG, V94, P206, DOI 10.1016/j.jml.2016.11.006
   Baayen RH, 2010, MENT LEX, V5, P436, DOI 10.1075/ml.5.3.10baa
   Baayen RH., 2008, ANAL LINGUISTIC DATA, DOI [10.1017/CBO9780511801686, DOI 10.1017/CBO9780511801686]
   BAAYEN RH, 2010, LINGUISTISCHE BERICH, V17, P383
   Balota DA, 2007, BEHAV RES METHODS, V39, P445, DOI 10.3758/BF03193014
   Balota DA, 2012, CUR ISS PSYCHOL LANG, P90
   Barr DJ, 2008, J MEM LANG, V59, P457, DOI 10.1016/j.jml.2007.09.002
   Ben-David BM, 2011, J SPEECH LANG HEAR R, V54, P243, DOI 10.1044/1092-4388(2010/09-0233)
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Brouwer S, 2016, J PSYCHOLINGUIST RES, V45, P1151, DOI 10.1007/s10936-015-9396-9
   Chan KY, 2015, J EXP PSYCHOL HUMAN, V41, P69, DOI 10.1037/a0038347
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   COOPER RM, 1974, COGNITIVE PSYCHOL, V6, P84, DOI 10.1016/0010-0285(74)90005-X
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750
   Dahan D, 2008, COGNITION, V108, P710, DOI 10.1016/j.cognition.2008.06.003
   Davies M., 2008, CORPUS CONT AM ENGLI
   Efron B., 1993, INTRO BOOTSTRAP
   Fischer B., 1992, EYE MOVEMENTS VISUAL, P31
   Goslin J, 2012, BRAIN LANG, V122, P92, DOI 10.1016/j.bandl.2012.04.017
   Hintz F, 2016, INTERSPEECH, P2816, DOI 10.21437/Interspeech.2016-882
   Huettig F, 2007, J MEM LANG, V57, P460, DOI 10.1016/j.jml.2007.02.001
   Idemaru K, 2011, J EXP PSYCHOL HUMAN, V37, P1939, DOI 10.1037/a0025641
   Johnson K, 2006, J PHONETICS, V34, P485, DOI 10.1016/j.wocn.2005.08.004
   Kraljic T, 2008, PSYCHOL SCI, V19, P332, DOI 10.1111/j.1467-9280.2008.02090.x
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   MATIN E, 1993, PERCEPT PSYCHOPHYS, V53, P372, DOI 10.3758/BF03206780
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McQueen J., 2007, OXFORD HDB PSYCHOLIN, P37, DOI DOI 10.1093/0XF0RDHB/9780198568971.013.0003
   McQueen JM, 2007, Q J EXP PSYCHOL, V60, P661, DOI 10.1080/17470210601183890
   Munro MJ, 1995, LANG SPEECH, V38, P289, DOI 10.1177/002383099503800305
   MUNRO MJ, 1993, LANG SPEECH, V36, P39, DOI 10.1177/002383099303600103
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Pinheiro J., 2000, MIXED EFFECTS MODELS
   Piske T, 2001, J PHONETICS, V29, P191, DOI 10.1006/jpho.2001.0134
   Porretta V., 2016, VWPRE TOOLS PREPROCE
   Porretta V, 2018, SMART INNOV SYST TEC, V73, P268, DOI 10.1007/978-3-319-59424-8_25
   Porretta V, 2017, J NEUROLINGUIST, V44, P54, DOI 10.1016/j.jneuroling.2017.03.002
   Porretta V, 2016, J PHONETICS, V58, P1, DOI 10.1016/j.wocn.2016.05.006
   Porretta V, 2015, ATTEN PERCEPT PSYCHO, V77, P2438, DOI 10.3758/s13414-015-0916-3
   R Development Core Team, 2016, R LANG ENV STAT COMP
   Reinisch E, 2012, J ACOUST SOC AM, V132, P1165, DOI 10.1121/1.4730884
   SCHARENBORG O, 2012, INTERSPEECH 2012 13, P882
   Scharenborg O, 2018, J EXP PSYCHOL LEARN, V44, P233, DOI 10.1037/xlm0000441
   Scharenborg O, 2010, J ACOUST SOC AM, V127, P3758, DOI 10.1121/1.3377050
   Seidl A, 2012, FRONT PSYCHOL, V3, DOI [10.3389/fpsyg.2012.00448, 10.3389/fpsyg.2012.00479]
   Speelman D, 2018, QUANT METH HUMAN SOC, P1, DOI 10.1007/978-3-319-69830-4
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Tremblay A, 2015, PSYCHOPHYSIOLOGY, V52, P124, DOI 10.1111/psyp.12299
   Trude AM, 2013, J MEM LANG, V69, P349, DOI 10.1016/j.jml.2013.05.002
   Tucker B. V., 2015, P 18 INT C PHON SCI, P1
   Van Engen KJ, 2018, HEARING RES, V369, P56, DOI 10.1016/j.heares.2018.04.013
   Van Engen KJ, 2010, LANG SPEECH, V53, P510, DOI 10.1177/0023830910372495
   van Rij J., 2015, ITSADUG INTERPRETING
   van Rij J., 2016, EMPIRICAL PERSPECTIV, V277, P267
   Vitevitch MS, 1999, J MEM LANG, V40, P374, DOI 10.1006/jmla.1998.2618
   Weber A, 2012, WIRES COGN SCI, V3, P387, DOI 10.1002/wcs.1178
   Witteman MJ, 2013, ATTEN PERCEPT PSYCHO, V75, P537, DOI 10.3758/s13414-012-0404-y
   Wood, 2016, MGCV MIXED GAM COMPU
   Wood SN., 2017, GEN ADDITIVE MODELS
   Zuur Alain F., 2009, P1
NR 62
TC 1
Z9 1
U1 0
U2 3
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0278-7393
EI 1939-1285
J9 J EXP PSYCHOL LEARN
JI J. Exp. Psychol.-Learn. Mem. Cogn.
PD OCT
PY 2019
VL 45
IS 10
BP 1832
EP 1851
DI 10.1037/xlm0000674
PG 20
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6WJ
UT WOS:000485123700008
PM 30816767
DA 2021-02-24
ER

PT J
AU McMurray, B
   Klein-Packard, J
   Tomblin, JB
AF McMurray, Bob
   Klein-Packard, Jamie
   Tomblin, J. Bruce
TI A real-time mechanism underlying lexical deficits in developmental
   language disorder: Between-word inhibition
SO COGNITION
LA English
DT Article
DE Developmental Language Disorder; Specific language impairment; Word
   recognition; Inhibition
ID INDIVIDUAL-DIFFERENCES; SPOKEN WORDS; SENTENCE COMPREHENSION; CORTICAL
   ORGANIZATION; SPEECH-PERCEPTION; ORAL LANGUAGE; CHILDREN; IMPAIRMENT;
   RECOGNITION; MODEL
AB Eight to 11% of children have a clinical disorder in oral language (Developmental Language Disorder, DLD). Language deficits in DLD can affect all levels of language and persist through adulthood. Word-level processing may be critical as words link phonology, orthography, syntax and semantics. Thus, a lexical deficit could cascade throughout language. Cognitively, word recognition is a competition process: as the input (e.g., lizard) unfolds, multiple candidates (liver, wizard) compete for recognition. Children with DLD do not fully resolve this competition, but it is unclear what cognitive mechanisms underlie this. We examined lexical inhibition-the ability of more active words to suppress competitors-in 79 adolescents with and without DLD. Participants heard words (e.g. net) in which the onset was manipulated to briefly favor a competitor (neck). This was predicted to inhibit the target, slowing recognition. Word recognition was measured using a task in which participants heard the stimulus, and clicked on a picture of the item from an array of competitors, while eye-movements were monitored as a measure of how strongly the participant was committed to that interpretation over time. TD listeners showed evidence of inhibition with greater interference for stimuli that briefly activated a competitor word. DLD listeners did not. This suggests deficits in DLD may stem from a failure to engage lexical inhibition. This in turn could have ripple effects throughout the language system. This supports theoretical approaches to DLD that emphasize lexical-level deficits, and deficits in real-time processing.
C1 [McMurray, Bob; Klein-Packard, Jamie] Univ Iowa, Dept Psychol & Brain Sci, W311 SSH, Iowa City, IA 52242 USA.
   [McMurray, Bob; Tomblin, J. Bruce] Univ Iowa, Dept Commun Sci & Disorders, Iowa City, IA 52242 USA.
   [McMurray, Bob] Univ Iowa, Dept Linguist, Iowa City, IA 52242 USA.
   [McMurray, Bob] Univ Iowa, Dept Otolaryngol, Iowa City, IA 52242 USA.
   [McMurray, Bob; Tomblin, J. Bruce] Univ Iowa, DeLTA Ctr, Iowa City, IA 52242 USA.
RP McMurray, B (corresponding author), Univ Iowa, Dept Psychol & Brain Sci, W311 SSH, Iowa City, IA 52242 USA.
EM Bob-mcmurray@uiowa.edu
OI McMurray, Bob/0000-0002-6532-284X
FU NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [DC008089]; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC008089] Funding Source: NIH RePORTER
FX The authors would like to thank Effie Kapnoula for assistance generating
   the stimulus, Marlea O'Brien for coordinating subject recruitment,
   Joanna Lee, Wendy Fick, Claire Goodwin, and Tyler Ellis for assistance
   with subject recruitment and assessment. This research was supported by
   NIDCD grant DC008089 awarded to BM. The data and R scripts used for
   analysis are available on a permanent third-party archive at
   https://osf.io/kfwxu/.
CR Apfelbaum KS, 2017, COGNITIVE SCI, V41, P706, DOI 10.1111/cogs.12401
   Apfelbaum KS, 2011, PSYCHON B REV, V18, P141, DOI 10.3758/s13423-010-0039-8
   Barkley RA., 2012, EXECUTIVE FUNCTIONS
   Bishop DVM, 2008, GENES BRAIN BEHAV, V7, P365, DOI 10.1111/j.1601-183X.2007.00360.x
   Bishop DVM, 2005, APPL PSYCHOLINGUIST, V26, P175, DOI 10.1017/S0142716405050137
   Blomquist C., WAR WORDS DEV UNPUB
   Bornstein MH, 2016, DEV PSYCHOL, V52, P704, DOI 10.1037/dev0000111
   Borovsky A, 2013, J COMMUN DISORD, V46, P413, DOI 10.1016/j.jcomdis.2013.09.001
   Castles A, 2007, J EXP CHILD PSYCHOL, V97, P165, DOI 10.1016/j.jecp.2007.01.006
   Clegg J, 2005, J CHILD PSYCHOL PSYC, V46, P128, DOI 10.1111/j.1469-7610.2004.00342.x
   CONNINE CM, 1993, J MEM LANG, V32, P193, DOI 10.1006/jmla.1993.1011
   Conti-Ramsden G, 2012, J SPEECH LANG HEAR R, V55, P1716, DOI 10.1044/1092-4388(2012/10-0182)
   Conti-Ramsden G, 2009, INT J LANG COMM DIS, V44, P15, DOI 10.1080/13682820801921601
   Corriveau K, 2007, J SPEECH LANG HEAR R, V50, P647, DOI 10.1044/1092-4388(2007/046)
   Dahan D, 2001, LANG COGNITIVE PROC, V16, P507, DOI 10.1080/01690960143000074
   Dahan D., 2006, HDB PSYCHOLINGUISTIC, P249, DOI DOI 10.1016/B978-012369374-7/50009-2
   Davis CJ, 2006, J EXP PSYCHOL HUMAN, V32, P668, DOI 10.1037/0096-1523.32.3.668
   Davis MH, 2009, PHILOS T R SOC B, V364, P3773, DOI 10.1098/rstb.2009.0111
   Dennis M, 2009, J INT NEUROPSYCH SOC, V15, P331, DOI 10.1017/S1355617709090481
   Dollaghan C, 1998, APPL PSYCHOLINGUIST, V19, P193, DOI 10.1017/S0142716400010031
   Dumay N, 2007, PSYCHOL SCI, V18, P35, DOI 10.1111/j.1467-9280.2007.01845.x
   Dunn D. M., 2007, PEABODY PICTURE VOCA
   Eisenreich BR, 2017, J COGNITIVE NEUROSCI, V29, P1684, DOI 10.1162/jocn_a_01139
   Fernandes T, 2009, COGNITION, V112, P349, DOI 10.1016/j.cognition.2009.05.002
   Gow DW, 2012, BRAIN LANG, V121, P273, DOI 10.1016/j.bandl.2012.03.005
   GOW DW, 1995, J EXP PSYCHOL HUMAN, V21, P344, DOI 10.1037/0096-1523.21.2.344
   Grube M, 2012, P ROY SOC B-BIOL SCI, V279, P4496, DOI 10.1098/rspb.2012.1817
   Hannagan T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00563
   Hedenius M, 2011, RES DEV DISABIL, V32, P2362, DOI 10.1016/j.ridd.2011.07.026
   Helenius P, 2009, BRAIN, V132, P1918, DOI 10.1093/brain/awp134
   Henry LA, 2012, J CHILD PSYCHOL PSYC, V53, P37, DOI 10.1111/j.1469-7610.2011.02430.x
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hsu HJ, 2014, DEVELOPMENTAL SCI, V17, P352, DOI 10.1111/desc.12125
   Kapnoula EC, 2016, PSYCHON B REV, V23, P491, DOI 10.3758/s13423-015-0897-1
   Kapnoula EC, 2016, J EXP PSYCHOL GEN, V145, P8, DOI 10.1037/xge0000123
   Kapnoula EC, 2015, COGNITION, V134, P85, DOI 10.1016/j.cognition.2014.09.007
   Lee JC, 2013, NEUROPSYCHOLOGIA, V51, P2154, DOI 10.1016/j.neuropsychologia.2013.07.011
   Leonard C, 2006, BRAIN, V129, P3329, DOI 10.1093/brain/awl262
   Levy R, 2009, P NATL ACAD SCI USA, V106, P21086, DOI 10.1073/pnas.0907664106
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Luce PA, 1998, PERCEPT PSYCHOPHYS, V60, P484, DOI 10.3758/BF03206868
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676
   Magnuson JS, 2007, COGNITIVE SCI, V31, P133, DOI 10.1080/03640210709336987
   Mainela-Arnold E, 2008, J SPEECH LANG HEAR R, V51, P381, DOI 10.1044/1092-4388(2008/028)
   Malins JG, 2013, DEV COGN NEUROS-NETH, V5, P134, DOI 10.1016/j.dcn.2013.02.005
   Markram H., 2004, NATURE REV NEUROSCIE, V5
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McGregor K. K., 2013, INT J LANGUAGE COMMU
   McMurray B, 2018, DEV PSYCHOL, V54, P1472, DOI 10.1037/dev0000542
   McMurray B, 2017, CUR ISS PSYCHOL LANG, P116
   McMurray B, 2014, J SPEECH LANG HEAR R, V57, P1344, DOI 10.1044/2014_JSLHR-L-13-0196
   McMurray B, 2012, PSYCHOL REV, V119, P831, DOI 10.1037/a0029872
   McMurray B, 2010, COGNITIVE PSYCHOL, V60, P1, DOI 10.1016/j.cogpsych.2009.06.003
   McMurray B, 2009, DEVELOPMENTAL SCI, V12, P369, DOI 10.1111/j.1467-7687.2009.00822.x
   Miller CA, 2001, J SPEECH LANG HEAR R, V44, P416, DOI 10.1044/1092-4388(2001/034)
   Miyake A, 2000, COGNITIVE PSYCHOL, V41, P49, DOI 10.1006/cogp.1999.0734
   Montgomery JW, 2002, APPL PSYCHOLINGUIST, V23, P447, DOI 10.1017/S0142716402003077
   Munakata Y, 2011, TRENDS COGN SCI, V15, P453, DOI 10.1016/j.tics.2011.07.011
   Nation K, 2003, J EXP CHILD PSYCHOL, V86, P314, DOI 10.1016/j.jecp.2003.09.001
   Nation K, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0387
   Norbury CF, 2005, J EXP CHILD PSYCHOL, V90, P142, DOI 10.1016/j.jecp.2004.11.003
   Norbury CF, 2016, J CHILD PSYCHOL PSYC, V57, P1247, DOI 10.1111/jcpp.12573
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Obeid R, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01245
   Oleson JJ, 2017, STAT METHODS MED RES, V26, P2708, DOI 10.1177/0962280215607411
   Pennington BF, 2009, ANNU REV PSYCHOL, V60, P283, DOI 10.1146/annurev.psych.60.110707.163548
   Raaijmakers JGW, 1999, J MEM LANG, V41, P416, DOI 10.1006/jmla.1999.2650
   Rapp B, 2000, PSYCHOL REV, V107, P460, DOI 10.1037/0033-295X.107.3.460
   Rice ML, 2015, J SPEECH LANG HEAR R, V58, P345, DOI 10.1044/2015_JSLHR-L-14-0150
   Rigler H, 2015, DEV PSYCHOL, V51, P1690, DOI 10.1037/dev0000044
   Rosen S, 2003, J PHONETICS, V31, P509, DOI 10.1016/S0095-4470(03)00046-9
   Seedorff M., PSYCHOL METHOD UNPUB
   Seedorff M., J MEMORY LANGUAGE
   Sekerina IA, 2007, J EXP CHILD PSYCHOL, V98, P20, DOI 10.1016/j.jecp.2007.04.005
   Semel E., 2006, CELF 4 CLIN EVALUATI
   Snowling MJ, 2006, J CHILD PSYCHOL PSYC, V47, P759, DOI 10.1111/j.1469-7610.2006.01631.x
   STARK RE, 1995, APPL PSYCHOLINGUIST, V16, P137, DOI 10.1017/S0142716400007050
   TALLAL P, 1973, NEUROPSYCHOLOGIA, V11, P389, DOI 10.1016/0028-3932(73)90025-0
   TALLAL P, 1973, NATURE, V241, P468, DOI 10.1038/241468a0
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Tomblin JB, 2007, LANG LEARN DEV, V3, P269, DOI 10.1080/15475440701377477
   Tomblin JB, 1997, J SPEECH LANG HEAR R, V40, P1245, DOI 10.1044/jslhr.4006.1245
   Toscano JC, 2013, PSYCHON B REV, V20, P981, DOI 10.3758/s13423-013-0417-0
   Ullman MT, 2005, CORTEX, V41, P399, DOI 10.1016/S0010-9452(08)70276-4
   Ullman MT, 2004, COGNITION, V92, P231, DOI 10.1016/j.cognition.2003.10.008
   Usher M, 2001, PSYCHOL REV, V108, P550, DOI 10.1037//0033-295X.108.3.550
   Vandewalle E, 2012, RES DEV DISABIL, V33, P635, DOI 10.1016/j.ridd.2011.11.005
   Verhoeven JS, 2012, CEREB CORTEX, V22, P2263, DOI 10.1093/cercor/bhr292
   Wechsler D, 2011, WASI II WECHSLER ABB
   Williams K., 1997, EXPRESSIVE VOCABULAR
   Zhang XJ, 2018, J MEM LANG, V100, P32, DOI 10.1016/j.jml.2018.01.002
   Zhao LB, 2019, COGNITION, V190, P42, DOI 10.1016/j.cognition.2018.12.004
   ZWITSERLOOD P, 1989, COGNITION, V32, P25, DOI 10.1016/0010-0277(89)90013-9
NR 93
TC 5
Z9 5
U1 3
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD OCT
PY 2019
VL 191
AR 104000
DI 10.1016/j.cognition.2019.06.012
PG 13
WC Psychology, Experimental
SC Psychology
GA IW0LZ
UT WOS:000484654700021
PM 31234114
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Rammell, CS
   Cheng, H
   Pisoni, DB
   Newman, SD
AF Rammell, Charlotte Sophia
   Cheng, Hu
   Pisoni, David B.
   Newman, Sharlene D.
TI L2 speech perception in noise: An fMRI study of advanced Spanish
   learners
SO BRAIN RESEARCH
LA English
DT Article
DE Second language acquisition; Speech in noise; Sentence recognition;
   Speech perception
ID SHORT-TERM-MEMORY; SENTENCE RECOGNITION; ADVERSE CONDITIONS; LANGUAGE
   CONTROL; BILINGUAL BRAIN; HEARING; 1ST; INTELLIGIBILITY; IDENTIFICATION;
   REPRESENTATION
AB This experiment examined the neural correlates of second language (L2) speech perception in noise in advanced Spanish students. Participants completed a speech perception task in quiet and noise in their first language (L1 = English) and L2 during fMR1. Behavioral tests of L2 Spanish sentence recognition confirmed that advanced learners of Spanish can recognize sentences in quiet and in noise with an average of 85.45% and 74.43% accuracy, respectively. While listening to degraded sentences in the L2, both auditory and executive processing regions (specifically those of attention) were activated. While listening to L2 sentences in noise, learners focused on decoding the speech signal at the perceptual level, indicating a bottom-up processing strategy relying heavily on the signal's phonetic detail. During the processing of L1 in noise there was only significant activation in executive processing regions like the cingulate cortex and a region linked to lexical-semantic access (LIFG). In this case, participants appear to use a top-down strategy for sentence recognition, relying on lexical resources using a holistic strategy for perception. These findings suggest that L2 learners use fundamentally different perceptual strategies and neural circuits for understanding speech in noise in their L1 and L2.
C1 [Rammell, Charlotte Sophia] Indiana Univ, Dept Spanish & Portuguese, 355 North Jordan Ave,GISB 2160, Bloomington, IN 47405 USA.
   [Cheng, Hu; Pisoni, David B.; Newman, Sharlene D.] Indiana Univ, Dept Psychol & Brain Sci, 1101 E 10th St, Bloomington, IN 47405 USA.
RP Rammell, CS (corresponding author), Duke Univ, Linguist Program, 306 Languages Bldg, Durham, NC 27708 USA.
EM charlotte.rammell@duke.edu
FU National Institute on Deafness and Communication DisordersUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01 DC-00111, T32 DC-00012]; Indiana University Graduate and
   Professional Student Organization Research Grant; Imaging Research
   Facility at Indiana University [Brain Scan Credit Program]
FX This work was supported by the National Institute on Deafness and
   Communication Disorders [Grant numbers R01 DC-00111, T32 DC-00012
   (Principal Investigator: Dr. David B. Pisoni)]; an Indiana University
   Graduate and Professional Student Organization Research Grant awarded to
   CSR; and the Imaging Research Facility at Indiana University [Brain Scan
   Credit Program].
CR Abutalebi J., 2012, HDB NEUROPSYCHOLOGY, P516, DOI DOI 10.1002/9781118432501.CH25
   Abutalebi J, 2007, J NEUROSCI, V27, P13762, DOI 10.1523/JNEUROSCI.3294-07.2007
   Abutalebi J, 2007, J NEUROLINGUIST, V20, P242, DOI 10.1016/j.jneuroling.2006.10.003
   Abutalebi J, 2009, BRAIN LANG, V109, P141, DOI 10.1016/j.bandl.2009.03.003
   Abutalebi J, 2009, BRAIN LANG, V109, P51, DOI 10.1016/j.bandl.2009.04.001
   Andrews E., 2018, HISP LING S AUST TEX
   Beer Jessica, 2011, Cochlear Implants Int, V12 Suppl 1, pS89, DOI 10.1179/146701011X13001035752570
   Blumenfeld HK, 2011, COGNITION, V118, P245, DOI 10.1016/j.cognition.2010.10.012
   Boersma P., 2018, PRAAT DOING PHONETIC
   Botvinick MM, 2001, PSYCHOL REV, V108, P624, DOI 10.1037//0033-295X.108.3.624
   Braver TS, 2006, TRENDS COGN SCI, V10, P529, DOI 10.1016/j.tics.2006.10.006
   Callan DE, 2004, NEUROIMAGE, V22, P1182, DOI 10.1016/j.neuroimage.2004.03.006
   Crinion J, 2006, SCIENCE, V312, P1537, DOI 10.1126/science.1127761
   de Otero CB, 2008, INT J AUDIOL, V47, P362, DOI 10.1080/14992020802060888
   Erb J, 2013, J NEUROSCI, V33, P10688, DOI 10.1523/JNEUROSCI.4596-12.2013
   European Commission, 2012, 1 EUR SURV LANG COMP
   Foo C, 2007, J AM ACAD AUDIOL, V18, P618, DOI 10.3766/jaaa.18.7.8
   Friederici AD, 2010, HUM BRAIN MAPP, V31, P448, DOI 10.1002/hbm.20878
   Friston KJ, 1995, HUM BRAIN MAPP, V3, P165, DOI 10.1002/hbm.460030303
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Gilbert JL, 2013, J AM ACAD AUDIOL, V24, P26, DOI 10.3766/jaaa.24.1.4
   Heinrich A, 2008, Q J EXP PSYCHOL, V61, P735, DOI 10.1080/17470210701402372
   Hernandez AE, 2000, BRAIN LANG, V73, P421, DOI 10.1006/brln.1999.2278
   Hernandez AE, 2009, BRAIN LANG, V109, P133, DOI 10.1016/j.bandl.2008.12.005
   Hochmuth S, 2012, INT J AUDIOL, V51, P536, DOI 10.3109/14992027.2012.670731
   Huarte A, 2008, INT J AUDIOL, V47, P369, DOI 10.1080/14992020801908269
   Instituto Cervantes, 2008, DIPL ESP COM LENG EX
   Jin SH, 2012, J ACOUST SOC AM, V132, pEL391, DOI 10.1121/1.4757730
   Kotz SA, 2010, TRENDS COGN SCI, V14, P392, DOI 10.1016/j.tics.2010.06.005
   Kotz SA, 2009, CORTEX, V45, P982, DOI 10.1016/j.cortex.2009.02.010
   Leff AP, 2009, BRAIN, V132, P3401, DOI 10.1093/brain/awp273
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Mayo LH, 1997, J SPEECH LANG HEAR R, V40, P686, DOI 10.1044/jslhr.4003.686
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Obleser J., 2009, CEREB CORTEX
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Peelle JE, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00309
   Perani D, 2005, CURR OPIN NEUROBIOL, V15, P202, DOI 10.1016/j.conb.2005.03.007
   Perani D, 1996, NEUROREPORT, V7, P2439, DOI 10.1097/00001756-199611040-00007
   Perani D, 1998, BRAIN, V121, P1841, DOI 10.1093/brain/121.10.1841
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   Pisoni DB, 1996, LANG COGNITIVE PROC, V11, P681, DOI 10.1080/016909696387097
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Price CJ, 2010, ANN NY ACAD SCI, V1191, P62, DOI 10.1111/j.1749-6632.2010.05444.x
   RABBITT PMA, 1968, Q J EXP PSYCHOL, V20, P241, DOI 10.1080/14640746808400158
   Rodriguez-Fornells A, 2006, LANG LEARN, V56, P133, DOI 10.1111/j.1467-9922.2006.00359.x
   Ronnberg J, 2010, NOISE HEALTH, V12, P263, DOI 10.4103/1463-1741.70505
   Sakai KL, 2004, CEREB CORTEX, V14, P1233, DOI 10.1093/cercor/bhh084
   Scott SK, 2013, HEARING RES, V303, P58, DOI 10.1016/j.heares.2013.05.001
   Sebastian R, 2011, APPL PSYCHOLINGUIST, V32, P799, DOI 10.1017/S0142716411000075
   Strait DL, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00113
   Tice R., 1998, LEVEL 16
   Wellcome Trust Centre for Neuroimaging, 2014, STAT PARAMETRIC MAPP, V12
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
NR 55
TC 0
Z9 0
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0006-8993
EI 1872-6240
J9 BRAIN RES
JI Brain Res.
PD OCT 1
PY 2019
VL 1720
AR 146316
DI 10.1016/j.brainres.2019.146316
PG 7
WC Neurosciences
SC Neurosciences & Neurology
GA IW3KJ
UT WOS:000484878600022
PM 31278936
DA 2021-02-24
ER

PT J
AU Mitterer, H
   Kim, S
   Cho, T
AF Mitterer, Holger
   Kim, Sahyang
   Cho, Taehong
TI The glottal stop between segmental and suprasegmental processing: The
   case of Maltese
SO JOURNAL OF MEMORY AND LANGUAGE
LA English
DT Article
DE Prosodic processing; Segmental processing; Glottal stop; Maltese;
   Eye-tracking and gating; Phonemic vs. epenthetic; Spoken word
   recognition
ID SPOKEN WORD RECOGNITION; PHONOLOGICAL VARIATION; SPEECH-PERCEPTION;
   LEXICAL ACCESS; ASSIMILATION; REPRESENTATION; MODEL; BOUNDARIES;
   KNOWLEDGE; TRACKING
AB Many languages mark vowel-initial words with a glottal stop. We show that this occurs in Maltese, even though the glottal stop also occurs as a phoneme in Maltese. As a consequence, words with and without an underlying (phonemic) glottal stop (e.g., a glottal stop-zero minimal pair qal /?a:l/ vs. ghal /a:l/ Engl., 'he said'-'because') can become homophonous in connected speech. We first tested the extent of this phonetic marking of vowel-initial words in a production experiment and found that even in fluent productions, about half of the vowel-initial words are marked with an epenthetic glottal stop. The epenthetic glottal stop is more likely to occur when the preceding word is longer, showing a kind of preboundary lengthening at a phrase-level prosodic boundary. A subsequent perception study (Experiment 2) using a two-alternative forced-choice task with a minimal pair of a glottal stop-initial and a vowel-initial word indicated that listeners are sensitive to the durationally conditioned prosodic context before the test word, and they are more likely to perceive a vowel-initial word when the preceding word is lengthened. An additional eye-tracking study (Experiment 3) using onset-overlap pairs (e.g., qafla /?afla/ - afda, /afda/ -> [?afda], Engl., 'to trust' - 'chord') showed no early influence of prosodic cues on segmental processing. But a gating experiment (Experiment 4) replicated the prosodic effect observed in Experiment 2. Taken together, our results indicate an interaction between prosodic processing and segmental processing that comes into effect relatively late in speech processing.
C1 [Mitterer, Holger] Univ Malta, Dept Cognit Sci, Msida, Malta.
   [Kim, Sahyang] Hongik Univ, Dept English Educ, Seoul, South Korea.
   [Cho, Taehong] Hanyang Univ, Hanyang Inst Phonet & Cognit Sci, Dept English Language & Literature, Seoul 04763, South Korea.
RP Cho, T (corresponding author), Hanyang Univ, Hanyang Inst Phonet & Cognit Sci, Dept English Language & Literature, Seoul 04763, South Korea.
EM tcho@hanyang.ac.kr
RI Mitterer, Holger/D-1908-2010
OI Mitterer, Holger/0000-0003-4318-0032
FU University of Malta Research Grant [CGSRP01-18]; Global Research Network
   program through the Ministry of Education of the Republic of Korea;
   National Research Foundation of KoreaNational Research Foundation of
   Korea [NRF-2016S1A2A2912410]
FX We thank the students at the University of Malta who participated in the
   study. We also thank the editors Kathleen Rastle and Gareth Gaskell, and
   three anonymous reviewers for their insightful and constructive comments
   from which we have benefited greatly in improving the quality of our
   manuscript in various aspects. The work was supported by University of
   Malta Research Grant (CGSRP01-18) awarded to the first author, and by
   Global Research Network program through the Ministry of Education of the
   Republic of Korea and the National Research Foundation of Korea (Grant
   No. NRF-2016S1A2A2912410) awarded to the third author. The data and
   analysis scripts associated with four experiments can be found online at
   htips://osf.io/pw74u.
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Azzopardi-Alexander M, 1996, MALTESE
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Booij G., 1995, PHONOLOGY DUTCH
   Brouwer S, 2012, Q J EXP PSYCHOL, V65, P2193, DOI 10.1080/17470218.2012.693109
   Burki A, 2012, J EXP PSYCHOL LEARN, V38, P617, DOI 10.1037/a0026167
   Burki A, 2010, J MEM LANG, V62, P421, DOI 10.1016/j.jml.2010.01.002
   Bybee Joan, 2001, PHONOLOGY LANGUAGE U
   Cho TH, 2007, J PHONETICS, V35, P210, DOI 10.1016/j.wocn.2006.03.003
   Cho T, 2017, J PHONETICS, V64, P71, DOI 10.1016/j.wocn.2016.12.003
   Cho T, 2016, LANG LINGUIST COMPAS, V10, P120, DOI 10.1111/lnc3.12178
   Christophe A, 2004, J MEM LANG, V51, P523, DOI 10.1016/j.jml.2004.07.001
   Chung S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196885
   Connine CM, 2004, PSYCHON B REV, V11, P1084, DOI 10.3758/BF03196741
   Connine CM, 2006, LINGUIST REV, V23, P235, DOI 10.1515/TLR.2006.009
   Cutler A, 2012, NATIVE LISTENING LAN
   Dilley L, 1996, J PHONETICS, V24, P423, DOI 10.1006/jpho.1996.0023
   Draxler C, 2004, P 4 INT C LANG RES E
   Ferreira VS, 2000, COGNITIVE PSYCHOL, V40, P296, DOI 10.1006/cogp.1999.0730
   Fox J, 2018, J STAT SOFTW, V87, P1, DOI 10.18637/jss.v087.i09
   Gales L., 2016, THESIS
   Garellek M, 2014, J PHONETICS, V45, P106, DOI 10.1016/j.wocn.2014.04.001
   Gaskell MG, 2008, J EXP PSYCHOL HUMAN, V34, P1632, DOI 10.1037/a0011977
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   Gaskell MG, 2003, J PHONETICS, V31, P447, DOI 10.1016/S0095-4470(03)00012-3
   Gaskell MG, 1996, J EXP PSYCHOL HUMAN, V22, P144, DOI 10.1037/0096-1523.22.1.144
   Gatt A, 2013, CORPUS LINGUISTICS 2, V96, P96
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Gow DW, 2003, PERCEPT PSYCHOPHYS, V65, P575, DOI 10.3758/BF03194584
   Gow DW, 2001, J MEM LANG, V45, P133, DOI 10.1006/jmla.2000.2764
   John Fox, 2003, J STAT SOFTW, V8, P1, DOI DOI 10.18637/JSS.V008.I15
   Jun S.-A., 1998, PHONOLOGY, V15, P189, DOI DOI 10.1017/S0952675798003571
   Kazanina N, 2018, PSYCHON B REV, V25, P560, DOI 10.3758/s13423-017-1362-0
   Kim S, 2013, J ACOUST SOC AM, V134, pEL19, DOI 10.1121/1.4807431
   Kisler T, 2017, COMPUT SPEECH LANG, V45, P326, DOI 10.1016/j.csl.2017.01.005
   Ladefoged P, 2014, COURSE PHONETICS
   Ladefoged Peter, 1996, SOUNDS WORLDS LANGUA
   LAHIRI A, 1991, COGNITION, V38, P245, DOI 10.1016/0010-0277(91)90008-R
   Luck S. J., 2005, INTRO EVENT RELATED
   Maddieson I., 1989, J ACOUST SOC AM, V86, pS19, DOI DOI 10.1121/1.2027403
   MARSLENWILSON W, 1989, J EXP PSYCHOL HUMAN, V15, P576, DOI 10.1037/0096-1523.15.3.576
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McLennan CT, 2003, J EXP PSYCHOL LEARN, V29, P539, DOI 10.1037/0278-7393.29.4.539
   McQueen JM, 2007, Q J EXP PSYCHOL, V60, P661, DOI 10.1080/17470210601183890
   Mitterer H, 2006, J PHONETICS, V34, P73, DOI 10.1016/j.wocn.2005.03.003
   Mitterer H, 2006, Q J EXP PSYCHOL, V59, P1395, DOI 10.1080/17470210500198726
   Mitterer H, 2006, COGNITIVE SCI, V30, P451, DOI 10.1207/s15516709cog0000_57
   Mitterer H, 2018, J PHONETICS, V66, P28, DOI 10.1016/j.wocn.2017.09.003
   Mitterer H, 2018, J MEM LANG, V98, P77, DOI 10.1016/j.jml.2017.09.005
   Mitterer H, 2016, J PHONETICS, V54, P68, DOI 10.1016/j.wocn.2015.09.002
   Mitterer H, 2015, J MEM LANG, V85, P116, DOI 10.1016/j.jml.2015.08.005
   Mitterer H, 2013, J MEM LANG, V69, P59, DOI 10.1016/j.jml.2013.02.001
   Mitterer H, 2013, ATTEN PERCEPT PSYCHO, V75, P557, DOI 10.3758/s13414-012-0407-8
   Mitterer H, 2009, J EXP PSYCHOL HUMAN, V35, P244, DOI 10.1037/a0012730
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Ohala J. J., 1995, PHONOLOGY PHONETIC E, V4, P41, DOI DOI 10.1017/CB09780511554315.004
   Pardo JS, 2018, J PHONETICS, V69, P1, DOI 10.1016/j.wocn.2018.04.001
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Pitt MA, 2009, J MEM LANG, V61, P19, DOI 10.1016/j.jml.2009.02.005
   Redi L, 2001, J PHONETICS, V29, P407, DOI 10.1006/jpho.2001.0145
   Roberts AC, 2013, MENT LEX, V8, P140, DOI 10.1075/ml.8.2.02rob
   Roettger TB, 2014, J PHONETICS, V43, P11, DOI 10.1016/j.wocn.2014.01.002
   Salverda AP, 2003, COGNITION, V90, P51, DOI 10.1016/S0010-0277(03)00139-2
   Selkirk E., 1986, PHONOLOGY YB, V3, P371, DOI DOI 10.1017/S0952675700000695
   ShattuckHufnagel S, 1996, J PSYCHOLINGUIST RES, V25, P193, DOI 10.1007/BF01708572
   Shatzman KB, 2006, PSYCHOL SCI, V17, P372, DOI 10.1111/j.1467-9280.2006.01714.x
   Steffman J, 2019, J PHONETICS, V74, P114, DOI 10.1016/j.wocn.2019.03.002
   Steriade D., 1999, UCLA WORKING PAPERS, V2, P25
   SWINNEY DA, 1979, J VERB LEARN VERB BE, V18, P645, DOI 10.1016/S0022-5371(79)90355-4
   TANENHAUS MK, 1979, J VERB LEARN VERB BE, V18, P427, DOI 10.1016/S0022-5371(79)90237-8
   TARR MJ, 1995, J EXP PSYCHOL HUMAN, V21, P1494, DOI 10.1037/0096-1523.21.6.1494
   Turk AE, 2007, J PHONETICS, V35, P445, DOI 10.1016/j.wocn.2006.12.001
   Viebahn MC, 2018, ATTEN PERCEPT PSYCHO, V80, P1539, DOI 10.3758/s13414-018-1525-8
   Warner N, 2001, J PHONETICS, V29, P53, DOI 10.1006/jpho.2001.0129
   Westfall J, 2014, J EXP PSYCHOL GEN, V143, P2020, DOI 10.1037/xge0000014
NR 78
TC 5
Z9 5
U1 1
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0749-596X
EI 1096-0821
J9 J MEM LANG
JI J. Mem. Lang.
PD OCT
PY 2019
VL 108
AR 104034
DI 10.1016/j.jml.2019.104034
PG 19
WC Linguistics; Psychology; Psychology, Experimental
SC Linguistics; Psychology
GA IT0DJ
UT WOS:000482516600010
OA Other Gold
DA 2021-02-24
ER

PT J
AU Haumann, S
   Bauernfeind, G
   Teschner, MJ
   Schierholz, I
   Bleichner, MG
   Buchner, A
   Lenarz, T
AF Haumann, S.
   Bauernfeind, G.
   Teschner, M. J.
   Schierholz, I
   Bleichner, M. G.
   Buechner, A.
   Lenarz, T.
TI Epidural recordings in cochlear implant users
SO JOURNAL OF NEURAL ENGINEERING
LA English
DT Article
DE auditory evoked potentials (AEPs); auditory cortex (AC); epidural
   recordings; cochlear implant (CI)
ID AUDITORY-EVOKED-POTENTIALS; ELECTROCORTICOGRAPHIC SIGNALS;
   SPEECH-PERCEPTION; DISCRIMINATION; PERFORMANCE; IMPROVEMENT; INTERFACES;
   CORTEX
AB Objective. In the long term it is desirable for CI users to control their device via brain signals. A possible strategy is the use of auditory evoked potentials (AEPs). Several studies have shown the suitability of auditory paradigms for such an approach. However, these investigations are based on non-invasive recordings. When thinking about everyday life applications, it would be more convenient to use implanted electrodes for signal acquisition. Ideally, the electrodes would be directly integrated into the CI. Further it is to be expected that invasively recorded signals have higher signal quality and are less affected by artifacts. Approach. In this project we investigated the feasibility of implanting epidural electrodes temporarily during CI surgery and the possibility to record AEPs in the course of several days after implantation. Intraoperatively, auditory brainstem responses were recorded, whereas various kinds of AEPs were recorded postoperatively. After a few days the epidural electrodes were removed. Main results. Data sets of ten subjects were obtained. Invasively recorded potentials were compared subjectively and objectively to clinical standard recordings using surface electrodes. Especially the cortical evoked response audiometry depicted clearer N1 waves for the epidural electrodes which were also visible at lower stimulation intensities compared to scalp electrodes. Furthermore the signal was less disturbed by artifacts. The objective quality measure (based on data sets of six patients) showed a significant better signal quality for the epidural compared to the scalp recordings. Significance. Altogether the approach revealed to be feasible and well tolerated by the patients. The epidural recordings showed a clearly better signal quality than the scalp recordings with AEPs being clearer recognizable. The results of the present study suggest that including epidural recording electrodes in future CI systems will improve the everyday life applicability of auditory closed loop systems for CI subjects.
C1 [Haumann, S.; Bauernfeind, G.; Teschner, M. J.; Schierholz, I; Buechner, A.; Lenarz, T.] Hannover Med Sch, Dept Otolaryngol, Hannover, Germany.
   [Bleichner, M. G.] Carl von Ossietzky Univ Oldenburg, Dept Psychol, Oldenburg, Germany.
   [Haumann, S.; Bauernfeind, G.; Teschner, M. J.; Schierholz, I; Bleichner, M. G.; Buechner, A.; Lenarz, T.] Cluster Excellence Hearing4all, Hannover, Germany.
   [Haumann, S.; Bauernfeind, G.; Teschner, M. J.; Schierholz, I; Bleichner, M. G.; Buechner, A.; Lenarz, T.] Cluster Excellence Hearing4all, Oldenburg, Germany.
RP Haumann, S (corresponding author), Hannover Med Sch, Dept Otolaryngol, Hannover, Germany.; Haumann, S (corresponding author), Cluster Excellence Hearing4all, Hannover, Germany.; Haumann, S (corresponding author), Cluster Excellence Hearing4all, Oldenburg, Germany.
EM haumann.sabine@mh-hannover.de
RI Bleichner, Martin G/AAA-1383-2021
OI Bleichner, Martin G/0000-0001-6933-9238; Bauernfeind,
   Gunther/0000-0002-5205-8920
FU German Research Foundation (Deutsche Forschungsgemeinschaft, DFG),
   Cluster of Excellence Hearing4allGerman Research Foundation (DFG) [EXC
   1077/1]
FX This work was supported by the German Research Foundation (Deutsche
   Forschungsgemeinschaft, DFG), Cluster of Excellence Hearing4all (EXC
   1077/1). This paper only reflects the authors' views and funding
   agencies are not liable for any use that may be made of the information
   contained herein.
CR Bauernfeind G, 2015, IEEE ENG MED BIO, P1902, DOI 10.1109/EMBC.2015.7318754
   Bleichner MG, 2016, BRAIN STRUCT FUNCT, V221, P203, DOI 10.1007/s00429-014-0902-x
   Bleichner MG, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00163
   Bleichner MG, 2015, PHYSIOL REP, V3, DOI 10.14814/phy2.12362
   Bruns L, 2016, SCI REP-UK, V6, DOI 10.1038/srep32026
   Buchner A, 2017, HNO, V65, P276, DOI 10.1007/s00106-017-0339-7
   Buechner A, 2006, INT J AUDIOL, V45, P407, DOI 10.1080/14992020600625155
   Caldwell MT, 2017, LARYNGOSCOPE INVEST, V2, P119, DOI 10.1002/lio2.71
   Finke Mareike, 2017, Ear Hear, V38, pe118, DOI 10.1097/AUD.0000000000000377
   Frohne C, 1997, AM J OTOL, V18, pS93
   Frohne C, 1997, AM J OTOL, V18, pS95
   Haumann S, 2007, HNO, V55, P613, DOI 10.1007/s00106-006-1485-5
   Haumann S, 2016, J OTOL RHINOL, V5, P5
   Haumann S, 2016, BIOMED TECH, V61, ps240
   Haumann S, 2010, ORL-J OTO-RHIN-LARYN, V72, P312, DOI 10.1159/000318872
   Heinke W, 2005, CURR OPIN ANESTHESIO, V18, P625, DOI 10.1097/01.aco.0000189879.67092.12
   Hochberg LR, 2006, NATURE, V442, P164, DOI 10.1038/nature04970
   Krueger B, 2008, OTOL NEUROTOL, V29, P509, DOI 10.1097/MAO.0b013e318171972f
   Kubler A, 2009, ANN NY ACAD SCI, V1157, P90, DOI 10.1111/j.1749-6632.2008.04122.x
   Lenarz M, 2012, OTOLARYNG HEAD NECK, V147, P112, DOI 10.1177/0194599812438041
   Lenarz T., 2017, HEAD NECK SURG, V16, pDoc04, DOI [10.3205/cto000143, DOI 10.3205/CTO000143]
   Lenarz T, 2013, INT J AUDIOL, V52, P838, DOI 10.3109/14992027.2013.802032
   Leuthardt EC, 2004, J NEURAL ENG, V1, P63, DOI 10.1088/1741-2560/1/2/001
   Loizou PC, 1999, IEEE ENG MED BIOL, V18, P34, DOI 10.1109/51.765187
   Maynard EM, 1997, ELECTROEN CLIN NEURO, V102, P228, DOI 10.1016/S0013-4694(96)95176-0
   Mc Laughlin M, 2013, HEARING RES, V302, P84, DOI 10.1016/j.heares.2013.05.006
   Mc Laughlin M, 2012, IEEE T NEUR SYS REH, V20, P443, DOI 10.1109/TNSRE.2012.2186982
   McDermott Hugh J, 2004, Trends Amplif, V8, P49, DOI 10.1177/108471380400800203
   Muhler R, 2009, ORL-J OTO-RHIN-LARYN, V71, P14, DOI 10.1159/000165170
   Muller-Putz G R, 2015, FUTURE BRAIN NEURAL, DOI [10.3217/978-3-85125-379-5, DOI 10.3217/978-3-85125-379-5]
   Nourski KV, 2013, JARO-J ASSOC RES OTO, V14, P435, DOI 10.1007/s10162-013-0382-3
   PICTON TW, 1974, ELECTROEN CLIN NEURO, V36, P179, DOI 10.1016/0013-4694(74)90155-2
   Pokorny C, 2013, ARTIF INTELL MED, V59, P81, DOI 10.1016/j.artmed.2013.07.003
   Sandmann P, 2015, CLIN NEUROPHYSIOL, V126, P594, DOI 10.1016/j.clinph.2014.06.029
   Schalk G, 2007, J NEURAL ENG, V4, P264, DOI 10.1088/1741-2560/4/3/012
   Schwartz AB, 2006, NEURON, V52, P205, DOI 10.1016/j.neuron.2006.09.019
   Slutzky MW, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/2/026004
   Teschner M, 2013, OTOL NEUROTOL, V34, P66, DOI 10.1097/MAO.0b013e318278bf58
   Vaisanen J, 2009, 11th International Congress of the IUPESM. Medical Physics and Biomedical Engineering. World Congress 2009. Neuroengineering, Neural Systems, Rehabilitation and Prosthetics, P267, DOI 10.1007/978-3-642-03889-1_72
   Valderrama AT, 2010, J NEUROSCI METH, V187, P270, DOI 10.1016/j.jneumeth.2010.01.019
   Vansteensel MJ, 2010, ANN NEUROL, V67, P809, DOI 10.1002/ana.21985
   Wang W, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0055344
   Wilson BS, 2008, J REHABIL RES DEV, V45, P695, DOI 10.1682/JRRD.2007.10.0173
   Wilson BS, 2008, HEARING RES, V242, P3, DOI 10.1016/j.heares.2008.06.005
   Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3
   Zander TO, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/2/025005
NR 46
TC 0
Z9 0
U1 0
U2 6
PU IOP PUBLISHING LTD
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 1741-2560
EI 1741-2552
J9 J NEURAL ENG
JI J. Neural Eng.
PD OCT
PY 2019
VL 16
IS 5
AR 056008
DI 10.1088/1741-2552/ab1e80
PG 13
WC Engineering, Biomedical; Neurosciences
SC Engineering; Neurosciences & Neurology
GA IN5VK
UT WOS:000478744500003
PM 31042688
OA Other Gold
DA 2021-02-24
ER

PT J
AU Jain, C
   Priya, MB
   Joshi, K
AF Jain, Chandni
   Priya, M. B.
   Joshi, Kirti
TI Relationship between temporal processing and phonological awareness in
   children with speech sound disorders
SO CLINICAL LINGUISTICS & PHONETICS
LA English
DT Article
DE Temporal processing; phonological processing; speech sound disorder
ID 8-YEAR-OLD CHILDREN; LITERACY SKILLS; LANGUAGE; PERCEPTION; DISABILITY;
   IMPAIRMENT; DEFICITS
AB Temporal processing ability contributes to the identification of small phonetic elements that is important for speech perception. Difficulty in these interferes with normal speech perception and phoneme recognition. The present study aimed to assess the temporal and phonological processing abilities in children with speech sound disorders (SSD). Temporal processing and phonological skills were evaluated in 32 participants in the age range of 6-10 years, equally divided into two groups. Group I included typically developing children, and Group II included children with SSD. Gap detection test and duration pattern test were used to assess temporal processing abilities, and phonological sensitivity training kit in Kannada (PhoST-K) assessed phonological processing abilities. The results showed that there was a significant difference in temporal and phonological processing between the two groups of children. A significant correlation between gap detection ability and deletion tasks and between duration pattern ability and oddity tasks was obtained. Based on the results, it is recommended to assess the temporal process pertinent to central auditory processing in children with SSD, as a close relationship between temporal processing abilities and phonological awareness exists.
C1 [Jain, Chandni; Priya, M. B.; Joshi, Kirti] All India Inst Speech & Hearing, Audiol, Mysuru 570006, Karnataka, India.
RP Jain, C (corresponding author), All India Inst Speech & Hearing, Audiol, Mysuru 570006, Karnataka, India.
EM chandni.aud@gmail.com
FU AIISH Research Fund [SH/CDN/ARF-AUD-4/2017-2018]
FX This work was supported by the AIISH Research Fund
   [SH/CDN/ARF-AUD-4/2017-2018].
CR Ahissar M, 2000, P NATL ACAD SCI USA, V97, P6832, DOI 10.1073/pnas.97.12.6832
   Amaral MIR, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/256340
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   Basavaraj V., 2009, ETHICAL GUIDANCE BIO
   Ben-Artzi E, 2005, NEUROPSYCHOLOGIA, V43, P714, DOI 10.1016/j.neuropsychologia.2004.08.004
   BIRD J, 1995, J SPEECH HEAR RES, V38, P446, DOI 10.1044/jshr.3802.446
   Broomfield J, 2004, INT J LANG COMM DIS, V39, P303, DOI 10.1080/13682820310001625589
   Caumo Débora Tomazi Moreira, 2009, Rev. soc. bras. fonoaudiol., V14, P234, DOI 10.1590/S1516-80342009000200015
   Cohen-Mimran R, 2006, J SPEECH LANG HEAR R, V49, P127, DOI 10.1044/1092-4388(2006/010)
   Dodd B, 2008, INT J SPEECH-LANG PA, V10, P169, DOI 10.1080/14417040701682076
   Fostick L, 2012, PSYCHOL RES, V2, P77
   Fostick L, 2014, J EXP PSYCHOL HUMAN, V40, P1799, DOI 10.1037/a0037527
   Heiervang E, 2002, J CHILD PSYCHOL PSYC, V43, P931, DOI 10.1111/1469-7610.00097
   Hoover E, 2015, J AM ACAD AUDIOL, V26, P540, DOI 10.3766/jaaa.14088
   Hurley R M, 1997, J Am Acad Audiol, V8, P257
   Lewis BA, 2015, AM J SPEECH-LANG PAT, V24, P150, DOI 10.1044/2014_AJSLP-14-0075
   LUBERT N, 1981, J SPEECH HEAR DISORD, V46, P3, DOI 10.1044/jshd.4601.03
   MANN VA, 1988, J CONSULT CLIN PSYCH, V56, P811
   Mathworks I., 2014, MATLAB R2014A
   McArthur G, 2009, DEVELOPMENTAL SCI, V12, P768, DOI 10.1111/j.1467-7687.2008.00804.x
   Muniz Lílian Ferreira, 2007, Rev. CEFAC, V9, P550, DOI 10.1590/S1516-18462007000400016
   Musiek F E, 1994, J Am Acad Audiol, V5, P265
   Nathan L, 2004, J SPEECH LANG HEAR R, V47, P377, DOI 10.1044/1092-4388(2004/031)
   Prema K. S., 2012, DEV PHONOLOGIC UNPUB
   Quintas Victor Gandra, 2010, Pró-Fono R. Atual. Cient., V22, P497, DOI 10.1590/S0104-56872010000400023
   Raitano NA, 2004, J CHILD PSYCHOL PSYC, V45, P821, DOI 10.1111/j.1469-7610.2004.00275.x
   Ronen M, 2018, ACTA PSYCHOL, V190, P1, DOI 10.1016/j.actpsy.2018.06.010
   Roulstone S, 2009, INT J SPEECH-LANG PA, V11, P381, DOI 10.1080/17549500903125111
   Rvachew S, 2003, AM J SPEECH-LANG PAT, V12, P463, DOI 10.1044/1058-0360(2003/092)
   Sayyahi F, 2017, RES DEV DISABIL, V61, P151, DOI 10.1016/j.ridd.2016.12.004
   Shin JB, 2003, HEAR J, V56, P52, DOI [10.1097/01.HJ.0000292557.52409.67, DOI 10.1097/01.HJ.0000292557.52409.67]
   Singhi P, 2007, J TROP PEDIATRICS, V53, P383, DOI 10.1093/tropej/fmm047
   TALLAL P, 1978, BRAIN LANG, V5, P13, DOI 10.1016/0093-934X(78)90003-2
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Tallal P, 1997, FOUNDATIONS OF READING ACQUISITION AND DYSLEXIA, P49
   Vilela N, 2016, CLINICS, V71, P62, DOI 10.6061/clinics/2016(02)02
   Wren Y, 2013, J COMMUN DISORD, V46, P53, DOI 10.1016/j.jcomdis.2012.08.008
NR 37
TC 1
Z9 1
U1 2
U2 7
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0269-9206
EI 1464-5076
J9 CLIN LINGUIST PHONET
JI Clin. Linguist. Phon.
PD JUN 2
PY 2020
VL 34
IS 6
BP 566
EP 575
DI 10.1080/02699206.2019.1671902
EA SEP 2019
PG 10
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA LK5VO
UT WOS:000488188500001
PM 31566027
DA 2021-02-24
ER

PT J
AU Luo, JX
   Li, VG
   Mok, PPK
AF Luo, Jingxin
   Li, Vivian Guo
   Mok, Peggy Pik Ki
TI The Perception of Cantonese Vowel Length Contrast by Mandarin Speakers
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Vowel length contrast; speech perception; Cantonese; speech acquisition;
   cross-linguistic influence
ID ENGLISH; ACQUISITION; SPANISH; DISCRIMINATION; ASSIMILATION; EXPERIENCE;
   QUANTITY; DURATION; ADULTS; TONES
AB The study investigates the perception of vowel length contrasts in Cantonese by native Mandarin speakers with varying degrees of experience in Cantonese: naive listeners (no exposure), inexperienced learners (1 year), and experienced learners (5 years). While vowel length contrasts do not exist in Mandarin, they are, to some extent, exploited in English, the second language (L2) of all the participants. Using an AXB discrimination task, we investigate how native and L2 phonological knowledge affects the acquisition of vowel length contrasts in a third language (L3). The results revealed that all participant groups could discriminate three contrastive vowel pairs (/a:/-/e/, /epsilon/-/e/, sic:/-/o/), but their performance was influenced by the degree of Cantonese exposure, particularly for learners in the early stage of acquisition. In addition to vowel quality differences, durational differences were proposed to explain the perceptual patterns. Furthermore, L2 English perception of the participants was found to modulate the perception of L3 Cantonese vowel length contrasts. Our findings demonstrate the bi-directional interaction between languages acquired at different stages, and provide concrete data to evaluate some speech acquisition models.
C1 [Luo, Jingxin; Li, Vivian Guo; Mok, Peggy Pik Ki] Chinese Univ Hong Kong, Hong Kong, Peoples R China.
RP Mok, PPK (corresponding author), Chinese Univ Hong Kong, Dept Linguist & Modern Languages, Shatin, Leung Kau Kui Bldg, Hong Kong, Peoples R China.
EM peggymok@cuhk.edu.hk
OI Mok, Peggy/0000-0002-9284-6083
FU Department of Linguistics and Modern Languages of The Chinese University
   of Hong Kong
FX This work was supported by the Department of Linguistics and Modern
   Languages of The Chinese University of Hong Kong.
CR Amaro JC, 2017, INT J BILINGUAL, V21, P698, DOI 10.1177/1367006916637287
   Amaro JC, 2016, INT J MULTILING, V13, P395, DOI 10.1080/14790718.2016.1217601
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Bauer L., 2004, HDB VARIETIES ENGLIS, V1, P580
   Bauer R., 1997, MODERN CANTONESE PHO
   Behne Darn, 1999, P 14 INT C PHON SCI, P857
   Best C., 1995, SPEECH PERCEPTION LI, P171
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   BLICHER DL, 1990, J PHONETICS, V18, P37, DOI 10.1016/S0095-4470(19)30357-2
   Boersma P., 2003, P 15 INT C PHON SCI, P1013
   Bohn O.-S., 1995, SPEECH PERCEPTION LI, P279
   BROWMAN CP, 1992, PHONETICA, V49, P155, DOI 10.1159/000261913
   Browman CP., 1989, PHONOLOGY, V6, P201, DOI [10.1017/S0952675700001019, DOI 10.1017/S0952675700001019]
   Cabrelli Amaro J., 2012, 3 LANGUAGE ACQUISITI, P33
   Cabrelli Amaro J., 2013, THESIS
   Cabrelli Amaro J, 2017, L3 SYNTACTIC TRANSFE
   Cabrelli Amaro J, 2010, IRAL-INT REV APPL LI, V48, P275
   Chen H., 2011, THESIS
   Cheung Hung-nin, 1972, XIANGGANG YUEYU YUFA
   Cheung K. H., 1986, THESIS
   Davenport M, 2010, INTRO PHONETICS PHON
   Duanmu S., 2007, PHONOLOGY STANDARD C
   Escudero P., 2005, LINGUISTIC PERCEPTIO
   Escudero P., 2009, PHONOLOGY PERCEPTION, P151
   Escudero P, 2011, J ACOUST SOC AM, V129, pEL1, DOI 10.1121/1.3525042
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2001, STUDIES 2 LANGUAGE A, V23, P527
   Flege J. E., 2003, PHONETICS PHONOLOGY, P319, DOI DOI 10.1515/9783110895094.319
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   FLEGE JE, 1989, J ACOUST SOC AM, V86, P1684, DOI 10.1121/1.398599
   FLEGE JE, 1988, J ACOUST SOC AM, V84, P70, DOI 10.1121/1.396876
   Flege JE, 1999, SEC LANG ACQ RES, P101
   Flynn S, 2004, INT J MULTILING, V1, P3, DOI DOI 10.1080/14790710408668175
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   Garcia A., 2013, 2011 2 LANG RES FOR, P173
   Giegerich Heinz J., 1992, ENGLISH PHONOLOGY IN
   Hadding-Koch K., 1964, STUD LINGUISTICA, V18, P94, DOI DOI 10.1111/J.1467-9582.1964.TB00451.X
   HOUSE AS, 1961, J ACOUST SOC AM, V33, P1174, DOI 10.1121/1.1908941
   Hui B., 2010, HONG KONG J APPL LIN, V12, P45
   Jia G, 2006, J ACOUST SOC AM, V119, P1118, DOI 10.1121/1.2151806
   Kao D, 1971, STRUCTURE SYLLABLE C
   Lee A, 2018, SECOND LANG RES, V34, P419, DOI 10.1177/0267658317739056
   Lee T. H.-t., 1983, UCLA WORKING PAPERS, V57, P97
   Lee T. H.-t., 1985, FANGYAN DIALECT, V1, P28
   Lee W-S., 2003, J INT PHON ASSOC, V33, P109, DOI DOI 10.1017/S0025100303001208
   Lenth R, 2018, EMMEANS ESTIMATED MA, V1, P2
   Leung Y.-K. I, 2007, SECOND LANG RES, V23, P97
   Li Xin-hui, 1995, GUANGZHOU FANGYAN YA
   Lin Yen-Hwei, 2007, SOUNDS CHINESE
   Liu S., 1987, YUYAN YANJIU LUNCONG, P3
   Liu S., 2003, DI BA JIE GUOJI YUE
   Liu SY, 2004, LANG SPEECH, V47, P109, DOI 10.1177/00238309040470020101
   livonen  A., 2005, J INT PHON ASSOC, V35, P59
   Llama R, 2016, INT J MULTILING, V13, P444, DOI 10.1080/14790718.2016.1217602
   McAllister R, 2002, J PHONETICS, V30, P229, DOI 10.1006/jpho.2002.0174
   Montrul S, 2011, SECOND LANG RES, V27, P21, DOI 10.1177/0267658310386649
   Odden D., 2011, BLACKWELL COMPANION, P465, DOI [10.1002/9781444335262.wbctp0020, DOI 10.1002/9781444335262]
   POLKA L, 1991, J ACOUST SOC AM, V89, P2961, DOI 10.1121/1.400734
   Qin Z, 2016, LANG SPEECH, V59, P318, DOI 10.1177/0023830915590191
   R Core Team, 2018, R LANG ENV STAT COMP
   Riney T. J., 1998, STUDIES 2 LANGUAGE A, V20, P213
   Rothman J., 2010, IRAL-INT REV APPL LI, V48, P245, DOI DOI 10.1515/IRAL.2010.011
   Rothman J, 2015, BILING-LANG COGN, V18, P179, DOI 10.1017/S136672891300059X
   Rothman J, 2011, SECOND LANG RES, V27, P107, DOI 10.1177/0267658310386439
   Schmid MS, 2014, SECOND LANG RES, V30, P129, DOI 10.1177/0267658313505314
   Shi F., 2002, DONGFANG YUYAN YU WE, P98
   Shi F., 2005, FANGYAN, V1, P1
   Shi F., 2003, ZHONGGUO YUNWEN YANJ, V2, P50
   Tremblay M. C., 2006, CAHIERS LINGUISTIQUE, V34, P109
   Tyler MD, 2014, PHONETICA, V71, P4, DOI 10.1159/000356237
   Vance Timothy J., 2008, SOUNDS JAPANESE
   Wang Z., 1999, GONGXING YU GEXING H, P255
   Warren P, 2018, J INT PHON ASSOC, V48, P305, DOI 10.1017/S0025100317000329
   WERKER JF, 1984, J ACOUST SOC AM, V75, P1866, DOI 10.1121/1.390988
   Wong S. L., 1941, YUE YIN JUN HUI
   Wrembel M., 2012, 3 LANGUAGE ACQUISITI, P381, DOI [10.1075/SIBIL.46.16WRE, DOI 10.1075/SIBIL.46.16WRE]
   Wrembel M, 2010, INT J MULTILING, V7, P1, DOI 10.1080/14790710902972230
   YUAN JH, 1960, HANYU FANGYAN GAIYAO
   Yue-Hashimoto A. O., 1972, CANTONESE
   Zee E., 2003, P 15 INT C PHON SCI, P1117
   Zee E., 1999, HDB INT PHONETIC ASS, P58
NR 82
TC 0
Z9 0
U1 2
U2 5
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD SEP
PY 2020
VL 63
IS 3
BP 635
EP 659
AR 0023830919879471
DI 10.1177/0023830919879471
EA SEP 2019
PG 25
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA MX6CZ
UT WOS:000489867900001
PM 31566064
DA 2021-02-24
ER

PT J
AU Pejovic, J
   Yee, E
   Molnar, M
AF Pejovic, Jovana
   Yee, Eiling
   Molnar, Monika
TI Speaker matters: Natural inter-speaker variation affects 4-month-olds'
   perception of audio-visual speech
SO FIRST LANGUAGE
LA English
DT Article
DE Audio-visual matching; eye-tracking; infant; speech perception
   development; visual and auditory perceptual salience
ID PHONETIC INFORMATION; INFANTS; LIPS
AB In the language development literature, studies often make inferences about infants' speech perception abilities based on their responses to a single speaker. However, there can be significant natural variability across speakers in how speech is produced (i.e., inter-speaker differences). The current study examined whether inter-speaker differences can affect infants' ability to detect a mismatch between the auditory and visual components of vowels. Using an eye-tracker, 4.5-month-old infants were tested on auditory-visual (AV) matching for two vowels (/i/ and /u/). Critically, infants were tested with two speakers who naturally differed in how distinctively they articulated the two vowels within and across the categories. Only infants who watched and listened to the speaker whose visual articulations of the two vowels were most distinct from one another were sensitive to AV mismatch. This speaker also produced a visually more distinct /i/ as compared to the other speaker. This finding suggests that infants are sensitive to the distinctiveness of AV information across speakers, and that when making inferences about infants' perceptual abilities, characteristics of the speaker should be taken into account.
C1 [Pejovic, Jovana] BCBL Basque Ctr Cognit Brain & Language, San Sebastian, Spain.
   [Pejovic, Jovana] Univ Lisbon, Lisbon, Portugal.
   [Yee, Eiling] Univ Connecticut, Mansfield, PA USA.
   [Molnar, Monika] Univ Toronto, Toronto, ON, Canada.
RP Pejovic, J (corresponding author), Univ Lisbon, Lab Fonet & Lisbon Baby Lab, Ctr Linguist, Fac Letras, Alameda Univ, P-1600214 Lisbon, Portugal.
EM jpejovic@edu.ulisboa.pt
FU Spanish Ministry of Economy and Competitiveness [PSI2014-5452-P]; Severo
   Ochoa Program for Centers/Units of Excellence in RD [SEV-2015-490];
   Basque Government 'Programa Predoctoral'Basque Government
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship and/or publication of this article: This
   research was funded by the grant PSI2014-5452-P from the Spanish
   Ministry of Economy and Competitiveness to M.M. The authors also
   acknowledge financial support from the 'Severo Ochoa Program for
   Centers/Units of Excellence in R&D' (SEV-2015-490) and from the Basque
   Government 'Programa Predoctoral' to J.P.
CR Altvater-Mackensen N, 2016, DEV PSYCHOL, V52, P191, DOI 10.1037/a0039964
   Altvater-Mackensen N, 2015, CHILD DEV, V86, P362, DOI 10.1111/cdev.12320
   Baier R., 2007, P INT C AUD VIS SPEE
   Buchner A, 2009, G POWER VERSION 3 1
   Green JR, 2010, J SPEECH LANG HEAR R, V53, P1529, DOI 10.1044/1092-4388(2010/09-0005)
   Hunter M. A., 1988, ADV INFANCY RES, V5, P69, DOI DOI 10.1037/0012-1649.19.3.338
   JOHNSON K, 1993, J ACOUST SOC AM, V94, P701, DOI 10.1121/1.406887
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   KUHL PK, 1984, INFANT BEHAV DEV, V7, P361, DOI 10.1016/S0163-6383(84)80050-8
   Liu HM, 2003, DEVELOPMENTAL SCI, V6, pF1, DOI 10.1111/1467-7687.00275
   Masapollo M., 2019, J ACOUST SOC AM, V44, P1103
   Molnar M, 2014, INFANCY, V19, P326, DOI 10.1111/infa.12041
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Patterson ML, 1999, INFANT BEHAV DEV, V22, P237, DOI 10.1016/S0163-6383(99)00003-X
   Pejovic J., 2017, 3 WORKSH INF LANG DE
   Streri A, 2016, INFANCY, V21, P177, DOI 10.1111/infa.12104
   Tomalski P, 2013, EUR J DEV PSYCHOL, V10, P611, DOI 10.1080/17405629.2012.728076
   Yeung HH, 2013, PSYCHOL SCI, V24, P603, DOI 10.1177/0956797612458802
NR 18
TC 1
Z9 1
U1 0
U2 1
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0142-7237
EI 1740-2344
J9 FIRST LANG
JI First Lang.
PD APR
PY 2020
VL 40
IS 2
BP 113
EP 127
AR 0142723719876382
DI 10.1177/0142723719876382
EA SEP 2019
PG 15
WC Psychology, Developmental; Linguistics; Language & Linguistics
SC Psychology; Linguistics
GA LC4IR
UT WOS:000490584600001
DA 2021-02-24
ER

PT J
AU El-Assal, HA
   El-Gharib, AM
   Kolkaila, EA
   Elmahallawy, TH
AF El-Assal, Hiba Ahmed
   El-Gharib, Amani Mohamed
   Kolkaila, Enaas Ahmad
   Elmahallawy, Trandil Hassan
TI Encoding of speech in noise in adults using hearing aids: effect of
   noise reduction algorithm
SO HEARING BALANCE AND COMMUNICATION
LA English
DT Article
DE Speech; noise; hearing aids
ID BRAIN-STEM RESPONSE
AB Introduction: Subjects using hearing aids complains of difficulty in speech understanding in noise. Speech auditory brainstem response (S-ABR) provides cues for temporal and spectral encoding of speech in the brainstem. Objective: This work was designed to evaluate speech processing in patients fitted with hearing aid using S-ABR and to study the effect of noise reduction algorithm on speech processing in patients fitted with hearing aids. Materials and method: This study included 20 adults with mild to severe SNHL fitted with HA at least 3 months with aided threshold in all frequencies better than or equal to 30 dB. Hearing aid was used with all the subjects and was programed for each subject according to his audiogram followed by aided evaluation using S-ABR. Through sound field in four different test conditions with NR algorithm on in quiet and in the presence of noise then with the NR off in quiet and in the presence of noise were performed. Results: There was a statistically significant delay in the S-ABR onset and offset in noise compared to quiet. The effect of noise on S-ABR while the NR was on showed statistically significant difference in the onset response in both quiet and noise. When the NR was off, there was marked effect of noise on both the onset response and offset response. Conclusions: It was found that hearing aid users are vulnerable to noise regarding the speech encoding at the level of the brainstem. Noise reduction algorithm maintains the neural activity in response to speech and improves speech perception in noise.
C1 [El-Assal, Hiba Ahmed; El-Gharib, Amani Mohamed; Kolkaila, Enaas Ahmad; Elmahallawy, Trandil Hassan] Tanta Univ, Fac Med, ENT Dept, Audiol Unit, Tanta, Egypt.
RP El-Gharib, AM (corresponding author), Tanta Univ, Fac Med, ENT Dept, Audiol Unit, Tanta, Egypt.
EM amanielgharib@yahoo.com
CR Abd El-Ghaffar NM, 2018, ACTA OTO-LARYNGOL, V138, P145, DOI 10.1080/00016489.2017.1380311
   Ahadi M, 2014, INT J AUDIOL, V53, P243, DOI 10.3109/14992027.2013.866281
   Anderson S, 2010, HEARING RES, V270, P151, DOI 10.1016/j.heares.2010.08.001
   Anderson S, 2010, TRENDS AMPLIF, V14, P73, DOI 10.1177/1084713810380227
   Bellier L, 2015, HEARING RES, V325, P49, DOI 10.1016/j.heares.2015.03.004
   Boymans M, 2000, AUDIOLOGY, V39, P260
   Hu Y, 2007, SPEECH COMMUN, V49, P588, DOI 10.1016/j.specom.2006.12.006
   JAMIESON DG, 1995, EAR HEARING, V16, P274, DOI 10.1097/00003446-199506000-00004
   Pittman M, 2013, SPEECH EFFORT SPEECH
   Rudner Mary, 2013, Seminars in Hearing, V34, P298, DOI 10.1055/s-0033-1356642
   Sandeep M, 2007, J INDIAN SPEECH HEAR, V21, P25
   Sarampalis A, 2009, J SPEECH LANG HEAR R, V52, P1230, DOI 10.1044/1092-4388(2009/08-0111)
   Shetty HN, 2017, BRAZ J OTORHINOLAR, V83, P512, DOI 10.1016/j.bjorl.2016.06.004
   Walden B E, 2000, J Am Acad Audiol, V11, P540
   Werff KRV, 2011, EAR HEARING, V32, P168, DOI 10.1097/AUD.0b013e3181f534b5
NR 15
TC 0
Z9 0
U1 0
U2 5
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2169-5717
EI 2169-5725
J9 HEARING BALANC COMMU
JI Hearing Balanc. Commun.
PD APR 2
PY 2020
VL 18
IS 2
BP 98
EP 104
DI 10.1080/21695717.2019.1667687
EA SEP 2019
PG 7
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA NG4CF
UT WOS:000490542100001
DA 2021-02-24
ER

PT J
AU van de Rijt, LPH
   Roye, A
   Mylanus, EAM
   van Opstal, AJ
   van Wanrooij, MM
AF van de Rijt, Luuk P. H.
   Roye, Anja
   Mylanus, Emmanuel A. M.
   van Opstal, A. John
   van Wanrooij, Marc M.
TI The Principle of Inverse Effectiveness in Audiovisual Speech Perception
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE multisensory; lipreading; listening; hearing; speech recognition in
   noise
ID AUDITORY-VISUAL INTERACTIONS; MULTISENSORY INTEGRATION; SUPERIOR
   COLLICULUS; SENTENCE TEST; OLDER-ADULTS; INTELLIGIBILITY; EYE;
   RECOGNITION; ATTENTION; INFERENCE
AB We assessed how synchronous speech listening and lipreading affects speech recognition in acoustic noise. In simple audiovisual perceptual tasks, inverse effectiveness is often observed, which holds that the weaker the unimodal stimuli, or the poorer their signal-to-noise ratio, the stronger the audiovisual benefit. So far, however, inverse effectiveness has not been demonstrated for complex audiovisual speech stimuli. Here we assess whether this multisensory integration effect can also be observed for the recognizability of spoken words. To that end, we presented audiovisual sentences to 18 native-Dutch normal-hearing participants, who had to identify the spoken words from a finite list. Speech-recognition performance was determined for auditory-only, visual-only (lipreading), and auditory-visual conditions. To modulate acoustic task difficulty, we systematically varied the auditory signal-to-noise ratio. In line with a commonly observed multisensory enhancement on speech recognition, audiovisual words were more easily recognized than auditory-only words (recognition thresholds of -15 and -12 dB, respectively). We here show that the difficulty of recognizing a particular word, either acoustically or visually, determines the occurrence of inverse effectiveness in audiovisual word integration. Thus, words that are better heard or recognized through lipreading, benefit less from bimodal presentation. Audiovisual performance at the lowest acoustic signal-to-noise ratios (45%) fell below the visual recognition rates (60%), reflecting an actual deterioration of lipreading in the presence of excessive acoustic noise. This suggests that the brain may adopt a strategy in which attention has to be divided between listening and lipreading.
C1 [van de Rijt, Luuk P. H.; Mylanus, Emmanuel A. M.] Radboud Univ Nijmegen, Med Ctr, Dept Otorhinolaryngol, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
   [Roye, Anja; van Opstal, A. John; van Wanrooij, Marc M.] Radboud Univ Nijmegen, Dept Biophys, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
RP van Wanrooij, MM (corresponding author), Radboud Univ Nijmegen, Dept Biophys, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
EM m.vanwanrooij@donders.ru.nl
RI van de Rijt, Luuk P.H./P-8706-2015; van Wanrooij, Marc/J-3385-2012; van
   Opstal, John/D-1907-2010; van de Rijt, Luuk/AAL-1336-2020
OI van de Rijt, Luuk P.H./0000-0002-4425-2176; van Wanrooij,
   Marc/0000-0003-4180-1835; van de Rijt, Luuk/0000-0002-4425-2176
FU EU FP7-PEOPLE-2013-ITN iCARE [407139]; EU Horizon 2020 ERC Advanced
   Grant ORIENT [693400]; Cochlear Benelux NV; Radboud University Medical
   Center; Radboud University
FX This research was supported by EU FP7-PEOPLE-2013-ITN iCARE (grant
   407139, AR), EU Horizon 2020 ERC Advanced Grant ORIENT (grant 693400,
   AO), Cochlear Benelux NV (LR and MW), the Radboud University Medical
   Center (LR and EM), and the Radboud University (MW). The funders had no
   role in study design, data collection and analysis, decision to publish,
   or preparation of the manuscript.
CR Alais D, 2004, COGNITIVE BRAIN RES, V19, P185, DOI 10.1016/j.cogbrainres.2003.11.011
   Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Bell AH, 2005, J NEUROPHYSIOL, V93, P3659, DOI 10.1152/jn.01214.2004
   Bernstein LE, 2000, PERCEPT PSYCHOPHYS, V62, P233, DOI 10.3758/BF03205546
   Bernstein LE, 2004, SPEECH COMMUN, V44, P5, DOI 10.1016/j.specom.2004.10.011
   Bonnel AM, 1998, PERCEPT PSYCHOPHYS, V60, P179, DOI 10.3758/BF03206027
   Bremen P, 2017, FRONT SYST NEUROSCI, V11, DOI 10.3389/fnsys.2017.00089
   Brooks SP, 1998, J COMPUT GRAPH STAT, V7, P434, DOI 10.2307/1390675
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Corneil BD, 2002, J NEUROPHYSIOL, V88, P438, DOI 10.1152/jn.2002.88.1.438
   FRENS MA, 1995, PERCEPT PSYCHOPHYS, V57, P802, DOI 10.3758/BF03206796
   Gelman Andrew, 2013, BAYESIAN DATA ANAL T
   Gosselin PA, 2011, J SPEECH LANG HEAR R, V54, P944, DOI 10.1044/1092-4388(2010/10-0069)
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   HAGERMAN B, 1982, SCAND AUDIOL, V11, P79, DOI 10.3109/01050398209076203
   Helfer KS, 1997, J SPEECH LANG HEAR R, V40, P432, DOI 10.1044/jslhr.4002.432
   Hochmuth S, 2012, INT J AUDIOL, V51, P536, DOI 10.3109/14992027.2012.670731
   Holmes NP, 2009, BRAIN TOPOGR, V21, P168, DOI 10.1007/s10548-009-0097-2
   Houben R, 2015, TRENDS HEAR, V19, DOI 10.1177/2331216515583138
   Houben R, 2014, INT J AUDIOL, V53, P760, DOI 10.3109/14992027.2014.920111
   Kass RE, 1998, AM STAT, V52, P93, DOI 10.2307/2685466
   Kording KP, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000943
   Kruschke JK, 2015, DOING BAYESIAN DATA
   Kuss M, 2005, J VISION, V5, P478, DOI 10.1167/5.5.8
   Lee M. D., 2014, BAYESIAN COGNITIVE M
   Ma WJ, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004638
   MACLEOD A, 1987, British Journal of Audiology, V21, P131, DOI 10.3109/03005368709077786
   MACLEOD A, 1990, British Journal of Audiology, V24, P29, DOI 10.3109/03005369009077840
   MEREDITH MA, 1986, BRAIN RES, V365, P350
   MIDDELWEERD MJ, 1987, J ACOUST SOC AM, V82, P2145, DOI 10.1121/1.395659
   O'Neill JJ, 1954, J SPEECH HEAR DISORD, V19, P429, DOI 10.1044/jshd.1904.429
   Ozimek E, 2010, INT J AUDIOL, V49, P444, DOI 10.3109/14992021003681030
   Plummer M., 2003, P 3 INT WORKSH DISBT
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Rouger J, 2007, P NATL ACAD SCI USA, V104, P7295, DOI 10.1073/pnas.0609419104
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   Stein B. E., 1993, MERGING SENSES
   Stein BE, 2009, EXP BRAIN RES, V198, P113, DOI 10.1007/s00221-009-1880-8
   Stevenson RA, 2015, NEUROBIOL AGING, V36, P283, DOI 10.1016/j.neurobiolaging.2014.08.003
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Turner BM, 2013, NEUROIMAGE, V72, P193, DOI 10.1016/j.neuroimage.2013.01.048
   Tye-Murray N, 2007, EAR HEARING, V28, P656, DOI 10.1097/AUD.0b013e31812f7185
   Tye-Murray N, 2016, PSYCHOL AGING, V31, P380, DOI 10.1037/pag0000094
   Tye-Murray N, 2010, EAR HEARING, V31, P636, DOI 10.1097/AUD.0b013e3181ddf7ff
   Van Barneveld DCPBM, 2013, EUR J NEUROSCI, V37, P1501, DOI 10.1111/ejn.12176
   van de Rijt L. P. H., 2019, BIORXIV, DOI [10.1101/585182, DOI 10.1101/585182]
   van de Rijt LPH, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00048
   Van Wanrooij MM, 2009, EXP BRAIN RES, V198, P425, DOI 10.1007/s00221-009-1815-4
   Wagener K, 2003, INT J AUDIOL, V42, P10, DOI 10.3109/14992020309056080
   Wallace MT, 2004, EXP BRAIN RES, V158, P252, DOI 10.1007/s00221-004-1899-9
   Wallace MT, 1998, J NEUROPHYSIOL, V80, P1006
   Winn MB, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00824
NR 52
TC 2
Z9 2
U1 1
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD SEP 26
PY 2019
VL 13
AR 335
DI 10.3389/fnhum.2019.00335
PG 15
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA JA8LA
UT WOS:000488102200001
PM 31611780
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Ching, TYC
   Cupples, L
   Marnane, V
AF Ching, Teresa Y. C.
   Cupples, Linda
   Marnane, Vivienne
TI Early Cognitive Predictors of 9-Year-Old Spoken Language in Children
   With Mild to Severe Hearing Loss Using Hearing Aids
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE short-term memory; language; cognitive predictors; hearing aids;
   children with hearing loss
ID NEUROCOGNITIVE OUTCOMES; COCHLEAR IMPLANTATION; PHONOLOGICAL MEMORY;
   SPEECH-PERCEPTION; DEAF-CHILDREN; SKILLS
AB This study examined the extent to which cognitive ability at 5 years of age predicted language development from 5 to 9 years of age in a population-based sample of children with hearing loss who participated in the Longitudinal Outcomes of Children with Hearing Impairment (LOCHI) study. The developmental outcomes of 81 children with hearing loss were evaluated at 5 and 9 years of age. Hearing loss ranged from mild to severe degrees, and all participants used hearing aids. They all used spoken language as the primary mode of communication and education. Nine-year-old language was assessed using the Clinical Evaluation of Language Fundamentals - 4th edition (CELF-4), the Peabody Picture Vocabulary Test - 4th edition (PPVT-4), and the Expressive Vocabulary Test - 2nd edition (EVT-2). Multiple regression analyses were conducted to examine the extent to which children's scores on these standardized assessments were predicted by their cognitive ability (non-verbal IQ and verbal working memory) measured at 5 years of age. The influence of early language scores at 5 years and a range of demographic characteristics on language scores at 9 years of age was evaluated. We found that 5-year-old digit span score was a significant predictor of receptive and expressive language, but not receptive or expressive vocabulary, at 9 years of age. Also, 5-year-old non-word repetition test score was a significant predictor of only expressive language and vocabulary, but not receptive language or vocabulary at 9 years of age. After allowing for the effects of non-verbal IQ and 5-year-old receptive vocabulary, early digit span score (but not non-word repetition score) was a significant predictor of expressive and receptive language scores at 9 years of age. The findings shed light on the unique role of early verbal working memory in predicting the development of receptive and expressive language skills and vocabulary skills in children who use hearing aids.
C1 [Ching, Teresa Y. C.; Marnane, Vivienne] Natl Acoust Labs, Sydney, NSW, Australia.
   [Ching, Teresa Y. C.; Marnane, Vivienne] Hearing CRC, Melbourne, Vic, Australia.
   [Cupples, Linda] Macquarie Univ, Dept Linguist, Sydney, NSW, Australia.
   [Cupples, Linda] Macquarie Univ, Ctr Language Sci, Sydney, NSW, Australia.
RP Ching, TYC (corresponding author), Natl Acoust Labs, Sydney, NSW, Australia.; Ching, TYC (corresponding author), Hearing CRC, Melbourne, Vic, Australia.
EM Teresa.Ching@nal.gov.au
OI Ching, Teresa/0000-0002-1588-5599; Cupples, Linda/0000-0003-3659-1642
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC008080]; Commonwealth of Australia
   through the Office of Hearing Services
FX The project described was partly supported by Award Number R01DC008080
   from the National Institute on Deafness and Other Communication
   Disorders. The content is solely the responsibility of the authors and
   does not necessarily represent the official views of the National
   Institute on Deafness and Other Communication Disorders or the National
   Institutes of Health. The project was also supported by the Commonwealth
   of Australia through the Office of Hearing Services, and through the
   establishment of the HEARing CRC and the Cooperative Research Centres
   Program. The funding organizations had no role in the design and conduct
   of the study; in the collection, analysis, and interpretation of the
   data; or in the decision to submit the paper for publication; or in the
   preparation, review, or approval of the manuscript.
CR Avons SE, 1998, APPL PSYCHOLINGUIST, V19, P583, DOI 10.1017/S0142716400010377
   Baddeley A, 1998, PSYCHOL REV, V105, P158, DOI 10.1037/0033-295X.105.1.158
   Baddeley AD, 2019, CORTEX, V112, P91, DOI 10.1016/j.cortex.2018.05.015
   Botting N, 2017, CHILD DEV, V88, P1689, DOI 10.1111/cdev.12659
   Castellanos I, 2016, AM J SPEECH-LANG PAT, V25, P381, DOI 10.1044/2016_AJSLP-15-0023
   Castellanos Irina, 2014, Cochlear Implants Int, V15, P200, DOI 10.1179/1754762813Y.0000000043
   Ching TYC, 2018, INT J AUDIOL, V57, pS41, DOI 10.1080/14992027.2017.1380851
   Ching TYC, 2018, INT J AUDIOL, V57, pS70, DOI 10.1080/14992027.2017.1346307
   Ching TYC, 2017, PEDIATRICS, V140, DOI 10.1542/peds.2016-4274
   Ching TYC, 2013, EAR HEARING, V34, P535, DOI 10.1097/AUD.0b013e3182857718
   Conway CM, 2011, DEV NEUROPSYCHOL, V36, P237, DOI 10.1080/87565641.2010.549869
   Conway CM, 2011, DEVELOPMENTAL SCI, V14, P69, DOI 10.1111/j.1467-7687.2010.00960.x
   Conway CM, 2009, CURR DIR PSYCHOL SCI, V18, P275, DOI 10.1111/j.1467-8721.2009.01651.x
   Cupples L, 2018, INT J AUDIOL, V57, pS55, DOI 10.1080/14992027.2017.1370140
   Dollaghan C, 1998, J SPEECH LANG HEAR R, V41, P1136, DOI 10.1044/jslhr.4105.1136
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   Figueras B, 2008, J DEAF STUD DEAF EDU, V13, P362, DOI 10.1093/deafed/enm067
   Gathercole S. E., 1996, CHILDRENS TEST NONWO
   GATHERCOLE SE, 1992, DEV PSYCHOL, V28, P887, DOI 10.1037//0012-1649.28.5.887
   GATHERCOLE SE, 1990, BRIT J PSYCHOL, V81, P439, DOI 10.1111/j.2044-8295.1990.tb02371.x
   Giustolisi B, 2018, COGNITIVE SCI, V42, P3177, DOI 10.1111/cogs.12691
   Hall ML, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12575
   Hunter CR, 2017, J SPEECH LANG HEAR R, V60, P2321, DOI 10.1044/2017_JSLHR-H-16-0152
   Jones A, 2020, CHILD DEV, V91, pE400, DOI 10.1111/cdev.13226
   Kronenberger WG, 2014, J DEAF STUD DEAF EDU, V19, P456, DOI 10.1093/deafed/enu011
   Nittrouer S, 2016, RES DEV DISABIL, V55, P143, DOI 10.1016/j.ridd.2016.03.020
   Pisoni D. B., 2011, EAR HEARING, V32, P60, DOI DOI 10.1097/AUD.0B013E3181FFD58E
   Pisoni DB, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00493
   Semel E. M., 2003, CLIN EVALUATION LANG
   SNOWLING M, 1989, COGNITIVE NEUROPSYCH, V6, P379, DOI 10.1080/02643298908253289
   Tomblin J Bruce, 2015, Ear Hear, V36 Suppl 1, p76S, DOI 10.1097/AUD.0000000000000219
   Torkildsen JV, 2018, COGNITION, V170, P123, DOI 10.1016/j.cognition.2017.09.017
   Wagner K. R, 1999, CTOPP COMPREHENSIVE
   Wechsler D, 2006, WECHSLER NONVERBAL S
   Williams K, 2007, EXPRESSIVE VOCABULAR
NR 35
TC 1
Z9 1
U1 1
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD SEP 26
PY 2019
VL 10
AR 2180
DI 10.3389/fpsyg.2019.02180
PG 9
WC Psychology, Multidisciplinary
SC Psychology
GA JA8HY
UT WOS:000488093200001
PM 31616354
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Ovchinnikova, I
   Zhukova, MA
   Luchina, A
   Petrov, MV
   Vasilyeva, MJ
   Grigorenko, EL
AF Ovchinnikova, Irina
   Zhukova, Marina A.
   Luchina, Anna
   Petrov, Maxim, V
   Vasilyeva, Marina J.
   Grigorenko, Elena L.
TI Auditory Mismatch Negativity Response in Institutionalized Children
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE institutionalization; psychosocial deprivation; language development;
   auditory discrimination; event-related potentials; mismatch negativity;
   MMN
ID LANGUAGE-ACQUISITION; ST-PETERSBURG; SPEECH; INFANCY; EXPOSURE; MMN;
   DISCRIMINATION; REPRESENTATION; EXPERIENCE; DYSLEXIA
AB The attunement of speech perception/discrimination to the properties of one's native language is a crucial step in speech and language development at early ages. Studying these processes in young children with a history of institutionalization is of great interest, as being raised in institutional care (IC) may lead to lags in language development. The sample consisted of 82 children, split into two age groups. The younger age group (<12 months) included 17 children from the IC and 17 children from the biological-family-care (BFC) group. The older group (>12 months) consisted of 23 children from the IC group, and 25 children from the BFC group. A double-oddball paradigm with three consonant-vowel syllables was used, utilizing native (Russian) and foreign (Hindi) languages. A Mismatch Negativity (MMN) component was elicited within a 125-225 ms time window in the frontal-central electrode. Findings demonstrate the absence of MMN effect in the younger age group, regardless of the living environment. Children in the older group are sensitive to native deviants and do not differentiate foreign language contrasts. No significant differences were observed between the IC and BFC groups for children older than 12 months, indicating that children in the IC have typical phonological processing. The results show that the MMN effect is not registered in Russian speaking children before the age of 12 months, regardless of their living environment. At 20 months of age, institutionally reared children show no evidence of delays in phonetic development despite a limited experience of language.
C1 [Ovchinnikova, Irina; Zhukova, Marina A.; Luchina, Anna; Petrov, Maxim, V; Grigorenko, Elena L.] St Petersburg State Univ, Lab Translat Sci Human Dev, St Petersburg, Russia.
   [Ovchinnikova, Irina; Zhukova, Marina A.; Grigorenko, Elena L.] Univ Houston, Dept Psychol, Houston, TX 77004 USA.
   [Vasilyeva, Marina J.] St Petersburg State Univ, Biol Fac, Dept Higher Nervous Act & Psychophysiol, St Petersburg, Russia.
   [Grigorenko, Elena L.] Baylor Coll Med, Dept Mol & Human Genet, Houston, TX 77030 USA.
   [Grigorenko, Elena L.] Yale Univ, Child Study Ctr, New Haven, CT 06520 USA.
   [Grigorenko, Elena L.] Yale Univ, Haskins Labs, New Haven, CT 06520 USA.
RP Grigorenko, EL (corresponding author), St Petersburg State Univ, Lab Translat Sci Human Dev, St Petersburg, Russia.; Grigorenko, EL (corresponding author), Univ Houston, Dept Psychol, Houston, TX 77004 USA.; Grigorenko, EL (corresponding author), Baylor Coll Med, Dept Mol & Human Genet, Houston, TX 77030 USA.; Grigorenko, EL (corresponding author), Yale Univ, Child Study Ctr, New Haven, CT 06520 USA.; Grigorenko, EL (corresponding author), Yale Univ, Haskins Labs, New Haven, CT 06520 USA.
EM elena.grigorenko@times.uh.edu
RI Zhukova, Marina A./AAM-9550-2020; Ovchinnikova, Irina V/K-2212-2017;
   Petrov, Maxim/L-4114-2017
OI Zhukova, Marina A./0000-0002-3069-570X; Ovchinnikova, Irina
   V/0000-0001-5950-5765; Petrov, Maxim/0000-0002-4370-7212
FU Government of the Russian Federation (PI: EG) [14, Z50.31.0027]
FX This research was supported by grant No 14.Z50.31.0027 from the
   Government of the Russian Federation (PI: EG).
CR Baldeweg T, 1999, ANN NEUROL, V45, P495, DOI 10.1002/1531-8249(199904)45:4<495::AID-ANA11>3.0.CO;2-M
   Bishop DVM, 2007, PSYCHOL BULL, V133, P651, DOI 10.1037/0033-2909.133.4.651
   Bornkessel-Schlesewsky I, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00298
   Burns TC, 2007, APPL PSYCHOLINGUIST, V28, P455, DOI 10.1017/S0142716407070257
   Cheour M, 1998, NAT NEUROSCI, V1, P351, DOI 10.1038/1561
   Cheour M, 2000, CLIN NEUROPHYSIOL, V111, P4, DOI 10.1016/S1388-2457(99)00191-1
   Chepikova K. A., 2015, AKTUAL NAPRAVL NAUCH, V3, P232
   Conboy BT, 2011, DEVELOPMENTAL SCI, V14, P242, DOI 10.1111/j.1467-7687.2010.00973.x
   Desmarais C, 2012, J SPEECH LANG HEAR R, V55, P45, DOI 10.1044/1092-4388(2011/10-0246)
   Duncan CC, 2009, CLIN NEUROPHYSIOL, V120, P1883, DOI 10.1016/j.clinph.2009.07.045
   Eigsti IM, 2011, DEV PSYCHOPATHOL, V23, P629, DOI 10.1017/S0954579411000204
   Friederici AD, 2002, NEUROREPORT, V13, P1251, DOI 10.1097/00001756-200207190-00006
   Garin D. P., 2008, SARAT NAUCH MED ZH, V4, P86
   Gorjainova G. Y., 2019, JEL RES MEZHD S NEJR
   Govindan RM, 2010, CEREB CORTEX, V20, P561, DOI 10.1093/cercor/bhp122
   Hanna J, 2017, BRAIN LANG, V175, P86, DOI 10.1016/j.bandl.2017.10.002
   Helder EJ, 2014, CHILD NEUROPSYCHOL, V20, P470, DOI 10.1080/09297049.2013.819846
   Hodanovich M. Y., 2009, ZH VYSSHEJ NERVNOJ D, V59, P296
   Innis SM, 2001, J PEDIATR-US, V139, P532, DOI 10.1067/mpd.2001.118429
   Kornilov SA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40007-9
   Kuhl PK, 2003, P NATL ACAD SCI USA, V100, P9096, DOI 10.1073/pnas.1532872100
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kumar A, 2014, J CHILD NEUROL, V29, P318, DOI 10.1177/0883073812474098
   Kushnerenko E, 2002, NEUROREPORT, V13, P1843, DOI 10.1097/00001756-200210280-00002
   Leppanen PHT, 2012, NEUROPHYSIOL CLIN, V42, P35, DOI 10.1016/j.neucli.2011.08.005
   Lewkowicz DJ, 2009, TRENDS COGN SCI, V13, P470, DOI 10.1016/j.tics.2009.08.004
   Loman MM, 2009, J DEV BEHAV PEDIATR, V30, P426, DOI 10.1097/DBP.0b013e3181b1fd08
   Marklund E, 2019, DEV COGN NEUROS-NETH, V36, DOI 10.1016/j.dcn.2019.100622
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   Morozova A.V., 2012, MEZHDUNARODNYJ NEVRO, V3, P26
   Muhamedrahimov RJ, 2014, INFANT MENT HEALTH J, V35, P111, DOI 10.1002/imhj.21435
   Muhamedrahimov RJ, 2005, J APPL DEV PSYCHOL, V26, P477, DOI 10.1016/j.appdev.2005.06.002
   Naatanen R, 2003, INT J PSYCHOPHYSIOL, V48, P179, DOI 10.1016/S0167-8760(03)00053-9
   Naatanen R, 2004, CLIN NEUROPHYSIOL, V115, P140, DOI 10.1016/j.clinph.2003.04.001
   Nagornova Z. V., 2018, FIZIOLOGIJA CHELOVEK, V44, P84
   Neuhoff N, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034909
   Pena M, 2012, J NEUROSCI, V32, P11159, DOI 10.1523/JNEUROSCI.6516-11.2012
   Petrov M. V., 2017, VESTNIK SANKT PET 16, V7, P91
   Petrov M. V., 2018, INT J PSYCHOPHYSIOL, V131, pS51, DOI [10.1016/j.ijpsycho.2018.07.155, DOI 10.1016/J.IJPSYCHO.2018.07.155]
   Rivera-Gaxiola M, 2005, NEUROREPORT, V16, P495, DOI 10.1097/00001756-200504040-00015
   Savel'eva N. A., 2015, FUNDAMENTALNYE ISSLE, V2, P346
   Scott KA, 2011, J SPEECH LANG HEAR R, V54, P1153, DOI 10.1044/1092-4388(2010/10-0075)
   van Zuijen TL, 2013, DEVELOPMENTAL SCI, V16, P554, DOI 10.1111/desc.12049
   Vasil'eva M Iu, 2015, Ross Fiziol Zh Im I M Sechenova, V101, P85
   Vorria P, 2014, ADOPT FOSTER, V38, P271, DOI 10.1177/0308575914543237
   Weikum WM, 2012, P NATL ACAD SCI USA, V109, P17221, DOI 10.1073/pnas.1121263109
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wible B, 2004, BIOL PSYCHOL, V67, P299, DOI 10.1016/j.biopsycho.2004.02.002
   Windsor J, 2007, J SPEECH LANG HEAR R, V50, P1365, DOI 10.1044/1092-4388(2007/095)
   Winkler I, 1999, PSYCHOPHYSIOLOGY, V36, P638, DOI 10.1017/S0048577299981908
   Winkler I, 2007, J PSYCHOPHYSIOL, V21, P147, DOI 10.1027/0269-8803.21.34.147
   Zhavoronkova L A, 2010, Fiziol Cheloveka, V36, P32
   Zhukova M., 2015, 7 ANN M SOC NEUR LAN, P75
NR 53
TC 1
Z9 1
U1 0
U2 7
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD SEP 25
PY 2019
VL 13
AR 300
DI 10.3389/fnhum.2019.00300
PG 8
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA JA3FU
UT WOS:000487706000001
PM 31607875
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Wass, M
   Anmyr, L
   Lyxell, B
   Ostlund, E
   Karltorp, E
   Lofkvist, U
AF Wass, Malin
   Anmyr, Lena
   Lyxell, Bjorn
   Ostlund, Elisabet
   Karltorp, Eva
   Lofkvist, Ulrike
TI Predictors of Reading Comprehension in Children With Cochlear Implants
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE reading comprehension; children with CI; vocabulary; word decoding;
   cochlear implants; simple view of reading; lexical quality hypothesis
ID VOCABULARY KNOWLEDGE; MATERNAL EDUCATION; SPOKEN LANGUAGE;
   WORKING-MEMORY; HEARING-LOSS; SKILLS; DEAF; ACHIEVEMENT; COMPONENTS;
   MODEL
AB Children with a profound hearing loss who have been implanted with cochlear implants (CI), vary in terms of their language and reading skills. Some of these children have strong language skills and are proficient readers whereas others struggle with language and both the decoding and comprehension aspects of reading. Reading comprehension is dependent on a number of skills where decoding, spoken language comprehension and receptive vocabulary have been found to be the strongest predictors of performance. Children with CI have generally been found to perform more poorly than typically hearing peers on most predictors of reading comprehension including word decoding, vocabulary and spoken language comprehension, as well as working memory. The purpose of the current study was to investigate the relationships between reading comprehension and a number of predictor variables in a sample of twenty-nine 11-12-year-old children with profound hearing loss, fitted with CI. We were particularly interested in the extent to which reading comprehension in children with CI at this age is dependent on decoding and receptive vocabulary. The predictor variables that we set out to study were word decoding, receptive vocabulary, phonological skills, and working memory. A second purpose was to explore the relationships between reading comprehension and demographic factors, i.e., parental education, speech perception and age of implantation. The results from these 29 children indicate that receptive vocabulary is the most influential predictor of reading comprehension in this group of children although phonological decoding is, of course, fundamental.
C1 [Wass, Malin] Lulea Univ Technol, Dept Business Adm Technol & Social Sci, Lulea, Sweden.
   [Anmyr, Lena; Karltorp, Eva; Lofkvist, Ulrike] Karolinska Inst, Dept Clin Sci Intervent & Technol, Stockholm, Sweden.
   [Anmyr, Lena] Karolinska Univ Hosp, Dept Social Work Hlth, Stockholm, Sweden.
   [Lyxell, Bjorn; Lofkvist, Ulrike] Univ Oslo, Dept Special Needs Educ, Oslo, Norway.
   [Lyxell, Bjorn] Linkoping Univ, Dept Behav Sci & Learning, Linkoping, Sweden.
   [Ostlund, Elisabet; Karltorp, Eva] Karolinska Univ Hosp, Dept Otorhinolaryogol, Stockholm, Sweden.
RP Wass, M (corresponding author), Lulea Univ Technol, Dept Business Adm Technol & Social Sci, Lulea, Sweden.
EM malin.wass@ltu.se
RI lofkvist, ulrika/D-1787-2015
OI lofkvist, ulrika/0000-0003-0919-0384; Karltorp, Eva/0000-0003-0380-2378
FU Riksbankens Jubileumsfond [P15-0442:1]; Horselforskningsfonden
   [2014-460]; Jerringfonden
FX This work was supported by Riksbankens Jubileumsfond P15-0442:1,
   Horselforskningsfonden Dnr 2014-460, and Jerringfonden.
CR Asker-Arnason L, 2007, ACTA NEUROPSYCHOL, V5, P163
   Bell N, 2019, J SPEECH LANG HEAR R, V62, P456, DOI 10.1044/2018_JSLHR-H-17-0469
   Braze D, 2007, J LEARN DISABIL-US, V40, P226, DOI 10.1177/00222194070400030401
   Byrne B, 2009, J NEUROLINGUIST, V22, P219, DOI 10.1016/j.jneuroling.2008.09.003
   Coltheart M, 2001, PSYCHOL REV, V108, P204, DOI 10.1037//0033-295X.108.1.204
   Connor CM, 2004, J SPEECH LANG HEAR R, V47, P509, DOI 10.1044/1092-4388(2004/040)
   Coppens KM, 2013, J SPEECH LANG HEAR R, V56, P654, DOI 10.1044/1092-4388(2012/11-0138)
   Currie NK, 2015, J EXP CHILD PSYCHOL, V137, P57, DOI 10.1016/j.jecp.2015.03.005
   Dillon CM, 2012, J DEAF STUD DEAF EDU, V17, P205, DOI 10.1093/deafed/enr043
   Dollaghan CA, 1999, J SPEECH LANG HEAR R, V42, P1432, DOI 10.1044/jslhr.4206.1432
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   Ehri LC, 2005, SCI STUD READ, V9, P167, DOI 10.1207/s1532799xssr0902_4
   Ehri LC, 2014, SCI STUD READ, V18, P5, DOI 10.1080/10888438.2013.819356
   Fagan MK, 2010, J DEAF STUD DEAF EDU, V15, P149, DOI 10.1093/deafed/enq001
   Fitzpatrick EM, 2016, PEDIATRICS, V137, DOI 10.1542/peds.2015-1974
   Geers AE, 2003, EAR HEARING, V24, p59S, DOI 10.1097/01.AUD.0000051690.43989.5D
   Geers AE, 2017, PEDIATRICS, V140, DOI 10.1542/peds.2016-3489
   Geers Ann E, 2011, Ear Hear, V32, p49S, DOI 10.1097/AUD.0b013e3181fa41fa
   Geers AE, 2009, J DEAF STUD DEAF EDU, V14, P371, DOI 10.1093/deafed/enn046
   Gough P.B., 1986, REMEDIAL SPECIAL ED, V7, DOI [DOI 10.1177/074193258600700104, https://doi.org/10.1177/074193258600700104, 10.1177/074193258600700104]
   Harris M, 2011, J DEAF STUD DEAF EDU, V16, P24, DOI 10.1093/deafed/enq031
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   Kyle FE, 2006, J DEAF STUD DEAF EDU, V11, P273, DOI 10.1093/deafed/enj037
   Lervag A, 2010, J CHILD PSYCHOL PSYC, V51, P612, DOI 10.1111/j.1469-7610.2009.02185.x
   Lieu JEC, 2010, PEDIATRICS, V125, pE1348, DOI 10.1542/peds.2009-2448
   Magnuson K, 2007, DEV PSYCHOL, V43, P1497, DOI 10.1037/0012-1649.43.6.1497
   Markwardt F., 1998, PEABODY INDIVIDUAL A
   Melby-Lervag M, 2014, PSYCHOL BULL, V140, P409, DOI 10.1037/a0033890
   Naucler K, 1993, BEDOMNING SPRAKLIG M
   Olson RK, 2011, SCI STUD READ, V15, P26, DOI 10.1080/10888438.2011.536128
   Ouellette G, 2010, READ WRIT, V23, P189, DOI 10.1007/s11145-008-9159-1
   Perfetti C, 2007, SCI STUD READ, V11, P357, DOI 10.1080/10888430701530730
   Perfetti C, 2014, SCI STUD READ, V18, P22, DOI 10.1080/10888438.2013.827687
   Protopapas A, 2007, SCI STUD READ, V11, P165, DOI 10.1080/10888430701344322
   Raven J., 2003, MANUAL RAVENS PROGR
   Samuelsson S., 2009, LAST HOGREFE PSYKOLO
   Stiles DJ, 2012, J SPEECH LANG HEAR R, V55, P154, DOI 10.1044/1092-4388(2011/11-0021)
   Tunmer W, 2010, J LEARN DISABIL-US, V43, P229, DOI 10.1177/0022219409345009
   Tunmer WE, 2012, J LEARN DISABIL-US, V45, P453, DOI 10.1177/0022219411432685
   Verhoeven L, 2008, APPL COGNITIVE PSYCH, V22, P407, DOI 10.1002/acp.1414
   Vermeulen AM, 2007, J DEAF STUD DEAF EDU, V12, P283, DOI 10.1093/deafed/enm017
   von Mentzer CN, 2014, SCAND J PSYCHOL, V55, P448, DOI 10.1111/sjop.12149
   von Muenster K, 2014, INT J PEDIATR OTORHI, V78, P433, DOI 10.1016/j.ijporl.2013.12.009
   Walker EA, 2019, J SPEECH LANG HEAR R, V62, P525, DOI 10.1044/2018_JSLHR-L-ASTM-18-0250
   Wass M, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00143
   Wass M, 2008, SCAND J PSYCHOL, V49, P559, DOI 10.1111/j.1467-9450.2008.00680.x
   Yoshinaga-Itano C, 2010, OTOL NEUROTOL, V31, P1268, DOI 10.1097/MAO.0b013e3181f1ce07
NR 47
TC 1
Z9 1
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD SEP 24
PY 2019
VL 10
AR 2155
DI 10.3389/fpsyg.2019.02155
PG 9
WC Psychology, Multidisciplinary
SC Psychology
GA JA1RH
UT WOS:000487594100001
PM 31607988
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Broderick, MP
   Anderson, AJ
   Lalor, EC
AF Broderick, Michael P.
   Anderson, Andrew J.
   Lalor, Edmund C.
TI Semantic Context Enhances the Early Auditory Encoding of Natural Speech
SO JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE computational linguistics; EEG; natural speech; perception; semantic
   processing; top-down effects
ID CORTICAL ENTRAINMENT; NEURAL RESPONSES; COCKTAIL PARTY; COMPREHENSION;
   CORTEX; BRAIN; RECOGNITION; PERCEPTION; MECHANISMS; SELECTION
AB Speech perception involves the integration of sensory input with expectations based on the context of that speech. Much debate surrounds the issue of whether or not prior knowledge feeds back to affect early auditory encoding in the lower levels of the speech processing hierarchy, or whether perception can be best explained as a purely feedforward process. Although there has been compelling evidence on both sides of this debate, experiments involving naturalistic speech stimuli to address these questions have been lacking. Here, we use a recently introduced method for quantifying the semantic context of speech and relate it to a commonly used method for indexing low-level auditory encoding of speech. The relationship between these measures is taken to be an indication of how semantic context leading up to a word influences how its low-level acoustic and phonetic features are processed. We record EEG from human participants (both male and female) listening to continuous natural speech and find that the early cortical tracking of a word's speech envelope is enhanced by its semantic similarity to its sentential context. Using a forward modeling approach, we find that prediction accuracy of the EEG signal also shows the same effect. Furthermore, this effect shows distinct temporal patterns of correlation depending on the type of speech input representation (acoustic or phonological) used for the model, implicating a top-down propagation of information through the processing hierarchy. These results suggest a mechanism that links top-down prior information with the early cortical entrainment of words in natural, continuous speech.
C1 [Broderick, Michael P.; Lalor, Edmund C.] Trinity Coll Dublin, Trinity Ctr Bioengn, Sch Engn, Dublin 2, Ireland.
   [Broderick, Michael P.; Lalor, Edmund C.] Trinity Coll Dublin, Trinity Coll Inst Neurosci, Dublin 2, Ireland.
   [Anderson, Andrew J.; Lalor, Edmund C.] Univ Rochester, Dept Biomed Engn, 601 Elmwood Ave, Rochester, NY 14627 USA.
   [Anderson, Andrew J.; Lalor, Edmund C.] Univ Rochester, Dept Neurosci, 601 Elmwood Ave, Rochester, NY 14627 USA.
   [Anderson, Andrew J.; Lalor, Edmund C.] Univ Rochester, Del Monte Inst Neurosci, 601 Elmwood Ave, Rochester, NY 14627 USA.
RP Broderick, MP (corresponding author), Trinity Coll Dublin, Trinity Ctr Bioengn, Sch Engn, Dublin 2, Ireland.; Broderick, MP (corresponding author), Trinity Coll Dublin, Trinity Coll Inst Neurosci, Dublin 2, Ireland.
EM brodermi@tcd.ie
OI Broderick, Michael/0000-0001-9765-5537; Lalor,
   Edmund/0000-0002-2498-6631
FU Irish Research Council Government of Ireland Postgraduate Scholarship
   scheme; Science Foundation Ireland Career Development AwardScience
   Foundation Ireland
FX This work was supported by Irish Research Council Government of Ireland
   Postgraduate Scholarship scheme to M.P.B. and Science Foundation Ireland
   Career Development Award to E.C.L.
CR Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Aiken SJ, 2008, EAR HEARING, V29, P139, DOI 10.1097/AUD.0b013e31816453dc
   Anderson AJ, 2017, CEREB CORTEX, V27, P4379, DOI 10.1093/cercor/bhw240
   Badre D, 2005, NEURON, V47, P907, DOI 10.1016/j.neuron.2005.07.023
   Baroni M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P238
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Binder JR, 2009, CEREB CORTEX, V19, P2767, DOI 10.1093/cercor/bhp055
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Brodbeck C, 2018, CURR BIOL, V28, P3976, DOI 10.1016/j.cub.2018.10.042
   Broderick MP, 2018, CURR BIOL, V28, P803, DOI 10.1016/j.cub.2018.01.080
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477
   Crosse MJ, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00604
   Crosse MJ, 2016, J NEUROSCI, V36, P9888, DOI 10.1523/JNEUROSCI.1396-16.2016
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014
   Davis MF, 2011, J OCCUP ENVIRON MED, V53, P190, DOI [10.1097/JOM.0b013e31820805d5, 10.1162/jocn_a_00084]
   Davis MH, 2003, J NEUROSCI, V23, P3423
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Di Liberto GM, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0084-18.2018
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Ding N, 2014, NEUROIMAGE, V88, P41, DOI 10.1016/j.neuroimage.2013.10.054
   Ding N, 2013, J NEUROSCI, V33, P5728, DOI 10.1523/JNEUROSCI.5297-12.2013
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Ding N, 2012, J NEUROPHYSIOL, V107, P78, DOI 10.1152/jn.00297.2011
   EHRLICH SF, 1981, J VERB LEARN VERB BE, V20, P641, DOI 10.1016/S0022-5371(81)90220-6
   Federmeier KD, 1999, J MEM LANG, V41, P469, DOI 10.1006/jmla.1999.2660
   Frank SL, 2017, LANG COGN NEUROSCI, V32, P1192, DOI 10.1080/23273798.2017.1323109
   Frank SL, 2013, TOP COGN SCI, V5, P475, DOI 10.1111/tops.12025
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   Garofolo J., 1993, TIMIT ACOUSTIC PHONE
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Gorman K., 2011, CANADIAN ACOUSTICS, V39, P192
   GREENWOOD D, 1961, J ACOUST SOC AM, V33, P484, DOI 10.1121/1.1908699
   Gwilliams L, 2018, P 8 WORKSH COGN MOD, P29
   Hale John, 2001, 2 M N AM CHAPT ASS C
   Hemingway Ernest, 1952, OLD MAN SEA
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Huth AG, 2016, NATURE, V532, P453, DOI 10.1038/nature17637
   Hyvarinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722
   Jin PQ, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07773-y
   Khalighinejad B, 2017, J NEUROSCI, V37, P2176, DOI 10.1523/JNEUROSCI.2383-16.2017
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299
   KUTAS M, 1980, SCIENCE, V207, P203, DOI 10.1126/science.7350657
   Lalor EC, 2010, EUR J NEUROSCI, V31, P189, DOI 10.1111/j.1460-9568.2009.07055.x
   Leonard MK, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13619
   Liebenthal E, 2005, CEREB CORTEX, V15, P1621, DOI 10.1093/cercor/bhi040
   LIEBERMAN P, 1963, LANG SPEECH, V6, P172, DOI 10.1177/002383096300600306
   Lin M., 2013, INFORM SYST RES, V7047, P1
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Mattys SL, 2009, COGNITIVE PSYCHOL, V59, P203, DOI 10.1016/j.cogpsych.2009.04.001
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Mesgarani N, 2009, J NEUROPHYSIOL, V102, P3329, DOI 10.1152/jn.91128.2008
   Mikolov T, 2013, INT C LEARN REPR ICL
   Mikolov T., 2013, CORR, P3111, DOI DOI 10.1162/JMLR.2003.3.4-5.951
   MILLER GA, 1951, J EXP PSYCHOL, V41, P329, DOI 10.1037/h0062491
   Norman-Haignere S, 2013, J NEUROSCI, V33, P19451, DOI 10.1523/JNEUROSCI.2880-13.2013
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   O'Sullivan JA, 2015, CEREB CORTEX, V25, P1697, DOI 10.1093/cercor/bht355
   Oganian Y., 2018, SPEECH ENVELOPE LAND, DOI [10.1101/388280, DOI 10.1101/388280]
   Peelle JE, 2018, EAR HEARING, V39, P204, DOI 10.1097/AUD.0000000000000494
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Poeppel D, 2014, CURR OPIN NEUROBIOL, V28, P142, DOI 10.1016/j.conb.2014.07.005
   Power AJ, 2012, EUR J NEUROSCI, V35, P1497, DOI 10.1111/j.1460-9568.2012.08060.x
   Pynte J, 2009, VISION RES, V49, P544, DOI 10.1016/j.visres.2008.12.016
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580
   Smith NJ, 2013, COGNITION, V128, P302, DOI 10.1016/j.cognition.2013.02.013
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   Strauss A, 2013, J COGNITIVE NEUROSCI, V25, P1383, DOI 10.1162/jocn_a_00389
   Teoh ES, 2019, EUR J NEUROSCI, V50, P3831, DOI 10.1111/ejn.14510
   Travis KE, 2013, CEREB CORTEX, V23, P2370, DOI 10.1093/cercor/bhs228
   Wang L, 2018, ELIFE, V7, DOI 10.7554/eLife.39061
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
NR 75
TC 6
Z9 6
U1 1
U2 14
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
SN 0270-6474
EI 1529-2401
J9 J NEUROSCI
JI J. Neurosci.
PD SEP 18
PY 2019
VL 39
IS 38
BP 7564
EP 7575
DI 10.1523/JNEUROSCI.0584-19.2019
PG 12
WC Neurosciences
SC Neurosciences & Neurology
GA IY5AI
UT WOS:000486403700010
PM 31371424
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Zhang, N
   Zhang, QF
AF Zhang, Ning
   Zhang, Qingfang
TI Rhythmic pattern facilitates speech production: An ERP study
SO SCIENTIFIC REPORTS
LA English
DT Article
ID MISMATCH NEGATIVITY MMN; PERSISTENCE; REGULARITY; ATTENTION; RESPONSES;
   METER
AB Rhythm affects the speech perception of events unfolding overtime. However, it is not clear to what extent the rhythm could affect the processes of sentence speech production. In this event-related potential (ERP) study, we examined whether a particular rhythmic pattern could affect the planning of speech production before articulation. We recorded electrophysiological (EEG) and behavioural (reaction time) data while participants read aloud a target speech in Chinese. Target speeches were sentences or phrases consisting four characters, with regular (e.g., the 2 + 2 pattern; numbers in the brackets represent the number of syllables) or irregular (e.g., 1 + 3) rhythmic patterns, which were preceded by congruent or incongruent musical rhythmic patterns formed by simple pure tones with different temporal intervals. Behavioural and ERP findings indicated a rhythmic priming effect in comparing congruent and incongruent conditions in the regular target speeches, but not in the irregular ones. An early component (N100) that was elicited in response to target speeches that were rhythmically mismatched to primes was linked to the detection of hierarchical linguistic units, which did not conform to expectations. A later negative component (N400) was thought to reflect the violation of expectation on rhythmic pattern in speech production. These findings suggest that rhythmic pattern constrains grammatical and prosodic encoding during speech production, and support the hypothesis that speakers form a grammatical or a prosodic abstract frame before articulation.
C1 [Zhang, Ning; Zhang, Qingfang] Renmin Univ China, Dept Psychol, Beijing 100872, Peoples R China.
RP Zhang, QF (corresponding author), Renmin Univ China, Dept Psychol, Beijing 100872, Peoples R China.
EM qingfang.zhang@ruc.edu.cn
FU Key project of Beijing Social Science Foundation in China [16YYA006];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [31471074]; Fundamental Research funds for
   the Central UniversitiesFundamental Research Funds for the Central
   Universities; Research Funds of Renmin University of China [18XNLG28]
FX This research was supported by grants from the Key project of Beijing
   Social Science Foundation in China (16YYA006), the National Natural
   Science Foundation of China (31471074), and the Fundamental Research
   funds for the Central Universities; and the Research Funds of Renmin
   University of China (18XNLG28) to Qingfang Zhang.
CR Arnal LH, 2015, CEREB CORTEX, V25, P3077, DOI 10.1093/cercor/bhu103
   Bedoin N, 2018, ANN PHYS REH MED, V61
   Bedoin N, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00245
   BOCK JK, 1986, COGNITIVE PSYCHOL, V18, P355, DOI 10.1016/0010-0285(86)90004-6
   Boulenger V, 2011, BRAIN LANG, V116, P51, DOI 10.1016/j.bandl.2010.09.011
   Cason N, 2015, ACTA PSYCHOL, V155, P43, DOI 10.1016/j.actpsy.2014.12.002
   Cason N, 2015, NEUROPSYCHOLOGY, V29, P102, DOI 10.1037/neu0000115
   Cason N, 2012, NEUROPSYCHOLOGIA, V50, P2652, DOI 10.1016/j.neuropsychologia.2012.07.018
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234
   Chern A, 2018, J EXP CHILD PSYCHOL, V173, P371, DOI 10.1016/j.jecp.2018.04.007
   CUTLER A, 1994, COGNITION, V50, P79, DOI 10.1016/0010-0277(94)90021-3
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x
   Feng S, 1995, THESIS
   Feng S, 2018, HANYU YUNLV YUFA JIA, P78
   FROMKIN VA, 1971, LANGUAGE, V47, P27, DOI 10.2307/412187
   Garrett M. F, 1975, PSYCHOL LEARN MOTIV, V9, P505
   Garrod S, 2004, TRENDS COGN SCI, V8, P8, DOI 10.1016/j.tics.2003.10.016
   Gould L, 2016, LANG COGN NEUROSCI, V31, P236, DOI 10.1080/23273798.2015.1089360
   Haegens S, 2018, NEUROSCI BIOBEHAV R, V86, P150, DOI 10.1016/j.neubiorev.2017.12.002
   Hardy MW, 2013, FRONT INTEGR NEUROSC, V7, DOI 10.3389/fnint.2013.00019
   Hausen M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00566
   Herholz SC, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-42
   Howell D. C., 2010, STAT METHODS PSYCHOL, P372
   Indefrey P, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00255
   Iversen J. R., 2008, P 10 INT C MUS PERC
   Jones MR, 2002, PSYCHOL SCI, V13, P313, DOI 10.1111/1467-9280.00458
   JONES MR, 1989, PSYCHOL REV, V96, P459, DOI 10.1037/0033-295X.96.3.459
   Jungers M. K., 2002, COGN PROCESS, V2, P21
   Jungers M, 2009, LANG COGNITIVE PROC, V24, P611, DOI 10.1080/01690960802602241
   Jusczyk PW, 1999, COGNITIVE PSYCHOL, V39, P159, DOI 10.1006/cogp.1999.0716
   Kjelgaard MM, 1999, J MEM LANG, V40, P153, DOI 10.1006/jmla.1998.2620
   Kotz SA, 2005, BRAIN LANG, V95, P70, DOI 10.1016/j.bandl.2005.07.039
   Kotz SA, 2015, ANN NY ACAD SCI, V1337, P62, DOI 10.1111/nyas.12657
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Large EW, 1999, PSYCHOL REV, V106, P119, DOI 10.1037/0033-295X.106.1.119
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1
   Liberman M. Y., 1975, THESIS
   List A, 2007, BRAIN RES, V1153, P122, DOI 10.1016/j.brainres.2007.03.040
   Luo YY, 2010, NEUROIMAGE, V49, P2836, DOI 10.1016/j.neuroimage.2009.10.008
   Magne C, 2007, CEREB CORTEX, V17, P2659, DOI 10.1093/cercor/bhl174
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 2005, PSYCHOPHYSIOLOGY, V42, P25, DOI 10.1111/j.1469-8986.2005.00256.x
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9
   Patel AD, 2014, PLOS BIOL, V12, DOI 10.1371/journal.pbio.1001821
   Pena M, 2002, SCIENCE, V298, P604, DOI 10.1126/science.1072901
   Peretz I, 2003, ANN NY ACAD SCI, V999, P58, DOI 10.1196/annals.1284.006
   Pickering MJ, 2008, PSYCHOL BULL, V134, P427, DOI 10.1037/0033-2909.134.3.427
   Pickering MJ, 1998, J MEM LANG, V39, P633, DOI 10.1006/jmla.1998.2592
   PITT MA, 1990, J EXP PSYCHOL HUMAN, V16, P564, DOI 10.1037/0096-1523.16.3.564
   Przybylski L, 2013, NEUROPSYCHOLOGY, V27, P121, DOI 10.1037/a0031277
   Quene H, 2005, PHONETICA, V62, P1, DOI 10.1159/000087222
   Repp BH, 2005, PSYCHON B REV, V12, P969, DOI 10.3758/BF03206433
   Rohenkohl G, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0014620
   Rothermich K, 2012, NEUROPSYCHOLOGIA, V50, P232, DOI 10.1016/j.neuropsychologia.2011.10.025
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Schmidt-Kassow M, 2008, BRAIN RES, V1226, P144, DOI 10.1016/j.brainres.2008.06.017
   Schmidt-Kassow M, 2009, NEUROREPORT, V20, P1643, DOI 10.1097/WNR.0b013e328333b0c6
   Snyder JS, 2005, COGNITIVE BRAIN RES, V24, P117, DOI 10.1016/j.cogbrainres.2004.12.014
   Steinhauer K, 1999, NAT NEUROSCI, V2, P191, DOI 10.1038/5757
   ten Oever S, 2017, J NEUROSCI, V37, P4903, DOI 10.1523/JNEUROSCI.3658-16.2017
   Tooley KM, 2018, MEM COGNITION, V46, P625, DOI 10.3758/s13421-018-0789-5
   Tooley KM, 2014, J EXP PSYCHOL LEARN, V40, P348, DOI 10.1037/a0034900
   van den Brink D, 2006, J EXP PSYCHOL LEARN, V32, P364, DOI 10.1037/0278-7393.32.3.364
   Vuust P, 2005, NEUROIMAGE, V24, P560, DOI 10.1016/j.neuroimage.2004.08.039
   Wagner M, 2010, LANG COGNITIVE PROC, V25, P905, DOI 10.1080/01690961003589492
   Wilsch A, 2015, PSYCHOPHYSIOLOGY, V52, P910, DOI 10.1111/psyp.12413
   ZEC D, 1990, PHONOLOGY-SYNTAX CONNECTION, P365
   Zhou XL, 1999, LANG COGNITIVE PROC, V14, P525, DOI 10.1080/016909699386185
NR 69
TC 0
Z9 0
U1 3
U2 7
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD SEP 10
PY 2019
VL 9
AR 12974
DI 10.1038/s41598-019-49375-8
PG 11
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA IW4YK
UT WOS:000484985500022
PM 31506472
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Ambridge, B
AF Ambridge, Ben
TI Against stored abstractions: A radical exemplar model of language
   acquisition
SO FIRST LANGUAGE
LA English
DT Article
DE Abstraction; child language acquisition; construction; exemplar account;
   instance-based; memory-based; morphology; n-grams; phonology; syntax;
   word meaning
ID ENGLISH PAST-TENSE; PHONOLOGICAL NEIGHBORHOOD DENSITY;
   ELICITED-PRODUCTION; CHILDRENS ACQUISITION; ARGUMENT-STRUCTURE;
   CONNECTIONIST MODEL; SPEECH-PERCEPTION; LINKING ELEMENTS; VERB
   MORPHOLOGY; INPUT FREQUENCY
AB The goal of this article is to make the case for a radical exemplar account of child language acquisition, under which unwitnessed forms are produced and comprehended by on-the-fly analogy across multiple stored exemplars, weighted by their degree of similarity to the target with regard to the task at hand. Across the domains of (1) word meanings, (2) morphologically inflected words, (3) n-grams, (4) sentence-level constructions and (5) phonetics and phonology, accounts based on independently-represented abstractions (whether formal rules or prototype categories) fail for two reasons. First, it is not possible to posit abstractions that delineate possible and impossible form; e.g. that (1) rule in pool tables and data tables, but rule out chairs, (2) rule in the past-tense forms netted and bet but rule out *setted and *jet, (3) rule in the bigram f+t but rule out (probabilistically) v+t, (4) rule in both John feared Bill and John frightened Bill but rule out *John laughed Bill, (5) rule in Speaker A but rule out Speaker B as the person who produced a particular word (e.g. Sa'urday). Second, for each domain, empirical data provide evidence of exemplar storage that cannot be captured by putative abstractions: e.g. speakers prefer and/or show an advantage for (1) exemplar variation even within word-meaning 'category boundaries', (2) novel inflected forms that are similar to existing exemplars, (3) n-grams that have occurred frequently in the input, (4) SVO sentences with he as SUBJECT and it as OBJECT and (5) repeated productions of 'the same' word that are phonologically similar or, better still, identical. An exemplar account avoids an intractable lumping-or-splitting dilemma facing abstraction-based accounts and provides a unitary explanation of language acquisition across all domains; one that is consistent with models and empirical findings from the computational modelling and neuroimaging literature.
C1 [Ambridge, Ben] Univ Liverpool, Liverpool, Merseyside, England.
   [Ambridge, Ben] ESRC Int Ctr Language & Commun Dev LuCiD, Liverpool, Merseyside, England.
RP Ambridge, B (corresponding author), Univ Liverpool, Psychol Sci, Eleanor Rathbone Bldg,Bedford St South, Liverpool L69 7ZA, Merseyside, England.
EM ben.ambridge@liverpool.ac.uk
OI Ambridge, Ben/0000-0003-2389-8477
FU European Research Council (ERC) under the European UnionEuropean
   Research Council (ERC) [681296]; Economic and Social Research CouncilUK
   Research & Innovation (UKRI)Economic & Social Research Council (ESRC)
   [ES/L008955/1]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship and/or publication of this article: This
   project has received funding from the European Research Council (ERC)
   under the European Union's Horizon 2020 research and innovation
   programme (Grant Agreement No. 681296: CLASS). Ben Ambridge is a
   Professor in the International Centre for Language and Communicative
   Development (LuCiD) at The University of Liverpool. The support of the
   Economic and Social Research Council [ES/L008955/1] is gratefully
   acknowledged.
CR Abbot-Smith K, 2001, COGNITIVE DEV, V16, P679, DOI 10.1016/S0885-2014(01)00054-5
   Abbot-Smith K, 2006, COGNITIVE SCI, V30, P995, DOI 10.1207/s15516709cog0000_61
   Abbot-Smith K, 2006, LINGUIST REV, V23, P275, DOI 10.1515/TLR.2006.011
   Abney S., 1987, THESIS
   Aguado-Orea J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119613
   Akhtar N, 1999, J CHILD LANG, V26, P339, DOI 10.1017/S030500099900375X
   Albright A, 2003, COGNITION, V90, P119, DOI 10.1016/S0010-0277(03)00146-X
   Ambridge B., 2015, HDB LANGUAGE EMERGEN, P478, DOI [10.1002/9781118346136.ch22, DOI 10.1002/9781118346136.CH22]
   Ambridge B., 2011, CHILD LANGUAGE ACQUI
   Ambridge B, 2008, COGNITION, V106, P87, DOI 10.1016/j.cognition.2006.12.015
   Ambridge B, 2016, COGNITIVE SCI, V40, P1435, DOI 10.1111/cogs.12277
   Ambridge B, 2014, LANGUAGE, V90, pE53, DOI 10.1353/lan.2014.0051
   Ambridge B, 2010, DEV PSYCHOL, V46, P1497, DOI 10.1037/a0020668
   Ambridge B, 2009, COGNITIVE SCI, V33, P1301, DOI 10.1111/j.1551-6709.2009.01055.x
   Arnon I, 2011, LANG LEARN DEV, V7, P107, DOI 10.1080/15475441.2010.505489
   Arnon I, 2010, J MEM LANG, V62, P67, DOI 10.1016/j.jml.2009.09.005
   Ashby FG, 2017, PSYCHOL REV, V124, P472, DOI 10.1037/rev0000064
   Aylett M, 2006, J ACOUST SOC AM, V119, P3048, DOI 10.1121/1.2188331
   Baayen R. H., 2016, SEMANTICS DIALECTOME, P1
   Baayen RH, 2013, LANG SPEECH, V56, P329, DOI 10.1177/0023830913484896
   Bannard C, 2008, PSYCHOL SCI, V19, P241, DOI 10.1111/j.1467-9280.2008.02075.x
   BARSALOU LW, 1983, MEM COGNITION, V11, P211, DOI 10.3758/BF03196968
   Bidgood A., COGNITIVE SCI UNPUB
   Blything RP, 2018, COGNITIVE SCI, V42, P621, DOI 10.1111/cogs.12581
   BOCK K, 1990, COGNITION, V35, P1, DOI 10.1016/0010-0277(90)90035-I
   Bod R, 2006, LINGUIST REV, V23, P291, DOI 10.1515/TLR.2006.012
   Bod R, 2009, COGNITIVE SCI, V33, P752, DOI 10.1111/j.1551-6709.2009.01031.x
   Branigan HP, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X16002028
   Brooks PJ, 1999, LANGUAGE, V75, P720, DOI 10.2307/417731
   Brown R., 1973, 1 LANGUAGE EARLY STA
   Bybee J, 1999, LINGUISTICS, V37, P575, DOI 10.1515/ling.37.4.575
   BYBEE J, 1995, LANG COGNITIVE PROC, V10, P425, DOI 10.1080/01690969508407111
   Bybee J., 2010, LANGUAGE USAGE AND C
   Bybee J. L., 1985, MORPHOLOGY STUDY REL, V9
   Cabeza R, 2013, PERSPECT PSYCHOL SCI, V8, P49, DOI 10.1177/1745691612469033
   Carey S., 1978, PAPERS REPORTS CHILD, P17
   Chandler S, 2017, LANG COGN, V9, P52, DOI 10.1017/langcog.2015.24
   Chandler S, 2010, COGN LINGUIST, V21, P371, DOI 10.1515/COGL.2010.014
   Chandler Steve, 2002, ANALOGICAL MODELING, P51, DOI 10.1075/ hcp. 10.07cha
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234
   Chang F, 2003, COGNITION, V90, P29, DOI 10.1016/S0010-0277(03)00123-9
   Chang F, 2002, COGNITIVE SCI, V26, P609, DOI 10.1207/s15516709cog2605_3
   Chang F, 2000, J PSYCHOLINGUIST RES, V29, P217, DOI 10.1023/A:1005101313330
   Chater N, 2018, CURR OPIN BEHAV SCI, V21, P205, DOI 10.1016/j.cobeha.2018.04.001
   Childers JB, 2001, DEV PSYCHOL, V37, P739, DOI 10.1037//0012-1649.37.6.739
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Chomsky N., 1980, LANGUAGE LEARNING DE
   Christiansen MH, 2016, BEHAV BRAIN SCI, V39, DOI 10.1017/S0140525X1500031X
   Conwell E, 2018, LANG SPEECH, V61, P466, DOI 10.1177/0023830917737108
   Corkery M., 2019, ARXIV190601280
   CRAIK FIM, 1974, Q J EXP PSYCHOL, V26, P274, DOI 10.1080/14640747408400413
   CRAIN S, 1987, LANGUAGE, V63, P522, DOI 10.2307/415004
   Croft W., 2001, RADICAL CONSTRUCTION
   Croft William, 2000, EXPLAINING LANGUAGE
   Croft William, 2004, COGNITIVE LINGUISTIC
   Culicover PW, 2017, TOP COGN SCI, V9, P552, DOI 10.1111/tops.12255
   Dabrowska E, 2008, J MEM LANG, V58, P931, DOI 10.1016/j.jml.2007.11.005
   Dabrowska E, 2006, J CHILD LANG, V33, P559, DOI 10.1017/S0305000906007471
   Dabrowska E, 2018, COGNITION, V178, P222, DOI 10.1016/j.cognition.2018.05.018
   Daelemans Walter, 2002, ANALOGICAL MODELING, P157
   Daelemans Walter, 2010, HDB COMPUTATIONAL LI, P154
   Dawdy-Hesterberg LG, 2014, LANG COGN NEUROSCI, V29, P1268, DOI 10.1080/23273798.2014.899377
   Dbrowska E., 2000, LINGUISTICS, V11, P83
   Diesendruck G, 2003, PSYCHOL SCI, V14, P164, DOI 10.1111/1467-9280.t01-1-01436
   Dittmar M, 2008, DEVELOPMENTAL SCI, V11, P575, DOI 10.1111/j.1467-7687.2008.00703.x
   Dodson K, 1998, J CHILD LANG, V25, P605, DOI 10.1017/S0305000998003535
   Eddington D, 2004, LINGUA, V114, P849, DOI 10.1016/S0024-3841(03)00063-9
   Elman JL, 2009, COGNITIVE SCI, V33, P547, DOI 10.1111/j.1551-6709.2009.01023.x
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1016/0364-0213(90)90002-E
   Engelmann F, 2019, COGNITIVE PSYCHOL, V110, P30, DOI 10.1016/j.cogpsych.2019.02.001
   Erk K., 2010, ASS COMP LING C UPPS
   Feldman LB, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X17000358
   FODOR JA, 1988, COGNITION, V28, P3, DOI 10.1016/0010-0277(88)90031-5
   Gertner Y, 2006, PSYCHOL SCI, V17, P684, DOI 10.1111/j.1467-9280.2006.01767.x
   Gillis S., 2000, MODELS LANGUAGE ACQU, P76
   Goldberg Adele, 2006, CONSTRUCTIONS WORK N
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Goldwater MB, 2011, COGNITIVE SCI, V35, P156, DOI 10.1111/j.1551-6709.2010.01150.x
   Granlund S, 2019, J MEM LANG, V107, P169, DOI 10.1016/j.jml.2019.04.004
   Guenther FH, 1996, J ACOUST SOC AM, V100, P1111, DOI 10.1121/1.416296
   Hahn U, 2000, COGNITIVE PSYCHOL, V41, P313, DOI 10.1006/cogp.2000.0737
   Hameroff S, 2014, PHYS LIFE REV, V11, P39, DOI 10.1016/j.plrev.2013.08.002
   Hartshorne JK, 2006, DEVELOPMENTAL SCI, V9, P21, DOI 10.1111/j.1467-7687.2005.00459.x
   Hartshorne JK, 2016, COGNITION, V157, P268, DOI 10.1016/j.cognition.2016.08.008
   Hay J, 2006, LINGUIST REV, V23, P321, DOI 10.1515/TLR.2006.013
   Hay J, 2018, TOP COGN SCI, V10, P696, DOI 10.1111/tops.12326
   HINTZMAN DL, 1984, BEHAV RES METH INS C, V16, P96, DOI 10.3758/BF03202365
   Houston DM, 2000, J EXP PSYCHOL HUMAN, V26, P1570, DOI 10.1037/0096-1523.26.5.1570
   Houston DM, 2003, J EXP PSYCHOL HUMAN, V29, P1143, DOI 10.1037/0096-1523.29.6.1143
   Ibbotson P, 2012, COGNITIVE SCI, V36, P1268, DOI 10.1111/j.1551-6709.2012.01249.x
   Iozzi L., 2009, FIRST LANG, V29, P192, DOI DOI 10.1177/0142723708099453
   Janssen N, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033202
   Johnson K., 2007, EXPT APPROACHES PHON, P25
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Jurafsky D., 2000, FREQUENCY EMERGENCE, P229, DOI DOI 10.1075/TSL.45.13JUR
   JUSCZYK PW, 1993, J PHONETICS, V21, P3, DOI 10.1016/S0095-4470(19)31319-1
   Kellman P. J., 2002, STEVENS HDB EXPT PSY, V3, P259
   Kempson R, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X17000449
   Keuleers E., 2008, THESIS
   Keuleers E, 2007, COGNITIVE PSYCHOL, V54, P283, DOI 10.1016/j.cogpsych.2006.07.002
   Kidd E, 2008, DEVELOPMENTAL SCI, V11, P882, DOI 10.1111/j.1467-7687.2008.00744.x
   Kirjavainen M, 2012, COGN LINGUIST, V23, P273, DOI 10.1515/cog-2012-0009
   Kirov C., 2018, T ASS COMPUTATIONAL, V6, P651, DOI DOI 10.1162/TACL_A_00247
   Kjaerbaek L, 2014, NORD J LINGUIST, V37, P47, DOI 10.1017/S0332586514000067
   Krajewski G, 2011, LANG COGNITIVE PROC, V26, P830, DOI 10.1080/01690965.2010.506062
   Krott A, 2002, BRAIN LANG, V81, P708, DOI 10.1006/brln.2001.2558
   Krott A, 2007, LANG COGNITIVE PROC, V22, P25, DOI 10.1080/01690960500343429
   Krug M., 1998, J ENGLISH LINGUISTIC, V26, P286, DOI DOI 10.1177/007542429802600402
   KRUSCHKE JK, 1992, PSYCHOL REV, V99, P22, DOI 10.1037/0033-295X.99.1.22
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Kunnari S, 2011, J CHILD LANG, V38, P999, DOI 10.1017/S0305000910000528
   LABOV W, 1963, WORD, V19, P273, DOI 10.1080/00437956.1963.11659799
   LANDAU B, 1988, COGNITIVE DEV, V3, P299, DOI 10.1016/0885-2014(88)90014-7
   Langacker R. W., 2009, EMERGENCE STRUCTURE
   Langacker Ronald, 1988, TOPICS COGNITIVE LIN, P127, DOI DOI 10.1075/CILT.50.06LAN
   Lent R, 2012, EUR J NEUROSCI, V35, P1, DOI 10.1111/j.1460-9568.2011.07923.x
   Leonard L. B., 2002, FIRST LANG, V22, P287, DOI DOI 10.1177/014272370202206604
   LIEBERMAN P, 1963, LANG SPEECH, V6, P172, DOI 10.1177/002383096300600306
   Lieven E, 2009, COGN LINGUIST, V20, P481, DOI 10.1515/COGL.2009.022
   LIITTSCHWAGER JC, 1994, DEV PSYCHOL, V30, P955, DOI 10.1037/0012-1649.30.6.955
   Love B. C., 2013, OXFORD HDB COGNITIVE, P342
   Mack ML, 2013, CURR BIOL, V23, P2023, DOI 10.1016/j.cub.2013.08.035
   MACWHINNEY B, 2001, FREQUENCY EMERGENCE, P449, DOI DOI 10.1075/TSL.45.23MAC
   Mahowald K, 2016, J MEM LANG, V91, P5, DOI 10.1016/j.jml.2016.03.009
   Maratsos M, 2000, J CHILD LANG, V27, P183, DOI 10.1017/S0305000999004067
   Marchman VA, 1997, COGNITIVE SCI, V21, P283
   Marchman VA, 1999, J SPEECH LANG HEAR R, V42, P206, DOI 10.1044/jslhr.4201.206
   MARCHMAN VA, 1994, J CHILD LANG, V21, P339, DOI 10.1017/S0305000900009302
   Maslen RJC, 2004, J SPEECH LANG HEAR R, V47, P1319, DOI 10.1044/1092-4388(2004/099)
   Matthews D, 2005, COGNITIVE DEV, V20, P121, DOI 10.1016/j.cogdev.2004.08.001
   Matthews D, 2007, J CHILD LANG, V34, P381, DOI 10.1017/S030500090600794X
   Matthews D, 2010, COGNITIVE SCI, V34, P465, DOI 10.1111/j.1551-6709.2009.01091.x
   Mattys SL, 2001, COGNITION, V78, P91, DOI 10.1016/S0010-0277(00)00109-8
   McClure K, 2006, J CHILD LANG, V33, P693, DOI 10.1017/S0305000906007525
   McDonald SA, 2003, PSYCHOL SCI, V14, P648, DOI 10.1046/j.0956-7976.2003.psci_1480.x
   MEDIN DL, 1978, PSYCHOL REV, V85, P207, DOI 10.1037/0033-295X.85.3.207
   Milin P, 2016, COGN LINGUIST, V27, P507, DOI 10.1515/cog-2016-0055
   Minsky M.L, 1969, PERCEPTRONS INTRO CO
   MOSCOVITCH M, 1992, J COGNITIVE NEUROSCI, V4, P257, DOI 10.1162/jocn.1992.4.3.257
   Mudrow M., 2002, ANALOGICAL MODELING, P225
   Nakisa R., 2000, MODELS LANGUAGE ACQU, P201
   Newmeyer FJ, 2003, LANGUAGE, V79, P682, DOI 10.1353/lan.2003.0260
   Ninio A, 2018, FIRST LANG, V38, P399, DOI 10.1177/0142723718755879
   NOSOFSKY RM, 1990, J MATH PSYCHOL, V34, P393, DOI 10.1016/0022-2496(90)90020-A
   Nosofsky RM, 2016, PSYCHOL LEARN MOTIV, V65, P47, DOI 10.1016/bs.plm.2016.03.002
   Nosofsky RM, 2012, P NATL ACAD SCI USA, V109, P333, DOI 10.1073/pnas.1111304109
   O'Donnell T. J., 2015, PRODUCTIVITY REUSE L
   O'Grady W, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X17000541
   PALMERI TJ, 1993, J EXP PSYCHOL LEARN, V19, P309, DOI 10.1037/0278-7393.19.2.309
   Pierre P, 2018, TOP COGN SCI, V11, P520
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Pine JM, 1997, APPL PSYCHOLINGUIST, V18, P123, DOI 10.1017/S0142716400009930
   Pinker S, 2002, TRENDS COGN SCI, V6, P456, DOI 10.1016/S1364-6613(02)01990-3
   PINKER S, 1999, WORDS RULES
   Pinker S., 1989, LEARNABILITY COGNITI
   Pinker Steven, 1987, MECH LANGUAGE ACQUIS, P399
   Pluymaekers M, 2005, PHONETICA, V62, P146, DOI 10.1159/000090095
   Port RF, 2005, LANGUAGE, V81, P927, DOI 10.1353/lan.2005.0195
   POSNER MI, 1970, J EXP PSYCHOL, V83, P304, DOI 10.1037/h0028558
   PRASADA S, 1993, LANG COGNITIVE PROC, V8, P1, DOI 10.1080/01690969308406948
   Prince Alan, 2008, OPTIMALITY THEORY CO
   Quiroga RQ, 2017, CELL, V169, P975, DOI 10.1016/j.cell.2017.05.012
   Rasanen SHM, 2014, J CHILD LANG, V41, P756, DOI 10.1017/S0305000913000159
   Ramscar M, 2017, PSYCHOL SCI, V28, P1171, DOI 10.1177/0956797617706393
   Ramscar M, 2016, LANG SCI, V53, P58, DOI 10.1016/j.langsci.2015.08.002
   Ramscar M, 2015, HANDB SPRACH KOMMUN, V39, P75
   Ramscar M, 2013, LANGUAGE, V89, P760, DOI 10.1353/lan.2013.0068
   Ramscar M, 2013, PSYCHOL SCI, V24, P1017, DOI 10.1177/0956797612460691
   Rasanen SHM, 2016, COGNITIVE SCI, V40, P1704, DOI 10.1111/cogs.12305
   Ravid Dorit, 1999, FIRST LANG, V19, P187, DOI DOI 10.1177/014272379901905603
   REBER AS, 1969, J EXP PSYCHOL, V81, P115, DOI 10.1037/h0027454
   REBER AS, 1989, J EXP PSYCHOL GEN, V118, P219, DOI 10.1037/0096-3445.118.3.219
   Regier T, 2005, COGNITIVE SCI, V29, P819, DOI 10.1207/s15516709cog0000_31
   Rissman L, 2019, PSYCHON B REV, V26, P1850, DOI 10.3758/s13423-019-01634-5
   ROEDIGER HL, 1993, HDB NEUROPSYCHOLOGY, V8, P63
   ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P573, DOI 10.1016/0010-0285(75)90024-9
   Rowland CF, 2012, COGNITION, V125, P49, DOI 10.1016/j.cognition.2012.06.008
   RUBENSTEIN H, 1971, J VERB LEARN VERB BE, V10, P645, DOI 10.1016/S0022-5371(71)80071-3
   Rubino RB, 1998, J CHILD LANG, V25, P35, DOI 10.1017/S0305000997003310
   Rumelhart D, 1986, PARALLEL DISTRIBUTED
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Sakas WG, 2012, LANG ACQUIS, V19, P83, DOI 10.1080/10489223.2012.660553
   Savage C, 2003, DEVELOPMENTAL SCI, V6, P557, DOI 10.1111/1467-7687.00312
   Savage C, 2006, LANG LEARN DEV, V2, P27, DOI 10.1207/s15473341lld0201_2
   Saviciute E, 2018, J CHILD LANG, V45, P641, DOI 10.1017/S030500091700037X
   Schatz T., EARLY PHONETIC UNPUB, DOI [10.31234/osf.io/fc4wh, DOI 10.31234/OSF.IO/FC4WH]
   Shariatmadari D., 2015, GUARDIAN
   Singh L, 2002, PROC ANN BUCLD, P608
   Siyanova-Chanturia A, 2011, J EXP PSYCHOL LEARN, V37, P776, DOI 10.1037/a0022531
   Skousen R., 2005, ARXIVQUANTPH0510146
   Skousen R., 1989, ANALOGICAL MODELING
   Smith JD, 2000, J EXP PSYCHOL LEARN, V26, P3, DOI 10.1037/0278-7393.26.1.3
   Smoke KL, 1932, PSYCHOL MONOGR, V42, P1
   Snider N., 2008, THESIS
   Sosa AV, 2012, J SPEECH LANG HEAR R, V55, P596, DOI 10.1044/1092-4388(2011/10-0113)
   Sosa AV, 2002, BRAIN LANG, V83, P227, DOI 10.1016/S0093-934X(02)00032-9
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   STANDING L, 1973, Q J EXP PSYCHOL, V25, P207, DOI 10.1080/14640747308400340
   STEMBERGER JP, 1993, J CHILD LANG, V20, P503, DOI 10.1017/S030500090000845X
   Stoel-Gammon C, 2011, J CHILD LANG, V38, P1, DOI 10.1017/S0305000910000425
   Tatsumi T, 2018, COGNITIVE SCI, V42, P555, DOI 10.1111/cogs.12554
   Theakston AL, 2001, J CHILD LANG, V28, P127, DOI 10.1017/S0305000900004608
   Theakston AL, 2015, COGNITIVE SCI, V39, P1369, DOI 10.1111/cogs.12216
   Thomas E. M., 2007, FIRST LANG, V27, DOI [https://doi.org/10.1177/0142723707077056, DOI 10.1177/0142723707077056]
   Thornton R, 2012, FIRST LANG, V32, P281, DOI 10.1177/0142723711403881
   Thorpe W.H., 1956, LEARNING INSTINCT AN
   Tomasello M, 2000, COGNITION, V74, P209, DOI 10.1016/S0010-0277(99)00069-4
   Tomasello M., 2003, CONSTRUCTING LANGUAG
   Tremblay A., 2010, PERSPECTIVES FORMULA, P151
   Ullman M. T., 2015, NEUROBIOLOGY LANGUAG, P953
   Valian V, 2014, J CHILD LANG, V41, P78, DOI 10.1017/S0305000914000336
   Van Noord R., 2015, COMPUT LINGUIST, V5, P65
   Walsh M, 2010, COGNITIVE SCI, V34, P537, DOI 10.1111/j.1551-6709.2010.01099.x
   Wexler K, 1998, LINGUA, V106, P23, DOI 10.1016/S0024-3841(98)00029-1
   Yang C, 2016, PRICE OF LINGUISTIC PRODUCTIVITY: HOW CHILDREN LEARN TO BREAK THE RULES OF LANGUAGE, P1, DOI 10.7551/mitpress/9780262035323.001.0001
   Zaki SR, 2003, J EXP PSYCHOL LEARN, V29, P1160, DOI 10.1037/0278-7393.29.6.1160
   Ziegler J., 2018, 31 ANN M CUNY C HUM
   Ziegler J, 2018, COGNITION, V179, P221, DOI 10.1016/j.cognition.2018.06.019
NR 220
TC 24
Z9 24
U1 3
U2 5
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0142-7237
EI 1740-2344
J9 FIRST LANG
JI First Lang.
PD OCT
PY 2020
VL 40
IS 5-6
SI SI
BP 509
EP 559
AR 0142723719869731
DI 10.1177/0142723719869731
EA SEP 2019
PG 51
WC Psychology, Developmental; Linguistics; Language & Linguistics
SC Psychology; Linguistics
GA NV7WT
UT WOS:000485609700001
OA Other Gold
DA 2021-02-24
ER

PT J
AU Roden, I
   Fruchtenicht, K
   Kreutz, G
   Linderkamp, F
   Grube, D
AF Roden, Ingo
   Fruechtenicht, Kaija
   Kreutz, Gunter
   Linderkamp, Friedrich
   Grube, Dietmar
TI Auditory Stimulation Training With Technically Manipulated Musical
   Material in Preschool Children With Specific Language Impairments: An
   Explorative Study
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE auditory stimulation; working memory; language disorders; transfer
   (psychology); preschool children
ID PHONOLOGICAL AWARENESS INTERVENTION; FAST-FORWORD; DEVELOPMENTAL
   DYSLEXIA; PROCESSING DISORDER; SPEECH; MEMORY; SKILLS; BRAIN;
   COMPREHENSION; PERCEPTION
AB Auditory stimulation training (AST) has been proposed as a potential treatment for children with specific language impairments (SLI). The current study was designed to test this assumption by using an AST with technically modulated musical material (ASTM) in a randomized control group design. A total of 101 preschool children (62 male, 39 females; mean age = 4.52 years, SD = 0.62) with deficits in speech comprehension and poor working memory capacity were randomly allocated into one of two treatment groups or a control group. Children in the ASTM group (n = 40) received three 30-min sessions per week over 12 weeks, whereas children in the comparison group received pedagogical activities during these intervals (n = 24). Children in the control group (n = 37) received no treatment. Working memory, phoneme discrimination and speech perception skills were tested prior to (baseline) and after treatment. Children in the ASTM group showed significantly greater working memory capacity, speech perception, and phoneme discrimination skills after treatment, whereas children in the other groups did not show such improvement. Taken together, these results suggest that ASTM can enhance auditory cognitive performance in children with SLI.
C1 [Roden, Ingo; Fruechtenicht, Kaija; Grube, Dietmar] Carl von Ossietzky Univ Oldenburg, Dept Educ Psychol, Oldenburg, Germany.
   [Kreutz, Gunter] Carl von Ossietzky Univ Oldenburg, Speech & Mus Lab, Oldenburg, Germany.
   [Linderkamp, Friedrich] Univ Wuppertal, Sch Educ, Wuppertal, Germany.
RP Roden, I (corresponding author), Carl von Ossietzky Univ Oldenburg, Dept Educ Psychol, Oldenburg, Germany.
EM ingo.roden@uni-oldenburg.de
CR Agnew JA, 2004, BRAIN LANG, V88, P21, DOI 10.1016/S0093-934X(03)00157-3
   ALEXANDER DW, 1982, PERCEPT MOTOR SKILL, V55, P783, DOI 10.2466/pms.1982.55.3.783
   Baddeley A, 2006, WORKING MEMORY AND NEURODEVELOPMENTAL DISORDERS, pXI
   Bishop D, 1989, TEST RECEPTION GRAMM
   Bishop DVM, 2006, INT J LANG COMM DIS, V41, P19, DOI 10.1080/13682820500144000
   Murphy CFB, 2013, CLINICS, V68, P1364, DOI 10.6061/clinics/2013(10)12
   Brandt A, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00327
   Carr KW, 2014, P NATL ACAD SCI USA, V111, P14559, DOI 10.1073/pnas.1406219111
   Clement S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00420
   *COGN CONC, 1997, EAR AUD DEV PHON PRO
   Cognitive Concepts, 1996, EAR COMP SOFTW
   Cohen W, 2005, J SPEECH LANG HEAR R, V48, P715, DOI 10.1044/1092-4388(2005/049)
   Corriveau K, 2007, J SPEECH LANG HEAR R, V50, P647, DOI 10.1044/1092-4388(2007/046)
   Corriveau KH, 2009, CORTEX, V45, P119, DOI 10.1016/j.cortex.2007.09.008
   Cumming R, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3339/fnhum.2015.00672, 10.3389/fnhum.2015.00672]
   CUPPLES LA, 1984, ANN INTERN MED, V100, P122, DOI 10.7326/0003-4819-100-1-122
   de Miranda Elisiane Crestani, 2008, Braz J Otorhinolaryngol, V74, P919, DOI 10.1016/S1808-8694(15)30154-3
   Dege F, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00124
   Ecalle J, 2009, DYSLEXIA, V15, P218, DOI 10.1002/DYS.373
   Erdfelder E, 1996, BEHAV RES METH INS C, V28, P1, DOI 10.3758/BF03203630
   Fey ME, 2011, LANG SPEECH HEAR SER, V42, P246, DOI 10.1044/0161-1461(2010/10-0013)
   Filippini R, 2012, FOLIA PHONIATR LOGO, V64, P217, DOI 10.1159/000342139
   Fisher M, 2009, AM J PSYCHIAT, V166, P805, DOI 10.1176/appi.ajp.2009.08050757
   Fitch RH, 1997, ANNU REV NEUROSCI, V20, P331, DOI 10.1146/annurev.neuro.20.1.331
   Flaugnacco E, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00392
   Fonseca-Mora MC, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00286
   Francois C, 2013, CEREB CORTEX, V23, P2038, DOI 10.1093/cercor/bhs180
   Franssen V, 2006, PSYCHOL RES-PSYCH FO, V70, P304, DOI 10.1007/s00426-005-0217-x
   Friel-Patti S, 2001, AM J SPEECH-LANG PAT, V10, P203, DOI 10.1044/1058-0360(2001/019)
   Gaab N, 2007, RESTOR NEUROL NEUROS, V25, P295
   Gathercole S. E., 1996, CHILDRENS TEST NONWO
   Gil D, 2010, CLINICS, V65, P165, DOI 10.1590/S1807-59322010000200008
   Gillam RB, 2001, AM J SPEECH-LANG PAT, V10, P231, DOI 10.1044/1058-0360(2001/021)
   Goh C. C. M., 2006, ELT J, V60, P222, DOI DOI 10.1093/ELT/CCL002
   Gordon RL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01777
   Goswami U., 2010, LANGUAGE MUSIC COGNI, P292, DOI DOI 10.1093/ACPROF:OSO/9780199553426.003.0030
   Habib M, 2000, BRAIN, V123, P2373, DOI 10.1093/brain/123.12.2373
   Hannon EE, 2005, COGNITIVE PSYCHOL, V50, P354, DOI 10.1016/j.cogpsych.2004.09.003
   Hasselhorn V. M., 2012, ARBEITSGEDACHTNISTES
   Hayes EA, 2003, CLIN NEUROPHYSIOL, V114, P673, DOI 10.1016/S1388-2457(02)00414-5
   Heim S, 2013, NEUROPSYCHOLOGIA, V51, P990, DOI 10.1016/j.neuropsychologia.2013.01.011
   Henry L, 2012, DEV WORKING MEMORY C
   Huss M, 2011, CORTEX, V47, P674, DOI 10.1016/j.cortex.2010.07.010
   Kampfe J, 2011, PSYCHOL MUSIC, V39, P424, DOI 10.1177/0305735610376261
   Kast M, 2007, RESTOR NEUROL NEUROS, V25, P355
   Kast M, 2011, ANN DYSLEXIA, V61, P177, DOI 10.1007/s11881-011-0052-2
   Kujala T, 2001, P NATL ACAD SCI USA, V98, P10509, DOI 10.1073/pnas.181589198
   Lee YS, 2007, LEARN INSTR, V17, P336, DOI 10.1016/j.learninstruc.2007.02.010
   Lindamood Bell Learning Processes, 1999, LIND PHON SEQ PROGR
   Loeb DF, 2001, AM J SPEECH-LANG PAT, V10, P216, DOI 10.1044/1058-0360(2001/020)
   Megale Renata Luciane, 2010, Pró-Fono R. Atual. Cient., V22, P101, DOI 10.1590/S0104-56872010000200006
   Milhken G. A., 1984, ANAL MESSY DATA, V1
   Overy K, 2003, DYSLEXIA, V9, P18, DOI 10.1002/dys.233
   Overy K., 2000, PSYCHOL MUSIC, V28, P218, DOI DOI 10.1177/0305735600282010
   Planchou C, 2015, ADV COGN PSYCHOL, V11, P118, DOI 10.5709/acp-0177-8
   Pokorni JL, 2004, J EDUC RES, V97, P147, DOI 10.3200/JOER.97.3.147-158
   Przybylski L, 2013, NEUROPSYCHOLOGY, V27, P121, DOI 10.1037/a0031277
   Reilly S, 2014, INT J LANG COMM DIS, V49, P452, DOI 10.1111/1460-6984.12111
   Roden I, 2014, PSYCHOL MUSIC, V42, P284, DOI 10.1177/0305735612471239
   Roden I, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00572
   Ross ED, 1997, BRAIN LANG, V56, P27, DOI 10.1006/brln.1997.1731
   Russo NM, 2005, BEHAV BRAIN RES, V156, P95, DOI 10.1016/j.bbr.2004.05.012
   Ryding E, 1996, BRAIN LANG, V52, P435, DOI 10.1006/brln.1996.0023
   Sallat S, 2015, BEHAV NEUROL, V2015, DOI 10.1155/2015/606470
   Schochat E, 2010, BRAZ J MED BIOL RES, V43, P777, DOI 10.1590/S0100-879X2010000800011
   Scholer H., 2009, HEIDELBERGER AUDITIV
   Scientific Learning Corporation, 1998, FAST WORD COMP SOFTW
   Segers E, 2004, LANG SPEECH HEAR SER, V35, P229, DOI 10.1044/0161-1461(2004/022)
   SIDAK Z, 1967, J AM STAT ASSOC, V62, P626, DOI 10.2307/2283989
   Steinbrink C, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00805
   Steinbrink C, 2014, CHILD DEV, V85, P1711, DOI 10.1111/cdev.12208
   Stevens C, 2008, BRAIN RES, V1205, P55, DOI 10.1016/j.brainres.2007.10.108
   Strehlow U, 2006, EUR CHILD ADOLES PSY, V15, P19, DOI 10.1007/s00787-006-0500-4
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Tallal P, 1996, SCIENCE, V271, P81, DOI 10.1126/science.271.5245.81
   TALLAL P, 1973, NATURE, V241, P468, DOI 10.1038/241468a0
   Thomson JM, 2008, J PHYSIOL-PARIS, V102, P120, DOI 10.1016/j.jphysparis.2008.03.007
   Tierney A, 2013, PROG BRAIN RES, V207, P209, DOI 10.1016/B978-0-444-63327-9.00008-4
   Vilela Nadia, 2012, J. Soc. Bras. Fonoaudiol., V24, P42, DOI 10.1590/S2179-64912012000100008
   Von Fox- Boyer A., 2009, TROG D TEST UBERPRUF
   Vukovic RK, 2006, J LEARN DISABIL-US, V39, P25, DOI 10.1177/00222194060390010401
   Wiens N, 2018, ANN NY ACAD SCI, V1423, P219, DOI 10.1111/nyas.13639
NR 82
TC 1
Z9 1
U1 3
U2 13
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD SEP 4
PY 2019
VL 10
AR 2026
DI 10.3389/fpsyg.2019.02026
PG 15
WC Psychology, Multidisciplinary
SC Psychology
GA IU7WY
UT WOS:000483795200001
PM 31551875
OA DOAJ Gold, Green Published, Green Accepted
DA 2021-02-24
ER

PT J
AU Del Saz, M
AF Del Saz, Maria
TI NATIVE AND NONNATIVE PERCEPTION OF WESTERN ANDALUSIAN SPANISH /S/
   ASPIRATION IN QUIET AND NOISE
SO STUDIES IN SECOND LANGUAGE ACQUISITION
LA English
DT Article
ID SPEECH-PERCEPTION; LANGUAGE EXPERIENCE; CROSS-LANGUAGE; ENGLISH;
   INTELLIGIBILITY; VOWELS; IDENTIFICATION; FRENCH
AB Many college students set out on Study Abroad Programs to other countries in which the variant of the foreign language spoken in the region differs from the variant to which learners have been exposed. This study explores the perception of L2 Western Andalusian Spanish aspiration of word-final /s/ by L1 American English listeners, in relation to their length of exposure to the L2 in quiet conditions and to their competence level in the L2 in noisy conditions. Results indicate that perception drops in adverse conditions, particularly for listeners in their intermediate stages of learning. Proficient listeners' perception also suffers with respect to native listeners' performance at lower signal-to-noise ratios. For all listeners, native and nonnative, standard features are best identified, whether in quiet or noise.
C1 [Del Saz, Maria] Univ Santiago Chile, Fac Humanidades, Dept Linguist & Literatura, Santiago, Chile.
RP Del Saz, M (corresponding author), Univ Santiago Chile, Ave Libertador Bernardo OHiggins 3363, Santiago, Chile.
EM maria.delsaz@usach.cl
CR ALVAR LOPEZ M., 2004, ESTUDIOS HABLAS MERI
   Alvar M., 1996, MANUAL DIALECTOLOGIA
   Barreiro Bilbao S. C., 2002, ODISEA, V2, P7
   Barreiro Bilbao S. C., 1999, ACT 1 C FON EXP, P111
   BEST CT, 1992, J PHONETICS, V20, P305, DOI 10.1016/S0095-4470(19)30637-0
   Boersma P., 2009, PRAAT DOING PHONETIC
   BOHN OS, 1990, APPL PSYCHOLINGUIST, V11, P303, DOI 10.1017/S0142716400008912
   Boomershine A., 2008, PHONOLOGICAL CONTRAS, P146
   Bybee Joan, 2002, STUDIES 2 LANGUAGE A, V24, P215, DOI DOI 10.1017/S0272263102002061
   Cebrian J., 2011, P 17 INT C PHON SCI, P424
   Celata C., 2007, NEW SOUNDS 2007, P114
   Cervera T, 2011, BEHAV RES METHODS, V43, P459, DOI 10.3758/s13428-011-0063-2
   Clopper C. G., 2006, J ACOUST SOC AM, V119, P3424
   Clopper CG, 2008, LANG SPEECH, V51, P175, DOI 10.1177/0023830908098539
   Cutler A, 2005, SPEECH COMMUN, V47, P32, DOI 10.1016/j.specom.2005.02.001
   CUTLER A, 2007, P INTERSPEECH 2007 A, P1585
   Del Saz M., 2015, PERSPECTIVAS ACTUALE, P399
   Escudero P, 2004, STUD SECOND LANG ACQ, V26, P551, DOI 10.1017/S0272226310400021
   Escudero P, 2009, J PHONETICS, V37, P452, DOI 10.1016/j.wocn.2009.07.006
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Gerfen C., 2002, PROBUS, V14, P247, DOI DOI 10.1515/PRBS.2002.010
   Hawkins S., 2011, P 17 INT C PHON SCI, P9
   Hualde J. I., 2014, SONIDOS ESPANOL
   Iverson P, 2009, J ACOUST SOC AM, V126, P866, DOI 10.1121/1.3148196
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Johnson K., 2012, ACOUSTIC AUDITORY PH
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Kissling EM, 2015, LANG TEACH RES, V19, P254, DOI 10.1177/1362168814541735
   Levy ES, 2008, J PHONETICS, V36, P141, DOI 10.1016/j.wocn.2007.03.001
   Levy ES, 2009, J ACOUST SOC AM, V125, P1138, DOI 10.1121/1.3050256
   Lipski JM, 1999, ADVANCES IN HISPANIC LINGUISTICS, VOLS 1 AND 2, P198
   Major R. C., 2001, FOREIGN ACCENT ONTOG
   Mitterer H., 2012, FRONT PSYCHOL, V3, P1
   Mora J. C., 2016, 53 REFLEXIONES ASPEC, P395
   ONEILL P, 2005, LANGUAGE DESIGN, V7, P151
   Plitcha B., 2010, AKUSTYK VERSION 1 9
   POLKA L, 1985, J ACOUST SOC AM, V78, P1187, DOI 10.1121/1.392887
   Romero Gallego J., 1995, RIV LINGUISTICA, V7, P191
   Roseano P., 2015, PERSPECTIVAS ACTUALE, P163
   Ruch H, 2016, LAB PHONOL, V7, DOI 10.5334/labphon.2
   Ruch H, 2014, J PHONETICS, V45, P12, DOI 10.1016/j.wocn.2014.02.009
   Schmidt L. B., 2009, SEL P 11 HISP LING S, P143
   Schmidt LB, 2018, STUD SECOND LANG ACQ, V40, P857, DOI 10.1017/S0272263118000116
   Schmidtke J, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00678
   Strange W., 2008, PHONOLOGY 2 LANGUAGE, P153
   Strange W, 2011, J PHONETICS, V39, P456, DOI 10.1016/j.wocn.2010.09.001
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   Syrdal A. K., 2014, SPEECH LANGUAGE ADV, P313
   Tabri D, 2011, INT J LANG COMM DIS, V46, P411, DOI 10.3109/13682822.2010.519372
   Torreira F, 2007, SEL P 9 HISP LING S, P113
   Torreira F., 2007, SEGMENTAL PROSODIC I, P67, DOI 10.1075/cilt.282.06tor
   Torreira F, 2012, J INT PHON ASSOC, V42, P49, DOI 10.1017/S0025100311000491
   Tuinman A., 2007, P 16 INT C PHON SCI, P1905
   Tuinman A, 2011, J ACOUST SOC AM, V130, P1643, DOI 10.1121/1.3619793
   Wagner A, 2006, J ACOUST SOC AM, V120, P2267, DOI 10.1121/1.2335422
   Widdison K. A., 1993, ESTUDIOS FONETICA EX, VV, P34
NR 58
TC 0
Z9 0
U1 1
U2 2
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0272-2631
EI 1470-1545
J9 STUD SECOND LANG ACQ
JI Stud. Second Lang. Acquis.
PD SEP
PY 2019
VL 41
IS 4
BP 673
EP 694
DI 10.1017/S0272263119000056
PG 22
WC Linguistics
SC Linguistics
GA KK8HO
UT WOS:000512977600002
DA 2021-02-24
ER

PT J
AU Hasanbegovic, H
   Mahmutovic, EH
AF Hasanbegovic, Husnija
   Mahmutovic, Esad H.
TI The Education of d/Dhh Children in Bosnia and Herzegovina
SO AMERICAN ANNALS OF THE DEAF
LA English
DT Article
DE deaf education; language development; information technology; motoric
   abilities and skills; multilingual learners
ID HARD-OF-HEARING; PRELINGUALLY DEAF-CHILDREN; COCHLEAR IMPLANTS;
   SPEECH-PERCEPTION; SIGN-LANGUAGE; READING-COMPREHENSION; EARLY
   INTERVENTION; MOTOR DEVELOPMENT; POSTURAL CONTROL; CAREER-DEVELOPMENT
AB The authors provide guidelines, based on an extensive review of the international literature, for conducting, interpreting, and reporting primary and secondary research on children who are deaf and hard of hearing in Bosnia and Herzegovina. The purpose of the review is to present arguments in support of conceptualizing education and rehabilitation, to explore the educational implications of such conceptualizations, and to suggest directions for future inquiry. Problematic areas are covered, such as research on the structure of a signed language, the use of information technology, inclusion, vocational and professional orientation, and motoric abilities and skills. The article concludes with recommendations for further investigating the educational achievement of students who are deaf and hard of hearing so as to improve educational practice.
C1 [Hasanbegovic, Husnija] Univ Tuzla, Fac Educ & Rehabil, Dept Speech Pathol & Audiol, Tuzla, Bosnia & Herceg.
   [Mahmutovic, Esad H.] Univ Tuzla, Ctr Educ & Rehabil Deaf & Hard Hearing Students, Deaf, Tuzla, Bosnia & Herceg.
RP Hasanbegovic, H (corresponding author), Univ Tuzla, Fac Educ & Rehabil, Dept Speech Pathol & Audiol, Tuzla, Bosnia & Herceg.
CR Aarons D., 1994, THESIS
   Akamatsu C. T., 2008, DEAF COGNITION FDN O, P131, DOI DOI 10.1093/ACPROF:0S0/9780195368673.003.0005
   ANDREWS JF, 1991, EXCEPT CHILDREN, V57, P536, DOI 10.1177/001440299105700607
   ANDREWS JF, 1988, EXCEPT CHILDREN, V54, P349
   ANGELIDES P, 2007, EUROPEAN J SPECIAL N, V22, P63, DOI DOI 10.1080/08856250601082299
   Antia S. D., 2002, J DEAF STUD DEAF EDU, V7, P214, DOI DOI 10.1093/DEAFED/7.3.214
   Antia SD, 2005, J DEAF STUD DEAF EDU, V10, P244, DOI 10.1093/deafed/eni026
   ANTIA SD, 2003, OXFORD HDB DEAF STUD, P164
   Antia SD, 2009, J DEAF STUD DEAF EDU, V14, P293, DOI 10.1093/deafed/enp009
   ARNOLD P, 1978, TEACH DEAF, V2, P196
   Aronoff M, 2005, LANGUAGE, V81, P301, DOI 10.1353/lan.2005.0043
   Aronoff Mark, 2000, U MARYLAND WORKING P, V10, P1
   Barker L.J., 2003, J DEAF STUD DEAF EDU, V8, P187, DOI DOI 10.1093/DEAFED/ENG002
   Bat-Chava Y, 2005, J CHILD PSYCHOL PSYC, V46, P1287, DOI 10.1111/j.1469-7610.2005.01426.x
   Batten G, 2014, J DEAF STUD DEAF EDU, V19, P285, DOI 10.1093/deafed/ent052
   Beadle EAR, 2005, OTOL NEUROTOL, V26, P1152, DOI 10.1097/01.mao.0000180483.16619.8f
   Beeker R, 1998, J Deaf Stud Deaf Educ, V3, P157
   BENCH RJ, 1992, COMMUNICATION SKILLS
   Bergeson TR, 2003, VOLTA REV, V103, P347
   Berndsen M, 2012, COMMUN DISORD Q, V33, P111, DOI 10.1177/1525740110384398
   Blamey PJ, 2001, J SPEECH LANG HEAR R, V44, P264, DOI 10.1044/1092-4388(2001/022)
   Bolt SE, 2004, REM SPEC EDUC, V25, P141, DOI 10.1177/07419325040250030201
   Brentari D, 1996, LINGUA, V98, P43, DOI 10.1016/0024-3841(95)00032-1
   Brentari D., 2010, SIGN LANGUAGES
   Brentari Diane, 1998, PROSODIC MODEL SIGN
   Bullis M., 1990, ISSUES RES SPECIAL E, P297
   Cannon JE, 2011, J DEAF STUD DEAF EDU, V16, P437, DOI 10.1093/deafed/enr023
   Cawthon S. W., 2014, ED POLICY ANAL ARCH, V22, P13, DOI [10.14507/epaa.v22n13.2014, DOI 10.14507/EPAA.V22N13.2014]
   Cawthon SW, 2008, J DEAF STUD DEAF EDU, V13, P55, DOI 10.1093/deafed/enm029
   Cawthon SW, 2010, J DEAF STUD DEAF EDU, V15, P185, DOI 10.1093/deafed/enq002
   Cawthon SW, 2009, J DEAF STUD DEAF EDU, V14, P155, DOI 10.1093/deafed/enn027
   Chomsky N., 2006, LANGUAGE MIND
   Clapper A. T., 2005, 58 U MINN NAT CTR ED
   Corina D, 2009, CHILD DEV, V80, P952, DOI 10.1111/j.1467-8624.2009.01310.x
   Cushing SL, 2008, ARCH OTOLARYNGOL, V134, P34, DOI 10.1001/archoto.2007.16
   Dammeyer J, 2010, J DEAF STUD DEAF EDU, V15, P50, DOI 10.1093/deafed/enp024
   De Kegel A, 2011, GAIT POSTURE, V33, P679, DOI 10.1016/j.gaitpost.2011.02.024
   Debevc M, 2004, DISABIL REHABIL, V26, P1048, DOI 10.1080/09638280410001702441
   DeCaro JJ, 2001, AM ANN DEAF, V146, P51, DOI 10.1353/aad.2012.0110
   Derlich M, 2011, RES DEV DISABIL, V32, P1808, DOI 10.1016/j.ridd.2011.03.009
   Dolinay V., 2005, ANN DAAAM P
   Dornan A. D, 2010, THESIS
   Dotter F., 1996, INT C COMP HELP PEOP
   DUMMER GM, 1996, ADAPT PHYS ACT Q, V13, P400
   Dunmade A. O., 2009, EUROPEAN J SCI RES, V25, P597
   Easterbrooks SR, 2008, VOLTA REV, V108, P91
   Ebrahimi Amir-Abbas, 2016, Acta Med Iran, V54, P737
   EFFGEN SK, 1981, PHYS THER, V61, P873, DOI 10.1093/ptj/61.6.873
   El-Zraigat IA, 2013, INT ED STUDIES, V6, P63, DOI [10.5539/ies.v6n2p63, DOI 10.5539/IES.V6N2P63]
   Eriks-Brophy A, 2013, AM ANN DEAF, V158, P63, DOI 10.1353/aad.2013.0009
   Evans CJ, 2004, AM ANN DEAF, V149, P17, DOI 10.1353/aad.2004.0011
   Foster S, 2003, INT J AUDIOL, V42, pS128
   Froude J., 2003, MAKING SENSE SIGN LI
   Furlonger B, 1998, AM ANN DEAF, V143, P268, DOI 10.1353/aad.2012.0183
   Gaad N. E, 2002, J FACULTY ED UAEU, V17, P53
   GAYLE GW, 1990, PERCEPT MOTOR SKILL, V70, P883, DOI 10.2466/PMS.70.3.883-888
   GEERS A, 1994, VOLTA REV, V96, P97
   Geers A, 2003, EAR HEARING, V24, p24S, DOI 10.1097/01.AUD.0000051687.99218.0F
   Geers A., 1999, CTR CHILDHOOD DEAFNE, P5
   Geers Ann E, 2011, Ear Hear, V32, p49S, DOI 10.1097/AUD.0b013e3181fa41fa
   Gheysen F, 2008, J DEAF STUD DEAF EDU, V13, P215, DOI 10.1093/deafed/enm053
   Gilley PM, 2008, BRAIN RES, V1239, P56, DOI 10.1016/j.brainres.2008.08.026
   Hasanbegovic H., 2012, HUMAN RES REHABILITA, V2, P31
   Hasanbegovic H., 2004, DEFEKTOLOGIJA, V9, P89
   Hasanbegovic H., 2014, HUMAN J INTERDISCIPL, V4, P4
   Hasanbegovic H., 2013, J INT SOCIAL RES, V6, P153
   Hasanbegovic H, 2011, BILINGVALNI POJMOVNI
   Hasanbegovic H, 2004, DEFEKTOLOGIJA, V11, P39
   Hasanbegovic H., 2013, CAHIERS SCI NATURELL, V22, P2
   Hasanbegovic H, 2012, US CHINA FOREIGN LAN, V10, P1061
   Hasanbegovic H, 2009, DEFEKTOLOGIJA, V15, P47
   Hasanbegovic H, 2009, CONT TREATM CHILDR S
   Hasanbegovic H, 2007, BEOGRADSKA DEFEKTOLO, V3, P1
   Hasanbegovic H, 2008, BEOGRADSKA DEFEKTOLO, V1, P33
   Hasanbegovic H., 2009, DEFEKTOLOGIJA, V15, P78
   Hasanbegovic H., 2010, J SPECIAL ED REHABIL, V11, P7
   Hasanbegovic H, 2008, DEFEKTOLOGIJA, V14, P44
   Hasanbegovic H, 2003, DEFEKTOLOGIJA, V8, P93
   Hasanbegovic H, 2014, SINO US ENGLISH TEAC, V11, P307
   Hasanbegovic H, 2007, ACTA MED SALINIANA, V36, P147
   Hasanbegovic H., 2008, J INT SOCIAL RES, V1, P372
   Hasanbegovic H., 2013, HUMAN, V3, P25
   Hasanbegovic H, 2008, ACTA MED SALINIANA, V37, P127
   Haug Tobias, 2011, ADAPTATION EVALUATIO
   Hilic-Huskic A., 2018, HUMAN RES REHABILITA, V8, P79, DOI [10.21554/hrr.091809, DOI 10.21554/HRR.091809]
   Hogan S, 2008, DEAF EDUC INT, V10, P143, DOI 10.1002/dei.242
   HOLT J, 1994, AM ANN DEAF, V139, P430, DOI 10.1353/aad.2012.0274
   Horn DL, 2006, LARYNGOSCOPE, V116, P1500, DOI 10.1097/01.mlg.0000230404.84242.4c
   Hyde M, 2005, AM ANN DEAF, V150, P415, DOI 10.1353/aad.2006.0004
   Ibertsson T, 2009, INT J LANG COMM DIS, V44, P319, DOI 10.1080/13682820802052067
   Imai T, 2001, EXP BRAIN RES, V136, P1, DOI 10.1007/s002210000533
   Jeanes R. C., 2000, J DEAF STUD DEAF EDU, V5, P237, DOI DOI 10.1093/DEAFED/5.3.237
   Johnson H, 2006, DEAF LEARNERS NEW DE, P221
   Kasumovic A, 2005, CASOPIS KULTURU BOSA, V4, P161
   Kasumovic A, 2002, RJECNIK GLUHE
   Kasumovic A., 2005, ZBORNIK RADOVA FILOZ, V6, P109
   Kelly L., 2003, J DEAF STUD DEAF EDU, V8, P230, DOI [DOI 10.1093/DEAFED/ENG013, 10.1093/deafed/eng013]
   Kelly RR, 2001, AM ANN DEAF, V146, P251, DOI 10.1353/aad.2012.0088
   Khwaldeh S, 2011, IMPLEMENTATION USE A
   King M. C, 1985, READING AND DEAFNESS
   Klima S. E, 1979, SIGNS LANGUAGE
   Kurtagic I., 2005, MOSTOVI, V18-19, P22
   Kurtagic I., 2006, DEFEKTOLOGIJA, V9, P265
   Kyle J, 1985, SIGN LANGUAGE STUDY, DOI Cambridge
   Lachs L, 2001, EAR HEARING, V22, P236, DOI 10.1097/00003446-200106000-00007
   Lane H., 1996, JOURNEY DEAF WORLD
   Lang H. G, 2005, BEST PRACTICES MATH
   Larson J. W., 2000, CALICO Journal, V18, P53
   LASASSO C, 1987, VOLTA REV, V89, P211
   Lederberg AR, 2009, J DEAF STUD DEAF EDU, V14, P44, DOI 10.1093/deafed/enn021
   Luckner JL, 2008, AM ANN DEAF, V153, P6, DOI 10.1353/aad.0.0006
   Macedo C. E., 2004, DEV TEST BATTERY ASS
   Mahmutovic E, 2014, HUMAN J INTERDISCIPL, V4, P25
   Mahmutovic E, 2016, HUMAN J INTERDISCIPL, V6, P26
   Mahmutovic E, 2017, HUMAN J INTERDISCIPL, V7, P78, DOI [10.21554/hrr.091715, DOI 10.21554/HRR.091715]
   Mahmutovic E., 2018, HUMAN J INTERDISCIPL, V8, P77, DOI [10.21554/hrr.041811, DOI 10.21554/HRR.041811]
   Mahshie N., 1995, ED DEAF CHILDREN BIL
   Maina N. E., 2011, INT RES J, V2, P956
   Marschark M, 2005, J DEAF STUD DEAF EDU, V10, P38, DOI 10.1093/deafed/eni002
   Marschark M, 2004, AM ANN DEAF, V149, P51, DOI 10.1353/aad.2004.0013
   MARSCHARK M, 2003, OXFORD HDB DEAF STUD, P464, DOI DOI 10.1093/OXFORDHB/9780195390032.001.0001
   Marschark M, 2001, LOOKING OBVIOUS ASSE
   Marschark M., 2009, EVIDENCE BEST PRACTI
   Marschark M., 2006, DEAF LEARNERS DEV CU, P179
   MARSCHARK M, 1993, PSYCHOL DEV DEAF CHI
   Marschark M., 2002, ED DEAF STUDENTS RES
   Marschark M. E., 2008, DEAF COGNITION FDN O, P309
   Martin D, 2011, J DEAF STUD DEAF EDU, V16, P108, DOI 10.1093/deafed/enq037
   Mayer C, 1996, J Deaf Stud Deaf Educ, V1, P93
   Meadow-Orlans K. P., 2003, PARENTS THEIR DEAF C
   Melo Renato de Souza, 2012, Rev. paul. pediatr., V30, P385
   Meloa RD, 2015, BRAZ J OTORHINOLAR, V81, P431, DOI 10.1016/j.bjorl.2014.08.014
   METZGER M, 2000, BILINGUALISM IDENTIT
   MILLER M, 2006, DEAF LEARNERS DEV CU, P161
   Miller PF, 2000, AM ANN DEAF, V145, P436, DOI 10.1353/aad.2012.0116
   Moeller MP, 2007, EAR HEARING, V28, P740, DOI 10.1097/AUD.0b013e318157f07f
   Moeller MP, 2000, PEDIATRICS, V106, DOI 10.1542/peds.106.3.e43
   Moores D F, 1990, Int J Rehabil Res, V13, P178, DOI 10.1097/00004356-199006000-00011
   Moores D. F, 2001, ED DEAF PRINCIPLES P
   Moores DF, 2006, DEAF LEARNERS DEV CU
   Most T, 2007, J DEAF STUD DEAF EDU, V12, P350, DOI 10.1093/deafed/enm012
   Musselman C., 2000, J DEAF STUD DEAF EDU, V5, P9, DOI DOI 10.1093/DEAFED/5.1.9
   Nakamura K, 2008, DEAF RESOURCE LIB AM
   Nezdaril V., 2011, THESIS
   Nicholas JG, 2008, AM J SPEECH-LANG PAT, V17, P121, DOI 10.1044/1058-0360(2008/013)
   Nicholas JG, 2006, EAR HEARING, V27, P286, DOI 10.1097/01.aud.0000215973.76912.c6
   Noorian M., 2013, INT RES J APPL BASIC, V7, P367
   Ogundiran O, 2013, J ED PRACTICE, V4, P42
   Pagliaro C. M, 2006, DEAF LEARNERS DEV CU, P29
   Palmer S, 2000, DEAFNESS ED INT, V2, P165, DOI [10.1002/dei.88, DOI 10.1002/DEI.88]
   Paul P, 1996, J Deaf Stud Deaf Educ, V1, P3
   Paul P. V, 2009, LANGUAGE DEAFNESS
   Pisoni B. D, 2004, SPEECH PERCEPTION DE
   PlazaPust C, 2008, STUD BILINGUAL, V38, P1
   Power D, 2008, AM ANN DEAF, V153, P37
   Powers S, 2003, J DEAF STUD DEAF EDU, V8, P57, DOI DOI 10.1093/DEAFED/8.1.57
   Punch R, 2006, J DEAF STUD DEAF EDU, V11, P224, DOI 10.1093/deafed/enj023
   Punch R, 2005, J DEAF STUD DEAF EDU, V10, P146, DOI 10.1093/deafed/eni015
   Punch R, 2004, AM ANN DEAF, V149, P28, DOI 10.1353/aad.2004.0015
   Punch R, 2007, J DEAF STUD DEAF EDU, V12, P504, DOI 10.1093/deafed/enm011
   Punch R, 2011, J DEAF STUD DEAF EDU, V16, P474, DOI 10.1093/deafed/enr001
   Punch R, 2010, J DEAF STUD DEAF EDU, V15, P405, DOI 10.1093/deafed/enq019
   Quigley S. P, 1987, ADV APPL PSYCHOLINGU, V1, P180
   Richardson JTE, 2010, J DEAF STUD DEAF EDU, V15, P358, DOI 10.1093/deafed/enq030
   Rine RM, 2004, INT J PEDIATR OTORHI, V68, P1141, DOI 10.1016/j.ijporl.2004.04.007
   Roberts JE, 2005, J SPEECH LANG HEAR R, V48, P345, DOI 10.1044/1092-4388(2005/024)
   Rose S, 2007, MONITORING PROGR STU
   Salkic N., 2018, HUMAN RES REHABILITA, V8, P55, DOI [10.21554/hrr.0918106, DOI 10.21554/HRR.0918106]
   Sandler W, 2006, SIGN LANGUAGE AND LINGUISTIC UNIVERSALS, P1, DOI 10.2277/ 0521483956
   Sandler W, 2017, ANNU REV LINGUIST, V3, P43, DOI 10.1146/annurev-linguistics-011516-034122
   Savelsbergh G. J. B, 1992, ADAPTED PHYS ACTIVIT, V9, P343, DOI [10.1123/apaq.9.4.343, DOI 10.1123/APAQ.9.4.343]
   Savic L J., 1983, PUTEVI DOSTIGNUCA GL
   Scherich D. L, 1997, J AM DEAFNESS REHABI, V31, P31
   Scherich DL, 1996, J REHABIL, V62, P27
   SCHILDROTH A, 1991, VOLTA REV, V93, P41
   Schorr E. A., 2008, COMMUN DISORD Q, V29, P195, DOI DOI 10.1177/1525740108321217
   SCHROEDEL J, 1992, VOLTA REV, V94, P37
   SCHROEDEL JG, 1991, AM ANN DEAF, V136, P330, DOI 10.1353/aad.2012.0534
   Schroedel JG, 2000, AM ANN DEAF, V145, P303, DOI 10.1353/aad.2012.0099
   SCHROEDEL JG, 2001, J APPL REHABILITATIO, V32, P35
   Sousa A, 2010, J PHYS ED STATE U MA, V21, P47
   Sousa D. S., 2010, REV DIGITAL, V15, P1
   Spencer P., 2010, EVIDENCE BASED PRACT
   Stinson M. S., 1999, J DEAF STUD DEAF EDU, V4, P163, DOI [DOI 10.1093/DEAFED/4.3.163, 10.1037/0022-0663.88.1.132]
   Stokoe WC, 2005, J DEAF STUD DEAF EDU, V10, P3, DOI 10.1093/deafed/eni001
   Stokoe William C., 1965, DICT AM SIGN LANGUAG
   Suarez H, 2007, INT J PEDIATR OTORHI, V71, P629, DOI 10.1016/j.ijporl.2006.12.014
   SUGOSG B&H, 2005, GOV LI ZNAK
   SUGOSG B&H, 2007, GOV LI ZNAK
   Swanwick R, 2005, J EARLY CHILD LIT, V5, P53, DOI 10.1177/1468798405050594
   Swanwick R, 2010, DEAF EDUC INT, V12, P217, DOI 10.1179/1557069X10Y.0000000002
   Swanwick R, 2007, DEAF EDUC INT, V9, P214, DOI 10.1002/dei.226
   Torres S, 2006, J DEAF STUD DEAF EDU, V11, P438, DOI 10.1093/deafed/enl006
   Toscano RM, 2002, AM ANN DEAF, V147, P5, DOI 10.1353/aad.2012.0184
   Traxler C.B., 2000, J DEAF STUDIES DEAF, V5, DOI [https://doi.org/10.1093/deafed/5.4.337, DOI 10.1093/DEAFED/5.4.337]
   Trezek B., 2009, READING AND DEAFNESS
   Tyler RS, 1997, OTOLARYNG HEAD NECK, V117, P180, DOI 10.1016/S0194-5998(97)70172-4
   Walker L, 1998, VOLTA REV, V100, P87
   Wang Y, 2008, AM ANN DEAF, V153, P396
   Wauters LN, 2008, J DEAF STUD DEAF EDU, V13, P21, DOI 10.1093/deafed/enm028
   Weisel A, 2005, J DEAF STUD DEAF EDU, V10, P376, DOI 10.1093/deafed/eni045
   White KR, 2006, VOLTA REV, V106, P237
   WIEGERSMA PH, 1983, J CHILD PSYCHOL PSYC, V24, P103, DOI 10.1111/j.1469-7610.1983.tb00107.x
   Wilbur RB, 2001, DRUS ISTRAZ, V10, P1039
   Wilbur Ronnie B., 2008, SIGNS TIME SELECTED, V2004, P217
   Williams Cheri, 2004, J Deaf Stud Deaf Educ, V9, P352, DOI 10.1093/deafed/enh045
   Wolbers KA, 2008, J DEAF STUD DEAF EDU, V13, P257, DOI 10.1093/deafed/enm052
   Yoshinaga-Itano C, 1998, VOLTA REV, V100, P181
   Yoshinaga-Itano C, 2004, J COMMUN DISORD, V37, P451, DOI 10.1016/j.jcomdis.2004.04.008
   Yoshinaga-Itano C, 2003, MENT RETARD DEV D R, V9, P252, DOI 10.1002/mrdd.10088
   Yoshinaga-Itano C, 2001, Semin Neonatol, V6, P521, DOI 10.1053/siny.2001.0075
   Yoshinaga-Itano C, 2011, RESILIENCE IN DEAF CHILDREN: ADAPTATION THROUGH EMERGING ADULTHOOD, P87, DOI 10.1007/978-1-4419-7796-0_4
   YoshinagaItano C, 1996, VOLTA REV, V98, P9
   YOSHINAGAITANO C, 1992, VOLTA REV, V94, P131
   Young A, 2009, J DEAF STUD DEAF EDU, V14, P422, DOI 10.1093/deafed/enp016
   Zalewska M, 1990, Probl Med Wieku Rozwoj, V16, P87
   Zimmermann A, 1986, UVODNI SEMINAR KOMUN
   Zwierzchowska A., 2004, J HUM KINET, V11, P83
NR 218
TC 0
Z9 0
U1 1
U2 5
PU GALLAUDET UNIV PRESS
PI WASHINGTON
PA 800 FLORIDA AVE NE, WASHINGTON, DC 20002 USA
SN 0002-726X
EI 1543-0375
J9 AM ANN DEAF
JI Am. Ann. Deaf
PD FAL
PY 2019
VL 164
IS 4
BP 450
EP 477
DI 10.1353/aad.2019.0027
PG 28
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA KB4OS
UT WOS:000506477500003
PM 31902798
DA 2021-02-24
ER

PT J
AU Hoyt, JM
   Perkel, DJ
   Portfors, CV
AF Hoyt, Jeffrey M.
   Perkel, David J.
   Portfors, Christine, V
TI Dopamine Acts via D2-Like Receptors to Modulate Auditory Responses in he
   Inferior Colliculus
SO ENEURO
LA English
DT Article
DE auditory; dopamine; inferior colliculus; mice; optogenetics; Parkinson's
ID SUBPARAFASCICULAR THALAMIC NUCLEUS; PARKINSONS-DISEASE;
   TYROSINE-HYDROXYLASE; BRAIN-STEM; NEURONS; RAT; PROJECTIONS;
   CONNECTIONS; PERCEPTION; MIDBRAIN
AB The ability to understand speech relies on accurate auditory processing of complex sounds. Individuals with Parkinson's disease suffer from speech perception deficits, suggesting that dopamine is involved in the encoding of complex sounds. Recent studies have demonstrated that dopamine has heterogeneous effects on the responses of many neurons in the inferior colliculus (IC) of mice, although the strongest effect is to suppress neural activity. However, it was previously unknown which dopamine receptors are involved in modulating neuronal responses, and whether the observed preponderance of depressive effects reflects the endogenous dopamine system in the IC. In this study, we tested whether dopamine acts via D1- and/or D2-like receptors to alter responses of IC neurons in female and male mice. We also tested the effect of optogenetically induced dopamine release on auditory responses in the IC. We found that the effects of dopamine in the IC occur via D2-like receptors. In iontophoretic and freely behaving experiments, the single-unit and multi-unit effects of dopamine and a D2-like agonist were heterogeneous as both either increased or decreased responses of IC neurons to tones, while a D2-like antagonist had opposite effects. We also found that optogenetic activation of the endogenous dopamine system in the IC alters responses of auditory neurons. Similar to the effects of exogenous dopamine application, optogenetic induction of endogenous dopamine release heterogeneously altered auditory responses in the majority of cells in mice expressing channelrhodopsin-2 (ChR2). Understanding how dopamine modulates auditory processing will ultimately inform therapies targeting mechanisms underlying auditory-related communication disorders.
C1 [Hoyt, Jeffrey M.; Portfors, Christine, V] Washington State Univ, Integrat Physiol & Neurosci, Vancouver, WA 98686 USA.
   [Hoyt, Jeffrey M.; Portfors, Christine, V] Washington State Univ, Sch Biol Sci, Vancouver, WA 98686 USA.
   [Perkel, David J.] Univ Washington, Dept Biol, Seattle, WA 98195 USA.
   [Perkel, David J.] Univ Washington, Dept Otolaryngol, Seattle, WA 98195 USA.
RP Portfors, CV (corresponding author), Washington State Univ, Integrat Physiol & Neurosci, Vancouver, WA 98686 USA.; Portfors, CV (corresponding author), Washington State Univ, Sch Biol Sci, Vancouver, WA 98686 USA.
EM portfors@wsu.edu
FU National Institutes of Health National Institute of Deafness and
   Communication DisordersUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01013102]
FX This work was supported by the National Institutes of Health National
   Institute of Deafness and Communication Disorders Grant R01013102 (to
   C.V.P. and D.J.P.).
CR AITKIN LM, 1981, J COMP NEUROL, V196, P25, DOI 10.1002/cne.901960104
   Angwin AJ, 2006, NEUROPSYCHOLOGY, V20, P299, DOI 10.1037/0894-4105.20.3.299
   Aragona BJ, 2003, J NEUROSCI, V23, P3483, DOI 10.1523/jneurosci.23-08-03483.2003
   Ariatti A, 2008, NEUROL SCI, V29, P219, DOI 10.1007/s10072-008-0971-9
   Batton AD, 2019, SYNAPSE, V73, DOI 10.1002/syn.22073
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Bender KJ, 2010, NEURON, V68, P500, DOI 10.1016/j.neuron.2010.09.026
   Bryce CA, 2019, PSYCHOPHARMACOLOGY, V236, P2699, DOI 10.1007/s00213-019-05244-w
   Buentello DC, 2015, J COMP NEUROL, V523, P2683, DOI 10.1002/cne.23810
   Dara C, 2008, BRAIN RES, V1188, P100, DOI 10.1016/j.brainres.2007.10.034
   Dawes P, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119616
   de Oliveira AR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0104228
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Dromey C, 2000, J MED SPEECH-LANG PA, V8, P255
   Flagel SB, 2011, NATURE, V469, P53, DOI 10.1038/nature09588
   Fyk-Kolodziej BE, 2015, FRONT NEUROANAT, V9, DOI 10.3389/fnana.2015.00088
   Gittelman JX, 2013, JARO-J ASSOC RES OTO, V14, P719, DOI 10.1007/s10162-013-0405-0
   Graber S, 2002, BRAIN LANG, V82, P65, DOI 10.1016/S0093-934X(02)00002-0
   Happel MFK, 2014, J NEUROSCI, V34, P1234, DOI 10.1523/JNEUROSCI.1990-13.2014
   HAVEY DC, 1980, ELECTROEN CLIN NEURO, V48, P249, DOI 10.1016/0013-4694(80)90313-2
   Ho AK, 2000, MOVEMENT DISORD, V15, P1125, DOI 10.1002/1531-8257(200011)15:6<1125::AID-MDS1010>3.0.CO;2-R
   KEBABIAN JW, 1978, LIFE SCI, V23, P479, DOI 10.1016/0024-3205(78)90157-1
   Khurana S, 2011, J NEUROSCI, V31, P8936, DOI 10.1523/JNEUROSCI.1079-11.2011
   Kim S, 2019, PUBCHEM DATABASE ACE
   LEDOUX JE, 1985, J COMP NEUROL, V242, P182, DOI 10.1002/cne.902420204
   Li CM, 2014, JAMA OTOLARYNGOL, V140, P293, DOI 10.1001/jamaoto.2014.42
   MALMIERCA MS, 1995, J COMP NEUROL, V357, P124, DOI 10.1002/cne.903570112
   MASCETTI GG, 1988, BRAIN RES, V442, P387, DOI 10.1016/0006-8993(88)91531-4
   Medina J, 2007, J GERIATR PSYCH NEUR, V20, P153, DOI 10.1177/0891988707303603
   Merchan M, 2005, NEUROSCIENCE, V136, P907, DOI 10.1016/j.neuroscience.2004.12.030
   Metzger RR, 2006, J NEUROSCI, V26, P7468, DOI 10.1523/JNEUROSCI.5401-05.2006
   Monteiro ER, 2007, VET ANAESTH ANALG, V34, P312, DOI 10.1111/j.1467-2995.2006.00328.x
   Monzani D, 2008, ACTA OTORHINOLARYNGO, V28, P61
   Muniak MA, 2012, JOVE-J VIS EXP, DOI 10.3791/3755
   Muthuraju S, 2014, NEUROSCIENCE, V261, P195, DOI 10.1016/j.neuroscience.2013.11.063
   Nakamoto KT, 2014, FRONT NEUROANAT, V8, DOI 10.3389/fnana.2014.00108
   Nevue AA, 2016, HEARING RES, V341, P202, DOI 10.1016/j.heares.2016.09.001
   Nevue AA, 2016, FRONT NEUROANAT, V9, DOI 10.3389/fnana.2015.00168
   O'Neill B, 2017, ACS CHEM NEUROSCI, V8, P310, DOI 10.1021/acschemneuro.6b00300
   OLIVER DL, 1991, J COMP NEUROL, V303, P75, DOI 10.1002/cne.903030108
   Paloff AM, 2000, ANN ANAT, V182, P423, DOI 10.1016/S0940-9602(00)80047-3
   Paxinos G., 2001, MOUSE BRAIN STEREOTA
   Perez MF, 2006, J NEUROPHYSIOL, V96, P2217, DOI 10.1152/jn.00254.2006
   Ramanathan S, 2008, J NEUROPHYSIOL, V99, P442, DOI 10.1152/jn.00998.2007
   Rangel-Barajas C, 2015, AGING DIS, V6, P349, DOI 10.14336/AD.2015.0330
   Rinne T, 2008, J NEUROPHYSIOL, V100, P3323, DOI 10.1152/jn.90607.2008
   SaintMarie RL, 1996, J COMP NEUROL, V373, P255, DOI 10.1002/(SICI)1096-9861(19960916)373:2<255::AID-CNE8>3.0.CO;2-2
   SAINTMARIE RL, 1990, BRAIN RES, V524, P244, DOI 10.1016/0006-8993(90)90698-B
   SALDANA E, 1992, J COMP NEUROL, V319, P417, DOI 10.1002/cne.903190308
   Sasaki A, 2006, J NEUROSCI, V26, P9010, DOI 10.1523/JNEUROSCI.1335-06.2006
   Satake S, 2012, NEUROSCI LETT, V509, P60, DOI 10.1016/j.neulet.2011.12.052
   Schreiner CE, 1997, NATURE, V388, P383, DOI 10.1038/41106
   Schroder C, 2010, J NEUROL SCI, V289, P32, DOI 10.1016/j.jns.2009.08.038
   Schultz W, 2010, BEHAV BRAIN FUNCT, V6, DOI 10.1186/1744-9081-6-24
   SIBLEY DR, 1992, TRENDS PHARMACOL SCI, V13, P61, DOI 10.1016/0165-6147(92)90025-2
   Spano P F, 1978, Adv Biochem Psychopharmacol, V19, P155
   Surmeier DJ, 2007, TRENDS NEUROSCI, V30, P228, DOI 10.1016/j.tins.2007.03.008
   TAKADA M, 1988, BRAIN RES, V455, P346, DOI 10.1016/0006-8993(88)90093-5
   Tong L, 2005, HEARING RES, V206, P28, DOI 10.1016/j.heares.2005.03.006
   Toro C, 2015, J NEUROSCI, V35, P16494, DOI 10.1523/JNEUROSCI.1691-15.2015
   Valdez-Baizabal C, 2018, ASS RES OT SAN DIEG
   Vandecasteele M, 2008, P NATL ACAD SCI USA, V105, P4904, DOI 10.1073/pnas.0703121105
   Wallace MN, 2012, FRONT NEURAL CIRCUIT, V6, DOI 10.3389/fncir.2012.00055
   WAMSLEY JK, 1989, J CHEM NEUROANAT, V2, P119
   Wang J, 2006, NEUROSCIENCE, V138, P197, DOI 10.1016/j.neuroscience.2005.11.010
   WEINER DM, 1991, P NATL ACAD SCI USA, V88, P1859, DOI 10.1073/pnas.88.5.1859
   YASUI Y, 1992, EXP BRAIN RES, V90, P508
NR 67
TC 3
Z9 3
U1 1
U2 1
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
EI 2373-2822
J9 ENEURO
JI eNeuro
PD SEP-OCT
PY 2019
VL 6
IS 5
AR UNSP ENEURO.0350-19.2019
DI 10.1523/ENEURO.0350-19.2019
PG 14
WC Neurosciences
SC Neurosciences & Neurology
GA JJ6QC
UT WOS:000494278900015
PM 31548368
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Singh, L
AF Singh, Leher
TI Does infant speech perception predict later vocabulary development in
   bilingual infants?
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Bilingualism; Speech perception; Perceptual attunement
ID LANGUAGE-DEVELOPMENT; BRAIN RESPONSES; 1ST YEAR; CONTRASTS;
   DISCRIMINATION; RECOGNITION; ADULTS; REORGANIZATION; FLEXIBILITY;
   ACQUISITION
AB One of the most significant transitions reported in infant psychological development is perceptual narrowing whereby infants orient towards their native language. In monolingual infants, the progress made by infants in perceptual narrowing positively predicts later vocabulary size. The relationship between infant speech perception and later language development has not been thus far reported in bilingual populations. The present study investigated infant speech perception in relation to later vocabulary development in a prospective longitudinal study of bilingual infants over the first three years of life. Our study revealed three primary findings. First, unlike monolingual infants, bilingual infants demonstrated a positive correlation between native and non-native phonetic discrimination. Second, native speech perception at 10-11 months predicted single-language (English) vocabulary at 2 years, but not second language (Mandarin), nor total conceptual vocabulary. Third, infants with a native language orientation relative to a non-native orientation in phonetic discrimination at 10-11 months tended towards higher English vocabulary scores at 3 years of age. When placed in the context of prior research with monolingual infants, results with bilingual infants point to distinct relationships between native and non-native speech perception in infancy, but to a similar continuity between infant speech discrimination and later vocabulary growth. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Singh, Leher] Natl Univ Singapore, Dept Psychol, 9 Arts Link, Singapore 117570, Singapore.
RP Singh, L (corresponding author), Natl Univ Singapore, Dept Psychol, 9 Arts Link, Singapore 117570, Singapore.
EM leher.singh.nus@gmail.com
FU Ministry of Education [FY2013-FRC2-009]; HSS grant
FX We are grateful to a Ministry of Education Tier 1 Academic Research Fund
   (FY2013-FRC2-009) and an HSS grant awarded to LS. We appreciate
   assistance from Felicia Poh, Charlene Fu, Darrell Loh and Huang Leng
   Wong in recruitment and testing of participants.
CR Albareda-Castellot B, 2011, DEVELOPMENTAL SCI, V14, P395, DOI 10.1111/j.1467-7687.2010.00989.x
   Best CC, 2003, LANG SPEECH, V46, P183, DOI 10.1177/00238309030460020701
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Bosch L, 2003, LANG SPEECH, V46, P217, DOI 10.1177/00238309030460020801
   Bosch L, 1997, COGNITION, V65, P33, DOI 10.1016/S0010-0277(97)00040-1
   Bosch L, 2003, P 15 INT C PHON SCI, P1987
   Burns TC, 2007, APPL PSYCHOLINGUIST, V28, P455, DOI 10.1017/S0142716407070257
   Conboy BT, 2008, DEV PSYCHOL, V44, P1505, DOI 10.1037/a0012975
   Conboy BT, 2011, DEVELOPMENTAL SCI, V14, P242, DOI 10.1111/j.1467-7687.2010.00973.x
   Cristia A, 2014, CHILD DEV, V85, P1330, DOI 10.1111/cdev.12193
   Estes KG, 2015, CHILD DEV, V86, P1371, DOI 10.1111/cdev.12392
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   Fernald A, 2013, DEVELOPMENTAL SCI, V16, P234, DOI 10.1111/desc.12019
   Garcia-Sierra A, 2016, INT J PSYCHOPHYSIOL, V110, P1, DOI 10.1016/j.ijpsycho.2016.10.004
   Garcia-Sierra A, 2011, J PHONETICS, V39, P546, DOI 10.1016/j.wocn.2011.07.002
   Hao ML, 2008, BEHAV RES METHODS, V40, P728, DOI 10.3758/BRM.40.3.728
   Hartanto Andree, 2019, Child Dev, V90, P1215, DOI 10.1111/cdev.13032
   Hay JF, 2015, CHILD DEV, V86, P10, DOI 10.1111/cdev.12269
   Hoff E, 2003, CHILD DEV, V74, P1368, DOI 10.1111/1467-8624.00612
   Hoff E, 2003, MON PARENT, P147
   Hollingshead A., 1975, 4 FACTOR INDEX SOCIA
   Jansson-Verkasalo E, 2010, BMC NEUROSCI, V11, DOI 10.1186/1471-2202-11-88
   Junge C, 2012, DEVELOPMENTAL SCI, V15, P463, DOI 10.1111/j.1467-7687.2012.1144.x
   Kooijman V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00025
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Kuhl PK, 2000, P NATL ACAD SCI USA, V97, P11850, DOI 10.1073/pnas.97.22.11850
   Liu LQ, 2017, BILING-LANG COGN, V20, P561, DOI 10.1017/S1366728916000183
   Liu LQ, 2016, INT J BILINGUAL, V20, P335, DOI 10.1177/1367006914566082
   Liu LQ, 2015, INFANT BEHAV DEV, V38, P27, DOI 10.1016/j.infbeh.2014.12.004
   Marchman VA, 2010, J CHILD LANG, V37, P817, DOI 10.1017/S0305000909990055
   Mattock K, 2010, DEVELOPMENTAL SCI, V13, P229, DOI 10.1111/j.1467-7687.2009.00891.x
   May L, 2014, INFANCY, V19, P281, DOI 10.1111/infa.12048
   Oakes LM, 2019, BEHAV RES METHODS, V51, P1943, DOI 10.3758/s13428-019-01244-y
   PEARSON BZ, 1993, LANG LEARN, V43, P93, DOI 10.1111/j.1467-1770.1993.tb00174.x
   Petitto LA, 2012, BRAIN LANG, V121, P130, DOI 10.1016/j.bandl.2011.05.003
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Pruitt J. S., 1995, J ACOUST SOC AM, V97, P3417, DOI DOI 10.1121/1.412451
   Ramirez NF, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12427
   Rivera-Gaxiola M, 2005, NEUROREPORT, V16, P495, DOI 10.1097/00001756-200504040-00015
   Rowe ML, 2009, DEVELOPMENTAL SCI, V12, P182, DOI 10.1111/j.1467-7687.2008.00764.x
   Sebastian-Galles N, 2009, DEVELOPMENTAL SCI, V12, P874, DOI 10.1111/j.1467-7687.2009.00829.x
   Singh L, 2018, CHILD DEV, V89, pe397, DOI 10.1111/cdev.12852
   Singh L, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01563
   Sundara M, 2008, COGNITION, V108, P232, DOI 10.1016/j.cognition.2007.12.013
   Sundara M, 2006, COGNITION, V100, P369, DOI 10.1016/j.cognition.2005.04.007
   Sundara M, 2011, J PHONETICS, V39, P505, DOI 10.1016/j.wocn.2010.08.006
   Tsao FM, 2006, J ACOUST SOC AM, V120, P2285, DOI 10.1121/1.2338290
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1988, DEV PSYCHOL, V24, P672, DOI 10.1037/0012-1649.24.5.672
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
NR 55
TC 1
Z9 1
U1 2
U2 3
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD SEP
PY 2019
VL 76
AR 100914
DI 10.1016/j.wocn.2019.100914
PG 9
WC Linguistics; Language & Linguistics
SC Linguistics
GA JB6KM
UT WOS:000488673000002
DA 2021-02-24
ER

PT J
AU Zellou, G
   Dahan, D
AF Zellou, Georgia
   Dahan, Delphine
TI Listeners maintain phonological uncertainty over time and across words:
   The case of vowel nasality in English
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Spoken word recognition; Discrimination; Predictability; Eye movements;
   Semantic priming
ID VISUAL WORLD PARADIGM; SPEECH-PERCEPTION; COARTICULATION;
   CATEGORIZATION; CONTEXT; CUES; COMPREHENSION; RECOGNITION; INFORMATION;
   INTEGRATION
AB While the fact that phonetic information is evaluated in a non-discrete, probabilistic fashion is well established, there is less consensus regarding how long such encoding is maintained. Here, we examined whether people maintain in memory the amount of vowel nasality present in a word when processing a subsequent word that holds a semantic dependency with the first one. Vowel nasality in English is an acoustic correlate of the oral vs. nasal status of an adjacent consonant, and sometimes it is the only distinguishing phonetic feature (e.g., bet vs. bent). In Experiment 1, we show that people can perceive differences in nasality between two vowels above and beyond differences in the categorization of those vowels. In Experiment 2, we tracked listeners' eye-movements as they heard a sentence that mentioned one of four displayed images (e.g., 'money') following a prime word (e.g., 'bet') that held a semantic relationship with the target word. Recognition of the target was found to be modulated by the degree of nasality in the first words vowel: Slightly greater uncertainty regarding the oral status of the post-vocalic consonant in the first word translated into a weaker semantic cue for the identification of the second word. Thus, listeners appear to maintain in memory the degree of vowel nasality they perceived on the first word and bring this information to bear onto the interpretation of a subsequent, semantically-dependent word. Probabilistic cue integration across words that hold semantic coherence, we argue, contributes to achieving robust language comprehension despite the inherent ambiguity of the speech signal. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Zellou, Georgia] Univ Calif Davis, Davis, CA 95616 USA.
   [Dahan, Delphine] Univ Penn, Philadelphia, PA 19104 USA.
RP Zellou, G (corresponding author), Univ Calif Davis, Linguist Dept, 469 Kerr Hall,One Shields Ave, Davis, CA 95616 USA.
EM gzellou@ucdavis.edu
OI Zellou, Georgia/0000-0001-9167-0744
CR ALI L, 1971, J ACOUST SOC AM, V49, P538, DOI 10.1121/1.1912384
   ANDRUSKI JE, 1994, COGNITION, V52, P163, DOI 10.1016/0010-0277(94)90042-6
   Aydelott J, 2004, LANG COGNITIVE PROC, V19, P29, DOI 10.1080/01690960344000099
   Beddor PS, 2013, J ACOUST SOC AM, V133, P2350, DOI 10.1121/1.4794366
   Beddor PS, 2009, LANGUAGE, V85, P785
   Bicknell K, 2016, BEHAV BRAIN SCI, V39, DOI 10.1017/S0140525X15000734
   Blumstein SE, 2005, J COGNITIVE NEUROSCI, V17, P1353, DOI 10.1162/0898929054985473
   Brown-Schmidt S, 2017, LANG COGN NEUROSCI, V32, P1211, DOI 10.1080/23273798.2017.1325508
   Chen MY, 1997, J ACOUST SOC AM, V102, P2360, DOI 10.1121/1.419620
   Cho PW, 2017, LINGUIST VANGUARD, V3, DOI 10.1515/lingvan-2016-0105
   Cho T, 2017, J PHONETICS, V64, P71, DOI 10.1016/j.wocn.2016.12.003
   Christiansen MH, 2016, BEHAV BRAIN SCI, V39, DOI 10.1017/S0140525X1500031X
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   CONNINE CM, 1991, J MEM LANG, V30, P234, DOI 10.1016/0749-596X(91)90005-5
   Dahan D, 2004, J EXP PSYCHOL LEARN, V30, P498, DOI 10.1037/0278-7393.30.2.498
   Dahan D, 2001, LANG COGNITIVE PROC, V16, P507, DOI 10.1080/01690960143000074
   Dahan D, 2019, HUMAN LANGUAGE: FROM GENES AND BRAINS TO BEHAVIOR, P21
   Dahan D, 2010, CURR DIR PSYCHOL SCI, V19, P121, DOI 10.1177/0963721410364726
   DeLong KA, 2014, LANG LINGUIST COMPAS, V8, P631, DOI 10.1111/lnc3.12093
   Farris-Trimble A, 2013, J SPEECH LANG HEAR R, V56, P1328, DOI 10.1044/1092-4388(2012/12-0145)
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   LAHIRI A, 1991, COGNITION, V38, P245, DOI 10.1016/0010-0277(91)90008-R
   Levy R., 2008, P 2008 C EMP METH NA, P234, DOI DOI 10.3115/1613715.1613749
   Levy R, 2009, P NATL ACAD SCI USA, V106, P21086, DOI 10.1073/pnas.0907664106
   Massaro D. W., 1992, SPEECH PERCEPTION PR, P79
   MASSARO DW, 1990, PSYCHOL REV, V97, P225, DOI 10.1037/0033-295X.97.2.225
   McClelland JL, 2014, COGNITIVE SCI, V38, P1139, DOI 10.1111/cogs.12146
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   McMurray B, 2009, J MEM LANG, V60, P65, DOI 10.1016/j.jml.2008.07.002
   McMurray B, 2008, PSYCHON B REV, V15, P1064, DOI 10.3758/PBR.15.6.1064
   MILLER JL, 1989, PERCEPT PSYCHOPHYS, V46, P505, DOI 10.3758/BF03208147
   Mirman D, 2008, J MEM LANG, V59, P475, DOI 10.1016/j.jml.2007.11.006
   Nearey TM, 1997, J ACOUST SOC AM, V101, P3241, DOI 10.1121/1.418290
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   RAPHAEL LJ, 1975, J SPEECH HEAR RES, V18, P389, DOI 10.1044/jshr.1803.389
   Remez RE, 2010, ATTEN PERCEPT PSYCHO, V72, P2054, DOI 10.3758/APP.72.8.2054
   Samuel AG, 2016, COGNITIVE PSYCHOL, V88, P88, DOI 10.1016/j.cogpsych.2016.06.007
   Scarborough R, 2013, J PHONETICS, V41, P491, DOI 10.1016/j.wocn.2013.09.004
   Scarborough R, 2013, J ACOUST SOC AM, V134, P3793, DOI 10.1121/1.4824120
   Seedorff M, 2018, J MEM LANG, V102, P55, DOI 10.1016/j.jml.2018.05.004
   Smolensky P, 2014, COGNITIVE SCI, V38, P1102, DOI 10.1111/cogs.12047
   Szostak CM, 2013, ATTEN PERCEPT PSYCHO, V75, P1533, DOI 10.3758/s13414-013-0492-3
   Toscano JC, 2010, PSYCHOL SCI, V21, P1532, DOI 10.1177/0956797610384142
   WARREN P, 1987, PERCEPT PSYCHOPHYS, V41, P262, DOI 10.3758/BF03208224
   WOOD CC, 1976, J ACOUST SOC AM, V60, P1381, DOI 10.1121/1.381231
   Zellou G., 2011, J ACOUST SOC AM, V130, P2443, DOI DOI 10.1121/1.3654800
   Zellou G, 2017, LANG COGN NEUROSCI, V32, P776, DOI 10.1080/23273798.2016.1275710
   Zellou G, 2017, J PHONETICS, V61, P13, DOI 10.1016/j.wocn.2016.12.002
   Zellou G, 2016, J ACOUST SOC AM, V140, P3560, DOI 10.1121/1.4966232
   Zellou G, 2015, LAB PHONOL, V6, P305, DOI 10.1515/lp-2015-0010
   Zellou G, 2014, J PHONETICS, V47, P18, DOI 10.1016/j.wocn.2014.09.002
NR 55
TC 3
Z9 3
U1 1
U2 1
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD SEP
PY 2019
VL 76
AR 100910
DI 10.1016/j.wocn.2019.06.001
PG 20
WC Linguistics; Language & Linguistics
SC Linguistics
GA JB6KM
UT WOS:000488673000003
DA 2021-02-24
ER

PT J
AU Derrick, D
   Madappallimattam, J
   Theys, C
AF Derrick, Donald
   Madappallimattam, Jilcy
   Theys, Catherine
TI Aero-tactile integration during speech perception: Effect of response
   and stimulus characteristics on syllable identification
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID VOICE ONSET TIME; ARTICULATION; SOFTWARE; PLACE
AB Integration of auditory and aero-tactile information during speech perception has been documented during two-way closed-choice syllable classification tasks [Gick and Derrick (2009). Nature 462, 502-504], but not during an open-choice task using continuous speech perception [Derrick, O'Beirne, Gorden, De Rybel, Fiasson, and Hay (2016). J. Acoust. Soc. Am. 140(4), 3225]. This study was designed to compare audio-tactile integration during open-choice perception of individual syllables. In addition, this study aimed to compare the effects of place and manner of articulation. Thirty-four untrained participants identified syllables in both auditory-only and audio-tactile conditions in an open-choice paradigm. In addition, forty participants performed a closed-choice perception experiment to allow direct comparison between these two response-type paradigms. Adaptive staircases, as noted by Watson [(1983). Percept. Psychophys. 33(2), 113-120] were used to identify the signal-to-noise ratio for identification accuracy thresholds. The results showed no significant effect of air flow on syllable identification accuracy during the open-choice task, but found a bias towards voiceless identification of labials, and towards voiced identification of velars. Comparison of the open-choice results to those of the closed-choice task show a significant difference between both response types, with audio-tactile integration shown in the closed-choice task, but not in the open-choice task. These results suggest that aero-tactile enhancement of speech perception is dependent on response type demands.
C1 [Derrick, Donald] Univ Canterbury, New Zealand Inst Language Brain & Behav, 20 Kirkwood Ave, Christchurch 8041, New Zealand.
   [Madappallimattam, Jilcy; Theys, Catherine] Univ Canterbury, Sch Psychol Speech & Hearing, 20 Kirkwood Ave, Christchurch 8041, New Zealand.
RP Derrick, D (corresponding author), Univ Canterbury, New Zealand Inst Language Brain & Behav, 20 Kirkwood Ave, Christchurch 8041, New Zealand.
EM donald.derrick@canterbury.ac.nz
FU New Zealand Ministry of Business, Innovation, and Employment "Smart
   Ideas" Phase II grant "Aero-tactile Enhancement of Speech Perception
   Phase 2"; University of Canterbury
FX This research was funded by a New Zealand Ministry of Business,
   Innovation, and Employment "Smart Ideas" Phase II grant "Aero-tactile
   Enhancement of Speech Perception Phase 2" to the first author. We would
   also like to thank the University of Canterbury for a Marsden Support
   Fund grant "How do our brains hear, see and feel speech?" to the first
   and third author.
CR [Anonymous], 2014, MATLAB STAT TOOLB RE
   Araya-Salas M, 2017, METHODS ECOL EVOL, V8, P184, DOI 10.1111/2041-210X.12624
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Benki JR, 2001, J PHONETICS, V29, P1, DOI 10.1006/jpho.2000.0128
   Bicevskis K, 2016, J ACOUST SOC AM, V140, P3531, DOI 10.1121/1.4965968
   Boersma Paul, 2019, PRAAT DOING PHONETIC
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Cassels TG, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093653
   Colin C, 2005, EUR J COGN PSYCHOL, V17, P541, DOI 10.1080/09541440440000168
   Derrick D., 2016, 5 JOINT M AC SOC AM
   Derrick D., 2018, LABPHON, P2
   Derrick D., P 15 ANN C INT SPEEC, P2580
   Derrick D., 2015, PCT patent, Patent No. [WO2015/122785A1, 2015122785]
   Derrick D, 2015, CAN ACOUST, V43, P3
   Derrick D., 2019, P 19 INT C PHON SCI, P3508
   Derrick D., 2016, J ACOUST SOC AM, V140, P3225, DOI [10.1121/1.4970183, DOI 10.1121/1.4970183]
   Derrick D, 2014, INTERSPEECH, P1484
   Derrick D, 2013, MULTISENS RES, V26, P405, DOI 10.1163/22134808-00002427
   EIMAS PD, 1978, PERCEPT PSYCHOPHYS, V23, P12, DOI 10.3758/BF03214289
   FFmpeg Developers, 2016, FFMPEG TOOL COMP SOF
   FOWLER CA, 1991, J EXP PSYCHOL HUMAN, V17, P816, DOI 10.1037/0096-1523.17.3.816
   Gick B, 2010, J ACOUST SOC AM, V128, pEL342, DOI 10.1121/1.3505759
   Gick B, 2009, NATURE, V462, P502, DOI 10.1038/nature08572
   Goldenberg D., 2015, P 18 INT C PHON SCI
   Jansen S, 2010, INT J AUDIOL, V49, P378, DOI 10.3109/14992020903431272
   Kleiner M., 2007, PERC 30 EUR C VIS S
   LISKER L, 1967, LANG SPEECH, V10, P1, DOI 10.1177/002383096701000101
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   LISKER L, 1970, P 6 INT C PHON SCI
   Massaro D. W., 1998, PERCEIVING TALKING F
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MILLER JL, 1977, J ACOUST SOC AM, V61, P835, DOI 10.1121/1.381373
   ORNE MT, 1962, AM PSYCHOL, V17, P776, DOI 10.1037/h0043424
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Peirce JW, 2009, FRONT NEUROINFORM, V2, DOI 10.3389/neuro.11.010.2008
   PELLI D G, 1987, Investigative Ophthalmology and Visual Science, V28, P366
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Phatak SA, 2007, J ACOUST SOC AM, V121, P2312, DOI 10.1121/1.2642397
   PHILLIPS JR, 1990, EXP BRAIN RES, V81, P589, DOI 10.1007/BF02423508
   R Development Core Team, 2018, R LANG ENV STAT COMP
   Sawusch James R, 1974, J Phon, V2, P181
   Smits C, 2004, INT J AUDIOL, V43, P15, DOI 10.1080/14992020400050004
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Treille A, 2014, NEUROPSYCHOLOGIA, V57, P71, DOI 10.1016/j.neuropsychologia.2014.02.004
   WATSON AB, 1983, PERCEPT PSYCHOPHYS, V33, P113, DOI 10.3758/BF03202828
   ZLATIN MA, 1974, J ACOUST SOC AM, V56, P981, DOI 10.1121/1.1903359
NR 46
TC 1
Z9 1
U1 0
U2 0
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD SEP
PY 2019
VL 146
IS 3
BP 1605
EP 1614
DI 10.1121/1.5125131
PG 10
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA JC3DY
UT WOS:000489159400027
PM 31590504
OA Green Published
DA 2021-02-24
ER

PT J
AU Otsuka, S
   Nakagawa, S
   Furukawa, S
AF Otsuka, Sho
   Nakagawa, Seiji
   Furukawa, Shigeto
TI Relationship between cochlear mechanics and speech-in-noise reception
   performance
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID INDIVIDUAL-DIFFERENCES; OTOACOUSTIC EMISSIONS; NORMAL-HEARING; SOUNDS
AB Some normal-hearing listeners report difficulties in speech perception in noisy environments, and the cause is not well understood. The present study explores the correlation between speech-in-noise reception performance and cochlear mechanical characteristics, which were evaluated using a principal component analysis of the otoacoustic emission (OAE) spectra. A principal component, specifically a characteristic dip at around 2-2.5 kHz in OAE spectra, correlated with speech reception thresholds in noise but not in quiet. The results suggest that subclinical cochlear dysfunction specifically contributes to difficulties in speech perception in noisy environments, which is possibly a new form of "hidden hearing deficits."
C1 [Otsuka, Sho; Nakagawa, Seiji] Chiba Univ, Ctr Frontier Med Engn, Inage Ku, 1-33 Yayoicho, Chiba, Chiba 2638522, Japan.
   [Furukawa, Shigeto] NTT Corp, NTT Commun Sci Labs, 3-1 Morinosato Wakamiya, Atsugi, Kanagawa 2430198, Japan.
   [Otsuka, Sho; Nakagawa, Seiji] Chiba Univ, Ctr Frontier Med Engn, Chiba, Japan.
RP Otsuka, S (corresponding author), Chiba Univ, Ctr Frontier Med Engn, Inage Ku, 1-33 Yayoicho, Chiba, Chiba 2638522, Japan.
EM otsuka.s@chiba-u.jp; s-nakagawa@chiba-u.jp;
   shigeto.furukawa.ne@hco.ntt.co.jp
FU JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [18K18066];
   Health Science Center Foundation
FX This work was supported by JSPS KAKENHI [Grant No. 18K18066] and Health
   Science Center Foundation. S.O., S.N., and S.F. conceived the study and
   designed the experiments. S.O. performed the experiments and analyzed
   the data. S.O., S.N., and S.F. wrote the paper. We declare that we have
   no conflict of interest.
CR Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Badri R, 2011, J ACOUST SOC AM, V129, P852, DOI 10.1121/1.3523476
   Bharadwaj HM, 2015, J NEUROSCI, V35, P2161, DOI 10.1523/JNEUROSCI.3915-14.2015
   Bharadwaj HM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00026
   Choi YS, 2008, J ACOUST SOC AM, V123, P2651, DOI 10.1121/1.2902184
   Conway ARA, 2001, PSYCHON B REV, V8, P331, DOI 10.3758/BF03196169
   Furman AC, 2013, J NEUROPHYSIOL, V110, P577, DOI 10.1152/jn.00164.2013
   HILGER AW, 1995, HEARING RES, V84, P1, DOI 10.1016/0378-5955(95)00007-Q
   Hinchcliffe R., 1992, J AUDIOL MED, V1, P89
   KEMP DT, 1978, J ACOUST SOC AM, V64, P1386, DOI 10.1121/1.382104
   Kidd GR, 2007, J ACOUST SOC AM, V122, P418, DOI 10.1121/1.2743154
   KING K, 1992, SCAND AUDIOL, V21, P109, DOI 10.3109/01050399209045990
   Kujawa SG, 2009, J NEUROSCI, V29, P14077, DOI 10.1523/JNEUROSCI.2845-09.2009
   LACHENBR.PA, 1968, TECHNOMETRICS, V10, P1, DOI 10.2307/1266219
   Lobarinas E, 2013, HEARING RES, V302, P113, DOI 10.1016/j.heares.2013.03.012
   Lopez-Poveda EA, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00124
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Moore D.R., 2006, AUDIOL MED, V4, P4, DOI DOI 10.1080/16513860600568573
   Otsuka S, 2016, JARO-J ASSOC RES OTO, V17, P541, DOI 10.1007/s10162-016-0581-9
   Otsuka S, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146751
   Otsuka S, 2014, JARO-J ASSOC RES OTO, V15, P175, DOI 10.1007/s10162-013-0439-3
   Plack CJ, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514550621
   PROBST R, 1991, J ACOUST SOC AM, V89, P2027, DOI 10.1121/1.400897
   Ruggles D, 2011, P NATL ACAD SCI USA, V108, P15516, DOI 10.1073/pnas.1108912108
   SAUNDERS GH, 1989, EAR HEARING, V10, P200, DOI 10.1097/00003446-198906000-00011
   SCHUKNECHT H F, 1955, J Laryngol Otol, V69, P75, DOI 10.1017/S0022215100050465
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   Strelcyk O, 2009, J ACOUST SOC AM, V125, P3328, DOI 10.1121/1.3097469
   Surprenant AM, 2001, J ACOUST SOC AM, V110, P2085, DOI 10.1121/1.1404973
   Tognola G, 1997, HEARING RES, V106, P112, DOI 10.1016/S0378-5955(97)00007-5
   WIT HP, 1994, HEARING RES, V73, P141, DOI 10.1016/0378-5955(94)90228-3
   Zhao F, 2006, INT J AUDIOL, V45, P34, DOI 10.1080/02640410500243939
   Zhao F, 1999, ACTA OTO-LARYNGOL, V119, P306
   Zhao F., 2007, AUDIOL MED, V5, P119, DOI DOI 10.1080/16513860701296421
   ZWEIG G, 1995, J ACOUST SOC AM, V98, P2018, DOI 10.1121/1.413320
NR 36
TC 0
Z9 0
U1 0
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD SEP
PY 2019
VL 146
IS 3
BP EL265
EP EL271
DI 10.1121/1.5125008
PG 7
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA JC3DY
UT WOS:000489159400012
PM 31590549
OA Bronze
DA 2021-02-24
ER

PT J
AU Shen, J
   Souza, PE
AF Shen, Jing
   Souza, Pamela E.
TI The ability to glimpse dynamic pitch in noise by younger and older
   listeners
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID FUNDAMENTAL-FREQUENCY; SPEECH RECOGNITION; HEARING-LOSS;
   INTELLIGIBILITY; INTONATION; MODULATION; SEPARATION; SIGNALS
AB While dynamic pitch is helpful for speech perception in temporally-modulated noise, the ability to benefit from this cue varies substantially among older listeners. To examine the perceptual factors that contribute to this variability, this study aimed to characterize individuals' ability to perceive dynamic pitch in temporally-modulated noise using dynamic pitch segments extracted from real speech and embedded in temporally modulated noise. Data from younger and older listeners showed stronger pitch contours were more easily perceived than weaker pitch contours. The metric significantly predicted speech-in-noise ability in older listeners. Potential implications of this work are discussed.
C1 [Shen, Jing] Western Michigan Univ, Kalamazoo, MI 49008 USA.
   [Souza, Pamela E.] Northwestern Univ, Evanston, IL 60208 USA.
RP Shen, J (corresponding author), Western Michigan Univ, Kalamazoo, MI 49008 USA.
EM jing.shen@wmich.edu; p-souza@northwestern.edu
FU NIHGrantUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R21DC017560, R01DC012289]; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01DC012289, R01DC012289, R01DC012289, R01DC012289,
   R01DC012289, R01DC012289, R21DC017560, R21DC017560] Funding Source: NIH
   RePORTER
FX The authors thank Alexandra Brockner and Melissa Sherman for assistance
   with data collection. Work supported by NIHGrant Nos. R21DC017560 and
   R01DC012289.
CR [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   Assmann P. F., 1999, P 14 INT C PHON SCI, P179
   BADDELEY AD, 1975, J VERB LEARN VERB BE, V14, P575, DOI 10.1016/S0022-5371(75)80045-4
   Bates D., 2014, R PACKAGE VERSION LME4 LINEAR MIXED EF LME4 LINEAR MIXED EF, DOI DOI 10.18637/JSS.V067.I01
   Binns C, 2007, J ACOUST SOC AM, V122, P1765, DOI 10.1121/1.2751394
   Boersma P, PRAAT DOING PHONETIC
   Bregman AS., 1994, AUDITORY SCENE ANAL
   BROKX JPL, 1982, J PHONETICS, V10, P23, DOI 10.1016/S0095-4470(19)30909-X
   Brown M, 2011, PSYCHON B REV, V18, P1189, DOI 10.3758/s13423-011-0167-9
   Chandrasekaran B, 2009, BRAIN LANG, V108, P1, DOI 10.1016/j.bandl.2008.02.001
   Coffey EBJ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152374
   CUTLER A, 1976, PERCEPT PSYCHOPHYS, V20, P55, DOI 10.3758/BF03198706
   Dreschler WA, 2001, AUDIOLOGY, V40, P148
   Fairbanks G, 1940, J ACOUST SOC AM, V11, P457, DOI 10.1121/1.1916060
   Green T, 2002, J ACOUST SOC AM, V112, P2155, DOI 10.1121/1.1506688
   Hirst D, 2012, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON SPEECH PROSODY, VOLS I AND II, P15
   KILLION MC, 2001, J ACOUST SOC AM, V109, P2502, DOI DOI 10.1121/1.4744912
   Kuznetsova A., LMERTEST TESTS RANDO
   Ladd D.Robert., 1996, INTONATIONAL PHONOLO
   Laures JS, 2003, J COMMUN DISORD, V36, P449, DOI 10.1016/S0021-9924(03)00032-7
   Lehiste Isle, 1976, CONT ISSUES EXPT PHO, P225
   Makowski D., 2018, J OPEN SOURCE SOFTW, V3, P470, DOI [10.21105/joss.00470, DOI 10.21105/J0SS.00470]
   MILLER GA, 1950, J ACOUST SOC AM, V22, P167, DOI 10.1121/1.1906584
   Miller SE, 2010, J ACOUST SOC AM, V128, P435, DOI 10.1121/1.3397384
   Nooteboom S. G., 1978, STUDIES PERCEPTION L, P75
   Palmer A. R., 1998, PSYCHOPHYSICAL PHYSL, P263
   Sheft S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134330
   Sheft S, 2012, EAR HEARING, V33, P709, DOI 10.1097/AUD.0b013e31825aab15
   Shen J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01967
   Shen J, 2017, AM J AUDIOL, V26, P462, DOI 10.1044/2017_AJA-16-0137
   Shen J, 2017, J SPEECH LANG HEAR R, V60, P2725, DOI 10.1044/2017_JSLHR-H-16-0389
   Shen J, 2016, J SPEECH LANG HEAR R, V59, P572, DOI 10.1044/2015_JSLHR-H-15-0228
   Summers V, 1998, J SPEECH LANG HEAR R, V41, P1294, DOI 10.1044/jslhr.4106.1294
   SWETS JA, 1961, PSYCHOL REV, V68, P301, DOI 10.1037/h0040547
   TAKAHASHI GA, 1992, J SPEECH HEAR RES, V35, P1410, DOI 10.1044/jshr.3506.1410
   Wu MH, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0209976
NR 36
TC 0
Z9 0
U1 0
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD SEP
PY 2019
VL 146
IS 3
BP EL232
EP EL237
DI 10.1121/1.5126021
PG 6
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA JC3DY
UT WOS:000489159400007
PM 31590538
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Steffman, J
   Jun, SA
AF Steffman, Jeremy
   Jun, Sun-Ah
TI Perceptual integration of pitch and duration: Prosodic and
   psychoacoustic influences in speech perception
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID FUNDAMENTAL-FREQUENCY; VOWEL DURATION; CUE
AB Two experiments explored how pitch influences perception of vowel duration as a cue to voicing in light of (1) psychoacoustic interactions between pitch and duration and (2) predicted compensatory effects based on the patterning of pitch and duration in the accentual/prominence-marking system of English. Listeners categorized a "coat"-"code" vowel duration continuum with pitch height on the vowel manipulated. In experiment 1 the expected psychoacoustic effect was observed. In experiment 2 the continuum was altered, highlighting pitch as a prosodic property, resulting in predicted compensatory effects. Results thus indicate prosodic patterns can mediate the perception of durational cues in isolated words.
C1 [Steffman, Jeremy; Jun, Sun-Ah] Univ Calif Los Angeles, Dept Linguist, 3125 Campbell Hall, Los Angeles, CA 90095 USA.
RP Steffman, J (corresponding author), Univ Calif Los Angeles, Dept Linguist, 3125 Campbell Hall, Los Angeles, CA 90095 USA.
EM jsteffman@ucla.edu; jun@humnet.ucla.edu
CR Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   BRIGNER WL, 1988, PERCEPT MOTOR SKILL, V67, P301, DOI 10.2466/pms.1988.67.1.301
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Cho T, 2016, LANG LINGUIST COMPAS, V10, P120, DOI 10.1111/lnc3.12178
   Dainora A., 2006, LAB PHONOLOGY, V8
   Green KP, 1997, PERCEPT PSYCHOPHYS, V59, P675, DOI 10.3758/BF03206015
   Greenberg S, 2003, J PHONETICS, V31, P465, DOI 10.1016/j.wocn.2003.09.005
   GRUENENFELDER TM, 1980, PERCEPT PSYCHOPHYS, V28, P514, DOI 10.3758/BF03198819
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Kimball A., 2015, P 18 INT C PHON SCI, P1
   KLATT D. H., 1975, STRUCTURE PROCESSP, P69, DOI [DOI 10.1007/978-3-642-81000-8_, 10.1007/978-3-642-81000-8_5]
   Kochanski G, 2005, J ACOUST SOC AM, V118, P1038, DOI 10.1121/1.1923349
   KOHLER KJ, 1985, J ACOUST SOC AM, V78, P21, DOI 10.1121/1.392562
   Ladd DR, 1997, J PHONETICS, V25, P313, DOI 10.1006/jpho.1997.0046
   Lehiste I., 1976, J PHONETICS, V4, P113
   Miller J. L., 1987, MODULARITY KNOWLEDGE, P309
   Mitterer H, 2016, J PHONETICS, V54, P68, DOI 10.1016/j.wocn.2015.09.002
   Mo Yajun, 2011, THESIS
   Pierrehumbert J., 1980, THESIS
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Prince JB, 2011, Q J EXP PSYCHOL, V64, P2125, DOI 10.1080/17470218.2011.573080
   RAPHAEL LJ, 1972, J ACOUST SOC AM, V51, P1296, DOI 10.1121/1.1912974
   Schweitzer K, 2015, SPEECH COMMUN, V66, P65, DOI 10.1016/j.specom.2014.09.006
   Simko J., 2016, 18TH INTERNATIONAL C
   Steffman J, 2019, J ACOUST SOC AM, V145, pEL560, DOI 10.1121/1.5111772
   Turk AE, 1997, J PHONETICS, V25, P25, DOI 10.1006/jpho.1996.0032
   Yu A., 2014, 4 INT S TON ASP LANG, P41
NR 27
TC 1
Z9 1
U1 1
U2 2
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD SEP
PY 2019
VL 146
IS 3
BP EL251
EP EL257
DI 10.1121/1.5126107
PG 7
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA JC3DY
UT WOS:000489159400010
PM 31590516
OA Bronze
DA 2021-02-24
ER

PT J
AU Marino, C
   Gervain, J
AF Marino, Caterina
   Gervain, Judit
TI The impact of generative linguistics on psychology: Language
   acquisition, a paradigm example
SO ACTA LINGUISTICA HUNGARICA
LA English
DT Article
DE language acquisition; generative linguistics; poverty of the stimulus;
   logical problem of language acquisition; bootstrapping theories of
   language acquisition
ID SPEECH-PERCEPTION; INFANTS SENSITIVITY; CRITICAL PERIOD; ZEBRA FINCHES;
   WORD-ORDER; 1ST YEAR; RULE; LEARN; SEQUENCES; DYNAMICS
AB Noam Chomsky's early work was at the core of the "cognitive revolution" in the 1950s-60s, leading to a paradigm shift from a behavioralist to a mentalistic approach to human psychology. Central to this revolution has been the question of how infants learn language. Here, we provide an overview of how the generative enterprise has shaped research on language acquisition over the last decades. We argue that a large body of empirical knowledge about infants' representation of grammar has accumulated. Many of these questions would most likely not have been investigated empirically without the impetus of such a mentalistic approach.
C1 [Marino, Caterina] Univ Paris 05, INCC, UMR8002, Paris, France.
   [Gervain, Judit] CNRS, INCC, UMR8002, Paris, France.
RP Marino, C (corresponding author), Univ Paris 05, INCC, UMR8002, Paris, France.
EM cateemar@gmail.com; judit.gervain@parisdescartes.fr
OI Gervain, Judit/0000-0002-2125-6369
FU Human Frontiers Science ProgramHuman Frontier Science Program [RGY
   0073/2014]; ERCEuropean Research Council (ERC)European Commission
   [773202 ERC-2017-COG]; Labex EFL grant of the ANR progam
   "Investissements d'Avenir"French National Research Agency (ANR)
   [ANR-10-LABX- 0083]; Marie Curie ITN grant "PredictAble"
FX This work was supported by the Human Frontiers Science Program Young
   Investigator Grant nr. RGY 0073/2014, an ERC Consolidator Grant 773202
   ERC-2017-COG "BabyRhythm", the Labex EFL grant of the ANR progam
   "Investissements d'Avenir" (reference: ANR-10-LABX- 0083), as well as
   the Marie Curie ITN grant "PredictAble" to JG.
CR Abboub N, 2016, BRAIN LANG, V162, P46, DOI 10.1016/j.bandl.2016.08.002
   Abney S., 1987, THESIS
   Ackles P. K., 1988, ADV PSYCHOPHYSIOLOGY, V3, P139
   Bastiaansen M, 2006, PROG BRAIN RES, V159, P179, DOI 10.1016/S0079-6123(06)59012-0
   Bastiaansen M, 2010, J COGNITIVE NEUROSCI, V22, P1333, DOI 10.1162/jocn.2009.21283
   BERKO J, 1958, WORD, V14, P150, DOI 10.1080/00437956.1958.11659661
   Bernard C, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00451
   Best C.T., 1994, DEV SPEECH PERCEPTIO, P167
   Bickerton D., 2016, ROOTS LANGUAGE
   Boas Franz, 1940, RACE LANGUAGE CULTUR
   Braine MartinD.S., 1971, ONTOGENESIS GRAMMAR, P153
   Bybee J.L., 2001, FREQUENCY EMERGENCE
   Chen JN, 2015, ANIM COGN, V18, P151, DOI 10.1007/s10071-014-0786-4
   CHOMSKY N, 1959, LANGUAGE, V35, P26, DOI 10.2307/411334
   Chomsky N., 1981, LECT GOVT BINDING
   Chomsky N., 1995, MINIMALIST PROGRAM
   Chomsky N, 2007, STUD GENERAT GRAMM, V89, P1
   Chomsky Noam, 1957, SYNTACTIC STRUCTURES
   Chomsky Noam, 1965, ASPECTS THEORY SYNTA, V11
   Christiansen M. H., 2003, LANGUAGE EVOLUTION
   Christophe A, 1997, LANG COGNITIVE PROC, V12, P585, DOI 10.1080/016909697386637
   Christophe A, 2003, DEVELOPMENTAL SCI, V6, P211, DOI 10.1111/1467-7687.00273
   CRAIN S, 1991, BEHAV BRAIN SCI, V14, P597, DOI 10.1017/S0140525X00071491
   CRAIN S, 1987, LANGUAGE, V63, P522, DOI 10.2307/415004
   CURTISS S, 1974, LANGUAGE, V50, P528, DOI 10.2307/412222
   Cutler A., 1987, Computer Speech and Language, V2, P133, DOI 10.1016/0885-2308(87)90004-0
   Dawson C, 2009, COGNITION, V111, P378, DOI 10.1016/j.cognition.2009.02.010
   de la Mora D. M., 2012, ATTEN PERCEPT PSYCHO, P1
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   Dehaene-Lambertz G, 2008, EUR REV, V16, P399, DOI DOI 10.1017/S1062798708000513
   DRYER MS, 1992, LANGUAGE, V68, P81, DOI 10.2307/416370
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Elman JL., 1996, RETHINKING INNATENES
   Endress AD, 2009, TRENDS COGN SCI, V13, P348, DOI 10.1016/j.tics.2009.05.005
   Faulkner KF, 2013, NEUROSCI DISCOV, V1, P9, DOI DOI 10.7243/2052-6946-1-9
   Ferguson Charles A., 1978, UNIVERSALS HUMAN LAN
   Fitch WT, 2004, SCIENCE, V303, P377, DOI 10.1126/science.1089401
   Frank MC, 2009, DEVELOPMENTAL SCI, V12, P504, DOI 10.1111/j.1467-7687.2008.00794.x
   Franklin TB, 2010, NEUROBIOL DIS, V39, P61, DOI 10.1016/j.nbd.2009.11.012
   Friederici AD, 2003, CEREB CORTEX, V13, P170, DOI 10.1093/cercor/13.2.170
   Friederici AD, 2000, J MEM LANG, V43, P476, DOI 10.1006/jmla.2000.2709
   Friederici AD, 2007, CURR BIOL, V17, P1208, DOI 10.1016/j.cub.2007.06.011
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   Fukui N., 1986, THESIS
   Gentner TQ, 2006, NATURE, V440, P1204, DOI 10.1038/nature04675
   Gervain J, 2008, COGNITIVE PSYCHOL, V57, P56, DOI 10.1016/j.cogpsych.2007.12.001
   Gervain J, 2020, TOP COGN SCI, V12, P815, DOI 10.1111/tops.12400
   Gervain J, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2430
   Gervain J, 2012, J COGNITIVE NEUROSCI, V24, P564, DOI 10.1162/jocn_a_00157
   Gervain J, 2011, DEV COGN NEUROS-NETH, V1, P22, DOI 10.1016/j.dcn.2010.07.004
   Gervain Judit, 2012, J CHILD LANGUAGE 1 V, P1
   Gleitman L. R., 1994, ACQUISITION LEXICON
   Gleitman L. R., 1982, LANG ACQUIS, P3
   Gleitman Lelia, 1990, LANG ACQUIS, V1, P3, DOI DOI 10.1207/S15327817LA0101_2
   Gomez RL, 2000, TRENDS COGN SCI, V4, P178, DOI 10.1016/S1364-6613(00)01467-4
   Gomez RL, 1999, COGNITION, V70, P109, DOI 10.1016/S0010-0277(99)00003-7
   Graff J, 2008, BEHAV BRAIN RES, V192, P70, DOI 10.1016/j.bbr.2008.01.021
   Hauser MD, 2002, SCIENCE, V298, P1569, DOI 10.1126/science.298.5598.1569
   Hochmann JR, 2008, COGNITIVE SCI, V32, P1021, DOI 10.1080/03640210801897849
   Hochmann JR, 2010, COGNITION, V115, P444, DOI 10.1016/j.cognition.2010.03.006
   Jirtle RL, 2007, NAT REV GENET, V8, P253, DOI 10.1038/nrg2045
   JOHNSON JS, 1989, COGNITIVE PSYCHOL, V21, P60, DOI 10.1016/0010-0285(89)90003-0
   Johnson SP, 2009, INFANCY, V14, P2, DOI 10.1080/15250000802569611
   Kegl J., 2002, DIRECTIONS SIGN LANG, P207
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   Kucera H., 1967, COMPUTATIONAL ANAL P
   Kuhl PK, 2010, NEURON, V67, P713, DOI 10.1016/j.neuron.2010.08.038
   KUHL PK, 1993, NATO ADV SCI INST SE, V69, P259
   Landau B., 1985, LANGUAGE EXPERIENCE
   Lany J, 2010, PSYCHOL SCI, V21, P284, DOI 10.1177/0956797609358570
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lenneberg E. H., 1967, BIOL FDN LANGUAGE
   Lewkowicz DJ, 2000, PSYCHOL BULL, V126, P281, DOI 10.1037/0033-2909.126.2.281
   Lidz J, 2003, COGNITION, V87, P151, DOI 10.1016/S0010-0277(02)00230-5
   Liu L, 2009, NEUROBIOL AGING, V30, P549, DOI 10.1016/j.neurobiolaging.2007.07.020
   MacWhinney B., 2000, CHILDES PROJECT TOOL
   Malassis R, 2018, COGNITIVE SCI, V42, P1677, DOI 10.1111/cogs.12617
   Marchetto E, 2015, J CHILD LANG, V42, P873, DOI 10.1017/S0305000914000452
   Marcus G., 2018, DEEP LEARNING CRITIC
   Marcus GF, 2007, PSYCHOL SCI, V18, P387, DOI 10.1111/j.1467-9280.2007.01910.x
   Marcus GF, 1999, SCIENCE, V283, P77, DOI 10.1126/science.283.5398.77
   MARCUS GF, 1993, COGNITION, V46, P53, DOI 10.1016/0010-0277(93)90022-N
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   Minagawa-Kawai Y, 2007, J NEUROSCI, V27, P315, DOI 10.1523/JNEUROSCI.1984-06.2007
   Morgan J., 1996, SIGNAL SYNTAX BOOTST
   Musso M, 2003, NAT NEUROSCI, V6, P774, DOI 10.1038/nn1077
   Narayan Chandan R., DEV SCI
   Nespor M, 2008, LINGUE LINGUAGGIO, V7, P139, DOI 10.1418/28093
   Nespor Marina, 1990, LOGICAL ISSUES LANGU, P157
   Nespor Marina, 1986, PROSODIC PHONOLOGY
   Pelucchi B, 2009, COGNITION, V113, P244, DOI 10.1016/j.cognition.2009.07.011
   Pena M, 2003, P NATL ACAD SCI USA, V100, P11702, DOI 10.1073/pnas.1934290100
   Petkov CI, 2018, CURR OPIN BEHAV SCI, V21, pV, DOI 10.1016/j.cobeha.2018.06.002
   PINKER S, 1990, BEHAV BRAIN SCI, V13, P707, DOI 10.1017/S0140525X00081061
   Pinker S., 1984, LANGUAGE LEARNABILIT
   Poeppel D, 2014, CURR OPIN NEUROBIOL, V28, P142, DOI 10.1016/j.conb.2014.07.005
   Pullum GK, 2002, LINGUIST REV, V19, P9, DOI 10.1515/tlir.19.1-2.9
   Pulvermuller F, 1999, BEHAV BRAIN SCI, V22, P253, DOI 10.1017/S0140525X9900182X
   Ravignani A, 2013, BIOL LETTERS, V9, DOI 10.1098/rsbl.2013.0852
   Reber A. S., 1967, J EXPT PSYCHOL HUMAN, V2, P88
   REBER AS, 1969, J EXP PSYCHOL, V81, P115, DOI 10.1037/h0027454
   Rey A, 2019, TOP COGN SCI, V11, P573, DOI 10.1111/tops.12343
   Roth TL, 2009, CURR OPIN NEUROBIOL, V19, P336, DOI 10.1016/j.conb.2009.05.011
   Saffran JR, 2007, COGNITION, V105, P669, DOI 10.1016/j.cognition.2006.11.004
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Sato Y, 2010, J COGNITIVE NEUROSCI, V22, P2503, DOI 10.1162/jocn.2009.21377
   Selkirk Elizabeth, 1984, PHONOLOGY SYNTAX REL
   Senghas A, 2001, PSYCHOL SCI, V12, P323, DOI 10.1111/1467-9280.00359
   Shi RS, 1999, COGNITION, V72, pB11, DOI 10.1016/S0010-0277(99)00047-5
   Skinner B. F., 1957, VERBAL BEHAV
   Slater A, 2010, CHILD DEV PERSPECT, V4, P205, DOI 10.1111/j.1750-8606.2010.00147.x
   SNOW C, 1987, SENSITIVE PERIODS DE, P183
   SNOW CE, 1978, CHILD DEV, V49, P1114, DOI 10.2307/1128751
   Spierings M, 2017, ANIM COGN, V20, P665, DOI 10.1007/s10071-017-1089-3
   Teinonen T, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-21
   Tomasello M, 2000, COGNITION, V74, P209, DOI 10.1016/S0010-0277(99)00069-4
   Toro JM, 2016, COGNITION, V146, P1, DOI 10.1016/j.cognition.2015.09.006
   van Turennout M, 1998, SCIENCE, V280, P572, DOI 10.1126/science.280.5363.572
   Waddington CH, 1942, NATURE, V150, P563, DOI 10.1038/150563a0
   Watson TL, 2014, DEV PSYCHOBIOL, V56, P1454, DOI 10.1002/dev.21243
   Weikum WM, 2012, P NATL ACAD SCI USA, V109, P17221, DOI 10.1073/pnas.1121263109
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wilson B, 2013, J NEUROSCI, V33, P18825, DOI 10.1523/JNEUROSCI.2414-13.2013
   Zhang TY, 2010, ANNU REV PSYCHOL, V61, P439, DOI 10.1146/annurev.psych.60.110707.163625
NR 126
TC 1
Z9 1
U1 2
U2 10
PU AKADEMIAI KIADO ZRT
PI BUDAPEST
PA BUDAFOKI UT 187-189-A-3, H-1117 BUDAPEST, HUNGARY
SN 1216-8076
EI 1588-2624
J9 ACTA LINGUIST HUNGAR
JI Acta Linguist. Hung.
PD SEP
PY 2019
VL 66
IS 3
BP 371
EP 396
DI 10.1556/2062.2019.66.3.4
PG 26
WC Linguistics; Language & Linguistics
SC Linguistics
GA JB0DM
UT WOS:000488221500005
DA 2021-02-24
ER

PT J
AU Du, YH
   Fang, WN
   Qiu, HZ
AF Du, Yihang
   Fang, Weining
   Qiu, Hanzhao
TI DEVELOPMENT AND VALIDATION OF A METHOD TO ENHANCE AUDITORY ATTENTION
   DURING CONTINUOUS SPEECH-SHAPED NOISE ENVIRONMENT
SO JOURNAL OF MECHANICS IN MEDICINE AND BIOLOGY
LA English
DT Article
DE Enhanced auditory target tracking task; speech-shaped noise; selective
   attention
ID BIOLOGICAL IMPACT; HEARING-LOSS; MUSIC; LANGUAGE; PITCH; BRAIN;
   PERCEPTION; DISCRIMINATION; MASKING; PLASTICITY
AB Auditory training (AT) may strengthen auditory skills that help human not only in on-task auditory perception performance but in continuous speech-shaped noise (SSN) environment. AT based on musical material has provided some evidence for an "auditory advantage" in understanding speech-in-noise (SIN), but with a long period training and complex procedure. Experimental research is essential to develop a simplified method named auditory target tracking training (ATT) which refined from musical material is necessary to determine the benefits of training. We developed two kinds of refined AT method: basic auditory target tracking (BAT) training and enhanced auditory target tracking (EAT) training to adult participants (n = 30) separately for 20 units, assessing performance to perceive speech in noise environment after training. The EAT group presented better speech perception performance than the other groups and no significant differences between BAT group and control group. The training effect of EAT is the most significant when uni-gender SSN and SNR = -4 dB. Outcomes suggest that efficacy of trained EAT can improve speech perception performance and selective attention during SSN environment. These findings provide an important link between musical-based training and auditory selective attention in real-world, and extended to special vocational training.
C1 [Du, Yihang; Qiu, Hanzhao] Beijing Jiaotong Univ, Sch Mech Elect & Control Engn, Beijing 100044, Peoples R China.
   [Fang, Weining] Beijing Jiaotong Univ, State Key Lab Rail Traff Control & Safety, Beijing 100044, Peoples R China.
RP Fang, WN (corresponding author), Beijing Jiaotong Univ, State Key Lab Rail Traff Control & Safety, Beijing 100044, Peoples R China.
EM 13116335@bjtu.edu.cn; wnfang@bjtu.edu.cn; 15116370@bjtu.edu.cn
OI Du, Yihang/0000-0003-3944-2511
CR Adcock RA, 2009, SCHIZOPHRENIA BULL, V35, P1132, DOI 10.1093/schbul/sbp068
   Ahissar M, 2007, TRENDS COGN SCI, V11, P458, DOI 10.1016/j.tics.2007.08.015
   Ahissar M, 2006, NAT NEUROSCI, V9, P1558, DOI 10.1038/nn1800
   Amitay S, 2006, NAT NEUROSCI, V9, P1446, DOI 10.1038/nn1787
   ASSMANN PF, 1990, J ACOUST SOC AM, V88, P680, DOI 10.1121/1.399772
   Baumann S, 2008, J COGNITIVE NEUROSCI, V20, P2238, DOI 10.1162/jocn.2008.20157
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   Best V, 2008, P NATL ACAD SCI USA, V105, P13174, DOI 10.1073/pnas.0803718105
   Bidelman GM, 2011, J COGNITIVE NEUROSCI, V23, P425, DOI 10.1162/jocn.2009.21362
   BROKX JPL, 1982, J PHONETICS, V10, P23, DOI 10.1016/S0095-4470(19)30909-X
   Brokx JPL, 1979, IPO ANN PROG REP, V14, P55
   BRONKHORST AW, 1992, J ACOUST SOC AM, V92, P3132, DOI 10.1121/1.404209
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Carey D, 2015, COGNITION, V137, P81, DOI 10.1016/j.cognition.2014.12.005
   CARHART R, 1969, J ACOUST SOC AM, V45, P694, DOI 10.1121/1.1911445
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Chobert J, 2014, CEREB CORTEX, V24, P956, DOI 10.1093/cercor/bhs377
   Cooke M, 2003, J PHONETICS, V31, P579, DOI 10.1016/S0095-4470(03)00013-5
   Culling JF, 2003, J ACOUST SOC AM, V114, P2871, DOI 10.1121/1.1616922
   Dahmen JC, 2007, CURR OPIN NEUROBIOL, V17, P456, DOI 10.1016/j.conb.2007.07.004
   de Boer J, 2008, J NEUROSCI, V28, P4929, DOI 10.1523/JNEUROSCI.0902-08.2008
   Drullman R, 2000, J ACOUST SOC AM, V107, P2224, DOI 10.1121/1.428503
   Ebata M., 2003, Acoustical Science and Technology, V24, P208, DOI 10.1250/ast.24.208
   Ferguson MA, 2015, FRONT PSYCHOL, V6, DOI [10.3389/fpsyg.2015.00556, 10.3389/fpg.2015.00556]
   Filippini R, 2012, FOLIA PHONIATR LOGO, V64, P217, DOI 10.1159/000342139
   Fricke Fergus R., 1997, PSYCHOL MUSIC, V25, P70, DOI [10.1177/0305735697251006, DOI 10.1177/0305735697251006]
   Fritz JB, 2007, CURR OPIN NEUROBIOL, V17, P437, DOI 10.1016/j.conb.2007.07.011
   Fu Qian-Jie, 2004, Cochlear Implants Int, V5 Suppl 1, P84, DOI 10.1179/cim.2004.5.Supplement-1.84
   Fujioka T, 2004, J COGNITIVE NEUROSCI, V16, P1010, DOI 10.1162/0898929041502706
   Fuller CD, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00179
   GALILI E, 1993, INT J NAUT ARCHAEOL, V22, P61, DOI 10.1111/j.1095-9270.1993.tb00392.x
   George EM, 2011, NEUROPSYCHOLOGIA, V49, P1083, DOI 10.1016/j.neuropsychologia.2011.02.001
   Groussard M, 2014, BRAIN COGNITION, V90, P174, DOI 10.1016/j.bandc.2014.06.013
   Hannon EE, 2007, TRENDS COGN SCI, V11, P466, DOI 10.1016/j.tics.2007.08.008
   HARRIS JD, 1948, AM J PSYCHOL, V61, P309, DOI 10.2307/1417151
   Henshaw H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0062836
   Hopkins K, 2011, J ACOUST SOC AM, V130, P334, DOI 10.1121/1.3585848
   Humes LE, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00055
   Ihiefeld A, 2008, J ACOUST SOC AM, V123, P4369, DOI 10.1121/1.2904826
   Irvine DRF, 2005, INT REV NEUROBIOL, V70, P435, DOI 10.1016/S0074-7742(05)70013-1
   Kidd G, 2005, J ACOUST SOC AM, V118, P3804, DOI 10.1121/1.2109187
   Kidd G, 2005, ACTA ACUST UNITED AC, V111, P2427
   Koelsch S, 2005, J COGNITIVE NEUROSCI, V17, P1565, DOI 10.1162/089892905774597290
   Koelsch S, 2009, HUM BRAIN MAPP, V30, P859, DOI 10.1002/hbm.20550
   Koffka K., 1935, PRINCIPLES GESTALT P
   Kraus N, 2010, ANN NY ACAD SCI, V1169, P543
   Kraus N, 2007, CURR DIR PSYCHOL SCI, V16, P105, DOI 10.1111/j.1467-8721.2007.00485.x
   Kraus N, 2015, ANN NY ACAD SCI, V1337, P163, DOI 10.1111/nyas.12631
   Kraus N, 2014, J NEUROSCI, V34, P11913, DOI 10.1523/JNEUROSCI.1881-14.2014
   Kraus N, 2012, J COMMUN DISORD, V45, P403, DOI 10.1016/j.jcomdis.2012.06.005
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Kuhnis J, 2013, NEUROPSYCHOLOGIA, V51, P1608, DOI 10.1016/j.neuropsychologia.2013.04.007
   Larson E, 2014, NEUROIMAGE, V84, P681, DOI 10.1016/j.neuroimage.2013.09.061
   Lim CJ, 2006, ANAT REC PART A, V288A, P435, DOI 10.1002/ar.a.20316
   Magne C, 2006, J COGNITIVE NEUROSCI, V18, P199, DOI 10.1162/089892906775783660
   Meddis R, 1997, J ACOUST SOC AM, V102, P1811, DOI 10.1121/1.420088
   Mehrgou M, 2012, 3745 ISO MARC WALL L
   Micheyl C, 2006, HEARING RES, V219, P36, DOI 10.1016/j.heares.2006.05.004
   MILLER GA, 1950, J ACOUST SOC AM, V22, P167, DOI 10.1121/1.1906584
   MILLER GA, 1947, PSYCHOL BULL, V44, P105, DOI 10.1037/h0055960
   Moreno S, 2005, ANN NY ACAD SCI, V1060, P93, DOI 10.1196/annals.1360.054
   Moreno S, 2009, CEREB CORTEX, V19, P712, DOI 10.1093/cercor/bhn120
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Nutley SB, 2014, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00926
   O'Sullivan JA, 2015, CEREB CORTEX, V25, P1697, DOI 10.1093/cercor/bht355
   Pallesen KJ, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011120
   Parbery-Clark A, 2012, NEUROSCIENCE, V219, P111, DOI 10.1016/j.neuroscience.2012.05.042
   Parbery-Clark A, 2012, FRONT AGING NEUROSCI, V4, DOI 10.3389/fnagi.2012.00030
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Patel A. D., 2007, MUSIC LANGUAGE BRAIN
   Patel AD, 2003, NAT NEUROSCI, V6, P674, DOI 10.1038/nn1082
   Patel AD, 1997, NEUROPSYCHOLOGICAL A
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Peretz I, 2012, LANGUAGE MUSIC COGNI, P254
   Putkinen V, 2014, NEUROBIOL LEARN MEM, V110, P8, DOI 10.1016/j.nlm.2014.01.007
   Schafer RJ, 2011, SCIENCE, V332, P1568, DOI 10.1126/science.1199892
   Scheffers M. T. M., 1983, THESIS
   Schulze K, 2011, HUM BRAIN MAPP, V32, P771, DOI 10.1002/hbm.21060
   SHIFFRIN RM, 1977, PSYCHOL REV, V84, P127, DOI 10.1037/0033-295X.84.2.127
   Shinn-Cunningham Barbara G, 2008, Trends Amplif, V12, P283, DOI 10.1177/1084713808325306
   Slater J, 2015, BEHAV BRAIN RES, V291, P244, DOI 10.1016/j.bbr.2015.05.026
   Smith EE, 1999, SCIENCE, V283, P1657, DOI 10.1126/science.283.5408.1657
   Song JH, 2012, CEREB CORTEX, V22, P1180, DOI 10.1093/cercor/bhr196
   SPIEGEL MF, 1984, J ACOUST SOC AM, V76, P1690, DOI 10.1121/1.391605
   Stecker GC, 2006, J REHABIL RES DEV, V43, P537, DOI 10.1682/JRRD.2005.11.0171
   Steinbeis N, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002226
   Steinbeis N, 2008, CEREB CORTEX, V18, P1169, DOI 10.1093/cercor/bhm149
   Strait DL, 2014, CEREB CORTEX, V24, P2512, DOI 10.1093/cercor/bht103
   Strait DL, 2014, HEARING RES, V308, P109, DOI 10.1016/j.heares.2013.08.004
   Strait DL, 2013, DEV COGN NEUROS-NETH, V6, P51, DOI 10.1016/j.dcn.2013.06.003
   Strait DL, 2012, BRAIN LANG, V123, P191, DOI 10.1016/j.bandl.2012.09.001
   Strait DL, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00113
   Strait DL, 2010, HEARING RES, V261, P22, DOI 10.1016/j.heares.2009.12.021
   Swaminathan J, 2014, J ACOUST SOC AM, V135, P2078, DOI 10.1121/1.4865920
   Tallal P, 2004, NAT REV NEUROSCI, V5, P721, DOI 10.1038/nrn1499
   Tervaniemi M, 2005, EXP BRAIN RES, V161, P1, DOI 10.1007/s00221-004-2044-5
   TREISMAN AM, 1964, AM J PSYCHOL, V77, P206, DOI 10.2307/1420127
   Tremblay Kelly L., 2007, Seminars in Hearing, V28, P120, DOI 10.1055/s-2007-973438
   Vermiglio AJ, 2012, J AM ACAD AUDIOL, V23, P779, DOI 10.3766/jaaa.23.10.4
   Wang J, 2014, SAFETY SCI, V70, P339, DOI 10.1016/j.ssci.2014.07.014
   Wang X, 2015, CONSCIOUS COGN, V36, P169, DOI 10.1016/j.concog.2015.06.014
   Watkins AJ, 2005, J ACOUST SOC AM, V118, P249, DOI 10.1121/1.1923369
   Wilson S, 2013, P RES C AUSTR COUNC, V102, P1
   Winkler I, 2009, TRENDS COGN SCI, V13, P532, DOI 10.1016/j.tics.2009.09.003
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Wright BA, 2009, PHILOS T R SOC B, V364, P301, DOI 10.1098/rstb.2008.0262
   Yeend I, 2017, HEARING RES, V353, P224, DOI 10.1016/j.heares.2017.07.006
   Zendel BR, 2015, J COGNITIVE NEUROSCI, V27, P1044, DOI 10.1162/jocn_a_00758
   Zendel BR, 2009, J COGNITIVE NEUROSCI, V21, P1488, DOI 10.1162/jocn.2009.21140
   Zuk J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0080546
NR 110
TC 0
Z9 0
U1 2
U2 5
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0219-5194
EI 1793-6810
J9 J MECH MED BIOL
JI J. Mech. Med. Biol.
PD SEP
PY 2019
VL 19
IS 6
AR 1950048
DI 10.1142/S0219519419500489
PG 21
WC Biophysics; Engineering, Biomedical
SC Biophysics; Engineering
GA JA7PK
UT WOS:000488037100006
DA 2021-02-24
ER

PT J
AU Guan, JJ
   Liu, C
AF Guan, Jingjing
   Liu, Chang
TI Speech Perception in Noise With Formant Enhancement for Older Listeners
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SENSORINEURAL HEARING IMPAIRMENT; SPECTRAL CONTRAST ENHANCEMENT;
   INFORMATIONAL MASKING; VOWEL; RECOGNITION; INTELLIGIBILITY;
   IDENTIFICATION; AGE; DISCRIMINATION; YOUNG
AB Purpose: Degraded speech intelligibility in background noise is a common complaint of listeners with hearing loss. The purpose of the current study is to explore whether 2nd formant (F2) enhancement improves speech perception in noise for older listeners with hearing impairment (HI) and normal hearing (NH).
   Method: Target words (e.g., color and digit) were selected and presented based on the paradigm of the coordinate response measure corpus. Speech recognition thresholds with original and F2-enhanced speech in 2- and 6-talker babble were examined for older listeners with NH and HI.
   Results: The thresholds for both the NH and HI groups improved for enhanced speech signals primarily in 2-talker babble, but not in 6-talker babble. The F2 enhancement benefits did not correlate significantly with listeners' age and their average hearing thresholds in most listening conditions. However, speech intelligibility index values increased significantly with F2 enhancement in babble for listeners with HI, but not for NH listeners.
   Conclusions: Speech sounds with F2 enhancement may improve listeners' speech perception in 2-talker babble, possibly due to a greater amount of speech information available in temporally modulated noise or a better capacity to separate speech signals from background babble.
C1 [Guan, Jingjing; Liu, Chang] Univ Texas Austin, Dept Commun Sci & Disorders, Austin, TX 78712 USA.
RP Liu, C (corresponding author), Univ Texas Austin, Dept Commun Sci & Disorders, Austin, TX 78712 USA.
EM changliu@utexas.edu
CR Agus TR, 2009, J ACOUST SOC AM, V126, P1926, DOI 10.1121/1.3205403
   ALCANTARA JI, 1994, AUDIOLOGY, V33, P15
   Alexander JM, 2004, J ACOUST SOC AM, V116, P2234, DOI 10.1121/1.1784437
   American National Standards Institute, 1997, S351997 ANSI
   BAER T, 1993, J REHABIL RES DEV, V30, P49
   Bernstein JGW, 2009, J ACOUST SOC AM, V125, P3358, DOI 10.1121/1.3110132
   Boers P. M, 1980, IPO ANN PROG REP, V15, P21
   BUNNELL HT, 1990, J ACOUST SOC AM, V88, P2546, DOI 10.1121/1.399976
   Buus S, 2002, JARO-J ASSOC RES OTO, V3, P120, DOI 10.1007/s101620010084
   Chen J, 2013, J ACOUST SOC AM, V133, P2910, DOI 10.1121/1.4799807
   Chen J, 2012, J ACOUST SOC AM, V131, P2987, DOI 10.1121/1.3689556
   Coughlin M, 1998, J ACOUST SOC AM, V104, P3597, DOI 10.1121/1.423942
   Dubno JR, 2002, J ACOUST SOC AM, V111, P2897, DOI 10.1121/1.1480421
   DUBNO JR, 1984, J ACOUST SOC AM, V76, P87, DOI 10.1121/1.391011
   Eddins D. A, 2007, ASS RES OTOLARYNGOLO, V30
   Fogerty D, 2012, J ACOUST SOC AM, V132, P1667, DOI 10.1121/1.4739463
   Fogerty D, 2009, J ACOUST SOC AM, V126, P847, DOI 10.1121/1.3159302
   Franck BAM, 1999, J ACOUST SOC AM, V106, P1452, DOI 10.1121/1.428055
   Helfer KS, 2005, J ACOUST SOC AM, V117, P842, DOI 10.1121/1.1836832
   Hornsby B. W. Y., 2004, HEARING J, V57, P10
   Humes LE, 2002, J ACOUST SOC AM, V112, P1112, DOI 10.1121/1.1499132
   Jin SH, 2006, J ACOUST SOC AM, V119, P3097, DOI 10.1121/1.2188688
   KLEIN AJ, 1990, J ACOUST SOC AM, V87, P1266, DOI 10.1121/1.398802
   LEEK MR, 1987, J ACOUST SOC AM, V81, P148, DOI 10.1121/1.395024
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Liu C, 2007, J ACOUST SOC AM, V122, P2855, DOI 10.1121/1.2781580
   Lock D., 2009, NEW CHILDRENS ENCY, P8
   Lyzenga J, 2002, J ACOUST SOC AM, V112, P1145, DOI 10.1121/1.1497619
   Marrone N, 2008, J ACOUST SOC AM, V124, P3064, DOI 10.1121/1.2980441
   Micheyl C, 2000, ACTA OTO-LARYNGOL, V120, P242
   Moore B. C. J, 2007, COCHLEAR HEARING LOS, P332
   Moore BCJ, 1999, J ACOUST SOC AM, V105, P400, DOI 10.1121/1.424571
   Moore BCJ, 2008, JARO-J ASSOC RES OTO, V9, P399, DOI 10.1007/s10162-008-0143-x
   Moore T, 1981, AGARD C P 331 AUR CO, V2, P1
   Parikh G, 2005, J ACOUST SOC AM, V118, P3874, DOI 10.1121/1.2118407
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Phatak SA, 2007, J ACOUST SOC AM, V121, P2312, DOI 10.1121/1.2642397
   PLOMP R, 1979, J ACOUST SOC AM, V66, P1333, DOI 10.1121/1.383554
   SIMPSON AM, 1990, ACTA OTO-LARYNGOL, P101
   Simpson SA, 2005, J ACOUST SOC AM, V118, P2775, DOI 10.1121/1.2062650
   STONE MA, 1992, J REHABIL RES DEV, V29, P39, DOI 10.1682/JRRD.1992.04.0039
   SUMMERFIELD Q, 1985, SPEECH COMMUN, V4, P213, DOI 10.1016/0167-6393(85)90048-2
   Van Engen KJ, 2007, J ACOUST SOC AM, V121, P519, DOI 10.1121/1.2400666
   Vermiglio AJ, 2012, J AM ACAD AUDIOL, V23, P779, DOI 10.3766/jaaa.23.10.4
   Woodall A, 2013, AM J AUDIOL, V22, P94, DOI 10.1044/1059-0889(2012/12-0044)
   Yang J, 2003, SPEECH COMMUN, V39, P33, DOI 10.1016/S0167-6393(02)00057-2
NR 46
TC 0
Z9 0
U1 2
U2 5
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD SEP
PY 2019
VL 62
IS 9
BP 3290
EP 3301
DI 10.1044/2019_JSLHR-S-18-0089
PG 12
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA IZ7CR
UT WOS:000487244000012
PM 31479380
DA 2021-02-24
ER

PT J
AU Zhang, GY
   Si, YK
   Dang, JW
AF Zhang, Gaoyan
   Si, Yuke
   Dang, Jianwu
TI Revealing the Dynamic Brain Connectivity from Perception of Speech Sound
   to Semantic Processing by EEG
SO NEUROSCIENCE
LA English
DT Article
DE speech perception and processing; electroencephalograph (EEG); source
   reconstruction; dynamic brain connectivity
ID FUNCTIONAL CONNECTIVITY; CORTICAL ORGANIZATION; WORDS
AB Understanding brain processing mechanisms from the perception of speech sounds to high-level semantic processing is vital for effective human-robot communication. In this study, 128-channel electroencephalograph (EEG) signals were recorded when subjects were listening to real and pseudowords in Mandarin. By using an EEG source reconstruction method and a sliding-window Granger causality analysis, we analyzed the dynamic brain connectivity patterns. Results showed that the bilateral temporal cortex (ITC and rTC), the bilateral motor cortex (IMC and rMC), the frontal cortex (FC), and the occipital cortex (OC) were recruited in the process, with complex patterns in the real word condition than in the pseudoword condition. The spatial pattern is basically consistent with previous functional MRI studies on the understanding of spoken Chinese. For the real word condition, speech perception and processing involved different connection patterns in the initial phoneme perception and processing phase, the phonological processing and lexical selection phase, and the semantic integration phase. Specifically, compared with pseudowords, a hub region in the FC and unique patterns of IMC -> rMC and ITC -> FC connectivity were found during processing real words after 180 ms, while a distributed network of temporal, motor, and frontal brain areas was involved after 300 ms. This may be related to semantic processing and integration, The involvement of both bottom-up input and top-down modulation in real word processing may support the previously proposed TRACE model. In sum, the findings of this study suggest that representations of speech involve dynamic interactions among distributed brain regions that communicate through time-specific functional networks. (C) 2019 IBRO. Published by Elsevier Ltd. All rights reserved.
C1 [Zhang, Gaoyan; Si, Yuke; Dang, Jianwu] Tianjin Univ, Tianjin Key Lab Cognit Comp & Applicat, Coll Intelligence & Comp, 135 Yaguan Rd,Haihe Educ Pk, Tianjin 300350, Peoples R China.
   [Dang, Jianwu] Japan Adv Inst Sci & Technol, Sch Informat Sci, Nomi, Ishikawa, Japan.
RP Zhang, GY; Dang, JW (corresponding author), Tianjin Univ, Tianjin Key Lab Cognit Comp & Applicat, Coll Intelligence & Comp, 135 Yaguan Rd,Haihe Educ Pk, Tianjin 300350, Peoples R China.
EM zhanggaoyan@tju.edu.cn; dangjian-wu@tju.edu.cn
FU National Key Research and Development Program of China [2018YFB1305200];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61876126, 61503278]; Peiyang Scholar Program
   of Tianjin University [2018XRG-0037]
FX The research is supported by the National Key Research and Development
   Program of China (No. 2018YFB1305200), National Natural Science
   Foundation of China (No. 61876126, No. 61503278), and Peiyang Scholar
   Program of Tianjin University (2018XRG-0037). Besides, we express
   sincere gratitude to Makoto Miyakoshi in University of California, San
   Diego for providing support in this study.
CR Alavash M, 2019, P NATL ACAD SCI USA, V116, P660, DOI 10.1073/pnas.1815321116
   Baart M, 2015, NEUROSCI LETT, V585, P98, DOI 10.1016/j.neulet.2014.11.044
   Cheung C, 2016, ELIFE, V5, DOI 10.7554/eLife.12577
   Delorme A, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/130714
   Desroches AS, 2010, BRAIN RES, V1356, P73, DOI 10.1016/j.brainres.2010.07.097
   Dittinger E, 2018, HUM BRAIN MAPP, V39, P722, DOI 10.1002/hbm.23877
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2012, J COMMUN DISORD, V45, P393, DOI 10.1016/j.jcomdis.2012.06.004
   Hickok Gregory, 2015, NEUROBIOLOGY LANGUAG
   Jiang LS., 2012, MOD CHIN DICT
   Kocagoncu E, 2017, J NEUROSCI, V37, P1312, DOI 10.1523/JNEUROSCI.2858-16.2016
   Li XS, 2006, J COGNITIVE NEUROSCI, V18, P1774, DOI 10.1162/jocn.2006.18.10.1774
   MacGregor LJ, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms1715
   MARSLENWILSON W, 1980, COGNITION, V8, P1, DOI 10.1016/0010-0277(80)90015-3
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   Meade G, 2019, NEUROPSYCHOLOGIA, V129, P385, DOI 10.1016/j.neuropsychologia.2019.02.014
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Obleser J, 2006, CEREB CORTEX, V16, P1069, DOI 10.1093/cercor/bhj047
   Roy AC, 2008, J PHYSIOLOGY-PARIS, V102, P101, DOI 10.1016/j.jphysparis.2008.03.006
   Sun X, 2019, NEUROPSYCHOLOGIA, V129, P263, DOI 10.1016/j.neuropsychologia.2019.03.020
   TYLER LK, 1984, PERCEPT PSYCHOPHYS, V36, P417, DOI 10.3758/BF03207496
   Wang H., 1986, MODERN CHINESE FREQU
   World Med Assoc, 2013, JAMA-J AM MED ASSOC, V310, P2191, DOI 10.1001/jama.2013.281053
   Xiao ZW, 2005, HUM BRAIN MAPP, V25, P212, DOI 10.1002/hbm.20105
   Xu B, 2001, CEREB CORTEX, V11, P267, DOI 10.1093/cercor/11.3.267
   Yue Q, 2013, NEUROSCIENCE, V237, P87, DOI 10.1016/j.neuroscience.2012.12.067
   Zhao B, 2017, NEUROSCIENCE, V359, P183, DOI 10.1016/j.neuroscience.2017.07.019
NR 27
TC 0
Z9 0
U1 2
U2 20
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0306-4522
EI 1873-7544
J9 NEUROSCIENCE
JI Neuroscience
PD SEP 1
PY 2019
VL 415
BP 70
EP 76
DI 10.1016/j.neuroscience.2019.07.023
PG 7
WC Neurosciences
SC Neurosciences & Neurology
GA IZ6TQ
UT WOS:000487217100007
PM 31330232
DA 2021-02-24
ER

PT J
AU Ma, O
   Tian, X
AF Ma, Ou
   Tian, Xing
TI Distinct Mechanisms of Imagery Differentially Influence Speech
   Perception
SO ENEURO
LA English
DT Article
DE efference copy/corollary discharge; internal forward model; memory
   retrieval; mental imagery; prediction; sensorimotor integration
ID SPREADING ACTIVATION THEORY; MENTAL-IMAGERY; DYNAMICS; BRAIN
AB Neural representation can be induced without external stimulation, such as in mental imagery. Our previous study found that imagined speaking and imagined hearing modulated perceptual neural responses in opposite directions, suggesting motor-to-sensory transformation and memory retrieval as two separate routes that induce auditory representation (Tian and Poeppel, 2013). We hypothesized that the precision of representation induced from different types of speech imagery led to different modulation effects. Specifically, we predicted that the one-to-one mapping between motor and sensory domains established during speech production would evoke a more precise auditory representation in imagined speaking than retrieving the same sounds from memory in imagined hearing. To test this hypothesis, we built the function of representational precision as the modulation of connection strength in a neural network model. The model fitted the magnetoencephalography (MEG) imagery repetition effects, and the best-fitting parameters showed sharper tuning after imagined speaking than imagined hearing, consistent with the representational precision hypothesis. Moreover, this model predicted that different types of speech imagery would affect perception differently. In an imagery-adaptation experiment, the categorization of /ba/-/da/ continuum from male and female human participants showed more positive shifts towards the preceding imagined syllable after imagined speaking than imagined hearing. These consistent simulation and behavioral results support our hypothesis that distinct mechanisms of speech imagery construct auditory representation with varying degrees of precision and differentially influence auditory perception. This study provides a mechanistic connection between neural-level activity and psychophysics that reveals the neural computation of mental imagery.
C1 [Ma, Ou; Tian, Xing] East China Normal Univ, Minist Educ, Sch Psychol & Cognit Sci, Shanghai Key Lab Brain Funct Genom, Shanghai 200062, Peoples R China.
   [Ma, Ou; Tian, Xing] New York Univ Shanghai, NYU ECNU Inst Brain & Cognit Sci, Shanghai 200062, Peoples R China.
   [Tian, Xing] New York Univ Shanghai, Div Arts & Sci, Shanghai 200122, Peoples R China.
RP Tian, X (corresponding author), East China Normal Univ, Minist Educ, Sch Psychol & Cognit Sci, Shanghai Key Lab Brain Funct Genom, Shanghai 200062, Peoples R China.; Tian, X (corresponding author), New York Univ Shanghai, NYU ECNU Inst Brain & Cognit Sci, Shanghai 200062, Peoples R China.; Tian, X (corresponding author), New York Univ Shanghai, Div Arts & Sci, Shanghai 200122, Peoples R China.
EM xing.tian@nyu.edu
OI Tian, Xing/0000-0003-1629-6304
FU National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) [31871131]; Major Program of Science
   and Technology Commission of Shanghai Municipality (STCSM)
   [17JC1404104]; Program of Introducing Talents of Discipline to
   Universities Base [B16018]
FX This work was supported by the National Natural Science Foundation of
   China (NSFC) 31871131, the Major Program of Science and Technology
   Commission of Shanghai Municipality (STCSM) 17JC1404104, and the Program
   of Introducing Talents of Discipline to Universities Base B16018.
CR Aitchison L, 2017, CURR OPIN NEUROBIOL, V46, P219, DOI 10.1016/j.conb.2017.08.010
   ANDERSON JR, 1983, J VERB LEARN VERB BE, V22, P261, DOI 10.1016/S0022-5371(83)90201-3
   Bar M, 2007, TRENDS COGN SCI, V11, P280, DOI 10.1016/j.tics.2007.05.005
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   COLLINS AM, 1975, PSYCHOL REV, V82, P407, DOI 10.1037/0033-295X.82.6.407
   Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787
   Friston KJ, 2009, PHILOS T R SOC B, V364, P1211, DOI 10.1098/rstb.2008.0300
   Hochstein S, 2002, NEURON, V36, P791, DOI 10.1016/S0896-6273(02)01091-7
   Hubbard TL, 2010, PSYCHOL BULL, V136, P302, DOI 10.1037/a0018436
   Huber DE, 2003, COGNITIVE SCI, V27, P403, DOI 10.1016/S0364-0213(03)00012-0
   Keller GB, 2018, NEURON, V100, P424, DOI 10.1016/j.neuron.2018.10.003
   Kosslyn SM, 1999, SCIENCE, V284, P167, DOI 10.1126/science.284.5411.167
   Kosslyn SM, 2001, NAT REV NEUROSCI, V2, P635, DOI 10.1038/35090055
   Morillon B, 2015, CURR OPIN NEUROBIOL, V31, P230, DOI 10.1016/j.conb.2014.12.005
   Moulton ST, 2009, PHILOS T R SOC B, V364, P1273, DOI 10.1098/rstb.2008.0314
   O'Craven KM, 2000, J COGNITIVE NEUROSCI, V12, P1013, DOI 10.1162/08989290051137549
   O'Reilly R. C., 2000, COMPUTATIONAL EXPLOR
   Okada K, 2018, PSYCHON B REV, V25, P423, DOI 10.3758/s13423-017-1284-x
   Oppenheim GM, 2008, COGNITION, V106, P528, DOI 10.1016/j.cognition.2007.02.006
   Oppenheim GM, 2010, MEM COGNITION, V38, P1147, DOI 10.3758/MC.38.8.1147
   Pearson J, 2015, P NATL ACAD SCI USA, V112, P10089, DOI 10.1073/pnas.1504933112
   Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580
   Rimmele JM, 2018, TRENDS COGN SCI, V22, P870, DOI 10.1016/j.tics.2018.08.003
   Schroeder CE, 2010, CURR OPIN NEUROBIOL, V20, P172, DOI 10.1016/j.conb.2010.02.010
   Szpunar KK, 2014, P NATL ACAD SCI USA, V111, P18414, DOI 10.1073/pnas.1417144111
   Tan X, 2012, FRONT HUM NEUROSCI, V6, DOI [10.3389/fnhum.2012.00305, 10.3389/fnhum.2012.00314]
   Tian X, 2018, NAT HUM BEHAV, V2, P225, DOI 10.1038/s41562-018-0305-8
   Tian X, 2016, CORTEX, V77, P1, DOI 10.1016/j.cortex.2016.01.002
   Tian X, 2015, J COGNITIVE NEUROSCI, V27, P352, DOI 10.1162/jocn_a_00692
   Tian X, 2013, J COGNITIVE NEUROSCI, V25, P1020, DOI 10.1162/jocn_a_00381
   Tian X, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00166
   Zatorre RJ, 2005, NEURON, V47, P9, DOI 10.1016/j.neuron.2005.06.013
NR 32
TC 5
Z9 5
U1 1
U2 2
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
EI 2373-2822
J9 ENEURO
JI eNeuro
PD SEP-OCT
PY 2019
VL 6
IS 5
AR UNSP ENEURO.0261-19.2019
DI 10.1523/ENEURO.0261-19.2019
PG 11
WC Neurosciences
SC Neurosciences & Neurology
GA IY7WC
UT WOS:000486604800005
PM 31481396
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Jeddi, Z
   Lotfi, Y
   Moossavi, A
   Bakhshi, E
   Hashemi, SB
AF Jeddi, Zahra
   Lotfi, Younes
   Moossavi, Abdollah
   Bakhshi, Enayatollah
   Hashemi, Seyed Basir
TI Correlation between Auditory Spectral Resolution and Speech Perception
   in Children with Cochlear Implants
SO IRANIAN JOURNAL OF MEDICAL SCIENCES
LA English
DT Article
DE Child; Cochlear implants; Auditory threshold; Speech perception
ID FREQUENCY DISCRIMINATION; RIPPLE DISCRIMINATION; RECOGNITION; NOISE;
   PERFORMANCE; USERS; IDENTIFICATION; CUES
AB Background: Variability in speech performance is a major concern for children with cochlear implants (CIs). Spectral resolution is an important acoustic component in speech perception. Considerable variability and limitations of spectral resolution in children with CIs may lead to individual differences in speech performance. The aim of this study was to assess the correlation between auditory spectral resolution and speech perception in pediatric CI users.
   Methods: This cross-sectional study was conducted in Shiraz, Iran, in 2017. The frequency discrimination threshold (FDT) and the spectral-temporal modulated ripple discrimination threshold (SMRT) were measured for 75 pre-lingual hearing-impaired children with CIs (age=8-12 y). Word recognition and sentence perception tests were completed to assess speech perception. The Pearson correlation analysis and multiple linear regression analysis were used to determine the correlation between the variables and to determine the predictive variables of speech perception, respectively.
   Results: There was a significant correlation between the SMRT and word recognition (r=0.573 and P<0.001). The FDT was significantly correlated with word recognition (r=0.487 and P<0.001). Sentence perception had a significant correlation with the SMRT and the FDT. There was a significant correlation between chronological age and age at implantation with SMRT but not the FDT.
   Conclusion: Auditory spectral resolution correlated well with speech perception among our children with CIs. Spectral resolution ability accounted for approximately 40% of the variance in speech perception among the children with CIs.
C1 [Jeddi, Zahra; Lotfi, Younes] Univ Social Welf & Rehabil Sci, Dept Audiol, Kodakyar Ave,Daneshjo Blvd, Tehran 1985713834, Iran.
   [Moossavi, Abdollah] Iran Univ Med Sci, Sch Med, Dept Otolaryngol & Head & Neck Surg, Tehran, Iran.
   [Bakhshi, Enayatollah] Univ Social Welf & Rehabil Sci, Dept Biostat, Tehran, Iran.
   [Hashemi, Seyed Basir] Shiraz Univ Med Sci, Khalili Hosp, Dept Otolaryngol, Shiraz, Iran.
RP Lotfi, Y (corresponding author), Univ Social Welf & Rehabil Sci, Dept Audiol, Kodakyar Ave,Daneshjo Blvd, Tehran 1985713834, Iran.
EM yones1333@gmail.com
RI Bakhshi, Enayatollah/D-8589-2017; Jeddi, Zahra/A-2188-2010
OI Jeddi, Zahra/0000-0002-8939-0361
CR Anderson ES, 2012, J ACOUST SOC AM, V132, P3925, DOI 10.1121/1.4763999
   Anderson ES, 2011, J ACOUST SOC AM, V130, P364, DOI 10.1121/1.3589255
   Aronoff JM, 2013, J ACOUST SOC AM, V134, pEL217, DOI 10.1121/1.4813802
   Conway CM, 2014, J SPEECH LANG HEAR R, V57, P2174, DOI 10.1044/2014_JSLHR-L-13-0236
   Davies-Venn E, 2015, J ACOUST SOC AM, V138, P492, DOI 10.1121/1.4922700
   Doman MF, 1996, J ACOUST SOC AM, V99, P1174, DOI 10.1121/1.414600
   Eisenberg LS, 2000, J ACOUST SOC AM, V107, P2704, DOI 10.1121/1.428656
   Faulkner KF, 2012, UNDERSTANDING FREQUE
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P180, DOI 10.1007/s10162-005-5061-6
   Goldsworthy RL, 2013, TRENDS AMPLIF, V17, P27, DOI 10.1177/1084713813477244
   Goldsworthy RL, 2015, JARO-J ASSOC RES OTO, V16, P797, DOI 10.1007/s10162-015-0541-9
   Halliday LF, 2005, J SPEECH LANG HEAR R, V48, P1187, DOI 10.1044/1092-4388(2005/083)
   Henry BA, 2003, J ACOUST SOC AM, V113, P2861, DOI 10.1121/1.1561900
   Jung KH, 2012, AUDIOL NEURO-OTOL, V17, P189, DOI 10.1159/000336407
   Kopelovich JC, 2010, HEARING RES, V268, P105, DOI 10.1016/j.heares.2010.05.006
   KRAUS N, 1995, EAR HEARING, V16, P19, DOI 10.1097/00003446-199502000-00003
   Landsberger DM, 2018, EAR HEARING, V39, P60, DOI 10.1097/AUD.0000000000000463
   Litvak LM, 2007, J ACOUST SOC AM, V122, P982, DOI 10.1121/1.2749413
   Lotfi Y, 2016, AUD VEST RES, V25, P194
   Moore DR, 2008, HEARING RES, V238, P147, DOI 10.1016/j.heares.2007.11.013
   Moossavi A., 2017, AUD VEST RES, V26, P27
   Peter V, 2014, J AM ACAD AUDIOL, V25, P210, DOI 10.3766/jaaa.25.2.9
   Sagi E, 2009, J SPEECH LANG HEAR R, V52, P385, DOI [10.1044/1092-4388(2008/07-0219), 10.1044/1092-4388(2008/07-0219]
   Santarelli R, 2009, OTOL NEUROTOL, V30, P304, DOI 10.1097/MAO.0b013e3181967a19
   Scheperle RA, 2015, EAR HEARING, V36, P441, DOI 10.1097/AUD.0000000000000144
   SUPIN AY, 1994, HEARING RES, V78, P31, DOI 10.1016/0378-5955(94)90041-8
   Turgeon Christine, 2015, Cochlear Implants Int, V16, P88, DOI 10.1179/1754762814Y.0000000091
   Wei CG, 2007, EAR HEARING, V28, p62S, DOI 10.1097/AUD.0b013e318031512c
   Won JH, 2007, JARO-J ASSOC RES OTO, V8, P384, DOI 10.1007/s10162-007-0085-8
NR 29
TC 0
Z9 0
U1 0
U2 1
PU SHIRAZ UNIV MEDICAL SCIENCES
PI SHIRAZ
PA ZAND ST, SHIRAZ, FARS 00000, IRAN
SN 0253-0716
EI 1735-3688
J9 IRAN J MED SCI
JI Iran. J. Med. Sci.
PD SEP
PY 2019
VL 44
IS 5
BP 382
EP 389
DI 10.30476/IJMS.2019.44967
PG 8
WC Medicine, General & Internal
SC General & Internal Medicine
GA IY7UW
UT WOS:000486601600003
PM 31582862
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Kaplan, E
   Jesse, A
AF Kaplan, Elina
   Jesse, Alexandra
TI Fixating the eyes of a speaker provides sufficient visual information to
   modulate early auditory processing
SO BIOLOGICAL PSYCHOLOGY
LA English
DT Article
DE Audiovisual speech perception; Attention; Event-related potentials;
   Multisensory processing
ID AUDIOVISUAL SPEECH-PERCEPTION; ELECTROPHYSIOLOGICAL EVIDENCE; GAZE
   BEHAVIOR; LIP-READ; RECOGNITION; ATTENTION; SELECTION; FACE;
   REQUIREMENTS; PERFORMANCE
AB In face-to-face conversations, when listeners process and combine information obtained from hearing and seeing a speaker, they mostly look at the eyes rather than at the more informative mouth region. Measuring event-related potentials, we tested whether fixating the speaker's eyes is sufficient for gathering enough visual speech information to modulate early auditory processing, or whether covert attention to the speaker's mouth is needed. Results showed that when listeners fixated the eye region of the speaker, the amplitudes of the auditory evoked N1 and P2 were reduced when listeners heard and saw the speaker than when they only heard her. These cross-modal interactions also occurred when, in addition, attention was restricted to the speaker's eye region. Fixating the speaker's eyes thus provides listeners with sufficient visual information to facilitate early auditory processing. The spread of covert attention to the mouth area is not needed to observe audiovisual interactions.
C1 [Kaplan, Elina; Jesse, Alexandra] Univ Massachusetts, Dept Psychol & Brain Sci, Amherst, MA 01003 USA.
RP Jesse, A (corresponding author), Univ Massachusetts, Dept Psychol & Brain Sci, Amherst, MA 01003 USA.
EM ajesse@psych.umass.edu
FU National Institute on Aging of the National Institutes of HealthUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Aging (NIA) [R03AG059105];
   NATIONAL INSTITUTE ON AGINGUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Aging (NIA) [R03AG059105, R03AG059105] Funding Source: NIH RePORTER
FX The authors thank Virginie van Wassenhove for providing the speech
   materials and Kyle Cave, John Kingston, Jonas Obleser, and Lisa Sanders
   for their comments. Research reported in this publication was supported
   by the National Institute on Aging of the National Institutes of Health
   under Award Number R03AG059105. The content is solely the responsibility
   of the authors and does not necessarily represent the official views of
   the National Institutes of Health.
CR Adolphs R, 2005, NATURE, V433, P68, DOI 10.1038/nature03086
   Arnold P, 2001, BRIT J PSYCHOL, V92, P339, DOI 10.1348/000712601162220
   Baart M, 2017, EUR J NEUROSCI, V46, P2578, DOI 10.1111/ejn.13734
   Baart M, 2016, PSYCHOPHYSIOLOGY, V53, P1295, DOI 10.1111/psyp.12683
   Baart M, 2015, J MEM LANG, V85, P42, DOI 10.1016/j.jml.2015.06.008
   Baart M, 2014, NEUROPSYCHOLOGIA, V53, P115, DOI 10.1016/j.neuropsychologia.2013.11.011
   Besle J, 2004, EUR J NEUROSCI, V20, P2225, DOI 10.1111/j.1460-9568.2004.03670.x
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   CASTIELLO U, 1990, ACTA PSYCHOL, V73, P195, DOI 10.1016/0001-6918(90)90022-8
   Cohen MA, 2012, TRENDS COGN SCI, V16, P411, DOI 10.1016/j.tics.2012.06.013
   Cohen MA, 2011, PSYCHOL SCI, V22, P1165, DOI 10.1177/0956797611419168
   DARK VJ, 1985, J EXP PSYCHOL GEN, V114, P472, DOI 10.1037/0096-3445.114.4.472
   Davis C, 2006, COGNITION, V100, pB21, DOI 10.1016/j.cognition.2005.09.002
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Eaton JW, 2014, GNU OCTAVE VERSION 3
   ERIKSEN CW, 1985, J EXP PSYCHOL HUMAN, V11, P583, DOI 10.1037/0096-1523.11.5.583
   ERIKSEN CW, 1986, PERCEPT PSYCHOPHYS, V40, P225, DOI 10.3758/BF03211502
   Everdell IT, 2007, PERCEPTION, V36, P1535, DOI 10.1068/p5852
   Gauthier I, 2003, COGN NEUROPSYCHOL, V20, P507, DOI 10.1080/02643290244000275
   Grant KW, 1996, J ACOUST SOC AM, V100, P2415, DOI 10.1121/1.417950
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Hunt AR, 2003, COGNITIVE BRAIN RES, V18, P102, DOI 10.1016/j.cogbrainres.2003.08.006
   Hunt AR, 2003, J EXP PSYCHOL HUMAN, V29, P1068, DOI 10.1037/0096-1523.29.5.1068
   IJSSELDIJK FJ, 1992, J SPEECH HEAR RES, V35, P466, DOI 10.1044/jshr.3502.466
   Jesse A., 2000, INTERPRETING, V5, P95, DOI [DOI 10.1075/INTP.5.2.04JES, 10.1075/intp.5.2.04jes]
   Jesse A, 2012, LANG COGNITIVE PROC, V27, P1167, DOI 10.1080/01690965.2011.620335
   Jesse A, 2010, ATTEN PERCEPT PSYCHO, V72, P209, DOI 10.3758/APP.72.1.209
   Jiang J, 2017, SOC COGN AFFECT NEUR, V12, P319, DOI 10.1093/scan/nsw127
   Jordan TR, 2011, ATTEN PERCEPT PSYCHO, V73, P2270, DOI 10.3758/s13414-011-0152-4
   Kampe KKW, 2003, J NEUROSCI, V23, P5258
   Klucharev V, 2003, COGNITIVE BRAIN RES, V18, P65, DOI 10.1016/j.cogbrainres.2003.09.004
   Lansing IR, 2003, PERCEPT PSYCHOPHYS, V65, P536, DOI 10.3758/BF03194581
   LAVIE N, 1994, PERCEPT PSYCHOPHYS, V56, P183, DOI 10.3758/BF03213897
   LAVIE N, 1995, J EXP PSYCHOL HUMAN, V21, P451, DOI 10.1037/0096-1523.21.3.451
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   MACLEOD A, 1987, British Journal of Audiology, V21, P131, DOI 10.3109/03005368709077786
   MARASSA LK, 1995, J SPEECH HEAR RES, V38, P1387, DOI 10.1044/jshr.3806.1387
   Massaro D. W., 2008, OXFORD HDB PSYCHOLIN, P19
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Pare M, 2003, PERCEPT PSYCHOPHYS, V65, P553, DOI 10.3758/BF03194582
   Paris T, 2016, CORTEX, V75, P220, DOI 10.1016/j.cortex.2015.03.010
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   POSNER MI, 1982, PHILOS T ROY SOC B, V298, P187, DOI 10.1098/rstb.1982.0081
   Preminger JE, 1998, J SPEECH LANG HEAR R, V41, P564, DOI 10.1044/jslhr.4103.564
   Reisberg D, 1987, HEARING EYE PSYCHOL, P97
   Senju A, 2009, TRENDS COGN SCI, V13, P127, DOI 10.1016/j.tics.2008.11.009
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Thomas SM, 2004, J EXP PSYCHOL HUMAN, V30, P873, DOI 10.1037/0096-1523.30.5.873
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Vatikiotis-Bateson E, 1998, PERCEPT PSYCHOPHYS, V60, P926, DOI 10.3758/BF03211929
   WALDEN BE, 1974, J SPEECH HEAR RES, V17, P270, DOI 10.1044/jshr.1702.270
   Wilson AH, 2016, J SPEECH LANG HEAR R, V59, P601, DOI 10.1044/2016_JSLHR-S-15-0092
   YANTIS S, 1990, J EXP PSYCHOL HUMAN, V16, P135, DOI 10.1037/0096-1523.16.1.135
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
NR 55
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0301-0511
EI 1873-6246
J9 BIOL PSYCHOL
JI Biol. Psychol.
PD SEP
PY 2019
VL 146
AR 107724
DI 10.1016/j.biopsycho.2019.107724
PG 9
WC Psychology, Biological; Behavioral Sciences; Psychology; Psychology,
   Experimental
SC Psychology; Behavioral Sciences
GA IX6HU
UT WOS:000485784700016
PM 31323242
OA Green Accepted
DA 2021-02-24
ER

PT J
AU May, L
   Baron, AS
   Werker, JF
AF May, Lillian
   Baron, Andrew S.
   Werker, Janet F.
TI Who can speak that language? Eleven-month-old infants have
   language-dependent expectations regarding speaker ethnicity
SO DEVELOPMENTAL PSYCHOBIOLOGY
LA English
DT Article
DE ethnicity; eye-tracking; infancy; language
ID OTHER-RACE FACES; OWN-RACE; SPEECH-PERCEPTION; NATIVE-LANGUAGE;
   DISCRIMINATION; NEWBORNS; RECOGNITION; ATTENTION; REVEALS
AB Research demonstrates that young infants attend to the indexical characteristics of speakers, including age, gender, and ethnicity, and that the relationship between language and ethnicity is intuitive among older children. However, little research has examined whether infants, within the first year, are sensitive to the co-occurrences of ethnicity and language. In this paper, we demonstrate that by 11 months of age, infants hold language-dependent expectations regarding speaker ethnicity. Specifically, 11-month-old English-learning Caucasian infants looked more to Asian versus Caucasian faces when hearing Cantonese versus English (Studies 1 and 3), but did not look more to Asian versus Caucasian faces when paired with Spanish (Study 2), making it unlikely that they held a general expectation that unfamiliar languages pair with unfamiliar faces. Moreover, infants who had regular exposure to one or more significant non-Caucasian individuals showed this pattern more strongly (Study 3). Given that infants tested were raised in a multilingual metropolitan area-which includes a Caucasian population speaking many languages, but seldom Cantonese, as well as a sizeable Asian population speaking both Cantonese and English-these results are most parsimoniously explained by infants having learned specific language-ethnicity associations based on those individuals they encountered in their environment.
C1 [May, Lillian; Baron, Andrew S.; Werker, Janet F.] Univ British Columbia, Dept Psychol, Vancouver, BC, Canada.
RP Werker, JF (corresponding author), Univ British Columbia, Dept Psychol, Vancouver, BC, Canada.
EM jwerker@psych.ubc.ca
OI Werker, Janet F./0000-0002-1168-9013
FU University of British Columbia; Social Sciences and Humanities Research
   Council of CanadaSocial Sciences and Humanities Research Council of
   Canada (SSHRC) [435-2014-0917]
FX University of British Columbia; Social Sciences and Humanities Research
   Council of Canada, Grant/Award Number: 435-2014-0917
CR Bahrick LE, 2005, DEV PSYCHOL, V41, P541, DOI 10.1037/0012-1649.41.3.541
   Bahrick LE, 1998, CHILD DEV, V69, P1263, DOI 10.2307/1132264
   Bar-Haim Y, 2006, PSYCHOL SCI, V17, P159, DOI 10.1111/j.1467-9280.2006.01679.x
   Bosch L, 1997, COGNITION, V65, P33, DOI 10.1016/S0010-0277(97)00040-1
   Byers-Heinlein K, 2010, PSYCHOL SCI, V21, P343, DOI 10.1177/0956797609360758
   Danielson DK, 2017, COGNITIVE DEV, V42, P37, DOI 10.1016/j.cogdev.2017.02.004
   de Boisferon AH, 2015, INFANCY, V20, P661, DOI 10.1111/infa.12088
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   Ellis AE, 2017, DEV PSYCHOBIOL, V59, DOI 10.1002/dev.21527
   Fassbender I, 2016, EUR J DEV PSYCHOL, V13, P152, DOI 10.1080/17405629.2015.1073585
   Hirschfeld LA, 1997, COGNITIVE DEV, V12, P213, DOI 10.1016/S0885-2014(97)90014-9
   Hu S., IT DEPENDS WHOS TALK
   Johnson EK, 2011, DEVELOPMENTAL SCI, V14, P1002, DOI 10.1111/j.1467-7687.2011.01052.x
   Kelly DJ, 2005, DEVELOPMENTAL SCI, V8, pF31, DOI 10.1111/j.1467-7687.2005.0434a.x
   Kinzler KD, 2007, P NATL ACAD SCI USA, V104, P12577, DOI 10.1073/pnas.0705345104
   Kinzler KD, 2012, J COGN DEV, V13, P67, DOI 10.1080/15248372.2011.567200
   Kubicek C, 2013, INT J BEHAV DEV, V37, P106, DOI 10.1177/0165025412473016
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Liu SY, 2015, DEV PSYCHOL, V51, P500, DOI 10.1037/a0038835
   May L, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12564
   May L, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00222
   MEHLER J, 1988, COGNITION, V29, P143, DOI 10.1016/0010-0277(88)90035-2
   Minagawa-Kawai Y, 2011, CEREB CORTEX, V21, P254, DOI 10.1093/cercor/bhq082
   Molnar M, 2014, INFANCY, V19, P326, DOI 10.1111/infa.12041
   Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037/0096-1523.24.3.756
   Nazzi T, 2000, J MEM LANG, V43, P1, DOI 10.1006/jmla.2000.2698
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Pena M, 2003, P NATL ACAD SCI USA, V100, P11702, DOI 10.1073/pnas.1934290100
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   POULINDUBOIS D, 1994, DEV PSYCHOL, V30, P436, DOI 10.1037/0012-1649.30.3.436
   Ramus F, 2000, SCIENCE, V288, P349, DOI 10.1126/science.288.5464.349
   Richoz AR, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169325
   Sato H, 2012, HUM BRAIN MAPP, V33, P2092, DOI 10.1002/hbm.21350
   Sebastian-Galles N, 2012, PSYCHOL SCI, V23, P994, DOI 10.1177/0956797612436817
   Singarajah A, 2017, COGNITION, V159, P76, DOI 10.1016/j.cognition.2016.11.006
   Smith L, 2008, COGNITION, V106, P1558, DOI 10.1016/j.cognition.2007.06.010
   Statistics Canada, 2016, VANC CENS METR BRIT
   Uttley L, 2013, INT J BEHAV DEV, V37, P84, DOI 10.1177/0165025412467583
   Vannasing P, 2016, NEUROPSYCHOLOGIA, V84, P63, DOI 10.1016/j.neuropsychologia.2016.01.038
   Vouloumanos A, 2007, DEVELOPMENTAL SCI, V10, P159, DOI 10.1111/j.1467-7687.2007.00549.x
   Vouloumanos A, 2009, P NATL ACAD SCI USA, V106, P18867, DOI 10.1073/pnas.0906049106
   WALKER-ANDREWS A S, 1991, Ecological Psychology, V3, P55, DOI 10.1207/s15326969eco0302_1
   Weatherhead D, 2018, COGNITION, V177, P87, DOI 10.1016/j.cognition.2018.04.004
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   Wheeler A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018621
   Xiao NQG, 2015, DEV PSYCHOL, V51, P744, DOI 10.1037/dev0000019
   Xiao WS, 2013, INT J BEHAV DEV, V37, P100, DOI 10.1177/0165025412467584
NR 48
TC 1
Z9 1
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0012-1630
EI 1098-2302
J9 DEV PSYCHOBIOL
JI Dev. Psychobiol.
PD SEP
PY 2019
VL 61
IS 6
BP 859
EP 873
DI 10.1002/dev.21851
PG 15
WC Developmental Biology; Psychology
SC Developmental Biology; Psychology
GA IW5UY
UT WOS:000485044700005
PM 31012093
DA 2021-02-24
ER

PT J
AU Zendel, BR
   West, GL
   Belleville, S
   Peretz, I
AF Zendel, Benjamin Rich
   West, Greg L.
   Belleville, Sylvie
   Peretz, Isabelle
TI Musical training improves the ability to understand speech-in-noise in
   older adults
SO NEUROBIOLOGY OF AGING
LA English
DT Article
DE Aging; Musical training; ERPs; Speech perception; Speech-in-noise;
   Hearing
ID MONTREAL COGNITIVE ASSESSMENT; HEARING-LOSS; MOTOR THEORY; PERCEPTION;
   POTENTIALS; CORTEX; ENHANCEMENT; P2; REPRESENTATIONS; EPIDEMIOLOGY
AB It is well known that hearing abilities decline with age, and one of the most commonly reported hearing difficulties reported in older adults is a reduced ability to understand speech in noisy environments. Older adult musicians have an enhanced ability to understand speech in noise, and this has been associated with enhanced brain responses related to both speech processing and the deployment of attention; however, the causal impact of music lessons in older adults has not yet been demonstrated. To investigate whether a causal relationship exists between short-term musical training and performance on auditory tests in older adults and to determine if musical training can be used to improve hearing in older adult nonmusicians, we conducted a longitudinal training study with random assignment. A sample of older adults was randomly assigned to learn to play piano (Music), to learn to play a visuo-spatially demanding video game (Video), or to serve as a no-contact control (No-contact). After 6 months, the Music group improved their ability to understand a word presented in loud background noise, whereas the other 2 groups did not. This improvement was related to an increase in positive-going electrical brain activity at fronto-left electrodes 200-1000 ms after the presentation of a word in noise. Source analyses suggest that this activity was due to sources located in the left inferior frontal gyrus and other regions involved in the speech-motor system. These findings support the idea that musical training provides a causal benefit to hearing abilities. Importantly, these findings suggest that musical training could be used as a foundation to develop auditory rehabilitation programs for older adults. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zendel, Benjamin Rich] Mem Univ Newfoundland, 230 Elizabeth Ave, St John, NF A1B 3X9, Canada.
   [Zendel, Benjamin Rich; Peretz, Isabelle] Int Lab Brain Mus & Sound Res, Montreal, PQ, Canada.
   [Zendel, Benjamin Rich; Belleville, Sylvie] CRIUGM, Montreal, PQ, Canada.
   [Zendel, Benjamin Rich] Aging Res Ctr Newfoundland & Labrador, Corner Brook, NF, Canada.
   [West, Greg L.; Belleville, Sylvie; Peretz, Isabelle] Univ Montreal, Dept Psychol, Montreal, PQ, Canada.
RP Zendel, BR (corresponding author), Mem Univ Newfoundland, 230 Elizabeth Ave, St John, NF A1B 3X9, Canada.
EM bzendel@mun.ca
FU Canada Research Chairs programCanada Research Chairs; GRAMMY Foundation;
   Fondation Caroline Durant; Fonds de Recherche du Quebec-SanteFonds de la
   Recherche en Sante du Quebec; Natural Sciences and Engineering Research
   Council of Canada Collaborative Research and Training Experience Program
   in Auditory Cognitive Neuroscience (NSERC-CREATE-ACN)Natural Sciences
   and Engineering Research Council of Canada (NSERC)
FX The authors thank Olivier Dussault, Charles-David Tremblay, Samira
   Mellah, and Mihaela Felezeu for assistance with data collection. Support
   for this research came from the Canada Research Chairs program, the
   GRAMMY Foundation, Fondation Caroline Durant, Fonds de Recherche du
   QuebeceSante, and Natural Sciences and Engineering Research Council of
   Canada Collaborative Research and Training Experience Program in
   Auditory Cognitive Neuroscience (NSERC-CREATE-ACN).
CR Ackermann H, 2007, CEREBELLUM, V6, P202, DOI 10.1080/14734220701266742
   Alain C., 2006, HDB MODELS HUMAN AGI, P759, DOI DOI 10.1016/B978-012369391-4/50065-5
   Alain C, 2014, HEARING RES, V308, P162, DOI 10.1016/j.heares.2013.06.008
   Amenedo E, 1998, BIOL PSYCHOL, V48, P235, DOI 10.1016/S0301-0511(98)00040-4
   Anderer P, 1996, ELECTROEN CLIN NEURO, V99, P458, DOI 10.1016/S0013-4694(96)96518-9
   Anderson S, 2013, P NATL ACAD SCI USA, V110, P4357, DOI 10.1073/pnas.1213555110
   BERG P, 1994, ELECTROEN CLIN NEURO, V90, P229, DOI 10.1016/0013-4694(94)90094-9
   Billings CJ, 2009, HEARING RES, V254, P15, DOI 10.1016/j.heares.2009.04.002
   Bugos JA, 2007, AGING MENT HEALTH, V11, P464, DOI 10.1080/13607860601086504
   Carson N, 2018, INT J GERIATR PSYCH, V33, P379, DOI 10.1002/gps.4756
   Coffey EBJ, 2017, HEARING RES, V352, P49, DOI 10.1016/j.heares.2017.02.006
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   Davis SW, 2008, CEREB CORTEX, V18, P1201, DOI 10.1093/cercor/bhm155
   Diarra M, 2019, EXP BRAIN RES, V237, P723, DOI 10.1007/s00221-018-5453-6
   Du Y, 2017, P NATL ACAD SCI USA, V114, P13579, DOI 10.1073/pnas.1712223114
   Du Y, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12241
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   Fleming D., 2019, BRAIN COGN
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8
   Frisina DR, 1997, HEARING RES, V106, P95, DOI 10.1016/S0378-5955(97)00006-3
   Fujioka T, 2006, BRAIN, V129, P2593, DOI 10.1093/brain/awl247
   Gajewski A., 2011, PIANO LESSON PACKAGE
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Gates GA, 2005, LANCET, V366, P1111, DOI 10.1016/S0140-6736(05)67423-5
   GRADY CL, 1994, J NEUROSCI, V14, P1450
   Hanna-Pladdy B, 2011, NEUROPSYCHOLOGY, V25, P378, DOI 10.1037/a0021895
   HANSEN JC, 1980, ELECTROEN CLIN NEURO, V49, P277, DOI 10.1016/0013-4694(80)90222-9
   Humes LE, 2019, INT J AUDIOL, V58, P12, DOI 10.1080/14992027.2018.1518598
   Hwang JH, 2006, ACTA OTO-LARYNGOL, V126, P916, DOI 10.1080/00016480500546375
   Kaplan-Neeman R, 2006, J ACOUST SOC AM, V120, P926, DOI 10.1121/1.2217567
   KESTENBAUM GI, 1985, J AM ACAD CHILD PSY, V24, P329, DOI 10.1016/S0002-7138(09)61094-3
   Koelsch S, 1999, NEUROREPORT, V10, P1309, DOI 10.1097/00001756-199904260-00029
   Kok A, 2001, PSYCHOPHYSIOLOGY, V38, P557, DOI 10.1017/S0048577201990559
   Kraus N, 2015, TRENDS COGN SCI, V19, P642, DOI 10.1016/j.tics.2015.08.017
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Lappe C, 2008, J NEUROSCI, V28, P9632, DOI 10.1523/JNEUROSCI.2254-08.2008
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Martin BA, 1997, J ACOUST SOC AM, V101, P1585, DOI 10.1121/1.418146
   Menendez RGD, 2001, BRAIN TOPOGR, V14, P131, DOI 10.1023/A:1012944913650
   Mick P, 2014, OTOLARYNG HEAD NECK, V150, P378, DOI 10.1177/0194599813518021
   NAATANEN R, 1982, PSYCHOL BULL, V92, P605
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Nishitani N, 2005, PHYSIOLOGY, V20, P60, DOI 10.1152/physiol.00043.2004
   Pantev C, 2001, NEUROREPORT, V12, P169, DOI 10.1097/00001756-200101220-00041
   Pantev C, 1998, NATURE, V392, P811, DOI 10.1038/33918
   Parbery-Clark A, 2012, NEUROBIOL AGING, V33, DOI 10.1016/j.neurobiolaging.2011.12.015
   Parbery-Clark A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018082
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Parbery-Clark A, 2009, J NEUROSCI, V29, P14100, DOI 10.1523/JNEUROSCI.3256-09.2009
   Pettigrew Catharine M, 2004, J Am Acad Audiol, V15, P469, DOI 10.3766/jaaa.15.7.2
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811
   Quaranta N, 2015, HEARING BALANC COMMU, V13, P77, DOI 10.3109/21695717.2014.994869
   Scherg M, 1989, J Cogn Neurosci, V1, P336, DOI 10.1162/jocn.1989.1.4.336
   Schneider BA, 2010, SPRINGER HANDB AUDIT, V34, P167, DOI 10.1007/978-1-4419-0993-0_7
   Seinfeld S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00810
   Shahin A, 2003, J NEUROSCI, V23, P5545
   Shahin A, 2005, NEUROREPORT, V16, P1781, DOI 10.1097/01.wnr.0000185017.29316.63
   Silva-Pereyra J, 2003, CLIN NEUROPHYSIOL, V114, P2469, DOI 10.1016/S1388-2457(03)00248-7
   Slater J, 2015, BEHAV BRAIN RES, V291, P244, DOI 10.1016/j.bbr.2015.05.026
   Stenklev NC, 2004, INT J AUDIOL, V43, P295, DOI 10.1080/14992020400050039
   Tierney AT, 2015, P NATL ACAD SCI USA, V112, P10062, DOI 10.1073/pnas.1505114112
   Tse CY, 2007, P NATL ACAD SCI USA, V104, P17157, DOI 10.1073/pnas.0707901104
   van Dinteren R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087347
   Vigneau M, 2006, NEUROIMAGE, V30, P1414, DOI 10.1016/j.neuroimage.2005.11.002
   Vigneau M, 2011, NEUROIMAGE, V54, P577, DOI 10.1016/j.neuroimage.2010.07.036
   Watkins K, 2004, J COGNITIVE NEUROSCI, V16, P978, DOI 10.1162/0898929041502616
   West GL, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187779
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Yamasoba T, 2013, HEARING RES, V303, P30, DOI 10.1016/j.heares.2013.01.021
   ZATORRE RJ, 1992, SCIENCE, V256, P846, DOI 10.1126/science.1589767
   Zendel BR, 2015, J COGNITIVE NEUROSCI, V27, P1044, DOI 10.1162/jocn_a_00758
   Zendel BR, 2014, NEUROBIOL AGING, V35, P55, DOI 10.1016/j.neurobiolaging.2013.06.022
   Zendel BR, 2013, J COGNITIVE NEUROSCI, V25, P503, DOI 10.1162/jocn_a_00329
   Zendel BR, 2012, PSYCHOL AGING, V27, P410, DOI 10.1037/a0024816
NR 79
TC 9
Z9 9
U1 1
U2 8
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0197-4580
EI 1558-1497
J9 NEUROBIOL AGING
JI Neurobiol. Aging
PD SEP
PY 2019
VL 81
BP 102
EP 115
DI 10.1016/j.neurobiolaging.2019.05.015
PG 14
WC Geriatrics & Gerontology; Neurosciences
SC Geriatrics & Gerontology; Neurosciences & Neurology
GA IV7GT
UT WOS:000484435300011
PM 31280114
DA 2021-02-24
ER

PT J
AU Martinez, AM
AF Martinez, Aleix M.
TI The Promises and Perils of Automated Facial Action Coding in Studying
   Children's Emotions
SO DEVELOPMENTAL PSYCHOLOGY
LA English
DT Article
DE facial action coding; facial expression; emotion; computer vision;
   machine learning
ID EXPRESSION RECOGNITION; SPEECH-PERCEPTION; 1ST YEAR; FACE; SEQUENCES;
   PCA; 3D
AB Computer vision algorithms have made tremendous advances in recent years. We now have algorithms that can detect and recognize objects, faces, and even facial actions in still images and video sequences. This is wonderful news for researchers that need to code facial articulations in large data sets of images and videos, because this task is time consuming and can only be completed by expert coders, making it very expensive. The availability of computer algorithms that can automatically code facial actions in extremely large data sets also opens the door to studies in psychology and neuroscience that were not previously possible, for example, to study the development of the production of facial expressions from infancy to adulthood within and across cultures. Unfortunately, there is a lack of methodological understanding on how these algorithms should and should not be used, and on how to select the most appropriate algorithm for each study. This article aims to address this gap in the literature. Specifically, we present several methodologies for use in hypothesis-based and exploratory studies, explain how to select the computer algorithms that best fit to the requirements of our experimental design, and detail how to evaluate whether the automatic annotations provided by existing algorithms are trustworthy.
C1 [Martinez, Aleix M.] Ohio State Univ, Ctr Cognit & Brain Sci, 205 Dreese Labs,2015 Neil Ave, Columbus, OH 43210 USA.
RP Martinez, AM (corresponding author), Ohio State Univ, Ctr Cognit & Brain Sci, 205 Dreese Labs,2015 Neil Ave, Columbus, OH 43210 USA.; Martinez, AM (corresponding author), Ohio State Univ, Dept Elect & Comp Engn, 205 Dreese Labs,2015 Neil Ave, Columbus, OH 43210 USA.
EM martinez.158@osu.edu
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01-DC-014498,
   R01-EY-020834]; Human Frontier Science ProgramHuman Frontier Science
   Program [RGP0036/2016]; Center for Cognitive and Brain Sciences at The
   Ohio State University; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC014498,
   R01DC014498, R01DC014498] Funding Source: NIH RePORTER
FX The author and the research described in this article were supported by
   the National Institutes of Health, grants R01-DC-014498 and
   R01-EY-020834, the Human Frontier Science Program, grant RGP0036/2016,
   and by the Center for Cognitive and Brain Sciences at The Ohio State
   University. The author thanks Qianli Feng, Fabian Benitez-Quiroz,
   Ramprakash Srinivasan, and Shichuan Du for discussion. The Ohio State
   University is licensing some of the computational tools developed in the
   author's lab.
CR Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606
   Agudo A, 2018, COMPUT VIS IMAGE UND, V167, P121, DOI 10.1016/j.cviu.2018.01.002
   Agudo A, 2014, PROC CVPR IEEE, P1558, DOI 10.1109/CVPR.2014.202
   Albiero V, 2018, IEEE IMAGE PROC, P2037, DOI 10.1109/ICIP.2018.8451267
   Bai Y., 2018, P EUR C COMP VIS ECC, P20
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   Barrett L. F., PSYCHOL SCI PUBLIC I
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   Benitez-Quiroz CF, 2017, IEEE I CONF COMP VIS, P3990, DOI 10.1109/ICCV.2017.428
   Benitez-Quiroz CF, 2016, PROC CVPR IEEE, P5562, DOI 10.1109/CVPR.2016.600
   Benitez-Quiroz CF, 2016, COGNITION, V150, P77, DOI 10.1016/j.cognition.2016.02.004
   Benitez-Quiroz CF, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086268
   Benitez-Quiroz CF, 2018, P NATL ACAD SCI USA, V115, P3581, DOI 10.1073/pnas.1716084115
   Benitez-Quiroz F, 2019, IEEE T PATTERN ANAL, V41, P2835, DOI 10.1109/TPAMI.2018.2868952
   Bennett DS, 2005, INFANCY, V8, P167, DOI 10.1207/s15327078in0802_4
   Buolamwini J., 2018, V81, P77
   Camras L, HDB EMOTIONAL DEV
   Castro VL, 2018, EMOTION, V18, P260, DOI 10.1037/emo0000354
   Chang FJ, 2018, IEEE INT CONF AUTOMA, P122, DOI 10.1109/FG.2018.00027
   Chu WS, 2019, IMAGE VISION COMPUT, V81, P1, DOI 10.1016/j.imavis.2018.10.002
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Corneanu C. A, 2018, P EUR C COMP VIS, DOI [10.1016/S1077-3142(03)00081-X, DOI 10.1016/S1077-3142(03)00081-X]
   Cumming G., 2013, UNDERSTANDING NEW ST, DOI [10.4324/9780203807002, DOI 10.4324/9780203807002]
   Deng WH, 2018, IEEE T PATTERN ANAL, V40, P2513, DOI 10.1109/TPAMI.2017.2757923
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Dotsch R, 2017, NAT HUM BEHAV, V1, DOI 10.1038/s41562-016-0001
   Draper BA, 2003, COMPUT VIS IMAGE UND, V91, P115, DOI 10.1016/S1077-3142(03)00077-8
   Du SC, 2015, DIALOGUES CLIN NEURO, V17, P443
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   Ekman P, 2002, A HUMAN FACE, P77
   Ekman P., 1997, WHAT FACE REVEALS BA, DOI [10.1093/acprof:oso/9780195179644.001.0001, DOI 10.1093/ACPROF:OSO/9780195179644.001.0001]
   Ekman P, 2016, PERSPECT PSYCHOL SCI, V11, P31, DOI 10.1177/1745691615596992
   Garg R, 2013, PROC CVPR IEEE, P1272, DOI 10.1109/CVPR.2013.168
   Gaspar A, 2012, INT J BEHAV DEV, V36, P348, DOI 10.1177/0165025412441762
   Gegenfurtner KR, 2003, NAT REV NEUROSCI, V4, P563, DOI 10.1038/nrn1138
   Gervain J, 2010, ANNU REV PSYCHOL, V61, P191, DOI 10.1146/annurev.psych.093008.100408
   Girard Jeffrey M, 2015, IEEE Int Conf Autom Face Gesture Recognit Workshops, V1, DOI 10.1109/FG.2015.7163106
   Goodfellow I., 2016, DEEP LEARNING
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gotardo PFU, 2011, IEEE I CONF COMP VIS, P802, DOI 10.1109/ICCV.2011.6126319
   Gotardo PFU, 2011, PROC CVPR IEEE, DOI 10.1109/cvpr.2011.5995560
   Gotardo PFU, 2011, IEEE T PATTERN ANAL, V33, P2051, DOI 10.1109/TPAMI.2011.50
   Hamsici OC, 2008, IEEE T PATTERN ANAL, V30, P647, DOI 10.1109/TPAMI.2007.70717
   Hamsici OC, 2007, J MACH LEARN RES, V8, P1583
   Hamsici OC, 2012, LECT NOTES COMPUT SC, V7575, P260, DOI 10.1007/978-3-642-33765-9_19
   Hamsici OC, 2009, IEEE I CONF COMP VIS, P1003, DOI 10.1109/ICCV.2009.5459365
   Hamsici OC, 2009, IEEE T PATTERN ANAL, V31, P1985, DOI 10.1109/TPAMI.2008.234
   Holodynski M, 2019, DEV PSYCHOL, V55, P1812, DOI 10.1037/dev0000698
   Izard C. E., 1983, SYSTEM IDENTIFYING A
   Jack RE, 2012, P NATL ACAD SCI USA, V109, P7241, DOI 10.1073/pnas.1200155109
   Jia HJ, 2009, IEEE T PATTERN ANAL, V31, P841, DOI 10.1109/TPAMI.2008.122
   Jin X, 2017, COMPUT VIS IMAGE UND, V162, P1, DOI 10.1016/j.cviu.2017.08.008
   Jourabloo A, 2017, IEEE I CONF COMP VIS, P3219, DOI 10.1109/ICCV.2017.347
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Lee M, 2013, PROC CVPR IEEE, P1280, DOI 10.1109/CVPR.2013.169
   Li K, 2015, IEEE T CYBERNETICS, V45, P1401, DOI 10.1109/TCYB.2014.2351831
   Lien JJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P390, DOI 10.1109/AFGR.1998.670980
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Lucey P, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI [DOI 10.1109/CVPRW.2010.5543262, 10.1109/CVPRW.2010.5543262]
   Lyons MJ, 2000, P ROY SOC B-BIOL SCI, V267, P2239, DOI 10.1098/rspb.2000.1274
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Martinez A, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P35, DOI 10.1109/IVL.1999.781120
   Martinez A. M., 2003, P IEEE COMP VIS PATT, DOI [10.1109/CVPR.2003.1211375, DOI 10.1109/CVPR.2003.1211375]
   Martinez A, 2012, J MACH LEARN RES, V13, P1589
   Martinez AM, 2017, CURR OPIN PSYCHOL, V17, P27, DOI 10.1016/j.copsyc.2017.06.009
   Martinez AM, 2017, CURR DIR PSYCHOL SCI, V26, P263, DOI 10.1177/0963721417698535
   Martinez AM, 2005, IEEE T PATTERN ANAL, V27, P1934, DOI 10.1109/TPAMI.2005.250
   Martinez AM, 2003, VISION RES, V43, P1047, DOI 10.1016/S0042-6989(03)00079-8
   Martinez AM, 2001, IEEE T SYST MAN CY B, V31, P669, DOI 10.1109/3477.956029
   Martinez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   MATIAS R, 1993, DEV PSYCHOL, V29, P524, DOI 10.1037/0012-1649.29.3.524
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Neth D, 2010, VISION RES, V50, P1693, DOI 10.1016/j.visres.2010.05.024
   Neth D, 2009, J VISION, V9, DOI 10.1167/9.1.5
   Oostenbroek J, 2013, J REPROD INFANT PSYC, V31, P328, DOI 10.1080/02646838.2013.832180
   Oster H, 2003, ANN NY ACAD SCI, V1000, P197, DOI 10.1196/annals.1280.024
   Oster H, 2006, MONOGRAPH CODING MAN
   Pons G., 2018, ARXIV180206664
   Poursabzi-Sangdeh F., 2018, ARXIV180207810
   Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50
   Rad Mahdi, 2018, ARXIV181003707
   Reeb-Sutherland BC, 2015, COGNITION EMOTION, V29, P372, DOI 10.1080/02699931.2014.913552
   Reynolds D, 2015, ENCY BIOMETRICS, P827, DOI [DOI 10.1007/978-1-4899-7488-4_196, 10.1007/978-1-4899-7488-4_196]
   Rivera S, 2012, PATTERN RECOGN, V45, P1792, DOI 10.1016/j.patcog.2011.09.023
   Romero A, 2018, ARXIV181203704
   Savran A, 2012, IMAGE VISION COMPUT, V30, P774, DOI 10.1016/j.imavis.2011.11.008
   Sikka K, 2015, PEDIATRICS, V136, pE124, DOI 10.1542/peds.2015-0029
   Simon T, 2010, PROC CVPR IEEE, P2737, DOI 10.1109/CVPR.2010.5539998
   Song Yale, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163081
   Srinivasan R., 2017, EMOTIONET CHALLENGE
   Srinivasan R, 2019, IEEE T AFFECTIVE COM
   Srinivasan R, 2016, J NEUROSCI, V36, P4434, DOI 10.1523/JNEUROSCI.1704-15.2016
   Sun YJ, 2008, SENSYS'08: PROCEEDINGS OF THE 6TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P1, DOI 10.1145/1460412.1460414
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Tian YL, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P229, DOI 10.1109/AFGR.2002.1004159
   Tome D, 2017, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR.2017.603
   Vielzeuf V, 2018, ARXIV181013197
   Wan H, 2018, IEEE T PATTERN ANAL, V40, P409, DOI 10.1109/TPAMI.2017.2672557
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wiles O., 2018, ARXIV180806882
   Witkower Z., PSYCHOL SCI
   Yang P., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383059
   You D, 2011, IEEE T PATTERN ANAL, V33, P631, DOI 10.1109/TPAMI.2010.173
   Zanette S, 2016, J EXP CHILD PSYCHOL, V150, P165, DOI 10.1016/j.jecp.2016.05.007
   Zhang X, 2014, IEEE WINT CONF APPL, P1104, DOI 10.1109/WACV.2014.6835735
   Zhao KL, 2018, PROC CVPR IEEE, P2090, DOI 10.1109/CVPR.2018.00223
   Zhao RQ, 2018, IEEE T PATTERN ANAL, V40, P3059, DOI 10.1109/TPAMI.2017.2772922
   Zhao RQ, 2016, LECT NOTES COMPUT SC, V9914, P590, DOI 10.1007/978-3-319-48881-3_41
   Zhu M., 2006, CVPR 06, V1, P132, DOI DOI 10.1109/CVPR.2006.271
NR 110
TC 2
Z9 2
U1 0
U2 9
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0012-1649
EI 1939-0599
J9 DEV PSYCHOL
JI Dev. Psychol.
PD SEP
PY 2019
VL 55
IS 9
SI SI
BP 1965
EP 1981
DI 10.1037/dev0000728
PG 17
WC Psychology, Developmental
SC Psychology
GA IT7PC
UT WOS:000483067100012
PM 31464498
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU McKenzie, RM
   Huang, M
   Ong, TT
   Snodin, N
AF McKenzie, Robert M.
   Huang, Mimi
   Ong, Theng Theng
   Snodin, Navaporn
TI Socio-psychological salience and categorisation accuracy of speaker
   place of origin
SO LINGUA
LA English
DT Article
DE Sociolinguistic awareness; Social categorisation; Speech perception;
   Dialect identification; Salience; Language attitudes
ID UNIVERSITY-STUDENTS ATTITUDES; FREE CLASSIFICATION; FOREIGN ACCENT;
   LANGUAGE ATTITUDES; REGIONAL DIALECTS; SPOKEN-ENGLISH; VARIETIES;
   IDENTIFICATION; SPEECH; PERCEPTIONS
AB There exists a dearth of research investigating how listeners use their knowledge of variation in their L2 to categorise speaker provenance from stimulus speech. The present study, employing a free classification measure, examined 191 Thai university students' categorisations of the geographical origin of nine speakers of English. Analysis demonstrated participants were generally able to distinguish between native and non-native English speech more broadly, and this distinction was found to be the primary perceptual dimension underlying speaker provenance categorisations. With regards to more fine-grained classifications, recognition rates for Thai, UK, US and Indian English speakers were substantially higher when compared to Vietnamese and Australian English speakers, indicating the social-psychological salience of the speech forms, rather than geographical proximity, was key in determining categorisation accuracy. Analysis of misidentification patterns showed a tendency for the Thai students to conflate Asian English speech forms, despite substantial phonological and phonetic differences between the English spoken in different Asian nations. Participant comments also indicated segmental features were largely responsible for (mis)categorisations. Consistent with current speaker evaluation theories, the findings point to speaker categorisation as an initial processing stage, leading to the activation of stereotypes about and attitudes towards the speakers' perceived social and ethnic group membership. Crown Copyright (C) 2019 Published by Elsevier B.V.
C1 [McKenzie, Robert M.] Northumbria Univ, English Language & Linguist, Dept Humanities, Lipman Bldg,Sandyford Rd, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.
   [Huang, Mimi; Ong, Theng Theng] Northumbria Univ, Dept Humanities, Newcastle Upon Tyne, Tyne & Wear, England.
   [Snodin, Navaporn] Kasetsart Univ, Dept Foreign Languages, Bangkok, Thailand.
RP McKenzie, RM (corresponding author), Northumbria Univ, English Language & Linguist, Dept Humanities, Lipman Bldg,Sandyford Rd, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.
EM robert.mckenzie@northumbria.ac.uk
RI McKenzie, Robert M./AAA-3193-2019
OI McKenzie, Robert M./0000-0002-7212-6724; Huang,
   Mimi/0000-0003-1082-8904; Snodin, Navaporn/0000-0002-5042-4608
CR Aitken A. J., 1984, LANGUAGE BRIT ISLES, P94
   Atagi E, 2016, APPL PSYCHOLINGUIST, V37, P241, DOI 10.1017/S014271641400054X
   Baker W, 2009, AM SPEECH, V84, P48, DOI 10.1215/00031283-2009-004
   Bent T, 2017, WIRES COGN SCI, V8, DOI 10.1002/wcs.1434
   Bent T, 2016, J PHONETICS, V58, P104, DOI 10.1016/j.wocn.2016.08.004
   BLAAUW E, 1994, SPEECH COMMUN, V14, P359, DOI 10.1016/0167-6393(94)90028-0
   Bradley D., 2010, ROUTLEDGE HDB SOCIOL, P98
   Braun V, 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]
   Campbell-Kibler K, 2012, LINGUA, V122, P753, DOI 10.1016/j.lingua.2012.01.002
   Carrie E, 2018, J MULTILING MULTICUL, V39, P313, DOI 10.1080/01434632.2017.1389946
   Clark L, 2010, LANG AWARE, V19, P299, DOI 10.1080/09658416.2010.524301
   Clopper C., 2004, LANG VAR CHANGE, V18, P193
   Clopper CG, 2007, J PHONETICS, V35, P421, DOI 10.1016/j.wocn.2006.06.001
   Cruttenden Alan, 2014, GIMSONS PRONUNCIATIO
   Deterding David, 2013, MISUNDERSTANDINGS EN
   Dragojevic M, 2018, J LANG SOC PSYCHOL, V37, P28, DOI 10.1177/0261927X17706942
   Dragojevic M, 2017, COMMUN MONOGR, V84, P385, DOI 10.1080/03637751.2017.1322213
   Garrett Peter., 2010, ATTITUDES LANGUAGE
   Gnevsheva K, 2018, J MULTILING MULTICUL, V39, P688, DOI 10.1080/01434632.2018.1427756
   Hogg MA, 2006, COMMUN THEOR, V16, P7, DOI 10.1111/j.1468-2885.2006.00003.x
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kreiman J., 2011, FDN VOICE STUDIES
   Kristiansen G, 2018, REV COGN LINGUIST, V16, P494, DOI 10.1075/rcl.00019.kri
   Ladegaard H. J., 2001, LANG AWARE, V10, P25, DOI [10.1080/09658410108667023, DOI 10.1080/09658410108667023]
   Ladegaard HJ, 1998, LANG COMMUN, V18, P251, DOI 10.1016/S0271-5309(98)00008-1
   MacFarlane AE, 2012, LINGUA, V122, P764, DOI 10.1016/j.lingua.2012.01.007
   McCullough EA, 2016, J PHONETICS, V55, P19, DOI 10.1016/j.wocn.2015.11.002
   McGowan KB, 2016, AWARENESS CONTROL SO, P25, DOI DOI 10.1017/CBO9781139680448.004
   McKenzie R., 2010, SOCIAL PSYCHOL ENGLI
   McKenzie R., 2015, INT J SOCIOL LANG, V236, P31
   McKenzie RM, 2008, JPN FORUM, V20, P267, DOI 10.1080/09555800802047525
   McKenzie RM, 2018, J MULTILING MULTICUL, V39, P830, DOI 10.1080/01434632.2018.1445744
   McKenzie RM, 2017, INT J APPL LINGUIST, V27, P152, DOI 10.1111/ijal.12110
   McKenzie RM, 2016, J MULTILING MULTICUL, V37, P536, DOI 10.1080/01434632.2015.1083573
   McKenzie RM, 2015, LANG AWARE, V24, P150, DOI 10.1080/09658416.2014.998232
   McKenzie RM, 2008, INT J APPL LINGUIST, V18, P63, DOI 10.1111/j.1473-4192.2008.00179.x
   McKenzie RM, 2008, J MULTILING MULTICUL, V29, P139, DOI 10.2167/jmmd565.0
   Melchers G., 2011, WORLD ENGLISHES
   Montgomery C, 2012, J SOCIOLING, V16, P638, DOI 10.1111/josl.12003
   Munro MJ, 2006, STUD SECOND LANG ACQ, V28, P111, DOI 10.1017/S0272263106060049
   Office of Higher Education Commission, 2018, TOT STUD AC YEAR 201
   Osburne AG, 1996, APPL LINGUIST, V17, P164, DOI 10.1093/applin/17.2.164
   Park H, 2013, J PHONETICS, V41, P78, DOI 10.1016/j.wocn.2012.11.001
   Peleggi Maurizio, 2007, THAILAND WORLDLY KIN
   Peters P, 2012, TOP ENGL LINGUIST, V80, P233
   Preston D.R., 1999, HDB PERCEPTUAL DIALE, V1
   Prikhodkine A., 2018, LANGUAGE REGARD, P218
   Ruch H, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00818
   Sailaja P., 2009, INDIAN ENGLISH
   Snodin NS, 2015, ASIAN ENGL, V17, P248, DOI 10.1080/13488678.2015.1083354
   Stanlaw James, 2004, JAPANESE ENGLISH LAN
   Trudgill P., 2008, ENGLISH PRONUNCIATIO, P77
   Van Bezooijen R, 1999, J LANG SOC PSYCHOL, V18, P31, DOI 10.1177/0261927X99018001003
   Watanabe Y, 2017, LANG AWARE, V26, P134, DOI 10.1080/09658416.2017.1319849
   Watanabe Yutai, 2008, TE REO, V51, P99
   Williams A., 1999, HDB PERCEPTUAL DIALE, DOI DOI 10.1075/Z.HPD1.29WIL
   Yan Q., 2015, J LINGUISTIC GEOGRAP, V3, P1, DOI DOI 10.1017/JLG.2015.3
   Yook C, 2013, J MULTILING MULTICUL, V34, P279, DOI 10.1080/01434632.2012.734509
NR 58
TC 0
Z9 0
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0024-3841
EI 1872-6135
J9 LINGUA
JI Lingua
PD SEP
PY 2019
VL 228
AR 102705
DI 10.1016/j.lingua.2019.06.006
PG 17
WC Linguistics; Language & Linguistics
SC Linguistics
GA IT2QZ
UT WOS:000482697800003
OA Green Published, Other Gold, Green Accepted
DA 2021-02-24
ER

PT J
AU Robertson, EK
   Gallant, JE
AF Robertson, Erin K.
   Gallant, Jennifer E.
TI Eye tracking reveals subtle spoken sentence comprehension problems in
   children with dyslexia
SO LINGUA
LA English
DT Article
DE Dyslexia; Children; Spoken sentence comprehension; Eye tracking
ID SUBJECT-VERB AGREEMENT; LANGUAGE IMPAIRMENT; SYNTACTIC COMPREHENSION;
   DEVELOPMENTAL DYSLEXIA; INDIVIDUAL-DIFFERENCES; SPEECH-PERCEPTION;
   MEMORY; MORPHOLOGY; PHONOLOGY; DEFICITS
AB Children with dyslexia who did not have SLI (n = 31) and typically-developing (TD, n = 31) children with similar oral language and nonverbal skills completed a spoken sentence-picture matching task while an eye tracker recorded fixations and dwell time. No group differences were found on accuracy - which was very high across both groups. However, there were online processing differences. The TD group made more target fixations and the dyslexic group made more fixations to syntax distractors. Time course analyses revealed that compared to the dyslexic group, the TD group looked longer at the target when sentences became unambiguous. Across groups, sentence accuracy, target fixations, and cumulative target dwell time were correlated. Word reading was correlated with sentence accuracy and both online sentence processing measures, but only in the dyslexic group. In conclusion, the eye tracking data uncovered more than the behavioral measures alone, and children with dyslexia showed subtle sentence comprehension difficulties compared to TD peers. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Robertson, Erin K.] Cape Breton Univ, 1250 Grand Lake Rd, Sydney, NSW B1P 6L2, Australia.
   [Gallant, Jennifer E.] Univ New Brunswick, Fredericton, NB, Canada.
RP Robertson, EK (corresponding author), Cape Breton Univ, 1250 Grand Lake Rd, Sydney, NSW B1P 6L2, Australia.
EM erin_robertson@cbu.ca
FU Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR
   [402,411-2011]; Canadian Foundation for InnovationCanada Foundation for
   Innovation; Nova Scotia Research Trust; Cape Breton University [30,088]
FX Funding for this project was provided to the first author from the
   Natural Sciences and Engineering Research Council of Canada (Grant #
   402,411-2011), the Canadian Foundation for Innovation, Nova Scotia
   Research Trust, and Cape Breton University (Grant # 30,088).
CR Andreu L, 2013, APPL PSYCHOLINGUIST, V34, P5, DOI 10.1017/S0142716411000592
   [Anonymous], SR RES EYELINK 1000
   Bishop D, 1989, TEST RECEPTION GRAMM
   Bishop DVM, 2017, INT J LANG COMM DIS, V52, P671, DOI 10.1111/1460-6984.12335
   BISHOP DOROTHY V.M., 1997, UNCOMMON UNDERSTANDI
   Bishop DVM, 2004, PSYCHOL BULL, V130, P858, DOI 10.1037/0033-2909.130.6.858
   BRADLEY L, 1983, NATURE, V301, P419, DOI 10.1038/301419a0
   Casalis S, 2013, J LEARN DISABIL-US, V46, P210, DOI 10.1177/0022219412449423
   Catts HW, 2005, J SPEECH LANG HEAR R, V48, P1378, DOI 10.1044/1092-4388(2005/096)
   Chung KKH, 2014, ANN DYSLEXIA, V64, P222, DOI 10.1007/s11881-014-0095-2
   COOPER RM, 1974, COGNITIVE PSYCHOL, V6, P84, DOI 10.1016/0010-0285(74)90005-X
   Desroches AS, 2006, COGNITION, V100, pB32, DOI 10.1016/j.cognition.2005.09.001
   GATHERCOLE SE, 1990, J MEM LANG, V29, P336, DOI 10.1016/0749-596X(90)90004-J
   Huettig F, 2015, DYSLEXIA, V21, P97, DOI 10.1002/dys.1497
   Joanisse MF, 2000, J EXP CHILD PSYCHOL, V77, P30, DOI 10.1006/jecp.1999.2553
   Kaufman A., 2004, KAUFMAN BRIEF INTELL, V2nd
   Lecocq P., 1996, ECOSSE VILLENEUVE AS
   Leikin M., 2004, READING WRITING INTE, V17, P801, DOI DOI 10.1007/S11145-004-2661-1
   Leonard LB, 2013, J SPEECH LANG HEAR R, V56, P577, DOI 10.1044/1092-4388(2012/11-0254)
   Mani N, 2014, J EXP CHILD PSYCHOL, V126, P264, DOI 10.1016/j.jecp.2014.05.004
   McArthur GM, 2000, J CHILD PSYCHOL PSYC, V41, P869, DOI 10.1111/1469-7610.00674
   McMurray B, 2010, COGNITIVE PSYCHOL, V60, P1, DOI 10.1016/j.cogpsych.2009.06.003
   Mishra RK, 2012, J EYE MOVEMENT RES, V5
   Montgomery JW, 2009, J SPEECH LANG HEAR R, V52, P269, DOI 10.1044/1092-4388(2008/07-0116)
   Nation K, 2003, J EXP CHILD PSYCHOL, V86, P314, DOI 10.1016/j.jecp.2003.09.001
   Norbury CF, 2001, J SPEECH LANG HEAR R, V44, P165, DOI 10.1044/1092-4388(2001/015)
   Rispens J, 2004, J NEUROLINGUIST, V17, P333, DOI 10.1016/j.jneuroling.2003.09.001
   Rispens J, 2007, INT J LANG COMM DIS, V42, P293, DOI 10.1080/13682820600988777
   Robertson EK, 2010, APPL PSYCHOLINGUIST, V31, P141, DOI 10.1017/S0142716409990208
   SCARBOROUGH HS, 1991, ANN DYSLEXIA, V41, P207, DOI 10.1007/BF02648087
   Semel E. M., 2003, CLIN EVALUATION LANG
   SHANWEILER D, 1995, PSYCHOL SCI, V6, P149, DOI 10.1111/j.1467-9280.1995.tb00324.x
   SMITH ST, 1989, APPL PSYCHOLINGUIST, V10, P429, DOI 10.1017/S0142716400009012
   Snowling M., 2000, DYSLEXIA
   STANOVICH KE, 1986, READ RES QUART, V21, P360, DOI 10.1598/RRQ.21.4.1
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   vanderLely HKJ, 1996, LINGUA, V98, P243, DOI 10.1016/0024-3841(95)00044-5
   Wagner R, 1999, COMPREHENSIVE TEST P
   Wiseheart R, 2009, ANN DYSLEXIA, V59, P151, DOI 10.1007/s11881-009-0028-7
   Woodcock R.W., 2011, WOODCOCK READING MAS
NR 40
TC 1
Z9 1
U1 1
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0024-3841
EI 1872-6135
J9 LINGUA
JI Lingua
PD SEP
PY 2019
VL 228
AR 102708
DI 10.1016/j.lingua.2019.06.009
PG 17
WC Linguistics; Language & Linguistics
SC Linguistics
GA IT2QZ
UT WOS:000482697800001
DA 2021-02-24
ER

PT J
AU Dillon, MR
   Duyck, M
   Dehaene, S
   Amalric, M
   Izard, V
AF Dillon, Moira R.
   Duyck, Marianne
   Dehaene, Stanislas
   Amalric, Marie
   Izard, Veronique
TI Geometric Categories in Cognition
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE
LA English
DT Article
DE categories; shape discrimination; spatial cognition; angle; geometry
ID OBJECT RECOGNITION; SPEECH-PERCEPTION; SHAPE; DISCRIMINATION; ANGLE;
   DISSOCIATION; ORIENTATION; SYMMETRY; JUDGMENT
AB At the scale in which we live, space is continuous. Nevertheless, our perception and cognition parse the world into categories, whether physical, like scene or object. or abstract, like infinitesimal point or 7. The present study focuses on 2 categories of special angles in planar geometry. parallels and perpendiculars, and we evaluate how these categories might be reflected in adults' basic angle discrimination. In the first experiment, participants were most precise when detecting 2 parallel or perpendicular lines among other pairs of lines at different relative orientations. Detection was also enhanced for 2 connected lines whose angle approached 90 degrees, with precision peaking at 90 degrees. These patterns emerged despite large variations in the scales and orientations of the angle exemplars. In the second experiment, the enhanced detection of perpendiculars persisted when stimuli were rotated in depth. indicating a capacity to discriminate shapes based on perpendicularity in 3 dimensions despite large variation in angles' 2-dimensional projections. The results suggest that 2 categorical concepts which lie at the foundation of Euclidean geometry, parallelism and perpendicularity, are reflected in our discrimination of simple visual forms. and they pave the way for future studies exploring the developmental and evolutionary origins of these cognitive categories.
C1 [Dillon, Moira R.] NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
   [Duyck, Marianne; Izard, Veronique] CNRS, Integrat Neurosci & Cognit Ctr, UMR 8002, Paris, France.
   [Duyck, Marianne; Izard, Veronique] Univ Paris 05, Paris, France.
   [Duyck, Marianne] NEI, Lab Sensorimotor Res, NIH, Bethesda, MD 20892 USA.
   [Dehaene, Stanislas] Coll France, Paris, France.
   [Dehaene, Stanislas; Amalric, Marie] Univ Paris Saclay, Cognit Neuroimaging Unit, CEA, INSERM,Univ Paris Sud,NeuroSpin Ctr, Saclay, France.
   [Amalric, Marie] Sorbonne Univ, Paris, France.
RP Dillon, MR (corresponding author), NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
EM moira.dillon@nyu.edu
OI Dillon, Moira/0000-0002-6689-5316
FU Starting Grant of the European Research Council [263179]; National
   Science FoundationNational Science Foundation (NSF) [DGE-1144152];
   Norman Henry Anderson Graduate Psychology Fund
FX The full data set and analysis code are available on the Open Science
   Framework at: https://osf.io/wa64q/.Code for the generation of the
   experimental stimuli are available upon request. This work was supported
   by a Starting Grant of the European Research Council to Veronique Izard
   (FP7 Project MathConstruction 263179), by a grant from the National
   Science Foundation to Moira R. Dillon (DGE-1144152), and by the Norman
   Henry Anderson Graduate Psychology Fund to Moira R. Dillon. All authors
   conceived of and designed the study. Marianne Duyck programmed the
   stimuli. Moira R. Dillon, Marianne Duyck, and Veronique Izard collected
   the data. Moira R. Dillon, Marianne Duyck, and Veronique Izard performed
   the data analysis. Moira R. Dillon, Marianne Duyck, and Veronique Izard
   drafted the article, and all authors provided critical revisions. All
   authors approved the final version of the article. Moira R. Dillon and
   Marianne Duyck contributed equally and are listed in alphabetical order.
CR Amir O, 2012, VISION RES, V62, P35, DOI 10.1016/j.visres.2012.03.020
   Amir O, 2011, VISION RES, V51, P2198, DOI 10.1016/j.visres.2011.08.015
   Anselmi F, 2014, REPRESENTATION LEARN
   Anthony JL, 2005, CURR DIR PSYCHOL SCI, V14, P255, DOI 10.1111/j.0963-7214.2005.00376.x
   APPELLE S, 1972, PSYCHOL BULL, V78, P266, DOI 10.1037/h0033117
   Augustine E, 2011, J COGN DEV, V12, P556, DOI 10.1080/15248372.2011.560586
   Biederman I, 2009, PSYCHOL SCI, V20, P1437, DOI 10.1111/j.1467-9280.2009.02465.x
   BORNSTEIN MH, 1981, DEV PSYCHOL, V17, P82, DOI 10.1037/0012-1649.17.1.82
   CARPENTER RH, 1973, EXP BRAIN RES, V18, P287
   Chen S, 1996, VISION RES, V36, P1721, DOI 10.1016/0042-6989(95)00245-6
   Deen B, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms13995
   Dehaene S, 2006, SCIENCE, V311, P381, DOI 10.1126/science.1121739
   Dehaene S, 2005, TRENDS COGN SCI, V9, P335, DOI 10.1016/j.tics.2005.05.004
   Dillon M. R, 2019, INFANTS SENSIT UNPUB
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Euclid, 1990, GREAT BOOKS W WORLD
   Firestone C, 2016, BEHAV BRAIN SCI, V39, DOI 10.1017/S0140525X15000965
   Goldstone RL, 2010, WIRES COGN SCI, V1, P69, DOI 10.1002/wcs.26
   Heeley DW, 1996, VISION RES, V36, P3607, DOI 10.1016/0042-6989(96)00077-6
   Howe CQ, 2005, P NATL ACAD SCI USA, V102, P1228, DOI 10.1073/pnas.0409311102
   Huang Y, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24558-x
   Izard V, 2011, ATTENTION PERFORM, P319, DOI 10.1016/B978-0-12-385948-8.00019-0
   Izard V, 2011, P NATL ACAD SCI USA, V108, P9782, DOI 10.1073/pnas.1016686108
   Juttner M, 2006, BEHAV BRAIN RES, V175, P420, DOI 10.1016/j.bbr.2006.09.005
   Juttner M, 2013, DEV PSYCHOL, V49, P161, DOI 10.1037/a0027707
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Landau B, 2006, COGNITION, V100, P483, DOI 10.1016/j.cognition.2005.06.005
   LIBERMAN AM, 1961, J EXP PSYCHOL, V61, P379, DOI 10.1037/h0049038
   Lovett A, 2017, PSYCHOL SCI, V28, P1408, DOI 10.1177/0956797617709814
   Lupyan G, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00054
   Maurer D, 2002, TRENDS COGN SCI, V6, P255, DOI 10.1016/S1364-6613(02)01903-4
   Nakayama K., 1995, INVITATION COGNITIVE, V2, P1
   Nundy S, 2000, P NATL ACAD SCI USA, V97, P5592, DOI 10.1073/pnas.97.10.5592
   Piazza M, 2013, PSYCHOL SCI, V24, P1037, DOI 10.1177/0956797612464057
   REGAN D, 1992, VISION RES, V32, P1845, DOI 10.1016/0042-6989(92)90046-L
   Regan D, 1996, VISION RES, V36, P323, DOI 10.1016/0042-6989(95)00113-E
   SLATER A, 1991, J EXP CHILD PSYCHOL, V51, P395, DOI 10.1016/0022-0965(91)90084-6
   Smith LB, 2009, CURR DIR PSYCHOL SCI, V18, P290, DOI 10.1111/j.1467-8721.2009.01654.x
   SNIPPE HP, 1994, J OPT SOC AM A, V11, P1222, DOI 10.1364/JOSAA.11.001222
   von Helmholtz H.L.F, 1866, HELMHOLTZS TREATISE
   WENDEROTH P, 1984, PERCEPT PSYCHOPHYS, V36, P538, DOI 10.3758/BF03207514
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKHOVEN P, 1993, PERCEPTION, V22, P177, DOI 10.1068/p220177
   Wundt W., 1897, OUTLINES PSYCHOL
   Xu ZX, 2018, J VISION, V18, DOI 10.1167/18.13.10
NR 45
TC 2
Z9 2
U1 1
U2 9
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0096-1523
EI 1939-1277
J9 J EXP PSYCHOL HUMAN
JI J. Exp. Psychol.-Hum. Percept. Perform.
PD SEP
PY 2019
VL 45
IS 9
BP 1236
EP 1247
DI 10.1037/xhp0000663
PG 12
WC Psychology; Psychology, Experimental
SC Psychology
GA IS9TY
UT WOS:000482492000008
PM 31219284
OA Bronze
DA 2021-02-24
ER

PT J
AU Choi, JY
   Perrachione, TK
AF Choi, Ja Young
   Perrachione, Tyler K.
TI Noninvasive neurostimulation of left temporal lobe disrupts rapid talker
   adaptation in speech processing
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Speech perception; tDCS; Adaptation; Phonetic variability; Superior
   temporal cortex
ID DIRECT-CURRENT STIMULATION; AUDITORY-CORTEX; NEURAL ADAPTATION;
   INFORMATION; NORMALIZATION; PERCEPTION; MEMORY; IDENTIFICATION;
   PLASTICITY; ATTENTION
AB Talker adaptation improves speech processing efficiency by reducing possible mappings between talkers' speech acoustics and listeners' phonemic representations. We investigated the functional neuroanatomy of talker adaptation by applying noninvasive neurostimulation (high-definition transcranial direct current stimulation; HD-tDCS) to left superior temporal lobe while participants performed an auditory word identification task. We factorially manipulated talker variability (single vs. mixed talkers) and speech context (isolated words vs. connected speech), measuring listeners' speech processing efficiency under anodal, cathodal, or sham stimulation. Speech processing was faster for single talkers than mixed talkers, and connected speech reduced the additional processing costs associated with mixed-talker speech. However, the beneficial effect of connected speech in the mixed-talker condition was significantly attenuated under both anodal and cathodal stimulation versus sham. Stimulation of left superior temporal lobe disrupts the brain's ability to use local phonetic context to rapidly adapt to a talker, revealing this region's causal role in talker adaptation.
C1 [Choi, Ja Young; Perrachione, Tyler K.] Boston Univ, Dept Speech Language & Hearing Sci, 635 Commonwealth Ave, Boston, MA 02215 USA.
   [Choi, Ja Young] Harvard Univ, Program Speech & Hearing Biosci & Technol, Cambridge, MA 02138 USA.
RP Perrachione, TK (corresponding author), Boston Univ, Dept Speech Language & Hearing Sci, 635 Commonwealth Ave, Boston, MA 02215 USA.
EM tkp@bu.edu
FU NIDCD of the National Institutes of HealthUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R03DC014045]; NARSAD Young Investigator Award from the Brain and
   Behavior Research FoundationNARSAD; NATIONAL INSTITUTE ON DEAFNESS AND
   OTHER COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R03DC014045]
   Funding Source: NIH RePORTER
FX We thank Elly Hu and Sara Dougherty for their assistance. This research
   was supported by the NIDCD of the National Institutes of Health under
   award number R03DC014045 and by a NARSAD Young Investigator Award from
   the Brain and Behavior Research Foundation to TP.
CR Abrams DA, 2008, J NEUROSCI, V28, P3958, DOI 10.1523/JNEUROSCI.0187-08.2008
   ASSMANN PF, 1982, J ACOUST SOC AM, V71, P975, DOI 10.1121/1.387579
   Belin P, 2003, NEUROREPORT, V14, P2105, DOI 10.1097/00001756-200311140-00019
   Bestmann S, 2015, TRENDS COGN SCI, V19, P13, DOI 10.1016/j.tics.2014.10.003
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Chandrasekaran B, 2011, J COGNITIVE NEUROSCI, V23, P2690, DOI 10.1162/jocn.2011.21631
   Choi JY, 2019, COGNITION, V192, DOI 10.1016/j.cognition.2019.05.019
   Choi JY, 2018, ATTEN PERCEPT PSYCHO, V80, P784, DOI 10.3758/s13414-017-1395-5
   Datta A, 2009, BRAIN STIMUL, V2, P201, DOI 10.1016/j.brs.2009.03.005
   Dayan E, 2013, NAT NEUROSCI, V16, P838, DOI 10.1038/nn.3422
   Francis AL, 2006, J ACOUST SOC AM, V119, P1712, DOI 10.1121/1.2149768
   Fritz J, 2003, NAT NEUROSCI, V6, P1216, DOI 10.1038/nn1141
   Froemke RC, 2007, NATURE, V450, P425, DOI 10.1038/nature06289
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Green KP, 1997, PERCEPT PSYCHOPHYS, V59, P675, DOI 10.3758/BF03206015
   Herrmann B, 2015, J NEUROPHYSIOL, V113, P2582, DOI 10.1152/jn.00634.2014
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Jaaskelainen IP, 2007, TRENDS NEUROSCI, V30, P653, DOI 10.1016/j.tins.2007.09.003
   Jacobson L, 2012, EXP BRAIN RES, V216, P1, DOI 10.1007/s00221-011-2891-9
   JOHNSON K, 1990, J ACOUST SOC AM, V88, P642, DOI 10.1121/1.399767
   Johnson K, 2005, BLACKW HBK LINGUIST, P363, DOI 10.1002/9780470757024.ch15
   Joos M., 1948, LANGUAGE MONOGRAPHS, V24, P136
   Kaganovich N, 2006, BRAIN RES, V1114, P161, DOI 10.1016/j.brainres.2006.07.049
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Kuo HI, 2013, BRAIN STIMUL, V6, P644, DOI 10.1016/j.brs.2012.09.010
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Laing EJC, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00203
   Liebenthal E, 2005, CEREB CORTEX, V15, P1621, DOI 10.1093/cercor/bhi040
   Lim SJ, 2019, ATTEN PERCEPT PSYCHO, V81, P1167, DOI 10.3758/s13414-019-01684-w
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   MULLENNIX JW, 1990, PERCEPT PSYCHOPHYS, V47, P379, DOI 10.3758/BF03210878
   Myers EB, 2007, NEUROPSYCHOLOGIA, V45, P1463, DOI 10.1016/j.neuropsychologia.2006.11.005
   NEAREY TM, 1989, J ACOUST SOC AM, V85, P2088, DOI 10.1121/1.397861
   Nitsche MA, 2000, J PHYSIOL-LONDON, V527, P633, DOI 10.1111/j.1469-7793.2000.t01-1-00633.x
   Nusbaum HC, 1992, SPEECH PERCEPTION PR, P113
   Obleser J, 2007, CEREB CORTEX, V17, P2251, DOI 10.1093/cercor/bhl133
   Ohn SH, 2008, NEUROREPORT, V19, P43, DOI 10.1097/WNR.0b013e3282f2adfd
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   PALMERI TJ, 1993, J EXP PSYCHOL LEARN, V19, P309, DOI 10.1037/0278-7393.19.2.309
   Peelle JE, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00309
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Perrachione TK, 2016, NEURON, V92, P1383, DOI 10.1016/j.neuron.2016.11.020
   Roe JM, 2016, NEUROPSYCHOLOGIA, V80, P1, DOI 10.1016/j.neuropsychologia.2015.11.005
   Scott SK, 2000, BRAIN, V123, P2400, DOI 10.1093/brain/123.12.2400
   Sjerps MJ, 2011, ATTEN PERCEPT PSYCHO, V73, P1195, DOI 10.3758/s13414-011-0096-8
   Stevens AA, 2004, COGNITIVE BRAIN RES, V18, P162, DOI 10.1016/j.cogbrainres.2003.10.008
   STRANGE W, 1976, J ACOUST SOC AM, V60, P213, DOI 10.1121/1.381066
   Thair H, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00641
   Todorovic A, 2011, J NEUROSCI, V31, P9118, DOI 10.1523/JNEUROSCI.1425-11.2011
   von Kriegstein K, 2003, COGNITIVE BRAIN RES, V17, P48, DOI 10.1016/S0926-6410(03)00079-X
   Wehr M, 2003, NATURE, V426, P442, DOI 10.1038/nature02116
   Wernicke C., 1874, APHASISCHE SYMPTOMEN
   Wong PCM, 2004, J COGNITIVE NEUROSCI, V16, P1173, DOI 10.1162/0898929041920522
   Zaehle T, 2011, EXP BRAIN RES, V215, P135, DOI 10.1007/s00221-011-2879-5
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
   Zhang CC, 2016, NEUROIMAGE, V124, P536, DOI 10.1016/j.neuroimage.2015.08.064
   Zoefel B, 2017, LANG COGN NEUROSCI, V32, P910, DOI 10.1080/23273798.2016.1247970
NR 59
TC 2
Z9 2
U1 1
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD SEP
PY 2019
VL 196
AR 104655
DI 10.1016/j.bandl.2019.104655
PG 7
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA IR6PY
UT WOS:000481562400003
PM 31310963
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Kousaie, S
   Baum, S
   Phillips, NA
   Gracco, V
   Titone, D
   Chen, JK
   Chai, XQJ
   Klein, D
AF Kousaie, Shanna
   Baum, Shari
   Phillips, Natalie A.
   Gracco, Vincent
   Titone, Debra
   Chen, Jen-Kai
   Chai, Xiaoqian J.
   Klein, Denise
TI Language learning experience and mastering the challenges of perceiving
   speech in noise
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Age of acquisition; Bilingualism; Functional magnetic resonance imaging
   (fMRI); Language; Speech perception in noise
ID IN-NOISE; 2ND-LANGUAGE ACQUISITION; DEGRADED SPEECH; PERCEPTION; AGE;
   CONTEXT; INTELLIGIBILITY; INFORMATION; NETWORK; DIFFER
AB Given the ubiquity of noisy environments and increasing globalization, the necessity to perceive speech in noise in a non-native language is common and necessary for successful communication. In the current investigation, bilingual individuals who learned their non-native language at different ages underwent magnetic resonance imaging while listening to sentences in both of their languages, in quiet and in noise. Sentence context was varied such that the final word could be of high or low predictability. Results show that early non-native language learning is associated with superior ability to benefit from contextual information behaviourally, and a pattern of neural recruitment in the left inferior frontal gyrus that suggests easier processing when perceiving non-native speech in noise. These findings have implications for our understanding of speech processing in non-optimal listening conditions and shed light on how individuals navigate every day complex communicative environments, in a native and non-native language.
C1 [Kousaie, Shanna; Chen, Jen-Kai; Klein, Denise] McGill Univ, Montreal Neurol Inst, Cognit Neurosci Unit, Montreal, PQ H3A 2B4, Canada.
   [Kousaie, Shanna; Baum, Shari; Phillips, Natalie A.; Gracco, Vincent; Titone, Debra; Chen, Jen-Kai; Klein, Denise] McGill Univ, Ctr Res Brain Language & Mus, Montreal, PQ H3G 2A8, Canada.
   [Baum, Shari; Gracco, Vincent] McGill Univ, Fac Med, Sch Commun Sci & Disorders, Montreal, PQ H3A 1G1, Canada.
   [Phillips, Natalie A.] Concordia Univ, Ctr Res Human Dev, Dept Psychol, Montreal, PQ H4B 1R6, Canada.
   [Phillips, Natalie A.] McGill Univ, Bloomfield Ctr Res Aging, Lady Davis Inst Med Res, Memory Clin,Jewish Gen Hosp, Montreal, PQ H3T 1E2, Canada.
   [Phillips, Natalie A.] McGill Univ, Jewish Gen Hosp, Memory Clin, Montreal, PQ H3T 1E2, Canada.
   [Gracco, Vincent] Haskins Labs Inc, New Haven, CT 06511 USA.
   [Titone, Debra] McGill Univ, Dept Psychol, Montreal, PQ H3A 1G1, Canada.
   [Chai, Xiaoqian J.] McGill Univ, Montreal Neurol Inst, Dept Neurol & Neurosurg, Montreal, PQ H3A 2B4, Canada.
RP Kousaie, S; Klein, D (corresponding author), McGill Univ, Montreal Neurol Inst, 3801 Univ St, Montreal, PQ H3A 2B4, Canada.
EM shanna.kousaie@mail.mcgill.ca; denise.klein@mcgill.ca
FU Canadian Institutes of Health Research postdoctoral fellowshipCanadian
   Institutes of Health Research (CIHR); Natural Sciences and Engineering
   Research Council of CanadaNatural Sciences and Engineering Research
   Council of Canada (NSERC)CGIAR; Fonds de recherches du Quebec - Societe
   et culture (FRQSC), Soutien aux equipes de recherche grant; Blema and
   Arnold Steinberg Family Foundation; Fonds de recherches du Quebec -
   Societe et culture and Nature et technologies (FRQSC/FRQNT)
FX This work was supported by a Canadian Institutes of Health Research
   postdoctoral fellowship to SK, by an individual Discovery Grant from the
   Natural Sciences and Engineering Research Council of Canada to DK, by a
   Fonds de recherches du Quebec - Societe et culture (FRQSC), Soutien aux
   equipes de recherche grant to SB, VG, DT, DK, NP, by the Fonds de
   recherches du Quebec - Societe et culture and Nature et technologies
   (FRQSC/FRQNT) funded Centre for Research on Brain Language and Music,
   and by funds from the Blema and Arnold Steinberg Family Foundation.
CR [Anonymous], 2006, ACTES DE LA CONFEREN
   Audacity Team, 2014, AUDACITY R FREE AUDI
   Berken JA, 2016, J NEUROSCI, V36, P1165, DOI 10.1523/JNEUROSCI.1960-15.2016
   BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32
   Booth JR, 2002, HUM BRAIN MAPP, V16, P251, DOI 10.1002/hbm.10054
   BOOTHROYD A, 1988, J ACOUST SOC AM, V84, P101, DOI 10.1121/1.396976
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Clos M, 2014, HUM BRAIN MAPP, V35, P61, DOI 10.1002/hbm.22151
   COLTHEART M, 1981, Q J EXP PSYCHOL-A, V33, P497, DOI 10.1080/14640748108400805
   Davies M., 2008, CORPUS CONT AM ENGLI
   Davis MF, 2011, J OCCUP ENVIRON MED, V53, P190, DOI [10.1097/JOM.0b013e31820805d5, 10.1162/jocn_a_00084]
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Diaz MT, 2007, J COGNITIVE NEUROSCI, V19, P1768, DOI 10.1162/jocn.2007.19.11.1768
   Du Y, 2017, P NATL ACAD SCI USA, V114, P13579, DOI 10.1073/pnas.1712223114
   DUFFY JR, 1974, J SPEECH HEAR RES, V17, P631, DOI 10.1044/jshr.1704.631
   Fabbro F, 1999, THE NEUROLINGUISTICS
   Gaser C, 2003, J NEUROSCI, V23, P9240
   Golestani N, 2013, NEUROIMAGE, V79, P52, DOI 10.1016/j.neuroimage.2013.04.049
   Golestani N, 2009, BILING-LANG COGN, V12, P385, DOI 10.1017/S1366728909990150
   GOUGH PM, 2005, THE JOURNAL OF NEURO, V25, P80, DOI DOI 10.1523/JNEUROSCI.2307-05.2005
   GROSJEAN F, 1989, BRAIN LANG, V36, P3, DOI 10.1016/0093-934X(89)90048-5
   Grosjean F., 2008, STUDYING BILINGUALS
   Hervais-Adelman A, 2014, BRAIN LANG, V132, P1, DOI 10.1016/j.bandl.2014.01.009
   Kaiser A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00638
   Klein D, 2014, BRAIN LANG, V131, P20, DOI 10.1016/j.bandl.2013.05.014
   LUCKS M, 2016, INTERNATIONAL JOURNA, V55, P126, DOI DOI 10.3109/14992027.2015.1061710
   Mayo LH, 1997, J SPEECH LANG HEAR R, V40, P686, DOI 10.1044/jslhr.4003.686
   MCLAUGHLIN B, 1983, LANG LEARN, V33, P135, DOI 10.1111/j.1467-1770.1983.tb00532.x
   Mercier J, 2014, BILING-LANG COGN, V17, P89, DOI 10.1017/S1366728913000084
   MIILDWLAINEN R, 2009, LECTURE NOTES IN COM, V5629, P191
   MILLER GA, 1951, J EXP PSYCHOL, V41, P329, DOI 10.1037/h0062491
   MILLER GA, 1962, IRE T INFORM THEOR, V8, P81, DOI 10.1109/TIT.1962.1057697
   New B, 2001, ANN PSYCHOL, V101, P447
   Noonan KA, 2013, J COGNITIVE NEUROSCI, V25, P1824, DOI 10.1162/jocn_a_00442
   Obleser J, 2007, J NEUROSCI, V27, P2283, DOI 10.1523/JNEUROSCI.4663-06.2007
   Obleser J, 2010, CEREB CORTEX, V20, P633, DOI 10.1093/cercor/bhp128
   Peelle J. E, 2019, THE ROUDEDGE HANDBOO
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Price CJ, 2010, ANN NY ACAD SCI, V1191, P62, DOI 10.1111/j.1749-6632.2010.05444.x
   Reetzke R, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168048
   SEGALOWITZ NS, 1993, APPL PSYCHOLINGUIST, V14, P369, DOI 10.1017/S0142716400010845
   Seghier ML, 2010, J NEUROSCI, V30, P16809, DOI 10.1523/JNEUROSCI.3377-10.2010
   Shahin AJ, 2009, NEUROIMAGE, V44, P1133, DOI 10.1016/j.neuroimage.2008.09.045
   Shi LF, 2010, J SPEECH LANG HEAR R, V53, P821, DOI 10.1044/1092-4388(2010/09-0081)
   Shook A, 2013, BILING-LANG COGN, V16, P304, DOI 10.1017/S1366728912000466
   Skoe E, 2018, J AM ACAD AUDIOLOGY
   Tabri D, 2011, INT J LANG COMM DIS, V46, P411, DOI 10.3109/13682822.2010.519372
   Thieba C, 2019, BRAIN COGNITION, V134, P71, DOI 10.1016/j.bandc.2018.05.009
   Volk S, 2014, J INT BUS STUD, V45, P862, DOI 10.1057/jibs.2014.26
   Wei M, 2015, J NEUROLINGUIST, V36, P35, DOI 10.1016/j.jneuroling.2015.05.001
   Winneke AH, 2011, PSYCHOL AGING, V26, P427, DOI 10.1037/a0021683
   Woo CW, 2014, NEUROIMAGE, V91, P412, DOI 10.1016/j.neuroimage.2013.12.058
   Zhao XW, 2010, INT J BILING EDUC BI, V13, P505, DOI 10.1080/13670050.2010.488284
NR 54
TC 1
Z9 1
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD SEP
PY 2019
VL 196
AR 104645
DI 10.1016/j.bandl.2019.104645
PG 9
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA IR6PY
UT WOS:000481562400005
PM 31284145
DA 2021-02-24
ER

PT J
AU Bressmann, T
   Eick, T
   Pardo, J
AF Bressmann, Tim
   Eick, Tamara
   Pardo, Jennifer
TI Effect of the Visual Presentation of a Craniofacial Syndrome on Speech
   Intelligibility in Noise
SO CLEFT PALATE-CRANIOFACIAL JOURNAL
LA English
DT Article
DE Speech perception; nonsyndromic clefting; facial morphology; esthetics;
   psychosocial adjustment; scarring; social support
ID MEDICAL-STUDENTS KNOWLEDGE; CLEFT-PALATE; PERCEPTUAL EVALUATION;
   JUDGMENTS; EXPOSURE; EXPECTATIONS; APPEARANCE; RATINGS
AB Objective: Research has argued that a speaker's facial appearance can result in an "intelligibility cost" for the listener. The study investigated whether such an intelligibility cost exists for a visible repaired cleft lip and nasal asymmetry.
   Setting: University department.
   Participants: Eight typical speakers provided speech samples. Twenty-eight naive listeners participated in a speech in noise experiment.
   Interventions: Listeners transcribed sentences in noise that were paired with faces of individuals with repaired cleft lip and nasal asymmetry or typical faces. They also rated speaker intelligibility and answered a questionnaire about their previous knowledge about cleft lip and palate.
   Main Outcome Measures: Percentage of words transcribed correctly and intelligibility ratings, compared by experimental condition (photo of typical face or face with repaired cleft lip and nasal asymmetry) and speaker gender.
   Results: There were no statistically significant differences between speech stimuli that were presented with faces with repaired cleft lip and nasal asymmetry or typical faces. The percentage of words transcribed correctly by the listeners was lower for female speakers (F = 12.7, df = 1; P < .01). Speech intelligibility of female speakers was rated more poorly (F = 10.5, df = 1; P < .01).
   Conclusions: Presence of a repaired cleft lip and nasal asymmetry did not result in an intelligibility cost for naive listeners. Future research should investigate possible effects of facial motion or previous knowledge.
C1 [Bressmann, Tim; Eick, Tamara] Univ Toronto, Dept Speech Language Pathol, 160-500 Univ Ave, Toronto, ON M5G 1V7, Canada.
   [Pardo, Jennifer] Montclair State Univ, Dept Psychol, Montclair, NJ USA.
RP Bressmann, T (corresponding author), Univ Toronto, Dept Speech Language Pathol, 160-500 Univ Ave, Toronto, ON M5G 1V7, Canada.
EM tim.bressmann@utoronto.ca
FU University of Toronto Excellence Award-Social Sciences and Humanities
   [502784]; Social Sciences and Humanities Research Council Insight
   Development Award [430-2016-00253]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: The
   authors gratefully acknowledge funding of this project through a
   University of Toronto Excellence Award-Social Sciences and Humanities to
   Ms Eick (fund numer 502784) as well as a Social Sciences and Humanities
   Research Council Insight Development Award (fund number 430-2016-00253).
CR Babel M, 2015, J ACOUST SOC AM, V137, P2823, DOI 10.1121/1.4919317
   Barker J, 2007, SPEECH COMMUN, V49, P402, DOI 10.1016/j.specom.2006.11.003
   Bench J., 1979, SPEECH HEARING TESTS
   Bennun RD, 2016, CLEFT LIP AND PALATE MANAGEMENT: A COMPREHENSIVE ATLAS, P1
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Branemark P, 1999, REHABILITATION COMPL
   Brunnegard K, 2009, INT J LANG COMM DIS, V44, P656, DOI 10.1080/13682820802295203
   CLIFFORD E, 1983, CLEFT PALATE J, V20, P83
   Dagenais PA, 1999, J MED SPEECH-LANG PA, V7, P91
   Damrose JF, 2004, J VOICE, V18, P415, DOI 10.1016/j.jvoice.2000.11.001
   Eadie TL, 2007, ANN OTO RHINOL LARYN, V116, P695, DOI 10.1177/000348940711600912
   Eadie TL, 2010, J VOICE, V24, P564, DOI 10.1016/j.jvoice.2008.12.005
   Finizia C, 1998, LARYNGOSCOPE, V108, P138, DOI 10.1097/00005537-199801000-00027
   GLASS L, 1979, CLEFT PALATE J, V16, P436
   Kang O, 2009, J LANG SOC PSYCHOL, V28, P441, DOI 10.1177/0261927X09341950
   Laczi E, 2005, CLEFT PALATE-CRAN J, V42, P202, DOI 10.1597/03-011.1
   Mathot S, 2012, BEHAV RES METHODS, V44, P314, DOI 10.3758/s13428-011-0168-7
   McGowan KB, 2015, LANG SPEECH, V58, P502, DOI 10.1177/0023830914565191
   PODOL J, 1976, CLEFT PALATE J, V13, P361
   RICHMAN LC, 1978, CLEFT PALATE J, V15, P155
   RUBIN DL, 1992, RES HIGH EDUC, V33, P511, DOI 10.1007/BF00973770
   Stevenage SV, 1999, BRIT J PSYCHOL, V90, P221, DOI 10.1348/000712699161369
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Vallino LD, 1996, ANN PLAS SURG, V36, P380, DOI 10.1097/00000637-199604000-00009
   VALLINO LD, 1992, CLEFT PALATE-CRAN J, V29, P275, DOI 10.1597/1545-1569(1992)029<0275:MSKOAE>2.3.CO;2
   VALLINO LD, 1991, CLEFT PALATE-CRAN J, V28, P169, DOI 10.1597/1545-1569(1991)028<0169:DSKOAE>2.3.CO;2
   van As CJ, 2003, J SPEECH LANG HEAR R, V46, P947, DOI 10.1044/1092-4388(2003/3074)
   Voineskos SH, 2018, ANNU REV MED, V69, P467, DOI 10.1146/annurev-med-060116-022831
   Yi HG, 2013, J ACOUST SOC AM, V134, pEL387, DOI 10.1121/1.4822320
NR 29
TC 0
Z9 0
U1 0
U2 1
PU ALLIANCE COMMUNICATIONS GROUP DIVISION ALLEN PRESS
PI LAWRENCE
PA 810 EAST 10TH STREET, LAWRENCE, KS 66044 USA
SN 1055-6656
EI 1545-1569
J9 CLEFT PALATE-CRAN J
JI Cleft Palate-Craniofac. J.
PD SEP
PY 2019
VL 56
IS 8
BP 1038
EP 1043
DI 10.1177/1055665618825403
PG 6
WC Dentistry, Oral Surgery & Medicine; Surgery
SC Dentistry, Oral Surgery & Medicine; Surgery
GA IR5BA
UT WOS:000481446800007
PM 30669867
DA 2021-02-24
ER

PT J
AU Lee, H
   Jongman, A
AF Lee, Hyunjung
   Jongman, Allard
TI Effects of Sound Change on the Weighting of Acoustic Cues to the
   Three-Way Laryngeal Stop Contrast in Korean: Diachronic and Dialectal
   Comparisons
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Korean stop production; sound change; VOT; F0; Kyungsang dialect
ID PITCH-ACCENT SYSTEM; VOICE ONSET TIME; FUNDAMENTAL-FREQUENCY;
   SPEECH-PERCEPTION; TONAL ALIGNMENT; SEOUL; LANGUAGE; TENSE
AB Both segmental and suprasegmental properties of the South Kyungsang dialect of Korean have changed under the influence of standard Seoul Korean. This study examines how such sound change affects acoustic cues to the three-way laryngeal contrast among Korean stops across Kyungsang generations through a comparison with Seoul Korean. Thirty-nine female Korean speakers differing in dialect (Kyungsang, Seoul) and age (older, younger) produced words varying in initial stops and lexical accent patterns, for which voice onset time and fundamental frequency (F0) at vowel onset were measured. This study first confirms previous findings regarding age and dialectal variation in distinguishing the three Korean stops. In addition, we report age variation in the use of voice onset time and F0 for the stops in Kyungsang Korean, with younger speakers using F0 more than older speakers as a cue to the stop distinction. This age variation is accounted for by the reduced lexical tonal properties of Kyungsang Korean and the increased influence of Seoul Korean. A comparison of the specific cue weighting across speaker groups also reveals that younger Kyungsang speakers pattern with Seoul speakers who arguably follow the enhancing F0 role of the innovative younger Seoul speakers. The shared cue weighting pattern across generations and dialects suggests that each speaker group changes the acoustic cue weighting in a similar direction.
C1 [Lee, Hyunjung] Incheon Natl Univ, Incheon, South Korea.
   [Jongman, Allard] Univ Kansas, Incheon, South Korea.
RP Lee, H (corresponding author), Incheon Natl Univ, 12 Gaebeol Ro,Songdo Dong,Yeonsu Gu, Incheon, South Korea.
EM hyunjunglee123@gmail.com
FU Ministry of Education of the Republic of Korea; National Research
   Foundation of KoreaNational Research Foundation of Korea
   [NRF-2016S1A5A2A02925192]
FX This work was supported by the Ministry of Education of the Republic of
   Korea and the National Research Foundation of Korea
   (NRF-2016S1A5A2A02925192).
CR Abramson A. S., 1985, PHONETIC LINGUISTICS
   Arvaniti A, 1998, J PHONETICS, V26, P3, DOI 10.1006/jpho.1997.0063
   Bang HY, 2018, J PHONETICS, V66, P120, DOI 10.1016/j.wocn.2017.09.005
   Bates D., 2014, R PACKAGE VERSION LME4 LINEAR MIXED EF LME4 LINEAR MIXED EF, DOI DOI 10.18637/JSS.V067.I01
   BENJAMIN BJ, 1981, J GERONTOL, V36, P722, DOI 10.1093/geronj/36.6.722
   Bruce G., 1977, SWEDISH WORD ACCENTS
   Chang S. C., 2007, THESIS
   Chang S.-E., 2008, 82 ANN M LING SOC AM
   Chang SE, 2013, LANG SPEECH, V56, P211, DOI 10.1177/0023830912443951
   Cho TH, 2002, J PHONETICS, V30, P193, DOI 10.1006/jpho.2001.0153
   Dmitrieva O, 2015, J PHONETICS, V49, P77, DOI 10.1016/j.wocn.2014.12.005
   Escudero P, 2004, STUD SECOND LANG ACQ, V26, P551, DOI 10.1017/S0272226310400021
   Francis AL, 2006, J ACOUST SOC AM, V120, P2884, DOI 10.1121/1.2346131
   Gandour Jack, 1974, J PHONETICS, V2, P337
   HAN MS, 1970, PHONETICA, V22, P112, DOI 10.1159/000259311
   Hombert J., 1978, TONE LINGUISTIC SURV, P77
   Jun J, 2006, J EAST ASIAN LINGUIS, V15, P289, DOI 10.1007/s10831-006-9000-2
   Kang KH, 2006, J ACOUST SOC AM, V119, P1672, DOI 10.1121/1.2166607
   Kang KH, 2008, J ACOUST SOC AM, V124, P3909, DOI 10.1121/1.2988292
   Kang YJ, 2014, J PHONETICS, V45, P76, DOI 10.1016/j.wocn.2014.03.005
   Kenstowicz Michael, 2006, [Studies in Phonetics, Phonology, and Morphology, 음성음운형태론연구], V12, P247
   KIM CW, 1965, WORD, V21, P339, DOI 10.1080/00437956.1965.11435434
   Kim Jieun, 2009, [LANGUAGE RESEARCH, 어학연구], V45, P43
   Kim MR, 2004, J EAST ASIAN LINGUIS, V13, P59, DOI 10.1023/B:JEAL.0000007344.43938.4e
   Kim MR, 2002, J PHONETICS, V30, P77, DOI 10.1006/jpho.2001.0152
   Kong EJ, 2011, J PHONETICS, V39, P196, DOI 10.1016/j.wocn.2011.02.002
   Lee Dongmyung, 2009, [LANGUAGE RESEARCH, 어학연구], V45, P3
   Lee H., 2016, J KOREAN SOC SPEECH, V8, P23
   Lee Hyun Su, 2008, THESIS
   Lee H, 2016, J ACOUST SOC AM, V140, pEL491, DOI 10.1121/1.4971203
   Lee H, 2016, PHONOLOGY, V33, P325, DOI 10.1017/S0952675716000142
   Lee H, 2016, J INT PHON ASSOC, V46, P157, DOI 10.1017/S0025100316000013
   Lee H, 2015, J PHONETICS, V50, P15, DOI 10.1016/j.wocn.2015.01.003
   Lee H, 2014, J EAST ASIAN LINGUIS, V23, P71, DOI 10.1007/s10831-013-9119-x
   Lee H, 2013, J PHONETICS, V41, P117, DOI 10.1016/j.wocn.2012.12.002
   Lee H, 2012, J INT PHON ASSOC, V42, P145, DOI 10.1017/S0025100312000035
   Lehiste I, 1967, READINGS ACOUSTIC PH
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007
   Nittrouer S, 2005, J COMMUN DISORD, V38, P29, DOI 10.1016/j.jcomdis.2004.03.006
   Oglesbee Eric Nathanael, 2008, THESIS
   Oh E, 2011, J PHONETICS, V39, P59, DOI 10.1016/j.wocn.2010.11.002
   Pearce M, 2009, LINGUA, V119, P846, DOI 10.1016/j.lingua.2007.10.023
   PRIETO P, 1995, J PHONETICS, V23, P429, DOI 10.1006/jpho.1995.0032
   R Core Team, 2015, R LANG ENV STAT COMP
   Ramsey S. R., 1975, THESIS
   REPP BH, 1982, PSYCHOL BULL, V92, P81, DOI 10.1037/0033-2909.92.1.81
   Schuh R., 2007, S KYENGSANG TO UNPUB
   Silva D. J., 2006, PHONOLOGY, V23, P287, DOI DOI 10.1017/S0952675706000911
   Venables W. N, 2002, MODERN APPL STAT S
   Weihs C, 2005, ST CLASS DAT ANAL, P335
   Xu Yi, 1993, THESIS
NR 52
TC 4
Z9 4
U1 1
U2 3
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD SEP
PY 2019
VL 62
IS 3
BP 509
EP 530
DI 10.1177/0023830918786305
PG 22
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA IR5FM
UT WOS:000481458400005
PM 30014745
DA 2021-02-24
ER

PT J
AU Llompart, M
   Reinisch, E
AF Llompart, Miquel
   Reinisch, Eva
TI Imitation in a Second Language Relies on Phonological Categories but
   Does Not Reflect the Productive Usage of Difficult Sound Contrasts
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Second language learning; imitation; speech production; speech
   perception; perception-production link
ID TRAINING JAPANESE LISTENERS; R-VERTICAL-BAR; SPEECH-PERCEPTION;
   SENSORIMOTOR ADAPTATION; LEXICAL REPRESENTATIONS; VOWEL IMITATION;
   COGNITIVE LOAD; ENGLISH; SPEAKERS; COARTICULATION
AB This study investigated the relationship between imitation and both the perception and production abilities of second language (L2) learners for two non-native contrasts differing in their expected degree of difficulty. German learners of English were tested on perceptual categorization, imitation and a word reading task for the difficult English /e/-/AE/ contrast, which tends not to be well encoded in the learners' phonological inventories, and the easy, near-native /i/-/?/ contrast. As expected, within-task comparisons between contrasts revealed more robust perception and better differentiation during production for /i/-/?/ than /e/-/AE/. Imitation also followed this pattern, suggesting that imitation is modulated by the phonological encoding of L2 categories. Moreover, learners' ability to imitate /e/ and /AE/ was related to their perception of that contrast, confirming a tight perception-production link at the phonological level for difficult L2 sound contrasts. However, no relationship was observed between acoustic measures for imitated and read-aloud tokens of /e/ and /AE/. This dissociation is mostly attributed to the influence of inaccurate non-native lexical representations in the word reading task. We conclude that imitation is strongly related to the phonological representation of L2 sound contrasts, but does not need to reflect the learners' productive usage of such non-native distinctions.
C1 [Llompart, Miquel; Reinisch, Eva] Ludwig Maximilian Univ Munich, Munich, Germany.
RP Llompart, M (corresponding author), Ludwig Maximilian Univ Munich, Inst Phonet & Speech Proc, Schellingstrasse 3, D-80799 Munich, Bavaria, Germany.
EM m.llompart@phonetik.uni-muenchen.de
RI Llompart, Miquel/ABF-3326-2020; Reinisch, Eva/R-1646-2016
OI Llompart, Miquel/0000-0002-2002-8778; Reinisch, Eva/0000-0002-1400-5473
FU German Research Foundation (DFG)German Research Foundation (DFG) [RE
   3047/1-1]
FX This project was funded by a grant from the German Research Foundation
   (DFG; grant nr. RE 3047/1-1) to the second author. This work is part of
   the first author's Ph.D. project. We would like to thank Rosa Franzke
   for her help with testing participants, Jonathan Harrington for advice
   concerning statistics and Jessica Siddins for comments on a previous
   version of the manuscript.
CR Akahane-Yamada R., 1998, P INT C SPOK LANG PR, V5, P1
   Alivuotila L., 2007, P 16 INT C PHON SCI, P361
   Amengual M, 2016, APPL PSYCHOLINGUIST, V37, P1221, DOI 10.1017/S0142716415000557
   Babel Molly, 2009, THESIS
   Bent T, 2005, THESIS
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2010, PRAAT DOING PHONETIC
   Bohn O.-S., 1992, STUDIES 2 LANGUAGE A, V14, P131, DOI DOI 10.1017/S0272263100010792
   BOHN OS, 1990, APPL PSYCHOLINGUIST, V11, P303, DOI 10.1017/S0142716400008912
   Bosker HR, 2017, J MEM LANG, V94, P166, DOI 10.1016/j.jml.2016.12.002
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P977, DOI 10.3758/BF03206911
   Broersma M., 2005, THESIS
   Chistovich L., 1966, Q PROGR STATUS REPOR, V2, P1
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Cutler A, 2006, J PHONETICS, V34, P269, DOI 10.1016/j.wocn.2005.06.002
   Darcy I, 2013, MENT LEX, V8, P372, DOI 10.1075/ml.8.3.06dar
   de Jong K, 2009, J PHONETICS, V37, P357, DOI 10.1016/j.wocn.2009.06.001
   Diaz B, 2016, BILING-LANG COGN, V19, P955, DOI 10.1017/S1366728915000450
   Diaz B, 2012, LEARN INDIVID DIFFER, V22, P680, DOI 10.1016/j.lindif.2012.05.005
   Diehl R. L., 1989, ECOL PSYCHOL, V1, P121, DOI [10.1207/s15326969-co0102_2, DOI 10.1207/S15326969-CO0102_2, DOI 10.1207/s15326969eco0102_2]
   DIEHL RL, 1985, J EXP PSYCHOL HUMAN, V11, P209
   DIEHL RL, 1978, J EXP PSYCHOL HUMAN, V4, P599, DOI 10.1037/0096-1523.4.4.599
   Draxler Christoph, 2004, P 4 INT C LANG RES E, P559
   Eger N. A., 2018, J EXPT PSYCHOL LEARN, DOI [10.1037/xlm0000599., DOI 10.1037/XLM0000599.]
   Eger NA, 2019, STUD SECOND LANG ACQ, V41, P179, DOI 10.1017/S0272263117000377
   Escudero P, 2008, J PHONETICS, V36, P345, DOI 10.1016/j.wocn.2007.11.002
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   FLEGE JE, 1988, J ACOUST SOC AM, V83, P729, DOI 10.1121/1.396115
   FOURAKIS M, 1984, PHONETICA, V41, P140, DOI 10.1159/000261720
   Fowler CA, 2003, J MEM LANG, V49, P396, DOI 10.1016/S0749-596X(03)00072-X
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger SD, 2004, PSYCHON B REV, V11, P716, DOI 10.3758/BF03196625
   Hao YC, 2016, J PHONETICS, V54, P151, DOI 10.1016/j.wocn.2015.10.003
   Harrington J, 2008, J ACOUST SOC AM, V123, P2825, DOI 10.1121/1.2897042
   Harrington J, 2013, J ACOUST SOC AM, V134, P551, DOI 10.1121/1.4808328
   Hirata Y., 2004, Computer Assisted Language Learning, V17, P357, DOI 10.1080/0958822042000319629
   Holt LL, 2008, CURR DIR PSYCHOL SCI, V17, P42, DOI 10.1111/j.1467-8721.2008.00545.x
   Holt LL, 2006, J ACOUST SOC AM, V120, P2801, DOI 10.1121/1.2354071
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213
   Houde JF, 2002, J SPEECH LANG HEAR R, V45, P295, DOI 10.1044/1092-4388(2002/023)
   Iverson P., 2007, J ACOUST SOC AM, V121, P3072, DOI [10.1121/1.4781875, DOI 10.1121/1.4781875]
   Jia G, 2006, J ACOUST SOC AM, V119, P1118, DOI 10.1121/1.2151806
   JONGMAN A, 1989, LANG SPEECH, V32, P221
   Kartushina N, 2016, J PHONETICS, V57, P21, DOI 10.1016/j.wocn.2016.05.001
   Kartushina N, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01246
   KENT RD, 1973, PHONETICA, V28, P1, DOI 10.1159/000259442
   KENT RD, 1977, J ACOUST SOC AM, V62, pS101, DOI 10.1121/1.2016015
   KENT RD, 1974, J SPEECH HEAR RES, V17, P203, DOI 10.1044/jshr.1702.203
   Kewley-Port D., 2009, J ACOUST SOC AM, V125, P2756, DOI DOI 10.1121/1.4784637
   Kisler T, 2012, P DIG HUM 2012 HAMB, P30
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   LINDBLOM B., 1986, EXPT PHONOLOGY, P13
   Llompart M, 2019, BILING-LANG COGN, V22, P1085, DOI 10.1017/S1366728918000925
   Llompart M, 2017, J EXP PSYCHOL HUMAN, V43, P1040, DOI 10.1037/xhp0000383
   Lombard E., 1911, ANN MALADIES OREILLE, V37, P101
   Mattys SL, 2011, J MEM LANG, V65, P145, DOI 10.1016/j.jml.2011.04.004
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B, 2008, J EXP PSYCHOL HUMAN, V34, P1609, DOI 10.1037/a0011747
   Meyer AS, 2016, J MEM LANG, V89, P1, DOI 10.1016/j.jml.2016.03.002
   Mitterer H, 2008, COGNITION, V109, P168, DOI 10.1016/j.cognition.2008.08.002
   MOULTON WG, 1962, SOUNDS ENGLISH GERMA
   Nelson NR, 2017, J PHONETICS, V64, P51, DOI 10.1016/j.wocn.2017.01.008
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007
   Nooteboom SG, 2013, J MEM LANG, V69, P417, DOI 10.1016/j.jml.2013.04.006
   Pallier C, 1997, COGNITION, V64, pB9, DOI 10.1016/S0010-0277(97)00030-9
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Peperkamp S., 2011, P INTERSPEECH, V12, P161
   PORT RF, 1985, J PHONETICS, V13, P455, DOI 10.1016/S0095-4470(19)30797-1
   Reiterer S, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00334
   REPP BH, 1985, SPEECH COMMUN, V4, P105, DOI 10.1016/0167-6393(85)90039-1
   Rochet-Capellan A, 2011, J NEUROSCI, V31, P2657, DOI 10.1523/JNEUROSCI.6020-10.2011
   Rojczyk A., 2013, RES LANGUAGE, V11, P3, DOI [10.2478/v10015-012-0007-7, DOI 10.2478/V10015-012-0007-7]
   Rojczyk A., 2013, P 4 PRON 2 LANG LEAR, P66
   Schiel F., 1999, P ICPHS 1999 SAN FRA, P607
   Schmitz J, 2018, LANG COGN NEUROSCI, V33, P527, DOI 10.1080/23273798.2017.1390142
   Schouten M. E. H., 1977, J FINANC ECON, V5, P273
   Scott SK, 2009, NAT REV NEUROSCI, V10, P295, DOI 10.1038/nrn2603
   Sebastian-Galles N, 2005, TWENTY-FIRST CENTURY PSYCHOLINGUISTICS: FOUR CORNERSTONES, P279
   Sebastian-Galles N, 2005, J MEM LANG, V52, P240, DOI 10.1016/j.jml.2004.11.001
   Shockley K, 2004, PERCEPT PSYCHOPHYS, V66, P422, DOI 10.3758/BF03194890
   Simonchyk A, 2018, LANG SPEECH, V61, P522, DOI 10.1177/0023830918761490
   Smith BL, 2009, J PHONETICS, V37, P257, DOI 10.1016/j.wocn.2009.03.001
   Strange W, 2004, J ACOUST SOC AM, V115, P1791, DOI 10.1121/1.1687832
   Thorin J, 2018, J ACOUST SOC AM, V144, P92, DOI 10.1121/1.5044415
   van Heuven WJB, 2014, Q J EXP PSYCHOL, V67, P1176, DOI 10.1080/17470218.2013.850521
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Wong J. W. S., 2013, P INTERSPEECH, V14, P2113
   Zajac M, 2014, POZ STUD CONTEMP LIN, V50, P495, DOI 10.1515/psicl-2014-0025
NR 93
TC 6
Z9 6
U1 4
U2 7
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD SEP
PY 2019
VL 62
IS 3
BP 594
EP 622
DI 10.1177/0023830918803978
PG 29
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA IR5FM
UT WOS:000481458400009
PM 30319031
DA 2021-02-24
ER

PT J
AU Davidson, LS
   Geers, AE
   Uchanski, RM
   Firszt, JB
AF Davidson, Lisa S.
   Geers, Ann E.
   Uchanski, Rosalie M.
   Firszt, Jill B.
TI Effects of Early Acoustic Hearing on Speech Perception and Language for
   Pediatric Cochlear Implant Recipients
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SPOKEN LANGUAGE; NORMALLY-HEARING; DEAF-CHILDREN; AUDITORY EXPERIENCE;
   ASYMMETRIC HEARING; BIMODAL BENEFIT; RECOGNITION; AGE; SKILLS;
   STIMULATION
AB Purpose: The overall goal of the current study was to identify an optimal level and duration of acoustic experience that facilitates language development for pediatric cochlear implant (CI) recipients-specifically, to determine whether there is an optimal duration of hearing aid (HA) use and unaided threshold levels that should be considered before proceeding to bilateral CIs.
   Method: A total of 117 pediatric CI recipients (ages 5-9 years) were given speech perception and standardized tests of receptive vocabulary and language. The speech perception battery included tests of segmental perception (e.g., word recognition in quiet and noise, and vowels and consonants in quiet) and of suprasegmental perception (e.g., talker and stress discrimination, and emotion identification). Hierarchical regression analyses were used to determine the effects of speech perception on language scores, and the effects of residual hearing level (unaided pure tone average [PTA]) and duration of HA use on speech perception.
   Results: A continuum of residual hearing levels and the length of HA use were represented by calculating the unaided PTA of the ear with the longest duration of HA use for each child. All children wore 2 devices: Some wore bimodal devices, while others received their 2nd CI either simultaneously or sequentially, representing a wide range of HA use (0.03-9.05 years). Regression analyses indicate that suprasegmental perception contributes unique variance to receptive language scores and that both segmental and suprasegmental skills each contribute independently to receptive vocabulary scores. Also, analyses revealed an optimal duration of HA use for each of 3 ranges of hearing loss severity (with mean PTAs of 73, 92, and 111 dB HL) that maximizes suprasegmental perception.
   Conclusions: For children with the most profound losses, early bilateral CIs provide the greatest opportunity for developing good spoken language skills. For those with moderate-to severe losses, however, a prescribed period of bimodal use may be more advantageous for developing good spoken language skills.
C1 [Davidson, Lisa S.; Uchanski, Rosalie M.; Firszt, Jill B.] Washington Univ, Sch Med, St Louis, MO 63130 USA.
   [Geers, Ann E.] Univ Texas Dallas, Richardson, TX 75083 USA.
RP Davidson, LS (corresponding author), Washington Univ, Sch Med, St Louis, MO 63130 USA.
EM davidsonls@wustl.edu
OI Davidson, Lisa/0000-0003-2174-1230
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [RO1 DC012778]; Louis, Child's
   Voice-Chicago, Children's Hospital of Philadelphia, Children's Choice
   for Hearing and Talking-Sacramento; Talk-Seattle, Memphis Oral School
   for the Deaf, Moog Center for Deaf Education-St; Ohio Valley
   Voices-Cincinnati, Presbyterian Ear Institute-Albuquerque, University of
   Miami, University of Minnesota Children's Hospital-Minneapolis,
   University of Texas at Dallas;  [IRB ID 201305136]; NATIONAL INSTITUTE
   ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC012778, R01DC012778] Funding Source: NIH RePORTER
FX This research was approved by the Human Studies Committee at Washington
   University School of Medicine (IRB ID 201305136). This research was
   supported by National Institute on Deafness and Other Communication
   Disorders Grant RO1 DC012778, awarded to PI: Davidson. We thank Chris
   Brenner, Sarah Fessenden, Caroline Lartz, Marie Richter, and Kaitlyn
   Wenrich for their efforts in recruiting participants and in data
   collection, analysis, and management. Appreciation is expressed to the
   117 students and their families who graciously gave their time and
   effort to participate in this study. Appreciation is expressed to
   speech-language pathologists, audiologists, and deaf educators who
   conducted tests at the following sites: Arkansas Children's
   Hospital-Little Rock, Central Institute for the Deaf-St. Louis, Child's
   Voice-Chicago, Children's Hospital of Philadelphia, Children's Choice
   for Hearing and Talking-Sacramento, Hearts for Hearing-Oklahoma City,
   Listen and Talk-Seattle, Memphis Oral School for the Deaf, Moog Center
   for Deaf Education-St. Louis, Ohio Valley Voices-Cincinnati,
   Presbyterian Ear Institute-Albuquerque, University of Miami, University
   of Minnesota Children's Hospital-Minneapolis, University of Texas at
   Dallas, Vanderbilt University Medical Center-Nashville, and Weingarten
   Children's Center-Redwood City.
CR Bauer PW, 2006, ARCH OTOLARYNGOL, V132, P1133, DOI 10.1001/archotol.132.10.1133
   Blamey P, 2002, AUDIOL NEURO-OTOL, V7, P114, DOI 10.1159/000057659
   Blamey PJ, 2001, J SPEECH LANG HEAR R, V44, P264, DOI 10.1044/1092-4388(2001/022)
   Boons T, 2012, ARCH PEDIAT ADOL MED, V166, P28, DOI 10.1001/archpediatrics.2011.748
   BOOTHROYD A, 1994, VOLTA REV, V96, P151
   Boothroyd A, 2010, J SPEECH LANG HEAR R, V53, P531, DOI 10.1044/1092-4388(2009/08-0260)
   Bradlow AR, 1996, SPEECH COMMUN, V20, P255, DOI 10.1016/S0167-6393(96)00063-5
   Cadieux JH, 2013, OTOL NEUROTOL, V34, P408, DOI 10.1097/MAO.0b013e31827850b8
   Carlson ML, 2018, OTOL NEUROTOL, V39, pE12, DOI 10.1097/MAO.0000000000001632
   Carroll J, 2007, HEARING RES, V231, P42, DOI 10.1016/j.heares.2007.05.004
   Chatterjee M, 2015, HEARING RES, V322, P151, DOI 10.1016/j.heares.2014.10.003
   Ching TYC, 2018, INT J AUDIOL, V57, pS105, DOI 10.1080/14992027.2017.1385865
   Ching Teresa Y C, 2014, Cochlear Implants Int, V15 Suppl 1, pS43, DOI 10.1179/1467010014Z.000000000168
   Cohen J., 2003, APPL MULTIPLE REGRES, V3rd
   Davidson LS, 2006, EAR HEARING, V27, P493, DOI 10.1097/01.aud.0000234635.48564.ce
   Dettman SJ, 2016, OTOL NEUROTOL, V37, pE82, DOI 10.1097/MAO.0000000000000915
   Dhondt CMC, 2018, INT J PEDIATR OTORHI, V104, P170, DOI 10.1016/j.ijporl.2017.10.043
   Dillon CM, 2004, J SPEECH LANG HEAR R, V47, P1103, DOI 10.1044/1092-4388(2004/082)
   Dollaghan CA, 1999, J SPEECH LANG HEAR R, V42, P1432, DOI 10.1044/jslhr.4206.1432
   Dorman MF, 2008, AUDIOL NEURO-OTOL, V13, P105, DOI 10.1159/000111782
   Dorman MF, 2015, HEARING RES, V322, P107, DOI 10.1016/j.heares.2014.09.010
   Dowell Richard C, 2002, Cochlear Implants Int, V3, P1, DOI 10.1179/cim.2002.3.1.1
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   FERREIRA F, 1993, PSYCHOL REV, V100, P233, DOI 10.1037/0033-295X.100.2.233
   Gantz BJ, 2005, LARYNGOSCOPE, V115, P796, DOI 10.1097/01.MLG.0000157695.07536.D2
   Geers A, 2003, EAR HEARING, V24, p24S, DOI 10.1097/01.AUD.0000051687.99218.0F
   Geers AE, 2003, EAR HEARING, V24, p46S, DOI 10.1097/01.AUD.0000051689.57380.1B
   Geers Ann E, 2006, Adv Otorhinolaryngol, V64, P50, DOI 10.1159/000094644
   Geers AE, 2016, J SPEECH LANG HEAR R, V59, P155, DOI 10.1044/2015_JSLHR-H-14-0173
   Geers AE, 2013, EAR HEARING, V34, P562, DOI 10.1097/AUD.0b013e31828d2bd6
   Geers AE, 2013, J SPEECH LANG HEAR R, V56, P643, DOI 10.1044/1092-4388(2012/11-0347)
   Geers AE, 2009, J DEAF STUD DEAF EDU, V14, P371, DOI 10.1093/deafed/enn046
   Gervain J, 2008, LANG LINGUIST COMPAS, V2, P1149, DOI 10.1111/j.1749-818x.2008.00089.x
   Gifford RH, 2010, EAR HEARING, V31, P186, DOI 10.1097/AUD.0b013e3181c6b831
   Golub JS, 2012, OTOL NEUROTOL, V33, P147, DOI 10.1097/MAO.0b013e318241b6d3
   Gordon KA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00719
   Gordon KA, 2013, BRAIN, V136, P1609, DOI 10.1093/brain/awt052
   GRANT KW, 1987, J ACOUST SOC AM, V82, P1172, DOI 10.1121/1.395253
   Grieco-Calub TM, 2010, EAR HEARING, V31, P645, DOI 10.1097/AUD.0b013e3181e50a1d
   Illg A, 2014, OTOL NEUROTOL, V35, pE240, DOI 10.1097/MAO.0000000000000529
   Jusczyk PW, 1999, COGNITIVE PSYCHOL, V39, P159, DOI 10.1006/cogp.1999.0716
   Karl J. R., 1994, EFFECTS STIMULUS VAR
   KIRK KI, 1995, EAR HEARING, V16, P470, DOI 10.1097/00003446-199510000-00004
   Kong YY, 2005, J ACOUST SOC AM, V117, P1351, DOI 10.1121/1.1857526
   Leigh J, 2011, EAR HEARING, V32, P313, DOI 10.1097/AUD.0b013e3182008b1c
   Leigh JR, 2016, INT J AUDIOL, V55, pS9, DOI 10.3109/14992027.2016.1157268
   Litovsky RY, 2016, HEARING RES, V338, P76, DOI 10.1016/j.heares.2016.01.003
   Lovett RES, 2015, EAR HEARING, V36, P14, DOI 10.1097/AUD.0000000000000087
   Mastropieri D, 1999, DEV PSYCHOBIOL, V35, P204, DOI 10.1002/(SICI)1098-2302(199911)35:3<204::AID-DEV5>3.0.CO;2-V
   Moberly AC, 2016, OTOL NEUROTOL, V37, P24, DOI 10.1097/MAO.0000000000000871
   Mondain M, 2002, INT J PEDIATR OTORHI, V63, P91, DOI 10.1016/S0165-5876(01)00638-3
   Most T, 2007, J DEAF STUD DEAF EDU, V12, P350, DOI 10.1093/deafed/enm012
   Mowry SE, 2012, OTOLARYNG CLIN N AM, V45, P187, DOI 10.1016/j.otc.2011.09.001
   Nicholas JG, 2007, J SPEECH LANG HEAR R, V50, P1048, DOI 10.1044/1092-4388(2007/073)
   Nicholas JG, 2006, EAR HEARING, V27, P286, DOI 10.1097/01.aud.0000215973.76912.c6
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Nittrouer S, 2018, J SPEECH LANG HEAR R, V61, P2561, DOI 10.1044/2018_JSLHR-H-18-0047
   Nittrouer S, 2016, RES DEV DISABIL, V55, P143, DOI 10.1016/j.ridd.2016.03.020
   Nittrouer Susan, 2009, Trends Amplif, V13, P190, DOI 10.1177/1084713809346160
   O'Brien RM, 2007, QUAL QUANT, V41, P673, DOI 10.1007/s11135-006-9018-6
   OSBERGER MJ, 1991, AM J OTOL, V12, P105
   OSTERHOUT L, 1993, LANG COGNITIVE PROC, V8, P413, DOI 10.1080/01690969308407584
   PAPOUSEK M, 1990, INFANT BEHAV DEV, V13, P539, DOI 10.1016/0163-6383(90)90022-Z
   Peng SC, 2012, TRENDS AMPLIF, V16, P67, DOI 10.1177/1084713812451159
   Peters BR, 2010, LARYNGOSCOPE, V120, pS17, DOI 10.1002/lary.20859
   Polonenko MJ, 2015, AUDIOL NEURO-OTOL, V20, P13, DOI 10.1159/000380743
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Sampaio Andre L L, 2011, Int J Otolaryngol, V2011, P573968, DOI 10.1155/2011/573968
   Sarant J, 2014, EAR HEARING, V35, P396, DOI 10.1097/AUD.0000000000000022
   Sarant JZ, 2015, J SPEECH LANG HEAR R, V58, P1017, DOI 10.1044/2015_JSLHR-H-14-0075
   Schafer EC, 2011, INT J AUDIOL, V50, P871, DOI 10.3109/14992027.2011.622300
   Segal O, 2016, EAR HEARING, V37, P225, DOI 10.1097/AUD.0000000000000243
   Seidl A, 2008, J CHILD LANG, V35, P1, DOI 10.1017/S0305000907008215
   Seidl A, 2008, DEVELOPMENTAL SCI, V11, P596, DOI 10.1111/j.1467-7687.2008.00704.x
   Semel E.M., 2004, CLIN EVALUATION LANG
   Sheffield SW, 2016, EAR HEARING, V37, P282, DOI 10.1097/AUD.0000000000000281
   Sidtis D, 2012, INTEGR PSYCHOL BEHAV, V46, P146, DOI 10.1007/s12124-011-9177-4
   Singh L, 2004, J MEM LANG, V51, P173, DOI 10.1016/j.jml.2004.04.004
   Singh L, 2002, INFANCY, V3, P365, DOI 10.1207/S15327078IN0303_5
   Stoyneshka I, 2010, LANG COGNITIVE PROC, V25, P1265, DOI 10.1080/01690961003661192
   Strube MJ, 2003, EAR HEARING, V24, p15S, DOI 10.1097/01.AUD.0000051686.02809.18
   Svirsky MA, 2004, AUDIOL NEURO-OTOL, V9, P224, DOI 10.1159/000078392
   Swingley D, 2009, PHILOS T R SOC B, V364, P3617, DOI 10.1098/rstb.2009.0107
   Thiessen ED, 2007, LANG LEARN DEV, V3, P73, DOI 10.1080/15475440709337001
   Tomblin J Bruce, 2015, Ear Hear, V36 Suppl 1, p76S, DOI 10.1097/AUD.0000000000000219
   Wechsler D., 2003, WECHSLER INTELLIGENC
   Wechsler D., 2011, WECHSLER ABBREVIATED
   Wenrich KA, 2017, J AM ACAD AUDIOL, V28, P901, DOI 10.3766/jaaa.16105
   Werker JF, 2005, TRENDS COGN SCI, V9, P519, DOI 10.1016/j.tics.2005.09.003
   Zhang T, 2010, EAR HEARING, V31, P195, DOI 10.1097/AUD.0b013e3181c4758d
NR 90
TC 2
Z9 2
U1 0
U2 0
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD SEP
PY 2019
VL 62
IS 9
BP 3620
EP 3637
DI 10.1044/2019_JSLHR-H-18-0255
PG 18
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA IZ7CR
UT WOS:000487244000035
PM 31518517
OA Green Published
DA 2021-02-24
ER

PT J
AU Bouchon, C
   Toro, JM
AF Bouchon, Camillia
   Toro, Juan M.
TI Is the consonant bias specifically human? Long-Evans rats encode vowels
   better than consonants in words
SO ANIMAL COGNITION
LA English
DT Article
DE Lexical processing; Consonant bias; Comparative cognition; Operant
   conditioning
ID SPEECH-PERCEPTION; ENHANCED DISCRIMINABILITY; PHONETIC BOUNDARIES;
   PROCESSING EVIDENCE; LEXICAL SELECTION; LANGUAGE FACULTY; INFANTS;
   EVOLUTION; ENGLISH; IDENTIFICATION
AB In natural languages, vowels tend to convey structures (syntax, prosody) while consonants are more important lexically. The consonant bias, which is the tendency to rely more on consonants than on vowels to process words, is well attested in human adults and infants after the first year of life. Is the consonant bias based on evolutionarily ancient mechanisms, potentially present in other species? The current study investigated this issue in a species phylogenetically distant from humans: Long-Evans rats. During training, the animals were presented with four natural word-forms (e.g., mano, "hand"). We then compared their responses to novel words carrying either a consonant (pano) or a vowel change (meno). Results show that the animals were less disrupted by consonantal alterations than by vocalic alterations of words. That is, word recognition was more affected by the alteration of a vowel than a consonant. Together with previous findings in very young human infants, this reliance on vocalic information we observe in rats suggests that the emergence of the consonant bias may require a combination of vocal, cognitive and auditory skills that rodents do not seem to possess.
C1 [Bouchon, Camillia; Toro, Juan M.] Univ Pompeu Fabra, Ctr Brain & Cognit, Carrer Ramon Trias Fargas 25-27, Barcelona 08005, Spain.
   [Toro, Juan M.] ICREA, Barcelona, Spain.
   [Bouchon, Camillia] Univ Paris Nanterre, Lab Ethol Cognit Dev, Nanterre, France.
RP Bouchon, C (corresponding author), Univ Pompeu Fabra, Ctr Brain & Cognit, Carrer Ramon Trias Fargas 25-27, Barcelona 08005, Spain.; Bouchon, C (corresponding author), Univ Paris Nanterre, Lab Ethol Cognit Dev, Nanterre, France.
EM camillia.bouchon@gmail.com
RI Toro, Juan M./F-3933-2010
OI Toro, Juan M./0000-0002-5336-5658
FU European Union's ERC Starting Grant [312519]; Spanish Ministerio de
   Economia Grant [PSI2013-44992-P]; Horizon 2020 research and program
   Individual Fellowship MARIE SkLodowska-CURIE ACTIONS' Grant
   (H2020-MSCA-IF-2015) [707996]
FX This study was funded by funding from an European Union's ERC Starting
   Grant (Ref: 312519, BioCon) and Spanish Ministerio de Economia Grant
   (PSI2013-44992-P) awarded to Juan Manuel Toro, and the Horizon 2020
   research and program Individual Fellowship MARIE SkLodowska-CURIE
   ACTIONS' Grant (H2020-MSCA-IF-2015, Ref: 707996, Title: Speech-sound
   Processing in Infant Development and Evolution) awarded to Camillia
   Bouchon.
CR Acha J, 2010, LANG COGNITIVE PROC, V25, P423, DOI 10.1080/01690960903411666
   Dunabeitia JA, 2011, J EXP PSYCHOL LEARN, V37, P1143, DOI 10.1037/a0023577
   Aslin RN, 2012, CURR DIR PSYCHOL SCI, V21, P170, DOI 10.1177/0963721412436806
   Benavides-Varela S, 2012, P NATL ACAD SCI USA, V109, P17908, DOI 10.1073/pnas.1205413109
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   BERTONCINI J, 1988, J EXP PSYCHOL GEN, V117, P21, DOI 10.1037/0096-3445.117.1.21
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Bonatti LL, 2005, PSYCHOL SCI, V16, P451, DOI 10.1111/j.0956-7976.2005.01556.x
   Bonatti LL, 2007, PSYCHOL SCI, V18, P924, DOI 10.1111/j.1467-9280.2007.02002.x
   Bouchon C, 2017, M 42 ANN BOST U C LA
   Bouchon C, 2015, DEVELOPMENTAL SCI, V18, P587, DOI 10.1111/desc.12242
   Caramazza A, 2000, NATURE, V403, P428, DOI 10.1038/35000206
   Carreiras M, 2008, CEREB CORTEX, V18, P1727, DOI 10.1093/cercor/bhm202
   Carreiras M, 2007, NEUROSCI LETT, V419, P219, DOI 10.1016/j.neulet.2007.04.053
   Carreiras M, 2009, CEREB CORTEX, V19, P2659, DOI 10.1093/cercor/bhp019
   Carreiras M, 2009, J COGNITIVE NEUROSCI, V21, P275, DOI 10.1162/jocn.2008.21023
   Christiansen M. H., 2003, LANGUAGE EVOLUTION
   Creel SC, 2006, J MEM LANG, V54, P1, DOI 10.1016/j.jml.2005.09.003
   Cutler A, 2000, MEM COGNITION, V28, P746, DOI 10.3758/BF03198409
   CUTLER A, 1993, J PHONETICS, V21, P103, DOI 10.1016/S0095-4470(19)31323-3
   Cutler A, 1999, COMPREHENDING SPOKEN, P123
   de la Mora DM, 2013, COGNITION, V126, P307, DOI 10.1016/j.cognition.2012.09.015
   Delle Luche C, 2014, J MEM LANG, V72, P1, DOI 10.1016/j.jml.2013.12.001
   DOOLING RJ, 1995, J ACOUST SOC AM, V97, P1839, DOI 10.1121/1.412058
   Erickson ML, 2000, J ACOUST SOC AM, V108, P2980, DOI 10.1121/1.1322025
   Eriksson JL, 2006, BEHAV PROCESS, V73, P348, DOI 10.1016/j.beproc.2006.08.005
   Escudero P, 2016, COGNITIVE SCI, V40, P455, DOI 10.1111/cogs.12243
   Fitch WT, 2005, COGNITION, V97, P179, DOI 10.1016/j.cognition.2005.02.005
   Fitch WT, 2005, BIOL PHILOS, V20, P193, DOI 10.1007/s10539-005-5597-1
   FRY DB, 1962, LANG SPEECH, V5, P171, DOI 10.1177/002383096200500401
   Halle PA, 1996, INFANT BEHAV DEV, V19, P463, DOI 10.1016/S0163-6383(96)90007-7
   HALLE PA, 1994, INFANT BEHAV DEV, V17, P119, DOI 10.1016/0163-6383(94)90047-7
   Hauser MD, 2002, SCIENCE, V298, P1569, DOI 10.1126/science.298.5598.1569
   Havy M, 2014, LANG SPEECH, V57, P254, DOI 10.1177/0023830913507693
   Hochmann JR, 2018, INFANCY, V23, P136, DOI 10.1111/infa.12203
   Hochmann JR, 2011, DEVELOPMENTAL SCI, V14, P1445, DOI 10.1111/j.1467-7687.2011.01089.x
   Jackendoff R, 2005, COGNITION, V97, P211, DOI 10.1016/j.cognition.2005.04.006
   Keidel JL, 2007, PSYCHOL SCI, V18, P922, DOI 10.1111/j.1467-9280.2007.02001.x
   Kewley-Port D, 2007, J ACOUST SOC AM, V122, P2365, DOI 10.1121/1.2773986
   Kluender KR, 1998, J ACOUST SOC AM, V104, P3568, DOI 10.1121/1.423939
   KUHL PK, 1983, J ACOUST SOC AM, V73, P1003, DOI 10.1121/1.389148
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   KUHL PK, 1978, J ACOUST SOC AM, V63, P905, DOI 10.1121/1.381770
   KUHL PK, 1982, PERCEPT PSYCHOPHYS, V32, P542, DOI 10.3758/BF03204208
   KUHL PK, 1981, J ACOUST SOC AM, V70, P340, DOI 10.1121/1.386782
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Ladefoged P, 1993, COURSE PHONETICS
   Ladefoged P., 2001, VOWELS CONSONANTS IN
   Lameira AR, 2014, TRENDS COGN SCI, V18, P60, DOI 10.1016/j.tics.2013.10.013
   Lameira AR, 2017, NAT HUM BEHAV, V1, DOI 10.1038/s41562-016-0044
   Lee HW, 2001, J MEM LANG, V44, P189, DOI 10.1006/jmla.2000.2725
   Liberman AM, 1954, PSYCHOL MONOGR-GEN A, V68, P1, DOI 10.1037/h0093673
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   MacWhinney B., 2000, CHILDES PROJECT TOOL
   Maddieson I., 1984, PATTERNS SOUNDS
   Malmierca MS, 2003, INT REV NEUROBIOL, V56, P147, DOI 10.1016/S0074-7742(03)56005-6
   Mehler J, 2006, CORTEX, V42, P846, DOI 10.1016/S0010-9452(08)70427-1
   MORSE PA, 1975, PERCEPT PSYCHOPHYS, V17, P9, DOI 10.3758/BF03203991
   Murphy RA, 2008, SCIENCE, V319, P1849, DOI 10.1126/science.1151564
   Naatanen R, 2001, PSYCHOPHYSIOLOGY, V38, P1, DOI 10.1017/S0048577201000208
   Nazzi T, 2016, CURR DIR PSYCHOL SCI, V25, P291, DOI 10.1177/0963721416655786
   Nespor M., 2003, LINGUE LINGUAGGIO, V2, P203, DOI [10. 1418/ 10879, DOI 10.1418/10879]
   New B, 2014, LANG COGN NEUROSCI, V29, P147, DOI 10.1080/01690965.2012.735678
   New B, 2008, PSYCHOL SCI, V19, P1223, DOI 10.1111/j.1467-9280.2008.02228.x
   Newport EL, 2004, COGNITIVE PSYCHOL, V49, P85, DOI 10.1016/j.cogpsych.2003.12.002
   Nishibayashi LL, 2016, COGNITION, V155, P188, DOI 10.1016/j.cognition.2016.07.003
   Owren MJ, 2006, J ACOUST SOC AM, V119, P1727, DOI 10.1121/1.2161431
   Perez CA, 2013, CEREB CORTEX, V23, P670, DOI 10.1093/cercor/bhs045
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   Poltrock S, 2015, J EXP CHILD PSYCHOL, V131, P135, DOI 10.1016/j.jecp.2014.11.011
   Pons F, 2006, J EXP PSYCHOL ANIM B, V32, P97, DOI 10.1037/0097-7403.32.1.97
   Reed P, 2003, J EXP ANAL BEHAV, V80, P205, DOI 10.1901/jeab.2003.80-205
   Repp BH, 1984, ADV BASIC RES PRACTI, P243
   Rescorla R.A., 1972, CLASSICAL CONDITIONI, V2, P64, DOI DOI 10.1101/GR.110528.110
   Saffran JR, 1996, J MEM LANG, V35, P606, DOI 10.1006/jmla.1996.0032
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Sharp DJ, 2005, BRAIN LANG, V92, P309, DOI 10.1016/j.bandl.2004.07.002
   SINNOTT JM, 1991, J ACOUST SOC AM, V89, P2421, DOI 10.1121/1.400974
   SINNOTT JM, 1989, J ACOUST SOC AM, V86, P557, DOI 10.1121/1.398235
   Soares AP, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0088580
   STEVENS KN, 1978, J ACOUST SOC AM, V64, P1358, DOI 10.1121/1.382102
   Swingley D, 2005, DEVELOPMENTAL SCI, V8, P432, DOI 10.1111/j.1467-7687.2005.00432.x
   Tincoff R, 1999, PSYCHOL SCI, V10, P172, DOI 10.1111/1467-9280.00127
   Tincoff R, 2012, INFANCY, V17, P432, DOI 10.1111/j.1532-7078.2011.00084.x
   Toro JM, 2016, COGNITION, V146, P1, DOI 10.1016/j.cognition.2015.09.006
   Tsuji S, 2014, DEV PSYCHOBIOL, V56, P179, DOI 10.1002/dev.21179
   vanOoijen B, 1996, MEM COGNITION, V24, P573, DOI 10.3758/BF03201084
   Vergara-Martinez M, 2011, BRAIN LANG, V118, P105, DOI 10.1016/j.bandl.2010.09.006
   Vihman MM, 2004, J MEM LANG, V50, P336, DOI 10.1016/j.jml.2003.11.004
   WATERS RS, 1976, PERCEPT PSYCHOPHYS, V19, P285, DOI 10.3758/BF03204232
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wich SA, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036180
   Yip MJ, 2006, TRENDS COGN SCI, V10, P442, DOI 10.1016/j.tics.2006.08.001
   Zesiger P, 2012, INFANCY, V17, P591, DOI 10.1111/j.1532-7078.2011.00111.x
NR 95
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1435-9448
EI 1435-9456
J9 ANIM COGN
JI Anim. Cogn.
PD SEP
PY 2019
VL 22
IS 5
BP 839
EP 850
DI 10.1007/s10071-019-01280-3
PG 12
WC Behavioral Sciences; Zoology
SC Behavioral Sciences; Zoology
GA IQ2IB
UT WOS:000480571100020
PM 31222546
DA 2021-02-24
ER

PT J
AU Tamura, S
   Ito, K
   Hirose, N
   Mori, S
AF Tamura, Shunsuke
   Ito, Kazuhito
   Hirose, Nobuyuki
   Mori, Shuji
TI Precision of voicing perceptual identification is altered in association
   with voice-onset time production changes
SO EXPERIMENTAL BRAIN RESEARCH
LA English
DT Article
DE Voicing production; Voicing perception; Voice-onset time;
   Cross-categorical auditory feedback
ID SPEECH-PERCEPTION; SENSORIMOTOR ADAPTATION; MOTOR REPRESENTATIONS;
   BROCAS AREA; DISCRIMINATION; COMPENSATION; PLASTICITY; APHASIA; SYSTEM;
   MAPS
AB There is ample evidence that motor learning changes the function of perceptual systems. Previous studies examining the interactions between speech production and perception have shown that the discrimination of phonetic contrasts characterized by the difference in articulatory place features is altered following their production changes caused by the perturbation of auditory feedback. The present study focused on a voiced-voiceless contrast in stop consonants, which is characterized by a temporal articulatory parameter, voice-onset time (VOT). In the experiment, we manipulated the participants' motor functions concerning VOT using a cross-categorical auditory feedback (CAF) paradigm (Mitsuya et al. in J Acoust Soc Am 135:2986-2994, 2014), in which a pre-recorded syllable sound starting with a voiced stop consonant (/da/) was fed back simultaneously with the participant's utterance of a voiceless stop consonant (/ta/), and vice versa. The VOT difference between /da/ and /ta/ productions was increased by the CAF, which is consistent with the result of Mitsuya's study. In addition, we conducted perceptual identification tasks of /da/-/ta/ continuum stimuli varying in VOT before and after the CAF task, and found that the identification function became sharper after as compared to before the CAF task. A significant positive correlation between such production and perception changes was also found. On the basis of these results, we consider that the change in motor function concerning VOT affected voiced-voiceless perceptual processing. The present study is the first to show the involvement of the speech production system in the perception of phonetic contrasts characterized by articulatory temporal features.
C1 [Tamura, Shunsuke] Kyushu Univ, Grad Sch Informat Sci & Elect Engn, Dept Informat, Nishi Ku, 744 Motooka, Fukuoka, Fukuoka 8190395, Japan.
   [Ito, Kazuhito] Tohoku Gakuin Univ, Fac Liberal Arts, Dept Informat Sci, Izumi Ku, 2-1-1 Tenjinzawa, Sendai, Miyagi 9813193, Japan.
   [Hirose, Nobuyuki; Mori, Shuji] Kyushu Univ, Fac Informat Sci & Elect Engn, Dept Informat, Nishi Ku, 744 Motooka, Fukuoka, Fukuoka 8190395, Japan.
RP Tamura, S (corresponding author), Kyushu Univ, Grad Sch Informat Sci & Elect Engn, Dept Informat, Nishi Ku, 744 Motooka, Fukuoka, Fukuoka 8190395, Japan.
EM tamuras@cog.inf.kyushu-u.ac.jp
FU JSPSMinistry of Education, Culture, Sports, Science and Technology,
   Japan (MEXT)Japan Society for the Promotion of Science [JP18J10654,
   JP25240023]
FX This research was supported by JSPS KAKENHI Grant numbers JP18J10654,
   JP25240023.
CR Ackermann H, 1997, BRAIN LANG, V60, P323, DOI 10.1006/brln.1997.1826
   BASSO A, 1977, CORTEX, V13, P85, DOI 10.1016/S0010-9452(77)80057-9
   BLUMSTEIN SE, 1980, BRAIN LANG, V9, P153, DOI 10.1016/0093-934X(80)90137-6
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Chevillet MA, 2013, J NEUROSCI, V33, P5208, DOI 10.1523/JNEUROSCI.1870-12.2013
   Devlin JT, 2009, CURR BIOL, V19, pR198, DOI 10.1016/j.cub.2009.01.005
   Diehl RL, 2008, PHILOS T R SOC B, V363, P965, DOI 10.1098/rstb.2007.2153
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   Evans S, 2015, CEREB CORTEX, V25, P4772, DOI 10.1093/cercor/bhv136
   Hickok G, 2011, BRAIN LANG, V119, P214, DOI 10.1016/j.bandl.2011.08.001
   Holt LL, 2004, J ACOUST SOC AM, V116, P1763, DOI 10.1121/1.1778838
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213
   Houde JF, 2002, J SPEECH LANG HEAR R, V45, P295, DOI 10.1044/1092-4388(2002/023)
   IVRY RB, 1993, ATTENTION PERFORM, V14, P771
   Jones JA, 2000, J ACOUST SOC AM, V108, P1246, DOI 10.1121/1.1288414
   Jones JA, 2005, CURR BIOL, V15, P1768, DOI 10.1016/j.cub.2005.08.063
   KLATT DH, 1980, J ACOUST SOC AM, V67, P971, DOI 10.1121/1.383940
   Lametti DR, 2014, J NEUROSCI, V34, P10339, DOI 10.1523/JNEUROSCI.0108-14.2014
   Lee YS, 2012, J NEUROSCI, V32, P3942, DOI 10.1523/JNEUROSCI.3814-11.2012
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   MILLER JL, 1983, J ACOUST SOC AM, V73, P2124, DOI 10.1121/1.389455
   Mitsuya T, 2014, J ACOUST SOC AM, V135, P2986, DOI 10.1121/1.4871359
   Ostry DJ, 2016, TRENDS NEUROSCI, V39, P114, DOI 10.1016/j.tins.2015.12.006
   Patri JF, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005942
   Perkell JS, 2004, J ACOUST SOC AM, V116, P2338, DOI 10.1121/1.1787524
   PISONI DB, 1977, J ACOUST SOC AM, V61, P1352, DOI 10.1121/1.381409
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Rauschecker JP, 2011, HEARING RES, V271, P16, DOI 10.1016/j.heares.2010.09.001
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   SAMUEL AG, 1982, PERCEPT PSYCHOPHYS, V31, P307, DOI 10.3758/BF03202653
   Schomers MR, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00435
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   Shiller DM, 2009, J ACOUST SOC AM, V125, P1103, DOI 10.1121/1.3058638
   Sininger YS, 2012, LATERALITY, V17, P129, DOI 10.1080/1357650X.2010.541464
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Steinschneider M, 2005, CEREB CORTEX, V15, P170, DOI 10.1093/cercor/bhh120
   Stevens K., 1967, MODELS PERCEPTION SP, P88
   STEVENS KN, 1989, J PHONETICS, V17, P3, DOI 10.1016/S0095-4470(19)31520-7
   Tamura S, 2018, J SPEECH LANG HEAR R, V61, P789, DOI 10.1044/2017_JSLHR-H-17-0131
   Villacorta VM, 2007, J ACOUST SOC AM, V122, P2306, DOI 10.1121/1.2773966
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
NR 43
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0014-4819
EI 1432-1106
J9 EXP BRAIN RES
JI Exp. Brain Res.
PD SEP
PY 2019
VL 237
IS 9
BP 2197
EP 2204
DI 10.1007/s00221-019-05584-1
PG 8
WC Neurosciences
SC Neurosciences & Neurology
GA IN4UL
UT WOS:000478671900006
PM 31218370
DA 2021-02-24
ER

PT J
AU Wiener, S
   Lee, CY
   Tao, L
AF Wiener, Seth
   Lee, Chao-Yang
   Tao, Liang
TI Statistical Regularities Affect the Perception of Second Language
   Speech: Evidence From Adult Classroom Learners of Mandarin Chinese
SO LANGUAGE LEARNING
LA English
DT Article
DE speech perception; Mandarin Chinese; gating task; statistical learning;
   lexical tone
ID NEIGHBORHOOD ACTIVATION; WORD RECOGNITION; LEXICAL ACCESS; SPEAKER
   NORMALIZATION; HOMOPHONE DENSITY; NATIVE ENGLISH; SPOKEN WORDS; TONES;
   IDENTIFICATION; LISTENERS
AB This study investigated how adult second language (L2) learners of Mandarin Chinese use knowledge of phonological and lexical statistical regularities when acoustic information is insufficient for word recognition. A gating task was used to test intermediate L2 learners at two time points across a semester of classroom learning. Native Mandarin speakers (tested once) served as a control group. Mixed-effects modeling revealed that upon hearing truncated speech, L2 learners, like native speakers, identified high token frequency syllable-tone combinations more accurately than low token frequency syllable-tone combinations. Error analysis of correct syllable/incorrect tone responses revealed that native speakers made specific probability-based errors. L2 learners primarily demonstrated more acoustic-based errors but exhibited a trend toward greater probability-based errors during the second test. These findings are interpreted in light of L2 speech learning models that emphasize a statistical learning mechanism. Open Practices This article has been awarded an Open Materials badge. All materials are publicly accessible via the Open Science Framework at . Learn more about the Open Practices badges from the Center for Open Science: .
C1 [Wiener, Seth] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Lee, Chao-Yang; Tao, Liang] Ohio Univ, Athens, OH 45701 USA.
RP Wiener, S (corresponding author), Carnegie Mellon Univ, Dept Modern Languages, 160 Baker Hall,5000 Forbes Ave, Pittsburgh, PA 15213 USA.
EM sethw1@cmu.edu
OI Lee, Chao-Yang/0000-0002-4593-7142; Wiener, Seth/0000-0002-7383-3682
CR Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bradlow AR, 1999, J ACOUST SOC AM, V106, P2074, DOI 10.1121/1.427952
   Bybee J., 2001, PHONOLOGY LANGUAGE U, DOI [10.1017/CBO9780511612886, DOI 10.1017/CBO9780511612886, 10.1017/CB09780511612886]
   Bybee Joan, 2010, LANGUAGE USAGE COGNI, DOI [10.1017/CBO9780511750526, DOI 10.1017/CBO9780511750526]
   Bybee Joan, 2001, FREQUENCY EMERGENCE, DOI [10.1075/tsl.45.17byb, DOI 10.1075/TSL.45, 10.1075/tsl.45]
   Cai Q, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010729
   Chandrasekaran B, 2010, J ACOUST SOC AM, V128, P456, DOI 10.1121/1.3445785
   Chen HC, 2009, LANG COGNITIVE PROC, V24, P967, DOI 10.1080/01690960902804515
   Chen JY, 2002, J MEM LANG, V46, P751, DOI 10.1006/jmla.2001.2825
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Colantoni L., 2015, 2 LANGUAGE SPEECH
   COTTON S, 1984, PERCEPT PSYCHOPHYS, V35, P41, DOI 10.3758/BF03205923
   Cutler A, 2012, NATIVE LISTENING LAN
   Dahan D., 2006, HDB PSYCHOLINGUISTIC, P249, DOI DOI 10.1016/B978-012369374-7/50009-2
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Duanmu S., 2007, PHONOLOGY STANDARD C
   Duanmu S., 2009, SYLLABLE STRUCTURE L
   Ellis N. C., 2015, HDB LANGUAGE EMERGEN, P163, DOI DOI 10.1002/9781118346136.CH7
   Ellis N. C, 2002, STUDIES 2 LANGUAGE A, V24, P143, DOI DOI 10.1017/S0272263102002024
   Ellis NC, 2013, LANG LEARN, V63, P25, DOI 10.1111/j.1467-9922.2012.00736.x
   Escudero P., 2009, PHONOLOGY PERCEPTION, V15, P152
   ESCUDERO P., 2005, THESIS, P348
   Escudero P, 2014, COGNITION, V133, P408, DOI 10.1016/j.cognition.2014.07.002
   Escudero P, 2011, J ACOUST SOC AM, V130, pEL206, DOI 10.1121/1.3629144
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege JE, 2003, SPEECH COMMUN, V40, P467, DOI 10.1016/S0167-6393(02)00128-0
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Gottfried TL, 1997, J PHONETICS, V25, P207, DOI 10.1006/jpho.1997.0042
   Green P, 2016, METHODS ECOL EVOL, V7, P493, DOI 10.1111/2041-210X.12504
   GROSJEAN F, 1980, PERCEPT PSYCHOPHYS, V28, P267, DOI 10.3758/BF03204386
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Hao YC, 2018, SPEECH COMMUN, V97, P32, DOI 10.1016/j.specom.2017.12.015
   Hao YC, 2018, LANG SPEECH, V61, P135, DOI 10.1177/0023830917717759
   Hao YC, 2012, J PHONETICS, V40, P269, DOI 10.1016/j.wocn.2011.11.001
   HAXBY JV, 1993, BEHAV RES METH INSTR, V25, P400, DOI 10.3758/BF03204531
   Hayes-Harb R, 2008, SECOND LANG RES, V24, P5, DOI 10.1177/0267658307082980
   Hayes-Harb R, 2007, SECOND LANG RES, V23, P65, DOI 10.1177/0267658307071601
   Howie J.M., 1976, ACOUSTICAL STUDIES M
   Idemaru K, 2014, J EXP PSYCHOL HUMAN, V40, P1009, DOI 10.1037/a0035269
   Idemaru K, 2011, J EXP PSYCHOL HUMAN, V37, P1939, DOI 10.1037/a0025641
   Imai S, 2005, J ACOUST SOC AM, V117, P896, DOI 10.1121/1.1823291
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   LEATHER J, 1983, J PHONETICS, V11, P373, DOI 10.1016/S0095-4470(19)30836-8
   Lee C.-Y., 2013, SPEECH LANGUAGE HEAR, V16, P1, DOI DOI 10.1179/2050571X12Z.0000000003
   Lee CY, 2010, SPEECH COMMUN, V52, P900, DOI 10.1016/j.specom.2010.01.004
   Lee CY, 2009, J PHONETICS, V37, P1, DOI 10.1016/j.wocn.2008.08.001
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Li P, 1996, J MEM LANG, V35, P757, DOI 10.1006/jmla.1996.0039
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   MacKay IRA, 2001, PHONETICA, V58, P103, DOI 10.1159/000028490
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   McClelland JL, 2006, TRENDS COGN SCI, V10, P363, DOI 10.1016/j.tics.2006.06.007
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   Meador D, 2000, BILING-LANG COGN, V3, P55, DOI DOI 10.1017/S1366728900000134
   Moore CB, 1997, J ACOUST SOC AM, V102, P1864, DOI 10.1121/1.420092
   Myers J., 2012, METHODOLOGICAL ANAL, P155, DOI DOI 10.1075/BCT.47.09MYE
   Myers J., 2006, REPRESENTATION PROCE, P169, DOI DOI 10.1093/ACPROF:OSO/9780199228911.001.0001
   Myers J, 2010, MENT LEX, V5, P421, DOI 10.1075/ml.5.3.09mye
   Newport EL, 2016, LANG COGN, V8, P447, DOI 10.1017/langcog.2016.20
   Packard J. L., 2000, MORPHOLOGY CHINESE L, DOI [10.1017/CBO9780511486821, DOI 10.1017/CBO9780511486821]
   Packard JL, 1999, BRAIN LANG, V68, P89, DOI 10.1006/brln.1999.2102
   Pelzl E, 2019, STUD SECOND LANG ACQ, V41, P59, DOI 10.1017/S0272263117000444
   Perrachione TK, 2011, J ACOUST SOC AM, V130, P461, DOI 10.1121/1.3593366
   Romberg AR, 2010, WIRES COGN SCI, V1, P906, DOI 10.1002/wcs.78
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Samuel AG, 2011, ANNU REV PSYCHOL, V62, P49, DOI 10.1146/annurev.psych.121208.131643
   Shen J, 2013, J ACOUST SOC AM, V133, P3016, DOI 10.1121/1.4795775
   Shen X. S., 1989, J CHINESE LANGUAGE T, V24, P27
   SHEN XNS, 1991, LANG SPEECH, V34, P145, DOI 10.1177/002383099103400202
   So CK, 2014, STUD SECOND LANG ACQ, V36, P195, DOI 10.1017/S0272263114000047
   So CK, 2010, LANG SPEECH, V53, P273, DOI 10.1177/0023830909357156
   STRANGE W, 1995, SPEECH PERCEPTION LI
   Tao Hongyin, 2015, OXFORD HDB CHINESE L, P336
   van Leussen JW, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01000
   Vitevitch MS, 1999, J MEM LANG, V40, P374, DOI 10.1006/jmla.1998.2618
   Vitevitch MS, 1998, PSYCHOL SCI, V9, P325, DOI 10.1111/1467-9280.00064
   Vitevitch MS, 1999, BRAIN LANG, V68, P306, DOI 10.1006/brln.1999.2116
   Wang H. S., 1998, STUDIA LINGUISTICA S, P259
   Wang WN, 2012, NEUROSCI LETT, V516, P67, DOI 10.1016/j.neulet.2012.03.059
   Wang Y, 2001, BRAIN LANG, V78, P332, DOI 10.1006/brln.2001.2474
   Wang Y, 1999, J ACOUST SOC AM, V106, P3649, DOI 10.1121/1.428217
   Wanrooij K, 2013, J PHONETICS, V41, P307, DOI 10.1016/j.wocn.2013.03.005
   Wayland RP, 2004, LANG LEARN, V54, P681, DOI 10.1111/j.1467-9922.2004.00283.x
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0
   Wiener S., 2016, P 8 INT C SPEECH PRO, P538, DOI DOI 10.21437/SPEECHPROSODY.2016-110
   Wiener S, 2017, INTERSPEECH, P1765, DOI 10.21437/Interspeech.2017-289
   Wiener S, 2018, LANG SPEECH, V61, P632, DOI 10.1177/0023830918761762
   Wiener S, 2016, J PHONETICS, V56, P38, DOI 10.1016/j.wocn.2016.02.001
   Wiener S, 2016, LANG SPEECH, V59, P59, DOI 10.1177/0023830915578000
   Wiener S, 2015, LANG COGN NEUROSCI, V30, P1048, DOI 10.1080/23273798.2014.946934
   Wong PCM, 2007, APPL PSYCHOLINGUIST, V28, P565, DOI 10.1017/S0142716407070312
   Yang C., 2016, ACQUISITION L2 MANDA, DOI [10.1075/bpa.1, DOI 10.1075/BPA.1]
   YANG C, 2010, J CHINESE LANG TEACH, V45, P7
   Ye Y, 1999, LANG COGNITIVE PROC, V14, P609, DOI 10.1080/016909699386202
   You WP, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0046595
   Zhou XL, 1995, LANG COGNITIVE PROC, V10, P545, DOI 10.1080/01690969508407114
   ZHOU XL, 1994, LANG COGNITIVE PROC, V9, P393, DOI 10.1080/01690969408402125
   Zuur AF, 2010, METHODS ECOL EVOL, V1, P3, DOI 10.1111/j.2041-210X.2009.00001.x
NR 104
TC 4
Z9 4
U1 0
U2 31
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0023-8333
EI 1467-9922
J9 LANG LEARN
JI Lang. Learn.
PD SEP
PY 2019
VL 69
IS 3
BP 527
EP 558
DI 10.1111/lang.12342
PG 32
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA IN7ZH
UT WOS:000478899900001
DA 2021-02-24
ER

PT J
AU Kobald, SO
   Wascher, E
   Heppner, H
   Getzmann, S
AF Kobald, S. Oliver
   Wascher, Edmund
   Heppner, Holger
   Getzmann, Stephan
TI Eye blinks are related to auditory information processing: evidence from
   a complex speech perception task
SO PSYCHOLOGICAL RESEARCH-PSYCHOLOGISCHE FORSCHUNG
LA English
DT Article
ID MICROSACCADIC RESPONSES; RATES CORRELATE; DOPAMINE; STARTLE; INHIBITION;
   MODULATION; P3
AB There is increasing evidence that spontaneous eye blinks are related to mental states and can predict performance in certain tasks because of their relation to dopaminergic activity. Moreover, it has been shown that eye blinks while performing visual tasks are preferably executed not before all available information and even the manual response has been processed and given. Thus, blinks provide a natural endpoint of visual information processing. In the present study, we investigate to what degree such functional assignment of eye blinks also applies when only auditory stimuli are processed. For that, we present blink analyses on data of an auditory stock price monitoring task to examine the timing and frequency of blinks relative to the temporal dynamics of the task and different kinds of available cues. Our results show that blinks are meaningfully rather than randomly paced, although no visual information has to be processed. Blinks are significantly accelerated if a no-go trial is indicated which made all the subsequent information irrelevant. Although the stimuli were exclusively auditory, blinks were mostly inhibited during stimulus presentation. Taken together, blinks depend on the information being presented and mark a distinct point in time at which this information is conclusively processed. These findings deliver further support for the usefulness of eyeblink analyses, independently of the modality of the information being processed.
C1 [Kobald, S. Oliver; Wascher, Edmund; Getzmann, Stephan] Leibniz Res Ctr Working Environm & Human Factors, Ardeystr 67, D-44139 Dortmund, Germany.
   [Heppner, Holger] Bielefeld Univ, Univ Str 25, D-33615 Bielefeld, Germany.
RP Kobald, SO (corresponding author), Leibniz Res Ctr Working Environm & Human Factors, Ardeystr 67, D-44139 Dortmund, Germany.
EM kobald@ifado.de
RI Wascher, Edmund/AAQ-1023-2020
OI Wascher, Edmund/0000-0003-3616-9767; Heppner,
   Holger/0000-0002-0434-9571; Getzmann, Stephan/0000-0002-6382-0183;
   Kobald, Sven Oliver/0000-0002-4294-7601
FU Deutsche ForschungsgemeinschaftGerman Research Foundation (DFG) [DFG GE
   1920/3-1]
FX The original study was funded by the Deutsche Forschungsgemeinschaft
   (DFG GE 1920/3-1).
CR Adam AR, 2009, INT J PSYCHOPHYSIOL, V74, P266, DOI 10.1016/j.ijpsycho.2009.09.011
   Boksem MAS, 2008, BRAIN RES REV, V59, P125, DOI 10.1016/j.brainresrev.2008.07.001
   Bonneh YS, 2016, J VISION, V16, DOI 10.1167/16.7.1
   BRADLEY MM, 1991, PSYCHOPHYSIOLOGY, V28, P285, DOI 10.1111/j.1469-8986.1991.tb02196.x
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Colzato LS, 2009, EXP BRAIN RES, V196, P467, DOI 10.1007/s00221-009-1862-x
   Darwin CJ, 2008, PHILOS T R SOC B, V363, P1011, DOI 10.1098/rstb.2007.2156
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Doughty Michael J, 2006, Eye Contact Lens, V32, P294, DOI 10.1097/01.icl.0000224359.32709.4d
   Fitzpatrick E, 2012, J NEUROL, V259, P739, DOI 10.1007/s00415-011-6261-0
   Fukuda K, 2001, INT J PSYCHOPHYSIOL, V40, P239, DOI 10.1016/S0167-8760(00)00192-6
   Getzmann S, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00413
   Getzmann S, 2011, BRAIN RES, V1415, P8, DOI 10.1016/j.brainres.2011.08.001
   Groman SM, 2014, J NEUROSCI, V34, P14443, DOI 10.1523/JNEUROSCI.3037-14.2014
   KARSON CN, 1983, BRAIN, V106, P643, DOI 10.1093/brain/106.3.643
   Lipp OV, 1997, PSYCHOPHYSIOLOGY, V34, P340, DOI 10.1111/j.1469-8986.1997.tb02404.x
   Lipp OV, 2001, BIOL PSYCHOL, V58, P89, DOI 10.1016/S0301-0511(01)00109-0
   MACKERT A, 1991, SCHIZOPHR RES, V4, P41, DOI 10.1016/0920-9964(91)90008-F
   Meyberg S, 2015, NEUROIMAGE, V104, P79, DOI 10.1016/j.neuroimage.2014.09.065
   Nakano T, 2015, NEUROSCI RES, V96, P54, DOI 10.1016/j.neures.2015.02.010
   Nakano T, 2013, P NATL ACAD SCI USA, V110, P702, DOI 10.1073/pnas.1214804110
   Nakano T, 2009, P ROY SOC B-BIOL SCI, V276, P3635, DOI 10.1098/rspb.2009.0828
   Oh J, 2012, HUM MOVEMENT SCI, V31, P1353, DOI 10.1016/j.humov.2012.06.003
   ORCHARD L N, 1991, Integrative Physiological and Behavioral Science, V26, P108, DOI 10.1007/BF02691032
   Pannasch S, 2001, VISION RES, V41, P3345, DOI 10.1016/S0042-6989(01)00207-3
   Rolfs M, 2008, J VISION, V8, DOI 10.1167/8.11.5
   Sarter M, 2006, BRAIN RES REV, V51, P145, DOI 10.1016/j.brainresrev.2005.11.002
   Shin YS, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141242
   Slagter HA, 2015, NEUROPSYCHOLOGIA, V71, P126, DOI 10.1016/j.neuropsychologia.2015.03.028
   Sweeney DF, 2013, EXP EYE RES, V117, P28, DOI 10.1016/j.exer.2013.08.010
   Taylor JR, 1999, EXP NEUROL, V158, P214, DOI 10.1006/exnr.1999.7093
   Valsecchi M, 2009, PSYCHOL RES-PSYCH FO, V73, P23, DOI 10.1007/s00426-008-0142-x
   van Bochove ME, 2013, COGN AFFECT BEHAV NE, V13, P346, DOI 10.3758/s13415-012-0138-2
   van der Post J, 2004, J PSYCHOPHARMACOL, V18, P109, DOI 10.1177/0269881104042832
   VERLEGER R, 1991, ELECTROEN CLIN NEURO, V78, P240, DOI 10.1016/0013-4694(91)90039-7
   Wascher E, 2016, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00711
   Wascher E, 2015, EXCLI J, V14, P1207, DOI 10.17179/excli2015-696
   Wascher E, 2014, INT J PSYCHOPHYSIOL, V91, P3, DOI 10.1016/j.ijpsycho.2013.10.006
   Widmann A, 2014, J NEUROSCI, V34, P11152, DOI 10.1523/JNEUROSCI.1568-14.2014
   Zhang T, 2016, BRAIN COGNITION, V105, P95, DOI 10.1016/j.bandc.2016.04.003
   Zhang T, 2015, INT J PSYCHOPHYSIOL, V96, P155, DOI 10.1016/j.ijpsycho.2015.04.010
NR 42
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 0340-0727
EI 1430-2772
J9 PSYCHOL RES-PSYCH FO
JI Psychol. Res.-Psychol. Forsch.
PD SEP
PY 2019
VL 83
IS 6
BP 1281
EP 1291
DI 10.1007/s00426-017-0952-9
PG 11
WC Psychology, Experimental
SC Psychology
GA IJ5YX
UT WOS:000475980400015
PM 29353461
DA 2021-02-24
ER

PT J
AU Singh, L
   Seet, SK
AF Singh, Leher
   Seet, See Kim
TI The impact of foreign language caregiving on native language acquisition
SO JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY
LA English
DT Article
DE Language acquisition; Critical periods; Language replacement
ID CRITICAL-PERIOD; SPEECH-PERCEPTION; EARLY-CHILDHOOD; EYE-MOVEMENTS; AGE;
   SENSITIVITY; MORPHOLOGY; KNOWLEDGE; FIXATION; ADOPTEES
AB There is increasing interest in the influence of language input during children's early years. Over the first 3 years of life, children are highly sensitive to the quantity and quality of language input they receive. The focus of this study was on whether learning a different language in the early years affects the acquisition of English over the longer term. In this study, we investigated effects of foreign language (Hokkien) caregiving on the eventual acquisition of English as well as on memory traces of Hokkien. We sampled individuals who received foreign language caregiving in Hokkien during their early years either predominantly or in addition to English. Our control group had lifetime primary exposure to English. We compared the Hokkien- and English-only reared groups on phonological, semantic, and grammatical knowledge in English. We also compared the groups on memories for Hokkien tonal phonology and vocabulary. Overall, there were no statistically significant differences in performance in English tasks between groups, yet the Hokkien-reared group demonstrated selective learning advantages in reacquiring Hokkien tonal contrasts. Findings are discussed with reference to the effects of timing and language input on later language proficiency. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Singh, Leher; Seet, See Kim] Natl Univ Singapore, Dept Psychol, Singapore 117570, Singapore.
RP Singh, L (corresponding author), Natl Univ Singapore, Dept Psychol, Singapore 117570, Singapore.
EM leher.singh@gmail.com
FU National University of Singapore Office of Deputy President (Research &
   Technology) fund
FX We are grateful to Yvonne Lam and Agnes Lim for assistance with
   methodological setup and assistance with recruiting and testing
   participants. We acknowledge a National University of Singapore Office
   of Deputy President (Research & Technology) fund (LS) and a thesis
   support fund (SKS) for providing funds for this research.
CR Abrahamsson N, 2009, LANG LEARN, V59, P249, DOI 10.1111/j.1467-9922.2009.00507.x
   Au TKF, 2002, PSYCHOL SCI, V13, P238, DOI 10.1111/1467-9280.00444
   Birdsong D, 2001, J MEM LANG, V44, P235, DOI 10.1006/jmla.2000.2750
   Birdsong D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00081
   Bowers JS, 2009, PSYCHOL SCI, V20, P1064, DOI 10.1111/j.1467-9280.2009.02407.x
   Choi JY, 2017, P NATL ACAD SCI USA, V114, P7307, DOI 10.1073/pnas.1706405114
   Choi J, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.160660
   Chondrogianni V, 2012, BILING-LANG COGN, V15, P5, DOI 10.1017/S1366728911000368
   Colantoni L, 2006, SEL P 7 C ACQ SPAN P, P59
   COOPER RM, 1974, COGNITIVE PSYCHOL, V6, P84, DOI 10.1016/0010-0285(74)90005-X
   Croft C, 2007, J CHILD PSYCHOL PSYC, V48, P31, DOI 10.1111/j.1469-7610.2006.01689.x
   Davies A., 2004, HDB APPL LINGUISTICS, P82, DOI DOI 10.1002/9780470757000.CH3
   Dunn LM, 2007, PPVT 4 PEABODY PICTU
   Fernald A, 2015, HUM DEV, V58, P1, DOI 10.1159/000375515
   Flege J. E., 1992, INTELLIGIBILITY SPEE, P157, DOI DOI 10.1075/SSPCL.1.06FLE
   FLEGE JE, 1995, J ACOUST SOC AM, V97, P3125, DOI 10.1121/1.413041
   Gerken L, 2006, COGNITION, V98, pB67, DOI 10.1016/j.cognition.2005.03.003
   Gollan TH, 2008, J MEM LANG, V58, P787, DOI 10.1016/j.jml.2007.07.001
   Gollan TH, 2007, J INT NEUROPSYCH SOC, V13, P197, DOI 10.1017/S1355617707070038
   Gomez RL, 2000, TRENDS COGN SCI, V4, P178, DOI 10.1016/S1364-6613(00)01467-4
   Granena G, 2013, SECOND LANG RES, V29, P311, DOI 10.1177/0267658312461497
   Hakuta K, 2003, PSYCHOL SCI, V14, P31, DOI 10.1111/1467-9280.01415
   Hart B., 1995, MEANINGFUL DIFFERENC
   Hartshorne JK, 2018, COGNITION, V177, P263, DOI 10.1016/j.cognition.2018.04.007
   Hindman AH, 2016, CHILD DEV PERSPECT, V10, P134, DOI 10.1111/cdep.12177
   Hirsh-Pasek K, 2015, PSYCHOL SCI, V26, P1071, DOI 10.1177/0956797615581493
   Hoff E, 2003, CHILD DEV, V74, P1368, DOI 10.1111/1467-8624.00612
   Hoff E, 2003, MON PARENT, P147
   Hoff E, 2012, J CHILD LANG, V39, P1, DOI 10.1017/S0305000910000759
   Huettig F, 2005, COGNITION, V96, pB23, DOI 10.1016/j.cognition.2004.10.003
   HUTTENLOCHER J, 1991, DEV PSYCHOL, V27, P236, DOI 10.1037/0012-1649.27.2.236
   Hyltenstam K, 2009, BILING-LANG COGN, V12, P121, DOI 10.1017/S1366728908004008
   Ionin Tania, 2002, SECOND LANG RES, V18, P95, DOI DOI 10.1191/0267658302SR1950A
   Jia G, 2007, J SPEECH LANG HEAR R, V50, P1280, DOI 10.1044/1092-4388(2007/090)
   JOHNSON JS, 1989, COGNITIVE PSYCHOL, V21, P60, DOI 10.1016/0010-0285(89)90003-0
   JOHNSON JS, 1992, LANG LEARN, V42, P217, DOI 10.1111/j.1467-1770.1992.tb00708.x
   JOHNSON JS, 1991, COGNITION, V39, P215, DOI 10.1016/0010-0277(91)90054-8
   Kidd E, 2018, TRENDS COGN SCI, V22, P154, DOI 10.1016/j.tics.2017.11.006
   Lardiere D., 2000, 2 LANGUAGE ACQUISITI, P102
   Leigh P, 2011, PERCEPT MOTOR SKILL, V113, P281, DOI 10.2466/10.17.21.28.PMS.113.4.281-299
   Lu L, 1994, PEABODY PICTURE VOCA
   Marinis T, 2010, LANG LEARN LANG TEAC, V27, P139
   Marinova-Todd SH, 2000, TESOL QUART, V34, P9, DOI 10.2307/3588095
   Mayberry RI, 2018, BILING-LANG COGN, V21, P886, DOI 10.1017/S1366728917000724
   MAYBERRY RI, 1993, J SPEECH HEAR RES, V36, P1258, DOI 10.1044/jshr.3606.1258
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   Moores E, 2003, NAT NEUROSCI, V6, P182, DOI 10.1038/nn996
   Navarra J, 2005, J EXP PSYCHOL HUMAN, V31, P912, DOI 10.1037/0096-1523.31.5.912
   Oh JS, 2010, J CHILD LANG, V37, P1123, DOI 10.1017/S0305000909990286
   Pallier C, 2003, CEREB CORTEX, V13, P155, DOI 10.1093/cercor/13.2.155
   Park HS, 2015, APPL PSYCHOLINGUIST, V36, P773, DOI 10.1017/S0142716413000507
   Pierce LJ, 2014, P NATL ACAD SCI USA, V111, P17314, DOI 10.1073/pnas.1409411111
   Roberts Jenny A., 2005, Seminars in Speech and Language, V26, P76, DOI 10.1055/s-2005-864218
   Roberts M., 2002, APHASIOLOGY, V16, P635, DOI DOI 10.1080/02687030244000220
   Sandoval TC, 2010, BILING-LANG COGN, V13, P231, DOI 10.1017/S1366728909990514
   Schneider W., 2002, E PRIME 2 0
   Schwartz B., 1997, ARE THERE OPTIONAL I, P257
   Singh L, 2011, DEVELOPMENTAL SCI, V14, P949, DOI 10.1111/j.1467-7687.2011.01044.x
   Slabakova R, 2006, SECOND LANG RES, V22, P302, DOI 10.1191/0267658306sr270oa
   Snedeker J, 2007, PSYCHOL SCI, V18, P79, DOI 10.1111/j.1467-9280.2007.01852.x
   Tamis-LeMonda CS, 2009, J APPL DEV PSYCHOL, V30, P321, DOI 10.1016/j.appdev.2008.12.018
   Tan TX, 2007, J PEDIATR PSYCHOL, V32, P807, DOI 10.1093/jpepsy/jsm025
   Vanhove J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0069172
   Ventureyra VAG, 2004, J NEUROLINGUIST, V17, P79, DOI 10.1016/S0911-6044(03)00053-8
   Weber-Fox CM, 1999, SEC LANG ACQ RES, P23
   Weisleder A, 2013, PSYCHOL SCI, V24, P2143, DOI 10.1177/0956797613488145
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1985, PERCEPT PSYCHOPHYS, V37, P35, DOI 10.3758/BF03207136
   Xu F, 2007, PSYCHOL REV, V114, P245, DOI 10.1037/0033-295X.114.2.245
   Yee E, 2006, J EXP PSYCHOL LEARN, V32, P1, DOI 10.1037/0278-7393.32.1.1
   Yee E, 2009, PSYCHON B REV, V16, P869, DOI 10.3758/PBR.16.5.869
   Zhou C. J., 2000, SKETCH SINGAPORE HOK
NR 73
TC 1
Z9 1
U1 0
U2 4
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0022-0965
EI 1096-0457
J9 J EXP CHILD PSYCHOL
JI J. Exp. Child Psychol.
PD SEP
PY 2019
VL 185
BP 51
EP 70
DI 10.1016/j.jecp.2019.04.010
PG 20
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA IH7JB
UT WOS:000474678800004
PM 31103781
DA 2021-02-24
ER

PT J
AU Davies, B
   Rattanasone, NX
   Schembri, T
   Demuth, K
AF Davies, Benjamin
   Rattanasone, Nan Xu
   Schembri, Tamara
   Demuth, Katherine
TI Preschoolers' developing comprehension of the plural: The effects of
   number and allomorphic variation
SO JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY
LA English
DT Article
DE Morphology; Syntax; Language Acquisition; Speech Perception
ID CONCEPTUAL DISTINCTION; ACQUISITION; ENGLISH; MARKING; SETS
AB Previous intermodal preferential looking (IPL) studies have found that children learning English acquire knowledge of plural allomorphs incrementally. The segmental plural /-s/ (e.g., cats) is understood at 24 months of age, whereas the syllabic plural /-partial derivative z/ (e.g., buses) is not comprehended until 36 months. Production studies also show ongoing challenges with the syllabic plural /-partial derivative z/, suggesting a prolonged weaker representation for this allomorph. IPL studies also suggest that children do not understand the singular, which has no overt marking, until 36 months of age. However, the status of children's developing representations of the singular has been largely unstudied. The current study, therefore explored 116 3- and 4-year-olds' developing comprehension of novel singular and plural words, where the plurals were inflected with segmental and syllabic plural allomorphs. Results found that children were equally proficient at identifying novel plurals of both allomorph types, increasing accuracy with age. However, children's accuracy with novel singulars did not increase with age, raising questions about the representation of null morphology. Children's equal accuracy across plural allomorphs is more consistent with rule-based models of morphological representation than those proposing morphology as an emergent property of the lexicon. However, neither model completely accounts for the developmental differences found between singular and plural. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Davies, Benjamin; Rattanasone, Nan Xu; Schembri, Tamara; Demuth, Katherine] Macquarie Univ, Dept Linguist, Sydney, NSW 2109, Australia.
   [Davies, Benjamin; Rattanasone, Nan Xu; Schembri, Tamara; Demuth, Katherine] Macquarie Univ, Australian Res Council, Ctr Excellence Cognit & Its Disorders, Sydney, NSW 2109, Australia.
   [Schembri, Tamara] Toybox Labs, Sydney, NSW 2000, Australia.
RP Davies, B (corresponding author), Macquarie Univ, Dept Linguist, Sydney, NSW 2109, Australia.
EM ben.davies@mq.edu.au
OI Xu Rattanasone, Nan/0000-0002-2916-8435; Demuth,
   Katherine/0000-0003-3884-8886; Schembri, Tamara/0000-0002-2434-484X;
   Davies, Benjamin/0000-0002-4766-4942
FU Macquarie University; Australian Research Council (ARC) Centre of
   Excellence in Cognition and Its DisordersAustralian Research Council
   [CE110001021]; ARCAustralian Research Council [FL130100014]
FX This research was partially funded by Macquarie University, the
   Australian Research Council (ARC) Centre of Excellence in Cognition and
   Its Disorders (CE110001021), and ARC (FL130100014). We thank Fabia
   Andronos, Nyari Marunda, Kelly Miles, Peter Budziszewski, Katherine
   Revius, Peter Humberg, and the Child Language Lab at Macquarie
   University for assistance and feedback. We also thank the participants
   and their parents as well as management and staff at the preschools that
   took part in this study.
CR Arias-Trejo N, 2014, J CHILD LANG, V41, P1356, DOI 10.1017/S0305000913000615
   Australian Bureau of Statistics, 2013, SOC IND AR SEIFA TAB
   Barner D, 2008, COGNITION, V107, P603, DOI 10.1016/j.cognition.2007.11.010
   Barner D, 2007, DEVELOPMENTAL SCI, V10, P365, DOI 10.1111/j.1467-7687.2007.00591.x
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, CONVERGENCE, V12
   BERKO J, 1958, WORD, V14, P150, DOI 10.1080/00437956.1958.11659661
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Brown R., 1973, 1 LANGUAGE EARLY STA
   Budziszewski P., 2003, SERENITY ENGINE COMP
   Bybee Joan, 2001, PHONOLOGY LANGUAGE U
   Corbett G. G., 2000, NUMBER
   Davies B, 2019, ACQUIRING LAST UNPUB
   Davies B, 2017, LANG LEARN DEV, V13, P38, DOI 10.1080/15475441.2016.1219257
   de Villiers J G, 1973, J Psycholinguist Res, V2, P267, DOI 10.1007/BF01067106
   Demuth K, 2006, LANG SPEECH, V49, P137, DOI 10.1177/00238309060490020201
   Demuth K, 2012, MORPHOLOGY, V22, P67, DOI 10.1007/s11525-011-9192-7
   Demuth Katherine, 1992, CROSSLINGUISTIC STUD, V3, P557
   GOLDFIELD BA, 1990, J CHILD LANG, V17, P171, DOI 10.1017/S0305000900013167
   GOLINKOFF RM, 1987, J CHILD LANG, V14, P23, DOI 10.1017/S030500090001271X
   GRAVES MF, 1971, CHILD DEV, V42, P1165, DOI 10.2307/1127801
   Harrington J., 1997, AUST J LINGUIST, V17, P155, DOI DOI 10.1080/07268609708599550
   HOLM S, 1979, SCAND J STAT, V6, P65
   Kopcke KM, 1998, J CHILD LANG, V25, P293, DOI 10.1017/S0305000998003407
   Kouider S, 2006, LANG LEARN DEV, V2, P1, DOI 10.1207/s15473341lld0201_1
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Li P, 2009, DEV PSYCHOL, V45, P1644, DOI 10.1037/a0015553
   Marcus G. F, 1992, MONOGRAPHS SOC RES C, V57
   Matthews DE, 2006, COGNITIVE SCI, V30, P1027, DOI 10.1207/s15516709cog0000_66
   Maurer D, 2006, DEVELOPMENTAL SCI, V9, P316, DOI 10.1111/j.1467-7687.2006.00495.x
   Mealings KT, 2013, J SPEECH LANG HEAR R, V56, P1260, DOI 10.1044/1092-4388(2012/12-0163)
   MERVIS CB, 1991, DEV PSYCHOL, V27, P222, DOI 10.1037/0012-1649.27.2.222
   Nelson K, 1973, MONOGRAPHS SOC RES C, V38
   R Core Team, 2016, R LANG ENV STAT COMP
   XuRattanasone N, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01773
   Sauerland U., 2005, LINGUISTIC EVIDENCE, P413, DOI DOI 10.1515/9783110197549.413
   SMIT AB, 1990, J SPEECH HEAR DISORD, V55, P779, DOI 10.1044/jshd.5504.779
   Song JY, 2008, LANG SPEECH, V51, P385, DOI 10.1177/0023830908099071
   Zapf J., 2007, FIRST LANG, V27, P53, DOI DOI 10.1177/0142723707070286
   Zimmerman I.L., 2011, PLS 5 PRESCHOOL LANG, V5th ed.
NR 40
TC 6
Z9 6
U1 0
U2 1
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0022-0965
EI 1096-0457
J9 J EXP CHILD PSYCHOL
JI J. Exp. Child Psychol.
PD SEP
PY 2019
VL 185
BP 95
EP 108
DI 10.1016/j.jecp.2019.04.015
PG 14
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA IH7JB
UT WOS:000474678800006
PM 31129475
DA 2021-02-24
ER

PT J
AU Casillas, JV
AF Casillas, Joseph V.
TI Phonetic Category Formation is Perceptually Driven During the Early
   Stages of Adult L2 Development
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Sequential language learning; SLA; production; perception; stop voicing
ID TRAINING JAPANESE LISTENERS; R-VERTICAL-BAR; SPEECH-PERCEPTION; FOREIGN
   ACCENT; CROSS-LANGUAGE; CORONAL STOPS; ENGLISH; ACQUISITION; SPEAKERS;
   SPANISH
AB Research on the acquisition of L2 phonology in sequential language learners has stressed the importance of language use and input as a means to accurate production and perception; however, the two constructs are difficult to evaluate and control. This study focuses on the role of language use during the initial stages of development of phonetic categories related to stop voicing and analyzes the relationship between production and perception. Native English-speaking late learners of Spanish provided production/perception data on a weekly basis throughout the course of a seven-week immersion program in which L1 use was prohibited. The production/perception data were analyzed using generalized linear mixed effects models. Generalized additive mixed models were used to analyze and compare the learning trajectories of each modality. The analyses revealed phonetic learning in both production and perception over the course of the program. Perception gains paralleled those of native bilinguals by the conclusion of the program and preceded production gains. This study is novel in that it provides production/perception data in a semi-longitudinal design. Moreover, the beginning adult learners are examined in a learning context in which L1 use was minimal and L2 input was maximized. Taken together, the experiments suggest that L2 phonetic category formation can occur abruptly, at an early stage of development, is perceptually driven, and appears to be particularly fragile during the initial stages of learning.
C1 [Casillas, Joseph V.] Rutgers State Univ, New Brunswick, NJ USA.
RP Casillas, JV (corresponding author), Rutgers State Univ, Dept Spanish & Portuguese, 15 Seminary Pl, New Brunswick, NJ 08904 USA.
EM joseph.casillas@rutgers.edu
OI Casillas, Joseph/0000-0001-8735-9910
FU Comanche Nation Higher Education Grant; University of Arizona Graduate
   and Professional Student Council Research and Project Grant
   [RSRCH-702FY15]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was partially funded by the Comanche Nation Higher Education Grant
   (Numunuu), as well as the University of Arizona Graduate and
   Professional Student Council Research and Project Grant (RSRCH-702FY15).
CR BARRY WJ, 1989, PHONETICA, V46, P155, DOI 10.1159/000261840
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Boersma P., 2018, PRAAT DOING PHONETIC
   BORDEN G, 1983, LANG LEARN, V33, P499, DOI 10.1111/j.1467-1770.1983.tb00946.x
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P977, DOI 10.3758/BF03206911
   CARAMAZZA A, 1973, J ACOUST SOC AM, V54, P421, DOI 10.1121/1.1913594
   Casillas J. V., 2018, LINGSTUFF TOOLS GEMS
   Davidson L, 2018, J INT PHON ASSOC, V48, P331, DOI 10.1017/S0025100317000330
   Diaz-Campos M., 2006, SEL P 7 C ACQ SPAN P, P26
   Edwards M. L., 1974, J CHILD LANG, V1, P205, DOI [DOI 10.1017/S0305000900000659, 10.1017/S0305000900000659]
   Elliott AR, 1997, HISPANIA-J DEV INTER, V80, P95, DOI 10.2307/345983
   EMILFLEGE J, 1987, APPL LINGUIST, V8, P162
   Escudero P, 2004, STUD SECOND LANG ACQ, V26, P551, DOI 10.1017/S0272226310400021
   Escudero P., 2009, PHONOLOGY PERCEPTION, P151
   ESCUDERO P., 2005, THESIS, P348
   Escudero P, 2006, PHONOLOGY IN CONTEXT, P109
   Flege J. E., 2012, P 6 INT C NAT NONN A
   Flege J. E., 2001, STUDIES 2 LANGUAGE A, V23, P527
   Flege J. E., 2003, PHONETICS PHONOLOGY, P319, DOI DOI 10.1515/9783110895094.319
   Flege James, 1995, SPEECH PERCEPTION LI, P229
   FLEGE JE, 1995, J ACOUST SOC AM, V97, P3125, DOI 10.1121/1.413041
   FLEGE JE, 1981, TESOL QUART, V15, P443, DOI 10.2307/3586485
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   FLEGE JE, 1988, J ACOUST SOC AM, V83, P729, DOI 10.1121/1.396115
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   FLEGE JE, 1993, J ACOUST SOC AM, V93, P1589, DOI 10.1121/1.406818
   FLEGE JE, 1987, J PHONETICS, V15, P67, DOI 10.1016/S0095-4470(19)30538-8
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   Fowler CA, 2008, J PHONETICS, V36, P649, DOI 10.1016/j.wocn.2008.04.001
   Gertken Libby, 2012, BILINGUAL LANGUAGE P
   Gonzalez Lopez V., 2013, SEL P 16 HISP LING S, P118
   Gonzalez-Bueno M, 1997, IRAL-INT REV APPL LI, V35, P251, DOI 10.1515/iral.1997.35.4.251
   GOTO H, 1971, NEUROPSYCHOLOGIA, V9, P317, DOI 10.1016/0028-3932(71)90027-3
   Grasseger H., 1991, ACT 12 C INT SCI PHO, V5, P290
   Ingram D., 1977, PHONOLOGICAL DISABIL, V2
   Kissling E. M., 2014, LANG TEACH RES
   Leather J, 1999, LANG LEARN, V49, P1, DOI 10.1111/0023-8333.49.s1.1
   Leather J., 1997, 2 LANGUAGE SPEECH ST, P75, DOI DOI 10.1515/9783110882933.75
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Llisterri J., 1995, P 13 INT C PHON SCI, V4, P92
   Lopez VG, 2012, SECOND LANG RES, V28, P243, DOI 10.1177/0267658312439821
   MACK M, 1989, PERCEPT PSYCHOPHYS, V46, P187, DOI 10.3758/BF03204982
   Mathews J., 1997, NEW SOUNDS 97, P223
   Menyuk P, 1977, LANGUAGE MATURATION
   Morrison GS, 2007, SEGMENTAL PROSODIC I, P219
   Munro MJ, 2013, P 4 PRON 2 LANG LEAR, P112
   Nagle C. L., 2017, APPL LINGUIST, V40, P86
   Nagle C.L., 2016, HDB RES STUDY ABROAD, P673
   Nakagawa S, 2013, METHODS ECOL EVOL, V4, P133, DOI 10.1111/j.2041-210x.2012.00261.x
   NEUFELD GG, 1988, LANG LEARN, V38, P531, DOI 10.1111/j.1467-1770.1988.tb00166.x
   OYAMA S, 1976, J PSYCHOLINGUIST RES, V5, P261, DOI 10.1007/BF01067377
   Pallier C, 1997, COGNITION, V64, pB9, DOI 10.1016/S0010-0277(97)00030-9
   Peirce JW, 2009, FRONT NEUROINFORM, V2, DOI 10.3389/neuro.11.010.2008
   R Core Team, 2017, R LANG ENV STAT COMP
   Rochet B. L., 1995, SPEECH PERCEPTION LI, P379
   Sakai M., 2018, J 2 LANGUAGE PRONUNC, V4, P11
   Saville-Troike M., 2005, INTRO 2 LANGUAGE ACQ
   Sebastian-Galles N, 2005, J MEM LANG, V52, P240, DOI 10.1016/j.jml.2004.11.001
   Sebastian-Galles N, 1999, COGNITION, V72, P111, DOI 10.1016/S0010-0277(99)00024-4
   Sebastian-Galles N, 2006, TRENDS COGN SCI, V10, P239, DOI 10.1016/j.tics.2006.04.009
   SHELDON A, 1982, APPL PSYCHOLINGUIST, V3, P243, DOI 10.1017/S0142716400001417
   Smith N. V, 1973, ACQUISITION PHONOLOG
   Soskuthy M., 2017, ARXIV170305339
   Stevens J, 2001, MIFLC REV, V10, P137
   Strange W., 1995, SPEECH PERCEPTION LI, P3
   Sundara M, 2006, BILING-LANG COGN, V9, P97, DOI 10.1017/S1366728905002403
   Sundara M, 2008, COGNITION, V106, P234, DOI 10.1016/j.cognition.2007.01.011
   Sundara M, 2006, COGNITION, V100, P369, DOI 10.1016/j.cognition.2005.04.007
   van Rij J., 2017, ITSADUG INTERPRETING
   Wang X., 2002, THESIS
   WILLIAMS L, 1979, PERCEPT PSYCHOPHYS, V26, P95, DOI 10.3758/BF03208301
   Winter B, 2016, J LANG EVOL, V1, P7, DOI 10.1093/jole/lzv003
   Wood S., 2006, GEN ADDITIVE MODELS
   Wood SN, 2004, J AM STAT ASSOC, V99, P673, DOI 10.1198/016214504000000980
   Zampini M., 1998, TEXAS PAPERS FOREIGN, V3, P85
   Zampini M. L., 2001, ONE MIND 2 LANGUAGES, P23
NR 77
TC 1
Z9 1
U1 0
U2 2
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD SEP
PY 2020
VL 63
IS 3
BP 550
EP 581
AR 0023830919866225
DI 10.1177/0023830919866225
EA AUG 2019
PG 32
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA MX6CZ
UT WOS:000484274800001
PM 31455174
DA 2021-02-24
ER

PT J
AU Brechmann, A
   Angenstein, N
AF Brechmann, Andre
   Angenstein, Nicole
TI The impact of task difficulty on the lateralization of processing in the
   human auditory cortex
SO HUMAN BRAIN MAPPING
LA English
DT Article
DE audition; categorization; contralateral noise procedure; hemispheric
   specialization; sequential processing; working memory
ID INTERHEMISPHERIC INTERACTION; DEPENDENT ACTIVATIONS; FUNCTIONAL-ANATOMY;
   SPEECH-PERCEPTION; WORKING-MEMORY; PITCH MEMORY; DISCRIMINATION;
   INTENSITY; STREAM; FMRI
AB Perception of complex auditory stimuli like speech requires the simultaneous processing of different fundamental acoustic parameters. The contribution of left and right auditory cortex (AC) in the processing of these parameters differs. In addition, activity within the AC can vary positively or negatively with task performance depending on the type of task. This might affect the allocation of processing to the left and right AC. Here we studied with functional magnetic resonance imaging the impact of task difficulty on the degree of involvement of the left and right AC in two tasks that have previously been shown to differ in hemispheric involvement: categorization and sequential comparison of the direction of frequency modulations (FM). Task difficulty was manipulated by changing the speed of modulation and by that the frequency range covered by the FM. To study the impact of task-difficulty despite covarying the stimulus parameters, we utilized the contralateral noise procedure that allows comparing AC activation unconfounded by bottom-up driven activity. The easiest conditions confirmed the known right AC involvement during the categorization task and the left AC involvement during the comparison task. The involvement of the right AC increased with increasing task difficulty for both tasks presumably due to the common task component of categorizing FM direction. The involvement of left AC varied with task difficulty depending on the task. Thus, task difficulty has a strong impact on lateralized processing in AC. This connection must be taken into account when interpreting future results on lateralized processing in the AC.
C1 [Brechmann, Andre; Angenstein, Nicole] Leibniz Inst Neurobiol, Special Lab Noninvas Brain Imaging, Brenneckestr 6, D-39118 Magdeburg, Germany.
RP Angenstein, N (corresponding author), Leibniz Inst Neurobiol, Special Lab Noninvas Brain Imaging, Brenneckestr 6, D-39118 Magdeburg, Germany.
EM nicole.angenstein@lin-magdeburg.de
OI Brechmann, Andre/0000-0003-3903-0840
FU Deutsche ForschungsgemeinschaftGerman Research Foundation (DFG) [DFG/AN
   861/4-2]
FX Deutsche Forschungsgemeinschaft, Grant/Award Number: DFG/AN 861/4-2
CR Angenstein N, 2017, HUM BRAIN MAPP, V38, P4459, DOI 10.1002/hbm.23673
   Angenstein N, 2016, HEARING RES, V333, P87, DOI 10.1016/j.heares.2016.01.007
   Angenstein N, 2015, NEUROIMAGE, V119, P362, DOI 10.1016/j.neuroimage.2015.06.074
   Angenstein N, 2013, NEUROIMAGE, V83, P1, DOI 10.1016/j.neuroimage.2013.06.071
   Angenstein N, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00115
   Banich MT, 1998, BRAIN COGNITION, V36, P128, DOI 10.1006/brcg.1997.0950
   Baumgart F, 1998, MED PHYS, V25, P2068, DOI 10.1118/1.598368
   Behne N, 2006, J NEUROPHYSIOL, V95, P2630, DOI 10.1152/jn.01201.2005
   Behne N, 2005, J NEUROPHYSIOL, V93, P414, DOI 10.1152/jn.00568.2004
   Bethmann A, 2007, BRAIN RES, V1133, P145, DOI 10.1016/j.brainres.2006.11.057
   Binder JR, 2009, CEREB CORTEX, V19, P2767, DOI 10.1093/cercor/bhp055
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   BRADSHAW JL, 1981, BEHAV BRAIN SCI, V4, P51, DOI 10.1017/S0140525X00007548
   Brancucci A, 2004, EUR J NEUROSCI, V19, P2329, DOI 10.1111/j.0953-816X.2004.03302.x
   Brechmann A, 2005, CEREB CORTEX, V15, P578, DOI 10.1093/cercor/bhh159
   Brechmann A, 2007, CEREB CORTEX, V17, P2544, DOI 10.1093/cercor/bhl160
   Deike S, 2004, NEUROREPORT, V15, P1511, DOI 10.1097/01.wnr.0000132919.12990.34
   Deike S, 2010, HEARING RES, V265, P30, DOI 10.1016/j.heares.2010.03.005
   Eickhoff SB, 2006, CEREB CORTEX, V16, P268, DOI 10.1093/cercor/bhi106
   Eickhoff SB, 2010, J NEUROSCI, V30, P6409, DOI 10.1523/JNEUROSCI.5664-09.2010
   Gaab N, 2003, NEUROIMAGE, V19, P1417, DOI 10.1016/S1053-8119(03)00224-6
   Goebel R, 2012, NEUROIMAGE, V62, P748, DOI 10.1016/j.neuroimage.2012.01.083
   Hackett TA, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00072
   Harinen K, 2013, NEUROIMAGE, V77, P279, DOI 10.1016/j.neuroimage.2013.03.064
   Holcomb HH, 1998, CEREB CORTEX, V8, P534, DOI 10.1093/cercor/8.6.534
   Kaas JH, 2000, P NATL ACAD SCI USA, V97, P11793, DOI 10.1073/pnas.97.22.11793
   Kaneko K, 2003, HEARING RES, V183, P1, DOI 10.1016/S0378-5955(03)00186-2
   Kimura D, 1967, CORTEX, V3, P163, DOI [DOI 10.1016/S0010-9452(67)80010-8, 10.1016/s0010-9452(67)80010-8]
   Leech R, 2014, BRAIN, V137, P12, DOI 10.1093/brain/awt162
   Lewandowska M, 2010, NEUROBIOL LEARN MEM, V94, P382, DOI 10.1016/j.nlm.2010.08.005
   Liegeois-Chauvel C, 1999, CEREB CORTEX, V9, P484, DOI 10.1093/cercor/9.5.484
   Neumann N, 2016, HUM BRAIN MAPP, V37, P262, DOI 10.1002/hbm.23028
   Padoa-Schioppa C, 2017, NEURON, V96, P736, DOI 10.1016/j.neuron.2017.09.031
   Petersen SE, 2012, ANNU REV NEUROSCI, V35, P73, DOI 10.1146/annurev-neuro-062111-150525
   Raichle ME, 2015, ANNU REV NEUROSCI, V38, P433, DOI 10.1146/annurev-neuro-071013-014030
   Reiterer SM, 2005, NEUROREPORT, V16, P239, DOI 10.1097/00001756-200502280-00007
   Reiterer S, 2008, BRAIN IMAGING BEHAV, V2, P1, DOI 10.1007/s11682-007-9010-3
   Rinne T, 2012, NEUROIMAGE, V59, P4126, DOI 10.1016/j.neuroimage.2011.10.069
   Rinne T, 2009, J NEUROSCI, V29, P13338, DOI 10.1523/JNEUROSCI.3012-09.2009
   Roebroeck A, 2005, NEUROIMAGE, V25, P230, DOI 10.1016/j.neuroimage.2004.11.017
   Rosenthal MA, 2016, PSYCHOL BULL, V142, P1165, DOI 10.1037/bul0000076
   Rottschy C, 2012, NEUROIMAGE, V60, P830, DOI 10.1016/j.neuroimage.2011.11.050
   Scalf PE, 2009, EXP BRAIN RES, V194, P317, DOI 10.1007/s00221-009-1739-z
   Scheich H, 2007, HEARING RES, V229, P213, DOI 10.1016/j.heares.2007.01.025
   Seghier ML, 2013, NEUROSCIENTIST, V19, P43, DOI 10.1177/1073858412440596
   Sepulcre J, 2015, CEREB CORTEX, V25, P658, DOI 10.1093/cercor/bht256
   Stefanatos GA, 2008, NEUROPSYCHOLOGIA, V46, P301, DOI 10.1016/j.neuropsychologia.2007.07.008
   Tregellas JR, 2006, NEUROIMAGE, V32, P307, DOI 10.1016/j.neuroimage.2006.02.036
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
   Zatorre RJ, 2008, PHILOS T R SOC B, V363, P1087, DOI 10.1098/rstb.2007.2161
NR 50
TC 2
Z9 2
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1065-9471
EI 1097-0193
J9 HUM BRAIN MAPP
JI Hum. Brain Mapp.
PD DEC 15
PY 2019
VL 40
IS 18
BP 5341
EP 5353
DI 10.1002/hbm.24776
EA AUG 2019
PG 13
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA JK4FM
UT WOS:000483951400001
PM 31460688
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Henry, KS
   Sayles, M
   Hickox, AE
   Heinz, MG
AF Henry, Kenneth S.
   Sayles, Mark
   Hickox, Ann E.
   Heinz, Michael G.
TI Divergent Auditory Nerve Encoding Deficits Between Two Common Etiologies
   of Sensorineural Hearing Loss
SO JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE auditory nerve; envelope; metabolic hearing loss; noise-induced hearing
   loss; temporal fine structure; Wiener-kernel analysis
ID PRODUCT OTOACOUSTIC EMISSIONS; CHRONIC COCHLEAR PATHOLOGY; WIENER-KERNEL
   ANALYSIS; CHARACTERISTIC FREQUENCY; FINE-STRUCTURE; TUNING CURVES;
   FUROSEMIDE; RESPONSES; FIBERS; MODEL
AB Speech intelligibility can vary dramatically between individuals with similar clinically defined severity of hearing loss based on the audiogram. These perceptual differences, despite equal audiometric-threshold elevation, are often assumed to reflect central-processing variations. Here, we compared peripheral-processing in auditory nerve (AN) fibers of male chinchillas between two prevalent hearing loss etiologies: metabolic hearing loss (MHL) and noise-induced hearing loss (NIHL). MHL results from age-related reduction of the endocochlear potential due to atrophy of the stria vascularis. MHL in the present study was induced using furosemide, which provides a validated model of age-related MHL in young animals by reversibly inhibiting the endocochlear potential. Effects of MHL on peripheral processing were assessed using Wiener- kernel (system identification) analyses of single AN fiber responses to broadband noise, for direct comparison to previously published AN responses from animals with NIHL. Wiener- kernel analyses show that even mild NIHL causes grossly abnormal coding of low-frequency stimulus components. In contrast, for MHL the same abnormal coding was only observed with moderate to severe loss. For equal sensitivity loss, coding impairment was substantially less severe with MHL than with NIHL, probably due to greater preservation of the tip-to-tail ratio of cochlear frequency tuning with MHL compared with NIHL rather than different intrinsic AN properties. Differences in peripheral neural coding between these two pathologies-the more severe of which, NIHL, is preventable-likely contribute to individual speech perception differences. Our results underscore the need to minimize noise overexposure and for strategies to personalize diagnosis and treatment for individuals with sensorineural hearing loss.
C1 [Henry, Kenneth S.] Univ Rochester, Dept Otolaryngol, Rochester, NY 14642 USA.
   [Henry, Kenneth S.; Sayles, Mark; Hickox, Ann E.; Heinz, Michael G.] Purdue Univ, Dept Speech Language & Hearing Sci, W Lafayette, IN 47907 USA.
   [Sayles, Mark; Heinz, Michael G.] Purdue Univ, Weldon Sch Biomed Engn, W Lafayette, IN 47907 USA.
RP Henry, KS (corresponding author), Univ Rochester, Dept Otolaryngol, Rochester, NY 14642 USA.; Henry, KS; Heinz, MG (corresponding author), Purdue Univ, Dept Speech Language & Hearing Sci, W Lafayette, IN 47907 USA.; Heinz, MG (corresponding author), Purdue Univ, Weldon Sch Biomed Engn, W Lafayette, IN 47907 USA.
EM kenneth_henry@urmc.rochester.edu; mheinz@purdue.edu
OI Henry, Kenneth S./0000-0003-1364-318X; Heinz,
   Michael/0000-0002-1524-402X
FU National Institute on Deafness and other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [F32-DC012236, R01-DC009838]; UK-US
   Fulbright Commission - Action on Hearing Loss; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC009838, R01DC009838] Funding Source: NIH RePORTER
FX This work was supported by the National Institute on Deafness and other
   Communication Disorders (Grant F32-DC012236 to K.S.H. and Grant
   R01-DC009838 to M.G.H.). M.S. was supported by a UK-US Fulbright
   Commission scholarship award funded by Action on Hearing Loss.
CR Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Bharadwaj HM, 2015, J NEUROSCI, V35, P2161, DOI 10.1523/JNEUROSCI.3915-14.2015
   Chintanpalli A, 2007, J ACOUST SOC AM, V122, pEL203, DOI 10.1121/1.2794880
   DUBNO JR, 1982, J SPEECH HEAR RES, V25, P141, DOI 10.1044/jshr.2501.141
   Dubno JR, 2013, JARO-J ASSOC RES OTO, V14, P687, DOI 10.1007/s10162-013-0396-x
   EGGERMONT JJ, 1983, Q REV BIOPHYS, V16, P341, DOI 10.1017/S0033583500005126
   Fitzgibbons PJ, 2010, SPRINGER HANDB AUDIT, V34, P111, DOI 10.1007/978-1-4419-0993-0_5
   Halpin C, 2009, OTOLARYNG HEAD NECK, V140, P473, DOI 10.1016/j.otohns.2008.12.021
   He NJ, 1996, J ACOUST SOC AM, V99, P1002, DOI 10.1121/1.414629
   Heinz M. G., 2013, P M AC, V19
   Heinz MG, 2001, NEURAL COMPUT, V13, P2273, DOI 10.1162/089976601750541804
   Henry KS, 2016, J NEUROSCI, V36, P2227, DOI 10.1523/JNEUROSCI.3944-15.2016
   Humes LE, 2012, J AM ACAD AUDIOL, V23, P635, DOI 10.3766/jaaa.23.8.5
   JOHNSON DH, 1980, J ACOUST SOC AM, V68, P1115, DOI 10.1121/1.384982
   Jorgensen S, 2013, J ACOUST SOC AM, V134, P436, DOI 10.1121/1.4807563
   JORIS PX, 1992, J ACOUST SOC AM, V91, P215, DOI 10.1121/1.402757
   Lewis Edwin R, 2004, Hear Res, V189, P120, DOI 10.1016/S0378-5955(03)00406-4
   Lewis ER, 2002, HEARING RES, V174, P206, DOI 10.1016/S0378-5955(02)00695-0
   LIBERMAN MC, 1982, J ACOUST SOC AM, V72, P1441, DOI 10.1121/1.388677
   LIBERMAN MC, 1984, HEARING RES, V16, P55, DOI 10.1016/0378-5955(84)90025-X
   LIBERMAN MC, 1984, HEARING RES, V16, P33, DOI 10.1016/0378-5955(84)90023-6
   Lopez-Poveda EA, 2012, JARO-J ASSOC RES OTO, V13, P485, DOI 10.1007/s10162-012-0327-2
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Lurie M. H., 1944, LARYNGOSCOPE, V54, P375
   MILLS DM, 1993, J ACOUST SOC AM, V94, P2108, DOI 10.1121/1.407483
   MILLS DM, 1994, HEARING RES, V77, P183, DOI 10.1016/0378-5955(94)90266-6
   Mills John H., 2006, Seminars in Hearing, V27, P228, DOI 10.1055/s-2006-954849
   Moore BCJ, 1999, J ACOUST SOC AM, V106, P2761, DOI 10.1121/1.428133
   Recio-Spinoso A, 2005, J NEUROPHYSIOL, V93, P3615, DOI 10.1152/jn.00882.2004
   RUGGERO MA, 1992, J NEUROPHYSIOL, V68, P1087
   RUGGERO MA, 1991, J NEUROSCI, V11, P1057
   RYBAK LP, 1992, HEARING RES, V59, P75, DOI 10.1016/0378-5955(92)90104-U
   Sayles M, 2017, SPRINGER HANDB AUDIT, V62, P215, DOI 10.1007/978-3-319-52073-5_8
   Schmiedt RA, 2002, J NEUROSCI, V22, P9643
   SCHMIEDT RA, 1990, HEARING RES, V45, P221, DOI 10.1016/0378-5955(90)90122-6
   Schmiedt RA, 2010, SPRINGER HANDB AUDIT, V34, P9, DOI 10.1007/978-1-4419-0993-0_2
   SCHUKNECHT HF, 1993, ANN OTO RHINOL LARYN, V102, P1
   SEWELL WF, 1984, HEARING RES, V14, P305, DOI 10.1016/0378-5955(84)90057-1
   Temchin AN, 2008, J NEUROPHYSIOL, V100, P2889, DOI 10.1152/jn.90637.2008
   van Drongelen W, 2010, SIGNAL PROCESSING FOR NEUROSCIENTISTS, A COMPANION VOLUME: ADVANCED TOPICS, NONLINEAR TECHNIQUES AND MULTI-CHANNEL ANALYSIS, P61, DOI 10.1016/B978-0-12-384915-1.00004-8
   VANDIJK P, 1994, J ACOUST SOC AM, V95, P904, DOI 10.1121/1.410009
NR 41
TC 6
Z9 6
U1 0
U2 2
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
SN 0270-6474
EI 1529-2401
J9 J NEUROSCI
JI J. Neurosci.
PD AUG 28
PY 2019
VL 39
IS 35
BP 6879
EP 6887
DI 10.1523/JNEUROSCI.0038-19.2019
PG 9
WC Neurosciences
SC Neurosciences & Neurology
GA IU2MZ
UT WOS:000483415800006
PM 31285299
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Johnson, EK
   White, KS
AF Johnson, Elizabeth K.
   White, Katherine S.
TI Developmental sociolinguistics: Children's acquisition of language
   variation
SO WILEY INTERDISCIPLINARY REVIEWS-COGNITIVE SCIENCE
LA English
DT Article
DE children; language development; sociolinguistics; speech perception;
   speech production
ID TODDLERS PERCEPTION; AMERICAN ENGLISH; FOREIGN ACCENT; VARIABLE RULES;
   SPEECH; DIALECT; COMPREHENSION; INFORMATION; RECOGNITION; VARIABILITY
AB Developmental sociolinguistics is a rapidly evolving interdisciplinary framework that builds upon theoretical and methodological contributions from multiple disciplines (i.e., sociolinguistics, language acquisition, the speech sciences, developmental psychology, and psycholinguistics). A core assumption of this framework is that language is by its very nature variable, and that much of this variability is informative, as it is (probabilistically) governed by a variety of factors-including linguistic context, social or cultural context, the relationship between speaker and addressee, a language user's geographic origin, and a language user's gender identity. It is becoming increasingly clear that consideration of these factors is absolutely essential to developing realistic and ecologically valid models of language development. Given the central importance of language in our social world, a more complete understanding of early social development will also require a deeper understanding of when and how language variation influences children's social inferences and behavior. As the cross-pollination between formerly disparate fields continues, we anticipate a paradigm shift in the way many language researchers conceptualize the challenge of early acquisition. This article is categorized under: Linguistics > Linguistic Theory Linguistics > Language Acquisition Neuroscience > Development Psychology > Language
C1 [Johnson, Elizabeth K.] Univ Toronto, Dept Psychol, Toronto, ON, Canada.
   [White, Katherine S.] Univ Waterloo, Dept Psychol, Waterloo, ON, Canada.
RP Johnson, EK (corresponding author), Univ Toronto, Dept Psychol, Toronto, ON, Canada.; White, KS (corresponding author), Univ Waterloo, Dept Psychol, Waterloo, ON, Canada.
EM elizabeth.johnson@utoronto.ca; white@uwaterloo.ca
OI Johnson, Elizabeth Kay/0000-0002-9941-9949
FU Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR; Social
   Sciences and Humanities Research Council of CanadaSocial Sciences and
   Humanities Research Council of Canada (SSHRC)
FX Natural Sciences and Engineering Research Council of Canada; Social
   Sciences and Humanities Research Council of Canada
CR Adank P, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00280
   Apfelbaum KS, 2011, COGNITIVE SCI, V35, P1105, DOI 10.1111/j.1551-6709.2011.01181.x
   Aslin RN, 1996, SIGNAL TO SYNTAX: BOOTSTRAPPING FROM SPEECH TO GRAMMAR IN EARLY ACQUISITION, P117
   Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001
   Babel M, 2010, LANG SOC, V39, P437, DOI 10.1017/S0047404510000400
   Barbu S, 2013, LINGUISTICS, V51, P381, DOI 10.1515/ling-2013-0015
   Bent T, 2015, J ACOUST SOC AM, V138, P3985, DOI 10.1121/1.4938228
   Best CT, 2009, PSYCHOL SCI, V20, P539, DOI 10.1111/j.1467-9280.2009.02327.x
   Bosch M, 2010, REG SCI URBAN ECON, V40, P11, DOI 10.1016/j.regsciurbeco.2009.11.001
   Brooks R, 2008, J CHILD LANG, V35, P207, DOI 10.1017/S030500090700829X
   Brown R., 1973, 1 LANGUAGE EARLY STA
   Buckler H, 2018, J PHONETICS, V66, P45, DOI 10.1016/j.wocn.2017.09.004
   Buckler H, 2017, J EXP CHILD PSYCHOL, V164, P87, DOI 10.1016/j.jecp.2017.06.017
   Byers-Heinlein K, 2010, PSYCHOL SCI, V21, P343, DOI 10.1177/0956797609360758
   Chen H, 2017, J ACOUST SOC AM, V142, P1707, DOI 10.1121/1.4995994
   Chevrot JP, 2011, LANG SCI, V33, P180, DOI 10.1016/j.langsci.2010.08.007
   Clopper Cynthia G, 2004, Lang Var Change, V16, P31
   Comeau L, 2007, J CHILD LANG, V34, P159, DOI 10.1017/S0305000906007690
   Corriveau KH, 2013, DEV PSYCHOL, V49, P470, DOI 10.1037/a0030604
   Craig HK, 2012, J SPEECH LANG HEAR R, V55, P1274, DOI 10.1044/1092-4388(2012/11-0055)
   Creel S. C., 2018, DEV SCI, V21
   Creel SC, 2016, J EXP CHILD PSYCHOL, V146, P156, DOI 10.1016/j.jecp.2016.01.018
   Curtin S, 2011, J PHONETICS, V39, P492, DOI 10.1016/j.wocn.2010.12.002
   DeJesus JM, 2017, J EXP CHILD PSYCHOL, V164, P178, DOI 10.1016/j.jecp.2017.07.005
   DePaolis RA, 2011, INFANT BEHAV DEV, V34, P590, DOI 10.1016/j.infbeh.2011.06.005
   Docherty GJ, 2013, LINGUISTICS, V51, P355, DOI 10.1515/ling-2013-0014
   Durrant S, 2015, J CHILD LANG, V42, P447, DOI 10.1017/S0305000914000063
   Edwards J, 2014, J SPEECH LANG HEAR R, V57, P1883, DOI 10.1044/2014_JSLHR-L-13-0228
   Evans BG, 2007, J ACOUST SOC AM, V121, P3814, DOI 10.1121/1.2722209
   Fennell C, 2014, INT J BEHAV DEV, V38, P309, DOI 10.1177/0165025414530631
   Floccia C, 2012, COGNITION, V124, P95, DOI 10.1016/j.cognition.2012.03.011
   Floccia C, 2009, INT J BEHAV DEV, V33, P366, DOI 10.1177/0165025409103871
   Foulkes P, 2005, LANGUAGE, V81, P177, DOI 10.1353/lan.2005.0018
   Foulkes P, 2006, J PHONETICS, V34, P409, DOI 10.1016/j.wocn.2005.08.002
   Fridland V, 2012, LINGUA, V122, P779, DOI 10.1016/j.lingua.2011.12.007
   Fuertes JN, 2012, EUR J SOC PSYCHOL, V42, P120, DOI 10.1002/ejsp.862
   Giles H., 1981, LANG SCI, V3, P91, DOI DOI 10.1016/S0388-0001(81)80015-0
   Goldinger S. D., 2007, 16 INT C PHON SCI, P49
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Gonzales K, 2018, COGNITIVE PSYCHOL, V106, P1, DOI 10.1016/j.cogpsych.2018.04.003
   Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014
   Houston DM, 2000, J EXP PSYCHOL HUMAN, V26, P1570, DOI 10.1037/0096-1523.26.5.1570
   Hwang HG, 2018, J CHILD LANG, V45, P1018, DOI 10.1017/S0305000917000587
   Johnson EK, 2016, ANNU REV LINGUIST, V2, P391, DOI 10.1146/annurev-linguistics-011415-040616
   Johnson EK, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0083546
   Jones Z, 2017, J PHONETICS, V60, P20, DOI 10.1016/j.wocn.2016.11.001
   Juscyzk P. W, 1997, DISCOVERY SPOKEN LAN
   JUSCZYK PW, 1995, COGNITIVE PSYCHOL, V29, P1, DOI 10.1006/cogp.1995.1010
   Kam CLH, 2005, LANG LEARN DEV, V1, P151, DOI 10.1207/s15473341lld0102_3
   Kam CLH, 2015, LANGUAGE, V91, P906, DOI 10.1353/lan.2015.0051
   Kam CLH, 2009, COGNITIVE PSYCHOL, V59, P30, DOI 10.1016/j.cogpsych.2009.01.001
   Kendall T, 2017, LANG VAR CHANGE, V29, P245, DOI 10.1017/S0954394517000084
   Kerswill P, 2000, LANG SOC, V29, P65, DOI 10.1017/S0047404500001020
   Kinzler KD, 2007, P NATL ACAD SCI USA, V104, P12577, DOI 10.1073/pnas.0705345104
   Kinzler KD, 2013, Q J EXP PSYCHOL, V66, P1146, DOI 10.1080/17470218.2012.731695
   Kinzler KD, 2009, SOC COGNITION, V27, P623, DOI 10.1521/soco.2009.27.4.623
   Kitamura C, 2013, CHILD DEV, V84, P1686, DOI 10.1111/cdev.12068
   Ko SJ, 2015, PSYCHOL SCI, V26, P3, DOI 10.1177/0956797614553009
   Kouider S, 2006, LANG LEARN DEV, V2, P1, DOI 10.1207/s15473341lld0201_1
   Kozlowski A., 2015, INKBLOT, V4, P12
   Labov W, 1972, ATLANTIC, P1
   Labov W, 1964, SOCIAL DIALECTS LANG, P77
   Labov William, 1990, LANG VAR CHANGE, V2, P205, DOI [10. 1017/S09543945 00000338, DOI 10.1017/S0954394500000338]
   Lahey M, 2014, LANG LEARN DEV, V10, P308, DOI 10.1080/15475441.2013.860813
   Masapollo M, 2016, DEVELOPMENTAL SCI, V19, P318, DOI 10.1111/desc.12298
   Merriman W E, 1989, Monogr Soc Res Child Dev, V54, P1
   Miller K, 2013, LANG VAR CHANGE, V25, P311, DOI 10.1017/S095439451300015X
   Nardy A, 2013, LINGUISTICS, V51, P255, DOI 10.1515/ling-2013-0011
   Nathan L, 1998, J CHILD LANG, V25, P343, DOI 10.1017/S0305000998003444
   Nazzi T, 2000, J MEM LANG, V43, P1, DOI 10.1006/jmla.2000.2698
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Nielsen M, 2017, J EXP CHILD PSYCHOL, V162, P31, DOI 10.1016/j.jecp.2017.04.017
   Paquette-Smith M, 2019, DEV PSYCHOL, V55, P809, DOI 10.1037/dev0000659
   Paquette-Smith M, 2016, LANG LEARN DEV, V12, P328, DOI 10.1080/15475441.2015.1112801
   Rakic T, 2011, J PERS SOC PSYCHOL, V100, P16, DOI 10.1037/a0021522
   Roberts J, 1997, J CHILD LANG, V24, P351, DOI 10.1017/S0305000997003073
   Roberts J. L., 1994, IRCS9609 U PENNS
   Rost GC, 2010, INFANCY, V15, P608, DOI 10.1111/j.1532-7078.2010.00033.x
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Samara A, 2017, COGNITIVE PSYCHOL, V94, P85, DOI 10.1016/j.cogpsych.2017.02.004
   Santelmann LM, 1998, COGNITION, V69, P105, DOI 10.1016/S0010-0277(98)00060-2
   Schmale R, 2010, P INT C IND POS IND, P1, DOI DOI 10.1109/IPIN.2010.5647630
   Schmale R, 2009, DEVELOPMENTAL SCI, V12, P583, DOI 10.1111/j.1467-7687.2009.00809.x
   SHATZ M, 1973, MONOGR SOC RES CHILD, V38, P1, DOI 10.2307/1165783
   Shin NL, 2016, J CHILD LANG, V43, P914, DOI 10.1017/S0305000915000380
   Shipley Kenneth G., 1991, LANG SPEECH HEAR SER, V22, P115, DOI DOI 10.1044/0161-1461.2203.115
   SHOCKEY L, 1980, PHONETICA, V37, P267, DOI 10.1159/000259996
   Singh L, 2004, J MEM LANG, V51, P173, DOI 10.1016/j.jml.2004.04.004
   Singleton JL, 2004, COGNITIVE PSYCHOL, V49, P370, DOI 10.1016/j.cogpsych.2004.05.001
   Slobin D. I., 1973, STUDIES CHILD LANGUA
   Smith J, 2007, LANG VAR CHANGE, V19, P63, DOI 10.1017/S0954394507070044
   Smith J, 2013, LINGUISTICS, V51, P285, DOI 10.1515/ling-2013-0012
   Smith J, 2009, LANG VAR CHANGE, V21, P69, DOI 10.1017/S0954394509000039
   Strand EA, 1999, J LANG SOC PSYCHOL, V18, P86, DOI 10.1177/0261927X99018001006
   Subiaul F, 2016, J EXP CHILD PSYCHOL, V141, P145, DOI 10.1016/j.jecp.2015.08.010
   Sumner M, 2015, TRENDS COGN SCI, V19, P238, DOI 10.1016/j.tics.2015.03.007
   Sumner M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01015
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   Tagliamonte SA, 2007, LANG SOC, V36, P649, DOI 10.1017/S0047404507070911
   Trudgill Peter, 1972, LANGUAGE SOC, V1, P179, DOI [10.1017/S0047404500000488, DOI 10.1017/S0047404500000488]
   Trudgill Peter, 1974, SOCIAL DIFFERENTIATI
   Van Berkum JJA, 2008, J COGNITIVE NEUROSCI, V20, P580, DOI 10.1162/jocn.2008.20054
   van der Feest SVH, 2016, LANG ACQUIS, V23, P89, DOI 10.1080/10489223.2015.1047096
   van Heugten M, 2017, J ACOUST SOC AM, V142, pEL196, DOI 10.1121/1.4997604
   van Heugten M, 2015, LANG LEARN DEV, V11, P41, DOI 10.1080/15475441.2013.879636
   van Heugten M, 2015, INFANCY, V20, P675, DOI 10.1111/infa.12094
   van Heugten M, 2009, DEVELOPMENTAL SCI, V12, P419, DOI 10.1111/j.1467-7687.2008.00788.x
   Wagner L, 2014, J CHILD LANG, V41, P1062, DOI 10.1017/S0305000913000330
   Washington JA, 1998, J SPEECH LANG HEAR R, V41, P618, DOI 10.1044/jslhr.4103.618
   Weatherhead D, 2018, COGNITION, V177, P87, DOI 10.1016/j.cognition.2018.04.004
   Weatherhead D, 2018, CHILD DEV, V89, P1613, DOI 10.1111/cdev.12797
   Weatherhead D, 2016, LANG LEARN DEV, V12, P92, DOI 10.1080/15475441.2015.1024835
   Weatherhead D, 2016, J EXP CHILD PSYCHOL, V143, P171, DOI 10.1016/j.jecp.2015.10.011
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   White KS, 2011, DEVELOPMENTAL SCI, V14, P372, DOI 10.1111/j.1467-7687.2010.00986.x
   Wolfram W. A., 1969, URBAN LANGUAGE SERIE, V5
NR 117
TC 0
Z9 0
U1 3
U2 17
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1939-5078
EI 1939-5086
J9 WIRES COGN SCI
JI Wiley Interdiscip. Rev.-Cogn. Sci.
PD JAN-FEB
PY 2020
VL 11
IS 1
AR e1515
DI 10.1002/wcs.1515
EA AUG 2019
PG 15
WC Psychology, Experimental
SC Psychology
GA NJ2GZ
UT WOS:000483803300001
PM 31454182
DA 2021-02-24
ER

PT J
AU McAllister, A
   Rantala, L
   Jonsdottir, VI
AF McAllister, Anita
   Rantala, Leena
   Jonsdottir, Valdis Ingibjorg
TI The Others Are Too Loud! Children's Experiences and Thoughts Related to
   Voice, Noise, and Communication in Nordic Preschools
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE communication; experience; environment; strategies; risk factors;
   awareness; voice
ID SPEECH-PERCEPTION; CLASSROOM ACOUSTICS; SUBJECTIVE RATINGS;
   NORMAL-HEARING; TEACHERS; REVERBERATION; COMPREHENSION; PREVALENCE;
   DISORDERS; QUALITY
AB Background: High noise levels affect hearing, voice use, and communication. Several studies have reported high noise levels in preschools and impaired voice quality in children. Noise and poor listening conditions impair speech comprehension in children more than in adults and even more for children with hearing or language impairment, attention deficits, or another first language.
   Aim: The aim of this study was to explore how children in Finland, Sweden, and Iceland describe the preschool environment in relation to noise, voice, and verbal communication; what were their experiences, knowledge and ideas in relation to voice, noise, and communication. Children's awareness of effects of noise, reactions, and coping strategies were also studied. In addition, country and gender differences were analyzed.
   Methods: Eighteen Icelandic, 14 Finnish, and 16 Swedish children were interviewed using a common interview-guide. Swedish and Finnish children were interviewed in focus groups and Icelandic children individually. All interviews were transcribed verbatim and analyzed thematically by the native speaker. The interviews were translated to English to be re-analyzed for inter-judge reliability of identified themes. Inter-judge reliability was calculated using percentage absolute agreement.
   Results: The interviews resulted in 1052 utterances, 471 from focus groups, and 581 from individual interviews. Three themes were identified, Experiences, Environment, and Strategies with two to three subcategories. Inter-judge agreement for the themes was excellent, 92-98%. Experiences occurred in 55% of the utterances. The subcategories were bodily and emotional experiences and experiences of hearing and being heard. Environment occurred in 20% of the utterances, with subcategories indoor vs. outdoor and noise. Strategies was found in 15%, with subcategories games and problem oriented actions. The only significant difference between the countries was for the theme Strategies where the Swedish children produced more utterances than the Finnish. No gender differences were found.
   Conclusion: Children are aware of high noise levels and mainly blame other children for making noise and shouting. They describe reactions and strategies related to noise like impaired communication and effects on hearing but are less aware of effects on voice. Expressed thoughts were similar across countries. No gender differences were found.
C1 [McAllister, Anita] Karolinska Inst, Div Speech & Language Pathol, CLINTEC, Solna, Sweden.
   [McAllister, Anita] Karolinska Univ Hosp, Funct Area Speech & Language Pathol, Stockholm, Sweden.
   [Rantala, Leena] Univ Tampere, Dept Logoped, Tampere, Finland.
   [Jonsdottir, Valdis Ingibjorg] Univ Akureyri, Thad Er Malid Voice Pathol, Akureyri, Iceland.
RP McAllister, A (corresponding author), Karolinska Inst, Div Speech & Language Pathol, CLINTEC, Solna, Sweden.; McAllister, A (corresponding author), Karolinska Univ Hosp, Funct Area Speech & Language Pathol, Stockholm, Sweden.
EM anita.mcallister@ki.se
OI McAllister, Anita/0000-0003-2208-0630
FU Nordplus Horizontal grant [HZ-2012_1a30063]
FX This work was partly financed by a Nordplus Horizontal grant,
   project-ID: HZ-2012_1a30063.
CR American Speech-Language Hearing Association, 2005, GUID ADDR AC ED SETT
   [Anonymous], 2004, SFS 5907
   Basner M, 2014, LANCET, V383, P1325, DOI 10.1016/S0140-6736(13)61613-X
   Boman E, 2004, ENVIRON BEHAV, V36, P207, DOI 10.1177/0013916503256644
   Bradley JS, 2008, J ACOUST SOC AM, V123, P2078, DOI 10.1121/1.2839285
   Bradley J. S., 2004, Canadian Acoustics, V32, P26
   Brannstrom KJ, 2015, J VOICE, V29, P624, DOI 10.1016/j.jvoice.2014.11.003
   Brannstrom KJ, 2017, NOISE HEALTH, V19, P84, DOI 10.4103/nah.NAH_33_16
   CHARMAZ K, 2014, CONSTRUCTING GROUNDE, V2nd
   Crandell C. C., 1995, J ACOUST SOC AM, V97, P3262, DOI [10.1121/1.411633, DOI 10.1121/1.411633]
   Crandell Carl C., 1996, AM J AUDIOL, V5, P47, DOI DOI 10.1044/1059-0889.0503.47
   Crandell CC, 2000, LANG SPEECH HEAR SER, V31, P362, DOI 10.1044/0161-1461.3104.362
   Dellve L, 2013, QUAL RES PSYCHOL, V10, P1, DOI 10.1080/14780887.2011.586099
   Fritzell B., 1996, LOGOP PHONIATR VOCO, V21, P7, DOI DOI 10.3109/14015439609099197
   Gill P, 2008, BRIT DENT J, V204, P291, DOI 10.1038/bdj.2008.192
   Graneheim UH, 2004, NURS EDUC TODAY, V24, P105, DOI 10.1016/j.nedt.2003.10.001
   Haines M M, 2003, Noise Health, V5, P19
   Huang CC, 2010, J PRAGMATICS, V42, P825, DOI 10.1016/j.pragma.2009.08.005
   Hurtig A, 2016, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.02029
   *ISO TR, 1974, 3352 ISOTR
   Jonsdottir V., 2009, IS AMPLIFICATION NEC
   Jonsdottir V, 2015, NOISE HEALTH, V17, P282, DOI 10.4103/1463-1741.165044
   Jonsdottir Valdis I, 2002, Logoped Phoniatr Vocol, V27, P29, DOI 10.1080/140154302760146952
   Kallvik E, 2015, J VOICE, V29, DOI 10.1016/j.jvoice.2013.08.019
   Karjalainen M., 1996, THESIS
   Keenan E. O., 1975, ANN M BERKELEY LING, V1, P279, DOI [10.3765/bls.v1i0, DOI 10.3765/BLS.V1I0]
   Klatte M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00578
   Klatte M, 2010, NOISE HEALTH, V12, P270, DOI 10.4103/1463-1741.70506
   Krippendorff K., 2013, CONTENT ANAL INTRO I
   Kristiansen J, 2013, ENVIRON BEHAV, V45, P283, DOI 10.1177/0013916511429700
   Krueger R., 2009, FOCUS GROUPS PRACTIC
   LANE H, 1971, J SPEECH HEAR RES, V14, P677, DOI 10.1044/jshr.1404.677
   Lu YY, 2008, J ACOUST SOC AM, V124, P3261, DOI 10.1121/1.2990705
   Malterud K., 2009, QUALITATIVE METHODS
   McAllister A., 2019, VOICE ERGONOMICS OCC, P221
   McAllister A., 2019, VOICE ERGONOMICS OCC, P130
   McAllister AM, 2009, J VOICE, V23, P587, DOI 10.1016/j.jvoice.2007.10.017
   McAllister R., 1990, PERCEPTUAL FOREIGN A
   McKellin WH, 2007, J PRAGMATICS, V39, P2159, DOI 10.1016/j.pragma.2006.11.012
   Neuman AC, 2010, EAR HEARING, V31, P336, DOI 10.1097/AUD.0b013e3181d3d514
   Nyberg J, 2016, CLEFT PALATE-CRAN J, V53, P516, DOI 10.1597/15-140
   Patton MQ, 2002, QUALITATIVE RES EVAL, V3rd
   Peelle JE, 2018, EAR HEARING, V39, P204, DOI 10.1097/AUD.0000000000000494
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Portela AS, 2018, J VOICE, V32, DOI 10.1016/j.jvoice.2017.04.010
   Rantala LM, 2012, J VOICE, V26, DOI 10.1016/j.jvoice.2012.06.001
   Rantala LM, 2015, J SPEECH LANG HEAR R, V58, P1397, DOI 10.1044/2015_JSLHR-S-14-0248
   Rogers CL, 2006, APPL PSYCHOLINGUIST, V27, P465, DOI 10.1017/S014271640606036X
   Roy N, 2004, J SPEECH LANG HEAR R, V47, P281, DOI 10.1044/1092-4388(2004/023)
   Sala E, 2001, J VOICE, V15, P413, DOI 10.1016/S0892-1997(01)00042-X
   Sala E., 2019, VOICE ERGONOMICS OCC, P172
   Sala E, 2016, APPL ACOUST, V114, P252, DOI 10.1016/j.apacoust.2016.08.009
   Sala Eeva, 2002, Logoped Phoniatr Vocol, V27, P21, DOI 10.1080/140154302760146943
   SEDERHOLM E, 1995, FOLIA PHONIATR LOGO, V47, P262, DOI 10.1159/000266360
   Sederholm E., 1995, LOGOP PHONIATR VOCO, V20, P165, DOI DOI 10.3109/14015439509098744
   Shield B, 2004, J ACOUST SOC AM, V115, P730, DOI 10.1121/1.1635837
   Shield BM, 2008, J ACOUST SOC AM, V123, P133, DOI 10.1121/1.2812596
   Sodersten M, 2005, J VOICE, V19, P29, DOI 10.1016/j.jvoice.2004.05.002
   Sodersten M, 2002, J VOICE, V16, P356, DOI 10.1016/S0892-1997(02)00107-8
   Tabri D, 2011, INT J LANG COMM DIS, V46, P411, DOI 10.3109/13682822.2010.519372
   Ternstrom S, 2006, J ACOUST SOC AM, V119, P1648, DOI 10.1121/1.2161435
   Vilkman E, 2004, FOLIA PHONIATR LOGO, V56, P220, DOI 10.1159/000078344
   Waye KP, 2013, BMJ OPEN, V3, DOI 10.1136/bmjopen-2012-002408
   Whitling S, 2017, J VOICE, V31, DOI 10.1016/j.jvoice.2016.12.012
   Williams AC, 2004, BRIT DENT J, V197, P67, DOI 10.1038/sj.bdj.4811467
NR 65
TC 2
Z9 2
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD AUG 21
PY 2019
VL 10
AR 1954
DI 10.3389/fpsyg.2019.01954
PG 13
WC Psychology, Multidisciplinary
SC Psychology
GA IS3VC
UT WOS:000482080600001
PM 31496984
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Lyu, J
   Kong, Y
   Xu, TQ
   Dong, RJ
   Qi, BE
   Wang, S
   Li, YX
   Liu, HH
   Chen, XQ
AF Lyu, Jing
   Kong, Ying
   Xu, Tian-Qiu
   Dong, Rui-Juan
   Qi, Bei-Er
   Wang, Shuo
   Li, Yong-Xin
   Liu, Hai-Hong
   Chen, Xue-Qing
TI Long-term follow-up of auditory performance and speech perception and
   effects of age on cochlear implantation in children with pre-lingual
   deafness
SO CHINESE MEDICAL JOURNAL
LA English
DT Article
DE Categorical auditory performance; Speech intelligibility rating;
   Cochlear implantation; Children; Pre-lingual deafness; Age at cochlear
   implantation
AB Background:The development of auditory and speech perception ability of children with hearing loss is affected by many factors after they undergo cochlear implantation (CI). Age at CI (CI age) appears to play an important role among these factors. This study aimed to evaluate the development of auditory and speech perception ability and explore the impact of CI age on children with pre-lingual deafness present before 3 years of age.Methods:Two hundred and seventy-eight children with pre-lingual deafness (176 boys and 102 girls) were included in this study, and the CI age ranged from 6 to 36 months (mean age, 19 months). Categorical auditory performance (CAP) was assessed to evaluate auditory ability, and the speech intelligibility rating was used to evaluate speech intelligibility. The evaluations were performed before CI and 1, 3, 6, 12, 18, 24, 36, 48, and 60 months after CI.Results:The auditory ability of the pre-lingually hearing-impaired children showed the fastest development within 6 months after CI (k=0.524, t=30.992, P<0.05); then, the progress started to decelerate (k=0.14, t=3.704, P<0.05) and entered a plateau at the 24th month (k=0.03, t=1.908, P<0.05). Speech intelligibility showed the fastest improvement between the 12th and 24th months after CI (k=0.138, t=5.365, P<0.05); then, the progress started to decelerate (k=0.026, t=1.465, P<0.05) and entered a plateau at the 48th month (k=0.012, t=1.542, P<0.05). The CI age had no statistical significant effect on the auditory and speech abilities starting at 2 years after CI (P>0.05). The optimal cutoff age for CI was 15 months.Conclusions:Within 5 years after CI, the auditory and speech ability of young hearing-impaired children continuously improved, although speech development lagged behind that of hearing. An earlier CI age is recommended; the optimal cutoff age for CI is at 15 months.
C1 [Lyu, Jing; Kong, Ying; Xu, Tian-Qiu; Dong, Rui-Juan; Qi, Bei-Er; Wang, Shuo; Li, Yong-Xin; Chen, Xue-Qing] Capital Med Univ, Beijing Tongren Hosp, Beijing Inst Otolaryngol, Dept Otolaryngol Head & Neck Surg, 17 Hougou Hutong, Beijing 100005, Peoples R China.
   [Liu, Hai-Hong] Capital Med Univ, Beijing Key Lab Pediat Dis Otolaryngol Head & Nec, Dept Otolaryngol Head & Neck Surg, Beijing Childrens Hosp,Natl Ctr Childrens Hlth, Beijing 100045, Peoples R China.
RP Chen, XQ (corresponding author), Capital Med Univ, Beijing Tongren Hosp, Beijing Inst Otolaryngol, Dept Otolaryngol Head & Neck Surg, 17 Hougou Hutong, Beijing 100005, Peoples R China.
EM xueqingchen2006@aliyun.com
CR Anderson I, 2004, INT J PEDIATR OTORHI, V68, P425, DOI 10.1016/j.ijporl.2003.11.013
   Chen XQ, 2012, CHIN ARCH OTOLARYNGO, V19, P529, DOI [10.16066/j.1672-7002.2012.10.010, DOI 10.16066/J.1672-7002.2012.10.010]
   Cheng Jiajia, 2012, Lin Chung Er Bi Yan Hou Tou Jing Wai Ke Za Zhi, V26, P595
   Colletti V, 2005, LARYNGOSCOPE, V115, P445, DOI 10.1097/01.mlg.0000157838.61497.e7
   Fang HY, 2014, INT J PEDIATR OTORHI, V78, P799, DOI 10.1016/j.ijporl.2014.02.014
   Geers AE, 2006, ADV OTORHINOLARYNGOL, V64, P47
   Goodman R, 2000, J CHILD PSYCHOL PSYC, V41, P645, DOI 10.1111/j.1469-7610.2000.tb02345.x
   Govaerts PJ, 2002, OTOL NEUROTOL, V23, P885, DOI 10.1097/00129492-200211000-00013
   Guo LJ, 2016, EVALUATION AUDITORY
   Hassanzadeh S, 2002, OTOLARYNG HEAD NECK, V126, P524, DOI 10.1067/mhn.2002.125110
   Liu Q, 2011, VALIDATION REHABILIT
   Men XM, 2017, CHARACTERISTICS AUDI
   Meng C, 2016, CHIN SCI J HEARING S, V14, P259, DOI [10.3969/j.issn.1672-4933.2016.04.005, DOI 10.3969/J.ISSN.1672-4933.2016.04.005]
   Mikic B, 2014, Cochlear Implants Int, V15 Suppl 1, pS33, DOI 10.1179/1467010014Z.000000000191
   Nikolopoulos TP, 2005, INT J PEDIATR OTORHI, V69, P175, DOI 10.1016/j.ijporl.2004.08.016
   Robbins AM, 2004, ARCH OTOLARYNGOL, V130, P570
   Sharma A, 2005, HEARING RES, V203, P134, DOI 10.1016/j.heares.2004.12.010
   Stephen JR, 2015, CHINA MED DEVICE INF, V2, P1
   Sun Yi, 2015, Lin Chung Er Bi Yan Hou Tou Jing Wai Ke Za Zhi, V29, P1622
   Tajudeen BA, 2010, OTOL NEUROTOL, V31, P1254, DOI 10.1097/MAO.0b013e3181f2f475
   Thompson DC, 2001, JAMA-J AM MED ASSOC, V286, P2000, DOI 10.1001/jama.286.16.2000
   Tobey EA, 2013, INT J AUDIOL, V52, P219, DOI 10.3109/14992027.2012.759666
   Uziel AS, 2007, OTOL NEUROTOL, V28, P615, DOI 10.1097/01.mao.0000281802.59444.02
   WALTZMAN SB, 1994, AM J OTOL, V15, P9
   Waltzman SB, 1998, AM J OTOL, V19, P158
   Zhou LJ, 2007, CHIN SCI J HEARING S, V3, P41
NR 26
TC 0
Z9 1
U1 0
U2 3
PU LIPPINCOTT WILLIAMS & WILKINS
PI PHILADELPHIA
PA TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA
SN 0366-6999
EI 2542-5641
J9 CHINESE MED J-PEKING
JI Chin. Med. J.
PD AUG 20
PY 2019
VL 132
IS 16
BP 1925
EP 1934
DI 10.1097/CM9.0000000000000370
PG 10
WC Medicine, General & Internal
SC General & Internal Medicine
GA JA2SB
UT WOS:000487666200006
PM 31365431
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Ostrolenk, A
   Bao, VA
   Mottron, L
   Collignon, O
   Bertone, A
AF Ostrolenk, Alexia
   Bao, Vanessa A.
   Mottron, Laurent
   Collignon, Olivier
   Bertone, Armando
TI Reduced multisensory facilitation in adolescents and adults on the
   Autism Spectrum
SO SCIENTIFIC REPORTS
LA English
DT Article
ID SPEECH-PERCEPTION; INTEGRATION; CHILDREN; SCHIZOPHRENIA; PRINCIPLES;
   ATTENTION; DISORDER; RACE
AB Individuals with autism are reported to integrate information from visual and auditory channels in an idiosyncratic way. Multisensory integration (MSI) of simple, non-social stimuli (i.e., flashes and beeps) was evaluated in adolescents and adults with (n = 20) and without autism (n = 19) using a reaction time (RT) paradigm using audio, visual, and audiovisual stimuli. For each participant, the race model analysis compares the RTs on the audiovisual condition to a bound value computed from the unimodal RTs that reflects the effect of redundancy. If the actual audiovisual RTs are significantly faster than this bound, the race model is violated, indicating evidence of MSI. Our results show that the race model violation occurred only for the typically-developing (TD) group. While the TD group shows evidence of MSI, the autism group does not. These results suggest that multisensory integration of simple information, void of social content or complexity, is altered in autism. Individuals with autism may not benefit from the advantage conferred by multisensory stimulation to the same extent as TD individuals. Altered MSI for simple, non-social information may have cascading effects on more complex perceptual processes related to language and behaviour in autism.
C1 [Ostrolenk, Alexia; Bao, Vanessa A.; Bertone, Armando] McGill Univ, Perceptual Neurosci Lab Autism & Dev PNLab, Montreal, PQ, Canada.
   [Bao, Vanessa A.; Bertone, Armando] McGill Univ, Sch Appl Child Psychol, Dept Educ & Counselling Psychol, Montreal, PQ, Canada.
   [Ostrolenk, Alexia; Mottron, Laurent; Bertone, Armando] Univ Montreal, Ctr Excellence Pervas Dev Disorders CETEDUM, CIUSSS Nord De Ille Montreal, Montreal, PQ, Canada.
   [Collignon, Olivier] Univ Trento, Ctr Mind Brain Sci CIMeC, Trento, Italy.
   [Collignon, Olivier] Univ Louvain La Neuve, Inst Rech Psychol IPSY & Neurosci IoNS, Ottignies, Belgium.
RP Bertone, A (corresponding author), McGill Univ, Perceptual Neurosci Lab Autism & Dev PNLab, Montreal, PQ, Canada.; Bertone, A (corresponding author), McGill Univ, Sch Appl Child Psychol, Dept Educ & Counselling Psychol, Montreal, PQ, Canada.; Bertone, A (corresponding author), Univ Montreal, Ctr Excellence Pervas Dev Disorders CETEDUM, CIUSSS Nord De Ille Montreal, Montreal, PQ, Canada.
EM armando.bertone@mcgill.ca
RI Ostrolenk, Alexia/H-2020-2013
OI Ostrolenk, Alexia/0000-0002-0353-5786
CR American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   Bahrick L. E., 2010, BLACKWELL HDB INFANT, P120, DOI [10.1002/9781444327564.ch4, DOI 10.1002/9781444327564.CH4]
   Baker AEZ, 2008, J AUTISM DEV DISORD, V38, P867, DOI 10.1007/s10803-007-0459-0
   Bao VA, 2017, J AUTISM DEV DISORD, V47, P2535, DOI 10.1007/s10803-017-3172-7
   Barutchu A, 2009, DEVELOPMENTAL SCI, V12, P464, DOI 10.1111/j.1467-7687.2008.00782.x
   Bebko JM, 2014, AUTISM RES, V7, P50, DOI 10.1002/aur.1343
   Ben-Sasson A, 2009, J AUTISM DEV DISORD, V39, P1, DOI 10.1007/s10803-008-0593-3
   Brandwein AB, 2015, J AUTISM DEV DISORD, V45, P230, DOI 10.1007/s10803-014-2212-9
   Brandwein AB, 2013, CEREB CORTEX, V23, P1329, DOI 10.1093/cercor/bhs109
   Brandwein AB, 2011, CEREB CORTEX, V21, P1042, DOI 10.1093/cercor/bhq170
   Bremner A. J, 2012, MULTISENSORY DEV, P1, DOI DOI 10.1093/ACPROF:OSO/9780199586059.003.0001
   Brock J, 2002, DEV PSYCHOPATHOL, V14, P209, DOI 10.1017/S0954579402002018
   Calvert GA, 2004, J PHYSIOL-PARIS, V98, P191, DOI 10.1016/j.jphysparis.2004.03.018
   Charbonneau G, 2013, NEUROPSYCHOLOGIA, V51, P1002, DOI 10.1016/j.neuropsychologia.2013.02.009
   Chen YH, 2009, J AUTISM DEV DISORD, V39, P635, DOI 10.1007/s10803-008-0663-6
   Collignon O, 2013, CORTEX, V49, P1704, DOI 10.1016/j.cortex.2012.06.001
   de Boer-Schellekens L, 2013, NEUROPSYCHOLOGIA, V51, P3004, DOI 10.1016/j.neuropsychologia.2013.10.005
   Van de Cruys S, 2014, PSYCHOL REV, V121, P649, DOI 10.1037/a0037665
   De Gelder B, 2003, TRENDS COGN SCI, V7, P460, DOI 10.1016/j.tics.2003.08.014
   Fearon C, 2015, J PARKINSON DIS, V5, P925, DOI 10.3233/JPD-150655
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   Foxe JJ, 2015, CEREB CORTEX, V25, P298, DOI 10.1093/cercor/bht213
   Foxe JJ, 2009, BRAIN TOPOGR, V21, P149, DOI 10.1007/s10548-009-0102-9
   FRITH U, 1994, COGNITION, V50, P115, DOI 10.1016/0010-0277(94)90024-8
   Girard S, 2013, EXP BRAIN RES, V224, P275, DOI 10.1007/s00221-012-3308-0
   Gondan M, 2016, ATTEN PERCEPT PSYCHO, V78, P723, DOI 10.3758/s13414-015-1018-y
   Harrar V, 2014, CURR BIOL, V24, P531, DOI 10.1016/j.cub.2014.01.029
   Hazen EP, 2014, HARVARD REV PSYCHIAT, V22, P112, DOI 10.1097/01.HRP.0000445143.08773.58
   HERSHENSON M, 1962, J EXP PSYCHOL, V63, P289, DOI 10.1037/h0039516
   Hilton C, 2007, RES AUTISM SPECT DIS, V1, P164, DOI 10.1016/j.rasd.2006.10.002
   Iarocci G, 2006, J AUTISM DEV DISORD, V36, P77, DOI 10.1007/s10803-005-0044-3
   Iarocci G, 2010, AUTISM, V14, P305, DOI 10.1177/1362361309353615
   Kern JK, 2006, AUTISM, V10, P480, DOI 10.1177/1362361306066564
   Lane AE, 2010, J AUTISM DEV DISORD, V40, P112, DOI 10.1007/s10803-009-0840-2
   Lord C, 2000, NEURON, V28, P355, DOI 10.1016/S0896-6273(00)00115-X
   LORD C, 1994, J AUTISM DEV DISORD, V24, P659, DOI 10.1007/BF02172145
   LOVAAS I, 1987, J APPL BEHAV ANAL, V20, P45, DOI 10.1901/jaba.1987.20-45
   Mahoney JR, 2011, BRAIN RES, V1426, P43, DOI 10.1016/j.brainres.2011.09.017
   Marco EJ, 2011, PEDIATR RES, V69, p48R, DOI [10.1203/PDR.0b013e3182130c54, 10.1109/SPL.2011.5782616]
   MILLER J, 1982, COGNITIVE PSYCHOL, V14, P247, DOI 10.1016/0010-0285(82)90010-X
   Mongillo EA, 2008, J AUTISM DEV DISORD, V38, P1349, DOI 10.1007/s10803-007-0521-y
   Mottron L, 2006, J AUTISM DEV DISORD, V36, P27, DOI 10.1007/s10803-005-0040-7
   Mottron L, 2001, DEVELOPMENT OF AUTISM: PERSPECTIVES FROM THEORY AND RESEARCH, P131
   Silverman LB, 2010, COGNITION, V115, P380, DOI 10.1016/j.cognition.2010.01.002
   Smith EG, 2007, J CHILD PSYCHOL PSYC, V48, P813, DOI 10.1111/j.1469-7610.2007.01766.x
   Stein B. E., 1993, MERGING SENSES
   Stein B. E., 2011, NEW HDB MULTISENSORY
   Stevenson RA, 2018, AUTISM, V22, P609, DOI 10.1177/1362361317704413
   Stevenson RA, 2014, J AUTISM DEV DISORD, V44, P1470, DOI 10.1007/s10803-013-1992-7
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Taylor N, 2010, J AUTISM DEV DISORD, V40, P1403, DOI 10.1007/s10803-010-1000-4
   Ulrich R, 2007, BEHAV RES METHODS, V39, P291, DOI 10.3758/BF03193160
   van der Smagt MJ, 2007, J AUTISM DEV DISORD, V37, P2014, DOI 10.1007/s10803-006-0346-0
   Wechsler D., 2003, WECHSLER INTELLIGENC
   Wechsler D., 2008, WECHSLER ADULT INTEL, V22, P498
   Wechsler D, 2011, WASI 2 WECHSLER ABBR
   Williams LE, 2010, NEUROPSYCHOLOGIA, V48, P3128, DOI 10.1016/j.neuropsychologia.2010.06.028
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
   Wynn JK, 2014, COGN NEUROPSYCHIATRY, V19, P319, DOI 10.1080/13546805.2013.866892
   Zhang J, 2019, J AUTISM DEV DISORD, V49, P34, DOI 10.1007/s10803-018-3680-0
NR 60
TC 3
Z9 3
U1 0
U2 3
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD AUG 19
PY 2019
VL 9
AR 11965
DI 10.1038/s41598-019-48413-9
PG 9
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA IR6ZQ
UT WOS:000481590200006
PM 31427634
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Xie, ZL
   Zinszer, BD
   Riggs, M
   Beevers, CG
   Chandrasekaran, B
AF Xie, Zilong
   Zinszer, Benjamin D.
   Riggs, Meredith
   Beevers, Christopher G.
   Chandrasekaran, Bharath
TI Impact of depression on speech perception in noise
SO PLOS ONE
LA English
DT Article
ID INDUCED WORD MISPERCEPTIONS; ENERGETIC MASKING; MICROSCOPIC PREDICTION;
   INFORMATIONAL MASKING; ERROR PATTERNS; NORMAL-HEARING; RECOGNITION;
   DISTRACTIBILITY; LISTENERS; CORPUS
AB Effective speech communication is critical to everyday quality of life and social well-being. In addition to the well-studied deficits in cognitive and motor function, depression also impacts communication. Here, we examined speech perception in individuals who were clinically diagnosed with major depressive disorder (MDD) relative to neurotypical controls. Forty-two normal-hearing (NH) individuals with MDD and 41 NH neurotypical controls performed sentence recognition tasks across three conditions with maskers varying in the extent of linguistic content (high, low, and none): 1-talker masker (1T), reversed 1-talker masker (1T_tr), and speech-shaped noise (SSN). Individuals with MDD, relative to neurotypical controls, demonstrated lower recognition accuracy in the 1T condition but not in the 1T_tr or SSN condition. To examine the nature of the listening condition-specific speech perception deficit, we analyzed speech recognition errors. Errors as a result of interference from masker sentences were higher for individuals with MDD (vs. neurotypical controls) in the 1T condition. This depression-related listening condition-specific pattern in recognition errors was not observed for other error types. We posit that this depression-related listening condition-specific deficit in speech perception may be related to heightened distractibility due to linguistic interference from background talkers.
C1 [Xie, Zilong] Univ Maryland, Dept Hearing & Speech Sci, Baltimore, MD 21201 USA.
   [Zinszer, Benjamin D.] Univ Delaware, Dept Linguist & Cognit Sci, Newark, DE USA.
   [Riggs, Meredith] Univ Texas Austin, Dept Commun Sci & Disorders, Austin, TX 78712 USA.
   [Beevers, Christopher G.] Univ Texas Austin, Dept Psychol, Austin, TX 78712 USA.
   [Beevers, Christopher G.] Inst Mental Hlth Res, Austin, TX USA.
   [Chandrasekaran, Bharath] Univ Pittsburgh, Sch Hlth & Rehabil Sci, Dept Commun Sci & Disorders, Pittsburgh, PA 15260 USA.
RP Chandrasekaran, B (corresponding author), Univ Pittsburgh, Sch Hlth & Rehabil Sci, Dept Commun Sci & Disorders, Pittsburgh, PA 15260 USA.
EM b.chandra@pitt.edu
RI ; Beevers, Christopher/Z-1965-2019
OI Xie, Zilong/0000-0002-6851-7554; Beevers,
   Christopher/0000-0002-4480-0902
FU National Institute on Drug AbuseUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute on Drug Abuse (NIDA)European Commission [DA032457]; National
   Institute on Deafness and Other Communication DisordersUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01DC013315]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC013315,
   R01DC013315] Funding Source: NIH RePORTER
FX This work was supported by grant DA032457 to CGB from the National
   Institute on Drug Abuse (https://www.drugabuse.gov/) and grant
   R01DC013315 to BC from National Institute on Deafness and Other
   Communication Disorders (https://www.nidcd.nih.gov/).The funders had no
   role in study design, data collection and analysis, decision to publish,
   or preparation of the manuscript.
CR Arbogast TL, 2002, J ACOUST SOC AM, V112, P2086, DOI 10.1121/1.1510141
   Toth MA, 2015, J ACOUST SOC AM, V137, pEL184, DOI 10.1121/1.4905877
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Bamford J, 1979, SPEECH HEARING TESTS, P148
   Bates D., 2014, R PACKAGE VERSION LME4 LINEAR MIXED EF LME4 LINEAR MIXED EF, DOI DOI 10.18637/JSS.V067.I01
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Best V, 2011, J ACOUST SOC AM, V129, P1616, DOI 10.1121/1.3533733
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Brungart DS, 2001, J ACOUST SOC AM, V110, P2527, DOI 10.1121/1.1408946
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Cacciatore F, 1999, GERONTOLOGY, V45, P323, DOI 10.1159/000022113
   Chandrasekaran B, 2015, COGNITION EMOTION, V29, P900, DOI 10.1080/02699931.2014.944106
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   CORNBLATT BA, 1989, PSYCHIAT RES, V29, P65, DOI 10.1016/0165-1781(89)90188-1
   Cuijpers P, 2004, ACTA PSYCHIAT SCAND, V109, P325, DOI 10.1111/j.1600-0447.2004.00301.x
   Cummins N, 2015, SPEECH COMMUN, V71, P10, DOI 10.1016/j.specom.2015.03.004
   De Smedt T, 2012, J MACH LEARN RES, V13, P2063
   Desseilles M, 2009, J NEUROSCI, V29, P1395, DOI 10.1523/JNEUROSCI.3341-08.2009
   Durlach N, 2006, J ACOUST SOC AM, V120, P1787, DOI 10.1121/1.2335426
   Ferrari AJ, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0069637
   Fiske A, 2009, ANNU REV CLIN PSYCHO, V5, P363, DOI 10.1146/annurev.clinpsy.032408.153621
   Lecumberri MLG, 2016, INTERSPEECH, P640, DOI 10.21437/Interspeech.2016-330
   Geravanchizadeh M, 2015, J ACOUST SOC AM, V138, P4004, DOI 10.1121/1.4938230
   Hasin DS, 2005, ARCH GEN PSYCHIAT, V62, P1097, DOI 10.1001/archpsyc.62.10.1097
   Helfer KS, 2008, EAR HEARING, V29, P87, DOI 10.1097/AUD.0b013e31815d638b
   Helfer KS, 2016, J ACOUST SOC AM, V140, P3844, DOI 10.1121/1.4967297
   Helfer KS, 2014, J ACOUST SOC AM, V136, P748, DOI 10.1121/1.4887463
   Hothorn T., 2008, MULTCOMP SIMULTANEOU
   Jurgens T, 2009, J ACOUST SOC AM, V126, P2635, DOI 10.1121/1.3224721
   Keidser G, 2015, INT J AUDIOL, V54, P653, DOI 10.3109/14992027.2015.1046503
   Koelewijn T, 2014, J ACOUST SOC AM, V135, P1596, DOI 10.1121/1.4863198
   Lam BPW, 2017, J SPEECH LANG HEAR R, P1, DOI [10.1121/1.4960483, DOI 10.1121/1.4960483]
   Lemelin S, 1997, J NERV MENT DIS, V185, P542, DOI 10.1097/00005053-199709000-00002
   Lepisto T, 2004, CLIN NEUROPHYSIOL, V115, P620, DOI 10.1016/j.clinph.2003.10.020
   Levenshtein VI, 1966, SOV PHYS DOKL, V10, P707, DOI DOI 10.1109/TVCG.2012.323
   Lewinsohn PM, 2000, J ABNORM PSYCHOL, V109, P345, DOI 10.1037//0021-843X.109.2.345
   Li CM, 2014, JAMA OTOLARYNGOL, V140, P293, DOI 10.1001/jamaoto.2014.42
   Luppa M, 2012, J AFFECT DISORDERS, V136, P212, DOI 10.1016/j.jad.2010.11.033
   Marxer R, 2016, J ACOUST SOC AM, V140, pEL458, DOI 10.1121/1.4967185
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   MILLER WR, 1975, PSYCHOL BULL, V82, P238, DOI 10.1037/h0076367
   Mundt JC, 2012, BIOL PSYCHIAT, V72, P580, DOI 10.1016/j.biopsych.2012.03.015
   Nachtegaal J, 2009, EAR HEARING, V30, P302, DOI 10.1097/AUD.0b013e31819c6e01
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   Phatak SA, 2007, J ACOUST SOC AM, V121, P2312, DOI 10.1121/1.2642397
   POGUEGEILE MF, 1980, J ABNORM PSYCHOL, V89, P115, DOI 10.1037/0021-843X.89.2.115
   RADLOFF L S, 1977, Applied Psychological Measurement, V1, P385, DOI 10.1177/014662167700100306
   Rajan R, 2008, NEUROSCIENCE, V154, P784, DOI 10.1016/j.neuroscience.2008.03.067
   Reetzke R, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168048
   Riggs M, 2018, SPIN SCORCERER
   Roberts RE, 1997, J GERONTOL B-PSYCHOL, V52, pS252, DOI 10.1093/geronb/52B.5.S252
   Saito H, 2010, J AM GERIATR SOC, V58, P93, DOI 10.1111/j.1532-5415.2009.02615.x
   Sheehan DV, 1998, J CLIN PSYCHIAT, V59, P34, DOI 10.4088/JCP.09m05305whi
   Shinn-Cunningham BG, 2008, TRENDS COGN SCI, V12, P182, DOI 10.1016/j.tics.2008.02.003
   Smith KG, 2017, J ACOUST SOC AM, V142, pEL306, DOI 10.1121/1.5003916
   Snyder HR., 2013, MAJOR DEPRESSIVE DIS
   Stone MA, 2016, J ACOUST SOC AM, V140, P832, DOI 10.1121/1.4960483
   Stone MA, 2012, J ACOUST SOC AM, V132, P317, DOI 10.1121/1.4725766
   Team RC, 2014, R LANG ENV STAT COMP
   Van Engen KJ, 2012, LANG COGNITIVE PROC, V27, P1089, DOI 10.1080/01690965.2012.654644
   Van Engen KJ, 2010, LANG SPEECH, V53, P510, DOI 10.1177/0023830910372495
   Xie ZL, 2015, NEUROPSYCHOLOGIA, V67, P121, DOI 10.1016/j.neuropsychologia.2014.12.013
   Xie ZL, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114439
   Zinszer BD, 2019, J ACOUST SOC AM, V145, pEL129, DOI 10.1121/1.5087271
NR 65
TC 0
Z9 0
U1 1
U2 5
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD AUG 15
PY 2019
VL 14
IS 8
AR e0220928
DI 10.1371/journal.pone.0220928
PG 17
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA IW5KK
UT WOS:000485017200047
PM 31415624
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Cervera-Crespo, T
   Gonzalez-Alvarez, J
AF Cervera-Crespo, Teresa
   Gonzalez-Alvarez, Julio
TI Speech Perception: Phonological Neighborhood Effects on Word Recognition
   Persist Despite Semantic Sentence Context
SO PERCEPTUAL AND MOTOR SKILLS
LA English
DT Article
DE auditory word recognition; phonological proximity; sentence context
ID SPOKEN WORDS; MODEL; COMPETITION; ACTIVATION
AB This study tested the hypothesis that two lexical properties, both phonological neighborhood density (ND) and neighborhood frequency (NF), influence the recognition of target words when preceded by either a semantically congruent or semantically neutral context. Our study is the first to test this hypothesis using a language other than English (i.e., Spanish). We used highly familiar bisyllabic nouns with medium-frequency occurrence as target words, and we expected recognition accuracy to increase as ND and NF decreased in both semanticallly congruent and semantically neutral sentences. We presented 48 undergraduate listeners with a set of 80 words, differing in ND and NF, within these two sentence contexts (i.e., 160 sentences). We then tested the relationships between ND, NF, and variations in semantic sentence context within a linear logistic model and found that words with a low frequency of neighbors were more likely to be correctly recognized in both sentence contexts. Thus, during word recognition, the influence of phonological competition outweighed semantic sentence context even when words were presented in Spanish.
C1 [Cervera-Crespo, Teresa; Gonzalez-Alvarez, Julio] Univ Valencia, Dept Basic Psychol, Blasco Ibanez 21, Valencia 46010, Spain.
   [Gonzalez-Alvarez, Julio] Univ Jaume 1, Dept Basic & Clin Psychol & Psychobiol, Castellon de La Plana, Spain.
RP Cervera-Crespo, T (corresponding author), Univ Valencia, Dept Basic Psychol, Blasco Ibanez 21, Valencia 46010, Spain.
EM Teresa.Cervera@uv.es
RI Gonzalez-Alvarez, Julio/C-6114-2011
OI Gonzalez-Alvarez, Julio/0000-0002-0389-5263
FU Spanish Ministry of Economy and Competitiveness [FFI2017-84951-P]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This study
   was supported by the Spanish Ministry of Economy and Competitiveness
   (Research Grant FFI2017-84951-P).
CR Amano S., 2000, NEIGHBORHOOD COHORT
   [Anonymous], 2010, AM PSYCHOL, V65, P493, DOI [10.1037/a0020168, DOI 10.1037/a0020168]
   Brock J, 2014, Q J EXP PSYCHOL, V67, P114, DOI 10.1080/17470218.2013.791331
   Cervera T., 2010, PERCEPT MOTOR SKILL, V111, P1
   Duchon A, 2013, BEHAV RES METHODS, V45, P1246, DOI 10.3758/s13428-013-0326-1
   Dufour S, 2010, Q J EXP PSYCHOL, V63, P226, DOI 10.1080/17470210903308336
   Forster K. I., 1978, EXPLORATIONS BIOL LA, P139, DOI 10.1017/S0022267000684
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   GOLDINGER SD, 1989, J MEM LANG, V28, P501, DOI 10.1016/0749-596X(89)90009-0
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Luce PA, 2000, PERCEPT PSYCHOPHYS, V62, P615, DOI 10.3758/BF03212113
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   MARSLENWILSON W, 1980, COGNITION, V8, P1, DOI 10.1016/0010-0277(80)90015-3
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Sommers MS, 1999, PSYCHOL AGING, V14, P458, DOI 10.1037/0882-7974.14.3.458
   Taler V, 2010, J GERONTOL B-PSYCHOL, V65, P551, DOI 10.1093/geronb/gbq039
   Vitevitch M. S., 2009, INFLUENCE NEIGHBORHO
   Vitevitch Michael S, 2004, J Multiling Commun Disord, V3, P64, DOI 10.1080/14769670400027332
   Vitevitch MS, 2016, ANNU REV LINGUIST, V2, P75, DOI 10.1146/annurev-linguistics-030514-124832
   Vitevitch MS, 2002, LANG SPEECH, V45, P407, DOI 10.1177/00238309020450040501
   ZWITSERLOOD P, 1989, COGNITION, V32, P25, DOI 10.1016/0010-0277(89)90013-9
NR 22
TC 0
Z9 0
U1 0
U2 2
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0031-5125
EI 1558-688X
J9 PERCEPT MOTOR SKILL
JI Percept. Mot. Skills
PD DEC
PY 2019
VL 126
IS 6
BP 1047
EP 1057
AR 0031512519870032
DI 10.1177/0031512519870032
EA AUG 2019
PG 11
WC Psychology, Experimental
SC Psychology
GA IW8VQ
UT WOS:000483565700001
PM 31412741
DA 2021-02-24
ER

PT J
AU Rodvik, AK
   Tvete, O
   Torkildsen, JV
   Wie, OB
   Skaug, I
   Silvola, JT
AF Rodvik, Arne Kirkhorn
   Tvete, Ole
   Torkildsen, Janne von Koss
   Wie, Ona Bo
   Skaug, Ingebjorg
   Silvola, Juha Tapio
TI Consonant and Vowel Confusions in Well-Performing Children and
   Adolescents With Cochlear Implants, Measured by a Nonsense Syllable
   Repetition Test
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE cochlear implants; speech perception; speech sound confusions;
   consonants; vowels; hearing
ID SPEECH-PERCEPTION SKILLS; LANGUAGE-DEVELOPMENT; RECOGNITION; HEARING;
   WORD; SENSITIVITY; NOISE; AGE; IMPROVEMENT; LISTENERS
AB Although the majority of early implanted, profoundly deaf children with cochlear implants (CIs), will develop correct pronunciation if they receive adequate oral language stimulation, many of them have difficulties with perceiving minute details of speech. The main aim of this study is to measure the confusion of consonants and vowels in well-performing children and adolescents with CIs. The study also aims to investigate how age at onset of severe to profound deafness influences perception. The participants are 36 children and adolescents with CIs (18 girls), with a mean (SD) age of 11.6 (3.0) years (range: 5.9-16.0 years). Twenty-nine of them are prelingually deaf and seven are postlingually deaf. Two reference groups of normal-hearing (NH) 6- and 13-year-olds are included. Consonant and vowel perception is measured by repetition of 16 bisyllabic vowel-consonant-vowel nonsense words and nine monosyllabic consonant-vowel-consonant nonsense words in an open-set design. For the participants with CIs, consonants were mostly confused with consonants with the same voicing and manner, and the mean (SD) voiced consonant repetition score, 63.9 (10.6)%, was considerably lower than the mean (SD) unvoiced consonant score, 76.9 (9.3)%. There was a devoicing bias for the stops; unvoiced stops were confused with other unvoiced stops and not with voiced stops, and voiced stops were confused with both unvoiced stops and other voiced stops. The mean (SD) vowel repetition score was 85.2 (10.6)% and there was a bias in the confusions of [i:] and [y:]; [y:] was perceived as [i:] twice as often as [y:] was repeated correctly. Subgroup analyses showed no statistically significant differences between the consonant scores for pre- and postlingually deaf participants. For the NH participants, the consonant repetition scores were substantially higher and the difference between voiced and unvoiced consonant repetition scores considerably lower than for the participants with CIs. The participants with CIs obtained scores close to ceiling on vowels and real-word monosyllables, but their perception was substantially lower for voiced consonants. This may partly be related to limitations in the CI technology for the transmission of low-frequency sounds, such as insertion depth of the electrode and ability to convey temporal information.
C1 [Rodvik, Arne Kirkhorn; Torkildsen, Janne von Koss; Wie, Ona Bo; Silvola, Juha Tapio] Univ Oslo, Inst Educ Sci, Dept Special Needs Educ, Oslo, Norway.
   [Rodvik, Arne Kirkhorn; Tvete, Ole; Wie, Ona Bo; Silvola, Juha Tapio] Oslo Univ Hosp, Dept Otothinokaryngol, Div Surg & Clin Neurosci, Cochlear Implant Unit, Oslo, Norway.
   [Skaug, Ingebjorg] Cochletten Fdn, Oslo, Norway.
   [Silvola, Juha Tapio] Akershus Univ Hosp, Ear Nose & Throat Dept, Div Surg, Lorenskog, Norway.
RP Rodvik, AK (corresponding author), Univ Oslo, Inst Educ Sci, Dept Special Needs Educ, Oslo, Norway.; Rodvik, AK (corresponding author), Oslo Univ Hosp, Dept Otothinokaryngol, Div Surg & Clin Neurosci, Cochlear Implant Unit, Oslo, Norway.
EM a.k.rodvik@isp.uio.no
RI Rodvik, Arne K/AAE-5303-2019
CR Arisi E, 2010, OTOLARYNG HEAD NECK, V142, P804, DOI 10.1016/j.otohns.2010.02.016
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bruijnzeel H, 2016, AUDIOL NEURO-OTOL, V21, P113, DOI 10.1159/000443363
   Buckley KA, 2011, EAR HEARING, V32, P2, DOI [10.1097/AUD.0b013e3181e8534c, 10.1097/AUD.0b013e3181fa41bb]
   Caldwell MT, 2017, LARYNGOSCOPE INVEST, V2, P119, DOI 10.1002/lio2.71
   Ching TYC, 2018, INT J AUDIOL, V57, pS70, DOI 10.1080/14992027.2017.1346307
   Clopper CG, 2006, J AM ACAD AUDIOL, V17, P331, DOI 10.3766/jaaa.17.5.4
   Coady JA, 2004, J EXP CHILD PSYCHOL, V89, P183, DOI 10.1016/j.jecp.2004.07.004
   D'Alessandro HD, 2018, EAR HEARING, V39, P679, DOI 10.1097/AUD.0000000000000525
   DARLEY FL, 1961, J SPEECH HEAR DISORD, V26, P272, DOI 10.1044/jshd.2603.272
   Dettman SJ, 2016, OTOL NEUROTOL, V37, pE82, DOI 10.1097/MAO.0000000000000915
   DiNino M, 2016, J ACOUST SOC AM, V140, P4404, DOI 10.1121/1.4971420
   Donaldson GS, 2006, EAR HEARING, V27, P658, DOI 10.1097/01.aud.0000240543.31567.54
   Dorman MF, 1997, J ACOUST SOC AM, V102, P2403, DOI 10.1121/1.419603
   DOYLE K, 1995, AM J OTOL, V16, P676
   Drullman R., 2005, FP6004171 HEARCOM FR
   Elley WB, 1992, WORLD DO STUDENTS RE
   Engdahl B, 2005, INT J AUDIOL, V44, P213, DOI 10.1080/14992020500057731
   Fant G., 1973, SPEECH SOUNDS FEATUR
   Feng GY, 2018, P NATL ACAD SCI USA, V115, pE1022, DOI 10.1073/pnas.1717603115
   Findlen UM, 2011, J AM ACAD AUDIOL, V22, P13, DOI 10.3766/jaaa.22.1.3
   Fischer B, 2004, DYSLEXIA, V10, P105, DOI 10.1002/dys.268
   Freed D., 2001, SPEECH UTILITY COMPU
   Gathercole S E, 1994, Memory, V2, P103, DOI 10.1080/09658219408258940
   Geers A, 2003, EAR HEARING, V24, p24S, DOI 10.1097/01.AUD.0000051687.99218.0F
   Halvorsen B., 1998, THESIS
   Hamzavi J, 2006, ACTA OTO-LARYNGOL, V126, P1182, DOI 10.1080/00016480600672683
   Harrison RV, 2005, DEV PSYCHOBIOL, V46, P252, DOI 10.1002/dev.20052
   Henry KS, 2012, NAT NEUROSCI, V15, P1362, DOI 10.1038/nn.3216
   Kral A, 2013, NEUROSCIENCE, V247, P117, DOI 10.1016/j.neuroscience.2013.05.021
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   Kristoffersen G., 2000, PHONOLOGY NORWEGIAN
   KUROWSKI K, 1984, J ACOUST SOC AM, V76, P383, DOI 10.1121/1.391139
   LEAKE PA, 1988, HEARING RES, V33, P11, DOI 10.1016/0378-5955(88)90018-4
   Leigh J, 2013, OTOL NEUROTOL, V34, P443, DOI 10.1097/MAO.0b013e3182814d2c
   Lisker L., 1981, HASKINS LABORATORIES, V65, P251
   Litovsky R. Y., 2015, HDB CLIN NEUROLOGY
   Liu HH, 2015, INT J PEDIATR OTORHI, V79, P1677, DOI 10.1016/j.ijporl.2015.07.023
   Locke J. L., 1983, PHONOLOGICAL ACQUISI
   MAXON AB, 1982, EAR HEARING, V3, P301, DOI 10.1097/00003446-198211000-00003
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Moreno-Torres I, 2018, J ACOUST SOC AM, V144, P69, DOI 10.1121/1.5044416
   Munson B, 2003, J ACOUST SOC AM, V113, P925, DOI 10.1121/1.1536630
   Myhrum M, 2017, EAR HEARING, V38, P301, DOI 10.1097/AUD.0000000000000383
   National Institute for Occupational Safety and Health [NIOSH], 1996, DRAFT CRIT REC STAND
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Oygarden J, 2009, THESIS
   Rodvik AK, 2018, J SPEECH LANG HEAR R, V61, P1023, DOI 10.1044/2018_JSLHR-H-16-0463
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Sharma A, 2002, ANN OTO RHINOL LARYN, V111, P38
   Sharma A, 2002, NEUROREPORT, V13, P1365, DOI 10.1097/00001756-200207190-00030
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   Sheffield BM, 2012, J ACOUST SOC AM, V131, P518, DOI 10.1121/1.3662074
   Sommers MS, 1997, EAR HEARING, V18, P89, DOI 10.1097/00003446-199704000-00001
   Svirsky MA, 2015, ACTA OTO-LARYNGOL, V135, P354, DOI 10.3109/00016489.2014.1002052
   Tingleff H., 2002, NORSK FONEMTEST
   Tobey EA, 2013, INT J AUDIOL, V52, P219, DOI 10.3109/14992027.2012.759666
   TREHUB SE, 1988, J EXP CHILD PSYCHOL, V46, P273, DOI 10.1016/0022-0965(88)90060-4
   TYEMURRAY N, 1990, EAR HEARING, V11, P195, DOI 10.1097/00003446-199006000-00005
   TYEMURRAY N, 1995, J ACOUST SOC AM, V98, P2454, DOI 10.1121/1.413278
   TYLER RS, 1990, AM J OTOL, V11, P99
   TYLER RS, 1992, J ACOUST SOC AM, V92, P3068, DOI 10.1121/1.404203
   Valimaa TT, 2002, J SPEECH LANG HEAR R, V45, P1055, DOI 10.1044/1092-4388(2002/085)
   van Wieringen A, 1999, EAR HEARING, V20, P89, DOI 10.1097/00003446-199904000-00001
   WERNEROLSHO L, 1988, J ACOUST SOC AM, V84, P1316, DOI 10.1121/1.396630
   Wie OB, 2010, INT J PEDIATR OTORHI, V74, P1258, DOI 10.1016/j.ijporl.2010.07.026
   Wilson BS, 2008, J REHABIL RES DEV, V45, P695, DOI 10.1682/JRRD.2007.10.0173
   WMA. World Medical Association, 2017, WMA DECL HELS ETH PR
   Wolfe J, 2011, OTOL NEUROTOL, V32, P533, DOI 10.1097/MAO.0b013e318210b6ec
   World Health Organisation, 2019, GRAD HEAR IMP
   Wouters J, 2015, IEEE SIGNAL PROC MAG, V32, P67, DOI 10.1109/MSP.2014.2371671
   Yoon YS, 2012, J SPEECH LANG HEAR R, V55, P105, DOI 10.1044/1092-4388(2011/10-0325)
   Zeitler DM, 2012, ARCH PEDIAT ADOL MED, V166, P35, DOI 10.1001/archpediatrics.2011.574
NR 73
TC 0
Z9 0
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD AUG 14
PY 2019
VL 10
AR 1813
DI 10.3389/fpsyg.2019.01813
PG 17
WC Psychology, Multidisciplinary
SC Psychology
GA IQ4SX
UT WOS:000480742000001
PM 31474900
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Gehrig, J
   Michalareas, G
   Forster, MT
   Lei, J
   Hok, P
   Laufs, H
   Senft, C
   Seifert, V
   Schoffelen, JM
   Hanslmayr, S
   Kell, CA
AF Gehrig, Johannes
   Michalareas, Georgios
   Forster, Marie-Therese
   Lei, Juan
   Hok, Pavel
   Laufs, Helmut
   Senft, Christian
   Seifert, Volker
   Schoffelen, Jan-Mathijs
   Hanslmayr, Simon
   Kell, Christian A.
TI Low-Frequency Oscillations Code Speech during Verbal Working Memory
SO JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE electrocorticography; memory representations; sentence repetition;
   speech perception; speech production; temporal pattern similarity
ID TIME-COMPRESSED SPEECH; BRAIN OSCILLATIONS; COMPUTATIONAL PRINCIPLES;
   CORTICAL OSCILLATIONS; CORTEX ACTIVITY; TOP-DOWN; DYNAMICS; BETA;
   SYNCHRONIZATION; RHYTHMS
AB The way the human brain represents speech in memory is still unknown. An obvious characteristic of speech is its evolvement over time. During speech processing, neural oscillations are modulated by the temporal properties of the acoustic speech signal, but also acquired knowledge on the temporal structure of language influences speech perception-related brain activity. This suggests that speech could be represented in the temporal domain, a form of representation that the brain also uses to encode autobiographic memories. Empirical evidence for such a memory code is lacking. We investigated the nature of speech memory representations using direct cortical recordings in the left perisylvian cortex during delayed sentence reproduction in female and male patients undergoing awake tumor surgery. Our results reveal that the brain endogenously represents speech in the temporal domain. Temporal pattern similarity analyses revealed that the phase of frontotemporal low-frequency oscillations, primarily in the beta range, represents sentence identity in working memory. The positive relationship between beta power during working memory and task performance suggests that working memory representations benefit from increased phase separation.
C1 [Gehrig, Johannes; Lei, Juan; Hok, Pavel; Laufs, Helmut; Kell, Christian A.] Goethe Univ, Dept Neurol, D-60528 Frankfurt, Germany.
   [Michalareas, Georgios] Max Planck Inst Empir Aesthet, D-60322 Frankfurt, Germany.
   [Forster, Marie-Therese; Senft, Christian; Seifert, Volker] Goethe Univ, Dept Neurosurg, D-60528 Frankfurt, Germany.
   [Lei, Juan] Goethe Univ, Inst Cell Biol & Neurosci, D-60438 Frankfurt, Germany.
   [Hok, Pavel] Palacky Univ, Dept Neurol, Olomouc 77147, Czech Republic.
   [Hok, Pavel] Univ Hosp Olomouc, Olomouc 77147, Czech Republic.
   [Laufs, Helmut] Univ Kiel, Dept Neurol, D-24105 Kiel, Germany.
   [Schoffelen, Jan-Mathijs] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, NL-6525 HR Nijmegen, Netherlands.
   [Hanslmayr, Simon] Univ Birmingham, Sch Psychol, Birmingham B15 2TT, W Midlands, England.
RP Kell, CA (corresponding author), Goethe Univ, Dept Neurol, D-60528 Frankfurt, Germany.
EM c.kell@em.uni-frankfurt.de
RI Hanslmayr, Simon/AAF-8995-2020; Senft, Christian/F-4252-2010; Hok,
   Pavel/K-8224-2017; Forster, Marie-Therese/AAY-5616-2020
OI Hanslmayr, Simon/0000-0003-4448-2147; Senft,
   Christian/0000-0003-1288-6913; Hok, Pavel/0000-0003-1010-384X;
   Michalareas, Georgios/0000-0002-8196-3049
FU Deutsche Research Foundation [KE1514/2-1]; Medical Faculty of Goethe
   University
FX This work was supported by Deutsche Research Foundation Grant KE1514/2-1
   to C.A.K. and the Medical Faculty of Goethe University. We thank
   Benjamin Morillon, Nadine Jahn, Stefanie Borchardt, and Jana Gessert for
   support; and Anne-Lise Giraud and Wolf Singer for reviewing an earlier
   version of the manuscript.
CR Alderson-Day B, 2015, PSYCHOL BULL, V141, P931, DOI 10.1037/bul0000021
   Arnal LH, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00225
   Ashburner J, 2007, NEUROIMAGE, V38, P95, DOI 10.1016/j.neuroimage.2007.07.007
   Baddeley A, 2003, J COMMUN DISORD, V36, P189, DOI 10.1016/S0021-9924(03)00019-4
   Bastiaansen M, 2010, J COGNITIVE NEUROSCI, V22, P1333, DOI 10.1162/jocn.2009.21283
   Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038
   Behroozmand R, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00109
   Bonhage CE, 2017, NEUROIMAGE, V152, P647, DOI 10.1016/j.neuroimage.2017.03.018
   Bonhage CE, 2014, J COGNITIVE NEUROSCI, V26, P1654, DOI 10.1162/jocn_a_00566
   Bouchard KE, 2013, NATURE, V495, P327, DOI 10.1038/nature11911
   Bouton S, 2018, P NATL ACAD SCI USA, V115, pE1299, DOI 10.1073/pnas.1714279115
   Bressler SL, 2015, CURR OPIN NEUROBIOL, V31, P62, DOI 10.1016/j.conb.2014.08.010
   Buchsbaum BR, 2008, J COGNITIVE NEUROSCI, V20, P762, DOI 10.1162/jocn.2008.20501
   Busch RM, 2015, NEUROLOGY, V85, P1475, DOI 10.1212/WNL.0000000000002066
   Buschman TJ, 2007, SCIENCE, V315, P1860, DOI 10.1126/science.1138071
   Buzsaki G., 2006, RHYTHMS BRAIN
   Cheung C, 2016, ELIFE, V5, DOI 10.7554/eLife.12577
   Cogan GB, 2017, NAT NEUROSCI, V20, P279, DOI 10.1038/nn.4459
   Cogan GB, 2014, NATURE, V507, P94, DOI 10.1038/nature12935
   Courtemanche R, 2003, J NEUROSCI, V23, P11741
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   Ding N, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00311
   Duzel E, 2010, CURR OPIN NEUROBIOL, V20, P143, DOI 10.1016/j.conb.2010.01.004
   Flinker A, 2010, J NEUROSCI, V30, P16643, DOI 10.1523/JNEUROSCI.1809-10.2010
   Fujioka T, 2012, J NEUROSCI, V32, P1791, DOI 10.1523/JNEUROSCI.4107-11.2012
   Ghitza O, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00130
   Ghitza O, 2009, PHONETICA, V66, P113, DOI 10.1159/000208934
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Gompf F, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00582
   Grabner G, 2006, LECT NOTES COMPUT SC, V4191, P58
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Hanslmayr S, 2014, CURR BIOL, V24, P904, DOI 10.1016/j.cub.2014.03.007
   Henson RN, 2014, TRENDS COGN SCI, V18, P376, DOI 10.1016/j.tics.2014.03.004
   Herff C, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00217
   Herman AB, 2013, J NEUROSCI, V33, P5439, DOI 10.1523/JNEUROSCI.1472-12.2013
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158
   Howe MW, 2011, P NATL ACAD SCI USA, V108, P16801, DOI 10.1073/pnas.1113158108
   Indefrey P, 2004, COGNITION, V92, P101, DOI 10.1016/j.cognition.2002.06.001
   Jacquemot C, 2006, TRENDS COGN SCI, V10, P480, DOI 10.1016/j.tics.2006.09.002
   Korzeniewska A, 2011, NEUROIMAGE, V56, P2218, DOI 10.1016/j.neuroimage.2011.03.030
   Kriegeskorte N, 2008, FRONT SYST NEUROSCI, V2, DOI 10.3389/neuro.06.004.2008
   Kubanek J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053398
   Lachaux JP, 1999, HUM BRAIN MAPP, V8, P194, DOI 10.1002/(SICI)1097-0193(1999)8:4<194::AID-HBM4>3.0.CO;2-C
   Lam NHL, 2016, NEUROIMAGE, V142, P43, DOI 10.1016/j.neuroimage.2016.03.007
   Lee JH, 2015, J NEUROSCI, V35, P15000, DOI 10.1523/JNEUROSCI.0629-15.2015
   Lotte F, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00097
   Lundqvist M, 2018, J NEUROSCI, V38, P7013, DOI 10.1523/JNEUROSCI.2485-17.2018
   Lundqvist M, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-017-02791-8
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Mercier MR, 2017, NEUROIMAGE, V147, P219, DOI 10.1016/j.neuroimage.2016.08.037
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Michalareas G, 2016, NEURON, V89, P384, DOI 10.1016/j.neuron.2015.12.018
   Michelmann S, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002528
   Miller EK, 2018, NEURON, V100, P463, DOI 10.1016/j.neuron.2018.09.023
   Murakami T, 2015, J NEUROSCI, V35, P1411, DOI 10.1523/JNEUROSCI.0246-14.2015
   Nelson MJ, 2017, P NATL ACAD SCI USA, V114, pE3669, DOI 10.1073/pnas.1701590114
   Nourski KV, 2009, J NEUROSCI, V29, P15564, DOI 10.1523/JNEUROSCI.3065-09.2009
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   Pei XM, 2011, NEUROIMAGE, V54, P2960, DOI 10.1016/j.neuroimage.2010.10.029
   Pena M, 2012, J COGNITIVE NEUROSCI, V24, P1149, DOI 10.1162/jocn_a_00144
   Perrone-Bertolotti M, 2014, BEHAV BRAIN RES, V261, P220, DOI 10.1016/j.bbr.2013.12.034
   POTTER MC, 1990, J MEM LANG, V29, P633, DOI 10.1016/0749-596X(90)90042-X
   Potter MC, 1998, J MEM LANG, V38, P265, DOI 10.1006/jmla.1997.2546
   Rimmele JM, 2015, CORTEX, V68, P144, DOI 10.1016/j.cortex.2014.12.014
   Roelfsema PR, 1997, NATURE, V385, P157, DOI 10.1038/385157a0
   Salazar RF, 2012, SCIENCE, V338, P1097, DOI 10.1126/science.1224000
   Siegel M, 2009, P NATL ACAD SCI USA, V106, P21341, DOI 10.1073/pnas.0908193106
   Staudigl T, 2015, J NEUROSCI, V35, P5373, DOI 10.1523/JNEUROSCI.4198-14.2015
   Tang C, 2017, SCIENCE, V357, P797, DOI 10.1126/science.aam8577
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   Waldhauser GT, 2015, CEREB CORTEX, V25, P4180, DOI 10.1093/cercor/bhu138
   Wang XJ, 2010, PHYSIOL REV, V90, P1195, DOI 10.1152/physrev.00035.2008
   Yaffe RB, 2014, P NATL ACAD SCI USA, V111, P18727, DOI 10.1073/pnas.1417017112
NR 79
TC 3
Z9 4
U1 0
U2 4
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
SN 0270-6474
EI 1529-2401
J9 J NEUROSCI
JI J. Neurosci.
PD AUG 14
PY 2019
VL 39
IS 33
BP 6498
EP 6512
DI 10.1523/JNEUROSCI.0018-19.2019
PG 15
WC Neurosciences
SC Neurosciences & Neurology
GA IR6SY
UT WOS:000481570300010
PM 31196933
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Karas, PJ
   Magnotti, JF
   Metzger, BA
   Zhu, LL
   Smith, KB
   Yoshor, D
   Beauchamp, MS
AF Karas, Patrick J.
   Magnotti, John F.
   Metzger, Brian A.
   Zhu, Lin L.
   Smith, Kristen B.
   Yoshor, Daniel
   Beauchamp, Michael S.
TI The visual speech head start improves perception and reduces superior
   temporal cortex responses to auditory speech
SO ELIFE
LA English
DT Article
ID SURFACE-BASED ANALYSIS; VOICE; MODULATION; PREDICTION; SOFTWARE; BRAIN;
   NOISE
AB Visual information about speech content from the talker's mouth is often available before auditory information from the talker's voice. Here we examined perceptual and neural responses to words with and without this visual head start. For both types of words, perception was enhanced by viewing the talker's face, but the enhancement was significantly greater for words with a head start. Neural responses were measured from electrodes implanted over auditory association cortex in the posterior superior temporal gyrus (pSTG) of epileptic patients. The presence of visual speech suppressed responses to auditory speech, more so for words with a visual head start. We suggest that the head start inhibits representations of incompatible auditory phonemes, increasing perceptual accuracy and decreasing total neural responses. Together with previous work showing visual cortex modulation (Ozker et al., 2018b) these results from pSTG demonstrate that multisensory interactions are a powerful modulator of activity throughout the speech perception network.
C1 [Karas, Patrick J.; Magnotti, John F.; Metzger, Brian A.; Zhu, Lin L.; Smith, Kristen B.; Yoshor, Daniel; Beauchamp, Michael S.] Baylor Coll Med, Dept Neurosurg, Houston, TX 77030 USA.
RP Beauchamp, MS (corresponding author), Baylor Coll Med, Dept Neurosurg, Houston, TX 77030 USA.
EM michael.beauchamp@bcm.edu
RI Beauchamp, Michael/AAK-9813-2020
OI Beauchamp, Michael/0000-0002-7599-9934; Zhu, Lin/0000-0001-6260-2515;
   Magnotti, John/0000-0003-2093-0603; Karas, Patrick/0000-0002-2605-8820
FU National Institute of Neurological Disorders and StrokeUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute of Neurological Disorders & Stroke (NINDS)
   [R01NS065395, R25NS070694, R24MH117529, U01NS098976, F30DC014911];
   NATIONAL INSTITUTE OF MENTAL HEALTHUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute of Mental Health (NIMH) [R24MH117529, R24MH117529,
   R24MH117529] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF
   NEUROLOGICAL DISORDERS AND STROKEUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute of Neurological Disorders & Stroke (NINDS) [R25NS070694,
   R01NS065395, R25NS070694, R01NS065395, U01NS098976, U01NS113339,
   R25NS070694, R01NS065395, U01NS113339, R01NS065395, U01NS098976,
   R01NS065395, U01NS098976] Funding Source: NIH RePORTER; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [F30DC014911] Funding Source: NIH RePORTER
FX National Institute of Neurological Disorders and Stroke R01NS065395
   Michael S Beauchamp; National Institute of Neurological Disorders and
   Stroke R25NS070694 Patrick J Karas Daniel Yoshor; National Institute of
   Mental Health R24MH117529 Michael S Beauchamp; National Institute of
   Neurological Disorders and Stroke U01NS098976 Michael S Beauchamp;
   National Institute on Deafness and Other Communication Disorders
   F30DC014911 Lin L Zhu; The funders had no role in study design, data
   collection and interpretation, or the decision to submit the work for
   publication.
CR Argall BD, 2006, HUM BRAIN MAPP, V27, P14, DOI 10.1002/hbm.20158
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beauchamp MS, 2004, NAT NEUROSCI, V7, P1190, DOI 10.1038/nn1333
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Bernstein LE, 2004, SPEECH COMMUN, V44, P5, DOI 10.1016/j.specom.2004.10.011
   Bernstein LE, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00386
   Bernstein LE, 2011, HUM BRAIN MAPP, V32, P1660, DOI 10.1002/hbm.21139
   Bernstein LE, 2008, BRAIN RES, V1242, P172, DOI 10.1016/j.brainres.2008.04.018
   Besle J, 2008, J NEUROSCI, V28, P14301, DOI 10.1523/JNEUROSCI.2875-08.2008
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Cappelletta L, 2012, P 1 INT C PATT REC A
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Cohen M.X., 2014, ANAL NEURAL TIME SER, DOI [10.7551/mitpress/9609.001.0001, DOI 10.7551/MITPRESS/9609.001.0001]
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   Crosse MJ, 2016, J NEUROSCI, V36, P9888, DOI 10.1523/JNEUROSCI.1396-16.2016
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   David SV, 2009, J NEUROSCI, V29, P3374, DOI 10.1523/JNEUROSCI.5249-08.2009
   Denham SL, 2020, EUR J NEUROSCI, V51, P1151, DOI 10.1111/ejn.13802
   Ferraro S, 2019, BIORXIV, DOI [10.1101/549733, DOI 10.1101/549733]
   Fischl B, 1999, NEUROIMAGE, V9, P195, DOI 10.1006/nimg.1998.0396
   Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318
   Ghazanfar AA, 2006, TRENDS COGN SCI, V10, P278, DOI 10.1016/j.tics.2006.04.008
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Grill-Spector K, 2006, TRENDS COGN SCI, V10, P14, DOI 10.1016/j.tics.2005.11.006
   Hamilton LS, 2018, CURR BIOL, V28, P1860, DOI 10.1016/j.cub.2018.04.033
   Hickok G, 2018, CORTEX, V103, P360, DOI 10.1016/j.cortex.2018.03.030
   Hickok Gregory, 2015, Handb Clin Neurol, V129, P149, DOI 10.1016/B978-0-444-62630-1.00008-1
   Holmes CJ, 1998, J COMPUT ASSIST TOMO, V22, P324, DOI 10.1097/00004728-199803000-00032
   Jeffers J., 1971, SPEECHREADING LIPREA
   Kayser C, 2008, CEREB CORTEX, V18, P1560, DOI 10.1093/cercor/bhm187
   Kleiner M, 2007, PERCEPTION, V36, P14
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Leaver AM, 2016, J NEUROSCI, V36, P1416, DOI 10.1523/JNEUROSCI.0226-15.2016
   Ma WJ, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004638
   Magnotti JF, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-36772-8
   Magnotti JF, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005229
   Magnotti JF, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00798
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Megevand P, 2019, BIORXIV, DOI [10.1101/405597, DOI 10.1101/405597]
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Neti C., 2000, AUDIO VISUAL SPEECH
   Okada K, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068959
   Ozker M, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00141
   Ozker M, 2018, ELIFE, V7, DOI 10.7554/eLife.30387
   Ozker M, 2017, J COGNITIVE NEUROSCI, V29, P1044, DOI 10.1162/jocn_a_01110
   Peelle JE, 2015, CORTEX, V68, P169, DOI 10.1016/j.cortex.2015.03.006
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   R Development Core Team, 2017, R LANG ENV STAT COMP
   Rennig J., 2018, FACE VIEWING BEHAV P, P1, DOI [10.1101/331306, DOI 10.1101/331306]
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Salmelin R, 2007, CLIN NEUROPHYSIOL, V118, P237, DOI 10.1016/j.clinph.2006.07.316
   Sanchez-Garcia C, 2018, MULTISENS RES, V31, P57, DOI 10.1163/22134808-00002560
   Schepers IM, 2015, CEREB CORTEX, V25, P4103, DOI 10.1093/cercor/bhu127
   Schwartz JL, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003743
   Shahin AJ, 2018, J NEUROSCI, V38, P1835, DOI 10.1523/JNEUROSCI.1566-17.2017
   Sohoglu E, 2016, P NATL ACAD SCI USA, V113, pE1747, DOI 10.1073/pnas.1523266113
   Stasenko A, 2015, COGN NEUROPSYCHOL, V32, P38, DOI 10.1080/02643294.2015.1035702
   Strand JF, 2019, PSYCHON B REV, V26, P291, DOI 10.3758/s13423-018-1489-7
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Warren SG, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms6643
   Zhu LL, 2017, J NEUROSCI, V37, P2697, DOI 10.1523/JNEUROSCI.2914-16.2017
NR 65
TC 5
Z9 5
U1 0
U2 5
PU ELIFE SCIENCES PUBLICATIONS LTD
PI CAMBRIDGE
PA SHERATON HOUSE, CASTLE PARK, CAMBRIDGE, CB3 0AX, ENGLAND
SN 2050-084X
J9 ELIFE
JI eLife
PD AUG 8
PY 2019
VL 8
AR e48116
DI 10.7554/eLife.48116
PG 19
WC Biology
SC Life Sciences & Biomedicine - Other Topics
GA IP8NH
UT WOS:000480302600001
PM 31393261
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Turker, S
   Reiterer, SM
   Schneider, P
   Seither-Preisler, A
AF Turker, Sabrina
   Reiterer, Susanne Maria
   Schneider, Peter
   Seither-Preisler, Annemarie
TI Auditory Cortex Morphology Predicts Language Learning Potential in
   Children and Teenagers
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE auditory cortex morphology; language aptitude; Heschl's gyrus; foreign
   language learning; working memory; arithmetic fluency
ID SHORT-TERM-MEMORY; WORKING-MEMORY; MUSICAL APTITUDE; SPEECH-PERCEPTION;
   HESCHLS GYRUS; SKILLS; LATERALIZATION; PRONUNCIATION; SENSITIVITY;
   PROFICIENCY
AB In two recent studies, we identified neuroanatomical and neurofunctional markers of musical aptitude, attention deficit (hyperactivity) disorder and dyslexia in the auditory cortex (AC) of children. In a subsequent study with adults, we found evidence for neuroanatomical correlates of speech imitation ability in right Heschl's gyrus (HG), a structure comprising primary and parts of secondary AC. In the present study, we aimed to verify this previously suggested link between structural variation of right HG and language aptitude in a younger population of children and teenagers (N = 42; age range: 10-16 years), while behaviorally exploring the relationship between language aptitude, working memory, arithmetic skills and musicality. Behaviorally, scores on the language aptitude battery strongly correlated with working memory and speech imitation ability. Furthermore, we found that self-and parent-reported language aptitude and school grades were closely associated with language aptitude scores. Neuroanatomical analyses revealed a significant relationship between the occurrence of multiple HGs and high gray matter (GM) volumes in right AC and high language aptitude regardless of age, gender or musical ability. Additionally, low language aptitude was associated with the occurrence of single gyri in right AC. In accordance with previous research, we suggest that right HG might be associated with language aptitude, with a stronger gyrification and higher GM volumes being beneficial for successful auditory processing and the integration of speech-related cues.
C1 [Turker, Sabrina; Seither-Preisler, Annemarie] Karl Franzens Univ Graz, Ctr Systemat Musicol, Graz, Austria.
   [Reiterer, Susanne Maria] Univ Vienna, Dept Linguist, Vienna, Austria.
   [Schneider, Peter] Heidelberg Univ Hosp, Dept Neuroradiol, Sect Biomagnetism, Heidelberg, Germany.
   [Seither-Preisler, Annemarie] Karl Franzens Univ Graz, BioTechMed Graz, Graz, Austria.
RP Turker, S (corresponding author), Karl Franzens Univ Graz, Ctr Systemat Musicol, Graz, Austria.; Reiterer, SM (corresponding author), Univ Vienna, Dept Linguist, Vienna, Austria.
EM turker.sabrina@gmail.com; Susanne.Reiterer@univie.ac.at
FU German Federal Ministry of Education and Research (BMBF)Federal Ministry
   of Education & Research (BMBF) [01KJ0809/10, 01KJ1204]; German Research
   Foundation (DFG) as part of the Heisenberg programGerman Research
   Foundation (DFG); Austrian Academy of Sciences
FX This work was supported by the German Federal Ministry of Education and
   Research (BMBF) as Grants 01KJ0809/10 and 01KJ1204 (project: "AMseL:
   Audio-and Neuroplasticity of Musical Learning I + II", part of the
   accompanying research of the cultural education program " An Instrument
   for Every Child") and by the German Research Foundation (DFG) as part of
   the Heisenberg program ("Sound perception between outstanding musical
   abilities and auditory dysfunction: the neural basis of individual
   predisposition, maturation, and learning-induced plasticity in a
   lifespan perspective"). Furthermore, ST is a recipient of a
   DOC-team-fellowship of the Austrian Academy of Sciences.
CR Ameringer V., 2018, EXPLORING LANGUAGE A, P1
   Baddeley A, 1998, PSYCHOL REV, V105, P158, DOI 10.1037/0033-295X.105.1.158
   Baddeley A, 2003, J COMMUN DISORD, V36, P189, DOI 10.1016/S0021-9924(03)00019-4
   Baddeley A, 2003, NAT REV NEUROSCI, V4, P829, DOI 10.1038/nrn1201
   Baddeley A., 1974, PSYCHOL LEARN MOTIV, V8, P47, DOI [10.1016/S0079-7421(08)60452-1, DOI 10.1016/S0079-7421(08)60452-1]
   Baddeley AD, 2017, SECOND LANG RES, V33, P299, DOI 10.1177/0267658317709852
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Benner J, 2017, BRAIN STRUCT FUNCT, V222, P3587, DOI 10.1007/s00429-017-1419-x
   Benner U., 2005, THESIS
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   Caroll J. B., 1962, TRAINING RES ED, P87
   Carroll J. B., 1990, LANGUAGE APTITUDE RE, P11
   Carroll J. B., 1959, MODERN LANGUAGE APTI
   CARROLL JB, 1973, LINGUISTICS, P1
   CATTELL RB, 1963, J EDUC PSYCHOL, V54, P1, DOI 10.1037/h0046743
   Chiron C, 1997, BRAIN, V120, P1057, DOI 10.1093/brain/120.6.1057
   Chobert J, 2013, BRAIN SCI, V3, P923, DOI 10.3390/brainsci3020923
   Dehaene-Lambertz G, 2008, EUR REV, V16, P399, DOI DOI 10.1017/S1062798708000513
   Dehaene-Lambertz G, 2006, P NATL ACAD SCI USA, V103, P14240, DOI 10.1073/pnas.0606302103
   DeStefano D, 2004, EUR J COGN PSYCHOL, V16, P353, DOI 10.1080/09541440244000328
   Dirks E, 2008, J LEARN DISABIL-US, V41, P460, DOI 10.1177/0022219408321128
   Dogil G, 2009, TALENT BRAIN ACTIVIT
   Dornyei Z., 2014, PSYCHOL LANGUAGE LEA
   Ellis NC, 1996, Q J EXP PSYCHOL-A, V49, P234, DOI 10.1080/027249896392883
   Field A., 2013, DISCOVERING STAT USI
   Flinker A, 2019, NAT HUM BEHAV, V3, P393, DOI 10.1038/s41562-019-0548-z
   French J. W., 1963, MANUAL KIT REFERENCE
   Friederici AD, 2013, CURR OPIN NEUROBIOL, V23, P250, DOI 10.1016/j.conb.2012.10.002
   Gagne F, 2004, HIGH ABIL STUD, V15, P119, DOI 10.1080/1359813042000314682
   Gagne F., 2005, CONCEPTIONS GIFTEDNE, P98, DOI [DOI 10.1017/CBO9780511610455, 10.1017/cbo9780511610455.008]
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Golestani N, 2002, NEURON, V35, P997, DOI 10.1016/S0896-6273(02)00862-0
   Golestani N, 2007, CEREB CORTEX, V17, P929, DOI 10.1093/cercor/bhl003
   Golestani N, 2007, CEREB CORTEX, V17, P575, DOI 10.1093/cercor/bhk001
   Golestani N, 2011, J NEUROSCI, V31, P4213, DOI 10.1523/JNEUROSCI.3891-10.2011
   Gordon Edwin, 1989, ADV MEASURES MUSIC A
   Granena G, 2019, STUD SECOND LANG ACQ, V41, P313, DOI 10.1017/S0272263118000256
   Hanson J, 2019, J RES MUSIC EDUC, V67, P193, DOI 10.1177/0022429418819165
   Herholz SC, 2012, NEURON, V76, P486, DOI 10.1016/j.neuron.2012.10.011
   Homae F, 2007, NEUROSCI RES, V59, P29, DOI 10.1016/j.neures.2007.05.005
   Hu XC, 2013, BRAIN LANG, V127, P366, DOI 10.1016/j.bandl.2012.11.006
   Hulshoff-Pol HE, 2006, J NEUROSCI, V26, P10235, DOI 10.1523/JNEUROSCI.1312-06.2006
   Hyde KL, 2008, NEUROPSYCHOLOGIA, V46, P632, DOI 10.1016/j.neuropsychologia.2007.09.004
   Hyde KL, 2009, J NEUROSCI, V29, P3019, DOI 10.1523/JNEUROSCI.5118-08.2009
   Jackendoff R, 2009, MUSIC PERCEPT, V26, P195, DOI 10.1525/MP.2009.26.3.195
   Jancke L, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00123
   Kempe V, 2015, BRIT J PSYCHOL, V106, P349, DOI 10.1111/bjop.12092
   Kepinska O, 2018, NEUROIMAGE, V165, P1, DOI 10.1016/j.neuroimage.2017.09.058
   Kepinska O, 2017, NEUROBIOL LEARN MEM, V144, P96, DOI 10.1016/j.nlm.2017.07.003
   Kepinska O, 2017, BEHAV BRAIN RES, V320, P333, DOI 10.1016/j.bbr.2016.12.015
   Kepinska O, 2017, NEUROPSYCHOLOGIA, V98, P156, DOI 10.1016/j.neuropsychologia.2016.06.014
   Kormos J, 2008, BILING-LANG COGN, V11, P261, DOI 10.1017/S1366728908003416
   Leaver AM, 2010, J NEUROSCI, V30, P7604, DOI 10.1523/JNEUROSCI.0296-10.2010
   LeFevre JA, 2010, CHILD DEV, V81, P1753, DOI 10.1111/j.1467-8624.2010.01508.x
   Lehrl S., 1992, KURZTEST ALLGEMEINE
   Leong V, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00096
   Liem F, 2014, HUM BRAIN MAPP, V35, P1779, DOI 10.1002/hbm.22291
   Linck JA, 2013, LANG LEARN, V63, P530, DOI 10.1111/lang.12011
   Magne C, 2016, BRAIN LANG, V153, P13, DOI 10.1016/j.bandl.2016.01.001
   Marie D, 2017, LANG COGN NEUROSCI, V32, P870, DOI 10.1080/23273798.2016.1250926
   McGettigan C, 2012, TRENDS COGN SCI, V16, P269, DOI 10.1016/j.tics.2012.04.006
   Meara P., 2005, LLAMA LANGUAGE APTIT
   Milovanou R, 2008, BRAIN RES, V1194, P81, DOI 10.1016/j.brainres.2007.11.042
   Milovanov R., 2009, CONNECTIVITY MUSICAL
   Milovanov R, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00321
   Milovanov R, 2009, NEUROSCI LETT, V460, P161, DOI 10.1016/j.neulet.2009.05.063
   Mullensiefan D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089642
   Ortega L., 2014, UNDERSTANDING 2 LANG
   PAPAGNO C, 1991, J MEM LANG, V30, P331, DOI 10.1016/0749-596X(91)90040-Q
   Patel A.D., 2012, LANGUAGE MUSIC COGNI, P204
   Patel AD, 2003, NAT NEUROSCI, V6, P674, DOI 10.1038/nn1082
   Peng P, 2016, J EDUC PSYCHOL, V108, P455, DOI 10.1037/edu0000079
   Penhune VB, 2011, CORTEX, V47, P1126, DOI 10.1016/j.cortex.2011.05.010
   Perani D, 2011, P NATL ACAD SCI USA, V108, P16056, DOI 10.1073/pnas.1102991108
   Poeppel D, 2004, NEUROPSYCHOLOGIA, V42, P183, DOI 10.1016/j.neuropsychologia.2003.07.010
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Poeppel D, 2001, COGNITIVE SCI, V25, P679, DOI 10.1016/S0364-0213(01)00050-7
   Reiterer S. M., 2018, EXPLORING LANGUAGE A
   Reiterer SM, 2005, NEUROREPORT, V16, P239, DOI 10.1097/00001756-200502280-00007
   Reiterer S, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00334
   Ressel V, 2012, J NEUROSCI, V32, P16597, DOI 10.1523/JNEUROSCI.1996-12.2012
   Rimfeld K, 2015, TRANSL PSYCHIAT, V5, DOI 10.1038/tp.2015.128
   Rogers V. E., 2016, EUROSLA YB, V16, P179, DOI [10.1075/eurosla.16.07rog, DOI 10.1075/EUROSLA.16.07ROG]
   Schirmer A, 2012, NEUROIMAGE, V63, P137, DOI 10.1016/j.neuroimage.2012.06.025
   Schneider P, 2005, ANN NY ACAD SCI, V1060, P387, DOI 10.1196/annals.1360.033
   Schneider P, 2002, NAT NEUROSCI, V5, P688, DOI 10.1038/nn871
   Schneider P., 2015, BILDUNGSFORSCHUNG, V41, P19
   Seither-Preisler A, 2014, J NEUROSCI, V34, P10937, DOI 10.1523/JNEUROSCI.5315-13.2014
   Serrallach B, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00324
   Sheng JW, 2019, CEREB CORTEX, V29, P3232, DOI 10.1093/cercor/bhy191
   Simmons FR, 2008, DYSLEXIA, V14, P77, DOI 10.1002/dys.341
   Skehan P, 1986, SPOKEN LANGUAGE, P95
   Skehan P., 1998, COGNITIVE APPROACH L
   Skehan P., 2002, INDIVIDUAL DIFFERENC, P69, DOI DOI 10.1075/LLLT.2
   Slevc LR, 2006, PSYCHOL SCI, V17, P675, DOI 10.1111/j.1467-9280.2006.01765.x
   Sternberg Robert, 2002, INDIVIDUAL DIFFERENC, P1343, DOI DOI 10.1075/LLLT.2
   Talairach J, 1988, COPLANAR STEREOTAXIC
   Turker S., 2018, EXPLORING LANGUAGE A, P119
   Turker S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02096
   Vangehuchten L, 2015, REV LINGUIST LENGUAS, V10, P90, DOI 10.4995/rlyla.2015.3372
   Vogel S.E., 2017, J NUMERICAL COGNITIO, V3, P288, DOI DOI 10.5964/JNC.V3I2.55
   Vukovic RK, 2013, LEARN INDIVID DIFFER, V23, P87, DOI 10.1016/j.lindif.2012.10.007
   Weiss R. H., 2008, GRUNDINTELLIGENZTEST
   Wen ZS, 2011, ILHA DESTERRO, V60, P15
   Wen ZS, 2012, ELT J, V66, P233, DOI 10.1093/elt/ccr068
   Wen Z, 2017, LANG TEACHING, V50, P1, DOI 10.1017/S0261444816000276
   Wengenroth M, 2014, CEREB CORTEX, V24, P1127, DOI 10.1093/cercor/bhs391
   Wengenroth M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0012326
   Zatorre RJ, 2001, J NEUROSCI, V21, P6321
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
   Zatorre RJ, 2013, SCIENCE, V342, P585, DOI 10.1126/science.1238414
   Zoellner S, 2019, HUM BRAIN MAPP, V40, P1139, DOI 10.1002/hbm.24434
NR 112
TC 4
Z9 4
U1 1
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD AUG 7
PY 2019
VL 13
AR 824
DI 10.3389/fnins.2019.00824
PG 16
WC Neurosciences
SC Neurosciences & Neurology
GA IO1SH
UT WOS:000479161700003
PM 31447639
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Narayan, CR
AF Narayan, Chandan R.
TI An acoustic perspective on 45 years of infant speech perception, Part 1:
   Consonants
SO LANGUAGE AND LINGUISTICS COMPASS
LA English
DT Article
ID CROSS-LANGUAGE; LINGUISTIC EXPERIENCE; ONSET TIME; DISCRIMINATION;
   PLACE; DISTINCTION; ADULTS; TRANSITIONS; CONFUSIONS; CONTRASTS
AB In this two-part review, we examine major results from infant consonant (Part 1), vowel, and suprasegmental (Part 2) discrimination research over the past 45 years from an acoustic perspective-an exegesis of the developmental speech perception literature that appeals to both acoustic aspects of speech contrasts and historically relevant typological facts about the sound systems of the world's languages. We argue that infants' speech discrimination abilities are best viewed through a lens that considers both synchronic and diachronic aspects of the particular speech contrast. The key to this approach is the notion that acoustic-perceptual salience, or the relative separation of speech categories along perceptually relevant acoustic dimensions and corresponding discrimination performance in adults, is reflected in both infants perceptual performance and patterns observed in phonological typology and history. The review highlights challenges presented by four decades of literature, identifies broad patterns in infant consonant perception according to the acoustic properties of speech contrasts, and offers linguistically motivated explanations and directions for future research into the nature of young infants' discrimination abilities.
C1 [Narayan, Chandan R.] York Univ, Dept Languages Literatures & Linguist, Speech & Psycholinguist Lab, Toronto, ON, Canada.
RP Narayan, CR (corresponding author), York Univ, Dept Languages Literatures & Linguist, Speech & Psycholinguist Lab, Toronto, ON, Canada.
EM chandann@yorku.ca
OI Narayan, Chandan/0000-0003-0782-3467
CR Agnew ZK, 2011, J COGNITIVE NEUROSCI, V23, P4038, DOI 10.1162/jocn_a_00106
   AHMED R, 1969, J ACOUST SOC AM, V45, P758, DOI 10.1121/1.1911459
   ALLEN GD, 1985, J CHILD LANG, V12, P37, DOI 10.1017/S0305000900006218
   Aslin R. N., 1980, CHILD PHONOLOGY, V2, P67
   Benki J. R., 2005, P 4 INT S BIL, P240
   Bergmann C, 2018, CHILD DEV, V89, P1996, DOI 10.1111/cdev.13079
   BERTONCINI J, 1987, J ACOUST SOC AM, V82, P31, DOI 10.1121/1.395570
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Best CT, 1999, PSYCHOL SCI, V10, P65, DOI 10.1111/1467-9280.00108
   Browman Catherine, 1986, PHONOLOGY YB, V3, P219, DOI DOI 10.1017/S0952675700000658
   BURNHAM DK, 1986, APPL PSYCHOLINGUIST, V7, P207, DOI 10.1017/S0142716400007542
   Chang S. C., 2001, ROLE SPEECH PERCEPTI
   Christdas P., 1988, THESIS
   Cristia A, 2011, J PHONETICS, V39, P388, DOI 10.1016/j.wocn.2011.02.004
   Dave R., 1977, ANN REPORTS I PHONET, V11, P27
   EILERS RE, 1977, J SPEECH HEAR RES, V20, P766, DOI 10.1044/jshr.2004.766
   EILERS RE, 1979, CHILD DEV, V50, P14
   EILERS RE, 1984, J CHILD LANG, V11, P313, DOI 10.1017/S0305000900005791
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   EIMAS PD, 1975, PERCEPT PSYCHOPHYS, V18, P341, DOI 10.3758/BF03211210
   EIMAS PD, 1974, PERCEPT PSYCHOPHYS, V16, P513, DOI 10.3758/BF03198580
   EIMAS PD, 1980, SCIENCE, V209, P1140, DOI 10.1126/science.7403875
   Fuchs S., 2007, P ICPHS, P449
   GANDOUR J, 1986, J CHILD LANG, V13, P561
   GOTO H, 1971, NEUROPSYCHOLOGIA, V9, P317, DOI 10.1016/0028-3932(71)90027-3
   Guion SG, 1998, PHONETICA, V55, P18
   Hamann Silke, 2003, THESIS
   Hamilton Philip J., 1996, THESIS
   HILLENBRAND J, 1984, J ACOUST SOC AM, V75, P1613, DOI 10.1121/1.390871
   HOLMBERG TL, 1977, J ACOUST SOC AM, V62, pS99, DOI 10.1121/1.2016488
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   JUSCZYK PW, 1978, PERCEPT PSYCHOPHYS, V23, P105, DOI 10.3758/BF03208289
   JUSCZYK PW, 1977, PERCEPT PSYCHOPHYS, V21, P450, DOI 10.3758/BF03199501
   KEATING P, 1983, J PHONETICS, V11, P277, DOI 10.1016/S0095-4470(19)30827-7
   KLUENDER KR, 1991, J ACOUST SOC AM, V90, P83, DOI 10.1121/1.402285
   Krishnamurti B., 2003, DRAVIDIAN LANGUAGES
   Kuhl P. K., 1985, MEASUREMENT AUDITION, P223
   KUHL PK, 1983, J ACOUST SOC AM, V73, P1003, DOI 10.1121/1.389148
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   KUROWSKI K, 1987, J ACOUST SOC AM, V81, P1917, DOI 10.1121/1.394756
   Ladefoged P., 1968, PHONETIC STUDY W AFR
   LARKEY LS, 1978, PERCEPT PSYCHOPHYS, V23, P299, DOI 10.3758/BF03199713
   LASKY RE, 1975, J EXP CHILD PSYCHOL, V20, P215, DOI 10.1016/0022-0965(75)90099-5
   LAWRENCE DL, 1969, J SPEECH HEAR RES, V12, P426, DOI 10.1044/jshr.1202.426
   LEVITT A, 1988, J EXP PSYCHOL HUMAN, V14, P361
   Li MX, 2017, LAB PHONOL, V8, DOI 10.5334/labphon.27
   LIBERMAN AM, 1958, LANG SPEECH, V1, P153, DOI 10.1177/002383095800100301
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Maddieson I., 1984, PATTERNS SOUNDS
   Masica C. P., 1993, INDOARYAN LANGUAGES
   Mayo C, 2005, J ACOUST SOC AM, V118, P1730, DOI 10.1121/1.1979451
   McGuire G. L., 2007, THESIS
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   MILLER JL, 1979, PERCEPT PSYCHOPHYS, V25, P457, DOI 10.3758/BF03213823
   MIYAWAKI K, 1975, PERCEPT PSYCHOPHYS, V18, P331, DOI 10.3758/BF03211209
   MORSE PA, 1972, J EXP CHILD PSYCHOL, V14, P477, DOI 10.1016/0022-0965(72)90066-5
   Narayan C., 2013, ORIGINS SOUND CHANGE, P128
   Narayan CR, 2008, J PHONETICS, V36, P191, DOI 10.1016/j.wocn.2007.10.001
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Narayanan S, 1999, J ACOUST SOC AM, V106, P1993, DOI 10.1121/1.427946
   Nittrouer S, 2001, J ACOUST SOC AM, V110, P1598, DOI 10.1121/1.1379078
   Nowak PM, 2006, J PHONETICS, V34, P139, DOI 10.1016/j.wocn.2005.03.001
   Ohala M., 2001, TRAVAUX CERCLE LINGU, P265
   OLLER DK, 1993, PHONETICA, V50, P1
   Phatak SA, 2008, J ACOUST SOC AM, V124, P1220, DOI 10.1121/1.2913251
   PISONI DB, 1977, J ACOUST SOC AM, V61, P1352, DOI 10.1121/1.381409
   Polka L, 2001, J ACOUST SOC AM, V109, P2190, DOI 10.1121/1.1362689
   REPP BH, 1979, LANG SPEECH, V22, P173, DOI 10.1177/002383097902200207
   Simonet M., 2008, SEL P 3 C LAB APPR S, P72
   SINNOTT JM, 1976, J ACOUST SOC AM, V60, P687, DOI 10.1121/1.381140
   SMIT AB, 1990, J SPEECH HEAR DISORD, V55, P29
   STEVENS KN, 1974, J ACOUST SOC AM, V55, P653, DOI 10.1121/1.1914578
   Stevens KN, 1998, ACOUSTIC PHONETICS
   STREETER LA, 1976, NATURE, V259, P39, DOI 10.1038/259039a0
   Sundara M, 2018, COGNITION, V178, P57, DOI 10.1016/j.cognition.2018.05.009
   Sussman JE, 2001, J ACOUST SOC AM, V109, P1173, DOI 10.1121/1.1349428
   TREHUB SE, 1976, CHILD DEV, V47, P466, DOI 10.2307/1128803
   Tsushima T, 1994, 3 INT C SPOK LANG PR
   WANG MD, 1973, J ACOUST SOC AM, V54, P1248, DOI 10.1121/1.1914417
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
   Whalen DH, 2007, J PHONETICS, V35, P341, DOI 10.1016/j.wocn.2006.10.001
   WHALEN DH, 1991, J ACOUST SOC AM, V90, P1776, DOI 10.1121/1.401658
   Zhao SY, 2010, J ACOUST SOC AM, V128, P2009, DOI 10.1121/1.3478856
   Zhou XH, 2008, J ACOUST SOC AM, V123, P4466, DOI 10.1121/1.2902168
   Zygis M, 2010, J PHONETICS, V38, P207, DOI 10.1016/j.wocn.2009.10.003
NR 87
TC 1
Z9 1
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1749-818X
J9 LANG LINGUIST COMPAS
JI Lang. Linguist. Compass
PD OCT
PY 2019
VL 13
IS 10
AR e12352
DI 10.1111/lnc3.12352
EA AUG 2019
PG 17
WC Language & Linguistics
SC Linguistics
GA JG2YX
UT WOS:000478898600001
DA 2021-02-24
ER

PT J
AU Sarant, J
   Harris, D
   Busby, P
   Maruff, P
   Schembri, A
   Dowell, R
   Briggs, R
AF Sarant, Julia
   Harris, David
   Busby, Peter
   Maruff, Paul
   Schembri, Adrian
   Dowell, Richard
   Briggs, Robert
TI The Effect of Cochlear Implants on Cognitive Function in Older Adults:
   Initial Baseline and 18-Month Follow Up Results for a Prospective
   International Longitudinal Study
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE cognitive decline; hearing loss; cochlear implants; executive function;
   visual attention; education; age; speech perception
ID QUALITY-OF-LIFE; REPORTED HEARING-LOSS; ALZHEIMERS-DISEASE;
   PHYSICAL-ACTIVITY; DEPRESSIVE SYMPTOMS; GENDER-DIFFERENCES; VASCULAR
   DEMENTIA; SOCIAL NETWORKS; SENSORY LOSS; DEAF ADULTS
AB In older adults, hearing loss is independently associated with an increased rate of cognitive decline, and has been identified to be a modifiable risk factor for dementia. The mechanism underlying the cognitive decline associated with hearing loss is not understood, but it is known that the greater the hearing loss, the faster the rate of decline. It is unknown whether remediation of hearing loss with hearing devices can delay cognitive decline. This 5-year international longitudinal study is investigating the impact of cochlear implants on cognitive function in older people with severe-profound hearing loss, and whether remediation of hearing loss could delay the onset of cognitive impairment. This is the first study to examine the major primary risk factors associated with dementia in the same cohort. Participants were assessed before cochlear implantation and 18 months later using an identical battery including a visually presented cognitive assessment tool (Cogstate battery) that is highly sensitive to small changes in cognition and suitable for use with people with hearing loss. Hearing and speech perception ability were assessed in sound-treated conditions by an audiologist, and a range of questionnaire tools was administered to assess self-perceived ease of listening, quality of life, physical activity, diet, social and emotional loneliness, isolation, anxiety, and depression. A detailed medical health history was taken. Pre-operatively, despite the small initial sample size (n = 59), increased hearing loss and age predicted significantly poorer executive function and visual attention, while tertiary education predicted better executive function. Better self-reported quality of life was correlated with better visual learning performance, and engaging in frequent vigorous physical activity was correlated with poorer visual learning performance. At 18 months, for the first 20 participants, significant benefits of cochlear implants were seen in terms of speech perception, communication ability, and quality of life. Multiple linear regression modeling showed executive function improved significantly for non-tertiary educated males, while cognitive function remained stable for other participants. Further follow-up at 18 month intervals with a larger sample will reveal the effects of cochlear implant intervention on all outcomes, and whether this can delay cognitive decline.
C1 [Sarant, Julia; Busby, Peter; Dowell, Richard] Univ Melbourne, Dept Audiol & Speech Pathol, Melbourne, Vic, Australia.
   [Harris, David] Univ Melbourne, Dept Econ, Melbourne, Vic, Australia.
   [Maruff, Paul; Schembri, Adrian] Cogstate Ltd, Melbourne, Vic, Australia.
   [Briggs, Robert] Royal Victorian Eye & Ear Hosp, Melbourne, Vic, Australia.
RP Sarant, J (corresponding author), Univ Melbourne, Dept Audiol & Speech Pathol, Melbourne, Vic, Australia.
EM jsarant@unimelb.edu.au
RI Maruff, Paul/ABA-1673-2020; Maruff, Paul/AAD-2454-2021; Dowell,
   Richard/AAX-7046-2020
OI Maruff, Paul/0000-0002-6947-9537; Harris, David/0000-0002-4237-6888
FU Australian Research CouncilAustralian Research Council [LP 150101180];
   Cochlear Ltd.
FX This research was supported by Australian Research Council Linkage Grant
   LP 150101180 and by Cochlear Ltd., with in-kind support from the Royal
   Victorian Eye and Ear Hospital.
CR Amieva H, 2015, J AM GERIATR SOC, V63, P2099, DOI 10.1111/jgs.13649
   Andersen K, 1999, NEUROLOGY, V53, P1992, DOI 10.1212/WNL.53.9.1992
   Anstey K, 2000, GERONTOLOGY, V46, P163, DOI 10.1159/000022153
   Arlinger S, 2003, INT J AUDIOL, V42, pS17
   Barnes LL, 2004, NEUROLOGY, V63, P2322, DOI 10.1212/01.WNL.0000147473.04043.B3
   Bennett DA, 2006, LANCET NEUROL, V5, P406, DOI 10.1016/S1474-4422(06)70417-3
   Bherer Louis, 2013, J Aging Res, V2013, P657508, DOI 10.1155/2013/657508
   Blamey P, 2013, AUDIOL NEURO-OTOL, V18, P36, DOI 10.1159/000343189
   Brown AD, 2010, NEUROBIOL AGING, V31, P2047, DOI 10.1016/j.neurobiolaging.2008.11.002
   Cacciatore F, 1999, GERONTOLOGY, V45, P323, DOI 10.1159/000022113
   Cambridge Cognition Limited, 2012, CANTAB ECL TEST ADM
   Campbell J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00071
   Chen JH, 2009, J FORMOS MED ASSOC, V108, P754, DOI 10.1016/S0929-6646(09)60402-2
   Chene G, 2015, ALZHEIMERS DEMENT, V11, P310, DOI 10.1016/j.jalz.2013.10.005
   Chia EM, 2007, EAR HEARING, V28, P187, DOI 10.1097/AUD.0b013e31803126b6
   COBB JL, 1995, NEUROLOGY, V45, P1707, DOI 10.1212/WNL.45.9.1707
   Cohen SM, 2004, OTOLARYNG HEAD NECK, V131, P413, DOI 10.1016/j.otohns.2004.03.026
   Collie A, 2003, CLIN J SPORT MED, V13, P28, DOI 10.1097/00042752-200301000-00006
   COX RM, 1995, EAR HEARING, V16, P176, DOI 10.1097/00003446-199504000-00005
   Craig CL, 2003, MED SCI SPORT EXER, V35, P1381, DOI 10.1249/01.MSS.0000078924.61453.FB
   Damen GWJA, 2007, OTOLARYNG HEAD NECK, V136, P597, DOI 10.1016/j.otohns.2006.11.044
   Davenport MH, 2012, EXERC SPORT SCI REV, V40, P153, DOI 10.1097/JES.0b013e3182553430
   Dawes P, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119616
   Deal JA, 2015, AM J EPIDEMIOL, V181, P680, DOI 10.1093/aje/kwu333
   DEJONGGIERVELD J, 1985, APPL PSYCH MEAS, V9, P289, DOI 10.1177/014662168500900307
   Dowell RC, 2012, EVIDENCE BASED PRACT, P141
   Dupuis K, 2015, AGING NEUROPSYCHOL C, V22, P413, DOI 10.1080/13825585.2014.968084
   Erickson KI, 2012, ARCH MED RES, V43, P615, DOI 10.1016/j.arcmed.2012.09.008
   Falleti MG, 2006, J CLIN EXP NEUROPSYC, V28, P1095, DOI 10.1080/13803390500205718
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   FORSELL Y, 1994, AM J PSYCHIAT, V151, P1600
   Francis HW, 2002, LARYNGOSCOPE, V112, P1482, DOI 10.1097/00005537-200208000-00028
   Fratiglioni L, 2000, LANCET, V355, P1315, DOI 10.1016/S0140-6736(00)02113-9
   Fulton Susan E., 2015, Seminars in Hearing, V36, P140, DOI 10.1055/s-0035-1555117
   Gallacher J, 2012, NEUROLOGY, V79, P1583, DOI 10.1212/WNL.0b013e31826e263d
   Gao S, 1998, ARCH GEN PSYCHIAT, V55, P809, DOI 10.1001/archpsyc.55.9.809
   Gopinath B, 2009, J AM GERIATR SOC, V57, P1306, DOI 10.1111/j.1532-5415.2009.02317.x
   Heine C, 2002, DISABIL REHABIL, V24, P763, DOI 10.1080/09638280210129162
   Hinderink JB, 2000, OTOLARYNG HEAD NECK, V123, P756, DOI 10.1067/mhn.2000.108203
   Hindmarch I, 1998, DEMENT GERIATR COGN, V9, P20, DOI 10.1159/000051195
   Hogan A, 2009, J AGING HEALTH, V21, P1098, DOI 10.1177/0898264309347821
   Horsman John, 2003, Health Qual Life Outcomes, V1, P54, DOI 10.1186/1477-7525-1-54
   Huang CQ, 2010, AGEING RES REV, V9, P131, DOI 10.1016/j.arr.2009.05.005
   Jayakody DMP, 2018, CLIN OTOLARYNGOL, V43, P182, DOI 10.1111/coa.12937
   Jayakody DMP, 2017, OTOL NEUROTOL, V38, pE289, DOI 10.1097/MAO.0000000000001502
   Jorm AF, 2000, GERONTOLOGY, V46, P219, DOI 10.1159/000022163
   Katz MJ, 2012, ALZ DIS ASSOC DIS, V26, P335, DOI 10.1097/WAD.0b013e31823dbcfc
   Lamb SE, 2018, BMJ-BRIT MED J, V361, DOI 10.1136/bmj.k1675
   Lazard DS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048739
   Lim YY, 2013, J ALZHEIMERS DIS, V33, P675, DOI 10.3233/JAD-2012-121516
   Lin FR, 2011, NEUROPSYCHOLOGY, V25, P763, DOI 10.1037/a0024238
   LINDENBERGER U, 1994, PSYCHOL AGING, V9, P339, DOI 10.1037/0882-7974.9.3.339
   Livingston G, 2017, LANCET, V390, P2673, DOI 10.1016/S0140-6736(17)31363-6
   Loughrey DG, 2018, JAMA OTOLARYNGOL, V144, P115, DOI 10.1001/jamaoto.2017.2513
   Lubben J.E., 1988, J FAMILY COMMUNITY H, V11, P42, DOI DOI 10.1097/00003727-198811000-00008
   Maharani A, 2018, J AM GERIATR SOC, V66, P1130, DOI 10.1111/jgs.15363
   Mandolesi L, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00509
   Manrique-Huarte R, 2016, AUDIOL NEURO-OTOL, V21, P29, DOI 10.1159/000448352
   Maruff P, 2009, ARCH CLIN NEUROPSYCH, V24, P165, DOI 10.1093/arclin/acp010
   Matthews FE, 2013, LANCET, V382, P1405, DOI 10.1016/S0140-6736(13)61570-6
   Mick P, 2018, CAN FAM PHYSICIAN, V64, pE33
   Miller G, 2015, BMC GERIATR, V15, DOI 10.1186/s12877-015-0014-3
   Mo B, 2005, EAR HEARING, V26, P186, DOI 10.1097/00003446-200504000-00006
   Mosnier I, 2018, J AM GERIATR SOC, V66, P1553, DOI 10.1111/jgs.15445
   Mosnier I, 2015, JAMA OTOLARYNGOL, V141, P442, DOI 10.1001/jamaoto.2015.129
   MULROW CD, 1990, ANN INTERN MED, V113, P188, DOI 10.7326/0003-4819-113-3-188
   MULROW CD, 1990, J AM GERIATR SOC, V38, P45, DOI 10.1111/j.1532-5415.1990.tb01595.x
   Murphy DR, 2006, PSYCHOL AGING, V21, P49, DOI 10.1037/0882-7974.21.1.49
   Norton S, 2014, LANCET NEUROL, V13, P788, DOI 10.1016/S1474-4422(14)70136-X
   OTT A, 1995, BRIT MED J, V310, P970, DOI 10.1136/bmj.310.6985.970
   Prencipe M, 1996, J NEUROL NEUROSUR PS, V60, P628, DOI 10.1136/jnnp.60.6.628
   Prince M, 2015, GLOBAL IMPACT DEMENT, P1
   Roberts RO, 2012, NEUROLOGY, V78, P342, DOI 10.1212/WNL.0b013e3182452862
   Rocca WA, 2014, MATURITAS, V79, P196, DOI 10.1016/j.maturitas.2014.05.008
   Ruitenberg A, 2001, NEUROBIOL AGING, V22, P575, DOI 10.1016/S0197-4580(01)00231-7
   Sindhusake D, 2001, INT J EPIDEMIOL, V30, P1371, DOI 10.1093/ije/30.6.1371
   Sink KM, 2015, JAMA-J AM MED ASSOC, V314, P781, DOI 10.1001/jama.2015.9617
   Skinner MW, 2002, EAR HEARING, V23, p2S, DOI 10.1097/00003446-200202001-00002
   Sonerson A., 2006, FINANC DEV, V43, P48
   Swan W, 2010, AUSTR 2050 FUT CHALL
   Taljaard DS, 2016, CLIN OTOLARYNGOL, V41, P718, DOI 10.1111/coa.12607
   van Uffelen JGZ, 2008, CLIN J SPORT MED, V18, P486, DOI 10.1097/JSM.0b013e3181845f0b
   VandenLangenberg GM, 1998, AM J EPIDEMIOL, V148, P204, DOI 10.1093/oxfordjournals.aje.a009625
   Vermeire K, 2005, OTOL NEUROTOL, V26, P188, DOI 10.1097/00129492-200503000-00010
   Westerman R, 2001, AUSTR DEFENCE FORCE, V2, P29
   Wilson D., 1998, HEARING IMPAIRMENT A
   Wimo A, 2010, WORLD ALZHEIMER REPO
   Wimo A, 2010, ALZHEIMERS DEMENT, V6, P98, DOI 10.1016/j.jalz.2010.01.010
   World Health Organization [ WHO], 2009, AGEING
   Young J, 2015, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD005381.pub4
   ZIGMOND AS, 1983, ACTA PSYCHIAT SCAND, V67, P361, DOI 10.1111/j.1600-0447.1983.tb09716.x
NR 91
TC 12
Z9 12
U1 0
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD AUG 2
PY 2019
VL 13
AR 789
DI 10.3389/fnins.2019.00789
PG 13
WC Neurosciences
SC Neurosciences & Neurology
GA IN4KI
UT WOS:000478643500001
PM 31427915
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Dimitrijevic, A
   Smith, ML
   Kadis, DS
   Moore, DR
AF Dimitrijevic, Andrew
   Smith, Michael L.
   Kadis, Darren S.
   Moore, David R.
TI Neural indices of listening effort in noisy environments
SO SCIENTIFIC REPORTS
LA English
DT Article
ID INFERIOR FRONTAL GYRUS; SPEECH RECOGNITION; SPATIAL ATTENTION; CORTICAL
   ACTIVITY; AUDITORY-CORTEX; NORMAL-HEARING; ALPHA-ACTIVITY; ENTRAINMENT;
   MODULATION; REPRESENTATIONS
AB Listening in a noisy environment is challenging for individuals with normal hearing and can be a significant burden for those with hearing impairment. The extent to which this burden is alleviated by a hearing device is a major, unresolved issue for rehabilitation. Here, we found adult users of cochlear implants (CIs) self-reported listening effort during a speech-in-noise task that was positively related to alpha oscillatory activity in the left inferior frontal cortex, canonical Broca's area, and inversely related to speech envelope coherence in the 2-5 Hz range originating in the superior-temporal plane encompassing auditory cortex. Left frontal cortex coherence in the 2-5 Hz range also predicted speech-in-noise identification. These data demonstrate that neural oscillations predict both speech perception ability in noise and listening effort.
C1 [Dimitrijevic, Andrew] Sunnybrook Hlth Sci Ctr, Dept Otolaryngol Head & Neck Surg, Toronto, ON, Canada.
   [Dimitrijevic, Andrew] Univ Toronto, Dept Otolaryngol Head & Neck Surg, Toronto, ON, Canada.
   [Dimitrijevic, Andrew; Smith, Michael L.; Moore, David R.] Cincinnati Childrens Hosp Med Ctr, Commun Sci Res Ctr, Cincinnati, OH 45229 USA.
   [Kadis, Darren S.] Cincinnati Childrens Hosp Med Ctr, Div Neurol, Cincinnati, OH 45229 USA.
   [Kadis, Darren S.] Cincinnati Childrens Hosp Med Ctr, PNRC, Cincinnati, OH 45229 USA.
   [Kadis, Darren S.] Univ Cincinnati, Coll Med, Dept Pediat, Cincinnati, OH USA.
   [Moore, David R.] Univ Cincinnati, Coll Med, Dept Otolaryngol, Cincinnati, OH USA.
   [Moore, David R.] Univ Manchester, Manchester Ctr Hearing & Deafness, Manchester, Lancs, England.
   [Smith, Michael L.] Univ Washington, Dept Speech & Hearing Sci, Seattle, WA 98195 USA.
RP Dimitrijevic, A (corresponding author), Sunnybrook Hlth Sci Ctr, Dept Otolaryngol Head & Neck Surg, Toronto, ON, Canada.; Dimitrijevic, A (corresponding author), Univ Toronto, Dept Otolaryngol Head & Neck Surg, Toronto, ON, Canada.; Dimitrijevic, A (corresponding author), Cincinnati Childrens Hosp Med Ctr, Commun Sci Res Ctr, Cincinnati, OH 45229 USA.
EM andrew.dimitrijevic@sunnybrook.ca
OI Kadis, Darren/0000-0001-6785-2425; Dimitrijevic,
   Andrew/0000-0003-1170-3484
FU NIHR Manchester Biomedical Research CentreNational Institute for Health
   Research (NIHR); NIHUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01DC014078];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC014078, R01DC014078, R01DC014078,
   R01DC014078] Funding Source: NIH RePORTER
FX The authors would like to thank the anonymous reviewers for their very
   helpful and insightful comments. David R. Moore is supported by the NIHR
   Manchester Biomedical Research Centre. D.M. and A.D. were also partially
   supported by an NIH grant R01DC014078.
CR Aiken SJ, 2008, EAR HEARING, V29, P139, DOI 10.1097/AUD.0b013e31816453dc
   Alain C, 2018, HUM BRAIN MAPP, V39, P2695, DOI 10.1002/hbm.24031
   Alhanbali S, 2017, EAR HEARING, V38, pE39, DOI 10.1097/AUD.0000000000000361
   Assaneo MF, 2019, NAT NEUROSCI, V22, P627, DOI 10.1038/s41593-019-0353-z
   Banerjee S, 2011, J NEUROSCI, V31, P9923, DOI 10.1523/JNEUROSCI.4660-10.2011
   Bidelman GM, 2018, HEARING RES, V367, P149, DOI 10.1016/j.heares.2018.05.018
   Bleichner MG, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/6/066004
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Dimitrijevic A, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00088
   Dimitrijevic A, 2013, CLIN NEUROPHYSIOL, V124, P1204, DOI 10.1016/j.clinph.2012.11.014
   Ding N, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00311
   Ding N, 2012, J NEUROPHYSIOL, V107, P78, DOI 10.1152/jn.00297.2011
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   Eisner F, 2010, J NEUROSCI, V30, P7179, DOI 10.1523/JNEUROSCI.4040-09.2010
   Fiedler L, 2016, IEEE ENG MED BIO, P5697, DOI 10.1109/EMBC.2016.7592020
   Foxe JJ, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00154
   Frey JN, 2014, J NEUROSCI, V34, P6634, DOI 10.1523/JNEUROSCI.4813-13.2014
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P180, DOI 10.1007/s10162-005-5061-6
   Fu QJ, 2002, NEUROREPORT, V13, P1635, DOI 10.1097/00001756-200209160-00013
   Gagne JP, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216516687287
   Gaudrain E, 2007, HEARING RES, V231, P32, DOI 10.1016/j.heares.2007.05.001
   Giraud AL, 2004, CEREB CORTEX, V14, P247, DOI 10.1093/cercor/bhg124
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Gross J, 2001, P NATL ACAD SCI USA, V98, P694, DOI 10.1073/pnas.98.2.694
   Haegens S, 2011, J NEUROSCI, V31, P5197, DOI 10.1523/JNEUROSCI.5199-10.2011
   Han JH, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00038
   HART S G, 1988, P139
   Hervais-Adelman AG, 2012, LANG COGNITIVE PROC, V27, P1145, DOI 10.1080/01690965.2012.662280
   HETU R, 1988, British Journal of Audiology, V22, P251
   Hoechstetter K, 2004, BRAIN TOPOGR, V16, P233
   Horton C, 2013, J NEUROPHYSIOL, V109, P3082, DOI 10.1152/jn.01026.2012
   Hsieh L, 2001, BRAIN LANG, V76, P227, DOI 10.1006/brln.2000.2382
   Huang S, 2014, NEUROIMAGE, V86, P461, DOI 10.1016/j.neuroimage.2013.10.043
   Hughes Kathryn C, 2013, Cochlear Implants Int, V14, P121, DOI 10.1179/1754762812Y.0000000009
   Jensen O, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00186
   Kadis DS, 2011, J INT NEUROPSYCH SOC, V17, P896, DOI 10.1017/S1355617711000932
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Khoshkhoo S, 2018, BRAIN LANG, V187, P83, DOI 10.1016/j.bandl.2018.01.007
   Krueger M, 2017, AM J AUDIOL, V26, P378, DOI 10.1044/2017_AJA-16-0136
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Mazaheri A, 2014, NEUROIMAGE, V87, P356, DOI 10.1016/j.neuroimage.2013.10.052
   McGarrigle R, 2014, INT J AUDIOL, V53, P433, DOI 10.3109/14992027.2014.890296
   McMahon CM, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00745
   Miles K, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517706396
   Nelson DA, 2008, J ACOUST SOC AM, V123, P1522, DOI 10.1121/1.2836786
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049
   Park MH, 2015, JARO-J ASSOC RES OTO, V16, P389, DOI 10.1007/s10162-014-0499-z
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Petersen EB, 2017, J NEUROPHYSIOL, V117, P18, DOI 10.1152/jn.00527.2016
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Picton TW, 2003, INT J AUDIOL, V42, P177, DOI 10.3109/14992020309101316
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Shergill SS, 2002, HUM BRAIN MAPP, V16, P219, DOI 10.1002/hbm.10046
   Smits C, 2004, INT J AUDIOL, V43, P15, DOI 10.1080/14992020400050004
   Smits C, 2013, J ACOUST SOC AM, V133, P1693, DOI 10.1121/1.4789933
   Strauss A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00350
   Thorpe S, 2012, BRAIN TOPOGR, V25, P39, DOI 10.1007/s10548-011-0186-x
   Tune S, 2018, EUR J NEUROSCI, V48, P2537, DOI 10.1111/ejn.13862
   Vanthornhout J, 2018, JARO-J ASSOC RES OTO, V19, P181, DOI 10.1007/s10162-018-0654-z
   Vlaming MSMG, 2014, EAR HEARING, V35, P667, DOI 10.1097/AUD.0000000000000073
   Weisz N, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00073
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
   Winn MB, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516669723
   Wisniewski MG, 2015, NEUROREPORT, V26, P94, DOI 10.1097/WNR.0000000000000306
   Wostmann M, 2017, CEREB CORTEX, V27, P3307, DOI 10.1093/cercor/bhx074
   Wostmann M, 2015, J NEUROSCI, V35, P1458, DOI 10.1523/JNEUROSCI.3250-14.2015
   Won JH, 2007, JARO-J ASSOC RES OTO, V8, P384, DOI 10.1007/s10162-007-0085-8
   Youssofzadeh V, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00173
   Zeng Fan-Gang, 2004, Trends Amplif, V8, P1, DOI 10.1177/108471380400800102
NR 73
TC 12
Z9 12
U1 0
U2 4
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD AUG 2
PY 2019
VL 9
AR 11278
DI 10.1038/s41598-019-47643-1
PG 10
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA IN3KE
UT WOS:000478575000065
PM 31375712
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Bertozzo, MC
   Blasca, WQ
AF Bertozzo, Marilia Cancian
   Blasca, Wanderleia Quinhoneiro
TI Comparative analysis of the NAL-NL2 and DSL v5.0a prescription
   procedures in the adaptation of hearing aids in the elderly
SO CODAS
LA English
DT Article
DE Aged; Hearing; Hearing Loss; Hearing Aids; Speech Perception
ID REAL-EAR; ADULTS; GAIN
AB Purpose: To comparatively analyze the NAL-NL2 and DSL v5.0a prescriptive methods according to the hearing aids individualized programming for the elderly with hearing loss. Methods: The study included 60 elderly individuals with hearing loss, who underwent RECD (Real Ear to Coupler Difference) measurement and hearing aids individualized programming by NAL-NL2 and DSL v5.0a prescriptive methods. The performance verification for each prescription was performed using REAR measurements (Real Ear Aided Response), SII calculation (Speech Intelligibility Index) and HINT (Hearing In Noise Test). The comparative statistical analysis was performed using the paired t-test. Results: The NAL-NL2 method presented a better performance in the REAR evaluation in low and high frequency hands for medium and loud intensity input sounds, in the high frequency range for low intensity input sounds, and in the SIT calculation for soft input sounds. The DSL v5.0a presented better results in the REAR evaluation in medium frequencies for medium input sounds, in low and medium frequencies for soft input sounds. in the SII calculation for medium and loud input sound. and in the HINT test in silent and noisy situations. Conclusion: The findings of this study point to an equivalent performance between the DSL v5.0a and NAL-NL2 procedures in the adaptation of hearing aids in the elderly with hearing loss. The amplification calculated by DSL v5.0a provided better speech perception in silence.
C1 [Bertozzo, Marilia Cancian; Blasca, Wanderleia Quinhoneiro] Univ Sao Paulo, Fac Odontol Bauru, Dept Eonoaudiol, Bauru, SP, Brazil.
   [Bertozzo, Marilia Cancian] Univ Sao Paulo, Fac Odontol Bauru, Programa Posgrad Fonoaudiol, Bauru, SP, Brazil.
RP Bertozzo, MC (corresponding author), Av Octavio Pinheiro Brisola 9-75, BR-17012901 Bauru, SP, Brazil.
EM marilia.bertozzo@usp.br
RI Blasca, Wanderleia Quinhoneiro/D-2284-2012
OI Blasca, Wanderleia Quinhoneiro/0000-0002-2634-0607; Bertozzo,
   Marilia/0000-0003-4893-9159
FU Foundation for Research Support of the State of Sao Paulo
   (FAPESP)Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP)
   [2015/22817-4]
FX This study was conducted by the Coordination of Improvement of Higher
   Education Personnel (CAPES) and Foundation for Research Support of the
   State of Sao Paulo (FAPESP - process no 2015/22817-4).
CR Aarts NL, 2005, INT J AUDIOL, V44, P293, DOI 10.1080/14992020500057830
   Aazh H, 2007, J AM ACAD AUDIOL, V18, P653, DOI 10.3766/jaaa.18.8.3
   Almeida K., 2011, TRATADO AUDIOLOGIA, P377
   American Academy of Audiology, 2008, GUID AUD MAN AD HEAR
   American National Standards Institute, 2012, S351997 ANSI
   Ching TYC, 2010, INT J AUDIOL, V49, pS16, DOI 10.3109/14992020903082096
   College of Audiologists and Speech-Language Pathologists of Ontario, 2014, PREF PRACT GUID PRES
   Dillon H, 2003, HEAR J, V56, P28, DOI DOI 10.1097/01.HJ.0000292916.91825.6A
   Dworsack-Dodge M., 2013, AUDIOLOGY
   Glista D, 2016, HEAR REV, V23, P26
   Gustafson SJ, 2011, INT J AUDIOL, V50, P34, DOI 10.3109/14992027.2010.521198
   Hannula S, 2011, INT J AUDIOL, V50, P793, DOI 10.3109/14992027.2011.593562
   HAWKINS DB, 2003, HEARING J, V56, P26, DOI DOI 10.1097/01.HJ.0000292552.60032.8B
   Johnson EE, 2013, TRENDS HEAR, V17, P143, DOI 10.1177/1084713813506301
   Johnson EE, 2011, J AM ACAD AUDIOL, V22, P441, DOI 10.3766/jaaa.22.7.5
   Keidser G, 2011, AUDIOL RES, V1, P88, DOI 10.4081/audiores.2011.e24
   Keidser G, 2012, TRENDS AMPLIF, V16, P211, DOI 10.1177/1084713812468511
   Moodie S, 2007, FOCUS, V37, P2
   Mueller HG, 2017, SPEECH MAPPING PROBE
   Munro KJ, 2005, EAR HEARING, V26, P27, DOI 10.1097/00003446-200502000-00003
   Polonenko MJ, 2010, INT J AUDIOL, V49, P550, DOI 10.3109/14992021003713122
   da Silva APR, 2014, CODAS, V26, P112, DOI 10.1590/2317-1782/2014211IN
   Sanders J., 2015, HEAR REV, V21, P24
   Scollie S., 2006, HEARING J, V59, P10, DOI [10.1097/01.HJ.0000285823.75952.f5, DOI 10.1097/01.HJ.0000285823.75952.F5]
   Scollie S., 2007, AUDIOLOGY
   Scollie Susan, 2005, Trends Amplif, V9, P159, DOI 10.1177/108471380500900403
   Smeds K., 2015, HEARING REV, V22, P16
   Valente M., 2006, AUDIOLOGY
   Venema T., 2001, AUDIOLOGY
NR 29
TC 0
Z9 0
U1 0
U2 2
PU SOC BRASILEIRA FONOAUDIOLOGIA
PI SAO PAULO SP
PA AL JAU, 684 7 ANDAR, SAO PAULO SP, 01420-001, BRAZIL
SN 2317-1782
J9 CODAS
JI CoDAS
PD AUG
PY 2019
VL 31
IS 4
AR e20180171
DI 10.1590/2317-1782/20192018171
PG 7
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA JJ6OT
UT WOS:000494275200006
PM 31433039
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Guijo, LM
   Horiuti, MB
   Cardoso, ACV
AF Guijo, Laura Mochiatti
   Horiuti, Mirella Boaglio
   Vieira Cardoso, Ana Claudia
TI Measurement of listening effort using of a dual-task paradigm of
   Brazilian Portuguese: a pilot study
SO CODAS
LA English
DT Article
DE Hearing; Listening Effort; Auditory Perception; Auditory Tests; Memory;
   Cognition
ID HEARING-LOSS; MEMORY; COMPREHENSION; MECHANISMS
AB Purpose: To measure listening effort using of a dual-task paradigm of working memory and analyze the clinical significance (tithe normal-hearing individuals' performance. Methods: Participants were 10 young adults with similar socio-cultural level, aged 18-30 years. or both genders. classified as normal-hearing individuals based on the quadritonal average (500, 1000, 2000 and 4000 Hz). The participants were submitted to audiological anamnesis, meatoscopy, and pure tone audiometry. Listening effort was measured using a dual-task paradigm comprising the tasks of speech perception and working memory with logatotnes, real words. and meaningless sentences. Prior to measurement, the dual-task paradigm was carried out in audiometric booth in order to train the participants to perform the tasks properly. After the training stage, this paradigm was conducted under two different hearing situations with white noise: signal-to-noise ratios of +5 and -5dB. Results: Performance comparison per ear. right or Zell, for the two signal-to-noise ratios significantly influenced the speech perception tasks with logatomes and meaningless sentences in both ears; however, significant difference was observed only for the right ear in the tasks of listening effort and working memory. Conclusion: Listening effort can he measured using the paradigm proposed, and this instrument was proven sensitive for the quantification of this auditory parameter.
C1 [Guijo, Laura Mochiatti; Horiuti, Mirella Boaglio; Vieira Cardoso, Ana Claudia] Univ Estadual Paulista, UNESP, Fac Filosofia & Ciencias, Dept Fonoaudiol, Marilia, SP, Brazil.
   [Guijo, Laura Mochiatti; Vieira Cardoso, Ana Claudia] Univ Estadual Paulista, UNESP, Fac Filosofia & Ciencias, Rua Guiro Shimabukuro,106,Parque Acacias, BR-17510050 Marilia, SP, Brazil.
   [Horiuti, Mirella Boaglio] Univ Fed Sao Paulo UNIFESP, EPM, Sao Paulo, SP, Brazil.
RP Guijo, LM (corresponding author), Univ Estadual Paulista, UNESP, Fac Filosofia & Ciencias, Rua Guiro Shimabukuro,106,Parque Acacias, BR-17510050 Marilia, SP, Brazil.
EM lauramochiatti@gmail.com
CR Brannstrom K Jonas, 2018, J Am Acad Audiol, V29, P734, DOI 10.3766/jaaa.17024
   Bregman AS., 1990, AUDITORY SCENE ANAL, V4, DOI [10.7551/mitpress/1486.001.0001, DOI 10.7551/MITPRESS/1486.001.0001]
   COSTA MJ, 1998, ACTA AWHO, V17, P84
   Cousins KAQ, 2014, MEM COGNITION, V42, P622, DOI 10.3758/s13421-013-0377-7
   DANEMAN M, 1980, J VERB LEARN VERB BE, V19, P450, DOI 10.1016/S0022-5371(80)90312-6
   Gordon MS, 2009, EXP AGING RES, V35, P277, DOI 10.1080/03610730902769262
   Heinrich A, 2008, Q J EXP PSYCHOL, V61, P735, DOI 10.1080/17470210701402372
   Heinrich A, 2011, Q J EXP PSYCHOL, V64, P186, DOI 10.1080/17470218.2010.492621
   Hicks CB, 2002, J SPEECH LANG HEAR R, V45, P573, DOI 10.1044/1092-4388(2002/046)
   Mackersie CL, 2011, J AM ACAD AUDIOL, V22, P113, DOI 10.3766/jaaa.22.2.6
   MCADAMS S, 1993, THINKING SOUND COGNI
   McCoy SL, 2005, Q J EXP PSYCHOL-A, V58, P22, DOI 10.1080/02724980443000151
   Neuhoff J. G., 2004, ECOLOGICAL PSYCHOACO
   Pals C, 2013, J SPEECH LANG HEAR R, V56, P1075, DOI 10.1044/1092-4388(2012/12-0074)
   Peelle JE, 2018, EAR HEARING, V39, P204, DOI 10.1097/AUD.0000000000000494
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   Picou EM, 2013, EAR HEARING, V34, pe52, DOI 10.1097/AUD.0b013e31827f0431
   Sarampalis A, 2009, J SPEECH LANG HEAR R, V52, P1230, DOI 10.1044/1092-4388(2009/08-0111)
   Schlittmeier SI, 2008, EUR J COGN PSYCHOL, V20, P252, DOI 10.1080/09541440701427838
   Tun PA, 2009, PSYCHOL AGING, V24, P761, DOI 10.1037/a0014802
   Wayne RV, 2015, AGEING RES REV, V23, P154, DOI 10.1016/j.arr.2015.06.002
   Wingfield A, 2005, CURR DIR PSYCHOL SCI, V14, P144, DOI 10.1111/j.0963-7214.2005.00356.x
   Wingfield A, 2007, J AM ACAD AUDIOL, V18, P548, DOI 10.3766/jaaa.18.7.3
   Wingfield A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00684
   Working Group on Speech Understanding and Aging, 1988, J ACOUST SOC AM, V83, P859, DOI DOI 10.1121/1.395965
NR 26
TC 0
Z9 0
U1 1
U2 1
PU SOC BRASILEIRA FONOAUDIOLOGIA
PI SAO PAULO SP
PA AL JAU, 684 7 ANDAR, SAO PAULO SP, 01420-001, BRAZIL
SN 2317-1782
J9 CODAS
JI CoDAS
PD AUG
PY 2019
VL 31
IS 4
AR e20180181
DI 10.1590/2317-1782/20192018181
PG 9
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA JJ6OT
UT WOS:000494275200010
PM 31482997
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Hanenberg, C
   Getzmann, S
   Lewald, J
AF Hanenberg, Christina
   Getzmann, Stephan
   Lewald, Joerg
TI Transcranial direct current stimulation of posterior temporal cortex
   modulates electrophysiological correlates of auditory selective spatial
   attention in posterior parietal cortex
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Transcranial direct current stimulation (tDCS); Sound localization;
   Auditory selective spatial attention; Posterior parietal cortex
ID NONINVASIVE BRAIN-STIMULATION; DUAL-PATHWAY MODEL; SOUND LOCALIZATION;
   INTERAURAL TIME; MOTOR CORTEX; HEMISPHERIC LESIONS; ACOUSTIC SPACE;
   TDCS; RESPONSES; DEFICITS
AB Speech perception in "cocktail-party" situations, in which a sound source of interest has to be extracted out of multiple irrelevant sounds, poses a remarkable challenge to the human auditory system. Studies on structural and electrophysiological correlates of auditory selective spatial attention revealed critical roles of the posterior temporal cortex and the N2 event-related potential (ERP) component in the underlying processes. Here, we explored effects of transcranial direct current stimulation (tDCS) to posterior temporal cortex on neurophysiological correlates of auditory selective spatial attention, with a specific focus on the N2. In a single-blind, sham-controlled crossover design with baseline and follow-up measurements, monopolar anodal and cathodal tDCS was applied for 16 min to the right posterior superior temporal cortex. Two age groups of human subjects, a younger (n = 20; age 18-30 yrs) and an older group (n = 19; age 66-77 yrs), completed an auditory free-field multiple-speakers localization task while ERPs were recorded. The ERP data showed an offline effect of anodal, but not cathodal, tDCS immediately after DC offset for targets contralateral, but not ipsilateral, to the hemisphere of tDCS, without differences between groups. This effect mainly consisted in a substantial increase of the N2 amplitude by 0.9 mu V (SE 0.4 mu V; d = 0.40) compared with sham tDCS. At the same point in time, cortical source localization revealed a reduction of activity in ipsilateral (right) posterior parietal cortex. Also, localization error was improved after anodal, but not cathodal, tDCS. Given that both the N2 and the posterior parietal cortex are involved in processes of auditory selective spatial attention, these results suggest that anodal tDCS specifically enhanced inhibitory attentional brain processes underlying the focusing onto a target sound source, possibly by improved suppression of irrelevant distracters.
C1 [Hanenberg, Christina; Lewald, Joerg] Ruhr Univ Bochum, Fac Psychol, D-44780 Bochum, Germany.
   [Hanenberg, Christina; Getzmann, Stephan] Leibniz Res Ctr Working Environm & Human Factors, D-44139 Dortmund, Germany.
RP Lewald, J (corresponding author), Ruhr Univ Bochum, Fac Psychol, Dept Cognit Psychol, D-44780 Bochum, Germany.
EM Joerg.Lewald@rub.de
RI Lewald, Jorg/D-3034-2009
OI Lewald, Jorg/0000-0001-9351-0170; Getzmann, Stephan/0000-0002-6382-0183
FU German Federal Ministry of Education and ResearchFederal Ministry of
   Education & Research (BMBF) [01GQ1424E]
FX The authors are grateful to David Schmude, Jonas Heyermann, and
   Michael-Christian Schluter for their help in running the experiments, to
   Peter Dillmann and Tobias Blanke for preparing software and parts of the
   electronic equipment. This work was supported by the German Federal
   Ministry of Education and Research in the framework of the TRAIN-STIM
   project (grant number 01GQ1424E).
CR Alain C, 2001, P NATL ACAD SCI USA, V98, P12301, DOI 10.1073/pnas.211209098
   Arnott SR, 2004, NEUROIMAGE, V22, P401, DOI 10.1016/j.neuroimage.2004.01.014
   At A, 2011, NEUROPSYCHOLOGIA, V49, P2794, DOI 10.1016/j.neuropsychologia.2011.05.024
   Baudewig J, 2001, MAGN RESON MED, V45, P196, DOI 10.1002/1522-2594(200102)45:2<196::AID-MRM1026>3.0.CO;2-1
   Bikson M, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00688
   BISIACH E, 1984, BRAIN, V107, P37, DOI 10.1093/brain/107.1.37
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Boggio PS, 2006, J NEUROL SCI, V249, P31, DOI 10.1016/j.jns.2006.05.062
   Bolognini N, 2010, EUR J NEUROSCI, V31, P1800, DOI 10.1111/j.1460-9568.2010.07211.x
   Bushara KO, 1999, NAT NEUROSCI, V2, P759
   Cappon D, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00157
   Cespon J, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00420
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Chrysikou EG, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00448
   Clarke S, 2000, NEUROPSYCHOLOGIA, V38, P797, DOI 10.1016/S0028-3932(99)00141-4
   Clarke S, 2002, EXP BRAIN RES, V147, P8, DOI 10.1007/s00221-002-1203-9
   Corbetta M, 2008, NEURON, V58, P306, DOI 10.1016/j.neuron.2008.04.017
   Falkenstein M, 2002, J PSYCHOPHYSIOL, V16, P167, DOI 10.1027//0269-8803.16.3.167
   Ferrucci R, 2008, NEUROLOGY, V71, P493, DOI 10.1212/01.wnl.0000317060.43722.a3
   Fiori V, 2017, BEHAV BRAIN RES, V321, P170, DOI 10.1016/j.bbr.2016.12.044
   Folstein JR, 2008, PSYCHOPHYSIOLOGY, V45, P152, DOI 10.1111/j.1469-8986.2007.00602.x
   Gamble ML, 2011, PSYCHOPHYSIOLOGY, V48, P1057, DOI 10.1111/j.1469-8986.2010.01172.x
   Getzmann S, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00341
   Getzmann S, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00413
   Gonsalvez I, 2017, CURR ALZHEIMER RES, V14, P362, DOI 10.2174/1567205013666160930113907
   GRATTON G, 1983, ELECTROEN CLIN NEURO, V55, P468, DOI 10.1016/0013-4694(83)90135-9
   Griffiths TD, 1998, NAT NEUROSCI, V1, P74, DOI 10.1038/276
   Hausmann M, 2005, COGNITIVE BRAIN RES, V25, P537, DOI 10.1016/j.cogbrainres.2005.08.008
   HEFFNER HE, 1989, J NEUROPHYSIOL, V62, P789
   Heimrath K, 2014, NEUROSCIENCE, V261, P68, DOI 10.1016/j.neuroscience.2013.12.031
   Heimrath K, 2015, EUR J NEUROSCI, V41, P1580, DOI 10.1111/ejn.12908
   Hill KT, 2010, CEREB CORTEX, V20, P583, DOI 10.1093/cercor/bhp124
   Hsu WY, 2015, NEUROBIOL AGING, V36, P2348, DOI 10.1016/j.neurobiolaging.2015.04.016
   Impey D, 2015, J NEURAL TRANSM, V122, P1175, DOI 10.1007/s00702-015-1365-9
   JENKINS WM, 1982, J NEUROPHYSIOL, V47, P987
   Kaiser J, 2000, J NEUROSCI, V20, P6631, DOI 10.1523/JNEUROSCI.20-17-06631.2000
   Karhson DS, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144221
   Klein E, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0055455
   Kong LQ, 2014, CEREB CORTEX, V24, P773, DOI 10.1093/cercor/bhs359
   Krumbholz K, 2005, EUR J NEUROSCI, V21, P230, DOI 10.1111/j.1460-9568.2004.03836.x
   Krumbholz K, 2007, J NEUROPHYSIOL, V97, P1649, DOI 10.1152/jn.00560.2006
   Kuo MF, 2014, NEUROIMAGE, V85, P948, DOI 10.1016/j.neuroimage.2013.05.117
   Ladeira A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025399
   Lang N, 2005, EUR J NEUROSCI, V22, P495, DOI 10.1111/j.1460-9568.2005.04233.x
   Lewald J, 2004, NEUROPSYCHOLOGIA, V42, P1598, DOI 10.1016/j.neuropsychologia.2004.04.012
   Lewald J, 2002, J NEUROSCI, V22, DOI 10.1523/JNEUROSCI.22-03-j0005.2002
   Lewald J, 2008, EUR J NEUROSCI, V27, P1261, DOI 10.1111/j.1460-9568.2008.06094.x
   Lewald J, 2019, EXP BRAIN RES, V237, P1539, DOI 10.1007/s00221-019-05525-y
   Lewald J, 2016, PSYCHOPHYSIOLOGY, V53, P1484, DOI 10.1111/psyp.12692
   Lewald J, 2015, BEHAV BRAIN RES, V292, P157, DOI 10.1016/j.bbr.2015.06.025
   Lewald J, 2013, HEARING RES, V299, P46, DOI 10.1016/j.heares.2013.02.005
   Lewald J, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025146
   Lewald J, 2011, NEUROPSYCHOLOGIA, V49, P209, DOI 10.1016/j.neuropsychologia.2010.11.038
   Lewald J, 2016, NEUROPSYCHOLOGIA, V84, P282, DOI 10.1016/j.neuropsychologia.2016.01.030
   Lindenberg R, 2013, J NEUROSCI, V33, P9176, DOI 10.1523/JNEUROSCI.0055-13.2013
   Loui Psyche, 2010, Proc Meet Acoust, V9, P50002
   Maeder PP, 2001, NEUROIMAGE, V14, P802, DOI 10.1006/nimg.2001.0888
   Magezi DA, 2010, J NEUROPHYSIOL, V104, P1997, DOI 10.1152/jn.00424.2009
   Mathys C, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00193
   Mazzoni P, 1996, J NEUROPHYSIOL, V75, P1233
   Meinzer M, 2015, ALZHEIMERS DEMENT, V11, P1032, DOI 10.1016/j.jalz.2014.07.159
   Meinzer M, 2013, J NEUROSCI, V33, P12470, DOI 10.1523/JNEUROSCI.5743-12.2013
   Miller LM, 2009, P NATL ACAD SCI USA, V106, P5931, DOI 10.1073/pnas.0901023106
   Miranda PC, 2006, CLIN NEUROPHYSIOL, V117, P1623, DOI 10.1016/j.clinph.2006.04.009
   Naros G, 2016, CLIN NEUROPHYSIOL, V127, P2119, DOI 10.1016/j.clinph.2015.12.020
   Nitsche MA, 2003, CLIN NEUROPHYSIOL, V114, P2220, DOI 10.1016/S1388-2457(03)00235-9
   Nitsche MA, 2000, J PHYSIOL-LONDON, V527, P633, DOI 10.1111/j.1469-7793.2000.t01-1-00633.x
   Nitsche MA, 2008, BRAIN STIMUL, V1, P206, DOI 10.1016/j.brs.2008.06.004
   Nummenmaa L, 2010, CEREB CORTEX, V20, P1780, DOI 10.1093/cercor/bhp244
   Palomaki KJ, 2005, COGNITIVE BRAIN RES, V24, P364, DOI 10.1016/j.cogbrainres.2005.02.013
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P5
   Pavani F, 2005, BRAIN COGNITION, V59, P215, DOI 10.1016/j.bandc.2005.06.003
   Pavani F, 2002, CURR BIOL, V12, P1584, DOI 10.1016/S0960-9822(02)01143-0
   Pichora-Fuller MK, 2017, SPRINGER HANDB AUDIT, V60, P227, DOI 10.1007/978-3-319-51662-2_9
   PINEK B, 1992, BRAIN COGNITION, V18, P1, DOI 10.1016/0278-2626(92)90107-W
   PINEK B, 1989, CORTEX, V25, P175, DOI 10.1016/S0010-9452(89)80035-8
   Potts GF, 1998, ELECTROEN CLIN NEURO, V106, P444, DOI 10.1016/S0013-4694(97)00160-0
   Priori A, 2008, CEREB CORTEX, V18, P451, DOI 10.1093/cercor/bhm088
   Rauschecker JP, 2018, CORTEX, V98, P262, DOI 10.1016/j.cortex.2017.10.020
   RUFF RM, 1981, NEUROPSYCHOLOGIA, V19, P435, DOI 10.1016/0028-3932(81)90073-7
   Salminen NH, 2012, NEUROSCIENTIST, V18, P602, DOI 10.1177/1073858411434209
   Salminen NH, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007600
   Shomstein S, 2006, J NEUROSCI, V26, P435, DOI 10.1523/JNEUROSCI.4408-05.2006
   Spitoni GF, 2013, EXP BRAIN RES, V228, P63, DOI 10.1007/s00221-013-3538-9
   Stagg CJ, 2009, EUR J NEUROSCI, V30, P1412, DOI 10.1111/j.1460-9568.2009.06937.x
   Stagg CJ, 2013, J NEUROSCI, V33, P11425, DOI 10.1523/JNEUROSCI.3887-12.2013
   Stricanne B, 1996, J NEUROPHYSIOL, V76, P2071
   Tanaka H, 1999, J NEUROL NEUROSUR PS, V67, P481, DOI 10.1136/jnnp.67.4.481
   Tang MF, 2013, EUR J NEUROSCI, V38, P2802, DOI 10.1111/ejn.12280
   Ungan P, 2001, CLIN NEUROPHYSIOL, V112, P485, DOI 10.1016/S1388-2457(00)00550-2
   Vines BW, 2008, BMC NEUROSCI, V9, DOI 10.1186/1471-2202-9-103
   von Kriegstein K, 2008, J NEUROPHYSIOL, V100, P2712, DOI 10.1152/jn.90210.2008
   Wagner S, 2014, J NEURAL ENG, V11, DOI 10.1088/1741-2560/11/1/016002
   Weeks RA, 1999, NEUROSCI LETT, V262, P155, DOI 10.1016/S0304-3940(99)00062-2
   Werner-Reiss U, 2008, J NEUROSCI, V28, P3747, DOI 10.1523/JNEUROSCI.5044-07.2008
   Wostmann M, 2018, BRAIN STIMUL, V11, P752, DOI 10.1016/j.brs.2018.04.006
   Woldorff MG, 1999, HUM BRAIN MAPP, V7, P49, DOI 10.1002/(SICI)1097-0193(1999)7:1<49::AID-HBM5>3.3.CO;2-A
   Woods TM, 2006, J NEUROPHYSIOL, V96, P3323, DOI 10.1152/jn.00392.2006
   Zaehle T, 2011, EXP BRAIN RES, V215, P135, DOI 10.1007/s00221-011-2879-5
   Zatorre RJ, 2001, J NEUROSCI, V21, P6321
   Zatorre RJ, 2002, NAT NEUROSCI, V5, P905, DOI 10.1038/nn904
   Zhang XL, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00203
   Zheng X, 2011, NEUROIMAGE, V58, P26, DOI 10.1016/j.neuroimage.2011.06.018
   Zimmer U, 2006, NEUROPSYCHOLOGIA, V44, P454, DOI 10.1016/j.neuropsychologia.2005.05.021
   Zundorf IC, 2016, NEUROIMAGE, V124, P672, DOI 10.1016/j.neuroimage.2015.09.026
   Zundorf IC, 2014, BRAIN, V137, P1410, DOI 10.1093/brain/awu044
   Zundorf IC, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0064259
   Zundorf IC, 2011, CORTEX, V47, P741, DOI 10.1016/j.cortex.2010.08.002
NR 108
TC 4
Z9 4
U1 1
U2 2
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD AUG
PY 2019
VL 131
BP 160
EP 170
DI 10.1016/j.neuropsychologia.2019.05.023
PG 11
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA JJ1II
UT WOS:000493913900016
PM 31145907
DA 2021-02-24
ER

PT J
AU Ho, A
   Boshra, R
   Schmidtke, D
   Oralova, G
   Moro, AL
   Service, E
   Connolly, JF
AF Ho, Amanda
   Boshra, Rober
   Schmidtke, Daniel
   Oralova, Gaisha
   Moro, Anna L.
   Service, Elisabet
   Connolly, John F.
TI Electrophysiological evidence for the integral nature of tone in
   Mandarin spoken word recognition
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Electroencephalography; Mandarin Chinese; Language processing; N400;
   PMN; Event-related potentials; EEG/ERP
ID TIME-COURSE; INFORMATION; CONTEXT; CHINESE; MODEL
AB Current models of spoken word recognition have been predominantly based on studies of Indo-European languages. As a result, less is known about the recognition processes involved in the perception of tonal languages (e.g., Mandarin Chinese), and the role of lexical tone in speech perception. One view is that words in tonal languages are processed phonologically through individual segments, while another view is that they are processed lexically as a whole. Moreover, a recent study claimed to be the first to discover an early phonological processing stage in Mandarin (Huang et al., 2014). There seems to be a lack of investigations concerning tonal languages, as no clear conclusions have been reached about the nature of tonal processes, or a model of spoken word recognition that best incorporates lexical tone. The current study addressed these issues by presenting 18 native Mandarin speakers with aural sentences with medial target words. These either matched or mismatched the preceding visually presented sentences with medial target words (e.g, /jia1/home). Violation conditions involved target words that differed in the following ways: tone violation, where only the tone was different (e.g., /jia4/"price"), onset violation, where only the onset was different (e.g., /xia1/"shrimp"), and syllable violation, where both the tone and the onset were different (e.g., /tang2/"candy"). We did not find evidence for an early phonological processing stage in Mandarin. Instead, our findings indicate that Mandarin syllables are processed incrementally through phonological segments and that tone is strongly associated with lexical access. These results are discussed with respect to modifications for existing models in spoken word recognition to incorporate the processes involved with tonal language recognition.
C1 [Ho, Amanda] Univ Toronto, Speech Language Pathol, Toronto, ON, Canada.
   [Ho, Amanda; Schmidtke, Daniel; Oralova, Gaisha; Moro, Anna L.; Service, Elisabet; Connolly, John F.] McMaster Univ, Linguist & Languages, Hamilton, ON, Canada.
   [Ho, Amanda; Boshra, Rober; Schmidtke, Daniel; Oralova, Gaisha; Moro, Anna L.; Service, Elisabet; Connolly, John F.] McMaster Univ, ARiEAL Res Ctr, Hamilton, ON, Canada.
   [Boshra, Rober; Connolly, John F.] McMaster Univ, Sch Biomed Engn, Hamilton, ON, Canada.
   [Boshra, Rober; Connolly, John F.] MaRS Ctr, Vector Inst, Toronto, ON, Canada.
   [Schmidtke, Daniel; Moro, Anna L.] McMaster Univ, MELD, Hamilton, ON, Canada.
   [Service, Elisabet; Connolly, John F.] McMaster Univ, Psychol Neurosci & Behav, Hamilton, ON, Canada.
RP Connolly, JF (corresponding author), McMaster Univ, Psychol Neurosci & Behav, Hamilton, ON, Canada.
EM amanda.ho@alum.utoronto.ca; boshrar@mcmaster.ca; schmiddf@mcmaster.ca;
   oralovag@mcmaster.ca; moroal@mcmaster.ca; eservic@mcmaster.ca;
   jconnol@mcmaster.ca
RI Boshra, Rober/AAE-6466-2019; Service, Elisabet/M-7686-2015
OI Boshra, Rober/0000-0003-2925-199X; Service,
   Elisabet/0000-0002-7698-1189; Connolly, John/0000-0001-8869-5369
FU Canadian Institutes of Health ResearchCanadian Institutes of Health
   Research (CIHR); Canada Foundation for InnovationCanada Foundation for
   InnovationCGIAR; Senator William McMaster Chair in Cognitive
   Neuroscience of Language; MacDATA fellowship award; Vector Institute;
   Ontario Ministry of Research and InnovationMinistry of Research and
   Innovation, Ontario
FX First, we would like to thank the reviewers of this manuscript who were
   both thorough and generous with their extremely helpful comments. There
   is no question that the manuscript has benefited significantly from
   their suggestions. This work was supported by the Canadian Institutes of
   Health Research, Canada Foundation for Innovation (JFC), Senator William
   McMaster Chair in Cognitive Neuroscience of Language (JFC), the MacDATA
   fellowship award (RB), the Vector Institute postgraduate affiliate award
   (RB), and the Ontario Ministry of Research and Innovation (RB, GO). The
   funders had no role in study design, data collection and analysis,
   decision to publish, or preparation of the manuscript.
CR Boersma P, 2015, PRAAT DOING PHONETIC
   Brown-Schmidt S, 2004, J PSYCHOLINGUIST RES, V33, P103, DOI 10.1023/B:JOPR.0000017223.98667.10
   CONNOLLY JF, 1995, J CLIN EXP NEUROPSYC, V17, P548, DOI 10.1080/01688639508405145
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256
   Desroches AS, 2009, J COGNITIVE NEUROSCI, V21, P1893, DOI 10.1162/jocn.2008.21142
   Frishkoff G., 2009, ICBO 09, P31
   Gaskell MG, 2002, COGNITIVE PSYCHOL, V45, P220
   Hagoort P, 1999, J PSYCHOLINGUIST RES, V28, P715, DOI 10.1023/A:1023277213129
   Huang XJ, 2014, NEUROPSYCHOLOGIA, V63, P165, DOI 10.1016/j.neuropsychologia.2014.08.015
   Kutas M., 1994, HDB PSYCHOLINGUISTIC, P83, DOI DOI 10.1016/8978-012369374-7/50018-3
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Lau E, 2009, BRAIN LANG, V111, P161, DOI 10.1016/j.bandl.2009.08.007
   Liu YN, 2006, BRAIN LANG, V96, P37, DOI 10.1016/j.bandl.2005.08.007
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Malins JG, 2012, NEUROPSYCHOLOGIA, V50, P2032, DOI 10.1016/j.neuropsychologia.2012.05.002
   Malins JG, 2010, J MEM LANG, V62, P407, DOI 10.1016/j.jml.2010.02.004
   MARSLENWILSON W, 1980, COGNITION, V8, P1, DOI 10.1016/0010-0277(80)90015-3
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   Newman RL, 2003, PSYCHOPHYSIOLOGY, V40, P640, DOI 10.1111/1469-8986.00065
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   O'Seaghdha PG, 2010, COGNITION, V115, P282, DOI 10.1016/j.cognition.2010.01.001
   Perfetti CA, 2006, HANDBOOK OF EAST ASIAN PSYCHOLINGUISTICS, VOL 1: CHINESE, P225
   Schirmer A, 2005, J COGNITIVE NEUROSCI, V17, P1, DOI 10.1162/0898929052880057
   Wang H., 1986, XIANDAI HANYU PINLU
   Zeelenberg R, 2003, PSYCHON B REV, V10, P653, DOI 10.3758/BF03196528
   Zhao JJ, 2011, NEUROPSYCHOLOGIA, V49, P1761, DOI 10.1016/j.neuropsychologia.2011.02.054
NR 27
TC 0
Z9 0
U1 0
U2 2
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD AUG
PY 2019
VL 131
BP 325
EP 332
DI 10.1016/j.neuropsychologia.2019.05.031
PG 8
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA JJ1II
UT WOS:000493913900031
PM 31185227
DA 2021-02-24
ER

PT J
AU Daland, R
   Oh, M
   Davidson, L
AF Daland, Robert
   Oh, Mira
   Davidson, Lisa
TI On the relation between speech perception and loanword adaptation
   Cross-linguistic perception of Korean-illicit word-medial clusters
SO NATURAL LANGUAGE & LINGUISTIC THEORY
LA English
DT Article
DE Speech perception; Loanword phonology; Bayesian; Korean; Phonotactics
ID CONSONANT CLUSTERS; PHONOLOGICAL INFLUENCES; LISTENERS PERCEPTION;
   ENGLISH; JAPANESE; DISCRIMINATION; EPENTHESIS; CONTACT; VOWELS; FRENCH
AB Loanword adaptation has been claimed to provide a unique window onto the relation between speech perception and the phonological grammar. This paper focuses on whether the `illusory vowel' effect-in which the presence/absence of a vowel is poorly discriminated within an illicit cluster-is sufficient to explain why vowel epenthesis is the preferred repair for medial clusters in Korean loanword adaptation. A cross-linguistic discrimination experiment revealed a causative role of the stop release burst (or other audible frication noise) in the perception of an illusory vowel; in some cases, perception alone explains vowel epenthesis in loanword adaptation. A follow-up, identification experiment showed that Koreans' perceptual similarity judgements do not match up with the adaptation pattern for stop-nasal clusters (e.g. pakna), although they do for fricative-stop and stop-stop clusters (e.g. paska, pakta). This finding is problematic for a purely perceptual account of loanword adaptation. The paper sketches a Bayesian account of Korean speech perception that integrates top-down phonotactic likelihood and bottom-up acoustic match and is able to explain the experimental results. It closes with some speculation on the role of the Preservation Principle versus perception in loanword adaptation.
C1 [Daland, Robert] Univ Calif Los Angeles, Dept Linguist, Los Angeles, CA 90024 USA.
   [Oh, Mira] Chonnam Natl Univ, Dept English, Gwangju, South Korea.
   [Davidson, Lisa] NYU, Dept Linguist, New York, NY USA.
RP Oh, M (corresponding author), Chonnam Natl Univ, Dept English, Gwangju, South Korea.
EM r.daland@gmail.com; mroh@chonnam.ac.kr; lisa.davidson@nyu.edu
FU Ministry of Education of the Republic of Korea; National Research
   Foundation of KoreaNational Research Foundation of Korea
   [NRF-2016S1A5A2A01024340]
FX We wish to acknowledge Sharon Peperkamp, Michael Kenstowicz, and an
   anonymous reviewer for constructive suggestions. This work has
   benefitted from the comments of various audiences, including the UCLA
   Phonology Seminar, Northwestern University Linguistics Department,
   Chonnam National University English Department, University of Arizona
   Linguistics Department, and the Keio Reading Circle (including Shigeto
   Kawahara, Junko Ito, and Armin Mester). We also wish to acknowledge
   Quinton Maynard and IMC for the use of office space during winter and
   summer breaks, and Syejeong Kim for facilitating the experiments in
   Korea. This work was supported by the Ministry of Education of the
   Republic of Korea and the National Research Foundation of Korea
   (NRF-2016S1A5A2A01024340).
CR Abramson AS, 1999, PHONETICA, V56, P111, DOI 10.1159/000028446
   Ahn S., 1998, INTRO KOREAN PHONOLO
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best Catherine T., 1991, SR107108 HASK LAB, P1
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P, 2009, AMST STUD THEORY HIS, V307, P11
   Bohn OS, 2012, J PHONETICS, V40, P109, DOI 10.1016/j.wocn.2011.08.002
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   BYRD D, 1992, J ACOUST SOC AM, V49, P1
   Chang CB, 2012, J ACOUST SOC AM, V132, P2700, DOI 10.1121/1.4747615
   Chen Larissa, 2003, INT C PHON SCI ICPHS, V15
   Cho TH, 2006, J ACOUST SOC AM, V119, P3085, DOI 10.1121/1.2188917
   Daland Robert, 2011, INT C PHON SCI ICPHS
   Davidson L, 2015, J ACOUST SOC AM, V137, P856, DOI 10.1121/1.4906264
   Davidson L, 2011, SPEECH COMMUN, V53, P1042, DOI 10.1016/j.specom.2011.05.010
   de Jong K, 2012, LANGUAGE, V88, P341, DOI 10.1353/lan.2012.0035
   de Jong K, 2012, STUD SECOND LANG ACQ, V34, P127, DOI 10.1017/S0272263111000520
   Dupoux E, 1999, J EXP PSYCHOL HUMAN, V25, P1568, DOI 10.1037/0096-1523.25.6.1568
   Dupoux E, 2011, J MEM LANG, V64, P199, DOI 10.1016/j.jml.2010.12.004
   Durvasula K, 2015, PHONOLOGY, V32, P385, DOI 10.1017/S0952675715000263
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Fleischhacker Heidi, 2005, THESIS
   GOTO H, 1971, NEUROPSYCHOLOGIA, V9, P317, DOI 10.1016/0028-3932(71)90027-3
   Halle PA, 1998, J EXP PSYCHOL HUMAN, V24, P592, DOI 10.1037/0096-1523.24.2.592
   Halle PA, 1999, J PHONETICS, V27, P281, DOI 10.1006/jpho.1999.0097
   Haugen E, 1950, LANGUAGE, V26, P210, DOI 10.2307/410058
   Hayes B, 2008, LINGUIST INQ, V39, P379, DOI 10.1162/ling.2008.39.3.379
   Hwang J., 2011, THESIS
   Jun J., 1996, PHONOLOGY, V13, P377, DOI DOI 10.1017/S0952675700002682
   Kabak B, 2007, LANG SPEECH, V50, P23, DOI 10.1177/00238309070500010201
   Kang Hyunsook, 1996, STUDIES PHONETICS PH, V12, P21
   Kang YJ, 2010, PHONOLOGY, V27, P225, DOI 10.1017/S0952675710000114
   Kang Yoonjung, 2003, PHONOLOGY, V20, P219, DOI DOI 10.1017/S0952675703004524
   KBS Hangugeo Yeonkwuhwe [KBS Korean Language Research Team], 1987, REPR WER PHYOG YONGR
   Kim S, 2002, JAPANESE/KOREAN LINGUISTICS, VOL 10, P406
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kwon H, 2017, J PHONETICS, V60, P1, DOI 10.1016/j.wocn.2016.10.001
   Kwulipkwukeyenkwuwen [The National Academy for the Korean Language], 1991, OYL SAYONG SILT COS
   LaCharite Darlene, 2002, LANGUES LINGUISTIQUE, V28, P71
   Maye J, 2000, PROC ANN BUCLD, P522
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MIYAWAKI K, 1975, PERCEPT PSYCHOPHYS, V18, P331, DOI 10.3758/BF03211209
   Mo Yoonsook, 2007, INT C PHON SCI ICPHS, P445
   Oh M, 2012, J EAST ASIAN LINGUIS, V21, P267, DOI 10.1007/s10831-012-9089-4
   Oh Mira, 1996, PHONOLOGY MORPHOLOGY, V2, P117
   Paradis C, 1997, J LINGUIST, V33, P379, DOI 10.1017/S0022226797006786
   Park H, 2008, J PHONETICS, V36, P704, DOI 10.1016/j.wocn.2008.06.002
   Peperkamp S, 2008, PHONOLOGY, V25, P129, DOI 10.1017/S0952675708001425
   Pitt MA, 1998, J MEM LANG, V39, P347, DOI 10.1006/jmla.1998.2571
   R Core Development Team, 2014, R 3 02 LANG ENV STAT
   Shin Ji-young, 2011, HANKUKEOIY MALSORI
   Shinohara S, 2011, LINGUA, V121, P1461, DOI 10.1016/j.lingua.2011.04.001
   Silverman Daniel, 1992, PHONOLOGY, V9, P289, DOI DOI 10.1017/S0952675700001627
   Sundara M, 2008, COGNITION, V106, P234, DOI 10.1016/j.cognition.2007.01.011
   Wilson C, 2014, J MEM LANG, V77, P1, DOI 10.1016/j.jml.2014.08.001
   Wilson Colin, 2013, N E LINGUISTIC SOC N, V40
   Wright Richard, 2004, PHONETICALLY BASED P, P34, DOI DOI 10.1017/CBO9780511486401.002
   Yip M, 2006, LINGUA, V116, P950, DOI 10.1016/j.lingua.2005.05.007
   Yun S., 2016, THESIS
NR 59
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0167-806X
EI 1573-0859
J9 NAT LANG LINGUIST TH
JI Nat. Lang. Linguist. Theory
PD AUG
PY 2019
VL 37
IS 3
BP 825
EP 868
DI 10.1007/s11049-018-9423-2
PG 44
WC Linguistics; Language & Linguistics
SC Linguistics
GA JC9CR
UT WOS:000489572900002
DA 2021-02-24
ER

PT J
AU Raman, S
   Serrano, L
   Winneke, A
   Navas, E
   Hernaez, I
AF Raman, Sneha
   Serrano, Luis
   Winneke, Axel
   Navas, Eva
   Hernaez, Inma
TI Intelligibility and Listening Effort of Spanish Oesophageal Speech
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE speech intelligibility; listening effort; speech and voice disorders;
   pathological speech and language; Spanish speech; speech perception;
   spoken language understanding
ID TRACHEOESOPHAGEAL SPEECH; RATINGS; VOICE; RECOGNITION; CHILDREN;
   QUALITY; FATIGUE
AB Communication is a huge challenge for oesophageal speakers, be it for interactions with fellow humans or with digital voice assistants. We aim to quantify these communication challenges (both human-human and human-machine interactions) by measuring intelligibility and Listening Effort (LE) of Oesophageal Speech (OS) in comparison to Healthy Laryngeal Speech (HS). We conducted two listening tests (one web-based, the other in laboratory settings) to collect these measurements. Participants performed a sentence recognition and LE rating task in each test. Intelligibility, calculated as Word Error Rate, showed significant correlation with self-reported LE ratings. Speaker type (healthy or oesophageal) had a major effect on intelligibility and effort. More LE was reported for OS compared to HS even when OS intelligibility was close to HS. Listeners familiar with OS reported less effort when listening to OS compared to nonfamiliar listeners. However, such advantage of familiarity was not observed for intelligibility. Automatic speech recognition scores were higher for OS compared to HS.
C1 [Raman, Sneha; Serrano, Luis; Navas, Eva; Hernaez, Inma] Univ Basque Country, UPV EHU, Aholab Signal Proc Lab, Bilbao 48013, Spain.
   [Winneke, Axel] Fraunhofer Inst Digital Media Technol, Branch Hearing Speech & Audio Technol, D-26129 Oldenburg, Germany.
RP Raman, S; Navas, E; Hernaez, I (corresponding author), Univ Basque Country, UPV EHU, Aholab Signal Proc Lab, Bilbao 48013, Spain.
EM sneha.raman@ehu.eus; eva.navas@ehu.eus; inma.hernaez@ehu.eus
RI Navas, Eva/AAA-3325-2021; Hernaez-Rioja, Inma/AAQ-8183-2020
OI Navas, Eva/0000-0003-3804-4984; Hernaez-Rioja, Inma/0000-0003-4447-7575
FU EUs H2020 research and innovation programme [MSCA GA 67532*4]; Spanish
   Ministry of Economy and Competitiveness with FEDER
   [TEC2015-67163-C2-1-R]; Basque GovernmentBasque Government [DL4NLP
   KK-2019/00045, PIBA_2018_1_0035, IT355-19]
FX This project was supported by funding from the EUs H2020 research and
   innovation programme under the MSCA GA 67532*4 (the ENRICH network:
   www.enrich-etn.eu), the Spanish Ministry of Economy and Competitiveness
   with FEDER support (RESTORE project, TEC2015-67163-C2-1-R) and the
   Basque Government (DL4NLP KK-2019/00045, PIBA_2018_1_0035 and IT355-19).
CR Andersen AH, 2017, INT CONF ACOUST SPEE, P5085, DOI 10.1109/ICASSP.2017.7953125
   BENNETT S, 1973, J SPEECH HEAR RES, V16, P608, DOI 10.1044/jshr.1604.608
   Bhatnagar G, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P21, DOI 10.1109/ICAPR.2009.19
   Borghini G, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00152
   Cervera T, 2001, J SPEECH LANG HEAR R, V44, P988, DOI 10.1044/1092-4388(2001/077)
   Cote-Reschny KJ, 2010, J MED SPEECH-LANG PA, V18, P24
   CULLINAN WL, 1986, J COMMUN DISORD, V19, P185, DOI 10.1016/0021-9924(86)90008-0
   Drugman T, 2015, COMPUT SPEECH LANG, V30, P16, DOI 10.1016/j.csl.2014.07.003
   Eriksen CW, 1995, VISUAL SELECTIVE ATTENTION, P101
   Erro D., 2015, P 16 ANN C INT SPEEC
   Erro D., 2014, P ENTERFACE 14 BILB, P1178
   Hicks CB, 2002, J SPEECH LANG HEAR R, V45, P573, DOI 10.1044/1092-4388(2002/046)
   Hilbert S, 2015, EUR J PSYCHOL ASSESS, V31, P174, DOI 10.1027/1015-5759/a000223
   JASP Team, JASP VERS 0 8 6 COMP
   Koike M, 2002, ACTA OTO-LARYNGOL, V122, P107, DOI 10.1080/000164802760057716
   Landa S, 2014, INT J SPEECH-LANG PA, V16, P408, DOI 10.3109/17549507.2014.927922
   Levenshtein VI, 1966, SOV PHYS DOKL, V10, P707, DOI DOI 10.1109/TVCG.2012.323
   Lippmann RP, 1997, SPEECH COMMUN, V22, P1, DOI 10.1016/S0167-6393(97)00021-6
   Maier A, 2009, SPEECH COMMUN, V51, P425, DOI 10.1016/j.specom.2009.01.004
   Mantilla A, 2006, CIC 2006: 15TH INTERNATIONAL CONFERENCE ON COMPUTING, PROCEEDINGS, P115
   McGarrigle R, 2014, INT J AUDIOL, V53, P433, DOI 10.3109/14992027.2014.890296
   Meyers J E, 2000, Appl Neuropsychol, V7, P154, DOI 10.1207/S15324826AN0703_6
   Middag C., 2009, P 6 INT WORKSH MOD A, P165
   Middag C., 2011, P 12 ANN C INT SPEEC
   MIRALLES JL, 1995, J SPEECH HEAR RES, V38, P564, DOI 10.1044/jshr.3803.564
   MOHIDE EA, 1992, AM J SURG, V164, P619, DOI 10.1016/S0002-9610(05)80720-2
   Most T, 2000, J COMMUN DISORD, V33, P165, DOI 10.1016/S0021-9924(99)00030-1
   Nagle KF, 2012, J COMMUN DISORD, V45, P235, DOI 10.1016/j.jcomdis.2012.01.001
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Polityko E., WORD ERROR RATE
   Povey Daniel, 2011, P IEEE WORKSHOP AUTO
   Preece D.A., 2014, WILEY STATSREF STAT
   Rath SP, 2013, INTERSPEECH, P109
   Rennies J, 2014, J ACOUST SOC AM, V136, P2642, DOI 10.1121/1.4897398
   Sainz I, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3308
   Scharenborg O, 2007, SPEECH COMMUN, V49, P336, DOI 10.1016/j.specom.2007.01.009
   Serrano L., 2014, P IBERSPEECH 2016 LI, P33
   Serrano L., 2018, P IBERSPEECH 2018 BA, P122, DOI 10.21437/IberSPEECH.2018-26.
   Sesma A., 2000, CORPUSCRT 1 0 DISENO
   Sharma D, 2016, SPEECH COMMUN, V80, P84, DOI 10.1016/j.specom.2016.03.005
   Stajner-Katusic S, 2006, CLIN LINGUIST PHONET, V20, P195, DOI 10.1080/026992004000269975
   Steeneken HJ, 2001, P I ACOUSTICS, V23, P69
   Tits N., 2017, THESIS
   Van Engen KJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00577
   Van Kuyk S, 2018, IEEE-ACM T AUDIO SPE, V26, P2153, DOI 10.1109/TASLP.2018.2856374
   Weinberg B., 1986, LARYNGECTOMEE REHABI, P113
   Whitehill TL, 2006, J MED SPEECH-LANG PA, V14, P335
   YORKSTON KM, 1978, J COMMUN DISORD, V11, P499, DOI 10.1016/0021-9924(78)90024-2
NR 48
TC 2
Z9 2
U1 1
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD AUG
PY 2019
VL 9
IS 16
AR 3233
DI 10.3390/app9163233
PG 16
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
SC Chemistry; Engineering; Materials Science; Physics
GA IV7JZ
UT WOS:000484444100027
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Chiu, F
   Rakusen, LL
   Mattys, SL
AF Chiu, Faith
   Rakusen, Lyndon L.
   Mattys, Sven L.
TI Cognitive load elevates discrimination thresholds of duration,
   intensity, and f(0) for a synthesized vowel
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID TEMPORAL INTEGRATION; SPEECH; ATTENTION; PERCEPTION; MODULATION;
   HEARING; TONES
AB Dual-tasking negatively impacts on speech perception by raising cognitive load (CL). Previous research has shown that CL increases reliance on lexical knowledge and decreases reliance on phonetic detail. Less is known about the effect of CL on the perception of acoustic dimensions below the phonetic level. This study tested the effect of CL on the ability to discriminate differences in duration, intensity, and fundamental frequency of a synthesized vowel. A psychophysical adaptive procedure was used to obtain just noticeable differences (JNDs) on each dimension under load and no load. Load was imposed by N-back tasks at two levels of difficulty (one-back, two-back) and under two types of load (images, nonwords). Compared to a control condition with no CL, all N-back conditions increased JNDs across the three dimensions. JNDs were also higher under two-back than one-back load. Nonword load was marginally more detrimental than image load for intensity and fundamental frequency discrimination. Overall, the decreased auditory acuity demonstrates that the effect of CL on the listening experience can be traced to distortions in the perception of core auditory dimensions.
C1 [Chiu, Faith; Rakusen, Lyndon L.; Mattys, Sven L.] Univ York, Dept Psychol, York YO10 5DD, N Yorkshire, England.
RP Chiu, F (corresponding author), Univ York, Dept Psychol, York YO10 5DD, N Yorkshire, England.
EM faith.chiu@york.ac.uk
FU Economic and Social Research Council (ESRC)UK Research & Innovation
   (UKRI)Economic & Social Research Council (ESRC) [ES/R004722/1]
FX This study was supported by a research grant from the Economic and
   Social Research Council (ESRC) to S.L.M. (Grant No. ES/R004722/1).
CR Adcock RA, 2000, P NATL ACAD SCI USA, V97, P3567, DOI 10.1073/pnas.060588897
   Best V, 2010, EAR HEARING, V31, P213, DOI 10.1097/AUD.0b013e3181c34ba6
   Block RA, 1996, TIME AND MIND, P171
   Block RA, 2010, ACTA PSYCHOL, V134, P330, DOI 10.1016/j.actpsy.2010.03.006
   Boersma P., 2018, PRAAT DOING PHONETIC
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Burle B, 2001, J EXP PSYCHOL HUMAN, V27, P195, DOI 10.1037/0096-1523.27.1.195
   Casini L, 1997, MEM COGNITION, V25, P812, DOI 10.3758/BF03211325
   Casini L, 2009, COGNITION, V112, P318, DOI 10.1016/j.cognition.2009.04.005
   Durlach NI, 2003, J ACOUST SOC AM, V113, P2984, DOI 10.1121/1.1570435
   FLORENTINE M, 1988, J ACOUST SOC AM, V84, P195, DOI 10.1121/1.396964
   FLORENTINE M, 1986, J ACOUST SOC AM, V79, P792, DOI 10.1121/1.393469
   Gennari SP, 2018, NEUROIMAGE, V178, P735, DOI 10.1016/j.neuroimage.2018.06.035
   GIBBON J, 1984, ANN NY ACAD SCI, V423, P52, DOI 10.1111/j.1749-6632.1984.tb23417.x
   Green DM, 1966, SIGNAL DETECTION THE, V1
   KINGSTON J, 1994, LANGUAGE, V70, P419, DOI 10.2307/416481
   KLATT DH, 1990, J ACOUST SOC AM, V87, P820, DOI 10.1121/1.398894
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Macdonald JSP, 2011, ATTEN PERCEPT PSYCHO, V73, P1780, DOI 10.3758/s13414-011-0144-4
   Mattys SL, 2014, PSYCHON B REV, V21, P748, DOI 10.3758/s13423-013-0544-7
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Mattys SL, 2011, J MEM LANG, V65, P145, DOI 10.1016/j.jml.2011.04.004
   Mattys SL, 2009, COGNITIVE PSYCHOL, V59, P203, DOI 10.1016/j.cogpsych.2009.04.001
   MCQUEEN JM, 1993, MEM COGNITION, V21, P210, DOI 10.3758/BF03202734
   Mitterer H, 2017, ATTEN PERCEPT PSYCHO, V79, P344, DOI 10.3758/s13414-016-1195-3
   Molloy K, 2015, J NEUROSCI, V35, P16046, DOI 10.1523/JNEUROSCI.2931-15.2015
   MOORE BCJ, 1973, J ACOUST SOC AM, V54, P610, DOI 10.1121/1.1913640
   Palmer SD, 2016, Q J EXP PSYCHOL, V69, P2390, DOI 10.1080/17470218.2015.1112825
   Petersen SE, 2012, ANNU REV NEUROSCI, V35, P73, DOI 10.1146/annurev-neuro-062111-150525
   PLACK CJ, 1995, J ACOUST SOC AM, V98, P1355, DOI 10.1121/1.413471
   TREISMAN M, 1963, PSYCHOL MONOGR, V77, P1, DOI 10.1037/h0093864
   VIEMEISTER NF, 1991, J ACOUST SOC AM, V90, P858, DOI 10.1121/1.401953
   Woodruff PWR, 1996, NEUROREPORT, V7, P1909, DOI 10.1097/00001756-199608120-00007
   Zakay D, 1995, TIME DYNAMIC CONTROL, P167
NR 34
TC 2
Z9 2
U1 0
U2 0
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD AUG
PY 2019
VL 146
IS 2
BP 1077
EP 1084
DI 10.1121/1.5120404
PG 8
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA IU9FV
UT WOS:000483887400036
PM 31472597
OA Green Accepted, Other Gold
DA 2021-02-24
ER

PT J
AU Stilp, CE
AF Stilp, Christian E.
TI Auditory enhancement and spectral contrast effects in speech perception
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID CONTEXT; TONE; MASKING; SOUNDS; COMPONENTS; HEARING; MASKER; LEVEL
AB The auditory system is remarkably sensitive to changes in the acoustic environment. This is exemplified by two classic effects of preceding spectral context on perception. In auditory enhancement effects (EEs), the absence and subsequent insertion of a frequency component increases its salience. In spectral contrast effects (SCEs), spectral differences between earlier and later (target) sounds are perceptually magnified, biasing target sound categorization. These effects have been suggested to be related, but have largely been studied separately. Here, EEs and SCEs are demonstrated using the same speech materials. In Experiment 1, listeners categorized vowels (/?/-//) or consonants (/d/-/g/) following a sentence processed by a bandpass or bandstop filter (vowel tasks: 100-400 or 550-850Hz; consonant tasks: 1700-2700 or 2700-3700Hz). Bandpass filtering produced SCEs and bandstop filtering produced EEs, with effect magnitudes significantly correlated at the individual differences level. In Experiment 2, context sentences were processed by variable-depth notch filters in these frequency regions (-5 to -20dB). EE magnitudes increased at larger notch depths, growing linearly in consonant categorization. This parallels previous research where SCEs increased linearly for larger spectral peaks in the context sentence. These results link EEs and SCEs, as both shape speech categorization in orderly ways.
C1 [Stilp, Christian E.] Univ Louisville, 317 Life Sci Bldg, Louisville, KY 40292 USA.
RP Stilp, CE (corresponding author), Univ Louisville, 317 Life Sci Bldg, Louisville, KY 40292 USA.
EM christian.stilp@louisville.edu
CR Boersma P., 2018, PRAAT DOING PHONETIC
   BROADBENT DE, 1956, NATURE, V178, P815, DOI 10.1038/178815b0
   Byrne AJ, 2013, J ACOUST SOC AM, V134, P2631, DOI 10.1121/1.4820897
   Byrne AJ, 2011, J ACOUST SOC AM, V129, P2088, DOI 10.1121/1.3552880
   Carcagno S, 2012, JARO-J ASSOC RES OTO, V13, P693, DOI 10.1007/s10162-012-0339-y
   CARLYON RP, 1989, HEARING RES, V41, P223, DOI 10.1016/0378-5955(89)90014-2
   Coady JA, 2003, J ACOUST SOC AM, V114, P2225, DOI 10.1121/1.1608955
   Delgutte B., 1996, P AUD BAS SPEECH PER
   Delgutte B., 1996, HDB PHONETIC SCI, P507
   Erviti M, 2011, J ACOUST SOC AM, V129, P3837, DOI 10.1121/1.3589257
   Feng L, 2018, J ACOUST SOC AM, V144, P552, DOI 10.1121/1.5048414
   Feng L, 2018, J ACOUST SOC AM, V143, pEL468, DOI 10.1121/1.5042082
   Feng L, 2018, J EXP PSYCHOL HUMAN, V44, P1447, DOI 10.1037/xhp0000546
   Feng L, 2015, J EXP PSYCHOL HUMAN, V41, P1696, DOI 10.1037/xhp0000115
   Frazier JM, 2019, ATTEN PERCEPT PSYCHO, V81, P1119, DOI 10.3758/s13414-019-01675-x
   Goupell MJ, 2012, J ACOUST SOC AM, V131, P1007, DOI 10.1121/1.3672650
   Holt LL, 2005, PSYCHOL SCI, V16, P305, DOI 10.1111/j.0956-7976.2005.01532.x
   Holt LL, 2002, HEARING RES, V167, P156, DOI 10.1016/S0378-5955(02)00383-0
   Holt LL, 2000, J ACOUST SOC AM, V108, P710, DOI 10.1121/1.429604
   Holt LL, 2006, J ACOUST SOC AM, V120, P2801, DOI 10.1121/1.2354071
   KIDD G, 1994, J ACOUST SOC AM, V95, P962, DOI 10.1121/1.408402
   Kidd G, 2011, J ACOUST SOC AM, V130, P3926, DOI 10.1121/1.3658442
   Kingston J, 2014, ATTEN PERCEPT PSYCHO, V76, P1437, DOI 10.3758/s13414-013-0593-z
   Kluender KR, 2003, SPEECH COMMUN, V41, P59, DOI 10.1016/S0167-6393(02)00093-6
   Kreft HA, 2018, J ACOUST SOC AM, V143, P901, DOI 10.1121/1.5023687
   Kreft HA, 2017, JARO-J ASSOC RES OTO, V18, P483, DOI 10.1007/s10162-017-0618-8
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Lotto AJ, 1998, PERCEPT PSYCHOPHYS, V60, P602, DOI 10.3758/BF03206049
   Nelson PC, 2010, J NEUROSCI, V30, P6577, DOI 10.1523/JNEUROSCI.0277-10.2010
   PALMER AR, 1995, J ACOUST SOC AM, V97, P1786, DOI 10.1121/1.412055
   R Development Core Team, 2016, R LANG ENV STAT COMP
   Schouten JF, 1940, P K NED AKAD WETENSC, V43, P356
   Sjerps MJ, 2018, J EXP PSYCHOL HUMAN, V44, P914, DOI 10.1037/xhp0000504
   Spahr AJ, 2012, EAR HEARING, V33, P112, DOI 10.1097/AUD.0b013e31822c2549
   Stephens JDW, 2011, SPEECH COMMUN, V53, P877, DOI 10.1016/j.specom.2011.02.007
   Stilp C. E., 2016, P M ACOUST, V26
   Stilp CE, 2019, ATTEN PERCEPT PSYCHO, V81, P2037, DOI 10.3758/s13414-018-01659-3
   Stilp CE, 2018, ATTEN PERCEPT PSYCHO, V80, P1300, DOI 10.3758/s13414-018-1488-9
   Stilp CE, 2017, JARO-J ASSOC RES OTO, V18, P465, DOI 10.1007/s10162-017-0615-y
   Stilp CE, 2017, J ACOUST SOC AM, V141, pEL153, DOI 10.1121/1.4974769
   Stilp CE, 2015, J ACOUST SOC AM, V137, P3466, DOI 10.1121/1.4921600
   Stilp CE, 2010, ATTEN PERCEPT PSYCHO, V72, P470, DOI 10.3758/APP.72.2.470
   SUMMERFIELD Q, 1984, PERCEPT PSYCHOPHYS, V35, P203, DOI 10.3758/BF03205933
   SUMMERFIELD Q, 1987, J ACOUST SOC AM, V81, P700, DOI 10.1121/1.394838
   THIBODEAU LM, 1991, J ACOUST SOC AM, V89, P2843, DOI 10.1121/1.400722
   Viemeister N. F., 1980, PSYCHOPHYSICAL PHYSL, P190, DOI DOI 10.1007/978-94-009-9144-6_28
   Viemeister NF, 2013, ADV EXP MED BIOL, V787, P167, DOI 10.1007/978-1-4614-1590-9_19
   VIEMEISTER NF, 1982, J ACOUST SOC AM, V71, P1502, DOI 10.1121/1.387849
   Wang NY, 2016, HEARING RES, V333, P150, DOI 10.1016/j.heares.2016.01.012
   Wang NY, 2012, J ACOUST SOC AM, V131, pEL421, DOI 10.1121/1.4710838
   WATKINS AJ, 1991, J ACOUST SOC AM, V90, P2942, DOI 10.1121/1.401769
   Wegel RL, 1924, PHYS REV, V23, P266, DOI 10.1103/PhysRev.23.266
   Winn MB, 2015, J ACOUST SOC AM, V137, P1430, DOI 10.1121/1.4908308
   Winn MB, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00824
NR 54
TC 3
Z9 3
U1 1
U2 2
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD AUG
PY 2019
VL 146
IS 2
BP 1503
EP 1517
DI 10.1121/1.5120181
PG 15
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA IU9FV
UT WOS:000483887400073
PM 31472539
DA 2021-02-24
ER

PT J
AU Nagao, K
   Walter, C
   Parkes, WJ
   Teixido, M
   Theroux, MC
   Szymkowski, S
   Morlet, T
   Tomatsu, S
AF Nagao, Kyoko
   Walter, Cassidy
   Parkes, William J.
   Teixido, Michael
   Theroux, Mary C.
   Szymkowski, Stacy
   Morlet, Thierry
   Tomatsu, Shunji
TI Cochlear implantation in a patient with mucopolysaccharidosis IVA
SO SAGE OPEN MEDICAL CASE REPORTS
LA English
DT Article
DE Mucopolysaccharidosis; cochlear implantation; hearing loss; speech
   perception
ID MORQUIO
AB Mucopolysaccharidosis IVA (OMIM 253000; also known as Morquio A syndrome) is associated with skeletal, airway, and hearing abnormalities. Cochlear implantation is an effective intervention for patients with severe-to-profound hearing loss. Patients can gain substantial improvement in auditory performance, speech perception, and their quality of life from cochlear implantation. Although severe progressive sensorineural hearing loss is a common feature of mucopolysaccharidosis IVA, no detailed description of cochlear implantation for mucopolysaccharidosis IVA has been reported. To review the effectiveness and special considerations associated with cochlear implantation in patients with mucopolysaccharidosis IVA, we here report the case of cochlear implantation in mucopolysaccharidosis IVA by a multidisciplinary team. A retrospective chart review was conducted on a 34-year-old female with mucopolysaccharidosis IVA, who received a cochlear implant. Audiometric thresholds, speech perception scores, and cochlear implant processor mapping information were reviewed during the first 12 months following cochlear implantation. The results of audiological tests indicate improved hearing thresholds as well as remarkable enhancement of speech perception skills over 12 months of cochlear implant use. Cochlear implantation improved auditory performance in a mucopolysaccharidosis IVA patient with postlingually severe-to-profound sensorineural hearing loss. The benefits of cochlear implantation could be meaningful for other Morquio patients with progressive hearing loss, although the risks of surgery and anesthesia should be carefully considered by a multidisciplinary team of experts during the cochlear implant candidacy process.
C1 [Nagao, Kyoko; Morlet, Thierry; Tomatsu, Shunji] Nemours Alfred I DuPont Hosp Children, Nemours Biomed Res, 1600 Rockland Rd, Wilmington, DE 19803 USA.
   [Nagao, Kyoko; Walter, Cassidy; Morlet, Thierry] Univ Delaware, Dept Linguist & Cognit Sci, Newark, DE USA.
   [Nagao, Kyoko; Morlet, Thierry] Univ Delaware, Coll Hlth Sci, Commun Sci & Disorders, Newark, DE USA.
   [Parkes, William J.; Teixido, Michael] Nemours Alfred I DuPont Hosp Children, Otolaryngol, Wilmington, DE 19803 USA.
   [Parkes, William J.; Teixido, Michael; Theroux, Mary C.; Tomatsu, Shunji] Thomas Jefferson Univ, Sidney Kimmel Med Coll, Philadelphia, PA 19107 USA.
   [Teixido, Michael] Christiana Care Hlth Syst, Otol, Wilmington, DE USA.
   [Teixido, Michael] Univ Penn, Dept Otorhinolaryngol, Philadelphia, PA 19104 USA.
   [Theroux, Mary C.] Nemours Alfred I DuPont Hosp Children, Dept Anesthesiol & Perioperat Med, Wilmington, DE 19803 USA.
   [Szymkowski, Stacy] Nemours Alfred I DuPont Hosp Children, Dept Audiol, Wilmington, DE 19803 USA.
   [Morlet, Thierry] Salus Univ, Osborne Coll Audiol, Elkins Pk, PA USA.
RP Nagao, K (corresponding author), Nemours Alfred I DuPont Hosp Children, Nemours Biomed Res, 1600 Rockland Rd, Wilmington, DE 19803 USA.
EM kyoko.nagao@nemours.org
RI Nagao, Kyoko/AAA-1690-2019
OI Nagao, Kyoko/0000-0003-0917-6603
FU Institutional Development Award (IDeA) from National Institute of
   General Medical Sciences of National Institutes of Health (NIH)
   [P30GM114736]; NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCESUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute of General Medical Sciences
   (NIGMS) [P30GM114736, P30GM114736, P30GM114736, P30GM114736,
   P30GM114736, P30GM114736, P30GM114736, P30GM114736, P30GM114736,
   P30GM114736, P30GM114736, P30GM114736] Funding Source: NIH RePORTER
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: ST was
   supported by an Institutional Development Award (IDeA) from the National
   Institute of General Medical Sciences of National Institutes of Health
   (NIH) under grant number P30GM114736.
CR Barone R, 2018, ITAL J PEDIATR, V44, DOI 10.1186/s13052-018-0561-2
   Hendriksz CJ, 2013, MOL GENET METAB, V110, P54, DOI 10.1016/j.ymgme.2013.04.002
   Lavery C, 2015, JIMD REP, V15, P59, DOI 10.1007/8904_2014_298
   Montano AM, 2007, J INHERIT METAB DIS, V30, P165, DOI 10.1007/s10545-007-0529-7
   Nagao K, 2018, MOL GENET METAB, V123, P472, DOI 10.1016/j.ymgme.2018.02.002
   RIEDNER ED, 1977, ARCH OTOLARYNGOL, V103, P518
   Saeed H, 2013, INT J PEDIATR OTORHI, V77, P1255, DOI 10.1016/j.ijporl.2013.05.003
   Theroux MC, 2012, PEDIATR ANESTH, V22, P901, DOI 10.1111/j.1460-9592.2012.03904.x
   Tomatsu S, 2011, CURR PHARM BIOTECHNO, V12, P931, DOI 1389-2010/11 $58.00+.00
NR 9
TC 2
Z9 2
U1 0
U2 0
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 2050-313X
J9 SAGE OPEN MED CASE R
JI SAGE Open Med. Case Rep.
PD AUG
PY 2019
VL 7
AR 2050313X19873791
DI 10.1177/2050313X19873791
PG 6
WC Medicine, General & Internal
SC General & Internal Medicine
GA IU4CT
UT WOS:000483535100001
PM 31516706
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Stokes, RC
   Venezia, JH
   Hickok, G
AF Stokes, Ryan C.
   Venezia, Jonathan H.
   Hickok, Gregory
TI The motor system's [modest] contribution to speech perception
SO PSYCHONOMIC BULLETIN & REVIEW
LA English
DT Article
DE Speech; Motor theory of speech perception; Motor cortex; Articulatory
   suppression
ID ARTICULATORY SUPPRESSION; PSYCHOMETRIC FUNCTIONS; CORTICAL ORGANIZATION;
   STATISTICAL POWER; MIRROR-NEURONS; CORTEX; LANGUAGE; DISCRIMINATION;
   APHASIA; COMPREHENSION
AB Recent evidence suggests that the motor system may have a facilitatory role in speech perception during noisy listening conditions. Studies clearly show an association between activity in auditory and motor speech systems, but also hint at a causal role for the motor system in noisy speech perception. However, in the most compelling "causal" studies performance was only measured at a single signal-to-noise ratio (SNR). If listening conditions must be noisy to invoke causal motor involvement, then effects will be contingent on the SNR at which they are tested. We used articulatory suppression to disrupt motor-speech areas while measuring phonemic identification across a range of SNRs. As controls, we also measured phoneme identification during passive listening, mandible gesturing, and foot-tapping conditions. Two-parameter (threshold, slope) psychometric functions were fit to the data in each condition. Our findings indicate: (1) no effect of experimental task on psychometric function slopes; (2) a small effect of articulatory suppression, in particular, on psychometric function thresholds. The size of the latter effect was 1 dB (similar to 5% correct) on average, suggesting, at best, a minor modulatory role of the speech motor system in perception.
C1 [Stokes, Ryan C.; Venezia, Jonathan H.; Hickok, Gregory] Univ Calif Irvine, Dept Cognit Sci Social & Behav Sci Gateway, Irvine, CA 92697 USA.
RP Stokes, RC (corresponding author), Univ Calif Irvine, Dept Cognit Sci Social & Behav Sci Gateway, Irvine, CA 92697 USA.
EM stokesr@uci.edu
RI Venezia, Jonathan/AAD-1296-2019
FU NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC009659, R01DC009659, R01DC009659,
   R01DC009659] Funding Source: NIH RePORTER; NIDCD NIH HHSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01 DC009659, DC009659] Funding Source: Medline
CR Alwan A, 2011, SPEECH COMMUN, V53, P195, DOI 10.1016/j.specom.2010.09.001
   Archila-Melendez ME, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0252-17.2018
   Arlinger S, 2009, SCAND J PSYCHOL, V50, P371, DOI 10.1111/j.1467-9450.2009.00753.x
   Arsenault JS, 2016, PSYCHON B REV, V23, P1231, DOI 10.3758/s13423-015-0988-z
   BADDELEY A, 1984, Q J EXP PSYCHOL-A, V36, P233, DOI 10.1080/14640748408402157
   Barnaud ML, 2018, BRAIN LANG, V187, P19, DOI 10.1016/j.bandl.2017.12.003
   Bever TG, 2010, BIOLINGUISTICS, V4, P174
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   BISHOP DVM, 1990, J SPEECH HEAR RES, V33, P210, DOI 10.1044/jshr.3302.210
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Buss E, 2009, J ACOUST SOC AM, V125, P1050, DOI 10.1121/1.3050273
   Cheung C, 2016, ELIFE, V5, DOI 10.7554/eLife.12577
   COLE RA, 1978, J ACOUST SOC AM, V64, P44, DOI 10.1121/1.381955
   Correia JM, 2015, J NEUROSCI, V35, P15015, DOI 10.1523/JNEUROSCI.0977-15.2015
   Craigherol L, 2007, PROG BRAIN RES, V164, P39, DOI 10.1016/S0079-6123(07)64003-5
   D'Ausilio A, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0418
   D'Ausilio A, 2011, BRAIN LANG, V118, P9, DOI 10.1016/j.bandl.2011.02.007
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   Devlin JT, 2007, BRAIN, V130, P610, DOI 10.1093/brain/awl331
   Du Y, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12241
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fechner G. T., 1860, ELEMENTE PSYCHOPHYSI
   Guenther FH, 1998, PSYCHOL REV, V105, P611, DOI 10.1037/0033-295X.105.4.611-633
   Hamilton L. S., 2018, CURRENT BIOL
   Hanley JR, 2003, PSYCHON B REV, V10, P435, DOI 10.3758/BF03196503
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2008, BRAIN LANG, V107, P179, DOI 10.1016/j.bandl.2008.09.006
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2014, LANG COGN NEUROSCI, V29, P2, DOI 10.1080/01690965.2013.834370
   Hickok G, 2012, J COMMUN DISORD, V45, P393, DOI 10.1016/j.jcomdis.2012.06.004
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158
   Hickok G, 2011, BRAIN LANG, V119, P214, DOI 10.1016/j.bandl.2011.08.001
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Hickok G, 2010, LANG COGNITIVE PROC, V25, P749, DOI 10.1080/01690961003595572
   Hillis AE, 2007, NEUROLOGY, V69, P200, DOI 10.1212/01.wnl.0000265600.69385.6f
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213
   Houde JF, 2002, J COGNITIVE NEUROSCI, V14, P1125, DOI 10.1162/089892902760807140
   Klatt D. H., 1980, PERCEPTION PRODUCTIO, P243
   Klein SA, 2001, PERCEPT PSYCHOPHYS, V63, P1421, DOI 10.3758/BF03194552
   Kleiner M, 2007, PERCEPTION, V36, P14
   Kontsevich LI, 1999, J OPT SOC AM A, V16, P217, DOI 10.1364/JOSAA.16.000217
   Kuhl PK, 1971, ANN NY ACAD SCI, V185, P345
   Laurent R., 2017, PSYCHOL REV
   LEEK MR, 1992, PERCEPT PSYCHOPHYS, V51, P247, DOI 10.3758/BF03212251
   Lenneberg E. H, 1962, UNDERSTANDING LANGUA
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Liebenthal E, 2018, BRAIN LANG, V187, P33, DOI 10.1016/j.bandl.2017.12.004
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Liu HT, 2016, J DEAF STUD DEAF EDU, V21, P362, DOI 10.1093/deafed/enw048
   MacPherson A, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514537722
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Mottonen R, 2012, APHASIOLOGY, V26, P1103, DOI 10.1080/02687038.2011.619515
   MOHR JP, 1978, NEUROLOGY, V28, P311, DOI 10.1212/WNL.28.4.311
   Morey RD, 2008, TUTOR QUANT METHODS, V4, P61, DOI 10.20982/tqmp.04.2.p061
   Morgan M, 2012, ATTEN PERCEPT PSYCHO, V74, P185, DOI 10.3758/s13414-011-0222-7
   Morillon B, 2015, CURR OPIN NEUROBIOL, V31, P230, DOI 10.1016/j.conb.2014.12.005
   Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009
   Okada K, 2018, PSYCHON B REV, V25, P423, DOI 10.3758/s13423-017-1284-x
   Panouilleres MTN, 2018, NEUROBIOL AGING, V72, P89, DOI 10.1016/j.neurobiolaging.2018.07.013
   Panouilleres MTN, 2018, CORTEX, V103, P44, DOI 10.1016/j.cortex.2018.02.007
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Potvin PJ, 2000, BEHAV RES METH INS C, V32, P347, DOI 10.3758/BF03207805
   Price CJ, 2000, J ANAT, V197, P335, DOI 10.1046/j.1469-7580.2000.19730335.x
   Prins N., 2009, PALAMEDES MATLAB ROU
   Rogalsky C, 2011, NEUROCASE, V17, P178, DOI 10.1080/13554794.2010.509318
   Ronnberg J, 2011, TRENDS AMPLIF, V15, P140, DOI 10.1177/1084713811409762
   Saeki E, 2004, MEMORY, V12, P257, DOI 10.1080/09658210244000649
   Sams M, 2005, COGNITIVE BRAIN RES, V23, P429, DOI 10.1016/j.cogbrainres.2004.11.006
   Sato M, 2009, BRAIN LANG, V111, P1, DOI 10.1016/j.bandl.2009.03.002
   Schomers MR, 2015, CEREB CORTEX, V25, P3894, DOI 10.1093/cercor/bhu274
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Venezia JH, 2009, LANG LINGUIST COMPAS, V3, P1403, DOI 10.1111/j.1749-818x.2009.00169.x
   Venezia JH, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00157
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   Werker JF, 2005, TRENDS COGN SCI, V9, P519, DOI 10.1016/j.tics.2005.09.003
   Whitford TJ, 2017, ELIFE, V6, DOI 10.7554/eLife.28197
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Wilson SM, 2009, TRENDS COGN SCI, V13, P329, DOI 10.1016/j.tics.2009.06.001
   Wu ZM, 2014, NEUROSCI BULL, V30, P490, DOI 10.1007/s12264-013-1428-6
NR 84
TC 6
Z9 6
U1 2
U2 12
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1069-9384
EI 1531-5320
J9 PSYCHON B REV
JI Psychon. Bull. Rev.
PD AUG
PY 2019
VL 26
IS 4
BP 1354
EP 1366
DI 10.3758/s13423-019-01580-2
PG 13
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA IT3VA
UT WOS:000482783800023
PM 30945170
OA Bronze
DA 2021-02-24
ER

PT J
AU Choi, D
   Bruderer, AG
   Werker, JF
AF Choi, Dawoon
   Bruderer, Alison G.
   Werker, Janet F.
TI Sensorimotor influences on speech perception in pre-babbling infants:
   Replication and extension of Bruderer et al. (2015)
SO PSYCHONOMIC BULLETIN & REVIEW
LA English
DT Article
DE Speech perception; Infancy; Language acquisition; Multisensory
ID PHONETIC PERCEPTION; VISUAL SPEECH; 1ST YEAR; LANGUAGE; INFORMATION;
   INTEGRATION; EXPERIENCE; PLACE; CONTRASTS; ADULTS
AB The relationship between speech perception and production is central to understanding language processing, yet remains under debate, particularly in early development. Recent research suggests that in infants aged 6 months, when the native phonological system is still being established, sensorimotor information from the articulators influences speech perception: The placement of a teething toy restricting tongue-tip movements interfered with infants' discrimination of a non-native contrast, /Da/-/da/, that involves tongue-tip movement. This effect was selective: A different teething toy that prevented lip closure but not tongue-tip movement did not disrupt discrimination. We conducted two sets of studies to replicate and extend these findings. Experiments 1 and 2 replicated the study by Bruderer et al. (Proceedings of the National Academy of Sciences of the United States of America, 112 (44), 13531-13536, 2015), but with synthesized auditory stimuli. Infants discriminated the non-native contrast (dental /da/ - retroflex /Da/) (Experiment 1), but showed no evidence of discrimination when the tongue-tip movement was prevented with a teething toy (Experiment 2). Experiments 3 and 4 extended this work to a native phonetic contrast (bilabial /ba/ - dental /da/). Infants discriminated the distinction with no teething toy present (Experiment 3), but when they were given a teething toy that interfered only with lip closure, a movement involved in the production of /ba/, discrimination was disrupted (Experiment 4). Importantly, this was the same teething toy that did not interfere with discrimination of /da/-/Da/ in Bruderer et al. (2015). These findings reveal specificity in the relation between sensorimotor and perceptual processes in pre-babbling infants, and show generalizability to a second phonetic contrast.
C1 [Choi, Dawoon; Werker, Janet F.] Univ British Columbia, Dept Psychol, 2136 West Mall, Vancouver, BC V6T 1Z4, Canada.
   [Bruderer, Alison G.] North Isl Coll, 2300 Ryan Rd, Courtenay, BC V9N 8N6, Canada.
RP Choi, D (corresponding author), Univ British Columbia, Dept Psychol, 2136 West Mall, Vancouver, BC V6T 1Z4, Canada.
EM dchoi@psych.ubc.ca
OI Werker, Janet F./0000-0002-1168-9013
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [1R21HD079260-01];
   Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR
   [RGPIN-2015-03967]
FX This research is funded by grants from the National Institutes of Health
   (1R21HD079260-01) and the Natural Sciences and Engineering Research
   Council of Canada (RGPIN-2015-03967) to Janet F. Werker.
CR Best C., 1995, SPEECH PERCEPTION LI, P171
   Best C.T., 1998, INFANT BEHAV DEV, V21, P295, DOI [10.1016/S0163, DOI 10.1016/S0163, DOI 10.1016/S0163-6383(98)91508-9]
   Best CC, 2003, LANG SPEECH, V46, P183, DOI 10.1177/00238309030460020701
   Bristow D, 2009, J COGNITIVE NEUROSCI, V21, P905, DOI 10.1162/jocn.2009.21076
   Bruderer AG, 2015, P NATL ACAD SCI USA, V112, P13531, DOI 10.1073/pnas.1508631112
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Chen X, 2004, DEVELOPMENTAL SCI, V7, P42, DOI 10.1111/j.1467-7687.2004.00321.x
   Coulon M, 2013, INFANCY, V18, P782, DOI 10.1111/infa.12001
   Danielson DK, 2017, COGNITIVE DEV, V42, P37, DOI 10.1016/j.cogdev.2017.02.004
   Dehaene-Lambertz G, 2006, P NATL ACAD SCI USA, V103, P14240, DOI 10.1073/pnas.0606302103
   DePaolis RA, 2011, INFANT BEHAV DEV, V34, P590, DOI 10.1016/j.infbeh.2011.06.005
   Dubois J, 2016, CEREB CORTEX, V26, P2283, DOI 10.1093/cercor/bhv082
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   ERBER NP, 1975, J SPEECH HEAR DISORD, V40, P481, DOI 10.1044/jshd.4004.481
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Feldman NH, 2013, COGNITION, V127, P427, DOI 10.1016/j.cognition.2013.02.007
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Guellai B, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00812
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Imada T, 2006, NEUROREPORT, V17, P957, DOI 10.1097/01.wnr.0000223387.51704.89
   JASP Team, 2017, JASP VERS 0 9 1 COMP
   Kuhl PK, 2014, P NATL ACAD SCI USA, V111, P11238, DOI 10.1073/pnas.1410963111
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Kuhl PK, 1996, J ACOUST SOC AM, V100, P2425, DOI 10.1121/1.417951
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Lee M. D., 2014, BAYESIAN COGNITIVE M
   Leroy F, 2011, J NEUROSCI, V31, P1500, DOI 10.1523/JNEUROSCI.4141-10.2011
   MACKAIN KS, 1981, APPL PSYCHOLINGUIST, V2, P369, DOI 10.1017/S0142716400009796
   Majorano M, 2014, LANG LEARN DEV, V10, P179, DOI 10.1080/15475441.2013.829740
   Matchin W, 2014, J COGNITIVE NEUROSCI, V26, P606, DOI 10.1162/jocn_a_00515
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Mottonen R, 2013, CEREB CORTEX, V23, P1190, DOI 10.1093/cercor/bhs110
   Munhall K.G., 2004, HDB MULTISENSORY PRO, P177
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Okada K, 2009, NEUROSCI LETT, V452, P219, DOI 10.1016/j.neulet.2009.01.060
   Patterson ML, 1999, INFANT BEHAV DEV, V22, P237, DOI 10.1016/S0163-6383(99)00003-X
   Pena M, 2012, J NEUROSCI, V32, P11159, DOI 10.1523/JNEUROSCI.6516-11.2012
   Perani D, 2011, P NATL ACAD SCI USA, V108, P16056, DOI 10.1073/pnas.1102991108
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Reale RA, 2007, NEUROSCIENCE, V145, P162, DOI 10.1016/j.neuroscience.2006.11.036
   Rivera-Gaxiola M, 2005, DEVELOPMENTAL SCI, V8, P162, DOI 10.1111/j.1467-7687.2005.00403.x
   Sams M, 2005, COGNITIVE BRAIN RES, V23, P429, DOI 10.1016/j.cogbrainres.2004.11.006
   Scott M, 2013, J ACOUST SOC AM, V133, pEL286, DOI 10.1121/1.4794932
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Streri A, 2016, INFANCY, V21, P177, DOI 10.1111/infa.12104
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Teinonen T, 2008, COGNITION, V108, P850, DOI 10.1016/j.cognition.2008.05.009
   Tyler MD, 2014, DEV PSYCHOBIOL, V56, P210, DOI 10.1002/dev.21195
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Wagenmakers EJ, 2018, PSYCHON B REV, V25, P58, DOI [10.3758/s13423-017-1323-7, 10.3758/s13423-017-1343-3]
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1988, DEV PSYCHOL, V24, P672, DOI 10.1037/0012-1649.24.5.672
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
   Whitehill TL, 2003, J SPEECH LANG HEAR R, V46, P451, DOI 10.1044/1092-4388(2003/037)
   Yeung HH, 2013, PSYCHOL SCI, V24, P603, DOI 10.1177/0956797612458802
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   Yeung HH, 2009, COGNITION, V113, P234, DOI 10.1016/j.cognition.2009.08.010
NR 61
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1069-9384
EI 1531-5320
J9 PSYCHON B REV
JI Psychon. Bull. Rev.
PD AUG
PY 2019
VL 26
IS 4
BP 1388
EP 1399
DI 10.3758/s13423-019-01601-0
PG 12
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA IT3VA
UT WOS:000482783800026
PM 31037603
OA Bronze, Green Accepted
DA 2021-02-24
ER

PT J
AU Dombrowski, T
   Rankovic, V
   Moser, T
AF Dombrowski, Tobias
   Rankovic, Vladan
   Moser, Tobias
TI Toward the Optical Cochlear Implant
SO COLD SPRING HARBOR PERSPECTIVES IN MEDICINE
LA English
DT Article
ID GUINEA-PIG COCHLEA; INFRARED NEURAL STIMULATION; MEDIATED GENE-TRANSFER;
   AUDITORY-NERVE FIBERS; OPTOGENETICS 10 YEARS; INNER-EAR; ADENOASSOCIATED
   VIRUS; TRANSGENE EXPRESSION; VESTIBULAR FUNCTION; AAV VECTORS
AB When hearing fails, cochlear implants (CIs) provide open speech perception to most of the currently half a million CI users. CIs bypass the defective sensory organ and stimulate the auditory nerve electrically. The major bottleneck of current CIs is the poor coding of spectral information, which results from wide current spread from each electrode contact. As light can be more conveniently confined, optical stimulation of the auditory nerve presents a promising perspective for a fundamental advance of CIs. Moreover, given the improved frequency resolution of optical excitation and its versatility for arbitrary stimulation patterns the approach also bears potential for auditory research. Here, we review the current state of the art focusing on the emerging concept of optogenetic stimulation of the auditory pathway. Developing optogenetic stimulation for auditory research and future CIs requires efforts toward viral gene transfer to the neurons, design and characterization of appropriate optogenetic actuators, as well as engineering of multichannel optical implants.
C1 [Dombrowski, Tobias; Rankovic, Vladan; Moser, Tobias] Univ Med Ctr, Inst Auditory Neurosci, D-37075 Gottingen, Germany.
   [Dombrowski, Tobias; Rankovic, Vladan; Moser, Tobias] Univ Med Ctr, InnerEarLab, D-37075 Gottingen, Germany.
   [Dombrowski, Tobias] Ruhr Univ Bochum, St Elisabeth Hosp, Dept Otorhinolaryngol Head & Neck Surg, D-44787 Bochum, Germany.
   [Rankovic, Vladan; Moser, Tobias] German Primate Ctr, Auditory Neurosci & Optogenet Grp, D-37077 Gottingen, Germany.
   [Moser, Tobias] Max Planck Inst Expt Med, Auditory Neurosci Grp, D-37075 Gottingen, Germany.
RP Rankovic, V; Moser, T (corresponding author), Univ Med Ctr, Inst Auditory Neurosci, D-37075 Gottingen, Germany.; Rankovic, V; Moser, T (corresponding author), Univ Med Ctr, InnerEarLab, D-37075 Gottingen, Germany.; Rankovic, V; Moser, T (corresponding author), German Primate Ctr, Auditory Neurosci & Optogenet Grp, D-37077 Gottingen, Germany.; Moser, T (corresponding author), Max Planck Inst Expt Med, Auditory Neurosci Grp, D-37075 Gottingen, Germany.
EM vrankovic@dpz.eu; tmoser@gwdg.de
RI Rankovic, Vladan/S-4353-2019; Moser, Tobias/L-5068-2014
OI Rankovic, Vladan/0000-0003-0285-5232; Moser, Tobias/0000-0001-7145-0533
CR A Kotterman Melissa, 2015, Neurogenesis (Austin), V2, pe1122700, DOI 10.1080/23262133.2015.1122700
   Adamantidis A, 2015, NAT NEUROSCI, V18, P1202, DOI 10.1038/nn.4106
   Akil O, 2012, NEURON, V75, P283, DOI 10.1016/j.neuron.2012.05.019
   Astolfi L, 2016, HEARING RES, V336, P44, DOI 10.1016/j.heares.2016.04.005
   Boyden ES, 2005, NAT NEUROSCI, V8, P1263, DOI 10.1038/nn1525
   Chaffiol A, 2017, MOL THER, V25, P2546, DOI 10.1016/j.ymthe.2017.07.011
   Chan KY, 2017, NAT NEUROSCI, V20, P1172, DOI 10.1038/nn.4593
   Chen X, 2015, GENE THER, V22, P866, DOI 10.1038/gt.2015.63
   Corey DP, 2004, NATURE, V432, P723, DOI 10.1038/nature03066
   Corfas G, 2018, COLD SPRING HARB PER, DOI [10.1101/cshperspect.a035493, DOI 10.1101/CSHPERSPECT.A035493]
   Dai CK, 2017, JARO-J ASSOC RES OTO, V18, P601, DOI 10.1007/s10162-017-0628-6
   Dalkara D, 2013, SCI TRANSL MED, V5, DOI 10.1126/scitranslmed.3005708
   Dazert S, 1997, INT J DEV NEUROSCI, V15, P595, DOI 10.1016/S0736-5748(96)00114-1
   Deisseroth K, 2015, NAT NEUROSCI, V18, P1213, DOI 10.1038/nn.4091
   Deverman BE, 2016, NAT BIOTECHNOL, V34, P204, DOI 10.1038/nbt.3440
   Donaldson GS, 2005, J ACOUST SOC AM, V118, P623, DOI 10.1121/1.1937362
   Dunbar CE, 2018, SCIENCE, V359, P175, DOI 10.1126/science.aan4672
   Emptoz A, 2017, P NATL ACAD SCI USA, V114, P9695, DOI 10.1073/pnas.1708894114
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538
   Ge XX, 2007, OTOLARYNG HEAD NECK, V137, P619, DOI 10.1016/j.otohns.2007.04.013
   Gossler C, 2014, J PHYS D APPL PHYS, V47, DOI 10.1088/0022-3727/47/20/205401
   Gradinaru V, 2010, CELL, V141, P154, DOI 10.1016/j.cell.2010.02.037
   Gunaydin LA, 2010, NAT NEUROSCI, V13, P387, DOI 10.1038/nn.2495
   Guo W, 2015, SCI REP-UK, V5, DOI 10.1038/srep10319
   Gyorgy B, 2017, MOL THER, V25, P379, DOI 10.1016/j.ymthe.2016.12.010
   Han JJ, 1999, HUM GENE THER, V10, P1867, DOI 10.1089/10430349950017545
   Han MM, 2015, NEUROSCI LETT, V600, P164, DOI 10.1016/j.neulet.2015.06.011
   Hernandez VH, 2014, J CLIN INVEST, V124, P1114, DOI 10.1172/JCI69050
   Hickey DG, 2017, GENE THER, V24, P787, DOI 10.1038/gt.2017.85
   Hight AE, 2015, HEARING RES, V322, P235, DOI 10.1016/j.heares.2015.01.004
   Hofherr A, 2005, J CELL SCI, V118, P1935, DOI 10.1242/jcs.02322
   Holt JR, 1999, J NEUROPHYSIOL, V81, P1881
   Holt JR, 2002, AUDIOL NEURO-OTOL, V7, P157, DOI 10.1159/000058302
   Husseman J, 2009, ADV OTO-RHINO-LARYNG, V66, P37, DOI 10.1159/000218206
   Izzo AD, 2008, BIOPHYS J, V94, P3159, DOI 10.1529/biophysj.107.117150
   Izzo AD, 2007, J BIOMED OPT, V12, DOI 10.1117/1.2714296
   Jeschke M, 2015, HEARING RES, V322, P224, DOI 10.1016/j.heares.2015.01.005
   Jung SY, 2015, EMBO J, V34, P2686, DOI 10.15252/embj.201591885
   Kang R, 2009, EAR HEARING, V30, P411, DOI 10.1097/AUD.0b013e3181a61bc0
   Keppeler D, 2018, EMBO J, V37, DOI 10.15252/embj.201899649
   Khabou H, 2016, BIOTECHNOL BIOENG, V113, P2712, DOI 10.1002/bit.26031
   Klapoetke NC, 2014, NAT METHODS, V11, P338, DOI [10.1038/nmeth.2836, 10.1038/NMETH.2836]
   Kleinlogel S, 2011, NAT NEUROSCI, V14, P513, DOI 10.1038/nn.2776
   Kohlberg G, 2014, LARYNGOSCOPE, V124, P587, DOI 10.1002/lary.24171
   Konishi M, 2008, J GENE MED, V10, P610, DOI 10.1002/jgm.1189
   Kraft S, 2013, LARYNGOSCOPE, V123, P992, DOI 10.1002/lary.22171
   Kral A, 1998, HEARING RES, V121, P11, DOI 10.1016/S0378-5955(98)00061-6
   Kurioka T, 2016, GENE THER, V23, P187, DOI 10.1038/gt.2015.94
   Lalwani AK, 1996, GENE THER, V3, P588
   Landegger LD, 2017, NAT BIOTECHNOL, V35, P280, DOI 10.1038/nbt.3781
   Laubsch A, 2010, IEEE T ELECTRON DEV, V57, P79, DOI 10.1109/TED.2009.2035538
   Li H, 2017, BIOMATERIALS, V122, P1, DOI 10.1016/j.biomaterials.2016.12.020
   LIBERMAN MC, 1978, J ACOUST SOC AM, V63, P442, DOI 10.1121/1.381736
   Lima SQ, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006099
   Luebke AE, 2001, HUM GENE THER, V12, P773, DOI 10.1089/104303401750148702
   Luebke AE, 2001, GENE THER, V8, P789, DOI 10.1038/sj.gt.3301445
   Luecke H, 2001, SCIENCE, V293, P1499, DOI 10.1126/science.1062977
   Lustig L, 2019, CSH PERSPECT MED, V9, DOI 10.1101/cshperspect.a033191
   Ma DK, 2001, SCIENCE, V291, P316, DOI 10.1126/science.291.5502.316
   Maass JC, 2013, JARO-J ASSOC RES OTO, V14, P495, DOI 10.1007/s10162-013-0383-2
   MacDougall M, 2016, J NEUROPHYSIOL, V116, P1286, DOI 10.1152/jn.00197.2016
   Mager T, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04146-3
   Middlebrooks JC, 2008, HEARING RES, V242, P52, DOI 10.1016/j.heares.2008.04.001
   Mingozzi F, 2013, BLOOD, V122, P23, DOI 10.1182/blood-2013-01-306647
   Miyashita T, 2013, FRONT NEURAL CIRCUIT, V7, DOI 10.3389/fncir.2013.00008
   Moser T, 2016, NAT REV NEUROL, V12, P135, DOI 10.1038/nrneurol.2016.10
   Moser T, 2015, CURR OPIN NEUROBIOL, V34, P29, DOI 10.1016/j.conb.2015.01.004
   Nagel G, 2002, SCIENCE, V296, P2395, DOI 10.1126/science.1072068
   Nagel G, 2003, P NATL ACAD SCI USA, V100, P13940, DOI 10.1073/pnas.1936192100
   Nakanishi T, 2013, BIOPHYS J, V104, P377, DOI 10.1016/j.bpj.2012.12.018
   Ogita H, 2009, ORL-J OTO-RHIN-LARYN, V71, P32, DOI 10.1159/000165915
   Pan B, 2017, NAT BIOTECHNOL, V35, P264, DOI 10.1038/nbt.3801
   Perny M, 2016, CELL DEATH DIS, V7, DOI 10.1038/cddis.2016.351
   Pinyon JL, 2014, SCI TRANSL MED, V6, DOI 10.1126/scitranslmed.3008177
   Praetorius M, 2007, ACTA OTO-LARYNGOL, V127, P486, DOI 10.1080/00016480600895102
   Quan YZ, 2015, SCI REP-UK, V5, DOI 10.1038/srep08181
   Rance G, 2015, BRAIN, V138, DOI 10.1093/brain/awv270
   Reisinger E, 2011, J NEUROSCI, V31, P4886, DOI 10.1523/JNEUROSCI.5122-10.2011
   Richardson GP, 2019, CSH PERSPECT MED, V9, DOI 10.1101/cshperspect.a033142
   Richardson RT, 2017, EXPERT OPIN BIOL TH, V17, P213, DOI 10.1080/14712598.2017.1271870
   Richter CP, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/5/056006
   Rost BR, 2017, NEURON, V96, P572, DOI 10.1016/j.neuron.2017.09.047
   Roy S, 2010, INT J PHARMACEUT, V390, P214, DOI 10.1016/j.ijpharm.2010.02.003
   Rubinstein JT, 1999, HEARING RES, V127, P108, DOI 10.1016/S0378-5955(98)00185-3
   Russell DW, 2007, MOL THER, V15, P1740, DOI 10.1038/sj.mt.6300299
   Rutherford MA, 2012, J NEUROSCI, V32, P4773, DOI 10.1523/JNEUROSCI.4511-11.2012
   Sahel JA, 2013, ANNU REV NEUROSCI, V36, P467, DOI 10.1146/annurev-neuro-062012-170304
   San Sebastian W, 2013, GENE THER, V20, P1178, DOI 10.1038/gt.2013.48
   Santiago-Ortiz J, 2015, GENE THER, V22, P934, DOI 10.1038/gt.2015.74
   Schultz M, 2012, BIOMED OPT EXPRESS, V3, P3332, DOI 10.1364/BOE.3.003332
   Shannon RV, 2012, CURR OPIN NEUROL, V25, P61, DOI 10.1097/WCO.0b013e32834ef878
   SHANNON RV, 1983, HEARING RES, V12, P1, DOI 10.1016/0378-5955(83)90115-6
   Shapiro MG, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms1742
   Shibata SB, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09805-x
   Shimano T, 2013, BRAIN RES, V1511, P138, DOI 10.1016/j.brainres.2012.10.030
   Shu YL, 2016, HUM GENE THER, V27, P687, DOI 10.1089/hum.2016.053
   Simonelli F, 2010, MOL THER, V18, P643, DOI 10.1038/mt.2009.277
   Staecker H, 2001, ACTA OTO-LARYNGOL, V121, P157
   Staecker H, 2014, LARYNGOSCOPE, V124, pS1, DOI 10.1002/lary.24775
   Stockklausner C, 2001, FEBS LETT, V493, P129, DOI 10.1016/S0014-5793(01)02286-4
   Strenzke N, 2009, J NEUROSCI, V29, P7991, DOI 10.1523/JNEUROSCI.0632-09.2009
   Suzuki J, 2017, SCI REP-UK, V7, DOI 10.1038/srep45524
   Taberner AM, 2005, J NEUROPHYSIOL, V93, P557, DOI 10.1152/jn.00574.2004
   Tehovnik EJ, 2006, J NEUROPHYSIOL, V96, P512, DOI 10.1152/jn.00126.2006
   Teudt IU, 2011, IEEE T BIO-MED ENG, V58, P1648, DOI 10.1109/TBME.2011.2108297
   Thaler M, 2011, NANOMED-NANOTECHNOL, V7, P360, DOI 10.1016/j.nano.2010.11.005
   Thompson AC, 2015, HEARING RES, V324, P46, DOI 10.1016/j.heares.2015.03.005
   Tomita H, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007679
   Vellinga D, 2017, EAR HEARING, V38, P487, DOI 10.1097/AUD.0000000000000416
   Verma RU, 2014, HEARING RES, V310, P69, DOI 10.1016/j.heares.2014.01.008
   Wang H, 2007, P NATL ACAD SCI USA, V104, P8143, DOI 10.1073/pnas.0700384104
   Wassmer SJ, 2017, SCI REP-UK, V7, DOI 10.1038/srep45329
   Weiss RS, 2016, NETWORK-COMP NEURAL, V27, P212, DOI 10.1080/0954898X.2016.1224944
   Wells J, 2007, BIOPHYS J, V93, P2567, DOI 10.1529/biophysj.107.104786
   Wenzel GI, 2007, OTOL NEUROTOL, V28, P1100, DOI 10.1097/MAO.0b013e318158973f
   WINTER IM, 1990, HEARING RES, V45, P191, DOI 10.1016/0378-5955(90)90120-E
   Wrobel C, 2018, SCI TRANSL MED, V10, DOI 10.1126/scitranslmed.aao0540
   Wu T, 2016, BIOPHYS J, V110, P493, DOI 10.1016/j.bpj.2015.11.3521
   Yizhar O, 2011, NEURON, V71, P9, DOI 10.1016/j.neuron.2011.06.004
   Zeng FG, 2017, IEEE T BIO-MED ENG, V64, P1662, DOI 10.1109/TBME.2017.2718939
   Zeng Fan-Gang, 2008, IEEE Rev Biomed Eng, V1, P115, DOI 10.1109/RBME.2008.2008250
   Zeng FG, 2002, J ACOUST SOC AM, V111, P377, DOI 10.1121/1.1423926
   Zeng FG, 1999, EAR HEARING, V20, P60, DOI 10.1097/00003446-199902000-00006
   Zhang WK, 2011, INT J NANOMED, V6, P535, DOI 10.2147/IJN.S16973
   Zierhofer C. M., 1995, IEEE Transactions on Rehabilitation Engineering, V3, P112, DOI 10.1109/86.372900
   Zinn E, 2015, CELL REP, V12, P1056, DOI 10.1016/j.celrep.2015.07.019
NR 126
TC 7
Z9 7
U1 0
U2 6
PU COLD SPRING HARBOR LAB PRESS, PUBLICATIONS DEPT
PI COLD SPRING HARBOR
PA 1 BUNGTOWN RD, COLD SPRING HARBOR, NY 11724 USA
SN 2157-1422
J9 CSH PERSPECT MED
JI Cold Spring Harb. Perspect. Med.
PD AUG
PY 2019
VL 9
IS 8
AR a033225
DI 10.1101/cshperspect.a033225
PG 15
WC Medicine, Research & Experimental
SC Research & Experimental Medicine
GA IT2GV
UT WOS:000482669100004
PM 30323016
DA 2021-02-24
ER

PT J
AU Sheng, JW
   Zheng, L
   Lyu, BJ
   Cen, ZH
   Qin, L
   Tan, LH
   Huang, MX
   Ding, N
   Gao, JH
AF Sheng, Jingwei
   Zheng, Li
   Lyu, Bingjiang
   Cen, Zhehang
   Qin, Lang
   Tan, Li Hai
   Huang, Ming-Xiong
   Ding, Nai
   Gao, Jia-Hong
TI The Cortical Maps of Hierarchical Linguistic Structures during Speech
   Perception
SO CEREBRAL CORTEX
LA English
DT Article
DE linguistic hierarchy; MEG; minimum L1-norm; motor cortex
ID TEMPORAL CORTEX; LANGUAGE; BRAIN; RESPONSES; REPRESENTATION;
   COMPREHENSION; OSCILLATIONS; UNIFICATION; MECHANISMS; PATTERNS
AB The hierarchical nature of language requires human brain to internally parse connected-speech and incrementally construct abstract linguistic structures. Recent research revealed multiple neural processing timescales underlying grammar-based configuration of linguistic hierarchies. However, little is known about where in the whole cerebral cortex such temporally scaled neural processes occur. This study used novel magnetoencephalography source imaging techniques combined with a unique language stimulation paradigm to segregate cortical maps synchronized to 3 levels of linguistic units (i.e., words, phrases, and sentences). Notably, distinct ensembles of cortical loci were identified to feature structures at different levels. The superior temporal gyrus was found to be involved in processing all 3 linguistic levels while distinct ensembles of other brain regions were recruited to encode each linguistic level. Neural activities in the right motor cortex only followed the rhythm of monosyllabic words which have clear acoustic boundaries, whereas the left anterior temporal lobe and the left inferior frontal gyrus were selectively recruited in processing phrases or sentences. Our results ground a multi-timescale hierarchical neural processing of speech in neuroanatomical reality with specific sets of cortices responsible for different levels of linguistic units.
C1 [Sheng, Jingwei; Cen, Zhehang; Gao, Jia-Hong] Peking Univ, Sch Phys, Inst Heavy Ion Phys, Beijing City Key Lab Med Phys & Engn, Beijing 100871, Peoples R China.
   [Sheng, Jingwei; Zheng, Li; Cen, Zhehang; Qin, Lang; Gao, Jia-Hong] Peking Univ, Acad Adv Interdisciplinary Studies, Ctr MRI Res, Beijing 100871, Peoples R China.
   [Sheng, Jingwei; Zheng, Li; Cen, Zhehang; Gao, Jia-Hong] Peking Univ, McGovern Inst Brain Res, Beijing 100871, Peoples R China.
   [Zheng, Li] Peking Univ, Dept Biomed Engn, Beijing 100871, Peoples R China.
   [Lyu, Bingjiang] Univ Cambridge, Dept Psychol, Ctr Speech Language & Brain, Cambridge CB2 3EB, England.
   [Qin, Lang] Univ Hong Kong, Dept Linguist, Hong Kong, Peoples R China.
   [Tan, Li Hai] Shenzhen Univ, Ctr Brain Disorders & Cognit Sci, Shenzhen 518060, Guangdong, Peoples R China.
   [Tan, Li Hai; Gao, Jia-Hong] Shenzhen Inst Neurosci, Ctr Language & Brain, Shenzhen 518057, Guangdong, Peoples R China.
   [Huang, Ming-Xiong] Univ Calif San Diego, Dept Radiol, San Diego, CA 92093 USA.
   [Huang, Ming-Xiong] VA San Diego Healthcare Syst, Radiol Res & Psychiat Serv, San Diego, CA 92161 USA.
   [Ding, Nai] Zhejiang Univ, Coll Biomed Engn & Instrument Sci, Hangzhou 310027, Zhejiang, Peoples R China.
   [Ding, Nai] Zhejiang Univ, Minist Educ, Key Lab Biomed Engn, Hangzhou 310027, Zhejiang, Peoples R China.
   [Ding, Nai] Zhejiang Univ, State Key Lab Ind Control Technol, Hangzhou 310027, Zhejiang, Peoples R China.
   [Gao, Jia-Hong] Shenzhen Univ, Inst Affect & Social Neurosci, Shenzhen Key Lab Affect & Social Cognit Sci, Shenzhen 518060, Guangdong, Peoples R China.
RP Ding, N (corresponding author), Zhejiang Univ, Coll Biomed Engn & Instrument Sci, Hangzhou 310027, Zhejiang, Peoples R China.; Gao, JH (corresponding author), Peking Univ, Ctr MRI Res, Beijing 100871, Peoples R China.
EM ding_nai@zju.edu.cn; jgao@pku.edu.cn
RI Lyu, Bingjiang/AAE-4293-2019
OI Lyu, Bingjiang/0000-0001-8554-5138
FU National Key Research and Development Program of China [2017YFC0108901];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [81790650, 81790651, 81727808, 81430037,
   31421003, 31771248, 31 500 873]; Beijing Municipal Science & Technology
   CommissionBeijing Municipal Science & Technology Commission
   [Z171100000117012]; Shenzhen Peacock Plan [KQTD2015033016104926];
   Shenzhen Science and Technology Research Funding Program
   [JCYJ20170412164413575]; Guangdong Pearl River Talents Plan Innovative
   and Entrepreneurial Team grant [2016ZT06S220]; State Key Laboratory of
   Industrial Control Technology, Zhejiang University
FX This work was supported by National Key Research and Development Program
   of China (2017YFC0108901); National Natural Science Foundation of China
   grants (81790650, 81790651, 81727808, 81430037, 31421003, 31771248 and
   31 500 873); Beijing Municipal Science & Technology Commission
   (Z171100000117012); Shenzhen Peacock Plan (KQTD2015033016104926);
   Shenzhen Science and Technology Research Funding Program
   (JCYJ20170412164413575); Guangdong Pearl River Talents Plan Innovative
   and Entrepreneurial Team grant (2016ZT06S220) and research funding from
   the State Key Laboratory of Industrial Control Technology, Zhejiang
   University. The authors also thank National Center for Protein Sciences
   at Peking University in Beijing, China, for assistance with MEG and MRI
   data acquisition.
CR Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Baldauf D, 2014, SCIENCE, V344, P424, DOI 10.1126/science.1247003
   Baron SG, 2011, NEUROIMAGE, V55, P1847, DOI 10.1016/j.neuroimage.2011.01.066
   Bastiaansen M, 2015, J COGNITIVE NEUROSCI, V27, P2095, DOI 10.1162/jocn_a_00829
   Bastiaansen M, 2010, J COGNITIVE NEUROSCI, V22, P1333, DOI 10.1162/jocn.2009.21283
   Bemis DK, 2011, J NEUROSCI, V31, P2801, DOI 10.1523/JNEUROSCI.5003-10.2011
   Bernacchia A, 2011, NAT NEUROSCI, V14, P366, DOI 10.1038/nn.2752
   Berwick RC, 2013, TRENDS COGN SCI, V17, P89, DOI 10.1016/j.tics.2012.12.002
   Bourguignon M, 2013, HUM BRAIN MAPP, V34, P314, DOI 10.1002/hbm.21442
   Buiatti M, 2009, NEUROIMAGE, V44, P509, DOI 10.1016/j.neuroimage.2008.09.015
   Chaudhuri R, 2014, ELIFE, V3, DOI 10.7554/eLife.01239
   Chomsky Noam, 1957, SYNTACTIC STRUCTURES
   Ding N, 2017, NEUROSCI BIOBEHAV R, V81, P181, DOI 10.1016/j.neubiorev.2017.02.011
   Ding N, 2017, LANG COGN NEUROSCI, V32, P570, DOI 10.1080/23273798.2016.1215477
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   Engel AK, 2010, CURR OPIN NEUROBIOL, V20, P156, DOI 10.1016/j.conb.2010.02.015
   Everaert MBH, 2015, TRENDS COGN SCI, V19, P729, DOI 10.1016/j.tics.2015.09.008
   Fedorenko E, 2012, CURR BIOL, V22, P2059, DOI 10.1016/j.cub.2012.09.011
   Friederici AD, 2000, BRAIN LANG, V74, P289, DOI 10.1006/brln.2000.2313
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   Ge JQ, 2015, P NATL ACAD SCI USA, V112, P2972, DOI 10.1073/pnas.1416000112
   Gibson E, 1998, COGNITION, V68, P1, DOI 10.1016/S0010-0277(98)00034-1
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Greenberg S, 2003, J PHONETICS, V31, P465, DOI 10.1016/j.wocn.2003.09.005
   Grodzinsky Y, 2006, CURR OPIN NEUROBIOL, V16, P240, DOI 10.1016/j.conb.2006.03.007
   Grodzinsky Y, 2008, TRENDS COGN SCI, V12, P474, DOI 10.1016/j.tics.2008.09.001
   Hagoort P, 2005, TRENDS COGN SCI, V9, P416, DOI 10.1016/j.tics.2005.07.004
   Hagoort P, 2014, ANNU REV NEUROSCI, V37, P347, DOI 10.1146/annurev-neuro-071013-013847
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Huang MX, 2012, NEUROIMAGE, V61, P1067, DOI 10.1016/j.neuroimage.2012.04.029
   Huang MX, 2006, NEUROIMAGE, V31, P1025, DOI 10.1016/j.neuroimage.2006.01.029
   Humphries C, 2006, J COGNITIVE NEUROSCI, V18, P665, DOI 10.1162/jocn.2006.18.4.665
   Humphries C, 2005, HUM BRAIN MAPP, V26, P128, DOI 10.1002/hbm.20148
   Iversen JR, 2009, ANN NY ACAD SCI, V1169, P58, DOI 10.1111/j.1749-6632.2009.04579.x
   Kuhl PK, 2014, P NATL ACAD SCI USA, V111, P11238, DOI 10.1073/pnas.1410963111
   Lerner Y, 2011, J NEUROSCI, V31, P2906, DOI 10.1523/JNEUROSCI.3684-10.2011
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Luo H, 2006, P NATL ACAD SCI USA, V103, P19558, DOI 10.1073/pnas.0607065104
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Lyu BJ, 2016, J NEUROSCI, V36, P10813, DOI 10.1523/JNEUROSCI.0583-16.2016
   Matchin W, 2017, CORTEX, V88, P106, DOI 10.1016/j.cortex.2016.12.010
   Meyer L, 2017, CEREB CORTEX, V27, P4293, DOI 10.1093/cercor/bhw228
   Mitterer H, 2017, ATTEN PERCEPT PSYCHO, V79, P344, DOI 10.3758/s13414-016-1195-3
   MONTAGUE R, 1970, THEORIA, V36, P373
   Morillon B, 2017, P NATL ACAD SCI USA, V114, pE8913, DOI 10.1073/pnas.1705373114
   Nelson MJ, 2017, P NATL ACAD SCI USA, V114, pE3669, DOI 10.1073/pnas.1701590114
   Ou WM, 2009, NEUROIMAGE, V44, P932, DOI 10.1016/j.neuroimage.2008.05.063
   Overath T, 2015, NAT NEUROSCI, V18, P903, DOI 10.1038/nn.4021
   Pallier C, 2011, P NATL ACAD SCI USA, V108, P2522, DOI 10.1073/pnas.1018711108
   Partee Barbara, 2004, COMPOSITIONALITY FOR
   Pellegrino F, 2011, LANGUAGE, V87, P539
   PETERSEN SE, 1988, NATURE, V331, P585, DOI 10.1038/331585a0
   Price AR, 2015, J NEUROSCI, V35, P3276, DOI 10.1523/JNEUROSCI.3446-14.2015
   Ralph MAL, 2017, NAT REV NEUROSCI, V18, P42, DOI 10.1038/nrn.2016.150
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rogalsky C, 2009, CEREB CORTEX, V19, P786, DOI 10.1093/cercor/bhn126
   Salmelin R, 2006, TRENDS COGN SCI, V10, P519, DOI 10.1016/j.tics.2006.09.007
   Scott SK, 2004, J ACOUST SOC AM, V115, P813, DOI 10.1121/1.1639336
   Scott SK, 2009, NAT REV NEUROSCI, V10, P295, DOI 10.1038/nrn2603
   Si XP, 2017, P NATL ACAD SCI USA, V114, P12303, DOI 10.1073/pnas.1710752114
   Vandenberghe R, 2002, J COGNITIVE NEUROSCI, V14, P550, DOI 10.1162/08989290260045800
   von Humboldt WF, 1836, VERSCHIEDENHEIT DESM
   Westerlund M, 2014, NEUROPSYCHOLOGIA, V57, P59, DOI 10.1016/j.neuropsychologia.2014.03.001
NR 64
TC 4
Z9 4
U1 3
U2 14
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 1047-3211
EI 1460-2199
J9 CEREB CORTEX
JI Cereb. Cortex
PD AUG
PY 2019
VL 29
IS 8
BP 3232
EP 3240
DI 10.1093/cercor/bhy191
PG 9
WC Neurosciences
SC Neurosciences & Neurology
GA IT4DE
UT WOS:000482808900004
PM 30137249
DA 2021-02-24
ER

PT J
AU Puschmann, S
   Baillet, S
   Zatorre, RJ
AF Puschmann, Sebastian
   Baillet, Sylvain
   Zatorre, Robert J.
TI Musicians at the Cocktail Party: Neural Substrates of Musical Training
   During Selective Listening in Multispeaker Situations
SO CEREBRAL CORTEX
LA English
DT Article
DE auditory cognition; MEG; selective attention; speech
ID WORKING-MEMORY CAPACITY; SURFACE-BASED ANALYSIS; CORTICAL
   REPRESENTATION; INDIVIDUAL-DIFFERENCES; SPEECH-PERCEPTION;
   AUDITORY-CORTEX; BRAIN-STEM; TOP-DOWN; OSCILLATIONS; NOISE
AB Musical training has been demonstrated to benefit speech-in-noise perception. It is however unknown whether this effect translates to selective listening in cocktail party situations, and if so what its neural basis might be. We investigated this question using magnetoencephalography-based speech envelope reconstruction and a sustained selective listening task, in which participants with varying amounts of musical training attended to 1 of 2 speech streams while detecting rare target words. Cortical frequency-following responses (FFR) and auditory working memory were additionally measured to dissociate musical training-related effects on low-level auditory processing versus higher cognitive function. Results show that the duration of musical training is associated with a reduced distracting effect of competing speech on target detection accuracy. Remarkably, more musical training was related to a robust neural tracking of both the to-be-attended and the to-be-ignored speech stream, up until late cortical processing stages. Musical training-related increases in FFR power were associated with a robust speech tracking in auditory sensory areas, whereas training-related differences in auditory working memory were linked to an increased representation of the to-be-ignored stream beyond auditory cortex. Our findings suggest that musically trained persons can use additional information about the distracting stream to limit interference by competing speech.
C1 [Puschmann, Sebastian; Baillet, Sylvain; Zatorre, Robert J.] McGill Univ, Montreal Neurol Inst, Montreal, PQ H3A 2B4, Canada.
   [Puschmann, Sebastian; Baillet, Sylvain; Zatorre, Robert J.] Ctr Res Brain Language & Mus, Montreal, PQ H3G 2A8, Canada.
   [Zatorre, Robert J.] Int Lab Brain Mus & Sound Res, Montreal, PQ H2V 2J2, Canada.
RP Puschmann, S (corresponding author), Montreal Neurol Inst, Cognit Neurosci Unit, 3801 Rue Univ, Montreal, PQ H3A 2B4, Canada.
EM sebastian.puschmann@mail.mcgill.ca
RI Baillet, Sylvain/AAF-6512-2019
OI Baillet, Sylvain/0000-0002-6762-5713
FU Deutsche Forschungsgemeinschaft (DFG)German Research Foundation (DFG)
   [PU590/1]; Natural Sciences and Engineering Research Council of Canada
   (NSERC)Natural Sciences and Engineering Research Council of Canada
   (NSERC) [436355-13]; National Institutes of Health (NIH)United States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USA [2R01EB009048-05]; Brain Canada Foundation [PSG15-3755]; Canadian
   Institutes of Health Research (CIHR)Canadian Institutes of Health
   Research (CIHR) [FDN143217]
FX Research scholarship of the Deutsche Forschungsgemeinschaft (DFG;
   PU590/1) to S.P., a Discovery grant from the Natural Sciences and
   Engineering Research Council of Canada (NSERC; 436355-13), an operating
   grant from the National Institutes of Health (NIH; 2R01EB009048-05) and
   a Platform Support Grant from the Brain Canada Foundation (PSG15-3755)
   to S.B., and a Foundation Grant from the Canadian Institutes of Health
   Research (CIHR; FDN143217) to R.J.Z.
CR Albouy P, 2017, NEURON, V94, P193, DOI 10.1016/j.neuron.2017.03.015
   Albouy P, 2013, BRAIN RES, V1537, P224, DOI 10.1016/j.brainres.2013.09.003
   Baskent D, 2016, J ACOUST SOC AM, V139, pEL51, DOI 10.1121/1.4942628
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bharadwaj HM, 2015, J NEUROSCI, V35, P2161, DOI 10.1523/JNEUROSCI.3915-14.2015
   Bharadwaj HM, 2014, FRONT INTEGR NEUROSC, V8, DOI 10.3389/fnint.2014.00006
   Bidelman GM, 2014, EUR J NEUROSCI, V40, P2662, DOI 10.1111/ejn.12627
   Bidelman GM, 2011, EUR J NEUROSCI, V33, P530, DOI 10.1111/j.1460-9568.2010.07527.x
   Boebinger D, 2015, J ACOUST SOC AM, V137, P378, DOI 10.1121/1.4904537
   Brodbeck C, 2018, NEUROIMAGE, V172, P162, DOI 10.1016/j.neuroimage.2018.01.042
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Clayton KK, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157638
   Coffey EBJ, 2011, NEUROSCIENCES MUSIC
   Coffey EBJ, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00479
   Coffey EBJ, 2017, HEARING RES, V352, P49, DOI 10.1016/j.heares.2017.02.006
   Coffey EBJ, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11070
   Cohen MA, 2011, PSYCHON B REV, V18, P586, DOI 10.3758/s13423-011-0074-0
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   Crosse MJ, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00604
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   Dalton P, 2009, Q J EXP PSYCHOL, V62, P2126, DOI 10.1080/17470210903023646
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Ding N, 2013, J NEUROSCI, V33, P5728, DOI 10.1523/JNEUROSCI.5297-12.2013
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Ding N, 2012, J NEUROPHYSIOL, V107, P78, DOI 10.1152/jn.00297.2011
   Disbergen NR, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00121
   Du Y, 2017, P NATL ACAD SCI USA, V114, P13579, DOI 10.1073/pnas.1712223114
   Elhilali M, 2008, J ACOUST SOC AM, V124, P3751, DOI 10.1121/1.3001672
   Fischl B, 2004, CEREB CORTEX, V14, P11, DOI 10.1093/cercor/bhg087
   Fischl B, 1999, NEUROIMAGE, V9, P195, DOI 10.1006/nimg.1998.0396
   Foster NEV, 2013, NEUROIMAGE, V75, P27, DOI 10.1016/j.neuroimage.2013.02.044
   Fritz JB, 2007, CURR OPIN NEUROBIOL, V17, P437, DOI 10.1016/j.conb.2007.07.011
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Gross J, 2013, NEUROIMAGE, V65, P349, DOI 10.1016/j.neuroimage.2012.10.001
   Herholz SC, 2012, NEURON, V76, P486, DOI 10.1016/j.neuron.2012.10.011
   HOUTGAST T, 1985, J ACOUST SOC AM, V77, P1069, DOI 10.1121/1.392224
   Jones GL, 2008, J ACOUST SOC AM, V124, P3818, DOI 10.1121/1.2996336
   Keitel A, 2017, NEUROIMAGE, V147, P32, DOI 10.1016/j.neuroimage.2016.11.062
   Kidd G, 2008, J ACOUST SOC AM, V124, P3793, DOI 10.1121/1.2998980
   Kraus N, 2012, ANN NY ACAD SCI, V1252, P100, DOI 10.1111/j.1749-6632.2012.06463.x
   Kubanek J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053398
   Lehmann A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085442
   MACKINNON DP, 1995, MULTIVAR BEHAV RES, V30, P41, DOI 10.1207/s15327906mbr3001_3
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Mirkovic B, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00349
   Morillon B, 2017, P NATL ACAD SCI USA, V114, pE8913, DOI 10.1073/pnas.1705373114
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   O'Sullivan JA, 2015, CEREB CORTEX, V25, P1697, DOI 10.1093/cercor/bht355
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Parbery-Clark A, 2009, J NEUROSCI, V29, P14100, DOI 10.1523/JNEUROSCI.3256-09.2009
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Picton TW, 2003, INT J AUDIOL, V42, P177, DOI 10.3109/14992020309101316
   Purcell DW, 2004, J ACOUST SOC AM, V116, P3581, DOI 10.1121/1.1798354
   Puschmann S, 2017, J NEUROSCI, V37, P11505, DOI 10.1523/JNEUROSCI.1007-17.2017
   Puvvada KC, 2017, J NEUROSCI, V37, P9189, DOI 10.1523/JNEUROSCI.0938-17.2017
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Rudner M, 2012, J AM ACAD AUDIOL, V23, P577, DOI 10.3766/jaaa.23.7.7
   Schoonhoven R, 2003, CLIN NEUROPHYSIOL, V114, P2096, DOI 10.1016/S1388-2457(03)00200-1
   Schulze K, 2012, ANN NY ACAD SCI, V1252, P229, DOI 10.1111/j.1749-6632.2012.06447.x
   Schulze K, 2011, HUM BRAIN MAPP, V32, P771, DOI 10.1002/hbm.21060
   Shinn-Cunningham B, 2017, SPRINGER HANDB AUDIT, V61, P159, DOI 10.1007/978-3-319-47944-6_7
   Sobel M.E., 1982, SOCIOL METHODOL, V13, P290, DOI [10.2307/270723, DOI 10.2307/270723]
   Sorqvist P, 2010, MEMORY, V18, P310, DOI 10.1080/09658211003601530
   Strait DL, 2014, CEREB CORTEX, V24, P2512, DOI 10.1093/cercor/bht103
   Strait DL, 2014, HEARING RES, V308, P109, DOI 10.1016/j.heares.2013.08.004
   Strait DL, 2012, BRAIN LANG, V123, P191, DOI 10.1016/j.bandl.2012.09.001
   Swaminathan J, 2015, SCI REP-UK, V5, DOI 10.1038/srep11628
   Tadel F, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/879716
   TEDER W, 1993, NEUROREPORT, V5, P307, DOI 10.1097/00001756-199312000-00032
   Tsuchida Y, 2012, NEUROSCI LETT, V516, P62, DOI 10.1016/j.neulet.2012.03.057
   Van Rijsbergen CJ., 1979, INFORM RETRIEVAL
   Zekveld AA, 2013, J ACOUST SOC AM, V134, P2225, DOI 10.1121/1.4817926
   Zendel BR, 2009, J COGNITIVE NEUROSCI, V21, P1488, DOI 10.1162/jocn.2009.21140
NR 75
TC 7
Z9 7
U1 0
U2 7
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 1047-3211
EI 1460-2199
J9 CEREB CORTEX
JI Cereb. Cortex
PD AUG
PY 2019
VL 29
IS 8
BP 3253
EP 3265
DI 10.1093/cercor/bhy193
PG 13
WC Neurosciences
SC Neurosciences & Neurology
GA IT4DE
UT WOS:000482808900006
PM 30137239
OA Green Published
DA 2021-02-24
ER

PT J
AU Pimperton, H
   Kyle, F
   Hulme, C
   Harris, M
   Beedie, I
   Ralph-Lewis, A
   Worster, E
   Rees, R
   Donlan, C
   MacSweeney, M
AF Pimperton, Hannah
   Kyle, Fiona
   Hulme, Charles
   Harris, Margaret
   Beedie, Indie
   Ralph-Lewis, Amelia
   Worster, Elizabeth
   Rees, Rachel
   Donlan, Chris
   MacSweeney, Mairead
TI Computerized Speechreading Training for Deaf Children: A Randomized
   Controlled Trial
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SPEECH-PERCEPTION; HEARING CHILDREN; ACHIEVEMENT; CONCURRENT; PREDICTORS
AB Purpose: We developed and evaluated in a randomized controlled trial a computerized speechreading training program to determine (a) whether it is possible to train speechreading in deaf children and (b) whether speechreading training results in improvements in phonological and reading skills. Previous studies indicate a relationship between speechreading and reading skill and further suggest this relationship may be mediated by improved phonological representations. This is important since many deaf children find learning to read to be very challenging.
   Method: Sixty-six deaf 5- to 7-year-olds were randomized into speechreading and maths training arms. Each training program was composed of a 10-min sessions a day, 4 days a week for 12 weeks. Children were assessed on a battery of language and literacy measures before training, immediately after training, and 3 months and 11 months after training.
   Results: We found no significant benefits for participants who completed the speechreading training, compared to those who completed the maths training, on the speechreading primary outcome measure. However, significantly greater gains were observed in the speechreading training group on one of the secondary measures of speechreading. There was also some evidence of beneficial effects of the speechreading training on phonological representations; however, these effects were weaker. No benefits were seen to word reading.
   Conclusions: Speechreading skill is trainable in deaf children. However, to support early reading, training may need to be longer or embedded in a broader literacy program. Nevertheless, a training tool that can improve speechreading is likely to be of great interest to professionals working with deaf children.
C1 [Pimperton, Hannah; Beedie, Indie; Ralph-Lewis, Amelia; Worster, Elizabeth; MacSweeney, Mairead] UCL, Inst Cognit Neurosci, London, England.
   [Pimperton, Hannah; Kyle, Fiona; Beedie, Indie; Ralph-Lewis, Amelia; MacSweeney, Mairead] UCL, Deafness Cognit & Language Res Ctr, London, England.
   [Kyle, Fiona] City Univ London, Div Language & Commun Sci, London, England.
   [Hulme, Charles] Univ Oxford, Dept Educ, Oxford, England.
   [Harris, Margaret] Oxford Brookes Univ, Fac Hlth & Life Sci, Oxford, England.
   [Rees, Rachel; Donlan, Chris] UCL, Dept Language & Cognit, London, England.
RP MacSweeney, M (corresponding author), UCL, Inst Cognit Neurosci, London, England.; MacSweeney, M (corresponding author), UCL, Deafness Cognit & Language Res Ctr, London, England.
EM m.macsweeney@ucl.ac.uk
OI Ralph-Lewis, Amelia/0000-0003-4474-6288; Kyle, Fiona/0000-0003-2997-3167
FU Wellcome TrustWellcome TrustEuropean Commission [100229/Z/12/Z];
   Economic and Social Research CouncilUK Research & Innovation
   (UKRI)Economic & Social Research Council (ESRC) [RES-620-28-0002]
FX This work was funded by a Wellcome Trust Fellowship to M. M.
   (100229/Z/12/Z) and an Economic and Social Research Council Centre Grant
   to M. M. (RES-620-28-0002). We would like to acknowledge the work of
   Cauldron (http://cauldron.sc/welcome) in developing the games. We also
   thank Paul Iversen for advice and Sophie Ball, Zoe Richardson, and
   Oliver Sawyer for their help in analyzing the speech output data.
   Finally, we thank all of the schools and children who participated in
   this research.
CR Arnold P, 1997, J Deaf Stud Deaf Educ, V2, P199
   ARNOLD P, 1993, INT J PEDIATR OTORHI, V26, P209, DOI 10.1016/0165-5876(93)90091-G
   Auer ET, 2007, J SPEECH LANG HEAR R, V50, P1157, DOI 10.1044/1092-4388(2007/080)
   Bergeron JP, 2009, VOLTA REV, V109, P87
   Bernstein LE, 2000, PERCEPT PSYCHOPHYS, V62, P233, DOI 10.3758/BF03205546
   Bernstein LE, 2001, J SPEECH LANG HEAR R, V44, P5, DOI 10.1044/1092-4388(2001/001)
   Elliot C. D., 2011, BRIT ABILITY SCALES
   Gougoux F, 2004, NATURE, V430, P309, DOI 10.1038/430309a
   Harris M, 2017, J DEAF STUD DEAF EDU, V22, P233, DOI 10.1093/deafed/enw101
   Heikkila J, 2017, J SPEECH LANG HEAR R, V60, P485, DOI 10.1044/2016_JSLHR-S-15-0071
   Hulme C, 2016, TEST BASIC ARITHMETI
   Kyle F. E., 2015, RES METHODS SIGN LAN, P300, DOI 10.1002/
   Kyle FE, 2006, J DEAF STUD DEAF EDU, V11, P273, DOI 10.1093/deafed/enj037
   Kyle FE, 2013, J SPEECH LANG HEAR R, V56, P416, DOI 10.1044/1092-4388(2012/12-0039)
   Kyle FE, 2011, J DEAF STUD DEAF EDU, V16, P289, DOI 10.1093/deafed/enq069
   Kyle FE, 2010, J EXP CHILD PSYCHOL, V107, P229, DOI 10.1016/j.jecp.2010.04.011
   Kyle FE, 2016, RES DEV DISABIL, V48, P13, DOI 10.1016/j.ridd.2015.10.004
   Miller EM, 2013, J DEAF STUD DEAF EDU, V18, P206, DOI 10.1093/deafed/ens067
   Mohammed T, 2006, CLIN LINGUIST PHONET, V20, P621, DOI 10.1080/02699200500266745
   Morris SB, 2008, ORGAN RES METHODS, V11, P364, DOI 10.1177/1094428106291059
   Pimperton H, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00106
   Qi S, 2012, J DEAF STUD DEAF EDU, V17, P1, DOI 10.1093/deafed/enr028
   Rodriguez-Ortiz IR, 2017, J RES READ, V40, P75, DOI 10.1111/1467-9817.12062
   Snowling M. J., 2009, YORK ASSESSMENT READ
   Stackhouse J., 1997, CHILDRENS SPEECH LIT
   SUMMERFIELD Q, 1992, PHILOS T ROY SOC B, V335, P71, DOI 10.1098/rstb.1992.0009
   Tucci SL, 2014, COMMUN DISORD Q, V35, P191, DOI 10.1177/1525740114523776
   Tye-Murray N, 2014, J SPEECH LANG HEAR R, V57, P556, DOI 10.1044/2013_JSLHR-H-12-0273
   Van Uden A., 1983, DIAGNOSTIC TESTING D
   Wauters LN, 2006, READ WRIT, V19, P49, DOI 10.1007/s11145-004-5894-0
   Worster E, 2018, LANG LEARN, V68, P1111
NR 31
TC 2
Z9 2
U1 0
U2 1
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD AUG
PY 2019
VL 62
IS 8
BP 2882
EP 2894
DI 10.1044/2019_JSLHR-H-19-0073
PG 13
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA IR6WB
UT WOS:000481580000022
PM 31336055
OA Green Published, Green Accepted, Other Gold
DA 2021-02-24
ER

PT J
AU Stilp, CE
   Assgari, AA
AF Stilp, Christian E.
   Assgari, Ashley A.
TI Natural speech statistics shift phoneme categorization
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Perceptual categorization and identification; Hearing
ID RELIABLE SPECTRAL PROPERTIES; PERCEPTUAL COMPENSATION; IMAGE STATISTICS;
   ACOUSTIC CUES; CONTRAST; INFORMATION; CONTEXT; SENSITIVITY; SOUNDS;
   INTELLIGIBILITY
AB All perception takes place in context. Recognition of a given speech sound is influenced by the acoustic properties of surrounding sounds. When the spectral composition of earlier (context) sounds (e.g., more energy at lower first formant [F-1] frequencies) differs from that of a later (target) sound (e.g., vowel with intermediate F-1), the auditory system magnifies this difference, biasing target categorization (e.g., towards higher-F-1 //). Historically, these studies used filters to force context sounds to possess desired spectral compositions. This approach is agnostic to the natural signal statistics of speech (inherent spectral compositions without any additional manipulations). The auditory system is thought to be attuned to such stimulus statistics, but this has gone untested. Here, vowel categorization was measured following unfiltered (already possessing the desired spectral composition) or filtered sentences (to match spectral characteristics of unfiltered sentences). Vowel categorization was biased in both cases, with larger biases as the spectral prominences in context sentences increased. This confirms sensitivity to natural signal statistics, extending spectral context effects in speech perception to more naturalistic listening conditions. Importantly, categorization biases were smaller and more variable following unfiltered sentences, raising important questions about how faithfully experiments using filtered contexts model everyday speech perception.
C1 [Stilp, Christian E.; Assgari, Ashley A.] Univ Louisville, Dept Psychol & Brain Sci, 317 Life Sci Bldg, Louisville, KY 40292 USA.
RP Stilp, CE (corresponding author), Univ Louisville, Dept Psychol & Brain Sci, 317 Life Sci Bldg, Louisville, KY 40292 USA.
EM christian.stilp@louisville.edu
CR Ainsworth W, 1973, P BRIT ACOUSTICAL SO, V2, P1
   Ainsworth W, 1975, AUDITORY ANAL PERCEP, P10
   American National Standards Institute, 1997, S351997 ANSI
   [Anonymous], 2016, R LANG ENV STAT COMP
   Assgari A. A., 2016, J ACOUST SOC AM, V139, P2124
   Assgari AA, 2015, J ACOUST SOC AM, V138, P3023, DOI 10.1121/1.4934559
   Assmann PF, 2004, PERCEPTION SPEECH AD
   ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663
   Barlow H. B, 1961, SENS COMMUN, P53
   Barlow HB, 1959, MECH THOUGHT PROCESS, P535
   Barreda S, 2012, J ACOUST SOC AM, V131, P466, DOI 10.1121/1.3662068
   Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bosker HR, 2017, J MEM LANG, V94, P166, DOI 10.1016/j.jml.2016.12.002
   Burge J, 2010, J NEUROSCI, V30, P7269, DOI 10.1523/JNEUROSCI.5551-09.2010
   BYRNE D, 1994, J ACOUST SOC AM, V96, P2108, DOI 10.1121/1.410152
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Einhauser W, 2010, CURR OPIN NEUROBIOL, V20, P389, DOI 10.1016/j.conb.2010.03.010
   Elliott TM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000302
   Escabi MA, 2003, J NEUROSCI, V23, P11489
   Felsen G, 2005, NAT NEUROSCI, V8, P1643, DOI 10.1038/nn1608
   FIELD DJ, 1994, NEURAL COMPUT, V6, P559, DOI 10.1162/neco.1994.6.4.559
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Garofolo J, 1990, PB91505065 NIST
   Geisler WS, 2008, ANNU REV PSYCHOL, V59, P167, DOI 10.1146/annurev.psych.58.110405.085632
   Geisler WS, 2001, VISION RES, V41, P711, DOI 10.1016/S0042-6989(00)00277-7
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Holt LL, 2005, PSYCHOL SCI, V16, P305, DOI 10.1111/j.0956-7976.2005.01532.x
   Holt LL, 2006, J ACOUST SOC AM, V120, P2801, DOI 10.1121/1.2354071
   HOUTGAST T, 1985, J ACOUST SOC AM, V77, P1069, DOI 10.1121/1.392224
   Huang JY, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00010
   JOHNSON K, 1990, J ACOUST SOC AM, V88, P642, DOI 10.1121/1.399767
   Kingston J, 2014, ATTEN PERCEPT PSYCHO, V76, P1437, DOI 10.3758/s13414-013-0593-z
   Kluender K. R, 2013, VOWEL INHERENT SPECT, P117
   Kluender KR, 2003, SPEECH COMMUN, V41, P59, DOI 10.1016/S0167-6393(02)00093-6
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Lesica NA, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001655
   Lewicki MS, 2002, NAT NEUROSCI, V5, P356, DOI 10.1038/nn831
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   Lotto AJ, 1998, PERCEPT PSYCHOPHYS, V60, P602, DOI 10.3758/BF03206049
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   McDermott JH, 2013, NAT NEUROSCI, V16, P493, DOI 10.1038/nn.3347
   McDermott JH, 2011, NEURON, V71, P926, DOI 10.1016/j.neuron.2011.06.032
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   McQueen JM, 1998, J MEM LANG, V39, P21, DOI 10.1006/jmla.1998.2568
   McWalter R, 2018, CURR BIOL, V28, P1405, DOI 10.1016/j.cub.2018.03.049
   NEAREY TM, 1989, J ACOUST SOC AM, V85, P2088, DOI 10.1121/1.397861
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Olshausen BA, 1996, NETWORK-COMP NEURAL, V7, P333, DOI 10.1088/0954-898X/7/2/014
   REPP BH, 1978, J EXP PSYCHOL HUMAN, V4, P621, DOI 10.1037/0096-1523.4.4.621
   REPP BH, 1982, PSYCHOL BULL, V92, P81, DOI 10.1037/0033-2909.92.1.81
   Rieke F, 1995, P ROY SOC B-BIOL SCI, V262, P259, DOI 10.1098/rspb.1995.0204
   Ruderman DL, 1998, J OPT SOC AM A, V15, P2036, DOI 10.1364/JOSAA.15.002036
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Sayles M, 2010, HEARING RES, V262, P26, DOI 10.1016/j.heares.2010.01.015
   Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193
   Simoncelli EP, 2003, CURR OPIN NEUROBIOL, V13, P144, DOI 10.1016/S0959-4388(03)00047-3
   Singh NC, 2003, J ACOUST SOC AM, V114, P3394, DOI 10.1121/1.1624067
   Sjerps MJ, 2015, J EXP PSYCHOL HUMAN, V41, P710, DOI 10.1037/a0039028
   Sjerps MJ, 2011, ATTEN PERCEPT PSYCHO, V73, P1195, DOI 10.3758/s13414-011-0096-8
   Spahr AJ, 2012, EAR HEARING, V33, P112, DOI 10.1097/AUD.0b013e31822c2549
   Stilp C. E., 2016, P M AC, V26, DOI [10.1121/2.0000233, DOI 10.1121/2.0000233]
   Stilp C. E., 2014, P M AC, V20, DOI [10. 1121/1. 4865250, DOI 10.1121/1.4865250]
   Stilp C. E., 2015, P M AC, V23, DOI [10. 1121/2. 0000064, DOI 10.1121/2.0000064]
   Stilp CE, 2018, J ACOUST SOC AM, V143, P1944
   Stilp CE, 2018, ATTEN PERCEPT PSYCHO, V80, P1300, DOI 10.3758/s13414-018-1488-9
   Stilp CE, 2017, JARO-J ASSOC RES OTO, V18, P465, DOI 10.1007/s10162-017-0615-y
   Stilp CE, 2017, J ACOUST SOC AM, V141, pEL153, DOI 10.1121/1.4974769
   Stilp CE, 2016, HEARING RES, V341, P168, DOI 10.1016/j.heares.2016.08.004
   Stilp CE, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161001
   Stilp CE, 2015, J ACOUST SOC AM, V137, P3466, DOI 10.1121/1.4921600
   Stilp CE, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030845
   Stilp CE, 2011, J ACOUST SOC AM, V130, pEL352, DOI 10.1121/1.3647264
   Stilp CE, 2010, P NATL ACAD SCI USA, V107, P21914, DOI 10.1073/pnas.1009020107
   Stilp CE, 2010, J ACOUST SOC AM, V128, P2112, DOI 10.1121/1.3483719
   Stilp CE, 2010, ATTEN PERCEPT PSYCHO, V72, P470, DOI 10.3758/APP.72.2.470
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   Theunissen FE, 2000, J NEUROSCI, V20, P2315
   Theunissen FE, 2014, NAT REV NEUROSCI, V15, P355, DOI 10.1038/nrn3731
   Tkacik G, 2010, P NATL ACAD SCI USA, V107, P18149, DOI 10.1073/pnas.0914916107
   Torralba A, 2003, NETWORK-COMP NEURAL, V14, P391, DOI 10.1088/0954-898X/14/3/302
   Toscano JC, 2010, COGNITIVE SCI, V34, P434, DOI 10.1111/j.1551-6709.2009.01077.x
   van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359, DOI 10.1098/rspb.1998.0303
   Vinje WE, 2000, SCIENCE, V287, P1273, DOI 10.1126/science.287.5456.1273
   Vitevitch MS, 1999, J MEM LANG, V40, P374, DOI 10.1006/jmla.1998.2618
   VOSS RF, 1975, NATURE, V258, P317, DOI 10.1038/258317a0
   Watkins AJ, 1996, J ACOUST SOC AM, V99, P588, DOI 10.1121/1.414515
   WATKINS AJ, 1991, J ACOUST SOC AM, V90, P2942, DOI 10.1121/1.401769
   WATKINS AJ, 1994, J ACOUST SOC AM, V96, P1263, DOI 10.1121/1.410275
   Watkins AJ, 1996, J ACOUST SOC AM, V99, P3749, DOI 10.1121/1.414981
   Winn MB, 2015, J ACOUST SOC AM, V137, P1430, DOI 10.1121/1.4908308
   Winn MB, 2018, ROUTLEDGE HDB PHONET
NR 94
TC 5
Z9 4
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD AUG
PY 2019
VL 81
IS 6
BP 2037
EP 2052
DI 10.3758/s13414-018-01659-3
PG 16
WC Psychology; Psychology, Experimental
SC Psychology
GA IN3IM
UT WOS:000478570600024
PM 30887381
OA Bronze
DA 2021-02-24
ER

PT J
AU Ching, ASM
   Kim, J
   Davis, C
AF Ching, April Shi Min
   Kim, Jeesun
   Davis, Chris
TI Auditory-visual integration during nonconscious perception
SO CORTEX
LA English
DT Article
DE Multimodal integration; Subliminal; Consciousness; Priming
ID COGNITIVE NEUROSCIENCE; SPEECH-PERCEPTION; CONSCIOUSNESS; PSYCHOPHYSICS;
   MCGURK; INFORMATION; REVEALS; HUMANS
AB Our study proposes a test of a key assumption of the most prominent model of consciousness the global workspace (GWS) model (e.g., Baars, 2002, 2005, 2007; Dehaene & Naccache, 2001; Mudrik, Faivre, & Koch, 2014). This assumption is that multimodal integration requires consciousness; however, few studies have explicitly tested if integration can occur between nonconscious information from different modalities. The proposed study examined whether a classic indicator of multimodal integration the McGurk effect can be elicited with subliminal auditory visual speech stimuli. We used a masked speech priming paradigm developed by Kouider and Dupoux (2005) in conjunction with continuous flash suppression (CFS; Tsuchiya & Koch, 2005), a binocular rivalry technique for presenting video stimuli subliminally. Applying these techniques together, we carried out two experiments in which participants categorised auditory syllable targets which were preceded by subliminal auditory visual (AV) speech primes. Subliminal AV primes were either illusion-inducing (McGurk) or illusion-neutral (Incongruent) combinations of speech stimuli. In Experiment 1, the categorisation of the syllable target ("pa") was facilitated by the same syllable prime when it was part of a McGurk combination (auditory "pa" and visual "ka") but not when part of an Incongruent combination (auditory "pa" and visual "wa"). This dependency on specific AV combinations indicated a nonconscious AV interaction. Experiment 2 presented a different syllable target ("ta") which matched the predicted illusory outcome of the McGurk combination here, both the McGurk combination (auditory "pa" and visual "ka") and the Incongruent combination (auditory "ta" and visual "ka") failed to facilitate target categorisation. The combined results of both Experiments demonstrate a type of nonconscious multimodal interaction that is distinct from integration it allows unimodal information that is compatible for integration (i.e., McGurk combinations) to persist and influence later processes, but does not actually combine and alter that information. As the GWS model does not account for non-integrative multimodal interactions, this places some pressure on such models of consciousness. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Ching, April Shi Min; Kim, Jeesun; Davis, Chris] Western Sydney Univ, MARCS Inst, Locked Bag 1797, Sydney, NSW 2751, Australia.
RP Ching, ASM (corresponding author), Western Sydney Univ, MARCS Inst, Locked Bag 1797, Sydney, NSW 2751, Australia.
EM a.ching@westernsydney.edu.au
OI Ching, April Shi Min/0000-0002-2579-9934
CR Arzi A, 2012, NAT NEUROSCI, V15, P1460, DOI 10.1038/nn.3193
   Baars B. J., 2007, GLOBAL WORKSPACE THE, P236
   Baars BJ, 2005, PROG BRAIN RES, V150, P45, DOI 10.1016/S0079-6123(05)50004-9
   Baars BJ, 2002, TRENDS COGN SCI, V6, P47, DOI 10.1016/S1364-6613(00)01819-2
   Beauchamp MS, 2010, J NEUROSCI, V30, P2414, DOI 10.1523/JNEUROSCI.4865-09.2010
   Boersma P., 2018, PRAAT DOING PHONETIC
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Calvert GA, 2001, NEUROIMAGE, V14, P427, DOI 10.1006/nimg.2001.0812
   Davis C, 2010, J ACOUST SOC AM, V127, P2110, DOI 10.1121/1.3353116
   Dehaene S, 2001, COGNITION, V79, P1, DOI 10.1016/S0010-0277(00)00123-2
   Dehaene S, 2011, NEURON, V70, P200, DOI 10.1016/j.neuron.2011.03.018
   Deroy O, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0207
   Driver J, 2008, NEURON, V57, P11, DOI 10.1016/j.neuron.2007.12.013
   Dupoux E, 2008, COGNITION, V109, P267, DOI 10.1016/j.cognition.2008.06.012
   Eskelund K, 2011, EXP BRAIN RES, V208, P447, DOI 10.1007/s00221-010-2495-9
   Faivre N, 2014, PSYCHOL SCI, V25, P2006, DOI 10.1177/0956797614547916
   Finkbeiner M, 2011, ATTEN PERCEPT PSYCHO, V73, P1255, DOI 10.3758/s13414-011-0088-8
   Gelbard-Sagiv H, 2016, J VISION, V16, DOI 10.1167/16.1.3
   Green P, 2016, METHODS ECOL EVOL, V7, P493, DOI 10.1111/2041-210X.12504
   Henke K, 2010, NAT REV NEUROSCI, V11, P523, DOI 10.1038/nrn2850
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Jiang JT, 2011, J EXP PSYCHOL HUMAN, V37, P1193, DOI 10.1037/a0023100
   Kleiner M, 2007, PERCEPTION, V36, P14
   Klucharev V, 2003, COGNITIVE BRAIN RES, V18, P65, DOI 10.1016/j.cogbrainres.2003.09.004
   Kouider S, 2005, PSYCHOL SCI, V16, P617, DOI 10.1111/j.1467-9280.2005.01584.x
   Lakens D, 2014, EUR J SOC PSYCHOL, V44, P701, DOI 10.1002/ejsp.2023
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   Massaro D. W., 2009, CAVEAT EMPTOR MEANIN
   Massaro DW, 1998, AM SCI, V86, P236, DOI 10.1511/1998.25.861
   Miller LM, 2005, J NEUROSCI, V25, P5884, DOI 10.1523/JNEUROSCI.0896-05.2005
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Mudrik L, 2014, TRENDS COGN SCI, V18, P488, DOI 10.1016/j.tics.2014.04.009
   Munhall KG, 2009, CURR BIOL, V19, P735, DOI 10.1016/j.cub.2009.03.019
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Noel JP, 2015, CURR BIOL, V25, pR157, DOI 10.1016/j.cub.2015.01.007
   Norris D, 2008, J EXP PSYCHOL GEN, V137, P434, DOI 10.1037/a0012799
   Palmer TD, 2012, COGNITION, V125, P353, DOI 10.1016/j.cognition.2012.08.003
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Porta JB, 1593, REFRACTIONE OPTICES
   R Core Team, 2015, R LANG ENV STAT COMP
   Ramsoy T., 2004, PHENOMENOL COGN SCI, V3, P1, DOI [10.1023/B:PHEN.0000041900.30172.e8, DOI 10.1023/B:PHEN.0000041900.30172.E8]
   Rouder JN, 2007, PSYCHON B REV, V14, P597, DOI 10.3758/BF03196808
   Schroeder CE, 2005, CURR OPIN NEUROBIOL, V15, P454, DOI 10.1016/j.conb.2005.06.008
   Scott RB, 2018, COGNITION, V175, P169, DOI 10.1016/j.cognition.2018.02.008
   Sherman R., 2014, PHACK
   The MathWorks, 2015, MATL VERS 2015A
   Tsuchiya N, 2005, NAT NEUROSCI, V8, P1096, DOI 10.1038/nn1500
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   Venezia JH, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00174
   WILCOX RR, 1995, BRIT J MATH STAT PSY, V48, P99, DOI 10.1111/j.2044-8317.1995.tb01052.x
NR 50
TC 0
Z9 0
U1 2
U2 14
PU ELSEVIER MASSON, CORPORATION OFFICE
PI PARIS
PA 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE
SN 0010-9452
EI 1973-8102
J9 CORTEX
JI Cortex
PD AUG
PY 2019
VL 117
BP 1
EP 15
DI 10.1016/j.cortex.2019.02.014
PG 15
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA IN5HU
UT WOS:000478707300001
PM 30925308
DA 2021-02-24
ER

PT J
AU Shofner, WP
   Yacko, N
   Bowdrie, K
AF Shofner, William P.
   Yacko, Nicole
   Bowdrie, Kristina
TI Perception of Degraded Speech by Chinchillas (Chinchilla laniger):
   Word-Level Stimulus Generalization
SO JOURNAL OF COMPARATIVE PSYCHOLOGY
LA English
DT Article
DE chinchilla; speech perception; noise-vocoder; stimulus generalization
ID FREQUENCY DISCRIMINATION; COCHLEAR IMPLANTATION; PRELINGUAL DEAFNESS;
   PSEUDOREPLICATION; RECOGNITION; ADULTS; NOISE
AB One characteristic of human speech perception is a remarkable ability to recognize speech when the speech signal is highly degraded. It has been argued that this ability to perceive highly degraded speech reflects speech-specific mechanisms. The present study tested this hypothesis by measuring the ability of chinchillas to recognize noise-vocoded (NV) versions of naturally spoken monosyllabic words using operant conditioning in a stimulus generalization paradigm. Chinchillas do not generalize the vocoded words to be perceptually equivalent to the naturally spoken words. The responses from chinchillas to the vocoded words fall well below their responses to the naturally spoken words. In this case, pitch cues rather than speech cues may be controlling the behavioral responses. To reduce pitch cues, chinchillas were retrained using 64-channel NV words. The responses from chinchillas to the vocoded test words were now similar to those of the 64-channel versions and were similar to those obtained from human listeners. However, responses obtained from chinchillas to time-reversed versions were high and similar to responses obtained to time-normal versions suggesting that the cue controlling behavioral responses was the phonetic structure of the words. These results show that chinchillas used different acoustic cues than human listeners. The ability of chinchillas to recognize NV words as being perceptually equivalent to the naturally spoken versions is inferior compared to that of human listeners. The findings suggest that the ability of human listeners to recognize highly degraded speech is unlikely to be based solely on the general auditory and perceptual mechanisms that are common among mammals.
C1 [Shofner, William P.; Yacko, Nicole; Bowdrie, Kristina] Indiana Univ, Dept Speech & Hearing Sci, 200 South Jordan Ave, Bloomington, IN 47405 USA.
RP Shofner, WP (corresponding author), Indiana Univ, Dept Speech & Hearing Sci, 200 South Jordan Ave, Bloomington, IN 47405 USA.
EM wshofner@indiana.edu
CR Boersma P., PRAAT VERSION 6 0 20
   BURDICK CK, 1975, J ACOUST SOC AM, V58, P415, DOI 10.1121/1.380686
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Fitch WT, 2011, CURR BIOL, V21, pR543, DOI 10.1016/j.cub.2011.06.035
   Fu Q.-J., 2008, TIGERSPEECH TECHNOLO
   Guttman N., 1963, PSYCHOL STUDY SCI, V5, P114
   HEFFNER RS, 1991, HEARING RES, V52, P13, DOI 10.1016/0378-5955(91)90183-A
   Heimbauer LA, 2011, CURR BIOL, V21, P1210, DOI 10.1016/j.cub.2011.06.007
   Huchon D, 2002, MOL BIOL EVOL, V19, P1053, DOI 10.1093/oxfordjournals.molbev.a004164
   Hulse S. H., 1995, METHODS COMP PSYCHOA, P319
   HURLBERT SH, 1984, ECOL MONOGR, V54, P187, DOI 10.2307/1942661
   Institute of Medicine, 2011, CHIMPANZEES BIOMEDIC
   KIRK KI, 1995, EAR HEARING, V16, P470, DOI 10.1097/00003446-199510000-00004
   KROODSMA DE, 1990, ANIM BEHAV, V40, P1138, DOI 10.1016/S0003-3472(05)80180-0
   KUHL PK, 1978, J ACOUST SOC AM, V63, P905, DOI 10.1121/1.381770
   KUHL PK, 1975, SCIENCE, V190, P69, DOI 10.1126/science.1166301
   McGregor Peter K., 2000, Acta Ethologica, V3, P3, DOI 10.1007/s102110000023
   NELSON DA, 1978, J ACOUST SOC AM, V64, P114, DOI 10.1121/1.381977
   NIEMIEC AJ, 1992, J ACOUST SOC AM, V92, P2636, DOI 10.1121/1.404380
   Ohlemiller KK, 1999, BEHAV BRAIN RES, V100, P185, DOI 10.1016/S0166-4328(98)00130-2
   Oksanen L, 2001, OIKOS, V94, P27, DOI 10.1034/j.1600-0706.2001.11311.x
   Pilley JW, 2011, BEHAV PROCESS, V86, P184, DOI 10.1016/j.beproc.2010.11.007
   Ranasinghe KG, 2012, JARO-J ASSOC RES OTO, V13, P527, DOI 10.1007/s10162-012-0328-1
   REMEZ RE, 1994, PSYCHOL REV, V101, P129, DOI 10.1037/0033-295X.101.1.129
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   ROCK I, 1969, AM J PSYCHOL, V82, P1, DOI 10.2307/1420604
   Saberi K, 1999, NATURE, V398, P760, DOI 10.1038/19652
   Shannon RV, 2005, INT REV NEUROBIOL, V70, P121, DOI 10.1016/S0074-7742(05)70004-0
   Sherbecoe RL, 2004, INT J AUDIOL, V43, P442, DOI 10.1080/14992020400050056
   Shofner WP, 2014, J ACOUST SOC AM, V135, P2065, DOI 10.1121/1.4867362
   Shofner WP, 2013, J COMP PSYCHOL, V127, P142, DOI 10.1037/a0029734
   Shofner WP, 2011, JARO-J ASSOC RES OTO, V12, P101, DOI 10.1007/s10162-010-0237-0
   Shofner WP, 1997, HEARING RES, V110, P15, DOI 10.1016/S0378-5955(97)00063-4
   Shofner WP, 2000, HEARING RES, V149, P106, DOI 10.1016/S0378-5955(00)00171-4
   SHOFNER WP, 1994, HEARING RES, V77, P231, DOI 10.1016/0378-5955(94)90271-2
   SHOFNER WP, 1993, HEARING RES, V66, P67, DOI 10.1016/0378-5955(93)90261-X
   Stebbins W. C., 1970, ANIMAL PSYCHOPHYSICS, P363, DOI DOI 10.1007/978-1-4757-4514-6_17
   Teoh SW, 2004, LARYNGOSCOPE, V114, P1714, DOI 10.1097/00005537-200410000-00007
   Teoh SW, 2004, LARYNGOSCOPE, V114, P1536
   Trout JD, 2001, PSYCHOL REV, V108, P523, DOI 10.1037//0033-295X.108.3.523
   Uddin M, 2004, P NATL ACAD SCI USA, V101, P2957, DOI 10.1073/pnas.0308725100
   Wang GD, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2814
NR 42
TC 1
Z9 1
U1 2
U2 4
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0735-7036
EI 1939-2087
J9 J COMP PSYCHOL
JI J. Comp. Psychol.
PD AUG
PY 2019
VL 133
IS 3
BP 326
EP 339
DI 10.1037/com0000165
PG 14
WC Behavioral Sciences; Psychology; Psychology, Multidisciplinary; Zoology
SC Behavioral Sciences; Psychology; Zoology
GA IN5OY
UT WOS:000478727600006
PM 30589293
DA 2021-02-24
ER

PT J
AU Giroud, N
   Keller, M
   Hirsiger, S
   Dellwo, V
   Meyer, M
AF Giroud, Nathalie
   Keller, Matthias
   Hirsiger, Sarah
   Dellwo, Volker
   Meyer, Martin
TI Bridging the brain structure-brain function gap in prosodic speech
   processing in older adults
SO NEUROBIOLOGY OF AGING
LA English
DT Article
DE Prosody perception; Aging; Central hearing loss; Auditory atrophy;
   Cortical thickness; Cortical surface area; Mismatch negativity; AST
   hypothesis; Lateralization; Dedifferentiation
ID SURFACE-BASED ANALYSIS; HEARING-LOSS; CORTICAL THICKNESS;
   CEREBRAL-CORTEX; HEMISPHERIC-ASYMMETRY; AUDITORY-CORTEX; LIFE-SPAN; AGE;
   PERCEPTION; SEGMENTATION
AB Age-related decline in speech perception may result in difficulties partaking in spoken conversation and potentially lead to social isolation and cognitive decline in older adults. It is therefore important to better understand how age-related differences in neurostructural factors such as cortical thickness (CT) and cortical surface area (CSA) are related to neurophysiological sensitivity to speech cues in younger and older adults. Age-related differences in CT and CSA of bilateral auditory-related areas were extracted using FreeSurfer in younger and older adults with normal peripheral hearing. Behavioral and neurophysiological sensitivity to prosodic speech cues (word stress and fundamental frequency of oscillation) was evaluated using discrimination tasks and a passive oddball paradigm, while EEG was recorded, to quantify mismatch negativity responses. Results revealed (a) higher neural sensitivity (i.e., larger mismatch negativity responses) to word stress in older adults compared to younger adults, suggesting a higher importance of prosodic speech cues in the speech processing of older adults, and (b) lower CT in auditory-related regions in older compared to younger individuals, suggesting neuronal loss associated with aging. Within the older age group, less neuronal loss (i.e., higher CT) in a right auditory-related area (i.e., the supratemporal sulcus) was related to better performance in fundamental frequency discrimination, while higher CSA in left auditory-related areas was associated with higher neural sensitivity toward prosodic speech cues as evident in the mismatch negativity patterns. Overall, our results offer evidence for neurostructural changes in aging that are associated with differences in the extent to which left and right auditory-related areas are involved in speech processing in older adults. We argue that exploring age-related differences in brain structure and function associated with decline in speech perception in older adults may help develop much needed rehabilitation strategies for older adults with central age-related hearing loss. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Giroud, Nathalie; Keller, Matthias; Meyer, Martin] Psychol Inst, Dept Psychol, Div Neuropsychol, Zurich, Switzerland.
   [Giroud, Nathalie] Concordia Univ, Dept Psychol, Cognit Aging & Psychophysiol Lab, Montreal, PQ, Canada.
   [Giroud, Nathalie] McGill Univ, CRBLM, Montreal, PQ, Canada.
   [Hirsiger, Sarah] Univ Zurich, Dept Psychiat Psychotherapy & Psychosomat, Psychiat Hosp, Zurich, Switzerland.
   [Dellwo, Volker] Univ Zurich, Inst Computat Linguist, Phonet Lab, Zurich, Switzerland.
   [Meyer, Martin] Charite Univ Med Berlin, Tinnitus Ctr, Berlin, Germany.
RP Giroud, N (corresponding author), Concordia Univ, Cognit Aging & Psychophysiol Lab, 7141 Sherbrooke St West, Montreal, PQ H4B 1R6, Canada.
EM nathalie.giroud@uzh.ch
FU Swiss National Science FoundationSwiss National Science Foundation
   (SNSF)European Commission [105314_152905, 105319_169964];
   Schwerhorigenverein Nordwestschweiz
FX This research was supported by the Swiss National Science Foundation
   (grant no. 105314_152905 and 105319_169964 to MM) and by the
   Schwerhorigenverein Nordwestschweiz. The authors thank Allison Christen
   for proofreading the manuscript. There are no conflicts of interest to
   declare.
CR Abrams DA, 2008, J NEUROSCI, V28, P3958, DOI 10.1523/JNEUROSCI.0187-08.2008
   ANNETT M, 1970, BRIT J PSYCHOL, V61, P303, DOI 10.1111/j.2044-8295.1970.tb01248.x
   Arlinger S, 2003, INT J AUDIOL, V42, pS17
   Bellis TJ, 2000, J NEUROSCI, V20, P791, DOI 10.1523/JNEUROSCI.20-02-00791.2000
   Ben Shalom D, 2008, NEUROSCIENTIST, V14, P119, DOI 10.1177/1073858407305726
   Bermudez P, 2009, CEREB CORTEX, V19, P1583, DOI 10.1093/cercor/bhn196
   Cabeza R, 2002, PSYCHOL AGING, V17, P85, DOI 10.1037//0882-7974.17.1.85
   Cardinale F, 2014, NEUROINFORMATICS, V12, P535, DOI 10.1007/s12021-014-9229-2
   COHEN G, 1986, LANG COMMUN, V6, P91, DOI 10.1016/0271-5309(86)90008-X
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   DALE AM, 1993, J COGNITIVE NEUROSCI, V5, P162, DOI 10.1162/jocn.1993.5.2.162
   Destrieux C, 2010, NEUROIMAGE, V53, P1, DOI 10.1016/j.neuroimage.2010.06.010
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   DUBNO JR, 1984, J ACOUST SOC AM, V76, P87, DOI 10.1121/1.391011
   Engvig A, 2010, NEUROIMAGE, V52, P1667, DOI 10.1016/j.neuroimage.2010.05.041
   Fischl B, 1999, HUM BRAIN MAPP, V8, P272, DOI 10.1002/(SICI)1097-0193(1999)8:4<272::AID-HBM10>3.0.CO;2-4
   Fischl B, 2004, NEUROIMAGE, V23, pS69, DOI 10.1016/j.neuroimage.2004.07.016
   Fischl B, 2004, CEREB CORTEX, V14, P11, DOI 10.1093/cercor/bhg087
   Fischl B, 2001, IEEE T MED IMAGING, V20, P70, DOI 10.1109/42.906426
   Fischl B, 1999, NEUROIMAGE, V9, P195, DOI 10.1006/nimg.1998.0396
   Fischl B, 2002, NEURON, V33, P341, DOI 10.1016/S0896-6273(02)00569-X
   Fischl B, 2000, P NATL ACAD SCI USA, V97, P11050, DOI 10.1073/pnas.200033797
   Fogerty D, 2012, J SPEECH LANG HEAR R, V55, P487, DOI 10.1044/1092-4388(2011/11-0102)
   Fogerty D, 2010, J ACOUST SOC AM, V127, P2509, DOI 10.1121/1.3316291
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Geiser E, 2008, J COGNITIVE NEUROSCI, V20, P541, DOI 10.1162/jocn.2008.20029
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Giroud N, 2018, BRAIN STRUCT FUNCT, V223, P145, DOI 10.1007/s00429-017-1477-0
   Giroud N, 2018, EUR J NEUROSCI, V47, P58, DOI 10.1111/ejn.13772
   Giroud N, 2017, HEARING RES, V353, P162, DOI 10.1016/j.heares.2017.06.012
   Goossens T, 2017, HEARING RES, V344, P109, DOI 10.1016/j.heares.2016.11.004
   Gordon-Salant S, 2001, J SPEECH LANG HEAR R, V44, P709, DOI 10.1044/1092-4388(2001/056)
   GORDONSALANT S, 1993, J SPEECH HEAR RES, V36, P1276, DOI 10.1044/jshr.3606.1276
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Harris KC, 2010, HEARING RES, V264, P21, DOI 10.1016/j.heares.2009.09.017
   Heinrich A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00782
   HELFER KS, 1990, J SPEECH HEAR RES, V33, P149, DOI 10.1044/jshr.3301.149
   Homae F, 2006, NEUROSCI RES, V54, P276, DOI 10.1016/j.neures.2005.12.006
   Homans NC, 2017, LARYNGOSCOPE, V127, P725, DOI 10.1002/lary.26150
   Humes LE, 2012, J AM ACAD AUDIOL, V23, P635, DOI 10.3766/jaaa.23.8.5
   Hurschler MA, 2013, HUM BRAIN MAPP, V34, P3182, DOI 10.1002/hbm.22134
   Hurtz S, 2014, DEMENT GER COGN D EX, V4, P221, DOI 10.1159/000362872
   Hutsler J, 2003, TRENDS NEUROSCI, V26, P429, DOI 10.1016/S0166-2236(03)00198-X
   Janssen U., 2013, UNTERSUCHUNGEN ZUM W
   Jung TP, 2000, PSYCHOPHYSIOLOGY, V37, P163, DOI 10.1017/S0048577200980259
   Keller M, 2019, NEUROIMAGE, V189, P886, DOI 10.1016/j.neuroimage.2019.01.050
   Kemper S, 1999, PSYCHOL AGING, V14, P656, DOI 10.1037/0882-7974.14.4.656
   Kuperberg GR, 2003, ARCH GEN PSYCHIAT, V60, P878, DOI 10.1001/archpsyc.60.9.878
   Liem F, 2015, NEUROIMAGE, V108, P95, DOI 10.1016/j.neuroimage.2014.12.035
   Liem F, 2014, HUM BRAIN MAPP, V35, P1779, DOI 10.1002/hbm.22291
   Lin FR, 2011, ARCH NEUROL-CHICAGO, V68, P214, DOI 10.1001/archneurol.2010.362
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Luo H, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00170
   Marasek Krzysztof, 1995, P 13 ICPHS STOCKH, V4, P428
   Mathers C, 2008, GLOBAL BURDEN OF DISEASE: 2004 UPDATE, P1
   Meyer M, 2004, BRAIN LANG, V89, P277, DOI 10.1016/S0093-934X(03)00350-X
   Meyer M, 2002, HUM BRAIN MAPP, V17, P73, DOI 10.1002/hbm.10042
   Meyer M., 2018, OXFORD HDB VOICE PER
   Meyer M, 2008, Z NEUROPSYCHOL, V19, P101, DOI 10.1024/1016-264X.19.2.101
   Meyer M, 2016, HEARING RES, V342, P1, DOI 10.1016/j.heares.2016.08.016
   Meyer M, 2014, CEREB CORTEX, V24, P2541, DOI 10.1093/cercor/bht094
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Peelle JE, 2016, TRENDS NEUROSCI, V39, P486, DOI 10.1016/j.tins.2016.05.001
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Pena M, 2012, J NEUROSCI, V32, P11159, DOI 10.1523/JNEUROSCI.6516-11.2012
   Penhune VB, 1996, CEREB CORTEX, V6, P661, DOI 10.1093/cercor/6.5.661
   Perani D, 2011, P NATL ACAD SCI USA, V108, P16056, DOI 10.1073/pnas.1102991108
   PERRIN F, 1987, ELECTROEN CLIN NEURO, V66, P75, DOI 10.1016/0013-4694(87)90141-6
   Pickles J, 2012, INTRO PHYSL HEARING
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Poeppel D, 2008, PHILOS T R SOC B, V363, P1071, DOI 10.1098/rstb.2007.2160
   Pontious A, 2008, DEV NEUROSCI-BASEL, V30, P24, DOI 10.1159/000109848
   Profant O, 2014, NEUROSCIENCE, V260, P87, DOI 10.1016/j.neuroscience.2013.12.010
   Profant O, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116692
   RAKIC P, 1988, SCIENCE, V241, P170, DOI 10.1126/science.3291116
   RAKIC P, 1995, TRENDS NEUROSCI, V18, P383, DOI 10.1016/0166-2236(95)93934-P
   Rakic P, 2007, BRAIN RES REV, V55, P204, DOI 10.1016/j.brainresrev.2007.02.010
   Reuter M, 2010, NEUROIMAGE, V53, P1181, DOI 10.1016/j.neuroimage.2010.07.020
   Rigters SC, 2018, NEUROBIOL AGING, V61, P124, DOI 10.1016/j.neurobiolaging.2017.09.018
   Rosas HD, 2002, NEUROLOGY, V58, P695, DOI 10.1212/WNL.58.5.695
   Rosemann S, 2018, NEUROIMAGE, V175, P425, DOI 10.1016/j.neuroimage.2018.04.023
   Roth TN, 2011, EUR ARCH OTO-RHINO-L, V268, P1101, DOI 10.1007/s00405-011-1597-8
   Rufener KS, 2016, BRAIN TOPOGR, V29, P440, DOI 10.1007/s10548-015-0464-0
   Salat DH, 2004, CEREB CORTEX, V14, P721, DOI 10.1093/cercor/bhh032
   Segonne F, 2004, NEUROIMAGE, V22, P1060, DOI 10.1016/j.neuroimage.2004.03.032
   Steinhauer K, 2010, NEUROSCI LETT, V472, P133, DOI 10.1016/j.neulet.2010.01.072
   Thambisetty M, 2010, NEUROIMAGE, V52, P1215, DOI 10.1016/j.neuroimage.2010.04.258
   Vannson N, 2015, AUDIOL NEURO-OTOL, V20, P38, DOI 10.1159/000380746
   Werkle-Bergner M, 2009, CLIN NEUROPHYSIOL, V120, P1291, DOI 10.1016/j.clinph.2009.04.012
   WINGFIELD A, 1992, J GERONTOL, V47, pP350, DOI 10.1093/geronj/47.5.P350
   Wingfield A, 2000, J SPEECH LANG HEAR R, V43, P915, DOI 10.1044/jslhr.4304.915
   Wong PCM, 2010, EAR HEARING, V31, P471, DOI 10.1097/AUD.0b013e3181d709c2
   Zatorre RJ, 2008, PHILOS T R SOC B, V363, P1087, DOI 10.1098/rstb.2007.2161
   Zekveld AA, 2011, EAR HEARING, V32, P498, DOI 10.1097/AUD.0b013e31820512bb
NR 95
TC 2
Z9 2
U1 3
U2 5
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0197-4580
EI 1558-1497
J9 NEUROBIOL AGING
JI Neurobiol. Aging
PD AUG
PY 2019
VL 80
BP 116
EP 126
DI 10.1016/j.neurobiolaging.2019.04.017
PG 11
WC Geriatrics & Gerontology; Neurosciences
SC Geriatrics & Gerontology; Neurosciences & Neurology
GA IM0VG
UT WOS:000477707200013
PM 31170532
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Morin-Lessard, E
   Poulin-Dubois, D
   Segalowitz, N
   Byers-Heinlein, K
AF Morin-Lessard, Elizabeth
   Poulin-Dubois, Diane
   Segalowitz, Norman
   Byers-Heinlein, Krista
TI Selective Attention to the Mouth of Talking Faces in Monolinguals and
   Bilinguals Aged 5 Months to 5 Years
SO DEVELOPMENTAL PSYCHOLOGY
LA English
DT Article
DE infancy; childhood; bilingualism; audio-visual speech; multisensory
   perception
ID VISUAL LANGUAGE DISCRIMINATION; DEVELOPMENTAL-CHANGES;
   SPEECH-PERCEPTION; INFANTS; CHILDREN; GROWTH; EYES
AB A talking face provides redundant cues on the mouth that might support language learning and highly salient social cues in the eyes. What drives children's looking toward the mouth versus eyes of a talking face? This study reports data from 292 children who viewed faces speaking English, French, and Russian. We investigated the impact of children's age (5 months to 5 years) and language background (monolingual English, monolingual French, bilingual English-French), and the speaker's language (dominant, nondominant, or nonnative) relative to children's native language(s). Data from 129 bilingual adults were also collected for comparison. Five-month-olds showed balanced attention to the eyes and mouth, but children up to 5 years tended to be most interested in the mouth. In contrast, adults were most interested in the eyes. We found little evidence for different patterns of attention for monolinguals versus bilinguals, or to a native versus a nonnative speaker. Using percentile scores, monolinguals with larger productive vocabularies looked more at the mouth, while bilinguals with larger comprehension vocabularies looked marginally less at the mouth, although both effects were small and not as robust with raw vocabulary scores. Children showed large but stable individual variability in their face scanning patterns across different speakers. Our results show that the way that children allocate their attention to talking faces continues to change from infancy through the preschool years and beyond. Future studies will need to go beyond looking at bilingualism, speaker language, and vocabulary size to understand what drives children's in-the-moment attention to talking faces.
C1 [Morin-Lessard, Elizabeth; Poulin-Dubois, Diane; Segalowitz, Norman; Byers-Heinlein, Krista] Concordia Univ, Dept Psychol, 7141 Sherbrooke St West, Montreal, PQ H4B 1R6, Canada.
   [Segalowitz, Norman] Queensland Univ Technol, Sch Psychol & Counseling, Brisbane, Qld, Australia.
   [Morin-Lessard, Elizabeth] Univ Calgary, Dept Psychol, Calgary, AB, Canada.
RP Byers-Heinlein, K (corresponding author), Concordia Univ, Dept Psychol, 7141 Sherbrooke St West, Montreal, PQ H4B 1R6, Canada.
EM k.byers@concordia.ca
OI Byers-Heinlein, Krista/0000-0002-7040-2510
FU Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR
   [402470-2011]; Concordia University; Fonds de Recherche du
   Quebec-Societe et Culture Doctoral Fellowship
FX This research was supported by grants from the Natural Sciences and
   Engineering Research Council of Canada awarded to Krista ByersHeinlein
   (Grant 402470-2011) and Diane Poulin-Dubois (2003-2013), a Seed Funding
   Team Program grant from Concordia University awarded to Norman
   Segalowitz and Krista Byers-Heinlein, and a Fonds de Recherche du
   Quebec-Societe et Culture Doctoral Fellowship awarded to Elizabeth
   Morin-Lessard. Special thanks to Nathalie Germain, Alexa Fogel, the
   teams at the Concordia Infant Research Lab and the Cognitive Language
   Development Lab, and the parents, children, and adults who participated.
CR Atagi N., 2017, M SOC RES CHILD DEV
   Ayneto A, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12446
   Barenholtz E, 2016, COGNITION, V147, P100, DOI 10.1016/j.cognition.2015.11.013
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Birmingham E, 2013, CHILD DEV, V84, P1407, DOI 10.1111/cdev.12039
   Birules J, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12755
   Bosch L, 2001, INFANCY, V2, P29, DOI 10.1207/S15327078IN0201_3
   Brown R., 1973, 1 LANGUAGE EARLY STA, DOI [10.4159/harvard.978067, DOI 10.4159/HARVARD.978067]
   Byers-Heinlein K., 2019, MAPLE MULTILINGUAL A
   Core C, 2013, J SPEECH LANG HEAR R, V56, P1637, DOI 10.1044/1092-4388(2013/11-0044)
   Creel SC, 2015, TRENDS COGN SCI, V19, P713, DOI 10.1016/j.tics.2015.09.006
   de Boisferon AH, 2018, J EXP CHILD PSYCHOL, V172, P189, DOI 10.1016/j.jecp.2018.03.009
   de Boisferon AH, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12381
   De Houwer A, 2014, APPL PSYCHOLINGUIST, V35, P1189, DOI 10.1017/S0142716412000744
   Emery NJ, 2000, NEUROSCI BIOBEHAV R, V24, P581, DOI 10.1016/S0149-7634(00)00025-7
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   Fort M., 2017, LANG LEARN, V132, P111
   Frank MC, 2017, J CHILD LANG, V44, P677, DOI 10.1017/S0305000916000209
   Frank MC, 2012, INFANCY, V17, P355, DOI 10.1111/j.1532-7078.2011.00086.x
   Grimm KJ, 2011, CHILD DEV, V82, P1357, DOI 10.1111/j.1467-8624.2011.01630.x
   Hirst RJ, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30798-8
   Hoareau M., 2017, BOST U C LANG DEV BO
   HOLM S, 1979, SCAND J STAT, V6, P65
   Hunnius S, 2004, INFANCY, V6, P231, DOI 10.1207/s15327078in0602_5
   Jerger S, 2014, J EXP CHILD PSYCHOL, V126, P295, DOI 10.1016/j.jecp.2014.05.003
   Kandel S, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01080
   Lansing CR, 1999, J SPEECH LANG HEAR R, V42, P526, DOI 10.1044/jslhr.4203.526
   Lansing IR, 2003, PERCEPT PSYCHOPHYS, V65, P536, DOI 10.3758/BF03194581
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Marion V, 2007, J SPEECH LANG HEAR R, V50, P940, DOI 10.1044/1092-4388(2007/067)
   Meary D, 2018, LANG LEARN, V68, P14, DOI 10.1111/lang.12287
   Mercure E, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12701
   Merin N, 2007, J AUTISM DEV DISORD, V37, P108, DOI 10.1007/s10803-006-0342-4
   Pascalis O, 2011, WIRES COGN SCI, V2, P666, DOI 10.1002/wcs.146
   PEARSON BZ, 1994, LANG LEARN, V44, P617, DOI 10.1111/j.1467-1770.1994.tb00633.x
   Pejovic J., 2017, WORKSH INF LANG DEV
   Pons F, 2018, LANG LEARN, V68, P180, DOI 10.1111/lang.12276
   Pons F, 2015, PSYCHOL SCI, V26, P490, DOI 10.1177/0956797614568320
   R Core Team, 2018, R LANG ENV STAT COMP
   Ramus F, 1999, COGNITION, V73, P265, DOI 10.1016/S0010-0277(99)00058-X
   Roach P., 1982, LINGUISTIC CONTROVER, P73
   Sebastian-Galles N, 2012, PSYCHOL SCI, V23, P994, DOI 10.1177/0956797612436817
   Segalowitz N., 2009, THE LANGUAGE BACKGRO
   Smith NA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00601
   Stoel-Gammon C, 2011, J CHILD LANG, V38, P1, DOI 10.1017/S0305000910000425
   SUMMERFIELD Q, 1992, PHILOS T ROY SOC B, V335, P71, DOI 10.1098/rstb.1992.0009
   Tenenbaum EJ, 2013, INFANCY, V18, P534, DOI 10.1111/j.1532-7078.2012.00135.x
   Trudeau N., 1997, INVENTAIRE MACARTHUR
   Tsang T, 2018, J EXP CHILD PSYCHOL, V169, P93, DOI 10.1016/j.jecp.2018.01.002
   Vatikiotis-Bateson E, 1998, PERCEPT PSYCHOPHYS, V60, P926, DOI 10.3758/BF03211929
   Vatikiotis-Bateson E, 1998, HEARING EYE 2, P123
   Wagner JB, 2013, INT J BEHAV DEV, V37, P118, DOI 10.1177/0165025412468064
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   Weikum WM, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00086
   Worster E, 2018, LANG LEARN, V68, P159, DOI 10.1111/lang.12264
   Xiao NQG, 2015, DEV PSYCHOL, V51, P744, DOI 10.1037/dev0000019
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
   Young GS, 2009, DEVELOPMENTAL SCI, V12, P798, DOI 10.1111/j.1467-7687.2009.00833.x
NR 58
TC 6
Z9 6
U1 1
U2 11
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0012-1649
EI 1939-0599
J9 DEV PSYCHOL
JI Dev. Psychol.
PD AUG
PY 2019
VL 55
IS 8
BP 1640
EP 1655
DI 10.1037/dev0000750
PG 16
WC Psychology, Developmental
SC Psychology
GA IK3OJ
UT WOS:000476498000007
PM 31169400
DA 2021-02-24
ER

PT J
AU Pomper, R
   Weismer, SE
   Saffran, J
   Edwards, J
AF Pomper, Ron
   Weismer, Susan Ellis
   Saffran, Jenny
   Edwards, Jan
TI Specificity of Phonological Representations for Children with Autism
   Spectrum Disorder
SO JOURNAL OF AUTISM AND DEVELOPMENTAL DISORDERS
LA English
DT Article
DE Autism; Lexical processing; Weak central coherence; Phonology;
   Eye-tracking
ID WEAK CENTRAL COHERENCE; LANGUAGE IMPAIRMENT; SPEECH-PERCEPTION;
   DEVELOPMENTAL-CHANGES; EARLY RECOGNITION; ASPERGER-SYNDROME;
   VISUAL-SEARCH; WORDS; INDIVIDUALS; DISCRIMINATION
AB This study investigated whether children with autism spectrum disorder (ASD) are sensitive to mispronunciations of familiar words and compared their sensitivity to children with typical-development. Sixty-four toddlers with ASD and 31 younger, typical controls participated in a looking-while-listening task that measured their accuracy in fixating the correct object when it was labelled with a correct pronunciation versus mispronunciation. A cognitive style that prioritizes processing local, rather than global features, as claimed by the weak central coherence theory, predicts that children with ASD should be more sensitive to mispronunciations than typical controls. The results, however, reveal no differences in the effect of mispronunciations on lexical processing between groups, even when matched for receptive language or non-verbal cognitive skills.
C1 [Pomper, Ron; Saffran, Jenny] Univ Wisconsin, Dept Psychol, Brogden Hall 1202,West Johnson St, Madison, WI 53706 USA.
   [Pomper, Ron; Weismer, Susan Ellis; Saffran, Jenny] Univ Wisconsin, Waisman Ctr, 1500 Highland Ave, Madison, WI 53705 USA.
   [Weismer, Susan Ellis] Univ Wisconsin, Dept Commun Sci & Disorders, Goodnight Hall,1975 Willow Dr, Madison, WI 53706 USA.
   [Edwards, Jan] Univ Maryland, Dept Hearing & Speech Sci, Samuel J LeFrak Hall,7521 Preinkert Dr, College Pk, MD 20742 USA.
RP Pomper, R (corresponding author), Univ Wisconsin, Dept Psychol, Brogden Hall 1202,West Johnson St, Madison, WI 53706 USA.; Pomper, R (corresponding author), Univ Wisconsin, Waisman Ctr, 1500 Highland Ave, Madison, WI 53705 USA.
EM rpomper@wisc.edu
OI Ellis Weismer, Susan/0000-0003-3484-9910
FU NICHD NIH HHSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [U54 HD090256]
   Funding Source: Medline; NIDCD NIH HHSUnited States Department of Health
   & Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute on Deafness & Other Communication Disorders (NIDCD) [R01
   DC012513] Funding Source: Medline; EUNICE KENNEDY SHRIVER NATIONAL
   INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   Eunice Kennedy Shriver National Institute of Child Health & Human
   Development (NICHD) [U54HD090256, U54HD090256, U54HD090256, U54HD090256,
   U54HD090256, U54HD090256, U54HD090256, U54HD090256, U54HD090256,
   U54HD090256, U54HD090256, U54HD090256, U54HD090256, U54HD090256,
   U54HD090256, U54HD090256, U54HD090256, U54HD090256, U54HD090256,
   U54HD090256] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC012513] Funding Source: NIH RePORTER
CR American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU
   Baron-Cohen S., 1993, UNDERSTANDING OTHER
   BaronCohen S, 1997, CHILD DEV, V68, P48
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Booth R, 2003, PHILOS T ROY SOC B, V358, P387, DOI 10.1098/rstb.2002.1204
   Booth R, 2010, J EXP CHILD PSYCHOL, V107, P377, DOI 10.1016/j.jecp.2010.06.003
   Brock J, 2008, COGNITION, V108, P896, DOI 10.1016/j.cognition.2008.06.007
   Brown SM, 2012, RES AUTISM SPECT DIS, V6, P733, DOI 10.1016/j.rasd.2011.10.012
   Cardy JEO, 2005, NEUROREPORT, V16, P521, DOI 10.1097/00001756-200504040-00021
   Ceponiene R, 2003, P NATL ACAD SCI USA, V100, P5567, DOI 10.1073/pnas.0835631100
   CHARLESLUCE J, 1990, J CHILD LANG, V17, P205, DOI 10.1017/S0305000900013180
   Constantino JN, 2007, J AUTISM DEV DISORD, V37, P1256, DOI 10.1007/s10803-006-0269-9
   Dawson G, 2004, DEV PSYCHOL, V40, P271, DOI 10.1037/0012-1649.40.2.271
   Dawson G, 1998, J AUTISM DEV DISORD, V28, P479, DOI 10.1023/A:1026043926488
   Van de Cruys S, 2014, PSYCHOL REV, V121, P649, DOI 10.1037/a0037665
   Dennis M, 2009, J INT NEUROPSYCH SOC, V15, P331, DOI 10.1017/S1355617709090481
   DEPAPE A, 2012, PLOS ONE, V7, P1
   DiLavore P. C., 2012, AUTISM DIAGNOSTIC OB
   Eberhardt M, 2018, RES DEV DISABIL, V72, P284, DOI 10.1016/j.ridd.2016.01.017
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   Fernald A, 2006, DEV PSYCHOL, V42, P98, DOI 10.1037/0012-1649.42.1.98
   Fernald A, 2008, DEVELOPMENTAL PSYCHOLINGUISTICS: ON-LINE METHODS IN CHILDREN'S LANGUAGE PROCESSING, P97
   Frith U., 1983, BRIT J DEV PSYCHOL, V1, P329, DOI [10.1111/j.2044-835X.1983.tb00906.x, DOI 10.1111/J.2044-835X.1983.TB00906.X]
   Frith Uta, 1989, AUTISM EXPLAINING EN
   Gomot M, 2012, INT J PSYCHOPHYSIOL, V83, P240, DOI 10.1016/j.ijpsycho.2011.09.017
   Greene R, 2019, AUTISM RES, V5, P2
   Hala S, 2007, J AUTISM DEV DISORD, V37, P329, DOI 10.1007/s10803-006-0162-6
   Happe F, 2006, J AUTISM DEV DISORD, V36, P5, DOI 10.1007/s10803-005-0039-0
   Happe FGE, 1997, BRIT J DEV PSYCHOL, V15, P1, DOI 10.1111/j.2044-835X.1997.tb00721.x
   Happe FGE, 2008, Q J EXP PSYCHOL, V61, P50, DOI 10.1080/17470210701508731
   Henderson L, 2014, DEVELOPMENTAL SCI, V17, P858, DOI 10.1111/desc.12169
   Hoy JA, 2004, AUTISM, V8, P267, DOI 10.1177/1362361304045218
   Iarocci G, 2006, J AUTISM DEV DISORD, V36, P77, DOI 10.1007/s10803-005-0044-3
   Jansson-Verkasalo E, 2003, NEUROSCI LETT, V338, P197, DOI 10.1016/S0304-3940(02)01405-2
   Jolliffe T, 1999, COGNITION, V71, P149, DOI 10.1016/S0010-0277(99)00022-0
   JUSCZYK PW, 1993, J PHONETICS, V21, P109, DOI 10.1016/S0095-4470(19)31324-5
   KEMNER C, 1995, BIOL PSYCHIAT, V38, P150, DOI 10.1016/0006-3223(94)00247-Z
   Key AP, 2016, J INTELL DISABIL RES, V60, P478, DOI 10.1111/jir.12286
   Kjelgaard MM, 2001, LANG COGNITIVE PROC, V16, P287, DOI 10.1080/01690960042000058
   Kuhl PK, 2005, DEVELOPMENTAL SCI, V8, pF1, DOI 10.1111/j.1467-7687.2004.00384.x
   Lepisto T, 2005, BRAIN RES, V1066, P147, DOI 10.1016/j.brainres.2005.10.052
   Lindgren KA, 2009, AUTISM RES, V2, P22, DOI 10.1002/aur.63
   Lopez B, 2003, J CHILD PSYCHOL PSYC, V44, P285, DOI 10.1111/1469-7610.00121
   Loucas T, 2008, J CHILD PSYCHOL PSYC, V49, P1184, DOI 10.1111/j.1469-7610.2008.01951.x
   Mahr T, 2015, COGNITION, V142, P345, DOI 10.1016/j.cognition.2015.05.009
   McDuffie A., 2006, FIRST LANG, V26, P421, DOI [DOI 10.1177/0142723706067438, 10.1177/0142723706067438]
   Metsala JL, 1998, WORD RECOGNITION IN BEGINNING LITERACY, P89
   Miller GA, 2001, J ABNORM PSYCHOL, V110, P40, DOI 10.1037//0021-843X.110.1.40
   Mirman D., 2016, GROWTH CURVE ANAL VI
   Mottron L, 2001, DEVELOPMENT OF AUTISM: PERSPECTIVES FROM THEORY AND RESEARCH, P131
   Mottron L, 2003, J CHILD PSYCHOL PSYC, V44, P904, DOI 10.1111/1469-7610.00174
   Mullen E., 1995, MULLEN SCALES EARLY
   MUNDY P, 1986, J CHILD PSYCHOL PSYC, V27, P657, DOI 10.1111/j.1469-7610.1986.tb00190.x
   Norbury CF, 2005, J EXP CHILD PSYCHOL, V90, P142, DOI 10.1016/j.jecp.2004.11.003
   Norbury CF, 2002, INT J LANG COMM DIS, V37, P227, DOI 10.1080/13682820210136269
   Norbury CF, 2010, NEUROPSYCHOLOGIA, V48, P4012, DOI 10.1016/j.neuropsychologia.2010.10.015
   O'Riordan MA, 2001, J EXP PSYCHOL HUMAN, V27, P719, DOI 10.1037//0096-1523.27.3.719
   OSTERLING J, 1994, J AUTISM DEV DISORD, V24, P247, DOI 10.1007/BF02172225
   Osterling JA, 2002, DEV PSYCHOPATHOL, V14, P239, DOI 10.1017/S0954579402002031
   Pellicano E., 2011, RES AUTISM SPECT DIS, P219
   Pellicano E, 2010, DEV PSYCHOL, V46, P530, DOI 10.1037/a0018287
   Pickles A, 2014, J CHILD PSYCHOL PSYC, V55, P1354, DOI 10.1111/jcpp.12269
   Plaisted K, 1998, J CHILD PSYCHOL PSYC, V39, P777, DOI 10.1111/1469-7610.00376
   Plaisted K. C., 2000, UNDERSTANDING OTHER
   Plaisted KC, 2001, DEVELOPMENT OF AUTISM: PERSPECTIVES FROM THEORY AND RESEARCH, P149
   PLANTE E, 1993, J SPEECH HEAR RES, V36, P772, DOI 10.1044/jshr.3604.772
   Riches NG, 2016, J AUTISM DEV DISORD, V46, P155, DOI 10.1007/s10803-015-2560-0
   Robins DL, 2001, J AUTISM DEV DISORD, V31, P131, DOI 10.1023/A:1010738829569
   Rutter M., 2003, SOCIAL COMMUNICATION
   SHAH A, 1983, J CHILD PSYCHOL PSYC, V24, P613, DOI 10.1111/j.1469-7610.1983.tb00137.x
   SHAH A, 1993, J CHILD PSYCHOL PSYC, V34, P1351, DOI 10.1111/j.1469-7610.1993.tb02095.x
   Sinha P, 2014, P NATL ACAD SCI USA, V111, P15220, DOI 10.1073/pnas.1416797111
   Stewart ME, 2008, COGNITION, V109, P157, DOI 10.1016/j.cognition.2008.07.010
   Swingley D, 2005, DEVELOPMENTAL SCI, V8, P432, DOI 10.1111/j.1467-7687.2005.00432.x
   Swingley D, 2002, PSYCHOL SCI, V13, P480, DOI 10.1111/1467-9280.00485
   Tager-Flusberg H, 2013, AUTISM RES, V6, P468, DOI 10.1002/aur.1329
   Venker CE, 2019, J AUTISM DEV DISORD, V49, P1011, DOI 10.1007/s10803-018-3778-4
   Venker CE, 2016, J AUTISM DEV DISORD, V46, P2260, DOI 10.1007/s10803-016-2747-z
   Weismer SE, 2016, J AUTISM DEV DISORD, V46, P3755, DOI 10.1007/s10803-016-2926-y
   Werner E, 2000, J AUTISM DEV DISORD, V30, P157, DOI 10.1023/A:1005463707029
   You RS, 2017, RES DEV DISABIL, V61, P158, DOI 10.1016/j.ridd.2016.12.009
   Zimmerman I. L., 2002, PRESCHOOL LANGUAGE S
NR 82
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER/PLENUM PUBLISHERS
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0162-3257
EI 1573-3432
J9 J AUTISM DEV DISORD
JI J. Autism Dev. Disord.
PD AUG
PY 2019
VL 49
IS 8
BP 3351
EP 3363
DI 10.1007/s10803-019-04054-5
PG 13
WC Psychology, Developmental
SC Psychology
GA IJ1JS
UT WOS:000475655300024
PM 31098924
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Thielens, A
   Bockstael, A
   Declerck, S
   Aminzadeh, R
   Aerts, S
   Botteldooren, D
   Martens, L
   Joseph, W
AF Thielens, Arno
   Bockstael, Annelies
   Declerck, Sofie
   Aminzadeh, Reza
   Aerts, Sam
   Botteldooren, Dick
   Martens, Luc
   Joseph, Wout
TI Mobile phones: A trade-off between speech intelligibility and exposure
   to noise levels and to radio-frequency electromagnetic fields
SO ENVIRONMENTAL RESEARCH
LA English
DT Article
DE RF EM-Exposure; Mobile phone; Sound; Specific absorption rate; Speech
   intelligibility
ID TISSUE-SPECIFIC EXPOSURE; RF-EMF EXPOSURE; OUTPUT POWER; CELL PHONE;
   COMMUNICATION; HEARING; IMPACT; HEAD; DISTRIBUTIONS; RECOGNITION
AB When making phone calls, cellphone and smartphone users are exposed to radio-frequency (RF) electromagnetic fields (EMFs) and sound pressure simultaneously. Speech intelligibility during mobile phone calls is related to the sound pressure level of speech relative to potential background sounds and also to the RF-EMF exposure, since the signal quality is correlated with the RF-EMF strength. Additionally, speech intelligibility, sound pressure level, and exposure to RF-EMFs are dependent on how the call is made (on speaker, held at the ear, or with headsets). The relationship between speech intelligibility, sound exposure, and exposure to RF-EMFs is determined in this study. To this aim, the transmitted RF-EMF power was recorded during phone calls made by 53 subjects in three different, controlled exposure scenarios: calling with the phone at the ear, calling in speaker mode, and calling with a headset. This emitted power is directly proportional to the exposure to RF EMFs and is translated into specific absorption rate using numerical simulations. Simultaneously, sound pressure levels have been recorded and speech intelligibility has been assessed during each phone call. The results show that exposure to RF-EMFs, quantified as the specific absorption in the head, will be reduced when speaker-mode or a headset is used, in comparison to calling next to the ear. Additionally, personal exposure to sound pressure is also found to be highest in the condition where the phone is held next to the ear. On the other hand, speech perception is found to be the best when calling with a phone next to the ear in comparison to the other studied conditions, when background noise is present.
C1 [Thielens, Arno; Bockstael, Annelies; Declerck, Sofie; Aminzadeh, Reza; Aerts, Sam; Botteldooren, Dick; Martens, Luc; Joseph, Wout] Univ Ghent, Dept Informat Technol, iMinds, Technol Pk 126, B-9052 Ghent, Belgium.
   [Thielens, Arno] Univ Calif Berkeley, Berkeley Wireless Res Ctr, Dept Elect Engn & Comp Sci, 2108 Allston Way,Suite 200, Berkeley, CA 94704 USA.
   [Bockstael, Annelies] Univ Montreal, Ecole Orthophonie & Audiol, 7077 Av Parc, Montreal, PQ H3N 1X7, Canada.
RP Thielens, A (corresponding author), Univ Ghent, Dept Informat Technol, IMEC, Technol Pk 126, B-9052 Ghent, Belgium.
EM arno.thielens@ugent.be
RI Botteldooren, Dick/P-1506-2019; Aerts, Sam/G-4817-2013; Aminzadeh,
   Reza/M-4045-2016
OI Botteldooren, Dick/0000-0002-7756-7238; Aerts, Sam/0000-0002-7444-4312;
   Thielens, Arno/0000-0002-8089-6382; Aminzadeh, Reza/0000-0003-2309-6888
FU European Union's Horizon 2020 research and innovation programme
   [665501]; research Foundation Flanders (FWO)FWO
FX This project has received funding from the European Union's Horizon 2020
   research and innovation programme under the Marie Sklodowska-Curie grant
   agreement No 665501 with the research Foundation Flanders (FWO). AT is
   an FWO [PEGASUS]<SUP>2</SUP> Marie Sklodowska-Curie Fellow. S. A. is a
   postdoctoral fellow of the FWO.
CR Adibzadeh F, 2015, BIOELECTROMAGNETICS, V36, P66, DOI 10.1002/bem.21885
   Aerts S, 2015, INT J ENV RES PUB HE, V12, P2639, DOI 10.3390/ijerph120302639
   Ahlbom A, 1998, HEALTH PHYS, V74, P494
   Aminzadeh R, 2016, BIOELECTROMAGNETICS, V37, P298, DOI 10.1002/bem.21975
   Bockstael A, 2011, J ACOUST SOC AM, V129, P3702, DOI 10.1121/1.3575599
   Bockstael A, 2009, J ACOUST SOC AM, V125, P1479, DOI 10.1121/1.3075603
   Bolte JFB, 2012, ENVIRON INT, V48, P133, DOI 10.1016/j.envint.2012.07.006
   Christ A, 2010, PHYS MED BIOL, V55, P1767, DOI 10.1088/0031-9155/55/7/001
   Collet C, 2010, ERGONOMICS, V53, P602, DOI 10.1080/00140131003769092
   Foerster M., 2018, ENV HLTH PERSPECT, V126, P13
   Gabriel S, 1996, PHYS MED BIOL, V41, P2271, DOI 10.1088/0031-9155/41/11/003
   Gati A, 2010, IEEE T ELECTROMAGN C, V52, P829, DOI 10.1109/TEMC.2010.2066978
   Ghanmi A, 2014, BIOELECTROMAGNETICS, V35, P568, DOI 10.1002/bem.21856
   Gosselin MC, 2014, PHYS MED BIOL, V59, P5287, DOI 10.1088/0031-9155/59/18/5287
   Gosselin MC, 2011, BIOELECTROMAGNETICS, V32, P493, DOI 10.1002/bem.20662
   Guxens M, 2016, ENVIRON RES, V150, P364, DOI 10.1016/j.envres.2016.06.021
   Hammershoi D, 2008, ACTA ACUST UNITED AC, V94, P114, DOI 10.3813/AAA.918014
   Hillert L, 2006, J EXPO SCI ENV EPID, V16, P507, DOI 10.1038/sj.jes.7500485
   International Electrotechnical Commission (IEC), 2001, IEC62209CD
   Jorgensen S, 2015, ACTA ACUST UNITED AC, V101, P1016, DOI 10.3813/AAA.918896
   Joseph W, 2013, PROG BIOPHYS MOL BIO, V111, P30, DOI 10.1016/j.pbiomolbio.2012.10.002
   Joshi P, 2015, IEEE ACCESS, V3, P1051, DOI 10.1109/ACCESS.2015.2453056
   Kelsh MA, 2011, J EXPO SCI ENV EPID, V21, P343, DOI 10.1038/jes.2010.12
   Krayni A, 2017, INT J ANTENN PROPAG, V2017, DOI 10.1155/2017/8243490
   Krayni A, 2016, IEEE T ELECTROMAGN C, V58, P896, DOI 10.1109/TEMC.2016.2524543
   Kuehn S, 2013, BIOELECTROMAGNETICS, V34, P479, DOI 10.1002/bem.21784
   Kuhn S, 2013, IEEE T ELECTROMAGN C, V55, P275, DOI 10.1109/TEMC.2012.2220971
   Lauer O, 2013, BIOELECTROMAGNETICS, V34, P366, DOI 10.1002/bem.21782
   Li CH, 2012, IEEE T MICROW THEORY, V60, P2267, DOI 10.1109/TMTT.2012.2197019
   Lonn S, 2004, OCCUP ENVIRON MED, V61, P769, DOI 10.1136/oem.2003.012567
   MILLS JH, 1981, J ACOUST SOC AM, V70, P390, DOI 10.1121/1.386774
   Morrissey JJ, 2007, RADIAT PROT DOSIM, V123, P490, DOI 10.1093/rpd/ncl547
   Neuman AC, 2010, EAR HEARING, V31, P336, DOI 10.1097/AUD.0b013e3181d3d514
   Panda NK, 2011, OTOLARYNG HEAD NECK, V144, P581, DOI 10.1177/0194599810394953
   Patel S, 2013, HANDBOOK OF LC-MS BIOANALYSIS: BEST PRACTICES, EXPERIMENTAL PROTOCOLS, AND REGULATIONS, P15
   Persson T, 2012, BIOELECTROMAGNETICS, V33, P320, DOI 10.1002/bem.20710
   Porter S. J., 2004, Technical Seminar on Antenna Measurements and SAR (AMS 2004), P9, DOI 10.1049/ic:20040067
   Porter S. J., 2003, SAR TESTING HANDS FR
   ROBINSON DW, 1957, J ACOUST SOC AM, V29, P1284, DOI 10.1121/1.1908766
   Roser K, 2016, INT J HYG ENVIR HEAL, V219, P759, DOI 10.1016/j.ijheh.2016.08.007
   Roser K, 2015, INT J ENV RES PUB HE, V12, P5634, DOI 10.3390/ijerph120505634
   Sagiv D, 2018, J LARYNGOL OTOL, V132, P29, DOI 10.1017/S0022215117002365
   Schoeni A, 2015, ENVIRON INT, V85, P343, DOI 10.1016/j.envint.2015.09.025
   Siegbahn M, 2010, IEEE T ELECTROMAGN C, V52, P804, DOI 10.1109/TEMC.2010.2051672
   Smits C., 2004, EAR HEAR
   Thielens A, 2013, BIOELECTROMAGNETICS, V34, P549, DOI 10.1002/bem.21799
   Varsier N, 2015, BIOELECTROMAGNETICS, V36, P451, DOI 10.1002/bem.21928
   Vrijheid M, 2009, OCCUP ENVIRON MED, V66, P664, DOI 10.1136/oem.2008.043380
   Wiart J, 2000, IEEE T ELECTROMAGN C, V42, P376, DOI 10.1109/15.902307
   Wouters J, 1994, LOGOPEDIE, V7, P28
NR 50
TC 0
Z9 0
U1 1
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0013-9351
EI 1096-0953
J9 ENVIRON RES
JI Environ. Res.
PD AUG
PY 2019
VL 175
BP 1
EP 10
DI 10.1016/j.envres.2019.05.006
PG 10
WC Environmental Sciences; Public, Environmental & Occupational Health
SC Environmental Sciences & Ecology; Public, Environmental & Occupational
   Health
GA IG5II
UT WOS:000473836300001
PM 31096087
OA Green Published
DA 2021-02-24
ER

PT J
AU Harmon, Z
   Idemaru, K
   Kapatsinski, V
AF Harmon, Zara
   Idemaru, Kaori
   Kapatsinski, Vsevolod
TI Learning mechanisms in cue reweighting
SO COGNITION
LA English
DT Article
DE Reinforcement learning; Error-driven learning; Distributional learning;
   Rescorla-Wagner; Speech perception; Phonetic cues
ID SELECTIVE ATTENTION; AUDITORY CATEGORIZATION; SPEECH-PERCEPTION; TRADING
   RELATIONS; CONTEXT; ACQUISITION; CHILDREN; COMPREHENSION; EXPECTATION;
   INFORMATION
AB Feedback has been shown to be effective in shifting attention across perceptual cues to a phonological contrast in speech perception (Francis, Baldwin & Nusbaum, 2000). However, the learning mechanisms behind this process remain obscure. We compare the predictions of supervised error-driven learning (Rescorla & Wagner, 1972) and reinforcement learning (Sutton & Barto, 1998) using computational simulations. Supervised learning predicts downweighting of an informative cue when the learner receives evidence that it is no longer informative. In contrast, reinforcement learning suggests that a reduction in cue weight requires positive evidence for the informativeness of an alternative cue. Experimental evidence supports the latter prediction, implicating reinforcement learning as the mechanism behind the effect of feedback on cue weighting in speech perception. Native English listeners were exposed to either bimodal or unimodal VOT distributions spanning the un-aspirated/aspirated boundary (bear/pear). VOT is the primary cue to initial stop voicing in English. However, lexical feedback in training indicated that VOT was no longer predictive of voicing. Reduction in the weight of VOT was observed only when participants could use an alternative cue, F0, to predict voicing. Frequency distributions had no effect on learning. Overall, the results suggest that attention shifting in learning the phonetic cues to phonological categories is accomplished using simple reinforcement learning principles that also guide the choice of actions in other domains.
C1 [Harmon, Zara; Kapatsinski, Vsevolod] Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.
   [Idemaru, Kaori] Univ Oregon, Dept East Asian Languages & Literatures, Eugene, OR 97403 USA.
RP Harmon, Z (corresponding author), Dept Linguist, 1290 Univ Oregon, Eugene, OR 97403 USA.
EM zharmon@uoregon.edu
RI Kapatsinski, Vsevolod/I-6923-2019
CR Abramson A. S., 1985, PHONETIC LINGUISTICS, P25
   Arnold D, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174623
   Baayen RH, 2016, LANG COGN NEUROSCI, V31, P106, DOI 10.1080/23273798.2015.1065336
   Baayen RH, 2011, PSYCHOL REV, V118, P438, DOI 10.1037/a0023851
   Baese-Berk MM, 2010, THESIS
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bates E., 1989, CROSSLINGUISTIC STUD, V3, P73
   Boersma P., 2003, P 15 INT C PHON SCI, P1013
   Boersma P., 2010, PRAAT DOING PHONETIC
   BRESLOW NE, 1993, J AM STAT ASSOC, V88, P9, DOI 10.1080/01621459.1993.10594284
   Clayards M, 2018, PHONETICA, V75, P1, DOI 10.1159/000448809
   Danks D, 2003, J MATH PSYCHOL, V47, P109, DOI 10.1016/S0022-2496(02)00016-0
   Ellis NC, 2006, APPL LINGUIST, V27, P164, DOI 10.1093/applin/aml015
   Escudero P., 2005, LINGUISTIC PERCEPTIO
   Feldman NH, 2009, PSYCHOL REV, V116, P752, DOI 10.1037/a0017196
   Francis AL, 2002, J EXP PSYCHOL HUMAN, V28, P349, DOI 10.1037//0096-1523.28.2.349
   Francis AL, 2000, PERCEPT PSYCHOPHYS, V62, P1668, DOI 10.3758/BF03212164
   Gabay Y, 2015, J EXP PSYCHOL HUMAN, V41, P1124, DOI 10.1037/xhp0000073
   Gallistel CR, 2004, P NATL ACAD SCI USA, V101, P13124, DOI 10.1073/pnas.0404965101
   German JS, 2013, J PHONETICS, V41, P228, DOI 10.1016/j.wocn.2013.03.001
   GLUCK MA, 1988, J MEM LANG, V27, P166, DOI 10.1016/0749-596X(88)90072-1
   Goudbeek M, 2008, SPEECH COMMUN, V50, P109, DOI 10.1016/j.specom.2007.07.003
   Gureckis T. M., 2008, P 30 ANN C COGN SCI, V30, P1876
   HARRIS KS, 1958, J ACOUST SOC AM, V30, P122, DOI 10.1121/1.1909501
   Hayes-Harb R, 2007, SECOND LANG RES, V23, P65, DOI 10.1177/0267658307071601
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   Holt L. L., 1998, CHICAGO LINGUISTIC S, P253
   Holt LL, 2001, J ACOUST SOC AM, V109, P764, DOI 10.1121/1.1339825
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Holt LL, 2018, HEARING RES, V366, P50, DOI 10.1016/j.heares.2018.06.014
   Idemaru K, 2012, J ACOUST SOC AM, V132, P3950, DOI 10.1121/1.4765076
   Idemaru K, 2011, J EXP PSYCHOL HUMAN, V37, P1939, DOI 10.1037/a0025641
   Ingvalson EM, 2011, J PHONETICS, V39, P571, DOI 10.1016/j.wocn.2011.03.003
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Kapatsinski V, 2018, CHANGING MINDS CHANGING TOOLS: FROM LEARNING THEORY TO LANGUAGE ACQUISITION TO LANGUAGE CHANGE
   Kim MR, 2002, J PHONETICS, V30, P77, DOI 10.1006/jpho.2001.0152
   KIM MRC, 2002, KOREAN LANGUAGE AM, V7, P177
   KINGSTON J, 1994, LANGUAGE, V70, P419, DOI 10.2307/416481
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Lim SJ, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00230
   LISKER L, 1978, LANG SPEECH, V21, P375, DOI 10.1177/002383097802100413
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Lively S. E., 1992, SPEECH PERCEPTION PR, P175
   LUCE RD, 1959, PSYCHOL REV, V66, P81, DOI 10.1037/h0043178
   MacWhinney B, 2005, HDB BILINGUALISM PSY, P49
   MacWhinney Brian, 1987, MECH LANGUAGE ACQUIS, P249
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Maye J, 2000, PROC ANN BUCLD, P522
   Maye J, 2008, DEVELOPMENTAL SCI, V11, P122, DOI 10.1111/j.1467-7687.2007.00653.x
   Mayo C, 2004, J ACOUST SOC AM, V115, P3184, DOI 10.1121/1.1738838
   McMurray B, 2005, COGNITION, V95, pB15, DOI 10.1016/j.cognition.2004.07.005
   MILLER RR, 1995, PSYCHOL BULL, V117, P363, DOI 10.1037/0033-2909.117.3.363
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   MORRONGIELLO BA, 1984, J EXP CHILD PSYCHOL, V37, P231, DOI 10.1016/0022-0965(84)90002-X
   Navarro DJ, 2012, COGNITIVE SCI, V36, P187, DOI 10.1111/j.1551-6709.2011.01212.x
   Nearey TM, 1997, J ACOUST SOC AM, V101, P3241, DOI 10.1121/1.418290
   NITTROUER S, 1992, J PHONETICS, V20, P351, DOI 10.1016/S0095-4470(19)30639-4
   Nittrouer S, 1997, J ACOUST SOC AM, V102, P572, DOI 10.1121/1.419730
   Nittrouer S, 2002, J ACOUST SOC AM, V112, P711, DOI 10.1121/1.1496082
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Olejarczuk P, 2018, LINGUIST VANGUARD, V4, DOI 10.1515/lingvan-2017-0020
   PARNELL MM, 1978, J SPEECH HEAR RES, V21, P682, DOI 10.1044/jshr.2104.682
   R Core Team, 2015, R LANG ENV STAT COMP
   Ramscar M, 2014, TOP COGN SCI, V6, P5, DOI 10.1111/tops.12078
   Ramscar M, 2013, LANGUAGE, V89, P760, DOI 10.1353/lan.2013.0068
   Ramscar M, 2013, PSYCHOL SCI, V24, P1017, DOI 10.1177/0956797612460691
   Ramscar M, 2010, COGNITIVE SCI, V34, P909, DOI 10.1111/j.1551-6709.2009.01092.x
   REPP BH, 1982, PSYCHOL BULL, V92, P81, DOI 10.1037/0033-2909.92.1.81
   Rescorla R.A., 1972, CLASSICAL CONDITIONI, V2, P64, DOI DOI 10.1101/GR.110528.110
   Roelfsema PR, 2010, TRENDS COGN SCI, V14, P64, DOI 10.1016/j.tics.2009.11.005
   Schertz Jessamyn L., 2013, Journal of the Acoustical Society of America, V134, DOI 10.1121/1.4830715
   Seitz AR, 2009, NEURON, V61, P700, DOI 10.1016/j.neuron.2009.01.016
   Seitz AR, 2003, NATURE, V422, P36, DOI 10.1038/422036a
   SILBERBERG A, 1978, J EXP PSYCHOL-ANIM B, V4, P368, DOI 10.1037/0097-7403.4.4.368
   SUTTON RS, 1981, PSYCHOL REV, V88, P135, DOI 10.1037/0033-295X.88.2.135
   Sutton RS., 1998, INTRO REINFORCEMENT, V1st edn
   Thiessen ED, 2011, DEV PSYCHOL, V47, P1448, DOI 10.1037/a0024439
   Toscano JC, 2012, ATTEN PERCEPT PSYCHO, V74, P1284, DOI 10.3758/s13414-012-0306-z
   Toscano JC, 2010, COGNITIVE SCI, V34, P434, DOI 10.1111/j.1551-6709.2009.01077.x
   Wagenmakers EJ, 2007, PSYCHON B REV, V14, P779, DOI 10.3758/BF03194105
   Wanrooij K, 2015, FRONT PSYCHOL, V6, DOI [10.3389/fpsyg.2015.01341, 10.3389/fpg.21115.111341]
   Wanrooij K, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0109806
   WHALEN DH, 1993, J ACOUST SOC AM, V93, P2152, DOI 10.1121/1.406678
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3_1
   Widrow B., 1960, IRE Wescon Convention Record, V4, P96
   Xu F, 2007, DEVELOPMENTAL SCI, V10, P288, DOI 10.1111/j.1467-7687.2007.00590.x
   Yamada R. A., 1991, SPEECH PERCEPTION PR, P155
NR 88
TC 3
Z9 3
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD AUG
PY 2019
VL 189
BP 76
EP 88
DI 10.1016/j.cognition.2019.03.011
PG 13
WC Psychology, Experimental
SC Psychology
GA IE9KS
UT WOS:000472693900009
PM 30928780
DA 2021-02-24
ER

PT J
AU Choi, W
   Tong, XL
   Samuel, AG
AF Choi, William
   Tong, Xiuli
   Samuel, Arthur G.
TI Better than native: Tone language experience enhances English lexical
   stress discrimination in Cantonese-English bilingual listeners
SO COGNITION
LA English
DT Article
DE Tone language expertise; Second language learning; Lexical stress;
   Lexical tone; Cross-language speech perception
ID PERCEPTION; DEAFNESS; SPEECH
AB While many second language (L2) listeners are known to struggle when discriminating non-native features absent in their first language (L1), no study has reported that L2 listeners perform better than native listeners in this regard. The present study tested whether Cantonese-English bilinguals were better in discriminating English lexical stress in individual words or pseudowords than native English listeners, even though lexical stress is absent in Cantonese. In experiments manipulating acoustic, phonotactic, and lexical cues, Cantonese-English bilingual adults exhibited superior performance in discriminating English lexical stress than native English listeners across all phonotactic/lexical conditions when the fundamental frequency (f0) cue to lexical stress was present. The findings underscore the facilitative effect of Cantonese tone language experience on English lexical stress discrimination.
C1 [Choi, William] UCL, Inst Cognit Neurosci, London, England.
   [Choi, William] UCL, Deafness Cognit & Language Res Ctr, London, England.
   [Tong, Xiuli] Univ Hong Kong, Div Speech & Hearing Sci, Hong Kong, Peoples R China.
   [Samuel, Arthur G.] SUNY Stony Brook, Dept Psychol, Stony Brook, NY 11794 USA.
   [Samuel, Arthur G.] Basque Ctr Cognit Brain & Language, Donostia San Sebastian, Gipuzkoa, Spain.
   [Samuel, Arthur G.] Basque Fdn Sci, Ikerbasque, Bilbao, Bizkaia, Spain.
RP Choi, W (corresponding author), Alexandra House,17-19 Queen Sq, London WC1N 3AZ, England.; Tong, XL (corresponding author), Univ Hong Kong, 804 Meng Wah Complex, Hong Kong, Peoples R China.
EM w.choi@ucl.ac.uk; xltong@hku.hk
RI Samuel, Arthur G./Q-4683-2019
OI , Arthur Gary Samuel/0000-0001-8552-2710
FU Fulbright-Lee Hysan Research Scholar Award from the US Department of
   State; Lee Hysan Foundation; Language Learning Dissertation Grant from
   Language Learning; Pilot Scheme on International Experiences for
   Research Postgraduate Students from The University of Hong Kong; Early
   Career Scheme from the HKSAR Research Grant Council [27402514]; General
   Research Fund from the HKSAR Research Grant Council [17609518,
   17673216]; Ministerio de Ciencia E Innovation [PSI2014-53277]; Centro de
   Excelencia Severo Ochoa [SEV-2015-0490]; National Science
   FoundationNational Science Foundation (NSF) [IBSS-1519908]
FX This article is based on the fourth chapter of the PhD thesis submitted
   by William Choi to The University of Hong Kong. This research was
   supported, in part, by the Fulbright-Lee Hysan Research Scholar Award
   from the US Department of State and Lee Hysan Foundation, and the
   Language Learning Dissertation Grant from Language Learning to William
   Choi. It was also supported by the Pilot Scheme on International
   Experiences for Research Postgraduate Students from The University of
   Hong Kong to William Choi, and the Early Career Scheme (27402514),
   General Research Fund (17673216), and General Research Fund (17609518)
   from the HKSAR Research Grant Council to Xiuli Tong. Support was also
   provided by Ministerio de Ciencia E Innovation, Grant PSI2014-53277,
   Centro de Excelencia Severo Ochoa, Grant SEV-2015-0490, and by the
   National Science Foundation under Grant IBSS-1519908 to Arthur Samuel.
   We thank Benjamin Munson for his useful suggestion about the
   syllable-timed nature of Cantonese and the four anonymous reviewers for
   comments that have helped us to develop our ideas and presentation more
   clearly.
CR Beckman M. E., 1986, PHONOLOGY YB, V3, P255, DOI [DOI 10.1017/S095267570000066X, 10.1017/S095267570000066X]
   Beckman M. E., 1994, PHONOLOGICAL STRUCTU, P7, DOI DOI 10.1017/CBO9780511659461.002
   Bidelman GM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0060676
   Campbell N., 1997, J ACOUST SOC AM, V101, P3195
   Choi W, 2017, J NEUROLINGUIST, V41, P11, DOI 10.1016/j.jneuroling.2016.09.003
   Chrabaszcz A, 2014, J SPEECH LANG HEAR R, V57, P1468, DOI 10.1044/2014_JSLHR-L-13-0279
   DEJONG KJ, 1995, J ACOUST SOC AM, V97, P491, DOI 10.1121/1.412275
   Dupoux E, 1997, J MEM LANG, V36, P406, DOI 10.1006/jmla.1996.2500
   Dupoux E, 2008, COGNITION, V106, P682, DOI 10.1016/j.cognition.2007.04.001
   Dupoux E, 2010, COGNITION, V114, P266, DOI 10.1016/j.cognition.2009.10.001
   EADY SJ, 1982, LANG SPEECH, V25, P29, DOI 10.1177/002383098202500103
   Flege James, 1995, SPEECH PERCEPTION LI, P229
   Fry D. B., 1958, LANG SPEECH, V1, P205
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   GANDOUR J, 1981, J CHINESE LINGUIST, V9, P20
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Krishnan A, 2010, J NEUROLINGUIST, V23, P81, DOI 10.1016/j.jneuroling.2009.09.001
   Ladefoged P., 2006, COURSE PHONETICS
   Lee YS, 1996, J PSYCHOLINGUIST RES, V25, P527, DOI 10.1007/BF01758181
   Mok P.P.K, 2008, CHINESE J PHONETICS, V2, P148
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Pfordresher PQ, 2009, ATTEN PERCEPT PSYCHO, V71, P1385, DOI 10.3758/APP.71.6.1385
   Roach P, 2003, PHONETICS
   Rosner B. S., 1994, VOWEL PERCEPTION PRO
   Sluijter A, 1996, 4 INT C SPOK LANG PR
   Teschner R. V., 2004, PRONOUNCING ENGLISH
   Tong XL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142896
   Underhill A, 1998, SOUND FDN LIVING PHO
   Wang Q., 2008, THESIS
   Wayland RP, 2004, LANG LEARN, V54, P681, DOI 10.1111/j.1467-9922.2004.00283.x
   Yu VY, 2010, J PSYCHOLINGUIST RES, V39, P323, DOI 10.1007/s10936-009-9142-2
   Zhang YH, 2010, J PHONETICS, V38, P260, DOI 10.1016/j.wocn.2009.11.002
   Zheng Y, 2018, Q J EXP PSYCHOL, V71, P2627, DOI 10.1177/1747021818757435
NR 34
TC 2
Z9 2
U1 2
U2 10
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD AUG
PY 2019
VL 189
BP 188
EP 192
DI 10.1016/j.cognition.2019.04.004
PG 5
WC Psychology, Experimental
SC Psychology
GA IE9KS
UT WOS:000472693900018
PM 30991274
DA 2021-02-24
ER

PT J
AU Karimi, H
   Brothers, T
   Ferreira, F
AF Karimi, Hossein
   Brothers, Trevor
   Ferreira, Fernanda
TI Phonological versus semantic prediction in focus and repair
   constructions: No evidence for differential predictions
SO COGNITIVE PSYCHOLOGY
LA English
DT Article
DE Language comprehension; Differential prediction; Disfluency; Spreading
   activation
ID WORD PRE-ACTIVATION; EYE-MOVEMENTS; INDIVIDUAL-DIFFERENCES; LANGUAGE
   PRODUCTION; SPOKEN LANGUAGE; SPEECH-PERCEPTION; COGNITIVE CONTROL;
   TIME-COURSE; COMPREHENSION; INHIBITION
AB Evidence suggests that the language processing system is predictive. Although past research has established prediction as a general tendency, it is not yet clear whether comprehenders can modulate their anticipatory strategies in response to cues based on sentence constructions. In two visual world eye-tracking experiments, we investigated whether focus constructions (not the hammer but rather the ...) and repair disfluencies (the hammer uh I mean the ...) would lead listeners to generate different patterns of predictions. In three offline tasks, we observed that participants preferred semantically related continuations (hammer - nail) following focus constructions and phonologically related continuations (hammer - hammock) following disfluencies. However, these offline preferences were not evident in participants' predictive eye-movements during online language processing: Semantically related (nail) and phonologically related words (hammock) received additional predictive looks regardless of whether the target word appeared in a disfluency or in a focus construction. However, significantly less semantic and phonological activation was observed in two "control" linguistic contexts in which predictive processing was discouraged. These findings suggest that although the prediction system is sensitive to sentence construction, is it not flexible enough to alter the type of prediction generated based on preceding context.
C1 [Karimi, Hossein] Penn State Univ, University Pk, PA 16801 USA.
   [Brothers, Trevor] Tufts Univ, Medford, MA 02155 USA.
   [Ferreira, Fernanda] Univ Calif Davis, Davis, CA 95616 USA.
RP Karimi, H (corresponding author), Penn State Univ, Dept Psychol, 109 Moore Bldg,Univ Pk, State Coll, PA 16801 USA.
EM karimi@psu.edu
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Barr DJ, 2008, J MEM LANG, V59, P457, DOI 10.1016/j.jml.2007.09.002
   Borovsky A, 2012, J EXP CHILD PSYCHOL, V112, P417, DOI 10.1016/j.jecp.2012.01.005
   Bortfeld H, 2001, LANG SPEECH, V44, P123, DOI 10.1177/00238309010440020101
   Braver TS, 2002, NEUROSCI BIOBEHAV R, V26, P809, DOI 10.1016/S0149-7634(02)00067-2
   Braver TS, 2001, J EXP PSYCHOL GEN, V130, P746, DOI 10.1037//0096-3445.130.4.746
   Brill E, 2000, 38TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P286, DOI 10.3115/1075218.1075255
   Brothers T, 2017, J MEM LANG, V93, P203, DOI 10.1016/j.jml.2016.10.002
   Brothers T, 2015, COGNITION, V136, P135, DOI 10.1016/j.cognition.2014.10.017
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234
   Chow W. Y., 2018, LANG COGN NEUROSCI, P1
   Chow WY, 2016, LANG COGN NEUROSCI, V31, P577, DOI 10.1080/23273798.2015.1066832
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477
   COOPER RM, 1974, COGNITIVE PSYCHOL, V6, P84, DOI 10.1016/0010-0285(74)90005-X
   Davies C, 2013, J PRAGMATICS, V49, P78, DOI 10.1016/j.pragma.2013.01.004
   DeLong KA, 2005, NAT NEUROSCI, V8, P1117, DOI 10.1038/nn1504
   DeLong KA, 2017, LANG COGN NEUROSCI, V32, P966, DOI 10.1080/23273798.2017.1279339
   Donnelly S, 2017, J MEM LANG, V94, P28, DOI 10.1016/j.jml.2016.10.005
   Drake E, 2015, MEM COGNITION, V43, P111, DOI 10.3758/s13421-014-0451-9
   EHRLICH SF, 1981, J VERB LEARN VERB BE, V20, P641, DOI 10.1016/S0022-5371(81)90220-6
   Engelhardt PE, 2013, ACTA PSYCHOL, V144, P424, DOI 10.1016/j.actpsy.2013.08.002
   Engelhardt PE, 2010, MEM COGNITION, V38, P617, DOI 10.3758/MC.38.5.617
   Engelhardt PE, 2006, J MEM LANG, V54, P554, DOI 10.1016/j.jml.2005.12.009
   Federmeier KD, 2007, BRAIN RES, V1146, P75, DOI 10.1016/j.brainres.2006.06.101
   Federmeier KD, 2010, BRAIN LANG, V115, P149, DOI 10.1016/j.bandl.2010.07.006
   Federmeier KD, 1999, COGNITIVE BRAIN RES, V8, P373, DOI 10.1016/S0926-6410(99)00036-1
   Ferreira F, 2018, CURR DIR PSYCHOL SCI, V27, P443, DOI 10.1177/0963721418794491
   Fine AB, 2013, COGNITIVE SCI, V37, P578, DOI 10.1111/cogs.12022
   Frisson S, 2005, J EXP PSYCHOL LEARN, V31, P862, DOI 10.1037/0278-7393.31.5.862
   Fukumura K, 2017, J MEM LANG, V95, P1, DOI 10.1016/j.jml.2017.01.008
   Gallistel CR, 2009, PSYCHOL REV, V116, P439, DOI 10.1037/a0015251
   Gibson E, 2013, PSYCHOL SCI, V24, P1079, DOI 10.1177/0956797612463705
   Henderson J. M., 2004, INTERFACE LANGUAGE V, P1, DOI DOI 10.4324/9780203488430
   Huettig F, 2005, COGNITION, V96, pB23, DOI 10.1016/j.cognition.2004.10.003
   Huettig F, 2007, J MEM LANG, V57, P460, DOI 10.1016/j.jml.2007.02.001
   Huettig F, 2016, LANG COGN NEUROSCI, V31, P19, DOI 10.1080/23273798.2015.1072223
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014
   Huettig F, 2011, ACTA PSYCHOL, V137, P151, DOI 10.1016/j.actpsy.2010.11.003
   Husband EM, 2016, LANG COGN NEUROSCI, V31, P217, DOI 10.1080/23273798.2015.1083113
   Ito A, 2017, LANG COGN NEUROSCI, V32, P954, DOI 10.1080/23273798.2016.1242761
   Ito A, 2016, J MEM LANG, V86, P157, DOI 10.1016/j.jml.2015.10.007
   Jaeger TF, 2011, WIRES COGN SCI, V2, P323, DOI 10.1002/wcs.126
   Jaeger TF, 2010, COGNITIVE PSYCHOL, V61, P23, DOI 10.1016/j.cogpsych.2010.02.002
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Jeffreys H., 1961, THEORY PROBABILITY
   Kahneman D., 2011, THINKING FAST SLOW
   Kaschak MP, 2004, J EXP PSYCHOL GEN, V133, P450, DOI 10.1037/0096-3445.133.3.450
   Kleinschmidt D.F., 2012, P ANN M COGN SCI SOC, V34
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kretzschtnar F, 2015, J EXP PSYCHOL LEARN, V41, P1648, DOI 10.1037/xlm0000128
   Kukona A, 2016, ACTA PSYCHOL, V171, P72, DOI 10.1016/j.actpsy.2016.09.009
   Kukona A, 2011, COGNITION, V119, P23, DOI 10.1016/j.cognition.2010.12.002
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299
   Kurumada C, 2015, J MEM LANG, V83, P152, DOI 10.1016/j.jml.2015.03.003
   Kutas M., 1984, BRAIN POTENTIALS REA
   Kutas M, 2011, HANDBOOK OF PSYCHOLINGUISTIC AND COGNITIVE PROCESSES: PERSPECTIVES IN COMMUNICATION DISORDERS, P119
   Laszlo S, 2009, J MEM LANG, V61, P326, DOI 10.1016/j.jml.2009.06.004
   Lau EF, 2013, J COGNITIVE NEUROSCI, V25, P484, DOI 10.1162/jocn_a_00328
   Levy R., 2008, P 2008 C EMP METH NA, P234, DOI DOI 10.3115/1613715.1613749
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006
   Levy Roger, 2007, ADV NEURAL INFORM PR, V19, P849
   Lowder MW, 2016, J EXP PSYCHOL LEARN, V42, P1400, DOI 10.1037/xlm0000256
   Lowder MW, 2016, LANG COGN NEUROSCI, V31, P73, DOI 10.1080/23273798.2015.1036089
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676
   MACDONALD MC, 1994, LANG COGNITIVE PROC, V9, P157, DOI 10.1080/01690969408402115
   Mani N, 2012, J EXP PSYCHOL HUMAN, V38, P843, DOI 10.1037/a0029284
   McDonald SA, 2003, PSYCHOL SCI, V14, P648, DOI 10.1046/j.0956-7976.2003.psci_1480.x
   Mirman D, 2012, J EXP PSYCHOL GEN, V141, P601, DOI 10.1037/a0026451
   Miyake A, 2012, CURR DIR PSYCHOL SCI, V21, P8, DOI 10.1177/0963721411429458
   NEELY JH, 1977, J EXP PSYCHOL GEN, V106, P226, DOI 10.1037/0096-3445.106.3.226
   Nieuwland M, 2017, BIORXIV, P111807, DOI [10.1101/111807, DOI 10.1101/111807]
   Osaka M, 2002, MEM COGNITION, V30, P562, DOI 10.3758/BF03194957
   Peirce J, 2019, BEHAV RES METHODS, V51, P195, DOI 10.3758/s13428-018-01193-y
   Piantadosi S. T, 2013, P NATL ACAD SCI USA
   Pickering MJ, 2007, TRENDS COGN SCI, V11, P105, DOI 10.1016/j.tics.2006.12.002
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   Rommers J, 2013, NEUROPSYCHOLOGIA, V51, P437, DOI 10.1016/j.neuropsychologia.2012.12.002
   Rouder JN, 2009, PSYCHON B REV, V16, P225, DOI 10.3758/PBR.16.2.225
   SASLOW MG, 1967, J OPT SOC AM, V57, P1030, DOI 10.1364/JOSA.57.001030
   Spivey MJ, 2002, COGNITIVE PSYCHOL, V45, P447, DOI 10.1016/S0010-0285(02)00503-0
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Tree JEF, 1995, J MEM LANG, V34, P709, DOI 10.1006/jmla.1995.1032
   Wetzels R, 2011, PERSPECT PSYCHOL SCI, V6, P291, DOI 10.1177/1745691611406923
   Yee E, 2006, J EXP PSYCHOL LEARN, V32, P1, DOI 10.1037/0278-7393.32.1.1
NR 87
TC 1
Z9 1
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0010-0285
EI 1095-5623
J9 COGNITIVE PSYCHOL
JI Cogn. Psychol.
PD AUG
PY 2019
VL 112
BP 25
EP 47
DI 10.1016/j.cogpsych.2019.04.001
PG 23
WC Psychology; Psychology, Experimental
SC Psychology
GA IE9LA
UT WOS:000472694700002
PM 31078824
DA 2021-02-24
ER

PT J
AU Li, MYC
   Braze, D
   Kukona, A
   Johns, CL
   Tabor, W
   Van Dyke, JA
   Mencl, WE
   Shankweiler, DP
   Pugh, KR
   Magnuson, JS
AF Li, Monica Y. C.
   Braze, David
   Kukona, Anuenue
   Johns, Clinton L.
   Tabor, Whitney
   Van Dyke, Julie A.
   Mencl, W. Einar
   Shankweiler, Donald P.
   Pugh, Kenneth R.
   Magnuson, James S.
TI Individual differences in subphonemic sensitivity and phonological
   skills
SO JOURNAL OF MEMORY AND LANGUAGE
LA English
DT Article
DE Spoken word recognition; Eye tracking; Phonological skills; Individual
   differences; Reading ability
ID EVENT-RELATED POTENTIALS; SPEECH-PERCEPTION; DEVELOPMENTAL DYSLEXIA;
   WORD RECOGNITION; LANGUAGE-SKILLS; ALLOPHONIC MODE; FAMILIAL RISK;
   TIME-COURSE; PREDICTING DYSLEXIA; READING-ABILITY
AB Many studies have established a link between phonological abilities (indexed by phonological awareness and phonological memory tasks) and typical and atypical reading development. Individuals who perform poorly on phonological assessments have been mostly assumed to have underspecified (or "fuzzy") phonological representations, with typical phonemic categories, but with greater category overlap due to imprecise encoding. An alternative posits that poor readers have overspecified phonological representations, with speech sounds perceived allophonically (phonetically distinct variants of a single phonemic category). On both accounts, mismatch between phonological categories and orthography leads to reading difficulty. Here, we consider the implications of these accounts for online speech processing. We used eye tracking and an individual differences approach to assess sensitivity to subphonemic detail in a community sample of young adults with a wide range of reading-related skills. Subphonemic sensitivity inversely correlated with meta-phonological task performance, consistent with overspecification.
C1 [Li, Monica Y. C.; Tabor, Whitney; Shankweiler, Donald P.; Pugh, Kenneth R.; Magnuson, James S.] Univ Connecticut, Dept Psychol Sci, Storrs, CT 06269 USA.
   [Li, Monica Y. C.; Braze, David; Tabor, Whitney; Van Dyke, Julie A.; Pugh, Kenneth R.; Magnuson, James S.] Univ Connecticut, Connecticut Inst Brain & Cognit Sci, Storrs, CT 06269 USA.
   [Li, Monica Y. C.; Pugh, Kenneth R.; Magnuson, James S.] Univ Connecticut, Brain Imaging Res Ctr, Storrs, CT 06269 USA.
   [Li, Monica Y. C.; Braze, David; Kukona, Anuenue; Johns, Clinton L.; Tabor, Whitney; Van Dyke, Julie A.; Mencl, W. Einar; Shankweiler, Donald P.; Pugh, Kenneth R.; Magnuson, James S.] Haskins Labs Inc, 300 George St, New Haven, CT 06510 USA.
   [Kukona, Anuenue] De Montfort Univ, Sch Appl Social Sci, Leicester LE1 9BH, Leics, England.
   [Pugh, Kenneth R.] Yale Univ, Dept Linguist, New Haven, CT 06520 USA.
RP Li, MYC (corresponding author), Univ Connecticut, Dept Psychol Sci, Storrs, CT 06269 USA.
EM monica.li@uconn.edu
RI ; Van Dyke, Julie/I-4767-2017
OI Magnuson, James/0000-0003-0158-2367; Kukona,
   Anuenue/0000-0003-4377-3057; Van Dyke, Julie/0000-0002-5542-018X
FU US National Institutes of HealthUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USA [R01 HD40353,
   R01 HD071988]; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH
   & HUMAN DEVELOPMENTUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [R01HD071988] Funding Source: NIH RePORTER
FX The data and analysis code of the current study are available at
   https://osf.io/6rd2u/files/. A preliminary report of the current study
   was reported by Magnuson et al. (2011). Magnuson et al. (2011)
   summarized trends from a small preliminary subset of the eye tracking
   data presented here (n = 32, about half of the full sample), and did not
   consider the individual differences that are our focus in this full
   report. We thank Joshua Coppola and Erica Davis for their help with this
   project. This work was supported by US National Institutes of Health
   [grant numbers R01 HD40353, R01 HD071988] to Haskins Laboratories.
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Altmann GTM, 2009, COGNITION, V111, P55, DOI 10.1016/j.cognition.2008.12.005
   Anthony JL, 2010, READ WRIT, V23, P969, DOI 10.1007/s11145-009-9185-7
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   BLACHMAN BA, 1984, J EDUC PSYCHOL, V76, P610, DOI 10.1037/0022-0663.76.4.610
   Bogliotti C, 2008, J EXP CHILD PSYCHOL, V101, P137, DOI 10.1016/j.jecp.2008.03.006
   BOX GEP, 1964, J ROY STAT SOC B, V26, P211, DOI 10.1111/j.2517-6161.1964.tb00553.x
   Brady SA, 2011, NEW DIR COMMUN D RES, P69
   Braze D, 2007, J LEARN DISABIL-US, V40, P226, DOI 10.1177/00222194070400030401
   Braze D, 2016, READ WRIT, V29, P435, DOI 10.1007/s11145-015-9608-6
   BRUCK M, 1992, DEV PSYCHOL, V28, P874, DOI 10.1037/0012-1649.28.5.874
   BYRNE B, 1991, J EDUC PSYCHOL, V83, P451, DOI 10.1037/0022-0663.83.4.451
   Catts HW, 2017, READ WRIT, V30, P613, DOI 10.1007/s11145-016-9692-2
   Catts HW, 2011, NEW DIR COMMUN D RES, P137
   Chambers CG, 2004, J EXP PSYCHOL LEARN, V30, P687, DOI 10.1037/0278-7393.30.3.687
   Clark NB, 2012, CLIN LINGUIST PHONET, V26, P577, DOI 10.3109/02699206.2012.673045
   CORKIN S, 1974, NEUROPSYCHOLOGIA, V12, P347, DOI 10.1016/0028-3932(74)90050-5
   Cross AM, 2018, LANG COGN NEUROSCI, V33, P1315, DOI 10.1080/23273798.2018.1484148
   Dahan D, 2001, LANG COGNITIVE PROC, V16, P507, DOI 10.1080/01690960143000074
   DANEMAN M, 1980, J VERB LEARN VERB BE, V19, P450, DOI 10.1016/S0022-5371(80)90312-6
   Desroches AS, 2006, COGNITION, V100, pB32, DOI 10.1016/j.cognition.2005.09.001
   Dunn L. M., 1997, PEABODY PICTURE VOCA
   Elbro C, 1998, READ RES QUART, V33, P36, DOI 10.1598/RRQ.33.1.3
   Elbro C, 1998, SCAND J PSYCHOL, V39, P149, DOI 10.1111/1467-9450.393070
   Elliott Julian, 2014, THE DYSLEXIA DEBATE
   Elwer A, 2015, SCAND J PSYCHOL, V56, P157, DOI 10.1111/sjop.12188
   Engelhardt PE, 2006, J MEM LANG, V54, P554, DOI 10.1016/j.jml.2005.12.009
   Fischer B., 1992, EYE MOVEMENTS VISUAL, P31
   Fox J., 2011, R COMPANION APPL REG
   Frost R, 1998, PSYCHOL BULL, V123, P71, DOI 10.1037/0033-2909.123.1.71
   Frost SJ, 2009, ANN DYSLEXIA, V59, P78, DOI 10.1007/s11881-009-0024-y
   Gabay Y, 2015, CORTEX, V73, P131, DOI 10.1016/j.cortex.2015.08.008
   Gallagher A, 2000, J CHILD PSYCHOL PSYC, V41, P203, DOI 10.1111/1469-7610.00601
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   GOSWAMI U, 1989, J READING BEHAV, V21, P413, DOI 10.1080/10862968909547687
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Gow DW, 2008, NEUROIMAGE, V43, P614, DOI 10.1016/j.neuroimage.2008.07.027
   Guttorm TK, 2003, J NEURAL TRANSM, V110, P1059, DOI 10.1007/s00702-003-0014-x
   Guttorm TK, 2005, CORTEX, V41, P291, DOI 10.1016/S0010-9452(08)70267-3
   Hancock R, 2017, TRENDS COGN SCI, V21, P434, DOI 10.1016/j.tics.2017.03.008
   Harm MW, 1999, PSYCHOL REV, V106, P491, DOI 10.1037/0033-295X.106.3.491
   Hoonhorst I, 2009, J EXP CHILD PSYCHOL, V104, P353, DOI 10.1016/j.jecp.2009.07.005
   Huettig F, 2005, COGNITION, V96, pB23, DOI 10.1016/j.cognition.2004.10.003
   Johns CL, 2018, LANG COGN NEUROSCI, V33, P1275, DOI 10.1080/23273798.2018.1476727
   Johns CL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01552
   Kaiser E, 2009, COGNITION, V112, P55, DOI 10.1016/j.cognition.2009.03.010
   KARLSON B, 1995, STANFORD DIAGNOSTIC
   Katz L, 2012, READ WRIT, V25, P1259, DOI 10.1007/s11145-011-9316-9
   Kieffer MJ, 2016, SCI STUD READ, V20, P436, DOI 10.1080/10888438.2016.1214591
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Kukona A, 2016, ACTA PSYCHOL, V171, P72, DOI 10.1016/j.actpsy.2016.09.009
   Lehongre K, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00454
   Lehongre K, 2011, NEURON, V72, P1080, DOI 10.1016/j.neuron.2011.11.002
   Leonard MK, 2014, TRENDS COGN SCI, V18, P472, DOI 10.1016/j.tics.2014.05.001
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Liberman I.Y., 1973, B ORTON SOC, V23, P64, DOI [10.1007/BF02653842, DOI 10.1007/BF02653842, https://doi.org/10.1007/bf02653842]
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Luce P. A., 1986, THESIS
   Lyytinen H, 2004, ANN DYSLEXIA, V54, P184, DOI 10.1007/s11881-004-0010-3
   MacGinitie W.H., 2000, GATES MACGINITIE REA
   Magnuson J. S., 2011, DYSLEXIA LANGUAGES O, P184
   Magnuson JS, 2008, COGNITION, V108, P866, DOI 10.1016/j.cognition.2008.06.005
   Magnuson JS, 2007, COGNITIVE SCI, V31, P133, DOI 10.1080/03640210709336987
   Magnuson JS, 2003, J EXP PSYCHOL GEN, V132, P202, DOI 10.1037/0096-3445.132.2.202
   Maisog JM, 2008, ANN NY ACAD SCI, V1145, P237, DOI 10.1196/annals.1416.024
   Markwardt F. C., 1989, PEABODY INDIVIDUAL A
   MARSLENWILSON W, 1994, PSYCHOL REV, V101, P653, DOI 10.1037/0033-295X.101.4.653
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MCDOUGALL S, 1994, J EXP CHILD PSYCHOL, V58, P112, DOI 10.1006/jecp.1994.1028
   McMurray B, 2014, J SPEECH LANG HEAR R, V57, P1344, DOI 10.1044/2014_JSLHR-L-13-0196
   McMurray B, 2008, J EXP PSYCHOL HUMAN, V34, P1609, DOI 10.1037/a0011747
   Mirman D., 2014, GROWTH CURVE ANAL VI
   Mirman D, 2008, J MEM LANG, V59, P475, DOI 10.1016/j.jml.2007.11.006
   Molfese DL, 2000, BRAIN LANG, V72, P238, DOI 10.1006/brln.2000.2287
   Molfese DL, 1997, DEV NEUROPSYCHOL, V13, P135, DOI 10.1080/87565649709540674
   Molfese VJ, 2001, J LEARN DISABIL-US, V34, P545, DOI 10.1177/002221940103400607
   Myers EB, 2008, CEREB CORTEX, V18, P278, DOI 10.1093/cercor/bhm053
   Noordenbos MW, 2012, NEUROPSYCHOLOGIA, V50, P2010, DOI 10.1016/j.neuropsychologia.2012.04.026
   Noordenbos MW, 2012, RES DEV DISABIL, V33, P1469, DOI 10.1016/j.ridd.2012.03.021
   Noordenbos MW, 2013, CLIN NEUROPHYSIOL, V124, P1151, DOI 10.1016/j.clinph.2012.12.044
   O'Brien GE, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34823-8
   Paulesu E, 2001, SCIENCE, V291, P2165, DOI 10.1126/science.1057179
   Pennington BF, 2006, COGNITION, V101, P385, DOI 10.1016/j.cognition.2006.04.008
   Perfetti C, 2007, SCI STUD READ, V11, P357, DOI 10.1080/10888430701530730
   Preston JL, 2016, PSYCHOL SCI, V27, P75, DOI 10.1177/0956797615611921
   Pugh KR, 2014, J NEUROSCI, V34, P4082, DOI 10.1523/JNEUROSCI.3907-13.2014
   Puolakanaho A, 2007, J CHILD PSYCHOL PSYC, V48, P923, DOI 10.1111/j.1469-7610.2007.01763.x
   R Core Team, 2018, R LANG ENV STAT COMP
   Ramus F, 2003, CURR OPIN NEUROBIOL, V13, P212, DOI 10.1016/S0959-4388(03)00035-7
   Ramus F, 2013, BRAIN, V136, P630, DOI 10.1093/brain/aws356
   Robertson EK, 2009, DEVELOPMENTAL SCI, V12, P753, DOI 10.1111/j.1467-7687.2009.00806.x
   SCARBOROUGH HS, 1989, J EDUC PSYCHOL, V81, P101
   Serniclaes W, 2001, J SPEECH LANG HEAR R, V44, P384, DOI 10.1044/1092-4388(2001/032)
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   Serniclaes W, 2006, WRIT LANG LIT, V9, P135, DOI 10.1075/wll.9.1.09ser
   SHANKWEILER D, 1979, J EXP PSYCHOL-HUM L, V5, P531, DOI 10.1037/0278-7393.5.6.531
   Shankweiler D, 2008, DEV NEUROPSYCHOL, V33, P745, DOI 10.1080/87565640802418688
   Simos PG, 2002, NEUROLOGY, V58, P1203, DOI 10.1212/WNL.58.8.1203
   Snowling MJ, 2008, Q J EXP PSYCHOL, V61, P142, DOI 10.1080/17470210701508830
   Snowling MJ, 2006, TOP LANG DISORD, V26, P110, DOI 10.1097/00011363-200604000-00004
   Snowling MJ, 2003, CHILD DEV, V74, P358, DOI 10.1111/1467-8624.7402003
   STANOVICH KE, 1992, MEM COGNITION, V20, P51, DOI 10.3758/BF03208254
   STANOVICH KE, 1988, J LEARN DISABIL-US, V21, P590, DOI 10.1177/002221948802101003
   Steinbrink C, 2008, NEUROPSYCHOLOGIA, V46, P3170, DOI 10.1016/j.neuropsychologia.2008.07.015
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Tallal P, 1998, EXP BRAIN RES, V123, P210, DOI 10.1007/s002210050563
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Torgesen J. K., 1999, TESTS WORD READING E
   Tunmer WE, 2012, SCI STUD READ, V16, P122, DOI 10.1080/10888438.2010.542527
   van Buuren S, 2011, J STAT SOFTW, V45, P1
   Van Dyke JA, 2014, COGNITION, V131, P373, DOI 10.1016/j.cognition.2014.01.007
   Vandermosten M, 2010, P NATL ACAD SCI USA, V107, P10389, DOI 10.1073/pnas.0912858107
   Venables WN, 2002, MODERN APPL STAT S 4
   Venezky R.L., 1999, AM WAY SPELLING STRU
   Viviani P, 1990, Rev Oculomot Res, V4, P353
   Wagner R, 1999, COMPREHENSIVE TEST P
   Wechsler D, 1999, WASI WECHSLER ABBREV
   Wiederholt J.L., 2001, GRAY ORAL READING TE
   Wolf M, 1999, J EDUC PSYCHOL, V91, P415, DOI 10.1037/0022-0663.91.3.415
   Woodcock R. W., 2001, WOODCOCKJOHNSON 3 TE
NR 120
TC 2
Z9 2
U1 1
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0749-596X
EI 1096-0821
J9 J MEM LANG
JI J. Mem. Lang.
PD AUG
PY 2019
VL 107
BP 195
EP 215
DI 10.1016/j.jml.2019.03.008
PG 21
WC Linguistics; Psychology; Psychology, Experimental
SC Linguistics; Psychology
GA IF1BV
UT WOS:000472813000012
PM 31431796
OA Green Accepted, Other Gold
DA 2021-02-24
ER

PT J
AU Chang, CHC
   Lin, TH
   Kuo, WJ
AF Chang, Claire H. C.
   Lin, Tzu-Hui
   Kuo, Wen-Jui
TI Does phonological rule of tone substitution modulate mismatch
   negativity?
SO JOURNAL OF NEUROLINGUISTICS
LA English
DT Article
DE Mismatch negativity; Phonological rule; Lexical tone; Mandarin;
   Taiwanese; Sandhi
ID MANDARIN LEXICAL TONES; SPEECH-PERCEPTION; RESPONSES; ASSIMILATION;
   ENGLISH; SANDHI
AB This study examined whether the phonological substitution rule of tone sandhi modulates tone perception in the preattentive stage. Tone sandhi is commonly present in East Asian languages. An example from Mandarin is the Tone tone 3 sandhi rule: T3 is pronounced as T2 when followed by another T3 (33 -> 23). Previous mismatch negativity (MMN) studies in Mandarin have reported a smaller amplitude or longer latency in standard-deviant pair consisting of T2 and T3 (T2-T3) than in Tl-T3. The most widely accepted explanation for this is that T2 and T3 have steeper pitch slopes than Tl. This study tested an alternative account based on the phonological rule that the frequent substitution that occurs between T2 and T3 results in reduced MMN. In Experiment 1, we first tried to replicate the finding in Mandarin. In Experiment 2, using both unskilled and skilled speakers, we tested a sandhi tone pair of very different pitch slopes in Taiwanese. Delayed peak latency of sandhi pair was evident in both languages but only in skilled speakers. Our results did not support the shared-pitch-slope account and were instead consistent with the argument that a language-specific phonological rule could modulate preattentive tone processing.
C1 [Chang, Claire H. C.; Lin, Tzu-Hui; Kuo, Wen-Jui] Natl Yang Ming Univ, Inst Neurosci, Taipei, Taiwan.
   [Kuo, Wen-Jui] Natl Yang Ming Univ, Brain Res Ctr, Taipei, Taiwan.
RP Kuo, WJ (corresponding author), Natl Yang Ming Univ, Room 805,8F Lib,Informat & Res Bldg,155,Sec 2, Taipei 112, Taiwan.
EM wjkuo@ym.edu.tw
OI CHANG, CLAIRE HUI-CHUAN/0000-0002-3773-1777
FU Ministry of Science and Technology, TaiwanMinistry of Science and
   Technology, Taiwan [104-2410-H-010 -003 -MY2, 106-2420-H-010 -002 -MY2,
   107-2410-H-010-006-]; Brain Research Center, National Yang-Ming
   University
FX This work was partly supported by the Ministry of Science and
   Technology, Taiwan (104-2410-H-010 -003 -MY2, 106-2420-H-010 -002 -MY2,
   107-2410-H-010-006-) and the Brain Research Center, National Yang-Ming
   University.
CR ANDERSON SR, 1981, LINGUIST INQ, V12, P493
   Archangeli D., 1988, PHONOLOGY, V5, DOI [DOI 10.1017/S0952675700002268, 10.1017/S0952675700002268]
   Blevins J, 2006, THEOR LINGUIST, V32, P117, DOI 10.1515/TL.2006.009
   Boersma P., 2007, PRAAT DOING PHONETIC
   Chandrasekaran B, 2007, RESTOR NEUROL NEUROS, V25, P195
   Chandrasekaran B, 2007, NEUROREPORT, V18, P1963, DOI 10.1097/WNR.0b013e3282f213c5
   Chandrasekaran B, 2007, BRAIN RES, V1128, P148, DOI 10.1016/j.brainres.2006.10.064
   Chang C. Y., 2010, DIALECT DIFFERENCES
   Chao Y. R., 1948, MANDARIN PRIMER, DOI [10.4159/harvard.9780674732889, DOI 10.4159/HARVARD.9780674732889]
   Chen A, 2016, LANG COGN NEUROSCI, V31, P751, DOI 10.1080/23273798.2016.1156715
   Chen A, 2015, LANG SCI, V48, P62, DOI 10.1016/j.langsci.2014.12.002
   Chen Matthew Y., 2000, TONE SANDHI PATTERNS
   Cheng YY, 2013, DEV NEUROPSYCHOL, V38, P281, DOI 10.1080/87565641.2013.799672
   Cornell S. A., 2008, BEHAV BRAIN SCI, V31, P79, DOI [10.1017/S0140525X08004998, DOI 10.1017/S0140525X08004998]
   Eulitz C, 2004, J COGNITIVE NEUROSCI, V16, P577, DOI 10.1162/089892904323057308
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   GANDOUR J, 1984, J CHINESE LINGUIST, V12, P235
   GANDOUR JT, 1978, LANG SPEECH, V21, P1, DOI 10.1177/002383097802100101
   Hao YC, 2018, LANG SPEECH, V61, P135, DOI 10.1177/0023830917717759
   Hsieh H., 1975, TRANSFORMATIONAL GEN, P109
   Hsieh H., 1970, 6TH REG M CHIC LING, V6, P489
   HSIEH HI, 1976, LINGUA, V38, P1, DOI 10.1016/0024-3841(76)90038-3
   Hsu CH, 2014, BRAIN RES, V1582, P154, DOI 10.1016/j.brainres.2014.07.023
   Huang T, 2010, PHONETICA, V67, P243, DOI 10.1159/000327392
   Hyman L. L. M, 2011, TONE IS IT DIFFERENT, DOI [10.1002/9781444343069.ch7, DOI 10.1002/9781444343069.CH7]
   Jongman A, 2017, J ACOUST SOC AM, V142, pEL163, DOI 10.1121/1.4995526
   Lai Y, 2007, KANSAS WORKING PAPER, V29, P33
   Lawrence MA, 2013, EASY ANAL VISUALIZAT
   Li A., 2006, P 5 INT S CHIN SPOK, P157
   Li X, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0122884
   Maddieson Ian, 2013, WORLD ATLAS LANGUAGE
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Meyers James, 2008, INTERFACES CHINESE P, P47, DOI DOI 10.1002/HBM.21191
   Mitterer H, 2003, PERCEPT PSYCHOPHYS, V65, P956, DOI 10.3758/BF03194826
   Mitterer H, 2006, COGNITIVE SCI, V30, P451, DOI 10.1207/s15516709cog0000_57
   Myers J, 1996, P ANN M BERK LING SO
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   National Languages Committee, 2011, ONL PRACT DICT TAIW
   OHALA JJ, 1993, LANG SPEECH, V36, P155, DOI 10.1177/002383099303600303
   Peng SH, 1997, J PHONETICS, V25, P371, DOI 10.1006/jpho.1997.0047
   Politzer-Ahles S, 2016, J EXP PSYCHOL HUMAN, V42, P1547, DOI 10.1037/xhp0000242
   R Development Core Team, 2007, COMPUTATIONAL MANY P, V1, DOI [10.1007/978-3-540-74686-7, DOI 10.1007/978-3-540-74686-7]
   Scharinger M, 2016, NEUROIMAGE, V128, P293, DOI 10.1016/j.neuroimage.2016.01.003
   Shen X. S., 1992, ACTA LINGUIST HAFNIE, V25, P83, DOI [10.1080/03740463.1992.10412279, DOI 10.1080/03740463.1992.10412279]
   Shih C, 2008, INTERFACES CHINESE P, V0623805, P99
   So CK, 2014, STUD SECOND LANG ACQ, V36, P195, DOI 10.1017/S0272263114000047
   Speer S. R., 2016, PROSODIC STRUCTURE L, DOI [10.1177/002383098903200403, DOI 10.1177/002383098903200403]
   SPEER SR, 1989, LANG SPEECH, V32, P337, DOI 10.1177/002383098903200403
   Sun Y, 2015, BRAIN LANG, V149, P55, DOI 10.1016/j.bandl.2015.06.009
   Tavabi K, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004452
   Wang H.S., 1993, TSINGHUA XUEBAO, V23, P175
   Xi L., 2016, P 5 INT S TON ASP LA, P33
   Xu Y., 2004, LANGUAGE LINGUISTICS, V5, P757
   Yan HB, 2016, INT J CHIN LINGUIST, V3, P1, DOI 10.1075/ijchl.3.1.01yan
   Yu YH, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00095
   Zhang C., 2013, EASTWARD FLOWS GREAT, P256
   Zhang J, 2010, PHONOLOGY, V27, P153, DOI 10.1017/S0952675710000060
NR 57
TC 0
Z9 0
U1 1
U2 5
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0911-6044
J9 J NEUROLINGUIST
JI J. Neurolinguist.
PD AUG
PY 2019
VL 51
BP 63
EP 75
DI 10.1016/j.jneuroling.2019.01.001
PG 13
WC Linguistics; Neurosciences; Psychology, Experimental
SC Linguistics; Neurosciences & Neurology; Psychology
GA IC8FC
UT WOS:000471210700005
DA 2021-02-24
ER

PT J
AU Li, WJ
   Zhang, H
   Zheng, ZL
   Li, XQ
AF Li, Weijun
   Zhang, Hang
   Zheng, Zilong
   Li, Xiaoqing
TI Prosodic phrase priming during listening to Chinese ambiguous phrases in
   different experimental tasks
SO JOURNAL OF NEUROLINGUISTICS
LA English
DT Article
DE Prosodic boundary; Priming; Ambiguous phrase comprehension; Closure
   Positive Shift
ID WORD REPETITION; SENTENCE COMPREHENSION; SYNTACTIC PERSISTENCE;
   SPEECH-PERCEPTION; SPOKEN LANGUAGE; BOUNDARIES; REPRESENTATIONS;
   COREFERENCE; ATTACHMENT; DISCOURSE
AB Using the structural priming paradigm, the present study investigates prosodic phrase priming with ERPs (event-related potentials). Participants listened to 2 consecutive Chinese ambiguous phrases that can be analyzed as a modifier-noun construction or as a narrative-object structure in both lexical judgment and structural judgment tasks. The results indicated that prosodic boundaries embedded in ambiguous phrases stably elicited the Closure Positive Shift (CPS). More importantly, the prosodic priming effect occurs, as evidenced by the fact that the amplitude of the CPS elicited by the target phrases was lower than that of the CPS elicited by the prime phrases. In addition, the priming effect was stronger in the structural judgment task than in the lexical judgment task. This result may suggest that prosodic priming was facilitated when the listener's attention was directed to the prosodic aspect and that under such circumstances listeners process the prosodic boundary deeply. In conclusion, prosodic phrase structures are formulated in the brain and modulate the processing of the immediately subsequent item during speech comprehension, and this process is influenced by the type of task being performed.
C1 [Li, Weijun; Zhang, Hang; Zheng, Zilong] Liaoning Normal Univ, Res Ctr Brain & Cognit Neurosci, Huanghe Rd 850, Dalian 116029, Peoples R China.
   [Li, Weijun; Li, Xiaoqing] Chinese Acad Sci, Inst Psychol, Key Lab Behav Sci, Lincui Rd 16, Beijing 100101, Peoples R China.
   [Li, Xiaoqing] Univ Chinese Acad Sci, Dept Psychol, Beijing, Peoples R China.
RP Li, WJ (corresponding author), Liaoning Normal Univ, Res Ctr Brain & Cognit Neurosci, Huanghe Rd 850, Dalian 116029, Peoples R China.; Li, XQ (corresponding author), Chinese Acad Sci, Inst Psychol, Key Lab Behav Sci, Lincui Rd 16, Beijing 100101, Peoples R China.
EM li_wj@126.com; lixq@psych.ac.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [31000505, 31471075]; Ministry of Education
   Humanities and Social Science Fund [17YJC190013]; Open Research Fund of
   the CAS Key Laboratory of Behavioral Science, Institute of Psychology
FX This research was supported by National Natural Science Foundation of
   China (grant numbers 31000505, 31471075), Ministry of Education
   Humanities and Social Science Fund (17YJC190013), and Open Research Fund
   of the CAS Key Laboratory of Behavioral Science, Institute of
   Psychology.
CR Anderson JE, 2005, BRAIN LANG, V94, P200, DOI 10.1016/j.bandl.2005.01.001
   Arai M, 2007, COGNITIVE PSYCHOL, V54, P218, DOI 10.1016/j.cogpsych.2006.07.001
   Bever TG, 2010, BIOLINGUISTICS, V4, P174
   BOCK JK, 1986, COGNITIVE PSYCHOL, V18, P355, DOI 10.1016/0010-0285(86)90004-6
   Boudewyn MA, 2014, Q J EXP PSYCHOL, V67, P424, DOI 10.1080/17470218.2013.815237
   Branigan HP, 2005, J EXP PSYCHOL LEARN, V31, P468, DOI 10.1037/0278-7393.31.3.468
   Branigan HP, 2000, MEM COGNITION, V28, P1297, DOI 10.3758/BF03211830
   Camblin CC, 2007, BRAIN RES, V1146, P172, DOI 10.1016/j.brainres.2006.07.033
   Chen QR, 2013, BRAIN COGNITION, V83, P142, DOI 10.1016/j.bandc.2013.07.005
   Cutler A, 1997, LANG SPEECH, V40, P141, DOI 10.1177/002383099704000203
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   Garrod S, 2004, TRENDS COGN SCI, V8, P8, DOI 10.1016/j.tics.2003.10.016
   Giles H., 1991, CONTEXTS ACCOMMODATI, P1, DOI [10.1017/CBO9780511663673.001, DOI 10.1017/CBO9780511663673.001]
   Hahne A, 2002, COGNITIVE BRAIN RES, V13, P339, DOI 10.1016/S0926-6410(01)00127-6
   Hale J, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P159
   Halle M, 1959, P SEM SPEECH COMPR P
   Hirschberg J, 2011, EXP THEOR ADV PROS 2, V2
   Holzgrefe J, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00421
   Honbolygo F, 2016, J NEUROLINGUIST, V37, P22, DOI 10.1016/j.jneuroling.2015.08.001
   Hupp JM, 2009, BRIT J DEV PSYCHOL, V27, P495, DOI 10.1348/026151008X345988
   Jaeger T. F., 2008, P 29 ANN COGN SCI SO, P1061
   Jaeger TF, 2013, COGNITION, V127, P57, DOI 10.1016/j.cognition.2012.10.013
   Jun SA, 2015, STUD THEOR PSYCHOLIN, V46, P217, DOI 10.1007/978-3-319-12961-7_12
   Jun SA, 2015, LANG SPEECH, V58, P459, DOI 10.1177/0023830914563368
   Jungers M, 2009, LANG COGNITIVE PROC, V24, P611, DOI 10.1080/01690960802602241
   Kerkhofs R, 2007, J COGNITIVE NEUROSCI, V19, P1421, DOI 10.1162/jocn.2007.19.9.1421
   Kutas M, 2000, TRENDS COGN SCI, V4, P463, DOI 10.1016/S1364-6613(00)01560-6
   Ledoux K, 2007, PSYCHOL SCI, V18, P135, DOI 10.1111/j.1467-9280.2007.01863.x
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006
   Li W, 2010, NEUROSCIENCE, V168, P757, DOI 10.1016/j.neuroscience.2010.03.069
   Li W, 2009, NEUROSCIENCE, V158, P1416, DOI 10.1016/j.neuroscience.2008.10.065
   Li XQ, 2010, BIOL PSYCHOL, V83, P250, DOI 10.1016/j.biopsycho.2010.01.009
   Loebell H, 2003, LINGUISTICS, V41, P791, DOI 10.1515/ling.2003.026
   Mari-Beffa P, 2005, COGNITIVE BRAIN RES, V23, P293, DOI 10.1016/j.cogbrainres.2004.10.016
   Mari-Beffa P, 2000, MEM COGNITION, V28, P635, DOI 10.3758/BF03201253
   Maxfield L, 1997, CONSCIOUS COGN, V6, P204, DOI 10.1006/ccog.1997.0311
   MEYER DE, 1971, J EXP PSYCHOL, V90, P227, DOI 10.1037/h0031564
   Nan Y, 2006, BRAIN RES, V1094, P179, DOI 10.1016/j.brainres.2006.03.115
   Neumann R, 2000, J PERS SOC PSYCHOL, V79, P211, DOI 10.1037//0022-3514.79.2.211
   Pannekamp A, 2005, J COGNITIVE NEUROSCI, V17, P407, DOI 10.1162/0898929053279450
   Pauker E, 2011, J COGNITIVE NEUROSCI, V23, P2731, DOI 10.1162/jocn.2011.21610
   Peter V, 2014, BMC NEUROSCI, V15, DOI 10.1186/s12868-014-0129-z
   Pickering MJ, 2008, PSYCHOL BULL, V134, P427, DOI 10.1037/0033-2909.134.3.427
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169
   Pickering MJ, 1998, J MEM LANG, V39, P633, DOI 10.1006/jmla.1998.2592
   Poeppel D, 2008, PHILOS T R SOC B, V363, P1071, DOI 10.1098/rstb.2007.2160
   Poeppel D, 2011, LANG COGNITIVE PROC, V26, P935, DOI 10.1080/01690965.2010.493301
   Reitter D, 2011, COGNITIVE SCI, V35, P587, DOI 10.1111/j.1551-6709.2010.01165.x
   RUGG MD, 1985, PSYCHOPHYSIOLOGY, V22, P642, DOI 10.1111/j.1469-8986.1985.tb01661.x
   Savage C, 2003, DEVELOPMENTAL SCI, V6, P557, DOI 10.1111/1467-7687.00312
   Scheepers C, 2017, J MEM LANG, V95, P102, DOI 10.1016/j.jml.2017.03.001
   Speer S, 2015, STUDIES THEORETICAL, V46
   Steinhauer K, 1999, NAT NEUROSCI, V2, P191, DOI 10.1038/5757
   Steinhauer K, 2003, BRAIN LANG, V86, P142, DOI 10.1016/S0093-934X(02)00542-4
   Steinhauer K, 2001, J PSYCHOLINGUIST RES, V30, P267, DOI 10.1023/A:1010443001646
   STEVENS KN, 1967, MODELS PERCEPTION SP
   Summerfield C, 2006, SCIENCE, V314, P1311, DOI 10.1126/science.1132028
   Thothathiri M, 2008, COGNITION, V108, P51, DOI 10.1016/j.cognition.2007.12.012
   Thothathiri M, 2008, J MEM LANG, V58, P188, DOI 10.1016/j.jml.2007.06.012
   Tooley KM, 2018, MEM COGNITION, V46, P625, DOI 10.3758/s13421-018-0789-5
   Tooley KM, 2014, J EXP PSYCHOL LEARN, V40, P348, DOI 10.1037/a0034900
   Tooley KM, 2009, J EXP PSYCHOL LEARN, V35, P19, DOI 10.1037/a0013984
   Townsend D.J., 2001, SENTENCE COMPREHENSI
   Traxler MJ, 2008, LANG COGNITIVE PROC, V23, P609, DOI 10.1080/01690960701639898
   Traxler MJ, 2008, PSYCHON B REV, V15, P149, DOI 10.3758/PBR.15.1.149
   TRAXLER MJ, 2005, CUNY SENT PROC C TUC
   VANPETTEN C, 1991, J COGNITIVE NEUROSCI, V3, P131, DOI 10.1162/jocn.1991.3.2.131
   Wagner M, 2010, LANG COGNITIVE PROC, V25, P905, DOI 10.1080/01690961003589492
   WANG L, 2005, CHINESE PROSODY
   Wei H., 2016, FRONT PLANT SCI, V7, P1, DOI DOI 10.3389/fpls.2016.01806
   Xu Y, 2018, COGNITION, V170, P147, DOI 10.1016/j.cognition.2017.09.018
   Zhang JJ, 2016, NEUROPSYCHOLOGIA, V91, P490, DOI 10.1016/j.neuropsychologia.2016.09.013
   Zhang YX, 2000, CHINESE J PSYCHOL, V32, DOI 10.3724/SP.J.1041.2018.01323
   Zhu D, 1980, STUDIES MODERN CHINE
NR 77
TC 0
Z9 0
U1 1
U2 6
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0911-6044
J9 J NEUROLINGUIST
JI J. Neurolinguist.
PD AUG
PY 2019
VL 51
BP 135
EP 150
DI 10.1016/j.jneuroling.2019.02.003
PG 16
WC Linguistics; Neurosciences; Psychology, Experimental
SC Linguistics; Neurosciences & Neurology; Psychology
GA IC8FC
UT WOS:000471210700011
DA 2021-02-24
ER

PT J
AU Perez, A
   Dunabeitia, JA
AF Perez, Alejandro
   Andoni Dunabeitia, Jon
TI Speech perception in bilingual contexts: Neuropsychological impact of
   mixing languages at the inter-sentential level
SO JOURNAL OF NEUROLINGUISTICS
LA English
DT Article
DE Bilingualism; Speech perception; Codeswitch; Language mixing; EEG
ID VOLUNTARY LANGUAGE; OSCILLATIONS; DYNAMICS; THETA; ENTRAINMENT;
   RETRIEVAL; RESPONSES; TRACKING
AB The neuropsychological impact of processing naturalistic speech streams containing code switches at the inter-sentential level was studied in fluent bilinguals who frequently switch between languages. To this end, electroencephalographic recordings (EEG) and a behavioral recall test were used to address speech perception while processing pieces of information conveyed in a single- or mixed-language speech carrier. Measurements of spectral power in the continuous EEG signal accompanying perception of speech were directly compared between conditions. The direction of the switch was also assessed. Our principal finding was a reduced oscillatory power in the beta frequencies when bilinguals are attentively listening to informative speech streams in which the two known languages are intermixed. The memory recall test showed equivalent performance across the different language conditions. These results suggest that the cognitive cost of processing speech containing inter-sentential language switches is reflected at a neural level but that it has no measurable impact on the recall of long steams of information. Listening speech in which the two languages known to a bilingual are mixed at a sentence level, may have no clear behavioral drawback, but implies some neural processing cost.
C1 [Perez, Alejandro] Univ Toronto, Ctr French & Linguist, Toronto, ON M1C 1A4, Canada.
   [Perez, Alejandro] Univ Toronto, Dept Psychol, Toronto, ON M1C 1A4, Canada.
   [Andoni Dunabeitia, Jon] Univ Nebrija, Fac Lenguas & Educ, Madrid 28015, Spain.
RP Perez, A (corresponding author), Univ Toronto, Ctr French & Linguist, Toronto, ON M1C 1A4, Canada.; Perez, A (corresponding author), 1265 Mil Trail, Toronto, ON M1C 1A4, Canada.
EM alejandro.perez@utoronto.ca
RI Dunabeitia, Jon Andoni/C-8503-2014; Perez, Alejandro/H-2202-2015
OI Dunabeitia, Jon Andoni/0000-0002-3312-8559; Perez,
   Alejandro/0000-0001-6631-9653
FU Spanish GovernmentSpanish GovernmentEuropean Commission
   [PSI2015-65689-P]; European UnionEuropean Commission [AThEME-613465];
   Social Sciences and Humanities Research Council (SSHRC) of CanadaSocial
   Sciences and Humanities Research Council of Canada (SSHRC) [IDG
   430-15-00647]; Natural Sciences and Engineering Council (NSERC) of
   CanadaNatural Sciences and Engineering Research Council of Canada
   (NSERC) [RGPIN-2017-06053]
FX This work was supported by the Spanish Government [grant
   PSI2015-65689-P], the European Union [grant AThEME-613465], the Social
   Sciences and Humanities Research Council (SSHRC) of Canada (IDG
   430-15-00647) and the Natural Sciences and Engineering Council (NSERC)
   of Canada (RGPIN-2017-06053) to Philip J. Monahan.
CR Anton E, 2016, LANG LEARN, V66, P29, DOI 10.1111/lang.12173
   Anton E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130069
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Arnal LH, 2011, NAT NEUROSCI, V14, P797, DOI 10.1038/nn.2810
   Bakker I, 2015, J COGNITIVE NEUROSCI, V27, P1286, DOI 10.1162/jocn_a_00801
   Bastiaansen M, 2006, PROG BRAIN RES, V159, P179, DOI 10.1016/S0079-6123(06)59012-0
   Bastiaansen M, 2015, J COGNITIVE NEUROSCI, V27, P2095, DOI 10.1162/jocn_a_00829
   Bastiaansen MCM, 2008, BRAIN LANG, V106, P15, DOI 10.1016/j.bandl.2007.10.006
   Bastiaansen MCM, 2005, J COGNITIVE NEUROSCI, V17, P530, DOI 10.1162/0898929053279469
   Bigdely-Shamlo N, 2015, FRONT NEUROINFORM, V9, DOI 10.3389/fninf.2015.00016
   Branzi FM, 2014, NEUROPSYCHOLOGIA, V52, P102, DOI 10.1016/j.neuropsychologia.2013.09.022
   Bultena S, 2015, LANG COGN NEUROSCI, V30, P586, DOI 10.1080/23273798.2014.964268
   Buzsaki G., 2006, RHYTHMS BRAIN
   Costa A, 2004, TRENDS COGN SCI, V8, P253, DOI 10.1016/j.tics.2004.04.005
   de Bruin A, 2018, J MEM LANG, V103, P28, DOI 10.1016/j.jml.2018.07.005
   de Bruin A, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00522
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dijkstra T, 2002, BILING-LANG COGN, V5, P175, DOI 10.1017/S1366728902003012
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Engel AK, 2010, CURR OPIN NEUROBIOL, V20, P156, DOI 10.1016/j.conb.2010.02.015
   Fernandez CB, 2019, J NEUROLINGUIST, V51, P17, DOI 10.1016/j.jneuroling.2018.10.004
   Garcia-Penton L, 2016, LANG COGN NEUROSCI, V31, P303, DOI 10.1080/23273798.2015.1068944
   Gollan TH, 2014, J EXP PSYCHOL GEN, V143, P2167, DOI 10.1037/a0038006
   Grainger J., 2010, LANG ACQUIS, P267, DOI DOI 10.1075/LALD.52.18GRA
   Green DW, 2013, J COGN PSYCHOL, V25, P515, DOI 10.1080/20445911.2013.796377
   Gullifer JW, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00278
   Lewis AG, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00085
   Lewis AG, 2015, CORTEX, V68, P155, DOI 10.1016/j.cortex.2015.02.014
   Litcofsky KA, 2017, NEUROPSYCHOLOGIA, V97, P112, DOI 10.1016/j.neuropsychologia.2017.02.002
   Liu HH, 2017, INT J BILINGUAL, V21, P57, DOI 10.1177/1367006915600800
   McIntosh RD, 2017, CORTEX, V96, pA1, DOI 10.1016/j.cortex.2017.07.014
   Obleser J, 2012, CEREB CORTEX, V22, P2466, DOI 10.1093/cercor/bhr325
   Obleser J, 2012, J NEUROSCI, V32, P12376, DOI 10.1523/JNEUROSCI.4908-11.2012
   Perez A, 2015, BRAIN LANG, V147, P51, DOI 10.1016/j.bandl.2015.05.008
   Poplack S., 1978, LATINO DISCOURSE COM, P169
   Riecke L, 2018, CURR BIOL, V28, P161, DOI 10.1016/j.cub.2017.11.033
   Rimmele JM, 2015, CORTEX, V68, P144, DOI 10.1016/j.cortex.2014.12.014
   Van Hell J. G., 2015, CAMBRIDGE HDB BILING, P459, DOI DOI 10.1017/CB09781107447257.020
   van Heuven WJB, 2010, BRAIN RES REV, V64, P104, DOI 10.1016/j.brainresrev.2010.03.002
   Verhoef K, 2009, COGNITION, V110, P84, DOI 10.1016/j.cognition.2008.10.013
   Weiss S, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00201
   Yang HJ, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00560
   Zoefel B, 2018, CURR BIOL, V28, P401, DOI 10.1016/j.cub.2017.11.071
NR 43
TC 1
Z9 1
U1 3
U2 9
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0911-6044
J9 J NEUROLINGUIST
JI J. Neurolinguist.
PD AUG
PY 2019
VL 51
BP 258
EP 267
DI 10.1016/j.jneuroling.2019.04.002
PG 10
WC Linguistics; Neurosciences; Psychology, Experimental
SC Linguistics; Neurosciences & Neurology; Psychology
GA IC8FC
UT WOS:000471210700019
DA 2021-02-24
ER

PT J
AU Di Liberto, GM
   Wong, D
   Melnik, GA
   de Cheveigne, A
AF Di Liberto, Giovanni M.
   Wong, Daniel
   Melnik, Gerda Ana
   de Cheveigne, Alain
TI Low-frequency cortical responses to natural speech reflect probabilistic
   phonotactics
SO NEUROIMAGE
LA English
DT Article
DE cortical tracking; EEG; Language; Neighbourhood density; Phonemes
ID WORD SEGMENTATION; COMPONENT; CONSTRAINTS; ENTRAINMENT; PERCEPTION;
   PHONOLOGY; DYNAMICS; BRAIN; COMPREHENSION; WORDLIKENESS
AB Humans comprehend speech despite the various challenges such as mispronunciation and noisy environments. Our auditory system is robust to these thanks to the integration of the sensory input with prior knowledge and expectations built on language-specific regularities. One such regularity regards the permissible phoneme sequences, which determine the likelihood that a word belongs to a given language (phonotactic probability; "blick" is more likely to be an English word than "bnick"). Previous research demonstrated that violations of these rules modulate brain-evoked responses. However, several fundamental questions remain unresolved, especially regarding the neural encoding and integration strategy of phonotactics in naturalistic conditions, when there are no (or few) violations. Here, we used linear modelling to assess the influence of phonotactic probabilities on the brain responses to narrative speech measured with non-invasive EEG. We found that the relationship between continuous speech and EEG responses is best described when the stimulus descriptor includes phonotactic probabilities. This indicates that low-frequency cortical signals (<9 Hz) reflect the integration of phonotactic information during natural speech perception, providing us with a measure of phonotactic processing at the individual subject-level. Furthermore, phonotactics-related signals showed the strongest speech-EEG interactions at latencies of 100-500 ms, supporting a pre-lexical role of phonotactic information.
C1 [Di Liberto, Giovanni M.; Wong, Daniel; de Cheveigne, Alain] CNRS, UMR 8248, Lab Syst Perceptifs, Paris, France.
   [Di Liberto, Giovanni M.; Wong, Daniel; Melnik, Gerda Ana; de Cheveigne, Alain] PSL Univ, Ecole Normale Super, Dept Etud Cognit, Paris, France.
   [Melnik, Gerda Ana] CNRS, EHESS, ENS, Lab Sci Cognit & Psycholinguist, Paris, France.
   [de Cheveigne, Alain] UCL Ear Inst, London, England.
RP Di Liberto, GM (corresponding author), Lab Syst Perceptifs, 29 Rue Ulm, F-75005 Paris, France.
EM diliberg@tcd.ie
RI Melnik-Leroy, Gerda Ana/AAD-4915-2021; Di Liberto,
   Giovanni/AAT-8865-2020; de Cheveigne, Alain/F-4947-2012
OI Melnik-Leroy, Gerda Ana/0000-0001-6644-3179; Di Liberto,
   Giovanni/0000-0002-7361-0980; de Cheveigne, Alain/0000-0002-7305-1891
FU EU H2020-ICT grant [644732]
FX This work was supported by the EU H2020-ICT grant 644732 (COCOHA). The
   authors would like to thank Dorothee Arzounian for useful discussions at
   the start of this study.
CR Bailey TM, 2001, J MEM LANG, V44, P568, DOI 10.1006/jmla.2000.2756
   Balling LW, 2012, COGNITION, V125, P80, DOI 10.1016/j.cognition.2012.06.003
   Balling LW, 2008, LANG COGNITIVE PROC, V23, P1159, DOI 10.1080/01690960802201010
   Brent MR, 1996, COGNITION, V61, P93, DOI 10.1016/S0010-0277(96)00719-6
   Brodbeck C., 2018, 326785 BIORXIV
   Broderick MP, 2018, CURR BIOL, V28, P803, DOI 10.1016/j.cub.2018.01.080
   Carlson MT, 2016, BILING-LANG COGN, V19, P939, DOI 10.1017/S1366728915000334
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   CHURCH KW, 1987, COGNITION, V25, P53, DOI 10.1016/0010-0277(87)90004-7
   Cibelli ES, 2015, BRAIN LANG, V147, P66, DOI 10.1016/j.bandl.2015.05.005
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256
   Crosse MJ, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00604
   Davidson L, 2006, J PHONETICS, V34, P104, DOI 10.1016/j.wocn.2005.03.004
   Davidson L, 2006, COGNITIVE SCI, V30, P837, DOI 10.1207/s15516709cog0000_73
   Davidson L, 2011, J EXP PSYCHOL HUMAN, V37, P270, DOI 10.1037/a0020988
   de Cheveigne A., 2018, 344960 BIORXIV
   de Cheveigne A, 2018, NEUROIMAGE, V172, P206, DOI 10.1016/j.neuroimage.2018.01.033
   Deacon D, 2004, PSYCHOPHYSIOLOGY, V41, P60, DOI 10.1111/1469-8986.00120
   Dehaene-Lambertz G, 2000, J COGNITIVE NEUROSCI, V12, P635, DOI 10.1162/089892900562390
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Di Liberto GM, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0084-18.2018
   Di Liberto GM, 2018, NEUROIMAGE, V175, P70, DOI 10.1016/j.neuroimage.2018.03.072
   Di Liberto GM, 2018, NEUROIMAGE, V166, P247, DOI 10.1016/j.neuroimage.2017.10.066
   Di Liberto GM, 2017, HEARING RES, V348, P70, DOI 10.1016/j.heares.2017.02.015
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Ding N, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00481
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Ding N, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00311
   Ding N, 2012, J NEUROPHYSIOL, V107, P78, DOI 10.1152/jn.00297.2011
   Domahs U, 2009, LANG SPEECH, V52, P415, DOI 10.1177/0023830909336581
   Dupoux E, 2001, LANG COGNITIVE PROC, V16, P491, DOI 10.1080/01690960143000191
   Dupoux E, 1999, J EXP PSYCHOL HUMAN, V25, P1568, DOI 10.1037/0096-1523.25.6.1568
   Dupoux E, 2011, J MEM LANG, V64, P199, DOI 10.1016/j.jml.2010.12.004
   Ettinger A., 2014, ROLE MORPHOLOGY PHON
   Friedrich M, 2005, J COGNITIVE NEUROSCI, V17, P1785, DOI 10.1162/089892905774589172
   Frisch SA, 2000, J MEM LANG, V42, P481, DOI 10.1006/jmla.1999.2692
   Gaston P, 2018, LANG COGN NEUROSCI, V33, P402, DOI 10.1080/23273798.2017.1395466
   Goldwater Sharon, 2003, P STOCKH WORKSH VAR, P111
   Gorman K., 2011, CANADIAN ACOUSTICS, V39, P192
   GREENWOOD D, 1961, J ACOUST SOC AM, V33, P484, DOI 10.1121/1.1908699
   Grendar M., 2001, ENTROPY, V3, P58
   Halle PA, 2008, J EXP PSYCHOL HUMAN, V34, P177, DOI 10.1037/0096-1523.34.1.177
   Hammond M., 2004, INT J ENGL STUD, V4
   Hayes B., 2012, BLICK PHONOTACTIC PR
   Hayes B, 2008, LINGUIST INQ, V39, P379, DOI 10.1162/ling.2008.39.3.379
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.2307/2333955
   Jaynes E. T., 1988, RELATION BAYESIAN MA
   Jusczyk PW, 1999, COGNITIVE PSYCHOL, V39, P159, DOI 10.1006/cogp.1999.0716
   JUSCZYK PW, 1994, J MEM LANG, V33, P630, DOI 10.1006/jmla.1994.1030
   Khalighinejad B, 2017, J NEUROSCI, V37, P2176, DOI 10.1523/JNEUROSCI.2383-16.2017
   Kosem A., 2016, LANG COGN NEUROSCI, P1
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Lalor EC, 2006, NEUROIMAGE, V32, P1549, DOI 10.1016/j.neuroimage.2006.05.054
   Lalor EC, 2009, J NEUROPHYSIOL, V102, P349, DOI 10.1152/jn.90896.2008
   Lentz TO, 2015, LANG SPEECH, V58, P387, DOI 10.1177/0023830914559572
   Leonard MK, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13619
   Leonard MK, 2015, J NEUROSCI, V35, P7203, DOI 10.1523/JNEUROSCI.4100-14.2015
   Luck S. J., 2005, INTRO EVENT RELATED
   Mattys SL, 1999, COGNITIVE PSYCHOL, V38, P465, DOI 10.1006/cogp.1999.0721
   Mattys SL, 2001, COGNITION, V78, P91, DOI 10.1016/S0010-0277(00)00109-8
   McClelland JL, 2006, TRENDS COGN SCI, V10, P363, DOI 10.1016/j.tics.2006.06.007
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McQueen JM, 1998, J MEM LANG, V39, P21, DOI 10.1006/jmla.1998.2568
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Munz ED, 2017, NERVENHEILKUNDE, V36, P800
   O'Sullivan JA, 2015, CEREB CORTEX, V25, P1697, DOI 10.1093/cercor/bht355
   Obleser J, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00250
   Obrig H, 2016, BRAIN, V139, P1800, DOI 10.1093/brain/aww077
   Pisoni DB, 2005, BLACKW HBK LINGUIST, P1, DOI 10.1002/9780470757024
   Pylkkanen L, 2002, BRAIN LANG, V81, P666, DOI 10.1006/brln.2001.2555
   Pylkkanen L., 2000, P BIOM 2000 12 INT C, P1
   Rossi S, 2013, BRAIN LANG, V127, P404, DOI 10.1016/j.bandl.2013.02.009
   Rossi S, 2011, J COGNITIVE NEUROSCI, V23, P1752, DOI 10.1162/jocn.2010.21547
   Scholes Robert J., 1966, PHONOTACTIC GRAMMATI
   Sebastian-Galles N, 2007, DEVELOPMENTAL SCI, V10, P713, DOI 10.1111/j.1467-7687.2007.00649.x
   Storkel H. L., 2000, CLIN LINGUIST PHON
   Storkel HL, 2004, J SPEECH LANG HEAR R, V47, P1194, DOI 10.1044/1092-4388(2004/088)
   Storkel HL, 2002, LANG SPEECH HEAR SER, V33, DOI 10.1044/0161-1461(2002/003)
   Storkel HL, 2001, J SPEECH LANG HEAR R, V44, P1321, DOI 10.1044/1092-4388(2001/103)
   Storkel HL, 2006, J SPEECH LANG HEAR R, V49, P1175, DOI 10.1044/1092-4388(2006/085)
   Ulbrich C., 2017, LANGUAGE COGNITION N
   VanRullen R, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00060
   Vanthornhout J, 2018, JARO-J ASSOC RES OTO, V19, P181, DOI 10.1007/s10162-018-0654-z
   Vitevitch MS, 1997, LANG SPEECH, V40, P47, DOI 10.1177/002383099704000103
   Vitevitch MS, 1999, BRAIN LANG, V68, P306, DOI 10.1006/brln.1999.2116
   Wagner M, 2012, BRAIN LANG, V123, P30, DOI 10.1016/j.bandl.2012.06.002
   White J, 2017, ACTA LINGUIST HUNGAR, V64, P513, DOI 10.1556/2062.2017.64.4.2
   Widmann A, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00233
   Wiese R., 2017, ERP EXPT LEARNABILIT, V7
   Zamuner T. S., 2016, PHONOTACTICS SYLLABL
   2012, PHONOL PHONET, V18, P1
NR 91
TC 5
Z9 5
U1 2
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD AUG 1
PY 2019
VL 196
BP 237
EP 247
DI 10.1016/j.neuroimage.2019.04.037
PG 11
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA IC3BK
UT WOS:000470833800023
PM 30991126
OA Green Published
DA 2021-02-24
ER

PT J
AU Kaganovich, N
   Ancel, E
AF Kaganovich, Natalya
   Ancel, Elizabeth
TI Different neural processes underlie visual speech perception in
   school-age children and adults: An event-related potentials study
SO JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY
LA English
DT Article
DE Multisensory development; Audiovisual word perception; N400; Late
   positive complex; Speech-in-noise perception; Lexical access;
   Audiovisual matching
ID HEARING-LIPS; WORD REPETITION; SEEING-VOICES; BRAIN; RECOGNITION;
   CHILDHOOD; ERP; MANIFESTATIONS; ACQUISITION; FRAMEWORK
AB The ability to use visual speech cues does not fully develop until late adolescence. The cognitive and neural processes underlying this slow maturation are not yet understood. We examined electrophysiological responses of younger (8-9 years) and older (11-12 years) children as well as adults elicited by visually perceived articulations in an audiovisual word matching task and related them to the amount of benefit gained during a speech-in noise (SIN) perception task when seeing the talker's face. On each trial, participants first heard a word and, after a short pause, saw a speaker silently articulate a word. In half of the trials the articulated word matched the auditory word (congruent trials), whereas in the other half it did not (incongruent trials). In all three age groups, incongruent articulations elicited the N400 component and congruent articulations elicited the late positive complex (LPC). Groups did not differ in the mean amplitude of N400. The mean amplitude of LPC was larger in younger children compared with older children and adults. Importantly, the relationship between event-related potential measures and SIN performance varied by group. In 8- and 9-year-olds, neither component was predictive of SIN gain. The LPC amplitude predicted the SIN gain in older children but not in adults. Conversely, the N400 amplitude predicted the SIN gain in adults. We argue that although all groups were able to detect correspondences between auditory and visual word onsets at the phonemic/syllabic level, only adults could use this information for lexical access. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Kaganovich, Natalya; Ancel, Elizabeth] Purdue Univ, Dept Speech Language & Hearing Sci, W Lafayette, IN 47907 USA.
   [Kaganovich, Natalya] Purdue Univ, Dept Psychol Sci, W Lafayette, IN 47907 USA.
RP Kaganovich, N (corresponding author), Purdue Univ, Dept Speech Language & Hearing Sci, W Lafayette, IN 47907 USA.
EM kaganovi@purdue.edu
FU National Institute on Deafness and Other Communicative Disorders,
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R03DC013151]
FX This research was supported in part by Grant R03DC013151 from the
   National Institute on Deafness and Other Communicative Disorders,
   National Institutes of Health. The content is solely the responsibility
   of the authors and does not necessarily represent the official view of
   the National Institute on Deafness and Other Communicative Disorders or
   the National Institutes of Health. We are grateful to Kevin Barlow for
   creating stimulus presentation programs, to Steven Hnath and Samantha
   Hoover for helping with video materials, and to Jennifer Schumaker for
   helping with various stages of data collection and analysis.
CR Alsius A, 2018, MULTISENS RES, V31, P111, DOI 10.1163/22134808-00002565
   Anglin J. M., 1989, READING CANADA, V7, P142
   [Anonymous], 1994, J Clin Neurophysiol, V11, P111
   Astheimer LB, 2012, DEV COGN NEUROS-NETH, V2, P120, DOI 10.1016/j.dcn.2011.03.002
   Astheimer LB, 2009, BIOL PSYCHOL, V80, P23, DOI 10.1016/j.biopsycho.2008.01.015
   Barutchu A, 2008, EUR J COGN PSYCHOL, V20, P1, DOI 10.1080/09541440601125623
   Bentin S, 1999, J COGNITIVE NEUROSCI, V11, P235, DOI 10.1162/089892999563373
   BioSemi, 2013, ACT EL
   Boersma P., 2011, PRAAT DOING PHONETIC
   Brancazio L, 2004, J EXP PSYCHOL HUMAN, V30, P445, DOI 10.1037/0096-1523.30.3.445
   Brown L., 2010, TEST NONVERBAL INTEL
   Buchwald AB, 2009, LANG COGNITIVE PROC, V24, P580, DOI 10.1080/01690960802536357
   Calvert GA, 2001, CEREB CORTEX, V11, P1110, DOI 10.1093/cercor/11.12.1110
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Coch D, 2008, PSYCHOPHYSIOLOGY, V45, P949, DOI 10.1111/j.1469-8986.2008.00701.x
   Cohen M.S., 2008, HANDEDNESS QUESTIONN
   Conners K., 1997, CONNERS RATING SCALE
   D'Arcy RCN, 2004, HUM BRAIN MAPP, V22, P40, DOI 10.1002/hbm.20008
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   Erickson LC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00534
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   Fernald A, 2013, DEVELOPMENTAL SCI, V16, P234, DOI 10.1111/desc.12019
   Field A., 2013, DISCOVERING STAT USI
   Fort M, 2013, LANG COGNITIVE PROC, V28, P1207, DOI 10.1080/01690965.2012.701758
   Fort M, 2012, INT J BEHAV DEV, V36, P457, DOI 10.1177/0165025412447752
   Fort M, 2010, SPEECH COMMUN, V52, P525, DOI 10.1016/j.specom.2010.02.005
   Giedd JN, 1999, NAT NEUROSCI, V2, P861, DOI 10.1038/13158
   Gogtay N, 2004, P NATL ACAD SCI USA, V101, P8174, DOI 10.1073/pnas.0402680101
   Grossi G, 2001, J COGNITIVE NEUROSCI, V13, P610, DOI 10.1162/089892901750363190
   Havy M, 2017, CHILD DEV, V88, P2043, DOI 10.1111/cdev.12715
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hillock-Dunn A, 2012, DEVELOPMENTAL SCI, V15, P688, DOI 10.1111/j.1467-7687.2012.01171.x
   Jerger S, 2018, J CHILD LANG, V45, P392, DOI 10.1017/S0305000917000265
   Jerger S, 2017, J CHILD LANG, V44, P185, DOI 10.1017/S030500091500077X
   Jerger S, 2014, J EXP CHILD PSYCHOL, V126, P295, DOI 10.1016/j.jecp.2014.05.003
   Jerger S, 2009, J EXP CHILD PSYCHOL, V102, P40, DOI 10.1016/j.jecp.2008.08.002
   Kaganovich N, 2016, J NEURODEV DISORD, V8, DOI 10.1186/s11689-016-9168-3
   Kaganovich N, 2016, BRAIN LANG, V157, P14, DOI 10.1016/j.bandl.2016.04.010
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Lewkowicz DJ, 2012, NEURAL BASES MULTISE, P325
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1
   MacSweeney M, 2013, J COGNITIVE NEUROSCI, V25, P1037, DOI 10.1162/jocn_a_00373
   Malins JG, 2013, DEV COGN NEUROS-NETH, V5, P134, DOI 10.1016/j.dcn.2013.02.005
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Metsala JL, 1997, MEM COGNITION, V25, P47, DOI 10.3758/BF03197284
   Metting van Rijn AC, 1996, 18 ANN INT C IEEE EN
   MICELI G, 1980, BRAIN LANG, V11, P159, DOI 10.1016/0093-934X(80)90117-0
   MILBERG W, 1988, BRAIN LANG, V34, P279, DOI 10.1016/0093-934X(88)90139-3
   Mohan R, 2015, J NEURODEV DISORD, V7, DOI 10.1186/s11689-015-9124-7
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Panouilleres MTN, 2018, CORTEX, V103, P44, DOI 10.1016/j.cortex.2018.02.007
   Peelle JE, 2015, CORTEX, V68, P169, DOI 10.1016/j.cortex.2015.03.006
   Pflieger ME, 2001, EMSE WORKSH PRINC U
   PRAAMSTRA P, 1993, COGNITIVE BRAIN RES, V1, P73, DOI 10.1016/0926-6410(93)90013-U
   PRAAMSTRA P, 1994, J COGNITIVE NEUROSCI, V6, P204, DOI 10.1162/jocn.1994.6.3.204
   Riedel P, 2015, CORTEX, V68, P86, DOI 10.1016/j.cortex.2014.11.016
   Ross LA, 2011, EUR J NEUROSCI, V33, P2329, DOI 10.1111/j.1460-9568.2011.07685.x
   RUGG MD, 1992, ELECTROEN CLIN NEURO, V84, P521, DOI 10.1016/0168-5597(92)90041-9
   RUGG MD, 1984, BRAIN LANG, V23, P225, DOI 10.1016/0093-934X(84)90065-8
   Rugg MD, 1999, NEUROREPORT, V10, P2661, DOI 10.1097/00001756-199908200-00041
   RUGG MD, 1987, MEM COGNITION, V15, P473, DOI 10.3758/BF03198381
   RUGG MD, 1984, NEUROPSYCHOLOGIA, V22, P435, DOI 10.1016/0028-3932(84)90038-1
   RUGG MD, 2000, OXFORD HDB MEMORY, P521
   Rugg MD, 2007, TRENDS COGN SCI, V11, P251, DOI 10.1016/j.tics.2007.04.004
   Schelinski S, 2014, NEUROPSYCHOLOGIA, V65, P1, DOI 10.1016/j.neuropsychologia.2014.09.031
   Schopler E, 2010, CHILDHOOD AUTISM RAT
   Semel E.M., 2004, CLIN EVALUATION LANG
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Stevenson RA, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00352
   ten Oever S, 2014, NEUROPSYCHOLOGIA, V63, P43, DOI 10.1016/j.neuropsychologia.2014.08.008
   Tremblay C, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000742
   U. S. Department of Education, 1996, READ LIT US FIND IEA
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   VANRIJN ACM, 1990, MED BIOL ENG COMPUT, V28, P389, DOI 10.1007/BF02441961
   Weber-Fox C, 2008, DEVELOPMENTAL SCI, V11, P321, DOI 10.1111/j.1467-7687.2008.00678.x
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   Werker JF, 1998, DEV PSYCHOL, V34, P1289, DOI 10.1037/0012-1649.34.6.1289
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   World Medical Association General Assembly, 1964, WMA DECL HELS ETH PR
   Zhu LL, 2017, J NEUROSCI, V37, P2697, DOI 10.1523/JNEUROSCI.2914-16.2017
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
NR 84
TC 4
Z9 4
U1 0
U2 5
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0022-0965
EI 1096-0457
J9 J EXP CHILD PSYCHOL
JI J. Exp. Child Psychol.
PD AUG
PY 2019
VL 184
BP 98
EP 122
DI 10.1016/j.jecp.2019.03.009
PG 25
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA IB1WB
UT WOS:000470054600007
PM 31015101
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Taranu, M
   Wimmer, MC
   Ross, J
   Farkas, D
   van Ee, R
   Winkler, I
   Denham, SL
AF Taranu, Mihaela
   Wimmer, Marina C.
   Ross, Josephine
   Farkas, David
   van Ee, Raymond
   Winkler, Istvan
   Denham, Susan L.
TI Children's perception of visual and auditory ambiguity and its link to
   executive functions and creativity
SO JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY
LA English
DT Article
DE Perceptual bistability; Visual bistability; Auditory bistability;
   Perceptual switching; Executive functions; Creativity
ID MULTISTABLE PERCEPTION; WORKING-MEMORY; SUSTAINED ATTENTION; SELECTIVE
   ATTENTION; SPEECH-PERCEPTION; CORTEX; INTELLIGENCE; ADAPTATION;
   REVERSALS; FIGURES
AB The phenomenon of perceptual bistability provides insights into aspects of perceptual processing not normally accessible to everyday experience. However, most experiments have been conducted in adults, and it is not clear to what extent key aspects of perceptual switching change through development. The current research examined the ability of 6-, 8-, and 10-year-old children (N = 66) to switch between competing percepts of ambiguous visual and auditory stimuli and links between switching rate, executive functions, and creativity. The numbers of switches participants reported in two visual tasks (ambiguous figure and ambiguous structure from motion) and two auditory tasks (verbal transformation and auditory streaming) were measured in three 60-s blocks. In addition, inhibitory control was measured with a Stroop task, set shifting was measured with a verbal fluency task, and creativity was measured with a divergent thinking task. The numbers of perceptual switches increased in all four tasks from 6 to 10 years of age but differed across tasks in that they were higher in the verbal transformation and ambigous structure-from-motion tasks than in the ambigous figure and auditory streaming tasks for all age groups. Although perceptual switching rates differed across tasks, there were predictive relationships between switching rates in some tasks. However, little evidence for the influence of central processes on perceptual switching was found. Overall, the results support the notion that perceptual switching is largely modality and task specific and that this property is already evident when perceptual switching emerges. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Taranu, Mihaela; Wimmer, Marina C.; Denham, Susan L.] Univ Plymouth, Cognit Inst, Plymouth PL4 8AA, Devon, England.
   [Taranu, Mihaela; Wimmer, Marina C.; Denham, Susan L.] Univ Plymouth, Sch Psychol, Plymouth PL4 8AA, Devon, England.
   [Ross, Josephine] Univ Dundee, Sch Social Sci, Psychol, Dundee DD1 4HN, Scotland.
   [Farkas, David] Hungarian Acad Sci, Res Ctr Nat Sci, Inst Cognit Neurosci & Psychol, H-1117 Budapest, Hungary.
   [van Ee, Raymond] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Biophys, NL-6500 GL Nijmegen, Netherlands.
   [van Ee, Raymond] Leuven Univ, Dept Brain & Cognit, BE-3000 Leuven, Belgium.
   [van Ee, Raymond] Philips Res, Dept Brain Behav & Cognit, High Tech Campus, NL-5656 AE Eindhoven, Netherlands.
   [Winkler, Istvan] Budapest Univ Technol & Econ, Fac Nat Sci, Dept Cognit Sci, H-1111 Budapest, Hungary.
RP Wimmer, MC (corresponding author), Univ Plymouth, Cognit Inst, Plymouth PL4 8AA, Devon, England.; Wimmer, MC (corresponding author), Univ Plymouth, Sch Psychol, Plymouth PL4 8AA, Devon, England.
EM marina.wimmer@plymouth.ac.uk
RI Winkler, Istvan/A-7659-2008
OI Winkler, Istvan/0000-0002-3344-6151
FU European Union's (EU) Marie Curie Initial Training Network, CogNovo
   [FP7-PEOPLE-2013-ITN-604764]; EU HealthPac grant; Methusalem program of
   the Flemish Government [METH/14/02]; Research Foundation FlandersFWO;
   Hungarian National Research, Development and Innovation Office [NKFIH
   K115385]
FX M.T. was supported by funding from the European Union's (EU) Marie Curie
   Initial Training Network, CogNovo (FP7-PEOPLE-2013-ITN-604764). R.v.E.
   was supported by the EU HealthPac grant (awarded to J. van Opstal), the
   Methusalem program of the Flemish Government (METH/14/02) awarded to J.
   Wagemans, and the Research Foundation Flanders. IW was supported by the
   Hungarian National Research, Development and Innovation Office (NKFIH
   K115385). We thank Martin Coath, Nicolas Pugeault, and Chris Klink for
   their help in designing the auditory streaming task animations and the
   ambiguous structure-from-motion cylinder. We also thank the technical
   support office at the University of Plymouth for programming the
   experiment and thank the children and teachers from Montpelier primary
   school who made this research possible.
CR Alais D, 2010, VISION RES, V50, P929, DOI 10.1016/j.visres.2010.03.010
   Arani E, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27398-x
   Benedek M, 2014, INTELLIGENCE, V46, P73, DOI 10.1016/j.intell.2014.05.007
   Betts J, 2006, CHILD NEUROPSYCHOL, V12, P205, DOI 10.1080/09297040500488522
   Bialystok E, 2005, DEVELOPMENTAL SCI, V8, P595, DOI 10.1111/j.1467-7687.2005.00451.x
   Brascamp J, 2018, ANNU REV PSYCHOL, V69, P77, DOI 10.1146/annurev-psych-010417-085944
   Brascamp JW, 2006, J VISION, V6, P1244, DOI 10.1167/6.11.8
   Brascamp JW, 2010, J NEUROSCI, V30, P760, DOI 10.1523/JNEUROSCI.4171-09.2010
   Bremner AJ, 2016, CHILD DEV, V87, P962, DOI 10.1111/cdev.12511
   Chamberlain R, 2018, BRIT J PSYCHOL, V109, P244, DOI 10.1111/bjop.12253
   de Graaf TA, 2011, CEREB CORTEX, V21, P2322, DOI 10.1093/cercor/bhr015
   Dekker TM, 2019, DEV COGN NEUROS-NETH, V37, DOI 10.1016/j.dcn.2019.01.001
   Denham S. L., 2013, LEARN PERCEPT, V5, P73, DOI DOI 10.1556/LP.5.2013.SUPPL2.6
   Denham SL, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25587-2
   Diaz-Santos M, 2017, AGING NEUROPSYCHOL C, V24, P115, DOI 10.1080/13825585.2016.1173646
   Doherty MJ, 2012, PERCEPTION, V41, P1262, DOI 10.1068/p7350
   Doherty MJ, 2010, DEVELOPMENTAL SCI, V13, P714, DOI 10.1111/j.1467-7687.2009.00931.x
   Ehlers J, 2006, INT J PSYCHOPHYSIOL, V61, P377
   Ehlers J, 2016, INT J PSYCHOPHYSIOL, V103, P129, DOI 10.1016/j.ijpsycho.2015.02.013
   Farkas D, 2018, NEUROPSYCHOLOGIA, V108, P82, DOI 10.1016/j.neuropsychologia.2017.11.032
   Farkas D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154810
   Farkas D, 2016, J ACOUST SOC AM, V139, P1762, DOI 10.1121/1.4945720
   Gale AG, 1983, EYE MOVEMENTS PSYCHO, P145
   Gonen-Yaacovi G, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00465
   Gopnik A, 2001, DEVELOPMENTAL SCI, V4, P175, DOI 10.1111/1467-7687.00163
   Hupe JM, 2008, J VISION, V8, DOI 10.1167/8.7.1
   Intaite M, 2014, NEUROPSYCHOLOGIA, V56, P428, DOI 10.1016/j.neuropsychologia.2014.02.016
   Jastrow J., 1899, POPULAR SCI MONTHLY, V54, P299, DOI DOI 10.1037/10919-008
   Kaldy Z, 2003, PERCEPTION, V32, P657, DOI 10.1068/p3473
   Klink PC, 2008, J VISION, V8, DOI 10.1167/8.5.16
   Lafer-Sousa R, 2015, CURR BIOL, V25, pR545, DOI 10.1016/j.cub.2015.04.053
   Lin CCH, 1999, J ABNORM CHILD PSYCH, V27, P403, DOI 10.1023/A:1021932119311
   Long GM, 2004, PSYCHOL BULL, V130, P748, DOI 10.1037/0033-2909.130.5.748
   McIntosh AR, 2010, ARCH ITAL BIOL, V148, P323
   Mill RW, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1002925
   Mitroff SR, 2006, PERCEPTION, V35, P709, DOI 10.1068/p5520
   Miyake A, 2000, COGNITIVE PSYCHOL, V41, P49, DOI 10.1006/cogp.1999.0734
   Nayar K, 2015, J EXP CHILD PSYCHOL, V131, P38, DOI 10.1016/j.jecp.2014.11.001
   PLUDE DJ, 1994, ACTA PSYCHOL, V86, P227, DOI 10.1016/0001-6918(94)90004-3
   Porporino M, 2004, INT J BEHAV DEV, V28, P358, DOI 10.1080/01650250444000063
   Pressnitzer D, 2006, CURR BIOL, V16, P1351, DOI 10.1016/j.cub.2006.05.054
   Rayner K, 2009, BIOL PSYCHOL, V80, P4, DOI 10.1016/j.biopsycho.2008.05.002
   ROCK I, 1994, PERCEPTION, V23, P635, DOI 10.1068/p230635
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   SCHOOLER JW, 1995, CREATIVE COGNITION A, P97
   Sharma S, 2017, CREATIVITY RES J, V29, P71, DOI 10.1080/10400419.2017.1263512
   Shpiro A, 2009, J COMPUT NEUROSCI, V27, P37, DOI 10.1007/s10827-008-0125-3
   Simpson A, 2005, BRIT J DEV PSYCHOL, V23, P471, DOI 10.1348/026151005X28712
   Stuart M, 1993, CHILDRENS PRINTED WO
   Sussman E, 2007, HEARING RES, V225, P117, DOI 10.1016/j.heares.2006.12.013
   Troyer AK, 1997, NEUROPSYCHOLOGY, V11, P138, DOI 10.1037/0894-4105.11.1.138
   van Ee R, 2011, J VISION, V11, DOI 10.1167/11.2.13
   van Ee R, 2009, J OPT SOC AM A, V26, P2612, DOI 10.1364/JOSAA.26.002612
   van Ee R, 2009, J NEUROSCI, V29, P11641, DOI 10.1523/JNEUROSCI.0873-09.2009
   van Noorden L. P. A. S, 1975, TEMPORAL COHERENCE P
   WALLACH H, 1953, J EXP PSYCHOL, V45, P205, DOI 10.1037/h0056880
   WALLACH MA, 1965, J PERS, V33, P348, DOI 10.1111/j.1467-6494.1965.tb01391.x
   WARREN RM, 1958, AM J PSYCHOL, V71, P612, DOI 10.2307/1420267
   WARREN RM, 1966, J VERB LEARN VERB BE, V5, P142, DOI 10.1016/S0022-5371(66)80007-5
   Watson Chloe, 2018, GUARDIAN
   Wimmer M. C., 2011, MONOGRAPHS SOC RES C, V76
   Wimmer MC, 2014, J EXP CHILD PSYCHOL, V126, P412, DOI 10.1016/j.jecp.2014.03.004
   Wiseman R, 2011, BRIT J PSYCHOL, V102, P615, DOI 10.1111/j.2044-8295.2011.02031.x
NR 63
TC 0
Z9 0
U1 3
U2 19
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0022-0965
EI 1096-0457
J9 J EXP CHILD PSYCHOL
JI J. Exp. Child Psychol.
PD AUG
PY 2019
VL 184
BP 123
EP 138
DI 10.1016/j.jecp.2019.03.010
PG 16
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA IB1WB
UT WOS:000470054600008
PM 31029832
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Kitapci, K
   Galbrun, L
AF Kitapci, Kivanc
   Galbrun, Laurent
TI Perceptual analysis of the speech intelligibility and soundscape of
   multilingual environments
SO APPLIED ACOUSTICS
LA English
DT Article
DE Speech intelligibility; Soundscape; Room acoustics; Speech perception
AB This paper examines the perceived speech intelligibility of English, Polish, Arabic, and Mandarin and, more generally, the soundscape associated to multilingual environments. Listening tests were used to evaluate three acoustic environments (an airport, a hospital, and a caf) under three room acoustic conditions defined by a different speech transmission index (STI) (STI = 0.4, 0.5 and 0.6). In the tests, participants rated eleven semantic attributes representative of speech perception and the overall soundscape (speech intelligibility, speech level, speech pleasantness, noisiness, annoyance, relaxation, comfort, environment pleasantness, eventfulness, excitement, and familiarity). Results obtained indicate that inter-language comparisons based on perceived speech intelligibility are different from those obtained from objective speech intelligibility tests. Noticeably, English participants were found to be most sensitive to changes in room acoustic conditions and to meaningful and distractive noise sources, whilst Arab participants were least sensitive to changes in room acoustic conditions and more tolerant to noise. Perceived speech intelligibility correlated significantly with non-acoustical factors (speech pleasantness, comfort and environment pleasantness), and 'emotional factors' (annoyance, relaxation, comfort and environment pleasantness) explained a large portion of the variance in soundscape assessment. Results also showed that language affected the perceived speech intelligibility marginally (p = 0.051) and noisiness significantly (p = 0.047), the latter being the best indicator of cultural variations amongst the attributes tested. Overall, the study shows that designing for speech intelligibility cannot be solely based on room acoustic parameters, especially in the case of multi-lingual environments. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Kitapci, Kivanc] Cankaya Univ, Dept Interior Architecture, Ankara, Turkey.
   [Galbrun, Laurent] Heriot Watt Univ, Sch Energy Geosci Infrastruct & Soc, Edinburgh, Midlothian, Scotland.
RP Kitapci, K (corresponding author), Cankaya Univ, Dept Interior Architecture, Fac Architecture, Ogretmenler Caddesi 14, TR-06530 Ankara, Turkey.
EM kivanckitapci@cankaya.edu.tr
OI Galbrun, Laurent/0000-0001-6152-8405; Kitapci,
   Kivanc/0000-0003-4409-5147
CR [Anonymous], 2003, 9921 EN ISO
   Boudraa M, 2000, ACUSTICA, V86, P870
   COX RM, 1991, J SPEECH HEAR RES, V34, P904, DOI 10.1044/jshr.3404.904
   Extra G, 2011, J PRAGMATICS, V43, P1173, DOI 10.1016/j.pragma.2010.10.007
   Field A., 2009, DISCOVERING STAT USI
   Galbrun L, 2016, APPL ACOUST, V114, P79, DOI 10.1016/j.apacoust.2016.07.003
   Galbrun L, 2014, J ACOUST SOC AM, V136, P2609, DOI 10.1121/1.4897313
   HOUTGAST T, 1973, ACUSTICA, V28, P66
   Jeon JY, 2018, APPL ACOUST, V133, P107, DOI 10.1016/j.apacoust.2017.12.016
   Jones Daniel, 1917, ENGLISH PRONOUNCING
   Kang J, 2010, BUILD ENVIRON, V45, P150, DOI 10.1016/j.buildenv.2009.05.014
   Kitapci K, 2016, THESIS
   Long M, 2006, ARCHITECTURAL ACOUST
   Maddieson I., 2008, WORLD ATLAS LANGUAGE
   Maddieson Ian, 2013, WORLD ATLAS LANGUAGE
   Marquis-Favre C, 2005, ACTA ACUST UNITED AC, V91, P626
   Martin-Jones M., 2012, ROUTLEDGE HDB MULTIL
   Osgood C.E., 1957, MEASUREMENT MEANING
   PEUTZ VMA, 1971, J AUDIO ENG SOC, V19, P915
   Schafer R.M., 1994, SOUNDSCAPE OUR SONIC
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420
   Wodak R, 2012, LANG SOC, V41, P157, DOI 10.1017/S0047404512000036
   Yang W, 2005, APPL ACOUST, V66, P211, DOI 10.1016/j.apacoust.2004.07.011
NR 23
TC 0
Z9 1
U1 1
U2 14
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0003-682X
EI 1872-910X
J9 APPL ACOUST
JI Appl. Acoust.
PD AUG
PY 2019
VL 151
BP 124
EP 136
DI 10.1016/j.apacoust.2019.03.001
PG 13
WC Acoustics
SC Acoustics
GA HT7UY
UT WOS:000464771100012
OA Bronze
DA 2021-02-24
ER

PT J
AU O' Leary, D
   Lee, A
   O'Toole, C
   Gibbon, F
AF O' Leary, Deirdre
   Lee, Alice
   O'Toole, Ciara
   Gibbon, Fiona
TI Perceptual and acoustic evaluation of speech production in Down
   syndrome: A case series
SO CLINICAL LINGUISTICS & PHONETICS
LA English
DT Article
DE Intelligibility; acoustic analysis; speech perception
ID SPECTRAL CHARACTERISTICS; YOUNG-ADULTS; CHILDREN; INTELLIGIBILITY;
   VOICE; HYPERNASALITY; ADOLESCENTS; PARAMETERS; PHONATION; PROSODY
AB People with Down syndrome (DS) can experience difficulties with speech production that can impact on speech intelligibility. In previous research, both perceptual and acoustic analysis has shown that people with DS can have difficulties with speech production in the areas of respiration, phonation, articulation, resonance and prosody. However, these studies have investigated various aspects of speech production separately. No study has examined all components of speech production in one single study and considered how these components, if impaired, may impact on speech intelligibility in DS. This paper presents the data of three male speakers with DS and three age- and gender-matched controls as a case series. The participants' speech samples were analysed using a number of perceptual and acoustic parameters, across the major components of speech production - respiration, phonation, articulation, resonance, and prosody. Results showed that different areas of speech production were affected in each participant, to different extents. The main perceptual difficulties included poor voice quality, monopitch, and monoloudness. Acoustic findings showed a higher mean F0, lower harmonics-to-noise ratio and longer voice onset times. These preliminary findings show that people with DS can present with mixed profiles of speech production that can affect speech intelligibility. When assessing speech production in DS, clinicians need to evaluate all components of speech production and consider how they may be impacting intelligibility.
C1 [O' Leary, Deirdre; Lee, Alice; O'Toole, Ciara; Gibbon, Fiona] Univ Coll Cork, Dept Speech & Hearing Sci, Brookfield Hlth Sci Bldg,Coll Rd, Cork, Ireland.
RP O' Leary, D (corresponding author), Univ Coll Cork, Dept Speech & Hearing Sci, Brookfield Hlth Sci Bldg,Coll Rd, Cork, Ireland.
EM deirdre.ol@ucc.ie
RI Lee, Alice Su Ying/G-1846-2011
OI Lee, Alice Su Ying/0000-0003-0188-0612
FU Irish Research Council [Government of Ireland Postgraduate Scholarship
   Programme]
FX This work was supported by the Irish Research Council [Government of
   Ireland Postgraduate Scholarship Programme].
CR Albertini G, 2010, RES DEV DISABIL, V31, P995, DOI 10.1016/j.ridd.2010.04.024
   Bang YI, 2013, NEUROREHABILITATION, V32, P649, DOI 10.3233/NRE-130887
   Barbosa de Lima D. C., 2014, REV CEFAC, V16, P592
   Barnes E, 2009, J SPEECH LANG HEAR R, V52, P1048, DOI 10.1044/1092-4388(2009/08-0001)
   Boersma P., 2018, PRAAT VERSION 6 0 28
   BrownSweeney SG, 1997, CLIN LINGUIST PHONET, V11, P345, DOI 10.3109/02699209708985200
   Bunton K, 2011, CLIN LINGUIST PHONET, V25, P321, DOI 10.3109/02699206.2010.535647
   Chapman RS, 1998, J SPEECH LANG HEAR R, V41, P861, DOI 10.1044/jslhr.4104.861
   Clark J, 2007, TLS-TIMES LIT SUPPL, P3
   Cleland J, 2009, CLIN LINGUIST PHONET, V23, P926, DOI 10.3109/02699200903061776
   Corrales-Astorgano M, 2018, SPEECH COMMUN, V99, P90, DOI 10.1016/j.specom.2018.03.006
   DARLEY FL, 1969, J SPEECH HEAR RES, V12, P246, DOI 10.1044/jshr.1202.246
   De Bodt MS, 2002, J COMMUN DISORD, V35, P283, DOI 10.1016/S0021-9924(02)00065-5
   DEKROM G, 1995, J SPEECH HEAR RES, V38, P794, DOI 10.1044/jshr.3804.794
   Dellavia C, 2007, EUR J ORTHODONT, V29, P417, DOI 10.1093/ejo/cjm026
   Fawcett S., 2008, DOWN SYNDROME Q, V10, P4
   Goldman R., 2015, GOLDMAN FRISTOE TEST, V3rd edition.
   Hacki T, 1996, Logoped Phoniatr Vocol, V21, P123, DOI 10.3109/14015439609098879
   HOLLIEN H, 1965, J SPEECH HEAR DISORD, V30, P344, DOI 10.1044/jshd.3004.344
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   Karlsson H. B., 2003, ACOUSTIC MOMENTS DAT
   Karmiloff-Smith Annette, 2016, F1000Res, V5, DOI 10.12688/f1000research.7506.1
   Kataoka R, 2001, J ACOUST SOC AM, V109, P2181, DOI 10.1121/1.1360717
   Kempster GB, 2009, AM J SPEECH-LANG PAT, V18, P124, DOI 10.1044/1058-0360(2008/08-0017)
   Kent RD, 2013, J SPEECH LANG HEAR R, V56, P178, DOI 10.1044/1092-4388(2012/12-0148)
   KENT RD, 1987, J SPEECH HEAR DISORD, V52, P367, DOI 10.1044/jshd.5204.367
   KENT RD, 1989, CLIN LINGUIST PHONET, V3, P347, DOI 10.3109/02699208908985295
   KLINE LS, 1980, AM J MENT DEF, V85, P153
   Kumin Libby, 2006, Downs Syndr Res Pract, V10, P10, DOI 10.3104/reports.301
   Kummer AW, 1996, LANG SPEECH HEAR SER, V27, P271, DOI 10.1044/0161-1461.2703.271
   Lansford KL, 2014, J SPEECH LANG HEAR R, V57, P57, DOI 10.1044/1092-4388(2013/12-0262)
   Lee MT, 2009, J VOICE, V23, P82, DOI 10.1016/j.jvoice.2007.04.006
   Liu HM, 2005, J ACOUST SOC AM, V117, P3879, DOI 10.1121/1.1898623
   Magnus LC, 2011, CAN J SPEECH-LANG PA, V35, P32
   Maslan J, 2011, J VOICE, V25, P709, DOI [10.1016/j.jvoice.2010.10.002, 10.1016/j.jvoicc.2010.10.002]
   MONTAGUE JC, 1978, FOLIA PHONIATR, V30, P245, DOI 10.1159/000264133
   MORAN MJ, 1982, AM J MENT DEF, V86, P553
   Moura CP, 2008, J VOICE, V22, P34, DOI 10.1016/j.jvoice.2006.08.011
   Nissen SL, 2005, J ACOUST SOC AM, V118, P2570, DOI 10.1121/1.2010407
   Pettinato M., 2009, SYNDROME RES PRACTIC, P1, DOI [10.3104/reports.2036, DOI 10.3104/REPORTS.2036]
   Pryce M., 1994, DOWN SYNDR RES PRACT, V2, P106, DOI [10.3104/reports.39, DOI 10.3104/research, DOI 10.3104/REPORTS.39]
   Ramig L., 1992, INTELLIGIBILITY SPEE, P119, DOI DOI 10.1075/SSPCL.1.05RAM
   Rochet-Capellan A., 2015, 18 INT C PHON SCI IC
   Rodger R., 2009, THESIS
   ROLFE CR, 1979, FOLIA PHONIATR, V31, P177, DOI 10.1159/000264164
   Rosin M. M., 1988, J CHILDHOOD COMMUNIC, V12, P49, DOI DOI 10.1177/152574018801200105
   Sands K, 2002, J INT PHON ASSOC, V32, P2, DOI [10.1558/ijsll.v23i2.30345, DOI 10.1558/IJSLL.V23I2.30345]
   Seifpanahi S, 2011, FOLIA PHONIATR LOGO, V63, P72, DOI 10.1159/000316326
   SHRIBERG LD, 1990, J SPEECH HEAR RES, V33, P627, DOI 10.1044/jshr.3304.627
   VanBorsel J, 1996, EUR J DISORDER COMM, V31, P415
   Vorperian H. K., 2014, MOT SPEECH C SAR FL
   Vuorenkoski V., 1971, SPEECH TRANSMISSION, V12, P68
   Weismer G, 2012, J NEUROLINGUIST, V25, P74, DOI 10.1016/j.jneuroling.2011.08.006
   Wild A, 2018, AM J SPEECH-LANG PAT, V27, P222, DOI 10.1044/2017_AJSLP-17-0002
   World Health Organization, GEN HUM DIS
   Yorkston K. M., 1996, AM J SPEECH-LANG PAT, V5, P55, DOI DOI 10.1044/1058-0360.0501.55
   Yorkston K. M., 1984, ASSESSMENT INTELLIGI
   Zampini L, 2016, INT J LANG COMM DIS, V51, P74, DOI 10.1111/1460-6984.12186
NR 58
TC 1
Z9 2
U1 1
U2 4
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0269-9206
EI 1464-5076
J9 CLIN LINGUIST PHONET
JI Clin. Linguist. Phon.
PD FEB 1
PY 2020
VL 34
IS 1-2
SI SI
BP 72
EP 91
DI 10.1080/02699206.2019.1611925
EA JUL 2019
PG 20
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA KB3WR
UT WOS:000478234100001
PM 31345071
DA 2021-02-24
ER

PT J
AU Rahman, TTA
   Kader, HAA
   Aziz, TTA
AF Rahman, Tayseer Taha Abdel
   Kader, Hesham Abd El Aty Abdel
   Aziz, Tougan Taha Abdel
TI Audiological correlates of cone beam computed tomography (CBCT) in
   cochlear implant recipients
SO HEARING BALANCE AND COMMUNICATION
LA English
DT Article
DE Audiological correlates; cone beam computed tomography; cochlear
   implant; early speech perception in noise
ID TEMPORAL BONE; ELECTRODE; INSERTION; POSITION; TRAUMA
AB Objectives: To evaluate the role of Cone beam CT (CBCT) regarding the intracochlear electrode position, the exact localization of the electrode in either the Scala tympani or Scala vestibuli and any accompanying inner ear trauma to the delicate intracochlear structures and furthermore correlate these findings with the hearing thresholds and speech tests in patients with unilateral cochlear implant (CI).
   Method: A total number of 20 subjects were examined in this study, 6 males and 14 females, their ages ranged from 3 to 10 years who underwent cochlear implantation. CBCT was done to the entire study group 3 months after surgery. After one year, audio logical evaluation was done in the form of aided warble tone response, aided speech reception threshold and early speech perception test (ESP) both in quiet and in noise. The study group was subdivided according to the degree of inner ear trauma into four groups: grade 0 trauma (9 subjects), grade I trauma (3 subjects), grade II trauma (3 subjects), grade III trauma (5 subjects).
   Results: There was a significant difference among no trauma patients and trauma patients regarding the insertion angle, aided threshold at 250 Hz, percentage of working electrodes and ESP in noise test. Moreover, significant inverse correlation was present between the grade of trauma and both ESP in noise and the percentage of working electrodes.
   Conclusions: The optimal image quality and the small radiation dose renders CBCT as an optimal and secure imaging tool for the assessment of the CI electrode location and evaluation of inner ear trauma as it affects postoperative programing and hearing perspectives.
C1 [Rahman, Tayseer Taha Abdel; Aziz, Tougan Taha Abdel] Ain Shams Univ, Fac Med, Cairo, Egypt.
   [Kader, Hesham Abd El Aty Abdel] Ain Shams Univ, Fac Med, Oto Rhino Laryngol Dept, Cairo, Egypt.
RP Rahman, TTA (corresponding author), Ain Shams Univ, Fac Med, Cairo, Egypt.
EM tayseerhesham2005@gmail.com
OI Taha, Tougan/0000-0002-8275-6498
CR Aschendorff A, 2007, EAR HEARING, V28, p75S, DOI 10.1097/AUD.0b013e318031542e
   Barker E, 2009, OTOLARYNG HEAD NECK, V140, P697, DOI 10.1016/j.otohns.2008.12.046
   Bartling SH, 2006, OTOL NEUROTOL, V27, P491, DOI 10.1097/00129492-200606000-00010
   CLARK G, 2003, AIP SER MOD AC SIG, pR31
   Cushing SL, 2012, ACTA OTO-LARYNGOL, V132, P361, DOI 10.3109/00016489.2011.644805
   Czerny C, 1997, AM J ROENTGENOL, V169, P1689, DOI 10.2214/ajr.169.6.9393191
   Dalbert A, 2016, OTOL NEUROTOL, V37, P446, DOI 10.1097/MAO.0000000000000998
   Dammann F, 2015, AWMF, P417
   De Seta D, 2016, OTOLARYNG HEAD NECK, V155, P485, DOI 10.1177/0194599816645774
   Dietz A, 2016, EUR ARCH OTO-RHINO-L, V273, P1411, DOI 10.1007/s00405-015-3716-4
   El Kholi W, 2001, EGYPT J OTOLARYNGOL, V18, P1
   Eshraghi AA, 2003, LARYNGOSCOPE, V113, P415, DOI 10.1097/00005537-200303000-00005
   Frijns JHM, 2002, EAR HEARING, V23, P184, DOI 10.1097/00003446-200206000-00003
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052
   Greisiger Ralf, 2015, Cochlear Implants Int, V16 Suppl 4, P1, DOI 10.1080/14670100.2015.1110372
   Guldner C, 2012, EUR ARCH OTO-RHINO-L, V269, P767, DOI 10.1007/s00405-011-1719-3
   MARSH MA, 1993, AM J OTOL, V14, P386
   Pearl MS, 2014, AM J NEURORADIOL, V35, P1202, DOI 10.3174/ajnr.A3814
   Rakszawski B, 2016, J AM ACAD AUDIOL, V27, P85, DOI 10.3766/jaaa.14058
   Richter B, 2001, LARYNGOSCOPE, V111, P837, DOI 10.1097/00005537-200105000-00015
   Sennaroglu Levent, 2010, Cochlear Implants Int, V11, P4, DOI 10.1002/cii.416
   Soliman S, 1984, THESIS
   Vaerenberg B, 2014, SCI WORLD J, DOI 10.1155/2014/501738
   Wardrop P, 2005, HEARING RES, V203, P68, DOI 10.1016/j.heares.2004.11.007
   Witte RJ, 2003, RADIOGRAPHICS, V23, P1185, DOI 10.1148/rg.235025046
   Wolfe J, 2012, OTOL NEUROTOL, V33, P553, DOI 10.1097/MAO.0b013e31825367a5
   Xu J, 2000, AM J OTOL, V21, P49, DOI 10.1016/S0196-0709(00)80075-7
NR 27
TC 0
Z9 0
U1 0
U2 2
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2169-5717
EI 2169-5725
J9 HEARING BALANC COMMU
JI Hearing Balanc. Commun.
PY 2019
VL 17
IS 4
BP 249
EP 256
DI 10.1080/21695717.2019.1644861
EA JUL 2019
PG 8
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA JP2BZ
UT WOS:000477609200001
DA 2021-02-24
ER

PT J
AU Kayser, C
AF Kayser, Christoph
TI Evidence for the Rhythmic Perceptual Sampling of Auditory Scenes
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE hearing; auditory perception; rhythmic perception; reverse correlation;
   perceptual weights; delta band; theta band
ID NEURAL OSCILLATIONS; SELECTIVE ATTENTION; SPEECH-PERCEPTION; DECISION;
   PHASE; FLUCTUATIONS; EXCITABILITY; STIMULATION; INFORMATION; ENTRAINMENT
AB Converging results suggest that perception is controlled by rhythmic processes in the brain. In the auditory domain, neuroimaging studies show that the perception of sounds is shaped by rhythmic activity prior to the stimulus, and electrophysiological recordings have linked delta and theta band activity to the functioning of individual neurons. These results have promoted theories of rhythmic modes of listening and generally suggest that the perceptually relevant encoding of acoustic information is structured by rhythmic processes along auditory pathways. A prediction from this perspective-which so far has not been tested-is that such rhythmic processes also shape how acoustic information is combined over time to judge extended soundscapes. The present study was designed to directly test this prediction. Human participants judged the overall change in perceived frequency content in temporally extended (1.2-1.8 s) soundscapes, while the perceptual use of the available sensory evidence was quantified using psychophysical reverse correlation. Model-based analysis of individual participant's perceptual weights revealed a rich temporal structure, including linear trends, a U-shaped profile tied to the overall stimulus duration, and importantly, rhythmic components at the time scale of 1-2 Hz. The collective evidence found here across four versions of the experiment supports the notion that rhythmic processes operating on the delta time scale structure how perception samples temporally extended acoustic scenes.
C1 [Kayser, Christoph] Bielefeld Univ, Ctr Excellence, Dept Cognit Neurosci & Cognit Interact Technol, Bielefeld, Germany.
RP Kayser, C (corresponding author), Bielefeld Univ, Ctr Excellence, Dept Cognit Neurosci & Cognit Interact Technol, Bielefeld, Germany.
EM christoph.kayser@uni-bielefeld.de
RI Kayser, Christoph/A-3203-2012
OI Kayser, Christoph/0000-0001-7362-5704
FU European Research Council (ERC-2014-CoG) [646657]; German Research
   Foundation (DFG)German Research Foundation (DFG); Bielefeld University
FX CK is supported by the European Research Council (ERC-2014-CoG; grant No
   646657), German Research Foundation (DFG) and the Open Access
   Publication Fund of Bielefeld University. The funders had no role in
   designing the research.
CR Barnes R, 2000, COGNITIVE PSYCHOL, V41, P254, DOI 10.1006/cogp.2000.0738
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Burnham KP, 2004, SOCIOL METHOD RES, V33, P261, DOI 10.1177/0049124104268644
   Busch NA, 2010, P NATL ACAD SCI USA, V107, P16048, DOI 10.1073/pnas.1004801107
   Busch NA, 2009, J NEUROSCI, V29, P7869, DOI 10.1523/JNEUROSCI.0113-09.2009
   Chandrasekaran C, 2009, J NEUROPHYSIOL, V101, P773, DOI 10.1152/jn.90843.2008
   Chauvin A, 2005, J VISION, V5, P659, DOI 10.1167/5.9.1
   Daube C, 2019, CURR BIOL, V29, P1924, DOI 10.1016/j.cub.2019.04.067
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Drugowitsch J, 2016, NEURON, V92, P1398, DOI 10.1016/j.neuron.2016.11.005
   Eckstein MP, 2002, J VISION, V2, pI, DOI 10.1167/2.1.i
   Edwards E, 2013, HEARING RES, V305, P113, DOI 10.1016/j.heares.2013.08.017
   Fiebelkorn IC, 2011, J NEUROSCI, V31, P9971, DOI 10.1523/JNEUROSCI.1338-11.2011
   Garcia-Perez MA, 1998, VISION RES, V38, P1861, DOI 10.1016/S0042-6989(97)00340-4
   Gelman A, 2014, STAT COMPUT, V24, P997, DOI 10.1007/s11222-013-9416-2
   Ghitza O, 2009, PHONETICA, V66, P113, DOI 10.1159/000208934
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Guo W, 2017, NEURON, V95, P180, DOI 10.1016/j.neuron.2017.05.019
   Haegens S, 2018, NEUROSCI BIOBEHAV R, V86, P150, DOI 10.1016/j.neubiorev.2017.12.002
   Helfrich RF, 2018, J NEUROPHYSIOL, V119, P1251, DOI 10.1152/jn.00810.2017
   Henry MJ, 2016, J NEUROSCI, V36, P860, DOI 10.1523/JNEUROSCI.2191-15.2016
   Henry MJ, 2014, P NATL ACAD SCI USA, V111, P14935, DOI 10.1073/pnas.1408741111
   Henry MJ, 2012, P NATL ACAD SCI USA, V109, P20095, DOI 10.1073/pnas.1213390109
   Hickok G, 2015, PSYCHOL SCI, V26, P1006, DOI 10.1177/0956797615576533
   Ho HT, 2017, CURR BIOL, V27, P3643, DOI 10.1016/j.cub.2017.10.017
   HURVICH CM, 1991, BIOMETRIKA, V78, P499
   Iemi L, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0430-17.2018
   Kayser C, 2019, BIORXIV PREPRINT, DOI [10.1101/618652, DOI 10.1101/618652]
   Kayser C, 2015, J NEUROSCI, V35, P7750, DOI 10.1523/JNEUROSCI.0268-15.2015
   Kayser SJ, 2016, P NATL ACAD SCI USA, V113, P4842, DOI 10.1073/pnas.1524087113
   Keitel A, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2004473
   Lakatos P, 2005, J NEUROPHYSIOL, V94, P1904, DOI 10.1152/jn.00263.2005
   Lakatos P, 2016, NAT NEUROSCI, V19, P1707, DOI 10.1038/nn.4386
   Lakatos P, 2013, NEURON, V77, P750, DOI 10.1016/j.neuron.2012.11.034
   Landau AN, 2012, CURR BIOL, V22, P1000, DOI 10.1016/j.cub.2012.03.054
   Makalic E., 2016, HIGH DIMENSIONAL BAY, P1189
   Marmarelis V. Z., 1978, ANAL PHYSL SYSTEMS W
   McNair SW, 2019, NEUROIMAGE, V186, P22, DOI 10.1016/j.neuroimage.2018.10.085
   Mulder MJ, 2013, ATTEN PERCEPT PSYCHO, V75, P1048, DOI 10.3758/s13414-013-0447-8
   Neri P, 2002, NAT NEUROSCI, V5, P812, DOI 10.1038/nn886
   Ng BSW, 2012, J NEUROSCI, V32, P12268, DOI 10.1523/JNEUROSCI.1877-12.2012
   O'Connell MN, 2014, J NEUROSCI, V34, P16496, DOI 10.1523/JNEUROSCI.2055-14.2014
   Okazawa G, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-05797-y
   Palminteri S, 2017, TRENDS COGN SCI, V21, P425, DOI 10.1016/j.tics.2017.03.011
   Rigoux L, 2014, NEUROIMAGE, V84, P971, DOI 10.1016/j.neuroimage.2013.08.065
   Romei V, 2008, CEREB CORTEX, V18, P2010, DOI 10.1093/cercor/bhm229
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Schroeder CE, 2009, TRENDS NEUROSCI, V32, P9, DOI 10.1016/j.tins.2008.09.012
   Simmons JP, 2011, PSYCHOL SCI, V22, P1359, DOI 10.1177/0956797611417632
   Song K, 2014, J NEUROSCI, V34, P4837, DOI 10.1523/JNEUROSCI.4856-13.2014
   Strauss A, 2015, J NEUROSCI, V35, P3256, DOI 10.1523/JNEUROSCI.3357-14.2015
   ten Oever S, 2015, P NATL ACAD SCI USA, V112, P15833, DOI 10.1073/pnas.1517519112
   VanRullen R, 2016, TRENDS COGN SCI, V20, P723, DOI 10.1016/j.tics.2016.07.006
   VanRullen R, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0214
   VanRullen R, 2012, CURR BIOL, V22, P995, DOI 10.1016/j.cub.2012.03.050
   VanRullen R, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00203
   VORBERG D, 1987, NATURWISSENSCHAFTEN, V74, P446, DOI 10.1007/BF00446104
   Waskom ML, 2018, CURR BIOL, V28, P3850, DOI 10.1016/j.cub.2018.10.021
   Wilsch A, 2018, NEUROIMAGE, V172, P766, DOI 10.1016/j.neuroimage.2018.01.038
   Wostmann M, 2016, P NATL ACAD SCI USA, V113, P3873, DOI 10.1073/pnas.1523357113
   Wyart V, 2012, NEURON, V76, P847, DOI 10.1016/j.neuron.2012.09.015
   Yi HG, 2019, NEURON, V102, P1096, DOI 10.1016/j.neuron.2019.04.023
   Zoefel B., 2019, BIORXIV, DOI [10.1101/517243, DOI 10.1101/517243]
   Zoefel B, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00296
   Zoefel B, 2017, LANG COGN NEUROSCI, V32, P910, DOI 10.1080/23273798.2016.1247970
   Zoefel B, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3389/fnhum.2015.00651, 10.1038/NATURE11020]
   Zoefel B, 2015, NEUROREPORT, V26, P773, DOI 10.1097/WNR.0000000000000422
NR 67
TC 4
Z9 4
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD JUL 23
PY 2019
VL 13
AR 249
DI 10.3389/fnhum.2019.00249
PG 10
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA IL1AZ
UT WOS:000477032600001
PM 31396064
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Burghard, A
   Voigt, MB
   Kral, A
   Hubka, P
AF Burghard, Alice
   Voigt, Mathias Benjamin
   Kral, Andrej
   Hubka, Peter
TI Categorical processing of fast temporal sequences in the guinea pig
   auditory brainstem
SO COMMUNICATIONS BIOLOGY
LA English
DT Article
ID SPEECH-PERCEPTION; NOISE; CAT; DISCRIMINATION; REPRESENTATION;
   GENERATORS; RESOLUTION; RESPONSES; SOUNDS; CORTEX
AB Discrimination of temporal sequences is crucial for auditory object recognition, phoneme categorization and speech understanding. The present study shows that auditory brainstem responses (ABR) to pairs of noise bursts separated by a short gap can be classified into two distinct groups based on the ratio of gap duration to initial noise burst duration in guinea pigs. If this ratio was smaller than 0.5, the ABR to the trailing noise burst was strongly suppressed. On the other hand, if the initial noise burst duration was short compared to the gap duration (a ratio greater than 0.5), a release from suppression and/or enhancement of the trailing ABR was observed. Consequently, initial noise bursts of shorter duration caused a faster transition between response classes than initial noise bursts of longer duration. We propose that the described findings represent a neural correlate of subcortical categorical preprocessing of temporal sequences in the auditory system.
C1 [Burghard, Alice; Voigt, Mathias Benjamin; Kral, Andrej; Hubka, Peter] Hannover Med Sch, Inst Audioneurotechnol, D-30625 Hannover, Germany.
   [Burghard, Alice; Voigt, Mathias Benjamin; Kral, Andrej; Hubka, Peter] Hannover Med Sch, Dept Expt Otol, ENT Clin, D-30625 Hannover, Germany.
   [Burghard, Alice] Univ Connecticut, Dept Neurosci, Hlth Ctr, Farmington, CT 06030 USA.
RP Hubka, P (corresponding author), Hannover Med Sch, Inst Audioneurotechnol, D-30625 Hannover, Germany.; Hubka, P (corresponding author), Hannover Med Sch, Dept Expt Otol, ENT Clin, D-30625 Hannover, Germany.
EM hubka.peter@mh-hannover.de
RI Hubka, Peter/X-1306-2019
OI Hubka, Peter/0000-0002-2221-9252; Voigt, Mathias/0000-0003-2678-722X;
   Burghard, Alice/0000-0002-6482-1815; Kral, Andrej/0000-0002-7762-4642
FU Deutsche ForschungsgemeinschaftGerman Research Foundation (DFG) [Exc
   1077, SPP 1608]; MedEl Comp., Innsbruck, Austria; German Research
   Foundation (DFG)German Research Foundation (DFG); Open Access
   Publication Fund of Hannover Medical School (MHH)
FX The present study was supported by Deutsche Forschungsgemeinschaft (Exc
   1077 and SPP 1608) and MedEl Comp., Innsbruck, Austria. We thank and
   appreciate the technical support provided by Daniela and Karl-Jurgen
   Kuhne. We acknowledge support by the German Research Foundation (DFG)
   and the Open Access Publication Fund of Hannover Medical School (MHH).
CR Anderson LA, 2016, J NEUROSCI, V36, P1977, DOI 10.1523/JNEUROSCI.1652-15.2016
   Banai K, 2009, CEREB CORTEX, V19, P2699, DOI 10.1093/cercor/bhp024
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bidelman GM, 2014, NEUROBIOL AGING, V35, P2526, DOI 10.1016/j.neurobiolaging.2014.05.006
   Bidelman GM, 2014, NEUROSCI LETT, V572, P53, DOI 10.1016/j.neulet.2014.04.037
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Bizley JK, 2013, NAT REV NEUROSCI, V14, P693, DOI 10.1038/nrn3565
   BLAIR RC, 1993, PSYCHOPHYSIOLOGY, V30, P518, DOI 10.1111/j.1469-8986.1993.tb02075.x
   Catterall WA, 2008, NEURON, V59, P882, DOI 10.1016/j.neuron.2008.09.005
   Chandrasekaran B, 2009, NEURON, V64, P311, DOI 10.1016/j.neuron.2009.10.006
   CHOI HI, 1989, IEEE T ACOUST SPEECH, V37, P862, DOI 10.1109/ASSP.1989.28057
   Eggermont JJ, 2001, HEARING RES, V157, P1, DOI 10.1016/S0378-5955(01)00259-3
   Frisina DR, 1997, HEARING RES, V106, P95, DOI 10.1016/S0378-5955(97)00006-3
   FULLERTON BC, 1987, ELECTROEN CLIN NEURO, V66, P547, DOI 10.1016/0013-4694(87)90102-7
   Goldstone RL, 2010, WIRES COGN SCI, V1, P69, DOI 10.1002/wcs.26
   Griffiths T. D., NAT REV NEUROSCI
   Griffiths TD, 2001, NAT NEUROSCI, V4, P633, DOI 10.1038/88459
   HARRIS DM, 1979, J NEUROPHYSIOL, V42, P1083
   Henry KS, 2011, J COMP PHYSIOL A, V197, P351, DOI 10.1007/s00359-010-0619-0
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   Hornickel J, 2009, P NATL ACAD SCI USA, V106, P13022, DOI 10.1073/pnas.0901123106
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   Kraus N, 2016, ANNU REV PSYCHOL, V67, P83, DOI 10.1146/annurev-psych-122414-033318
   KUHL PK, 1978, J ACOUST SOC AM, V63, P905, DOI 10.1121/1.381770
   Liberman AM, 2000, TRENDS COGN SCI, V4, P187, DOI 10.1016/S1364-6613(00)01471-6
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Lotto A. J., 2016, NEUROBIOLOGY LANGUAG, P185
   Mannell R., 2008, SPEECH ACOUSTICS SPE
   Melcher JR, 1996, HEARING RES, V93, P52, DOI 10.1016/0378-5955(95)00200-6
   Melcher JR, 1996, HEARING RES, V93, P1, DOI 10.1016/0378-5955(95)00178-6
   Miller EK, 2003, CURR OPIN NEUROBIOL, V13, P198, DOI 10.1016/S0959-4388(03)00037-0
   MORSE PA, 1975, PERCEPT PSYCHOPHYS, V17, P9, DOI 10.3758/BF03203991
   Nelken I, 2008, CURR OPIN NEUROBIOL, V18, P413, DOI 10.1016/j.conb.2008.08.014
   Nourski KV, 2018, J NEUROSCI, V38, P8441, DOI 10.1523/JNEUROSCI.0967-18.2018
   Oxenham AJ, 2018, ANNU REV PSYCHOL, V69, P27, DOI 10.1146/annurev-psych-122216-011635
   Perez CA, 2013, CEREB CORTEX, V23, P670, DOI 10.1093/cercor/bhs045
   Powers D. M., 2011, J MACH LEARN TECHNOL, V2, P37, DOI DOI 10.9735/2229-3981
   Prather JF, 2009, NAT NEUROSCI, V12, P221, DOI 10.1038/nn.2246
   Raz A, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00191
   Russ BE, 2007, HEARING RES, V229, P204, DOI 10.1016/j.heares.2006.10.010
   Sharma A, 1999, J ACOUST SOC AM, V106, P1078, DOI 10.1121/1.428048
   Steinschneider M, 2005, CEREB CORTEX, V15, P170, DOI 10.1093/cercor/bhh120
   Steinschneider M, 2013, HEARING RES, V305, P57, DOI 10.1016/j.heares.2013.05.013
   Stronks HC, 2010, HEARING RES, V260, P20, DOI 10.1016/j.heares.2009.10.015
   SUPIN AY, 1995, J ACOUST SOC AM, V97, P2586, DOI 10.1121/1.411913
   Weiss MW, 2015, J NEUROSCI, V35, P1687, DOI 10.1523/JNEUROSCI.3680-14.2015
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
NR 48
TC 0
Z9 0
U1 0
U2 1
PU NATURE PUBLISHING GROUP
PI NEW YORK
PA 75 VARICK ST, 9TH FLR, NEW YORK, NY 10013-1917 USA
EI 2399-3642
J9 COMMUN BIOL
JI Commun. Biol.
PD JUL 19
PY 2019
VL 2
AR 265
DI 10.1038/s42003-019-0472-9
PG 9
WC Biology; Multidisciplinary Sciences
SC Life Sciences & Biomedicine - Other Topics; Science & Technology - Other
   Topics
GA IK9ST
UT WOS:000476937100005
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Roque, L
   Karawani, H
   Gordon-Salant, S
   Anderson, S
AF Roque, Lindsey
   Karawani, Hanin
   Gordon-Salant, Sandra
   Anderson, Samira
TI Effects of Age, Cognition, and Neural Encoding on the Perception of
   Temporal Speech Cues
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE aging; temporal processing; speech perception; cognition;
   frequency-following response; cortical auditory-evoked potentials
ID PRIMARY AUDITORY-CORTEX; HEARING-LOSS; PROCESSING-SPEED; RECOGNITION
   PERFORMANCE; PSYCHOMETRIC FUNCTION; OLDER LISTENERS; VISUAL SPEECH;
   AGING AFFECTS; NOISE; BRAIN
AB Older adults commonly report difficulty understanding speech, particularly in adverse listening environments. These communication difficulties may exist in the absence of peripheral hearing loss. Older adults, both with normal hearing and with hearing loss, demonstrate temporal processing deficits that affect speech perception. The purpose of the present study is to investigate aging, cognition, and neural processing factors that may lead to deficits on perceptual tasks that rely on phoneme identification based on a temporal cue - vowel duration. A better understanding of the neural and cognitive impairments underlying temporal processing deficits could lead to more focused aural rehabilitation for improved speech understanding for older adults. This investigation was conducted in younger (YNH) and older normal-hearing (ONH) participants who completed three measures of cognitive functioning known to decline with age: working memory, processing speed, and inhibitory control. To evaluate perceptual and neural processing of auditory temporal contrasts, identification functions for the contrasting word-pair WHEAT and WEED were obtained on a nine-step continuum of vowel duration, and frequency-following responses (FFRs) and cortical auditory-evoked potentials (CAEPs) were recorded to the two endpoints of the continuum. Multiple linear regression analyses were conducted to determine the cognitive, peripheral, and/or central mechanisms that may contribute to perceptual performance. YNH participants demonstrated higher cognitive functioning on all three measures compared to ONH participants. The slope of the identification function was steeper in YNH than in ONH participants, suggesting a clearer distinction between the contrasting words in the YNH participants. FFRs revealed better response waveform morphology and more robust phase-locking in YNH compared to ONH participants. ONH participants also exhibited earlier latencies for CAEP components compared to the YNH participants. Linear regression analyses revealed that cortical processing significantly contributed to the variance in perceptual performance in the WHEAT/WEED identification functions. These results suggest that reduced neural precision contributes to age-related speech perception difficulties that arise from temporal processing deficits.
C1 [Roque, Lindsey; Karawani, Hanin; Gordon-Salant, Sandra; Anderson, Samira] Univ Maryland, Dept Hearing & Speech Sci, College Pk, MD 20742 USA.
   [Karawani, Hanin] Univ Haifa, Dept Commun Sci & Disorders, Haifa, Israel.
RP Anderson, S (corresponding author), Univ Maryland, Dept Hearing & Speech Sci, College Pk, MD 20742 USA.
EM sander22@umd.edu
FU National Institute on Deafness and Other Communication Disorders of the
   National Institutes of Health (NIH) [R21DC015843]; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R21DC015843, R21DC015843, R21DC015843] Funding Source: NIH RePORTER
FX This study was supported by the National Institute on Deafness and Other
   Communication Disorders of the National Institutes of Health (NIH) under
   Award number R21DC015843 (Anderson). The content is solely the
   responsibility of the authors and does not necessarily represent the
   official views of the National Institutes of Health.
CR Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Alain C, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00008
   Anderson S, 2012, J NEUROSCI, V32, P14156, DOI 10.1523/JNEUROSCI.2176-12.2012
   Bellier L, 2015, PSYCHOPHYSIOLOGY, V52, P594, DOI 10.1111/psyp.12369
   Bharadwaj HM, 2015, J NEUROSCI, V35, P2161, DOI 10.1523/JNEUROSCI.3915-14.2015
   Bidelman GM, 2018, NEUROIMAGE, V175, P56, DOI 10.1016/j.neuroimage.2018.03.060
   Bidelman GM, 2014, NEUROBIOL AGING, V35, P2526, DOI 10.1016/j.neurobiolaging.2014.05.006
   Billings CJ, 2015, EAR HEARING, V36, P710, DOI 10.1097/AUD.0000000000000191
   Billings CJ, 2013, JARO-J ASSOC RES OTO, V14, P891, DOI 10.1007/s10162-013-0415-y
   Bramhall NF, 2017, EAR HEARING, V38, pE1, DOI 10.1097/AUD.0000000000000370
   Brodbeck C, 2018, NEUROIMAGE, V172, P162, DOI 10.1016/j.neuroimage.2018.01.042
   Burke DM, 1997, J GERONTOL B-PSYCHOL, V52, pP254, DOI 10.1093/geronb/52B.6.P254
   Carlozzi NE, 2015, ARCH CLIN NEUROPSYCH, V30, P359, DOI 10.1093/arclin/acv031
   CASPARY DM, 1995, EXP GERONTOL, V30, P349, DOI 10.1016/0531-5565(94)00052-5
   Caspary DM, 2008, J EXP BIOL, V211, P1781, DOI 10.1242/jeb.013581
   Clinard CG, 2010, HEARING RES, V264, P48, DOI 10.1016/j.heares.2009.11.010
   Cohena JI, 2017, J ACOUST SOC AM, V141, pEL470, DOI 10.1121/1.4983399
   Daneman M., 2007, COGNITIVE NEUROSCIEN, P21, DOI DOI 10.1093/ACPROF:OSO/9780198570394.003.0002
   de Cheveigne A, 2008, J NEUROSCI METH, V171, P331, DOI 10.1016/j.jneumeth.2008.03.015
   de Villers-Sidani E, 2010, P NATL ACAD SCI USA, V107, P13900, DOI 10.1073/pnas.1007885107
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dey A, 2015, PSYCHOL AGING, V30, P634, DOI 10.1037/pag0000033
   DUBNO JR, 1984, J ACOUST SOC AM, V76, P87, DOI 10.1121/1.391011
   Durrant J.D., 2007, AUDITORY EVOKED POTE
   Fitzgibbons PJ, 1995, J ACOUST SOC AM, V98, P3140, DOI 10.1121/1.413803
   FLORENTINE M, 1980, J SPEECH HEAR RES, V23, P646, DOI 10.1044/jshr.2303.646
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Genova HM, 2012, APPL NEUROPSYCH-ADUL, V19, P132, DOI 10.1080/09084282.2011.643951
   Gordon-Salant S, 2006, J ACOUST SOC AM, V119, P2455, DOI 10.1121/1.2171527
   Gordon-Salant S, 2001, J SPEECH LANG HEAR R, V44, P709, DOI 10.1044/1092-4388(2001/056)
   Gordon-Salant S, 2017, J ACOUST SOC AM, V142, P151, DOI 10.1121/1.4992026
   Gordon-Salant S, 2016, EAR HEARING, V37, P593, DOI 10.1097/AUD.0000000000000316
   Gordon-Salant S, 2010, J ACOUST SOC AM, V128, P3152, DOI 10.1121/1.3495940
   GORDONSALANT S, 1993, J SPEECH HEAR RES, V36, P1276, DOI 10.1044/jshr.3606.1276
   Grose JH, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216519839615
   Grose JH, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517737417
   Gwilliams L, 2018, J NEUROSCI, V38, P7585, DOI 10.1523/JNEUROSCI.0065-18.2018
   Hedden T, 2004, NAT REV NEUROSCI, V5, P87, DOI 10.1038/nrn1323
   HELFER KS, 1990, J SPEECH HEAR RES, V33, P149, DOI 10.1044/jshr.3301.149
   Henry MJ, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15801
   Henshaw H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0062836
   Hughes LF, 2010, HEARING RES, V264, P79, DOI 10.1016/j.heares.2009.09.005
   Jenkins KA, 2018, EAR HEARING, V39, P810, DOI 10.1097/AUD.0000000000000538
   Johns AR, 2018, LANG LINGUIST COMPAS, V12, DOI 10.1111/lnc3.12272
   Juarez-Salinas DL, 2010, J NEUROSCI, V30, P14795, DOI 10.1523/JNEUROSCI.3393-10.2010
   Kerr CC, 2008, BIOL CYBERN, V98, P171, DOI 10.1007/s00422-007-0201-1
   Koeritzer MA, 2018, J SPEECH LANG HEAR R, V61, P740, DOI 10.1044/2017_JSLHR-H-17-0077
   Konrad-Martin D, 2012, J AM ACAD AUDIOL, V23, P18, DOI 10.3766/jaaa.23.1.3
   Liberman MC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162726
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P1131, DOI 10.1093/gerona/glr115
   Lunner T, 2003, INT J AUDIOL, V42, pS49
   Lunner T, 2007, J AM ACAD AUDIOL, V18, P604, DOI 10.3766/jaaa.18.7.7
   Maamor N, 2017, NEUROSCI LETT, V636, P258, DOI 10.1016/j.neulet.2016.11.020
   Matschke R G, 1990, Acta Otolaryngol Suppl, V476, P114
   McClearn GE, 1997, SCIENCE, V276, P1560, DOI 10.1126/science.276.5318.1560
   MOUSHEGIAN G, 1973, ELECTROEN CLIN NEURO, V35, P665, DOI 10.1016/0013-4694(73)90223-X
   Naatanen R, 1999, PSYCHOL BULL, V125, P826, DOI 10.1037/0033-2909.125.6.826
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Parthasarathy A, 2011, NEUROSCIENCE, V192, P619, DOI 10.1016/j.neuroscience.2011.06.042
   Perez-Gonzalez D, 2014, FRONT INTEGR NEUROSC, V8, DOI 10.3389/fnint.2014.00019
   Pichora-Fuller M Kathleen, 2006, Trends Amplif, V10, P29, DOI 10.1177/108471380601000103
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   Presacco A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0213899
   Presacco A, 2016, J NEUROPHYSIOL, V116, P2346, DOI 10.1152/jn.00372.2016
   Presacco A, 2015, EAR HEARING, V36, pE352, DOI 10.1097/AUD.0000000000000193
   PSATTA DM, 1988, ELECTROEN CLIN NEURO, V71, P27, DOI 10.1016/0168-5597(88)90016-0
   Romero Sergio, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P5495
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   Roque L, 2019, J SPEECH LANG HEAR R, V62, P1099, DOI 10.1044/2018_JSLHR-H-ASCC7-18-0076
   Ross B, 2013, BMC NEUROSCI, V14, DOI 10.1186/1471-2202-14-151
   SALTHOUSE TA, 1991, DEV PSYCHOL, V27, P763, DOI 10.1037/0012-1649.27.5.763
   Salthouse TA, 1996, PSYCHOL REV, V103, P403, DOI 10.1037/0033-295X.103.3.403
   Salthouse TA, 2010, BRAIN COGNITION, V73, P51, DOI 10.1016/j.bandc.2010.02.003
   Sarela J, 2005, J MACH LEARN RES, V6, P233
   Schlogl A, 2007, CLIN NEUROPHYSIOL, V118, P98, DOI 10.1016/j.clinph.2006.09.003
   Schmiedt RA, 1996, J NEUROPHYSIOL, V76, P2799
   SCHNEIDER BA, 1994, J ACOUST SOC AM, V95, P980, DOI 10.1121/1.408403
   Sergeyenko Y, 2013, J NEUROSCI, V33, P13686, DOI 10.1523/JNEUROSCI.1783-13.2013
   Skrandies Wolfgang, 2005, Acta Neurol Taiwan, V14, P164
   SMITH JC, 1975, ELECTROEN CLIN NEURO, V39, P465, DOI 10.1016/0013-4694(75)90047-4
   Sumner CJ, 2012, EUR J NEUROSCI, V36, P2428, DOI 10.1111/j.1460-9568.2012.08151.x
   TallonBaudry C, 1996, J NEUROSCI, V16, P4240
   Tan AYY, 2004, J NEUROPHYSIOL, V92, P630, DOI 10.1152/jn.01020.2003
   Tremblay KL, 2003, CLIN NEUROPHYSIOL, V114, P1332, DOI 10.1016/S1388-2457(03)00114-7
   Tulsky DS, 2014, J INT NEUROPSYCH SOC, V20, P599, DOI 10.1017/S135561771400040X
   Verhulst S, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516672186
   Walton JP, 1998, J NEUROSCI, V18, P2764
   Weintraub S, 2013, NEUROLOGY, V80, pS54, DOI 10.1212/WNL.0b013e3182872ded
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1314, DOI 10.3758/BF03194545
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1293, DOI 10.3758/BF03194544
   Wingfield A, 1996, J Am Acad Audiol, V7, P175
   Wingfield A, 2006, J NEUROPHYSIOL, V96, P2830, DOI 10.1152/jn.00628.2006
   Working Group on Speech Understanding and Aging, 1988, J ACOUST SOC AM, V83, P859, DOI DOI 10.1121/1.395965
   Zelazo PD, 2014, J INT NEUROPSYCH SOC, V20, P620, DOI 10.1017/S1355617714000472
   Zhu J, 1999, WECHSLER ABBREVIATED
NR 97
TC 8
Z9 9
U1 0
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD JUL 19
PY 2019
VL 13
AR 749
DI 10.3389/fnins.2019.00749
PG 15
WC Neurosciences
SC Neurosciences & Neurology
GA IK7HO
UT WOS:000476760300001
PM 31379494
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Madsen, SMK
   Marschall, M
   Dau, T
   Oxenham, RJ
AF Madsen, Sara M. K.
   Marschall, Marton
   Dau, Torsten
   Oxenham, Rew J.
TI Speech perception is similar for musicians and non-musicians across a
   wide range of conditions
SO SCIENTIFIC REPORTS
LA English
DT Article
ID MUSICAL EXPERTISE; NOISE; PERCUSSIONISTS; VOCALISTS; HEARING
AB It remains unclear whether musical training is associated with improved speech understanding in a noisy environment, with different studies reaching differing conclusions. Even in those studies that have reported an advantage for highly trained musicians, it is not known whether the benefits measured in laboratory tests extend to more ecologically valid situations. This study aimed to establish whether musicians are better than non-musicians at understanding speech in a background of competing speakers or speech-shaped noise under more realistic conditions, involving sounds presented in space via a spherical array of 64 loudspeakers, rather than over headphones, with and without simulated room reverberation. The study also included experiments testing fundamental frequency discrimination limens (F0DLs), interaural time differences limens (ITDLs), and attentive tracking. Sixty-four participants (32 non-musicians and 32 musicians) were tested, with the two groups matched in age, sex, and IQ as assessed with Raven's Advanced Progressive matrices. There was a significant benefit of musicianship for F0DLs, ITDLs, and attentive tracking. However, speech scores were not significantly different between the two groups. The results suggest no musician advantage for understanding speech in background noise or talkers under a variety of conditions.
C1 [Madsen, Sara M. K.; Marschall, Marton; Dau, Torsten] Tech Univ Denmark, Dept Hlth Technol, Hearing Syst Grp, DK-2800 Lyngby, Denmark.
   [Madsen, Sara M. K.; Oxenham, Rew J.] Univ Minnesota, Dept Psychol, 75 East River Pkwy, Minneapolis, MN 55455 USA.
RP Madsen, SMK (corresponding author), Tech Univ Denmark, Dept Hlth Technol, Hearing Syst Grp, DK-2800 Lyngby, Denmark.; Madsen, SMK (corresponding author), Univ Minnesota, Dept Psychol, 75 East River Pkwy, Minneapolis, MN 55455 USA.
EM madse399@umn.edu
RI ; Dau, Torsten/AAJ-3709-2020
OI Madsen, Sara/0000-0003-2824-7526; Dau, Torsten/0000-0001-8110-4343;
   Oxenham, Andrew/0000-0002-9365-1157
FU Oticon Centre of Excellence for Hearing and Speech Sciences (CHeSS);
   Center for Applied Research (Cahr); Carlsberg FoundationCarlsberg
   Foundation; NIHUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01 DC005216];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC005216, R01DC005216, R01DC005216,
   R01DC005216] Funding Source: NIH RePORTER
FX This study was supported by the Oticon Centre of Excellence for Hearing
   and Speech Sciences (CHeSS), the Center for Applied Research (Cahr), the
   Carlsberg Foundation, and NIH grant R01 DC005216. We would like to thank
   Kevin Woods, Jens Bo Nielsen, and Axel Ahrens for MATLAB code and useful
   advice and Eriksholm Research Centre for providing us with the
   multi-talker version of the Dantale II speech material.
CR Ahrens A, 2019, HEARING RES, V377, P307, DOI 10.1016/j.heares.2019.02.003
   Baer LH, 2015, NEUROIMAGE, V109, P130, DOI 10.1016/j.neuroimage.2014.12.076
   Baskent D, 2016, J ACOUST SOC AM, V139, pEL51, DOI 10.1121/1.4942628
   Behrens T., 2007, P INT S AUD AUD RES, V1, P449
   Bianchi F, 2019, JARO-J ASSOC RES OTO, V20, P263, DOI 10.1007/s10162-018-00710-2
   Boebinger D, 2015, J ACOUST SOC AM, V137, P378, DOI 10.1121/1.4904537
   Boersma P., 2009, PRAAT DOING PHONETIC
   Brand T, 2002, J ACOUST SOC AM, V111, P2801, DOI 10.1121/1.1479152
   Brown CJ, 2017, EAR HEARING, V38, pE74, DOI 10.1097/AUD.0000000000000375
   Clayton KK, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157638
   Coffey E. B., NEUROSCIENCES MUSIC
   Deroche MLD, 2017, J ACOUST SOC AM, V142, P1739, DOI 10.1121/1.5005496
   Favrot S, 2010, ACTA ACUST UNITED AC, V96, P364, DOI 10.3813/AAA.918285
   GORDON Edwin, 2012, LEARNING SEQUENCES M
   Hammershoj D., 2005, BINAURAL TECHNIQUE B
   HAUTUS MJ, 1995, BEHAV RES METH INS C, V27, P46, DOI 10.3758/BF03203619
   *IEC, 1985, IEC26813
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   KLATT DH, 1980, J ACOUST SOC AM, V67, P971, DOI 10.1121/1.383940
   Madsen SMK, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12937-9
   Mankel K, 2018, P NATL ACAD SCI USA, V115, P13129, DOI 10.1073/pnas.1811793115
   McDermott JH, 2010, J ACOUST SOC AM, V128, P1943, DOI 10.1121/1.3478785
   Micheyl C, 2006, HEARING RES, V219, P36, DOI 10.1016/j.heares.2006.05.004
   Nielsen JB, 2009, INT J AUDIOL, V48, P729, DOI 10.1080/14992020903019312
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Parbery-Clark A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018082
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Ruggles DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086980
   Schneider P, 2002, NAT NEUROSCI, V5, P688, DOI 10.1038/nn871
   Slater J, 2017, EUR J NEUROSCI, V45, P952, DOI 10.1111/ejn.13535
   Slater J, 2016, COGN PROCESS, V17, P79, DOI 10.1007/s10339-015-0740-7
   Sorensen A. J., 2017, P INT S AUD AUD RES, V6, P47
   Strait DL, 2012, BRAIN LANG, V123, P191, DOI 10.1016/j.bandl.2012.09.001
   Swaminathan J, 2015, SCI REP-UK, V5, DOI 10.1038/srep14401
   Verde MF, 2006, PERCEPT PSYCHOPHYS, V68, P643, DOI 10.3758/BF03208765
   Wagener K, 2003, INT J AUDIOL, V42, P10, DOI 10.3109/14992020309056080
   Woods KJP, 2015, CURR BIOL, V25, P2238, DOI 10.1016/j.cub.2015.07.043
   Yeend I, 2017, HEARING RES, V353, P224, DOI 10.1016/j.heares.2017.07.006
   Zarate JM, 2012, J ACOUST SOC AM, V132, P984, DOI 10.1121/1.4733535
   Zendel BR, 2012, PSYCHOL AGING, V27, P410, DOI 10.1037/a0024816
NR 40
TC 7
Z9 7
U1 1
U2 9
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD JUL 18
PY 2019
VL 9
AR 10404
DI 10.1038/s41598-019-46728-1
PG 10
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA IJ3ZY
UT WOS:000475845400008
PM 31320656
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Assaneo, MF
   Rimmele, JM
   Orpella, J
   Ripolles, P
   de Diego-Balaguer, R
   Poeppel, D
AF Assaneo, M. F.
   Rimmele, J. M.
   Orpella, J.
   Ripolles, P.
   de Diego-Balaguer, R.
   Poeppel, D.
TI The Lateralization of Speech-Brain Coupling Is Differentially Modulated
   by Intrinsic Auditory and Top-Down Mechanisms
SO FRONTIERS IN INTEGRATIVE NEUROSCIENCE
LA English
DT Article
DE asymmetrical sampling; brain to stimulus synchronization; MEG
   (magnetoencephalography); speech perception; speech envelope tracking
ID CORTICAL ENTRAINMENT; CORTEX; OSCILLATIONS; COMPREHENSION; RESPONSES;
   ENVELOPE; PATTERNS; NOISE; SENSITIVITY; PERCEPTION
AB The lateralization of neuronal processing underpinning hearing, speech, language, and music is widely studied, vigorously debated, and still not understood in a satisfactory manner. One set of hypotheses focuses on the temporal structure of perceptual experience and links auditory cortex asymmetries to underlying differences in neural populations with differential temporal sensitivity (e.g., ideas advanced by Zatorre et al. (2002) and Poeppel (2003). The Asymmetric Sampling in Time theory (AST) (Poeppel, 2003), builds on cytoarchitectonic differences between auditory cortices and predicts that modulation frequencies within the range of, roughly, the syllable rate, are more accurately tracked by the right hemisphere. To date, this conjecture is reasonably well supported, since - while there is some heterogeneity in the reported findings - the predicted asymmetrical entrainment has been observed in various experimental protocols. Here, we show that under specific processing demands, the rightward dominance disappears. We propose an enriched and modified version of the asymmetric sampling hypothesis in the context of speech. Recent work (Rimmele et al., 2018b) proposes two different mechanisms to underlie the auditory tracking of the speech envelope: one derived from the intrinsic oscillatory properties of auditory regions; the other induced by top-down signals coming from other non-auditory regions of the brain. We propose that under non-speech listening conditions, the intrinsic auditory mechanism dominates and thus, in line with AST, entrainment is rightward lateralized, as is widely observed. However, (i) depending on individual brain structural/functional differences, and/or (ii) in the context of specific speech listening conditions, the relative weight of the top-down mechanism can increase. In this scenario, the typically observed auditory sampling asymmetry (and its rightward dominance) diminishes or vanishes.
C1 [Assaneo, M. F.; Orpella, J.; Ripolles, P.; Poeppel, D.] NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
   [Rimmele, J. M.; Poeppel, D.] Max Planck Inst Empir Aesthet, Dept Neurosci, Frankfurt, Germany.
   [de Diego-Balaguer, R.] Univ Barcelona, Dept Cognicio Desenvolupament & Psicol Educ, Barcelona, Spain.
RP Assaneo, MF (corresponding author), NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
EM fassaneo@gmail.com
RI Assaneo, M Florencia/AAI-1525-2020; de Diego-Balaguer, Ruth/V-2131-2017
OI Ripolles, Pablo/0000-0002-8463-3723; Assaneo, M
   florencia/0000-0002-2793-7827; de Diego-Balaguer,
   Ruth/0000-0002-2357-5195
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [2R01DC05660]; FP7 Ideas: European
   Research Council [ERC-StG-313841]; NATIONAL INSTITUTE ON DEAFNESS AND
   OTHER COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC005660,
   R01DC005660, R01DC005660] Funding Source: NIH RePORTER
FX This work was supported by NIH grant 2R01DC05660 (DP) and FP7 Ideas:
   European Research Council grant ERC-StG-313841 (RdD-B).
CR Abrams DA, 2008, J NEUROSCI, V28, P3958, DOI 10.1523/JNEUROSCI.0187-08.2008
   Abrams DA, 2009, J NEUROSCI, V29, P7686, DOI 10.1523/JNEUROSCI.5242-08.2009
   Adachi Y, 2001, IEEE T APPL SUPERCON, V11, P669, DOI 10.1109/77.919433
   Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Assaneo MF, 2019, NAT NEUROSCI, V22, P627, DOI 10.1038/s41593-019-0353-z
   Assaneo MF, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aao3842
   Baayen RH, 1995, CELEX LEXICAL DATABA
   Bidelman GM, 2016, NEUROIMAGE, V124, P581, DOI 10.1016/j.neuroimage.2015.09.020
   Binder JR, 2009, CEREB CORTEX, V19, P2767, DOI 10.1093/cercor/bhp055
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Cogan GB, 2014, NATURE, V507, P94, DOI 10.1038/nature12935
   Crosse MJ, 2015, J NEUROSCI, V35, P14195, DOI 10.1523/JNEUROSCI.1829-15.2015
   Dale AM, 2000, NEURON, V26, P55, DOI 10.1016/S0896-6273(00)81138-1
   de Cheveigne A, 2007, J NEUROSCI METH, V165, P297, DOI 10.1016/j.jneumeth.2007.06.003
   Ding N, 2017, NEUROSCI BIOBEHAV R, V81, P181, DOI 10.1016/j.neubiorev.2017.02.011
   Ding N, 2014, NEUROIMAGE, V88, P41, DOI 10.1016/j.neuroimage.2013.10.054
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Dutoit T., 1996, ACT JOURN ET PAR AV, P441
   Fan LZ, 2016, CEREB CORTEX, V26, P3508, DOI 10.1093/cercor/bhw157
   Federmeier KD, 2007, PSYCHOPHYSIOLOGY, V44, P491, DOI 10.1111/j.1469-8986.2007.00531.x
   Flinker A, 2019, NAT HUM BEHAV, V3, P393, DOI 10.1038/s41562-019-0548-z
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Ghitza O, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00652
   Giraud AL, 2000, J NEUROPHYSIOL, V84, P1588
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Gross J, 2001, P NATL ACAD SCI USA, V98, P694, DOI 10.1073/pnas.98.2.694
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hutsler J, 2003, TRENDS NEUROSCI, V26, P429, DOI 10.1016/S0166-2236(03)00198-X
   Kubanek J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053398
   Lachaux JP, 2000, INT J BIFURCAT CHAOS, V10, P2429, DOI 10.1142/S0218127400001560
   Lopez-Barroso D, 2013, P NATL ACAD SCI USA, V110, P13168, DOI 10.1073/pnas.1301696110
   Lopez-Barroso D, 2011, CEREB CORTEX, V21, P2742, DOI 10.1093/cercor/bhr064
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Makeig S., 1996, P 8 INT C NEUR INF P, DOI [10.1109/ICOSP.2002.1180091, DOI 10.1109/ICOSP.2002.1180091]
   Morillon B, 2017, P NATL ACAD SCI USA, V114, pE8913, DOI 10.1073/pnas.1705373114
   Morillon B, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00248
   Nolte G, 2003, PHYS MED BIOL, V48, P3637, DOI 10.1088/0031-9155/48/22/002
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Park Hyojin, 2018, Lang Cogn Neurosci, V35, P739, DOI 10.1080/23273798.2018.1506589
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Pikovsky A., 2003, SYNCHRONIZATION UNIV, P432, DOI DOI 10.1063/1.1554136
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rimmele J. M., 2019, BIORXIV
   Rimmele JM, 2018, TRENDS COGN SCI, V22, P870, DOI 10.1016/j.tics.2018.08.003
   Rimmele JM, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00039
   Rimmele JM, 2015, CORTEX, V68, P144, DOI 10.1016/j.cortex.2014.12.014
   Rodd JM, 2015, BRAIN LANG, V141, P89, DOI 10.1016/j.bandl.2014.11.012
   Sammler D, 2015, CURR BIOL, V25, P3079, DOI 10.1016/j.cub.2015.10.009
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Scott SK, 2000, BRAIN, V123, P2400, DOI 10.1093/brain/123.12.2400
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   Stolk A, 2013, NEUROIMAGE, V68, P39, DOI 10.1016/j.neuroimage.2012.11.047
   Telkemeyer S, 2009, J NEUROSCI, V29, P14726, DOI 10.1523/JNEUROSCI.1246-09.2009
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Vanvooren S, 2014, J NEUROSCI, V34, P1523, DOI 10.1523/JNEUROSCI.3209-13.2014
   Vinck M, 2011, NEUROIMAGE, V55, P1548, DOI 10.1016/j.neuroimage.2011.01.055
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
   Zoefel B, 2018, CURR BIOL, V28, P401, DOI 10.1016/j.cub.2017.11.071
   Zoefel B, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3389/fnhum.2015.00651, 10.1038/NATURE11020]
NR 67
TC 4
Z9 4
U1 1
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5145
J9 FRONT INTEGR NEUROSC
JI Front. Integr. Neurosci.
PD JUL 17
PY 2019
VL 13
AR 28
DI 10.3389/fnint.2019.00028
PG 11
WC Behavioral Sciences; Neurosciences
SC Behavioral Sciences; Neurosciences & Neurology
GA IM1BQ
UT WOS:000477723800001
PM 31379527
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Liu, SS
   Wang, LC
   Liu, D
AF Liu, Sisi
   Wang, Li-Chih
   Liu, Duo
TI Auditory, Visual, and Cross-Modal Temporal Processing Skills Among
   Chinese Children With Developmental Dyslexia
SO JOURNAL OF LEARNING DISABILITIES
LA English
DT Article
DE cognitive processing; dyslexia; reading disabilities
ID PHONOLOGICAL ABILITY; SPEECH-PERCEPTION; DEFICIT; LANGUAGE; SENSITIVITY;
   AWARENESS; LITERACY; PATTERNS; ACUITY; ORDER
AB The present study examined whether temporal processing (TP) is associated with reading of a non-alphabetic script, that is, Chinese. A total of 126 primary school-aged Chinese children from Taiwan (63 children with dyslexia) completed cross-modal, visual, and auditory temporal order judgment tasks and measures of Chinese reading and literacy-related skills. The results showed that typically developing children and children with dyslexia differed in all TP skills. Structural equation modeling indicated that cross-modal TP contributed independently to character recognition in the entire sample if the significant effects of phonological awareness, orthographic knowledge, and rapid automatized naming were considered. The multi-sample analysis showed that TP did not predict reading in the typical group after controlling for literacy-related skills, but visual and cross-modal TP skills independently contributed to reading in the group with dyslexia in addition to literacy-related skills. Finally, the path analysis indicated that in the typical group, separate TP skills affected reading through literacy-related skills, but visual and cross-modal TP skills had direct effects on character reading in the group with dyslexia. These findings suggest that TP is more important for reading in children with dyslexia than in typically developing children, and the roles of TP in dyslexia require further examination.
C1 [Liu, Sisi; Wang, Li-Chih; Liu, Duo] Educ Univ Hong Kong, Hong Kong, Peoples R China.
RP Wang, LC (corresponding author), Educ Univ Hong Kong, Dept Special Educ & Counselling, Tai Po, 10 Lo Ping Rd, Hong Kong, Peoples R China.
EM wanglca@eduhk.hk
RI WANG, Li-Chih/H-8173-2019
OI WANG, Li-Chih/0000-0002-4011-7305; LIU, Duo/0000-0002-2352-2616
FU Research Support Scheme of Department of Special Education and
   Counseling at The Education University of Hong Kong [RSS2017-18-003]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was partially supported by the Research Support Scheme of Department of
   Special Education and Counseling at The Education University of Hong
   Kong (RSS2017-18-003).
CR Au A, 2001, PERCEPTION, V30, P1127, DOI 10.1068/p3025
   Ben-Yehudah G, 2004, NEUROREPORT, V15, P627, DOI 10.1097/00001756-200403220-00011
   Benasich AA, 1996, INFANT BEHAV DEV, V19, P339, DOI 10.1016/S0163-6383(96)90033-8
   Boets B, 2008, BRAIN LANG, V106, P29, DOI 10.1016/j.bandl.2007.12.004
   Booth JR, 2000, SCI STUD READ, V4, P101, DOI DOI 10.1207/S1532799XSSR0402_02
   Bretherton L, 2003, J EXP CHILD PSYCHOL, V84, P218, DOI 10.1016/S0022-0965(03)00023-7
   CASTLES A, 1993, COGNITION, V47, P149, DOI 10.1016/0010-0277(93)90003-E
   Chen J. H., 2006, RAVENS PROGR MATRICE
   Chung KKH, 2008, ANN DYSLEXIA, V58, P15, DOI 10.1007/s11881-008-0015-4
   Edwards VT, 2004, DEV NEUROPSYCHOL, V25, P321, DOI 10.1207/s15326942dn2503_5
   Farmer ME, 1995, PSYCHON B REV, V2, P460, DOI 10.3758/BF03210983
   Goswami U, 2011, J COGNITIVE NEUROSCI, V23, P325, DOI 10.1162/jocn.2010.21453
   Grondin S, 2010, ATTEN PERCEPT PSYCHO, V72, P561, DOI 10.3758/APP.72.3.561
   Groth K, 2011, READ WRIT, V24, P285, DOI 10.1007/s11145-009-9213-7
   Haden GP, 2015, INT J PSYCHOPHYSIOL, V96, P23, DOI 10.1016/j.ijpsycho.2015.02.024
   Hari R, 1996, NEUROSCI LETT, V205, P138, DOI 10.1016/0304-3940(96)12393-4
   Heiervang E, 2002, J CHILD PSYCHOL PSYC, V43, P931, DOI 10.1111/1469-7610.00097
   Huang H-S., 2001, GRADED CHINESE CHARA
   Hung L. Y., 2006, PHONETIC RADICAL TES
   Hung L. Y., 2006, SEMANTIC RADICAL TES
   Hung L.-Y., 2006, RADICAL RECOGNITION
   Kline R. B., 2011, PRINCIPLES PRACTICE
   Laasonen M, 2002, BRAIN LANG, V80, P340, DOI 10.1006/brln.2001.2593
   Laasonen M, 2001, COGN AFFECT BEHAV NE, V1, P394, DOI 10.3758/CABN.1.4.394
   Liu D, 2016, READ WRIT, V29, P1435, DOI 10.1007/s11145-016-9644-x
   Liu D, 2015, SCI STUD READ, V19, P307, DOI 10.1080/10888438.2015.1030749
   Luo YC, 2013, SCI STUD READ, V17, P22, DOI 10.1080/10888438.2012.689790
   Malenfant N, 2012, CHILD DEV, V83, P1332, DOI 10.1111/j.1467-8624.2012.01777.x
   Marshall CM, 2001, J SPEECH LANG HEAR R, V44, P925, DOI 10.1044/1092-4388(2001/073)
   McArthur G M, 2001, Dyslexia, V7, P150
   Mcbride-Chang C., 2005, READ WRIT, V18, P99, DOI [DOI 10.1007/S11145-004-7343-5, 10.1007/s11145-004-7343-5]
   Meng XZ, 2005, DYSLEXIA, V11, P292, DOI 10.1002/dys.309
   Meyler A, 2005, DYSLEXIA, V11, P93, DOI 10.1002/dys.294
   Muthen L., 1998, MPLUS USERS GUIDE 8, VEighth
   Olson R, 2002, READING WRITING INTE, P127, DOI DOI 10.1023/A:1013872422108
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   Rose SA, 1999, J LEARN DISABIL-US, V32, P256, DOI 10.1177/002221949903200307
   Rosen S, 2003, J PHONETICS, V31, P509, DOI 10.1016/S0095-4470(03)00046-9
   Schulte-Korne G, 1999, EUR CHILD ADOLES PSY, V8, P28
   Schwartz JL, 2004, COGNITION, V93, pB69, DOI 10.1016/j.cognition.2004.01.006
   Siok WT, 2009, CURR BIOL, V19, pR890, DOI 10.1016/j.cub.2009.08.014
   Stein J, 2001, Dyslexia, V7, P12, DOI 10.1002/dys.186
   Talcott JB, 2000, P NATL ACAD SCI USA, V97, P2952, DOI 10.1073/pnas.040546597
   Talcott Joel B, 2002, Dyslexia, V8, P204, DOI 10.1002/dys.224
   Tallal P, 2004, NAT REV NEUROSCI, V5, P721, DOI 10.1038/nrn1499
   Tallal P., 1980, B ORTON SOC, V30, P170, DOI [10.1007/BF02653716, DOI 10.1007/BF02653716]
   Teinonen T, 2008, COGNITION, V108, P850, DOI 10.1016/j.cognition.2008.05.009
   Tzeng S. J., 2006, PHONOLOGICAL AWARENE
   Tzeng S. J., 2011, RAPID AUTOMATIZED NA
   Walker KMM, 2006, BRAIN RES, V1124, P126, DOI 10.1016/j.brainres.2006.09.080
   Wang LC, 2018, J LEARN DISABIL-US, V51, P302, DOI 10.1177/0022219416680798
   Witton C, 1998, CURR BIOL, V8, P791, DOI 10.1016/S0960-9822(98)70320-3
   Wright BA, 2000, CURR OPIN NEUROBIOL, V10, P482, DOI 10.1016/S0959-4388(00)00119-7
NR 53
TC 0
Z9 0
U1 3
U2 14
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0022-2194
EI 1538-4780
J9 J LEARN DISABIL-US
JI J. Learn. Disabil.
PD NOV
PY 2019
VL 52
IS 6
BP 431
EP 441
AR 0022219419863766
DI 10.1177/0022219419863766
EA JUL 2019
PG 11
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA JG7IE
UT WOS:000476435500001
PM 31313628
DA 2021-02-24
ER

PT J
AU Lindborg, A
   Baart, M
   Stekelenburg, JJ
   Vroomen, J
   Andersen, TS
AF Lindborg, Alma
   Baart, Martijn
   Stekelenburg, Jeroen J.
   Vroomen, Jean
   Andersen, Tobias S.
TI Speech-specific audiovisual integration modulates induced theta-band
   oscillations
SO PLOS ONE
LA English
DT Article
ID ELECTROPHYSIOLOGICAL EVIDENCE; MULTISENSORY INTEGRATION; CORTICAL
   OSCILLATIONS; SEEING-VOICES; VISUAL SPEECH; HEARING-LIPS; EEG;
   COMPREHENSION; FACILITATION; PERCEPTION
AB Speech perception is influenced by vision through a process of audiovisual integration. This is demonstrated by the McGurk illusion where visual speech (for example /ga/) dubbed with incongruent auditory speech (such as /ba/) leads to a modified auditory percept (/da/). Recent studies have indicated that perception of the incongruent speech stimuli used in McGurk paradigms involves mechanisms of both general and audiovisual speech specific mismatch processing and that general mismatch processing modulates induced theta-band (4-8 Hz) oscillations. Here, we investigated whether the theta modulation merely reflects mismatch processing or, alternatively, audiovisual integration of speech. We used electroencephalographic recordings from two previously published studies using audiovisual sine-wave speech (SWS), a spectrally degraded speech signal sounding nonsensical to naive perceivers but perceived as speech by informed subjects. Earlier studies have shown that informed, but not naive subjects integrate SWS phonetically with visual speech. In an N1/P2 event-related potential paradigm, we found a significant difference in theta-band activity between informed and naive perceivers of audiovisual speech, suggesting that audiovisual integration modulates induced theta-band oscillations. In a McGurk mismatch negativity paradigm (MMN) where infrequent McGurk stimuli were embedded in a sequence of frequent audio-visually congruent stimuli we found no difference between congruent and McGurk stimuli. The infrequent stimuli in this paradigm are violating both the general prediction of stimulus content, and that of audiovisual congruence. Hence, we found no support for the hypothesis that audiovisual mismatch modulates induced theta-band oscillations. We also did not find any effects of audiovisual integration in the MMN paradigm, possibly due to the experimental design.
C1 [Lindborg, Alma; Andersen, Tobias S.] Tech Univ Denmark, DTU Compute, Sect Cognit Syst, Lyngby, Denmark.
   [Baart, Martijn; Stekelenburg, Jeroen J.; Vroomen, Jean] Tilburg Univ, Dept Cognit Neuropsychol, Tilburg, Netherlands.
   [Baart, Martijn] BCBL Basque Ctr Cognit Brain & Language, Donostia San Sebastian, Spain.
RP Lindborg, A (corresponding author), Tech Univ Denmark, DTU Compute, Sect Cognit Syst, Lyngby, Denmark.
EM allin@dtu.dk
RI Vroomen, Jean/K-1033-2013; Baart, Martijn/L-2910-2013; Andersen,
   Tobias/I-5317-2013
OI Vroomen, Jean/0000-0001-5923-5988; Lindborg, Alma/0000-0002-7578-3826;
   Baart, Martijn/0000-0002-5015-4265; Andersen, Tobias/0000-0002-0263-1354
FU Netherlands Organization for Scientific Research (NWO: VENI)Netherlands
   Organization for Scientific Research (NWO) [275-89-027]
FX MB was supported by The Netherlands Organization for Scientific Research
   (NWO: VENI Grant 275-89-027). The funders had no role in study design,
   data collection and analysis, decision to publish, or preparation of the
   manuscript.
CR Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Alsius A, 2018, MULTISENS RES, V31, P111, DOI 10.1163/22134808-00002565
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009
   Baart M, 2017, EUR J NEUROSCI, V46, P2578, DOI 10.1111/ejn.13734
   Baart M, 2016, PSYCHOPHYSIOLOGY, V53, P1295, DOI 10.1111/psyp.12683
   Baart M, 2014, NEUROPSYCHOLOGIA, V53, P115, DOI 10.1016/j.neuropsychologia.2013.11.011
   Colin C, 2002, CLIN NEUROPHYSIOL, V113, P495, DOI 10.1016/S1388-2457(02)00024-X
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Eskelund K, 2011, EXP BRAIN RES, V208, P447, DOI 10.1007/s00221-010-2495-9
   Frolich L, 2015, PSYCHOPHYSIOLOGY, V52, P32, DOI 10.1111/psyp.12290
   Fuentemilla L, 2008, BRAIN RES, V1220, P93, DOI 10.1016/j.brainres.2007.07.079
   Ganesh AC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01340
   Ghitza O, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00130
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Golumbic EZ, 2013, J NEUROSCI, V33, P1417, DOI 10.1523/JNEUROSCI.3675-12.2013
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Grant KW, 1998, J ACOUST SOC AM, V104, P2438, DOI 10.1121/1.423751
   Hsiao FJ, 2009, BIOL PSYCHOL, V81, P58, DOI 10.1016/j.biopsycho.2009.01.007
   Keil J, 2018, NEUROSCIENTIST, V24, P609, DOI 10.1177/1073858418755352
   Keil J, 2012, CEREB CORTEX, V22, P221, DOI 10.1093/cercor/bhr125
   Keitel A, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2004473
   Ko D, 2012, J CLIN NEUROL, V8, P35, DOI 10.3988/jcn.2012.8.1.35
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Luo H, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000445
   Magnotti JF, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005229
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Massaro D. W., 1987, SPEECH PERCEPTION EA
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Fernandez LM, 2018, EUR J NEUROSCI, V48, P2630, DOI 10.1111/ejn.13804
   Fernandez LM, 2017, HUM BRAIN MAPP, V38, P5691, DOI 10.1002/hbm.23758
   Mottonen R, 2002, COGNITIVE BRAIN RES, V13, P417, DOI 10.1016/S0926-6410(02)00053-8
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   Saint-Amour D, 2007, NEUROPSYCHOLOGIA, V45, P587, DOI 10.1016/j.neuropsychologia.2006.03.036
   SAMS M, 1991, NEUROSCI LETT, V127, P141, DOI 10.1016/0304-3940(91)90914-F
   Senkowski D, 2008, TRENDS NEUROSCI, V31, P401, DOI 10.1016/j.tins.2008.05.002
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964
   Stekelenburg JJ, 2012, NEUROPSYCHOLOGIA, V50, P1425, DOI 10.1016/j.neuropsychologia.2012.02.027
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Tiippana K, 2004, EUR J COGN PSYCHOL, V16, P457, DOI 10.1080/09541440340000268
   Tuomainen J, 2005, COGNITION, V96, pB13, DOI 10.1016/j.cognition.2004.10.004
   van Atteveldt N, 2014, NEURON, V81, P1240, DOI 10.1016/j.neuron.2014.02.044
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Wang L, 2012, FRONT PSYCHOL, V3, DOI [10.3389/fpsyg.2012.00438, 10.3389/fpsyg.2012.00187]
   Widmann A, 2015, J NEUROSCI METH, V250, P34, DOI 10.1016/j.jneumeth.2014.08.002
   Zhang F, 2009, J AM ACAD AUDIOL, V20, P239, DOI 10.3766/jaaa.20.4.4
NR 50
TC 0
Z9 0
U1 1
U2 6
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD JUL 16
PY 2019
VL 14
IS 7
AR e0219744
DI 10.1371/journal.pone.0219744
PG 15
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA IW4SF
UT WOS:000484969300029
PM 31310616
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Boerrigter, M
   Vermeulen, A
   Marres, H
   Mylanus, E
   Langereis, M
AF Boerrigter, Merle
   Vermeulen, Anneke
   Marres, Henri
   Mylanus, Emmanuel
   Langereis, Margreet
TI Frequencies of Behavioral Problems Reported by Parents and Teachers of
   Hearing-Impaired Children With Cochlear Implants
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE cochlear implant; hearing loss; behavioral problems; education; speech
   perception; receptive vocabulary
ID PROFOUNDLY DEAF-CHILDREN; MENTAL-HEALTH PROBLEMS; LANGUAGE-DEVELOPMENT;
   DUTCH CHILDREN; PSYCHOPATHOLOGY; AGREEMENT; AGE; ADOLESCENTS; ATTENTION;
   COMMUNICATION
AB Background: Internalizing and externalizing behavioral problems were frequently reported in profoundly hearing-impaired (HI) children with hearing aids. Due to the positive effect of cochlear implants (CIs) on hearing and language development, a positive effect on behavioral problems was expected. However, there is no consensus about the frequency of behavioral problems in CI children, and studies are often based on one informant with the risk of missing behavioral problems in other contexts.
   Aims: The first aim of this study was to investigate the frequency of behavioral problems in children with CIs as compared to a hearing normative sample. The second aim was to measure the agreement between the parents' and teachers' rates on the behavioral problem scales. And the third aim was to investigate the relation between speech perception, language skills and the frequencies of reported behavioral problems.
   Methods: Of 71 CI children, 51% were girls and 49% were boys, and the mean age was 8.6 (SD = 3.3). Behavior was reported by parents using the Child Behavior Checklist (CBCL) and by teachers using the Teacher Report Form (TRF). Frequencies of behavioral problems of CI children (6-16 years) were compared to a normative sample with the chi square test. Parent-teacher agreement was measured with the intraclass correlation coefficient (ICC 2,1). Next CI children were divided into four ability level categories regarding speech perception and language skills. Frequencies of behavioral problems were compared between the categories with the chi square test.
   Results: Parents and teachers of CI children reported similar frequencies of behavioral problems to the normative sample. Fair to low parent-teacher agreements were found on the behavioral problem scales. A significantly higher frequency of behavioral problems was reported in children with low speech perception and receptive vocabulary at school.
   Conclusion: Parents and teachers report similar frequencies of behavioral problems children with CIs compared to a hearing normative sample. Children with lower speech perception and language levels are more at risk of developing behavioral problems at school. Adequate speech perception and language levels are found to be protective factors for the development of behavior.
C1 [Boerrigter, Merle; Vermeulen, Anneke; Marres, Henri; Mylanus, Emmanuel; Langereis, Margreet] Radboud Univ Nijmegen, Dept Otorhinolaryngol, Med Ctr, Nijmegen, Netherlands.
   [Boerrigter, Merle; Vermeulen, Anneke; Marres, Henri; Mylanus, Emmanuel; Langereis, Margreet] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
RP Boerrigter, M; Mylanus, E (corresponding author), Radboud Univ Nijmegen, Dept Otorhinolaryngol, Med Ctr, Nijmegen, Netherlands.; Boerrigter, M; Mylanus, E (corresponding author), Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
EM merle.boerrigter@radboudumc.nl; emmanual.mylanus@radboudumc.nl
RI Boerrigter, Merle S./E-4013-2016
OI Boerrigter, Merle S./0000-0003-4983-9336
FU Cochlear Benelux
FX This study was financially supported by the Cochlear Benelux.
CR Achenbach T., 2000, MANUAL ASEBA PRESCHO
   Achenbach T., 2010, MULTICULTURAL SUPPLE
   Barker DH, 2009, DEV PSYCHOPATHOL, V21, P373, DOI 10.1017/S0954579409000212
   Boons T, 2013, RES DEV DISABIL, V34, P2008, DOI 10.1016/j.ridd.2013.03.003
   Bosman AJ, 1995, AUDIOLOGY, V34, P260
   Brown JD, 2006, AMBUL PEDIATR, V6, P347, DOI 10.1016/j.ambp.2006.09.004
   Calderon R., 2003, OXFORD HDB DEAF STUD, P177
   Chao WC, 2015, INT J PEDIATR OTORHI, V79, P648, DOI 10.1016/j.ijporl.2015.02.006
   Cicchetti D. V., 1994, PSYCHOL ASSESS, V6, P284, DOI [10.1037/1040-3590.6.4.284, DOI 10.1037/1040-3590.6.4.284]
   Colletti L, 2011, INT J PEDIATR OTORHI, V75, P504, DOI 10.1016/j.ijporl.2011.01.005
   De Los Reyes A, 2009, J ABNORM CHILD PSYCH, V37, P637, DOI 10.1007/s10802-009-9307-3
   Dettman S. J., 2016, OTOL NEUROTOL, V37, P82, DOI DOI 10.1097/MA0.0000000000000915
   Dunn LM, 2005, PEABODY PICTURE VOCA
   Fulcher A, 2012, INT J PEDIATR OTORHI, V76, P1785, DOI 10.1016/j.ijporl.2012.09.001
   Geers AE, 2013, J SPEECH LANG HEAR R, V56, P643, DOI 10.1044/1092-4388(2012/11-0347)
   Hicks CB, 2002, J SPEECH LANG HEAR R, V45, P573, DOI 10.1044/1092-4388(2002/046)
   Hinshaw SP, 2003, CHILD PSYCHOPATHOL, V2, P144, DOI DOI 10.1207/S15374424JCCP33
   Holwell A, 2011, ADV PSYCHIAT TREATME, V17, P54, DOI DOI 10.1192/APT.BP.109.006718
   Huber M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00953
   Huber M, 2011, INT J AUDIOL, V50, P146, DOI 10.3109/14992027.2010.533704
   Khan S, 2005, AUDIOL NEURO-OTOL, V10, P117, DOI 10.1159/000083367
   Kral A, 2010, NEW ENGL J MED, V363, P1438, DOI 10.1056/NEJMra0911225
   Kuhl P, 2008, ANNU REV NEUROSCI, V31, P511, DOI 10.1146/annurev.neuro.30.051606.094321
   Langberg JM, 2010, J EMOT BEHAV DISORD, V18, P41, DOI 10.1177/1063426608330792
   Leigh J, 2013, OTOL NEUROTOL, V34, P443, DOI 10.1097/MAO.0b013e3182814d2c
   Leigh JR, 2016, INT J AUDIOL, V55, pS9, DOI 10.3109/14992027.2016.1157268
   Letourneau NL, 2013, J EMOT BEHAV DISORD, V21, P211, DOI 10.1177/1063426611421007
   Mitchell R., 2011, OXFORD HDB DEAF STUD, V1, P18
   Mitchell TV, 1996, J CLIN CHILD PSYCHOL, V25, P83, DOI 10.1207/s15374424jccp2501_10
   Moeller MP, 2007, EAR HEARING, V28, P740, DOI 10.1097/AUD.0b013e318157f07f
   Nekes S., 2016, THESIS
   Netten AP, 2018, EAR HEARING, V39, P495, DOI 10.1097/AUD.0000000000000500
   Netten AP, 2015, INT J PEDIATR OTORHI, V79, P2221, DOI 10.1016/j.ijporl.2015.10.008
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Park M, 2016, INT J PEDIATR OTORHI, V83, P137, DOI 10.1016/j.ijporl.2016.01.038
   Schroeder JF, 2010, J CHILD FAM STUD, V19, P646, DOI 10.1007/s10826-010-9352-0
   Stevenson J, 2015, EUR CHILD ADOLES PSY, V24, P477, DOI 10.1007/s00787-015-0697-1
   Stevenson J, 2010, J CHILD PSYCHOL PSYC, V51, P77, DOI 10.1111/j.1469-7610.2009.02124.x
   Svirsky MA, 2004, AUDIOL NEURO-OTOL, V9, P224, DOI 10.1159/000078392
   Theunissen SCPM, 2015, EAR HEARING, V36, pe190, DOI 10.1097/AUD.0000000000000147
   Theunissen SCPM, 2014, EUR CHILD ADOLES PSY, V23, P187, DOI 10.1007/s00787-013-0444-4
   Theunissen SCPM, 2014, JAMA PEDIATR, V168, P170, DOI 10.1001/jamapediatrics.2013.3974
   Theunissen SCPM, 2011, INT J PEDIATR OTORHI, V75, P1313, DOI 10.1016/j.ijporl.2011.07.023
   Tick NT, 2007, ACTA PSYCHIAT SCAND, V116, P473, DOI 10.1111/j.1600-0447.2007.01068.x
   Vaccari C, 1997, J CHILD PSYCHOL PSYC, V38, P793, DOI 10.1111/j.1469-7610.1997.tb01597.x
   van der Ende J, 2012, PSYCHOL ASSESSMENT, V24, P293, DOI 10.1037/a0025500
   Van Eldik T, 2005, AM ANN DEAF, V150, P11, DOI 10.1353/aad.2005.0024
   Van Eldik T, 2004, AM ANN DEAF, V148, P390, DOI 10.1353/aad.2004.0002
   van Gent T, 2007, J CHILD PSYCHOL PSYC, V48, P950, DOI 10.1111/j.1469-7610.2007.01775.x
   Verhulst F. C, 2013, HANDLEIDING ASEBA
   Verhulst FC, 1996, HANDLEIDING CBCL 4 1
   Vostanis P, 1997, CHILD CARE HLTH DEV, V23, P233, DOI 10.1111/j.1365-2214.1997.tb00966.x
   Wiefferink CH, 2012, INT J PEDIATR OTORHI, V76, P883, DOI 10.1016/j.ijporl.2012.02.065
   Wong CL, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517710373
NR 54
TC 0
Z9 0
U1 2
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUL 16
PY 2019
VL 10
AR 1591
DI 10.3389/fpsyg.2019.01591
PG 10
WC Psychology, Multidisciplinary
SC Psychology
GA IJ3PR
UT WOS:000475817300001
PM 31379656
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Zoubrinetzky, R
   Collet, G
   Nguyen-Morel, MA
   Valdois, S
   Serniclaes, W
AF Zoubrinetzky, Rachel
   Collet, Gregory
   Nguyen-Morel, Marie-Ange
   Valdois, Sylviane
   Serniclaes, Willy
TI Remediation of Allophonic Perception and Visual Attention Span in
   Developmental Dyslexia: A Joint Assay
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE dyslexia; reading; remediation; allophonic perception; visual attention
   span
ID SPEECH-PERCEPTION; PHONOLOGICAL SKILLS; VISUOSPATIAL ATTENTION; READING
   DISABILITIES; SPATIAL ATTENTION; NEURAL EVIDENCE; CHILDREN LEARN; FMRI
   EVIDENCE; CAUSAL LINK; DUAL-ROUTE
AB Categorical perception of phonemes and visual attention span are cognitive processes that contribute independently to poor reading skills in developmental dyslexia. We here explored whether training programs specifically targeting one or the other process do improve reading performance in dyslexic children. The dyslexic participants were trained using either the RapDys (c) program designed to improve phonemic perception or the MAEVA (c) program targeting visual attention span. Each participant was provided the two programs successively for intensive training. Results show specific effects of RapDys (c) on phonemic discrimination and pseudo-word reading. MAEVA (c) specifically improved visual attention span and irregular word reading. Phonemic awareness and regular word reading improved after application of both training programs, suggesting similar positive effects of both methods although effects of concomitant phonic training cannot be ruled out (as there was no control group). The overall findings suggest that both categorical perception and visual attention span remediation contribute to reading.
C1 [Zoubrinetzky, Rachel; Nguyen-Morel, Marie-Ange; Valdois, Sylviane] Ctr Hosp Univ, Pole Couple Enfant, Ctr Referent Troubles Langage & Apprentissages, Grenoble, France.
   [Zoubrinetzky, Rachel; Valdois, Sylviane] Univ Grenoble Alpes, UMR 5105, CNRS, Lab Psychobgie & NeuroCognit, Grenoble, France.
   [Collet, Gregory; Serniclaes, Willy] Univ Libre Bruxelles, Ctr Rech Cognit & Neurosci, Unite Rech Neurosci Cognit, Brussels, Belgium.
   [Serniclaes, Willy] Univ Sorbonne Paris Cite, UMR 8002, CNRS, Inst Neurosci & Cognit, Paris, France.
RP Serniclaes, W (corresponding author), Univ Libre Bruxelles, Ctr Rech Cognit & Neurosci, Unite Rech Neurosci Cognit, Brussels, Belgium.; Serniclaes, W (corresponding author), Univ Sorbonne Paris Cite, UMR 8002, CNRS, Inst Neurosci & Cognit, Paris, France.
EM willy.serniclaes@gmail.com
OI Collet, Gregory/0000-0002-7378-0074
FU French National Research Agency (ANR) as part of the "Investissements
   d'Avenir" programFrench National Research Agency (ANR)
   [ANR-10-LABX-0083]
FX This work was supported by public grants overseen by the French National
   Research Agency (ANR) as part of the "Investissements d'Avenir" program
   (reference: ANR-10-LABX-0083).
CR Ans B, 1998, PSYCHOL REV, V105, P678, DOI 10.1037/0033-295X.105.4.678-723
   Banfi C, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0198903
   Bialystok E, 2005, SCI STUD READ, V9, P43, DOI 10.1207/s1532799xssr0901_4
   Boets B, 2010, BRIT J DEV PSYCHOL, V28, P5, DOI 10.1348/026151010X485223
   Bogliotti C, 2008, J EXP CHILD PSYCHOL, V101, P137, DOI 10.1016/j.jecp.2008.03.006
   Borsting E, 1996, VISION RES, V36, P1047, DOI 10.1016/0042-6989(95)00199-9
   Bosse ML, 2007, COGNITION, V104, P198, DOI 10.1016/j.cognition.2006.05.009
   Bosse ML, 2015, J RES READ, V38, P141, DOI 10.1111/j.1467-9817.2012.01551.x
   Bosse ML, 2009, J RES READ, V32, P230, DOI 10.1111/j.1467-9817.2008.01387.x
   Brem S, 2010, P NATL ACAD SCI USA, V107, P7939, DOI 10.1073/pnas.0904402107
   Bus AG, 1999, J EDUC PSYCHOL, V91, P403, DOI 10.1037/0022-0663.91.3.403
   Castles A, 2004, COGNITION, V91, P77, DOI 10.1016/S0010-0277(03)00164-1
   Cestnick L, 1999, COGNITION, V71, P231, DOI 10.1016/S0010-0277(99)00023-2
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Cohen L, 2004, NEUROIMAGE, V22, P466, DOI 10.1016/j.neuroimage.2003.12.049
   Collet G, 2012, RES DEV DISABIL, V33, P1805, DOI 10.1016/j.ridd.2012.05.003
   Coltheart M, 2001, PSYCHOL REV, V108, P204, DOI 10.1037//0033-295X.108.1.204
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Dandache S, 2014, DYSLEXIA, V20, P305, DOI 10.1002/dys.1482
   Danon-Boileau L, 2002, PLAY LOGICIEL ENTRAI
   Denhiere G, 1991, ENTRETIENS NATHAN LE, V1, P67
   Dubois M, 2010, CORTEX, V46, P717, DOI 10.1016/j.cortex.2009.11.002
   Dufor O, 2009, NEUROIMAGE, V46, P241, DOI 10.1016/j.neuroimage.2009.01.035
   Eden GF, 2004, NEURON, V44, P411, DOI 10.1016/j.neuron.2004.10.019
   Ehri LC, 2001, READ RES QUART, V36, P250, DOI 10.1598/RRQ.36.3.2
   Facoetti A, 2004, TRENDS IN DYSLEXIA RESEARCH, P35
   Facoetti A, 2006, COGN NEUROPSYCHOL, V23, P841, DOI 10.1080/02643290500483090
   Facoetti A, 2010, J COGNITIVE NEUROSCI, V22, P1011, DOI 10.1162/jocn.2009.21232
   Franceschini S, 2012, CURR BIOL, V22, P814, DOI 10.1016/j.cub.2012.03.013
   Germano GD, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01169
   Goswami U, 2015, NAT REV NEUROSCI, V16, P43, DOI 10.1038/nrn3836
   Guenther FH, 2004, J SPEECH LANG HEAR R, V47, P46, DOI 10.1044/1092-4388(2004/005)
   Hari R, 2001, TRENDS COGN SCI, V5, P525, DOI 10.1016/S1364-6613(00)01801-5
   Harris H, 2012, CURR BIOL, V22, P1813, DOI 10.1016/j.cub.2012.07.059
   Hays W. L, 1988, STAT SOCIAL SCI
   Hoonhorst I, 2011, SPEECH COMMUN, V53, P417, DOI 10.1016/j.specom.2010.11.005
   HURFORD DP, 1990, J LEARN DISABIL, V23, P564, DOI 10.1177/002221949002300906
   JAMIESON DG, 1989, CAN J PSYCHOL, V43, P88, DOI 10.1037/h0084209
   Lallier M., 2012, DYSLEXIA COMPREHENSI, P73, DOI DOI 10.5772/39042
   Lallier M, 2010, CORTEX, V46, P231, DOI 10.1016/j.cortex.2009.03.014
   Lassus-Sangosse D, 2008, VISION RES, V48, P979, DOI 10.1016/j.visres.2008.01.025
   Lefavrais P, 1965, TEST DE LALOUETTE
   Lervag A, 2009, DEV PSYCHOL, V45, P764, DOI 10.1037/a0014132
   Lete B, 2004, BEHAV RES METH INS C, V36, P156, DOI 10.3758/BF03195560
   LISKER L, 1977, LANG SPEECH, V20, P209, DOI 10.1177/002383097702000303
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Lobier M, 2015, NAT REV NEUROSCI, V16, P225, DOI 10.1038/nrn3836-c1
   Lobier M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0058097
   Lobier M, 2012, NEUROPSYCHOLOGIA, V50, P2195, DOI 10.1016/j.neuropsychologia.2012.05.023
   Lobier M, 2012, CORTEX, V48, P768, DOI 10.1016/j.cortex.2011.09.003
   Lobier MA, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00479
   MACMILLAN NA, 1977, PSYCHOL REV, V84, P452, DOI 10.1037/0033-295X.84.5.452
   Magnan A, 2006, COMPUT EDUC, V46, P407, DOI 10.1016/j.compedu.2004.08.008
   Magnan A, 2004, DYSLEXIA, V10, P131, DOI 10.1002/dys.270
   Manis FR, 1997, J EXP CHILD PSYCHOL, V66, P211, DOI 10.1006/jecp.1997.2383
   McBride-Chang C, 1997, J EDUC PSYCHOL, V89, P621, DOI 10.1037/0022-0663.89.4.621
   Melby-Lervag M, 2012, PSYCHOL BULL, V138, P322, DOI 10.1037/a0026744
   Moore DR, 2005, BRAIN LANG, V94, P72, DOI 10.1016/j.bandl.2004.11.009
   Mousty P., 1994, EVALUER TROUBLES LEC, P127
   Noordenbos MW, 2012, NEUROPSYCHOLOGIA, V50, P2010, DOI 10.1016/j.neuropsychologia.2012.04.026
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   Noordenbos MW, 2013, CLIN NEUROPHYSIOL, V124, P1151, DOI 10.1016/j.clinph.2012.12.044
   Pelli DG, 2006, VISION RES, V46, P4646, DOI 10.1016/j.visres.2006.04.023
   Peterson RL, 2013, COGNITION, V126, P20, DOI 10.1016/j.cognition.2012.08.007
   Peyrin C, 2012, BRAIN LANG, V120, P381, DOI 10.1016/j.bandl.2011.12.015
   Peyrin C, 2011, BRAIN LANG, V118, P128, DOI 10.1016/j.bandl.2010.06.005
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Raven J. C., 1998, PROGRESSIVE MATRICES
   Reilhac C, 2013, NEUROPSYCHOLOGIA, V51, P601, DOI 10.1016/j.neuropsychologia.2012.12.010
   Saksida A, 2016, DEV PSYCHOL, V52, P1503, DOI 10.1037/dev0000184
   Serniclaes W, 2015, HDB COMMUNICATION DI, P34, DOI DOI 10.1080/23273798.2014.1002796
   Serniclaes W., 1987, THESIS
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   Serniclaes W, 2018, BRAIN SCI, V8, DOI 10.3390/brainsci8040054
   Shapiro LR, 2013, J EXP CHILD PSYCHOL, V116, P278, DOI 10.1016/j.jecp.2013.05.011
   Simos PG, 2002, NEUROLOGY, V58, P1203, DOI 10.1212/WNL.58.8.1203
   Snowling M J, 2001, Dyslexia, V7, P37
   Sprenger-Charolles L., 2006, READING ACQUISITION
   Stein John, 2014, Curr Dev Disord Rep, V1, P267
   Thomson JM, 2013, READ WRIT, V26, P139, DOI 10.1007/s11145-012-9359-6
   Torgesen JK, 2001, J LEARN DISABIL-US, V34, P33, DOI 10.1177/002221940103400104
   Valdois S, 2003, READ WRIT, V16, P541, DOI DOI 10.1023/A:1025501406971
   Valdois S, 2014, COREVA EXERCICES PRO
   Valdois S, 2018, NEUROPSYCHOLOGIA
   Valdois S, 2014, CORTEX, V53, P120, DOI 10.1016/j.cortex.2013.11.006
   Valdois S, 2011, CORTEX, V47, P1197, DOI 10.1016/j.cortex.2011.05.011
   van den Boer M, 2018, SCI STUD READ, V22, P434, DOI 10.1080/10888438.2018.1472266
   van den Boer M, 2015, LEARN INDIVID DIFFER, V39, P141, DOI 10.1016/j.lindif.2015.03.017
   van den Boer M, 2013, SCI STUD READ, V17, P243, DOI 10.1080/10888438.2012.683222
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   Veuillet E, 2007, BRAIN, V130, P2915, DOI 10.1093/brain/awm235
   Vidyasagar TR, 2010, TRENDS COGN SCI, V14, P57, DOI 10.1016/j.tics.2009.12.003
   Wechsler D., 2005, WISC 4 ECHELLE INTEL
   Wilson Anna J, 2006, Behav Brain Funct, V2, P20, DOI 10.1186/1744-9081-2-20
   Witton C, 1998, CURR BIOL, V8, P791, DOI 10.1016/S0960-9822(98)70320-3
   Zhang J, 2014, DEV PSYCHOL, V50, P1001, DOI 10.1037/a0035086
   Zhao J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21578-5
   Zoubrinetzky R, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151015
   Zoubrinetzky R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099337
NR 99
TC 4
Z9 4
U1 0
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUL 16
PY 2019
VL 10
AR 1502
DI 10.3389/fpsyg.2019.01502
PG 16
WC Psychology, Multidisciplinary
SC Psychology
GA IJ3NE
UT WOS:000475810600001
PM 31379640
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Schertz, J
   Kang, Y
   Han, S
AF Schertz, Jessamyn
   Kang, Yoonjung
   Han, Sungwoo
TI Sources of variability in phonetic perception: The joint influence of
   listener and talker characteristics on perception of the Korean stop
   contrast
SO LABORATORY PHONOLOGY
LA English
DT Article
DE sociophonetics; Korean; dialectal variation; perception; listener
   expectations
ID VOICE ONSET TIME; SPEECH-PERCEPTION; SOUND CHANGE; INFORMATION; SEOUL;
   CONTEXT; MERGER
AB Where there is dialectal variability in production of a sound contrast, listeners from the two dialects may show parallel differences in perception. At the same time, perception is not static and can be influenced by other factors, including listeners' experience with, and expectations about, different talkers. This work examines perception of the Korean three-way stop phonation contrast by listeners of two dialects of Korean. We examine to what extent listeners' perception reflects production norms in their local community and, via a reverse matched-guise task, test whether their knowledge of cross-dialectal variability plays an active role in the way they categorize the contrast. While perception appears to reflect production norms on a broad level, we found age-related differences in perception, even for listener groups who showed no sign of a parallel difference in production. Furthermore, listeners showed different response patterns depending on the apparent dialect of the talker. Our results suggest that exposure to dialectal variability and expectations about the talker influence perception.
C1 [Schertz, Jessamyn] Univ Toronto Mississauga, Dept Language Studies, Mississauga, ON, Canada.
   [Schertz, Jessamyn; Kang, Yoonjung] Univ Toronto, Dept Linguist, Toronto, ON, Canada.
   [Kang, Yoonjung] Univ Toronto Scarborough, Ctr French & Linguist, Toronto, ON, Canada.
   [Han, Sungwoo] Inha Univ, Dept Korean Language & Literature, Incheon, South Korea.
RP Schertz, J (corresponding author), Univ Toronto Mississauga, Dept Language Studies, Mississauga, ON, Canada.; Schertz, J (corresponding author), Univ Toronto, Dept Linguist, Toronto, ON, Canada.
EM jessamyn.schertz@utoronto.ca
FU SSHRCSocial Sciences and Humanities Research Council of Canada (SSHRC)
   [435-2013-2092]
FX The authors would like to thank Professor Sun Ying at Liaoning
   University, Yunyan Luo, and Yuanyang Song for invaluable help with the
   data collection process. Kyeong-Hye Kim, Dong-Ki Han, Hae-Dong Park,
   Sung-Geol Kim, and Na-Young Ryu helped with stimulus preparation, and
   Rachel Soo and N.-Y. Ryu assisted with data processing. This research
   was supported by SSHRC Grant #435-2013-2092 to Yoonjung Kang.
CR Ahn H., 1999, THESIS
   Bang H., 2015, P INT C PHON SCI
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boersma P., 2014, PRAAT DOING PHONETIC
   Chang CB, 2013, KOREAN LINGUIST, V15, P7, DOI 10.1075/kl.15.1.02cha
   Chang YHS, 2017, CONCENTRIC-STUD LING, V43, P1, DOI 10.6241/concentric.ling.43.1.01
   China Data Center, 2006, CHIN DAT ONL
   Cho TH, 2002, J PHONETICS, V30, P193, DOI 10.1006/jpho.2001.0153
   Chung E., 2011, THESIS
   Cui J., 2011, THESIS
   D'Onofrio A, 2015, J SOCIOLING, V19, P241, DOI 10.1111/josl.12115
   De Rosario-Martinez H., 2015, PACKAGE PHIA V 0 1
   Drager K, 2011, LANG SPEECH, V54, P99, DOI 10.1177/0023830910388017
   Dufour S, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01200
   Evans BG, 2004, J ACOUST SOC AM, V115, P352, DOI 10.1121/1.1635413
   Fridland V, 2012, LINGUA, V122, P779, DOI 10.1016/j.lingua.2011.12.007
   Gordon M, 2001, J PHONETICS, V29, P383, DOI 10.1006/jpho.2001.0147
   Han S., 2011, DIALECTOLOGY, V14, P114
   Harrington J, 2015, LAB PHONOL, V6, P87, DOI 10.1515/lp-2015-0002
   Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   HILLENBRAND J, 1994, J SPEECH HEAR RES, V37, P769, DOI 10.1044/jshr.3704.769
   Holliday Jeffrey, 2011, INT C PHONETIC SCI, VXVII, P878
   Hyman Larry, 1976, LINGUISTIC STUDIES O, P407
   Ito C., 2018, OXFORD RES ENCY LING, DOI [10.1093/acrefore/9780199384655.013.242, DOI 10.1093/ACREFORE/9780199384655.013.242]
   Ito C., 2008, PHONOLOGICAL STUDIES, V12, P61
   Jang H., 2012, THESIS
   Jeon L., 2011, THESIS
   Jin W., 2017, ASIA PACIFIC LANGUAG, V3, P41, DOI [10.1075/aplv.3.1.03jin, DOI 10.1075/APLV.3.1.03JIN]
   Jin W., 2008, THESIS
   Kang J, 2012, TEXT BIOENG INFORM S, P120, DOI 10.3993/tbis2012016
   Kang Y., CAMBRIDGE HDB KOREAN
   Kang YJ, 2014, J PHONETICS, V45, P76, DOI 10.1016/j.wocn.2014.03.005
   Kim MR, 2002, J PHONETICS, V30, P77, DOI 10.1006/jpho.2001.0152
   Kirby J., 2013, ORIGINS SOUND CHANGE, P228, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0011
   Kong EJ, 2011, J PHONETICS, V39, P196, DOI 10.1016/j.wocn.2011.02.002
   Koops C., 2008, U PENN WORKING PAPER, V14
   Lawrence D., 2015, P INT C PHON SCI
   Lee H., 2009, TRAINING PROGRAM LIN
   Lee H, 2019, LANG SPEECH, V62, P509, DOI 10.1177/0023830918786305
   Lee H, 2013, J PHONETICS, V41, P117, DOI 10.1016/j.wocn.2012.12.002
   Lee H, 2012, J INT PHON ASSOC, V42, P145, DOI 10.1017/S0025100312000035
   LISKER L, 1967, LANG SPEECH, V10, P1, DOI 10.1177/002383096701000101
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001
   Mira Oh, 2013, [Phonetics and Speech Sciences, 말소리와 음성과학], V5, P185, DOI 10.13064/KSSS.2013.5.4.185
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Oh E, 2011, J PHONETICS, V39, P59, DOI 10.1016/j.wocn.2010.11.002
   OHALA JJ, 1993, SPEECH COMMUN, V13, P155, DOI 10.1016/0167-6393(93)90067-U
   Pharao N., 2015, P INT C PHON SCI 201
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   Silva D. J., 2006, PHONOLOGY, V23, P287, DOI DOI 10.1017/S0952675706000911
   Squires L, 2013, J SOCIOLING, V17, P200, DOI 10.1111/josl.12025
   Staum Casasanto L., 2010, U PENN WORKING PAPER, V15
   Strand EA, 1996, NATURAL LANGUAGE PROCESSING AND SPEECH TECHNOLOGY, P14
   Tai PW, 2004, LANGUAGE POLICY, V4, P303, DOI 10.1007/1-4020-8039-5_17
   Thomas ER, 2002, AM SPEECH, V77, P115, DOI 10.1215/00031283-77-2-115
   WILLIS C, 1972, J SPEECH HEAR RES, V15, P246, DOI 10.1044/jshr.1502.246
   Yang S., 2013, THESIS
   한성우, 2014, 한국학연구, V32, P411
NR 61
TC 1
Z9 1
U1 0
U2 0
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD JUL 16
PY 2019
VL 10
IS 1
AR 13
DI 10.5334/labphon.67
PG 32
WC Linguistics; Language & Linguistics
SC Linguistics
GA IJ1GV
UT WOS:000475647700001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Schwartze, M
   Kotz, SA
AF Schwartze, Michael
   Kotz, Sonja A.
TI Decreased sensitivity to changing durational parameters of syllable
   sequences in people who stutter
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Stuttering; speech perception; timing; change detection; sequencing
ID DELAYED AUDITORY-FEEDBACK; BASAL GANGLIA; SPEECH; CEREBELLUM;
   PERCEPTION; CHILDREN; DEFICIT
AB Stuttering is a disorder that affects the coordination of complex sequencing mechanisms that define the temporal layout of speech. However, classical motor areas of the brain, responsible for the sequencing of articulatory aspects in speech production also process non-verbal and even non-motor temporal information. This configuration suggests that perceptual temporal processing capacities may factor into the symptom profile of various motor disorders. We investigated perceptual sensitivity for changing temporal parameters of sequentially presented consonant-vowel-consonant syllables in people who stutter (PWS) and matched controls. Changes were durational contrasts (short vs. long) of the whole syllable and/or the vocalic nucleus. Analyses focused on sensitivity indices (d'), response times, response time variability, and co-variation of these variables with offline measures of cognitive performance. Results indicate lower sensitivity for durational contrasts and longer and more variable response times for long vowels in the PWS group, pointing towards subtle perceptual verbal temporal processing differences.
C1 [Schwartze, Michael; Kotz, Sonja A.] Maastricht Univ, Fac Psychol & Neurosci, Dept Neuropsychol & Psychopharmacol, Maastricht, Netherlands.
RP Schwartze, M (corresponding author), Maastricht Univ, Fac Psychol & Neurosci, Dept Neuropsychol & Psychopharmacol, Maastricht, Netherlands.
EM michael.schwartze@maastrichtuniversity.nl
OI Schwartze, Michael/0000-0003-3366-4893
CR Ackermann H, 2007, CEREBELLUM, V6, P202, DOI 10.1080/14734220701266742
   Akkal D, 2007, J NEUROSCI, V27, P10659, DOI 10.1523/JNEUROSCI.3134-07.2007
   Alm PA, 2004, J COMMUN DISORD, V37, P325, DOI 10.1016/j.jcomdis.2004.03.001
   Bostan AC, 2018, NAT REV NEUROSCI, V19, P338, DOI 10.1038/s41583-018-0002-7
   Chang SE, 2009, NEUROIMAGE, V46, P201, DOI 10.1016/j.neuroimage.2009.01.066
   COOPER MH, 1977, J SPEECH HEAR RES, V20, P55, DOI 10.1044/jshr.2001.55
   Etchell AC, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00467
   Falk S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00847
   Ghitza O, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00138
   Giraud AL, 2008, BRAIN LANG, V104, P190, DOI 10.1016/j.bandl.2007.04.005
   Greenberg S, 2003, J PHONETICS, V31, P465, DOI 10.1016/j.wocn.2003.09.005
   Guenther F. H., 2016, NEUROBIOLOGY LANGUAG, P725, DOI DOI 10.1016/B978-0-12-407794-2.00058-4
   HARRINGTON J, 1988, J SPEECH HEAR RES, V31, P36, DOI 10.1044/jshr.3101.36
   Hilger AI, 2016, J SPEECH LANG HEAR R, V59, P674, DOI 10.1044/2016_JSLHR-S-15-0172
   HOLM S, 1979, SCAND J STAT, V6, P65
   Ivry RB, 2008, TRENDS COGN SCI, V12, P273, DOI 10.1016/j.tics.2008.04.002
   Kotz S. A., 2016, NEUROBIOLOGY LANGUAG, P717, DOI [10.1016/B978-0-12-407794-2.00057-2, DOI 10.1016/B978-0-12-407794-2.00057-2]
   LOTZMANN G, 1961, FOLIA PHONIATR, V13, P276, DOI 10.1159/000262924
   MacKay D. G., 1984, NATURE TREATMENT STU, P261
   MACMILLAN NA, 1985, PSYCHOL BULL, V98, P185, DOI 10.1037/0033-2909.98.1.185
   Marien P, 2013, CEREBELLUM, V12, P686, DOI 10.1007/s12311-013-0478-7
   Merchant H, 2013, ANNU REV NEUROSCI, V36, P313, DOI 10.1146/annurev-neuro-062012-170349
   MORTON J, 1976, PSYCHOL REV, V83, P405, DOI 10.1037/0033-295X.83.5.405
   Olander L, 2010, J SPEECH LANG HEAR R, V53, P876, DOI 10.1044/1092-4388(2009/09-0007)
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Park J, 2015, J FLUENCY DISORD, V46, P41, DOI 10.1016/j.jfludis.2015.07.001
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Petacchi A, 2005, HUM BRAIN MAPP, V25, P118, DOI 10.1002/hbm.20137
   Picard N, 2001, CURR OPIN NEUROBIOL, V11, P663, DOI 10.1016/S0959-4388(01)00266-5
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Port RF, 2003, J PHONETICS, V31, P599, DOI 10.1016/j.wocn.2003.08.001
   Riley G. D., 1994, STUTTERING SEVERITY
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Sares A. G., 2019, ANN NEWYORK ACAD SCI
   Sares AG, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34517-1
   Schwartze M, 2016, BRAIN LANG, V161, P28, DOI 10.1016/j.bandl.2015.08.005
   Schwartze M, 2013, NEUROSCI BIOBEHAV R, V37, P2587, DOI 10.1016/j.neubiorev.2013.08.005
   Scott SK, 2009, NAT REV NEUROSCI, V10, P295, DOI 10.1038/nrn2603
   SODERBERG GA, 1968, J SPEECH HEAR DISORD, V33, P260, DOI 10.1044/jshd.3303.260
   Spencer RMC, 2013, HDB CEREBELLUM CEREB, P1201, DOI [10.1007/978-94-007-1333-8, DOI 10.1007/978-94-007-1333-8_52]
   Stanislaw H, 1999, BEHAV RES METH INS C, V31, P137, DOI 10.3758/BF03207704
   Strick PL, 2009, ANNU REV NEUROSCI, V32, P413, DOI 10.1146/annurev.neuro.31.060407.125606
   TUKEY JW, 1958, ANN MATH STAT, V29, P614
   Van Riper C., 1982, NATURE STUTTERING
   Van Riper C., 1996, SPEECH CORRECTION IN
   Wechsler D., 1997, WAIS 3 ADM SCORING M
   Wieland EA, 2015, BRAIN LANG, V144, P26, DOI 10.1016/j.bandl.2015.03.008
   Wiener M, 2010, NEUROIMAGE, V49, P1728, DOI 10.1016/j.neuroimage.2009.09.064
NR 48
TC 0
Z9 0
U1 0
U2 3
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PD FEB 4
PY 2020
VL 35
IS 2
BP 179
EP 187
DI 10.1080/23273798.2019.1642499
EA JUL 2019
PG 9
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA KC5ZK
UT WOS:000476020000001
OA Other Gold
DA 2021-02-24
ER

PT J
AU Mashal, N
   Bat-el Yankovitz
   Lifshitz, H
AF Mashal, Nira
   Bat-el Yankovitz
   Lifshitz, Hefziba
TI Lexical decision performance using the divided visual field technique
   following training in adults with intellectual disabilities with and
   without Down syndrome
SO LATERALITY
LA English
DT Article
DE Down syndrome; lateralization; hemispheres; intellectual disability;
   lexical decision
ID VERBAL-MOTOR INTEGRATION; CEREBRAL SPECIALIZATION; WORKING-MEMORY;
   INDIVIDUALS; COOPERATION; INFORMATION; LATERALITY; WILLIAMS; CHILDREN;
   TASK
AB Studies of brain lateralization in individuals with non-specific intellectual disability and Down syndrome suggest atypical brain lateralization to speech perception. According to the biological dissociation model, the right hemisphere (RH) mediates speech perception and the left hemisphere (LH) mediates motor control in Down syndrome. The current study aimed to test, for the first time, brain lateralization in both non-specific intellectual disability and Down syndrome, compared to individuals with typical development. Furthermore, bilateral word presentation was utilized to assess interhemispheric communication. Twenty adults with non-specific intellectual disability, 14 adults with Down syndrome, and 30 adults with typical development participated in the study. Participants in the non-specific intellectual disability and Down syndrome groups were trained to perform the task prior to the experiment. The results showed that whereas hemispheric lateralization did not differ between individuals with non-specific intellectual disability and typical development, individuals with DS showed reduced brain lateralization in comparison to adults with typical development. All three groups showed no significant difference between words presented to the LH and bilaterally. Our results also show that individuals with intellectual disabilities can benefit from training programmes and that they may perform equally as fast as their typically developing peers.
C1 [Mashal, Nira; Bat-el Yankovitz; Lifshitz, Hefziba] Bar Ilan Univ, Sch Educ, Ramat Gan, Israel.
   [Mashal, Nira] Bar Ilan Univ, Gonda Multidisciplinary Brain Res Ctr, Ramat Gan, Israel.
RP Mashal, N (corresponding author), Bar Ilan Univ, Sch Educ, Ramat Gan, Israel.; Mashal, N (corresponding author), Bar Ilan Univ, Gonda Multidisciplinary Brain Res Ctr, Ramat Gan, Israel.
EM mashaln@mail.biu.ac.il
CR Aitchison J., 2003, WORDS MIND INTRO MEN
   Belger A, 1998, NEUROPSYCHOLOGY, V12, P380, DOI 10.1037/0894-4105.12.3.380
   Bishop D.V.M., 1990, HANDEDNESS DEV DISOR
   Borkowski J. G., 1983, COGNITIVE STRATEGY R, P103
   Bourne VJ, 2006, LATERALITY, V11, P373, DOI 10.1080/13576500600633982
   Cornoldi C, 2014, RES DEV DISABIL, V35, P2224, DOI 10.1016/j.ridd.2014.05.013
   Costanzo F, 2013, RES DEV DISABIL, V34, P1770, DOI 10.1016/j.ridd.2013.01.024
   ELLIOTT D, 1990, J MOTOR BEHAV, V22, P6
   ELLIOTT D, 1994, BRAIN COGNITION, V26, P191, DOI 10.1006/brcg.1994.1050
   Fink W., 1982, MENT RETARD, P231
   FRITH U, 1974, J CHILD PSYCHOL PSYC, V15, P293, DOI 10.1111/j.1469-7610.1974.tb01253.x
   GIENCKE S, 1989, CORTEX, V25, P93, DOI 10.1016/S0010-9452(89)80009-7
   Grieco J, 2015, AM J MED GENET C, V169, P135, DOI 10.1002/ajmg.c.31439
   Grossman H. J., 1983, CLASSIFICATION MENTA
   Gunn P., 1996, NEW APPROACHES DOWN, P249
   Heath M, 2007, J INTELL DISABIL RES, V51, P972, DOI 10.1111/j.1365-2788.2007.01009.x
   Heath M, 2005, CORTEX, V41, P61, DOI 10.1016/S0010-9452(08)70178-3
   Hellige J. B., 1987, WENNER GREN CTR INT, V47, DOI [10.1007/978-1-4613-1949-8_27, DOI 10.1007/978-1-4613-1949-8_27]
   Hulme C., 1992, WORKING MEMORY SEVER
   Iacoboni M, 2002, IS CL CO NE, P301
   Kim H., 1994, NEUROPSYCHOLOGY, V8, P148, DOI [DOI 10.1037/0894-4105.8.2.148, 10.1037/0894-4105.8.2.148]
   Lanfranchi S, 2012, J INTELL DISABIL RES, V56, P157, DOI 10.1111/j.1365-2788.2011.01444.x
   Lifshitz H, 2016, RES DEV DISABIL, V59, P147, DOI 10.1016/j.ridd.2016.08.001
   Linzen T., 2009, CORPUS BLOG POSTINGS
   MOHR B, 1994, NEUROSCI LETT, V181, P17, DOI 10.1016/0304-3940(94)90550-9
   Mohr B, 1996, NEUROPSYCHOLOGIA, V34, P1003, DOI 10.1016/0028-3932(96)00006-1
   Natsopoulos D, 2002, RES DEV DISABIL, V23, P297, DOI 10.1016/S0891-4222(02)00088-4
   Paour J. L., 1992, INTERACTIVE ASSESSME, P119
   Perrone-Bertolotti M, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00316
   Pinter JD, 2001, AM J PSYCHIAT, V158, P1659, DOI 10.1176/appi.ajp.158.10.1659
   PIPE ME, 1983, CORTEX, V19, P481, DOI 10.1016/S0010-9452(83)80030-6
   PIPE ME, 1988, PSYCHOL BULL, V104, P343, DOI 10.1037/0033-2909.104.3.343
   PULVERMULLER F, 1992, CONCEPT NEUROSCI, V3, P157
   RAYMAN J, 1991, BRAIN LANG, V40, P89, DOI 10.1016/0093-934X(91)90118-K
   Schiff R., 2009, SINGLE WORD RE UNPUB
   Schiff R., 2009, PHONOLOGICAL A UNPUB
   Shnitzer-Meirovich S, 2018, RES DEV DISABIL, V74, P113, DOI 10.1016/j.ridd.2018.01.010
   van der Schuit M, 2011, RES DEV DISABIL, V32, P1884, DOI 10.1016/j.ridd.2011.03.015
   Vicari S, 2005, DEV MED CHILD NEUROL, V47, P305, DOI 10.1017/S0012162205000599
   WANG PP, 1992, ARCH NEUROL-CHICAGO, V49, P407, DOI 10.1001/archneur.1992.00530280101029
   Wechsler D, 2001, WECHSLER ADULT INTEL
   Welsh TN, 2003, BRAIN LANG, V84, P152, DOI 10.1016/S0093-934X(02)00511-4
   Welsh TN, 2001, ADAPT PHYS ACT Q, V18, P156, DOI 10.1123/apaq.18.2.156
NR 43
TC 0
Z9 0
U1 1
U2 3
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1357-650X
EI 1464-0678
J9 LATERALITY
JI Laterality
PD MAR 3
PY 2020
VL 25
IS 2
BP 177
EP 197
DI 10.1080/1357650X.2019.1642344
EA JUL 2019
PG 21
WC Psychology, Multidisciplinary; Psychology, Experimental
SC Psychology
GA KH2EN
UT WOS:000476227300001
PM 31294645
DA 2021-02-24
ER

PT J
AU Kolozsvari, OB
   Xu, WY
   Leppanen, PHT
   Hamalainen, JA
AF Kolozsvari, Orsolya B.
   Xu, Weiyong
   Leppanen, Paavo H. T.
   Hamalainen, Jarmo A.
TI Top-Down Predictions of Familiarity and Congruency in Audio-Visual
   Speech Perception at Neural Level
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE speech perception; magnetoencephalography; audio-visual stimuli;
   audio-visual integration; familiarity
ID MULTISENSORY INTERACTIONS; VISUAL SPEECH; INTEGRATION; BRAIN;
   ACTIVATION; RESPONSES; FMRI; MEG; LOCALIZATION; INFORMATION
AB During speech perception, listeners rely on multimodal input and make use of both auditory and visual information. When presented with speech, for example syllables, the differences in brain responses to distinct stimuli are not, however, caused merely by the acoustic or visual features of the stimuli. The congruency of the auditory and visual information and the familiarity of a syllable, that is, whether it appears in the listener's native language or not, also modulates brain responses. We investigated how the congruency and familiarity of the presented stimuli affect brain responses to audio-visual (AV) speech in 12 adult Finnish native speakers and 12 adult Chinese native speakers. They watched videos of a Chinese speaker pronouncing syllables (/pa/, /pha/, /ta/, /tha/, /fa/) during a magnetoencephalography (MEG) measurement where only /pa/ and /ta/ were part of Finnish phonology while all the stimuli were part of Chinese phonology. The stimuli were presented in audio-visual (congruent or incongruent), audio only, or visual only conditions. The brain responses were examined in five time-windows: 75-125, 150-200, 200-300, 300-400, and 400-600 ms. We found significant differences for the congruency comparison in the fourth time-window (300-400 ms) in both sensor and source level analysis. Larger responses were observed for the incongruent stimuli than for the congruent stimuli. For the familiarity comparisons no significant differences were found. The results are in line with earlier studies reporting on the modulation of brain responses for audio-visual congruency around 250-500 ms. This suggests a much stronger process for the general detection of a mismatch between predictions based on lip movements and the auditory signal than for the top-down modulation of brain responses based on phonological information.
C1 [Kolozsvari, Orsolya B.; Xu, Weiyong; Leppanen, Paavo H. T.; Hamalainen, Jarmo A.] Univ Jyvaskyla, Dept Psychol, Jyvaskyla, Finland.
   [Kolozsvari, Orsolya B.; Xu, Weiyong; Leppanen, Paavo H. T.; Hamalainen, Jarmo A.] Univ Jyvaskyla, Jyvaskyla Ctr Interdisciplinary Brain Res CIBR, Jyvaskyla, Finland.
RP Kolozsvari, OB (corresponding author), Univ Jyvaskyla, Dept Psychol, Jyvaskyla, Finland.; Kolozsvari, OB (corresponding author), Univ Jyvaskyla, Jyvaskyla Ctr Interdisciplinary Brain Res CIBR, Jyvaskyla, Finland.
EM orsolya.b.kolozsvari@jyu.fi
RI Xu, Weiyong/AAD-3793-2019
OI Xu, Weiyong/0000-0003-4453-9836; Kolozsvari, Orsolya
   Beatrix/0000-0002-1619-6314
FU European Union Project ChildBrain (Marie Curie Innovative Training
   Networks) [641652]; European Union Project Predictable (Marie Curie
   Innovative Training Networks) [641858]; Academy of Finland
   (MultiLeTe)Academy of Finland [292 466]
FX This work was supported by the European Union Projects ChildBrain (Marie
   Curie Innovative Training Networks, #641652), Predictable (Marie Curie
   Innovative Training Networks, #641858), and the Academy of Finland
   (MultiLeTe #292 466).
CR Arnal LH, 2009, J NEUROSCI, V29, P13445, DOI 10.1523/JNEUROSCI.3194-09.2009
   Baart M, 2014, NEUROPSYCHOLOGIA, V53, P115, DOI 10.1016/j.neuropsychologia.2013.11.011
   Beauchamp MS, 2010, J NEUROSCI, V30, P2414, DOI 10.1523/JNEUROSCI.4865-09.2010
   Bernstein LE, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00386
   Besle J, 2004, EUR J NEUROSCI, V20, P2225, DOI 10.1111/j.1460-9568.2004.03670.x
   Boersma P., 2018, PRAAT DOING PHONETIC
   Callan DE, 2004, J COGNITIVE NEUROSCI, V16, P805, DOI 10.1162/089892904970771
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155
   Capek CM, 2004, COGNITIVE BRAIN RES, V20, P111, DOI 10.1016/j.cogbrainres.2003.10.014
   Dale AM, 2000, NEURON, V26, P55, DOI 10.1016/S0896-6273(00)81138-1
   Gramfort A, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00267
   HAMALAINEN MS, 1994, MED BIOL ENG COMPUT, V32, P35, DOI 10.1007/BF02512476
   Hein G, 2007, J NEUROSCI, V27, P7881, DOI 10.1523/JNEUROSCI.1740-07.2007
   Helenius P, 2002, J NEUROSCI, V22, P2936, DOI 10.1523/JNEUROSCI.22-07-02936.2002
   Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Iacoboni M, 2001, P NATL ACAD SCI USA, V98, P13995, DOI 10.1073/pnas.241474598
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Jones JA, 2003, NEUROREPORT, V14, P1129, DOI 10.1097/00001756-200306110-00006
   Klucharev V, 2003, COGNITIVE BRAIN RES, V18, P65, DOI 10.1016/j.cogbrainres.2003.09.004
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kuhl PK, 2000, P NATL ACAD SCI USA, V97, P11850, DOI 10.1073/pnas.97.22.11850
   Kujala A, 2004, COGNITIVE BRAIN RES, V21, P106, DOI 10.1016/j.cogbrainres.2004.05.011
   Lin FH, 2006, NEUROIMAGE, V31, P160, DOI 10.1016/j.neuroimage.2005.11.054
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Miller LM, 2005, J NEUROSCI, V25, P5884, DOI 10.1523/JNEUROSCI.0896-05.2005
   Mottonen R, 2004, NEUROSCI LETT, V363, P112, DOI 10.1016/j.neulet.2004.03.076
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Nishitani N, 2002, NEURON, V36, P1211, DOI 10.1016/S0896-6273(02)01089-9
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Parviainen T, 2005, CEREB CORTEX, V15, P1054, DOI 10.1093/cercor/bhh206
   Poeppel D, 1996, COGNITIVE BRAIN RES, V4, P231, DOI 10.1016/S0926-6410(96)00643-X
   Puce A, 1998, J NEUROSCI, V18, P2188
   Raij T, 2000, NEURON, V28, P617, DOI 10.1016/S0896-6273(00)00138-0
   Salmelin R, 2007, CLIN NEUROPHYSIOL, V118, P237, DOI 10.1016/j.clinph.2006.07.316
   SAMS M, 1991, NEUROSCI LETT, V127, P141, DOI 10.1016/0304-3940(91)90914-F
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964
   Taulu S, 2005, J APPL PHYS, V97, DOI 10.1063/1.1935742
   Taulu S, 2005, IEEE T SIGNAL PROCES, V53, P3359, DOI 10.1109/TSP.2005.853302
   van Atteveldt NM, 2007, NEUROIMAGE, V36, P1345, DOI 10.1016/j.neuroimage.2007.03.065
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Vihla M, 2000, P NATL ACAD SCI USA, V97, P10590, DOI 10.1073/pnas.180317297
   Vroomen J, 2010, J COGNITIVE NEUROSCI, V22, P1583, DOI 10.1162/jocn.2009.21308
   Winkler I, 1999, PSYCHOPHYSIOLOGY, V36, P638, DOI 10.1017/S0048577299981908
   Xu WY, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00018
   Zhang Y, 2005, NEUROIMAGE, V26, P703, DOI 10.1016/j.neuroimage.2005.02.040
   Zhang Y, 2009, NEUROIMAGE, V46, P226, DOI 10.1016/j.neuroimage.2009.01.028
NR 48
TC 0
Z9 0
U1 1
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD JUL 12
PY 2019
VL 13
AR 243
DI 10.3389/fnhum.2019.00243
PG 11
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA II9CP
UT WOS:000475492900001
PM 31354459
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Silva, DMR
   Rothe-Neves, R
AF Rodrigues Silva, Daniel Marcio
   Rothe-Neves, Rui
TI Context-dependent categorisation of vowels: a mismatch negativity study
   of positional neutralisation
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Neutralisation; stress; categorisation; mismatch negativity; speech
   perception
ID MASS UNIVARIATE ANALYSIS; SPEECH-PERCEPTION; NEUROBIOLOGICAL EVIDENCE;
   PHONEME REPRESENTATIONS; ERP EVIDENCE; WORD STRESS; BRAIN; RECOGNITION;
   MMN; SOUNDS
AB Studies exploring the mismatch negativity (MMN) response to speech sounds have identified neural activity associated with processing of phonologically distinctive information and language-specific perceptual categorisation. Yet little attention has been given to a basic fact of phonology, namely, that not all phoneme distinctions in a language are functional in all phonological contexts. The present ERP study explores a case in which the low-mid versus high-mid vowel distinction is limited to stressed syllables, resulting in category merger elsewhere - i.e. "positional neutralisation". We provide evidence that the sensitivity of MMN generator processes to vowel distinctions parallels their position-dependent phonological status (functional versus neutralised). As an additional finding, the MMN peaked earlier for stressed than for unstressed distinctions, indicating that stress facilitates automatic auditory discrimination. The results fit neatly into models assuming that MMN reflects a mismatch between a deviant stimulus and an abstract representation of standards that omit phonologically non-distinctive information.
C1 [Rodrigues Silva, Daniel Marcio; Rothe-Neves, Rui] Univ Fed Minas Gerais, Fac Letters, Phonet Lab, Belo Horizonte, MG, Brazil.
RP Rothe-Neves, R (corresponding author), Univ Fed Minas Gerais, Fac Letters, Phonet Lab, Belo Horizonte, MG, Brazil.
EM rothe-neves@ufmg.com
RI ROTHE-NEVES, RUI/V-6051-2018
OI ROTHE-NEVES, RUI/0000-0002-8896-8862; Rodrigues Silva, Daniel
   Marcio/0000-0001-7884-9205
FU National Council for Scientific and Technological Development
   (CNPq/Brazil)National Council for Scientific and Technological
   Development (CNPq) [PQ 312277/2015-6]; CNPq postdoctoral fellowship
FX This work was supported by the National Council for Scientific and
   Technological Development (CNPq/Brazil) under grant number PQ
   312277/2015-6 awarded to the second author and by a CNPq postdoctoral
   fellowship awarded to the first author.
CR Barbosa P. A., 2004, J INT PHON ASSOC, V34, P227, DOI DOI 10.1017/S0025100304001756
   Barbosa PA, 2013, INTERSPEECH, P282
   Barnes Jonathan, 2006, STRENGTH WEAKNESS IN
   Barry JG, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006270
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beckman J. N., 2013, POSITIONAL FAITHFULN
   Benjamini Y, 2001, ANN STAT, V29, P1165
   Boersma Paul, 2012, PRAAT DOING PHONETIC
   Chen A, 2018, BRAIN LANG, V180, P31, DOI 10.1016/j.bandl.2018.04.006
   Cheour M, 1998, NAT NEUROSCI, V1, P351, DOI 10.1038/1561
   Cheour M, 2001, AUDIOL NEURO-OTOL, V6, P2, DOI 10.1159/000046804
   Cornell SA, 2011, BRAIN RES, V1394, P79, DOI 10.1016/j.brainres.2011.04.001
   Crosswhite Katherine, 2004, PHONETICALLY BASED P, P191, DOI [DOI 10.1017/CBO9780511486401.007, 10.1017/CBO9780511486401.007]
   De Baene W, 2004, BIOL PSYCHOL, V67, P319, DOI 10.1016/j.biopsycho.2004.01.003
   Dehaene-Lambertz G, 2005, NEUROIMAGE, V24, P21, DOI 10.1016/j.neuroimage.2004.09.039
   DehaeneLambertz G, 1997, NEUROREPORT, V8, P919, DOI 10.1097/00001756-199703030-00021
   DELATTRE P, 1969, IRAL-INT REV APPL LI, V7, P295, DOI 10.1515/iral.1969.7.4.295
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Delorme A, 2007, NEUROIMAGE, V34, P1443, DOI 10.1016/j.neuroimage.2006.11.004
   DORMAN MF, 1977, Q J EXP PSYCHOL, V29, P483, DOI 10.1080/14640747708400624
   Eulitz C, 2004, J COGNITIVE NEUROSCI, V16, P577, DOI 10.1162/089892904323057308
   Fahey RP, 1996, PERCEPT PSYCHOPHYS, V58, P725, DOI 10.3758/BF03213105
   Fails W., 1992, ROMANCE LINGUISTICS, P31
   Flemming Edward, 2001, PHONOLOGY, V18, P7, DOI DOI 10.1017/s0952675701004006
   Friedrichs D, 2017, J ACOUST SOC AM, V142, P1025, DOI 10.1121/1.4998706
   Fromer R, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00048
   Groppe DM, 2011, PSYCHOPHYSIOLOGY, V48, P1726, DOI 10.1111/j.1469-8986.2011.01272.x
   Groppe DM, 2011, PSYCHOPHYSIOLOGY, V48, P1711, DOI 10.1111/j.1469-8986.2011.01273.x
   Harris John, 2005, HEADHOOD ELEMENTS SP, P119, DOI [10.1075/cilt.259.10har, DOI 10.1075/CILT.259.10HAR]
   Hestvik A, 2016, BRAIN LANG, V152, P28, DOI 10.1016/j.bandl.2015.10.007
   Hill PR, 2004, NEUROREPORT, V15, P2195, DOI 10.1097/00001756-200410050-00010
   HOEMEKE KA, 1994, J ACOUST SOC AM, V96, P661, DOI 10.1121/1.410305
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   Honbolygo F, 2017, INT J PSYCHOPHYSIOL, V118, P9, DOI 10.1016/j.ijpsycho.2017.05.009
   Honbolygo F, 2013, INT J PSYCHOPHYSIOL, V87, P165, DOI 10.1016/j.ijpsycho.2012.12.005
   Jacewicz E, 2018, PHONETICA, V75, P273, DOI 10.1159/000484610
   Kazanina N, 2006, P NATL ACAD SCI USA, V103, P11381, DOI 10.1073/pnas.0604821103
   Kenstowicz M, 2016, J PORT LINGUIST, V15, DOI 10.5334/jpl.7
   Kewley-Port D, 2001, J ACOUST SOC AM, V110, P2141, DOI 10.1121/1.1400737
   KewleyPort D, 1996, J ACOUST SOC AM, V100, P2462, DOI 10.1121/1.417954
   Kujala T, 2007, BIOL PSYCHOL, V74, P1, DOI 10.1016/j.biopsycho.2006.06.001
   Lahiri A, 2010, J PHONETICS, V38, P44, DOI 10.1016/j.wocn.2010.01.002
   Lawyer LA, 2018, LANG COGN NEUROSCI, V33, P50, DOI 10.1080/23273798.2017.1359635
   Lawyer LA, 2017, LANG COGN NEUROSCI, V32, P1176, DOI 10.1080/23273798.2017.1318213
   Lee S.-H., 2010, ESTUDOS LINGUISTICOS, V39, P35
   Lee S.-H., 2013, ORGANON, V28, P101
   Massini-Cagliari G., 2016, HDB PORTUGUESE LINGU, P56, DOI [10. 1002/9781118791844.ch4., DOI 10.1002/9781118791844.CH4]
   Mateus Maria H., 2000, PHONOLOGY PORTUGUESE
   Miglietta S, 2013, BRAIN LANG, V126, P285, DOI 10.1016/j.bandl.2013.06.001
   Moraes Joao Antonio de, 1998, INTONATION SYSTEMS S, P179
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Naatanen R, 1999, PSYCHOL BULL, V125, P826, DOI 10.1037/0033-2909.125.6.826
   Naatanen R, 2001, PSYCHOPHYSIOLOGY, V38, P1, DOI 10.1017/S0048577201000208
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Naatanen R, 2011, PSYCHOPHYSIOLOGY, V48, P4, DOI 10.1111/j.1469-8986.2010.01114.x
   Nadeu M, 2014, J PHONETICS, V46, P1, DOI 10.1016/j.wocn.2014.05.003
   Nevins A, 2012, LET HOJE, V47, P228
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Phillips C, 2001, COGNITIVE SCI, V25, P711, DOI 10.1016/S0364-0213(01)00049-0
   Pisoni D. B., 1972, SR3132 STAT REP SPEE, V31/32, P83
   PITT MA, 1990, J EXP PSYCHOL HUMAN, V16, P564, DOI 10.1037/0096-1523.16.3.564
   Salo S, 1999, EAR HEARING, V20, P265, DOI 10.1097/00003446-199906000-00008
   Santana AP, 2018, ACTA LINGUIST HUNGAR, V65, P69, DOI 10.1556/2062.2018.65.1.4
   Scharinger M, 2016, NEUROIMAGE, V128, P293, DOI 10.1016/j.neuroimage.2016.01.003
   Scharinger M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040953
   Scharinger M, 2012, J SPEECH LANG HEAR R, V55, P903, DOI 10.1044/1092-4388(2011/11-0065)
   Scharinger M, 2010, J NEUROLINGUIST, V23, P383, DOI 10.1016/j.jneuroling.2010.02.005
   Schluter K, 2016, LANG COGN NEUROSCI, V31, P728, DOI 10.1080/23273798.2016.1151058
   Schluter KT, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00746
   Schroger E, 2014, BRAIN TOPOGR, V27, P565, DOI 10.1007/s10548-013-0334-6
   Schroger E, 1998, BEHAV RES METH INS C, V30, P131, DOI 10.3758/BF03209423
   Schroger E, 1996, EVOKED POTENTIAL, V100, P517, DOI 10.1016/S0921-884X(96)95576-9
   Sharma A, 1999, J ACOUST SOC AM, V106, P1078, DOI 10.1121/1.428048
   Sharma A, 2000, J ACOUST SOC AM, V107, P2697, DOI 10.1121/1.428655
   Silva DMR, 2017, PSYCHOPHYSIOLOGY, V54, P591, DOI 10.1111/psyp.12824
   SILVA Daniel Márcio Rodrigues, 2016, DELTA, V32, P355, DOI 10.1590/0102-4450984064164376868
   Spahr C, 2014, LINGUIST REV, V31, P551, DOI 10.1515/tlr-2014-0008
   Steriade D., 1994, POSITIONAL NEUTRALIZ
   Sussman ES, 2014, BRAIN TOPOGR, V27, P553, DOI 10.1007/s10548-013-0326-6
   SYRDAL AK, 1986, J ACOUST SOC AM, V79, P1086, DOI 10.1121/1.393381
   Tervaniemi M, 1997, NEUROREPORT, V8, P2571, DOI 10.1097/00001756-199707280-00030
   TRAUNMULLER H, 1990, J ACOUST SOC AM, V88, P97, DOI 10.1121/1.399849
   TRAUNMULLER H, 1981, J ACOUST SOC AM, V69, P1465, DOI 10.1121/1.385780
   Virtala P, 2018, BIOL PSYCHOL, V132, P217, DOI 10.1016/j.biopsycho.2018.01.002
   Wang JT, 2005, PSYCHOPHYSIOLOGY, V42, P43, DOI 10.1111/j.1469-8986.2005.00260.x
   WETZELS L., 2011, TONES AND FEATURES, P331, DOI DOI 10.1515/9783110246223.331
   WHALEN DH, 1995, J PHONETICS, V23, P349, DOI 10.1016/S0095-4470(95)80165-0
   WINKLER I, 1993, PERCEPT PSYCHOPHYS, V53, P443, DOI 10.3758/BF03206788
   Winkler I, 1999, COGNITIVE BRAIN RES, V7, P357, DOI 10.1016/S0926-6410(98)00039-1
   Winkler I, 1999, PSYCHOPHYSIOLOGY, V36, P638, DOI 10.1017/S0048577299981908
   WINKLER I, 1992, NEUROSCI LETT, V140, P239, DOI 10.1016/0304-3940(92)90111-J
   Winkler I, 2009, TRENDS COGN SCI, V13, P532, DOI 10.1016/j.tics.2009.09.003
   Zachau S, 2005, NEUROREPORT, V16, P2015, DOI 10.1097/00001756-200512190-00009
   Zhang Y, 2005, NEUROIMAGE, V26, P703, DOI 10.1016/j.neuroimage.2005.02.040
NR 96
TC 1
Z9 1
U1 1
U2 3
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PD FEB 4
PY 2020
VL 35
IS 2
BP 163
EP 178
DI 10.1080/23273798.2019.1638948
EA JUL 2019
PG 16
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA KC5ZK
UT WOS:000479724200001
DA 2021-02-24
ER

PT J
AU Kroger, BJ
   Bafna, T
   Cao, MX
AF Kroeger, Bernd J.
   Bafna, Tanya
   Cao, Mengxue
TI Emergence of an Action Repository as Part of a Biologically Inspired
   Model of Speech Processing: The Role of Somatosensory Information in
   Learning Phonetic-Phonological Sound Features
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE neural model simulation; speech production and acquisition; speech
   perception; neural self-organization; connectionism and neural nets
ID SELF-ORGANIZING MAPS; ACQUISITION; EXTRACTION; LANGUAGE; ACCESS; BRAIN
AB A comprehensive model of speech processing and speech learning has been established. The model comprises a mental lexicon, an action repository and an articulatory-acoustic module for executing motor plans and generating auditory and somatosensory feedback information (Kroger and Cao, 2015). In this study a "model language" based on three auditory and motor realizations of 70 monosyllabic words has been trained in order to simulate early phases of speech acquisition (babbling and imitation). We were able to show that (i) the emergence of phonetic-phonological features results from an increasing degree of ordering of syllable representations within the action repository and that (ii) this ordering or arrangement of syllables is mainly shaped by auditory information. Somatosensory information helps to increase the speed of learning. Especially consonantal features like place of articulation are learned earlier if auditory information is accompanied by somatosensory information. It can be concluded that somatosensory information as it is generated already during the babbling and the imitation phase of speech acquisition is very helpful especially for learning features like place of articulation. After learning is completed acoustic information together with semantic information is sufficient for determining the phonetic-phonological information from the speech signal. Moreover it is possible to learn phonetic-phonological features like place of articulation from auditory and semantic information only but not as fast as when somatosensory information is also available during the early stages of learning.
C1 [Kroeger, Bernd J.] Rhein Westfal TH Aachen, Med Sch, Dept Phoniatr Pedaudiol & Commun Disorders, Neurophonet Grp, Aachen, Germany.
   [Bafna, Tanya] Rhein Westfal TH Aachen, Med Sch, Aachen, Germany.
   [Cao, Mengxue] Beijing Normal Univ, Sch Chinese Language & Literature, Beijing, Peoples R China.
RP Kroger, BJ (corresponding author), Rhein Westfal TH Aachen, Med Sch, Dept Phoniatr Pedaudiol & Commun Disorders, Neurophonet Grp, Aachen, Germany.
EM bernd.kroecger@rwth-aachen.de
CR Alahakoon D, 2000, IEEE T NEURAL NETWOR, V11, P601, DOI 10.1109/72.846732
   Bauer D, 2009, LECT NOTES COMPUT SC, V5641, P344, DOI 10.1007/978-3-642-03320-9_32
   Best CT, 2016, ECOL PSYCHOL, V28, P216, DOI 10.1080/10407413.2016.1230372
   Birkholz P, 2006, 7 INT SEM SPEECH PRO, P493
   Birkhoz P, 2007, IEEE T AUDIO SPEECH, V15, P1218, DOI 10.1109/TASL.2006.889731
   Bohland JW, 2010, J COGNITIVE NEUROSCI, V22, P1504, DOI 10.1162/jocn.2009.21306
   Brendel B, 2011, MOTOR CONTROL, V15, P34, DOI 10.1123/mcj.15.1.34
   Cao MX, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00236
   Castles A, 2004, COGNITION, V91, P77, DOI 10.1016/S0010-0277(03)00164-1
   Cholin J, 2008, APHASIOLOGY, V22, P1127, DOI 10.1080/02687030701820352
   Civier O, 2013, BRAIN LANG, V126, P263, DOI 10.1016/j.bandl.2013.05.016
   Dell GS, 1997, PSYCHOL REV, V104, P123, DOI 10.1037/0033-295X.104.1.123
   Feng YQ, 2011, J NEUROPHYSIOL, V106, P667, DOI 10.1152/jn.00638.2010
   Guenther FH, 2006, BRAIN LANG, V96, P280, DOI 10.1016/j.bandl.2005.06.001
   Guenther FH, 2012, J NEUROLINGUIST, V25, P408, DOI 10.1016/j.jneuroling.2009.08.006
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158
   Indefrey P, 2004, COGNITION, V92, P101, DOI 10.1016/j.cognition.2002.06.001
   Iverson JM, 2010, J CHILD LANG, V37, P229, DOI 10.1017/S0305000909990432
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Kohonen T., 2001, SELF ORG MAPS, V3rd
   Kohonen T, 2013, NEURAL NETWORKS, V37, P52, DOI 10.1016/j.neunet.2012.09.018
   Kroeger BJ, 2015, J PHONETICS, V53, P88, DOI 10.1016/j.wocn.2015.09.006
   Kroger BJ, 2014, EPJ NONLINEAR BIOMED, V2, DOI 10.1140/epjnbp15
   Kroger BJ, 2011, LECT NOTES COMPUT SC, V6800, P287, DOI 10.1007/978-3-642-25775-9_27
   Kroger BJ, 2009, SPEECH COMMUN, V51, P793, DOI 10.1016/j.specom.2008.08.002
   Kroger BJ, 2007, LECT NOTES COMPUT SC, V4775, P174
   Kroger B. J., 2011, ASSESSMENT MOTOR SPE, P325
   Lametti DR, 2012, J NEUROSCI, V32, P9351, DOI 10.1523/JNEUROSCI.0404-12.2012
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1
   LEVELT WJM, 1994, COGNITION, V50, P239, DOI 10.1016/0010-0277(94)90030-2
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Obleser J, 2004, J COGNITIVE NEUROSCI, V16, P31, DOI 10.1162/089892904322755539
   Obleser J, 2006, HUM BRAIN MAPP, V27, P562, DOI 10.1002/hbm.20201
   Obleser J, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00232
   OHMAN SEG, 1966, J ACOUST SOC AM, V39, P151, DOI 10.1121/1.1909864
   Saltzman E., 1989, ECOL PSYCHOL, V1, P333, DOI [10.1207/s15326969eco0104_2, DOI 10.1207/S15326969EC00104_, 10.1207/ s15326969-co0104_2, DOI 10.1207/S15326969ECO0104_2]
   Shestakova A, 2004, COGNITIVE BRAIN RES, V21, P342, DOI 10.1016/j.cogbrainres.2004.06.011
   Tyler MD, 2014, DEV PSYCHOBIOL, V56, P210, DOI 10.1002/dev.21195
   Walker GM, 2016, PSYCHON B REV, V23, P339, DOI 10.3758/s13423-015-0903-7
   Zuk J, 2018, J SPEECH LANG HEAR R, V61, P583, DOI 10.1044/2017_JSLHR-S-16-0106
NR 40
TC 2
Z9 2
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUL 10
PY 2019
VL 10
AR 1462
DI 10.3389/fpsyg.2019.01462
PG 17
WC Psychology, Multidisciplinary
SC Psychology
GA IH9FW
UT WOS:000474813000001
PM 31354560
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Zheng, XB
   Ji, YL
   Meng, XZ
AF Zheng, Xiaobei
   Ji, Yinglin
   Meng, Xiangzhi
TI Protracted Development on Native Tone Interpretation: Evidence From
   Mandarin-Learning Infants' Novel Word Learning
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE infant word learning; Mandarin tone; habituation; word-object
   association; tone; intonation
ID LEXICAL TONE; SPEECH-PERCEPTION; PHONETIC DETAIL; RECOGNITION;
   ACQUISITION; INTONATION; SOUNDS
AB Studies have shown that infants from cultures with tone languages develop categorical perception of their native lexical tone before their first birthday, but few studies have explored whether, and when, they interpret the phonemic function of lexical tone in word learning. Two habituation-switch experiments were conducted to explore whether Mandarin-learning infants could exploit tonal cues during their word learning, and detect a change when the association of two word-object pairs was switched. In Experiment 1, two words were solely differentiated by their lexical tones (fai/ vs. /fai/), and Mandarin-learning infants failed to detect the switch of tones at 14 months, but succeeded at 18 months. In Experiment 2, two words were markedly distinct (/fai/ vs. /bou/), and infants could detect the change of words as early as 14 months. The results indicate that infants may not refer to the lexical function of tone during their novel word learning until 18 months, even though infants from birth are able to distinguish the Tone 1 vs. Tone 3 contrast. Given that lexical tone is expressed by variations of the pitch contours, which are also related to intonation, infants' increasing knowledge of both tone and intonation may contribute to their misinterpretation of pitch contours in word learning at 14 months and, further, to their development of a sophisticated use of the phonemic function of lexical tone at 18 months of age.
C1 [Zheng, Xiaobei] Shenzhen Univ, Res Ctr Language & Cognit, Sch Foreign Languages, Shenzhen, Peoples R China.
   [Ji, Yinglin] Shenzhen Univ, Res Ctr Language & Cognit, Sch Arts & Humanities, Shenzhen, Peoples R China.
   [Meng, Xiangzhi] Peking Univ, Sch Psychol & Cognit Sci, Beijing Key Lab Behav & Mental Hlth, Beijing, Peoples R China.
RP Meng, XZ (corresponding author), Peking Univ, Sch Psychol & Cognit Sci, Beijing Key Lab Behav & Mental Hlth, Beijing, Peoples R China.
EM mengxzh@pku.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [NSFC: 81171016, 81371206]; National Social
   Sciences Foundation of China [17CYY018]
FX This study is funded by the National Natural Science Foundation of China
   (NSFC: 81171016, 81371206) and the National Social Sciences Foundation
   of China (17CYY018).
CR American Psychological Association [APA], 2010, PUBL MAN AM PSYCH AS
   Bolinger D., 1958, AM SPEECH, V33, P5, DOI DOI 10.2307/453459
   Burnham D, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02190
   Cheng YY, 2013, DEV NEUROPSYCHOL, V38, P281, DOI 10.1080/87565641.2013.799672
   Cohen L.B, 2004, HABIT X NEW PROGRAM
   Curtin S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01007
   Fennell CT, 2010, CHILD DEV, V81, P1376, DOI 10.1111/j.1467-8624.2010.01479.x
   Fromkin V.A., 1978, TONE LINGUISTIC SURV
   GANDOUR J, 1981, J CHINESE LINGUIST, V9, P20
   GANDOUR JT, 1978, LANG SPEECH, V21, P1, DOI 10.1177/002383097802100101
   Gotz A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00477
   Hay JF, 2015, CHILD DEV, V86, P10, DOI 10.1111/cdev.12269
   KARZON RG, 1989, PERCEPT PSYCHOPHYS, V45, P10, DOI 10.3758/BF03208026
   Khouw E, 2007, J PHONETICS, V35, P104, DOI 10.1016/j.wocn.2005.10.003
   [陶冶 Tao Ye], 2012, [心理学报, Acta Psychologica Sinica], V44, P1066
   Lecanuet J. P., 1998, PERCEPTUAL DEV VISUA
   LI CN, 1977, J CHILD LANG, V4, P185, DOI 10.1017/S0305000900001598
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Ma WY, 2017, COGNITION, V159, P139, DOI 10.1016/j.cognition.2016.11.011
   MacKenzie H, 2012, CHILD DEV, V83, P1129, DOI 10.1111/j.1467-8624.2012.01764.x
   MacKenzie H, 2011, DEVELOPMENTAL SCI, V14, P249, DOI 10.1111/j.1467-7687.2010.00975.x
   Mampe B, 2009, CURR BIOL, V19, P1994, DOI 10.1016/j.cub.2009.09.064
   Mani N, 2007, J MEM LANG, V57, P252, DOI 10.1016/j.jml.2007.03.005
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Namy LL, 1998, CHILD DEV, V69, P295, DOI 10.1111/j.1467-8624.1998.tb06189.x
   Nazzi T, 1998, INFANT BEHAV DEV, V21, P779, DOI 10.1016/S0163-6383(98)90044-3
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Singh L, 2017, J CHILD LANG, V44, P924, DOI 10.1017/S0305000916000325
   Singh L, 2016, CHILD DEV, V87, P834, DOI 10.1111/cdev.12512
   Singh L, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00667
   Singh L, 2016, J PHONETICS, V55, P109, DOI 10.1016/j.wocn.2015.12.005
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   [陶冶 Tao Ye], 2013, [心理学报, Acta Psychologica Sinica], V45, P1111
   Tsao FM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00558
   VANCE TJ, 1976, PHONETICA, V33, P368, DOI 10.1159/000259793
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   Werker JF, 1998, DEV PSYCHOL, V34, P1289, DOI 10.1037/0012-1649.34.6.1289
   Werker JF, 2005, TRENDS COGN SCI, V9, P519, DOI 10.1016/j.tics.2005.09.003
   Woodward AL, 1999, CHILD DEV, V70, P65, DOI 10.1111/1467-8624.00006
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   Yip M., 2002, TONE
   Zheng XB, 2018, LINGUA, V207, P38, DOI 10.1016/j.lingua.2018.02.007
NR 42
TC 0
Z9 0
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUL 5
PY 2019
VL 10
AR 1512
DI 10.3389/fpsyg.2019.01512
PG 11
WC Psychology, Multidisciplinary
SC Psychology
GA IH0TC
UT WOS:000474204400001
PM 31333543
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Smith, J
   Wang, J
   Grobler, AC
   Lange, K
   Clifford, SA
   Wake, M
AF Smith, Julia
   Wang, Jing
   Grobler, Anneke C.
   Lange, Katherine
   Clifford, Susan A.
   Wake, Melissa
TI Hearing, speech reception, vocabulary and language: population
   epidemiology and concordance in Australian children aged 11 to 12 years
   and their parents
SO BMJ OPEN
LA English
DT Article
DE reference values; children; inheritance patterns; pure-tone audiometry;
   speech perception; epidemiologic studies
ID OLDER-ADULTS; FOLLOW-UP; PREVALENCE; THRESHOLDS; DELAY; TWIN; NOISE;
   COMPREHENSION; ASSOCIATIONS; ADOLESCENTS
AB Objectives To describe the epidemiology and parent-child concordance of hearing, speech reception, vocabulary and language in Australian parent-child dyads at child age 11 to 12 years. Design Population-based cross-sectional study (Child Health CheckPoint) nested within the Longitudinal Study of Australian Children. Setting Assessment centres in seven Australian cities and eight regional towns or home visits around Australia, February 2015 to March 2016. Participants Of all participating CheckPoint families (n=1874), 1516 children (50% female) and 1520 parents (87% mothers, mean age 43.8 years) undertook at least one of four measurements of hearing and language. Outcome measures Hearing threshold (better ear mean of 1, 2 and 4 kHz) from pure-tone audiometry, speech reception threshold, receptive vocabulary, expressive and receptive languages using a sentence repetition task. Parent-child concordance was examined using Pearson's correlation coefficients and adjusted linear regression models. Survey weights and methods accounted for Longitudinal Study of Australian Children's complex sampling and stratification. Results Children had a similar speech reception threshold to parents (children mean -14.3, SD 2.4; parents -14.9, SD 3.2 dB) but better hearing acuity (children 8.3, SD 6.3; parents 13.4, SD 7.0 decibels hearing level). Standardised sentence repetition scores were similar (children 9.8, SD 2.9; parents 9.1, SD 3.3) but, as expected, parents had superior receptive vocabularies. Parent-child correlations were higher for the cognitively-based language measures (vocabulary 0.31, 95% CI 0.26 to 0.36; sentence repetition 0.29, 95% CI 0.24 to 0.34) than the auditory measures (hearing 0.18, 95% CI 0.13 to 0.23; speech reception threshold 0.18, 95% CI 0.13 to 0.22). Mother-child and father-child concordances were similar for all measures. Conclusions We provide population reference values for multiple measures spanning auditory and verbal communication systems in children and mid-life adults. Concordance values aligned with previous twin studies and offspring studies in adults, in keeping with polygenic heritability that is modest for audition but around 60% for language by late childhood.
C1 [Smith, Julia; Wang, Jing; Grobler, Anneke C.; Lange, Katherine; Clifford, Susan A.; Wake, Melissa] Murdoch Childrens Res Inst, Parkville, Vic, Australia.
   [Smith, Julia; Wang, Jing; Grobler, Anneke C.; Lange, Katherine; Clifford, Susan A.; Wake, Melissa] Univ Melbourne, Dept Paediat, Parkville, Vic, Australia.
   [Wake, Melissa] Univ Auckland, Dept Paediat, Auckland, New Zealand.
   [Wake, Melissa] Univ Auckland, Liggins Inst, Auckland, New Zealand.
RP Wake, M (corresponding author), Murdoch Childrens Res Inst, Parkville, Vic, Australia.; Wake, M (corresponding author), Univ Melbourne, Dept Paediat, Parkville, Vic, Australia.; Wake, M (corresponding author), Univ Auckland, Dept Paediat, Auckland, New Zealand.; Wake, M (corresponding author), Univ Auckland, Liggins Inst, Auckland, New Zealand.
EM melissa.wake@mcri.edu.au
RI Wake, Melissa/J-1396-2012
OI Wake, Melissa/0000-0001-7501-9257; Wang, Jing/0000-0001-5701-476X;
   Clifford, Susan/0000-0002-2678-9439; Lange,
   Katherine/0000-0002-8175-6285; Grobler, Anneke/0000-0002-7809-7688;
   Smith, Julia/0000-0002-9634-9471
FU National Health and Medical Research Council (NHMRC) of
   AustraliaNational Health and Medical Research Council of Australia
   [1041352, 1109355]; Royal Children's Hospital Foundation [2014-241];
   Murdoch Children's Research Institute (MCRI); National Heart Foundation
   of AustraliaNational Heart Foundation of Australia [100660]; Financial
   Markets Foundation for Children [2014-055, 2016310]; Victoria Deaf
   Education Institute; NHMRC Senior Research FellowshipNational Health and
   Medical Research Council of Australia [1046518]; Cure Kids New Zealand;
   Victorian Government's Operational Infrastructure Support Programme; The
   University of MelbourneUniversity of Melbourne
FX This work was supported by the National Health and Medical Research
   Council (NHMRC) of Australia (Project Grants 1041352, 1109355), The
   Royal Children's Hospital Foundation (2014-241), the Murdoch Children's
   Research Institute (MCRI), The University of Melbourne, the National
   Heart Foundation of Australia (100660), Financial Markets Foundation for
   Children (2014-055, 2016310), and the Victoria Deaf Education Institute.
   MW is supported by NHMRC Senior Research Fellowship 1046518 and Cure
   Kids New Zealand. The MCRI administered the research grants for the
   study and provided infrastructural support (IT and biospecimen
   management) to its staff and the study, but played no role in the
   conduct or analysis of the trial. DSS played a role in study design;
   however, no other funding bodies had a role in the study design and
   conduct; data collection, management, analysis and interpretation;
   preparation, review or approval of the manuscript; and decision to
   submit the manuscript for publication. Research at the MCRI is supported
   by the Victorian Government's Operational Infrastructure Support
   Programme.
CR Agrawal Y, 2008, ARCH INTERN MED, V168, P1522, DOI 10.1001/archinte.168.14.1522
   Akshoomoff N, 2014, NEUROPSYCHOLOGY, V28, P1, DOI 10.1037/neu0000001
   Baiduc RR, 2013, DM-DIS MON, V59, P147, DOI 10.1016/j.disamonth.2013.01.005
   Besser J, 2015, EAR HEARING, V36, P24, DOI 10.1097/AUD.0000000000000096
   Cameron S, 2007, EAR HEARING, V28, P196, DOI 10.1097/AUD.0b013e318031267f
   Cameron S, 2011, J AM ACAD AUDIOL, V22, P697, DOI 10.3766/jaaa.22.10.7
   Clegg J, 2005, J CHILD PSYCHOL PSYC, V46, P128, DOI 10.1111/j.1469-7610.2004.00342.x
   Clifford S, 2018, LONGITUDINAL STUDY A
   Clifford SA, 2019, BMJ OPEN, V9, P3, DOI 10.1136/bmjopen-2017-020261
   Edwards B, 2014, FAMILY MATTERS, P5
   Ellul S, 2018, LONGITUDINAL STUDY A, DOI [10.25374/MCRI. 5687593, DOI 10.25374/MCRI.5687593]
   Emmett SD, 2015, OTOL NEUROTOL, V36, P545, DOI 10.1097/MAO.0000000000000562
   Gates GA, 1999, ARCH OTOLARYNGOL, V125, P654, DOI 10.1001/archotol.125.6.654
   Gershon RC, 2013, MONOGR SOC RES CHILD, V78, P49, DOI 10.1111/mono.12034
   Gopinath B, 2009, ARCH INTERN MED, V169, P415, DOI 10.1001/archinternmed.2008.597
   Haworth CMA, 2010, MOL PSYCHIATR, V15, P1112, DOI 10.1038/mp.2009.55
   Hayiou-Thomas ME, 2012, DEVELOPMENTAL SCI, V15, P233, DOI 10.1111/j.1467-7687.2011.01119.x
   Heeringa SG WB, 2010, APPL SURVEY DATA ANA
   Hendrickx JJ, 2013, OTOL NEUROTOL, V34, P838, DOI 10.1097/MAO.0b013e318288646a
   Hoekstra RA, 2009, DEVELOPMENTAL SCI, V12, P1041, DOI 10.1111/j.1467-7687.2009.00843.x
   Kvestad E, 2012, EPIDEMIOLOGY, V23, P328, DOI 10.1097/EDE.0b013e318245996e
   Law J, 2000, INT J LANG COMM DIS, V35, P165, DOI 10.1080/136828200247133
   Law J, 2000, DEV MED CHILD NEUROL, V42, P190, DOI 10.1017/S0012162200000335
   le Clercq CMP, 2017, JAMA OTOLARYNGOL, V143, P928, DOI 10.1001/jamaoto.2017.1068
   Marcoux AM, 2012, J ACOUST SOC AM, V131, P2787, DOI 10.1121/1.3689550
   Mason A, 2007, PRIMARY CARE, V34, P407, DOI 10.1016/j.pop.2007.04.003
   McLeod S, 2007, INT J LANG COMM DIS, V42, P37, DOI 10.1080/13682820601173262
   Moore JK, 2007, INT J AUDIOL, V46, P460, DOI 10.1080/14992020701383019
   Morell RJ, 2007, HUM GENET, V122, P103, DOI 10.1007/s00439-007-0384-5
   Morris MA, 2016, DISABIL HEALTH J, V9, P140, DOI 10.1016/j.dhjo.2015.07.004
   Nelson HD, 2006, PEDIATRICS, V117, pE298, DOI 10.1542/peds.2005-1467
   Noble W, 2009, AUST FAM PHYSICIAN, V38, P591
   Olson RK, 2011, SCI STUD READ, V15, P26, DOI 10.1080/10888438.2011.536128
   Pink B., 2013, SOCIOECONOMIC INDEXE
   Rice ML, 2015, J SPEECH LANG HEAR R, V58, P345, DOI 10.1044/2015_JSLHR-L-14-0150
   Rutter M, 2003, J CHILD PSYCHOL PSYC, V44, P326, DOI 10.1111/1469-7610.00125
   Salthouse TA, 2017, NEUROPSYCHOLOGY, V31, P11, DOI 10.1037/neu0000330
   Salthouse TA, 2014, INTELLIGENCE, V46, P122, DOI 10.1016/j.intell.2014.05.009
   Sanson A, 2004, FAMILY MATTERS, V67, P46
   Semel E, 2006, CLIN EVALUATION LANG
   Shargorodsky J, 2010, JAMA-J AM MED ASSOC, V304, P772, DOI 10.1001/jama.2010.1124
   Slotkin J, 2012, NIH TOOLBOX TECHNICA
   Smits C, 2006, EAR HEARING, V27, P538, DOI 10.1097/01.aud.0000233917.72551.cf
   Stollman MHP, 2004, INT J AUDIOL, V43, P34, DOI 10.1080/14992020400050006
   Stothard SE, 1998, J SPEECH LANG HEAR R, V41, P407, DOI 10.1044/jslhr.4102.407
   Teunisse RJ, 2012, AM J GERIAT PSYCHIAT, V20, P1075, DOI 10.1097/JGP.0b013e31823e31c4
   Twardella D, 2013, NOISE HEALTH, V15, P412, DOI 10.4103/1463-1741.121241
   VandenLangenberg GM, 1998, AM J EPIDEMIOL, V148, P204, DOI 10.1093/oxfordjournals.aje.a009625
   Wake M, 2014, FAM MATTERS, V95, P15
   Wang J, 2018, ARCH DIS CHILD, V103, P579, DOI 10.1136/archdischild-2017-313505
   Wassenberg R, 2008, J CLIN EXP NEUROPSYC, V30, P435, DOI 10.1080/13803390701523091
   Williams W, 2014, INT J AUDIOL, V53, P289, DOI 10.3109/14992027.2013.873957
   Wilson RH, 2014, J AM ACAD AUDIOL, V25, P171, DOI 10.3766/jaaa.25.2.6
   Wingfield A, 2007, J GERONTOL A-BIOL, V62, P1294, DOI 10.1093/gerona/62.11.1294
   Wolf MS, 2012, J GEN INTERN MED, V27, P1300, DOI 10.1007/s11606-012-2079-4
NR 55
TC 2
Z9 2
U1 1
U2 2
PU BMJ PUBLISHING GROUP
PI LONDON
PA BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND
SN 2044-6055
J9 BMJ OPEN
JI BMJ Open
PD JUL 4
PY 2019
VL 9
SU 3
SI SI
BP 85
EP 94
DI 10.1136/bmjopen-2018-023196
PG 10
WC Medicine, General & Internal
SC General & Internal Medicine
GA IM1DR
UT WOS:000477729200009
PM 31273019
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Fecher, N
   Johnson, EK
AF Fecher, Natalie
   Johnson, Elizabeth K.
TI By 4.5 Months, Linguistic Experience Already Affects Infants' Talker
   Processing Abilities
SO CHILD DEVELOPMENT
LA English
DT Article
ID VOICE RECOGNITION; LANGUAGE; PERCEPTION; FAMILIARITY; CHILDREN;
   DISCRIMINATION; IDENTIFICATION; COMPREHENSION; INFORMATION; VARIABILITY
AB Contemporary models of adult speech perception acknowledge that the processing of linguistic and nonlinguistic aspects of the speech signal are interdependent. But when in development does this interdependence first emerge? In the adult literature, one way to demonstrate this relationship has been to examine how language experience affects talker identification. Thus, in this study, 4- to 5-month-old infants (N = 96) were tested on their ability to tell apart talkers in a familiar language (English) compared to unfamiliar languages (Polish or Spanish). Infants readily distinguished between talkers in the familiar language but not in the unfamiliar languages, supporting the hypothesis that the integrated processing of linguistic and nonlinguistic information in speech is early emerging and robust.
C1 [Fecher, Natalie; Johnson, Elizabeth K.] Univ Toronto Mississauga, Mississauga, ON, Canada.
RP Johnson, EK (corresponding author), Univ Toronto Mississauga, Dept Psychol, 3359 Mississauga Rd, Mississauga, ON L5L 1C6, Canada.
EM eliza-beth.johnson@utoronto.ca
OI Johnson, Elizabeth Kay/0000-0002-9941-9949
FU SSHRC (Social Sciences and Humanities Research Council of Canada)Social
   Sciences and Humanities Research Council of Canada (SSHRC); CRC (Canada
   Research Chairs) ProgramCanada Research Chairs; NSERC (Natural Sciences
   and Engineering Research Council of Canada)Natural Sciences and
   Engineering Research Council of Canada (NSERC)
FX Thanks to Lisa Hotson, the members of the Child Language and Speech
   Studies lab, and all participating families. This research was supported
   by grants awarded to E.K.J. from SSHRC (Social Sciences and Humanities
   Research Council of Canada), NSERC (Natural Sciences and Engineering
   Research Council of Canada), and the CRC (Canada Research Chairs)
   Program. Portions of this work were presented at the 58th Annual Meeting
   of the Psychonomic Society in Vancouver, BC, Canada, November 2017.
CR Andics A., 2007, P 16 INT C PHON SCI
   BALDWIN DA, 1993, DEV PSYCHOL, V29, P832, DOI 10.1037/0012-1649.29.5.832
   Barker BA, 2004, COGNITION, V94, pB45, DOI 10.1016/j.cognition.2004.06.001
   BARTHOLOMEUS B, 1973, CAN J PSYCHOL, V27, P464, DOI 10.1037/h0082498
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   Bergmann C, 2018, INFANCY, V23, P484, DOI 10.1111/infa.12232
   Borovsky A, 2014, DEV PSYCHOL, V50, P1600, DOI 10.1037/a0035591
   Brooks R, 2005, DEVELOPMENTAL SCI, V8, P535, DOI 10.1111/j.1467-7687.2005.00445.x
   Creel SC, 2008, COGNITION, V106, P633, DOI 10.1016/j.cognition.2007.03.013
   Creel SC, 2012, J EXP CHILD PSYCHOL, V113, P487, DOI 10.1016/j.jecp.2012.07.007
   Cutler A., 2011, P 17 INT C PHON SCI, P552
   DECASPER AJ, 1980, SCIENCE, V208, P1174, DOI 10.1126/science.7375928
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   Fecher N, 2019, INFANCY, V24, P570, DOI 10.1111/infa.12290
   Fecher N, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12778
   Fecher N, 2018, J ACOUST SOC AM, V143, P2409, DOI 10.1121/1.5032199
   Fecher N, 2018, J EXP PSYCHOL LEARN, V44, P1911, DOI 10.1037/xlm0000555
   Floccia C, 2000, DEVELOPMENTAL SCI, V3, P333, DOI 10.1111/1467-7687.00128
   Fodor J., 1983, MODULARITY MIND
   GOGGIN JP, 1991, MEM COGNITION, V19, P448, DOI 10.3758/BF03199567
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Gonzales K, 2018, COGNITIVE PSYCHOL, V106, P1, DOI 10.1016/j.cogpsych.2018.04.003
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   Houston DM, 2000, J EXP PSYCHOL HUMAN, V26, P1570, DOI 10.1037/0096-1523.26.5.1570
   Houston-Price C, 2004, INFANT CHILD DEV, V13, P341, DOI 10.1002/icd.364
   Hunter M. A., 1988, ADV INFANCY RES, V5, P69, DOI DOI 10.1037/0012-1649.19.3.338
   JERGER S, 1988, BRAIN LANG, V35, P86, DOI 10.1016/0093-934X(88)90102-2
   Johnson EK, 2018, COGNITIVE SCI, V42, P633, DOI 10.1111/cogs.12520
   Johnson EK, 2016, ANNU REV LINGUIST, V2, P391, DOI 10.1146/annurev-linguistics-011415-040616
   Johnson EK, 2011, DEVELOPMENTAL SCI, V14, P1002, DOI 10.1111/j.1467-7687.2011.01052.x
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Kidd E, 2012, DEV PSYCHOL, V48, P171, DOI 10.1037/a0025405
   Lecanuet J.-P., 1993, EARLY DEV PARENTING, V2, P217, DOI [10.1002/edp.2430020405, DOI 10.1002/EDP.2430020405, 10.1002/edp.]
   Levi SV, 2019, WIRES COGN SCI, V10, DOI 10.1002/wcs.1483
   Levi SV, 2018, BILING-LANG COGN, V21, P523, DOI 10.1017/S1366728917000153
   Levi SV, 2013, J SPEECH LANG HEAR R, V56, P913, DOI 10.1044/1092-4388(2012/12-0095)
   MANN VA, 1979, J EXP CHILD PSYCHOL, V27, P153, DOI 10.1016/0022-0965(79)90067-5
   Mather E, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00491
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   MEHLER J, 1978, PERCEPTION, V7, P491, DOI 10.1068/p070491
   MILLER CL, 1983, INFANT BEHAV DEV, V6, P313, DOI 10.1016/S0163-6383(83)80040-X
   MILLS M, 1974, NATURE, V252, P123, DOI 10.1038/252123a0
   MULLENNIX JW, 1990, PERCEPT PSYCHOPHYS, V47, P379, DOI 10.3758/BF03210878
   NITTROUER S, 1992, J PHONETICS, V20, P351, DOI 10.1016/S0095-4470(19)30639-4
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Oakes LM, 2010, J COGN DEV, V11, P255, DOI 10.1080/15248371003699977
   Ohde RN, 1997, J ACOUST SOC AM, V102, P3711, DOI 10.1121/1.420135
   Orena AJ, 2015, COGNITION, V143, P36, DOI 10.1016/j.cognition.2015.06.002
   Paquette-Smith M., 2015, P 18 INT C PHON SCI
   Pell MD, 2008, SPEECH COMMUN, V50, P519, DOI 10.1016/j.specom.2008.03.006
   Perea M, 2014, EXP PSYCHOL, V61, P480, DOI 10.1027/1618-3169/a000265
   Perrachione T. K., 2017, OXFORD HDB VOICE PER, P515
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Scherer KR, 2001, J CROSS CULT PSYCHOL, V32, P76, DOI 10.1177/0022022101032001009
   Tincoff R, 1999, PSYCHOL SCI, V10, P172, DOI 10.1111/1467-9280.00127
   van der Feest SVH, 2016, LANG ACQUIS, V23, P89, DOI 10.1080/10489223.2015.1047096
   Weatherhead D, 2016, LANG LEARN DEV, V12, P92, DOI 10.1080/15475441.2015.1024835
NR 58
TC 2
Z9 2
U1 0
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0009-3920
EI 1467-8624
J9 CHILD DEV
JI Child Dev.
PD SEP
PY 2019
VL 90
IS 5
BP 1535
EP 1543
DI 10.1111/cdev.13280
EA JUL 2019
PG 9
WC Psychology, Educational; Psychology, Developmental
SC Psychology
GA IY6RS
UT WOS:000474161900001
PM 31273757
DA 2021-02-24
ER

PT J
AU Kim, D
   Clayards, M
AF Kim, Donghyun
   Clayards, Meghan
TI Individual differences in the link between perception and production and
   the mechanisms of phonetic imitation
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Phonetic imitation; perception-production link; cue weighting;
   individual differences; vowel contrasts
ID SPEECH-PERCEPTION; VERTICAL-BAR; ENGLISH; LISTENERS; DURATION; SPANISH;
   SALIENCE; CONTRAST; SPEAKERS; VOWELS
AB This study investigates the relationship between speech perception and production using explicit phonetic imitation. We used manipulated natural vowel (head-had) stimuli varying in spectral quality and duration in both perception and production tasks to explore the perception-production link in a direct and controlled way. We examined (1) whether individual listeners' perceptual cue weights are related to their patterns of phonetic imitation and (2) phonological and perceptual constraints underlying phonetic imitation. Results showed that better perceptual abilities (i.e. larger cue weights) were related to better imitation of vowel duration. Furthermore, imitation of vowel spectral quality was mediated by contrast maintenance while vowel duration was not. Overall, vowel duration was better imitated despite being the less important cue perceptually. These results suggest that speech perception and production are indeed linked at the individual level, and both linguistic and perceptual-cognitive factors play a role in this process.
C1 [Kim, Donghyun; Clayards, Meghan] McGill Univ, Dept Linguist, Montreal, PQ, Canada.
   [Clayards, Meghan] McGill Univ, Sch Commun Sci & Disorders, Montreal, PQ, Canada.
   [Kim, Donghyun] Univ Exeter, Dept Psychol, Exeter, Devon, England.
RP Kim, D (corresponding author), McGill Univ, Dept Linguist, Montreal, PQ, Canada.; Kim, D (corresponding author), Univ Exeter, Dept Psychol, Exeter, Devon, England.
EM d.kim2@exeter.ac.uk
OI Kim, Donghyun/0000-0003-1972-2508
FU Social Sciences and Humanities Research Council of CanadaSocial Sciences
   and Humanities Research Council of Canada (SSHRC) [435-2016-0747]
FX This work was supported by Social Sciences and Humanities Research
   Council of Canada [grant number 435-2016-0747] to Meghan Clayards.
CR AINSWORTH WA, 1984, J PHONETICS, V12, P237, DOI 10.1016/S0095-4470(19)30880-0
   Babel M, 2014, LAB PHONOL, V5, P123, DOI 10.1515/lp-2014-0006
   Babel M, 2012, LANG SPEECH, V55, P231, DOI 10.1177/0023830911417695
   Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001
   BAILEY PJ, 1980, PHONETICA, V37, P377, DOI 10.1159/000260004
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Beddor PS, 2018, LANGUAGE, V94, P931, DOI 10.1353/lan.2018.0051
   Boberg C, 2008, J ENGL LINGUIST, V36, P129, DOI 10.1177/0075424208316648
   Boersma P, 2015, PRAAT DOING PHONETIC
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Brunner J, 2011, J SPEECH LANG HEAR R, V54, P727, DOI 10.1044/1092-4388(2010/09-0256)
   Clopper CG, 2006, SPEECH COMMUN, V48, P633, DOI 10.1016/j.specom.2005.09.010
   Coetzee AW, 2018, J PHONETICS, V66, P185, DOI 10.1016/j.wocn.2017.09.009
   D'Imperio M., 2015, P 18 INT C PHON SCI
   Delaney M., 2010, CANADIAN ACOUSTICS, V38, P132
   Delvaux V, 2007, PHONETICA, V64, P145, DOI 10.1159/000107914
   Dufour S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00346
   Escudero Paola., 2000, THESIS
   FLEGE JE, 1988, J ACOUST SOC AM, V83, P729, DOI 10.1121/1.396115
   FOX RA, 1982, PHONETICA, V39, P1, DOI 10.1159/000261647
   Frieda EM, 2000, J SPEECH LANG HEAR R, V43, P129, DOI 10.1044/jslhr.4301.129
   Gambi C, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00340
   Garrod S, 2004, TRENDS COGN SCI, V8, P8, DOI 10.1016/j.tics.2003.10.016
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Hay J, 2018, LANGUAGE, V94, P360, DOI 10.1353/lan.2018.0020
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hillenbrand JM, 2000, J ACOUST SOC AM, V108, P3013, DOI 10.1121/1.1323463
   Honeybone P, 2013, ENGL WORLD-WIDE, V34, P305, DOI 10.1075/eww.34.3.03hon
   Honorof DN, 2011, J PHONETICS, V39, P18, DOI 10.1016/j.wocn.2010.10.007
   HOUSE AS, 1953, J ACOUST SOC AM, V25, P105, DOI 10.1121/1.1906982
   Iverson P, 1996, J ACOUST SOC AM, V99, P1130, DOI 10.1121/1.415234
   Jaeger TF, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01115
   Kawahara H., 2009, P AS PAC SIGN INF PR, P111
   Kondaurova MV, 2010, J PHONETICS, V38, P569, DOI 10.1016/j.wocn.2010.08.003
   Kondaurova MV, 2008, J ACOUST SOC AM, V124, P3959, DOI 10.1121/1.2999341
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Kuznetsova A., 2015, LMERTEST
   Kwon H., 2015, P 18 INT C PHON SCI
   Labov W., 2006, ATLAS N AM ENGLISH P
   Liberman AM, 2000, TRENDS COGN SCI, V4, P187, DOI 10.1016/S1364-6613(00)01471-6
   Liu R, 2015, J EXP PSYCHOL HUMAN, V41, P1783, DOI 10.1037/xhp0000092
   MacLeod B., 2015, AMPERSAND, V2, P83, DOI [10.1016/j.amper.2015.07.001, DOI 10.1016/J.AMPER.2015.07.001]
   Mitterer H, 2013, ATTEN PERCEPT PSYCHO, V75, P557, DOI 10.3758/s13414-012-0407-8
   Mitterer H, 2008, COGNITION, V109, P168, DOI 10.1016/j.cognition.2008.08.002
   Morrison GS, 2009, J ACOUST SOC AM, V126, P2159, DOI 10.1121/1.3216917
   Morrison GS, 2005, STUD SECOND LANG ACQ, V27, P597, DOI 10.1017/S0272263105050266
   Morrison GS, 2007, SEGMENTAL PROSODIC I, P219
   Newman RS, 2003, J ACOUST SOC AM, V113, P2850, DOI 10.1121/1.1567280
   Nielsen K., 2015, P 18 INT C PHON SCI
   Nielsen K, 2014, J SPEECH LANG HEAR R, V57, P2065, DOI 10.1044/2014_JSLHR-S-13-0093
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007
   Nguyen N, 2015, J PHONETICS, V53, P46, DOI 10.1016/j.wocn.2015.08.004
   NOSOFSKY RM, 1991, COGNITIVE PSYCHOL, V23, P94, DOI 10.1016/0010-0285(91)90004-8
   Nye PW, 2003, J PHONETICS, V31, P63, DOI 10.1016/S0095-4470(02)00072-4
   Pardo JS, 2013, J MEM LANG, V69, P183, DOI 10.1016/j.jml.2013.06.002
   Perkell JS, 2004, J ACOUST SOC AM, V116, P2338, DOI 10.1121/1.1787524
   PETERSON GE, 1960, J ACOUST SOC AM, V32, P693, DOI 10.1121/1.1908183
   Phillips B, 2011, SLEEP MED, V12, P3, DOI 10.1016/j.sleep.2010.10.002
   Podlipsky V. J., 2015, P 18 INT C PHON SCI
   Postma-Nilsenova M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00826
   R Core Team, 2016, R LANG ENV STAT COMP
   Racz P., 2013, SALIENCE SOCIOLINGUI
   Rochet B. L., 1995, SPEECH PERCEPTION LI, P379
   Savill N, 2017, NEUROPSYCHOLOGIA, V98, P85, DOI 10.1016/j.neuropsychologia.2016.03.006
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   Shockley K, 2004, PERCEPT PSYCHOPHYS, V66, P422, DOI 10.3758/BF03194890
   Shultz AA, 2012, J ACOUST SOC AM, V132, pEL95, DOI 10.1121/1.4736711
   Tilsen S, 2009, J PHONETICS, V37, P276, DOI 10.1016/j.wocn.2009.03.004
   Walker A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00546
   Yu ACL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0074746
   Zellou G., 2013, P M AC, V19
   Zellou G, 2017, LANG COGN NEUROSCI, V32, P776, DOI 10.1080/23273798.2016.1275710
   Zellou G, 2017, J PHONETICS, V61, P13, DOI 10.1016/j.wocn.2016.12.002
   Zellou G, 2016, J ACOUST SOC AM, V140, P3560, DOI 10.1121/1.4966232
   Zetterholm Elisabeth, 2007, Speaker Classification II. Selected Projects. (Lecture Notes in Artificial Intelligence Vol.4441), P192
NR 75
TC 3
Z9 3
U1 0
U2 5
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PD JUL 3
PY 2019
VL 34
IS 6
BP 769
EP 786
DI 10.1080/23273798.2019.1582787
PG 18
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA HU8YD
UT WOS:000465577600006
DA 2021-02-24
ER

PT J
AU Brang, D
AF Brang, David
TI The Stolen Voice Illusion
SO PERCEPTION
LA English
DT Article
DE multisensory; cross-modal; auditory-visual; speech; congruity; gender;
   identity
ID MULTISENSORY INTEGRATION; UNITY ASSUMPTION; SPEECH; PERCEPTION;
   IDENTITY; BINDING; SIGNALS; FACES; CUES
AB Visual cues facilitate speech perception during face-to-face communication, particularly in noisy environments. These visual-driven enhancements arise from both automatic lip-reading behaviors and attentional tuning to auditory-visual signals. However, in crowded settings, such as a cocktail party, how do we accurately bind the correct voice to the correct face, enabling the benefit of visual cues on speech perception processes? Previous research has emphasized that spatial and temporal alignment of the auditory-visual signals determines which voice is integrated with which speaking face. Here, we present a novel illusion demonstrating that when multiple faces and voices are presented in the presence of ambiguous temporal and spatial information as to which pairs of auditory-visual signals should be integrated, our perceptual system relies on identity information extracted from each signal to determine pairings. Data from three experiments demonstrate that expectations about an individual's voice (based on their identity) can change where individuals perceive that voice to arise from.
C1 [Brang, David] Univ Michigan, Dept Psychol, 530 Church St, Ann Arbor, MI 48109 USA.
RP Brang, D (corresponding author), Univ Michigan, Dept Psychol, 530 Church St, Ann Arbor, MI 48109 USA.
EM djbrang@umich.edu
OI Brang, David/0000-0002-2706-6777
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R00 DC013828]; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R00DC013828, R00DC013828, K99DC013828, R00DC013828] Funding Source: NIH
   RePORTER
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This study
   was supported by NIH Grant R00 DC013828.
CR Adler R. K., 2012, VOICE COMMUNICATION
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Chen YC, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00445
   Chuen L, 2016, ATTEN PERCEPT PSYCHO, V78, P1512, DOI 10.3758/s13414-016-1088-5
   CRYSTAL TH, 1982, J ACOUST SOC AM, V72, P705, DOI 10.1121/1.388251
   Dabbs JM, 1999, PERS INDIV DIFFER, V27, P801, DOI 10.1016/S0191-8869(98)00272-4
   Davies S, 2006, INT J TRANSGENDERISM, V9, P167, DOI 10.1300/J485v09n03_08
   DIXON NF, 1980, PERCEPTION, V9, P719, DOI 10.1068/p090719
   Fant G, 1971, ACOUSTIC THEORY SPEE, V2
   Ghazanfar AA, 2005, J NEUROSCI, V25, P5004, DOI 10.1523/JNEUROSCI.0799-05.2005
   Grant K. W., 2003, AVSP 2003 INT C AUD
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Greenberg S, 2003, J PHONETICS, V31, P465, DOI 10.1016/j.wocn.2003.09.005
   GREENHOUSE SW, 1959, PSYCHOMETRIKA, V24, P95, DOI 10.1007/BF02289823
   Kamachi M, 2003, CURR BIOL, V13, P1709, DOI 10.1016/j.cub.2003.09.005
   Kanaya S, 2011, PSYCHON B REV, V18, P123, DOI 10.3758/s13423-010-0027-z
   Keetels M, 2005, EXP BRAIN RES, V167, P635, DOI 10.1007/s00221-005-0067-1
   Kim J, 2004, SPEECH COMMUN, V44, P19, DOI 10.1016/j.specom.2004.09.008
   Kim J, 2003, PERCEPTION, V32, P111, DOI 10.1068/p3466
   Lachs L, 2004, ECOL PSYCHOL, V16, P159, DOI 10.1207/s15326969eco1603_1
   Lee H, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00868
   Lewkowicz DJ, 1996, J EXP PSYCHOL HUMAN, V22, P1094, DOI 10.1037/0096-1523.22.5.1094
   Magnotti JF, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00798
   MORAY N, 1959, Q J EXP PSYCHOL, V11, P56, DOI 10.1080/17470215908416289
   Munhall KG, 1996, PERCEPT PSYCHOPHYS, V58, P351, DOI 10.3758/BF03206811
   Pernet CR, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00023
   PICK HL, 1969, PERCEPT PSYCHOPHYS, V6, P203, DOI 10.3758/BF03207017
   Pisanski K, 2012, EVOL HUM BEHAV, V33, P509, DOI 10.1016/j.evolhumbehav.2012.01.004
   RADEAU M, 1987, PSYCHOL RES-PSYCH FO, V49, P17, DOI 10.1007/BF00309198
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   Rouger J, 2007, P NATL ACAD SCI USA, V104, P7295, DOI 10.1073/pnas.0609419104
   Smith HMJ, 2016, EVOL PSYCHOL-US, V14, DOI 10.1177/1474704916630317
   Spence C, 2013, ANN NY ACAD SCI, V1296, P31, DOI 10.1111/nyas.12121
   Stein B. E., 1993, MERGING SENSES
   Stein BE, 2008, NAT REV NEUROSCI, V9, P255, DOI 10.1038/nrn2331
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Van der Burg E, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010664
   Vatakis A, 2008, ACTA PSYCHOL, V127, P12, DOI 10.1016/j.actpsy.2006.12.002
   Vatakis A, 2007, PERCEPT PSYCHOPHYS, V69, P744, DOI 10.3758/BF03193776
   Vatakis A, 2008, J VISION, V8, DOI 10.1167/8.9.14
   WALKER S, 1995, PERCEPT PSYCHOPHYS, V57, P1124, DOI 10.3758/BF03208369
   Wallace MT, 2004, EXP BRAIN RES, V158, P252, DOI 10.1007/s00221-004-1899-9
   WELCH RB, 1980, PSYCHOL BULL, V88, P638, DOI 10.1037/0033-2909.88.3.638
   Wobbrock JO, 2011, P SIGCHI C HUM FACT
NR 44
TC 1
Z9 1
U1 1
U2 3
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0301-0066
EI 1468-4233
J9 PERCEPTION
JI Perception
PD AUG
PY 2019
VL 48
IS 8
BP 649
EP 667
AR 0301006619858076
DI 10.1177/0301006619858076
EA JUL 2019
PG 19
WC Ophthalmology; Psychology; Psychology, Experimental
SC Ophthalmology; Psychology
GA IV3GP
UT WOS:000481380000001
PM 31262234
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Drozdova, P
   van Hout, R
   Scharenborg, O
AF Drozdova, Polina
   van Hout, Roeland
   Scharenborg, Odette
TI Talker-familiarity benefit in non-native recognition memory and word
   identification: The role of listening conditions and proficiency
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Familiar talker benefit; Non-native speech comprehension; Noise;
   Non-native proficiency
ID SPEECH-PERCEPTION; SPOKEN WORDS; TIME-COURSE; VOICE; VARIABILITY;
   SPECIFICITY; ADAPTATION; LANGUAGE; REPRESENTATIONS; COMPETITION
AB Native listeners benefit from talker familiarity in recognition memory and word identification, especially in adverse listening conditions. The present study addresses the talker familiarity benefit in non-native listening, and the role of listening conditions and listeners' lexical proficiency in the emergence of this benefit. Dutch non-native listeners of English were trained to identify four English talkers over 4 days. Talker familiarity benefit in recognition memory was investigated using a recognition memory task with " old" and " new" words produced by familiar and unfamiliar talkers presented either in the clear or in noise. Talker familiarity benefit in word identification was investigated by comparing non-native listeners' performances on the first and the last day in identifying words in different noise levels, produced by either a trained (included in the voice recognition training) or by an untrained talker (not included in the voice recognition training). Non-native listeners demonstrated a talker familiarity benefit in recognition memory, which was modulated by listening conditions and proficiency in the non-native language. No talker familiarity benefit was found in word identification. These results suggest that, similar to native listening, both linguistic and indexical (talker-specific) information influence non-native speech perception. However, this is dependent on the task and type of speech recognition process involved.
C1 [Drozdova, Polina; van Hout, Roeland; Scharenborg, Odette] Radboud Univ Nijmegen, Ctr Language Studies, Erasmuspl 1, NL-6525 HT Nijmegen, Netherlands.
   [Drozdova, Polina] Diakonessenhuis Utrecht, Concerndienst, Postbus 80250, NL-3508 TG Utrecht, Netherlands.
   [Scharenborg, Odette] Delft Univ Technol, Multimedia Comp Grp, Van Mourik Broekmanweg 6, NL-2628 XE Delft, Netherlands.
RP Scharenborg, O (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies, Erasmuspl 1, NL-6525 HT Nijmegen, Netherlands.; Scharenborg, O (corresponding author), Delft Univ Technol, Multimedia Comp Grp, Van Mourik Broekmanweg 6, NL-2628 XE Delft, Netherlands.
EM pdrozdova@diakhuis.nl; r.vanhout@let.ru.nl; O.E.Scharenborg@tudelft.nl
OI Scharenborg, Odette/0000-0003-0693-8852
FU Netherlands Organization for Scientific Research (NWO)Netherlands
   Organization for Scientific Research (NWO) [276-89-003]
FX This research is supported by a Vidi-grant from the Netherlands
   Organization for Scientific Research (NWO; grant number 276-89-003)
   awarded to Odette Scharenborg. Odette Scharenborg is now at the
   Multimedia Computing Group, Delft University of Technology, the
   Netherlands.
CR Abercombie D., 1967, ELEMENTS GEN PHONETI
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Boersma P., 2009, PRAAT DOING PHONETIC
   Borghini G, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00152
   Bradlow AR, 1999, J ACOUST SOC AM, V106, P2074, DOI 10.1121/1.427952
   Bregman MR, 2014, COGNITION, V130, P85, DOI 10.1016/j.cognition.2013.09.010
   Broersma M, 2012, LANG COGNITIVE PROC, V27, P1205, DOI 10.1080/01690965.2012.660170
   Brouwer S, 2016, J PSYCHOLINGUIST RES, V45, P1151, DOI 10.1007/s10936-015-9396-9
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Cooper A, 2017, LAB PHONOL, V8, DOI 10.5334/labphon.99
   Creel SC, 2008, COGNITION, V106, P633, DOI 10.1016/j.cognition.2007.03.013
   Cutler A., 2010, LAB PHONOLOGY, V10, P91
   CUTLER ANNE., 2010, LAB PHONOLOGY, V1, P301, DOI [10.1515/labphon.2010.016, DOI 10.1515/LABPHON.2010.016]
   Dahan D, 2008, COGNITION, V108, P710, DOI 10.1016/j.cognition.2008.06.003
   Drozdova P, 2017, J ACOUST SOC AM, V142, P3058, DOI 10.1121/1.5010169
   Drozdova P, 2016, BILING-LANG COGN, V19, P914, DOI 10.1017/S136672891600002X
   Dufour S, 2017, LANG COGN NEUROSCI, V32, P1273, DOI 10.1080/23273798.2017.1335421
   Dufour S, 2014, J COGN PSYCHOL, V26, P256, DOI 10.1080/20445911.2014.890204
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Goh WD, 2005, J EXP PSYCHOL LEARN, V31, P40, DOI 10.1037/0278-7393.31.1.40
   Goldinger S. D., 2007, 16 INT C PHON SCI, P49
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Hintz F., 2016, EFFECT BACKGROUND NO
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Jesse A., 2007, P 16 INT C PHON SCI, P1921
   Kittredge A, 2006, BRAIN LANG, V97, P25, DOI 10.1016/j.bandl.2005.07.012
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Lee CY, 2015, J PSYCHOLINGUIST RES, V44, P237, DOI 10.1007/s10936-014-9307-5
   Lemhofer K, 2012, BEHAV RES METHODS, V44, P325, DOI 10.3758/s13428-011-0146-0
   Levi SV, 2014, PHONETICA, V71, P201, DOI 10.1159/000370160
   Levi SV, 2011, J ACOUST SOC AM, V130, P4053, DOI 10.1121/1.3651816
   Luce P. A., 2003, RETHINKING IMPLICIT, P197, DOI DOI 10.1093/ACPROF:OSO/9780192632326.003.0009
   Luce PA, 1998, MEM COGNITION, V26, P708, DOI 10.3758/BF03211391
   MACLEOD CM, 1984, ACTA PSYCHOL, V57, P215, DOI 10.1016/0001-6918(84)90032-5
   MACMILLAN NA, 1985, PSYCHOL BULL, V98, P185, DOI 10.1037/0033-2909.98.1.185
   Maibauer AM, 2014, ATTEN PERCEPT PSYCHO, V76, P11, DOI 10.3758/s13414-013-0600-4
   Mattys SL, 2008, PERCEPT PSYCHOPHYS, V70, P1235, DOI 10.3758/PP.70.7.1235
   Mattys SL, 2010, SPEECH COMMUN, V52, P887, DOI 10.1016/j.specom.2010.01.005
   Mayo LH, 1997, J SPEECH LANG HEAR R, V40, P686, DOI 10.1044/jslhr.4003.686
   McLennan CT, 2012, ATTEN PERCEPT PSYCHO, V74, P824, DOI 10.3758/s13414-012-0315-y
   McLennan CT, 2005, J EXP PSYCHOL LEARN, V31, P306, DOI 10.1037/0278-7393.31.2.306
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   MULLENNIX JW, 1989, J ACOUST SOC AM, V85, P365, DOI 10.1121/1.397688
   Newman RS, 2007, J PHONETICS, V35, P85, DOI 10.1016/j.wocn.2005.10.004
   Nijveld A, 2015, P 18 INT C PHON SCI
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Norris D, 2016, LANG COGN NEUROSCI, V31, P4, DOI 10.1080/23273798.2015.1081703
   Nygaard L. C, 2008, J ACOUST SOC AM, V124, P2459, DOI DOI 10.1121/1.4782666
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   PALMERI TJ, 1993, J EXP PSYCHOL LEARN, V19, P309, DOI 10.1037/0278-7393.19.2.309
   Papesh MH, 2016, J EXP PSYCHOL GEN, V145, P314, DOI 10.1037/xge0000135
   Perrachione TK, 2007, NEUROPSYCHOLOGIA, V45, P1899, DOI 10.1016/j.neuropsychologia.2006.11.015
   Pierrehumbert J, 2001, EXEMPLAR DYNAMICS WO, P137
   Pisoni DB, 1997, TALKER VARIABILITY S, P9
   Pufahl A, 2014, COGNITIVE PSYCHOL, V70, P1, DOI 10.1016/j.cogpsych.2014.01.001
   Reinisch E, 2013, J EXP PSYCHOL HUMAN, V39, P75, DOI 10.1037/a0027979
   Rogers CL, 2006, APPL PSYCHOLINGUIST, V27, P465, DOI 10.1017/S014271640606036X
   Ryalls BO, 1997, DEV PSYCHOL, V33, P441, DOI 10.1037/0012-1649.33.3.441
   SCHACTER DL, 1992, J EXP PSYCHOL LEARN, V18, P915, DOI 10.1037/0278-7393.18.5.915
   Scharenborg O, 2018, J EXP PSYCHOL LEARN, V44, P233, DOI 10.1037/xlm0000441
   Sheffert SM, 1998, MEM COGNITION, V26, P591, DOI 10.3758/BF03201165
   SOMMERS MS, 1994, J ACOUST SOC AM, V96, P1314, DOI 10.1121/1.411453
   Tamati TN, 2014, J AM ACAD AUDIOL, V25, P869, DOI 10.3766/jaaa.25.9.9
   Theodore RM, 2015, ATTEN PERCEPT PSYCHO, V77, P1674, DOI 10.3758/s13414-015-0854-0
   Trofimovich P, 2005, APPL PSYCHOLINGUIST, V26, P479, DOI 10.1017/S0142716405050265
   Trofimovich P, 2008, J PSYCHOLINGUIST RES, V37, P309, DOI 10.1007/s10936-008-9069-z
   Trude AM, 2012, LANG COGNITIVE PROC, V27, P979, DOI 10.1080/01690965.2011.597153
   Tuft SE, 2018, Q J EXP PSYCHOL, V71, P435, DOI 10.1080/17470218.2016.1253757
   van Heuven WJB, 2014, Q J EXP PSYCHOL, V67, P1176, DOI 10.1080/17470218.2013.850521
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0
   Winters S, 2013, 2 LANGUAGE RES FORUM
   Yonan CA, 2000, PSYCHOL AGING, V15, P88, DOI 10.1037/0882-7974.15.1.88
NR 75
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD JUL
PY 2019
VL 81
IS 5
BP 1675
EP 1697
DI 10.3758/s13414-018-01657-5
PG 23
WC Psychology; Psychology, Experimental
SC Psychology
GA IW8FI
UT WOS:000485229200038
PM 30834484
OA Bronze, Green Published
DA 2021-02-24
ER

PT J
AU Frey, A
   Francois, C
   Chobert, J
   Besson, M
   Ziegler, JC
AF Frey, Aline
   Francois, Clement
   Chobert, Julie
   Besson, Mireille
   Ziegler, Johannes C.
TI Behavioral and electrophysiological investigation of speech perception
   deficits in silence, noise and envelope conditions in developmental
   dyslexia
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE N1; Speech; Noise; Envelope; Dyslexia; ERP
ID EVENT-RELATED POTENTIALS; DEAD REGIONS; CHILDREN; SOUNDS;
   INTELLIGIBILITY; DISCRIMINATION; PERFORMANCE; IDENTIFICATION;
   MODULATIONS; ENHANCEMENT
AB The present study investigated whether children with developmental dyslexia showed specific deficits in the perception of three phonetic features (voicing, place, and manner of articulation) in optimal (silence) and degraded listening conditions (envelope-coded speech versus noise), using both standard behavioral and electrophysiological measures. Performance of children with dyslexia was compared to that of younger typically developing children who were matched in terms of reading age. Results showed no significant group differences in response accuracy except for the reception of place-of-articulation in noise. However, dyslexic children responded more slowly than typically developing children across all conditions with larger deficits in noise than in envelope than in silence. At the neural level, dyslexic children exhibited reduced N1 components in silence and the reduction of N1 amplitude was more pronounced for voicing than for the other phonetic features. In the envelope condition, the N1 was localized over the right hemisphere and it was larger for typically developing readers than for dyslexic children. Finally, in stationary noise, the N1 to place of articulation was clearly delayed in children with dyslexia, which suggests a temporal de-organization in the most adverse listening conditions. The results clearly show abnormal neural processing to speech sounds in all conditions. They are discussed in the context of recent theories on perceptual noise exclusion, neural noise and temporal sampling.
C1 [Frey, Aline] Univ East Paris Creteil Val de Marne, Creteil Acad, CHArt Lab, ESPE, Creteil, France.
   [Francois, Clement] Bellvitge Biomed Res Inst IDIBELL, Cognit & Brain Plastic Grp, Barcelona 08097, Spain.
   [Francois, Clement] Univ Barcelona, Dept Cognit Dev & Educ Sci, Campus Bellvitge, Barcelona 08097, Spain.
   [Francois, Clement] Hosp St Joan de Deu, Inst Recerca Pediat, Barcelona, Spain.
   [Chobert, Julie; Besson, Mireille] CNRS, Marseille, France.
   [Chobert, Julie; Besson, Mireille] Aix Marseille Univ, LNC, Federat 3C, Marseille, France.
   [Ziegler, Johannes C.] Aix Marseille Univ, LPC, Federat 3C, CNRS, Marseille, France.
RP Ziegler, JC (corresponding author), Aix Marseille Univ, LPC, Federat 3C, CNRS, Marseille, France.
EM Johannes.Ziegler@univ-amu.fr
RI Ziegler, Johannes C./C-2234-2008; Francois, Clement/F-7133-2013
OI Ziegler, Johannes C./0000-0002-2061-5729; Francois,
   Clement/0000-0003-2271-6942; FREY, Aline/0000-0002-0110-8633
FU French government [ANR-11-LABX0036, ANR-16-CONV-0002]; ANR-NeuroFrench
   National Research Agency (ANR) [024-01]; Spanish MINECO grant
   [PSI2015-69132P]; Catalan Government (Generalitat de Catalunya-PERIS
   2016-2020)
FX This research, carried out within the Labex BLRI (ANR-11-LABX0036) and
   the Institute of Convergence ILCB (ANR-16-CONV-0002), has benefited from
   support from the French government, managed by the French National
   Agency for Research (ANR) and the Excellence Initiative of Aix-Marseille
   University (A*MIDEX). This research was further supported by a grant
   from the ANR-Neuro (#024-01 to MB). At the time the study was conducted,
   JC and CF were PhD students supported by the ANR-Neuro (#024-01). CF is
   now a post-doctoral researcher supported by a Spanish MINECO grant
   (PSI2015-69132P) and by the Catalan Government (Generalitat de
   Catalunya-PERIS 2016-2020). We are thankful to Jean-Luc Velay, Daniele
   Schon and Michel Habib for their precious help in organizing the
   procedures, aspects of data processing and access to the elementary
   schools. We also thank the directors of the two schools where the
   children were tested, Mrs Muriel Gaiarsa and Mr Jean-Jacques Gaubert,
   the teachers of the schools, as well as all the children who
   participated in this study and their parents.
CR Ahissar M, 2007, TRENDS COGN SCI, V11, P458, DOI 10.1016/j.tics.2007.08.015
   Ahissar M, 2006, NAT NEUROSCI, V9, P1558, DOI 10.1038/nn1800
   Anderson S, 2013, P NATL ACAD SCI USA, V110, P4357, DOI 10.1073/pnas.1213555110
   Baer T, 2002, J ACOUST SOC AM, V112, P1133, DOI 10.1121/1.1498853
   Belin P, 1998, J COGNITIVE NEUROSCI, V10, P536, DOI 10.1162/089892998562834
   Bertranrd D, 2010, ANN PSYCHOL, V110, P299
   Billings CJ, 2011, EAR HEARING, V32, P53, DOI 10.1097/AUD.0b013e3181ec5c46
   BINNIE CA, 1974, J SPEECH HEAR RES, V17, P619, DOI 10.1044/jshr.1704.619
   Boets B, 2007, NEUROPSYCHOLOGIA, V45, P1608, DOI 10.1016/j.neuropsychologia.2007.01.009
   Bogliotti C, 2008, J EXP CHILD PSYCHOL, V101, P137, DOI 10.1016/j.jecp.2008.03.006
   Bradley JS, 2008, J ACOUST SOC AM, V123, P2078, DOI 10.1121/1.2839285
   Calcus A, 2016, J SPEECH LANG HEAR R, V59, P835, DOI 10.1044/2016_JSLHR-H-15-0076
   Casini L., 2017, DEVELOPMENTAL SCI, V21
   Chandrasekaran B, 2009, NEURON, V64, P311, DOI 10.1016/j.neuron.2009.10.006
   Cunningham J, 2001, CLIN NEUROPHYSIOL, V112, P758, DOI 10.1016/S1388-2457(01)00465-5
   Cutini S, 2016, NEUROIMAGE, V143, P40, DOI 10.1016/j.neuroimage.2016.08.012
   Davis C, 2001, COGNITION, V81, pB21, DOI 10.1016/S0010-0277(01)00129-9
   Dehaene S, 2015, NAT REV NEUROSCI, V16, P234, DOI 10.1038/nrn3924
   Dehaene S, 2010, SCIENCE, V330, P1359, DOI 10.1126/science.1194140
   Demonet JF, 2004, LANCET, V363, P1451, DOI 10.1016/S0140-6736(04)16106-0
   Dimitrijevic A, 2013, CLIN NEUROPHYSIOL, V124, P1204, DOI 10.1016/j.clinph.2012.11.014
   Dole M, 2014, NEUROPSYCHOLOGIA, V60, P103, DOI 10.1016/j.neuropsychologia.2014.05.016
   Dole M, 2012, NEUROPSYCHOLOGIA, V50, P1543, DOI 10.1016/j.neuropsychologia.2012.03.007
   Franceschini S, 2013, CURR BIOL, V23, P462, DOI 10.1016/j.cub.2013.01.044
   Franceschini S, 2012, CURR BIOL, V22, P814, DOI 10.1016/j.cub.2012.03.013
   Francois C, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00475
   Francois C, 2013, CEREB CORTEX, V23, P2038, DOI 10.1093/cercor/bhs180
   Fullgrabe C, 2006, HEARING RES, V211, P74, DOI 10.1016/j.heares.2005.09.001
   Gilbert G, 2006, J ACOUST SOC AM, V119, P2438, DOI 10.1121/1.2173522
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   GODFREY JJ, 1981, J EXP CHILD PSYCHOL, V32, P401, DOI 10.1016/0022-0965(81)90105-3
   Gori S., 2015, CEREB CORTEX
   Gori S, 2015, J VISION, V15, DOI [10.1167/15.1.8, 10.1167/15.12.195]
   Goswami U, 2003, TRENDS COGN SCI, V7, P534, DOI 10.1016/j.tics.2003.10.003
   Goswami U, 2015, NAT REV NEUROSCI, V16, P43, DOI 10.1038/nrn3836
   Goswami U, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00904
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   GREENHOUSE SW, 1959, PSYCHOMETRIKA, V24, P95, DOI 10.1007/BF02289823
   Hamalainen JA, 2008, CLIN NEUROPHYSIOL, V119, P100, DOI 10.1016/j.clinph.2007.09.064
   Hamalainen JA, 2007, CLIN NEUROPHYSIOL, V118, P2263, DOI 10.1016/j.clinph.2007.07.007
   Hamalainen JA, 2012, NEUROIMAGE, V59, P2952, DOI 10.1016/j.neuroimage.2011.09.075
   Hancock R, 2017, TRENDS COGN SCI, V21, P434, DOI 10.1016/j.tics.2017.03.008
   Hazan V, 2013, J SPEECH LANG HEAR R, V56, P44, DOI 10.1044/1092-4388(2012/10-0107)
   Helenius P, 2002, J COGNITIVE NEUROSCI, V14, P603, DOI 10.1162/08989290260045846
   Hornickel J, 2009, P NATL ACAD SCI USA, V106, P13022, DOI 10.1073/pnas.0901123106
   Jacquier-Roux M., 2002, ODEDYS OUTIL DEPISTA
   Johnson KL, 2007, J COGNITIVE NEUROSCI, V19, P376, DOI 10.1162/jocn.2007.19.3.376
   Kaplan-Neeman R, 2006, J ACOUST SOC AM, V120, P926, DOI 10.1121/1.2217567
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Korkman M., 2004, NEPSY BILAN NEUROPSY
   Lefavrais J., 2005, TEST DE LALOUETTE
   Lohvansuu K, 2014, INT J PSYCHOPHYSIOL, V94, P298, DOI 10.1016/j.ijpsycho.2014.10.002
   Lorenzi C, 2000, J SPEECH LANG HEAR R, V43, P1367, DOI 10.1044/jslhr.4306.1367
   Lovio R, 2010, BRAIN RES, V1335, P53, DOI 10.1016/j.brainres.2010.03.097
   Lyytinen Heikki, 2015, Curr Dev Disord Rep, V2, P330
   Manis FR, 1997, J EXP CHILD PSYCHOL, V66, P211, DOI 10.1006/jecp.1997.2383
   Martin BA, 1997, J ACOUST SOC AM, V101, P1585, DOI 10.1121/1.418146
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Morillon B, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00248
   Morillon B, 2010, P NATL ACAD SCI USA, V107, P18688, DOI 10.1073/pnas.1007189107
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Nagarajan S, 1999, P NATL ACAD SCI USA, V96, P6483, DOI 10.1073/pnas.96.11.6483
   Norton ES, 2015, CURR OPIN NEUROBIOL, V30, P73, DOI 10.1016/j.conb.2014.09.007
   Parbery-Clark A, 2012, NEUROSCIENCE, V219, P111, DOI 10.1016/j.neuroscience.2012.05.042
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Picton T. W., 1995, HDB NEUROPSYCHOLOGY, V10, P3
   Power AJ, 2016, BRAIN LANG, V160, P1, DOI 10.1016/j.bandl.2016.06.006
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   Raven J.C., 1976, STANDARD PROGR MATRI
   Saksida A, 2016, DEV PSYCHOL, V52, P1503, DOI 10.1037/dev0000184
   Serniclaes W, 2001, J SPEECH LANG HEAR R, V44, P384, DOI 10.1044/1092-4388(2001/032)
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Slater J, 2015, BEHAV BRAIN RES, V291, P244, DOI 10.1016/j.bbr.2015.05.026
   Snowling M., 2000, DYSLEXIA
   Sperling AJ, 2005, NAT NEUROSCI, V8, P862, DOI 10.1038/nn1474
   Sperling AJ, 2006, PSYCHOL SCI, V17, P1047, DOI 10.1111/j.1467-9280.2006.01825.x
   Strait DL, 2013, DEV COGN NEUROS-NETH, V6, P51, DOI 10.1016/j.dcn.2013.06.003
   Strait DL, 2012, BRAIN LANG, V123, P191, DOI 10.1016/j.bandl.2012.09.001
   Sutcliffe P, 2005, J EXP CHILD PSYCHOL, V91, P249, DOI 10.1016/j.jecp.2005.03.004
   Thompson EC, 2016, SCI REP-UK, V6, DOI 10.1038/srep19737
   Tremblay K, 2001, EAR HEARING, V22, P79, DOI 10.1097/00003446-200104000-00001
   Vanvooren S, 2017, RES DEV DISABIL, V70, P138, DOI 10.1016/j.ridd.2017.09.005
   Vanvooren S, 2014, J NEUROSCI, V34, P1523, DOI 10.1523/JNEUROSCI.3209-13.2014
   Vickers DA, 2001, J ACOUST SOC AM, V110, P1164, DOI 10.1121/1.1381534
   Wechsler D., 2003, WECHSLER INTELLIGENC
   White S, 2006, DEVELOPMENTAL SCI, V9, P237, DOI 10.1111/j.1467-7687.2006.00483.x
   Wible B, 2002, CLIN NEUROPHYSIOL, V113, P485, DOI 10.1016/S1388-2457(02)00017-2
   Ziegler JC, 1998, PSYCHON B REV, V5, P683, DOI 10.3758/BF03208845
   Ziegler JC, 2005, P NATL ACAD SCI USA, V102, P14110, DOI 10.1073/pnas.0504446102
   Ziegler JC, 2008, TRENDS COGN SCI, V12, P244, DOI 10.1016/j.tics.2008.04.001
   Ziegler JC, 2011, J EXP CHILD PSYCHOL, V110, P362, DOI 10.1016/j.jecp.2011.05.001
   Ziegler JC, 2009, DEVELOPMENTAL SCI, V12, P732, DOI 10.1111/j.1467-7687.2009.00817.x
NR 93
TC 6
Z9 6
U1 1
U2 4
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD JUL
PY 2019
VL 130
SI SI
BP 3
EP 12
DI 10.1016/j.neuropsychologia.2018.07.033
PG 10
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA JJ1HZ
UT WOS:000493912900002
PM 30075216
DA 2021-02-24
ER

PT J
AU Bayard, C
   Machart, L
   Strauss, A
   Gerber, S
   Aubanel, V
   Schwartz, JL
AF Bayard, Clernence
   Machart, Laura
   Strauss, Antje
   Gerber, Silvain
   Aubanel, Vincent
   Schwartz, Jean-Luc
TI Cued Speech Enhances Speech-in-Noise Perception
SO JOURNAL OF DEAF STUDIES AND DEAF EDUCATION
LA English
DT Article
ID PRELINGUALLY DEAF-CHILDREN; NORMAL-HEARING; CONSONANT RECOGNITION;
   SENTENCE RECOGNITION; AUTOMATIC SPEECH; COCHLEAR; INTELLIGIBILITY;
   INFORMATION; PERFORMANCE; RECEPTION
AB Speech perception in noise remains challenging for Deaf/Hard of Hearing people (D/HH), even fitted with hearing aids or cochlear implants. The perception of sentences in noise by 20 implanted or aided D/HH subjects mastering Cued Speech (CS), a system of hand gestures complementing lip movements, was compared with the perception of 15 typically hearing (TH) controls in three conditions: audio only, audiovisual, and audiovisual + CS. Similar audiovisual scores were obtained for signal-to-noise ratios (SNRs) 11 dB higher in D/HH participants compared with TH ones. Adding CS information enabled D/HH participants to reach a mean score of 83% in the audiovisual + CS condition at a mean SNR of 0 dB, similar to the usual audio score for TH participants at this SNR. This confirms that the combination of lipreading and Cued Speech system remains extremely important for persons with hearing loss, particularly in adverse hearing conditions.
C1 [Bayard, Clernence; Machart, Laura; Gerber, Silvain; Aubanel, Vincent; Schwartz, Jean-Luc] Univ Grenoble Alpes, GIPSA Lab, Grenoble INP, CNRS, Grenoble, France.
   [Strauss, Antje] Univ Konstanz, FB Sprachwissensch, Zukunftskolleg, Constance, Germany.
RP Schwartz, JL (corresponding author), GIPSA Lab, 11 Rue Math,Grenoble Campus,BP46, F-38402 St Martin Dheres, France.
EM jean-luc.schwartz@gipsa-lab.grenoble-inp.fr
OI Schwartz, Jean-Luc/0000-0001-8969-9185
FU European Research CouncilEuropean Research Council (ERC)European
   Commission [339152]
FX This research was funded by the European Research Council (FP7/2007-2013
   Grant Agreement no. 339152-"Speech Unit(e)s").
CR Alegria J, 2005, J DEAF STUD DEAF EDU, V10, P122, DOI 10.1093/deafed/eni013
   [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   Aparicio M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00426
   Aparicio M, 2012, SCAND J PSYCHOL, V53, P41, DOI 10.1111/j.1467-9450.2011.00919.x
   Attina V, 2006, LECT NOTES ARTIF INT, V3881, P13
   Attina V, 2004, SPEECH COMMUN, V44, P197, DOI 10.1016/j.specom.2004.10.013
   Attina V., 2005, THESIS
   Aubanel V, 2017, P 14 INT C AUD VIS S
   Aubanel V, FHARVARD CORPUS PHON
   Aubanel V, 2014, INT J AUDIOL, V53, P633, DOI 10.3109/14992027.2014.907507
   BAER T, 1993, J REHABIL RES DEV, V30, P49
   BAYARD C, 2014, FRONT PSYCHOL, V5, DOI DOI 10.3389/FPSYG.2014.00416
   Bayard C, 2015, P 1 JOINT C FAC AN A, P163
   Bergeson TR, 2005, EAR HEARING, V26, P149, DOI 10.1097/00003446-200504000-00004
   Bernstein JGW, 2011, J ACOUST SOC AM, V130, P473, DOI 10.1121/1.3589440
   Bernstein JGW, 2009, J ACOUST SOC AM, V125, P3358, DOI 10.1121/1.3110132
   Bernstein L., 1998, HEARING EYE, P211
   Bernstein LE, 2000, PERCEPT PSYCHOPHYS, V62, P233, DOI 10.3758/BF03205546
   Boothroyd A, 1996, J ACOUST SOC AM, V100, P1807, DOI 10.1121/1.416000
   Bradlow AR, 1996, SPEECH COMMUN, V20, P255, DOI 10.1016/S0167-6393(96)00063-5
   BRATAKOS MS, 1998, CUED SPEECH J, V6, P1
   Caldwell A, 2013, J SPEECH LANG HEAR R, V56, P13, DOI 10.1044/1092-4388(2012/11-0338)
   CLARKE BR, 1976, VOLTA REV, V78, P23
   Cooke M, 2013, SPEECH COMMUN, V55, P572, DOI 10.1016/j.specom.2013.01.001
   Cornett R. O., 1994, CUED SPEECH J, V5, P19
   CORNETT RO, 1967, AM ANN DEAF, V112, P3
   Desai S, 2008, J ACOUST SOC AM, V123, P428, DOI 10.1121/1.2816573
   Duchnowski P, 2000, IEEE T BIO-MED ENG, V47, P487, DOI 10.1109/10.828148
   ERBER NP, 1971, J SPEECH HEAR RES, V14, P496, DOI 10.1044/jshr.1403.496
   ERBER NP, 1975, J SPEECH HEAR DISORD, V40, P481, DOI 10.1044/jshd.4004.481
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538
   Fu QJ, 1998, J ACOUST SOC AM, V104, P3586, DOI 10.1121/1.423941
   Gibert G, 2005, J ACOUST SOC AM, V118, P1144, DOI 10.1121/1.1944587
   Grant KW, 1998, J ACOUST SOC AM, V103, P2677, DOI 10.1121/1.422788
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   GREGORY JF, 1987, AM ANN DEAF, V132, P393, DOI 10.1353/aad.2012.1466
   Holt RF, 2011, J SPEECH LANG HEAR R, V54, P632, DOI 10.1044/1092-4388(2010/09-0148)
   Kaiser AR, 2003, J SPEECH LANG HEAR R, V46, P390, DOI 10.1044/1092-4388(2003/032)
   Kim J, 2014, BRAIN LANG, V137, P86, DOI 10.1016/j.bandl.2014.07.012
   Lachs L, 2001, EAR HEARING, V22, P236, DOI 10.1097/00003446-200106000-00007
   Leybaert J, 2010, TRENDS AMPLIF, V14, P96, DOI 10.1177/1084713810375567
   Liu SY, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107252
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   MARTHOURET M, 2011, LANGUE PARLEE COMPLE, P147, DOI DOI 10.1177/1084713810375567
   Nascimento Leandra Tabanez do, 2005, Rev. Bras. Otorrinolaringol., V71, P432, DOI 10.1590/S0034-72992005000400006
   NICHOLLS GH, 1982, J SPEECH HEAR RES, V25, P262, DOI 10.1044/jshr.2502.262
   Percy V., 2013, AUSTR NZ J AUDIOLOGY, V33, P35
   PERIER O, 1990, CUED SPEECH J, V4, P45
   Picard M, 2001, AUDIOLOGY, V40, P221
   R Development Core Team, 2016, R LANG ENV STAT COMP
   REVOILE SG, 1991, J ACOUST SOC AM, V90, P787, DOI 10.1121/1.401948
   Rouger J, 2007, P NATL ACAD SCI USA, V104, P7295, DOI 10.1073/pnas.0609419104
   Schorr EA, 2005, P NATL ACAD SCI USA, V102, P18748, DOI 10.1073/pnas.0508862102
   Schwartz JL, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003743
   Shannon RV, 2004, SPR HDB AUD, V20, P334
   SHANNON RV, 2004, ACTA OTO-LARYNGOL, V552, P50
   Srinivasan AG, 2013, HEARING RES, V299, P29, DOI 10.1016/j.heares.2013.02.004
   Strauss A, 2013, J COGNITIVE NEUROSCI, V25, P1383, DOI 10.1162/jocn_a_00389
   Taitelbaum-Swead R, 2017, INT J PEDIATR OTORHI, V92, P146, DOI 10.1016/j.ijporl.2016.11.022
   Todorov Michelle J, 2018, Cochlear Implants Int, V19, P210, DOI 10.1080/14670100.2018.1452584
   Troille E, 2007, ICPHS, P291
   Tutz G, 1996, COMPUT STAT DATA AN, V22, P537, DOI 10.1016/0167-9473(96)00004-7
   Tyler RS, 1997, J ACOUST SOC AM, V102, P508, DOI 10.1121/1.419724
   UCHANSKI RM, 1994, J REHABIL RES DEV, V31, P20
   Wolfe J, 2015, J AM ACAD AUDIOL, V26, P502, DOI 10.3766/jaaa.14099
   Zeng FG, 1999, EAR HEARING, V20, P60, DOI 10.1097/00003446-199902000-00006
NR 66
TC 2
Z9 3
U1 0
U2 1
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1081-4159
EI 1465-7325
J9 J DEAF STUD DEAF EDU
JI J. Deaf Stud. Deaf Educ.
PD JUL
PY 2019
VL 24
IS 3
BP 223
EP 233
DI 10.1093/deafed/enz003
PG 11
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA JH8VQ
UT WOS:000493046400004
PM 30809665
DA 2021-02-24
ER

PT J
AU Michael, R
   Attias, J
   Raveh, E
AF Michael, Rinat
   Attias, Joseph
   Raveh, Eyal
TI Perceived Quality of Life Among Adults With Hearing Loss: Relationships
   With Amplification Device and Financial Well-Being
SO REHABILITATION COUNSELING BULLETIN
LA English
DT Article
DE deafness; disability(ies); sensory impairments
ID COCHLEAR IMPLANTS; SPEECH-PERCEPTION; DEAF; CHILDREN; ADOLESCENTS;
   OUTCOMES; PERFORMANCE; PEOPLE; YOUTH; COMMUNICATION
AB The current study explored the relationship between perceived quality of life and financial well-being among adult cochlear implant (CI) users as compared with hearing aid (HA) users. Participants were 66 adults: 30 CI users and 36 HA users. They completed the Perceived Quality of Life for Deaf and Hard-of-Hearing (DHH) scale, the In Charge Financial Distress/Financial Well-Being scale, and a background questionnaire. Significant differences were found between the two study groups in two perceived quality-of-life factors: participation, t(58) = 1.71, p < .05, and perceived stigma, t(58) = -1.80, p < .05. CI users reported higher levels of participation and lower levels of perceived stigma as compared with HA users. In addition, financial well-being was a significant predictor of participation (beta = .32, p < .05), and CI users who used their device for a longer time reported higher levels of financial well-being (r = .35, p < .05). Research findings emphasize the possible contribution that both CIs and financial well-being may have on the perceived quality of life of DHH adults. In addition, time since implantation may be an important variable when measuring improvements after cochlear implantation, especially when evaluating long-term processes, such as changes in financial well-being.
C1 [Michael, Rinat] Tel Aviv Univ, Tel Aviv, Israel.
   [Attias, Joseph] Univ Haifa, Haifa, Israel.
   [Raveh, Eyal] Schneider Childrens Med Ctr Israel, Petah Tiqwa, Israel.
RP Michael, R (corresponding author), Tel Aviv Univ, Sch Educ, Ramat Aviv, IL-6997801 Tel Aviv, Israel.
EM freskori@post.tau.ac.il
CR Blamey PJ, 2001, J SPEECH LANG HEAR R, V44, P264, DOI 10.1044/1092-4388(2001/022)
   Boothroyd A., 2008, PEDIAT AUDIOLOGY DIA, P159
   Borum V, 2012, AM ANN DEAF, V157, P7, DOI 10.1353/aad.2012.1606
   Bradley CF, 2013, J REHABIL, V79, P24
   Bullis M, 1997, REHABIL COUNS BULL, V40, P251
   Chan S. F., 2012, COLL STUDENT J, V46, P114
   Chute PM, 2012, DEAF EDUC INT, V14, P60, DOI 10.1179/1557069X12Y.0000000002
   Consumer Financial Protection Bureau, 2015, FIN WELL BEING GOAL
   Dalton DS, 2003, GERONTOLOGIST, V43, P661, DOI 10.1093/geront/43.5.661
   Drever AI, 2015, J CONSUM AFF, V49, P13, DOI 10.1111/joca.12068
   Erikson E.H., 1968, IDENTITY YOUTH CRISI
   Fazel Maisam Z, 2007, Cochlear Implants Int, V8, P87, DOI 10.1002/cii.332
   Gilman R, 2004, SOC INDIC RES, V66, P143, DOI 10.1023/B:SOCI.0000007495.40790.85
   Hallberg LRM, 2004, INT J AUDIOL, V43, P115, DOI 10.1080/14992020400050016
   Hamzavi J, 2003, ACTA OTO-LARYNGOL, V123, P493, DOI 10.1080/0036554021000028120
   Hawthorne G, 2004, INT J AUDIOL, V43, P183, DOI 10.1080/14992020400050026
   Hintermair M, 2011, J DEAF STUD DEAF EDU, V16, P254, DOI 10.1093/deafed/enq045
   Hogan A, 2009, J AGING HEALTH, V21, P1098, DOI 10.1177/0898264309347821
   Huber M, 2005, INT J PEDIATR OTORHI, V69, P1089, DOI 10.1016/j.ijporl.2005.02.018
   Huber M, 2008, INT J PEDIATR OTORHI, V72, P1393, DOI 10.1016/j.ijporl.2008.06.002
   Karinen PJ, 2001, SCAND AUDIOL, V30, P48, DOI 10.1080/010503901300007047
   Kushalnagar P, 2011, J DEAF STUD DEAF EDU, V16, P512, DOI 10.1093/deafed/enr015
   Leigh IW, 2009, J DEAF STUD DEAF EDU, V14, P244, DOI 10.1093/deafed/enn038
   LEIGH IW, 1999, J DEAF STUD DEAF EDU, V4, P236, DOI DOI 10.1093/DEAFED/4.3.236
   Leigh IW, 2009, LENS DEAF IDENTITIES
   Lin FR, 2006, INT J PEDIATR OTORHI, V70, P1695, DOI 10.1016/j.ijporl.2006.05.009
   Lollis J, 2009, J DEAF STUD DEAF EDU, V14, P76, DOI 10.1093/deafed/enn017
   LUCKNER JL, 2002, FACILITATING TRANSIT
   Mauldin L, 2014, SCI TECHNOL HUM VAL, V39, P130, DOI 10.1177/0162243913512538
   Meserole RL, 2014, QUAL LIFE RES, V23, P721, DOI 10.1007/s11136-013-0509-3
   Mitchell Ross, 2004, SIGN LANGUAGE STUDIE, V4, P138, DOI DOI 10.1353/SLS.2004.0005
   Orley J., 1994, QUALITY LIFE ASSESSM, P41
   Patrick DL, 2011, OTOLARYNG HEAD NECK, V145, P137, DOI 10.1177/0194599810397604
   Prawitz A. D., 2006, FINANCIAL COUNSELING, V17, P34, DOI DOI 10.1037/T60365-000
   Pugh Kenneth C, 2002, J Am Acad Audiol, V13, P493
   Punch R, 2004, AM ANN DEAF, V149, P28, DOI 10.1353/aad.2004.0015
   Ramos Angel, 2013, Cochlear Implants Int, V14, P241, DOI 10.1179/1754762812Y.0000000028
   Ringdahl A, 2000, SCAND AUDIOL, V29, P266, DOI 10.1080/010503900750022907
   Roland L, 2016, OTOLARYNG HEAD NECK, V155, P208, DOI 10.1177/0194599816640485
   Ruffin CV, 2007, LARYNGOSCOPE, V117, P1183, DOI 10.1097/MLG.0b013e318058191a
   Santarelli R, 2008, AUDIOL NEURO-OTOL, V13, P257, DOI 10.1159/000115435
   Schick B, 2013, J DEAF STUD DEAF EDU, V18, P47, DOI 10.1093/deafed/ens039
   Smith J. A., 2011, J AM DEAFNESS REHABI, V44, P67
   Spencer LJ, 2004, LARYNGOSCOPE, V114, P1576, DOI 10.1097/00005537-200409000-00014
   Spencer LJ, 2003, EAR HEARING, V24, P236, DOI 10.1097/01.AUD.0000069231.72244.94
   Stika C. J., 1997, HEARING LOSS, V18, P29
   STINSON M, 1999, J DEAF STUD DEAF EDU, V4, P191, DOI DOI 10.1093/DEAFED/4.3.191
   THOUTENHOOFD E, 2005, PEDIAT COCHLEAR IMPL
   Traxler Carol Bloomquist, 2000, J DEAF STUD DEAF EDU, V5, P337, DOI [DOI 10.1093/DEAFED/5.4.337, 10.1093/deafed/5.4.337]
   Tyler RS, 1997, J ACOUST SOC AM, V102, P508, DOI 10.1121/1.419724
   Uziel AS, 2007, OTOL NEUROTOL, V28, P615, DOI 10.1097/01.mao.0000281802.59444.02
   Vannson N, 2015, AUDIOL NEURO-OTOL, V20, P38, DOI 10.1159/000380746
   Wagner M., 2006, 20063004 NCSER
   Wake M, 2004, AMBUL PEDIATR, V4, P411, DOI 10.1367/A03-191R.1
   Waltzman SB, 2002, OTOLARYNG HEAD NECK, V126, P505, DOI 10.1067/mhn.2002.124472
   Weisel A, 2005, J DEAF STUD DEAF EDU, V10, P376, DOI 10.1093/deafed/eni045
   Winn S, 2007, AM ANN DEAF, V152, P382, DOI 10.1353/aad.2008.0006
NR 57
TC 0
Z9 0
U1 0
U2 5
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0034-3552
EI 1538-4853
J9 REHABIL COUNS BULL
JI Rehabil. Couns. Bull.
PD JUL
PY 2019
VL 62
IS 4
BP 234
EP 242
DI 10.1177/0034355217738717
PG 9
WC Rehabilitation
SC Rehabilitation
GA IW6FO
UT WOS:000485072800004
DA 2021-02-24
ER

PT J
AU Francois, C
   Ripolles, P
   Ferreri, L
   Muchart, J
   Sierpowska, J
   Fons, C
   Sole, J
   Rebollo, M
   Zatorre, RJ
   Garcia-Alix, A
   Bosch, L
   Rodriguez-Fornells, A
AF Francois, Clement
   Ripolles, Pablo
   Ferreri, Laura
   Muchart, Jordi
   Sierpowska, Joanna
   Fons, Carme
   Sole, Jorgina
   Rebollo, Monica
   Zatorre, Robert J.
   Garcia-Alix, Alfredo
   Bosch, Laura
   Rodriguez-Fornells, Antoni
TI RIGHT STRUCTURAL AND FUNCTIONAL REORGANIZATION IN 4-YEAR-OLD CHILDREN
   WITH PERINATAL ARTERIAL ISCHEMIC STROKE PREDICT LANGUAGE PRODUCTION
SO ENEURO
LA English
DT Article
ID RIGHT-HEMISPHERIC LANGUAGE; WHITE-MATTER; SPEECH-PERCEPTION;
   BRAIN-INJURY; SPATIAL NORMALIZATION; ARCUATE FASCICULUS; VENTRAL
   PATHWAYS; AUDITORY-CORTEX; ORGANIZATION; MRI
AB Brain imaging methods have contributed to shed light on the mechanisms of recovery after early brain insult. The assumption that the unaffected right hemisphere can take over language functions after left perinatal stroke is still under debate. Here, we report how patterns of brain structural and functional reorganization were associated with language outcomes in a group of 4-year-old children with left perinatal arterial ischemic stroke. Specifically, we gathered specific fine-grained developmental measures of receptive and productive aspects of language as well as standardized measures of cognitive development. We also collected structural neuroimaging data as well as functional activations during a passive listening story-telling fMRI task and a resting state session (rs-fMRI). Children with a left perinatal stroke showed larger lateralization indices of both structural and functional connectivity of the dorsal language pathway towards the right hemisphere that, in turn, were associated with better language outcomes. Importantly, the pattern of structural asymmetry was significantly more right-lateralized in children with a left perinatal brain insult than in a group of matched healthy controls. These results strongly suggest that early lesions of the left dorsal pathway and the associated perisylvian regions can induce the inter-hemispheric transfer of language functions to right homolog regions. This study provides combined evidence of structural and functional brain reorganization of language networks after early stroke with strong implications for neurobiological models of language development.
C1 [Francois, Clement; Ferreri, Laura; Sierpowska, Joanna; Rodriguez-Fornells, Antoni] IDIBELL, Cognit & Brain Plast Grp, Bellvitge Biomed Res Inst, Barcelona 08907, Spain.
   [Francois, Clement; Ferreri, Laura; Sierpowska, Joanna; Sole, Jorgina; Bosch, Laura; Rodriguez-Fornells, Antoni] Univ Barcelona, Dept Cognit Dev & Educ Sci, Barcelona 08035, Spain.
   [Ripolles, Pablo] NYU, Dept Psychol, Poeppel Lab, New York, NY 10003 USA.
   [Muchart, Jordi; Fons, Carme; Rebollo, Monica; Garcia-Alix, Alfredo] Univ Barcelona, Inst Recerca St Joan de Deu, Hosp St Joan de Deu, Barcelona 08950, Spain.
   Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
   Radboud Univ Nijmegen, Dept Med Psychol, Med Ctr, Nijmegen, Netherlands.
   [Garcia-Alix, Alfredo] Univ Barcelona, Hosp St Joan de Deu, Pediat Neurol Dept, Inst Recerca Pediat, Barcelona 08950, Spain.
   [Zatorre, Robert J.] McGill Univ, Montreal Neurol Inst, Cognit Neurosci Unit, Montreal, PQ H3A 2B4, Canada.
   CIBER Enfermedades Raras CIBERER, U724, Madrid, Spain.
   [Bosch, Laura] Univ Barcelona, Inst Neurosci UBNeuro, Barcelona 08035, Spain.
   [Rodriguez-Fornells, Antoni] ICREA, Catalan Inst Res & Adv Studies, Barcelona 08010, Spain.
RP Bosch, L (corresponding author), Univ Barcelona, Dept Cognit Dev & Educ Sci, Barcelona 08035, Spain.; Rodriguez-Fornells, A (corresponding author), Univ Barcelona, Dept Cognit Dev & Educ Sci, Campus Bellvitge Pavello Govern, Lhospitalet De Llobregat 08908, Barcelona, Spain.
EM laurabosch@ub.edu; antoni.rodriguez@icrea.cat
RI Sierpowska, Joanna/U-5922-2019; Garcia-Alix, Alfredo/AAG-4474-2019;
   Galceran, Laura Bosch/D-5520-2012; Francois, Clement/F-7133-2013
OI Galceran, Laura Bosch/0000-0002-6536-4855; Muchart Lopez,
   Jordi/0000-0003-4702-5072; Francois, Clement/0000-0003-2271-6942;
   Ripolles, Pablo/0000-0002-8463-3723
FU "Plan Nacional de I+D+I; ISCIII-SubdireccionGeneral de Evaluacion y
   Fomento de la Investigacion Sanitaria" [PI15/00846]; European Regional
   Development Fund (FEDER "a Way to Build Europe") [SLT002/16/00390];
   Department of Health of the Generalitat de Catalunya; Bial
   FoundationBial Foundation [PSI 2014-55105P]
FX This work was partially funded by the "Plan Nacional de I+D+I and
   ISCIII-SubdireccionGeneral de Evaluacion y Fomento de la Investigacion
   Sanitaria", Project PI15/00846, the European Regional Development Fund
   (FEDER "a Way to Build Europe"), a SLT002/16/00390 grant, funded by the
   Department of Health of the Generalitat de Catalunya by the call "Accio
   instrumental d'incorporacio de cientifics i tecnolegs" to CFr, a grant
   from the Bial Foundation to ARF and a Spanish MINECO project (PSI
   2014-55105P) to LB.
CR Almli CR, 2007, NEUROIMAGE, V35, P308, DOI 10.1016/j.neuroimage.2006.08.058
   Andersen SM, 2010, NEUROIMAGE, V53, P78, DOI 10.1016/j.neuroimage.2010.06.003
   Ashburner J, 2005, NEUROIMAGE, V26, P839, DOI 10.1016/j.neuroimage.2005.02.018
   Assaneo MF, 2019, NAT NEUROSCI, V22, P627, DOI 10.1038/s41593-019-0353-z
   Bajada CJ, 2015, CORTEX, V69, P141, DOI 10.1016/j.cortex.2015.05.011
   Ballantyne AO, 2008, BRAIN, V131, P2975, DOI 10.1093/brain/awn176
   Bates E, 1997, DEV NEUROPSYCHOL, V13, P447, DOI 10.1080/87565649709540686
   Bates E, 2001, BRAIN LANG, V79, P223, DOI 10.1006/brln.2001.2482
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bernal Byron, 2012, J Clin Med Res, V4, P363, DOI 10.4021/jocmr1047w
   Binder JR, 2011, TRENDS COGN SCI, V15, P527, DOI 10.1016/j.tics.2011.10.001
   Blasi A, 2011, CURR BIOL, V21, P1220, DOI 10.1016/j.cub.2011.06.009
   Bosch L., 2004, EVALUACION FONOLOGIC
   Boveroux P, 2010, ANESTHESIOLOGY, V113, P1038, DOI 10.1097/ALN.0b013e3181f697f5
   Brauer J, 2013, BRAIN LANG, V127, P289, DOI 10.1016/j.bandl.2013.03.001
   Brett M, 2001, NEUROIMAGE, V14, P486, DOI 10.1006/nimg.2001.0845
   Brown TT, 2005, CEREB CORTEX, V15, P275, DOI 10.1093/cercor/bhh129
   Budisavljevic S, 2015, J NEUROSCI, V35, P12625, DOI 10.1523/JNEUROSCI.1255-14.2015
   Calhoun VD, 2001, NEUROIMAGE, V14, P1080, DOI 10.1006/nimg.2001.0921
   Calhoun VD, 2001, HUM BRAIN MAPP, V14, P140, DOI 10.1002/hbm.1048
   Carne RP, 2006, J CLIN NEUROSCI, V13, P60, DOI 10.1016/j.jocn.2005.02.013
   Catani M, 2003, BRAIN, V126, P2093, DOI 10.1093/brain/awg203
   Catani M, 2005, ANN NEUROL, V57, P8, DOI 10.1002/ana.20319
   Catani M, 2008, CORTEX, V44, P1105, DOI 10.1016/j.cortex.2008.05.004
   Catani M, 2007, P NATL ACAD SCI USA, V104, P17163, DOI 10.1073/pnas.0702116104
   Catani M, 2014, CURR OPIN NEUROBIOL, V28, P165, DOI 10.1016/j.conb.2014.07.018
   Ciccarelli O, 2006, BRAIN, V129, P1859, DOI 10.1093/brain/awl100
   Crawford JR, 2010, COGN NEUROPSYCHOL, V27, P245, DOI 10.1080/02643294.2010.513967
   de Diego-Balaguer R, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01478
   Dehaene-Lambertz G, 2015, NEURON, V88, P93, DOI 10.1016/j.neuron.2015.09.026
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   Dehaene-Lambertz G, 2006, P NATL ACAD SCI USA, V103, P14240, DOI 10.1073/pnas.0606302103
   Dell'Acqua F, 2010, NEUROIMAGE, V49, P1446, DOI 10.1016/j.neuroimage.2009.09.033
   Demir OE, 2015, DEV PSYCHOL, V51, P161, DOI 10.1037/a0038476
   Demir OE, 2014, DEV PSYCHOL, V50, P815, DOI 10.1037/a0034322
   Dick AS, 2013, J NEUROSCI, V33, P5612, DOI 10.1523/JNEUROSCI.2851-12.2013
   DiFrancesco MW, 2013, J MAGN RESON IMAGING, V38, P1184, DOI 10.1002/jmri.24082
   Dunn L. M., 1997, PPVT III PEABODY PIC
   Fernandez M., 2007, REV LOGOPEDIA FONIAT, V27, P140, DOI DOI 10.1016/S0214-4603(07)70083-9
   Filippi P, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.161035
   Fillmore PT, 2015, DEV NEUROSCI-BASEL, V37, P515, DOI 10.1159/000438749
   Forkel SJ, 2014, BRAIN, V137, P2027, DOI 10.1093/brain/awu113
   Francois C, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12798-2
   Francois C, 2016, CORTEX, V77, P95, DOI 10.1016/j.cortex.2016.01.010
   Friederici Angela D, 2012, Front Evol Neurosci, V4, P3, DOI 10.3389/fnevo.2012.00003
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   Friederici AD, 2009, TRENDS COGN SCI, V13, P175, DOI 10.1016/j.tics.2009.01.001
   Gervain J, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2430
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Hartwigsen G, 2017, NEUROIMAGE, P31000
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hope TMH, 2017, BRAIN, V140, P1718, DOI 10.1093/brain/awx086
   Ingram D, 2002, J CHILD LANG, V29, P713, DOI 10.1017/S0305000902005275
   Jacola LM, 2006, NEUROPEDIATRICS, V37, P46, DOI 10.1055/s-2006-923934
   JASP Team, 2018, JASP VERSION 0 8 6
   Jenkinson M, 2012, NEUROIMAGE, V62, P782, DOI 10.1016/j.neuroimage.2011.09.015
   Kerssens C, 2005, ANESTHESIOLOGY, V103, P11, DOI 10.1097/00000542-200507000-00006
   Korkman M., 2014, NEPSY 2
   Lai G, 2011, RADIOLOGY, V260, P521, DOI 10.1148/radiol.11101576
   Lebel C, 2009, HUM BRAIN MAPP, V30, P3563, DOI 10.1002/hbm.20779
   Leemans A, 2009, MAGN RESON MED, V61, P1336, DOI 10.1002/mrm.21890
   Leroy F, 2011, J NEUROSCI, V31, P1500, DOI 10.1523/JNEUROSCI.4141-10.2011
   Levine S.C., 2016, NEUROBIOLOGY LANGUAG, P969
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Lidzba K, 2006, NEUROREPORT, V17, P929, DOI 10.1097/01.wnr.0000221841.12632.d6
   Lidzba K, 2017, EUR J PAEDIATR NEURO, V21, P715, DOI 10.1016/j.ejpn.2017.06.001
   Lidzba K, 2017, BRAIN LANG, V173, P1, DOI 10.1016/j.bandl.2017.04.006
   Lidzba K, 2006, NEUROPSYCHOLOGIA, V44, P1088, DOI 10.1016/j.neuropsychologia.2005.10.022
   Liu F, 2010, BRAIN, V133, P1682, DOI 10.1093/brain/awq089
   Liu ZW, 2008, STROKE, V39, P2571, DOI 10.1161/STROKEAHA.107.511659
   Lopez-Barroso D, 2013, P NATL ACAD SCI USA, V110, P13168, DOI 10.1073/pnas.1301696110
   Lukic S, 2017, NEURAL PLAST, V2017, DOI 10.1155/2017/5601509
   Meyer L, 2014, NEUROPSYCHOLOGIA, V61, P190, DOI 10.1016/j.neuropsychologia.2014.06.014
   Moller M, 2007, J NEUROL NEUROSUR PS, V78, P587, DOI 10.1136/jnnp.2006.100248
   Morey R. D, 2015, BAYESFACTOR VERSION
   Nelson KB, 2004, LANCET NEUROL, V3, P150, DOI 10.1016/S1474-4422(04)00679-9
   Northam GB, 2018, ANN NEUROL, V83, P664, DOI 10.1002/ana.25218
   Ocklenburg S, 2014, NEUROSCI LETT, V580, P32, DOI 10.1016/j.neulet.2014.07.044
   Pahs G, 2013, BRAIN, V136, P3163, DOI 10.1093/brain/awt225
   Pani E, 2016, NEUROLOGY, V86, P1574, DOI 10.1212/WNL.0000000000002613
   Patel AD, 1998, BRAIN LANG, V61, P123, DOI 10.1006/brln.1997.1862
   Perani D, 2011, P NATL ACAD SCI USA, V108, P16056, DOI 10.1073/pnas.1102991108
   Perani D, 2010, P NATL ACAD SCI USA, V107, P4758, DOI 10.1073/pnas.0909074107
   Pernet CR, 2015, NEUROIMAGE, V119, P164, DOI 10.1016/j.neuroimage.2015.06.050
   Piai V, 2017, HUM BRAIN MAPP, V38, P3151, DOI 10.1002/hbm.23581
   Pierpaoli C, 2010, ISMRM P, V18, P1597, DOI DOI 10.1016/J.NEUROIMAGE.2011.01.038
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Raja Beharelle A, 2010, BRAIN, V133, P1707, DOI 10.1093/brain/awq104
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Reilly JS, 2013, DEVELOPMENTAL SCI, V16, P67, DOI 10.1111/j.1467-7687.2012.01192.x
   Richards JE, 2016, NEUROIMAGE, V124, P1254, DOI 10.1016/j.neuroimage.2015.04.055
   Richter W, 2003, NEUROIMAGE, V20, P1122, DOI 10.1016/S1053-8119(03)00347-1
   Ripolles P, 2012, NEUROIMAGE, V60, P1296, DOI 10.1016/j.neuroimage.2012.01.094
   Ripolles P, 2017, J NEUROSCI, V37, P11101, DOI 10.1523/JNEUROSCI.1720-17.2017
   Rodriguez-Fornells A, 2009, PHILOS T R SOC B, V364, P3711, DOI 10.1098/rstb.2009.0130
   Rojkova K, 2016, BRAIN STRUCT FUNCT, V221, P1751, DOI 10.1007/s00429-015-1001-3
   Rouder JN, 2012, MULTIVAR BEHAV RES, V47, P877, DOI 10.1080/00273171.2012.734737
   Rowe ML, 2009, DEV PSYCHOL, V45, P90, DOI 10.1037/a0012848
   Sammler D, 2015, CURR BIOL, V25, P3079, DOI 10.1016/j.cub.2015.10.009
   Sanchez CE, 2012, DEV PSYCHOBIOL, V54, P77, DOI 10.1002/dev.20579
   Satz P., 1994, NEUROPSYCHOLOGY, V8, P255, DOI DOI 10.1037/0894-4105.8.2.255
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Saygin ZM, 2013, J NEUROSCI, V33, P13251, DOI 10.1523/JNEUROSCI.4383-12.2013
   Schaechter JD, 2009, HUM BRAIN MAPP, V30, P3461, DOI 10.1002/hbm.20770
   Schlaug G, 2018, ANN NEUROL, V83, P661, DOI 10.1002/ana.25217
   Schonberg T, 2006, NEUROIMAGE, V30, P1100, DOI 10.1016/j.neuroimage.2005.11.015
   Shattuck DW, 2008, NEUROIMAGE, V39, P1064, DOI 10.1016/j.neuroimage.2007.09.031
   Shukla M, 2011, P NATL ACAD SCI USA, V108, P6038, DOI 10.1073/pnas.1017617108
   Shultz S, 2014, DEVELOPMENTAL SCI, V17, P766, DOI 10.1111/desc.12151
   Smith SM, 2006, NEUROIMAGE, V31, P1487, DOI 10.1016/j.neuroimage.2006.02.024
   Souweidane MM, 1999, PEDIATR NEUROSURG, V30, P86, DOI 10.1159/000028768
   Sreedharan RM, 2015, NEURORADIOLOGY, V57, P291, DOI 10.1007/s00234-014-1469-1
   Staudt M, 2002, NEUROIMAGE, V16, P954, DOI 10.1006/nimg.2002.1108
   Stiles J, 2005, TRENDS COGN SCI, V9, P136, DOI 10.1016/j.tics.2005.01.002
   Szaflarski JP, 2006, ANN NEUROL, V59, P796, DOI 10.1002/ana.20817
   Telkemeyer S, 2009, J NEUROSCI, V29, P14726, DOI 10.1523/JNEUROSCI.1246-09.2009
   Thiebaut de Schotten M, 2011, NEUROIMAGE, V54, P49, DOI 10.1016/j.neuroimage.2010.07.055
   Tillema JM, 2008, BRAIN LANG, V106, P184, DOI 10.1016/j.bandl.2008.08.001
   Tivarus ME, 2012, BRAIN LANG, V123, P1, DOI 10.1016/j.bandl.2012.06.006
   Tuomiranta LM, 2014, CORTEX, V50, P174, DOI 10.1016/j.cortex.2013.10.003
   Vandermosten M, 2012, BRAIN, V135, P935, DOI 10.1093/brain/awr363
   Vaquero L, 2017, CEREB CORTEX, V27, P3906, DOI 10.1093/cercor/bhw199
   Westmacott R, 2010, DEV MED CHILD NEUROL, V52, P386, DOI 10.1111/j.1469-8749.2009.03403.x
   Westmacott R, 2009, STROKE, V40, P2012, DOI 10.1161/STROKEAHA.108.533976
   Whitfield-Gabrieli S, 2012, BRAIN CONNECT, V2, P125, DOI 10.1089/brain.2012.0073
   Xing SH, 2016, BRAIN, V139, P227, DOI 10.1093/brain/awv323
   YASUDA N, 1991, ANESTH ANALG, V72, P316
   Zaske R, 2017, CORTEX, V94, P100, DOI 10.1016/j.cortex.2017.06.005
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
   Zhang JY, 2007, NEUROIMAGE, V38, P239, DOI 10.1016/j.neuroimage.2007.07.033
   Zipse L, 2012, ANN NY ACAD SCI, V1252, P237, DOI 10.1111/j.1749-6632.2012.06454.x
NR 132
TC 4
Z9 4
U1 1
U2 4
PU SOC NEUROSCIENCE
PI WASHINGTON
PA 11 DUPONT CIRCLE, NW, STE 500, WASHINGTON, DC 20036 USA
EI 2373-2822
J9 ENEURO
JI eNeuro
PD JUL-AUG
PY 2019
VL 6
IS 4
AR UNSP ENEURO.0447-18.2019
DI 10.1523/ENEURO.0447-18.2019
PG 47
WC Neurosciences
SC Neurosciences & Neurology
GA IU1AR
UT WOS:000483309700058
PM 31383726
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Gabay, Y
   Najjar, IJ
   Reinisch, E
AF Gabay, Yafit
   Najjar, Inaas-Jana
   Reinisch, Eva
TI Another Temporal Processing Deficit in Individuals With Developmental
   Dyslexia: The Case of Normalization for Speaking Rate
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SPEECH-PERCEPTION; PHONOLOGICAL SKILLS; CHILDREN; CONTEXT;
   DISCRIMINATION; LANGUAGE; ADULTS; TRANSPARENCY; OSCILLATIONS;
   DIFFICULTIES
AB Purpose: Developmental dyslexia (DD) has mostly been attributed to arise from phonological impairments; however, several theories indicate a temporal processing deficit as the underlying cause of DD. So far, research examined the influence of temporal cues on concurrent speech sound categorization in DD, but effects of temporal information from a context (e.g., speaking rate) on the perception of subsequent sounds (i.e., "rate normalization") have not been considered. This study examined whether individuals with DD are capable of implicitly extracting temporal information embedded in context and use it for phoneme categorization to the same extent as healthy readers.
   Method: Fifteen individuals diagnosed with DD and 16 healthy readers, all native speakers of Hebrew, listened to context sentences followed by target words. They had to indicate whether the target word sounded more like taam ("taste"; a long-vowel response) or tam ("naive"; a short-vowel response). Temporal information of the context was manipulated (slow vs. fast speaking rate sentences) as well as the vowel duration of the target in a 5-step continuum.
   Results: Listeners with DD did use the rate context to inform their decisions but to a significantly lesser extent than healthy listeners. In addition, their categorization of the vowel duration continuum was somewhat less distinct than that of the control group.
   Conclusions: Individuals with DD are impaired not only in tasks involving direct temporal processing, as shown in previous studies but also in the use of temporal information of a context that impacts the perception of subsequent target words. This inability to fully utilize rate normalization processes may influence the formation of abstract phonological representations in individuals with DD.
C1 [Gabay, Yafit; Najjar, Inaas-Jana] Univ Haifa, Dept Special Educ, Haifa, Israel.
   [Gabay, Yafit; Najjar, Inaas-Jana] Univ Haifa, Edmond J Safra Brain Res Ctr Study Learning Disab, Haifa, Israel.
   [Reinisch, Eva] Ludwig Maximilian Univ Munich, Inst Phonet & Speech Proc, Munich, Germany.
RP Gabay, Y (corresponding author), Univ Haifa, Dept Special Educ, Haifa, Israel.; Gabay, Y (corresponding author), Univ Haifa, Edmond J Safra Brain Res Ctr Study Learning Disab, Haifa, Israel.
EM ygabay@edu.haifa.ac.il
FU German Research FoundationGerman Research Foundation (DFG) [RE 3047/1-1]
FX This study is part of the research conducted at the University of Haifa,
   by Inaas-Jana Najjar, as partial fulfillment of her requirements for a
   master's degree under the supervision of Yafit Gabay. This project was
   funded by a grant from the German Research Foundation (Grant RE
   3047/1-1) to the third author. We would like to thank Shai Gabay and
   Rosa Franzke for their help with preparing the speech materials, Almog
   Shurkey for testing participants, and Jessica Siddins for proofreading
   the article.
CR American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Baese-Berk MM, 2014, PSYCHOL SCI, V25, P1546, DOI 10.1177/0956797614533705
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Ben-Artzi E, 2005, NEUROPSYCHOLOGIA, V43, P714, DOI 10.1016/j.neuropsychologia.2004.08.004
   Blomert L, 2004, J SPEECH LANG HEAR R, V47, P1030, DOI 10.1044/1092-4388(2004/077)
   Boersma P., 2018, PRAAT DOING PHONETIC
   Boets B, 2011, RES DEV DISABIL, V32, P560, DOI 10.1016/j.ridd.2010.12.020
   Bosker HR, 2018, LANG COGN NEUROSCI, V33, P955, DOI 10.1080/23273798.2018.1439179
   Bosker HR, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01063
   Bosker HR, 2017, J MEM LANG, V94, P166, DOI 10.1016/j.jml.2016.12.002
   Bosker HR, 2017, ATTEN PERCEPT PSYCHO, V79, P333, DOI 10.3758/s13414-016-1206-4
   Breznitz Z, 2003, GENET SOC GEN PSYCH, V129, P183
   Breznitz Z, 2003, BRAIN LANG, V85, P486, DOI 10.1016/S0093-934X(03)00071-3
   Cohen-Mimran R, 2007, DYSLEXIA, V13, P175, DOI 10.1002/dys.323
   Corriveau KH, 2010, J LEARN DISABIL-US, V43, P369, DOI 10.1177/0022219410369071
   Demonet JF, 2004, LANCET, V363, P1451, DOI 10.1016/S0140-6736(04)16106-0
   DIEHL RL, 1989, J ACOUST SOC AM, V85, P2154, DOI 10.1121/1.397864
   Farmer ME, 1995, PSYCHON B REV, V2, P460, DOI 10.3758/BF03210983
   Field A, 2012, DISCOVERING STAT USI
   Francis AL, 2006, J ACOUST SOC AM, V119, P1712, DOI 10.1121/1.2149768
   FREEMAN BA, 1978, J SPEECH HEAR RES, V21, P497, DOI 10.1044/jshr.2103.487
   Gabay Y, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0205110
   Gabay Y, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0198146
   Gabay Y, 2015, CORTEX, V73, P131, DOI 10.1016/j.cortex.2015.08.008
   Gabay Y, 2015, J SPEECH LANG HEAR R, V58, P934, DOI 10.1044/2015_JSLHR-L-14-0324
   Gabay Y, 2012, NEUROPSYCHOLOGIA, V50, P2435, DOI 10.1016/j.neuropsychologia.2012.06.014
   Ghitza O, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00130
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   GODFREY JJ, 1981, J EXP CHILD PSYCHOL, V32, P401, DOI 10.1016/0022-0965(81)90105-3
   Gooch D, 2011, J CHILD PSYCHOL PSYC, V52, P195, DOI 10.1111/j.1469-7610.2010.02312.x
   Goswami U, 2002, P NATL ACAD SCI USA, V99, P10911, DOI 10.1073/pnas.122368599
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Groth K, 2011, READ WRIT, V24, P285, DOI 10.1007/s11145-009-9213-7
   Halliday LF, 2017, COGNITION, V166, P139, DOI 10.1016/j.cognition.2017.04.014
   Heald SLM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00035
   Heffner CC, 2017, ATTEN PERCEPT PSYCHO, V79, P964, DOI 10.3758/s13414-016-1274-5
   Howard JH, 2006, NEUROPSYCHOLOGIA, V44, P1131, DOI 10.1016/j.neuropsychologia.2005.10.015
   Hufnagle DG, 2013, J EXP CHILD PSYCHOL, V116, P728, DOI 10.1016/j.jecp.2013.05.008
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Khan A., 2014, OPEN J MED PSYCHOL, V3, P373, DOI DOI 10.4236/ojmp.2014.35039
   Kosem A, 2018, CURR BIOL, V28, P2867, DOI 10.1016/j.cub.2018.07.023
   Krishnan S, 2016, TRENDS COGN SCI, V20, P701, DOI 10.1016/j.tics.2016.06.012
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Lum JAG, 2013, RES DEV DISABIL, V34, P3460, DOI 10.1016/j.ridd.2013.07.017
   Maslowski M, 2019, J EXP PSYCHOL LEARN, V45, P128, DOI 10.1037/xlm0000579
   Melby-Lervag M, 2012, PSYCHOL BULL, V138, P322, DOI 10.1037/a0026744
   Mody M, 1997, J EXP CHILD PSYCHOL, V64, P199, DOI 10.1006/jecp.1996.2343
   Morey RD, 2008, TUTOR QUANT METHODS, V4, P61, DOI 10.20982/tqmp.04.2.p061
   Muneaux M, 2004, NEUROREPORT, V15, P1255, DOI 10.1097/01.wnr.0000127459.31232.c4
   Newman RS, 2009, J PHONETICS, V37, P46, DOI 10.1016/j.wocn.2008.09.001
   NICOLSON RI, 1995, P ROY SOC B-BIOL SCI, V259, P43, DOI 10.1098/rspb.1995.0007
   Nicolson RI, 2007, TRENDS NEUROSCI, V30, P135, DOI 10.1016/j.tins.2007.02.003
   Nicolson RI, 2011, CORTEX, V47, P117, DOI 10.1016/j.cortex.2009.08.016
   Nittrouer S, 1999, J SPEECH LANG HEAR R, V42, P925, DOI 10.1044/jslhr.4204.925
   Nozaradan S, 2017, CORTEX, V95, P156, DOI 10.1016/j.cortex.2017.08.015
   Perrachione T. K, 2011, P 17 INT C PHON SCI
   Peterson RL, 2015, ANNU REV CLIN PSYCHO, V11, P283, DOI 10.1146/annurev-clinpsy-032814-112842
   Pinheiro J., 2017, NLME LINEAR NONLINEA, DOI DOI 10.5194/TC-10-2291-2016
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Protopapas A, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0090
   Quene H, 2008, J MEM LANG, V59, P413, DOI 10.1016/j.jml.2008.02.002
   Ramus F, 2008, Q J EXP PSYCHOL, V61, P129, DOI 10.1080/17470210701508822
   REED MA, 1989, J EXP CHILD PSYCHOL, V48, P270, DOI 10.1016/0022-0965(89)90006-4
   Reinisch E, 2016, APPL PSYCHOLINGUIST, V37, P1397, DOI 10.1017/S0142716415000612
   Reinisch E, 2016, ATTEN PERCEPT PSYCHO, V78, P1203, DOI 10.3758/s13414-016-1067-x
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   Reinisch E, 2011, LANG SPEECH, V54, P147, DOI 10.1177/0023830910397489
   Rey V, 2002, BRAIN LANG, V80, P576, DOI 10.1006/brln.2001.2618
   Richardson U, 2004, DYSLEXIA, V10, P215, DOI 10.1002/dys.276
   Schneider W., 2002, E PRIME USERS GUIDE
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   Shany M, 2011, DEV NEUROPSYCHOL, V36, P889, DOI 10.1080/87565641.2011.606410
   Singh S, 2018, ANN DYSLEXIA, V68, P165, DOI 10.1007/s11881-018-0161-2
   Sjerps MJ, 2015, J EXP PSYCHOL HUMAN, V41, P710, DOI 10.1037/a0039028
   Snowling M J, 2001, Dyslexia, V7, P37
   Steinbrink C, 2014, RES DEV DISABIL, V35, P3034, DOI 10.1016/j.ridd.2014.07.049
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   TALLAL P, 1984, APPL PSYCHOLINGUIST, V5, P167, DOI 10.1017/S0142716400004963
   Toscano JC, 2015, LANG COGN NEUROSCI, V30, P529, DOI 10.1080/23273798.2014.946427
   Ullman MT, 2004, COGNITION, V92, P231, DOI 10.1016/j.cognition.2003.10.008
   Van Ingelghem M, 2001, NEUROREPORT, V12, P3603, DOI 10.1097/00001756-200111160-00046
   Vandermosten M, 2011, RES DEV DISABIL, V32, P593, DOI 10.1016/j.ridd.2010.12.015
   Vandermosten M, 2010, P NATL ACAD SCI USA, V107, P10389, DOI 10.1073/pnas.0912858107
   Wade T, 2005, PERCEPT PSYCHOPHYS, V67, P939, DOI 10.3758/BF03193621
   WATSON M, 1990, PERCEPT MOTOR SKILL, V71, P107
   Wechsler D., 1997, WAIS 3 ADM SCORING M
   Weiss Y, 2016, CORTEX, V83, P145, DOI 10.1016/j.cortex.2016.07.017
   World Health Organisation, 2001, WORLD HLTH REPORT 20
   Yael W, 2015, ANN DYSLEXIA, V65, P84, DOI 10.1007/s11881-015-0100-4
NR 93
TC 1
Z9 1
U1 1
U2 3
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD JUL
PY 2019
VL 62
IS 7
BP 2171
EP 2184
DI 10.1044/2019_JSLHR-S-18-0264
PG 14
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA IO1EM
UT WOS:000479123500008
PM 31200610
DA 2021-02-24
ER

PT J
AU Witte, E
   Kobler, S
AF Witte, Erik
   Kobler, Susanne
TI Linguistic Materials and Metrics for the Creation of Well-Controlled
   Swedish Speech Perception Tests
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID CALCULATE PHONOTACTIC PROBABILITY; WEB-BASED INTERFACE; WORD
   RECOGNITION; NEIGHBORHOOD ACTIVATION; LEXICAL DECISION; FREQUENCY;
   NONWORDS; HEARING; RELIABILITY; NOISE
AB Purpose: As factors influencing human word perception are important in the construction of speech perception tests used within the speech and hearing sciences, the purposes of this study were as follows: first, to develop algorithms that can be used to calculate different types of word metrics that influence the speed and accuracy of word perception and, second, to create a database in which those word metrics were calculated for a large set of Swedish words.
   Method: Based on a revision of a large Swedish phonetic dictionary, data and algorithms were developed by which various frequency metrics, word length metrics, semantic metrics, neighborhood metrics, phonotactic metrics, and orthographic transparency metrics were calculated for each word in the dictionary. Of the various word metric algorithms used, some were Swedish language reimplementations of previously published algorithms, and some were developed in this study.
   Results: The results of this study have been gathered in a Swedish word metric database called the AFC-list. The AFC-list consists of 816,404 phonetically transcribed Swedish words, all supplied with the word metric data calculated. The full AFC-list has been made publicly available under the Creative Commons Attribution 4.0 International license.
   Conclusion: The results of this study constitute an extensive linguistic resource for the process of selecting test items in new well-controlled speech perception tests in the Swedish language.
C1 [Witte, Erik; Kobler, Susanne] Orebro Univ Hosp, Audiol Res Ctr, Orebro, Sweden.
   [Witte, Erik; Kobler, Susanne] Orebro Univ, Sch Hlth Sci, Orebro, Sweden.
   [Witte, Erik; Kobler, Susanne] Swedish Inst Disabil Res, Orebro, Sweden.
RP Witte, E (corresponding author), Orebro Univ Hosp, Audiol Res Ctr, Orebro, Sweden.; Witte, E (corresponding author), Orebro Univ, Sch Hlth Sci, Orebro, Sweden.; Witte, E (corresponding author), Swedish Inst Disabil Res, Orebro, Sweden.
EM erik.witte@oru.se
FU Nyckelfonden at Region Orebro County, Sweden [OLL597471]; Research
   Committee at Region Orebro County, Sweden [OLL-551401]
FX This work was supported by Nyckelfonden (Grant OLL597471) and The
   Research Committee (Grant OLL-551401) at Region Orebro County, Sweden.
   The authors thank Claes Moller and Jonas Ekeroot for substantial
   comments and suggestions that helped in the development of this study
   and for the improvement of the article.
CR Adelman JS, 2006, PSYCHOL SCI, V17, P814, DOI 10.1111/j.1467-9280.2006.01787.x
   Aljasser F, 2018, BEHAV RES METHODS, V50, P313, DOI 10.3758/s13428-017-0872-z
   Andrews S, 1997, PSYCHON B REV, V4, P439, DOI 10.3758/BF03214334
   Balota DA, 2004, J EXP PSYCHOL GEN, V133, P283, DOI 10.1037/0096-3445.133.2.283
   BERNDT RS, 1987, BEHAV RES METH INSTR, V19, P1, DOI 10.3758/BF03207663
   Bertenstam J, 1995, 1 STLQPSR
   Borin L, 2013, LANG RESOUR EVAL, V47, P1191, DOI 10.1007/s10579-013-9233-4
   Borin L, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P474
   Brysbaert M, 2016, J EXP PSYCHOL HUMAN, V42, P441, DOI 10.1037/xhp0000159
   Brysbaert M, 2011, EXP PSYCHOL, V58, P412, DOI 10.1027/1618-3169/a000123
   Brysbaert M, 2009, Q J EXP PSYCHOL, V62, P1832, DOI 10.1080/17470210802585471
   Delattre M, 2006, J EXP PSYCHOL LEARN, V32, P1330, DOI 10.1037/0278-7393.32.6.1330
   Dich N, 2014, J PSYCHOLINGUIST RES, V43, P141, DOI 10.1007/s10936-013-9247-5
   EGAN JP, 1948, LARYNGOSCOPE, V58, P955, DOI 10.1288/00005537-194809000-00002
   FEENEY MP, 1982, EAR HEARING, V3, P59, DOI 10.1097/00003446-198203000-00002
   Garlen C, 1988, SWEDISH PHONOLOGY CO
   Gelfand SA, 1998, J SPEECH LANG HEAR R, V41, P1088, DOI 10.1044/jslhr.4105.1088
   GELFAND SA, 1992, J REHABIL RES DEV, V29, P53, DOI 10.1682/JRRD.1992.01.0053
   Hallgren M, 2006, INT J AUDIOL, V45, P227, DOI 10.1080/14992020500429583
   Hedelin P, 1997, NORSTEDTS SWEDISH PR
   Helgason P, 2007, P 15 INT C PHON SCI, P1357
   HOUSE AS, 1965, J ACOUST SOC AM, V37, P158, DOI 10.1121/1.1909295
   International Phonetic Association, 1999, HDB INT PHON ASS GUI
   Jurafsky Daniel, 2009, SPEECH LANGUAGE PROC
   Keuleers E, 2010, BEHAV RES METHODS, V42, P627, DOI 10.3758/BRM.42.3.627
   Kuk F, 2010, EAR HEARING, V31, P779, DOI 10.1097/AUD.0b013e3181e97bfb
   Kuronen M., 2000, THESIS
   Leinonen T., 2010, THESIS
   LIDEN G, 1954, Acta Otolaryngol Suppl, V116, P189
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Martin N, 2019, BRIT J PSYCHOL, V110, P745, DOI 10.1111/bjop.12362
   Myrberg S, 2015, NORD J LINGUIST, V38, P115, DOI 10.1017/S0332586515000177
   Nasjonalbiblioteket, 2011, LEKS DAT SVENSK
   Paglialonga A, 2014, COMPUT BIOL MED, V52, P66, DOI 10.1016/j.compbiomed.2014.06.012
   Parker S, 2008, J PHONETICS, V36, P55, DOI 10.1016/j.wocn.2007.09.003
   Pisoni DB, 2005, BLACKW HBK LINGUIST, P1, DOI 10.1002/9780470757024
   Rastle K, 2002, Q J EXP PSYCHOL-A, V55, P1339, DOI 10.1080/02724980244000099
   Riad T., 2014, PHONOLOGY SWEDISH
   Schmalz X, 2015, PSYCHON B REV, V22, P1614, DOI 10.3758/s13423-015-0835-2
   Sigurd B, 1965, THESIS
   Spencer KA, 2009, BEHAV RES METHODS, V41, P220, DOI 10.3758/BRM.41.1.220
   Storkel H, 2004, J SPEECH LANG HEAR R, V47, P1454, DOI 10.1044/1092-4388(2004/108)
   van Heuven WJB, 2014, Q J EXP PSYCHOL, V67, P1176, DOI 10.1080/17470218.2013.850521
   Vitevitch MS, 1999, J MEM LANG, V40, P374, DOI 10.1006/jmla.1998.2618
   Vitevitch MS, 2004, BEHAV RES METH INS C, V36, P481, DOI 10.3758/BF03195594
   Vitevitch MS, 1998, PSYCHOL SCI, V9, P325, DOI 10.1111/1467-9280.00064
   Witte E, 2014, THESIS
   Yap MJ, 2011, PSYCHON B REV, V18, P742, DOI 10.3758/s13423-011-0092-y
   Ziegler JC, 2003, J MEM LANG, V48, P779, DOI 10.1016/S0749-596X(03)00006-8
   Ziegler JC, 2010, PSYCHOL SCI, V21, P551, DOI 10.1177/0956797610363406
NR 50
TC 1
Z9 1
U1 0
U2 0
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD JUL
PY 2019
VL 62
IS 7
BP 2280
EP 2294
DI 10.1044/2019_JSLHR-S-18-0454
PG 15
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA IO1EM
UT WOS:000479123500016
PM 31265791
DA 2021-02-24
ER

PT J
AU Walker, EA
   Kessler, D
   Klein, K
   Spratford, M
   Oleson, JJ
   Welhaven, A
   McCreery, RW
AF Walker, Elizabeth A.
   Kessler, David
   Klein, Kelsey
   Spratford, Meredith
   Oleson, Jacob J.
   Welhaven, Anne
   McCreery, Ryan W.
TI Time-Gated Word Recognition in Children: Effects of Auditory Access,
   Age, and Semantic Context
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SPOKEN MONOSYLLABIC NOUNS; WORKING-MEMORY; SPEECH-PERCEPTION; COCHLEAR
   IMPLANTS; HEARING-LOSS; NEIGHBORHOOD DENSITY; SIMILARITY NEIGHBORHOODS;
   INDIVIDUAL-DIFFERENCES; YOUNG-CHILDREN; LEXICAL ACCESS
AB Purpose: We employed a time-gated word recognition task to investigate how children who are hard of hearing (CHH) and children with normal hearing (CNH) combine cognitive-linguistic abilities and acoustic-phonetic cues to recognize words in sentence-final position.
   Method: The current study included 40 CHH and 30 CNH in 1st or 3rd grade. Participants completed vocabulary and working memory tests and a time-gated word recognition task consisting of 14 high- and 14 low-predictability sentences. A time-to-event model was used to evaluate the effect of the independent variables (age, hearing status, predictability) on word recognition. Mediation models were used to examine the associations between the independent variables vocabulary size and working memory), aided audibility, and word recognition.
   Results: Gated words were identified significantly earlier for high-predictability than low-predictability sentences. First-grade CHH and CNH showed no significant difference in performance. Third-grade CHH needed more information than CNH to identify final words. Aided audibility was associated with word recognition. This association was fully mediated by vocabulary size but not working memory.
   Conclusions: Both CHH and CNH benefited from the addition of semantic context. Interventions that focus on consistent aided audibility and vocabulary may enhance children's ability to fill in gaps in incoming messages.
C1 [Walker, Elizabeth A.; Klein, Kelsey] Univ Iowa, Dept Commun Sci & Disorders, Iowa City, IA 52242 USA.
   [Kessler, David] Vanderbilt Univ, Dept Hearing & Speech Sci, 221 Kirkland Hall, Nashville, TN 37235 USA.
   [Spratford, Meredith; McCreery, Ryan W.] Boys Town Natl Res Hosp, Omaha, NE 68131 USA.
   [Oleson, Jacob J.; Welhaven, Anne] Univ Iowa, Dept Biostat, Iowa City, IA USA.
RP Walker, EA (corresponding author), Univ Iowa, Dept Commun Sci & Disorders, Iowa City, IA 52242 USA.
EM elizabeth-walker@uiowa.edu
RI Klein, Kelsey/AAH-2166-2019
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC009560, R01DC013591]; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01DC013591, R01DC013591, R01DC013591, R01DC009560,
   R01DC013591] Funding Source: NIH RePORTER
FX This research was supported by the National Institute on Deafness and
   Other Communication Disorders Grants R01DC009560 (co-principal
   investigators: J. Bruce Tomblin and Mary Pat Moeller) and R01DC013591
   (principal investigator: Ryan W. McCreery). The authors had full
   editorial control of this work and article. The content of this project
   is solely the responsibility of the authors and does not necessarily
   represent the official views of the National Institute on Deafness and
   Other Communication Disorders or the National Institutes of Health.
   Several people provided support, assistance, and feedback at various
   points in the project, including Mary Pat Moeller, J. Bruce Tomblin,
   Wendy Fick, Marlea O'Brien, Margaret Dallapiazza, and Madeline Narducci.
   Special thanks go to the examiners at the University of Iowa and Boys
   Town National Research Hospital, as well as the families and children
   who participated in the research.
CR Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Alloway T. P., 2007, AUTOMATIC WORKING ME
   American National Standard Institute S3.5-1997, 1997, S351997 AM NAT STAND
   American National Standards Institute, 2003, S3222003 AM NAT STAN
   Antia SD, 2009, J DEAF STUD DEAF EDU, V14, P293, DOI 10.1093/deafed/enp009
   AuBuchon AM, 2015, EAR HEARING, V36, P733, DOI 10.1097/AUD.0000000000000189
   Bagatto Marlene, 2005, Trends Amplif, V9, P199, DOI 10.1177/108471380500900404
   BARON RM, 1986, J PERS SOC PSYCHOL, V51, P1173, DOI 10.1037/0022-3514.51.6.1173
   BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32
   Blamey PJ, 2001, J SPEECH LANG HEAR R, V44, P264, DOI 10.1044/1092-4388(2001/022)
   Borovsky A, 2013, J COMMUN DISORD, V46, P413, DOI 10.1016/j.jcomdis.2013.09.001
   Briscoe J, 2001, J CHILD PSYCHOL PSYC, V42, P329, DOI 10.1017/S0021963001007041
   CharlesLuce J, 1995, J CHILD LANG, V22, P727, DOI 10.1017/S0305000900010023
   Cole B., 2005, AUDIONOTE2 VERIFIT T
   Collison EA, 2004, J SPEECH LANG HEAR R, V47, P496, DOI 10.1044/1092-4388(2004/039)
   Conway CM, 2014, J SPEECH LANG HEAR R, V57, P2174, DOI 10.1044/2014_JSLHR-L-13-0236
   COX RM, 1989, J SPEECH HEAR RES, V32, P347, DOI 10.1044/jshr.3202.347
   CRAIG CH, 1993, J SPEECH HEAR RES, V36, P832, DOI 10.1044/jshr.3604.832
   Dahan D, 2001, LANG COGNITIVE PROC, V16, P507, DOI 10.1080/01690960143000074
   Davidson Lisa S, 2011, Ear Hear, V32, p19S, DOI 10.1097/AUD.0b013e3181ffdb8b
   Deocampo JA, 2018, LANG SPEECH HEAR SER, V49, P723, DOI 10.1044/2018_LSHSS-STLT1-17-0138
   Dollaghan C, 1998, APPL PSYCHOLINGUIST, V19, P193, DOI 10.1017/S0142716400010031
   Dunn D. M., 2007, PEABODY PICTURE VOCA
   Eisenberg LS, 2007, EAR HEARING, V28, P773, DOI 10.1097/AUD.0b013e318157f06c
   ELLIOTT LL, 1987, PERCEPT PSYCHOPHYS, V42, P150, DOI 10.3758/BF03210503
   ELLIOTT LL, 1990, J LEARN DISABIL, V23, P248, DOI 10.1177/002221949002300408
   Evans JL, 2018, J SPEECH LANG HEAR R, V61, P1409, DOI 10.1044/2018_JSLHR-L-17-0150
   Farris-Trimble A, 2014, J EXP PSYCHOL HUMAN, V40, P308, DOI 10.1037/a0034353
   Garlock VM, 2001, J MEM LANG, V45, P468, DOI 10.1006/jmla.2000.2784
   GROSJEAN F, 1980, PERCEPT PSYCHOPHYS, V28, P267, DOI 10.3758/BF03204386
   Jerger S, 2007, EAR HEARING, V28, P754, DOI 10.1097/AUD.0b013e318157f049
   Klein KE, 2017, J SPEECH LANG HEAR R, V60, P2281, DOI 10.1044/2017_JSLHR-H-16-0086
   Lewis D, 2017, EAR HEARING, V38, pE180, DOI 10.1097/AUD.0000000000000395
   Lowenstein J. H, 2007, J ACOUST SOC AM, V122, P3032
   Lunner T, 2009, SCAND J PSYCHOL, V50, P395, DOI 10.1111/j.1467-9450.2009.00742.x
   Magimairaj BM, 2018, J SPEECH LANG HEAR R, V61, P1294, DOI 10.1044/2018_JSLHR-H-17-0312
   Mainela-Arnold E, 2008, J SPEECH LANG HEAR R, V51, P381, DOI 10.1044/1092-4388(2008/028)
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   McCreery Ryan W, 2015, Ear Hear, V36 Suppl 1, p24S, DOI 10.1097/AUD.0000000000000211
   McCreery RW, 2017, INT J AUDIOL, V56, P306, DOI 10.1080/14992027.2016.1266703
   McCreery RW, 2015, EAR HEARING, V36, P309, DOI [10.1097/AUD.0000000000000213, 10.1097/AUD.0000000000000120]
   McMurray B, 2017, COGNITION, V169, P147, DOI 10.1016/j.cognition.2017.08.013
   McMurray B, 2010, COGNITIVE PSYCHOL, V60, P1, DOI 10.1016/j.cogpsych.2009.06.003
   Metsala JL, 1997, MEM COGNITION, V25, P47, DOI 10.3758/BF03197284
   Moeller Mary Pat, 2015, Ear Hear, V36 Suppl 1, p4S, DOI 10.1097/AUD.0000000000000210
   Montgomery JW, 1999, J SPEECH LANG HEAR R, V42, P735, DOI 10.1044/jslhr.4203.735
   Nation K, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0387
   NITTROUER S, 1990, J ACOUST SOC AM, V87, P2705, DOI 10.1121/1.399061
   NITTROUER S, 1987, J SPEECH HEAR RES, V30, P319, DOI 10.1044/jshr.3003.319
   Nittrouer S, 2017, J SPEECH LANG HEAR R, V60, P3342, DOI 10.1044/2017_JSLHR-H-16-0474
   Nittrouer S, 2013, INT J PEDIATR OTORHI, V77, P1886, DOI 10.1016/j.ijporl.2013.09.001
   Osman H, 2014, J SPEECH LANG HEAR R, V57, P1503, DOI 10.1044/2014_JSLHR-H-13-0286
   Page TA, 2018, LANG SPEECH HEAR SER, V49, P965, DOI 10.1044/2018_LSHSS-17-0145
   Patro C, 2018, J SPEECH LANG HEAR R, V61, P145, DOI 10.1044/2017_JSLHR-H-17-0141
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2010, NOISE HEALTH, V12, P263, DOI 10.4103/1463-1741.70505
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   Sininger YS, 2010, EAR HEARING, V31, P166, DOI 10.1097/AUD.0b013e3181c8e7b6
   SNOWLING M, 1986, J EXP CHILD PSYCHOL, V41, P489, DOI 10.1016/0022-0965(86)90006-8
   Stelmachowicz PG, 2000, J SPEECH LANG HEAR R, V43, P902, DOI 10.1044/jslhr.4304.902
   Stiles DJ, 2012, J SPEECH LANG HEAR R, V55, P764, DOI 10.1044/1092-4388(2011/10-0264)
   Storkel HL, 2002, J CHILD LANG, V29, P251, DOI 10.1017/S0305000902005032
   Storkel HL, 2010, BEHAV RES METHODS, V42, P497, DOI 10.3758/BRM.42.2.497
   Sullivan JR, 2015, J SPEECH LANG HEAR R, V58, P1043, DOI 10.1044/2015_JSLHR-H-14-0204
   Tomblin JB, 2020, CHILD DEV, V91, pE179, DOI 10.1111/cdev.13158
   Tomblin J Bruce, 2015, Ear Hear, V36 Suppl 1, p76S, DOI 10.1097/AUD.0000000000000219
   Tomblin JB, 2014, JAMA OTOLARYNGOL, V140, P403, DOI 10.1001/jamaoto.2014.267
   WAGNER RK, 1987, PSYCHOL BULL, V101, P192, DOI 10.1037/0033-2909.101.2.192
   Walker EA, 2019, J SPEECH LANG HEAR R, V62, P525, DOI 10.1044/2018_JSLHR-L-ASTM-18-0250
   Walker EA, 2015, J SPEECH LANG HEAR R, V58, P1611, DOI 10.1044/2015_JSLHR-H-15-0043
   WALLEY AC, 1988, COGNITIVE DEV, V3, P137, DOI 10.1016/0885-2014(88)90016-0
   WALLEY AC, 1993, DEV REV, V13, P286, DOI 10.1006/drev.1993.1015
   Wechsler D., 2011, WECHSLER ABBREVIATED
   Willis S, 2014, INT J PEDIATR OTORHI, V78, P1107, DOI 10.1016/j.ijporl.2014.04.025
NR 75
TC 4
Z9 4
U1 0
U2 1
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD JUL
PY 2019
VL 62
IS 7
BP 2519
EP 2534
DI 10.1044/2019_JSLHR-H-18-0407
PG 16
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA IO1EM
UT WOS:000479123500032
PM 31194921
OA Green Published
DA 2021-02-24
ER

PT J
AU Manker, J
AF Manker, Jonathan
TI Contextual predictability and phonetic attention
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Speech perception; Attention; Listening modes; Predictability; Context;
   Discrimination; Sound change
ID SPEECH; PERCEPTION; DURATION; INTELLIGIBILITY; RESTORATION; CONVERGENCE;
   RECOGNITION; EXPLANATION; IMITATION
AB The interaction of contextual, high-level linguistic knowledge and the listener's attention to low-level phonetic details has been the subject of a large body of research in speech perception for several decades. In the current paper, I investigate this interaction by considering the specific phenomenon of word predictability and its role in modulating the listener's attention to subphonemic details of the acoustic signal. In the first experiment, subjects are presented with a discrimination task in which target words are presented in either predictable or unpredictable sentential context and then repeated in isolation, being either acoustically identical or subtly different. The subjects more accurately discriminate contextually unpredictable words, suggesting more attention to the phonetic details of words in unpredictable contexts. In the second experiment, considering the predictions of exemplar theory, I test whether this perceptual bias could result in changes in production. In this experiment, in which subjects heard and repeated sentences, I find a significant effect of word predictability on how close the subjects' productions were to the model's, which suggests a role of predictability on phonetic accommodation. The results of these experiments contribute to our understanding of stored exemplars and suggest the influence of contextual predictability in sound change. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Manker, Jonathan] Univ Calif Berkeley, Dept Linguist, Berkeley, CA 94720 USA.
RP Manker, J (corresponding author), Univ Calif Berkeley, Dept Linguist, Berkeley, CA 94720 USA.
EM jtmanker@berkeley.edu
FU UC Berkeley Linguistics Department
FX Special thanks to Dr. Keith Johnson, Dr. Susan Lin, Dr. Jason Shaw, the
   Berkeley PhonLab, the Berkeley Phonology Phorum, and the Yale Phonology
   Reading Group for their helpful comments and suggestions. Also thanks to
   Libby Perfitt, Steven Chan Ho, and Sofea Dil for assisting in collecting
   the data for this experiment. Funding provided by the UC Berkeley
   Linguistics Department.
CR Aylett M, 2004, LANG SPEECH, V47, P31, DOI 10.1177/00238309040470010201
   Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001
   Babel M, 2010, LANG SOC, V39, P437, DOI 10.1017/S0047404510000400
   Beckman Jill N., 1998, THESIS
   Bell A, 2003, J ACOUST SOC AM, V113, P1001, DOI 10.1121/1.1534836
   Bloomfield L., 1933, LANGUAGE
   Boersma P., 2014, PRAAT DOING PHONETIC
   Bybee Joan, 2001, PHONOLOGY LANGUAGE U
   Cohen Priva U, 2008, P 27 W COAST C FORM
   COLE RA, 1978, J ACOUST SOC AM, V64, P44, DOI 10.1121/1.381955
   Cutler A., 1979, SENTENCE PROCESSING, P113
   Foss D. J, 1980, PERCEPTION PRODUCTIO
   Gahl S, 2012, J MEM LANG, V66, P789, DOI 10.1016/j.jml.2011.11.006
   Garrett Andrew, 2013, ORIGINS SOUND CHANGE, P51, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0003
   Goldinger S. D, 2007, P 17 INT C PHON SCI
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Goldinger SD, 2003, J PHONETICS, V31, P305, DOI 10.1016/S0095-4470(03)00030-5
   Gor K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01449
   HAUTUS MJ, 1995, BEHAV RES METH INS C, V27, P46, DOI 10.3758/BF03203619
   Hay JB, 2015, COGNITION, V139, P83, DOI 10.1016/j.cognition.2015.02.012
   Heath J. S, 2014, UC BERKELEY PHONOLOG, P119
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Honorof DN, 2011, J PHONETICS, V39, P18, DOI 10.1016/j.wocn.2010.10.007
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Jurafsky D., 2000, FREQUENCY EMERGENCE, P229, DOI DOI 10.1075/TSL.45.13JUR
   Klatt D. H, 1979, PERCEPTION PRODUCTIO, P243
   Labov W, 2007, LANGUAGE, V83, P344, DOI 10.1353/lan.2007.0082
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LINDBLOM B, 1990, NATO ADV SCI I D-BEH, V55, P403
   LINDBLOM BJORN, 1995, RIV LINGUISTICA, P75
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X
   Martinet Andre, 1960, ELEMENTS LINGUISTIQU
   Mattys SL, 2009, COGNITIVE PSYCHOL, V59, P203, DOI 10.1016/j.cogpsych.2009.04.001
   Maye J, 2007, P 17 INT C PHON SCI, P63
   MILLER GA, 1951, J EXP PSYCHOL, V41, P329, DOI 10.1037/h0062491
   Minkova D, 2005, RETHINKING MIDDLE EN, P263
   Mitterer H, 2008, COGNITION, V109, P168, DOI 10.1016/j.cognition.2008.08.002
   Mixdorff H, 2012, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON SPEECH PROSODY, VOLS I AND II, P571
   MORTON J, 1976, J VERB LEARN VERB BE, V15, P43, DOI 10.1016/S0022-5371(76)90005-0
   Namy LL, 2002, J LANG SOC PSYCHOL, V21, P422, DOI 10.1177/026192702237958
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007
   Nye PW, 2003, J PHONETICS, V31, P63, DOI 10.1016/S0095-4470(02)00072-4
   Ohala J., 1983, PRODUCTION SPEECH, P189, DOI [DOI 10.1007/978-1-4613-8202-7_9, 10.1007/978-1-4613-8202-7_9]
   Ohala John, 1981, PAPERS PARASESSION L, P178
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720
   Phillips BS, 2006, PALGR STUD LANG HIST, P1, DOI 10.1057/9780230286610
   Pierrehumbert JB, 2006, J PHONETICS, V34, P516, DOI 10.1016/j.wocn.2006.06.003
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   POLLACK I, 1964, J VERB LEARN VERB BE, V3, P79, DOI 10.1016/S0022-5371(64)80062-1
   Priva UC, 2015, LAB PHONOL, V6, P243, DOI 10.1515/lp-2015-0008
   SAMUEL AG, 1987, J MEM LANG, V26, P36, DOI 10.1016/0749-596X(87)90061-1
   SAMUEL AG, 1981, J EXP PSYCHOL GEN, V110, P474, DOI 10.1037/0096-3445.110.4.474
   Sancier ML, 1997, J PHONETICS, V25, P421, DOI 10.1006/jpho.1997.0051
   Schnoebelen T, 2010, PSIHOLOGIJA, V43, P441, DOI 10.2298/PSI1004441S
   Seyfarth S, 2014, COGNITION, V133, P140, DOI 10.1016/j.cognition.2014.06.013
   Shockley K, 2004, PERCEPT PSYCHOPHYS, V66, P422, DOI 10.3758/BF03194890
   Stanislaw H, 1999, BEHAV RES METH INS C, V31, P137, DOI 10.3758/BF03207704
   Stickney GS, 2001, J ACOUST SOC AM, V109, P1157, DOI 10.1121/1.1340643
   Sumner M, 2013, J ACOUST SOC AM, V134, pEL26, DOI 10.1121/1.4807432
   Talkin D, 1996, GET F0 ONLINE DOCUME
   Taylor WL, 1953, JOURNALISM QUART, V30, P415, DOI 10.1177/107769905303000401
   Tilsen S, 2009, J PHONETICS, V37, P276, DOI 10.1016/j.wocn.2009.03.004
   Turnbull Rory John, 2015, THESIS
   Ungerleider Leslie G., 1994, Current Opinion in Neurobiology, V4, P157, DOI 10.1016/0959-4388(94)90066-3
   WANG WSY, 1969, LANGUAGE, V45, P9, DOI 10.2307/411748
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Yu ACL, 2014, J ACOUST SOC AM, V136, P382, DOI 10.1121/1.4883380
   Yu ACL, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011950
   Yuan Jiahong, 2008, P AC 08
   Zellou G, 2013, P M AC, V19, DOI [10.1121/1.4805633, DOI 10.1121/1.4805633]
   Zipf G.K., 1949, HUMAN BEHAV PRINCIPL
NR 73
TC 1
Z9 1
U1 1
U2 3
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD JUL
PY 2019
VL 75
BP 94
EP 112
DI 10.1016/j.wocn.2019.05.005
PG 19
WC Linguistics; Language & Linguistics
SC Linguistics
GA IM1ZE
UT WOS:000477789600007
DA 2021-02-24
ER

PT J
AU Bidelman, GM
   Sigley, L
   Lewis, GA
AF Bidelman, Gavin M.
   Sigley, Lauren
   Lewis, Gwyneth A.
TI Acoustic noise and vision differentially warp the auditory
   categorization of speech
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID CATEGORICAL PERCEPTION; INTRAINDIVIDUAL VARIABILITY; PSYCHOMETRIC
   FUNCTIONS; LANGUAGE EXPERIENCE; NEURAL ORGANIZATION; NORMAL-HEARING;
   VISUAL SPEECH; BRAIN-STEM; CHILDREN; INTEGRATION
AB Speech perception requires grouping acoustic information into meaningful linguistic-phonetic units via categorical perception (CP). Beyond shrinking observers' perceptual space, CP might aid degraded speech perception if categories are more resistant to noise than surface acoustic features. Combining audiovisual (AV) cues also enhances speech recognition, particularly in noisy environments. This study investigated the degree to which visual cues from a talker (i.e., mouth movements) aid speech categorization amidst noise interference by measuring participants' identification of clear and noisy speech (0 dB signal-to-noise ratio) presented in auditory-only or combined AV modalities (i.e., A, A+noise, AV, AV+noise conditions). Auditory noise expectedly weakened (i.e., shallower identification slopes) and slowed speech categorization. Interestingly, additional viseme cues largely counteracted noise-related decrements in performance and stabilized classification speeds in both clear and noise conditions suggesting more precise acoustic-phonetic representations with multisensory information. Results are parsimoniously described under a signal detection theory framework and by a reduction (visual cues) and increase (noise) in the precision of perceptual object representation, which were not due to lapses of attention or guessing. Collectively, findings show that (i) mapping sounds to categories aids speech perception in "cocktail party" environments; (ii) visual cues help lattice formation of auditory-phonetic categories to enhance and refine speech identification. (C) 2019 Acoustical Society of America.
C1 [Bidelman, Gavin M.; Sigley, Lauren; Lewis, Gwyneth A.] Univ Memphis, Sch Commun Sci & Disorders, 4055 North Pk Loop, Memphis, TN 38152 USA.
   [Bidelman, Gavin M.; Lewis, Gwyneth A.] Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.
RP Bidelman, GM (corresponding author), Univ Memphis, Sch Commun Sci & Disorders, 4055 North Pk Loop, Memphis, TN 38152 USA.
EM gmbdlman@memphis.edu
FU National Institute on Deafness and Other Communication Disorders of the
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [NIH/NIDCD
   R01DC016267]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R01DC016267, R01DC016267,
   R01DC016267, R01DC016267] Funding Source: NIH RePORTER
FX This work was supported by the National Institute on Deafness and Other
   Communication Disorders of the National Institutes of Health under award
   number NIH/NIDCD R01DC016267 (G.M.B.).
CR Adank P, 2012, NEUROPSYCHOLOGIA, V50, P77, DOI 10.1016/j.neuropsychologia.2011.10.024
   Alain C, 2018, HUM BRAIN MAPP, V39, P2695, DOI 10.1002/hbm.24031
   Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029
   Altmann CF, 2014, NEUROPSYCHOLOGIA, V64, P13, DOI 10.1016/j.neuropsychologia.2014.09.006
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   BEALE JM, 1995, COGNITION, V57, P217, DOI 10.1016/0010-0277(95)00669-X
   Bejjanki VR, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019812
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bernstein J., 2019, SPRINGER HDB AUDITOR, P33
   Bernstein LE, 2004, SPEECH COMMUN, V44, P5, DOI 10.1016/j.specom.2004.10.011
   BERNSTEIN LE, 2014, FRONT NEUROSCI, V8, P1, DOI DOI 10.3389/FNINS.2014.00386
   Bernstein LJ, 2014, J INT NEUROPSYCH SOC, V20, P380, DOI 10.1017/S1355617714000125
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Bidelman G. M., 2019, BIORXIV
   Bidelman G. M., 2019, EAR HEAR
   Bidelman GM, 2018, HEARING RES, V367, P149, DOI 10.1016/j.heares.2018.05.018
   Bidelman GM, 2017, HEARING RES, V351, P34, DOI 10.1016/j.heares.2017.05.008
   Bidelman GM, 2017, J NEUROSCI, V37, P3610, DOI 10.1523/JNEUROSCI.3700-16.2017
   Bidelman GM, 2017, EUR J NEUROSCI, V45, P690, DOI 10.1111/ejn.13526
   Bidelman GM, 2016, NEUROIMAGE, V124, P581, DOI 10.1016/j.neuroimage.2015.09.020
   Bidelman GM, 2015, NEUROIMAGE, V120, P191, DOI 10.1016/j.neuroimage.2015.06.087
   Bidelman GM, 2015, BRAIN LANG, V143, P32, DOI 10.1016/j.bandl.2015.02.002
   Bidelman GM, 2014, EUR J NEUROSCI, V40, P2662, DOI 10.1111/ejn.12627
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   Bizley JK, 2016, TRENDS NEUROSCI, V39, P74, DOI 10.1016/j.tins.2015.12.007
   Bizley JK, 2013, NAT REV NEUROSCI, V14, P693, DOI 10.1038/nrn3565
   BOOTHROYD A, 1988, J ACOUST SOC AM, V84, P101, DOI 10.1121/1.396976
   BRADLEY JV, 1958, J AM STAT ASSOC, V53, P525, DOI 10.2307/2281872
   BRAIDA LD, 1991, Q J EXP PSYCHOL-A, V43, P647, DOI 10.1080/14640749108400991
   Calcus A, 2016, J SPEECH LANG HEAR R, V59, P835, DOI 10.1044/2016_JSLHR-H-15-0076
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593
   Carlyon RP, 2001, J EXP PSYCHOL HUMAN, V27, P115, DOI 10.1037/0096-1523.27.1.115
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Colonius H, 2006, PSYCHOL REV, V113, P148, DOI 10.1037/0033-295X.113.1.148
   DENES PB, 1963, J ACOUST SOC AM, V35, P892, DOI 10.1121/1.1918622
   Deneve S, 2004, J PHYSIOLOGY-PARIS, V98, P249, DOI 10.1016/j.jphysparis.2004.03.011
   Desai S, 2008, J ACOUST SOC AM, V123, P428, DOI 10.1121/1.2816573
   Files BT, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00878
   Franklin A, 2008, P NATL ACAD SCI USA, V105, P18221, DOI 10.1073/pnas.0809952105
   Geschneider G. A, 1997, PSYCHOPHYSICS FUNDAM
   Getz LM, 2017, BRAIN SCI, V7, DOI 10.3390/brainsci7030032
   Gifford AM, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003715
   Golumbic EZ, 2013, J NEUROSCI, V33, P1417, DOI 10.1523/JNEUROSCI.3675-12.2013
   Grant KW, 2001, J ACOUST SOC AM, V109, P2272, DOI 10.1121/1.1362687
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   GREEN KP, 1989, PERCEPT PSYCHOPHYS, V45, P34, DOI 10.3758/BF03208030
   Hakvoort B, 2016, J SPEECH LANG HEAR R, V59, P1448, DOI 10.1044/2016_JSLHR-L-15-0306
   Harnad S., 1987, CATEGORICAL PERCEPTI, P1
   Harnad Stevan, 1987, CATEGORICAL PERCEPTI
   Helfer KS, 2009, J ACOUST SOC AM, V125, P447, DOI 10.1121/1.3035837
   Helie S, 2017, BRAIN COGNITION, V116, P63, DOI 10.1016/j.bandc.2017.06.001
   Kawahara H, 2008, INT CONF ACOUST SPEE, P3933, DOI 10.1109/ICASSP.2008.4518514
   Kayser C, 2008, CEREB CORTEX, V18, P1560, DOI 10.1093/cercor/bhm187
   KEWLEYPORT D, 1988, J ACOUST SOC AM, V83, P1133, DOI 10.1121/1.396058
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Kuhl P. K., 1988, PERCEPTUAL DEV INFAN, V20, P235
   LIBERMAN AM, 1989, SCIENCE, V243, P489, DOI 10.1126/science.2643163
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   MACLEOD A, 1987, British Journal of Audiology, V21, P131, DOI 10.3109/03005368709077786
   Mankel K, 2018, P NATL ACAD SCI USA, V115, P13129, DOI 10.1073/pnas.1811793115
   MASSARO DW, 1983, J EXP PSYCHOL HUMAN, V9, P753, DOI 10.1037/0096-1523.9.5.753
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Messaoud-Galusi S, 2011, J SPEECH LANG HEAR R, V54, P1682, DOI 10.1044/1092-4388(2011/09-0261)
   Miller J, 2003, COGNITIVE PSYCHOL, V46, P101, DOI 10.1016/S0010-0285(02)00517-0
   MILLER JL, 1984, PHONETICA, V41, P215, DOI 10.1159/000261728
   Moradi S, 2017, J SPEECH LANG HEAR R, V60, P2687, DOI 10.1044/2016_JSLHR-H-16-0160
   Myers MH, 2017, BMC OPHTHALMOL, V17, DOI 10.1186/s12886-017-0640-y
   Narinesingh C, 2015, INVEST OPHTH VIS SCI, V56, P2107, DOI 10.1167/iovs.14-15898
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   NOTHDURFT HC, 1991, VISION RES, V31, P1073, DOI 10.1016/0042-6989(91)90211-M
   O'Sullivan AE, 2017, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00679
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Peelle JE, 2015, CORTEX, V68, P169, DOI 10.1016/j.cortex.2015.03.006
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Perez-Gay F., 2018, ARXIV180504619
   Picou EM, 2016, EAR HEARING, V37, P1, DOI 10.1097/AUD.0000000000000222
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   PISONI DB, 1987, COGNITION, V25, P21, DOI 10.1016/0010-0277(87)90003-5
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   Prather JF, 2009, NAT NEUROSCI, V12, P221, DOI 10.1038/nn.2246
   Reetzke R, 2018, CURR BIOL, V28, P1419, DOI 10.1016/j.cub.2018.03.026
   Reetzke R, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168048
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   ROZSYPAL AJ, 1985, J MATH PSYCHOL, V29, P271, DOI 10.1016/0022-2496(85)90009-4
   Schorr EA, 2005, P NATL ACAD SCI USA, V102, P18748, DOI 10.1073/pnas.0508862102
   Schutt HH, 2016, VISION RES, V122, P105, DOI 10.1016/j.visres.2016.02.002
   Schwartz JL, 2004, COGNITION, V93, pB69, DOI 10.1016/j.cognition.2004.01.006
   Scott SK, 2013, HEARING RES, V303, P58, DOI 10.1016/j.heares.2013.05.001
   Shen Y, 2012, J ACOUST SOC AM, V132, P957, DOI 10.1121/1.4733540
   Smayda KE, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00682
   Strauss E, 2002, J INT NEUROPSYCH SOC, V8, P893, DOI 10.1017/S1355617702870035
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Vatikiotis-Bateson E, 1998, PERCEPT PSYCHOPHYS, V60, P926, DOI 10.3758/BF03211929
   WALDEN BE, 1977, J SPEECH HEAR RES, V20, P130, DOI 10.1044/jshr.2001.130
   WALDEN BE, 1990, J SPEECH HEAR RES, V33, P163, DOI 10.1044/jshr.3301.163
   Weinholtz C., 2016, J ACOUST SOC AM, V139, P2018, DOI [10.1121/1.4949950, DOI 10.1121/1.4949950]
   Xie ZL, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114439
   Xu YS, 2006, J ACOUST SOC AM, V120, P1063, DOI 10.1121/1.2213572
   Zoubrinetzky R, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151015
NR 103
TC 4
Z9 4
U1 1
U2 8
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JUL
PY 2019
VL 146
IS 1
BP 60
EP 70
DI 10.1121/1.5114822
PG 11
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA IN4EU
UT WOS:000478628800016
PM 31370660
OA Green Published
DA 2021-02-24
ER

PT J
AU Maslowski, M
   Meyer, AS
   Bosker, HR
AF Maslowski, Merel
   Meyer, Antje S.
   Bosker, Hans Rutger
TI Listeners normalize speech for contextual speech rate even without an
   explicit recognition task
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID WITHIN-SPEAKER VARIATION; BETWEEN-SPEAKER; REPETITION; PERCEPTION;
   FREQUENCY; WORDS; SOUND
AB Speech can be produced at different rates. Listeners take this rate variation into account by normalizing vowel duration for contextual speech rate: An ambiguous Dutch word /m?t/ is perceived as short /m?t/ when embedded in a slow context, but long /ma:t/ in a fast context. While some have argued that this rate normalization involves low-level automatic perceptual processing, there is also evidence that it arises at higher-level cognitive processing stages, such as decision making. Prior research on rate-dependent speech perception has only used explicit recognition tasks to investigate the phenomenon, involving both perceptual processing and decision making. This study tested whether speech rate normalization can be observed without explicit decision making, using a cross-modal repetition priming paradigm. Results show that a fast precursor sentence makes an embedded ambiguous prime (/m?t/) sound (implicitly) more /a:/-like, facilitating lexical access to the long target word "maat" in a (explicit) lexical decision task. This result suggests that rate normalization is automatic, taking place even in the absence of an explicit recognition task. Thus, rate normalization is placed within the realm of everyday spoken conversation, where explicit categorization of ambiguous sounds is rare. (C) 2019 Acoustical Society of America.
C1 [Maslowski, Merel; Meyer, Antje S.; Bosker, Hans Rutger] Max Planck Inst Psycholinguist, POB 310, NL-6500 AH Nijmegen, Netherlands.
RP Maslowski, M (corresponding author), Max Planck Inst Psycholinguist, POB 310, NL-6500 AH Nijmegen, Netherlands.
EM Merel.Maslowski@mpi.nl
RI Maslowski, Merel/AAK-1828-2020
CR Adank P, 2004, J ACOUST SOC AM, V116, P1729, DOI 10.1121/1.1779271
   Baese-Berk MM, 2019, ATTEN PERCEPT PSYCHO, V81, P571, DOI 10.3758/s13414-018-1626-4
   Baese-Berk MM, 2014, PSYCHOL SCI, V25, P1546, DOI 10.1177/0956797614533705
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Boersma P, 2015, PRAAT DOING PHONETIC
   Bosker H. R., 2015, 18 INT C PHON SCI 20
   Bosker HR, 2017, J EXP PSYCHOL LEARN, V43, P1225, DOI 10.1037/xlm0000381
   Bosker HR, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01063
   Bosker HR, 2017, J MEM LANG, V94, P166, DOI 10.1016/j.jml.2016.12.002
   Bosker HR, 2017, ATTEN PERCEPT PSYCHO, V79, P333, DOI 10.3758/s13414-016-1206-4
   DIEHL RL, 1980, PERCEPT PSYCHOPHYS, V27, P435, DOI 10.3758/BF03204461
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   FORBACH GB, 1974, MEM COGNITION, V2, P337, DOI 10.3758/BF03209005
   FORSTER KI, 1984, J EXP PSYCHOL LEARN, V10, P680, DOI 10.1037/0278-7393.10.4.680
   GORDON PC, 1988, PERCEPT PSYCHOPHYS, V43, P137, DOI 10.3758/BF03214191
   Heffner CC, 2015, J SPEECH LANG HEAR R, V58, P1341, DOI 10.1044/2015_JSLHR-H-14-0239
   Jacewicz E, 2010, J ACOUST SOC AM, V128, P839, DOI 10.1121/1.3459842
   Kaufeld G, 2020, J EXP PSYCHOL LEARN, V46, P549, DOI 10.1037/xlm0000744
   Keuleers E, 2010, BEHAV RES METHODS, V42, P643, DOI 10.3758/BRM.42.3.643
   Kosem A, 2018, CURR BIOL, V28, P2867, DOI 10.1016/j.cub.2018.07.023
   Marian V, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043230
   MARSLENWILSON W, 1989, J EXP PSYCHOL HUMAN, V15, P576, DOI 10.1037/0096-1523.15.3.576
   Martin AE, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00120
   Maslowski M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203571
   Maslowski M, 2019, J EXP PSYCHOL LEARN, V45, P128, DOI 10.1037/xlm0000579
   MILLER JL, 1983, J ACOUST SOC AM, V73, P1751, DOI 10.1121/1.389399
   MILLER JL, 1981, PHONETICA, V38, P159, DOI 10.1159/000260021
   MILLER JL, 1994, COGNITION, V50, P271, DOI 10.1016/0010-0277(94)90031-0
   Mitterer H, 2018, LAB PHONOL, V9, DOI 10.5334/labphon.66
   MONSELL S, 1992, J EXP PSYCHOL LEARN, V18, P452, DOI 10.1037/0278-7393.18.3.452
   Newman RS, 2009, J PHONETICS, V37, P46, DOI 10.1016/j.wocn.2008.09.001
   PICKETT JM, 1960, LANG SPEECH, V3, P11, DOI 10.1177/002383096000300103
   Pitt MA, 2016, ATTEN PERCEPT PSYCHO, V78, P334, DOI 10.3758/s13414-015-0981-7
   Quene H, 2008, J ACOUST SOC AM, V123, P1104, DOI 10.1121/1.2821762
   R Core Team, 2014, R LANG ENV STAT COMP
   Reinisch E, 2016, APPL PSYCHOLINGUIST, V37, P1397, DOI 10.1017/S0142716415000612
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   Reinisch E, 2011, J EXP PSYCHOL HUMAN, V37, P978, DOI 10.1037/a0021923
   SCARBOROUGH DL, 1977, J EXP PSYCHOL HUMAN, V3, P1, DOI 10.1037/0096-1523.3.1.1
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   Toscano JC, 2015, LANG COGN NEUROSCI, V30, P529, DOI 10.1080/23273798.2014.946427
   Toscano JC, 2012, ATTEN PERCEPT PSYCHO, V74, P1284, DOI 10.3758/s13414-012-0306-z
   Wade T, 2005, PERCEPT PSYCHOPHYS, V67, P939, DOI 10.3758/BF03193621
NR 44
TC 6
Z9 6
U1 0
U2 0
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JUL
PY 2019
VL 146
IS 1
BP 179
EP 188
DI 10.1121/1.5116004
PG 10
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA IN4EU
UT WOS:000478628800031
PM 31370593
OA Green Published
DA 2021-02-24
ER

PT J
AU O'Neill, ER
   Kreft, HA
   Oxenham, AJ
AF O'Neill, Erin R.
   Kreft, Heather A.
   Oxenham, Andrew J.
TI Cognitive factors contribute to speech perception in cochlear-implant
   users and age-matched normal-hearing listeners under vocoded conditions
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPECTRAL-RIPPLE RESOLUTION; SPOKEN WORD RECOGNITION; CROSS-MODAL
   PLASTICITY; INDIVIDUAL-DIFFERENCES; AUDITORY-CORTEX; WORKING-MEMORY;
   ELECTRODE; NOISE; PERFORMANCE; CONTEXT
AB This study examined the contribution of perceptual and cognitive factors to speech-perception abilities in cochlear-implant (CI) users. Thirty CI users were tested on word intelligibility in sentences with and without semantic context, presented in quiet and in noise. Performance was compared with measures of spectral-ripple detection and discrimination, thought to reflect peripheral processing, as well as with cognitive measures of working memory and non-verbal intelligence. Thirty age-matched and thirty younger normal-hearing (NH) adults also participated, listening via tone-excited vocoders, adjusted to produce mean performance for speech in noise comparable to that of the CI group. Results suggest that CI users may rely more heavily on semantic context than younger or older NH listeners, and that non-auditory working memory explains significant variance in the CI and age-matched NH groups. Between-subject variability in spectral-ripple detection thresholds was similar across groups, despite the spectral resolution for all NH listeners being limited by the same vocoder, whereas speech perception scores were more variable between CI users than between NH listeners. The results highlight the potential importance of central factors in explaining individual differences in CI users and question the extent to which standard measures of spectral resolution in CIs reflect purely peripheral processing. (C) 2019 Author(s).
C1 [O'Neill, Erin R.; Kreft, Heather A.; Oxenham, Andrew J.] Univ Minnesota, Dept Psychol, Elliott Hall,75 East River Pkwy, Minneapolis, MN 55455 USA.
RP O'Neill, ER (corresponding author), Univ Minnesota, Dept Psychol, Elliott Hall,75 East River Pkwy, Minneapolis, MN 55455 USA.
EM oneil554@umn.edu
OI Oxenham, Andrew/0000-0002-9365-1157
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R01 DC012262]; NSFNational Science
   Foundation (NSF) [NRT-UtB1734815]; NATIONAL INSTITUTE ON DEAFNESS AND
   OTHER COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC012262,
   R01DC012262, R01DC012262, R01DC012262] Funding Source: NIH RePORTER
FX This work was supported by NIH Grant No. R01 DC012262 and by NSF Grant
   No. NRT-UtB1734815. We thank the participants for their patience and
   dedication in the sound booth.
CR Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Amichetti NM, 2018, EAR HEARING, V39, P101, DOI 10.1097/AUD.0000000000000469
   Anderson CA, 2017, P NATL ACAD SCI USA, V114, P10256, DOI 10.1073/pnas.1704785114
   Anderson ES, 2012, J ACOUST SOC AM, V132, P3925, DOI 10.1121/1.4763999
   Anderson ES, 2011, J ACOUST SOC AM, V130, P364, DOI 10.1121/1.3589255
   [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   Araneda R, 2015, RESTOR NEUROL NEUROS, V33, P67, DOI 10.3233/RNN-140433
   Arehart KH, 2013, EAR HEARING, V34, P251, DOI 10.1097/AUD.0b013e318271aa5e
   Aronoff JM, 2013, J ACOUST SOC AM, V134, pEL217, DOI 10.1121/1.4813802
   Aschendorff A, 2007, EAR HEARING, V28, p75S, DOI 10.1097/AUD.0b013e318031542e
   Baskent D, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516670279
   Bhargava P, 2014, HEARING RES, V309, P113, DOI 10.1016/j.heares.2013.12.003
   Bingabr M, 2008, HEARING RES, V241, P73, DOI 10.1016/j.heares.2008.04.012
   Blamey P, 1996, Audiol Neurootol, V1, P293
   Blamey P, 2013, AUDIOL NEURO-OTOL, V18, P36, DOI 10.1159/000343189
   Carbonell KM, 2017, J ACOUST SOC AM, V142, pEL461, DOI 10.1121/1.5010148
   Choi JE, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-017-17350-w
   Claes AJ, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00580
   Conway ARA, 2005, PSYCHON B REV, V12, P769, DOI 10.3758/BF03196772
   Conway CM, 2014, J SPEECH LANG HEAR R, V57, P2174, DOI 10.1044/2014_JSLHR-L-13-0236
   Crew JD, 2012, J ACOUST SOC AM, V132, pEL429, DOI 10.1121/1.4758770
   Dingemanse JG, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216519838672
   Dorman MF, 1998, J ACOUST SOC AM, V104, P3583, DOI 10.1121/1.423940
   Drennan WR, 2014, EAR HEARING, V35, pE92, DOI 10.1097/AUD.0000000000000009
   Finley CC, 2008, OTOL NEUROTOL, V29, P920, DOI 10.1097/MAO.0b013e318184f492
   Freyman RL, 2013, J ACOUST SOC AM, V134, P1183, DOI 10.1121/1.4807824
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P180, DOI 10.1007/s10162-005-5061-6
   Fullgrabe C, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01268
   Gifford RH, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518771176
   Glick H, 2017, HEARING RES, V343, P191, DOI 10.1016/j.heares.2016.08.012
   Grange JA, 2017, J ACOUST SOC AM, V142, pEL484, DOI 10.1121/1.5009602
   Hast A, 2015, OTOL NEUROTOL, V36, P1638, DOI 10.1097/MAO.0000000000000883
   Helfer KS, 1997, J SPEECH LANG HEAR R, V40, P432, DOI 10.1044/jslhr.4002.432
   Henry BA, 2005, J ACOUST SOC AM, V118, P1111, DOI 10.1121/1.1944567
   Henry BA, 2003, J ACOUST SOC AM, V113, P2861, DOI 10.1121/1.1561900
   Heydebrand G, 2007, AUDIOL NEURO-OTOL, V12, P254, DOI 10.1159/000101473
   Holden LK, 2016, OTOL NEUROTOL, V37, P1662, DOI 10.1097/MAO.0000000000001241
   Holden LK, 2013, EAR HEARING, V34, P342, DOI 10.1097/AUD.0b013e3182741aa7
   Hua H, 2017, J SPEECH LANG HEAR R, V60, P2752, DOI 10.1044/2017_JSLHR-H-16-0276
   Humes LE, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00055
   Jeon EK, 2015, J ACOUST SOC AM, V138, P2350, DOI 10.1121/1.4932020
   Lash A, 2014, PSYCHOL AGING, V29, P907, DOI 10.1037/a0037829
   Lash A, 2013, EXP AGING RES, V39, P235, DOI 10.1080/0361073X.2013.779175
   Lee JS, 2003, J NUCL MED, V44, P1435
   Lenarz M, 2012, OTOLARYNG HEAD NECK, V147, P112, DOI 10.1177/0194599812438041
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Litvak LM, 2007, J ACOUST SOC AM, V122, P982, DOI 10.1121/1.2749413
   Livingston G, 2017, LANCET, V390, P2673, DOI 10.1016/S0140-6736(17)31363-6
   Lunner T, 2003, INT J AUDIOL, V42, pS49
   Mahmoud AF, 2014, OTOL NEUROTOL, V35, pE286, DOI 10.1097/MAO.0000000000000581
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X
   Mattys SL, 2005, J EXP PSYCHOL GEN, V134, P477, DOI 10.1037/0096-3445.134.4.477
   McGettigan C., 2008, J ACOUST SOC AM, V123, P3330, DOI [10.1121/1.2933839, DOI 10.1121/1.2933839]
   McKay CM, 2018, JARO-J ASSOC RES OTO, V19, P589, DOI 10.1007/s10162-018-0675-7
   Mesnildrey Q, 2015, HEARING RES, V319, P32, DOI 10.1016/j.heares.2014.11.001
   Moberly AC, 2017, LARYNGOSCOPE INVEST, V2, P254, DOI 10.1002/lio2.90
   Moradi S, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514545406
   Nechaev DI, 2019, TRENDS HEAR, V23, DOI 10.1177/2331216518824435
   Neher T, 2012, J ACOUST SOC AM, V131, P2561, DOI 10.1121/1.3689850
   O'Connell BP, 2016, LARYNSCOPE INVESTIG, V1, P169, DOI 10.1002/lio2.42
   O'Neill ER, 2019, JARO-J ASSOC RES OTO, V20, P151, DOI 10.1007/s10162-018-00702-2
   Oxenham AJ, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514553783
   Raven J, 1998, MANUAL RAVENS PROGR
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Rouger J, 2012, HUM BRAIN MAPP, V33, P1929, DOI 10.1002/hbm.21331
   Ruggles DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086980
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   Saoji AA, 2009, J ACOUST SOC AM, V126, P955, DOI 10.1121/1.3179670
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Signoret C, 2018, J EXP PSYCHOL HUMAN, V44, P277, DOI 10.1037/xhp0000442
   Skinner MW, 2007, ANN OTO RHINOL LARYN, V116, P2, DOI 10.1177/000348940711600401
   Spahr AJ, 2012, EAR HEARING, V33, P112, DOI 10.1097/AUD.0b013e31822c2549
   Strelnikov K, 2013, BRAIN, V136, P3682, DOI 10.1093/brain/awt274
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Thorndike E. L., 1945, TEACHERS WORD BOOK 3
   van der Marel KS, 2015, AUDIOL NEURO-OTOL, V20, P202, DOI 10.1159/000377616
   Wanna GB, 2014, LARYNGOSCOPE, V124, pS1, DOI 10.1002/lary.24728
   Winn MB, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516669723
   Won JH, 2007, JARO-J ASSOC RES OTO, V8, P384, DOI 10.1007/s10162-007-0085-8
   Won JH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140920
   Won JH, 2011, JARO-J ASSOC RES OTO, V12, P375, DOI 10.1007/s10162-011-0257-4
   Yeend I, 2019, EAR HEARING, V40, P458, DOI 10.1097/AUD.0000000000000640
   Zekveld AA, 2012, BRAIN LANG, V122, P103, DOI 10.1016/j.bandl.2012.05.006
   Zhou N, 2017, J ACOUST SOC AM, V141, pEL243, DOI 10.1121/1.4977235
   Zhou X, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518786850
NR 86
TC 5
Z9 5
U1 1
U2 2
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JUL
PY 2019
VL 146
IS 1
BP 195
EP 210
DI 10.1121/1.5116009
PG 16
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA IN4EU
UT WOS:000478628800033
PM 31370651
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU O'Brien, GE
   McCloy, DR
   Yeatman, JD
AF O'Brien, Gabrielle E.
   McCloy, Daniel R.
   Yeatman, Jason D.
TI Categorical phoneme labeling in children with dyslexia does not depend
   on stimulus duration
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID TEMPORAL PROCESSING DEFICITS; SPEECH-PERCEPTION DEFICITS; DEVELOPMENTAL
   DYSLEXIA; READING DISABILITIES; DISCRIMINATION; SENSITIVITY;
   IDENTIFICATION; SOUNDS; PERFORMANCE; READERS
AB It is established that individuals with dyslexia are less consistent at auditory phoneme categorization than typical readers. One hypothesis attributes these differences in phoneme labeling to differences in auditory cue integration over time, suggesting that the performance of individuals with dyslexia would improve with longer exposure to informative phonetic cues. Here, the relationship between phoneme labeling and reading ability was investigated while manipulating the duration of steady-state auditory information available in a consonant-vowel syllable. Children with dyslexia obtained no more benefit from longer cues than did children with typical reading skills, suggesting that poor task performance is not explained by deficits in temporal integration or temporal sampling. (C) 2019 Author(s).
C1 [O'Brien, Gabrielle E.; McCloy, Daniel R.; Yeatman, Jason D.] Univ Washington, Inst Learning & Brain Sci, Seattle, WA 98105 USA.
   [O'Brien, Gabrielle E.; McCloy, Daniel R.; Yeatman, Jason D.] Univ Washington, Dept Speech & Hearing Sci, Seattle, WA 98195 USA.
RP O'Brien, GE (corresponding author), Univ Washington, Inst Learning & Brain Sci, Seattle, WA 98105 USA.
EM eobrien3@uw.edu
FU National Institutes of Health (NIH) National Institute on Deafness and
   Other Communication Disorders (NIDCD)United States Department of Health
   & Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute on Deafness & Other Communication Disorders (NIDCD)
   [T32-DC005361]; National Science Foundation (NSF)/United States-Israel
   Behavioral and Cognitive Sciences (BCS) GrantNational Science Foundation
   (NSF) [1551330]; NIH National Institute of Child Health and Human
   DevelopmentUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R21HD092771];
   Microsoft; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH &
   HUMAN DEVELOPMENTUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [R21HD092771, R21HD092771] Funding Source: NIH RePORTER; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [T32DC005361, T32DC005361, T32DC005361, T32DC005361] Funding
   Source: NIH RePORTER
FX We thank Emily Kubota for recruiting, scheduling, and running
   participants. This work was funded by National Institutes of Health
   (NIH) National Institute on Deafness and Other Communication Disorders
   (NIDCD) Grant No. T32-DC005361 to the University of Washington, as well
   as National Science Foundation (NSF)/United States-Israel Behavioral and
   Cognitive Sciences (BCS) Grant No. 1551330, NIH National Institute of
   Child Health and Human Development Grant No. R21HD092771, and grants
   from Microsoft to J.D.Y.
CR Ahissar M, 2006, NAT NEUROSCI, V9, P1558, DOI 10.1038/nn1800
   Amitay S, 2002, BRAIN, V125, P2272, DOI 10.1093/brain/awf231
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Blomert L, 2004, BRAIN LANG, V89, P21, DOI 10.1016/S0093-934X(03)00305-5
   Boersma Paul, 2019, PRAAT DOING PHONETIC
   Boets B, 2011, RES DEV DISABIL, V32, P560, DOI 10.1016/j.ridd.2010.12.020
   Bogliotti C, 2008, J EXP CHILD PSYCHOL, V101, P137, DOI 10.1016/j.jecp.2008.03.006
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   BRANDT J, 1980, BRAIN LANG, V9, P324, DOI 10.1016/0093-934X(80)90152-2
   Breier JI, 2001, J EXP CHILD PSYCHOL, V80, P245, DOI 10.1006/jecp.2001.2630
   Calcus A, 2016, J SPEECH LANG HEAR R, V59, P835, DOI 10.1044/2016_JSLHR-H-15-0076
   Chiappe P, 2001, J EXP CHILD PSYCHOL, V80, P58, DOI 10.1006/jecp.2000.2624
   Cleary M., 2001, HDB PERCEPTION, P499
   Farmer ME, 1995, PSYCHON B REV, V2, P460, DOI 10.3758/BF03210983
   Gaab N, 2007, RESTOR NEUROL NEUROS, V25, P295
   Gabay Y, 2015, CORTEX, V73, P131, DOI 10.1016/j.cortex.2015.08.008
   Gabay Y, 2015, J SPEECH LANG HEAR R, V58, P934, DOI 10.1044/2015_JSLHR-L-14-0324
   Germano E, 2010, DEV NEUROPSYCHOL, V35, P475, DOI 10.1080/87565641.2010.494748
   GODFREY JJ, 1981, J EXP CHILD PSYCHOL, V32, P401, DOI 10.1016/0022-0965(81)90105-3
   Goswami U, 2002, P NATL ACAD SCI USA, V99, P10911, DOI 10.1073/pnas.122368599
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Hakvoort B, 2016, J SPEECH LANG HEAR R, V59, P1448, DOI 10.1044/2016_JSLHR-L-15-0306
   Halekoh U, 2014, J STAT SOFTW, V59, P1
   Hamalainen JA, 2013, J LEARN DISABIL-US, V46, P413, DOI 10.1177/0022219411436213
   Hazan V, 2009, J SPEECH LANG HEAR R, V52, P1510, DOI 10.1044/1092-4388(2009/08-0220)
   Ingelghem V, 2005, CHILDREN LEARNING DI, P47
   Johnson EP, 2011, J COMMUN DISORD, V44, P294, DOI 10.1016/j.jcomdis.2011.01.001
   Law JM, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00482
   Lehongre K, 2011, NEURON, V72, P1080, DOI 10.1016/j.neuron.2011.11.002
   Lorenzi C, 2000, J SPEECH LANG HEAR R, V43, P1367, DOI 10.1044/jslhr.4306.1367
   Manis FR, 1997, J EXP CHILD PSYCHOL, V66, P211, DOI 10.1006/jecp.1997.2383
   McMurray B, 2003, J PSYCHOLINGUIST RES, V32, P77, DOI 10.1023/A:1021937116271
   McMurray B, 2009, J MEM LANG, V60, P65, DOI 10.1016/j.jml.2008.07.002
   McQueen JM, 1999, J EXP PSYCHOL HUMAN, V25, P1363, DOI 10.1037/0096-1523.25.5.1363
   Menell P, 1999, J SPEECH LANG HEAR R, V42, P797, DOI 10.1044/jslhr.4204.797
   Merzenich MM, 1996, SCIENCE, V271, P77, DOI 10.1126/science.271.5245.77
   Messaoud-Galusi S, 2011, J SPEECH LANG HEAR R, V54, P1682, DOI 10.1044/1092-4388(2011/09-0261)
   Mody M, 1997, J EXP CHILD PSYCHOL, V64, P199, DOI 10.1006/jecp.1996.2343
   Nittrouer S, 1999, J SPEECH LANG HEAR R, V42, P925, DOI 10.1044/jslhr.4204.925
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   O'Brien GE, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34823-8
   Pennington BF, 2006, COGNITION, V101, P385, DOI 10.1016/j.cognition.2006.04.008
   PISONI DB, 1982, J EXP PSYCHOL HUMAN, V8, P297, DOI 10.1037/0096-1523.8.2.297
   PISONI DB, 1974, J ACOUST SOC AM, V55, P328, DOI 10.1121/1.1914506
   Poelmans H, 2011, RES DEV DISABIL, V32, P2810, DOI 10.1016/j.ridd.2011.05.025
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   Ramus F, 2012, COGN NEUROPSYCHOL, V29, P104, DOI 10.1080/02643294.2012.677420
   Richardson U, 2004, DYSLEXIA, V10, P215, DOI 10.1002/dys.276
   Rimrodt SL, 2010, CORTEX, V46, P739, DOI 10.1016/j.cortex.2009.07.008
   Rocheron I, 2002, NEUROREPORT, V13, P1683, DOI 10.1097/00001756-200209160-00023
   Schrank F. A., 2014, WOODCOCK JOHNSON 4 T
   Schutt H., 2015, J VISION, V15, P474, DOI [10.1167/15.12.474, DOI 10.1167/15.12.474]
   Serniclaes W, 2001, J SPEECH LANG HEAR R, V44, P384, DOI 10.1044/1092-4388(2001/032)
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   Shaywitz BA, 2002, BIOL PSYCHIAT, V52, P101, DOI 10.1016/S0006-3223(02)01365-3
   SHAYWITZ SE, 1992, NEW ENGL J MED, V326, P145, DOI 10.1056/NEJM199201163260301
   STEFFENS ML, 1992, J SPEECH HEAR RES, V35, P192, DOI 10.1044/jshr.3501.192
   Stevenson J, 2005, J CHILD PSYCHOL PSYC, V46, P1081, DOI 10.1111/j.1469-7610.2005.01533.x
   Stuart GW, 2006, COGN NEUROPSYCHOL, V23, P1215, DOI 10.1080/02643290600814624
   Talcott JB, 2000, NEUROPSYCHOLOGIA, V38, P935, DOI 10.1016/S0028-3932(00)00020-8
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Tallal P, 1996, SCIENCE, V271, P81, DOI 10.1126/science.271.5245.81
   Torgesen J. K., 2011, TOWRE 2 TEST WORD RE
   Toscano JC, 2010, PSYCHOL SCI, V21, P1532, DOI 10.1177/0956797610384142
   Treutwein B, 1999, PERCEPT PSYCHOPHYS, V61, P87, DOI 10.3758/BF03211951
   van Beinum FJ, 2005, SPEECH COMMUN, V47, P124, DOI 10.1016/j.specom.2005.04.003
   Vandermosten M, 2019, SCI STUD READ, V23, P116, DOI 10.1080/10888438.2018.1473404
   Vandermosten M, 2011, RES DEV DISABIL, V32, P593, DOI 10.1016/j.ridd.2010.12.015
   Vandermosten M, 2010, P NATL ACAD SCI USA, V107, P10389, DOI 10.1073/pnas.0912858107
   Wechsler D., 2011, WECHSLER ABBREVIATED
   Witton C, 2002, J COGNITIVE NEUROSCI, V14, P866, DOI 10.1162/089892902760191090
   Zhang YJ, 2012, J CHILD PSYCHOL PSYC, V53, P874, DOI 10.1111/j.1469-7610.2012.02528.x
   Ziegler JC, 2008, TRENDS COGN SCI, V12, P244, DOI 10.1016/j.tics.2008.04.001
NR 73
TC 2
Z9 2
U1 0
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JUL
PY 2019
VL 146
IS 1
BP 245
EP 255
DI 10.1121/1.5116568
PG 11
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA IN4EU
UT WOS:000478628800037
PM 31370631
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Cooke, M
   Lecumberri, MLG
AF Cooke, Martin
   Garcia Lecumberri, Maria Luisa
TI Non-native consonant acquisition in noise: Effects of exposure/test
   similarity
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID ADVERSE CONDITIONS; SPEECH-PERCEPTION; BACKGROUND-NOISE; RECOGNITION;
   LISTENERS; TALKER; LANGUAGE; MEMORY; WORDS
AB When faced with speech in noise, do listeners rely on robust cues or can they make use of joint speech-plus-noise patterns based on prior experience? Recent studies have suggested that listeners are better able to identify words in noise if they experienced the same word-in-noise tokens in an earlier exposure phase. The current study examines the role of token similarity in exposure and test conditions. In three experiments, Spanish learners of English were exposed to intervocalic consonants during an extensive training phase, bracketed by pre- and post-tests. Distinct cohorts experienced tokens that were either matched or mismatched across test and training phases in one or both of two factors: signal-to-noise ratio (SNR) and talker. Cohorts with fully matching test-training exposure were no better at identifying consonants at the post-test phase than those trained in partially or fully mismatched conditions. Indeed, at more adverse test SNRs, training at more favourable SNRs was beneficial. These findings argue against the use of joint speech-plus-noise representations at the segmental level and instead suggest that listeners are able to extract useful acoustic-phonetic information across a range of exposure conditions. (C) 2019 Acoustical Society of America.
C1 [Cooke, Martin] Ikerbasque, Basque Sci Fdn, Maria Diaz de Haro 3,6, Bilbao 48013, Spain.
   [Garcia Lecumberri, Maria Luisa] Univ Basque Country, Language & Speech Lab, Vitoria 01006, Spain.
RP Cooke, M (corresponding author), Ikerbasque, Basque Sci Fdn, Maria Diaz de Haro 3,6, Bilbao 48013, Spain.
EM m.cooke@ikerbasque.org
RI Garcia Lecumberri, Maria Luisa/P-3983-2014
OI Garcia Lecumberri, Maria Luisa/0000-0002-8651-7558
FU Basque Government Consolidados grantBasque Government
FX This study was carried with funding from the Basque Government
   Consolidados grant to the Language and Speech Laboratory at the
   University of the Basque Country.
CR Barker J, 2007, SPEECH COMMUN, V49, P402, DOI 10.1016/j.specom.2006.11.003
   Barker J, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P504, DOI 10.1109/ASRU.2015.7404837
   Bent T, 2010, J ACOUST SOC AM, V128, P3142, DOI 10.1121/1.3493428
   Best C., 1995, SPEECH PERCEPTION LI, P171
   BLACK JW, 1962, J SPEECH HEAR RES, V5, P70, DOI 10.1044/jshr.0501.70
   Bradlow AR, 1999, J ACOUST SOC AM, V106, P2074, DOI 10.1121/1.427952
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   Clopper CG, 2004, LANG SPEECH, V47, P207, DOI 10.1177/00238309040470030101
   Cooke M, 2008, J ACOUST SOC AM, V123, P414, DOI 10.1121/1.2804952
   Cooke M, 2018, J ACOUST SOC AM, V143, P2602, DOI 10.1121/1.5035080
   Cooke M, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1765
   Cooper A, 2017, LAB PHONOL, V8, DOI 10.5334/labphon.99
   Cooper A, 2015, ATTEN PERCEPT PSYCHO, V77, P1342, DOI 10.3758/s13414-015-0855-z
   Creel SC, 2012, LANG COGNITIVE PROC, V27, P1021, DOI 10.1080/01690965.2011.610597
   Cutler A, 2004, J ACOUST SOC AM, V116, P3668, DOI 10.1121/1.1810292
   Cutler A, 2012, NATIVE LISTENING LAN
   Drozdova P, 2016, BILING-LANG COGN, V19, P914, DOI 10.1017/S136672891600002X
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Gonzalez CR, 2015, NEURAL COMPUT, V27, P365, DOI 10.1162/NECO_a_00697
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   HINTZMAN DL, 1988, PSYCHOL REV, V95, P528, DOI 10.1037/0033-295X.95.4.528
   Jesse A., 2007, P 16 INT C PHON SCI, P1921
   Jin SH, 2012, J ACOUST SOC AM, V132, pEL391, DOI 10.1121/1.4757730
   Lee CY, 2010, SPEECH COMMUN, V52, P900, DOI 10.1016/j.specom.2010.01.004
   LOGAN JS, 1991, J ACOUST SOC AM, V89, P874, DOI 10.1121/1.1894649
   Lovitt A, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P2154
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Meador D, 2000, BILING-LANG COGN, V3, P55, DOI DOI 10.1017/S1366728900000134
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   Pisoni DB, 2007, OXFORD HDB PSYCHOLIN, P3
   Pufahl A, 2014, COGNITIVE PSYCHOL, V70, P1, DOI 10.1016/j.cogpsych.2014.01.001
   Rogers CL, 2006, APPL PSYCHOLINGUIST, V27, P465, DOI 10.1017/S014271640606036X
   SCHACTER DL, 1992, J EXP PSYCHOL LEARN, V18, P915, DOI 10.1037/0278-7393.18.5.915
   Scharenborg O, 2019, SPEECH COMMUN, V108, P53, DOI 10.1016/j.specom.2019.03.001
   Scharenborg O, 2018, J EXP PSYCHOL LEARN, V44, P233, DOI 10.1037/xlm0000441
   Sivasankaran S, 2017, INT CONF ACOUST SPEE, P4885, DOI 10.1109/ICASSP.2017.7953085
   Strori D, 2018, ATTEN PERCEPT PSYCHO, V80, P222, DOI 10.3758/s13414-017-1425-3
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Tian Y, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1151
   Wright Richard, 2004, PHONETICALLY BASED P, P34, DOI DOI 10.1017/CBO9780511486401.002
NR 42
TC 0
Z9 0
U1 0
U2 1
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JUL
PY 2019
VL 146
IS 1
BP 297
EP 306
DI 10.1121/1.5116575
PG 10
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA IN4EU
UT WOS:000478628800042
PM 31370635
DA 2021-02-24
ER

PT J
AU Goehring, T
   Keshavarzi, M
   Carlyon, RP
   Moore, BCJ
AF Goehring, Tobias
   Keshavarzi, Mahmoud
   Carlyon, Robert P.
   Moore, Brian C. J.
TI Using recurrent neural networks to improve the perception of speech in
   non-stationary noise by people with cochlear implants
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID HEARING-IMPAIRED LISTENERS; INTELLIGIBILITY; RECOGNITION; REDUCTION;
   ALGORITHM; SEGREGATION; QUALITY; ENHANCEMENT; SUPPRESSION; ENVIRONMENT
AB Speech-in-noise perception is a major problem for users of cochlear implants (CIs), especially with non-stationary background noise. Noise-reduction algorithms have produced benefits but relied on a priori information about the target speaker and/or background noise. A recurrent neural network (RNN) algorithm was developed for enhancing speech in non-stationary noise and its benefits were evaluated for speech perception, using both objective measures and experiments with CI simulations and CI users. The RNN was trained using speech from many talkers mixed with multi-talker or traffic noise recordings. Its performance was evaluated using speech from an unseen talker mixed with different noise recordings of the same class, either babble or traffic noise. Objective measures indicated benefits of using a recurrent over a feed-forward architecture, and predicted better speech intelligibility with than without the processing. The experimental results showed significantly improved intelligibility of speech in babble noise but not in traffic noise. CI subjects rated the processed stimuli as significantly better in terms of speech distortions, noise intrusiveness, and overall quality than unprocessed stimuli for both babble and traffic noise. These results extend previous findings for CI users to mostly unseen acoustic conditions with non-stationary noise. (C) 2019 Author(s).
C1 [Goehring, Tobias; Carlyon, Robert P.] Univ Cambridge, MRC, Cognit & Brain Sci Unit, 15 Chaucer Rd, Cambridge CB2 7EF, England.
   [Keshavarzi, Mahmoud; Moore, Brian C. J.] Univ Cambridge, Dept Expt Psychol, Downing St, Cambridge CB2 3EB, England.
RP Goehring, T (corresponding author), Univ Cambridge, MRC, Cognit & Brain Sci Unit, 15 Chaucer Rd, Cambridge CB2 7EF, England.
EM Tobias.Goehring@mrc-cbu.cam.ac.uk
RI Goehring, Tobias/I-5363-2019
OI Goehring, Tobias/0000-0002-9038-3310; Carlyon,
   Robert/0000-0002-6166-501X
FU Action on Hearing Loss (UK) [82]; Action on Hearing Loss (Flexi) [92];
   Engineering and Physical Sciences Research Council (EPSRC) (UK)UK
   Research & Innovation (UKRI)Engineering & Physical Sciences Research
   Council (EPSRC) [RG78536]
FX We thank the subjects who took part in this study. This work was funded
   by Action on Hearing Loss (UK, Grant No. 82 and Flexi Grant No. 92).
   Author B.C.J.M. was supported by the Engineering and Physical Sciences
   Research Council (EPSRC) (UK, Grant No. RG78536). We also thank two
   reviewers for very helpful comments.
CR Abadi M., 2016, ARXIV1603004467
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   Bentsen T, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196924
   BOLL SF, 1979, IEEE T ACOUST SPEECH, V27, P113, DOI 10.1109/TASSP.1979.1163209
   Bolner F, 2016, INT CONF ACOUST SPEE, P6520, DOI 10.1109/ICASSP.2016.7472933
   Boyle PJ, 2013, EAR HEARING, V34, P203, DOI 10.1097/AUD.0b013e31826a8e82
   Bramslow L, 2018, J ACOUST SOC AM, V144, P172, DOI 10.1121/1.5045322
   Busch T, 2017, J SPEECH LANG HEAR R, V60, P1362, DOI 10.1044/2016_JSLHR-H-16-0162
   Carlyon RP, 2007, JARO-J ASSOC RES OTO, V8, P119, DOI 10.1007/s10162-006-0068-1
   Chen JT, 2017, J ACOUST SOC AM, V141, P4705, DOI 10.1121/1.4986931
   Chen JT, 2016, J ACOUST SOC AM, V139, P2604, DOI 10.1121/1.4948445
   Chen JT, 2014, IEEE-ACM T AUDIO SPE, V22, P1993, DOI 10.1109/TASLP.2014.2359159
   Choi JS, 2016, JAMA OTOLARYNGOL, V142, P652, DOI 10.1001/jamaoto.2016.0700
   Croghan NBH, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518787276
   Cullington HE, 2008, J ACOUST SOC AM, V123, P450, DOI 10.1121/1.2805617
   Dawson PW, 2011, EAR HEARING, V32, P382, DOI 10.1097/AUD.0b013e318201c200
   Fletcher MD, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518797838
   Fonseca E., 2017, P 18 ISMIR C 2017 OC, P486
   Fu QJ, 1998, J ACOUST SOC AM, V104, P3586, DOI 10.1121/1.423941
   Garofolo J.S., 1993, 93 NASA STI REC
   GLASBERG BR, 1990, HEARING RES, V47, P103, DOI 10.1016/0378-5955(90)90170-T
   Goehring T, 2018, INT J AUDIOL, V57, P61, DOI 10.1080/14992027.2017.1367848
   Goehring T, 2017, HEARING RES, V344, P183, DOI 10.1016/j.heares.2016.11.012
   Grange JA, 2017, J ACOUST SOC AM, V142, pEL484, DOI 10.1121/1.5009602
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Healy EW, 2019, J ACOUST SOC AM, V145, P1378, DOI 10.1121/1.5093547
   Healy EW, 2015, J ACOUST SOC AM, V138, P1660, DOI 10.1121/1.4929493
   Healy EW, 2013, J ACOUST SOC AM, V134, P3029, DOI 10.1121/1.4820893
   Hersbach AA, 2012, EAR HEARING, V33, pE13, DOI 10.1097/AUD.0b013e31824b9e21
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Holube I, 1996, J ACOUST SOC AM, V100, P1703, DOI 10.1121/1.417354
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   Hu Y, 2010, J ACOUST SOC AM, V127, P3689, DOI 10.1121/1.3365256
   Huber M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00953
   Keshavarzi M, 2019, J ACOUST SOC AM, V145, P1493, DOI 10.1121/1.5094765
   Keshavarzi M, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518770964
   Kim G, 2009, J ACOUST SOC AM, V126, P1486, DOI 10.1121/1.3184603
   Kingma Diederik P, 2014, ARXIV 1412 6980
   Kolbaek M, 2017, IEEE-ACM T AUDIO SPE, V25, P1901, DOI 10.1109/TASLP.2017.2726762
   Lai YH, 2018, EAR HEARING, V39, P795, DOI 10.1097/AUD.0000000000000537
   Launer S, 2016, SPRINGER HANDB AUDIT, V56, P93, DOI 10.1007/978-3-319-33036-5_4
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Loizou PC, 2005, J ACOUST SOC AM, V118, P2791, DOI 10.1121/1.2065847
   MACLEOD A, 1990, British Journal of Audiology, V24, P29, DOI 10.3109/03005369009077840
   Madhu N, 2013, IEEE T AUDIO SPEECH, V21, P61, DOI 10.1109/TASL.2012.2213248
   Mauger SJ, 2012, J ACOUST SOC AM, V131, P327, DOI 10.1121/1.3665990
   May T, 2014, J ACOUST SOC AM, V136, pEL398, DOI 10.1121/1.4901133
   Monaghan JJM, 2017, J ACOUST SOC AM, V141, P1985, DOI 10.1121/1.4977197
   Moore BCJ, 2005, SPR HDB AUD, V24, P234
   Oxenham AJ, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514553783
   PATTERSON RD, 1995, J ACOUST SOC AM, V98, P1890, DOI 10.1121/1.414456
   Scalart P., 1996, IEEE INT C AC SPEECH
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Steiger M, 2013, WSCG 2013, FULL PAPERS PROCEEDINGS, P1
   Stickney GS, 2004, J ACOUST SOC AM, V116, P1081, DOI 10.1121/1.1772399
   Stone MA, 1999, EAR HEARING, V20, P182, DOI 10.1097/00003446-199906000-00002
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881
   Tang Y., 2016, ARXIV161204251
   Veaux C., 2016, CSTR VCTK CORPUS ENG
   Weninger F, 2015, LECT NOTES COMPUT SC, V9237, P91, DOI 10.1007/978-3-319-22482-4_11
   Wouters J, 2001, EAR HEARING, V22, P420, DOI 10.1097/00003446-200110000-00006
NR 63
TC 8
Z9 9
U1 0
U2 2
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JUL
PY 2019
VL 146
IS 1
BP 705
EP 718
DI 10.1121/1.5119226
PG 14
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA IN4EU
UT WOS:000478628800074
PM 31370586
OA Other Gold, Green Published, Green Accepted
DA 2021-02-24
ER

PT J
AU Schertz, J
   Chow, CTY
   Kamal, NSN
AF Schertz, Jessamyn
   Chow, Crystal Tze Ying
   Kamal, Nur Sakinah Nor
TI The influence of tone language experience and speech style on the use of
   intonation in language discrimination
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID LINGUISTIC EXPERIENCE; RHYTHM CLASS; VARIABILITY; PERCEPTION; NEWBORNS;
   PITCH; READ
AB This work tests whether listeners' use of suprasegmental information in speech perception is modulated by language background and speech style. Native Mandarin (tone language) and Malay (non-tone language) listeners completed an AX language discrimination task with four levels of signal degradation and two speech styles. Listeners in both groups showed more benefit from pitch information in read than in spontaneous speech. Mandarin listeners showed a greater benefit than Malay listeners from the inclusion of f0 information in a segmentally degraded signal, suggesting that experience with lexical tone may extend to increased attention and/or sensitivity to phrase-level pitch contours. (C) 2019 Acoustical Society of America
C1 [Schertz, Jessamyn; Chow, Crystal Tze Ying; Kamal, Nur Sakinah Nor] Univ Toronto Mississauga, Dept Language Studies, Mississauga, ON L5L 1C6, Canada.
   [Schertz, Jessamyn] Univ Toronto, Dept Linguist, Toronto, ON M5S 3G3, Canada.
RP Schertz, J (corresponding author), Univ Toronto Mississauga, Dept Language Studies, Mississauga, ON L5L 1C6, Canada.
EM jessamyn.schertz@utoronto.ca; crystal.chow@mail.utoronto.ca;
   nur.norkamal@mail.utoronto.ca
FU University of Toronto Excellence AwardUniversity of Toronto; SSHRCSocial
   Sciences and Humanities Research Council of Canada (SSHRC)
   [430-2017-00011]
FX This research was supported by a University of Toronto Excellence Award
   to C.T.Y.C. and by SSHRC Grant No. 430-2017-00011 to J.S. We would like
   to thank Hui Zhong Zhu for help with experiment preparation.
CR Arvaniti A, 2013, LAB PHONOL, V4, P7, DOI 10.1515/lp-2013-0002
   Asaridou SS, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00321
   BATES D, 2015, CONVERGENCE, V12, P1
   Bent T, 2006, J EXP PSYCHOL HUMAN, V32, P97, DOI 10.1037/0096-1523.32.1.97
   Bidelman GM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0060676
   Boersma P., 2014, PRAAT DOING PHONETIC
   Chandrasekaran B, 2010, J ACOUST SOC AM, V128, P456, DOI 10.1121/1.3445785
   Chang YHS, 2017, J ACOUST SOC AM, V141, pEL120, DOI 10.1121/1.4976037
   Chen A, 2016, LANG COGN NEUROSCI, V31, P751, DOI 10.1080/23273798.2016.1156715
   Clynes A, 2011, J INT PHON ASSOC, V41, P259, DOI 10.1017/S002510031100017X
   De Rosario-Martinez H, 2015, PACKAGE PHIA V 0 2 1
   de Ruiter LE, 2015, J PHONETICS, V48, P29, DOI 10.1016/j.wocn.2014.10.008
   Dellwo V, 2015, J PHONETICS, V48, P13, DOI 10.1016/j.wocn.2014.10.011
   Frota S, 2002, P SPEECH PROS AIX EN, P319
   Grabe E, 2002, PHONOL PHONET, V4-1, P515
   Kraus N, 2007, CURR DIR PSYCHOL SCI, V16, P105, DOI 10.1111/j.1467-8721.2007.00485.x
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001
   Molnar M, 2014, INFANCY, V19, P326, DOI 10.1111/infa.12041
   Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037/0096-1523.24.3.756
   R Core Team, 2016, R LANG ENV STAT COMP
   Ramus F, 1999, J ACOUST SOC AM, V105, P512, DOI 10.1121/1.424522
   Ramus F, 2000, SCIENCE, V288, P349, DOI 10.1126/science.288.5464.349
   Schertz J, 2016, ATTEN PERCEPT PSYCHO, V78, P355, DOI 10.3758/s13414-015-0987-1
   Smiljanic R, 2008, J ACOUST SOC AM, V124, P3171, DOI 10.1121/1.2990712
   Stevens CJ, 2013, PSYCHOL MUSIC, V41, P59, DOI 10.1177/0305735611415749
   UCLA: Statistical Consulting Group, 2018, R LIB CONTR COD SYST
   Vicenik C, 2013, J PHONETICS, V41, P297, DOI 10.1016/j.wocn.2013.03.003
   Wagner P, 2015, J PHONETICS, V48, P1, DOI 10.1016/j.wocn.2014.11.001
   Winn MB, 2013, J SPEECH LANG HEAR R, V56, P1097, DOI 10.1044/1092-4388(2012/12-0086)
NR 29
TC 0
Z9 0
U1 1
U2 3
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JUL
PY 2019
VL 146
IS 1
BP EL58
EP EL64
DI 10.1121/1.5117167
PG 7
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA IN4EU
UT WOS:000478628800015
PM 31370592
OA Bronze
DA 2021-02-24
ER

PT J
AU Sanker, C
AF Sanker, Chelsea
TI Influence of coda stop features on perceived vowel duration
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Voicing effect; Vowel duration; Speech perception
ID VOICE ONSET TIME; INCOMPLETE NEUTRALIZATION; FUNDAMENTAL-FREQUENCY;
   SEGMENTAL FOCUS; LEXICAL FOCUS; PERCEPTION; CONTRAST; ENGLISH; PATTERNS;
   STRESS
AB Four experiments tested what cues contribute to English speakers' perception of vowel duration. Listeners categorized the duration of vowels as 'long' or 'short' for stimuli produced with voiced, voiceless, breathy voiced, or voiceless aspirated stop codas. Listeners demonstrated a strong ability to perceive vowel duration, though perception was continuous rather than categorical. There were several interacting factors influencing perceived vowel duration, based on expectations set by the presence of particular codas and also acoustic effects of the coda on the vowel. When the coda was removed, vowels that had been produced before voiced codas were perceived as longer than vowels produced before voiceless codas, though they exhibited the opposite effect when codas were present. Vowels were also perceived as longer when produced before breathy voiced stops, regardless of whether or not the stop was present. The steeper f0 falls associated with voiced codas within these stimuli likely contributed to the longer perceived duration of vowels from this environment; manipulating f0 contours eliminated effects of the original coda on perceived vowel duration. The effects of the production environment on perceived vowel duration suggest a possible perceptual pathway for the voicing effect on vowel duration. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Sanker, Chelsea] Brown Univ, Providence, RI 02912 USA.
RP Sanker, C (corresponding author), Brown Univ, Providence, RI 02912 USA.
EM chelsea_sanker@brown.edu
CR ABEL SM, 1972, J ACOUST SOC AM, V51, P1219, DOI 10.1121/1.1912963
   ABRAMSON AS, 1990, J PHONETICS, V18, P79, DOI 10.1016/S0095-4470(19)30395-X
   Al-Tamimi J, 2018, J PHONETICS, V71, P306, DOI 10.1016/j.wocn.2018.09.010
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Benki JR, 2001, J PHONETICS, V29, P1, DOI 10.1006/jpho.2000.0128
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Chang CB, 2018, J PHONETICS, V68, P85, DOI 10.1016/j.wocn.2018.03.003
   CHEN M, 1970, PHONETICA, V22, P129, DOI 10.1159/000259312
   Cho T, 2019, J PHONETICS, V72, P52, DOI 10.1016/j.wocn.2018.11.002
   Choi J, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00624
   Chong AJ, 2018, LAB PHONOL, V9, DOI 10.5334/labphon.70
   Coleman J, 2003, J PHONETICS, V31, P351, DOI 10.1016/j.wocn.2003.10.001
   COOPER WE, 1981, PHONETICA, V38, P106, DOI 10.1159/000260017
   Cumming R, 2011, J PHONETICS, V39, P375, DOI 10.1016/j.wocn.2011.01.004
   Davidson L, 2011, J EXP PSYCHOL HUMAN, V37, P270, DOI 10.1037/a0020988
   de Jong K, 2004, J PHONETICS, V32, P493, DOI 10.1016/j.wocn.2004.05.002
   de Jong K, 2002, J PHONETICS, V30, P53, DOI 10.1006/jpho.2001.0151
   DEJONG K, 1991, PHONETICA, V48, P1, DOI 10.1159/000261868
   Durvasula K., 2014, P MTGS ACOUST, V18
   FOURAKIS M, 1984, PHONETICA, V41, P140, DOI 10.1159/000261720
   FOWLER CA, 1992, J PHONETICS, V20, P143, DOI 10.1016/S0095-4470(19)30244-X
   GRUENENFELDER TM, 1980, PERCEPT PSYCHOPHYS, V28, P514, DOI 10.3758/BF03198819
   Gussenhoven C, 2004, SPEECH LANGUAGE STUD, P65
   Gussenhoven C, 2013, INTERSPEECH, P1364
   Hadding-Koch K., 1964, STUD LINGUISTICA, V18, P94, DOI DOI 10.1111/J.1467-9582.1964.TB00451.X
   Halle M., 1967, 85 MIT RES LAB EL, V85
   HOMBERT JM, 1979, LANGUAGE, V55, P37, DOI 10.2307/412518
   Hussein L., 1994, THESIS
   Javkin H. R., 1976, REPORT PHONOLOGY LAB, V1, P78, DOI 10.1121/1.2002209
   Keating P, 1985, UCLA WORKING PAPERS, V60, P20
   Keating P. A., 1979, THESIS
   KLUENDER KR, 1988, J PHONETICS, V16, P153, DOI 10.1016/S0095-4470(19)30480-2
   KOHLER KJ, 1985, J ACOUST SOC AM, V78, P21, DOI 10.1121/1.392562
   KOHLER KJ, 1982, PHONETICA, V39, P199, DOI 10.1159/000261663
   Kong EJ, 2012, J PHONETICS, V40, P725, DOI 10.1016/j.wocn.2012.07.002
   Kuznetsova A, 2015, PROC CVPR IEEE, P28, DOI 10.1109/CVPR.2015.7298597
   LAEUFER C, 1992, J PHONETICS, V20, P411, DOI 10.1016/S0095-4470(19)30648-5
   Lehiste I., 1976, J PHONETICS, V4, P113
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   Machac P, 2007, P 16 C PHON SCI SAAR, P537
   Maddieson I, 1976, UCLA WORKING PAPERS, V31, P47
   Maddieson I, 1977, UCLA WORKING PAPERS, V38, P82
   MITLEB FM, 1984, J PHONETICS, V12, P23, DOI 10.1016/S0095-4470(19)30847-2
   MOHR B, 1971, PHONETICA, V23, P65, DOI 10.1159/000259332
   Moreton E, 2004, J PHONETICS, V32, P1, DOI 10.1016/S0095-4470(03)00004-4
   Nowak P. M., 2006, THESIS
   Ohala M., 1992, P INT C SPOK LANG PR, P831
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Penney J, 2018, J PHONETICS, V66, P161, DOI 10.1016/j.wocn.2017.10.001
   PETERSON GE, 1960, J ACOUST SOC AM, V32, P693, DOI 10.1121/1.1908183
   PORT RF, 1980, PHONETICA, V37, P235, DOI 10.1159/000259994
   Pycha A, 2016, J PHONETICS, V56, P15, DOI 10.1016/j.wocn.2016.01.002
   R Core Team, 2017, R LANG ENV STAT COMP
   RAMMSAYER TH, 1991, PERCEPT PSYCHOPHYS, V50, P565, DOI 10.3758/BF03207541
   RAPHAEL LJ, 1972, J ACOUST SOC AM, V51, P1296, DOI 10.1121/1.1912974
   Sanker C, 2018, PAPERS HIST PHONOLOG, V3, P180, DOI DOI 10.2218/PIHPH.3.2018.2898
   Seyfarth S, 2018, J PHONETICS, V71, P425, DOI 10.1016/j.wocn.2018.09.001
   SHARF DJ, 1964, LANG SPEECH, V7, P89, DOI 10.1177/002383096400700204
   Stevens K. N., 1974, J ACOUST SOC AM, V82, P847
   Summers W. V., 1987, J ACOUST SOC AM, V84, P485
   VANDOMMELEN WA, 1993, J PHONETICS, V21, P367, DOI 10.1016/S0095-4470(19)30226-8
   VANSUMMERS W, 1987, J ACOUST SOC AM, V82, P847, DOI 10.1121/1.395284
   Warner N, 2004, J PHONETICS, V32, P251, DOI 10.1016/S0095-4470(03)00032-9
   Yu Alan C. L., 2010, LAB PHONOLOGY, V10, P151, DOI DOI 10.1515/9783110224917.2.151
NR 64
TC 3
Z9 3
U1 1
U2 3
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD JUL
PY 2019
VL 75
BP 43
EP 56
DI 10.1016/j.wocn.2019.04.003
PG 14
WC Linguistics; Language & Linguistics
SC Linguistics
GA IM1ZE
UT WOS:000477789600003
DA 2021-02-24
ER

PT J
AU Dilley, L
   Gamache, J
   Wang, YY
   Houston, DM
   Bergeson, TR
AF Dilley, Laura
   Gamache, Jessica
   Wang, Yuanyuan
   Houston, Derek M.
   Bergeson, Tonya R.
TI Statistical distributions of consonant variants in infant-directed
   speech: Evidence that /t/ may be exceptional
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Infant-directed speech; phonetic variants
ID REGRESSIVE PLACE ASSIMILATION; SPOKEN WORD RECOGNITION; PHONOLOGICAL
   ABSTRACTION; ACOUSTIC CHARACTERISTICS; MOTHERS SPEECH; MATERNAL SPEECH;
   LEXICAL FORM; VOWEL SPACE; PERCEPTION; REPRESENTATION
AB Statistical distributions of phonetic variants in spoken language influence speech perception for both language learners and mature users. We theorized that patterns of phonetic variant processing of consonants demonstrated by adults might stem in part from patterns of early exposure to statistics of phonetic variants in infant-directed (ID) speech. In particular, we hypothesized that ID speech might involve greater proportions of canonical /t/ pronunciations compared to adult-directed (AD) speech in at least some phonological contexts. This possibility was tested using a corpus of spontaneous speech of mothers speaking to other adults, or to their typically-developing infant. Tokens of word-final alveolar stops - including /t/, /d/, and the nasal stop /n/ - were examined in assimilable contexts (i.e., those followed by a word-initial labial and/or velar); these were classified as canonical, assimilated, deleted, or glottalized. Results confirmed that there were significantly more canonical pronunciations in assimilable contexts in ID compared with AD speech, an effect which was driven by the phoneme N. These findings suggest that at least in phonological contexts involving possible assimilation, children are exposed to more canonical /t/ variant pronunciations than adults are. This raises the possibility that perceptual processing of canonical /t/ may be partly attributable to exposure to canonical /t/ variants in ID speech. Results support the need for further research into how statistics of variant pronunciations in early language input may shape speech processing across the lifespan. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Dilley, Laura] Michigan State Univ, Dept Commun Sci & Disorders, 1026 Red Cedar Rd,Rm 102, E Lansing, MI 48824 USA.
   [Gamache, Jessica] Michigan State Univ, Dept Linguist & German Slav Asian & African Langu, E Lansing, MI 48824 USA.
   [Wang, Yuanyuan; Houston, Derek M.] Ohio State Univ, Dept Otolaryngol, Columbus, OH 43210 USA.
   [Bergeson, Tonya R.] Indiana Univ Sch Med, Dept Otolaryngol Head & Neck Surg, Indianapolis, IN 46202 USA.
   [Bergeson, Tonya R.] Butler Univ, Dept Commun Sci & Disorders, Indianapolis, IN 46208 USA.
RP Dilley, L (corresponding author), Michigan State Univ, Dept Commun Sci & Disorders, 1026 Red Cedar Rd,Rm 102, E Lansing, MI 48824 USA.
EM ldilley@msu.edu
RI Houston, Derek/AAM-6553-2020
FU NIH-NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R01DC008581]
FX This research is supported by NIH-NIDCD grant 5R01DC008581-08 to D.M.
   Houston and L. Dilley and NIH-NIDCD grant R01DC008581 to T. Bergeson.
   Thanks to Mark Pitt for valuable feedback. We thank Claire Carpenter,
   Dan Chabala, Evamarie Cropsey, Erin Dixon, Dana Flowerday, Devin
   McAuley, Amanda Millett, Shaina Selbig, Zach Zells for their assistance
   with data analysis, organization, and/or coding. We thank Madeleine
   McAuley, Leif McAuley, Jason Cristini, and Dominic Cristini for
   supporting of the research effort.
CR Adriaans F, 2017, J ACOUST SOC AM, V141, P3070, DOI 10.1121/1.4982246
   Agresti A, 2012, CATEGORICAL DATA ANA, V3rd
   Andruski J. E, 1999, 14 INT C PHON SCI SA
   Baayen H., 2008, ANAL LINGUISTIC DATA
   Baran J. A., 1977, J PHONETICS, V5, P339, DOI 10.1016/S0095-4470(19)31204-5
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Barth D, 2018, QUANT METH HUMAN SOC, P99, DOI 10.1007/978-3-319-69830-4_6
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Beals K., 1994, PAPERS ANN REGIONAL, P232
   Benders T, 2013, INFANT BEHAV DEV, V36, P847, DOI 10.1016/j.infbeh.2013.09.001
   Bergeson TR, 2006, INFANCY, V10, P221, DOI 10.1207/s15327078in1003_2
   Bergeson TR, 2002, PSYCHOL SCI, V13, P72, DOI 10.1111/1467-9280.00413
   Bolstad W., 2016, INTRO BAYESIAN STAT
   Bowers JS, 2016, J MEM LANG, V87, P71, DOI 10.1016/j.jml.2015.11.002
   Breen M, 2012, CORPUS LINGUIST LING, V8, P277, DOI 10.1515/cllt-2012-0011
   Buckler H, 2018, J PHONETICS, V66, P45, DOI 10.1016/j.wocn.2017.09.004
   Burnham D, 2002, SCIENCE, V296, P1435, DOI 10.1126/science.1069587
   Burnham EB, 2015, J SPEECH LANG HEAR R, V58, P241, DOI 10.1044/2015_JSLHR-S-13-0205
   Buz E, 2016, J MEM LANG, V89, P68, DOI 10.1016/j.jml.2015.12.009
   Cho T, 2008, J PHONETICS, V36, P239, DOI 10.1016/j.wocn.2007.06.001
   Chong AJ, 2018, LAB PHONOL, V9, DOI 10.5334/labphon.70
   Connine CM, 2004, PSYCHON B REV, V11, P1084, DOI 10.3758/BF03196741
   Connine CM, 2008, PERCEPT PSYCHOPHYS, V70, P403, DOI 10.3758/PP.70.3.403
   COOPER FS, 1952, J ACOUST SOC AM, V24, P597, DOI 10.1121/1.1906940
   COOPER RP, 1994, CHILD DEV, V65, P1663, DOI 10.1111/j.1467-8624.1994.tb00841.x
   Cristia A, 2019, CHILD DEV, V90, P759, DOI 10.1111/cdev.12974
   Cristia A, 2014, J CHILD LANG, V41, P913, DOI 10.1017/S0305000912000669
   de Boer B, 2003, ACOUST RES LETT ONL, V4, P129, DOI 10.1121/1.1613311
   Deelman T, 2001, J EXP PSYCHOL HUMAN, V27, P656, DOI 10.1037//0096-1523.27.3.656
   DIJKSTRA T, 1995, CAN J EXP PSYCHOL, V49, P264, DOI 10.1037/1196-1961.49.2.264
   Dilley LC, 2007, J ACOUST SOC AM, V122, P2340, DOI 10.1121/1.2772226
   Dilley LC, 2014, J CHILD LANG, V41, P155, DOI 10.1017/S0305000912000670
   Eaves BS, 2016, PSYCHOL REV, V123, P758, DOI 10.1037/rev0000031
   Ellis L, 2002, J PHONETICS, V30, P373, DOI 10.1006/jpho.2001.0162
   Englund K, 2006, INFANT CHILD DEV, V15, P139, DOI 10.1002/icd.445
   Englund Kjellrun T., 2005, FIRST LANG, V25, P219, DOI DOI 10.1177/0142723705050286
   Englund KT, 2005, J PSYCHOLINGUIST RES, V34, P259, DOI 10.1007/s10936-005-3640-7
   Ernestus M, 2007, P INT C PHON SCI SAA
   Ernestus M, 2011, J PHONETICS, V39, P253, DOI 10.1016/S0095-4470(11)00055-6
   FERNALD A, 1984, DEV PSYCHOL, V20, P104, DOI 10.1037/0012-1649.20.1.104
   Fernald A, 1992, NONVERBAL VOCAL COMM, P262
   Fish MS, 2017, J PHONETICS, V63, P19, DOI 10.1016/j.wocn.2017.04.003
   Fong YY, 2010, BIOSTATISTICS, V11, P397, DOI 10.1093/biostatistics/kxp053
   Foulkes P, 2005, LANGUAGE, V81, P177, DOI 10.1353/lan.2005.0018
   Garellek M, 2015, J ACOUST SOC AM, V137, P822, DOI 10.1121/1.4906155
   Gaskell MG, 1998, J EXP PSYCHOL HUMAN, V24, P380, DOI 10.1037/0096-1523.24.2.380
   Gergely G, 2007, DEVELOPMENTAL SCI, V10, P139, DOI 10.1111/j.1467-7687.2007.00576.x
   Gomez R. L., 2007, OXFORD HDB PSYCHOLIN
   Gow DW, 2003, PERCEPT PSYCHOPHYS, V65, P575, DOI 10.3758/BF03194584
   Gow DW, 2002, J EXP PSYCHOL HUMAN, V28, P163, DOI 10.1037//0096-1523.28.1.163
   Gow DW, 2001, J MEM LANG, V45, P133, DOI 10.1006/jmla.2000.2764
   Gries ST, 2015, CORPORA, V10, P95, DOI 10.3366/cor.2015.0068
   Gries Stefan Th, 2016, QUANTITATIVE CORPUS
   Hadfield J, 2010, MCMCGIMM MARKOV CHAI
   Hadfield JD, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i02
   Hartman KM, 2017, J CHILD LANG, V44, P1140, DOI 10.1017/S0305000916000520
   Holst T., 1995, PHONOLOGY PHONETIC E, P315
   Huffman MK, 2005, J PHONETICS, V33, P335, DOI 10.1016/j.wocn.2005.02.004
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Johnson K, 2006, J PHONETICS, V34, P485, DOI 10.1016/j.wocn.2005.08.004
   Kalashnikova M, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.170306
   Kazanina N, 2018, PSYCHON B REV, V25, P560, DOI 10.3758/s13423-017-1362-0
   Kirchhoff K, 2005, J ACOUST SOC AM, V117, P2238, DOI 10.1121/1.1869172
   Kittredge AK, 2008, COGN NEUROPSYCHOL, V25, P463, DOI 10.1080/02643290701674851
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kondaurova MV, 2012, J ACOUST SOC AM, V132, P1039, DOI 10.1121/1.4728169
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Ladefoged P, 1996, SOUNDS WORLDS
   Lahey M, 2014, LANG LEARN DEV, V10, P308, DOI 10.1080/15475441.2013.860813
   LAHIRI A, 1991, COGNITION, V38, P245, DOI 10.1016/0010-0277(91)90008-R
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Liu HM, 2003, DEVELOPMENTAL SCI, V6, pF1, DOI 10.1111/1467-7687.00275
   Liu HM, 2009, J CHILD LANG, V36, P909, DOI 10.1017/S030500090800929X
   Malsheen B., 1980, CHILD PHONOLOGY, V2, P173
   Maniwa K, 2009, J ACOUST SOC AM, V125, P3962, DOI 10.1121/1.2990715
   Martin A, 2015, PSYCHOL SCI, V26, P341, DOI 10.1177/0956797614562453
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   McLennan CT, 2005, J EXP PSYCHOL HUMAN, V31, P1308, DOI 10.1037/0096-1523.31.6.1308
   McLennan CT, 2003, J EXP PSYCHOL LEARN, V29, P539, DOI 10.1037/0278-7393.29.4.539
   McMurray B, 2013, COGNITION, V129, P362, DOI 10.1016/j.cognition.2013.07.015
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   Mitterer H, 2006, J PHONETICS, V34, P73, DOI 10.1016/j.wocn.2005.03.003
   Mitterer H, 2018, J MEM LANG, V98, P77, DOI 10.1016/j.jml.2017.09.005
   Mitterer H, 2016, J PHONETICS, V54, P68, DOI 10.1016/j.wocn.2015.09.002
   Mitterer H, 2015, J MEM LANG, V85, P116, DOI 10.1016/j.jml.2015.08.005
   Mitterer H, 2013, COGNITION, V129, P356, DOI 10.1016/j.cognition.2013.07.011
   Mitterer H, 2013, J MEM LANG, V69, P59, DOI 10.1016/j.jml.2013.02.001
   Mitterer H, 2011, COGNITIVE SCI, V35, P184, DOI 10.1111/j.1551-6709.2010.01140.x
   Mitterer H, 2009, J EXP PSYCHOL HUMAN, V35, P244, DOI 10.1037/a0012730
   Miyazawa K, 2017, COGNITION, V166, P84, DOI 10.1016/j.cognition.2017.05.003
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Oviatt S, 1998, SPEECH COMMUN, V24, P87, DOI 10.1016/S0167-6393(98)00005-3
   Papousek M., 1985, SOCIAL PERCEPTION IN, P269
   Patterson D, 2003, PHONETICA, V60, P47, DOI 10.1159/000070454
   Patterson D, 2001, PHONETICA, V58, P254, DOI 10.1159/000046178
   PICHENY MA, 1986, J SPEECH HEAR RES, V29, P434, DOI 10.1044/jshr.2904.434
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   Pitt MA, 2011, J PHONETICS, V39, P304, DOI 10.1016/j.wocn.2010.07.004
   Pitt MA, 2009, J MEM LANG, V61, P19, DOI 10.1016/j.jml.2009.02.005
   Pitt MA, 2009, J EXP PSYCHOL HUMAN, V35, P896, DOI 10.1037/a0013160
   Powell M.J.D., 2009, 2009NA06 DAMTP U CAM
   Ranbom LJ, 2007, J MEM LANG, V57, P273, DOI 10.1016/j.jml.2007.04.001
   RATNER NB, 1984, J PHONETICS, V12, P245, DOI 10.1016/S0095-4470(19)30881-2
   Redi L, 2001, J PHONETICS, V29, P407, DOI 10.1006/jpho.2001.0145
   Reinisch E, 2016, J PHONETICS, V55, P96, DOI 10.1016/j.wocn.2015.12.004
   Reinisch E, 2014, J PHONETICS, V45, P91, DOI 10.1016/j.wocn.2014.04.002
   Rietveld T., 1993, STAT TECHNIQUES STUD
   Saffran JR, 2003, CURR DIR PSYCHOL SCI, V12, P110, DOI 10.1111/1467-8721.01243
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   Schertz J, 2013, J PHONETICS, V41, P249, DOI 10.1016/j.wocn.2013.03.007
   SEIDENBERG MS, 1979, J EXP PSYCHOL-HUM L, V5, P546, DOI 10.1037/0278-7393.5.6.546
   Seyfarth S., 2015, P 18 INT C PHON SCI
   Seyfarth S, 2014, COGNITION, V133, P140, DOI 10.1016/j.cognition.2014.06.013
   Shafto P, 2014, COGNITIVE PSYCHOL, V71, P55, DOI 10.1016/j.cogpsych.2013.12.004
   SHATTUCKHUFNAGE.S, 1986, PHONOLOGY YB, V3, P117
   SHOCKEY L, 1980, PHONETICA, V37, P267, DOI 10.1159/000259996
   Sjerps MJ, 2010, J EXP PSYCHOL HUMAN, V36, P195, DOI 10.1037/a0016803
   SNOW CE, 1977, J CHILD LANG, V4, P1, DOI 10.1017/S0305000900000453
   Staum Casasanto L, 2008, EXPT INVESTIGATIONS
   Stent AJ, 2008, SPEECH COMMUN, V50, P163, DOI 10.1016/j.specom.2007.07.005
   Stevens KN, 2000, PHONETICA, V57, P139, DOI 10.1159/000028468
   Stevens KN, 2002, J ACOUST SOC AM, V111, P1872, DOI 10.1121/1.1458026
   Sumner M, 2005, J MEM LANG, V52, P322, DOI 10.1016/j.jml.2004.11.004
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   Sundberg U, 1999, PHONETICA, V56, P186, DOI 10.1159/000028450
   Sundberg U, 2001, LUND U WORK PAP
   Swingley D, 2018, COGNITIVE SCI, V42, P1618, DOI 10.1111/cogs.12620
   Thiessen ED, 2005, INFANCY, V7, P53, DOI 10.1207/s15327078in0701_5
   Tucker B. V., 2007, P 16 INT C PHON SCI
   Uther M, 2007, SPEECH COMMUN, V49, P2, DOI 10.1016/j.specom.2006.10.003
   Wang Y., 2015, ACTA CHROMATOGR, V1, P1, DOI DOI 10.1186/S12984-015-0034-4
   Wang YY, 2017, J SPEECH LANG HEAR R, V60, P3321, DOI 10.1044/2017_JSLHR-H-17-0149
   Wang YY, 2015, J CHILD LANG, V42, P821, DOI 10.1017/S0305000914000439
   Warner N, 2011, J ACOUST SOC AM, V130, P1606, DOI 10.1121/1.3621306
   Warner N, 2009, J ACOUST SOC AM, V125, P3317, DOI 10.1121/1.3097773
   Wassink AB, 2007, J PHONETICS, V35, P363, DOI 10.1016/j.wocn.2006.07.002
   Weisleder A, 2013, PSYCHOL SCI, V24, P2143, DOI 10.1177/0956797613488145
   Werker JF, 2007, COGNITION, V103, P147, DOI 10.1016/j.cognition.2006.03.006
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2012, CURR DIR PSYCHOL SCI, V21, P221, DOI 10.1177/0963721412449459
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wieland EA, 2015, J SPEECH LANG HEAR R, V58, P254, DOI 10.1044/2015_JSLHR-S-13-0250
   Zellou G, 2015, LAB PHONOL, V6, P305, DOI 10.1515/lp-2015-0010
NR 145
TC 1
Z9 1
U1 3
U2 6
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD JUL
PY 2019
VL 75
BP 73
EP 87
DI 10.1016/j.wocn.2019.05.004
PG 15
WC Linguistics; Language & Linguistics
SC Linguistics
GA IM1ZE
UT WOS:000477789600005
PM 32884162
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Rajan, V
   Konishi, H
   Ridge, K
   Houston, DM
   Golinkoff, RM
   Hirsh-Pasek, K
   Eastman, N
   Schwartz, RG
AF Rajan, Vinaya
   Konishi, Haruka
   Ridge, Katherine
   Houston, Derek M.
   Golinkoff, Roberta Michnick
   Hirsh-Pasek, Kathy
   Eastman, Nancy
   Schwartz, Richard G.
TI Novel word learning at 21 months predicts receptive vocabulary outcomes
   in later childhood
SO JOURNAL OF CHILD LANGUAGE
LA English
DT Article
DE novel word learning; language development; infancy
ID LANGUAGE-DEVELOPMENT; SPEECH-PERCEPTION; PHONETIC DETAIL; CHILDREN;
   VALIDITY; ACQUISITION; QUALITY; ABILITY; FORM
AB Several aspects of early language skills, including parent-report measures of vocabulary, phoneme discrimination, speech segmentation, and speed of lexical access predict later childhood language outcomes. To date, no studies have examined the long-term predictive validity of novel word learning. We examined whether individual differences in novel word learning at 21 months predict later childhood receptive vocabulary outcomes rather than generalized cognitive abilities. Twenty-eight 21-month-olds were taught novel words using a modified version of the Intermodal Preferential Looking Paradigm. Seventeen children (range 7-10 years) returned to participate in a longitudinal follow-up. Novel word learning in infancy uniquely accounted for 22% of the variance in childhood receptive vocabulary but did not predict later childhood visuospatial ability or non-verbal IQ. These results suggest that the ability to associate novel sound patterns to novel objects, an index of the process of word learning, may be especially important for long-term language mastery.
C1 [Rajan, Vinaya] Univ Sci, 600 S 43rd St, Philadelphia, PA 19104 USA.
   [Konishi, Haruka] Missouri Western State Coll, St Joseph, MO 64507 USA.
   [Ridge, Katherine] Univ Minnesota, Minneapolis, MN USA.
   [Houston, Derek M.; Eastman, Nancy] Ohio State Univ, Coll Med, Columbus, OH 43210 USA.
   [Houston, Derek M.; Eastman, Nancy] Nationwide Childrens Hosp, Columbus, OH USA.
   [Golinkoff, Roberta Michnick] Univ Delaware, Newark, DE 19716 USA.
   [Hirsh-Pasek, Kathy] Temple Univ, Philadelphia, PA 19122 USA.
   [Schwartz, Richard G.] CUNY, New York, NY 10021 USA.
RP Rajan, V (corresponding author), Univ Sci, 600 S 43rd St, Philadelphia, PA 19104 USA.
EM v.rajan@usciences.edu
RI Houston, Derek/AAM-6553-2020; Schwartz, Richard/AAT-2639-2020
OI Schwartz, Richard/0000-0001-9153-1349
FU [NIH 5R01DC006235];  [NIH 5R01DC011041];  [R305A100215];  [R305A090525];
    [R305B130012]
FX This research was supported by research grants to Derek M. Houston (NIH
   5R01DC006235), Richard G. Schwartz (NIH 5R01DC011041), Roberta Michnick
   Golinkoff and Kathy Hirsh-Pasek (IES grants R305A100215, R305A090525,
   and R305B130012). The content of this manuscript is solely the
   responsibility of the authors and does not necessarily represent the
   official views of the National Institutes of Health or Institute of
   Education Sciences.
CR ALTEPETER TS, 1989, J CLIN PSYCHOL, V45, P935, DOI 10.1002/1097-4679(198911)45:6<935::AID-JCLP2270450618>3.0.CO;2-H
   Axelsson EL, 2013, ACTA PSYCHOL, V144, P264, DOI 10.1016/j.actpsy.2013.07.002
   Bates E, 1988, 1 WORDS GRAMMAR INDI
   Benasich AA, 2002, BEHAV BRAIN RES, V136, P31, DOI 10.1016/S0166-4328(02)00098-0
   Bernhardt B. M., 2007, FIRST LANG, V27, P315, DOI DOI 10.1177/0142723707081652
   Bion RAH, 2013, COGNITION, V126, P39, DOI 10.1016/j.cognition.2012.08.008
   Bornstein MH, 1998, CHILD DEV, V69, P654, DOI 10.2307/1132196
   Brown L., 1997, TONI 3 TEST NONVERBA
   Can DD, 2013, J CHILD LANG, V40, P821, DOI 10.1017/S030500091200030X
   CHILDERS JS, 1994, PERCEPT MOTOR SKILL, V79, P1195, DOI 10.2466/pms.1994.79.3.1195
   Dunn L. M., 1997, PEABODY PICTURE VOCA
   Feldman HM, 2005, CHILD DEV, V76, P856, DOI 10.1111/j.1467-8624.2005.00882.x
   Fennell CT, 2003, LANG SPEECH, V46, P245, DOI 10.1177/00238309030460020901
   Fenson L., 1994, MONOGRAPHS SOC RES C, V59
   Fenson L., 1993, MACARTHUR COMMUNICAT
   Fernald A, 2006, DEV PSYCHOL, V42, P98, DOI 10.1037/0012-1649.42.1.98
   Gleitman Lelia, 1990, LANG ACQUIS, V1, P3, DOI DOI 10.1207/S15327817LA0101_2
   Golinkoff R. M., 2017, USERS MANUAL QUICK I
   GOLINKOFF RM, 1992, DEV PSYCHOL, V28, P99, DOI 10.1037/0012-1649.28.1.99
   GOLINKOFF RM, 1987, J CHILD LANG, V14, P23, DOI 10.1017/S030500090001271X
   Golinkoff RM, 2008, TRENDS COGN SCI, V12, P397, DOI 10.1016/j.tics.2008.07.003
   Golinkoff RM, 2013, PERSPECT PSYCHOL SCI, V8, P316, DOI 10.1177/1745691613484936
   Hart B., 1995, MEANINGFUL DIFFERENC
   Hirsh-Pasek K, 2015, PSYCHOL SCI, V26, P1071, DOI 10.1177/0956797615581493
   HIRSHPASEK K, 1996, LANG SPEECH & COMMUN, P105
   Hodapp AF, 1999, PSYCHOL REP, V84, P1139, DOI 10.2466/PR0.84.3.1139-1142
   Horst JS, 2008, INFANCY, V13, P128, DOI 10.1080/15250000701795598
   Houston DM, 2012, DEVELOPMENTAL SCI, V15, P448, DOI 10.1111/j.1467-7687.2012.01140.x
   Ma WY, 2011, LANG LEARN DEV, V7, P185, DOI 10.1080/15475441.2011.579839
   Marchman VA, 2008, DEVELOPMENTAL SCI, V11, pF9, DOI 10.1111/j.1467-7687.2008.00671.x
   Mather E, 2010, J EXP CHILD PSYCHOL, V105, P232, DOI 10.1016/j.jecp.2009.11.004
   Mather E, 2009, INFANCY, V14, P60, DOI 10.1080/15250000802569702
   MERTON RK, 1968, SCIENCE, V159, P56, DOI 10.1126/science.159.3810.56
   Newman R, 2006, DEV PSYCHOL, V42, P643, DOI 10.1037/0012-1649.42.4.643
   Rowe ML, 2012, CHILD DEV, V83, P1762, DOI 10.1111/j.1467-8624.2012.01805.x
   Schafer G, 1998, CHILD DEV, V69, P309, DOI 10.2307/1132166
   Singh L, 2012, DEVELOPMENTAL SCI, V15, P482, DOI 10.1111/j.1467-7687.2012.01141.x
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Swingley D, 2002, PSYCHOL SCI, V13, P480, DOI 10.1111/1467-9280.00485
   Thal DJ, 1999, J SPEECH LANG HEAR R, V42, P482, DOI 10.1044/jslhr.4202.482
   Tomasello M., 1999, MONOGRAPHS SOC RES C, V59, P174
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Wecshler D., 2003, WECSHLER INTELLIGENC
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   Werker JF, 1998, DEV PSYCHOL, V34, P1289, DOI 10.1037/0012-1649.34.6.1289
   Wojcik EH, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00151
   WOODWARD AL, 1994, DEV PSYCHOL, V30, P553, DOI 10.1037/0012-1649.30.4.553
NR 48
TC 0
Z9 0
U1 1
U2 5
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0305-0009
EI 1469-7602
J9 J CHILD LANG
JI J. Child Lang.
PD JUL
PY 2019
VL 46
IS 4
BP 617
EP 631
AR PII S0305000918000600
DI 10.1017/S0305000918000600
PG 15
WC Psychology, Developmental; Linguistics; Psychology, Experimental
SC Psychology; Linguistics
GA IG2UR
UT WOS:000473655600001
PM 30803465
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Monsell, S
   Lavric, A
   Strivens, A
   Paul, E
AF Monsell, Stephen
   Lavric, Aureliu
   Strivens, Amy
   Paul, Emilia
TI Can We Prepare to Attend to One of Two Simultaneous Voices?
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE
LA English
DT Article
DE cocktail party problem; multitalker speech perception; selective
   attention; endogenous attention; control of attention
ID TASK-SET RECONFIGURATION; AUDITORY ATTENTION; SPEECH-PERCEPTION; SPATIAL
   ATTENTION; STIMULUS; SWITCH; MASKING; INTERFERENCE; FAMILIARITY;
   DIMENSIONS
AB We can selectively attend to one of two simultaneous voices sharing a source location. Can we endogenously select the voice before speech is heard? Participants heard two digit names, spoken simultaneously by a male voice and a female voice, following a visual cue indicating which voice's digit to classify as odd or even. There was a suhstantial cast in reaction time and errors when the target voice switched from one trial to the next. In Experiment 1, with a highly familiar pair of voices, the switch cost reduced by nearly half as the cue-stimulus interval increased from 50 to 800 ms, indicating (contrary to previous reports) effective endogenous preparation for a change of voice. No further reduction in switch cost occurred with a longer preparation interval-this "residual" switch cost may be attributable to attentional "inertia." In Experiment 2, with previously unfamiliar voices. the pattern of switch costs was very similar, though repeated attention to the same target voice over a run of trials improved performance more. Delaying the Onset of one voice by 366 ins improved performance, but the pattern of preparatory tuning effects was similar. Thus, endogenous preparation for a voice is possible, but it is limited in efficacy, as for some other attentional domains.
C1 [Monsell, Stephen; Lavric, Aureliu; Strivens, Amy; Paul, Emilia] Univ Exeter, Coll Life & Environm Sci, Dept Psychol, Exeter, Devon, England.
RP Monsell, S (corresponding author), Univ Exeter, Coll Life & Environm Sci, Psychol, Washington Singer Labs, Exeter EX4 4QG, Devon, England.
EM s.monsell@exeter.ac.uk
OI Monsell, Stephen/0000-0002-4337-1675
CR ALLPORT A, 1994, ATTENTION PERFORM, V15, P421
   Boersma P., 2014, PRAAT DOING PHONETIC
   Bressler S, 2014, PSYCHOL RES-PSYCH FO, V78, P349, DOI 10.1007/s00426-014-0555-7
   BROADBENT DE, 1954, J EXP PSYCHOL, V47, P191, DOI 10.1037/h0054182
   Bronkhorst AW, 2015, ATTEN PERCEPT PSYCHO, V77, P1465, DOI 10.3758/s13414-015-0882-9
   Brungart DS, 2001, J ACOUST SOC AM, V110, P2527, DOI 10.1121/1.1408946
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Carlyon RP, 2004, TRENDS COGN SCI, V8, P465, DOI 10.1016/j.tics.2004.08.008
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Darwin CJ, 2008, PHILOS T R SOC B, V363, P1011, DOI 10.1098/rstb.2007.2156
   Darwin CJ, 2000, J ACOUST SOC AM, V107, P970, DOI 10.1121/1.428278
   Darwin CJ, 2003, J ACOUST SOC AM, V114, P2913, DOI 10.1121/1.1616924
   Darwin CJ, 2000, J ACOUST SOC AM, V108, P335, DOI 10.1121/1.429468
   Elchlepp H, 2017, PSYCHOL SCI, V28, P470, DOI 10.1177/0956797616686855
   Elchlepp H, 2015, J EXP PSYCHOL GEN, V144, P299, DOI 10.1037/a0038740
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fintor E, 2019, Q J EXP PSYCHOL, V72, P955, DOI 10.1177/1747021818771836
   Freyman RL, 2004, J ACOUST SOC AM, V115, P2246, DOI 10.1121/1.1689343
   Hill KT, 2010, CEREB CORTEX, V20, P583, DOI 10.1093/cercor/bhp124
   Holmes E., 2014, THESIS U YORK YORK
   Holmes E, 2018, PSYCHOL SCI, V29, P1575, DOI 10.1177/0956797618779083
   Holmes E, 2018, ATTEN PERCEPT PSYCHO, V80, P1520, DOI 10.3758/s13414-018-1531-x
   Holmes E, 2016, HEARING RES, V336, P83, DOI 10.1016/j.heares.2016.04.007
   Johnsrude IS, 2013, PSYCHOL SCI, V24, P1995, DOI 10.1177/0956797613482467
   Kidd G, 2005, J ACOUST SOC AM, V118, P3804, DOI 10.1121/1.2109187
   Kiesel A, 2010, PSYCHOL BULL, V136, P849, DOI 10.1037/a0019842
   Kikumoto A, 2016, PSYCHON B REV, V23, P899, DOI 10.3758/s13423-015-0944-y
   Kitterick PT, 2010, J ACOUST SOC AM, V127, P2498, DOI 10.1121/1.3327507
   Koch I, 2006, MEM COGNITION, V34, P433, DOI 10.3758/BF03193420
   Koch I, 2018, PSYCHOL BULL, V144, P557, DOI 10.1037/bul0000144
   Koch I, 2011, J EXP PSYCHOL HUMAN, V37, P1140, DOI 10.1037/a0022189
   KRISTOFFERSON AB, 1967, ACTA PSYCHOL, V27, P93, DOI 10.1016/0001-6918(67)90049-2
   Larson E, 2014, NEUROIMAGE, V84, P681, DOI 10.1016/j.neuroimage.2013.09.061
   Larson E, 2013, J ACOUST SOC AM, V134, pEL165, DOI 10.1121/1.4812439
   Lavric A, 2008, EUR J NEUROSCI, V28, P1016, DOI 10.1111/j.1460-9568.2008.06372.x
   Lawo V, 2015, J COGN PSYCHOL, V27, P194, DOI 10.1080/20445911.2014.995669
   Lawo V, 2014, Q J EXP PSYCHOL, V67, P2010, DOI 10.1080/17470218.2014.898079
   Lawo V, 2014, J GERONTOL B-PSYCHOL, V69, P237, DOI 10.1093/geronb/gbs107
   Lee AKC, 2013, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00190
   Lien MC, 2010, J EXP PSYCHOL HUMAN, V36, P1, DOI 10.1037/a0015875
   Longman CS, 2017, J EXP PSYCHOL LEARN, V43, P862, DOI 10.1037/xlm0000347
   Longman CS, 2016, Q J EXP PSYCHOL, V69, P2248, DOI 10.1080/17470218.2015.1115112
   Longman CS, 2014, J EXP PSYCHOL HUMAN, V40, P1580, DOI 10.1037/a0036552
   Lukas S, 2010, ACTA PSYCHOL, V134, P318, DOI 10.1016/j.actpsy.2010.03.004
   Mayr U, 2013, J EXP PSYCHOL GEN, V142, P489, DOI 10.1037/a0029353
   Meiran N, 2002, MEM COGNITION, V30, P540, DOI 10.3758/BF03194955
   Meiran N, 2000, CONTROL OF COGNITIVE PROCESSES: ATTENTION AND PERFORMANCE XVIII, P377
   Meiran N, 1996, J EXP PSYCHOL LEARN, V22, P1423, DOI 10.1037/0278-7393.22.6.1423
   Meiran N., 2014, TASK SWITCHING COGNI, P45, DOI DOI 10.1093/ACPROF:OSOBL/9780199921959.003.0003
   MONDOR TA, 1995, J EXP PSYCHOL HUMAN, V21, P387, DOI 10.1037/0096-1523.21.2.387
   Monsell S, 2003, TRENDS COGN SCI, V7, P134, DOI 10.1016/S1364-6613(03)00028-7
   Monsell S, 2003, MEM COGNITION, V31, P327, DOI 10.3758/BF03194391
   Monsell S., 2017, WILEY HDB COGNITIVE, P29, DOI DOI 10.1002/9781118920497.CH2
   Monsell S, 2006, J EXP PSYCHOL HUMAN, V32, P493, DOI 10.1037/0096-1523.32.3.493
   Monsell S, 2015, HANDBOOK OF ATTENTION, P139
   Muller HJ, 2003, J EXP PSYCHOL HUMAN, V29, P1021, DOI 10.1037/0096-1523.29.5.1021
   Nobre AC, 2015, HANDBOOK OF ATTENTION, P57
   Nolden S, 2019, ATTEN PERCEPT PSYCHO, V81, P727, DOI 10.3758/s13414-018-1620-x
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   Posner MI, 2016, Q J EXP PSYCHOL, V69, P1864, DOI 10.1080/17470218.2014.937446
   ROGERS RD, 1995, J EXP PSYCHOL GEN, V124, P207, DOI 10.1037/0096-3445.124.2.207
   Rubin O, 2006, Q J EXP PSYCHOL, V59, P1033, DOI 10.1080/02724980543000105
   Rushworth MFS, 2002, J COGNITIVE NEUROSCI, V14, P1139, DOI 10.1162/089892902760807159
   Samson F, 2016, J ACOUST SOC AM, V139, P1037, DOI 10.1121/1.4942589
   Seibold JC, 2018, Q J EXP PSYCHOL, V71, P1382, DOI 10.1080/17470218.2017.1344867
   Shafiro V, 2007, J ACOUST SOC AM, V122, pEL229, DOI 10.1121/1.2806174
   Shinn-Cunningham B, 2015, HANDBOOK OF ATTENTION, P99
   Souza P, 2013, J AM ACAD AUDIOL, V24, P689, DOI 10.3766/jaaa.24.8.6
   Spence C, 2010, CONSCIOUS COGN, V19, P364, DOI 10.1016/j.concog.2009.12.001
   TREISMAN AM, 1969, PSYCHOL REV, V76, P282, DOI 10.1037/h0027242
   Vandierendonck A, 2010, PSYCHOL BULL, V136, P601, DOI 10.1037/a0019791
   Waszak F, 2003, COGNITIVE PSYCHOL, V46, P361, DOI 10.1016/S0010-0285(02)00520-0
   Waszak F, 2005, MEM COGNITION, V33, P595, DOI 10.3758/BF03195327
   Yonan CA, 2000, PSYCHOL AGING, V15, P88, DOI 10.1037/0882-7974.15.1.88
NR 76
TC 0
Z9 0
U1 0
U2 8
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0096-1523
EI 1939-1277
J9 J EXP PSYCHOL HUMAN
JI J. Exp. Psychol.-Hum. Percept. Perform.
PD JUL
PY 2019
VL 45
IS 7
BP 966
EP 982
DI 10.1037/xhp0000650
PG 17
WC Psychology; Psychology, Experimental
SC Psychology
GA IF4AC
UT WOS:000473023200009
PM 31021156
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Pisoni, A
   Mattavelli, G
   Casarotti, A
   Comi, A
   Riva, M
   Bello, L
   Papagno, C
AF Pisoni, Alberto
   Mattavelli, Giulia
   Casarotti, Alessandra
   Comi, Alessandro
   Riva, Marco
   Bello, Lorenzo
   Papagno, Costanza
TI The neural correlates of auditory-verbal short-term memory: a
   voxel-based lesion-symptom mapping study on 103 patients after glioma
   removal
SO BRAIN STRUCTURE & FUNCTION
LA English
DT Article
DE Auditory-verbal short-term memory; Supramarginal gyrus; Forward digit
   span; VLSM
ID NORMATIVE DATA; WORKING-MEMORY; COMPREHENSION EVIDENCE; PERFORMANCE;
   REHEARSAL; FLUENCY; CORTEX; LOCALIZATION; IMPAIRMENT; RESECTION
AB The relationship between verbal-auditory short-term memory (STM) and language is an open area of debate and contrasting hypotheses have been proposed, suggesting either that STM would strongly rely on language-related processes, or that it depends on a dedicated system related to language, but independent from it. In this study we examined 103 patients undergoing surgery for glioma resection in the left or right hemisphere, and we conducted a VLSM analysis on their behavioral performance on auditory-verbal STM, as well as on more general verbal and nonverbal tasks. The aim was to investigate whether the anatomical correlates of auditory-verbal STM were part of the language system or they were spatially segregated from it. VLSM results showed that digit span scores were linked to lesions in both the left supramarginal gyrus and superior-posterior temporal areas, as reported in the literature on patients with a selective deficit of auditory-verbal STM. Conversely, other verbal tasks involved areas only partly overlapping with those found for digit span, with repetition being affected by lesions in more anterior regions in the parietal, temporal, and frontal lobes, and word comprehension by lesions in a network including cortical and subcortical pathways in the temporal lobe. The present results, thus, show that auditory-verbal STM neural correlates are only partially overlapping with those supporting comprehension and production: while the left posterior-superior temporal cortex, involved in speech perception, takes part in both functions, the left supramarginal gyrus has a consistent and specific role only in STM, supporting the hypothesis of interacting but segregated networks.
C1 [Pisoni, Alberto; Mattavelli, Giulia; Comi, Alessandro; Papagno, Costanza] Univ Milano Bicocca, Dipartimento Psicol, Piazza Ateneo Nuovo 1,Edificio U6, I-20126 Milan, Italy.
   [Pisoni, Alberto; Mattavelli, Giulia] Univ Milano Bicocca, NeuroMi Neurosci Ctr, Milan, Italy.
   [Casarotti, Alessandra; Riva, Marco; Bello, Lorenzo] Humanitas Res Hosp, Unit Oncol Neurosurg, Via Manzoni 56, Rozzano, Italy.
   [Bello, Lorenzo] Univ Milan, Dept Oncol & Hematooncol, Via Festa del Perdono 7, I-20122 Milan, Italy.
   [Papagno, Costanza] Univ Trento & Rovereto, CeRiN Ctr Neurocognit Rehabil, CIMeC, Via Matteo del Ben 5-B, I-38068 Rovereto, Italy.
RP Papagno, C (corresponding author), Univ Milano Bicocca, Dipartimento Psicol, Piazza Ateneo Nuovo 1,Edificio U6, I-20126 Milan, Italy.; Papagno, C (corresponding author), Univ Trento & Rovereto, CeRiN Ctr Neurocognit Rehabil, CIMeC, Via Matteo del Ben 5-B, I-38068 Rovereto, Italy.
EM costanza.papagno@unitn.it
RI papagno, costanza/K-8460-2012; Riva, Marco/AAC-1357-2019; Mattavelli,
   Giulia/K-5723-2016
OI papagno, costanza/0000-0002-3659-6294; Riva, Marco/0000-0003-4643-6451;
   Casarotti, Alessandra/0000-0001-9330-8415; Mattavelli,
   Giulia/0000-0003-2042-8947
CR Ashburner J, 1999, HUM BRAIN MAPP, V266, P1
   Awh E, 1995, ANN NY ACAD SCI, V769, P97, DOI 10.1111/j.1749-6632.1995.tb38134.x
   Baddeley A., 1974, PSYCHOL LEARN MOTIV, V8, P47, DOI [10.1016/S0079-7421(08)60452-1, DOI 10.1016/S0079-7421(08)60452-1]
   Baddeley A., 1990, NEUROPSYCHOLOGICAL I, P54
   Baldo JV, 2006, J INT NEUROPSYCH SOC, V12, P896, DOI 10.1017/S1355617706061078
   Buchsbaum BR, 2008, J COGNITIVE NEUROSCI, V20, P762, DOI 10.1162/jocn.2008.20501
   Buchsbaum BR, 2019, CORTEX, V112, P134, DOI 10.1016/j.cortex.2018.11.010
   Buchsbaum BR, 2011, BRAIN LANG, V119, P119, DOI 10.1016/j.bandl.2010.12.001
   Campanella F, 2014, BRAIN, V137, P2532, DOI 10.1093/brain/awu183
   Carlesimo GA, 1996, EUR NEUROL, V36, P378, DOI 10.1159/000117297
   Cecchetto C, 2012, COMPRENDO BATTERIA C
   Chouiter L, 2016, NEUROSCIENCE, V329, P275, DOI 10.1016/j.neuroscience.2016.05.029
   Crinion J, 2007, NEUROIMAGE, V37, P866, DOI 10.1016/j.neuroimage.2007.04.065
   D'Esposito M, 2015, ANNU REV PSYCHOL, V66, P115, DOI 10.1146/annurev-psych-010814-015031
   DAMASIO H, 1980, BRAIN, V103, P337, DOI 10.1093/brain/103.2.337
   DERENZI E, 1978, CORTEX, V14, P41, DOI 10.1016/S0010-9452(78)80006-9
   DERenzi E., 1965, CORTEX, V1, P410, DOI DOI 10.1016/S0010-9452(65)80003-X
   Duffau H, 2002, J NEUROL NEUROSUR PS, V72, P511
   Gorno-Tempini ML, 2008, NEUROLOGY, V71, P1227, DOI 10.1212/01.wnl.0000320506.79811.da
   Henry JD, 2004, NEUROPSYCHOLOGY, V18, P284, DOI 10.1037/0894-4105.18.2.284
   Henson RNA, 2000, NEUROPSYCHOLOGIA, V38, P426, DOI 10.1016/S0028-3932(99)00098-6
   Hurlstone MJ, 2014, PSYCHOL BULL, V140, P339, DOI 10.1037/a0034221
   Karnath HO, 2017, BRAIN STRUCT FUNCT, V222, P2059, DOI 10.1007/s00429-016-1325-7
   Karnath HO, 2011, CORTEX, V47, P1004, DOI 10.1016/j.cortex.2010.08.006
   Kinkingnehun S, 2007, NEUROIMAGE, V37, P1237, DOI 10.1016/j.neuroimage.2007.06.027
   Koenigs M, 2011, NEUROPSYCHOLOGIA, V49, P3612, DOI 10.1016/j.neuropsychologia.2011.09.013
   Leff AP, 2009, BRAIN, V132, P3401, DOI 10.1093/brain/awp273
   Martin N, 1997, COGNITIVE NEUROPSYCH, V14, P641
   Mattavelli G, 2019, J NEUROPSYCHOL, V13, P1, DOI 10.1111/jnp.12130
   Miceli G, 1994, BATTERIA ANALISI DEI
   Monaco M, 2013, NEUROL SCI, V34, P749, DOI 10.1007/s10072-012-1130-x
   Newhart M, 2012, CORTEX, V48, P1288, DOI 10.1016/j.cortex.2011.09.009
   Newton AM, 2007, PSYCHOL SCI, V18, P574, DOI 10.1111/j.1467-9280.2007.01942.x
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   ORSINI A, 1987, ITAL J NEUROL SCI, V8, P539
   Papagno C, 2019, CORTEX, V112, P80, DOI 10.1016/j.cortex.2018.08.028
   Papagno C, 2017, HUM BRAIN MAPP, V38, P3011, DOI 10.1002/hbm.23569
   Papagno C, 2012, J NEURO-ONCOL, V108, P269, DOI 10.1007/s11060-012-0824-5
   Papagno C, 2011, BRAIN, V134, P405, DOI 10.1093/brain/awq283
   PAULESU E, 1993, NATURE, V362, P342, DOI 10.1038/362342a0
   PETRIDES M, 1993, P NATL ACAD SCI USA, V90, P878, DOI 10.1073/pnas.90.3.878
   Pettigrew C, 2014, APHASIOLOGY, V28, P1258, DOI 10.1080/02687038.2014.919436
   Pisoni A, 2018, NEUROIMAGE-CLIN, V18, P986, DOI 10.1016/j.nicl.2018.03.022
   Poeppel D, 1996, BRAIN LANG, V55, P317, DOI 10.1006/brln.1996.0108
   Romero L, 2006, J COGNITIVE NEUROSCI, V18, P1147, DOI 10.1162/jocn.2006.18.7.1147
   Rorden C, 2009, NEUROIMAGE, V44, P1355, DOI 10.1016/j.neuroimage.2008.09.031
   Shallice T, 2019, CORTEX, V112, P107, DOI 10.1016/j.cortex.2018.10.004
   Smith JS, 2008, J CLIN ONCOL, V26, P1338, DOI 10.1200/JCO.2007.13.9337
   Vallar G, 1997, NEUROPSYCHOLOGIA, V35, P795, DOI 10.1016/S0028-3932(96)00127-3
   Vallar G., 2002, HDB MEMORY DISORDERS, P249
   WARRINGTON EK, 1971, NEUROPSYCHOLOGIA, V9, P377, DOI 10.1016/0028-3932(71)90002-9
   Yue QH, 2019, CEREB CORTEX, V29, P1398, DOI 10.1093/cercor/bhy037
   Zamora L, 2016, NEUROPSYCHOLOGIA, V86, P1, DOI 10.1016/j.neuropsychologia.2016.04.004
NR 53
TC 4
Z9 4
U1 2
U2 3
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1863-2653
EI 1863-2661
J9 BRAIN STRUCT FUNCT
JI Brain Struct. Funct.
PD JUL
PY 2019
VL 224
IS 6
BP 2199
EP 2211
DI 10.1007/s00429-019-01902-z
PG 13
WC Anatomy & Morphology; Neurosciences
SC Anatomy & Morphology; Neurosciences & Neurology
GA IF2DO
UT WOS:000472887900016
PM 31177297
DA 2021-02-24
ER

PT J
AU Caffarra, S
   Martin, CD
AF Caffarra, Sendy
   Martin, Clara D.
TI Not all errors are the same: ERP sensitivity to error typicality in
   foreign accented speech perception
SO CORTEX
LA English
DT Article; Proceedings Paper
CT 10th International Morphological Processing Conference (MoProc)
CY JUN 22-24, 2017
CL SISSA, Trieste, ITALY
HO SISSA
DE Foreign accent; Sentence comprehension; Morphosyntax; ERP
ID SYNTAX; ACTIVATION; RETRIEVAL; FREQUENCY; SPEAKER; GENDER
AB Intercultural communication has become more and more frequent in the recent globalized society. When native listeners try to understand non-native speakers, they have to deal with different types of grammatical errors, some being frequently encountered and others being less common. The present Event-Related Potential (ERP) study investigated how native listeners process different types of morphosyntactic errors in foreign accented speech and whether they are sensitive to error typicality. Spanish natives listened to Spanish sentences in native and foreign (English) accent. ERPs were recorded in response to morphosyntactic violations that were commonly (gender errors) encountered in English accented Spanish or not (number errors). Although sentence comprehension accuracy did not differ across accents, the ERP responses changed as a function of accent and error type. In line with previous studies, gender and number violations in native accented speech elicited LAN-P600 responses. When speech was uttered by foreign speakers, number violations (uncommon errors) showed a P600 effect, while gender violations (common errors) did not elicit late repair processes (reflected by the P600) but an N400 effect. The present results provide evidence that the neural time course of parsing depends not only on speaker's accent, but also on input error typicality. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Caffarra, Sendy; Martin, Clara D.] BCBL, Basque Ctr Cognit Brain & Language, Paseo Mikeletegi 69, Donostia San Sebastian 20009, Spain.
   [Martin, Clara D.] Ikerbasque, Basque Fdn Sci, Bilbao, Spain.
RP Caffarra, S (corresponding author), BCBL, Basque Ctr Cognit Brain & Language, Paseo Mikeletegi 69, Donostia San Sebastian 20009, Spain.
EM s.caffarra@bcbl.eu
RI Caffarra, Sendy/P-9126-2019
OI Caffarra, Sendy/0000-0003-3667-5061
FU European Research CouncilEuropean Research Council (ERC)European
   Commission [ERC-2011-ADG_20110406, 613465-AThEME]; Spanish Ministry of
   Economy and Competitiveness [SEV-2015-490]; Spanish GovernmentSpanish
   GovernmentEuropean Commission [PSI 2014-54500]; Basque GovernmentBasque
   Government [PI_2015_1_25]
FX This work was supported by the European Research Council
   (ERC-2011-ADG_20110406, 613465-AThEME); the Spanish Ministry of Economy
   and Competitiveness (SEV-2015-490); the Spanish Government (PSI
   2014-54500); and the Basque Government (PI_2015_1_25). The authors wish
   to thank Sarah Perret for her help during the normative ratings, and
   Sarah Guediche and Nicola Molinaro for reviewing the manuscript and
   giving insightful comments on this work.
CR Barber H, 2005, J COGNITIVE NEUROSCI, V17, P137, DOI 10.1162/0898929052880101
   Batterink L, 2013, J NEUROSCI, V33, P8528, DOI 10.1523/JNEUROSCI.0618-13.2013
   Brouwer H, 2012, BRAIN RES, V1446, P127, DOI 10.1016/j.brainres.2012.01.055
   Caffarra S, 2015, NEUROSCI BIOBEHAV R, V51, P31, DOI 10.1016/j.neubiorev.2015.01.010
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Coulson S, 1998, LANG COGNITIVE PROC, V13, P21, DOI 10.1080/016909698386582
   Dube S, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01276
   Duchon A, 2013, BEHAV RES METHODS, V45, P1246, DOI 10.3758/s13428-013-0326-1
   Ferreira F, 1996, J EXP PSYCHOL LEARN, V22, P324, DOI 10.1037/0278-7393.22.2.324
   Ferreira F, 2002, CURR DIR PSYCHOL SCI, V11, P11, DOI 10.1111/1467-8721.00158
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Foote R, 2015, SECOND LANG RES, V31, P343, DOI 10.1177/0267658314565691
   Franceschina Florencia, 2005, FOSSILIZED 2 LANGUAG
   Franceschini Florencia, 2001, SECOND LANG RES, V17, P213, DOI DOI 10.1177/026765830101700301
   Fraundorf SH, 2016, J MEM LANG, V91, P28, DOI 10.1016/j.jml.2016.05.006
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8
   FRIEDERICI AD, 1993, COGNITIVE BRAIN RES, V1, P183, DOI 10.1016/0926-6410(93)90026-2
   FRIEDERICI AD, 1995, BRAIN LANG, V50, P259, DOI 10.1006/brln.1995.1048
   GASS S, 1984, LANG LEARN, V34, P115, DOI 10.1111/j.1467-1770.1984.tb01007.x
   Goslin J, 2012, BRAIN LANG, V122, P92, DOI 10.1016/j.bandl.2012.04.017
   Greenberg Joseph H., 1963, UNIVERSALS LANGUAGE, pxv
   Grey S, 2017, J NEUROLINGUIST, V42, P93, DOI 10.1016/j.jneuroling.2016.12.001
   Gunter TC, 2000, J COGNITIVE NEUROSCI, V12, P556, DOI 10.1162/089892900562336
   Gunter TC, 1997, PSYCHOPHYSIOLOGY, V34, P660, DOI 10.1111/j.1469-8986.1997.tb02142.x
   Hagoort P., 1999, NEUROCOGNITION LANGU, P273, DOI DOI 10.1093/ACPROF:OSO/9780198507932.001.0001
   Hahne A, 1999, J COGNITIVE NEUROSCI, V11, P194, DOI 10.1162/089892999563328
   Hahne A, 2001, J PSYCHOLINGUIST RES, V30, P251, DOI 10.1023/A:1010490917575
   Hanulikova A, 2012, J COGNITIVE NEUROSCI, V24, P878, DOI 10.1162/jocn_a_00103
   JESCHENIAK JD, 1994, J EXP PSYCHOL LEARN, V20, P824, DOI 10.1037/0278-7393.20.4.824
   Kleinschmidt D., 2012, P 34 ANN C COGN SCI, P605
   Kroll J., 2005, HDB BILINGUALISM PSY
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Lemhofer K, 2012, BEHAV RES METHODS, V44, P325, DOI 10.3758/s13428-011-0146-0
   Lev-Ari S, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01546
   Luka BJ, 2005, J MEM LANG, V52, P436, DOI 10.1016/j.jml.2005.01.013
   Mariko A., 2007, EC J TAKASAKI U EC, V49, P117
   MITCHELL DC, 1995, J PSYCHOLINGUIST RES, V24, P469, DOI 10.1007/BF02143162
   Molinaro N, 2011, CORTEX, V47, P908, DOI 10.1016/j.cortex.2011.02.019
   Nieuwland MS, 2014, J MEM LANG, V76, P1, DOI 10.1016/j.jml.2014.06.002
   Osterhout L, 2004, ON-LINE STUDY OF SENTENCE COMPREHENSION, P271
   ROELOFS A, 1992, COGNITION, V42, P107, DOI 10.1016/0010-0277(92)90041-F
   Roll M, 2010, BRAIN RES, V1330, P114, DOI 10.1016/j.brainres.2010.03.020
   Romero-Rivas C, 2016, NEUROPSYCHOLOGIA, V85, P245, DOI 10.1016/j.neuropsychologia.2016.03.022
   Rossi S, 2006, J COGNITIVE NEUROSCI, V18, P2030, DOI 10.1162/jocn.2006.18.12.2030
   Saito K, 2016, APPL PSYCHOLINGUIST, V37, P217, DOI 10.1017/S0142716414000502
   Schmidt-Kassow M, 2008, BRAIN RES, V1226, P144, DOI 10.1016/j.brainres.2008.06.017
   Steinhauer K, 2009, SECOND LANG RES, V25, P13, DOI 10.1177/0267658308098995
   Tanner D, 2014, NEUROPSYCHOLOGIA, V56, P289, DOI 10.1016/j.neuropsychologia.2014.02.002
   Thothathiri M, 2008, COGNITION, V108, P51, DOI 10.1016/j.cognition.2007.12.012
   Van Berkum JJA, 2008, J COGNITIVE NEUROSCI, V20, P580, DOI 10.1162/jocn.2008.20054
   de Meerendonk N, 2009, LANG LINGUIST COMPAS, V3, DOI 10.1111/j.1749-818x.2009.00163.x
   Van der Meij M, 2011, PSYCHOPHYSIOLOGY, V48, P44, DOI 10.1111/j.1469-8986.2010.01039.x
   Viebahn MC, 2017, J COGNITIVE NEUROSCI, V29, P1132, DOI 10.1162/jocn_a_01095
   WeberFox CM, 1996, J COGNITIVE NEUROSCI, V8, P231, DOI 10.1162/jocn.1996.8.3.231
   White L., 2003, 2 LANGUAGE ACQUISITI, P58
NR 55
TC 8
Z9 8
U1 0
U2 16
PU ELSEVIER MASSON, CORP OFF
PI PARIS
PA 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE
SN 0010-9452
EI 1973-8102
J9 CORTEX
JI Cortex
PD JUL
PY 2019
VL 116
SI SI
BP 308
EP 320
DI 10.1016/j.cortex.2018.03.007
PG 13
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA IF1BQ
UT WOS:000472812500020
PM 29657069
DA 2021-02-24
ER

PT J
AU Berdasco-Munoz, E
   Nazzi, T
   Yeung, HH
AF Berdasco-Munoz, Elena
   Nazzi, Thierry
   Yeung, H. Henny
TI Visual Scanning of a Talking Face in Preterm and Full-Term Infants
SO DEVELOPMENTAL PSYCHOLOGY
LA English
DT Article
DE preterm infants; eyes; mouth; audiovisual speech perception; development
ID SELECTIVE ATTENTION; SPEECH-PERCEPTION; 1ST YEAR; LANGUAGE
   DISCRIMINATION; DEVELOPMENTAL-CHANGES; 12-MONTH-OLD INFANTS; EARLY
   SEGMENTATION; 2ND YEAR; MOUTH; BEHAVIOR
AB Preterm birth (<37 gestational weeks) is associated with long-term risks for health and neurodevelopment, but recently, studies have also started exploring how preterm birth affects early language development in the 1st year of life. Because the timing and quality of auditory and visual input is very different for preterm versus full-term infants, audiovisual speech perception in early development may be particularly sensitive to preterm birth. We tested extremely preterm to late preterm infants at 8 months postnatal age (28 to 36 weeks of gestation), as well as 2 full-term comparison groups with similar postnatal (8 months) and maturational (6 months) ages, on visual scanning of a video showing a French-English bilingual woman speaking in the infants' native language (French) and a nonnative language (English). Preterm infants showed similar scanning patterns for both languages, failing to differentiate between native and nonnative languages in their looking, unlike both groups of full-term infants, who looked more to the eyes than the mouth for the native language compared with the nonnative language. No clear relationship between scanning patterns and degree of prematurity was found. These findings are the first to show that audiovisual speech perception is affected in even later-born preterm infants, thus identifying a particularly sensitive deficit in early speech processing. Further research will need to investigate how preterms' special vulnerability in audiovisual speech processing may contribute to the other language difficulties found in these populations.
C1 [Berdasco-Munoz, Elena; Nazzi, Thierry] Paris Descartes Univ, Integrat Neurosci & Cognit Ctr, Paris, France.
   [Nazzi, Thierry; Yeung, H. Henny] CNRS, Integrat Neurosci & Cognit Ctr, Paris, France.
   [Yeung, H. Henny] Simon Fraser Univ, Dept Linguist, Burnaby, BC, Canada.
RP Berdasco-Munoz, E (corresponding author), Univ Paris 05, Sorbonne Paris Cite, Integrat Neurosci & Cognit Ctr, 45 Rue St Peres, F-75270 Paris, France.
EM elenaberdascomunoz@gmail.com
OI Nazzi, Thierry/0000-0002-4378-3661; Yeung, Henny/0000-0003-4601-6924
FU Agence Nationale de la Recherche Blanche Grant [ANR-13-BSH2-0004];
   Labex-Empirical Foundations of Linguistics [ANR-10-LABX-0083]
FX This study was supported by Agence Nationale de la Recherche Blanche
   Grant ANR-13-BSH2-0004 to Thierry Nazzi and Labex-Empirical Foundations
   of Linguistics (ANR-10-LABX-0083) grant to Elena Berdasco-Munoz, Thierry
   Nazzi, and H. Henny Yeung.
CR Abboub N, 2015, J EXP CHILD PSYCHOL, V132, P111, DOI 10.1016/j.jecp.2014.12.004
   Altvater-Mackensen N, 2016, DEV PSYCHOL, V52, P191, DOI 10.1037/a0039964
   Aylward GP, 2014, J DEV BEHAV PEDIATR, V35, P394, DOI 10.1097/01.DBP.0000452240.39511.d4
   Ayneto A, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12446
   Bahrick LE, 2000, DEV PSYCHOL, V36, P190, DOI 10.1037//0012-1649.36.2.190
   Barenholtz E, 2016, COGNITION, V147, P100, DOI 10.1016/j.cognition.2015.11.013
   Berdasco-Munoz E, 2018, INFANCY, V23, P268, DOI 10.1111/infa.12217
   Bijeljac-Babic R, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030843
   Birules J, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12755
   Bosch L, 2011, PROG BRAIN RES, V189, P239, DOI 10.1016/B978-0-444-53884-0.00028-2
   Buchan JN, 2007, SOC NEUROSCI-UK, V2, P1, DOI 10.1080/17470910601043644
   Cave C, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P2175, DOI 10.1109/ICSLP.1996.607235
   Cvejic E, 2012, COGNITION, V122, P442, DOI 10.1016/j.cognition.2011.11.013
   Danielson DK, 2017, COGNITIVE DEV, V42, P37, DOI 10.1016/j.cogdev.2017.02.004
   de Boisferon AH, 2018, J EXP CHILD PSYCHOL, V172, P189, DOI 10.1016/j.jecp.2018.03.009
   Gogate L, 2014, J SPEECH LANG HEAR R, V57, P187, DOI 10.1044/1092-4388(2013/12-0403)
   Gonzalez-Gomez N, 2012, DEVELOPMENTAL SCI, V15, P885, DOI 10.1111/j.1467-7687.2012.01186.x
   GOTTLIEB G, 1968, Q REV BIOL, V43, P148, DOI 10.1086/405726
   Gottlieb G, 1971, BIOPSYCHOLOGY DEV, P67
   Goyet L, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0079646
   Granstrom B, 2005, SPEECH COMMUN, V46, P473, DOI 10.1016/j.specom.2005.02.017
   Green JR, 2010, J SPEECH LANG HEAR R, V53, P1529, DOI 10.1044/1092-4388(2010/09-0005)
   Herold B, 2008, DEV MED CHILD NEUROL, V50, P678, DOI 10.1111/j.1469-8749.2008.03055.x
   Hohle B, 2009, INFANT BEHAV DEV, V32, P262, DOI 10.1016/j.infbeh.2009.03.004
   Hoonhorst I, 2009, J EXP CHILD PSYCHOL, V104, P353, DOI 10.1016/j.jecp.2009.07.005
   Hunnius S, 2004, INFANCY, V6, P231, DOI 10.1207/s15327078in0602_5
   Imafuku M, 2019, EARLY HUM DEV, V128, P93, DOI 10.1016/j.earlhumdev.2018.11.001
   Jusczyk PW, 1999, COGNITIVE PSYCHOL, V39, P159, DOI 10.1006/cogp.1999.0716
   JUSCZYK PW, 1995, COGNITIVE PSYCHOL, V29, P1, DOI 10.1006/cogp.1995.1010
   Kabdebon C, 2015, BRAIN LANG, V148, P25, DOI 10.1016/j.bandl.2015.03.005
   Karmiloff-Smith A, 1998, TRENDS COGN SCI, V2, P389, DOI 10.1016/S1364-6613(98)01230-3
   Kern S., 2007, FIRST LANG, V27, P159, DOI 10.1177/
   Kubicek C, 2013, INT J BEHAV DEV, V37, P106, DOI 10.1177/0165025412473016
   Kushnerenko E, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00432
   Lansing CR, 1999, J SPEECH LANG HEAR R, V42, P526, DOI 10.1044/jslhr.4203.526
   Letourneau SM, 2011, PERCEPTION, V40, P563, DOI 10.1068/p6858
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Lusk LG, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00052
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Navarra J, 2012, NEW HDB MULTISENSORY, P435
   Navarra J, 2014, ACTA PSYCHOL, V151, P197, DOI 10.1016/j.actpsy.2014.05.021
   Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037/0096-1523.24.3.756
   Nazzi T, 2006, J MEM LANG, V54, P283, DOI 10.1016/j.jml.2005.10.004
   Nelson CA, 2011, MONOGR SOC RES CHILD, V76, P127, DOI 10.1111/j.1540-5834.2011.00630.x
   Nishibayashi LL, 2015, LANG SPEECH, V58, P334, DOI 10.1177/0023830914551375
   Pena M, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01708
   Pena M, 2014, PSYCHOL SCI, V25, P1884, DOI 10.1177/0956797614544307
   Pena M, 2010, P NATL ACAD SCI USA, V107, P3823, DOI 10.1073/pnas.0914326107
   Perszyk DR, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12522
   PICKENS J, 1994, INFANT BEHAV DEV, V17, P447, DOI 10.1016/0163-6383(94)90036-1
   Pons F, 2019, INFANT BEHAV DEV, V54, P80, DOI 10.1016/j.infbeh.2018.12.003
   Pons F, 2015, PSYCHOL SCI, V26, P490, DOI 10.1177/0956797614568320
   Richards JE, 2010, DEV REV, V30, P203, DOI 10.1016/j.dr.2010.03.005
   Scarborough R, 2009, LANG SPEECH, V52, P135, DOI 10.1177/0023830909103165
   Skoruppa K, 2009, DEVELOPMENTAL SCI, V12, P914, DOI 10.1111/j.1467-7687.2009.00835.x
   Soto-Faraco S, 2007, PERCEPT PSYCHOPHYS, V69, P218, DOI 10.3758/BF03193744
   Spierer A, 2004, OPHTHALMOLOGICA, V218, P397, DOI 10.1159/000080943
   Streri A, 2016, INFANCY, V21, P177, DOI 10.1111/infa.12104
   SUMMERFIELD Q, 1992, PHILOS T ROY SOC B, V335, P71, DOI 10.1098/rstb.1992.0009
   Telford EJ, 2016, J CHILD PSYCHOL PSYC, V57, P861, DOI 10.1111/jcpp.12546
   Tenenbaum EJ, 2015, J CHILD LANG, V42, P1173, DOI 10.1017/S0305000914000725
   Tenenbaum EJ, 2013, INFANCY, V18, P534, DOI 10.1111/j.1532-7078.2012.00135.x
   Therien JM, 2004, DEV MED CHILD NEUROL, V46, P816, DOI 10.1017/S0012162204001434
   Tomalski P, 2013, EUR J DEV PSYCHOL, V10, P611, DOI 10.1080/17405629.2012.728076
   Tsang T, 2018, J EXP CHILD PSYCHOL, V169, P93, DOI 10.1016/j.jecp.2018.01.002
   TURKEWITZ G, 1982, DEV PSYCHOBIOL, V15, P357, DOI 10.1002/dev.420150408
   TURKEWITZ G, 1985, J DEV BEHAV PEDIATR, V6, P302
   Vatikiotis-Bateson E, 1998, PERCEPT PSYCHOPHYS, V60, P926, DOI 10.3758/BF03211929
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   World Health Organization, 2012, BORN TOO SOON GLOBAL
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
   Yeung HH, 2013, PSYCHOL SCI, V24, P603, DOI 10.1177/0956797612458802
   Young GS, 2009, DEVELOPMENTAL SCI, V12, P798, DOI 10.1111/j.1467-7687.2009.00833.x
NR 74
TC 1
Z9 1
U1 0
U2 9
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0012-1649
EI 1939-0599
J9 DEV PSYCHOL
JI Dev. Psychol.
PD JUL
PY 2019
VL 55
IS 7
BP 1353
EP 1361
DI 10.1037/dev0000737
PG 9
WC Psychology, Developmental
SC Psychology
GA IE1NP
UT WOS:000472152900001
PM 31070435
DA 2021-02-24
ER

PT J
AU Hernaandez, M
   Ventura-Campos, N
   Costa, A
   Miroo-Padilla, A
   Avila, C
AF Hernandez, Mireia
   Ventura-Campos, Noelia
   Costa, Albert
   Miro-Padilla, Anna
   Avila, Cesar
TI Brain networks involved in accented speech processing
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Accented speech; Brain networks; fMRI; ICA; Regional accent; Speech
   perception
ID ANTERIOR TEMPORAL INVOLVEMENT; BILINGUAL LANGUAGE PRODUCTION; CEREBELLAR
   CONTRIBUTIONS; INDEPENDENT COMPONENTS; FOREIGN ACCENT; PERCEPTION;
   2ND-LANGUAGE; REGIONS; CONNECTIVITY; ARTICULATION
AB We investigated the neural correlates of accented speech processing (ASP) with an fMRI study that overcame prior limitations in this line of research: we preserved intelligibility by using two regional accents that differ in prosody but only mildly in phonetics (Latin American and Castilian Spanish), and we used independent component analysis to identify brain networks as opposed to isolated regions. ASP engaged a speech perception network composed primarily of structures related with the processing of prosody (cerebellum, putamen, and thalamus). This network also included anterior fronto-temporal areas associated with lexical-semantic processing and a portion of the inferior frontal gyrus linked to executive control. ASP also recruited domain-general executive control networks related with cognitive demands (dorsal attentional and default mode networks) and the processing of salient events (salience network). Finally, the reward network showed a preference for the native accent, presumably revealing people's sense of social belonging.
C1 [Hernandez, Mireia] Univ Barcelona, Inst Neurociencies, Dept Cognit Dev & Educ Psychol, Sect Cognit Proc, Barcelona, Spain.
   [Hernandez, Mireia] Bellvitge Biomed Res Inst IDIBELL, Cognit & Brain Plast Grp, Barcelona, Spain.
   [Ventura-Campos, Noelia; Miro-Padilla, Anna; Avila, Cesar] Univ Jaume 1, Dept Basic Psychol Clin Psychol & Psychobiol, Neuropsychol & Funct Imaging Grp, Castellon de La Plana, Spain.
   [Ventura-Campos, Noelia] Univ Jaume 1, Dept Educ & Specif Didact, Castellon de La Plana, Spain.
   [Costa, Albert] Univ Pompeu Fabra, Ctr Brain & Cognit, Barcelona, Spain.
   [Costa, Albert] ICREA, Barcelona, Spain.
RP Hernaandez, M (corresponding author), Univ Barcelona, Dept Cognit Dev & Educ Psychol, Sect Cognit Proc, Passeig Vall dHebron 171, Barcelona 08035, Spain.
EM mireiahemandez@ub.edu
RI Hernandez, Mireia/D-6812-2014; Avila, Cesar/B-4370-2011; Miro-Padilla,
   Anna/L-6193-2014; Campos, Noelia Ventura/L-4877-2014
OI Hernandez, Mireia/0000-0001-6819-3636; Avila, Cesar/0000-0002-5840-605X;
   Miro-Padilla, Anna/0000-0002-6004-7439; Campos, Noelia
   Ventura/0000-0002-0443-8048
FU Ramon y Cajal research program of the Spanish Ministry of Science,
   Innovation and Universities [RYC-2016-19477]; MINECO [PSI2016-78805-R];
   Jaume I University [UJI-A2017-8]
FX This work was supported by the Ramon y Cajal research program of the
   Spanish Ministry of Science, Innovation, and Universities
   (RYC-2016-19477 to MH), the MINECO (grant PSI2016-78805-R to CA), and
   Jaume I University (grant UJI-A2017-8 to NVC; pre-doctoral grant FPI to
   AMP).
CR Abou-Elseoud A, 2010, HUM BRAIN MAPP, V31, P1207, DOI 10.1002/hbm.20929
   Abutalebi J, 2008, LANG COGNITIVE PROC, V23, P557, DOI 10.1080/01690960801920602
   Abutalebi J, 2007, J NEUROLINGUIST, V20, P242, DOI 10.1016/j.jneuroling.2006.10.003
   Abutalebi J, 2013, BRAIN LANG, V125, P307, DOI 10.1016/j.bandl.2012.03.009
   Abutalebi J, 2012, CEREB CORTEX, V22, P2076, DOI 10.1093/cercor/bhr287
   Ackermann H, 2008, TRENDS NEUROSCI, V31, P265, DOI 10.1016/j.tins.2008.02.011
   Ackermann H, 2007, CEREBELLUM, V6, P202, DOI 10.1080/14734220701266742
   Adank P, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00558
   Adank P, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00634
   Adank P, 2012, NEUROPSYCHOLOGIA, V50, P77, DOI 10.1016/j.neuropsychologia.2011.10.024
   Adank P, 2012, HUM BRAIN MAPP, V33, P360, DOI 10.1002/hbm.21218
   Adank P, 2010, PSYCHOL AGING, V25, P736, DOI 10.1037/a0020054
   Allen EA, 2011, FRONT SYST NEUROSCI, V5, DOI 10.3389/fnsys.2011.00002
   ANDERSONHSIEH J, 1988, LANG LEARN, V38, P561, DOI 10.1111/j.1467-1770.1988.tb00167.x
   Avila C, 2004, NEUROREPORT, V15, P2267, DOI 10.1097/00001756-200410050-00025
   Banks B, 2015, J ACOUST SOC AM, V137, P2015, DOI 10.1121/1.4916265
   Barros-Loscertales A, 2013, BRAIN LANG, V126, P253, DOI 10.1016/j.bandl.2013.05.009
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   Bestelmeyer PEG, 2015, CEREB CORTEX, V25, P3953, DOI 10.1093/cercor/bhu282
   Brown S, 2009, BRAIN COGNITION, V70, P31, DOI 10.1016/j.bandc.2008.12.006
   Burton T, 2010, ALICE WONDERLAND MOV
   Calhoun VD, 2001, HUM BRAIN MAPP, V14, P140, DOI 10.1002/hbm.1048
   Calhoun VD, 2009, NEUROIMAGE, V45, pS163, DOI 10.1016/j.neuroimage.2008.10.057
   Callan D, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00275
   Callan DE, 2004, NEUROIMAGE, V22, P1182, DOI 10.1016/j.neuroimage.2004.03.006
   Cattaneo L, 2009, ARCH NEUROL-CHICAGO, V66, P557, DOI 10.1001/archneurol.2009.41
   Cohen E, 2012, CURR ANTHROPOL, V53, P588, DOI 10.1086/667654
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Coupland N, 2007, J SOCIOLING, V11, P74, DOI 10.1111/j.1467-9841.2007.00311.x
   Craig-McQuaide A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00884
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Erhardt EB, 2011, HUM BRAIN MAPP, V32, P2075, DOI 10.1002/hbm.21170
   Floccia C, 2006, J EXP PSYCHOL HUMAN, V32, P1276, DOI 10.1037/0096-1523.32.5.1276
   Frances C, 2018, ACTA PSYCHOL, V186, P63, DOI 10.1016/j.actpsy.2018.04.003
   Friederici AD, 2004, BRAIN LANG, V89, P267, DOI 10.1016/S0093-934X(03)00351-1
   Friston KJ, 1994, HUMAN BRAIN MAPPING, V2, P189, DOI DOI 10.1002/HBM.460020402
   Guediche S, 2015, CEREB CORTEX, V25, P1867, DOI 10.1093/cercor/bht428
   Haber SN, 2010, NEUROPSYCHOPHARMACOL, V35, P4, DOI 10.1038/npp.2009.129
   Ham T, 2013, J NEUROSCI, V33, P7091, DOI 10.1523/JNEUROSCI.4692-12.2013
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Himberg J, 2004, NEUROIMAGE, V22, P1214, DOI 10.1016/j.neuroimage.2004.03.027
   HOLM S, 1979, SCAND J STAT, V6, P65
   Hualde J. I., 2015, INTONATION ROMANCE, P350, DOI DOI 10.1093/ACPROF:OSO/9780199685332.003.0010
   Ivry R B, 1989, J Cogn Neurosci, V1, P136, DOI 10.1162/jocn.1989.1.2.136
   KLEIN D, 1994, NEUROREPORT, V5, P2295, DOI 10.1097/00001756-199411000-00022
   Lee YS, 2012, J NEUROSCI, V32, P3942, DOI 10.1523/JNEUROSCI.3814-11.2012
   Lev-Ari S, 2010, J EXP SOC PSYCHOL, V46, P1093, DOI 10.1016/j.jesp.2010.05.025
   Li YO, 2007, HUM BRAIN MAPP, V28, P1251, DOI 10.1002/hbm.20359
   Ludbrook J, 1998, CLIN EXP PHARMACOL P, V25, P1032, DOI 10.1111/j.1440-1681.1998.tb02179.x
   Mason MF, 2007, SCIENCE, V315, P393, DOI 10.1126/science.1131295
   Menon V., 2015, BRAIN MAPPING PP, P597, DOI [10.1016/B978-0-12-397025-1.00052-X., DOI 10.1016/B978-0-12-397025-1.00052-X]
   Meyer M, 2004, BRAIN LANG, V89, P277, DOI 10.1016/S0093-934X(03)00350-X
   Munro MJ, 1995, LANG SPEECH, V38, P289, DOI 10.1177/002383099503800305
   Myers EB, 2009, PSYCHOL SCI, V20, P895, DOI 10.1111/j.1467-9280.2009.02380.x
   Nee DE, 2013, CEREB CORTEX, V23, P264, DOI 10.1093/cercor/bhs007
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Prieto P., 2010, SPEECH PROSODY
   Prieto P., 2013, INTONATIONAL VARIATI, P392
   Sambataro F, 2010, NEUROPSYCHOPHARMACOL, V35, P904, DOI 10.1038/npp.2009.192
   Sammler D, 2015, CURR BIOL, V25, P3079, DOI 10.1016/j.cub.2015.10.009
   Sammler D, 2010, BRAIN, V133, P2643, DOI 10.1093/brain/awq231
   Schwartz MF, 2009, BRAIN, V132, P3411, DOI 10.1093/brain/awp284
   Seeley WW, 2007, J NEUROSCI, V27, P2349, DOI 10.1523/JNEUROSCI.5587-06.2007
   Segall JM, 2012, FRONT NEUROINFORM, V6, DOI 10.3389/fninf.2012.00010
   Seidl A, 2012, FRONT PSYCHOL, V3, DOI [10.3389/fpsyg.2012.00448, 10.3389/fpsyg.2012.00479]
   Vatansever D, 2015, NEUROIMAGE, V122, P96, DOI 10.1016/j.neuroimage.2015.07.053
   Venezia JH, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00157
   Walker GM, 2011, BRAIN LANG, V117, P110, DOI 10.1016/j.bandl.2010.09.008
   Wise RJS, 1999, LANCET, V353, P1057, DOI 10.1016/S0140-6736(98)07491-1
   Xu J., 2013, FRONTIERS NEUROSCIEN, V7, P54
   Ye Z, 2014, HUM BRAIN MAPP, V35, P367, DOI 10.1002/hbm.22182
   Yi HG, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00768
NR 72
TC 4
Z9 4
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD JUL
PY 2019
VL 194
BP 12
EP 22
DI 10.1016/j.bandl.2019.03.003
PG 11
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA ID5SI
UT WOS:000471735900002
PM 30959385
OA Green Published
DA 2021-02-24
ER

PT J
AU Zhao, TC
   Masapollo, M
   Polka, L
   Menard, L
   Kuhl, PK
AF Zhao, T. Christina
   Masapollo, Matthew
   Polka, Linda
   Menard, Lucie
   Kuhl, Patricia K.
TI Effects of formant proximity and stimulus prototypicality on the neural
   discrimination of vowels: Evidence from the auditory frequency-following
   response
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Speech perception; Focal vowels; Natural Referent Vowel framework;
   Native Language Magnet model; Auditory frequency-following response
ID BRAIN-STEM; SPEECH-PERCEPTION; UNIVERSAL BIAS; CATEGORIES; LANGUAGE;
   REPRESENTATION; ASYMMETRIES; PLASTICITY; EXPERIENCE; DYNAMICS
AB Cross-language speech perception experiments indicate that for many vowel contrasts, discrimination is easier when the same pair of vowels is presented in one direction compared to the reverse direction. According to one account, these directional asymmetries reflect a universal bias favoring "focal" vowels (i.e., vowels with prominent spectral peaks formed by the convergence of adjacent formants). An alternative account is that such effects reflect an experience-dependent bias favoring prototypical exemplars of native-language vowel categories. Here, we tested the predictions of these accounts by recording the auditory frequency-following response in English-speaking listeners to two synthetic variants of the vowel /u/ that differed in the proximity of their first and second formants and prototypicality, with stimuli arranged in oddball and reversed-oddball blocks. Participants showed evidence of neural discrimination when the more-focal/less-prototypic /u/ served as the deviant stimulus, but not when the less-focal/more-prototypic /u/ served as the deviant, consistent with the focalization account.
C1 [Zhao, T. Christina; Kuhl, Patricia K.] Univ Washington, Inst Learning & Brain Sci, Portage Bay Bldg,Box 357988, Seattle, WA 98195 USA.
   [Masapollo, Matthew] Boston Univ, Dept Speech Language & Hearing Sci, 635 Commonwealth Ave, Boston, MA 02215 USA.
   [Polka, Linda] McGill Univ, Sch Commun Sci & Disorders, 2001 McGill Coll,8th Floor, Montreal, PQ H3A 1G1, Canada.
   [Menard, Lucie] Univ Quebec, Dept Linguist, 320 St Catherine East, Montreal, PQ H2X 1L7, Canada.
RP Zhao, TC (corresponding author), Univ Washington, Inst Learning & Brain Sci, Portage Bay Bldg,Box 357988, Seattle, WA 98195 USA.
EM zhaotc@uw.edu; mmasapol@bu.edu; linda.polka@mcgill.ca;
   menard.lucie@uqam.ca; pkkuhl@uw.edu
FU Ready Mind Project at the University of Washington's Institute for
   Learning and Brain Sciences; NIHUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USA [R01 DC002852];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC002852, R01DC002852, R01DC002852,
   R01DC002852, R01DC002852] Funding Source: NIH RePORTER
FX The research reported here was supported by the Ready Mind Project at
   the University of Washington's Institute for Learning and Brain
   Sciences. Matthew Masapollo was also supported by NIH grant R01 DC002852
   (Frank H. Guenther, principal investigator) during the preparation and
   revision of the manuscript. We are grateful to Gloria Lam at the
   University of Washington for assistance with participant recruitment and
   data-collection. This work benefited from helpful discussions with, or
   comments from, Frank H. Guenther, Bharath Chandrasekaran, Pascale
   Tremblay, Caroline A. Niziolek, Tyler K. Perrachione, and Sung-Joo Lim.
CR Aiken SJ, 2008, HEARING RES, V245, P35, DOI 10.1016/j.heares.2008.08.004
   Bidelman GM, 2018, NEUROIMAGE, V175, P56, DOI 10.1016/j.neuroimage.2018.03.060
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Coffey EBJ, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11070
   Cutler A, 2012, NATIVE LISTENING LAN
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dufour S, 2013, J PSYCHOLINGUIST RES, V42, P161, DOI 10.1007/s10936-012-9212-8
   Easwar V, 2015, HEARING RES, V320, P38, DOI 10.1016/j.heares.2014.11.008
   Escera C, 2017, SPRINGER HANDB AUDIT, V61, P101, DOI 10.1007/978-3-319-47944-6_5
   Feldman NH, 2009, PSYCHOL REV, V116, P752, DOI 10.1037/a0017196
   Gage N, 1998, BRAIN RES, V814, P236, DOI 10.1016/S0006-8993(98)01058-0
   Guenther FH, 1999, J ACOUST SOC AM, V106, P2900, DOI 10.1121/1.428112
   Guenther FH, 2004, J SPEECH LANG HEAR R, V47, P46, DOI 10.1044/1092-4388(2004/005)
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   Intartaglia B, 2016, NEUROPSYCHOLOGIA, V89, P57, DOI 10.1016/j.neuropsychologia.2016.05.033
   Kent R.D, 2002, ACOUSTIC ANAL SPEECH
   Krishnan A, 2002, HEARING RES, V166, P192, DOI 10.1016/S0378-5955(02)00327-1
   Kuhl P. K., 1995, SPEECH PERCEPTION LI, P121
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Lahiri A, 2002, PHONOL PHONET, V4-1, P637
   LINDBLOM B, 1989, J PHONETICS, V17, P107, DOI 10.1016/S0095-4470(19)31516-5
   Liu Y. Y, DISENTANGLING UNPUB
   Marion V, 2007, J SPEECH LANG HEAR R, V50, P940, DOI 10.1044/1092-4388(2007/067)
   Masapollo M, 2019, J EXP PSYCHOL HUMAN, V45, P285, DOI 10.1037/xhp0000603
   Masapollo M, 2017, COGNITION, V166, P358, DOI 10.1016/j.cognition.2017.06.001
   Masapollo M, 2017, J ACOUST SOC AM, V141, P2857, DOI 10.1121/1.4981006
   Menard L, 2004, J SPEECH LANG HEAR R, V47, P1059, DOI 10.1044/1092-4388(2004/079)
   Miller JL, 1996, PERCEPT PSYCHOPHYS, V58, P1157, DOI 10.3758/BF03207549
   Molnar M, 2014, BILING-LANG COGN, V17, P526, DOI 10.1017/S136672891300062X
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Nam Y.W., 2014, THESIS
   Nam YJ, 2016, COGNITION, V155, P57, DOI 10.1016/j.cognition.2016.06.005
   Polka L, 2003, SPEECH COMMUN, V41, P221, DOI 10.1016/S0167-6393(02)00105-X
   Polka L, 2019, SOUND APPROACH LANGU, P561
   Polka L, 2011, J PHONETICS, V39, P467, DOI 10.1016/j.wocn.2010.08.007
   Schwartz JL, 2005, SPEECH COMMUN, V45, P425, DOI 10.1016/j.specom.2004.12.001
   SCHWARTZ JL, 1989, SPEECH COMMUN, V8, P235, DOI 10.1016/0167-6393(89)90004-6
   Shiga T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136794
   Skoe E, 2015, CEREB CORTEX, V25, P1415, DOI 10.1093/cercor/bht311
   Skoe E, 2014, NEUROBIOL LEARN MEM, V109, P82, DOI 10.1016/j.nlm.2013.11.011
   Skoe E, 2010, EAR HEARING, V31, P302, DOI 10.1097/AUD.0b013e3181cdb272
   Slabu L, 2012, J NEUROSCI, V32, P1447, DOI 10.1523/JNEUROSCI.2557-11.2012
   STEVENS KN, 1989, J PHONETICS, V17, P3, DOI 10.1016/S0095-4470(19)31520-7
   Stevens KN, 1998, ACOUSTIC PHONETICS
   Thomson JM, 2009, BRAIN RES, V1254, P74, DOI 10.1016/j.brainres.2008.11.087
   Tichko P, 2017, HEARING RES, V348, P1, DOI 10.1016/j.heares.2017.01.014
   Tsuji S, 2017, INTERSPEECH, P2108, DOI 10.21437/Interspeech.2017-1468
   Zhao TC, 2018, P NATL ACAD SCI USA, V115, P8716, DOI 10.1073/pnas.1800186115
NR 50
TC 1
Z9 1
U1 1
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD JUL
PY 2019
VL 194
BP 77
EP 83
DI 10.1016/j.bandl.2019.05.002
PG 7
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA ID5SI
UT WOS:000471735900008
PM 31129300
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Fecher, N
   Johnson, EK
AF Fecher, Natalie
   Johnson, Elizabeth K.
TI Bilingual infants excel at foreign-language talker recognition
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
DE bilingualism; cognitive development; infant speech perception; language
   acquisition; talker recognition
ID ADVANTAGE; PERCEPTION
AB Bilingual and monolingual infants differ in how they process linguistic aspects of the speech signal. But do they also differ in how they process non-linguistic aspects of speech, such as who is talking? Here, we addressed this question by testing Canadian monolingual and bilingual 9-month-olds on their ability to learn to identify native Spanish-speaking females in a face-voice matching task. Importantly, neither group was familiar with Spanish prior to participating in the study. In line with our predictions, bilinguals succeeded in learning the face-voice pairings, whereas monolinguals did not. We consider multiple explanations for this finding, including the possibility that simultaneous bilingualism enhances perceptual attentiveness to talker-specific speech cues in infancy (even in unfamiliar languages), and that early bilingualism delays perceptual narrowing to language-specific talker recognition cues. This work represents the first evidence that multilingualism in infancy affects the processing of non-linguistic aspects of the speech signal, such as talker identity.
C1 [Fecher, Natalie; Johnson, Elizabeth K.] Univ Toronto Mississauga, Dept Psychol, 3359 Mississauga Rd, Mississauga, ON L5L 1C6, Canada.
RP Johnson, EK (corresponding author), Univ Toronto Mississauga, Dept Psychol, 3359 Mississauga Rd, Mississauga, ON L5L 1C6, Canada.
EM elizabeth.johnson@utoronto.ca
OI Johnson, Elizabeth Kay/0000-0002-9941-9949
FU SSHRCSocial Sciences and Humanities Research Council of Canada (SSHRC);
   NSERCNatural Sciences and Engineering Research Council of Canada
   (NSERC); CRCAustralian GovernmentDepartment of Industry, Innovation and
   ScienceCooperative Research Centres (CRC) Programme
FX SSHRC; NSERC; CRC
CR Best C.T., 1994, DEV SPEECH PERCEPTIO, P167
   Brito N, 2014, DEV PSYCHOBIOL, V56, P1156, DOI 10.1002/dev.21188
   Byers-Heinlein K, 2014, DEV PSYCHOBIOL, V56, P274, DOI 10.1002/dev.21167
   Byers-Heinlein K, 2010, PSYCHOL SCI, V21, P343, DOI 10.1177/0956797609360758
   Cohen L. B, 2000, HABIT 2000 NEW PROGR
   Fecher N, 2018, J ACOUST SOC AM, V143, P2409, DOI 10.1121/1.5032199
   Fecher N, 2018, J EXP PSYCHOL LEARN, V44, P1911, DOI 10.1037/xlm0000555
   Johnson EK, 2018, COGNITIVE SCI, V42, P633, DOI 10.1111/cogs.12520
   Johnson EK, 2011, DEVELOPMENTAL SCI, V14, P1002, DOI 10.1111/j.1467-7687.2011.01052.x
   Kovacs AM, 2009, P NATL ACAD SCI USA, V106, P6556, DOI 10.1073/pnas.0811323106
   Kreiman J., 2011, FDN VOICE STUDIES IN
   Levi SV, 2018, BILING-LANG COGN, V21, P523, DOI 10.1017/S1366728917000153
   Liu LQ, 2017, BILING-LANG COGN, V20, P561, DOI 10.1017/S1366728916000183
   Molnar M, 2015, J MEM LANG, V81, P91, DOI 10.1016/j.jml.2015.01.002
   Orena AJ, 2015, COGNITION, V143, P36, DOI 10.1016/j.cognition.2015.06.002
   Paquette-Smith M., 2015, P 18 INT C PHON SCI
   Perrachione TK, 2011, SCIENCE, V333, P595, DOI 10.1126/science.1207327
   Pons F, 2015, PSYCHOL SCI, V26, P490, DOI 10.1177/0956797614568320
   Sebastian-Galles N, 2012, PSYCHOL SCI, V23, P994, DOI 10.1177/0956797612436817
   Sheffert SM, 2002, J EXP PSYCHOL HUMAN, V28, P1447, DOI 10.1037//0096-1523.28.6.1447
   Singh L, 2015, CHILD DEV, V86, P294, DOI 10.1111/cdev.12271
   Werker JF, 1998, DEV PSYCHOL, V34, P1289, DOI 10.1037/0012-1649.34.6.1289
   Yow WQ, 2011, BILING-LANG COGN, V14, P562, DOI 10.1017/S1366728910000404
NR 23
TC 3
Z9 3
U1 1
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD JUL
PY 2019
VL 22
IS 4
AR e12778
DI 10.1111/desc.12778
PG 6
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA ID5KL
UT WOS:000471715200018
PM 30485599
DA 2021-02-24
ER

PT J
AU Goss, SJ
   Tamaoka, K
AF Goss, Seth J.
   Tamaoka, Katsuo
TI Lexical accent perception in highly-proficient L2 Japanese learners: The
   roles of language-specific experience and domain-general resources
SO SECOND LANGUAGE RESEARCH
LA English
DT Article
DE cross-linguistic perception; individual differences; Japanese; lexical
   accent
ID PHONOLOGICAL MEMORY; PITCH; HYPOTHESIS; CONTRASTS; SPEECH
AB This article reports empirical findings on the roles of domain-general resources and language-specific experience in the second language (L2) acquisition of Japanese lexical pitch accent. Sixty-one advanced-proficiency L2 Japanese learners from two first languages (L1s), Mandarin Chinese and Korean, identified and categorized Japanese nouns embedded in short sentences in two aurally-presented tasks. Mixed effects models showed that although the tonal-language Chinese group outperformed non-tonal Korean speakers, L2 lexical knowledge, but not overall proficiency or learning experience, predicted performance on both perception tasks regardless of L1, suggesting that long-term knowledge of L2 phonological structure facilitates perception of lexical-level prosody. Domain-general resources, however, played no predictive role in advanced learners' accent perception. A decision-tree analysis then revealed further divergence in perception accuracy by accent pattern, L1, and task type. Taken together, the results establish a close connection between language learning experience and L2 speech perception at the advanced level, and highlight the complexity inherent in the learning of non-native prosodic categories.
C1 [Goss, Seth J.] Emory Univ, Atlanta, GA 30322 USA.
   [Tamaoka, Katsuo] Nagoya Univ, Nagoya, Aichi, Japan.
RP Goss, SJ (corresponding author), Emory Univ, Dept Russian & East Asian Languages & Cultures, Modern Languages Bldg,532 Kilgo Circle, Atlanta, GA 30322 USA.
EM sethjgoss@emory.edu
OI Goss, Seth/0000-0003-2250-427X
FU Japan Foundation Dissertation Fellowship
FX The author disclosed receipt of the following financial support for the
   research, authorship, and/or publication of this article: The first
   author was supported by a Japan Foundation Dissertation Fellowship while
   conducting this research.
CR Amano S, 2000, NIHONGO GOITOKUSEI S
   Andringa S, 2012, LANG LEARN, V62, P49, DOI 10.1111/j.1467-9922.2012.00706.x
   Asaridou SS, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00321
   Ayusawa T., 2003, J PHONETIC SOC JPN, V7, P47
   Baddeley A, 1998, PSYCHOL REV, V105, P158, DOI 10.1037/0033-295X.105.1.158
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beckman M. E., 1986, PHONOLOGY YB, V3, P255, DOI [DOI 10.1017/S095267570000066X, 10.1017/S095267570000066X]
   Bent T, 2006, J EXP PSYCHOL HUMAN, V32, P97, DOI 10.1037/0096-1523.32.1.97
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Cheung H, 1996, DEV PSYCHOL, V32, P867, DOI 10.1037/0012-1649.32.5.867
   Crossley S, 2014, INT J CORPUS LINGUIS, V19, P301, DOI 10.1075/ijcl.19.3.01cro
   de Abreu PMJE, 2012, J EDUC PSYCHOL, V104, P974, DOI 10.1037/a0028390
   Deutsch D, 2009, J ACOUST SOC AM, V125, P2398, DOI 10.1121/1.3081389
   GANDOUR JT, 1978, LANG SPEECH, V21, P1, DOI 10.1177/002383097802100101
   Goss S, 2015, JPN PSYCHOL RES, V57, P143, DOI 10.1111/jpr.12076
   Hardison DM, 2010, APPL PSYCHOLINGUIST, V31, P81, DOI 10.1017/S0142716409990178
   Hummel KM, 2009, APPL PSYCHOLINGUIST, V30, P225, DOI 10.1017/S0142716409090109
   Ishizaki A, 1999, GOKAKU DEKIRU 1 KYUU
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Japan Foundation, 2002, NIH NOOR SIK SYUT KI
   Jongman A, 2017, J ACOUST SOC AM, V142, pEL163, DOI 10.1121/1.4995526
   Jun S.-A., 1998, PHONOLOGY, V15, P189, DOI DOI 10.1017/S0952675798003571
   Kaushanskaya M, 2012, BILING-LANG COGN, V15, P470, DOI 10.1017/S1366728911000472
   Kitahara M., 2001, THESIS
   Kubozono H., 2008, OXFORD HDB JAPANESE, P165
   Lee Wood Hung, 2006, NIHONGAKUKAN, V10, P38
   Mandel J., 2009, ADAPTIVE PITCH TEST
   Martin KI, 2012, STUD SECOND LANG ACQ, V34, P379, DOI 10.1017/S0272263112000125
   Meara P.M., 1996, PERFORMANCE COMPETEN, P35
   Miyaoka Y, 2011, HIROSHIMA KEIZAI DAI, V34, P1
   Miyaoka Y, 2014, HIROSHIMA KEIZAI DAI, V36, P33
   Nation I, 2010, LEARNING VOCABULARY
   Nishinuma Y, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P646, DOI 10.1109/ICSLP.1996.607444
   O'Brien I, 2007, STUD SECOND LANG ACQ, V29, P557, DOI 10.1017/S027226310707043X
   O'Brien I, 2006, APPL PSYCHOLINGUIST, V27, P377, DOI 10.1017/S0142716406060322
   Otake T, 1999, J PHONETICS, V27, P229, DOI 10.1006/jpho.1999.0095
   Pignot-Shahov V., 2012, LANGUAGE STUDIES WOR, V4, P37
   Sakamoto E., 2010, THESIS
   Segalowitz SJ, 1998, APPL PSYCHOLINGUIST, V19, P53, DOI 10.1017/S0142716400010572
   Sekiguchi T, 1999, J PSYCHOLINGUIST RES, V28, P439, DOI 10.1023/A:1023245216726
   Shibata T., 2008, UNDERSTANDING 2 LANG, P176
   Shibata Takeshi, 1990, KEIRYO KOKUGOGAKU, V17, P317
   Shibatani Masayoshi, 1990, LANGUAGES JAPAN
   Shport I, 2011, THESIS
   Shport IA, 2016, STUD SECOND LANG ACQ, V38, P739, DOI 10.1017/S027226311500039X
   Shport IA, 2015, J ACOUST SOC AM, V138, P307, DOI 10.1121/1.4922468
   Silva D, 2016, PHONOLOGY, V23, P287
   So CK, 2010, LANG SPEECH, V53, P273, DOI 10.1177/0023830909357156
   Speciale G, 2004, APPL PSYCHOLINGUIST, V25, P293, DOI 10.1017/S0142716404001146
   Strange W, 2008, PHONOLOGY 2 LANGUAGE, P193
   Strange W, 2011, J PHONETICS, V39, P456, DOI 10.1016/j.wocn.2010.09.001
   Sugito M, 1982, NIHONGO AKUSENTO KEN, P182
   Tamaoka K., 2014, JAPANESE LANGUAGE LI, V48, P431
   Tamaoka K, 2010, GENGO KENKYU, V138, P65
   Tanaka S, 2012, NIHONGO HATSUON KYOO
   Taylor B, 2011, POZ STUD CONTEMP LIN, V47, P146, DOI 10.2478/psicl-2011-0012
   Toda Takako, 2001, B CTR JAPANESE LANGU, V14, P67
   Ueno T, 2014, J COGNITIVE NEUROSCI, V26, P433, DOI 10.1162/jocn_a_00467
   Wayland R, 2010, J PHONETICS, V38, P654, DOI 10.1016/j.wocn.2010.10.001
   Williams JN, 2003, LANG LEARN, V53, P67, DOI 10.1111/1467-9922.00211
   Wong PCM, 2007, APPL PSYCHOLINGUIST, V28, P565, DOI 10.1017/S0142716407070312
NR 62
TC 1
Z9 1
U1 1
U2 6
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0267-6583
EI 1477-0326
J9 SECOND LANG RES
JI Second Lang. Res.
PD JUL
PY 2019
VL 35
IS 3
BP 351
EP 376
DI 10.1177/0267658318775143
PG 26
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA ID6DO
UT WOS:000471767200003
DA 2021-02-24
ER

PT J
AU Lukacs, B
   Honbolygo, F
AF Lukacs, Borbala
   Honbolygo, Ferenc
TI Task-Dependent Mechanisms in the Perception of Music and Speech:
   Domain-Specific Transfer Effects of Elementary School Music Education
SO JOURNAL OF RESEARCH IN MUSIC EDUCATION
LA English
DT Article
DE music education; music perception; phonological awareness; reading;
   task-dependent processing
ID CHILDREN; ABILITIES; SKILLS; RHYTHM
AB Previous studies have demonstrated that active engagement in musical activities benefits auditory and cognitive processing. However, it is still unclear whether musical experience improves domain-general mechanisms reflected in superior functioning in language or the enhancement is selective and limited to musical abilities. In the present study, we evaluated the transfer effect of general elementary school music education on the development of linguistic abilities. The relationship between specific musical auditory skills, phonological awareness, and reading was investigated in 30 second-grade children who attended either a class with an intensive music curriculum or a class with a regular curriculum. Results indicated no significant differences between the music and the regular class, suggesting that 1 year of Kodaly-based classroom music education is not enough to yield relevant improvement in musical and linguistic abilities. Although there was no considerable relationship between reading and musical abilities, phoneme deletion accuracy was specifically associated with tonal memory. These findings suggest that similar cognitive mechanisms may be required to process melodic and phonological sequences. Therefore, we assume that task-dependent mechanisms may exist in melody and speech perception, which might account for the presence of inconsistent findings in the music transfer literature.
C1 [Lukacs, Borbala; Honbolygo, Ferenc] Hungarian Acad Sci, Budapest, Hungary.
   [Lukacs, Borbala] Eotvos Lorand Univ, Mus Cognit, Budapest, Hungary.
   [Honbolygo, Ferenc] Eotvos Lorand Univ, Budapest, Hungary.
RP Lukacs, B (corresponding author), Hungarian Acad Sci, Brain Imaging Ctr, Res Ctr Nat Sci, Magyar Tudosok Korutja 2, H-1117 Budapest, Hungary.
EM lukacs.borbala@ttk.mta.hu
RI Lukacs, Borbala/M-5734-2018
OI Lukacs, Borbala/0000-0002-2417-3032
FU Content Pedagogy Research Program of the Hungarian Academy of Sciences
   [SZ-009/2016]; Janos Bolyai Research Fellowship of the Hungarian Academy
   of SciencesHungarian Academy of Sciences
FX The authors disclosed receipt of the following financial support for the
   research, authorship, and/or publication of this article: This study was
   funded by the Content Pedagogy Research Program of the Hungarian Academy
   of Sciences (SZ-009/2016.) and Janos Bolyai Research Fellowship of the
   Hungarian Academy of Sciences (F.H.).
CR [Anonymous], 2012, WAVEPAD SOUND ED MAS
   [Anonymous], 2013, TON GEN VERS 3 07 CO
   Anvari SH, 2002, J EXP CHILD PSYCHOL, V83, P111, DOI 10.1016/S0022-0965(02)00124-8
   Asaridou SS, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00321
   Asztalos K, 2017, PSYCHOL MUSIC, V45, P682, DOI 10.1177/0305735616678055
   BARKOCZI I., 1977, KODALY ZENEI NEVELES
   BARWICK J, 1989, BRIT J EDUC PSYCHOL, V59, P253, DOI 10.1111/j.2044-8279.1989.tb03097.x
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bentley A., 1973, MUSIKALISCHE BEGABUN
   Besson M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00094
   Blomert L., 2009, DIFFERENTIAAL DIAGNO
   Boersma P., 2007, PRAAT DOING PHONETIC
   David D, 2007, J RES READ, V30, P169, DOI 10.1111/j.1467-9817.2006.00323.x
   Dobszay L., 1972, STUDIA MUSICOLOGICA, V14, P15, DOI 10. 2307/901863
   Douglas S., 1994, J RES READING, V17, P99, DOI DOI 10.1111/J.1467-9817.1994.TB00057.X
   Field A., 2013, DISCOVERING STAT USI, DOI [10.1111/insr.12011_21., DOI 10.1111/INSR.12011_21, 10.1111/insr.12011_21]
   Forgeard M, 2008, MUSIC PERCEPT, V25, P383, DOI 10.1525/MP.2008.25.4.383
   Gevayne Janurik M, 2010, THESIS
   Gokturk Cary D, 2012, ZONGULDAK KARAELMAS, V8, P179, DOI 10. 11122/ijmeb. 2013. 8. 15. 66
   Gordon RL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01777
   Hanson M, 2001, THESIS
   Holliman AJ, 2010, EDUC PSYCHOL-UK, V30, P247, DOI 10.1080/01443410903560922
   IBM Corp, 2013, IBM SPSS STAT WIND V
   Ilari BS, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00062
   Jaschke AC, 2013, REV NEUROSCIENCE, V24, P665, DOI 10.1515/revneuro-2013-0023
   JASP Team, 2017, JASP VERS 0 8 1 2 CO
   Jusczyk PW, 1999, TRENDS COGN SCI, V3, P323, DOI 10.1016/S1364-6613(99)01363-7
   KOKAS K, 1969, J RES MUSIC EDUC, V17, P125, DOI 10.2307/3344199
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   LACZO Z, 1985, B COUN RES MUSIC ED, P109
   Laczo Z., 1987, B COUNCIL RES MUSIC, V91, P87
   Lamb S. J., 1993, ED PSYCHOL, V13, p19?27, DOI DOI 10.1080/0144341930130103
   Loui P, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00111
   MakeMusic Inc, 2012, FIN 2012 MUS NOT SOF
   McMullen E, 2004, MUSIC PERCEPT, V21, P289, DOI 10.1525/mp.2004.21.3.289
   Montesinos-Gelet I., 2005, PSYCHOMUSICOLOGY, V19, P3, DOI DOI 10.1037/H0094043
   Moreno S, 2014, HEARING RES, V308, P84, DOI 10.1016/j.heares.2013.09.012
   Moritz C, 2013, READ WRIT, V26, P739, DOI 10.1007/s11145-012-9389-0
   MORTON J, 1965, LANG SPEECH, V8, P159, DOI 10.1177/002383096500800303
   Nagyne Rez I., 2008, WECHSLER INTELLIGENC
   Patel A. D., 2003, COGNITIVE NEUROSCIEN, P321, DOI [10. 1093/acprof:oso/9780198525202. 003. 0021, DOI 10.1093/ACPROF:OSO/9780198525202.003.0021]
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Peretz I, 2003, NAT NEUROSCI, V6, P688, DOI 10.1038/nn1083
   PRATT AC, 1988, J EDUC PSYCHOL, V80, P319, DOI 10.1037/0022-0663.80.3.319
   Ramus F, 2008, Q J EXP PSYCHOL, V61, P129, DOI 10.1080/17470210701508822
   Register D, 2001, J MUSIC THER, V38, P239, DOI 10.1093/jmt/38.3.239
   Roden I, 2014, PSYCHOL MUSIC, V42, P284, DOI 10.1177/0305735612471239
   Roden I, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00572
   Sala G, 2017, EDUC RES REV-NETH, V20, P55, DOI 10.1016/j.edurev.2016.11.005
   Tierney A, 2013, PROG BRAIN RES, V207, P209, DOI 10.1016/B978-0-444-63327-9.00008-4
   Toth D., 2014, DISZLEXIA DIFFERENCI
   Wagenmakers EJ, 2007, PSYCHON B REV, V14, P779, DOI 10.3758/BF03194105
   Wechsler D., 2003, WECHSLER INTELLIGENC
   White EJ, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00090
   YOUNG WT, 1973, J RES MUSIC EDUC, V21, P74, DOI 10.2307/3343982
   Ziegler JC, 2012, BRAIN LANG, V120, P265, DOI 10.1016/j.bandl.2011.12.002
NR 56
TC 2
Z9 2
U1 7
U2 13
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0022-4294
EI 1945-0095
J9 J RES MUSIC EDUC
JI J. Res. Music Educ.
PD JUL
PY 2019
VL 67
IS 2
BP 153
EP 170
DI 10.1177/0022429419836422
PG 18
WC Education & Educational Research; Music
SC Education & Educational Research; Music
GA IB5QD
UT WOS:000470325700003
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Fecher, N
   Paquette-Smith, M
   Johnson, EK
AF Fecher, Natalie
   Paquette-Smith, Melissa
   Johnson, Elizabeth K.
TI Resolving the (Apparent) Talker Recognition Paradox in Developmental
   Speech Perception
SO INFANCY
LA English
DT Article
ID MOTHERS VOICE; UNFAMILIAR VOICE; INFANTS; DISCRIMINATION;
   IDENTIFICATION; INFORMATION; VARIABILITY; KNOWLEDGE; CHILDREN; STRANGER
AB The infant literature suggests that humans enter the world with impressive built-in talker processing abilities. For example, newborns prefer the sound of their mother's voice over the sound of another woman's voice, and well before their first birthday, infants tune in to language-specific speech cues for distinguishing between unfamiliar talkers. The early childhood literature, however, suggests that preschoolers are unable to learn to identify the voices of two unfamiliar talkers unless these voices are highly distinct from one another, and that adult-level talker recognition does not emerge until children near adolescence. How can we reconcile these apparently paradoxical messages conveyed by the infant and early childhood literatures? Here, we address this question by testing 16.5-month-old infants (N = 80) in three talker recognition experiments. Our results demonstrate that infants at this age have difficulty recognizing unfamiliar talkers, suggesting that talker recognition (associating voices with people) is mastered later in life than talker discrimination (telling voices apart). We conclude that methodological differences across the infant and early childhood literatures-rather than a true developmental discontinuity-account for the performance differences in talker processing between these two age groups. Related findings in other areas of developmental psychology are discussed.
C1 [Fecher, Natalie; Johnson, Elizabeth K.] Univ Toronto Mississauga, Dept Psychol, 3359 Mississauga Rd, Mississauga, ON L5L 1C6, Canada.
   [Paquette-Smith, Melissa] Univ Calif Los Angeles, Dept Psychol, Los Angeles, CA USA.
RP Johnson, EK (corresponding author), Univ Toronto Mississauga, Dept Psychol, 3359 Mississauga Rd, Mississauga, ON L5L 1C6, Canada.
EM elizabeth.johnson@utoronto.ca
RI Paquette-Smith, Melissa/AAP-7428-2020
FU Social Sciences and Humanities Research Council of CanadaSocial Sciences
   and Humanities Research Council of Canada (SSHRC); Natural Sciences and
   Engineering Research Council of CanadaNatural Sciences and Engineering
   Research Council of Canada (NSERC)CGIAR; Canada Research Chairs
   ProgramCanada Research Chairs
FX Thanks to Lisa Hotson, Katrina Aranas, and Shukri Nur for their
   assistance with stimulus creation and data collection, and all
   participating families. This research was supported by grants awarded to
   E.K.J. from the Social Sciences and Humanities Research Council of
   Canada, the Natural Sciences and Engineering Research Council of Canada,
   and the Canada Research Chairs Program. The authors declare no conflicts
   of interest with regard to the funding source for this study. Portions
   of this work were presented at the 20th International Conference on
   Infant Studies, New Orleans, Louisiana, USA (May 2016).
CR Andics A., 2007, P 16 INT C PHON SCI
   Bahrick LE, 2005, DEV PSYCHOL, V41, P541, DOI 10.1037/0012-1649.41.3.541
   Beauchemin M, 2011, CEREB CORTEX, V21, P1705, DOI 10.1093/cercor/bhq242
   BRICKER PD, 1966, J ACOUST SOC AM, V40, P1441, DOI 10.1121/1.1910246
   Brookes H, 2001, INFANT CHILD DEV, V10, P75, DOI 10.1002/icd.249
   Burnham D, 2004, DEV PSYCHOBIOL, V45, P204, DOI 10.1002/dev.20032
   Cook S, 1997, APPL COGNITIVE PSYCH, V11, P95
   Creel SC, 2015, TRENDS COGN SCI, V19, P713, DOI 10.1016/j.tics.2015.09.006
   Creel SC, 2012, J EXP CHILD PSYCHOL, V113, P487, DOI 10.1016/j.jecp.2012.07.007
   DECASPER AJ, 1984, DEV PSYCHOBIOL, V17, P481, DOI 10.1002/dev.420170506
   DECASPER AJ, 1980, SCIENCE, V208, P1174, DOI 10.1126/science.7375928
   Fecher N, 2018, J ACOUST SOC AM, V143, P2409, DOI 10.1121/1.5032199
   Fecher N, 2018, J EXP PSYCHOL LEARN, V44, P1911, DOI 10.1037/xlm0000555
   Floccia C, 2000, DEVELOPMENTAL SCI, V3, P333, DOI 10.1111/1467-7687.00128
   Friendly RH, 2014, DEV PSYCHOBIOL, V56, P228, DOI 10.1002/dev.21164
   GOGGIN JP, 1991, MEM COGNITION, V19, P448, DOI 10.3758/BF03199567
   GOREN CC, 1975, PEDIATRICS, V56, P544
   Hepper P, 1993, J REPRODUCTIVE INFAN, V11, P147, DOI DOI 10.1080/02646839308403210
   Hollich G, 2005, SUPERCODER PROGRAM C
   Houston DM, 2000, J EXP PSYCHOL HUMAN, V26, P1570, DOI 10.1037/0096-1523.26.5.1570
   Johnson EK, 2018, COGNITIVE SCI, V42, P633, DOI 10.1111/cogs.12520
   Johnson EK, 2011, DEVELOPMENTAL SCI, V14, P1002, DOI 10.1111/j.1467-7687.2011.01052.x
   Kisilevsky BS, 2009, INFANT BEHAV DEV, V32, P59, DOI 10.1016/j.infbeh.2008.10.002
   Kisilevsky BS, 2011, DEVELOPMENTAL SCI, V14, P214, DOI 10.1111/j.1467-7687.2010.00970.x
   LANGLOIS JH, 1987, DEV PSYCHOL, V23, P363, DOI 10.1037/0012-1649.23.3.363
   Lecanuet J.-P., 1993, EARLY DEV PARENTING, V2, P217, DOI [10.1002/edp.2430020405, DOI 10.1002/EDP.2430020405, 10.1002/edp.]
   Levi SV, 2018, BILING-LANG COGN, V21, P523, DOI 10.1017/S1366728917000153
   Levi SV, 2013, J SPEECH LANG HEAR R, V56, P913, DOI 10.1044/1092-4388(2012/12-0095)
   MANN VA, 1979, J EXP CHILD PSYCHOL, V27, P153, DOI 10.1016/0022-0965(79)90067-5
   MEHLER J, 1978, PERCEPTION, V7, P491, DOI 10.1068/p070491
   MILLER CL, 1983, INFANT BEHAV DEV, V6, P313, DOI 10.1016/S0163-6383(83)80040-X
   MILLER CL, 1982, INFANT BEHAV DEV, V5, P143, DOI 10.1016/S0163-6383(82)80024-6
   MILLS M, 1974, NATURE, V252, P123, DOI 10.1038/252123a0
   Mondloch CJ, 1999, PSYCHOL SCI, V10, P419, DOI 10.1111/1467-9280.00179
   MULLENNIX JW, 1989, J ACOUST SOC AM, V85, P365, DOI 10.1121/1.397688
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Ohman L, 2011, J POLICE CRIM PSYCHO, V26, P118, DOI 10.1007/s11896-010-9076-5
   Paquette-Smith M, 2016, INFANCY, V21, P104, DOI 10.1111/infa.12098
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Perea M, 2014, EXP PSYCHOL, V61, P480, DOI 10.1027/1618-3169/a000265
   Poulin-Dubois D, 1998, MERRILL PALMER QUART, V44, P338
   POULINDUBOIS D, 1994, DEV PSYCHOL, V30, P436, DOI 10.1037/0012-1649.30.3.436
   Purhonen M, 2004, INT J PSYCHOPHYSIOL, V52, P257, DOI 10.1016/j.ijpsycho.2003.11.003
   Remez RE, 2007, J ACOUST SOC AM, V122, P3688, DOI 10.1121/1.2799903
   Richoz AR, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169325
   Sadakata M, 2013, J ACOUST SOC AM, V134, P1324, DOI 10.1121/1.4812767
   Stevenage SV, 2018, NEUROPSYCHOLOGIA, V116, P162, DOI 10.1016/j.neuropsychologia.2017.07.005
   Trehub SE, 2009, ANN NY ACAD SCI, V1169, P508, DOI 10.1111/j.1749-6632.2009.04851.x
   TURNURE C, 1971, DEV PSYCHOL, V4, P182, DOI 10.1037/h0030431
   VANLANCKER D, 1987, NEUROPSYCHOLOGIA, V25, P829, DOI 10.1016/0028-3932(87)90120-5
   Voegtline KM, 2013, INFANT BEHAV DEV, V36, P526, DOI 10.1016/j.infbeh.2013.05.002
   WALKER-ANDREWS A S, 1991, Ecological Psychology, V3, P55, DOI 10.1207/s15326969eco0302_1
   WalkerAndrews AS, 1997, PSYCHOL BULL, V121, P437, DOI 10.1037/0033-2909.121.3.437
   Ward CD, 1999, DEV PSYCHOBIOL, V35, P49, DOI 10.1002/(SICI)1098-2302(199907)35:1<49::AID-DEV7>3.0.CO;2-3
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   Winters SJ, 2008, J ACOUST SOC AM, V123, P4524, DOI 10.1121/1.2913046
   YARMEY AD, 1992, APPL COGNITIVE PSYCH, V6, P367, DOI 10.1002/acp.2350060502
NR 57
TC 4
Z9 4
U1 0
U2 7
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1525-0008
EI 1532-7078
J9 INFANCY
JI Infancy
PD JUL
PY 2019
VL 24
IS 4
BP 570
EP 588
DI 10.1111/infa.12290
PG 19
WC Psychology, Developmental
SC Psychology
GA IB1BJ
UT WOS:000469998100005
PM 32677248
DA 2021-02-24
ER

PT J
AU Broos, WPJ
   Dijkgraaf, A
   Van Assche, E
   Vander Beken, H
   Dirix, N
   Lagrou, E
   Hartsuiker, RJ
   Duyck, W
AF Broos, Wouter P. J.
   Dijkgraaf, Aster
   Van Assche, Eva
   Vander Beken, Heleen
   Dirix, Nicolas
   Lagrou, Evelyne
   Hartsuiker, Robert J.
   Duyck, Wouter
TI Is There Adaptation of Speech Production After Speech Perception in
   Bilingual Interaction?
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION
LA English
DT Article
DE speech alignment; phonetic adaptation; second language production;
   bilingualism
ID CLOSURE DURATION; VOWEL DURATION; ALIGNMENT
AB In dialogue, speakers tend to adapt their speech to the speech of their interlocutor. Adapting speech production to preceding speech input may be particularly relevant for second language (L2) speakers interacting with native (L1) speakers, as adaptation may facilitate L2 learning. Here we asked whether Dutch-English bilinguals adapt pronunciation of the English phonemes /ae/ and coda /b/ when reading aloud sentences after exposure to native English speech. Additionally, we tested whether social context (presence or absence of a native English confederate) and time lag between perception and production of the phoneme affected adaptation. Participants produced more English-like target words that ended in word-final /b/ after exposure to target phonemes produced by a native speaker, but the participants did not change their production of the phoneme /ae/ after exposure to native /ae/. The native English speaking confederate did not show consistent changes in speech production after exposure to target phonemes produced by L2 speakers. These findings are in line with Gambi and Pickering's simulation theory of phonetic imitation (Gambi & Pickering, 2013).
C1 [Broos, Wouter P. J.; Dijkgraaf, Aster; Van Assche, Eva; Vander Beken, Heleen; Dirix, Nicolas; Lagrou, Evelyne; Hartsuiker, Robert J.; Duyck, Wouter] Univ Ghent, Dept Expt Psychol, Henri Dunantlaan 2, B-9000 Ghent, Belgium.
RP Broos, WPJ (corresponding author), Univ Ghent, Dept Expt Psychol, Henri Dunantlaan 2, B-9000 Ghent, Belgium.
EM wouter.broos@ugent.be
RI Dirix, Nicolas/ABE-2719-2020
OI Dirix, Nicolas/0000-0001-5875-5834; Van Assche, Eva/0000-0001-5623-7144;
   Duyck, Wouter/0000-0003-2114-6212
FU Ghent University (GOA - Concerted Research Action) [BOF13/GOA/032]
FX This article received funding from the special research fund of Ghent
   University (GOA - Concerted Research Action BOF13/GOA/032).
CR Baayen RH., 2008, ANAL LINGUISTIC DATA, DOI [10.1017/CBO9780511801686, DOI 10.1017/CBO9780511801686]
   Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001
   Bernolet S, 2013, COGNITION, V127, P287, DOI 10.1016/j.cognition.2013.02.005
   Bernolet S, 2012, BILING-LANG COGN, V15, P503, DOI 10.1017/S1366728911000162
   BOHN OS, 1990, APPL PSYCHOLINGUIST, V11, P303, DOI 10.1017/S0142716400008912
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Branigan HP, 2011, COGNITION, V121, P41, DOI 10.1016/j.cognition.2011.05.011
   Broersma M. E., 2005, PHONETIC LEXICAL PRO
   Broersma P., 2014, PRAAT DOING PHONETIC
   Collins B., 1996, PHONETICS ENGLISH DU
   Costa A, 2008, LANG COGNITIVE PROC, V23, P528, DOI 10.1080/01690960801920545
   Eisner F, 2006, J ACOUST SOC AM, V119, P1950, DOI 10.1121/1.2178721
   Gambi C, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00340
   Garrod S, 2004, TRENDS COGN SCI, V8, P8, DOI 10.1016/j.tics.2003.10.016
   Giegerich H. J., 1992, ENGLISH PHONOLOGY IN, DOI [10.1017/CBO978113, DOI 10.1017/CBO978113]
   Hwane J, 2015, J MEM LANG, V81, P72, DOI 10.1016/j.jml.2015.01.001
   Kim M., 2012, PHONETIC ACCOMMODATI
   Kim Midam, 2011, Lab Phonol, V2, P125
   Kraljic T, 2008, COGNITION, V107, P54, DOI 10.1016/j.cognition.2007.07.013
   Lametti DR, 2014, PSYCHOL SCI, V25, P1325, DOI 10.1177/0956797614529978
   Lemhofer K, 2012, BEHAV RES METHODS, V44, P325, DOI 10.3758/s13428-011-0146-0
   LISKER L, 1957, LANGUAGE, V33, P42, DOI 10.2307/410949
   LIVELY SE, 1994, J ACOUST SOC AM, V96, P2076, DOI 10.1121/1.410149
   LUCE PA, 1985, J ACOUST SOC AM, V78, P1949, DOI 10.1121/1.392651
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   Pickering MJ, 1999, TRENDS COGN SCI, V3, P136, DOI 10.1016/S1364-6613(99)01293-0
   R Core Team, 2013, R LANG ENV STAT COMP
   RAPHAEL LJ, 1972, J ACOUST SOC AM, V51, P1296, DOI 10.1121/1.1912974
   TRAUNMULLER H, 1990, J ACOUST SOC AM, V88, P97, DOI 10.1121/1.399849
   Trofimovich P, 2014, BILING-LANG COGN, V17, P822, DOI 10.1017/S1366728913000801
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0
   Weber A, 2014, J PHONETICS, V46, P34, DOI 10.1016/j.wocn.2014.05.002
NR 34
TC 0
Z9 0
U1 1
U2 10
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0278-7393
EI 1939-1285
J9 J EXP PSYCHOL LEARN
JI J. Exp. Psychol.-Learn. Mem. Cogn.
PD JUL
PY 2019
VL 45
IS 7
BP 1252
EP 1270
DI 10.1037/xlm0000647
PG 19
WC Psychology; Psychology, Experimental
SC Psychology
GA IB1BP
UT WOS:000469998700007
PM 30265054
DA 2021-02-24
ER

PT J
AU Yellamsetty, A
   Bidelman, GM
AF Yellamsetty, Anusha
   Bidelman, Gavin M.
TI Brainstem correlates of concurrent speech identification in adverse
   listening conditions
SO BRAIN RESEARCH
LA English
DT Article
DE FFR; Double-vowel identification; Speech-in-noise perception
ID FREQUENCY-FOLLOWING RESPONSE; INFERIOR COLLICULUS NEURONS; IN-NOISE
   PERCEPTION; VOWEL-LIKE SOUNDS; AUDITORY-NERVE; COMPLEX TONES; 2-TONE
   APPROXIMATIONS; RECEPTION THRESHOLDS; DISCHARGE PATTERNS; MODEL
   PREDICTIONS
AB When two voices compete, listeners can segregate and identify concurrent speech sounds using pitch (fundamental frequency, F0) and timbre (harmonic) cues. Speech perception is also hindered by the signal-to-noise ratio (SNR). How clear and degraded concurrent speech sounds are represented at early, pre-attentive stages of the auditory system is not well understood. To this end, we measured scalp-recorded frequency-following responses (FFR) from the EEG while human listeners heard two concurrently presented, steady-state (time-invariant) vowels whose FO differed by zero or four semitones (ST) presented diotically in either clean (no noise) or noise-degraded (+ 5dB SNR) conditions. Listeners also performed a speeded double vowel identification task in which they were required to identify both vowels correctly. Behavioral results showed that speech identification accuracy increased with F0 differences between vowels, and this perceptual F0 benefit was larger for clean compared to noise degraded (+ 5dB SNR) stimuli. Neurophysiological data demonstrated more robust FFR F0 amplitudes for single compared to double vowels and considerably weaker responses in noise. F0 amplitudes showed speech-on-speech masking effects, along with a non-linear constructive interference at 0ST, and suppression effects at 4ST. Correlations showed that FFR F0 amplitudes failed to predict listeners' identification accuracy. In contrast, FFR F1 amplitudes were associated with faster reaction times, although this correlation was limited to noise conditions. The limited number of brain-behavior associations suggests subcortical activity mainly reflects exogenous processing rather than perceptual correlates of concurrent speech perception. Collectively, our results demonstrate that FFRs reflect pre-attentive coding of concurrent auditory stimuli that only weakly predict the success of identifying concurrent speech.
C1 [Yellamsetty, Anusha; Bidelman, Gavin M.] Univ Memphis, Sch Commun Sci & Disorders, Memphis, TN 38152 USA.
   [Yellamsetty, Anusha] Univ S Florida, Dept Commun Sci & Disorders, 4202 E Fowler Ave,PCD 1017, Tampa, FL 32620 USA.
   [Bidelman, Gavin M.] Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.
   [Bidelman, Gavin M.] Univ Tennessee, Ctr Hlth Sci, Dept Anat & Neurobiol, Memphis, TN 38163 USA.
RP Yellamsetty, A (corresponding author), Univ S Florida, Dept Commun Sci & Disorders, 4202 E Fowler Ave,PCD 1017, Tampa, FL 32620 USA.
EM yellamsettya@usf.edu; gmbdlman@memphis.edu
OI Bidelman, Gavin M/0000-0002-1821-3261
FU Institute for Intelligent Systems Student Dissertation Grant Program at
   the University of Memphis; National Institute On Deafness And Other
   Communication Disorders of the National Institutes of HealthUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC016267]; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC016267] Funding Source: NIH RePORTER
FX This research was supported by the Institute for Intelligent Systems
   Student Dissertation Grant Program at the University of Memphis (A.Y.)
   and by the National Institute On Deafness And Other Communication
   Disorders of the National Institutes of Health under award number
   R01DC016267 (G.M.B.). Reprints and requests for materials should be
   directed to G.M.B. [gmbdlman@memphis.edu].
CR Aiken SJ, 2006, AUDIOL NEURO-OTOL, V11, P213, DOI 10.1159/000092589
   Aiken SJ, 2008, HEARING RES, V245, P35, DOI 10.1016/j.heares.2008.08.004
   Al Osman R, 2017, J ACOUST SOC AM, V142, pEL555, DOI 10.1121/1.5017522
   Alain C, 2005, J COGNITIVE NEUROSCI, V17, P811, DOI 10.1162/0898929053747621
   Alain C, 2007, HEARING RES, V229, P225, DOI 10.1016/j.heares.2007.01.011
   Alain C, 2007, CEREB CORTEX, V17, P1074, DOI 10.1093/cercor/bhl018
   Alain C, 2017, SCI REP-UK, V7, DOI 10.1038/srep40790
   Amitay S., 2009, LEARN PERCEPT, V1, P59
   Anderson S, 2013, P INT S AUD AUD RES, V3, P231
   Anderson S, 2012, J NEUROSCI, V32, P14156, DOI 10.1523/JNEUROSCI.2176-12.2012
   Anderson S, 2010, J AM ACAD AUDIOL, V21, P575, DOI 10.3766/jaaa.21.9.3
   Anderson S, 2010, HEARING RES, V270, P151, DOI 10.1016/j.heares.2010.08.001
   Arehart KH, 1997, J SPEECH LANG HEAR R, V40, P1434, DOI 10.1044/jslhr.4006.1434
   Assmann Peter, 2004, VVolume 18, P231
   ASSMANN PF, 1989, J ACOUST SOC AM, V85, P327, DOI 10.1121/1.397684
   ASSMANN PF, 1990, J ACOUST SOC AM, V88, P680, DOI 10.1121/1.399772
   ASSMANN PF, 1994, J ACOUST SOC AM, V95, P471, DOI 10.1121/1.408342
   Atiani S, 2009, NEURON, V61, P467, DOI 10.1016/j.neuron.2008.12.027
   Bidebnan GM, 2010, BRAIN RES, V1355, P112, DOI 10.1016/j.brainres.2010.07.100
   Bidelman G. M, 2018, HEAR RES
   Bidelman G, 2018, INT J AUDIOL, V57, P665, DOI 10.1080/14992027.2018.1470338
   Bidelman GM, 2018, NEUROIMAGE, V175, P56, DOI 10.1016/j.neuroimage.2018.03.060
   Bidelman GM, 2017, SPRINGER HANDB AUDIT, V61, P193, DOI 10.1007/978-3-319-47944-6_8
   Bidelman GM, 2017, HEARING RES, V351, P34, DOI 10.1016/j.heares.2017.05.008
   Bidelman GM, 2016, J ACOUST SOC AM, V140, pEL358, DOI 10.1121/1.4965248
   Bidelman GM, 2016, NEUROIMAGE, V124, P581, DOI 10.1016/j.neuroimage.2015.09.020
   Bidelman GM, 2015, HEARING RES, V323, P68, DOI 10.1016/j.heares.2015.01.011
   Bidelman GM, 2015, NEUROPSYCHOLOGIA, V68, P38, DOI 10.1016/j.neuropsychologia.2014.12.020
   Bidelman GM, 2015, BRAIN LANG, V141, P62, DOI 10.1016/j.bandl.2014.11.003
   Bidelman GM, 2014, NEUROBIOL AGING, V35, P2526, DOI 10.1016/j.neurobiolaging.2014.05.006
   Bidelman GM, 2014, EUR J NEUROSCI, V40, P2662, DOI 10.1111/ejn.12627
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Bidelman GM, 2011, BRAIN COGNITION, V77, P1, DOI 10.1016/j.bandc.2011.07.006
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   Bregman, 1990, AUDITORY SCENE ANAL
   Brugge JF, 2009, J NEUROPHYSIOL, V102, P2358, DOI 10.1152/jn.91346.2008
   Cariani PA, 1996, J NEUROPHYSIOL, V76, P1698
   Carlyon RP, 2004, TRENDS COGN SCI, V8, P465, DOI 10.1016/j.tics.2004.08.008
   Cedolin L, 2005, J NEUROPHYSIOL, V94, P347, DOI 10.1152/jn.01114.2004
   Chandrasekaran B, 2009, NEURON, V64, P311, DOI 10.1016/j.neuron.2009.10.006
   Chandrasekaran B, 2010, PSYCHOPHYSIOLOGY, V47, P236, DOI 10.1111/j.1469-8986.2009.00928.x
   CHIMENTO TC, 1990, ELECTROEN CLIN NEURO, V75, P88, DOI 10.1016/0013-4694(90)90156-E
   Chintanpalli A, 2016, J ACOUST SOC AM, V140, P4142, DOI 10.1121/1.4968781
   Chintanpalli A, 2014, JARO-J ASSOC RES OTO, V15, P823, DOI 10.1007/s10162-014-0475-7
   Chintanpalli A, 2013, J ACOUST SOC AM, V134, P2988, DOI 10.1121/1.4820888
   Coffey EBJ, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00479
   Coffey EBJ, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11070
   Culling J., 1990, P I ACOUST, V12, P559
   Cunningham J, 2001, CLIN NEUROPHYSIOL, V112, P758, DOI 10.1016/S1388-2457(01)00465-5
   deCheveigne A, 1997, J ACOUST SOC AM, V101, P2839, DOI 10.1121/1.418517
   DELGUTTE B, 1984, J ACOUST SOC AM, V75, P866, DOI 10.1121/1.390596
   Du Y, 2011, NEUROSCI BIOBEHAV R, V35, P2046, DOI 10.1016/j.neubiorev.2011.05.008
   Dyson BJ, 2004, J ACOUST SOC AM, V115, P280, DOI 10.1121/1.1631945
   Elhilali M, 2009, NEURON, V61, P317, DOI 10.1016/j.neuron.2008.12.005
   GARDI J, 1979, AUDIOLOGY, V18, P353
   GLASER EM, 1976, ELECTROEN CLIN NEURO, V40, P25, DOI 10.1016/0013-4694(76)90176-0
   Gockel HE, 2011, JARO-J ASSOC RES OTO, V12, P767, DOI 10.1007/s10162-011-0284-1
   Henry KS, 2017, JARO-J ASSOC RES OTO, V18, P165, DOI 10.1007/s10162-016-0594-4
   Hornickel J, 2011, BEHAV BRAIN RES, V216, P597, DOI 10.1016/j.bbr.2010.08.051
   Hornickel J, 2009, P NATL ACAD SCI USA, V106, P13022, DOI 10.1073/pnas.0901123106
   HOUTGAST T, 1974, LATERAL SUPPRESSION
   Keilson SE, 1997, J ACOUST SOC AM, V102, P1056, DOI 10.1121/1.419859
   KIANG NYS, 1974, J ACOUST SOC AM, V55, P620, DOI 10.1121/1.1914572
   KLATT DH, 1980, J ACOUST SOC AM, V67, P971, DOI 10.1121/1.383940
   Koffka K., 1935, PRINCIPLES GESTALT P
   Kozou H, 2005, HEARING RES, V199, P31, DOI 10.1016/j.heares.2004.07.010
   Krishnan A, 1999, AUDIOL NEURO-OTOL, V4, P95, DOI 10.1159/000013826
   Krishnan A, 2002, HEARING RES, V166, P192, DOI 10.1016/S0378-5955(02)00327-1
   Krishnan A, 2010, HEARING RES, V268, P60, DOI 10.1016/j.heares.2010.04.016
   Krishnan A, 2010, AUDIOL NEURO-OTOL, V15, P221, DOI 10.1159/000255340
   Li XM, 2011, J ACOUST SOC AM, V129, pEL21, DOI 10.1121/1.3528775
   Liu C, 2004, J ACOUST SOC AM, V116, P3119, DOI 10.1121/1.1802671
   Liu LF, 2006, J NEUROPHYSIOL, V95, P1926, DOI 10.1152/jn.00497.2005
   MARSH JT, 1974, ELECTROEN CLIN NEURO, V36, P415, DOI 10.1016/0013-4694(74)90192-8
   MCKEOWN JD, 1992, SPEECH COMMUN, V11, P1
   MEDDIS R, 1992, J ACOUST SOC AM, V91, P233, DOI 10.1121/1.402767
   Miller RL, 1997, J ACOUST SOC AM, V101, P3602, DOI 10.1121/1.418321
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   NOSOFSKY RM, 1987, J EXP PSYCHOL LEARN, V13, P87, DOI 10.1037/0278-7393.13.1.87
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   PALMER AR, 1990, J ACOUST SOC AM, V88, P1412, DOI 10.1121/1.400329
   PALMER AR, 1992, ADV BIOSCI, V83, P231
   Parbery-Clark A, 2011, EUR J NEUROSCI, V33, P549, DOI 10.1111/j.1460-9568.2010.07546.x
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Peters RW, 1998, J ACOUST SOC AM, V103, P577, DOI 10.1121/1.421128
   Prevost F, 2013, CLIN NEUROPHYSIOL, V124, P52, DOI 10.1016/j.clinph.2012.05.009
   REALE RA, 1980, J ACOUST SOC AM, V67, P891, DOI 10.1121/1.383969
   Reetzke R, 2018, CURR BIOL
   Reinke KS, 2003, COGNITIVE BRAIN RES, V17, P781, DOI 10.1016/S0926-6410(03)00202-7
   RUGGERO MA, 1992, J NEUROPHYSIOL, V68, P1087
   Russo N, 2004, CLIN NEUROPHYSIOL, V115, P2021, DOI 10.1016/j.clinph.2004.04.003
   SACHS MB, 1968, J ACOUST SOC AM, V43, P1120, DOI 10.1121/1.1910947
   SCHEFFERS M, 1983, SIFTING VOWELS AUDIT
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   SHANNON RV, 1976, J ACOUST SOC AM, V59, P1460, DOI 10.1121/1.381007
   Shetty Hemanth Narayan, 2016, J Otol, V11, P95, DOI 10.1016/j.joto.2016.08.001
   SINEX DG, 1983, J ACOUST SOC AM, V73, P602, DOI 10.1121/1.389007
   Sinex DG, 2002, HEARING RES, V168, P150, DOI 10.1016/S0378-5955(02)00366-0
   Sinex DG, 2005, J NEUROPHYSIOL, V94, P3523, DOI 10.1152/jn.01194.2004
   Sinex DG, 2002, JARO, V3, P390, DOI 10.1007/s101620020026
   Sinex DG, 2008, HEARING RES, V238, P39, DOI 10.1016/j.heares.2007.11.001
   Slee SJ, 2015, J NEUROSCI, V35, P13090, DOI 10.1523/JNEUROSCI.1671-15.2015
   Smalt CJ, 2012, HEARING RES, V292, P26, DOI 10.1016/j.heares.2012.08.001
   SMITH JC, 1975, ELECTROEN CLIN NEURO, V39, P465, DOI 10.1016/0013-4694(75)90047-4
   Song JH, 2011, J COGNITIVE NEUROSCI, V23, P2268, DOI 10.1162/jocn.2010.21556
   STILLMAN RD, 1978, ELECTROEN CLIN NEURO, V44, P438, DOI 10.1016/0013-4694(78)90028-7
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Suga N, 2000, P NATL ACAD SCI USA, V97, P11807, DOI 10.1073/pnas.97.22.11807
   Suga N, 2012, NEUROSCI BIOBEHAV R, V36, P969, DOI 10.1016/j.neubiorev.2011.11.006
   Swaminathan J, 2012, J NEUROSCI, V32, P1747, DOI 10.1523/JNEUROSCI.4493-11.2012
   Tadel F, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/879716
   Tan Q, 2005, J ACOUST SOC AM, V117, P1210, DOI 10.1121/1.1856391
   Tierney A, 2011, HEARING RES, V282, P145, DOI 10.1016/j.heares.2011.08.014
   Vollmer M, 2017, J NEUROPHYSIOL, V117, P47, DOI 10.1152/jn.00392.2016
   WORDEN FG, 1968, ELECTROEN CLIN NEURO, V25, P42, DOI 10.1016/0013-4694(68)90085-0
   Xie ZL, 2017, J NEUROPHYSIOL, V117, P1407, DOI 10.1152/jn.00445.2016
   Yellamsetty A, 2018, HEARING RES, V361, P92, DOI 10.1016/j.heares.2018.01.006
   YOUNG ED, 1979, J ACOUST SOC AM, V66, P1381, DOI 10.1121/1.383532
   Yu JJ, 2000, P NATL ACAD SCI USA, V97, P11780, DOI 10.1073/pnas.97.22.11780
   Zhang YK, 2005, J NEUROPHYSIOL, V94, P2676, DOI 10.1152/jn.00549.2005
   ZWICKER UT, 1984, SPEECH COMMUN, V3, P265, DOI 10.1016/0167-6393(84)90023-2
   2009, J NEUROSCI, V29, P1410, DOI DOI 10.1523/JNEUROSCI.3256-09.2009
   2005, NEUROIMAGE, V26, P592, DOI DOI 10.1016/J.NEUROIMAGE.2005.02.006
NR 123
TC 4
Z9 4
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0006-8993
EI 1872-6240
J9 BRAIN RES
JI Brain Res.
PD JUL 1
PY 2019
VL 1714
BP 182
EP 192
DI 10.1016/j.brainres.2019.02.025
PG 11
WC Neurosciences
SC Neurosciences & Neurology
GA HY6PK
UT WOS:000468252000020
PM 30796895
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Mason, GM
   Goldstein, MH
   Schwade, JA
AF Mason, Gina M.
   Goldstein, Michael H.
   Schwade, Jennifer A.
TI The role of multisensory development in early language learning
SO JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY
LA English
DT Article
DE Infant development; Social learning; Multisensory perception;
   Caregiver-infant interactions; Word learning; Neurodevelopmental
   disorders
ID INFANT-DIRECTED SPEECH; AUTISM SPECTRUM DISORDERS; SOCIAL FEEDBACK;
   MATERNAL SPEECH; YOUNG-CHILDREN; RISK; INPUT; MOTHERS; COMMUNICATION;
   PERCEPTION
AB In typical development, communicative skills such as language emerge from infants' ability to combine multisensory information into cohesive percepts. For example, the act of associating the visual or tactile experience of an object with its spoken name is commonly used as a measure of early word learning, and social attention and speech perception frequently involve integrating both visual and auditory attributes. Early perspectives once regarded perceptual integration as one of infants' primary challenges, whereas recent work suggests that caregivers' social responses contain structured patterns that may facilitate infants' perception of multisensory social cues. In the current review, we discuss the regularities within caregiver feedback that may allow infants to more easily discriminate and learn from social signals. We focus on the statistical regularities that emerge in the moment-by-moment behaviors observed in studies of naturalistic caregiver-infant play. We propose that the spatial form and contingencies of caregivers' responses to infants' looks and prelinguistic vocalizations facilitate communicative and cognitive development. We also explore how individual differences in infants' sensory and motor abilities may reciprocally influence caregivers' response patterns, in turn regulating and constraining the types of social learning opportunities that infants experience across early development. We end by discussing implications for neurodevelopmental conditions affecting both multisensory integration and communication (i.e., autism) and suggest avenues for further research and intervention. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Mason, Gina M.; Goldstein, Michael H.; Schwade, Jennifer A.] Cornell Univ, Dept Psychol, Ithaca, NY 14853 USA.
RP Mason, GM (corresponding author), Cornell Univ, Dept Psychol, Ithaca, NY 14853 USA.
EM gmm89@cornell.edu
OI Goldstein, Michael/0000-0001-6672-3752
CR Albert RR, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12641
   Albin DD, 1996, INFANT BEHAV DEV, V19, P401, DOI 10.1016/S0163-6383(96)90002-8
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   Bahrick LE, 2002, ADV CHILD DEV BEHAV, V30, P153
   Baranek GT, 2013, DEV PSYCHOPATHOL, V25, P307, DOI 10.1017/S0954579412001071
   BARONCOHEN S, 1989, J CHILD PSYCHOL PSYC, V30, P285, DOI 10.1111/j.1469-7610.1989.tb00241.x
   Batki A, 2000, INFANT BEHAV DEV, V23, P223, DOI 10.1016/S0163-6383(01)00037-6
   Baumwell L, 1997, INFANT BEHAV DEV, V20, P247, DOI 10.1016/S0163-6383(97)90026-6
   Begus K, 2018, ACTIVE LEARNING INFA, P13, DOI [DOI 10.1007/978-3-319-77182-3_2, 10.1007/978-3-319-77182-3_2]
   Bhat AN, 2012, INFANT BEHAV DEV, V35, P838, DOI 10.1016/j.infbeh.2012.07.019
   BIRNHOLZ JC, 1983, SCIENCE, V222, P516, DOI 10.1126/science.6623091
   Bornstein MH, 2015, PSYCHOL SCI, V26, P1272, DOI 10.1177/0956797615586796
   BRADLEY RM, 1975, PHYSIOL REV, V55, P352
   Bremner AJ, 2017, CURR BIOL, V27, pR305, DOI 10.1016/j.cub.2017.02.055
   Broesch TL, 2015, J COGN DEV, V16, P31, DOI 10.1080/15248372.2013.833923
   Brown P., 2014, CAMBRIDGE HDB LINGUI, P187
   Burnham D, 2002, SCIENCE, V296, P1435, DOI 10.1126/science.1069587
   Carpenter M., 1998, MONOGRAPHS SOC RES C, V63
   Centers for Disease Control and Prevention, 2018, DAT STAT AUT SPECTR
   Chen YC, 2017, CURR BIOL, V27, P583, DOI 10.1016/j.cub.2017.01.009
   CHENG MF, 1992, ANIM BEHAV, V43, P1035, DOI 10.1016/0003-3472(92)90016-3
   CHOMSKY N, 1967, SYNTHESE, V17, P2, DOI 10.1007/BF00485013
   Chong SCF, 2003, INFANT CHILD DEV, V12, P211, DOI 10.1002/icd.286
   Church R., 2005, J ACOUST SOC AM, V117, P2429, DOI [10.1121/1.4786663, DOI 10.1121/1.4786663]
   Clerkin EM, 2017, PHILOS T R SOC B, V372, DOI 10.1098/rstb.2016.0055
   COOPER RP, 1990, CHILD DEV, V61, P1584, DOI 10.1111/j.1467-8624.1990.tb02885.x
   Cristia A, 2013, LANG LINGUIST COMPAS, V7, P157, DOI 10.1111/lnc3.12015
   Csibra G, 2009, TRENDS COGN SCI, V13, P148, DOI 10.1016/j.tics.2009.01.005
   Damiano-Goodwin CR, 2018, DEV COGN NEUROS-NETH, V29, P41, DOI 10.1016/j.dcn.2017.08.005
   de Barbaro K, 2017, CHILD DEV, V88, P629, DOI 10.1111/cdev.12689
   De Leon L., 1998, J LINGUIST ANTHROPOL, V8, P131, DOI [10.1525/jlin.1998.8.2.131, DOI 10.1525/JLIN.1998.8.2.131]
   Deak G. O., 2013, COGNITION BRAIN DEV, P173, DOI DOI 10.1037/14043-010
   DECASPER AJ, 1980, SCIENCE, V208, P1174, DOI 10.1126/science.7375928
   DECASPER AJ, 1986, INFANT BEHAV DEV, V9, P133, DOI 10.1016/0163-6383(86)90025-1
   DECASPER AJ, 1994, INFANT BEHAV DEV, V17, P159, DOI 10.1016/0163-6383(94)90051-5
   Dunn W, 1997, INFANT YOUNG CHILD, V9, P23, DOI 10.1097/00001163-199704000-00005
   Farran LK, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151518
   Fausey CM, 2016, COGNITION, V152, P101, DOI 10.1016/j.cognition.2016.03.005
   Feldman R, 2007, CURR DIR PSYCHOL SCI, V16, P340, DOI 10.1111/j.1467-8721.2007.00532.x
   Fenson L., 1994, MONOGRAPHS SOC RES C, V59
   FERNALD A, 1987, INFANT BEHAV DEV, V10, P279, DOI 10.1016/0163-6383(87)90017-8
   FERNALD A, 1989, J CHILD LANG, V16, P477, DOI 10.1017/S0305000900010679
   FERNALD A, 1985, INFANT BEHAV DEV, V8, P181, DOI 10.1016/S0163-6383(85)80005-9
   FERNALD A, 1984, DEV PSYCHOL, V20, P104, DOI 10.1037/0012-1649.20.1.104
   FERNALD A, 1991, DEV PSYCHOL, V27, P209, DOI 10.1037/0012-1649.27.2.209
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   Germani T, 2014, J AUTISM DEV DISORD, V44, P3264, DOI 10.1007/s10803-014-2175-x
   Gibson EJ, 1969, PRINCIPLES PERCEPTUA
   Gogate LJ, 2006, INFANCY, V9, P259, DOI 10.1207/s15327078in0903_1
   Gogate LJ, 2000, CHILD DEV, V71, P878, DOI 10.1111/1467-8624.00197
   Gogate LJ, 1998, J EXP CHILD PSYCHOL, V69, P133, DOI 10.1006/jecp.1998.2438
   Goldstein M. H., 2010, OXFORD HDB DEV COMP, V29, P737
   Goldstein MH, 2003, P NATL ACAD SCI USA, V100, P8030, DOI 10.1073/pnas.1332441100
   Goldstein MH, 2008, PSYCHOL SCI, V19, P515, DOI 10.1111/j.1467-9280.2008.02117.x
   Goldstein MH, 2010, TRENDS COGN SCI, V14, P249, DOI 10.1016/j.tics.2010.02.004
   Goldstein MH, 2010, INFANCY, V15, P362, DOI 10.1111/j.1532-7078.2009.00020.x
   Goldstein MH, 2009, CHILD DEV, V80, P636, DOI 10.1111/j.1467-8624.2009.01287.x
   Golinkoff RM, 2015, CURR DIR PSYCHOL SCI, V24, P339, DOI 10.1177/0963721415595345
   GOTTLIEB G, 1989, INFANT BEHAV DEV, V12, P1, DOI 10.1016/0163-6383(89)90048-9
   GOTTLIEB G, 1976, PSYCHOL REV, V83, P215, DOI 10.1037/0033-295X.83.3.215
   Gottlieb G, 1971, BIOPSYCHOLOGY DEV, P67
   Gredeback G, 2018, CHILD DEV, V89, P2091, DOI 10.1111/cdev.13026
   Green JR, 2010, J SPEECH LANG HEAR R, V53, P1529, DOI 10.1044/1092-4388(2010/09-0005)
   GREENOUGH WT, 1987, CHILD DEV, V58, P539, DOI 10.2307/1130197
   GRIESER DL, 1988, DEV PSYCHOL, V24, P14, DOI 10.1037/0012-1649.24.1.14
   Gros-Louis J, 2006, INT J BEHAV DEV, V30, P509, DOI 10.1177/0165025406071914
   Heyes C, 2014, DEVELOPMENTAL SCI, V17, P647, DOI 10.1111/desc.12148
   Heyes C, 2012, J COMP PSYCHOL, V126, P193, DOI 10.1037/a0025180
   Hsu HC, 2003, DEV PSYCHOL, V39, P1061, DOI 10.1037/0012-1649.39.6.1061
   Iverson JM, 2010, J CHILD LANG, V37, P229, DOI 10.1017/S0305000909990432
   Jaffe J., 2001, MONOGRAPHS SOC RES C, V66
   James W., 1890, AMERICAN SCIENCE SER, P483
   Jayaraman S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123780
   KAPLAN PS, 1995, INFANT BEHAV DEV, V18, P209, DOI 10.1016/0163-6383(95)90050-0
   Karasik LB, 2014, DEVELOPMENTAL SCI, V17, P388, DOI 10.1111/desc.12129
   Karmiloff-Smith A, 1998, TRENDS COGN SCI, V2, P389, DOI 10.1016/S1364-6613(98)01230-3
   Kolevzon A, 2007, ARCH PEDIAT ADOL MED, V161, P326, DOI 10.1001/archpedi.161.4.326
   Landa R, 2006, J CHILD PSYCHOL PSYC, V47, P629, DOI 10.1111/j.1469-7610.2006.01531.x
   Landa RJ, 2007, ARCH GEN PSYCHIAT, V64, P853, DOI 10.1001/archpsyc.64.7.853
   Le Grand R, 2004, PSYCHOL SCI, V15, P762, DOI 10.1111/j.0956-7976.2004.00753.x
   LeBarton ES, 2016, INFANT BEHAV DEV, V44, P59, DOI 10.1016/j.infbeh.2016.05.003
   LeBarton ES, 2013, DEVELOPMENTAL SCI, V16, P815, DOI 10.1111/desc.12069
   Lecanuet J.-P, 1998, PERCEPTUAL DEV VISUA, P317
   Lecanuet JP, 1996, EUR J OBSTET GYN R B, V68, P1, DOI 10.1016/0301-2115(96)02509-2
   Leekam SR, 2007, J AUTISM DEV DISORD, V37, P894, DOI 10.1007/s10803-006-0218-7
   Leslie A.M., 1992, CURRENT DIRECTIONS P, V1, P18, DOI DOI 10.1111/1467-8721
   Lewkowicz DJ, 2015, J EXP CHILD PSYCHOL, V130, P147, DOI 10.1016/j.jecp.2014.10.006
   Lewkowicz DJ, 2010, INFANCY, V15, P46, DOI 10.1111/j.1532-7078.2009.00005.x
   Lewkowicz DJ, 2002, COGNITIVE BRAIN RES, V14, P41, DOI 10.1016/S0926-6410(02)00060-5
   LICKLITER R, 1990, DEV PSYCHOBIOL, V23, P15, DOI 10.1002/dev.420230103
   Lickliter R, 2011, CLIN PERINATOL, V38, P591, DOI 10.1016/j.clp.2011.08.007
   Locke JL, 2001, SOC DEV, V10, P294, DOI 10.1111/1467-9507.00167
   Ma WY, 2011, LANG LEARN DEV, V7, P185, DOI 10.1080/15475441.2011.579839
   Marchman VA, 2008, DEVELOPMENTAL SCI, V11, pF9, DOI 10.1111/j.1467-7687.2008.00671.x
   Maurer D, 2007, DEVELOPMENTAL SCI, V10, P40, DOI 10.1111/j.1467-7687.2007.00562.x
   MAYER DL, 1982, VISION RES, V22, P1141, DOI 10.1016/0042-6989(82)90079-7
   McCormick C, 2016, AUTISM, V20, P572, DOI 10.1177/1362361315599755
   Newport E, 1977, COGNITIVE THEORY, V2, P177
   Nickel LR, 2013, INFANCY, V18, P639, DOI 10.1111/infa.12025
   Northrup JB, 2017, AUTISM RES, V10, P1239, DOI 10.1002/aur.1770
   Nystrom P, 2015, MOL AUTISM, V6, DOI 10.1186/s13229-015-0011-6
   Olson J, 2011, J CHILD LANG, V38, P1028, DOI 10.1017/S0305000910000565
   Ozonoff S, 2011, PEDIATRICS, V128, pE488, DOI 10.1542/peds.2010-2825
   Patten E, 2014, J AUTISM DEV DISORD, V44, P2413, DOI 10.1007/s10803-014-2047-4
   Putzar L, 2007, NAT NEUROSCI, V10, P1243, DOI 10.1038/nn1978
   Rogers SJ, 2009, AUTISM RES, V2, P125, DOI 10.1002/aur.81
   Rogers SJ, 2005, J CHILD PSYCHOL PSYC, V46, P1255, DOI 10.1111/j.1469-7610.2005.01431.x
   Roy BC, 2015, P NATL ACAD SCI USA, V112, P12663, DOI 10.1073/pnas.1419773112
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Sandin S, 2014, JAMA-J AM MED ASSOC, V311, P1770, DOI 10.1001/jama.2014.4144
   SEYFARTH RM, 1980, ANIM BEHAV, V28, P1070, DOI 10.1016/S0003-3472(80)80097-2
   Shepard KG, 2012, INFANT CHILD DEV, V21, P555, DOI 10.1002/icd.1757
   Shneidman LA, 2012, DEVELOPMENTAL SCI, V15, P659, DOI 10.1111/j.1467-7687.2012.01168.x
   Sinha P, 2014, P NATL ACAD SCI USA, V111, P15220, DOI 10.1073/pnas.1416797111
   Smith LB, 2018, TRENDS COGN SCI, V22, P325, DOI 10.1016/j.tics.2018.02.004
   Snow C. E., 1977, TALKING CHILDREN LAN, P31
   Soderstrom M, 2007, DEV REV, V27, P501, DOI 10.1016/j.dr.2007.06.002
   Spinelli M, 2017, DEV REV, V44, P1, DOI 10.1016/j.dr.2016.12.001
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Thiessen ED, 2005, INFANCY, V7, P53, DOI 10.1207/s15327078in0701_5
   Thomas MSC, 2016, DEVELOPMENTAL SCI, V19, P284, DOI 10.1111/desc.12303
   TURKEWITZ G, 1982, DEV PSYCHOBIOL, V15, P357, DOI 10.1002/dev.420150408
   TURKEWITZ G, 1985, J DEV BEHAV PEDIATR, V6, P302
   Warlaumont AS, 2014, PSYCHOL SCI, V25, P1314, DOI 10.1177/0956797614531023
   Waterfall HR, 2010, J CHILD LANG, V37, P671, DOI 10.1017/S0305000910000024
   Webb AR, 2015, P NATL ACAD SCI USA, V112, P3152, DOI 10.1073/pnas.1414924112
   Werker JF, 1998, DEV PSYCHOL, V34, P1289, DOI 10.1037/0012-1649.34.6.1289
   Wiren Mats, 2016, 54 ANN M ASS COMP LI, P44, DOI 10.18653/v1/W16-19.
   Yingling J., 1981, THESIS
   Yu C, 2012, COGNITION, V125, P244, DOI 10.1016/j.cognition.2012.06.016
   Zangl R, 2007, INFANCY, V11, P31, DOI 10.1207/s15327078in1101_2
   2013, INFANCY, V18, P797
   1986, DEV PSYCHOL, V22, P155
   2014, DEV SCI, V17, P270
NR 134
TC 4
Z9 4
U1 3
U2 33
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0022-0965
EI 1096-0457
J9 J EXP CHILD PSYCHOL
JI J. Exp. Child Psychol.
PD JUL
PY 2019
VL 183
BP 48
EP 64
DI 10.1016/j.jecp.2018.12.011
PG 17
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA HV8UG
UT WOS:000466259000004
PM 30856417
DA 2021-02-24
ER

PT J
AU de Almeida, LR
   Pope, PA
   Hansen, PC
AF de Almeida, Lilian Rodrigues
   Pope, Paul A.
   Hansen, Peter C.
TI Task load modulates tDCS effects on language performance
SO JOURNAL OF NEUROSCIENCE RESEARCH
LA English
DT Article
DE cognition; language; pars opercularis of the left inferior frontal gyrus
   (LIFGop); phonological processing; task load; transcranial direct
   current stimulation (tDCS)
ID DIRECT-CURRENT STIMULATION; INFERIOR FRONTAL GYRUS; TRANSCRANIAL
   MAGNETIC STIMULATION; DORSOLATERAL PREFRONTAL CORTEX; NONINVASIVE
   BRAIN-STIMULATION; VENTRAL PREMOTOR CORTEX; PRIMARY MOTOR CORTEX; SPEECH
   PRODUCTION; INHIBITORY CONTROL; VIRTUAL LESION
AB Transcranial direct current stimulation (tDCS) effects in cognition are inconsistent across studies. This study aimed to discuss why typical models might be insufficient to explain these effects, and to investigate a brain state factor, task load, with behavioral experiments on phonological processing. The motor theory of speech perception states that motor codes for articulation take part in speech perception, a view sharpened by neuroimaging findings, which show that the motor role in phonological processing is weighted by the nature of the tasks. Three groups of 20 participants, each under a different tDCS condition (anodal, cathodal, or sham), performed a categorical perception (CP), a lexical decision (LD), and a word naming (WN) task while stimulated on the pars opercularis of the left inferior frontal gyrus, a language area typically involved with the motor role. These tasks were assumed to be subserved by a network of nodes which included the target, believed to be increasingly relevant for performance from speech perception to speech production. A-tDCS facilitation and C-tDCS downregulation should directly increase with the relevance of the target for the task. Downregulation of a low relevance node could result in facilitation by compensation from other nodes. Overall, our brain stimulation findings support the neuroimaging literature in that motor participation in phonological processing depends on task nature and show that tDCS effects are modulated by task load relative to the target. Outcomes such as the improved performance following cathodal tDCS in CP and WN suggest that compensatory mechanisms may take place when the tasks involve more complex neuronal networks.
C1 [de Almeida, Lilian Rodrigues; Pope, Paul A.; Hansen, Peter C.] Univ Birmingham, Sch Psychol, Birmingham B15 2TT, W Midlands, England.
RP de Almeida, LR (corresponding author), Univ Birmingham, Sch Psychol, Birmingham B15 2TT, W Midlands, England.
EM L.RodriguesDeAlmeida@bham.ac.uk
OI Rodrigues de Almeida, Lilian/0000-0002-1498-2207; Hansen,
   Peter/0000-0002-4948-1007
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES)
   (Brazil)/University of BirminghamCAPES
FX This work was supported by a postgraduate scholarship from Coordenacao
   de Aperfeicoamento de Pessoal de Nivel Superior (CAPES)
   (Brazil)/University of Birmingham to L.R.A.
CR Ackermann H, 2004, BRAIN LANG, V89, P320, DOI 10.1016/S0093-934X(03)00347-X
   Adank P, 2012, BRAIN LANG, V122, P42, DOI 10.1016/j.bandl.2012.04.014
   Amunts K, 1999, J COMP NEUROL, V412, P319, DOI 10.1002/(SICI)1096-9861(19990920)412:2<319::AID-CNE10>3.0.CO;2-7
   ANNETT M, 1972, BRIT J PSYCHOL, V63, P343, DOI 10.1111/j.2044-8295.1972.tb01282.x
   Au J, 2016, J COGNITIVE NEUROSCI, V28, P1419, DOI 10.1162/jocn_a_00979
   Baayen RH, 1995, CELEX LEXICAL DATABA
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Belyk M, 2017, NEUROIMAGE, V156, P240, DOI 10.1016/j.neuroimage.2017.04.020
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bestmann S, 2008, EXP BRAIN RES, V191, P383, DOI 10.1007/s00221-008-1601-8
   Bikson M, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00688
   Binder JR, 2003, J COGNITIVE NEUROSCI, V15, P372, DOI 10.1162/089892903321593108
   BINDMAN LJ, 1964, J PHYSIOL-LONDON, V172, P369, DOI 10.1113/jphysiol.1964.sp007425
   Bishop DVM, 2013, SCIENCE, V340, DOI 10.1126/science.1230531
   Blank SC, 2002, BRAIN, V125, P1829, DOI 10.1093/brain/awf191
   Boggio PS, 2007, J AFFECT DISORDERS, V101, P91, DOI 10.1016/j.jad.2006.10.026
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Buch ER, 2010, J NEUROSCI, V30, P1395, DOI 10.1523/JNEUROSCI.4882-09.2010
   Burton MW, 2001, COGNITIVE SCI, V25, P695, DOI 10.1207/s15516709cog2505_4
   Carreiras M, 2007, J COGNITIVE NEUROSCI, V19, P433, DOI 10.1162/jocn.2007.19.3.433
   Cattaneo Z, 2010, NEUROIMAGE, V49, P2728, DOI 10.1016/j.neuroimage.2009.10.048
   Chiappini E, 2018, CURR BIOL, V28, pR735, DOI 10.1016/j.cub.2018.05.083
   Cornelissen PL, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0005359
   Dapretto M, 1999, NEURON, V24, P427, DOI 10.1016/S0896-6273(00)80855-7
   DaSilva AF, 2011, JOVE-J VIS EXP, DOI 10.3791/2744
   Davare M, 2008, J PHYSIOL-LONDON, V586, P2735, DOI 10.1113/jphysiol.2008.152603
   Deng Y, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033337
   Duffau H, 2003, NEUROIMAGE, V20, P1903, DOI 10.1016/S1053-8119(03)00203-9
   Dufour S, 2010, Q J EXP PSYCHOL, V63, P226, DOI 10.1080/17470210903308336
   Eickhoff SB, 2009, PHILOS T R SOC A, V367, P2399, DOI 10.1098/rsta.2008.0287
   Feher J, 2012, ACAD PR SER BIOM ENG, P419
   Fertonani A, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00131
   Fiebach CJ, 2002, J COGNITIVE NEUROSCI, V14, P11, DOI 10.1162/089892902317205285
   FIEZ JA, 1995, J COGNITIVE NEUROSCI, V7, P357, DOI 10.1162/jocn.1995.7.3.357
   FORSTER KI, 1973, J VERB LEARN VERB BE, V12, P627, DOI 10.1016/S0022-5371(73)80042-8
   Foundas AL, 1996, P NATL ACAD SCI USA, V93, P719, DOI 10.1073/pnas.93.2.719
   Friederici AD, 2013, J COGNITIVE NEUROSCI, V25, P814, DOI 10.1162/jocn_a_00350
   Fritsch B, 2010, NEURON, V66, P198, DOI 10.1016/j.neuron.2010.03.035
   GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8
   Gough PM, 2005, J NEUROSCI, V25, P8010, DOI 10.1523/JNEUROSCI.2307-05.2005
   Hampson M, 2010, FRONT SYST NEUROSCI, V4, DOI 10.3389/fnsys.2010.00040
   Hanel PHP, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168354
   Hartwigsen G, 2016, CEREB CORTEX, V26, P2590, DOI 10.1093/cercor/bhv092
   Hartwigsen G, 2015, BRAIN LANG, V148, P81, DOI 10.1016/j.bandl.2014.10.007
   Hartwigsen G, 2013, P NATL ACAD SCI USA, V110, P16402, DOI 10.1073/pnas.1310190110
   Hartwigsen G, 2012, J NEUROSCI, V32, P16162, DOI 10.1523/JNEUROSCI.1010-12.2012
   Heim S, 2005, COGNITIVE BRAIN RES, V25, P982, DOI 10.1016/j.cogbrainres.2005.09.022
   Heinen K, 2016, NEUROPSYCHOLOGIA, V87, P35, DOI 10.1016/j.neuropsychologia.2016.04.028
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hussey EK, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141417
   Indefrey P, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00255
   Jackson GM, 2015, TRENDS COGN SCI, V19, P655, DOI 10.1016/j.tics.2015.08.006
   Jacobson L, 2012, EXP BRAIN RES, V216, P1, DOI 10.1007/s00221-011-2891-9
   Jager J, 2017, MONOGR SOC RES CHILD, V82, P13, DOI 10.1111/mono.12296
   JOHNSON NF, 1994, COGNITIVE PSYCHOL, V26, P240, DOI 10.1006/cogp.1994.1008
   Kaller CP, 2011, CEREB CORTEX, V21, P307, DOI 10.1093/cercor/bhq096
   Keuleers E, 2010, BEHAV RES METHODS, V42, P627, DOI 10.3758/BRM.42.3.627
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Krause B, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00602
   Kummerer D, 2013, BRAIN, V136, P619, DOI 10.1093/brain/aws354
   Kuo MF, 2006, NEUROREPORT, V17, P1703, DOI 10.1097/01.wnr.0000239955.68319.c2
   Lang N, 2004, EXP BRAIN RES, V156, P439, DOI 10.1007/s00221-003-1800-2
   Lee YS, 2012, J NEUROSCI, V32, P3942, DOI 10.1523/JNEUROSCI.3814-11.2012
   Leonard MK, 2014, TRENDS COGN SCI, V18, P472, DOI 10.1016/j.tics.2014.05.001
   Levy J, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0006675
   Liakakis G, 2011, BEHAV BRAIN RES, V225, P341, DOI 10.1016/j.bbr.2011.06.022
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Liebenthal E, 2013, J NEUROSCI, V33, P15414, DOI 10.1523/JNEUROSCI.1511-13.2013
   Loftus AM, 2015, BRAIN BEHAV, V5, DOI 10.1002/brb3.332
   Maldonado IL, 2011, BRAIN STRUCT FUNCT, V216, P263, DOI 10.1007/s00429-011-0309-x
   MARSHALL JC, 1973, J PSYCHOLINGUIST RES, V2, P175, DOI 10.1007/BF01067101
   Mazoyer B, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0101165
   McNorgan C, 2015, BRAIN LANG, V141, P110, DOI 10.1016/j.bandl.2014.12.002
   Meinzer M, 2013, J NEUROSCI, V33, P12470, DOI 10.1523/JNEUROSCI.5743-12.2013
   Meinzer M, 2012, J NEUROSCI, V32, P1859, DOI 10.1523/JNEUROSCI.4812-11.2012
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Miniussi C, 2013, NEUROSCI BIOBEHAV R, V37, P1702, DOI 10.1016/j.neubiorev.2013.06.014
   Miranda PC, 2006, CLIN NEUROPHYSIOL, V117, P1623, DOI 10.1016/j.clinph.2006.04.009
   Mirman D, 2013, J COGNITIVE NEUROSCI, V25, P1504, DOI 10.1162/jocn_a_00408
   Mishkin M., 1982, ANAL VISUAL BEHAV, P549
   Monti A, 2008, J NEUROL NEUROSUR PS, V79, P451, DOI 10.1136/jnnp.2007.135277
   Monti A, 2013, J NEUROL NEUROSUR PS, V84, P832, DOI 10.1136/jnnp-2012-302825
   Newman SD, 2003, COGNITIVE BRAIN RES, V16, P297, DOI 10.1016/S0926-6410(02)00285-9
   Nitsche MA, 2000, J PHYSIOL-LONDON, V527, P633, DOI 10.1111/j.1469-7793.2000.t01-1-00633.x
   Nitsche MA, 2015, BRAIN STIMUL, V8, P666, DOI 10.1016/j.brs.2015.03.008
   Nitsche MA, 2008, BRAIN STIMUL, V1, P206, DOI 10.1016/j.brs.2008.06.004
   Nosarti C, 2010, CEREB CORTEX, V20, P315, DOI 10.1093/cercor/bhp101
   Nozari N, 2014, BRAIN STIMUL, V7, P784, DOI 10.1016/j.brs.2014.07.035
   Nozari N, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0084338
   Pascual-Leone A, 2000, CURR OPIN NEUROBIOL, V10, P232, DOI 10.1016/S0959-4388(00)00081-7
   Patterson K, 1987, COGNITIVE NEUROPSYCH, P273
   Penolazzi B, 2014, J NEUROSCI, V34, P6606, DOI 10.1523/JNEUROSCI.0349-14.2014
   Pinheiro J., 2016, COMPUTER SOFTWARE, V3, P1, DOI DOI 10.1016/J.CR0PR0.2007.08.015
   Pirulli C, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00226
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   Pope PA, 2015, CEREB CORTEX, V25, P4551, DOI 10.1093/cercor/bhv094
   R Core Team, 2016, R LANG ENV STAT COMP
   Raizada RDS, 2007, NEURON, V56, P726, DOI 10.1016/j.neuron.2007.11.001
   Rampersad SM, 2014, IEEE T NEUR SYS REH, V22, P441, DOI 10.1109/TNSRE.2014.2308997
   Reynolds C., 2007, TEST IRREGULAR WORD
   ROGERS J, 1981, NEUROBIOL AGING, V2, P15, DOI 10.1016/0197-4580(81)90054-3
   Rogers JC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00754
   Rroji O, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127270
   Russell M, 2014, FRONT PSYCHIATRY, V5, DOI 10.3389/fpsyt.2014.00104
   Salvador R, 2010, IEEE ENG MED BIO, P2073, DOI 10.1109/IEMBS.2010.5626315
   Sasaki R, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00030
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Schnur TT, 2009, P NATL ACAD SCI USA, V106, P322, DOI 10.1073/pnas.0805874106
   SCHOTT GD, 1993, J NEUROL NEUROSUR PS, V56, P329, DOI 10.1136/jnnp.56.4.329
   Sergeeva EG, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00899
   Silvanto J, 2007, EUR J NEUROSCI, V25, P1874, DOI 10.1111/j.1460-9568.2007.05440.x
   Silvanto J, 2017, BRAIN COGNITION, V119, P32, DOI 10.1016/j.bandc.2017.09.007
   Silvanto J, 2008, TRENDS COGN SCI, V12, P447, DOI 10.1016/j.tics.2008.09.004
   Smalle EHM, 2015, CEREB CORTEX, V25, P3690, DOI 10.1093/cercor/bhu218
   Snyder HR, 2007, J COGNITIVE NEUROSCI, V19, P761, DOI 10.1162/jocn.2007.19.5.761
   Standage D, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00236
   Stewart L, 2001, ACTA PSYCHOL, V107, P275, DOI 10.1016/S0001-6918(01)00035-X
   TERZUOLO CA, 1956, P NATL ACAD SCI USA, V42, P687, DOI 10.1073/pnas.42.9.687
   Torgesen J, 1999, TEST WORD READING EF
   TURNER DA, 1991, NEUROBIOL AGING, V12, P201, DOI 10.1016/0197-4580(91)90098-5
   Vandermosten M, 2011, RES DEV DISABIL, V32, P593, DOI 10.1016/j.ridd.2010.12.015
   Vitevitch MS, 2007, MEM COGNITION, V35, P166, DOI 10.3758/BF03195952
   Wagner T, 2007, NEUROIMAGE, V35, P1113, DOI 10.1016/j.neuroimage.2007.01.027
   Wang Bin, 2009, Journal of Aeronautical Materials, V29, P1
   Watkins K, 2004, J COGNITIVE NEUROSCI, V16, P978, DOI 10.1162/0898929041502616
   Weidacker K, 2016, CLIN NEUROPHYSIOL, V127, P3102, DOI 10.1016/j.clinph.2016.05.274
   Wheat KL, 2010, J NEUROSCI, V30, P5229, DOI 10.1523/JNEUROSCI.4448-09.2010
   Whelan R, 2008, PSYCHOL REC, V58, P475, DOI 10.1007/BF03395630
   WILLIAMS EJ, 1949, AUST J SCI RES SER A, V2, P149, DOI 10.1071/CH9490149
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Winter B., 2013, LINEAR MODELS LINEAR
   Wise RJS, 1999, LANCET, V353, P1057, DOI 10.1016/S0140-6736(98)07491-1
   Woodhead ZVJ, 2014, CEREB CORTEX, V24, P817, DOI 10.1093/cercor/bhs365
   Xiao ZW, 2005, HUM BRAIN MAPP, V25, P212, DOI 10.1002/hbm.20105
   Yarkoni T, 2008, PSYCHON B REV, V15, P971, DOI 10.3758/PBR.15.5.971
NR 135
TC 4
Z9 4
U1 1
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0360-4012
EI 1097-4547
J9 J NEUROSCI RES
JI J. Neurosci. Res.
PD NOV
PY 2019
VL 97
IS 11
BP 1430
EP 1454
DI 10.1002/jnr.24490
EA JUN 2019
PG 25
WC Neurosciences
SC Neurosciences & Neurology
GA IZ4YJ
UT WOS:000474044600001
PM 31254311
DA 2021-02-24
ER

PT J
AU Cardon, G
   Sharma, A
AF Cardon, Garrett
   Sharma, Anu
TI Somatosensory Cross-Modal Reorganization in Children With Cochlear
   Implants
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE cochlear implants; cross-modal reorganization; somatosensory;
   vibrotactile; cortical somatosensory evoked potential; high density EEG;
   independent components analysis; sLORETA
ID SPOKEN LANGUAGE-DEVELOPMENT; VISUAL-EVOKED-POTENTIALS; ACTIVATE
   AUDITORY-CORTEX; PROFOUNDLY DEAF-CHILDREN; SPEECH-PERCEPTION; CORTICAL
   REORGANIZATION; DEVELOPMENTAL-CHANGES; SELECTIVE ATTENTION; MOTOR
   THEORY; HEARING
AB Deprived of sensory input, as in deafness, the brain tends to reorganize. Cross-modal reorganization occurs when cortices associated with deficient sensory modalities are recruited by other, intact senses for processing of the latter's sensory input. Studies have shown that this type of reorganization may affect outcomes when sensory stimulation is later introduced via intervention devices. One such device is the cochlear implant (CI). Hundreds of thousands of CIs have been fitted on people with hearing impairment worldwide, many of them children. Factors such as age of implantation have proven useful in predicting speech perception outcome with these devices in children. However, a portion of the variance in speech understanding ability remains unexplained. It is possible that the degree of cross-modal reorganization may explain additional variability in listening outcomes. Thus, the current study aimed to examine possible somatosensory cross-modal reorganization of the auditory cortices. To this end we used high density EEG to record cortical responses to vibrotactile stimuli in children with normal hearing (NH) and those with CIs. We first investigated cortical somatosensory evoked potentials (CSEP) in NH children, in order to establish normal patterns of CSEP waveform morphology and sources of cortical activity. We then compared CSEP waveforms and estimations of cortical sources between NH children and those with CIs to assess the degree of somatosensory cross-modal reorganization. Results showed that NH children showed expected patterns of CSEP and current density reconstructions, such that postcentral cortices were activated contralaterally to the side of stimulation. Participants with CIs also showed this pattern of activity. However, in addition, they showed activation of auditory cortical areas in response to somatosensory stimulation. Additionally, certain CSEP waveform components were significantly earlier in the CI group than the children with NH. These results are taken as evidence of cross-modal reorganization by the somatosensory modality in children with CIs. Speech perception in noise scores were negatively associated with CSEP waveform components latencies in the CI group, suggesting that the degree of cross-modal reorganization is related to speech perception outcomes. These findings may have implications for clinical rehabilitation in children with cochlear implants.
C1 [Cardon, Garrett] Colorado State Univ, Dept Psychol, Ft Collins, CO 80523 USA.
   [Sharma, Anu] Univ Colorado, Dept Speech Language & Hearing Sci, Boulder, CO 80309 USA.
RP Sharma, A (corresponding author), Univ Colorado, Dept Speech Language & Hearing Sci, Boulder, CO 80309 USA.
EM Anu.sharma@colorado.edu
FU NIMHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute of Mental Health
   (NIMH) [T32MH015442]; NIDCDUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [F31 DC013218-01A1,
   R01 DC016346]; NATIONAL INSTITUTE OF MENTAL HEALTHUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute of Mental Health (NIMH) [T32MH015442,
   T32MH015442, T32MH015442] Funding Source: NIH RePORTER; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01DC016346, R01DC016346, R01DC016346, R01DC016346] Funding
   Source: NIH RePORTER
FX This research was funded by NIMH T32MH015442 and NIDCD F31 DC013218-01A1
   to GC and R01 DC016346 to AS.
CR ALLISON T, 1984, ELECTROEN CLIN NEURO, V58, P14, DOI 10.1016/0013-4694(84)90196-2
   Allman BL, 2009, P NATL ACAD SCI USA, V106, P5925, DOI 10.1073/pnas.0809483106
   Ammirante P, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053585
   Auer ET, 2007, NEUROREPORT, V18, P645, DOI 10.1097/WNR.0b013e3280d943b9
   Baldwin R. L, 2002, THESIS
   Bavelier D, 2002, NAT REV NEUROSCI, V3, P443, DOI 10.1038/nrn848
   Bavelier D, 2010, NAT NEUROSCI, V13, P1309, DOI 10.1038/nn1110-1309
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Brett-Green BA, 2008, BRAIN RES, V1242, P283, DOI 10.1016/j.brainres.2008.03.090
   Caetano G, 2006, NEUROIMAGE, V29, P15, DOI 10.1016/j.neuroimage.2005.07.023
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   Cardon G, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00172
   Clemo HR, 2016, CEREB CORTEX, V26, P1365, DOI 10.1093/cercor/bhu225
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   DESMEDT JE, 1989, ELECTROEN CLIN NEURO, V74, P321, DOI 10.1016/0168-5597(89)90001-4
   DESMEDT JE, 1976, ELECTROEN CLIN NEURO, V40, P43, DOI 10.1016/0013-4694(76)90178-4
   Doucet ME, 2006, BRAIN, V129, P3376, DOI 10.1093/brain/awl264
   EGGERMONT JJ, 1988, ELECTROEN CLIN NEURO, V70, P293, DOI 10.1016/0013-4694(88)90048-X
   ELLINGSON RJ, 1986, ELECTROEN CLIN NEURO, V63, P309, DOI 10.1016/0013-4694(86)90015-5
   Etymotic Research, 2005, BKB SINTM SPEECH IN
   EVANS AC, 1993, NUCLEAR SCIENCE SYMPOSIUM & MEDICAL IMAGING CONFERENCE, VOLS 1-3, P1813, DOI 10.1109/NSSMIC.1993.373602
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   FAGAN ER, 1987, PEDIATR NEUROL, V3, P189, DOI 10.1016/0887-8994(87)90015-4
   Fine I, 2005, J COGNITIVE NEUROSCI, V17, P1621, DOI 10.1162/089892905774597173
   Fink Nancy E, 2007, Cochlear Implants Int, V8, P92, DOI 10.1002/cii.333
   Finney EM, 2003, NEUROREPORT, V14, P1425, DOI 10.1097/00001756-200308060-00004
   Finney EM, 2001, NAT NEUROSCI, V4, P1171, DOI 10.1038/nn763
   Food and Drug Administration [ FDA], 2012, MAN VOL REP REG DEV
   Foxe JJ, 2000, COGNITIVE BRAIN RES, V10, P77, DOI 10.1016/S0926-6410(00)00024-0
   Fuchs M, 2002, CLIN NEUROPHYSIOL, V113, P702, DOI 10.1016/S1388-2457(02)00030-5
   Gaffney M., 2010, Morbidity and Mortality Weekly Report, V59, P220
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Geers Ann E, 2006, Adv Otorhinolaryngol, V64, P50, DOI 10.1159/000094644
   Geers AE, 2009, J DEAF STUD DEAF EDU, V14, P371, DOI 10.1093/deafed/enn046
   Gick B, 2009, NATURE, V462, P502, DOI 10.1038/nature08572
   Gilley PM, 2008, BRAIN RES, V1239, P56, DOI 10.1016/j.brainres.2008.08.026
   Gilley PM, 2005, CLIN NEUROPHYSIOL, V116, P648, DOI 10.1016/j.clinph.2004.09.009
   Gobbele R, 2003, NEUROIMAGE, V20, P503, DOI 10.1016/S1053-8119(03)00312-4
   Gordon KA, 2013, BRAIN, V136, P1609, DOI 10.1093/brain/awt052
   Gordon KA, 2009, OTOL NEUROTOL, V30, P319, DOI 10.1097/MAO.0b013e31819a8f4c
   Grech R, 2008, J NEUROENG REHABIL, V5, DOI 10.1186/1743-0003-5-25
   Hackett TA, 2007, PERCEPTION, V36, P1419, DOI 10.1068/p5841
   Hallez H, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-46
   HAMALAINEN H, 1990, ELECTROEN CLIN NEURO, V75, P13, DOI 10.1016/0013-4694(90)90148-D
   HARI R, 1984, ELECTROEN CLIN NEURO, V57, P254, DOI 10.1016/0013-4694(84)90126-3
   HARI R, 1993, EUR J NEUROSCI, V5, P724, DOI 10.1111/j.1460-9568.1993.tb00536.x
   HARI R, 1983, ACTA NEUROL SCAND, V68, P207, DOI 10.1111/j.1600-0404.1983.tb04828.x
   Harrison RV, 2005, DEV PSYCHOBIOL, V46, P252, DOI 10.1002/dev.20052
   Hickok G, 1997, HUM BRAIN MAPP, V5, P437, DOI 10.1002/(SICI)1097-0193(1997)5:6<437::AID-HBM4>3.0.CO;2-4
   Hixson SM, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152264
   Holt RF, 2008, EAR HEARING, V29, P492, DOI 10.1097/AUD.0b013e31816c409f
   Huang J, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-02429-1
   Hubka P, 2015, CELL TISSUE RES, V361, P279, DOI 10.1007/s00441-014-2059-6
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   Jiwani S, 2016, HUM BRAIN MAPP, V37, P135, DOI 10.1002/hbm.23019
   JOHNSON D, 1975, EXP BRAIN RES, V22, P331
   Jousmaki V, 1998, CURR BIOL, V8, pR190, DOI 10.1016/S0960-9822(98)70120-4
   Karns CM, 2012, J NEUROSCI, V32, P9626, DOI 10.1523/JNEUROSCI.6488-11.2012
   Kayser C, 2005, NEURON, V48, P373, DOI 10.1016/j.neuron.2005.09.018
   Kok MA, 2014, J COMP NEUROL, V522, P654, DOI 10.1002/cne.23439
   Kral A, 2002, CEREB CORTEX, V12, P797, DOI 10.1093/cercor/12.8.797
   Kral A, 2007, INT J AUDIOL, V46, P479, DOI 10.1080/14992020701383027
   Kral A, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00093
   Lakatos P, 2007, NEURON, V53, P279, DOI 10.1016/j.neuron.2006.12.011
   Levanen S, 1998, CURR BIOL, V8, P869, DOI 10.1016/S0960-9822(07)00348-X
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Lomber SG, 2010, NAT NEUROSCI, V13, P1421, DOI 10.1038/nn.2653
   Lund E, 2016, J DEAF STUD DEAF EDU, V21, P107, DOI 10.1093/deafed/env060
   LUU P, 2000, DETERMINATION GEODES
   MAUGUIERE F, 1983, BRAIN, V106, P271, DOI 10.1093/brain/106.2.271
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Merabet LB, 2010, NAT REV NEUROSCI, V11, P44, DOI 10.1038/nrn2758
   Meredith MA, 2012, NEURAL PLAST, V2012, DOI 10.1155/2012/601591
   Meredith MA, 2011, HEARING RES, V280, P38, DOI 10.1016/j.heares.2011.02.004
   MICHIE PT, 1987, PSYCHOPHYSIOLOGY, V24, P449, DOI 10.1111/j.1469-8986.1987.tb00316.x
   NEVILLE HJ, 1987, BRAIN RES, V405, P268, DOI 10.1016/0006-8993(87)90296-4
   NEVILLE HJ, 1983, BRAIN RES, V266, P127, DOI 10.1016/0006-8993(83)91314-8
   Nicholas JG, 2007, J SPEECH LANG HEAR R, V50, P1048, DOI 10.1044/1092-4388(2007/073)
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   PANDYA DN, 1969, BRAIN RES, V13, P13, DOI 10.1016/0006-8993(69)90141-3
   Pascual-Marqui RD, 2002, METHOD FIND EXP CLIN, V24, P5
   Pihko E, 2009, CLIN NEUROPHYSIOL, V120, P1552, DOI 10.1016/j.clinph.2009.05.028
   PLACZEK M, 1985, DEV MED CHILD NEUROL, V27, P448
   Ponton CW, 2000, CLIN NEUROPHYSIOL, V111, P220, DOI 10.1016/S1388-2457(99)00236-9
   REBILLARD G, 1977, BRAIN RES, V129, P162, DOI 10.1016/0006-8993(77)90980-5
   Russo FA, 2012, J EXP PSYCHOL HUMAN, V38, P822, DOI 10.1037/a0029046
   Sadato N, 2005, NEUROSCIENTIST, V11, P577, DOI 10.1177/1073858405277314
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   Sarant J, 2014, EAR HEARING, V35, P396, DOI 10.1097/AUD.0000000000000022
   Sarant JZ, 2001, EAR HEARING, V22, P18, DOI 10.1097/00003446-200102000-00003
   Schroeder CE, 2001, J NEUROPHYSIOL, V85, P1322
   Scott GD, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00177
   Sharma A, 1997, EVOKED POTENTIAL, V104, P540, DOI 10.1016/S0168-5597(97)00050-6
   Sharma A, 2002, NEUROREPORT, V13, P1365, DOI 10.1097/00001756-200207190-00030
   Sharma A, 2007, INT J AUDIOL, V46, P494, DOI 10.1080/14992020701524836
   Sharma A, 2016, BRAIN SCI, V6, DOI 10.3390/brainsci6010004
   Sharma A, 2016, OTOL NEUROTOL, V37, pE26, DOI 10.1097/MAO.0000000000000904
   Sharma A, 2015, INT J PSYCHOPHYSIOL, V95, P135, DOI 10.1016/j.ijpsycho.2014.04.007
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   Shore SE, 2008, EUR J NEUROSCI, V27, P155, DOI 10.1111/j.1460-9568.2007.05983.x
   SITZOGLOU C, 1985, NEUROPEDIATRICS, V16, P205, DOI 10.1055/s-2008-1059538
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Soto-Faraco S, 2009, BEHAV BRAIN RES, V196, P145, DOI 10.1016/j.bbr.2008.09.018
   Svirsky MA, 2004, AUDIOL NEURO-OTOL, V9, P224, DOI 10.1159/000078392
   Svirsky MA, 2000, PSYCHOL SCI, V11, P153, DOI 10.1111/1467-9280.00231
   Szagun G, 2016, J CHILD LANG, V43, P505, DOI 10.1017/S0305000915000641
   The MathWorks, 2014, MATLAB VERS R2014B S
   Tobey EA, 2003, EAR HEARING, V24, p36S, DOI 10.1097/01.AUD.0000051688.48224.A6
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   WEINSTEIN SIDNEY, 1968, P195
   Wilke M, 2007, EXP BRAIN RES, V178, P296, DOI 10.1007/s00221-006-0732-z
   YAMAGUCHI S, 1991, ELECTROEN CLIN NEURO, V78, P297, DOI 10.1016/0013-4694(91)90184-6
   Zeng CH, 2012, J NEUROSCI, V32, P15791, DOI 10.1523/JNEUROSCI.2598-12.2012
NR 115
TC 1
Z9 1
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD JUN 26
PY 2019
VL 13
AR 469
DI 10.3389/fnins.2019.00469
PG 14
WC Neurosciences
SC Neurosciences & Neurology
GA IF6YI
UT WOS:000473228300001
PM 31312115
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Caccia, M
   Presti, G
   Toraldo, A
   Radaelli, A
   Ludovico, LA
   Ogliari, A
   Lorusso, ML
AF Caccia, Martina
   Presti, Giorgio
   Toraldo, Alessio
   Radaelli, Anthea
   Ludovico, Luca Andrea
   Ogliari, Anna
   Lorusso, Maria Luisa
TI Pitch as the Main Determiner of Italian Lexical Stress Perception Across
   the Lifespan: Evidence From Typical Development and Dyslexia
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE lexical stress; acoustic parameters; developmental dyslexia;
   developmental trajectories; Italian language; pitch; duration; intensity
ID AMPLITUDE ENVELOPE PERCEPTION; PHONOLOGICAL AWARENESS; READING
   DEVELOPMENT; SPEECH-PERCEPTION; YOUNG-CHILDREN; INFANTS; LANGUAGE;
   SENSITIVITY; DURATION; PHONEME
AB The study deals with the issue of lexical stress perception in both a developmental (comparing children and adults with typical development) and a clinical perspective (comparing typically developing children and children with dyslexia). The three parameters characterizing the acoustic profiles of words and non-words in a certain language are duration, pitch and intensity of its syllables. Based on (sparse) previous literature on Italian and other European languages, it was expected that syllable duration would be the parameter predominantly determining the perception of stress position. It was furthermore anticipated that children with dyslexia may be found to have an altered perception of lexical stress, due to their impairments in auditory processing of either pitch, duration or (more controversial) intensity. Systematic manipulation of the pitch, duration and intensity profiles of three Italian trisyllabic non-words produced a series of 81 stimuli, that were judged with respect to stress position (perceived on the ultimate, penultimate, or antepenultimate syllable) by the three groups of participants. The results showed, contrarily to expectations, that the pitch component is the most reliable acoustic cue in stress perception for both adults, in whom this dominance is very strong, and typically developing children, who showed a similar but quantitatively less marked pattern. As to children with dyslexia, they did not seem to rely on any parameter for their judgments, and rather gave random responses, which point to a general inability to process the various acoustic modulations that normally contribute to stress perception. Performance on the stress perception task strongly correlates with language (morphosyntactic) measures in the whole sample of children, and with reading abilities in the group with dyslexia, confirming the strict relationship between the two sets of skills. These findings seem to support a language-specific approach, suggesting that the set of acoustic parameters required for the development of stress perception is language-dependent rather than universal.
C1 [Caccia, Martina] Univ Sch Adv Studies, Ctr Neurocognit Epistemol & Theoret Syntax, Pavia, Italy.
   [Caccia, Martina; Lorusso, Maria Luisa] Sci Inst IRCCS E Medea, Dept Child Psychopathol, Unit Neuropsychol Dev Disorders, Bosisio Parini, Italy.
   [Presti, Giorgio; Ludovico, Luca Andrea] Univ Milan, Dept Comp Sci, Lab Mus Informat LIM, Milan, Italy.
   [Toraldo, Alessio] Univ Pavia, Dept Brain & Behav Sci, Pavia, Italy.
   [Toraldo, Alessio] Milan Ctr Neurosci, Milan, Italy.
   [Radaelli, Anthea; Ogliari, Anna] Univ Vita Salute San Raffaele, Dev Psychopathol Unit, Milan, Italy.
RP Lorusso, ML (corresponding author), Sci Inst IRCCS E Medea, Dept Child Psychopathol, Unit Neuropsychol Dev Disorders, Bosisio Parini, Italy.
EM marialuisalorusso@lanostrafamiglia.it
RI Ogliari, Anna/AAN-1961-2020; Ludovico, Luca Andrea/X-6542-2019; Lorusso,
   Maria Luisa/K-8769-2016
OI Ogliari, Anna/0000-0003-0920-3595; Ludovico, Luca
   Andrea/0000-0002-8251-2231; Lorusso, Maria Luisa/0000-0003-4640-306X;
   PRESTI, GIORGIO/0000-0001-7643-9915
FU Italian Ministry of HealthMinistry of Health, Italy
FX This work was supported by the Italian Ministry of Health (Grant No.
   RC2018-2019).
CR Alfano I., 2006, P 2 AISV, P632
   Alfano I., 2007, P 16 INT C PHON SCI
   Angelelli P, 2010, CORTEX, V46, P1299, DOI 10.1016/j.cortex.2010.06.015
   [Anonymous], 2001, REPORT TASK FORCE DY
   Antoniou M, 2015, APPL PSYCHOLINGUIST, V36, P1493, DOI 10.1017/S0142716414000514
   Arciuli J, 2016, SPEECH COMMUN, V80, P22, DOI 10.1016/j.specom.2016.03.002
   Bakker Dirk J, 2006, Pediatr Rehabil, V9, P3
   Baldeweg T, 1999, ANN NEUROL, V45, P495, DOI 10.1002/1531-8249(199904)45:4<495::AID-ANA11>3.0.CO;2-M
   Barry JG, 2012, DYSLEXIA, V18, P139, DOI 10.1002/dys.1440
   Belacchi C, 2008, CPM COLOURED PROGR M
   BERTINETTO PM, 1980, J PHONETICS, V8, P385, DOI 10.1016/S0095-4470(19)31495-0
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bogliotti C, 2008, J EXP CHILD PSYCHOL, V101, P137, DOI 10.1016/j.jecp.2008.03.006
   Bonacina S, 2015, FRONT PSYCHOL, V6, DOI [10.3389/fpsyg.2015.01510, 10.3389/fpsyg.2015,01510]
   Bortolini U., 1976, STUDI FONETICA FONOL, V1, P2
   Caccia M, 2019, LINGUA, V224, P16, DOI 10.1016/j.lingua.2019.03.008
   Cantiani C, 2015, DEV NEUROPSYCHOL, V40, P291, DOI 10.1080/87565641.2015.1072536
   Cantiani C, 2010, DEV NEUROPSYCHOL, V35, P115, DOI 10.1080/87565640903335955
   CHIAT S, 1983, COGNITION, V14, P275, DOI 10.1016/0010-0277(83)90007-0
   Chung WL, 2017, READ WRIT, V30, P1407, DOI 10.1007/s11145-017-9730-8
   Cornoldi C., 2011, PROVE RAPIDITA CORRE
   D'Imperio Mariapaola, 1999, PHONOLOGY, V16, P1, DOI DOI 10.1017/S0952675799003681
   DAUER RM, 1983, J PHONETICS, V11, P51, DOI 10.1016/S0095-4470(19)30776-4
   DImperio Mariapaola, 2002, PROBUS, V14, DOI [10.1515/prbs.2002.005, DOI 10.1515/PRBS.2002.005]
   Dupoux E, 1997, J MEM LANG, V36, P406, DOI 10.1006/jmla.1996.2500
   Elbro C, 2005, SCAND J PSYCHOL, V46, P375, DOI 10.1111/j.1467-9450.2005.00468.x
   Eriksson A, 2016, INTERSPEECH, P1059, DOI 10.21437/Interspeech.2016-348
   FANT G, 1991, J PHONETICS, V19, P351, DOI 10.1016/S0095-4470(19)30327-4
   Fava Elisabetta, 1976, ATT C INT STUD FON F, P35
   FERRARI E, 1981, NEUROPSICHIATRIA INF, V235, P148
   Ferrero F., 1972, PAROLE METODI, V3, P9
   FOWLER CA, 1983, J EXP PSYCHOL GEN, V112, P386, DOI 10.1037/0096-3445.112.3.386
   Fox R. A., 1987, P WORKING PAPERS LIN, V35, P11
   FOX RA, 1987, PERCEPT MOTOR SKILL, V65, P35, DOI 10.2466/pms.1987.65.1.35
   FOX RA, 1985, J ACOUST SOC AM, V77, pS54
   Frazier L, 2006, TRENDS COGN SCI, V10, P244, DOI 10.1016/j.tics.2006.04.002
   Frey A, 2019, NEUROPSYCHOLOGIA, V130, P3, DOI 10.1016/j.neuropsychologia.2018.07.033
   Gemelli A., 1950, STRUTTURAZIONE PSICO
   Gleitman L. R., 1982, LANG ACQUIS, P3
   Gomes H, 1999, DEV PSYCHOL, V35, P294, DOI 10.1037/0012-1649.35.1.294
   Goswami U, 2002, P NATL ACAD SCI USA, V99, P10911, DOI 10.1073/pnas.122368599
   Goswami U, 2013, J MEM LANG, V69, P1, DOI 10.1016/j.jml.2013.03.001
   Goswami U, 2010, READ WRIT, V23, P995, DOI 10.1007/s11145-009-9186-6
   Goswami U, 2011, J COGNITIVE NEUROSCI, V23, P325, DOI 10.1162/jocn.2010.21453
   Hamalainen JA, 2009, APPL PSYCHOLINGUIST, V30, P511, DOI 10.1017/S0142716409090250
   Hamalainen JA, 2013, J LEARN DISABIL-US, V46, P413, DOI 10.1177/0022219411436213
   HASEGAWA Y, 1992, LANG SPEECH, V35, P87, DOI 10.1177/002383099203500208
   Himmelmann NP, 2008, LANG DOC CONSERV, V2, P244
   Hirst D., 1998, INTONATION SYSTEMS S
   HOEQUIST CE, 1983, LANG SPEECH, V26, P367, DOI 10.1177/002383098302600404
   Huss M, 2011, CORTEX, V47, P674, DOI 10.1016/j.cortex.2010.07.010
   JUSCZYK PW, 1993, CHILD DEV, V64, P675, DOI 10.2307/1131210
   JUSCZYK PW, 1978, PERCEPT PSYCHOPHYS, V23, P105, DOI 10.3758/BF03208289
   KELLER TA, 1994, DEV PSYCHOL, V30, P855, DOI 10.1037/0012-1649.30.6.855
   KELLY MH, 1988, COGNITION, V30, P107, DOI 10.1016/0010-0277(88)90037-6
   Kuhn MR., 2010, READ RES QUART, V45, P230, DOI [DOI 10.1598/RRQ.45.2.4, 10.1598/RRQ.45.2.4]
   Kujala T, 2000, PSYCHOPHYSIOLOGY, V37, P262
   Law JM, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00482
   Lehiste Ilse, 1977, J PHONETICS, V5, P253, DOI 10.1016/S0095-4470(19)31139-8
   Leong V, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00096
   Leppanen PHT, 2002, DEV NEUROPSYCHOL, V22, P407, DOI 10.1207/S15326942dn2201_4
   Leppanen PHT, 1999, NEUROREPORT, V10, P969, DOI 10.1097/00001756-199904060-00014
   Lorusso ML, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00313
   Lorusso ML, 2011, J LEARN DISABIL-US, V44, P136, DOI 10.1177/0022219410391186
   Lorusso ML, 2006, NEUROPSYCHOL REHABIL, V16, P194, DOI 10.1080/09602010500145620
   MARCOS H, 1987, J CHILD LANG, V14, P255, DOI 10.1017/S0305000900012915
   Marinelli CV, 2017, COGN NEUROPSYCHOL, V34, P163, DOI 10.1080/02643294.2017.1386168
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Mattys SL, 1999, COGNITIVE PSYCHOL, V38, P465, DOI 10.1006/cogp.1999.0721
   McAnally KI, 1996, P ROY SOC B-BIOL SCI, V263, P961, DOI 10.1098/rspb.1996.0142
   McBride-Chang C, 2008, SCI STUD READ, V12, P171, DOI 10.1080/10888430801917290
   Metsala JL, 1998, WORD RECOGNITION IN BEGINNING LITERACY, P89
   MORTON J, 1976, PSYCHOL REV, V83, P405, DOI 10.1037/0033-295X.83.5.405
   Muneaux M, 2004, NEUROREPORT, V15, P1255, DOI 10.1097/01.wnr.0000127459.31232.c4
   Nespor M, 2011, BLACKWELL COMPANION, P1147, DOI [10.1002/9781444335262.wbctp0048, DOI 10.1002/9781444335262]
   Orsini A., 2012, WISC 4 CONTRIBUTO TA
   Orsolini M, 2006, LANG COGNITIVE PROC, V21, P576, DOI 10.1080/01690960500139355
   Paizi D, 2011, READ WRIT, V24, P443, DOI 10.1007/s11145-010-9236-0
   Panconcelli-Calzia G., 1912, VOX, V27, P127
   Pavlidou EV, 2009, ANN DYSLEXIA, V59, P55, DOI 10.1007/s11881-009-0023-z
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Perfetti C, 2007, SCI STUD READ, V11, P357, DOI 10.1080/10888430701530730
   Peterson RL, 2012, LANCET, V379, P1997, DOI 10.1016/S0140-6736(12)60198-6
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   Plantinga J, 2005, COGNITION, V98, P1, DOI 10.1016/j.cognition.2004.09.008
   Raven J. C., 1947, RAVENS PROGR MAT TES
   Richardson U, 2004, DYSLEXIA, V10, P215, DOI 10.1002/dys.276
   ROSSON MB, 1983, MEM COGNITION, V11, P152, DOI 10.3758/BF03213470
   Sansavini A, 1997, DEV PSYCHOL, V33, P3, DOI 10.1037/0012-1649.33.1.3
   Sartori G., 2007, DDE 2 GIUNTI OS ORG
   Schulte-Korne G, 1999, EUR CHILD ADOLES PSY, V8, P28
   Siegel L., 2008, SAGE HDB DYSLEXIA
   Skoruppa K, 2009, DEVELOPMENTAL SCI, V12, P914, DOI 10.1111/j.1467-7687.2009.00835.x
   Snedeker J, 2008, J MEM LANG, V58, P574, DOI 10.1016/j.jml.2007.08.001
   Sturm P, 2016, J PHONETICS, V55, P38, DOI 10.1016/j.wocn.2015.11.003
   Tallal P., 1980, B ORTON SOC, V30, P170, DOI [10.1007/BF02653716, DOI 10.1007/BF02653716]
   Thomson JM, 2013, READ WRIT, V26, P139, DOI 10.1007/s11145-012-9359-6
   Toraldo A, 2006, APHASIOLOGY, V20, P823, DOI 10.1080/02687030600738838
   Toraldo A, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00518
   Trainor LJ, 2002, PSYCHON B REV, V9, P335, DOI 10.3758/BF03196290
   Trehub SE, 2001, ANN NY ACAD SCI, V930, P1
   TREHUB SE, 1984, CHILD DEV, V55, P821, DOI 10.2307/1130133
   Wang HLS, 2012, READ WRIT, V25, P509, DOI 10.1007/s11145-010-9284-5
   Wang Y, 1999, J ACOUST SOC AM, V106, P3649, DOI 10.1121/1.428217
   Wood C., 2009, CONT PERSPECTIVES RE, P9, DOI 10.4324/9780203877838
   Wood C, 2006, J RES READ, V29, P270, DOI 10.1111/j.1467-9817.2006.00308.x
   World Health Organization, 1992, ICD 10 CLASSIFICATIO
   Zhang JA, 2010, EDUC PSYCHOL REV, V22, P323, DOI 10.1007/s10648-010-9137-4
   Ziegler JC, 2012, BRAIN LANG, V120, P265, DOI 10.1016/j.bandl.2011.12.002
NR 109
TC 1
Z9 1
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JUN 26
PY 2019
VL 10
AR 1458
DI 10.3389/fpsyg.2019.01458
PG 16
WC Psychology, Multidisciplinary
SC Psychology
GA IF6GR
UT WOS:000473179600001
PM 31316427
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU van Bijnen, S
   Karkkainen, S
   Helenius, P
   Parviainen, T
AF van Bijnen, Sam
   Karkkainen, Salme
   Helenius, Paivi
   Parviainen, Tiina
TI SCIENTIFIC REP RTS OPEN Left hemisphere enhancement of auditory
   activation in language impaired children
SO SCIENTIFIC REPORTS
LA English
DT Article
ID EVENT-RELATED POTENTIALS; MAGNETIC RESPONSE; SPEECH-PERCEPTION;
   SAMPLE-SIZE; LATERALIZATION; COMPONENTS; MATURATION; LATENCY; STIMULI;
   SOUNDS
AB Specific language impairment (SLI) is a developmental disorder linked to deficient auditory processing. In this magnetoencephalography (MEG) study we investigated a specific prolonged auditory response (N250m) that has been reported predominantly in children and is associated with level of language skills. We recorded auditory responses evoked by sine-wave tones presented alternately to the right and left ear of 9-10-year-old children with SLI (n = 10) and children with typical language development (n = 10). Source analysis was used to isolate the N250m response in the left and right hemisphere. In children with language impairment left-hemisphere N250m responses were enhanced compared to those of controls, while no group difference was found in the right hemisphere. Consequently, language impaired children lacked the typical right-ward asymmetry that was found in control children. Furthermore, left but not right hemisphere N250m responses correlated positively with performance on a phonological processing task in the SLI group exclusively, possibly signifying a compensatory mechanism for delayed maturation of language processing. These results suggest that enhanced left-hemisphere auditory activation reflects a core neurophysiological manifestation of developmental language disorders, and emphasize the relevance of this developmentally specific activation pattern for competent language development.
C1 [van Bijnen, Sam; Parviainen, Tiina] Univ Jyvaskyla, Ctr Interdisciplinary Brain Res, Dept Psychol, POB 35, FI-40014 Jyvaskyla, Finland.
   [Karkkainen, Salme] Univ Jyvaskyla, Dept Math & Stat, POB 35, FI-40014 Jyvaskyla, Finland.
   [Helenius, Paivi] Helsinki Univ Hosp, HUS, Div Child Neurol, POB 100, FI-00029 Helsinki, Finland.
   [Parviainen, Tiina] Aalto Univ, Meg Core Aalto Neuroimaging, POB 15100, FI-00076 Espoo, Finland.
RP van Bijnen, S (corresponding author), Univ Jyvaskyla, Ctr Interdisciplinary Brain Res, Dept Psychol, POB 35, FI-40014 Jyvaskyla, Finland.
EM sam.s.yanbijnen@jyu.fi
RI Parviainen, Tiina/I-4803-2016; Helenius, Paivi/W-9470-2019
OI Parviainen, Tiina/0000-0001-6992-5157; Helenius,
   Paivi/0000-0001-8842-7065; van Bijnen, Sam/0000-0003-0023-6032
FU EU project ChildBrain (Horizon2020 Marie Sklodowska-Curie Action (MSCA)
   Innovative Training Network (ITN) - European Training Network (ETN))
   [641652]; Academy of FinlandAcademy of FinlandEuropean Commission
   [114794]
FX We are grateful to Paivi Sivonen, Leena Isotalo and Mia Illman for
   assistance in the MEG recordings, to Mari Laine for behavioral testing
   of the children, to Riitta Salmelin and Timo Kauppila for valuable
   comments when planning the experiments and Twan Hendrikx for fruitful
   discussion on the statistical analysis. This work was supported by EU
   project ChildBrain (Horizon2020 Marie Sklodowska-Curie Action (MSCA)
   Innovative Training Network (ITN) - European Training Network (ETN),
   grant agreement no. 641652) and the Academy of Finland (grant 114794 to
   PH).
CR Albrecht R, 2000, CLIN NEUROPHYSIOL, V111, P2268, DOI 10.1016/S1388-2457(00)00464-8
   Ashton JC, 2013, NAT REV NEUROSCI, V14, DOI 10.1038/nrn3475-c2
   Bacchetti P, 2013, NAT REV NEUROSCI, V14, DOI 10.1038/nrn3475-c3
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Bates TC, 2011, BEHAV GENET, V41, P50, DOI 10.1007/s10519-010-9402-9
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bishop DVM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0035851
   Bishop DVM, 2007, DEVELOPMENTAL SCI, V10, P576, DOI 10.1111/j.1467-7687.2007.00620.x
   Bishop DVM, 2017, J CHILD PSYCHOL PSYC, V58, P1068, DOI 10.1111/jcpp.12721
   Bishop DVM, 2013, SCIENCE, V340, DOI 10.1126/science.1230531
   Bishop DVM, 2004, PSYCHOL BULL, V130, P858, DOI 10.1037/0033-2909.130.6.858
   Bishop DVM, 2004, DEVELOPMENTAL SCI, V7, pF11, DOI 10.1111/j.1467-7687.2004.00356.x
   Bishop DVM, 1999, J SPEECH LANG HEAR R, V42, P155, DOI 10.1044/jslhr.4201.155
   Brown H, 2014, APPL MIXED MODELS ME
   Burlingame E, 2005, J SPEECH LANG HEAR R, V48, P805, DOI 10.1044/1092-4388(2005/056)
   Button KS, 2013, NAT REV NEUROSCI, V14, DOI 10.1038/nrn3475-c4
   Button KS, 2013, NAT REV NEUROSCI, V14, P365, DOI 10.1038/nrn3475
   Ceponiene R, 2002, CLIN NEUROPHYSIOL, V113, P870, DOI 10.1016/S1388-2457(02)00078-0
   de Guibert C, 2011, BRAIN, V134, P3044, DOI 10.1093/brain/awr141
   Della Penna S, 2007, CEREB CORTEX, V17, P2303, DOI 10.1093/cercor/bhl139
   DENCKLA MB, 1976, NEUROPSYCHOLOGIA, V14, P471, DOI 10.1016/0028-3932(76)90075-0
   Field A., 2009, DISCOVERING STAT USI
   Friston K, 2012, NEUROIMAGE, V61, P1300, DOI 10.1016/j.neuroimage.2012.04.018
   Fujiki N, 2002, J NEUROSCI, V22, DOI 10.1523/JNEUROSCI.22-03-j0003.2002
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Halekoh U, 2014, J STAT SOFTW, V59, P1
   Hamalainen JA, 2007, CLIN NEUROPHYSIOL, V118, P2263, DOI 10.1016/j.clinph.2007.07.007
   Hamalainen JA, 2013, DEV NEUROPSYCHOL, V38, P550, DOI 10.1080/87565641.2012.718817
   HAMALAINEN M, 1993, REV MOD PHYS, V65, P413, DOI 10.1103/RevModPhys.65.413
   Hannus S, 2013, FOLIA PHONIATR LOGO, V65, P40, DOI 10.1159/000350318
   Hansen PC, 2010, MEG INTRO METHODS
   Helenius P, 2014, BRAIN LANG, V130, P11, DOI 10.1016/j.bandl.2014.01.005
   Helenius P, 2009, BRAIN, V132, P1918, DOI 10.1093/brain/awp134
   Herbert MR, 2005, BRAIN, V128, P213, DOI 10.1093/brain/awh330
   Howard MF, 2009, HEARING RES, V257, P41, DOI 10.1016/j.heares.2009.07.010
   Hox J., 2010, MULTILEVEL ANAL TECH
   Isoaho P., 2012, THESIS
   Jackson E, 2016, INT J LANG COMM DIS, V51, P61, DOI 10.1111/1460-6984.12185
   Jancke L, 2007, BRAIN LANG, V102, P91, DOI 10.1016/j.bandl.2006.08.003
   Jin CY, 2008, NEUROSCI RES, V60, P397, DOI 10.1016/j.neures.2007.12.008
   Johnson BW, 2013, NEUROPSYCHOLOGIA, V51, P633, DOI 10.1016/j.neuropsychologia.2012.12.015
   Johnstone SJ, 1996, INT J PSYCHOPHYSIOL, V24, P223, DOI 10.1016/S0167-8760(96)00065-7
   Karhu J, 1997, NEUROREPORT, V8, P1327, DOI 10.1097/00001756-199704140-00002
   Korkman M., 1997, LASTEN NEUROPSYKOLOG
   Lamminmaki S, 2012, J NEUROSCI, V32, P966, DOI 10.1523/JNEUROSCI.4007-11.2012
   Lee JC, 2013, NEUROPSYCHOLOGIA, V51, P2154, DOI 10.1016/j.neuropsychologia.2013.07.011
   Lindeman J., 1998, ALLU ALA ASTEEN LUKE
   Lohvansuu K, 2014, INT J PSYCHOPHYSIOL, V94, P298, DOI 10.1016/j.ijpsycho.2014.10.002
   Lovio R, 2012, BRAIN RES, V1448, P42, DOI 10.1016/j.brainres.2012.01.071
   Lovio R, 2010, BRAIN RES, V1335, P53, DOI 10.1016/j.brainres.2010.03.097
   Luke SG, 2017, BEHAV RES METHODS, V49, P1494, DOI 10.3758/s13428-016-0809-y
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001
   McArthur G, 2009, DEVELOPMENTAL SCI, V12, P768, DOI 10.1111/j.1467-7687.2008.00804.x
   McArthur GM, 2010, DEV NEUROPSYCHOL, V35, P656, DOI 10.1080/87565641.2010.508548
   Melby-Lervag M, 2012, PSYCHOL BULL, V138, P322, DOI 10.1037/a0026744
   Montgomery JW, 2010, AM J SPEECH-LANG PAT, V19, P78, DOI 10.1044/1058-0360(2009/09-0028)
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Orekhova EV, 2013, BRAIN TOPOGR, V26, P410, DOI 10.1007/s10548-012-0262-x
   Orekhova EV, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0039906
   Ors Marianne, 2002, Eur J Paediatr Neurol, V6, P47, DOI 10.1053/ejpn.2001.0541
   PAETAU R, 1995, J CLIN NEUROPHYSIOL, V12, P177, DOI 10.1097/00004691-199503000-00008
   Pantev C, 1998, AUDIOL NEURO-OTOL, V3, P183, DOI 10.1159/000013789
   Parviainen T, 2019, HUM BRAIN MAPP, V40, P2699, DOI 10.1002/hbm.24553
   Parviainen T, 2011, HUM BRAIN MAPP, V32, P2193, DOI 10.1002/hbm.21181
   PICTON TW, 1974, ELECTROEN CLIN NEURO, V36, P179, DOI 10.1016/0013-4694(74)90155-2
   Pihko E, 2008, INT J PSYCHOPHYSIOL, V68, P161, DOI 10.1016/j.ijpsycho.2007.10.016
   Pinheiro J., 2000, MIXED EFFECTS MODELS
   Plonski P, 2017, HUM BRAIN MAPP, V38, P900, DOI 10.1002/hbm.23426
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Poeppel D, 2008, PHILOS T R SOC B, V363, P1071, DOI 10.1098/rstb.2007.2160
   Ponton CW, 2000, CLIN NEUROPHYSIOL, V111, P220, DOI 10.1016/S1388-2457(99)00236-9
   Quinlan PT, 2013, NAT REV NEUROSCI, V14, DOI 10.1038/nrn3475-c1
   R Core Team, 2013, R LANG ENV STAT COMP
   Richards S, 2015, J SPEECH LANG HEAR R, V58, P1292, DOI 10.1044/2015_JSLHR-L-13-0306
   Rinker T, 2007, NEUROSCI LETT, V413, P99, DOI 10.1016/j.neulet.2006.11.033
   Rutherford A., 2001, INTRO ANOVA ANCOVA G
   Salmelin R, 1999, P NATL ACAD SCI USA, V96, P10460, DOI 10.1073/pnas.96.18.10460
   Schaalje GB, 2002, J AGRIC BIOL ENVIR S, V7, P512, DOI 10.1198/108571102726
   Schonbrodt FD, 2013, J RES PERS, V47, P609, DOI 10.1016/j.jrp.2013.05.009
   Shaw ME, 2013, NEUROIMAGE, V74, P22, DOI 10.1016/j.neuroimage.2013.02.002
   Smith Paul F, 2017, J Undergrad Neurosci Educ, V16, pR1
   Smith PL, 2018, PSYCHON B REV, V25, P2083, DOI 10.3758/s13423-018-1451-8
   Takeshita K, 2002, CLIN NEUROPHYSIOL, V113, P1470, DOI 10.1016/S1388-2457(02)00202-X
   Taulu S, 2006, PHYS MED BIOL, V51, P1759, DOI 10.1088/0031-9155/51/7/008
   TonnquistUhlen I, 1996, EAR HEARING, V17, P314, DOI 10.1097/00003446-199608000-00003
   Uusitalo MA, 1997, MED BIOL ENG COMPUT, V35, P135, DOI 10.1007/BF02534144
   Wechsler D, 1999, WECHSLER INTELLIGENC
   Whitehouse AJO, 2008, BRAIN, V131, P3193, DOI 10.1093/brain/awn266
   Wilson AC, 2018, PEERJ, V6, DOI 10.7717/peerj.4217
   WOLF M, 1986, BRAIN LANG, V27, P360, DOI 10.1016/0093-934X(86)90025-8
   Wunderlich JL, 2006, HEARING RES, V212, P212, DOI 10.1016/j.heares.2005.11.008
   Yoshimura Y, 2014, NEUROIMAGE, V101, P440, DOI 10.1016/j.neuroimage.2014.07.034
NR 93
TC 1
Z9 1
U1 1
U2 4
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD JUN 24
PY 2019
VL 9
AR 9087
DI 10.1038/s41598-019-45597-y
PG 11
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA IE8AU
UT WOS:000472597100015
PM 31235763
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Sharma, S
   Mens, LHM
   Snik, AFM
   van Opstal, AJ
   van Wanrooij, MM
AF Sharma, Snandan
   Mens, Lucas H. M.
   Snik, Ad F. M.
   van Opstal, A. John
   van Wanrooij, Marc M.
TI An Individual With Hearing Preservation and Bimodal Hearing Using a
   Cochlear Implant and Hearing Aids Has Perturbed Sound Localization but
   Preserved Speech Perception
SO FRONTIERS IN NEUROLOGY
LA English
DT Article
DE bimodal; spatial hearing; speech-in-noise; electro-acoustic; residual
   hearing
ID MATRIX SENTENCE TEST; INTELLIGIBILITY; LISTENERS; CUES
AB This study describes sound localization and speech-recognition-in-noise abilities of a cochlear-implant user with electro-acoustic stimulation (EAS) in one ear, and a hearing aid in the contralateral ear. This listener had low-frequency, up to 250 Hz, residual hearing within the normal range in both ears. The objective was to determine how hearing devices affect spatial hearing for an individual with substantial unaided low-frequency residual hearing. Sound-localization performance was assessed for three sounds with different bandpass characteristics: low center frequency (100-400 Hz), mid center frequency (500-1,500 Hz) and high frequency broad-band (500-20,000 Hz) noise. Speech recognition was assessed with the Dutch Matrix sentence test presented in noise. Tests were performed while the listener used several on-off combinations of the devices. The listener localized low-center frequency sounds well in all hearing conditions, but mid-center frequency and high frequency broadband sounds were localized well almost exclusively in the completely unaided condition (mid-center frequency sounds were also localized well with the EAS device alone). Speech recognition was best in the fully aided condition with speech presented in the front and noise presented at either side. Furthermore, there was no significant improvement in speech recognition with all devices on, compared to when the listener used her cochlear implant only. Hearing aids and cochlear implant impair high frequency spatial hearing due to improper weighing of interaural time and level difference cues. The results reinforce the notion that hearing symmetry is important for sound localization. The symmetry is perturbed by the hearing devices for higher frequencies. Speech recognition depends mainly on hearing through the cochlear implant and is not significantly improved with the added information from hearing aids. A contralateral hearing aid provides benefit when the noise is spatially separated from the speech. However, this benefit is explained by the head shadow in that ear, rather than by an ability to spatially segregate noise from speech, as sound localization was perturbed with all devices in use.
C1 [Sharma, Snandan; Snik, Ad F. M.; van Opstal, A. John; van Wanrooij, Marc M.] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Dept Biophys, Nijmegen, Netherlands.
   [Mens, Lucas H. M.] Radboud Univ Nijmegen, Med Ctr, Donders Inst Brain Cognit & Behav, Dept Otorhinolaryngol, Nijmegen, Netherlands.
RP van Wanrooij, MM (corresponding author), Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Dept Biophys, Nijmegen, Netherlands.
EM m.vanwanrooij@donders.ru.nl
RI van Opstal, John/D-1907-2010; van Wanrooij, Marc/J-3385-2012
OI van Wanrooij, Marc/0000-0003-4180-1835; van Opstal,
   John/0000-0001-5957-5712
FU European Union program FP7-PEOPLE-2013-ITN HealthPAC [604063-IDP]; EU
   Horizon 2020 program ERC Advanced Grant Orient [693400]; Radboud
   University Medical Center
FX This study was supported by the European Union program
   FP7-PEOPLE-2013-ITN HealthPAC, Nr. 604063-IDP (SS), the EU Horizon 2020
   program ERC Advanced Grant Orient, Nr. 693400 (AvO, AS, MvW), and
   Radboud University Medical Center (LM).
CR Brand T, 2002, J ACOUST SOC AM, V111, P2801, DOI 10.1121/1.1479152
   Dorman MF, 2013, EAR HEARING, V34, P245, DOI 10.1097/AUD.0b013e318269ce70
   Dorman MF, 2010, INT J AUDIOL, V49, P912, DOI 10.3109/14992027.2010.509113
   Dunn CC, 2010, J AM ACAD AUDIOL, V21, P44, DOI 10.3766/jaaa.21.1.6
   Gifford RH, 2014, AUDIOL NEURO-OTOL, V19, P57, DOI 10.1159/000355700
   Gifford RH, 2013, EAR HEARING, V34, P413, DOI 10.1097/AUD.0b013e31827e8163
   Houben R, 2014, INT J AUDIOL, V53, P760, DOI 10.3109/14992027.2014.920111
   KNUDSEN EI, 1979, J COMP PHYSIOL, V133, P13, DOI 10.1007/BF00663106
   Litovsky RY, 2009, EAR HEARING, V30, P419, DOI 10.1097/AUD.0b013e3181a165be
   Loiselle LH, 2016, J SPEECH LANG HEAR R, V59, P810, DOI 10.1044/2015_JSLHR-H-14-0355
   Theelen-van den Hoek FL, 2014, INT J AUDIOL, V53, P817, DOI 10.3109/14992027.2014.922223
   Van Bentum GC, 2017, J ACOUST SOC AM, V142, P3094, DOI 10.1121/1.5011182
   Van Wanrooij MM, 2007, J NEUROPHYSIOL, V97, P715, DOI 10.1152/jn.00260.2006
NR 13
TC 1
Z9 1
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-2295
J9 FRONT NEUROL
JI Front. Neurol.
PD JUN 21
PY 2019
VL 10
AR 637
DI 10.3389/fneur.2019.00637
PG 7
WC Clinical Neurology; Neurosciences
SC Neurosciences & Neurology
GA IE6EW
UT WOS:000472470200001
PM 31293495
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Daube, C
   Ince, RAA
   Gross, J
AF Daube, Christoph
   Ince, Robin A. A.
   Gross, Joachim
TI Simple Acoustic Features Can Explain Phoneme-Based Predictions of
   Cortical Responses to Speech
SO CURRENT BIOLOGY
LA English
DT Article
ID INFORMATION; DYNAMICS; COMPREHENSION; OSCILLATIONS; PRINCIPLES;
   FREQUENCY; ENVELOPE; MODELS; MEG
AB When we listen to speech, we have to make sense of a waveform of sound pressure. Hierarchical models of speech perception assume that, to extract semantic meaning, the signal is transformed into unknown, intermediate neuronal representations. Traditionally, studies of such intermediate representations are guided by linguistically defined concepts, such as phonemes. Here, we argue that in order to arrive at an unbiased understanding of the neuronal responses to speech, we should focus instead on representations obtained directly from the stimulus. We illustrate our view with a data-driven, information theoretic analysis of a dataset of 24 young, healthy humans who listened to a 1 h narrative while their magnetoencephalogram (MEG) was recorded. We find that two recent results, the improved performance of an encoding model in which annotated linguistic and acoustic features were combined and the decoding of phoneme subgroups from phoneme-locked responses, can be explained by an encoding model that is based entirely on acoustic features. These acoustic features capitalize on acoustic edges and outperform Gabor-filtered spectrograms, which can explicitly describe the spectrotemporal characteristics of individual phonemes. By replicating our results in publicly available electroencephalography (EEG) data, we conclude that models of brain responses based on linguistic features can serve as excellent benchmarks. However, we believe that in order to further our understanding of human cortical responses to speech, we should also explore low-level and parsimonious explanations for apparent high-level phenomena.
C1 [Daube, Christoph; Ince, Robin A. A.; Gross, Joachim] Univ Glasgow, Inst Neurosci & Psychol, 62 Hillhead St, Glasgow G12 8QB, Lanark, Scotland.
   [Gross, Joachim] Univ Munster, Inst Biomagnetism & Biosignalanal, Malmedyweg 15, D-48149 Munster, Germany.
RP Daube, C (corresponding author), Univ Glasgow, Inst Neurosci & Psychol, 62 Hillhead St, Glasgow G12 8QB, Lanark, Scotland.
EM christoph.daube@gmail.com
OI Gross, Joachim/0000-0002-3994-1006; Daube, Christoph/0000-0002-1763-8508
FU College of Science and Engineering at the University of Glasgow
   [214120/Z/18/Z, 098433]; Wellcome TrustWellcome TrustEuropean Commission
FX C.D. is funded by the College of Science and Engineering at the
   University of Glasgow; R.A.A.I. (UK; 214120/Z/18/Z) and J.G. (UK;
   098433) received support from the Wellcome Trust. We thank Moritz Boos,
   Jan-Mathijs Schoffelen, Dale J. Barr, and Christoph Scheepers for
   helpful discussions as well as Giovanni M. Di Liberto and Edmund C.
   Lalor for sharing their data, useful discussions, and insightful
   debates.
CR Abraham A, 2014, FRONT NEUROINFORM, V8, DOI 10.3389/fninf.2014.00014
   Acerbi L., 2017, P ADV NEURAL INFORM, P1834
   Berezutskaya J, 2017, J NEUROSCI, V37, P7906, DOI 10.1523/JNEUROSCI.0238-17.2017
   Biesmans W, 2017, IEEE T NEUR SYS REH, V25, P402, DOI 10.1109/TNSRE.2016.2571900
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bouton S, 2018, P NATL ACAD SCI USA, V115, pE1299, DOI 10.1073/pnas.1714279115
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Brette R., 2018, BIORXIV, DOI [10.1101/168237, DOI 10.1101/168237]
   Brodbeck C, 2018, CURR BIOL, V28, P3976, DOI 10.1016/j.cub.2018.10.042
   Brodbeck C, 2018, NEUROIMAGE, V172, P162, DOI 10.1016/j.neuroimage.2018.01.042
   Broderick MP, 2018, CURR BIOL, V28, P803, DOI 10.1016/j.cub.2018.01.080
   Burkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   Bzdok D, 2017, NEUROIMAGE, V155, P549, DOI 10.1016/j.neuroimage.2017.04.061
   Carlson T, 2018, NEUROIMAGE, V180, P88, DOI 10.1016/j.neuroimage.2017.08.019
   Chi T, 2005, J ACOUST SOC AM, V118, P887, DOI 10.1121/1.1945807
   Chung Yu-An, 2018, ARXIV180507467
   COHEN D, 1983, ELECTROEN CLIN NEURO, V56, P38, DOI 10.1016/0013-4694(83)90005-6
   Crosse MJ, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00604
   de Heer WA, 2017, J NEUROSCI, V37, P6539, DOI 10.1523/JNEUROSCI.3267-16.2017
   de-Wit L, 2016, PSYCHON B REV, V23, P1415, DOI 10.3758/s13423-016-1002-0
   Destoky F, 2019, NEUROIMAGE, V184, P201, DOI 10.1016/j.neuroimage.2018.09.006
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Engemann DA, 2015, NEUROIMAGE, V108, P328, DOI 10.1016/j.neuroimage.2014.12.040
   Farahibozorg SR, 2018, NEUROIMAGE, V169, P23, DOI 10.1016/j.neuroimage.2017.09.009
   Fiedler L, 2019, NEUROIMAGE, V186, P33, DOI 10.1016/j.neuroimage.2018.10.057
   Forte AE, 2017, ELIFE, V6, DOI 10.7554/eLife.27203
   Ghitza O, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00138
   Giordano BL, 2017, ELIFE, V6, DOI 10.7554/eLife.24763
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Hahn T., 2018, PYTHON BASED HYPERPA
   Hambrook DA, 2014, BRAIN LANG, V135, P52, DOI 10.1016/j.bandl.2014.05.003
   Hamilton LS, 2020, LANG COGN NEUROSCI, V35, P573, DOI 10.1080/23273798.2018.1499946
   Hamilton LS, 2018, CURR BIOL, V28, P1860, DOI 10.1016/j.cub.2018.04.033
   Hasson U, 2018, COGNITION, V180, P135, DOI 10.1016/j.cognition.2018.06.018
   Hertrich I, 2012, PSYCHOPHYSIOLOGY, V49, P322, DOI 10.1111/j.1469-8986.2011.01314.x
   Holdgraf CR, 2017, FRONT SYST NEUROSCI, V11, DOI 10.3389/fnsys.2017.00061
   Honey CJ, 2012, NEURON, V76, P423, DOI 10.1016/j.neuron.2012.08.011
   Huth AG, 2016, NATURE, V532, P453, DOI 10.1038/nature17637
   Hyafil A, 2015, ELIFE, V4, DOI 10.7554/eLife.06213
   Ince R.A.A., 2017, ARXIV170201591
   Ince R. A. A., 2017, ENTROPY, V19, P21
   Ince RAA, 2017, HUM BRAIN MAPP, V38, P1541, DOI 10.1002/hbm.23471
   Kay KN, 2018, NEUROIMAGE, V180, P101, DOI 10.1016/j.neuroimage.2017.08.016
   Keitel A, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2004473
   Kell AJE, 2018, NEURON, V98, P630, DOI 10.1016/j.neuron.2018.03.044
   Khalighinejad B, 2017, J NEUROSCI, V37, P2176, DOI 10.1523/JNEUROSCI.2383-16.2017
   Kriegeskorte N., 2018, ARXIV181200278
   Kriegeskorte N, 2018, NAT NEUROSCI, V21, P1148, DOI 10.1038/s41593-018-0210-5
   Kumar K, 2011, INT CONF ACOUST SPEE, P4784
   Lotto AJ, 2000, CHICAGO LINGUISTIC S, V35, P191
   Maddox RK, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0441-17.2018
   MASSARO DW, 1974, J EXP PSYCHOL, V102, P199, DOI 10.1037/h0035854
   MCGILL WJ, 1954, PSYCHOMETRIKA, V19, P97
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Mlynarski W, 2018, NEURAL COMPUT, V30, P631, DOI 10.1162/neco_a_01048
   Naselaris T, 2011, NEUROIMAGE, V56, P400, DOI 10.1016/j.neuroimage.2010.07.073
   Nolte G, 2003, PHYS MED BIOL, V48, P3637, DOI 10.1088/0031-9155/48/22/002
   Norman-Haignere SV, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2005127
   Obleser J, 2009, TRENDS COGN SCI, V13, P14, DOI 10.1016/j.tics.2008.09.005
   Oganian Y., 2018, SPEECH ENVELOPE LAND, DOI [10.1101/388280, DOI 10.1101/388280]
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Panzeri S, 2017, NEURON, V93, P491, DOI 10.1016/j.neuron.2016.12.036
   Panzeri S, 2015, TRENDS COGN SCI, V19, P162, DOI 10.1016/j.tics.2015.01.002
   Park H, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2006558
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   PISONI DB, 1987, COGNITION, V25, P21, DOI 10.1016/0010-0277(87)90003-5
   Prendergast G, 2010, EUR J NEUROSCI, V32, P1599, DOI 10.1111/j.1460-9568.2010.07423.x
   Qiu AQ, 2003, J NEUROPHYSIOL, V90, P456, DOI 10.1152/jn.00851.2002
   R Core Team, 2013, R LANG ENV STAT COMP
   Rasanen O, 2018, COGNITION, V171, P130, DOI 10.1016/j.cognition.2017.11.003
   Santoro R, 2017, P NATL ACAD SCI USA, V114, P4799, DOI 10.1073/pnas.1617622114
   Santoro R, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003412
   Sarikaya R., 2016, OVERVIEW END TO END
   Sassenhagen J, 2019, LANG COGN NEUROSCI, V34, P474, DOI 10.1080/23273798.2018.1502458
   Schadler MR, 2012, J ACOUST SOC AM, V131, P4134, DOI 10.1121/1.3699200
   Schonwiesner M, 2009, P NATL ACAD SCI USA, V106, P14611, DOI 10.1073/pnas.0907682106
   Sitek KR, 2019, BIORXIV, DOI [10.1101/568139, DOI 10.1101/568139]
   Stan Development Team, 2018, RSTAN R INT STAN
   Theunissen FE, 2014, NAT REV NEUROSCI, V15, P355, DOI 10.1038/nrn3731
   Tishby N., 2000, ARXIVPHYSICS0004057
   VanVeen BD, 1997, IEEE T BIO-MED ENG, V44, P867, DOI 10.1109/10.623056
   Varoquaux G, 2017, NEUROIMAGE, V145, P166, DOI 10.1016/j.neuroimage.2016.10.038
   Verhulst S, 2018, HEARING RES, V360, P55, DOI 10.1016/j.heares.2017.12.018
   Weichwald S, 2015, NEUROIMAGE, V110, P48, DOI 10.1016/j.neuroimage.2015.01.036
   Wibral M, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00005
   Williams MA, 2007, NAT NEUROSCI, V10, P685, DOI 10.1038/nn1900
   Williams P. L., 2012, ARXIV10042515
   Woolrich M, 2011, NEUROIMAGE, V57, P1466, DOI 10.1016/j.neuroimage.2011.04.041
   Yuan J, 2008, J ACOUST SOC AM, V124, P2078, DOI 10.1121/1.2968700
NR 93
TC 14
Z9 14
U1 0
U2 6
PU CELL PRESS
PI CAMBRIDGE
PA 50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA
SN 0960-9822
EI 1879-0445
J9 CURR BIOL
JI Curr. Biol.
PD JUN 17
PY 2019
VL 29
IS 12
BP 1924
EP +
DI 10.1016/j.cub.2019.04.067
PG 23
WC Biochemistry & Molecular Biology; Biology; Cell Biology
SC Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other
   Topics; Cell Biology
GA ID6IY
UT WOS:000471783100019
PM 31130454
OA Green Accepted, Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Voeten, CC
   Levelt, CC
AF Voeten, Cesko C.
   Levelt, Clara C.
TI ERP Responses to Regional Accent Reflect Two Distinct Processes of
   Perceptual Compensation
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE accent processing; perceptual compensation; language change; language
   variation; N400; P600
ID EVENT-RELATED POTENTIALS; BRAIN POTENTIALS; CONTEXT
AB Humans possess a robust speech-perception apparatus that is able to cope with variation in spoken language. However, linguists have often claimed that this coping ability must be limited, since otherwise there is no way for such variation to lead to language change and regional accents. Previous research has shown that the presence or absence of perceptual compensation is indexed by the N400 and P600 components, where the N400 reflects the general awareness of accented speech input, and the P600 responds to phonological-rule violations. The present exploratory paper investigates the hypothesis that these same components are involved in the accommodation to sound change, and that their amplitudes reduce as a sound change becomes accepted by an individual. This is investigated on the basis of a vowel shift in Dutch that has occurred in the Netherlands but not in Flanders (the Dutch-speaking part of Belgium). Netherlandic and Flemish participants were presented auditorily with words containing either conservative or novel vowel realizations, plus two control conditions. Exploratory analyses found no significant differences in ERPs to these realizations, but did uncover two systematic differences. Over 9 months, the N400 response became less negative for both groups of participants, but this effect was significantly smaller for the Flemish participants, a finding in line with earlier results on accent processing. Additionally, in one control condition where a "novel" realization was produced based on vowel lengthening, which cannot be achieved by any rule of either Netherlandic or Flemish Dutch and changes the vowel's phonemic identity, a P600 was obtained in the Netherlandic participants, but not in the Flemish participants. This P600 corroborates a small number of other studies which found phonological P600s, and provides ERP validation of earlier behavioral results that adaptation to variation in speech is possible, until the variation crosses a phoneme boundary. The results of this exploratory study thus reveal two types of perceptual-compensation (dys)function: on-line accent processing, visible as N400 amplitude, and failure to recover from an ungrammatical realization that crosses a phoneme boundary, visible as a P600. These results provide further insight on how these two ERPs reflect the processing of variation.
C1 [Voeten, Cesko C.; Levelt, Clara C.] Leiden Univ, Ctr Linguist, Leiden, Netherlands.
   [Voeten, Cesko C.; Levelt, Clara C.] Leiden Univ, Leiden Inst Brain & Cognit, Leiden, Netherlands.
RP Voeten, CC (corresponding author), Leiden Univ, Ctr Linguist, Leiden, Netherlands.; Voeten, CC (corresponding author), Leiden Univ, Leiden Inst Brain & Cognit, Leiden, Netherlands.
EM c.c.voeten@hum.leidenuniv.nl
FU Netherlands Organisation for Scientific Research (NWO)Netherlands
   Organization for Scientific Research (NWO) [PGW-15-15]
FX This work is part of the research programme Watching Dutch Change with
   project number PGW-15-15, which is (partly) financed by the Netherlands
   Organisation for Scientific Research (NWO).
CR Baayen RH, 1995, CELEX LEXICAL DATABA
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bermudez- Otero R., 2015, AMPHICHRONIC EXPLANA
   Blevins Juliette, 2004, EVOLUTIONARY PHONOLO
   Booij E. E., 1995, PHONOLOGY DUTCH
   Bosker H. R., 2015, P 18 INT C PHON SCI
   Boyd- Bowman P., 1954, LATIN ROMANCE SOUND
   Cutler A, 2012, NATIVE LISTENING
   Dambacher M, 2006, BRAIN RES, V1084, P89, DOI 10.1016/j.brainres.2006.02.010
   Domahs U, 2009, LANG SPEECH, V52, P415, DOI 10.1177/0023830909336581
   Evans BG, 2007, J ACOUST SOC AM, V121, P3814, DOI 10.1121/1.2722209
   Floccia C, 2006, J EXP PSYCHOL HUMAN, V32, P1276, DOI 10.1037/0096-1523.32.5.1276
   Floccia C, 2009, J PSYCHOLINGUIST RES, V38, P379, DOI 10.1007/s10936-008-9097-8
   FRIEDERICI AD, 1993, COGNITIVE BRAIN RES, V1, P183, DOI 10.1016/0926-6410(93)90026-2
   Goslin J, 2012, BRAIN LANG, V122, P92, DOI 10.1016/j.bandl.2012.04.017
   Grondelaers S, 2011, J GER LINGUIST, V23, P199, DOI 10.1017/S1470542711000110
   Hyman L. M., 2013, ORIGINS SOUND CHANGE, P3, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0001
   Hyman Larry, 1976, LINGUISTIC STUDIES O, P407
   Kung C, 2014, NEUROPSYCHOLOGIA, V53, P293, DOI 10.1016/j.neuropsychologia.2013.11.020
   Liu BL, 2011, EXP BRAIN RES, V212, P399, DOI 10.1007/s00221-011-2739-3
   Lo S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01171
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P213, DOI 10.3758/BF03204377
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Maye J, 2008, COGNITIVE SCI, V32, P543, DOI 10.1080/03640210802035357
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Ohala John, 1981, PAPERS PARASESSION L, P178
   Ohala John J., 2012, INITIATION SOUND CHA, P21, DOI DOI 10.1075/CILT.323.05OHA
   OSTERHOUT L, 1992, J MEM LANG, V31, P785, DOI 10.1016/0749-596X(92)90039-Z
   Pater J., EVENT RELATED UNPUB
   R Core Team, 2019, R LANG ENV STAT COMP
   Sebregts Koen, 2015, SOCIOPHONETICS PHONO
   Van de Velde H., 1996, VARIATIE VERANDERING
   Witteman MJ, 2015, LANG SPEECH, V58, P168, DOI 10.1177/0023830914528102
   Witteman MJ, 2014, PSYCHON B REV, V21, P512, DOI 10.3758/s13423-013-0519-8
   Young S., 2002, HTK BOOK
NR 35
TC 0
Z9 0
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD JUN 14
PY 2019
VL 13
AR 546
DI 10.3389/fnins.2019.00546
PG 13
WC Neurosciences
SC Neurosciences & Neurology
GA ID9VH
UT WOS:000472034700001
PM 31258459
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Kwon, H
AF Kwon, Harim
TI The role of native phonology in spontaneous imitation: Evidence from
   Seoul Korean
SO LABORATORY PHONOLOGY
LA English
DT Article
DE spontaneous imitation; phonological imitation; cue primacy; aspirated
   stop; Seoul Korean
ID VOICE ONSET TIME; PHONETIC CONVERGENCE; FUNDAMENTAL-FREQUENCY;
   SPEECH-PERCEPTION; STOPS
AB This study investigates the role of phonology in spontaneous imitation in Seoul Korean speakers' imitation of aspirated stops by comparing the primary and non-primary cues. Seoul Korean aspirated stops are differentiated from stops of other phonation types by at least two distinct acoustic properties, stop VOT and f0 of the post-stop vowel, with the latter being the primary cue. In the imitation experiment, Seoul Korean speakers heard and shadowed model speech that contained aspirated stops manipulated by either raising post-stop f0 or lengthening VOT. Their realization of these properties in /t(h)/, /t/, and /t*/ productions were compared before, during, and after exposure. Although both high f0 and long VOT induced imitative changes in post-shadowing productions, the results revealed that exposure to an enhanced non-primary cue (long VOT) also influences the production of the primary cue for aspirated stops (post-stop f0). However, an enhanced primary cue (high f0) does not have similar effects on the non-primary cue. These results provide evidence that spontaneous imitation is not strictly tied to individual phonetic properties but it is rather phonological in that abstract categories are involved in the process of imitation.
C1 [Kwon, Harim] Univ Michigan, Dept Linguist, Ann Arbor, MI 48109 USA.
   [Kwon, Harim] George Mason Univ, Dept English, Fairfax, VA 22030 USA.
RP Kwon, H (corresponding author), Univ Michigan, Dept Linguist, Ann Arbor, MI 48109 USA.; Kwon, H (corresponding author), George Mason Univ, Dept English, Fairfax, VA 22030 USA.
EM hkwon20@gmu.edu
CR Allen JS, 1999, J ACOUST SOC AM, V106, P2031, DOI 10.1121/1.427949
   Babel M, 2014, LAB PHONOL, V5, P123, DOI 10.1515/lp-2014-0006
   Babel M, 2012, LANG SPEECH, V55, P231, DOI 10.1177/0023830911417695
   Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D., 2014, R PACKAGE VERSION LME4 LINEAR MIXED EF LME4 LINEAR MIXED EF, DOI DOI 10.18637/JSS.V067.I01
   Boersma P., 2014, PRAAT DOING PHONETIC
   Cho TH, 2002, J PHONETICS, V30, P193, DOI 10.1006/jpho.2001.0153
   Fowler CA, 2003, J MEM LANG, V49, P396, DOI 10.1016/S0749-596X(03)00072-X
   Fowler CA, 1996, J ACOUST SOC AM, V99, P1730, DOI 10.1121/1.415237
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger SD, 2004, PSYCHON B REV, V11, P716, DOI 10.3758/BF03196625
   Halle Morris, 1971, MIT Q PROGR REPORT, V101, P198
   HOMBERT JM, 1979, LANGUAGE, V55, P37, DOI 10.2307/412518
   Honorof DN, 2011, J PHONETICS, V39, P18, DOI 10.1016/j.wocn.2010.10.007
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Johnson K, 2006, J PHONETICS, V34, P485, DOI 10.1016/j.wocn.2005.08.004
   KAGAYA R, 1974, J PHON, V2, P161
   Kang KH, 2008, J ACOUST SOC AM, V124, P3909, DOI 10.1121/1.2988292
   Kang YJ, 2014, J PHONETICS, V45, P76, DOI 10.1016/j.wocn.2014.03.005
   Kim M., 2012, THESIS, DOI [10.1121/1.4755133, DOI 10.1121/1.4755133]
   Kim M.-R., 2000, THESIS
   Kim MR, 2002, J PHONETICS, V30, P77, DOI 10.1006/jpho.2001.0152
   Kong EJ, 2011, J PHONETICS, V39, P196, DOI 10.1016/j.wocn.2011.02.002
   Lee H, 2013, J PHONETICS, V41, P117, DOI 10.1016/j.wocn.2012.12.002
   Lee H, 2012, J INT PHON ASSOC, V42, P145, DOI 10.1017/S0025100312000035
   McCrea CR, 2005, J SPEECH LANG HEAR R, V48, P1013, DOI 10.1044/1092-4388(2005/069)
   Mitterer H, 2013, ATTEN PERCEPT PSYCHO, V75, P557, DOI 10.3758/s13414-012-0407-8
   Mitterer H, 2008, COGNITION, V109, P168, DOI 10.1016/j.cognition.2008.08.002
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Narayan C., 2013, P M AC, V19, P1, DOI 10.1121/1.4800681
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007
   Oh E, 2011, J PHONETICS, V39, P59, DOI 10.1016/j.wocn.2010.11.002
   Pardo J., 2013, P MTGS ACOUST, V19, DOI DOI 10.1121/1.4798479
   Pardo JS, 2013, J MEM LANG, V69, P183, DOI 10.1016/j.jml.2013.06.002
   Pardo JS, 2012, J PHONETICS, V40, P190, DOI 10.1016/j.wocn.2011.10.001
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   R Development Core Team, 2014, R LANG ENV STAT COMP
   Schmid HJ, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01110
   Shockley K, 2004, PERCEPT PSYCHOPHYS, V66, P422, DOI 10.3758/BF03194890
   Silva D. J., 2006, PHONOLOGY, V23, P287, DOI DOI 10.1017/S0952675706000911
   The National Institute of the Korean Language, 2005, SPEECH CORP READ STY
   Tilsen S, 2009, J PHONETICS, V37, P276, DOI 10.1016/j.wocn.2009.03.004
   Walker A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00546
   Zellou G, 2016, J ACOUST SOC AM, V140, P3560, DOI 10.1121/1.4966232
NR 47
TC 0
Z9 0
U1 0
U2 0
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD JUN 14
PY 2019
VL 10
IS 1
AR 10
DI 10.5334/labphon.83
PG 24
WC Linguistics; Language & Linguistics
SC Linguistics
GA ID5XY
UT WOS:000471752000001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Leppanen, PHT
   Toth, D
   Honbolygo, F
   Lohvansuu, K
   Hamalainen, JA
   Demonet, JF
   Schulte-Korne, G
   Csepe, V
   Bartling, J
   Bruder, J
   Chaix, Y
   Iannuzzi, S
   Nenert, R
   Neuhoff, N
   Streiftau, S
   Tanskanen, A
   Tuomainen, J
AF Leppanen, Paavo H. T.
   Toth, Denes
   Honbolygo, Ferenc
   Lohvansuu, Kaisa
   Hamalainen, Jarmo A.
   Demonet, Jean-Francois
   Schulte-Koerne, Gerd
   Csepe, Valeria
   Bartling, Juergen
   Bruder, Jennifer
   Chaix, Yves
   Iannuzzi, Stephanie
   Nenert, Rodolphe
   Neuhoff, Nina
   Streiftau, Silke
   Tanskanen, Annika
   Tuomainen, Jyrki
CA NEURODYS WP7 Grp
TI Reproducibility of Brain Responses: High for Speech Perception, Low for
   Reading Difficulties
SO SCIENTIFIC REPORTS
LA English
DT Article
ID MISMATCH NEGATIVITY; AUDITORY-DISCRIMINATION; DEVELOPMENTAL DYSLEXIA;
   PROCESSING DEFICITS; CHILDREN; ASSOCIATION; FREQUENCY; LANGUAGE; ADULTS;
   MMN
AB Neuroscience findings have recently received critique on the lack of replications. To examine the reproducibility of brain indices of speech sound discrimination and their role in dyslexia, a specific reading difficulty, brain event-related potentials using EEG were measured using the same cross-linguistic passive oddball paradigm in about 200 dyslexics and 200 typically reading 8-12-year-old children from four countries with different native languages. Brain responses indexing speech and non-speech sound discrimination were extremely reproducible, supporting the validity and reliability of cognitive neuroscience methods. Significant differences between typical and dyslexic readers were found when examined separately in different country and language samples. However, reading group differences occurred at different time windows and for different stimulus types between the four countries. This finding draws attention to the limited generalizability of atypical brain response findings in children with dyslexia across language environments and raises questions about a common neurobiological factor for dyslexia. Our results thus show the robustness of neuroscience methods in general while highlighting the need for multi-sample studies in the brain research of language disorders.
C1 [Leppanen, Paavo H. T.; Lohvansuu, Kaisa; Hamalainen, Jarmo A.; Tanskanen, Annika] Univ Jyvaskyla, Ctr Interdisciplinary Brain Res, Dept Psychol, POB 35, Jyvaskyla 40014, Finland.
   [Toth, Denes; Honbolygo, Ferenc; Csepe, Valeria] Hungarian Acad Sci, Brain Imaging Ctr, Res Ctr Nat Sci, POB 286, H-1519 Budapest, Hungary.
   [Demonet, Jean-Francois; Chaix, Yves] Univ Toulouse, UPS, Imagerie Cerebrale & Handicaps Neurol, UMR 825, Pl Dr Baylac, F-31059 Toulouse 9, France.
   [Demonet, Jean-Francois; Chaix, Yves] CHU Purpan, Pl Dr Baylac, F-31059 Toulouse 9, France.
   [Demonet, Jean-Francois] CHU Vaudois, Leenaards Memory Ctr, Dept Neurosci Clin, Rue Bugnon 46, CH-1011 Lausanne, Switzerland.
   [Demonet, Jean-Francois] Univ Lausanne, Rue Bugnon 46, CH-1011 Lausanne, Switzerland.
   [Schulte-Koerne, Gerd; Bartling, Juergen; Bruder, Jennifer; Neuhoff, Nina; Streiftau, Silke] Ludwig Maximilians Univ Munchen, Dept Child & Adolescent Psychiat Psychosomat & Ps, Nussbaumstr 5A, D-80336 Munich, Germany.
   [Iannuzzi, Stephanie; Nenert, Rodolphe] INSERM, Imagerie Cerebrale & Handicaps Neurol, UMR 825, F-31059 Toulouse, France.
   [Tuomainen, Jyrki] UCL, Language & Cognit, Gower St, London WC1E 6BT, England.
RP Leppanen, PHT (corresponding author), Univ Jyvaskyla, Ctr Interdisciplinary Brain Res, Dept Psychol, POB 35, Jyvaskyla 40014, Finland.
EM paavo.ht.leppanen@jyu.fi
OI Lohvansuu, Kaisa/0000-0002-1641-844X
FU European Sixth Framework Programme, NeuroDys-project (Dyslexia genes and
   neurobiological pathways) [018696]; Finnish Center of Excellence in
   Learning and Motivation Research the University of Jyvaskyla, Finland -
   Academy of Finland [213486]; University of Jyvaskyla
FX The study was supported by the European Sixth Framework Programme,
   NeuroDys-project (Dyslexia genes and neurobiological pathways, nr.
   018696) and The Finnish Center of Excellence in Learning and Motivation
   Research, the University of Jyvaskyla, Finland, funded by the Academy of
   Finland (No. 213486) and the University of Jyvaskyla. We thank NEURODYS
   WP7 group members Jurgen Bartling, Jennifer Bruder, Yves Chaix,
   Stephanie Iannuzzi, Rodolphe Nenert, Nina Neuhoff, Silke Streiftau, and
   Annika Tanskanen for participating in planning the experiments, the data
   collection and data analysis, and Jyrki Tuomainen for helping in the
   stimulus preparation.
CR Aarts AA, 2015, SCIENCE, V349, DOI 10.1126/science.aac4716
   Alonso-Bua B, 2006, INT J PSYCHOPHYSIOL, V59, P159, DOI 10.1016/j.ijpsycho.2005.03.020
   ANNETT M, 1970, BRIT J PSYCHOL, V61, P303, DOI 10.1111/j.2044-8295.1970.tb01248.x
   Baldeweg T, 1999, ANN NEUROL, V45, P495, DOI 10.1002/1531-8249(199904)45:4<495::AID-ANA11>3.0.CO;2-M
   Bishop DVM, 2007, PSYCHOL BULL, V133, P651, DOI 10.1037/0033-2909.133.4.651
   Boersma P., 2006, PRAAT DOING PHONETIC
   Boets B, 2013, SCIENCE, V342, P1251, DOI 10.1126/science.1244333
   Cheour M, 2001, AUDIOL NEURO-OTOL, V6, P2, DOI 10.1159/000046804
   Corbera S, 2006, NEUROREPORT, V17, P1051, DOI 10.1097/01.wnr.0000221846.43126.a6
   Corey DM, 1998, J GEN PSYCHOL, V125, P245, DOI 10.1080/00221309809595548
   Csepe V, 2003, INT J PSYCHOPHYSIOL, V51, P69, DOI 10.1016/S0167-8760(03)00154-5
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Hakvoort B, 2015, CORTEX, V63, P90, DOI 10.1016/j.cortex.2014.08.013
   Hamalainen JA, 2013, J LEARN DISABIL-US, V46, P413, DOI 10.1177/0022219411436213
   HAYRINEN T, 1999, LUKILASSE
   Heim S, 2000, NEUROPSYCHOLOGIA, V38, P1749, DOI 10.1016/S0028-3932(00)00075-0
   Ille N, 2002, J CLIN NEUROPHYSIOL, V19, P113, DOI 10.1097/00004691-200203000-00002
   Ioannidis JPA, 2005, PLOS MED, V2, P696, DOI 10.1371/journal.pmed.0020124
   Killeen PR, 2005, PSYCHOL SCI, V16, P345, DOI 10.1111/j.0956-7976.2005.01538.x
   Koenig T., 2009, ELECT NEUROIMAGING, V2009, DOI DOI 10.1017/CBO9780511596889.009
   Kujala T, 2006, CLIN NEUROPHYSIOL, V117, P885, DOI 10.1016/j.clinph.2006.01.002
   Lachmann T, 2005, INT J PSYCHOPHYSIOL, V56, P105, DOI 10.1016/j.ijpsycho.2004.11.005
   Landerl K, 2013, J CHILD PSYCHOL PSYC, V54, P686, DOI 10.1111/jcpp.12029
   Leppanen PHT, 2010, CORTEX, V46, P1362, DOI 10.1016/j.cortex.2010.06.003
   Maurer U, 2003, NEUROREPORT, V14, P2245, DOI 10.1097/00001756-200312020-00022
   Meng XZ, 2005, DYSLEXIA, V11, P292, DOI 10.1002/dys.309
   Moll K., 2010, SLRT II LESE RECHTSC
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 1995, Int J Neurosci, V80, P317, DOI 10.3109/00207459508986107
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Olejnik S, 2003, PSYCHOL METHODS, V8, P434, DOI 10.1037/1082-989X.8.4.434
   Paul I, 2006, EUR J NEUROSCI, V24, P2945, DOI 10.1111/j.1460-9568.2006.05153.x
   Paulesu E, 2001, SCIENCE, V291, P2165, DOI 10.1126/science.1057179
   PERRIN F, 1989, ELECTROEN CLIN NEURO, V72, P184, DOI 10.1016/0013-4694(89)90180-6
   R Development Core Team, 2016, R LANG ENV STAT COMP
   Schilling F. D. B., 1979, MOTORIK, V2, P43
   Schulte-Korne G, 2010, CLIN NEUROPHYSIOL, V121, P1794, DOI 10.1016/j.clinph.2010.04.028
   Schulte-Korne G, 2001, INT J PSYCHOPHYSIOL, V40, P77, DOI 10.1016/S0167-8760(00)00152-5
   Sharma M, 2006, CLIN NEUROPHYSIOL, V117, P1130, DOI 10.1016/j.clinph.2006.02.001
   Tallal P, 2003, CURR DIR PSYCHOL SCI, V12, P206, DOI 10.1046/j.0963-7214.2003.01263.x
   Toth D, 2014, TECHNIKAI KEZIKONYV
   Tucker JD, 2013, COMPUT STAT DATA AN, V61, P50, DOI 10.1016/j.csda.2012.12.001
   Valdois S., 2002, ODEDYS OUTIL DEPISTA
   Vellutino FR, 2004, J CHILD PSYCHOL PSYC, V45, P2, DOI 10.1046/j.0021-9630.2003.00305.x
   Wechsler D., 2003, WECHSLER INTELLIGENC
   Wechsler D., 1991, WECHSLER INTELLIGENC
   Ziegler JC, 2010, PSYCHOL SCI, V21, P551, DOI 10.1177/0956797610363406
NR 47
TC 1
Z9 1
U1 0
U2 8
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD JUN 11
PY 2019
VL 9
AR 8487
DI 10.1038/s41598-019-41992-7
PG 12
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA IC4UN
UT WOS:000470962100051
PM 31186430
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Dematties, D
   Rizzi, S
   Thiruvathukal, GK
   Wainselboim, A
   Zanutto, BS
AF Dematties, Dario
   Rizzi, Silvio
   Thiruvathukal, George K.
   Wainselboim, Alejandro
   Silvano Zanutto, B.
TI Phonetic acquisition in cortical dynamics, a computational approach
SO PLOS ONE
LA English
DT Article
ID PRIMARY AUDITORY-CORTEX; RECEPTIVE-FIELDS; FUNCTIONAL ARCHITECTURE;
   VISUAL PROJECTIONS; SPEECH-PERCEPTION; NEURONS; ORGANIZATION;
   SENSITIVITY; CONSTRAINTS; INFORMATION
AB Many computational theories have been developed to improve artificial phonetic classification performance from linguistic auditory streams. However, less attention has been given to psycholinguistic data and neurophysiological features recently found in cortical tissue. We focus on a context in which basic linguistic units-such as phonemes-are extracted and robustly classified by humans and other animals from complex acoustic streams in speech data. We are especially motivated by the fact that 8-month-old human infants can accomplish segmentation of words from fluent audio streams based exclusively on the statistical relationships between neighboring speech sounds without any kind of supervision. In this paper, we introduce a biologically inspired and fully unsupervised neurocomputational approach that incorporates key neurophysiological and anatomical cortical properties, including columnar organization, spontaneous micro-columnar formation, adaptation to contextual activations and Sparse Distributed Representations (SDRs) produced by means of partial N-Methyl-D-aspartic acid (NMDA) depolarization. Its feature abstraction capabilities show promising phonetic invariance and generalization attributes. Our model improves the performance of a Support Vector Machine (SVM) classifier for monosyllabic, disyllabic and trisyllabic word classification tasks in the presence of environmental disturbances such as white noise, reverberation, and pitch and voice variations. Furthermore, our approach emphasizes potential self-organizing cortical principles achieving improvement without any kind of optimization guidance which could minimize hypothetical loss functions by means of-for example-backpropagation. Thus, our computational model outperforms multiresolution spectro-temporal auditory feature representations using only the statistical sequential structure immerse in the phonotactic rules of the input stream.
C1 [Dematties, Dario; Silvano Zanutto, B.] Univ Buenos Aires, Fac Ingn, Inst Ingn Biomed, Buenos Aires, DF, Argentina.
   [Rizzi, Silvio; Thiruvathukal, George K.] Argonne Natl Lab, Lemont, IL USA.
   [Thiruvathukal, George K.] Loyola Univ Chicago, Dept Comp Sci, Chicago, IL USA.
   [Silvano Zanutto, B.] Consejo Nacl Invest Cient & Tecn, Inst Biol & Med Expt, Buenos Aires, DF, Argentina.
   [Wainselboim, Alejandro] Consejo Nacl Invest Cient & Tecn, Inst Ciencias Humanas Sociales & Ambientales, Ctr Cient Tecnol, Mendoza, Argentina.
RP Dematties, D (corresponding author), Univ Buenos Aires, Fac Ingn, Inst Ingn Biomed, Buenos Aires, DF, Argentina.
EM ddematties@fi.uba.ar
OI Wainselboim, Alejandro/0000-0001-6787-1888
FU Agencia Nacional de Promocion Cientifica y TecnologicaANPCyT [PICT
   2016-2145, 2017-3208]; University of Buenos AiresUniversity of Buenos
   Aires [UBACYT 20020170100568BA]; Office of Science of the U.S.
   Department of EnergyUnited States Department of Energy (DOE)
   [DE-AC02-06CH11357]; U.S. Department of Energy, Office of Science User
   Facility [DE-AC02-06CH11357]
FX This research was supported by grants from Agencia Nacional de Promocion
   Cientifica y Tecnologica (PICT 2016-2145 and 2017-3208), University of
   Buenos Aires (UBACYT 20020170100568BA). This work used resources of the
   Argonne Leadership Computing Facility at Argonne National Laboratory,
   which is supported by the Office of Science of the U.S. Department of
   Energy under contract DE-AC02-06CH11357. The funders had no role in
   study design, data collection and analysis, decision to publish, or
   preparation of the manuscript.; This work used resources of the Argonne
   Leadership Computing Facility, which is a U.S. Department of Energy,
   Office of Science User Facility supported under Contract
   DE-AC02-06CH11357.
CR Ahmad S, 2016, ARXIV 160100720 Q BI
   Ahmad S., 2015, PROPERTIES SPARSE DI
   Angelucci A, J COMP NEUROL, V400, P417, DOI [10.1002/(SICI)1096-9861(19981026)400:3%3C417::AID-CNE10%3E3.0.CO;2-O, DOI 10.1002/(SICI)1096-9861(19981026)400:3%3C417::AID-CNE10%3E3.0.CO;2-O]
   [Anonymous], 2014, FESTIVAL SPEECH SYNT
   [Anonymous], 1999, AUDACITY 2 0 5 FREE
   Antic SD, 2010, J NEUROSCI RES, V88, P2991, DOI 10.1002/jnr.22444
   Barth AL, 2012, TRENDS NEUROSCI, V35, P345, DOI 10.1016/j.tins.2012.03.008
   Brent MR, 1996, COGNITION, V61, P93, DOI 10.1016/S0010-0277(96)00719-6
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chi T, 2005, J ACOUST SOC AM, V118, P887, DOI 10.1121/1.1945807
   Cui YW, 2016, NEURAL COMPUT, V28, P2474, DOI 10.1162/NECO_a_00893
   De-La-Calle-Silos F, 2016, LECT NOTES COMPUT SC, V10077, P87, DOI 10.1007/978-3-319-49169-1_9
   Dent ML, 1997, J ACOUST SOC AM, V102, P1891, DOI 10.1121/1.420111
   Eatock RA, 2000, ANNU REV NEUROSCI, V23, P285, DOI 10.1146/annurev.neuro.23.1.285
   Frigo M, 2005, P IEEE, V93, P216, DOI 10.1109/JPROC.2004.840301
   Guerguiev J, 2017, ELIFE, V6, DOI 10.7554/eLife.22901
   Hannemann R, 2007, BRAIN RES, V1153, P134, DOI 10.1016/j.brainres.2007.03.069
   Hawkins J, 2016, FRONT NEURAL CIRCUIT, V10, DOI 10.3389/fncir.2016.00023
   HEIL P, 1992, HEARING RES, V63, P135, DOI 10.1016/0378-5955(92)90081-W
   Hienz RD, 1996, J ACOUST SOC AM, V99, P3656, DOI 10.1121/1.414980
   Holle H, 2010, NEUROIMAGE, V49, P875, DOI 10.1016/j.neuroimage.2009.08.058
   Holt JR, 2000, P NATL ACAD SCI USA, V97, P11730, DOI 10.1073/pnas.97.22.11730
   HOMMEL G, 1988, BIOMETRIKA, V75, P383, DOI 10.2307/2336190
   HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Javitt DC, 1996, P NATL ACAD SCI USA, V93, P11962, DOI 10.1073/pnas.93.21.11962
   Kluender KR, 1998, J ACOUST SOC AM, V104, P3568, DOI 10.1121/1.423939
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Kohonen T., 1989, SELF ORG ASS MEMORY, V3rd
   Krause MR, 2014, VISION RES, V104, P36, DOI 10.1016/j.visres.2014.10.006
   KUHL PK, 1983, J ACOUST SOC AM, V73, P1003, DOI 10.1121/1.389148
   KUHL PK, 1975, SCIENCE, V190, P69, DOI 10.1126/science.1166301
   Kusy B, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN 2009), P109
   Le Goff L, 2005, P NATL ACAD SCI USA, V102, P16996, DOI 10.1073/pnas.0508731102
   Lillicrap TP, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13276
   Linden JF, 2003, CEREB CORTEX, V13, P83, DOI 10.1093/cercor/13.1.83
   Lotto AJ, 1997, J ACOUST SOC AM, V102, P1134, DOI 10.1121/1.419865
   Major G, 2013, ANNU REV NEUROSCI, V36, P1, DOI 10.1146/annurev-neuro-062111-150343
   Marblestone AH, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00094
   Marques T, 2018, NAT NEUROSCI, P1546
   MENDELSON JR, 1985, BRAIN RES, V327, P331, DOI 10.1016/0006-8993(85)91530-6
   Mesgarani N, 2014, PNAS, V123, P899
   Mesgarani N, 2008, J ACOUST SOC AM, V123, P899, DOI 10.1121/1.2816572
   Meyer HS, 2013, P NATL ACAD SCI USA, V110, P19113, DOI 10.1073/pnas.1312691110
   Mountcastle VB, 1997, BRAIN, V120, P701, DOI 10.1093/brain/120.4.701
   MOUNTCASTLE VB, 1957, J NEUROPHYSIOL, V20, P408
   Mountcastle VB, 1955, AM J PHYSL, V183
   Natan RG, 2015, ELIFE, V4, DOI [10.7554/eLife.09868, 10.7554/eLife.09868.001]
   Obleser J, 2007, J NEUROSCI, V27, P2283, DOI 10.1523/JNEUROSCI.4663-06.2007
   Obleser J, 2011, NEUROIMAGE, V55, P713, DOI 10.1016/j.neuroimage.2010.12.020
   Obleser J, 2010, CEREB CORTEX, V20, P633, DOI 10.1093/cercor/bhp128
   Pons F, 2006, J EXP PSYCHOL ANIM B, V32, P97, DOI 10.1037/0097-7403.32.1.97
   Rasanen O, 2012, SPEECH COMMUN, V54, P975, DOI 10.1016/j.specom.2012.05.001
   REITER HO, 1988, P NATL ACAD SCI USA, V85, P3623, DOI 10.1073/pnas.85.10.3623
   ROE AW, 1990, SCIENCE, V250, P818, DOI 10.1126/science.2237432
   ROE AW, 1992, J NEUROSCI, V12, P3651
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Saffran JR, 1997, PSYCHOL SCI, V8, P101, DOI 10.1111/j.1467-9280.1997.tb00690.x
   SCHREINER CE, 1990, J NEUROPHYSIOL, V64, P1442
   SHAMMA SA, 1993, J NEUROPHYSIOL, V69, P367
   Sharma J, 2000, NATURE, V404, P841, DOI 10.1038/35009043
   Snow M, 2016, J VISION, V16, DOI 10.1167/16.13.1
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   SUR M, 1988, SCIENCE, V242, P1437, DOI 10.1126/science.2462279
   Ulanovsky N, 2003, NAT NEUROSCI, V6, P391, DOI 10.1038/nn1032
   WANG KS, 1995, IEEE T SPEECH AUDI P, V3, P382, DOI 10.1109/89.466657
NR 67
TC 1
Z9 1
U1 1
U2 3
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD JUN 7
PY 2019
VL 14
IS 6
AR e0217966
DI 10.1371/journal.pone.0217966
PG 28
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA IC0OB
UT WOS:000470658500024
PM 31173613
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Tsukada, K
AF Tsukada, Kimiko
TI Are Asian Language Speakers Similar or Different? The Perception of
   Mandarin Lexical Tones by Naive Listeners from Tonal Language
   Backgrounds: A Preliminary Comparison of Thai and Vietnamese Listeners*
SO AUSTRALIAN JOURNAL OF LINGUISTICS
LA English
DT Article
DE Cross-language Speech Perception; Mandarin Lexical Tones; Thai;
   Vietnamese; Australian English
ID NATIVE SPEAKERS; ENGLISH; VOWELS; EXPERIENCE; CANTONESE; CONTRASTS;
   LEARNERS; JAPANESE
AB Mandarin is one of the most representative tonal languages in the world with four tone categories (Tone 1 (T1): high level (a); Tone 2 (T2): high rising (a); Tone 3 (T3): dipping (); Tone 4 (T4): high falling (a)). Learning Mandarin tones is known to be difficult for speakers from diverse linguistic backgrounds. The perception of Mandarin tones by naive, non-native listeners from two tonal languages with a larger tone inventory than Mandarin-Thai and Vietnamese-was examined. The listeners' discrimination accuracy of six tone pairs (T1-T2, T1-T3, T1-T4, T2-T3, T2-T4, T3-T4) was assessed and compared to that of native speakers of Mandarin on the one hand and Australian English on the other hand. The Thai and Vietnamese groups were clearly less accurate than the Mandarin group and showed a different pattern of results from each other. The Australian English group was less accurate than the Thai group only for T2-T4 and did not differ from the Vietnamese group for any of the pairs. Taken together, these findings suggest that first language tone knowledge may not necessarily be facilitative and that lack of experience with lexical tones may not disadvantage listeners from non-tonal language backgrounds in processing unfamiliar tones.
C1 [Tsukada, Kimiko] Macquarie Univ, N Ryde, NSW, Australia.
   [Tsukada, Kimiko] Univ Melbourne, Melbourne, Vic, Australia.
RP Tsukada, K (corresponding author), Macquarie Univ, N Ryde, NSW, Australia.; Tsukada, K (corresponding author), Univ Melbourne, Melbourne, Vic, Australia.
EM kimiko.tsukada@gmail.com
OI Tsukada, Kimiko/0000-0001-6365-3322
CR Abramson Arthur S., 1975, STUDIES TAI LINGUIST, P1
   ABRAMSON AS, 1978, LANG SPEECH, V21, P319, DOI 10.1177/002383097802100406
   Abramson AS, 1976, TAI LINGUISTICS HONO, P1
   Alexander JA, 2016, P 5 INT S TON ASP LA, P28
   Aoyama K, 2004, J PHONETICS, V32, P233, DOI 10.1016/S0095-4470(03)00036-6
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Broselow E., 1987, INTERLANGUAGE PHONOL, P350
   Brunelle M, 2016, LANG LINGUIST COMPAS, V10, P191, DOI 10.1111/lnc3.12182
   Brunelle M, 2009, J PHONETICS, V37, P79, DOI 10.1016/j.wocn.2008.09.003
   Burnham D., 2015, APPL PSYCHOLINGUIST, V36, P1459, DOI [10.1017/S0142716414000496, DOI 10.1017/S0142716414000496]
   Burnham D., 1997, SE ASIAN LINGUISTIC, P29
   Caldwell-Harris CL, 2015, STUD SECOND LANG ACQ, V37, P335, DOI 10.1017/S0272263114000849
   Chen C-M, 2012, FOREIGN LANGUAGE LEA, V1, P14
   Chow RW-C, 2018, P 6 INT S TON ASP LA
   Dao MD, 2017, HERITAGE LANGUAGE J, V14, P224
   Escudero P, 2014, J ACOUST SOC AM, V135, P1577, DOI 10.1121/1.4864477
   Flege J. E., 2003, ISSUES CLIN LINGUIST, P19
   Flege JE, 2004, STUD SECOND LANG ACQ, V26, P1, DOI 10.1017/S0272263104261010
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   Guion SG, 2000, J ACOUST SOC AM, V107, P2711, DOI 10.1121/1.428657
   Hao YC, 2018, LANG SPEECH, V61, P135, DOI 10.1177/0023830917717759
   Hao YC, 2012, J PHONETICS, V40, P269, DOI 10.1016/j.wocn.2011.11.001
   Huang T, 2010, PHONETICA, V67, P243, DOI 10.1159/000327392
   Hwa-Froelich D, 2002, AM J SPEECH-LANG PAT, V11, P264, DOI 10.1044/1058-0360(2002/031)
   Khouw E, 2007, J PHONETICS, V35, P104, DOI 10.1016/j.wocn.2005.10.003
   Kirby J, 2010, J ACOUST SOC AM, V127, P3749, DOI 10.1121/1.3327793
   Kirby JP, 2011, J INT PHON ASSOC, V41, P381, DOI 10.1017/S0025100311000181
   Krebs-Lazendic L, 2013, LAB PHONOL, V4, P435
   Lee YS, 1996, J PSYCHOLINGUIST RES, V25, P527, DOI 10.1007/BF01758181
   Li B, 2017, J PSYCHOLINGUIST RES, V46, P107, DOI 10.1007/s10936-016-9422-6
   Li Y, 2016, ENGLISH LANGUAGE TEA, V9, P122, DOI [10.5539/elt.v9n1p122, DOI 10.5539/ELT.V9N1P122]
   Lin W. C. J., 1985, RELC J, V16, P31
   NGUYEN VL, 1998, MON KHMER STUDIES J, V28, P1
   Oakley M, 2017, J ACOUST SOC AM, V142, P2725, DOI [10.1121/1.5014947, DOI 10.1121/1.5014947]
   Pham B, 2016, INT J SPEECH-LANG PA, V18, P122, DOI 10.3109/17549507.2015.1101162
   Reid A, 2015, ATTEN PERCEPT PSYCHO, V77, P571, DOI 10.3758/s13414-014-0791-3
   Rungruang A, 2017, ASIAN SOCIAL SCI, V13, P107, DOI [10.5539/ass.v13n5p107, DOI 10.5539/ASS.V13N5P107]
   SARAVARI C, 1983, J PHONETICS, V11, P231, DOI 10.1016/S0095-4470(19)30824-1
   Schaefer V, 2014, LAB PHONOL, V5, P489, DOI 10.1515/lp-2014-0016
   Shen X. S., 1989, J CHINESE LANGUAGE T, V24, P27
   SHEN XS, 1990, J PHONETICS, V18, P281, DOI 10.1016/S0095-4470(19)30394-8
   Smith S., 1997, USER MANUAL UAB SOFT
   Snodgrass J. G., 1985, HUMAN EXPT PSYCHOL
   So CK, 2010, LANG SPEECH, V53, P273, DOI 10.1177/0023830909357156
   Strange W., 2008, PHONOLOGY 2 LANGUAGE, P153
   Tingsabadh M. R. Kalaya, 1993, THAI J INT PHONETIC, V23, P24, DOI [10.1017/S0025100300004746, DOI 10.1017/S0025100300004746]
   Tsukada K, 2005, J PHONETICS, V33, P263, DOI 10.1016/j.wocn.2004.10.002
   Tsukada  K., 2016, J 2 LANGUAGE PRONUNC, V2, P225, DOI DOI 10.1075/jslp.2.2.05tsu
   Tsukada  K., 2015, CHINESE 2 LANGUAGE R, V4, P141, DOI [10.1515/caslar-2015-0009, DOI 10.1515/CASLAR-2015-0009]
   Tsukada K, 2019, SECOND LANG RES, V35, P305, DOI 10.1177/0267658318775155
   Tsukada K, 2019, LANG SPEECH, V62, P625, DOI 10.1177/0023830918806550
   Tsukada K, 2011, J ACOUST SOC AM, V129, P989, DOI 10.1121/1.3531801
   Wang XC, 2013, MOD LANG J, V97, P144, DOI 10.1111/j.1540-4781.2013.01386.x
   Wang Y, 1999, J ACOUST SOC AM, V106, P3649, DOI 10.1121/1.428217
   Wayland R, 2003, APPL PSYCHOLINGUIST, V24, P113, DOI 10.1017/S0142716403000067
   Wayland R, 1997, APPL LINGUIST, V18, P345, DOI 10.1093/applin/18.3.345
   Wayland RP, 2004, LANG LEARN, V54, P681, DOI 10.1111/j.1467-9922.2004.00283.x
   Zhang XJ, 2012, J MEM LANG, V66, P438, DOI 10.1016/j.jml.2011.12.006
NR 58
TC 0
Z9 0
U1 2
U2 5
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0726-8602
EI 1469-2996
J9 AUST J LINGUIST
JI Aust. J. Linguist.
PD JUL 3
PY 2019
VL 39
IS 3
BP 329
EP 346
DI 10.1080/07268602.2019.1620681
EA JUN 2019
PG 18
WC Linguistics; Language & Linguistics
SC Linguistics
GA IN3KD
UT WOS:000471380400001
DA 2021-02-24
ER

PT J
AU Pike, CD
   Kriengwatana, BP
AF Pike, Cleopatra Diana
   Kriengwatana, Buddhamas Pralle
TI Vocal tract constancy in birds and humans
SO BEHAVIOURAL PROCESSES
LA English
DT Article
DE Vocal tract normalisation; Auditory constancy; Bird song; Speech;
   Categorical perception; Spectral contrast; Spectral compensation effect;
   Auditory afterimage
ID FINCHES TAENIOPYGIA-GUTTATA; CATEGORICAL PERCEPTION; SPEECH-PERCEPTION;
   ZEBRA FINCH; AUDITORY-NERVE; FUNDAMENTAL-FREQUENCY; NOTE
   DISCRIMINATIONS; CONSPECIFIC SONG; BODY-SIZE; VOWEL
AB Humans perceive speech as being relatively stable despite acoustic variation caused by vocal tract (VT) differences between speakers. Humans use perceptual 'vocal tract normalisation' (VTN) and other processes to achieve this stability. Similarity in vocal apparatus/acoustics between birds and humans means that birds might also experience VT variation. This has the potential to impede bird communication. No known studies have explicitly examined this, but a number of studies show perceptual stability or 'perceptual constancy' in birds similar to that seen in humans when dealing with VT variation. This review explores similarities between birds and humans and concludes that birds show sufficient evidence of perceptual constancy to warrant further research in this area. Future work should 1) quantify the multiple sources of variation in bird vocalisations, including, but not limited to VT variations, 2) determine whether vocalisations are perniciously disrupted by any of these and 3) investigate how birds reduce variation to maintain perceptual constancy and perceptual efficiency.
C1 [Pike, Cleopatra Diana; Kriengwatana, Buddhamas Pralle] Univ St Andrews, Sch Psychol & Neurosci, South St, St Andrews KY16 9JP, Fife, Scotland.
RP Pike, CD (corresponding author), Univ St Andrews, Sch Psychol & Neurosci, South St, St Andrews KY16 9JP, Fife, Scotland.
EM cdp5@st-andrews.ac.uk
OI Kriengwatana, Buddhamas (Pralle)/0000-0002-4258-883X
FU Biotechnology and Biological Sciences Research Council (BBSRC)UK
   Research & Innovation (UKRI)Biotechnology and Biological Sciences
   Research Council (BBSRC) [BB/N010108/1]; BBSRCUK Research & Innovation
   (UKRI)Biotechnology and Biological Sciences Research Council (BBSRC)
   [BB/L002264/1]
FX Cleopatra Pike was funded by the Biotechnology and Biological Sciences
   Research Council (BBSRC) grant BB/N010108/1. Pralle Kriengwatana was
   funded by BBSRC Grant BB/L002264/1.
CR Ainsworth W., 1988, SPEECH RECOGNITION M
   AINSWORTH WA, 1972, J ACOUST SOC AM, V51, P648, DOI 10.1121/1.1912889
   Antunes FM, 2014, BRAIN TOPOGR, V27, P480, DOI 10.1007/s10548-013-0342-6
   ASSMANN PF, 1982, J ACOUST SOC AM, V71, P975, DOI 10.1121/1.387579
   Baugh AT, 2008, P NATL ACAD SCI USA, V105, P8985, DOI 10.1073/pnas.0802201105
   Beeston AV, 2014, J ACOUST SOC AM, V136, P3072, DOI 10.1121/1.4900596
   Elgoyhen AB, 2012, J PHYSIOL-PARIS, V106, P47, DOI 10.1016/j.jphysparis.2011.06.001
   BENNETT DC, 1968, LANG SPEECH, V11, P65, DOI 10.1177/002383096801100201
   Berwick RC, 2011, TRENDS COGN SCI, V15, P113, DOI 10.1016/j.tics.2011.01.002
   Bolhuis JJ, 2015, NEUROSCI BIOBEHAV R, V50, P41, DOI 10.1016/j.neubiorev.2014.11.019
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   BRENOWITZ EA, 1991, SCIENCE, V251, P303, DOI 10.1126/science.1987645
   Bruckert L, 2010, CURR BIOL, V20, P116, DOI 10.1016/j.cub.2009.11.034
   Cambria E, 2014, IEEE COMPUT INTELL M, V9, P48, DOI 10.1109/MCI.2014.2307227
   CARLSON R, 1975, AUDITORY ANAL PERCEP, P55, DOI DOI 10.1016/B978-0-12-248550-3.50008-8
   Catchpole CK, 2008, BIRD SONG: BIOLOGICAL THEMES AND VARIATIONS, 2ND EDITION, P1
   Chew SJ, 1996, P NATL ACAD SCI USA, V93, P1950, DOI 10.1073/pnas.93.5.1950
   Chirathivat N, 2015, SCI REP-UK, V5, DOI 10.1038/srep11359
   Clack JA, 2002, J NEUROBIOL, V53, P251, DOI 10.1002/neu.10129
   Cohen J, 1995, J ACOUST SOC AM, V97, P3246
   COWAN N, 1984, PSYCHOL BULL, V96, P341, DOI 10.1037/0033-2909.96.2.341
   CUTTING JE, 1974, PERCEPT PSYCHOPHYS, V16, P564, DOI 10.3758/BF03198588
   CYNX J, 1990, J COMP PSYCHOL, V104, P303, DOI 10.1037/0735-7036.104.4.303
   CYNX J, 1992, P NATL ACAD SCI USA, V89, P1368, DOI 10.1073/pnas.89.4.1368
   CYNX J, 1993, J COMP PSYCHOL, V107, P395, DOI 10.1037/0735-7036.107.4.395
   DELATTRE PC, 1955, J ACOUST SOC AM, V27, P769, DOI 10.1121/1.1908024
   Dienes Z, 1997, PSYCHON B REV, V4, P3, DOI 10.3758/BF03210769
   Doupe AJ, 1999, ANNU REV NEUROSCI, V22, P567, DOI 10.1146/annurev.neuro.22.1.567
   DuBois AL, 2009, BIOL LETTERS, V5, P163, DOI 10.1098/rsbl.2008.0626
   Elie JE, 2016, ANIM COGN, V19, P285, DOI 10.1007/s10071-015-0933-6
   Ellis, 1994, IMPLICIT EXPLICIT LE
   Fant G., 2001, Q PROGR STATUS REPOR, V42, P59
   Fitch W., 2001, ACOUSTIC COMMUNICATI, P275
   Fitch W. T., 2002, ACOUSTIC COMMUNICATI, P65
   Fitch WT, 2000, ETHOLOGY, V106, P559, DOI 10.1046/j.1439-0310.2000.00572.x
   Fitch WT, 1997, J ACOUST SOC AM, V102, P1213, DOI 10.1121/1.421048
   Flege JE, 1999, J MEM LANG, V41, P78, DOI 10.1006/jmla.1999.2638
   Foster DH, 2011, VISION RES, V51, P674, DOI 10.1016/j.visres.2010.09.006
   Fritzsch B, 2013, EVOL DEV, V15, P63, DOI 10.1111/ede.12015
   Fujisaki H., 1970, Annual Report of the Engineering Research Institute, Faculty of Engineering, University of Tokyo, V29, P207
   Galantucci B., 2016, PSYCH B REV, V13, P361
   GERSTMAN LJ, 1968, IEEE T ACOUST SPEECH, VAU16, P78, DOI 10.1109/TAU.1968.1161953
   Gobes SMH, 2007, CURR BIOL, V17, P789, DOI 10.1016/j.cub.2007.03.059
   Halberstam B, 2004, J PHONETICS, V32, P423, DOI 10.1016/j.wocn.2004.03.001
   Hall ML, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0056717
   Hardouin LA, 2014, J AVIAN BIOL, V45, P157, DOI 10.1111/j.1600-048X.2013.00144.x
   HELMHOLTZ HLF, 1863, SENSATIONS TONE
   HELSON H, 1948, PSYCHOL REV, V55, P297, DOI 10.1037/h0056721
   HINDS DS, 1971, EVOLUTION, V25, P429, DOI 10.1111/j.1558-5646.1971.tb01899.x
   Holt L. L., 1999, THESIS
   Holt LL, 2005, PSYCHOL SCI, V16, P305, DOI 10.1111/j.0956-7976.2005.01532.x
   Holt LL, 2002, HEARING RES, V167, P156, DOI 10.1016/S0378-5955(02)00383-0
   Holt LL, 2006, J ACOUST SOC AM, V120, P2801, DOI 10.1121/1.2354071
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   HOUSE AS, 1953, J ACOUST SOC AM, V25, P105, DOI 10.1121/1.1906982
   Huang JY, 2009, J ACOUST SOC AM, V125, P3983, DOI 10.1121/1.3125342
   HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308
   Huber SK, 2006, BIOL J LINN SOC, V88, P489, DOI 10.1111/j.1095-8312.2006.00638.x
   Johnson K, 2005, BLACKW HBK LINGUIST, P363, DOI 10.1002/9780470757024.ch15
   Joos M., 1948, J LINGUIST SOC AM, V24
   Kiang N. Y., 1965, MIT RES MONOGR, V35
   Kiefte M, 2005, J ACOUST SOC AM, V117, P1395, DOI 10.1121/1.1861158
   Kluender KR, 1998, J ACOUST SOC AM, V104, P3568, DOI 10.1121/1.423939
   Koffka K., 1935, PRINCIPLES GESTALT P
   Koppl C, 1997, J NEUROSCI, V17, P3312
   Kriengwatana B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01243
   Kroodsma DE, 1999, AUK, V116, P373, DOI 10.2307/4089372
   KUHL P, 1995, SPEECH PERCEPTION LI
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   KUHL PK, 1975, SCIENCE, V190, P69, DOI 10.1126/science.1166301
   Lachlan RF, 2014, P ROY SOC B-BIOL SCI, V281, DOI 10.1098/rspb.2014.0252
   Lachlan RF, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00980
   Lachlan RF, 2015, P NATL ACAD SCI USA, V112, P1892, DOI 10.1073/pnas.1410844112
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Laing EJC, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00203
   LEHISTE I, 1973, LANG SPEECH, V16, P356, DOI 10.1177/002383097301600406
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Liberman P., 1973, COGNITION, V2, P59
   LINDBLOM B, 1963, J ACOUST SOC AM, V35, P1773, DOI 10.1121/1.1918816
   LINDBLOM BE, 1967, J ACOUST SOC AM, V42, P830, DOI 10.1121/1.1910655
   Linhart P, 2015, ANIM BEHAV, V103, P91, DOI 10.1016/j.anbehav.2015.01.038
   Lippmann RP, 1996, IEEE T SPEECH AUDI P, V4, P66, DOI 10.1109/TSA.1996.481454
   Lloyd R., 1890, PHONETISCHE STUDIEN, V3, P251
   Lloyd RJ, 1890, SOME RES NATURE VOWE
   Lohr B, 1998, J COMP PSYCHOL, V112, P36, DOI 10.1037/0735-7036.112.1.36
   Lohr B, 2008, BEHAV PROCESS, V77, P156, DOI 10.1016/j.beproc.2007.11.003
   Lotto AJ, 1997, J ACOUST SOC AM, V102, P1134, DOI 10.1121/1.419865
   MACCHI MJ, 1980, J ACOUST SOC AM, V68, P1636, DOI 10.1121/1.385219
   Maddox WT, 2002, PERCEPT PSYCHOPHYS, V64, P584, DOI 10.3758/BF03194728
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P407, DOI 10.3758/BF03204884
   MARGOLIASH D, 1983, J NEUROSCI, V3, P1039
   MARLER P, 1964, SCIENCE, V146, P1483, DOI 10.1126/science.146.3650.1483
   MAY B, 1989, J ACOUST SOC AM, V85, P837, DOI 10.1121/1.397555
   MCCASLAND JS, 1981, P NATL ACAD SCI-BIOL, V78, P7815, DOI 10.1073/pnas.78.12.7815
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MCGREGOR PK, 1984, BEHAV ECOL SOCIOBIOL, V16, P49, DOI 10.1007/BF00293103
   MELLO CV, 1992, P NATL ACAD SCI USA, V89, P6818, DOI 10.1073/pnas.89.15.6818
   MILLER JD, 1989, J ACOUST SOC AM, V85, P2114, DOI 10.1121/1.397862
   MILLER JD, 1976, J ACOUST SOC AM, V60, P410, DOI 10.1121/1.381097
   MILLER RL, 1953, J ACOUST SOC AM, V25, P114, DOI 10.1121/1.1906983
   MORTON ES, 1986, BEHAVIOUR, V99, P65, DOI 10.1163/156853986X00414
   MULLENNIX JW, 1989, J ACOUST SOC AM, V85, P365, DOI 10.1121/1.397688
   NEAREY TM, 1986, J ACOUST SOC AM, V80, P1297, DOI 10.1121/1.394433
   NEAREY TM, 1989, J ACOUST SOC AM, V85, P2088, DOI 10.1121/1.397861
   NELSON DA, 1989, SCIENCE, V244, P976, DOI 10.1126/science.2727689
   Nordstrom P.-E., 1975, P 8 INT C PHON SCI
   NOTTEBOHM F, 1990, PHILOS T R SOC B, V329, P115, DOI 10.1098/rstb.1990.0156
   Nowicki S, 2005, AUK, V122, P1, DOI 10.1642/0004-8038(2005)122[0001:SAMCIB]2.0.CO;2
   NOWICKI S, 1988, MUSIC PERCEPT, V5, P391
   NOWICKI S, 1987, NATURE, V325, P53, DOI 10.1038/325053a0
   Nusbaum HC, 1992, SPEECH PERCEPTION PR, P113
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   Ohl FW, 1997, P NATL ACAD SCI USA, V94, P9440, DOI 10.1073/pnas.94.17.9440
   Ohms VR, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011923
   PALMER AR, 1995, J ACOUST SOC AM, V97, P1786, DOI 10.1121/1.412055
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Pike C., 2014, AUD ENG SOC 136 CONV
   Pike C. D., 2015, THESIS
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   Pisoni DB, 1997, TALKER VARIABILITY S, P9
   Podos J, 1996, ANIM BEHAV, V51, P1061, DOI 10.1006/anbe.1996.0107
   Podos J, 2001, NATURE, V409, P185, DOI 10.1038/35051570
   Podos J, 2009, ADV STUD BEHAV, V40, P159, DOI 10.1016/S0065-3454(09)40005-6
   POTTER RK, 1950, J ACOUST SOC AM, V22, P807, DOI 10.1121/1.1906694
   Prather JF, 2009, NAT NEUROSCI, V12, P221, DOI 10.1038/nn.2246
   Prince B, 2011, J MORPHOL, V272, P1527, DOI 10.1002/jmor.11007
   Pytte CL, 1999, NEUROREPORT, V10, P1773, DOI 10.1097/00001756-199906030-00027
   Reby D, 2003, ANIM BEHAV, V65, P519, DOI 10.1006/anbe.2003.2078
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   REPP BH, 1982, PSYCHOL BULL, V92, P81, DOI 10.1037/0033-2909.92.1.81
   Ribeiro S, 1998, NEURON, V21, P359, DOI 10.1016/S0896-6273(00)80545-0
   Riede T, 2006, P NATL ACAD SCI USA, V103, P5543, DOI 10.1073/pnas.0601262103
   Riede T, 1999, J EXP BIOL, V202, P2859
   Riede T, 2014, P ROY SOC B-BIOL SCI, V281, DOI 10.1098/rspb.2013.2306
   Riede T, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011368
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Saino N, 1997, BEHAV ECOL, V8, P364, DOI 10.1093/beheco/8.4.364
   SAMUEL AG, 1982, PERCEPT PSYCHOPHYS, V31, P307, DOI 10.3758/BF03202653
   Samuels BD, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01082
   SEARCY WA, 1986, ANNU REV ECOL SYST, V17, P507, DOI 10.1146/annurev.es.17.110186.002451
   Searcy WA, 2006, BEHAV ECOL SOCIOBIOL, V60, P234, DOI 10.1007/s00265-006-0161-9
   SHAPLEY RM, 1973, J PHYSIOL-LONDON, V229, P165, DOI 10.1113/jphysiol.1973.sp010133
   SMITH RL, 1979, J ACOUST SOC AM, V65, P166, DOI 10.1121/1.382260
   Soha J, 2017, ANIM BEHAV, V124, P247, DOI 10.1016/j.anbehav.2016.09.016
   Stilp CE, 2010, ATTEN PERCEPT PSYCHO, V72, P470, DOI 10.3758/APP.72.2.470
   STRANGE W, 1989, J ACOUST SOC AM, V85, P2081, DOI 10.1121/1.397860
   STRANGE W, 1976, J ACOUST SOC AM, V60, P213, DOI 10.1121/1.381066
   Sturdy CB, 1999, J COMP PSYCHOL, V113, P204, DOI 10.1037/0735-7036.113.2.204
   Sturdy CB, 2000, J COMP PSYCHOL, V114, P357, DOI 10.1037/0735-7036.114.4.357
   SUMMERFIELD Q, 1989, PERCEPT PSYCHOPHYS, V45, P529, DOI 10.3758/BF03208060
   SUMMERFIELD Q, 1984, PERCEPT PSYCHOPHYS, V35, P203, DOI 10.3758/BF03205933
   SUMMERFIELD Q, 1987, J ACOUST SOC AM, V81, P700, DOI 10.1121/1.394838
   Sussman H., 1997, BRAIN BEHAV SCI, V21, P260
   SUSSMAN HM, 1989, PSYCHOL REV, V96, P631, DOI 10.1037/0033-295X.96.4.631
   Suthers RA, 2001, NETH J ZOOL, V51, P217, DOI 10.1163/156854201750385163
   SUTHERS RA, 1994, J COMP PHYSIOL A, V175, P457
   Templeton CN, 2005, SCIENCE, V308, P1934, DOI 10.1126/science.1108841
   Theunissen FE, 2004, ANN NY ACAD SCI, V1016, P222, DOI 10.1196/annals.1298.023
   TRAUNMULLER H, 1984, SPEECH COMMUN, V3, P49, DOI 10.1016/0167-6393(84)90008-6
   Ulanovsky N, 2004, J NEUROSCI, V24, P10440, DOI 10.1523/JNEUROSCI.1905-04.2004
   Ulanovsky N, 2003, NAT NEUROSCI, V6, P391, DOI 10.1038/nn1032
   Uno H, 1997, BEHAV BRAIN RES, V89, P225, DOI 10.1016/S0166-4328(97)00064-8
   Vallet E, 1998, ANIM BEHAV, V55, P291, DOI 10.1006/anbe.1997.0631
   VALLET E, 1995, ANIM BEHAV, V49, P1603, DOI 10.1016/0003-3472(95)90082-9
   VERBRUGGE RR, 1976, J ACOUST SOC AM, V59, pS5, DOI 10.1121/1.2002786
   VIEMEISTER NF, 1982, J ACOUST SOC AM, V71, P1502, DOI 10.1121/1.387849
   Vignal C, 2008, BEHAV PROCESS, V77, P191, DOI 10.1016/j.beproc.2007.09.003
   VOICU H, 2004, J COGNITIVE NEUROSCI, V16, P1, DOI DOI 10.1080/09540090410001664641
   Warren TL, 2011, J NEUROPHYSIOL, V106, P1806, DOI 10.1152/jn.00311.2011
   Watkins AJ, 1996, J ACOUST SOC AM, V99, P588, DOI 10.1121/1.414515
   WATKINS AJ, 1991, J ACOUST SOC AM, V90, P2942, DOI 10.1121/1.401769
   WATKINS AJ, 1994, J ACOUST SOC AM, V96, P1263, DOI 10.1121/1.410275
   Watkins AJ, 1996, J ACOUST SOC AM, V99, P3749, DOI 10.1121/1.414981
   WEARY DM, 1992, ANIM BEHAV, V43, P283, DOI 10.1016/S0003-3472(05)80223-4
   WEARY DM, 1989, J COMP PSYCHOL, V103, P320, DOI 10.1037/0735-7036.103.4.320
   WEISMAN R, 1994, J COMP PSYCHOL, V108, P363, DOI 10.1037/0735-7036.108.4.363
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   White SA, 2006, J NEUROSCI, V26, P10376, DOI 10.1523/JNEUROSCI.3379-06.2006
   WILLIAMS H, 1989, J COMP PSYCHOL, V103, P366, DOI 10.1037/0735-7036.103.4.366
   WILLIAMS H, 1989, ANN NY ACAD SCI, V563, P148, DOI 10.1111/j.1749-6632.1989.tb42196.x
   Wohlgemuth MJ, 2010, J NEUROSCI, V30, P12936, DOI 10.1523/JNEUROSCI.2690-10.2010
   Wyttenbach RA, 1996, SCIENCE, V273, P1542, DOI 10.1126/science.273.5281.1542
   Yip M. J., 2006, TRENDS COGNIT SCI, V10
NR 184
TC 1
Z9 1
U1 0
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0376-6357
EI 1872-8308
J9 BEHAV PROCESS
JI Behav. Processes
PD JUN
PY 2019
VL 163
SI SI
BP 99
EP 112
DI 10.1016/j.beproc.2018.08.001
PG 14
WC Psychology, Biological; Behavioral Sciences; Zoology
SC Psychology; Behavioral Sciences; Zoology
GA IH2IH
UT WOS:000474317900013
PM 30145277
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Healy, EW
   Vasko, JL
   Wang, DL
AF Healy, Eric W.
   Vasko, Jordan L.
   Wang, DeLiang
TI The optimal threshold for removing noise from speech is similar across
   normal and impaired hearing-a time-frequency masking study
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID INTELLIGIBILITY; ALGORITHM; RECOGNITION; LISTENERS
AB Hearing-impaired listeners' intolerance to background noise during speech perception is well known. The current study employed speech materials free of ceiling effects to reveal the optimal trade-off between rejecting noise and retaining speech during time-frequency masking. This relative criterion value (-7 dB) was found to hold across noise types that differ in acoustic spectro-temporal complexity. It was also found that listeners with hearing impairment and those with normal hearing performed optimally at this same value, suggesting no true noise intolerance once time-frequency units containing speech are extracted.
C1 [Healy, Eric W.; Vasko, Jordan L.] Ohio State Univ, Dept Speech & Hearing Sci, Columbus, OH 43210 USA.
   [Healy, Eric W.; Vasko, Jordan L.; Wang, DeLiang] Ohio State Univ, Ctr Cognit & Brain Sci, Columbus, OH 43210 USA.
   [Wang, DeLiang] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
RP Healy, EW (corresponding author), Ohio State Univ, Dept Speech & Hearing Sci, Columbus, OH 43210 USA.; Healy, EW (corresponding author), Ohio State Univ, Ctr Cognit & Brain Sci, Columbus, OH 43210 USA.
EM Healy.66@osu.edu; Vasko.30@osu.edu; Dwang@cse.ohio-state.edu
FU National Institute on Deafness and other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01 DC015521, R01 DC012048]; Ohio State
   University Center for Cognitive and Brain Sciences; NATIONAL INSTITUTE
   ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC015521, R01DC012048, R01DC012048, R01DC015521, R01DC012048,
   R01DC012048, R01DC015521, R01DC012048, R01DC015521] Funding Source: NIH
   RePORTER
FX This work was supported in part by the National Institute on Deafness
   and other Communication Disorders (Grant No. R01 DC015521 to E.W.H. and
   Grant No. R01 DC012048 to D.L.W.) and by a summer graduate fellowship
   from The Ohio State University Center for Cognitive and Brain Sciences
   (J.L.V.).
CR Apoux F, 2009, HEARING RES, V255, P99, DOI 10.1016/j.heares.2009.06.005
   Brungart DS, 2006, J ACOUST SOC AM, V120, P4007, DOI 10.1121/1.2363929
   BUUS S, 1985, J ACOUST SOC AM, V78, P1958, DOI 10.1121/1.392652
   Chen F, 2016, J ACOUST SOC AM, V140, P4161, DOI 10.1121/1.4971206
   Chen JT, 2016, J ACOUST SOC AM, V139, P2604, DOI 10.1121/1.4948445
   Healy EW, 2015, J ACOUST SOC AM, V138, P1660, DOI 10.1121/1.4929493
   Healy EW, 2014, J ACOUST SOC AM, V135, P581, DOI 10.1121/1.4861363
   Healy EW, 2013, J ACOUST SOC AM, V134, P3029, DOI 10.1121/1.4820893
   Hu GN, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P79, DOI 10.1109/ASPAA.2001.969547
   Kjems U, 2009, J ACOUST SOC AM, V126, P1415, DOI 10.1121/1.3179673
   Li N, 2008, J ACOUST SOC AM, V123, P1673, DOI 10.1121/1.2832617
   Moore B. C. J., 2007, COCHLEAR HEARING LOS, P45
   Roman N, 2013, J ACOUST SOC AM, V133, P1707, DOI 10.1121/1.4789895
   Sinex DG, 2013, J ACOUST SOC AM, V133, P2390, DOI 10.1121/1.4792143
   Wang DL, 2005, SPEECH SEPARATION BY HUMANS AND MACHINES, P181, DOI 10.1007/0-387-22794-6_12
   Zhao Y, 2018, J ACOUST SOC AM, V144, P1627, DOI 10.1121/1.5055562
NR 16
TC 2
Z9 2
U1 1
U2 2
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JUN
PY 2019
VL 145
IS 6
BP EL581
EP EL586
DI 10.1121/1.5112828
PG 6
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA IH6KF
UT WOS:000474603700020
PM 31255108
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Yang, J
   Li, P
AF Yang, Jing
   Li, Ping
TI Mechanisms for Auditory Perception: A Neurocognitive Study of Second
   Language Learning of Mandarin Chinese
SO BRAIN SCIENCES
LA English
DT Article
DE auditory perception; second language word learning; individual
   differences; functional magnetic resonance imaging; effective
   connectivity
ID WHITE-MATTER STRUCTURE; STRUCTURAL CONNECTIVITY; NEURAL ORGANIZATION;
   LANGUAGE APTITUDE; TONE PERCEPTION; SPEECH; BRAIN; PREDICTS;
   ACQUISITION; FMRI
AB Speech perception is an important early skill for language learning. This study uses functional magnetic resonance imaging (fMRI) to examine the relationship between auditory perception abilities and second language (L2) vocabulary learning in an effort to explore behavior-brain correlations. Twenty-one English monolinguals learned 48 auditory Chinese pseudowords over six weeks. Their pre-training abilities in non-linguistic pitch and linguistic tone perception significantly and positively predicted their novel word-learning performance, which correlated with their brain response patterns in the left Heschl's gyrus. Analyses of regions of interest (ROIs) showed coactivation of the frontal and temporal regions during novel lexical retrieval, and the non-linguistic pitch perception ability modulated brain activations in these regions. Effective connectivity analyses further indicated a collaboration of a ventral stream for speech perception and a dorsal stream for sensory-motor mapping in the L2 network. The ventral stream, compared with the dorsal stream, played a more dominant role in auditory word learning as the L2 proficiency increased. Better pitch and tone perception abilities strengthened the ventral pathways and decreased the reliance on frontal regions. These findings are discussed in light of current models of speech processing and L2 learning.
C1 [Yang, Jing] Guangdong Univ Foreign Studies, Ctr Linguist & Appl Linguist, Guangzhou 510420, Guangdong, Peoples R China.
   [Yang, Jing] Guangdong Univ Foreign Studies, Bilingual Cognit & Dev Lab, Guangzhou 510420, Guangdong, Peoples R China.
   [Yang, Jing; Li, Ping] Penn State Univ, Dept Psychol, University Pk, PA 16802 USA.
   [Yang, Jing; Li, Ping] Penn State Univ, Ctr Brain Behav & Cognit, University Pk, PA 16802 USA.
RP Li, P (corresponding author), Penn State Univ, Dept Psychol, University Pk, PA 16802 USA.; Li, P (corresponding author), Penn State Univ, Ctr Brain Behav & Cognit, University Pk, PA 16802 USA.
EM yangjing@gdufs.edu.cn; pingpsu@gmail.com
FU US National Science FoundationNational Science Foundation (NSF)
   [BCS-1533625, BCS-1349110]; National Natural Science Foundation of
   ChinaNational Natural Science Foundation of China (NSFC) [31500924];
   Innovative School Project in Higher Education of Guangdong, China
   [GWTP-GC-2017-01]; MOE Project of Key Research Institute of Humanities
   and Social Sciences at Universities [13JJD740009]
FX This research was funded by grants from the US National Science
   Foundation (BCS-1533625; BCS-1349110) to P.L. Preparation of the
   manuscript was also supported by the National Natural Science Foundation
   of China (31500924), Innovative School Project in Higher Education of
   Guangdong, China (GWTP-GC-2017-01), and the MOE Project of Key Research
   Institute of Humanities and Social Sciences at Universities
   (13JJD740009) to J.Y.
CR Abutalebi J, 2016, BILING-LANG COGN, V19, P689, DOI 10.1017/S1366728916000225
   Bates D, FITTING LINEAR MIXED
   Bates E, 2003, PSYCHON B REV, V10, P344, DOI 10.3758/BF03196494
   Breitenstein C, 2005, NEUROIMAGE, V25, P958, DOI 10.1016/j.neuroimage.2004.12.019
   Chai XQJ, 2016, J NEUROSCI, V36, P755, DOI 10.1523/JNEUROSCI.2234-15.2016
   Chandrasekaran B, 2010, J ACOUST SOC AM, V128, P456, DOI 10.1121/1.3445785
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Cumming R, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00972
   Davis MH, 2009, J COGNITIVE NEUROSCI, V21, P803, DOI 10.1162/jocn.2009.21059
   Della Rosa PA, 2013, CORTEX, V49, P605, DOI 10.1016/j.cortex.2012.12.001
   Friederici AD, 2000, BRAIN LANG, V74, P289, DOI 10.1006/brln.2000.2313
   Friederici AD, 2013, CURR OPIN NEUROBIOL, V23, P250, DOI 10.1016/j.conb.2012.10.002
   Friederici AD, 2009, TRENDS COGN SCI, V13, P175, DOI 10.1016/j.tics.2009.01.001
   Gates KM, 2012, NEUROIMAGE, V63, P310, DOI 10.1016/j.neuroimage.2012.06.026
   Gates KM, 2010, NEUROIMAGE, V50, P1118, DOI 10.1016/j.neuroimage.2009.12.117
   Gierhan SME, 2013, BRAIN LANG, V127, P205, DOI 10.1016/j.bandl.2012.11.002
   Golestani N, 2004, NEUROIMAGE, V21, P494, DOI 10.1016/j.neuroimage.2003.09.071
   Golestani N., 2010, P COGN NEUR SOC M MO
   Golestani N, 2007, CEREB CORTEX, V17, P929, DOI 10.1093/cercor/bhl003
   Golestani N, 2007, CEREB CORTEX, V17, P575, DOI 10.1093/cercor/bhk001
   Golestani N, 2016, BILING-LANG COGN, V19, P674, DOI 10.1017/S1366728915000644
   Golestani N, 2009, BRAIN LANG, V109, P55, DOI 10.1016/j.bandl.2008.01.005
   Grant A., 2019, HDB NEUROSCIENCE MUL, P48
   Grant AM, 2015, BRAIN LANG, V144, P35, DOI 10.1016/j.bandl.2015.03.010
   Graves WW, 2008, J COGNITIVE NEUROSCI, V20, P1698, DOI 10.1162/jocn.2008.20113
   Green DW, 2013, J COGN PSYCHOL, V25, P515, DOI 10.1080/20445911.2013.796377
   Hagoort P, 2014, ANNU REV NEUROSCI, V37, P347, DOI 10.1146/annurev-neuro-071013-013847
   Hao YC, 2012, J PHONETICS, V40, P269, DOI 10.1016/j.wocn.2011.11.001
   Hickok G, 2009, PHYS LIFE REV, V6, P121, DOI 10.1016/j.plrev.2009.06.001
   Hu XC, 2013, BRAIN LANG, V127, P366, DOI 10.1016/j.bandl.2012.11.006
   Iacoboni M, 2008, J PHYSIOL-PARIS, V102, P31, DOI 10.1016/j.jphysparis.2008.03.003
   Kerns JG, 2004, SCIENCE, V303, P1023, DOI 10.1126/science.1089910
   Kim J, 2007, HUM BRAIN MAPP, V28, P85, DOI 10.1002/hbm.20259
   Kimppa L, 2015, NEUROIMAGE, V118, P282, DOI 10.1016/j.neuroimage.2015.05.098
   Klein D, 2001, NEUROIMAGE, V13, P646, DOI 10.1006/nimg.2000.0738
   Kuhl PK, 2011, MIND BRAIN EDUC, V5, P128, DOI 10.1111/j.1751-228X.2011.01121.x
   Lane S., GIMME GROUP ITERATIV
   Lane ST, 2017, STRUCT EQU MODELING, V24, P768, DOI 10.1080/10705511.2017.1309978
   Lee YS, 1996, J PSYCHOLINGUIST RES, V25, P527, DOI 10.1007/BF01758181
   Legault J, 2019, BRAIN COGNITION, V134, P90, DOI 10.1016/j.bandc.2018.09.004
   Li P, 2020, BILING-LANG COGN, V23, P938, DOI 10.1017/S1366728918001153
   Li P, 2014, CORTEX, V58, P301, DOI 10.1016/j.cortex.2014.05.001
   Li P, 2014, BILING-LANG COGN, V17, P673, DOI 10.1017/S1366728913000606
   Liu Y, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0015639
   Majerus S, 2008, NEUROIMAGE, V42, P1698, DOI 10.1016/j.neuroimage.2008.06.003
   Makris N, 2006, SCHIZOPHR RES, V83, P155, DOI 10.1016/j.schres.2005.11.020
   Martensson J, 2012, NEUROIMAGE, V63, P240, DOI 10.1016/j.neuroimage.2012.06.043
   McLaughlin J, 2004, NAT NEUROSCI, V7, P703, DOI 10.1038/nn1264
   Mechelli A, 2004, NATURE, V431, P757, DOI 10.1038/431757a
   Mei LL, 2008, NEUROREPORT, V19, P215, DOI 10.1097/WNR.0b013e3282f46ea9
   Mei LL, 2014, NEUROPSYCHOLOGIA, V65, P156, DOI 10.1016/j.neuropsychologia.2014.10.019
   Penny W. D., 2011, STAT PARAMETRIC MAPP
   Prat CS, 2016, BRAIN LANG, V157, P44, DOI 10.1016/j.bandl.2016.04.007
   Qi ZH, 2019, NEUROIMAGE, V192, P76, DOI 10.1016/j.neuroimage.2019.03.008
   Qi ZH, 2015, J NEUROLINGUIST, V33, P14, DOI 10.1016/j.jneuroling.2014.08.004
   Raboyeau G, 2010, NEUROIMAGE, V49, P2850, DOI 10.1016/j.neuroimage.2009.10.007
   Ranganath C, 2000, J NEUROSCI, V20, DOI 10.1523/JNEUROSCI.20-22-j0005.2000
   Rivera-Gaxiola M, 2005, DEVELOPMENTAL SCI, V8, P162, DOI 10.1111/j.1467-7687.2005.00403.x
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Schlauch R.S., 2015, HDB CLIN AUDIOLOGY, V7th, P29
   Schlegel AA, 2012, J COGNITIVE NEUROSCI, V24, P1664, DOI 10.1162/jocn_a_00240
   Sheppard JP, 2012, J COGNITIVE NEUROSCI, V24, P1087, DOI 10.1162/jocn_a_00210
   SNYDER PJ, 1993, CORTEX, V29, P115, DOI 10.1016/S0010-9452(13)80216-X
   Stein M, 2012, CORTEX, V48, P458, DOI 10.1016/j.cortex.2010.10.007
   Stocco A, 2014, INT J BILINGUAL, V18, P67, DOI 10.1177/1367006912456617
   Ventura-Campos N, 2013, J NEUROSCI, V33, P9295, DOI 10.1523/JNEUROSCI.4655-12.2013
   Veroude K, 2010, BRAIN LANG, V113, P21, DOI 10.1016/j.bandl.2009.12.005
   Wang Y, 2003, J ACOUST SOC AM, V113, P1033, DOI 10.1121/1.1531176
   Whitney C, 2011, CEREB CORTEX, V21, P1066, DOI 10.1093/cercor/bhq180
   Wong FCK, 2011, J NEUROSCI, V31, P8780, DOI 10.1523/JNEUROSCI.0999-11.2011
   Wong PCM, 2008, CEREB CORTEX, V18, P828, DOI 10.1093/cercor/bhm115
   Wong PCM, 2007, APPL PSYCHOLINGUIST, V28, P565, DOI 10.1017/S0142716407070312
   Wong PCM, 2007, HUM BRAIN MAPP, V28, P995, DOI 10.1002/hbm.20330
   Xiang HD, 2015, BRAIN CONNECT, V5, P349, DOI 10.1089/brain.2013.0199
   Xiang HD, 2012, LANG LEARN, V62, P110, DOI 10.1111/j.1467-9922.2012.00708.x
   Yan CG, 2016, NEUROINFORMATICS, V14, P339, DOI 10.1007/s12021-016-9299-4
   Yang J, 2015, J NEUROLINGUIST, V33, P29, DOI 10.1016/j.jneuroling.2014.09.004
   Yang J, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0042993
   Zhang LJ, 2010, HUM BRAIN MAPP, V31, P1106, DOI 10.1002/hbm.20922
NR 79
TC 3
Z9 3
U1 1
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3425
J9 BRAIN SCI
JI Brain Sci.
PD JUN
PY 2019
VL 9
IS 6
AR 139
DI 10.3390/brainsci9060139
PG 15
WC Neurosciences
SC Neurosciences & Neurology
GA IG4UE
UT WOS:000473797900016
PM 31212921
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Savchenko, VV
AF Savchenko, V. V.
TI Itakura-Saito Divergence as an Element of the Information Theory of
   Speech Perception
SO JOURNAL OF COMMUNICATIONS TECHNOLOGY AND ELECTRONICS
LA English
DT Article
ID DECODING METHOD; MINIMUM
AB On the basis of the information theory of speech perception, a substantiation of the symmetric form of the Itakura-Saito divergence as the minimum decision-making statistics of the asymptotically optimal algorithm for recognition of speech signals at the basic, phonetic level of their processing is given. The conclusions of the theoretical study are confirmed by the results of an experiment. It is shown that the use of the synthesized algorithm can significantly improve the accuracy and reliability of the automatic recognition of the most problematic phonetic units.
C1 [Savchenko, V. V.] Linguist Univ Nizhny Novgorod, Nizhnii Novgorod 603155, Russia.
RP Savchenko, VV (corresponding author), Linguist Univ Nizhny Novgorod, Nizhnii Novgorod 603155, Russia.
EM vvsavchenko@yandex.ru
RI Savchenko, Vladimir/S-7389-2017
OI Savchenko, Vladimir/0000-0003-3045-3337
CR Benesty J., 2008, SPRINGER HDB SPEECH
   Borovkov A. A., 2010, MATH STAT
   Chen G, 2003, SIGNAL PROCESS, V83, P1445, DOI 10.1016/S0165-1684(03)00061-6
   GRAY RM, 1980, IEEE T ACOUST SPEECH, V28, P367, DOI 10.1109/TASSP.1980.1163421
   Konev A. A., 2012, P 6 MATH INT WORKSH, P35
   Kullback S, 1997, INFORM THEORY STAT
   Marple S. L., 1987, DIGITAL SPECTRAL ANA
   Savchenko AV, 2014, LECT NOTES COMPUT SC, V8509, P638, DOI 10.1007/978-3-319-07998-1_73
   Savchenko VV, 2018, J COMMUN TECHNOL EL+, V63, P53, DOI 10.1134/S1064226918010126
   Savchenko V. V., 1997, Journal of Communications Technology and Electronics, V42, P393
   Savchenko VV, 2017, J COMMUN TECHNOL EL+, V62, P788, DOI 10.1134/S1064226917070099
   Savchenko VV, 2016, J COMMUN TECHNOL EL+, V61, P1374, DOI 10.1134/S1064226916120226
   Savchenko VV, 2016, J COMMUN TECHNOL EL+, V61, P430, DOI 10.1134/S1064226916040112
   Savchenko VV, 2015, RADIOPHYS QUANT EL+, V58, P373, DOI 10.1007/s11141-015-9611-4
   [Савченко В.В. Savchenko V.V.], 2007, [Известия высших учебных заведений России. Радиоэлектроника, Izvestiya vysshikh uchebnykh zavedenii Rossii. Radioelektronika], P3
   Savchenko V. V., 2017, ELEKTROSVYAZ, P22
   Savchenko V. V., 2015, NAUCH VEDOM BELGO EI, V33, P74
   Savchenko V. V., 2012, IZV VYSSH UCHEBN ZAV, P47
   Savchenko VV, 2005, J COMMUN TECHNOL EL+, V50, P286
   Schuster M, 2010, LECT NOTES ARTIF INT, V6230, P8, DOI 10.1007/978-3-642-15246-7_3
   Wei B., 2000, P IEEE DIG SIGN PROC, P3
   Zhow J., 2014, CHINESE J ACOUST, V33, P312
NR 22
TC 3
Z9 6
U1 0
U2 1
PU PLEIADES PUBLISHING INC
PI MOSCOW
PA PLEIADES PUBLISHING INC, MOSCOW, 00000, RUSSIA
SN 1064-2269
EI 1555-6557
J9 J COMMUN TECHNOL EL+
JI J. Commun. Technol. Electron.
PD JUN
PY 2019
VL 64
IS 6
BP 590
EP 596
DI 10.1134/S1064226919060093
PG 7
WC Engineering, Electrical & Electronic; Telecommunications
SC Engineering; Telecommunications
GA IG0US
UT WOS:000473506400008
DA 2021-02-24
ER

PT J
AU Getz, LM
   Toscano, JC
AF Getz, Laura M.
   Toscano, Joseph C.
TI Electrophysiological Evidence for Top-Down Lexical Influences on Early
   Speech Perception
SO PSYCHOLOGICAL SCIENCE
LA English
DT Article
DE speech perception; semantic priming; perceptual encoding; top-down
   processing; event-related potentials
ID INTERACTIVE PROCESSES; COMPENSATION; INFORMATION; COARTICULATION;
   CATEGORIZATION; RESTORATION; RECOGNITION; LANGUAGE; FEEDBACK; MODEL
AB An unresolved issue in speech perception concerns whether top-down linguistic information influences perceptual responses. We addressed this issue using the event-related-potential technique in two experiments that measured cross-modal sequential-semantic priming effects on the auditory N1, an index of acoustic-cue encoding. Participants heard auditory targets (e.g., "potatoes") following associated visual primes (e.g., "MASHED"), neutral visual primes (e.g., "FACE"), or a visual mask (e.g., "XXXX"). Auditory targets began with voiced (/b/, /d/, /g/) or voiceless (/p/, /t/, /k/) stop consonants, an acoustic difference known to yield differences in N1 amplitude. In Experiment 1 (N = 21), semantic context modulated responses to upcoming targets, with smaller N1 amplitudes for semantic associates. In Experiment 2 (N = 29), semantic context changed how listeners encoded sounds: Ambiguous voice-onset times were encoded similarly to the voicing end point elicited by semantic associates. These results are consistent with an interactive model of spoken-word recognition that includes top-down effects on early perception.
C1 [Getz, Laura M.; Toscano, Joseph C.] Villanova Univ, Dept Psychol & Brain Sci, 800 E Lancaster Ave, Villanova, PA 19085 USA.
RP Getz, LM (corresponding author), Villanova Univ, Dept Psychol & Brain Sci, 800 E Lancaster Ave, Villanova, PA 19085 USA.
EM laura.getz@villanova.edu
FU Mendel Science Experience postdoctoral fellowship from the Villanova
   University College of Liberal Arts and Sciences
FX L. M. Getz was supported by a Mendel Science Experience postdoctoral
   fellowship from the Villanova University College of Liberal Arts and
   Sciences.
CR Boersma P., 2009, PRAAT DOING PHONETIC
   Cairns P., 1995, CONNECTIONIST MODELS, P289
   CLIFTON C, 1991, J MEM LANG, V30, P251, DOI 10.1016/0749-596X(91)90006-6
   CONNINE CM, 1987, J MEM LANG, V26, P527, DOI 10.1016/0749-596X(87)90138-0
   CONNINE CM, 1987, J EXP PSYCHOL HUMAN, V13, P291, DOI 10.1037/0096-1523.13.2.291
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   ELMAN JL, 1988, J MEM LANG, V27, P143, DOI 10.1016/0749-596X(88)90071-X
   FOX RA, 1984, J EXP PSYCHOL HUMAN, V10, P526, DOI 10.1037/0096-1523.10.4.526
   FRAZIER L, 1978, COGNITION, V6, P291, DOI 10.1016/0010-0277(78)90002-1
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Gow DW, 2016, LANG COGN NEUROSCI, V31, P841, DOI 10.1080/23273798.2015.1029498
   Kingston J, 2016, J EXP PSYCHOL HUMAN, V42, P1969, DOI 10.1037/xhp0000269
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   Magnuson JS, 2003, COGNITIVE SCI, V27, P285, DOI 10.1016/S0364-0213(03)00004-1
   Mathot S, 2012, BEHAV RES METHODS, V44, P314, DOI 10.3758/s13428-011-0168-7
   McClelland JL, 2006, TRENDS COGN SCI, V10, P363, DOI 10.1016/j.tics.2006.06.007
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2008, J EXP PSYCHOL HUMAN, V34, P1609, DOI 10.1037/a0011747
   McQueen JM, 2009, J MEM LANG, V61, P1, DOI 10.1016/j.jml.2009.03.002
   McQueen JM, 2003, COGNITIVE SCI, V27, P795, DOI 10.1016/S0364-0213(03)00069-7
   Myers EB, 2008, CEREB CORTEX, V18, P278, DOI 10.1093/cercor/bhm053
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   Olejnik S, 2003, PSYCHOL METHODS, V8, P434, DOI 10.1037/1082-989X.8.4.434
   PICTON TW, 1974, ELECTROEN CLIN NEURO, V36, P191, DOI 10.1016/0013-4694(74)90156-4
   Pitt MA, 1998, J MEM LANG, V39, P347, DOI 10.1006/jmla.1998.2571
   PITT MA, 1995, J EXP PSYCHOL LEARN, V21, P1037, DOI 10.1037/0278-7393.21.4.1037
   PITT MA, 1995, COGNITIVE PSYCHOL, V29, P149, DOI 10.1006/cogp.1995.1014
   R Core Team, 2017, R LANG ENV STAT COMP
   SAMUEL AG, 1981, J EXP PSYCHOL GEN, V110, P474, DOI 10.1037/0096-3445.110.4.474
   Samuel AG, 2003, J MEM LANG, V48, P416, DOI 10.1016/S0749-596X(02)00514-4
   Schouten B, 2003, SPEECH COMMUN, V41, P71, DOI 10.1016/S0167-6393(02)00094-8
   Schroger E, 2015, EUR J NEUROSCI, V41, P641, DOI 10.1111/ejn.12816
   Scott M, 2013, J ACOUST SOC AM, V133, pEL286, DOI 10.1121/1.4794932
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Toscano JC, 2018, BRAIN LANG, V184, P32, DOI 10.1016/j.bandl.2018.06.006
   Toscano JC, 2010, PSYCHOL SCI, V21, P1532, DOI 10.1177/0956797610384142
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   TRUESWELL JC, 1994, J MEM LANG, V33, P285, DOI 10.1006/jmla.1994.1014
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
NR 41
TC 4
Z9 4
U1 2
U2 5
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0956-7976
EI 1467-9280
J9 PSYCHOL SCI
JI Psychol. Sci.
PD JUN
PY 2019
VL 30
IS 6
BP 830
EP 841
DI 10.1177/0956797619841813
PG 12
WC Psychology, Multidisciplinary
SC Psychology
GA IG0OM
UT WOS:000473490000003
PM 31018103
DA 2021-02-24
ER

PT J
AU Lumaca, M
   Haumann, NT
   Brattico, E
   Grube, M
   Vuust, P
AF Lumaca, Massimo
   Haumann, Niels Trusbak
   Brattico, Elvira
   Grube, Manon
   Vuust, Peter
TI Weighting of neural prediction error by rhythmic complexity: A
   predictive coding account using mismatch negativity
SO EUROPEAN JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE EEG; MMN; predictive coding; rhythmic complexity; Shannon entropy
ID EVENT-RELATED POTENTIALS; MASS UNIVARIATE ANALYSIS; SELECTIVE-ATTENTION;
   REPETITION SUPPRESSION; INVOLUNTARY ATTENTION; SOUND; COMPONENT;
   DISTINCTIVENESS; VIOLATIONS; MECHANISM
AB The human brain's ability to extract and encode temporal regularities and to predict the timing of upcoming events is critical for music and speech perception. This work addresses how these mechanisms deal with different levels of temporal complexity, here the number of distinct durations in rhythmic patterns. We use electroencephalography (EEG) to relate the mismatch negativity (MMN), a proxy of neural prediction error, to a measure of information content of rhythmic sequences, the Shannon entropy. Within each of three conditions, participants listened to repeatedly presented standard rhythms of five tones (four inter-onset intervals) and of a given level of entropy: zero (isochronous), medium entropy (two distinct interval durations), or high entropy (four distinct interval durations). Occasionally, the fourth tone was moved forward in time that is it occurred 100 ms (small deviation) or 300 ms early (large deviation). According to the predictive coding framework, high-entropy stimuli are more difficult to model for the brain, resulting in less confident predictions and yielding smaller prediction errors for deviant sounds. Our results support this hypothesis, showing a gradual decrease in MMN amplitude as a function of entropy, but only for small timing deviants. For large timing deviants, in contrast, a modulation of activity in the opposite direction was observed for the earlier N1 component, known to also be sensitive to sudden changes in directed attention. Our results suggest the existence of a fine-grained neural mechanism that weights neural prediction error to the complexity of rhythms and that mostly manifests in the absence of directed attention.
C1 [Lumaca, Massimo; Haumann, Niels Trusbak; Brattico, Elvira; Grube, Manon; Vuust, Peter] Aarhus Univ, Ctr Mus Brain, Dept Clin Med, Aarhus C, Denmark.
   [Lumaca, Massimo; Haumann, Niels Trusbak; Brattico, Elvira; Grube, Manon; Vuust, Peter] Royal Acad Mus, Aarhus C, Denmark.
   [Lumaca, Massimo] SISSA Int Sch Adv Studies, Trieste, Italy.
RP Lumaca, M (corresponding author), Aarhus Univ, Ctr Mus Brain, Dept Clin Med, Aarhus C, Denmark.; Lumaca, M (corresponding author), Royal Acad Mus, Aarhus C, Denmark.
EM massimo.lumaca@clin.au.dk
OI Lumaca, Massimo/0000-0002-3432-3911
FU Danmarks GrundforskningsfondDanmarks Grundforskningsfond [DNRF117]
FX Danmarks Grundforskningsfond, Grant/Award Number: DNRF117
CR Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Bates D. M., 2012, LME4 LINEAR MIXED EF
   Bendixen A, 2012, INT J PSYCHOPHYSIOL, V83, P120, DOI 10.1016/j.ijpsycho.2011.08.003
   BLAIR RC, 1993, PSYCHOPHYSIOLOGY, V30, P518, DOI 10.1111/j.1469-8986.1993.tb02075.x
   Boh B, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021458
   Bouwer FL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01094
   Bouwer FL, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0097467
   Clementz BA, 2002, AUDIOL NEURO-OTOL, V7, P303, DOI 10.1159/000064444
   COHEN JE, 1962, BEHAV SCI, V7, P137
   Costa-Faidella J, 2011, J NEUROSCI, V31, P18590, DOI 10.1523/JNEUROSCI.2599-11.2011
   de Fleurian R, 2017, COGNITIVE SCI, V41, P800, DOI 10.1111/cogs.12347
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dowling W. J., 1999, MUSIC MIND SCI, P166
   Drake C, 2001, ANN NY ACAD SCI, V930, P17, DOI 10.1111/j.1749-6632.2001.tb05722.x
   Elliott MT, 2014, P ROY SOC B-BIOL SCI, V281, DOI 10.1098/rspb.2014.0751
   Escera C, 2000, AUDIOL NEURO-OTOL, V5, P151, DOI 10.1159/000013877
   Ewbank MP, 2011, J NEUROSCI, V31, P5635, DOI 10.1523/JNEUROSCI.5013-10.2011
   Feldman H, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00215
   Fields E. C., 2017, FACTORIAL MASS UNIVA
   FORD JM, 1981, PSYCHOPHYSIOLOGY, V18, P322, DOI 10.1111/j.1469-8986.1981.tb03043.x
   Fraisse P., 1974, PSYCHOLOGIE RYTHME
   Friston KJ, 2002, ANNU REV NEUROSCI, V25, P221, DOI 10.1146/annurev.neuro.25.112701.142846
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   Gomez F, 2007, P INT COMP MUS C COP, P101
   Groppe DM, 2011, PSYCHOPHYSIOLOGY, V48, P1726, DOI 10.1111/j.1469-8986.2011.01272.x
   Groppe DM, 2011, PSYCHOPHYSIOLOGY, V48, P1711, DOI 10.1111/j.1469-8986.2011.01273.x
   Grube M, 2009, CORTEX, V45, P72, DOI 10.1016/j.cortex.2008.01.006
   Harada N, 2005, NEUROSCI LETT, V379, P223, DOI 10.1016/j.neulet.2005.01.012
   Heilbron M, 2018, NEUROSCIENCE, V389, P54, DOI 10.1016/j.neuroscience.2017.07.061
   Hillyard SA, 1998, PHILOS T ROY SOC B, V353, P1257, DOI 10.1098/rstb.1998.0281
   Hsu YF, 2015, J NEUROSCI, V35, P14653, DOI 10.1523/JNEUROSCI.2204-15.2015
   IMADA T, 1993, ELECTROEN CLIN NEURO, V87, P144, DOI 10.1016/0013-4694(93)90120-K
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jones D, 1999, J EXP PSYCHOL LEARN, V25, P464, DOI 10.1037/0278-7393.25.2.464
   Khouri L, 2015, CURR OPIN NEUROBIOL, V35, P142, DOI 10.1016/j.conb.2015.08.003
   Knolle F, 2012, J COGNITIVE NEUROSCI, V24, P698, DOI 10.1162/jocn_a_00167
   Lange K, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00263
   Lange K, 2009, BRAIN COGNITION, V69, P127, DOI 10.1016/j.bandc.2008.06.004
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1
   Lumaca M, 2018, SOC COGN AFFECT NEUR, V13, P877, DOI 10.1093/scan/nsy054
   Lumaca M, 2016, SOC COGN AFFECT NEUR, V11, P1970, DOI 10.1093/scan/nsw112
   Macken WJ, 1999, J EXP PSYCHOL LEARN, V25, P810, DOI 10.1037/0278-7393.25.3.810
   May P, 1999, J COMPUT NEUROSCI, V6, P99, DOI 10.1023/A:1008896417606
   Moberget T, 2008, NEUROPSYCHOLOGIA, V46, P2569, DOI 10.1016/j.neuropsychologia.2008.03.016
   Monahan C. B., 1985, THESIS
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9
   NAATANEN R, 1990, BEHAV BRAIN SCI, V13, P201, DOI 10.1017/S0140525X00078407
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Opitz B, 2002, NEUROIMAGE, V15, P167, DOI 10.1006/nimg.2001.0970
   Paavilainen P, 2013, INT J PSYCHOPHYSIOL, V88, P109, DOI 10.1016/j.ijpsycho.2013.03.015
   R Core Team, 2014, R LANG ENV STAT COMP
   Rao RPN, 2005, NEUROREPORT, V16, P1843, DOI 10.1097/01.wnr.0000183900.92901.fc
   Ravignani A, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01820
   SCHAFER EWP, 1981, ELECTROEN CLIN NEURO, V52, P9, DOI 10.1016/0013-4694(81)90183-8
   Schroger E, 1996, J COGNITIVE NEUROSCI, V8, P527, DOI 10.1162/jocn.1996.8.6.527
   Schwartze M, 2013, NEUROPSYCHOLOGIA, V51, P320, DOI 10.1016/j.neuropsychologia.2012.09.037
   Schwartze M, 2011, BIOL PSYCHOL, V87, P146, DOI 10.1016/j.biopsycho.2011.02.021
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Shmulevich I, 2000, J NEW MUSIC RES, V29, P61, DOI 10.1076/0929-8215(200003)29:01;1-P;FT061
   SNYDER Bob, 2000, MUSIC MEMORY INTRO
   Southwell R, 2018, CORTEX, V109, P92, DOI 10.1016/j.cortex.2018.08.032
   Southwell R, 2017, PHILOS T R SOC B, V372, DOI 10.1098/rstb.2016.0105
   Summerfield C, 2008, NAT NEUROSCI, V11, P1004, DOI 10.1038/nn.2163
   Takegata R, 1999, NEUROSCI LETT, V274, P207, DOI 10.1016/S0304-3940(99)00711-9
   Tavano A, 2014, EUR J NEUROSCI, V39, P308, DOI 10.1111/ejn.12404
   Temperley D., 2007, MUSIC PROBABILITY
   Toussaint Godfried T., 2013, GEOMETRY MUSICAL RHY
   Vuust P, 2018, ANN NY ACAD SCI, V1423, P19, DOI 10.1111/nyas.13622
   Vuust P, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01111
   Vuust P, 2009, CORTEX, V45, P80, DOI 10.1016/j.cortex.2008.05.014
   Wacongne C, 2012, J NEUROSCI, V32, P3665, DOI 10.1523/JNEUROSCI.5003-11.2012
   Winkler I, 2009, TRENDS COGN SCI, V13, P532, DOI 10.1016/j.tics.2009.09.003
   Zhao JY, 2013, PSYCHOL SCI, V24, P667, DOI 10.1177/0956797612460407
NR 75
TC 8
Z9 8
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0953-816X
EI 1460-9568
J9 EUR J NEUROSCI
JI Eur. J. Neurosci.
PD JUN
PY 2019
VL 49
IS 12
BP 1597
EP 1609
DI 10.1111/ejn.14329
PG 13
WC Neurosciences
SC Neurosciences & Neurology
GA IE7OB
UT WOS:000472562500006
PM 30589481
DA 2021-02-24
ER

PT J
AU Pappa, AK
   Hutson, KA
   Scott, WC
   Wilson, JD
   Fox, KE
   Masood, MM
   Giardina, CK
   Pulver, SH
   Grana, GD
   Askew, C
   Fitzpatrick, DC
AF Pappa, Andrew K.
   Hutson, Kendall A.
   Scott, William C.
   Wilson, J. David
   Fox, Kevin E.
   Masood, Maheer M.
   Giardina, Christopher K.
   Pulver, Stephen H.
   Grana, Gilberto D.
   Askew, Charles
   Fitzpatrick, Douglas C.
TI Hair cell and neural contributions to the cochlear summating potential
SO JOURNAL OF NEUROPHYSIOLOGY
LA English
DT Article
DE auditory nerve; cochlear implants; electrocochleography; inner hair
   cells; outer hair cells
ID ROUND WINDOW ELECTROCOCHLEOGRAPHY; POSTSTIMULUS TIME HISTOGRAM;
   SPEECH-PERCEPTION OUTCOMES; POTASSIUM CURRENTS; INTRACOCHLEAR
   ELECTROCOCHLEOGRAPHY; TRANSTYMPANIC ELECTROCOCHLEOGRAPHY; AUDITORY
   NEUROPATHY; UNIT RESPONSE; INNER; IMPLANT
AB The cochlear summating potential (SP) to a tone is a baseline shift that persists for the duration of the burst. It is often considered the most enigmatic of cochlear potentials because its magnitude and polarity vary across frequency and level and its origins are uncertain. In this study, we used pharmacology to isolate sources of the SP originating from the gerbil cochlea. Animals either had the full complement of outer and inner hair cells (OHCs and IHCs) and an intact auditory nerve or had systemic treatment with furosemide and kanamycin (FK) to remove the outer hair cells. Responses to tone bursts were recorded from the round window before and after the neurotoxin kainic acid (KA) was applied. IHC responses were then isolated from the post-KA responses in FK animals, neural responses were isolated from the subtraction of post-KA from pre-KA responses in NH animals, and OHC responses were isolated by subtraction of post-KA responses in FK animals from post-KA responses in normal hearing (NH) animals. All three sources contributed to the SP: OHCs with a negative polarity and IHCs and the auditory nerve with positive polarity. Thus the recorded SP in NH animals is a sum of contributions from different sources, contributing to the variety of magnitudes and polarities seen across frequency and intensity. When this information was applied to observations of the SP recorded from the round window in human cochlear implant subjects, a strong neural contribution to the SP was confirmed in humans as well as gerbils.
   NEW & NOTEWORTHY Of the various potentials produced by the cochlea, the summating potential (SP) is typically described as the most enigmatic. Using combinations of ototoxins and neurotoxins, we show contributions to the SP from the auditory nerve and from inner and outer hair cells, which differ in polarity and vary in size across frequency and level. This complexity of sources helps to explain the enigmatic nature of the SP.
C1 [Pappa, Andrew K.; Hutson, Kendall A.; Scott, William C.; Wilson, J. David; Masood, Maheer M.; Giardina, Christopher K.; Pulver, Stephen H.; Grana, Gilberto D.; Fitzpatrick, Douglas C.] Univ N Carolina, Dept Otolaryngol & Head & Neck Surg, 101 Mason Farm Rd,CB 7546, Chapel Hill, NC 27599 USA.
   [Fox, Kevin E.] Campbell Univ, Sch Osteopath Med, Lillington, NC USA.
   [Askew, Charles] Univ N Carolina, Gene Therapy Ctr, Chapel Hill, NC 27599 USA.
RP Fitzpatrick, DC (corresponding author), Univ N Carolina, Dept Otolaryngol & Head & Neck Surg, 101 Mason Farm Rd,CB 7546, Chapel Hill, NC 27599 USA.
EM dcf@med.unc.edu
OI Askew, Charles/0000-0002-6131-6602
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [F30 DC015168]; Med El
   Corporation; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [F30DC015168, F30DC015168,
   F30DC015168] Funding Source: NIH RePORTER
FX This work was supported by National Institutes of Health Grant F30
   DC015168 to C. K. Giardina) and a research contract from the Med El
   Corporation.
CR Abbas L, 2015, HEARING RES, V325, P12, DOI 10.1016/j.heares.2015.03.002
   Acharya AN, 2016, OTOL NEUROTOL, V37, pE148, DOI 10.1097/MAO.0000000000000950
   Adunka OF, 2010, OTOL NEUROTOL, V31, P1233, DOI 10.1097/MAO.0b013e3181f1ffdf
   ARENBERG IK, 1993, ACTA OTO-LARYNGOL, P58
   Berlin CI, 1998, EAR HEARING, V19, P37, DOI 10.1097/00003446-199802000-00002
   Calloway NH, 2014, OTOL NEUROTOL, V35, P1451, DOI 10.1097/MAO.0000000000000451
   Campbell L, 2015, OTOL NEUROTOL, V36, P399, DOI 10.1097/MAO.0000000000000678
   Chambers AR, 2012, JARO-J ASSOC RES OTO, V13, P209, DOI 10.1007/s10162-011-0306-z
   Chertoff ME, 2004, J ACOUST SOC AM, V116, P3022, DOI 10.1121/1.1791911
   Choudhury B, 2012, OTOL NEUROTOL, V33, P1507, DOI 10.1097/MAO.0b013e31826dbc80
   CODY AR, 1987, J PHYSIOL-LONDON, V383, P551
   Dalbert A, 2015, OTOL NEUROTOL, V36, P1172, DOI 10.1097/MAO.0000000000000768
   DALLOS P, 1985, J NEUROSCI, V5, P1591
   DALLOS P, 1972, ACTA OTO-LARYNGOL, P1
   DALLOS P, 1976, J ACOUST SOC AM, V60, P510, DOI 10.1121/1.381086
   DALLOS P, 1978, J NEUROPHYSIOL, V41, P365
   Dallos P., 1973, AUDITORY PERIPHERY B
   DAUMAN R, 1988, AM J OTOL, V9, P31
   DAVIS H, 1950, P NATL ACAD SCI USA, V36, P580, DOI 10.1073/pnas.36.10.580
   DAVIS H, 1958, AM J PHYSIOL, V195, P251
   DAVIS H, 1965, COLD SPRING HARB SYM, V30, P181, DOI 10.1101/SQB.1965.030.01.020
   DOLAN DF, 1989, J ACOUST SOC AM, V86, P2167, DOI 10.1121/1.398477
   DOLAN DF, 1990, J ACOUST SOC AM, V87, P2621, DOI 10.1121/1.399054
   Durrant JD, 1998, J ACOUST SOC AM, V104, P370, DOI 10.1121/1.423293
   Earl BR, 2010, EAR HEARING, V31, P7, DOI 10.1097/AUD.0b013e3181ba748c
   Eggermont JJ, 2017, FRONT SYST NEUROSCI, V11, DOI 10.3389/fnsys.2017.00002
   Ferraro J A, 1994, J Am Acad Audiol, V5, P24
   Ferraro JA, 2010, J AM ACAD AUDIOL, V21, P145, DOI 10.3766/jaaa.21.3.2
   Fitzpatrick DC, 2014, OTOL NEUROTOL, V35, P64, DOI 10.1097/MAO.0000000000000219
   Fontenot TE, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00592
   Fontenot TE, 2019, EAR HEARING, V40, P577, DOI 10.1097/AUD.0000000000000630
   Forgues M, 2014, J NEUROPHYSIOL, V111, P580, DOI 10.1152/jn.00446.2013
   Formeister EJ, 2015, EAR HEARING, V36, P249, DOI 10.1097/AUD.0000000000000106
   GANS DP, 1983, J ACOUST SOC AM, V74, P1742, DOI 10.1121/1.390257
   Giardina CK, 2019, EAR HEARING, V40, P833, DOI 10.1097/AUD.0000000000000659
   Giardina CK, 2018, EAR HEARING, V39, P1146, DOI 10.1097/AUD.0000000000000571
   Gibson WPR, 2009, ACTA OTO-LARYNGOL, V129, P38, DOI 10.1080/00016480902729843
   GOLDSTEIN MH, 1958, J ACOUST SOC AM, V30, P107, DOI 10.1121/1.1909497
   Guitton MJ, 2004, NEUROREPORT, V15, P1379, DOI 10.1097/01.wnr.0000131672.15566.64
   HARVEY D, 1992, HEARING RES, V61, P137, DOI 10.1016/0378-5955(92)90044-N
   Helmstaedter V, 2018, EAR HEARING, V39, P687, DOI 10.1097/AUD.0000000000000526
   HONRUBIA VH, 1969, J ACOUST SOC AM, V45, P1443, DOI 10.1121/1.1911622
   Hornibrook J, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00301
   Hornibrook Jeremy, 2012, Int J Otolaryngol, V2012, P852714, DOI 10.1155/2012/852714
   HOUSLEY GD, 1992, J PHYSIOL-LONDON, V448, P73, DOI 10.1113/jphysiol.1992.sp019030
   Iseli C, 2010, ACTA OTO-LARYNGOL, V130, P95, DOI 10.3109/00016480902858899
   Johnson SL, 2015, ELIFE, V4, DOI 10.7554/eLife.08177
   Johnson SL, 2011, NEURON, V70, P1143, DOI 10.1016/j.neuron.2011.04.024
   Kaga K, 1996, SCAND AUDIOL, V25, P233, DOI 10.3109/01050399609074960
   Kiang N.Y.S., 1976, ELECTROCOCHLEOGRAPHY, p95e115
   KROS CJ, 1990, J PHYSIOL-LONDON, V421, P263, DOI 10.1113/jphysiol.1990.sp017944
   Kupperman R, 1966, Acta Otolaryngol, V62, P465, DOI 10.3109/00016486609119591
   Liberman MC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162726
   Lichtenhan JT, 2008, J ACOUST SOC AM, V123, P2200, DOI 10.1121/1.2885748
   Lopez-Poveda EA, 2006, JARO-J ASSOC RES OTO, V7, P218, DOI 10.1007/s10162-006-0037-8
   Mammano F, 1996, J PHYSIOL-LONDON, V496, P639, DOI 10.1113/jphysiol.1996.sp021715
   McClellan JH, 2014, OTOL NEUROTOL, V35, pE245, DOI 10.1097/MAO.0000000000000557
   McMahon CM, 2002, HEARING RES, V173, P134, DOI 10.1016/S0378-5955(02)00281-2
   Mikulec AA, 2009, OTOL NEUROTOL, V30, P131, DOI 10.1097/MAO.0b013e318191bff8
   Muller M, 1996, HEARING RES, V94, P148, DOI 10.1016/0378-5955(95)00230-8
   Oesterle EC, 2008, JARO-J ASSOC RES OTO, V9, P65, DOI 10.1007/s10162-007-0106-7
   OHLEMILLER KK, 1992, HEARING RES, V63, P79, DOI 10.1016/0378-5955(92)90076-Y
   PRIJS VF, 1986, HEARING RES, V21, P127, DOI 10.1016/0378-5955(86)90034-1
   Rance G, 1999, EAR HEARING, V20, P238, DOI 10.1097/00003446-199906000-00006
   Riggs WJ, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00416
   RUSSELL IJ, 1983, J PHYSIOL-LONDON, V338, P179, DOI 10.1113/jphysiol.1983.sp014668
   RUSSELL IJ, 1983, NATURE, V301, P334, DOI 10.1038/301334a0
   Russell IJ, 2008, SENSES COMPREHENSIVE, P319
   SANTI PA, 1982, HEARING RES, V7, P261, DOI 10.1016/0378-5955(82)90040-5
   SANTOS-SACCHI J, 1993, BIOPHYS J, V65, P2217, DOI 10.1016/S0006-3495(93)81247-5
   Scott WC, 2016, OTOL NEUROTOL, V37, P1654, DOI 10.1097/MAO.0000000000001224
   Sellick P, 2003, HEARING RES, V176, P42, DOI 10.1016/S0378-5955(02)00716-5
   SEWELL WF, 1984, HEARING RES, V14, P305, DOI 10.1016/0378-5955(84)90057-1
   SNYDER RL, 1984, HEARING RES, V15, P261, DOI 10.1016/0378-5955(84)90033-9
   Starr A, 1996, BRAIN, V119, P741, DOI 10.1093/brain/119.3.741
   SYKA J, 1985, HEARING RES, V20, P267, DOI 10.1016/0378-5955(85)90031-0
   Teagle HFB, 2010, EAR HEARING, V31, P325, DOI 10.1097/AUD.0b013e3181ce693b
   van Emst MG, 1998, HEARING RES, V115, P184, DOI 10.1016/S0378-5955(97)00192-5
   VANDEELEN GW, 1986, ACTA OTO-LARYNGOL, V101, P207, DOI 10.3109/00016488609132829
   VANEMST MG, 1995, HEARING RES, V88, P27, DOI 10.1016/0378-5955(95)00095-L
   VERSNEL H, 1992, HEARING RES, V59, P157, DOI 10.1016/0378-5955(92)90112-Z
   Wang B., 1979, THESIS, P219
   Whitfield IC, 2005, J ACOUST SOC AM, V38, P126
   Zheng XY, 1997, HEARING RES, V113, P76, DOI 10.1016/S0378-5955(97)00127-5
NR 84
TC 11
Z9 11
U1 1
U2 6
PU AMER PHYSIOLOGICAL SOC
PI BETHESDA
PA 9650 ROCKVILLE PIKE, BETHESDA, MD 20814 USA
SN 0022-3077
EI 1522-1598
J9 J NEUROPHYSIOL
JI J. Neurophysiol.
PD JUN
PY 2019
VL 121
IS 6
BP 2163
EP 2180
DI 10.1152/jn.00006.2019
PG 18
WC Neurosciences; Physiology
SC Neurosciences & Neurology; Physiology
GA IE0AY
UT WOS:000472050000017
PM 30943095
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Hoover, EC
   Kinney, BN
   Bell, KL
   Gallun, FJ
   Eddins, DA
AF Hoover, Eric C.
   Kinney, Brianna N.
   Bell, Karen L.
   Gallun, Frederick J.
   Eddins, David A.
TI A Comparison of Behavioral Methods for Indexing the Auditory Processing
   of Temporal Fine Structure Cues
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID COCHLEAR HEARING-LOSS; FREQUENCY-MODULATION; AMPLITUDE-MODULATION;
   SPEECH-PERCEPTION; GAP DETECTION; STRUCTURE INFORMATION; STRUCTURE
   SENSITIVITY; IMPAIRED LISTENERS; CARRIER FREQUENCY; COGNITIVE-FACTORS
AB Purpose: Growing evidence supports the inclusion of perceptual tests that quantify the processing of temporal fine structure (TFS) in clinical hearing assessment. Many tasks have been used to evaluate TFS in the laboratory that vary greatly in the stimuli used and whether the judgments require monaural or binaural comparisons of TFS. The purpose of this study was to compare laboratory measures of TFS for inclusion in a battery of suprathreshold auditory tests. A subset of available TFS tasks were selected on the basis of potential clinical utility and were evaluated using metrics that focus on characteristics important for clinical use.
   Method: TFS measures were implemented in replication of studies that demonstrated clinical utility. Monaural, diotic, and dichotic measures were evaluated in 11 young listeners with normal hearing. Measures included frequency modulation (FM) tasks, harmonic frequency shift detection, interaural phase difference (TFS-low frequency), interaural time difference (ITD), monaural gap duration discrimination, and tone detection in noise with and without a difference in interaural phase (N0S0, N0STT). Data were compared with published results and evaluated with metrics of consistency and efficiency.
   Results: Thresholds obtained were consistent with published data. There was no evidence of predictive relationships among the measures consistent with a homogenous group. The most stable tasks across repeated testing were TFS- low frequency, diotic and dichotic FM, and N-0 S-TT. Monaural and diotic FM had the lowest normalized variance and were the most efficient accounting for differences in total test duration, followed by ITD.
   Conclusions: Despite a long stimulus duration, FM tasks dominated comparisons of consistency and efficiency. Small differences separated the dichotic tasks FM, ITD, and N0STT. Future comparisons following procedural optimization of the tasks will evaluate clinical efficiency in populations with impairment.
C1 [Hoover, Eric C.; Kinney, Brianna N.; Bell, Karen L.; Eddins, David A.] Univ S Florida, Dept Commun Sci & Disorders, Tampa, FL 33620 USA.
   [Gallun, Frederick J.] Portland VA Med Ctr, Natl Ctr Rehabil Auditory Res, Portland, OR USA.
   [Gallun, Frederick J.] Oregon Hlth & Sci Univ, Dept Otolaryngol Head & Neck Surg, Portland, OR 97201 USA.
RP Hoover, EC (corresponding author), Univ S Florida, Dept Commun Sci & Disorders, Tampa, FL 33620 USA.
EM erichoover@usf.edu
RI Gallun, Frederick J./G-3792-2012
OI Gallun, Frederick J./0000-0002-4145-2199
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01 DC015051];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC015051, R01DC015051, R01DC015051,
   R01DC015051] Funding Source: NIH RePORTER
FX This work was supported by National Institutes of Health Grant R01
   DC015051, awarded to Frederick Gallun. The authors thank Michelle Molis
   for her comments on drafts of this article.
CR American National Standards Institute, 2004, S3212004 ANSIASA
   BERNSTEIN LR, 1992, J ACOUST SOC AM, V91, P306, DOI 10.1121/1.402773
   Bolia RS, 2000, J ACOUST SOC AM, V107, P1065, DOI 10.1121/1.428288
   Buss E, 2004, EAR HEARING, V25, P242, DOI 10.1097/01.AUD.0000130796.73809.09
   Cacace AT, 2013, J AM ACAD AUDIOL, V24, P572, DOI 10.3766/jaaa.24.7.6
   Carney LH, 2002, ACTA ACUST UNITED AC, V88, P334
   DEMANY L, 1986, ACUSTICA, V61, P243
   Eddins AC, 2018, EAR HEARING, V39, P594, DOI 10.1097/AUD.0000000000000518
   Eddins DA, 1998, J ACOUST SOC AM, V103, P2578, DOI 10.1121/1.423112
   Ellinger RL, 2017, J ACOUST SOC AM, V141, pEL170, DOI 10.1121/1.4976113
   Ewert SD, 2020, EUR J NEUROSCI, V51, P1265, DOI 10.1111/ejn.13846
   FANTINI DA, 1993, J ACOUST SOC AM, V93, P2106, DOI 10.1121/1.406697
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Gallun F. J., 2015, P M AC, V25, DOI 10.1121/2.0000165
   Gallun Frederick J, 2018, Proc Meet Acoust, V33, DOI 10.1121/2.0000878
   Gallun FJ, 2017, BRAIN INJURY, V31, P1183, DOI 10.1080/02699052.2016.1274781
   Gallun FJ, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00172
   Gallun FJ, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00252
   Ghitza O, 2001, J ACOUST SOC AM, V110, P1628, DOI 10.1121/1.1396325
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052
   GROSE JH, 1989, J ACOUST SOC AM, V86, P1747, DOI 10.1121/1.398606
   Grose JH, 2012, HEARING RES, V294, P49, DOI 10.1016/j.heares.2012.09.007
   HALL JW, 1994, J ACOUST SOC AM, V96, P150, DOI 10.1121/1.410474
   HALL JW, 1985, AUDIOLOGY, V24, P25
   HALL JW, 1995, J ACOUST SOC AM, V98, P847, DOI 10.1121/1.413511
   Hartmann W. M., 2004, SIGNALS SOUND SENSAT
   HELLER LM, 1995, J ACOUST SOC AM, V97, P3775, DOI 10.1121/1.412393
   Hoover E, 2015, J AM ACAD AUDIOL, V26, P540, DOI 10.3766/jaaa.14088
   Hoover EC, 2017, J AM ACAD AUDIOL, V28, P325, DOI 10.3766/jaaa.16051
   Hopkins K, 2008, J ACOUST SOC AM, V123, P1140, DOI 10.1121/1.2824018
   Hopkins K, 2007, J ACOUST SOC AM, V122, P1055, DOI 10.1121/1.2749457
   Hopkins K, 2011, J ACOUST SOC AM, V130, P334, DOI 10.1121/1.3585848
   Hopkins K, 2010, INT J AUDIOL, V49, P940, DOI 10.3109/14992027.2010.512613
   Innes-Brown H, 2016, ADV EXP MED BIOL, V894, P315, DOI 10.1007/978-3-319-25474-6_33
   IRWIN RJ, 1985, CHILD DEV, V56, P614
   JAIN M, 1991, J ACOUST SOC AM, V90, P1918, DOI 10.1121/1.401671
   Jakien KM, 2018, AM J AUDIOL, V27, P529, DOI 10.1044/2018_AJA-17-0069
   Jakien KM, 2017, AM J AUDIOL, V26, P507, DOI 10.1044/2017_AJA-17-0013
   Johannesen PT, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516641055
   Kale S, 2014, JARO-J ASSOC RES OTO, V15, P465, DOI 10.1007/s10162-014-0451-2
   Keith R W, 2000, J Am Acad Audiol, V11, P438
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Lacher-Fougere S, 2005, J ACOUST SOC AM, V118, P2519, DOI 10.1121/1.2032747
   Levi E. C., 1996, ABSTRACTS ASS RES OT, V19, P142
   LICKLIDER JCR, 1951, EXPERIENTIA, V7, P128, DOI 10.1007/BF02156143
   LICKLIDER JCR, 1948, J ACOUST SOC AM, V20, P150, DOI 10.1121/1.1906358
   Lopez-Poveda EA, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517730526
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Lunner T, 2012, EAR HEARING, V33, P377, DOI 10.1097/AUD.0b013e3182387a8c
   Mao JW, 2013, J ACOUST SOC AM, V134, P396, DOI 10.1121/1.4807815
   MCFADDEN D, 1992, J ACOUST SOC AM, V92, P144, DOI 10.1121/1.404279
   Moore B.C., 2012, INTRO PSYCHOL HEARIN
   Moore BCJ, 2002, J ACOUST SOC AM, V111, P327, DOI 10.1121/1.1424871
   Moore BCJ, 2004, EAR HEARING, V25, P98, DOI 10.1097/01.AUD.0000120359.49711.D7
   Moore BCJ, 2014, AUDITORY PROCESSING OF TEMPORAL FINE STRUCTURE: EFFECTS OF AGE AND HEARING LOSS, P1, DOI 10.1142/9064
   Moore BCJ, 1996, J ACOUST SOC AM, V100, P2320, DOI 10.1121/1.417941
   MOORE BCJ, 1994, J ACOUST SOC AM, V96, P741, DOI 10.1121/1.410312
   MOORE BCJ, 1992, J ACOUST SOC AM, V92, P3119, DOI 10.1121/1.404208
   Moore BCJ, 2008, JARO-J ASSOC RES OTO, V9, P399, DOI 10.1007/s10162-008-0143-x
   Moore BCJ, 2009, INT J AUDIOL, V48, P161, DOI 10.1080/14992020802475235
   Narne VK, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0055995
   Neher T, 2012, J ACOUST SOC AM, V131, P2561, DOI 10.1121/1.3689850
   Ozmeral EJ, 2016, J NEUROPHYSIOL, V116, P2720, DOI 10.1152/jn.00560.2016
   PALMER AR, 1986, HEARING RES, V24, P1, DOI 10.1016/0378-5955(86)90002-X
   Papakonstantinou A, 2011, HEARING RES, V280, P30, DOI 10.1016/j.heares.2011.02.005
   Paraouty N, 2016, J ACOUST SOC AM, V140, P121, DOI 10.1121/1.4955078
   Paul BT, 2017, HEARING RES, V344, P170, DOI 10.1016/j.heares.2016.11.010
   Perez E, 2014, FRONT NEUROSCI-SWITZ, V8, DOI [10.3389/FNINS.2014.00007, 10.3389/fnins.2014.00007]
   Qin MK, 2003, J ACOUST SOC AM, V114, P446, DOI 10.1121/1.1579009
   Ridley CL, 2018, EAR HEARING, V39, P829, DOI 10.1097/AUD.0000000000000543
   Roup CM, 2015, AM J AUDIOL, V24, P204, DOI 10.1044/2015_AJA-14-0017
   SABERI K, 1995, NATURE, V374, P537, DOI 10.1038/374537a0
   SCHNEIDER BA, 1994, J ACOUST SOC AM, V95, P980, DOI 10.1121/1.408403
   Schoof T, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00307
   SHAILER MJ, 1987, J ACOUST SOC AM, V81, P1110, DOI 10.1121/1.394631
   Strelcyk O, 2009, J ACOUST SOC AM, V125, P3328, DOI 10.1121/1.3097469
   Summers V, 2013, J AM ACAD AUDIOL, V24, P274, DOI 10.3766/jaaa.24.4.4
   TAYLOR MM, 1967, J ACOUST SOC AM, V41, P782, DOI 10.1121/1.1910407
   vanderHeijden M, 1997, J ACOUST SOC AM, V101, P1019, DOI 10.1121/1.418026
   VANTASELL DJ, 1987, J ACOUST SOC AM, V82, P1152, DOI 10.1121/1.395251
   Wallaert N, 2016, J ACOUST SOC AM, V139, P3088, DOI 10.1121/1.4953019
   Whiteford KL, 2017, JARO-J ASSOC RES OTO, V18, P619, DOI 10.1007/s10162-017-0624-x
   Yeend I, 2017, HEARING RES, V353, P224, DOI 10.1016/j.heares.2017.07.006
   Zeng FG, 2004, J ACOUST SOC AM, V116, P1351, DOI 10.1121/1.1777938
   Zwicker E., 1990, PSYCHOACOUSTICS FACT
NR 85
TC 2
Z9 2
U1 0
U2 4
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD JUN
PY 2019
VL 62
IS 6
BP 2018
EP 2034
DI 10.1044/2019_JSLHR-H-18-0217
PG 17
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA ID9PX
UT WOS:000472020700029
PM 31145649
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Theodore, RM
   Monto, NR
AF Theodore, Rachel M.
   Monto, Nicholas R.
TI Distributional learning for speech reflects cumulative exposure to a
   talker's phonetic distributions
SO PSYCHONOMIC BULLETIN & REVIEW
LA English
DT Article
DE Speech perception; Perceptual learning; Computational models;
   Distributional learning
ID VARIABILITY; PERCEPTION
AB Efficient speech perception requires listeners to maintain an exquisite tension between stability of the language architecture and flexibility to accommodate variation in the input, such as that associated with individual talker differences in speech production. Achieving this tension can be guided by top-down learning mechanisms, wherein lexical information constrains interpretation of speech input, and by bottom-up learning mechanisms, in which distributional information in the speech signal is used to optimize the mapping to speech sound categories. An open question for theories of perceptual learning concerns the nature of the representations that are built for individual talkers: do these representations reflect long-term, global exposure to a talker or rather only short-term, local exposure? Recent research suggests that when lexical knowledge is used to resolve a talker's ambiguous productions, listeners disregard previous experience with a talker and instead rely on only recent experience, a finding that is contrary to predictions of Bayesian belief-updating accounts of perceptual adaptation. Here we use a distributional learning paradigm in which lexical information is not explicitly required to resolve ambiguous input to provide an additional test of global versus local exposure accounts. Listeners completed two blocks of phonetic categorization for stimuli that differed in voice-onset-time, a probabilistic cue to the voicing contrast in English stop consonants. In each block, two distributions were presented, one specifying /g/ and one specifying /k/. Across the two blocks, variance of the distributions was manipulated to be either narrow or wide. The critical manipulation was order of the two blocks; half of the listeners were first exposed to the narrow distributions followed by the wide distributions, with the order reversed for the other half of the listeners. The results showed that for earlier trials, the identification slope was steeper for the narrow-wide group compared to the wide-narrow group, but this difference was attenuated for later trials. The between-group convergence was driven by an asymmetry in learning between the two orders such that only those in the narrow-wide group showed slope movement during exposure, a pattern that was mirrored by computational simulations in which the distributional statistics of the present talker were integrated with prior experience with English. This pattern of results suggests that listeners did not disregard all prior experience with the talker, and instead used cumulative exposure to guide phonetic decisions, which raises the possibility that accommodating a talker's phonetic signature entails maintaining representations that reflect global experience.
C1 [Theodore, Rachel M.; Monto, Nicholas R.] Univ Connecticut, Dept Speech Language & Hearing Sci, 850 Bolton Rd,Unit 1085, Storrs, CT 06269 USA.
   [Theodore, Rachel M.; Monto, Nicholas R.] Univ Connecticut, Connecticut Inst Brain & Cognit Sci, 337 Mansfield Rd,Unit 1872, Storrs, CT 06269 USA.
RP Theodore, RM (corresponding author), Univ Connecticut, Dept Speech Language & Hearing Sci, 850 Bolton Rd,Unit 1085, Storrs, CT 06269 USA.; Theodore, RM (corresponding author), Univ Connecticut, Connecticut Inst Brain & Cognit Sci, 337 Mansfield Rd,Unit 1872, Storrs, CT 06269 USA.
EM rachel.theodore@uconn.edu
FU NIH NIDCD grant [R21DC016141]; Acoustical Society of America Raymond H.
   Stetson Scholarship in Phonetics and Speech Science; NATIONAL INSTITUTE
   ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R21DC016141] Funding Source: NIH RePORTER
FX This work was supported by NIH NIDCD grant R21DC016141 to RMT and by the
   Acoustical Society of America Raymond H. Stetson Scholarship in
   Phonetics and Speech Science to NRM. The views expressed here reflect
   those of the authors and not the NIH or the NIDCD. We express gratitude
   to Stephen Graham for his assistance with data collection and to Emily
   Myers for fruitful discussion and feedback on this manuscript.
CR Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Holt LL, 2005, PSYCHOL SCI, V16, P305, DOI 10.1111/j.0956-7976.2005.01532.x
   Idemaru K, 2011, J EXP PSYCHOL HUMAN, V37, P1939, DOI 10.1037/a0025641
   Kleinschmidt D. F., 2016, P 38 ANN M COGN SCI, DOI [10.1037/a0038695, DOI 10.1037/A0038695]
   Kleinschmidt D. F, 2017, BELIEFUPDATR BELIEF
   Kleinschmidt DF, 2019, LANG COGN NEUROSCI, V34, P43, DOI 10.1080/23273798.2018.1500698
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2008, PSYCHOL SCI, V19, P332, DOI 10.1111/j.1467-9280.2008.02090.x
   McMurray B, 2009, DEVELOPMENTAL SCI, V12, P369, DOI 10.1111/j.1467-7687.2009.00822.x
   Newman RS, 2001, J ACOUST SOC AM, V109, P1181, DOI 10.1121/1.1348009
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   Saltzman D, 2018, PSYCHON B REV, V25, P718, DOI 10.3758/s13423-017-1376-7
   Theodore RM, 2015, J ACOUST SOC AM, V138, P1068, DOI 10.1121/1.4927489
   Theodore RM, 2010, J ACOUST SOC AM, V128, P2090, DOI 10.1121/1.3467771
   Theodore RM, 2009, J ACOUST SOC AM, V125, P3974, DOI 10.1121/1.3106131
NR 18
TC 3
Z9 3
U1 1
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1069-9384
EI 1531-5320
J9 PSYCHON B REV
JI Psychon. Bull. Rev.
PD JUN
PY 2019
VL 26
IS 3
BP 985
EP 992
DI 10.3758/s13423-018-1551-5
PG 8
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA IE0VG
UT WOS:000472104300019
PM 30604404
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Leipold, S
   Brauchli, C
   Greber, M
   Jancke, L
AF Leipold, Simon
   Brauchli, Christian
   Greber, Marielle
   Jancke, Lutz
TI Absolute and relative pitch processing in the human brain: neural and
   behavioral evidence
SO BRAIN STRUCTURE & FUNCTION
LA English
DT Article
DE Absolute pitch; Multivariate pattern analysis; Neural efficiency; Pitch
   processing; fMRI
ID AUDITORY-CORTEX; FUNCTIONAL-ANATOMY; WORKING-MEMORY;
   INDIVIDUAL-DIFFERENCES; MUSICAL PITCH; PERCEPTION; LANGUAGE; FMRI;
   CLASSIFICATION; CONNECTIVITY
AB Pitch is a primary perceptual dimension of sounds and is crucial in music and speech perception. When listening to melodies, most humans encode the relations between pitches into memory using an ability called relative pitch (RP). A small subpopulation, almost exclusively musicians, preferentially encode pitches using absolute pitch (AP): the ability to identify the pitch of a sound without an external reference. In this study, we recruited a large sample of musicians with AP (AP musicians) and without AP (RP musicians). The participants performed a pitch-processing task with a Listening and a Labeling condition during functional magnetic resonance imaging. General linear model analysis revealed that while labeling tones, AP musicians showed lower blood oxygenation level-dependent (BOLD) signal in the inferior frontal gyrus and the presupplementary motor areabrain regions associated with working memory, language functions, and auditory imagery. At the same time, AP musicians labeled tones more accurately suggesting that AP might be an example of neural efficiency. In addition, using multivariate pattern analysis, we found that BOLD signal patterns in the inferior frontal gyrus and the presupplementary motor area differentiated between the groups. These clusters were similar, but not identical compared to the general linear model-based clusters. Therefore, information about AP and RP might be present on different spatial scales. While listening to tones, AP musicians showed increased BOLD signal in the right planum temporale which may reflect the matching of pitch information with internal templates and corroborates the importance of the planum temporale in AP processing. Taken together, AP and RP musicians show diverging frontal activations during Labeling and, more subtly, differences in right auditory activation during Listening. The results of this study do not support the previously reported importance of the dorsolateral prefrontal cortex in associating a pitch with its label.
C1 [Leipold, Simon; Brauchli, Christian; Greber, Marielle; Jancke, Lutz] Univ Zurich, Dept Psychol, Div Neuropsychol, Binzmuhlestr 14,Box 25, CH-8050 Zurich, Switzerland.
   [Jancke, Lutz] Univ Zurich, Dynam Hlth Aging, Univ Res Prior Program URPP, CH-8050 Zurich, Switzerland.
   [Jancke, Lutz] King Abdulaziz Univ, Dept Special Educ, Jeddah 21589, Saudi Arabia.
RP Leipold, S; Jancke, L (corresponding author), Univ Zurich, Dept Psychol, Div Neuropsychol, Binzmuhlestr 14,Box 25, CH-8050 Zurich, Switzerland.; Jancke, L (corresponding author), Univ Zurich, Dynam Hlth Aging, Univ Res Prior Program URPP, CH-8050 Zurich, Switzerland.; Jancke, L (corresponding author), King Abdulaziz Univ, Dept Special Educ, Jeddah 21589, Saudi Arabia.
EM simon.leipold@uzh.ch; lutz.jaencke@uzh.ch
RI Leipold, Simon/G-3397-2019
OI Leipold, Simon/0000-0002-1308-6048; Greber, Marielle/0000-0001-9717-0804
FU Swiss National Science Foundation (SNSF)Swiss National Science
   Foundation (SNSF) [320030_163149]
FX This work was supported by the Swiss National Science Foundation (SNSF),
   Grant no. 320030_163149 to LJ.
CR Albers C, 2018, J EXP SOC PSYCHOL, V74, P187, DOI 10.1016/j.jesp.2017.09.004
   ANNETT M, 1970, BRIT J PSYCHOL, V61, P303, DOI 10.1111/j.2044-8295.1970.tb01248.x
   BACHEM A, 1955, J ACOUST SOC AM, V27, P1180, DOI 10.1121/1.1908155
   Bermudez P, 2005, J NEUROSCI, V25, P7718, DOI 10.1523/JNEUROSCI.1560-05.2005
   Bermudez P, 2009, CEREB CORTEX, V19, P1583, DOI 10.1093/cercor/bhn196
   Binder JR, 2011, TRENDS COGN SCI, V15, P527, DOI 10.1016/j.tics.2011.10.001
   Brauchli C, 2019, NEUROIMAGE, V189, P241, DOI 10.1016/j.neuroimage.2019.01.021
   Buchanan TW, 2000, COGNITIVE BRAIN RES, V9, P227, DOI 10.1016/S0926-6410(99)00060-9
   Burkhard A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-38273-0
   Button KS, 2013, NAT REV NEUROSCI, V14, P365, DOI 10.1038/nrn3475
   Catani M, 2013, BRAIN, V136, P2619, DOI 10.1093/brain/awt163
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Deutsch D, 2013, PSYCHOLOGY OF MUSIC, THIRD EDITION, P141, DOI 10.1016/B978-0-12-381460-9.00005-5
   Dohn A, 2015, CEREB CORTEX, V25, P1379, DOI 10.1093/cercor/bht334
   EDEN GF, 2004, MAGN RESON MED, V41, P13, DOI DOI 10.1002/(SICI)1522-2594(199901)41:1
   Eklund A, 2016, P NATL ACAD SCI USA, V113, P7900, DOI 10.1073/pnas.1602413113
   Etzel JA, 2013, NEUROIMAGE, V78, P261, DOI 10.1016/j.neuroimage.2013.03.041
   Foster NEV, 2010, NEUROIMAGE, V53, P26, DOI 10.1016/j.neuroimage.2010.06.042
   Foster NEV, 2010, CEREB CORTEX, V20, P1350, DOI 10.1093/cercor/bhp199
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   Gaab N, 2003, NEUROIMAGE, V19, P1417, DOI 10.1016/S1053-8119(03)00224-6
   Gordon Edwin, 1989, ADV MEASURES MUSIC A
   Gorgolewski KJ, 2015, FRONT NEUROINFORM, V9, DOI 10.3389/fninf.2015.00008
   Greber M, 2018, ENEURO, V5, DOI 10.1523/ENEURO.0333-18.2018
   Griffiths TD, 2002, TRENDS NEUROSCI, V25, P348, DOI 10.1016/S0166-2236(02)02191-4
   Henson R, 2007, STATISTICAL PARAMETRIC MAPPING: THE ANALYSIS OF FUNCTIONAL BRAIN IMAGES, P193, DOI 10.1016/B978-012372560-8/50015-2
   Ioannidis JPA, 2008, EPIDEMIOLOGY, V19, P640, DOI 10.1097/EDE.0b013e31818131e7
   Itoh K, 2005, CEREB CORTEX, V15, P760, DOI 10.1093/cercor/bhh177
   Jancke L, 2012, J COGNITIVE NEUROSCI, V24, P1447, DOI 10.1162/jocn_a_00227
   Keenan JP, 2001, NEUROIMAGE, V14, P1402, DOI 10.1006/nimg.2001.0925
   Kim SG, 2017, HUM BRAIN MAPP, V38, P3899, DOI 10.1002/hbm.23637
   Kim SG, 2016, HUM BRAIN MAPP, V37, P3486, DOI 10.1002/hbm.23254
   KLEIN M, 1984, SCIENCE, V223, P1306, DOI 10.1126/science.223.4642.1306
   Koelsch S, 2009, HUM BRAIN MAPP, V30, P859, DOI 10.1002/hbm.20550
   Kriegeskorte N, 2006, P NATL ACAD SCI USA, V103, P3863, DOI 10.1073/pnas.0600244103
   Kriegeskorte N, 2007, NEUROIMAGE, V38, P649, DOI 10.1016/j.neuroimage.2007.02.022
   Lacadie CM, 2008, NEUROIMAGE, V42, P717, DOI 10.1016/j.neuroimage.2008.04.240
   Lee YS, 2012, J NEUROSCI, V32, P3942, DOI 10.1523/JNEUROSCI.3814-11.2012
   Lehrl S., 2005, MEHRFACHWAHL WORTSCH
   Lehrl S, 1991, KURZTEST ALLGEMEINE
   Leipold S, 2019, INT J PSYCHOPHYSIOL, V137, P21, DOI 10.1016/j.ijpsycho.2018.12.016
   Levitin DJ, 2005, TRENDS COGN SCI, V9, P26, DOI 10.1016/j.tics.2004.11.007
   LEVITIN DJ, 1994, PERCEPT PSYCHOPHYS, V56, P414, DOI 10.3758/BF03206733
   Lima CF, 2016, TRENDS NEUROSCI, V39, P527, DOI 10.1016/j.tins.2016.06.003
   Loui P, 2012, NEUROIMAGE, V63, P632, DOI 10.1016/j.neuroimage.2012.07.030
   McDermott JH, 2008, CURR OPIN NEUROBIOL, V18, P452, DOI 10.1016/j.conb.2008.09.005
   McKetton L, 2019, J NEUROSCI
   Miyazaki K, 2002, PERCEPT PSYCHOPHYS, V64, P1337, DOI 10.3758/BF03194776
   Mumford JA, 2012, SOC COGN AFFECT NEUR, V7, P738, DOI 10.1093/scan/nss059
   Neubauer AC, 2009, NEUROSCI BIOBEHAV R, V33, P1004, DOI 10.1016/j.neubiorev.2009.04.001
   Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058
   Oechslin MS, 2010, CEREB CORTEX, V20, P447, DOI 10.1093/cercor/bhp113
   Ohnishi T, 2001, CEREB CORTEX, V11, P754, DOI 10.1093/cercor/11.8.754
   PETRIDES M, 1993, P NATL ACAD SCI USA, V90, P873, DOI 10.1073/pnas.90.3.873
   Plack C.J., 2005, PITCH NEURAL CODING
   Plantinga J, 2005, COGNITION, V98, P1, DOI 10.1016/j.cognition.2004.09.008
   Poldrack RA, 2007, SOC COGN AFFECT NEUR, V2, P67, DOI 10.1093/scan/nsm006
   Poldrack RA, 2017, NAT REV NEUROSCI, V18, P115, DOI 10.1038/nrn.2016.167
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   SCHLAUG G, 1995, SCIENCE, V267, P699, DOI 10.1126/science.7839149
   Schulze K, 2018, SPRINGER HBK, P461, DOI 10.1007/978-3-662-55004-5_24
   Schulze K, 2013, HUM BRAIN MAPP, V34, P1579, DOI 10.1002/hbm.22010
   Schulze K, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-106
   Shah NJ, 2000, NEUROIMAGE, V12, P100, DOI 10.1006/nimg.2000.0588
   Stelzer J, 2013, NEUROIMAGE, V65, P69, DOI 10.1016/j.neuroimage.2012.09.063
   Van Hedger SC, 2018, ACTA PSYCHOL, V191, P251, DOI 10.1016/j.actpsy.2018.10.007
   Van Hedger SC, 2015, COGNITION, V140, P95, DOI 10.1016/j.cognition.2015.03.012
   Wengenroth M, 2014, CEREB CORTEX, V24, P1127, DOI 10.1093/cercor/bhs391
   Wilson SJ, 2009, CEREB CORTEX, V19, P724, DOI 10.1093/cercor/bhn121
   Zatorre RJ, 1998, P NATL ACAD SCI USA, V95, P3172, DOI 10.1073/pnas.95.6.3172
   ZATORRE RJ, 1994, J NEUROSCI, V14, P1908, DOI 10.1523/jneurosci.14-04-01908.1994
   Zatorre RJ, 2003, NAT NEUROSCI, V6, P692, DOI 10.1038/nn1085
   ZATORRE RJ, 1989, MEM COGNITION, V17, P582, DOI 10.3758/BF03197081
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
NR 74
TC 8
Z9 8
U1 0
U2 5
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1863-2653
EI 1863-2661
J9 BRAIN STRUCT FUNCT
JI Brain Struct. Funct.
PD JUN
PY 2019
VL 224
IS 5
BP 1723
EP 1738
DI 10.1007/s00429-019-01872-2
PG 16
WC Anatomy & Morphology; Neurosciences
SC Anatomy & Morphology; Neurosciences & Neurology
GA IC8MS
UT WOS:000471236200003
PM 30968240
DA 2021-02-24
ER

PT J
AU Tucker, BV
   Brenner, D
   Danielson, DK
   Kelley, MC
   Nenadic, F
   Sims, M
AF Tucker, Benjamin V.
   Brenner, Daniel
   Danielson, D. Kyle
   Kelley, Matthew C.
   Nenadic, Filip
   Sims, Michelle
TI The Massive Auditory Lexical Decision (MALD) database
SO BEHAVIOR RESEARCH METHODS
LA English
DT Article
DE Megastudy; Auditory lexical decision; Spoken word recognition
ID VISUAL WORD RECOGNITION; STATISTICAL POWER; SPEECH-PERCEPTION;
   EYE-MOVEMENTS; PROJECT; NEIGHBORHOOD; LANGUAGE; NORMS; TIME; INFORMATION
AB The Massive Auditory Lexical Decision (MALD) database is an end-to-end, freely available auditory and production data set for speech and psycholinguistic research, providing time-aligned stimulus recordings for 26,793 words and 9592 pseudowords, and response data for 227,179 auditory lexical decisions from 231 unique monolingual English listeners. In addition to the experimental data, we provide many precompiled listener- and item-level descriptor variables. This data set makes it easy to explore responses, build and test theories, and compare a wide range of models. We present summary statistics and analyses.
C1 [Tucker, Benjamin V.; Brenner, Daniel; Kelley, Matthew C.; Nenadic, Filip; Sims, Michelle] Univ Alberta, Dept Linguist, Edmonton, AB, Canada.
   [Danielson, D. Kyle] Univ Toronto, Toronto, ON, Canada.
RP Tucker, BV (corresponding author), Univ Alberta, Dept Linguist, Edmonton, AB, Canada.
EM bvtucker@ualberta.ca
RI Tucker, Benjamin V./AAQ-5029-2020
OI Tucker, Benjamin V./0000-0001-8965-7890
FU SSHRCSocial Sciences and Humanities Research Council of Canada (SSHRC)
   [435-2014-0678]; University of Alberta Killam Research Grant
FX This research was funded by SSHRC Grant #435-2014-0678 and by a
   University of Alberta Killam Research Grant, both to the first author.
   It also benefited greatly from planning consultation with R. Harald
   Baayen, and organizational, subject-running, coding, and markup
   contributions by Kara Hawthorne, Danielle Fonseca, Catherine Ford, Pearl
   Lorentzen, and Katelynn Pawlenchuk. Thanks also to Emmanuel Keuleers for
   adapting Wuggy for our pseudoword creation. Correspondence may be
   addressed to Benjamin V. Tucker, 4-32 Assiniboia Hall, Department of
   Linguistics, University of Alberta, Edmonton, Alberta, T6G2E7, Canada
   (e-mail: bvtucker@ualberta.ca).
CR Abdi H., 2007, ENCY MEASUREMENT STA, P886
   Akaike H., 1973, INFORM THEORY EXTENS
   Andrews S, 1997, PSYCHON B REV, V4, P439, DOI 10.3758/BF03214334
   Antworth E. L, 1995, USERS GUIDE PC KIMMO
   Antworth E. L, 1994, P N TEX NAT LANG PRO, P24
   Baayen H, 2017, J MEM LANG, V94, P206, DOI 10.1016/j.jml.2016.11.006
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Baayen RH, 1995, CELEX LEXICAL DATABA
   Balota D. A., 2006, HDB PSYCHOLINGUISTIC, P285, DOI [DOI 10.1016/B978-012369374-7/50010-9, 10.1016/B978-012369374-7/50010-9]
   Balota DA, 2007, BEHAV RES METHODS, V39, P445, DOI 10.3758/BF03193014
   Balota DA, 2012, CUR ISS PSYCHOL LANG, P90
   Boersma P., 2011, PRAAT SYSTEM DOING P
   Bosch L. Ten, 2013, INTERSPEECH 2013, P2822
   BRADLEY DC, 1987, COGNITION, V25, P103, DOI 10.1016/0010-0277(87)90006-0
   Brysbaert M, 2016, J EXP PSYCHOL HUMAN, V42, P441, DOI 10.1037/xhp0000159
   Brysbaert M, 2014, BEHAV RES METHODS, V46, P904, DOI 10.3758/s13428-013-0403-5
   Brysbaert M, 2012, BEHAV RES METHODS, V44, P991, DOI 10.3758/s13428-012-0190-4
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   CAMPBELL DT, 1959, PSYCHOL BULL, V56, P81, DOI 10.1037/h0046016
   Chee MWL, 1999, HUM BRAIN MAPP, V7, P15, DOI 10.1002/(SICI)1097-0193(1999)7:1<15::AID-HBM2>3.0.CO;2-6
   COHEN J, 1962, J ABNORM PSYCHOL, V65, P145, DOI 10.1037/h0045186
   Coltheat Max, 1977, ATTENTION PERFORM, VVI, P535, DOI DOI 10.3758/BF03197471
   CUTLER A, 1981, COGNITION, V10, P65, DOI 10.1016/0010-0277(81)90026-3
   Cutler A, 2012, NATIVE LISTENING LAN
   Davies M, 2009, INT J CORPUS LINGUIS, V14, P159, DOI 10.1075/ijcl.14.2.02dav
   Dufau S, 2012, J EXP PSYCHOL LEARN, V38, P1117, DOI 10.1037/a0026948
   Ernestus M, 2015, Q J EXP PSYCHOL, V68, P1469, DOI 10.1080/17470218.2014.984730
   Ferrand L, 2018, BEHAV RES METHODS, V50, P1285, DOI 10.3758/s13428-017-0943-1
   Ferrand L, 2010, BEHAV RES METHODS, V42, P488, DOI 10.3758/BRM.42.2.488
   Forster K. I., 1976, NEW APPROACHES LANGU, P257
   Forster KI, 2000, MEM COGNITION, V28, P1109, DOI 10.3758/BF03211812
   Forster KI., 2003, MASKED PRIMING STATE, P3
   Goh WD, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00976
   Hoffman P, 2013, BEHAV RES METHODS, V45, P718, DOI 10.3758/s13428-012-0278-x
   Ioannidis JPA, 2005, PLOS MED, V2, P696, DOI 10.1371/journal.pmed.0020124
   Jarema G., 2015, BENJAMINS CURRENT TO, V80, P1, DOI [10.1075/bct.80.002int.https://benjamins. com/catalog/bct.80.002int, DOI 10.1075/BCT.80.002INT]
   Jusczyk PW, 2002, EAR HEARING, V23, P2, DOI 10.1097/00003446-200202000-00002
   Keuleers E, 2015, Q J EXP PSYCHOL, V68, P1665, DOI 10.1080/17470218.2015.1022560
   Keuleers E, 2012, BEHAV RES METHODS, V44, P287, DOI 10.3758/s13428-011-0118-4
   Keuleers E, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00174
   Keuleers E, 2010, BEHAV RES METHODS, V42, P627, DOI 10.3758/BRM.42.3.627
   Kuperman V, 2015, Q J EXP PSYCHOL, V68, P1693, DOI 10.1080/17470218.2014.989865
   Levenshtein VI, 1966, SOV PHYS DOKL, V10, P707, DOI DOI 10.1109/TVCG.2012.323
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Mandera P, 2017, J MEM LANG, V92, P57, DOI 10.1016/j.jml.2016.04.001
   Mattys SL, 1997, PSYCHON B REV, V4, P310, DOI 10.3758/BF03210789
   Maxwell SE, 2015, AM PSYCHOL, V70, P487, DOI 10.1037/a0039400
   McRae K, 2005, BEHAV RES METHODS, V37, P547, DOI 10.3758/BF03192726
   Michel JB, 2011, SCIENCE, V331, P176, DOI 10.1126/science.1199644
   New B, 2006, PSYCHON B REV, V13, P45, DOI 10.3758/BF03193811
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Norris D, 2013, TRENDS COGN SCI, V17, P517, DOI 10.1016/j.tics.2013.08.003
   PASTORE RE, 1974, PSYCHOL BULL, V81, P945, DOI 10.1037/h0037357
   Pitt M., 2007, BUCKEYE CORPUS CONVE
   Radach R, 2013, Q J EXP PSYCHOL, V66, P429, DOI 10.1080/17470218.2012.750676
   Rayner K, 2006, SCI STUD READ, V10, P241, DOI 10.1207/s1532799xssr1003_3
   Rayner K, 2009, BIOL PSYCHOL, V80, P4, DOI 10.1016/j.biopsycho.2008.05.002
   Schmidtke D, 2018, LANG COGN NEUROSCI, V33, P923, DOI 10.1080/23273798.2018.1437192
   Schneider W, 2012, E PRIME REFERENCE GU
   Schroter P, 2017, BEHAV RES METHODS, V49, P2183, DOI 10.3758/s13428-016-0851-9
   SEDLMEIER P, 1989, PSYCHOL BULL, V105, P309, DOI 10.1037/0033-2909.105.2.309
   SEIDENBERG MS, 1989, B PSYCHONOMIC SOC, V27, P489
   Shadish W., 1993, NEW DIRECTIONS PROGR, V60, P13, DOI DOI 10.1002/(ISSN)1551-2371
   Shaoul C, 2010, BEHAV RES METHODS, V42, P393, DOI 10.3758/BRM.42.2.393
   Smits R, 2003, J ACOUST SOC AM, V113, P563, DOI 10.1121/1.1525287
   Taft M., 1986, LANG COGNITIVE PROC, V1, P297, DOI [10.1080/01690968608404679, DOI 10.1080/01690968608404679]
   ten Bosch L, 2014, INTERSPEECH, P462
   ten Bosch L, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1576
   ten Bosch L., 2015, 18 INT C PHON SCI IC
   Tse CS, 2017, BEHAV RES METHODS, V49, P1503, DOI 10.3758/s13428-016-0810-5
   Tucker BV, 2016, MENT LEX, V11, P375, DOI 10.1075/ml.11.3.03tuc
   Vitevitch MS, 1998, PSYCHOL SCI, V9, P325, DOI 10.1111/1467-9280.00064
   Warner N., 2014, CELT LING C ED UK, V8
   Warriner AB, 2013, BEHAV RES METHODS, V45, P1191, DOI 10.3758/s13428-012-0314-x
   Weide Robert, 2005, CARNEGIE MELLON PRON
   Yap MJ, 2015, J EXP PSYCHOL LEARN, V41, P597, DOI 10.1037/xlm0000064
   Yap MJ, 2012, J EXP PSYCHOL HUMAN, V38, P53, DOI 10.1037/a0024177
   Yarkoni T, 2008, PSYCHON B REV, V15, P971, DOI 10.3758/PBR.15.5.971
   Yates M, 2004, PSYCHON B REV, V11, P452, DOI 10.3758/BF03196594
   Yuan Jiahong, 2008, P AC
   Ziegler JC, 2003, J MEM LANG, V48, P779, DOI 10.1016/S0749-596X(03)00006-8
NR 81
TC 11
Z9 11
U1 2
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1554-351X
EI 1554-3528
J9 BEHAV RES METHODS
JI Behav. Res. Methods
PD JUN
PY 2019
VL 51
IS 3
BP 1187
EP 1204
DI 10.3758/s13428-018-1056-1
PG 18
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA IA3FH
UT WOS:000469448400013
PM 29916041
OA Bronze
DA 2021-02-24
ER

PT J
AU Leonard, MK
   Cai, RF
   Babiak, MC
   Ren, A
   Chang, EF
AF Leonard, Matthew K.
   Cai, Ruofan
   Babiak, Miranda C.
   Ren, Angela
   Chang, Edward F.
TI The peri-Sylvian cortical network underlying single word repetition
   revealed by electrocortical stimulation and direct neural recordings
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Electrocorticography; Electrocortical stimulation; Verbal repetition;
   Peri-Sylvian cortex; Neurosurgery; Speech perception; Speech production
ID SUPERIOR TEMPORAL GYRUS; CONDUCTION APHASIA; ARCUATE FASCICULUS; MOTOR
   INTEGRATION; SPEECH; CORTEX; ORGANIZATION; DORSAL; LOBE; REGIONS
AB Verbal repetition requires the coordination of auditory, memory, linguistic, and motor systems. To date, the basic dynamics of neural information processing in this deceptively simple behavior are largely unknown. Here, we examined the neural processes underlying verbal repetition using focal interruption (electrocortical stimulation) in 58 patients undergoing awake craniotomies, and neurophysiological recordings (electrocorticography) in 8 patients while they performed a single word repetition task. Electrocortical stimulation revealed that sub-components of the left peri-Sylvian network involved in single word repetition could be differentially interrupted, producing transient perceptual deficits, paraphasic errors, or speech arrest. Electrocorticography revealed the detailed spatio-temporal dynamics of cortical activation, involving a highly-ordered, but overlapping temporal progression of cortical high gamma (75-150 Hz) activity throughout the peri-Sylvian cortex. We observed functionally distinct serial and parallel cortical processing corresponding to successive stages of general auditory processing (posterior superior temporal gyrus), speech-specific auditory processing (middle and posterior superior temporal gyrus), working memory (inferior frontal cortex), and motor articulation (sensorimotor cortex). Together, these methods reveal the dynamics of coordinated activity across peri-Sylvian cortex during verbal repetition. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Leonard, Matthew K.; Cai, Ruofan; Babiak, Miranda C.; Ren, Angela; Chang, Edward F.] Univ Calif San Francisco, Dept Neurol Surg, San Francisco, CA USA.
   [Leonard, Matthew K.; Cai, Ruofan; Babiak, Miranda C.; Ren, Angela; Chang, Edward F.] Univ Calif San Francisco, Ctr Integrat Neurosci, San Francisco, CA 94143 USA.
   [Chang, Edward F.] Univ Calif San Francisco, Dept Physiol, Box 0444, San Francisco, CA USA.
RP Chang, EF (corresponding author), 675 Nelson Rising Lane,Room 511, San Francisco, CA 94158 USA.
EM ChangEd@neurosurg.ucsf.edu
OI Leonard, Matthew/0000-0002-8530-880X
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [F32-DC013486, DP2-OD00862,
   R01-DC012379]; Kavli Institute for Brain and Mind Innovative Research
   grant; Ester A. and Joseph Klingenstein Foundation; NATIONAL INSTITUTE
   ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC012379, R01DC012379, R01DC012379, R01DC012379, R01DC012379,
   R01DC012379, R01DC012379, F32DC013486, R01DC012379, F32DC013486,
   R01DC012379, F32DC013486, R01DC012379] Funding Source: NIH RePORTER;
   OFFICE OF THE DIRECTOR, NATIONAL INSTITUTES OF HEALTHUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USA [DP2OD008627] Funding Source: NIH RePORTER
FX This work was supported by NIH grants F32-DC013486, DP2-OD00862, and
   R01-DC012379; a Kavli Institute for Brain and Mind Innovative Research
   grant; and the Ester A. and Joseph Klingenstein Foundation.
CR Anderson JM, 1999, BRAIN LANG, V70, P1, DOI 10.1006/brln.1999.2135
   Baldo JV, 2008, BRAIN LANG, V105, P134, DOI 10.1016/j.bandl.2007.12.007
   Berger M S, 1994, Clin Neurosurg, V41, P444
   BERGER MS, 1992, STEREOT FUNCT NEUROS, V58, P153, DOI 10.1159/000098989
   Boatman D, 2000, BRAIN, V123, P1634, DOI 10.1093/brain/123.8.1634
   BOATMAN D, 1995, BRAIN LANG, V51, P269, DOI 10.1006/brln.1995.1061
   Bouchard KE, 2013, NATURE, V495, P327, DOI 10.1038/nature11911
   Buchsbaum BR, 2005, NEURON, V48, P687, DOI 10.1016/j.neuron.2005.09.029
   Buchsbaum BR, 2001, COGNITIVE SCI, V25, P663, DOI 10.1207/s15516709cog2505_2
   Buchsbaum BR, 2011, BRAIN LANG, V119, P119, DOI 10.1016/j.bandl.2010.12.001
   Chang EF, 2013, P NATL ACAD SCI USA, V110, P2653, DOI 10.1073/pnas.1216827110
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Cheung C, 2016, ELIFE, V5, DOI 10.7554/eLife.12577
   Cibelli ES, 2015, BRAIN LANG, V147, P66, DOI 10.1016/j.bandl.2015.05.005
   Cogan GB, 2014, NATURE, V507, P94, DOI 10.1038/nature12935
   Corina DP, 2010, BRAIN LANG, V115, P101, DOI 10.1016/j.bandl.2010.04.001
   Crinion JT, 2003, BRAIN, V126, P1193, DOI 10.1093/brain/awg104
   DeWitt I, 2012, P NATL ACAD SCI USA, V109, pE505, DOI 10.1073/pnas.1113427109
   Dick AS, 2012, BRAIN, V135, P3529, DOI 10.1093/brain/aws222
   Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277
   Dronkers NF, 2000, BRAIN LANG, V71, P59, DOI 10.1006/brln.1999.2212
   Duffau H, 2003, J NEUROSURG, V98, P764, DOI 10.3171/jns.2003.98.4.0764
   Edwards E, 2010, NEUROIMAGE, V50, P291, DOI 10.1016/j.neuroimage.2009.12.035
   Eliades SJ, 2008, NATURE, V453, P1102, DOI 10.1038/nature06910
   Flinker A, 2011, BRAIN LANG, V117, P103, DOI 10.1016/j.bandl.2010.09.009
   Geschwind N., 1974, DISCONNEXION SYNDROM
   Goodglass H, 1992, CONDUCTION APHASIA, P39
   Gow DW, 2012, BRAIN LANG, V121, P273, DOI 10.1016/j.bandl.2012.03.005
   Graves WW, 2008, J COGNITIVE NEUROSCI, V20, P1698, DOI 10.1162/jocn.2008.20113
   Greenlee JDW, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0014744
   HAGLUND MM, 1994, NEUROSURGERY, V34, P567, DOI 10.1227/00006123-199404000-00001
   Herman AB, 2013, J NEUROSCI, V33, P5439, DOI 10.1523/JNEUROSCI.1472-12.2013
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Hope TMH, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00246
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213
   Jones OP, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00024
   Kertesz A., 1982, W APHASIA BATTERY TE
   Kummerer D, 2013, BRAIN, V136, P619, DOI 10.1093/brain/aws354
   Leonard M. K., 2015, NEUROBIOLOGY LANGUAG
   Leonard MK, 2015, J NEUROSCI, V35, P7203, DOI 10.1523/JNEUROSCI.4100-14.2015
   Leonard MK, 2014, TRENDS COGN SCI, V18, P472, DOI 10.1016/j.tics.2014.05.001
   Leuthardt EC, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/3/036004
   Majerus S, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00357
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Moritz-Gasser S, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00405
   OJEMANN G, 1989, J NEUROSURG, V71, P316, DOI 10.3171/jns.1989.71.3.0316
   OJEMANN GA, 1978, BRAIN LANG, V5, P331, DOI 10.1016/0093-934X(78)90030-5
   PAULESU E, 1993, NATURE, V362, P342, DOI 10.1038/362342a0
   Pei XM, 2011, NEUROIMAGE, V54, P2960, DOI 10.1016/j.neuroimage.2010.10.029
   Penfield W, 1959, SPEECH BRAIN MECH
   Price CJ, 1996, BRAIN, V119, P919, DOI 10.1093/brain/119.3.919
   Quigg M, 2006, J NEUROSURG, V104, P845, DOI 10.3171/jns.2006.104.5.845
   Quigg M, 1999, J NEUROL NEUROSUR PS, V66, P393, DOI 10.1136/jnnp.66.3.393
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Ray S, 2010, NEURON, V67, P885, DOI 10.1016/j.neuron.2010.08.004
   Rogalsky C, 2015, NEUROPSYCHOLOGIA, V71, P18, DOI 10.1016/j.neuropsychologia.2015.03.012
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Steinschneider M, 2008, CEREB CORTEX, V18, P610, DOI 10.1093/cercor/bhm094
   Steinschneider M, 2011, CEREB CORTEX, V21, P2332, DOI 10.1093/cercor/bhr014
   Tate MC, 2014, BRAIN, V137, P2773, DOI 10.1093/brain/awu168
   Ullman MT, 1997, J COGNITIVE NEUROSCI, V9, P266, DOI 10.1162/jocn.1997.9.2.266
   Vallar G, 1997, NEUROPSYCHOLOGIA, V35, P795, DOI 10.1016/S0028-3932(96)00127-3
   Warburton E, 1996, BRAIN, V119, P159, DOI 10.1093/brain/119.1.159
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
NR 67
TC 14
Z9 14
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD JUN
PY 2019
VL 193
SI SI
BP 58
EP 72
DI 10.1016/j.bandl.2016.06.001
PG 15
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA IA4GS
UT WOS:000469522600007
PM 27450996
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Martin, S
   Milian, JD
   Knight, RT
   Pasley, BN
AF Martin, Stephanie
   Milian, Jose del R.
   Knight, Robert T.
   Pasley, Brian N.
TI The use of intracranial recordings to decode human language: Challenges
   and opportunities
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Intracranial recording; Electrocorticography; Speech decoding;
   Spatio-temporal pattern of brain activity; Time course; Imagined speech;
   Neuroprosthetics
ID UNDERLYING FEEDBACK-CONTROL; BRAIN-COMPUTER INTERFACES;
   ELECTROCORTICOGRAPHIC SIGNALS; LEXICAL ACCESS; SPEECH; MOTOR; FMRI;
   RESPONSES; NEURONS; CORTEX
AB Decoding speech from intracranial recordings serves two main purposes: understanding the neural correlates of speech processing and decoding speech features for targeting speech neuroprosthetic devices. Intracranial recordings have high spatial and temporal resolution, and thus offer a unique opportunity to investigate and decode the electrophysiological dynamics underlying speech processing. In this review article, we describe current approaches to decoding different features of speech perception and production - such as spectrotemporal, phonetic, phonotactic, semantic, and articulatory components - using intracranial recordings. A specific section is devoted to the decoding of imagined speech, and potential applications to speech prosthetic devices. We outline the challenges in decoding human language, as well as the opportunities in scientific and neuroengineering applications. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Martin, Stephanie; Milian, Jose del R.] Ecole Polytech Fed Lausanne, Ctr Neuroprosthet, Defitech Chair Brain Machine Interface, Lausanne, Switzerland.
   [Martin, Stephanie; Knight, Robert T.; Pasley, Brian N.] Univ Calif Berkeley, Helen Wills Neurosci Inst, Berkeley, CA 94720 USA.
   [Knight, Robert T.] Univ Calif Berkeley, Dept Psychol, 3210 Tolman Hall, Berkeley, CA 94720 USA.
RP Pasley, BN (corresponding author), Univ Calif Berkeley, Helen Wills Neurosci Inst, Berkeley, CA 94720 USA.
EM bpasley@berkeley.edu
RI martin, stephanie/AAX-9088-2020; del R. Millan, Jose/F-1696-2011
OI del R. Millan, Jose/0000-0001-5819-1522
FU Zeno-Karl Schindler Foundation; NINDSUnited States Department of Health
   & Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute of Neurological Disorders & Stroke (NINDS) [R3721135,
   K99DC012804]; Nielsen Corporation; NATIONAL INSTITUTE OF NEUROLOGICAL
   DISORDERS AND STROKEUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   of Neurological Disorders & Stroke (NINDS) [R37NS021135, R37NS021135,
   R37NS021135, R37NS021135, R37NS021135, R37NS021135, R37NS021135,
   R37NS021135] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [K99DC012804, K99DC012804] Funding Source: NIH RePORTER
FX This work was supported by the Zeno-Karl Schindler Foundation, NINDS
   Grant R3721135, K99DC012804, and the Nielsen Corporation.
CR Aleman A, 2005, CEREB CORTEX, V15, P221, DOI 10.1093/cercor/bhh124
   Ashmore RC, 2012, IEEE ENG MED BIO, P1740, DOI 10.1109/EMBC.2012.6346285
   Ball T, 2009, NEUROIMAGE, V46, P708, DOI 10.1016/j.neuroimage.2009.02.028
   Berninger VW, 2010, J EDUC PSYCHOL, V102, P635, DOI 10.1037/a0019319
   Blakely T, 2008, IEEE ENG MED BIO, P4964, DOI 10.1109/IEMBS.2008.4650328
   Bouchard KE, 2013, NATURE, V495, P327, DOI 10.1038/nature11911
   Brown S, 2009, BRAIN COGNITION, V70, P31, DOI 10.1016/j.bandc.2008.12.006
   Brumberg JS, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00065
   Brumberg JS, 2010, SPEECH COMMUN, V52, P367, DOI 10.1016/j.specom.2010.01.001
   Buzsaki G, 2012, NAT REV NEUROSCI, V13, P407, DOI 10.1038/nrn3241
   Canolty RT, 2007, FRONT NEUROSCI-SWITZ, V1, P185, DOI 10.3389/neuro.01.1.1.014.2007
   Chakrabarti S, 2013, 6 INT IEEE EMBS C NE
   Chan AM, 2014, CEREB CORTEX, V24, P2679, DOI 10.1093/cercor/bht127
   Chang EF, 2013, P NATL ACAD SCI USA, V110, P2653, DOI 10.1073/pnas.1216827110
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Chi T, 2005, J ACOUST SOC AM, V118, P887, DOI 10.1121/1.1945807
   Chi TS, 1999, J ACOUST SOC AM, V106, P2719, DOI 10.1121/1.428100
   Conway ARA, 2001, PSYCHON B REV, V8, P331, DOI 10.3758/BF03196169
   de Boer E., 1967, J AUDITORY RES, V7
   deCharms RC, 1998, SCIENCE, V280, P1439, DOI 10.1126/science.280.5368.1439
   Demonet JF, 2005, PHYSIOL REV, V85, P49, DOI 10.1152/physrev.00049.2003
   Depireux DA, 2001, J NEUROPHYSIOL, V85, P1220
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Donoghue JP, 2002, NAT NEUROSCI, V5, P1085, DOI 10.1038/nn947
   Dronkers NF, 1996, NATURE, V384, P159, DOI 10.1038/384159a0
   Elliott TM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000302
   Felton EA, 2007, J NEUROSURG, V106, P495, DOI 10.3171/jns.2007.106.3.495
   Flinker A, 2011, BRAIN LANG, V117, P103, DOI 10.1016/j.bandl.2010.09.009
   Flinker A, 2015, P NATL ACAD SCI USA, V112, P2871, DOI 10.1073/pnas.1414491112
   Fritz JB, 2007, CURR OPIN NEUROBIOL, V17, P437, DOI 10.1016/j.conb.2007.07.011
   Ganushchak LY, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00208
   GEORGOPOULOS AP, 1988, J NEUROSCI, V8, P2928
   Geva S, 2011, BRAIN, V134, P3071, DOI 10.1093/brain/awr232
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   GRACCO VL, 1994, J NEUROSCI, V14, P6585
   Groothuis J, 2014, BRAIN STIMUL, V7, P1, DOI 10.1016/j.brs.2013.07.001
   Guenther FH, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0008218
   Halgren E, 1998, ELECTROEN CLIN NEURO, V106, P156, DOI 10.1016/S0013-4694(97)00119-3
   Herff C, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00217
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hochberg LR, 2012, NATURE, V485, P372, DOI 10.1038/nature11076
   Houde JF, 2015, CURR OPIN NEUROBIOL, V33, P174, DOI 10.1016/j.conb.2015.04.006
   Huang J, 2002, HUM BRAIN MAPP, V15, P39, DOI 10.1002/hbm.1060
   Ikeda S, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00125
   Indefrey P, 2004, COGNITION, V92, P101, DOI 10.1016/j.cognition.2002.06.001
   Kaur Parneet, 2012, INT J COMPUTER SCI I, V3
   Kay KN, 2009, NAT NEUROSCI, V12, P245, DOI 10.1038/nn0309-245
   Kellis S, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/5/056007
   King S, 2011, SADHANA-ACAD P ENG S, V36, P837, DOI 10.1007/s12046-011-0048-y
   Kubanek J, 2009, J NEURAL ENG, V6, DOI 10.1088/1741-2560/6/6/066001
   Kubanek J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053398
   Lachaux JP, 2012, PROG NEUROBIOL, V98, P279, DOI 10.1016/j.pneurobio.2012.06.008
   Leonard MK, 2015, J NEUROSCI, V35, P7203, DOI 10.1523/JNEUROSCI.4100-14.2015
   Leuthardt EC, 2004, J NEURAL ENG, V1, P63, DOI 10.1088/1741-2560/1/2/001
   Leuthardt EC, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00099
   Levelt, 1993, SPEAKING INTENTION A
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Manning JR, 2009, J NEUROSCI, V29, P13613, DOI 10.1523/JNEUROSCI.2041-09.2009
   Martin Stephanie, 2014, Front Neuroeng, V7, P14, DOI 10.3389/fneng.2014.00014
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Millan JD, 2009, IEEE ENG MED BIO, P3361, DOI 10.1109/IEMBS.2009.5332828
   Minev IR, 2015, SCIENCE, V347, P159, DOI 10.1126/science.1260318
   Mugler EM, 2014, J NEURAL ENG, V11, DOI 10.1088/1741-2560/11/3/035015
   Naselaris T, 2011, NEUROIMAGE, V56, P400, DOI 10.1016/j.neuroimage.2010.07.073
   Nishimoto S, 2011, CURR BIOL, V21, P1641, DOI 10.1016/j.cub.2011.08.031
   Palmer ED, 2001, NEUROIMAGE, V14, P182, DOI 10.1006/nimg.2001.0779
   Paninski L, 2007, PROG BRAIN RES, V165, P493, DOI 10.1016/S0079-6123(06)65031-0
   Pasley BN, 2013, PROG BRAIN RES, V207, P435, DOI 10.1016/B978-0-444-63327-9.00018-7
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   Pei XM, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/4/046028
   Perrone-Bertolotti M, 2014, BEHAV BRAIN RES, V261, P220, DOI 10.1016/j.bbr.2013.12.034
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Price CJ, 2000, J ANAT, V197, P335, DOI 10.1046/j.1469-7580.2000.19730335.x
   Rapp B, 2015, PSYCHOL SCI, V26, P892, DOI 10.1177/0956797615573520
   Rissman J, 2010, P NATL ACAD SCI USA, V107, P9849, DOI 10.1073/pnas.1001028107
   Robson H, 2013, CORTEX, V49, P1808, DOI 10.1016/j.cortex.2012.11.012
   Rouse AG, 2013, J NEUROSCI, V33, P1326, DOI 10.1523/JNEUROSCI.0271-12.2013
   Schalk G, 2007, J NEURAL ENG, V4, P264, DOI 10.1088/1741-2560/4/3/012
   Shamma S, 2003, J PHONETICS, V31, P495, DOI 10.1016/j.wocn.2003.09.001
   Shuster LI, 2005, BRAIN LANG, V93, P20, DOI 10.1016/j.bandl.2004.07.007
   Singleton Nina Capone, 2014, LANGUAGE DEV FDN PRO
   Slutzky MW, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/2/026004
   Staba RJ, 2002, J NEUROPHYSIOL, V88, P1743, DOI 10.1152/jn.2002.88.4.1743
   Theunissen FE, 2001, NETWORK-COMP NEURAL, V12, P289, DOI 10.1088/0954-898X/12/3/304
   Tomasello Michael, 2008, JEAN NIC LECT 2008
   Trask RL, 1999, LANGUAGE THE BASICS
   Varoquaux G, 2014, GIGASCIENCE, V3, DOI 10.1186/2047-217X-3-28
   Vitevitch MS, 1999, BRAIN LANG, V68, P306, DOI 10.1006/brln.1999.2116
   Vu VQ, 2011, ANN APPL STAT, V5, P1159, DOI 10.1214/11-AOAS476
   Waibel A., 1990, READINGS SPEECH RECO
   Wang W, 2011, IEEE ENG MED BIO, P6294, DOI 10.1109/IEMBS.2011.6091553
   Watkins KE, 2002, BRAIN, V125, P452, DOI 10.1093/brain/awf058
   Winkler I, 2009, TRENDS COGN SCI, V13, P532, DOI 10.1016/j.tics.2009.09.003
   Wodlinger B, 2011, IEEE ENG MED BIO, P3083, DOI 10.1109/IEMBS.2011.6090842
   WOLPAW JR, 1991, ELECTROEN CLIN NEURO, V78, P252, DOI 10.1016/0013-4694(91)90040-B
   Wolpaw JR, 2002, CLIN NEUROPHYSIOL, V113, P767, DOI 10.1016/S1388-2457(02)00057-3
   Wu MCK, 2006, ANNU REV NEUROSCI, V29, P477, DOI 10.1146/annurev.neuro.29.051605.113024
NR 99
TC 5
Z9 5
U1 5
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD JUN
PY 2019
VL 193
SI SI
BP 73
EP 83
DI 10.1016/j.bandl.2016.06.003
PG 11
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA IA4GS
UT WOS:000469522600008
PM 27377299
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Olson, DJ
AF Olson, Daniel J.
TI Feature Acquisition in Second Language Phonetic Development: Evidence
   From Phonetic Training
SO LANGUAGE LEARNING
LA English
DT Article
DE phonetics; second language; acquisition; feature; voice onset time;
   Spanish
ID SELECTIVE ADAPTATION; SPEECH-PERCEPTION; VISUAL FEEDBACK; SEGMENTAL
   PRODUCTION; FOREIGN-LANGUAGE; CROSS-LANGUAGE; PRONUNCIATION; ENGLISH;
   RECALIBRATION; CONTRAST
AB This study employed a targeted phonetic instruction to explore the mechanisms that underpin second language (L2) phonetic acquisition. Broadly, two general approaches to phonetic acquisition have been previously proposed. A segmental approach suggests that learners acquire a series of individual, discrete phonemes (e.g., Flege, 1995), while a featural approach posits that L2 phonetic development occurs at the subsegmental level of the feature, which may be shared across multiple phonemes (e.g., de Jong, Hao, & Park, 2009). This study extended this line of research, using a visual feedback paradigm to train English speakers on one of the three voiceless stop consonants in Spanish. Analysis focused on the change in voice onset time across three testing sessions (pretest, posttest, delayed posttest). Results demonstrated a significant change in voice onset time for trained and nontrained phonemes, suggesting that featural changes generalize to related phonemes. Theoretical and pedagogical implications are discussed.
C1 [Olson, Daniel J.] Purdue Univ, W Lafayette, IN 47906 USA.
RP Olson, DJ (corresponding author), Purdue Univ, Sch Languages & Cultures, 640 Oval Dr, W Lafayette, IN 47906 USA.
EM danielolson@purdue.edu
OI Olson, Daniel/0000-0002-7113-6699
CR Abramson A. S., 1985, PHONETIC LINGUISTICS, P25
   Amengual M, 2012, BILING-LANG COGN, V15, P517, DOI 10.1017/S1366728911000460
   Anderson-Hsieh J., 1992, SYSTEM, V20, P51, DOI DOI 10.1016/0346-251X(92)90007-P
   Arteaga DL, 2000, MOD LANG J, V84, P339, DOI 10.1111/0026-7902.00073
   Auer ET, 2000, MEM COGNITION, V28, P789, DOI 10.3758/BF03198414
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D., 2014, R PACKAGE VERSION LME4 LINEAR MIXED EF LME4 LINEAR MIXED EF, DOI DOI 10.18637/JSS.V067.I01
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2018, PRAAT DOING PHONETIC
   Breitkreutz J. A., 2001, TESL CANADA J, V19, P51, DOI DOI 10.18806/TESL.V19I1.919
   Brown C., 2000, 2 LANGUAGE ACQUISITI, V1, P4
   Brown C. A., 1997, THESIS
   Cho T, 1999, J PHONETICS, V27, P207, DOI 10.1006/jpho.1999.0094
   Chun D., 1998, LANGUAGE LEARNING TE, V2, P61
   Clements George N., 1985, PHONOLOGY YB, V2, P225, DOI DOI 10.1017/S0952675700000440
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Darcy I, 2012, P 3 PRON 2 LANG LEAR, P93
   de Jong K, 2009, J PHONETICS, V37, P357, DOI 10.1016/j.wocn.2009.06.001
   de Jong KJ, 2009, LANG LEARN, V59, P1, DOI 10.1111/j.1467-9922.2009.00499.x
   DEBOT K, 1983, LANG SPEECH, V26, P331, DOI 10.1177/002383098302600402
   Derwing T., 2015, PRONUNCIATION FUNDAM
   Derwing TM, 2012, TESL CAN J, V30, P22
   desBot K., 1980, INT J PSYCHOLINGUIST, V7, P81
   DIEHL RL, 1985, J EXP PSYCHOL HUMAN, V11, P209
   DIEHL RL, 1978, J EXP PSYCHOL HUMAN, V4, P599, DOI 10.1037/0096-1523.4.4.599
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 1998, NEW PERSPECTIVES CRI, P101
   Flege J. E., 2001, STUDIES 2 LANGUAGE A, V23, P527
   Flege James E., 1991, CROSSCURRENTS 2 LANG, V2, P249, DOI DOI 10.1075/LALD.2.15FLE
   FLEGE JE, 1992, J ACOUST SOC AM, V92, P128, DOI 10.1121/1.404278
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   FLEGE JE, 1988, J ACOUST SOC AM, V84, P70, DOI 10.1121/1.396876
   FLEGE JE, 1987, SPEECH COMMUN, V6, P185, DOI 10.1016/0167-6393(87)90025-2
   Foote JA, 2011, TESL CAN J, V29, P1
   Foote JA, 2016, LANG LEARN J, V44, P181, DOI 10.1080/09571736.2013.784345
   Goldinger SD, 2003, J PHONETICS, V31, P305, DOI 10.1016/S0095-4470(03)00030-5
   GOLDINGER SD, 1989, J MEM LANG, V28, P501, DOI 10.1016/0749-596X(89)90009-0
   Green P, 2016, METHODS ECOL EVOL, V7, P493, DOI 10.1111/2041-210X.12504
   Hammond RM, 2001, SOUNDS SPANISH ANAL
   Hancin-Bhatt B. J., 1994, SECOND LANG RES, V10, P241, DOI DOI 10.1177/026765839401000304
   Hardison DM, 2004, LANG LEARN TECHNOL, V8, P34
   Hualde Jose Ignacio, 2005, SOUNDS SPANISH
   Jurafsky D., 2000, FREQUENCY EMERGENCE, P229, DOI DOI 10.1075/TSL.45.13JUR
   Kartushina N, 2015, J ACOUST SOC AM, V138, P817, DOI 10.1121/1.4926561
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   Kuhl P. K., 1993, INT J PSYCHOLING, V9, P33
   Kuhl P. K., 1995, SPEECH PERCEPTION LI, P121
   Kuhl P. K., 1992, P INT C SPOK LANG PR, P3
   KUHL PK, 1993, NATO ADV SCI INST SE, V69, P259
   KUHL PK, 1978, J ACOUST SOC AM, V63, P905, DOI 10.1121/1.381770
   Lee J, 2015, APPL LINGUIST, V36, P345, DOI 10.1093/applin/amu040
   Levis JM, 2005, TESOL QUART, V39, P369, DOI 10.2307/3588485
   LISKER L, 1967, LANG SPEECH, V10, P1, DOI 10.1177/002383096701000101
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Lord G, 2005, HISPANIA-J DEV INTER, V88, P557, DOI 10.2307/20063159
   Mitterer H, 2018, J MEM LANG, V98, P77, DOI 10.1016/j.jml.2017.09.005
   Morgan T., 2010, SONIDOS EN CONTEXTO
   Motohashi-Saigo M, 2009, LANG LEARN TECHNOL, V13, P29
   Munro M. J., 2016, P ISAPH 2016 INT S A, P26, DOI [10.21437/ISAPh.2016, DOI 10.21437/ISAPH.2016]
   MUNRO MJ, 1995, LANG LEARN, V45, P73, DOI 10.1111/j.1467-1770.1995.tb00963.x
   Munro MJ, 2015, IRAL-INT REV APPL LI, V53, P39, DOI 10.1515/iral-2015-0002
   Nielsen K, 2014, J SPEECH LANG HEAR R, V57, P2065, DOI 10.1044/2014_JSLHR-S-13-0093
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Norris JM, 2000, LANG LEARN, V50, P417, DOI 10.1111/0023-8333.00136
   Nusbaum H. C., 1984, RES SPEECH PERCEPTIO, V10, P357
   Offerman HM, 2016, SYSTEM, V59, P45, DOI 10.1016/j.system.2016.03.003
   Okuno T., 2013, THESIS
   Olson DJ, 2014, LANG LEARN TECHNOL, V18, P173
   Olson DJ, 2014, HISPANIA-J DEV INTER, V97, P47, DOI 10.1353/hpn.2014.0030
   Pickering L., 2004, SYSTEM, V32, P505, DOI DOI 10.1016/J.SYSTEM.2004.09.009
   Plonsky L, 2014, LANG LEARN, V64, P878, DOI 10.1111/lang.12079
   R Core Team, 2013, R LANG ENV STAT COMP
   Reinisch E, 2014, J PHONETICS, V45, P91, DOI 10.1016/j.wocn.2014.04.002
   REMEZ RE, 1979, COGNITIVE PSYCHOL, V11, P38, DOI 10.1016/0010-0285(79)90003-3
   Sagey E. C., 1986, THESIS
   Saito K., 2007, LINGUISTICS J, V3, P16
   SAMUEL AG, 1986, COGNITIVE PSYCHOL, V18, P452, DOI 10.1016/0010-0285(86)90007-1
   THOMPSON I, 1991, LANG LEARN, V41, P177, DOI 10.1111/j.1467-1770.1991.tb00683.x
   Thomson RI, 2015, APPL LINGUIST, V36, P326, DOI 10.1093/applin/amu076
   Vroomen J, 2004, SPEECH COMMUN, V44, P55, DOI 10.1016/j.specom.2004.03.009
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
NR 82
TC 1
Z9 1
U1 2
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0023-8333
EI 1467-9922
J9 LANG LEARN
JI Lang. Learn.
PD JUN
PY 2019
VL 69
IS 2
BP 366
EP 404
DI 10.1111/lang.12336
PG 39
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA HX5OD
UT WOS:000467450400004
DA 2021-02-24
ER

PT J
AU Kelly, NE
AF Kelly, Niamh E.
TI The perception of dental and alveolar stops among speakers of Irish
   English and American English
SO ENGLISH LANGUAGE & LINGUISTICS
LA English
DT Article
DE perception; stops; plosives; dental; alveolar; dialect variation
ID LANGUAGE SPEECH-PERCEPTION; CROSS-LANGUAGE; VOWEL DURATION; NATIVE
   SPEAKERS; EXPERIENCE; CONSONANTS; INFANTS; SPANISH; ADULTS
AB Most speakers of Irish English use a dental stop for words containing , a sound that is generally pronounced as [theta] and [o], in other varieties of English (Wells 1982; hurdail 1997). Alveolar stops [t,d] and dental stops [t] are articulatorily and acoustically similar, and thus it is unusual for a language to use them contrastively (e.g. Ladefoged 2001). Despite this, Irish English contrasts them and speakers of this dialect have no trouble distinguishing them. This raises the question as to whether speakers of a dialect which does not use this contrast can distinguish them. To investigate this, speakers of Irish English and American English participated in an identification task involving words produced by an Irish English speaker. American English speakers had a high accuracy but did significantly worse than Irish English speakers, and both groups did significantly worse when the contrast was in final position than when it was in initial position. A small-scale production experiment examined words with this contrast and the vowel /a/, with the finding that for speakers of both dialects, the vowel is longer in words ending in than . The findings are discussed in the context of linguistic experience, and the effect of surrounding consonants on vowel duration.
C1 [Kelly, Niamh E.] Amer Univ Beirut, Beirut, Lebanon.
RP Kelly, NE (corresponding author), Amer Univ Beirut, Dept English, 333 Fisk Hall, Beirut, Lebanon.
EM nk114@aub.edu.lb
CR Aschmann Rick, 2015, N AM ENGLISH DIALECT
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best C.T., 1994, DEV SPEECH PERCEPTIO, P167
   BEST CT, 1992, J PHONETICS, V20, P305, DOI 10.1016/S0095-4470(19)30637-0
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2011, PRAAT DOING PHONETIC
   Cho T, 1999, J PHONETICS, V27, P207, DOI 10.1006/jpho.1999.0094
   Dart S, 1991, UCLA WORKING PAPERS, V79
   Dart SN, 1998, J PHONETICS, V26, P71, DOI 10.1006/jpho.1997.0060
   DiCanio CT, 2012, J PHONETICS, V40, P672, DOI 10.1016/j.wocn.2012.05.003
   Donaldson T., 1980, NGIYAMBAA LANGUAGE W
   Dubois Sylvie, 1998, LANG VAR CHANGE, V10, P246, DOI [DOI 10.1017/S0954394500001320, 10.1017/S0954394500001320]
   Dupoux E, 1997, J MEM LANG, V36, P406, DOI 10.1006/jmla.1996.2500
   Edwards WF, 2008, VARIETIES OF ENGLISH 2: THE AMERICAS AND THE CARIBBEAN, P181
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J.E., 1984, FOLIA LINGUIST, V18, P117
   Francis AL, 2008, J PHONETICS, V36, P268, DOI 10.1016/j.wocn.2007.06.005
   Frazier Melissa, 2009, THESIS
   Gordon MJ, 2008, VARIETIES OF ENGLISH 2: THE AMERICAS AND THE CARIBBEAN, P67
   Haowen Jiang, 2010, MALAYALAM GRAM UNPUB
   Hayward K. M., 1989, AFRICAN LANGUAGES CU, V2, P51, DOI [10.1080/09544168908717695, DOI 10.1080/09544168908717695]
   HAZAN V, 1991, PERCEPT PSYCHOPHYS, V49, P187, DOI 10.3758/BF03205038
   Heffner RMS, 1940, LANGUAGE, V16, P33, DOI 10.2307/409092
   HICKEY R, 1984, J LINGUIST, V20, P233, DOI 10.1017/S0022226700013876
   Hickey R, 2008, VARIETIES OF ENGLISH 1: THE BRITISH ISLES, P71
   HOUSE AS, 1953, J ACOUST SOC AM, V25, P105, DOI 10.1121/1.1906982
   HOUSE AS, 1961, J ACOUST SOC AM, V33, P1174, DOI 10.1121/1.1908941
   Hughes E. J., 1971, PAPERS LANGUAGES AUS, V38, P72
   hurdail R., 1997, THE CELTIC ENGLISHES, P180
   Huttar George L., 1981, LINGUISTICS CONTINEN
   JONGMAN A, 1985, J PHONETICS, V13, P235, DOI 10.1016/S0095-4470(19)30738-7
   Kallen J.L., 2005, DIALECT CHANGE CONVE, P51, DOI DOI 10.1017/CBO9780511486623.004
   Kallen J. L., 2013, IRISH ENGLISH, V2
   Kondaurova MV, 2008, J ACOUST SOC AM, V124, P3959, DOI 10.1121/1.2999341
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Ladefoged P., 2001, VOWELS CONSONANTS IN
   Ladefoged Peter, 1996, SOUNDS WORLDS LANGUA
   Lavoie L. M., 2002, ZAS PAPERS LINGUISTI, V28, P39
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Lisker L., 1970, P 6 INT C PHON SCI P, P563
   Maddieson Ian, 1997, HDB PHONETIC SCI, P619
   MANN VA, 1986, COGNITION, V24, P169, DOI 10.1016/S0010-0277(86)80001-4
   McAllister R, 2002, J PHONETICS, V30, P229, DOI 10.1006/jpho.2002.0174
   McGuire G., 2012, LAB PHONOLOGY, V3, P1, DOI [10.1515/lp-2012-0014, DOI 10.1515/LP-2012-0014]
   Morphy F., 1983, HDB AUSTR LANGUAGES, V3, DOI [10.1075/z.hal3, DOI 10.1075/Z.HAL3]
   Nagy N, 2008, VARIETIES OF ENGLISH 2: THE AMERICAS AND THE CARIBBEAN, P52
   Pandeli Helen, 1997, J INT PHON ASSOC, V27, P65, DOI DOI 10.1017/S0025100300005430
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   PETERSON GE, 1960, J ACOUST SOC AM, V32, P693, DOI 10.1121/1.1908183
   POLKA L, 1991, J ACOUST SOC AM, V89, P2961, DOI 10.1121/1.400734
   Polka Linda, 1989, THESIS
   Pruitt JS, 2006, J ACOUST SOC AM, V119, P1684, DOI 10.1121/1.2161427
   R Core Team, 2017, R LANGUAGE ENV STAT
   RAPHAEL LJ, 1972, J ACOUST SOC AM, V51, P1296, DOI 10.1121/1.1912974
   Remijsen B, 2009, J INT PHON ASSOC, V39, P113, DOI 10.1017/S0025100308003605
   Sokolovi-Perovi M., 2009, NEWCASTLE WORKING PA, V15, P126
   Strange W., 1995, SPEECH PERCEPTION LI, P3
   Strange Winifred, 1992, SPEECH PERCEPTION PR, P197
   Thomas ER, 2008, VARIETIES OF ENGLISH 2: THE AMERICAS AND THE CARIBBEAN, P87
   Van Dommelen W, 2009, RECENT RES 2 LANGUAG, P308
   Wells J. C., 1982, ACCENTS OF ENGLISH, V2
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Xu YS, 2006, J ACOUST SOC AM, V120, P1063, DOI 10.1121/1.2213572
NR 64
TC 0
Z9 0
U1 1
U2 5
PU CAMBRIDGE UNIV PRESS
PI CAMBRIDGE
PA EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN 1360-6743
EI 1469-4379
J9 ENGL LANG LINGUIST
JI Engl. Lang. Linguist.
PD JUN
PY 2019
VL 23
IS 2
BP 277
EP 302
DI 10.1017/S1360674317000405
PG 26
WC Linguistics; Language & Linguistics
SC Linguistics
GA HU4SQ
UT WOS:000465267300003
DA 2021-02-24
ER

PT J
AU Uhrig, S
   Mittag, G
   Moller, S
   Voigt-Antons, JN
AF Uhrig, Stefan
   Mittag, Gabriel
   Moeller, Sebastian
   Voigt-Antons, Jan-Niklas
TI Neural correlates of speech quality dimensions analyzed using
   electroencephalography (EEG)
SO JOURNAL OF NEURAL ENGINEERING
LA English
DT Article
DE electroencephalography; P300; event-related potential; oddball paradigm;
   speech quality; quality reference; speech perception
ID STIMULUS-INTENSITY; P300; P3A; PROBABILITY; ATTENTION; NOVELTY;
   DETERMINANTS; PERCEPTION; AMPLITUDE
AB Objective. By means of subjective psychophysical methods, quality of transmitted speech has been decomposed into three perceptual dimensions named 'discontinuity' (F), 'noisiness' (N) and 'coloration' (C). Previous studies using electroencephalography (EEG) already reported effects of perceived intensity of single quality dimensions on electrical brain activity. However, it has not been investigated so far, whether the dimensions themselves are dissociable on a neurophysiological level of analysis. Approach. Pursuing this goal in the present study, a high-quality (HQ) recording of a spoken word was degraded on each dimension at a time, resulting in three quality-impaired stimuli (F, N, C) which were on average described as being equal in perceived degradation intensity. Participants performed a three-stimulus oddball task, involving the serial presentation of different stimulus types: (1) HQ or degraded 'standard' stimuli to establish sensory/perceptual quality references. (2) Degraded 'oddball' stimuli to cause random, infrequent deviations from those references. EEG was employed to examine the neuro-electrical correlates of speech quality perception. Main results. Emphasis was placed on modulations in temporal and morphological characteristics of the P300 component of the event-related brain potential (ERP), whose subcomponents P3a and P3b are commonly linked to attentional orienting and task relevance categorization, respectively. Electrophysiological data analysis (N = 28) revealed significant modulations of P300 amplitude and latency by the perceptual dimensions underlying both quality references and oddball stimuli. Significance. The present study exemplifies the utility of physiological methods like EEG for dissociating speech degradations not only based on perceived intensity level, but also their distinctive quality dimension.
C1 [Uhrig, Stefan; Mittag, Gabriel; Moeller, Sebastian; Voigt-Antons, Jan-Niklas] Tech Univ Berlin, Qual & Usabil Lab, D-10587 Berlin, Germany.
   [Moeller, Sebastian; Voigt-Antons, Jan-Niklas] German Res Ctr Artificial Intelligence DFKI, D-10559 Berlin, Germany.
RP Uhrig, S (corresponding author), Tech Univ Berlin, Qual & Usabil Lab, D-10587 Berlin, Germany.
EM stefan.uhrig@qu.tu-berlin.de
OI Uhrig, Stefan/0000-0002-9221-4617; Voigt-Antons,
   Jan-Niklas/0000-0002-2786-9262
FU Technische Universitat Berlin, Germany; Norwegian University of Science
   and Technology in Trondheim, Norway
FX This work was supported by the strategic partnership program between
   Technische Universitat Berlin, Germany, and the Norwegian University of
   Science and Technology in Trondheim, Norway.
CR Acqualagna L, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/2/026012
   [Anonymous], 2011, OBJ MEAS ACT SPEECH
   [Anonymous], 1996, METHODS SUBJECTIVE D
   [Anonymous], 2010, SOFTWARE TOOLS SPEEC
   [Anonymous], 1996, MODULATED NOISE REFE
   Antons J. N., 2010, P 129 CONV AUD ENG S, V129, P1
   Antons J-N, 2015, T LABS SERIES TELECO, DOI [10.1007/978-3-319-15521-0, DOI 10.1007/978-3-319-15521-0]
   Antons JN, 2014, T-LAB SER TELECOMMUN, P109, DOI 10.1007/978-3-319-02681-7_8
   Antons JN, 2013, INT CONF ACOUST SPEE, P3672, DOI 10.1109/ICASSP.2013.6638343
   Antons JN, 2012, IEEE J-STSP, V6, P721, DOI 10.1109/JSTSP.2012.2191936
   Arndt S, 2016, T LABS SERIES TELECO, DOI [10.1007/978-981-10-0248-9, DOI 10.1007/978-981-10-0248-9]
   Arndt S, 2014, IEEE J-STSP, V8, P366, DOI 10.1109/JSTSP.2014.2313026
   Avarvand FS, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa6d8b
   Blauert J, 1997, ACUSTICA, V83, P747
   Blauert J, 2010, P 3 INT WORKSH PERC, P18
   Blauert J, 2007, P 19 INT C AC ICA 20, P1205
   Boksem MAS, 2005, COGNITIVE BRAIN RES, V25, P107, DOI 10.1016/j.cogbrainres.2005.04.011
   Bosse S, 2018, IEEE T CIRC SYST VID, V28, P1694, DOI 10.1109/TCSVT.2017.2694807
   Comerchero MD, 1999, CLIN NEUROPHYSIOL, V110, P24, DOI 10.1016/S0168-5597(98)00033-1
   Comerchero MD, 1998, COGNITIVE BRAIN RES, V7, P41, DOI 10.1016/S0926-6410(98)00009-3
   COURCHESNE E, 1975, ELECTROEN CLIN NEURO, V39, P131, DOI 10.1016/0013-4694(75)90003-6
   Duncan CC, 2009, CLIN NEUROPHYSIOL, V120, P1883, DOI 10.1016/j.clinph.2009.07.045
   Engelke U, 2017, IEEE J-STSP, V11, P6, DOI 10.1109/JSTSP.2016.2609843
   Fabiani M, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P85, DOI 10.1017/CBO9780511546396.004
   Friedman D, 2001, NEUROSCI BIOBEHAV R, V25, P355, DOI 10.1016/S0149-7634(01)00019-7
   Gaeta H, 2003, PSYCHOPHYSIOLOGY, V40, P198, DOI 10.1111/1469-8986.00022
   Jekosch U, 2005, SIG COM TEC
   JOHNSON R, 1993, PSYCHOPHYSIOLOGY, V30, P90
   Katayama J, 1996, EVOKED POTENTIAL, V100, P555, DOI 10.1016/S0168-5597(96)95171-0
   Katayama J, 1998, PSYCHOPHYSIOLOGY, V35, P23, DOI 10.1017/S0048577298961479
   Katayama J, 1999, CLIN NEUROPHYSIOL, V110, P463, DOI 10.1016/S1388-2457(98)00035-2
   Kok A, 2001, PSYCHOPHYSIOLOGY, V38, P557, DOI 10.1017/S0048577201990559
   Lindemann L., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3109, DOI 10.1109/ICIP.2011.6116324
   Lindin M, 2005, BIOL PSYCHOL, V69, P375, DOI 10.1016/j.biopsycho.2004.08.001
   MCDERMOTT BJ, 1969, J ACOUST SOC AM, V45, P774, DOI 10.1121/1.1911465
   Moller S., 2014, PIK PRAXIS INFORMATI, V37, P255
   Naatanen R, 2011, PSYCHOPHYSIOLOGY, V48, P4, DOI 10.1111/j.1469-8986.2010.01114.x
   Nuwer MR, 1998, ELECTROEN CLIN NEURO, V106, P259, DOI 10.1016/S0013-4694(97)00106-5
   Olejnik S, 2003, PSYCHOL METHODS, V8, P434, DOI 10.1037/1082-989X.8.4.434
   PAPANICOLAOU AC, 1985, PSYCHOPHYSIOLOGY, V22, P326, DOI 10.1111/j.1469-8986.1985.tb01608.x
   Pizzagalli DA, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P56, DOI 10.1017/CBO9780511546396.003
   POLICH J, 1986, ELECTROEN CLIN NEURO, V63, P251, DOI 10.1016/0013-4694(86)90093-3
   POLICH J, 1987, ELECTROEN CLIN NEURO, V68, P311, DOI 10.1016/0168-5597(87)90052-9
   Polich J, 2012, NEUROPSYCHOLOGY P300, P159
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   Porbadnigk A K, 2011, NEUROSCI LETT, V500, pe26
   Porbadnigk AK, 2013, J NEURAL ENG, V10, DOI 10.1088/1741-2560/10/5/056003
   Porbadnigk AK, 2010, IEEE ENG MED BIO, P2690, DOI 10.1109/IEMBS.2010.5626549
   Raake A., 2006, SPEECH QUALITY VOIP, DOI [10.1002/9780470033005, DOI 10.1002/9780470033005]
   Raake A, 2014, T-LAB SER TELECOMMUN, P11, DOI 10.1007/978-3-319-02681-7_2
   Reiter U, 2014, T-LAB SER TELECOMMUN, P55, DOI 10.1007/978-3-319-02681-7_4
   Sabri M, 2004, NEUROIMAGE, V21, P69, DOI 10.1016/j.neuroimage.2003.08.033
   Scholler S, 2012, IEEE T IMAGE PROCESS, V21, P2619, DOI 10.1109/TIP.2012.2187672
   Sokolov E. N., 2002, ORIENTING RESPONSE I
   Tibon R, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00555
   Uhrig S, 2018, 2018 10 INT C QUAL M, P1
   Uhrig S, 2017, QUAL USER EXP, V2, P10
   Verleger R, 2005, J PSYCHOPHYSIOL, V19, P165, DOI 10.1027/0269-8803.19.3.165
   Verleger R, 2008, CLIN NEUROPHYSIOL, V119, P968, DOI 10.1016/j.clinph.2007.11.175
   Verleger R, 2014, PSYCHOPHYSIOLOGY, V51, P1089, DOI 10.1111/psyp.12262
   Waltermann M, 2010, ACTA ACUST UNITED AC, V96, P1090, DOI 10.3813/AAA.918370
   Waltermann M, 2012, J AUDIO ENG SOC, V60, P246
   Waltermann M, 2013, T LABS SERIES TELECO, DOI [10.1007/978-3-642-35019-1, DOI 10.1007/978-3-642-35019-1]
   Wostmann M, 2015, J COGNITIVE NEUROSCI, V27, P988, DOI 10.1162/jocn_a_00761
   Wostmann M, 2015, THESIS
NR 65
TC 3
Z9 3
U1 0
U2 18
PU IOP PUBLISHING LTD
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 1741-2560
EI 1741-2552
J9 J NEURAL ENG
JI J. Neural Eng.
PD JUN
PY 2019
VL 16
IS 3
AR 036009
DI 10.1088/1741-2552/aaf122
PG 19
WC Engineering, Biomedical; Neurosciences
SC Engineering; Neurosciences & Neurology
GA HP8QT
UT WOS:000461958600004
PM 30523930
DA 2021-02-24
ER

PT J
AU Pan, FD
   Zhang, L
   Ou, YH
   Zhang, XN
AF Pan, Fada
   Zhang, Li
   Ou, Yuhong
   Zhang, Xinni
TI The audio-visual integration effect on music emotion: Behavioral and
   physiological evidence
SO PLOS ONE
LA English
DT Article
ID MULTISENSORY INTEGRATION; CROSSMODAL BINDING; SPEECH-PERCEPTION;
   VISUAL-ATTENTION; TIME-COURSE; RESPONSES; VOICE; BRAIN; INFORMATION;
   CONFLICT
AB Previous research has indicated that, compared to audio-only presentation, audio-visual congruent presentation can lead to a more intense emotional response. In the present study, we investigated the audio-visual integration effect on emotions elicited by positive or negative music and the role of visual information presentation durations. The participants were presented with audio-only condition, audio-visual congruent condition, and audiovisual incongruent condition and then required to judge the intensity of emotional experience elicited by the music. Their emotional responses to the music were measured using self-ratings and physiological aspects, including heart rate, skin temperature, EMG root mean square and prefrontal EEG. Relative to the audio-only presentation, the audio-visual congruent presentation led to a more intense emotional response. More importantly, the audiovisual integration occurred both in the positive music and in the negative music. Furthermore, the audio-visual integration effect was larger for positive music than for negative music; meanwhile the audio-visual integration effect was strongest with the visual information presented within 80s for negative music, which indicated that this integration effect was more likely to occur in the negative music. These results suggest that when the music was positive, the effect of audio-visual integration was greater. When the music was negative, the modulation effect of the presentation durations of visual information on the music induced emotion was more significant.
C1 [Pan, Fada; Zhang, Li; Ou, Yuhong; Zhang, Xinni] Nantong Univ, Sch Educ Sci, Nantong, Peoples R China.
RP Pan, FD (corresponding author), Nantong Univ, Sch Educ Sci, Nantong, Peoples R China.
EM psyc_lee2015@126.com
FU Social Sciences Foundation of Jiangsu Province, China [14SHC006];
   Program for Twelfth Five-Year Plan of Educational Science of Jiangsu
   Province, China [C-a/2013/01/003]; Postgraduate Research & Practice
   Innovation Program of Jiangsu Province [KYCX18_2389]
FX Fada Pan was supported by Grant number: 14SHC006, The Social Sciences
   Foundation of Jiangsu Province, China. http://jspopss.jschina.com.cn/;
   and Grant number: C-a/2013/01/003, The Program for Twelfth Five-Year
   Plan of Educational Science of Jiangsu Province, China.
   http://www.jssghb.cn/.Li Zhang was supported by Grant number:
   KYCX18_2389, Postgraduate Research & Practice Innovation Program of
   Jiangsu Province. http://jyt.jiangsu.gov.cn/.The funders had no role in
   study design, data collection and analysis, decision to publish, or
   preparation of the manuscript.
CR Armony JL, 2002, NEUROPSYCHOLOGIA, V40, P817, DOI 10.1016/S0028-3932(01)00178-6
   Bigand E, 2005, COGNITION EMOTION, V19, P1113, DOI 10.1080/02699930500204250
   Bigand E, 2005, ANN NY ACAD SCI, V1060, P429, DOI 10.1196/annals.1360.036
   Brett-Green BA, 2008, BRAIN RES, V1242, P283, DOI 10.1016/j.brainres.2008.03.090
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593
   Chapados C, 2008, COGNITION, V108, P639, DOI 10.1016/j.cognition.2008.05.008
   Chen MC, 2013, BRAIN INJURY, V27, P75, DOI 10.3109/02699052.2012.722255
   Chen XH, 2016, INT J PSYCHOPHYSIOL, V106, P14, DOI 10.1016/j.ijpsycho.2016.05.009
   Conrey B, 2006, J ACOUST SOC AM, V119, P4065, DOI 10.1121/1.2195091
   de Gelder B, 2000, COGNITION EMOTION, V14, P289, DOI 10.1080/026999300378824
   Dolan RJ, 2001, P NATL ACAD SCI USA, V98, P10006, DOI 10.1073/pnas.171288598
   Driver J, 2008, NEURON, V57, P11, DOI 10.1016/j.neuron.2007.12.013
   Ethofer T, 2006, HUM BRAIN MAPP, V27, P707, DOI 10.1002/hbm.20212
   Etkin A, 2006, NEURON, V51, P871, DOI 10.1016/j.neuron.2006.07.029
   Eysenck MW, 2007, EMOTION, V7, P336, DOI 10.1037/1528-3542.7.2.336
   Frassinetti F, 2002, EXP BRAIN RES, V147, P332, DOI 10.1007/s00221-002-1262-y
   Gao YL, 2014, NEUROREPORT, V25, P668, DOI 10.1097/WNR.0000000000000155
   [龚栩 Gong Xu], 2011, [中国心理卫生杂志, Chinese Mental Health Journal], V25, P40
   HERSHENSON M, 1962, J EXP PSYCHOL, V63, P289, DOI 10.1037/h0039516
   Jeong JW, 2011, NEUROIMAGE, V54, P2973, DOI 10.1016/j.neuroimage.2010.11.017
   Jessen S, 2011, NEUROIMAGE, V58, P665, DOI 10.1016/j.neuroimage.2011.06.035
   Kreifelts B, 2007, NEUROIMAGE, V37, P1445, DOI 10.1016/j.neuroimage.2007.06.020
   Marin MM, 2012, EMOTION, V12, P618, DOI 10.1037/a0025020
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MEREDITH MA, 1986, BRAIN RES, V365, P350
   Park JY, 2010, CORTEX, V46, P161, DOI 10.1016/j.cortex.2008.06.008
   Paulmann S, 2009, J PSYCHOPHYSIOL, V23, P63, DOI 10.1027/0269-8803.23.2.63
   Peretz I, 1998, COGNITION, V68, P111, DOI 10.1016/S0010-0277(98)00043-2
   Platz F, 2012, MUSIC PERCEPT, V30, P71, DOI 10.1525/MP.2012.30.1.71
   Pourtois G, 2000, NEUROREPORT, V11, P1329, DOI 10.1097/00001756-200004270-00036
   Pourtois G, 2005, CORTEX, V41, P49, DOI 10.1016/S0010-9452(08)70177-1
   Santangelo V, 2010, NEUROIMAGE, V49, P2717, DOI 10.1016/j.neuroimage.2009.10.061
   Senkowski D, 2005, EXP BRAIN RES, V166, P411, DOI 10.1007/s00221-005-2381-z
   Stevenson RA, 2010, NEUROIMAGE, V49, P3308, DOI 10.1016/j.neuroimage.2009.12.001
   Szycik GR, 2008, BRAIN RES, V1220, P142, DOI 10.1016/j.brainres.2007.08.027
   Talsma D, 2007, CEREB CORTEX, V17, P679, DOI 10.1093/cercor/bhk016
   Tang XY, 2016, NEUROSCI BIOBEHAV R, V61, P208, DOI 10.1016/j.neubiorev.2015.11.002
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   Vines BW, 2011, COGNITION, V118, P157, DOI 10.1016/j.cognition.2010.11.010
   Vuoskoski J. K., 2016, PSYCHOMUSICOLOGY MUS, V26, P179, DOI DOI 10.1037/PMU0000142
   Vuoskoski JK, 2014, ATTEN PERCEPT PSYCHO, V76, P591, DOI 10.3758/s13414-013-0582-2
   Watson R, 2014, J NEUROSCI, V34, P6813, DOI 10.1523/JNEUROSCI.4478-13.2014
   Weijkamp J, 2017, PSYCHOL MUSIC, V45, P204, DOI 10.1177/0305735616654216
   Werner S, 2010, J NEUROSCI, V30, P2662, DOI 10.1523/JNEUROSCI.5091-09.2010
   Yu HT, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, P1965, DOI 10.1109/ICMA.2016.7558867
   Zimmer U, 2010, NEUROIMAGE, V52, P606, DOI 10.1016/j.neuroimage.2010.04.245
NR 47
TC 1
Z9 1
U1 1
U2 12
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD MAY 30
PY 2019
VL 14
IS 5
AR e0217040
DI 10.1371/journal.pone.0217040
PG 21
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA IA2XG
UT WOS:000469425500009
PM 31145745
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Santarelli, R
   La Morgia, C
   Valentino, ML
   Barboni, P
   Monteleone, A
   Scimemi, P
   Carelli, V
AF Santarelli, Rosamaria
   La Morgia, Chiara
   Valentino, Maria Lucia
   Barboni, Piero
   Monteleone, Anna
   Scimemi, Pietro
   Carelli, Valerio
TI Hearing Dysfunction in a Large Family Affected by Dominant Optic Atrophy
   (OPA8-Related DOA): A Human Model of Hidden Auditory Neuropathy
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE hearing impairment; electrocochleography; speech perception; optic
   atrophy; acoustic reflexes
ID MITOCHONDRIAL-DNA INSTABILITY; SUMMATING POTENTIALS; MISSENSE MUTATION;
   GENE; OPA1; DISEASE
AB Hidden auditory neuropathy is characterized by reduced performances in challenging auditory tasks with the preservation of hearing thresholds, resulting from diffuse loss of cochlear inner hair cell (IHC) synapses following primary degeneration of unmyelinated terminals of auditory fibers. We report the audiological and electrophysiological findings collected from 10 members (4 males, 6 females) of a large Italian family affected by dominant optic atrophy, associated with the OPA8 locus, who complained of difficulties in understanding speech in the presence of noise. The patients were pooled into two groups, one consisting of 4 young adults (19-50 years) with normal hearing thresholds, and the other made up of 6 patients of an older age (55-72 years) showing mild hearing loss. Speech perception scores were normal in the first group and decreased in the second. Otoacoustic emissions (OAEs) and cochlear microphonics (CMs) recordings were consistent with preservation of outer hair cell (OHC) function in all patients, whereas auditory brainstem responses (ABRs) showed attenuated amplitudes in the first group and severe abnormalities in the second. Middle ear acoustic reflexes had delayed peak latencies in all patients in comparison with normally hearing individuals. Transtympanic electrocochleography (ECochG) recordings in response to 0.1 ms clicks at intensities from 120 to 60 dB peak equivalent SPL showed a reduction in amplitude of both summating potential (SP) and compound action potential (CAP) together with delayed CAP peak latencies and prolonged CAP duration in all patients in comparison with a control group of 20 normally hearing individuals. These findings indicate that underlying the hearing impairment in OPA8 patients is hidden AN resulting from diffuse loss of IHCs synapses. At an early stage the functional alterations only consist of abnormalities of ABR and ECochG potentials with increased latencies of acoustic reflexes, whereas reduction in speech perception scores become apparent with progression of the disease. Central mechanisms increasing the cortical gain are likely to compensate for the reduction of cochlear input.
C1 [Santarelli, Rosamaria; Scimemi, Pietro] Univ Padua, Dept Neurosci, Padua, Italy.
   [Santarelli, Rosamaria; Scimemi, Pietro] Santi Giovanni & Paolo Hosp, Audiol Serv, Venice, Italy.
   [Santarelli, Rosamaria; Monteleone, Anna; Scimemi, Pietro] Treviso Reg Hosp, Audiol & Phoniatr Serv, Treviso, Italy.
   [La Morgia, Chiara; Valentino, Maria Lucia; Carelli, Valerio] Univ Bologna, Dipartimento Sci Biomed & Neuromotorie, Bologna, Italy.
   [La Morgia, Chiara; Valentino, Maria Lucia; Carelli, Valerio] IRCCS Ist Sci Neurol Bologna, UOC Clin Neurol Bologna, Bologna, Italy.
   [Barboni, Piero] Studio Oculist DAzeglio, Bologna, Italy.
RP Santarelli, R (corresponding author), Univ Padua, Dept Neurosci, Padua, Italy.; Santarelli, R (corresponding author), Santi Giovanni & Paolo Hosp, Audiol Serv, Venice, Italy.; Santarelli, R (corresponding author), Treviso Reg Hosp, Audiol & Phoniatr Serv, Treviso, Italy.
EM rosamaria.santarelli@unipd.it
RI Scimemi, Pietro/T-5390-2017; Barboni, Piero/AAA-9936-2020
OI Scimemi, Pietro/0000-0001-5273-1938; Barboni, Piero/0000-0002-0118-4177
FU Telethon GrantFondazione Telethon [GGP06233]
FX This work was supported in part by the Telethon Grant GGP06233 to VC.
CR Alexander C, 2000, NAT GENET, V26, P211, DOI 10.1038/79944
   Amati-Bonneau P, 2008, BRAIN, V131, P338, DOI 10.1093/brain/awm298
   Bocca E., 1950, ARCH ITAL OTOL, V61, P116
   Carelli V, 2004, PROG RETIN EYE RES, V23, P53, DOI 10.1016/j.preteyeres.2003.10.003
   Carelli V, 2011, HUM MOL GENET, V20, P1893, DOI 10.1093/hmg/ddr071
   Chambers AR, 2016, NEURON, V89, P867, DOI 10.1016/j.neuron.2015.12.041
   Delettre C, 2000, NAT GENET, V26, P207, DOI 10.1038/79936
   DON M, 2002, HDB CLIN AUDIOLOGY, P274
   Durrant JD, 1998, J ACOUST SOC AM, V104, P370, DOI 10.1121/1.423293
   Eggermont J. J., 1976, AUDITORY SYSTEM CLIN, P625
   EGGERMONT JJ, 1974, ACTA OTO-LARYNGOL, P39
   EGGERMONT JJ, 1991, J ACOUST SOC AM, V90, P288, DOI 10.1121/1.401299
   Eiberg H, 2006, J MED GENET, V43, P435, DOI 10.1136/jmg.2005.034892
   Gelfand SA, 2002, HDB CLIN AUDIOLOGY, P205
   Gerber S, 2017, BRAIN, V140, P2586, DOI 10.1093/brain/awx219
   Huang TS, 2009, BRAIN RES, V1300, P97, DOI 10.1016/j.brainres.2009.08.083
   Hudson G, 2008, BRAIN, V131, P329, DOI 10.1093/brain/awm272
   KJER P, 1959, Acta Ophthalmol Suppl, V164, P1
   Klebe S, 2012, BRAIN, V135, P2980, DOI 10.1093/brain/aws240
   KOBLER JB, 1992, J NEUROPHYSIOL, V68, P807
   Lenaers G, 2012, ORPHANET J RARE DIS, V7, DOI 10.1186/1750-1172-7-46
   Leruez S, 2013, BRAIN, V136, DOI 10.1093/brain/aws340
   Liberman MC, 2017, HEARING RES, V349, P138, DOI 10.1016/j.heares.2017.01.003
   Martin B. A., 2007, AUDITORY EVOKED POTE, P482
   Mazzoli M., 2003, AUDIOL MED, V1, P148, DOI [10.1080/16513860301713, DOI 10.1080/16513860301713]
   Noguchi Y, 1999, AUDIOLOGY, V38, P135
   Parthasarathy A, 2018, J NEUROSCI, V38, P7108, DOI 10.1523/JNEUROSCI.3240-17.2018
   Quaranta A, 1996, ACTA PHON LAT, V18, P187
   Rance G, 2012, J NEUROL, V259, P2746, DOI 10.1007/s00415-012-6679-z
   Rendtorff ND, 2011, AM J MED GENET A, V155A, P1298, DOI 10.1002/ajmg.a.33970
   Reynier P, 2004, J MED GENET, V41, DOI 10.1136/jmg.2003.016576
   Rouzier C, 2012, BRAIN, V135, P23, DOI 10.1093/brain/awr323
   Salvi R, 2017, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00621
   Santarelli R., 2015, HDB CLIN AUDIOLOGY, P207
   Santarelli R., 2013, HDB CLIN NEUROPHYSIO, P83
   Santarelli R, 2008, CLIN NEUROPHYSIOL, V119, P1028, DOI 10.1016/j.clinph.2008.01.018
   Santarelli R, 2016, BRAIN, V139, pE34, DOI 10.1093/brain/aww052
   Santarelli R, 2015, BRAIN, V138, P563, DOI 10.1093/brain/awu378
   Schaette R, 2011, J NEUROSCI, V31, P13452, DOI 10.1523/JNEUROSCI.2156-11.2011
   Schoonhoven R., 2007, AUDITORY EVOKED POTE, P180
   Sergouniotis PI, 2015, NEUROGENETICS, V16, P69, DOI 10.1007/s10048-014-0416-y
   Starr A, 1996, BRAIN, V119, P741, DOI 10.1093/brain/119.3.741
   Valero MD, 2018, HEARING RES, V363, P109, DOI 10.1016/j.heares.2018.03.012
   Wynne DP, 2013, BRAIN, V136, P1626, DOI 10.1093/brain/awt056
   Yu-Wai-Man P, 2010, BRAIN, V133, P771, DOI 10.1093/brain/awq007
   Yu-Wai-Man P, 2016, ACTA NEUROPATHOL, V132, P789, DOI 10.1007/s00401-016-1625-2
   Yu-Wai-Man P, 2013, OPHTHALMOLOGY, V120, P1712, DOI 10.1016/j.ophtha.2013.04.022
   Yu-Wai-Man P, 2011, PROG RETIN EYE RES, V30, P81, DOI 10.1016/j.preteyeres.2010.11.002
   Zeng FG, 2005, J NEUROPHYSIOL, V93, P3050, DOI 10.1152/jn.00985.2004
NR 49
TC 2
Z9 3
U1 0
U2 1
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD MAY 28
PY 2019
VL 13
AR 501
DI 10.3389/fnins.2019.00501
PG 15
WC Neurosciences
SC Neurosciences & Neurology
GA IA0WD
UT WOS:000469279100001
PM 31191217
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Levy, H
   Hanulikova, A
AF Levy, Helena
   Hanulikova, Adriana
TI Variation in children's vowel production: Effects of language exposure
   and lexical frequency
SO LABORATORY PHONOLOGY
LA English
DT Article
DE Vowel production; school-aged children; bilingualism; regional
   varieties; foreign accents; lexical frequency; input variation
ID PHONOLOGICAL VARIATION; ANALYTICAL EXPRESSIONS; ACOUSTIC REDUCTION;
   SPEECH-PERCEPTION; NATIVE-LANGUAGE; ENGLISH; ADULTS; REPRESENTATION;
   VARIABILITY; DURATIONS
AB According to usage-based models of phonology, the more frequently a word is used and perceived in accented pronunciation variants, the more exemplars of accented tokens are stored and then used for subsequent productions of this word. This may lead to greater production variability in speakers with more variable input than in speakers with less variable input (cf. Pierrehumbert, 2001). This contrasts with abstractionist theories and with proposals according to which children unconsciously filter out accent features. This study assesses the effects of variable input and lexical frequency on speech production by children (mean age 9;10) growing up with one or more languages and with exposure to regional varieties and foreign accents. In a picture-naming task, 60 children were tested on their production of eight German vowels. Children who experience more input variability produced more variable vowels in terms of greater Euclidean distances. Vowels in frequent words were produced with more variability than in infrequent words. Vowel position (F1) differed depending on language background (monolingual versus bilingual) and amount of input in regional varieties. The results imply that greater input variation can account for variable vowel production, in line with usage-based theories.
C1 [Levy, Helena; Hanulikova, Adriana] Univ Freiburg, GRK Frequency Effects Language, Freiburg Im Breisgau, Germany.
   [Hanulikova, Adriana] Univ Freiburg, German Dept, Freiburg Im Breisgau, Germany.
   [Hanulikova, Adriana] Freiburg Inst Adv Studies FRIAS, Freiburg Im Breisgau, Germany.
RP Levy, H (corresponding author), Univ Freiburg, GRK Frequency Effects Language, Freiburg Im Breisgau, Germany.
EM helena.levy@frequenz.uni-freiburg.de
OI Levy, Helena/0000-0001-6610-6316; Hanulikova,
   Adriana/0000-0001-9010-4185
FU German Research Foundation (Deutsche Forschungsgemeinschaft DFG)German
   Research Foundation (DFG) [GRK 1624]
FX This research was funded by the German Research Foundation (Deutsche
   Forschungsgemeinschaft DFG), Research training group GRK 1624 "Frequency
   effects in language."
CR Amengual M, 2012, BILING-LANG COGN, V15, P517, DOI 10.1017/S1366728911000460
   Ammon U., 1977, DIALEKT HOCHSPRACHE
   Ammon U., 2015, B SUISSE LINGUISTIQU, V3, P53
   [Anonymous], 2015, CITO LANGUAGE TEST V
   Aoyama K, 2004, J PHONETICS, V32, P233, DOI 10.1016/S0095-4470(03)00036-6
   Audacity Team, 2014, AUD R FREE AUD ED RE
   Baker W, 2005, LANG SPEECH, V48, P1, DOI 10.1177/00238309050480010101
   Baker W, 2002, PROC ANN BUCLD, P36
   Baker W, 2008, LANG SPEECH, V51, P317, DOI 10.1177/0023830908099068
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bell A, 2009, J MEM LANG, V60, P92, DOI 10.1016/j.jml.2008.06.003
   Bent T, 2017, LANG SPEECH, V60, P110, DOI 10.1177/0023830916645374
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma Paul, 2012, PRAAT DOING PHONETIC
   Bosch L, 2011, J PHONETICS, V39, P514, DOI 10.1016/j.wocn.2011.02.001
   Brown EL, 2015, INT J BILINGUAL, V19, P387, DOI 10.1177/1367006913516042
   Burki A, 2018, PSYCHON B REV, V25, P1973, DOI 10.3758/s13423-017-1423-4
   Burki A, 2010, J MEM LANG, V62, P421, DOI 10.1016/j.jml.2010.01.002
   Bybee J., 2001, PHONOLOGY LANGUAGE U, DOI [10.1017/CBO9780511612886, DOI 10.1017/CBO9780511612886, 10.1017/CB09780511612886]
   Bybee J.L., 2010, OXFORD HDB LINGUISTI, P827, DOI [DOI 10.1093/OXFORDHB/9780199544004.013.0032, 10.1093/oxfordhb/9780199544004.013.0032]
   Bybee Joan, 2001, FREQUENCY EMERGENCE, DOI [10.1075/tsl.45.17byb, DOI 10.1075/TSL.45, 10.1075/tsl.45]
   Bybee Joan L., 2007, FREQUENCY USE ORG LA, DOI [10.1093/acprof:oso/9780195301571.001.0001, DOI 10.1093/ACPROF:OSO/9780195301571.001.0001]
   Chambers J. K., 2002, J SOCIOLING, P117, DOI [10.1111/1467-9481.00180, DOI 10.1111/1467-9481.00180]
   Chiswick BR., 2005, J MULTILING MULTICUL, V26, P1, DOI [DOI 10.1080/14790710508668395, 10.1080/14790710508668395]
   Clopper CG, 2014, LAB PHONOL, V5, P69, DOI 10.1515/lp-2014-0004
   Cutler A, 2012, NATIVE LISTENING LAN, DOI [10.7551/mitpress/9012.001.0001, DOI 10.7551/MITPRESS/9012.001.0001]
   Darcy I, 2012, J PHONETICS, V40, P568, DOI 10.1016/j.wocn.2012.05.001
   De Houwer A., 2009, BILINGUAL 1 LANGUAGE, DOI [10.21832/9781847691507, DOI 10.21832/9781847691507]
   De Houwer A, 2017, BILINGUAL COGNITION, P127, DOI DOI 10.1075/SIBIL.54.07HOU
   Derdemezis E, 2016, AM J SPEECH-LANG PAT, V25, P335, DOI 10.1044/2015_AJSLP-15-0020
   Drager K, 2016, AWARENESS CONTROL SO, P1, DOI DOI 10.1017/CBO9781139680448.003
   Ernestus M, 2014, LINGUA, V142, P27, DOI 10.1016/j.lingua.2012.12.006
   Fant G., 1966, SPEECH TRANSMISSION, V7, P22
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2007, LAB PHONOLOGY, P353
   Flege JE, 1999, J MEM LANG, V41, P78, DOI 10.1006/jmla.1999.2638
   Foulkes P, 2006, J PHONETICS, V34, P409, DOI 10.1016/j.wocn.2005.08.002
   Fowler CA, 2008, J PHONETICS, V36, P649, DOI 10.1016/j.wocn.2008.04.001
   Francot R. J., 2017, LANGUAGE VARIATION E, VVI, P85, DOI [10.1075/silv.19.05fra, DOI 10.1075/SILV.19.05FRA]
   Gahl S, 2008, LANGUAGE, V84, P474
   Gildersleeve-Neumann CE, 2008, LANG SPEECH HEAR SER, V39, P314, DOI 10.1044/0161-1461(2008/030)
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Guy GR, 2014, LINGUA, V142, P57, DOI 10.1016/j.lingua.2012.07.007
   Huber JE, 1999, J ACOUST SOC AM, V106, P1532, DOI 10.1121/1.427150
   Jurafsky D., 2000, FREQUENCY EMERGENCE, P229, DOI DOI 10.1075/TSL.45.13JUR
   Kang YJ, 2015, LAB PHONOL, V6, P469, DOI 10.1515/lp-2015-0014
   Keating P. A., 1998, ZAS PAPERS LINGUISTI, V11, P35, DOI DOI 10.1142/9781848160712_
   Kehoe M., 2002, INT J BILINGUAL, V6, P315, DOI DOI 10.1177/13670069020060030601
   Khattab G., 2006, PHONOLOGICAL DEV DIS, P383, DOI [10.21832/9781853598906-017, DOI 10.21832/9781853598906-017]
   Khattab G., 2007, LAB PHONOLOGY, V9, P383
   Khattab G, 2009, CAMB HB LANG LINGUIS, P142
   Kirchner R., 2012, OXFORD HDB LAB PHONO, P332, DOI [10.1093/oxfordhb/9780199575039.001.0001, DOI 10.1093/OXFORDHB/9780199575039.001.0001]
   Kirchner R, 2010, J PHONETICS, V38, P540, DOI 10.1016/j.wocn.2010.07.005
   Kuhl P. K., 1995, SPEECH PERCEPTION LI, P433
   Lee S, 1999, J ACOUST SOC AM, V105, P1455, DOI 10.1121/1.426686
   Leinonen T., 2011, CITERAT, V5, P75
   Lenneberg EH, 1967, HOSP PRACT, V2, P59, DOI [DOI 10.1080/21548331.1967.11707799, 10.1080/21548331.1967.11707799]
   Lennes M., 2017, SPECT SPEECH CORPUS
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1
   Marecka M., 2015, P INT S MON BIL SPEE, P207, DOI DOI 10.13140/RG.2.1.3134.9845
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001
   McCarthy KM, 2014, CHILD DEV, V85, P1965, DOI 10.1111/cdev.12275
   McCloy D., 2016, PHONR TOOLS PHONETIC
   Mitterer H, 2008, COGNITION, V109, P168, DOI 10.1016/j.cognition.2008.08.002
   Munson B, 2004, J SPEECH LANG HEAR R, V47, P1048, DOI 10.1044/1092-4388(2004/078)
   Nicolaidis K., 2003, P 15 INT C PHON SCI, P3221
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Oh GE, 2011, J PHONETICS, V39, P156, DOI 10.1016/j.wocn.2011.01.002
   Pallier C, 2001, PSYCHOL SCI, V12, P445, DOI 10.1111/1467-9280.00383
   Paradis J., 2001, INT J BILINGUAL, V5, P19, DOI DOI 10.1177/13670069010050010201
   Pickl Simon, 2014, J LINGUISTIC GEOGRAP, V2, P25, DOI DOI 10.1017/JLG.2014.3
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Piske T, 2002, PHONETICA, V59, P49, DOI 10.1159/000056205
   Pluymaekers M, 2005, J ACOUST SOC AM, V118, P2561, DOI 10.1121/1.2011150
   Porretta V, 2016, J PHONETICS, V58, P1, DOI 10.1016/j.wocn.2016.05.006
   Porzuczek A., 2012, RES LANGUAGE, V10, P201, DOI [10.2478/v10015-011-0034-9, DOI 10.2478/V10015-011-0034-9]
   R Core Team, 2016, R LANG ENV STAT COMP
   Ranbom LJ, 2007, J MEM LANG, V57, P273, DOI 10.1016/j.jml.2007.04.001
   Rathcke TV, 2015, J ACOUST SOC AM, V137, P2834, DOI 10.1121/1.4919322
   Schertz J, 2014, CORPUS LINGUIST LING, V10, P329, DOI 10.1515/cllt-2014-0024
   Schroeder S, 2015, BEHAV RES METHODS, V47, P1085, DOI 10.3758/s13428-014-0528-1
   Schweitzer K, 2015, SPEECH COMMUN, V66, P65, DOI 10.1016/j.specom.2014.09.006
   STRANGE W, 1995, SPEECH PERCEPTION LI
   Stroup W. W., 2012, GEN LINEAR MIXED MOD
   Styler W., 2011, USING PRAAT LINGUIST
   Tomaschek F., 2014, P 10 ISSP COL, P429
   TRAUNMULLER H, 1990, J ACOUST SOC AM, V88, P97, DOI 10.1121/1.399849
   TRAUNMULLER H, 1984, SPEECH COMMUN, V3, P49, DOI 10.1016/0167-6393(84)90008-6
   Tsukada K, 2005, J PHONETICS, V33, P263, DOI 10.1016/j.wocn.2004.10.002
   van Heugten M, 2017, J ACOUST SOC AM, V142, pEL196, DOI 10.1121/1.4997604
   VIHMAN MM, 1993, J PHONETICS, V21, P61, DOI 10.1016/S0095-4470(19)31321-X
   Vorperian HK, 2007, J SPEECH LANG HEAR R, V50, P1510, DOI 10.1044/1092-4388(2007/104)
   Weber R., 2008, BADEN WURTTEMBERG PO
   Wells J. C., 1962, THESIS
   Whitworth N., 2000, LEEDS WORKING PAPERS, V8, P15
   Zuur Alain F., 2009, P1
   ZWICKER E, 1980, J ACOUST SOC AM, V68, P1523, DOI 10.1121/1.385079
NR 101
TC 3
Z9 3
U1 0
U2 5
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD MAY 22
PY 2019
VL 10
IS 1
AR 9
DI 10.5334/labphon.131
PG 26
WC Linguistics; Language & Linguistics
SC Linguistics
GA HZ4JX
UT WOS:000468814800001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Bharadwaj, HM
   Mai, AR
   Simpson, JM
   Choi, I
   Heinz, MG
   Shinn-Cunningham, BG
AF Bharadwaj, Hari M.
   Mai, Alexandra R.
   Simpson, Jennifer M.
   Choi, Inyong
   Heinz, Michael G.
   Shinn-Cunningham, Barbara G.
TI Non-Invasive Assays of Cochlear Synaptopathy - Candidates and
   Considerations
SO NEUROSCIENCE
LA English
DT Article
DE cochlear synaptopathy; middle-ear muscle reflex; hidden-hearing loss;
   auditory brainstem response; envelope-following response; individual
   differences
ID BRAIN-STEM RESPONSE; STEADY-STATE RESPONSES; HIDDEN HEARING-LOSS;
   HIGH-FREQUENCY AUDIOMETRY; INDIVIDUAL-DIFFERENCES; NOISE EXPOSURE;
   SPEECH-PERCEPTION; REFLEX THRESHOLD; AUDITORY-NERVE; YOUNG-ADULTS
AB Studies in multiple species, including in post-mortem human tissue, have shown that normal aging and/or acoustic overexposure can lead to a significant loss of afferent synapses innervating the cochlea. Hypothetically, this cochlear synaptopathy can lead to perceptual deficits in challenging environments and can contribute to central neural effects such as tinnitus. However, because cochlear synaptopathy can occur without any measurable changes in audiometric thresholds, synaptopathy can remain hidden from standard clinical diagnostics. To understand the perceptual sequelae of synaptopathy and to evaluate the efficacy of emerging therapies, sensitive and specific non-invasive measures at the individual patient level need to be established. Pioneering experiments in specific mice strains have helped identify many candidate assays. These include auditory brainstem responses, the middle-ear muscle reflex, envelope-following responses, and extended high-frequency audiograms. Unfortunately, because these non-invasive measures can be also affected by extraneous factors other than synaptopathy, their application and interpretation in humans is not straightforward. Here, we systematically examine six extraneous factors through a series of interrelated human experiments aimed at understanding their effects. Using strategies that may help mitigate the effects of such extraneous factors, we then show that these suprathreshold physiological assays exhibit across-individual correlations with each other indicative of contributions from a common physiological source consistent with cochlear synaptopathy. Finally, we discuss the application of these assays to two key outstanding questions, and discuss some barriers that still remain.
   This article is part of a Special Issue entitled: Hearing Loss, Tinnitus, Hyperacusis, Central Gain. (C) 2019 IBRO. Published by Elsevier Ltd. All rights reserved.
C1 [Bharadwaj, Hari M.; Mai, Alexandra R.; Simpson, Jennifer M.; Heinz, Michael G.] Purdue Univ, Dept Speech Language & Hearing Sci, W Lafayette, IN 47907 USA.
   [Bharadwaj, Hari M.; Heinz, Michael G.] Purdue Univ, Weldon Sch Biomed Engn, W Lafayette, IN 47907 USA.
   [Choi, Inyong] Univ Iowa, Dept Commun Sci & Disorders, Iowa City, IA USA.
   [Shinn-Cunningham, Barbara G.] Carnegie Mellon Univ, Carnegie Mellon Neurosci Inst, Pittsburgh, PA 15213 USA.
RP Bharadwaj, HM (corresponding author), Purdue Univ, Lyles Porter Hall,715 Clin Dr, W Lafayette, IN 47907 USA.
EM hbharadwaj@purdue.edu
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R01 DC015989, R01 DC013825]; Hearing
   Health Foundation; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC015989,
   R01DC015989, R01DC015989, R01DC015989, R01DC013825, R01DC013825,
   R01DC013825, R01DC013825] Funding Source: NIH RePORTER
FX This work was supported by NIH grants R01 DC015989 (HMB), R01 DC013825
   (BGSC), and two emerging research grants (ERG) from Hearing Health
   Foundation (HMB and IC). We would like to thank Brooke Flesher, Kelsey
   Dougherty, and Anna Hagedorn for assistance with data collection at
   Purdue University, Karolina Charaziak for input during the initial
   stages of setting up the FPL calibration for the ER-10X system, and M.
   Charles Liberman for pointing us to relevant literature for Section 3.1.
CR Ahlfors SP, 2010, BRAIN TOPOGR, V23, P227, DOI 10.1007/s10548-010-0154-x
   Badri R, 2011, J ACOUST SOC AM, V129, P852, DOI 10.1121/1.3523476
   Bardsley WE, 1999, J HYDROL, V219, P1, DOI 10.1016/S0022-1694(99)00043-8
   Bharadwaj HM, 2015, J NEUROSCI, V35, P2161, DOI 10.1523/JNEUROSCI.3915-14.2015
   Bharadwaj HM, 2014, CLIN NEUROPHYSIOL, V125, P1878, DOI 10.1016/j.clinph.2014.01.011
   Bharadwaj HM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00026
   Bidelman GM, 2018, NEUROIMAGE, V175, P56, DOI 10.1016/j.neuroimage.2018.03.060
   Bourien J, 2014, J NEUROPHYSIOL, V112, P1025, DOI 10.1152/jn.00738.2013
   Bramhall NF, 2017, EAR HEARING, V38, pE1, DOI 10.1097/AUD.0000000000000370
   Bressler SC, 2014, J NEUROTRAUM, V31, pA2
   Brungart DS, 2006, J ACOUST SOC AM, V120, P4007, DOI 10.1121/1.2363929
   Charaziak KK, 2017, J ACOUST SOC AM, V141, P515, DOI 10.1121/1.4973618
   Choi I, 2014, HEARING RES, V314, P10, DOI 10.1016/j.heares.2014.04.008
   Coffey EBJ, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11070
   COHEN MS, 1982, ANESTH ANALG, V61, P338
   Conway ARA, 2001, PSYCHON B REV, V8, P331, DOI 10.3758/BF03196169
   Cruickshanks KJ, 2010, SPRINGER HANDB AUDIT, V34, P259, DOI 10.1007/978-1-4419-0993-0_9
   Davis R R, 2003, Noise Health, V5, P19
   Dobie RA, 2017, INT J AUDIOL, V56, P74, DOI 10.1080/14992027.2016.1255359
   DON M, 1993, J ACOUST SOC AM, V94, P2135, DOI 10.1121/1.407485
   DON M, 1978, J ACOUST SOC AM, V63, P1084, DOI 10.1121/1.381816
   DON M, 1994, J ACOUST SOC AM, V96, P3476, DOI 10.1121/1.410608
   Dubno JR, 2013, JARO-J ASSOC RES OTO, V14, P687, DOI 10.1007/s10162-013-0396-x
   Feeney MP, 2017, EAR HEARING, V38, pE142, DOI 10.1097/AUD.0000000000000399
   Fitzgibbons P. J., 2010, BEHAV STUDIES AGING, P111
   Francis NA, 2018, FRONT SYST NEUROSCI, V12, DOI 10.3389/fnsys.2018.00042
   Furman AC, 2013, J NEUROPHYSIOL, V110, P577, DOI 10.1152/jn.00164.2013
   Gannouni N, 2015, J NEUROSCI RES, V93, P848, DOI 10.1002/jnr.23567
   Gorga MP, 2003, J ACOUST SOC AM, V113, P3275, DOI 10.1121/1.1570433
   Grose JH, 2009, EAR HEARING, V30, P568, DOI 10.1097/AUD.0b013e3181ac128f
   HAMALAINEN M, 1993, REV MOD PHYS, V65, P413, DOI 10.1103/RevModPhys.65.413
   Herdman AT, 2002, BRAIN TOPOGR, V15, P69, DOI 10.1023/A:1021470822922
   Hickox AE, 2017, HEARING RES, V349, P164, DOI 10.1016/j.heares.2016.12.010
   Hickox AE, 2014, J NEUROPHYSIOL, V111, P552, DOI 10.1152/jn.00184.2013
   Hubbard J, 1971, AM J PHYS MED REHABI, V50, P303
   Irimia A, 2013, CLIN NEUROPHYSIOL, V124, P2129, DOI 10.1016/j.clinph.2013.04.336
   Iseberg S, 2015, AUD ENG SOC C 58 INT
   JORIS PX, 1992, J ACOUST SOC AM, V91, P215, DOI 10.1121/1.402757
   Joris PX, 2004, PHYSIOL REV, V84, P541, DOI 10.1152/physrev.00029.2003
   KEEFE DH, 1992, J ACOUST SOC AM, V91, P470, DOI 10.1121/1.402733
   Keefe DH, 2017, JARO-J ASSOC RES OTO, V18, P65, DOI 10.1007/s10162-016-0599-z
   Kidd GR, 2007, J ACOUST SOC AM, V122, P418, DOI 10.1121/1.2743154
   KOBLER JB, 1992, J NEUROPHYSIOL, V68, P807
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Kujawa SG, 2015, HEARING RES, V330, P191, DOI 10.1016/j.heares.2015.02.009
   Kujawa SG, 2009, J NEUROSCI, V29, P14077, DOI 10.1523/JNEUROSCI.2845-09.2009
   Kuwada S, 2002, J AM ACAD AUDIOL, V13
   Lee J, 2012, EAR HEARING, V33, P315, DOI 10.1097/AUD.0b013e31823d7917
   Leigh-Paffenroth ED, 2006, J AM ACAD AUDIOL, V17, P582, DOI 10.3766/jaaa.17.8.5
   Liberman MC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162726
   Liberman MC, 2014, J NEUROSCI, V34, P4599, DOI 10.1523/JNEUROSCI.4923-13.2014
   LIBERMAN MC, 1984, HEARING RES, V16, P75, DOI 10.1016/0378-5955(84)90026-1
   Lin FR, 2011, ARCH INTERN MED, V171, P1851, DOI 10.1001/archinternmed.2011.506
   Lins OG, 1996, EAR HEARING, V17, P81, DOI 10.1097/00003446-199604000-00001
   Lobarinas E, 2013, HEARING RES, V302, P113, DOI 10.1016/j.heares.2013.03.012
   Maison SF, 2013, J NEUROSCI, V33, P5542, DOI 10.1523/JNEUROSCI.5027-12.2013
   Makary CA, 2011, JARO-J ASSOC RES OTO, V12, P711, DOI 10.1007/s10162-011-0283-2
   Mehraei G, 2016, J NEUROSCI, V36, P3755, DOI 10.1523/JNEUROSCI.4460-15.2016
   Mehrparvar AH, 2011, NOISE HEALTH, V13, P402, DOI 10.4103/1463-1741.90295
   Mohrle D, 2016, NEUROBIOL AGING, V44, P173, DOI 10.1016/j.neurobiolaging.2016.05.001
   National Institute for Occupational Safety and Health (NIOSH), 1998, CRIT REC STAND OCC N
   Nuttall HE, 2015, J NEUROPHYSIOL, V113, P3683, DOI 10.1152/jn.00548.2014
   Okada YC, 1997, ELECTROEN CLIN NEURO, V103, P474, DOI 10.1016/S0013-4694(97)00043-6
   Oxenham AJ, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516686768
   Parthasarathy A, 2018, J NEUROSCI, V38, P7108, DOI 10.1523/JNEUROSCI.3240-17.2018
   Paul BT, 2017, HEARING RES, V344, P170, DOI 10.1016/j.heares.2016.11.010
   Plack CJ, 2014, TRENDS HEAR, V18, DOI 10.1177/2331216514550621
   Prendergast G, 2017, HEARING RES, V344, P68, DOI 10.1016/j.heares.2016.10.028
   Purcell DW, 2004, J ACOUST SOC AM, V116, P3581, DOI 10.1121/1.1798354
   Rabinowitz PM, 2006, EAR HEARING, V27, P369, DOI 10.1097/01.aud.0000224125.12338.9a
   Ross B, 2000, J ACOUST SOC AM, V108, P679, DOI 10.1121/1.429600
   Ruggles D, 2012, CURR BIOL, V22, P1417, DOI 10.1016/j.cub.2012.05.025
   Ruggles D, 2011, P NATL ACAD SCI USA, V108, P15516, DOI 10.1073/pnas.1108912108
   Ruggles D, 2011, JARO-J ASSOC RES OTO, V12, P395, DOI 10.1007/s10162-010-0254-z
   SATO H, 1991, ACTA OTO-LARYNGOL, V111, P1037, DOI 10.3109/00016489109100753
   Schaette R, 2011, J NEUROSCI, V31, P13452, DOI 10.1523/JNEUROSCI.2156-11.2011
   Scheperle RA, 2008, J ACOUST SOC AM, V124, P288, DOI 10.1121/1.2931953
   Schoonhoven R, 2003, CLIN NEUROPHYSIOL, V114, P2096, DOI 10.1016/S1388-2457(03)00200-1
   Sergeyenko Y, 2013, J NEUROSCI, V33, P13686, DOI 10.1523/JNEUROSCI.1783-13.2013
   Shaheen LA, 2015, JARO-J ASSOC RES OTO, V16, P727, DOI 10.1007/s10162-015-0539-3
   Shaw GM, 1996, BRIT J AUDIOL, V30, P233, DOI 10.3109/03005369609076770
   Shera CA, 2003, J ACOUST SOC AM, V113, P2762, DOI 10.1121/1.1557211
   Shinn-Cunningham B, 2017, SPRINGER HANDB AUDIT, V61, P159, DOI 10.1007/978-3-319-47944-6_7
   Shinn-Cunningham BG, 2008, TRENDS COGN SCI, V12, P182, DOI 10.1016/j.tics.2008.02.003
   SIEGEL JH, 1994, J ACOUST SOC AM, V95, P2589, DOI 10.1121/1.409829
   Silventoinen K, 2003, TWIN RES, V6, P399, DOI 10.1375/136905203770326402
   Singer W, 2013, MOL NEUROBIOL, V47, P261, DOI 10.1007/s12035-012-8372-8
   Skoe E, 2018, HEARING RES, V361, P80, DOI 10.1016/j.heares.2018.01.005
   Smith SB, 2019, HEARING RES, V371, P66, DOI 10.1016/j.heares.2018.11.008
   Snell KB, 2000, J ACOUST SOC AM, V107, P1615, DOI 10.1121/1.428446
   Song Q, 2016, SCI REP, V6
   Souza NN, 2014, J ACOUST SOC AM, V136, P1768, DOI 10.1121/1.4894787
   Stamper GC, 2015, EAR HEARING, V36, P172, DOI 10.1097/AUD.0000000000000107
   Stapells DR, 1997, AUDIOL NEURO-OTOL, V2, P257, DOI 10.1159/000259252
   Teki S, 2013, ELIFE, V2, DOI 10.7554/eLife.00699
   THORNTON C, 1989, BRIT J ANAESTH, V63, P411, DOI 10.1093/bja/63.4.411
   Valero MD, 2017, HEARING RES, V353, P213, DOI 10.1016/j.heares.2017.07.003
   Valero MD, 2018, HEARING RES, V363, P109, DOI 10.1016/j.heares.2018.03.012
   Varghese L, 2015, BRAIN RES, V1626, P146, DOI 10.1016/j.brainres.2015.06.038
   Verhulst S, 2015, J ACOUST SOC AM, V138, P1637, DOI 10.1121/1.4928305
   Viana LM, 2015, HEARING RES, V327, P78, DOI 10.1016/j.heares.2015.04.014
   Wang Y, 2002, JARO, V3, P248, DOI 10.1007/s101620020028
   Wojtczak M, 2017, ENEURO, V4, DOI 10.1523/ENEURO.0363-17.2017
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
   Wu PZ, 2019, NEUROSCIENCE, V407, P8, DOI 10.1016/j.neuroscience.2018.07.053
   Yeend I, 2017, HEARING RES, V353, P224, DOI 10.1016/j.heares.2017.07.006
   2014, P NATL ACAD SCI USA, V111, P7126, DOI DOI 10.1073/PNAS.1318738111
NR 107
TC 13
Z9 13
U1 4
U2 8
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0306-4522
EI 1873-7544
J9 NEUROSCIENCE
JI Neuroscience
PD MAY 21
PY 2019
VL 407
SI SI
BP 53
EP 66
DI 10.1016/j.neuroscience.2019.02.031
PG 14
WC Neurosciences
SC Neurosciences & Neurology
GA HX4SH
UT WOS:000467390100006
PM 30853540
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Guest, H
   Munro, KJ
   Plack, CJ
AF Guest, Hannah
   Munro, Kevin J.
   Plack, Christopher J.
TI Acoustic Middle-Ear-Muscle-Reflex Thresholds in Humans with Normal
   Audiograms: No Relations to Tinnitus, Speech Perception in Noise, or
   Noise Exposure
SO NEUROSCIENCE
LA English
DT Article
DE Cochlear synaptopathy; hidden hearing loss; tinnitus; middle-ear-muscle
   reflex; acoustic reflex; noise-induced hearing loss
ID HIDDEN HEARING-LOSS; COCHLEAR SYNAPTOPATHY; YOUNG-ADULTS; AUDITORY
   FUNCTION; NEUROPATHY; POTENTIALS; DIAGNOSIS; HISTORY; FIBERS; NERVE
AB The acoustic middle-ear-muscle reflex (MEMR) has been suggested as a sensitive non-invasive measure of cochlear synaptopathy, the loss of synapses between inner hair cells and auditory nerve fibers. In the present study, clinical MEMR thresholds were measured for 1-, 2-, and 4-kHz tonal elicitors, using a procedure shown to produce thresholds with excellent reliability. MEMR thresholds of 19 participants with tinnitus and normal audiograms were compared to those of 19 age-and sex-matched controls. MEMR thresholds did not differ significantly between the two groups at any frequency. These 38 participants were included in a larger sample of 70 participants with normal audiograms. For this larger group, MEMR thresholds were compared to a measure of spatial speech perception in noise (SPiN) and a detailed self-report estimate of lifetime noise exposure. MEMR thresholds were unrelated to either SPiN or noise exposure, despite a wide range in both measures. It is possible that thresholds measured using a clinical paradigm are less sensitive to synaptopathy than those obtained using more sophisticated measurement techniques; however, we had good sensitivity at the group level, and even trends in the hypothesized direction were not observed. To the extent that MEMR thresholds are sensitive to cochlear synaptopathy, the present results provide no evidence that tinnitus, SPiN, or noise exposure are related to synaptopathy in the population studied.
   This article is part of a Special Issue entitled: Hearing Loss, Tinnitus, Hyperacusis, Central Gain. (C) 2018 The Author(s). Published by Elsevier Ltd on behalf of IBRO.
C1 [Guest, Hannah; Munro, Kevin J.; Plack, Christopher J.] Univ Manchester, Manchester Ctr Audiol & Deafness, Manchester Acad Hlth Sci Ctr, Manchester, Lancs, England.
   [Munro, Kevin J.] Manchester Univ Hosp NHS Fdn Trust, Manchester, Lancs, England.
   [Plack, Christopher J.] Univ Lancaster, Dept Psychol, Lancaster, England.
RP Guest, H (corresponding author), Univ Manchester, Manchester Ctr Audiol & Deafness, Manchester Acad Hlth Sci Ctr, Manchester, Lancs, England.
EM hannah.guest@manchester.ac.uk
RI ; Plack, Christopher/P-4209-2017
OI Guest, Hannah/0000-0002-4981-6663; Plack,
   Christopher/0000-0002-2987-5332
FU Marston Family Foundation (a small charitable foundation); Action on
   Hearing Loss (a large UK charity); Medical Research Council UKUK
   Research & Innovation (UKRI)Medical Research Council UK (MRC)
   [MR/L003589/1]; NIHR Manchester Biomedical Research CentreNational
   Institute for Health Research (NIHR)
FX This research was funded by The Marston Family Foundation (a small
   charitable foundation) and Action on Hearing Loss (a large UK charity),
   with support from the Medical Research Council UK (MR/L003589/1) and the
   NIHR Manchester Biomedical Research Centre.
CR Bharadwaj HM, 2015, J NEUROSCI, V35, P2161, DOI 10.1523/JNEUROSCI.3915-14.2015
   Bharadwaj HM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00026
   Bourien J, 2014, J NEUROPHYSIOL, V112, P1025, DOI 10.1152/jn.00738.2013
   Bramhall N, 2015, J AM ACAD AUDIOL, V26, P509, DOI 10.3766/jaaa.14100
   Bramhall NF, 2018, EAR HEARING, V39, P881, DOI 10.1097/AUD.0000000000000544
   Bramhall NF, 2017, EAR HEARING, V38, pE1, DOI 10.1097/AUD.0000000000000370
   Davis A.C., 1995, HEARING IN ADULTS
   Dobie RA, 2017, INT J AUDIOL, V56, P74, DOI 10.1080/14992027.2016.1255359
   DON M, 1978, J ACOUST SOC AM, V63, P1084, DOI 10.1121/1.381816
   Feeney MP, 2017, EAR HEARING, V38, pE142, DOI 10.1097/AUD.0000000000000399
   Fernandez KA, 2015, J NEUROSCI, V35, P7509, DOI 10.1523/JNEUROSCI.5138-14.2015
   Fulbright Angela N. C., 2017, Seminars in Hearing, V38, P298, DOI 10.1055/s-0037-1606325
   Furman AC, 2013, J NEUROPHYSIOL, V110, P577, DOI 10.1152/jn.00164.2013
   Gilles A, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00288
   Grinn SK, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00465
   Grose JH, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517737417
   Gu JW, 2012, JARO-J ASSOC RES OTO, V13, P819, DOI 10.1007/s10162-012-0344-1
   Guest H, 2018, BRIT SOC AUD BAS AUD
   Guest H, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518803213
   Guest H, 2018, HEARING RES, V364, P142, DOI 10.1016/j.heares.2018.03.008
   Guest H, 2017, HEARING RES, V356, P116, DOI 10.1016/j.heares.2017.10.002
   Guest H, 2017, HEARING RES, V344, P265, DOI 10.1016/j.heares.2016.12.002
   KOBLER JB, 1992, J NEUROPHYSIOL, V68, P807
   Kujawa SG, 2009, J NEUROSCI, V29, P14077, DOI 10.1523/JNEUROSCI.2845-09.2009
   Liberman MC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162726
   LIBERMAN MC, 1984, HEARING RES, V16, P75, DOI 10.1016/0378-5955(84)90026-1
   Lopez-Poveda EA, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00124
   Oxenham AJ, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516686768
   Paul BT, 2017, HEARING RES, V344, P170, DOI 10.1016/j.heares.2016.11.010
   Prendergast G, 2018, HEAR RES
   Prendergast G, 2017, HEARING RES, V356, P74, DOI 10.1016/j.heares.2017.10.007
   Prendergast G, 2017, HEARING RES, V344, P68, DOI 10.1016/j.heares.2016.10.028
   R Core Team, 2015, R LANG ENV STAT COMP
   Roberts LE, 2018, HEARING RES, V361, P157, DOI 10.1016/j.heares.2018.01.011
   Schaette R, 2011, J NEUROSCI, V31, P13452, DOI 10.1523/JNEUROSCI.2156-11.2011
   Sergeyenko Y, 2013, J NEUROSCI, V33, P13686, DOI 10.1523/JNEUROSCI.1783-13.2013
   Shaheen LA, 2015, JARO-J ASSOC RES OTO, V16, P727, DOI 10.1007/s10162-015-0539-3
   Shim HJ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0189157
   Spankovich C, 2017, EAR HEARING, V38, P724, DOI 10.1097/AUD.0000000000000457
   Stamper GC, 2015, EAR HEARING, V36, P738, DOI 10.1097/AUD.0000000000000228
   Valero MD, 2017, HEARING RES, V353, P213, DOI 10.1016/j.heares.2017.07.003
   Valero MD, 2018, HEARING RES, V363, P109, DOI 10.1016/j.heares.2018.03.012
   Valero MD, 2016, HEARING RES, V332, P29, DOI 10.1016/j.heares.2015.11.005
   Viana LM, 2015, HEARING RES, V327, P78, DOI 10.1016/j.heares.2015.04.014
   Wojtczak M, 2018, ASS RES OT 41 ANN MI
   Wojtczak M, 2017, ENEURO, V4, DOI 10.1523/ENEURO.0363-17.2017
   Wu PZ, 2019, NEUROSCIENCE, V407, P8, DOI 10.1016/j.neuroscience.2018.07.053
   Yeend I, 2017, HEARING RES, V353, P224, DOI 10.1016/j.heares.2017.07.006
NR 48
TC 5
Z9 5
U1 0
U2 3
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0306-4522
EI 1873-7544
J9 NEUROSCIENCE
JI Neuroscience
PD MAY 21
PY 2019
VL 407
SI SI
BP 75
EP 82
DI 10.1016/j.neuroscience.2018.12.019
PG 8
WC Neurosciences
SC Neurosciences & Neurology
GA HX4SH
UT WOS:000467390100008
PM 30579832
OA Green Accepted, Other Gold
DA 2021-02-24
ER

PT J
AU Qi, ZH
   Han, M
   Wang, YX
   de los Angeles, C
   Liu, Q
   Garel, K
   San Chen, E
   Whitfield-Gabrieli, S
   Gabrieli, JDE
   Perrachione, TK
AF Qi, Zhenghan
   Han, Michelle
   Wang, Yunxin
   de los Angeles, Carlo
   Liu, Qi
   Garel, Keri
   San Chen, Ee
   Whitfield-Gabrieli, Susan
   Gabrieli, John D. E.
   Perrachione, Tyler K.
TI Speech processing and plasticity in the right hemisphere predict
   variation in adult foreign language learning
SO NEUROIMAGE
LA English
DT Article
DE fMRI; Individual differences; Language learning; Prediction; Resting
   state connectivity; Speech perception
ID WHITE-MATTER STRUCTURE; SHORT-TERM-MEMORY; FUNCTIONAL CONNECTIVITY;
   BRAIN; PITCH; PERCEPTION; FMRI; PERFORMANCE; INHIBITION; PATTERNS
AB Foreign language learning in adulthood often takes place in classrooms where learning outcomes vary widely among students, for both initial learning and long-term retention. Despite the fundamental role of speech perception in first language acquisition, its role in foreign language learning outcomes remains unknown. Using a speech discrimination functional magnetic resonance imaging (fMRI) task and resting-state fMRI before and after an intensive, classroom-based, Mandarin Chinese course, we examined how variations in pre-training organization and pre-to-post reorganization of brain functions predicted successful language learning in male and female native English-speakers. Greater pre-training activation in right inferior frontal gyrus (IFG) to Mandarin speech was associated with better Mandarin attainment at the end of the course. After four weeks of class, learners showed overall increased activation in left IFG and left superior parietal lobule (SPL) to Mandarin speech, but in neither region was variation related to learning outcomes. Immediate attainment was associated with greater preto-post reduction of right IFG activation to Mandarin speech but also greater enhancement of resting-state connectivity between this region and both left IFG and left SPL. Long-term retention of Mandarin skills measured three months later was more accurately predicted by models using features of neural preparedness (pre-training activation) and neural plasticity (pre-to-post activation change) than models using behavior preparedness and plasticity features (pre-training speech discrimination accuracy and Mandarin attainment, respectively). These findings suggest that successful holistic foreign language acquisition in human adulthood requires right IFG engagement during initial learning but right IFG disengagement for long-term retention of language skills.
C1 [Qi, Zhenghan] Univ Delaware, Dept Linguist & Cognit Sci, Newark, DE 19711 USA.
   [Qi, Zhenghan; Han, Michelle; Wang, Yunxin; de los Angeles, Carlo; Liu, Qi; Garel, Keri; San Chen, Ee; Gabrieli, John D. E.] MIT, McGovern Inst Brain Res, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Wang, Yunxin; Liu, Qi] Beijing Normal Univ, State Key Lab Cognit Neurosci & Learning, Beijing, Peoples R China.
   [Whitfield-Gabrieli, Susan] Northeastern Univ, Dept Psychol, Boston, MA 02115 USA.
   [Gabrieli, John D. E.] MIT, Dept Brain & Cognit Sci, E25-618, Cambridge, MA 02139 USA.
   [Perrachione, Tyler K.] Boston Univ, Dept Speech Language & Hearing Sci, Boston, MA 02215 USA.
RP Qi, ZH (corresponding author), Univ Delaware, 125 E Main St,Rm 103, Newark, DE 19711 USA.
EM zqi@udel.edu
RI Gabrieli, John/AAJ-2869-2020
OI Qi, Zhenghan/0000-0002-4812-8842
FU Defense Advanced Research Projects AgencyUnited States Department of
   DefenseDefense Advanced Research Projects Agency (DARPA) [DI-MISC
   80508B, H98230-07-D-0175]
FX We thank Amy S. Finn and Jennifer Minas for advice on the project
   design, and Valkyrie Felso for her contribution in data collection. We
   thank Atsushi Takahashi, Sheeba Arnold Anteraper, and Steven Shannon in
   Athinoula A. Martinos Imaging Center at McGovern Institute for Brain
   Research, Massachusetts Institute of Technology for their technical
   support. This work was supported by Defense Advanced Research Projects
   Agency DI-MISC 80508B to JDEG, Contract No. H98230-07-D-0175.
CR Avants BB, 2011, NEUROIMAGE, V54, P2033, DOI 10.1016/j.neuroimage.2010.09.025
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D., 2015, LINEAR MIXED EFFECTS
   Behzadi Y, 2007, NEUROIMAGE, V37, P90, DOI 10.1016/j.neuroimage.2007.04.042
   Bitan T, 2010, J NEUROSCI, V30, P11576, DOI 10.1523/JNEUROSCI.1245-10.2010
   Blumstein SE, 2005, J COGNITIVE NEUROSCI, V17, P1353, DOI 10.1162/0898929054985473
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Buckner RL, 2008, ANN NY ACAD SCI, V1124, P1, DOI 10.1196/annals.1440.011
   Burton MW, 2001, COGNITIVE SCI, V25, P695, DOI 10.1207/s15516709cog2505_4
   Callan DE, 2003, NEUROIMAGE, V19, P113, DOI 10.1016/S1053-8119(03)00020-X
   Carroll J., 2002, MODERN LANGUAGE APTI
   Chai XQJ, 2016, J NEUROSCI, V36, P755, DOI 10.1523/JNEUROSCI.2234-15.2016
   Chandrasekaran B, 2010, J ACOUST SOC AM, V128, P456, DOI 10.1121/1.3445785
   Chiarello C, 1996, BRAIN COGNITION, V30, P81, DOI 10.1006/brcg.1996.0006
   COOK ND, 1984, BEHAV SCI, V29, P98, DOI 10.1002/bs.3830290203
   Cooper A, 2012, J ACOUST SOC AM, V131, P4756, DOI 10.1121/1.4714355
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   Diaz B, 2008, P NATL ACAD SCI USA, V105, P16083, DOI 10.1073/pnas.0805022105
   Eickhoff SB, 2007, NEUROIMAGE, V36, P511, DOI 10.1016/j.neuroimage.2007.03.060
   Eklund A, 2016, P NATL ACAD SCI USA, V113, P7900, DOI 10.1073/pnas.1602413113
   Fedorenko E, 2011, P NATL ACAD SCI USA, V108, P16428, DOI 10.1073/pnas.1112937108
   Feinberg DA, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0015710
   Finn AS, 2008, COGNITION, V108, P477, DOI 10.1016/j.cognition.2008.04.002
   Finn AS, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00085
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   Gandour J, 2004, NEUROIMAGE, V23, P344, DOI 10.1016/j.neuroimage.2004.06.004
   Gandour J, 2002, J COGNITIVE NEUROSCI, V14, P1076, DOI 10.1162/089892902320474526
   Gaser C, 2003, J NEUROSCI, V23, P9240
   Golestani N, 2004, NEUROIMAGE, V21, P494, DOI 10.1016/j.neuroimage.2003.09.071
   Golestani N, 2007, CEREB CORTEX, V17, P575, DOI 10.1093/cercor/bhk001
   Gorgolewski Krzysztof, 2011, Front Neuroinform, V5, P13, DOI 10.3389/fninf.2011.00013
   Greve DN, 2009, NEUROIMAGE, V48, P63, DOI 10.1016/j.neuroimage.2009.06.060
   Hall DA, 1999, HUM BRAIN MAPP, V7, P213, DOI 10.1002/(SICI)1097-0193(1999)7:3<213::AID-HBM5>3.0.CO;2-N
   Herholz SC, 2016, CEREB CORTEX, V26, P3125, DOI 10.1093/cercor/bhv138
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hinkley LBN, 2016, J NEUROSCI, V36, P4522, DOI 10.1523/JNEUROSCI.3850-14.2016
   Hoeft F, 2011, P NATL ACAD SCI USA, V108, P361, DOI 10.1073/pnas.1008950108
   Hothorn T, 2008, BIOMETRICAL J, V50, P346, DOI 10.1002/bimj.200810425
   Hsieh L, 2001, BRAIN LANG, V76, P227, DOI 10.1006/brln.2000.2382
   Hyde KL, 2008, NEUROPSYCHOLOGIA, V46, P632, DOI 10.1016/j.neuropsychologia.2007.09.004
   Hyde KL, 2009, J NEUROSCI, V29, P3019, DOI 10.1523/JNEUROSCI.5118-08.2009
   Kaufman A., 2004, KAUFMAN BRIEF INTELL, V2nd
   Keshavan A., 2012, FRONT NEUROINFORM
   Kormos J, 2008, BILING-LANG COGN, V11, P261, DOI 10.1017/S1366728908003416
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhn M, 2008, J STAT SOFTW, V28, P1, DOI 10.18637/jss.v028.i05
   Linck JA, 2013, LANG LEARN, V63, P530, DOI 10.1111/lang.12011
   Liu X, 2010, NEW PRACTICAL CHINES, V1
   Loui P, 2015, ANN NY ACAD SCI, V1337, P263, DOI 10.1111/nyas.12623
   Luo H, 2006, P NATL ACAD SCI USA, V103, P19558, DOI 10.1073/pnas.0607065104
   Magne C, 2006, J COGNITIVE NEUROSCI, V18, P199, DOI 10.1162/089892906775783660
   Martensson J, 2012, NEUROIMAGE, V63, P240, DOI 10.1016/j.neuroimage.2012.06.043
   Moeller S, 2010, MAGN RESON MED, V63, P1144, DOI 10.1002/mrm.22361
   Morey RD, 2008, TUTOR QUANT METHODS, V4, P61, DOI 10.20982/tqmp.04.2.p061
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Mueller JL, 2012, P NATL ACAD SCI USA, V109, P15953, DOI 10.1073/pnas.1204319109
   Murtagh L, 2004, INT J BILINGUAL, V8, P279, DOI DOI 10.1177/13670069040080030701
   Myers EB, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00238
   Myers EB, 2012, J COGNITIVE NEUROSCI, V24, P1695, DOI 10.1162/jocn_a_00243
   Myers EB, 2009, PSYCHOL SCI, V20, P895, DOI 10.1111/j.1467-9280.2009.02380.x
   Naeser MA, 2012, ARCH PHYS MED REHAB, V93, pS26, DOI 10.1016/j.apmr.2011.04.026
   Naeser MA, 2011, BRAIN LANG, V119, P206, DOI 10.1016/j.bandl.2011.07.005
   Nicolo P, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00371
   Nir Y, 2008, NAT NEUROSCI, V11, P1100, DOI 10.1038/nn.2177
   Norman-Haignere S, 2013, J NEUROSCI, V33, P19451, DOI 10.1523/JNEUROSCI.2880-13.2013
   Perrachione TK, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00055
   Power JD, 2012, NEUROIMAGE, V59, P2142, DOI 10.1016/j.neuroimage.2011.10.018
   Qi ZH, 2015, J NEUROLINGUIST, V33, P14, DOI 10.1016/j.jneuroling.2014.08.004
   R Core Team, 2015, R LANG ENV STAT COMP
   Raichle ME, 2001, P NATL ACAD SCI USA, V98, P676, DOI 10.1073/pnas.98.2.676
   Rivera-Gaxiola M, 2005, NEUROREPORT, V16, P495, DOI 10.1097/00001756-200504040-00015
   Robinson P., 2001, SECOND LANG RES, V17, P368, DOI [DOI 10.1177/026765830101700405, 10.1177/026765830101700405]
   Schlegel AA, 2012, J COGNITIVE NEUROSCI, V24, P1664, DOI 10.1162/jocn_a_00240
   Sebastian-Galles N, 2012, LANG LEARN, V62, P131, DOI 10.1111/j.1467-9922.2012.00709.x
   Setsompop K, 2012, MAGN RESON MED, V67, P1210, DOI 10.1002/mrm.23097
   Siegel JS, 2014, HUM BRAIN MAPP, V35, P1981, DOI 10.1002/hbm.22307
   Silbert NH, 2015, J PHONETICS, V50, P99, DOI 10.1016/j.wocn.2015.03.001
   Silver M, 2011, NEUROIMAGE, V54, P992, DOI 10.1016/j.neuroimage.2010.08.049
   Smayda KE, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00682
   Smith SM, 2004, NEUROIMAGE, V23, pS208, DOI 10.1016/j.neuroimage.2004.07.051
   Smith SM, 2012, P NATL ACAD SCI USA, V109, P3131, DOI 10.1073/pnas.1121329109
   Stein M, 2012, CORTEX, V48, P458, DOI 10.1016/j.cortex.2010.10.007
   Thesen S, 2000, MAGNET RESON MED, V44, P457, DOI 10.1002/1522-2594(200009)44:3<457::AID-MRM17>3.0.CO;2-R
   van der Kouwe AJW, 2008, NEUROIMAGE, V40, P559, DOI 10.1016/j.neuroimage.2007.12.025
   Ventura-Campos N, 2013, J NEUROSCI, V33, P9295, DOI 10.1523/JNEUROSCI.4655-12.2013
   Wang Y, 2003, J COGNITIVE NEUROSCI, V15, P1019, DOI 10.1162/089892903770007407
   Whitfield-Gabrieli S, 2012, BRAIN CONNECT, V2, P125, DOI 10.1089/brain.2012.0073
   Wollman I, 2018, P NATL ACAD SCI USA, V115, pE6056, DOI 10.1073/pnas.1721414115
   Wong FCK, 2011, J NEUROSCI, V31, P8780, DOI 10.1523/JNEUROSCI.0999-11.2011
   Wong PCM, 2007, APPL PSYCHOLINGUIST, V28, P565, DOI 10.1017/S0142716407070312
   Wong PCM, 2007, HUM BRAIN MAPP, V28, P995, DOI 10.1002/hbm.20330
   Wong PCM, 2004, J NEUROSCI, V24, P9153, DOI 10.1523/JNEUROSCI.2225-04.2004
   Woolrich MW, 2009, NEUROIMAGE, V45, pS173, DOI 10.1016/j.neuroimage.2008.10.055
   Xu YS, 2006, HUM BRAIN MAPP, V27, P173, DOI 10.1002/hbm.20176
   [杨杰 Yang Jie], 2014, [材料工程, Journal of Materials Engineering], P1
   Zatorre RJ, 2008, PHILOS T R SOC B, V363, P1087, DOI 10.1098/rstb.2007.2161
   Zatorre RJ, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00544
NR 98
TC 6
Z9 6
U1 1
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD MAY 15
PY 2019
VL 192
BP 76
EP 87
DI 10.1016/j.neuroimage.2019.03.008
PG 12
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA HR9XJ
UT WOS:000463514600007
PM 30853566
DA 2021-02-24
ER

PT J
AU van Zon, A
   Smulders, YE
   Kraaijenga, VJC
   van Zanten, GA
   Stokroos, RJ
   Stegeman, I
AF van Zon, Alice
   Smulders, Yvette E.
   Kraaijenga, Veronique J. C.
   van Zanten, Gijsbert A.
   Stokroos, Robert J.
   Stegeman, Inge
TI Comparison Between Simulated and Actual Unilateral Hearing in
   Sequentially Implanted Cochlear Implant Users, a Cohort Study
SO FRONTIERS IN SURGERY
LA English
DT Article
DE cochlear implantation (CI); bilateral cochlear implantation; sequential
   bilateral cochlear implantation; sequential bilateral cochlear implant;
   cochlear implant; unilateral cochlear implant; unilateral cochlear
   implantation
ID SPEECH-INTELLIGIBILITY; ADULTS; LOCALIZATION; NOISE; PERCEPTION;
   BENEFITS
AB Introduction: Previous studies have proven the effectiveness of bilateral cochlear implantation compared to unilateral cochlear implantation. In many of these studies the unilateral hearing situation was simulated by switching off one of the cochlear implants in bilateral cochlear implant users. In the current study we assess the accuracy of this test method. Does simulated unilateral hearing (switching off one cochlear implant) result in the same outcomes as real life unilateral hearing with one cochlear implant and a non-implanted contralateral ear?
   Study design: We assessed the outcomes of one arm of a multicenter randomized controlled trial.
   Methods: In the original trial, 38 postlingually deafened adults were randomly allocated to either simultaneous bilateral cochlear implantation or sequential bilateral cochlear implantation. In the current study we used the data of the sequentially implanted group (n = 19). The primary outcome was speech perception-in-noise from straight ahead. Secondary outcomes were speech perception-in-silence, speech intelligibility-in-noise from spatially separated sources and localization capabilities. A within-subjects design was used to compare the results of hearing with one cochlear implant and a non-implanted contralateral ear (1- and 2-year follow-up) with the results of switching off one cochlear implant after sequential bilateral implantation (3-year follow-up).
   Results: We found no significant differences on any of the objective outcomes after 1-, 2-, or 3-year follow-up.
   Conclusion: This study shows that simulating unilateral hearing by switching off one cochlear implant seems a reliable method to compare unilateral and bilateral hearing in bilaterally implanted patients.
C1 [van Zon, Alice; Smulders, Yvette E.; Kraaijenga, Veronique J. C.; van Zanten, Gijsbert A.; Stokroos, Robert J.; Stegeman, Inge] Univ Med Ctr Utrecht, Dept Otorhinolaryngol Head & Neck Surg, Utrecht, Netherlands.
RP van Zon, A (corresponding author), Univ Med Ctr Utrecht, Dept Otorhinolaryngol Head & Neck Surg, Utrecht, Netherlands.
EM alicevanzon@gmail.com
RI stokroos, robert/AAC-9814-2021; Kraaijenga, Veronique/AAT-7741-2020
OI Stegeman, Inge/0000-0001-5154-7178
FU Advanced Bionics(R)
FX For this study, all centers received the second cochlear implant from
   Advanced Bionics (R). Advanced Bionics (R) in part sponsored this study.
   This company did not have any influence on the data collection, data
   analysis, data interpretation, or study design.
CR BRONKHORST AW, 1989, J ACOUST SOC AM, V86, P1374, DOI 10.1121/1.398697
   Buss E, 2008, EAR HEARING, V29, P20
   COX RM, 1981, EAR HEARING, V2, P194, DOI 10.1097/00003446-198109000-00003
   Eapen RJ, 2009, OTOL NEUROTOL, V30, P153, DOI 10.1097/MAO.0b013e3181925025
   Giolas T., 1994, HDB CLIN AUDIOLOGY, P776
   Grantham DW, 2007, EAR HEARING, V28, P524, DOI 10.1097/AUD.0b013e31806dc21a
   Kraaijenga VJC, 2017, JAMA OTOLARYNGOL, V143, P881, DOI 10.1001/jamaoto.2017.0745
   Litovsky R, 2006, EAR HEARING, V27, P714, DOI 10.1097/01.aud.0000246816.50820.42
   Litovsky RY, 2009, EAR HEARING, V30, P419, DOI 10.1097/AUD.0b013e3181a165be
   MIDDLEBROOKS JC, 1991, ANNU REV PSYCHOL, V42, P135, DOI 10.1146/annurev.ps.42.020191.001031
   Neuman AC, 2007, EAR HEARING, V28, P73, DOI 10.1097/01.aud.0000249910.80803.b9
   Ricketts TA, 2006, EAR HEARING, V27, P763, DOI 10.1097/01.aud.0000240814.27151.b9
   Smulders YE, 2016, JAMA OTOLARYNGOL, V142, P249, DOI 10.1001/jamaoto.2015.3305
   Tyler RS, 2007, EAR HEARING, V28, p86S, DOI 10.1097/AUD.0b013e31803153e2
   van Schoonhoven J, 2013, OTOL NEUROTOL, V34, P190, DOI 10.1097/MAO.0b013e318278506d
   van Zon A, 2017, LARYNGOSCOPE, V127, P1161, DOI 10.1002/lary.26239
   Verschuur CA, 2005, OTOL NEUROTOL, V26, P965, DOI 10.1097/01.mao.0000185073.81070.07
NR 17
TC 1
Z9 1
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 2296-875X
J9 FRONT SURG
JI Front. Surg.
PD MAY 8
PY 2019
VL 6
AR 24
DI 10.3389/fsurg.2019.00024
PG 5
WC Surgery
SC Surgery
GA HX6II
UT WOS:000467506900001
PM 31134209
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Creel, SC
AF Creel, Sarah C.
TI The familiar-melody advantage in auditory perceptual development:
   Parallels between spoken language acquisition and general auditory
   perception
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Music cognition; Sound recognition; Speech perception; Spoken word
   recognition
ID SPEECH-PERCEPTION; PHONETIC DETAIL; PRESCHOOLERS; INFANTS; EXPERIENCE;
   DIFFICULTY; CHILDREN; CONTOUR; WORDS; MUSIC
AB How do learners build up auditory pattern knowledge? Findings from children's spoken word learning suggest more robust auditory representations for highly familiar words than for newly learned words. This argues against spoken language learning as a process of simply acquiring a fixed set of speech sound categories, suggesting instead that specific words may be the relevant units. More generally, one might state this as the specific-learning hypothesis-that acquiring sound pattern knowledge involves learning specific patterns, rather than abstract pattern components. To understand the nature of human language knowledge, it is important to determine whether this specific learning reflects processes unique to spoken language learning or instead reflects more general auditory-learning processes. To investigate whether the specific-learning hypothesis extends to auditory pattern learning more generally, the present study tested the perceptual processing of familiar melodies versus carefully matched unfamiliar melodies. Children performed better at both audiovisual mapping (Exp. 1) and same-different auditory discrimination (Exp. 2) when hearing familiar melodies than when hearing unfamiliar melodies. This is consistent with the specific-learning hypothesis and with exemplar-style general-auditory accounts of pattern learning, although alternative explanations are possible.
C1 [Creel, Sarah C.] Univ Calif San Diego, Cognit Sci, 9500 Gilman Dr,Mail Code 0515, La Jolla, CA 92093 USA.
RP Creel, SC (corresponding author), Univ Calif San Diego, Cognit Sci, 9500 Gilman Dr,Mail Code 0515, La Jolla, CA 92093 USA.
EM screel@ucsd.edu
FU Division of Behavioral and Cognitive SciencesNational Science Foundation
   (NSF)NSF - Directorate for Social, Behavioral & Economic Sciences (SBE)
   [BCS-1057080] Funding Source: Medline
CR Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Boersma P., 2014, PRAAT DOING PHONETIC
   Corrigall KA, 2010, MUSIC PERCEPT, V28, P195, DOI 10.1525/mp.2010.28.2.195
   Creel SC, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12503
   Creel SC, 2016, COGNITIVE SCI, V40, P373, DOI 10.1111/cogs.12237
   Creel SC, 2015, TRENDS COGN SCI, V19, P713, DOI 10.1016/j.tics.2015.09.006
   Creel SC, 2014, LANG LEARN DEV, V10, P68, DOI 10.1080/15475441.2013.803871
   Creel SC, 2014, J MEM LANG, V73, P81, DOI 10.1016/j.jml.2014.03.001
   Creel SC, 2014, J EXP PSYCHOL HUMAN, V40, P1146, DOI 10.1037/a0036057
   Creel SC, 2012, J EXP CHILD PSYCHOL, V113, P487, DOI 10.1016/j.jecp.2012.07.007
   DIEHL RL, 1989, J ACOUST SOC AM, V85, P2154, DOI 10.1121/1.397864
   Doherty MJ, 2004, J CHILD LANG, V31, P203, DOI 10.1017/S030500090300583X
   DOWLING WJ, 1978, PSYCHOL REV, V85, P341, DOI 10.1037/0033-295X.85.4.341
   Fennell CT, 2003, LANG SPEECH, V46, P245, DOI 10.1177/00238309030460020901
   Fragoulis D, 2006, IEEE T AUDIO SPEECH, V14, P1040, DOI 10.1109/TSA.2005.857571
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Hay JSF, 2007, PERCEPT PSYCHOPHYS, V69, P113, DOI 10.3758/BF03194458
   IVERSON P, 1993, J ACOUST SOC AM, V94, P2595, DOI 10.1121/1.407371
   KLUENDER KR, 1988, J PHONETICS, V16, P153, DOI 10.1016/S0095-4470(19)30480-2
   KLUENDER KR, 1987, SCIENCE, V237, P1195, DOI 10.1126/science.3629235
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   LYNCH MP, 1990, PSYCHOL SCI, V1, P272, DOI 10.1111/j.1467-9280.1990.tb00213.x
   MacMillan N. A., 2005, DETECTION THEORY USE
   McFadden D, 1999, J EXP PSYCHOL HUMAN, V25, P543, DOI 10.1037/0096-1523.25.2.543
   Pajak B, 2016, J EXP PSYCHOL LEARN, V42, P1377, DOI 10.1037/xlm0000247
   R Core Team, 2014, R LANG ENV STAT COMP
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Storkel HL, 2005, J CHILD LANG, V32, P827, DOI 10.1017/S0305000905007099
   Swingley D, 2002, PSYCHOL SCI, V13, P480, DOI 10.1111/1467-9280.00485
   TRAINOR LJ, 1994, PERCEPT PSYCHOPHYS, V56, P125, DOI 10.3758/BF03213891
   TREHUB SE, 1984, CHILD DEV, V55, P821, DOI 10.2307/1130133
   Vongpaisal T, 2009, MUSIC PERCEPT, V27, P17, DOI 10.1525/MP.2009.27.1.17
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wickham H, 2016, GGPLOT2 ELEGANT GRAP
   Yeung HH, 2009, COGNITION, V113, P234, DOI 10.1016/j.cognition.2009.08.010
NR 36
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 948
EP 957
DI 10.3758/s13414-018-01663-7
PG 10
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6NQ
UT WOS:000485098800007
PM 30635834
OA Bronze
DA 2021-02-24
ER

PT J
AU Jesse, A
   Kaplan, E
AF Jesse, Alexandra
   Kaplan, Elina
TI Attentional resources contribute to the perceptual learning of talker
   idiosyncrasies in audiovisual speech
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Perceptual learning; Multisensory processing
ID SELECTIVE ADAPTATION; PHONETIC RECALIBRATION; LIPREAD SPEECH; VISUAL
   RECALIBRATION; AUDITORY SPEECH; WORKING-MEMORY; COGNITIVE LOAD;
   INFORMATION; REPRESENTATIONS; AUTOMATICITY
AB To recognize audiovisual speech, listeners evaluate and combine information obtained from the auditory and visual modalities. Listeners also use information from one modality to adjust their phonetic categories to a talker's idiosyncrasy encountered in the other modality. In this study, we examined whether the outcome of this cross-modal recalibration relies on attentional resources. In a standard recalibration experiment in Experiment 1, participants heard an ambiguous sound, disambiguated by the accompanying visual speech as either /p/ or /t/. Participants' primary task was to attend to the audiovisual speech while either monitoring a tone sequence for a target tone or ignoring the tones. Listeners subsequently categorized the steps of an auditory /p/-/t/ continuum more often in line with their exposure. The aftereffect of phonetic recalibration was reduced, but not eliminated, by attentional load during exposure. In Experiment 2, participants saw an ambiguous visual speech gesture that was disambiguated auditorily as either /p/ or /t/. At test, listeners categorized the steps of a visual /p/-/t/ continuum more often in line with the prior exposure. Imposing load in the auditory modality during exposure did not reduce the aftereffect of this type of cross-modal phonetic recalibration. Together, these results suggest that auditory attentional resources are needed for the processing of auditory speech and/or for the shifting of auditory phonetic category boundaries. Listeners thus need to dedicate attentional resources in order to accommodate talker idiosyncrasies in audiovisual speech.
C1 [Jesse, Alexandra; Kaplan, Elina] Univ Massachusetts, Dept Psychol & Brain Sci, 135 Hicks Way, Amherst, MA 01003 USA.
RP Jesse, A (corresponding author), Univ Massachusetts, Dept Psychol & Brain Sci, 135 Hicks Way, Amherst, MA 01003 USA.
EM ajesse@psych.umass.edu
CR Adank P, 2010, PSYCHOL AGING, V25, P736, DOI 10.1037/a0020054
   Alais D, 2006, P R SOC B, V273, P1339, DOI 10.1098/rspb.2005.3420
   Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Alsius A, 2007, EXP BRAIN RES, V183, P399, DOI 10.1007/s00221-007-1110-1
   Alsius A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00727
   [Anonymous], 2014, R LANG ENV STAT COMP
   Arrighi R, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00056
   Baart M, 2012, ACTA PSYCHOL, V140, P91, DOI 10.1016/j.actpsy.2012.03.003
   Baart M, 2010, EXP BRAIN RES, V203, P575, DOI 10.1007/s00221-010-2264-9
   Baart M, 2010, NEUROSCI LETT, V471, P100, DOI 10.1016/j.neulet.2010.01.019
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Berman RA, 2002, COGNITIVE BRAIN RES, V14, P64, DOI 10.1016/S0926-6410(02)00061-7
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Brancazio L, 2005, PERCEPT PSYCHOPHYS, V67, P759, DOI 10.3758/BF03193531
   Chun MM, 2011, ANNU REV PSYCHOL, V62, P73, DOI 10.1146/annurev.psych.093008.100427
   Colin C, 2002, CLIN NEUROPHYSIOL, V113, P495, DOI 10.1016/S1388-2457(02)00024-X
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Dias JW, 2016, J PHONETICS, V56, P75, DOI 10.1016/j.wocn.2016.02.004
   DIEHL RL, 1975, PERCEPT PSYCHOPHYS, V17, P48, DOI 10.3758/BF03203996
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   Heald SLM, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00698
   Houghton RJ, 2003, J EXP PSYCHOL HUMAN, V29, P731, DOI 10.1037/0096-1523.29.4.731
   Huyck JJ, 2012, J ACOUST SOC AM, V131, pEL236, DOI 10.1121/1.3685511
   Jaeggi SM, 2010, MEMORY, V18, P394, DOI 10.1080/09658211003702171
   Janse E, 2012, Q J EXP PSYCHOL, V65, P1563, DOI 10.1080/17470218.2012.658822
   Jesse A., 2000, INTERPRETING, V5, P95, DOI [DOI 10.1075/INTP.5.2.04JES, 10.1075/intp.5.2.04jes]
   Jesse A, 2018, COGNITION, V176, P195, DOI 10.1016/j.cognition.2018.03.018
   Jesse A, 2010, ATTEN PERCEPT PSYCHO, V72, P209, DOI 10.3758/APP.72.1.209
   KAHNEMAN D, 1983, J EXP PSYCHOL HUMAN, V9, P497, DOI 10.1037/0096-1523.9.4.497
   Kajander D, 2016, ABSTRACTS PSYCHONOMI, V21, P114
   Keetels M, 2016, J PHONETICS, V56, P124, DOI 10.1016/j.wocn.2016.02.005
   Keetels M, 2015, COGNITION, V141, P121, DOI 10.1016/j.cognition.2015.04.019
   Kilian-Hutten N, 2011, NEUROIMAGE, V57, P1601, DOI 10.1016/j.neuroimage.2011.05.043
   LAVIE N, 1994, PERCEPT PSYCHOPHYS, V56, P183, DOI 10.3758/BF03213897
   LAVIE N, 1995, J EXP PSYCHOL HUMAN, V21, P451, DOI 10.1037/0096-1523.21.3.451
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   Massaro D. W., 1998, PERCEIVING TALKING F
   Massaro D. W., 1987, SPEECH PERCEPTION EA
   Mattys SL, 2015, J ACOUST SOC AM, V137, P1464, DOI 10.1121/1.4913507
   Mattys SL, 2014, PSYCHON B REV, V21, P748, DOI 10.3758/s13423-013-0544-7
   Mattys SL, 2011, J MEM LANG, V65, P145, DOI 10.1016/j.jml.2011.04.004
   Murphy G, 2017, APPL COGNITIVE PSYCH, V31, P258, DOI 10.1002/acp.3311
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Prabhakaran V, 2000, NAT NEUROSCI, V3, P85, DOI 10.1038/71156
   Rees G, 2001, NEUROPSYCHOLOGIA, V39, P937, DOI 10.1016/S0028-3932(01)00016-1
   Reisberg D, 1987, HEARING EYE PSYCHOL, P97
   ROBERTS M, 1981, PERCEPT PSYCHOPHYS, V30, P309, DOI 10.3758/BF03206144
   Rosenblum LD, 1996, J EXP PSYCHOL HUMAN, V22, P318, DOI 10.1037/0096-1523.22.2.318
   SALDANA HM, 1994, J ACOUST SOC AM, V95, P3658, DOI 10.1121/1.409935
   Samuel AG, 1998, PERCEPT PSYCHOPHYS, V60, P503, DOI 10.3758/BF03206870
   Samuel AG, 2016, COGNITIVE PSYCHOL, V88, P88, DOI 10.1016/j.cogpsych.2016.06.007
   Samuel AG, 2014, J EXP PSYCHOL HUMAN, V40, P1479, DOI 10.1037/a0036656
   Santangelo V, 2007, J EXP PSYCHOL HUMAN, V33, P1311, DOI 10.1037/0096-1523.33.6.1311
   Scharenborg O, 2014, ATTEN PERCEPT PSYCHO, V77, P493
   Seitz AR, 2010, COGNITION, V115, P435, DOI 10.1016/j.cognition.2010.03.004
   Sinnett S, 2018, Q J EXPT PSYCHOL, V59, P1425
   Soto-Faraco S, 2004, COGNITION, V92, pB13, DOI 10.1016/j.cognition.2003.10.005
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1984, Q J EXP PSYCHOL-A, V36, P51, DOI 10.1080/14640748408401503
   SUSSMAN JE, 1993, J ACOUST SOC AM, V93, P488, DOI 10.1121/1.405629
   THEEUWES J, 1991, PERCEPT PSYCHOPHYS, V49, P83, DOI 10.3758/BF03211619
   Tiippana K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00725
   Tuomainen J, 2005, COGNITION, V96, pB13, DOI 10.1016/j.cognition.2004.10.004
   van der Zande P, 2014, J PHONETICS, V43, P38, DOI 10.1016/j.wocn.2014.01.003
   van der Zande P, 2013, J ACOUST SOC AM, V134, P562, DOI 10.1121/1.4807814
   Van Linden S, 2008, J CHILD LANG, V35, P809, DOI 10.1017/S0305000908008817
   van Linden S, 2007, J EXP PSYCHOL HUMAN, V33, P1483, DOI 10.1037/0096-1523.33.6.1483
   Vroomen J, 2004, SPEECH COMMUN, V44, P55, DOI 10.1016/j.specom.2004.03.009
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
   Vroomen J, 2009, LANG SPEECH, V52, P341, DOI 10.1177/0023830909103178
   Vroomen J, 2009, COGNITION, V110, P254, DOI 10.1016/j.cognition.2008.10.015
   Wahn B, 2017, ADV COGN PSYCHOL, V13, P83, DOI 10.5709/acp-0209-2
   Wahn B, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669516688026
   Wahn B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01084
   WALDEN BE, 1974, J SPEECH HEAR RES, V17, P270, DOI 10.1044/jshr.1702.270
   Wilhelm O, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00433
   Wong PCM, 2004, J COGNITIVE NEUROSCI, V16, P1173, DOI 10.1162/0898929041920522
   Woodman GF, 2007, CEREB CORTEX, V17, pI118, DOI 10.1093/cercor/bhm065
   Wright BA, 2010, J NEUROSCI, V30, P12868, DOI 10.1523/JNEUROSCI.0487-10.2010
   Yakel DA, 2000, PERCEPT PSYCHOPHYS, V62, P1405, DOI 10.3758/BF03212142
   YANTIS S, 1984, J EXP PSYCHOL HUMAN, V10, P601, DOI 10.1037/0096-1523.10.5.601
   Zhang XJ, 2014, J EXP PSYCHOL HUMAN, V40, P200, DOI 10.1037/a0033182
NR 85
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 1006
EP 1019
DI 10.3758/s13414-018-01651-x
PG 14
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6NQ
UT WOS:000485098800010
PM 30684204
OA Bronze
DA 2021-02-24
ER

PT J
AU Lau, JCY
   Wong, PCM
   Chandrasekaran, B
AF Lau, Joseph C. Y.
   Wong, Patrick C. M.
   Chandrasekaran, Bharath
TI Interactive effects of linguistic abstraction and stimulus statistics in
   the online modulation of neural speech encoding
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Neural speech encoding; Frequency-following response (FFR); Lexical
   tone; Context-dependent plasticity; Linguistic abstraction; Allotones
ID AUDITORY BRAIN-STEM; FREQUENCY-FOLLOWING RESPONSE; CORTICAL
   ORGANIZATION; INFERIOR COLLICULUS; WORD; PERCEPTION; PLASTICITY;
   CONTEXT; REPRESENTATION; PROBABILITY
AB Speech processing is highly modulated by context. Prior studies examining frequency-following responses (FFRs), an electrophysiological neurophonic' potential that faithfully reflects phase-locked activity from neural ensembles within the auditory network, have demonstrated that stimulus context modulates the integrity of speech encoding. The extent to which context-dependent encoding reflects general auditory properties or interactivities between statistical and higher-level linguistic processes remains unexplored. Our study examined whether speech encoding, as reflected by FFRs, is modulated by abstract phonological relationships between a stimulus and surrounding contexts. FFRs were elicited to a Mandarin rising-tone syllable (/ji-TR/, second') randomly presented with other syllables in three contexts from 17 native listeners. In a contrastive context, /ji-TR/ occurred with meaning-contrastive high-level-tone syllables (/ji-H/, one'). In an allotone context, TR occurred with dipping-tone syllables /ji-D/, a non-meaning-contrastive variant of /ji-TR/. In a repetitive context, the same /ji-TR/ occurred with other speech tokens of /ji-TR/. Consistent with prior work, neural tracking of /ji-TR/ pitch contour was more faithful in the repetitive condition wherein /ji-TR/ occurred more predictably (p =1) than in the contrastive condition (p =0.34). Crucially, in the allotone context, neural tracking of /ji-TR/ was more accurate relative to the contrastive context, despite both having an identical transitional probability (p =0.34). Mechanistically, the non-meaning-contrastive relationship may have augmented the probability to /ji-TR/ occurrence in the allotone context. Results indicate online interactions between bottom-up and top-down mechanisms, which facilitate speech perception. Such interactivities may predictively fine-tune incoming speech encoding using linguistic and statistical information from prior context.
C1 [Lau, Joseph C. Y.; Wong, Patrick C. M.] Chinese Univ Hong Kong, Dept Linguist & Modern Languages, Shatin, Hong Kong, Peoples R China.
   [Lau, Joseph C. Y.; Wong, Patrick C. M.] Chinese Univ Hong Kong, Brain & Mind Inst, Shatin, Hong Kong, Peoples R China.
   [Chandrasekaran, Bharath] Univ Pittsburgh, Dept Commun Sci & Disorders, Sch Hlth & Rehabil Sci, Pittsburgh, PA USA.
RP Wong, PCM (corresponding author), Chinese Univ Hong Kong, Dept Linguist & Modern Languages, Shatin, Hong Kong, Peoples R China.; Wong, PCM (corresponding author), Chinese Univ Hong Kong, Brain & Mind Inst, Shatin, Hong Kong, Peoples R China.
EM p.wong@cuhk.edu.hk; b.chandra@pitt.edu
OI Chandrasekaran, Bharath/0000-0002-3673-9435; Wong,
   Patrick/0000-0002-6105-5027
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [1R01-DC-013315]; Research Grants
   Council of Hong Kong General Research FundHong Kong Research Grants
   Council [14117514]; Global Parent Child Resource Centre Limited; Lui Che
   Woo Institute of Innovative Medicine; Dr. Stanley Ho Medical Development
   Foundation
FX This work was supported by the National Institute on Deafness and Other
   Communication Disorders Grant 1R01-DC-013315 (to B. Chandrasekaran),
   Research Grants Council of Hong Kong General Research Fund 14117514 (to
   P.C.M. Wong), Global Parent Child Resource Centre Limited (to P.C.M.
   Wong), Lui Che Woo Institute of Innovative Medicine (to P.C.M. Wong),
   and Dr. Stanley Ho Medical Development Foundation (to P.C.M. Wong). We
   also wish to thank Christopher Chan, Kirin Cheung, Tianfan Liu, Grace
   Pan, Binghui Shen, Xiaohui Sun, and Yi Wu for their assistance with data
   collection.
CR Anderson LA, 2013, EUR J NEUROSCI, V37, P52, DOI 10.1111/ejn.12018
   Bidelman GM, 2018, NEUROIMAGE, V175, P56, DOI 10.1016/j.neuroimage.2018.03.060
   Bidelman GM, 2015, HEARING RES, V323, P68, DOI 10.1016/j.heares.2015.01.011
   Bidelman GM, 2011, BRAIN COGNITION, V77, P1, DOI 10.1016/j.bandc.2011.07.006
   Boersma P., 2014, PRAAT DOING PHONETIC
   Chandrasekaran B, 2014, BRAIN TOPOGR, V27, P539, DOI 10.1007/s10548-013-0323-9
   Chandrasekaran B, 2010, J ACOUST SOC AM, V128, P456, DOI 10.1121/1.3445785
   Chandrasekaran B, 2009, NEURON, V64, P311, DOI 10.1016/j.neuron.2009.10.006
   Chandrasekaran B, 2010, PSYCHOPHYSIOLOGY, V47, P236, DOI 10.1111/j.1469-8986.2009.00928.x
   Chien YF, 2016, LANG COGN NEUROSCI, V31, P179, DOI 10.1080/23273798.2015.1064976
   Coffey E. B., 2016, NATURE COMMUNICATION, V7
   Coffey EBJ, 2017, J NEUROSCI, V37, P830, DOI 10.1523/JNEUROSCI.1265-16.2016
   CONNOLLY JF, 1994, J COGNITIVE NEUROSCI, V6, P256, DOI 10.1162/jocn.1994.6.3.256
   Denham S. L., 2017, EUROPEAN J NEUROSCIE
   Diaz MT, 2007, BRAIN RES, V1146, P85, DOI 10.1016/j.brainres.2006.07.034
   Diehl R. L., 1987, PSYCHOPHYSICS SPEECH, P39
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Escera C, 2003, EUR J NEUROSCI, V18, P2408, DOI 10.1046/j.1460-9568.2003.02937.x
   Eulitz C, 2004, J COGNITIVE NEUROSCI, V16, P577, DOI 10.1162/089892904323057308
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8
   Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Gaskell MG, 2002, COGNITIVE PSYCHOL, V45, P220
   GIARD MH, 1990, PSYCHOPHYSIOLOGY, V27, P627, DOI 10.1111/j.1469-8986.1990.tb03184.x
   Hagoort P, 2000, NEUROPSYCHOLOGIA, V38, P1518, DOI 10.1016/S0028-3932(00)00052-X
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2012, J COMMUN DISORD, V45, P393, DOI 10.1016/j.jcomdis.2012.06.004
   Holt L. L., 1998, CHICAGO LINGUISTIC S, P253
   Jaaskelainen IP, 2004, P NATL ACAD SCI USA, V101, P6809, DOI 10.1073/pnas.0303760101
   Kraus N, 2017, SPRINGER HANDB AUDIT, V61, P1, DOI 10.1007/978-3-319-47944-6_1
   Kraus N, 2015, TRENDS COGN SCI, V19, P642, DOI 10.1016/j.tics.2015.08.017
   Krishnan A, 2004, HEARING RES, V189, P1, DOI 10.1016/S0378-5955(03)00402-7
   Krishnan A, 2009, BRAIN LANG, V110, P135, DOI 10.1016/j.bandl.2009.03.005
   Lau EF, 2008, NAT REV NEUROSCI, V9, P920, DOI 10.1038/nrn2532
   Lau JCY, 2017, J NEUROPHYSIOL, V117, P594, DOI 10.1152/jn.00656.2016
   Li XQ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0143097
   Liu F, 2015, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.01029
   Lopez-Caballero F, 2016, BIOL PSYCHOL, V120, P1, DOI 10.1016/j.biopsycho.2016.08.001
   Lotto AJ, 2000, PHONETICA, V57, P189, DOI 10.1159/000028472
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Lupyan G, 2015, CURR DIR PSYCHOL SCI, V24, P279, DOI 10.1177/0963721415570732
   Malmierca MS, 2015, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00019
   Malmierca MS, 2009, J NEUROSCI, V29, P5483, DOI 10.1523/JNEUROSCI.4153-08.2009
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Natan RG, 2015, ELIFE, V4, DOI [10.7554/eLife.09868, 10.7554/eLife.09868.001]
   Nourski KV, 2017, NEUROIMAGE, V152, P78, DOI 10.1016/j.neuroimage.2017.02.061
   Nusbaum H.C., 1997, TALKER VARIABILITY S, P109
   Parbery-Clark A, 2011, NEUROPSYCHOLOGIA, V49, P3338, DOI 10.1016/j.neuropsychologia.2011.08.007
   Perez-Gonzalez D, 2005, EUR J NEUROSCI, V22, P2879, DOI 10.1111/j.1460-9568.2005.04472.x
   Politzer-Ahles S., 2012, P M AC 164ASA, V18
   Politzer-Ahles S, 2016, J EXP PSYCHOL HUMAN, V42, P1547, DOI 10.1037/xhp0000242
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rubin J, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1005058
   Russo N, 2004, CLIN NEUROPHYSIOL, V115, P2021, DOI 10.1016/j.clinph.2004.04.003
   SHEN XNS, 1991, LANG SPEECH, V34, P145, DOI 10.1177/002383099103400202
   Skoe E, 2014, NEUROBIOL LEARN MEM, V109, P82, DOI 10.1016/j.nlm.2013.11.011
   Skoe E, 2010, EAR HEARING, V31, P302, DOI 10.1097/AUD.0b013e3181cdb272
   Slabu L, 2012, J NEUROSCI, V32, P1447, DOI 10.1523/JNEUROSCI.2557-11.2012
   SLOWIACZEK LM, 1987, J EXP PSYCHOL LEARN, V13, P64, DOI 10.1037/0278-7393.13.1.64
   Song JH, 2008, J COGNITIVE NEUROSCI, V20, P1892, DOI 10.1162/jocn.2008.20131
   Strait DL, 2012, BRAIN LANG, V123, P191, DOI 10.1016/j.bandl.2012.09.001
   Strait DL, 2011, BEHAV BRAIN FUNCT, V7, DOI 10.1186/1744-9081-7-44
   Suga N, 2008, J COMP PHYSIOL A, V194, P169, DOI 10.1007/s00359-007-0274-2
   Szefer JM, 2011, P IEEE RAP SYST PROT, P38, DOI 10.1109/RSP.2011.5929973
   WHALEN DH, 1992, PHONETICA, V49, P25, DOI 10.1159/000261901
   Winer JA, 1998, J COMP NEUROL, V400, P147
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Wong PCM, 2003, J SPEECH LANG HEAR R, V46, P413, DOI 10.1044/1092-4388(2003/034)
   Xie ZL, 2018, NEUROSCIENCE, V384, P64, DOI 10.1016/j.neuroscience.2018.05.023
   Xie ZL, 2017, J NEUROPHYSIOL, V117, P1407, DOI 10.1152/jn.00445.2016
   Yip M., 2002, TONE
   Zhang CC, 2015, J NEUROLINGUIST, V33, P149, DOI 10.1016/j.jneuroling.2014.07.002
   Zhou XL, 1997, COGNITIVE PROCESSING OF CHINESE AND RELATED ASIAN LANGUAGES, P3
NR 76
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 1020
EP 1033
DI 10.3758/s13414-018-1621-9
PG 14
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6NQ
UT WOS:000485098800011
PM 30565097
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Carney, LH
   McDonough, JM
AF Carney, Laurel H.
   McDonough, Joyce M.
TI Nonlinear auditory models yield new insights into representations of
   vowels
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Audition; Speech perception; Physiological psychology
ID NERVE FIBERS; PHENOMENOLOGICAL MODEL; HAIR-CELLS; VERTICAL-BAR;
   RESPONSES; INNER; SIMULATION; EPSILON; COCHLEA; CAT
AB Studies of vowel systems regularly appeal to the need to understand how the auditory system encodes and processes the information in the acoustic signal. The goal of this study is to present computational models to address this need, and to use the models to illustrate responses to vowels at two levels of the auditory pathway. Many of the models previously used to study auditory representations of speech are based on linear filter banks simulating the tuning of the inner ear. These models do not incorporate key nonlinear response properties of the inner ear that influence responses at conversational-speech sound levels. These nonlinear properties shape neural representations in ways that are important for understanding responses in the central nervous system. The model for auditory-nerve (AN) fibers used here incorporates realistic nonlinear properties associated with the basilar membrane, inner hair cells (IHCs), and the IHC-AN synapse. These nonlinearities set up profiles of f0-related fluctuations that vary in amplitude across the population of frequency-tuned AN fibers. Amplitude fluctuations in AN responses are smallest near formant peaks and largest at frequencies between formants. These f0-related fluctuations strongly excite or suppress neurons in the auditory midbrain, the first level of the auditory pathway where tuning for low-frequency fluctuations in sounds occurs. Formant-related amplitude fluctuations provide representations of the vowel spectrum in discharge rates of midbrain neurons. These representations in the midbrain are robust across a wide range of sound levels, including the entire range of conversational-speech levels, and in the presence of realistic background noise levels.
C1 [Carney, Laurel H.] Univ Rochester, Dept Biomed Engn, 601 Elmwood Ave,Box 603, Rochester, NY 14642 USA.
   [Carney, Laurel H.] Univ Rochester, Dept Neurosci, 601 Elmwood Ave,Box 603, Rochester, NY 14642 USA.
   [McDonough, Joyce M.] Univ Rochester, Dept Linguist, Rochester, NY USA.
RP Carney, LH (corresponding author), Univ Rochester, Dept Biomed Engn, 601 Elmwood Ave,Box 603, Rochester, NY 14642 USA.; Carney, LH (corresponding author), Univ Rochester, Dept Neurosci, 601 Elmwood Ave,Box 603, Rochester, NY 14642 USA.
EM Laurel.Carney@Rochester.edu
OI Carney, Laurel/0000-0002-4729-5702
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [NIDCD R01-001641];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC001641, R01DC001641, R01DC001641,
   R01DC001641, R01DC001641] Funding Source: NIH RePORTER
FX Supported by National Institutes of Health Grant #NIDCD R01-001641. This
   project received a boost of energy from a fascinating conversation with
   Professor Bjorn Lindblom at the University of Stockholm. He also
   arranged for us to attend the workshop in honor of Professor Randy Diehl
   at the University of Texas at Austin, which further inspired this
   effort. Professor Kenneth Henry at the University of Rochester suggested
   the modification of the midbrain model for convenient BMF tuning.
CR Becker-Kristal R., 2010, THESIS
   BYRNE D, 1994, J ACOUST SOC AM, V96, P2108, DOI 10.1121/1.410152
   Carlson R, 1982, REPRESENTATION SPEEC, P109
   Carney LH, 2018, JARO-J ASSOC RES OTO, V19, P331, DOI 10.1007/s10162-018-0669-5
   Carney LH, 2015, ENEURO, V2, DOI 10.1523/ENEURO.0004-15.2015
   Carney LH, 2016, ADV EXP MED BIOL, V894, P427, DOI 10.1007/978-3-319-25474-6_45
   CARNEY LH, 1993, J ACOUST SOC AM, V93, P401, DOI 10.1121/1.405620
   CODY AR, 1992, HEARING RES, V62, P166, DOI 10.1016/0378-5955(92)90182-M
   Crothers J, 1978, UNIVERSALS HUMAN LAN, V2, P99
   DALLOS P, 1986, HEARING RES, V22, P185, DOI 10.1016/0378-5955(86)90095-X
   DALLOS P, 1985, J NEUROSCI, V5, P1591
   DELGUTTE B, 1984, J ACOUST SOC AM, V75, P866, DOI 10.1121/1.390596
   Delgutte B., 1996, AUDITORY COMPUTATION, P157, DOI [10.1007/978-1-4612-4070-9_5, DOI 10.1007/978-1-4612-4070-9_5]
   Delgutte B., 1987, PSYCHOPHYSICS SPEECH, V39, P333
   DENG L, 1987, J ACOUST SOC AM, V82, P1989, DOI 10.1121/1.395643
   Diehl R, 2003, CAUSAL PUBLICATIONS, V2, P1381
   Diehl R. L., 1989, ECOL PSYCHOL, V1, P121, DOI [10.1207/s15326969-co0102_2, DOI 10.1207/S15326969-CO0102_2, DOI 10.1207/s15326969eco0102_2]
   Diehl R. L., 1991, COGNITION SYMBOLIC P, V3, P59
   Diehl RL, 2008, PHILOS T R SOC B, V363, P965, DOI 10.1098/rstb.2007.2153
   Diehl Randy L., 2004, VVolume 18, P101
   Diehl RL, 2000, PHONETICA, V57, P267, DOI 10.1159/000028479
   Disner S, 1984, CAMBRIDGE STUDIES SP
   Ghosh PK, 2011, J ACOUST SOC AM, V129, P4014, DOI 10.1121/1.3573987
   Guinan JJ, 2011, SPRINGER HANDB AUDIT, V38, P39, DOI 10.1007/978-1-4419-7070-1_3
   Henry KS, 2017, JARO-J ASSOC RES OTO, V18, P165, DOI 10.1007/s10162-016-0594-4
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hillenbrand JM, 1999, J ACOUST SOC AM, V105, P3509, DOI 10.1121/1.424676
   HOWARD J, 1988, ANNU REV BIOPHYS BIO, V17, P99
   Hudspeth AJ, 2014, NAT REV NEUROSCI, V15, P600, DOI 10.1038/nrn3786
   Ibrahim RA, 2010, NEUROPHYSIOLOGICAL BASES OF AUDITORY PERCEPTION, P429, DOI 10.1007/978-1-4419-5686-6_40
   Joris PX, 2004, PHYSIOL REV, V84, P541, DOI 10.1152/physrev.00029.2003
   KEITHLEY EM, 1987, J ACOUST SOC AM, V81, P1036, DOI 10.1121/1.394675
   KIM DO, 1986, HEARING RES, V22, P105, DOI 10.1016/0378-5955(86)90088-2
   KINGSTON J, 1994, LANGUAGE, V70, P419, DOI 10.2307/416481
   LANGNER G, 1988, J NEUROPHYSIOL, V60, P1799
   LIBERMAN MC, 1978, J ACOUST SOC AM, V63, P442, DOI 10.1121/1.381736
   LILJENCRANTS J, 1972, LANGUAGE, V48, P839, DOI 10.2307/411991
   LINDBLOM B., 1986, EXPT PHONOLOGY, P13
   Lindblom Bjorn, 1988, LANGUAGE SPEECH MIND, P62
   Miller RL, 1997, J ACOUST SOC AM, V101, P3602, DOI 10.1121/1.418321
   Nearey TM, 1997, J ACOUST SOC AM, V101, P3241, DOI 10.1121/1.418290
   Nelson PC, 2007, J NEUROPHYSIOL, V97, P522, DOI 10.1152/jn.00776.2006
   Nelson PC, 2004, J ACOUST SOC AM, V116, P2173, DOI 10.1121/1.1784442
   Plomp R, 1970, FREQUENCY ANAL PERIO, P397
   Rao A, 2014, IEEE T BIO-MED ENG, V61, P2081, DOI 10.1109/TBME.2014.2313618
   RUGGERO MA, 1992, J NEUROPHYSIOL, V68, P1087
   RUSSELL IJ, 1983, J PHYSIOL-LONDON, V338, P179, DOI 10.1113/jphysiol.1983.sp014668
   RUSSELL IJ, 1986, NATURE, V321, P517, DOI 10.1038/321517a0
   SACHS MB, 1980, J ACOUST SOC AM, V68, P858, DOI 10.1121/1.384825
   Schwartz JL, 1997, J PHONETICS, V25, P255, DOI 10.1006/jpho.1997.0043
   Schwartz JL, 1997, J PHONETICS, V25, P233, DOI 10.1006/jpho.1997.0044
   Shera CA, 2002, P NATL ACAD SCI USA, V99, P3318, DOI 10.1073/pnas.032675099
   Stevens Kenneth N., 1972, HUMAN COMMUNICATION, P51
   STEVENS KN, 1989, J PHONETICS, V17, P3, DOI 10.1016/S0095-4470(19)31520-7
   Terreros G, 2015, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00134
   Zeddies DG, 2004, J ACOUST SOC AM, V116, P426, DOI 10.1121/1.1755237
   Zhang XD, 2001, J ACOUST SOC AM, V109, P648, DOI 10.1121/1.1336503
   Zilany MSA, 2007, J ACOUST SOC AM, V122, P402, DOI 10.1121/1.2735117
   Zilany MSA, 2006, J ACOUST SOC AM, V120, P1446, DOI 10.1121/1.2225512
   Zilany MSA, 2014, J ACOUST SOC AM, V135, P283, DOI 10.1121/1.4837815
   Zilany MSA, 2009, J ACOUST SOC AM, V126, P2390, DOI 10.1121/1.3238250
NR 61
TC 2
Z9 2
U1 1
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 1034
EP 1046
DI 10.3758/s13414-018-01644-w
PG 13
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6NQ
UT WOS:000485098800012
PM 30565098
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Lim, SJ
   Shinn-Cunningham, BG
   Perrachione, TK
AF Lim, Sung-Joo
   Shinn-Cunningham, Barbara G.
   Perrachione, Tyler K.
TI Effects of talker continuity and speech rate on auditory working memory
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Talker adaptation; Speech perception; Auditory working memory; Recall
   efficiency; Aditory streaming
ID SHORT-TERM-MEMORY; SPOKEN-WORD RECOGNITION; STIMULUS VARIABILITY; STREAM
   SEGREGATION; TIME-COURSE; PERCEPTION; ATTENTION; INFORMATION; VOICE;
   NORMALIZATION
AB Speech processing is slower and less accurate when listeners encounter speech from multiple talkers compared to one continuous talker. However, interference from multiple talkers has been investigated only using immediate speech recognition or long-term memory recognition tasks. These tasks reveal opposite effects of speech processing time on speech recognition - while fast processing of multi-talker speech impedes immediate recognition, it also results in more abstract and less talker-specific long-term memories for speech. Here, we investigated whether and how processing multi-talker speech disrupts working memory maintenance, an intermediate stage between perceptual recognition and long-term memory. In a digit sequence recall task, listeners encoded seven-digit sequences and recalled them after a 5-s delay. Sequences were spoken by either a single talker or multiple talkers at one of three presentation rates (0-, 200-, and 500-ms inter-digit intervals). Listeners' recall was slower and less accurate for sequences spoken by multiple talkers than a single talker. Especially for the fastest presentation rate, listeners were less efficient when recalling sequences spoken by multiple talkers. Our results reveal that talker-specificity effects for speech working memory are most prominent when listeners must rapidly encode speech. These results suggest that, like immediate speech recognition, working memory for speech is susceptible to interference from variability across talkers. While many studies ascribe effects of talker variability to the need to calibrate perception to talker-specific acoustics, these results are also consistent with the idea that a sudden change of talkers disrupts attentional focus, interfering with efficient working-memory processing.
C1 [Lim, Sung-Joo; Perrachione, Tyler K.] Boston Univ, Dept Speech Language & Hearing Sci, 635 Commonwealth Ave, Boston, MA 02215 USA.
   [Lim, Sung-Joo; Shinn-Cunningham, Barbara G.] Boston Univ, Biomed Engn, Boston, MA 02215 USA.
RP Lim, SJ (corresponding author), Boston Univ, Dept Speech Language & Hearing Sci, 635 Commonwealth Ave, Boston, MA 02215 USA.; Lim, SJ (corresponding author), Boston Univ, Biomed Engn, Boston, MA 02215 USA.
EM sungjoo@bu.edu
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R03DC014045, R01DC009477,
   T32DC013017]; Brain and Behavioral Research Foundation NARSAD Young
   Investigator grant; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [T32DC013017,
   T32DC013017, R03DC014045, T32DC013017, T32DC013017] Funding Source: NIH
   RePORTER
FX This work was supported by NIH grant R03DC014045 and a Brain and
   Behavioral Research Foundation NARSAD Young Investigator grant to TKP
   and NIH grant R01DC009477 to BGSC. SJL was supported by NIH training
   grant T32DC013017. We thank Yaminah Carter for her assistance.
CR Antoniou M, 2015, J ACOUST SOC AM, V138, P571, DOI 10.1121/1.4923362
   Baddeley A, 2003, NAT REV NEUROSCI, V4, P829, DOI 10.1038/nrn1201
   Baddeley A, 2010, CURR BIOL, V20, pR136, DOI 10.1016/j.cub.2009.12.014
   Best V, 2008, P NATL ACAD SCI USA, V105, P13174, DOI 10.1073/pnas.0803718105
   Bizley JK, 2013, NAT REV NEUROSCI, V14, P693, DOI 10.1038/nrn3565
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P206, DOI 10.3758/BF03206883
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   BREGMAN AS, 1971, J EXP PSYCHOL, V89, P244, DOI 10.1037/h0031163
   Bressler S, 2014, PSYCHOL RES-PSYCH FO, V78, P349, DOI 10.1007/s00426-014-0555-7
   Bruyer R, 2011, PSYCHOL BELG, V51, P5, DOI 10.5334/pb-51-1-5
   Chambers J. M., 1992, STAT MODELS S
   Chandrasekaran B, 2011, J COGNITIVE NEUROSCI, V23, P2690, DOI 10.1162/jocn.2011.21631
   Choi JY, 2018, ATTEN PERCEPT PSYCHO, V80, P784, DOI 10.3758/s13414-017-1395-5
   Conway ARA, 2002, INTELLIGENCE, V30, P163, DOI 10.1016/S0160-2896(01)00096-4
   Cowan N, 2008, PROG BRAIN RES, V169, P323, DOI 10.1016/S0079-6123(07)00020-9
   CRAIK FIM, 1974, Q J EXP PSYCHOL, V26, P274, DOI 10.1080/14640747408400413
   Darwin C. J., 1995, HDB PERCEPTION COGNI, P387, DOI DOI 10.1016/B978-012505626-7/50013-3
   Darwin CJ, 2000, J ACOUST SOC AM, V107, P970, DOI 10.1121/1.428278
   Engle RW, 1999, J EXP PSYCHOL GEN, V128, P309, DOI 10.1037/0096-3445.128.3.309
   Evans BG, 2004, J ACOUST SOC AM, V115, P352, DOI 10.1121/1.1635413
   GEISELMAN RE, 1977, MEM COGNITION, V5, P658, DOI 10.3758/BF03197412
   GOLDINGER SD, 1991, J EXP PSYCHOL LEARN, V17, P152, DOI 10.1037/0278-7393.17.1.152
   Green KP, 1997, PERCEPT PSYCHOPHYS, V59, P675, DOI 10.3758/BF03206015
   Griffiths TD, 2004, NAT REV NEUROSCI, V5, P887, DOI 10.1038/nrn1538
   Heald SLM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00781
   Heald SLM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00035
   Hickok G, 2009, PHYS LIFE REV, V6, P121, DOI 10.1016/j.plrev.2009.06.001
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Huang JY, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00010
   Jacquemot C, 2006, TRENDS COGN SCI, V10, P480, DOI 10.1016/j.tics.2006.09.002
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Joseph S, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00013
   Kane MJ, 2001, J EXP PSYCHOL GEN, V130, P169, DOI 10.1037/0096-3445.130.2.169
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Lakatos P, 2013, NEURON, V77, P750, DOI 10.1016/j.neuron.2012.11.034
   LIBERMAN AM, 1956, J EXP PSYCHOL, V52, P127, DOI 10.1037/h0041240
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Lim SJ, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00184
   Lim SJ, 2015, J NEUROSCI, V35, P16094, DOI 10.1523/JNEUROSCI.2674-15.2015
   Luce PA, 2005, BLACKW HBK LINGUIST, P591
   Macken WJ, 2003, J EXP PSYCHOL HUMAN, V29, P43, DOI 10.1037/0096-1523.29.1.43
   Maddox RK, 2012, JARO-J ASSOC RES OTO, V13, P119, DOI 10.1007/s10162-011-0299-7
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   MANN VA, 1986, COGNITION, V24, P169, DOI 10.1016/S0010-0277(86)80001-4
   MARTIN CS, 1989, J EXP PSYCHOL LEARN, V15, P676, DOI 10.1037/0278-7393.15.4.676
   Mathias SR, 2014, J EXP PSYCHOL HUMAN, V40, P445, DOI 10.1037/a0034890
   Mattys SL, 2008, PERCEPT PSYCHOPHYS, V70, P1235, DOI 10.3758/PP.70.7.1235
   McLennan CT, 2012, ATTEN PERCEPT PSYCHO, V74, P824, DOI 10.3758/s13414-012-0315-y
   McLennan CT, 2005, J EXP PSYCHOL LEARN, V31, P306, DOI 10.1037/0278-7393.31.2.306
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   MULLENNIX JW, 1990, PERCEPT PSYCHOPHYS, V47, P379, DOI 10.3758/BF03210878
   MULLENNIX JW, 1989, J ACOUST SOC AM, V85, P365, DOI 10.1121/1.397688
   Nearey TM, 1998, J ACOUST SOC AM, V85, P2088
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Nusbaum H.C., 1997, TALKER VARIABILITY S, P109
   Nusbaum HC, 1992, SPEECH PERCEPTION PR, P113
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   NYGAARD LC, 1995, PERCEPT PSYCHOPHYS, V57, P989, DOI 10.3758/BF03205458
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   PALMERI TJ, 1993, J EXP PSYCHOL LEARN, V19, P309, DOI 10.1037/0278-7393.19.2.309
   Perrachione TK, 2017, J SPEECH LANG HEAR R, V60, P1959, DOI 10.1044/2017_JSLHR-L-15-0446
   Perrachione TK, 2016, NEURON, V92, P1383, DOI 10.1016/j.neuron.2016.11.020
   Perrachione TK, 2011, J ACOUST SOC AM, V130, P461, DOI 10.1121/1.3593366
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Shinn-Cunningham BG, 2008, TRENDS COGN SCI, V12, P182, DOI 10.1016/j.tics.2008.02.003
   Souza P, 2013, J AM ACAD AUDIOL, V24, P689, DOI 10.3766/jaaa.24.8.6
   Sussman ES, 2007, PERCEPT PSYCHOPHYS, V69, P136, DOI 10.3758/BF03194460
   Theodore RM, 2015, ATTEN PERCEPT PSYCHO, V77, P1674, DOI 10.3758/s13414-015-0854-0
   Townsend J., 1983, STOCHASTIC MODELING
   Townsend J. T., 1978, COGNITIVE THEORY, V3, P200
   van Noorden LPAS, 1975, TEMPORAL COHERENCE P, P1
   Vliegen J, 1999, J ACOUST SOC AM, V106, P938, DOI 10.1121/1.427140
   Winkler I, 2009, TRENDS COGN SCI, V13, P532, DOI 10.1016/j.tics.2009.09.003
   Wostmann M, 2017, CEREB CORTEX, V27, P3307, DOI 10.1093/cercor/bhx074
   Wong PCM, 2004, J COGNITIVE NEUROSCI, V16, P1173, DOI 10.1162/0898929041920522
   Woods KJP, 2015, CURR BIOL, V25, P2238, DOI 10.1016/j.cub.2015.07.043
NR 77
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 1167
EP 1177
DI 10.3758/s13414-019-01684-w
PG 11
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6NQ
UT WOS:000485098800021
PM 30737757
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Greenberg, S
   Christiansen, TU
AF Greenberg, Steven
   Christiansen, Thomas U.
TI The perceptual flow of phonetic information
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Phonology; Bayesian modeling
ID YOUNG NORMAL-HEARING; SPEECH RECOGNITION; CONSONANT RECOGNITION; VISUAL
   SPEECH; ARTICULATION; INTELLIGIBILITY; CONTEXT; VOWELS; INDEX; PLACE
AB Over a long and distinguished career, Randy Diehl has elucidated the brain mechanisms underlying spoken language processing. The present study touches on two of Randy's central interests, phonetic features and Bayesian statistics. How does the brain go from sound to meaning? Traditional approaches to the study of speech intelligibility and word recognition are unlikely to provide a definitive answer. A finer-grained, Bayesian-inspired approach may help. In this study, listeners identified 11 Danish consonants spoken in a Consonant + Vowel + [l] environment. Each syllable was filtered so that only a portion of the original audio spectrum was presented. Three-quarter-octave bands of speech, centered at 750, 1,500, and 3,000 Hz, were presented individually and in combination. The conditional, posterior probabilities associated with decoding the phonetic-features Voicing, Manner, and Place of Articulation were computed from confusion matrices to delineate the perceptual flow of phonetic information processing. Analysis of the conditional probabilities associated with both correct and incorrect feature decoding suggest that Manner of articulation is linked to the decoding of Voicing (but not vice-versa), and that decoding of Place of articulation is associated with decoding of Manner of articulation (but not the converse). Such feature-decoding asymmetries may reflect processing strategies in which the decoding of lower-level features, such as Voicing and Manner, is leveraged to enhance the recognition of more complex linguistic elements (e.g., phonetic segments, syllables, and words), especially in adverse listening conditions. Such asymmetric feature decoding patterns are consistent with a hierarchical, perceptual flow model of phonetic processing.
C1 [Greenberg, Steven] Silicon Speech, Hidden Valley Lake, CA 95467 USA.
   [Christiansen, Thomas U.] Oticon, Kongebakken 9, DK-2765 Smorum, Denmark.
RP Greenberg, S (corresponding author), Silicon Speech, Hidden Valley Lake, CA 95467 USA.
EM steven@siliconspeech.com
FU Carlsberg FoundationCarlsberg Foundation; Technical University of
   Denmark; United States Air Force Office of Scientific ResearchUnited
   States Department of DefenseAir Force Office of Scientific Research
   (AFOSR)
FX This research was funded by the Carlsberg Foundation, Technical
   University of Denmark, and the United States Air Force Office of
   Scientific Research. The authors thank Torsten Dau for helpful
   suggestions and comments on various aspects of this research, as well as
   Andy Lotto and an anonymous reviewer for helpful suggestions on
   improving the original draft of this paper.
CR Abramson A. S., 1970, P 6 INT C PHON SCI, V196, P569
   Allen JB, 2005, J ACOUST SOC AM, V117, P2212, DOI 10.1121/1.1856231
   ANSI, 1969, STAND SECR ACOUST S, VS3, P5
   ANSI A., 1997, S3 5 1997 METH CALC
   Basboll Hans, 2005, PHONOLOGY DANISH
   BELL TS, 1992, J SPEECH HEAR RES, V35, P950, DOI 10.1044/jshr.3504.950
   Bonatti LL, 2005, PSYCHOL SCI, V16, P451, DOI 10.1111/j.0956-7976.2005.01556.x
   BOOTHROYD A, 1988, J ACOUST SOC AM, V84, P101, DOI 10.1121/1.396976
   BRAIDA LD, 1991, Q J EXP PSYCHOL-A, V43, P647, DOI 10.1080/14640749108400991
   Chan D., 1995, P 4 EUR C SPEECH COM, V1, P867
   Chang SY, 2005, SPEECH COMMUN, V47, P290, DOI 10.1016/j.specom.2005.01.006
   Cheung C, 2016, ELIFE, V5, DOI 10.7554/eLife.12577
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Clements George N., 1985, PHONOLOGY YB, V2, P225, DOI DOI 10.1017/S0952675700000440
   Cohen Michael M., 1995, P25
   Cole RA, 1996, INT CONF ACOUST SPEE, P853, DOI 10.1109/ICASSP.1996.543255
   Diehl Randy L., 2004, VVolume 18, P101
   Divenyi P., 2004, SPEECH SEPARATION HU
   Elhilali M, 2003, SPEECH COMMUN, V41, P331, DOI 10.1016/S0167-6393(02)00134-6
   Fletcher H., 1953, SPEECH HEARING COMMU
   Frankel J, 2007, COMPUT SPEECH LANG, V21, P620, DOI 10.1016/j.csl.2007.03.002
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407
   Ghosh PK, 2011, J ACOUST SOC AM, V130, pEL251, DOI 10.1121/1.3634122
   GRANT KW, 1991, J ACOUST SOC AM, V89, P2952, DOI 10.1121/1.400733
   Grant KW, 1998, J ACOUST SOC AM, V103, P2677, DOI 10.1121/1.422788
   Greenberg S., 2002, P ISCA WORKSH PROS S
   Greenberg S., 2008, AUDITORY SIGNAL PROC, P351
   Greenberg Steven, 2004, VVolume 18, P1
   GRONNUM N, 1998, J INT PHON ASSOC, V28, P99, DOI DOI 10.1017/S0025100300006290
   Hasegawa-Johnson M., 2005, P IEEE INT C AC SPEE, V1
   Jakobson R., 1963, PRELIMINARIES SPEECH
   Juneja A., 2004, THESIS
   Kewley-Port D, 2007, J ACOUST SOC AM, V122, P2365, DOI 10.1121/1.2773986
   KEWLEYPORT D, 1983, J ACOUST SOC AM, V73, P1779, DOI 10.1121/1.389402
   KRYTER KD, 1962, J ACOUST SOC AM, V34, P1689, DOI 10.1121/1.1909094
   Ladefoged Peter, 1971, PRELIMINARIES LINGUI
   Ladefoged Peter, 1996, SOUNDS WORLDS LANGUA
   Lee JH, 2009, J ACOUST SOC AM, V125, P1153, DOI 10.1121/1.3021304
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Livescu K, 2007, INT CONF ACOUST SPEE, P621
   Marr D., 1982, VISION COMPUTATIONAL
   Massaro D. W., 1987, SPEECH PERCEPTION EA
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   PAVLOVIC CV, 1994, EAR HEARING, V15, P100, DOI 10.1097/00003446-199402000-00012
   Pavlovic CV, 2006, J ACOUST SOC AM, V119, P3326, DOI [10.1121/1.4786372, DOI 10.1121/1.4786372]
   Rasipuram R, 2016, COMPUT SPEECH LANG, V36, P233, DOI 10.1016/j.csl.2015.04.003
   Redford MA, 1999, J ACOUST SOC AM, V106, P1555, DOI 10.1121/1.427152
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464
   Stevens KN, 2002, J ACOUST SOC AM, V111, P1872, DOI 10.1121/1.1458026
   SUSSMAN HM, 1991, J ACOUST SOC AM, V90, P1309, DOI 10.1121/1.401923
   Trubetzkoy N., 1969, PRINCIPLES PHONOLOGY
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
NR 55
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 884
EP 896
DI 10.3758/s13414-019-01666-y
PG 13
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6NQ
UT WOS:000485098800002
PM 30706386
OA Bronze
DA 2021-02-24
ER

PT J
AU Heffner, CC
   Idsardi, WJ
   Newman, RS
AF Heffner, Christopher C.
   Idsardi, William J.
   Newman, Rochelle S.
TI Constraints on learning disjunctive, unidimensional auditory and
   phonetic categories
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Category learning; Categorization; Speech perception; Phonetics
ID COMPLEMENTARY SYSTEMS ACCOUNT; DECISION BOUND MODELS; PLUS-EXCEPTION
   MODEL; SPEECH-PERCEPTION; MEMORY; CLASSIFICATION; ABSTRACTION; EXEMPLAR;
   REPRESENTATIONS; IDENTIFICATION
AB Phonetic categories must be learned, but the processes that allow that learning to unfold are still under debate. The current study investigates constraints on the structure of categories that can be learned and whether these constraints are speech-specific. Category structure constraints are a key difference between theories of category learning, which can roughly be divided into instance-based learning (i.e., exemplar only) and abstractionist learning (i.e., at least partly rule-based or prototype-based) theories. ionist theories can relatively easily accommodate constraints on the structure of categories that can be learned, whereas instance-based theories cannot easily include such constraints. The current study included three groups to investigate these possible constraints as well as their speech specificity: English speakers learning German speech categories, German speakers learning German speech categories, and English speakers learning musical instrument categories, with each group including participants who learned different sets of categories. Both speech groups had greater difficulty learning disjunctive categories (ones that require an "or" statement) than nondisjunctive categories, which suggests that instance-based learning alone is insufficient to explain the learning of the participants learning phonetic categories. This fact was true for both novices (English speakers) and experts (German speakers), which implies that expertise with the materials used cannot explain the patterns observed. However, the same was not true for the musical instrument categories, suggesting a degree of domain-specificity in these constraints that cannot be explained through recourse to expertise alone.
C1 [Heffner, Christopher C.; Idsardi, William J.; Newman, Rochelle S.] Univ Maryland, Program Neurosci & Cognit Sci, College Pk, MD 20742 USA.
   [Heffner, Christopher C.; Idsardi, William J.] Univ Maryland, Dept Linguist, College Pk, MD 20742 USA.
   [Heffner, Christopher C.; Newman, Rochelle S.] Univ Maryland, Dept Speech & Hearing Sci, College Pk, MD 20742 USA.
   [Heffner, Christopher C.] Univ Connecticut, Dept Speech Language & Hearing Sci, 850 Bolton Rd,U-1085, Storrs, CT 06269 USA.
RP Heffner, CC (corresponding author), Univ Maryland, Program Neurosci & Cognit Sci, College Pk, MD 20742 USA.; Heffner, CC (corresponding author), Univ Maryland, Dept Linguist, College Pk, MD 20742 USA.; Heffner, CC (corresponding author), Univ Maryland, Dept Speech & Hearing Sci, College Pk, MD 20742 USA.; Heffner, CC (corresponding author), Univ Connecticut, Dept Speech Language & Hearing Sci, 850 Bolton Rd,U-1085, Storrs, CT 06269 USA.
EM christopher.heffner@uconn.edu
FU National Science Foundation Graduate Research Fellowship awardNational
   Science Foundation (NSF); University of Maryland, College Park Graduate
   School Flagship Fellowship; NSF IGERT Grant [0801465]; NSF Linguistics
   Doctoral Dissertation Research Improvement grant [BCS 1650791]; Maryland
   Language Science Center; University of Maryland-University of Tubingen
   International Interdisciplinary Research and Teaching Collaboration;
   Department of Linguistics at the University of Maryland, College Park;
   Department of Linguistics and Germanic, Slavic, Asian; African Languages
   of Michigan State University
FX This work was supported by a National Science Foundation Graduate
   Research Fellowship award and a University of Maryland, College Park
   Graduate School Flagship Fellowship, to C.C.H., as well as NSF IGERT
   Grant 0801465 (PI: C. Phillips), an NSF Linguistics Doctoral
   Dissertation Research Improvement grant awarded to W.J.I. (co-PI: CCH),
   BCS 1650791, the Maryland Language Science Center, and the University of
   Maryland-University of Tubingen International Interdisciplinary Research
   and Teaching Collaboration. Data from this experiment will be available
   online, in line with the Open Science Framework, for participants who
   consented to sharing data. We thank Peter Deaville, Stephen DeVilbiss,
   Scott Kaplowitz, Priyanka Konanur, Zoe Schlueter, and the members of the
   UMD Language Development Lab for their help in running English-speaking
   participants for this project. We thank Andrea Weber's lab at Eberhard
   Karls University, Tubingen, for their space and support for the
   German-speaking participants, particularly Sara Beck, Ann-Kathrin Grohe,
   Lisa Kienzle, and Sarah Schwarz. Michael Key generously allowed us to
   use his German fricative stimuli for this study.; Many people have
   provided discussion and insightful comments during the development and
   publication process in this study. Among others, we would like to thank
   Ann Bradlow, Al Braun, Catherine Carr, Bharath Chandrasekaran, Jeff
   Chrabaszcz, Karthik Durvasula, Naomi Feldman, Drew Hendrickson, Lori
   Holt, Ellen Lau, Todd Maddox, Holger Mitterer, Emily Myers, Chris
   Neufeld, Rob Nosofsky, Janet Pierrehumbert, Eva Reinisch, Kirsten
   Smayda, and Joe Toscano. Jared Linck gave immensely useful statistical
   support. Portions of this research were presented at the eighty-eighth
   annual Meeting of the Linguistics Society of America (LSA) in
   Minneapolis, Minnesota, travel to which was financed by the Department
   of Linguistics at the University of Maryland, College Park, at the sixth
   annual Michigan State Undergraduate Linguistics Conference (MSULC) in
   East Lansing, Michigan, travel to which was funded by the Department of
   Linguistics and Germanic, Slavic, Asian, and African Languages of
   Michigan State University, and at the Mini-Workshop on Phonetic
   Processing and Learning at Eberhard Karls University, Tubingen in
   Tubingen, Baden-Wurttemberg, Germany.
CR ASHBY FG, 1988, J EXP PSYCHOL LEARN, V14, P33, DOI 10.1037/0278-7393.14.1.33
   ASHBY FG, 1993, J MATH PSYCHOL, V37, P372, DOI 10.1006/jmps.1993.1023
   Ashby FG, 1998, PSYCHOL REV, V105, P442, DOI 10.1037/0033-295X.105.3.442
   ASHBY FG, 1986, PSYCHOL REV, V93, P154, DOI 10.1037/0033-295X.93.2.154
   Ashby FG, 1999, PSYCHON B REV, V6, P363, DOI 10.3758/BF03210826
   ASHBY FG, 1995, J MATH PSYCHOL, V39, P216, DOI 10.1006/jmps.1995.1021
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   BRAIDA LD, 1984, J ACOUST SOC AM, V76, P722, DOI 10.1121/1.391258
   Buxo-Lugo A, 2016, J MEM LANG, V90, P1, DOI 10.1016/j.jml.2016.03.001
   Bybee Joan, 2002, STUDIES 2 LANGUAGE A, V24, P215, DOI DOI 10.1017/S0272263102002061
   CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791
   Chandrasekaran B, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00825
   Chandrasekaran B, 2014, PSYCHON B REV, V21, P488, DOI 10.3758/s13423-013-0501-5
   Chandrasekaran B, 2010, J ACOUST SOC AM, V128, P456, DOI 10.1121/1.3445785
   Dahan D, 2008, COGNITION, V108, P710, DOI 10.1016/j.cognition.2008.06.003
   Davis MH, 2009, PHILOS T R SOC B, V364, P3773, DOI 10.1098/rstb.2009.0111
   Diehl RL, 2008, PHILOS T R SOC B, V363, P965, DOI 10.1098/rstb.2007.2153
   Diehl RL, 2000, PHONETICA, V57, P267, DOI 10.1159/000028479
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldstone RL, 2001, COGNITION, V78, P27, DOI 10.1016/S0010-0277(00)00099-8
   Goldstone RL, 2010, WIRES COGN SCI, V1, P69, DOI 10.1002/wcs.26
   Goodman ND, 2008, COGNITIVE SCI, V32, P108, DOI 10.1080/03640210701802071
   Hawkins S, 2003, J PHONETICS, V31, P373, DOI 10.1016/j.wocn.2003.09.006
   Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014
   HINTZMAN DL, 1986, PSYCHOL REV, V93, P411, DOI 10.1037/0033-295X.93.4.411
   Holt LL, 2004, J ACOUST SOC AM, V116, P1763, DOI 10.1121/1.1778838
   Holt LL, 2008, CURR DIR PSYCHOL SCI, V17, P42, DOI 10.1111/j.1467-8721.2008.00545.x
   HOMA D, 1973, J EXP PSYCHOL, V101, P116, DOI 10.1037/h0035772
   Johnson EK, 2008, INFANCY, V13, P440, DOI 10.1080/15250000802329321
   Johnson K., 2007, EXPT APPROACHES PHON, P25
   Kassambara A, 2018, SURVMINER DRAWING SU
   Kemp C, 2007, DEVELOPMENTAL SCI, V10, P307, DOI 10.1111/j.1467-7687.2007.00585.x
   Key M, 2014, J ACOUST SOC AM, V135, pEL350, DOI 10.1121/1.4879669
   Kingston J, 2003, LANG SPEECH, V46, P295, DOI 10.1177/00238309030460020201
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   LIN DY, 1989, J AM STAT ASSOC, V84, P1074, DOI 10.2307/2290085
   Lindsay S, 2010, LANG LEARN, V60, P45, DOI 10.1111/j.1467-9922.2010.00600.x
   LISKER L, 1985, J ACOUST SOC AM, V77, P1199, DOI 10.1121/1.392185
   Livingston KR, 1998, J EXP PSYCHOL LEARN, V24, P732, DOI 10.1037/0278-7393.24.3.732
   Lotto AJ, 2004, SOUND SENSE 50 YEARS, pC181
   Love BC, 2004, PSYCHOL REV, V111, P309, DOI 10.1037/0033-295X.111.2.309
   Maddox WT, 2014, BILING-LANG COGN, V17, P709, DOI 10.1017/S1366728913000783
   Maddox WT, 2014, CORTEX, V58, P186, DOI 10.1016/j.cortex.2014.06.013
   Maddox WT, 2002, PERCEPT PSYCHOPHYS, V64, P584, DOI 10.3758/BF03194728
   Mair P., 2016, SMACOF MULTIDIMENSIO
   MANTEL NATHAN, 1966, CANCERCHEMOTHERAP REP, V50, P163
   MCKINLEY SC, 1995, J EXP PSYCHOL HUMAN, V21, P128, DOI 10.1037/0096-1523.21.1.128
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   McMurray B, 2009, DEVELOPMENTAL SCI, V12, P369, DOI 10.1111/j.1467-7687.2009.00822.x
   Minda JP, 2008, J EXP PSYCHOL LEARN, V34, P1518, DOI 10.1037/a0013355
   Moreton E, 2017, COGNITIVE SCI, V41, P4, DOI 10.1111/cogs.12319
   Myers EB, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00238
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Nosofsky RM, 1998, PSYCHON B REV, V5, P345, DOI 10.3758/BF03208813
   NOSOFSKY RM, 1994, MEM COGNITION, V22, P352, DOI 10.3758/BF03200862
   NOSOFSKY RM, 1994, PSYCHOL REV, V101, P53, DOI 10.1037/0033-295X.101.1.53
   NOSOFSKY RM, 1987, J EXP PSYCHOL LEARN, V13, P87, DOI 10.1037/0278-7393.13.1.87
   NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39
   Pajak B, 2014, J PHONETICS, V46, P147, DOI 10.1016/j.wocn.2014.07.001
   Palmeri TJ, 2004, TRENDS COGN SCI, V8, P378, DOI 10.1016/j.tics.2004.06.001
   PETO R, 1972, J R STAT SOC SER A-G, V135, P185, DOI 10.2307/2344317
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Pitt MA, 2011, J PHONETICS, V39, P304, DOI 10.1016/j.wocn.2010.07.004
   Poeppel D, 2008, PHILOS T R SOC B, V363, P1071, DOI 10.1098/rstb.2007.2160
   Port R, 2007, NEW IDEAS PSYCHOL, V25, P143, DOI 10.1016/j.newideapsych.2007.02.001
   Port RF, 2010, LANG SCI, V32, P43, DOI 10.1016/j.langsci.2009.06.001
   Pycha A, 2010, PHONOLOGY, V27, P119, DOI 10.1017/S0952675710000059
   Pycha A, 2009, J INT PHON ASSOC, V39, P1, DOI 10.1017/S0025100308003666
   REPP BH, 1982, PSYCHOL BULL, V92, P81, DOI 10.1037/0033-2909.92.1.81
   Rocamora M., 2009, 12 BRAZ S COMP MUS R
   Rosseel Y, 2002, J MATH PSYCHOL, V46, P178, DOI 10.1006/jmps.2001.1379
   SAMUEL AG, 1982, PERCEPT PSYCHOPHYS, V31, P307, DOI 10.3758/BF03202653
   Scharinger M, 2013, MEM COGNITION, V41, P752, DOI 10.3758/s13421-013-0294-9
   SHEPARD RN, 1961, PSYCHOL MONOGR, V75, P1, DOI 10.1037/h0093825
   Slote J, 2016, BEHAV RES METHODS, V48, P553, DOI 10.3758/s13428-015-0599-7
   Smith R, 2012, J PHONETICS, V40, P213, DOI 10.1016/j.wocn.2011.11.003
   Squire LR, 2009, J NEUROSCI, V29, P12711, DOI 10.1523/JNEUROSCI.3575-09.2009
   THERNEAU TM, 1990, BIOMETRIKA, V77, P147, DOI 10.2307/2336057
   Toscano JC, 2010, COGNITIVE SCI, V34, P434, DOI 10.1111/j.1551-6709.2009.01077.x
   Ullman M.T., 2016, NEUROBIOLOGY LANGUAG, P953, DOI DOI 10.1016/B978-0-12-407794-2.00076-6
   Ullman MT, 2004, COGNITION, V92, P231, DOI 10.1016/j.cognition.2003.10.008
   Zeithamova D, 2006, MEM COGNITION, V34, P387, DOI 10.3758/BF03193416
NR 84
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 958
EP 980
DI 10.3758/s13414-019-01683-x
PG 23
WC Psychology; Psychology, Experimental
SC Psychology
GA KK8FJ
UT WOS:000512971900002
OA Bronze
DA 2021-02-24
ER

PT J
AU Yang, J
   Liang, Q
   Chen, HT
   Liu, YJ
   Xu, L
AF Yang, Jing
   Liang, Qi
   Chen, Haotong
   Liu, Yanjun
   Xu, Li
TI Singing Proficiency of Members of a Choir Formed by Prelingually
   Deafened Children With Cochlear Implants
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID MANDARIN-SPEAKING CHILDREN; AUDITORY BRAIN-STEM; MUSIC PERCEPTION;
   SPEECH-PERCEPTION; TIMBRE PERCEPTION; PITCH PERCEPTION; TONE PRODUCTION;
   HEARING-LOSS; RECOGNITION; RECIPIENTS
AB Purpose: A group of 10 prelingually deafened children with cochlear implants (CIs) formed a choir and received 21 months of formal music training. The purpose of this study was to evaluate the singing proficiency of these children.
   Method: The participants included all choir members (7 girls and 3 boys, mean age of 9.5 years old) who were unilateral CI users. Meanwhile, 8 age-matched children with normal hearing were recruited as controls and were trained on 1 song for 2 weeks. Individual singing samples without instrument accompaniment were recorded from all participants. The singing samples were subject to acoustic analysis in which the fundamental frequency (F0) of each note was extracted and the duration was measured. Five metrics were developed and computed to quantify the accuracy of their pitch and rhythm performance. The 5 metrics included (a) percent correct of F0 contour direction of adjacent notes, (b) mean deviation of the normalized F0 across the notes, (c) mean deviation of the pitch intervals, (d) mean deviation of adjacent note duration ratio, and (e) mean absolute deviation of note duration.
   Results: The choir members with CIs demonstrated high accuracy in both pitch and tempo measures and performed on par with the children with normal hearing. Early start of music training after implantation and use of bimodal hearing contributed to the development of better music ability in these children with CIs.
   Conclusion: These findings indicated that rigorous music training could facilitate high singing proficiency in prelingually deafened children with CIs.
C1 [Yang, Jing] Univ Wisconsin, Dept Commun Sci & Disorders, Milwaukee, WI 53201 USA.
   [Liang, Qi; Liu, Yanjun] Aier Times Ltd, Beijing, Peoples R China.
   [Chen, Haotong; Xu, Li] Ohio Univ, Dept Commun Sci & Disorders, Athens, OH 45701 USA.
RP Xu, L (corresponding author), Ohio Univ, Dept Commun Sci & Disorders, Athens, OH 45701 USA.
EM xul@ohio.edu
OI Xu, Li/0000-0002-0988-7934
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R15-DC014587]
FX The study was supported, in part, by National Institute on Deafness and
   Other Communication Disorders Grant R15-DC014587, awarded to L. X. We
   thank Bo Zhu, Rui Gao, Jingying Wang, Peggy Liu, Yu Zhang, Shengzhe Qin,
   and Lexi Neltner for technical assistance.
CR Abdi S, 2001, INT J PEDIATR OTORHI, V59, P105, DOI 10.1016/S0165-5876(01)00460-8
   Arehart KH, 2014, EAR HEARING, V35, P195, DOI 10.1097/AUD.0b013e3182a69a5c
   Bartov T, 2014, J SPEECH LANG HEAR R, V57, P1929, DOI 10.1044/2014_JSLHR-H-13-0190
   Bella SD, 2007, J ACOUST SOC AM, V121, P1182, DOI 10.1121/1.2427111
   Chatterjee M., 2018, J ACOUST SOC AM, V144, P1840
   Chen JKC, 2010, PEDIATRICS, V125, pE793, DOI 10.1542/peds.2008-3620
   Chen Y, 2017, INT J AUDIOL, V56, pS7, DOI 10.1080/14992027.2017.1300694
   Ciocca V, 2002, J ACOUST SOC AM, V111, P2250, DOI 10.1121/1.1471897
   Cooper WB, 2008, EAR HEARING, V29, P618, DOI 10.1097/AUD.0b013e318174e787
   Crew JD, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516669329
   Dege F, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00124
   Dorman MF, 2008, AUDIOL NEURO-OTOL, V13, P105, DOI 10.1159/000111782
   El Fata F, 2009, AUDIOL NEURO-OTOL, V14, P14, DOI 10.1159/000206491
   Fu QJ, 2015, J SPEECH LANG HEAR R, V58, P163, DOI 10.1044/2014_JSLHR-H-14-0127
   Fujita S, 1999, ANN OTO RHINOL LARYN, V108, P634, DOI 10.1177/000348949910800702
   Galvin JJ, 2007, EAR HEARING, V28, P302, DOI 10.1097/01.aud.0000261689.35445.20
   Garway-Heath DF, 2018, HEALTH TECHNOL ASSES, V22, P1, DOI 10.3310/hta22040
   Gfeller K, 1998, VOLTA REV, V100, P213
   Gfeller K, 2016, EUR ANN OTORHINOLARY, V133, pS50, DOI 10.1016/j.anorl.2016.01.010
   Gfeller K, 2007, EAR HEARING, V28, P412, DOI 10.1097/AUD.0b013e3180479318
   Gfeller Kate, 2002, J Am Acad Audiol, V13, P132
   Gfeller K, 2012, J MUSIC THER, V49, P68, DOI 10.1093/jmt/49.1.68
   Gordon KA, 2006, AUDIOL NEURO-OTOL, V11, P7, DOI 10.1159/000088851
   Gozaine TC, 2005, LARYNGOSCOPE, V115, P81, DOI 10.1097/01.mlg.0000150699.38753.74
   Green CS, 2008, PSYCHOL AGING, V23, P692, DOI 10.1037/a0014345
   Han DM, 2007, INT J PEDIATR OTORHI, V71, P875, DOI 10.1016/j.ijporl.2007.02.008
   Hardie NA, 1999, HEARING RES, V128, P147, DOI 10.1016/S0378-5955(98)00209-3
   Hopyan T, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00425
   Hopyan-Misakyan TM, 2009, CHILD NEUROPSYCHOL, V15, P136, DOI 10.1080/09297040802403682
   Innes-Brown H, 2013, J AM ACAD AUDIOL, V24, P789, DOI 10.3766/jaaa.24.9.4
   Interkultur, 2017, 10 INT J BRAHMS CHOI
   Interkultur, 2016, WORLD CHOIR GAM SOCH
   Kang R, 2009, EAR HEARING, V30, P411, DOI 10.1097/AUD.0b013e3181a61bc0
   Kempermann G, 2010, FRONT NEUROSCI-SWITZ, V4, DOI 10.3389/fnins.2010.00189
   Kong YY, 2012, EAR HEARING, V33, P645, DOI 10.1097/AUD.0b013e318252caae
   Kral A, 2000, CEREB CORTEX, V10, P714, DOI 10.1093/cercor/10.7.714
   Larson CR, 2008, EXP BRAIN RES, V187, P613, DOI 10.1007/s00221-008-1330-z
   Li YG, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111707
   Limb CJ, 2012, OTOLARYNG CLIN N AM, V45, P129, DOI 10.1016/j.otc.2011.08.021
   Limb CJ, 2010, JARO-J ASSOC RES OTO, V11, P133, DOI 10.1007/s10162-009-0184-9
   Liu Haihong, 2017, Pediatr Investig, V1, P32, DOI 10.1002/ped4.12011
   Looi V, 2008, EAR HEARING, V29, P421, DOI 10.1097/AUD.0b013e31816a0d0b
   Looi Valerie, 2012, Seminars in Hearing, V33, P307, DOI 10.1055/s-0032-1329222
   Looi V, 2011, INT J PEDIATR OTORHI, V75, P472, DOI 10.1016/j.ijporl.2010.12.023
   Mao YT, 2017, INT J AUDIOL, V56, pS23, DOI 10.1080/14992027.2016.1219073
   Mao YT, 2013, INT J PEDIATR OTORHI, V77, P1833, DOI 10.1016/j.ijporl.2013.08.022
   McDermott Hugh J, 2004, Trends Amplif, V8, P49, DOI 10.1177/108471380400800203
   Moore BCJ, 2005, SPR HDB AUD, V24, P234
   MOORE DR, 1994, J COMP NEUROL, V339, P301, DOI 10.1002/cne.903390209
   Nakata T, 2006, MUSIC PERCEPT, V24, P147, DOI 10.1525/mp.2006.24.2.147
   Nan Y, 2018, P NATL ACAD SCI USA, V115, pE6630, DOI 10.1073/pnas.1808412115
   NORDEEN KW, 1983, J COMP NEUROL, V214, P131, DOI 10.1002/cne.902140203
   Peng SC, 2004, ARCH OTOLARYNGOL, V130, P592, DOI 10.1001/archotol.130.5.592
   Polonenko MJ, 2017, J ACOUST SOC AM, V141, P4494, DOI 10.1121/1.4985123
   Prentiss SM, 2015, J AM ACAD AUDIOL, V26, P494, DOI 10.3766/jaaa.14098
   Ryugo DK, 1998, J COMP NEUROL, V397, P532, DOI 10.1002/(SICI)1096-9861(19980810)397:4<532::AID-CNE6>3.0.CO;2-2
   Scorpecci A, 2012, INT J PEDIATR OTORHI, V76, P1507, DOI 10.1016/j.ijporl.2012.07.005
   See RL, 2013, OTOL NEUROTOL, V34, P490, DOI 10.1097/MAO.0b013e318287c985
   Sharma A, 2005, HEARING RES, V203, P134, DOI 10.1016/j.heares.2004.12.010
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   Sundberg J., 1987, SCI SINGING VOICE
   Tan J, 2016, AM J AUDIOL, V25, P246, DOI 10.1044/2016_AJA-15-0069
   Thai-Van H, 2007, CLIN NEUROPHYSIOL, V118, P676, DOI 10.1016/j.clinph.2006.11.010
   Tierney AT, 2015, P NATL ACAD SCI USA, V112, P10062, DOI 10.1073/pnas.1505114112
   Torppa R, 2018, MUSIC PERCEPT, V36, P156, DOI 10.1525/MP.2018.36.2.156
   Torppa R, 2014, INT J AUDIOL, V53, P182, DOI 10.3109/14992027.2013.872302
   Trehub SE, 2009, ANN NY ACAD SCI, V1169, P534, DOI 10.1111/j.1749-6632.2009.04554.x
   Wang WQ, 2011, INT J AUDIOL, V50, P270, DOI 10.3109/14992027.2010.542490
   Wilson BS, 2008, HEARING RES, V242, P3, DOI 10.1016/j.heares.2008.06.005
   Wilson BS, 2015, HEARING RES, V322, P24, DOI 10.1016/j.heares.2014.11.009
   WYKE BD, 1974, FOLIA PHONIATR, V26, P295, DOI 10.1159/000263791
   Xu L, 2004, ACTA OTO-LARYNGOL, V124, P363, DOI 10.1080/00016480410016351
   Xu L, 2011, PROCEEDINGS OF THE THIRD INTERNATIONAL SYMPOSIUM ON REGIONAL MANAGEMENT SCIENCE AND ENGINEERING, P343
   Xu L, 2011, ACTA OTO-LARYNGOL, V131, P395, DOI 10.3109/00016489.2010.536993
   Xu L, 2009, HEARING RES, V255, P129, DOI 10.1016/j.heares.2009.06.011
   Yucel E, 2009, INT J PEDIATR OTORHI, V73, P1043, DOI 10.1016/j.ijporl.2009.04.009
NR 76
TC 5
Z9 5
U1 0
U2 2
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD MAY
PY 2019
VL 62
IS 5
BP 1561
EP 1573
DI 10.1044/2019_JSLHR-H-18-0385
PG 13
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA HZ9UI
UT WOS:000469202500027
PM 31021668
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Schmitz, J
   Bartoli, E
   Maffongelli, L
   Fadiga, L
   Sebastian-Galles, N
   D'Ausilio, A
AF Schmitz, Judith
   Bartoli, Eleonora
   Maffongelli, Laura
   Fadiga, Luciano
   Sebastian-Galles, Nuria
   D'Ausilio, Alessandro
TI Motor cortex compensates for lack of sensory and motor experience during
   auditory speech perception
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Speech perception; Speech production; Native language; Non-native
   language; Motor evoked potentials; Transcranial magnetic stimulation
ID HEARING LIPS; PLASTICITY; LANGUAGE; IDENTIFICATION; EXCITABILITY;
   REPRESENTATIONS; DISCRIMINATION; MODULATION; SIMULATION; DISTORTION
AB Listening to speech has been shown to activate motor regions, as measured by corticobulbar excitability. In this experiment, we explored if motor regions are also recruited during listening to non-native speech, for which we lack both sensory and motor experience. By administering Transcranial Magnetic Stimulation (TMS) over the left motor cortex we recorded corticobulbar excitability of the lip muscles when Italian participants listened to native-like and non-native German vowels. Results showed that lip corticobulbar excitability increased for a combination of lip use during articulation and non-nativeness of the vowels. Lip corticobulbar excitability was further related to measures obtained in perception and production tasks showing a negative relationship with nativeness ratings and a positive relationship with the uncertainty of lip movement during production of the vowels. These results suggest an active and compensatory role of the motor system during listening to perceptually/articulatory unfamiliar phonemes.
C1 [Schmitz, Judith; Sebastian-Galles, Nuria] Univ Pompeu Fabra, Ctr Brain & Cognit, Roc Boronat 138, Barcelona 08018, Spain.
   [Bartoli, Eleonora] Univ Texas Hlth Sci Ctr Houston, Neurosurg Dept, 6431 Fannin St, Houston, TX 77030 USA.
   [Maffongelli, Laura] Univ Zurich, Dept Psychol, Binzmuehlestr 14,Box 21, CH-8050 Zurich, Switzerland.
   [Fadiga, Luciano; D'Ausilio, Alessandro] Univ Ferrara, Sect Human Physiol, Dipartimento Sci Biomed & Chirurg Specialist, Via Fossato Mortara 17-19, I-44121 Ferrara, Italy.
   [Fadiga, Luciano; D'Ausilio, Alessandro] Fdn Ist Italiano Tecnol, Ctr Translat Neurophysiol Speech & Commun, Via Fossato Mortara 17-19, I-44121 Ferrara, Italy.
RP Schmitz, J (corresponding author), Univ Pompeu Fabra, Ctr Brain & Cognit, Roc Boronat 138, Barcelona 08018, Spain.; D'Ausilio, A (corresponding author), Univ Ferrara, Sect Human Physiol, Dipartimento Sci Biomed & Chirurg Specialist, Via Fossato Mortara 17-19, I-44121 Ferrara, Italy.; D'Ausilio, A (corresponding author), Fdn Ist Italiano Tecnol, Ctr Translat Neurophysiol Speech & Commun, Via Fossato Mortara 17-19, I-44121 Ferrara, Italy.
EM judith-schmitz@gmx.net; alessandro.dausilio@unife.it
RI D'Ausilio, Alessandro/M-6688-2019; Bartoli, Eleonora/AAC-1052-2020;
   D'Ausilio, Alessandro/A-3997-2010; Sebastian-Galles, Nuria/A-4215-2008
OI D'Ausilio, Alessandro/0000-0003-1472-6200; Bartoli,
   Eleonora/0000-0002-5824-5065; D'Ausilio, Alessandro/0000-0003-1472-6200;
   Sebastian-Galles, Nuria/0000-0001-6938-2498; fadiga,
   luciano/0000-0001-5691-5080
FU European Community Grant POETICON ++ (STREP) [288382]; European
   CommissionEuropean CommissionEuropean Commission Joint Research Centre
   [323961, 613465]; Spanish Ministerio de Economia y Competitividad
   [PSI2015-66918-P]; Catalan Government [SGR 2014-1210]; Generalitat de
   CatalunyaGeneralitat de Catalunya
FX This research was supported by the European Community Grant POETICON ++
   (STREP-Project ICT - 288382) awarded to L.F, and grants from the
   European Commission Seventh Framework Programme (FP7/2007-2013): ERG
   grant agreement number 323961 (UNDER CONTROL); Cooperation grant
   agreement number 613465 - (AThEME), the Spanish Ministerio de Economia y
   Competitividad (PSI2015-66918-P) and the Catalan Government (SGR
   2014-1210) awarded to N.S.G. She also received the prize "ICREA
   Academia'' for excellence in research, funded by the Generalitat de
   Catalunya.
CR Aglioti SM, 2008, NAT NEUROSCI, V11, P1109, DOI 10.1038/nn.2182
   Agnew ZK, 2011, J COGNITIVE NEUROSCI, V23, P4038, DOI 10.1162/jocn_a_00106
   Avenanti A, 2018, CEREB CORTEX, V28, P1282, DOI 10.1093/cercor/bhx041
   Avenanti A, 2013, CEREB CORTEX, V23, P570, DOI 10.1093/cercor/bhs040
   Bangert M, 2003, BMC NEUROSCI, V4, DOI 10.1186/1471-2202-4-26
   Bartoli E, 2015, CEREB CORTEX, V25, P281, DOI 10.1093/cercor/bht257
   Bernstein LE, 2000, PERCEPT PSYCHOPHYS, V62, P233, DOI 10.3758/BF03205546
   Bertinetto Pier Marco, 2005, J INT PHON ASSOC, V35, P131, DOI DOI 10.1017/S0025100305002148
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2010, PRAAT DOING PHONETIC
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Callan DE, 2003, NEUROIMAGE, V19, P113, DOI 10.1016/S1053-8119(03)00020-X
   Callan DE, 2004, NEUROIMAGE, V22, P1182, DOI 10.1016/j.neuroimage.2004.03.006
   Calvo-Merino B, 2005, CEREB CORTEX, V15, P1243, DOI 10.1093/cercor/bhi007
   Cross ES, 2006, NEUROIMAGE, V31, P1257, DOI 10.1016/j.neuroimage.2006.01.033
   D'Ausilio A, 2006, EUR J NEUROSCI, V24, P955, DOI 10.1111/j.1460-9568.2006.04960.x
   D'Ausilio A, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0418
   D'Ausilio A, 2015, PHYS LIFE REV, V12, P91, DOI 10.1016/j.plrev.2014.11.002
   D'Ausilio A, 2012, CORTEX, V48, P882, DOI 10.1016/j.cortex.2011.05.017
   D'Ausilio A, 2011, NEUROPSYCHOLOGIA, V49, P3670, DOI 10.1016/j.neuropsychologia.2011.09.022
   D'Ausilio A, 2011, BRAIN LANG, V118, P9, DOI 10.1016/j.bandl.2011.02.007
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2003, PHONETICS PHONOLOGY, P319, DOI DOI 10.1515/9783110895094.319
   Fourkas AD, 2008, CEREB CORTEX, V18, P2382, DOI 10.1093/cercor/bhn005
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Ganel T, 2019, NEUROPSYCHOLOGIA, V128, P249, DOI 10.1016/j.neuropsychologia.2017.09.016
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   MIYAWAKI K, 1975, PERCEPT PSYCHOPHYS, V18, P331, DOI 10.3758/BF03211209
   Mottonen R, 2014, J NEUROSCI, V34, P4064, DOI 10.1523/JNEUROSCI.2214-13.2014
   Mottonen R, 2013, CEREB CORTEX, V23, P1190, DOI 10.1093/cercor/bhs110
   Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009
   Murakami T, 2011, NEUROPSYCHOLOGIA, V49, P2045, DOI 10.1016/j.neuropsychologia.2011.03.034
   Nuttall HE, 2017, NEUROPSYCHOLOGIA, V94, P13, DOI 10.1016/j.neuropsychologia.2016.11.016
   Nuttall HE, 2016, NEUROIMAGE, V128, P218, DOI 10.1016/j.neuroimage.2015.12.038
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Pallier C, 1997, COGNITION, V64, pB9, DOI 10.1016/S0010-0277(97)00030-9
   Passingham RE, 2019, NEUROPSYCHOLOGIA, V128, P241, DOI 10.1016/j.neuropsychologia.2017.06.012
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811
   R Foundation for Statistical Computing, 2013, R LANG ENV STAT COMP
   Ronquest RE, 2010, ATTEN PERCEPT PSYCHO, V72, P1601, DOI 10.3758/APP.72.6.1601
   Salminen-Vaparanta N, 2019, NEUROPSYCHOLOGIA, V128, P223, DOI 10.1016/j.neuropsychologia.2017.11.013
   Sato M, 2009, BRAIN LANG, V111, P1, DOI 10.1016/j.bandl.2009.03.002
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Soto-Faraco S, 2007, PERCEPT PSYCHOPHYS, V69, P218, DOI 10.3758/BF03193744
   Stevens K., 1967, MODELS PERCEPTION SP, P88
   Swaminathan S, 2013, BRAIN LANG, V126, P1, DOI 10.1016/j.bandl.2013.03.002
   Tremblay P, 2016, BRAIN LANG, V162, P60, DOI 10.1016/j.bandl.2016.08.004
   Vicario CM, 2017, SOC COGN AFFECT NEUR, V12, P352, DOI 10.1093/scan/nsw129
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   Weikum WM, 2013, FRONT CELL NEUROSCI, V7, DOI 10.3389/fncel.2013.00180
   WEISKRANTZ L, 1973, BRIT J PSYCHOL, V64, P511, DOI 10.1111/j.2044-8295.1973.tb01375.x
   WEISKRANTZ L, 1974, PHYSIOL PSYCHOL, V2, P53
   Weiskrantz L., 1960, STIMULATION FRONTAL
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Wilson SM, 2006, NEUROIMAGE, V33, P316, DOI 10.1016/j.neuroimage.2006.05.032
NR 63
TC 4
Z9 4
U1 0
U2 1
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD MAY
PY 2019
VL 128
SI SI
BP 290
EP 296
DI 10.1016/j.neuropsychologia.2018.01.006
PG 7
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA JJ1HF
UT WOS:000493910900035
PM 29317325
DA 2021-02-24
ER

PT J
AU Wright, BA
   LeBlanc, EK
   Little, DF
   Conderman, JS
   Glavin, CC
AF Wright, Beverly A.
   LeBlanc, Emma K.
   Little, David F.
   Conderman, Jessica S.
   Glavin, Courtney Coburn
TI Semi-supervised learning of a nonnative phonetic contrast: How much
   feedback is enough?
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Perceptual learning; Long-term memory; Speech perception
ID PERFORMANCE; PLASTICITY; PERIODS; TASK
AB Semi-supervised learning refers to learning that occurs when feedback about performance is provided on only a subset of training trials. Algorithms for semi-supervised learning are popular in machine learning because of their minimal reliance on labeled data. There have been, however, only a few reports of semi-supervised learning in humans. Here we document human semi-supervised learning on a nonnative phonetic classification task. Classification performance remained unchanged when 60 feedback trials were provided on each of the two days of training. In contrast, performance improved when 60 feedback trials were combined with 240 no-feedback trials each day. In variants of this successful semi-supervised regimen, increasing the daily number of feedback trials from 60 to 240 did not increase the amount of learning, while decreasing that number to 30 abolished learning. Finally, replacing the no-feedback trials with stimulus exposure alone had little effect on the outcome. These results were an unexpected consequence of combining training periods with feedback and testing periods without feedback, illustrating that no-feedback testing can influence learning outcomes. More broadly, these data suggest that task performance with feedback can function as an all-or-none trigger for recruiting the contribution of trials without feedback, or mere stimulus exposures, to human learning.
C1 [Wright, Beverly A.] Northwestern Univ, Dept Commun Sci & Disorders, Northwestern Inst Neurosci, Knowles Hearing Ctr, Evanston, IL 60208 USA.
   [LeBlanc, Emma K.; Conderman, Jessica S.; Glavin, Courtney Coburn] Northwestern Univ, Dept Commun Sci & Disorders, Evanston, IL USA.
   [Little, David F.] Johns Hopkins Univ, Dept Elect & Comp Engn, Baltimore, MD 21218 USA.
RP Wright, BA (corresponding author), Northwestern Univ, Dept Commun Sci & Disorders, Northwestern Inst Neurosci, Knowles Hearing Ctr, Evanston, IL 60208 USA.
EM b-wright@northwestern.edu
FU Defense Advanced Research Projects Agency (DARPA) Biological
   Technologies Office (BTO) TNT program under Doug Weber and Tristan
   McClure-Begley, through the Space and Naval Warfare Systems Center
   [N66001-17-2-4011]; Knowles Hearing Center at Northwestern University
FX This work was sponsored in part by the Defense Advanced Research
   Projects Agency (DARPA) Biological Technologies Office (BTO) TNT
   program, under the auspices of Doug Weber and Tristan McClure-Begley,
   through the Space and Naval Warfare Systems Center, Pacific
   Grant/Contract No. N66001-17-2-4011, and by the Knowles Hearing Center
   at Northwestern University. Any opinions, findings, and conclusions or
   recommendations expressed in this publication are those of the authors
   and do not necessarily reflect the views of the DARPA BTO. The data and
   analyses for all experiments are available at https://osf.io/d83c4/.None
   of the experiments was preregistered.
CR Aberg KC, 2009, VISION RES, V49, P2087, DOI 10.1016/j.visres.2009.05.020
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Cohen J, 1988, STAT POWER ANAL BEHA, P1, DOI DOI 10.4324/9780203771587
   Gelman A, 2000, COMPUTATION STAT, V15, P373, DOI 10.1007/s001800000040
   Gelman A., 2007, DATA ANAL USING REGR
   Gelman A., 2014, BAYESIAN DATA ANAL, V3rd
   Gelman A, 2012, J RES EDUC EFF, V5, P189, DOI 10.1080/19345747.2011.618213
   Gelman A, 2008, ANN APPL STAT, V2, P1360, DOI 10.1214/08-AOAS191
   Gibson BR, 2013, TOP COGN SCI, V5, P132, DOI 10.1111/tops.12010
   Hauptmann B, 2005, COGNITIVE BRAIN RES, V24, P181, DOI 10.1016/j.cogbrainres.2005.01.012
   Hauptmann B, 2002, COGNITIVE BRAIN RES, V13, P313, DOI 10.1016/S0926-6410(01)00124-0
   Hoffman MD, 2014, J MACH LEARN RES, V15, P1593
   Kalish CW, 2015, DEVELOPMENTAL SCI, V18, P940, DOI 10.1111/desc.12280
   Kalish CW, 2011, COGNITION, V120, P106, DOI 10.1016/j.cognition.2011.03.002
   Lake B., 2011, P ANN M COGN SCI SOC, V33
   Little DF, 2019, ATTEN PERCEPT PSYCHO, V81, P344, DOI 10.3758/s13414-018-1584-x
   Little DF, 2017, CURR BIOL, V27, P3699, DOI 10.1016/j.cub.2017.10.032
   MACKAIN KS, 1981, APPL PSYCHOLINGUIST, V2, P369, DOI 10.1017/S0142716400009796
   McCandliss BD, 2002, COGN AFFECT BEHAV NE, V2, P89, DOI 10.3758/CABN.2.2.89
   MCCLASKEY CL, 1983, PERCEPT PSYCHOPHYS, V34, P323, DOI 10.3758/BF03203044
   Ofen-Noy N, 2003, COGNITIVE BRAIN RES, V17, P507, DOI 10.1016/S0926-6410(03)00166-6
   Ortiz JA, 2010, EXP BRAIN RES, V201, P441, DOI 10.1007/s00221-009-2053-5
   PISONI DB, 1982, J EXP PSYCHOL HUMAN, V8, P297, DOI 10.1037/0096-1523.8.2.297
   Rogers T. T., 2010, P ANN M COGN SCI SOC, V32
   Savion-Lemieux T, 2005, EXP BRAIN RES, V161, P423, DOI 10.1007/s00221-004-2085-9
   Szpiro SFA, 2014, VISION RES, V101, P118, DOI 10.1016/j.visres.2014.06.004
   Tremblay K, 1997, J ACOUST SOC AM, V102, P3762, DOI 10.1121/1.420139
   Tricomi E, 2006, J COGNITIVE NEUROSCI, V18, P1029, DOI 10.1162/jocn.2006.18.6.1029
   Vong WK, 2016, PSYCHON B REV, V23, P230, DOI 10.3758/s13423-015-0857-9
   Wright BA, 2007, EXP BRAIN RES, V180, P727, DOI 10.1007/s00221-007-0898-z
   Wright BA, 2015, J ACOUST SOC AM, V138, P928, DOI 10.1121/1.4927411
   Wright BA, 2010, J NEUROSCI, V30, P12868, DOI 10.1523/JNEUROSCI.0487-10.2010
   Zhu X, 2010, STRUCT HLTH MONIT, P1241
   Zhu X., 2007, 22 AAAI C ART INT AA
   Zhu X., 2009, INTRO SEMISUPERVISED
NR 35
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 927
EP 934
DI 10.3758/s13414-019-01741-4
PG 8
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6NQ
UT WOS:000485098800005
PM 31062297
OA Bronze
DA 2021-02-24
ER

PT J
AU Vlahou, E
   Seitz, AR
   Kopco, N
AF Vlahou, Eleni
   Seitz, Aaron R.
   Kopco, Norbert
TI Nonnative implicit phonetic training in multiple reverberant
   environments
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Adaptation to reverberation; Speech perception; Phonetic learning;
   Implicit learning; Perceptual learning
ID R-VERTICAL-BAR; JAPANESE LISTENERS; SPEECH-PERCEPTION;
   CONFIDENCE-INTERVALS; ADVERSE CONDITIONS; ENGLISH; NOISE; ROOM;
   COMPENSATION; RECOGNITION
AB Speech intelligibility is adversely affected by reverberation, particularly when listening to a foreign language. However, little is known about how phonetic learning is affected by room acoustics. This study investigated how room reverberation impacts the acquisition of novel phonetic categories during implicit training in virtual environments. Listeners were trained to distinguish a difficult nonnative dental-retroflex contrast in phonemes presented either in a fixed room (anechoic or reverberant) or in multiple anechoic and reverberant spaces typical of everyday listening. Training employed a videogame in which phonetic stimuli were paired with rewards delivered upon successful task performance, in accordance with the task-irrelevant perceptual learning paradigm. Before and after training, participants were tested using familiar and unfamiliar speech tokens, speakers, and rooms. Implicit training performed in multiple rooms induced learning, while training in a single environment did not. The multiple-room training improvement generalized to untrained rooms and tokens, but not to untrained voices. These results show that, following implicit training, nonnative listeners can overcome the detrimental effects of reverberation and that exposure to sounds in multiple reverberant environments during training enhances implicit phonetic learning rather than disrupting it.
C1 [Vlahou, Eleni; Seitz, Aaron R.] Univ Calif Riverside, Dept Psychol, 900 Univ Ave, Riverside, CA 92521 USA.
   [Vlahou, Eleni; Kopco, Norbert] Safarik Univ, Fac Sci, Inst Comp Sci, Kosice, Slovakia.
   [Kopco, Norbert] Boston Univ, Hearing Res Ctr, Boston, MA 02215 USA.
   [Kopco, Norbert] Boston Univ, Dept Biomed Engn, Boston, MA 02215 USA.
RP Vlahou, E (corresponding author), Univ Calif Riverside, Dept Psychol, 900 Univ Ave, Riverside, CA 92521 USA.; Vlahou, E (corresponding author), Safarik Univ, Fac Sci, Inst Comp Sci, Kosice, Slovakia.
EM evlahou@gmail.com
RI Kopco, Norbert/S-1447-2016
OI Kopco, Norbert/0000-0001-5901-6355; Vlahou, Eleni/0000-0003-2497-577X
FU Slovak Science Grant Agency VEGAVedecka grantova agentura MSVVaS SR a
   SAV (VEGA) [1/1011/16]; SRDA [APVV-0452-12]; EU H2020-MSCA-RISE-2015
   [691229]; EU RDP project TECHNICOM I [ITMS: 26220220182]; EU RDP project
   TECHNICOM II [ITMS2014+: 313011D23]; National Science FoundationNational
   Science Foundation (NSF) [BCS-1057]
FX This work was supported by the Slovak Science Grant Agency VEGA
   1/1011/16, SRDA, Contract No. APVV-0452-12, EU H2020-MSCA-RISE-2015
   Grant No. 691229, by the EU RDP projects TECHNICOM I, ITMS: 26220220182,
   and TECHNICOM II, ITMS2014+: 313011D23 and by National Science
   Foundation Grant No. BCS-1057.
CR Banai K, 2016, J ACOUST SOC AM, V140, P1686, DOI 10.1121/1.4962499
   Beeston AV, 2014, J ACOUST SOC AM, V136, P3072, DOI 10.1121/1.4900596
   Bejjanki VR, 2014, P NATL ACAD SCI USA, V111, P16961, DOI 10.1073/pnas.1417056111
   Brandewie E, 2010, J ACOUST SOC AM, V128, P291, DOI 10.1121/1.3436565
   Cooke M, 2008, J ACOUST SOC AM, V123, P414, DOI 10.1121/1.2804952
   Cousineau D, 2005, TUTOR QUANT METHODS, V1, P42, DOI 10.20982/tqmp.01.1.p042
   Creel SC, 2012, LANG COGNITIVE PROC, V27, P1021, DOI 10.1080/01690965.2011.610597
   David M, 2014, J ACOUST SOC AM, V136, P5, DOI 10.1121/1.4883387
   Devore S., 2003, PP INT C AUD DISPL B, P75
   Flege J. E., 2003, PHONETICS PHONOLOGY, P319, DOI DOI 10.1515/9783110895094.319
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Golestani N, 2004, NEUROIMAGE, V21, P494, DOI 10.1016/j.neuroimage.2003.09.071
   Green CS, 2010, TOP COGN SCI, V2, P202, DOI 10.1111/j.1756-8765.2009.01054.x
   HARTMANN WM, 1983, J ACOUST SOC AM, V74, P1380, DOI 10.1121/1.390163
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Iverson P, 2005, J ACOUST SOC AM, V118, P3267, DOI 10.1121/1.2062307
   Kayser H, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/298605
   Lim SJ, 2011, COGNITIVE SCI, V35, P1390, DOI 10.1111/j.1551-6709.2011.01192.x
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   LOGAN JS, 1991, J ACOUST SOC AM, V89, P874, DOI 10.1121/1.1894649
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Morey RD, 2008, TUTOR QUANT METHODS, V4, P61, DOI 10.20982/tqmp.04.2.p061
   NABELEK AK, 1984, J ACOUST SOC AM, V75, P632
   Parikh G, 2005, J ACOUST SOC AM, V118, P3874, DOI 10.1121/1.2118407
   Peng ZE, 2016, J ACOUST SOC AM, V139, P2772, DOI 10.1121/1.4948564
   Polley DB, 2008, J AM ACAD AUDIOL, V19, P780, DOI 10.3766/jaaa.19.10.6
   Polley DB, 2006, J NEUROSCI, V26, P4970, DOI 10.1523/JNEUROSCI.3771-05.2006
   Pruitt JS, 2006, J ACOUST SOC AM, V119, P1684, DOI 10.1121/1.2161427
   Rogers CL, 2006, APPL PSYCHOLINGUIST, V27, P465, DOI 10.1017/S014271640606036X
   Seitz A, 2005, TRENDS COGN SCI, V9, P329, DOI 10.1016/j.tics.2005.05.010
   Seitz AR, 2007, CURR OPIN NEUROBIOL, V17, P148, DOI 10.1016/j.conb.2007.02.004
   Seitz AR, 2010, COGNITION, V115, P435, DOI 10.1016/j.cognition.2010.03.004
   Seitz AR, 2009, VISION RES, V49, P2604, DOI 10.1016/j.visres.2009.08.003
   Seitz AR, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003792
   Seitz AR, 2003, NATURE, V422, P36, DOI 10.1038/422036a
   Shinn-Cunningham B., 2000, P INT C AUD DISPL AT, P126
   Shinn-Cunningham BG, 2005, J ACOUST SOC AM, V117, P3100, DOI 10.1121/1.1872572
   Srinivasan NK, 2013, J ACOUST SOC AM, V133, pEL33, DOI 10.1121/1.4771978
   STRANGE W, 1984, PERCEPT PSYCHOPHYS, V36, P131, DOI 10.3758/BF03202673
   Takagi N, 2002, J ACOUST SOC AM, V111, P2887, DOI 10.1121/1.1480418
   TAKATA Y, 1990, J ACOUST SOC AM, V88, P663, DOI 10.1121/1.399769
   Ueno K., 2005, P FOR AC BUD HUNG
   Vlahou EL, 2012, J EXP PSYCHOL GEN, V141, P363, DOI 10.1037/a0025014
   Watkins AJ, 2005, J ACOUST SOC AM, V118, P249, DOI 10.1121/1.1923369
   WERKER JF, 1984, J ACOUST SOC AM, V75, P1866, DOI 10.1121/1.390988
   Zahorik P, 2005, ACTA ACUST UNITED AC, V91, P409
NR 48
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 935
EP 947
DI 10.3758/s13414-019-01680-0
PG 13
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6NQ
UT WOS:000485098800006
PM 30737758
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Heffner, CC
   Idsardi, WJ
   Newman, RS
AF Heffner, Christopher C.
   Idsardi, William J.
   Newman, Rochelle S.
TI Constraints on learning disjunctive, unidimensional auditory and
   phonetic categories
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Category learning; Categorization; Speech perception; Phonetics
ID COMPLEMENTARY SYSTEMS ACCOUNT; DECISION BOUND MODELS; PLUS-EXCEPTION
   MODEL; SPEECH-PERCEPTION; MEMORY; CLASSIFICATION; ABSTRACTION; EXEMPLAR;
   REPRESENTATIONS; IDENTIFICATION
AB Phonetic categories must be learned, but the processes that allow that learning to unfold are still under debate. The current study investigates constraints on the structure of categories that can be learned and whether these constraints are speech-specific. Category structure constraints are a key difference between theories of category learning, which can roughly be divided into instance-based learning (i.e., exemplar only) and abstractionist learning (i.e., at least partly rule-based or prototype-based) theories. Abstractionist theories can relatively easily accommodate constraints on the structure of categories that can be learned, whereas instance-based theories cannot easily include such constraints. The current study included three groups to investigate these possible constraints as well as their speech specificity: English speakers learning German speech categories, German speakers learning German speech categories, and English speakers learning musical instrument categories, with each group including participants who learned different sets of categories. Both speech groups had greater difficulty learning disjunctive categories (ones that require an or statement) than nondisjunctive categories, which suggests that instance-based learning alone is insufficient to explain the learning of the participants learning phonetic categories. This fact was true for both novices (English speakers) and experts (German speakers), which implies that expertise with the materials used cannot explain the patterns observed. However, the same was not true for the musical instrument categories, suggesting a degree of domain-specificity in these constraints that cannot be explained through recourse to expertise alone.
C1 [Heffner, Christopher C.; Idsardi, William J.; Newman, Rochelle S.] Univ Maryland, Program Neurosci & Cognit Sci, College Pk, MD 20742 USA.
   [Heffner, Christopher C.; Idsardi, William J.] Univ Maryland, Dept Linguist, College Pk, MD 20742 USA.
   [Heffner, Christopher C.; Newman, Rochelle S.] Univ Maryland, Dept Speech & Hearing Sci, College Pk, MD 20742 USA.
   [Heffner, Christopher C.] Univ Connecticut, Dept Speech Language & Hearing Sci, 850 Bolton Rd,U-1085, Storrs, CT 06269 USA.
RP Heffner, CC (corresponding author), Univ Maryland, Program Neurosci & Cognit Sci, College Pk, MD 20742 USA.; Heffner, CC (corresponding author), Univ Maryland, Dept Linguist, College Pk, MD 20742 USA.; Heffner, CC (corresponding author), Univ Maryland, Dept Speech & Hearing Sci, College Pk, MD 20742 USA.; Heffner, CC (corresponding author), Univ Connecticut, Dept Speech Language & Hearing Sci, 850 Bolton Rd,U-1085, Storrs, CT 06269 USA.
EM christopher.heffner@uconn.edu
RI Newman, Rochelle/AAA-3185-2019
OI Newman, Rochelle/0000-0002-1626-4241
FU National Science FoundationNational Science Foundation (NSF); University
   of Maryland, College Park Graduate School Flagship Fellowship; NSF IGERT
   Grant [0801465]; NSF Linguistics Doctoral Dissertation Research
   Improvement grant [BCS 1650791]; Maryland Language Science Center;
   University of Maryland-University of Tubingen International
   Interdisciplinary Research and Teaching Collaboration; Department of
   Linguistics at the University of Maryland, College Park, at the sixth
   annual Michigan State Undergraduate Linguistics Conference (MSULC) in
   East Lansing; Department of Linguistics and Germanic, Slavic, Asian, and
   African Languages of Michigan State University
FX This work was supported by a National Science Foundation Graduate
   Research Fellowship award and a University of Maryland, College Park
   Graduate School Flagship Fellowship, to C.C.H., as well as NSF IGERT
   Grant 0801465 (PI: C. Phillips), an NSF Linguistics Doctoral
   Dissertation Research Improvement grant awarded to W.J.I. (co-PI: CCH),
   BCS 1650791, the Maryland Language Science Center, and the University of
   Maryland-University of Tubingen International Interdisciplinary Research
   and Teaching Collaboration. Data from this experiment will be available
   online, in line with the Open Science Framework, for participants who
   consented to sharing data. We thank Peter Deaville, Stephen DeVilbiss,
   Scott Kaplowitz, Priyanka Konanur, Zoe Schlueter, and the members of the
   UMD Language Development Lab for their help in running English-speaking
   participants for this project. We thank Andrea Weber's lab at Eberhard
   Karls University, Tubingen, for their space and support for the
   German-speaking participants, particularly Sara Beck, Ann-Kathrin Grohe,
   Lisa Kienzle, and Sarah Schwarz. Michael Key generously allowed us to
   use his German fricative stimuli for this study.; Many people have
   provided discussion and insightful comments during the development and
   publication process in this study. Among others, we would like to thank
   Ann Bradlow, Al Braun, Catherine Carr, Bharath Chandrasekaran, Jeff
   Chrabaszcz, Karthik Durvasula, Naomi Feldman, Drew Hendrickson, Lori
   Holt, Ellen Lau, ToddMaddox, HolgerMitterer, Emily Myers, Chris Neufeld,
   Rob Nosofsky, Janet Pierrehumbert, Eva Reinisch, Kirsten Smayda, and Joe
   Toscano. Jared Linck gave immensely useful statistical support. Portions
   of this research were presented at the eighty-eighth annual Meeting of
   the Linguistics Society of America (LSA) in Minneapolis, Minnesota,
   travel to which was financed by the Department of Linguistics at the
   University of Maryland, College Park, at the sixth annual Michigan State
   Undergraduate Linguistics Conference (MSULC) in East Lansing, Michigan,
   travel to which was funded by the Department of Linguistics and
   Germanic, Slavic, Asian, and African Languages of Michigan State
   University, and at the Mini-Workshop on Phonetic Processing and Learning
   at Eberhard Karls University, Tubingen in Tubingen, Baden-Wurttemberg,
   Germany.
CR ASHBY FG, 1988, J EXP PSYCHOL LEARN, V14, P33, DOI 10.1037/0278-7393.14.1.33
   ASHBY FG, 1993, J MATH PSYCHOL, V37, P372, DOI 10.1006/jmps.1993.1023
   Ashby FG, 1998, PSYCHOL REV, V105, P442, DOI 10.1037/0033-295X.105.3.442
   ASHBY FG, 1986, PSYCHOL REV, V93, P154, DOI 10.1037/0033-295X.93.2.154
   Ashby FG, 1999, PSYCHON B REV, V6, P363, DOI 10.3758/BF03210826
   ASHBY FG, 1995, J MATH PSYCHOL, V39, P216, DOI 10.1006/jmps.1995.1021
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   BRAIDA LD, 1984, J ACOUST SOC AM, V76, P722, DOI 10.1121/1.391258
   Buxo-Lugo A, 2016, J MEM LANG, V90, P1, DOI 10.1016/j.jml.2016.03.001
   Bybee Joan, 2002, STUDIES 2 LANGUAGE A, V24, P215, DOI DOI 10.1017/S0272263102002061
   CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791
   Chandrasekaran B, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00825
   Chandrasekaran B, 2014, PSYCHON B REV, V21, P488, DOI 10.3758/s13423-013-0501-5
   Chandrasekaran B, 2010, J ACOUST SOC AM, V128, P456, DOI 10.1121/1.3445785
   Dahan D, 2008, COGNITION, V108, P710, DOI 10.1016/j.cognition.2008.06.003
   Davis MH, 2009, PHILOS T R SOC B, V364, P3773, DOI 10.1098/rstb.2009.0111
   Diehl RL, 2008, PHILOS T R SOC B, V363, P965, DOI 10.1098/rstb.2007.2153
   Diehl RL, 2000, PHONETICA, V57, P267, DOI 10.1159/000028479
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldstone RL, 2001, COGNITION, V78, P27, DOI 10.1016/S0010-0277(00)00099-8
   Goldstone RL, 2010, WIRES COGN SCI, V1, P69, DOI 10.1002/wcs.26
   Goodman ND, 2008, COGNITIVE SCI, V32, P108, DOI 10.1080/03640210701802071
   Hawkins S, 2003, J PHONETICS, V31, P373, DOI 10.1016/j.wocn.2003.09.006
   Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014
   HINTZMAN DL, 1986, PSYCHOL REV, V93, P411, DOI 10.1037/0033-295X.93.4.411
   Holt LL, 2004, J ACOUST SOC AM, V116, P1763, DOI 10.1121/1.1778838
   Holt LL, 2008, CURR DIR PSYCHOL SCI, V17, P42, DOI 10.1111/j.1467-8721.2008.00545.x
   HOMA D, 1973, J EXP PSYCHOL, V101, P116, DOI 10.1037/h0035772
   Johnson EK, 2008, INFANCY, V13, P440, DOI 10.1080/15250000802329321
   Johnson K., 2007, EXPT APPROACHES PHON, P25
   Kassambara A, 2018, SURVMINER DRAWING SU
   Kemp C, 2007, DEVELOPMENTAL SCI, V10, P307, DOI 10.1111/j.1467-7687.2007.00585.x
   Key M, 2014, J ACOUST SOC AM, V135, pEL350, DOI 10.1121/1.4879669
   Kingston J, 2003, LANG SPEECH, V46, P295, DOI 10.1177/00238309030460020201
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   LIN DY, 1989, J AM STAT ASSOC, V84, P1074, DOI 10.2307/2290085
   Lindsay S, 2010, LANG LEARN, V60, P45, DOI 10.1111/j.1467-9922.2010.00600.x
   LISKER L, 1985, J ACOUST SOC AM, V77, P1199, DOI 10.1121/1.392185
   Livingston KR, 1998, J EXP PSYCHOL LEARN, V24, P732, DOI 10.1037/0278-7393.24.3.732
   Lotto AJ, 2004, SOUND SENSE 50 YEARS, pC181
   Love BC, 2004, PSYCHOL REV, V111, P309, DOI 10.1037/0033-295X.111.2.309
   Maddox WT, 2014, BILING-LANG COGN, V17, P709, DOI 10.1017/S1366728913000783
   Maddox WT, 2014, CORTEX, V58, P186, DOI 10.1016/j.cortex.2014.06.013
   Maddox WT, 2002, PERCEPT PSYCHOPHYS, V64, P584, DOI 10.3758/BF03194728
   Mair P., 2016, SMACOF MULTIDIMENSIO
   MANTEL NATHAN, 1966, CANCERCHEMOTHERAP REP, V50, P163
   MCKINLEY SC, 1995, J EXP PSYCHOL HUMAN, V21, P128, DOI 10.1037/0096-1523.21.1.128
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   McMurray B, 2009, DEVELOPMENTAL SCI, V12, P369, DOI 10.1111/j.1467-7687.2009.00822.x
   Minda JP, 2008, J EXP PSYCHOL LEARN, V34, P1518, DOI 10.1037/a0013355
   Moreton E, 2017, COGNITIVE SCI, V41, P4, DOI 10.1111/cogs.12319
   Myers EB, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00238
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Nosofsky RM, 1998, PSYCHON B REV, V5, P345, DOI 10.3758/BF03208813
   NOSOFSKY RM, 1994, MEM COGNITION, V22, P352, DOI 10.3758/BF03200862
   NOSOFSKY RM, 1994, PSYCHOL REV, V101, P53, DOI 10.1037/0033-295X.101.1.53
   NOSOFSKY RM, 1987, J EXP PSYCHOL LEARN, V13, P87, DOI 10.1037/0278-7393.13.1.87
   NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39
   Pajak B, 2014, J PHONETICS, V46, P147, DOI 10.1016/j.wocn.2014.07.001
   Palmeri TJ, 2004, TRENDS COGN SCI, V8, P378, DOI 10.1016/j.tics.2004.06.001
   PETO R, 1972, J R STAT SOC SER A-G, V135, P185, DOI 10.2307/2344317
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Pitt MA, 2011, J PHONETICS, V39, P304, DOI 10.1016/j.wocn.2010.07.004
   Poeppel D, 2008, PHILOS T R SOC B, V363, P1071, DOI 10.1098/rstb.2007.2160
   Port R, 2007, NEW IDEAS PSYCHOL, V25, P143, DOI 10.1016/j.newideapsych.2007.02.001
   Port RF, 2010, LANG SCI, V32, P43, DOI 10.1016/j.langsci.2009.06.001
   Pycha A, 2010, PHONOLOGY, V27, P119, DOI 10.1017/S0952675710000059
   Pycha A, 2009, J INT PHON ASSOC, V39, P1, DOI 10.1017/S0025100308003666
   REPP BH, 1982, PSYCHOL BULL, V92, P81, DOI 10.1037/0033-2909.92.1.81
   Rocamora M., 2009, 12 BRAZ S COMP MUS R
   Rosseel Y, 2002, J MATH PSYCHOL, V46, P178, DOI 10.1006/jmps.2001.1379
   SAMUEL AG, 1982, PERCEPT PSYCHOPHYS, V31, P307, DOI 10.3758/BF03202653
   Scharinger M, 2013, MEM COGNITION, V41, P752, DOI 10.3758/s13421-013-0294-9
   SHEPARD RN, 1961, PSYCHOL MONOGR, V75, P1, DOI 10.1037/h0093825
   Slote J, 2016, BEHAV RES METHODS, V48, P553, DOI 10.3758/s13428-015-0599-7
   Smith R, 2012, J PHONETICS, V40, P213, DOI 10.1016/j.wocn.2011.11.003
   Squire LR, 2009, J NEUROSCI, V29, P12711, DOI 10.1523/JNEUROSCI.3575-09.2009
   THERNEAU TM, 1990, BIOMETRIKA, V77, P147, DOI 10.2307/2336057
   Toscano JC, 2010, COGNITIVE SCI, V34, P434, DOI 10.1111/j.1551-6709.2009.01077.x
   Ullman M.T., 2016, NEUROBIOLOGY LANGUAG, P953, DOI DOI 10.1016/B978-0-12-407794-2.00076-6
   Ullman MT, 2004, COGNITION, V92, P231, DOI 10.1016/j.cognition.2003.10.008
   Zeithamova D, 2006, MEM COGNITION, V34, P387, DOI 10.3758/BF03193416
NR 84
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 958
EP 980
DI 10.3758/s13414-019-01683-x
PG 23
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6NQ
UT WOS:000485098800008
OA Bronze
DA 2021-02-24
ER

PT J
AU Baese-Berk, MM
AF Baese-Berk, Melissa Michaud
TI Interactions between speech perception and production during learning of
   novel phonemic categories
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Speech production; Perceptual learning
ID TRAINING JAPANESE LISTENERS; R-VERTICAL-BAR; ACOUSTIC VARIABILITY;
   NONNATIVE SPEAKERS; 2ND-LANGUAGE; DISCRIMINATION; IMITATION; SOUNDS;
   ADULTS; REORGANIZATION
AB A successful language learner must be able to perceive and produce novel sounds in their second language. However, the relationship between learning in perception and production is unclear. Some studies show correlations between the two modalities; however, other studies have not shown such correlations. In the present study, I examine learning in perception and production after training in a distributional learning paradigm. Training modality is manipulated, while testing modality remained constant. Overall, participants showed substantial learning in the modality in which they were trained; however, learning across modalities shows a more complex pattern. Although individuals trained in perception improved in production, individuals trained in production did not show substantial learning in perception. That is, production during training disrupted perceptual learning. Further, correlations between learning in the two modalities were not strong. Several possible explanations for the pattern of results are explored, including a close examination of the role of production variability, and the results are explained using a paradigm appealing to shared cognitive resources. The article concludes with a discussion of the implications of these results for theories of second-language learning, speech perception, and production.
C1 [Baese-Berk, Melissa Michaud] 1290 Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.
RP Baese-Berk, MM (corresponding author), 1290 Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.
EM mbaesebe@uoregon.edu
FU National Science FoundationNational Science Foundation (NSF)
   [BCS-0951943, BCS-1734166]
FX This work was supported by National Science Foundation Grants
   BCS-0951943 and BCS-1734166. I would like to thank Ann Bradlow, Matthew
   Goldrick, and Arthur Samuel for their comments on previous versions of
   this work.
CR Arnold HS, 2014, J SPEECH LANG HEAR R, V57, P1296, DOI 10.1044/2014_JSLHR-S-12-0265
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Babel M, 2014, LAB PHONOL, V5, P123, DOI 10.1515/lp-2014-0006
   Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001
   Baese-Berk MM, 2016, J MEM LANG, V89, P23, DOI 10.1016/j.jml.2015.10.008
   Baese-Berk MM, 2015, J ACOUST SOC AM, V138, pEL223, DOI 10.1121/1.4929622
   Baese-Berk MM, 2013, J ACOUST SOC AM, V133, pEL174, DOI 10.1121/1.4789864
   Barcroft J, 2005, STUD SECOND LANG ACQ, V27, P387, DOI 10.1017/S0272263105050175
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best C. T., 1994, DEV SPEECH PERCEPT, V167, P224
   BEST CT, 1995, INFANT BEHAV DEV, V18, P339, DOI 10.1016/0163-6383(95)90022-5
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P, 2015, PRAAT DOING PHONETIC
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P977, DOI 10.3758/BF03206911
   Brouwer S, 2010, J ACOUST SOC AM, V128, pEL32, DOI 10.1121/1.3448022
   Brown H.D., 2015, TEACHING PRINCIPLES
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Davidson L, 2016, J PHONETICS, V54, P35, DOI 10.1016/j.wocn.2015.09.003
   Diehl R. L., 1989, ECOL PSYCHOL, V1, P121, DOI [10.1207/s15326969-co0102_2, DOI 10.1207/S15326969-CO0102_2, DOI 10.1207/s15326969eco0102_2]
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Dromey C, 2003, J SPEECH LANG HEAR R, V46, P1234, DOI 10.1044/1092-4388(2003/096)
   Ellis N.C., 2003, HDB 2 LANGUAGE ACQUI, P33, DOI DOI 10.1002/9780470756492.CH4
   Ellis NC, 2009, HDB LANGUAGE TEACHIN, P139, DOI DOI 10.1002/9781444315783.CH9
   Ellis R., 2013, EXPLORING LANGUAGE P
   Ferreira VS, 2002, J EXP PSYCHOL LEARN, V28, P1187, DOI 10.1037//0278-7393.28.6.1187
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   Francis AL, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00263
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger SD, 2004, PSYCHON B REV, V11, P716, DOI 10.3758/BF03196625
   GOTO H, 1971, NEUROPSYCHOLOGIA, V9, P317, DOI 10.1016/0028-3932(71)90027-3
   Guenther FH, 1998, PSYCHOL REV, V105, P611, DOI 10.1037/0033-295X.105.4.611-633
   Hao YC, 2016, J PHONETICS, V54, P151, DOI 10.1016/j.wocn.2015.10.003
   Hattori K, 2010, THESIS
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Hymes Dell, 1972, SOCIOLINGUISTICS, P269
   Iverson P, 2005, J ACOUST SOC AM, V118, P3267, DOI 10.1121/1.2062307
   Iverson P, 2009, J ACOUST SOC AM, V126, P866, DOI 10.1121/1.3148196
   KINGSTON J, 1994, LANGUAGE, V70, P419, DOI 10.2307/416481
   Kingston J, 2003, LANG SPEECH, V46, P295, DOI 10.1177/00238309030460020201
   Kingston J., 1995, PHONOLOGY PHONETIC E, VIV, P7
   KRASHEN S, 1989, MOD LANG J, V73, P440, DOI 10.2307/326879
   KRASHEN S., 1985, INPUT HYPOTHESIS ISS
   Krashen S, 1981, SCH LANGUAGE MINORIT, P51
   Kronrod Y, 2016, PSYCHON B REV, V23, P1681, DOI 10.3758/s13423-016-1049-y
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Leach L, 2007, COGNITIVE PSYCHOL, V55, P306, DOI 10.1016/j.cogpsych.2007.01.001
   Leather J., 1990, NEW SOUNDS 90, V90, P72
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   LIBERMAN AM, 1989, SCIENCE, V243, P489, DOI 10.1126/science.2643163
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   LIBERMAN AM, 1952, AM J PSYCHOL, V65, P497, DOI 10.2307/1418032
   LILJENCRANTS J, 1972, LANGUAGE, V48, P839, DOI 10.2307/411991
   Lim SJ, 2011, COGNITIVE SCI, V35, P1390, DOI 10.1111/j.1551-6709.2011.01192.x
   LOGAN JS, 1991, J ACOUST SOC AM, V89, P874, DOI 10.1121/1.1894649
   MACKAIN KS, 1981, APPL PSYCHOLINGUIST, V2, P369, DOI 10.1017/S0142716400009796
   Maye J, 2000, PROC ANN BUCLD, P522
   MCCLASKEY CL, 1983, PERCEPT PSYCHOPHYS, V34, P323, DOI 10.3758/BF03203044
   McDONOUGH J, 2013, MAT METHODS ELT TEAC
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mitterer H, 2008, COGNITION, V109, P168, DOI 10.1016/j.cognition.2008.08.002
   Morrill T, 2016, P INT C SPEECH PROS, V2016, P1119
   Nagle CL, 2018, LANG LEARN, V68, P234, DOI 10.1111/lang.12275
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007
   Nunan D., 2002, METHODOLOGY LANGUAGE, P238, DOI [10.1017/CBO9780511667190.032, DOI 10.1017/CBO9780511667190.032]
   Nye PW, 2003, J PHONETICS, V31, P63, DOI 10.1016/S0095-4470(02)00072-4
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720
   Pederson E, 2010, J ACOUST SOC AM, V127, pEL54, DOI 10.1121/1.3292286
   Pegg J, 1992, PHONOLOGICAL DEV MOD, P285
   Perrachione TK, 2011, J ACOUST SOC AM, V130, P461, DOI 10.1121/1.3593366
   Polio C, 2007, ASSESSING IMPACT INP
   Prather JF, 2017, NEUROSCI BIOBEHAV R, V81, P225, DOI 10.1016/j.neubiorev.2016.12.035
   Rost GC, 2010, INFANCY, V15, P608, DOI 10.1111/j.1532-7078.2010.00033.x
   Samuel AG, 2011, LEXICAL REPRESENTATI
   SHELDON A, 1982, APPL PSYCHOLINGUIST, V3, P243, DOI 10.1017/S0142716400001417
   Shockley K, 2004, PERCEPT PSYCHOPHYS, V66, P422, DOI 10.3758/BF03194890
   Sidaras SK, 2009, J ACOUST SOC AM, V125, P3306, DOI 10.1121/1.3101452
   Sommers MS, 2007, APPL PSYCHOLINGUIST, V28, P231, DOI 10.1017/S0142716407070129
   STRANGE W, 1984, PERCEPT PSYCHOPHYS, V36, P131, DOI 10.3758/BF03202673
   Sumner M, 2011, COGNITION, V119, P131, DOI 10.1016/j.cognition.2010.10.018
   Tateishi M., 2013, THESIS
   Thorin J, 2018, J ACOUST SOC AM, V144, P92, DOI 10.1121/1.5044415
   Tremblay K, 1998, NEUROREPORT, V9, P3557, DOI 10.1097/00001756-199811160-00003
   Vallabha GK, 2004, J ACOUST SOC AM, V116, P1184, DOI 10.1121/1.1764832
   van Leussen JW, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01000
   Vaughn C. R., 2018, PHONETICA, DOI [10.1159/00048726, DOI 10.1159/00048726]
   Wade T, 2007, PHONETICA, V64, P122, DOI 10.1159/000107913
   Wang Y, 2003, J ACOUST SOC AM, V113, P1033, DOI 10.1121/1.1531176
   Wang Y, 1999, J ACOUST SOC AM, V106, P3649, DOI 10.1121/1.428217
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
NR 97
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 981
EP 1005
DI 10.3758/s13414-019-01725-4
PG 25
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6NQ
UT WOS:000485098800009
PM 30976997
OA Bronze
DA 2021-02-24
ER

PT J
AU Dial, HR
   McMurray, B
   Martin, RC
AF Dial, Heather R.
   McMurray, Bob
   Martin, Randi C.
TI Lexical processing depends on sublexical processing: Evidence from the
   visual world paradigm and aphasia
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Perceptual categorization and identification; Eye
   movements; Cognitive
ID SPEECH-PERCEPTION EVIDENCE; NEIGHBORHOOD ACTIVATION; TIME-COURSE;
   RECOGNITION; MODEL; INFORMATION; TRACKING; PHONEME; WORDS
AB Some early studies of people with aphasia reported strikingly better performance on lexical than on sublexical speech perception tasks. These findings challenged the claim that lexical processing depends on sublexical processing and suggested that acoustic information could be mapped directly to lexical representations. However, Dial and Martin (Neuropsychologia 96: 192-212, 2017) argued that these studies failed to match the discriminability of targets and distractors for the sublexical and lexical stimuli and showed that when using closely matched tasks with natural speech tokens, no patient performed substantially better at the lexical than at the sublexical processing task. In the current study, we sought to provide converging evidence for the dependence of lexical on sublexical processing by examining the perception of synthetic speech stimuli varied on a voice-onset time continuum using eye-tracking methodology, which is sensitive to online speech perception processes. Eight individuals with aphasia and ten age-matched controls completed two visual world paradigm tasks: phoneme (sublexical) and word (lexical) identification. For both identification and eye-movement data, strong correlations were observed between the sublexical and lexical tasks. Critically, no patient within the control range on the lexical task was impaired on the sublexical task. Overall, the current study supports the claim that lexical processing depends on sublexical processing. Implications for inferring deficits in people with aphasia and the use of sublexical tasks to assess sublexical processing are also discussed.
C1 [Dial, Heather R.] Univ Texas Austin, Dept Commun Sci & Disorders, 2504A Whitis Ave,A1100,4th Floor CMA, Austin, TX 78712 USA.
   [McMurray, Bob] Univ Iowa, Dept Psychol & Brain Sci, Dept Commun Sci & Disorders, Dept Linguist,Dept Otolaryngol, Iowa City, IA USA.
   [Martin, Randi C.] Rice Univ, Dept Psychol Sci, Houston, TX USA.
RP Dial, HR (corresponding author), Univ Texas Austin, Dept Commun Sci & Disorders, 2504A Whitis Ave,A1100,4th Floor CMA, Austin, TX 78712 USA.
EM heather.raye.dial@gmail.com
FU Gertrude Maurin fund; T.L.L. Temple Foundation Neuroplasticity Lab at
   Rice University; NIHUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [DC 008089]; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01DC008089, F32DC016812, R01DC008089, F32DC016812,
   F32DC016812] Funding Source: NIH RePORTER
FX ``We wish to acknowledge the contribution of the participants,
   particularly those with aphasia, to the current study. We would like to
   thank the members of the Brain and Language Lab at Rice University and
   the MACLab at University of Iowa for assistance. Finally, we would like
   to thank the reviewers for their thoughtful comments and suggestions.
   This work was supported by the Gertrude Maurin fund (HRD) and the T.L.L.
   Temple Foundation Neuroplasticity Lab (RM) at Rice University and NIH
   grant DC 008089 (BM).
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   [Anonymous], 2015, MATLAB STAT TOOLB RE
   BASSO A, 1977, CORTEX, V13, P85, DOI 10.1016/S0010-9452(77)80057-9
   BLUMSTEIN SE, 1977, NEUROPSYCHOLOGIA, V15, P371, DOI 10.1016/0028-3932(77)90089-6
   BLUMSTEIN SE, 1977, NEUROPSYCHOLOGIA, V15, P19, DOI 10.1016/0028-3932(77)90111-7
   BLUMSTEIN SE, 1994, BRAIN LANG, V46, P181, DOI 10.1006/brln.1994.1011
   Chen Q, 2012, PSYCHOL REV, V119, P417, DOI 10.1037/a0027175
   COLE RA, 1974, PSYCHOL REV, V81, P348, DOI 10.1037/h0036656
   Crawford JR, 1998, CLIN NEUROPSYCHOL, V12, P482, DOI 10.1076/clin.12.4.482.7241
   Dahan D, 2001, LANG COGNITIVE PROC, V16, P507, DOI 10.1080/01690960143000074
   Dalton DS, 2003, GERONTOLOGIST, V43, P661, DOI 10.1093/geront/43.5.661
   Dial H, 2017, NEUROPSYCHOLOGIA, V96, P192, DOI 10.1016/j.neuropsychologia.2017.01.009
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Gow DW, 2012, BRAIN LANG, V121, P273, DOI 10.1016/j.bandl.2012.03.005
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NATURE REV NEUROSCIE, V8, P292
   Hickok G, 2014, LANG COGN NEUROSCI, V29, P2, DOI 10.1080/01690965.2013.834370
   Huettig F, 2005, COGNITION, V96, pB23, DOI 10.1016/j.cognition.2004.10.003
   International Organization for Standardization, 2000, ISO7029
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   Luce PA, 2000, PERCEPT PSYCHOPHYS, V62, P615, DOI 10.3758/BF03212113
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B, 2017, EYELINKANAL
   McMurray B, 2017, NONLINEAR CURVEFITTI
   McMurray B, 2018, DEV PSYCHOL, V54, P1472, DOI 10.1037/dev0000542
   McMurray B, 2014, J SPEECH LANG HEAR R, V57, P1344, DOI 10.1044/2014_JSLHR-L-13-0196
   McMurray B, 2010, COGNITIVE PSYCHOL, V60, P1, DOI 10.1016/j.cogpsych.2009.06.003
   McMurray B, 2009, DEVELOPMENTAL SCI, V12, P369, DOI 10.1111/j.1467-7687.2009.00822.x
   McMurray B, 2008, J EXP PSYCHOL HUMAN, V34, P1609, DOI 10.1037/a0011747
   MICELI G, 1980, BRAIN LANG, V11, P159, DOI 10.1016/0093-934X(80)90117-0
   MILLER JL, 1989, PERCEPT PSYCHOPHYS, V46, P505, DOI 10.3758/BF03208147
   Mirman D, 2011, BRAIN LANG, V117, P53, DOI 10.1016/j.bandl.2011.01.004
   Nearey T. M., 1994, J INT PHON ASSOC, V24, P1, DOI [10.1017/S0025100300004965, DOI 10.1017/S0025100300004965]
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Norris D, 2000, BEHAV BRAIN SCI, V23, P299, DOI 10.1017/S0140525X00003241
   ODEN GC, 1978, PSYCHOL REV, V85, P172, DOI 10.1037/0033-295X.85.3.172
   Pierrehumbert JB, 2001, FREQUENCY EFFECTS EM, P45
   Repp BH., 1984, SPEECH LANG ADV BASI, V10, P243, DOI DOI 10.1016/B978-0-12-608610-2.50012-1
   Salverda AP, 2003, COGNITION, V90, P51, DOI 10.1016/S0010-0277(03)00139-2
NR 44
TC 0
Z9 1
U1 1
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 1047
EP 1064
DI 10.3758/s13414-019-01718-3
PG 18
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6NQ
UT WOS:000485098800013
PM 30945141
OA Bronze, Green Accepted
DA 2021-02-24
ER

PT J
AU McLaughlin, DE
   Carter, YD
   Cheng, CC
   Perrachione, TK
AF McLaughlin, Deirdre E.
   Carter, Yaminah D.
   Cheng, Cecilia C.
   Perrachione, Tyler K.
TI Hierarchical contributions of linguistic knowledge to talker
   identification: Phonological versus lexical familiarity
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Talker identification; Phonology; Priming; Accent;
   Language-familiarity effect
ID LANGUAGE-FAMILIARITY; VOICE RECOGNITION; CROSS-LANGUAGE; PERCEPTION;
   SPEECH; DISCRIMINATION; COMPREHENSION; VARIABILITY; EXPERIENCE; IMPACT
AB Listeners identify talkers more accurately when listening to their native language compared to an unfamiliar, foreign language. This language-familiarity effect in talker identification has been shown to arise from familiarity with both the sound patterns (phonetics and phonology) and the linguistic content (words) of one's native language. However, it has been unknown whether these two sources of information contribute independently to talker identification abilities, particularly whether hearing familiar words can facilitate talker identification in the absence of familiar phonetics. To isolate the contribution of lexical familiarity, we conducted three experiments that tested listeners' ability to identify talkers saying familiar words, but with unfamiliar phonetics. In two experiments, listeners identified talkers from recordings of their native language (English), an unfamiliar foreign language (Mandarin Chinese), or hybrid speech stimuli (sentences spoken in Mandarin, but which can be convincingly coerced to sound like English when presented with subtitles that prime plausible English-language lexical interpretations based on the Mandarin phonetics). In a third experiment, we explored natural variation in lexical-phonetic congruence as listeners identified talkers with varying degrees of a Mandarin accent. Priming listeners to hear English speech did not improve their ability to identify talkers speaking Mandarin, even after additional training, and talker identification accuracy decreased as talkers' phonetics became increasingly dissimilar to American English. Together, these experiments indicate that unfamiliar sound patterns preclude talker identification benefits otherwise afforded by familiar words. These results suggest that linguistic representations contribute hierarchically to talker identification; the facilitatory effect of familiar words requires the availability of familiar phonological forms.
C1 [McLaughlin, Deirdre E.; Carter, Yaminah D.; Cheng, Cecilia C.; Perrachione, Tyler K.] Boston Univ, Dept Speech Language & Hearing Sci, Coll Hlth & Rehabil Sci, Sargent Coll, 635 Commonwealth Ave, Boston, MA 02215 USA.
RP Perrachione, TK (corresponding author), Boston Univ, Dept Speech Language & Hearing Sci, Coll Hlth & Rehabil Sci, Sargent Coll, 635 Commonwealth Ave, Boston, MA 02215 USA.
EM tkp@bu.edu
FU NIDCD of the National Institutes of HealthUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R03DC014045]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R03DC014045] Funding Source: NIH
   RePORTER
FX We thank Sara Dougherty, Kristina Furbeck, Jessica Tin, Emily Thurston,
   Lauren Gustainis, Jennifer Golditch, Michelle Lee, JonathanMirsky,
   Andrea Chang, Cassandra Chan, Ja Young Choi, Sudha Arunachalam, and
   Charles Chang for their assistance. We especially thank Rachel Theodore
   for thoughtful comments on this manuscript. Research reported in this
   article was supported by the NIDCD of the National Institutes of Health
   under award number R03DC014045 (to TP). The content is solely the
   responsibility of the authors and does not necessarily represent the
   official views of the National Institutes of Health.
CR [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   Antoniou M, 2015, J ACOUST SOC AM, V138, P571, DOI 10.1121/1.4923362
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Bregman MR, 2014, COGNITION, V130, P85, DOI 10.1016/j.cognition.2013.09.010
   BRICKER PD, 1966, J ACOUST SOC AM, V40, P1441, DOI 10.1121/1.1910246
   Bunge SA, 2000, P NATL ACAD SCI USA, V97, P3573, DOI 10.1073/pnas.050583797
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   Doty ND, 1998, AM J PSYCHOL, V111, P191, DOI 10.2307/1423486
   Fecher N, 2018, J ACOUST SOC AM, V143, P2409, DOI 10.1121/1.5032199
   Fecher N, 2018, J EXP PSYCHOL LEARN, V44, P1911, DOI 10.1037/xlm0000555
   Fleming D, 2014, P NATL ACAD SCI USA, V111, P13795, DOI 10.1073/pnas.1401383111
   Fu QJ, 2011, J ACOUST SOC AM, V129, pEL267, DOI 10.1121/1.3590739
   Furbeck K. T., 2018, 175 M AC SOC AM MINN
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Getz LM, 2019, PSYCHOL SCI, V30, P830, DOI 10.1177/0956797619841813
   Gibson E, 1998, COGNITION, V68, P1, DOI 10.1016/S0010-0277(98)00034-1
   GOGGIN JP, 1991, MEM COGNITION, V19, P448, DOI 10.3758/BF03199567
   GOLDSTEIN AG, 1981, B PSYCHONOMIC SOC, V17, P217
   Heald SLM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00035
   Holdgraf CR, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13654
   Johnson EK, 2018, COGNITIVE SCI, V42, P633, DOI 10.1111/cogs.12520
   Johnson EK, 2011, DEVELOPMENTAL SCI, V14, P1002, DOI 10.1111/j.1467-7687.2011.01052.x
   Kadam MA, 2016, J ACOUST SOC AM, V139, pEL6, DOI 10.1121/1.4937488
   Kerstholt JH, 2006, APPL COGNITIVE PSYCH, V20, P187, DOI 10.1002/acp.1175
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Koster O, 1997, FORENSIC LINGUIST, V4, P18, DOI DOI 10.1558/IJSLL.V4I1.18
   Kuhl PK, 2011, SCIENCE, V333, P529, DOI 10.1126/science.1210277
   Latinus M, 2013, CURR BIOL, V23, P1075, DOI 10.1016/j.cub.2013.04.055
   Latinus M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00175
   Liberman M, 2007, AUTOUR MONDEGREENS B
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   McLaughlin D. E., 2015, 18 INT C PHON SCI GL
   Meltzner GS, 2005, J SPEECH LANG HEAR R, V48, P766, DOI 10.1044/1092-4388(2005/053)
   MULLENNIX JW, 1990, PERCEPT PSYCHOPHYS, V47, P379, DOI 10.3758/BF03210878
   Narayan CR, 2017, COGNITIVE SCI, V41, P1361, DOI 10.1111/cogs.12396
   Orena AJ, 2015, COGNITION, V143, P36, DOI 10.1016/j.cognition.2015.06.002
   Perrachione T. K., 2015, 18 INT C PHON SCI
   Perrachione T. K, 2018, OXFORD HDB VOICE PER
   Perrachione TK, 2007, NEUROPSYCHOLOGIA, V45, P1899, DOI 10.1016/j.neuropsychologia.2006.11.015
   Perrachione TK, 2014, J SPEECH LANG HEAR R, V57, P1651, DOI 10.1044/2014_JSLHR-S-13-0161
   Perrachione TK, 2011, SCIENCE, V333, P595, DOI 10.1126/science.1207327
   Perrachione TK, 2010, COGNITION, V114, P42, DOI 10.1016/j.cognition.2009.08.012
   Perrachione TK, 2009, J EXP PSYCHOL HUMAN, V35, P1950, DOI 10.1037/a0015869
   POLLACK I, 1954, J ACOUST SOC AM, V26, P403, DOI 10.1121/1.1907349
   Porretta V, 2016, J PHONETICS, V58, P1, DOI 10.1016/j.wocn.2016.05.006
   Porretta V, 2015, ATTEN PERCEPT PSYCHO, V77, P2438, DOI 10.3758/s13414-015-0916-3
   Samuel AG, 2001, PSYCHOL SCI, V12, P348, DOI 10.1111/1467-9280.00364
   Samuel AG, 1997, COGNITIVE PSYCHOL, V32, P97, DOI 10.1006/cogp.1997.0646
   Samuel AG, 2015, PSYCHON B REV, V22, P1746, DOI 10.3758/s13423-015-0847-y
   Sohoglu E, 2016, P NATL ACAD SCI USA, V113, pE1747, DOI 10.1073/pnas.1523266113
   Stevenage SV, 2012, J COGN PSYCHOL, V24, P647, DOI 10.1080/20445911.2012.675321
   THOMPSON CP, 1987, APPL COGNITIVE PSYCH, V1, P121, DOI 10.1002/acp.2350010205
   Thurstone LL, 1927, PSYCHOL REV, V34, P273, DOI 10.1037/h0070288
   Tsao FM, 2006, J ACOUST SOC AM, V120, P2285, DOI 10.1121/1.2338290
   Wester M, 2012, SPEECH COMMUN, V54, P781, DOI 10.1016/j.specom.2012.01.006
   Winters SJ, 2008, J ACOUST SOC AM, V123, P4524, DOI 10.1121/1.2913046
   Xie X., 2015, P 37 ANN M COGN SCI
   Xie X, 2015, J ACOUST SOC AM, V137, P419, DOI 10.1121/1.4904699
   Zarate JM, 2015, SCI REP-UK, V5, DOI 10.1038/srep11475
NR 59
TC 1
Z9 1
U1 2
U2 8
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 1088
EP 1107
DI 10.3758/s13414-019-01778-5
PG 20
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6NQ
UT WOS:000485098800016
PM 31218598
OA Bronze, Green Accepted
DA 2021-02-24
ER

PT J
AU Rysling, A
   Jesse, A
   Kingston, J
AF Rysling, Amanda
   Jesse, Alexandra
   Kingston, John
TI Regressive spectral assimilation bias in speech perception
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Psycholinguistics; Grouping and segmentation
ID HIERARCHICAL CATEGORIZATION; NONLINGUISTIC SOUNDS; FORMANT TRANSITIONS;
   PRECEDING LIQUID; CONTRAST; COMPENSATION; CONTEXT; NONSPEECH;
   COARTICULATION; IDENTIFICATION
AB Speech perception presents a parsing problem: construing information from the acoustic input we receive as evidence for the speech sounds we recognize as language. Most work on segmental perception has focused on how listeners use differences between successive speech sounds to solve this problem. Prominent models either assume (a) that listeners attribute acoustics to the sounds whose articulation created them, or (b) that the auditory system exaggerates the changes in the auditory quality of the incoming speech signal. Both approaches predict contrast effects in that listeners will usually judge two successive phones to be distinct from each other. Few studies have examined cases in which listeners hear two sounds in a row as similar, apparently failing to differentiate them. We examine such under-studied cases. In a series of experiments, listeners were faced with ambiguity about the identity of the first of two successive phones. Listeners consistently heard the first sound as spectrally similar to the second sound in a manner suggesting that they construed the transitions between the two as evidence about the identity of the first. In these and previously reported studies, they seemed to default to this construal when the signal was not sufficiently informative for them to do otherwise. These effects go unaccounted for in the two prominent models of speech perception, but they parallel known domain-general effects in perceptual processing, and as such are likely a consequence of the structure of the human auditory system.
C1 [Rysling, Amanda] Univ Calif Santa Cruz, Dept Linguist, Santa Cruz, CA 95064 USA.
   [Jesse, Alexandra] Univ Massachusetts, Dept Psychol & Brain Sci, Amherst, MA 01003 USA.
   [Kingston, John] Univ Massachusetts, Dept Linguist, Amherst, MA 01003 USA.
RP Rysling, A (corresponding author), Univ Calif Santa Cruz, Dept Linguist, Santa Cruz, CA 95064 USA.
EM rysling@ucsc.edu
CR Aravamudhan R, 2008, J ACOUST SOC AM, V124, P1695, DOI 10.1121/1.2956482
   Boersma P, PRAAT DOING PHONETIC
   Bybee J., PROMINENCE PAL UNPUB
   CHEN MY, 1975, LANGUAGE, V51, P255, DOI 10.2307/412854
   Cutler A, 2012, NATIVE LISTENING
   Diehl R. L., 1989, ECOL PSYCHOL, V1, P121, DOI [10.1207/s15326969-co0102_2, DOI 10.1207/S15326969-CO0102_2, DOI 10.1207/s15326969eco0102_2]
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   DIEHL RL, 1989, J ACOUST SOC AM, V85, P2154, DOI 10.1121/1.397864
   Fowler C. A., 1986, STATUS REPORT SPEECH, P139
   Fowler CA, 2000, J EXP PSYCHOL HUMAN, V26, P877, DOI 10.1037/0096-1523.26.3.877
   Fowler CA, 2006, PERCEPT PSYCHOPHYS, V68, P161, DOI 10.3758/BF03193666
   FUJIMURA O, 1978, LANG SPEECH, V21, P337, DOI 10.1177/002383097802100408
   HELSON H, 1963, J OPT SOC AM, V53, P179, DOI 10.1364/JOSA.53.000179
   Holt L. L., 1999, THESIS
   Holt LL, 2006, J ACOUST SOC AM, V119, P4016, DOI 10.1121/1.2195119
   Holt LL, 2005, PSYCHOL SCI, V16, P305, DOI 10.1111/j.0956-7976.2005.01532.x
   Holt LL, 2000, J ACOUST SOC AM, V108, P710, DOI 10.1121/1.429604
   Holt LL, 2006, J ACOUST SOC AM, V120, P2801, DOI 10.1121/1.2354071
   HURA SL, 1992, LANG SPEECH, V35, P59, DOI 10.1177/002383099203500206
   Javkin Hector, 1977, THESIS
   Jun J, 1995, PERCEPTUAL ARTICULAT
   Jun J., 2004, PHONETICALLY BASED P, P58, DOI [DOI 10.1017/CBO9780511486401.003, 10.1017/CBO9780511486401.003]
   Kiefte M, 2008, J ACOUST SOC AM, V123, P366, DOI 10.1121/1.2804951
   Kingston J., 2003, P 15 INT C PHON SCI, P399
   KLATT DH, 1990, J ACOUST SOC AM, V87, P820, DOI 10.1121/1.398894
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Liberman AM, 1985, SCIENCE, V243, P489
   Lotto A. J., 2015, NEUROBIOLOGY LANGUAG, P185
   Lotto AJ, 1998, PERCEPT PSYCHOPHYS, V60, P602, DOI 10.3758/BF03206049
   Lotto AJ, 2006, PERCEPT PSYCHOPHYS, V68, P178, DOI 10.3758/BF03193667
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P407, DOI 10.3758/BF03204884
   Marr D., 1982, VISION COMPUTATIONAL
   Mitterer H, 2006, PERCEPT PSYCHOPHYS, V68, P1227, DOI 10.3758/BF03193723
   Myers T., 1981, COGNITIVE REPRESENTA, P111
   NITTROUER S, 1989, J ACOUST SOC AM, V86, P1266, DOI 10.1121/1.398741
   OHALA JJ, 1993, SPEECH COMMUN, V13, P155, DOI 10.1016/0167-6393(93)90067-U
   REPP BH, 1983, PERCEPT PSYCHOPHYS, V33, P147, DOI 10.3758/BF03202832
   Sjerps MJ, 2013, ATTEN PERCEPT PSYCHO, V75, P576, DOI 10.3758/s13414-012-0408-7
   Sjerps MJ, 2012, BRAIN LANG, V120, P401, DOI 10.1016/j.bandl.2011.12.012
   Sjerps MJ, 2011, ATTEN PERCEPT PSYCHO, V73, P1195, DOI 10.3758/s13414-011-0096-8
   Smits R, 2001, PERCEPT PSYCHOPHYS, V63, P1109, DOI 10.3758/BF03194529
   Smits R, 2001, J EXP PSYCHOL HUMAN, V27, P1145, DOI 10.1037/0096-1523.27.5.1145
   Stilp CE, 2018, ATTEN PERCEPT PSYCHO, V1, P1
   Stilp CE, 2015, J ACOUST SOC AM, V137, P3466, DOI 10.1121/1.4921600
   Stilp CE, 2014, J ACOUST SOC AM, V136, pEL383, DOI 10.1121/1.4898741
   Viswanathan N, 2009, PSYCHON B REV, V16, P74, DOI 10.3758/PBR.16.1.74
   Wade T, 2005, J ACOUST SOC AM, V118, P1701, DOI 10.1121/1.1984839
   Wagner A, 2006, J ACOUST SOC AM, V120, P2267, DOI 10.1121/1.2335422
   WATKINS AJ, 1991, J ACOUST SOC AM, V90, P2942, DOI 10.1121/1.401769
   WATKINS AJ, 1994, J ACOUST SOC AM, V96, P1263, DOI 10.1121/1.410275
   Watkins AJ, 1996, J ACOUST SOC AM, V99, P3749, DOI 10.1121/1.414981
   WHALEN DH, 1981, J ACOUST SOC AM, V69, P275, DOI 10.1121/1.385348
   Winn MB, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00824
NR 54
TC 3
Z9 2
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 1127
EP 1146
DI 10.3758/s13414-019-01720-9
PG 20
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6NQ
UT WOS:000485098800019
PM 31114954
OA Bronze
DA 2021-02-24
ER

PT J
AU Schreiber, KE
   McMurray, B
AF Schreiber, Kayleen E.
   McMurray, Bob
TI Listeners can anticipate future segments before they identify the
   current one
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Spoken word recognition; Coarticulation;
   Anticipation; Cue integrationm Auditory memory
ID TO-VOWEL COARTICULATION; EYE-MOVEMENT EVIDENCE; SPEAKING-RATE;
   PERCEPTUAL CENTER; CUE-INTEGRATION; TEMPORAL CUES; TIME-COURSE; SPEECH;
   INFORMATION; IDENTIFICATION
AB Speech unfolds rapidly over time, and the information necessary to recognize even a single phoneme may not be available simultaneously. Consequently, listeners must both integrate prior acoustic cues and anticipate future segments. Prior work on stop consonants and vowels suggests that listeners integrate asynchronous cues by partially activating lexical entries as soon as any information is available, and then updating this when later cues arrive. However, a recent study suggests that for the voiceless sibilant fricatives (/s/ and /?/), listeners wait to initiate lexical access until all cues have arrived at the onset of the vowel. Sibilants also contain coarticulatory cues that could be used to anticipate the vowel upcoming. However, given these results, it is unclear if listeners could use them fast enough to speed vowel recognition. The current study examines anticipation by asking when listeners use coarticulatory information in the frication to predict the upcoming vowel. A visual world paradigm experiment found that listeners do not wait: they anticipate the vowel immediately from the onset of the frication, even as they wait several hundred milliseconds to identify the fricative. This finding suggests listeners do not strictly process phonemes in the order that they appear; rather the dynamics of language processing may be largely internal and only loosely coupled to the dynamics of the input.
C1 [Schreiber, Kayleen E.] Univ Iowa, Interdisciplinary Grad Program Neurosci, Iowa City, IA USA.
   [McMurray, Bob] Univ Iowa, Dept Psychol & Brain Sci, Dept Commun Sci & Disorders, Dept Linguist, W311 SSH, Iowa City, IA 52242 USA.
RP McMurray, B (corresponding author), Univ Iowa, Dept Psychol & Brain Sci, Dept Commun Sci & Disorders, Dept Linguist, W311 SSH, Iowa City, IA 52242 USA.
EM bob-mcmurray@uiowa.edu
FU [DC 0008089]; NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND
   STROKEUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute of Neurological
   Disorders & Stroke (NINDS) [T32NS007421, T32NS007421, T32NS007421,
   T32NS007421, T32NS007421] Funding Source: NIH RePORTER; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01DC008089, R01DC008089, R01DC008089, R01DC008089] Funding
   Source: NIH RePORTER
FX The authors would like to thank Jamie KleinPackard and the members of
   the MACLab for assistance with data collection; Marcus Galle for
   critical ideas leading to this work; Mathias Sjerps for suggesting the
   P-Center hypothesis; and Kilgore Trout for assistance with the title of
   this project. We would also like to thank Randy Diehl whose lifetime of
   scholarship demonstrated a commitment to questioning assumptions,
   thinking deeply about the role of basic auditory processing in speech,
   and exploring odd phenomena to lasting theoretical gain. This research
   was supported by DC 0008089 awarded to BM.
CR Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   [Anonymous], AUD FREE AUD ED REC
   Apfelbaum KS, 2014, LANG COGN NEUROSCI, V29, P1070, DOI 10.1080/01690965.2013.824995
   Apfelbaum KS, 2011, PSYCHON B REV, V18, P141, DOI 10.3758/s13423-010-0039-8
   Beddor PS, 2002, J PHONETICS, V30, P591, DOI 10.1006/jpho.2002.0177
   Benjamini Y., 1985, J ROYAL STAT SOC B, V57, P289
   Boersma P., 2009, PRAAT DOING PHONETIC
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Cole J, 2010, J PHONETICS, V38, P167, DOI 10.1016/j.wocn.2009.08.004
   Dahan D., 2006, HDB PSYCHOLINGUISTIC, P249, DOI DOI 10.1016/B978-012369374-7/50009-2
   DANILOFF R, 1968, J SPEECH HEAR RES, V11, P707, DOI 10.1044/jshr.1104.707
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   DIEHL RL, 1989, J ACOUST SOC AM, V85, P2154, DOI 10.1121/1.397864
   DIEHL RL, 1987, J MEM LANG, V26, P564, DOI 10.1016/0749-596X(87)90143-4
   Elman Jeffrey L, 2009, Cogn Sci, V33, P547
   Fernald A, 2006, DEV PSYCHOL, V42, P98, DOI 10.1037/0012-1649.42.1.98
   FORREST K, 1988, J ACOUST SOC AM, V84, P115, DOI 10.1121/1.396977
   Frazier L, 1987, SENTENCE PROCESSING
   Galle ME, 2019, COGNITIVE SCI, V43, DOI 10.1111/cogs.12700
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   Gow D. W., 2007, LAB PHONOLOGY, V9, P173
   Gow DW, 2003, PERCEPT PSYCHOPHYS, V65, P575, DOI 10.3758/BF03194584
   Gow DW, 2001, J MEM LANG, V45, P133, DOI 10.1006/jmla.2000.2764
   Hannagan T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00563
   Hawkins S, 2003, J PHONETICS, V31, P373, DOI 10.1016/j.wocn.2003.09.006
   HOEQUIST CE, 1983, LANG SPEECH, V26, P367, DOI 10.1177/002383098302600404
   Holt LL, 2008, CURR DIR PSYCHOL SCI, V17, P42, DOI 10.1111/j.1467-8721.2008.00545.x
   JENKINS JJ, 1983, PERCEPT PSYCHOPHYS, V34, P441, DOI 10.3758/BF03203059
   JENKINS JJ, 1994, J ACOUST SOC AM, V95, P1030, DOI 10.1121/1.410014
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   Kingston J, 2016, J EXP PSYCHOL HUMAN, V42, P1969, DOI 10.1037/xhp0000269
   Law F, 2017, APPL PSYCHOLINGUIST, V38, P89, DOI 10.1017/S0142716416000126
   Levy R, 2009, P NATL ACAD SCI USA, V106, P21086, DOI 10.1073/pnas.0907664106
   Luck SJ, 1997, NATURE, V390, P279, DOI 10.1038/36846
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676
   Magen HS, 1997, J PHONETICS, V25, P187, DOI 10.1006/jpho.1996.0041
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P213, DOI 10.3758/BF03204377
   MARCUS SM, 1981, PERCEPT PSYCHOPHYS, V30, P247, DOI 10.3758/BF03214280
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2015, PSYCHOL SCI, V27, P43
   McMurray B, 2017, COGNITION, V169, P147, DOI 10.1016/j.cognition.2017.08.013
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   McMurray B, 2010, COGNITIVE PSYCHOL, V60, P1, DOI 10.1016/j.cogpsych.2009.06.003
   McMurray B, 2009, J MEM LANG, V60, P65, DOI 10.1016/j.jml.2008.07.002
   McMurray B, 2008, PSYCHON B REV, V15, P1064, DOI 10.3758/PBR.15.6.1064
   Miller J, 1998, PSYCHOPHYSIOLOGY, V35, P99, DOI 10.1111/1469-8986.3510099
   MILLER JL, 1988, J EXP PSYCHOL HUMAN, V14, P369, DOI 10.1037/0096-1523.14.3.369
   MILLER JL, 1989, PERCEPT PSYCHOPHYS, V46, P505, DOI 10.3758/BF03208147
   MILLER RG, 1974, BIOMETRIKA, V61, P1
   Mitterer H, 2013, J MEM LANG, V69, P527, DOI 10.1016/j.jml.2013.07.002
   Nearey T. M., 1994, J INT PHON ASSOC, V24, P1, DOI [10.1017/S0025100300004965, DOI 10.1017/S0025100300004965]
   NITTROUER S, 1989, J ACOUST SOC AM, V86, P1266, DOI 10.1121/1.398741
   Oganian Y., 2018, SPEECH ENVELOPE LAND, DOI [10.1101/388280, DOI 10.1101/388280]
   OHDE RN, 1984, J ACOUST SOC AM, V75, P224, DOI 10.1121/1.390399
   OHMAN SEG, 1966, J ACOUST SOC AM, V39, P151, DOI 10.1121/1.1909864
   Oleson JJ, 2017, STAT METHODS MED RES, V26, P2708, DOI 10.1177/0962280215607411
   PARKER EM, 1984, PERCEPT PSYCHOPHYS, V36, P369, DOI 10.3758/BF03202791
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   Rigler H, 2015, DEV PSYCHOL, V51, P1690, DOI 10.1037/dev0000044
   Salverda AP, 2014, J MEM LANG, V71, P145, DOI 10.1016/j.jml.2013.11.002
   Salverda AP, 2011, ACTA PSYCHOL, V137, P172, DOI 10.1016/j.actpsy.2010.09.010
   Seedorff M, 2018, J MEM LANG, V102, P55, DOI 10.1016/j.jml.2018.05.004
   SERENO JA, 1987, J ACOUST SOC AM, V81, P512, DOI 10.1121/1.394917
   Smits R, 2003, J ACOUST SOC AM, V113, P563, DOI 10.1121/1.1525287
   Smits R, 2001, PERCEPT PSYCHOPHYS, V63, P1109, DOI 10.3758/BF03194529
   Strand EA, 1999, J LANG SOC PSYCHOL, V18, P86, DOI 10.1177/0261927X99018001006
   STRANGE W, 1983, J ACOUST SOC AM, V74, P695, DOI 10.1121/1.389855
   SUMMERFIELD Q, 1977, J ACOUST SOC AM, V62, P435, DOI 10.1121/1.381544
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Toscano JC, 2015, LANG COGN NEUROSCI, V30, P529, DOI 10.1080/23273798.2014.946427
   Toscano JC, 2013, PSYCHON B REV, V20, P981, DOI 10.3758/s13423-013-0417-0
   Toscano JC, 2012, ATTEN PERCEPT PSYCHO, V74, P1284, DOI 10.3758/s13414-012-0306-z
   Viviani P, 1990, Rev Oculomot Res, V4, P353
   Vonnegut K., 1969, SLAUGHTERHOUSE 5 CHI
   Wagner A, 2006, J ACOUST SOC AM, V120, P2267, DOI 10.1121/1.2335422
   Warner N, 2014, J ACOUST SOC AM, V135, P2995, DOI 10.1121/1.4870486
   WARREN P, 1987, PERCEPT PSYCHOPHYS, V41, P262, DOI 10.3758/BF03208224
   Weber A, 2012, WIRES COGN SCI, V3, P387, DOI 10.1002/wcs.1178
   YENIKOMSHIAN GH, 1981, J ACOUST SOC AM, V70, P966, DOI 10.1121/1.387031
NR 83
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 1147
EP 1166
DI 10.3758/s13414-019-01712-9
PG 20
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6NQ
UT WOS:000485098800020
PM 31087271
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Vaughn, CR
AF Vaughn, Charlotte R.
TI Expectations about the source of a speaker's accent affect accent
   adaptation
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH-PERCEPTION; FOREIGN ACCENT; LISTENER EXPECTATIONS; NONNATIVE
   SPEAKERS; STEREOTYPE THREAT; INFORMATION; FLUENCY; COMPREHENSION;
   PREDICTORS; ATTITUDES
AB When encountering speakers whose accents differ from the listener's own, listeners initially show a processing cost, but that cost can be attenuated after short term exposure. The extent to which processing foreign accents (L2-accents) and within-language accents (L1-accents) is similar is still an open question. This study considers whether listeners' expectations about the source of a speaker's accent-whether the speaker is purported to be an L1 or an L2 speaker-affect intelligibility. Prior work has indirectly manipulated expectations about a speaker's accent through photographs, but the present study primes listeners with a description of the speaker's accent itself. In experiment 1, native English listeners transcribed Spanish-accented English sentences in noise under three different conditions (speaker's accent: monolingual L1 Latinx English, L1-Spanish/ L2-English, no information given). Results indicate that, by the end of the experiment, listeners given some information about the accent outperformed listeners given no information, and listeners told the speaker was L1-accented outperformed listeners told to expect L2-accented speech. Findings are interpreted in terms of listeners' expectations about task difficulty, and a follow-up experiment (experiment 2) found that priming listeners to expect that their ability to understand L2-accented speech can improve does in fact improve intelligibility. (C) 2019 Acoustical Society of America.
C1 [Vaughn, Charlotte R.] Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.
RP Vaughn, CR (corresponding author), Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.
EM cvaughn@uoregon.edu
CR Adank P, 2007, P 16 INT C PHON SCI, P1925
   Adank P, 2009, J EXP PSYCHOL HUMAN, V35, P520, DOI 10.1037/a0013552
   Aronson J, 2002, J EXP SOC PSYCHOL, V38, P113, DOI 10.1006/jesp.2001.1491
   Atagi E, 2015, J ACOUST SOC AM, V137, pEL44, DOI 10.1121/1.4903916
   Babel M, 2015, J ACOUST SOC AM, V137, P2823, DOI 10.1121/1.4919317
   Banks B, 2015, J ACOUST SOC AM, V137, P2015, DOI 10.1121/1.4916265
   Bent T, 2016, J ACOUST SOC AM, V140, P3775, DOI 10.1121/1.4966677
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Brungart DS, 2001, J ACOUST SOC AM, V110, P2527, DOI 10.1121/1.1408946
   Burchill Z, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199358
   Campbell-Kibler K., 2015, RESPONSES LANGUAGE V, P175
   Campbell-Kibler K, 2007, AM SPEECH, V82, P32, DOI 10.1215/00031283-2007-002
   Carmichael K., 2016, AWARENESS CONTROL SO, P152
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   CRAIK FIM, 1975, J EXP PSYCHOL GEN, V104, P268, DOI 10.1037/0096-3445.104.3.268
   D'Onofrio A, 2015, J SOCIOLING, V19, P241, DOI 10.1111/josl.12115
   Derwing T.M., 1997, STUDIES 2 LANGUAGE A, V19, P1, DOI [10.1017/s0272263197001010, DOI 10.1017/S0272263197001010]
   Dragojevic M, 2017, COMMUN MONOGR, V84, P385, DOI 10.1080/03637751.2017.1322213
   Dunning D, 2013, CURR DIR PSYCHOL SCI, V22, P33, DOI 10.1177/0963721412463693
   Dweck C. S, 1999, SELF THEORIES THEIR
   Eckert P, 2008, INT J BILINGUAL, V12, P25, DOI 10.1177/13670069080120010301
   Fiske S. T., 1998, HDB SOCIAL PSYCHOL, V2, P357, DOI DOI 10.1002/9780470561119
   Floccia C, 2006, J EXP PSYCHOL HUMAN, V32, P1276, DOI 10.1037/0096-1523.32.5.1276
   Floccia C, 2009, J PSYCHOLINGUIST RES, V38, P379, DOI 10.1007/s10936-008-9097-8
   Fought C, 2006, KEY T SOCIOLINGUIST, P1, DOI 10.1017/CBO9780511791215
   Fought Carmen, 2003, CHICANO ENGLISH CONT
   Freeman JB, 2011, PSYCHOL REV, V118, P247, DOI 10.1037/a0022327
   Gnevsheva K, 2018, LINGUISTICS, V56, P581, DOI 10.1515/ling-2018-0006
   GODINEZ M, 1985, INT J SOCIOL LANG, P43
   Goslin J, 2012, BRAIN LANG, V122, P92, DOI 10.1016/j.bandl.2012.04.017
   Grey S, 2017, J NEUROLINGUIST, V42, P93, DOI 10.1016/j.jneuroling.2016.12.001
   Hanulikova A, 2012, J COGNITIVE NEUROSCI, V24, P878, DOI 10.1162/jocn_a_00103
   Hu GL, 2015, LANG AWARE, V24, P273, DOI 10.1080/09658416.2015.1077853
   Ingvalson EM, 2017, J ACOUST SOC AM, V141, P4652, DOI 10.1121/1.4986930
   Ingvalson EM, 2017, J ACOUST SOC AM, V141, pEL234, DOI 10.1121/1.4977583
   Jamieson JP, 2011, PERS SOC PSYCHOL B, V37, P652, DOI 10.1177/0146167211399776
   Johns M, 2005, PSYCHOL SCI, V16, P175, DOI 10.1111/j.0956-7976.2005.00799.x
   Kamachi M, 2003, CURR BIOL, V13, P1709, DOI 10.1016/j.cub.2003.09.005
   Kang O, 2009, J LANG SOC PSYCHOL, V28, P441, DOI 10.1177/0261927X09341950
   Kitterick PT, 2010, J ACOUST SOC AM, V127, P2498, DOI 10.1121/1.3327507
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Koelewijn T, 2015, HEARING RES, V323, P81, DOI 10.1016/j.heares.2015.02.004
   Konopka K., 2008, S LANG SOC AUST SALS
   LAMBERT WE, 1960, J ABNORM SOC PSYCH, V60, P44, DOI 10.1037/h0044430
   Laturnus R., 2018, THESIS
   Lev-Ari S, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01546
   Lick DJ, 2015, CURR DIR PSYCHOL SCI, V24, P143, DOI 10.1177/0963721414558116
   Lindemann S, 2002, LANG SOC, V31, P419, DOI 10.1017/S0047404502020286
   Lippi-Green R., 1997, ENGLISH ACCENT LANGU, V2nd ed.
   Liss JM, 2009, J SPEECH LANG HEAR R, V52, P1334, DOI 10.1044/1092-4388(2009/08-0208)
   Liu LD, 2018, COGNITION, V174, P55, DOI 10.1016/j.cognition.2018.01.003
   Lou NM, 2016, CONTEMP EDUC PSYCHOL, V46, P22, DOI 10.1016/j.cedpsych.2016.03.004
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   McGowan KB, 2015, LANG SPEECH, V58, P502, DOI 10.1177/0023830914565191
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   Mendoza-Denton Norma, 2008, HOMEGIRLLANGUAGE C
   Miele DB, 2010, J EXP PSYCHOL GEN, V139, P535, DOI 10.1037/a0019745
   Morales A., 2014, THESIS
   Moser JS, 2011, PSYCHOL SCI, V22, P1484, DOI 10.1177/0956797611419520
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Oppenheimer DM, 2008, TRENDS COGN SCI, V12, P237, DOI 10.1016/j.tics.2008.02.014
   Ornstein-Galicia J., 1984, FORM FUNCTION CHICAN
   Pantos AJ, 2013, J LANG SOC PSYCHOL, V32, P3, DOI 10.1177/0261927X12463005
   Pennington CR, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146487
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   RUBIN DL, 1992, RES HIGH EDUC, V33, P511, DOI 10.1007/BF00973770
   Santa Ana O., 2004, HDB VARIETIES ENGLIS, V1, P417
   Santa Ana O., 1993, HISPANIC J BEHAV SCI, V15, P1
   Schmader T, 2004, SEX ROLES, V50, P835, DOI 10.1023/B:SERS.0000029101.74557.a0
   Seidl A, 2012, FRONT PSYCHOL, V3, DOI [10.3389/fpsyg.2012.00448, 10.3389/fpsyg.2012.00479]
   Smith R, 2014, Q J EXP PSYCHOL, V67, P590, DOI 10.1080/17470218.2013.822009
   Sohoglu E, 2016, P NATL ACAD SCI USA, V113, pE1747, DOI 10.1073/pnas.1523266113
   Staum Casasanto L., 2008, P ANN M COGN SCI SOC, V30
   Strand EA, 1999, J LANG SOC PSYCHOL, V18, P86, DOI 10.1177/0261927X99018001006
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   SUMNER M, 2013, P ANN M 35 ANN C COG, P3486
   Sumner M, 2013, J ACOUST SOC AM, V134, pEL26, DOI 10.1121/1.4807432
   Tseng Amelia, 2015, THESIS
   Van Engen KJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00577
   Vaughn C., 2018, PHONETICA
   Walker A, 2016, PENN WORKING PAPERS, V22, P20
   Warton DI, 2011, ECOLOGY, V92, P3, DOI 10.1890/10-0340.1
   Xie X, 2018, J ACOUST SOC AM, V143, P2013, DOI 10.1121/1.5027410
   Yi HG, 2013, J ACOUST SOC AM, V134, pEL387, DOI 10.1121/1.4822320
   Zheng Y, 2017, ATTEN PERCEPT PSYCHO, V79, P1841, DOI 10.3758/s13414-017-1329-2
NR 87
TC 2
Z9 2
U1 0
U2 4
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD MAY
PY 2019
VL 145
IS 5
BP 3218
EP 3232
DI 10.1121/1.5108831
PG 15
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA IV0MP
UT WOS:000483973600055
PM 31153344
DA 2021-02-24
ER

PT J
AU Heeringa, AN
   van Dijk, P
AF Heeringa, Amarins N.
   van Dijk, Pim
TI Neural coding of the sound envelope is changed in the inferior
   colliculus immediately following acoustic trauma
SO EUROPEAN JOURNAL OF NEUROSCIENCE
LA English
DT Article
DE amplitude modulation; guinea pig; noise-induced hearing loss; rate
   coding; temporal coding
ID AMPLITUDE-MODULATED TONES; SPEECH-PERCEPTION; AUDITORY-CORTEX; RESPONSE
   PROPERTIES; NEURONAL RESPONSES; COCHLEAR DAMAGE; FINE-STRUCTURE; INTENSE
   SOUND; HEARING; NOISE
AB Sensorineural hearing loss is often accompanied by difficulties with understanding speech in fluctuating backgrounds, suggesting that neural coding of complex sound features, such as the sound envelope, is impaired. Here, we studied how temporal and rate coding of the envelope is affected in the inferior colliculus immediately after acoustic trauma. Neural activity in response to amplitude-modulated noise was -recorded from the inferior colliculus of the guinea pig, before and immediately after a 1-hr 11-kHz acoustic trauma. Units with a characteristic frequency (CF) below the trauma frequency (< 11 kHz) showed increased response gains, a measure for temporal coding of the sound envelope, especially at low modulation frequencies (= 128 Hz). Units with a CF > 11 kHz, which had large acoustic trauma-induced threshold shifts, had decreased response gains to amplitude-modulated noise. Shapes of temporal modulation transfer functions shifted toward a higher proportion of low-pass shapes in low-CF units, and to less band-pass shapes in high-CF units. Furthermore, driven firing rates decreased, especially at high modulation frequencies for high-CF units. The observed changes occurred immediately following trauma and were thus a result of the immediate trauma-induced damage to the auditory system. If also present in human subjects, reduced response gains in high-frequency units could disrupt coding of consonants and consequently impair speech understanding in noisy environments. Moreover, the enhanced temporal coding by low-CF units of the low modulation frequencies could overly amplify responses to low-frequency noise, further deteriorating listening in noise.
C1 [Heeringa, Amarins N.; van Dijk, Pim] Univ Groningen, Univ Med Ctr Groningen, Dept Otorhinolaryngol Head & Neck Surg, Groningen, Netherlands.
   [Heeringa, Amarins N.; van Dijk, Pim] Univ Groningen, Grad Sch Med Sci, Res Sch Behav & Cognit Neurosci, Groningen, Netherlands.
RP Heeringa, AN (corresponding author), Carl von Ossietzky Univ Oldenburg, Cochlea & Auditory Brainstem Physiol, Sch Med & Hlth Sci, Cluster Excellence Hearing4All, Carl von Ossietzky Str 9-11, D-26129 Oldenburg, Germany.
EM amarins.nieske.heeringa@uni-oldenburg.de
RI Van Dijk, Pim/E-8019-2010
OI Van Dijk, Pim/0000-0002-8023-7571; Heeringa, Amarins/0000-0002-8391-0581
FU Heinsius Houbolt Foundation; Stichting Gehoorgestoorde Kind
FX This work was supported by the Heinsius Houbolt Foundation and the
   Stichting Gehoorgestoorde Kind. The study is part of the research
   program of our department: Healthy Aging and Communication. The authors
   want to thank Christian Lorenzi for his valuable discussions on the
   subject, Russ Snyder for showing us the surgical procedures involved in
   the inferior colliculus recordings, and Annemieke Smit-van Oosten,
   Michel Weij, and Andre Zandvoort for technical support during the
   experiments.
CR Avissar M, 2013, J NEUROSCI, V33, P7681, DOI 10.1523/JNEUROSCI.3405-12.2013
   BRONKHORST AW, 1992, J ACOUST SOC AM, V92, P3132, DOI 10.1121/1.404209
   Bures Z, 2010, EUR J NEUROSCI, V32, P155, DOI 10.1111/j.1460-9568.2010.07280.x
   Cai S, 2008, JARO-J ASSOC RES OTO, V10, P5
   Carney LH, 2018, JARO-J ASSOC RES OTO, V19, P331, DOI 10.1007/s10162-018-0669-5
   Caspary DM, 2005, J NEUROSCI, V25, P10952, DOI 10.1523/JNEUROSCI.2451-05.2005
   Dehmel S, 2012, J NEUROSCI, V32, P1660, DOI 10.1523/JNEUROSCI.4608-11.2012
   Dong SY, 2010, EUR J NEUROSCI, V31, P1616, DOI 10.1111/j.1460-9568.2010.07183.x
   Fullgrabe C, 2003, HEARING RES, V178, P35, DOI 10.1016/S0378-5955(03)00027-3
   Gai Y, 2008, J NEUROPHYSIOL, V99, P1077, DOI 10.1152/jn.00708.2007
   Grimault N, 2002, J ACOUST SOC AM, V111, P1340, DOI 10.1121/1.1452740
   Heeringa AN, 2014, HEARING RES, V312, P38, DOI 10.1016/j.heares.2014.03.004
   Heeringa AN, 2016, HEARING RES, V331, P47, DOI 10.1016/j.heares.2015.10.007
   Heinz MG, 2004, J NEUROPHYSIOL, V91, P784, DOI 10.1152/jn.00776.2003
   Henry KS, 2016, J NEUROSCI, V36, P2227, DOI 10.1523/JNEUROSCI.3944-15.2016
   Insanally MN, 2010, J NEUROPHYSIOL, V103, P2611, DOI 10.1152/jn.00872.2009
   Joris PX, 2004, PHYSIOL REV, V84, P541, DOI 10.1152/physrev.00029.2003
   Kale S, 2010, JARO-J ASSOC RES OTO, V11, P657, DOI 10.1007/s10162-010-0223-6
   Kaltenbach JA, 1998, HEARING RES, V124, P78, DOI 10.1016/S0378-5955(98)00119-1
   Krishna BS, 2000, J NEUROPHYSIOL, V84, P255
   Kuenzel T, 2015, FRONT NEURAL CIRCUIT, V9, DOI 10.3389/fncir.2015.00014
   LANGNER G, 1988, J NEUROPHYSIOL, V60, P1799
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Mardia K. V., 2000, DIRECTIONAL STAT
   McAlpine D, 2004, J NEUROPHYSIOL, V92, P1295, DOI 10.1152/jn.00034.2004
   Millman RE, 2017, J NEUROSCI, V37, P7727, DOI 10.1523/JNEUROSCI.2722-16.2017
   Moore BCJ, 2001, J ACOUST SOC AM, V110, P1067, DOI 10.1121/1.1385177
   Moore BCJ, 2008, JARO-J ASSOC RES OTO, V9, P399, DOI 10.1007/s10162-008-0143-x
   Mulders WHAM, 2011, J COMP NEUROL, V519, P2637, DOI 10.1002/cne.22644
   Nelson PC, 2007, J NEUROPHYSIOL, V97, P522, DOI 10.1152/jn.00776.2006
   Niu YG, 2013, J NEUROSCI RES, V91, P292, DOI 10.1002/jnr.23152
   Niwa M, 2012, J NEUROSCI, V32, P9323, DOI 10.1523/JNEUROSCI.5832-11.2012
   Norena AJ, 2003, J NEUROPHYSIOL, V90, P2387, DOI 10.1152/jn.00139.2003
   Overton JA, 2016, J NEUROPHYSIOL, V115, P2911, DOI 10.1152/jn.01098.2015
   Pilati N, 2012, P NATL ACAD SCI USA, V109, P8292, DOI 10.1073/pnas.1116981109
   POLLAK GD, 1993, HEARING RES, V65, P99, DOI 10.1016/0378-5955(93)90205-F
   Popelar J, 2016, HEARING RES, V332, P7, DOI 10.1016/j.heares.2015.10.021
   Qin MK, 2003, J ACOUST SOC AM, V114, P446, DOI 10.1121/1.1579009
   REES A, 1989, J ACOUST SOC AM, V85, P1978, DOI 10.1121/1.397851
   RUGGERO MA, 1991, J NEUROSCI, V11, P1057
   SALVI RJ, 1990, HEARING RES, V50, P245, DOI 10.1016/0378-5955(90)90049-U
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Sivaramakrishnan S, 2004, J NEUROSCI, V24, P5031, DOI 10.1523/JNEUROSCI.0357-04.2004
   Slama MCC, 2015, J NEUROSCI, V35, P4452, DOI 10.1523/JNEUROSCI.3615-14.2015
   Winer J., 2005, INFERIOR COLLICULUS, DOI [10.1007/bl38578, DOI 10.1007/B138578]
   Zeng CH, 2009, J NEUROSCI, V29, P4210, DOI 10.1523/JNEUROSCI.0208-09.2009
   Zhong ZW, 2014, HEARING RES, V309, P55, DOI 10.1016/j.heares.2013.11.006
NR 47
TC 2
Z9 2
U1 0
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0953-816X
EI 1460-9568
J9 EUR J NEUROSCI
JI Eur. J. Neurosci.
PD MAY
PY 2019
VL 49
IS 10
BP 1220
EP 1232
DI 10.1111/ejn.14299
PG 13
WC Neurosciences
SC Neurosciences & Neurology
GA IH3TX
UT WOS:000474416400004
PM 30549334
DA 2021-02-24
ER

PT J
AU Chang, CB
AF Chang, Charles B.
TI Language change and linguistic inquiry in a world of multicompetence:
   Sustained phonetic drift and its implications for behavioral linguistic
   research
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Ambient exposure; First language attrition; Plasticity; Crosslinguistic
   influence; Voice onset time; Fundamental frequency; Vowel formants
ID COMMON REPRESENTATIONAL SYSTEM; FOREIGN-LANGUAGE; AMERICAN ENGLISH;
   CROSS-LANGUAGE; SPEECH-PERCEPTION; L1; BILINGUALS; AGE; ACQUISITION;
   ATTRITION
AB Linguistic studies focusing on monolinguals have often examined individuals with considerable experience using another language. Results of a methodological review suggest that conflating ostensibly 'multicompetent' individuals with monolinguals is still common practice. A year-long longitudinal study of speech production demonstrates why this practice is problematic. Adult native English speakers recently arrived in Korea showed significant changes in their production of English stops and vowels (in terms of voice onset time, fundamental frequency, and formant frequencies) during Korean classes and continued to show altered English production a year later, months after their last Korean class. Consistent with an INCIDENTAL PROCESSING HYPOTHESIS (IPH) concerning the processing of ambient linguistic input, some changes persisted even in speakers who reported limited active use of Korean in their daily life. These patterns thus suggest that the linguistic experience obtained in a foreign language environment induces and then prolongs restructuring of the native language, making the multicompetent native speaker in a foreign language environment unrepresentative of a monolingual in a native language environment. Such restructuring supports the view that one's native language continues to evolve in adulthood, highlighting the need for researchers to be explicit about a population under study and to accordingly control (and describe) language background in a study sample. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Chang, Charles B.] Boston Univ, Dept Linguist, 621 Commonwealth Ave, Boston, MA 02215 USA.
RP Chang, CB (corresponding author), Boston Univ, Dept Linguist, 621 Commonwealth Ave, Boston, MA 02215 USA.
EM cc@bu.edu
RI Chang, Charles B./M-1343-2016
OI Chang, Charles B./0000-0002-3537-2053
FU National Science FoundationNational Science Foundation (NSF)
   [BCS-0922652]; Center for Korean Studies at UC Berkeley; Department of
   Linguistics at UC Berkeley
FX The author gratefully acknowledges financial support from the National
   Science Foundation (BCS-0922652) and the Center for Korean Studies and
   Department of Linguistics at UC Berkeley; research assistance from
   Daiana Chang and Kevin Sitek; and logistical assistance from the
   Fulbright Korean-American Educational Commission. The research reported
   here benefited from the feedback of many individuals, including
   Ocke-Schwen Bohn, Ann Bradlow, Chiara Celata, Taehong Cho, Lisa
   Davidson, Esther de Leeuw, Susanne Gahl, Carla Hudson Kam, Sharon
   Inkelas, Keith Johnson, John Ohala, Kathryn Pruitt, three anonymous
   reviewers, and audiences at UC Berkeley, Yonsei University, NYU, the
   CUNY Graduate Center, Rice University, the 11th International Symposium
   on Bilingualism (ISB 11), and meetings of the Linguistic Society of
   America and the Acoustical Society of America. Any errors, however, are
   those of the author.
CR Abdelli-Beruh NB, 2012, J PHONETICS, V40, P521, DOI 10.1016/j.wocn.2012.02.009
   Ahn S, 2017, LANG LEARN, V67, P694, DOI 10.1111/lang.12252
   Alam F, 2014, ENGLISH INDIAN DIASP, P29
   Alam F., 2011, P 17 INT C PHON SCI, P216
   Antoniou M, 2015, BILING-LANG COGN, V18, P683, DOI 10.1017/S1366728914000777
   Antoniou M, 2012, J PHONETICS, V40, P582, DOI 10.1016/j.wocn.2012.05.005
   Bang HY, 2018, J PHONETICS, V66, P120, DOI 10.1016/j.wocn.2017.09.005
   Bassetti B, 2011, LANGUAGE AND BILINGUAL COGNITION, P143
   Beinhoff B, 2008, ISSUES ACCENTS ENGLI, P120
   Bergmann C, 2016, J PHONETICS, V58, P71, DOI 10.1016/j.wocn.2016.07.001
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Bialystok E, 2010, CURR DIR PSYCHOL SCI, V19, P19, DOI 10.1177/0963721409358571
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Bournot-Trites M., 2002, REPORT CURRENT RES E
   Bowers JS, 2009, PSYCHOL SCI, V20, P1064, DOI 10.1111/j.1467-9280.2009.02407.x
   Brown A, 2008, GESTURE, V8, P256, DOI 10.1075/gest.8.2.08bro
   Brown A, 2012, SECOND LANG RES, V28, P415, DOI 10.1177/0267658312455822
   Brown A, 2011, BILING-LANG COGN, V14, P79, DOI 10.1017/S1366728910000064
   Caramazza A., 1974, J PHONETICS, V2, P239
   Celata C, OXFORD HDB LANGUAGE
   Chang C. B, OXFORD HDB LANGUAGE
   Chang C.C., 2010, THESIS
   Chang CB, 2013, J PHONETICS, V41, P520, DOI 10.1016/j.wocn.2013.09.006
   Chang CB, 2012, J PHONETICS, V40, P249, DOI 10.1016/j.wocn.2011.10.007
   Childers D. G., 1978, MODERN SPECTRUM ANAL
   Cho MH, 2016, LANG SCI, V56, P30, DOI 10.1016/j.langsci.2016.02.006
   Choi JY, 2017, P NATL ACAD SCI USA, V114, P7307, DOI 10.1073/pnas.1706405114
   Chomsky N., 1986, KNOWLEDGE LANGUAGE I
   Chomsky Noam, 1957, SYNTACTIC STRUCTURES
   Cook V. J., 2003, EFFECTS 2 LANGUAGE 1, P1
   Cook Vivian, 1991, SECOND LANG RES, V7, P103, DOI DOI 10.1177/026765839100700203
   Cook Vivian, 1997, TUTORIALS BILINGUALI, P279
   COOK VJ, 1992, LANG LEARN, V42, P557, DOI 10.1111/j.1467-1770.1992.tb01044.x
   Davies A., 2003, NATIVE SPEAKER MYTH
   de Bot K., 2007, LANGUAGE ATTRITION T, P53
   De Bot K., 1991, 1 LANGUAGE ATTRITION, P87
   De Leeuw E, 2018, BILING-LANG COGN, V21, P278, DOI 10.1017/S1366728917000025
   de Leeuw E, 2013, INT J BILINGUAL, V17, P683, DOI 10.1177/1367006912454620
   De Leeuw E, 2010, BILING-LANG COGN, V13, P33, DOI 10.1017/S1366728909990289
   Dmitrieva O, 2010, J PHONETICS, V38, P483, DOI 10.1016/j.wocn.2010.06.001
   Dussias PE, 2007, BILING-LANG COGN, V10, P101, DOI 10.1017/S1366728906002847
   Filiaci F., 2004, INT J BILINGUAL, V8, P257, DOI DOI 10.1177/13670069040080030601
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2007, LAB PHONOLOGY, P353
   Flege James, 1996, 2 LANGUAGE SPEECH ST, P11
   Flege James, 2002, INTEGRATED VIEW LANG, P217
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   Forster J. C, 2014, DMDX VERSION 5 1 0 0
   Fowler CA, 2008, J PHONETICS, V36, P649, DOI 10.1016/j.wocn.2008.04.001
   Fox E, 1996, J MEM LANG, V35, P353, DOI 10.1006/jmla.1996.0020
   Freedman SE, 2012, INT J BILINGUAL, V16, P369, DOI 10.1177/1367006911425815
   GENESEE F, 1989, J CHILD LANG, V16, P161, DOI 10.1017/S0305000900013490
   Gertken Libby, 2012, BILINGUAL LANGUAGE P
   GROSJEAN F, 1989, BRAIN LANG, V36, P3, DOI 10.1016/0093-934X(89)90048-5
   Grosjean F, 1985, J MULTILING MULTICUL, V6, P467, DOI [10.1080/01434632.1985.9994221, DOI 10.1080/01434632.1985.9994221]
   Guion SG, 2000, J PHONETICS, V28, P27, DOI 10.1006/jpho.2000.0104
   Guion SG, 2003, PHONETICA, V60, P98, DOI 10.1159/000071449
   Hagiwara R, 1997, J ACOUST SOC AM, V102, P655, DOI 10.1121/1.419712
   Harrington J., 2000, J INT PHONETIC ASS, V30, P63, DOI [10.1017/S0025100300006666, DOI 10.1017/S0025100300006666]
   Helgason P, 2008, J PHONETICS, V36, P607, DOI 10.1016/j.wocn.2008.02.003
   Herd W. J., 2015, P M AC, V23
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Holliday JJ, 2015, J PHONETICS, V50, P1, DOI 10.1016/j.wocn.2015.01.004
   Huffman Marie K., 2015, Journal of the Acoustical Society of America, V137, DOI 10.1121/1.4920280
   Jarvis S., 2008, CROSSLINGUISTIC INFL
   Jarvis S., 2003, EFFECTS 2 LANGUAGE 1, P81
   Jessner U., 1999, LANG AWARE, V8, P3, DOI [10.1080/09658419908667129, DOI 10.1080/09658419908667129]
   Joh Jeongsoon, 2010, [Korean Journal of Applied Linguistics, 응용언어학], V26, P101
   Kartushina N, 2015, THESIS
   Kartushina N, 2016, LANG LEARN, V66, P155, DOI 10.1111/lang.12187
   Kartushina N, 2016, J PHONETICS, V57, P21, DOI 10.1016/j.wocn.2016.05.001
   KEATING P, 1983, J PHONETICS, V11, P277, DOI 10.1016/S0095-4470(19)30827-7
   KEATING PA, 1984, LANGUAGE, V60, P286, DOI 10.2307/413642
   Kecskes I, 1998, WORD, V49, P321, DOI 10.1080/00437956.1998.11432476
   Kecskes I., 2000, FOREIGN LANGUAGE MOT
   Kim JH, 2010, BILING-LANG COGN, V13, P73, DOI 10.1017/S136672890999037X
   Kim KHS, 1997, NATURE, V388, P171, DOI 10.1038/40623
   Kim M., 2009, J ACOUST SOC AM, V125, P2764
   Kim Midam, 2011, Lab Phonol, V2, P125
   Kroll JF, 2014, CURR DIR PSYCHOL SCI, V23, P159, DOI 10.1177/0963721414528511
   Ladefoged P, 2005, VOWELS CONSONANTS
   Lai Y, 2009, P 2 INT C E AS LING
   Lang B, LANGUAGE SPEECH
   Laufer B., 2015, ITL INT J APPL LINGU, V166, P229
   Lewis Paul M., 2015, ETHNOLOGUE LANGUAGES
   Li P, 2014, BILING-LANG COGN, V17, P673, DOI 10.1017/S1366728913000606
   Linck JA, 2009, PSYCHOL SCI, V20, P1507, DOI 10.1111/j.1467-9280.2009.02480.x
   LISKER L, 1977, LANG SPEECH, V20, P209, DOI 10.1177/002383097702000303
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Liu S., 2000, BILING-LANG COGN, V3, P131, DOI DOI 10.1017/S1366728900000225
   Lupke Friederike, 2013, REPERTOIRES CHOICES
   MAJOR RC, 1992, MOD LANG J, V76, P190, DOI 10.2307/329772
   Marian V, 2003, BRAIN LANG, V86, P70, DOI 10.1016/S0093-934X(02)00535-7
   Marion V, 2007, J SPEECH LANG HEAR R, V50, P940, DOI 10.1044/1092-4388(2007/067)
   Mayr R, 2012, BILING-LANG COGN, V15, P687, DOI 10.1017/S136672891100071X
   Mennen I, 2004, J PHONETICS, V32, P543, DOI 10.1016/j.wocn.2004.02.002
   Morris RJ, 2008, J PHONETICS, V36, P308, DOI 10.1016/j.wocn.2007.06.003
   Namjoshi J., 2015, P 18 INT C PHON SCI
   Nearey T. M., 1994, J INT PHON ASSOC, V24, P1, DOI [10.1017/S0025100300004965, DOI 10.1017/S0025100300004965]
   Obler L., 2014, AFINLA E SOVELTAVAN, V6, P32
   Oh GE, 2011, J PHONETICS, V39, P156, DOI 10.1016/j.wocn.2011.01.002
   Oh JS, 2010, J CHILD LANG, V37, P1123, DOI 10.1017/S0305000909990286
   Paradis J., 2001, INT J BILINGUAL, V5, P19, DOI DOI 10.1177/13670069010050010201
   Parmentier FBR, 2010, COGNITION, V115, P504, DOI 10.1016/j.cognition.2010.03.002
   Pavlenko A, 2002, APPL LINGUIST, V23, P190, DOI 10.1093/applin/23.2.190
   Pavlenko A., 2000, ISSUES APPL LINGUIST, V11, P175
   Pavlenko Aneta, 2003, EFFECTS 2 LANGUAGE 1, P32
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Pillar Ingrid, 2002, J SOCIOLING, V6, P179, DOI DOI 10.1111/1467-9481.00184
   R Development Core Team, 2018, R LANG ENV STAT COMP
   Rickford J, 2013, J SOCIOLING, V17, P143, DOI 10.1111/josl.12017
   Sancier ML, 1997, J PHONETICS, V25, P421, DOI 10.1006/jpho.1997.0051
   Sankoff G, 2007, LANGUAGE, V83, P560, DOI 10.1353/lan.2007.0106
   Schmid M. S., 2009, BILINGUAL MENTAL LEX, P209, DOI DOI 10.21832/9781847691262-011
   Schmid M. S., OXFORD HDB LANGUAGE
   Schmid MS, 2013, WIRES COGN SCI, V4, P117, DOI 10.1002/wcs.1218
   Schuhmann K. S., 2015, P 18 INT C PHON SCI
   SCHWANENFLUGEL PJ, 1986, J MEM LANG, V25, P605, DOI 10.1016/0749-596X(86)90014-8
   Seliger H. W., 1991, 1 LANGUAGE ATTRITION, P3, DOI DOI 10.1017/CBO9780511620720.001
   Sharma D, 2011, LANG VAR CHANGE, V23, P399, DOI 10.1017/S0954394511000159
   Stolberg D, 2010, BILING-LANG COGN, V13, P19, DOI 10.1017/S1366728909990332
   Tice M., 2012, PAGUETTES BASTRIES N, V2012, P72
   Tobin SJ, 2017, J PHONETICS, V65, P45, DOI 10.1016/j.wocn.2017.05.006
   Tucker GR, 1999, GLOBAL PERSPECTIVE B
   Ulbrich C, 2014, J PHONETICS, V45, P26, DOI 10.1016/j.wocn.2014.02.008
   Unsworth S, 2013, BILING-LANG COGN, V16, P86, DOI 10.1017/S1366728912000284
   van Hell JG, 2002, PSYCHON B REV, V9, P780, DOI 10.3758/BF03196335
   Wagner SE, 2012, LANG VAR CHANGE, V24, P179, DOI 10.1017/S0954394512000099
   Wagner SE, 2011, LANG VAR CHANGE, V23, P275, DOI 10.1017/S0954394511000111
   Ward N., 2009, J ACOUST SOC AM, V126, P2311
   Yang BG, 1996, J PHONETICS, V24, P245, DOI 10.1006/jpho.1996.0013
   YELLAND GW, 1993, APPL PSYCHOLINGUIST, V14, P423, DOI 10.1017/S0142716400010687
   Yoon SY, 2015, COMMUN SCI DISORD-CS, V20, P178, DOI 10.12963/csd.14188
NR 133
TC 4
Z9 4
U1 1
U2 1
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD MAY
PY 2019
VL 74
SI 1
BP 96
EP 113
DI 10.1016/j.wocn.2019.03.001
PG 18
WC Linguistics; Language & Linguistics
SC Linguistics
GA ID0HD
UT WOS:000471363700006
DA 2021-02-24
ER

PT J
AU Steffman, J
AF Steffman, Jeremy
TI Intonational structure mediates speech rate normalization in the
   perception of segmental categories
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Prosody; Intonation; Segmental categorization; Speech perception;
   Speaking rate normalization
ID SPEAKING RATE; LANGUAGE EXPERIENCE; VOWEL LENGTH; ENGLISH; DOMAIN;
   PITCH; CUE; DURATION; COMPENSATION; INFORMATION
AB The question of if and to what extent listeners' perceptual phonetic categories are sensitive to prosodically driven variability has been a topic of interest in the literature. The present study reports on two experiments which address this question in light of recent research. In Experiment 1, listeners categorized a VOT continuum as /p/ or /b/ in a target syllable (/pa/ or /ba/). The target was placed in a carrier phrase where the duration and f0 of the pre-target syllable were manipulated. Results suggest listeners are sensitive to intonational structure in their computation of speech rate, interpreting a short syllable with low-rising f0 (created from an L-H% boundary tone in English intonational phonology) as an increase in speech rate. This perceived increase in rate shifts the category boundary of the subsequent target VOT. Experiment 2 showed listeners similarly adjusted categorization of a vowel duration continuum, where vowel duration is a cue to a following obstruent's voicing (categorized as "coat" or "code"). Taken together, these results suggest that listeners are sensitive to intonational structure in their perception of segmental contrasts and use the distribution of tonal targets over a given temporal interval in computing speech rate. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Steffman, Jeremy] Univ Calif Los Angeles, Dept Linguist, 3125 Campbell Hall, Los Angeles, CA 90095 USA.
RP Steffman, J (corresponding author), Univ Calif Los Angeles, Dept Linguist, 3125 Campbell Hall, Los Angeles, CA 90095 USA.
EM jsteffman@ucla.edu
FU UCLA Summer Research Mentorship Award
FX I would like to thank Sun-Ah Jun, Pat Keating, and Megha Sundara for
   valuable advice, as well as members of the UCLA Phonetics Lab and three
   anonymous reviewers for insightful comments and feedback. Further thanks
   to Yang Wang for assistance with data collection and to Adam Royer for
   recording speech for the stimuli. This research was supported in part by
   a UCLA Summer Research Mentorship Award (2017) to the author.
CR Baese-Berk M. M, 2016, P SPEECH PROSODY, V8, P979
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, PARSIMONIOUS MIXED M
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bech M, 2005, HEALTH ECON, V14, P1079, DOI 10.1002/hec.984
   Beckman M. E., 1986, PHONOLOGY YB, V3, P255, DOI [DOI 10.1017/S095267570000066X, 10.1017/S095267570000066X]
   Beckman M. E, 1990, PAPERS LAB PHONOLOGY, VI
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bosker H. R., 2015, P 18 INT C PHON SCI
   Bosker HR, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01063
   Bosker HR, 2017, ATTEN PERCEPT PSYCHO, V79, P333, DOI 10.3758/s13414-016-1206-4
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Byrd D, 2000, PHONETICA, V57, P3, DOI 10.1159/000028456
   CHEN M, 1970, PHONETICA, V22, P129, DOI 10.1159/000259312
   Cho T., 2002, EFFECTS PROSODY ARTI
   Cho TH, 2007, J PHONETICS, V35, P210, DOI 10.1016/j.wocn.2006.03.003
   Cho T, 2015, BLACKW HBK LINGUIST, P505
   Cho T, 2009, J PHONETICS, V37, P466, DOI 10.1016/j.wocn.2009.08.001
   Cho TH, 2001, J PHONETICS, V29, P155, DOI 10.1006/jpho.2001.0131
   Cumming R, 2011, J PHONETICS, V39, P375, DOI 10.1016/j.wocn.2011.01.004
   DIEHL RL, 1989, J ACOUST SOC AM, V85, P2154, DOI 10.1121/1.397864
   DIEHL RL, 1980, PERCEPT PSYCHOPHYS, V27, P435, DOI 10.3758/BF03204461
   Dilley LC, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01002
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Docherty G., 1992, PAPERS LABORATORY PH, P90, DOI DOI 10.1017/CBO9780511519918.005
   FLEGE JE, 1992, J ACOUST SOC AM, V92, P128, DOI 10.1121/1.404278
   Fougeron C, 1997, J ACOUST SOC AM, V101, P3728, DOI 10.1121/1.418332
   Fougeron C, 2001, J PHONETICS, V29, P109, DOI 10.1006/jpho.2000.0114
   Fougeron C, 1998, THESIS
   Fullana N., 2009, RECENT RES 2 LANGUAG, P97
   Georgeton L, 2014, J PHONETICS, V44, P83, DOI 10.1016/j.wocn.2014.02.006
   Georgeton L, 2016, J SPEECH LANG HEAR R, V59, pS1575, DOI 10.1044/2016_JSLHR-S-15-0044
   Harrington J, 2008, J ACOUST SOC AM, V123, P2825, DOI 10.1121/1.2897042
   Heffner CC, 2017, ATTEN PERCEPT PSYCHO, V79, P964, DOI 10.3758/s13414-016-1274-5
   Holt LL, 2000, J ACOUST SOC AM, V108, P710, DOI 10.1121/1.429604
   Iverson P, 2016, J ACOUST SOC AM, V139, P1799, DOI 10.1121/1.4944755
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   John Fox, 2003, J STAT SOFTW, V8, P1, DOI DOI 10.18637/JSS.V008.I15
   Jun S.-A., 1998, PHONOLOGY, V15, P189, DOI DOI 10.1017/S0952675798003571
   Jun S.-A., 2005, PROSODIC TYPOLOGY PH, P201, DOI DOI 10.1093/ACPROF:OSO/9780199249633.003.0008
   Jun S.-A., 1995, PHONOLOGY PHONETIC E, P235
   Jun SA, 1993, THESIS
   Keating P., 2006, SPEECH PRODUCTION MO, P167
   Keating P, 2003, PHONETIC INTERPRETAT, VVI
   Kim S. J., 2004, THESIS
   Kim S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202912
   Kim S, 2013, J ACOUST SOC AM, V134, pEL19, DOI 10.1121/1.4807431
   Kim S, 2009, J ACOUST SOC AM, V125, P3373, DOI 10.1121/1.3097777
   Kjelgaard MM, 1999, J MEM LANG, V40, P153, DOI 10.1006/jmla.1998.2620
   KLATT DH, 1976, J ACOUST SOC AM, V59, P1208, DOI 10.1121/1.380986
   Krishnan A, 2005, COGNITIVE BRAIN RES, V25, P161, DOI 10.1016/j.cogbrainres.2005.05.004
   Krishnan A, 2009, J COGNITIVE NEUROSCI, V21, P1092, DOI 10.1162/jocn.2009.21077
   Krishnan A, 2009, NEUROREPORT, V20, P408, DOI 10.1097/WNR.0b013e3283263000
   Ladd DR, 2003, J PHONETICS, V31, P81, DOI 10.1016/S0095-4470(02)00073-6
   Ladd DR, 2008, CAMB STUD LINGUIST, V79, P1
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Lee EK, 2011, LANG COGNITIVE PROC, V26, P262, DOI 10.1080/01690965.2010.491650
   Lehiste I., 1976, J PHONETICS, V4, P113
   LIBERMAN AM, 1989, SCIENCE, V243, P489, DOI 10.1126/science.2643163
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P407, DOI 10.3758/BF03204884
   MANN VA, 1981, J ACOUST SOC AM, V69, P548, DOI 10.1121/1.385483
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001
   MILLER JL, 1989, PERCEPT PSYCHOPHYS, V46, P505, DOI 10.3758/BF03208147
   MILLER JL, 1984, PERCEPT PSYCHOPHYS, V35, P5, DOI 10.3758/BF03205919
   Mitterer H, 2006, PERCEPT PSYCHOPHYS, V68, P1227, DOI 10.3758/BF03193723
   Mitterer H, 2016, J PHONETICS, V54, P68, DOI 10.1016/j.wocn.2015.09.002
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Newman RS, 2009, J PHONETICS, V37, P46, DOI 10.1016/j.wocn.2008.09.001
   Newman RS, 1996, PERCEPT PSYCHOPHYS, V58, P540, DOI 10.3758/BF03213089
   Onaka A., 2003, P 15 INT C PHON SCI, P2091
   Pierrehumbert J., 1980, THESIS
   Pind J, 1998, J ACOUST SOC AM, V103, P2117, DOI 10.1121/1.421357
   PISONI DB, 1983, PERCEPT PSYCHOPHYS, V34, P314, DOI 10.3758/BF03203043
   Pitt MA, 2016, ATTEN PERCEPT PSYCHO, V78, P334, DOI 10.3758/s13414-015-0981-7
   PRICE PJ, 1991, J ACOUST SOC AM, V90, P2956, DOI 10.1121/1.401770
   RAPHAEL LJ, 1972, J ACOUST SOC AM, V51, P1296, DOI 10.1121/1.1912974
   Reinisch E, 2016, ATTEN PERCEPT PSYCHO, V78, P1203, DOI 10.3758/s13414-016-1067-x
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   RIETVELD ACM, 1987, J PHONETICS, V15, P273, DOI 10.1016/S0095-4470(19)30571-6
   RStudio Team, 2016, RSTUDIO INTEGRATED D
   Saltzman D, 2016, ROLE SPEECH ENVELOPE
   Schafer A, 1996, LANG COGNITIVE PROC, V11, P135, DOI 10.1080/016909696387240
   ShattuckHufnagel S, 1996, J PSYCHOLINGUIST RES, V25, P193, DOI 10.1007/BF01708572
   Sjerps MJ, 2013, J PHONETICS, V41, P145, DOI 10.1016/j.wocn.2013.01.005
   Spinelli E, 2010, ATTEN PERCEPT PSYCHO, V72, P775, DOI 10.3758/APP.72.3.775
   STREETER LA, 1978, J ACOUST SOC AM, V64, P1582, DOI 10.1121/1.382142
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   Turk AE, 1997, J PHONETICS, V25, P25, DOI 10.1006/jpho.1996.0032
   Turk AE, 1999, J PHONETICS, V27, P171, DOI 10.1006/jpho.1999.0093
   Turk AE, 2007, J PHONETICS, V35, P445, DOI 10.1016/j.wocn.2006.12.001
   Tyler MD, 2009, J ACOUST SOC AM, V126, P367, DOI 10.1121/1.3129127
   VANDOMMELEN WA, 1993, J PHONETICS, V21, P367, DOI 10.1016/S0095-4470(19)30226-8
   Veilleux N, 6 911 TRANSCRIBING P
   Wade T, 2005, PERCEPT PSYCHOPHYS, V67, P939, DOI 10.3758/BF03193621
   WALSH T, 1981, J PHONETICS, V9, P305, DOI 10.1016/S0095-4470(19)30973-8
   Warner N, 2010, LANG SPEECH, V53, P107, DOI 10.1177/0023830909351235
   WIGHTMAN CW, 1992, J ACOUST SOC AM, V91, P1707, DOI 10.1121/1.402450
   Xu YS, 2006, J ACOUST SOC AM, V120, P1063, DOI 10.1121/1.2213572
NR 99
TC 6
Z9 6
U1 2
U2 4
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD MAY
PY 2019
VL 74
SI 1
BP 114
EP 129
DI 10.1016/j.wocn.2019.03.002
PG 16
WC Linguistics; Language & Linguistics
SC Linguistics
GA ID0HD
UT WOS:000471363700007
DA 2021-02-24
ER

PT J
AU Schulz, SE
   Stevenson, RA
AF Schulz, Samantha E.
   Stevenson, Ryan A.
TI Sensory hypersensitivity predicts repetitive behaviours in autistic and
   typically-developing children
SO AUTISM
LA English
DT Article
DE autism spectrum disorder; repetitive behaviours; restricted interests;
   sensory hypersensitivity; sensory processing
ID MULTISENSORY SPEECH-PERCEPTION; STEREOTYPED BEHAVIORS; YOUNG-CHILDREN;
   SPECTRUM DISORDERS; FEATURES; ANXIETY; TRAITS; RESPONSIVENESS;
   QUESTIONNAIRE; EXPERIENCES
AB The objective of this study was to examine the relationship between sensory hypersensitivity and restricted interests and repetitive behaviours associated with autism spectrum disorder and their typically-developing peers. Furthermore, the aims included the examination of the relationship across sensory modalities and various types of restricted interests and repetitive behaviours. Data were collected from the parents of 114 children: 49 of whom were diagnosed with autism spectrum disorder and 65 typically-developing children. Parents completed the Sensory Profile 2 - Child Version and the Repetitive Behaviours Questionnaire, Second Edition. The results suggested that sensory hypersensitivity is strongly related to the core autism spectrum disorder symptom of repetitive behaviours. This relationship was not specific to autism spectrum disorder; repetitive behaviours significantly increased with sensory hypersensitivity in typically-developing individuals as well. This effect was consistent across all modalities in both autism spectrum disorder and typically developing groups; group differences were observed in the oral and tactile modalities. Furthermore, sensory hypersensitivity was significantly predictive of repetitive behaviours in all participants, autism spectrum disorder and typically-developing, and importantly, autism spectrum disorder diagnosis did not add any predictive influence above and beyond sensory hypersensitivity. Finally, sensory hypersensitivity was significantly predictive of all subdomains of repetitive behaviours, including repetitive motor movements, rigidity and adherence to routine, preoccupation with restricted patterns of interest and unusual sensory interests, and diagnosis added no predictive ability beyond sensory hypersensitivity.
C1 [Schulz, Samantha E.; Stevenson, Ryan A.] Western Univ, Dept Psychol, London, ON, Canada.
   [Schulz, Samantha E.; Stevenson, Ryan A.] Western Univ, Brain & Mind Inst, London, ON, Canada.
   [Stevenson, Ryan A.] York Univ, Dept Psychol, N York, ON, Canada.
RP Schulz, SE (corresponding author), Dept Psychol, Western Interdisciplinary Res Bldg, London, ON N6A 3K7, Canada.
EM sschulz@uwo.ca
FU NSERCNatural Sciences and Engineering Research Council of Canada (NSERC)
   [RGPIN-2017-04656]; SSHRC Insight Grant [435-2017-0936]; University of
   Western Ontario Faculty Development Research Fund; Western Graduate
   Research Scholarship; Dr. Benjamin Goldberg Research Award
FX This work was funded by grants to R.A.S. by an NSERC Discovery Grant
   (RGPIN-2017-04656), an SSHRC Insight Grant (435-2017-0936) and the
   University of Western Ontario Faculty Development Research Fund and to
   S.E.S. by the Western Graduate Research Scholarship and the Dr. Benjamin
   Goldberg Research Award.
CR American Psychiatric Association (APA), 2013, DIAGN STAT MAN MENT
   Baker AEZ, 2008, J AUTISM DEV DISORD, V38, P867, DOI 10.1007/s10803-007-0459-0
   Baranek G. T., 1999, SENSORY PROCES UNPUB
   Baranek G. T, 2010, TACTILE DEFENS UNPUB
   Baranek GT, 2007, AM J MENT RETARD, V112, P233, DOI 10.1352/0895-8017(2007)112[233:HSPIYC]2.0.CO;2
   Baranek GT, 2006, J CHILD PSYCHOL PSYC, V47, P591, DOI 10.1111/j.1469-7610.2005.01546.x
   BARTAK L, 1976, J AUTISM CHILD SCHIZ, V6, P109, DOI 10.1007/BF01538054
   Baum SH, 2015, PROG NEUROBIOL, V134, P140, DOI 10.1016/j.pneurobio.2015.09.007
   Bishop SL, 2006, CHILD NEUROPSYCHOL, V12, P247, DOI 10.1080/09297040600630288
   Black KR, 2017, J AUTISM DEV DISORD, V47, P2459, DOI 10.1007/s10803-017-3161-x
   Bodfish J. W., 1999, W CAROLINA CTR RES R
   Bodfish JW, 2000, J AUTISM DEV DISORD, V30, P237, DOI 10.1023/A:1005596502855
   Boyd BA, 2010, AUTISM RES, V3, P78, DOI 10.1002/aur.124
   Boyd BA, 2009, RES AUTISM SPECT DIS, V3, P959, DOI 10.1016/j.rasd.2009.05.003
   Brereton AV, 2002, J AM ACAD CHILD PSY, V41, P1369, DOI 10.1097/00004583-200211000-00019
   Carcani-Rathwell I, 2006, J CHILD PSYCHOL PSYC, V47, P573, DOI 10.1111/j.1469-7610.2005.01565.x
   Chen YH, 2009, J AUTISM DEV DISORD, V39, P635, DOI 10.1007/s10803-008-0663-6
   COLMAN RS, 1976, J AUTISM CHILD SCHIZ, V6, P157, DOI 10.1007/BF01538059
   Dunn W., 2014, SENSORY PROFILE 2 US
   Evans DW, 1997, CHILD DEV, V68, P58, DOI 10.2307/1131925
   Gabriels RL, 2005, RES DEV DISABIL, V26, P169, DOI 10.1016/j.ridd.2004.05.003
   Gabriels RL, 2008, RES AUTISM SPECT DIS, V2, P660, DOI 10.1016/j.rasd.2008.02.002
   Hellendoorn A, 2014, RES DEV DISABIL, V35, P423, DOI 10.1016/j.ridd.2013.11.012
   Honey E, 2007, J AUTISM DEV DISORD, V37, P1107, DOI 10.1007/s10803-006-0253-4
   Honey E, 2012, RES AUTISM SPECT DIS, V6, P355, DOI 10.1016/j.rasd.2011.06.009
   Horder J, 2014, J AUTISM DEV DISORD, V44, P1461, DOI 10.1007/s10803-013-2012-7
   HUTT C, 1965, ANIM BEHAV, V13, P1, DOI 10.1016/0003-3472(65)90064-3
   HUTT C, 1964, NATURE, V204, P908, DOI 10.1038/204908a0
   Kern JK, 2007, RES AUTISM SPECT DIS, V1, P185, DOI 10.1016/j.rasd.2006.09.002
   Kim SH, 2010, AUTISM RES, V3, P162, DOI 10.1002/aur.142
   Leekam S, 2007, J CHILD PSYCHOL PSYC, V48, P1131, DOI 10.1111/j.1469-7610.2007.01778.x
   Lewis MH, 1998, MENT RETARD DEV D R, V4, P80, DOI 10.1002/(SICI)1098-2779(1998)4:2<80::AID-MRDD4>3.0.CO;2-0
   Lidstone J, 2014, RES AUTISM SPECT DIS, V8, P82, DOI 10.1016/j.rasd.2013.10.001
   Lord C., 2002, ADOS MANUAL
   MacDonald R, 2007, RES DEV DISABIL, V28, P266, DOI 10.1016/j.ridd.2006.01.004
   Matson JL, 1997, RES DEV DISABIL, V18, P471, DOI 10.1016/S0891-4222(97)00023-1
   Miguel HO, 2017, J AUTISM DEV DISORD, V47, P2425, DOI 10.1007/s10803-017-3163-8
   Militerni R, 2002, EUR CHILD ADOLES PSY, V11, P210, DOI 10.1007/s00787-002-0279-x
   Morgan L, 2008, J CHILD PSYCHOL PSYC, V49, P826, DOI 10.1111/j.1469-7610.2008.01904.x
   PERRY A, 1989, J AUTISM DEV DISORD, V19, P41, DOI 10.1007/BF02212717
   Poustka F, 1993, Acta Paedopsychiatr, V56, P69
   Richler J, 2007, J AUTISM DEV DISORD, V37, P73, DOI 10.1007/s10803-006-0332-6
   Robertson AE, 2013, J AUTISM DEV DISORD, V43, P775, DOI 10.1007/s10803-012-1608-7
   Rogers SJ, 2003, J AUTISM DEV DISORD, V33, P631, DOI 10.1023/B:JADD.0000006000.38991.a7
   Saulnier CA, 2002, THESIS
   Stevenson RA, 2017, AUTISM, DOI [10.1177/1362361317704413., DOI 10.1177/1362361317704413.]
   Stevenson RA, 2017, AUTISM RES, V10, P1280, DOI 10.1002/aur.1776
   Stevenson RA, 2016, AUTISM RES, V9, P720, DOI 10.1002/aur.1566
   Stevenson RA, 2018, J AUTISM DEV DISORD, V48, P1382, DOI 10.1007/s10803-016-2711-y
   Stevenson RA, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00379
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Stewart ME, 2009, AUTISM, V13, P133, DOI 10.1177/1362361308098515
   Sutherland A, 2010, BRAIN, V133, P2089, DOI 10.1093/brain/awq122
   Szatmari P, 2006, J CHILD PSYCHOL PSYC, V47, P582, DOI 10.1111/j.1469-7610.2005.01537.x
   Talay-Ongan A., 2000, INT J DISABIL DEV ED, V47, P201, DOI DOI 10.1080/713671112
   THOMPSON TJ, 1985, AM J MENT DEF, V89, P580
   Thye MD, 2018, DEV COGN NEUROS-NETH, V29, P151, DOI 10.1016/j.dcn.2017.04.010
   Tomchek SD, 2007, AM J OCCUP THER, V61, P190, DOI 10.5014/ajot.61.2.190
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   Watt N, 2008, J AUTISM DEV DISORD, V38, P1518, DOI 10.1007/s10803-007-0532-8
   Wechsler D., 2011, WECHSLER ABBREVIATED
   Werner E, 2005, J AUTISM DEV DISORD, V35, P337, DOI 10.1007/s10803-005-3301-6
   Wigham S, 2015, J AUTISM DEV DISORD, V45, P943, DOI 10.1007/s10803-014-2248-x
   Wolff JJ, 2017, MOL AUTISM, V8, DOI 10.1186/s13229-017-0126-z
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
NR 65
TC 9
Z9 9
U1 0
U2 19
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1362-3613
EI 1461-7005
J9 AUTISM
JI Autism
PD MAY
PY 2019
VL 23
IS 4
BP 1028
EP 1041
DI 10.1177/1362361318774559
PG 14
WC Psychology, Developmental
SC Psychology
GA IC3KD
UT WOS:000470858200020
PM 30244585
DA 2021-02-24
ER

PT J
AU Stone, A
   Bosworth, RG
AF Stone, Adam
   Bosworth, Rain G.
TI Exploring Infant Sensitivity to Visual Language using Eye Tracking and
   the Preferential Looking Paradigm
SO JOVE-JOURNAL OF VISUALIZED EXPERIMENTS
LA English
DT Article
DE Behavior; Issue 147; eye tracking; infant development; infant attention;
   language acquisition; preferential looking
ID SPEECH-PERCEPTION; INSIGHTS; DISCRIMINATION; FACILITATION; FACES
AB We discuss the use of the preferential looking paradigm in eye tracking studies in order to study how infants develop, understand, and attend to the world around them. Eye tracking is a safe and non-invasive way to collect gaze data from infants, and the preferential looking paradigm is simple to design and only requires the infant to be attending to the screen. By simultaneously showing two visual stimuli that differ in one dimension, we can assess whether infants show different looking behavior for either stimulus, thus demonstrating sensitivity to that difference. The challenges in such experimental approaches are that experiments must be kept brief (no more than 10 min) and be carefully controlled such that the two stimuli differ in only one way. The interpretation of null results must also be carefully considered. In this paper, we illustrate a successful example of an infant eye tracking study with a preferential looking paradigm to discover that 6-month-olds are sensitive to linguistic cues in a signed language despite having no prior exposure to signed language, suggesting that infants possess intrinsic or innate sensitivities to these cues.
C1 [Stone, Adam] Convo Commun, Austin, TX USA.
   [Bosworth, Rain G.] Rochester Inst Technol, Natl Tech Inst Deaf, Rochester, NY 14623 USA.
RP Bosworth, RG (corresponding author), Rochester Inst Technol, Natl Tech Inst Deaf, Rochester, NY 14623 USA.
EM rain@mail.rit.edu
RI Bosworth, Rain/W-3224-2019
OI Bosworth, Rain/0000-0001-9645-8371
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R01EY024623]; NSFNational Science
   Foundation (NSF) [SBE-1041725]; NATIONAL EYE INSTITUTEUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Eye Institute (NEI) [R01EY024623, R01EY024623,
   R01EY024623, R01EY024623, R01EY024623, R01EY024623] Funding Source: NIH
   RePORTER
FX Data collection for the study was conducted in the UCSD Mind,
   Experience, and Perception Lab (UCSD MEP Lab) at the University of
   California, San Diego. Funding was provided by NIH R01EY024623 (Bosworth
   & Dobkins) and NSF SBE-1041725 (Petitto & Allen; subaward to Bosworth).
   We are grateful to the MEPLab student research team, and to the infants
   and families in San Diego, California, who participated in this study.
CR Aslin RN, 2004, INFANCY, V6, P155, DOI 10.1207/s15327078in0602_1
   Baker SA, 2006, LANG LEARN DEV, V2, P147, DOI 10.1207/s15473341lld0203_1
   Berent I., 2013, PHONOLOGICAL MIND
   Brentari Diane, 1998, PROSODIC MODEL SIGN
   Byers-Heinlein K, 2009, DEVELOPMENTAL SCI, V12, P815, DOI 10.1111/j.1467-7687.2009.00902.x
   Colombo J, 2009, NEUROBIOL LEARN MEM, V92, P225, DOI 10.1016/j.nlm.2008.06.002
   Duchowski A., 2007, EYE TRACKING METHODO
   Feng G, 2011, J COGN DEV, V12, P1, DOI 10.1080/15248372.2011.547447
   Gredeback G, 2004, INFANCY, V6, P165, DOI 10.1207/s15327078in0602_2
   Gredeback G, 2012, INFANCY, V17, P79, DOI 10.1111/j.1532-7078.2011.00091.x
   Gredeback G, 2010, DEV NEUROPSYCHOL, V35, P1, DOI 10.1080/87565640903325758
   Hall WC, 2017, MATERN CHILD HLTH J, V21, P961, DOI 10.1007/s10995-017-2287-y
   Holmqvist K., 2012, P S EYE TRACK RES AP, DOI [DOI 10.1145/2168556.2168563, 10.1145/2168556.2168563]
   Jantunen Tommi, 2010, SIGN LANGUAGES, P312
   JOHNSON MH, 1994, PSYCHOL SCI, V5, P90, DOI 10.1111/j.1467-9280.1994.tb00636.x
   JUSCZYK PW, 1988, LANG SPEECH, V31, P217, DOI 10.1177/002383098803100301
   Krentz UC, 2008, DEVELOPMENTAL SCI, V11, P1, DOI 10.1111/j.1467-7687.2007.00652.x
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   MACNEILAGE PF, 1970, J ACOUST SOC AM, V47, P104, DOI 10.1121/1.1973807
   Gomez DM, 2014, P NATL ACAD SCI USA, V111, P5837, DOI 10.1073/pnas.1318261111
   Morgante JD, 2012, INFANCY, V17, P9, DOI 10.1111/j.1532-7078.2011.00089.x
   NOTON D, 1971, SCIENCE, V171, P308, DOI 10.1126/science.171.3968.308
   Oakes LM, 2012, INFANCY, V17, P1, DOI 10.1111/j.1532-7078.2011.00101.x
   Ohala J. J., 1990, PAPERS LABORATORY PH, P258, DOI DOI 10.1017/CBO9780511627736.014
   PERLMUTTER DM, 1992, LINGUIST INQ, V23, P407
   Petitto LA, 2016, WIRES COGN SCI, V7, P366, DOI 10.1002/wcs.1404
   Petitto LA, 2012, BRAIN LANG, V121, P130, DOI 10.1016/j.bandl.2011.05.003
   Quinn PC, 2008, J NEUROPSYCHOL, V2, P15, DOI 10.1348/174866407X231029
   Rhodes G, 2002, PERCEPTION, V31, P315, DOI 10.1068/p3129
   Sandler Wendy, 1993, PHONOLOGY, V10, P209, DOI DOI 10.1017/S0952675700000051
   Sirois S, 2012, INFANCY, V17, P61, DOI 10.1111/j.1532-7078.2011.00096.x
   Stone A., 2017, LANGUAGE LEARNING DE, V14, P130
   Wass SV, 2013, BEHAV RES METHODS, V45, P229, DOI 10.3758/s13428-012-0245-6
   Watanabe K, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016919
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
NR 35
TC 2
Z9 2
U1 0
U2 5
PU JOURNAL OF VISUALIZED EXPERIMENTS
PI CAMBRIDGE
PA 1 ALEWIFE CENTER, STE 200, CAMBRIDGE, MA 02140 USA
SN 1940-087X
J9 JOVE-J VIS EXP
JI J. Vis. Exp.
PD MAY
PY 2019
IS 147
AR e59581
DI 10.3791/59581
PG 9
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA IB0US
UT WOS:000469977600110
PM 31157775
DA 2021-02-24
ER

PT J
AU Han, C
   O'Sullivan, J
   Luo, Y
   Herrero, J
   Mehta, AD
   Mesgarani, N
AF Han, Cong
   O'Sullivan, James
   Luo, Yi
   Herrero, Jose
   Mehta, Ashesh D.
   Mesgarani, Nima
TI Speaker-independent auditory attention decoding without access to clean
   speech sources
SO SCIENCE ADVANCES
LA English
DT Article
ID ATTENDED SPEECH; TRACKING; NOISE; REPRESENTATION; ENVIRONMENT;
   SEPARATION
AB Speech perception in crowded environments is challenging for hearing-impaired listeners. Assistive hearing devices cannot lower interfering speakers without knowing which speaker the listener is focusing on. One possible solution is auditory attention decoding in which the brainwaves of listeners are compared with sound sources to determine the attended source, which can then be amplified to facilitate hearing. In realistic situations, however, only mixed audio is available. We utilize a novel speech separation algorithm to automatically separate speakers in mixed audio, with no need for the speakers to have prior training. Our results show that auditory attention decoding with automatically separated speakers is as accurate and fast as using clean speech sounds. The proposed method significantly improves the subjective and objective quality of the attended speaker. Our study addresses a major obstacle in actualization of auditory attention decoding that can assist hearing-impaired listeners and reduce listening effort for normal-hearing subjects.
C1 [Han, Cong; O'Sullivan, James; Luo, Yi; Mesgarani, Nima] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
   [Han, Cong; O'Sullivan, James; Luo, Yi; Mesgarani, Nima] Columbia Univ, Zuckerman Mind Brain Behav Inst, New York, NY 10027 USA.
   [Herrero, Jose; Mehta, Ashesh D.] Hofstra Northwell Sch Med, Dept Neurosurg, New York, NY USA.
   [Herrero, Jose; Mehta, Ashesh D.] Feinstein Inst Med Res, New York, NY USA.
RP Mesgarani, N (corresponding author), Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.; Mesgarani, N (corresponding author), Columbia Univ, Zuckerman Mind Brain Behav Inst, New York, NY 10027 USA.
EM nima@ee.columbia.edu
RI Luo, Yi/Y-4347-2019
OI Luo, Yi/0000-0002-7447-3885; Han, Cong/0000-0003-2121-000X; Mehta,
   Ashesh/0000-0001-7293-1101
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [NIDCD-DC014279];
   National Institute of Mental HealthUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute of Mental Health (NIMH) [R21MH114166]; Columbia Technology
   Ventures; Pew Charitable Trusts, Pew Biomedical Scholars Program;
   NATIONAL INSTITUTE OF MENTAL HEALTHUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute of Mental Health (NIMH) [R21MH114166, R21MH114166] Funding
   Source: NIH RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC014279,
   R01DC014279, R01DC014279, R01DC014279] Funding Source: NIH RePORTER
FX This work was funded by a grant from the National Institutes of Health
   (NIDCD-DC014279), National Institute of Mental Health (R21MH114166),
   Columbia Technology Ventures, and the Pew Charitable Trusts, Pew
   Biomedical Scholars Program.
CR Akbari H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37359-z
   Akram S, 2016, NEUROIMAGE, V124, P906, DOI 10.1016/j.neuroimage.2015.09.048
   Andri R, 2016, IEEE COMP SOC ANN, P236, DOI 10.1109/ISVLSI.2016.111
   Aroudi A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P851, DOI 10.1109/ICASSP.2018.8462278
   Benovitski YB, 2017, EPILEPSY RES, V135, P29, DOI 10.1016/j.eplepsyres.2017.06.003
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   CARHART R, 1970, ARCHIV OTOLARYNGOL, V91, P273
   Chan W, 2016, INT CONF ACOUST SPEE, P4960, DOI 10.1109/ICASSP.2016.7472621
   Chen JT, 2016, J ACOUST SOC AM, V139, P2604, DOI 10.1121/1.4948445
   Chen Z, 2017, IEEE TRANSP EL ASIA, P437, DOI 10.1109/ASRU.2017.8268969
   Chen Z, 2017, INT CONF ACOUST SPEE, P246, DOI 10.1109/ICASSP.2017.7952155
   Crone NE, 2001, CLIN NEUROPHYSIOL, V112, P565, DOI 10.1016/S1388-2457(00)00545-9
   de Cheveigne A, 2018, NEUROIMAGE, V172, P206, DOI 10.1016/j.neuroimage.2018.01.033
   Destrieux C, 2010, NEUROIMAGE, V53, P1, DOI 10.1016/j.neuroimage.2010.06.010
   Fiedler L, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa66dd
   Fuglsang SA, 2017, NEUROIMAGE, V156, P435, DOI 10.1016/j.neuroimage.2017.04.026
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Grant K. W., 2001, P WORKSH AUD VIS SPE, P132
   Hamacher V, 2005, EURASIP J APPL SIG P, V2005, P2915, DOI 10.1155/ASP.2005.2915
   Hassan A., 2018, BIORXIV
   Hershey JR, 2016, INT CONF ACOUST SPEE, P31, DOI 10.1109/ICASSP.2016.7471631
   Heymann J, 2016, INT CONF ACOUST SPEE, P196, DOI 10.1109/ICASSP.2016.7471664
   Hullett PW, 2016, J NEUROSCI, V36, P2014, DOI 10.1523/JNEUROSCI.1779-15.2016
   Isik Y., P INT, P545
   Jensen J, 2016, IEEE-ACM T AUDIO SPE, V24, P2009, DOI 10.1109/TASLP.2016.2585878
   Jolliffe I., 2011, INT ENCY STAT SCI, P1094, DOI DOI 10.1007/978-3-642-04898-2_455
   Kingma D. P., 2014, ARXIV14126980, P1
   Kolbaek M., 2017, 2017 IEEE 27 INT WOR, P1
   Kolbaek M, 2017, IEEE-ACM T AUDIO SPE, V25, P1901, DOI 10.1109/TASLP.2017.2726762
   Lacey G., 2016, ARXIV160204283
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Mesgarani N, 2009, J NEUROPHYSIOL, V102, P3329, DOI 10.1152/jn.91128.2008
   Miran S, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00262
   Mirkovic B, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/4/046007
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   MOS, 2006, VOC PERF QUAL SERV I
   O'Sullivan J, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa7ab4
   O'Sullivan JA, 2015, CEREB CORTEX, V25, P1697, DOI 10.1093/cercor/bht355
   Ovtcharov K, 2015, MICROSOFT RES WHITEP, V2, P1
   Patel P, 2018, CELL REP, V24, P2051, DOI 10.1016/j.celrep.2018.07.076
   PAUL DB, 1992, SPEECH AND NATURAL LANGUAGE, P357
   PLOMP R, 1994, EAR HEARING, V15, P2, DOI 10.1097/00003446-199402000-00002
   Ray S, 2011, PLOS BIOL, V9, DOI 10.1371/journal.pbio.1000610
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023
   Sak H, 2014, INTERSPEECH, P338
   Strang G., 1993, INTRO LINEAR ALGEBRA
   Van Eyndhoven S, 2017, IEEE T BIO-MED ENG, V64, P1045, DOI 10.1109/TBME.2016.2587382
   Van Veen B. D., 1988, IEEE ASSP Magazine, V5, P4, DOI 10.1109/53.665
   Wang DL, 2018, IEEE-ACM T AUDIO SPE, V26, P1702, DOI 10.1109/TASLP.2018.2842159
   Yi Luo, 2018, IEEE/ACM Transactions on Audio, Speech and Language Processing, V26, P787, DOI 10.1109/TASLP.2018.2795749
NR 50
TC 11
Z9 11
U1 0
U2 3
PU AMER ASSOC ADVANCEMENT SCIENCE
PI WASHINGTON
PA 1200 NEW YORK AVE, NW, WASHINGTON, DC 20005 USA
SN 2375-2548
J9 SCI ADV
JI Sci. Adv.
PD MAY
PY 2019
VL 5
IS 5
AR eaav6134
DI 10.1126/sciadv.aav6134
PG 11
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA IB2UU
UT WOS:000470125000060
PM 31106271
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Levi, SV
   Harel, D
   Schwartz, RG
AF Levi, Susannah, V
   Harel, Daphna
   Schwartz, Richard G.
TI Language Ability and the Familiar Talker Advantage: Generalizing to
   Unfamiliar Talkers Is What Matters
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID DEVELOPMENTAL APHASIA; LISTENER SENSITIVITY; SPEECH-PERCEPTION; VOWEL
   PERCEPTION; CHILDREN; IMPAIRMENT; WORD; DISCRIMINATION; DEFICITS; AGE
AB Purpose: Previous studies with children and adults have demonstrated a familiar talker advantage-better word recognition for familiar talkers. The goal of the current study was to test whether this phenomenon is modulated by a child's language ability.
   Method: Sixty children with a range of language ability were trained to learn the voices of 3 foreign-accented, German-English bilingual talkers and received feedback about their performance. Both before and after this talker voice training, children completed a spoken word recognition task in which they heard consonant-vowel-consonant words mixed with noise that were spoken by the 3 familiarized talkers and by 3 unfamiliar German-English bilinguals.
   Results: Two findings emerged from this study: First, children with both higher and lower language ability performed similarly on the familiarized talkers. Second, children with higher language scores performed similarly on both the familiarized and unfamiliar talkers, whereas children with lower language scores performed worse on the unfamiliar talkers compared to familiar talkers, suggesting an inability to generalize to novel, unfamiliar talkers who spoke with a similar accent.
   Discussion: Together, these findings indicate that children with higher language scores are able to generalize knowledge about foreign-accented talkers to help spoken word recognition for novel talkers with the same accent. In contrast, children with lower language skills did not exhibit the same magnitude of generalization. This lack of generalization to similar talkers may mean that children with lower language skills are at a disadvantage in spoken language tasks because they are unable to process speech as well when listening to unfamiliar talkers.
C1 [Levi, Susannah, V] NYU, Dept Commun Sci & Disorders, New York, NY 10003 USA.
   [Harel, Daphna] NYU, Dept Appl Stat Social Sci & Humanities, PRIISM Appl Stat Ctr, New York, NY USA.
   [Schwartz, Richard G.] CUNY, Grad Ctr, Program Speech Language Hearing Sci, New York, NY USA.
RP Levi, SV (corresponding author), NYU, Dept Commun Sci & Disorders, New York, NY 10003 USA.
EM svlevi@nyu.edu
RI Schwartz, Richard/AAT-2639-2020
OI Schwartz, Richard/0000-0001-9153-1349; Levi,
   Susannah/0000-0002-3115-8981
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [1R03DC009851]
FX This work was supported by National Institute on Deafness and Other
   Communication Disorders Grant 1R03DC009851 to the first author. We would
   like to thank Gabrielle Alfano, Josh Barocas, Jennifer Bruno, Stephanie
   Lee, Emma Mack, Alexandra Muratore, Sydney Robert, and Margo Waltz for
   help with data collection and the children and their families for their
   participation.
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   Allen JS, 2004, J ACOUST SOC AM, V115, P3171, DOI 10.1121/1.1701898
   Barker BA, 2004, COGNITION, V94, pB45, DOI 10.1016/j.cognition.2004.06.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Benki JR, 2003, J ACOUST SOC AM, V113, P1689, DOI 10.1121/1.1534102
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Brown L, 1997, TEST NONVERBAL INTEL
   Case J, 2018, J SPEECH LANG HEAR R, V61, P1251, DOI 10.1044/2018_JSLHR-L-17-0298
   Cortese MJ, 2008, BEHAV RES METHODS, V40, P791, DOI 10.3758/BRM.40.3.791
   Dailey NS, 2013, J COMMUN DISORD, V46, P330, DOI 10.1016/j.jcomdis.2013.05.001
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   Evans JL, 2009, J SPEECH LANG HEAR R, V52, P321, DOI 10.1044/1092-4388(2009/07-0189)
   Felty R. A., 2007, THESIS
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Kucera H., 1967, COMPUTATIONAL ANAL P
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Levi SV, 2007, J ACOUST SOC AM, V121, P2327, DOI 10.1121/1.2537345
   Levi SV, 2015, J CHILD LANG, V42, P843, DOI 10.1017/S0305000914000506
   Levi SV, 2013, J SPEECH LANG HEAR R, V56, P913, DOI 10.1044/1092-4388(2012/12-0095)
   Levi SV, 2011, J ACOUST SOC AM, V130, P4053, DOI 10.1121/1.3651816
   Markham D, 2004, J SPEECH LANG HEAR R, V47, P725, DOI 10.1044/1092-4388(2004/055)
   McAllister T, J SPEECH LANGUAGE HE
   McArthur GM, 2004, COGN NEUROPSYCHOL, V21, P79, DOI 10.1080/02643290342000087
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   MCREYNOLDS LV, 1966, J SPEECH HEAR RES, V9, P519, DOI 10.1044/jshr.0904.519
   Newman RS, 2007, J PHONETICS, V35, P85, DOI 10.1016/j.wocn.2005.10.004
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   R Development Core Team, 2017, R LANG ENV STAT COMP
   Rosen S, 2003, J PHONETICS, V31, P509, DOI 10.1016/S0095-4470(03)00046-9
   Schneider W., 2007, E PRIME VERSION 2 0
   SCHROEDER MR, 1968, J ACOUST SOC AM, V44, P1735, DOI 10.1121/1.1911323
   Semel E. M., 2003, CLIN EVALUATION LANG
   Shafer VL, 2005, J COGNITIVE NEUROSCI, V17, P1168, DOI 10.1162/0898929054475217
   Sidaras SK, 2009, J ACOUST SOC AM, V125, P3306, DOI 10.1121/1.3101452
   Stark RE, 1996, J SPEECH HEAR RES, V39, P860, DOI 10.1044/jshr.3904.860
   SUSSMAN JE, 1993, J SPEECH HEAR RES, V36, P1286, DOI 10.1044/jshr.3606.1286
   Sussman JE, 2001, J ACOUST SOC AM, V109, P1173, DOI 10.1121/1.1349428
   TALLAL P, 1981, J ACOUST SOC AM, V69, P568, DOI 10.1121/1.385431
   TALLAL P, 1975, NEUROPSYCHOLOGIA, V13, P69, DOI 10.1016/0028-3932(75)90049-4
   TALLAL P, 1974, NEUROPSYCHOLOGIA, V12, P83, DOI 10.1016/0028-3932(74)90030-X
   Theodore RM, 2010, J ACOUST SOC AM, V128, P2090, DOI 10.1121/1.3467771
   Wright BA, 1997, NATURE, V387, P176, DOI 10.1038/387176a0
   Yonan CA, 2000, PSYCHOL AGING, V15, P88, DOI 10.1037/0882-7974.15.1.88
NR 45
TC 0
Z9 0
U1 0
U2 0
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD MAY
PY 2019
VL 62
IS 5
BP 1427
EP 1436
DI 10.1044/2019_JSLHR-L-18-0160
PG 10
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA HZ9UI
UT WOS:000469202500017
PM 31021674
OA Green Published
DA 2021-02-24
ER

PT J
AU Lee, S
   Mendel, LL
   Bidelman, GM
AF Lee, Sungmin
   Mendel, Lisa Lucks
   Bidelman, Gavin M.
TI Predicting Speech Recognition Using the Speech Intelligibility Index and
   Other Variables for Cochlear Implant Users
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID WORKING-MEMORY; NORMAL-HEARING; SPECTRAL-RIPPLE; PHONEME RECOGNITION;
   STIMULATION RATE; TEMPORAL CUES; DEAF-CHILDREN; DIGIT SPAN; SHORT-TERM;
   PERCEPTION
AB Purpose: Although the speech intelligibility index (SII) has been widely applied in the field of audiology and other related areas, application of this metric to cochlear implants (CIs) has yet to be investigated. In this study, SIIs for CI users were calculated to investigate whether the SII could be an effective tool for predicting speech perception performance in a population with CI.
   Method: Fifteen pre- and postlingually deafened adults with CI participated. Speech recognition scores were measured using the AzBio sentence lists. CI users also completed questionnaires and performed psychoacoustic (spectral and temporal resolution) and cognitive function (digit span) tests. Obtained SIIs were compared with predicted SIIs using a transfer function curve. Correlation and regression analyses were conducted on perceptual and demographic predictor variables to investigate the association between these factors and speech perception performance.
   Result: Because of the considerably poor hearing and large individual variability in performance, the SII did not predict speech performance for this CI group using the traditional calculation. However, new SII models were developed incorporating predictive factors, which improved the accuracy of SII predictions in listeners with CI.
   Conclusion: Conventional SII models are not appropriate for predicting speech perception scores for CI users. Demographic variables (aided audibility and duration of deafness) and perceptual-cognitive skills (gap detection and auditory digit span outcomes) are needed to improve the use of the SII for listeners with CI. Future studies are needed to improve our CI-corrected SII model by considering additional predictive factors.
C1 [Lee, Sungmin] Univ Texas Dallas, Erik Jonsson Sch Engn & Comp Sci, Richardson, TX 75083 USA.
   [Mendel, Lisa Lucks; Bidelman, Gavin M.] Univ Memphis, Sch Commun Sci & Disorders, Memphis, TN 38152 USA.
   [Bidelman, Gavin M.] Univ Memphis, Inst Intelligent Syst, Memphis, TN 38152 USA.
   [Bidelman, Gavin M.] Univ Tennessee, Hlth Sci Ctr, Dept Anat & Neurobiol, Knoxville, TN 37996 USA.
RP Lee, S (corresponding author), Univ Texas Dallas, Erik Jonsson Sch Engn & Comp Sci, Richardson, TX 75083 USA.
EM Sung.Lee@utdallas.edu
FU American Academy of Audiology/American Academy of Audiology Foundation
   Research Grant in Hearing & Balance Program; National Institute on
   Deafness and Other Communication Disorders Award [R01DC016267]; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01DC016267, R01DC016267, R01DC016267] Funding Source: NIH
   RePORTER
FX This study was supported by the American Academy of Audiology/American
   Academy of Audiology Foundation Research Grant in Hearing & Balance
   Program (S. L.) and National Institute on Deafness and Other
   Communication Disorders Award R01DC016267 (G. M. B.). This study is a
   part of the first author's PhD dissertation. We would like to thank all
   the dissertation committee members, Eugene Buder and George Relyea, who
   contributed to discussing some of the issues raised in this study.
CR American National Standards Institute (ANSI), 1999, S311999R2013 ANSI
   [Anonymous], 1997, S351997 ANSI
   Aronoff JM, 2013, J ACOUST SOC AM, V134, pEL217, DOI 10.1121/1.4813802
   AuBuchon AM, 2015, EAR HEARING, V36, P733, DOI 10.1097/AUD.0000000000000189
   Baddeley A., 1974, PSYCHOL LEARN MOTIV, V8, P47, DOI [10.1016/S0079-7421(08)60452-1, DOI 10.1016/S0079-7421(08)60452-1]
   Baddeley Alan, 1993, P11
   BENTLER RA, 1989, EAR HEARING, V10, P58, DOI 10.1097/00003446-198902000-00010
   Bidelman GM, 2017, J NEUROSCI, V37, P3610, DOI 10.1523/JNEUROSCI.3700-16.2017
   Bidelman GM, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01498
   Bidelman GM, 2014, NEUROBIOL AGING, V35, P2526, DOI 10.1016/j.neurobiolaging.2014.05.006
   Blamey P, 1996, Audiol Neurootol, V1, P293
   Bosen AK, 2016, J ACOUST SOC AM, V140, P3718, DOI 10.1121/1.4967298
   Burkholder R. A., 2006, ADV SPOKEN LANGUAGE, P328
   Bush L. C., 2016, LIST EQUIVALENCY AZB, P419
   Ching TYC, 1998, J ACOUST SOC AM, V103, P1128, DOI 10.1121/1.421224
   Cleary M, 2001, EAR HEARING, V22, P395, DOI 10.1097/00003446-200110000-00004
   Cohen MA, 2009, P NATL ACAD SCI USA, V106, P6008, DOI 10.1073/pnas.0811884106
   Collison EA, 2004, J SPEECH LANG HEAR R, V47, P496, DOI 10.1044/1092-4388(2004/039)
   Daya H, 1999, INT J PEDIATR OTORHI, V49, P135, DOI 10.1016/S0165-5876(99)00112-3
   Draine S., 1998, INQUISIT COMPUTER SO
   Firszt JB, 2004, EAR HEARING, V25, P375, DOI 10.1097/01.AUD.0000134552.22205.EE
   FLETCHER H, 1950, J ACOUST SOC AM, V22, P89, DOI 10.1121/1.1906605
   FLORENTINE M, 1984, J SPEECH HEAR RES, V27, P449, DOI 10.1044/jshr.2703.449
   FRENCH NR, 1947, J ACOUST SOC AM, V19, P90, DOI 10.1121/1.1916407
   Fu QJ, 2000, J ACOUST SOC AM, V107, P589, DOI 10.1121/1.428325
   Geers AE, 2013, OTOL NEUROTOL, V34, P396, DOI 10.1097/MAO.0b013e318277a0cb
   Goldsworthy RL, 2013, TRENDS AMPLIF, V17, P27, DOI 10.1177/1084713813477244
   Gordon KA, 2000, INT J PEDIATR OTORHI, V56, P101, DOI 10.1016/S0165-5876(00)00400-6
   Green K M J, 2007, Cochlear Implants Int, V8, P1, DOI 10.1002/cii.326
   Henry BA, 2005, J ACOUST SOC AM, V118, P1111, DOI 10.1121/1.1944567
   Henry BA, 2003, J ACOUST SOC AM, V113, P2861, DOI 10.1121/1.1561900
   Hilton E., 2001, IU S BEND UNDERGRADU, V4, P47
   Holden LK, 2013, EAR HEARING, V34, P342, DOI 10.1097/AUD.0b013e3182741aa7
   Kemtes KA, 2008, J CLIN EXP NEUROPSYC, V30, P661, DOI 10.1080/13803390701641414
   Kiefer J, 1998, AUDIOLOGY, V37, P382
   Kirby AE, 2010, J NEUROPHYSIOL, V103, P531, DOI 10.1152/jn.00794.2009
   Kronenberger WG, 2013, J PEDIATR PSYCHOL, V38, P902, DOI 10.1093/jpepsy/jst034
   Lawler M, 2017, EAR HEARING, V38, P760, DOI 10.1097/AUD.0000000000000496
   Lee S, 2017, J ACOUST SOC AM, V142, P3416, DOI 10.1121/1.5014056
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Litvak LM, 2007, J ACOUST SOC AM, V122, P982, DOI 10.1121/1.2749413
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   LUDVIGSEN C, 1987, J ACOUST SOC AM, V82, P1162, DOI 10.1121/1.395252
   Macherey O, 2014, CURR BIOL, V24, pR878, DOI 10.1016/j.cub.2014.06.053
   Mendel L. L, 2016, CLIN ARICHIVES COMMU, V1, P87
   Moberly AC, 2017, J SPEECH LANG HEAR R, V60, P1046, DOI 10.1044/2016_JSLHR-H-16-0119
   Moberly AC, 2014, J SPEECH LANG HEAR R, V57, P566, DOI 10.1044/2014_JSLHR-H-12-0323
   Nie K, 2006, EAR HEARING, V27, P208, DOI 10.1097/01.aud.0000202312.31837.25
   Oxenham AJ, 2004, P NATL ACAD SCI USA, V101, P1421, DOI 10.1073/pnas.0306958101
   PAVLOVIC CV, 1987, J ACOUST SOC AM, V82, P413, DOI 10.1121/1.395442
   PAVLOVIC CV, 1986, J ACOUST SOC AM, V80, P50, DOI 10.1121/1.394082
   PENNEY CG, 1989, MEM COGNITION, V17, P398, DOI 10.3758/BF03202613
   Pisoni David B, 2011, Ear Hear, V32, p60S, DOI 10.1097/AUD.0b013e3181ffd58e
   Pisoni DB, 2003, EAR HEARING, V24, p106S, DOI 10.1097/01.AUD.0000051692.05140.8E
   Pisoni DB, 1999, VOLTA REV, V101, P111
   Pisoni DB, 2000, ANN OTO RHINOL LARYN, V109, P92
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   SHANNON RV, 1989, J ACOUST SOC AM, V85, P2587, DOI 10.1121/1.397753
   Sherbecoe Robert L., 2003, Ear and Hearing, V24, P71, DOI 10.1097/01.AUD.0000052748.94309.8A
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   Spahr AJ, 2005, EAR HEARING, V26, p2S, DOI 10.1097/00003446-200508001-00002
   Studebaker G A, 1999, J Am Acad Audiol, V10, P355
   Studebaker G A, 1997, J Am Acad Audiol, V8, P150
   Svirsky MA, 2004, AUDIOL NEURO-OTOL, V9, P224, DOI 10.1159/000078392
   Tong Y. C., 1998, J ACOUST SOC AM, V84, P951
   Utrup A, 2016, J ED PED REHAB AUDIO, V22, P1
   van Dijk JE, 1999, AUDIOLOGY, V38, P109
   Vandali AE, 2000, EAR HEARING, V21, P608, DOI 10.1097/00003446-200012000-00008
   Wechsler D., 2008, WECHSLER ADULT INTEL, V4th ed
   Winn MB, 2016, EAR HEARING, V37, pE377, DOI 10.1097/AUD.0000000000000328
   Won JH, 2007, JARO-J ASSOC RES OTO, V8, P384, DOI 10.1007/s10162-007-0085-8
   Xu L, 2007, J ACOUST SOC AM, V122, P1758, DOI 10.1121/1.2767000
NR 72
TC 3
Z9 3
U1 1
U2 5
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD MAY
PY 2019
VL 62
IS 5
BP 1517
EP 1531
DI 10.1044/2018_JSLHR-H-18-0303
PG 15
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA HZ9UI
UT WOS:000469202500024
PM 31058575
OA Green Published
DA 2021-02-24
ER

PT J
AU Liberman, PHP
   Goffi-Gomez, MVS
   Schultz, C
   Jacob, PL
   de Paula, CAA
   Sartorato, EL
   Torrezan, GT
   Ferreira, EN
   Carraro, DM
AF Liberman, P. H. P.
   Goffi-Gomez, M. V. S.
   Schultz, C.
   Jacob, P. L.
   de Paula, C. A. A.
   Sartorato, E. L.
   Torrezan, G. T.
   Ferreira, E. N.
   Carraro, D. M.
TI Contribution of the GSTP1 c.313A > G variant to hearing loss risk in
   patients exposed to platin chemotherapy during childhood
SO CLINICAL & TRANSLATIONAL ONCOLOGY
LA English
DT Article
DE Hearing loss; Cancer; Ototoxicity; Cisplatin; Carboplatin; GSTP1
ID INDIVIDUAL SENSITIVITY; GENETIC POLYMORPHISMS; INDUCED OTOTOXICITY;
   MITOCHONDRIAL-DNA; CHILDREN; CANCER; SUSCEPTIBILITY; ASSOCIATION;
   CARBOPLATIN; PROTECTION
AB Background and aimOtotoxicity is a potential adverse effect of chemotherapy with platin drugs, such as cisplatin and carboplatin, in children. Hearing loss (HL) affecting frequencies below 4kHz can compromise speech perception. The aim of this study was to investigate whether genetic variants previously implicated in ototoxicity are associated with HL overall and HL below 4kHz in pediatric oncology patients treated with cisplatin or carboplatin.Materials and methodsPatients given cisplatin or carboplatin for a pediatric cancer at least 5years prior to the start of the study were enrolled. The patients underwent comprehensive audiological evaluations and genotyping to detect the presence of the GJB2 c.35delG, GSTP1 c.313A>G, and MT-RNR1m.1555A>G polymorphisms.ResultsHL was identified in 31/61 patients (50.8%), including 28/42 treated with cisplatin (66.6%) and 3/19 treated with carboplatin (15.8%). HL was associated with higher mean doses of cisplatin (p=.002) and carboplatin (p=.010). The c.313A>G variant of GSTP1 (heterozygous or homozygous) was detected in 31/61 patients (50.8%). An association between this variant allele and HL involving frequencies 4kHz was identified (p=.020; 10-fold vs. non-carriers). No associations with HL were observed for GJB2 or MT-RNR1 gene variants.ConclusionThe GSTP1 c.313A>G variant may increase the risk of low-frequency HL in pediatric oncology patients treated with cisplatin or carboplatin chemotherapy.
C1 [Liberman, P. H. P.; Goffi-Gomez, M. V. S.; Schultz, C.] AC Camargo Canc Ctr, Audiol Dept, R Antonio Prudente 211, BR-01509900 Sao Paulo, Brazil.
   [Jacob, P. L.; Sartorato, E. L.] State Univ Campinas UNICAMP, CBMEG, Mol Biol & Genet Engn Ctr, Human Mol Genet Lab, Campinas, SP, Brazil.
   [de Paula, C. A. A.; Torrezan, G. T.; Ferreira, E. N.; Carraro, D. M.] AC Camargo Canc Ctr, Int Res Ctr CIPE, Genom & Mol Biol Lab, Sao Paulo, Brazil.
RP Goffi-Gomez, MVS (corresponding author), AC Camargo Canc Ctr, Audiol Dept, R Antonio Prudente 211, BR-01509900 Sao Paulo, Brazil.
EM goffigomez@uol.com.br
RI Ferreira, Elisa N/A-6485-2011; carraro, dirce/C-9179-2009; Torrezan,
   Giovana Tardin/P-9639-2019; TORREZAN, GIOVANA/AAB-9992-2020
OI Ferreira, Elisa N/0000-0001-7809-7349; carraro,
   dirce/0000-0001-5667-1418; Torrezan, Giovana Tardin/0000-0002-8659-5329;
   Goffi, Valeria/0000-0002-4440-7692
CR Brock PR, 2012, J CLIN ONCOL, V30, P2408, DOI 10.1200/JCO.2011.39.1110
   BROCK PR, 1992, BRIT J CANCER, V66, pS36
   ELBARBARY A, 1993, HEARING RES, V71, P80
   Estivill X, 1998, AM J HUM GENET, V62, P27, DOI 10.1086/301676
   Friedman TB, 2003, ANNU REV GENOM HUM G, V4, P341, DOI 10.1146/annurev.genom.4.070802.110347
   Guan MX, 2000, HUM MOL GENET, V9, P1787, DOI 10.1093/hmg/9.12.1787
   Harries LW, 1997, CARCINOGENESIS, V18, P641, DOI 10.1093/carcin/18.4.641
   Hu X, 1998, CANCER RES, V58, P5340
   Hyppolito Miguel A., 2005, Medicina (Ribeirao Preto), V38, P279
   Iwasaki S, 2000, ORL J OTO-RHINO-LARY, V62, P100, DOI 10.1159/000027725
   Jehanne M, 2009, PEDIATR BLOOD CANCER, V52, P637, DOI 10.1002/pbc.21898
   Jeronimo C, 2002, CANCER EPIDEM BIOMAR, V11, P445
   Knoll C, 2006, LARYNGOSCOPE, V116, P72, DOI 10.1097/01.mlg.0000185596.20207.d2
   Langer T, 2013, TRENDS PHARMACOL SCI, V34, P458, DOI 10.1016/j.tips.2013.05.006
   Mukherjea D, 2011, PHARMACOGENOMICS, V12, P1039, DOI [10.2217/pgs.11.48, 10.2217/PGS.11.48]
   Oldenburg J, 2007, J CLIN ONCOL, V25, P708, DOI 10.1200/JCO.2006.08.9599
   Liberman PHP, 2012, INT ARCH OTORHINOLAR, V16, P26, DOI 10.7162/S1809-48722012000100003
   Liberman PHP, 2013, PEDIATR BLOOD CANCER, V60, P1709, DOI 10.1002/pbc.24560
   Peleva E, 2014, PEDIATR BLOOD CANCER, V61, P2012, DOI 10.1002/pbc.25123
   Peters U, 2003, ANTICANCER RES, V23, P1249
   Peters U, 2000, ANTI-CANCER DRUG, V11, P639, DOI 10.1097/00001813-200009000-00007
   Qaddoumi I, 2012, J CLIN ONCOL, V30, P1034, DOI 10.1200/JCO.2011.36.9744
   Rednam S, 2013, PEDIATR BLOOD CANCER, V60, P593, DOI 10.1002/pbc.24366
   Rybak LP, 2007, HEARING RES, V226, P157, DOI 10.1016/j.heares.2006.09.015
   Rybak LP, 2009, TOHOKU J EXP MED, V219, P177, DOI 10.1620/tjem.219.177
   Sabatini LM, 2016, J MOL DIAGN, V18, P319, DOI 10.1016/j.jmoldx.2015.11.010
   Schultz C, 2010, ARCH OTOLARYNGOL, V136, P1065, DOI 10.1001/archoto.2010.180
   Skinner R, 2004, EUR J CANCER, V40, P2352, DOI 10.1016/j.ejca.2004.08.002
   Yancey A, 2012, PEDIATR BLOOD CANCER, V59, P144, DOI 10.1002/pbc.24138
NR 29
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER INTERNATIONAL PUBLISHING AG
PI CHAM
PA GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND
SN 1699-048X
EI 1699-3055
J9 CLIN TRANSL ONCOL
JI Clin. Transl. Oncol.
PD MAY
PY 2019
VL 21
IS 5
BP 630
EP 635
DI 10.1007/s12094-018-1964-7
PG 6
WC Oncology
SC Oncology
GA HY4ET
UT WOS:000468081500010
PM 30361796
DA 2021-02-24
ER

PT J
AU Murphy, GL
AF Murphy, Gregory L.
TI On Fodor's First Law of the Nonexistence of Cognitive Science
SO COGNITIVE SCIENCE
LA English
DT Article
DE Cognitive science; Jerry Fodor; Higher-level cognition; Philosophy of
   science; Concepts
ID CATEGORY; SIMILARITY; RETRIEVAL; KNOWLEDGE; FAILURES; MODEL; TIME
AB In his enormously influential The Modularity of Mind, Jerry Fodor (1983) proposed that the mind was divided into input modules and central processes. Much subsequent research focused on the modules and whether processes like speech perception or spatial vision are truly modular. Much less attention has been given to Fodor's writing on the central processes, what would today be called higher-level cognition. In "Fodor's First Law of the Nonexistence of Cognitive Science," he argued that central processes are "bad candidates for scientific study" and would resist attempts at empirical analysis. This essay evaluates his argument for this remarkable claim, concluding that although central processes may well be "messier" than input modules, this does not mean that they cannot be studied and understood. The article briefly reviews the scientific progress made in understanding central processes in the 35 years since the book was published, showing that Fodor's prediction is clearly falsified by massive advances in topics like decision making and analogy. The essay concludes that Fodor's Law was not based on a clear argument for why the complexities of central systems could not be studied but was likely based on intuitions and preferences that were common in psychology at the time.
C1 [Murphy, Gregory L.] NYU, Dept Psychol, 6 Washington Pl,8th Floor, New York, NY 10003 USA.
RP Murphy, GL (corresponding author), NYU, Dept Psychol, 6 Washington Pl,8th Floor, New York, NY 10003 USA.
EM gregory.murphy@nyu.edu
CR Adler JE, 2008, REASONING: STUDIES OF HUMAN INFERENCE AND ITS FOUNDATIONS, P1
   Anderson J. R., 2007, CAN HUMAN MIND OCCUR
   Anderson JR., 1976, LANGUAGE MEMORY THOU
   Ashby FG, 2016, J EXP PSYCHOL LEARN, V42, P1731, DOI 10.1037/xlm0000277
   Baron J., 2008, THINKING DECIDING
   Betsch C, 2015, POLICY INSIGHTS BEHA, V2, P61, DOI DOI 10.1177/2372732215600716
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   COLLINS AM, 1969, J VERB LEARN VERB BE, V8, P240, DOI 10.1016/S0022-5371(69)80069-1
   Damasio A.R., 1994, DESCARTES ERROR EMOT
   Daw ND, 2011, NEURON, V69, P1204, DOI 10.1016/j.neuron.2011.02.027
   Daw ND, 2014, NEUROECONOMICS, P283, DOI DOI 10.1016/B978-0-12-416008-8.00015-2
   Dunbar K, 2001, ANALOGICAL MIND, P313
   Duncker K, 1945, PSYCHOL MONOGRAPHS, V58, P1, DOI [10.1037/h0093599, DOI 10.1037/H0093599]
   Dunsmoor JE, 2015, NEURON, V88, P47, DOI 10.1016/j.neuron.2015.09.028
   FALKENHAINER B, 1989, ARTIF INTELL, V41, P1, DOI 10.1016/0004-3702(89)90077-5
   Feeney A, 2007, INDUCTIVE REASONING: EXPERIMENTAL, DEVELOPMENTAL, AND COMPUTATIONAL APPROACHES, P1
   Feigenson L, 2004, TRENDS COGN SCI, V8, P307, DOI 10.1016/j.tics.2004.05.002
   Ferreira F, 2003, COGNITIVE PSYCHOL, V47, P164, DOI 10.1016/S0010-0285(03)00005-7
   Ferreira F., 2017, CONCEPTS MODULES LAN, P63
   Fodor J., 1975, LANGUAGE THOUGHT
   Fodor J., 1983, MODULARITY MIND
   Fodor J.A., 1981, REPRESENTATIONS PHIL
   Fodor J.A., 1998, CONCEPTS COGNITIVE S
   FODOR JA, 1985, BEHAV BRAIN SCI, V8, P1, DOI 10.1017/S0140525X0001921X
   Fodor JA., 1974, PSYCHOL LANGUAGE INT
   Frederick S, 2002, J ECON LIT, V40, P351, DOI 10.1257/002205102320161311
   Garrett M. F., 2017, CONCEPTS MODULES LAN, P41
   Gentner D, 2001, ANALOGICAL MIND PERS
   GICK ML, 1980, COGNITIVE PSYCHOL, V12, P306, DOI 10.1016/0010-0285(80)90013-4
   Glimcher PW, 2004, SCIENCE, V306, P447, DOI 10.1126/science.1102566
   Henrich J, 2010, BEHAV BRAIN SCI, V33, P111, DOI 10.1017/S0140525X10000725
   Hertwig R, 2004, PSYCHOL SCI, V15, P534, DOI 10.1111/j.0956-7976.2004.00715.x
   Holyoak K. J., 2005, CAMBRIDGE HDB THINKI, P117
   HOLYOAK KJ, 1989, COGNITIVE SCI, V13, P295, DOI 10.1207/s15516709cog1303_1
   HOLYOAK KJ, 1987, MEM COGNITION, V15, P332, DOI 10.3758/BF03197035
   Hummel JE, 1997, PSYCHOL REV, V104, P427, DOI 10.1037/0033-295X.104.3.427
   Jackendoff R, 2002, LANGUAGE, V78, P164, DOI 10.1353/lan.2002.0024
   Kahneman D., 2011, THINKING FAST SLOW
   Kaplan AS, 2000, J EXP PSYCHOL LEARN, V26, P829, DOI 10.1037//0278-7393.26.4.829
   Lewis GA, 2015, NEUROPSYCHOLOGIA, V68, P176, DOI 10.1016/j.neuropsychologia.2015.01.011
   Lin EL, 2001, J EXP PSYCHOL GEN, V130, P3, DOI 10.1037/0096-3445.130.1.3
   Lombrozo T, 2006, TRENDS COGN SCI, V10, P464, DOI 10.1016/j.tics.2006.08.004
   Love BC, 2004, PSYCHOL REV, V111, P309, DOI 10.1037/0033-295X.111.2.309
   Maes E, 2016, J EXP PSYCHOL GEN, V145, pE49, DOI 10.1037/xge0000200
   MALT BC, 1989, J EXP PSYCHOL LEARN, V15, P539, DOI 10.1037/0278-7393.15.4.539
   Malt BC, 1999, J MEM LANG, V40, P230, DOI 10.1006/jmla.1998.2593
   Mani A, 2013, SCIENCE, V341, P976, DOI 10.1126/science.1238041
   Melissa Knoll, 2015, BEHAV SCI POLICY, V1, P53
   Miller GF, 1998, TRENDS COGN SCI, V2, P190, DOI 10.1016/S1364-6613(98)01169-3
   MILLER JL, 1989, PERCEPT PSYCHOPHYS, V46, P505, DOI 10.3758/BF03208147
   Murphy G. L., 2007, COGNITIVE BASIS POLY, P47
   Murphy G. L., 2002, BIG BOOK CONCEPTS
   Newell A., 1990, UNIFIED THEORIES COG
   Pardo J. S., 2006, HDB PSYCHOLINGUISTIC, P201
   Patterson K, 2007, NAT REV NEUROSCI, V8, P976, DOI 10.1038/nrn2277
   Ramiro C, 2018, P NATL ACAD SCI USA, V115, P2323, DOI 10.1073/pnas.1714730115
   Rogers TT, 2004, PSYCHOL REV, V111, P205, DOI 10.1037/0033-295X.111.1.205
   Rosch E.H., 1973, COGNITIVE DEV ACQUIS, P111, DOI DOI 10.1016/B978-0-12-505850-6.50010-4
   ROSS BH, 1984, COGNITIVE PSYCHOL, V16, P371, DOI 10.1016/0010-0285(84)90014-8
   Rumelhart D. E., 1981, 100 CHIP
   Rumelhart D. E., 1981, COGNITIVE SKILLS THE, P335
   Rumelhart DE., 2017, THEORETICAL ISSUES R, P33, DOI DOI 10.4324/9781315107493-4
   Schank R. C., 1977, SCRIPTS PLANS GOALS
   Shah AK, 2012, SCIENCE, V338, P682, DOI 10.1126/science.1222426
   Smith E. E., 1974, PSYCHOL LEARN MOTIV, V8, P1
   Smith JD, 1997, J EXP PSYCHOL LEARN, V23, P659, DOI 10.1037/0278-7393.23.3.659
   Soto FA, 2018, J EXP PSYCHOL GEN, V147, P597, DOI 10.1037/xge0000341
   Spalding TL, 1996, J EXP PSYCHOL LEARN, V22, P525, DOI 10.1037/0278-7393.22.2.525
   Steyvers M, 2009, J MATH PSYCHOL, V53, P168, DOI 10.1016/j.jmp.2008.11.002
   Swabey P., 2015, QUANTUM SECURITY
   THAGARD P, 1990, ARTIF INTELL, V46, P259, DOI 10.1016/0004-3702(90)90018-U
   Urcelay GP, 2017, J EXP PSYCHOL-ANIM L, V43, P303, DOI 10.1037/xan0000149
   Williams JJ, 2010, COGNITIVE SCI, V34, P776, DOI 10.1111/j.1551-6709.2010.01113.x
   Woodworth RS, 1954, EXPT PSYCHOL
NR 74
TC 2
Z9 2
U1 0
U2 5
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0364-0213
EI 1551-6709
J9 COGNITIVE SCI
JI Cogn. Sci.
PD MAY
PY 2019
VL 43
IS 5
AR e12735
DI 10.1111/cogs.12735
PG 24
WC Psychology, Experimental
SC Psychology
GA HY2QL
UT WOS:000467967800003
PM 31087591
OA Bronze
DA 2021-02-24
ER

PT J
AU Goswami, U
AF Goswami, Usha
TI A neural oscillations perspective on phonological development and
   phonological processing in developmental dyslexia
SO LANGUAGE AND LINGUISTICS COMPASS
LA English
DT Article
ID AMPLITUDE-MODULATION; SPEECH-PERCEPTION; YOUNG-CHILDREN; RISE-TIME;
   ENVELOPE; BRAIN; ENTRAINMENT; LANGUAGE; STRESS; ADULTS
AB Children's ability to reflect upon and manipulate the sounds in words ("phonological awareness") develops as part of natural language acquisition, supports reading acquisition, and develops further as reading and spelling are learned. Children with developmental dyslexia typically have impairments in phonological awareness. Many developmental factors contribute to individual differences in phonological development. One important source of individual differences may be the child's sensory/neural processing of the speech signal from an amplitude modulation (energy or intensity variation) perspective, which may affect the quality of the sensory/neural representations ("phonological representations") that support phonological awareness. During speech encoding, brain electrical rhythms (oscillations, rhythmic variations in neural excitability) recalibrate their temporal activity to be in time with rhythmic energy variations in the speech signal. The accuracy of this neural alignment or "entrainment" process is related to speech intelligibility. Recent neural studies demonstrate atypical oscillatory function at slower rates in children with developmental dyslexia. Potential relations with the development of phonological awareness by children with dyslexia are discussed.
C1 [Goswami, Usha] Univ Cambridge, Ctr Neurosci Educ, Dept Psychol, Cambridge, England.
RP Goswami, U (corresponding author), Dept Psychol, Downing St, Cambridge CB2 3EB, England.
EM ucg10@cam.ac.uk
FU Fondation Botnar [6064]; Medical Research CouncilUK Research &
   Innovation (UKRI)Medical Research Council UK (MRC)European Commission
   [G0400574, G0902375]
FX Fondation Botnar, Grant/Award Number: 6064; Medical Research Council,
   Grant/Award Numbers: G0400574 and G0902375
CR Araujo J, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0205224
   Beattie RL, 2013, J LEARN DISABIL-US, V46, P200, DOI 10.1177/0022219412449421
   Bhide A, 2013, MIND BRAIN EDUC, V7, P113, DOI 10.1111/mbe.12016
   BRADLEY L, 1978, NATURE, V271, P746, DOI 10.1038/271746a0
   BRADLEY L, 1983, NATURE, V301, P419, DOI 10.1038/301419a0
   Castro-Caldas A, 1998, BRAIN, V121, P1053, DOI 10.1093/brain/121.6.1053
   Chandrasekaran B, 2009, NEURON, V64, P311, DOI 10.1016/j.neuron.2009.10.006
   Corriveau K, 2007, J SPEECH LANG HEAR R, V50, P647, DOI 10.1044/1092-4388(2007/046)
   Cumming R, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00972
   Cutini S, 2016, NEUROIMAGE, V143, P40, DOI 10.1016/j.neuroimage.2016.08.012
   DAUER RM, 1983, J PHONETICS, V11, P51, DOI 10.1016/S0095-4470(19)30776-4
   Di Liberto GM, 2018, NEUROIMAGE, V175, P70, DOI 10.1016/j.neuroimage.2018.03.072
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Ding N, 2017, NEUROSCI BIOBEHAV R, V81, P181, DOI 10.1016/j.neubiorev.2017.02.011
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Edwards E, 2013, HEARING RES, V305, P113, DOI 10.1016/j.heares.2013.08.017
   EHRI LC, 1980, APPL PSYCHOLINGUIST, V1, P371, DOI 10.1017/S0142716400009802
   Flanagan S, 2018, J ACOUST SOC AM, V143, P1366, DOI 10.1121/1.5026239
   Flaugnacco E, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00392
   Ghitza O, 2013, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00340
   Ghitza O, 2009, PHONETICA, V66, P113, DOI 10.1159/000208934
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Goswami U, 2002, P NATL ACAD SCI USA, V99, P10911, DOI 10.1073/pnas.122368599
   Goswami U., 1990, PHONOLOGICAL SKILLS
   Goswami U, 2015, NAT REV NEUROSCI, V16, P43, DOI 10.1038/nrn3836
   Goswami U, 2013, J MEM LANG, V69, P1, DOI 10.1016/j.jml.2013.03.001
   Goswami U, 2011, NEUROIMAGE, V57, P651, DOI 10.1016/j.neuroimage.2010.08.072
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Goswami U, 2011, DEVELOPMENTAL SCI, V14, P34, DOI 10.1111/j.1467-7687.2010.00955.x
   Goswami U, 2011, J COGNITIVE NEUROSCI, V23, P325, DOI 10.1162/jocn.2010.21453
   Greenberg S., 2006, LISTENING SPEECH AUD, P411
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Hamalainen JA, 2009, APPL PSYCHOLINGUIST, V30, P511, DOI 10.1017/S0142716409090250
   Hamalainen JA, 2012, NEUROIMAGE, V59, P2952, DOI 10.1016/j.neuroimage.2011.09.075
   Hulme C, 2013, CHILD DEV PERSPECT, V7, P1, DOI 10.1111/cdep.12005
   Kalashnikova M, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12487
   Lallier M, 2017, CLIN PSYCHOL SCI, V5, P379, DOI 10.1177/2167702616670119
   Lehongre K, 2011, NEURON, V72, P1080, DOI 10.1016/j.neuron.2011.11.002
   Leong V., 2017, OPEN MIND, V1, P78, DOI [10.1162/OPMI_a_00008, DOI 10.1162/OPMI_A_00008]
   Leong V, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12457
   Leong V, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144411
   Leong V, 2014, J ACOUST SOC AM, V136, P366, DOI 10.1121/1.4883366
   Leong V, 2014, HEARING RES, V308, P141, DOI 10.1016/j.heares.2013.07.015
   LIBERMAN IY, 1974, J EXP CHILD PSYCHOL, V18, P201, DOI 10.1016/0022-0965(74)90101-5
   LIBERMAN M, 1977, LINGUIST INQ, V8, P249
   Lizarazu M, 2015, HUM BRAIN MAPP, V36, P4986, DOI 10.1002/hbm.22986
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Megnin-Viggars O, 2013, BRAIN LANG, V124, P165, DOI 10.1016/j.bandl.2012.12.002
   Moelants D, 2002, P 7 INT C MUS PERC C, V7, P580, DOI DOI 10.1044/1059-0889(2002/ER01)
   Molinaro N, 2016, HUM BRAIN MAPP, V37, P2767, DOI 10.1002/hbm.23206
   Muneaux M, 2004, NEUROREPORT, V15, P1255, DOI 10.1097/01.wnr.0000127459.31232.c4
   Poelmans H, 2012, EAR HEARING, V33, P134, DOI 10.1097/AUD.0b013e31822c26b9
   Poelmans H, 2011, RES DEV DISABIL, V32, P2810, DOI 10.1016/j.ridd.2011.05.025
   Poeppel D, 2014, CURR OPIN NEUROBIOL, V28, P142, DOI 10.1016/j.conb.2014.07.005
   Port R, 2007, NEW IDEAS PSYCHOL, V25, P143, DOI 10.1016/j.newideapsych.2007.02.001
   Power AJ, 2016, BRAIN LANG, V160, P1, DOI 10.1016/j.bandl.2016.06.006
   Power AJ, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00777
   Power AJ, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00216
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Read C., 1986, CHILDRENS CREATIVE S
   Richards S, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9020033
   Richards S, 2015, J SPEECH LANG HEAR R, V58, P1292, DOI 10.1044/2015_JSLHR-L-13-0306
   Richlan F, 2013, HUM BRAIN MAPP, V34, P3055, DOI 10.1002/hbm.22127
   Sammler D, 2015, CURR BIOL, V25, P3079, DOI 10.1016/j.cub.2015.10.009
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   Smith AB, 2008, J SPEECH LANG HEAR R, V51, P1300, DOI 10.1044/1092-4388(2008/06-0193)
   Soltesz F, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076608
   Suranyi Z, 2009, READ WRIT, V22, P41, DOI 10.1007/s11145-007-9102-x
   Tallal P, 2004, NAT REV NEUROSCI, V5, P721, DOI 10.1038/nrn1499
   Telkemeyer S, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00062
   Teng XB, 2017, PLOS BIOL, V15, DOI 10.1371/journal.pbio.2000812
   Thomson JM, 2005, MEM COGNITION, V33, P1210, DOI 10.3758/BF03193223
   Trehub S.E., 1998, ADV INFANCY RES, V12, P43
   Vanvooren S, 2014, J NEUROSCI, V34, P1523, DOI 10.1523/JNEUROSCI.3209-13.2014
   Wood C, 2006, J RES READ, V29, P270, DOI 10.1111/j.1467-9817.2006.00308.x
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
   Ziegler JC, 2010, PSYCHOL SCI, V21, P551, DOI 10.1177/0956797610363406
NR 77
TC 7
Z9 7
U1 1
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1749-818X
J9 LANG LINGUIST COMPAS
JI Lang. Linguist. Compass
PD MAY
PY 2019
VL 13
IS 5
AR e12328
DI 10.1111/lnc3.12328
PG 21
WC Language & Linguistics
SC Linguistics
GA HY7KE
UT WOS:000468312900001
DA 2021-02-24
ER

PT J
AU Li, Y
   Somlak, T
AF Li, Ying
   Somlak, Taylor
TI The effects of articulatory gestures on L2 pronunciation learning: A
   classroom-based study
SO LANGUAGE TEACHING RESEARCH
LA English
DT Article
DE articulatory gestures; audio-visual; classroom based; L2 pronunciation
ID TRAINING JAPANESE LISTENERS; SPEECH-PERCEPTION; MOTOR THEORY; VISUAL
   CUES; LANGUAGE; ENGLISH; DISCRIMINATION; ACCENT
AB Research on second-language (L2) speech acquisition suggests that audio-visual aids could be effective in helping learners acquire difficult L2 speech sounds (Li, 2016a). However, most previous studies have been restricted to laboratory settings rather than the classroom environment. The present study, therefore, was designed to fill this knowledge gap by analysing the effectiveness of audio-visual aids, particularly articulatory gestures, in teaching L2 speech sounds in actual classrooms. The participants were students from two classes of non-English majors who had severe difficulties with the differentiation of /theta/-/s/ and /o/-/z/. 'Read-aloud' tasks were employed for pronunciation tests. The baseline data of the students' pronunciation of the two contrasts was collected with a pre-test, and the intuitive-imitative approach was adopted for teaching. Specifically, the students were exposed to seven audio- or audio-visually recorded poems (one poem per week over the course of seven weeks) containing the target contrasts. The students in Class 1 were taught with the audio-recordings without images of the speaker's face being displayed; in contrast, students in Class 2 were taught using audio-visual recordings, which allowed them to observe the speakers' articulatory gestures of /theta/-/s/ and /o/-/z/. To detect the teaching effect, a post-test was carried out after the teaching programme was completed. A delayed post-test was conducted one month after the post-test. Comparisons with the respective pre-test results indicated that students in Class 2 had a significant improvement in the pronunciation of the target contrasts in the post-test, whereas those in Class 1 did not. In the delayed post-test, neither class showed any significant difference in the pronunciation performance in comparison with the post-test. The findings, therefore, confirmed the effectiveness of exposure to audio-visual aids in teaching L2 pronunciation.
C1 [Li, Ying] Southwest Univ Polit Sci & Law, Chongqing, Peoples R China.
   [Somlak, Taylor] Chiang Mai Univ, Chiang Mai, Thailand.
RP Li, Y (corresponding author), Southwest Univ Polit Sci & Law, 301 Baosheng Ave, Yubei District 401120, Chongqing Munic, Peoples R China.
EM liying_22@163.com
FU Youth Foundation of Southwest University of Political Science and Law
FX This study was subsidized by 'The Youth Foundation of Southwest
   University of Political Science and Law, 2017'.
CR ASHER JJ, 1981, ANN NY ACAD SCI, V379, P324, DOI 10.1111/j.1749-6632.1981.tb42019.x
   Bada E., 2001, READING MATRIX INT O, V1
   BELLBERTI F, 1979, PHONETICA, V36, P373, DOI 10.1159/000259974
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best C. T., 1994, DEV SPEECH PERCEPT, V167, P224
   Best Catherine T., 2007, LANGUAGE EXPERIENCE, V1334
   BEST CT, 1992, J PHONETICS, V20, P305, DOI 10.1016/S0095-4470(19)30637-0
   BEST CT, 1995, ADV INFANCY RES, V9, P217
   Cauldwell R., 2003, 2 SIDES RULE TEACHIN
   Celce-Murcia M., 1996, TEACHING PRONUNCIATI
   De Gelder B. D., 1992, ADV PSYCHOL, P413, DOI 10.1016/S0166-4115(08)61508-3
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege James E., 1991, CROSSCURRENTS 2 LANG, V2, P249, DOI DOI 10.1075/LALD.2.15FLE
   Flege JE, 1995, APPL PSYCHOLINGUIST, V16, P425, DOI 10.1017/S0142716400066029
   FLEGE JE, 1995, LANG SPEECH, V38, P25, DOI 10.1177/002383099503800102
   FLEGE JE, 1992, J ACOUST SOC AM, V92, P128, DOI 10.1121/1.404278
   FOWLER CA, 1981, J SPEECH HEAR RES, V24, P127, DOI 10.1044/jshr.2401.127
   FOWLER CA, 1994, PERCEPT PSYCHOPHYS, V55, P597, DOI 10.3758/BF03211675
   FOWLER CA, 1984, PERCEPT PSYCHOPHYS, V36, P359, DOI 10.3758/BF03202790
   Fowler CA, 1996, J ACOUST SOC AM, V99, P1730, DOI 10.1121/1.415237
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   FOWLER CA, 1994, ENCY LANGUAGE LINGUI, P4199
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Guion SG, 2000, J PHONETICS, V28, P27, DOI 10.1006/jpho.2000.0104
   Hardison DM, 2003, APPL PSYCHOLINGUIST, V24, P495, DOI 10.1017/S0142716403000250
   Hashemian M., 2011, J LANGUAGE TEACHING, V2, P969
   Hawkins S., 1999, ACOUSTICS SPEECH COM, P198
   Hazan V, 2006, J ACOUST SOC AM, V119, P1740, DOI 10.1121/1.2166611
   Hazan V, 2005, SPEECH COMMUN, V47, P360, DOI 10.1016/j.specom.2005.04.007
   Hismanoglu M, 2010, PROCD SOC BEHV, V2, P983, DOI 10.1016/j.sbspro.2010.03.138
   Jamieson D.G., 1992, J SPEECH LANGUAGE PA, V16, P201
   Kenworthy Joanne, 1987, TEACHING ENGLISH PRO
   Krashen S.D., 1985, TESOL Q, V19, P591
   Ladefoged P., 1996, ELEMENTS ACOUSTIC PH
   Lenneberg E. H., 1967, BIOL FDN LANGUAGE
   Li Y., 2016, ASIAN EFL J, V10, P75
   Li Y., 2016, INT J ENGLISH LANGUA, V3, P14
   Liberman AM, 2000, TRENDS COGN SCI, V4, P187, DOI 10.1016/S1364-6613(00)01471-6
   LIBERMAN AM, 1989, SCIENCE, V243, P489, DOI 10.1126/science.2643163
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   LOGAN JS, 1991, J ACOUST SOC AM, V89, P874, DOI 10.1121/1.1894649
   Mortreux S., 2008, 8 INT SEM SPEECH PRO, P145
   Ortega-Llebaria M., 2001, AVSP 2001 INT C AUD
   Picard Marc, 2002, LINGVISTICAE INVESTI, V25, P87
   Piske T, 2001, J PHONETICS, V29, P191, DOI 10.1006/jpho.2001.0134
   PISONI DB, 1982, J EXP PSYCHOL HUMAN, V8, P297, DOI 10.1037/0096-1523.8.2.297
   Prator C., 1985, MANUAL AM ENGLISH PR
   Roohani A., 2013, ASIAN EFL J Q MARCH, V15, P87
   Saito Y., 2016, LANG TEACH RES, V2, P1
   Sekiyama K., 2003, AVSP 2003 INT C AUD
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   TAHTA S, 1981, LANG SPEECH, V24, P265, DOI 10.1177/002383098102400306
   Taylor I., 1976, INTRO PSYCHOLINGUIST
   Tergujeff E., 2012, J LANGUAGE TEACHING, V3, P599
   Trubetzkoy N.S., 1970, GRUNDZUGE PHONOLOGIE
   Wang Y, 2009, J PHONETICS, V37, P344, DOI 10.1016/j.wocn.2009.04.002
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   WILLIAMS GC, 1975, J SPEECH HEAR RES, V18, P401, DOI 10.1044/jshr.1803.401
NR 60
TC 1
Z9 1
U1 6
U2 16
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1362-1688
EI 1477-0954
J9 LANG TEACH RES
JI Lang. Teach Res.
PD MAY
PY 2019
VL 23
IS 3
BP 352
EP 371
DI 10.1177/1362168817730420
PG 20
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA HX1JK
UT WOS:000467146700005
DA 2021-02-24
ER

PT J
AU Lourido, GT
   Evans, BG
AF Lourido, Gisela Tome
   Evans, Bronwen G.
TI The effects of language dominance switch in bilinguals: Galician new
   speakers' speech production and perception
SO BILINGUALISM-LANGUAGE AND COGNITION
LA English
DT Article
DE language dominance switch; speech production; speech perception; new
   speakers
ID TRAINING JAPANESE LISTENERS; 1ST-LANGUAGE VOWEL SYSTEMS; SCOTTISH GAELIC
   SPEAKERS; LEARNING ENGLISH VOWELS; R-VERTICAL-BAR; 1ST; SPANISH; ACCENT;
   NORMALIZATION; PLASTICITY
AB It has long been debated whether speech production and perception remain flexible in adulthood. The current study investigates the effects of language dominance switch in Galician new speakers (neofalantes) who are raised with Spanish as a primary language and learn Galician at an early age in a bilingual environment, but in adolescence, decide to switch to using Galician almost exclusively, for ideological reasons. Results showed that neofalantes pattern with Spanish-dominants in their perception and production of mid-vowel and fricative contrasts, but with Galician-dominants in their realisation of unstressed word-final vowels, a highly salient feature of Galician. These results are taken to suggest that despite early exposure to Galician, high motivation and almost exclusive Galician language use post-switch, there are limitations to what neofalantes can learn in both production and perception, but that the hybrid categories they appear to develop may function as opportunities to mark identity within a particular community.
C1 [Lourido, Gisela Tome] Univ Leeds, Leeds, W Yorkshire, England.
   [Lourido, Gisela Tome; Evans, Bronwen G.] UCL, Speech Hearing & Phonet Sci, London, England.
RP Lourido, GT (corresponding author), Univ Leeds, Sch Languages Cultures & Soc, Room B14,Michael Sadler Bldg, Leeds LS2 9JT, W Yorkshire, England.
EM g.tomelourido@leeds.ac.uk
OI Tome Lourido, Gisela/0000-0002-3456-7334
CR Adank P, 2004, J ACOUST SOC AM, V116, P3099, DOI 10.1121/1.1795335
   Amengual M., 2015, P 18 INT C PHON SCI
   Amengual M, 2016, INT J BILINGUAL, V20, P133, DOI 10.1177/1367006914544988
   Amengual M, 2015, PHONETICA, V72, P207, DOI 10.1159/000439406
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best C.T., 1994, DEV SPEECH PERCEPTIO, P167
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2014, PRAAT DOING PHONETIC
   Bosch L, 2000, EUR J COGN PSYCHOL, V12, P189, DOI 10.1080/09541446.2000.10590222
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P977, DOI 10.3758/BF03206911
   CUTLER A, 1989, NATURE, V340, P229, DOI 10.1038/340229a0
   Drummond R., 2012, J ENGL LINGUIST, VXX, P1
   Drummond R, 2012, LANG VAR CHANGE, V24, P107, DOI 10.1017/S0954394512000026
   Dupoux E, 2010, COGNITION, V114, P266, DOI 10.1016/j.cognition.2009.10.001
   Eckert P, 2008, J SOCIOLING, V12, P453, DOI 10.1111/j.1467-9841.2008.00374.x
   Eckert Penelope, 2000, LINGUISTIC VARIATION
   Evans BG, 2004, J ACOUST SOC AM, V115, P352, DOI 10.1121/1.1635413
   Evans BG, 2007, J ACOUST SOC AM, V121, P3814, DOI 10.1121/1.2722209
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege JE, 2004, STUD SECOND LANG ACQ, V26, P1, DOI 10.1017/S0272263104261010
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   Foulkes P, 2006, J PHONETICS, V34, P409, DOI 10.1016/j.wocn.2005.08.002
   Garcia-Mateo C., 2014, 9 LANG RES EV C REYK
   Gonzalez M., 2008, CADA PALABRA PESABA, P363
   HAZAN VL, 1993, LANG SPEECH, V36, P17, DOI 10.1177/002383099303600102
   IGE [Instituto Galego de Estatistica], 2013, ENQ ESTR FOG CONN US
   IGE [Instituto Galego de Estatistica], 2008, ENQ ESTR FOG CONC US
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Iverson P, 2007, J ACOUST SOC AM, V122, P2842, DOI 10.1121/1.2783198
   Iverson P, 2009, J ACOUST SOC AM, V126, P866, DOI 10.1121/1.3148196
   Jaffe A., 2015, INT J SOCIOL LANG, V231, DOI 10.1515/ijsl-2014-0030
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   Labrana Barrero S., 2014, ESTUDIOS FONETICA EX, V23, P203
   LABRANA BARRERO Sabela, 2009, ESTUDIOS FONETICA EX, V18, P193
   LimeSurvey Project Team / Carsten Schmitz, 2012, LIMESURVEY OP SOURC
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   LOGAN JS, 1991, J ACOUST SOC AM, V89, P874, DOI 10.1121/1.1894649
   Regueira XL, 2012, ESTUD LINGUIST GALEG, V4, P187, DOI 10.3309/1989-578X-XX-XX
   Martinez Celdran Eugenio, 2007, MANUAL FONETICA ESPA
   MCQUEEN JM, 1991, J EXP PSYCHOL HUMAN, V17, P433, DOI 10.1037/0096-1523.17.2.433
   Molinos Castro Rita, 2002, CADERNOS LINGUA, V24, P55
   Mora J. C, 2015, PHONETICS PHONOLOGY, P33, DOI [10.1075/cilt.335.02mor, DOI 10.1075/CILT.335]
   Mora J. C., 2011, ACHIEVEMENTS PERSPEC, P183
   Nance C, 2016, J SOCIOLING, V20, P164, DOI 10.1111/josl.12173
   Nance C, 2015, LANG SOC, V44, P553, DOI 10.1017/S0047404515000408
   O'ROURKE B., 2015, INT J SOCIOL LANG, V231, P147, DOI DOI 10.1515/IJSL-2014-0036
   O'Rourke B, 2013, ESTUD LINGUIST GALEG, V5, P89
   O'Rourke B, 2013, LANG SOC, V42, P287, DOI 10.1017/S0047404513000249
   O'Rourke B, 2011, LANG PROBL LANG PLAN, V35, P139, DOI 10.1075/lplp.35.2.03oro
   O'Rourke Bernadette, 2015, INT J SOCIOL LANG, V231, P1, DOI DOI 10.1515/IJSL-2014-0029
   Pallier C, 2001, PSYCHOL SCI, V12, P445, DOI 10.1111/1467-9280.00383
   Pallier C, 1997, COGNITION, V64, pB9, DOI 10.1016/S0010-0277(97)00030-9
   Pallier C, 2003, CEREB CORTEX, V13, P155, DOI 10.1093/cercor/13.2.155
   Pierce LJ, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms10073
   Pujolar J., 2015, INT J SOCIOL LANG, V2015, P167, DOI [https://doi.org/10.1515/ijsl-2014-0037, DOI 10.1515/IJSL-2014-0037]
   R Core Team, 2016, R LANG ENV STAT COMP
   RAMALLO F., 2013, CONTACTO LINGUAS HIB, P245
   Ramallo F, 2014, DIGITHUM, P98
   Ramon-Casas M, 2009, COGNITIVE PSYCHOL, V59, P96, DOI 10.1016/j.cogpsych.2009.02.002
   Regueira X. L, 1999, CINGUIDOS UNHA ARELA, P855
   Regueira X. L., ROMANCE PHONETICS PH, DOI [10.1093/oso/9780198739401.001.0001, DOI 10.1093/OSO/9780198739401.001.0001]
   Regueira XL, 2007, ACT 7 C INT EST GAL, P859
   Regueira Xose Luis, 1994, CADERNOS LINGUA, V10, P37
   REPP BH, 1981, PERCEPT PSYCHOPHYS, V30, P217, DOI 10.3758/BF03214276
   Rojo Guillermo, 2004, HIST LENGUA ESPANOLA, P1087
   Sebastian-Galles N, 2005, J MEM LANG, V52, P240, DOI 10.1016/j.jml.2004.11.001
   Sebastian-Galles N, 1999, COGNITION, V72, P111, DOI 10.1016/S0010-0277(99)00024-4
   Sebastian-Galles N, 2012, LANG LEARN, V62, P131, DOI 10.1111/j.1467-9922.2012.00709.x
   Simonet M, 2010, J PHONETICS, V38, P663, DOI 10.1016/j.wocn.2010.10.002
   Simonet M, 2011, PHONETICA, V68, P88, DOI 10.1159/000328847
   Ventureyra VAG, 2004, J NEUROLINGUIST, V17, P79, DOI 10.1016/S0911-6044(03)00053-8
   2016, UKRAINSKA ENTOMOFAUN, V7, P1
NR 74
TC 4
Z9 4
U1 0
U2 7
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 1366-7289
EI 1469-1841
J9 BILING-LANG COGN
JI Biling.-Lang. Cogn.
PD MAY
PY 2019
VL 22
IS 3
BP 637
EP 654
DI 10.1017/S1366728918000603
PG 18
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA HW5XC
UT WOS:000466761600013
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Mallikarjun, A
   Shroads, E
   Newman, RS
AF Mallikarjun, Amritha
   Shroads, Emily
   Newman, Rochelle S.
TI The cocktail party effect in the domestic dog (Canis familiaris)
SO ANIMAL COGNITION
LA English
DT Article
DE Dogs; Canines; Speech perception in noise; Hearing in noise
ID BREED DIFFERENCES; INFANTS; DISCRIMINATION; COMPREHENSION; NOISE
AB Like humans, canine companions often find themselves in noisy environments, and are expected to respond to human speech despite potential distractors. Such environments pose particular problems for young children, who have limited linguistic knowledge. Here, we examined whether dogs show similar difficulties. We found that dogs prefer their name to a stress-matched foil in quiet conditions, despite hearing it spoken by a novel talker. They continued to prefer their name in the presence of multitalker human speech babble at signal-to-noise levels as low as 0dB, when their name was the same intensity as the foil. This surpasses the performance of 1-year-old infants, who fail to prefer their name to a foil at 0dB (Newman in Dev Psychol 41(2):352-362, 2005). Overall, we find better performance at name recognition in dogs that were trained to do tasks for humans, like service dogs, search-and-rescue dogs, and explosives detection dogs. These dogs were of several different breeds, and their tasks were widely different from one another. This suggests that their superior performance may be due to generally more training and better attention. In summary, these results demonstrate that dogs can recognize their name even in relatively difficult levels of multitalker babble, and that dogs who work with humans are especially adept at name recognition in comparison with companion dogs. Future studies will explore the effect of different types of background noise on word recognition in dogs.
C1 [Mallikarjun, Amritha; Shroads, Emily; Newman, Rochelle S.] Univ Maryland, College Pk, MD 20742 USA.
RP Mallikarjun, A (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM amritham@umd.edu
RI Newman, Rochelle/AAA-3185-2019
OI Newman, Rochelle/0000-0002-1626-4241; Mallikarjun,
   Amritha/0000-0003-3845-1694
CR Albuquerque N, 2018, BEHAV PROCESS, V146, P42, DOI 10.1016/j.beproc.2017.11.006
   Albuquerque N, 2016, BIOL LETTERS, V12, DOI 10.1098/rsbl.2015.0883
   Andics A, 2016, SCIENCE, V353, P1030, DOI 10.1126/science.aaf3777
   Andics A, 2014, CURR BIOL, V24, P574, DOI 10.1016/j.cub.2014.01.058
   APPLEYARD D, 1972, J AM I PLANNERS, V38, P84, DOI 10.1080/01944367208977410
   Ben-Aderet T, 2017, P ROY SOC B-BIOL SCI, V284, DOI 10.1098/rspb.2016.2429
   Cuaya LV, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149431
   Dorey NR, 2009, BEHAV PROCESS, V81, P409, DOI 10.1016/j.beproc.2009.03.011
   Erickson LC, 2017, CURR DIR PSYCHOL SCI, V26, P451, DOI 10.1177/0963721417709087
   Fugazza C, 2014, ANIM COGN, V17, P237, DOI 10.1007/s10071-013-0656-5
   Kaminski J, 2004, SCIENCE, V304, P1682, DOI 10.1126/science.1097859
   Marshall-Pescini S, 2008, BEHAV PROCESS, V78, P449, DOI 10.1016/j.beproc.2008.02.022
   Marshall-Pescini S, 2009, BEHAV PROCESS, V81, P416, DOI 10.1016/j.beproc.2009.03.015
   McAlexander TP, 2015, ENVIRON HEALTH-GLOB, V14, DOI 10.1186/s12940-015-0006-y
   McKinley J, 2000, ANIM COGN, V3, P13, DOI 10.1007/s100710050046
   Merola I, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047653
   Newman RS, 2009, ATTEN PERCEPT PSYCHO, V71, P822, DOI 10.3758/APP.71.4.822
   Newman RS, 2005, DEV PSYCHOL, V41, P352, DOI 10.1037/0012-1649.41.2.352
   Newman RS, 1996, PERCEPT PSYCHOPHYS, V58, P1145, DOI 10.3758/BF03207548
   NOZZA RJ, 1990, J ACOUST SOC AM, V87, P339, DOI 10.1121/1.399301
   Nozza RJ, 1991, AUDIOLOGY
   Pilley JW, 2011, BEHAV PROCESS, V86, P184, DOI 10.1016/j.beproc.2010.11.007
   Polka L, 2008, INFANCY, V13, P421, DOI 10.1080/15250000802329297
   Racca A, 2010, ANIM COGN, V13, P525, DOI 10.1007/s10071-009-0303-3
   Rhodes G, 2002, PERCEPTION, V31, P315, DOI 10.1068/p3129
   Schmidt JE, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.00373
   Soproni K, 2001, J COMP PSYCHOL, V115, P122, DOI 10.1037//0735-7036.115.2.122
   TREHUB SE, 1981, J SPEECH HEAR RES, V24, P202, DOI 10.1044/jshr.2402.202
   Werner LA, 2007, J COMMUN DISORD, V40, P275, DOI 10.1016/j.jcomdis.2007.03.004
   West RE, 2002, ANIM COGN, V5, P183, DOI 10.1007/s10071-002-0140-0
   Wobber V, 2009, INTERACT STUD, V10, P206, DOI 10.1075/is.10.2.06wob
   WYNN K, 1992, NATURE, V358, P749, DOI 10.1038/358749a0
NR 32
TC 2
Z9 2
U1 2
U2 8
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1435-9448
EI 1435-9456
J9 ANIM COGN
JI Anim. Cogn.
PD MAY
PY 2019
VL 22
IS 3
BP 423
EP 432
DI 10.1007/s10071-019-01255-4
PG 10
WC Behavioral Sciences; Zoology
SC Behavioral Sciences; Zoology
GA HT7BI
UT WOS:000464719200012
PM 30848384
DA 2021-02-24
ER

PT J
AU Kluender, KR
   Stilp, CE
   Lucas, FL
AF Kluender, Keith R.
   Stilp, Christian E.
   Lucas, Fernando Llanos
TI Long-standing problems in speech perception dissolve within an
   information-theoretic perspective
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Psychoacoustics; Perceptual learning
ID COCHLEA-SCALED ENTROPY; SHORT-TERM ADAPTATION; AUDITORY-NERVE;
   VOCAL-TRACT; SPECTRAL CHARACTERISTICS; ANATOMIC DEVELOPMENT; ACOUSTIC
   STRUCTURE; PRECEDING LIQUID; COLOR CONSTANCY; GAIN REDUCTION
AB An information theoretic framework is proposed to have the potential to dissolve (rather than attempt to solve) multiple long-standing problems concerning speech perception. By this view, speech perception can be reframed as a series of processes through which sensitivity to information-that which changes and/or is unpredictable-becomes increasingly sophisticated and shaped by experience. Problems concerning appropriate objects of perception (gestures vs. sounds), rate normalization, variance consequent to articulation, and talker normalization are reframed, or even dissolved, within this information-theoretic framework. Application of discriminative models founded on information theory provides a productive approach to answer questions concerning perception of speech, and perception most broadly.
C1 [Kluender, Keith R.] Purdue Univ, Dept Speech Language & Hearing Sci, 715 Clin Dr, W Lafayette, IN 47907 USA.
   [Stilp, Christian E.] Univ Louisville, Dept Psychol & Brain Sci, 308 Life Sci Bldg, Louisville, KY 40292 USA.
   [Lucas, Fernando Llanos] Univ Pittsburgh, Dept Commun Sci & Disorders, Pittsburgh, PA 15213 USA.
RP Kluender, KR (corresponding author), Purdue Univ, Dept Speech Language & Hearing Sci, 715 Clin Dr, W Lafayette, IN 47907 USA.
EM kkluender@purdue.edu; christian.stilp@louisville.edu; f.llanos@pitt.edu
CR Ainsworth W. A., 1975, AUDITORY ANAL PERCEP, P103
   AINSWORTH WA, 1972, J ACOUST SOC AM, V51, P648, DOI 10.1121/1.1912889
   AINSWORTH WA, 1974, LANG SPEECH, V17, P103, DOI 10.1177/002383097401700201
   Alexander JM, 2010, J ACOUST SOC AM, V128, P3597, DOI 10.1121/1.3500693
   Anderson BL, 2005, NATURE, V434, P79, DOI 10.1038/nature03271
   Antunes FM, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0014071
   Aslin RN, 1998, PSYCHOL SCI, V9, P321, DOI 10.1111/1467-9280.00063
   Assmann Peter, 2004, VVolume 18, P231
   ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663
   Attneave Fred, 1959, APPL INFORM THEORY P
   Aubanel V, 2018, J ACOUST SOC AM, V143, pEL443, DOI 10.1121/1.5041468
   Barlow H, 2001, NETWORK-COMP NEURAL, V12, P241, DOI 10.1088/0954-898X/12/3/301
   Barlow H. B, 1961, SENS COMMUN, P53
   Barlow HB, 1997, PHILOS T R SOC B, V352, P1141, DOI 10.1098/rstb.1997.0097
   Barlow HB, 1959, MECH THOUGHT PROCESS, P535
   Barlow HB, 1989, COMPUTING NEURON, P54
   Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038
   Berkeley G, 1709, PHILOS WORKS INCLUDI
   Blumstein SE, 1998, BEHAV BRAIN SCI, V21, P260, DOI 10.1017/S0140525X98221170
   BOYNTON RM, 1988, ANNU REV PSYCHOL, V39, P69, DOI 10.1146/annurev.ps.39.020188.000441
   BROAD DJ, 1976, PHONETICA, V33, P401, DOI 10.1159/000259830
   Brown CR, 1988, STARTING HUME
   CARDOZO BL, 1967, J ACOUST SOC AM, V42, P1193, DOI 10.1121/1.2144128
   Cathcart EP, 1928, BRIT J PSYCHOL, V19, P343
   CHAMPLIN CA, 1989, J ACOUST SOC AM, V85, P2005, DOI 10.1121/1.397853
   Chechik G, 2006, NEURON, V51, P359, DOI 10.1016/j.neuron.2006.06.030
   Chevillet M, 2011, J NEUROSCI, V31, P9345, DOI 10.1523/JNEUROSCI.1448-11.2011
   Chiba T., 1941, VOWEL ITS NATURE STR
   CHRISTMAN RJ, 1954, AM J PSYCHOL, V67, P484, DOI 10.2307/1417939
   Clifford CWG, 2007, VISION RES, V47, P3125, DOI 10.1016/j.visres.2007.08.023
   Cole R, 1996, INT C AC SPEECH SIGN
   Cutler A, 2012, NATIVE LISTENING LAN
   DELATTRE PC, 1955, J ACOUST SOC AM, V27, P769, DOI 10.1121/1.1908024
   DELGUTTE B, 1980, J ACOUST SOC AM, V68, P843, DOI 10.1121/1.384824
   DELGUTTE B, 1984, J ACOUST SOC AM, V75, P897, DOI 10.1121/1.390599
   Delgutte B., 1996, AUDITORY BASIS SPEEC, P1
   Delgutte B., 1996, HDB PHONETIC SCI, P507
   Delgutte B, 1986, INVARIANCE VARIABILI, P131
   Diehl R. L., 1989, ECOL PSYCHOL, V1, P121, DOI [10.1207/s15326969-co0102_2, DOI 10.1207/S15326969-CO0102_2, DOI 10.1207/s15326969eco0102_2]
   DIEHL RL, 1986, J PHONETICS, V14, P61, DOI 10.1016/S0095-4470(19)30609-6
   Diehl RL, 1990, ADV SPEECH HEARING L
   Evans JL, 2009, J SPEECH LANG HEAR R, V52, P321, DOI 10.1044/1092-4388(2009/07-0189)
   Fant G., 1970, ACOUSTIC THEORY SPEE
   Fant G., 1966, SPEECH TRANSMISSION, V7, P22
   Fiser J, 2002, J EXP PSYCHOL LEARN, V28, P458, DOI 10.1037//0278-7393.28.3.458
   Fletcher H, 1995, SPEECH HEARING COMMU
   Fogerty D, 2012, J ACOUST SOC AM, V132, P1667, DOI 10.1121/1.4739463
   Fogerty D, 2009, J ACOUST SOC AM, V126, P847, DOI 10.1121/1.3159302
   Foster DH, 2006, VISUAL NEUROSCI, V23, P341, DOI 10.1017/S0952523806233455
   FOWLER CA, 1990, PERCEPT PSYCHOPHYS, V48, P559, DOI 10.3758/BF03211602
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   Frazier J.M., 2019, ATTENTION PERCEPTION
   Frost R, 2015, TRENDS COGN SCI, V19, P117, DOI 10.1016/j.tics.2014.12.010
   FURUI S, 1986, J ACOUST SOC AM, V80, P1016, DOI 10.1121/1.393842
   Garofolo J, 1990, PB91505065 NTIS NAT
   Gervain J, 2016, NEUROIMAGE, V133, P144, DOI 10.1016/j.neuroimage.2016.03.001
   Gervain J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096278
   Gibson J., 1979, ECOLOGICAL APPROACH
   Gibson J.J., 1950, PERCEPTION VISUAL WO
   Gibson James J., 1966, SENSES CONSIDERED PE
   GLASBERG BR, 1990, HEARING RES, V47, P103, DOI 10.1016/0378-5955(90)90170-T
   GORDON C, 1992, B AM MATH SOC, V27, P134, DOI 10.1090/S0273-0979-1992-00289-6
   GOTTFRIED TL, 1990, PHONETICA, V47, P155, DOI 10.1159/000261860
   GREEN DM, 1959, J ACOUST SOC AM, V31, P1446, DOI 10.1121/1.1907648
   Hauser MD, 2001, COGNITION, V78, pB53, DOI 10.1016/S0010-0277(00)00132-3
   Hebb D.O., 1949, ORG BEHAV
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hillenbrand JM, 2001, J ACOUST SOC AM, V109, P748, DOI 10.1121/1.1337959
   Holt L. L., 1999, THESIS
   Holt LL, 2000, J ACOUST SOC AM, V108, P710, DOI 10.1121/1.429604
   HOUTGAST T, 1972, J ACOUST SOC AM, V51, P1885, DOI 10.1121/1.1913048
   Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Iskarous K, 2010, J ACOUST SOC AM, V128, P2021, DOI 10.1121/1.3479538
   Jakobson R., 1971, FUNDAMENTALS LANGUAG
   Kaas JH, 2000, P NATL ACAD SCI USA, V97, P11793, DOI 10.1073/pnas.97.22.11793
   Kent R., 1995, HDB CHILD LANGUAGE
   Kent R. D., 1995, J MED SPEECH-LANG PA, V3, P145
   KENT RD, 1979, J SPEECH HEAR DISORD, V44, P513, DOI 10.1044/jshd.4404.513
   Keuroghlian AS, 2007, PROG NEUROBIOL, V82, P109, DOI 10.1016/j.pneurobio.2007.03.005
   Kewley-Port D, 2007, J ACOUST SOC AM, V122, P2365, DOI 10.1121/1.2773986
   Kiefte M., 2000, THESIS
   Kiefte M, 2008, J ACOUST SOC AM, V123, P366, DOI 10.1121/1.2804951
   KINGSTON J, 1994, LANGUAGE, V70, P419, DOI 10.2307/416481
   Kirk EC, 2003, JARO-J ASSOC RES OTO, V4, P445, DOI 10.1007/s10162-002-3013-y
   Kirkham NZ, 2002, COGNITION, V83, pB35, DOI 10.1016/S0010-0277(02)00004-5
   Kluender K. R, 2013, VOWEL INHERENT SPECT, P117
   Kluender K. R., 2006, HDB PSYCHOLINGUISTIC, P153, DOI DOI 10.1016/B978-012369374-7/50007-9
   Kluender KR, 1998, J ACOUST SOC AM, V104, P3568, DOI 10.1121/1.423939
   KLUENDER KR, 1988, J PHONETICS, V16, P153, DOI 10.1016/S0095-4470(19)30480-2
   KLUENDER KR, 1987, SCIENCE, V237, P1195, DOI 10.1126/science.3629235
   Kluender KR, 2003, SPEECH COMMUN, V41, P59, DOI 10.1016/S0167-6393(02)00093-6
   Kluender KR, 1999, J ACOUST SOC AM, V105, P503, DOI 10.1121/1.424587
   Kluender KR, 1994, HDB PSYCHOLINGUISTIC, P173
   Kluender KR, 2008, SENSES COMPREHENSIVE, V3, P829, DOI DOI 10.1016/B978-012370880-9.00067-0
   Koffka K., 1935, PRINCIPLES GESTALT P
   Krull V, 2008, J ACOUST SOC AM, V123, P4352, DOI 10.1121/1.2912440
   KUHL PK, 1975, SCIENCE, V190, P69, DOI 10.1126/science.1166301
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   LILJENCRANTS J, 1972, LANGUAGE, V48, P839, DOI 10.2307/411991
   LINDBLOM B, 1963, J ACOUST SOC AM, V35, P1773, DOI 10.1121/1.1918816
   LINDBLOM B., 1986, EXPT PHONOLOGY, P13
   LINDBLOM BE, 1967, J ACOUST SOC AM, V42, P830, DOI 10.1121/1.1910655
   Lindblom B, 2012, J PHONETICS, V40, P1, DOI 10.1016/j.wocn.2011.09.005
   Liu S. T., 2019, NATURE COMMUNICATION, DOI [10.1101/411611, DOI 10.1101/411611]
   Llanos F, 2014, 168 M AC SOC AM
   Lloyd RJ, 1891, PHONETISCHE STUDIEN, V4, P37
   Lloyd RJ, 1892, PHONETISCHE STUDIEN, V5, P1
   Lloyd RJ, 1890, SOME RES NATURE VOWE
   Lloyd RJ, 1890, PHONETISCHE STUDIEN, V3, P251
   Locke J, 1690, ESSAY HUMAN UNDERSTA
   Lotto AJ, 2000, PHONETICA, V57, P189, DOI 10.1159/000028472
   Lotto AJ, 1998, PERCEPT PSYCHOPHYS, V60, P602, DOI 10.3758/BF03206049
   Lotto AJ, 1997, J ACOUST SOC AM, V102, P1134, DOI 10.1121/1.419865
   Lotto AJ, 2000, CHICAGO LINGUISTIC S, V35, P191
   Lu K., 2019, ADAPTIVE EFFICIENT C, DOI [10.1101/548156, DOI 10.1101/548156]
   LUCE PA, 1986, PERCEPT PSYCHOPHYS, V39, P155, DOI 10.3758/BF03212485
   Malmierca MS, 2015, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00019
   Malmierca MS, 2009, J NEUROSCI, V29, P5483, DOI 10.1523/JNEUROSCI.4153-08.2009
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P407, DOI 10.3758/BF03204884
   MANN VA, 1986, COGNITION, V24, P169, DOI 10.1016/S0010-0277(86)80001-4
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P213, DOI 10.3758/BF03204377
   MCFADDEN D, 1990, J ACOUST SOC AM, V87, P2634, DOI 10.1121/1.399056
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Miller J. L., 1981, PERSPECTIVES STUDY S, P39
   MILLER JD, 1989, J ACOUST SOC AM, V85, P2114, DOI 10.1121/1.397862
   MILLER JL, 1979, PERCEPT PSYCHOPHYS, V25, P457, DOI 10.3758/BF03213823
   MILLER JL, 1988, J EXP PSYCHOL HUMAN, V14, P369, DOI 10.1037/0096-1523.14.3.369
   Minifie FD, 1973, NORMAL ASPECTS SPEEC, P235
   MOORE BCJ, 1983, J ACOUST SOC AM, V74, P750, DOI 10.1121/1.389861
   Nassau K, 1983, PHYS CHEM COLOR
   NEAREY TM, 1989, J ACOUST SOC AM, V85, P2088, DOI 10.1121/1.397861
   Nearey TM, 2010, J ACOUST SOC AM, V127, P2020, DOI DOI 10.1121/1.3385273
   Ng A. Y., 2002, P ADV NEUR INF PROC, V14
   Nordstrom P-E, 1975, P 7 INT C PHON SCI
   Norris D, 1997, COGNITIVE PSYCHOL, V34, P191, DOI 10.1006/cogp.1997.0671
   OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687
   Okamura M, 1966, JPN J OTOL TOKYO, V69, P1198
   PARKER EM, 1986, PERCEPT PSYCHOPHYS, V39, P129, DOI 10.3758/BF03211495
   Pelucchi B, 2009, CHILD DEV, V80, P674, DOI 10.1111/j.1467-8624.2009.01290.x
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Port R, 2006, 2 LANGUAGE SPEECH LE, P349
   RAUSCHECKER JP, 1995, SCIENCE, V268, P111, DOI 10.1126/science.7701330
   Roverud E, 2014, J ACOUST SOC AM, V135, P1321, DOI 10.1121/1.4864783
   Roverud E, 2010, J ACOUST SOC AM, V128, P1203, DOI 10.1121/1.3473695
   Saberi K, 1999, NATURE, V398, P760, DOI 10.1038/19652
   Saffran JR, 2018, ANNU REV PSYCHOL, V69, P181, DOI 10.1146/annurev-psych-122216-011805
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Saffran JR, 1999, COGNITION, V70, P27, DOI 10.1016/S0010-0277(98)00075-4
   SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0
   Schouten JF, 1940, P K NED AKAD WETENSC, V43, P356
   Schwartz O, 2001, NAT NEUROSCI, V4, P819, DOI 10.1038/90526
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Siegelman N, 2017, BEHAV RES METHODS, V49, P418, DOI 10.3758/s13428-016-0719-z
   Siegelman N, 2017, PHILOS T R SOC B, V372, DOI 10.1098/rstb.2016.0059
   Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193
   Simoncelli EP, 2003, CURR OPIN NEUROBIOL, V13, P144, DOI 10.1016/S0959-4388(03)00047-3
   SMITH RL, 1977, J NEUROPHYSIOL, V40, P1098
   SMITH RL, 1975, BIOL CYBERN, V17, P169, DOI 10.1007/BF00364166
   Stilp C.E., 2019, ATTENTION PERCEPTION
   Stilp CE, 2018, J ACOUST SOC AM, V143, P2460, DOI 10.1121/1.5031018
   Stilp CE, 2016, HEARING RES, V341, P168, DOI 10.1016/j.heares.2016.08.004
   Stilp CE, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161001
   Stilp CE, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030845
   Stilp CE, 2011, J ACOUST SOC AM, V130, pEL352, DOI 10.1121/1.3647264
   Stilp CE, 2010, P NATL ACAD SCI USA, V107, P21914, DOI 10.1073/pnas.1009020107
   Stilp CE, 2010, J ACOUST SOC AM, V128, P2112, DOI 10.1121/1.3483719
   Stilp CE, 2010, P NATL ACAD SCI USA, V107, P12387, DOI 10.1073/pnas.0913625107
   Stilp CE, 2010, ATTEN PERCEPT PSYCHO, V72, P470, DOI 10.3758/APP.72.2.470
   Strickland EA, 2001, J ACOUST SOC AM, V109, P2062, DOI 10.1121/1.1357811
   Sussman HM, 1998, BEHAV BRAIN SCI, V21, P241, DOI 10.1017/S0140525X98001174
   SYRDAL AK, 1986, J ACOUST SOC AM, V79, P1086, DOI 10.1121/1.393381
   Tian B, 2004, J NEUROPHYSIOL, V92, P2993, DOI 10.1152/jn.00472.2003
   Trubetzkoy N., 1969, PRINCIPLES PHONOLOGY
   Ulanovsky N, 2003, NAT NEUROSCI, V6, P391, DOI 10.1038/nn1032
   Vapnik V.N., 1998, STAT LEARNING THEORY
   Viemeister N. F., 1980, PSYCHOPHYSICAL PHYSL, P190, DOI DOI 10.1007/978-94-009-9144-6_28
   VIEMEISTER NF, 1982, J ACOUST SOC AM, V71, P1502, DOI 10.1121/1.387849
   Viswanathan N, 2014, J EXP PSYCHOL HUMAN, V40, P1228, DOI 10.1037/a0036214
   Viswanathan N, 2013, J EXP PSYCHOL HUMAN, V39, P1181, DOI 10.1037/a0030735
   Viswanathan N, 2010, J EXP PSYCHOL HUMAN, V36, P1005, DOI 10.1037/a0018391
   Viswanathan N, 2009, PSYCHON B REV, V16, P74, DOI 10.3758/PBR.16.1.74
   VONKLITZING R, 1994, J ACOUST SOC AM, V95, P2192, DOI 10.1121/1.408679
   Vorperian HK, 2005, J ACOUST SOC AM, V117, P338, DOI 10.1121/1.1835958
   Vorperian HK, 1999, INT J PEDIATR OTORHI, V49, P197, DOI 10.1016/S0165-5876(99)00208-6
   Vorperian HK, 2009, J ACOUST SOC AM, V125, P1666, DOI 10.1121/1.3075589
   WATKINS AJ, 1991, J ACOUST SOC AM, V90, P2942, DOI 10.1121/1.401769
   WATKINS AJ, 1994, J ACOUST SOC AM, V96, P1263, DOI 10.1121/1.410275
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1988, DEV PSYCHOL, V24, P672, DOI 10.1037/0012-1649.24.5.672
   WERKER JF, 1984, J ACOUST SOC AM, V75, P1866, DOI 10.1121/1.390988
   WERKER JF, 1983, CAN J PSYCHOL, V37, P278, DOI 10.1037/h0080725
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
   WERKER JF, 1985, PERCEPT PSYCHOPHYS, V37, P35, DOI 10.3758/BF03207136
   Wessinger CM, 2001, J COGNITIVE NEUROSCI, V13, P1, DOI 10.1162/089892901564108
   ZWICKER E, 1961, J ACOUST SOC AM, V33, P248, DOI 10.1121/1.1908630
NR 197
TC 5
Z9 4
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 861
EP 883
DI 10.3758/s13414-019-01702-x
PG 23
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6NQ
UT WOS:000485098800001
PM 30937673
OA Bronze
DA 2021-02-24
ER

PT J
AU Freggens, M
   Thomas, A
   Pitt, MA
AF Freggens, Marjorie
   Thomas, Adam
   Pitt, Mark A.
TI A test of linguistic influences in the perceptual organization of speech
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Perceptual organization; Audition; Speech perception
ID ACROSS-FORMANT INTEGRATION; TEMPORAL-ORDER; TRANSFORMATION; VOWEL;
   INTELLIGIBILITY; SEGREGATION; SEQUENCES; ATTENTION; SOUNDS
AB Research in speech perception has explored how knowledge of a language influences phonetic perception. The current study investigated whether such linguistic influences extend to the perceptual (sequential) organization of speech. Listeners heard sinewave analogs of word pairs (e.g., loose seam, which contains a single [s] frication but is perceived as two /s/ phonemes) cycle continuously, which causes the stimulus to split apart into foreground and background percepts. They had to identify the foreground percept when the stimuli were heard as nonspeech and then again when heard as speech. Of interest was how grouping changed across listening condition when [s] was heard as speech or as a hiss. Although the section of the signal that was identified as the foreground differed little across listening condition, a strong bias to perceive [s] as forming the onset of the foreground was observed in the speech condition (Experiment 1). This effect was reduced in Experiment 2 by increasing the stimulus repetition rate. Findings suggest that the sequential organization of speech arises from the interaction of auditory and linguistic processes, with the former constraining the latter.
C1 [Freggens, Marjorie; Thomas, Adam; Pitt, Mark A.] Ohio State Univ, Dept Psychol, Columbus, OH 43220 USA.
RP Freggens, M (corresponding author), Ohio State Univ, Dept Psychol, Columbus, OH 43220 USA.
EM freggens.1@osu.edu
CR Best CT, 1999, PSYCHOL SCI, V10, P65, DOI 10.1111/1467-9280.00108
   Billig AJ, 2013, CURR BIOL, V23, P1585, DOI 10.1016/j.cub.2013.06.042
   BLESSER B, 1972, J SPEECH HEAR RES, V15, P5, DOI 10.1044/jshr.1501.05
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   BREGMAN AS, 1971, J EXP PSYCHOL, V89, P244, DOI 10.1037/h0031163
   Bregman AS, 1999, PERCEPT PSYCHOPHYS, V61, P195, DOI 10.3758/BF03206882
   Ciocca V, 2008, FRONT BIOSCI-LANDMRK, V13, P148, DOI 10.2741/2666
   Clements GN, 1992, PHONOLOGICA 1988, P63
   COLE RA, 1973, CAN J PSYCHOL, V27, P441, DOI 10.1037/h0082495
   Cutting J. E, 1973, HASKINS LAB STATUS R, P37
   Darwin CJ, 2008, PHILOS T R SOC B, V363, P1011, DOI 10.1098/rstb.2007.2156
   DARWIN CJ, 1984, Q J EXP PSYCHOL-A, V36, P193, DOI 10.1080/14640748408402155
   DARWIN CJ, 1986, J ACOUST SOC AM, V79, P838, DOI 10.1121/1.393474
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014
   Devergie A, 2010, J ACOUST SOC AM, V128, pEL1, DOI 10.1121/1.3436498
   Diehl RL, 2008, PHILOS T R SOC B, V363, P965, DOI 10.1098/rstb.2007.2153
   DIEHL RL, 1985, J EXP PSYCHOL HUMAN, V11, P209
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   DORMAN MF, 1975, J EXP PSYCHOL HUMAN, V104, P121
   Eddington D, 2013, J QUANT LINGUIST, V20, P45, DOI 10.1080/09296174.2012.754601
   Ernestus M, 2002, BRAIN LANG, V81, P162, DOI 10.1006/brln.2001.2514
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Gow DW, 2003, PERCEPT PSYCHOPHYS, V65, P575, DOI 10.3758/BF03194584
   Hamon C., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P238, DOI 10.1109/ICASSP.1989.266409
   Humphries C, 2014, FRONTIERS NEUROSCIEN, V8, P1
   JASP Team, 2018, JASP VERS 0 9 COMP S
   Kampstra P, 2008, J STAT SOFTW, V28, P1, DOI DOI 10.18637/JSS.V028.C01
   Kim D, 2012, J MEM LANG, V66, P509, DOI 10.1016/j.jml.2011.12.007
   Mattys SL, 2005, J EXP PSYCHOL GEN, V134, P477, DOI 10.1037/0096-3445.134.4.477
   Mattys SL, 2007, J ACOUST SOC AM, V122, P554, DOI 10.1121/1.2735105
   Mill RW, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1002925
   Moore BCJ, 2012, PHILOS T R SOC B, V367, P919, DOI 10.1098/rstb.2011.0355
   NYGAARD LC, 1993, J EXP PSYCHOL HUMAN, V19, P268, DOI 10.1037/0096-1523.19.2.268
   Oh GE, 2012, J PHONETICS, V40, P82, DOI 10.1016/j.wocn.2011.08.003
   Pitt MA, 2002, J EXP PSYCHOL HUMAN, V28, P150, DOI 10.1037//0096-1523.28.1.150
   R Foundation for Statistical Computing, 2013, R LANG ENV STAT COMP
   REMEZ RE, 1994, PSYCHOL REV, V101, P129, DOI 10.1037/0033-295X.101.1.129
   Roberts B, 2015, J EXP PSYCHOL HUMAN, V41, P680, DOI 10.1037/xhp0000038
   Roberts B, 2010, J ACOUST SOC AM, V128, P804, DOI 10.1121/1.3445786
   Scott SK, 2000, BRAIN, V123, P2400, DOI 10.1093/brain/123.12.2400
   SEXTON MA, 1981, J EXP PSYCHOL HUMAN, V7, P422, DOI 10.1037/0096-1523.7.2.422
   Shinn-Cunningham BG, 2008, J ACOUST SOC AM, V123, P295, DOI 10.1121/1.2804701
   Stachurski M, 2015, HEARING RES, V323, P22, DOI 10.1016/j.heares.2015.01.007
   Summers RJ, 2016, J ACOUST SOC AM, V140, P1227, DOI 10.1121/1.4960595
   Sussman ES, 2017, J SPEECH LANG HEAR R, V60, P2989, DOI 10.1044/2017_JSLHR-H-17-0041
   Treiman R, 1992, PHONOLOGICA 1988, P273
   Vandermosten M, 2010, P NATL ACAD SCI USA, V107, P10389, DOI 10.1073/pnas.0912858107
   Wagenmakers EJ, 2018, PSYCHON B REV, V25, P58, DOI [10.3758/s13423-017-1323-7, 10.3758/s13423-017-1343-3]
   WARREN RM, 1969, SCIENCE, V164, P586, DOI 10.1126/science.164.3879.586
   WARREN RM, 1958, AM J PSYCHOL, V71, P612, DOI 10.2307/1420267
   WARREN RM, 1968, PSYCHOL BULL, V70, P261, DOI 10.1037/h0026275
   Warren RM, 2008, AUDITORY PERCEPTION
   Yoshida KA, 2010, COGNITION, V115, P356, DOI 10.1016/j.cognition.2010.01.005
NR 54
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 1065
EP 1075
DI 10.3758/s13414-019-01699-3
PG 11
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6NQ
UT WOS:000485098800014
PM 30891663
OA Bronze
DA 2021-02-24
ER

PT J
AU Kreitewolf, J
   Wostmann, M
   Tune, S
   Plochl, M
   Obleser, J
AF Kreitewolf, Jens
   Woestmann, Malte
   Tune, Sarah
   Ploechl, Michael
   Obleser, Jonas
TI Working-memory disruption by task-irrelevant talkers depends on degree
   of talker familiarity
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Talker familiarity; Working memory; Irrelevant-speech task; Attention;
   Distraction
ID SHORT-TERM-MEMORY; SPEECH-PERCEPTION; VISUAL-SEARCH; DISTRACTOR; VOICE;
   ATTENTION; LANGUAGE; TARGET
AB When one is listening, familiarity with an attended talker's voice improves speech comprehension. Here, we instead investigated the effect of familiarity with a distracting talker. In an irrelevant-speech task, we assessed listeners' working memory for the serial order of spoken digits when a task-irrelevant, distracting sentence was produced by either a familiar or an unfamiliar talker (with rare omissions of the task-irrelevant sentence). We tested two groups of listeners using the same experimental procedure. The first group were undergraduate psychology students (N = 66) who had attended an introductory statistics course. Critically, each student had been taught by one of two course instructors, whose voices served as the familiar and unfamiliar task-irrelevant talkers. The second group of listeners were family members and friends (N = 20) who had known either one of the two talkers for more than 10 years. Students, but not family members and friends, made more errors when the task-irrelevant talker was familiar versus unfamiliar. Interestingly, the effect of talker familiarity was not modulated by the presence of task-irrelevant speech: Students experienced stronger working memory disruption by a familiar talker, irrespective of whether they heard a task-irrelevant sentence during memory retention or merely expected it. While previous work has shown that familiarity with an attended talker benefits speech comprehension, our findings indicate that familiarity with an ignored talker disrupts working memory for target speech. The absence of this effect in family members and friends suggests that the degree of familiarity modulates the memory disruption.
C1 [Kreitewolf, Jens; Woestmann, Malte; Tune, Sarah; Ploechl, Michael; Obleser, Jonas] Univ Lubeck, Dept Psychol, Lubeck, Germany.
RP Kreitewolf, J; Obleser, J (corresponding author), Univ Lubeck, Dept Psychol, Lubeck, Germany.
EM jens.kreitewolf@uni-luebeck.de; jonas.obleser@uni-luebeck.de
FU University of Lubeck
FX Research was funded by the University of Lubeck. Photographs appear by
   courtesy of Leo Waschke. We thank all of the students, family members,
   and friends who participated in this experiment, as well as two
   anonymous reviewers for their valuable comments on an earlier version of
   the manuscript.
CR [Anonymous], 2017, R LANG ENV STAT COMP
   Awh E, 2006, NEUROSCIENCE, V139, P201, DOI 10.1016/j.neuroscience.2005.08.023
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Bolia RS, 2000, J ACOUST SOC AM, V107, P1065, DOI 10.1121/1.428288
   Bressler S, 2014, PSYCHOL RES-PSYCH FO, V78, P349, DOI 10.1007/s00426-014-0555-7
   Burkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980
   COLLE HA, 1976, J VERB LEARN VERB BE, V15, P17, DOI 10.1016/S0022-5371(76)90003-7
   Cowan N., 1998, ATTENTION MEMORY INT
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Ellermeier W, 2015, J ACOUST SOC AM, V138, P1561, DOI 10.1121/1.4928954
   Erb J, 2012, NEUROPSYCHOLOGIA, V50, P2154, DOI 10.1016/j.neuropsychologia.2012.05.013
   Fritz JB, 2007, CURR OPIN NEUROBIOL, V17, P437, DOI 10.1016/j.conb.2007.07.011
   Gaspelin N, 2019, CURR OPIN PSYCHOL, V29, P12, DOI 10.1016/j.copsyc.2018.10.013
   Geyer T, 2006, PERCEPT PSYCHOPHYS, V68, P736, DOI 10.3758/BF03193697
   Holmes E, 2018, PSYCHOL SCI, V29, P1575, DOI 10.1177/0956797618779083
   Jeffreys H., 1961, THEORY PROBABILITY
   Johnsrude IS, 2013, PSYCHOL SCI, V24, P1995, DOI 10.1177/0956797613482467
   JONES D, 1992, SCAND J PSYCHOL, V33, P212, DOI 10.1111/j.1467-9450.1992.tb00911.x
   JONES DM, 1993, J EXP PSYCHOL LEARN, V19, P369, DOI 10.1037/0278-7393.19.2.369
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Kerzel D, 2016, J EXP PSYCHOL HUMAN, V42, P648, DOI 10.1037/xhp0000180
   Kreitewolf J, 2018, J ACOUST SOC AM, V144, P2178, DOI 10.1121/1.5058684
   Kreitewolf J, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01584
   Lavan N, 2019, BRIT J PSYCHOL, V110, P576, DOI 10.1111/bjop.12348
   Lavan N, 2019, PSYCHON B REV, V26, P90, DOI 10.3758/s13423-018-1497-7
   Lavner Y., 2001, INT J SPEECH TECHNOL, V4, P63, DOI [10.1023/A:1009656816383, DOI 10.1023/A:1009656816383]
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Levi SV, 2011, J ACOUST SOC AM, V130, P4053, DOI 10.1121/1.3651816
   Magnuson JS, 1995, P 1995 SPRING M AC S, P391
   Maguinness C, 2018, NEUROPSYCHOLOGIA, V116, P179, DOI 10.1016/j.neuropsychologia.2018.03.039
   Marini F, 2013, J EXP PSYCHOL GEN, V142, P906, DOI 10.1037/a0029905
   Mathias Samuel R, 2014, Front Biosci (Schol Ed), V6, P92
   McPherson MJ, 2018, NAT HUM BEHAV, V2, P52, DOI 10.1038/s41562-017-0261-8
   Newman RS, 2007, J PHONETICS, V35, P85, DOI 10.1016/j.wocn.2005.10.004
   Noonan MP, 2016, J NEUROSCI, V36, P1797, DOI 10.1523/JNEUROSCI.2133-15.2016
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Obleser J, 2012, J NEUROSCI, V32, P12376, DOI 10.1523/JNEUROSCI.4908-11.2012
   Roer JP, 2013, J COGN PSYCHOL, V25, P925, DOI 10.1080/20445911.2013.828063
   Roer JP, 2015, J EXP PSYCHOL HUMAN, V41, P692, DOI 10.1037/xhp0000028
   Ruff CC, 2006, J COGNITIVE NEUROSCI, V18, P522, DOI 10.1162/jocn.2006.18.4.522
   SALAME P, 1982, J VERB LEARN VERB BE, V21, P150, DOI 10.1016/S0022-5371(82)90521-7
   Saunders DR, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2620
   Schlittmeier SJ, 2011, PSYCHOPHYSIOLOGY, V48, P1669, DOI 10.1111/j.1469-8986.2011.01263.x
   Senior B, 2018, J ACOUST SOC AM, V143, P931, DOI 10.1121/1.5023681
   Shinn-Cunningham BG, 2008, TRENDS COGN SCI, V12, P182, DOI 10.1016/j.tics.2008.02.003
   Souza P, 2013, J AM ACAD AUDIOL, V24, P689, DOI 10.3766/jaaa.24.8.6
   Wostmann M, 2017, CEREB CORTEX, V27, P3307, DOI 10.1093/cercor/bhx074
   Wostmann M, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00538
NR 50
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD MAY
PY 2019
VL 81
IS 4
BP 1108
EP 1118
DI 10.3758/s13414-019-01727-2
PG 11
WC Psychology; Psychology, Experimental
SC Psychology
GA IW6NQ
UT WOS:000485098800017
PM 30993655
OA Bronze
DA 2021-02-24
ER

PT J
AU Liu, J
   Tsang, T
   Jackson, L
   Ponting, C
   Jeste, SS
   Bookheimer, SY
   Dapretto, M
AF Liu, Janelle
   Tsang, Tawny
   Jackson, Lisa
   Ponting, Carolyn
   Jeste, Shafali S.
   Bookheimer, Susan Y.
   Dapretto, Mirella
TI Altered lateralization of dorsal language tracts in 6-week-old infants
   at risk for autism
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
DE autism; development; DTI; infant; language; structural connectivity
ID SPECTRUM DISORDER; WHITE-MATTER; ARCUATE FASCICULUS; SPEECH-PERCEPTION;
   NEURAL CIRCUITRY; YOUNG-CHILDREN; BRAIN; CONNECTIVITY; TODDLERS;
   IMPAIRMENT
AB Altered structural connectivity has been identified as a possible biomarker of autism spectrum disorder (ASD) risk in the developing brain. Core features of ASD include impaired social communication and early language delay. Thus, examining white matter tracts associated with language may lend further insight into early signs of ASD risk and the mechanisms that underlie language impairments associated with the disorder. Evidence of altered structural connectivity has previously been detected in 6-month-old infants at high familial risk for developing ASD. However, as language processing begins in utero, differences in structural connectivity between language regions may be present in the early infant brain shortly after birth. Here we investigated key white matter pathways of the dorsal language network in 6-week-old infants at high (HR) and low (LR) risk for ASD to identify atypicalities in structural connectivity that may predict altered developmental trajectories prior to overt language delays and the onset of ASD symptomatology. Compared to HR infants, LR infants showed higher fractional anisotropy (FA) in the left superior longitudinal fasciculus (SLF); in contrast, in the right SLF, HR infants showed higher FA than LR infants. Additionally, HR infants showed more rightward lateralization of the SLF. Across both groups, measures of FA and lateralization of these pathways at 6 weeks of age were related to later language development at 18 months of age as well as ASD symptomatology at 36 months of age. These findings indicate that early differences in the structure of language pathways may provide an early predictor of future language development and ASD risk.
C1 [Liu, Janelle] Univ Calif Los Angeles, Interdept Neurosci Program, Los Angeles, CA USA.
   [Liu, Janelle; Tsang, Tawny; Jackson, Lisa; Jeste, Shafali S.; Bookheimer, Susan Y.; Dapretto, Mirella] Univ Calif Los Angeles, Dept Psychiat & Biobehav Sci, Los Angeles, CA 90024 USA.
   [Liu, Janelle; Tsang, Tawny; Jackson, Lisa; Ponting, Carolyn; Dapretto, Mirella] Univ Calif Los Angeles, Ahmanson Lovelace Brain Mapping Ctr, Los Angeles, CA USA.
   [Tsang, Tawny; Ponting, Carolyn; Bookheimer, Susan Y.] Univ Calif Los Angeles, Dept Psychol, Los Angeles, CA USA.
   [Jackson, Lisa; Ponting, Carolyn; Jeste, Shafali S.; Bookheimer, Susan Y.] Univ Calif Los Angeles, David Geffen Sch Med, Semel Inst Neurosci & Human Behav, Los Angeles, CA 90095 USA.
   [Bookheimer, Susan Y.] Univ Calif Los Angeles, Ctr Cognit Neurosci, Los Angeles, CA USA.
RP Dapretto, M (corresponding author), Ahmanson Lovelace Brain Mapping Ctr, Los Angeles, CA 90095 USA.
EM mirella@ucla.edu
RI Ponting, Carolyn/ABA-7798-2020
OI Ponting, Carolyn/0000-0002-5074-736X
FU National Institute on Drug AbuseUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute on Drug Abuse (NIDA)European Commission [T90 DA022768]; Eunice
   Kennedy Shriver National Institute of Child Health and Human
   DevelopmentUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [F31 HD088102, P50
   HD055784]; National Institute of Child Health and Human
   DevelopmentUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [F31 HD088102, P50
   HD055784]; Brain Mapping Medical Research Organization; Brain Mapping
   Support Foundation; Pierson-Lovelace Foundation; Ahmanson Foundation;
   Capital Group Companies Charitable Foundation; William M. and Linda R.
   Dietel Philanthropic Fund; Northstar Fund; EUNICE KENNEDY SHRIVER
   NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH Eunice Kennedy Shriver National Institute of Child Health &
   Human Development (NICHD) [P50HD055784, P50HD055784, U54HD087101,
   U54HD087101, P50HD055784, P50HD055784, P50HD055784, U54HD087101,
   U54HD087101, U54HD087101, U54HD087101, U54HD087101, U54HD087101,
   P50HD055784, U54HD087101, P50HD055784, U54HD087101, U54HD087101,
   U54HD087101, P50HD055784, U54HD087101, U54HD087101, U54HD087101,
   P50HD055784, P50HD055784, U54HD087101, P50HD055784, P50HD055784,
   P50HD055784, U54HD087101, U54HD087101, P50HD055784, U54HD087101,
   P50HD055784, U54HD087101, P50HD055784, P50HD055784, P50HD055784,
   P50HD055784, P50HD055784, P50HD055784, U54HD087101, P50HD055784,
   P50HD055784, P50HD055784, P50HD055784, P50HD055784, P50HD055784,
   U54HD087101, P50HD055784, P50HD055784, P50HD055784, P50HD055784,
   U54HD087101, U54HD087101, P50HD055784, P50HD055784, P50HD055784,
   U54HD087101, U54HD087101, U54HD087101, P50HD055784, P50HD055784,
   U54HD087101, P50HD055784] Funding Source: NIH RePORTER
FX National Institute on Drug Abuse, Grant/Award Number: T90 DA022768;
   Eunice Kennedy Shriver National Institute of Child Health and Human
   Development, Grant/Award Number: F31 HD088102 and P50 HD055784; National
   Institute of Child Health and Human Development, Grant/Award Number: P50
   HD055784 and F31 HD088102; Brain Mapping Medical Research Organization;
   Brain Mapping Support Foundation; Pierson-Lovelace Foundation; The
   Ahmanson Foundation; Capital Group Companies Charitable Foundation;
   William M. and Linda R. Dietel Philanthropic Fund; Northstar Fund
CR Aeby A, 2013, NEUROIMAGE, V78, P145, DOI 10.1016/j.neuroimage.2013.03.076
   Alarcon M, 2008, AM J HUM GENET, V82, P150, DOI 10.1016/j.ajhg.2007.09.005
   Bashat DB, 2007, NEUROIMAGE, V37, P40, DOI 10.1016/j.neuroimage.2007.04.060
   Behrens TEJ, 2007, NEUROIMAGE, V34, P144, DOI 10.1016/j.neuroimage.2006.09.018
   Behrens TEJ, 2003, MAGN RESON MED, V50, P1077, DOI 10.1002/mrm.10609
   Brauer J, 2013, BRAIN LANG, V127, P289, DOI 10.1016/j.bandl.2013.03.001
   Brauer J, 2011, CEREB CORTEX, V21, P459, DOI 10.1093/cercor/bhq108
   Conti E, 2017, HUM BRAIN MAPP, V38, P2333, DOI 10.1002/hbm.23520
   Conti E, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00159
   Dehaene-Lambertz G, 2010, BRAIN LANG, V114, P53, DOI 10.1016/j.bandl.2009.09.003
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   Dehaene-Lambertz G, 2006, TRENDS NEUROSCI, V29, P367, DOI 10.1016/j.tins.2006.05.011
   Dehaene-Lambertz G, 2017, PSYCHON B REV, V24, P48, DOI 10.3758/s13423-016-1156-9
   DiLavore P. C., 2012, AUTISM DIAGNOSTIC OB
   Dinstein I, 2011, NEURON, V70, P1218, DOI 10.1016/j.neuron.2011.04.018
   Dubois J, 2014, NEUROSCIENCE, V276, P48, DOI 10.1016/j.neuroscience.2013.12.044
   Dubois J, 2016, CEREB CORTEX, V26, P2283, DOI 10.1093/cercor/bhv082
   Dunn K, 2015, DEV COGN NEUROS-NETH, V13, P43, DOI 10.1016/j.dcn.2015.04.002
   Durkin MS, 2017, AM J PUBLIC HEALTH, V107, P1818, DOI [10.2105/ajph.2017.304032, 10.2105/AJPH.2017.304032]
   Eicher JD, 2015, AUTISM RES, V8, P229, DOI 10.1002/aur.1436
   Elison JT, 2013, AM J PSYCHIAT, V170, P899, DOI 10.1176/appi.ajp.2012.12091150
   Elison JT, 2013, DEVELOPMENTAL SCI, V16, P186, DOI 10.1111/desc.12015
   Emerson RW, 2016, J NEUROSCI, V36, P10883, DOI 10.1523/JNEUROSCI.3980-15.2016
   Eyler LT, 2012, BRAIN, V135, P949, DOI 10.1093/brain/awr364
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   Fitzgerald J, 2018, EUR J NEUROSCI, V47, P652, DOI 10.1111/ejn.13655
   Fletcher PT, 2010, NEUROIMAGE, V51, P1117, DOI 10.1016/j.neuroimage.2010.01.083
   Franchini M, 2018, J AUTISM DEV DISORD, V48, P3417, DOI 10.1007/s10803-018-3607-9
   Friederici AD, 2018, CURR OPIN BEHAV SCI, V21, P88, DOI 10.1016/j.cobeha.2018.03.004
   Friederici AD, 2017, NAT HUM BEHAV, V1, P713, DOI 10.1038/s41562-017-0184-4
   Friederici AD, 2017, PSYCHON B REV, V24, P41, DOI 10.3758/s13423-016-1090-x
   Friederici Angela D, 2012, Front Evol Neurosci, V4, P3, DOI 10.3389/fnevo.2012.00003
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   Friederici AD, 2009, TRENDS COGN SCI, V13, P175, DOI 10.1016/j.tics.2009.01.001
   Gamliel I, 2007, J AUTISM DEV DISORD, V37, P171, DOI 10.1007/s10803-006-0341-5
   Gao W, 2009, AM J NEURORADIOL, V30, P290, DOI 10.3174/ajnr.A1363
   Geschwind DH, 2011, TRENDS COGN SCI, V15, P409, DOI 10.1016/j.tics.2011.07.003
   Glasser MF, 2008, CEREB CORTEX, V18, P2471, DOI 10.1093/cercor/bhn011
   Gotham K, 2009, J AUTISM DEV DISORD, V39, P693, DOI 10.1007/s10803-008-0674-3
   Hackman DA, 2010, NAT REV NEUROSCI, V11, P651, DOI 10.1038/nrn2897
   Hackman DA, 2009, TRENDS COGN SCI, V13, P65, DOI 10.1016/j.tics.2008.11.003
   Herringshaw AJ, 2016, AUTISM RES, V9, P1046, DOI 10.1002/aur.1599
   Hudry K, 2014, J AUTISM DEV DISORD, V44, P154, DOI 10.1007/s10803-013-1861-4
   Hudry K, 2010, INT J LANG COMM DIS, V45, P681, DOI 10.3109/13682820903461493
   Iverson JM, 2007, J AUTISM DEV DISORD, V37, P158, DOI 10.1007/s10803-006-0339-z
   Jardri R, 2008, NEUROIMAGE, V42, P10, DOI 10.1016/j.neuroimage.2008.04.247
   Jardri R, 2012, INT J DEV NEUROSCI, V30, P159, DOI 10.1016/j.ijdevneu.2011.11.002
   Jenkinson M, 2012, NEUROIMAGE, V62, P782, DOI 10.1016/j.neuroimage.2011.09.015
   Joseph RM, 2014, BRAIN IMAGING BEHAV, V8, P60, DOI 10.1007/s11682-013-9245-0
   Kleinhans NM, 2008, BRAIN RES, V1221, P115, DOI 10.1016/j.brainres.2008.04.080
   Knaus TA, 2010, BRAIN LANG, V112, P113, DOI 10.1016/j.bandl.2009.11.005
   Landa R, 2006, J CHILD PSYCHOL PSYC, V47, P629, DOI 10.1111/j.1469-7610.2006.01531.x
   Lange N, 2010, AUTISM RES, V3, P350, DOI 10.1002/aur.162
   Lewis JD, 2014, TRANSL PSYCHIAT, V4, DOI 10.1038/tp.2014.24
   Lewis JD, 2017, BIOL PSYCHIAT, V82, P176, DOI 10.1016/j.biopsych.2017.03.006
   Leyfer OT, 2008, AUTISM RES, V1, P284, DOI 10.1002/aur.43
   Li H, 2014, HUM BRAIN MAPP, V35, P396, DOI 10.1002/hbm.22185
   Liu ZX, 2010, PROC SPIE, V7628, DOI 10.1117/12.844748
   Lombardo MV, 2015, NEURON, V86, P567, DOI 10.1016/j.neuron.2015.03.023
   Miller M, 2016, AUTISM RES, V9, P632, DOI 10.1002/aur.1572
   Miller M, 2015, J CHILD PSYCHOL PSYC, V56, P774, DOI 10.1111/jcpp.12342
   Mitchell S, 2006, J DEV BEHAV PEDIATR, V27, pS69, DOI 10.1097/00004703-200604002-00004
   Mori S, 2006, NEURON, V51, P527, DOI 10.1016/j.neuron.2006.08.012
   Nevill R, 2019, AUTISM, V23, P141, DOI 10.1177/1362361317726245
   Papinutto N, 2016, HUM BRAIN MAPP, V37, P2210, DOI 10.1002/hbm.23167
   Paul R, 2011, J CHILD PSYCHOL PSYC, V52, P588, DOI 10.1111/j.1469-7610.2010.02332.x
   Perani D, 2011, P NATL ACAD SCI USA, V108, P16056, DOI 10.1073/pnas.1102991108
   Qiu AQ, 2015, ANNU REV PSYCHOL, V66, P853, DOI 10.1146/annurev-psych-010814-015340
   Redcay E, 2008, BIOL PSYCHIAT, V64, P589, DOI 10.1016/j.biopsych.2008.05.020
   Redcay E, 2008, DEVELOPMENTAL SCI, V11, P237, DOI 10.1111/j.1467-7687.2008.00674.x
   Sadeghi N, 2013, NEUROIMAGE, V68, P236, DOI 10.1016/j.neuroimage.2012.11.040
   Sato H, 2012, HUM BRAIN MAPP, V33, P2092, DOI 10.1002/hbm.21350
   Seery AM, 2013, DEV COGN NEUROS-NETH, V5, P10, DOI 10.1016/j.dcn.2012.11.007
   Shi F, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018746
   Skeide MA, 2016, NAT REV NEUROSCI, V17, P323, DOI 10.1038/nrn.2016.23
   Smith SM, 2004, NEUROIMAGE, V23, pS208, DOI 10.1016/j.neuroimage.2004.07.051
   Solso S, 2016, BIOL PSYCHIAT, V79, P676, DOI 10.1016/j.biopsych.2015.06.029
   Sperdin HF, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00393
   Swanson MR, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12360
   Travers BG, 2012, AUTISM RES, V5, P289, DOI 10.1002/aur.1243
   VANDERKNAAP MS, 1991, DEV MED CHILD NEUROL, V33, P849
   von Hohenberg CC, 2013, J PSYCHIATR RES, V47, P1349, DOI 10.1016/j.jpsychires.2013.07.002
   Wan CY, 2012, ANN NY ACAD SCI, V1252, P332, DOI 10.1111/j.1749-6632.2012.06446.x
   Weinstein M, 2011, HUM BRAIN MAPP, V32, P534, DOI 10.1002/hbm.21042
   Weismer SE, 2010, J AUTISM DEV DISORD, V40, P1259, DOI 10.1007/s10803-010-0983-1
   Wolff JJ, 2018, DEV PSYCHOPATHOL, V30, P479, DOI 10.1017/S0954579417000980
   Wolff JJ, 2017, MOL AUTISM, V8, DOI 10.1186/s13229-017-0126-z
   Wolff JJ, 2012, AM J PSYCHIAT, V169, P589, DOI 10.1176/appi.ajp.2011.11091447
   Xiao Z, 2014, J AUTISM DEV DISORD, V44, P1633, DOI 10.1007/s10803-014-2033-x
   Zhang L, 2018, OPEN MED-WARSAW, V13, P90, DOI 10.1515/med-2018-0014
   Zwaigenbaum L, 2007, J AUTISM DEV DISORD, V37, P466, DOI 10.1007/s10803-006-0179-x
NR 91
TC 6
Z9 6
U1 1
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD MAY
PY 2019
VL 22
IS 3
AR e12768
DI 10.1111/desc.12768
PG 12
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA HU1OS
UT WOS:000465042300001
PM 30372577
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Yamashiro, A
   Vouloumanos, A
AF Yamashiro, Amy
   Vouloumanos, Athena
TI Are Linguistic and Social-Pragmatic Abilities Separable in Neurotypical
   Infants and Infants Later Diagnosed With ASD?
SO DEVELOPMENTAL PSYCHOLOGY
LA English
DT Article
DE speech perception; infancy; language; social-pragmatic abilities; autism
   spectrum disorder
ID AUTISM SPECTRUM DISORDER; INDIVIDUAL-DIFFERENCES; JOINT ATTENTION; EARLY
   LANGUAGE; 6-MONTH-OLD INFANTS; VOCABULARY GROWTH; 2ND YEAR; CHILDREN;
   SPEECH; COMMUNICATION
AB Adult humans process communicative interactions by recognizing that information is being communicated through speech (linguistic ability) and simultaneously evaluating how to respond appropriately (social-pragmatic ability). These abilities may originate in infancy. Infants understand how speech communicates in social interactions, helping them learn language and how to interact with others. Infants later diagnosed with autism spectrum disorder (ASD), who show deficits in social-pragmatic abilities, differ in how they attend to the linguistic and social-pragmatic information in their environment. Despite their interdependence, experimental measures of language and social-pragmatic attention are often studied in isolation in infancy. Thus, the extent to which language and social-pragmatic abilities are related constructs remains unknown. Understanding how related or separable language and social-pragmatic abilities are in infancy may reveal whether these abilities are supported by distinguishable developmental mechanisms. This study uses a single communicative scene to examine whether real-time linguistic and social-pragmatic attention are separable in neurotypical infants and infants later diagnosed with ASD, and whether attending to linguistic and social-pragmatic information separately predicts later language and social-pragmatic abilities 1 year later. For neurotypical 12-month-olds and 12-month-olds later diagnosed with ASD, linguistic attention was not correlated with concurrent social-pragmatic attention. Furthermore, infants' real-time attention to the linguistic and social-pragmatic aspects of the scene at 12 months predicted and distinguished language and social-pragmatic abilities at 24 months. Language and social-pragmatic attention during communication are thus separable in infancy and may follow distinguishable developmental trajectories.
C1 [Yamashiro, Amy; Vouloumanos, Athena] NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
RP Yamashiro, A (corresponding author), NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
EM amy.yamashiro@nyu.edu
FU Eunice Kennedy Shriver National Institute of Child Health & Human
   Development of the National Institutes of Health [R01HD072018]; EUNICE
   KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN
   DEVELOPMENTUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R01HD072018]
   Funding Source: NIH RePORTER
FX This research was supported by the Eunice Kennedy Shriver National
   Institute of Child Health & Human Development of the National Institutes
   of Health under Award R01HD072018. We'd like to thank members of the NYU
   Infant Cognition and Communication Lab, the parents and infants who
   participated, Pat Shrout for his assistance with analyses, and Gary
   Marcus for his feedback on the manuscript.
CR American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU
   Baillargeon R, 2010, TRENDS COGN SCI, V14, P110, DOI 10.1016/j.tics.2009.12.006
   Baio J, 2018, MMWR SURVEILL SUMM, V67, P1, DOI 10.15585/mmwr.ss6706a1
   BALDWIN DA, 1993, DEV PSYCHOL, V29, P832, DOI 10.1037/0012-1649.29.5.832
   BATES E, 1994, J CHILD LANG, V21, P85, DOI 10.1017/S0305000900008680
   Bauer DJ, 2002, APPL PSYCHOLINGUIST, V23, P313, DOI 10.1017/S0142716402003016
   Bennett TA, 2014, J AUTISM DEV DISORD, V44, P2797, DOI 10.1007/s10803-014-2138-2
   Bion RAH, 2013, COGNITION, V126, P39, DOI 10.1016/j.cognition.2012.08.008
   Brooks R, 2005, DEVELOPMENTAL SCI, V8, P535, DOI 10.1111/j.1467-7687.2005.00445.x
   Brooks R, 2008, J CHILD LANG, V35, P207, DOI 10.1017/S030500090700829X
   Brooks R, 2015, J EXP CHILD PSYCHOL, V130, P67, DOI 10.1016/j.jecp.2014.09.010
   Carpenter M, 1998, MONOGR SOC RES CHILD, V63, pV
   Charman T, 2005, J CHILD PSYCHOL PSYC, V46, P500, DOI 10.1111/j.1469-7610.2004.00377.x
   Chawarska K, 2007, J CHILD PSYCHOL PSYC, V48, P128, DOI 10.1111/j.1469-7610.2006.01685.x
   Chawarska K, 2014, J AM ACAD CHILD PSY, V53, P1317, DOI 10.1016/j.jaac.2014.09.015
   Chawarska K, 2013, BIOL PSYCHIAT, V74, P195, DOI 10.1016/j.biopsych.2012.11.022
   Chawarska K, 2012, J CHILD PSYCHOL PSYC, V53, P903, DOI 10.1111/j.1469-7610.2012.02538.x
   Cohen J., 2003, APPL MULTIPLE REGRES, V3rd
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fenson L., 1993, MACARTHUR BATES COMM
   Fernald A, 2012, CHILD DEV, V83, P203, DOI 10.1111/j.1467-8624.2011.01692.x
   Gillespie-Lynch K, 2012, J AUTISM DEV DISORD, V42, P161, DOI 10.1007/s10803-011-1222-0
   Goldstein MH, 2003, P NATL ACAD SCI USA, V100, P8030, DOI 10.1073/pnas.1332441100
   Guthrie W, 2013, J CHILD PSYCHOL PSYC, V54, P582, DOI 10.1111/jcpp.12008
   Hosozawa M, 2012, PEDIATRICS, V129, pE1453, DOI 10.1542/peds.2011-2278
   IBM Corp, 2017, IBM SPSS STAT MAC VE
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kuhl PK, 2005, DEVELOPMENTAL SCI, V8, pF1, DOI 10.1111/j.1467-7687.2004.00384.x
   Landa R, 2006, J CHILD PSYCHOL PSYC, V47, P629, DOI 10.1111/j.1469-7610.2006.01531.x
   Luyster R, 2009, J AUTISM DEV DISORD, V39, P1305, DOI 10.1007/s10803-009-0746-z
   Magiati I, 2014, CLIN PSYCHOL REV, V34, P73, DOI 10.1016/j.cpr.2013.11.002
   Marchman V. A, 2013, SCORING PROGRAM MACA
   Marchman VA, 2008, DEVELOPMENTAL SCI, V11, pF9, DOI 10.1111/j.1467-7687.2008.00671.x
   Markus J, 2000, SOC DEV, V9, P302, DOI 10.1111/1467-9507.00127
   Martin A, 2012, COGNITION, V123, P50, DOI 10.1016/j.cognition.2011.12.003
   Mitchell S, 2006, J DEV BEHAV PEDIATR, V27, pS69, DOI 10.1097/00004703-200604002-00004
   Moore R, 2017, BIOL PHILOS, V32, P797, DOI 10.1007/s10539-017-9598-7
   Morales M, 2000, J APPL DEV PSYCHOL, V21, P283, DOI 10.1016/S0193-3973(99)00040-4
   Mullen E., 1995, MULLEN SCALES EARLY
   Mundy P, 1998, INFANT BEHAV DEV, V21, P469, DOI 10.1016/S0163-6383(98)90020-0
   Nakano T, 2010, P ROY SOC B-BIOL SCI, V277, P2935, DOI 10.1098/rspb.2010.0587
   Oakes LM, 2010, INFANCY, V15, P1, DOI 10.1111/j.1532-7078.2010.00030.x
   Ozonoff S, 2015, J CHILD PSYCHOL PSYC, V56, P988, DOI 10.1111/jcpp.12421
   Ozonoff S, 2011, PEDIATRICS, V128, pE488, DOI 10.1542/peds.2010-2825
   Pfister R, 2013, TUTOR QUANT METHODS, V9, P72, DOI 10.20982/tqmp.09.2.p072
   Rosander K, 2011, NEUROPSYCHOLOGIA, V49, P2911, DOI 10.1016/j.neuropsychologia.2011.06.018
   Scott-Phillips TC, 2015, CURR ANTHROPOL, V56, P56, DOI 10.1086/679674
   Shic F, 2014, BIOL PSYCHIAT, V75, P231, DOI 10.1016/j.biopsych.2013.07.009
   Snedeker J., 2009, HDB CHILD LANGUAGE, P331, DOI [DOI 10.1017/CBO9780511576164, 10.1017/CBO9780511576164.018]
   Swanson MR, 2017, BIOL PSYCHIAT-COGN N, V2, P664, DOI 10.1016/j.bpsc.2017.07.007
   Tager-Flusberg H, 2016, J SPEECH LANG HEAR R, V59, P143, DOI 10.1044/2015_JSLHR-L-15-0146
   Thorgrimsson GB, 2015, INFANT BEHAV DEV, V39, P53, DOI 10.1016/j.infbeh.2015.02.002
   Tomasello M, 2008, JEAN NICOD LECT, P1
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Van Hecke AV, 2007, CHILD DEV, V78, P53
   von Hofsten C, 2009, RES AUTISM SPECT DIS, V3, P556, DOI 10.1016/j.rasd.2008.12.003
   Vouloumanos A, 2014, TRENDS COGN SCI, V18, P642, DOI 10.1016/j.tics.2014.10.001
   Vouloumanos A, 2014, DEVELOPMENTAL SCI, V17, P872, DOI 10.1111/desc.12170
   Vouloumanos A, 2014, COGNITIVE SCI, V38, P1675, DOI 10.1111/cogs.12128
   Vouloumanos A, 2009, P NATL ACAD SCI USA, V106, P18867, DOI 10.1073/pnas.0906049106
   Wellman HA, 2008, DEV PSYCHOL, V44, P618, DOI 10.1037/0012-1649.44.2.618
   Wellman HM, 2004, DEVELOPMENTAL SCI, V7, P283, DOI 10.1111/j.1467-7687.2004.00347.x
   Wodka EL, 2013, PEDIATRICS, V131, pE1128, DOI 10.1542/peds.2012-2221
   Yamashiro A, 2018, J EXP CHILD PSYCHOL, V173, P268, DOI 10.1016/j.jecp.2018.04.011
   Zwaigenbaum L, 2005, INT J DEV NEUROSCI, V23, P143, DOI 10.1016/j.ijdevneu.2004.05.001
NR 65
TC 1
Z9 1
U1 0
U2 2
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0012-1649
EI 1939-0599
J9 DEV PSYCHOL
JI Dev. Psychol.
PD MAY
PY 2019
VL 55
IS 5
BP 920
EP 933
DI 10.1037/dev0000676
PG 14
WC Psychology, Developmental
SC Psychology
GA HT2TE
UT WOS:000464415200002
PM 30730173
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Tsui, ASM
   Byers-Heinlein, K
   Fennell, CT
AF Tsui, Angeline Sin Mei
   Byers-Heinlein, Krista
   Fennell, Christopher T.
TI Associative Word Learning in Infancy: A Meta-Analysis of the Switch Task
SO DEVELOPMENTAL PSYCHOLOGY
LA English
DT Article
DE Switch task; infancy; word learning; speech perception; meta-analysis
ID PHONETIC DETAIL; CHILDRENS USE; DISTRIBUTIONAL INFORMATION; OBJECT
   ASSOCIATIONS; SPEECH-PERCEPTION; SOUND PATTERNS; FLEXIBILITY;
   ACQUISITION; VARIABILITY; MEANINGS
AB Associative word learning, the ability to pair a concept to a word, is an essential mechanism for early language development. One common method by which researchers measure this ability is the Switch task (Werker, Cohen, Lloyd, Casasola, & Stager, 1998), wherein infants are habituated to 2 word-object pairings and then tested on their ability to notice a switch in those pairings. In this comprehensive meta-analysis, we summarized 141 Switch task studies involving 2,723 infants of 12 to 20 months to estimate an average effect size for the task (random-effect model) and to explore how key experimental factors affect infants' performance (fixed-effect model). The average effect size was low to moderate in size, Cohen's d = 0.32. The use of language-typical and dissimilar-sounding words as well as the presence of additional facilitative cues aided performance, particularly for younger infants. Infants learning 2 languages at home outperformed those learning 1, indicating a bilingual advantage in learning word-object associations. Together, these findings support the Processing Rich Information from Multidimensional Interactive Representations (PRIMIR) theoretical framework of infant speech perception and word learning (e.g., Werker & Curtin, 2005), but invite further theoretical work to account for the observed bilingual advantage. Lastly, some of our analyses raised the possibility of questionable research practices in this literature. Therefore, we conclude with suggestions (e.g., preregistration, transparent data peeking, and alternate statistical approaches) for how to address this important issue.
C1 [Tsui, Angeline Sin Mei; Fennell, Christopher T.] Univ Ottawa, Sch Psychol, Ottawa, ON K1N 6N5, Canada.
   [Byers-Heinlein, Krista] Concordia Univ, Dept Psychol, Montreal, PQ, Canada.
RP Tsui, ASM (corresponding author), Univ Ottawa, Sch Psychol, Ottawa, ON K1N 6N5, Canada.
EM atsui029@uottawa.ca
OI Tsui, Angeline Sin Mei/0000-0003-0333-7234
FU Social Sciences and Humanities Research Council of Canada Insight Grant
   [435-2015-1974]; Natural Sciences and Engineering Research Council of
   Canada Discovery GrantNatural Sciences and Engineering Research Council
   of Canada (NSERC) [402470-2011]
FX This work was funded by a Social Sciences and Humanities Research
   Council of Canada Insight Grant (435-2015-1974) to Christopher T.
   Fennell and a Natural Sciences and Engineering Research Council of
   Canada Discovery Grant (402470-2011) to Krista Byers-Heinlein.
   Christopher T. Fennell holds the Official Languages and Bilingualism
   Institute Research Chair in Language Learning and Acquisition at the
   University of Ottawa; Krista Byers-Heinlein holds the Concordia
   University Research Chair in Bilingualism.
CR Aarts AA, 2015, SCIENCE, V349, DOI 10.1126/science.aac4716
   Altvater-Mackensen N, 2010, LINGUA, V120, P1898, DOI 10.1016/j.lingua.2010.02.010
   Apfelbaum KS, 2011, COGNITIVE SCI, V35, P1105, DOI 10.1111/j.1551-6709.2011.01181.x
   Archer S, 2014, J COGN DEV, V15, P110, DOI 10.1080/15248372.2012.728544
   BEGG CB, 1994, BIOMETRICS, V50, P1088, DOI 10.2307/2533446
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   Bergmann C, 2018, CHILD DEV, V89, P1996, DOI 10.1111/cdev.13079
   Bergmann C, 2016, DEVELOPMENTAL SCI, V19, P901, DOI 10.1111/desc.12341
   Best CT, 2009, PSYCHOL SCI, V20, P539, DOI 10.1111/j.1467-9280.2009.02327.x
   Bilson S, 2015, COGNITION, V140, P122, DOI 10.1016/j.cognition.2015.03.013
   Booth AE, 2005, DEV PSYCHOL, V41, P491, DOI 10.1037/0012-1649.41.3.491
   Borenstein M., 2009, INTRO METAANALYSIS, DOI [10.1002/9780470743386, DOI 10.1002/9780470743386]
   Borenstein M, 2010, RES SYNTH METHODS, V1, P97, DOI 10.1002/jrsm.12
   Braver SL, 2014, PERSPECT PSYCHOL SCI, V9, P333, DOI 10.1177/1745691614529796
   Brown C., 1997, FOCUS PHONOLOGICAL A, P67, DOI [10.1075/lald.16.05bro, DOI 10.1075/LALD.16.05BRO]
   Byers-Heinlein K, 2014, DEV PSYCHOBIOL, V56, P274, DOI 10.1002/dev.21167
   Byers-Heinlein K, 2013, BILING-LANG COGN, V16, P198, DOI 10.1017/S1366728912000417
   Carey S., 1978, PAPERS REPORTS CHILD, P17
   Chan CCY, 2011, DEV PSYCHOL, V47, P1459, DOI 10.1037/a0024049
   Cohen J., 1988, STAT POWER ANAL BEHA
   Core C, 2013, J SPEECH LANG HEAR R, V56, P1637, DOI 10.1044/1092-4388(2013/11-0044)
   Cumming G, 2014, PSYCHOL SCI, V25, P7, DOI 10.1177/0956797613504966
   Curtin S, 2012, J EXP CHILD PSYCHOL, V112, P127, DOI 10.1016/j.jecp.2012.02.007
   Curtin S, 2011, J PHONETICS, V39, P492, DOI 10.1016/j.wocn.2010.12.002
   Curtin S, 2009, J CHILD LANG, V36, P1157, DOI 10.1017/S0305000909009428
   Curtin S, 2009, DEVELOPMENTAL SCI, V12, P725, DOI 10.1111/j.1467-7687.2009.00814.x
   Dietrich C, 2007, P NATL ACAD SCI USA, V104, P16027, DOI 10.1073/pnas.0705270104
   Eason AE, 2017, INFANCY, V22, P470, DOI 10.1111/infa.12183
   Egger M, 1997, BMJ-BRIT MED J, V315, P629, DOI 10.1136/bmj.315.7109.629
   Estes KG, 2007, PSYCHOL SCI, V18, P254, DOI 10.1111/j.1467-9280.2007.01885.x
   Estes KG, 2015, CHILD DEV, V86, P1371, DOI 10.1111/cdev.12392
   Estes KG, 2014, J EXP CHILD PSYCHOL, V126, P313, DOI 10.1016/j.jecp.2014.05.006
   Estes KG, 2013, J EXP CHILD PSYCHOL, V114, P405, DOI 10.1016/j.jecp.2012.10.002
   Estes KG, 2013, INFANCY, V18, P797, DOI 10.1111/infa.12006
   Estes KG, 2011, INFANCY, V16, P180, DOI 10.1111/j.1532-7078.2010.00046.x
   Fais L., 2012, LAB PHONOLOGY, V3, P91, DOI DOI 10.1515/lp-2012-0007
   Fennell C. T., 2012, UNPUB
   Fennell C. T., 2014, COARTICULATORY UNPUB
   Fennell C. T., 2012, RES METHODS CHILD LA, P3, DOI DOI 10.1002/9781444344035.CH1
   Fennell C. T., 2016, BILINGUALISM LIFESPA, P43, DOI DOI 10.1037/14939-004
   Fennell C, 2014, INT J BEHAV DEV, V38, P309, DOI 10.1177/0165025414530631
   Fennell CT, 2007, CHILD DEV, V78, P1510, DOI 10.1111/j.1467-8624.2007.01080.x
   Fennell CT, 2006, PROC ANN BUCLD, P178
   Fennell CT, 2012, INFANCY, V17, P339, DOI 10.1111/j.1532-7078.2011.00080.x
   Fennell CT, 2010, CHILD DEV, V81, P1376, DOI 10.1111/j.1467-8624.2010.01479.x
   Fennell CT, 2003, LANG SPEECH, V46, P245, DOI 10.1177/00238309030460020901
   Fenson Larry, 1994, Monographs of the Society for Research in Child Development, V59, P1
   Ference J, 2015, INFANCY, V20, P242, DOI 10.1111/infa.12074
   FERGUSON CA, 1975, LANGUAGE, V51, P419, DOI 10.2307/412864
   Fikkert P, 2010, LAB PHONOL, V10, P227, DOI DOI 10.1515/9783110224917.3.227
   Galle ME, 2015, LANG LEARN DEV, V11, P66, DOI 10.1080/15475441.2014.895249
   Glass G V, 1981, METAANALYSIS SOCIAL
   Golinkoff RM, 2006, CURR DIR PSYCHOL SCI, V15, P30, DOI 10.1111/j.0963-7214.2006.00401.x
   Graf Estes Katharine, 2012, Front Psychol, V3, P447, DOI 10.3389/fpsyg.2012.00447
   Greenland S, 2016, EUR J EPIDEMIOL, V31, P337, DOI 10.1007/s10654-016-0149-3
   Harrell F.E., 2001, REGRESSION MODELING, P11, DOI DOI 10.1007/978-1-4757-3462-1_2
   Hay JF, 2015, CHILD DEV, V86, P10, DOI 10.1111/cdev.12269
   Hay JF, 2011, COGNITIVE PSYCHOL, V63, P93, DOI 10.1016/j.cogpsych.2011.06.002
   Higgins JPT, 2003, BRIT MED J, V327, P557, DOI 10.1136/bmj.327.7414.557
   Hunter M. A., 1988, ADV INFANCY RES, V1, P491
   John LK, 2012, PSYCHOL SCI, V23, P524, DOI 10.1177/0956797611430953
   JUSCZYK PW, 1993, J MEM LANG, V32, P402, DOI 10.1006/jmla.1993.1022
   JUSCZYK PW, 1994, J MEM LANG, V33, P630, DOI 10.1006/jmla.1994.1030
   Kovacs AM, 2009, P NATL ACAD SCI USA, V106, P6556, DOI 10.1073/pnas.0811323106
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Leon AC, 2009, COMPUT STAT DATA AN, V53, P603, DOI 10.1016/j.csda.2008.06.010
   Lindsay S. D., 2016, RES PREREGISTRATION
   MacKenzie H, 2012, DEVELOPMENTAL SCI, V15, P753, DOI 10.1111/j.1467-7687.2012.01166.x
   MacKenzie H, 2012, CHILD DEV, V83, P1129, DOI 10.1111/j.1467-8624.2012.01764.x
   MacKenzie H, 2011, DEVELOPMENTAL SCI, V14, P249, DOI 10.1111/j.1467-7687.2010.00975.x
   MacKenzie HK, 2014, DEV PSYCHOL, V50, P422, DOI 10.1037/a0033524
   Marcus GF, 2007, PSYCHOL SCI, V18, P387, DOI 10.1111/j.1467-9280.2007.01910.x
   MARKMAN EM, 1988, COGNITIVE PSYCHOL, V20, P121, DOI 10.1016/0010-0285(88)90017-5
   Mattock K, 2010, DEVELOPMENTAL SCI, V13, P229, DOI 10.1111/j.1467-7687.2009.00891.x
   May L, 2014, INFANCY, V19, P281, DOI 10.1111/infa.12048
   McMurray B, 2007, SCIENCE, V317, P631, DOI 10.1126/science.1144073
   MetaLab, 2016, INT TOOLS COMM AUGM
   Mitchell C, 2009, COGNITIVE SCI, V33, P1503, DOI 10.1111/j.1551-6709.2009.01071.x
   Moher D, 2010, INT J SURG, V8, P336, DOI [10.1371/journal.pmed.1000097, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.b2535]
   Morris SB, 2002, PSYCHOL METHODS, V7, P105, DOI 10.1037//1082-989X.7.1.105
   Pater J, 2004, LANGUAGE, V80, P384, DOI 10.1353/lan.2004.0141
   Peters JL, 2008, J CLIN EPIDEMIOL, V61, P991, DOI 10.1016/j.jclinepi.2007.11.010
   Rabagliati H, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12704
   Rost GC, 2010, INFANCY, V15, P608, DOI 10.1111/j.1532-7078.2010.00033.x
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Schott E, 2019, INFANT BEHAV DEV, V54, P166, DOI 10.1016/j.infbeh.2018.09.010
   Schwarzer G, 2015, META ANAL R, P28, DOI DOI 10.1007/978-3-319-21416-0
   Simmons JP, 2011, PSYCHOL SCI, V22, P1359, DOI 10.1177/0956797611417632
   Singh L, 2018, CHILD DEV, V89, pE183, DOI 10.1111/cdev.12747
   Singh L, 2015, CHILD DEV, V86, P294, DOI 10.1111/cdev.12271
   Sloutsky VM, 2008, COGNITIVE SCI, V32, P342, DOI 10.1080/03640210701863495
   Smith LB, 2003, COGNITION, V87, P209, DOI 10.1016/S0010-0277(02)00236-6
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Thiessen ED, 2007, J MEM LANG, V56, P16, DOI 10.1016/j.jml.2006.07.002
   Thiessen ED, 2016, J MEM LANG, V88, P117, DOI 10.1016/j.jml.2016.01.003
   Thiessen ED, 2011, DEV PSYCHOL, V47, P1448, DOI 10.1037/a0024439
   Thiessen ED, 2010, CHILD DEV, V81, P1287, DOI 10.1111/j.1467-8624.2010.01468.x
   Tincoff R, 2012, INFANCY, V17, P432, DOI 10.1111/j.1532-7078.2011.00084.x
   Tsui A. S. M., 2018, EFFECTS REFERE UNPUB
   Tsui A. S. M., 2016, EFFECTS COGNAT UNPUB
   Tsuji S, 2014, DEV PSYCHOBIOL, V56, P179, DOI 10.1002/dev.21179
   van de Schoot R, 2014, CHILD DEV, V85, P842, DOI 10.1111/cdev.12169
   Viechtbauer W, 2010, RES SYNTH METHODS, V1, P112, DOI 10.1002/jrsm.11
   Viechtbauer W, 2010, J STAT SOFTW, V36, P1, DOI 10.18637/jss.v036.i03
   Vukatana E, 2016, J CHILD LANG, V43, P1400, DOI 10.1017/S0305000915000707
   Waxman SR, 2009, TRENDS COGN SCI, V13, P258, DOI 10.1016/j.tics.2009.03.006
   Wellman HM, 2001, CHILD DEV, V72, P655, DOI 10.1111/1467-8624.00304
   Werker J. F., 2004, WEAVING LEXICON, P79
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Werker JF, 1998, DEV PSYCHOL, V34, P1289, DOI 10.1037/0012-1649.34.6.1289
   Zhao Q, 2014, THESIS
NR 114
TC 6
Z9 6
U1 0
U2 11
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0012-1649
EI 1939-0599
J9 DEV PSYCHOL
JI Dev. Psychol.
PD MAY
PY 2019
VL 55
IS 5
BP 934
EP 950
DI 10.1037/dev0000699
PG 17
WC Psychology, Developmental
SC Psychology
GA HT2TE
UT WOS:000464415200003
PM 30730174
DA 2021-02-24
ER

PT J
AU Farahani, ED
   Wouters, J
   van Wieringen, A
AF Farahani, Ehsan Darestani
   Wouters, Jan
   van Wieringen, Astrid
TI Contributions of non-primary cortical sources to auditory temporal
   processing
SO NEUROIMAGE
LA English
DT Article
DE Auditory steady-state responses; Bottom-up processing; Brain sources;
   EEG; Group-ICA
ID STEADY-STATE RESPONSES; MODULATION RATE; SPATIOTEMPORAL RECONSTRUCTION;
   SPECTRAL BANDWIDTH; BRAIN CONNECTIVITY; PHASE COHERENCE; SPEECH;
   AMPLITUDE; EEG; MEG
AB Temporal processing is essential for speech perception and directional hearing. However, the number and locations of cortical sources involved in auditory temporal processing are still a matter of debate. Using source reconstruction of human EEG responses, we show that, in addition to primary sources in the auditory cortices, sources outside the auditory cortex, designated as non-primary sources, are involved in auditory temporal processing. Non-primary sources within the left and right motor areas, the superior parietal lobe and the right occipital lobe were activated by amplitude-modulated stimuli, and were involved in the functional network. The robustness of these findings was checked for different stimulation conditions. The non-primary sources showed weaker phase-locking and lower activity than primary sources. These findings suggest that the non-primary sources belong to the non-primary auditory pathway. This pathway and non-primary sources detected in motor area explain how, in temporal prediction of upcoming stimuli and motor theory of speech perception, the motor area receives auditory inputs.
C1 [Farahani, Ehsan Darestani; Wouters, Jan; van Wieringen, Astrid] Univ Leuven, KU Leuven, Dept Neurosci, Res Grp Expt ORL, Leuven, Belgium.
RP Farahani, ED (corresponding author), Univ Leuven, KU Leuven, Dept Neurosci, Res Grp Expt ORL, Leuven, Belgium.
EM ehsan.darestani@kuleuven.be
RI Wouters, Jan/D-1800-2015
OI Wouters, Jan/0000-0002-0093-698X; Darestani Farahani,
   Ehsan/0000-0002-1559-3676
FU Research Council, KU LeuvenKU Leuven [OT/12/98]; Research Foundation
   Flanders through FWO-project [ZKC9024, ZKC5655]
FX This work was supported by the Research Council, KU Leuven through
   project OT/12/98 and by the Research Foundation Flanders through
   FWO-project ZKC9024 and FWO-project ZKC5655.
CR Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Arnal LH, 2015, CEREB CORTEX, V25, P3077, DOI 10.1093/cercor/bhu103
   Arnal LH, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00225
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Bastos AM, 2016, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00175
   Elgoyhen AB, 2015, NAT REV NEUROSCI, V16, P632, DOI 10.1038/nrn4003
   Bigdely-Shamlo N, 2015, FRONT NEUROINFORM, V9, DOI 10.3389/fninf.2015.00016
   Brenner CA, 2009, SCHIZOPHRENIA BULL, V35, P1065, DOI 10.1093/schbul/sbp091
   Calhoun Vince D, 2012, IEEE Rev Biomed Eng, V5, P60, DOI 10.1109/RBME.2012.2211076
   Cogan GB, 2011, J NEUROPHYSIOL, V106, P554, DOI 10.1152/jn.00075.2011
   Cuffin BN, 2001, CLIN NEUROPHYSIOL, V112, P2288, DOI 10.1016/S1388-2457(01)00669-1
   De Vos A, 2017, BRAIN LANG, V164, P106, DOI 10.1016/j.bandl.2016.10.002
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Delorme A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030135
   Devlin JT, 2006, NEUROIMAGE, V30, P1112, DOI 10.1016/j.neuroimage.2005.11.025
   Dobie RA, 1996, J ACOUST SOC AM, V100, P2236, DOI 10.1121/1.417933
   EFRON B, 1981, ANN STAT, V9, P586, DOI 10.1214/aos/1176345462
   Eggermont J. J, 2015, AUDITORY TEMPORAL PR, DOI [10.1093/acprof:oso/9780198719090.001.0001, DOI 10.1093/ACPROF:OSO/9780198719090.001.0001]
   Farahani ED, 2017, NEUROIMAGE, V148, P240, DOI 10.1016/j.neuroimage.2017.01.032
   Fujioka T, 2017, EUR J NEUROSCI, V46, P2339, DOI 10.1111/ejn.13693
   Fujioka T, 2012, J NEUROSCI, V32, P1791, DOI 10.1523/JNEUROSCI.4107-11.2012
   Giraud AL, 2000, J NEUROPHYSIOL, V84, P1588
   Goossens T, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00133
   Herdman AT, 2002, BRAIN TOPOGR, V15, P69, DOI 10.1023/A:1021470822922
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Holmes CJ, 1998, J COMPUT ASSIST TOMO, V22, P324, DOI 10.1097/00004728-199803000-00032
   Huster R. J., 2015, FRONT NEUROSCI, V9, P1, DOI DOI 10.3389/FNINS.2
   Javitt DC, 2015, NAT REV NEUROSCI, V16, P535, DOI 10.1038/nrn4002
   John C. M. S, 2000, JOHN PICTON 2000 HUM, V141, P57
   Koerner TK, 2015, HEARING RES, V328, P113, DOI 10.1016/j.heares.2015.08.002
   Kraus N, 2015, TRENDS COGN SCI, V19, P642, DOI 10.1016/j.tics.2015.08.017
   Kuriki S, 2013, HEARING RES, V296, P25, DOI 10.1016/j.heares.2012.11.002
   Lachaux JP, 1999, HUM BRAIN MAPP, V8, P194, DOI 10.1002/(SICI)1097-0193(1999)8:4<194::AID-HBM4>3.0.CO;2-C
   Li Y, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00009
   Luke R, 2017, NEUROIMAGE, V147, P568, DOI 10.1016/j.neuroimage.2016.11.023
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Medkour T, 2009, J NEUROSCI METH, V180, P374, DOI 10.1016/j.jneumeth.2009.04.003
   Mitra PP, 1999, BIOPHYS J, V76, P691, DOI 10.1016/S0006-3495(99)77236-X
   Moller AR, 2005, NEUROL RES, V27, P625, DOI 10.1179/016164105X25117
   Moller AR, 2002, NEUROSCI LETT, V319, P41, DOI 10.1016/S0304-3940(01)02516-2
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Nolan H, 2010, J NEUROSCI METH, V192, P152, DOI 10.1016/j.jneumeth.2010.07.015
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   ONTON J, 2009, FRONT HUM NEUROSCI, V3, P1, DOI DOI 10.3389/NEUR0.09.061.2009
   Onton J, 2006, NEUROSCI BIOBEHAV R, V30, P808, DOI 10.1016/j.neubiorev.2006.06.007
   Oostenveld R, 2003, CLIN NEUROPHYSIOL, V114, P1194, DOI 10.1016/S1388-2457(03)00059-2
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Overath T, 2012, J NEUROPHYSIOL, V107, P2042, DOI 10.1152/jn.00308.2011
   Palmer JA, 2008, INT CONF ACOUST SPEE, P1805, DOI 10.1109/ICASSP.2008.4517982
   Palmer JA, 2006, LECT NOTES COMPUT SC, V3889, P854
   Phipson B, 2010, STAT APPL GENET MOL, V9, DOI 10.2202/1544-6115.1585
   Picton T, 2013, EAR HEARING, V34, P385, DOI 10.1097/AUD.0b013e31827ada02
   Picton Terence W, 2005, J Am Acad Audiol, V16, P140, DOI 10.3766/jaaa.16.3.3
   Picton TW, 2003, INT J AUDIOL, V42, P177, DOI 10.3109/14992020309101316
   Picton TW, 2001, CLIN NEUROPHYSIOL, V112, P1698, DOI 10.1016/S1388-2457(01)00608-3
   Popescu M, 2008, IEEE T BIO-MED ENG, V55, P1092, DOI 10.1109/TBME.2007.906504
   Poulsen C, 2007, CEREB CORTEX, V17, P1454, DOI 10.1093/cercor/bhl056
   Reyes SA, 2005, HEARING RES, V204, P1, DOI 10.1016/j.heares.2004.11.016
   Reyes SA, 2004, HEARING RES, V194, P73, DOI 10.1016/j.heares.2004.04.001
   Rosenberg JR, 1998, J NEUROSCI METH, V83, P57, DOI 10.1016/S0165-0270(98)00061-2
   Ross B, 2000, J ACOUST SOC AM, V108, P679, DOI 10.1121/1.429600
   Ross B, 2005, CEREB CORTEX, V15, P2029, DOI 10.1093/cercor/bhi078
   Ross B, 2008, J NEUROPHYSIOL, V100, P1265, DOI 10.1152/jn.00048.2008
   Schoonhoven R, 2003, CLIN NEUROPHYSIOL, V114, P2096, DOI 10.1016/S1388-2457(03)00200-1
   Schroeder CE, 2009, TRENDS NEUROSCI, V32, P9, DOI 10.1016/j.tins.2008.09.012
   Schubotz RI, 2007, TRENDS COGN SCI, V11, P211, DOI 10.1016/j.tics.2007.02.006
   Spencer KM, 2012, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00190
   Steinmann I, 2011, NEUROIMAGE, V54, P495, DOI 10.1016/j.neuroimage.2010.07.064
   Teale P, 2008, NEUROIMAGE, V42, P1481, DOI 10.1016/j.neuroimage.2008.06.020
   Tian X, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00166
   Vakorin VA, 2010, NEUROIMAGE, V49, P1593, DOI 10.1016/j.neuroimage.2009.08.027
   van Mierlo P, 2014, PROG NEUROBIOL, V121, P19, DOI 10.1016/j.pneurobio.2014.06.004
   Vanvooren S, 2015, HEARING RES, V327, P153, DOI 10.1016/j.heares.2015.06.011
   Wang YD, 2012, J NEUROPHYSIOL, V107, P2033, DOI 10.1152/jn.00310.2011
   Weisz N, 2017, HEARING RES, V354, P102, DOI 10.1016/j.heares.2017.09.003
   Whitmer D, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00184
NR 77
TC 5
Z9 5
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD MAY 1
PY 2019
VL 191
BP 303
EP 314
DI 10.1016/j.neuroimage.2019.02.037
PG 12
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA HQ1GH
UT WOS:000462145700027
PM 30794868
DA 2021-02-24
ER

PT J
AU Dastpaak, H
   Alimohammadi, I
   Sameni, SJ
   Abolghaserni, J
   Vosoughi, S
AF Dastpaak, Hakimeh
   Alimohammadi, Iraj
   Sameni, Seyed Jalal
   Abolghaserni, Jamileh
   Vosoughi, Shahram
TI Effects of earplug hearing protectors on the intelligibility of Persian
   words in noisy environments
SO APPLIED ACOUSTICS
LA English
DT Article
DE Earplug; Hearing protector; Speech intelligibility; Noisy environment;
   Persian words
ID ROAD TRAFFIC NOISE; SPEECH-INTELLIGIBILITY; POLLUTION; EXPOSURE;
   WORKING; RATIOS
AB Purpose: Noise is one of the most important problems in the workplace. The main adverse effect of exposure to this physical pollutant is the hearing loss. For preventing such adverse effects, the use of hearing protective equipment is recommended. Despite the simplicity, hearing protective equipment can affect the correct perception of the words in a conversation.
   Methods: 32 students of Iran University of Medical Sciences with normal hearing were randomly selected and the speech intelligibility test (Speech Discrimination Test (SDS), using Ampaid plus, A177 audiometer) was performed on them. Each participant took the speech intelligibility test under four different conditions: without noise or earplugs, with noise but without earplugs, with noise and 25 Noise Reduction Rating (NRR) earplugs, with noise and 32 NRR earplugs. In each stage, the speech intelligibility test was repeated for each individual at signal-to-noise (S/N) ratios of +10, 0, and -10 (N = 85 dB, S = 75, 85, 95 dB).
   Results: The results demonstrated that maximum speech perception (89.75%) occurred without noise or earplugs, while minimum speech perception (8.13%) occurred with noise and without earplugs at S/N = -10. Results also revealed that hearing protectors (25 or 32 NNR earplugs) improve the average value of intelligibility. This value is greater with 25 NRR than with 32 NRR earplugs.
   Conclusion: Based on the results obtained, we can say that in the presence of background noise, hearing protectors increase the speech intelligibility; and the lower the NRR, the higher the intelligibility. Because of the inconsistent results of the studies in this field, and since speech interference and miscommunication in the workplace can lead to irreparable damage, more comprehensive research is required. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Dastpaak, Hakimeh; Vosoughi, Shahram] Iran Univ Med Sci, Sch Publ Hlth, Dept Occupat Hlth Engn, Tehran, Iran.
   [Alimohammadi, Iraj] Iran Univ Med Sci, Sch Rehabil Sci, Dept Occupat Hlth Engn, Occupat Hlth Res Ctr, Tehran, Iran.
   [Sameni, Seyed Jalal] Iran Univ Med Sci, Sch Rehabil Sci, Dept Audiol, Tehran, Iran.
   [Abolghaserni, Jamileh] Iran Univ Med Sci, Sch Publ Hlth, Dept Biostat, Tehran, Iran.
RP Alimohammadi, I (corresponding author), Iran Univ Med Sci, Sch Rehabil Sci, Dept Occupat Hlth Engn, Occupat Hlth Res Ctr, Tehran, Iran.
EM alimohammadi.i@iums.ac.ir
RI vosoughi, shahram/U-4914-2019; Abolghasemi, Jamileh/E-7534-2014
OI vosoughi, shahram/0000-0002-2672-3499; Abolghasemi,
   Jamileh/0000-0003-3898-2217; , Iraj/0000-0001-8353-6051
CR Alimohammadi I, 2010, IRAN J ENVIRON HEALT, V7, P25
   Alimohammadi I, 2017, APPL ACOUST, V126, P131, DOI 10.1016/j.apacoust.2017.05.021
   [Anonymous], 1998, DEV ASSESSMENT SPEEC
   Arezes PM, 2013, INT J IND ERGONOM, V43, P518, DOI 10.1016/j.ergon.2012.07.002
   Bockstael A, 2013, INT J IND ERGONOM, V43, P512, DOI 10.1016/j.ergon.2012.08.009
   Brammer AJ, 2012, NOISE HEALTH, V14, P281, DOI 10.4103/1463-1741.104894
   Oliveira CRD, 2012, REV BRAS ANESTESIOL, V62, P253, DOI 10.1016/S0034-7094(12)70123-X
   Fernandes JC, 2003, APPL ACOUST, V64, P581, DOI 10.1016/S0003-682X(02)00141-X
   Hammer MS, 2014, ENVIRON HEALTH PERSP, V122, P115, DOI 10.1289/ehp.1307272
   Helleman HW, 2015, INT J AUDIOL, V54, pS46, DOI 10.3109/14992027.2014.974114
   Kaliakatsos Dimitrios, 2015, Noise & Vibration Worldwide, V46, P8
   Ljung R, 2013, APPL COGNITIVE PSYCH, V27, P198, DOI 10.1002/acp.2896
   Nassiri P, 2014, J LOW FREQ NOISE V A, V33, P207, DOI 10.1260/0263-0923.33.2.207
   Nassiri P, 2011, INT J ENVIRON SCI TE, V8, P169, DOI 10.1007/BF03326206
   Norin JA, 2011, EAR HEARING, V32, P642, DOI 10.1097/AUD.0b013e31821478c8
   Organization WH, 2014, FACTS AB DEAFN
   Peng JX, 2010, APPL ACOUST, V71, P386, DOI 10.1016/j.apacoust.2009.10.004
   Dreossi Raquel Cecília Fischer, 2005, Pró-Fono R. Atual. Cient., V17, P251, DOI 10.1590/S0104-56872005000200014
   Shankar S, 2013, J ENVIRON PSYCHOL, V36, P87, DOI 10.1016/j.jenvp.2013.07.004
   Sorensen M, 2015, ENVIRON INT, V85, P238, DOI 10.1016/j.envint.2015.09.021
   Stansfeld SA, 2003, BRIT MED BULL, V68, P243, DOI 10.1093/bmb/ldg033
   Sulkowski Wieslaw J, 2004, Otolaryngol Pol, V58, P233
   Tufts JB, 2003, J ACOUST SOC AM, V114, P1069, DOI 10.1121/1.1592165
   Yuen FK, 2014, NOISE HEALTH, V16, P427, DOI 10.4103/1463-1741.144429
NR 24
TC 0
Z9 0
U1 1
U2 13
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0003-682X
EI 1872-910X
J9 APPL ACOUST
JI Appl. Acoust.
PD MAY
PY 2019
VL 148
BP 19
EP 22
DI 10.1016/j.apacoust.2018.11.017
PG 4
WC Acoustics
SC Acoustics
GA HO3SI
UT WOS:000460842800003
DA 2021-02-24
ER

PT J
AU Bakhtiar, M
   Zhang, CC
   Ki, SS
AF Bakhtiar, Mehdi
   Zhang, Caicai
   Ki, So Sze
TI Impaired processing speed in categorical perception: Speech perception
   of children who stutter
SO PLOS ONE
LA English
DT Article
ID NONWORD REPETITION ABILITIES; PRESCHOOL-CHILDREN; AUDITORY-FEEDBACK;
   BACKWARD-MASKING; YOUNG-CHILDREN; LEXICAL TONES; DISCRIMINATION;
   DYSLEXIA; IDENTIFICATION; EPIDEMIOLOGY
AB There have been controversial debates across multiple disciplines regarding the underlying mechanism of developmental stuttering. Stuttering is often related to issues in the speech production system; however, the presence and extent of a speech perception deficit is less clear. This study aimed to investigate the speech perception of children who stutter (CWS) using the categorical perception paradigm to examine their ability to categorize different acoustic variations of speech sounds into the same or different phonemic categories. In this study, 15 CWS and 16 children who do not stutter (CWNS) completed identification and discrimination tasks involving acoustic variations of Cantonese speech sounds in three stimulus contexts: consonants (voice onset times, VOTs), lexical tones, and vowels. The results showed similar categorical perception performance in boundary position and width in the identification task and similar d' scores in the discrimination task between the CWS and CWNS groups. However, the reaction times (RTs) were slower in the CWS group compared with the CWNS group in both tasks. Moreover, the CWS group had slower RTs in identifying stimuli located across categorical boundaries compared with stimuli located away from categorical boundaries. Overall, the data implied that the phoneme representation evaluated in speech perception might be intact in CWS as revealed by similar patterns in categorical perception as those in CWNS. However, the CWS group had slower processing speeds during categorical perception, which may indicate an insufficiency in accessing the phonemic representations in a timely manner, especially when the acoustic stimuli were ambiguous.
C1 [Bakhtiar, Mehdi; Zhang, Caicai; Ki, So Sze] Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Hong Kong, Peoples R China.
RP Bakhtiar, M (corresponding author), Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Hong Kong, Peoples R China.
EM m.bakhtiar@polyu.edu.hk
RI Zhang, Caicai/Q-6914-2018
OI Zhang, Caicai/0000-0002-7687-0518; Bakhtiar, Mehdi/0000-0001-6088-3106
CR Anderson JD, 2006, J FLUENCY DISORD, V31, P177, DOI 10.1016/j.jfludis.2006.05.001
   Anderson JD, 2010, J FLUENCY DISORD, V35, P216, DOI 10.1016/j.jfludis.2010.04.003
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Baayen R.H., 2008, ANAL LINGUISTIC DATA
   Backus O., 1938, ANN OTO RHINOL LARYN, V47, P632
   Bakhtiar Mehdi, 2007, Indian J Med Sci, V61, P462
   Basu S, 2018, J FLUENCY DISORD, V57, P11, DOI 10.1016/j.jfludis.2018.07.001
   Boersma P., 2014, PRAAT DOING PHONETIC
   Bogliotti C, 2008, J EXP CHILD PSYCHOL, V101, P137, DOI 10.1016/j.jecp.2008.03.006
   BRANDT J, 1980, BRAIN LANG, V9, P324, DOI 10.1016/0093-934X(80)90152-2
   Chen F, 2017, J CHILD LANG, V44, P1413, DOI 10.1017/S0305000916000581
   Cheour M, 2002, NEUROSCI LETT, V325, P187, DOI 10.1016/S0304-3940(02)00269-0
   Chon H. C., 2007, AM SPEECH LANG HEAR
   Corbera S, 2005, NEUROLOGY, V65, P1246, DOI 10.1212/01.wnl.0000180969.03719.81
   Craig A, 2002, J SPEECH LANG HEAR R, V45, P1097, DOI 10.1044/1092-4388(2002/088)
   Finney D. J., 1971, PROBIT ANAL
   GUITAR B, 2006, STUTTERING INTEGRATE
   Hakim HB, 2004, J FLUENCY DISORD, V29, P179, DOI 10.1016/j.jfludis.2004.06.001
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Hampton A, 2008, J FLUENCY DISORD, V33, P253, DOI 10.1016/j.jfludis.2008.08.001
   Harms MA, 1939, J SPEECH DISORD, V4, P363, DOI 10.1044/jshd.0404.363
   Hoonhorst I, 2011, SPEECH COMMUN, V53, P417, DOI 10.1016/j.specom.2010.11.005
   Howell P, 2000, PERCEPT MOTOR SKILL, V90, P355, DOI 10.2466/PMS.90.2.355-363
   Howell P, 2004, EAR HEARING, V25, P265, DOI 10.1097/01.AUD.0000130798.50938.EB
   HOWELL P, 1987, SPEECH MOTOR DYNAMIC, P361
   Howell P, 2006, J FLUENCY DISORD, V31, P257, DOI 10.1016/j.jfludis.2006.07.001
   Huang WT, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00829
   Jansson-Verkasalo E, 2014, J FLUENCY DISORD, V41, P1, DOI 10.1016/j.jfludis.2014.07.001
   Jiang CM, 2012, MEM COGNITION, V40, P1109, DOI 10.3758/s13421-012-0208-2
   Kaganovich N, 2010, DEV NEUROPSYCHOL, V35, P712, DOI 10.1080/87565641.2010.508549
   Kalinowski J, 1996, EUR J DISORDER COMM, V31, P259
   Kolk H., 1997, NATURE TREATMENT STU, P182
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Liu HM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095587
   MACLEOD J, 1995, J COMMUN DISORD, V28, P217, DOI 10.1016/0021-9924(94)00010-W
   Macmillan N. A., 2004, DETECTION THEORY USE, DOI [10.4324/9781410611147, DOI 10.4324/9781410611147]
   MARAIST JA, 1957, J SPEECH HEAR DISORD, V22, P385, DOI 10.1044/jshd.2203.385
   Massaro DW, 1987, SPEECH PERCEPTION EA, DOI [10.4324/9781315799742, DOI 10.4324/9781315799742]
   Matthews S., 2013, CANTONESE COMPREHENS
   Max L, 2004, CONT ISSUES COMMUN S, V31, P105, DOI [10.1044/cicsd_31_S_105., DOI 10.1044/CICSD_31_S_105]
   Neef NE, 2012, J SPEECH LANG HEAR R, V55, P276, DOI 10.1044/1092-4388(2011/10-0224)
   Pelczarski KM, 2016, J COMMUN DISORD, V62, P54, DOI 10.1016/j.jcomdis.2016.05.006
   Raven JC, 1938, RAVENS PROGR MATRICE, P72
   REICH A, 1981, J SPEECH HEAR RES, V24, P192, DOI 10.1044/jshr.2402.192
   Repp BH., 1984, SPEECH LANG ADV BASI, V10, P243, DOI DOI 10.1016/B978-0-12-608610-2.50012-1
   Riley G. D., 1994, STUTTERING SEVERITY
   Sasisekaran J, 2006, J FLUENCY DISORD, V31, P284, DOI 10.1016/j.jfludis.2006.08.001
   Sasisekaran J, 2013, INT J LANG COMM DIS, V48, P625, DOI 10.1111/1460-6984.12035
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   Smith A, 2012, J FLUENCY DISORD, V37, P344, DOI 10.1016/j.jfludis.2012.06.001
   Smits-Bandstra S, 2010, J FLUENCY DISORD, V35, P19, DOI 10.1016/j.jfludis.2009.12.002
   Spencer C, 2014, J FLUENCY DISORD, V41, P32, DOI 10.1016/j.jfludis.2014.06.001
   To C, 2007, HONG KONG CANTONESE
   Tong XH, 2014, PSYCHOPHYSIOLOGY, V51, P1158, DOI 10.1111/psyp.12257
   Ward D., 2008, STUTTERING CLUTTERIN
   Yairi E, 2013, J FLUENCY DISORD, V38, P66, DOI 10.1016/j.jfludis.2012.11.002
   Zhang C, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178986
   Zhang LJ, 2012, NEUROREPORT, V23, P35, DOI 10.1097/WNR.0b013e32834e4842
   Zhang YJ, 2012, J CHILD PSYCHOL PSYC, V53, P874, DOI 10.1111/j.1469-7610.2012.02528.x
   2001, INT J PSYCHOPHYSIOL, V40, P77
NR 60
TC 3
Z9 3
U1 0
U2 3
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD APR 26
PY 2019
VL 14
IS 4
AR e0216124
DI 10.1371/journal.pone.0216124
PG 18
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA HV2UQ
UT WOS:000465846200035
PM 31026270
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Walker, M
   Szakay, A
   Cox, F
AF Walker, Michael
   Szakay, Anita
   Cox, Felicity
TI Can kiwis and koalas as cultural primes induce perceptual bias in
   Australian English speaking listeners?
SO LABORATORY PHONOLOGY
LA English
DT Article
DE speech perception; vowel perception; sociophonetics; Australian English;
   New Zealand English
ID SPEECH-PERCEPTION; WORKING-MEMORY; TALKER GENDER; CAPACITY;
   IDENTIFICATION; RECOGNITION; INFORMATION
AB The presence of culturally significant objects has been shown to induce biases in speech perception consistent with features of the dialect relevant to the object. Questions remain about the transferability of this effect to different dialect contexts, and the efficacy of the task in inducing the effect. This paper details an Australian-context experiment modelled on Hay and Drager's (2010) New Zealand-context stuffed toy study. Seventy-five listeners heard spoken Australian English (AusE) phrases with phrase-final monosyllabic words containing either kit, DRESS, or TRAP vowels. Each phrase was followed by audio presentation of a six-step synthesized vowel continuum, from New Zealand English (NZE)-like to exaggerated AusE-like tokens. Listeners attempted to match one of the synthesized variants to the speaker's realization of the target vowel. Listeners were exposed to one of two priming conditions, established by stuffed toy kiwis (New Zealand) and stuffed toy koalas (Australia), or a control condition (no toy). Contrary to Hay and Drager (2010), token selections did not differ significantly between the New Zealand and Australian priming conditions. However, reversing the order of continuum presentation did significantly affect token selection for KIT vowels, raising questions about the task design itself. Results suggest that the influence of regional primes on speech perception may be more limited than previously thought.
C1 [Walker, Michael; Szakay, Anita; Cox, Felicity] Macquarie Univ, Dept Linguist, Ctr Language Sci, Sydney, NSW, Australia.
RP Walker, M (corresponding author), Macquarie Univ, Dept Linguist, Ctr Language Sci, Sydney, NSW, Australia.
EM michael.walker@mq.edu.au
OI Szakay, Anita/0000-0001-8124-0388; Cox, Felicity/0000-0001-8479-7624
FU Phonetics Lab at Macquarie University; Macquarie University
FX We would like to thank the Phonetics Lab at Macquarie University and the
   Macquarie linguistics writers' group for feedback and suggestions. Thank
   you to Peter Humburg for advice and assistance with the analysis and
   interpreting our data. We would also like to thank our two speakers and
   all participants, including pilot participants. Additional thanks to
   Katie Drager, Christian Langstrof, Kip Wilson, and two anonymous
   reviewers for insightful comments and helpful suggestions. Financial
   assistance was provided by the Research Training Pathway Scholarship
   from Macquarie University.
CR Babel M, 2015, J ACOUST SOC AM, V137, P2823, DOI 10.1121/1.4919317
   Babel M, 2010, LANG SOC, V39, P437, DOI 10.1017/S0047404510000400
   Baddeley A, 2010, CURR BIOL, V20, pR136, DOI 10.1016/j.cub.2009.12.014
   Bauer L., 2007, J INT PHON ASSOC, V37, P97, DOI DOI 10.1017/S0025100306002830
   Bauer L., 2004, HDB VARIETIES ENGLIS, V1, P580
   Bayard D., 2001, J SOCIOLING, V5, P22, DOI [10.1111/1467-9481.00136, DOI 10.1111/1467-9481.00136]
   Boersma P., 2014, PRAAT DOING PHONETIC
   Bybee J, 2006, LANGUAGE, V82, P711, DOI 10.1353/lan.2006.0186
   Catherine Watson, 2000, LANG VAR CHANGE, V12, P51, DOI [10.1017/S0954394500121039, DOI 10.1017/S0954394500121039]
   Christensen RHB, 2015, R PACKAGE VERSION, V2015, P6, DOI DOI 10.1016/S0022-5371(72)80001-X
   Clopper CG, 2004, J PHONETICS, V32, P111, DOI 10.1016/S0095-4470(03)00009-3
   Clopper CG, 2007, J PHONETICS, V35, P421, DOI 10.1016/j.wocn.2006.06.001
   Cowan N, 2001, BEHAV BRAIN SCI, V24, P87, DOI 10.1017/S0140525X01003922
   Cox F, 1999, PHONETICA, V56, P1, DOI 10.1159/000028438
   Cox F., 2007, J INT PHON ASSOC, V37, P341, DOI [10.1017/S0025100307003192, DOI 10.1017/S0025100307003192]
   Cox F., 2014, P 15 AUSTR INT C SPE, P33
   Cox F., 2006, AUST J LINGUIST, V26, P147, DOI DOI 10.1080/07268600600885494
   Cox F., 2014, AUSTR LING SOC C NEW
   Cox F, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P342
   Drager K., 2010, TE REO, V53, P27
   Drager K, 2011, LANG SPEECH, V54, P99, DOI 10.1177/0023830910388017
   EASTON A, 2000, AUST J LINGUIST, V20, P93, DOI DOI 10.1080/07268600020006021
   Foulkes P., 2010, HDB PHONETIC SCI, P703, DOI [10.1002/ 9781444317251. ch19, DOI 10.1002/9781444317251.CH19]
   Foulkes P, 2006, J PHONETICS, V34, P409, DOI 10.1016/j.wocn.2005.08.002
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Gordon E., 2004, NZ ENGLISH ITS ORIGI, DOI [10.1017/CBO9780511486678, DOI 10.1017/CBO9780511486678]
   Green P, 2016, METHODS ECOL EVOL, V7, P493, DOI 10.1111/2041-210X.12504
   Hay J, 2006, LINGUIST REV, V23, P351, DOI 10.1515/TLR.2006.014
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Jannedy S., 2011, P INT C PHON SCI ICP, P962
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   KINSBOURNE M, 1971, ACTA PSYCHOL, V35, P347, DOI 10.1016/0001-6918(71)90009-6
   Koops C, 2008, U PENNSYLVANIA WORKI, V14, P12
   Labov W., 2010, PRINCIPLES LINGUISTI, P48, DOI [10.1002/9781444327496.ch3, DOI 10.1002/9781444327496.CH3]
   LACERDA F, 1997, DISTRIBUTED ME UNPUB
   Lawrence D., 2015, SCOTTISH CONSORTIUM
   Li DW, 2013, ATTEN PERCEPT PSYCHO, V75, P145, DOI 10.3758/s13414-012-0383-z
   Luck SJ, 1997, NATURE, V390, P279, DOI 10.1038/36846
   Ludwig I., 2007, THESIS
   Maclagan M.A., 1999, LANG VAR CHANGE, V11, P19
   Maclagan M, 2007, LANG VAR CHANGE, V19, P1, DOI 10.1017/S0954394507070020
   MAY J, 1976, J ACOUST SOC AM, V59, pS25, DOI 10.1121/1.2002554
   McGowan KB, 2015, LANG SPEECH, V58, P502, DOI 10.1177/0023830914565191
   McLennan C. T., 2007, P 16 INT C PHON SCI, P67
   MEDIN DL, 1994, PSYCHON B REV, V1, P250, DOI 10.3758/BF03200776
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   Munson B, 2011, J ACOUST SOC AM, V130, P2631, DOI 10.1121/1.3641410
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Niedzielski N. A., 1997, THESIS
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Pierrehumbert JB, 2006, J PHONETICS, V34, P516, DOI 10.1016/j.wocn.2006.06.003
   Preston Dennis R., 1993, AM DIALECT RES, P333, DOI DOI 10.1075/Z.68.17PRE
   Psychology Software Tools, 2012, E PRIM 2 0
   R Core Team, 2016, R LANG ENV STAT COMP
   RUBIN DL, 1992, RES HIGH EDUC, V33, P511, DOI 10.1007/BF00973770
   Sanchez K, 2015, J PHONETICS, V48, P76, DOI 10.1016/j.wocn.2014.10.004
   SPERLING G, 1960, PSYCHOL MONOGR, V74, P1, DOI 10.1037/h0093759
   Squires L, 2013, J SOCIOLING, V17, P200, DOI 10.1111/josl.12025
   Strand EA, 1996, NATURAL LANGUAGE PROCESSING AND SPEECH TECHNOLOGY, P14
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   Thomas ER, 2002, AM SPEECH, V77, P115, DOI 10.1215/00031283-77-2-115
   Van Bezooijen R, 1999, J LANG SOC PSYCHOL, V18, P31, DOI 10.1177/0261927X99018001003
   Walker A, 2018, LINGUISTICS, V56, P257, DOI 10.1515/ling-2017-0036
   Watson C., 1998, AUST J LINGUIST, V18, P185, DOI DOI 10.1080/07268609808599567
   WEATHERALL A, 1998, TE REO, V41, P153
   Wedel AB, 2006, LINGUIST REV, V23, P247, DOI 10.1515/TLR.2006.010
   Wells John C., 1982, ACCENTS ENGLISH, DOI [10.1017/CBO9780511611759, DOI 10.1017/CBO9780511611759]
   Williams A., 1999, HDB PERCEPTUAL DIALE, DOI DOI 10.1075/Z.HPD1.29WIL
   ZWICKER E, 1961, J ACOUST SOC AM, V33, P248, DOI 10.1121/1.1908630
NR 72
TC 6
Z9 6
U1 0
U2 0
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD APR 9
PY 2019
VL 10
IS 1
AR 7
DI 10.5334/labphon.90
PG 29
WC Linguistics; Language & Linguistics
SC Linguistics
GA HZ4JR
UT WOS:000468814200001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Dugan, SH
   Silbert, N
   McAllister, T
   Preston, JL
   Sotto, C
   Boyce, SE
AF Dugan, Sarah Hamilton
   Silbert, Noah
   McAllister, Tara
   Preston, Jonathan L.
   Sotto, Carolyn
   Boyce, Suzanne E.
TI Modelling category goodness judgments in children with residual sound
   errors
SO CLINICAL LINGUISTICS & PHONETICS
LA English
DT Article
DE Speech perception; speech disorders; speech acoustics
ID SCHOOL-AGE-CHILDREN; SPEECH-PERCEPTION; ARTICULATION; DISCRIMINATION;
   IDENTIFICATION; DISORDERS; CATEGORIZATION; CONSISTENCY; SYLLABLES;
   CONTINUA
AB This study investigates category goodness judgments of /r/ in adults and children with and without residual speech errors (RSEs) using natural speech stimuli. Thirty adults, 38 children with RSE (ages 7-16) and 35 age-matched typically developing (TD) children provided category goodness judgments on whole words, recorded from 27 child speakers, with /r/ in various phonetic environments. The salient acoustic property of /r/ - the lowered third formant (F3) - was normalized in two ways. A logistic mixed-effect model quantified the relationships between listeners' responses and the third formant frequency, vowel context and clinical group status. Goodness judgments from the adult group showed a statistically significant interaction with the F3 parameter when compared to both child groups (p < 0.001) using both normalization methods. The RSE group did not differ significantly from the TD group in judgments of /r/. All listeners were significantly more likely to judge /r/ as correct in a front-vowel context. Our results suggest that normalized /r/ F3 is a statistically significant predictor of category goodness judgments for both adults and children, but children do not appear to make adult-like judgments. Category goodness judgments do not have a clear relationship with /r/ production abilities in children with RSE. These findings may have implications for clinical activities that include category goodness judgments in natural speech, especially for recorded productions.
C1 [Dugan, Sarah Hamilton; Silbert, Noah; Sotto, Carolyn; Boyce, Suzanne E.] Univ Cincinnati, Dept Commun Sci & Disorders, 3202 Eden Ave, Cincinnati, OH 45267 USA.
   [McAllister, Tara] NYU, Dept Commun Sci & Disorders, New York, NY USA.
   [Preston, Jonathan L.] Syracuse Univ, Dept Commun Sci & Disorders, Syracuse, NY USA.
RP Dugan, SH (corresponding author), Univ Cincinnati, Dept Commun Sci & Disorders, 3202 Eden Ave, Cincinnati, OH 45267 USA.
EM hamilsm@ucmail.uc.edu
RI ; Preston, Jonathan/E-9310-2010
OI Hamilton Dugan, Sarah/0000-0002-1063-7422; Preston,
   Jonathan/0000-0001-9971-6321
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [1R01DC013668-01];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC013668, R01DC013668, R01DC013668,
   R01DC013668] Funding Source: NIH RePORTER
FX This work was supported by the National Institutes of Health
   [#1R01DC013668-01].
CR Abboud H., 2017, SUPERLAB VERSION 5 0
   AUNGST LF, 1964, J SPEECH HEAR DISORD, V29, P76, DOI 10.1044/jshd.2901.76
   Bates D., 2017, PACKAGE LME4 LINEAR
   Beskow J., 2005, WAVESURFER VERSION 1
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Bradlow AR, 1996, SPEECH COMMUN, V20, P255, DOI 10.1016/S0167-6393(96)00063-5
   BROEN PA, 1983, J SPEECH HEAR RES, V26, P601, DOI 10.1044/jshr.2604.601
   Byun TM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0172022
   Byuna TM, 2017, J SPEECH LANG HEAR R, V60, P1175, DOI 10.1044/2016_JSLHR-S-16-0038
   Cabbage KL, 2016, SPEECH COMMUN, V82, P14, DOI 10.1016/j.specom.2016.05.002
   Campbell H, 2018, INT J SPEECH-LANG PA, V20, P635, DOI 10.1080/17549507.2017.1359334
   Espy-Wilson CY, 2000, J ACOUST SOC AM, V108, P343, DOI 10.1121/1.429469
   Flipsen P, 2001, CLIN LINGUIST PHONET, V15, P603
   GRAY AH, 1976, IEEE T ACOUST SPEECH, V24, P380, DOI 10.1109/TASSP.1976.1162849
   Gray S, 1992, LANG SPEECH HEAR SER, V23, P334, DOI DOI 10.1044/0161-1461.2304.334
   GRUNWELL P, 1988, CLIN LINGUIST PHONET, V2, P221, DOI 10.1080/02699208808985257
   Hagiwara R., 1995, THESIS
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   Hodson B., 1991, TARGETING INTELLIGIB
   HOFFMAN PR, 1983, J SPEECH HEAR DISORD, V48, P210, DOI 10.1044/jshd.4802.210
   HOFFMAN PR, 1985, J SPEECH HEAR DISORD, V50, P46, DOI 10.1044/jshd.5001.46
   Klein HB, 2012, CLIN LINGUIST PHONET, V26, P628, DOI 10.3109/02699206.2012.682695
   KOEGEL LK, 1986, J SPEECH HEAR DISORD, V51, P24, DOI 10.1044/jshd.5101.24
   Lehiste I., 1964, ACOUSTICAL CHARACTER
   LOCKE JL, 1980, J SPEECH HEAR DISORD, V45, P431, DOI 10.1044/jshd.4504.431
   MASSARO DW, 1983, SPEECH COMMUN, V2, P15, DOI 10.1016/0167-6393(83)90061-4
   McGowan RS, 2004, J ACOUST SOC AM, V115, P871, DOI 10.1121/1.1642624
   Mielke J., 2010, LAB PHONOLOGY, V10, P699, DOI DOI 10.1017/S0954394511000135
   MONNIN LM, 1974, J SPEECH HEAR RES, V17, P352, DOI 10.1044/jshr.1703.352
   NITTROUER S, 1989, J SPEECH HEAR RES, V32, P120, DOI 10.1044/jshr.3201.120
   Nittrouer S, 1997, J ACOUST SOC AM, V101, P2253, DOI 10.1121/1.418207
   OHDE RN, 1988, J SPEECH HEAR RES, V31, P556, DOI 10.1044/jshr.3104.556
   Preston JL, 2007, LANG SPEECH HEAR SER, V38, P297, DOI 10.1044/0161-1461(2007/032)
   Preston JL, 2015, SEMIN SPEECH LANG, V36, P224, DOI 10.1055/s-0035-1562906
   Preston JL, 2014, BRAIN LANG, V128, P25, DOI 10.1016/j.bandl.2013.11.001
   Preston JL, 2012, J SPEECH LANG HEAR R, V55, P1068, DOI 10.1044/1092-4388(2011/11-0056)
   Redle E, 2015, BRAIN RES, V1597, P47, DOI 10.1016/j.brainres.2014.11.047
   Robin X, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-77
   RUSCELLO DM, 1995, J COMMUN DISORD, V28, P279, DOI 10.1016/0021-9924(95)00058-X
   Rvachew S, 2002, CLIN LINGUIST PHONET, V16, P183, DOI 10.1080/02699200110112222
   RVACHEW S, 1989, J SPEECH HEAR DISORD, V54, P193, DOI 10.1044/jshd.5402.193
   RVACHEW S, 1994, J SPEECH HEAR RES, V37, P347, DOI 10.1044/jshr.3702.347
   SABEN CB, 1991, J SPEECH HEAR RES, V34, P1023, DOI 10.1044/jshr.3405.1023
   SHARF DJ, 1988, J SPEECH HEAR RES, V31, P193, DOI 10.1044/jshr.3102.193
   SHARF DJ, 1983, J SPEECH HEAR RES, V26, P525, DOI 10.1044/jshr.2604.525
   SHARF DJ, 1983, J SPEECH HEAR RES, V26, P516, DOI 10.1044/jshr.2604.516
   Shriberg L.D., 1987, LANGUAGE SPEECH HEAR, V18, DOI [10.1044/0161-1461.1802.144, DOI 10.1044/0161-1461.1802.144]
   SHRIBERG LD, 1993, J SPEECH HEAR RES, V36, P105, DOI 10.1044/jshr.3601.105
   Shriberg LD, 1997, J SPEECH LANG HEAR R, V40, P723, DOI 10.1044/jslhr.4004.723
   SHRIBERG LD, 1994, J SPEECH HEAR RES, V37, P1127, DOI 10.1044/jshr.3705.1127
   Shuster L. I., 1995, AM J SPEECH-LANG PAT, V4, P37, DOI DOI 10.1044/1058-0360.0402.37
   Shuster LI, 1998, J SPEECH LANG HEAR R, V41, P941, DOI 10.1044/jslhr.4104.941
   SMIT AB, 1983, J SPEECH HEAR RES, V26, P124, DOI 10.1044/jshr.2601.124
   Stavness I, 2012, J ACOUST SOC AM, V131, pEL355, DOI 10.1121/1.3695407
   Stevens Kenneth N, 1999, HDB PHONETIC SCI, V5, P462
   TREIMAN R, 1982, J PSYCHOLINGUIST RES, V11, P569, DOI 10.1007/BF01067613
   TYLER AA, 1990, J SPEECH HEAR DISORD, V55, P251, DOI 10.1044/jshd.5502.251
   Van Riper C., 1978, SPEECH CORRECTION PR
   Walley AC, 1999, J PHONETICS, V27, P307, DOI 10.1006/jpho.1999.0098
   Wolfe V, 2003, AM J SPEECH-LANG PAT, V12, P221, DOI 10.1044/1058-0360(2003/068)
NR 60
TC 2
Z9 2
U1 2
U2 7
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0269-9206
EI 1464-5076
J9 CLIN LINGUIST PHONET
JI Clin. Linguist. Phon.
PD APR 3
PY 2019
VL 33
IS 4
BP 295
EP 315
DI 10.1080/02699206.2018.1477834
PG 21
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA HP6DL
UT WOS:000461773000001
PM 29792525
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Kaylegian, K
   Stebritz, AJ
   Weible, AP
   Wehr, M
AF Kaylegian, Katherine
   Stebritz, Amanda J.
   Weible, Aldis P.
   Wehr, Michael
TI 5XFAD Mice Show Early Onset Gap Detection Deficits
SO FRONTIERS IN AGING NEUROSCIENCE
LA English
DT Article
DE Alzheimer's; gap detection; mouse model; auditory processing; acoustic
   startle response
ID ACOUSTIC STARTLE RESPONSE; MILD COGNITIVE IMPAIRMENT; AUDITORY-CORTEX;
   TEMPORAL RESOLUTION; INFERIOR COLLICULUS; ALZHEIMERS-DISEASE;
   SEX-DIFFERENCES; NOISE; AGE; LESIONS
AB Alzheimer's patients show auditory temporal processing deficits very early in disease progression, before the onset of major cognitive impairments. In addition to potentially contributing to speech perception and communication deficits in patients, this also represents a potential early biomarker for Alzheimer's. For this reason, tests of temporal processing such as gap detection have been proposed as an early diagnosis tool. For a biomarker such as gap detection deficits to have maximum clinical value, it is important to understand what underlying neuropathology it reflects. For example, temporal processing deficits could arise from alterations at cortical, midbrain, or brainstem levels. Mouse models of Alzheimer's disease can provide the ability to reveal in detail the molecular and circuit pathology underlying disease symptoms. Here we tested whether 5XFAD mice, a leading Alzheimer's mouse model, exhibit impaired temporal processing. We found that 5XFAD mice showed robust gap detection deficits. Gap detection deficits were first detectable at about 2 months of age and became progressively worse, especially for males and for longer gap durations. We conclude that 5XFAD mice are well-suited to serve as a model for understanding the circuit mechanisms that contribute to Alzheimer's-related gap detection deficits.
C1 [Kaylegian, Katherine; Stebritz, Amanda J.; Weible, Aldis P.; Wehr, Michael] Univ Oregon, Dept Psychol, Inst Neurosci, Eugene, OR 97403 USA.
RP Wehr, M (corresponding author), Univ Oregon, Dept Psychol, Inst Neurosci, Eugene, OR 97403 USA.
EM wehr@uoregon.edu
OI Weible, Aldis/0000-0001-8387-1124
FU NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R01 DC-015828]; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01DC015828, R01DC015828, R01DC015828, R01DC015828] Funding
   Source: NIH RePORTER
FX This work was supported by NIDCD R01 DC-015828.
CR Anderson LA, 2016, J NEUROSCI, V36, P1977, DOI 10.1523/JNEUROSCI.1652-15.2016
   Ardekani BA, 2016, J ALZHEIMERS DIS, V50, P847, DOI 10.3233/JAD-150780
   Bidelman GM, 2017, J NEUROSCI, V37, P3610, DOI 10.1523/JNEUROSCI.3700-16.2017
   Bowen GP, 2003, CEREB CORTEX, V13, P815, DOI 10.1093/cercor/13.8.815
   DEAN KF, 1990, PSYCHOBIOLOGY, V18, P89
   Devi L, 2010, MOL BRAIN, V3, DOI 10.1186/1756-6606-3-34
   Fitzgibbons P J, 1996, J Am Acad Audiol, V7, P183
   Friedman JT, 2004, DEV BRAIN RES, V152, P83, DOI 10.1016/j.devbrainres.2004.06.007
   Gates GA, 2002, J AM GERIATR SOC, V50, P482, DOI 10.1046/j.1532-5415.2002.50114.x
   GLASBERG BR, 1987, J ACOUST SOC AM, V81, P1546, DOI 10.1121/1.394507
   Hall AM, 2012, BRAIN RES BULL, V88, P3, DOI 10.1016/j.brainresbull.2011.11.017
   Iliadou V, 2017, J AM ACAD AUDIOL, V28, P463, DOI 10.3766/jaaa.16075
   ISON JR, 1991, BEHAV NEUROSCI, V105, P33, DOI 10.1037/0735-7044.105.1.33
   Jack CR, 2013, NEURON, V80, P1347, DOI 10.1016/j.neuron.2013.12.003
   Johnson KR, 2017, SCI REP-UK, V7, DOI 10.1038/srep44450
   Keller CH, 2018, J NEUROPHYSIOL, V120, P105, DOI 10.1152/jn.00911.2017
   Kelly JB, 1996, BEHAV NEUROSCI, V110, P542, DOI 10.1037/0735-7044.110.3.542
   Koch M, 1999, PROG NEUROBIOL, V59, P107, DOI 10.1016/S0301-0082(98)00098-7
   Mazure CM, 2016, LANCET NEUROL, V15, P451, DOI 10.1016/S1474-4422(16)00067-3
   O'Leary TP, 2017, GENES BRAIN BEHAV, V16, P554, DOI 10.1111/gbb.12370
   Oakley H, 2006, J NEUROSCI, V26, P10129, DOI 10.1523/JNEUROSCI.1202-06.2006
   PARHAM K, 1990, BEHAV NEUROSCI, V104, P831, DOI 10.1037/0735-7044.104.6.831
   Riedel BC, 2016, J STEROID BIOCHEM, V160, P134, DOI 10.1016/j.jsbmb.2016.03.012
   Smith NA, 2006, J SPEECH LANG HEAR R, V49, P1104, DOI 10.1044/1092-4388(2006/079)
   Snell KB, 2000, J ACOUST SOC AM, V107, P1615, DOI 10.1121/1.428446
   Swords GM, 2018, AGEING RES REV, V44, P49, DOI 10.1016/j.arr.2018.04.001
   Syka J, 2002, HEARING RES, V172, P151, DOI 10.1016/S0378-5955(02)00578-6
   Threlkeld SW, 2008, NEUROREPORT, V19, P893, DOI 10.1097/WNR.0b013e3283013d7e
   TREHUB SE, 1995, J ACOUST SOC AM, V98, P2532, DOI 10.1121/1.414396
   Tuwaig M, 2017, J ALZHEIMERS DIS, V60, P1589, DOI 10.3233/JAD-170545
   Walton JP, 1997, J COMP PHYSIOL A, V181, P161, DOI 10.1007/s003590050103
   Weibe AP, 2014, J NEUROSCI, V34, P15437, DOI 10.1523/JNEUROSCI.3408-14.2014
   Weible AP, 2014, CURR BIOL, V24, P1447, DOI 10.1016/j.cub.2014.05.031
   WERNER LA, 1992, CHILD DEV, V63, P260, DOI 10.2307/1131477
NR 34
TC 3
Z9 3
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1663-4365
J9 FRONT AGING NEUROSCI
JI Front. Aging Neurosci.
PD APR 2
PY 2019
VL 11
AR 66
DI 10.3389/fnagi.2019.00066
PG 9
WC Geriatrics & Gerontology; Neurosciences
SC Geriatrics & Gerontology; Neurosciences & Neurology
GA HR3WI
UT WOS:000463071500001
PM 31001105
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Yue, QH
   Martin, RC
   Hamilton, AC
   Rose, NS
AF Yue, Qiuhai
   Martin, Randi C.
   Hamilton, A. Cris
   Rose, Nathan S.
TI Non-perceptual Regions in the Left Inferior Parietal Lobe Support
   Phonological Short-term Memory: Evidence for a Buffer Account?
SO CEREBRAL CORTEX
LA English
DT Article
DE fMRI; inferior parietal lobe; multivariate pattern analysis;
   phonological short-term memory; speech perception
ID VERBAL WORKING-MEMORY; SUPERIOR TEMPORAL GYRUS; SURFACE-BASED ANALYSIS;
   PREFRONTAL CORTEX; BRAIN-REGIONS; SELECTIVE IMPAIRMENT; SUSTAINED
   ACTIVITY; NEURAL MECHANISMS; SPEECH-PERCEPTION; PATTERN-ANALYSIS
AB Buffer versus embedded processes accounts of short-term memory (STM) for phonological information were addressed by testing subjects' perception and memory for speech and non-speech auditory stimuli. Univariate and multivariate (MVPA) approaches were used to assess whether brain regions recruited in recognizing speech were involved in maintaining speech representations over a delay. As expected, a left superior temporal region was found to support speech perception. However, contrary to the embedded processes approach, this region failed to show a load effect, or any sustained activation, during a maintenance delay. Moreover, MVPA decoding during the maintenance stage was unsuccessful in this region by a perception classifier or an encoding classifier. In contrast, the left supramarginal gyrus showed both sustained activation and a load effect. Using MVPA, stimulus decoding was successful during the delay period. In addition, a functional connectivity analysis showed that, as memory load increased, the left temporal lobe involved in perception became more strongly connected with the parietal region involved in maintenance. Taken together, the findings provide greater support for a buffer than embedded processes account of phonological STM.
C1 [Yue, Qiuhai; Martin, Randi C.; Hamilton, A. Cris] Rice Univ, Dept Psychol, MS 25,POB 1892, Houston, TX 77251 USA.
   [Rose, Nathan S.] Univ Notre Dame, Dept Psychol, Notre Dame, IN 46556 USA.
RP Martin, RC (corresponding author), Rice Univ, Dept Psychol, MS 25,POB 1892, Houston, TX 77251 USA.
EM rmartin@rice.edu
RI Yue, Qiuhai/AAN-6810-2020
FU T.L.L. Temple Foundation Neuroplasticity Laboratory award; Rice
   University Social Sciences Research Institute (SSRI); Rice University
   SSRI Pre-dissertation Research grant; Dissertation Fellowship from the
   Dingwall Foundation
FX This work was supported by the T.L.L. Temple Foundation Neuroplasticity
   Laboratory award to Rice University, a Rice University Social Sciences
   Research Institute (SSRI) grant to R.C.M. and A.C.H., a Rice University
   SSRI Pre-dissertation Research grant and a Dissertation Fellowship from
   the Dingwall Foundation to Q.Y.
CR ALLPORT DA, 1984, ATTENTION PERFORM, V10, P313
   Aron AR, 2014, TRENDS COGN SCI, V18, P177, DOI 10.1016/j.tics.2013.12.003
   Arsenault JS, 2015, J NEUROSCI, V35, P634, DOI 10.1523/JNEUROSCI.2454-14.2015
   Baddeley A, 1998, PSYCHOL REV, V105, P158, DOI 10.1037/0033-295X.105.1.158
   BADDELEY A, 1984, Q J EXP PSYCHOL-A, V36, P233, DOI 10.1080/14640748408402157
   Baldo JV, 2012, APHASIOLOGY, V26, P338, DOI 10.1080/02687038.2011.602391
   Barbosa J, 2017, J NEUROSCI, V37, P8309, DOI 10.1523/JNEUROSCI.1547-17.2017
   Belleville S, 2003, J MEM LANG, V48, P686, DOI 10.1016/S0749-596X(02)00532-6
   Bettencourt KC, 2016, NAT NEUROSCI, V19, P150, DOI 10.1038/nn.4174
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   Bolkan SS, 2017, NAT NEUROSCI, V20, P987, DOI 10.1038/nn.4568
   Botvinick MM, 2006, PSYCHOL REV, V113, P201, DOI 10.1037/0033-295X.113.2.201
   Braver TS, 1997, NEUROIMAGE, V5, P49, DOI 10.1006/nimg.1996.0247
   Bray N, 2017, NAT REV NEUROSCI, V18, P385, DOI 10.1038/nrn.2017.70
   Buchsbaum BR, 2005, NEURON, V48, P687, DOI 10.1016/j.neuron.2005.09.029
   Buchsbaum BR, 2001, COGNITIVE SCI, V25, P663, DOI 10.1207/s15516709cog2505_2
   Burgess N, 1999, PSYCHOL REV, V106, P551, DOI 10.1037/0033-295X.106.3.551
   Burgess N, 2005, TRENDS COGN SCI, V9, P535, DOI 10.1016/j.tics.2005.09.011
   Button KS, 2013, NAT REV NEUROSCI, V14, P365, DOI 10.1038/nrn3475
   Chein JM, 2001, CEREB CORTEX, V11, P1003, DOI 10.1093/cercor/11.11.1003
   Christophel TB, 2015, NEUROIMAGE, V106, P198, DOI 10.1016/j.neuroimage.2014.11.018
   Christophel TB, 2012, J NEUROSCI, V32, P12983, DOI 10.1523/JNEUROSCI.0184-12.2012
   Cisler JM, 2014, NEUROIMAGE, V84, P1042, DOI 10.1016/j.neuroimage.2013.09.018
   Cohen JD, 1997, NATURE, V386, P604, DOI 10.1038/386604a0
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Cowan N, 2001, BEHAV BRAIN SCI, V24, P87, DOI 10.1017/S0140525X01003922
   Cowan N, 2011, J COGNITIVE NEUROSCI, V23, P2852, DOI 10.1162/jocn.2011.21625
   Cox RW, 2017, BRAIN CONNECT, V7, P152, DOI 10.1089/brain.2016.0475
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   Curtis CE, 2003, TRENDS COGN SCI, V7, P415, DOI 10.1016/S1364-6613(03)00197-9
   D'Esposito M, 2015, ANNU REV PSYCHOL, V66, P115, DOI 10.1146/annurev-psych-010814-015031
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   Eklund A, 2016, P NATL ACAD SCI USA, V113, P7900, DOI 10.1073/pnas.1602413113
   Emrich SM, 2013, J NEUROSCI, V33, P6516, DOI 10.1523/JNEUROSCI.5732-12.2013
   Ester EF, 2015, NEURON, V87, P893, DOI 10.1016/j.neuron.2015.07.013
   Fiebach CJ, 2006, NEURON, V51, P251, DOI 10.1016/j.neuron.2006.06.007
   Fischl B, 1999, NEUROIMAGE, V9, P195, DOI 10.1006/nimg.1998.0396
   Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318
   Friston KJ, 2019, NEUROIMAGE, V199, P730, DOI 10.1016/j.neuroimage.2017.02.045
   GATHERCOLE SE, 1989, J MEM LANG, V28, P200, DOI 10.1016/0749-596X(89)90044-2
   Gathercole SE, 1997, DEV PSYCHOL, V33, P966, DOI 10.1037/0012-1649.33.6.966
   GOLDMANRAKIC PS, 1995, NEURON, V14, P477, DOI 10.1016/0896-6273(95)90304-6
   Grootswagers T, 2017, J COGNITIVE NEUROSCI, V29, P677, DOI 10.1162/jocn_a_01068
   Gupta P, 2005, J MEM LANG, V53, P141, DOI 10.1016/j.jml.2004.12.002
   Gupta P, 2003, Q J EXP PSYCHOL-A, V56, P1213, DOI 10.1080/02724980343000071
   Harrison SA, 2009, NATURE, V458, P632, DOI 10.1038/nature07832
   Haxby JV, 2014, ANNU REV NEUROSCI, V37, P435, DOI 10.1146/annurev-neuro-062012-170325
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Jonides J, 1997, J COGNITIVE NEUROSCI, V9, P462, DOI 10.1162/jocn.1997.9.4.462
   Jonides J, 1998, J NEUROSCI, V18, P5026
   Jonides J, 2005, CURR DIR PSYCHOL SCI, V14, P2, DOI 10.1111/j.0963-7214.2005.00323.x
   Kalm K, 2014, J NEUROSCI, V34, P6879, DOI 10.1523/JNEUROSCI.4104-13.2014
   Kaminski J, 2017, NAT NEUROSCI, V20, P590, DOI 10.1038/nn.4509
   King AJ, 2009, NAT NEUROSCI, V12, P698, DOI 10.1038/nn.2308
   King JR, 2014, TRENDS COGN SCI, V18, P203, DOI 10.1016/j.tics.2014.01.002
   Kriegeskorte N, 2008, FRONT SYST NEUROSCI, V2, DOI 10.3389/neuro.06.004.2008
   Langel J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00440
   LaRocque JJ, 2017, CEREB CORTEX, V27, P4881, DOI 10.1093/cercor/bhw283
   LaRocque JJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00005
   Leavitt ML, 2017, TRENDS NEUROSCI, V40, P328, DOI 10.1016/j.tins.2017.04.004
   Lee SH, 2016, FRONT SYST NEUROSCI, V10, DOI 10.3389/fnsys.2016.00002
   Lee SH, 2013, NAT NEUROSCI, V16, P997, DOI 10.1038/nn.3452
   Leff AP, 2009, BRAIN, V132, P3401, DOI 10.1093/brain/awp273
   Lewis-Peacock JA, 2012, J COGNITIVE NEUROSCI, V24, P61, DOI 10.1162/jocn_a_00140
   Linke AC, 2015, J COGNITIVE NEUROSCI, V27, P1322, DOI 10.1162/jocn_a_00780
   Linke AC, 2011, P NATL ACAD SCI USA, V108, P12961, DOI 10.1073/pnas.1102118108
   Lundqvist M, 2016, NEURON, V90, P152, DOI 10.1016/j.neuron.2016.02.028
   Majerus S, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00357
   Majerus S, 2012, CEREB CORTEX, V22, P1086, DOI 10.1093/cercor/bhr174
   Martin N, 1997, COGNITIVE NEUROPSYCH, V14, P641
   Martin RC, 2005, CURR DIR PSYCHOL SCI, V14, P204, DOI 10.1111/j.0963-7214.2005.00365.x
   MARTIN RC, 1992, COGNITIVE NEUROPSYCH, V9, P509, DOI 10.1080/02643299208252070
   Martin RC, 2003, J NEUROLINGUIST, V16, P341, DOI 10.1016/S0911-6044(03)00025-3
   Martin RC, 1999, J MEM LANG, V41, P3, DOI 10.1006/jmla.1999.2637
   McLaren DG, 2012, NEUROIMAGE, V61, P1277, DOI 10.1016/j.neuroimage.2012.03.068
   Mendoza-Halliday D, 2014, NAT NEUROSCI, V17, P1255, DOI 10.1038/nn.3785
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Mongillo G, 2008, SCIENCE, V319, P1543, DOI 10.1126/science.1150769
   Myers NE, 2017, TRENDS COGN SCI, V21, P449, DOI 10.1016/j.tics.2017.03.010
   Narayanan NS, 2005, NEUROPSYCHOLOGY, V19, P223, DOI 10.1037/0894-4105.19.2.223
   Nee DE, 2013, CEREB CORTEX, V23, P264, DOI 10.1093/cercor/bhs007
   Norman KA, 2006, TRENDS COGN SCI, V10, P424, DOI 10.1016/j.tics.2006.07.005
   Oberauer K, 2009, COGNITIVE PSYCHOL, V58, P102, DOI 10.1016/j.cogpsych.2008.05.003
   Obleser J, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00232
   PAULESU E, 1993, NATURE, V362, P342, DOI 10.1038/362342a0
   Paulesu E, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00231
   Postle BR, 1999, P NATL ACAD SCI USA, V96, P12959, DOI 10.1073/pnas.96.22.12959
   Postle BR, 2006, NEUROSCIENCE, V139, P23, DOI 10.1016/j.neuroscience.2005.06.005
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Price CJ, 2010, ANN NY ACAD SCI, V1191, P62, DOI 10.1111/j.1749-6632.2010.05444.x
   Ravizza SM, 2004, NEUROIMAGE, V22, P562, DOI 10.1016/j.neuroimage.2004.01.039
   Ravizza SM, 2011, NEUROIMAGE, V55, P1836, DOI 10.1016/j.neuroimage.2010.12.021
   Riggall AC, 2012, J NEUROSCI, V32, P12990, DOI 10.1523/JNEUROSCI.1892-12.2012
   Rissman J, 2008, CEREB CORTEX, V18, P1618, DOI 10.1093/cercor/bhm195
   Romero L, 2006, J COGNITIVE NEUROSCI, V18, P1147, DOI 10.1162/jocn.2006.18.7.1147
   Rose NS, 2016, SCIENCE, V354, P1136, DOI 10.1126/science.aah7011
   ROUX F, 2014, SCI ENG ETHICS, V18, P16, DOI DOI 10.1016/J.TICS.2013.10.010
   Rypma B, 1999, NEUROIMAGE, V9, P216, DOI 10.1006/nimg.1998.0404
   Rypma B, 1999, P NATL ACAD SCI USA, V96, P6558, DOI 10.1073/pnas.96.11.6558
   Saad ZS, 2012, NEUROIMAGE, V62, P768, DOI 10.1016/j.neuroimage.2011.09.016
   SALAME P, 1982, J VERB LEARN VERB BE, V21, P150, DOI 10.1016/S0022-5371(82)90521-7
   Salmon E, 1996, BRAIN, V119, P1617, DOI 10.1093/brain/119.5.1617
   Schneegans S, 2017, J COGNITIVE NEUROSCI, V29, P1977, DOI 10.1162/jocn_a_01180
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   Serences JT, 2009, PSYCHOL SCI, V20, P207, DOI 10.1111/j.1467-9280.2009.02276.x
   SHALLICE T, 1977, BRAIN LANG, V4, P479, DOI 10.1016/0093-934X(77)90040-2
   Shallice T., 1990, NEUROPSYCHOLOGICAL I, P11, DOI [10.1017/CBO9780511665547.003, DOI 10.1017/CBO9780511665547.003]
   Siebenhuhner F, 2016, ELIFE, V5, DOI 10.7554/eLife.13451
   Smith EE, 1998, P NATL ACAD SCI USA, V95, P876, DOI 10.1073/pnas.95.3.876
   Smith EE, 1998, P NATL ACAD SCI USA, V95, P12061, DOI 10.1073/pnas.95.20.12061
   Sreenivasan KK, 2014, TRENDS COGN SCI, V18, P82, DOI 10.1016/j.tics.2013.12.001
   STERNBERG S, 1966, SCIENCE, V153, P652, DOI 10.1126/science.153.3736.652
   Stokes MG, 2015, TRENDS COGN SCI, V19, P394, DOI 10.1016/j.tics.2015.05.004
   Talairach J, 1988, COPLANAR STEREOTAXIC
   Todd JJ, 2005, PSYCHOL SCI, V16, P965, DOI 10.1111/j.1467-9280.2005.01645.x
   Turkeltaub PE, 2010, BRAIN LANG, V114, P1, DOI 10.1016/j.bandl.2010.03.008
   VALLAR G, 1984, J VERB LEARN VERB BE, V23, P151, DOI 10.1016/S0022-5371(84)90104-X
   VALLAR G, 1995, HDB MEMORY DISORDERS, P135
   Vigneau M, 2006, NEUROIMAGE, V30, P1414, DOI 10.1016/j.neuroimage.2005.11.002
   Wager TD, 2004, NEUROIMAGE, V22, P1679, DOI 10.1016/j.neuroimage.2004.03.052
   WARRINGTON EK, 1969, BRAIN, V92, P885, DOI 10.1093/brain/92.4.885
   WARRINGTON EK, 1971, NEUROPSYCHOLOGIA, V9, P377, DOI 10.1016/0028-3932(71)90002-9
   Watanabe K, 2014, NAT NEUROSCI, V17, P601, DOI 10.1038/nn.3667
   Wolff MJ, 2017, NAT NEUROSCI, V20, P864, DOI 10.1038/nn.4546
   Xu YD, 2017, TRENDS COGN SCI, V21, P794, DOI 10.1016/j.tics.2017.06.013
   Xu YD, 2006, NATURE, V440, P91, DOI 10.1038/nature04262
   Yarkoni T, 2009, PERSPECT PSYCHOL SCI, V4, P294, DOI 10.1111/j.1745-6924.2009.01127.x
   Zarahn E, 2005, CEREB CORTEX, V15, P303, DOI 10.1093/cercor/bhh132
NR 128
TC 13
Z9 13
U1 3
U2 7
PU OXFORD UNIV PRESS INC
PI CARY
PA JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA
SN 1047-3211
EI 1460-2199
J9 CEREB CORTEX
JI Cereb. Cortex
PD APR
PY 2019
VL 29
IS 4
BP 1398
EP 1413
DI 10.1093/cercor/bhy037
PG 16
WC Neurosciences
SC Neurosciences & Neurology
GA IS5GP
UT WOS:000482180900002
PM 29522178
DA 2021-02-24
ER

PT J
AU Palaz, D
   Magimai-Doss, M
   Collobert, R
AF Palaz, Dimitri
   Magimai-Doss, Mathew
   Collobert, Ronan
TI End-to-end acoustic modeling using convolutional neural networks for
   HMM-based automatic speech recognition
SO SPEECH COMMUNICATION
LA English
DT Article
DE Automatic speech recognition; Hidden Markov models; Deep learning;
   Feature learning; Artificial neural networks; Convolution neural
   networks; Hybrid HMM/ANN
ID EXTRACTION
AB In hidden Markov model (HMM) based automatic speech recognition (ASR) system, modeling the statistical relationship between the acoustic speech signal and the HMM states that represent linguistically motivated subword units such as phonemes is a crucial step. This is typically achieved by first extracting acoustic features from the speech signal based on prior knowledge such as, speech perception or/and speech production knowledge, and, then training a classifier such as artificial neural networks (ANN), Gaussian mixture model that estimates the emission probabilities of the HMM states. This paper investigates an end-to-end acoustic modeling approach using convolutional neural networks (CNNs), where the CNN takes as input raw speech signal and estimates the HMM states class conditional probabilities at the output. Alternately, as opposed to a divide and conquer strategy (i.e., separating feature extraction and statistical modeling steps), in the proposed acoustic modeling approach the relevant features and the classifier are jointly learned from the raw speech signal. Through ASR studies and analyses on multiple languages and multiple tasks, we show that: (a) the proposed approach yields consistently a better system with fewer parameters when compared to the conventional approach of cepstral feature extraction followed by ANN training, (b) unlike conventional method of speech processing, in the proposed approach the relevant feature representations are learned by first processing the input raw speech at the sub-segmental level (approximate to 2 ms). Specifically, through an analysis we show that the filters in the first convolution layer automatically learn "in-parts" formant-like information present in the sub-segmental speech, and (c) the intermediate feature representations obtained by subsequent filtering of the first convolution layer output are more discriminative compared to standard cepstral features and could be transferred across languages and domains.
C1 [Palaz, Dimitri] Speech Graph Ltd, Edinburgh, Midlothian, Scotland.
   [Palaz, Dimitri; Magimai-Doss, Mathew; Collobert, Ronan] Idiap Res Inst, Martigny, Switzerland.
   [Palaz, Dimitri] Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
   [Collobert, Ronan] Facebook AI Res, Menlo Pk, CA USA.
RP Palaz, D (corresponding author), Speech Graph Ltd, Edinburgh, Midlothian, Scotland.
EM dpalaz@speech-graphics.com; mathew@idiap.ch; ronan@collobert.com
FU HASA IT foundation through the grant "Universal Spoken Term Detection
   with Deep Learning" (DeepSTD) [11103]; HASA IT foundation through the
   grant "Universal Spoken Term Detection with Deep Learning" (DeepSTD-ext)
   [14050]
FX This work was supported by the HASA IT foundation
   (www.haslersliftung.cum) through the grant "Universal Spoken Term
   Detection with Deep Learning" (DeepSTD, project no. 11103 and
   DeepSTD-ext, project no. 14050). This work in its entirety was carried
   out at the Idiap Research Institute, Martigny, Switzerland, an
   independent not-for-profit research foundation. The authors would like
   to thank Dr. Ramya Rasipuram and Marzieh Razavi for their help with
   setting up Wall Street Journal and Mediaparl studies, and S Pavankumar
   Dubaganta for the help with additional experiments for rebuttal. The
   authors would also like to thank Dr. Michael Liebling for his critical
   inputs regarding the analysis of the first convolution layer in Section
   5.1.3. We would like to thank the reviewers for their valuable time and
   feedback.
CR Abdel-Hamid O, 2013, INTERSPEECH, P1848
   Abdel-Hamid O, 2013, INTERSPEECH, P1247
   Abdel-Hamid O, 2012, INT CONF ACOUST SPEE, P4277, DOI 10.1109/ICASSP.2012.6288864
   Amodei D., 2015, ARXIV151202595
   Bengio Y., 2006, ADV NEURAL INFORM PR, P153, DOI DOI 10.7551/mitpress/7503.003.0024
   Biem A, 2001, IEEE T SPEECH AUDI P, V9, P96, DOI 10.1109/89.902277
   Bottou L., 1991, P NEUR 91 NIM FRANC, V91, pEC2
   Bourlard Herve, 1994, CONNECTIONIST SPEECH, V247
   Bridle John S., 1990, NEUROCOMPUTING, P227, DOI DOI 10.1007/978-3-642-76153-9_28
   Chorowski J., 2015, P ANN C NEUR INF PRO
   Collobert R, 2011, BIGLEARN NIPS WORKSH
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Collobert Ronan, 2004, THESIS
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   DENG L, 2003, SPEECH PROCESSING DY
   Ephraim Y, 2005, IEEE SIGNAL PROC LET, V12, P166, DOI 10.1109/LSP.2004.840914
   Furui S., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P1991
   Gales MJF, 1996, COMPUT SPEECH LANG, V10, P249, DOI 10.1006/csla.1996.0013
   Garofolo J.S., 1993, 93 NASA STI REC
   Golik P, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P26
   Graves A., 2014, P INT C MACH LEARN, P1764, DOI DOI 10.1145/1143844.1143891
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   He K., 2015, ARXIV151203385
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Hermansky H, 1998, SPEECH COMMUN, V25, P3, DOI 10.1016/S0167-6393(98)00027-2
   Hifny Y, 2009, IEEE T AUDIO SPEECH, V17, P354, DOI 10.1109/TASL.2008.2010286
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Honig F., 2005, P INTERSPEECH 2005 L, P2997
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Imseng D, 2012, IEEE W SP LANG TECH, P263, DOI 10.1109/SLT.2012.6424233
   Jaitly N, 2011, INT CONF ACOUST SPEE, P5884
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kusy B, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN 2009), P109
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LEE KF, 1989, IEEE T ACOUST SPEECH, V37, P1641, DOI 10.1109/29.46546
   Lu L., 2016, ARXIV160300223
   Mesot B, 2007, IEEE T AUDIO SPEECH, V15, P1850, DOI 10.1109/TASL.2007.901312
   Mohamed A., 2009, NIPS WORKSH DEEP LEA
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Muckenhirn H., 2017, P INT JOINT C BIOM
   Muckenhirn H., 2018, IEEE INT C AC SPEECH
   Nair V, 2010, ICML, V27, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Palaz D., 2013, NIPS DEEP LEARN WORK
   Palaz D., 2013, P ANN C INT SPEECH C
   Palaz D., 2014, ARXIV14127110
   Palaz D., 2016, THESIS
   Palaz D, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P11
   PAUL DB, 1992, SPEECH AND NATURAL LANGUAGE, P357
   Poritz A., 1982, IEEE C AC NEW YORK S, V7, P1291, DOI DOI 10.1109/ICASSP.1982.1171633
   Rabiner L. R., 1993, FUNDAMENTALS SPEECH
   RABINER LR, 1975, DIGITAL PROCESSING S
   Rath SP, 2013, INTERSPEECH, P109
   Razavi M, 2014, INT CONF ACOUST SPEE
   ROBINSON AJ, 1994, IEEE T NEURAL NETWOR, V5, P298, DOI 10.1109/72.279192
   Sainath TN, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Schroeder M. R., 1985, P IEEE INT C AC SPEE, V10, P937, DOI DOI 10.1109/ICASSP.1985.1168147
   Seide F, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P444
   Sheikhzadeh H, 1994, IEEE T SPEECH AUDI P, V2, P80, DOI 10.1109/89.260337
   Swietojanski P, 2016, IEEE-ACM T AUDIO SPE, V24, P1450, DOI 10.1109/TASLP.2016.2560534
   Swietojanski P, 2014, IEEE SIGNAL PROC LET, V21, P1120, DOI 10.1109/LSP.2014.2325781
   Tuske Z, 2014, INTERSPEECH, P890
   Vesely K, 2013, INTERSPEECH, P2344
   WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701
   Woodland P., 1994, P IEEE INT C AC SPEE, V2
   Yegnanarayana B, 1998, IEEE T SPEECH AUDI P, V6, P313, DOI 10.1109/89.701359
   Young RR, 2002, CUR CLIN NEUROL, P3
   Yousafzai J., 2009, P INT, P2391
   Zeiler MD, 2013, INT CONF ACOUST SPEE, P3517, DOI 10.1109/ICASSP.2013.6638312
NR 72
TC 15
Z9 15
U1 3
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-6393
EI 1872-7182
J9 SPEECH COMMUN
JI Speech Commun.
PD APR
PY 2019
VL 108
BP 15
EP 32
DI 10.1016/j.specom.2019.01.004
PG 18
WC Acoustics; Computer Science, Interdisciplinary Applications
SC Acoustics; Computer Science
GA IE9HA
UT WOS:000472684300002
DA 2021-02-24
ER

PT J
AU Marklund, E
   Schwarz, IC
   Lacerda, F
AF Marklund, Ellen
   Schwarz, Iris-Corinna
   Lacerda, Francisco
TI Amount of speech exposure predicts vowel perception in four- to
   eight-month-olds
SO DEVELOPMENTAL COGNITIVE NEUROSCIENCE
LA English
DT Article
DE Mismatch negativity; MMN; Mismatch response; MMR; ERP; EEG; Speech
   perception; Language exposure; Speech exposure; LENA; Infants; Swedish
ID MISMATCH NEGATIVITY; PHONETIC PERCEPTION; BRAIN RESPONSES; LANGUAGE
   INPUT; 1ST YEAR; INFANTS; EXPERIENCE; DISCRIMINATION; REPRESENTATION;
   POTENTIALS
AB During the first year of life, infants shift their focus in speech perception from acoustic to linguistic information. This perceptual reorganization is related to exposure, and a direct relation has previously been demonstrated between amount of daily language exposure and mismatch response (MMR) amplitude to a native consonant contrast at around one year of age. The present study investigates the same relation between amount of speech exposure and MMR amplitude to a native vowel contrast at four to eight months of age. Importantly, the present study uses spectrally rotated speech in an effort to take general neural maturation into account. The amplitude of the part of the MMR that is tied specifically to speech processing correlates with amount of daily speech exposure, as estimated using the LENA system.
C1 [Marklund, Ellen; Schwarz, Iris-Corinna; Lacerda, Francisco] Stockholm Univ, Dept Linguist, SE-10691 Stockholm, Sweden.
RP Marklund, E (corresponding author), Stockholm Univ, Dept Linguist, SE-10691 Stockholm, Sweden.
EM ellen.marklund@ling.su.se
OI Marklund, Ellen/0000-0001-7658-9307; Schwarz,
   Iris-Corinna/0000-0002-8036-516X
FU Stockholm University, Sweden [SU-15300]; Marcus and Amalia Wallenberg
   Foundation, Sweden [MAW 2013.0056]
FX The research in this paper was funded by Stockholm University
   (SU-15300), Sweden, and Marcus and Amalia Wallenberg Foundation (MAW
   2013.0056), Sweden. The authors would like to thank all participants and
   their parents for their contribution, Fredrik Myr and Klara Hjerpe for
   help with data collection, and the reviewers for many helpful comments.
CR BLESSER B, 1972, J SPEECH HEAR RES, V15, P5, DOI 10.1044/jshr.1501.05
   Bosch L, 2003, LANG SPEECH, V46, P217, DOI 10.1177/00238309030460020801
   Burns TC, 2007, APPL PSYCHOLINGUIST, V28, P455, DOI 10.1017/S0142716407070257
   Cheour M, 1998, NAT NEUROSCI, V1, P351, DOI 10.1038/1561
   Cheour M, 2001, AUDIOL NEURO-OTOL, V6, P2, DOI 10.1159/000046804
   Conboy BT, 2011, DEVELOPMENTAL SCI, V14, P242, DOI 10.1111/j.1467-7687.2010.00973.x
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dien J, 2010, J NEUROSCI METH, V187, P138, DOI 10.1016/j.jneumeth.2009.12.009
   Garcia-Sierra A, 2016, INT J PSYCHOPHYSIOL, V110, P1, DOI 10.1016/j.ijpsycho.2016.10.004
   Garcia-Sierra A, 2011, J PHONETICS, V39, P546, DOI 10.1016/j.wocn.2011.07.002
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   KUHL PK, 1994, CURR OPIN NEUROBIOL, V4, P812, DOI 10.1016/0959-4388(94)90128-7
   Kuhl PK, 2003, P NATL ACAD SCI USA, V100, P9096, DOI 10.1073/pnas.1532872100
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Kushnerenko EV, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00595
   Marklund E, 2018, BRAIN LANG, V176, P26, DOI 10.1016/j.bandl.2017.10.006
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Molnar M, 2014, BILING-LANG COGN, V17, P526, DOI 10.1017/S136672891300062X
   Morr ML, 2002, EAR HEARING, V23, P118, DOI 10.1097/00003446-200204000-00005
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Rivera-Gaxiola M, 2005, DEVELOPMENTAL SCI, V8, P162, DOI 10.1111/j.1467-7687.2005.00403.x
   Shafer VL, 2012, NEUROSCI LETT, V526, P10, DOI 10.1016/j.neulet.2012.07.064
   Shafer VL, 2011, J PHONETICS, V39, P527, DOI 10.1016/j.wocn.2010.11.010
   Sharma A, 1999, J ACOUST SOC AM, V106, P1078, DOI 10.1121/1.428048
   SHIBASAKI H, 1992, J CLIN NEUROPHYSIOL, V9, P408, DOI 10.1097/00004691-199207010-00007
   SHUCARD JL, 1990, DEV PSYCHOL, V26, P923, DOI 10.1037/0012-1649.26.6.923
   Sjolander K., 2000, 6 INT C SPOK LANG PR, DOI [10.1038/372090a0, DOI 10.1038/372090A0]
   TIITINEN H, 1994, NATURE, V372, P90, DOI 10.1038/372090a0
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Winkler I, 1999, COGNITIVE BRAIN RES, V7, P357, DOI 10.1016/S0926-6410(98)00039-1
   Winkler I, 2007, J PSYCHOPHYSIOL, V21, P147, DOI 10.1027/0269-8803.21.34.147
   Xu D, 2008, LENA LANGUAGE ENV AN
   Yoshida KA, 2010, INFANCY, V15, P420, DOI 10.1111/j.1532-7078.2009.00024.x
   Zhang L. J., 2009, LANGUAGE INVITATION, V4, P85
NR 38
TC 5
Z9 5
U1 0
U2 1
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1878-9293
EI 1878-9307
J9 DEV COGN NEUROS-NETH
JI Dev. Cogn. Neurosci.
PD APR
PY 2019
VL 36
AR 100622
DI 10.1016/j.dcn.2019.100622
PG 8
WC Psychology, Developmental; Neurosciences
SC Psychology; Neurosciences & Neurology
GA HY5KN
UT WOS:000468166900020
PM 30785071
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Payne, H
   Gutierrez-Sigut, E
   Woll, B
   MacSweeney, M
AF Payne, Heather
   Gutierrez-Sigut, Eva
   Woll, Bencie
   MacSweeney, Mairead
TI Cerebral lateralisation during signed and spoken language production in
   children born deaf
SO DEVELOPMENTAL COGNITIVE NEUROSCIENCE
LA English
DT Article
DE Language; Lateralisation; Functional transcranial Doppler sonography;
   fTCD; Deaf; Children; Cochlear implants; Sign language
ID HEMISPHERIC-SPECIALIZATION; SPEECH-PERCEPTION; BRAIN; DOMINANCE; ADULTS;
   FMRI; ACQUISITION; MODULATION; RESPONSES; PATTERNS
AB The effect of sensory experience on hemispheric specialisation for language production is not well understood. Children born deaf, including those who have cochlear implants, have drastically different perceptual experiences of language than their hearing peers. Using functional transcranial Doppler sonography (fTCD), we measured lateralisation during language production in a heterogeneous group of 19 deaf children and in 19 hearing children, matched on language ability. In children born deaf, we observed significant left lateralisation during language production (British Sign Language, spoken English, or a combination of languages). There was no difference in the strength of lateralisation between deaf and hearing groups. Comparable proportions of children were categorised as left-, right-, or not significantly-lateralised in each group. Moreover, an exploratory subgroup analysis showed no significant difference in lateralisation between deaf children with cochlear implants and those without. These data suggest that the processes underpinning language production remain robustly left lateralised regardless of sensory language experience.
C1 [Payne, Heather; Gutierrez-Sigut, Eva; Woll, Bencie; MacSweeney, Mairead] UCL, Deafness Cognit & Language Res Ctr, London WC1H 0PD, England.
   [Payne, Heather; Gutierrez-Sigut, Eva; MacSweeney, Mairead] UCL, Inst Cognit Neurosci, 17 Queen Sq, London WC1N 3AZ, England.
   [Gutierrez-Sigut, Eva] Univ Valencia, Dept Metodol Ciencias Comportamiento, Av Blasco Ibanez 2146010, Valencia, Spain.
RP Payne, H (corresponding author), UCL, Inst Cognit Neurosci, 17 Queen Sq, London WC1N 3AZ, England.
EM h.payne@ucl.ac.uk; eva.gutierrez@ucl.ac.uk; b.woll@ucl.ac.uk;
   m.macsweeney@ucl.ac.uk
RI Gutierrez-Sigut, Eva/L-4116-2014; Woll, Bencie/C-2040-2008
OI Gutierrez-Sigut, Eva/0000-0002-6569-2138; Woll,
   Bencie/0000-0002-3300-4775
FU Wellcome TrustWellcome TrustEuropean Commission [100229/Z/12/Z];
   Economic and Social Research Council (Deafness Cognition and Language
   Research Centre) [RES-620-28-0002]; Spanish Ministerio de Economia y
   Competitividad [PSI2014-60611-JIN]
FX This work was funded by a Wellcome Trust Fellowship to M.M.
   (100229/Z/12/Z) and the Economic and Social Research Council (Deafness
   Cognition and Language Research Centre; RES-620-28-0002). EG was funded
   by the Spanish Ministerio de Economia y Competitividad (Grant Number
   PSI2014-60611-JIN).
CR AASLID R, 1982, J NEUROSURG, V57, P769, DOI 10.3171/jns.1982.57.6.0769
   Artiges E, 2000, SCHIZOPHRENIA BULL, V26, P709, DOI 10.1093/oxfordjournals.schbul.a033488
   Badcock NA, 2017, LANG COGN NEUROSCI, V32, P818, DOI 10.1080/23273798.2016.1276608
   Badcock NA, 2018, LATERALITY, V23, P391, DOI 10.1080/1357650X.2017.1363773
   Bishop DVM, 2014, PEERJ, V2, DOI 10.7717/peerj.507
   Bishop DVM, 2013, SCIENCE, V340, DOI 10.1126/science.1230531
   Bishop DVM, 2009, NEUROPSYCHOLOGIA, V47, P587, DOI 10.1016/j.neuropsychologia.2008.09.013
   Bishop DVM, 1996, BRIT J PSYCHOL, V87, P269, DOI 10.1111/j.2044-8295.1996.tb02590.x
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   Brandler WM, 2013, PLOS GENET, V9, DOI 10.1371/journal.pgen.1003751
   Braun AR, 1997, BRAIN, V120, P761, DOI 10.1093/brain/120.5.761
   Chilosi AM, 2014, BRAIN LANG, V129, P1, DOI 10.1016/j.bandl.2013.12.002
   Chirathivat N, 2015, SCI REP-UK, V5, DOI 10.1038/srep11359
   Corina DP, 2003, J COGNITIVE NEUROSCI, V15, P718, DOI 10.1162/089892903322307438
   Crow TJ, 1996, SCHIZOPHR RES, V22, P181, DOI 10.1016/S0920-9964(96)00068-0
   de Guibert C, 2010, NEUROIMAGE, V51, P897, DOI 10.1016/j.neuroimage.2010.02.054
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   Dehaene-Lambertz G, 2006, TRENDS NEUROSCI, V29, P367, DOI 10.1016/j.tins.2006.05.011
   Deppe M, 1997, J NEUROSCI METH, V75, P147, DOI 10.1016/S0165-0270(97)00067-8
   Dienes Z, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00781
   Elliot C. D., 2011, BRIT ABILITY SCALES
   Emmorey K, 2003, NEUROPSYCHOLOGIA, V41, P85, DOI 10.1016/S0028-3932(02)00089-1
   Emmorey K, 2002, NEUROIMAGE, V17, P812, DOI 10.1006/nimg.2002.1187
   Francks C, 2015, ANN NY ACAD SCI, V1359, P1, DOI 10.1111/nyas.12770
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Groen MA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0064876
   Groen MA, 2012, BRAIN BEHAV, V2, P256, DOI 10.1002/brb3.56
   Gutierrez-Sigut E, 2015, BRAIN LANG, V151, P23, DOI 10.1016/j.bandl.2015.10.006
   Herman R., 1999, ASSESSING BSL DEV RE
   Hodgson JC, 2016, DEV COGN NEUROS-NETH, V22, P9, DOI 10.1016/j.dcn.2016.09.005
   Holland SK, 2007, INT J AUDIOL, V46, P533, DOI 10.1080/14992020701448994
   Hulme C., 2009, YARC YORK ASSESSMENT
   Johnston ANB, 1999, BEHAV NEUROSCI, V113, P1267, DOI 10.1037/0735-7044.113.6.1267
   Josse G, 2004, BRAIN RES REV, V44, P1, DOI 10.1016/j.brainresrev.2003.10.001
   Knecht S, 2000, BRAIN, V123, P74, DOI 10.1093/brain/123.1.74
   Krishnan S, 2015, CEREB CORTEX, V25, P3261, DOI 10.1093/cercor/bhu120
   Kyle FE, 2013, J SPEECH LANG HEAR R, V56, P416, DOI 10.1044/1092-4388(2012/12-0039)
   Lakens D, 2020, J GERONTOL B-PSYCHOL, V75, P45, DOI 10.1093/geronb/gby065
   Lakens D, 2017, SOC PSYCHOL PERS SCI, V8, P355, DOI 10.1177/1948550617697177
   Letzner S, 2014, SCI REP-UK, V4, DOI 10.1038/srep04253
   MacSweeney M, 2002, BRAIN, V125, P1583, DOI 10.1093/brain/awf153
   MacSweeney M, 2008, TRENDS COGN SCI, V12, P432, DOI 10.1016/j.tics.2008.07.010
   Maisog JM, 2008, ANN NY ACAD SCI, V1145, P237, DOI 10.1196/annals.1416.024
   McNealy K, 2011, DEVELOPMENTAL SCI, V14, P1261, DOI 10.1111/j.1467-7687.2011.01075.x
   Minagawa-Kawai Y, 2011, DEV COGN NEUROS-NETH, V1, P217, DOI 10.1016/j.dcn.2011.03.005
   Moorman S, 2015, SCI REP-UK, V5, DOI 10.1038/srep09041
   Morillon B, 2010, P NATL ACAD SCI USA, V107, P18688, DOI 10.1073/pnas.1007189107
   Mottonen R, 2010, NEUROPSYCHOLOGIA, V48, P3173, DOI 10.1016/j.neuropsychologia.2010.06.033
   Ocklenburg S, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00005
   Papadatou-Pastou M, 2016, NEUROSCI BIOBEHAV R, V60, P98, DOI 10.1016/j.neubiorev.2015.11.013
   Paquette N, 2015, NEUROPSYCHOLOGIA, V68, P117, DOI 10.1016/j.neuropsychologia.2015.01.007
   Pena M, 2003, P NATL ACAD SCI USA, V100, P11702, DOI 10.1073/pnas.1934290100
   Plante E, 2015, LATERALITY, V20, P306, DOI 10.1080/1357650X.2014.963597
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Poeppel D, 2012, COGN NEUROPSYCHOL, V29, P34, DOI 10.1080/02643294.2012.710600
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Rosen S, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0024672
   Sowman PF, 2014, FRONT HUM NEUROSCI, V8, DOI [10.3389/fnhum.2014.00354, 10.3389/fnhum.2014.00398]
   Tsoi SC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0108929
   Tzourio-Mazoyer N, 2017, CORTEX, V86, P314, DOI 10.1016/j.cortex.2016.05.013
   Vigneau M, 2006, NEUROIMAGE, V30, P1414, DOI 10.1016/j.neuroimage.2005.11.002
   von Kriegstein K, 2003, COGNITIVE BRAIN RES, V17, P48, DOI 10.1016/S0926-6410(03)00079-X
   Weiss-Croft LJ, 2015, NEUROIMAGE, V123, P269, DOI 10.1016/j.neuroimage.2015.07.046
   Whitehouse AJO, 2008, BRAIN, V131, P3193, DOI 10.1093/brain/awn266
   Wilson AC, 2018, PEERJ, V6, DOI 10.7717/peerj.4217
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
NR 66
TC 2
Z9 2
U1 3
U2 5
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1878-9293
EI 1878-9307
J9 DEV COGN NEUROS-NETH
JI Dev. Cogn. Neurosci.
PD APR
PY 2019
VL 36
AR 100619
DI 10.1016/j.dcn.2019.100619
PG 9
WC Psychology, Developmental; Neurosciences
SC Psychology; Neurosciences & Neurology
GA HY5KN
UT WOS:000468166900017
PM 30711882
OA DOAJ Gold, Green Published, Green Accepted
DA 2021-02-24
ER

PT J
AU Politzer-Ahles, S
   Pan, L
AF Politzer-Ahles, Stephen
   Pan, Lei
TI Skilled musicians are indeed subject to the McGurk effect
SO ROYAL SOCIETY OPEN SCIENCE
LA English
DT Article
DE McGurk effect; speech perception; audiovisual integration; musicians;
   replication
ID PERCEPTION; CHINESE
AB The McGurk effect is an illusion whereby speech sounds are often mis-categorized when the auditory cues in the stimulus conflict with the visual cues from the speaker's face. A recent study claims that 'skilled musicians are not subject to' this effect. It is not clear, however, if this is intended to mean that skilled musicians do not experience the McGurk effect at all, or if they just experience it to a lesser magnitude than non-musicians. The study also does not statistically demonstrate either of these conclusions, as it does report a numerical (albeit non-significant) McGurk effect for musicians and does not report a significant difference between musicians' and non-musicians' McGurk effect sizes. This article reports a pre-registered, higher-power replication of that study (using twice the sample size and changing from a between-to a within-participants manipulation). Contrary to the original study's conclusion, we find that musicians do show a large and statistically significant McGurk effect and that their effect is no smaller than that of non-musicians.
C1 [Politzer-Ahles, Stephen; Pan, Lei] Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Hung Hom, Hong Kong, Peoples R China.
RP Politzer-Ahles, S (corresponding author), Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Hung Hom, Hong Kong, Peoples R China.
EM stephen.politzerahles@polyu.edu.hk
RI Politzer-Ahles, Stephen/N-4421-2014
OI Politzer-Ahles, Stephen/0000-0002-5474-7930; Pan,
   Lei/0000-0002-6791-3985
FU Hong Kong Polytechnic University Faculty of Humanities Dean's Reserve
   [1-ZE89]; HK PolyU-PKU Research Centre on Chinese Linguistics
FX L.P. was supported by grant #1-ZE89 from the Hong Kong Polytechnic
   University Faculty of Humanities Dean's Reserve. This paper also
   received support from the HK PolyU-PKU Research Centre on Chinese
   Linguistics.
CR Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boersma P., 2018, PRAAT DOING PHONETIC
   Chen TH, 2004, PERCEPT PSYCHOPHYS, V66, P820, DOI 10.3758/BF03194976
   Coffey EBJ, 2017, HEARING RES, V352, P49, DOI 10.1016/j.heares.2017.02.006
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   Gelman A, 2006, AM STAT, V60, P328, DOI 10.1198/000313006X152649
   Hirst RJ, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30798-8
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Magnotti JF, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202908
   Magnotti JF, 2015, EXP BRAIN RES, V233, P2581, DOI 10.1007/s00221-015-4324-7
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Proverbio AM, 2016, SCI REP-UK, V6, DOI 10.1038/srep30423
   R Core Team, 2016, R LANG ENV STAT COMP
   Sekiyama K, 1997, PERCEPT PSYCHOPHYS, V59, P73, DOI 10.3758/BF03206849
   Simonsohn U, 2015, PSYCHOL SCI, V26, P559, DOI 10.1177/0956797614567341
NR 17
TC 0
Z9 0
U1 0
U2 0
PU ROYAL SOC
PI LONDON
PA 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND
SN 2054-5703
J9 ROY SOC OPEN SCI
JI R. Soc. Open Sci.
PD APR
PY 2019
VL 6
IS 4
AR 181868
DI 10.1098/rsos.181868
PG 10
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA HW2KU
UT WOS:000466513900010
PM 31183122
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Roque, L
   Gaskins, C
   Gordon-Salant, S
   Goupell, MJ
   Anderson, S
AF Roque, Lindsey
   Gaskins, Casey
   Gordon-Salant, Sandra
   Goupell, Matthew J.
   Anderson, Samira
TI Age Effects on Neural Representation and Perception of Silence Duration
   Cues in Speech
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article; Proceedings Paper
CT 7th International and Interdisciplinary Research Conference on Aging and
   Speech Communication
CY NOV 14, 2017
CL Univ S Florida, Tampa, FL
HO Univ S Florida
ID BRAIN-STEM RESPONSE; GAP DETECTION THRESHOLDS; OLDER-ADULTS; TEMPORAL
   CUES; HEARING-LOSS; NOISE; FREQUENCY; SOUND; LISTENERS; ENVELOPE
AB Purpose: Degraded temporal processing associated with aging may be a contributing factor to older adults' hearing difficulties, especially in adverse listening environments. This degraded processing may affect the ability to distinguish between words based on temporal duration cues. The current study investigates the effects of aging and hearing loss on cortical and subcortical representation of temporal speech components and on the perception of silent interval duration cues in speech.
   Method: Identification functions for the words DISH and DITCH were obtained on a 7-step continuum of silence duration (0-60 ms) prior to the final fricative in participants who are younger with normal hearing (YNH), older with normal hearing (ONH), and older with hearing impairment (OHI). Frequency-following responses and cortical auditory-evoked potentials were recorded to the 2 end points of the continuum. Auditory brainstem responses to clicks were obtained to verify neural integrity and to compare group differences in auditory nerve function. A multiple linear regression analysis was conducted to determine the peripheral or central factors that contributed to perceptual performance.
   Results: ONH and OHI participants required longer silence durations to identify DITCH than did YNH participants. Frequency-following responses showed reduced phase locking and poorer morphology, and cortical auditory-evoked potentials showed prolonged latencies in ONH and OHI participants compared with YNH participants. No group differences were noted for auditory brainstem response Wave I amplitude or Wave V/I ratio. After accounting for the possible effects of hearing loss, linear regression analysis revealed that both midbrain and cortical processing contributed to the variance in the DISH-DITCH perceptual identification functions.
   Conclusions: These results suggest that age-related deficits in the ability to encode silence duration cues may be a contributing factor in degraded speech perception. In particular, degraded response morphology relates to performance on perceptual tasks based on silence duration contrasts between words.
C1 [Roque, Lindsey; Gaskins, Casey; Gordon-Salant, Sandra; Goupell, Matthew J.; Anderson, Samira] Univ Maryland, Dept Hearing & Speech Sci, College Pk, MD 20742 USA.
   [Gordon-Salant, Sandra; Goupell, Matthew J.; Anderson, Samira] Univ Maryland, Neurosci & Cognit Sci Program, College Pk, MD 20742 USA.
RP Anderson, S (corresponding author), Univ Maryland, Dept Hearing & Speech Sci, College Pk, MD 20742 USA.; Anderson, S (corresponding author), Univ Maryland, Neurosci & Cognit Sci Program, College Pk, MD 20742 USA.
EM sander22@umd.edu
RI Goupell, Matthew/ABF-2342-2020
OI Goupell, Matthew/0000-0003-2662-3057
FU American Hearing Research Foundation; National Institute on Deafness and
   Other Communication Disorders of the National Institutes of HealthUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R21DC015843]; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R21DC015843, R21DC015843] Funding Source: NIH RePORTER
FX This research was supported by the American Hearing Research Foundation
   (S. A.) and the National Institute on Deafness and Other Communication
   Disorders of the National Institutes of Health under Award R21DC015843
   (S. A.). The content is solely the responsibility of the authors and
   does not necessarily represent the official views of the National
   Institutes of Health. The authors wish to thank Calli Fodor and Erin
   Walter for their assistance with data collection and analysis.
CR American National Standards Institute, 2010, S361996 ANSI
   Ananthakrishnan S, 2016, EAR HEARING, V37, pe91, DOI 10.1097/AUD.0000000000000247
   Anderson S, 2013, HEARING RES, V300, P18, DOI 10.1016/j.heares.2013.03.006
   Anderson S, 2013, J SPEECH LANG HEAR R, V56, P31, DOI 10.1044/1092-4388(2012/12-0043)
   Anderson S, 2012, J NEUROSCI, V32, P14156, DOI 10.1523/JNEUROSCI.2176-12.2012
   Bharadwaj HM, 2015, J NEUROSCI, V35, P2161, DOI 10.1523/JNEUROSCI.3915-14.2015
   Bidelman GM, 2018, J AM ACAD AUDIOL, V29, P164, DOI 10.3766/jaaa.16167
   Billings CJ, 2015, EAR HEARING, V36, P710, DOI 10.1097/AUD.0000000000000191
   Billings CJ, 2013, JARO-J ASSOC RES OTO, V14, P891, DOI 10.1007/s10162-013-0415-y
   Bramhall NF, 2017, EAR HEARING, V38, pE1, DOI 10.1097/AUD.0000000000000370
   Caspary DM, 2008, J EXP BIOL, V211, P1781, DOI 10.1242/jeb.013581
   Casseday JH, 2000, J NEUROPHYSIOL, V84, P1475
   Ceponiene R, 2005, PSYCHOPHYSIOLOGY, V42, P391, DOI 10.1111/j.1469-8986.2005.00305.x
   Ceponiene R, 2002, CLIN NEUROPHYSIOL, V113, P870, DOI 10.1016/S1388-2457(02)00078-0
   Clinard CG, 2015, HEARING RES, V323, P91, DOI 10.1016/j.heares.2015.02.002
   Coffey EBJ, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11070
   de Cheveigne A, 2008, J NEUROSCI METH, V171, P331, DOI 10.1016/j.jneumeth.2008.03.015
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dimitrijevic A, 2016, EAR HEARING, V37, pE322, DOI 10.1097/AUD.0000000000000324
   Dupuis K, 2015, AGING NEUROPSYCHOL C, V22, P413, DOI 10.1080/13825585.2014.968084
   Eggermont JJ, 2001, HEARING RES, V157, P1, DOI 10.1016/S0378-5955(01)00259-3
   Faure PA, 2003, J NEUROSCI, V23, P3052
   FITZGIBBONS PJ, 1994, J SPEECH HEAR RES, V37, P662, DOI 10.1044/jshr.3703.662
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Galbraith GC, 1995, NEUROREPORT, V6, P2363, DOI 10.1097/00001756-199511270-00021
   Gehr SE, 1999, J ACOUST SOC AM, V106, P2793, DOI 10.1121/1.428104
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Gordon-Salant S, 2006, J ACOUST SOC AM, V119, P2455, DOI 10.1121/1.2171527
   Gordon-Salant S, 2008, J ACOUST SOC AM, V124, P3249, DOI 10.1121/1.2982409
   Goupell MJ, 2017, EAR HEARING, V38, pE335, DOI 10.1097/AUD.0000000000000447
   Grose JH, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216517737417
   Guest H, 2018, HEARING RES, V364, P142, DOI 10.1016/j.heares.2018.03.008
   Harris KC, 2017, NEUROBIOL AGING, V53, P150, DOI 10.1016/j.neurobiolaging.2017.01.008
   Harris KC, 2012, EAR HEARING, V33, P330, DOI 10.1097/AUD.0b013e31823fb585
   Heine C, 2002, DISABIL REHABIL, V24, P763, DOI 10.1080/09638280210129162
   Hughes LF, 2010, HEARING RES, V264, P79, DOI 10.1016/j.heares.2009.09.005
   Humes LE, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00055
   Humes LE, 2010, HEARING RES, V264, P30, DOI 10.1016/j.heares.2009.09.010
   Jenkins KA, 2018, EAR HEARING, V39, P810, DOI 10.1097/AUD.0000000000000538
   Juarez-Salinas DL, 2010, J NEUROSCI, V30, P14795, DOI 10.1523/JNEUROSCI.3393-10.2010
   Kujawa SG, 2009, J NEUROSCI, V29, P14077, DOI 10.1523/JNEUROSCI.2845-09.2009
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Maamor N, 2017, NEUROSCI LETT, V636, P258, DOI 10.1016/j.neulet.2016.11.020
   Mamo SK, 2016, HEARING RES, V333, P201, DOI 10.1016/j.heares.2015.09.005
   Martin B. A., 2007, AUDITORY EVOKED POTE, P482
   Mehraei G, 2016, J NEUROSCI, V36, P3755, DOI 10.1523/JNEUROSCI.4460-15.2016
   MOUSHEGIAN G, 1973, ELECTROEN CLIN NEURO, V35, P665, DOI 10.1016/0013-4694(73)90223-X
   NAATANEN R, 1990, BEHAV BRAIN SCI, V13, P201, DOI 10.1017/S0140525X00078407
   Naatanen R, 1999, PSYCHOL BULL, V125, P826, DOI 10.1037/0033-2909.125.6.826
   Palmer SB, 2014, J AM ACAD AUDIOL, V25, P999, DOI 10.3766/jaaa.25.10.8
   Parthasarathy A, 2011, NEUROSCIENCE, V192, P619, DOI 10.1016/j.neuroscience.2011.06.042
   Peelle JE, 2010, CEREB CORTEX, V20, P773, DOI 10.1093/cercor/bhp142
   Phillips SL, 2000, J SPEECH LANG HEAR R, V43, P217, DOI 10.1044/jslhr.4301.217
   Pichora-Fuller MK, 2006, J ACOUST SOC AM, V119, P1143, DOI 10.1121/1.2149837
   Prendergast G, 2018, HEARING RES, V364, P38, DOI 10.1016/j.heares.2018.04.002
   Presacco A, 2016, J NEUROPHYSIOL, V116, P2346, DOI 10.1152/jn.00372.2016
   Presacco A, 2015, EAR HEARING, V36, pE352, DOI 10.1097/AUD.0000000000000193
   Purcell DW, 2004, J ACOUST SOC AM, V116, P3581, DOI 10.1121/1.1798354
   Romero S., 2006, ANN INT C IEEE ENG M
   Ross B, 2013, BMC NEUROSCI, V14, DOI 10.1186/1471-2202-14-151
   Ruggles D, 2012, CURR BIOL, V22, P1417, DOI 10.1016/j.cub.2012.05.025
   Sarela J, 2005, J MACH LEARN RES, V6, P233
   Schatteman TA, 2008, NEUROSCIENCE, V154, P329, DOI 10.1016/j.neuroscience.2008.02.025
   Schlogl A, 2007, CLIN NEUROPHYSIOL, V118, P98, DOI 10.1016/j.clinph.2006.09.003
   Schmiedt RA, 1996, J NEUROPHYSIOL, V76, P2799
   SCHNEIDER BA, 1994, J ACOUST SOC AM, V95, P980, DOI 10.1121/1.408403
   Schneider BA, 1999, J ACOUST SOC AM, V106, P371, DOI 10.1121/1.427062
   Sergeyenko Y, 2013, J NEUROSCI, V33, P13686, DOI 10.1523/JNEUROSCI.1783-13.2013
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   Shtyrov Y, 1998, NEUROSCI LETT, V251, P141, DOI 10.1016/S0304-3940(98)00529-1
   SMITH JC, 1975, ELECTROEN CLIN NEURO, V39, P465, DOI 10.1016/0013-4694(75)90047-4
   TallonBaudry C, 1996, J NEUROSCI, V16, P4240
   Tremblay Kelly L, 2004, J Am Acad Audiol, V15, P226
   Tremblay KL, 2003, CLIN NEUROPHYSIOL, V114, P1332, DOI 10.1016/S1388-2457(03)00114-7
   Viana LM, 2015, HEARING RES, V327, P78, DOI 10.1016/j.heares.2015.04.014
   Walton JP, 1998, J NEUROSCI, V18, P2764
   Werff KRV, 2011, EAR HEARING, V32, P168, DOI 10.1097/AUD.0b013e3181f534b5
   Working Group on Speech Understanding and Aging, 1988, J ACOUST SOC AM, V83, P859, DOI DOI 10.1121/1.395965
   Zhu J, 1999, WECHSLER ABBREVIATED
NR 79
TC 6
Z9 6
U1 0
U2 3
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD APR
PY 2019
VL 62
IS 4
SU S
SI SI
BP 1099
EP 1116
DI 10.1044/2018_JSLHR-H-ASCC7-18-0076
PG 18
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA HV7HP
UT WOS:000466152400002
PM 31026197
OA Green Published
DA 2021-02-24
ER

PT J
AU Jesse, A
   Helfer, KS
AF Jesse, Alexandra
   Helfer, Karen S.
TI Lexical Influences on Errors in Masked Speech Perception in Younger,
   Middle-Aged, and Older Adults
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article; Proceedings Paper
CT 7th International and Interdisciplinary Research Conference on Aging and
   Speech Communication
CY NOV 14, 2017
CL Univ S Florida, Tampa, FL
HO Univ S Florida
ID SPOKEN-WORD RECOGNITION; COMPETING SPEECH; NEIGHBORHOOD ACTIVATION;
   MASKING; HEARING; TALKER; MODEL; FREQUENCY; NOISE; SHORTLIST
AB Purpose: In situations with a competing talker, lexical properties of words in both streams affect the recognition of words in the to-be-attended target stream. In this study, we tested whether these lexical properties also influence the type of errors made by listeners across the adult life span.
   Method: Errors from a corpus collected by Helfer and Jesse (2015) were categorized as phonologically similar to words in the target and/or masker streams. Younger, middle-aged, and older listeners had produced these errors when trying to identify key words from a target stream while ignoring a single-talker masker. Neighborhood density and lexical frequency of target words and masker words had been manipulated independently.
   Results: Lexical properties of target words influenced all types of errors. With higher frequency maskers, the probability of responding with a masker word increased and the phonological influence of target words decreased. Lower levels of lexical competition for maskers increased the probability that listeners reported a word phonologically related to both masker and target words. The influence of masker words increased across the adult life span, as evidenced by phonological intrusions into responses and the temporary failure in selectively attending to the target stream. The effects of lexical properties on error patterns, however, were consistent across age groups.
   Conclusions: The ease of recognition of words in both attended and unattended speech influences the breakdown of speech perception. These influences remain robust across the adult life span.
C1 [Jesse, Alexandra] Univ Massachusetts, Dept Psychol & Brain Sci, Amherst, MA 01003 USA.
   [Helfer, Karen S.] Univ Massachusetts, Dept Commun Disorders, Amherst, MA 01003 USA.
RP Jesse, A (corresponding author), Univ Massachusetts, Dept Psychol & Brain Sci, Amherst, MA 01003 USA.
EM ajesse@psych.umass.edu
OI Helfer, Karen/0000-0002-4924-8619
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01 012057]; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC012057, R01DC012057, R01DC012057] Funding Source: NIH RePORTER
FX This research was supported by National Institute on Deafness and Other
   Communication Disorders Grant R01 012057, awarded to Karen S. Helfer. We
   would like to thank Michael Rogers for his help with this project and
   Aline Sayer, Adrian Staub, and Andrew Cohen for valuable comments. Part
   of this work has been presented as "Lexical Influence on Error Patterns
   in Competing Speech Perception" at the Meeting of the Acoustical Society
   of America, Boston, MA, in June 2017, and as "Lexical Characteristics of
   Words in Competing Speech Streams Predict How Processing Breaks Down" at
   the Aging and Speech Communication Research Conference, Tampa, FL, in
   November 2017.
CR Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boulenger V, 2010, SPEECH COMMUN, V52, P246, DOI 10.1016/j.specom.2009.11.002
   Brouwer S, 2016, J PSYCHOLINGUIST RES, V45, P1151, DOI 10.1007/s10936-015-9396-9
   Calandruccio L, 2010, J ACOUST SOC AM, V128, P860, DOI 10.1121/1.3458857
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750
   Dirks DD, 2001, EAR HEARING, V22, P1, DOI 10.1097/00003446-200102000-00001
   DUQUESNOY AJ, 1983, J ACOUST SOC AM, V74, P739, DOI 10.1121/1.389859
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   George ELJ, 2006, J ACOUST SOC AM, V120, P2295, DOI 10.1121/1.2266530
   Glyde H, 2013, EAR HEARING, V34, P15, DOI 10.1097/AUD.0b013e3182617f94
   GOLDINGER SD, 1989, J MEM LANG, V28, P501, DOI 10.1016/0749-596X(89)90009-0
   Hasher Lynn, 1988, PSYCHOL LEARN MOTIV, V22, P193, DOI DOI 10.1016/S0079-7421(08)60041-9
   Helfer KS, 2008, EAR HEARING, V29, P87, DOI 10.1097/AUD.0b013e31815d638b
   Helfer KS, 2016, J ACOUST SOC AM, V140, P3844, DOI 10.1121/1.4967297
   Helfer KS, 2016, J ACOUST SOC AM, V140, pEL371, DOI 10.1121/1.4966586
   Helfer KS, 2015, AM J AUDIOL, V24, P80, DOI 10.1044/2015_AJA-14-0056
   Helfer KS, 2015, J ACOUST SOC AM, V138, P363, DOI 10.1121/1.4923155
   Helfer KS, 2014, J ACOUST SOC AM, V136, P748, DOI 10.1121/1.4887463
   Helfer KS, 2013, EAR HEARING, V34, P160, DOI 10.1097/AUD.0b013e31826a8ea7
   Helfer KS, 2009, J AM ACAD AUDIOL, V20, P264, DOI 10.3766/jaaa.20.4.6
   Humes LE, 2006, J ACOUST SOC AM, V120, P2926, DOI 10.1121/1.2354070
   Ihlefeld A, 2008, J ACOUST SOC AM, V123, P4380, DOI 10.1121/1.2904825
   Lee JH, 2012, J ACOUST SOC AM, V132, P1700, DOI 10.1121/1.4740482
   Luce P.A, 1986, RES SPEECH PERCEPTIO
   Luce PA, 2000, PERCEPT PSYCHOPHYS, V62, P615, DOI 10.3758/BF03212113
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   LUCE PA, 1990, ACL MIT NAT, P122
   MARSLENWILSON W, 1990, ACL MIT NAT, P148
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   Meister H, 2013, NEUROSCIENCE, V232, P74, DOI 10.1016/j.neuroscience.2012.12.006
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Norris D, 1997, COGNITIVE PSYCHOL, V34, P191, DOI 10.1006/cogp.1997.0671
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   R Core Team, 2017, R LANG ENV STAT COMP
   Revill KP, 2012, PSYCHOL AGING, V27, P80, DOI 10.1037/a0024113
   Ruggles D, 2012, CURR BIOL, V22, P1417, DOI 10.1016/j.cub.2012.05.025
   Sommers M. S, 2000, WASHINGTON U NEIGHBO
   Sommers MS, 1999, PSYCHOL AGING, V14, P458, DOI 10.1037/0882-7974.14.3.458
   TAKAHASHI GA, 1992, J SPEECH HEAR RES, V35, P1410, DOI 10.1044/jshr.3506.1410
   Taler V, 2010, J GERONTOL B-PSYCHOL, V65, P551, DOI 10.1093/geronb/gbq039
   Tun PA, 2002, PSYCHOL AGING, V17, P453, DOI 10.1037//0882-7974.17.3.453
   Tun PA, 1999, J GERONTOL B-PSYCHOL, V54, pP317, DOI 10.1093/geronb/54B.5.P317
   Van Engen KJ, 2007, J ACOUST SOC AM, V121, P519, DOI 10.1121/1.2400666
NR 45
TC 2
Z9 2
U1 0
U2 4
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD APR
PY 2019
VL 62
IS 4
SU S
SI SI
BP 1152
EP 1166
DI 10.1044/2018_JSLHR-H-ASCC7-18-0091
PG 15
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA HV7HP
UT WOS:000466152400006
PM 31026195
OA Green Published
DA 2021-02-24
ER

PT J
AU Lowenstein, JH
   Nittrouer, S
AF Lowenstein, Joanna H.
   Nittrouer, Susan
TI Perception-Production Links in Children's Speech
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID VOICE ONSET TIME; COCHLEAR IMPLANTS; ACOUSTIC CHARACTERISTICS;
   BILINGUAL-CHILDREN; ENGLISH; HEARING; INTELLIGIBILITY; RECOGNITION;
   LANGUAGE; FRICATIVES
AB Purpose: Child phonologists have long been interested in how tightly speech input constrains the speech production capacities of young children, and the question acquires clinical significance when children with hearing loss are considered. Children with sensorineural hearing loss often show differences in the spectral and temporal structures of their speech production, compared to children with normal hearing. The current study was designed to investigate the extent to which this problem can be explained by signal degradation.
   Method: Ten 5-year-olds with normal hearing were recorded imitating 120 three-syllable nonwords presented in unprocessed form and as noise-vocoded signals. Target segments consisted of fricatives, stops, and vowels. Several measures were made: 2 duration measures (voice onset time and fricative length) and 4 spectral measures involving 2 segments (1st and 3rd moments of fricatives and 1st and 2nd formant frequencies for the point vowels).
   Results: All spectral measures were affected by signal degradation, with vowel production showing the largest effects. Although a change in voice onset time was observed with vocoded signals for /d/, voicing category was not affected. Fricative duration remained constant.
   Conclusions: Results support the hypothesis that quality of the input signal constrains the speech production capacities of young children. Consequently, it can be concluded that the production problems of children with hearing loss-including those with cochlear implants-can be explained to some extent by the degradation in the signal they hear. However, experience with both speech perception and production likely plays a role as well.
C1 [Lowenstein, Joanna H.; Nittrouer, Susan] Univ Florida, Dept Speech Language & Hearing Sci, Gainesville, FL 32611 USA.
RP Lowenstein, JH (corresponding author), Univ Florida, Dept Speech Language & Hearing Sci, Gainesville, FL 32611 USA.
EM jlowenstein@phhp.ufl.edu
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01 DC000633]
FX This work was supported by Grant R01 DC000633 (awarded to Susan
   Nittrouer) from the National Institute on Deafness and Other
   Communication Disorders. The authors thank Richard McGowan for making
   acoustic measurements; Robert Fox for producing the stimuli; Eric Tarr
   for help with programming; and Ellen Hambley, Demarcus Williams, Lauren
   Linker, and Kierstyn Tietgens for their help with sound file processing.
CR Baudonck N, 2011, FOLIA PHONIATR LOGO, V63, P154, DOI 10.1159/000318879
   Baudonck N, 2010, INT J PEDIATR OTORHI, V74, P416, DOI 10.1016/j.ijporl.2010.01.017
   Bharadwaj SV, 2008, J SPEECH LANG HEAR R, V51, P629, DOI 10.1044/1092-4388(2008/045)
   Bradlow AR, 1996, SPEECH COMMUN, V20, P255, DOI 10.1016/S0167-6393(96)00063-5
   Bunta F, 2016, J SPEECH LANG HEAR R, V59, P686, DOI 10.1044/2016_JSLHR-S-15-0212
   Byrd D, 1993, UCLA WORKING PAPERS, V83, P97
   Caldwell A, 2013, J SPEECH LANG HEAR R, V56, P13, DOI 10.1044/1092-4388(2012/11-0338)
   Cho T, 1999, J PHONETICS, V27, P207, DOI 10.1006/jpho.1999.0094
   Chuang HF, 2012, INT J SPEECH-LANG PA, V14, P119, DOI 10.3109/17549507.2011.639391
   Culling JF, 2012, EAR HEARING, V33, P673, DOI 10.1097/AUD.0b013e3182587356
   de Boysson-Bardies B., 1986, PRECURSORS EARLY SPE, V44, P113
   Dollaghan C, 1998, J SPEECH LANG HEAR R, V41, P1136, DOI 10.1044/jslhr.4105.1136
   Dunn CC, 2008, EAR HEARING, V29, P352, DOI 10.1097/AUD.0b013e318167b870
   Edwards M. L., 1974, J CHILD LANG, V1, P205, DOI [DOI 10.1017/S0305000900000659, 10.1017/S0305000900000659]
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Eisenberg LS, 2000, J ACOUST SOC AM, V107, P2704, DOI 10.1121/1.428656
   FORREST K, 1988, J ACOUST SOC AM, V84, P115, DOI 10.1121/1.396977
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538
   Goldman R, 2000, GOLDMAN FRISTOE TEST
   Horga D, 2006, CLIN LINGUIST PHONET, V20, P211, DOI 10.1080/02699200400027015
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213
   Jafari N, 2016, J VOICE, V30, P340, DOI 10.1016/j.jvoice.2015.04.012
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   Kant AR, 2012, CLIN EXP OTORHINOLAR, V5, pS14, DOI 10.3342/ceo.2012.5.S1.S14
   Kewley-Port D. K., 1974, J PHONETICS, V2, P195
   Levy ES, 2010, J ACOUST SOC AM, V128, P1290, DOI 10.1121/1.3466879
   Li FF, 2017, J SPEECH LANG HEAR R, V60, P2427, DOI 10.1044/2017_JSLHR-S-16-0125
   Liker M, 2007, CLIN LINGUIST PHONET, V21, P1, DOI 10.1080/02699200400026991
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Lowenstein JH, 2008, J ACOUST SOC AM, V124, P1180, DOI 10.1121/1.2945118
   MACKEN MA, 1980, J CHILD LANG, V7, P41, DOI 10.1017/S0305000900007029
   Mahshie J, 2015, EAR HEARING, V36, P653, DOI 10.1097/AUD.0000000000000181
   McGowan RS, 2008, J SPEECH LANG HEAR R, V51, P879, DOI 10.1044/1092-4388(2008/064)
   Mildner V, 2008, CLIN LINGUIST PHONET, V22, P845, DOI 10.1080/02699200802130557
   Milenkovic P., 2005, TF32 COMPUTER PROGRA
   NITTROUER S, 1993, J SPEECH HEAR RES, V36, P959, DOI 10.1044/jshr.3605.959
   NITTROUER S, 1995, J ACOUST SOC AM, V97, P520, DOI 10.1121/1.412278
   Nittrouer S, 2014, APPL PSYCHOLINGUIST, V35, P333, DOI 10.1017/S0142716412000410
   Nittrouer S, 2010, J ACOUST SOC AM, V127, P1624, DOI 10.1121/1.3298435
   Nittrouer S, 2009, J EXP PSYCHOL HUMAN, V35, P1245, DOI 10.1037/a0015020
   Perkell JS, 2004, J ACOUST SOC AM, V116, P2338, DOI 10.1121/1.1787524
   Reidy PF, 2017, EAR HEARING, V38, P42, DOI 10.1097/AUD.0000000000000349
   Salas-Provance Marlene B, 2014, Cochlear Implants Int, V15, P222, DOI 10.1179/1754762813Y.0000000046
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Todd AE, 2011, J ACOUST SOC AM, V130, P3969, DOI 10.1121/1.3652852
   Uchanski RM, 2003, EAR HEARING, V24, p90S, DOI 10.1097/01.AUD.0000051744.24290.C1
   Werker JF, 1999, ANNU REV PSYCHOL, V50, P509, DOI 10.1146/annurev.psych.50.1.509
   Yang J, 2015, J ACOUST SOC AM, V138, P2791, DOI 10.1121/1.4932165
   ZLATIN MA, 1976, J SPEECH HEAR RES, V19, P93, DOI 10.1044/jshr.1901.93
NR 49
TC 2
Z9 2
U1 1
U2 7
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD APR
PY 2019
VL 62
IS 4
BP 853
EP +
DI 10.1044/2018_JSLHR-S-18-0178
PG 15
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA HT5MS
UT WOS:000464608600005
PM 30986136
OA Green Published
DA 2021-02-24
ER

PT J
AU Peng, ZE
   Wang, LM
AF Peng, Z. Ellen
   Wang, Lily M.
TI Listening Effort by Native and Nonnative Listeners Due to Noise,
   Reverberation, and Talker Foreign Accent During English Speech
   Perception
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID RECOGNITION; DIFFICULTY; AGE; INTELLIGIBILITY; COMMUNICATION;
   CLASSROOMS; TASK
AB Purpose: Understanding speech in complex realistic acoustic environments requires effort. In everyday listening situations, speech quality is often degraded due to adverse acoustics, such as excessive background noise level (BNL) and reverberation time (RT), or talker characteristics such as foreign accent (Mattys, Davis, Bradlow, & Scott, 2012). In addition to factors affecting the quality of the input acoustic signals, listeners' individual characteristics such as language abilities can also make it more difficult and effortful to understand speech. Based on the Framework for Understanding Effortful Listening (Pichora-Fuller et al., 2016), factors such as adverse acoustics, talker accent, and listener language abilities can all contribute to increasing listening effort. In this study, using both a dual-task paradigm and a self-report questionnaire, we seek to understand listening effort in a wide range of realistic classroom acoustic conditions as well as varying talker accent and listener English proficiency.
   Method: One hundred fifteen native and nonnative adult listeners with normal hearing were tested in a dual task of speech comprehension and adaptive pursuit rotor (APR) under 15 acoustic conditions from combinations of BNLs and RTs. Listeners provided responses on the NASA Task Load Index (TLX) questionnaire immediately after completing the dual task under each acoustic condition. The NASA TLX surveyed 6 dimensions of perceived listening effort: mental demand, physical demand, temporal demand, effort, frustration, and perceived performance. Fifty-six listeners were tested with speech produced by native American English talkers; the other 59 listeners, with speech from native Mandarin Chinese talkers. Based on their 1st language learned during childhood, 3 groups of listeners were recruited: listeners who were native English speakers, native Mandarin Chinese speakers, and native speakers of other languages (e.g., Hindu, Korean, and Portuguese).
   Results: Listening effort was measured objectively through the APR task performance and subjectively using the NASA TLX questionnaire. Performance on the APR task did not vary with changing acoustic conditions, but it did suggest increased listening effort for native listeners of other languages compared to the 2 other listener groups. From the NASA TLX, listeners reported feeling more frustrated and less successful in understanding Chinese-accented speech. Nonnative listeners reported more listening effort (i.e., physical demand, temporal demand, and effort) than native listeners in speech comprehension under adverse acoustics. When listeners' English proficiency was controlled, higher BNL was strongly related to a decrease in perceived performance, whereas such relationship with RT was much weaker. Nonnative listeners who shared the foreign talkers' accent reported no change in listening effort, whereas other listeners reported more difficulty in understanding the accented speech.
   Conclusions: Adverse acoustics required more effortful listening as measured subjectively with a self-report NASA TLX. This subjective scale was more sensitive than a dual task that involved speech comprehension, which was beyond sentence recall. It was better at capturing the negative impacts on listening effort from acoustic factors (i.e., both BNL and RT), talker accent, and listener language abilities.
C1 [Peng, Z. Ellen; Wang, Lily M.] Univ Nebraska, Durham Sch Architectural Engn & Construct, Omaha, NE 68182 USA.
   [Peng, Z. Ellen] Univ Wisconsin, Waisman Ctr, Madison, WI 53706 USA.
RP Peng, ZE (corresponding author), Univ Nebraska, Durham Sch Architectural Engn & Construct, Omaha, NE 68182 USA.; Peng, ZE (corresponding author), Univ Wisconsin, Waisman Ctr, Madison, WI 53706 USA.
EM z.ellen.peng@wisc.edu
FU Paul S. Veneklasen Research Foundation; Durham School of Architectural
   Engineering and Construction at the University of Nebraska-Lincoln
FX This research was funded by the Paul S. Veneklasen Research Foundation,
   awarded to L. M. W. and Z. E. P., and by a research seed grant from the
   Durham School of Architectural Engineering and Construction at the
   University of Nebraska-Lincoln, awarded to L. M. W.
CR Ahlstrom JB, 2014, EAR HEARING, V35, P72, DOI 10.1097/AUD.0b013e3182a02274
   Bent T, 2003, J ACOUST SOC AM, V114, P1600, DOI 10.1121/1.1603234
   Bent T, 2010, J ACOUST SOC AM, V128, P3142, DOI 10.1121/1.3493428
   BLAZIER WE, 1981, ASHRAE J, V23, P34
   Bologna WJ, 2013, J ACOUST SOC AM, V134, pEL352, DOI 10.1121/1.4820808
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Bradlow AR, 2002, J ACOUST SOC AM, V112, P272, DOI 10.1121/1.1487837
   Broadbent D., 1958, PERCEPTION COMMUNICA
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Desjardins JL, 2013, EAR HEARING, V34, P261, DOI 10.1097/AUD.0b013e31826d0ba4
   Educational Testing Service, TOEIC LIST READ TEST
   Harris KC, 2010, HEARING RES, V264, P21, DOI 10.1016/j.heares.2009.09.017
   HART S G, 1988, P139
   Hart SG, 2006, P HUM FACT ERG SOC A
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hodgson M, 1999, J ACOUST SOC AM, V105, P226, DOI 10.1121/1.424600
   Howard CS, 2010, INT J AUDIOL, V49, P928, DOI 10.3109/14992027.2010.520036
   Kahneman Daniel., 1973, AM J PSYCHOL, V88, P339, DOI [10.2307/1421603, DOI 10.2307/1421603]
   Lacouture Parodi Y, 2011, AUD ENG SOC CONV NEW
   Lauren Frohlich, 2010, CONDITION ED 2010
   Ljung R, 2009, BUILD ACOUST, V16, P301, DOI 10.1260/135101009790291273
   Mackersie CL, 2011, J AM ACAD AUDIOL, V22, P113, DOI 10.3766/jaaa.22.2.6
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   McGarrigle R, 2014, INT J AUDIOL, V53, P433, DOI 10.3109/14992027.2014.890296
   MunozSandoval A. F, 1998, BILINGUAL VERBAL ABI
   National Science Board, 2012, ASDF
   Pearson, 2008, VERS ENGL TEST
   Peelle JE, 2018, EAR HEARING, V39, P204, DOI 10.1097/AUD.0000000000000494
   Peng ZE, 2016, J ACOUST SOC AM, V139, P2772, DOI 10.1121/1.4948564
   Peng Z.F., 2014, THESIS
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Picou EM, 2016, EAR HEARING, V37, P1, DOI 10.1097/AUD.0000000000000222
   Prodi N, 2010, J ACOUST SOC AM, V128, P172, DOI 10.1121/1.3436563
   Rogers CL, 2006, APPL PSYCHOLINGUIST, V27, P465, DOI 10.1017/S014271640606036X
   Ronsse LM, 2010, ASHRAE TRAN, V116, P347
   Sato H, 2005, J ACOUST SOC AM, V117, P1157, DOI 10.1121/1.1849936
   Sato H, 2008, J ACOUST SOC AM, V123, P2064, DOI 10.1121/1.2839283
   Shield B, 2004, J ACOUST SOC AM, V115, P730, DOI 10.1121/1.1635837
   Shield B, 2015, J ACOUST SOC AM, V137, P177, DOI 10.1121/1.4904528
   Srinivasan N. K., 2010, THESIS
   Van Engen KJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00577
   Veneman CE, 2013, EAR HEARING, V34, P288, DOI 10.1097/AUD.0b013e31826d0b81
   Woodcock R. W., 2001, WOODCOCK JOHNSON 3 T
   Woodcock R. W., 2001, WOODCOCK JOHNSON TES
NR 44
TC 5
Z9 5
U1 2
U2 16
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD APR
PY 2019
VL 62
IS 4
BP 1068
EP 1081
DI 10.1044/2018_JSLHR-H-17-0423
PG 14
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA HT5MS
UT WOS:000464608600021
PM 30986135
DA 2021-02-24
ER

PT J
AU Flinker, A
   Doyle, WK
   Mehta, AD
   Devinsky, O
   Poeppel, D
AF Flinker, Adeen
   Doyle, Werner K.
   Mehta, Ashesh D.
   Devinsky, Orrin
   Poeppel, David
TI Spectrotemporal modulation provides a unifying framework for auditory
   cortical asymmetries
SO NATURE HUMAN BEHAVIOUR
LA English
DT Article
ID HEMISPHERIC-ASYMMETRY; SPEECH-PERCEPTION; SPECTRAL BANDWIDTH; CORTEX;
   SENSITIVITY; PITCH; SPECIALIZATION; FREQUENCY; RESPONSES; LANGUAGE
AB The principles underlying functional asymmetries in cortex remain debated. For example, it is accepted that speech is processed bilaterally in auditory cortex, but a left hemisphere dominance emerges when the input is interpreted linguistically. The mechanisms, however, are contested, such as what sound features or processing principles underlie laterality. Recent findings across species (humans, canines and bats) provide converging evidence that spectrotemporal sound features drive asymmetrical responses. Typically, accounts invoke models wherein the hemispheres differ in time-frequency resolution or integration window size. We develop a framework that builds on and unifies prevailing models, using spectrotemporal modulation space. Using signal processing techniques motivated by neural responses, we test this approach, employing behavioural and neurophysiological measures. We show how psychophysical judgements align with spectrotemporal modulations and then characterize the neural sensitivities to temporal and spectral modulations. We demonstrate differential contributions from both hemispheres, with a left lateralization for temporal modulations and a weaker right lateralization for spectral modulations. We argue that representations in the modulation domain provide a more mechanistic basis to account for lateralization in auditory cortex.
C1 [Flinker, Adeen; Poeppel, David] NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
   [Flinker, Adeen; Devinsky, Orrin] NYU, Sch Med, Dept Neurol, New York, NY 10003 USA.
   [Doyle, Werner K.] NYU, Sch Med, Dept Neurosurg, New York, NY USA.
   [Mehta, Ashesh D.] Donald & Barbara Zucker Sch Med Hofstra Northwell, Dept Neurosurg, Manhasset, NY USA.
   [Poeppel, David] Max Planck Inst Empir Aesthet, Frankfurt, Germany.
RP Flinker, A (corresponding author), NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.; Flinker, A (corresponding author), NYU, Sch Med, Dept Neurol, New York, NY 10003 USA.
EM adeen.f@gmail.com
OI Devinsky, Orrin/0000-0003-0044-4632; Flinker, Adeen/0000-0003-1247-1283
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [F32 DC011985, 2R01DC05660]; Charles H.
   Revson Senior Fellowships in Biomedical Science [15-28]; NIMHUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute of Mental Health (NIMH) [R21
   MH114166-01]; NATIONAL INSTITUTE OF MENTAL HEALTHUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute of Mental Health (NIMH) [R21MH114166,
   R21MH114166] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC005660, R01DC005660, R01DC005660] Funding Source: NIH RePORTER
FX This work was supported by NIH F32 DC011985 and Charles H. Revson Senior
   Fellowships in Biomedical Science 15-28 to A.F., by NIH 2R01DC05660 to
   D.P. and by NIMH R21 MH114166-01 to A.D.M. The funders had no role in
   study design, data collection and analysis, decision to publish or
   preparation of the manuscript. We would like to thank I.T. Kim and N.
   Mei, who assisted in the setup and acquisition of psychophysical
   dichotic data, B. Mahmood and M. Hofstradter, who assisted in NYU ECoG
   data acquisition and setup, D. Groppe, who assisted in North Shore ECoG
   data acquisition and electrode reconstruction, and H. Wang, who provided
   electrode reconstruction at NYU.
CR Adachi Y, 2001, IEEE T APPL SUPERCON, V11, P669, DOI 10.1109/77.919433
   Arnal LH, 2015, CURR BIOL, V25, P2051, DOI 10.1016/j.cub.2015.06.043
   Arsenault JS, 2015, J NEUROSCI, V35, P634, DOI 10.1523/JNEUROSCI.2454-14.2015
   Ashburner J, 2007, NEUROIMAGE, V38, P95, DOI 10.1016/j.neuroimage.2007.07.007
   Barton B, 2012, P NATL ACAD SCI USA, V109, P20738, DOI 10.1073/pnas.1213381109
   Belin P, 1998, J COGNITIVE NEUROSCI, V10, P536, DOI 10.1162/089892998562834
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   Bozic M, 2010, P NATL ACAD SCI USA, V107, P17439, DOI 10.1073/pnas.1000531107
   Broca P., 1861, B SOC ANAT PARIS, V6, P330, DOI DOI 10.1093/ACPROF:OSO/9780195177640.003.0018
   Camacho A, 2008, J ACOUST SOC AM, V124, P1638, DOI 10.1121/1.2951592
   Chi T., 2005, NSL MATLAB TOOLBOX
   Chi TS, 1999, J ACOUST SOC AM, V106, P2719, DOI 10.1121/1.428100
   Collingridge DS, 2013, J MIX METHOD RES, V7, P81, DOI 10.1177/1558689812454457
   Dale AM, 2000, NEURON, V26, P55, DOI 10.1016/S0896-6273(00)81138-1
   de Cheveigne A, 2007, J NEUROSCI METH, V165, P297, DOI 10.1016/j.jneumeth.2007.06.003
   De Valois Russel, 1990, SPATIAL VISION
   Ding N, 2017, NEUROSCI BIOBEHAV R, V81, P181, DOI 10.1016/j.neubiorev.2017.02.011
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P2670, DOI 10.1121/1.409836
   EFRON R, 1963, BRAIN, V86, P403, DOI 10.1093/brain/86.3.403
   Elhilali M, 2003, SPEECH COMMUN, V41, P331, DOI 10.1016/S0167-6393(02)00134-6
   Elliott TM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000302
   Flinker A, 2015, P NATL ACAD SCI USA, V112, P2871, DOI 10.1073/pnas.1414491112
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   Gabor D., 1946, Journal of the Institution of Electrical Engineers. III. Radio and Communication Engineering, V93, P429
   Garofolo J., 1993, TIMIT ACOUSTIC PHONE
   Gervain J, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00916
   Ghitza O, 2001, J ACOUST SOC AM, V110, P1628, DOI 10.1121/1.1396325
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Goetz C. G., 2007, TXB CLIN NEUROLOGY, P355
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   Groppe DM, 2017, J NEUROSCI METH, V281, P40, DOI 10.1016/j.jneumeth.2017.01.022
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Hagoort P, 2014, ANNU REV NEUROSCI, V37, P347, DOI 10.1146/annurev-neuro-071013-013847
   Herdener M, 2013, CORTEX, V49, P2822, DOI 10.1016/j.cortex.2013.04.003
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   HOUTGAST T, 1985, J ACOUST SOC AM, V77, P1069, DOI 10.1121/1.392224
   Hyde KL, 2008, NEUROPSYCHOLOGIA, V46, P632, DOI 10.1016/j.neuropsychologia.2007.09.004
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Jamison HL, 2006, CEREB CORTEX, V16, P1266, DOI 10.1093/cercor/bhj068
   Joanisse MF, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00306
   Joris PX, 2004, PHYSIOL REV, V84, P541, DOI 10.1152/physrev.00029.2003
   Kandel E. R., 2000, PRINCIPLES NEURAL SC, P457
   Kimura D, 1967, CORTEX, V3, P163, DOI [DOI 10.1016/S0010-9452(67)80010-8, 10.1016/s0010-9452(67)80010-8]
   Kowalski N, 1996, J NEUROPHYSIOL, V76, P3503
   Lawrence M. A., 2016, PACKAGE EZ
   Liegeois-Chauvel C, 1999, CEREB CORTEX, V9, P484, DOI 10.1093/cercor/9.5.484
   Liegeois-Chauvel C, 2004, CEREB CORTEX, V14, P731, DOI 10.1093/cercor/bhh033
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Luo H, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00170
   McGettigan C, 2012, TRENDS COGN SCI, V16, P269, DOI 10.1016/j.tics.2012.04.006
   Millman RE, 2011, NEUROIMAGE, V54, P2364, DOI 10.1016/j.neuroimage.2010.10.005
   Moore B., 1995, HEARING
   MOORE BCJ, 1981, J ACOUST SOC AM, V70, P1003, DOI 10.1121/1.386950
   Morillon B, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00248
   Morillon B, 2010, P NATL ACAD SCI USA, V107, P18688, DOI 10.1073/pnas.1007189107
   Obleser J, 2008, J NEUROSCI, V28, P8116, DOI 10.1523/JNEUROSCI.1290-08.2008
   Okamoto H., 2009, CEREB CORTEX, V19, P245
   Okamoto H, 2015, BRAIN TOPOGR, V28, P471, DOI 10.1007/s10548-013-0347-1
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Overath T, 2015, NAT NEUROSCI, V18, P903, DOI 10.1038/nn.4021
   Overath T, 2012, J NEUROPHYSIOL, V107, P2042, DOI 10.1152/jn.00308.2011
   Overath T, 2008, J NEUROSCI, V28, P13268, DOI 10.1523/JNEUROSCI.4596-08.2008
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Poeppel D, 2001, COGNITIVE SCI, V25, P679, DOI 10.1016/S0364-0213(01)00050-7
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Prins N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01250
   Ratcliffe VF, 2014, CURR BIOL, V24, DOI 10.1016/j.cub.2014.10.030
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   ROBIN DA, 1990, BRAIN LANG, V39, P539, DOI 10.1016/0093-934X(90)90161-9
   ROSS ED, 1979, ARCH NEUROL-CHICAGO, V36, P144, DOI 10.1001/archneur.1979.00500390062006
   Santoro R, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003412
   Schonwiesner M, 2009, P NATL ACAD SCI USA, V106, P14611, DOI 10.1073/pnas.0907682106
   Schonwiesner M, 2005, EUR J NEUROSCI, V22, P1521, DOI 10.1111/j.1460-9568.2005.04315.x
   SCHWARTZ J, 1980, SCIENCE, V207, P1380, DOI 10.1126/science.7355297
   Scott SK, 2013, BRAIN LANG, V127, P36, DOI 10.1016/j.bandl.2013.07.006
   Shamma S, 2001, TRENDS COGN SCI, V5, P340, DOI 10.1016/S1364-6613(00)01704-6
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   SHAPLEY R, 1985, ANNU REV NEUROSCI, V8, P547, DOI 10.1146/annurev.ne.08.030185.002555
   TALLAL P, 1973, NATURE, V241, P468, DOI 10.1038/241468a0
   Thompson EC, 2016, SCI REP-UK, V6, DOI 10.1038/srep19737
   TUCKER DM, 1977, NEUROLOGY, V27, P947, DOI 10.1212/WNL.27.10.947
   Venezia JH, 2016, J ACOUST SOC AM, V140, P1072, DOI 10.1121/1.4960544
   von Kriegstein K, 2010, J NEUROSCI, V30, P629, DOI 10.1523/JNEUROSCI.2742-09.2010
   Wang YD, 2012, J NEUROPHYSIOL, V107, P2033, DOI 10.1152/jn.00310.2011
   Washington SD, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00143
   Washington SD, 2012, J NEUROPHYSIOL, V108, P1548, DOI 10.1152/jn.00952.2011
   Wernicke C., 1874, APHASISCHE SYMPTOMEN
   Woolley SMN, 2005, NAT NEUROSCI, V8, P1371, DOI 10.1038/nn1536
   Yang AI, 2012, NEUROIMAGE, V63, P157, DOI 10.1016/j.neuroimage.2012.06.039
   ZATORRE RJ, 1992, SCIENCE, V256, P846, DOI 10.1126/science.1589767
   ZATORRE RJ, 1988, J ACOUST SOC AM, V84, P566, DOI 10.1121/1.396834
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
   Zatorre RJ, 2008, PHILOS T R SOC B, V363, P1087, DOI 10.1098/rstb.2007.2161
NR 97
TC 22
Z9 22
U1 6
U2 11
PU NATURE PUBLISHING GROUP
PI NEW YORK
PA 75 VARICK ST, 9TH FLR, NEW YORK, NY 10013-1917 USA
SN 2397-3374
J9 NAT HUM BEHAV
JI Nat. Hum. Behav.
PD APR
PY 2019
VL 3
IS 4
BP 393
EP 405
DI 10.1038/s41562-019-0548-z
PG 13
WC Psychology, Biological; Multidisciplinary Sciences; Neurosciences;
   Psychology, Experimental
SC Psychology; Science & Technology - Other Topics; Neurosciences &
   Neurology
GA HS7BC
UT WOS:000464024000019
PM 30971792
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Wang, HZ
   Wang, YF
   Hu, YS
AF Wang, Huizhi
   Wang, Yifang
   Hu, Yousong
TI Emotional Understanding in Children with A Cochlear Implant
SO JOURNAL OF DEAF STUDIES AND DEAF EDUCATION
LA English
DT Article
ID FACIAL EXPRESSION RECOGNITION; SPEECH-PERCEPTION; HEARING-LOSS; MIND
   DEVELOPMENT; LANGUAGE; PRESCHOOLERS; YOUNG; AGE; COMPREHENSION; CONTEXT
AB Emotional understanding plays an important role in the physical and mental health of children. To determine whether the development of emotional understanding is delayed in children with a cochlear implant (CI), 30 children with a CI and 30 matched children with typical hearing aged between 3 and 9 years old completed three tasks (facial expression, tone expression and scene of emotion matching), in which they identified four basic emotions (happiness, sadness, anger, and fear). The participants included 40 preschool children and 20 school-aged children. Compared with the children with typical hearing, the children with a CI were significantly delayed in the ability to understand emotion; the tone expression matching task was the most difficult task for all participants; and the school-aged children performed better than the preschool children, but this trend was only observed in the typical hearing group; and happiness was the easiest emotion to identify.
C1 [Wang, Huizhi; Wang, Yifang] Capital Normal Univ, 23 Baiduizijia, Beijing, Peoples R China.
   [Hu, Yousong] South China Normal Univ, Guangzhou, Guangdong, Peoples R China.
RP Wang, YF (corresponding author), Capital Normal Univ, 23 Baiduizijia, Beijing, Peoples R China.
EM wangyifang6275@126.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [31371058]; State Administration of Press,
   Publication, Radio, Film and Television of The People's Republic of
   China [GD1608]
FX The research was supported by National Natural Science Foundation of
   China [Grant number 31371058 to Wang Yifang] and State Administration of
   Press, Publication, Radio, Film and Television of The People's Republic
   of China [Grant number GD1608 to Wang Yifang].
CR Anastasi JS, 2005, PSYCHON B REV, V12, P1043, DOI 10.3758/BF03206441
   Anolli L, 2008, J CROSS CULT PSYCHOL, V39, P565, DOI 10.1177/0022022108321178
   Barrett LF, 2007, TRENDS COGN SCI, V11, P327, DOI 10.1016/j.tics.2007.06.003
   Blamey PJ, 2001, J SPEECH LANG HEAR R, V44, P264, DOI 10.1044/1092-4388(2001/022)
   Brown JR, 1996, CHILD DEV, V67, P789, DOI 10.1111/j.1467-8624.1996.tb01764.x
   Calder AJ, 2000, J EXP PSYCHOL HUMAN, V26, P527, DOI 10.1037/0096-1523.26.2.527
   Calmels MN, 2004, INT J PEDIATR OTORHI, V68, P347, DOI 10.1016/j.ijporl.2003.11.006
   CAMRAS LA, 1990, DEV PSYCHOL, V26, P304
   Chatterjee Monita, 2015, Journal of the Acoustical Society of America, V137, DOI 10.1121/1.4920020
   COOPER RP, 1990, CHILD DEV, V61, P1584, DOI 10.1111/j.1467-8624.1990.tb02885.x
   Day KL, 2013, EARLY CHILD RES Q, V28, P405, DOI 10.1016/j.ecresq.2012.10.003
   de Villiers PA, 2012, BRIT J DEV PSYCHOL, V30, P188, DOI 10.1111/j.2044-835X.2011.02072.x
   DENHAM SA, 1990, CHILD DEV, V61, P1145, DOI 10.1111/j.1467-8624.1990.tb02848.x
   DENHAM SA, 1994, DEV PSYCHOL, V30, P928, DOI 10.1037/0012-1649.30.6.928
   Denham SA, 2012, LEARN INDIVID DIFFER, V22, P178, DOI 10.1016/j.lindif.2011.05.001
   Dupuis K, 2010, PSYCHOL AGING, V25, P16, DOI 10.1037/a0018777
   FERNALD A, 1993, CHILD DEV, V64, P657, DOI 10.2307/1131209
   Flavell JH, 2004, MERRILL PALMER QUART, V50, P274, DOI 10.1353/mpq.2004.0018
   GROSS AL, 1991, DEV REV, V11, P368, DOI 10.1016/0273-2297(91)90019-K
   Herba C, 2004, J CHILD PSYCHOL PSYC, V45, P1185, DOI 10.1111/j.1469-7610.2004.00316.x
   Hintermair M, 2016, OXFORD HDB DEAF STUD, DOI [10.1093/oxfordhb/9780190241414.013.5, DOI 10.1093/OXFORDHB/9780190241414.013.5]
   Hopyan T, 2016, CHILD NEUROPSYCHOL, V22, P366, DOI 10.1080/09297049.2014.992400
   Hopyan-Misakyan TM, 2009, CHILD NEUROPSYCHOL, V15, P136, DOI 10.1080/09297040802403682
   Liang Q., 2013, COCHLEAR IMPLANTS S1, V1, pS26, DOI DOI 10.1179/1467010013Z.00000000080
   Lidstone JSM, 2012, DEV PSYCHOPATHOL, V24, P651, DOI 10.1017/S0954579412000223
   Mancini P, 2016, INT J PEDIATR OTORHI, V87, P219, DOI 10.1016/j.ijporl.2016.06.033
   Matsuda S, 2014, RES AUTISM SPECT DIS, V8, P944, DOI 10.1016/j.rasd.2014.04.010
   McClure EB, 2000, PSYCHOL BULL, V126, P424, DOI 10.1037/0033-2909.126.3.424
   Mildner V, 2006, CLIN LINGUIST PHONET, V20, P219, DOI 10.1080/02699200400027031
   Mildner V, 2014, CLIN LINGUIST PHONET, V28, P543, DOI 10.3109/02699206.2014.927000
   Montagne B, 2005, PERS INDIV DIFFER, V38, P5, DOI 10.1016/j.paid.2004.02.008
   Moore BCJ, 1996, EAR HEARING, V17, P133, DOI 10.1097/00003446-199604000-00007
   Morton JB, 2001, CHILD DEV, V72, P834, DOI 10.1111/1467-8624.00318
   MOST T, 1993, BRIT J AUDIOL, V27, P247, DOI 10.3109/03005369309076701
   Most T, 2012, J SPEECH LANG HEAR R, V55, P1148, DOI 10.1044/1092-4388(2011/11-0060)
   Most T, 2009, J DEAF STUD DEAF EDU, V14, P449, DOI 10.1093/deafed/enp007
   Nakata T, 2012, J ACOUST SOC AM, V131, P1307, DOI 10.1121/1.3672697
   Pons F, 2004, EUR J DEV PSYCHOL, V1, P127, DOI 10.1080/17405620344000022
   RIBORDY SC, 1988, J CLIN CHILD PSYCHOL, V17, P322, DOI 10.1207/s15374424jccp1704_4
   Rieffe C, 2000, J CHILD PSYCHOL PSYC, V41, P601, DOI 10.1111/1469-7610.00647
   Rieffe C, 2017, RES DEV DISABIL, V62, P40, DOI 10.1016/j.ridd.2016.12.018
   Rieffe C, 2012, EUR CHILD ADOLES PSY, V21, P349, DOI 10.1007/s00787-012-0267-8
   Schick B, 2007, CHILD DEV, V78, P376, DOI 10.1111/j.1467-8624.2007.01004.x
   Shackman JE, 2005, CHILD DEV, V76, P1116, DOI 10.1111/j.1467-8624.2005.00901.x
   Sidera F, 2017, J DEAF STUD DEAF EDU, V22, P164, DOI 10.1093/deafed/enw072
   Stanzione C, 2014, TOP LANG DISORD, V34, P296, DOI 10.1097/TLD.0000000000000038
   Symons DK, 2004, DEV REV, V24, P159, DOI 10.1016/j.dr.2004.03.001
   Tager-Flusberg H, 2000, COGNITION, V76, P59, DOI 10.1016/S0010-0277(00)00069-X
   Taumoepeau M, 2008, CHILD DEV, V79, P284, DOI 10.1111/j.1467-8624.2007.01126.x
   WALLBOTT HG, 1986, J PERS SOC PSYCHOL, V51, P690, DOI 10.1037/0022-3514.51.4.690
   Wang AT, 2004, J AM ACAD CHILD PSY, V43, P481, DOI 10.1097/00004583-200404000-00015
   Wang DJ, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00351
   Wang Y, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01699
   Wang YJ, 2012, CHIN J CHROMATOGR, V30, P847, DOI 10.3724/SP.J.1123.2012.04013
   Wang YF, 2011, RES DEV DISABIL, V32, P2583, DOI 10.1016/j.ridd.2011.06.019
   Widen SC, 2008, COGNITIVE DEV, V23, P291, DOI 10.1016/j.cogdev.2008.01.002
   Wiefferink CH, 2013, J DEAF STUD DEAF EDU, V18, P175, DOI 10.1093/deafed/ens042
   Xin Luo, 2007, Trends Amplif, V11, P301
   Ziv M, 2013, J DEAF STUD DEAF EDU, V18, P161, DOI 10.1093/deafed/ens073
NR 59
TC 1
Z9 1
U1 2
U2 7
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1081-4159
EI 1465-7325
J9 J DEAF STUD DEAF EDU
JI J. Deaf Stud. Deaf Educ.
PD APR
PY 2019
VL 24
IS 2
BP 65
EP 73
DI 10.1093/deafed/eny031
PG 9
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA HS4FD
UT WOS:000463816500002
PM 30295845
DA 2021-02-24
ER

PT J
AU Todd, S
   Pierrehumbert, JB
   Hay, J
AF Todd, Simon
   Pierrehumbert, Janet B.
   Hay, Jennifer
TI Word frequency effects in sound change as a consequence of perceptual
   asymmetries: An exemplar-based model
SO COGNITION
LA English
DT Article
DE Exemplar Theory; Sound change; Computational model; Lexical frequency;
   Speech perception
ID SPEECH-PERCEPTION; RECOGNITION; IDENTIFICATION; CONTEXT; TIME;
   INTELLIGIBILITY; CATEGORIZATION; INFORMATION; ADAPTATION; DURATIONS
AB Empirically-observed word frequency effects in regular sound change present a puzzle: how can high-frequency words change faster than low-frequency words in some cases, slower in other cases, and at the same rate in yet other cases? We argue that this puzzle can be answered by giving substantial weight to the role of the listener. We present an exemplar-based computational model of regular sound change in which the listener plays a large role, and we demonstrate that it generates sound changes with properties and word frequency effects seen in corpora. In particular, we consider the experimentally-supported assumption that high-frequency words may be more robustly recognized than low-frequency words in the face of acoustic ambiguity. We show that this assumption allows high-frequency words to change at the same rate as low-frequency words when a phoneme category moves without encroaching on the acoustic space of another, faster than low-frequency words when it moves toward another, and slower than low-frequency words when it moves away from another. We discuss how these predicted word frequency effects apply to different types of sound changes that have been observed in the literature. Importantly, these frequency effects follow from assumptions regarding processes in perception, not production. Frequency-based asymmetries in perception predict different frequency effects for different kinds of sound change.
C1 [Todd, Simon] Stanford Univ, Dept Linguist, Margaret Jacks Hall,Bldg 460, Stanford, CA 94305 USA.
   [Pierrehumbert, Janet B.] Univ Oxford, Oxford E Res Ctr, 7 Keble Rd, Oxford OX1 3QG, England.
   [Pierrehumbert, Janet B.; Hay, Jennifer] Univ Canterbury, New Zealand Inst Language Brain & Behav, Private Bag 4800, Christchurch, New Zealand.
   [Hay, Jennifer] Univ Canterbury, Dept Linguist, Private Bag 4800, Christchurch, New Zealand.
RP Todd, S (corresponding author), Stanford Univ, Dept Linguist, Margaret Jacks Hall,Bldg 460, Stanford, CA 94305 USA.
EM sjtodd@stanford.edu
OI Todd, Simon/0000-0003-2665-5737
FU John Templeton Foundation [36617]; Royal Society of New Zealand
   Rutherford Discovery FellowshipRoyal Society of New Zealand [E5909];
   Stanford University Pigott Scholars Program Fellowship; University of
   Canterbury; Foundation for Research, Science and TechnologyNew Zealand
   Foundation for Research, Science and Technology; Royal Society of New
   ZealandRoyal Society of New Zealand; New Zealand Lotteries Board Fund;
   Canterbury History Foundation
FX This work was supported by a grant from the John Templeton Foundation
   (Award ID 36617) to JBP and JH, a Royal Society of New Zealand
   Rutherford Discovery Fellowship (Grant No. E5909) to JH, and a Stanford
   University Pigott Scholars Program Fellowship to ST. The opinions
   expressed in this publication are those of the authors and do not
   necessarily reflect the views of the funding agencies.; The ONZE data
   were collected by the Mobile Disc recording Unit of the NZ Broadcasting
   Service, Rosemary Goodyear, Lesley Evans, members of the NZ English
   class of the University of Canterbury Linguistics Department, and
   members of the ONZE team. The work done by members of the ONZE team in
   preparing the data, making transcripts, and obtaining background
   information is also gratefully acknowledged. The corpus was created and
   supported with funding from the following sources: University of
   Canterbury; Foundation for Research, Science and Technology (the New
   Zealand Public Good Appendix A. Simplifications in modeling decisions
   Science Fund); the Royal Society of New Zealand; The New Zealand
   Lotteries Board Fund; and the Canterbury History Foundation.
CR Abramowicz Lukasz, 2007, U PENNSYLVANIA WORKI, V13, P27
   Adams J., 2008, INT J LISTENING, V22, P13, DOI DOI 10.1080/10904010701802139
   Arnold JE, 2004, J MEM LANG, V51, P55, DOI 10.1016/j.jml.2004.03.006
   Bard EG, 2000, J MEM LANG, V42, P1, DOI 10.1006/jmla.1999.2667
   Baudouin de Courtenay J., 1972, BAUDOUIN COURTENAY A, P144
   Beckner C, 2009, LANG LEARN, V59, P1
   Bell A, 2009, J MEM LANG, V60, P92, DOI 10.1016/j.jml.2008.06.003
   Bermudez-Otero Ricardo, 2015, 2 ED S HIST PHON
   Blevins J, 2006, THEOR LINGUIST, V32, P117, DOI 10.1515/TL.2006.009
   Blevins J, 2009, DIACHRONICA, V26, P143, DOI 10.1075/dia.26.2.01ble
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Buz E, 2016, J MEM LANG, V89, P68, DOI 10.1016/j.jml.2015.12.009
   Bybee Joan, 2002, LANG VAR CHANGE, V14, P261, DOI DOI 10.1017/S0954394502143018
   Clapper CG, 2016, J PHONETICS, V58, P87, DOI 10.1016/j.wocn.2016.06.002
   Clarke-Davidson CM, 2008, PERCEPT PSYCHOPHYS, V70, P604, DOI 10.3758/PP.70.4.604
   Clopper Cynthia G., 2010, LAB PHONOLOGY, V1, P65, DOI DOI 10.1515/LABPH0N.2010.005
   CONNINE CM, 1991, J MEM LANG, V30, P234, DOI 10.1016/0749-596X(91)90005-5
   CONNINE CM, 1993, J EXP PSYCHOL LEARN, V19, P81, DOI 10.1037/0278-7393.19.1.81
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750
   Dahan D, 2008, COGNITION, V108, P710, DOI 10.1016/j.cognition.2008.06.003
   Dinkin A., 2008, PENN WORKING PAPERS, V14, P97
   Ettlinger M., 2007, P 16 INT C PHON SCI, P685
   Fitt S., 2000, TECHNICAL REPORT
   Flemming E, 2004, PHONETIC BASES MARKE
   FORSTER KI, 1973, J VERB LEARN VERB BE, V12, P627, DOI 10.1016/S0022-5371(73)80042-8
   Fowler CA, 2003, J MEM LANG, V49, P396, DOI 10.1016/S0749-596X(03)00072-X
   FOX RA, 1984, J EXP PSYCHOL HUMAN, V10, P526, DOI 10.1037/0096-1523.10.4.526
   Gahl S, 2008, LANGUAGE, V84, P474
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Garrett Andrew, 2015, ROUTLEDGE HDB HIST L, P227
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Harrington J., 2018, TOP COGN SCI, P1
   Hay J, 2016, LANGUAGE, V92, P298, DOI 10.1353/lan.2016.0036
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Hay JB, 2015, COGNITION, V139, P83, DOI 10.1016/j.cognition.2015.02.012
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   HINTZMAN DL, 1971, J EXP PSYCHOL, V88, P297, DOI 10.1037/h0030907
   HOWES D, 1957, J ACOUST SOC AM, V29, P296, DOI 10.1121/1.1908862
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Johnson K, 2006, J PHONETICS, V34, P485, DOI 10.1016/j.wocn.2005.08.004
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   KRUSCHKE JK, 1992, PSYCHOL REV, V99, P22, DOI 10.1037/0033-295X.99.1.22
   Labov W., 2010, PRINCIPLES LINGUISTI, V3
   LANDAUER TK, 1986, COGNITIVE SCI, V10, P477, DOI 10.1016/S0364-0213(86)80014-3
   LILJENCRANTS J, 1972, LANGUAGE, V48, P839, DOI 10.2307/411991
   LINDBLOM B, 1990, NATO ADV SCI I D-BEH, V55, P403
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Martinet A, 1952, WORD, V8, P1
   Mikolov T., 2013, CORR, P3111, DOI DOI 10.1162/JMLR.2003.3.4-5.951
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Milroy J., 1994, LANG VAR CHANGE, V6, P327, DOI DOI 10.1017/S095439450000171X
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39
   Ohala John, 1981, PAPERS PARASESSION L, P178
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720
   PHILLIPS BS, 1981, AM SPEECH, V56, P72, DOI 10.2307/454480
   PHILLIPS BS, 1984, LANGUAGE, V60, P320, DOI 10.2307/413643
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   PITT MA, 1993, J EXP PSYCHOL HUMAN, V19, P699, DOI 10.1037/0096-1523.19.4.699
   SAVIN HB, 1963, J ACOUST SOC AM, V35, P200, DOI 10.1121/1.1918432
   Snedeker J, 2003, J MEM LANG, V48, P103, DOI 10.1016/S0749-596X(02)00519-3
   Soskuthy M, 2014, SOUND CHANG INT HUM
   Soskuthy Marton, 2013, THESIS
   Strand EA, 1996, NATURAL LANGUAGE PROCESSING AND SPEECH TECHNOLOGY, P14
   Sumner M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01015
   Tamminga Meredith, 2014, P 31 W COAST C FORM, V31, P457
   Tomlinson J., 2011, 33 ANN M COGN SCI SO, P3575
   Tupper PF, 2015, SIAM J APPL MATH, V75, P1469, DOI 10.1137/140998408
   VanDam M., 2007, THESIS
   Wedel A., 2004, P 7 M ACL SPEC INT G, P1
   Wedel A, 2017, J LANG EVOL, V2, P77, DOI 10.1093/jole/lzx009
   Wedel A, 2012, LANG COGN, V4, P319, DOI 10.1515/langcog-2012-0018
   Wedel AB, 2006, LINGUIST REV, V23, P247, DOI 10.1515/TLR.2006.010
NR 80
TC 10
Z9 10
U1 1
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD APR
PY 2019
VL 185
BP 1
EP 20
DI 10.1016/j.cognition.2019.01.004
PG 20
WC Psychology, Experimental
SC Psychology
GA HR4QS
UT WOS:000463131600001
PM 30641466
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Miyashiro, D
   Toyomura, A
   Haitani, T
   Kumano, H
AF Miyashiro, Daiki
   Toyomura, Akira
   Haitani, Tomosumi
   Kumano, Hiroaki
TI Altered auditory feedback perception following an 8-week mindfulness
   meditation practice
SO INTERNATIONAL JOURNAL OF PSYCHOPHYSIOLOGY
LA English
DT Article
DE Event-related potentials; Auditory feedback; Mindfulness; Longitudinal
   practice; Delayed auditory feedback
ID COGNITIVE THERAPY; SPEECH; N1; ATTENTION; ANXIETY
AB Our own ongoing motor actions are perceived through sensory feedback pathways, and are integrated with neural processes to modulate further actions. This sensory feedback mechanism is known to contribute to the rehabilitation of impaired motor functions. Recent evidence also suggests that mindfulness meditation improves our awareness to sensation; therefore, enhancement of awareness to sensory feedback through mindfulness meditation training may have potential clinical applications. This study investigated an effect of eight-week practice of mindfulness meditation on speech perception/production processes. Among the thirty healthy participants, half of them engaged in regular meditation practice of 10 min per day for eight weeks, and the other half were not given any instructions for their daily life. The change of speech performance in sentence reading under 200 ms delayed auditory feedback (DAF) condition were assessed compared to without delay condition. Also, event-related potential response to the short sound of /a/, were measured. The result showed that, after the eight-week practice, the meditation group showed significantly improved speech fluency in the DAF condition, when 16-min meditation was introduced before the experiments. Furthermore, significantly increased auditory evoked potentials were observed in the central-parietal region when the participants listened to the delayed auditory feedback sound of their own voice. These findings provide the first glimpses into the possible relationship between mindfulness meditation and auditory feedback. Different instructions for daily activity between the meditation and control groups should be considered in further studies.
C1 [Miyashiro, Daiki] Gunma Univ, Sch Hlth Sci, Fac Med, 3-39-22 Showa Machi, Maebashi, Gunma 3718514, Japan.
   [Miyashiro, Daiki] Gunma Univ Hosp, 3-39-15 Showa Machi, Maebashi, Gunma 3718511, Japan.
   [Toyomura, Akira] Gunma Univ, Grad Sch Hlth Sci, 3-39-22 Showa Machi, Maebashi, Gunma 3718514, Japan.
   [Haitani, Tomosumi] Waseda Univ, Grad Sch Human Sci, 2-579-15 Mikajima, Tokorozawa, Saitama 3591192, Japan.
   [Haitani, Tomosumi] Natl Rehabil Ctr Persons Disabil, Dept Rehabil Sensory Funct, Res Inst, 4-1 Namiki, Tokorozawa, Saitama 3598555, Japan.
   [Kumano, Hiroaki] Waseda Univ, Fac Human Sci, 2-579-15 Mikajima, Tokorozawa, Saitama 3591192, Japan.
RP Toyomura, A (corresponding author), Gunma Univ, Grad Sch Hlth Sci, 3-39-22 Showa Machi, Maebashi, Gunma 3718514, Japan.
EM ak.toyomura@gmail.com
RI Kumano, Hiroaki/AAN-1730-2020
OI Kumano, Hiroaki/0000-0001-6245-5535
FU JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [24680025,
   16K00366, 16K04389]
FX The authors would like to thank Ms. Fukiko Sugiyama for providing a
   guidance CD for mindfulness meditation practice. This study was
   supported by JSPS KAKENHI Grant Numbers 24680025, 16K00366 and 16K04389.
   The authors declare no competing financial interests.
CR Atchley R, 2016, NEUROSCIENCE, V320, P83, DOI 10.1016/j.neuroscience.2016.01.051
   Bass P, 2008, INT J PSYCHOPHYSIOL, V70, P137, DOI 10.1016/j.ijpsycho.2008.06.005
   Barnes LJ, 2018, INT J PSYCHOPHYSIOL, V127, P26, DOI 10.1016/j.ijpsycho.2018.03.003
   Biedermann B, 2016, INT J PSYCHOPHYSIOL, V109, P63, DOI 10.1016/j.ijpsycho.2016.09.016
   Boyle MP, 2011, J FLUENCY DISORD, V36, P122, DOI 10.1016/j.jfludis.2011.04.005
   Cahn BR, 2013, SOC COGN AFFECT NEUR, V8, P100, DOI 10.1093/scan/nss060
   Cahn BR, 2009, INT J PSYCHOPHYSIOL, V72, P51, DOI 10.1016/j.ijpsycho.2008.03.013
   Cheng PT, 2004, CLIN REHABIL, V18, P747, DOI 10.1191/0269215504cr778oa
   Corey DM, 2008, J FLUENCY DISORD, V33, P291, DOI 10.1016/j.jfludis.2008.12.001
   Dambrun M, 2016, CONSCIOUS COGN, V46, P89, DOI 10.1016/j.concog.2016.09.013
   Eisendrath SJ, 2015, MINDFULNESS, V6, P475, DOI 10.1007/s12671-014-0280-8
   Evans S, 2008, J ANXIETY DISORD, V22, P716, DOI 10.1016/j.janxdis.2007.07.005
   Forkmann T, 2014, COMPR PSYCHIAT, V55, P1883, DOI 10.1016/j.comppsych.2014.08.043
   Heuchert JP, 2012, PROFILE MOOD STATES
   Hillier S, 2015, NEUROREHAB NEURAL RE, V29, P933, DOI 10.1177/1545968315573055
   Holzel BK, 2011, PERSPECT PSYCHOL SCI, V6, P537, DOI 10.1177/1745691611419671
   Kabat-Zin J., 1990, FULL CATASTROPHE LIV
   Kabat-Zinn J, 2003, CLIN PSYCHOL-SCI PR, V10, P144, DOI 10.1093/clipsy/bpg016
   Kell CA, 2018, J FLUENCY DISORD, V55, P135, DOI 10.1016/j.jfludis.2017.02.001
   Kim B, 2013, YONSEI MED J, V54, P1454, DOI 10.3349/ymj.2013.54.6.1454
   Lebedev MA, 2017, PHYSIOL REV, V97, P767, DOI 10.1152/physrev.00027.2016
   LEE BS, 1950, J ACOUST SOC AM, V22, P824, DOI 10.1121/1.1906696
   Luck S. J, 2012, OXFORD HDB EVENT REL, P99
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1
   Lutz A, 2008, TRENDS COGN SCI, V12, P163, DOI 10.1016/j.tics.2008.01.005
   MacLean KA, 2010, PSYCHOL SCI, V21, P829, DOI 10.1177/0956797610371339
   Mathias B, 2017, PSYCHOPHYSIOLOGY, V54, P235, DOI 10.1111/psyp.12781
   Monshat K, 2013, J ADOLESCENT HEALTH, V52, P572, DOI 10.1016/j.jadohealth.2012.09.008
   Moore A, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00018
   Oestreich LKL, 2015, INT J PSYCHOPHYSIOL, V97, P131, DOI 10.1016/j.ijpsycho.2015.05.014
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Omidi A, 2013, IRAN RED CRESCENT ME, V15, P142, DOI 10.5812/ircmj.8018
   Ratner N, 2007, HDB STUTTERING
   Roemmich RT, 2016, CURR BIOL, V26, P2707, DOI 10.1016/j.cub.2016.08.012
   Sasai T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123722
   Sasisekaran J, 2012, PERCEPT MOTOR SKILL, V115, P845, DOI 10.2466/15.22.PMS.115.6.845-864
   Segal Z. V., 2001, MINDFULNESS BASED CO
   Takahashi T, 2005, INT J PSYCHOPHYSIOL, V55, P199, DOI 10.1016/j.ijpsycho.2004.07.004
   Tang YY, 2015, NAT REV NEUROSCI, V16, P213, DOI 10.1038/nrn3916
   Toyomura A, 2018, NEUROSCIENCE, V374, P144, DOI 10.1016/j.neuroscience.2018.01.037
   Tschida K, 2012, CURR OPIN NEUROBIOL, V22, P320, DOI 10.1016/j.conb.2011.11.006
   Van Borsel J, 2003, INT J LANG COMM DIS, V38, P119, DOI 10.1080/1368282021000042902
   Ventura MI, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-58
   Wang J, 2014, NEUROIMAGE, V91, P91, DOI 10.1016/j.neuroimage.2014.01.003
   Yang Y, 2017, NEUROSCIENCE, V346, P216, DOI 10.1016/j.neuroscience.2016.11.033
NR 45
TC 2
Z9 2
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8760
EI 1872-7697
J9 INT J PSYCHOPHYSIOL
JI Int. J. Psychophysiol.
PD APR
PY 2019
VL 138
BP 38
EP 46
DI 10.1016/j.ijpsycho.2019.01.010
PG 9
WC Psychology, Biological; Neurosciences; Physiology; Psychology;
   Psychology, Experimental
SC Psychology; Neurosciences & Neurology; Physiology
GA HR7CH
UT WOS:000463309000004
PM 30703400
DA 2021-02-24
ER

PT J
AU Kondhalkar, H
   Mukherji, P
AF Kondhalkar, Himgauri
   Mukherji, Prachi
TI A NOVEL ALGORITHM FOR SPEECH RECOGNITION USING TONAL FREQUENCY CEPSTRAL
   COEFFICIENTS BASED ON HUMAN COCHLEA FREQUENCY MAP
SO JOURNAL OF ENGINEERING SCIENCE AND TECHNOLOGY
LA English
DT Article
DE False positive rate; Gammachirp frequency cepstral coefficients; Mel
   frequency cepstral coefficients; Human cochlea; Ohm's acoustic law;
   Speech recognition
ID SYSTEM
AB Extraction of appropriate features from speech is the core of a speech recognition system. Appropriate features can improve the accuracy of perceiving speech. Accurate speech perception is important for implementing applications like voice search, hands free dialling, voice command and control for physically disabled people. Human auditory system performs most accurate and robust perception of sound. Front end of the auditory system, named as cochlea, processes sound with remarkable sensitivity. This paper proposes a mathematical model for cochlear frequency map. This will help to develop more accurate cochlear implant leading to high level of speech recognition for hearing impaired persons. This work primarily focusses on developing a novel algorithm for feature extraction named as Tonal Frequency Cepstral Coefficients based on human cochlea frequency map. The algorithm takes advantage of the relationship between human auditory system and Ohm's acoustic law. This novel feature extraction algorithm outperforms existing feature extraction techniques like Mel Frequency Cepstral Coefficients, Linear Predictive Coding and Gammachirp Frequency Cepstral Coefficients. A hybrid classifier using neural network and fuzzification has also been developed. The classifier recognizes spoken word accurately irrespective of the speaking rate variability. The average accuracy achieved for different datasets is 99.06%, which shows significant improvement over existing algorithms.
C1 [Kondhalkar, Himgauri; Mukherji, Prachi] Sinhgad Coll Engn, Dept Elect & Telecommun Engn, S 44-1, Pune 411041, Maharashtra, India.
RP Kondhalkar, H (corresponding author), Sinhgad Coll Engn, Dept Elect & Telecommun Engn, S 44-1, Pune 411041, Maharashtra, India.
EM gouri.ghule@viit.ac.in
RI Ghule, Gauri/W-1309-2019
CR [Anonymous], 2018, SR135432018
   Arora S., 2018, P 8 INT C ADV COMM C, P38
   Arul V., 2014, J COMPUTING TECHNOLO, V3, P4
   Boussaid L, 2018, INT J SPEECH TECHNOL, V21, P29, DOI 10.1007/s10772-017-9480-7
   Chu SM, 2010, INT CONF ACOUST SPEE, P4306, DOI 10.1109/ICASSP.2010.5495656
   Dalmiya CP, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P1263
   Darabkh KA, 2018, COMPUT APPL ENG EDUC, V26, P285, DOI 10.1002/cae.21884
   Debnath S, 2017, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON COMPUTER MODELING AND SIMULATION (ICCMS 2018), P92, DOI 10.1145/3177457.3191708
   Dong Wang, 2016, 2016 Conference of The Oriental Chapter of International Committee for Coordination and Standardization of Speech Databases and Assessment Techniques (O-COCOSDA), P84, DOI 10.1109/ICSDA.2016.7918989
   Gaikwad S.K., 2010, INT J COMPUTER APPL, V10, P16, DOI [DOI 10.5120/1462-1976, 10.5120/1462-1976]
   Ganoun Ali, 2012, Journal of Electronic Science and Technology, V10, P153, DOI 10.3969/j.issn.1674-862X.2012.02.011
   Gedam Y. K., 2014, INT J ENG INNOVATIVE, V3, P198
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052
   Haridas AV, 2018, INT J KNOWL-BASED IN, V22, P39, DOI 10.3233/KES-180374
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Kapit W., 1999, PHYSL COLORING BOOK
   Li WF, 2017, IEEE ACCESS, V5, P19420, DOI 10.1109/ACCESS.2017.2730920
   Londhe ND, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P667, DOI 10.1109/SPIN.2018.8474064
   Masood Sarfaraz, 2015, 2015 ANN IEEE IND C, P1
   McDermott JH, 2008, CURR OPIN NEUROBIOL, V18, P452, DOI 10.1016/j.conb.2008.09.005
   Parker A. P., 2003, P 18 327 WAV FILT, P1
   Pratik K., 2017, IMPERIAL J INTERDISC, V3, P30
   Rahali H, 2014, EUR SIGNAL PR CONF, P696
   Rask-Andersen H, 2012, ANAT REC, V295, P1791, DOI 10.1002/ar.22599
   Ravinder K, 2010, LECT NOTES COMPUT SC, V6419, P244
   Rossing D., 2014, SCI SOUND
   Sai Srinivas N. S., 2018, 2018 International CET Conference on Control, Communication, and Computing (IC4), P278, DOI 10.1109/CETIC4.2018.8530947
   Shahnawazuddin S, 2018, CIRC SYST SIGNAL PR, V37, P5540, DOI 10.1007/s00034-018-0828-2
   Shannon BJ, 2003, MICR ENG RES C, P1
   Shao Y, 2009, INT CONF ACOUST SPEE, P4625, DOI 10.1109/ICASSP.2009.4960661
   Shrishrimal P. P., 2017, INT J ADV INNOVATIVE, V6, P37
   Sneha V, 2018, ADV INTELL SYST, V564, P185, DOI 10.1007/978-981-10-6875-1_19
   Stakhovskaya O., 2017, JARO-J ASSOC RES OTO, V8, P220
   Tailor J. H., 2018, P INF COMM TECHN SUS, P451
   Zweig G., 1989, Speech and Natural Language. Proceedings of a Workshop, P230
NR 35
TC 0
Z9 0
U1 0
U2 0
PU TAYLORS UNIV SDN BHD
PI SELANGOR
PA 1 JALAN SS15-8, SUBANG JAYA, SELANGOR, 47500, MALAYSIA
SN 1823-4690
J9 J ENG SCI TECHNOL
JI J. Eng. Sci. Technol.
PD APR
PY 2019
VL 14
IS 2
BP 726
EP 746
PG 21
WC Engineering, Multidisciplinary
SC Engineering
GA HR1RO
UT WOS:000462912200016
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Gasser, E
   Ahn, B
   Napoli, DJ
   Zhou, ZL
AF Gasser, Emily
   Ahn, Byron
   Napoli, Donna Jo
   Zhou, Z. L.
TI Production, perception, and communicative goals of American newscaster
   speech
SO LANGUAGE IN SOCIETY
LA English
DT Article
ID TALKER SEX; VOICE; INTONATION; PERSUASION; DOMAIN; STYLE; NEWS
AB Listeners often have the intuition that the speech of broadcast news reporters somehow 'sounds different'; previous literature supports this observation and has described some distinctive aspects of newscaster register. This article presents two studies further describing the characteristic properties and functions of American English newscaster speech, focusing specifically on prosody. In the first, we investigate the production of newscaster speech. We describe the measurable differences in pitch, speed, intensity, and melodic features between newscaster and conversational speech, and connect those traits to perceptions of authority, credibility, charisma, and related characteristics. In the second, we investigate the perception of newscaster speech. Our experiments demonstrate that listeners can distinguish newscaster from conversational speech given only prosodic information, and that they use a subset of the newscasters' distinguishing features to do so. (News, prosody, discourse registers, speech perception, credibility, authority)*
C1 [Gasser, Emily; Napoli, Donna Jo] Swarthmore Coll, 500 Coll Ave, Swarthmore, PA 19081 USA.
   [Ahn, Byron] Princeton Univ, Princeton, NJ 08544 USA.
   [Zhou, Z. L.] Univ Calif Los Angeles, Los Angeles, CA USA.
RP Gasser, E (corresponding author), Swarthmore Coll, 500 Coll Ave, Swarthmore, PA 19081 USA.
EM egasserl@swarthmore.edu
RI Napoli, Donna Jo/AAJ-2504-2020
OI Zhou, Z.L./0000-0001-7866-2168
CR Ahn Byron, 2018, PROSODIC FEATURES NE
   Arrabito GR, 2009, HUM FACTORS, V51, P3, DOI 10.1177/0018720808333411
   Bachorowski JA, 1999, J ACOUST SOC AM, V106, P1054, DOI 10.1121/1.427115
   Beckman M. E., 2005, PROSODIC TYPOLOGY PH, P9, DOI DOI 10.1093/ACPROF:OSO/9780199249633.003.0002
   BELL A, 1984, LANG SOC, V13, P145, DOI 10.1017/S004740450001037X
   Bell A, 1991, LANGUAGE NEWS MEDIA
   Biadsy F., 2008, P SPEECH PROS 2008, P579
   Boersma P., 2018, PRAAT DOING PHONETIC
   BOLINGER D, 1982, J BROADCASTING, V26, P725, DOI 10.1080/08838158209364042
   Bolinger Dwight, 1989, INTONATION ITS USES
   BROOKE ME, 1986, J LANG SOC PSYCHOL, V5, P201, DOI DOI 10.1177/0261927X8600500303
   Castro Luciana, 2010, P 3 ISCA TUT RES WOR, P17
   Chattopadhyay A, 2003, J CONSUM PSYCHOL, V13, P198, DOI 10.1207/S15327663JCP1303_02
   Chebat JC, 2007, PERCEPT MOTOR SKILL, V104, P419, DOI 10.2466/PMS.104.2.419-437
   Cohler DK, 1985, BROADCAST JOURNALISM
   Cotter  C., 1993, P 1993 ANN M BERK LI, P90, DOI DOI 10.3765/BLS.V19I1.1520
   Cotter C., 2010, NEWS TALK INVESTIGAT
   Cotter Colleen, 1989, SOME PRAGMATIC CONSI
   Cotter Colleen, 1999, WORKINGS LANGUAGE PR, P165
   Edworthy J, 2003, Noise Health, V6, P39
   Elbert SP, 2014, PSYCHOL HEALTH, V29, P1014, DOI 10.1080/08870446.2014.903482
   Escudero D, 2017, COMPUT SPEECH LANG, V45, P39, DOI 10.1016/j.csl.2017.02.011
   GelinasChebat C, 1996, PERCEPT MOTOR SKILL, V83, P243, DOI 10.2466/pms.1996.83.1.243
   Goldstein Harry, 1940, READING LISTENING CO
   Grable John E., 2011, J FINANCIAL PLANNING
   Gussenhoven Carlos, 2004, PHONOLOGY TONE INTON
   HELFRICH H, 1986, J NONVERBAL BEHAV, V10, P187, DOI 10.1007/BF00987615
   Iivonen Antti, 1995, ICPHS, V95, P382
   Johns-Lewis C., 1986, INTONATION DISCOURSE, P199
   Johnson Brian K., 2009, ARTICULATE ADVOCATE
   Jones BC, 2010, ANIM BEHAV, V79, P57, DOI 10.1016/j.anbehav.2009.10.003
   KRAUSS E, 2000, BROADCASTING POLITIC
   Medrado R, 2005, J VOICE, V19, P340, DOI 10.1016/j.jvoice.2004.04.008
   MILLER N, 1976, J PERS SOC PSYCHOL, V34, P615, DOI 10.1037//0022-3514.34.4.615
   OHALA JJ, 1984, PHONETICA, V41, P1, DOI 10.1159/000261706
   Ohala John J., 1994, SOUND SYMBOLISM, P325
   Ostendorf M., 1996, BOSTON U RADIO SPEEC
   PIERREHUMBERT J, 1990, SYS DEV FDN, P271
   PITTAM J, 1990, J SOC PSYCHOL, V130, P81, DOI 10.1080/00224545.1990.9922937
   Price J, 2008, AAA-ARB ANGLIST AM, V33, P285
   Raymond G., 2000, DISCOURSE STUDIES, V2, P354, DOI DOI 10.1177/1461445600002003005
   Rodero E., 2013, ESTUDIOS MENSAJE PER, V19, P519, DOI DOI 10.5209/REV_ESMP.2013.V19.N1.42536
   Rodero E., 2010, ICONO, V14, P281
   Rodero E, 2015, J NONVERBAL BEHAV, V39, P79, DOI 10.1007/s10919-014-0201-5
   Rodero Emma, 2006, P ISCA TUT RES WORKS, P209
   Rodero Emma, 2014, J APPL LINGUISTICS P, V11, P91
   Rosenberg A, 2009, SPEECH COMMUN, V51, P640, DOI 10.1016/j.specom.2008.11.001
   Rosenberg Andrew, 2005, P INT 2005, V2005, P513
   SCHAFER AJ, 1997, THESIS U MASSACHUSET
   Schuppert A., 2012, COPENHAGEN STUDIES L, V42, P73
   van der Vaart W, 2006, INT J PUBLIC OPIN R, V18, P488, DOI 10.1093/ijpor/edh117
   Van Leeuwen T., 1984, AUSTR J CULTURAL STU, V2, P84
   Vermillion Patricia, 2006, ASPECTS NZ ENGLISH I
   Vermillion Patricia, 2004, P 10 AUSTR INT C SPE, P415
   Wheatley K.E., 1949, AM SPEECH, V24, P213, DOI DOI 10.2307/487050
   Whipple TW, 2002, J ADVERTISING, V31, P79, DOI 10.1080/00913367.2002.10673668
   Wynn Earl R., 1974, RADIO BROADCASTING I
   ZUCKERMAN M, 1993, J NONVERBAL BEHAV, V17, P119, DOI 10.1007/BF01001960
NR 58
TC 1
Z9 1
U1 1
U2 7
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0047-4045
EI 1469-8013
J9 LANG SOC
JI Lang. Soc.
PD APR
PY 2019
VL 48
IS 2
BP 233
EP 259
DI 10.1017/S0047404518001392
PG 27
WC Linguistics; Sociology
SC Linguistics; Sociology
GA HQ3RQ
UT WOS:000462328600003
DA 2021-02-24
ER

PT J
AU Keller, M
   Neuschwander, P
   Meyer, M
AF Keller, Matthias
   Neuschwander, Pia
   Meyer, Martin
TI When right becomes less right: Neural dedifferentiation during
   suprasegmental speech processing in the aging brain
SO NEUROIMAGE
LA English
DT Article
DE Speech processing; Lateralization; Aging; Compensation;
   Dedifferentiation
ID ADULT LIFE-SPAN; CORTICAL THICKNESS; HEARING-LOSS; LANGUAGE
   LATERALIZATION; HEMISPHERIC-ASYMMETRY; LONGITUDINAL CHANGES;
   AUDITORY-PERCEPTION; CEREBRAL MECHANISMS; SURFACE-AREA; AGE
AB This study combines event-related sparse-temporal acquisition fMRI with structural MRI to investigate older participants (n = 26, mean age = 70.64) with age-typical peripheral hearing. While participants were presented with locally time-reversed sentences of varying temporal integrity, they performed an auditory pattern-matching task. The major aim of the study was to find out whether functional lateralization for speech perception according to the 'Asymmetric Sampling in Time' (AST) hypothesis shows a similar pattern in elderly individuals as has been previously observed in younger adults. Our findings indicate that, unlike results previously obtained from younger adults, older individuals did not demonstrate the same pattern of rightward lateralization in response to suprasegmental speech cues in the three auditory regions of interest (ROI), namely Heschl's gyrus (HG), planum temporale (PT) and posterior lateral superior temporal gyrus (pSTG). A frequentist statistical approach did not yield evidence for functional lateralization in the aging brain, and this was corroborated by Bayesian evidence which supported the absence of lateralization in older adults in response to the suprasegmental manipulation. However, a relationship between structural measurements and functional responses demonstrated that individuals with thicker right PT showed less variance in lateralization. Hence, this study extends the division of labour between the left and the right auditory cortex during the processing of continuous spoken language as proposed by the 'AST-hypothesis in younger adults to a lifespan context.
C1 [Keller, Matthias; Neuschwander, Pia; Meyer, Martin] Univ Zurich, Div Neuropsychol, Psychol Inst, Binzmuhlestr 14, CH-8050 Zurich, Switzerland.
   [Keller, Matthias; Neuschwander, Pia; Meyer, Martin] Univ Zurich, Univ Res Prior Program Dynam Hlth Aging, Zurich, Switzerland.
   [Meyer, Martin] Charite Univ Med Berlin, Tinnituszentrum, Berlin, Germany.
RP Meyer, M (corresponding author), Univ Zurich, Div Neuropsychol, Psychol Inst, Binzmuhlestr 14, CH-8050 Zurich, Switzerland.
EM matthias.keller@uzh.ch; martin.meyer@uzh.ch
RI ; Meyer, Martin/H-4307-2012
OI Neuschwander, Pia/0000-0003-0897-7265; Meyer, Martin/0000-0003-2057-5533
FU Swiss National Science Foundation (SNF)Swiss National Science Foundation
   (SNSF) [105314_152905]; Jacobs Foundation; URPP Dynamics of Healthy
   Aging
FX We thank Franziskus Liem for providing us with the stimulus material and
   relevant code for setting up the experimental paradigm, as well as for
   helpful comments. This study was funded by the Swiss National Science
   Foundation (SNF, Grant no. 105314_152905 to MM). The sponsor did approve
   of the general study design but did not play any role in the collection,
   analysis and interpretation of the data. During the work on his
   dissertation, Matthias Keller was a pre-doctoral fellow of LIFE
   (International Max Planck Research School on the Life Course;
   participating institutions: MPI for Human Development,
   Humboldt-Universitat zu Berlin, Freie Universitat Berlin, University of
   Michigan, University of Virginia, University of Zurich). Financial
   support by the Jacobs Foundation helped to conduct this research. We
   would also like to express our gratitude to the URPP Dynamics of Healthy
   Aging for supporting this work.
CR Agcaoglu O, 2015, NEUROIMAGE, V104, P310, DOI 10.1016/j.neuroimage.2014.09.001
   ANNETT M, 1970, BRIT J PSYCHOL, V61, P303, DOI 10.1111/j.2044-8295.1970.tb01248.x
   Arlinger S, 2003, INT J AUDIOL, V42, pS17
   Baltes PB, 1997, PSYCHOL AGING, V12, P12, DOI 10.1037/0882-7974.12.1.12
   Bellis TJ, 2000, J NEUROSCI, V20, P791, DOI 10.1523/JNEUROSCI.20-02-00791.2000
   Bermudez P, 2009, CEREB CORTEX, V19, P1583, DOI 10.1093/cercor/bhn196
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   BRANT LJ, 1990, J ACOUST SOC AM, V88, P813, DOI 10.1121/1.399731
   Cabeza R, 2002, PSYCHOL AGING, V17, P85, DOI 10.1037//0882-7974.17.1.85
   Destrieux C, 2010, NEUROIMAGE, V53, P1, DOI 10.1016/j.neuroimage.2010.06.010
   Dienes Z, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00781
   Engvig A, 2010, NEUROIMAGE, V52, P1667, DOI 10.1016/j.neuroimage.2010.05.041
   Fjell AM, 2010, REV NEUROSCIENCE, V21, P187, DOI 10.1515/revneuro.2010.21.3.187
   Fjell AM, 2009, J NEUROSCI, V29, P15223, DOI 10.1523/JNEUROSCI.3252-09.2009
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   Garrett DD, 2011, J NEUROSCI, V31, P4496, DOI 10.1523/JNEUROSCI.5641-10.2011
   Geiser E, 2008, J COGNITIVE NEUROSCI, V20, P541, DOI 10.1162/jocn.2008.20029
   Giroud N, 2018, BRAIN STRUCT FUNCT, V223, P145, DOI 10.1007/s00429-017-1477-0
   Giroud N, 2017, HEARING RES, V353, P162, DOI 10.1016/j.heares.2017.06.012
   Goossens T, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00133
   Greve DN, 2013, J COGNITIVE NEUROSCI, V25, P1477, DOI 10.1162/jocn_a_00405
   Hesling I, 2005, HUM BRAIN MAPP, V26, P157, DOI 10.1002/hbm.20147
   Hesling I, 2005, NEUROIMAGE, V24, P937, DOI 10.1016/j.neuroimage.2004.11.003
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Humes LE, 2012, J AM ACAD AUDIOL, V23, P635, DOI 10.3766/jaaa.23.8.5
   Hurschler MA, 2015, BRAIN LANG, V147, P41, DOI 10.1016/j.bandl.2015.05.004
   Hurschler MA, 2013, HUM BRAIN MAPP, V34, P3182, DOI 10.1002/hbm.22134
   Kruschke JK, 2011, PERSPECT PSYCHOL SCI, V6, P299, DOI 10.1177/1745691611406925
   Kuehnel V, 1999, Z AUDIOL, V38, P4
   Lee MD, 2005, PSYCHOL REV, V112, P662, DOI 10.1037/0033-295X.112.3.662
   Li SC, 2004, PSYCHOL SCI, V15, P155, DOI 10.1111/j.0956-7976.2004.01503003.x
   Li SC, 2001, TRENDS COGN SCI, V5, P479, DOI 10.1016/S1364-6613(00)01769-1
   Liem F, 2014, HUM BRAIN MAPP, V35, P1779, DOI 10.1002/hbm.22291
   Liem F, 2012, NEUROREPORT, V23, P1026, DOI 10.1097/WNR.0b013e32835abc5c
   Liem F, 2012, BRAIN TOPOGR, V25, P182, DOI 10.1007/s10548-011-0206-x
   Lin FR, 2014, NEUROIMAGE, V90, P84, DOI 10.1016/j.neuroimage.2013.12.059
   Meyer M, 2002, HUM BRAIN MAPP, V17, P73, DOI 10.1002/hbm.10042
   Morey R. D., 2015, BAYESFACTOR COMPUTAT
   Nenert R, 2017, BRAIN RES, V1674, P20, DOI 10.1016/j.brainres.2017.08.021
   Panizzon MS, 2009, CEREB CORTEX, V19, P2728, DOI 10.1093/cercor/bhp026
   Park J, 2010, J NEUROSCI, V30, P9253, DOI 10.1523/JNEUROSCI.0853-10.2010
   Peelle JE, 2016, TRENDS NEUROSCI, V39, P486, DOI 10.1016/j.tins.2016.05.001
   Plante E, 2002, NEUROIMAGE, V17, P401, DOI 10.1006/nimg.2002.1182
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Poeppel D, 2001, COGNITIVE SCI, V25, P679, DOI 10.1016/S0364-0213(01)00050-7
   Profant O, 2014, NEUROSCIENCE, V260, P87, DOI 10.1016/j.neuroscience.2013.12.010
   R Core Team, 2017, R LANG ENV STAT COMP
   RAKIC P, 1988, SCIENCE, V241, P170, DOI 10.1126/science.3291116
   RAKIC P, 1995, TRENDS NEUROSCI, V18, P383, DOI 10.1016/0166-2236(95)93934-P
   Rakic P, 2007, BRAIN RES REV, V55, P204, DOI 10.1016/j.brainresrev.2007.02.010
   Reuter-Lorenz PA, 2014, NEUROPSYCHOL REV, V24, P355, DOI 10.1007/s11065-014-9270-9
   Roth TN, 2011, EUR ARCH OTO-RHINO-L, V268, P1101, DOI 10.1007/s00405-011-1597-8
   Rouder JN, 2009, PSYCHON B REV, V16, P225, DOI 10.3758/PBR.16.2.225
   Saberi K, 1999, NATURE, V398, P760, DOI 10.1038/19652
   Salat DH, 2004, CEREB CORTEX, V14, P721, DOI 10.1093/cercor/bhh032
   Sammler D, 2015, CURR BIOL, V25, P3079, DOI 10.1016/j.cub.2015.10.009
   Schmidt CF, 2008, HUM BRAIN MAPP, V29, P46, DOI 10.1002/hbm.20372
   Shiell MM, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/7217630
   Singmann H., 2018, AFEX ANAL FACTORIAL AFEX ANAL FACTORIAL AFEX ANAL FACTORIAL
   Sowell ER, 2003, NAT NEUROSCI, V6, P309, DOI 10.1038/nn1008
   Specht K, 2014, HEARING RES, V307, P121, DOI 10.1016/j.heares.2013.09.011
   Storsve AB, 2014, J NEUROSCI, V34, P8488, DOI 10.1523/JNEUROSCI.0391-14.2014
   Szaflarski JP, 2006, HUM BRAIN MAPP, V27, P202, DOI 10.1002/hbm.20177
   Thambisetty M, 2010, NEUROIMAGE, V52, P1215, DOI 10.1016/j.neuroimage.2010.04.258
   VandenLangenberg GM, 1998, AM J EPIDEMIOL, V148, P204, DOI 10.1093/oxfordjournals.aje.a009625
   Vannson N, 2015, AUDIOL NEURO-OTOL, V20, P38, DOI 10.1159/000380746
   Voss MW, 2008, BRAIN RES, V1244, P121, DOI 10.1016/j.brainres.2008.09.051
   Wagener K, 1999, Z AUDIOL, V38, P44, DOI DOI 10.3109/00206099909073001
   Wagener KC, 1999, AUDIOL ACOUST, V38, P8695
   Walker KMM, 2008, J COGNITIVE NEUROSCI, V20, P135, DOI 10.1162/jocn.2008.20012
   Wiley TL, 2008, J AM ACAD AUDIOL, V19, P281, DOI 10.3766/jaaa.19.4.2
   Wingfield A, 2000, J SPEECH LANG HEAR R, V43, P915, DOI 10.1044/jslhr.4304.915
   Zaehle T, 2004, EUR J NEUROSCI, V20, P2447, DOI 10.1111/j.1460-9568.2004.03687.x
   Zaehle T, 2007, NEUROIMAGE, V37, P1195, DOI 10.1016/j.neuroimage.2007.04.073
   Zhang LJ, 2010, HUM BRAIN MAPP, V31, P1106, DOI 10.1002/hbm.20922
   Zuo XN, 2010, J NEUROSCI, V30, P15034, DOI 10.1523/JNEUROSCI.2612-10.2010
NR 78
TC 2
Z9 2
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD APR 1
PY 2019
VL 189
BP 886
EP 895
DI 10.1016/j.neuroimage.2019.01.050
PG 10
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA HO7YU
UT WOS:000461166900075
PM 30685328
DA 2021-02-24
ER

PT J
AU Hay, JF
   Cannistraci, RA
   Zhao, Q
AF Hay, Jessica F.
   Cannistraci, Ryan A.
   Zhao, Qian
TI Mapping non-native pitch contours to meaning: Perceptual and
   experiential factors
SO JOURNAL OF MEMORY AND LANGUAGE
LA English
DT Article
DE Word learning; Lexical tone; Label-object associations; Pitch contours;
   Infancy; Speech perception
ID LEXICAL TONE; WORD RECOGNITION; PHONETIC DETAIL; INFANTS; INTONATION;
   SPEECH; ACQUISITION; PATTERNS; SOUNDS; FLEXIBILITY
AB Infants show interesting patterns of flexibility and constraint early in word learning. Here, we explore perceptual and experiential factors that drive associative learning of labels that differ in pitch contour. Contrary to the salience hypothesis proposed in Experiment 1, English-learning 14-month-olds failed to map acoustically distinctive level and dipping labels to novel referents, even though they discriminated the labels when no potential referents were present. Conversely, infants readily mapped the less distinctive rising and dipping labels. In Experiment 2, we found that the degree of pitch variation in labels also does not account for learning. Instead, English-learning infants only learned if one of the labels had a rising pitch contour. We argue that experience with hearing and/or producing native language prosody may lead infants to initially over-interpret the role rising pitch plays in differentiating words. Together, our findings suggest that multiple factors contribute to whether specific acoustic forms will function as candidate object labels.
C1 [Hay, Jessica F.; Cannistraci, Ryan A.; Zhao, Qian] Univ Tennessee, Dept Psychol, Knoxville, TN 37996 USA.
RP Hay, JF (corresponding author), Univ Tennessee, 416D Austin Peay Bldg, Knoxville, TN 37996 USA.
EM jhay@utk.edu
FU NICHDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R01HD083312];
   EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN
   DEVELOPMENTUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R01HD083312,
   R01HD083312, R01HD083312] Funding Source: NIH RePORTER
FX This research was funded partially by a grant from NICHD to JFH
   (R01HD083312). We would like to thank the members of the Infant Language
   and Perceptual Learning Lab and the participating families. We would
   also like to thank Jill Lany and Katie Graf Estes, and two anonymous
   reviewers for helpful comments.
CR Boersma P., 2001, PRAAT SPEECH PROCESS
   Bolinger Dwight, 1989, INTONATION ITS USES
   Brent MR, 2001, COGNITION, V81, pB33, DOI 10.1016/S0010-0277(01)00122-6
   Chao Y. R., 1948, MANDARIN PRIMER INTE
   Cohen L.B, 2004, HABIT X NEW PROGRAM
   Curtin S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01007
   Curtin S, 2009, J CHILD LANG, V36, P1157, DOI 10.1017/S0305000909009428
   Curtin S, 2009, DEVELOPMENTAL SCI, V12, P725, DOI 10.1111/j.1467-7687.2009.00814.x
   DePaolis RA, 2013, INFANT BEHAV DEV, V36, P642, DOI 10.1016/j.infbeh.2013.06.007
   Estes KG, 2015, CHILD DEV, V86, P1371, DOI 10.1111/cdev.12392
   Estes KG, 2013, INFANCY, V18, P797, DOI 10.1111/infa.12006
   Fennell C. T., 2012, RES METHODS CHILD LA, P1
   Fennell CT, 2010, CHILD DEV, V81, P1376, DOI 10.1111/j.1467-8624.2010.01479.x
   FERNALD A, 1987, INFANT BEHAV DEV, V10, P279, DOI 10.1016/0163-6383(87)90017-8
   FERNALD A, 1989, CHILD DEV, V60, P1497, DOI 10.2307/1130938
   FERNALD A, 1991, DEV PSYCHOL, V27, P209, DOI 10.1037/0012-1649.27.2.209
   Fernald A, 1992, NONVERBAL VOCAL COMM, P262
   Frota S, 2014, INFANCY, V19, P194, DOI 10.1111/infa.12037
   Geffen S., 2014, INFANTS DISCRIMINATE
   Graf Estes K., 2018, J COGN DEV, P1
   HADDINGKOCH K, 1964, PHONETICA, V11, P175, DOI 10.1159/000258338
   HALLE PA, 1991, LANG SPEECH, V34, P299, DOI 10.1177/002383099103400401
   Hay J. F., 2017, 2017 BIENN M SOC RES
   Hay JF, 2015, CHILD DEV, V86, P10, DOI 10.1111/cdev.12269
   HIRSHPASEK K, 2000, BECOMING WORD LEARNE, P136, DOI DOI 10.1093/ACPROF:OSO/9780195130324.003.006
   Howie J.M., 1976, ACOUSTICAL STUDIES M
   Kaplan R. M., 1975, EXPLORATIONS COGNITI, P117
   KENT RD, 1982, J ACOUST SOC AM, V72, P353, DOI 10.1121/1.388089
   Kidd C, 2014, CHILD DEV, V85, P1795, DOI 10.1111/cdev.12263
   Kluender K. R, 2013, VOWEL INHERENT SPECT, P117
   LI CN, 1977, J CHILD LANG, V4, P185, DOI 10.1017/S0305000900001598
   Ma WY, 2011, LANG LEARN DEV, V7, P185, DOI 10.1080/15475441.2011.579839
   MacKenzie H, 2012, CHILD DEV, V83, P1129, DOI 10.1111/j.1467-8624.2012.01764.x
   MacKenzie H, 2011, DEVELOPMENTAL SCI, V14, P249, DOI 10.1111/j.1467-7687.2010.00975.x
   Majorano M, 2014, LANG LEARN DEV, V10, P179, DOI 10.1080/15475441.2013.829740
   Namy LL, 2001, INFANCY, V2, P73, DOI 10.1207/S15327078IN0201_5
   Pater J, 2004, LANGUAGE, V80, P384, DOI 10.1353/lan.2004.0141
   Robertson VS, 2017, EAR HEARING, V38, P701, DOI 10.1097/AUD.0000000000000455
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Singh L, 2017, J CHILD LANG, V44, P924, DOI 10.1017/S0305000916000325
   Singh L, 2014, DEVELOPMENTAL SCI, V17, P94, DOI 10.1111/desc.12097
   Singh L, 2012, COGNITION, V124, P128, DOI 10.1016/j.cognition.2012.05.008
   Snow D, 2006, CHILD DEV, V77, P281, DOI 10.1111/j.1467-8624.2006.00870.x
   So CK, 2010, LANG SPEECH, V53, P273, DOI 10.1177/0023830909357156
   Soderstrom M, 2011, INFANT BEHAV DEV, V34, P107, DOI 10.1016/j.infbeh.2010.10.003
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   SULLIVAN JW, 1983, J CHILD LANG, V10, P521, DOI 10.1017/S0305000900005341
   Thiessen ED, 2007, J MEM LANG, V56, P16, DOI 10.1016/j.jml.2006.07.002
   Tsao F.-M., 2008, CHINESE J PSYCHOL, V50, P111, DOI [10.6129/CJP.2008.5002.01, DOI 10.6129/CJP.2008.5002.01]
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   Werker JF, 1998, DEV PSYCHOL, V34, P1289, DOI 10.1037/0012-1649.34.6.1289
   Whalen D., 1991, J CHILD LANG, V67, P297
   Woodward AL, 1999, CHILD DEV, V70, P65, DOI 10.1111/1467-8624.00006
   Yoshida KA, 2009, DEVELOPMENTAL SCI, V12, P412, DOI 10.1111/j.1467-7687.2008.00789.x
NR 56
TC 1
Z9 1
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0749-596X
EI 1096-0821
J9 J MEM LANG
JI J. Mem. Lang.
PD APR
PY 2019
VL 105
BP 131
EP 140
DI 10.1016/j.jml.2018.12.004
PG 10
WC Linguistics; Psychology; Psychology, Experimental
SC Linguistics; Psychology
GA HM5NU
UT WOS:000459523200009
PM 31244505
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Barutchu, A
   Toohey, S
   Shivdasani, MN
   Fifer, JM
   Crewther, SG
   Grayden, DB
   Paolini, AG
AF Barutchu, Ayla
   Toohey, Sarah
   Shivdasani, Mohit N.
   Fifer, Joanne M.
   Crewther, Sheila G.
   Grayden, David B.
   Paolini, Antonio G.
TI Multisensory perception and attention in school-age children
SO JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY
LA English
DT Article
DE Attention; Multisensory processing; Vision; Audition; Illusion; Children
ID AUDIOVISUAL INTEGRATION; SPATIAL ATTENTION; HUMAN BRAIN; CHILDHOOD;
   CONTINUES; LINKS
AB Although it is well known that attention can modulate multisensory processes in adults and infants, this relationship has not been investigated in school-age children. Attention abilities of 53 children (ages 7-13 years) were assessed using three subscales of the Test of Everyday Attention for Children (TEA-Ch): visuospatial attention (Sky Search [SS]), auditory sustained attention (Score), and audiovisual dual task (SSDT, where the SS and Score tasks are performed simultaneously). Multisensory processes were assessed using the McGurk effect (a verbal illusion where speech perception is altered by vision) and the Stream-Bounce (SB) effect (a nonverbal illusion where visual perception is altered by sound). The likelihood of perceiving both multisensory illusions tended to increase with age. The McGurk effect was significantly more pronounced in children who scored high on the audiovisual dual attention index (SSDT). In contrast, the SB effect was more pronounced in children with higher sustained auditory attention abilities as assessed by the Score index. These relationships between attention and the multisensory illusory percepts could not be explained solely by age or children's intellectual abilities. This study suggests that the interplay between attention and multisensory processing depends on both the nature of the multisensory task and the type of attention needed to effectively merge information across the senses. Crown Copyright (C) 2018 Published by Elsevier Inc. All rights reserved.
C1 [Barutchu, Ayla] Univ Oxford, Balliol Coll, Oxford OX1 3BJ, England.
   [Toohey, Sarah; Fifer, Joanne M.; Crewther, Sheila G.; Paolini, Antonio G.] La Trobe Univ, Sch Psychol & Publ Hlth, Bundoora, Vic 3086, Australia.
   [Shivdasani, Mohit N.] Univ New South Wales, Grad Sch Biomed Engn, Sydney, NSW 2033, Australia.
   [Grayden, David B.] Univ Melbourne, Dept Biomed Engn, Parkville, Vic 3010, Australia.
   [Shivdasani, Mohit N.; Grayden, David B.] Bion Inst, East Melbourne, Vic 3002, Australia.
   [Paolini, Antonio G.] Inst Social Neurosci, ISN Psychol, Heidelberg, Vic 3084, Australia.
RP Barutchu, A (corresponding author), Univ Oxford, Balliol Coll, Oxford OX1 3BJ, England.
EM ayla.barutchu@balliol.ox.ac.uk
RI Grayden, David B/L-5782-2018; SHIVDASANI, MOHIT/AAN-3438-2020; Crewther,
   Sheila G/A-2165-2008
OI Grayden, David B/0000-0002-5497-7234; SHIVDASANI,
   MOHIT/0000-0002-0692-4971; Paolini, Antonio/0000-0002-0853-4598
FU Bionics Institute, East Melbourne, VIC, Australia; School of Psychology
   and Public Health, La Trobe University, VIC, Australia; Jack Brockhoff
   Foundation; Jack & Robert Smorgon Families Foundation
FX This study was supported by the Bionics Institute, East Melbourne, VIC
   3002, Australia, and the School of Psychology and Public Health, La
   Trobe University, VIC 3086, Australia. Funding was provided by Neville
   and Di Bertalli, John and Janet Calvert-Jones; The Jack Brockhoff
   Foundation and the Jack & Robert Smorgon Families Foundation.
CR Abundis-Gutierrez A, 2014, NEUROPSYCHOLOGIA, V57, P78, DOI 10.1016/j.neuropsychologia.2014.02.013
   Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Andersen TS, 2009, SPEECH COMMUN, V51, P184, DOI 10.1016/j.specom.2008.07.004
   Bahrick LE, 2000, DEV PSYCHOL, V36, P190, DOI 10.1037//0012-1649.36.2.190
   Barutchu A., CHILD DEV
   Barutchu A, 2010, J EXP CHILD PSYCHOL, V105, P38, DOI 10.1016/j.jecp.2009.08.005
   Barutchu A, 2011, DEV PSYCHOL, V47, P877, DOI 10.1037/a0021903
   Barutchu A, 2009, DEVELOPMENTAL SCI, V12, P464, DOI 10.1111/j.1467-7687.2008.00782.x
   Brandwein AB, 2011, CEREB CORTEX, V21, P1042, DOI 10.1093/cercor/bhq170
   Bremner A. J., 2012, MULTISENSORY DEV
   Broadbent HJ, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12554
   Buchan JN, 2011, PERCEPTION, V40, P1164, DOI 10.1068/p6939
   Calvert GA, 2001, CEREB CORTEX, V11, P1110, DOI 10.1093/cercor/11.12.1110
   Chen YC, 2016, J EXP CHILD PSYCHOL, V146, P17, DOI 10.1016/j.jecp.2016.01.010
   Cromer JA, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00704
   Downing HC, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01559
   Driver J, 1998, PHILOS T R SOC B, V353, P1319, DOI 10.1098/rstb.1998.0286
   Driver J, 2008, NEURON, V57, P11, DOI 10.1016/j.neuron.2007.12.013
   Fairhall SL, 2009, EUR J NEUROSCI, V29, P1247, DOI 10.1111/j.1460-9568.2009.06688.x
   FOREMAN N, 1989, PERCEPT MOTOR SKILL, V69, P43, DOI 10.2466/pms.1989.69.1.43
   Fujisaki W, 2004, NAT NEUROSCI, V7, P773, DOI 10.1038/nn1268
   Gogtay N, 2004, P NATL ACAD SCI USA, V101, P8174, DOI 10.1073/pnas.0402680101
   GOLDBERG ME, 1972, J NEUROPHYSIOL, V35, P560
   Gori M, 2008, CURR BIOL, V18, P694, DOI 10.1016/j.cub.2008.04.036
   Gravetter FJ., 2017, STAT BEHAV SCI, V10
   Grove PM, 2012, PERCEPTION, V41, P379, DOI 10.1068/p6808
   Hillock AR, 2011, NEUROPSYCHOLOGIA, V49, P461, DOI 10.1016/j.neuropsychologia.2010.11.041
   Hillock-Dunn A, 2012, DEVELOPMENTAL SCI, V15, P688, DOI 10.1111/j.1467-7687.2012.01171.x
   Hillyard SA, 2016, NEUROPSYCHOLOGIA, V83, P170, DOI 10.1016/j.neuropsychologia.2015.06.003
   Innes-Brown H, 2011, DEVELOPMENTAL SCI, V14, P1089, DOI 10.1111/j.1467-7687.2011.01059.x
   James W., 1890, PRINCIPLES PSYCHOL
   Lebel C, 2011, J NEUROSCI, V31, P10937, DOI 10.1523/JNEUROSCI.5302-10.2011
   Manly T, 2001, J CHILD PSYCHOL PSYC, V42, P1065, DOI 10.1111/1469-7610.00806
   Manly T., 1998, TEST EVERYDAY ATTENT
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MUIR D, 1979, CHILD DEV, V50, P431, DOI 10.2307/1129419
   Nagy Z, 2004, J COGNITIVE NEUROSCI, V16, P1227, DOI 10.1162/0898929041920441
   Nardini M, 2016, DEVELOPMENTAL SCI, V19, P803, DOI 10.1111/desc.12327
   Nardini M, 2010, P NATL ACAD SCI USA, V107, P17041, DOI 10.1073/pnas.1001699107
   Ross LA, 2011, EUR J NEUROSCI, V33, P2329, DOI 10.1111/j.1460-9568.2011.07685.x
   Scheier C, 2003, DEVELOPMENTAL SCI, V6, P233, DOI 10.1111/1467-7687.00276
   Sekuler R, 1997, NATURE, V385, P308, DOI 10.1038/385308a0
   Shimojo S, 2001, VISUAL ATTENTION AND CORTICAL CIRCUITS, P243
   Spence C, 1996, J EXP PSYCHOL HUMAN, V22, P1005, DOI 10.1037/0096-1523.22.4.1005
   Stein BE, 2008, NAT REV NEUROSCI, V9, P255, DOI 10.1038/nrn2331
   Tabachnick Barbara, 2007, USING MULTIVARIATE S, V5
   Talsma D, 2015, FRONT INTEGR NEUROSC, V9, DOI 10.3389/fnint.2015.00019
   Talsma D, 2010, TRENDS COGN SCI, V14, P400, DOI 10.1016/j.tics.2010.06.008
   Tremblay C, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000742
   van Eijk RLJ, 2008, PERCEPT PSYCHOPHYS, V70, P955, DOI 10.3758/PP.70.6.955
   Wallace MT, 2004, J NEUROSCI, V24, P9580, DOI 10.1523/JNEUROSCI.2535-04.2004
   Wallace MT, 2004, EXP BRAIN RES, V158, P252, DOI 10.1007/s00221-004-1899-9
   Wechsler D., 2003, WECHSLER INTELLIGENC
NR 53
TC 5
Z9 5
U1 1
U2 21
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0022-0965
EI 1096-0457
J9 J EXP CHILD PSYCHOL
JI J. Exp. Child Psychol.
PD APR
PY 2019
VL 180
BP 141
EP 155
DI 10.1016/j.jecp.2018.11.021
PG 15
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA HL1OQ
UT WOS:000458469200011
PM 30655099
DA 2021-02-24
ER

PT J
AU Chao, SC
   Ochoa, D
   Daliri, A
AF Chao, Sara-Ching
   Ochoa, Damaris
   Daliri, Ayoub
TI Production Variability and Categorical Perception of Vowels Are Strongly
   Linked
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE speech; perception; variability; speech motor control; vowels
ID AUDITORY-FEEDBACK; SPEECH-PERCEPTION; MOTOR SYSTEM; MODULATION;
   LANGUAGE; ADULTS; DISCRIMINATION; PERTURBATIONS; DISTINCTNESS;
   ACQUISITION
AB Theoretical models of speech production suggest that the speech motor system (SMS) uses auditory goals to determine errors in its auditory output during vowel production. This type of error calculation indicates that within-speaker production variability of a given vowel is related to the size of the vowel's auditory goal. However, emerging evidence suggests that the SMS may also take into account perceptual knowledge of vowel categories (in addition to auditory goals) to estimate errors in auditory feedback. In this study, we examined how this mechanism influences within-speaker variability in vowel production. We conducted a study (n = 40 adults), consisting of a vowel categorization task and a vowel production task. The vowel categorization task was designed-based on participant-specific vowels-to estimate the categorical perceptual boundary (CPB) between two front vowels (/epsilon/ and /ae/). Using the vowel production data of each participant, we calculated a variability-based boundary (VBB) located at the "center of mass" of the two vowels. The inverse of the standard deviation of a vowel distribution was used as the "mass" of the vowel. We found that: (a) categorical boundary was located farther from more variable vowels; and (b) the calculated VBB (i.e., the center of mass of the vowels) significantly and positively correlated with the estimated categorical boundary (r = 0.912 for formants calculated in hertz; r = 0.854 for formants calculated in bark). Overall, our findings support a view that vowel production and vowel perception are strongly and bidirectionally linked.
C1 [Chao, Sara-Ching; Ochoa, Damaris; Daliri, Ayoub] Arizona State Univ, Coll Hlth Solut, Speech & Hearing Sci, Tempe, AZ 85281 USA.
RP Daliri, A (corresponding author), Arizona State Univ, Coll Hlth Solut, Speech & Hearing Sci, Tempe, AZ 85281 USA.
EM ayoub.daliri@asu.edu
RI Daliri, Ayoub/AAM-5004-2020
OI Daliri, Ayoub/0000-0003-3793-2947
FU Arizona State University New Faculty Startup
FX This work was supported by Arizona State University New Faculty Startup
   Funding to AD.
CR Bourguignon NJ, 2016, J EXP PSYCHOL HUMAN, V42, P1039, DOI 10.1037/xhp0000209
   Bourguignon Nicolas J, 2014, Front Hum Neurosci, V8, P208, DOI 10.3389/fnhum.2014.00208
   Cai S., 2015, AUDAPTER
   Callan DE, 2000, J SPEECH LANG HEAR R, V43, P721, DOI 10.1044/jslhr.4303.721
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   Daliri A, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12521
   Daliri A, 2018, CORTEX, V99, P55, DOI 10.1016/j.cortex.2017.10.019
   Daliri A, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00234
   Daliri A, 2015, BRAIN LANG, V143, P59, DOI 10.1016/j.bandl.2015.03.002
   Daliri A, 2013, J SPEECH LANG HEAR R, V56, P1774, DOI 10.1044/1092-4388(2013/12-0134)
   Feng YQ, 2011, J NEUROPHYSIOL, V106, P667, DOI 10.1152/jn.00638.2010
   Franken MK, 2017, J ACOUST SOC AM, V142, P2007, DOI 10.1121/1.5006899
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Goldstone RL, 2010, WIRES COGN SCI, V1, P69, DOI 10.1002/wcs.26
   Grabski K, 2013, J NEUROLINGUIST, V26, P384, DOI 10.1016/j.jneuroling.2012.11.003
   Guenther FH., 2016, NEURAL CONTROL SPEEC
   Guenther FH, 2006, J COMMUN DISORD, V39, P350, DOI 10.1016/j.jcomdis.2006.06.013
   Guenther FH, 2012, J NEUROLINGUIST, V25, P408, DOI 10.1016/j.jneuroling.2009.08.006
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158
   Houde JF, 2015, CURR OPIN NEUROBIOL, V33, P174, DOI 10.1016/j.conb.2015.04.006
   Houde JF, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00082
   Kingdom F. A. A., 2016, PSYCHOPHYSICS PRACTI
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Lametti DR, 2014, PSYCHOL SCI, V25, P1325, DOI 10.1177/0956797614529978
   Lametti DR, 2014, J NEUROSCI, V34, P10339, DOI 10.1523/JNEUROSCI.0108-14.2014
   LILJENCRANTS J, 1972, LANGUAGE, V48, P839, DOI 10.2307/411991
   Merrikhi Y, 2018, EXP BRAIN RES, V236, P1963, DOI 10.1007/s00221-018-5278-3
   Mitsuya T, 2011, J ACOUST SOC AM, V130, P2978, DOI 10.1121/1.3643826
   Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009
   Newman RS, 2003, J ACOUST SOC AM, V113, P2850, DOI 10.1121/1.1567280
   Nieto-Castanon A, 2005, J ACOUST SOC AM, V117, P3196, DOI 10.1121/1.1893271
   Niziolek CA, 2013, J NEUROSCI, V33, P16110, DOI 10.1523/JNEUROSCI.2137-13.2013
   Niziolek CA, 2013, J NEUROSCI, V33, P12090, DOI 10.1523/JNEUROSCI.1008-13.2013
   Perkell J, 1997, SPEECH COMMUN, V22, P227, DOI 10.1016/S0167-6393(97)00026-5
   Perkell J. S., 2008, P 8 INT SEM SPEECH P, P29
   Perkell JS, 2012, J NEUROLINGUIST, V25, P382, DOI 10.1016/j.jneuroling.2010.02.011
   Perkell JS, 2004, J SPEECH LANG HEAR R, V47, P1259, DOI 10.1044/1092-4388(2004/095)
   Perkell JS, 2004, J ACOUST SOC AM, V116, P2338, DOI 10.1121/1.1787524
   Prins N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01250
   Reilly KJ, 2017, J NEUROPHYSIOL, V118, P2925, DOI 10.1152/jn.00702.2016
   Schuerman WL, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00161
   Schwartz JL, 2005, SPEECH COMMUN, V45, P425, DOI 10.1016/j.specom.2004.12.001
   Schwartz JL, 1997, J PHONETICS, V25, P255, DOI 10.1006/jpho.1997.0043
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Stevens KN, 2010, J PHONETICS, V38, P10, DOI 10.1016/j.wocn.2008.10.004
   STEVENS KN, 1989, J PHONETICS, V17, P3, DOI 10.1016/S0095-4470(19)31520-7
   Tatham M, 2006, SPEECH PRODUCTION AND PERCEPTION, P1, DOI 10.1057/9780230513969
   Tourville JA, 2008, NEUROIMAGE, V39, P1429, DOI 10.1016/j.neuroimage.2007.09.054
   TRAUNMULLER H, 1990, J ACOUST SOC AM, V88, P97, DOI 10.1121/1.399849
   Villacorta VM, 2007, J ACOUST SOC AM, V122, P2306, DOI 10.1121/1.2773966
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
NR 54
TC 3
Z9 3
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD MAR 22
PY 2019
VL 13
AR 96
DI 10.3389/fnhum.2019.00096
PG 9
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA HQ7ZX
UT WOS:000462644100001
PM 30967768
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Modelska, M
   Pourquie, M
   Baart, M
AF Modelska, Maria
   Pourquie, Marie
   Baart, Martijn
TI No "Self" Advantage for Audiovisual Speech Aftereffects
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE speech perception; self-advantage; recalibration; adaptation;
   lip-reading
ID SELECTIVE ADAPTATION; VISUAL SPEECH; ELECTROPHYSIOLOGICAL EVIDENCE;
   PHONETIC RECALIBRATION; AUDITORY SPEECH; HEARING-LIPS; PERCEPTION;
   IDENTIFICATION; INFORMATION; LISTENERS
AB Although the default state of the world is that we see and hear other people talking, there is evidence that seeing and hearing ourselves rather than someone else may lead to visual (i.e., lip-read) or auditory "self" advantages. We assessed whether there is a "self" advantage for phonetic recalibration (a lip-read driven cross-modal learning effect) and selective adaptation (a contrastive effect in the opposite direction of recalibration). We observed both aftereffects as well as an on-line effect of lip-read information on auditory perception (i.e., immediate capture), but there was no evidence for a "self" advantage in any of the tasks (as additionally supported by Bayesian statistics). These findings strengthen the emerging notion that recalibration reflects a general learning mechanism, and bolster the argument that adaptation depends on rather low-level auditory/acoustic features of the speech signal.
C1 [Modelska, Maria; Pourquie, Marie; Baart, Martijn] BCBL Basque Ctr Cognit Brain & Language, Donostia San Sebastian, Spain.
   [Pourquie, Marie] UPPA, IKER UMR5478, Bayonne, France.
   [Baart, Martijn] Tilburg Univ, Dept Cognit Neuropsychol, Tilburg, Netherlands.
RP Baart, M (corresponding author), BCBL Basque Ctr Cognit Brain & Language, Donostia San Sebastian, Spain.; Baart, M (corresponding author), Tilburg Univ, Dept Cognit Neuropsychol, Tilburg, Netherlands.
EM m.baart@tilburguniversity.edu
RI Baart, Martijn/L-2910-2013
OI Baart, Martijn/0000-0002-5015-4265
FU Severo Ochoa program [SEV-2015-049]; Spanish Ministry of Economy and
   Competitiveness (MINECO) [PSI2014-51874-P]; Netherlands Organization for
   Scientific Research (NWO, VENI grant)Netherlands Organization for
   Scientific Research (NWO) [275-89-027]
FX This work was supported by the Severo Ochoa program grant SEV-2015-049
   awarded to the BCBL. MB and MP were supported by the Spanish Ministry of
   Economy and Competitiveness (MINECO, grant PSI2014-51874-P), and MB was
   also supported by the Netherlands Organization for Scientific Research
   (NWO, VENI grant 275-89-027).
CR Alsius A, 2018, MULTISENS RES, V31, P111, DOI 10.1163/22134808-00002565
   Aruffo C, 2012, PSYCHON B REV, V19, P66, DOI 10.3758/s13423-011-0176-8
   Baart M, 2018, EXP BRAIN RES, V236, P1911, DOI 10.1007/s00221-018-5270-y
   Baart M, 2017, EUR J NEUROSCI, V46, P2578, DOI 10.1111/ejn.13734
   Baart M, 2016, PSYCHOPHYSIOLOGY, V53, P1295, DOI 10.1111/psyp.12683
   Baart M, 2012, ACTA PSYCHOL, V140, P91, DOI 10.1016/j.actpsy.2012.03.003
   Baart M, 2010, EXP BRAIN RES, V203, P575, DOI 10.1007/s00221-010-2264-9
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   COOPER WE, 1974, PERCEPT PSYCHOPHYS, V16, P229, DOI 10.3758/BF03203934
   COOPER WE, 1974, NATURE, V252, P121, DOI 10.1038/252121a0
   COOPER WE, 1975, J ACOUST SOC AM, V58, P256, DOI 10.1121/1.380655
   DIEHL RL, 1980, J EXP PSYCHOL HUMAN, V6, P24, DOI 10.1037/0096-1523.6.1.24
   DIEHL RL, 1978, J EXP PSYCHOL HUMAN, V4, P599, DOI 10.1037/0096-1523.4.4.599
   DIEHL RL, 1975, PERCEPT PSYCHOPHYS, V17, P48, DOI 10.3758/BF03203996
   EIMAS PD, 1973, COGNITIVE PSYCHOL, V4, P99, DOI 10.1016/0010-0285(73)90006-6
   Fujisaki W, 2004, NAT NEUROSCI, V7, P773, DOI 10.1038/nn1268
   GREEN KP, 1991, PERCEPT PSYCHOPHYS, V50, P524, DOI 10.3758/BF03207536
   JASP Team, 2018, JASP VERS 0 9
   Kraljic T, 2008, PSYCHOL SCI, V19, P332, DOI 10.1111/j.1467-9280.2008.02090.x
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Peirce JW, 2009, FRONT NEUROINFORM, V2, DOI 10.3389/neuro.11.010.2008
   Prinz W, 1997, EUR J COGN PSYCHOL, V9, P129, DOI 10.1080/713752551
   RADEAU M, 1974, Q J EXP PSYCHOL, V26, P63, DOI 10.1080/14640747408400388
   Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063
   ROBERTS M, 1981, PERCEPT PSYCHOPHYS, V30, P309, DOI 10.3758/BF03206144
   SAMUEL AG, 1986, COGNITIVE PSYCHOL, V18, P452, DOI 10.1016/0010-0285(86)90007-1
   Samuel AG, 1998, PERCEPT PSYCHOPHYS, V60, P503, DOI 10.3758/BF03206870
   Schwartz J.-L, 2001, P INT C AUD SPEECH P, P18
   Schwartz JL, 2010, J ACOUST SOC AM, V127, P1584, DOI 10.1121/1.3293001
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Shimizu K., 1977, STUDIO PHONOLOGICA, V11, P25
   Stekelenburg JJ, 2007, J COGNITIVE NEUROSCI, V19, P1964, DOI 10.1162/jocn.2007.19.12.1964
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Tiippana K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00725
   Treille A, 2017, EXP BRAIN RES, V235, P2867, DOI 10.1007/s00221-017-5018-0
   Tye-Murray N, 2015, PSYCHON B REV, V22, P1048, DOI 10.3758/s13423-014-0774-3
   Tye-Murray N, 2013, PSYCHON B REV, V20, P115, DOI 10.3758/s13423-012-0328-5
   van Linden S, 2007, J EXP PSYCHOL HUMAN, V33, P1483, DOI 10.1037/0096-1523.33.6.1483
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   van Wassenhove V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00388
   Vroomen J, 2004, SPEECH COMMUN, V44, P55, DOI 10.1016/j.specom.2004.03.009
   Vroomen J., 2012, NEURAL BASEMULTISE, P363, DOI DOI 10.1201/9781439812174-24
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
   Vroomen J, 2009, COGNITION, V110, P254, DOI 10.1016/j.cognition.2008.10.015
   Wagenmakers EJ, 2007, PSYCHON B REV, V14, P779, DOI 10.3758/BF03194105
NR 49
TC 0
Z9 0
U1 1
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD MAR 22
PY 2019
VL 10
AR 658
DI 10.3389/fpsyg.2019.00658
PG 10
WC Psychology, Multidisciplinary
SC Psychology
GA HQ1BA
UT WOS:000462130400001
PM 30967827
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Lalonde, K
   Werner, LA
AF Lalonde, Kaylah
   Werner, Lynne A.
TI Perception of incongruent audiovisual English consonants
SO PLOS ONE
LA English
DT Article
ID AUDITORY-VISUAL INTEGRATION; SPEECH-PERCEPTION; NORMAL-HEARING;
   RECOGNITION; CONFUSIONS; EFFICIENCY; MCGURK
AB Causal inference-the process of deciding whether two incoming signals come from the same source-is an important step in audiovisual (AV) speech perception. This research explored causal inference and perception of incongruent AV English consonants. Nine adults were presented auditory, visual, congruent AV, and incongruent AV consonant-vowel syllables. Incongruent AV stimuli included auditory and visual syllables with matched vowels, but mismatched consonants. Open-set responses were collected. For most incongruent syllables, participants were aware of the mismatch between auditory and visual signals (59.04%) or reported the auditory syllable (33.73%). Otherwise, participants reported the visual syllable (1.13%) or some other syllable (6.11%). Statistical analyses were used to assess whether visual distinctiveness and place, voice, and manner features predicted responses. Mismatch responses occurred more when the auditory and visual consonants were visually distinct, when place and manner differed across auditory and visual consonants, and for consonants with high visual accuracy. Auditory responses occurred more when the auditory and visual consonants were visually similar, when place and manner were the same across auditory and visual stimuli, and with consonants produced further back in the mouth. Visual responses occurred more when voicing and manner were the same across auditory and visual stimuli, and for front and middle consonants. Other responses were variable, but typically matched the visual place, auditory voice, and auditory manner of the input. Overall, results indicate that causal inference and incongruent AV consonant perception depend on salience and reliability of auditory and visual inputs and degree of redundancy between auditory and visual inputs. A parameter-free computational model of incongruent AV speech perception based on unimodal confusions, with a causal inference rule, was applied. Data from the current study present an opportunity to test and improve the generalizability of current AV speech integration models.
C1 [Lalonde, Kaylah; Werner, Lynne A.] Univ Washington, Dept Speech & Hearing Sci, Seattle, WA 98195 USA.
   [Lalonde, Kaylah] Boys Town Natl Res Hosp, Ctr Hearing Res, Omaha, NE 68131 USA.
RP Lalonde, K (corresponding author), Univ Washington, Dept Speech & Hearing Sci, Seattle, WA 98195 USA.; Lalonde, K (corresponding author), Boys Town Natl Res Hosp, Ctr Hearing Res, Omaha, NE 68131 USA.
EM kaylah.lalonde@boystown.org
FU National Institute on Deafness and Communication DisordersUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01 DC 000396, P30 DC004661, T32 DC 005361]; NATIONAL INSTITUTE
   ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [T32DC005361, T32DC005361, T32DC005361, T32DC005361] Funding Source: NIH
   RePORTER
FX This research was funded by the National Institute on Deafness and
   Communication Disorders, R01 DC 000396, P30 DC004661, T32 DC 005361. The
   funders had no role in the study design, data collection and analysis,
   decision to publish, or preparation of the manuscript.
CR Bejjanki VR, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019812
   BERTELSON P, 1981, PERCEPT PSYCHOPHYS, V29, P578, DOI 10.3758/BF03207374
   Bertelson P., 1994, ICSLP 94. 1994 International Conference on Spoken Language Processing, P559
   BINNIE CA, 1976, J SPEECH HEAR DISORD, V41, P530, DOI 10.1044/jshd.4104.530
   BRAIDA LD, 1991, Q J EXP PSYCHOL-A, V43, P647, DOI 10.1080/14640749108400991
   Colin C, 2001, PSYCHOL BELG, V41, P131
   ERBER NP, 1972, J SPEECH HEAR RES, V15, P413, DOI 10.1044/jshr.1502.413
   ERBER NP, 1975, J SPEECH HEAR DISORD, V40, P481, DOI 10.1044/jshd.4004.481
   FISHER CG, 1968, J SPEECH HEAR RES, V11, P796, DOI 10.1044/jshr.1104.796
   Grant KW, 2007, J ACOUST SOC AM, V121, P1164, DOI 10.1121/1.2405859
   Grant KW, 1998, J ACOUST SOC AM, V104, P2438, DOI 10.1121/1.423751
   Grant KW, 1998, J ACOUST SOC AM, V103, P2677, DOI 10.1121/1.422788
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Jiang JT, 2011, J EXP PSYCHOL HUMAN, V37, P1193, DOI 10.1037/a0023100
   Kording KP, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000943
   Ma WJ, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004638
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   Magnotti JF, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005229
   Massaro D. W., 1987, SPEECH PERCEPTION EA
   Massaro DW, 1999, J SPEECH LANG HEAR R, V42, P21, DOI 10.1044/jslhr.4201.21
   Massaro DW, 2000, J ACOUST SOC AM, V108, P784, DOI 10.1121/1.429611
   MCGRATH M, 1985, J ACOUST SOC AM, V77, P678, DOI 10.1121/1.392336
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Munhall K.G., 2004, HDB MULTISENSORY PRO, P177
   Munhall KG, 1996, PERCEPT PSYCHOPHYS, V58, P351, DOI 10.3758/BF03206811
   OWENS E, 1985, J SPEECH HEAR RES, V28, P381, DOI 10.1044/jshr.2803.381
   PANDEY P C, 1986, Journal of Auditory Research, V26, P27
   Sankaran N, 2018, J ACOUST SOC AM, V144, P2462, DOI 10.1121/1.5065492
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   ten Oever S, 2013, FRONT NEUROSCI, V4, P1
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   Vroomen J., 2004, HDB MULTISENSORY PRO, P141
   WALDEN BE, 1981, J SPEECH HEAR RES, V24, P32, DOI 10.1044/jshr.2401.32
   WALDEN BE, 1977, J SPEECH HEAR RES, V20, P130, DOI 10.1044/jshr.2001.130
   Walden BE, 1975, J SPEECH HEAR RES, V18
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
NR 38
TC 3
Z9 3
U1 0
U2 0
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD MAR 21
PY 2019
VL 14
IS 3
AR e0213588
DI 10.1371/journal.pone.0213588
PG 32
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA HP7SO
UT WOS:000461889700029
PM 30897109
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Schaadt, G
   van der Meer, E
   Pannekamp, A
   Oberecker, R
   Mannel, C
AF Schaadt, Gesa
   van der Meer, Elke
   Pannekamp, Ann
   Oberecker, Regine
   Maennel, Claudia
TI Children with dyslexia show a reduced processing benefit from bimodal
   speech information compared to their typically developing peers
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Visual-auditory speech perception; Visual-auditory Mismatch Response;
   Spelling abilities; School children; German language
ID MISMATCH NEGATIVITY; DEVELOPMENTAL DYSLEXIA; AUDIOVISUAL SPEECH;
   AUDITORY-DISCRIMINATION; PERCEPTION; LANGUAGE; INTEGRATION; RESPONSES;
   SOUNDS; MMN
AB During information processing, individuals benefit from bimodally presented input, as has been demonstrated for speech perception (i.e., printed letters and speech sounds) or the perception of emotional expressions (i.e., facial expression and voice tuning). While typically developing individuals show this bimodal benefit, school children with dyslexia do not. Currently, it is unknown whether the bimodal processing deficit in dyslexia also occurs for visual-auditory speech processing that is independent of reading and spelling acquisition (i.e., no letter-sound knowledge is required). Here, we tested school children with and without spelling problems on their bimodal perception of video-recorded mouth movements pronouncing syllables. We analyzed the event-related potential Mismatch Response (MMR) to visual-auditory speech information and compared this response to the MMR to monomodal speech information (i.e., auditory-only, visual-only). We found a reduced MMR with later onset to visual-auditory speech information in children with spelling problems compared to children without spelling problems. Moreover, when comparing bimodal and monomodal speech perception, we found that children without spelling problems showed significantly larger responses in the visual-auditory experiment compared to the visual-only response, whereas children with spelling problems did not. Our results suggest that children with dyslexia exhibit general difficulties in bimodal speech perception independently of letter-speech sound knowledge, as apparent in altered bimodal speech perception and lacking benefit from bimodal information. This general deficit in children with dyslexia may underlie the previously reported reduced bimodal benefit for letter-speech sound combinations and similar findings in emotion perception.
C1 [Schaadt, Gesa; Oberecker, Regine; Maennel, Claudia] Max Planck Inst Human Cognit & Brain Sci, Dept Neuropsychol, Stephanstr 1a, D-04103 Leipzig, Germany.
   [Schaadt, Gesa; Maennel, Claudia] Max Planck Inst Human Cognit & Brain Sci, Dept Neurol, Stephanstr 1a, D-04103 Leipzig, Germany.
   [Schaadt, Gesa; Maennel, Claudia] Univ Leipzig, Clin Cognit Neurol, Med Fac, Liebigstr 16, D-04103 Leipzig, Germany.
   [Schaadt, Gesa; van der Meer, Elke; Pannekamp, Ann] Humboldt Univ, Dept Psychol, Rudower Chaussee 18, D-12489 Berlin, Germany.
   [van der Meer, Elke] Grad Sch Mind & Brain Berlin, Luisenstr 56, D-10117 Berlin, Germany.
RP Schaadt, G (corresponding author), Univ Leipzig, Clin Cognit Neurol, Med Fac, Liebigstr 16, D-04103 Leipzig, Germany.
EM schaadt@cbs.mpg.de
OI Mannel, Claudia/0000-0003-0678-4697
FU Max Planck SocietyMax Planck SocietyFoundation CELLEX;
   Humboldt-Universitat zu Berlin; Studienstiftung des Deutschen Volkes
   (German National Academic Foundation)
FX We wish to thank all participating families for supporting our research,
   and Christina Riigen for her empathy in looking after our participants
   as well as her commitment in recording the EEG data. We would also like
   to thank Shameem Wagner for proofreading the manuscript. This research
   was supported by the Max Planck Society (GS, CM), the
   Humboldt-Universitat zu Berlin (GS, EvdM), and the Studienstiftung des
   Deutschen Volkes (German National Academic Foundation; GS).
CR Ahmmed AU, 2008, DEV MED CHILD NEUROL, V50, P938, DOI 10.1111/j.1469-8749.2008.03093.x
   Alonso-Bua B, 2006, INT J PSYCHOPHYSIOL, V59, P159, DOI 10.1016/j.ijpsycho.2005.03.020
   Arnold P, 2001, BRIT J PSYCHOL, V92, P339, DOI 10.1348/000712601162220
   Beck L, 2012, EMOTION, V12, P503, DOI 10.1037/a0026320
   Bernstein LE, 2004, SPEECH COMMUN, V44, P5, DOI 10.1016/j.specom.2004.10.011
   Bishop DVM, 2007, PSYCHOL BULL, V133, P651, DOI 10.1037/0033-2909.133.4.651
   Blau V, 2010, BRAIN, V133, P868, DOI 10.1093/brain/awp308
   Blau V, 2009, CURR BIOL, V19, P503, DOI 10.1016/j.cub.2009.01.065
   Boetsch EA, 1996, DEV PSYCHOPATHOL, V8, P539, DOI 10.1017/S0954579400007264
   BRANDT J, 1980, BRAIN LANG, V9, P324, DOI 10.1016/0093-934X(80)90152-2
   Brem S, 2010, P NATL ACAD SCI USA, V107, P7939, DOI 10.1073/pnas.0904402107
   Burnham D, 2004, DEV PSYCHOBIOL, V45, P204, DOI 10.1002/dev.20032
   Cantiani C, 2013, NEUROPSYCHOLOGIA, V51, P1595, DOI 10.1016/j.neuropsychologia.2013.04.009
   Cheour M, 2002, NEUROSCI LETT, V325, P187, DOI 10.1016/S0304-3940(02)00269-0
   Clery H, 2012, NEUROPSYCHOLOGIA, V50, P979, DOI 10.1016/j.neuropsychologia.2012.01.035
   Cohen NJ, 1998, J CHILD PSYCHOL PSYC, V39, P853, DOI 10.1017/S0021963098002789
   Collignon O, 2008, BRAIN RES, V1242, P126, DOI 10.1016/j.brainres.2008.04.023
   Coltheart M, 2001, PSYCHOL REV, V108, P204, DOI 10.1037//0033-295X.108.1.204
   Creusere M, 2004, J COMMUN DISORD, V37, P5, DOI 10.1016/S0021-9924(03)00036-4
   Csepe V, 2003, NEUROPS COG, V23, P81
   Czigler I, 2006, NEUROSCI LETT, V401, P178, DOI 10.1016/j.neulet.2006.03.018
   de Gelder B, 2000, COGNITION EMOTION, V14, P289, DOI 10.1080/026999300378824
   de Gelder B, 1998, BRAIN LANG, V64, P269, DOI 10.1006/brln.1998.1973
   Dehaene S, 2010, SCIENCE, V330, P1359, DOI 10.1126/science.1194140
   Desjardins RN, 1997, J EXP CHILD PSYCHOL, V66, P85, DOI 10.1006/jecp.1997.2379
   Ford JA, 2003, J SPEECH LANG HEAR R, V46, P21, DOI 10.1044/1092-4388(2003/002)
   Friederici AD, 2002, NEUROREPORT, V13, P1251, DOI 10.1097/00001756-200207190-00006
   Friedrich M, 2004, PSYCHOPHYSIOLOGY, V41, P772, DOI 10.1111/j.1469-8986.2004.00202.x
   Froyen D, 2008, NEUROSCI LETT, V430, P23, DOI 10.1016/j.neulet.2007.10.014
   Froyen D, 2011, DEVELOPMENTAL SCI, V14, P635, DOI 10.1111/j.1467-7687.2010.01007.x
   Froyen DJW, 2009, J COGNITIVE NEUROSCI, V21, P567, DOI 10.1162/jocn.2009.21061
   Grossmann T, 2006, DEVELOPMENTAL SCI, V9, P309, DOI 10.1111/j.1467-7687.2006.00494.x
   He C, 2007, J COGNITIVE NEUROSCI, V19, P878, DOI 10.1162/jocn.2007.19.5.878
   Heiervang E, 2001, NORD J PSYCHIAT, V55, P251
   Iverson P, 2000, PERCEPT PSYCHOPHYS, V62, P874, DOI 10.3758/BF03206929
   Jansen H., 2002, BIELEFELD SCREENING
   Jiang JT, 2007, PERCEPT PSYCHOPHYS, V69, P1070, DOI 10.3758/BF03193945
   Kaufman AS, 2009, KAUFMAN ASSESSMENT B
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Kujala T, 2001, P NATL ACAD SCI USA, V98, P10509, DOI 10.1073/pnas.181589198
   Lachmann T, 2005, INT J PSYCHOPHYSIOL, V56, P105, DOI 10.1016/j.ijpsycho.2004.11.005
   Landerl K, 1997, COGNITION, V63, P315, DOI 10.1016/S0010-0277(97)00005-X
   Landerl K, 2008, J EDUC PSYCHOL, V100, P150, DOI 10.1037/0022-0663.100.1.150
   Lee CY, 2012, NEUROPSYCHOLOGIA, V50, P3228, DOI 10.1016/j.neuropsychologia.2012.08.025
   Leppanen PHT, 2004, EXP NEUROL, V190, pS91, DOI 10.1016/j.expneurol.2004.06.002
   Lovio R, 2012, BRAIN RES, V1448, P42, DOI 10.1016/j.brainres.2012.01.071
   Maekawa T, 2005, CLIN NEUROPHYSIOL, V116, P2392, DOI 10.1016/j.clinph.2005.07.006
   Mannel C, 2017, DEV COGN NEUROS-NETH, V23, P14, DOI 10.1016/j.dcn.2016.11.007
   Mannel C, 2015, CORTEX, V71, P291, DOI 10.1016/j.cortex.2015.06.029
   MASSARO DW, 1983, J EXP PSYCHOL HUMAN, V9, P753, DOI 10.1037/0096-1523.9.5.753
   Mittag M, 2013, CLIN NEUROPHYSIOL, V124, P315, DOI 10.1016/j.clinph.2012.08.003
   Mittag M, 2011, EXP BRAIN RES, V211, P287, DOI 10.1007/s00221-011-2686-z
   Mohammed T, 2006, CLIN LINGUIST PHONET, V20, P621, DOI 10.1080/02699200500266745
   Mueller JL, 2012, P NATL ACAD SCI USA, V109, P15953, DOI 10.1073/pnas.1204319109
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9
   NAATANEN R, 1993, PSYCHOPHYSIOLOGY, V30, P436, DOI 10.1111/j.1469-8986.1993.tb02067.x
   Neil P. A., 2006, DEVELOPMENTAL SCI, V9, DOI [10.1111/j.1467-7687.2006.005I2.x, DOI 10.1111/J.1467-7687.2006.005]
   Neuhoff N, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034909
   Nowicki EA, 2003, LEARN DISABILITY Q, V26, P171, DOI 10.2307/1593650
   Paul I, 2006, EUR J NEUROSCI, V24, P2945, DOI 10.1111/j.1460-9568.2006.05153.x
   Pelphrey KA, 2008, ANN NY ACAD SCI, V1145, P283, DOI 10.1196/annals.1416.007
   Pons F, 2003, SCAND J PSYCHOL, V44, P347, DOI 10.1111/1467-9450.00354
   Pons F, 2014, ACTA PSYCHOL, V149, P142, DOI 10.1016/j.actpsy.2013.12.013
   Pons F, 2013, J CHILD LANG, V40, P687, DOI 10.1017/S0305000912000189
   Ponton CW, 2009, BRAIN TOPOGR, V21, P207, DOI 10.1007/s10548-009-0094-5
   Raschle NM, 2012, P NATL ACAD SCI USA, V109, P2156, DOI 10.1073/pnas.1107721109
   Richardson U, 2004, DYSLEXIA, V10, P215, DOI 10.1002/dys.276
   Russeler J, 2015, NEUROSCIENCE, V287, P55, DOI 10.1016/j.neuroscience.2014.12.023
   SAMS M, 1993, J COGNITIVE NEUROSCI, V5, P363, DOI 10.1162/jocn.1993.5.3.363
   Schaadt G, 2016, DEVELOPMENTAL SCI, V19, P1020, DOI 10.1111/desc.12346
   Schaadt G, 2015, RES DEV DISABIL, V47, P318, DOI 10.1016/j.ridd.2015.10.002
   Schulte-Korne G., 2001, LESE RECHTSCHRELBSTO, V14
   Sekiyama K, 2003, NEUROSCI RES, V47, P277, DOI 10.1016/S0168-0102(03)00214-1
   Shestakova A, 2002, NEUROREPORT, V13, P1813, DOI 10.1097/00001756-200210070-00025
   Snowling MJ, 2007, J CHILD PSYCHOL PSYC, V48, P609, DOI 10.1111/j.1469-7610.2006.01725.x
   Soto-Faraco S, 2012, MULTISENSORY DEV, P207, DOI DOI 10.1093/ACPROF:OSO/9780199586059.003.0009
   SPAFFORD CS, 1993, J LEARN DISABIL, V26, P178, DOI 10.1177/002221949302600305
   SQUIRES NK, 1975, ELECTROEN CLIN NEURO, V38, P387, DOI 10.1016/0013-4694(75)90263-1
   Stock C., 2003, BASISKOMPETENZEN LES
   Stock C., 2008, DTSCH RECHTSCHREIBTE
   Teinonen T, 2008, COGNITION, V108, P850, DOI 10.1016/j.cognition.2008.05.009
   Trainor L, 2003, INT J PSYCHOPHYSIOL, V51, P5, DOI 10.1016/S0167-8760(03)00148-X
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   Wetzel N, 2004, NEUROREPORT, V15, P1355, DOI 10.1097/01.wnr.0000129858.40478.be
   Widmann Andreas, 2012, Front Psychol, V3, P60, DOI 10.3389/fpsyg.2012.00060
   Wimmer H, 1996, READ WRIT, V8, P171, DOI 10.1007/BF00555368
   Winkler I, 1999, PSYCHOPHYSIOLOGY, V36, P638, DOI 10.1017/S0048577299981908
   General Assembly of the World Medical Association, 2014, J Am Coll Dent, V81, P14, DOI 10.1001/jama.2013.281053
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
NR 90
TC 2
Z9 2
U1 3
U2 13
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD MAR 18
PY 2019
VL 126
BP 147
EP 158
DI 10.1016/j.neuropsychologia.2018.01.013
PG 12
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA IA2QV
UT WOS:000469407100019
PM 29352968
DA 2021-02-24
ER

PT J
AU Coffey, EBJ
   Arseneau-Bruneau, I
   Zhang, XC
   Zatorre, RJ
AF Coffey, Emily B. J.
   Arseneau-Bruneau, Isabelle
   Zhang, Xiaochen
   Zatorre, Robert J.
TI The Music-In-Noise Task (MINT): A Tool for Dissecting Complex Auditory
   Perception
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE hearing-in-noise; auditory stream segregation; musical training;
   multilingualism; neuroplasticity; interindividual variability; auditory
   working memory; skill assessment tool
ID STREAM SEGREGATION; INDIVIDUAL-DIFFERENCES; CONGENITAL AMUSIA;
   NORMAL-HEARING; BRAIN-STEM; SPEECH; SOUND; DISORDER; CHILDREN
AB The ability to segregate target sounds in noisy backgrounds is relevant both to neuroscience and to clinical applications. Recent research suggests that hearing-in-noise (HIN) problems are solved using combinations of sub-skills that are applied according to task demand and information availability. While evidence is accumulating for a musician advantage in HIN, the exact nature of the reported training effect is not fully understood. Existing HIN tests focus on tasks requiring understanding of speech in the presence of competing sound. Because visual, spatial and predictive cues are not systematically considered in these tasks, few tools exist to investigate the most relevant components of cognitive processes involved in stream segregation. We present the Music-In-Noise Task (MINT) as a flexible tool to expand HIN measures beyond speech perception, and for addressing research questions pertaining to the relative contributions of HIN sub-skills, inter-individual differences in their use, and their neural correlates. The MINT uses a match-mismatch trial design: in four conditions (Baseline, Rhythm, Spatial, and Visual) subjects first hear a short instrumental musical excerpt embedded in an informational masker of "multi-music" noise, followed by either a matching or scrambled repetition of the target musical excerpt presented in silence; the four conditions differ according to the presence or absence of additional cues. In a fifth condition (Prediction), subjects hear the excerpt in silence as a target first, which helps to anticipate incoming information when the target is embedded in masking sound. Data from samples of young adults show that the MINT has good reliability and internal consistency, and demonstrate selective benefits of musicianship in the Prediction, Rhythm, and Visual subtasks. We also report a performance benefit of multilingualism that is separable from that of musicianship. Average MINT scores were correlated with scores on a sentence-in-noise perception task, but only accounted for a relatively small percentage of the variance, indicating that the MINT is sensitive to additional factors and can provide a complement and extension of speech-based tests for studying stream segregation. A customizable version of the MINT is made available for use and extension by the scientific community.
C1 [Coffey, Emily B. J.] Concordia Univ, Dept Psychol, Montreal, PQ, Canada.
   [Coffey, Emily B. J.; Arseneau-Bruneau, Isabelle; Zatorre, Robert J.] Lab Brain Mus & Sound Res BRAMS, Montreal, PQ, Canada.
   [Coffey, Emily B. J.; Arseneau-Bruneau, Isabelle; Zatorre, Robert J.] CRBLM, Montreal, PQ, Canada.
   [Coffey, Emily B. J.; Arseneau-Bruneau, Isabelle; Zatorre, Robert J.] CIRMMT, Montreal, PQ, Canada.
   [Arseneau-Bruneau, Isabelle; Zatorre, Robert J.] McGill Univ, Montreal Neurol Inst, Montreal, PQ, Canada.
   [Zhang, Xiaochen] Tsinghua Univ, Sch Med, Dept Biomed Engn, Beijing, Peoples R China.
RP Coffey, EBJ (corresponding author), Concordia Univ, Dept Psychol, Montreal, PQ, Canada.; Coffey, EBJ (corresponding author), Lab Brain Mus & Sound Res BRAMS, Montreal, PQ, Canada.; Coffey, EBJ (corresponding author), CRBLM, Montreal, PQ, Canada.; Coffey, EBJ (corresponding author), CIRMMT, Montreal, PQ, Canada.
EM emily.coffey@concordia.ca
FU Canadian International Development Research Centre (IDRC); Canadian
   Institutes of Health Research (CIHR)Canadian Institutes of Health
   Research (CIHR); Centre for Research on Brain, Language, and Music
   (CRBLM); China Scholarship CouncilChina Scholarship Council
   [201706210202]
FX EC and RZ were supported by a grant from the Canadian International
   Development Research Centre (IDRC) and by funds from the Canadian
   Institutes of Health Research (CIHR). IA-B was supported by a Graduate
   Student Award from the Centre for Research on Brain, Language, and Music
   (CRBLM). XZ was funded by the China Scholarship Council (201706210202).
CR Agus TR, 2010, NEURON, V66, P610, DOI 10.1016/j.neuron.2010.04.014
   Alain C, 2014, HEARING RES, V308, P162, DOI 10.1016/j.heares.2013.06.008
   Albouy P, 2017, NEURON, V94, P193, DOI 10.1016/j.neuron.2017.03.015
   Amer T, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071630
   Anderson S, 2013, HEARING RES, V300, P18, DOI 10.1016/j.heares.2013.03.006
   Baskent D, 2016, J ACOUST SOC AM, V139, pEL51, DOI 10.1121/1.4942628
   Bench J, 1979, Br J Audiol, V13, P108, DOI 10.3109/03005367909078884
   Bey C, 2002, PERCEPT PSYCHOPHYS, V64, P844, DOI 10.3758/BF03194750
   Boebinger D, 2015, J ACOUST SOC AM, V137, P378, DOI 10.1121/1.4904537
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   Bregman AS, 2015, MUSIC PERCEPT, V33, P12, DOI 10.1525/MP.2015.33.1.12
   Bregman AS, 2000, PERCEPT PSYCHOPHYS, V62, P626, DOI 10.3758/BF03212114
   BREGMAN AS, 1978, CAN J PSYCHOL, V32, P19, DOI 10.1037/h0081664
   Carlyon RP, 2004, TRENDS COGN SCI, V8, P465, DOI 10.1016/j.tics.2004.08.008
   Coffey E.B.J., 2011, P NEUR MUS 4 LEARN M
   Coffey EBJ, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00479
   Coffey EBJ, 2017, HEARING RES, V352, P49, DOI 10.1016/j.heares.2017.02.006
   Costa A, 2014, NAT REV NEUROSCI, V15, P336, DOI 10.1038/nrn3709
   Cunningham J, 2001, CLIN NEUROPHYSIOL, V112, P758, DOI 10.1016/S1388-2457(01)00465-5
   Disbergen NR, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00121
   Du Y, 2017, P NATL ACAD SCI USA, V114, P13579, DOI 10.1073/pnas.1712223114
   Eisinga R, 2013, INT J PUBLIC HEALTH, V58, P637, DOI 10.1007/s00038-012-0416-3
   Foster NEV, 2010, NEUROIMAGE, V53, P26, DOI 10.1016/j.neuroimage.2010.06.042
   Foster NEV, 2010, CEREB CORTEX, V20, P1350, DOI 10.1093/cercor/bhp199
   Ghasemi A, 2012, INT J ENDOCRINOL MET, V10, P486, DOI 10.5812/ijem.3505
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Hornickel J, 2011, BEHAV BRAIN RES, V216, P597, DOI 10.1016/j.bbr.2010.08.051
   JERGER S, 1987, AUDIOLOGY, V26, P298
   Kidd Gerald Jr., 2008, V29, P143
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Kraus N, 2012, ANN NY ACAD SCI, V1252, P100, DOI 10.1111/j.1749-6632.2012.06463.x
   Krizman J, 2012, P NATL ACAD SCI USA, V109, P7877, DOI 10.1073/pnas.1201575109
   Lee H, 2011, P NATL ACAD SCI USA, V108, pE1441, DOI 10.1073/pnas.1115267108
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Lieu JEC, 2013, B-ENT, V9, P107
   Liu F, 2015, NEUROPSYCHOLOGIA, V66, P111, DOI 10.1016/j.neuropsychologia.2014.11.001
   Marozeau J, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011297
   McDermott JH, 2011, P NATL ACAD SCI USA, V108, P1188, DOI 10.1073/pnas.1004765108
   Mechelli A, 2004, NATURE, V431, P757, DOI 10.1038/431757a
   Middlebrooks JC, 2012, J ACOUST SOC AM, V132, P3896, DOI 10.1121/1.4764879
   Musacchia G, 2007, P NATL ACAD SCI USA, V104, P15894, DOI 10.1073/pnas.0701498104
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Oxenham AJ, 2003, J ACOUST SOC AM, V114, P1543, DOI 10.1121/1.1598197
   Parbery-Clark A, 2009, J NEUROSCI, V29, P14100, DOI 10.1523/JNEUROSCI.3256-09.2009
   Pearce M. T., 2005, THESIS, P267
   Pearce MT, 2012, TOP COGN SCI, V4, P625, DOI 10.1111/j.1756-8765.2012.01214.x
   Peretz I, 2002, NEURON, V33, P185, DOI 10.1016/S0896-6273(01)00580-3
   Pressnitzer D, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00158
   Puschmann S, 2019, CEREB CORTEX, V29, P3253, DOI 10.1093/cercor/bhy193
   Reetzke R, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168048
   Roberts B, 2002, J ACOUST SOC AM, V112, P2074, DOI 10.1121/1.1508784
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Shamma SA, 2010, CURR OPIN NEUROBIOL, V20, P361, DOI 10.1016/j.conb.2010.03.009
   Shinn-Cunningham B, 2013, ADV EXP MED BIOL, V787, P501, DOI 10.1007/978-1-4614-1590-9_55
   Slater J, 2015, BEHAV BRAIN RES, V291, P244, DOI 10.1016/j.bbr.2015.05.026
   Strait DL, 2012, BRAIN LANG, V123, P191, DOI 10.1016/j.bandl.2012.09.001
   Strait DL, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00113
   Swaminathan J, 2015, SCI REP-UK, V5, DOI 10.1038/srep11628
   Tabri D, 2011, INT J LANG COMM DIS, V46, P411, DOI 10.3109/13682822.2010.519372
   Thompson EC, 2017, HEARING RES, V344, P148, DOI 10.1016/j.heares.2016.11.007
   Thompson SK, 2011, J EXP PSYCHOL HUMAN, V37, P1253, DOI 10.1037/a0021925
   Vliegen J, 1999, J ACOUST SOC AM, V105, P339, DOI 10.1121/1.424503
   Wilson RH, 2007, J SPEECH LANG HEAR R, V50, P844, DOI 10.1044/1092-4388(2007/059)
   Wilson Richard H, 2003, J Am Acad Audiol, V14, P453
   Wong LLN, 2007, EAR HEARING, V28, p70S, DOI 10.1097/AUD.0b013e31803154d0
   Zendel BR, 2009, J COGNITIVE NEUROSCI, V21, P1488, DOI 10.1162/jocn.2009.21140
   Zheng Y, 2009, INT J AUDIOL, V48, P718, DOI 10.1080/14992020902902658
NR 67
TC 0
Z9 0
U1 1
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD MAR 14
PY 2019
VL 13
AR 199
DI 10.3389/fnins.2019.00199
PG 14
WC Neurosciences
SC Neurosciences & Neurology
GA HO7OT
UT WOS:000461137700001
PM 30930734
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Weissgerber, T
   Stover, T
   Baumann, U
AF Weissgerber, Tobias
   Stoever, Timo
   Baumann, Uwe
TI Speech perception in noise: Impact of directional microphones in users
   of combined electric-acoustic stimulation
SO PLOS ONE
LA English
DT Article
ID BILATERAL COCHLEAR IMPLANTS; HEARING-AIDS; BACKGROUND-NOISE; WIND NOISE;
   PROCESSOR; INTELLIGIBILITY; LOCALIZATION; RECIPIENTS; OPTIONS
AB Objectives
   Combined electric-acoustic stimulation (EAS) is a well-accepted therapeutic treatment for cochlear implant (CI) users with residual hearing in the low frequencies but severe to pro-found hearing loss in the high frequencies. The recently introduced SONNETeas audio processor offers different microphone directionality (MD) settings and wind noise reduction (WNR) as front-end processing. The aim of this study was to compare speech perception in quiet and noise between two EAS audio processors DUET 2 and SONNETeas, to assess the impact of MD and WNR on speech perception in EAS users in the absence of wind. Furthermore, subjective rating of hearing performance was registered.
   Method
   Speech perception and subjective rating with SONNETeas or DUET 2 audio processor were assessed in 10 experienced EAS users. Speech perception was measured in quiet and in a diffuse noise setup (MSNF). The SONNETeas processor was tested with three MD settings omnidirectional/natural/adaptive and with different intensities of WNR. Subjective rating of auditory benefit and sound quality was rated using two questionnaires.
   Results
   There was no significant difference between DUET 2 and SONNETeas processor using the omnidirectional microphone in quiet and in noise. There was a significant improvement in SRT with MD settings natural (2.2 dB) and adaptive (3.6 dB). No detrimental effect of the WNR algorithm on speech perception was found in the absence of wind. Sound quality was rated as "moderate" for both audio processors.
   Conclusions
   The different MD settings of the SONNETeas can provide EAS users with better speech perception compared to an omnidirectional microphone. Concerning speech perception in quiet and quality of life, the performance of the DUET 2 and SONNETeas audio processors was comparable.
C1 [Weissgerber, Tobias; Baumann, Uwe] Univ Hosp Frankfurt, ENT Dept, Audiol Acoust, Frankfurt, Germany.
   [Stoever, Timo] Univ Hosp Frankfurt, ENT Dept, Frankfurt, Germany.
RP Weissgerber, T (corresponding author), Univ Hosp Frankfurt, ENT Dept, Audiol Acoust, Frankfurt, Germany.
EM tobias.weissgerber@kgu.de
RI Baumann, Uwe/AAE-5640-2019
OI Baumann, Uwe/0000-0002-1295-2661
FU MED-EL Elektromedizinische Geraete GmbH Innsbruck, Austria
FX This work was funded by MED-EL Elektromedizinische Geraete GmbH
   Innsbruck, Austria to UB. The study was designed in collaboration with
   MED-EL corporation. The funders had no role in data collection and
   analysis, decision to publish, or preparation of the manuscript.
CR Amann E, 2014, ACTA OTO-LARYNGOL, V134, P915, DOI 10.3109/00016489.2014.909604
   Bentler Ruth A, 2005, J Am Acad Audiol, V16, P473, DOI 10.3766/jaaa.16.7.7
   BERKHOUT AJ, 1988, J AUDIO ENG SOC, V36, P977
   Brand T, 2002, J ACOUST SOC AM, V111, P2801, DOI 10.1121/1.1479152
   Brockmeyer AM, 2011, J AM ACAD AUDIOL, V22, P65, DOI 10.3766/jaaa.22.2.2
   Chung K, 2012, INT J AUDIOL, V51, P29, DOI 10.3109/14992027.2011.609184
   Chung K, 2009, J ACOUST SOC AM, V125, P2243, DOI 10.1121/1.3086268
   Dorman MF, 2018, J AM ACAD AUDIOL, V29, P197, DOI 10.3766/jaaa.16126
   Dorman MF, 2013, EAR HEARING, V34, P245, DOI 10.1097/AUD.0b013e318269ce70
   Dorman MF, 2010, INT J AUDIOL, V49, P912, DOI 10.3109/14992027.2010.509113
   Dunn CC, 2010, J AM ACAD AUDIOL, V21, P44, DOI 10.3766/jaaa.21.1.6
   GeiSSler Gunnar, 2015, Cochlear Implants Int, V16, P69, DOI 10.1179/1754762814Y.0000000088
   Gifford RH, 2013, EAR HEARING, V34, P413, DOI 10.1097/AUD.0b013e31827e8163
   Gifford RH, 2010, J AM ACAD AUDIOL, V21, P441, DOI 10.3766/jaaa.21.7.3
   HAHLBROCK K H, 1953, Arch Ohren Nasen Kehlkopfheilkd, V162, P394, DOI 10.1007/BF02105664
   Helbig S, 2008, ORL-J OTO-RHIN-LARYN, V70, P359, DOI 10.1159/000163031
   Helbig S, 2010, ADV OTO-RHINO-LARYNG, V67, P81, DOI 10.1159/000262599
   Hersbach AA, 2012, EAR HEARING, V33, pE13, DOI 10.1097/AUD.0b013e31824b9e21
   Honeder C, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0190718
   Lorens A, 2008, LARYNGOSCOPE, V118, P288, DOI 10.1097/MLG.0b013e3181598887
   Lorens A, 2012, ACTA OTO-LARYNGOL, V132, P739, DOI 10.3109/00016489.2012.654852
   McCreery RW, 2012, AM J AUDIOL, V21, P295, DOI 10.1044/1059-0889(2012/12-0014)
   Rader T, 2015, EAR HEARING, V36, P325
   Rader T, 2013, EAR HEARING, V34, P324, DOI 10.1097/AUD.0b013e318272f189
   Spriet A, 2007, EAR HEARING, V28, P62, DOI 10.1097/01.aud.0000252470.54246.54
   von Ilberg CA, 2011, AUDIOL NEURO-OTOL, V16, P1, DOI 10.1159/000327765
   Weissgerber T, 2017, OTOL NEUROTOL, V38, pE551, DOI 10.1097/MAO.0000000000001524
   Weissgerber T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126133
   Wimmer W, 2016, OTOL NEUROTOL, V37, P19, DOI 10.1097/MAO.0000000000000866
NR 29
TC 0
Z9 0
U1 0
U2 0
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD MAR 6
PY 2019
VL 14
IS 3
AR e0213251
DI 10.1371/journal.pone.0213251
PG 14
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA HN7LX
UT WOS:000460372100070
PM 30840668
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Chu, J
   Yang, CS
   Liu, GF
AF Chu, Jing
   Yang, Chunsheng
   Liu, Guofa
TI Analysis of Second Language Acquisition (SLA) Speech Perception Model &
   the Perception of Second Language Prosody
SO REVISTA DE CERCETARE SI INTERVENTIE SOCIALA
LA English
DT Article
DE second language; speech perception; perception models; prosodic
   perception
ID JAPANESE ADULTS; ENGLISH; LANGUAGE; SPANISH; SPEAKERS; VOWELS; GERMAN;
   FRENCH
AB This paper provides a critical review on the major models of speech perception in second language (L2) acquisition. It is argued that some new models, such as L2LP and ASP, have more explanatory power for L2 speech perception. However, due to the different theoretical frameworks, objectives and hypotheses in these models, it is difficult to integrate these models into one which is universally applicable. Although most of these models were proposed for accounting for the perception of L2 segments, they can also be applied in the perception of L2 prosody. When these models are used in examining L2 speech prosody, the prosodic systems of both L1 and L2 should be thoroughly investigated first.
C1 [Chu, Jing] Bohai Univ, Jinzhou City 121000, Liaoning, Peoples R China.
   [Yang, Chunsheng] Univ Connecticut, Storrs, CT USA.
   [Liu, Guofa] Beijing Century Internet Software Co LTD, Beijing, Peoples R China.
RP Chu, J (corresponding author), Bohai Univ, Jinzhou City 121000, Liaoning, Peoples R China.
EM feierandclub_bhu@163.com; yangchunsheng_uc@163.com;
   liuguofa_bjcls@163.com
FU Social Science Fund Project of Liaoning province [L18BYY004]; Dr.
   Start-up Fund Project of Liaoning province [JH1/102]
FX This work is supported by the Social Science Fund Project of Liaoning
   province (Project number: L18BYY004), and Dr. Start-up Fund Project of
   Liaoning province (Project number: JH1/102).
CR Bent T, 2005, THESIS
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P, 2001, LINGUIST INQ, V32, P45, DOI 10.1162/002438901554586
   Boersma Paul, 1998, THESIS
   CARAMAZZA A, 1973, J ACOUST SOC AM, V54, P421, DOI 10.1121/1.1913594
   Chen A, 2005, UNIVERSAL LANGUAGE S
   Escudero P, 2004, STUD SECOND LANG ACQ, V26, P551, DOI 10.1017/S0272226310400021
   Escudero P, 2006, PHONOLOGY IN CONTEXT
   ESCUDERO P., 2005, THESIS, P348
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege JE, 2004, STUD SECOND LANG ACQ, V26, P1, DOI 10.1017/S0272263104261010
   Flege JE, 2003, SPEECH COMMUN, V40, P467, DOI 10.1016/S0167-6393(02)00128-0
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   FLEGE JE, 1993, J ACOUST SOC AM, V93, P1589, DOI 10.1121/1.406818
   FLEGE JE, 1987, SPEECH COMMUN, V6, P185, DOI 10.1016/0167-6393(87)90025-2
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   GOTO H, 1971, NEUROPSYCHOLOGIA, V9, P317, DOI 10.1016/0028-3932(71)90027-3
   Grabe E, 2003, LANG SPEECH, V46, P375, DOI 10.1177/00238309030460040201
   Guion SG, 2000, J ACOUST SOC AM, V107, P2711, DOI 10.1121/1.428657
   Guion SG, 2003, PHONETICA, V60, P98, DOI 10.1159/000071449
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   Kuhl P. K., 1995, SPEECH PERCEPTION LI, P121
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Kuhl PK, 2000, P NATL ACAD SCI USA, V97, P11850, DOI 10.1073/pnas.97.22.11850
   Leather J, 1999, LANG LEARN, V49, P1, DOI 10.1111/0023-8333.49.s1.1
   Llisterri J., 1995, P 13 INT C PHON SCI, V4, P92
   MacKay IRA, 2001, J ACOUST SOC AM, V110, P516, DOI 10.1121/1.1377287
   MAJOR R., 2001, FOREIGN ACCENT
   Major R.C., 2002, PORTRAITS L2 USER, P65
   NEUFELD GG, 1988, LANG LEARN, V38, P531, DOI 10.1111/j.1467-1770.1988.tb00166.x
   Polivanov Evgenij D., 1931, TRAVAUX CERCLE LINGU, V4, P79
   SHELDON A, 1982, APPL PSYCHOLINGUIST, V3, P243, DOI 10.1017/S0142716400001417
   Strange W, 2004, J ACOUST SOC AM, V115, P1791, DOI 10.1121/1.1687832
   Strange W., 1995, SPEECH PERCEPTION LI, P3
   Strange W., 2006, J ACOUST SOC AM, V120, P3137, DOI DOI 10.1121/1.4787743
   Strange W., 2008, PHONOLOGY 2 LANGUAGE, P153
   Strange W, 2007, J ACOUST SOC AM, V122, P1111, DOI 10.1121/1.2749716
   Trubetzkov N.S, 1969, PRINCIPLES PHONOLOGY
   WILLIAMS L, 1977, PERCEPT PSYCHOPHYS, V21, P289, DOI 10.3758/BF03199477
NR 42
TC 0
Z9 0
U1 0
U2 0
PU EXPERT PROJECTS PUBLISHING
PI IASI
PA IASI, STR VOINESTI 63, IASI, 700615, ROMANIA
SN 1583-3410
EI 1584-5397
J9 REV CERCET INTERV SO
JI Rev. Cercet. Interv. Soc.
PD MAR
PY 2019
VL 64
BP 334
EP 351
DI 10.33788/rcis.64.25
PG 18
WC Social Sciences, Interdisciplinary
SC Social Sciences - Other Topics
GA JW1KH
UT WOS:000502817200025
OA Bronze
DA 2021-02-24
ER

PT J
AU Dominguez, AB
   Alegria, J
   Carrillo, MS
   Gonzalez, V
AF Dominguez, Ana-Belen
   Alegria, Jesus
   Carrillo, Maria-Soledad
   Gonzalez, Virginia
TI Learning to Read for Spanish-Speaking Deaf Children With and Without
   Cochlear Implants: The Role of Phonological and Orthographic
   Representation
SO AMERICAN ANNALS OF THE DEAF
LA English
DT Article
DE cochlear implant; reading; phonological representations; orthographic
   representations
ID SPEECH-PERCEPTION; LANGUAGE-DEVELOPMENT; HEARING-LOSS; SKILLS; AGE;
   LITERACY; OUTCOMES; STUDENTS; PERFORMANCE; VOCABULARY
AB The authors examined the relationship between cochlear implants (CIs) and reading acquisition and attempted to determine the part played by phonological and orthographic resources in this task. Four groups of Spanish-speaking deaf children were examined: children with either early-or late-implanted CIs, and children without CIs who had either moderate or profound hearing loss. A hearing group was included to control for age and reading level. Reading, spelling, and three metaphonological abilities were evaluated. The results showed that the reading levels achieved by deaf children strongly depend on phonological ability. Age at implantation and, for deaf children without CIs, degree of hearing loss, play important roles in this ability. The results further suggest that both deaf and hearing children develop phonological representations of words, a skill that contributes to reading and spelling acquisition. Reciprocally, reading itself contributes to the elaboration of phonological and orthographic representations.
C1 [Dominguez, Ana-Belen; Gonzalez, Virginia] Univ Salamanca, Fac Educ, Salamanca, Spain.
   [Alegria, Jesus] Free Univ Brussels, Cognit Language & Dev Lab LCLD, Brussels, Belgium.
   [Carrillo, Maria-Soledad] Univ Murcia, Fac Psychol, Murcia, Spain.
RP Dominguez, AB (corresponding author), Univ Salamanca, Fac Educ, Salamanca, Spain.
RI Gutierrez, Ana Belen Dominguez/M-9809-2015
OI Gutierrez, Ana Belen Dominguez/0000-0002-2423-507X
CR Abusamra V., 2010, TEST LEER COMPRENDER
   Alegria J., 2010, CUED SPEECH CUED LAN, P95
   Alegria J, 2014, ESTUD PSICOL-MADRID, V35, P476, DOI 10.1080/02109395.2014.978544
   Archbold S, 2008, INT J PEDIATR OTORHI, V72, P1471, DOI 10.1016/j.ijporl.2008.06.016
   Bayard C, 2014, FRONT PSYCHOL, V5, DOI [10.3389/fpsyg.2010.00416, DOI 10.3389/FPSYG.2010.00416]
   BERTELSON P, 1986, COGNITION, V24, P1, DOI 10.1016/0010-0277(86)90002-8
   Blamey PJ, 2001, J SPEECH LANG HEAR R, V44, P264, DOI 10.1044/1092-4388(2001/022)
   Bochner J. H., 2016, OXFORD HDB DEAF STUD, P393
   BRADLEY L, 1983, NATURE, V301, P419, DOI 10.1038/301419a0
   Bravo Valdivieso Luis, 2004, Estud. pedagóg., P7, DOI 10.4067/S0718-07052004000100001
   BRUCK M, 1992, DEV PSYCHOL, V28, P874, DOI 10.1037/0012-1649.28.5.874
   Byrne B., 1992, READING ACQUISITION, P1
   Cain K, 2014, READING DEV DIFFICUL
   Calet N, 2016, AN PSICOL-SPAIN, V32, P72, DOI 10.6018/analesps.32.1.216221
   Calet N, 2015, SCI STUD READ, V19, P51, DOI 10.1080/10888438.2014.976342
   Carrillo Gallego María Soledad, 2011, Escritos de Psicología, V4, P35
   Carter AK, 2002, CLIN LINGUIST PHONET, V16, P619, DOI 10.1080/02699200021000034958
   Chambre SJ, 2017, READ WRIT, V30, P1137, DOI 10.1007/s11145-016-9715-z
   Ching Teresa Y C, 2014, Cochlear Implants Int, V15 Suppl 1, pS27, DOI 10.1179/1467010014Z.000000000172
   Colin S, 2007, J CHILD PSYCHOL PSYC, V48, P139, DOI 10.1111/j.1469-7610.2006.01700.x
   Connor CM, 2006, EAR HEARING, V27, P628, DOI 10.1097/01.aud.0000240640.59205.42
   Cuadro A., 2009, EVALUACION NIVEL LEC
   Cuadro A., 2007, CIENCIAS PSICOLOGICA, VI, P133
   Cupples L, 2014, J DEAF STUD DEAF EDU, V19, P20, DOI 10.1093/deafed/ent039
   Dehaene S., 2009, READING BRAIN NEW SC
   Dettman SJ, 2007, EAR HEARING, V28, p11S, DOI 10.1097/AUD.0b013e31803153f8
   Dillon CM, 2012, J DEAF STUD DEAF EDU, V17, P205, DOI 10.1093/deafed/enr043
   Dodd B., 1998, HEARING EYE, P229
   Dominguez A.B., 2011, REV EDUC, V356, P353, DOI DOI 10.4438/1988-592X-RE-2011-356-043
   Dominguez AB, 2016, J DEAF STUD DEAF EDU, V21, P280, DOI 10.1093/deafed/enw026
   Dominguez AB, 2014, RES DEV DISABIL, V35, P1439, DOI 10.1016/j.ridd.2014.03.039
   Dominguez AB, 2012, INFANC APRENDIZ, V35, P327, DOI 10.1174/021037012802238993
   Dominguez AB, 2010, J DEAF STUD DEAF EDU, V15, P136, DOI 10.1093/deafed/enp033
   Dunn CC, 2014, EAR HEARING, V35, P148, DOI 10.1097/AUD.0b013e3182a4a8f0
   Dyer A., 2003, J DEAF STUD DEAF EDU, V8, P215, DOI [10.1093/deafed/eng012, DOI 10.1093/DEAFED/ENG012]
   Easterbrooks SR, 2012, AM ANN DEAF, V157, P27, DOI 10.1353/aad.2012.1611
   Ehri L. C., 1992, READING ACQUISITION, P107
   EHRI LC, 1995, READ WRIT, V7, P295, DOI 10.1007/BF03162082
   Ferreres A., 2011, REV NEUROPSICOLOGIA, V3, P1, DOI [10.5579/rnl.2011.0040, DOI 10.5579/RNL.2011.0040]
   Florit E, 2011, EDUC PSYCHOL REV, V23, P553, DOI 10.1007/s10648-011-9175-6
   FRITH U, 1986, ANN DYSLEXIA, V36, P69, DOI 10.1007/BF02648022
   Geers A. E., 2006, ADV SPOKEN LANGUAGE, P244, DOI DOI 10.1001/JAMA.2010.451
   Geers AE, 2003, EAR HEARING, V24, p59S, DOI 10.1097/01.AUD.0000051690.43989.5D
   Geers A, 2008, INT J AUDIOL, V47, pS21, DOI 10.1080/14992020802339167
   Geers Ann E, 2011, Ear Hear, V32, p49S, DOI 10.1097/AUD.0b013e3181fa41fa
   Geers AE, 2009, J DEAF STUD DEAF EDU, V14, P371, DOI 10.1093/deafed/enn046
   Geers Ann E, 2007, Audiol Med, V5, P262, DOI 10.1080/16513860701659404
   Gough P.B., 1986, REMEDIAL SPECIAL ED, V7, DOI [DOI 10.1177/074193258600700104, https://doi.org/10.1177/074193258600700104, 10.1177/074193258600700104]
   Gough P. B., 1991, LEARNING READ BASIC, P47
   Gough PB, 1996, READING COMPREHENSION DIFFICULTIES, P1
   Harris M, 1998, J Deaf Stud Deaf Educ, V3, P205
   Harris M., 2016, OXFORD HDB DEAF STUD, P407, DOI DOI 10.1093/DEAFED/ENQ031
   Harris M, 2017, J DEAF STUD DEAF EDU, V22, P233, DOI 10.1093/deafed/enw101
   Harris M, 2011, J DEAF STUD DEAF EDU, V16, P24, DOI 10.1093/deafed/enq031
   HATCHER PJ, 1994, CHILD DEV, V65, P41, DOI 10.1111/j.1467-8624.1994.tb00733.x
   HOOVER WA, 1990, READ WRIT, V2, P127, DOI 10.1007/BF00401799
   Johnson C, 2010, J SPEECH LANG HEAR R, V53, P237, DOI 10.1044/1092-4388(2009/08-0139)
   JORM AF, 1983, APPL PSYCHOLINGUIST, V4, P103, DOI 10.1017/S0142716400004380
   Joseph J, 2001, J LEARN DISABIL-US, V34, P566, DOI 10.1177/002221940103400609
   Kolinsky R., 2015, OXFORD HDB READING, P377, DOI DOI 10.1093/OXFORDHB/9780199324576.013.29
   Kyle FE, 2010, J EXP CHILD PSYCHOL, V107, P229, DOI 10.1016/j.jecp.2010.04.011
   Kyritsi E, 2017, SELECTED PAPERS THEO, V17, P433
   LaSasso C. J., 2010, CUED SPEECH CUED LAN
   Le Normand M. T, 2010, LANGUE FRANCAISE PAR, P191
   Le Normand M. T., 2005, REEDUCATION ORTHOPHO, V217, P125
   Leybaert J., 2011, OXFORD HDB DEAF STUD, V1, P276
   Marin J., 1999, TEST COLECTIVO EFICA
   Marschark M., 2010, OXFORD HDB DEAF STUD, V2, P127
   Mayberry RI, 2011, J DEAF STUD DEAF EDU, V16, P164, DOI 10.1093/deafed/enq049
   Mayer C, 2007, J DEAF STUD DEAF EDU, V12, P411, DOI 10.1093/deafed/enm020
   Mayer C, 2018, J DEAF STUD DEAF EDU, V23, P1, DOI 10.1093/deafed/enx043
   Mayer C, 2014, AM ANN DEAF, V159, P359, DOI 10.1353/aad.2014.0032
   McQuarrie L, 2009, J DEAF STUD DEAF EDU, V14, P137, DOI 10.1093/deafed/enn025
   Melby-Lervag M, 2012, PSYCHOL BULL, V138, P322, DOI 10.1037/a0026744
   Miller P, 2011, J DEV PHYS DISABIL, V23, P459, DOI 10.1007/s10882-011-9246-0
   MORAIS J, 1987, CAH PSYCHOL COGN, V7, P415
   Morais J, 1992, ANAL APPROACHES HUMA, P193
   Moreno-Perez FJ, 2015, J DEAF STUD DEAF EDU, V20, P374, DOI 10.1093/deafed/env030
   Morton J., 1980, COGNITIVE PROCESS, P117
   Narr RAF, 2006, TEACH EXCEPT CHILD, V38, P53, DOI 10.1177/004005990603800408
   National Institute of Child Health and Human Development, 2000, NIH PUBLICATION
   Nicholas JG, 2007, J SPEECH LANG HEAR R, V50, P1048, DOI 10.1044/1092-4388(2007/073)
   Nittrouer S, 2012, EAR HEARING, V33, P683, DOI 10.1097/AUD.0b013e318258c98e
   O'Donoghue GM, 1999, EAR HEARING, V20, P419, DOI 10.1097/00003446-199910000-00005
   Perfetti Charles A., 2000, J DEAF STUD DEAF EDU, V5, P32, DOI [DOI 10.1093/DEAFED/5.1.32, 10.1093/deafed/5.1.32]
   Perfetti Charles A., 1992, READING ACQUISITION, P145, DOI DOI 10.4324/9781351236904-6
   Pisoni D. B., 2008, DEAF COGNITION FDN O, P52, DOI [DOI 10.1093/ACPROF:OSO/9780195368673.001.0001, 10.1093/acprof:oso/9780195368673.003.0003]
   Pritchard SC, 2018, COGNITIVE SCI, V42, P722, DOI 10.1111/cogs.12571
   RACK JP, 1992, READ RES QUART, V27, P28, DOI 10.2307/747832
   Ramus F, 2014, TRENDS COGN SCI, V18, P274, DOI 10.1016/j.tics.2014.01.009
   Salceda J., 2014, REV LOGOPEDIA FONIAT, V43, P17, DOI [10.1016/j.rlfa.2013.04.006, DOI 10.1016/J.RLFA.2013.04.006]
   Schorr E. A., 2008, COMMUN DISORD Q, V29, P195, DOI DOI 10.1177/1525740108321217
   Seymour PHK, 2003, BRIT J PSYCHOL, V94, P143, DOI 10.1348/000712603321661859
   Share DL, 1999, J EXP CHILD PSYCHOL, V72, P95, DOI 10.1006/jecp.1998.2481
   SHARE DL, 1995, COGNITION, V55, P151, DOI 10.1016/0010-0277(94)00645-2
   Share DL, 1995, ISSUES ED CONTRIBUTI, V1, P1, DOI DOI 10.1111/J.1467-9817.1995.TB00075.X
   Shaywitz BA, 2002, BIOL PSYCHIAT, V52, P101, DOI 10.1016/S0006-3223(02)01365-3
   Snowling MJ, 2006, LOND REV EDUC, V4, P63, DOI 10.1080/13603110600574462
   Spencer LJ, 2009, J DEAF STUD DEAF EDU, V14, P1, DOI 10.1093/deafed/enn013
   Spencer P. E., 2011, OXFORD HDB DEAF STUD, P452, DOI DOI 10.1093/0XF0RDHB/9780199750986.013.0032
   Spencer Patricia E, 2004, J Deaf Stud Deaf Educ, V9, P395, DOI 10.1093/deafed/enh033
   STANOVICH KE, 1994, J EDUC PSYCHOL, V86, P24, DOI 10.1037/0022-0663.86.1.24
   Strong M, 2000, LANGUAGE ACQUISITION BY EYE, P131
   Svirsky MA, 2004, AUDIOL NEURO-OTOL, V9, P224, DOI 10.1159/000078392
   Svirsky MA, 2000, PSYCHOL SCI, V11, P153, DOI 10.1111/1467-9280.00231
   Tomblin JB, 1999, J SPEECH LANG HEAR R, V42, P497, DOI 10.1044/jslhr.4202.497
   Treiman R, 2005, BL HBK DEV PSYCHOL, P120, DOI 10.1002/9780470757642.ch7
   Trezek BJ, 2006, J DEAF STUD DEAF EDU, V11, P202, DOI 10.1093/deafed/enj031
   Vermeulen AM, 2007, J DEAF STUD DEAF EDU, V12, P283, DOI 10.1093/deafed/enm017
   Wang Y, 2008, AM ANN DEAF, V153, P396
   Young GA, 2002, ANN OTO RHINOL LARYN, V111, P802, DOI 10.1177/000348940211100908
   Ziegler JC, 2010, PSYCHOL SCI, V21, P551, DOI 10.1177/0956797610363406
   2009, APPL PSYCHOLINGUIST, V30, P1, DOI DOI 10.1017/50142716408090012
NR 113
TC 0
Z9 0
U1 0
U2 4
PU GALLAUDET UNIV PRESS
PI WASHINGTON
PA 800 FLORIDA AVE NE, WASHINGTON, DC 20002 USA
SN 0002-726X
EI 1543-0375
J9 AM ANN DEAF
JI Am. Ann. Deaf
PD SPR
PY 2019
VL 164
IS 1
BP 37
EP 72
DI 10.1353/aad.2019.0009
PG 36
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA HY3GV
UT WOS:000468012200003
PM 31080181
DA 2021-02-24
ER

PT J
AU Ravanshenas, E
   Jalilvand, H
   Baghban, AA
AF Ravanshenas, Elahe
   Jalilvand, Hamid
   Baghban, Alireza Akbarzade
TI Top-Down Auditory Plasticity: Acceptable Noise Level Predicts and
   Reflects the Effect of Perceptual Learning in Experience-Induced
   Plasticity
SO IRANIAN JOURNAL OF CHILD NEUROLOGY
LA English
DT Article
DE Acceptable noise level; Noise; Hearing; Auditory efferent system
ID OLIVOCOCHLEAR EFFERENTS; SPEECH; SYSTEM
AB Objective
   In the auditory system, tinnitus and superior speech perception in noise are examples of negative and positive plasticity that can result from sensory neural hearing loss and life experiences dealing with more complex stimuli and learning, respectively. The main objective of this study was to determine the relationship between acceptable noise level (ANL) values and perceptual learning in individuals exposed to unavoidable occupational noise.
   Materials & Methods
   Here we document a form of plasticity in top-down auditory pathways through the measurement of the acceptable noise level in 60 adults, 27 females and 33 males, with normal hearing (Amiraalam state Hospital, Tehran, Iran 2016). Individuals were assigned to one of two groups: those with and without the occupational experience of speech perception in noise.
   Results
   The test group had statistically significant lower acceptable noise level and significantly higher background noise level scores compared with the control group.
   Conclusion
   Using acceptable noise level, we attributed differences in individuals' abilities to tolerate varying amounts of background noise and speech perception in noise function to the auditory efferent system. Working in crowded locations due to job nature can influence differences in speech perception in noise function.
C1 [Ravanshenas, Elahe; Jalilvand, Hamid] Shahid Beheshti Univ Med Sci, Sch Rehabil, Dept Audiol, Tehran, Iran.
   [Baghban, Alireza Akbarzade] Shahid Beheshti Univ Med Sci, Sch Rehabil, Tehran, Iran.
RP Jalilvand, H (corresponding author), Shahid Beheshti Univ Med Sci, Sch Rehabil, Dept Audiol, Tehran, Iran.
EM hamidjalilvand4@gmail.com
RI Jalilvand, Hamid/V-3684-2018
OI Jalilvand, Hamid/0000-0002-2351-5918
CR Aghsoleimani M, 2018, CLIN EXP OTORHINOLAR, V11, P166, DOI 10.21053/ceo.2017.01375
   Ahmadi A, 2015, SCI J REHABIL MED, V4, P109
   Ahmadi R, 2018, CLIN EXP OTORHINOLAR, V11, P267, DOI 10.21053/ceo.2018.00052
   Andeol G, 2011, J NEUROSCI, V31, P6759, DOI 10.1523/JNEUROSCI.0248-11.2011
   Anderson S, 2013, HEARING RES, V300, P18, DOI 10.1016/j.heares.2013.03.006
   Brown GJ, 2010, J ACOUST SOC AM, V127, P943, DOI 10.1121/1.3273893
   Ciuman Raphael Richard, 2010, Int J Biomed Sci, V6, P276
   de Boer J, 2008, J NEUROSCI, V28, P4929, DOI 10.1523/JNEUROSCI.0902-08.2008
   de Boer J, 2012, J NEUROPHYSIOL, V107, P1301, DOI 10.1152/jn.00222.2011
   Freyaldenhoven MC, ACCEPTABLE NOISE LEV
   Freyaldenhoven MC, 2006, J AM ACAD AUDIOL, V17, P640, DOI 10.3766/jaaa.17.9.3
   Guinan JJ, 2006, EAR HEARING, V27, P589, DOI 10.1097/01.aud.0000240507.83072.e7
   Guinan JJ, 2014, SPRINGER HANDB AUDIT, V50, P229, DOI 10.1007/978-1-4614-9102-6_13
   Harkrider AW, 2006, J AM ACAD AUDIOL, V17, P667, DOI 10.3766/jaaa.17.9.6
   Kim JH, 2014, CLIN EXP OTORHINOLAR, V7, P94, DOI 10.3342/ceo.2014.7.2.94
   NABELEK AK, 1991, J SPEECH HEAR RES, V34, P679, DOI 10.1044/jshr.3403.679
   Prabhu P, 2016, J PHONETICS AUDIOLOG, V2, P1
   Shetty HN, 2014, AUDIOL RES, V4, P1, DOI 10.4081/audiores.2014.93
   Shetty Hemanth Narayan, 2015, J Otol, V10, P93, DOI 10.1016/j.joto.2015.10.002
   Shi LF, 2015, J SPEECH LANG HEAR R, V58, P497, DOI 10.1044/2015_JSLHR-H-14-0244
   White EJ, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00090
NR 21
TC 0
Z9 0
U1 0
U2 0
PU IRANIAN CHILD NEUROLOGY SOC
PI TEHRAN
PA 3D FL, CHILD NEUROLOGY OFF, MOFID CHILDREN HOSPITAL, TEHRAN,
   15468-15514, IRAN
SN 1735-4668
EI 2008-0700
J9 IRAN J CHILD NEUROL
JI Iran. J.Child Neurol.
PD SPR
PY 2019
VL 13
IS 2
BP 103
EP 111
PG 9
WC Clinical Neurology
SC Neurosciences & Neurology
GA HU7EA
UT WOS:000465442700011
PM 31037083
DA 2021-02-24
ER

PT J
AU Shastri, U
   Raj, KKP
   Mathew, M
   Kalaiah, MK
   Uppunda, AK
AF Shastri, Usha
   Raj, Keerthana Kulath Purath
   Mathew, Mable
   Kalaiah, Mohan Kumar
   Uppunda, Ajith Kumar
TI Relationship between Working Memory and Identification of a Few Native
   Phonetic Contrasts
SO COMMUNICATION SCIENCES AND DISORDERS-CSD
LA English
DT Article
DE Native speech perception; Working memory capacity; Top down influence;
   Native phone identification; Cognition; Individual variability
ID INDIVIDUAL-DIFFERENCES; SPEECH RECOGNITION; PERCEPTION; CAPACITY;
   LISTENERS; SPAN; COMPREHENSION; VARIABILITY; CONSONANTS; ADULTS
AB Objectives: Large individual variability is documented for identification performance of native phones, especially in challenging situations. It is not known whether the ability to utilize cues available for phone identification is facilitated by cognitive abilities, thereby explaining a proportion of the individual variability. This study investigated the relationship between working memory capacity and identification of a few Malayalam phones in the absence of contextual cues among native listeners. Methods: Forty native listeners of Malayalam, aged between 18 and 25, participated in this study. Participants identified 8 Malayalam phones embedded in nonsense words. Working memory capacity was measured using tasks such as reading span, operation span, digit forward span, and digit backward span. Identification score for each phone, total phone identification score (average identification score from 8 phones), and reaction time during identification were obtained. Results: Phone identification score of participants ranged from 57.8% to 99%. Pearson product moment correlation analysis showed a significant positive correlation between all measures of working memory capacity and total phone identification score, indicating that working memory capacity play a role in the identification of phones. Reaction time showed a significant negative correlation with digit backward span and operation span. The measures of working memory capacity accounted for 24.7% of the variability in phone identification score. Conclusion: Identification of phones in the absence of contextual cues increases the cognitive load. Therefore, higher working memory capacity might aid in native phone identification in difficult situations. This study reveals the top down influence of cognition on native speech perception.
C1 [Shastri, Usha; Kalaiah, Mohan Kumar] Kasturba Med Coll & Hosp, Dept Audiol & Speech Language Pathol, Light House Hill Rd, Mangalore 575001, Karnataka, India.
   [Shastri, Usha; Kalaiah, Mohan Kumar] Manipal Acad Higher Educ, Manipal, Karnataka, India.
   [Raj, Keerthana Kulath Purath; Mathew, Mable] Nitte Inst Speech & Hearing, Mangalore, Karnataka, India.
   [Uppunda, Ajith Kumar] All India Inst Speech & Hearing, Dept Audiol, Mysuru, Karnataka, India.
RP Kalaiah, MK (corresponding author), Kasturba Med Coll & Hosp, Dept Audiol & Speech Language Pathol, Light House Hill Rd, Mangalore 575001, Karnataka, India.
EM mohan.kumark@manipal.edu
RI Kalaiah, Mohan Kumar/B-2304-2016
OI Kalaiah, Mohan Kumar/0000-0001-9984-9175; Kumar,
   Ajith/0000-0002-1368-9834; Shastri, Usha/0000-0003-1172-3549
CR Asher R.E., 1997, MALAYALAM
   Broersma M, 2010, J ACOUST SOC AM, V127, P1636, DOI 10.1121/1.3292996
   Calmorin M. A., 1997, STAT ED SCI
   Chandrasekaran B, 2010, J ACOUST SOC AM, V128, P456, DOI 10.1121/1.3445785
   Chang CB, 2012, J ACOUST SOC AM, V132, P2700, DOI 10.1121/1.4747615
   Conway ARA, 2005, PSYCHON B REV, V12, P769, DOI 10.3758/BF03196772
   Conway ARA, 2003, TRENDS COGN SCI, V7, P547, DOI 10.1016/j.tics.2003.10.005
   Daneman M, 1996, PSYCHON B REV, V3, P422, DOI 10.3758/BF03214546
   DANEMAN M, 1983, J EXP PSYCHOL LEARN, V9, P561, DOI 10.1037/0278-7393.9.4.561
   Davis MF, 2011, J OCCUP ENVIRON MED, V53, P190, DOI [10.1097/JOM.0b013e31820805d5, 10.1162/jocn_a_00084]
   Engle RW, 2002, CURR DIR PSYCHOL SCI, V11, P19, DOI 10.1111/1467-8721.00160
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   Francis AL, 2009, ATTEN PERCEPT PSYCHO, V71, P1360, DOI 10.3758/APP.71.6.1360
   Gordon-Salant S, 2016, EAR HEARING, V37, P593, DOI 10.1097/AUD.0000000000000316
   Harnsberger JD, 2001, J PHONETICS, V29, P303, DOI 10.1006/jpho.2001.0140
   Heald SLM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00035
   Huguelet P, 2000, EUR ARCH PSY CLIN N, V250, P79, DOI 10.1007/s004060070039
   Janse E, 2014, Q J EXP PSYCHOL, V67, P1842, DOI 10.1080/17470218.2013.879391
   Jolliffe IT, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0202
   Kalaiah MK, 2016, J INT ADV OTOL, V12, P184, DOI 10.5152/iao.2016.2467
   Kane MJ, 2004, J EXP PSYCHOL GEN, V133, P189, DOI 10.1037/0096-3445.133.2.189
   KING J, 1991, J MEM LANG, V30, P580, DOI 10.1016/0749-596X(91)90027-H
   Kong Eun Jong, 2011, P 17 INT C PHON SCI, P1126
   Kumar AU, 2010, INT J AUDIOL, V49, P488, DOI 10.3109/14992021003645894
   Kumari B., 1972, MALAYALAM PHONETIC R
   Lee SJ, 2018, COMMUN SCI DISORD-CS, V23, P378, DOI 10.12963/csd.18492
   Lopez-Zamora M, 2012, SCI STUD READ, V16, P443, DOI 10.1080/10888438.2011.588763
   Makashay M. J, 2003, THESIS
   Mella N, 2015, MEM COGNITION, V43, P340, DOI 10.3758/s13421-014-0491-1
   MOHANAN KP, 1984, LINGUIST INQ, V15, P575
   Ou JH, 2017, ATTEN PERCEPT PSYCHO, V79, P945, DOI 10.3758/s13414-017-1283-z
   Rodd JM, 2012, CEREB CORTEX, V22, P1761, DOI 10.1093/cercor/bhr252
   Rodd JM, 2005, CEREB CORTEX, V15, P1261, DOI 10.1093/cercor/bhi009
   Ronnberg J., 1990, EUROPEAN J COGNITIVE, V2, P253, DOI [10.1080/09541449008406207, DOI 10.1080/09541449008406207]
   Shastri U, 2015, THESIS
   Shastri U, 2014, J ACOUST SOC AM, V135, P896, DOI 10.1121/1.4861350
   Tamati TN, 2013, J AM ACAD AUDIOL, V24, P616, DOI 10.3766/jaaa.24.7.10
   Tsao FM, 2006, J ACOUST SOC AM, V120, P2285, DOI 10.1121/1.2338290
   Whalen DH, 1997, J PHONETICS, V25, P501, DOI 10.1006/jpho.1997.0058
   Wilhelm O, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00433
   Wong PCM, 2007, APPL PSYCHOLINGUIST, V28, P565, DOI 10.1017/S0142716407070312
   Woods WS, 2013, J ACOUST SOC AM, V133, P4268, DOI 10.1121/1.4803859
   Zekveld AA, 2012, BRAIN LANG, V122, P103, DOI 10.1016/j.bandl.2012.05.006
NR 43
TC 0
Z9 0
U1 1
U2 1
PU KOREAN ACAD SPEECH-LANGUAGE PATHOLOGY & AUDIOLOGY
PI CHUONGNAM
PA KOREA NAZARENE UNIV, DEPT COMMUNICATION DISORDERS, CHUONGNAM, 331-718,
   SOUTH KOREA
SN 2288-1328
EI 2288-0917
J9 COMMUN SCI DISORD-CS
JI Commun. Sci. Disord.-CSD
PD MAR
PY 2019
VL 24
IS 1
BP 117
EP 128
DI 10.12963/csd.18571
PG 12
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA HT4XD
UT WOS:000464565700010
OA Other Gold
DA 2021-02-24
ER

PT J
AU Saunders, JL
   Wehr, M
AF Saunders, Jonny L.
   Wehr, Michael
TI Mice can learn phonetic categories
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH-PERCEPTION; AUDITORY-CORTEX; SOUNDS; DISCRIMINATION; RESPONSES;
   IDENTIFICATION; REPRESENTATION; FORMANT; MODEL
AB Speech is perceived as a series of relatively invariant phonemes despite extreme variability in the acoustic signal. To be perceived as nearly-identical phonemes, speech sounds that vary continuously over a range of acoustic parameters must be perceptually discretized by the auditory system. Such many-to-one mappings of undifferentiated sensory information to a finite number of discrete categories are ubiquitous in perception. Although many mechanistic models of phonetic perception have been proposed, they remain largely unconstrained by neurobiological data. Current human neurophysiological methods lack the necessary spatiotemporal resolution to provide it: speech is too fast, and the neural circuitry involved is too small. This study demonstrates that mice are capable of learning generalizable phonetic categories, and can thus serve as a model for phonetic perception. Mice learned to discriminate consonants and generalized consonant identity across novel vowel contexts and speakers, consistent with true category learning. A mouse model, given the powerful genetic and electrophysiological tools for probing neural circuits available for them, has the potential to powerfully augment a mechanistic understanding of phonetic perception. (C) 2019 Acoustical Society of America.
C1 [Wehr, Michael] Univ Oregon, Inst Neurosci, Eugene, OR 97403 USA.
   Univ Oregon, Dept Psychol, Eugene, OR 97403 USA.
RP Wehr, M (corresponding author), Univ Oregon, Inst Neurosci, Eugene, OR 97403 USA.
EM wehr@uoregon.edu
OI Saunders, Jonathan/0000-0003-0545-5066
FU National Science Foundation Graduate Research Fellowship ProgramNational
   Science Foundation (NSF) [1309047]; University of Oregon Incubating
   Interdisciplinary Initiatives award; NATIONAL INSTITUTE ON DEAFNESS AND
   OTHER COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC015828,
   R01DC015828, R01DC015828] Funding Source: NIH RePORTER
FX The authors would like to acknowledge Aldis Weible, Lucas Ott, and
   Connor O'Sullivan. This material is based upon work supported by the
   National Science Foundation Graduate Research Fellowship Program under
   Grant No. 1309047. Any opinions, findings, and conclusions or
   recommendations expressed in this material are those of the author(s)
   and do not necessarily reflect the views of the National Science
   Foundation. This work was also supported by a University of Oregon
   Incubating Interdisciplinary Initiatives award.
CR Bartlett EL, 2013, BRAIN LANG, V126, P29, DOI 10.1016/j.bandl.2013.03.003
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Bizley JK, 2013, NAT REV NEUROSCI, V14, P693, DOI 10.1038/nrn3565
   Blank H, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002577
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bornkessel-Schlesewsky I, 2015, TRENDS COGN SCI, V19, P142, DOI 10.1016/j.tics.2014.12.008
   Brenowitz EA, 1997, J NEUROBIOL, V33, P495, DOI 10.1002/(SICI)1097-4695(19971105)33:5<495::AID-NEU1>3.0.CO;2-#
   Carbonell KM, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00427
   Centanni TM, 2014, NEUROSCIENCE, V258, P292, DOI 10.1016/j.neuroscience.2013.11.030
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Dahl D. B., 2016, XTABLE EXPORT TABLES
   de Saussure Ferdinand, 1916, COURS LINGUISTIQUE G
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   DOOLING RJ, 1995, J ACOUST SOC AM, V97, P1839, DOI 10.1121/1.412058
   Dresher BE, 2008, PHONOL PHONET, V13, P11
   ELMAN JL, 1988, J ACOUST SOC AM, V83, P1615, DOI 10.1121/1.395916
   Engineer CT, 2008, NAT NEUROSCI, V11, P603, DOI 10.1038/nn.2109
   Engineer CT, 2015, BEHAV BRAIN RES, V287, P256, DOI 10.1016/j.bbr.2015.03.044
   FARNETANI E, 1990, NATO ADV SCI I D-BEH, V55, P93
   Fox NP, 2016, J EXP PSYCHOL HUMAN, V42, P730, DOI 10.1037/a0039965
   Gagnepain P., 2012, CURR BIOL, V10, P22
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   Ghazanfar AA, 1999, TRENDS COGN SCI, V3, P377, DOI 10.1016/S1364-6613(99)01379-0
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Kluender K. R, 2013, VOWEL INHERENT SPECT, P117
   Kluender K. R., 2000, J ACOUST SOC AM, V107, P2835
   KLUENDER KR, 1994, J ACOUST SOC AM, V95, P1044, DOI 10.1121/1.408466
   KLUENDER KR, 1987, SCIENCE, V237, P1195, DOI 10.1126/science.3629235
   Kronrod Y, 2016, PSYCHON B REV, V23, P1681, DOI 10.3758/s13423-016-1049-y
   KUHL PK, 1983, J ACOUST SOC AM, V73, P1003, DOI 10.1121/1.389148
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   KUHL PK, 1978, J ACOUST SOC AM, V63, P905, DOI 10.1121/1.381770
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Lieberman P., 1984, BIOL EVOLUTION LANGU, P138
   Lindblom B, 2012, J PHONETICS, V40, P1, DOI 10.1016/j.wocn.2011.09.005
   Lotto A. J., 1997, CHICAGO LINGUISTIC S, V33, P357
   Maechler M., 2017, CLUSTER CLUSTER ANAL
   MathWorks, PITCH SHIFT TIM DIL
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Ng A., 2002, ADV NEURAL INFORM PR, V28, P169
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   PATTERSON HD, 1971, BIOMETRIKA, V58, P545, DOI 10.1093/biomet/58.3.545
   Perkell J. S., 1986, INVARIANCE VARIABILI
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   R Core Team, 2018, R LANG ENV STAT COMP
   R. Team, RSTUDIO INT DEV R
   Radziwon KE, 2009, J COMP PHYSIOL A, V195, P961, DOI 10.1007/s00359-009-0472-1
   Ranasinghe KG, 2013, NEUROSCIENCE, V252, P80, DOI 10.1016/j.neuroscience.2013.08.005
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   Rutishauser U, 2015, PLOS COMPUT BIOL, V11, DOI 10.1371/journal.pcbi.1004039
   Sadagopan S, 2009, J NEUROSCI, V29, P11192, DOI 10.1523/JNEUROSCI.1286-09.2009
   Schouten B, 2003, SPEECH COMMUN, V41, P71, DOI 10.1016/S0167-6393(02)00094-8
   Steinschneider M, 2003, J ACOUST SOC AM, V114, P307, DOI 10.1121/1.1582449
   Strauss TJ, 2007, BEHAV RES METHODS, V39, P19, DOI 10.3758/BF03192840
   Sundar D.-R., BINOM BINOMIAL CONFI
   Sussman H. M., 1998, BEHAV BRAIN SCI, V21, P260
   Sussman HM, 1998, BEHAV BRAIN SCI, V21, P241, DOI 10.1017/S0140525X98001174
   Theunissen FE, 2014, NAT REV NEUROSCI, V15, P355, DOI 10.1038/nrn3731
   Wang XQ, 2005, NATURE, V435, P341, DOI 10.1038/nature03565
   WERKER JF, 1988, DEV PSYCHOL, V24, P672, DOI 10.1037/0012-1649.24.5.672
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3_1
   Wickham H, 2011, J STAT SOFTW, V40, P1, DOI 10.18637/jss.v040.i01
   Wickham H, 2007, J STAT SOFTW, V21, P1
   Wright Richard, 2004, PHONETICALLY BASED P, P34, DOI DOI 10.1017/CBO9780511486401.002
NR 70
TC 1
Z9 1
U1 1
U2 2
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD MAR
PY 2019
VL 145
IS 3
BP 1168
EP 1177
DI 10.1121/1.5091776
PG 10
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA HS3DU
UT WOS:000463743800016
PM 31067917
OA Green Published
DA 2021-02-24
ER

PT J
AU Assgari, AA
   Theodore, RM
   Stilp, CE
AF Assgari, Ashley A.
   Theodore, Rachel M.
   Stilp, Christian E.
TI Variability in talkers' fundamental frequencies shapes context effects
   in speech perception
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID RELIABLE SPECTRAL PROPERTIES; RECOGNITION; LISTENER; CATEGORIZATION;
   IDENTIFICATION; NORMALIZATION; COMPENSATION; VOICES; SOUNDS; WORDS
AB The perception of any given sound is influenced by surrounding sounds. When successive sounds differ in their spectral compositions, these differences may be perceptually magnified, resulting in spectral contrast effects (SCEs). For example, listeners are more likely to perceive /I/(low F-1) following sentences with higher F1 frequencies; listeners are also more likely to perceive /epsilon/(high F-1) following sentences with lower F1 frequencies. Previous research showed that SCEs for vowel categorization were attenuated when sentence contexts were spoken by different talkers [Assgari and Stilp. (2015). J. Acoust. Soc. Am. 138(5), 3023-3032], but the locus of this diminished contextual influence was not specified. Here, three experiments examined implications of variable talker acoustics for SCEs in the categorization of /I/and /E/. The results showed that SCEs were smaller when the mean fundamental frequency (f0) of context sentences was highly variable across talkers compared to when mean f0 was more consistent, even when talker gender was held constant. In contrast, SCE magnitudes were not influenced by variability in mean F1. These findings suggest that talker variability attenuates SCEs due to diminished consistency of f0 as a contextual influence. Connections between these results and talker normalization are considered. (C) 2019 Acoustical Society of America.
C1 [Assgari, Ashley A.; Stilp, Christian E.] Univ Louisville, Dept Psychol & Brain Sci, Louisville, KY 40292 USA.
   [Theodore, Rachel M.] Univ Connecticut, Dept Speech Language & Hearing Sci, Storrs, CT 06828 USA.
RP Stilp, CE (corresponding author), Univ Louisville, Dept Psychol & Brain Sci, Louisville, KY 40292 USA.
EM christian.stilp@louisville.edu
CR Assgari A. A, 2018, THESIS
   Assgari AA, 2015, J ACOUST SOC AM, V138, P3023, DOI 10.1121/1.4934559
   ASSMANN PF, 1982, J ACOUST SOC AM, V71, P975, DOI 10.1121/1.387579
   Bates D., 2014, R PACKAGE VERSION LME4 LINEAR MIXED EF LME4 LINEAR MIXED EF, DOI DOI 10.18637/JSS.V067.I01
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bosker HR, 2017, J MEM LANG, V94, P166, DOI 10.1016/j.jml.2016.12.002
   Bradlow AR, 1999, J ACOUST SOC AM, V106, P2074, DOI 10.1121/1.427952
   Choi JY, 2018, ATTEN PERCEPT PSYCHO, V80, P784, DOI 10.3758/s13414-017-1395-5
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   CREELMAN CD, 1957, J ACOUST SOC AM, V29, P655, DOI 10.1121/1.1909003
   Fant G., 1973, SPEECH SOUNDS FEATUR
   FOURCIN AJ, 1968, IEEE T ACOUST SPEECH, VAU16, P65, DOI 10.1109/TAU.1968.1161950
   Frazier J. F, 2019, ATTN PERCEPT PSYCHOP
   Garofolo J, 1990, PB91505065 NIST
   GEISELMAN RE, 1976, MEM COGNITION, V4, P483, DOI 10.3758/BF03213208
   GOLDINGER SD, 1991, J EXP PSYCHOL LEARN, V17, P152, DOI 10.1037/0278-7393.17.1.152
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Hillenbrand JM, 2009, ATTEN PERCEPT PSYCHO, V71, P1150, DOI 10.3758/APP.71.5.1150
   Holt LL, 2005, PSYCHOL SCI, V16, P305, DOI 10.1111/j.0956-7976.2005.01532.x
   Holt LL, 2006, J ACOUST SOC AM, V120, P2801, DOI 10.1121/1.2354071
   Huang JY, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00010
   Kluender K. R, 2013, VOWEL INHERENT SPECT, P117
   Kuznetsova A., 2013, LMERTEST TESTS RANDO
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Laing EJC, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00203
   Lotto AJ, 1998, PERCEPT PSYCHOPHYS, V60, P602, DOI 10.3758/BF03206049
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   MULLENNIX JW, 1990, PERCEPT PSYCHOPHYS, V47, P379, DOI 10.3758/BF03210878
   MULLENNIX JW, 1989, J ACOUST SOC AM, V85, P365, DOI 10.1121/1.397688
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   R Development Core Team, 2018, R LANG ENV STAT COMP
   RAND TC, 1971, J ACOUST SOC AM, V50, P139, DOI 10.1121/1.1977661
   Ryalls BO, 1997, DEV PSYCHOL, V33, P441, DOI 10.1037/0012-1649.33.3.441
   Sjerps MJ, 2018, J EXP PSYCHOL HUMAN, V44, P914, DOI 10.1037/xhp0000504
   Sjerps MJ, 2011, ATTEN PERCEPT PSYCHO, V73, P1195, DOI 10.3758/s13414-011-0096-8
   Spahr AJ, 2012, EAR HEARING, V33, P112, DOI 10.1097/AUD.0b013e31822c2549
   Stilp C. E., 2016, P M ACOUST, V26
   Stilp C. E, 2019, ATTN PERCEPT PSYCHOP
   Stilp CE, 2018, ATTEN PERCEPT PSYCHO, V80, P1300, DOI 10.3758/s13414-018-1488-9
   Stilp CE, 2017, JARO-J ASSOC RES OTO, V18, P465, DOI 10.1007/s10162-017-0615-y
   Stilp CE, 2017, J ACOUST SOC AM, V141, pEL153, DOI 10.1121/1.4974769
   Stilp CE, 2015, J ACOUST SOC AM, V137, P3466, DOI 10.1121/1.4921600
   Stilp CE, 2010, ATTEN PERCEPT PSYCHO, V72, P470, DOI 10.3758/APP.72.2.470
   Theodore RM, 2015, J ACOUST SOC AM, V138, P1068, DOI 10.1121/1.4927489
   Theodore RM, 2010, J ACOUST SOC AM, V128, P2090, DOI 10.1121/1.3467771
   WATKINS AJ, 1991, J ACOUST SOC AM, V90, P2942, DOI 10.1121/1.401769
   WATKINS AJ, 1994, J ACOUST SOC AM, V96, P1263, DOI 10.1121/1.410275
   Winn MB, 2015, J ACOUST SOC AM, V137, P1430, DOI 10.1121/1.4908308
NR 49
TC 4
Z9 3
U1 0
U2 3
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD MAR
PY 2019
VL 145
IS 3
BP 1443
EP 1454
DI 10.1121/1.5093638
PG 12
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA HS3DU
UT WOS:000463743800041
PM 31067942
DA 2021-02-24
ER

PT J
AU Krestar, ML
   McLennan, CT
AF Krestar, Maura L.
   McLennan, Conor T.
TI Responses to Semantically Neutral Words in Varying Emotional Intonations
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SPEECH-PERCEPTION; NEGATIVITY BIAS; ANGRY PROSODY; ATTENTION; BRAIN;
   ACTIVATION; MECHANISMS; STIMULI; VALENCE; AROUSAL
AB Purpose: Recent research on perception of emotionally charged material has found both an "emotionality effect" in which participants respond differently to emotionally charged stimuli relative to neutral stimuli in some cognitive-linguistic tasks and a "negativity bias" in which participants respond differently to negatively charged stimuli relative to neutral and positively charged stimuli. The current study investigated young adult listeners' bias when responding to neutral-meaning words in 2 tasks that varied attention to emotional intonation.
   Method: Half the participants completed a word identification task in which they were instructed to type a word they had heard presented binaurally through Sony stereo MDR-ZX100 headphones. The other half of the participants completed an intonation identification task in which they were instructed to use a SuperLab RB-740 button box to identify the emotional prosody of the same words over headphones. For both tasks, all auditory stimuli were semantically neutral words spoken in happy, sad, and neutral emotional intonations. Researchers measured percent correct and reaction time (RT) for each word in both tasks.
   Results: In the word identification task, when identifying semantically neutral words spoken in happy, sad, and neutral intonations, listeners' RTs to words in a sad intonation were longer than RTs to words in a happy intonation. In the intonation identification task, when identifying the emotional intonation of the same words spoken in the same emotional tones of voice, listeners' RTs to words in a sad intonation were significantly faster than those in a neutral intonation.
   Conclusions: Results demonstrate a potential attentional negativity bias for neutral words varying in emotional intonation. Such results support an attention-based theoretical account. In an intonation identification task, an advantage emerged for words in a negative (sad) intonation relative to words in a neutral intonation. Thus, current models of emotional speech should acknowledge the amount of attention to emotional content (i.e., prosody) necessary to complete a cognitive task, as it has the potential to bias processing.
C1 [Krestar, Maura L.] Texas A&M Univ Kingsville, Dept Clin Hlth Sci, Kingsville, TX 78363 USA.
   [McLennan, Conor T.] Cleveland State Univ, Language Res Lab, Dept Psychol, Cleveland, OH 44115 USA.
RP Krestar, ML (corresponding author), Texas A&M Univ Kingsville, Dept Clin Hlth Sci, Kingsville, TX 78363 USA.
EM maura.krestar@tamuk.edu
RI McLennan, Conor T/G-5061-2017
OI McLennan, Conor T/0000-0002-4770-262X
FU Cleveland State University
FX This project was carried out with support from a Dissertation Research
   Award (awarded to Maura Krestar) from Cleveland State University. The
   researchers graciously acknowledge Angel Ball, who provided important
   feedback on the current manuscript, and Sarah Dodson, who assisted with
   revisions.
CR Armony JL, 2002, NEUROPSYCHOLOGIA, V40, P817, DOI 10.1016/S0028-3932(01)00178-6
   Bertels J, 2010, ACTA PSYCHOL, V134, P264, DOI 10.1016/j.actpsy.2010.02.008
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bostanov V, 2004, PSYCHOPHYSIOLOGY, V41, P259, DOI 10.1111/j.1469-8986.2003.00142.x
   Bradley M. M., 1999, C1 U FLOR CTR RES PS
   Cacioppo JT, 1999, ANNU REV PSYCHOL, V50, P191, DOI 10.1146/annurev.psych.50.1.191
   Carretie L, 2001, J COGNITIVE NEUROSCI, V13, P1109, DOI 10.1162/089892901753294400
   Carretie L, 2009, INT J PSYCHOPHYSIOL, V71, P57, DOI 10.1016/j.ijpsycho.2008.07.006
   Carstensen LL, 2005, CURR DIR PSYCHOL SCI, V14, P117, DOI 10.1111/j.0963-7214.2005.00348.x
   Castro SL, 2010, BEHAV RES METHODS, V42, P74, DOI 10.3758/BRM.42.1.74
   Cedrus Corporation, 2006, SUPERLAB PRO 4 0
   Davidson RJ, 1999, TRENDS COGN SCI, V3, P11, DOI 10.1016/S1364-6613(98)01265-0
   Grandjean D, 2005, NAT NEUROSCI, V8, P145, DOI 10.1038/nn1392
   HANSEN CH, 1988, J PERS SOC PSYCHOL, V54, P917, DOI 10.1037/0022-3514.54.6.917
   Hein G, 2004, PSYCHOL AGING, V19, P416, DOI 10.1037/0882-7974.19.3.416
   Lane RD, 1999, NEUROPSYCHOLOGIA, V37, P989, DOI 10.1016/S0028-3932(99)00017-2
   Lang PJ, 1998, PSYCHOPHYSIOLOGY, V35, P199, DOI 10.1017/S0048577298001991
   LEVEY AB, 1975, BEHAV RES THER, V13, P221, DOI 10.1016/0005-7967(75)90026-1
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McIntosh LG, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00349
   Mitchell RLC, 2003, NEUROPSYCHOLOGIA, V41, P1410, DOI 10.1016/S0028-3932(03)00017-4
   Mogg K, 1999, COGNITION EMOTION, V13, P713, DOI 10.1080/026999399379050
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Ohman A., 2000, HDB PSYCHOPHYSIOLOGY, P533
   Pell MD, 2006, BRAIN LANG, V96, P221, DOI 10.1016/j.bandl.2005.04.007
   PRATTO F, 1991, J PERS SOC PSYCHOL, V61, P380, DOI 10.1037/0022-3514.61.3.380
   Rozin P, 2001, PERS SOC PSYCHOL REV, V5, P296, DOI 10.1207/S15327957PSPR0504_2
   Scherer Laura D, 2011, Emotion, V11, P203, DOI 10.1037/a0022588
   Sebe N, 2006, P 18 INT C PATT REC, DOI [10.1109/ICPR.2006.489, DOI 10.1109/ICPR.2006.489]
   Steiner J E, 1979, Adv Child Dev Behav, V13, P257, DOI 10.1016/S0065-2407(08)60349-3
   Taylor SF, 2000, NEUROPSYCHOLOGIA, V38, P1415, DOI 10.1016/S0028-3932(00)00032-4
   Vaish A, 2008, PSYCHOL BULL, V134, P383, DOI 10.1037/0033-2909.134.3.383
   Vuilleumier P, 2005, TRENDS COGN SCI, V9, P585, DOI 10.1016/j.tics.2005.10.011
   Vuilleumier P, 2001, NEURON, V30, P829, DOI 10.1016/S0896-6273(01)00328-2
   Williams JMG, 1996, PSYCHOL BULL, V120, P3, DOI 10.1037/0033-2909.120.1.3
   Wittfoth M, 2010, CEREB CORTEX, V20, P383, DOI 10.1093/cercor/bhp106
   Wurm LH, 1996, COGNITION EMOTION, V10, P409, DOI 10.1080/026999396380204
   Wurm LH, 2004, PSYCHOL AGING, V19, P523, DOI 10.1037/0882-7974.19.3.523
   Wurm LH, 2001, COGNITION EMOTION, V15, P831, DOI 10.1080/02699930143000086
NR 39
TC 0
Z9 0
U1 1
U2 8
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD MAR
PY 2019
VL 62
IS 3
BP 733
EP 744
DI 10.1044/2018_JSLHR-H-17-0428
PG 12
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA HQ9JK
UT WOS:000462743400019
PM 30950728
DA 2021-02-24
ER

PT J
AU Wess, JM
   Bernstein, JGW
AF Wess, Jessica M.
   Bernstein, Joshua G. W.
TI The Effect of Nonlinear Amplitude Growth on the Speech Perception
   Benefits Provided by a Single-Sided Vocoder
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SOUND SOURCE LOCALIZATION; BILATERAL COCHLEAR IMPLANTS; ANCHORED
   HEARING-AID; ENVELOPE EXPANSION; BINAURAL HEARING; SPATIAL RELEASE;
   INFORMATIONAL MASKING; TEMPORAL ENVELOPE; INTERAURAL TIME; HEAD SHADOW
AB Purpose: For listeners with single-sided deafness, a cochlear implant (CI) can improve speech understanding by giving the listener access to the ear with the better target-to-masker ratio (TMR; head shadow) or by providing interaural difference cues to facilitate the perceptual separation of concurrent talkers (squelch). CI simulations presented to listeners with normal hearing examined how these benefits could be affected by interaural differences in loudness growth in a speech-on-speech masking task.
   Method: Experiment 1 examined a target-masker spatial configuration where the vocoded ear had a poorer TMR than the nonvocoded ear. Experiment 2 examined the reverse configuration. Generic head-related transfer functions simulated free-field listening. Compression or expansion was applied independently to each vocoder channel (power-law exponents: 0.25, 0.5, 1, 1.5, or 2).
   Results: Compression reduced the benefit provided by the vocoder ear in both experiments. There was some evidence that expansion increased squelch in Experiment 1 but reduced the benefit in Experiment 2 where the vocoder ear provided a combination of head-shadow and squelch benefits.
   Conclusions: The effects of compression and expansion are interpreted in terms of envelope distortion and changes in the vocoded-ear TMR (for head shadow) or changes in perceived target-masker spatial separation (for squelch). The compression parameter is a candidate for clinical optimization to improve single-sided deafness CI outcomes.
C1 [Wess, Jessica M.; Bernstein, Joshua G. W.] Walter Reed Natl Mil Med Ctr, Natl Mil Audiol & Speech Pathol Ctr, Bethesda, MD 20889 USA.
   [Wess, Jessica M.] Univ Maryland, Neurosci & Cognit Sci Program, Dept Hearing & Speech Sci, College Pk, MD 20742 USA.
RP Bernstein, JGW (corresponding author), Walter Reed Natl Mil Med Ctr, Natl Mil Audiol & Speech Pathol Ctr, Bethesda, MD 20889 USA.
EM joshua.g.bemstein.civ@mail.mil
FU Defense Medical Research and Development Program [DM130007]
FX This study was supported by Grant DM130007 from the Defense Medical
   Research and Development Program (J.B.). We thank Sandra Gordon-Salant,
   Matthew Goupell, Jonathan Simon, Ken Grant, and Douglas Brungart for
   their helpful comments on a previous version of this article. The views
   expressed in this article are those of the authors and do not reflect
   the official policy of the Department of Army/Navy/Air Force, Department
   of Defense, or U.S. Government. The identification of specific products
   or scientific instrumentation does not constitute endorsement or implied
   endorsement on the part of the author, the Department of Defense, or any
   component agency.
CR Apoux F, 2001, HEARING RES, V153, P123, DOI 10.1016/S0378-5955(00)00265-3
   Arndt S, 2010, OTOL NEUROTOL, V31, P67, DOI 10.1097/MAO.0b013e3181c0e972
   Bernstein JGW, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518765514
   Bernstein JGW, 2017, OTOL NEUROTOL, V38, pE195, DOI 10.1097/MAO.0000000000001469
   Bernstein JGW, 2016, EAR HEARING, V37, P289, DOI 10.1097/AUD.0000000000000284
   Bernstein JGW, 2015, J ACOUST SOC AM, V137, P702, DOI 10.1121/1.4906167
   Blamey P, 2013, AUDIOL NEURO-OTOL, V18, P36, DOI 10.1159/000343189
   Bolia RS, 2000, J ACOUST SOC AM, V107, P1065, DOI 10.1121/1.428288
   Brungart DS, 2001, J ACOUST SOC AM, V110, P2527, DOI 10.1121/1.1408946
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Buechner A, 2010, OTOL NEUROTOL, V31, P1381, DOI 10.1097/MAO.0b013e3181e3d353
   Buss E, 2008, EAR HEARING, V29, P20
   CLARKSON PM, 1991, J ACOUST SOC AM, V89, P1378, DOI 10.1121/1.400538
   Culling JF, 2012, EAR HEARING, V33, P673, DOI 10.1097/AUD.0b013e3182587356
   Dorman MF, 2015, AUDIOL NEURO-OTOL, V20, P183, DOI 10.1159/000375394
   Dorman MF, 2014, EAR HEARING, V35, P633, DOI 10.1097/AUD.0000000000000057
   Erbele ID, 2015, OTOL NEUROTOL, V36, pE24, DOI 10.1097/MAO.0000000000000652
   Firszt JB, 2012, EAR HEARING, V33, P521, DOI 10.1097/AUD.0b013e31824b9dfc
   Freyman RL, 2008, J ACOUST SOC AM, V124, P1627, DOI 10.1121/1.2951964
   Freyman RL, 2001, J ACOUST SOC AM, V109, P2112, DOI 10.1121/1.1354984
   Fu QJ, 1998, J ACOUST SOC AM, V104, P2570, DOI 10.1121/1.423912
   Garadat SN, 2009, J ACOUST SOC AM, V126, P2522, DOI 10.1121/1.3238242
   Gifford RH, 2014, HEARING RES, V312, P28, DOI 10.1016/j.heares.2014.02.007
   Grantham DW, 2008, EAR HEARING, V29, P33
   Grantham DW, 2012, EAR HEARING, V33, P595, DOI 10.1097/AUD.0b013e3182503e5e
   Hansen MR, 2013, OTOL NEUROTOL, V34, P1681, DOI 10.1097/MAO.0000000000000102
   Ihlefeld A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0045296
   Kamal SM, 2012, CURR OPIN OTOLARYNGO, V20, P393, DOI 10.1097/MOO.0b013e328357a613
   Kan A, 2013, J ACOUST SOC AM, V134, P2923, DOI 10.1121/1.4820889
   Kasturi K, 2007, EAR HEARING, V28, P402, DOI 10.1097/AUD.0b013e31804793c4
   Kawano A, 1998, ACTA OTO-LARYNGOL, V118, P313
   Li N, 2009, J ACOUST SOC AM, V126, P338, DOI 10.1121/1.3133702
   Linstrom CJ, 2009, LARYNGOSCOPE, V119, P713, DOI 10.1002/lary.20164
   Litovsky RY, 2012, J AM ACAD AUDIOL, V23, P476, DOI 10.3766/jaaa.23.6.9
   Loizou PC, 1998, IEEE SIGNAL PROC MAG, V15, P101, DOI 10.1109/79.708543
   Lopez-Poveda EA, 2016, EAR HEARING, V37, pE138, DOI 10.1097/AUD.0000000000000273
   Lorenzi C, 1999, HEARING RES, V136, P131, DOI 10.1016/S0378-5955(99)00117-3
   Maslin MRD, 2013, CLIN NEUROPHYSIOL, V124, P1414, DOI 10.1016/j.clinph.2012.12.052
   McDermott HJ, 2003, J ACOUST SOC AM, V114, P2190, DOI 10.1121/1.1612488
   McDermott H, 2009, J NEURAL ENG, V6, DOI 10.1088/1741-2560/6/6/065007
   Moore B.C., 2012, INTRO PSYCHOL HEARIN
   Schleich P, 2004, EAR HEARING, V25, P197, DOI 10.1097/01.AUD.0000130792.43315.97
   STEENEKEN HJM, 1980, J ACOUST SOC AM, V67, P318, DOI 10.1121/1.384464
   van Buuren RA, 1999, J ACOUST SOC AM, V105, P2903, DOI 10.1121/1.426943
   van Hoesel R. J. M., 2012, AUDITORY PROSTHESES
   van Hoesel RJM, 2008, J ACOUST SOC AM, V124, P3861, DOI 10.1121/1.2998974
   Vermeire K, 2009, AUDIOL NEURO-OTOL, V14, P163, DOI 10.1159/000171478
   Wess JM, 2017, EAR HEARING, V38, P374, DOI 10.1097/AUD.0000000000000374
   Wierstorf H, 2011, AUDIO ENG SOC CONVEN, V130, P3
   Zeitler DM, 2015, OTOL NEUROTOL, V36, P1467, DOI 10.1097/MAO.0000000000000841
   ZENG FG, 1992, HEARING RES, V60, P231, DOI 10.1016/0378-5955(92)90024-H
   Zurek P. M., 1993, ACOUSTICAL FACTORS A, P255
NR 52
TC 2
Z9 2
U1 0
U2 2
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD MAR
PY 2019
VL 62
IS 3
BP 745
EP 757
DI 10.1044/2018_JSLHR-H-18-0001
PG 13
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA HQ9JK
UT WOS:000462743400020
PM 30950730
DA 2021-02-24
ER

PT J
AU Perszyk, DR
   Waxman, SR
AF Perszyk, Danielle R.
   Waxman, Sandra R.
TI Infants' advances in speech perception shape their earliest links
   between language and cognition
SO SCIENTIFIC REPORTS
LA English
DT Article
ID FACILITATE OBJECT CATEGORIZATION; ATTENTIONAL PREFERENCE; 4-MONTH-OLD
   INFANTS; FAMILIARITY; NOVELTY; WORDS; EXPERIENCE; DISCRIMINATION;
   EVOLUTION; NEWBORNS
AB The power of human language derives not only from the precision of its signal or the complexity of its grammar, but also from its links to cognition. Infants as young as 3 months have begun to link language and core cognitive capacities. At 3 and 4 months, this link is not exclusive to human language: listening to vocalizations of nonhuman primates also supports infant cognition. By 6 months, infants have tuned this link to human speech alone. Here we provide evidence that infants' increasing precision in speech perception shapes which signals they will link to cognition. Infants listening to German, a nonnative language that shares key rhythmic and prosodic properties with their own native language (English), successfully formed object categories. In contrast, those listening to Cantonese, a language that differs considerably in these suprasegmental properties, failed. This provides the first evidence that infants' increasingly precise perceptual tuning to the sounds of their native language sets constraints on the range of human languages they will link to cognition: infants begin to specify which human languages they will link to core cognitive capacities even before they sever the link between nonhuman primate vocalizations and cognition.
C1 [Perszyk, Danielle R.; Waxman, Sandra R.] Northwestern Univ, Evanston, IL 60208 USA.
RP Waxman, SR (corresponding author), Northwestern Univ, Evanston, IL 60208 USA.
EM s-waxman@northwestern.edu
FU EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN
   DEVELOPMENTUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R01HD083310,
   R01HD083310, R01HD083310, R01HD083310] Funding Source: NIH RePORTER;
   NICHD NIH HHSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R01 HD083310]
   Funding Source: Medline; U.S. Department of Health &amp; Human Services
   | National Institutes of Health (NIH)United States Department of Health
   & Human ServicesNational Institutes of Health (NIH) - USA [R01HD083310]
   Funding Source: Medline
CR Abboub N, 2016, BRAIN LANG, V162, P46, DOI 10.1016/j.bandl.2016.08.002
   Ackermann H, 2014, BEHAV BRAIN SCI, V37, DOI 10.1017/S0140525X1400003X
   [Anonymous], 1999, WORD PROSODIC SYSTEM
   Aslin RN, 2007, DEVELOPMENTAL SCI, V10, P48, DOI 10.1111/j.1467-7687.2007.00563.x
   Balaban MT, 1997, J EXP CHILD PSYCHOL, V64, P3, DOI 10.1006/jecp.1996.2332
   Bosch L, 1997, COGNITION, V65, P33, DOI 10.1016/S0010-0277(97)00040-1
   Chan Alice Y. W., 2000, LANG CULT CURRIC, V13, P67, DOI DOI 10.1080/07908310008666590
   Christophe A, 1998, DEVELOPMENTAL SCI, V1, P215, DOI 10.1111/1467-7687.00033
   Colombo J, 2002, CURR DIR PSYCHOL SCI, V11, P196, DOI 10.1111/1467-8721.00199
   COLOMBO J, 1983, INFANT BEHAV DEV, V6, P305, DOI 10.1016/S0163-6383(83)80039-3
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   Ferguson B, 2016, SCI REP-UK, V6, DOI 10.1038/srep25434
   Ferry AL, 2013, P NATL ACAD SCI USA, V110, P15231, DOI 10.1073/pnas.1221166110
   Ferry AL, 2010, CHILD DEV, V81, P472, DOI 10.1111/j.1467-8624.2009.01408.x
   Frick JE, 2000, INFANCY, V1, P375, DOI 10.1207/S15327078IN0103_6
   Fulkerson AL, 2007, COGNITION, V105, P218, DOI 10.1016/j.cognition.2006.09.005
   Ghazanfar AA, 2014, TRENDS COGN SCI, V18, P543, DOI 10.1016/j.tics.2014.06.004
   Ghazanfar AA, 2014, J COGNITIVE NEUROSCI, V26, P1196, DOI 10.1162/jocn_a_00575
   HUNT JM, 1970, J GENET PSYCHOL, V117, P99, DOI 10.1080/00221325.1970.10533940
   Hunter M. A., 1988, ADV INFANCY RES, V5, P69, DOI DOI 10.1037/0012-1649.19.3.338
   Kelly DJ, 2007, PSYCHOL SCI, V18, P1084, DOI 10.1111/j.1467-9280.2007.02029.x
   Kelly DJ, 2005, DEVELOPMENTAL SCI, V8, pF31, DOI 10.1111/j.1467-7687.2005.0434a.x
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2007, DEVELOPMENTAL SCI, V10, P110, DOI 10.1111/j.1467-7687.2007.00572.x
   Kuhl PK, 2014, P NATL ACAD SCI USA, V111, P11238, DOI 10.1073/pnas.1410963111
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Mampe B, 2009, CURR BIOL, V19, P1994, DOI 10.1016/j.cub.2009.09.064
   May L., 2018, DEVELOPMENTAL SCI, V21, P1
   MILLER GA, 1990, PSYCHOL SCI, V1, P7, DOI 10.1111/j.1467-9280.1990.tb00059.x
   Minagawa-Kawai Y, 2011, CEREB CORTEX, V21, P254, DOI 10.1093/cercor/bhq082
   MOON C, 1993, INFANT BEHAV DEV, V16, P495, DOI 10.1016/0163-6383(93)80007-U
   Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037/0096-1523.24.3.756
   Nazzi T, 2000, J MEM LANG, V43, P1, DOI 10.1006/jmla.2000.2698
   Owren MJ, 2011, AM J PRIMATOL, V73, P530, DOI 10.1002/ajp.20913
   Pascalis O, 2005, P NATL ACAD SCI USA, V102, P5297, DOI 10.1073/pnas.0406627102
   Pascalis O, 2002, SCIENCE, V296, P1321, DOI 10.1126/science.1070223
   Pena M, 2010, P NATL ACAD SCI USA, V107, P3823, DOI 10.1073/pnas.0914326107
   Perone S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00648
   Perszyk DR, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12522
   Perszyk DR, 2018, ANNU REV PSYCHOL, V69, P231, DOI 10.1146/annurev-psych-122216-011701
   Perszyk DR, 2016, COGNITION, V153, P175, DOI 10.1016/j.cognition.2016.05.004
   Reynolds GD, 2016, FRONT SYST NEUROSCI, V10, DOI 10.3389/fnsys.2016.00015
   Roder BJ, 2000, INFANCY, V1, P491, DOI 10.1207/S15327078IN0104_9
   Rose SA, 2004, DEV REV, V24, P74, DOI 10.1016/j.dr.2003.09.004
   Shinskey JL, 2010, DEVELOPMENTAL SCI, V13, P378, DOI 10.1111/j.1467-7687.2009.00899.x
   Shultz S, 2014, DEVELOPMENTAL SCI, V17, P766, DOI 10.1111/desc.12151
   Slater A, 2004, INFANT CHILD DEV, V13, P353, DOI 10.1002/icd.356
   UZGIRIS IC, 1970, J GENET PSYCHOL, V117, P109, DOI 10.1080/00221325.1970.10533941
   Waxman SR, 1995, COGNITIVE PSYCHOL, V29, P257, DOI 10.1006/cogp.1995.1016
   WEIZMANN F, 1971, DEV PSYCHOL, V4, P149, DOI 10.1037/h0030432
   Werker JF, 1999, ANNU REV PSYCHOL, V50, P509, DOI 10.1146/annurev.psych.50.1.509
   WETHERFORD MJ, 1973, CHILD DEV, V44, P416, DOI 10.2307/1127994
   Zangenehpour S, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004302
NR 53
TC 4
Z9 4
U1 0
U2 7
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD MAR 1
PY 2019
VL 9
AR 3293
DI 10.1038/s41598-019-39511-9
PG 6
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA HN1YW
UT WOS:000459983900099
PM 30824848
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Georgiou, GP
AF Georgiou, Georgios P.
TI Bit and beat are heard as the same: Mapping the vowel perceptual
   patterns of Greek-English bilingual children
SO LANGUAGE SCIENCES
LA English
DT Article
DE Perception; English vowels; Greek speakers; Cyprus
ID SPEECH-PERCEPTION; DISCRIMINATION; L2; ASSIMILATION; CONTRASTS;
   SPEAKERS; SYSTEMS; SPANISH; ADULTS
AB It has been previously proposed that small native vowel inventories impede the acquisition of foreign language vowels that come from larger inventories. The present study aims to investigate how the already-formed Greek phonological system is modified after the perception of the English vowels in a non-naturalistic environment and to what extent Greek speakers are able to discriminate challenging English vowel contrasts. Also, it aims to examine if learning experience enhances sensitivity to acoustical information of the foreign language vowels. The study relies on the theoretical framework of the Perceptual Assimilation Model-Second Language (PAM-L2). For developing predictions about the perception of the English vowels by Greek speakers, the vowel spaces of both Greek and English native speakers were investigated; 3 native speakers of Greek and 3 native speakers of English produced vowels in their native language. 26 Greek learners of English as a foreign language in Cyprus with an age that varied from 8 to 12 years participated in the perceptual study. Learners were divided into two groups according to their proficiency level in English. The participants took an identification test in order to determine how English vowels were assimilated to the listeners' native phonological categories and then they were tested in an AXB discrimination task in order to investigate to what extent they are able to discriminate English vowel contrasts. The results showed that several pairs of two or more English vowels were assimilated to a single Greek phonological category. Furthermore, the discrimination test showed poor to moderate discrimination accuracy for both groups regarding the English vowel contrasts, yet differences in the discrimination accuracy of the contrasts between the novice and the more advanced group of learners were minimal; only the English/e/-/3:/contrast was discriminated slightly better by the advanced learners. Thus, learners with a higher proficiency level did not generally perceive the English vowels better than learners with a lower proficiency level, signifying that perception of foreign language vowels is not merely a matter of amount of exposure to the foreign stimuli. Conclusions are drawn about the interference of native Greek with the learning of English vowels and the acquisition of the foreign language stimuli in a classroom environment. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Georgiou, Georgios P.] RUDN Univ, Dept Gen & Russian Linguist, Moscow, Russia.
   [Georgiou, Georgios P.] Sotiriou Tsangari 3C, Oroklini, Larnaca, Cyprus.
RP Georgiou, GP (corresponding author), RUDN Univ, Dept Gen & Russian Linguist, Moscow, Russia.; Georgiou, GP (corresponding author), Sotiriou Tsangari 3C, Oroklini, Larnaca, Cyprus.
EM georgiou.georgos@hotmail.com
RI Georgiou, Georgios/AAN-5899-2020
OI Georgiou, Georgios/0000-0002-7192-2649
CR Al Mahmoud MS, 2013, STUD SECOND LANG LE, V3, P261
   Al-Abdely A. A., 2016, ASEAN J TEACH LEARN, V8, P1
   Alispahic S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00052
   Antoniou M, 2010, THESIS
   Antoniou M, 2012, J PHONETICS, V40, P582, DOI 10.1016/j.wocn.2012.05.005
   Arvaniti A, 2007, J GREEK LINGUIST, V8, P97, DOI 10.1075/jgl.8.08arv
   Best C., 1995, SPEECH PERCEPTION LI, P171
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2009, PRAAT DOING PHONETIC
   Bohn O.-S., 1995, SPEECH PERCEPTION LI, P279
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Escudero P, 2004, STUD SECOND LANG ACQ, V26, P551, DOI 10.1017/S0272226310400021
   ESCUDERO P., 2005, THESIS, P348
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2001, STUDIES 2 LANGUAGE A, V23, P527
   Flege J.E., 2005, ORIGINS DEV SPEECH L
   Flege James, 2002, INTEGRATED VIEW LANG, P217
   Flege JE, 1997, J PHONETICS, V25, P169, DOI 10.1006/jpho.1996.0040
   FLEGE JE, 1995, SPEECH COMMUN, V16, P1, DOI 10.1016/0167-6393(94)00044-B
   FLEGE JE, 1992, J ACOUST SOC AM, V91, P370, DOI 10.1121/1.402780
   Flege JE, 1999, J ACOUST SOC AM, V106, P2973, DOI 10.1121/1.428116
   Georgiou G. P., 2018, THESIS
   Georgiou GP, 2019, J MULTILING MULTICUL, V40, P538, DOI 10.1080/01434632.2018.1539090
   Georgiou GP, 2018, SPEECH COMMUN, V102, P68, DOI 10.1016/j.specom.2018.07.003
   Guion SG, 2000, J ACOUST SOC AM, V107, P2711, DOI 10.1121/1.428657
   Iverson P, 2007, J ACOUST SOC AM, V122, P2842, DOI 10.1121/1.2783198
   Iverson P, 2009, J ACOUST SOC AM, V126, P866, DOI 10.1121/1.3148196
   Karakal A., 2012, HUMANISING LANG TEAC, V14
   Kartushina N., 2013, P INTERSPEECH, V14, P2118
   Kyprianou M., 2007, P PHON TEACH LEARN C
   Kyprianou M., 2015, THESIS
   Lengeris A., 2009, THESIS
   Lengeris A, 2009, PHONETICA, V66, P169, DOI 10.1159/000235659
   Maxwell O, 2015, P 18 INT C PHON SCI, P1
   Morrison G. S., 2003, P 15 INT C PHON SCI, V2003, P1533
   Morrison G. S., 2002, THESIS
   Pavlou P., 1996, P 16 M DEP LING AUT, P588
   Piske T, 2002, PHONETICA, V59, P49, DOI 10.1159/000056205
   Piske T, 2001, J PHONETICS, V29, P191, DOI 10.1006/jpho.2001.0134
   POLKA L, 1995, J ACOUST SOC AM, V97, P1286, DOI 10.1121/1.412170
   Roach P., 2004, J INT PHON ASSOC, V34, P239, DOI DOI 10.1017/S0025100304001768
   Romig S., 2013, THESIS
   Sakai M., 2016, THESIS
   SNOW C, 1987, SENSITIVE PERIODS DE, P183
   Themistocleous C, 2017, PHONETICA, V74, P157, DOI 10.1159/000450554
   Tyler MD, 2014, PHONETICA, V71, P4, DOI 10.1159/000356237
   Yazgin N., 2007, ROLE ENGLISH LANGUAG
   Zhang A., 2015, P 18 INT C PHON SCI
NR 50
TC 6
Z9 6
U1 0
U2 2
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0388-0001
EI 1873-5746
J9 LANG SCI
JI Lang. Sci.
PD MAR
PY 2019
VL 72
BP 1
EP 12
DI 10.1016/j.langsci.2018.12.001
PG 12
WC Linguistics; Language & Linguistics
SC Linguistics
GA HQ0UR
UT WOS:000462111000001
DA 2021-02-24
ER

PT J
AU Shport, IA
AF Shport, Irina A.
TI Perception of Vietnamese back vowels contrasting in rounding by English
   listeners
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Rounding; Back vowels; Vietnamese; Cross-language associations; Vowel
   discrimination; Perceptual Assimilation Model; Natural Referent Vowel
   framework
ID DISCRIMINATION; ASSIMILATION; FRENCH; IDENTIFICATION; ASYMMETRIES;
   SIMILARITY; CONTEXT
AB The perception of back vowels contrasting in rounding has not previously been examined in major theoretical frameworks of cross-language speech perception. In two experiments, Southern U.S. English speakers naive to the contrast categorized the Vietnamese vowels [u o w r] in terms of their native vowel categories and identified oddball vowels in triads representing the contrasts [u]-[o], [w]-[u], [w]-[r], and [o]-[r]. The relationship between vowel categorization and discrimination was more accurately predicted when predominant and secondary categorization patterns were taken into account. Group results showed that Vietnamese [r] and [u o] were perceived as being most similar to English /<^>/ and /o(u)/, respectively, whereas [w] did not have a predominant categorization. Discrimination was not significantly more accurate in vowel pairs contrasting in rounding than in vowel pairs contrasting in height. It was more accurate, however, in less-to-more peripheral vowel presentation order than in the opposite direction. This asymmetry was even observed in the [o]-[r] pair in which each member assimilated to a different native category. Collectively, the findings suggest that multiple-category membership and individual variability among listeners are to be considered in vowel perception. Acoustic-phonetic similarity between vowels may be a better predictor than the category membership in naive listeners. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Shport, Irina A.] Louisiana State Univ, Dept English, Baton Rouge, LA 70803 USA.
RP Shport, IA (corresponding author), Louisiana State Univ, Dept English, Baton Rouge, LA 70803 USA.
EM ishport@lsu.edu
FU College of Humanities & Social Sciences Funding, Louisiana State
   University, United States
FX This research was supported by a 2015 Manship Summer Research Award from
   the College of Humanities & Social Sciences Funding, Louisiana State
   University, United States.
CR Best C., 1995, SPEECH PERCEPTION LI, P171
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bohn O.-S, 2018, HDB PSYCHOLINGUISTIC, P213, DOI [10.1002/9781118829516, DOI 10.1002/9781118829516]
   Chladkova K, 2011, J ACOUST SOC AM, V130, pEL186, DOI 10.1121/1.3629135
   Chung H, 2017, J ACOUST SOC AM, V142, P2681, DOI [10.1121/1.5014777, DOI 10.1121/1.5014777]
   Clopper CG, 2005, J ACOUST SOC AM, V118, P1661, DOI 10.1121/1.2000774
   Cruttenden Alan, 2014, GIMSONS PRONUNCIATIO
   de Jong KJ, 2009, LANG LEARN, V59, P1, DOI 10.1111/j.1467-9922.2009.00499.x
   Escudero P, 2004, STUD SECOND LANG ACQ, V26, P551, DOI 10.1017/S0272226310400021
   Escudero P, 2012, J PHONETICS, V40, P280, DOI 10.1016/j.wocn.2011.11.004
   Escudero P, 2009, J PHONETICS, V37, P452, DOI 10.1016/j.wocn.2009.07.006
   Ettlinger M, 2009, PHONETICA, V66, P222, DOI 10.1159/000298584
   Flege J. E., 2003, ISSUES CLIN LINGUIST, P19
   Fridland V, 2014, J ACOUST SOC AM, V136, P341, DOI 10.1121/1.4883599
   GOTTFRIED TL, 1984, J PHONETICS, V12, P91, DOI 10.1016/S0095-4470(19)30858-7
   Harnsberger JD, 2001, J ACOUST SOC AM, V110, P489, DOI 10.1121/1.1371758
   IBM Corp, 2016, IBM SPSS STAT MAC VE
   Jacewicz E, 2012, J ACOUST SOC AM, V131, P1413, DOI 10.1121/1.3676603
   Jacewicz E, 2011, LANG VAR CHANGE, V23, P45, DOI 10.1017/S0954394510000219
   Kirby JP, 2011, J INT PHON ASSOC, V41, P381, DOI 10.1017/S0025100311000181
   Labov W., 2006, ATLAS N AM ENGLISH P
   Ladefoged P., 2015, COURSE PHONETICS
   Levy ES, 2009, J ACOUST SOC AM, V126, P2670, DOI 10.1121/1.3224715
   Lisker L., 1988, J ACOUSTICAL SOC S1, V83, pS83
   MacMillan N. A., 2005, DETECTION THEORY USE
   Maddieson Ian, 2013, WORLD ATLAS LANGUAGE
   NEAREY TM, 1986, J ACOUST SOC AM, V80, P1297, DOI 10.1121/1.394433
   Nishi K, 2008, J ACOUST SOC AM, V124, P576, DOI 10.1121/1.2931949
   Polka L, 2003, SPEECH COMMUN, V41, P221, DOI 10.1016/S0167-6393(02)00105-X
   Polka L, 2011, J PHONETICS, V39, P467, DOI 10.1016/j.wocn.2010.08.007
   Schwartz JL, 2005, SPEECH COMMUN, V45, P425, DOI 10.1016/j.specom.2004.12.001
   Stevens Kenneth N., 1972, HUMAN COMMUNICATION, P51
   TRAUNMULLER H, 1990, J ACOUST SOC AM, V88, P97, DOI 10.1121/1.399849
   Tyler MD, 2014, PHONETICA, V71, P4, DOI 10.1159/000356237
   Williams D, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01065
   Yu Alan C. L., 2010, LAB PHONOLOGY, V10, P151, DOI DOI 10.1515/9783110224917.2.151
NR 36
TC 1
Z9 1
U1 1
U2 1
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD MAR
PY 2019
VL 73
BP 8
EP 23
DI 10.1016/j.wocn.2018.12.003
PG 16
WC Linguistics; Language & Linguistics
SC Linguistics
GA HP1FZ
UT WOS:000461412100002
DA 2021-02-24
ER

PT J
AU Kan, RTY
   Schmid, MS
AF Kan, Rachel T. Y.
   Schmid, Monika S.
TI Development of tonal discrimination in young heritage speakers of
   Cantonese
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Heritage language; Cantonese; Tonal acquisition; Bilingual speech
   perception; Perceptual Assimilation Model for Suprasegmentals; L2
   Intonation Learning theory
ID MANDARIN CHINESE TONES; LEXICAL TONE; PERCEPTUAL ASSIMILATION; PHONETIC
   PERCEPTION; SPEECH-PERCEPTION; LANGUAGE; ACQUISITION; ENGLISH;
   LISTENERS; 1ST
AB This study uses the Perceptual Assimilation Model for Suprasegmentals (PAM-S) (So & Best, 2008, 2010), supported by the assumptions of the L2 Intonation Learning theory (LILt, Mennen, 2015), to investigate how young heritage speakers of Cantonese living in the United States acquired Cantonese tones. Sixty-seven heritage speakers, aged 5-11, were tested on their perception of Cantonese tonal contrasts using an ABX discrimination task. They were compared to 64 peers aged 5-12 in Hong Kong, where Cantonese is spoken as the majority language but English is also acquired from a young age. Two pairs of tones were tested: Tones 2 (mid rising) and 5 (low rising), which have similar pitch heights and contours, and Tones 1 (high level) and 4 (low falling), which have a larger phonetic contrast. As predicted, the heritage speakers were more accurate in discriminating between the more distinct pair of tones than between the more similar pair. They also scored lower than their peers from Hong Kong in both contrast conditions. Age of testing predicted accuracy for both groups, and Chinese literacy also had a significant effect for the heritage speakers. The potential lack of the Tone 2-5 contrast in the heritage speakers' input is discussed as an explanation for these findings. This study illustrates the divergence in heritage speakers' phonological development compared to majority language speakers, and shows the relevance of the PAM-S and LILt to the heritage language context. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Kan, Rachel T. Y.; Schmid, Monika S.] Univ Essex, Wivenhoe Pk, Colchester C04 3SQ, Essex, England.
RP Kan, RTY (corresponding author), Educ Univ Hong Kong, Tai Po, 10 Lo Ping Rd, Hong Kong, Peoples R China.
EM rtykan@eduhk.hk
OI Kan, Rachel/0000-0003-3893-4549
CR Ahn S, 2017, LANG LEARN, V67, P694, DOI 10.1111/lang.12252
   Au TKF, 2002, PSYCHOL SCI, V13, P238, DOI 10.1111/1467-9280.00444
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bauer R., 1997, MODERN CANTONESE PHO
   Bauer R. S, 1998, STUDIES CANTONESE LI, P1
   Bauer R. S., 2003, LANG VAR CHANGE, V15, P211, DOI DOI 10.1017/S0954394503152039
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best C. T, 1993, SR114 HASK LAB STAT, P31
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Bijeljac-Babic R, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030843
   Boomershine A, 2013, P 15 LING S, P103
   Bosch L, 2000, EUR J COGN PSYCHOL, V12, P189, DOI 10.1080/09541446.2000.10590222
   Bowles AR, 2016, LANG LEARN, V66, P774, DOI 10.1111/lang.12159
   Bylund E, 2012, STUD SECOND LANG ACQ, V34, P215, DOI 10.1017/S0272263112000034
   Cabo DPY, 2012, APPL LINGUIST, V33, P450, DOI 10.1093/applin/ams037
   Cantonese Pronunciation Electronic Dictionary Team (Research Institute for the Humanities Chinese University of Hong Kong, 1999, CHIN TALK SYLL CANT
   Chang Charles, 2016, HERITAGE LANGUAGE J, V13, P134
   Chang CB, 2016, BILING-LANG COGN, V19, P791, DOI 10.1017/S1366728914000261
   Chang CB, 2015, J ACOUST SOC AM, V138, P3703, DOI 10.1121/1.4937612
   Chang CB, 2011, J ACOUST SOC AM, V129, P3964, DOI 10.1121/1.3569736
   Chao Y. R., 1947, CANTONESE PRIMER
   Ching Y. C., 1984, LANGUAGE LEARNING CO, V3, P317
   Choi JY, 2017, P NATL ACAD SCI USA, V114, P7307, DOI 10.1073/pnas.1706405114
   Ciocca V., 2003, J MULTILINGUAL COMMU, V1, P141, DOI [10.1080/1476967031000090971, DOI 10.1080/1476967031000090971]
   De Leeuw E, 2018, BILING-LANG COGN, V21, P278, DOI 10.1017/S1366728917000025
   Fishman Joshua, 2001, HERITAGE LANGUAGES A, P81
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2007, LAB PHONOLOGY, P353
   FLEGE JE, 1995, SPEECH COMMUN, V16, P1, DOI 10.1016/0167-6393(94)00044-B
   Flege JE, 2003, SPEECH COMMUN, V40, P467, DOI 10.1016/S0167-6393(02)00128-0
   Flores C., 2016, HERITAGE LANGUAGE J, V13, P161, DOI DOI 10.1177/
   Fok-Chan Y.Y, 1974, PERCEPTUAL STUDY TON
   Francis AL, 2008, J PHONETICS, V36, P268, DOI 10.1016/j.wocn.2007.06.005
   GANDOUR J, 1983, J PHONETICS, V11, P149, DOI 10.1016/S0095-4470(19)30813-7
   Gass S. M., 2011, MODELING BILINGUALIS, P59, DOI DOI 10.1075/SIBIL.43.06GAS
   Gathercole SE, 1998, J CHILD PSYCHOL PSYC, V39, P3, DOI 10.1111/1469-7610.00301
   GODSON L, 2004, HERITAGE LANGUAGE J, V2, P44, DOI DOI 10.1121/1.3569736
   HAKUTA K, 1992, APPL LINGUIST, V13, P72, DOI 10.1093/applin/13.1.72
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Hao YC, 2012, J PHONETICS, V40, P269, DOI 10.1016/j.wocn.2011.11.001
   HKSAR Education Bureau, 2008, HONG KONG CHIN LEX L
   Hothorn T, 2008, BIOMETRICAL J, V50, P346, DOI 10.1002/bimj.200810425
   JEON M, 2001, WORKING PAPERS ED LI, V17, P83
   Jusczyk PW, 1999, COGNITIVE PSYCHOL, V39, P159, DOI 10.1006/cogp.1999.0716
   Kei J., 2002, ASIA PACIFIC J SPEEC, V7, P25, DOI DOI 10.1179/136132802805576535
   Kim JJ, 2016, THESIS
   Knightly LM, 2003, J ACOUST SOC AM, V114, P465, DOI 10.1121/1.1577560
   KUHL PK, 1994, CURR OPIN NEUROBIOL, V4, P812, DOI 10.1016/0959-4388(94)90128-7
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   KUHL PK, 1985, NEONATE COGNITION BL, P231
   Law C., 2006, THESIS
   Law N. C. W., 2006, INT J BILINGUAL, V10, P405, DOI DOI 10.1177/13670069060100040201
   Lee J. L, 2015, PYCANTONESE CANTONES
   Lee KYS, 2015, INT J SPEECH-LANG PA, V17, P53, DOI 10.3109/17549507.2014.898096
   Lee T. H. T, 1996, 199194 RGC
   Lee-Ellis S., 2012, THESIS
   Lefcheck JS, 2016, METHODS ECOL EVOL, V7, P573, DOI 10.1111/2041-210X.12512
   Leung MT, 2004, BEHAV RES METH INS C, V36, P500, DOI 10.3758/BF03195596
   LI CN, 1977, J CHILD LANG, V4, P185, DOI 10.1017/S0305000900001598
   Li XX, 2017, BILING-LANG COGN, V20, P549, DOI 10.1017/S1366728916000195
   Luke K. K, 2015, J CHINESE LINGUISTIC, V25, P309
   Lukyanchenko A, 2011, PROC ANN BUCLD, P414
   Ma JKY, 2006, J ACOUST SOC AM, V120, P3978, DOI 10.1121/1.2363927
   Mathot S, 2012, BEHAV RES METHODS, V44, P314, DOI 10.3758/s13428-011-0168-7
   Matthews S., 2001, CANTONESE COMPREHENS
   Mennen I., 2015, PROSODY LANGUAGE CON, P171, DOI [10.1007/978-3-662-45168-7_9, DOI 10.1007/978-3-662-45168-7_9]
   Mok  P.P.K., 2010, P SPEECH PROS, P1
   Mok PPK, 2013, LANG VAR CHANGE, V25, P341, DOI 10.1017/S0954394513000161
   Montrul S., 2008, INCOMPLETE ACQUISTIO
   Montrul S., 2016, ACQUISITION HERITAGE
   Munro MJ, 1996, APPL PSYCHOLINGUIST, V17, P313, DOI 10.1017/S0142716400007967
   Nagy N, 2015, LINGUA, V164, P309, DOI 10.1016/j.lingua.2014.04.012
   Oh JS, 2010, J CHILD LANG, V37, P1123, DOI 10.1017/S0305000909990286
   Oh JS, 2003, COGNITION, V86, pB53, DOI 10.1016/S0010-0277(02)00175-0
   Ou J., 2012, THESIS
   Pallier C, 2003, CEREB CORTEX, V13, P155, DOI 10.1093/cercor/13.2.155
   Pallier C., 2007, LANGUAGE ATTRITION T, P155, DOI DOI 10.1075/SIBIL.33.11PAL
   Polinsky M, 2011, STUD SECOND LANG ACQ, V33, P305, DOI 10.1017/S027226311000077X
   Polinsky M, 2007, LANG LINGUIST COMPAS, V1, DOI 10.1111/j.1749-818x.2007.00022.x
   R Core Team, 2016, R LANG ENV STAT COMP
   Rao R., 2015, HERITAGE LANGUAGE J, V12, P48, DOI DOI 10.1093/APPLIN/AMR040
   Reid A, 2015, ATTEN PERCEPT PSYCHO, V77, P571, DOI 10.3758/s13414-014-0791-3
   Rinke E, 2014, BILING-LANG COGN, V17, P681, DOI 10.1017/S136672891300076X
   Ronquest R. E, 2013, SEL P 15 HISP LING S, P171
   Rothman J, 2009, INT J BILINGUAL, V13, P155, DOI 10.1177/1367006909339814
   Shi RS, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01117
   Shin SJ, 2010, J LANG IDENTITY EDUC, V9, P203, DOI 10.1080/15348458.2010.486277
   Singh L, 2014, DEVELOPMENTAL SCI, V17, P94, DOI 10.1111/desc.12097
   So CK, 2012, STUD TYPOL, V12, P55
   So CK, 2014, STUD SECOND LANG ACQ, V36, P195, DOI 10.1017/S0272263114000047
   So CK, 2011, POZ STUD CONTEMP LIN, V47, P133, DOI 10.2478/psicl-2011-0011
   So CK, 2010, LANG SPEECH, V53, P273, DOI 10.1177/0023830909357156
   So CK, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1120
   So K. L. C., 2000, THESIS
   So L. K. H., 1996, CURRENT ISSUES LANGU, V3, P186, DOI DOI 10.1080/
   So LKH, 1995, J CHILD LANG, V22, P473, DOI 10.1017/S0305000900009922
   Soo R, 2017, P 43 ANN M BERK LING, V2, P47
   Stoehr A., 2017, BILINGUALISM LANGUAG
   Tsao F.-M., 2008, CHINESE J PSYCHOL, V50, P111, DOI [10.6129/CJP.2008.5002.01, DOI 10.6129/CJP.2008.5002.01]
   Tse A. C -Y., 1991, THESIS
   Tse H., 2016, ASIA PACIFIC LANGUAG, V2, P124, DOI [10.1075/aplv.2.2.02tse, DOI 10.1075/APLV.2.2.02TSE]
   Tse J. K.-P., 1973, THESIS
   TSE JKP, 1978, J CHILD LANG, V5, P191, DOI 10.1017/S0305000900007418
   Tse S.-M, 1982, THESIS
   Unsworth S, 2013, BILING-LANG COGN, V16, P86, DOI 10.1017/S1366728912000284
   Ventureyra VAG, 2004, STUD BILINGUAL, V28, P207
   Ventureyra VAG, 2004, J NEUROLINGUIST, V17, P79, DOI 10.1016/S0911-6044(03)00053-8
   Wang Y, 2004, APPL PSYCHOLINGUIST, V25, P449, DOI 10.1017/S0142716404001213
   Wayland RP, 2004, LANG LEARN, V54, P681, DOI 10.1111/j.1467-9922.2004.00283.x
   Werker JF, 2009, PHILOS T R SOC B, V364, P3649, DOI 10.1098/rstb.2009.0105
   Wong PS, 2005, J SPEECH LANG HEAR R, V48, P1065, DOI 10.1044/1092-4388(2005/074)
   Wong PS, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01450
   Wong P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182337
   Wong P, 2013, J ACOUST SOC AM, V133, P434, DOI 10.1121/1.4768883
   Wong P, 2012, J SPEECH LANG HEAR R, V55, P1423, DOI 10.1044/1092-4388(2012/11-0273)
   Wu W., 2006, COMP ANAL PHONETICS
   Xu BR, 2011, P 17 INT C PHON SCI, P2173, DOI DOI 10.1111/J.1467-9922.2004.00283.X
   Yang B., 2015, PERCEPTION PRODUCTIO
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   Zhang CC, 2012, J ACOUST SOC AM, V132, P1088, DOI 10.1121/1.4731470
   Zhang J, 2018, VAR CHANG CHIN
   Zhou WP, 2015, THESIS
NR 122
TC 6
Z9 6
U1 1
U2 5
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD MAR
PY 2019
VL 73
BP 40
EP 54
DI 10.1016/j.wocn.2018.12.004
PG 15
WC Linguistics; Language & Linguistics
SC Linguistics
GA HP1FZ
UT WOS:000461412100004
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Dmitrieva, O
AF Dmitrieva, Olga
TI Transferring perceptual cue-weighting from second language into first
   language: Cues to voicing in Russian speakers of English
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Russian; American English; Stop voicing; Vowel duration; Bilingual
   speech perception; Bilingual cue weighting
ID PRECEDING VOWEL DURATION; WORD-FINAL OBSTRUENTS; CLOSURE DURATION;
   SELECTIVE ATTENTION; NATIVE-LANGUAGE; CROSS-LANGUAGE; ACOUSTIC CUES;
   TEMPORAL CUES; CONTRAST; SPANISH
AB Does second language experience affect first language perception? The present paper addresses this question in a study of bilingual cue weighting with a focus on perceptual cues that are of markedly different importance for the corresponding monolingual groups. The study investigates the use of vowel duration and glottal pulsing duration as cues to stop voicing by adult Russian speakers of English, long-term residents of the USA, (n = 37, average age 38.8 years), as well as a control group of monolingual Russians, recruited and tested in Russia, (n = 34, average age 26.1 years) and a control group of monolingual English speakers, recruited and tested in the USA, (n = 34, average age 21.7 years). Participants took part in a binary-choice voicing identification experiment using resynthe-sized real-word stimuli recorded by native speakers of each language. The stimuli varied orthogonally in terms of preceding vowel duration and duration of glottal pulsing during stop closure. Results demonstrate that monolingual English participants assigned a greater perceptual weight to vowel duration and a lesser perceptual weight to glottal pulsing than monolingual Russian participants. Bilinguals also used different cue weighting depending on the language mode. Bilinguals' cue weighting in English mode was not statistically different from that of monolingual English participants. Bilinguals' cue weighting in Russian mode showed an increased reliance on vowel duration and a decreased reliance on glottal pulsing, compared to monolingual Russians, indicating the influence of English. These findings demonstrate that second language experience affects cue weighting patterns in bilinguals' first language. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Dmitrieva, Olga] Purdue Univ, W Lafayette, IN 47907 USA.
RP Dmitrieva, O (corresponding author), Purdue Univ, W Lafayette, IN 47907 USA.
EM odmitrie@purdue.edu
OI Dmitrieva, Olga/0000-0003-0117-3539
FU Purdue University Research Foundation
FX I would like to thank Alexander Francis and Charles Chang for their
   helpful comments on the earlier versions of this work. Statistical
   analysis presented in the paper was implemented in consultation with
   Prof. Bruce Craig, Purdue Department of Statistics, whose expert
   assistance was appreciated most sincerely. I am very grateful to Suzy
   Ahn for assistance in developing an equivalent analysis in R (R Core
   Team, 2013). I am deeply thankful to Yulia Nigmatulina for generous and
   competent assistance with data collection in Saint-Petersburg, Russia.
   Many thanks also go to Jenna Conklin who was extremely helpful during
   data collection at Purdue University. I would like to thank Taehong Cho,
   Chiara Celata, Esther de Leeuw, and three anonymous reviewers for their
   contributions to the improvement of this paper. The research reported
   here was supported by a summer faculty grant from the Purdue University
   Research Foundation.
CR Abramson A. S., 1985, PHONETIC LINGUISTICS, P25
   Abramson AS, 2017, J PHONETICS, V63, P75, DOI 10.1016/j.wocn.2017.05.002
   [Anonymous], R LANG ENV STAT COMP
   Antoniou M, 2012, J PHONETICS, V40, P582, DOI 10.1016/j.wocn.2012.05.005
   Antoniou M, 2011, J PHONETICS, V39, P558, DOI 10.1016/j.wocn.2011.03.001
   Baker W, 2005, LANG SPEECH, V48, P1, DOI 10.1177/00238309050480010101
   Bang HY, 2018, J PHONETICS, V66, P120, DOI 10.1016/j.wocn.2017.09.005
   Beckman J, 2013, J LINGUIST, V49, P259, DOI 10.1017/S0022226712000424
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2018, PRAAT DOING PHONETIC
   Broersma M, 2005, J ACOUST SOC AM, V117, P3890, DOI 10.1121/1.1906060
   Broersma M, 2010, J ACOUST SOC AM, V127, P1636, DOI 10.1121/1.3292996
   CARAMAZZA A, 1973, J ACOUST SOC AM, V54, P421, DOI 10.1121/1.1913594
   Chang CB, 2018, J PHONETICS, V68, P85, DOI 10.1016/j.wocn.2018.03.003
   Chang CB, 2016, BILING-LANG COGN, V19, P791, DOI 10.1017/S1366728914000261
   Dalal DK, 2012, ORGAN RES METHODS, V15, P339, DOI 10.1177/1094428111430540
   Davidson L, 2016, J PHONETICS, V54, P35, DOI 10.1016/j.wocn.2015.09.003
   de Jong K, 2004, J PHONETICS, V32, P493, DOI 10.1016/j.wocn.2004.05.002
   De Leeuw E, 2010, BILING-LANG COGN, V13, P33, DOI 10.1017/S1366728909990289
   DENES P, 1955, J ACOUST SOC AM, V27, P761, DOI 10.1121/1.1908020
   Dmitrieva O, 2010, J PHONETICS, V38, P483, DOI 10.1016/j.wocn.2010.06.001
   Docherty G., 1992, TIMING VOICING BRIT
   ELMAN JL, 1977, J ACOUST SOC AM, V62, P971, DOI 10.1121/1.381591
   Enomoto K., 1994, EDINBURGH WORKING PA, V5, P15
   Escudero P, 2009, J PHONETICS, V37, P452, DOI 10.1016/j.wocn.2009.07.006
   Eun-Jong Kong, 2013, [Phonetics and Speech Sciences, 말소리와 음성과학], V5, P81, DOI 10.13064/KSSS.2013.5.4.081
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege J. E., 2001, STUDIES 2 LANGUAGE A, V23, P527
   Flege JE, 2009, SECOND LANG ACQUIS, V35, P175
   Flege JE, 2003, SPEECH COMMUN, V40, P467, DOI 10.1016/S0167-6393(02)00128-0
   Flege JE, 2002, APPL PSYCHOLINGUIST, V23, P567, DOI 10.1017/S0142716402004046
   FLEGE JE, 1982, J PHONETICS, V10, P177, DOI 10.1016/S0095-4470(19)30956-8
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   FLEGE JE, 1993, J ACOUST SOC AM, V93, P1589, DOI 10.1121/1.406818
   FLEGE JE, 1987, J PHONETICS, V15, P67, DOI 10.1016/S0095-4470(19)30538-8
   FLEGE JE, 1986, J ACOUST SOC AM, V79, P508, DOI 10.1121/1.393538
   Fowler CA, 2008, J PHONETICS, V36, P649, DOI 10.1016/j.wocn.2008.04.001
   Francis AL, 2002, J EXP PSYCHOL HUMAN, V28, P349, DOI 10.1037//0096-1523.28.2.349
   Francis AL, 2008, J ACOUST SOC AM, V124, P1234, DOI 10.1121/1.2945161
   Garcia-Sierra A, 2009, SPEECH COMMUN, V51, P369, DOI 10.1016/j.specom.2008.11.005
   Gilichinskaya YD, 2010, J ACOUST SOC AM, V128, pEL80, DOI 10.1121/1.3462988
   Gonzales K, 2013, PSYCHOL SCI, V24, P2135, DOI 10.1177/0956797613486485
   HAZAN VL, 1993, LANG SPEECH, V36, P17, DOI 10.1177/002383099303600102
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   HILLENBRAND J, 1984, J ACOUST SOC AM, V76, P18, DOI 10.1121/1.391094
   Hillenbrand JM, 2000, J ACOUST SOC AM, V108, P3013, DOI 10.1121/1.1323463
   HOGAN JT, 1980, J ACOUST SOC AM, V67, P1764, DOI 10.1121/1.384304
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   HOUSE AS, 1953, J ACOUST SOC AM, V25, P105, DOI 10.1121/1.1906982
   HOUSE AS, 1961, J ACOUST SOC AM, V33, P1174, DOI 10.1121/1.1908941
   Idemaru K, 2013, J ACOUST SOC AM, V133, P4232, DOI 10.1121/1.4802905
   Idemaru K, 2012, J ACOUST SOC AM, V132, P3950, DOI 10.1121/1.4765076
   Idemaru K, 2011, J EXP PSYCHOL HUMAN, V37, P1939, DOI 10.1037/a0025641
   Iverson Gregory K., 2003, PHONOLOGY, V20, P43, DOI DOI 10.1017/S0952675703004469
   Iverson P, 2003, COGNITION, V87, pB47, DOI 10.1016/S0010-0277(02)00198-1
   IVERSON P, 1995, J ACOUST SOC AM, V97, P553, DOI 10.1121/1.412280
   Ju M, 2004, PSYCHOL SCI, V15, P314, DOI 10.1111/j.0956-7976.2004.00675.x
   Kharlamov V, 2012, THESIS, DOI [10.20381/ruor-5674, DOI 10.20381/RUOR-5674]
   Kharlamov V, 2015, LAB PHONOL, V6, P147, DOI 10.1515/lp-2015-0005
   Kharlamov V, 2014, J PHONETICS, V43, P47, DOI 10.1016/j.wocn.2014.02.002
   Kim MR, 2002, J PHONETICS, V30, P77, DOI 10.1006/jpho.2001.0152
   KINGSTON J, 1994, LANGUAGE, V70, P419, DOI 10.2307/416481
   KLATT DH, 1973, J ACOUST SOC AM, V54, P1102, DOI 10.1121/1.1914322
   Kluender K. R, 1988, J PHONETICS
   Kondaurova MV, 2010, J PHONETICS, V38, P569, DOI 10.1016/j.wocn.2010.08.003
   Kondaurova MV, 2008, J ACOUST SOC AM, V124, P3959, DOI 10.1121/1.2999341
   Kong Eun Jong, 2011, P 17 INT C PHON SCI, P1126
   KRAUSE SE, 1982, J ACOUST SOC AM, V71, P990, DOI 10.1121/1.387580
   Kulikov V, 2012, THESIS
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   LISKER L, 1957, LANGUAGE, V33, P42, DOI 10.2307/410949
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Llanos F, 2013, J ACOUST SOC AM, V134, P2213, DOI 10.1121/1.4817845
   LUCE PA, 1985, J ACOUST SOC AM, V78, P1949, DOI 10.1121/1.392651
   Lyakso E. E, 2009, P INT C INTER SPEECH, P1739
   MACKAIN KS, 1981, APPL PSYCHOLINGUIST, V2, P369, DOI 10.1017/S0142716400009796
   MAJOR RC, 1992, MOD LANG J, V76, P190, DOI 10.2307/329772
   Nittrouer S, 2004, J ACOUST SOC AM, V115, P1777, DOI 10.1121/1.1651192
   Padgett J, 2005, PHONETICA, V62, P14, DOI 10.1159/000087223
   Penney J, 2018, J PHONETICS, V66, P161, DOI 10.1016/j.wocn.2017.10.001
   PETERSON GE, 1960, J ACOUST SOC AM, V32, P693, DOI 10.1121/1.1908183
   POLKA L, 1985, J ACOUST SOC AM, V78, P1187, DOI 10.1121/1.392887
   PORT RF, 1982, PERCEPT PSYCHOPHYS, V32, P141, DOI 10.3758/BF03204273
   PORT RF, 1979, J PHONETICS, V7, P45, DOI 10.1016/S0095-4470(19)31032-0
   Pye S., 1986, CAMBRIDGE PAPERS PHO, V5, P1
   RAPHAEL LJ, 1972, J ACOUST SOC AM, V51, P1296, DOI 10.1121/1.1912974
   Ringen C, 2012, J SLAV LINGUIST, V20, P269, DOI 10.1353/jsl.2012.0012
   Sancier ML, 1997, J PHONETICS, V25, P421, DOI 10.1006/jpho.1997.0051
   SHARF DJ, 1962, LANG SPEECH, V5, P26, DOI 10.1177/002383096200500103
   Shultz A. A, 2011, THESIS, P1
   Strange W, 2011, J PHONETICS, V39, P456, DOI 10.1016/j.wocn.2010.09.001
   Tice M, 2012, PAGUETTES BASTRIES N, V8
   Tremblay MC, 2012, J ACOUST SOC AM, V132, P3465, DOI 10.1121/1.4756955
   VANSANTEN JPH, 1992, SPEECH COMMUN, V11, P513, DOI 10.1016/0167-6393(92)90027-5
   WARDRIPFRUIN C, 1982, J ACOUST SOC AM, V71, P187, DOI 10.1121/1.387346
   Warner N, 2011, J ACOUST SOC AM, V130, P1606, DOI 10.1121/1.3621306
   WARREN P, 1988, PERCEPT PSYCHOPHYS, V43, P21, DOI 10.3758/BF03208969
   WILLIAMS L, 1977, PERCEPT PSYCHOPHYS, V21, P289, DOI 10.3758/BF03199477
   Wright J. D, 2007, LARYNGEAL CONTRAST S
   Yamada R. A., 1992, SPEECH PERCEPTION PR, P155
NR 100
TC 4
Z9 4
U1 2
U2 3
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD MAR
PY 2019
VL 73
BP 128
EP 143
DI 10.1016/j.wocn.2018.12.008
PG 16
WC Linguistics; Language & Linguistics
SC Linguistics
GA HP1FZ
UT WOS:000461412100009
DA 2021-02-24
ER

PT J
AU van der Feest, SVH
   Blanco, CP
   Smiljanic, R
AF van der Feest, Suzanne V. H.
   Blanco, Cynthia P.
   Smiljanic, Rajka
TI Influence of speaking style adaptations and semantic context on the time
   course of word recognition in quiet and in noise
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Word recognition; Speech perception in noise; Clear Speech; Infant
   Directed Speech; Eye-tracking
ID INFANT-DIRECTED SPEECH; HARD-OF-HEARING; CLEAR SPEECH; SPOKEN WORDS;
   DEVELOPMENTAL DIFFERENCES; ACOUSTIC CHARACTERISTICS; COMMUNICATIVE
   INTENT; LEXICAL COMPETITION; RECOGNIZING SPEECH; INTELLIGIBILITY
AB This study examines the effects of different listener-oriented speaking styles and semantic contexts on online spoken word recognition using eyetracking. In Experiment 1, different groups of listeners participated in a word-identification-in-noise and in a pleasantness-rating task. Listeners heard sentences with high- versus low-predictability semantic contexts produced in infant-directed speech, Clear Speech, and Conversational Speech. Experiment 2 (in silence) and 3 (in noise) investigated the time course of visual fixations to target objects when participants were listening to different speaking styles and contexts. Results from all experiments show that relative to conversational speech, both infant-directed speech and Clear Speech improved word recognition for high-predictability sentences, in quiet as well as in noise. This indicates that established advantages of infant-directed speech for young listeners cannot be attributed only to affect; the acoustic enhancements in infant-directed speech benefit adult speech processing as well. Furthermore, in silence (Experiment 2) lexical access was facilitated by contextual cues even in conversational speech; but in noise (Experiment 3) listeners reliably focused the target only when a combination of contextual cues and listener-adapted acoustic-phonetic cues were available. These findings suggest that both semantic cues and listener-oriented acoustic enhancements are needed to facilitate word recognition, especially in adverse listening conditions. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [van der Feest, Suzanne V. H.; Blanco, Cynthia P.; Smiljanic, Rajka] Univ Texas Austin, Dept Linguist, 305 E 23rd St B5100, Austin, TX 78712 USA.
   [van der Feest, Suzanne V. H.] CUNY, Grad Ctr, Linguist Program, 365 Fifth Ave,Room 7407, New York, NY 10016 USA.
   [Blanco, Cynthia P.] Duolingo, 5900 Penn Ave, Pittsburgh, PA 15206 USA.
RP van der Feest, SVH (corresponding author), CUNY, Grad Ctr, Linguist Program, 365 Fifth Ave,Room 7407, New York, NY 10016 USA.
EM svanderfeest@gc.cuny.edu
CR Adriaans F, 2017, J ACOUST SOC AM, V141, P3070, DOI 10.1121/1.4982246
   Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Altmann GTM, 2011, ACTA PSYCHOL, V137, P190, DOI 10.1016/j.actpsy.2010.09.009
   Assmann Peter, 2004, VVolume 18, P231
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   BARD EG, 1988, PERCEPT PSYCHOPHYS, V44, P395, DOI 10.3758/BF03210424
   Bard EG, 2001, LANG COGNITIVE PROC, V16, P731, DOI 10.1080/01690960143000100
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Ben-David BM, 2011, J SPEECH LANG HEAR R, V54, P243, DOI 10.1044/1092-4388(2010/09-0233)
   Benders T, 2013, INFANT BEHAV DEV, V36, P847, DOI 10.1016/j.infbeh.2013.09.001
   Boersma Paul, 2012, PRAAT DOING PHONETIC
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Bradlow AR, 2003, J SPEECH LANG HEAR R, V46, P80, DOI 10.1044/1092-4388(2003/007)
   Bradlow AR, 2002, J ACOUST SOC AM, V112, P272, DOI 10.1121/1.1487837
   Bradlow AR, 1996, SPEECH COMMUN, V20, P255, DOI 10.1016/S0167-6393(96)00063-5
   Brouwer S, 2016, J PSYCHOLINGUIST RES, V45, P1151, DOI 10.1007/s10936-015-9396-9
   Brouwer S, 2013, APPL PSYCHOLINGUIST, V34, P519, DOI 10.1017/S0142716411000853
   Buckler H, 2018, J PHONETICS, V66, P45, DOI 10.1016/j.wocn.2017.09.004
   COOPER RM, 1974, COGNITIVE PSYCHOL, V6, P84, DOI 10.1016/0010-0285(74)90005-X
   COOPER RP, 1990, CHILD DEV, V61, P1584, DOI 10.1111/j.1467-8624.1990.tb02885.x
   COOPER RP, 1994, CHILD DEV, V65, P1663, DOI 10.1111/j.1467-8624.1994.tb00841.x
   Cristia A, 2013, LANG LINGUIST COMPAS, V7, P157, DOI 10.1111/lnc3.12015
   Cristia A, 2014, J CHILD LANG, V41, P913, DOI 10.1017/S0305000912000669
   Cristia A, 2010, J ACOUST SOC AM, V128, P424, DOI 10.1121/1.3436529
   Dahan D, 2010, CURR DIR PSYCHOL SCI, V19, P121, DOI 10.1177/0963721410364726
   DeCarlo LT, 1997, PSYCHOL METHODS, V2, P292, DOI 10.1037/1082-989X.2.3.292
   Eaves BS, 2016, PSYCHOL REV, V123, P758, DOI 10.1037/rev0000031
   Englund Kjellrun T., 2005, FIRST LANG, V25, P219, DOI DOI 10.1177/0142723705050286
   Estes KG, 2013, INFANCY, V18, P797, DOI 10.1111/infa.12006
   Fallon M, 2002, J ACOUST SOC AM, V111, P2242, DOI 10.1121/1.1466873
   Ferguson SH, 2002, J ACOUST SOC AM, V112, P259, DOI 10.1121/1.1482078
   FERNALD A, 1989, CHILD DEV, V60, P1497, DOI 10.2307/1130938
   Fernald A, 1998, PSYCHOL SCI, V9, P228, DOI 10.1111/1467-9280.00044
   FERNALD A, 1991, DEV PSYCHOL, V27, P209, DOI 10.1037/0012-1649.27.2.209
   Fernald A, 1984, ORIGINS GROWTH COMMU, P5, DOI DOI 10.1016/S0163-6383(84)80175-7
   Fish MS, 2017, J PHONETICS, V63, P19, DOI 10.1016/j.wocn.2017.04.003
   Francis AL, 2010, ATTEN PERCEPT PSYCHO, V72, P501, DOI 10.3758/APP.72.2.501
   Francis AL, 2009, ATTEN PERCEPT PSYCHO, V71, P1360, DOI 10.3758/APP.71.6.1360
   Friederici AD, 1999, MEM COGNITION, V27, P438, DOI 10.3758/BF03211539
   Gaskell MG, 2002, COGNITIVE PSYCHOL, V45, P220
   Gilbert RC, 2014, J ACOUST SOC AM, V135, P389, DOI 10.1121/1.4838975
   Godoy E, 2014, COMPUT SPEECH LANG, V28, P629, DOI 10.1016/j.csl.2013.09.007
   GOLINKOFF RM, 1987, J CHILD LANG, V14, P23, DOI 10.1017/S030500090001271X
   Golinkoff RM, 2015, CURR DIR PSYCHOL SCI, V24, P339, DOI 10.1177/0963721415595345
   GRIESER DL, 1988, DEV PSYCHOL, V24, P14, DOI 10.1037/0012-1649.24.1.14
   GROSJEAN F, 1980, PERCEPT PSYCHOPHYS, V28, P267, DOI 10.3758/BF03204386
   Harnsberger JD, 2008, SPEECH COMMUN, V50, P323, DOI 10.1016/j.specom.2007.11.001
   Hazan V, 2004, J ACOUST SOC AM, V116, P3108, DOI 10.1121/1.1806826
   Hazan V, 2011, J ACOUST SOC AM, V130, P2139, DOI 10.1121/1.3623753
   Hintz F, 2016, INTERSPEECH, P2816, DOI 10.21437/Interspeech.2016-882
   Hollich G, 2005, SUPERCODER PROGRAM C
   Johnson EK, 2013, J ACOUST SOC AM, V134, pEL534, DOI 10.1121/1.4828977
   Johnson EK, 2011, Q J EXP PSYCHOL, V64, P1672, DOI 10.1080/17470218.2011.594165
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   KAPLAN PS, 1995, DEV PSYCHOBIOL, V28, P45, DOI 10.1002/dev.420280105
   Keerstock S, 2018, J ACOUST SOC AM, V144, P2871, DOI 10.1121/1.5078589
   Knoll M, 2009, SPEECH COMMUN, V51, P296, DOI 10.1016/j.specom.2008.10.001
   Krause J. C., 2001, THESIS
   Krause JC, 2004, J ACOUST SOC AM, V115, P362, DOI 10.1121/1.1635842
   Kuhl PK, 2007, DEVELOPMENTAL SCI, V10, P110, DOI 10.1111/j.1467-7687.2007.00572.x
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   Lam J, 2013, J SPEECH LANG HEAR R, V56, P1429, DOI 10.1044/1092-4388(2013/12-0335)
   Lam J, 2012, J SPEECH LANG HEAR R, V55, P1807, DOI 10.1044/1092-4388(2012/11-0154)
   Liss JM, 1998, J ACOUST SOC AM, V104, P2457, DOI 10.1121/1.423753
   Liu H. M, 2003, DEV SCI, V6
   Liu S, 2006, J ACOUST SOC AM, V120, P424, DOI 10.1121/1.2208427
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Maniwa K, 2009, J ACOUST SOC AM, V125, P3962, DOI 10.1121/1.2990715
   MARSLENWILSON W, 1984, ATTENTION PERFORM, V10, P125
   MARSLENWILSON W, 1989, J EXP PSYCHOL HUMAN, V15, P576, DOI 10.1037/0096-1523.15.3.576
   Martin A, 2016, COGNITION, V156, P52, DOI 10.1016/j.cognition.2016.07.015
   Martin A, 2014, COGNITION, V132, P216, DOI 10.1016/j.cognition.2014.04.003
   Mattys SL, 2005, J EXP PSYCHOL GEN, V134, P477, DOI 10.1037/0096-3445.134.4.477
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Mattys SL, 2009, COGNITIVE PSYCHOL, V59, P203, DOI 10.1016/j.cogpsych.2009.04.001
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McCoy SL, 2005, Q J EXP PSYCHOL-A, V58, P22, DOI 10.1080/02724980443000151
   McMurray B, 2013, COGNITION, V129, P362, DOI 10.1016/j.cognition.2013.07.015
   McMurray B, 2008, PSYCHON B REV, V15, P1064, DOI 10.3758/PBR.15.6.1064
   McQueen J., 2007, OXFORD HDB PSYCHOLIN, P37, DOI DOI 10.1093/0XF0RDHB/9780198568971.013.0003
   MILLER GA, 1951, J EXP PSYCHOL, V41, P329, DOI 10.1037/h0062491
   Morgan S, 2017, J SPEECH LANG HEAR R, V60, P1
   NELSON DGK, 1989, J CHILD LANG, V16, P55, DOI 10.1017/S030500090001343X
   NITTROUER S, 1990, J ACOUST SOC AM, V87, P2705, DOI 10.1121/1.399061
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Orfanidou E, 2011, Q J EXP PSYCHOL, V64, P96, DOI 10.1080/17470211003743794
   Piazza E. A., 2017, CURR BIOL, V27, P1
   PICHENY MA, 1985, J SPEECH HEAR RES, V28, P96, DOI 10.1044/jshr.2801.96
   PICHENY MA, 1989, J SPEECH HEAR RES, V32, P600, DOI 10.1044/jshr.3203.600
   PICHENY MA, 1986, J SPEECH HEAR RES, V29, P434, DOI 10.1044/jshr.2904.434
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   R Core Team, 2016, R LANG ENV STAT COMP
   RABBITT PMA, 1968, Q J EXP PSYCHOL, V20, P241, DOI 10.1080/14640746808400158
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   RStudio Team, 2016, RSTUDIO INTEGRATED D
   Scarborough R., 2007, ICPHS P, V121, P3044, DOI DOI 10.1121/1.4781735
   Scherer KR, 2003, SER AFFECTIVE SCI, P433
   Schneider W, 2002, E PRIME 10 COMPUTER
   Schreiner MS, 2017, COGNITION, V160, P98, DOI 10.1016/j.cognition.2016.12.003
   Smiljanic R, 2005, J ACOUST SOC AM, V118, P1677, DOI 10.1121/1.2000788
   Smiljanic R, 2008, J ACOUST SOC AM, V124, P3171, DOI 10.1121/1.2990712
   Smiljanic R, 2017, J SPEECH LANG HEAR R, V60, P3081, DOI 10.1044/2017_JSLHR-S-16-0130
   Smiljanic R, 2013, J SPEECH LANG HEAR R, V56, P1085, DOI 10.1044/1092-4388(2012/12-0097)
   Smiljanic R, 2009, LANG LINGUIST COMPAS, V3, P236, DOI 10.1111/j.1749-818x.2008.00112.x
   Soderstrom M, 2007, DEV REV, V27, P501, DOI 10.1016/j.dr.2007.06.002
   Song JY, 2010, J ACOUST SOC AM, V128, P389, DOI 10.1121/1.3419786
   Sundberg U, 1999, PHONETICA, V56, P186, DOI 10.1159/000028450
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Swingley D, 2009, PHILOS T R SOC B, V364, P3617, DOI 10.1098/rstb.2009.0107
   Tanenhaus MK, 2000, J PSYCHOLINGUIST RES, V29, P557, DOI 10.1023/A:1026464108329
   Tang P, 2017, J ACOUST SOC AM, V142, P493, DOI 10.1121/1.4995998
   Tjaden K, 2014, J SPEECH LANG HEAR R, V57, P1191, DOI 10.1044/2014_JSLHR-S-13-0086
   Uchanski RM, 1996, J SPEECH HEAR RES, V39, P494, DOI 10.1044/jshr.3903.494
   Van der Feest S. V. H, 2016, 41 BOST U C LANG DEV
   van der Feest SVH, 2016, LANG ACQUIS, V23, P89, DOI 10.1080/10489223.2015.1047096
   Van Engen KJ, 2017, J ACOUST SOC AM, V142, P1067, DOI 10.1121/1.4998708
   Van Engen KJ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043753
   Wang Y, 2016, DIMENSIONS PHONOLOGI, P311
   Welby P, 2007, SPEECH COMMUN, V49, P28, DOI 10.1016/j.specom.2006.10.005
   Werker JF, 2007, COGNITION, V103, P147, DOI 10.1016/j.cognition.2006.03.006
   WERKER JF, 1989, CAN J PSYCHOL, V43, P230, DOI 10.1037/h0084224
NR 122
TC 2
Z9 2
U1 2
U2 5
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD MAR
PY 2019
VL 73
BP 158
EP 177
DI 10.1016/j.wocn.2019.01.003
PG 20
WC Linguistics; Language & Linguistics
SC Linguistics
GA HP1FZ
UT WOS:000461412100011
DA 2021-02-24
ER

PT J
AU Shen, GN
   Froud, K
AF Shen, Guannan
   Froud, Karen
TI Electrophysiological correlates of categorical perception of lexical
   tones by English learners of Mandarin Chinese: an ERP study
SO BILINGUALISM-LANGUAGE AND COGNITION
LA English
DT Article
DE ERPs; MMN; P300; lexical tones; categorical perception; second language
   learners; Mandarin Chinese
ID MISMATCH NEGATIVITY MMN; LANGUAGE EXPERIENCE; SPEECH-PERCEPTION; BRAIN;
   CATEGORIZATION; ORGANIZATION; PATTERNS; SOUNDS; CORTEX; SCALE
AB This study examines brain responses to boundary effects with respect to Mandarin lexical tone continua for three groups of adult listeners: (1) native English speakers who look advanced Mandarin courses; (2) naive English speakers; and (3) native Mandarin speakers. A cross-boundary tone pair and a within-category tone pair derived from tonal contrasts (Mandarin Tone 1/Tone 4; Tone 2/Tone 3) with equal physical/acoustical distance were used in an auditory oddball paradigm. Fir native Mandarin speakers, the cross-category deviant elicited a larger MMN over Jell hemisphere sensors and larger P300 responses over both hemispheres relative to within-category deviants, suggesting categorical perception of tones at both pre-attentive and attentional stages of processing. In contrast, native English speakers and Mandarin learners did not demonstrate categorical effects. However, learners of Mandarin showed larger P300 responses than the other two groups, suggesting heightened sensitivity to tones and possibly greater attentional resource allocation to tone identification.
C1 [Shen, Guannan] Temple Univ, Dept Psychol, Philadelphia, PA 19122 USA.
   [Froud, Karen] Columbia Univ, Dept Biobehav Sci, Teachers Coll, New York, NY 10027 USA.
RP Shen, GN (corresponding author), 1808 North Broad St, Philadelphia, PA 19122 USA.
EM guannan.shen@temple.edu
CR ATTNEAVE F, 1971, AM J PSYCHOL, V84, P147, DOI 10.2307/1421351
   Bidelman GM, 2015, NEUROIMAGE, V120, P191, DOI 10.1016/j.neuroimage.2015.06.087
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Boersma P., 2009, PRAAT DOING PHONETIC
   Broselow E., 1987, INTERLANGUAGE PHONOL, P350
   Chandrasekaran B, 2007, BRAIN RES, V1128, P148, DOI 10.1016/j.brainres.2006.10.064
   Chandrasekaran B, 2009, BRAIN LANG, V108, P1, DOI 10.1016/j.bandl.2008.02.001
   Dehaene-Lambertz G, 2005, NEUROIMAGE, V24, P21, DOI 10.1016/j.neuroimage.2004.09.039
   DehaeneLambertz G, 1997, NEUROREPORT, V8, P919, DOI 10.1097/00001756-199703030-00021
   Diaz B, 2012, LEARN INDIVID DIFFER, V22, P680, DOI 10.1016/j.lindif.2012.05.005
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Francis AL, 2003, PERCEPT PSYCHOPHYS, V65, P1029, DOI 10.3758/BF03194832
   Gandour J, 2004, NEUROIMAGE, V23, P344, DOI 10.1016/j.neuroimage.2004.06.004
   Gandour J, 2000, J COGNITIVE NEUROSCI, V12, P207, DOI 10.1162/089892900561841
   Gandour J. T., 1994, ENCY LANGUAGE LINGUI, V6, P3116
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Hao YC, 2012, J PHONETICS, V40, P269, DOI 10.1016/j.wocn.2011.11.001
   Harnad S., 1987, CATEGORICAL PERCEPTI, P1
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hsiao FJ, 2009, BIOL PSYCHOL, V81, P58, DOI 10.1016/j.biopsycho.2009.01.007
   Hsieh L, 2001, BRAIN LANG, V76, P227, DOI 10.1006/brln.2000.2382
   Jia SW, 2013, NEUROSCI LETT, V556, P135, DOI 10.1016/j.neulet.2013.10.014
   Joanisse MF, 2007, CEREB CORTEX, V17, P2084, DOI 10.1093/cercor/bhl124
   Jongman A., 2006, HDB E ASIAN PSYCHOLI, V1, DOI [10.1017/CBO9780511550751, DOI 10.1017/CBO9780511550751]
   Jongman A, 2017, J ACOUST SOC AM, V142, pEL163, DOI 10.1121/1.4995526
   Kaan E, 2008, BMC NEUROSCI, V9, DOI 10.1186/1471-2202-9-53
   Kasai K, 2001, NEUROREPORT, V12, P2467, DOI 10.1097/00001756-200108080-00036
   Kazanina N, 2006, P NATL ACAD SCI USA, V103, P11381, DOI 10.1073/pnas.0604821103
   Kuhl PK, 1997, SCIENCE, V277, P684, DOI 10.1126/science.277.5326.684
   Li XJ, 2010, NEUROREPORT, V21, P690, DOI 10.1097/WNR.0b013e32833b0a10
   Liebenthal E, 2010, CEREB CORTEX, V20, P2958, DOI 10.1093/cercor/bhq045
   Luo H, 2006, P NATL ACAD SCI USA, V103, P19558, DOI 10.1073/pnas.0607065104
   MAISTE AC, 1995, EAR HEARING, V16, P68, DOI 10.1097/00003446-199502000-00006
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Moore CB, 1997, J ACOUST SOC AM, V102, P1864, DOI 10.1121/1.420092
   MOULINES E, 1995, SPEECH COMMUN, V16, P175, DOI 10.1016/0167-6393(94)00054-E
   Naatanen R, 2005, PSYCHOPHYSIOLOGY, V42, P25, DOI 10.1111/j.1469-8986.2005.00256.x
   Naatanen R, 1997, AUDIOL NEURO-OTOL, V2, P341
   Naatanen R, 2001, PSYCHOPHYSIOLOGY, V38, P1, DOI 10.1017/S0048577201000208
   Peng G, 2010, J PHONETICS, V38, P616, DOI 10.1016/j.wocn.2010.09.003
   Pincze Z, 2001, CLIN NEUROPHYSIOL, V112, P778, DOI 10.1016/S1388-2457(01)00509-0
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   Ren GQ, 2009, NEUROSCIENCE, V162, P87, DOI 10.1016/j.neuroscience.2009.04.021
   Sebastian-Galles N, 2005, TWENTY-FIRST CENTURY PSYCHOLINGUISTICS: FOUR CORNERSTONES, P279
   Sharma A, 1999, J ACOUST SOC AM, V106, P1078, DOI 10.1121/1.428048
   Shen GN, 2016, J ACOUST SOC AM, V140, P4396, DOI 10.1121/1.4971765
   SHEN XNS, 1993, J ACOUST SOC AM, V93, P2241, DOI 10.1121/1.406688
   Stevens SS, 1941, AM J PSYCHOL, V53, P329
   Stevens SS, 1937, J ACOUST SOC AM, V8, P185, DOI 10.1121/1.1915893
   Toscano JC, 2010, PSYCHOL SCI, V21, P1532, DOI 10.1177/0956797610384142
   van Lancker D., 1980, PAP LINGUIST, V13, P201, DOI [10.1080/08351818009370498, DOI 10.1080/08351818009370498]
   Wang Y, 2001, BRAIN LANG, V78, P332, DOI 10.1006/brln.2001.2474
   Wang Y., 2003, P 15 INT C PHON SCI, P1537
   White C. M., 1981, J CHINESE LANGUAGE T, V16, P27
   Winkler I, 1999, COGNITIVE BRAIN RES, V7, P357, DOI 10.1016/S0926-6410(98)00039-1
   Wong PCM, 2004, J NEUROSCI, V24, P9153, DOI 10.1523/JNEUROSCI.2225-04.2004
   Xi J, 2010, NEUROSCIENCE, V170, P223, DOI 10.1016/j.neuroscience.2010.06.077
   Xu Y, 2005, J PHONETICS, V33, P159, DOI 10.1016/j.wocn.2004.11.001
   Xu YS, 2006, J ACOUST SOC AM, V120, P1063, DOI 10.1121/1.2213572
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
   Zhao TC, 2015, J ACOUST SOC AM, V137, P1452, DOI 10.1121/1.4913457
   Zheng H. J., 2010, THESIS
NR 62
TC 10
Z9 10
U1 3
U2 14
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 1366-7289
EI 1469-1841
J9 BILING-LANG COGN
JI Biling.-Lang. Cogn.
PD MAR
PY 2019
VL 22
IS 2
BP 253
EP 265
DI 10.1017/S136672891800038X
PG 13
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA HP3EI
UT WOS:000461558600003
DA 2021-02-24
ER

PT J
AU Toscano, JC
   Lansing, CR
AF Toscano, Joseph C.
   Lansing, Charissa R.
TI Age-Related Changes in Temporal and Spectral Cue Weights in Speech
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Speech perception; phonetic categorization; trading relations; cue
   weighting; age
ID VOICE-ONSET TIME; SPEAKING-RATE; ACOUSTIC CHARACTERISTICS; TRADING
   RELATIONS; COMPETING SPEECH; GAP DETECTION; OLDER-ADULTS; PERCEPTION;
   HEARING; CONTEXT
AB Listeners weight acoustic cues in speech according to their reliability, but few studies have examined how cue weights change across the lifespan. Previous work has suggested that older adults have deficits in auditory temporal discrimination, which could affect the reliability of temporal phonetic cues, such as voice onset time (VOT), and in turn, impact speech perception in real-world listening environments. We addressed this by examining younger and older adults' use of VOT and onset F0 (a secondary phonetic cue) for voicing judgments (e.g., /b/ vs. /p/), using both synthetic and naturally produced speech. We found age-related differences in listeners' use of the two voicing cues, such that older adults relied more heavily on onset F0 than younger adults, even though this cue is less reliable in American English. These results suggest that phonetic cue weights continue to change across the lifespan.
C1 [Toscano, Joseph C.] Villanova Univ, Villanova, PA 19085 USA.
   [Lansing, Charissa R.] Univ Illinois, Urbana, IL USA.
RP Toscano, JC (corresponding author), Villanova Univ, Dept Psychol & Brain Sci, 800 E Lancaster Ave, Villanova, PA 19085 USA.
EM joseph.toscano@villanova.edu
OI Toscano, Joseph/0000-0001-8141-0084
FU Beckman Postdoctoral Fellowship
FX This work was supported by a Beckman Postdoctoral Fellowship to JCT.
CR Abramson A., 1985, PHONETIC LINGUISTICS, P23
   Allen JS, 1999, J ACOUST SOC AM, V106, P2031, DOI 10.1121/1.427949
   ASHA American Speech Language Hearing Association, 2016, SELF TEST HEAR LOSS
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   BERNSTEIN LE, 1983, J PHONETICS, V11, P383, DOI 10.1016/S0095-4470(19)30837-X
   Boersma P., 2013, PRAAT DOING PHONETIC
   BOOTHROYD A, 1992, EAR HEARING, V13, P150, DOI 10.1097/00003446-199206000-00003
   Bowers JS, 2012, PSYCHOL BULL, V138, P389, DOI 10.1037/a0026450
   Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980
   Cho T, 1999, J PHONETICS, V27, P207, DOI 10.1006/jpho.1999.0094
   Dmitrieva O, 2015, J PHONETICS, V49, P77, DOI 10.1016/j.wocn.2014.12.005
   Dobie RA, 2011, EAR HEARING, V32, P732, DOI 10.1097/AUD.0b013e31822228be
   DORMAN MF, 1985, J ACOUST SOC AM, V77, P664, DOI 10.1121/1.391885
   Escudero P, 2004, STUD SECOND LANG ACQ, V26, P551, DOI 10.1017/S0272226310400021
   Germine L, 2012, PSYCHON B REV, V19, P847, DOI 10.3758/s13423-012-0296-9
   Getz LM, 2017, BRAIN SCI, V7, DOI 10.3390/brainsci7030032
   Gordon-Salant S, 2006, J ACOUST SOC AM, V119, P2455, DOI 10.1121/1.2171527
   Griffiths TL, 2006, PSYCHOL SCI, V17, P767, DOI 10.1111/j.1467-9280.2006.01780.x
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Hoekstra A., 1977, PSYCHOPHYSICS PHYSL, P263
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   HOUSE AS, 1953, J ACOUST SOC AM, V25, P105, DOI 10.1121/1.1906982
   Jacobs RA, 1999, VISION RES, V39, P3621, DOI 10.1016/S0042-6989(99)00088-7
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   Kim M., 2004, 8 INT C SPOK LANG PR, P49
   KLATT DH, 1990, J ACOUST SOC AM, V87, P820, DOI 10.1121/1.398894
   KRAUSE SE, 1982, J ACOUST SOC AM, V71, P990, DOI 10.1121/1.387580
   LEHISTE I, 1961, J ACOUST SOC AM, V33, P419, DOI 10.1121/1.1908681
   Li FP, 2012, J ACOUST SOC AM, V132, P2663, DOI 10.1121/1.4747008
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P213, DOI 10.3758/BF03204377
   MASSARO DW, 1986, J EXP CHILD PSYCHOL, V41, P93, DOI 10.1016/0022-0965(86)90053-6
   Mayo C, 2005, J ACOUST SOC AM, V118, P1730, DOI 10.1121/1.1979451
   Mayo C., 2003, P 15 INT C PHON SCI, P889
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   MILLER JL, 1979, PERCEPT PSYCHOPHYS, V25, P457, DOI 10.3758/BF03213823
   MILLER JL, 1993, PERCEPT PSYCHOPHYS, V54, P205, DOI 10.3758/BF03211757
   MOORE BCJ, 1992, J ACOUST SOC AM, V92, P1923, DOI 10.1121/1.405240
   MORRONGIELLO BA, 1984, J EXP CHILD PSYCHOL, V37, P231, DOI 10.1016/0022-0965(84)90002-X
   Nearey TM, 1997, J ACOUST SOC AM, V101, P3241, DOI 10.1121/1.418290
   NIDCD National Institute on Deafness and Other Communicative Disorders, 2013, NIH PUBLICATION, V13-4913
   Nittrouer S, 1997, J ACOUST SOC AM, V101, P2253, DOI 10.1121/1.418207
   Nittrouer S, 2002, J ACOUST SOC AM, V112, P711, DOI 10.1121/1.1496082
   NITTROUER S, 1987, J SPEECH HEAR RES, V30, P319, DOI 10.1044/jshr.3003.319
   ODEN GC, 1978, PSYCHOL REV, V85, P172, DOI 10.1037/0033-295X.85.3.172
   Ohde RN, 1997, J ACOUST SOC AM, V102, P3711, DOI 10.1121/1.420135
   Paolacci G, 2010, JUDGM DECIS MAK, V5, P411
   PARADY S, 1981, J ACOUST SOC AM, V69, P783, DOI 10.1121/1.385589
   PARNELL MM, 1978, J SPEECH HEAR RES, V21, P682, DOI 10.1044/jshr.2104.682
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Pichora-Fuller MK, 2006, J ACOUST SOC AM, V119, P1143, DOI 10.1121/1.2149837
   REPP BH, 1982, PSYCHOL BULL, V92, P81, DOI 10.1037/0033-2909.92.1.81
   Rogers CS, 2012, PSYCHOL AGING, V27, P33, DOI 10.1037/a0026231
   Schneider BA, 2002, CAN J EXP PSYCHOL, V56, P139, DOI 10.1037/h0087392
   Schneider BA, 1999, J ACOUST SOC AM, V106, P371, DOI 10.1121/1.427062
   Sekiyama K, 2008, DEVELOPMENTAL SCI, V11, P306, DOI 10.1111/j.1467-7687.2008.00677.x
   SHINN PC, 1985, PERCEPT PSYCHOPHYS, V38, P397, DOI 10.3758/BF03207170
   Silva D. J., 2006, PHONOLOGY, V23, P287, DOI DOI 10.1017/S0952675706000911
   Snell KB, 2000, J ACOUST SOC AM, V107, P1615, DOI 10.1121/1.428446
   Snell KB, 1997, J ACOUST SOC AM, V101, P2214, DOI 10.1121/1.418205
   Snyder JS, 2005, COGNITIVE BRAIN RES, V24, P492, DOI 10.1016/j.cogbrainres.2005.03.002
   Sommers MS, 1999, PSYCHOL AGING, V14, P458, DOI 10.1037/0882-7974.14.3.458
   Souza P, 2011, EAR HEARING, V32, P75, DOI 10.1097/AUD.0b013e3181eccfe9
   Souza PE, 2015, J SPEECH LANG HEAR R, V58, P520, DOI 10.1044/2015_JSLHR-H-14-0138
   STEVENS KN, 1992, J ACOUST SOC AM, V91, P2979, DOI 10.1121/1.402933
   SUMMERFIELD Q, 1977, J ACOUST SOC AM, V62, P435, DOI 10.1121/1.381544
   Summers V, 1998, J SPEECH LANG HEAR R, V41, P1294, DOI 10.1044/jslhr.4106.1294
   Toscano JC, 2012, ATTEN PERCEPT PSYCHO, V74, P1284, DOI 10.3758/s13414-012-0306-z
   Toscano JC, 2010, COGNITIVE SCI, V34, P434, DOI 10.1111/j.1551-6709.2009.01077.x
   Tun PA, 2002, PSYCHOL AGING, V17, P453, DOI 10.1037//0882-7974.17.3.453
   Turner C W, 1999, Am J Audiol, V8, P47, DOI 10.1044/1059-0889(1999/002)
   TYLER RS, 1982, J ACOUST SOC AM, V72, P740, DOI 10.1121/1.388254
   Utman JA, 1998, J ACOUST SOC AM, V103, P1640, DOI 10.1121/1.421297
   Vongpoisal T, 2007, J SPEECH LANG HEAR R, V50, P1139, DOI 10.1044/1092-4388(2007/079)
   WARDRIPFRUIN C, 1984, LANG SPEECH, V27, P367, DOI 10.1177/002383098402700407
   Winn MB, 2013, J SPEECH LANG HEAR R, V56, P1097, DOI 10.1044/1092-4388(2012/12-0086)
NR 79
TC 2
Z9 2
U1 1
U2 3
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD MAR
PY 2019
VL 62
IS 1
BP 61
EP 79
DI 10.1177/0023830917737112
PG 19
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA HO4YZ
UT WOS:000460931000004
PM 29103359
DA 2021-02-24
ER

PT J
AU Kaland, C
   Galata, V
   Spreafico, L
   Vietti, A
AF Kaland, Constantijn
   Galata, Vincenzo
   Spreafico, Lorenzo
   Vietti, Alessandro
TI Which Language R You Speaking? /r/ as a Language Marker in Tyrolean and
   Italian Bilinguals
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Phonetics; speech production; speech perception; articulation;
   bilingualism
AB Across languages of the world the /r/ sound is known for its variability. This variability has been investigated using articulatory models as well as in sociolinguistic studies. The current study investigates to what extent /r/ is a marker of a bilingual's dominant language. To this end, a reading task was carried out by bilingual speakers from South Tyrol, who produce /r/ differently according to whether they dominantly speak Tyrolean or Italian. The recorded reading data were subsequently used in a perception experiment to investigate whether South Tyrolean bilingual listeners are able to identify the dominant language of the speaker. Results indicate that listeners use /r/ as a cue to determine the dominant language of the speaker whilst relying on articulatory distinctions between the variants. It is furthermore shown that /r/ correlates with three interdependent variables: the sociolinguistic background of the speakers, their speech production, and how their speech is perceived.
C1 [Kaland, Constantijn; Galata, Vincenzo; Spreafico, Lorenzo; Vietti, Alessandro] Free Univ Bozen, Alpine Lab Phonet Sci, Bolzano, Italy.
RP Kaland, C (corresponding author), Univ Cologne, Inst Linguist, Meister Ekkehart Str 7, D-50937 Cologne, Germany.
EM ckaland@uni-koeln.de
OI GALATA', Vincenzo/0000-0003-1075-4984; Kaland,
   Constantijn/0000-0002-1813-5902
FU Autonomous Province of BolzanoPronvincia Autonoma di Bolzano
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This study
   is financially supported by the Autonomous Province of Bolzano.
CR Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boersma P, 2015, PRAAT DOING PHONETIC
   Canepari L., 2009, DIZIONARIO PRONUNCIA
   Ciccolone S., 2010, STANDARD TEDESCO ALT
   Clopper CG, 2004, J PHONETICS, V32, P111, DOI 10.1016/S0095-4470(03)00009-3
   Colantoni L, 2007, STUD SECOND LANG ACQ, V29, P381, DOI 10.1017/S0272263107070258
   Drager K, 2010, LANG LINGUIST COMPAS, V4, P473, DOI 10.1111/j.1749-818x.2010.00210.x
   Eichinger L., 2002, J MULTILING MULTICUL, V23, P137
   Evans JD, 1996, STRAIGHTFORWARD STAT
   FOULKES P, 2000, J SOCIOLING, V4, P30, DOI DOI 10.1111/1467-9481.00102
   Foulkes P, 2006, J PHONETICS, V34, P409, DOI 10.1016/j.wocn.2005.08.002
   Galata V., 2016, P INT 2016 SAN FRANC
   Grech H, 2008, INT J BILINGUAL, V12, P155, DOI 10.1177/1367006908098564
   IPA, 1999, HDB INT PHON ASS GUI
   Kaland C. C. L., 2016, P INT 2016 SAB FRABC
   Khattab Ghada, 2002, LEEDS WORKING PAPERS, V9, P91
   Krech EM, 2009, DEUTSCHES AUSSPRACHEWORTERBUCH, P1, DOI 10.1515/9783110215564
   Ladefoged Peter, 1996, SOUNDS WORLDS LANGUA
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lanthaler F., 1990, DIALEKT ZWEISPRACHIG, P57
   Lindau Mona, 1985, PHONETIC LINGUISTICS, P157
   Magnusson Thomas J., 2007, P 16 INT C PHON SCI, P1193
   Matras Y., 2009, LANGUAGE CONTACT
   Mioni A. M., 1990, MEHR ALS SPRACHE SPR, P13
   MURPHY AB, 1993, INT J SOCIOL LANG, P49
   Paradis J., 2001, INT J BILINGUAL, V5, P19, DOI DOI 10.1177/13670069010050010201
   R Core Team, 2016, R LANG ENV STAT COMP
   Rafat Y, 2010, IRAN STUD-UK, V43, P667, DOI 10.1080/00210862.2010.518030
   Romano A., 2013, RHOTICS NEW DATA PER, P209
   Scobbie J., 2006, ENCY LANGUAGE LINGUI, P337, DOI DOI 10.1016/B0-08-044854-2/04711-8
   Sebregts Koen, 2014, THESIS
   Shosted R. K., 2008, P ISSP 2008 8 INT SE, P417
   Sole M. J., 2007, EXPT APPROACHES PHON, P175
   Sole MJ, 2002, J PHONETICS, V30, P655, DOI 10.1006/jpho.2002.0179
   Spreafico L., 2016, INT J LINGUISTICS, V8, P72
   Thomas E. R., 2005, J ACOUST SOC AM, V117, P2458
   Thomason Sarah Grey, 1988, LANGUAGE CONTACT CRE
   Trudgill Peter, 1974, LANGUAGE SOC, V3, P215, DOI [DOI 10.1017/S0047404500004358, 10.1017/S0047404500004358]
   Van Bezooijen R, 1999, J LANG SOC PSYCHOL, V18, P31, DOI 10.1177/0261927X99018001003
   Veenker T. J. G., 2003, WWSTIM CGI SCRIPT PR
   Velde H. van de, 2013, RHOTICS NEW DATA PER, P227
   Verstraeten B., 2001, R ATICS SOCIOLINGUIS, P44
   Vietti A., 2015, P 18 INT C PHON SCI
   Vietti A., 2010, P WORKSH SOC CROSS S, P76
   Wiese Richard, 2001, R ATICS SOCIOLINGUIS, P11
   Wiese Richard, 2011, BLACKWELL COMPANION, P711, DOI DOI 10.1002/9781444335262.WBCTP0030
   Wiesinger Peter, 1990, DIALECTS MODERN GERM, P438
   Wollock J., 1982, FOLIA LINGUISTICA HI, V3, P185
NR 48
TC 1
Z9 1
U1 1
U2 1
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD MAR
PY 2019
VL 62
IS 1
BP 137
EP 163
DI 10.1177/0023830917746551
PG 27
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA HO4YZ
UT WOS:000460931000007
PM 29233049
DA 2021-02-24
ER

PT J
AU Wang, J
   Sung, V
   le Clercq, CMP
   Burt, RA
   Carew, P
   Liu, RS
   Mensah, FK
   Gold, L
   Wake, M
AF Wang, J.
   Sung, V.
   le Clercq, C. M. P.
   Burt, R. A.
   Carew, P.
   Liu, R. S.
   Mensah, F. K.
   Gold, L.
   Wake, M.
TI High prevalence of slight and mild hearing loss across mid-life: a
   cross-sectional national Australian study
SO PUBLIC HEALTH
LA English
DT Article
DE Hearing loss; Prevalence; Risk factors; Adults
ID RISK-FACTORS; LIFE-COURSE; AGED 20; ADULTS; HEALTH; THRESHOLDS;
   IMPAIRMENT; CHILDREN; DISEASE
AB Objectives: Although presbycusis typically becomes symptomatic only in older age, slight and mild hearing loss may be detectable well before this. We studied current prevalence and characteristics of hearing loss in Australian mid-life adults.
   Study design: This was a population-derived national cross-sectional study nested within the Longitudinal Study of Australian Children.
   Methods: A total of 1485 parents/guardians (87.3% female) aged 30-59 years underwent air-conduction audiometry. Hearing loss was defined in three ways to maximize cross-study comparability: high Fletcher index (mean of 1, 2 and 4 kHz; primary outcome relevant to speech perception), lower frequency (mean of 1 and 2 kHz) and higher frequency (mean of 4 and 8 kHz). Multivariable logistic regression examined how losses vary by age, sex and neighbourhood disadvantage.
   Results: On high Fletcher index, 27.3% had bilateral and 23.8% unilateral thresholds >15 dB hearing level (HL) (slight or worse), and 4.9% had bilateral and 6.3% unilateral thresholds >25 dB HL (mild or worse). Bilateral higher frequency losses were more common than lower frequency losses for thresholds >15 dB HL (30.9% vs. 26.4%) and >25 dB HL (11.0% vs. 4.6%). Age increased the risk of bilateral speech and higher frequency losses (all P for trend < 0.05), but not lower frequency losses >25 dB HL. Although sex was not associated with speech and lower frequency losses, men were more likely to have bilateral higher frequency losses (e.g. >15 dB HL: odds ratio [OR]: 2.2; 95% confidence interval [CI]: 1.5-3.2, P < 0.001).
   Conclusions: Both slight and mild hearing loss show high and rising prevalence across mid-life. This offers opportunities to prevent progression to reduce the profound later burden of age-related hearing loss. (C) 2018 The Royal Society for Public Health. Published by Elsevier Ltd. All rights reserved.
C1 [Wang, J.; Sung, V.; le Clercq, C. M. P.; Burt, R. A.; Carew, P.; Liu, R. S.; Mensah, F. K.; Gold, L.; Wake, M.] Royal Childrens Hosp, Murdoch Childrens Res Inst, Flemington Rd, Parkville, Vic 3052, Australia.
   [Wang, J.; Sung, V.; Burt, R. A.; Carew, P.; Liu, R. S.; Mensah, F. K.; Wake, M.] Univ Melbourne, Dept Paediat, Parkville, Vic 3052, Australia.
   [Sung, V.] Royal Childrens Hosp, Dept Gen Med, Parkville, Vic 3052, Australia.
   [le Clercq, C. M. P.] Erasmus MC, Dept Otolaryngol, NL-3015 Rotterdam, Netherlands.
   [Carew, P.] Univ Melbourne, Dept Audiol & Speech Pathol, Parkville, Vic 3052, Australia.
   [Gold, L.] Deakin Univ, Sch Hlth & Social Dev, Geelong, Vic 3217, Australia.
   [Wake, M.] Univ Auckland, Dept Paediat, Auckland 1142, New Zealand.
   [Wake, M.] Univ Auckland, Liggins Inst, Auckland 1142, New Zealand.
RP Wake, M (corresponding author), Royal Childrens Hosp, Murdoch Childrens Res Inst, Flemington Rd, Parkville, Vic 3052, Australia.
EM melissa.wake@mcri.edu.au
RI Sung, Valerie/AAB-9858-2019; Wake, Melissa/J-1396-2012; Mensah, Fiona
   K/G-3382-2018
OI Wake, Melissa/0000-0001-7501-9257; Mensah, Fiona K/0000-0002-6951-9949;
   Gold, Lisa/0000-0002-2733-900X; Wang, Jing/0000-0001-5701-476X
FU Australian National Health and Medical Research Council (NHMRC)National
   Health and Medical Research Council of Australia [1041352, 1109355];
   Royal Children's Hospital Foundation [2014-241]; Murdoch Children's
   Research Institute; National Heart Foundation of AustraliaNational Heart
   Foundation of Australia [100660]; Financial Markets Foundation for
   Children [2014-055, 2016-310]; Victorian Deaf Education Institute;
   University of Melbourne Postgraduate Scholarship; Murdoch Children's
   Research Institute PhD Top Up Scholarship; NHMRCNational Health and
   Medical Research Council of Australia [1125687, 1023493, 1114567,
   1111160, 1035100, 1046518]; Cottrell Research Fellowship from the Royal
   Australasian College of Physicians; Ter Meulen Grant from the Royal
   Netherlands Academy of Arts and Sciences; Cure Kids New Zealand;
   University of MelbourneUniversity of Melbourne
FX This work was supported by the Australian National Health and Medical
   Research Council (NHMRC) Project Grants 1041352 and 1109355, The Royal
   Children's Hospital Foundation (2014-241), Murdoch Children's Research
   Institute, The University of Melbourne, the National Heart Foundation of
   Australia (100660), the Financial Markets Foundation for Children
   (2014-055, 2016-310) and the Victorian Deaf Education Institute. The
   funding bodies did not play any role in the study. J. W. was supported
   by the University of Melbourne Postgraduate Scholarship and the Murdoch
   Children's Research Institute PhD Top Up Scholarship. The following
   authors were supported by the NHMRC: V.S. (Early Career Fellowship
   1125687), P.C. (Centre of Research Excellence in Child Language
   1023493), R.L. (Postgraduate Scholarship 1114567), F.M. (Career
   Development Fellowship 1111160), L.G. (Early Career Fellowship 1035100)
   and M.W. (Senior Research Fellowship 1046518) in this work. V.S. was
   additionally supported by a Cottrell Research Fellowship from the Royal
   Australasian College of Physicians, C.L.C. by a Ter Meulen Grant from
   the Royal Netherlands Academy of Arts and Sciences and M.W. by Cure Kids
   New Zealand.
CR [Anonymous], 2006, EC LISTEN HEAR EC IM
   Bainbridge KE, 2014, ANNU REV PUBL HEALTH, V35, P139, DOI 10.1146/annurev-publhealth-032013-182510
   Bredberg G., 1968, ACTA OTOLARYNGO S236
   Choi JE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171635
   Clark J G, 1981, ASHA, V23, P493
   Cone BK, 2010, EAR HEARING, V31, P202, DOI 10.1097/AUD.0b013e3181c62263
   DAVIS AC, 1989, INT J EPIDEMIOL, V18, P911, DOI 10.1093/ije/18.4.911
   Davis A, 2016, GERONTOLOGIST, V56, pS256, DOI 10.1093/geront/gnw033
   de Klaver MJM, 2007, J NEUROL NEUROSUR PS, V78, P1310, DOI 10.1136/jnnp.2006.111609
   Engdahl B, 2015, INT J AUDIOL, V54, P958, DOI 10.3109/14992027.2015.1090631
   Eriksson JG, 2005, BMJ-BRIT MED J, V330, P1096, DOI 10.1136/bmj.330.7500.1096
   Feder K, 2015, HEALTH REP, V26, P18
   GATES GA, 1993, ARCH OTOLARYNGOL, V119, P156
   Godfrey KM, 2010, TRENDS ENDOCRIN MET, V21, P199, DOI 10.1016/j.tem.2009.12.008
   Hoffman HJ, 2017, JAMA OTOLARYNGOL, V143, P274, DOI 10.1001/jamaoto.2016.3527
   Kim MB, 2017, INT J EPIDEMIOL, V46, P717, DOI 10.1093/ije/dyw243
   le Clercq CMP, 2016, OTOL NEUROTOL, V37, P1208, DOI 10.1097/MAO.0000000000001163
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P582, DOI 10.1093/gerona/glr002
   Mathers C, 2000, GLOBAL BURDEN DIS, V18, P1, DOI DOI 10.1097/mao.0000000000001630
   McMahon Catherine M, 2013, Int J Otolaryngol, V2013, P308509, DOI 10.1155/2013/308509
   Muhr P, 2007, SCAND J PUBLIC HEALT, V35, P524, DOI 10.1080/14034940701281477
   Nelson DI, 2005, AM J IND MED, V48, P446, DOI 10.1002/ajim.20223
   Norton A, 2015, 15 AUSTR I FAM STUD
   Pink B, 2006, SOCIOECONOMIC INDEXE
   Timmer B, 2014, HEARING REV, V21, P30
   Ucler R, 2016, ENDOCRINE, V52, P46, DOI 10.1007/s12020-015-0755-y
   Wake M, 2014, FAMILY MATTERS, P15
   Wilson RH, 2014, J AM ACAD AUDIOL, V25, P171, DOI 10.3766/jaaa.25.2.6
   World Health Organization, 2012, WHO GLOB EST PREV HE
   Yamasoba T, 2013, HEARING RES, V303, P30, DOI 10.1016/j.heares.2013.01.021
   Zhan WH, 2010, AM J EPIDEMIOL, V171, P260, DOI 10.1093/aje/kwp370
NR 32
TC 1
Z9 1
U1 1
U2 7
PU W B SAUNDERS CO LTD
PI LONDON
PA 32 JAMESTOWN RD, LONDON NW1 7BY, ENGLAND
SN 0033-3506
EI 1476-5616
J9 PUBLIC HEALTH
JI Public Health
PD MAR
PY 2019
VL 168
BP 26
EP 35
DI 10.1016/j.puhe.2018.11.017
PG 10
WC Public, Environmental & Occupational Health
SC Public, Environmental & Occupational Health
GA HN4GZ
UT WOS:000460143700005
PM 30682637
DA 2021-02-24
ER

PT J
AU Dufour, S
   Chuang, YY
   Nguyen, N
AF Dufour, Sophie
   Chuang, Yu-Ying
   Nguyen, Noel
TI The processing of dialectal variants: Further insight from French
SO APPLIED PSYCHOLINGUISTICS
LA English
DT Article
DE dialectal variants; lexical representations; semantic priming; spoken
   word recognition
ID PHONEMIC CONTRAST ABSENT; PHONOLOGICAL VARIATION; LEXICAL ACCESS;
   PERCEPTUAL REORGANIZATION; SPEECH-PERCEPTION; WORD RECOGNITION; NATIVE
   SPEAKERS; LANGUAGE; DISCRIMINATION; REPRESENTATION
AB In two semantic priming experiments, this study examined how southern French speakers process the standard French [o] variant in closed syllables in comparison to their own variant [LATIN SMALL LETTER OPEN O]. In Experiment 1, southern French speakers showed facilitation in the processing of the associated target word VIOLET whether the word prime mauve was pronounced by a standard French speaker ([mov]) or a southern French speaker ([mLATIN SMALL LETTER OPEN Ov]). More importantly, Experiment 1 has also revealed that words of type mauve, which are subject to dialectal variation, behave exactly in the same way as words of type gomme, which are pronounced with [LATIN SMALL LETTER OPEN O] by both southern and standard French speakers, and for which we also found no modulation in the magnitude of the priming effect as a function of the dialect of the speaker. Experiment 2 replicated the priming effect found with the standard French variant [mov], and failed to show a priming effect with nonwords such as [m oe v] that also differ from the southern French variant [mLATIN SMALL LETTER OPEN Ov] by only one phonetic feature. Our study thus provides further evidence for efficient processing of dialectal variants during spoken word recognition, even if these variants are not part of the speaker's own productions.
C1 [Dufour, Sophie; Nguyen, Noel] Aix Marseille Univ, Aix En Provence, France.
   [Chuang, Yu-Ying] Univ Tubingen, Tubingen, Germany.
RP Dufour, S (corresponding author), Aix Marseille Univ, CNRS, Lab Parole & Langage, 5 Ave Pasteur, F-13604 Aix En Provence, France.
EM sophie.dufour@lpl-aix.fr
RI Nguyen, Noel/R-5231-2017
OI Nguyen, Noel/0000-0003-3424-5340
FU Labex Brain and Language Research Institute [ANR-11-LABX-0036]; French
   National Agency of Research (ANR)French National Research Agency (ANR)
   [ANR-11-IDEX-0001-02]; Erasmus Mundus Action 2 program MULTI of the
   European Union [2009-5259-5]
FX This work was supported by the Labex Brain and Language Research
   Institute (Grant ANR-11-LABX-0036) and has benefited from support from
   the French National Agency of Research (ANR), under the project title
   "Investments of the Future" A*MIDEX (Grant ANR-11-IDEX-0001-02). This
   research was also supported in part by the Erasmus Mundus Action 2
   program MULTI of the European Union (Grant Agreement 2009-5259-5).
CR Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Baayen RH, 2010, INT J PSYCHOL RES, V3, P12
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   BATES D, 2007, LME4 LINEAR MIXED EF, V2, P6
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Connine CM, 2004, PSYCHON B REV, V11, P1084, DOI 10.3758/BF03196741
   CONNINE CM, 1993, J MEM LANG, V32, P193, DOI 10.1006/jmla.1993.1011
   Connine CM, 2008, PERCEPT PSYCHOPHYS, V70, P403, DOI 10.3758/PP.70.3.403
   Conrey B, 2005, BRAIN LANG, V95, P435, DOI 10.1016/j.bandl.2005.06.008
   Dahan D, 2008, COGNITION, V108, P710, DOI 10.1016/j.cognition.2008.06.003
   Dufour S, 2002, ANN PSYCHOL, V102, P725
   Dufour S, 2007, J ACOUST SOC AM, V121, pEL131, DOI 10.1121/1.2710742
   Dufour S, 2016, J ACOUST SOC AM, V140, P1871, DOI 10.1121/1.4962562
   Dufour S, 2013, J PSYCHOLINGUIST RES, V42, P161, DOI 10.1007/s10936-012-9212-8
   Dufour S, 2010, J ACOUST SOC AM, V128, pEL43, DOI 10.1121/1.3431102
   Ferrand L, 1998, ANN PSYCHOL, V98, P659
   Frauenfelder UH, 2001, LANG COGNITIVE PROC, V16, P583, DOI 10.1080/01690960143000146
   Gaskell MG, 1996, J EXP PSYCHOL HUMAN, V22, P144, DOI 10.1037/0096-1523.22.1.144
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   HINTZMAN DL, 1986, PSYCHOL REV, V93, P411, DOI 10.1037/0033-295X.93.4.411
   HINTZMAN DL, 1988, PSYCHOL REV, V95, P528, DOI 10.1037/0033-295X.95.4.528
   Ingram JCL, 1997, J PHONETICS, V25, P343, DOI 10.1006/jpho.1997.0048
   JANSON T, 1983, J LINGUIST, V19, P321, DOI 10.1017/S0022226700007763
   Labov W., 1991, LANG VAR CHANGE, V3, P33, DOI [10.1017/S0954394500000442, DOI 10.1017/S0954394500000442]
   Larraza S, 2017, Q J EXP PSYCHOL, V70, P92, DOI 10.1080/17470218.2015.1124896
   Larraza S, 2016, J EXP PSYCHOL LEARN, V42, P1774, DOI 10.1037/xlm0000252
   MarslenWilson W, 1996, J EXP PSYCHOL HUMAN, V22, P1376, DOI 10.1037/0096-1523.22.6.1376
   MARSLENWILSON W, 1994, PSYCHOL REV, V101, P653, DOI 10.1037/0033-295X.101.4.653
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X
   Maye J, 2008, COGNITIVE SCI, V32, P543, DOI 10.1080/03640210802035357
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   MIYAWAKI K, 1975, PERCEPT PSYCHOPHYS, V18, P331, DOI 10.3758/BF03211209
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Pierrehumbert J, 2001, LANG COGNITIVE PROC, V16, P691, DOI 10.1080/01690960143000218
   R Development Core Team, 2007, R LANG ENV STAT COMP
   Racine I, 2014, LANG COGN NEUROSCI, V29, P893, DOI 10.1080/01690965.2013.832784
   Ranbom LJ, 2007, J MEM LANG, V57, P273, DOI 10.1016/j.jml.2007.04.001
   Snoeren ND, 2008, COGNITION, V108, P512, DOI 10.1016/j.cognition.2008.02.008
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   TREHUB SE, 1976, CHILD DEV, V47, P466, DOI 10.2307/1128803
   Trude AM, 2012, LANG COGNITIVE PROC, V27, P979, DOI 10.1080/01690965.2011.597153
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
   Zhang XJ, 2012, J MEM LANG, V66, P438, DOI 10.1016/j.jml.2011.12.006
NR 46
TC 1
Z9 1
U1 0
U2 6
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0142-7164
EI 1469-1817
J9 APPL PSYCHOLINGUIST
JI Appl. Psycholinguist.
PD MAR
PY 2019
VL 40
IS 2
BP 351
EP 372
DI 10.1017/S0142716418000607
PG 22
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA HM6UB
UT WOS:000459612000006
DA 2021-02-24
ER

PT J
AU Kilpatrick, AJ
   Bundgaard-Nielsen, RL
   Baker, BJ
AF Kilpatrick, Alexander J.
   Bundgaard-Nielsen, Rikke L.
   Baker, Brett J.
TI Japanese co-occurrence restrictions influence second language perception
SO APPLIED PSYCHOLINGUISTICS
LA English
DT Article
DE Japanese; perceptual assimilation; phonology; phonotactics; second
   language perception
ID CONSONANT CLUSTERS; VOCABULARY SIZE; LANGUAGE; EXPERIENCE; ENGLISH;
   PHONOTACTICS; ACCENT
AB Most current models of nonnative speech perception (e.g., extended perceptual assimilation model, PAM-L2, Best & Tyler, 2007; speech learning model, Flege, 1995; native language magnet model, Kuhl, 1993) base their predictions on the native/nonnative status of individual phonetic/phonological segments. This paper demonstrates that the phonotactic properties of Japanese influence the perception of natively contrasting consonants and suggests that phonotactic influence must be formally incorporated in these models. We first propose that by extending the perceptual categories outlined in PAM-L2 to incorporate sequences of sounds, we can account for the effects of differences in native and nonnative phonotactics on nonnative and cross-language segmental perception. In addition, we test predictions based on such an extension in two perceptual experiments. In Experiment 1, Japanese listeners categorized and rated vowel-consonant-vowel strings in combinations that either obeyed or violated Japanese phonotactics. The participants categorized phonotactically illegal strings to the perceptually nearest (legal) categories. In Experiment 2, participants discriminated the same strings in AXB discrimination tests. Our results show that Japanese listeners are more accurate and have faster response times when discriminating between legal strings than between legal and illegal strings. These findings expose serious shortcomings in currently accepted nonnative perception models, which offer no framework for the influence of native language phonotactics.
C1 [Kilpatrick, Alexander J.; Baker, Brett J.] Univ Melbourne, Babel Bldg, Parkville, Vic 3052, Australia.
   [Bundgaard-Nielsen, Rikke L.] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Sydney, NSW, Australia.
RP Kilpatrick, AJ (corresponding author), Univ Melbourne, Babel Bldg, Parkville, Vic 3052, Australia.
EM alex.kilpatrick@unimelb.edu.au
OI Kilpatrick, Alexander/0000-0003-3134-3797
CR Adank P, 2009, J EXP PSYCHOL HUMAN, V35, P520, DOI 10.1037/a0013552
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best C.T., 1994, DEV SPEECH PERCEPTIO, P167
   BEST CT, 1992, J PHONETICS, V20, P305, DOI 10.1016/S0095-4470(19)30637-0
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Blevins J., 1995, HDB PHONOLOGICAL THE, V1, P206
   Bloch B, 1950, LANGUAGE, V26, P86, DOI 10.2307/410409
   Boersma P., 2015, PRAAT VERSION 5 4 08
   Bonatti L. L., 2010, PSYSCOPE 10 BUILD 77
   Bundgaard-Nielsen RL, 2011, STUD SECOND LANG ACQ, V33, P433, DOI 10.1017/S0272263111000040
   Bundgaard-Nielsen RL, 2014, P 15 AUSTR INT SPEEC, P205
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Cuetos F., 2011, 17 ICPHS, V17, P17
   Davidson L, 2012, J PHONETICS, V40, P234, DOI 10.1016/j.wocn.2011.11.005
   Dupoux E, 1999, J EXP PSYCHOL HUMAN, V25, P1568, DOI 10.1037/0096-1523.25.6.1568
   Dupoux E, 2011, J MEM LANG, V64, P199, DOI 10.1016/j.jml.2010.12.004
   Edwards J, 2004, J SPEECH LANG HEAR R, V47, P421, DOI 10.1044/1092-4388(2004/034)
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Halle PA, 1998, J EXP PSYCHOL HUMAN, V24, P592, DOI 10.1037/0096-1523.24.2.592
   Halle PA, 2008, J EXP PSYCHOL HUMAN, V34, P177, DOI 10.1037/0096-1523.34.1.177
   Halle PA, 2007, J ACOUST SOC AM, V121, P2899, DOI 10.1121/1.2534656
   It Junko, 1999, HDB JAPANESE LINGUIS, P62
   Ito Junko, 1995, U MASSACHUSETTS OCCA, V18, P181
   Kabak B, 2007, LANG SPEECH, V50, P23, DOI 10.1177/00238309070500010201
   Kahn D., 1976, SYLLABLE BASED UNPUB
   KAWAHARA S, 2006, JAPANESE KOREAN LING, V14, P27
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   KUHL PK, 1993, NATO ADV SCI INST SE, V69, P259
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Lewkowicz DJ, 2014, DEV PSYCHOBIOL, V56, P292, DOI 10.1002/dev.21197
   Munro MJ, 1995, LANG SPEECH, V38, P289, DOI 10.1177/002383099503800305
   Mutsukawa M., 2009, JAPANESE LOANWORD PH
   Pinter G, 2015, HANDB JAPAN LANG, V2, P121
   Pitt MA, 1998, J MEM LANG, V39, P347, DOI 10.1006/jmla.1998.2571
   Schmid PM, 1999, J SPEECH LANG HEAR R, V42, P56, DOI 10.1044/jslhr.4201.56
   Scott LS, 2007, CURR DIR PSYCHOL SCI, V16, P197, DOI 10.1111/j.1467-8721.2007.00503.x
   Scott LS, 2010, NEUROPSYCHOLOGIA, V48, P1857, DOI 10.1016/j.neuropsychologia.2010.02.008
   Stanovich KE, 2000, BEHAV BRAIN SCI, V23, P645, DOI 10.1017/S0140525X00003435
   Tamaoka K, 2004, BEHAV RES METH INS C, V36, P531, DOI 10.3758/BF03195600
   Tsujimura N., 2013, INTRO JAPANESE LINGU, V3rd ed.
   Vance Timothy J., 1987, INTRO JAPANESE PHONO
   Vitevitch MS, 1997, LANG SPEECH, V40, P47, DOI 10.1177/002383099704000103
   Vitevitch MS, 1998, PSYCHOL SCI, V9, P325, DOI 10.1111/1467-9280.00064
   Vitevitch MS, 1999, BRAIN LANG, V68, P306, DOI 10.1006/brln.1999.2116
   Wagner M, 2012, BRAIN LANG, V123, P30, DOI 10.1016/j.bandl.2012.06.002
   Werker JF, 2007, COGNITION, V103, P147, DOI 10.1016/j.cognition.2006.03.006
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
NR 48
TC 1
Z9 1
U1 0
U2 5
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0142-7164
EI 1469-1817
J9 APPL PSYCHOLINGUIST
JI Appl. Psycholinguist.
PD MAR
PY 2019
VL 40
IS 2
BP 585
EP 611
DI 10.1017/S0142716418000711
PG 27
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA HM6UB
UT WOS:000459612000015
DA 2021-02-24
ER

PT J
AU Levy, H
   Konieczny, L
   Hanulikova, A
AF Levy, Helena
   Konieczny, Lars
   Hanulikova, Adriana
TI Processing of unfamiliar accents in monolingual and bilingual children:
   effects of type and amount of accent experience
SO JOURNAL OF CHILD LANGUAGE
LA English
DT Article
DE experience with accents; regional accents; foreign accents; speech
   perception; school-aged children; intelligibility; bilingualism
ID FOREIGN ACCENT; PERCEPTION; SPEECH; COMPREHENSION; INTELLIGIBILITY;
   RECOGNITION; ADAPTATION; REPRESENTATION; EXPOSURE; NOISE
AB Substantial individual differences exist in regard to type and amount of experience with variable speech resulting from foreign or regional accents. Whereas prior experience helps with processing familiar accents, research on how experience with accented speech affects processing of unfamiliar accents is inconclusive, ranging from perceptual benefits to processing disadvantages. We examined how experience with accented speech modulates mono- and bilingual children's (mean age: 9;10) ease of speech comprehension for two unfamiliar accents in German, one foreign and one regional. More experience with regional accents helped children repeat sentences correctly in the regional condition and in the standard condition. More experience with foreign accents did not help in either accent condition. The results suggest that type and amount of accent experience co-determine processing ease of accented speech.
C1 [Levy, Helena] Univ Freiburg, GRK Frequency Effects Language, Freiburg, Germany.
   [Konieczny, Lars; Hanulikova, Adriana] Univ Freiburg, Freiburg, Germany.
   [Hanulikova, Adriana] Freiburg Inst Adv Studies FRIAS, Freiburg, Germany.
RP Levy, H (corresponding author), Univ Freiburg, Sprachwissenschaftl Seminar, D-79085 Freiburg, Germany.
EM helena.levy@frequenz.uni-freiburg.de
OI Levy, Helena/0000-0001-6610-6316; Hanulikova,
   Adriana/0000-0001-9010-4185
FU German Research Foundation (DFG)German Research Foundation (DFG) [GRK
   DFG 1624]
FX This research was supported by the German Research Foundation (DFG),
   grant GRK DFG 1624 'Frequency effects in language'.
CR Adank P, 2007, J ACOUST SOC AM, V121, P1130, DOI 10.1121/1.2409492
   Adank P, 2009, J EXP PSYCHOL HUMAN, V35, P520, DOI 10.1037/a0013552
   Algethami G., 2010, P 2 PRON 2 LANG LEAR, P30
   Ammon U., 1977, DIALEKT HOCHSPRACHE
   Ammon U., 2015, B SUISSE LINGUISTIQU, V3, P53
   Baese-Berk MM, 2013, J ACOUST SOC AM, V133, pEL174, DOI 10.1121/1.4789864
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Barry W. J., 1974, J PHONETICS, V2, P65
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Behrman A, 2013, J SPEECH LANG HEAR R, V56, P1567, DOI 10.1044/1092-4388(2013/12-0192)
   Bent T, 2003, J ACOUST SOC AM, V114, P1600, DOI 10.1121/1.1603234
   Bent T., 2015, P 18 INT C PHON SCI
   Bent T, 2018, J CHILD LANG, V45, P1400, DOI 10.1017/S0305000918000053
   Bent T, 2017, LANG SPEECH, V60, P110, DOI 10.1177/0023830916645374
   Bent T, 2016, J ACOUST SOC AM, V140, P3775, DOI 10.1121/1.4966677
   Bent T, 2015, J ACOUST SOC AM, V138, P3985, DOI 10.1121/1.4938228
   Bent T, 2014, J CHILD LANG, V41, P1334, DOI 10.1017/S0305000913000457
   Best CT, 2009, PSYCHOL SCI, V20, P539, DOI 10.1111/j.1467-9280.2009.02327.x
   Bialystok E., 2001, BILINGUALISM DEV LAN
   Bialystok E, 2010, BILING-LANG COGN, V13, P525, DOI 10.1017/S1366728909990423
   Bosch L, 2003, LANG SPEECH, V46, P217, DOI 10.1177/00238309030460020801
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Cito, 2015, CIT SPRACHT VERS 3 D
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Clopper CG, 2006, J AM ACAD AUDIOL, V17, P331, DOI 10.3766/jaaa.17.5.4
   Clopper CG, 2014, LAB PHONOL, V5, P69, DOI 10.1515/lp-2014-0004
   Connine CM, 2008, PERCEPT PSYCHOPHYS, V70, P403, DOI 10.3758/PP.70.3.403
   Creel SC, 2014, LANG LEARN DEV, V10, P68, DOI 10.1080/15475441.2013.803871
   Creel SC, 2012, DEVELOPMENTAL SCI, V15, P697, DOI 10.1111/j.1467-7687.2012.01173.x
   Davies A., 2003, BILINGUAL ED BILINGU
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   Dewaele JM, 2018, APPL LINGUIST, V39, P236, DOI 10.1093/applin/amw055
   Durrant S, 2015, J CHILD LANG, V42, P447, DOI 10.1017/S0305000914000063
   Ellis N. C, 2002, STUDIES 2 LANGUAGE A, V24, P143, DOI DOI 10.1017/S0272263102002024
   Evans B. G., PHONETICA
   FLEGE JE, 1994, J ACOUST SOC AM, V95, P3623, DOI 10.1121/1.409931
   Floccia C, 2006, J EXP PSYCHOL HUMAN, V32, P1276, DOI 10.1037/0096-1523.32.5.1276
   Floccia C, 2012, COGNITION, V124, P95, DOI 10.1016/j.cognition.2012.03.011
   Floccia C, 2009, J PSYCHOLINGUIST RES, V38, P379, DOI 10.1007/s10936-008-9097-8
   Floccia C, 2009, INT J BEHAV DEV, V33, P366, DOI 10.1177/0165025409103871
   Grabe E, 2000, J PHONETICS, V28, P161, DOI 10.1006/jpho.2000.0111
   Grosjean Francois, 2010, BILINGUAL LIFE REALI
   Hanulikova A, 2012, ATTEN PERCEPT PSYCHO, V74, P613, DOI 10.3758/s13414-011-0259-7
   Harte J, 2016, INT J LANG COMM DIS, V51, P221, DOI 10.1111/1460-6984.12211
   Heeringa W., 2004, THESIS
   Jacewicz E, 2014, J SPEECH LANG HEAR R, V57, P389, DOI 10.1044/2014_JSLHR-S-12-0248
   Johnson CE, 2000, J SPEECH LANG HEAR R, V43, P144, DOI 10.1044/jslhr.4301.144
   Jurafsky D., 2000, FREQUENCY EMERGENCE, P229, DOI DOI 10.1075/TSL.45.13JUR
   Keating P. A., 1998, ZAS PAPERS LINGUISTI, V11, P35, DOI DOI 10.1142/9781848160712_
   Kitamura C, 2013, CHILD DEV, V84, P1686, DOI 10.1111/cdev.12068
   Kuznetsova A., 2015, PACKAGE IMERTEST R P
   Lalonde K, 2016, J ACOUST SOC AM, V139, P1713, DOI 10.1121/1.4945590
   Leung AHC, 2012, J MULTILING MULTICUL, V33, P133, DOI 10.1080/01434632.2011.649038
   Levenshtein VI, 1966, SOV PHYS DOKL, V10, P707, DOI DOI 10.1109/TVCG.2012.323
   Major RC, 2002, TESOL QUART, V36, P173, DOI 10.2307/3588329
   Mathot S, 2012, BEHAV RES METHODS, V44, P314, DOI 10.3758/s13428-011-0168-7
   Mattheier K. J., 1990, INT J SOCIOL LANG, V83, P59
   Maye J, 2008, COGNITIVE SCI, V32, P543, DOI 10.1080/03640210802035357
   McDonald M., 2017, LANGUAGE LEARNING DE, V14, P113
   McQueen JM, 2012, LANG LEARN DEV, V8, P317, DOI 10.1080/15475441.2011.641887
   Metsala JL, 1998, WORD RECOGNITION IN BEGINNING LITERACY, P89
   Muench K., 2011, WORD LEARNING UNPUB
   Munro MJ, 2006, STUD SECOND LANG ACQ, V28, P111, DOI 10.1017/S0272263106060049
   Munro MJ, 1999, LANG LEARN, V49, P285, DOI 10.1111/0023-8333.49.s1.8
   Nathan L, 1998, J CHILD LANG, V25, P343, DOI 10.1017/S0305000998003444
   Pettersson E., 2013, P 19 NORD C COMP LIN, V85, P163
   Pinet M, 2011, J ACOUST SOC AM, V130, P1653, DOI 10.1121/1.3613698
   Pluymaekers M, 2005, J ACOUST SOC AM, V118, P2561, DOI 10.1121/1.2011150
   Porretta V, 2016, J PHONETICS, V58, P1, DOI 10.1016/j.wocn.2016.05.006
   Potter CE, 2017, COGNITION, V166, P67, DOI 10.1016/j.cognition.2017.05.031
   R Core Team, 2017, R LANG ENV STAT COMP
   Ramon-Casas M, 2009, COGNITIVE PSYCHOL, V59, P96, DOI 10.1016/j.cogpsych.2009.02.002
   Reinisch E, 2013, J EXP PSYCHOL HUMAN, V39, P75, DOI 10.1037/a0027979
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Samuel AG, 2015, J MEM LANG, V81, P51, DOI 10.1016/j.jml.2015.01.003
   Schafer P., 2016, DECIBEL ULTRA DECIBE
   Schertz J, 2014, CORPUS LINGUIST LING, V10, P329, DOI 10.1515/cllt-2014-0024
   Schmale R, 2011, J CHILD LANG, V38, P1096, DOI 10.1017/S0305000910000619
   Schmale R, 2012, DEVELOPMENTAL SCI, V15, P732, DOI 10.1111/j.1467-7687.2012.01175.x
   Scholer H., 2008, HASE HEIDELBERGER AU
   Schroeder S, 2015, BEHAV RES METHODS, V47, P1085, DOI 10.3758/s13428-014-0528-1
   Sebastian-Galles N, 2005, J MEM LANG, V52, P240, DOI 10.1016/j.jml.2004.11.001
   Seidl A, 2012, FRONT PSYCHOL, V3, DOI [10.3389/fpsyg.2012.00448, 10.3389/fpsyg.2012.00479]
   Sereno J, 2016, APPL PSYCHOLINGUIST, V37, P303, DOI 10.1017/S0142716414000575
   Sidaras SK, 2009, J ACOUST SOC AM, V125, P3306, DOI 10.1121/1.3101452
   Stibbard RM, 2006, J ACOUST SOC AM, V120, P433, DOI 10.1121/1.2203595
   Stringer L. M., 2015, THESIS
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   Tao L., 2016, BILING-LANG COGN, V20, P1030
   Truckenbrodt Hubert, 2002, PHONOLOGY, V19, P77, DOI DOI 10.1017/S095267570200427X
   van Heugten M, 2017, J ACOUST SOC AM, V142, pEL196, DOI 10.1121/1.4997604
   van Heugten M, 2014, J EXP PSYCHOL GEN, V143, P340, DOI 10.1037/a0032192
   Wells J., 1982, ACCENTS ENGLISH, V1
   Witteman MJ, 2014, PSYCHON B REV, V21, P512, DOI 10.3758/s13423-013-0519-8
NR 94
TC 1
Z9 1
U1 1
U2 6
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0305-0009
EI 1469-7602
J9 J CHILD LANG
JI J. Child Lang.
PD MAR
PY 2019
VL 46
IS 2
BP 368
EP 392
AR PII S030500091800051X
DI 10.1017/S030500091800051X
PG 25
WC Psychology, Developmental; Linguistics; Psychology, Experimental
SC Psychology; Linguistics
GA HL1XM
UT WOS:000458497800007
PM 30616700
OA Other Gold
DA 2021-02-24
ER

PT J
AU Wang, HLSR
   Wang, NYH
   Chen, IC
   Tsao, Y
AF Wang, Hsiao-Lan Sharon
   Wang, Natalie Yu-Hsien
   Chen, I-Chen
   Tsao, Yu
TI Auditory identification of frequency-modulated sweeps and reading
   difficulties in Chinese
SO RESEARCH IN DEVELOPMENTAL DISABILITIES
LA English
DT Article
DE Auditory processing; Frequency modulated sweeps; Reading difficulties;
   Chinese Mandarin
ID PHONOLOGICAL AWARENESS; SPEECH-PERCEPTION; DEVELOPMENTAL DYSLEXIA;
   SENSITIVITY; CHILDREN; CUES; TONE; DISCRIMINATION; RECOGNITION; ABILITY
AB Background: In Chinese Mandarin, lexical tones play an important role of providing contrasts in word meaning. They are pitch patterns expressed by frequency-modulated (FM) signals. Yet, few studies have looked at the relationship between low-level auditory processing of frequency signals and Chinese reading skills.
   Aims: The study aims to identify the role of auditory frequency processing in Chinese lexical tone awareness as well as character recognition in Chinese-speaking children.
   Methods: Children with (N = 28) and without (N = 27) developmental dyslexia (DD) were recruited. All participants completed two linguistic tasks, Chinese character recognition and lexical tone awareness, and two auditory frequency processing tasks, frequency discrimination and FM sweep direction identification.
   Results: The results revealed that Chinese-speaking children with DD were significantly poorer at all tasks. Particularly, Chinese character recognition was significantly related to FM sweep identification. Lexical tone awareness was significantly associated with both auditory frequency processing tasks. Regression analyses suggested the influence of FM sweep identification on Chinese character recognition contributed through lexical tone awareness.
   Conclusions and implication: This study suggests that poor auditory frequency processing may associate with Chinese developmental dyslexia with phonological deficits. In support of the phonological deficit hypothesis, what underlies phonological deficit is likely to be auditory-basis. A potential clinical implication is to reinforce auditory perception and sensitivity through intervention for phonological processing.
C1 [Wang, Hsiao-Lan Sharon] Natl Taiwan Normal Univ, Dept Special Educ, Taipei, Taiwan.
   [Wang, Natalie Yu-Hsien; Tsao, Yu] Acad Sinica, Res Ctr Informat Technol Innovat CITI, Taipei, Taiwan.
   [Chen, I-Chen] Univ Taipei, Dept Special Educ, Taipei, Taiwan.
RP Wang, HLSR (corresponding author), Natl Taiwan Normal Univ, Dept Special Educ, Taipei, Taiwan.
EM hlw36@ntnu.edu.tw; nataliewang@citi.sinica.edu.tw;
   g10605204@go.utaipei.edu.tw; yu.tsao@citi.sinica.edu.tw
RI Tsao, Yu/AAP-4779-2020
OI Tsao, Yu/0000-0001-6956-0418
FU Minister of Science and Technology [MOST103-2420-H-003-008-MY3]
FX We thank all our participants, their schools, and their parents.
   H.L.S.W. was supported by the Minister of Science and Technology
   (MOST103-2420-H-003-008-MY3).
CR Cabrera L, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01290
   Cabrera L, 2014, J ACOUST SOC AM, V136, P877, DOI 10.1121/1.4887444
   Castles A, 2014, MIND LANG, V29, P270, DOI 10.1111/mila.12050
   Catts H. W., 2005, CONNECTIONS LANGUAGE
   Ciocca V., 2003, J MULTILINGUAL COMMU, V1, P141, DOI [10.1080/1476967031000090971, DOI 10.1080/1476967031000090971]
   Fu QJ, 1998, J ACOUST SOC AM, V104, P505, DOI 10.1121/1.423251
   GANDOUR J, 1981, J CHINESE LINGUIST, V9, P20
   Goswami U, 2011, DEVELOPMENTAL SCI, V14, P34, DOI 10.1111/j.1467-7687.2010.00955.x
   Goswami U, 2010, READ WRIT, V23, P995, DOI 10.1007/s11145-009-9186-6
   Ho CSH, 2000, READ WRIT, V13, P57, DOI 10.1023/A:1008040922662
   Huang H-S., 2001, GRADED CHINESE CHARA
   Kong YY, 2006, J ACOUST SOC AM, V120, P2830, DOI 10.1121/1.2346009
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Li WS, 2011, J CHILD LANG, V38, P793, DOI 10.1017/S0305000910000346
   Liang Z., 1963, ACTA PHYS SINICA, V26, P85
   Liberman AM, 1996, SPEECH SPECIAL CODE
   Liu HM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02144
   Luo H, 2007, HEARING RES, V224, P75, DOI 10.1016/j.heares.2006.11.007
   McBride-Chang C, 2008, J CHILD PSYCHOL PSYC, V49, P211, DOI 10.1111/j.1469-7610.2007.01837.x
   Meng XZ, 2005, DYSLEXIA, V11, P292, DOI 10.1002/dys.309
   Moll K, 2014, LEARN INSTR, V29, P65, DOI 10.1016/j.learninstruc.2013.09.003
   Ploquin M., 2013, ADV LANGUAGE LIT STU, V4, P68
   Seki A, 2008, BRAIN DEV-JPN, V30, P179, DOI 10.1016/j.braindev.2007.07.006
   Shu H, 2008, DEVELOPMENTAL SCI, V11, P171, DOI 10.1111/j.1467-7687.2007.00654.x
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   Talcott JB, 2000, P NATL ACAD SCI USA, V97, P2952, DOI 10.1073/pnas.040546597
   Tong XH, 2018, J LEARN DISABIL-US, V51, P293, DOI 10.1177/0022219417712018
   Tong XL, 2015, LANG SPEECH, V58, P441, DOI 10.1177/0023830914562988
   Tsao FM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00558
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Wang HLS, 2012, READ WRIT, V25, P509, DOI 10.1007/s11145-010-9284-5
   Wang LC, 2017, CONTEMP EDUC PSYCHOL, V49, P203, DOI 10.1016/j.cedpsych.2017.02.002
   Wang Y, 2003, J ACOUST SOC AM, V113, P1033, DOI 10.1121/1.1531176
   Witton C, 1998, CURR BIOL, V8, P791, DOI 10.1016/S0960-9822(98)70320-3
   Witton C, 2002, J COGNITIVE NEUROSCI, V14, P866, DOI 10.1162/089892902760191090
   Xu L, 2002, J ACOUST SOC AM, V112, P247, DOI 10.1121/1.1487843
   Xu L, 2008, HEARING RES, V242, P132, DOI 10.1016/j.heares.2007.12.010
   Yip M., 2002, TONE
   Zhang JA, 2010, EDUC PSYCHOL REV, V22, P323, DOI 10.1007/s10648-010-9137-4
   Zheng Y, 2017, HEARING RES, V351, P45, DOI 10.1016/j.heares.2017.05.009
   Zhou YL, 2012, EARLY EDUC DEV, V23, P475, DOI 10.1080/10409289.2010.530478
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
NR 42
TC 4
Z9 5
U1 3
U2 13
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0891-4222
J9 RES DEV DISABIL
JI Res. Dev. Disabil.
PD MAR
PY 2019
VL 86
BP 53
EP 61
DI 10.1016/j.ridd.2019.01.006
PG 9
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA HL4SU
UT WOS:000458714200006
PM 30660853
DA 2021-02-24
ER

PT J
AU White, H
   Chroust, A
   Heck, A
   Jubran, R
   Galati, A
   Bhatt, RS
AF White, Hannah
   Chroust, Alyson
   Heck, Alison
   Jubran, Rachel
   Galati, Ashley
   Bhatt, Ramesh S.
TI Categorical Perception of Facial Emotions in Infancy
SO INFANCY
LA English
DT Article
ID 1ST YEAR; SPEECH-PERCEPTION; EXPRESSIONS; REPRESENTATION; FACES;
   DISCRIMINATION; CATEGORIZATION; RECOGNITION; ANGER; DIFFERENTIATION
AB Categorical perception, indicated by superior discrimination between stimuli that cross categorical boundaries than between stimuli within a category, is an efficient manner of classification. The current study examined the development of categorical perception of emotional stimuli in infancy. We used morphed facial images to investigate whether infants find contrasts between emotional facial images that cross categorical boundaries to be more salient than those that do not, while matching the degree of differences in the two contrasts. Five-month-olds exhibited sensitivity to the categorical boundary between sadness and disgust, between happiness and surprise, as well as between sadness and anger but not between anger and disgust. Even 9-month-olds failed to exhibit evidence of a definitive category boundary between anger and disgust. These findings indicate the presence of discrete boundaries between some, but not all, of the basic emotions early in life. Implications of these findings for the major theories of emotion representation are discussed.
C1 [White, Hannah; Chroust, Alyson; Heck, Alison; Jubran, Rachel; Galati, Ashley; Bhatt, Ramesh S.] Univ Kentucky, Lexington, KY USA.
RP Bhatt, RS (corresponding author), Univ Kentucky, Dept Psychol, Lexington, KY 40506 USA.
EM rbhatt@email.uky.edu
RI White, Hannah/AAF-9598-2021; Chroust, Alyson/S-1116-2019
OI Chroust, Alyson/0000-0003-4853-2017
FU National Institute of Child Health and Human DevelopmentUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH Eunice Kennedy Shriver National Institute of Child Health &
   Human Development (NICHD) [HD075829]
FX This research was supported by a grant from the National Institute of
   Child Health and Human Development (HD075829). The authors would like to
   thank the infants and parents who participated in this study. Alyson
   Chroust is now at East Tennessee State University and Ashley Galati is
   at Kent State University at Tuscarawas.
CR Adams RB, 2003, SCIENCE, V300, P1536, DOI 10.1126/science.1082244
   Albuquerque N, 2016, BIOL LETTERS, V12, DOI 10.1098/rsbl.2015.0883
   Altmann CF, 2014, NEUROPSYCHOLOGIA, V64, P13, DOI 10.1016/j.neuropsychologia.2014.09.006
   Anzures G, 2010, DEVELOPMENTAL SCI, V13, P553, DOI 10.1111/j.1467-7687.2009.00900.x
   Aviezer H., 2008, 1 IMPRESSIONS, P255
   BARRERA ME, 1981, CHILD DEV, V52, P203, DOI 10.2307/1129231
   Barrett L.F., 2008, HDB EMOTIONS, P364
   Barrett LF, 2006, PERSPECT PSYCHOL SCI, V1, P28, DOI 10.1111/j.1745-6916.2006.00003.x
   Bhatt RS, 2007, INFANCY, V12, P147, DOI 10.1111/j.1532-7078.2007.tb00238.x
   Bhatt RS, 2016, CHILD DEV PERSPECT, V10, P45, DOI 10.1111/cdep.12162
   Bhatt RS, 2011, INFANCY, V16, P2, DOI 10.1111/j.1532-7078.2010.00048.x
   Bornstein MH, 2003, DEVELOPMENTAL SCI, V6, P585, DOI 10.1111/1467-7687.00314
   BORNSTEIN MH, 1976, SCIENCE, V191, P201, DOI 10.1126/science.1246610
   Brosch T, 2010, COGNITION EMOTION, V24, P377, DOI 10.1080/02699930902975754
   Campos J J, 1992, New Dir Child Dev, P25
   CARON RF, 1985, CHILD DEV, V56, P1552, DOI 10.1111/j.1467-8624.1985.tb00220.x
   Clifford A, 2009, BRAIN COGNITION, V71, P165, DOI 10.1016/j.bandc.2009.05.002
   deGelder B, 1997, COGNITION EMOTION, V11, P1, DOI 10.1080/026999397380005
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   EKMAN P, 1976, ENVIRON PSYCH NONVER, V1, P56, DOI 10.1007/BF01115465
   Ekman P., 1989, HDB SOCIAL PSYCHOPHY, P143
   Ekman P., 2013, EMOTION HUMAN FACE G
   Ekman P., 1972, NEBRASKA S MOTIVATIO, P207, DOI DOI 10.1037/0022-3514.53.4.712
   Ekman P, 2016, PERSPECT PSYCHOL SCI, V11, P31, DOI 10.1177/1745691615596992
   ETCOFF NL, 1992, COGNITION, V44, P227, DOI 10.1016/0010-0277(92)90002-Y
   Farroni T, 2007, EUR J DEV PSYCHOL, V4, P2, DOI 10.1080/17405620601046832
   Grossmann T, 2010, RESTOR NEUROL NEUROS, V28, P219, DOI 10.3233/RNN-2010-0499
   HAVILAND JM, 1987, DEV PSYCHOL, V23, P97, DOI 10.1037/0012-1649.23.1.97
   Hayden A, 2008, PSYCHON B REV, V15, P443, DOI 10.3758/PBR.15.2.443
   Heck A, 2018, INFANT BEHAV DEV, V50, P42, DOI 10.1016/j.infbeh.2017.10.007
   Heck A, 2016, J EXP CHILD PSYCHOL, V147, P100, DOI 10.1016/j.jecp.2016.03.005
   Hock A, 2015, DEV PSYCHOL, V51, P346, DOI 10.1037/a0038743
   Hoehl S, 2017, EVOL HUM BEHAV, V38, P404, DOI 10.1016/j.evolhumbehav.2016.12.001
   Hoehl S, 2010, DEVELOPMENTAL SCI, V13, P813, DOI 10.1111/j.1467-7687.2009.00944.x
   Hu ZH, 2014, PSYCHON B REV, V21, P1214, DOI 10.3758/s13423-014-0603-8
   Hunnius S, 2011, COGNITION EMOTION, V25, P193, DOI 10.1080/15298861003771189
   Izard CE, 2010, EMOT REV, V2, P134, DOI 10.1177/1754073909355003
   IZARD CE, 1994, PSYCHOL BULL, V115, P288, DOI 10.1037/0033-2909.115.2.288
   Kangas A, 2013, PSYCHON B REV, V20, P726, DOI 10.3758/s13423-013-0385-4
   Kotsoni E, 2001, PERCEPTION, V30, P1115, DOI 10.1068/p3155
   LABARBERA JD, 1976, CHILD DEV, V47, P535, DOI 10.2307/1128816
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Lee V, 2015, INFANT BEHAV DEV, V40, P95, DOI 10.1016/j.infbeh.2015.04.006
   Leppanen JM, 2007, CHILD DEV, V78, P232, DOI 10.1111/j.1467-8624.2007.00994.x
   Leppanen JM, 2009, INFANCY, V14, P346, DOI 10.1080/15250000902839393
   LUDEMANN PM, 1988, DEV PSYCHOL, V24, P492, DOI 10.1037/0012-1649.24.4.492
   MARTIN RM, 1975, DEV PSYCHOL, V11, P178, DOI 10.1037/h0076448
   MOORE C, 1994, DEV REV, V14, P349, DOI 10.1006/drev.1994.1014
   NELSON CA, 1979, CHILD DEV, V50, P1239, DOI 10.1111/j.1467-8624.1979.tb02493.x
   Papageorgiou KA, 2014, PSYCHOL SCI, V25, P1371, DOI 10.1177/0956797614531295
   Peltola MJ, 2013, INFANCY, V18, P905, DOI 10.1111/infa.12013
   Pochedly JT, 2012, EMOTION, V12, P1315, DOI 10.1037/a0027998
   Quinn PC, 2011, EMOT REV, V3, P197, DOI 10.1177/1754073910387941
   Quinn PC, 2002, PERCEPTION, V31, P1109, DOI 10.1068/p3331
   Ramsey JL, 2005, DEV REV, V25, P212, DOI 10.1016/j.dr.2005.01.001
   Ruba AL, 2017, DEV PSYCHOL, V53, P1826, DOI 10.1037/dev0000381
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V38, P311
   Sauter DA, 2011, EMOTION, V11, P1479, DOI 10.1037/a0025336
   SCHWARTZ GM, 1985, INFANT BEHAV DEV, V8, P65, DOI 10.1016/S0163-6383(85)80017-5
   SERRANO JM, 1992, DEV PSYCHOBIOL, V25, P411, DOI 10.1002/dev.420250603
   Simion F, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00969
   SLATER A, 1985, J EXP CHILD PSYCHOL, V39, P37, DOI 10.1016/0022-0965(85)90028-1
   Soto FA, 2011, J VISION, V11, DOI 10.1167/11.3.24
   Susskind JM, 2007, NEUROPSYCHOLOGIA, V45, P152, DOI 10.1016/j.neuropsychologia.2006.05.001
   Tottenham N, 2009, PSYCHIAT RES, V168, P242, DOI 10.1016/j.psychres.2008.05.006
   Tukey J., 1977, ADDISON WESLEY SERIE
   Vaillant-Molina M, 2013, INFANCY, V18, pE97, DOI 10.1111/infa.12017
   Walker-Andrews AS, 2005, DEVELOPMENT OF SOCIAL COGNITION AND COMMUNICATION, P93
   WalkerAndrews AS, 1997, PSYCHOL BULL, V121, P437, DOI 10.1037/0033-2909.121.3.437
   Widen SC, 2008, COGNITIVE DEV, V23, P291, DOI 10.1016/j.cogdev.2008.01.002
   Widen SC, 2013, EMOT REV, V5, P72, DOI 10.1177/1754073912451492
   Widen SC, 2010, EMOTION, V10, P651, DOI 10.1037/a0019005
   Widen SC, 2010, EMOTION, V10, P455, DOI 10.1037/a0019151
   YOUNGBROWNE G, 1977, CHILD DEV, V48, P555, DOI 10.1111/j.1467-8624.1977.tb01197.x
   Zieber N, 2015, INFANCY, V20, P1, DOI 10.1111/infa.12064
   Zieber N, 2010, INFANCY, V15, P534, DOI 10.1111/j.1532-7078.2009.00026.x
NR 79
TC 4
Z9 4
U1 1
U2 14
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1525-0008
EI 1532-7078
J9 INFANCY
JI Infancy
PD MAR-APR
PY 2019
VL 24
IS 2
BP 139
EP 161
DI 10.1111/infa.12275
PG 23
WC Psychology, Developmental
SC Psychology
GA HK0TH
UT WOS:000457614000002
PM 32677204
DA 2021-02-24
ER

PT J
AU Jahromi, MZ
   Zahedi, A
   Jensen, J
   Ostergaard, J
AF Jahromi, Mohsen Zareian
   Zahedi, Adel
   Jensen, Jesper
   Ostergaard, Jan
TI Information Loss in the Human Auditory System
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
LA English
DT Article
DE Human auditory system; mutual information; Gaussian mixture model;
   maximum likelihood classifier
ID MODEL
AB From the eardrum to the auditory cortex, where acoustic stimuli are decoded, there are several stages of auditory processing and transmission where information may potentially he lost. In this paper, we aim at quantifying the total information loss in the human auditory system by using information theoretic tools. To do so, we consider a speech communication model, where words are uttered and sent through a noisy channel, and then received and processed by a human listener. We define a notion of information loss that is related to the human word recognition rate. To assess the word recognition rate of humans, we conduct a closed-vocabulary intelligibility test. We derive upper and lower bounds on the information loss. Simulations reveal that the bounds are tight and we observe that the information loss in the human auditory system increases as the signal to noise ratio (SNR) decreases. Our framework also allows us to study whether humans are optimal in terms of speech perception in a noisy environment. Toward that end, we derive optimal classifiers and compare the human and machine performance in terms of information lass and word recognition rate. We observe a higher information loss and lower word recognition rate for humans compared to the optimal classifiers. In fact, depending on the SNR, the machine classifier may outperform humans by as much as 8 dB. This implies that for the speech-in-stationary-noise setup considered here, the human auditory system is suboptimal for recognizing noisy words.
C1 [Jahromi, Mohsen Zareian; Jensen, Jesper; Ostergaard, Jan] Aalborg Univ, Dept Elect Syst, DK-9220 Aalborg, Denmark.
   [Zahedi, Adel; Jensen, Jesper] Oticon AS, DK-2765 Smorum, Denmark.
RP Jahromi, MZ (corresponding author), Aalborg Univ, Dept Elect Syst, DK-9220 Aalborg, Denmark.
EM mzj@es.aau.dk; adza@oticon.com; jesj@oticon.com; jo@es.aau.dk
RI Ostergaard, Jan/I-5693-2014
OI Ostergaard, Jan/0000-0002-3724-6114; Jensen, Jesper/0000-0003-1478-622X
FU VILLUM FONDEN Young Investigator Programme [10095]
FX This work was supported by VILLUM FONDEN Young Investigator Programme
   under Grant 10095. The associate editor coordinating the review of this
   manuscript and approving it for publication was Dr. Roland Badeau.
CR ATICK JJ, 1992, NETWORK-COMP NEURAL, V3, P213, DOI 10.1088/0954-898X/3/2/009
   BIALEK W, 1991, SCIENCE, V252, P1854, DOI 10.1126/science.2063199
   BIALEK W, 1993, PHYSICA A, V200, P581, DOI 10.1016/0378-4371(93)90563-J
   Bialek W., 1991, ADV NEURAL INFORMATI, V3, P363
   CARNEY LH, 1993, J ACOUST SOC AM, V93, P401, DOI 10.1121/1.405620
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Cover T.M., 2012, ELEMENTS INFORM THEO
   Dau T, 1996, J ACOUST SOC AM, V99, P3615, DOI 10.1121/1.414959
   Deller JR, 1993, DISCRETE TIME PROCES
   Geiger B. C., 2013, 9 INT ITG C SYST COM, P1
   Ghitza O., 1986, Computer Speech and Language, V1, P109, DOI 10.1016/S0885-2308(86)80018-3
   Godsill S., 1993, THESIS
   Harczos T, 2013, IEEE T BIOMED CIRC S, V7, P414, DOI 10.1109/TBCAS.2012.2219530
   Huber Marco F, 2008, 2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2008), P181, DOI 10.1109/MFI.2008.4648062
   Huettel LG, 1999, IEEE T BIO-MED ENG, V46, P1432, DOI 10.1109/10.804571
   Jebara T, 2003, LECT NOTES ARTIF INT, V2777, P57, DOI 10.1007/978-3-540-45167-9_6
   Jensen J, 2014, IEEE-ACM T AUDIO SPE, V22, P430, DOI 10.1109/TASLP.2013.2295914
   JOE H, 1989, ANN I STAT MATH, V41, P683, DOI 10.1007/BF00057735
   Kolchinsky A, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19070361
   Lyon R. F., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P1282
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Meyer RM, 2013, ACTA ACUST UNITED AC, V99, P442, DOI 10.3813/AAA.918625
   Najnin S, 2016, INTERSPEECH, P243, DOI 10.21437/Interspeech.2016-1488
   PATTERSON RD, 1995, J ACOUST SOC AM, V98, P1890, DOI 10.1121/1.414456
   Proakis J. G, 1995, DIGITAL COMMUNICATIO
   Renyi A, 1961, 4 BERK S MATH STAT P, P547, DOI DOI 10.1021/JP106846B
   Rieke F, 1995, P ROY SOC B-BIOL SCI, V262, P259, DOI 10.1098/rspb.1995.0204
   Schadler MR, 2015, INT J AUDIOL, V54, P100, DOI 10.3109/14992027.2015.1061708
   Seneff S., 1990, READINGS SPEECH RECO, P101
   Siebert W. M., 1968, RECOGNIZING PATTERNS, P104
   Smith EC, 2006, NATURE, V439, P978, DOI 10.1038/nature04485
   Taghia J, 2014, IEEE-ACM T AUDIO SPE, V22, P6, DOI 10.1109/TASL.2013.2281574
   Tchorz J, 1999, J ACOUST SOC AM, V106, P2040, DOI 10.1121/1.427950
   Wagener K, 2003, INT J AUDIOL, V42, P10, DOI 10.3109/14992020309056080
   Xu Y, 2015, IEEE-ACM T AUDIO SPE, V23, P7, DOI 10.1109/TASLP.2014.2364452
   YANG XW, 1992, IEEE T INFORM THEORY, V38, P824, DOI 10.1109/18.119739
NR 36
TC 0
Z9 0
U1 0
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2329-9290
J9 IEEE-ACM T AUDIO SPE
JI IEEE-ACM Trans. Audio Speech Lang.
PD MAR
PY 2019
VL 27
IS 3
BP 472
EP 481
DI 10.1109/TASLP.2018.2882913
PG 10
WC Acoustics; Engineering, Electrical & Electronic
SC Acoustics; Engineering
GA HF6IA
UT WOS:000454337900001
DA 2021-02-24
ER

PT J
AU Abrams, DA
   Padmanabhan, A
   Chen, TW
   Odriozola, P
   Baker, AE
   Kochalka, J
   Phillips, JM
   Menon, V
AF Abrams, Daniel Arthur
   Padmanabhan, Aarthi
   Chen, Tianwen
   Odriozola, Paola
   Baker, Amanda E.
   Kochalka, John
   Phillips, Jennifer M.
   Menon, Vinod
TI Impaired voice processing in reward and salience circuits predicts
   social communication in children with autism
SO ELIFE
LA English
DT Article
ID YOUNG-CHILDREN; SPECTRUM DISORDER; SPEECH-PERCEPTION; JOINT ATTENTION;
   BRAIN; MOTHERS; FACE; FMRI; RESPONSES; INFANTS
AB Engaging with vocal sounds is critical for children's social-emotional learning, and children with autism spectrum disorder (ASD) often 'tune out' voices in their environment. Little is known regarding the neurobiological basis of voice processing and its link to social impairments in ASD. Here, we perform the first comprehensive brain network analysis of voice processing in children with ASD. We examined neural responses elicited by unfamiliar voices and mother's voice, a biologically salient voice for social learning, and identified a striking relationship between social communication abilities in children with ASD and activation in key structures of reward and salience processing regions. Functional connectivity between voice-selective and reward regions during voice processing predicted social communication in children with ASD and distinguished them from typically developing children. Results support the Social Motivation Theory of ASD by showing reward system deficits associated with the processing of a critical social stimulus, mother's voice, in children with ASD.
   Editorial note: This article has been through an editorial process in which the authors decide how to respond to the issues raised during peer review. The Reviewing Editor's assessment is that minor issues remain unresolved (see decision letter).
C1 [Abrams, Daniel Arthur; Padmanabhan, Aarthi; Chen, Tianwen; Odriozola, Paola; Baker, Amanda E.; Kochalka, John; Phillips, Jennifer M.] Stanford Univ, Sch Med, Dept Psychiat & Behav Sci, Stanford, CA 94305 USA.
   [Menon, Vinod] Stanford Univ, Sch Med, Program Neurosci, Stanford, CA 94305 USA.
   [Menon, Vinod] Stanford Univ, Sch Med, Dept Neurol & Neurol Sci, Stanford, CA 94305 USA.
RP Abrams, DA (corresponding author), Stanford Univ, Sch Med, Dept Psychiat & Behav Sci, Stanford, CA 94305 USA.; Menon, V (corresponding author), Stanford Univ, Sch Med, Program Neurosci, Stanford, CA 94305 USA.; Menon, V (corresponding author), Stanford Univ, Sch Med, Dept Neurol & Neurol Sci, Stanford, CA 94305 USA.
EM daa@stanford.edu; menon@stanford.edu
OI Phillips, Jennifer/0000-0002-6360-2346; Abrams,
   Daniel/0000-0002-1255-1200
FU National Institute of Mental HealthUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute of Mental Health (NIMH) [MH102428, MH084164]; Brain and
   Behavior Research Foundation; Stanford School of Medicine, Stanford
   Medicine, Stanford University [UL1TR001085]; National Center for
   Advancing Translational SciencesUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Center for Advancing Translational Sciences (NCATS) [UL1TR001085];
   National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [DC011095]; Singer Family Foundation;
   Simons Foundation [308939]; NATIONAL CENTER FOR ADVANCING TRANSLATIONAL
   SCIENCESUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Center for Advancing
   Translational Sciences (NCATS) [UL1TR001085, UL1TR001085] Funding
   Source: NIH RePORTER; NATIONAL INSTITUTE OF MENTAL HEALTHUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute of Mental Health (NIMH) [R01MH084164,
   R01MH084164, R01MH084164] Funding Source: NIH RePORTER
FX National Institute of Mental Health MH102428 Daniel Arthur Abrams; Brain
   and Behavior Research Foundation NARSAD Young Investigator Grant Daniel
   Arthur Abrams; Stanford School of Medicine, Stanford Medicine, Stanford
   University UL1TR001085 Daniel Arthur Abrams; National Center for
   Advancing Translational Sciences UL1TR001085 Daniel Arthur Abrams;
   National Institute on Deafness and Other Communication Disorders
   DC011095 Vinod Menon; National Institute of Mental Health MH084164 Vinod
   Menon; Singer Family Foundation Vinod Menon Simons Foundation 308939
   Vinod Menon; The funders had no role in study design, data collection
   and interpretation, or the decision to submit the work for publication.
CR Abrams DA, 2008, J NEUROSCI, V28, P3958, DOI 10.1523/JNEUROSCI.0187-08.2008
   Abrams DA, 2016, P NATL ACAD SCI USA, V113, P6295, DOI 10.1073/pnas.1602948113
   Abrams DA, 2013, P NATL ACAD SCI USA, V110, P12060, DOI 10.1073/pnas.1302982110
   Abrams DA, 2013, EUR J NEUROSCI, V37, P1458, DOI 10.1111/ejn.12173
   Abrams DA, 2011, CEREB CORTEX, V21, P1507, DOI 10.1093/cercor/bhq198
   ADAMS RE, 1979, DEV PSYCHOL, V15, P269
   American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU
   Baron-Cohen S, 1999, EUR J NEUROSCI, V11, P1891, DOI 10.1046/j.1460-9568.1999.00621.x
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   BRICKER PD, 1976, CONT ISSUES EXPT PHO, P295
   Chevallier C, 2012, TRENDS COGN SCI, V16, P231, DOI 10.1016/j.tics.2012.02.007
   CHRISTOPHE A, 1994, J ACOUST SOC AM, V95, P1570, DOI 10.1121/1.408544
   Clements CC, 2018, JAMA PSYCHIAT, V75, P797, DOI 10.1001/jamapsychiatry.2018.1100
   Cohen JR, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00047
   Dalton KM, 2005, NAT NEUROSCI, V8, P519, DOI 10.1038/nn1421
   Dapretto M, 2006, NAT NEUROSCI, V9, P28, DOI 10.1038/nn1611
   Dawson G, 2002, CHILD DEV, V73, P700, DOI 10.1111/1467-8624.00433
   Dawson G, 2004, DEV PSYCHOL, V40, P271, DOI 10.1037/0012-1649.40.2.271
   Dawson G, 2010, PEDIATRICS, V125, pE17, DOI 10.1542/peds.2009-0958
   DECASPER AJ, 1980, SCIENCE, V208, P1174, DOI 10.1126/science.7375928
   Delprato DJ, 2001, J AUTISM DEV DISORD, V31, P315, DOI 10.1023/A:1010747303957
   Di Martino A, 2011, BIOL PSYCHIAT, V69, P847, DOI 10.1016/j.biopsych.2010.10.029
   Dichter GS, 2012, J AUTISM DEV DISORD, V42, P147, DOI 10.1007/s10803-011-1221-1
   DiLavore P. C., 2012, AUTISM DIAGNOSTIC OB
   Dinstein I, 2012, NEURON, V75, P981, DOI 10.1016/j.neuron.2012.07.026
   FORMAN SD, 1995, MAGNET RESON MED, V33, P636, DOI 10.1002/mrm.1910330508
   Friston KJ, 1997, NEUROIMAGE, V6, P218, DOI 10.1006/nimg.1997.0291
   Gervais H, 2004, NAT NEUROSCI, V7, P801, DOI 10.1038/nn1291
   Glover GH, 2001, MAGNET RESON MED, V46, P515, DOI 10.1002/mrm.1222
   Harms MB, 2010, NEUROPSYCHOL REV, V20, P290, DOI 10.1007/s11065-010-9138-6
   Harstad L, 2016, EARLY WARNING SIGNS
   Hecker MH., 1971, SPEAKER RECOGNITION
   Imafuku M, 2014, NEUROIMAGE, V103, P476, DOI 10.1016/j.neuroimage.2014.08.034
   KANNER L, 1968, ACTA PAEDOPSYCHIATR, V35, P100
   Kleinhans NM, 2009, AM J PSYCHIAT, V166, P467, DOI 10.1176/appi.ajp.2008.07101681
   KLIN A, 1991, J AUTISM DEV DISORD, V21, P29, DOI 10.1007/BF02206995
   KOEGEL LK, 2005, PSYCHOSOCIAL TREATME, P633
   Koegel R.L., 2006, PIVOTAL RESPONSE TRE
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   Kuhl PK, 2005, DEVELOPMENTAL SCI, V8, pF1, DOI 10.1111/j.1467-7687.2004.00384.x
   Lamb M. E., 1981, ADV INFANCY RES, V1, P101
   Leekam SR, 2007, J AUTISM DEV DISORD, V37, P894, DOI 10.1007/s10803-006-0218-7
   Liu HM, 2003, DEVELOPMENTAL SCI, V6, pF1, DOI 10.1111/1467-7687.00275
   Lombardo MV, 2015, NEURON, V86, P567, DOI 10.1016/j.neuron.2015.03.023
   Lord C, 2000, J AUTISM DEV DISORD, V30, P205, DOI 10.1023/A:1005592401947
   LORD C, 1994, J AUTISM DEV DISORD, V24, P659, DOI 10.1007/BF02172145
   Marco EJ, 2011, PEDIATR RES, V69, p48R, DOI [10.1203/PDR.0b013e3182130c54, 10.1109/SPL.2011.5782616]
   Markram H, 2007, FRONT NEUROSCI-SWITZ, V1, P77, DOI 10.3389/neuro.01.1.1.006.2007
   McLaren DG, 2012, NEUROIMAGE, V61, P1277, DOI 10.1016/j.neuroimage.2012.03.068
   Menon V, 2011, TRENDS COGN SCI, V15, P483, DOI 10.1016/j.tics.2011.08.003
   Moes DR, 2002, J AUTISM DEV DISORD, V32, P519, DOI 10.1023/A:1021298729297
   Mundy P, 2000, COMM LANG INTERVEN, V9, P55
   Mundy P, 2007, CURR DIR PSYCHOL SCI, V16, P269, DOI 10.1111/j.1467-8721.2007.00518.x
   *NAT RES COUNC, 2001, ED CHILDR AUT COMM E
   Nee DE., 2018, BIORXIV, DOI [10.1101/352633, DOI 10.1101/352633]
   Pelphrey KA, 2011, J CHILD PSYCHOL PSYC, V52, P631, DOI 10.1111/j.1469-7610.2010.02349.x
   Pierce K, 2001, BRAIN, V124, P2059, DOI 10.1093/brain/124.10.2059
   Purhonen M, 2004, INT J PSYCHOPHYSIOL, V52, P257, DOI 10.1016/j.ijpsycho.2003.11.003
   Richey JA, 2014, SOC COGN AFFECT NEUR, V9, P367, DOI 10.1093/scan/nss146
   Risi S, 2006, J AM ACAD CHILD PSY, V45, P1094, DOI 10.1097/01.chi.0000227880.42780.0e
   Russo N, 2010, AUTISM RES, V3, P253, DOI 10.1002/aur.152
   Schelinski S, 2016, SOC COGN AFFECT NEUR, V11, P1812, DOI 10.1093/scan/nsw089
   Schultz RT, 2000, ARCH GEN PSYCHIAT, V57, P331, DOI 10.1001/archpsyc.57.4.331
   Scott-Van Zeeland AA, 2010, AUTISM RES, V3, P53, DOI 10.1002/aur.122
   Semel E. M., 2003, CLIN EVALUATION LANG
   Sheinkopf SJ, 1998, J AUTISM DEV DISORD, V28, P15, DOI 10.1023/A:1026054701472
   Smith SM, 2004, NEUROIMAGE, V23, pS208, DOI 10.1016/j.neuroimage.2004.07.051
   STOKES TF, 1977, J APPL BEHAV ANAL, V10, P349, DOI 10.1901/jaba.1977.10-349
   THOMAN EB, 1977, CHILD DEV, V48, P563, DOI 10.2307/1128654
   Uddin Lucina Q, 2013, Front Hum Neurosci, V7, P458, DOI 10.3389/fnhum.2013.00458
   Uddin LQ, 2013, JAMA PSYCHIAT, V70, P869, DOI 10.1001/jamapsychiatry.2013.104
   von dem Hagen EAH, 2013, SOC COGN AFFECT NEUR, V8, P694, DOI 10.1093/scan/nss053
   Vul E, 2009, PERSPECT PSYCHOL SCI, V4, P274, DOI 10.1111/j.1745-6924.2009.01125.x
   Wagner R, 1999, COMPREHENSIVE TEST P
   Ward B.D, 2000, SIMULTANEOUS INFEREN
   Wass S, 2011, BRAIN COGNITION, V75, P18, DOI 10.1016/j.bandc.2010.10.005
   Wechsler D, 1999, WASI WECHSLER ABBREV
   Whitehouse AJO, 2008, DEVELOPMENTAL SCI, V11, P516, DOI 10.1111/j.1467-7687.2008.00697.x
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
   Yerys BE, 2009, HUM BRAIN MAPP, V30, P3426, DOI 10.1002/hbm.20767
NR 80
TC 5
Z9 5
U1 3
U2 12
PU ELIFE SCIENCES PUBLICATIONS LTD
PI CAMBRIDGE
PA SHERATON HOUSE, CASTLE PARK, CAMBRIDGE, CB3 0AX, ENGLAND
SN 2050-084X
J9 ELIFE
JI eLife
PD FEB 26
PY 2019
VL 8
AR e39906
DI 10.7554/eLife.39906
PG 33
WC Biology
SC Life Sciences & Biomedicine - Other Topics
GA HM9MZ
UT WOS:000459810400001
PM 30806350
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Profant, O
   Jilek, M
   Bures, Z
   Vencovsky, V
   Kucharova, D
   Svobodova, V
   Korynta, J
   Syka, J
AF Profant, Oliver
   Jilek, Milan
   Bures, Zbynek
   Vencovsky, Vaclav
   Kucharova, Diana
   Svobodova, Veronika
   Korynta, Jiri
   Syka, Josef
TI Functional Age-Related Changes Within the Human Auditory System Studied
   by Audiometric Examination
SO FRONTIERS IN AGING NEUROSCIENCE
LA English
DT Article
DE presbycusis; central hearing loss; temporal processing; laterogram;
   cognition
ID SPEECH RECOGNITION PERFORMANCE; PRODUCT OTOACOUSTIC EMISSIONS;
   HEARING-LOSS; CONTRALATERAL SUPPRESSION; DURATION DISCRIMINATION; SOUND
   LOCALIZATION; OLDER; NOISE; PRESBYCUSIS; RESPONSES
AB Age related hearing loss (presbycusis) is one of the most common sensory deficits in the aging population. The main subjective ailment in the elderly is the deterioration of speech understanding, especially in a noisy environment, which cannot solely be explained by increased hearing thresholds. The examination methods used in presbycusis are primarily focused on the peripheral pathologies (e.g., hearing sensitivity measured by hearing thresholds), with only a limited capacity to detect the central lesion. In our study, auditory tests focused on central auditory abilities were used in addition to classical examination tests, with the aim to compare auditory abilities between an elderly group (elderly, mean age 70.4 years) and young controls (young, mean age 24.4 years) with clinically normal auditory thresholds, and to clarify the interactions between peripheral and central auditory impairments. Despite the fact that the elderly were selected to show natural age-related deterioration of hearing (auditory thresholds did not exceed 20 dB HL for main speech frequencies) and with clinically normal speech reception thresholds (SRTs), the detailed examination of their auditory functions revealed deteriorated processing of temporal parameters [gap detection threshold (GDT), interaural time difference (ITD) detection] which was partially responsible for the altered perception of distorted speech (speech in babble noise, gated speech). An analysis of interactions between peripheral and central auditory abilities, showed a stronger influence of peripheral function than temporal processing ability on speech perception in silence in the elderly with normal cognitive function. However, in a more natural environment mimicked by the addition of background noise, the role of temporal processing increased rapidly.
C1 [Profant, Oliver; Jilek, Milan; Bures, Zbynek; Vencovsky, Vaclav; Kucharova, Diana; Svobodova, Veronika; Syka, Josef] Czech Acad Sci, Inst Expt Med, Dept Auditory Neurosci, Prague, Czech Republic.
   [Profant, Oliver] Charles Univ Prague, Dept Otorhinolaryngol, Fac Hosp Kralovske Vinohrady, Prague, Czech Republic.
   [Profant, Oliver] Charles Univ Prague, Fac Med 3, Prague, Czech Republic.
   [Bures, Zbynek] Coll Polytech, Dept Tech Studies, Jihlava, Czech Republic.
   [Kucharova, Diana; Svobodova, Veronika] Charles Univ Prague, Univ Hosp Motol, Fac Med 1, Dept Otorhinolaryngol & Head & Neck Surg, Prague, Czech Republic.
   [Korynta, Jiri] Eye Clin Liberec, Liberec, Czech Republic.
RP Profant, O (corresponding author), Czech Acad Sci, Inst Expt Med, Dept Auditory Neurosci, Prague, Czech Republic.; Profant, O (corresponding author), Charles Univ Prague, Dept Otorhinolaryngol, Fac Hosp Kralovske Vinohrady, Prague, Czech Republic.; Profant, O (corresponding author), Charles Univ Prague, Fac Med 3, Prague, Czech Republic.
EM oliver.profant@iem.cas.cz
FU GACR (Czech acronym of the Czech Science Foundation, Grantova Agentura
   Ceske Republiky) [16-16729S]
FX This work was supported by the grant GACR (Czech acronym of the Czech
   Science Foundation, Grantova Agentura Ceske Republiky) 16-16729S.
CR ABEL SM, 1972, J ACOUST SOC AM, V51, P1219, DOI 10.1121/1.1912963
   Abel SM, 1996, SCAND AUDIOL, V25, P3, DOI 10.3109/01050399609047549
   Abel SM, 2000, J ACOUST SOC AM, V108, P743, DOI 10.1121/1.429607
   Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Anderson S, 2012, J NEUROSCI, V32, P14156, DOI 10.1523/JNEUROSCI.2176-12.2012
   Babkoff H, 2002, HEARING RES, V165, P117, DOI 10.1016/S0378-5955(02)00292-7
   Bopp KL, 2009, PSYCHOL AGING, V24, P968, DOI 10.1037/a0017731
   Caspary DM, 2005, J NEUROSCI, V25, P10952, DOI 10.1523/JNEUROSCI.2451-05.2005
   CHABA, 1998, J ACOUST SOC AM, V83, P859
   Dlouha O, 2013, OTORHINOLARYNGOL FON, V61, P240
   Fitzgibbons PJ, 2011, J ACOUST SOC AM, V129, P1490, DOI 10.1121/1.3533728
   FITZGIBBONS PJ, 1994, J SPEECH HEAR RES, V37, P662, DOI 10.1044/jshr.3703.662
   Fitzgibbons PJ, 1995, J ACOUST SOC AM, V98, P3140, DOI 10.1121/1.413803
   Fogerty D, 2015, J ACOUST SOC AM, V137, P3487, DOI 10.1121/1.4921603
   Fowler E. P, 1942, JAMA-J AM MED ASSOC, V119, P1108
   Frisina DR, 1997, HEARING RES, V106, P95, DOI 10.1016/S0378-5955(97)00006-3
   Frisina RD, 2006, HEARING RES, V216, P216, DOI 10.1016/j.heares.2006.02.003
   Fullgrabe C, 2014, J ACOUST SOC AM, V136, pEL185, DOI 10.1121/1.4890201
   GARDNER G, 1988, ANN OTO RHINOL LARYN, V97, P55, DOI 10.1177/000348948809700110
   GATES GA, 1990, EAR HEARING, V11, P247, DOI 10.1097/00003446-199008000-00001
   GATES GA, 1991, ACTA OTO-LARYNGOL, V111, P240, DOI 10.3109/00016489109137382
   Giroud N, 2018, BRAIN STRUCT FUNCT, V223, P145, DOI 10.1007/s00429-017-1477-0
   Gordon-Salant S, 2014, J ACOUST SOC AM, V136, pEL268, DOI 10.1121/1.4895014
   GORDONSALANT S, 1993, J SPEECH HEAR RES, V36, P1276, DOI 10.1044/jshr.3606.1276
   GordonSalant S, 1997, J SPEECH LANG HEAR R, V40, P423, DOI 10.1044/jslhr.4002.423
   Grady CL, 2008, ANN NY ACAD SCI, V1124, P127, DOI 10.1196/annals.1440.009
   Grassi M, 2013, FRONT AGING NEUROSCI, V5, DOI 10.3389/fnagi.2013.00059
   Greenber S, 1996, PRINCIPLES EXPT PHON, P364
   Grose JH, 2006, J ACOUST SOC AM, V119, P2305, DOI 10.1121/1.2172169
   Grose JH, 2010, EAR HEARING, V31, P755, DOI 10.1097/AUD.0b013e3181e627e7
   He NJ, 1999, J ACOUST SOC AM, V106, P966, DOI 10.1121/1.427109
   Helleman HW, 2010, INT J AUDIOL, V49, P410, DOI 10.3109/14992020903527616
   Hickox AE, 2017, HEARING RES, V349, P164, DOI 10.1016/j.heares.2016.12.010
   Humes L E, 1996, J Am Acad Audiol, V7, P161
   Humes LE, 2012, J AM ACAD AUDIOL, V23, P635, DOI 10.3766/jaaa.23.8.5
   Jacobson M, 2003, LARYNGOSCOPE, V113, P1707, DOI 10.1097/00005537-200310000-00009
   Jayakody DMP, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00125
   Jilek M, 2014, J ACOUST SOC AM, V136, P1821, DOI 10.1121/1.4894719
   Kim SH, 2002, AUDIOL NEURO-OTOL, V7, P348, DOI 10.1159/000066159
   Kujawa SG, 2009, J NEUROSCI, V29, P14077, DOI 10.1523/JNEUROSCI.2845-09.2009
   Liberman MC, 2017, HEARING RES, V349, P138, DOI 10.1016/j.heares.2017.01.003
   Lin FR, 2011, NEUROPSYCHOLOGY, V25, P763, DOI 10.1037/a0024238
   Matthews LJ, 1997, J SPEECH LANG HEAR R, V40, P208, DOI 10.1044/jslhr.4001.208
   Mazelova J, 2003, EXP GERONTOL, V38, P87, DOI 10.1016/S0531-5565(02)00155-9
   Mitsudo T, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00763
   Moon IJ, 2015, J NEUROSCI, V35, P14260, DOI 10.1523/JNEUROSCI.5091-14.2015
   Moore BCJ, 2016, ADV EXP MED BIOL, V894, P1, DOI 10.1007/978-3-319-25474-6_1
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   NOBLE W, 1994, J ACOUST SOC AM, V95, P992, DOI 10.1121/1.408404
   Ouda L, 2012, EXP GERONTOL, V47, P497, DOI 10.1016/j.exger.2012.04.003
   Ozmeral EJ, 2016, J NEUROPHYSIOL, V116, P2720, DOI 10.1152/jn.00560.2016
   Ozmeral EJ, 2016, NEUROBIOL AGING, V43, P72, DOI 10.1016/j.neurobiolaging.2015.12.024
   Pannese A, 2015, HEARING RES, V328, P67, DOI 10.1016/j.heares.2015.07.003
   Pearman A, 2000, EXP AGING RES, V26, P383, DOI 10.1080/036107300750015769
   Pecka M, 2008, J NEUROSCI, V28, P6914, DOI 10.1523/JNEUROSCI.1660-08.2008
   Pichora-Fuller M Kathleen, 2006, Trends Amplif, V10, P29, DOI 10.1177/108471380601000103
   Pickett J. M., 1999, ACOUSTICS SPEECH COM
   Popelar J, 2013, NEUROSCI LETT, V553, P216, DOI 10.1016/j.neulet.2013.08.042
   Profant O, 2014, NEUROSCIENCE, V260, P87, DOI 10.1016/j.neuroscience.2013.12.010
   Profant O, 2017, CLIN NEUROPHYSIOL, V128, P1946, DOI 10.1016/j.clinph.2017.07.403
   Profant O, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0116692
   Profant O, 2013, EXP GERONTOL, V48, P795, DOI 10.1016/j.exger.2013.04.012
   Pronk M, 2013, EAR HEARING, V34, P722, DOI 10.1097/AUD.0b013e3182994eee
   Reban J., 2006, GER REV, V4, P224
   Rektorova I, 2011, NEUROL PRAX SG, V12, P37
   Ross B, 2007, J NEUROSCI, V27, P11172, DOI 10.1523/JNEUROSCI.1813-07.2007
   Rybalko N, 2010, BEHAV BRAIN RES, V209, P123, DOI 10.1016/j.bbr.2010.01.028
   Schatteman TA, 2008, NEUROSCIENCE, V154, P329, DOI 10.1016/j.neuroscience.2008.02.025
   SCHUKNECHT HF, 1993, ANN OTO RHINOL LARYN, V102, P1
   Seeman M, 1960, CZECH SPEECH AUDIOME
   Sergeyenko Y, 2013, J NEUROSCI, V33, P13686, DOI 10.1523/JNEUROSCI.1783-13.2013
   Sheldon S, 2008, J ACOUST SOC AM, V123, P489, DOI 10.1121/1.2783762
   Singh G, 2008, J ACOUST SOC AM, V124, P1294, DOI 10.1121/1.2949399
   Snell KB, 1997, J ACOUST SOC AM, V101, P2214, DOI 10.1121/1.418205
   Strouse A, 1998, J ACOUST SOC AM, V104, P2385, DOI 10.1121/1.423748
   Sussman ES, 2007, PERCEPT PSYCHOPHYS, V69, P136, DOI 10.3758/BF03194460
   Suta D, 2011, EXP GERONTOL, V46, P739, DOI 10.1016/j.exger.2011.05.004
   Syka J, 2002, PHYSIOL REV, V82, P601, DOI 10.1152/physrev.00002.2002
   Syka J, 2010, HEARING RES, V264, P70, DOI 10.1016/j.heares.2009.11.003
   Tadros SF, 2005, AUDIOL NEURO-OTOL, V10, P44, DOI 10.1159/000082307
   Ueberfuhr MA, 2016, HEARING RES, V332, P137, DOI 10.1016/j.heares.2015.11.006
   Vielsmeier V, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/302515
   Walton JP, 1998, J NEUROSCI, V18, P2764
   Wiley TL, 1998, J SPEECH LANG HEAR R, V41, P1061, DOI 10.1044/jslhr.4105.1061
   Williamson TT, 2015, CELL TISSUE RES, V361, P359, DOI 10.1007/s00441-014-2003-9
   Willott J F, 1996, J Am Acad Audiol, V7, P141
   Wingfield A, 1996, J Am Acad Audiol, V7, P175
   Wingfield A, 2006, J AM ACAD AUDIOL, V17, P487, DOI 10.3766/jaaa.17.7.4
   Zeng FG, 2005, J NEUROPHYSIOL, V93, P3050, DOI 10.1152/jn.00985.2004
NR 89
TC 3
Z9 3
U1 0
U2 9
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1663-4365
J9 FRONT AGING NEUROSCI
JI Front. Aging Neurosci.
PD FEB 26
PY 2019
VL 11
AR 26
DI 10.3389/fnagi.2019.00026
PG 16
WC Geriatrics & Gerontology; Neurosciences
SC Geriatrics & Gerontology; Neurosciences & Neurology
GA HM8HI
UT WOS:000459720400001
PM 30863300
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Best, CT
AF Best, Catherine T.
TI The Diversity of Tone Languages and the Roles of Pitch Variation in
   Non-tone Languages: Considerations for Tone Perception Research
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE tone processing; non-native speech perception; prosodic hierarchy; tone
   language diversity; non-tone languages
ID SPOKEN WORD RECOGNITION; LEXICAL TONE; MANDARIN TONES; CHINESE; FRENCH;
   VOWEL; ENGLISH; SPEECH; DISCRIMINATION; IDENTIFICATION
C1 [Best, Catherine T.] Western Sydney Univ, MARCS Inst, Penrith, NSW, Australia.
RP Best, CT (corresponding author), Western Sydney Univ, MARCS Inst, Penrith, NSW, Australia.
EM c.best@westernsydney.edu.au
FU Australian Research CouncilAustralian Research Council [DP130104237]
FX Preparation of this paper was supported in part by Australian Research
   Council grant DP130104237.
CR Beckman M. E., 1986, PHONOLOGY YB, V3, P255, DOI [DOI 10.1017/S095267570000066X, 10.1017/S095267570000066X]
   Beckman M. E., 2006, PROSODIC TYPOLOGY PH, P9
   Best C. T., 1995, SPEECH PERCEPTION LI, P167
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Braun B, 2011, J PHONETICS, V39, P585, DOI 10.1016/j.wocn.2011.06.002
   Burnham D, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02190
   Chandrasekaran B, 2010, J ACOUST SOC AM, V128, P456, DOI 10.1121/1.3445785
   Chao Y. R., 1930, MAITRE PHONETIQUE, V45, P24
   Chen A, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00297
   Cheng YY, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00448
   Choi W, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00492
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   DUANMU S, 1994, LINGUIST INQ, V25, P555
   Duanmu San, 1990, THESIS
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Francis AL, 2008, J PHONETICS, V36, P268, DOI 10.1016/j.wocn.2007.06.005
   Gao M., 2009, CHINESE J PHONETICS, V2, P43
   Gotz A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00477
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Harrison P, 2000, LINGUA, V110, P581, DOI 10.1016/S0024-3841(00)00003-6
   Hay JF, 2015, CHILD DEV, V86, P10, DOI 10.1111/cdev.12269
   Hoonhorst I, 2009, J EXP CHILD PSYCHOL, V104, P353, DOI 10.1016/j.jecp.2009.07.005
   Hu F., 2016, SPEECH PROSODY, V2016, P302, DOI [10.21437/SpeechProsody.2016-62, DOI 10.21437/SPEECHPROSODY.2016-62]
   Hyman L. M., 2011, HDB PHONOLOGICAL THE, V75, P50
   Hyman L. M., 2011, BLACKWELL COMPANION, V2, P1078, DOI [10.1515/9783110246223.50, DOI 10.1515/9783110246223.50]
   Hyman L. M., 2016, P TON ASP LANG 2016, V2016, P6, DOI [10.21437/TAL.2016-2, DOI 10.21437/TAL.2016-2]
   Jones D., 1944, ACTA LINGUISTICA, V4, P10, DOI [10.1080/03740463.1944.10410902, DOI 10.1080/03740463.1944.10410902]
   Kager R, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02093
   Li XJ, 2010, NEUROREPORT, V21, P690, DOI 10.1097/WNR.0b013e32833b0a10
   Lin Y. H., 1989, THESIS
   Liu L, 2006, NEUROIMAGE, V29, P515, DOI 10.1016/j.neuroimage.2005.07.046
   Liu LQ, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00162
   Liu LQ, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00117
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Ma WY, 2017, COGNITION, V159, P139, DOI 10.1016/j.cognition.2016.11.011
   MADDIESON I, 1984, J PHONETICS, V12, P9, DOI 10.1016/S0095-4470(19)30845-9
   Maddieson Ian, 2013, WORLD ATLAS LANGUAGE
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   McGinnis S, 1997, MOD LANG J, V81, P228, DOI 10.2307/328789
   Mucke D, 2012, CONSONANT CLUSTERS S, P205, DOI DOI 10.1515/9781614510772.205
   Nazzi T, 1998, INFANT BEHAV DEV, V21, P779, DOI 10.1016/S0163-6383(98)90044-3
   Nespor Marina, 1986, PROSODIC PHONOLOGY
   Ota M, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02354
   PACKARD JL, 1986, BRAIN LANG, V29, P212, DOI 10.1016/0093-934X(86)90045-3
   Pierrehumbert J., 1988, JAPANESE TONE STRUCT
   Poltrock S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01211
   Quam C, 2010, J MEM LANG, V62, P135, DOI 10.1016/j.jml.2009.09.003
   Ramachers S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01652
   Ratliff M., 2015, OXFORD HDB HIST PHON, P245, DOI [10.1093/oxfordhb/9780199232819.013.021, DOI 10.1093/OXFORDHB/9780199232819.013.021]
   Reid A, 2015, ATTEN PERCEPT PSYCHO, V77, P571, DOI 10.3758/s13414-014-0791-3
   Remijsen B., 2016, OXFORD RES ENCY LING, DOI [10.1093/acrefore/9780199384655.013.109, DOI 10.1093/ACREFORE/9780199384655.013.109]
   Sato Y, 2010, J COGNITIVE NEUROSCI, V22, P2503, DOI 10.1162/jocn.2009.21377
   Selkirk E., 1986, PHONOLOGY YB, V3, P371, DOI DOI 10.1017/S0952675700000695
   Shaw JA, 2016, J SPEECH LANG HEAR R, V59, pS1566, DOI 10.1044/2015_JSLHR-S-15-0031
   Shi RS, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01117
   Silva D. J., 2006, PHONOLOGY, V23, P287, DOI DOI 10.1017/S0952675706000911
   Silva DJ, 2006, KOREAN LINGUIST, V13, P1, DOI 10.1075/kl.l3.01djs
   Singh L, 2016, J PHONETICS, V55, P109, DOI 10.1016/j.wocn.2015.12.005
   Singh L, 2015, COGNITION, V142, P1, DOI 10.1016/j.cognition.2015.05.010
   Singh L, 2014, DEVELOPMENTAL SCI, V17, P94, DOI 10.1111/desc.12097
   Singh L, 2012, COGNITION, V124, P128, DOI 10.1016/j.cognition.2012.05.008
   Skoruppa K, 2013, LANG LEARN DEV, V9, P88, DOI 10.1080/15475441.2012.693881
   Skoruppa K, 2009, DEVELOPMENTAL SCI, V12, P914, DOI 10.1111/j.1467-7687.2009.00835.x
   So CK, 2014, STUD SECOND LANG ACQ, V36, P195, DOI 10.1017/S0272263114000047
   So CK, 2011, POZ STUD CONTEMP LIN, V47, P133, DOI 10.2478/psicl-2011-0011
   So CK, 2010, LANG SPEECH, V53, P273, DOI 10.1177/0023830909357156
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Tsao FM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00558
   WANG WSY, 1967, INT J AM LINGUIST, V33, P93, DOI 10.1086/464946
   Werker JF, 1999, ANNU REV PSYCHOL, V50, P509, DOI 10.1146/annurev.psych.50.1.509
   WHALEN DH, 1993, J ACOUST SOC AM, V93, P2152, DOI 10.1121/1.406678
   Wong PCM, 2007, APPL PSYCHOLINGUIST, V28, P565, DOI 10.1017/S0142716407070312
   Wong PCM, 2007, HUM BRAIN MAPP, V28, P995, DOI 10.1002/hbm.20330
   Wong PS, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01450
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   Yip Moira, 2002, TONE, DOI [10.1017/CBO9781139164559, DOI 10.1017/CBO9781139164559]
NR 77
TC 3
Z9 3
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD FEB 26
PY 2019
VL 10
AR 364
DI 10.3389/fpsyg.2019.00364
PG 7
WC Psychology, Multidisciplinary
SC Psychology
GA HM7TB
UT WOS:000459681000001
PM 30863341
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Babel, M
   Senior, B
   Bishop, S
AF Babel, Molly
   Senior, Brianne
   Bishop, Sophie
TI Do social preferences matter in lexical retuning?
SO LABORATORY PHONOLOGY
LA English
DT Article
DE voice evaluation; perceptual learning; lexical decision; priming;
   adaptation
ID SPEECH-PERCEPTION; LANGUAGE; ADAPTATION; DISCRIMINATION; IDENTIFICATION;
   INTEGRATION; JUDGMENTS; RECOGNIZE; ATTENTION; FLUENCY
AB In perceiving spoken language, listeners not only recognize and comprehend the intended meaning of the speaker's words and phrases; they also assess the social dimensions of the speaker. In the present study, we ask whether perceptual learning - a process by which listeners adapt to novel pronunciations - is modulated by listeners' social preferences. To this end, we use a novel accent exhibiting a back vowel lowering chain shift in pleasant and unpleasant conditions in a lexically guided perceptual learning paradigm to test whether listeners adapt less to the unpleasant guise. Experiment 1 confirms that listeners disprefer the unpleasant guise. Using a lexical decision task as a measure of lexical adaptation, Experiment 2 indicates that listeners in the pleasant and unpleasant guises learned the back vowel shift compared to listeners in a control group. These results suggest that exposure to a voice with lower social prestige does not inhibit lexical adaptation.
C1 [Babel, Molly] Univ British Columbia, Dept Linguist, Vancouver, BC, Canada.
   [Senior, Brianne; Bishop, Sophie] Univ British Columbia, Sch Audiol & Speech Sci, Vancouver, BC, Canada.
RP Babel, M (corresponding author), Univ British Columbia, Dept Linguist, Vancouver, BC, Canada.
EM molly.babel@ubc.ca
FU SSHRCSocial Sciences and Humanities Research Council of Canada (SSHRC)
   [435-2017-0136, 435-2014-1673]
FX Thanks to Karina Wong, Stephanie Chung, and Jennifer Abel for their
   indispensable contributions to this project. Thank you to Kodi
   Weatherholtz for sharing his original stimuli with us and engaging in
   many productive conversations about his dissertation work. This work was
   supported at various points by SSHRC Grant 435-2014-1673 to Eric
   Vatikiotis-Bateson and SSHRC Grant 435-2017-0136 to Molly Babel.
CR Babel M, 2014, LAB PHONOL, V5, P123, DOI 10.1515/lp-2014-0006
   Babel M, 2015, J ACOUST SOC AM, V137, P2823, DOI 10.1121/1.4919317
   Babel M, 2015, COGNITIVE SCI, V39, P766, DOI 10.1111/cogs.12179
   Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001
   Babel M, 2010, LANG SOC, V39, P437, DOI 10.1017/S0047404510000400
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   CHAMBERS JK, 1992, LANGUAGE, V68, P673, DOI 10.2307/416850
   Clapper CG, 2016, J PHONETICS, V58, P87, DOI 10.1016/j.wocn.2016.06.002
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Clarke-Davidson CM, 2008, PERCEPT PSYCHOPHYS, V70, P604, DOI 10.3758/PP.70.4.604
   CUTLER A, 1987, COGNITIVE PSYCHOL, V19, P141, DOI 10.1016/0010-0285(87)90010-7
   Dragojevic M, 2016, HUM COMMUN RES, V42, P396, DOI 10.1111/hcre.12079
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   Francis AL, 2002, J EXP PSYCHOL HUMAN, V28, P349, DOI 10.1037//0096-1523.28.2.349
   Francis AL, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00263
   GOGGIN JP, 1991, MEM COGNITION, V19, P448, DOI 10.3758/BF03199567
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Goldstone RL, 1998, ANNU REV PSYCHOL, V49, P585, DOI 10.1146/annurev.psych.49.1.585
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Holt RF, 2017, J SPEECH LANG HEAR R, V60, P223, DOI 10.1044/2016_JSLHR-H-16-0014
   Jesse A, 2011, PSYCHON B REV, V18, P943, DOI 10.3758/s13423-011-0129-2
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   Lattner S, 2003, HUM BRAIN MAPP, V20, P13, DOI 10.1002/hbm.10118
   Lippi-Green R., 1997, ENGLISH ACCENT LANGU, V2nd ed.
   Maye J, 2008, COGNITIVE SCI, V32, P543, DOI 10.1080/03640210802035357
   McAuliffe M, 2016, J ACOUST SOC AM, V140, P1727, DOI 10.1121/1.4962529
   Munson B., ROUTLEDGE HDB PHONET
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Payne Arvilla, 1980, LOCATING LANGUAGE TI, P143
   Perrachione TK, 2007, NEUROPSYCHOLOGIA, V45, P1899, DOI 10.1016/j.neuropsychologia.2006.11.015
   R Core Team, 2018, R LANG ENV STAT COMP
   Reby D, 2005, P ROY SOC B-BIOL SCI, V272, P941, DOI 10.1098/rspb.2004.2954
   Reinisch E, 2014, J EXP PSYCHOL HUMAN, V40, P539, DOI 10.1037/a0034409
   Reinisch E, 2013, J EXP PSYCHOL HUMAN, V39, P75, DOI 10.1037/a0027979
   Rendall D, 2004, J ACOUST SOC AM, V115, P411, DOI 10.1121/1.1635838
   RUBIN DL, 1992, RES HIGH EDUC, V33, P511, DOI 10.1007/BF00973770
   Sachs J., 1973, LANGUAGE ATTITUDES C, P74
   Scharenborg O, 2013, ATTEN PERCEPT PSYCHO, V75, P525, DOI 10.3758/s13414-013-0422-4
   SMITHER JA, 1993, BEHAV INFORM TECHNOL, V12, P330, DOI 10.1080/01449299308924397
   Sumner M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01015
   THOMPSON CP, 1987, APPL COGNITIVE PSYCH, V1, P121, DOI 10.1002/acp.2350010205
   Todd RM, 2012, J NEUROSCI, V32, P11201, DOI 10.1523/JNEUROSCI.0155-12.2012
   Van Engen KJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00577
   Weatherholtz K, 2015, THESIS
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   White M., 2009, P INT C SPOK LANG PR, P2523
   Winters SJ, 2008, J ACOUST SOC AM, V123, P4524, DOI 10.1121/1.2913046
   Yi HG, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00768
   Yi HG, 2013, J ACOUST SOC AM, V134, pEL387, DOI 10.1121/1.4822320
   Yu ACL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0074746
   Zahn C. J., 1985, J LANG SOC PSYCHOL, V4, P113, DOI DOI 10.1177/0261927X8500400203
   Zeelenberg R, 2004, J EXP PSYCHOL LEARN, V30, P270, DOI 10.1037/0278-7393.30.1.270
   Zhang XJ, 2014, J EXP PSYCHOL HUMAN, V40, P200, DOI 10.1037/a0033182
   Zheng Y, 2017, ATTEN PERCEPT PSYCHO, V79, P1841, DOI 10.3758/s13414-017-1329-2
NR 61
TC 1
Z9 1
U1 0
U2 1
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD FEB 25
PY 2019
VL 10
IS 1
AR 4
DI 10.5334/labphon.133
PG 22
WC Linguistics; Language & Linguistics
SC Linguistics
GA HZ4JJ
UT WOS:000468813300001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Choi, JE
   Ma, SM
   Park, H
   Cho, YS
   Hong, SH
   Moon, IJ
AF Choi, Ji Eun
   Ma, Sun Mi
   Park, Heesung
   Cho, Yang-Sun
   Hong, Sung Hwa
   Moon, Il Joon
TI A comparison between wireless CROS/BiCROS and soft-band BAHA for
   patients with unilateral hearing loss
SO PLOS ONE
LA English
DT Article
ID BONE-ANCHORED HEARING; INNER-EAR DEAFNESS; SPEECH-IN-NOISE; AIDS;
   HANDICAP; REHABILITATION; AMPLIFICATION; LOCALIZATION; RECEPTION;
   DEVICES
AB This study directly compared the performance of a contralateral routing of signal (CROS)/bilateral routing of signal (BiCROS) and a soft-band bone-anchored hearing aid (BAHA) in patients with unilateral sensorineural hearing loss (SNHL) and assessed the relationship between hearing aid benefits and personal factors. Participants with unilateral SNHL were prospectively enrolled in the study and were tested under the following three conditions: unaided, with CROS/BiCROS, and with soft-band BAHA. Sound localization, consonant, hearing in noise, and psychoacoustic tests were performed. Pseudobinaural benefits (e.g., squelch, summation, and head shadow effect) were obtained in both the CROS/BiCROS and soft-band BAHA conditions and compared to the unaided condition. Sound localization ability was not improved in either the CROS/BiCROS condition or soft-band BAHA condition. Rather, sound localization ability was significantly decreased in the CROS/BiCROS setting. A CROS/BiCROS hearing aid and a soft-band BAHA provided additional benefit for speech-in-noise perception when target speech was directed to the impaired ear side. The CROS/BiCROS hearing aid was superior to the soft-band BAHA one in decreasing the head shadow effect, but it appeared to have a negative effect when the noise was delivered to the better ear. The positive and negative effects of CROS/BiCROS for localization and speech perception were significantly correlated with personal factors such as age, hearing threshold in the better ear, and unaided psychoacoustic performances. Despite the lack of device acclimatization, we believe that this study provides counseling information for hearing aid clinics to use in the context of patients with unilateral SNHL.
C1 [Choi, Ji Eun] Dankook Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg, Cheonan, South Korea.
   [Ma, Sun Mi; Park, Heesung] Samsung Med Ctr, Hearing Res Lab, Seoul, South Korea.
   [Cho, Yang-Sun; Moon, Il Joon] Sungkyunkwan Univ, Samsung Med Ctr, Sch Med, Dept Otorhinolaryngol Head & Neck Surg, Seoul, South Korea.
   [Hong, Sung Hwa] Sungkyunkwan Univ, Sch Med, Samsung Changwon Hosp, Dept Otorhinolaryngol Head & Neck Surg, Seoul, South Korea.
RP Moon, IJ (corresponding author), Sungkyunkwan Univ, Samsung Med Ctr, Sch Med, Dept Otorhinolaryngol Head & Neck Surg, Seoul, South Korea.
EM moonij@skku.edu
OI MOON, IL JOON/0000-0002-3613-0734
CR Agterberg MJH, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00188
   Augustine AM, 2013, INDIAN J OTOLARYNGOL, V65, P120, DOI 10.1007/s12070-012-0586-6
   Baguley DM, 2006, CLIN OTOLARYNGOL, V31, P6, DOI 10.1111/j.1749-4486.2006.01137.x
   Bosman AJ, 2003, ACTA OTO-LARYNGOL, V123, P258, DOI 10.1080/000164580310001105
   Chiossoine-Kerdel JA, 2000, AM J OTOL, V21, P645
   Cho S. J., 2008, AUDIOLOGY, V4, P28
   Choi JE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171635
   Finbow J, 2015, OTOL NEUROTOL, V36, P819, DOI 10.1097/MAO.0000000000000762
   Flynn MC, 2011, ADV OTO-RHINO-LARYNG, V71, P112, DOI 10.1159/000323592
   Hol MKS, 2005, OTOL NEUROTOL, V26, P999, DOI 10.1097/01.mao.0000185065.04834.95
   Hol MKS, 2004, AUDIOL NEURO-OTOL, V9, P274, DOI 10.1159/000080227
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Lin LM, 2006, OTOL NEUROTOL, V27, P172, DOI 10.1097/01.mao.0000196421.30275.73
   McDermott AL, 2002, J LARYNGOL OTOL, V116, P29, DOI 10.1258/0022215021911310
   Moon SK, 2008, INT J AUDIOL, V47, P375, DOI 10.1080/14992020701882457
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Niparko JK, 2003, OTOL NEUROTOL, V24, P73, DOI 10.1097/00129492-200301000-00015
   Pedley AJ, 2017, HEARING RES, V353, P104, DOI 10.1016/j.heares.2017.06.007
   Peters JPM, 2015, LARYNGOSCOPE, V125, P218, DOI 10.1002/lary.24865
   Ryu NG, 2015, EUR ARCH OTO-RHINO-L, V272, P2213, DOI 10.1007/s00405-014-3133-0
   Sadeghi AM, 2016, B-ENT, V12, P41
   Sargent EW, 2001, OTOL NEUROTOL, V22, P480, DOI 10.1097/00129492-200107000-00012
   Silverman CA, 2006, J AM ACAD AUDIOL, V17, P747, DOI 10.3766/jaaa.17.10.6
   Snapp HA, 2017, OTOL NEUROTOL, V38, P11, DOI 10.1097/MAO.0000000000001269
   Van Wanrooij MM, 2004, J NEUROSCI, V24, P4163, DOI 10.1523/JNEUROSCI.0048-04.2004
   van Wieringen A, 2011, CLIN OTOLARYNGOL, V36, P114, DOI 10.1111/j.1749-4486.2011.02302.x
   Wazen JJ, 2003, OTOLARYNG HEAD NECK, V129, P248, DOI 10.1016/S0194-5998(03)00527-8
   Won JH, 2007, JARO-J ASSOC RES OTO, V8, P384, DOI 10.1007/s10162-007-0085-8
   Won JH, 2011, J ACOUST SOC AM, V130, P376, DOI 10.1121/1.3592521
NR 30
TC 1
Z9 2
U1 1
U2 7
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD FEB 21
PY 2019
VL 14
IS 2
AR e0212503
DI 10.1371/journal.pone.0212503
PG 17
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA HM2WC
UT WOS:000459330800031
PM 30789931
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Kraaijenga, VJC
   Ramakers, GGJ
   Smulders, YE
   Free, RH
   van Zon, A
   Frijns, JHM
   Huinck, WJ
   Stokroos, RJ
   Grolman, W
AF Kraaijenga, Veronique J. C.
   Ramakers, Geerte G. J.
   Smulders, Yvette E.
   Free, Rolien H.
   van Zon, Alice
   Frijns, Johan H. M.
   Huinck, Wendy J.
   Stokroos, Robert J.
   Grolman, Wilko
TI No Difference in Behavioral and Self-Reported Outcomes for Simultaneous
   and Sequential Bilateral Cochlear Implantation: Evidence From a
   Multicenter Randomized Controlled Trial
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE bilateral cochlear implantation; sequential; simultaneous; bimodal; QoL;
   RCT
ID QUALITY-OF-LIFE; COST-EFFECTIVENESS; ADULTS; SPEECH; BENEFITS;
   GUIDELINES; UTILITIES; CHILDREN; DUTCH
AB Objective: The primary aim of this study was to longitudinally compare the behavioral and self-reported outcomes of simultaneous bilateral cochlear implantation (simBiCI) and sequential BiCI (seqBiCI) in adults with severe-to-profound postlingual sensorineural hearing loss.
   Design: This study is a multicenter randomized controlled trial with a 4-year followup period after the first moment of implantation. Participants were allocated by randomization to receive bilateral cochlear implants (Cis) either, simultaneously (simBiCKI group) or sequentially with an inter-implant interval of 2 years (UCI/seqBiCI group). All sequential patients where encouraged to use their hearing aid on the non-implanted ear over of the first 2 years. Patients were followed-up on an annual basis. The primary outcome was speech perception in noise coming from a source directly in front of the patient. Other behavioral outcome measures were speech intelligibility-innoise from spatially separated sources, localization and speech perception in quiet. Self-reported outcome measures encompassed questionnaires on quality of life, quality of hearing and tinnitus. All outcome measures were analyzed longitudinally using a linear or logistic regression analysis with an autoregressive residual covariance matrix (generalized estimating equations type).
   Results: Nineteen participants were randomly allocated to the simBiCl group and 19 participants to the UCI/seqBiCI group. Three participants in the UCI/seqBiCI group did not proceed with their second implantation and were therefore unavailable for followup. Both study groups performed equally well on speech perception in noise from a source directly in front of the patient longitudinally. During all 4 years of follow-up the UCI/seqBiCI group performed significantly worse compared to the simBiCl group on spatial speech perception in noise in the best performance situation (8.70 dB [3.96 13.44], p < 0.001) and localization abilities (largest difference 60 degrees configuration: -44.45% [-52.15 - -36.74], p < 0.0001). Furthermore, during all years of follow-up, the UCI/seqBiCI group performed significantly worse on quality of hearing and quality of life questionnaires. The years of unilateral CI use were the reason for the inferior results in the UCI/SeqBiCI group. One year after receiving CI2, the UCI/seqBiCI group performance did not statistically differ from the performance of the simBiCl group on all these outcomes. Furthermore, no longitudinal differences were seen in tinnitus burden prevalence between groups. Finally, the complications that occurred during this trial were infection, dysfunction of CI, facial nerve palsy, tinnitus and vertigo.
   Conclusion: This randomized controlled trial on bilaterally severely hearing impaired participants found a significantly worse longitudinal performance of UCI/seqBiCI compared to simBiCI on multiple behavioral and self-reported outcomes regarding speech perception in noise and localization abilities. This difference is associated with the inferior performance of the UCI/seqBiCI participants during the years of unilateral CI use. After receiving the second CI however, the performance of the UCI/seqBiCI group did not significantly differ from the simBiCI group.
C1 [Kraaijenga, Veronique J. C.; Ramakers, Geerte G. J.; Smulders, Yvette E.; Free, Rolien H.; Stokroos, Robert J.] Univ Med Ctr Utrecht, Dept Otorhinolaryngol Head & Neck Surg, Utrecht, Netherlands.
   [Kraaijenga, Veronique J. C.; Ramakers, Geerte G. J.; Smulders, Yvette E.; Free, Rolien H.; Stokroos, Robert J.] Univ Med Ctr Utrecht, Brain Ctr Rudolf Magnus, Utrecht, Netherlands.
   [Smulders, Yvette E.] Beatrix Hosp, Dept Otorhinolaryngol, Gorinchem, Netherlands.
   [van Zon, Alice] Univ Med Ctr Groningen, Dept Otorhinolaryngol, Groningen, Netherlands.
   [van Zon, Alice] Univ Med Ctr Groningen, Grad Sch Med Sci, Res Sch Behav & Cognit Neurosci, Groningen, Netherlands.
   [Frijns, Johan H. M.] Leiden Univ, Dept Otorhinolaryngol Head & Neck Surg, Med Ctr, Leiden, Netherlands.
   [Frijns, Johan H. M.] Leiden Univ, Med Ctr, Leiden Inst Brain & Cognit, Leiden, Netherlands.
   [Huinck, Wendy J.] Radboud Univ Nijmegen, Med Ctr, Dept Otorhinolaryngol Head & Neck Surg, Nijmegen, Netherlands.
   [Huinck, Wendy J.] Radboud Univ Nijmegen, Med Ctr, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
   [Grolman, Wilko] Causse Ear Clin, Tertiary Ear Referral Ctr, Colombiers, France.
RP Kraaijenga, VJC (corresponding author), Univ Med Ctr Utrecht, Dept Otorhinolaryngol Head & Neck Surg, Utrecht, Netherlands.; Kraaijenga, VJC (corresponding author), Univ Med Ctr Utrecht, Brain Ctr Rudolf Magnus, Utrecht, Netherlands.
EM v.j.c.kraaijenga@umcutrecht.nl
RI stokroos, robert/AAC-9814-2021; Huinck, Wendy J./L-4396-2015;
   Kraaijenga, Veronique/AAT-7741-2020; Frijns, Johan H.M./H-6249-2011
OI Frijns, Johan H.M./0000-0002-1180-3314
FU Advanced Bionics(R)
FX This study was sponsored by Advanced Bionics (R). They did not have any
   influence on the conduct of the study, data collection, management,
   analysis or interpretation. The sponsor did not review or approve the
   content of this manuscript before submission.
CR BRONKHORST AW, 1988, J ACOUST SOC AM, V83, P1508, DOI 10.1121/1.395906
   Crathorne L, 2012, CLIN OTOLARYNGOL, V37, P342, DOI 10.1111/coa.12011
   DIRKS DD, 1969, J SPEECH HEAR RES, V12, P5, DOI 10.1044/jshr.1201.05
   Eapen RJ, 2009, OTOL NEUROTOL, V30, P153, DOI 10.1097/MAO.0b013e3181925025
   Farinetti A, 2014, EUR ANN OTORHINOLARY, V131, P177, DOI 10.1016/j.anorl.2013.05.005
   Feeny D, 2002, MED CARE, V40, P113, DOI 10.1097/00005650-200202000-00006
   Foteff C, 2016, OTOL NEUROTOL, V37, P454, DOI 10.1097/MAO.0000000000000999
   Gatehouse S, 2004, INT J AUDIOL, V43, P85, DOI 10.1080/14992020400050014
   Gaylor JM, 2013, JAMA OTOLARYNGOL, V139, P265, DOI 10.1001/jamaoto.2013.1744
   Hinderink JB, 2000, OTOLARYNG HEAD NECK, V123, P756, DOI 10.1067/mhn.2000.108203
   Kraaijenga VJC, 2017, JAMA OTOLARYNGOL, V143, P881, DOI 10.1001/jamaoto.2017.0745
   Kraaijenga VJC, 2016, OTOL NEUROTOL, V37, P1300, DOI 10.1097/MAO.0000000000001185
   Kuthubutheen J, 2015, LARYNGOSCOPE, V125, P442, DOI 10.1002/lary.24902
   Lamers LM, 2005, NED TIJDSCHR GENEES, V149, P1574
   MACKEITH N W, 1971, Journal of Laryngology and Otology, V85, P213, DOI 10.1017/S0022215100073369
   McCombe A, 2001, CLIN OTOLARYNGOL, V26, P388, DOI 10.1046/j.1365-2273.2001.00490.x
   Meeus O, 2007, B-ENT, P11
   MIDDLEBROOKS JC, 1991, ANNU REV PSYCHOL, V42, P135, DOI 10.1146/annurev.ps.42.020191.001031
   Newman CW, 1996, ARCH OTOLARYNGOL, V122, P143
   Olze H, 2012, OTOL NEUROTOL, V33, P1169, DOI 10.1097/MAO.0b013e31825e799f
   Ramakers GGJ, 2016, CLIN OTOLARYNGOL, V41, P737, DOI 10.1111/coa.12626
   Ramakers GGJ, 2017, BMC EAR NOSE THROAT, V17, DOI 10.1186/s12901-017-0043-y
   Ramakers GGJ, 2017, FRONT SURG, V4, DOI 10.3389/fsurg.2017.00065
   Ramsden R, 2005, OTOL NEUROTOL, V26, P988, DOI 10.1097/01.mao.0000185075.58199.22
   Schulz KF, 2010, OBSTET GYNECOL, V115, P1063, DOI 10.1097/AOG.0b013e3181d9d421
   Smulders YE, 2016, JAMA OTOLARYNGOL, V142, P249, DOI 10.1001/jamaoto.2015.3305
   Smulders YE, 2015, AUDIOLOGY NEUROTOL E, V5, P1, DOI 10.1159/000370300
   Summerfield AQ, 2006, INT J AUDIOL, V45, pS99, DOI 10.1080/14992020600783079
   TORRANCE GW, 1986, J HEALTH ECON, V5, P1, DOI 10.1016/0167-6296(86)90020-2
   van Schoonhoven J, 2013, OTOL NEUROTOL, V34, P190, DOI 10.1097/MAO.0b013e318278506d
   van Zon A, 2017, LARYNGOSCOPE, V127, P1161, DOI 10.1002/lary.26239
   WILLIAMS A, 1990, HEALTH POLICY, V16, P199
   Zeitler DM, 2008, OTOL NEUROTOL, V29, P314, DOI 10.1097/MAO.0b013e3181662cb5
NR 33
TC 3
Z9 3
U1 0
U2 4
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD FEB 20
PY 2019
VL 13
AR 54
DI 10.3389/fnins.2019.00054
PG 17
WC Neurosciences
SC Neurosciences & Neurology
GA HM0RZ
UT WOS:000459156000001
PM 30842721
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Rosemann, S
   Thiel, CM
AF Rosemann, Stephanie
   Thiel, Christiane M.
TI The effect of age-related hearing loss and listening effort on resting
   state connectivity
SO SCIENTIFIC REPORTS
LA English
DT Article
ID OLDER-ADULTS; FUNCTIONAL CONNECTIVITY; DEFAULT-MODE; AUDITORY-CORTEX;
   SPEECH; BRAIN; NETWORK; MEMORY; LANGUAGE; CONSEQUENCES
AB Age-related hearing loss is associated with a decrease in hearing abilities for high frequencies. This increases not only the difficulty to understand speech but also the experienced listening effort. Task based neuroimaging studies in normal-hearing and hearing-impaired participants show an increased frontal activation during effortful speech perception in the hearing-impaired. Whether the increased effort in everyday listening in hearing-impaired even impacts functional brain connectivity at rest is unknown. Nineteen normal-hearing and nineteen hearing-impaired participants with mild to moderate hearing loss participated in the study. Hearing abilities, listening effort and resting state functional connectivity were assessed. Our results indicate no differences in functional connectivity between hearing-impaired and normal-hearing participants. Increased listening effort, however, was related to significantly decreased functional connectivity between the dorsal attention network and the precuneus and superior parietal lobule as well as between the auditory and the inferior frontal cortex. We conclude that already mild to moderate age-related hearing loss can impact resting state functional connectivity. It is however not the hearing loss itself but the individually perceived listening effort that relates to functional connectivity changes.
C1 [Rosemann, Stephanie; Thiel, Christiane M.] Carl von Ossietzky Univ Oldenburg, Sch Med & Hlth Sci, Dept Psychol, Biol Psychol, Oldenburg, Germany.
   [Rosemann, Stephanie; Thiel, Christiane M.] Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, Oldenburg, Germany.
RP Rosemann, S (corresponding author), Carl von Ossietzky Univ Oldenburg, Sch Med & Hlth Sci, Dept Psychol, Biol Psychol, Oldenburg, Germany.; Rosemann, S (corresponding author), Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, Oldenburg, Germany.
EM Stephanie.rosemann@uni-oldenburg.de
OI Rosemann, Stephanie/0000-0003-2598-0538
FU German Research Foundation (Deutsche Forschungsgemeinschaft, DFG;
   Cluster of Excellence) [DFG 1077]; Neuroimaging Unit of the Carl von
   Ossietzky Universitat Oldenburg - German Research Foundation [3T MRI
   INST 184/152-1 FUGG]
FX This work was funded by the German Research Foundation (Deutsche
   Forschungsgemeinschaft, DFG; Cluster of Excellence DFG 1077
   "Hearing4all") and supported by the Neuroimaging Unit of the Carl von
   Ossietzky Universitat Oldenburg funded by grants from the German
   Research Foundation (3T MRI INST 184/152-1 FUGG). The authors wish to
   thank Gulsen Yanc and Katharina Grote for helping with MRI data
   acquisition.
CR Berding G, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128743
   Bernarding C, 2017, COGN NEURODYNAMICS, V11, P203, DOI 10.1007/s11571-017-9425-5
   Breckel TPK, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0074125
   Buckner RL, 2008, ANN NY ACAD SCI, V1124, P1, DOI 10.1196/annals.1440.011
   Buckner RL, 2004, NEURON, V44, P195, DOI 10.1016/j.neuron.2004.09.006
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   Campbell J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00071
   Cardin V, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00199
   Chen YC, 2018, FRONT BEHAV NEUROSCI, V12, DOI 10.3389/fnbeh.2018.00044
   Damoiseaux JS, 2008, CEREB CORTEX, V18, P1856, DOI 10.1093/cercor/bhm207
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Erb J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00116
   Erb J, 2013, J NEUROSCI, V33, P10688, DOI 10.1523/JNEUROSCI.4596-12.2013
   Fortunato S, 2016, ACTA OTORHINOLARYNGO, V36, P155, DOI 10.14639/0392-100X-993
   Grady C, 2012, NAT REV NEUROSCI, V13, P491, DOI 10.1038/nrn3256
   Greicius MD, 2004, P NATL ACAD SCI USA, V101, P4637, DOI 10.1073/pnas.0308627101
   Greicius MD, 2003, P NATL ACAD SCI USA, V100, P253, DOI 10.1073/pnas.0135058100
   Hampson M, 2010, MAGN RESON IMAGING, V28, P1051, DOI 10.1016/j.mri.2010.03.021
   Harris KC, 2009, J NEUROSCI, V29, P6078, DOI 10.1523/JNEUROSCI.0412-09.2009
   Hervais-Adelman AG, 2012, LANG COGNITIVE PROC, V27, P1145, DOI 10.1080/01690965.2012.662280
   Humes LE, 2013, ATTEN PERCEPT PSYCHO, V75, P508, DOI 10.3758/s13414-012-0406-9
   Husain FT, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00010
   Kiessling J, 2003, INT J AUDIOL, V42, pS92
   Koch W, 2010, NEUROIMAGE, V51, P280, DOI 10.1016/j.neuroimage.2009.12.008
   Lee YS, 2016, HEARING RES, V333, P108, DOI 10.1016/j.heares.2015.12.008
   Lin FR, 2012, JAMA-J AM MED ASSOC, V307, P1147, DOI 10.1001/jama.2012.321
   Lin FR, 2011, NEUROPSYCHOLOGY, V25, P763, DOI 10.1037/a0024238
   Menon V, 2010, BRAIN STRUCT FUNCT, V214, P655, DOI 10.1007/s00429-010-0262-0
   Moradi S, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00531
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Onoda K, 2012, J COGNITIVE NEUROSCI, V24, P2186, DOI 10.1162/jocn_a_00269
   Peelle JE, 2018, EAR HEARING, V39, P204, DOI 10.1097/AUD.0000000000000494
   Peelle JE, 2016, TRENDS NEUROSCI, V39, P486, DOI 10.1016/j.tins.2016.05.001
   Peelle JE, 2011, J NEUROSCI, V31, P12638, DOI 10.1523/JNEUROSCI.2559-11.2011
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Puschmann S, 2017, CORTEX, V86, P109, DOI 10.1016/j.cortex.2016.10.014
   Reuter-Lorenz PA, 2008, CURR DIR PSYCHOL SCI, V17, P177, DOI 10.1111/j.1467-8721.2008.00570.x
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2011, J SPEECH LANG HEAR R, V54, P705, DOI 10.1044/1092-4388(2010/09-0088)
   Rosemann S, 2018, NEUROIMAGE, V175, P425, DOI 10.1016/j.neuroimage.2018.04.023
   Schierholz I, 2015, HEARING RES, V328, P133, DOI 10.1016/j.heares.2015.08.009
   Schmidt SA, 2017, NEUROIMAGE-CLIN, V16, P196, DOI 10.1016/j.nicl.2017.07.015
   Schmidt SA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076488
   Schulte M., 2015, 18 JAHR DTSCH GES AU
   Sorqvist P, 2010, MEMORY, V18, P310, DOI 10.1080/09658211003601530
   Tomasi D, 2012, MOL PSYCHIATR, V17, P549, DOI 10.1038/mp.2011.81
   Tun PA, 2009, PSYCHOL AGING, V24, P761, DOI 10.1037/a0014802
   Tyler LK, 2010, CEREB CORTEX, V20, P352, DOI 10.1093/cercor/bhp105
   Vaden KI, 2015, J NEUROSCI, V35, P3929, DOI 10.1523/JNEUROSCI.2908-14.2015
   Vaden KI, 2013, J NEUROSCI, V33, P18979, DOI 10.1523/JNEUROSCI.1417-13.2013
   von Gablenz P, 2015, HNO, V63, P195, DOI 10.1007/s00106-014-2949-7
   Whitfield-Gabrieli S, 2012, BRAIN CONNECT, V2, P125, DOI 10.1089/brain.2012.0073
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
   Wild CJ, 2012, NEUROIMAGE, V60, P1490, DOI 10.1016/j.neuroimage.2012.01.035
   Wingfield A, 2005, CURR DIR PSYCHOL SCI, V14, P144, DOI 10.1111/j.0963-7214.2005.00356.x
   Wingfield A, 2006, J NEUROPHYSIOL, V96, P2830, DOI 10.1152/jn.00628.2006
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
NR 58
TC 10
Z9 10
U1 0
U2 6
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD FEB 20
PY 2019
VL 9
AR 2337
DI 10.1038/s41598-019-38816-z
PG 9
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA HL9WW
UT WOS:000459094800018
PM 30787339
OA DOAJ Gold, Green Published, Green Accepted
DA 2021-02-24
ER

PT J
AU Han, JH
   Lee, HJ
   Kang, H
   Oh, SH
   Lee, DS
AF Han, Ji-Hye
   Lee, Hyo-Jeong
   Kang, Hyejin
   Oh, Seung-Ha
   Lee, Dong Soo
TI Brain Plasticity Can Predict the Cochlear Implant Outcome in Adult-Onset
   Deafness
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE cross-modal plasticity; F-18-FDG-PET; deafness; cochlear implants;
   speech perception
ID CROSS-MODAL PLASTICITY; PRIMARY AUDITORY-CORTEX; SPEECH COMPREHENSION;
   CORTICAL ACTIVITY; CINGULATE SULCUS; REORGANIZATION; PERCEPTION;
   LANGUAGE; SENSITIVITY; CHILDREN
AB Sensory plasticity, which is associated with deafness, has not been as thoroughly investigated in the adult brain as it has in the developing brain. In this study, we examined the brain reorganization induced by auditory deprivation in people with adult-onset deafness and its clinical relevance by measuring glucose metabolism before cochlear implant (CI) surgery. F-18 fluorodeoxyglucose positron emission tomography (F-18-FDG-PET) scans were performed in 37 postlingually deafened patients during the preoperative workup period, and in 39 normal-hearing (NH) controls. Behavioral CI outcomes were measured at 1 year after implantation using a phoneme identification test with auditory cueing only. In the deaf individuals, areas involved in the auditory pathway such as the inferior colliculus and bilateral superior temporal gyri were hypometabolic compared to the NH controls. The hypometabolism observed in the deaf auditory cortices gradually returned to levels similar to the controls as the duration of deafness increased. However, contrary to our previous findings in congenitally deaf children, this metabolic recovery failed to have a significant prognostic value for the recovery of the speech perception ability in adult CI patients. In a broad occipital area centered on the primary visual cortices, glucose metabolism was higher in the deaf patients than the controls, suggesting that the area had become visually hyperactive for sensory compensation immediately after the onset of deafness. In addition, a negative correlation between the metabolic activity and behavioral speech perception outcomes was observed in the visual association areas. In the medial frontal cortices, cortical metabolism in most patients decreased, but patients who had preserved metabolic activities showed better speech performance. These results suggest that the auditory cortex in people with adultonset deafness is relatively resistant to cross-modal plasticity, and instead, individual traits in late-stage visual processing and cognitive control seem to be more reliable prognostic markers for adult-onset deafness.
C1 [Han, Ji-Hye; Lee, Hyo-Jeong] Hallym Univ, Coll Med, Lab Brain & Cognit Sci Convergence Med, Chunchon, South Korea.
   [Lee, Hyo-Jeong] Hallym Univ, Dept Otorhinolaryngol Head & Neck Surg, Coll Med, Chunchon, South Korea.
   [Kang, Hyejin; Lee, Dong Soo] Seoul Natl Univ, Dept Nucl Med, Coll Med, Seoul, South Korea.
   [Kang, Hyejin] Seoul Natl Univ, BK21 Plus Global Translat Res Mol Med & Biopharm, Seoul, South Korea.
   [Oh, Seung-Ha] Seoul Natl Univ, Dept Otorhinolaryngol Head & Neck Surg, Coll Med, Seoul, South Korea.
   [Oh, Seung-Ha] Seoul Natl Univ, Sensory Organ Res Inst, Coll Med, Seoul, South Korea.
   [Lee, Dong Soo] Seoul Natl Univ, Grad Sch Convergence Sci & Technol, Dept Mol Med & Biopharmaceut Sci, Seoul, South Korea.
RP Lee, HJ (corresponding author), Hallym Univ, Coll Med, Lab Brain & Cognit Sci Convergence Med, Chunchon, South Korea.; Lee, HJ (corresponding author), Hallym Univ, Dept Otorhinolaryngol Head & Neck Surg, Coll Med, Chunchon, South Korea.; Oh, SH (corresponding author), Seoul Natl Univ, Dept Otorhinolaryngol Head & Neck Surg, Coll Med, Seoul, South Korea.; Oh, SH (corresponding author), Seoul Natl Univ, Sensory Organ Res Inst, Coll Med, Seoul, South Korea.
EM hyojlee@hallym.ac.kr; shaoh@snu.ac.kr
RI Lee, Hyo-Jeong/AAK-7973-2020
OI Lee, Hyo-Jeong/0000-0003-2258-0803
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2016R1D1A1B03930074,
   2016R1A2B4016330, 2017R1D1A1B03030613]; Hallym University Research Fund
   (HURF)
FX This project was supported in part by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF), funded by the
   Ministry of Education (2016R1D1A1B03930074, 2016R1A2B4016330 and
   2017R1D1A1B03030613) and the Hallym University Research Fund (HURF).
CR ABBAS PJ, 1991, HEARING RES, V51, P139, DOI 10.1016/0378-5955(91)90012-X
   Ahn SH, 2004, HEARING RES, V196, P33, DOI 10.1016/j.heares.2004.05.012
   Anderson CA, 2017, P NATL ACAD SCI USA, V114, P10256, DOI 10.1073/pnas.1704785114
   Bavelier D, 2002, NAT REV NEUROSCI, V3, P443, DOI 10.1038/nrn848
   Bavelier D, 2006, TRENDS COGN SCI, V10, P512, DOI 10.1016/j.tics.2006.09.006
   Billington J, 2015, J NEUROSCI, V35, P4851, DOI 10.1523/JNEUROSCI.3640-14.2015
   Bottari D, 2014, NEUROIMAGE, V94, P172, DOI 10.1016/j.neuroimage.2014.02.031
   Brozinsky CJ, 2004, COGNITIVE BRAIN RES, V21, P1, DOI 10.1016/j.cogbrainres.2004.05.002
   Buckley KA, 2011, EAR HEARING, V32, P2, DOI [10.1097/AUD.0b013e3181e8534c, 10.1097/AUD.0b013e3181fa41bb]
   Cardin V, 2011, J NEUROPHYSIOL, V106, P1240, DOI 10.1152/jn.01120.2010
   Castiglione A, 2016, AUDIOL NEURO-OTOL, V21, P21, DOI 10.1159/000448350
   Chabot N, 2015, J COMP NEUROL, V523, P2297, DOI 10.1002/cne.23790
   Chen LC, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/4382656
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Doucet ME, 2006, BRAIN, V129, P3376, DOI 10.1093/brain/awl264
   Dye MWG, 2008, ANN NY ACAD SCI, V1145, P71, DOI 10.1196/annals.1416.013
   EMMOREY K, 1993, COGNITION, V46, P139, DOI 10.1016/0010-0277(93)90017-P
   Fine I, 2005, J COGNITIVE NEUROSCI, V17, P1621, DOI 10.1162/089892905774597173
   Finney EM, 2001, NAT NEUROSCI, V4, P1171, DOI 10.1038/nn763
   Finney EM, 2001, COGNITIVE BRAIN RES, V11, P171, DOI 10.1016/S0926-6410(00)00082-3
   Fischer E, 2012, CEREB CORTEX, V22, P865, DOI 10.1093/cercor/bhr154
   Fu Qian-Jie, 2007, Trends Amplif, V11, P193, DOI 10.1177/1084713807301379
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P180, DOI 10.1007/s10162-005-5061-6
   Giraud AL, 2002, NEUROPSYCHOLOGIA, V40, P1562, DOI 10.1016/S0028-3932(02)00023-4
   Giraud AL, 2001, BRAIN, V124, P1307, DOI 10.1093/brain/124.7.1307
   Giraud AL, 2007, RESTOR NEUROL NEUROS, V25, P381
   Han JH, 2016, CLIN NEUROPHYSIOL, V127, P1603, DOI 10.1016/j.clinph.2015.10.049
   Hauthal N, 2013, ADV COGN PSYCHOL, V9, P53, DOI [10.2478/v10053-008-0131-z, 10.5709/acp-0131-z]
   Hertz U, 2010, NEUROIMAGE, V52, P617, DOI 10.1016/j.neuroimage.2010.04.186
   Hirschfelder A, 2012, OTOL NEUROTOL, V33, P968, DOI 10.1097/MAO.0b013e31825e7c5d
   James AL, 2004, LARYNGOSCOPE, V114, P2191, DOI 10.1097/01.mlg.0000149456.75758.4c
   Karns CM, 2012, J NEUROSCI, V32, P9626, DOI 10.1523/JNEUROSCI.6488-11.2012
   Kim MB, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148466
   Koechlin E, 2006, NEURON, V50, P963, DOI 10.1016/j.neuron.2006.05.017
   Kral A, 2003, EXP BRAIN RES, V153, P605, DOI 10.1007/s00221-003-1609-z
   Land R, 2016, J NEUROSCI, V36, P6175, DOI 10.1523/JNEUROSCI.0046-16.2016
   Lazard DS, 2011, NEUROPSYCHOLOGIA, V49, P2475, DOI 10.1016/j.neuropsychologia.2011.04.025
   Lazard DS, 2010, NEUROIMAGE, V49, P3443, DOI 10.1016/j.neuroimage.2009.11.013
   Lazard DS, 2014, HEARING RES, V307, P136, DOI 10.1016/j.heares.2013.08.006
   Lazard DS, 2013, HUM BRAIN MAPP, V34, P1208, DOI 10.1002/hbm.21504
   Lee DS, 2001, NATURE, V409, P149, DOI 10.1038/35051653
   Lee HJ, 2007, BRAIN, V130, P2929, DOI 10.1093/brain/awm230
   Lee HJ, 2007, CEREB CORTEX, V17, P909, DOI 10.1093/cercor/bhl001
   Lee JS, 2003, J NUCL MED, V44, P1435
   Levanen S, 2001, NEUROSCI LETT, V301, P75, DOI 10.1016/S0304-3940(01)01597-X
   Lundin Karin, 2015, Cochlear Implants Int, V16, P254, DOI 10.1179/1754762815Y.0000000005
   MacSweeney M, 2004, NEUROIMAGE, V22, P1605, DOI 10.1016/j.neuroimage.2004.03.015
   Moore DR, 2009, NAT NEUROSCI, V12, P686, DOI 10.1038/nn.2326
   Mortensen MV, 2006, NEUROIMAGE, V31, P842, DOI 10.1016/j.neuroimage.2005.12.020
   Obretenova S, 2010, FRONT HUM NEUROSCI, V3, DOI 10.3389/neuro.09.060.2009
   Oh SH, 2003, ACTA OTO-LARYNGOL, V123, P148, DOI 10.1080/0036554021000028111
   Park MH, 2010, BRAIN RES, V1354, P85, DOI 10.1016/j.brainres.2010.07.105
   Patel AM, 2007, ARCH OTOLARYNGOL, V133, P677, DOI 10.1001/archotol.133.7.677
   Petersen B, 2013, NEURAL PLAST, V2013, DOI 10.1155/2013/318521
   Petrides M, 2000, J NEUROSCI, V20, P7496
   Pisoni DB, 2000, EAR HEARING, V21, P70, DOI 10.1097/00003446-200002000-00010
   Puce A, 1998, J NEUROSCI, V18, P2188
   Roditi RE, 2009, OTOL NEUROTOL, V30, P449, DOI 10.1097/MAO.0b013e31819d3480
   Rouger J, 2012, HUM BRAIN MAPP, V33, P1929, DOI 10.1002/hbm.21331
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   Sharma A, 2005, HEARING RES, V203, P134, DOI 10.1016/j.heares.2004.12.010
   Shiell MM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090498
   Shin OH, 2009, P NATL ACAD SCI USA, V106, P16469, DOI 10.1073/pnas.0908798106
   Smith AT, 2018, CEREB CORTEX, V28, P713, DOI 10.1093/cercor/bhx002
   Smith AT, 2012, CEREB CORTEX, V22, P1068, DOI 10.1093/cercor/bhr179
   Song JJ, 2015, BRAIN STRUCT FUNCT, V220, P1109, DOI 10.1007/s00429-013-0704-6
   Strelnikov K, 2013, BRAIN, V136, P3682, DOI 10.1093/brain/awt274
   Stropahl M, 2017, HEARING RES, V343, P128, DOI 10.1016/j.heares.2016.07.005
   Stropahl M, 2015, NEUROIMAGE, V121, P159, DOI 10.1016/j.neuroimage.2015.07.062
   Suh MW, 2009, BRAIN, V132, P2761, DOI 10.1093/brain/awp159
   Yoshinaga-Itano C, 1998, PEDIATRICS, V102, P1161, DOI 10.1542/peds.102.5.1161
NR 71
TC 6
Z9 6
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD FEB 19
PY 2019
VL 13
AR 38
DI 10.3389/fnhum.2019.00038
PG 12
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA HM1AC
UT WOS:000459178600001
PM 30837852
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Rampinini, AC
   Handjaras, G
   Leo, A
   Cecchetti, L
   Betta, M
   Marotta, G
   Ricciardi, E
   Pietrini, P
AF Rampinini, Alessandra Cecilia
   Handjaras, Giacomo
   Leo, Andrea
   Cecchetti, Luca
   Betta, Monica
   Marotta, Giovanna
   Ricciardi, Emiliano
   Pietrini, Pietro
TI Formant Space Reconstruction From Brain Activity in Frontal and Temporal
   Regions Coding for Heard Vowels
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE fMRI; language; speech; vowels; production; perception; tones; formants
ID VOCAL-TRACT; SPEECH-PERCEPTION; BROCAS AREA; AUDITORY-PERCEPTION; MOTOR
   SYSTEM; FMRI; LANGUAGE; REPRESENTATION; COMPREHENSION; APHASIA
AB Classical studies have isolated a distributed network of temporal and frontal areas engaged in the neural representation of speech perception and production. With modern literature arguing against unique roles for these cortical regions, different theories have favored either neural code-sharing or cortical space-sharing, thus trying to explain the intertwined spatial and functional organization of motor and acoustic components across the fronto-temporal cortical network. In this context, the focus of attention has recently shifted toward specific model fitting, aimed at motor and/or acoustic space reconstruction in brain activity within the language network. Here, we tested a model based on acoustic properties (formants), and one based on motor properties (articulation parameters), where model-free decoding of evoked fMRI activity during perception, imagery, and production of vowels had been successful. Results revealed that phonological information organizes around formant structure during the perception of vowels; interestingly, such a model was reconstructed in a broad temporal region, outside of the primary auditory cortex, but also in the pars triangularis of the left inferior frontal gyrus. Conversely, articulatory features were not associated with brain activity in these regions. Overall, our results call for a degree of interdependence based on acoustic information, between the frontal and temporal ends of the language network.
C1 [Rampinini, Alessandra Cecilia; Handjaras, Giacomo; Leo, Andrea; Cecchetti, Luca; Betta, Monica; Ricciardi, Emiliano; Pietrini, Pietro] IMT Sch Adv Studies Lucca, Lucca, Italy.
   [Marotta, Giovanna] Univ Pisa, Dept Philol Literature & Linguist, Pisa, Italy.
RP Rampinini, AC; Ricciardi, E (corresponding author), IMT Sch Adv Studies Lucca, Lucca, Italy.
EM alessandra.rampinini@imtlucca.it; emiliano.ricciardi@imtlucca.it
RI Pietrini, Pietro/Z-4202-2019; Ricciardi, Emiliano/E-6929-2011
OI Ricciardi, Emiliano/0000-0002-7178-9534; Pietrini,
   Pietro/0000-0002-6768-5556
CR Adank P, 2012, BRAIN LANG, V122, P42, DOI 10.1016/j.bandl.2012.04.014
   Albano Leoni F., 1995, MANUALE DI FONETICA
   Allen EJ, 2018, NEUROIMAGE, V166, P60, DOI 10.1016/j.neuroimage.2017.10.050
   Amunts K, 2012, TRENDS COGN SCI, V16, P418, DOI 10.1016/j.tics.2012.06.005
   Amunts K, 2010, PLOS BIOL, V8, DOI 10.1371/journal.pbio.1000489
   Anwander A, 2007, CEREB CORTEX, V17, P816, DOI 10.1093/cercor/bhk034
   Archila-Melendez M. E., 2018, SENSORIMOTOR REPRESE, DOI [10.1523/ENEURO.0252-17.2018, DOI 10.1523/ENEURO.0252-17.2018]
   Ardila Alfredo, 2016, Front Hum Neurosci, V10, P249, DOI 10.3389/fnhum.2016.00249
   Arsenault JS, 2015, J NEUROSCI, V35, P634, DOI 10.1523/JNEUROSCI.2454-14.2015
   Asaridou SS, 2016, CEREB CORTEX, V26, P2728, DOI 10.1093/cercor/bhv126
   ATAL BS, 1978, J ACOUST SOC AM, V63, P1535, DOI 10.1121/1.381848
   Basilakos A, 2015, STROKE, V46, P1561, DOI 10.1161/STROKEAHA.115.009211
   Beautemps D, 2001, J ACOUST SOC AM, V109, P2165, DOI 10.1121/1.1361090
   Bilenko NY, 2016, FRONT NEUROINFORM, V10, DOI 10.3389/fninf.2016.00049
   Boersma P., 2006, PRAAT DOING PHONETIC
   BOLLER F, 1978, BRAIN LANG, V5, P149, DOI 10.1016/0093-934X(78)90015-9
   Bonte M, 2014, J NEUROSCI, V34, P4548, DOI 10.1523/JNEUROSCI.4339-13.2014
   Bouchard KE, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151327
   CARAMAZZA A, 1976, BRAIN LANG, V3, P572, DOI 10.1016/0093-934X(76)90048-1
   Catani M, 2005, ANN NEUROL, V57, P8, DOI 10.1002/ana.20319
   Chakrabarti S, 2015, BIOMED ENG LETT, V5, P10, DOI 10.1007/s13534-015-0175-1
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Cheung C, 2016, ELIFE, V5, DOI 10.7554/eLife.12577
   COLE MF, 1971, P MARIES PAPERS SPEE
   Conant DF, 2018, J NEUROSCI, V38, P2955, DOI 10.1523/JNEUROSCI.2382-17.2018
   Correia JM, 2015, J NEUROSCI, V35, P15015, DOI 10.1523/JNEUROSCI.0977-15.2015
   D'Ausilio A, 2012, CORTEX, V48, P882, DOI 10.1016/j.cortex.2011.05.017
   D'Ausilio A, 2012, J NEUROLINGUIST, V25, P328, DOI 10.1016/j.jneuroling.2010.02.003
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   DAMASIO AR, 1984, ANNU REV NEUROSCI, V7, P127, DOI 10.1146/annurev.ne.07.030184.001015
   Dang JW, 2002, J PHONETICS, V30, P511, DOI 10.1006/jpho.2002.0167
   Davis C, 2008, BRAIN LANG, V105, P50, DOI 10.1016/j.bandl.2008.01.012
   De Angelis V, 2018, NEUROIMAGE, V180, P291, DOI 10.1016/j.neuroimage.2017.11.020
   Dronkers NF, 1996, NATURE, V384, P159, DOI 10.1038/384159a0
   Evans S, 2015, CEREB CORTEX, V25, P4772, DOI 10.1093/cercor/bhv136
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Feng GY, 2018, CEREB CORTEX, V28, P3241, DOI 10.1093/cercor/bhx195
   Flinker A, 2015, P NATL ACAD SCI USA, V112, P2871, DOI 10.1073/pnas.1414491112
   Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318
   Fullerton BC, 2007, J COMP NEUROL, V504, P470, DOI 10.1002/cne.21432
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Gernsbacher MA, 2003, ANNU REV PSYCHOL, V54, P91, DOI 10.1146/annurev.psych.54.101601.145128
   Gick B, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00977
   Grabski K, 2013, J NEUROLINGUIST, V26, P384, DOI 10.1016/j.jneuroling.2012.11.003
   Hagmann P, 2008, PLOS BIOL, V6, P1479, DOI 10.1371/journal.pbio.0060159
   Hausfeld L, 2018, NEUROIMAGE, V173, P472, DOI 10.1016/j.neuroimage.2018.02.065
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.2307/2333955
   Iacoboni M, 2008, J PHYSIOL-PARIS, V102, P31, DOI 10.1016/j.jphysparis.2008.03.003
   Jenkinson M, 2012, NEUROIMAGE, V62, P782, DOI 10.1016/j.neuroimage.2011.09.015
   Josephs KA, 2006, BRAIN, V129, P1385, DOI 10.1093/brain/awl078
   Kaas JH, 2000, P NATL ACAD SCI USA, V97, P11793, DOI 10.1073/pnas.97.22.11793
   Kriegeskorte N, 2006, P NATL ACAD SCI USA, V103, P3863, DOI 10.1073/pnas.0600244103
   Kwok VPY, 2016, J NEUROLINGUIST, V37, P34, DOI 10.1016/j.jneuroling.2015.08.003
   LADEFOGED P, 2012, VOWELS CONSONANTS
   Laukkanen AM, 2012, BIOMED SIGNAL PROCES, V7, P50, DOI 10.1016/j.bspc.2011.02.004
   Laurent R, 2017, PSYCHOL REV, V124, P572, DOI 10.1037/rev0000069
   Lee YS, 2012, J NEUROSCI, V32, P3942, DOI 10.1523/JNEUROSCI.3814-11.2012
   Leo A, 2016, ELIFE, V5, DOI [10.7554/el.ife.13420, 10.7554/eLife.13420]
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Luria A. R., 1966, HIGHER CORTICAL FUNC
   Markiewicz CJ, 2016, NEUROIMAGE, V141, P174, DOI 10.1016/j.neuroimage.2016.07.023
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   MOORE CA, 1992, J SPEECH HEAR RES, V35, P1009, DOI 10.1044/jshr.3505.1009
   Naselaris T, 2011, NEUROIMAGE, V56, P400, DOI 10.1016/j.neuroimage.2010.07.073
   Obleser J, 2006, HUM BRAIN MAPP, V27, P562, DOI 10.1002/hbm.20201
   Okada K, 2006, BRAIN LANG, V98, P112, DOI 10.1016/j.bandl.2006.04.006
   Papoutsi M, 2009, CEREB CORTEX, V19, P2156, DOI 10.1093/cercor/bhn239
   Penfield W, 1959, SPEECH BRAIN MECH
   Poeppel D, 2004, COGNITION, V92, P1, DOI 10.1016/j.cognition.2003.11.001
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Rampinini AC, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-17314-0
   Rauschecker JP, 2000, P NATL ACAD SCI USA, V97, P11800, DOI 10.1073/pnas.97.22.11800
   Reiterer S, 2008, BRAIN IMAGING BEHAV, V2, P1, DOI 10.1007/s11682-007-9010-3
   Richmond K, 2003, COMPUT SPEECH LANG, V17, P153, DOI 10.1016/S0885-2308(03)00005-6
   Romanski LM, 2009, ANNU REV NEUROSCI, V32, P315, DOI 10.1146/annurev.neuro.051508.135431
   Schomers MR, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00435
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Smith SM, 2004, NEUROIMAGE, V23, pS208, DOI 10.1016/j.neuroimage.2004.07.051
   Specht K, 2003, NEUROIMAGE, V20, P1944, DOI 10.1016/j.neuroimage.2003.07.034
   STEVENS KN, 1955, J ACOUST SOC AM, V27, P484, DOI 10.1121/1.1907943
   Tankus A, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms1995
   Toda T, 2008, SPEECH COMMUN, V50, P215, DOI 10.1016/j.specom.2007.09.001
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Yarkoni T, 2011, NAT METHODS, V8, P665, DOI [10.1038/NMETH.1635, 10.1038/nmeth.1635]
   Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015
   Zhang QT, 2016, EUR J NEUROSCI, V43, P773, DOI 10.1111/ejn.13164
NR 89
TC 0
Z9 0
U1 0
U2 3
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD FEB 8
PY 2019
VL 13
AR 32
DI 10.3389/fnhum.2019.00032
PG 13
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA HK9CI
UT WOS:000458286300001
PM 30837851
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Romanovska, L
   Janssen, R
   Bonte, M
AF Romanovska, Linda
   Janssen, Roef
   Bonte, Milene
TI Reading-Induced Shifts in Speech Perception in Dyslexic and Typically
   Reading Children
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE reading development; dyslexia; letter-speech sound coupling;
   recalibration; adaptation
ID DEVELOPMENTAL DYSLEXIA; PHONETIC RECALIBRATION; SELECTIVE ADAPTATION;
   VISUAL RECALIBRATION; PHONOLOGICAL BINDING; AUDITORY SPEECH; DEFICIT;
   INTEGRATION; BRAIN; ATTENTION
AB One of the proposed mechanisms underlying reading difficulties observed in developmental dyslexia is impaired mapping of visual to auditory speech representations. We investigate these mappings in 20 typically reading and 20 children with dyslexia aged 8-10 years using text-based recalibration. In this paradigm, the pairing of visual text and ambiguous speech sounds shifts (recalibrates) the participant's perception of the ambiguous speech in subsequent auditory-only post-test trials. Recent research in adults demonstrated this text-induced perceptual shift in typical, but not in dyslexic readers. Our current results instead show significant text-induced recalibration in both typically reading children and children with dyslexia. The strength of this effect was significantly linked to the strength of perceptual adaptation effects in children with dyslexia but not typically reading children. Furthermore, additional analyses in a sample of typically reading children of various reading levels revealed a significant link between recalibration and phoneme categorization. Taken together, our study highlights the importance of considering dynamic developmental changes in reading, letter-speech sound coupling and speech perception when investigating group differences between typical and dyslexic readers.
C1 [Romanovska, Linda; Janssen, Roef; Bonte, Milene] Maastricht Univ, Fac Psychol & Neurosci, Dept Cognit Neurosci, Maastricht Brain Imaging Ctr, Maastricht, Netherlands.
RP Romanovska, L (corresponding author), Maastricht Univ, Fac Psychol & Neurosci, Dept Cognit Neurosci, Maastricht Brain Imaging Ctr, Maastricht, Netherlands.
EM linda.romanovska@maastrichtuniversity.nl
FU Netherlands Organization for Scientific Research (Vidi-Grant)
   [452-16-004]
FX This research was supported by The Netherlands Organization for
   Scientific Research (Vidi-Grant 452-16-004 to MB).
CR Ahissar M, 2007, TRENDS COGN SCI, V11, P458, DOI 10.1016/j.tics.2007.08.015
   Aravena S., 2017, THESIS
   Aravena S, 2013, J EXP CHILD PSYCHOL, V115, P691, DOI 10.1016/j.jecp.2013.03.009
   Baart M, 2012, ACTA PSYCHOL, V140, P91, DOI 10.1016/j.actpsy.2012.03.003
   Baart M, 2010, EXP BRAIN RES, V203, P575, DOI 10.1007/s00221-010-2264-9
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Ben-Shachar M, 2011, J COGNITIVE NEUROSCI, V23, P2387, DOI 10.1162/jocn.2011.21615
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Blau V, 2010, BRAIN, V133, P868, DOI 10.1093/brain/awp308
   Blau V, 2009, CURR BIOL, V19, P503, DOI 10.1016/j.cub.2009.01.065
   Blomert L, 2004, J SPEECH LANG HEAR R, V47, P1030, DOI 10.1044/1092-4388(2004/077)
   Blomert L, 2004, BRAIN LANG, V89, P21, DOI 10.1016/S0093-934X(03)00305-5
   Blomert L, 2009, 3DM DIFFERENTIAL DIA
   Blomert L, 2011, NEUROIMAGE, V57, P695, DOI 10.1016/j.neuroimage.2010.11.003
   Blomert L, 2010, DYSLEXIA, V16, P300, DOI 10.1002/dys.405
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Boets B, 2008, BRAIN LANG, V106, P29, DOI 10.1016/j.bandl.2007.12.004
   Boets B, 2011, RES DEV DISABIL, V32, P560, DOI 10.1016/j.ridd.2010.12.020
   Bonte M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05356-3
   Bosse ML, 2007, COGNITION, V104, P198, DOI 10.1016/j.cognition.2006.05.009
   Brem S, 2009, HUM BRAIN MAPP, V30, P1833, DOI 10.1002/hbm.20751
   Brennan C, 2013, HUM BRAIN MAPP, V34, P3354, DOI 10.1002/hbm.22147
   Clayton FJ, 2018, SCI STUD READ, V22, P137, DOI 10.1080/10888438.2017.1390754
   Fawcett AJ, 1999, J MOTOR BEHAV, V31, P68, DOI 10.1080/00222899909601892
   Froyen D, 2008, NEUROSCI LETT, V430, P23, DOI 10.1016/j.neulet.2007.10.014
   Froyen D, 2011, DEVELOPMENTAL SCI, V14, P635, DOI 10.1111/j.1467-7687.2010.01007.x
   Froyen DJW, 2009, J COGNITIVE NEUROSCI, V21, P567, DOI 10.1162/jocn.2009.21061
   Gonzalez G.A., 2015, THESIS
   Gonzalez GF, 2017, BRAIN SCI, V7, DOI 10.3390/brainsci7010010
   Joanisse MF, 2000, J EXP CHILD PSYCHOL, V77, P30, DOI 10.1006/jecp.1999.2553
   Jones MW, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00071
   Karipidis II, 2017, HUM BRAIN MAPP, V38, P1038, DOI 10.1002/hbm.23437
   Keetels M, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00710
   Keetels M, 2016, ATTEN PERCEPT PSYCHO, V78, P938, DOI 10.3758/s13414-015-1034-y
   Kort W, 2005, WISC 3 NL
   Kronschnabel J, 2014, NEUROPSYCHOLOGIA, V62, P245, DOI 10.1016/j.neuropsychologia.2014.07.024
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Lallier M, 2018, PSYCHON B REV, V25, P386, DOI 10.3758/s13423-017-1273-0
   Ley A, 2012, J NEUROSCI, V32, P13273, DOI 10.1523/JNEUROSCI.0584-12.2012
   Lyon GR, 2003, ANN DYSLEXIA, V53, P1, DOI 10.1007/s11881-003-0001-9
   Manis FR, 1997, J EXP CHILD PSYCHOL, V66, P211, DOI 10.1006/jecp.1997.2383
   Maurer U, 2003, NEUROREPORT, V14, P2245, DOI 10.1097/00001756-200312020-00022
   Maurer U, 2008, J COGNITIVE NEUROSCI, V20, P1878, DOI 10.1162/jocn.2008.20125
   Maurer U, 2006, NEUROIMAGE, V33, P749, DOI 10.1016/j.neuroimage.2006.06.025
   McBrideChang C, 1996, CHILD DEV, V67, P1836, DOI 10.2307/1131735
   Moll K, 2016, CLIN NEUROPHYSIOL, V127, P1989, DOI 10.1016/j.clinph.2016.01.005
   Nash HM, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12423
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Paulesu E, 2000, NAT NEUROSCI, V3, P91
   Plewko J, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00393
   Price CJ, 2011, TRENDS COGN SCI, V15, P246, DOI 10.1016/j.tics.2011.04.001
   R Development Core Team, 2013, R LANG ENV STAT COMP
   Ramus F, 2003, CURR OPIN NEUROBIOL, V13, P212, DOI 10.1016/S0959-4388(03)00035-7
   Raschle NM, 2012, P NATL ACAD SCI USA, V109, P2156, DOI 10.1073/pnas.1107721109
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   Scott M, 2016, ATTEN PERCEPT PSYCHO, V78, P1496, DOI 10.3758/s13414-016-1087-6
   Shaywitz SE, 1998, P NATL ACAD SCI USA, V95, P2636, DOI 10.1073/pnas.95.5.2636
   Snellings P, 2010, ANN DYSLEXIA, V60, P151, DOI 10.1007/s11881-010-0039-4
   SNOWLING MJ, 1980, J EXP CHILD PSYCHOL, V29, P294, DOI 10.1016/0022-0965(80)90021-1
   Spivey M., 2000, P CHICAGO LINGUISTIC, V34, P205
   SUSSMAN JE, 1989, J SPEECH HEAR RES, V32, P151, DOI 10.1044/jshr.3201.151
   SUSSMAN JE, 1993, J SPEECH HEAR RES, V36, P380, DOI 10.1044/jshr.3602.380
   Tallal P, 2004, NAT REV NEUROSCI, V5, P721, DOI 10.1038/nrn1499
   Talsma D, 2005, J COGNITIVE NEUROSCI, V17, P1098, DOI 10.1162/0898929054475172
   Van Linden S, 2008, J CHILD LANG, V35, P809, DOI 10.1017/S0305000908008817
   Vandermosten M, 2010, P NATL ACAD SCI USA, V107, P10389, DOI 10.1073/pnas.0912858107
   Vidyasagar TR, 2010, TRENDS COGN SCI, V14, P57, DOI 10.1016/j.tics.2009.12.003
   Vroomen J, 2004, SPEECH COMMUN, V44, P55, DOI 10.1016/j.specom.2004.03.009
   Vroomen J., 2012, NEURAL BASEMULTISE, P363, DOI DOI 10.1201/9781439812174-24
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
   Zaric G, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00369
   Zaric G, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110337
NR 72
TC 1
Z9 1
U1 0
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD FEB 7
PY 2019
VL 10
AR 221
DI 10.3389/fpsyg.2019.00221
PG 13
WC Psychology, Multidisciplinary
SC Psychology
GA HK6SN
UT WOS:000458114300001
PM 30792685
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Luthra, S
   Guediche, S
   Blumstein, SE
   Myers, EB
AF Luthra, Sahil
   Guediche, Sara
   Blumstein, Sheila E.
   Myers, Emily B.
TI Neural substrates of subphonemic variation and lexical competition in
   spoken word recognition
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Lexical competition; phonetic variation; voice-onset time; inferior
   frontal gyrus; fMRI
ID GRANGER CAUSALITY ANALYSIS; INFERIOR FRONTAL GYRUS; LEFT PREFRONTAL
   CORTEX; CORTICAL ORGANIZATION; PHONETIC COMPETITION; SPEECH-PERCEPTION;
   LANGUAGE; REGIONS; INTEGRATION; ACTIVATION
AB In spoken word recognition, subphonemic variation influences lexical activation, with sounds near a category boundary increasing phonetic competition as well as lexical competition. The current study investigated the interplay of these factors using a visual world task in which participants were instructed to look at a picture of an auditory target (e.g. peacock). Eyetracking data indicated that participants were slowed when a voiced onset competitor (e.g. beaker) was also displayed, and this effect was amplified when acoustic-phonetic competition was increased. Simultaneously-collected fMRI data showed that several brain regions were sensitive to the presence of the onset competitor, including the supramarginal, middle temporal, and inferior frontal gyri, and functional connectivity analyses revealed that the coordinated activity of left frontal regions depends on both acoustic-phonetic and lexical factors. Taken together, results suggest a role for frontal brain structures in resolving lexical competition, particularly as atypical acoustic-phonetic information maps on to the lexicon.
C1 [Luthra, Sahil; Myers, Emily B.] Univ Connecticut, Dept Psychol Sci, Storrs, CT 06269 USA.
   [Guediche, Sara] BCBL Basque Ctr Cognit Brain & Language, Donostia San Sebastian, Spain.
   [Blumstein, Sheila E.] Brown Univ, Dept Cognit Linguist & Psychol Sci, Providence, RI 02912 USA.
   [Blumstein, Sheila E.] Brown Univ, Brown Inst Brain Sci, Providence, RI 02912 USA.
   [Myers, Emily B.] Univ Connecticut, Dept Speech Language & Hearing Sci, Storrs, CT USA.
   [Myers, Emily B.] Haskins Labs Inc, New Haven, CT USA.
RP Luthra, S (corresponding author), Univ Connecticut, Dept Psychol Sci, Storrs, CT 06269 USA.
EM sahil.luthra@uconn.edu
RI ; Guediche, Sara/B-3895-2017
OI /0000-0002-9475-764X; Guediche, Sara/0000-0002-8331-1378; Luthra,
   Sahil/0000-0002-3517-2609
FU National Institutes of Health (NIH)United States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USA [R01 DC013064];
   NIH NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R01 DC006220]; Spanish Ministry
   of Economy and Competitiveness through the Severo Ochoa Programme for
   Centres/Units of Excellence in RD [SEV-2015-490]; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC013064, R01DC013064] Funding Source: NIH RePORTER
FX Research was supported by National Institutes of Health (NIH) [grant
   number: R01 DC013064] to EBM and NIH NIDCD [grant number R01 DC006220]
   to SEB. SG was supported by the Spanish Ministry of Economy and
   Competitiveness through the Severo Ochoa Programme for Centres/Units of
   Excellence in R&D [SEV-2015-490]. The contents of this paper reflect the
   views of the authors and not those of the funding agencies.
CR Abramson A. S., 1985, PHONETIC LINGUISTICS, P25
   Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   ANDRUSKI JE, 1994, COGNITION, V52, P163, DOI 10.1016/0010-0277(94)90042-6
   Badre D, 2004, NEURON, V41, P473, DOI 10.1016/S0896-6273(03)00851-1
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   Blumstein SE, 2005, J COGNITIVE NEUROSCI, V17, P1353, DOI 10.1162/0898929054985473
   Borsky S, 1998, J ACOUST SOC AM, V103, P2670, DOI 10.1121/1.422787
   Braver TS, 2001, CEREB CORTEX, V11, P825, DOI 10.1093/cercor/11.9.825
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Burton MW, 2000, J COGNITIVE NEUROSCI, V12, P679, DOI 10.1162/089892900562309
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Chrysikou EG, 2014, NEUROPSYCHOLOGIA, V62, P341, DOI 10.1016/j.neuropsychologia.2013.10.021
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   COLTHEART M, 1981, Q J EXP PSYCHOL-A, V33, P497, DOI 10.1080/14640748108400805
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Desai R, 2008, J COGNITIVE NEUROSCI, V20, P1174, DOI 10.1162/jocn.2008.20081
   Erb J, 2013, J NEUROSCI, V33, P10688, DOI 10.1523/JNEUROSCI.4596-12.2013
   Evans S, 2014, CEREB CORTEX, V24, P2350, DOI 10.1093/cercor/bht083
   Fiez JA, 1997, HUM BRAIN MAPP, V5, P79, DOI 10.1002/(SICI)1097-0193(1997)5:2<79::AID-HBM1>3.0.CO;2-J
   Fischl B, 2012, NEUROIMAGE, V62, P774, DOI 10.1016/j.neuroimage.2012.01.021
   Francis AL, 2008, J ACOUST SOC AM, V124, P1234, DOI 10.1121/1.2945161
   Gabrieli JDE, 1998, P NATL ACAD SCI USA, V95, P906, DOI 10.1073/pnas.95.3.906
   Gold BT, 2002, NEURON, V35, P803, DOI 10.1016/S0896-6273(02)00800-0
   Gow DW, 2016, LANG COGN NEUROSCI, V31, P841, DOI 10.1080/23273798.2015.1029498
   Gow DW, 2012, BRAIN LANG, V121, P273, DOI 10.1016/j.bandl.2012.03.005
   Gow DW, 2008, NEUROIMAGE, V43, P614, DOI 10.1016/j.neuroimage.2008.07.027
   Grabowski TJ, 1998, NEUROIMAGE, V7, P232, DOI 10.1006/nimg.1998.0324
   Guediche S, 2013, J COGNITIVE NEUROSCI, V25, P706, DOI 10.1162/jocn_a_00351
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Kucera H., 1967, COMPUTATIONAL ANAL P
   Leonard MK, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13619
   Liebenthal E, 2005, CEREB CORTEX, V15, P1621, DOI 10.1093/cercor/bhi040
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Magnuson JS, 2007, COGNITIVE SCI, V31, P133, DOI 10.1080/03640210709336987
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McLaren DG, 2012, NEUROIMAGE, V61, P1277, DOI 10.1016/j.neuroimage.2012.03.068
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B, 2009, J MEM LANG, V60, P65, DOI 10.1016/j.jml.2008.07.002
   Mertus J. A., 2002, BLISS BROWN LAB INTE
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   MILLER JL, 1994, COGNITION, V50, P271, DOI 10.1016/0010-0277(94)90031-0
   Minicucci D, 2013, NEUROPSYCHOLOGIA, V51, P1980, DOI 10.1016/j.neuropsychologia.2013.06.016
   Mirman D., 2014, GROWTH CURVE ANAL VI
   Mirman D, 2008, J MEM LANG, V59, P475, DOI 10.1016/j.jml.2007.11.006
   Myers EB, 2008, CEREB CORTEX, V18, P278, DOI 10.1093/cercor/bhm053
   Myers EB, 2007, NEUROPSYCHOLOGIA, V45, P1463, DOI 10.1016/j.neuropsychologia.2006.11.005
   Myers EB, 2012, J COGNITIVE NEUROSCI, V24, P1695, DOI 10.1162/jocn_a_00243
   Myers EB, 2009, PSYCHOL SCI, V20, P895, DOI 10.1111/j.1467-9280.2009.02380.x
   Nixon P, 2004, J COGNITIVE NEUROSCI, V16, P289, DOI 10.1162/089892904322984571
   Obleser J, 2007, J NEUROSCI, V27, P2283, DOI 10.1523/JNEUROSCI.4663-06.2007
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   Peramunage D, 2011, J COGNITIVE NEUROSCI, V23, P593, DOI 10.1162/jocn.2010.21489
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   Poldrack RA, 2001, J COGNITIVE NEUROSCI, V13, P687, DOI 10.1162/089892901750363235
   Prabhakaran R, 2006, NEUROPSYCHOLOGIA, V44, P2209, DOI 10.1016/j.neuropsychologia.2006.05.025
   Raettig T, 2008, NEUROIMAGE, V39, P1420, DOI 10.1016/j.neuroimage.2007.09.030
   Ranaweera RD, 2016, HEARING RES, V331, P57, DOI 10.1016/j.heares.2015.09.017
   Righi G, 2010, J COGNITIVE NEUROSCI, V22, P213, DOI 10.1162/jocn.2009.21200
   Rogers JC, 2017, J COGNITIVE NEUROSCI, V29, P919, DOI 10.1162/jocn_a_01096
   Saad ZS, 2012, NEUROIMAGE, V62, P768, DOI 10.1016/j.neuroimage.2011.09.016
   Schwartze M, 2016, BRAIN LANG, V161, P28, DOI 10.1016/j.bandl.2015.08.005
   Scott SK, 2006, J ACOUST SOC AM, V120, P1075, DOI 10.1121/1.2216725
   Talairach J, 1988, COPLANAR STEREOTAXIC
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Thompson-Schill SL, 1997, P NATL ACAD SCI USA, V94, P14792, DOI 10.1073/pnas.94.26.14792
   Turkeltaub PE, 2010, BRAIN LANG, V114, P1, DOI 10.1016/j.bandl.2010.03.008
   Utman JA, 2001, BRAIN LANG, V79, P444, DOI 10.1006/brln.2001.2500
   Wagner AD, 2001, NEURON, V31, P329, DOI 10.1016/S0896-6273(01)00359-2
   Wild CJ, 2012, NEUROIMAGE, V60, P1490, DOI 10.1016/j.neuroimage.2012.01.035
   Xie X, 2018, J COGNITIVE NEUROSCI, V30, P267, DOI 10.1162/jocn_a_01208
   Zatorre RJ, 1996, CEREB CORTEX, V6, P21, DOI 10.1093/cercor/6.1.21
NR 79
TC 4
Z9 4
U1 1
U2 13
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PD FEB 7
PY 2019
VL 34
IS 2
BP 151
EP 169
DI 10.1080/23273798.2018.1531140
PG 19
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA HC8BS
UT WOS:000452027000002
PM 31106225
OA Green Published, Green Accepted
DA 2021-02-24
ER

PT J
AU Yu, ACL
AF Yu, Alan C. L.
TI On the nature of the perception-production link: Individual variability
   in English sibilant-vowel coarticulation
SO LABORATORY PHONOLOGY
LA English
DT Article
DE Perception-production link; perceptual compensation; coarticulation;
   sibilant; rounding; English
ID ACOUSTIC CONSEQUENCES; TIME-COURSE; COMPENSATION; INFORMATION; SPEAKERS;
   DISCRIMINATION; DISTINCTNESS; TRANSITIONS; FRICATIVES; IMITATION
AB This study aims to elucidate the nature of the perception-production link with respect to coarticulation by examining the production and perception of English sibilants before different vowels. A group of native speakers of American English were recorded reciting a set of /s/-and /integral/-initial words in different vocalic contexts and took part in an identification experiment designed to test their ability to adjust their perceptual expectation in light of the vocalic influence on the preceding sibilant. Significant correlations between the production and perception results were observed when by-subject estimates for context-relevant predictors (and their interactions) in the perception regression models were examined in relation to the by-subject estimates of the production regression models. These results suggest a positive correlation between how much an individual attends to context-specific variation in perception and how the sibilant contrast is realized in specific vocalic contexts. Ramifications of these findings are discussed for the nature of speech perception and production and the understanding of sound change.
C1 [Yu, Alan C. L.] Univ Chicago, Dept Linguist, Phonol Lab, Chicago, IL 60637 USA.
RP Yu, ACL (corresponding author), Univ Chicago, Dept Linguist, Phonol Lab, Chicago, IL 60637 USA.
EM aclyu@uchicago.edu
FU National Science FoundationNational Science Foundation (NSF)
   [BCS-0949754, BCS-1827409]; Linguistics in Open Access foundation
FX This work was partially supported by National Science Foundation Grants
   BCS-0949754 and BCS-1827409. Special thanks go to the anonymous
   reviewers as well as the handling editors for their useful comments and
   criticisms. Many thanks also to the audiences at the Sound Change in
   Interacting Human Systems at University of California, Berkeley, and at
   the Linguistics department colloquia at the University of Arizona,
   Cornell University, Hong Kong University, McGill University, New York
   University, University of Toronto, Stanford, the Ohio State University
   and UCLA. All errors are of course my own.; I also thank the Linguistics
   in Open Access foundation (https://www.lingoa.eu/) for financial support
   of open access publication of Laboratory Phonology.
CR American Psychiatric Ass ociation, 2013, DIAGN STAT MAN MENT, P271, DOI DOI 10.1176/APPI.BOOKS.9780890425596
   [Anonymous], 1994, INT CLASS DIS
   Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001
   Baker A, 2011, LANG VAR CHANGE, V23, P347, DOI 10.1017/S0954394511000135
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Bates D., 2011, LME4
   Beddor P. S., 1998, P 24 ANN M BERK LING, P320, DOI [10.3765/bls.v24i1.1235, DOI 10.3765/BLS.V24I1.1235]
   Beddor PS, 2018, LANGUAGE, V94, P931, DOI 10.1353/lan.2018.0051
   Beddor PS, 2013, J ACOUST SOC AM, V133, P2350, DOI 10.1121/1.4794366
   Beddor PS, 2009, LANGUAGE, V85, P785
   Beddor PS, 2002, J PHONETICS, V30, P591, DOI 10.1006/jpho.2002.0177
   Beddor PS, 1999, J ACOUST SOC AM, V106, P2868, DOI 10.1121/1.428111
   Blacklock Oliver, 2004, THESIS
   Blumstein SE, 2005, J COGNITIVE NEUROSCI, V17, P1353, DOI 10.1162/0898929054985473
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Cole J, 2010, J PHONETICS, V38, P167, DOI 10.1016/j.wocn.2009.08.004
   Diehl J. J., 2011, INT M AUT RES DIAD R
   Dimov S., 2012, INITIATION SOUND CHA, P185, DOI DOI 10.1075/CILT.323.15DIM
   Fowler CA, 2006, PERCEPT PSYCHOPHYS, V68, P161, DOI 10.3758/BF03193666
   Fowler CA, 2000, PERCEPT PSYCHOPHYS, V62, P21, DOI 10.3758/BF03212058
   Garrett Andrew, 2013, ORIGINS SOUND CHANGE, P51, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0003
   Grosvald M, 2012, APPL PSYCHOLINGUIST, V33, P55, DOI 10.1017/S0142716411000105
   Grosvald M, 2009, J PHONETICS, V37, P173, DOI 10.1016/j.wocn.2009.01.002
   Harrington J, 2008, J ACOUST SOC AM, V123, P2825, DOI 10.1121/1.2897042
   Heinze G., 2016, LOGISTF
   Houde JF, 2002, J SPEECH LANG HEAR R, V45, P295, DOI 10.1044/1092-4388(2002/023)
   HUGHES GW, 1956, J ACOUST SOC AM, V28, P303, DOI 10.1121/1.1908271
   Iskarous K, 2011, J ACOUST SOC AM, V129, P944, DOI 10.1121/1.3514537
   IVERSON JANA M, 1999, J CONSCIOUSNESS STUD, V6, P19
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   Kataoka R., 2011, THESIS
   Katseff S, 2012, LANG SPEECH, V55, P295, DOI 10.1177/0023830911417802
   Kong EJ, 2016, J PHONETICS, V59, P40, DOI 10.1016/j.wocn.2016.08.006
   Li FF, 2009, J PHONETICS, V37, P111, DOI 10.1016/j.wocn.2008.10.001
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Livescu K, 2016, COMPUT SPEECH LANG, V36, P212, DOI 10.1016/j.csl.2015.07.003
   Lotto AJ, 2006, PERCEPT PSYCHOPHYS, V68, P178, DOI 10.3758/BF03193667
   Mahler B. A., 2012, THESIS
   Mahr T, 2015, COGNITION, V142, P345, DOI 10.1016/j.cognition.2015.05.009
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P213, DOI 10.3758/BF03204377
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   Mielke J, 2016, LANGUAGE, V92, P101, DOI 10.1353/lan.2016.0019
   Mirman D., 2014, GROWTH CURVE ANAL VI
   Munson B, 2007, LANG LINGUIST COMPAS, V1, DOI 10.1111/j.1749-818x.2007.00028.x
   Newman RS, 2001, J ACOUST SOC AM, V109, P1181, DOI 10.1121/1.1348009
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007
   NITTROUER S, 1995, J ACOUST SOC AM, V97, P520, DOI 10.1121/1.412278
   Ohala J. J., 1993, HIST LINGUISTICS PRO, P237
   OHALA JJ, 1993, LANG SPEECH, V36, P155, DOI 10.1177/002383099303600303
   Perkell JS, 2004, J SPEECH LANG HEAR R, V47, P1259, DOI 10.1044/1092-4388(2004/095)
   Perkell JS, 2004, J ACOUST SOC AM, V116, P2338, DOI 10.1121/1.1787524
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Pinget A. -F., 2015, ACTUATION SOUND CHAN
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   Podesva RJ, 2002, LANGUAGE AND SEXUALITY: CONTESTING MEANING IN THEORY AND PRACTICE, P175
   REPP BH, 1981, PERCEPT PSYCHOPHYS, V30, P217, DOI 10.3758/BF03214276
   Shadle CH, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1521, DOI 10.1109/ICSLP.1996.607906
   Shiller DM, 2009, J ACOUST SOC AM, V125, P1103, DOI 10.1121/1.3058638
   SOLI SD, 1981, J ACOUST SOC AM, V70, P976, DOI 10.1121/1.387032
   Sonderegger M, 2010, COGNITION IN FLUX, P375
   Stevens M, 2014, LOQUENS, V1, DOI 10.3989/loquens.2014.003
   Strand EA, 1999, J LANG SOC PSYCHOL, V18, P86, DOI 10.1177/0261927X99018001006
   Stuart-Smith J., 2007, LAB PHONOLOGY, V9, P65
   Tomiak G. R., 1990, THESIS
   Viswanathan N, 2010, J EXP PSYCHOL HUMAN, V36, P1005, DOI 10.1037/a0018391
   Whalen D. H., 1999, P 14 ICPHS
   WHALEN DH, 1981, J ACOUST SOC AM, V69, P275, DOI 10.1121/1.385348
   WHALEN DH, 1991, J ACOUST SOC AM, V90, P1776, DOI 10.1121/1.401658
   Wickham H., 2012, PLYR
   Yu A. C. L., 2013, ORIGINS SOUND CHANGE, P201, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0010
   Yu ACL, 2016, J ACOUST SOC AM, V139, P1672, DOI 10.1121/1.4944992
   Yu ACL, 2014, J ACOUST SOC AM, V136, P382, DOI 10.1121/1.4883380
   Yu ACL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0074746
   Yu ACL, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011950
   Zellou G, 2017, LANG COGN NEUROSCI, V32, P776, DOI 10.1080/23273798.2016.1275710
   Zellou G, 2017, J PHONETICS, V61, P13, DOI 10.1016/j.wocn.2016.12.002
   Zellou G, 2016, J ACOUST SOC AM, V140, P3560, DOI 10.1121/1.4966232
NR 79
TC 4
Z9 4
U1 0
U2 1
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 1868-6346
EI 1868-6354
J9 LAB PHONOL
JI Lab. Phonol.
PD FEB 6
PY 2019
VL 10
IS 1
AR 2
DI 10.5334/labphon.97
PG 29
WC Linguistics; Language & Linguistics
SC Linguistics
GA HZ4JC
UT WOS:000468812600001
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Xu, WY
   Kolozsvari, OB
   Oostenveld, R
   Leppanen, PHT
   Hamalainen, JA
AF Xu, Weiyong
   Kolozsvari, Orsolya Beatrix
   Oostenveld, Robert
   Leppanen, Paavo Herman Tapio
   Hamalainen, Jarmo Arvid
TI Audiovisual Processing of Chinese Characters Elicits Suppression and
   Congruency Effects in MEG
SO FRONTIERS IN HUMAN NEUROSCIENCE
LA English
DT Article
DE audiovisual integration; magnetoencephalography; auditory cortex;
   language learning; reading; Chinese characters
ID MULTISENSORY INTEGRATION; FUNCTIONAL CONNECTIVITY; DEVELOPMENTAL
   DYSLEXIA; SPEECH-PERCEPTION; CHILDREN LEARN; TIME-COURSE; BRAIN;
   RESPONSES; HUMANS; ACTIVATION
AB Learning to associate written letters/characters with speech sounds is crucial for reading acquisition. Most previous studies have focused on audiovisual integration in alphabetic languages. Less is known about logographic languages such as Chinese characters, which map onto mostly syllable-based morphemes in the spoken language. Here we investigated how long-term exposure to native language affects the underlying neural mechanisms of audiovisual integration in a logographic language using magnetoencephalography (MEG). MEG sensor and source data from 12 adult native Chinese speakers and a control group of 13 adult Finnish speakers were analyzed for audiovisual suppression (bimodal responses vs. sum of unimodal responses) and congruency (bimodal incongruent responses vs. bimodal congruent responses) effects. The suppressive integration effect was found in the left angular and supramarginal gyri (205-365 ms), left inferior frontal and left temporal cortices (575-800 ms) in the Chinese group. The Finnish group showed a distinct suppression effect only in the right parietal and occipital cortices at a relatively early time window (285-460 ms). The congruency effect was only observed in the Chinese group in left inferior frontal and superior temporal cortex in a late time window (about 500-800 ms) probably related to modulatory feedback from multi-sensory regions and semantic processing. The audiovisual integration in a logographic language showed a clear resemblance to that in alphabetic languages in the left superior temporal cortex, but with activation specific to the logographic stimuli observed in the left inferior frontal cortex. The current MEG study indicated that learning of logographic languages has a large impact on the audiovisual integration of written characters with some distinct features compared to previous results on alphabetic languages.
C1 [Xu, Weiyong; Kolozsvari, Orsolya Beatrix; Leppanen, Paavo Herman Tapio; Hamalainen, Jarmo Arvid] Univ Jyvaskyla, Dept Psychol, Jyvaskyla, Finland.
   [Xu, Weiyong; Kolozsvari, Orsolya Beatrix; Leppanen, Paavo Herman Tapio; Hamalainen, Jarmo Arvid] Univ Jyvaskyla, Dept Psychol, Jyvaskyla Ctr Interdisciplinary Brain Res, Jyvaskyla, Finland.
   [Oostenveld, Robert] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
   [Oostenveld, Robert] Karolinska Inst, Dept Clin Neurosci, NatMEG, Stockholm, Sweden.
RP Xu, WY (corresponding author), Univ Jyvaskyla, Dept Psychol, Jyvaskyla, Finland.; Xu, WY (corresponding author), Univ Jyvaskyla, Dept Psychol, Jyvaskyla Ctr Interdisciplinary Brain Res, Jyvaskyla, Finland.
EM weiyong.w.xu@jyu.fi
RI Xu, Weiyong/AAD-3793-2019; Oostenveld, Robert/D-3259-2009
OI Xu, Weiyong/0000-0003-4453-9836; Oostenveld, Robert/0000-0002-1974-1293;
   Hamalainen, Jarmo/0000-0001-7188-8148; Kolozsvari, Orsolya
   Beatrix/0000-0002-1619-6314
FU European UnionEuropean Commission [641652, 641858]; Academy of
   FinlandAcademy of FinlandEuropean Commission [292466]
FX This study was supported by the European Union H2020 Marie
   Sklodowska-Curie Actions (MSCA)-ITN-2014-ETN Programme, "Advancing brain
   research in children's developmental neurocognitive disorders'' project
   (ChildBrain, #641652), "Understanding and predicting developmental
   language abilities and disorders in multilingual Europe'' project
   (Predictable, #641858) and the Academy of Finland (MultiLeTe, #292466).
CR Ahveninen J, 2006, P NATL ACAD SCI USA, V103, P14608, DOI 10.1073/pnas.0510480103
   Andersen TS, 2004, COGNITIVE BRAIN RES, V21, P301, DOI 10.1016/j.cogbrainres.2004.06.004
   Bernstein LE, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00386
   Besle J, 2004, COGN PROCESS, V5, P189, DOI DOI 10.1007/S10339-004-0026-Y
   Blau V, 2008, EUR J NEUROSCI, V28, P500, DOI 10.1111/j.1460-9568.2008.06350.x
   Brem S, 2010, P NATL ACAD SCI USA, V107, P7939, DOI 10.1073/pnas.0904402107
   Bremmer F, 2001, NEURON, V29, P287, DOI 10.1016/S0896-6273(01)00198-2
   Calvert GA, 2004, J PHYSIOL-PARIS, V98, P191, DOI 10.1016/j.jphysparis.2004.03.018
   Calvert GA, 2001, NEUROIMAGE, V14, P427, DOI 10.1006/nimg.2001.0812
   Calvert GA, 2001, CEREB CORTEX, V11, P1110, DOI 10.1093/cercor/11.12.1110
   Campanella S, 2007, TRENDS COGN SCI, V11, P535, DOI 10.1016/j.tics.2007.10.001
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155
   Cappe C, 2010, J NEUROSCI, V30, P12572, DOI 10.1523/JNEUROSCI.1099-10.2010
   Cohen YE, 2009, HEARING RES, V258, P100, DOI 10.1016/j.heares.2009.01.011
   Dale AM, 2000, NEURON, V26, P55, DOI 10.1016/S0896-6273(00)81138-1
   Doehrmann O, 2008, BRAIN RES, V1242, P136, DOI 10.1016/j.brainres.2008.03.071
   Du YC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090794
   Fort A, 2002, CEREB CORTEX, V12, P1031, DOI 10.1093/cercor/12.10.1031
   Foxe JJ, 2000, COGNITIVE BRAIN RES, V10, P77, DOI 10.1016/S0926-6410(00)00024-0
   Froyen DJW, 2009, J COGNITIVE NEUROSCI, V21, P567, DOI 10.1162/jocn.2009.21061
   Gramfort A, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00267
   Grunewald A, 1999, J NEUROPHYSIOL, V82, P330
   HAMALAINEN MS, 1994, MED BIOL ENG COMPUT, V32, P35, DOI 10.1007/BF02512476
   Hein G, 2007, J NEUROSCI, V27, P7881, DOI 10.1523/JNEUROSCI.1740-07.2007
   Herdman AT, 2006, NEUROSCI LETT, V399, P61, DOI 10.1016/j.neulet.2006.01.069
   Hocking J, 2009, BRAIN LANG, V108, P89, DOI 10.1016/j.bandl.2008.10.005
   Holloway ID, 2015, CEREB CORTEX, V25, P1544, DOI 10.1093/cercor/bht347
   Jones JA, 2003, NEUROREPORT, V14, P1129, DOI 10.1097/00001756-200306110-00006
   Jost LB, 2014, BRAIN TOPOGR, V27, P786, DOI 10.1007/s10548-013-0336-4
   Kamke MR, 2012, NEUROIMAGE, V62, P1334, DOI 10.1016/j.neuroimage.2012.05.063
   Kayser C, 2008, CEREB CORTEX, V18, P1560, DOI 10.1093/cercor/bhm187
   Kayser SJ, 2017, NEUROIMAGE, V148, P31, DOI 10.1016/j.neuroimage.2017.01.010
   Kuo WJ, 2001, NEUROREPORT, V12, P3997, DOI 10.1097/00001756-200112210-00029
   Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123
   Lafontaine H, 2012, NEUROPSYCHOLOGIA, V50, P2897, DOI 10.1016/j.neuropsychologia.2012.08.020
   Laurienti PJ, 2005, EXP BRAIN RES, V166, P289, DOI 10.1007/s00221-005-2370-2
   Lewis JW, 2000, CEREB CORTEX, V10, P873, DOI 10.1093/cercor/10.9.873
   LIBERMAN AM, 1992, ORTHOGRAPHY PHONOLOG, P167, DOI DOI 10.1016/S0166-4115(08)62794-6
   Lin FH, 2006, NEUROIMAGE, V31, P160, DOI 10.1016/j.neuroimage.2005.11.054
   Lutkenhoner B, 2002, NEUROIMAGE, V15, P509, DOI 10.1006/nimg.2001.0991
   Madec S, 2016, NEUROIMAGE, V132, P359, DOI 10.1016/j.neuroimage.2016.02.010
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Martin A, 2001, CURR OPIN NEUROBIOL, V11, P194, DOI 10.1016/S0959-4388(00)00196-3
   Maurer U, 2006, NEUROIMAGE, V33, P749, DOI 10.1016/j.neuroimage.2006.06.025
   McBride CA, 2016, EDUC PSYCHOL REV, V28, P523, DOI 10.1007/s10648-015-9318-2
   Meredith MA, 2002, COGNITIVE BRAIN RES, V14, P31, DOI 10.1016/S0926-6410(02)00059-9
   Molholm S, 2002, COGNITIVE BRAIN RES, V14, P115, DOI 10.1016/S0926-6410(02)00066-6
   Murray MM, 2016, TRENDS NEUROSCI, V39, P567, DOI 10.1016/j.tins.2016.05.003
   Murray MM, 2016, NEUROPSYCHOLOGIA, V83, P161, DOI 10.1016/j.neuropsychologia.2015.08.011
   Murray MM, 2009, HEARING RES, V258, P121, DOI 10.1016/j.heares.2009.04.022
   Ojanen V, 2005, NEUROIMAGE, V25, P333, DOI 10.1016/j.neuroimage.2004.12.001
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Pattamadilok C, 2011, BRAIN LANG, V116, P116, DOI 10.1016/j.bandl.2010.12.002
   Perfetti CA, 1998, J EXP PSYCHOL LEARN, V24, P101, DOI 10.1037/0278-7393.24.1.101
   Perrault TJ, 2005, J NEUROPHYSIOL, V93, P2575, DOI 10.1152/jn.00926.2004
   Price CJ, 2000, J ANAT, V197, P335, DOI 10.1046/j.1469-7580.2000.19730335.x
   Pugh KR, 2000, PSYCHOL SCI, V11, P51, DOI 10.1111/1467-9280.00214
   Raij T, 2000, NEURON, V28, P617, DOI 10.1016/S0896-6273(00)00138-0
   Russeler J, 2018, BRAIN IMAGING BEHAV, V12, P357, DOI 10.1007/s11682-017-9694-y
   Schlaggar BL, 2007, ANNU REV NEUROSCI, V30, P475, DOI 10.1146/annurev.neuro.28.061604.135645
   Schroeder CE, 2002, COGNITIVE BRAIN RES, V14, P187, DOI 10.1016/S0926-6410(02)00073-3
   Schroger E, 1998, PSYCHOPHYSIOLOGY, V35, P755, DOI 10.1111/1469-8986.3560755
   Service E, 2007, J COGNITIVE NEUROSCI, V19, P1193, DOI 10.1162/jocn.2007.19.7.1193
   Shu H, 2003, INT J PSYCHOL, V38, P274, DOI 10.1080/00207590344000060
   Simos PG, 2013, BRAIN LANG, V125, P156, DOI 10.1016/j.bandl.2012.07.003
   Sperdin HF, 2009, FRONT INTEGR NEUROSC, V3, DOI 10.3389/neuro.07.002.2009
   Stein BE, 2008, NAT REV NEUROSCI, V9, P255, DOI 10.1038/nrn2331
   Tan LH, 2005, P NATL ACAD SCI USA, V102, P8781, DOI 10.1073/pnas.0503523102
   Tan LH, 2001, NEUROIMAGE, V13, P836, DOI 10.1006/nimg.2001.0749
   Tan LH, 2000, HUM BRAIN MAPP, V10, P16
   Taulu S, 2005, J APPL PHYS, V97, DOI 10.1063/1.1935742
   Taulu S, 2006, PHYS MED BIOL, V51, P1759, DOI 10.1088/0031-9155/51/7/008
   Taulu S, 2004, BRAIN TOPOGR, V16, P269, DOI 10.1023/b:brat.0000032864.93890.f9
   Teder-Salejarvi WA, 2002, COGNITIVE BRAIN RES, V14, P106, DOI 10.1016/S0926-6410(02)00065-4
   van Atteveldt N, 2004, NEURON, V43, P271, DOI 10.1016/j.neuron.2004.06.025
   van Atteveldt N, 2014, TRENDS NEUROSCI EDUC, V3, P44, DOI 10.1016/j.tine.2014.04.001
   van Atteveldt N, 2014, NEURON, V81, P1240, DOI 10.1016/j.neuron.2014.02.044
   van Atteveldt N, 2009, HEARING RES, V258, P152, DOI 10.1016/j.heares.2009.05.007
   van Atteveldt NM, 2007, NEUROIMAGE, V36, P1345, DOI 10.1016/j.neuroimage.2007.03.065
   van Atteveldt NM, 2007, CEREB CORTEX, V17, P962, DOI 10.1093/cercor/bhl007
   Vartiainen J, 2009, J NEUROSCI, V29, P9271, DOI 10.1523/JNEUROSCI.5860-08.2009
   Wagner AD, 2001, NEURON, V31, P329, DOI 10.1016/S0896-6273(01)00359-2
   Wang SP, 2008, NEUROPSYCHOLOGIA, V46, P1371, DOI 10.1016/j.neuropsychologia.2007.12.020
   Wu CY, 2012, NEUROIMAGE, V63, P381, DOI 10.1016/j.neuroimage.2012.06.047
   Xu WY, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00304
   Zaric G, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00369
   Zaric G, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110337
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
NR 88
TC 3
Z9 3
U1 0
U2 10
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-5161
J9 FRONT HUM NEUROSCI
JI Front. Hum. Neurosci.
PD FEB 6
PY 2019
VL 13
AR 18
DI 10.3389/fnhum.2019.00018
PG 12
WC Neurosciences; Psychology
SC Neurosciences & Neurology; Psychology
GA HK6SZ
UT WOS:000458116000001
PM 30787872
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Han, JJ
   Suh, MW
   Park, MK
   Koo, JW
   Lee, JH
   Oh, SH
AF Han, Jae Joon
   Suh, Myung-Whan
   Park, Moo Kyun
   Koo, Ja-Won
   Lee, Jun Ho
   Oh, Seung Ha
TI A Predictive Model for Cochlear Implant Outcome in Children with
   Cochlear Nerve Deficiency
SO SCIENTIFIC REPORTS
LA English
DT Article
ID SPEECH-PERCEPTION; DEAF-CHILDREN; VESTIBULOCOCHLEAR NERVES; RESIDUAL
   HEARING; IMAGING FINDINGS; LOW-FREQUENCY; APLASIA; AGE; HYPOPLASIA;
   RECOGNITION
AB The outcome of cochlear implantation (CI) in patients with cochlear nerve deficiency (CND) is variable, resulting in a wide range of speech perception performance, from degrees of environmental sound perception to conversation without lip-reading. Twenty-five cochlear implantees with CND were enrolled retrospectively to determine the factors correlated with CI outcome in patients with CND and to develop a predictive model for CI outcome. CI outcome was evaluated using the Categories of Auditory Performance (CAP) score at 2 years after CI. Patients with negative auditory brainstem response (ABR) showed a significantly lower CAP score than those with positive ABR (2.5 +/- 1.7, 4.8 +/- 0.7; p = 0.001). The area ratio of vestibulocochlear nerve (VCN) to facial nerve (FN) at the cerebellopontine angle on magnetic resonance images was positively correlated with CI outcome (p < 0.001). With multiple regression analysis, a predictive equation accounting for 66% of variance of CAP score at 2 years after CI was deduced: CAP score = 0.7 + 1.9 * (ABR) + 1.2 * (VCN/FN). We found that preoperative ABR and area ratio of VCN to FN at the cerebellopontine angle could predict CI outcome in patients with CND. Preoperative counselling based on our predictive model might be helpful to determine treatment modality for auditory rehabilitation and which ear to implant.
C1 [Han, Jae Joon; Koo, Ja-Won] Seoul Natl Univ, Dept Otorhinolaryngol Head & Neck Surg, Bundang Hosp, Seongnam, South Korea.
   [Suh, Myung-Whan; Park, Moo Kyun; Lee, Jun Ho; Oh, Seung Ha] Seoul Natl Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg, Seoul, South Korea.
RP Oh, SH (corresponding author), Seoul Natl Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg, Seoul, South Korea.
EM shaoh@snu.ac.kr
RI Suh, Myung-Whan/AAZ-9615-2020
OI Suh, Myung-Whan/0000-0003-1301-2249; Park, Moo Kyun/0000-0002-8635-797X
FU Korea Health Industry Development Institute (KHIDI) - Ministry of Health
   & Welfare, Republic of Korea [HI17C1648]; Basic Science Research Program
   through the National Research Foundation of Korea(NRF) - Ministry of
   Education, Science and Technology [NRF-2016R1D1A1B03930074]
FX This research was supported by a grant of the Korea Health Industry
   Development Institute (KHIDI) funded by the Ministry of Health &
   Welfare, Republic of Korea (grant number: HI17C1648) and by Basic
   Science Research Program through the National Research Foundation of
   Korea(NRF) funded by the Ministry of Education, Science and Technology
   (NRF-2016R1D1A1B03930074).
CR Birman CS, 2016, OTOL NEUROTOL, V37, P438, DOI 10.1097/MAO.0000000000000997
   Black Jane, 2011, Cochlear Implants Int, V12, P67, DOI 10.1179/146701010X486417
   Blake KD, 2008, AM J MED GENET A, V146A, P585, DOI 10.1002/ajmg.a.32179
   Blamey P, 1997, AM J OTOL, V18, pS11
   Buchman CA, 2011, LARYNGOSCOPE, V121, P1979, DOI 10.1002/lary.22032
   Buchner A, 2009, AUDIOL NEURO-OTOL, V14, P8, DOI 10.1159/000206490
   Busa J, 2007, PEDIATRICS, V120, P898, DOI 10.1542/peds.2007-2333
   Casselman JW, 1997, RADIOLOGY, V202, P773, DOI 10.1148/radiology.202.3.9051033
   Chang DT, 2010, ARCH OTOLARYNGOL, V136, P648, DOI 10.1001/archoto.2010.90
   Chao XH, 2016, ACTA OTO-LARYNGOL, V136, P1051, DOI 10.1080/00016489.2016.1179788
   Ching TYC, 2004, EAR HEARING, V25, P9, DOI 10.1097/01.AUD.0000111261.84611.C8
   Choi SJ, 2016, LARYNGOSCOPE, V126, P2817, DOI 10.1002/lary.26014
   Chung JY, 2018, BIOMED RES INT, V2018, DOI 10.1155/2018/5675848
   Clemmens CS, 2013, OTOLARYNG HEAD NECK, V149, P318, DOI 10.1177/0194599813487681
   Colletti L, 2014, OTOLARYNG HEAD NECK, V151, P308, DOI 10.1177/0194599814531913
   Connor CM, 2006, EAR HEARING, V27, P628, DOI 10.1097/01.aud.0000240640.59205.42
   Chiossi JSC, 2017, INT J PEDIATR OTORHI, V100, P119, DOI 10.1016/j.ijporl.2017.06.036
   Dagkiran M, 2016, J INT ADV OTOL, V12, P43, DOI 10.5152/iao.2015.1450
   Deguine O, 1995, Ann Otol Rhinol Laryngol Suppl, V166, P403
   Ding H, 2015, BRAIN, V138, P2750, DOI 10.1093/brain/awv165
   Driscoll VD, 2016, OTOL NEUROTOL, V37, pE141, DOI 10.1097/MAO.0000000000000945
   Fatterpekar GM, 1999, J COMPUT ASSIST TOMO, V23, P776, DOI 10.1097/00004728-199909000-00027
   Gerard JM, 2010, INT J PEDIATR OTORHI, V74, P642, DOI 10.1016/j.ijporl.2010.03.010
   Giesemann AM, 2014, LARYNGOSCOPE, V124, P751, DOI 10.1002/lary.24300
   Giesemann AM, 2012, EUR RADIOL, V22, P519, DOI 10.1007/s00330-011-2287-z
   Glastonbury CM, 2002, AM J NEURORADIOL, V23, P635
   Gordon KA, 2001, J OTOLARYNGOL, V30, P216, DOI 10.2310/7070.2001.20157
   Kang WS, 2010, OTOLARYNG HEAD NECK, V143, P101, DOI 10.1016/j.otohns.2010.03.016
   Kim AH, 2008, OTOL NEUROTOL, V29, P626, DOI 10.1097/MAO.0b013e31817781f5
   Kim HS, 1998, AM J NEURORADIOL, V19, P1155
   Kutz JW, 2011, OTOL NEUROTOL, V32, P956, DOI 10.1097/MAO.0b013e31821f473b
   Lazard DS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048739
   Lee HJ, 2007, CEREB CORTEX, V17, P909, DOI 10.1093/cercor/bhl001
   Lee Youngmee, 2010, [Korean Journal of Otorhinolaryngology Head and Neck Surgery, 대한이비인후과학회지 두경부외과학], V53, P534
   Lin PH, 2017, JAMA OTOLARYNGOL, V143, P912, DOI 10.1001/jamaoto.2017.0945
   Ling D., 2002, SPEECH HEARING IMPAI
   Manrique M, 2004, LARYNGOSCOPE, V114, P1462, DOI 10.1097/00005537-200408000-00027
   Manrique M, 2004, ACTA OTO-LARYNGOL, V124, P55, DOI 10.1080/03655230410017148
   Maxwell AP, 1999, AM J OTOL, V20, P335
   Morlet T, 2017, OTOL NEUROTOL, V38, P429, DOI 10.1097/MAO.0000000000001308
   NADOL JB, 1992, ANN OTO RHINOL LARYN, V101, P988, DOI 10.1177/000348949210101205
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Peng KA, 2017, OTOLARYNG HEAD NECK, V157, P392, DOI 10.1177/0194599817718798
   Purcell PL, 2015, LARYNGOSCOPE, V125, P1691, DOI 10.1002/lary.25087
   Rah YC, 2016, ANN OTO RHINOL LARYN, V125, P924, DOI 10.1177/0003489416665190
   Rubinstein D, 1996, AM J NEURORADIOL, V17, P1099
   Sennaroglu L, 2016, OTOL NEUROTOL, V37, P865, DOI 10.1097/MAO.0000000000001050
   Shah PV, 2016, J AM BOARD FAM MED, V29, P286, DOI 10.3122/jabfm.2016.02.150258
   Stjernholm C, 2002, ACTA OTO-LARYNGOL, V122, P43, DOI 10.1080/00016480252775724
   Sue CM, 1998, ANN NEUROL, V43, P350, DOI 10.1002/ana.410430313
   Svirsky MA, 2004, AUDIOL NEURO-OTOL, V9, P224, DOI 10.1159/000078392
   Tillery KH, 2012, J ACOUST SOC AM, V131, P416, DOI 10.1121/1.3664101
   Usami S, 2017, ACTA OTO-LARYNGOL, V137, pS2, DOI 10.1080/00016489.2017.1300321
   Van HT, 2000, AM J OTOL, V21, P663
   von Ilberg CA, 2011, AUDIOL NEURO-OTOL, V16, P1, DOI 10.1159/000327765
   Wei XM, 2017, OTOL NEUROTOL, V38, P685, DOI 10.1097/MAO.0000000000001382
   Wu JL, 2006, INT J PEDIATR OTORHI, V70, P207, DOI 10.1016/j.ijporl.2005.06.013
   Yamazaki H, 2015, OTOL NEUROTOL, V36, P977, DOI 10.1097/MAO.0000000000000721
   Yi JS, 2013, INT J PEDIATR OTORHI, V77, P530, DOI 10.1016/j.ijporl.2012.12.031
   Young NM, 2012, INT J PEDIATR OTORHI, V76, P1442, DOI 10.1016/j.ijporl.2012.06.019
   Yucel E, 2015, J INT ADV OTOL, V11, P110, DOI 10.5152/iao.2015.915
   Zhang ZH, 2012, INT J PEDIATR OTORHI, V76, P1188, DOI 10.1016/j.ijporl.2012.05.003
   Zwolan T, 2016, PERSPECTIVES ASHA SP, V1, P21, DOI [10.1044/persp1.sig9.21, DOI 10.1044/PERSP1.SIG9.21]
   Zwolan TA, 2004, OTOL NEUROTOL, V25, P112, DOI 10.1097/00129492-200403000-00006
NR 64
TC 3
Z9 4
U1 0
U2 2
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD FEB 4
PY 2019
VL 9
AR 1154
DI 10.1038/s41598-018-37014-7
PG 10
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA HK0UA
UT WOS:000457616300043
PM 30718613
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Strand, JF
   Brown, VA
   Barbour, DL
AF Strand, Julia F.
   Brown, Violet A.
   Barbour, Dennis L.
TI Talking points: A modulating circle reduces listening effort without
   improving speech recognition
SO PSYCHONOMIC BULLETIN & REVIEW
LA English
DT Article
DE Spoken word recognition; Speech perception; Cross-modal attention
ID AUDIOVISUAL SPEECH; OLDER-ADULTS; VISUAL INFORMATION; NOISE-REDUCTION;
   INTELLIGIBILITY; YOUNG
AB Speech recognition is improved when the acoustic input is accompanied by visual cues provided by a talking face (Erber in Journal of Speech and Hearing Research, 12(2), 423-425 1969; Sumby & Pollack in The Journal of the Acoustical Society of America, 26(2), 212-215, 1954). One way that the visual signal facilitates speech recognition is by providing the listener with information about fine phonetic detail that complements information from the auditory signal. However, given that degraded face stimuli can still improve speech recognition accuracy (Munhall et al. in Perception & Psychophysics, 66(4), 574-583, 2004), and static or moving shapes can improve speech detection accuracy (Bernstein et al. in Speech Communication, 44(1/4), 5-18, 2004), aspects of the visual signal other than fine phonetic detail may also contribute to the perception of speech. In two experiments, we show that a modulating circle providing information about the onset, offset, and acoustic amplitude envelope of the speech does not improve recognition of spoken sentences (Experiment 1) or words (Experiment 2), but does reduce the effort necessary to recognize speech. These results suggest that although fine phonetic detail may be required for the visual signal to benefit speech recognition, low-level features of the visual signal may function to reduce the cognitive effort associated with processing speech.
C1 [Strand, Julia F.; Brown, Violet A.] Carleton Coll, Dept Psychol, Northfield, MN 55057 USA.
   [Barbour, Dennis L.] Washington Univ, Dept Biomed Engn, St Louis, MO USA.
RP Strand, JF (corresponding author), Carleton Coll, Dept Psychol, Northfield, MN 55057 USA.
EM jstrand@carleton.edu
RI ; Strand, Julia/J-5432-2014
OI Brown, Violet/0000-0001-5310-6499; Strand, Julia/0000-0001-5950-0139;
   Barbour, Dennis/0000-0003-0851-0665
FU Carleton CollegeEuropean Commission
FX Carleton College supported this work. We are grateful to Hunter Brown,
   Naseem Dillman-Hasso, Lydia Ding, Kate Finstuen-Magro, Alexander
   Frieden, Maryam Hedayati, Sasha Mayn, Madeleine Merchant, Lucia Ray,
   Julia Smith, Hettie Stern, Janna Wennberg, and Annie Zanger for
   assistance with data collection, Xinyu Song for creation of the custom
   stimulus delivery software, Daniel Hernandez for input on experiment
   design, Adam Putnam for comments on an earlier draft, and Aaron Swoboda
   for suggestions about data visualization.
CR Arnold P, 2001, BRIT J PSYCHOL, V92, P339, DOI 10.1348/000712601162220
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bentler R, 2008, INT J AUDIOL, V47, P447, DOI 10.1080/14992020802033091
   Bernstein LE, 2004, SPEECH COMMUN, V44, P5, DOI 10.1016/j.specom.2004.10.011
   Brysbaert M, 2012, BEHAV RES METHODS, V44, P991, DOI 10.3758/s13428-012-0190-4
   Desjardins JL, 2014, EAR HEARING, V35, P600, DOI 10.1097/AUD.0000000000000028
   DOWNS DW, 1982, J SPEECH HEAR DISORD, V47, P189, DOI 10.1044/jshd.4702.189
   ERBER NP, 1969, J SPEECH HEAR RES, V12, P423, DOI 10.1044/jshr.1202.423
   Gagne JP, 2017, TRENDS HEAR, V21, DOI 10.1177/2331216516687287
   Gosselin PA, 2011, INT J AUDIOL, V50, P786, DOI 10.3109/14992027.2011.599870
   Grant KW, 2004, SPEECH COMMUN, V44, P43, DOI 10.1016/j.specom.2004.06.004
   Grant KW, 1996, J ACOUST SOC AM, V100, P2415, DOI 10.1121/1.417950
   Helfer KS, 2005, J ACOUST SOC AM, V117, P842, DOI 10.1121/1.1836832
   Jordan TR, 2000, LANG SPEECH, V43, P107, DOI 10.1177/00238309000430010401
   Kahneman D., 1973, ATTENTION EFFORT
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Kim J, 2004, SPEECH COMMUN, V44, P19, DOI 10.1016/j.specom.2004.09.008
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Mishra S, 2013, J SPEECH LANG HEAR R, V56, P1120, DOI 10.1044/1092-4388(2012/12-0033)
   Munhall KG, 2004, PERCEPT PSYCHOPHYS, V66, P574, DOI 10.3758/BF03194902
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Picou EM, 2014, EAR HEARING, V35, P611, DOI 10.1097/AUD.0000000000000055
   RABBITT PMA, 1968, Q J EXP PSYCHOL, V20, P241, DOI 10.1080/14640746808400158
   Rosenblum LD, 1996, J SPEECH HEAR RES, V39, P1159, DOI 10.1044/jshr.3906.1159
   Sarampalis A, 2009, J SPEECH LANG HEAR R, V52, P1230, DOI 10.1044/1092-4388(2009/08-0111)
   Schwartz JL, 2004, COGNITION, V93, pB69, DOI 10.1016/j.cognition.2004.01.006
   Sommers MS, 2016, EAR HEARING, V37, p62S, DOI 10.1097/AUD.0000000000000322
   Strand J. F., J SPEECH LANGUAGE HE
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   SUMMERFIELD Q, 1979, PHONETICA, V36, P314, DOI 10.1159/000259969
   Tye-Murray N, 2011, EAR HEARING, V32, P650, DOI 10.1097/AUD.0b013e31821a4578
   Van Engen KJ, 2014, J SPEECH LANG HEAR R, V57, P1908, DOI 10.1044/JSLHR-H-13-0076
   Van Engen KJ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043753
NR 34
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1069-9384
EI 1531-5320
J9 PSYCHON B REV
JI Psychon. Bull. Rev.
PD FEB
PY 2019
VL 26
IS 1
BP 291
EP 297
DI 10.3758/s13423-018-1489-7
PG 7
WC Psychology, Mathematical; Psychology, Experimental
SC Psychology
GA HQ2GS
UT WOS:000462218900017
PM 29790122
OA Bronze
DA 2021-02-24
ER

PT J
AU Zhang, CX
   Tao, RX
   Zhao, H
AF Zhang, Changxin
   Tao, Renxia
   Zhao, Hang
TI Auditory spatial attention modulates the unmasking effect of perceptual
   separation in a "cocktail party" environment
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Auditory processing; Perceptual separation; Auditory spatial attention;
   "Cocktail party" environment; Cortical auditory evoked potentials
ID EVENT-RELATED POTENTIALS; SOUNDS VERTICAL-BAR; PASS NOISE MASKING;
   AGE-RELATED-CHANGES; SPEECH SOUNDS; INFORMATIONAL MASKING; CORTICAL
   REPRESENTATIONS; MISMATCH NEGATIVITY; ENERGETIC MASKING; OBJECT
   FORMATION
AB The perceptual separation between a signal speech and a competing speech (masker), induced by the precedence effect, plays an important role in releasing the signal speech from the masker, especially in a reverberant environment. The perceptual-separation-induced unmasking effect has been suggested to involve multiple cognitive processes, such as selective attention. However, whether listeners' spatial attention modulate the perceptual separation -induced unmasking effect is not clear. The present study investigated how perceptual separation and auditory spatial attention interact with each other to facilitate speech perception under a simulated noisy and reverberant environment by analyzing the cortical auditory evoked potentials to the signal speech. The results showed that the N1 wave was significantly enhanced by perceptual separation between the signal and masker regardless of whether the participants' spatial attention was directed to the signal or not. However, the P2 wave was significantly enhanced by perceptual separation only when the participants attended to the signal speech. The results indicate that the perceptual-separation-induced facilitation of P2 needs more attentional resource than that of N1. The results also showed that the signal speech caused an enhanced N1 in the contralateral hemisphere regardless of whether participants' attention was directed to the signal or not. In contrast, the signal speech caused an enhanced P2 in the contralateral hemisphere only when the participant attended to the signal. The results indicate that the hemispheric distribution of N1 is mainly affected by the perceptual features of the acoustic stimuli, while that of P2 is affected by the listeners' attentional status.
C1 [Zhang, Changxin; Tao, Renxia; Zhao, Hang] East China Normal Univ, Fac Educ, Shanghai, Peoples R China.
   [Zhang, Changxin; Tao, Renxia; Zhao, Hang] East China Normal Univ, Key Lab Speech & Hearing Sci, 3663 North Zhongshan Rd, Shanghai 200062, Peoples R China.
RP Zhang, CX (corresponding author), East China Normal Univ, Key Lab Speech & Hearing Sci, 3663 North Zhongshan Rd, Shanghai 200062, Peoples R China.
EM cxzhang@spe.ecnu.edu.cn
FU Peak Discipline Construction Project of Education at East China Normal
   University, Shanghai Sailing Program of Science and Technology
   Commission of Shanghai Municipality [16YF1403300]; Fundamental Research
   Funds for the Central UniversitiesFundamental Research Funds for the
   Central Universities [2017ECNU-YYJ045]
FX This work was sponsored by the Peak Discipline Construction Project of
   Education at East China Normal University, Shanghai Sailing Program of
   Science and Technology Commission of Shanghai Municipality
   (16YF1403300), and the Fundamental Research Funds for the Central
   Universities (2017ECNU-YYJ045). We thank Dr. Liang Li for helpful
   comments on earlier versions of this manuscript.
CR Alain C, 2005, J COGNITIVE NEUROSCI, V17, P811, DOI 10.1162/0898929053747621
   Alain C, 2002, J ACOUST SOC AM, V111, P990, DOI 10.1121/1.1434942
   Alain C, 2001, J ACOUST SOC AM, V109, P2211, DOI 10.1121/1.1367243
   Arbogast TL, 2002, J ACOUST SOC AM, V112, P2086, DOI 10.1121/1.1510141
   Atienza M, 2002, LEARN MEMORY, V9, P138, DOI 10.1101/lm.46502
   Aydelott J, 2015, J ACOUST SOC AM, V138, P964, DOI 10.1121/1.4927410
   Bae GY, 2018, J NEUROSCI, V38, P409, DOI 10.1523/JNEUROSCI.2860-17.2017
   Baumgartner HM, 2018, COGN NEUROSCI-UK, V9, P4, DOI 10.1080/17588928.2017.1333490
   Billings CJ, 2011, EAR HEARING, V32, P53, DOI 10.1097/AUD.0b013e3181ec5c46
   Bosnyak DJ, 2004, CEREB CORTEX, V14, P1088, DOI 10.1093/cercor/bhh068
   Brungart DS, 2001, J ACOUST SOC AM, V109, P1101, DOI 10.1121/1.1345696
   Brungart DS, 2005, J ACOUST SOC AM, V118, P3241, DOI 10.1121/1.2082557
   CALLAWAY E, 1982, PSYCHIAT RES, V7, P299, DOI 10.1016/0165-1781(82)90066-X
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Ding N, 2018, J NEUROSCI, V38, P1178, DOI 10.1523/JNEUROSCI.2606-17.2017
   DUBNO JR, 1992, J ACOUST SOC AM, V91, P2110, DOI 10.1121/1.403697
   Eimer M., 2018, OXFORD HDB ATTENTION, P289, DOI [DOI 10.1093/OXFORDHB/9780199675111.013.006, 10.1093/oxfordhb/9780199675111.013.006]
   FREYMAN RL, 1991, J ACOUST SOC AM, V90, P874, DOI 10.1121/1.401955
   Freyman RL, 1999, J ACOUST SOC AM, V106, P3578, DOI 10.1121/1.428211
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Handy TC, 2000, PERCEPT PSYCHOPHYS, V62, P175, DOI 10.3758/BF03212070
   Huang Y, 2008, HEARING RES, V244, P51, DOI 10.1016/j.heares.2008.07.006
   Huang Y, 2011, J COGNITIVE NEUROSCI, V23, P1003, DOI 10.1162/jocn.2010.21470
   Huang Y, 2009, J EXP PSYCHOL HUMAN, V35, P1618, DOI 10.1037/a0015791
   Kidd G, 2005, ACTA ACUST UNITED AC, V91, P526
   KNIGHT RT, 1981, ELECTROEN CLIN NEURO, V52, P571, DOI 10.1016/0013-4694(81)91431-0
   Lei M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-017-18793-x
   Li HH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0063106
   Li L, 2005, HEARING RES, V202, P235, DOI 10.1016/j.heares.2004.10.007
   Li L, 2004, J EXP PSYCHOL HUMAN, V30, P1077, DOI 10.1037/0096-1523.30.6.1077
   Lightfoot Guy, 2016, Seminars in Hearing, V37, P1, DOI 10.1055/s-0035-1570334
   Litovsky RY, 1999, J ACOUST SOC AM, V106, P1633, DOI 10.1121/1.427914
   Martin BA, 1999, J SPEECH LANG HEAR R, V42, P271, DOI 10.1044/jslhr.4202.271
   Martin BA, 2005, EAR HEARING, V26, P195, DOI 10.1097/00003446-200504000-00007
   Martin BA, 1997, J ACOUST SOC AM, V101, P1585, DOI 10.1121/1.418146
   McDonald KL, 2005, J ACOUST SOC AM, V118, P1593, DOI 10.1121/1.2000747
   Meyberg S, 2017, NEUROPSYCHOLOGIA, V99, P64, DOI 10.1016/j.neuropsychologia.2017.02.023
   Muller-Gass A, 2001, NEUROSCI LETT, V299, P197, DOI 10.1016/S0304-3940(01)01508-7
   POLICH J, 1985, BIOL PSYCHOL, V21, P309, DOI 10.1016/0301-0511(85)90185-1
   Rakerd B, 2006, J ACOUST SOC AM, V119, P1597, DOI 10.1121/1.2161438
   Reinke KS, 2003, COGNITIVE BRAIN RES, V17, P781, DOI 10.1016/S0926-6410(03)00202-7
   SALO SK, 1995, SCAND AUDIOL, V24, P165, DOI 10.3109/01050399509047531
   Shamma SA, 2011, TRENDS NEUROSCI, V34, P114, DOI 10.1016/j.tins.2010.11.002
   Shinn-Cunningham B., 2015, ENCY COMPUT NEUROSCI, P252
   Shinn-Cunningham B, 2017, SPRINGER HANDB AUDIT, V60, P7, DOI 10.1007/978-3-319-51662-2_2
   Shuai L, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00097
   Singh G, 2008, J ACOUST SOC AM, V124, P1294, DOI 10.1121/1.2949399
   Snyder JS, 2006, J COGNITIVE NEUROSCI, V18, P1, DOI 10.1162/089892906775250021
   Snyder JS, 2005, COGNITIVE BRAIN RES, V24, P492, DOI 10.1016/j.cogbrainres.2005.03.002
   Tallus J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0139318
   Tremblay K, 2001, EAR HEARING, V22, P79, DOI 10.1097/00003446-200104000-00001
   WALLACH H, 1949, AM J PSYCHOL, V62, P315, DOI 10.2307/1418275
   Wang YF, 2018, CANCER BIOL THER, V19, P1162, DOI 10.1080/15384047.2018.1491497
   Whiting KA, 1998, EAR HEARING, V19, P218, DOI 10.1097/00003446-199806000-00005
   Woods DL, 2001, J COGNITIVE NEUROSCI, V13, P492, DOI 10.1162/08989290152001916
   WOODS DL, 1993, COGNITIVE BRAIN RES, V1, P227, DOI 10.1016/0926-6410(93)90007-R
   Wu XH, 2005, HEARING RES, V199, P1, DOI 10.1016/j.heares.2004.03.010
   Xiang JJ, 2010, J NEUROSCI, V30, P12084, DOI 10.1523/JNEUROSCI.0827-10.2010
   Yang ZG, 2007, SPEECH COMMUN, V49, P892, DOI 10.1016/j.specom.2007.05.005
   Zhang CX, 2016, HEARING RES, V331, P119, DOI 10.1016/j.heares.2015.11.002
   Zhang CX, 2014, BRAIN LANG, V135, P85, DOI 10.1016/j.bandl.2014.06.002
   ZUREK PM, 1980, J ACOUST SOC AM, V67, P952, DOI 10.1121/1.383974
NR 62
TC 1
Z9 1
U1 1
U2 8
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD FEB
PY 2019
VL 124
BP 108
EP 116
DI 10.1016/j.neuropsychologia.2019.01.009
PG 9
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA HO5XQ
UT WOS:000461003000011
PM 30659864
DA 2021-02-24
ER

PT J
AU Wikman, P
   Rinne, T
AF Wikman, Patrik
   Rinne, Teemu
TI Interaction of the effects associated with auditory-motor integration
   and attention-engaging listening tasks
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Speech repetition; Speech production; Attention; Auditory cortex;
   Inferior parietal lobule
ID DEPENDENT ACTIVATIONS; CONDUCTION APHASIA; SPEECH-PERCEPTION;
   WORKING-MEMORY; MENTAL-IMAGERY; CORTEX; FMRI; MODULATION; RESPONSES;
   PITCH
AB A number of previous studies have implicated regions in posterior auditory cortex (AC) in auditory-motor integration during speech production. Other studies, in turn, have shown that activation in AC and adjacent regions in the inferior parietal lobule (IPL) is strongly modulated during active listening and depends on task requirements. The present fMRI study investigated whether auditory-motor effects interact with those related to active listening tasks in AC and IPL. In separate task blocks, our subjects performed either auditory discrimination or 2-back memory tasks on phonemic or nonphonemic vowels. They responded to targets by either overtly repeating the last vowel of a target pair, overtly producing a given response vowel, or by pressing a response button. We hypothesized that the requirements for auditory-motor integration, and the associated activation, would be stronger during repetition than production responses and during repetition of nonphonemic than phonemic vowels. We also hypothesized that if auditory-motor effects are independent of task-dependent modulations, then the auditory-motor effects should not differ during discrimination and 2-back tasks. We found that activation in AC and IPL was significantly modulated by task (discrimination vs. 2-back), vocal-response type (repetition vs. production), and motor-response type (vocal vs. button). Motor-response and task effects interacted in IPL but not in AC. Overall, the results support the view that regions in posterior AC are important in auditory-motor integration. However, the present study shows that activation in wide AC and IPL regions is modulated by the motor requirements of active listening tasks in a more general manner. Further, the results suggest that activation modulations in AC associated with attention-engaging listening tasks and those associated with auditory-motor performance are mediated by independent mechanisms.
C1 [Wikman, Patrik] Univ Helsinki, Dept Psychol & Logoped, POB 9, FI-00014 Helsinki, Finland.
   [Wikman, Patrik] Aalto Univ, Adv Magnet Imaging Ctr, Sch Sci, Espoo, Finland.
   [Rinne, Teemu] Univ Turku, Dept Clin Med, Turku Brain & Mind Ctr, Turku, Finland.
RP Wikman, P (corresponding author), Univ Helsinki, Dept Psychol & Logoped, POB 9, FI-00014 Helsinki, Finland.
EM patrik.wikman@helsinki.fi
RI Rinne, Teemu/A-6090-2009
OI Rinne, Teemu/0000-0002-3142-9438; Wikman, Patrik/0000-0001-9931-2028
FU Academy of FinlandAcademy of FinlandEuropean Commission; Finnish
   Cultural foundationFinnish Cultural Foundation
FX This work was supported by the Academy of Finland and the Finnish
   Cultural foundation.
CR Agnew ZK, 2013, NEUROIMAGE, V73, P191, DOI 10.1016/j.neuroimage.2012.08.020
   Alho J, 2012, NEUROIMAGE, V60, P1937, DOI 10.1016/j.neuroimage.2012.02.011
   Alho K, 2014, HEARING RES, V307, P29, DOI 10.1016/j.heares.2013.08.001
   Baldo JV, 2008, BRAIN LANG, V105, P134, DOI 10.1016/j.bandl.2007.12.007
   Bergerbest D, 2004, J COGNITIVE NEUROSCI, V16, P966, DOI 10.1162/0898929041502760
   Buchsbaum BR, 2001, COGNITIVE SCI, V25, P663, DOI 10.1207/s15516709cog2505_2
   Buchsbaum BR, 2011, BRAIN LANG, V119, P119, DOI 10.1016/j.bandl.2010.12.001
   Burnett TA, 1998, J ACOUST SOC AM, V103, P3153, DOI 10.1121/1.423073
   Eliades SJ, 2003, J NEUROPHYSIOL, V89, P2194, DOI 10.1152/jn.00627.2002
   Gaab N, 2006, NEUROIMAGE, V31, P255, DOI 10.1016/j.neuroimage.2005.11.046
   Golfinopoulos E, 2011, NEUROIMAGE, V55, P1324, DOI 10.1016/j.neuroimage.2010.12.065
   Greenlee JDW, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0014744
   Guenther FH, 2006, BRAIN LANG, V96, P280, DOI 10.1016/j.bandl.2005.06.001
   Guenther FH, 2006, J COMMUN DISORD, V39, P350, DOI 10.1016/j.jcomdis.2006.06.013
   Guenther FH, 2012, J NEUROLINGUIST, V25, P408, DOI 10.1016/j.jneuroling.2009.08.006
   Hakkinen S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01678
   Hall DA, 2000, HUM BRAIN MAPP, V10, P107, DOI 10.1002/1097-0193(200007)10:3<107::AID-HBM20>3.0.CO;2-8
   Harinen K, 2014, BRAIN LANG, V138, P71, DOI 10.1016/j.bandl.2014.09.006
   Harinen K, 2013, NEUROIMAGE, V77, P279, DOI 10.1016/j.neuroimage.2013.03.064
   Harinen K, 2013, HUM BRAIN MAPP, V34, P1272, DOI 10.1002/hbm.21506
   Heinks-Maldonado TH, 2005, PSYCHOPHYSIOLOGY, V42, P180, DOI 10.1111/j.1469-8986.2005.00272.x
   Hickok G, 2003, J COGNITIVE NEUROSCI, V15, P673, DOI 10.1162/089892903322307393
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2017, PSYCHON B REV, V24, P56, DOI 10.3758/s13423-016-1100-z
   Hickok G, 2012, SPRINGER HANDB AUDIT, V43, P333, DOI 10.1007/978-1-4614-2314-0_12
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Hickok G, 2009, PHYS LIFE REV, V6, P121, DOI 10.1016/j.plrev.2009.06.001
   Hickok G, 2009, J NEUROPHYSIOL, V101, P2725, DOI 10.1152/jn.91099.2008
   Houde JF, 2002, J COGNITIVE NEUROSCI, V14, P1125, DOI 10.1162/089892902760807140
   Huang J, 2002, HUM BRAIN MAPP, V15, P39, DOI 10.1002/hbm.1060
   Husain FT, 2006, HUM BRAIN MAPP, V27, P636, DOI 10.1002/hbm.20207
   Koelsch S, 2009, HUM BRAIN MAPP, V30, P859, DOI 10.1002/hbm.20550
   Leung AWS, 2011, NEUROIMAGE, V55, P1260, DOI 10.1016/j.neuroimage.2010.12.055
   Linke AC, 2015, J COGNITIVE NEUROSCI, V27, P1322, DOI 10.1162/jocn_a_00780
   McGettigan C., 2010, J COGNITIVE NEUROSCI, V23, P673
   Okada K, 2010, CEREB CORTEX, V20, P2486, DOI 10.1093/cercor/bhp318
   Pa J, 2008, NEUROPSYCHOLOGIA, V46, P362, DOI 10.1016/j.neuropsychologia.2007.06.024
   Parker Jones O.P., 2014, FRONT HUM NEUROSCI, V8
   Peschke C, 2009, NEUROIMAGE, V47, P392, DOI 10.1016/j.neuroimage.2009.03.061
   Peschke C, 2012, NEUROIMAGE, V59, P788, DOI 10.1016/j.neuroimage.2011.07.025
   Petkov CI, 2004, NAT NEUROSCI, V7, P658, DOI 10.1038/nn1256
   PROSEK RA, 1979, J FLUENCY DISORD, V4, P269, DOI 10.1016/0094-730X(79)90003-2
   Purcell DW, 2006, J ACOUST SOC AM, V119, P2288, DOI 10.1121/1.2173514
   Raizada RDS, 2007, NEURON, V56, P726, DOI 10.1016/j.neuron.2007.11.001
   Rauschecker JP, 2011, AUDITORY CORTEX, P99, DOI 10.1007/978-1-4419-0074-6_4
   Rauschecker JP, 2011, HEARING RES, V271, P16, DOI 10.1016/j.heares.2010.09.001
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rinne T, 2005, HUM BRAIN MAPP, V26, P94, DOI 10.1002/hbm.20123
   Rinne Teemu, 2017, Cereb Cortex, V27, P3471, DOI 10.1093/cercor/bhx092
   Rinne T, 2012, NEUROIMAGE, V59, P4126, DOI 10.1016/j.neuroimage.2011.10.069
   Rinne Teemu, 2010, Open Neuroimag J, V4, P187, DOI 10.2174/1874440001004010187
   Rinne T, 2009, J NEUROSCI, V29, P13338, DOI 10.1523/JNEUROSCI.3012-09.2009
   Rogalsky C, 2015, NEUROPSYCHOLOGIA, V71, P18, DOI 10.1016/j.neuropsychologia.2015.03.012
   Schneider DM, 2014, NATURE, V513, P189, DOI 10.1038/nature13724
   Shuster LI, 2005, BRAIN LANG, V93, P20, DOI 10.1016/j.bandl.2004.07.007
   Simmonds AJ, 2014, J NEUROSCI, V34, P12963, DOI 10.1523/JNEUROSCI.0336-14.2014
   Simmonds AJ, 2014, HUM BRAIN MAPP, V35, P1930, DOI 10.1002/hbm.22303
   Simmonds AJ, 2011, J NEUROPHYSIOL, V106, P470, DOI 10.1152/jn.00343.2011
   Tachibana RO, 2010, NEUROSCI LETT, V482, P198, DOI 10.1016/j.neulet.2010.07.032
   Tian X, 2015, J COGNITIVE NEUROSCI, V27, P352, DOI 10.1162/jocn_a_00692
   Tian X, 2013, J COGNITIVE NEUROSCI, V25, P1020, DOI 10.1162/jocn_a_00381
   Timm J, 2014, J COGNITIVE NEUROSCI, V26, P1481, DOI 10.1162/jocn_a_00552
   Tourville JA, 2008, NEUROIMAGE, V39, P1429, DOI 10.1016/j.neuroimage.2007.09.054
   Tremblay S, 2003, NATURE, V423, P866, DOI 10.1038/nature01710
   Wikman PA, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00378
   Wilson SM, 2006, NEUROIMAGE, V33, P316, DOI 10.1016/j.neuroimage.2006.05.032
   Winkler AM, 2014, NEUROIMAGE, V92, P381, DOI 10.1016/j.neuroimage.2014.01.060
   Woods DL, 2009, CURR OPIN OTOLARYNGO, V17, P407, DOI 10.1097/MOO.0b013e3283303330
   Zhang LJ, 2011, PLOS ONE, V6, DOI [10.1371/journal.pone.0020963, 10.1371/journal.pone.0026129, 10.1371/journal.pone.0022809, 10.1371/journal.pone.0028953, 10.1371/journal.pone.0026842]
   Zvyagintsev M, 2013, EUR J NEUROSCI, V37, P1421, DOI 10.1111/ejn.12140
NR 70
TC 2
Z9 2
U1 0
U2 8
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD FEB
PY 2019
VL 124
BP 322
EP 336
DI 10.1016/j.neuropsychologia.2018.11.006
PG 15
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA HO5XQ
UT WOS:000461003000032
PM 30444980
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Han, JJ
   Bae, YJ
   Song, SK
   Song, JJ
   Koo, JW
   Lee, JH
   Oh, SH
   Kim, BJ
   Choi, BY
AF Han, Jae Joon
   Bae, Yun Jung
   Song, Seul Ki
   Song, Jae-Jin
   Koo, Ja-Won
   Lee, Jun Ho
   Oh, Seung Ha
   Kim, Bong Jik
   Choi, Byung Yoon
TI Prediction of the Outcome of Cochlear Implantation in the Patients with
   Congenital Cytomegalovirus Infection based on Magnetic Resonance Imaging
   Characteristics
SO JOURNAL OF CLINICAL MEDICINE
LA English
DT Article
DE cytomegalovirus; hearing loss; cochlear implantation; speech perception;
   outcome; magnetic resonance imaging; radiologic biomarker; white matter
ID SENSORINEURAL HEARING-LOSS; WHITE-MATTER; SPEECH-PERCEPTION; CHILDREN;
   MRI; INTELLIGIBILITY; PATHOGENESIS; BREAKS
AB The goal of this study was to elucidate radiologic biomarker that can predict the outcome of cochlear implantation (CI) in congenital cytomegalovirus (cCMV) related deafness. A retrospective survey of speech perception after CI and an evaluation of brain magnetic resonance imaging (MRI) findings were performed in 10 cochlear implantees with cCMV-related prelingual deafness. Specifically, a special attention was paid to the degree of white matter (WM) abnormality shown in brain MRI, which was used to divide our cohort into two groups: The mild and severe pathology groups. Age-matched prelingual deaf patients with idiopathic sensorineural hearing loss were selected as controls. Subjects in mild pathology groups showed higher a Category of Auditory Performance (CAP) score (5.2 +/- 0.8) than those with severe pathologies (3.4 +/- 1.5) (P = 0.041). Importantly, speech performance from subjects with mild pathology was comparable to that of the control group (mean CAP score of 5.2 +/- 0.8 vs. 5.1 +/- 1.2) (P = 0.898). Mild pathologies related to the limited WM lesion in MRI not accompanied by severe MRI pathologies, such as diffuse WM abnormality, myelination delay, ventriculomegaly, migration abnormality, and cerebellar hypoplasia, can be tolerated and do not adversely affect the CI outcome in cCMV deafness.
C1 [Han, Jae Joon] Soonchunhyang Univ, Seoul Hosp, Dept Otorhinolaryngol Head & Neck Surg, Coll Med, Seoul 04401, South Korea.
   [Bae, Yun Jung] Seoul Natl Univ, Dept Radiol, Bundang Hosp, Seongnam 13620, South Korea.
   [Song, Seul Ki; Song, Jae-Jin; Koo, Ja-Won; Choi, Byung Yoon] Seoul Natl Univ, Dept Otorhinolaryngol Head & Neck Surg, Bundang Hosp, Seongnam 13620, South Korea.
   [Lee, Jun Ho; Oh, Seung Ha] Seoul Natl Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg, Seoul 03080, South Korea.
   [Kim, Bong Jik] Chungnam Natl Univ, Coll Med, Dept Otorhinolaryngol Head & Neck Surg, Daejeon 35015, South Korea.
RP Choi, BY (corresponding author), Seoul Natl Univ, Dept Otorhinolaryngol Head & Neck Surg, Bundang Hosp, Seongnam 13620, South Korea.; Kim, BJ (corresponding author), Chungnam Natl Univ, Coll Med, Dept Otorhinolaryngol Head & Neck Surg, Daejeon 35015, South Korea.
EM seagulla@naver.com; bae729@gmail.com; ssgi87@naver.com;
   jjsong96@gmail.com; jwkoo99@snu.ac.kr; junlee@snu.ac.kr;
   shaoh@snu.ac.kr; cellokimbj@gmail.com; choiby2010@gmail.com
RI , 배윤정/J-8327-2019
OI , 배윤정/0000-0002-1779-4949; Han, Jae Joon/0000-0002-5642-107X; Kim, Bong
   Jik/0000-0002-6384-2171
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2018R1A2B2001054]; Korea Health
   Technology R&D Project through the Korea Health Industry Development
   Institute (KHIDI) - Ministry of Health & Welfare, Republic of Korea
   [HI15C1632, HI17C0952]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (2018R1A2B2001054) and a grant from the Korea
   Health Technology R&D Project through the Korea Health Industry
   Development Institute (KHIDI), funded by the Ministry of Health &
   Welfare, Republic of Korea (grant numbers: HI15C1632, and HI17C0952).
CR Archbold S, 1995, Ann Otol Rhinol Laryngol Suppl, V166, P312
   Bauer PW, 2005, LARYNGOSCOPE, V115, P223, DOI 10.1097/01.mlg.0000154722.55044.fc
   BOESCH C, 1989, PEDIATR RADIOL, V19, P91, DOI 10.1007/BF02387893
   BOPPANA SB, 1992, PEDIATR INFECT DIS J, V11, P93, DOI 10.1097/00006454-199202000-00007
   Bosnjak VM, 2011, COLLEGIUM ANTROPOL, V35, P229
   Cannie MM, 2016, EUR RADIOL, V26, P3760, DOI 10.1007/s00330-015-4187-0
   Carraro M, 2017, JARO-J ASSOC RES OTO, V18, P263, DOI 10.1007/s10162-016-0606-4
   Ciorba A, 2009, EUR ARCH OTO-RHINO-L, V266, P1539, DOI 10.1007/s00405-009-0944-5
   Fazekas F, 2002, CEREBROVASC DIS, V13, P31, DOI 10.1159/000049147
   Fields RD, 2008, TRENDS NEUROSCI, V31, P361, DOI 10.1016/j.tins.2008.04.001
   Fortunato EA, 2000, P NATL ACAD SCI USA, V97, P853, DOI 10.1073/pnas.97.2.853
   Fowler KB, 1997, J PEDIATR-US, V130, P624, DOI 10.1016/S0022-3476(97)70248-8
   Gabrielli L, 2013, ACTA NEUROPATHOL COM, V1, DOI 10.1186/2051-5960-1-63
   Inscoe JMR, 2004, OTOL NEUROTOL, V25, P479, DOI 10.1097/00129492-200407000-00014
   Iwasaki S, 2009, AUDIOL NEURO-OTOL, V14, P146, DOI 10.1159/000171476
   Katano H, 2007, MICROBES INFECT, V9, P183, DOI 10.1016/j.micinf.2006.11.004
   Kawasaki H, 2017, PATHOL INT, V67, P72, DOI 10.1111/pin.12502
   Kenneson A, 2007, REV MED VIROL, V17, P253, DOI 10.1002/rmv.535
   Kim BJ, 2018, BIOMED RES INT, V2018, DOI 10.1155/2018/7087586
   Laccourreye L, 2015, EUR ANN OTORHINOLARY, V132, P317, DOI 10.1016/j.anorl.2015.08.020
   Lanzieri TM, 2017, PEDIATRICS, V139, DOI 10.1542/peds.2016-2610
   Lee DJ, 2005, OTOLARYNG HEAD NECK, V133, P900, DOI 10.1016/j.otohns.2005.08.013
   Luo MH, 2010, J VIROL, V84, P3528, DOI 10.1128/JVI.02161-09
   Lyutenski S, 2017, EUR ARCH OTO-RHINO-L, V274, P1397, DOI 10.1007/s00405-016-4408-4
   Malik V, 2011, LARYNGOSCOPE, V121, P1780, DOI 10.1002/lary.21818
   Manara R, 2011, PEDIATR RADIOL, V41, P962, DOI 10.1007/s00247-011-2120-5
   Matsui T, 2012, ACTA OTO-LARYNGOL, V132, P597, DOI 10.3109/00016489.2011.653445
   Nystad M, 2008, MUTAT RES-FUND MOL M, V637, P56, DOI 10.1016/j.mrfmmm.2007.07.009
   PECKHAM CS, 1987, ARCH DIS CHILD, V62, P1233, DOI 10.1136/adc.62.12.1233
   Philips B, 2014, INT J PEDIATR OTORHI, V78, P410, DOI 10.1016/j.ijporl.2013.11.009
   Pyman B, 2000, AM J OTOL, V21, P57, DOI 10.1016/S0196-0709(00)80076-9
   Rivera LB, 2002, PEDIATRICS, V110, P762, DOI 10.1542/peds.110.4.762
   Schiffmann R, 2009, NEUROLOGY, V72, P750, DOI 10.1212/01.wnl.0000343049.00540.c8
   Skiold B, 2012, J PEDIATR-US, V160, P559, DOI 10.1016/j.jpeds.2011.09.053
   Sugiura S, 2003, J MED VIROL, V69, P72, DOI 10.1002/jmv.10263
   Suzuki Y, 2008, BRAIN DEV-JPN, V30, P420, DOI 10.1016/j.braindev.2007.12.004
   van der Knaap MS, 2004, RADIOLOGY, V230, P529, DOI 10.1148/radiol.2302021459
   Viccaro M, 2012, AUDIOL NEURO-OTOL, V17, P395, DOI 10.1159/000341160
   Wang Y, 2013, LARYNGOSCOPE, V123, P2801, DOI 10.1002/lary.24090
   WILLIAMSON WD, 1992, PEDIATRICS, V90, P862
   Woodward LJ, 2006, NEW ENGL J MED, V355, P685, DOI 10.1056/NEJMoa053792
   Woodward LJ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0051879
   Yoshida H, 2017, OTOL NEUROTOL, V38, pE190, DOI 10.1097/MAO.0000000000001483
NR 43
TC 0
Z9 0
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2077-0383
J9 J CLIN MED
JI J. Clin. Med.
PD FEB
PY 2019
VL 8
IS 2
AR 136
DI 10.3390/jcm8020136
PG 11
WC Medicine, General & Internal
SC General & Internal Medicine
GA HN6KR
UT WOS:000460295400009
PM 30682778
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Zinszer, BD
   Riggs, M
   Reetzke, R
   Chandrasekaran, B
AF Zinszer, Benjamin D.
   Riggs, Meredith
   Reetzke, Rachel
   Chandrasekaran, Bharath
TI Error patterns of native and non-native listeners' perception of speech
   in noise
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID INFORMATIONAL MASKING; ADVERSE CONDITIONS; IN-NOISE; RECOGNITION;
   VARIABILITY
AB Speech perception in noise requires both bottom-up sampling of the stimulus and top-down reconstruction of the masked signal from a language model. Previous studies have provided mixed evidence about the exact role that linguistic knowledge plays in native and non-native listeners' perception of masked speech. This paper describes an analysis of whole utterance, content word, and morphosyntactic error patterns to test the prediction that non-native listeners are uniquely affected by energetic and informational masks because of limited information at multiple linguistic levels. The results reveal a consistent disadvantage for non-native listeners at all three levels in challenging listening environments. (C) 2019 Acoustical Society of America
C1 [Zinszer, Benjamin D.] Univ Delaware, Dept Linguist & Cognit Sci, Newark, DE 19716 USA.
   [Zinszer, Benjamin D.; Riggs, Meredith; Reetzke, Rachel] Univ Texas Austin, Dept Commun Sci & Disorders, Austin, TX 78705 USA.
   [Chandrasekaran, Bharath] Univ Pittsburgh, Dept Commun Sci & Disorders, Pittsburgh, PA 15620 USA.
   [Chandrasekaran, Bharath] Univ Pittsburgh, Ctr Neural Bases Cognit, Pittsburgh, PA 15620 USA.
   [Reetzke, Rachel] Univ Calif Davis, MIND Inst, Dept Psychiat & Behav Sci, Sacramento, CA 95817 USA.
RP Zinszer, BD (corresponding author), Univ Delaware, Dept Linguist & Cognit Sci, Newark, DE 19716 USA.
EM bzinszer@gmail.com; mfriggs@gmail.com; rdreetzke@ucdavis.edu;
   b.chandra@pitt.edu
OI Chandrasekaran, Bharath/0000-0002-3673-9435
FU National Institute on Deafness and other Communication Disorders of the
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01 DC015504];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC015504, R01DC015504, R01DC015504,
   R01DC015504] Funding Source: NIH RePORTER
FX This work was supported by a grant from the National Institute on
   Deafness and other Communication Disorders of the National Institutes of
   Health to B.C. (Grant No. R01 DC015504).
CR Bamford J, 1979, SPEECH HEARING TESTS, P148
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Brouwer S, 2014, J ACOUST SOC AM, V136, pEL26, DOI 10.1121/1.4881322
   Brungart DS, 2009, J ACOUST SOC AM, V125, P4006, DOI 10.1121/1.3117686
   Chandrasekaran B, 2015, COGNITION EMOTION, V29, P900, DOI 10.1080/02699931.2014.944106
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   Cooke M, 2008, J ACOUST SOC AM, V123, P414, DOI 10.1121/1.2804952
   De Smedt T, 2012, J MACH LEARN RES, V13, P2063
   Freyman RL, 2007, J ACOUST SOC AM, V121, P1040, DOI 10.1121/1.2427117
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Golestani N, 2009, BILING-LANG COGN, V12, P385, DOI 10.1017/S1366728909990150
   Hammill D. D., 2007, TOAL 4 TEST ADOLESCE
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Lecumberri MLG, 2006, J ACOUST SOC AM, V119, P2445, DOI 10.1121/1.2180210
   Li P, 2014, BILING-LANG COGN, V17, P673, DOI 10.1017/S1366728913000606
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Meador D, 2000, BILING-LANG COGN, V3, P55, DOI DOI 10.1017/S1366728900000134
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   Reetzke R., 2017, 6 INT C AUD CORT BAN
   Riggs M, 2018, SPIN SCORCERER
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Smith KG, 2017, J ACOUST SOC AM, V142, pEL306, DOI 10.1121/1.5003916
   Van Engen KJ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0043753
   Van Engen KJ, 2012, LANG COGNITIVE PROC, V27, P1089, DOI 10.1080/01690965.2012.654644
   Van Engen KJ, 2010, LANG SPEECH, V53, P510, DOI 10.1177/0023830910372495
   Watson C.S., 1987, AUDITORY PROCESSING, P267
   Xie ZL, 2015, NEUROPSYCHOLOGIA, V67, P121, DOI 10.1016/j.neuropsychologia.2014.12.013
NR 28
TC 1
Z9 1
U1 2
U2 3
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD FEB
PY 2019
VL 145
IS 2
BP EL129
EP EL135
DI 10.1121/1.5087271
PG 7
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA HN2SH
UT WOS:000460034600001
PM 30823795
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Lei, JH
   Gong, HN
   Chen, L
AF Lei, Jianghua
   Gong, Huina
   Chen, Liang
TI Enhanced Speechreading Performance in Young Hearing Aid Users in China
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID SPEECH-PERCEPTION; VISUAL SPEECH; WORKING-MEMORY; OLDER-ADULTS;
   CHILDREN; NOISE; DEAF; AGE; AMPLIFICATION; INDIVIDUALS
AB Purpose: The study was designed primarily to determine if the use of hearing aids (HAs) in individuals with hearing impairment in China would affect their speechreading performance.
   Method: Sixty-seven young adults with heating impairment with HAs and 78 young adults with hearing impairment without HAs completed newly developed Chinese speechreading tests targeting 3 linguistic levels (i.e., words, phrases, and sentences).
   Results: Groups with HAs were more accurate at speechreading than groups without HA across the 3 linguistic levels. For both groups, speechreading accuracy was higher for phrases than words and sentences, and speechreading speed was slower for sentences than words and phrases. Furthermore, there was a positive correlation between years of HA use and the accuracy of speechreading performance; longer HA use was associated with more accurate speechreading.
   Conclusions: Young HA users in China have enhanced speechreading performance over their peers with hearing impairment who are not HA users. This result argues against the perceptual dependence hypothesis that suggests greater dependence on visual information leads to improvement in visual speech perception.
C1 [Lei, Jianghua; Gong, Huina] Cent China Normal Univ, Dept Special Educ, Wuhan, Hubei, Peoples R China.
   [Chen, Liang] Univ Georgia, Dept Commun Sci & Special Educ, Athens, GA 30602 USA.
RP Chen, L (corresponding author), Univ Georgia, Dept Commun Sci & Special Educ, Athens, GA 30602 USA.
EM chen@uga.edu
FU China National Social Science Foundation [15BYY069]
FX We acknowledge the support of funding from the China National Social
   Science Foundation Grant 15BYY069, awarded to the first author. We would
   like to thank the participants, their families, and the teachers in the
   conduct of this research.
CR Arnold P, 1997, J Deaf Stud Deaf Educ, V2, P199
   Auer ET, 2007, J SPEECH LANG HEAR R, V50, P1157, DOI 10.1044/1092-4388(2007/080)
   Bavelier D, 2006, PSYCHOL SCI, V17, P1090, DOI 10.1111/j.1467-9280.2006.01831.x
   Bavelier D, 2006, TRENDS COGN SCI, V10, P512, DOI 10.1016/j.tics.2006.09.006
   Bottari D, 2010, RESTOR NEUROL NEUROS, V28, P167, DOI 10.3233/RNN-2010-0502
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593
   Chen L, 2018, CLIN LINGUIST PHONET, V32, P1090, DOI 10.1080/02699206.2018.1510986
   Chen TH, 2004, PERCEPT PSYCHOPHYS, V66, P820, DOI 10.3758/BF03194976
   Davies R, 2009, INT J LANG COMM DIS, V44, P164, DOI 10.1080/13682820801997189
   Doherty KA, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00721
   Fang J., 2015, PSYCHOL SPECIAL CHIL
   Feld JE, 2009, J SPEECH LANG HEAR R, V52, P1555, DOI 10.1044/1092-4388(2009/08-0137)
   Fine I, 2002, J VISION, V2, P190, DOI 10.1167/2.2.5
   GEERS A, 1994, VOLTA REV, V96, P97
   Gleiss S, 2014, J COGNITIVE NEUROSCI, V26, P699, DOI 10.1162/jocn_a_00524
   Grant K. W., 2002, J ACOUST SOC AM, V111, P2354
   GREEN KW, 1981, AM ANN DEAF, V126, P505, DOI 10.1353/aad.2012.1361
   Hauthal N, 2013, ADV COGN PSYCHOL, V9, P53, DOI [10.2478/v10053-008-0131-z, 10.5709/acp-0131-z]
   Heikkila J, 2017, J SPEECH LANG HEAR R, V60, P485, DOI 10.1044/2016_JSLHR-S-15-0071
   Heitz RP, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00150
   Hornsby BWY, 2013, EAR HEARING, V34, P523, DOI 10.1097/AUD.0b013e31828003d8
   Kyle FE, 2013, J SPEECH LANG HEAR R, V56, P416, DOI 10.1044/1092-4388(2012/12-0039)
   Lee HJ, 2007, BRAIN, V130, P2929, DOI 10.1093/brain/awm230
   Lidestam B, 2006, J SPEECH LANG HEAR R, V49, P835, DOI 10.1044/1092-4388(2006/059)
   Lugo E, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002860
   Lyxell B, 2000, BRIT J EDUC PSYCHOL, V70, P505, DOI 10.1348/000709900158272
   Manjarrez E, 2007, NEUROSCI LETT, V415, P231, DOI 10.1016/j.neulet.2007.01.030
   McGettigan C, 2012, NEUROPSYCHOLOGIA, V50, P762, DOI 10.1016/j.neuropsychologia.2012.01.010
   Montano J. J., 2014, ADULT AUDIOLOGIC REH
   Musacchia G, 2006, EXP BRAIN RES, V168, P1, DOI 10.1007/s00221-005-0071-5
   Nabelek AK, 2004, J SPEECH LANG HEAR R, V47, P1001, DOI 10.1044/1092-4388(2004/074)
   Neher T, 2018, INT J AUDIOL, V57, P335, DOI 10.1080/14992027.2017.1423118
   Oryadi-Zanjani MM, 2017, INT J PEDIATR OTORHI, V93, P167, DOI 10.1016/j.ijporl.2016.12.009
   Pavani F., 2012, FRONTIERS NEURAL BAS, P423
   Pimperton H, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00106
   Ronnberg J, 1999, J SPEECH LANG HEAR R, V42, P5, DOI 10.1044/jslhr.4201.05
   Ronnberg J., 1995, COMPENSATING PSYCHOL, P251
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   SEEWALD RC, 1985, J SPEECH HEAR RES, V28, P36, DOI 10.1044/jshr.2801.36
   Sekiyama K, 1997, PERCEPT PSYCHOPHYS, V59, P73, DOI 10.3758/BF03206849
   Shanks JE, 2002, EAR HEARING, V23, P280, DOI 10.1097/00003446-200208000-00003
   Smith D, 2012, J ACOUST SOC AM, V131, P1480, DOI 10.1121/1.3672703
   Soto-Faraco S, 2004, COGNITION, V92, pB13, DOI 10.1016/j.cognition.2003.10.005
   Souza P, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01894
   Stevenson RA, 2012, BRAIN TOPOGR, V25, P308, DOI 10.1007/s10548-012-0220-7
   Strelnikov K, 2009, NEUROPSYCHOLOGIA, V47, P972, DOI 10.1016/j.neuropsychologia.2008.10.017
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Tillberg I, 1996, SCAND AUDIOL, V25, P267, DOI 10.3109/01050399609074966
   Trevino M, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00572
   Tye-Murray N, 2007, EAR HEARING, V28, P656, DOI 10.1097/AUD.0b013e31812f7185
   Tye-Murray N, 2014, J SPEECH LANG HEAR R, V57, P556, DOI 10.1044/2013_JSLHR-H-12-0273
   van Hooren SAH, 2005, INT J AUDIOL, V44, P265, DOI 10.1080/14992020500060370
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Walden BE, 2001, EAR HEARING, V22, P333, DOI 10.1097/00003446-200108000-00007
   WIESENFELD K, 1995, NATURE, V373, P33, DOI 10.1038/373033a0
   Wightman F, 2006, J ACOUST SOC AM, V119, P3940, DOI 10.1121/1.2195121
   Woods DL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0114922
   Zhang H. - C., 1989, PSYCHOL TEST B, V2, P36
   Zhang M., 2005, CHINESE J SPECIAL ED, V5, P21
NR 61
TC 1
Z9 1
U1 0
U2 4
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD FEB
PY 2019
VL 62
IS 2
BP 307
EP 317
DI 10.1044/2018_JSLHR-S-18-0153
PG 11
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA HM7TM
UT WOS:000459682600008
PM 30950700
DA 2021-02-24
ER

PT J
AU Schouwenaars, A
   Finke, M
   Hendriks, P
   Ruigendijk, E
AF Schouwenaars, Atty
   Finke, Mareike
   Hendriks, Petra
   Ruigendijk, Esther
TI Which Questions Do Children With Cochlear Implants Understand? An
   Eye-Tracking Study
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID PROFOUNDLY DEAF-CHILDREN; SPOKEN LANGUAGE-DEVELOPMENT;
   SPEECH-PERCEPTION; SPEAKING CHILDREN; WORKING-MEMORY; HEARING; AGE;
   GERMAN; SKILLS; PERFORMANCE
AB Purpose: The purpose of this study was to investigate the processing of morphosyntactic cues (case and verb agreement) by children with cochlear implants (CIs) in German which-questions, where interpretation depends on these morphosyntactic cues. The aim was to examine whether children with CIs who perceive the different cues also make use of them in speech comprehension and processing in the same way as children with normal hearing (NH).
   Method: Thirty-three children with CIs (age 7;01-12;04 years; months, M = 9;07, bilaterally implanted before age 3;3) and 36 children with NH (age 7;05-10;09 years, M = 9;01) received a picture selection task with eye tracking to test their comprehension of subject, object, and passive which-questions. Two screening tasks tested their auditory discrimination of case morphology and their perception and comprehension of subject-verb agreement.
   Results: Children with CIs who performed well on the screening tests still showed more difficulty on the comprehension of object questions than children with NH, whereas they comprehended subject questions and passive questions equally well as children with NH. There was large interindividual variability within the CI group. The gaze patterns of children with NH showed reanalysis effects for object questions disambiguated later in the sentence by verb agreement, but not for object questions disambiguated by case at the first noun phrase. The gaze patterns of children with CIs showed reanalysis effects even for object questions disambiguated at the first noun phrase.
   Conclusions: Even when children with CIs perceive case and subject-verb agreement, their ability to use these cues for offline comprehension and online processing still lags behind normal development, which is reflected in lower performance rates and longer processing times. Individual variability within the CI group can partly be explained by working memory and hearing age.
C1 [Schouwenaars, Atty; Ruigendijk, Esther] Oldenburg Univ, Dept Dutch, Cluster Excellence Hearing4all, Oldenburg, Germany.
   [Finke, Mareike] Hannover Med Sch, Dept Otolaryngol, Cluster Excellence Hearing4all, Hannover, Germany.
   [Hendriks, Petra] Univ Groningen, Ctr Language & Cognit Groningen, Groningen, Netherlands.
RP Schouwenaars, A (corresponding author), Oldenburg Univ, Dept Dutch, Cluster Excellence Hearing4all, Oldenburg, Germany.
EM a.schouwenaars@hotmail.com
OI Hendriks, Petra/0000-0002-7584-4078
FU Cluster of Excellence "Hearing4all" - German Research Council (DFG) [EXC
   1077/1]
FX The research was supported by the Cluster of Excellence EXC 1077/1
   "Hearing4all" funded by the German Research Council (DFG).
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   Arosio F, 2012, LANG LEARN DEV, V8, P340, DOI 10.1080/15475441.2011.634691
   Baddeley A, 2003, J COMMUN DISORD, V36, P189, DOI 10.1016/S0021-9924(03)00019-4
   Biran M, 2015, LINGUA, V164, P215, DOI 10.1016/j.lingua.2015.06.012
   Boons T, 2013, RES DEV DISABIL, V34, P2008, DOI 10.1016/j.ridd.2013.03.003
   Boons T, 2012, EAR HEARING, V33, P627, DOI 10.1097/AUD.0b013e3182503e47
   Booth JR, 2000, CHILD DEV, V71, P981, DOI 10.1111/1467-8624.00203
   Carroll R, 2013, J PSYCHOLINGUIST RES, V42, P139, DOI 10.1007/s10936-012-9213-7
   Caselli MC, 2012, J SPEECH LANG HEAR R, V55, P382, DOI 10.1044/1092-4388(2011/10-0248)
   Conway CM, 2009, CURR DIR PSYCHOL SCI, V18, P275, DOI 10.1111/j.1467-8721.2009.01651.x
   De Villiers J., 1994, CONSTRAINTS LANGUAGE, P9
   De Vincenzi Marica, 1999, P EUR C COGN SCI
   Deevy P, 2004, J SPEECH LANG HEAR R, V47, P802, DOI 10.1044/1092-4388(2004/060)
   Delage H, 2007, J SPEECH LANG HEAR R, V50, P1300, DOI 10.1044/1092-4388(2007/091)
   DeLuca Z. W., 2015, THESIS
   Drennan WR, 2008, J REHABIL RES DEV, V45, P779, DOI 10.1682/JRRD.2007.08.0118
   Duchesne L, 2009, J DEAF STUD DEAF EDU, V14, P465, DOI 10.1093/deafed/enp010
   Fiebach CJ, 2002, J MEM LANG, V47, P250, DOI 10.1016/S0749-596X(02)00004-9
   FRAZIER L, 1989, J MEM LANG, V28, P331, DOI 10.1016/0749-596X(89)90037-5
   Friedmann N, 2006, J DEAF STUD DEAF EDU, V11, P56, DOI 10.1093/deafed/enj002
   Friedmann N, 2011, J DEAF STUD DEAF EDU, V16, P212, DOI 10.1093/deafed/enq052
   GEERS A, 1994, VOLTA REV, V96, P131
   Geers AE, 2003, EAR HEARING, V24, p46S, DOI 10.1097/01.AUD.0000051689.57380.1B
   GEERS AE, 1978, J SPEECH HEAR DISORD, V43, P380, DOI 10.1044/jshd.4303.380
   Gibson E, 1998, COGNITION, V68, P1, DOI 10.1016/S0010-0277(98)00034-1
   Giezen M. R., 2011, THESIS
   Gillis S., 2002, ANTWERP PAPERS LINGU, P23
   Giraud AL, 2007, RESTOR NEUROL NEUROS, V25, P381
   Guasti MT, 2014, APPL PSYCHOLINGUIST, V35, P739, DOI 10.1017/S0142716412000562
   Hammer A, 2016, EAR HEARING, V37, P64, DOI 10.1097/AUD.0000000000000205
   Harris MS, 2013, EAR HEARING, V34, P179, DOI 10.1097/AUD.0b013e318269ce50
   Harrison RV, 2005, DEV PSYCHOBIOL, V46, P252, DOI 10.1002/dev.20052
   Hennies J, 2012, LOGOP PHONIATR VOCO, V37, P83, DOI 10.3109/14015439.2012.664653
   Hothorn T, 2008, BIOMETRICAL J, V50, P346, DOI 10.1002/bimj.200810425
   Kirk KI, 2002, ANN OTO RHINOL LARYN, V111, P69
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   Kronenberger WG, 2014, JAMA OTOLARYNGOL, V140, P608, DOI 10.1001/jamaoto.2014.757
   Kronenberger WG, 2013, J PEDIATR PSYCHOL, V38, P902, DOI 10.1093/jpepsy/jst034
   Kronenberger WG, 2013, J SPEECH LANG HEAR R, V56, P805, DOI 10.1044/1092-4388(2012/11-0356)
   Krueger B, 2008, OTOL NEUROTOL, V29, P509, DOI 10.1097/MAO.0b013e318171972f
   Le Normand MT, 2003, BRAIN COGNITION, V53, P257, DOI 10.1016/S0278-2626(03)00122-2
   Lesinski-Schiedat A, 2004, Cochlear Implants Int, V5, P146, DOI 10.1179/cim.2004.5.4.146
   Lindner K, 2003, LINGUISTICS, V41, P213, DOI 10.1515/ling.2003.008
   Metz M., 2010, GAGL GRONINGER ARBEI, V51, P27
   NEVILLE HJ, 1992, CEREB CORTEX, V2, P244, DOI 10.1093/cercor/2.3.244
   Nicholas JG, 2007, J SPEECH LANG HEAR R, V50, P1048, DOI 10.1044/1092-4388(2007/073)
   Nikolopoulos TP, 2004, ARCH OTOLARYNGOL, V130, P629, DOI 10.1001/archotol.130.5.629
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Nittrouer S., 2016, PEDIAT COCHLEAR IMPL, P177, DOI [10.1007/978-1-4939-2788-3_11, 10.1121/1.4919316, DOI 10.1007/978-1-4939-2788-3_11]
   Nixon JS, 2016, J MEM LANG, V90, P103, DOI 10.1016/j.jml.2016.03.005
   NOLEN SB, 1985, AM ANN DEAF, V130, P231
   Petermann F., 2007, HAMBURG WECHSLER INT
   Peterson NR, 2010, RESTOR NEUROL NEUROS, V28, P237, DOI 10.3233/RNN-2010-0535
   Pisoni D. B., 2012, OXFORD HDB DEAF STUD, V2, DOI [10.1093/oxfordhb/9780195390032.013.0029, DOI 10.1093/OXFORDHB/9780195390032.013.0029]
   Pisoni D. B., 2011, EAR HEARING, V32, P60, DOI DOI 10.1097/AUD.0B013E3181FFD58E
   Porretta V, 2018, SMART INNOV SYST TEC, V73, P268, DOI 10.1007/978-3-319-59424-8_25
   Porretta V, 2016, J PHONETICS, V58, P1, DOI 10.1016/j.wocn.2016.05.006
   POWER DJ, 1973, J SPEECH HEAR RES, V16, P5, DOI 10.1044/jshr.1601.05
   Roberts L, 2007, J PSYCHOLINGUIST RES, V36, P175, DOI 10.1007/s10936-006-9038-3
   Roesch A. D., 2015, LANG ACQUIS, P379
   Ruben RJ, 1997, ACTA OTO-LARYNGOL, V117, P202, DOI 10.3109/00016489709117769
   Ruigendijk E, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00689
   Schlesewsky Matthias, 2000, GERMAN SENTENCE PROC, P65, DOI [DOI 10.1007/978-94-015-9618-3_3, 10.1007/978-94-015-9618-3_3]
   Schorr E. A., 2008, COMMUN DISORD Q, V29, P195, DOI DOI 10.1177/1525740108321217
   Schouwenaars A., 2014, SEL P 5 C GEN APPR L, P60
   Schouwenaars A, 2018, APPL PSYCHOLINGUIST, V39, P1279, DOI 10.1017/S0142716418000334
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   SLOBIN DI, 1982, COGNITION, V12, P229, DOI 10.1016/0010-0277(82)90033-6
   Stacey PC, 2006, EAR HEARING, V27, P161, DOI 10.1097/01.aud.0000202353.37567.b4
   Svirsky MA, 2004, AUDIOL NEURO-OTOL, V9, P224, DOI 10.1159/000078392
   Svirsky MA, 2000, PSYCHOL SCI, V11, P153, DOI 10.1111/1467-9280.00231
   Svirsky MA, 2002, ANN OTO RHINOL LARYN, V111, P109
   Szagun G, 2001, AUDIOL NEURO-OTOL, V6, P288, DOI 10.1159/000046134
   Szagun G, 2000, AUDIOL NEURO-OTOL, V5, P39, DOI 10.1159/000013864
   Szagun G, 2016, J CHILD LANG, V43, P505, DOI 10.1017/S0305000915000641
   Tobey EA, 2013, INT J AUDIOL, V52, P219, DOI 10.3109/14992027.2012.759666
   Tomblin JB, 2005, J SPEECH LANG HEAR R, V48, P853, DOI 10.1044/1092-4388(2005/059)
   Tomblin JB, 1999, J SPEECH LANG HEAR R, V42, P497, DOI 10.1044/jslhr.4202.497
   van Rij J., 2016, EMPIRICAL PERSPECTIV, V277, P267
   van Rij J., 2017, ITSADUG INTERPRETING
   van Wieringen A, 2015, HEARING RES, V322, P171, DOI 10.1016/j.heares.2014.09.002
   Volpato F., 2012, P ROM TURN 4 WORKSH, P284
   Wimmer E., 2015, LANG ACQUIS, P584
   Winter B, 2016, J LANG EVOL, V1, P7, DOI 10.1093/jole/lzv003
   Wood SN, 2011, J R STAT SOC B, V73, P3, DOI 10.1111/j.1467-9868.2010.00749.x
   Wood SN, 2006, TEXTS STAT SCI
   Young GA, 2002, ANN OTO RHINOL LARYN, V111, P802, DOI 10.1177/000348940211100908
NR 87
TC 1
Z9 1
U1 0
U2 7
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD FEB
PY 2019
VL 62
IS 2
BP 387
EP 409
DI 10.1044/2018_JSLHR-H-17-0310
PG 23
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA HM7TM
UT WOS:000459682600014
PM 30950684
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Tamura, S
   Ito, K
   Hirose, N
   Mori, S
AF Tamura, Shunsuke
   Ito, Kazuhito
   Hirose, Nobuyuki
   Mori, Shuji
TI Effects of Manipulating the Amplitude of Consonant Noise Portion on
   Subcortical Representation of Voice Onset Time and Voicing Perception in
   Stop Consonants
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID BRAIN-STEM RESPONSES; CATEGORICAL PERCEPTION; AUDITORY-CORTEX; HEARING
   SPEECH; INTELLIGIBILITY; REVERBERATION; LANGUAGE; VOT
AB Purpose: The purpose of this study was to investigate whether speech perception would reflect small latency changes in subcortical speech representation.
   Method: Twelve native Japanese listeners participated in the experiment. Those listeners participated in speech identification task and auditory brainstem response (ABR) measurement using /d/-/t/ continuum stimuli varying in voice onset time (VOT) with manipulation of the amplitude of initial noise (consonant) portion, the duration of which corresponded to VOT.
   Results: Increasing the noise portion amplitude lengthened subcortical representation of VOT, which is the latency difference between ABRs synchronizing to the onsets of initial noise and following periodic (vowel) portions (VOTABR) and made listeners likely to perceive the stimuli with ambiguous VOT as a voiceless stop /t/. In addition, the amount of VOTABR lengthening was close to that of the VOT boundary shortening.
   Conclusion: A few milliseconds of difference in subcortical speech representation are important for the perception of speech sounds with ambiguous acoustic cues.
C1 [Tamura, Shunsuke] Kyushu Univ, Grad Sch Informat Sci & Elect Engn, Fukuoka, Fukuoka, Japan.
   [Ito, Kazuhito; Hirose, Nobuyuki; Mori, Shuji] Kyushu Univ, Fac Informat Sci & Elect Engn, Fukuoka, Fukuoka, Japan.
RP Tamura, S (corresponding author), Kyushu Univ, Grad Sch Informat Sci & Elect Engn, Fukuoka, Fukuoka, Japan.
EM tamuras@cog.inf.kyushu-u.ac.jp
FU Japan KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [JP18J10654,
   JP25240023]
FX The research was supported by Japan KAKENHI Grant JP18J10654 to Shunsuke
   Tamura and JP25240023 to Shuji Mori.
CR Anderson S, 2013, P NATL ACAD SCI USA, V110, P4357, DOI 10.1073/pnas.1213555110
   Anderson S, 2010, J NEUROSCI, V30, P4922, DOI 10.1523/JNEUROSCI.0107-10.2010
   Bidelman GM, 2015, J NEUROSCI METH, V241, P94, DOI 10.1016/j.jneumeth.2014.12.019
   Boersma P., 2015, PRAAT VERSION 5 4 08
   Chandrasekaran B, 2009, NEURON, V64, P311, DOI 10.1016/j.neuron.2009.10.006
   Coffey EBJ, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11070
   Forte AE, 2017, ELIFE, V6, DOI 10.7554/eLife.27203
   Frye RE, 2007, J COGNITIVE NEUROSCI, V19, P1476, DOI 10.1162/jocn.2007.19.9.1476
   Fujihira H, 2017, NEUROSCI LETT, V637, P102, DOI 10.1016/j.neulet.2016.11.042
   Fujihira H, 2015, CLIN NEUROPHYSIOL, V126, P96, DOI 10.1016/j.clinph.2014.05.001
   HAGGARD M, 1970, J ACOUST SOC AM, V47, P613, DOI 10.1121/1.1911936
   Hornickel J, 2009, P NATL ACAD SCI USA, V106, P13022, DOI 10.1073/pnas.0901123106
   KLATT DH, 1980, J ACOUST SOC AM, V67, P971, DOI 10.1121/1.383940
   LISKER L, 1977, LANG SPEECH, V20, P209, DOI 10.1177/002383097702000303
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   LISKER L, 1975, J ACOUST SOC AM, V57, P1547, DOI 10.1121/1.380602
   Lisker L., 1970, P 6 INT C PHON SCI P, P563
   Marler JA, 2005, J SPEECH LANG HEAR R, V48, P189, DOI 10.1044/1092-4388(2005/014)
   NEELY ST, 1988, J ACOUST SOC AM, V83, P652, DOI 10.1121/1.396542
   PLOMP R, 1959, J ACOUST SOC AM, V31, P749, DOI 10.1121/1.1907781
   Reichenbach CS, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00047
   REPP BH, 1982, PSYCHOL BULL, V92, P81, DOI 10.1037/0033-2909.92.1.81
   REPP BH, 1979, LANG SPEECH, V22, P173, DOI 10.1177/002383097902200207
   Russo N, 2004, CLIN NEUROPHYSIOL, V115, P2021, DOI 10.1016/j.clinph.2004.04.003
   Sharma A, 1999, J ACOUST SOC AM, V106, P1078, DOI 10.1121/1.428048
   Simos PG, 1998, COGNITIVE BRAIN RES, V7, P215, DOI 10.1016/S0926-6410(98)00037-8
   Skoe E, 2010, EAR HEARING, V31, P302, DOI 10.1097/AUD.0b013e3181cdb272
   Song JH, 2006, AUDIOL NEURO-OTOL, V11, P233, DOI 10.1159/000093058
   Song JH, 2012, CEREB CORTEX, V22, P1180, DOI 10.1093/cercor/bhr196
   Steinschneider M, 1999, J NEUROPHYSIOL, V82, P2346
   Steinschneider M, 2005, CEREB CORTEX, V15, P170, DOI 10.1093/cercor/bhh120
   Steinschneider M, 2013, HEARING RES, V305, P57, DOI 10.1016/j.heares.2013.05.013
   SUMMERFIELD Q, 1982, J ACOUST SOC AM, V72, P51, DOI 10.1121/1.388024
   Tamura S, 2018, J SPEECH LANG HEAR R, V61, P789, DOI 10.1044/2017_JSLHR-H-17-0131
   Toscano JC, 2010, PSYCHOL SCI, V21, P1532, DOI 10.1177/0956797610384142
   Young ED, 2008, PHILOS T R SOC B, V363, P923, DOI 10.1098/rstb.2007.2151
NR 36
TC 2
Z9 2
U1 1
U2 3
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD FEB
PY 2019
VL 62
IS 2
BP 434
EP 441
DI 10.1044/2018_JSLHR-H-18-0102
PG 8
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA HM7TM
UT WOS:000459682600017
PM 30950688
DA 2021-02-24
ER

PT J
AU Oron, A
   Szelag, E
   Nowak, K
   Dacewicz, A
   Szymaszek, A
AF Oron, Anna
   Szelag, Elzbieta
   Nowak, Kamila
   Dacewicz, Anna
   Szymaszek, Aneta
TI Age-related differences in Voice-Onset-Time in Polish language users: An
   ERP study
SO ACTA PSYCHOLOGICA
LA English
DT Article
DE Voice-Onset-Time; Mismatch negativity; P1; N1; N1'; P2; N2; Aging
ID MISMATCH-NEGATIVITY MMN; NEURAL REPRESENTATION; EVOKED-POTENTIALS;
   SPEECH-PERCEPTION; CROSS-LANGUAGE; HEARING-LOSS; DURATION; COMPONENTS;
   STIMULI; YOUNGER
AB Using the Mismatch Negativity (MMN) paradigm we investigated for the first time cortical responses to consonant - vowel (CV) syllables differing in Voice-Onset-Time (VOT) for Polish, a member of the Slavic group of languages. The study aimed at testing age-related effects on different ERP responses in young (20-30 years of age) and elderly (60-68 years) native Polish speakers. Participants were presented with a sequence of voiced and voiceless stop CV syllables /to/ and /do/ with different VOT values (-100 ms, -70 ms, -30 ms, -20 ms, + 20 ms, + 50 ms). We analyzed MMN and P1, N1, N1', P2, N2 components. Our results showed an age-related decline in voicing perception in all tested ERP components. This decline could be explained in relation to a general slowing in neural processing with advancing age and may be associated with difficulties in temporal- and spectral-information processing in elderly people. Our findings revealed also that specific features of Slavic languages influence ERP morphology in a different way than reported in the literature for aspirating languages.
C1 [Oron, Anna; Szelag, Elzbieta; Nowak, Kamila; Dacewicz, Anna; Szymaszek, Aneta] Polish Acad Sci, Nencki Inst Expt Biol, Lab Neuropsychol, 3 Pasteur St, PL-02093 Warsaw, Poland.
RP Szymaszek, A (corresponding author), Polish Acad Sci, Nencki Inst Expt Biol, Lab Neuropsychol, 3 Pasteur St, PL-02093 Warsaw, Poland.
EM a.szymaszek@nencki.gov.pl
RI Szymaszek, Aneta/U-5474-2018; Szelag, Elzbieta/F-8959-2015
OI Szymaszek, Aneta/0000-0001-9786-1277; Szelag,
   Elzbieta/0000-0003-0245-4973
FU National Science Centre, PolandNational Science Centre, Poland
   [2016/21/13/HS6/03775, 2015/17/B/HS6/04182]
FX This research was supported by National Science Centre, Poland, grant
   numbers 2016/21/13/HS6/03775 and 2015/17/B/HS6/04182.
CR Aerts A, 2013, BRAIN LANG, V125, P253, DOI 10.1016/j.bandl.2013.02.010
   Aghamolaei M, 2018, CLIN NEUROPHYSIOL, V129, P2252, DOI 10.1016/j.clinph.2018.08.006
   Aine CJ, 2005, COGNITIVE BRAIN RES, V24, P1, DOI 10.1016/j.cogbrainres.2004.10.024
   Alain C, 1998, BRAIN RES, V812, P23, DOI 10.1016/S0006-8993(98)00851-8
   Alain C, 2007, CEREB CORTEX, V17, P1074, DOI 10.1093/cercor/bhl018
   Amenedo E, 2000, EUR J NEUROSCI, V12, P2570, DOI 10.1046/j.1460-9568.2000.00114.x
   American National Standards Institute, 2004, S362004 ANSI
   Anderson D.E., 2018, WILEY HDB AGING MIND, P188
   Anderson S, 2013, P NATL ACAD SCI USA, V110, P4357, DOI 10.1073/pnas.1213555110
   Anderson S, 2012, J NEUROSCI, V32, P14156, DOI 10.1523/JNEUROSCI.2176-12.2012
   Bellis TJ, 2000, J NEUROSCI, V20, P791, DOI 10.1523/JNEUROSCI.20-02-00791.2000
   Besson M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00094
   Botinhao CV, 2017, INTERSPEECH, P2944, DOI 10.21437/Interspeech.2017-105
   Brown A., 2017, NEURAL CODING NATURA
   Cabeza R., 2016, COGNITIVE NEUROSCIEN
   Ceponiene R, 2008, BRAIN RES, V1215, P53, DOI 10.1016/j.brainres.2008.02.010
   Cheng CH, 2015, BIOL PSYCHOL, V104, P48, DOI 10.1016/j.biopsycho.2014.11.003
   Chobert J, 2012, NEUROPSYCHOLOGIA, V50, P2044, DOI 10.1016/j.neuropsychologia.2012.05.004
   Dimitrijevic A, 2013, CLIN NEUROPHYSIOL, V124, P1204, DOI 10.1016/j.clinph.2012.11.014
   Doellinger Michael, 2011, Open Neurol J, V5, P37, DOI 10.2174/1874205X01105010037
   Du Y, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12241
   Duncan CC, 2009, CLIN NEUROPHYSIOL, V120, P1883, DOI 10.1016/j.clinph.2009.07.045
   Eckert MA, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00025
   GARCIALARREA L, 1992, NEUROPSYCHOLOGIA, V30, P723, DOI 10.1016/0028-3932(92)90042-K
   Getzmann S, 2015, NEUROPSYCHOLOGIA, V70, P43, DOI 10.1016/j.neuropsychologia.2015.02.009
   GOODIN DS, 1978, ELECTROEN CLIN NEURO, V44, P447, DOI 10.1016/0013-4694(78)90029-9
   Harkrider AW, 2005, CLIN NEUROPHYSIOL, V116, P2153, DOI 10.1016/j.clinph.2005.05.016
   Hasher Lynn, 1988, PSYCHOL LEARN MOTIV, V22, P193, DOI DOI 10.1016/S0079-7421(08)60041-9
   Hitchcock E. R., 2017, J ACOUST SOC AM, V141, P3982, DOI [10.1121/1.4989095, DOI 10.1121/1.4989095]
   Ho MC, 2012, NEUROSCI LETT, V507, P78, DOI 10.1016/j.neulet.2011.11.057
   Jacobsen T, 2003, CLIN NEUROPHYSIOL, V114, P1133, DOI 10.1016/S1388-2457(03)00043-9
   Kim JR, 2012, OTOL NEUROTOL, V33, P1105, DOI 10.1097/MAO.0b013e3182659b1e
   King KA, 2008, CLIN NEUROPHYSIOL, V119, P2855, DOI 10.1016/j.clinph.2008.09.015
   Kok A., 1999, AGING INHIBITION MUL, P100
   Kovacevic S, 2005, NEUROREPORT, V16, P1075, DOI 10.1097/00001756-200507130-00009
   Kraus Nina, 2013, Hear J, V66, P36
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Luke S. J., 2005, INTRO EVENT RELATED
   Martin BA, 2008, EAR HEARING, V29, P285, DOI 10.1097/AUD.0b013e3181662c0e
   May PJC, 2010, PSYCHOPHYSIOLOGY, V47, P66, DOI 10.1111/j.1469-8986.2009.00856.x
   Milner R., 2015, NOWA AUDIOFONOLOGIA, V4
   Mueller V, 2008, BMC NEUROSCI, V9, DOI 10.1186/1471-2202-9-18
   Naatanen R, 2003, INT J PSYCHOPHYSIOL, V48, P179, DOI 10.1016/S0167-8760(03)00053-9
   Naatanen R, 2012, CLIN NEUROPHYSIOL, V123, P424, DOI 10.1016/j.clinph.2011.09.020
   Naatanen R, 2000, AUDIOL NEURO-OTOL, V5, P105, DOI 10.1159/000013874
   Obleser J, 2006, CEREB CORTEX, V16, P1069, DOI 10.1093/cercor/bhj047
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Paavilainen P, 2013, INT J PSYCHOPHYSIOL, V88, P109, DOI 10.1016/j.ijpsycho.2013.03.015
   Pakarinen S, 2009, BIOL PSYCHOL, V82, P219, DOI 10.1016/j.biopsycho.2009.07.008
   PICTON TW, 1984, PSYCHOPHYSIOLOGY, V21, P312, DOI 10.1111/j.1469-8986.1984.tb02941.x
   Rimmele JM, 2015, INT J PSYCHOPHYSIOL, V95, P175, DOI 10.1016/j.ijpsycho.2014.06.010
   Rojczyk A., 2010, TEMPORAL SPECTRAL PA
   Rufener KS, 2014, BRAIN BEHAV, V4, P21, DOI 10.1002/brb3.188
   Salthouse T., 2016, THEORETICAL PERSPECT
   Schiff S, 2008, CLIN NEUROPHYSIOL, V119, P1795, DOI 10.1016/j.clinph.2008.04.007
   Sharma A, 1999, J ACOUST SOC AM, V106, P1078, DOI 10.1121/1.428048
   Sharma A, 2000, J ACOUST SOC AM, V107, P2697, DOI 10.1121/1.428655
   Staub B, 2015, NEUROPSYCHOLOGIA, V75, P607, DOI 10.1016/j.neuropsychologia.2015.07.021
   Steinschneider M, 2011, CEREB CORTEX, V21, P2332, DOI 10.1093/cercor/bhr014
   Stevenson RA, 2015, NEUROBIOL AGING, V36, P283, DOI 10.1016/j.neurobiolaging.2014.08.003
   Strouse A, 1998, J ACOUST SOC AM, V104, P2385, DOI 10.1121/1.423748
   Szelag E., 2014, NOWE SPOJRZENIE ZEGA
   Szymaszek A, 2009, COGN NEUROPSYCHOL, V26, P135, DOI 10.1080/02643290802504742
   Tome D, 2015, J NEURAL TRANSM, V122, P375, DOI 10.1007/s00702-014-1258-3
   Tremblay KL, 2003, EAR HEARING, V24, P225, DOI 10.1097/01.AUD.0000069229.84883.03
   Tremblay KL, 2003, CLIN NEUROPHYSIOL, V114, P1332, DOI 10.1016/S1388-2457(03)00114-7
   Tremblay KL, 2002, NEUROREPORT, V13, P1865, DOI 10.1097/00001756-200210280-00007
   Tusch ES, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0165645
   Vermeire K, 2016, ANN OTO RHINOL LARYN, V125, P297, DOI 10.1177/0003489415611424
   Werff KRV, 2011, EAR HEARING, V32, P168, DOI 10.1097/AUD.0b013e3181f534b5
   Winkler I, 2007, J PSYCHOPHYSIOL, V21, P147, DOI 10.1027/0269-8803.21.34.147
   Yu VY, 2015, LANG SPEECH, V58, P152, DOI 10.1177/0023830914522994
   Zhao TC, 2016, P NATL ACAD SCI USA, V113, P5212, DOI 10.1073/pnas.1603984113
NR 73
TC 0
Z9 0
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0001-6918
EI 1873-6297
J9 ACTA PSYCHOL
JI Acta Psychol.
PD FEB
PY 2019
VL 193
BP 18
EP 29
DI 10.1016/j.actpsy.2018.12.002
PG 12
WC Psychology, Experimental
SC Psychology
GA HL4RU
UT WOS:000458711600003
PM 30580059
DA 2021-02-24
ER

PT J
AU Perez, A
   Dumas, G
   Karadag, M
   Dunabeitia, JA
AF Perez, Alejandro
   Dumas, Guillaume
   Karadag, Melek
   Andoni Dunabeitia, Jon
TI Differential brain-to-brain entrainment while speaking and listening in
   native and foreign languages
SO CORTEX
LA English
DT Article
DE Brain-to-brain entrainment; Interbrain coupling; EEG hyperscanning;
   Two-Person neuroscience; Foreign language
ID NEURAL SYNCHRONIZATION; NEURONAL OSCILLATIONS; SOCIAL-INTERACTION;
   SPEECH-PERCEPTION; ATTENTION; ALPHA; COMMUNICATION; RESPONSES; TRACKING;
   TIME
AB The study explores interbrain neural coupling when interlocutors engage in a conversation whether it be in their native or nonnative language. To this end, electroencephalographic hyperscanning was used to study brain-to-brain phase synchronization during a two person turn-taking verbal exchange with no visual contact, in either a native or a foreign language context. Results show that the coupling strength between brain signals is increased in both, the native language context and the foreign language context, specifically, in the alpha frequency band. A difference in brain-to speech entrainment to native and foreign languages is also shown. These results indicate that between brain similarities in the timing of neural activations and their spatial distributions change depending on the language code used. We argue that factors like linguistic alignment, joint attention and brain-entrainment to speech operate with a language-idiosyncratic neural configuration, modulating the alignment of neural activity between speakers and listeners. Other possible factors leading to the differential interbrain synchronization patterns as well as the potential features of brain-to-brain entrainment as a mechanism are briefly discussed. We concluded that linguistic context should be considered when addressing interpersonal communication. The findings here open doors to quantifying linguistic interactions. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Perez, Alejandro] Univ Toronto Scarborough, Ctr French & Linguist, Toronto, ON, Canada.
   [Perez, Alejandro] Univ Toronto Scarborough, Dept Psychol, Toronto, ON, Canada.
   [Perez, Alejandro; Andoni Dunabeitia, Jon] Basque Ctr Cognit Brain & Language, BCBL, Donostia San Sebastian, Spain.
   [Dumas, Guillaume] Inst Pasteur, Human Genet & Cognit Funct Unit, Paris, France.
   [Dumas, Guillaume] Inst Pasteur, CNRS UMR 3571 Genes Synapses & Cognit, Paris, France.
   [Dumas, Guillaume] Univ Paris Diderot, Sorbonne Paris Cite, Human Genet & Cognit Funct, Paris, France.
   [Karadag, Melek] Univ Cambridge, Dept Psychol, Ctr Speech Language & Brain, Cambridge, England.
   [Andoni Dunabeitia, Jon] Univ Nebrija, Fac Lenguas & Educ, Madrid, Spain.
RP Perez, A (corresponding author), 1265 Mil Trail, Toronto, ON M1C 1A4, Canada.
EM alejandro.perez@utoronto.ca
RI Perez, Alejandro/H-2202-2015; Dumas, Guillaume/E-3756-2012; Dunabeitia,
   Jon Andoni/C-8503-2014
OI Perez, Alejandro/0000-0001-6631-9653; Dumas,
   Guillaume/0000-0002-2253-1844; Dunabeitia, Jon
   Andoni/0000-0002-3312-8559
FU Spanish Ministry of Economy and Competitiveness through the "Severo
   Ochoa Programme for Centres/Units of Excellence in RD" [SEV-2015-490,
   PSI2015-65689-P]
FX We thank Rosa M. Fernandez, Jo-Anne Blanchet and Gino Ruffo for their
   support at different stages of the study. We also thank Dr. Blair
   Armstrong for the revision of the manuscript. The authors acknowledge
   financial support from the Spanish Ministry of Economy and
   Competitiveness through the "Severo Ochoa Programme for Centres/Units of
   Excellence in R&D" (SEV-2015-490) and the PSI2015-65689-P grants.
CR Ahn S, 2018, HUM BRAIN MAPP, V39, P171, DOI 10.1002/hbm.23834
   Alexandrou AM, 2017, NEUROIMAGE, V152, P628, DOI 10.1016/j.neuroimage.2017.03.006
   Astolfi L, 2010, BRAIN TOPOGR, V23, P243, DOI 10.1007/s10548-010-0147-9
   Babiloni F, 2014, NEUROSCI BIOBEHAV R, V44, P76, DOI 10.1016/j.neubiorev.2012.07.006
   Beckner C, 2009, LANG LEARN, V59, P1
   Benjamini Y, 2001, ANN STAT, V29, P1165
   Berens P, 2009, J STAT SOFTW, V31, P1, DOI 10.18637/jss.v031.i10
   Bruce C, 2013, J COMMUN DISORD, V46, P475, DOI 10.1016/j.jcomdis.2013.08.002
   Buiatti M, 2009, NEUROIMAGE, V44, P509, DOI 10.1016/j.neuroimage.2008.09.015
   Burgess AP, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00881
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Cheng XJ, 2015, HUM BRAIN MAPP, V36, P2039, DOI 10.1002/hbm.22754
   Cohen MX, 2009, J COGNITIVE NEUROSCI, V21, P390, DOI 10.1162/jocn.2008.21020
   Craver Carl F., 2017, STANFORD ENCY PHILOS
   Dai BH, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04819-z
   de Bruin A, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00522
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Delorme A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030135
   Dikker S, 2017, CURR BIOL, V27, P1375, DOI 10.1016/j.cub.2017.04.002
   Dikker S, 2014, J NEUROSCI, V34, P6267, DOI 10.1523/JNEUROSCI.3796-13.2014
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Dumas G, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0012166
   Evans N, 2013, BEHAV BRAIN SCI, V36, P419, DOI 10.1017/S0140525X12001896
   Frey JN, 2015, BRAIN RES, V1626, P183, DOI 10.1016/j.brainres.2015.02.017
   Friston K, 2015, CONSCIOUS COGN, V36, P390, DOI 10.1016/j.concog.2014.12.003
   Friston KJ, 2015, CORTEX, V68, P129, DOI 10.1016/j.cortex.2015.03.025
   Garcia-Penton L, 2016, LANG COGN NEUROSCI, V31, P303, DOI 10.1080/23273798.2015.1068944
   Ghitza O, 2009, PHONETICA, V66, P113, DOI 10.1159/000208934
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Glanz O, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-26801-x
   Goldstein P, 2018, P NATL ACAD SCI USA, V115, pE2528, DOI 10.1073/pnas.1703643115
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Hari R, 2015, NEURON, V88, P181, DOI 10.1016/j.neuron.2015.09.022
   Hari R, 2009, PHYSIOL REV, V89, P453, DOI 10.1152/physrev.00041.2007
   Hasson U, 2012, TRENDS COGN SCI, V16, P114, DOI 10.1016/j.tics.2011.12.007
   Hayakawa S, 2018, COGNITION, V173, P8, DOI 10.1016/j.cognition.2017.12.010
   Jammalamadaka SR, 2001, TOPICS CIRCULAR STAT
   Jensen O, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00186
   Jiang J, 2012, J NEUROSCI, V32, P16064, DOI 10.1523/JNEUROSCI.2926-12.2012
   Kawasaki M, 2013, SCI REP-UK, V3, DOI 10.1038/srep01692
   Keitel A, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2004473
   Keitel A, 2017, NEUROIMAGE, V147, P32, DOI 10.1016/j.neuroimage.2016.11.062
   Klimesch W, 2012, TRENDS COGN SCI, V16, P606, DOI 10.1016/j.tics.2012.10.007
   Kormos J, 2000, LANG LEARN, V50, P343, DOI 10.1111/0023-8333.00120
   Kuhlen AK, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00266
   Lachat F, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00156
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735
   Lakatos P, 2007, NEURON, V53, P279, DOI 10.1016/j.neuron.2006.12.011
   Leong V, 2017, P NATL ACAD SCI USA, V114, P13290, DOI 10.1073/pnas.1702493114
   Leow RP, 1997, LANG LEARN, V47, P467, DOI 10.1111/0023-8333.00017
   Lev-Ari S, 2018, TOP COGN SCI, V10, P835, DOI 10.1111/tops.12325
   Liu YC, 2017, SCI REP-UK, V7, DOI 10.1038/srep43293
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Magrassi L, 2015, P NATL ACAD SCI USA, V112, P1868, DOI 10.1073/pnas.1418162112
   Mahon BZ, 2016, PSYCHON B REV, V23, P941, DOI 10.3758/s13423-016-1045-2
   Menenti L, 2011, PSYCHOL SCI, V22, P1173, DOI 10.1177/0956797611418347
   Mu Y, 2016, SOC COGN AFFECT NEUR, V11, P1882, DOI 10.1093/scan/nsw106
   Mullen T, 2013, IEEE ENG MED BIO, P2184, DOI 10.1109/EMBC.2013.6609968
   Mullen TR, 2015, IEEE T BIO-MED ENG, V62, P2553, DOI 10.1109/TBME.2015.2481482
   Munro MJ, 1995, LANG SPEECH, V38, P289, DOI 10.1177/002383099503800305
   Nozawa T, 2016, NEUROIMAGE, V133, P484, DOI 10.1016/j.neuroimage.2016.03.059
   Nummenmaa L, 2014, NEUROIMAGE, V102, P498, DOI 10.1016/j.neuroimage.2014.07.063
   Obleser J, 2012, CEREB CORTEX, V22, P2466, DOI 10.1093/cercor/bhr325
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Oostenveld R, 2002, HUM BRAIN MAPP, V17, P179, DOI 10.1002/hbm.10061
   Palmer J. A, 2007, 7 INT C
   Park H, 2016, ELIFE, V5, DOI 10.7554/eLife.14521
   Pate JK, 2015, J MEM LANG, V78, P1, DOI 10.1016/j.jml.2014.10.003
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Perani D, 2005, CURR OPIN NEUROBIOL, V15, P202, DOI 10.1016/j.conb.2005.03.007
   Perez A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04464-4
   Perez A, 2015, BRAIN LANG, V147, P51, DOI 10.1016/j.bandl.2015.05.008
   Perez A, 2015, NEUROPSYCHOLOGIA, V68, P209, DOI 10.1016/j.neuropsychologia.2015.01.021
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169
   Pineda JA, 2005, BRAIN RES REV, V50, P57, DOI 10.1016/j.brainresrev.2005.04.005
   Reznik D, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5059
   Riecke L, 2018, CURR BIOL, V28, P161, DOI 10.1016/j.cub.2017.11.033
   Rimmele JM, 2015, CORTEX, V68, P144, DOI 10.1016/j.cortex.2014.12.014
   Rommers J, 2017, NEUROPSYCHOLOGIA, V95, P101, DOI 10.1016/j.neuropsychologia.2016.12.013
   Schilbach L, 2013, BEHAV BRAIN SCI, V36, P393, DOI 10.1017/S0140525X12000660
   Schirmer A, 2016, TRENDS COGN SCI, V20, P760, DOI 10.1016/j.tics.2016.08.002
   Schoot L, 2016, NEUROSCI BIOBEHAV R, V68, P454, DOI 10.1016/j.neubiorev.2016.06.009
   Smith ZM, 2002, NATURE, V416, P87, DOI 10.1038/416087a
   Spiegelhalder K, 2014, BEHAV BRAIN RES, V258, P75, DOI 10.1016/j.bbr.2013.10.015
   Stephens GJ, 2010, P NATL ACAD SCI USA, V107, P14425, DOI 10.1073/pnas.1008662107
   Strauss A, 2014, NEUROIMAGE, V97, P387, DOI 10.1016/j.neuroimage.2014.04.005
   Strauss A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00350
   Tadic B, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0166787
   Tang HH, 2016, SOC COGN AFFECT NEUR, V11, P23, DOI 10.1093/scan/nsv092
   Weiss S, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00201
   Wilsch A, 2015, CEREB CORTEX, V25, P1938, DOI 10.1093/cercor/bhu004
   Zoefel B, 2018, CURR BIOL, V28, P401, DOI 10.1016/j.cub.2017.11.071
   Zoefel B, 2017, LANG COGN NEUROSCI, V32, P910, DOI 10.1080/23273798.2016.1247970
NR 94
TC 11
Z9 12
U1 8
U2 36
PU ELSEVIER MASSON, CORPORATION OFFICE
PI PARIS
PA 65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE
SN 0010-9452
EI 1973-8102
J9 CORTEX
JI Cortex
PD FEB
PY 2019
VL 111
BP 303
EP 315
DI 10.1016/j.cortex.2018.11.026
PG 13
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA HK8EY
UT WOS:000458223400021
PM 30598230
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Gonzalez-Gomez, N
   Schmandt, S
   Fazekas, J
   Nazzi, T
   Gervain, J
AF Gonzalez-Gomez, Nayeli
   Schmandt, Silvana
   Fazekas, Judit
   Nazzi, Thierry
   Gervain, Judit
TI Infants' sensitivity to nonadjacent vowel dependencies: The case of
   vowel harmony in Hungarian
SO JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY
LA English
DT Article
DE Early language acquisition; Speech perception; Vowel harmony;
   Nonadjacent phonological dependencies; Hungarian; French
ID 1ST YEAR; ACQUISITION; SPEECH; SEGMENTATION; CONSTRAINTS; PATTERNS;
   STRESS
AB Vowel harmony is a linguistic phenomenon whereby vowels within a word share one or several of their phonological features, constituting a nonadjacent, and thus challenging, dependency to learn. It can be found in a large number of agglutinating languages, such as Hungarian and Turkish, and it may apply both at the lexical level (i.e., within word stems) and at the morphological level (i.e., between stems and their affixes). Thus, it might affect both lexical and morphological development in infants whose native language has vowel harmony. The current study asked at what age infants learning an irregular harmonic language, Hungarian, become sensitive to vowel harmony within word stems. In a head-turn preference study, 13-month-old, but not 10-month-old, Hungarian-learning infants preferred listening to nonharmonic VCV (vowel-consonant-vowel) pseudowords over vowel harmonic ones. A control experiment with 13-month-olds exposed to French, a nonharmonic language, showed no listening preference for either of the sequences, suggesting that this finding cannot be explained by a universal preference for nonharmonic sequences but rather reflects language-specific knowledge emerging between 10 and 13 months of age. We discuss the implications of this finding for morphological and lexical learning. (C) 2018 Published by Elsevier Inc.
C1 [Gonzalez-Gomez, Nayeli] Oxford Brookes Univ, Dept Psychol, Oxford OX3 0BP, England.
   [Schmandt, Silvana] Univ Potsdam, Dept Linguist, D-14469 Potsdam, Germany.
   [Fazekas, Judit] Univ Edinburgh, Dept Linguist & English Language, Edinburgh EH8 9AD, Midlothian, Scotland.
   [Nazzi, Thierry; Gervain, Judit] Univ Paris 05, Lab Psychol Percept, Sorbonne Paris Cite, F-75006 Paris, France.
   [Nazzi, Thierry; Gervain, Judit] CNRS, Lab Psychol Percept, F-75006 Paris, France.
RP Gonzalez-Gomez, N (corresponding author), Oxford Brookes Univ, Dept Psychol, Oxford OX3 0BP, England.
EM ngonzalez-gomez@brookes.ac.uk
OI Nazzi, Thierry/0000-0002-4378-3661
FU Labex Empirical Foundations of Linguistics (EFL) Grant
   [ANR-10-LABX-0083]; Fyssen Foundation Startup grant; Emergence(s)
   program grant of the City of Paris;  [ANR-13-BSH2-0004]; 
   [ANR-16-FRAL-0007];  [ANR-15-CE37-0009-01]
FX This study was conducted with the support of Grant ANR-13-BSH2-0004 to
   T.N., Grant ANR-16-FRAL-0007 to T.N. and S.S., Labex Empirical
   Foundations of Linguistics (EFL) Grant ANR-10-LABX-0083 to T.N. and
   J.G., and a Fyssen Foundation Startup grant, the Emergence(s) program
   grant of the City of Paris, and Grant ANR-15-CE37-0009-01 to J.G.
   Special thanks go to the infants and their parents for their kindness
   and cooperation. We thank Gergely Csibra, Agnes Volein, and the whole
   Cognitive Developmental Center of the Central European University,
   Budapest, Hungary, for their invaluable help and support with testing
   the Hungarian infants.
CR Altan A, 2016, ACQUISITION TURKISH, P29
   Avar B., 2015, 12 OLD WORLD C PHON
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Cristia A, 2008, LANG LEARN DEV, V4, P203, DOI 10.1080/15475440802143109
   Gervain J, 2012, COGNITION, V125, P263, DOI 10.1016/j.cognition.2012.06.010
   Goldsmith J, 2012, NAT LANG LINGUIST TH, V30, P859, DOI 10.1007/s11049-012-9169-1
   Gonzalez-Gomez N, 2016, J CHILD LANG, V43, P186, DOI 10.1017/S0305000915000112
   Gonzalez-Gomez N, 2015, DEVELOPMENTAL SCI, V18, P864, DOI 10.1111/desc.12279
   Gonzalez-Gomez N, 2014, COGNITION, V132, P301, DOI 10.1016/j.cognition.2014.04.004
   Gonzalez-Gomez N, 2012, DEVELOPMENTAL SCI, V15, P885, DOI 10.1111/j.1467-7687.2012.01186.x
   Gonzalez-Gomez N, 2012, INFANCY, V17, P498, DOI 10.1111/j.1532-7078.2011.00104.x
   Hayes B., 2006, PHONOLOGY, V23, P59, DOI [10.1017/S0952675706000765, DOI 10.1017/S0952675706000765]
   Hayes B, 2009, LANGUAGE, V85, P822
   Hohenberger A., 2017, P 41 ANN BOST U C LA, P309
   Hunter M. A., 1988, ADV INFANCY RES, V5, P69, DOI DOI 10.1037/0012-1649.19.3.338
   JUSCZYK PW, 1993, CHILD DEV, V64, P675, DOI 10.2307/1131210
   Jusczyk PW, 1999, TRENDS COGN SCI, V3, P323, DOI 10.1016/S1364-6613(99)01363-7
   Kabak B, 2010, LAB PHONOLOGY, V1, P207, DOI DOI 10.1515/LABPHON.2010.010
   Ketrez FN, 2014, J CHILD LANG, V41, P439, DOI 10.1017/S0305000912000724
   Lee M. D., 2014, BAYESIAN COGNITIVE M
   MacWhinney B., 1974, THESIS
   MacWhinney B., 1975, J CHILD LANG, V2, P65, DOI DOI 10.1017/S0305000900000891
   MacWhinney B., 2000, CHILDES PROJECT DATA, V2
   Maddieson Ian, 2013, WORLD ATLAS LANGUAGE
   Mintz TH, 2018, COGNITION, V171, P95, DOI 10.1016/j.cognition.2017.10.020
   Nazzi T, 2009, J ACOUST SOC AM, V126, P1440, DOI 10.1121/1.3158931
   New B, 2001, ANN PSYCHOL, V101, P447
   Polgardi K., 1998, VOWEL HARMONY ACCOUN, V3
   Rebrus P, 2015, THEOR LINGUIST, V41, P1, DOI 10.1515/tl-2015-0001
   Reger Z., 2004, HUNGARIAN REGER CORP
   Ringen C.O., 1998, PHONOLOGY, V15, P393, DOI [10.1017/S0952675799003632, DOI 10.1017/S0952675799003632]
   Roach P, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1892, DOI 10.1109/ICSLP.1996.608002
   Segal O, 2015, INFANCY, V20, P208, DOI 10.1111/infa.12072
   Suomi K, 1997, J MEM LANG, V36, P422, DOI 10.1006/jmla.1996.2495
   Torkenczy M., 2011, BLACKWELL COMPANION, P2963
   vansKampen A., 2008, LANG ACQUIS, P313
   Vroomen J, 1998, J MEM LANG, V38, P133, DOI 10.1006/jmla.1997.2548
NR 37
TC 5
Z9 5
U1 0
U2 3
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0022-0965
EI 1096-0457
J9 J EXP CHILD PSYCHOL
JI J. Exp. Child Psychol.
PD FEB
PY 2019
VL 178
BP 170
EP 183
DI 10.1016/j.jecp.2018.08.014
PG 14
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA HK9XX
UT WOS:000458347300011
PM 30380456
DA 2021-02-24
ER

PT J
AU Sorcinelli, A
   Ference, J
   Curtin, S
   Vouloumanos, A
AF Sorcinelli, Andrea
   Ference, Jennifer
   Curtin, Suzanne
   Vouloumanos, Athena
TI Preference for speech in infancy differentially predicts language skills
   and autism-like behaviors
SO JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY
LA English
DT Article
DE Speech perception and bias; Conspecifics; Autism spectrum disorder;
   High-risk infant siblings; Language development; Social development
ID LISTENING PREFERENCES; AUDITORY PREFERENCES; MACACA-MULATTA; 1ST YEAR;
   CHILDREN; PERCEPTION; SOUNDS; ATTENTION; RISK; EXPOSURE
AB Early emerging biases for conspecific vocalizations are a hallmark of early development. Typically developing neonates listen to speech more than many other sounds, including non-biological non-speech sounds, but listen equally to speech and monkey calls. By 3 months of age, however, infants prefer speech over both non biological non-speech sounds and monkey calls. We examined whether different listening preferences continue to develop along different developmental trajectories and whether listening preferences are related to developmental outcomes. Given the static preference for speech over non-biological non-speech sounds and the dynamic preference for speech over monkey calls between birth and 3 months, we examined whether 9-month-olds prefer speech over non-biological non-speech sounds (Experiment 1) and prefer speech over monkey calls (Experiment 2). We compared preferences for sounds in infants at low risk (SIBS-TD) and infants at high risk (SIBS-A) of autism spectrum disorder (ASD), a heterogeneous population who differ from typically developing infants in their preferences for speech, and examined whether listening preferences predict vocabulary and autism-like behaviors at 12 months for both groups. At 9 months, SIBS-TD listened longer to speech than to non-speech sounds and listened longer to monkey calls than to speech, whereas SIBS-A listened longer to speech than to non-speech sounds but listened equally to speech and monkey calls. SIBS-TD's preferences did not predict immediate developmental outcomes. In contrast, SIBS-A who preferred speech over non-speech or monkey calls had larger vocabularies and fewer markers of autism-like behaviors at 12 months, which could have positive developmental implications. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Sorcinelli, Andrea; Vouloumanos, Athena] NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
   [Ference, Jennifer; Curtin, Suzanne] Univ Calgary, Dept Psychol, Calgary, AB T2N 1N4, Canada.
RP Sorcinelli, A (corresponding author), NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
EM andrea.sorcinelli@nyu.edu
OI Curtin, Suzanne/0000-0003-1509-7960
FU Eunice Kennedy Shriver National Institute of Child Health and Human
   Development of the National Institutes of HealthUnited States Department
   of Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   Eunice Kennedy Shriver National Institute of Child Health & Human
   Development (NICHD) [R01HD072018]; EUNICE KENNEDY SHRIVER NATIONAL
   INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   Eunice Kennedy Shriver National Institute of Child Health & Human
   Development (NICHD) [R01HD072018] Funding Source: NIH RePORTER
FX This research was supported by the Eunice Kennedy Shriver National
   Institute of Child Health and Human Development of the National
   Institutes of Health under Grant R01HD072018 awarded to A.V. and S.C.
   Special thanks go to all the members of the New York University Infant
   Cognition and Communication Lab and the University of Calgary Speech
   Development Lab and especially all the families who participated in this
   study.
CR American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   Bryson SE, 2008, J AUTISM DEV DISORD, V38, P731, DOI 10.1007/s10803-007-0440-y
   COOPER RP, 1990, CHILD DEV, V61, P1584, DOI 10.1111/j.1467-8624.1990.tb02885.x
   COOPER RP, 1994, CHILD DEV, V65, P1663, DOI 10.1111/j.1467-8624.1994.tb00841.x
   Cristia A, 2014, CHILD DEV, V85, P1330, DOI 10.1111/cdev.12193
   Curtin S, 2013, J AUTISM DEV DISORD, V43, P2114, DOI 10.1007/s10803-013-1759-1
   Feldman HM, 2000, CHILD DEV, V71, P310, DOI 10.1111/1467-8624.00146
   Fenson L., 1993, MACARTHUR COMMUNICAT
   Ference J, 2015, INFANCY, V20, P242, DOI 10.1111/infa.12074
   Ference J, 2013, J EXP CHILD PSYCHOL, V116, P891, DOI 10.1016/j.jecp.2013.08.006
   Ferry AL, 2013, P NATL ACAD SCI USA, V110, P15231, DOI 10.1073/pnas.1221166110
   Frank MC, 2017, INFANCY, V22, P421, DOI 10.1111/infa.12182
   Hauser MD, 2000, COGNITIVE SCI, V24, P445, DOI 10.1207/s15516709cog2403_5
   HAUSER MD, 1993, BEHAV ECOL, V4, P194, DOI 10.1093/beheco/4.3.194
   Hayashi A, 2001, J SPEECH LANG HEAR R, V44, P1189, DOI 10.1044/1092-4388(2001/092)
   Hunter M. A., 1988, ADV INFANCY RES, V5, P69, DOI DOI 10.1037/0012-1649.19.3.338
   JOHNSON MH, 1991, COGNITION, V40, P1, DOI 10.1016/0010-0277(91)90045-6
   Jones EJH, 2014, NEUROSCI BIOBEHAV R, V39, P1, DOI 10.1016/j.neubiorev.2013.12.001
   Kemp N, 2017, APPL PSYCHOLINGUIST, V38, P289, DOI 10.1017/S0142716416000199
   Kidd C, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036399
   Kinzler KD, 2007, P NATL ACAD SCI USA, V104, P12577, DOI 10.1073/pnas.0705345104
   KLIN A, 1991, J AUTISM DEV DISORD, V21, P29, DOI 10.1007/BF02206995
   KLIN A, 1992, J CHILD PSYCHOL PSYC, V33, P763, DOI 10.1111/j.1469-7610.1992.tb00911.x
   Kuhl P. K., 1988, HUMAN EVOL, V3, P19, DOI DOI 10.1007/BF02436589
   Kuhl P. K, 1989, COMP PSYCHOL AUDITIO, P379
   Kuhl PK, 2005, DEVELOPMENTAL SCI, V8, pF1, DOI 10.1111/j.1467-7687.2004.00384.x
   Legerstee M, 2000, DEV PSYCHOL, V36, P627, DOI [10.1037//0012-1649.36.5.627, 10.1037/0012-1649.36.5.627]
   Liberman AM, 2000, TRENDS COGN SCI, V4, P187, DOI 10.1016/S1364-6613(00)01471-6
   Marno H, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01150
   Mitchell S, 2006, J DEV BEHAV PEDIATR, V27, pS69, DOI 10.1097/00004703-200604002-00004
   Mullen E., 1995, MULLEN SCALES EARLY
   Ozonoff S, 2014, J AM ACAD CHILD PSY, V53, P398, DOI 10.1016/j.jaac.2013.12.020
   Ozonoff S, 2011, PEDIATRICS, V128, pE488, DOI 10.1542/peds.2010-2825
   Paul R, 2007, J SPEECH LANG HEAR R, V50, P1350, DOI 10.1044/1092-4388(2007/094)
   Pelphrey KA, 2011, J CHILD PSYCHOL PSYC, V52, P631, DOI 10.1111/j.1469-7610.2010.02349.x
   Pena M, 2003, P NATL ACAD SCI USA, V100, P11702, DOI 10.1073/pnas.1934290100
   Pena M, 2012, J NEUROSCI, V32, P11159, DOI 10.1523/JNEUROSCI.6516-11.2012
   Pinker S, 2005, COGNITION, V95, P201, DOI 10.1016/j.cognition.2004.08.004
   Redcay E, 2008, BIOL PSYCHIAT, V64, P589, DOI 10.1016/j.biopsych.2008.05.020
   Rendall D, 1998, J ACOUST SOC AM, V103, P602, DOI 10.1121/1.421104
   Roberts S, 2013, INFANCY, V18, pE1, DOI 10.1111/infa.12018
   Seery A, 2014, J NEURODEV DISORD, V6, DOI 10.1186/1866-1955-6-43
   Shultz S, 2014, DEVELOPMENTAL SCI, V17, P766, DOI 10.1111/desc.12151
   Shultz S, 2010, LANG LEARN DEV, V6, P241, DOI 10.1080/15475440903507830
   Singh L, 2012, DEVELOPMENTAL SCI, V15, P482, DOI 10.1111/j.1467-7687.2012.01141.x
   Siperstein G., 1970, 3 S OR SENS PERC MOU, P313
   SPENCE MJ, 1987, INFANT BEHAV DEV, V10, P133, DOI 10.1016/0163-6383(87)90028-2
   Vouloumanos A, 2004, DEVELOPMENTAL SCI, V7, P270, DOI 10.1111/j.1467-7687.2004.00345.x
   Vouloumanos A, 2001, J COGNITIVE NEUROSCI, V13, P994, DOI 10.1162/089892901753165890
   Vouloumanos A, 2007, DEVELOPMENTAL SCI, V10, P159, DOI 10.1111/j.1467-7687.2007.00549.x
   Vouloumanos A, 2014, COGNITIVE SCI, V38, P1675, DOI 10.1111/cogs.12128
   Vouloumanos A, 2010, CHILD DEV, V81, P517, DOI 10.1111/j.1467-8624.2009.01412.x
   Vouloumanos A, 2009, P NATL ACAD SCI USA, V106, P18867, DOI 10.1073/pnas.0906049106
   WalkerAndrews AS, 1997, PSYCHOL BULL, V121, P437, DOI 10.1037/0033-2909.121.3.437
   Warlaumont AS, 2014, PSYCHOL SCI, V25, P1314, DOI 10.1177/0956797614531023
   Weikum WM, 2012, P NATL ACAD SCI USA, V109, P17221, DOI 10.1073/pnas.1121263109
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Whitehouse AJO, 2008, DEVELOPMENTAL SCI, V11, P516, DOI 10.1111/j.1467-7687.2008.00697.x
   Yau SH, 2016, DEVELOPMENTAL SCI, V19, P834, DOI 10.1111/desc.12328
   Zwaigenbaum L, 2005, INT J DEV NEUROSCI, V23, P143, DOI 10.1016/j.ijdevneu.2004.05.001
NR 61
TC 1
Z9 1
U1 0
U2 9
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0022-0965
EI 1096-0457
J9 J EXP CHILD PSYCHOL
JI J. Exp. Child Psychol.
PD FEB
PY 2019
VL 178
BP 295
EP 316
DI 10.1016/j.jecp.2018.09.011
PG 22
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA HK9XX
UT WOS:000458347300019
PM 30448530
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Watanabe, H
   Tanaka, H
   Sakti, S
   Nakamura, S
AF Watanabe, Hiroki
   Tanaka, Hiroki
   Sakti, Sakriani
   Nakamura, Satoshi
TI Neural Oscillation-Based Classification of Japanese Spoken Sentences
   During Speech Perception
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
LA English
DT Article
DE brain-computer interface; electroencephalogram (EEG); neural decoding;
   neural oscillations; phase-locking
ID BRAIN-WAVE RECOGNITION; PHASE PATTERNS
AB Brain-computer interfaces (BCIs) have been used by users to convey their intentions directly with brain signals. For example, a spelling system that uses EEGs allows letters on a display to be selected. In comparison, previous studies have investigated decoding speech information such as syllables, words from single-trial brain signals during speech comprehension, or articulatory imagination. Such decoding realizes speech recognition with a relatively short time-lag and without relying on a display. Previous magnetoencephalogram (MEG) research showed that a template matching method could be used to classify three English sentences by using phase patterns in theta oscillations. This method is based on the synchronization between speech rhythms and neural oscillations during speech processing, that is, theta oscillations synchronized with syllabic rhythms and low-gamma oscillations with phonemic rhythms. The present study aimed to approximate this classification method to a BCI application. To this end, (1) we investigated the performance of the EEG-based classification of three Japanese sentences and (2) evaluated the generalizability of our models to other different users. For the purpose of improving accuracy, (3) we investigated the performances of four classifiers: template matching (baseline), logistic regression, support vector machine, and random forest. In addition, (4) we propose using novel features including phase patterns in a higher frequency range. Our proposed features were constructed in order to capture synchronization in a low-gamma band, that is, (i) phases in EEG oscillations in the range of 2-50 Hz from all electrodes used for measuring EEG data (all) and (ii) phases selected on the basis of feature importance (selected). The classification results showed that, except for random forest, most classifiers perform similarly. Our proposed features improved the classification accuracy with statistical significance compared with a baseline feature, which is a phase pattern in neural oscillations in the range of 4-8 Hz from the right hemisphere. The best mean accuracy across folds was 55.9% using template matching trained by all features. We concluded that the use of phase information in a higher frequency band improves the performance of EEG-based sentence classification and that this model is applicable to other different users.
C1 [Watanabe, Hiroki; Tanaka, Hiroki; Sakti, Sakriani; Nakamura, Satoshi] Nara Inst Sci & Technol, Ikoma 6300192, Japan.
   [Sakti, Sakriani] RIKEN, Ctr Adv Intelligence Project AIP, Ikoma 6300192, Japan.
RP Watanabe, H (corresponding author), Nara Inst Sci & Technol, Ikoma 6300192, Japan.
EM watanabe.hiroki.vx6@is.naist.jp
FU JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [18J14871,
   16K16172, 17K00237, 17H06101]
FX Part of this work was supported by JSPS KAKENHI Grant Numbers 18J14871,
   16K16172, 17K00237, and 17H06101.
CR Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bourguignon M, 2013, HUM BRAIN MAPP, V34, P314, DOI 10.1002/hbm.21442
   Brigham Katharine, 2010, BIOINF BIOM ENG ICBB, P1, DOI [DOI 10.1109/BTAS.2010.5634515, DOI 10.1109/ICBBE.2010.5515807]
   Brumberg JS, 2010, SPEECH COMMUN, V52, P367, DOI 10.1016/j.specom.2010.01.001
   Chan AM, 2011, NEUROIMAGE, V54, P3028, DOI 10.1016/j.neuroimage.2010.10.073
   Chi X., 2011, INT J BIOELECTROMAGN, V13, P201
   Correale J, 2015, FRONT NEUROL, V6, DOI 10.3389/fneur.2015.00180
   D'Zmura M, 2009, LECT NOTES COMPUT SC, V5610, P40, DOI 10.1007/978-3-642-02574-7_5
   DaSalla CS, 2009, NEURAL NETWORKS, V22, P1334, DOI 10.1016/j.neunet.2009.05.008
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   FARWELL LA, 1988, ELECTROEN CLIN NEURO, V70, P510, DOI 10.1016/0013-4694(88)90149-6
   Fox J., 2011, R COMPANION APPL REG
   Hothorn T, 2008, BIOMETRICAL J, V50, P346, DOI 10.1002/bimj.200810425
   Howard MF, 2010, J NEUROPHYSIOL, V104, P2500, DOI 10.1152/jn.00251.2010
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Lotte F, 2007, J NEURAL ENG, V4, pR1, DOI 10.1088/1741-2560/4/2/R01
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Luo H, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00170
   Maris E, 2007, J NEUROSCI METH, V163, P161, DOI 10.1016/j.jneumeth.2007.02.011
   Meyer L, 2017, CEREB CORTEX, V27, P4293, DOI 10.1093/cercor/bhw228
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   R Core Team, 2018, R LANG ENV STAT COMP
   Suppes P, 1997, P NATL ACAD SCI USA, V94, P14965, DOI 10.1073/pnas.94.26.14965
   Suppes P, 1998, P NATL ACAD SCI USA, V95, P15861, DOI 10.1073/pnas.95.26.15861
   Watanabe H, 2017, INTERSPEECH, P2431, DOI 10.21437/Interspeech.2017-854
   Wolpaw J., 2012, BRAIN COMPUTER INTER
NR 30
TC 1
Z9 1
U1 0
U2 2
PU IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG
PI TOKYO
PA KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011,
   JAPAN
SN 1745-1361
J9 IEICE T INF SYST
JI IEICE Trans. Inf. Syst.
PD FEB
PY 2019
VL E102D
IS 2
BP 383
EP 391
DI 10.1587/transinf.2018EDP7293
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
SC Computer Science
GA HJ6OU
UT WOS:000457312000016
OA Bronze
DA 2021-02-24
ER

PT J
AU Masapollo, M
   Zhao, TC
   Franklin, L
   Morgan, JL
AF Masapollo, Matthew
   Zhao, T. Christina
   Franklin, Lauren
   Morgan, James L.
TI Asymmetric Discrimination of Nonspeech Tonal Analogues of Vowels
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE
LA English
DT Article
DE speech perception; Natural Referent Vowel framework; focal vowels;
   auditory perception; auditory cognitive science
ID SPEECH-PERCEPTION; DIRECTIONAL ASYMMETRIES; UNIVERSAL BIAS;
   REPRESENTATION; RECOGNITION; CATEGORIES; CONTEXT; MODEL; 1ST
AB Directional asymmetries reveal a universal bias in vowel perception favoring extreme vocalic articulations, which lead to acoustic vowel signals with dynamic formant trajectories and well-defined spectral prominences because of the convergence of adjacent formants. The present experiments investigated whether this bias reflects speech-specific processes or general properties of spectral processing in the auditory system. Toward this end, we examined whether analogous asymmetries in perception arise with nonspeech tonal analogues that approximate some of the dynamic and static spectral characteristics of naturally produced /u/vowels executed with more versus less extreme lip gestures. We found a qualitatively similar but weaker directional effect with 2-component tones varying in both the dynamic changes and proximity of their spectral energies. In subsequent experiments, we pinned down the phenomenon using tones that varied in 1 or both of these 2 acoustic characteristics. We found comparable asymmetries with tones that differed exclusively in their spectral dynamics, and no asymmetries with tones that differed exclusively in their spectral proximity or both spectral features. We interpret these findings as evidence that dynamic spectral changes are a critical cue for eliciting asymmetries in nonspeech tone perception, but that the potential contribution of general auditory processes to asymmetries in vowel perception is limited.
   Public Significance Statement
   The present research investigated the extent to which directional asymmetries in vowel perception may reflect general auditory processes by examining discrimination of nonspeech tones that approximate certain spectro-temporal properties of vowel sounds, but are not explicitly recognized as speech. Specifically, we examined the relative contribution of 2 key acoustic properties hypothesized to differ between vowel signals generating asymmetries in phonetic discrimination tasks: the dynamics and proximity of spectral energies. The findings demonstrate that qualitatively similar but weaker asymmetries emerge only with tones varying in their spectral dynamics. Although these findings suggest that asymmetries in nonspeech tone perception may reflect a sensitivity to dynamic changes in spectral energies, the potential role of general auditory processes on asymmetries in vowel perception is limited.
C1 [Masapollo, Matthew; Franklin, Lauren; Morgan, James L.] Brown Univ, Dept Cognit Linguist & Psychol Sci, Providence, RI 02912 USA.
   [Masapollo, Matthew] Boston Univ, Dept Speech Language & Hearing Sci, 677 Beacon St, Boston, MA 02215 USA.
   [Zhao, T. Christina] Univ Washington, Inst Learning & Brain Sci, Seattle, WA 98195 USA.
RP Masapollo, M (corresponding author), Boston Univ, Dept Speech Language & Hearing Sci, 677 Beacon St, Boston, MA 02215 USA.
EM mmasapol@bu.edu
RI Morgan, James L/A-9494-2012
FU National Institutes of Health (NIH)United States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USA [R01 HD068501];
   Ready Mind Project at the University of Washington's Institute for
   Learning and Brain Sciences; NIHUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USA [R01 DC002852];
   EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN
   DEVELOPMENTUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R01HD068501]
   Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R01DC002852,
   R01DC002852, R01DC002852, R01DC002852] Funding Source: NIH RePORTER
FX The research reported here was supported by National Institutes of
   Health (NIH) Grant R01 HD068501 (James L. Morgan, principal
   investigator) and the Ready Mind Project at the University of
   Washington's Institute for Learning and Brain Sciences. Matthew
   Masapollo was also supported by NIH Grant R01 DC002852 (Frank H.
   Guenther, principal investigator) during the preparation and revision of
   the article. We are grateful to Ellen Macaruso, Leah Mann, and Lori
   Rolfe at Brown University for assistance with subject recruitment and
   data-collection. This work benefited from helpful discussions with, or
   comments from, Linda Polka, Navin Viswanathan, Frank H. Guenther,
   Stephen Politzer-Ahles, and Elaine Kearney.
CR BEDDOR PS, 1990, J ACOUST SOC AM, V87, P2684, DOI 10.1121/1.399060
   Bohn OS, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00511
   Brancazio L, 2006, LANG SPEECH, V49, P21, DOI 10.1177/00238309060490010301
   Chistovich L. A., 1979, FRONTIERS SPEECH COM, P143
   CHISTOVICH LA, 1979, HEARING RES, V1, P185, DOI 10.1016/0378-5955(79)90012-1
   CHISTOVICH LA, 1985, J ACOUST SOC AM, V77, P789, DOI 10.1121/1.392049
   Delattre P, 1952, WORD, V8, P195, DOI 10.1080/00437956.1952.11659431
   DIEHL RL, 1991, J ACOUST SOC AM, V89, P2905, DOI 10.1121/1.400728
   Dromey C, 2013, SPEECH COMMUN, V55, P315, DOI 10.1016/j.specom.2012.09.001
   Dufour S, 2013, J PSYCHOLINGUIST RES, V42, P161, DOI 10.1007/s10936-012-9212-8
   ESCUDERO P, 2003, P 15 INT C PHON SCI, P861
   FOWLER CA, 1990, J ACOUST SOC AM, V88, P1236, DOI 10.1121/1.399701
   FOWLER CA, 1990, J EXP PSYCHOL HUMAN, V16, P742, DOI 10.1037/0096-1523.16.4.742
   Fox RA, 2011, J SPEECH LANG HEAR R, V54, P1667, DOI 10.1044/1092-4388(2011/09-0279)
   GRIER JB, 1971, PSYCHOL BULL, V75, P424, DOI 10.1037/h0031246
   Hillenbrand JM, 2011, J ACOUST SOC AM, V129, P3991, DOI 10.1121/1.3573980
   Holt LL, 2005, PSYCHOL SCI, V16, P305, DOI 10.1111/j.0956-7976.2005.01532.x
   Holt LL, 2000, J ACOUST SOC AM, V108, P710, DOI 10.1121/1.429604
   Kent R.D, 2002, ACOUSTIC ANAL SPEECH
   Kriengwatana BP, 2017, J SPEECH LANG HEAR R, V60, P1088, DOI 10.1044/2016_JSLHR-H-16-0050
   Kuhl PK, 2014, P NATL ACAD SCI USA, V111, P11238, DOI 10.1073/pnas.1410963111
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Lee J, 2016, J ACOUST SOC AM, V139, P426, DOI 10.1121/1.4939894
   Lotto AJ, 1998, PERCEPT PSYCHOPHYS, V60, P602, DOI 10.3758/BF03206049
   MacLeod AAN, 2009, J PHONETICS, V37, P374, DOI 10.1016/j.wocn.2009.07.001
   Marion V, 2007, J SPEECH LANG HEAR R, V50, P940, DOI 10.1044/1092-4388(2007/067)
   Masapollo M, 2018, ASYMMETRIES UN UNPUB
   Masapollo M, 2018, J EXP PSYCHOL HUMAN, V44, P1103, DOI 10.1037/xhp0000518
   Masapollo M, 2017, COGNITION, V166, P358, DOI 10.1016/j.cognition.2017.06.001
   Masapollo M, 2017, J ACOUST SOC AM, V141, P2857, DOI 10.1121/1.4981006
   Medin D. L, 1987, CATEGORICAL PERCEPTI
   Mefferd AS, 2016, J ACOUST SOC AM, V140, P3728, DOI 10.1121/1.4967446
   Mefferd AS, 2010, J SPEECH LANG HEAR R, V53, P1206, DOI 10.1044/1092-4388(2010/09-0083)
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Morrison G., 2013, VOWEL INHERENT SPECT, P9, DOI DOI 10.1007/978-3-642-14209-3_2
   Noiray A, 2011, J ACOUST SOC AM, V129, P340, DOI 10.1121/1.3518452
   Poeppel D, 2011, LANG COGNITIVE PROC, V26, P935, DOI 10.1080/01690965.2010.493301
   Polka L, 2003, SPEECH COMMUN, V41, P221, DOI 10.1016/S0167-6393(02)00105-X
   Polka L, 2018, UNDERSTANDING UNPUB
   Polka L, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00941
   Polka L, 2011, J PHONETICS, V39, P467, DOI 10.1016/j.wocn.2010.08.007
   Pons F, 2012, CHILD DEV, V83, P965, DOI 10.1111/j.1467-8624.2012.01740.x
   R Core Team, 2013, R LANG ENV STAT COMP
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   REPP BH, 1979, J EXP PSYCHOL HUMAN, V5, P129, DOI 10.1037/0096-1523.5.1.129
   ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P532, DOI 10.1016/0010-0285(75)90021-3
   Schwartz JL, 2005, SPEECH COMMUN, V45, P425, DOI 10.1016/j.specom.2004.12.001
   SCHWARTZ JL, 1989, SPEECH COMMUN, V8, P235, DOI 10.1016/0167-6393(89)90004-6
   Schwartz JL, 1997, J PHONETICS, V25, P255, DOI 10.1006/jpho.1997.0043
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Stevens K. N., 1999, ACOUSTIC PHONETICS
   STRANGE W, 1989, J ACOUST SOC AM, V85, P2081, DOI 10.1121/1.397860
   Strange W, 2011, J PHONETICS, V39, P456, DOI 10.1016/j.wocn.2010.09.001
   SWOBODA PJ, 1978, CHILD DEV, V49, P332, DOI 10.1111/j.1467-8624.1978.tb02320.x
   SYRDAL AK, 1986, J ACOUST SOC AM, V79, P1086, DOI 10.1121/1.393381
   Tsuji S, 2017, INTERSPEECH, P2108, DOI 10.21437/Interspeech.2017-1468
   Tyler MD, 2014, PHONETICA, V71, P4, DOI 10.1159/000356237
   Viswanathan N, 2014, J EXP PSYCHOL HUMAN, V40, P1228, DOI 10.1037/a0036214
   Viswanathan N, 2009, PSYCHON B REV, V16, P74, DOI 10.3758/PBR.16.1.74
   WERKER JF, 1985, PERCEPT PSYCHOPHYS, V37, P35, DOI 10.3758/BF03207136
NR 61
TC 2
Z9 2
U1 0
U2 2
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0096-1523
EI 1939-1277
J9 J EXP PSYCHOL HUMAN
JI J. Exp. Psychol.-Hum. Percept. Perform.
PD FEB
PY 2019
VL 45
IS 2
BP 285
EP 300
DI 10.1037/xhp0000603
PG 16
WC Psychology; Psychology, Experimental
SC Psychology
GA HJ5XG
UT WOS:000457256000009
PM 30570319
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Venker, CE
AF Venker, Courtney E.
TI Cross-situational and ostensive word learning in children with and
   without autism spectrum disorder
SO COGNITION
LA English
DT Article
DE Cross-situational learning; Word learning; Fast mapping; Statistical
   learning; Autism spectrum disorder; Language development
ID DEVELOPMENTAL-DISABILITIES; COMMUNICATIVE DEVELOPMENT;
   SPEECH-PERCEPTION; INFANTS; LANGUAGE; RECOGNITION; CONSTRAINTS;
   ATTENTION
AB Numerous experimental studies have shown that infants and children can discover word meanings by using co-occurrences between labels and objects across individually ambiguous contexts a phenomenon known as cross situational learning. Like typically developing children, high-functioning school aged children with autism spectrum disorder (ASD) are capable of cross-situational learning. However, it is not yet clear whether cross situational learning is similarly available to children with ASD who are younger and show a broader range of language and cognitive abilities. Using eye-tracking methodology, the current study provided the first evidence that preschool and early school-aged children with ASD can rely on cross-situational statistics to learn new words. In fact, children with ASD learned as well as typically developing children with similar vocabulary knowledge. In both groups, the children with the highest cross-situational learning accuracy were those who showed the best familiar word processing skills. Surprisingly, children in both groups learned words equally well in the cross-situational task and an ostensive word-learning task, which presented only a single label-object pairing at a time. In combination, these results point to similarities in the word learning abilities available to typically developing children and children with ASD.
C1 [Venker, Courtney E.] Univ Wisconsin, Waisman Ctr, Madison, WI 53706 USA.
   [Venker, Courtney E.] Michigan State Univ, E Lansing, MI 48824 USA.
RP Venker, CE (corresponding author), Dept Commun Sci & Disorders, 1026 Red Cedar Rd,Room 216, E Lansing, MI 48824 USA.; Venker, CE (corresponding author), Michigan State Univ, E Lansing, MI 48824 USA.
EM cvenker@msu.edu
FU Friends of the Waisman Center [F31DC012451, R01DC011750, R37HD037466,
   P30HD003352]; Wisconsin Speech-Language Pathology and Audiology
   Association; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH &
   HUMAN DEVELOPMENTUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [R37HD037466, R37HD037466] Funding Source: NIH RePORTER; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [R01DC011750, R01DC012513, R01DC012513] Funding Source: NIH
   RePORTER
FX Thanks also to our funding sources. This work was supported by
   F31DC012451 (Venker, PI), R01DC011750 (Ellis Weismer & Kaushanskaya,
   PIs), R37HD037466 (Saffran, PI), P30HD003352 (Mailick, PI), the Friends
   of the Waisman Center, and the Wisconsin Speech-Language Pathology and
   Audiology Association. These funding sources had no direct involvement
   in the study design, data collection or analysis, manuscript writing, or
   decision to submit the article for publication.
CR Alt M, 2014, J COMMUN DISORD, V52, P207, DOI 10.1016/j.jcomdis.2014.07.002
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   Arunachalam S, 2016, AUTISM RES, V9, P810, DOI 10.1002/aur.1590
   Bebko JM, 2006, J CHILD PSYCHOL PSYC, V47, P88, DOI 10.1111/j.1469-7610.2005.01443.x
   Charman T, 2003, J CHILD LANG, V30, P213, DOI 10.1017/S0305000902005482
   Christensen DL, 2016, MMWR SURVEILL SUMM, V65, P1, DOI 10.15585/mmwr.ss6503a1
   de Marchena A, 2011, COGNITION, V119, P96, DOI 10.1016/j.cognition.2010.12.011
   Dunn L., 2006, PEABODY PICTURE VOCA
   Fernald A, 2008, DEVELOPMENTAL PSYCHOLINGUISTICS: ON-LINE METHODS IN CHILDREN'S LANGUAGE PROCESSING, P97
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   Frank MC, 2013, LANG LEARN DEV, V9, P1, DOI 10.1080/15475441.2012.707101
   Frank MC, 2009, PSYCHOL SCI, V20, P578, DOI 10.1111/j.1467-9280.2009.02335.x
   Gotham K, 2009, J AUTISM DEV DISORD, V39, P693, DOI 10.1007/s10803-008-0674-3
   Grossman R. B., 2015, GAZE PATTERNS IMPLIC, V8, P583, DOI [10.1002/aur.1474.Replication, DOI 10.1002/AUR.1474.REPLICATION]
   Grossman RB, 2009, J CHILD PSYCHOL PSYC, V50, P491, DOI 10.1111/j.1469-7610.2008.02002.x
   Iarocci G, 2006, J AUTISM DEV DISORD, V36, P77, DOI 10.1007/s10803-005-0044-3
   Irwin J. R., 2012, CHILD DEV, V29, P997, DOI [10.1016/j.biotechadv.2011.08.021.Secreted, DOI 10.1016/J.BIOTECHADV.2011.08.021.SECRETED]
   Keehn B, 2013, NEUROSCI BIOBEHAV R, V37, P164, DOI 10.1016/j.neubiorev.2012.11.014
   Kucker SC, 2015, CHILD DEV PERSPECT, V9, P74, DOI 10.1111/cdep.12110
   Lord C., 2012, AUTISM DIAGNOSTIC 1
   Luyster R, 2007, J CHILD LANG, V34, P623, DOI 10.1017/S0305000907008094
   Luyster R, 2009, DEV PSYCHOL, V45, P1774, DOI 10.1037/a0016223
   MacDonald K, 2017, COGNITIVE PSYCHOL, V94, P67, DOI 10.1016/j.cogpsych.2017.02.003
   Mahr T, 2015, COGNITION, V142, P345, DOI 10.1016/j.cognition.2015.05.009
   Mayo J, 2012, J AUTISM DEV DISORD, V42, P2476, DOI 10.1007/s10803-012-1493-0
   McDuffie A, 2013, J AUTISM DEV DISORD, V43, P1676, DOI 10.1007/s10803-012-1717-3
   McGregor KK, 2013, J CHILD PSYCHOL PSYC, V54, P745, DOI 10.1111/jcpp.12073
   Medina TN, 2011, P NATL ACAD SCI USA, V108, P9014, DOI 10.1073/pnas.1105040108
   Naigles LR, 2011, AUTISM RES, V4, P422, DOI 10.1002/aur.223
   Quine W.V., 1960, WORD OBJECT
   Roid G. H., 2002, LEITER INT PERFORMAN
   Rutter M., 2003, SOCIAL COMMUNICATION
   Smith K., 2009, P 31 ANN C COGN SCI, P2711
   Smith L, 2008, COGNITION, V106, P1558, DOI 10.1016/j.cognition.2007.06.010
   Smith LB, 2013, LANG LEARN DEV, V9, P25, DOI 10.1080/15475441.2012.707104
   Stevenson RA, 2014, J AUTISM DEV DISORD, V44, P1470, DOI 10.1007/s10803-013-1992-7
   Suanda SH, 2014, J EXP CHILD PSYCHOL, V126, P395, DOI 10.1016/j.jecp.2014.06.003
   Suanda SH, 2012, COGNITIVE SCI, V36, P545, DOI 10.1111/j.1551-6709.2011.01218.x
   Tek S, 2008, AUTISM RES, V1, P208, DOI 10.1002/aur.38
   Tenenbaum EJ, 2017, J AUTISM DEV DISORD, V47, P1791, DOI 10.1007/s10803-017-3098-0
   Trueswell JC, 2013, COGNITIVE PSYCHOL, V66, P126, DOI 10.1016/j.cogpsych.2012.10.001
   Venker CE, 2017, AUTISM, V21, P821, DOI 10.1177/1362361316653230
   Venker CE, 2016, J AUTISM DEV DISORD, V46, P1118, DOI 10.1007/s10803-015-2644-x
   Vitevitch MS, 2004, BEHAV RES METH INS C, V36, P481, DOI 10.3758/BF03195594
   Vlach HA, 2013, COGNITION, V127, P375, DOI 10.1016/j.cognition.2013.02.015
   Vouloumanos A, 2009, DEV PSYCHOL, V45, P1611, DOI 10.1037/a0016134
   Wass SV, 2013, BEHAV RES METHODS, V45, P229, DOI 10.3758/s13428-012-0245-6
   Woodard K, 2016, LANG LEARN DEV, V12, P252, DOI 10.1080/15475441.2016.1140581
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
   Yu C, 2007, PSYCHOL SCI, V18, P414, DOI 10.1111/j.1467-9280.2007.01915.x
   Yu C, 2012, PSYCHOL REV, V119, P21, DOI 10.1037/a0026182
   Yu C, 2011, DEVELOPMENTAL SCI, V14, P165, DOI 10.1111/j.1467-7687.2010.00958.x
   Yurovsky D, 2015, COGNITION, V145, P53, DOI 10.1016/j.cognition.2015.07.013
   Zettersten M, 2018, J MEM LANG, V99, P62, DOI 10.1016/j.jml.2017.11.001
NR 54
TC 4
Z9 4
U1 5
U2 12
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD FEB
PY 2019
VL 183
BP 181
EP 191
DI 10.1016/j.cognition.2018.10.025
PG 11
WC Psychology, Experimental
SC Psychology
GA HI7MP
UT WOS:000456640600012
PM 30468980
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Venezia, JH
   Thurman, SM
   Richards, VM
   Hickok, G
AF Venezia, Jonathan H.
   Thurman, Steven M.
   Richards, Virginia M.
   Hickok, Gregory
TI Hierarchy of speech-driven spectrotemporal receptive fields in human
   auditory cortex
SO NEUROIMAGE
LA English
DT Article
DE Speech perception; Spectrotemporal modulations; fMRI; Bubbles;
   Classification images
ID SUPERIOR TEMPORAL GYRUS; INTELLIGIBLE SPEECH; FUNCTIONAL-ORGANIZATION;
   CORTICAL REPRESENTATION; REPETITIVE TRANSIENTS; RESPONSE PROPERTIES;
   NEURAL RESPONSES; SINGLE NEURONS; BELT CORTEX; MACAQUE
AB Existing data indicate that cortical speech processing is hierarchically organized. Numerous studies have shown that early auditory areas encode fine acoustic details while later areas encode abstracted speech patterns. However, it remains unclear precisely what speech information is encoded across these hierarchical levels. Estimation of speech-driven spectrotemporal receptive fields (STRFs) provides a means to explore cortical speech processing in terms of acoustic or linguistic information associated with characteristic spectrotemporal patterns. Here, we estimate STRFs from cortical responses to continuous speech in fMRI. Using a novel approach based on filtering randomly-selected spectrotemporal modulations (STMs) from aurally-presented sentences, STRFs were estimated for a group of listeners and categorized using a data-driven clustering algorithm. 'Behavioral STRFs' highlighting STMs crucial for speech recognition were derived from intelligibility judgments. Clustering revealed that STRFs in the supratemporal plane represented a broad range of STMs, while STRFs in the lateral temporal lobe represented circumscribed STM patterns important to intelligibility. Detailed analysis recovered a bilateral organization with posterior-lateral regions preferentially processing STMs associated with phonological information and anterior-lateral regions preferentially processing STMs associated with word- and phrase-level information. Regions in lateral Heschl's gyrus preferentially processed STMs associated with vocalic information (pitch).
C1 [Venezia, Jonathan H.] VA Loma Linda Healthcare Syst, Loma Linda, CA USA.
   [Venezia, Jonathan H.] Loma Linda Univ, Sch Med, Dept Otolaryngol, Loma Linda, CA USA.
   [Thurman, Steven M.] US Army Res Lab, Aberdeen Proving Ground, MD USA.
   [Richards, Virginia M.; Hickok, Gregory] Univ Calif Irvine, Dept Cognit Sci, Irvine, CA 92717 USA.
   [Richards, Virginia M.; Hickok, Gregory] Univ Calif Irvine, Dept Language Sci, Irvine, CA USA.
RP Venezia, JH (corresponding author), 11201 Benton St, Loma Linda, CA 92357 USA.
EM jonathan.venezia@va.go
RI Venezia, Jonathan/AAD-1296-2019
FU National Institute on Deafness and Other Communication DisordersUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R21 DC013406, R01 DC03681]; National
   Institute on Deafness and Other Communication Disorders via the
   University of California, Irvine, CA, USA [R01 DC000626, T32 DC010775];
   VA Loma Linda Healthcare System, Loma Linda, CA; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [T32DC010775, T32DC010775, T32DC010775] Funding Source: NIH RePORTER
FX Research reported in this publication was supported by the National
   Institute on Deafness and Other Communication Disorders under Award
   Numbers R21 DC013406 (MPIs: VMR and Yi Shen) and R01 DC03681 (PI: GH).
   During this investigation, JHV was supported by the National Institute
   on Deafness and Other Communication Disorders under Award Numbers R01
   DC000626 (PI: Marjorie R. Leek) and T32 DC010775 (via the University of
   California, Irvine, CA, USA). The content is solely the responsibility
   of the authors and does not necessarily represent the official views of
   the National Institutes of Health. This material is the result of work
   supported with resources and the use of facilities at the VA Loma Linda
   Healthcare System, Loma Linda, CA. The contents do not represent the
   views of the U.S. Department of Veterans Affairs or the United States
   Government. The views and conclusions contained in this document are
   those of the authors and should not be interpreted as representing the
   official policies, either expressed or implied, of the Army Research
   Laboratory or the US Government. Borja Sanchez and Allison-Graham Martin
   performed quality control on the imaging data as undergraduate research
   assistants at the University of California, Irvine.
CR [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   Barton B, 2012, P NATL ACAD SCI USA, V109, P20738, DOI 10.1073/pnas.1213381109
   Bendor D, 2008, J NEUROPHYSIOL, V100, P888, DOI 10.1152/jn.00884.2007
   Bendor D, 2006, CURR OPIN NEUROBIOL, V16, P391, DOI 10.1016/j.conb.2006.07.001
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bernasconi F, 2011, INT J PSYCHOPHYSIOL, V79, P244, DOI 10.1016/j.ijpsycho.2010.10.017
   Bernasconi F, 2010, NEUROPSYCHOLOGIA, V48, P2579, DOI 10.1016/j.neuropsychologia.2010.05.004
   Berner LA, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00395
   Bieser A, 1996, EXP BRAIN RES, V108, P273
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   Bitterman Y, 2008, NATURE, V451, P197, DOI 10.1038/nature06476
   Bizley JK, 2013, NAT REV NEUROSCI, V14, P693, DOI 10.1038/nrn3565
   Bizley JK, 2009, J NEUROSCI, V29, P2064, DOI 10.1523/JNEUROSCI.4755-08.2009
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   Bornkessel-Schlesewsky I, 2015, TRENDS COGN SCI, V19, P142, DOI 10.1016/j.tics.2014.12.008
   BRUGGE JF, 1973, J NEUROPHYSIOL, V36, P1138
   Brugge JF, 2008, HEARING RES, V238, P12, DOI 10.1016/j.heares.2007.11.012
   Brugge JF, 2009, J NEUROPHYSIOL, V102, P2358, DOI 10.1152/jn.91346.2008
   Camalier CR, 2012, P NATL ACAD SCI USA, V109, P18168, DOI 10.1073/pnas.1206387109
   Chevillet M, 2011, J NEUROSCI, V31, P9345, DOI 10.1523/JNEUROSCI.1448-11.2011
   Chi T, 2005, J ACOUST SOC AM, V118, P887, DOI 10.1121/1.1945807
   Chi TS, 1999, J ACOUST SOC AM, V106, P2719, DOI 10.1121/1.428100
   Christoffels IK, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018307
   Coutanche MN, 2013, COGN AFFECT BEHAV NE, V13, P667, DOI 10.3758/s13415-013-0186-2
   Cox RW, 2012, NEUROIMAGE, V62, P743, DOI 10.1016/j.neuroimage.2011.08.056
   Davis MH, 2003, J NEUROSCI, V23, P3423
   De Angelis V, 2018, NEUROIMAGE, V180, P291, DOI 10.1016/j.neuroimage.2017.11.020
   de Heer WA, 2017, J NEUROSCI, V37, P6539, DOI 10.1523/JNEUROSCI.3267-16.2017
   de la Mothe LA, 2006, J COMP NEUROL, V496, P27, DOI 10.1002/cne.20923
   Destrieux C, 2010, NEUROIMAGE, V53, P1, DOI 10.1016/j.neuroimage.2010.06.010
   Ding N, 2012, J NEUROPHYSIOL, V107, P78, DOI 10.1152/jn.00297.2011
   Eklund A, 2016, P NATL ACAD SCI USA, V113, P7900, DOI 10.1073/pnas.1602413113
   Elliott TM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000302
   Evans S, 2014, CEREB CORTEX, V24, P2350, DOI 10.1093/cercor/bht083
   Evans S, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00041
   Evans S, 2015, CEREB CORTEX, V25, P4772, DOI 10.1093/cercor/bhv136
   Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1
   Fischl B, 2012, NEUROIMAGE, V62, P774, DOI 10.1016/j.neuroimage.2012.01.021
   Formisano E, 2008, SCIENCE, V322, P970, DOI 10.1126/science.1164318
   Foxe JJ, 2005, NEUROREPORT, V16, P419, DOI 10.1097/00001756-200504040-00001
   Giraud AL, 2007, NEURON, V56, P1127, DOI 10.1016/j.neuron.2007.09.038
   Gosselin F, 2001, VISION RES, V41, P2261, DOI 10.1016/S0042-6989(01)00097-9
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   Griffiths TD, 2004, NAT REV NEUROSCI, V5, P887, DOI 10.1038/nrn1538
   Griffiths TD, 2003, ANN NY ACAD SCI, V999, P40, DOI 10.1196/annals.1284.004
   Guenther FH, 2006, J COMMUN DISORD, V39, P350, DOI 10.1016/j.jcomdis.2006.06.013
   Hackett TA, 1998, J COMP NEUROL, V394, P475, DOI 10.1002/(SICI)1096-9861(19980518)394:4<475::AID-CNE6>3.0.CO;2-Z
   Hackett TA, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00072
   Hackett TA, 2011, HEARING RES, V271, P133, DOI 10.1016/j.heares.2010.01.011
   Hagler DJ, 2006, NEUROIMAGE, V33, P1093, DOI 10.1016/j.neuroimage.2006.07.036
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Hilgetag CC, 2000, PHILOS T R SOC B, V355, P71, DOI 10.1098/rstb.2000.0550
   Holdgraf CR, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13654
   Howard MA, 2000, J COMP NEUROL, V416, P79, DOI 10.1002/(SICI)1096-9861(20000103)416:1<79::AID-CNE6>3.0.CO;2-2
   Hullett PW, 2016, J NEUROSCI, V36, P2014, DOI 10.1523/JNEUROSCI.1779-15.2016
   Humphries C, 2005, HUM BRAIN MAPP, V26, P128, DOI 10.1002/hbm.20148
   Jancke L, 2002, NEUROIMAGE, V15, P733, DOI 10.1006/nimg.2001.1027
   Joosten E.R.M., 2012, BIOL CYBERN, P1
   Kaas JH, 2000, P NATL ACAD SCI USA, V97, P11793, DOI 10.1073/pnas.97.22.11793
   Kaas JH, 1998, AUDIOL NEURO-OTOL, V3, P73, DOI 10.1159/000013783
   Kikuchi Y, 2010, J NEUROSCI, V30, P13021, DOI 10.1523/JNEUROSCI.2267-10.2010
   Kleiner M, 2007, PERCEPTION, V36, P14
   Kowalski N, 1996, J NEUROPHYSIOL, V76, P3503
   Kuhn HW, 1955, NAV RES LOG, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]
   Kusmierek P, 2009, J NEUROPHYSIOL, V102, P1606, DOI 10.1152/jn.00167.2009
   Lakatos P, 2005, NEUROREPORT, V16, P933, DOI 10.1097/00001756-200506210-00011
   Lalor EC, 2010, EUR J NEUROSCI, V31, P189, DOI 10.1111/j.1460-9568.2009.07055.x
   Leaver AM, 2010, J NEUROSCI, V30, P7604, DOI 10.1523/JNEUROSCI.0296-10.2010
   Liang L, 2002, J NEUROPHYSIOL, V87, P2237, DOI 10.1152/jn.2002.87.5.2237
   Liebenthal E, 2005, CEREB CORTEX, V15, P1621, DOI 10.1093/cercor/bhi040
   LIEGEOISCHAUVEL C, 1994, ELECTROEN CLIN NEURO, V92, P204, DOI 10.1016/0168-5597(94)90064-7
   LIEGEOISCHAUVEL C, 1991, BRAIN, V114, P139
   Luke SG, 2017, BEHAV RES METHODS, V49, P1494, DOI 10.3758/s13428-016-0809-y
   McGettigan C, 2012, J COGNITIVE NEUROSCI, V24, P636, DOI 10.1162/jocn_a_00161
   McLachlan G., 2004, FINITE MIXTURE MODEL
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   Miller LM, 2002, J NEUROPHYSIOL, V87, P516, DOI 10.1152/jn.00395.2001
   Moerel M, 2012, J NEUROSCI, V32, P14205, DOI 10.1523/JNEUROSCI.1388-12.2012
   Mumford JA, 2012, NEUROIMAGE, V59, P2636, DOI 10.1016/j.neuroimage.2011.08.076
   Narain C, 2003, CEREB CORTEX, V13, P1362, DOI 10.1093/cercor/bhg083
   Naselaris T, 2011, NEUROIMAGE, V56, P400, DOI 10.1016/j.neuroimage.2010.07.073
   Neri P, 2010, FRONT COMPUT NEUROSC, V4, DOI 10.3389/fncom.2010.00151
   Neri P, 2008, J NEUROPHYSIOL, V100, P3117, DOI 10.1152/jn.90271.2008
   Nourski K. V., 2012, CEREB CORTEX, V24, P340
   Nourski KV, 2014, NEUROIMAGE, V101, P598, DOI 10.1016/j.neuroimage.2014.07.004
   Nourski KV, 2013, J NEUROPHYSIOL, V109, P1283, DOI 10.1152/jn.00718.2012
   Okada K, 2010, CEREB CORTEX, V20, P2486, DOI 10.1093/cercor/bhp318
   Oosterhof NN, 2011, NEUROIMAGE, V56, P593, DOI 10.1016/j.neuroimage.2010.04.270
   Overath T, 2015, NAT NEUROSCI, V18, P903, DOI 10.1038/nn.4021
   Pasley BN, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001251
   Peelle JE, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00309
   Peelle JE, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00051
   Penagos H, 2004, J NEUROSCI, V24, P6810, DOI 10.1523/JNEUROSCI.0383-04.2004
   Perrachione TK, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00055
   Petersen S E, 1989, J Cogn Neurosci, V1, P153, DOI 10.1162/jocn.1989.1.2.153
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Poeppel D, 2012, J NEUROSCI, V32, P14125, DOI 10.1523/JNEUROSCI.3244-12.2012
   Price C, 2005, TRENDS COGN SCI, V9, P271, DOI 10.1016/j.tics.2005.03.009
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Rauschecker JP, 1997, J COMP NEUROL, V382, P89
   Rauschecker JP, 2004, J NEUROPHYSIOL, V91, P2578, DOI 10.1152/jn.00834.2003
   RAUSCHECKER JP, 1995, SCIENCE, V268, P111, DOI 10.1126/science.7701330
   Rauschecker JP, 1998, CURR OPIN NEUROBIOL, V8, P516, DOI 10.1016/S0959-4388(98)80040-8
   Recanzone GH, 2000, J NEUROPHYSIOL, V83, P2315
   Reddy CG, 2010, J NEUROSURG, V112, P1301, DOI 10.3171/2009.7.JNS09404
   Riesenhuber M, 2002, CURR OPIN NEUROBIOL, V12, P162, DOI 10.1016/S0959-4388(02)00304-5
   Rogalsky C, 2009, CEREB CORTEX, V19, P786, DOI 10.1093/cercor/bhn126
   Saad ZS, 2012, NEUROIMAGE, V62, P768, DOI 10.1016/j.neuroimage.2011.09.016
   Santoro R, 2017, P NATL ACAD SCI USA, V114, P4799, DOI 10.1073/pnas.1617622114
   Santoro R, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003412
   Schonwiesner M, 2009, P NATL ACAD SCI USA, V106, P14611, DOI 10.1073/pnas.0907682106
   SCHREINER CE, 1988, HEARING RES, V32, P49, DOI 10.1016/0378-5955(88)90146-3
   Scott BH, 2011, J NEUROPHYSIOL, V105, P712, DOI 10.1152/jn.01120.2009
   Scott SK, 2003, SPEECH COMMUN, V41, P23, DOI 10.1016/S0167-6393(02)00090-0
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   Scott SK, 2000, BRAIN, V123, P2400, DOI 10.1093/brain/123.12.2400
   Scott SK, 2006, J ACOUST SOC AM, V120, P1075, DOI 10.1121/1.2216725
   Scrucca L, 2016, R J, V8, P289
   Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104
   Shamma S, 2001, TRENDS COGN SCI, V5, P340, DOI 10.1016/S1364-6613(00)01704-6
   Singmann H, 2017, NEW METHODS NEUROSCI
   Smith FW, 2008, NEUROIMAGE, V40, P1643, DOI 10.1016/j.neuroimage.2008.01.029
   Specht K, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00629
   Specht K, 2009, HUM BRAIN MAPP, V30, P3436, DOI 10.1002/hbm.20768
   Tang C, 2017, SCIENCE, V357, P797, DOI 10.1126/science.aam8577
   Theunissen FE, 2014, NAT REV NEUROSCI, V15, P355, DOI 10.1038/nrn3731
   Town SM, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00088
   Vaden KI, 2010, NEUROIMAGE, V49, P1018, DOI 10.1016/j.neuroimage.2009.07.063
   van de Ven V, 2009, NEUROIMAGE, V47, P1982, DOI 10.1016/j.neuroimage.2009.05.057
   Venezia JH, 2016, J ACOUST SOC AM, V140, P1072, DOI 10.1121/1.4960544
   Wessinger CM, 2001, J COGNITIVE NEUROSCI, V13, P1, DOI 10.1162/089892901564108
   Wilson SM, 2014, J COGNITIVE NEUROSCI, V26, P970, DOI 10.1162/jocn_a_00550
   Woods DL, 2010, FRONT SYST NEUROSCI, V4, DOI 10.3389/fnsys.2010.00155
   Woolley SMN, 2005, NAT NEUROSCI, V8, P1371, DOI 10.1038/nn1536
   Zatorre RJ, 2001, CEREB CORTEX, V11, P946, DOI 10.1093/cercor/11.10.946
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
NR 140
TC 3
Z9 3
U1 1
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD FEB 1
PY 2019
VL 186
BP 647
EP 666
DI 10.1016/j.neuroimage.2018.11.049
PG 20
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA HH8FX
UT WOS:000455968400059
PM 30500424
OA Green Accepted, Green Published
DA 2021-02-24
ER

PT J
AU Peiffer-Smadja, N
   Cohen, L
AF Peiffer-Smadja, Nathan
   Cohen, Laurent
TI The cerebral bases of the bouba-kiki effect
SO NEUROIMAGE
LA English
DT Article
DE Crossmodal; Speech perception; Shape; Language; fMRI
ID SOUND-SHAPE CORRESPONDENCES; MULTISENSORY INTEGRATION; NEURAL BASIS;
   CROSSMODAL CORRESPONDENCE; SPEECH; SYNESTHESIA; SYMBOLISM; PITCH;
   INFORMATION; RESPONSES
AB The crossmodal correspondence between some speech sounds and some geometrical shapes, known as the bouba-kiki (BK) effect, constitutes a remarkable exception to the general arbitrariness of the links between word meaning and word sounds. We have analyzed the association of shapes and sounds in order to determine whether it occurs at a perceptual or at a decisional level, and whether it takes place in sensory cortices or in supramodal regions. First, using an Implicit Association Test (IAT), we have shown that the BK effect may occur without participants making any explicit decision relative to sound-shape associations. Second, looking for the brain correlates of implicit BK matching, we have found that intermodal matching influences activations in both auditory and visual sensory cortices. Moreover, we found stronger prefrontal activation to mismatching than to matching stimuli, presumably reflecting a modulation of executive processes by crossmodal correspondence. Thus, through its roots in the physiology of object categorization and crossmodal matching, the BK effect provides a unique insight into some non-linguistic components of word formation.
C1 [Peiffer-Smadja, Nathan; Cohen, Laurent] Sorbonne Univ, CNRS, Inst Cerveau & Moelle Epiniere, ICM,INSERM,U 1127,UMR 7225, F-75013 Paris, France.
   [Cohen, Laurent] Hop La Pitie Salpetriere, AP HP, Dept Neurol 1, F-75013 Paris, France.
RP Cohen, L (corresponding author), Inst Cerveau & Moelle Epiniere, 47 Blvd Hop, F-75013 Paris, France.
EM laurentcohen2@gmail.com
OI Peiffer-Smadja, Nathan/0000-0003-1166-1958
FU "Investissements d'avenir" program of the French National Research
   AgencyFrench National Research Agency (ANR) [ANR-10-IAIHU-06]
FX This work was supported by the "Investissements d'avenir" program of the
   French National Research Agency (ANR-10-IAIHU-06; to the Brain and Spine
   Institute).
CR Alais D, 2010, SEEING PERCEIVING, V23, P3, DOI 10.1163/187847510X488603
   Alsius A, 2018, MULTISENS RES, V31, P111, DOI 10.1163/22134808-00002565
   Bien N, 2012, NEUROIMAGE, V59, P663, DOI 10.1016/j.neuroimage.2011.06.095
   Bisley JW, 2011, J PHYSIOL-LONDON, V589, P49, DOI 10.1113/jphysiol.2010.192666
   Bizley JK, 2016, TRENDS NEUROSCI, V39, P74, DOI 10.1016/j.tins.2015.12.007
   Bremner AJ, 2013, COGNITION, V126, P165, DOI 10.1016/j.cognition.2012.09.007
   Calvert GA, 2001, CEREB CORTEX, V11, P1110, DOI 10.1093/cercor/11.12.1110
   Chen YC, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00445
   Chen YC, 2016, SCI REP-UK, V6, DOI 10.1038/srep26681
   Cheng YR, 2019, PROTEIN CELL, V10, P295, DOI 10.1007/s13238-018-0529-4
   Chiou R, 2012, PERCEPTION, V41, P339, DOI 10.1068/p7161
   Cuskley C, 2017, PSYCHOL RES-PSYCH FO, V81, P119, DOI 10.1007/s00426-015-0709-2
   D'Onofrio A, 2014, LANG SPEECH, V57, P367, DOI 10.1177/0023830913507694
   Deroy O, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0207
   Deroy O, 2013, PSYCHON B REV, V20, P643, DOI 10.3758/s13423-013-0387-2
   Diehl MM, 2014, J NEUROSCI, V34, P11233, DOI 10.1523/JNEUROSCI.5168-13.2014
   Evans KK, 2010, J VISION, V10, DOI 10.1167/10.1.6
   Faivre N, 2014, PSYCHOL SCI, V25, P2006, DOI 10.1177/0956797614547916
   Fort M, 2015, LANG SPEECH, V58, P247, DOI 10.1177/0023830914534951
   Freedman DJ, 2003, J NEUROSCI, V23, P5235
   Friston KJ, 2006, NEUROIMAGE, V30, P1077, DOI 10.1016/j.neuroimage.2005.08.012
   Gallace A, 2006, PERCEPT PSYCHOPHYS, V68, P1191, DOI 10.3758/BF03193720
   Getz LM, 2018, COGNITION, V175, P101, DOI 10.1016/j.cognition.2018.02.015
   Ghazanfar AA, 2006, TRENDS COGN SCI, V10, P278, DOI 10.1016/j.tics.2006.04.008
   Greenwald AG, 1998, J PERS SOC PSYCHOL, V74, P1464, DOI 10.1037/0022-3514.74.6.1464
   Greenwald AG, 2017, AM PSYCHOL, V72, P861, DOI 10.1037/amp0000238
   Hein G, 2007, J NEUROSCI, V27, P7881, DOI 10.1523/JNEUROSCI.1740-07.2007
   Kilian-Hutten N, 2017, INNOVAT COGNIT NEURO, P105, DOI 10.1007/978-1-4939-7325-5_6
   Knoeferle K, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05965-y
   Kohler W., 1947, GESTALT PSYCHOL INTR
   Kohler Woldgang, 1929, GESTALT PSYCHOL
   Kriegeskorte N, 2009, NAT NEUROSCI, V12, P535, DOI 10.1038/nn.2303
   Lacey S, 2016, EUR J NEUROSCI, V44, P2716, DOI 10.1111/ejn.13381
   Li S, 2009, NEURON, V62, P441, DOI 10.1016/j.neuron.2009.03.016
   Martino G, 2001, CURR DIR PSYCHOL SCI, V10, P61, DOI 10.1111/1467-8721.00116
   Maurer D, 2006, DEVELOPMENTAL SCI, V9, P316, DOI 10.1111/j.1467-7687.2006.00495.x
   McCormick K, 2018, NEUROPSYCHOLOGIA, V112, P19, DOI 10.1016/j.neuropsychologia.2018.02.029
   Mudrik L, 2014, TRENDS COGN SCI, V18, P488, DOI 10.1016/j.tics.2014.04.009
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Naumer MJ, 2009, CEREB CORTEX, V19, P1641, DOI 10.1093/cercor/bhn200
   Noppeney U, 2008, CEREB CORTEX, V18, P598, DOI 10.1093/cercor/bhm091
   Noppeney U, 2010, J NEUROSCI, V30, P7434, DOI 10.1523/JNEUROSCI.0455-10.2010
   Noudoost B, 2010, CURR OPIN NEUROBIOL, V20, P183, DOI 10.1016/j.conb.2010.02.003
   Odegaard B, 2016, PSYCHOL SCI, V27, P583, DOI 10.1177/0956797616628860
   Ojanen V, 2005, NEUROIMAGE, V25, P333, DOI 10.1016/j.neuroimage.2004.12.001
   Palmer SE, 2013, P NATL ACAD SCI USA, V110, P8836, DOI 10.1073/pnas.1212562110
   Parise CV, 2012, EXP BRAIN RES, V220, P319, DOI 10.1007/s00221-012-3140-6
   Phelps EA, 2000, J COGNITIVE NEUROSCI, V12, P729, DOI 10.1162/089892900562552
   Poldrack RA, 2008, NEUROIMAGE, V40, P409, DOI 10.1016/j.neuroimage.2007.11.048
   Ramachandran V, 2001, J CONSCIOUSNESS STUD, V8, P3
   Revill KP, 2014, BRAIN LANG, V128, P18, DOI 10.1016/j.bandl.2013.11.002
   Sadaghiani S, 2009, J NEUROSCI, V29, P6490, DOI 10.1523/JNEUROSCI.5437-08.2009
   Seger CA, 2010, ANNU REV NEUROSCI, V33, P203, DOI 10.1146/annurev.neuro.051508.135546
   Solomon SR, 2009, J MOD APPL STAT METH, V8, P448, DOI 10.22237/jmasm/1257034080
   Spence C, 2013, CONSCIOUS COGN, V22, P245, DOI 10.1016/j.concog.2012.12.006
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Taitz A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193466
   TARTE RD, 1971, LANG SPEECH, V14, P158, DOI 10.1177/002383097101400206
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   van Atteveldt N, 2004, NEURON, V43, P271, DOI 10.1016/j.neuron.2004.06.025
   van Atteveldt NM, 2007, CEREB CORTEX, V17, P962, DOI 10.1093/cercor/bhl007
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Xu K., 2014, J OPEN PSYCHOL DATA, V2, pe3, DOI 10.5334/jopd.ac
NR 63
TC 4
Z9 4
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD FEB 1
PY 2019
VL 186
BP 679
EP 689
DI 10.1016/j.neuroimage.2018.11.033
PG 11
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA HH8FX
UT WOS:000455968400061
PM 30503933
OA Other Gold, Green Published
DA 2021-02-24
ER

PT J
AU Gao, YA
   Toscano, JC
   Shih, C
   Tanner, D
AF Gao, Yang Agnes
   Toscano, Joseph C.
   Shih, Chilin
   Tanner, Darren
TI Reassessing the electrophysiological evidence for categorical perception
   of Mandarin lexical tone: ERP evidence from native and naive non-native
   Mandarin listeners
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Categorical perception; Mandarin; Lexical tones; ERP; N2; P3
ID LANGUAGE EXPERIENCE; SPEECH-PERCEPTION; MISMATCH; COMPONENT; SOUNDS
AB Some studies have argued that native speakers of tonal languages have been shown to perceive lexical tone continua in a more categorical manner than speakers of non-tonal languages. Among these, Zhang and colleagues (NeuroReport 23 (1): 35-9) conducted an event-related potential (ERP) study using an oddball paradigm showing that native Mandarin speakers exhibit different sensitivity to deviant tones that cross category boundaries compared to deviants that belong to the same category as the standard. Other recent ERP findings examining consonant voicing categories question whether perception is truly categorical. The current study investigated these discrepant findings by replicating and extending the Zhang et al. study. Native Mandarin speakers and naive English speakers performed an auditory oddball detection test while ERPs were recorded. Naive English speakers were included to test for language experience effects. We found that Mandarin speakers and English speakers demonstrated qualitatively similar responses, in that both groups showed a larger N2 to the across-category deviant and a larger P3 to the within-category deviant. The N2/P3 pattern also did not differ in scalp topography for the within- versus across-category deviants, as was reported by Zhang et al. Cross-language differences surfaced in behavioral results, where Mandarin speakers showed better discrimination for the across-category deviant, but English speakers showed better discrimination for within-category deviants, though all results were near-ceiling. Our results therefore support models suggesting that listeners remain sensitive to gradient acoustic differences in speech even when they have learned phonological categories along an acoustic dimension.
C1 [Gao, Yang Agnes; Shih, Chilin; Tanner, Darren] Univ Illinois, Dept Linguist, Urbana, IL 61801 USA.
   [Gao, Yang Agnes; Toscano, Joseph C.] Villanova Univ, Dept Psychol & Brain Sci, 800 E Lancaster Ave, Villanova, PA 19085 USA.
   [Shih, Chilin] Univ Illinois, Dept East Asian Languages & Cultures, Urbana, IL USA.
   [Shih, Chilin; Tanner, Darren] Univ Illinois, Beckman Inst Adv Sci & Technol, Urbana, IL USA.
   [Tanner, Darren] Univ Illinois, Neurosci Program, Urbana, IL USA.
RP Gao, YA (corresponding author), Univ Illinois, Dept Linguist, Urbana, IL 61801 USA.; Gao, YA (corresponding author), Villanova Univ, Dept Psychol & Brain Sci, 800 E Lancaster Ave, Villanova, PA 19085 USA.
EM ygao2@villanova.edu
OI Toscano, Joseph/0000-0001-8141-0084
FU NSFNational Science Foundation (NSF) [BCS-1431324]
FX We would like to thank Jessica Philipp, Justin Brook, and Amanda Kim for
   assistance with data collection. We would also like to thank Jerome
   Packard for helpful discussion in the early stages of this project. This
   project was part of Yang Agnes Gao's undergraduate honors thesis in the
   Department of Linguistics at the University of Illinois at
   Urbana-Champaign. This work was partially supported by NSF BCS-1431324
   to DT.
CR Acunzo DJ, 2012, J NEUROSCI METH, V209, P212, DOI 10.1016/j.jneumeth.2012.06.011
   DehaeneLambertz G, 1997, NEUROREPORT, V8, P919, DOI 10.1097/00001756-199703030-00021
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Folstein JR, 2008, PSYCHOPHYSIOLOGY, V45, P152, DOI 10.1111/j.1469-8986.2007.00602.x
   Gandour J. T., 1978, TONE LINGUISTIC SURV, P41, DOI DOI 10.1016/B978-0-12-267350-4.50007-8
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   Jasper H., 1957, ELECTROEN CLIN NEURO, V10, P370, DOI [10.1016/0013-4694(58)90053-1, DOI 10.1016/0013-4694(58)90053-1]
   Joanisse MF, 2007, NEUROREPORT, V18, P901, DOI 10.1097/WNR.0b013e3281053c4e
   Lakens D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00863
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1952, AM J PSYCHOL, V65, P497, DOI 10.2307/1418032
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1
   MASSARO DW, 1983, SPEECH COMMUN, V2, P15, DOI 10.1016/0167-6393(83)90061-4
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   MILLER JL, 1994, COGNITION, V50, P271, DOI 10.1016/0010-0277(94)90031-0
   Naatanen R, 2001, PSYCHOPHYSIOLOGY, V38, P1, DOI 10.1017/S0048577201000208
   Peng G, 2010, J PHONETICS, V38, P616, DOI 10.1016/j.wocn.2010.09.003
   Phillips C, 2000, J COGNITIVE NEUROSCI, V12, P1038, DOI 10.1162/08989290051137567
   REPP BH, 1979, J EXP PSYCHOL HUMAN, V5, P129, DOI 10.1037/0096-1523.5.1.129
   SHARMA A, 1993, ELECTROEN CLIN NEURO, V88, P64, DOI 10.1016/0168-5597(93)90029-O
   Toscano JC, 2010, PSYCHOL SCI, V21, P1532, DOI 10.1177/0956797610384142
   WOLDORFF MG, 1991, PSYCHOPHYSIOLOGY, V28, P30, DOI 10.1111/j.1469-8986.1991.tb03384.x
   Xi J, 2010, NEUROSCIENCE, V170, P223, DOI 10.1016/j.neuroscience.2010.06.077
   Xu YS, 2006, J ACOUST SOC AM, V120, P1063, DOI 10.1121/1.2213572
   Yip M., 2002, TONE
   Zentner M, 2017, ANN NY ACAD SCI, V1400, P33, DOI 10.1111/nyas.13410
   Zhang LJ, 2012, NEUROREPORT, V23, P35, DOI 10.1097/WNR.0b013e32834e4842
NR 31
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD FEB
PY 2019
VL 81
IS 2
BP 543
EP 557
DI 10.3758/s13414-018-1614-8
PG 15
WC Psychology; Psychology, Experimental
SC Psychology
GA HH2UC
UT WOS:000455573300013
PM 30378083
OA Bronze
DA 2021-02-24
ER

PT J
AU Yoho, SE
   Borrie, SA
   Barrett, TS
   Whittaker, DB
AF Yoho, Sarah E.
   Borrie, Stephanie A.
   Barrett, Tyson S.
   Whittaker, Dane B.
TI Are there sex effects for speech intelligibility in American English?
   Examining the influence of talker, listener, and methodology
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Hearing; Speech perception
ID FUNDAMENTAL-FREQUENCY; SENTENCE INTELLIGIBILITY; CONVERSATIONAL SPEECH;
   GENDER-DIFFERENCES; NORMAL-HEARING; SPEAKER SEX; RECOGNITION; NOISE;
   WORD; IDENTIFICATION
AB Talker and listener sex in speech processing has been largely unknown and under-appreciated to this point, with many studies overlooking the possible influences. In the current study, the effects of both talker and listener sex on speech intelligibility were assessed. Different methodological approaches to measuring intelligibility (percent words correct vs. subjective rating scales) and collecting data (laboratory vs. crowdsourcing) were also evaluated. Findings revealed that, regardless of methodology, the spoken productions of female talkers were overall more intelligible than the spoken productions of male talkers; however, substantial variability across talkers was observed. Findings also revealed that when data were collected in the lab, there was an interaction between talker and listener sex. This interaction between listener and talker sex was not observed when subjective ratings were crowdsourced from listener subjects across the USA via Amazon Mechanical Turk, although overall ratings remained similar. This possibly suggests that subjective intelligibility ratings may be vulnerable to bias, and such biases may be reduced by recruiting a more heterogeneous subject pool. Many studies in speech perception do not account for these talker, listener, and methodology effects. However, the present results suggest that researchers should carefully consider these effects when assessing speech intelligibility in different conditions, and when comparing findings across studies that have used different subject demographics and/or methodologies.
C1 [Yoho, Sarah E.; Borrie, Stephanie A.; Whittaker, Dane B.] Utah State Univ, Dept Communicat Disorders & Deaf Educ, Logan, UT 84322 USA.
   [Barrett, Tyson S.] Utah State Univ, Dept Kinesiol & Hlth Sci, Logan, UT 84322 USA.
RP Yoho, SE (corresponding author), Utah State Univ, Dept Communicat Disorders & Deaf Educ, Logan, UT 84322 USA.
EM sarah.leopold@usu.edu
OI Barrett, Tyson/0000-0002-2137-1391; Borrie,
   Stephanie/0000-0002-2336-0071
FU National Institute of Deafness and Other Communication Disorders,
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R21 DC 016084];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R21DC016084, R21DC016084, R21DC016084]
   Funding Source: NIH RePORTER
FX This paper was written with partial support from the National Institute
   of Deafness and Other Communication Disorders, National Institutes of
   Health Grant No. R21 DC 016084 (awarded to S.A.B.). We gratefully
   acknowledge our research assistants Nicole Thiede and Monica Muncy for
   data analysis and manuscript preparation assistance.
CR Allmark P, 2004, J MED ETHICS, V30, P185, DOI 10.1136/jme.2003.004374
   American Speech-Language-Hearing Association Audiologic Assessment Panel, 1996, GUID AUD SCREEN
   [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   ANSI, 1997, S35 ANSI
   BACON SP, 1990, J ACOUST SOC AM, V88, P698, DOI 10.1121/1.399773
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Beaman LG, 2001, SOCIOL RELIG, V62, P65, DOI 10.2307/3712231
   BLEECKER ML, 1988, J CLIN PSYCHOL, V44, P403, DOI 10.1002/1097-4679(198805)44:3<403::AID-JCLP2270440315>3.0.CO;2-0
   Boersma P., 2018, PRAAT DOING PHONETIC
   Borrie SA, 2017, J SPEECH LANG HEAR R, V60, P2151, DOI 10.1044/2017_JSLHR-S-16-0411
   Borrie SA, 2017, J ACOUST SOC AM, V141, P4660, DOI 10.1121/1.4986746
   Bradlow AR, 2018, LAB PHONOL, V9, DOI 10.5334/labphon.137
   Bradlow AR, 1996, SPEECH COMMUN, V20, P255, DOI 10.1016/S0167-6393(96)00063-5
   Brown Bruce L., 1980, LANGUAGE SOCIAL PSYC, P293
   Bunton K, 2001, CLIN LINGUIST PHONET, V15, P181
   BYRD D, 1994, SPEECH COMMUN, V15, P39, DOI 10.1016/0167-6393(94)90039-6
   Byun TM, 2015, J COMMUN DISORD, V53, P70, DOI 10.1016/j.jcomdis.2014.11.003
   COLEMAN RO, 1971, J SPEECH HEAR RES, V14, P565, DOI 10.1044/jshr.1403.565
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   DEHAN CP, 1990, LARYNGOSCOPE, V100, P18
   DON M, 1993, J ACOUST SOC AM, V94, P2135, DOI 10.1121/1.407485
   Ellis L, 1996, PERCEPT MOTOR SKILL, V83, P771, DOI 10.2466/pms.1996.83.3.771
   Ferguson SH, 2018, J SPEECH LANG HEAR R, V61, P159, DOI 10.1044/2017_JSLHR-H-17-0082
   Ferguson SH, 2004, J ACOUST SOC AM, V116, P2365, DOI 10.1121/1.1788730
   Fogerty D, 2011, J ACOUST SOC AM, V129, P977, DOI 10.1121/1.3531954
   Garofolo J. S., 1988, NATL I STANDARDS TEC, V15, P29
   GENGEL RW, 1980, EAR HEARING, V1, P156, DOI 10.1097/00003446-198005000-00008
   Goy H, 2013, J VOICE, V27, P545, DOI 10.1016/j.jvoice.2013.03.002
   Hazan V, 2004, J ACOUST SOC AM, V116, P3108, DOI 10.1121/1.1806826
   Healy EW, 2013, J ACOUST SOC AM, V133, P463, DOI 10.1121/1.4770246
   Hirsh IJ, 1952, J SPEECH HEAR DISORD, V17, P321, DOI 10.1044/jshd.1703.321
   Hodges-Simeon CR, 2010, HUM NATURE-INT BIOS, V21, P406, DOI 10.1007/s12110-010-9101-5
   Klasner ER, 2005, J MED SPEECH-LANG PA, V13, P127
   Kwon HB, 2010, J ADV PROSTHODONT, V2, P71, DOI 10.4047/jap.2010.2.3.71
   Lansford KL, 2016, AM J SPEECH-LANG PAT, V25, DOI 10.1044/2015_AJSLP-15-0059
   LASS NJ, 1976, J ACOUST SOC AM, V59, P675, DOI 10.1121/1.380917
   Laures JS, 1999, J SPEECH LANG HEAR R, V42, P1148, DOI 10.1044/jslhr.4205.1148
   Markham D, 2004, J SPEECH LANG HEAR R, V47, P725, DOI 10.1044/1092-4388(2004/055)
   McCloy DR, 2015, LANG SPEECH, V58, P371, DOI 10.1177/0023830914559234
   McFadden D, 1998, DEV NEUROPSYCHOL, V14, P261, DOI 10.1080/87565649809540712
   McFadden D, 2018, J ACOUST SOC AM, V143, P2338, DOI 10.1121/1.5030998
   MCROBERTS GW, 1992, PERCEPT PSYCHOPHYS, V51, P118, DOI 10.3758/BF03212236
   Miller SE, 2010, J ACOUST SOC AM, V128, P435, DOI 10.1121/1.3397384
   National Institutes of Health, 2017, NIH GRANTS POL
   Parker MA, 2018, J VOICE, V32, P538, DOI 10.1016/j.jvoice.2017.08.002
   Rademacher J, 2001, NEUROREPORT, V12, P1561, DOI 10.1097/00001756-200106130-00010
   Rogers Deanna S, 2003, J Am Acad Audiol, V14, P372
   SCHWARTZ MF, 1968, J ACOUST SOC AM, V43, P1178, DOI 10.1121/1.1910954
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Simpson AP, 2009, LANG LINGUIST COMPAS, V3, P621, DOI 10.1111/j.1749-818x.2009.00125.x
   Slote J, 2016, BEHAV RES METHODS, V48, P553, DOI 10.3758/s13428-015-0599-7
   SMITH BL, 1975, LANG SPEECH, V18, P145, DOI 10.1177/002383097501800203
   Sumerau JE, 2015, SOCIOL RELIG, V76, P49, DOI 10.1093/socrel/sru040
   TITZE IR, 1989, J ACOUST SOC AM, V85, P1699, DOI 10.1121/1.397959
   Utah State University, 2015, INT DIV EXP ATT LONG
   Utah State University Office of Analysis Assessment and Accreditation, 2018, UT STAT U FALL 2017
   Van Engen KJ, 2007, J ACOUST SOC AM, V121, P519, DOI 10.1121/1.2400666
   WANG MD, 1973, J ACOUST SOC AM, V54, P1248, DOI 10.1121/1.1914417
   Yoho SE, 2018, J ACOUST SOC AM, V143, P1417, DOI 10.1121/1.5026787
   Yoho E, 2018, J ACOUST SOC AM, V143, P281, DOI 10.1121/1.5021254
   YORKSTON KM, 1978, J COMMUN DISORD, V11, P499, DOI 10.1016/0021-9924(78)90024-2
NR 61
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD FEB
PY 2019
VL 81
IS 2
BP 558
EP 570
DI 10.3758/s13414-018-1635-3
PG 13
WC Psychology; Psychology, Experimental
SC Psychology
GA HH2UC
UT WOS:000455573300014
PM 30506326
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Baese-Berk, MM
   Dilley, LC
   Henry, MJ
   Vinke, L
   Banzina, E
AF Baese-Berk, Melissa M.
   Dilley, Laura C.
   Henry, Molly J.
   Vinke, Louis
   Banzina, Elina
TI Not just a function of function words: Distal speech rate influences
   perception of prosodically weak syllables
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Speech perception; Spoken word recognition; Word perception
ID NEIGHBORHOOD ACTIVATION; LANGUAGE PRODUCTION; THETA OSCILLATIONS;
   ACOUSTIC DURATION; ARTICULATORY-RATE; EMBEDDED WORDS; SPEAKING RATE;
   SPOKEN WORDS; TIME-COURSE; SEGMENTATION
AB Listeners resolve ambiguities in speech perception using multiple sources, including non-local or distal speech rate (i.e., the speech rate of material surrounding a particular region). The ability to resolve ambiguities is particularly important for the perception of casual, everyday productions, which are often produced using phonetically reduced forms. Here, we examine whether the distal speech rate effect is specific to a lexical class of words and/or to particular lexical or phonological contexts. In Experiment 1, we examined whether distal speech rate influenced perception of phonologically similar content words differing in number of syllables (e.g., form/forum). In Experiment 2, we used both transcription and word-monitoring tasks to examine whether distal speech rate influenced perception of a reduced vowel, causing lexical reorganization (e.g., cease, see us). Distal speech rate influenced perception of lexical content in both experiments. This demonstrates that distal rate influences perception of a lexical class other than function words and affects perception in a variety of phonological and lexical contexts. These results support a view that distal speech rate is a pervasive source of information with far-reaching consequences for perception of lexical content and word segmentation.
C1 [Baese-Berk, Melissa M.] 1290 Univ Oregon, Dept Linguist, Eugene, OR 97403 USA.
   [Dilley, Laura C.] Michigan State Univ, Dept Communicat Sci & Disorders, 1026 Red Cedar Rd, E Lansing, MI 48824 USA.
   [Henry, Molly J.] Univ Western Ontario, Dept Psychol, Brain & Mind Inst, Social Sci Ctr Rm 7418, London, ON N6A 5C2, Canada.
   [Vinke, Louis] Boston Univ, Ctr Syst Neurosci, One Silber Way, Boston, MA 02215 USA.
   [Banzina, Elina] Stockholm Sch Econ Riga, Dept Linguist, Strelnieku Iela 4a, LV-1010 Riga, Latvia.
RP Dilley, LC (corresponding author), Michigan State Univ, Dept Communicat Sci & Disorders, 1026 Red Cedar Rd, E Lansing, MI 48824 USA.
EM mbaesebe@uoregon.edu; ldilley@msu.edu
FU NSF Faculty Early Career Development (CAREER) AwardNational Science
   Foundation (NSF); NSFNational Science Foundation (NSF) [BCS 1431063];
   University of Oregon Faculty Research Award
FX This work was partially supported by an NSF Faculty Early Career
   Development (CAREER) Award and NSF grant BCS 1431063 to Laura C. Dilley
   and by a University of Oregon Faculty Research Award to Melissa M.
   Baese-Berk.
CR Alexandrou A. M., 2018, J COGNITIVE NEUROSCI, P1
   Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Baese-Berk M. M, 2016, P SPEECH PROSODY, V8, P979
   Baese-Berk MM, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155975
   Baese-Berk MM, 2014, PSYCHOL SCI, V25, P1546, DOI 10.1177/0956797614533705
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   BEACH CM, 1991, J MEM LANG, V30, P644, DOI 10.1016/0749-596X(91)90030-N
   Beckman M. E., 1990, PAPERS LABORATORY PH, P152, DOI DOI 10.1017/CBO9780511627736.009
   Bell A, 2009, J MEM LANG, V60, P92, DOI 10.1016/j.jml.2008.06.003
   Boersma P, 2015, PRAAT DOING PHONETIC
   Bosker HR, 2018, LANG COGN NEUROSCI, V33, P955, DOI 10.1080/23273798.2018.1439179
   Bosker HR, 2017, ATTEN PERCEPT PSYCHO, V79, P333, DOI 10.3758/s13414-016-1206-4
   Breen M, 2014, LANG COGN NEUROSCI, V29, P1132, DOI 10.1080/23273798.2014.894642
   Brouwer S, 2012, LANG COGNITIVE PROC, V27, P539, DOI 10.1080/01690965.2011.555268
   BROWMAN CP, 1990, J PHONETICS, V18, P299, DOI 10.1016/S0095-4470(19)30376-6
   Brown M, 2014, THESIS
   Brown M., 2014, P 7 INT C SPEECH PRO, P1154
   Brown M., 2012, P ANN M COGN SCI SOC, V34
   Brown M, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00643
   Burki A, 2011, J PHONETICS, V39, P279, DOI 10.1016/j.wocn.2010.07.003
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   CUTLER A, 1988, J EXP PSYCHOL HUMAN, V14, P113, DOI 10.1037/0096-1523.14.1.113
   Dahan D., 2006, HDB PSYCHOLINGUISTIC, P249, DOI DOI 10.1016/B978-012369374-7/50009-2
   Davidson L, 2006, PHONETICA, V63, P79, DOI 10.1159/000095304
   Davis MH, 1997, PERSP NEURAL COMP, P254
   Davis MH, 2002, J EXP PSYCHOL HUMAN, V28, P218, DOI 10.1037//0096-1523.28.1.218
   De Ruiter JP, 2006, LANGUAGE, V82, P515, DOI 10.1353/lan.2006.0130
   Dell GS, 2013, BEHAV BRAIN SCI, V36, P351, DOI 10.1017/S0140525X12002531
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Dilley L, 1996, J PHONETICS, V24, P423, DOI 10.1006/jpho.1996.0023
   Dilley LC, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01002
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Dilley LC, 2017, J ACOUST SOC AM, V141, P3700
   Ding N, 2017, NEUROSCI BIOBEHAV R, V81, P181, DOI 10.1016/j.neubiorev.2017.02.011
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Docherty G., 1992, PAPERS LABORATORY PH, P90, DOI DOI 10.1017/CBO9780511519918.005
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   DORMAN MF, 1976, J ACOUST SOC AM, V59, pS40, DOI 10.1121/1.2002677
   Drijvers L, 2016, BRAIN LANG, V153, P27, DOI 10.1016/j.bandl.2016.01.003
   Eisner F, 2018, STEVENS HDB EXPT PSY, P1
   Ernestus M, 2002, BRAIN LANG, V81, P162, DOI 10.1006/brln.2001.2514
   Ernestus M, 2011, J PHONETICS, V39, P253, DOI 10.1016/S0095-4470(11)00055-6
   Farris M. C., 2013, MISUNDERSTANDINGS AT
   Fougeron Cecile, 1997, P EUR 97 INT SPEECH, V2, P943
   Gahl S, 2012, J MEM LANG, V66, P789, DOI 10.1016/j.jml.2011.11.006
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Gaskell MG, 2001, J MEM LANG, V44, P325, DOI 10.1006/jmla.2000.2741
   Gow DW, 2001, J MEM LANG, V45, P133, DOI 10.1006/jmla.2000.2764
   GOW DW, 1995, J EXP PSYCHOL HUMAN, V21, P344, DOI 10.1037/0096-1523.21.2.344
   Havy M, 2014, LANG SPEECH, V57, P254, DOI 10.1177/0023830913507693
   Heffner CC, 2017, ATTEN PERCEPT PSYCHO, V79, P964, DOI 10.3758/s13414-016-1274-5
   Heffner CC, 2013, LANG COGNITIVE PROC, V28, P1275, DOI 10.1080/01690965.2012.672229
   Hillenbrand JM, 1996, J SPEECH HEAR RES, V39, P1182, DOI 10.1044/jshr.3906.1182
   Indefrey P, 2004, COGNITION, V92, P101, DOI 10.1016/j.cognition.2002.06.001
   Jaeger TF, 2010, COGNITIVE PSYCHOL, V61, P23, DOI 10.1016/j.cogpsych.2010.02.002
   Johnson K, 2004, SPONTANEOUS SPEECH D, P29
   Keitel A, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2004473
   Kemps R, 2004, BRAIN LANG, V90, P117, DOI 10.1016/S0093-934X(03)00425-5
   Kessler B, 1997, J MEM LANG, V37, P295, DOI 10.1006/jmla.1997.2522
   KIDD GR, 1989, J EXP PSYCHOL HUMAN, V15, P736, DOI 10.1037/0096-1523.15.4.736
   Kohler K., 1998, ZAS WORKING PAPERS L, V11, P21
   Kohler KJ, 2006, METHODS EMPIRICAL PR, V3, P123
   Kosem A, 2018, CURR BIOL, V28, P2867, DOI 10.1016/j.cub.2018.07.023
   Krivokapic J, 2007, J PHONETICS, V35, P162, DOI 10.1016/j.wocn.2006.04.001
   Krivokapic J, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0397
   Kuperman V, 2007, J ACOUST SOC AM, V121, P2261, DOI 10.1121/1.2537393
   Kurumada C., 2017, PSYCHONOMIC B REV, P1
   Levinson SC, 2016, TRENDS COGN SCI, V20, P6, DOI 10.1016/j.tics.2015.10.010
   LIBERMAN AM, 1956, J EXP PSYCHOL, V52, P127, DOI 10.1037/h0041240
   Lisker L., 1967, P 6 INT C PHON SCI P
   Lisker L., 1970, P 6 INT C PHON SCI P
   LoCasto PC, 2002, PERCEPT PSYCHOPHYS, V64, P208, DOI 10.3758/BF03195787
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Mahowald K, 2013, COGNITION, V126, P313, DOI 10.1016/j.cognition.2012.09.010
   Manuel S. Y., 1992, 1992 INT C SPOK LANG
   MARSLENWILSON W, 1989, J EXP PSYCHOL HUMAN, V15, P576, DOI 10.1037/0096-1523.15.3.576
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X
   Mattys SL, 2005, J EXP PSYCHOL GEN, V134, P477, DOI 10.1037/0096-3445.134.4.477
   Mattys SL, 2007, J EXP PSYCHOL HUMAN, V33, P960, DOI 10.1037/0096-1523.33.4.960
   Mattys SL, 2007, J ACOUST SOC AM, V122, P554, DOI 10.1121/1.2735105
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McQueen JM, 1998, J MEM LANG, V39, P21, DOI 10.1006/jmla.1998.2568
   MILLER JL, 1979, PERCEPT PSYCHOPHYS, V25, P457, DOI 10.3758/BF03213823
   MILLER JL, 1984, PERCEPT PSYCHOPHYS, V35, P5, DOI 10.3758/BF03205919
   Mitterer H, 2018, LAB PHONOL, V9, DOI 10.5334/labphon.66
   Morrill T, 2015, PSYCHON B REV, V22, P1451, DOI 10.3758/s13423-015-0820-9
   Morrill TH, 2014, COGNITION, V131, P69, DOI 10.1016/j.cognition.2013.12.006
   New B, 2014, LANG COGN NEUROSCI, V29, P147, DOI 10.1080/01690965.2012.735678
   Niebuhr O, 2011, J PHONETICS, V39, P319, DOI 10.1016/j.wocn.2010.12.003
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Norris D, 2006, COGNITIVE PSYCHOL, V53, P146, DOI 10.1016/j.cogpsych.2006.03.001
   Norris D, 2016, LANG COGN NEUROSCI, V31, P4, DOI 10.1080/23273798.2015.1081703
   O'Dell M., 2018, P 9 INT C SPEECH PRO, P646, DOI [10.21437/SpeechProsody.2018-131, DOI 10.21437/SPEECHPROSODY.2018-131]
   Oh YM, 2015, J PHONETICS, V53, P153, DOI 10.1016/j.wocn.2015.08.003
   Olasagasti I, 2015, CORTEX, V68, P61, DOI 10.1016/j.cortex.2015.04.008
   Park H., 2018, PREDICTIVE ENTRAINME
   Patterson D, 2003, PHONETICA, V60, P47, DOI 10.1159/000070454
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   PICKETT JM, 1960, LANG SPEECH, V3, P11, DOI 10.1177/002383096000300103
   PISONI DB, 1983, PERCEPT PSYCHOPHYS, V34, P314, DOI 10.3758/BF03203043
   Pitt MA, 2016, ATTEN PERCEPT PSYCHO, V78, P334, DOI 10.3758/s13414-015-0981-7
   Pitt MA, 2011, J PHONETICS, V39, P304, DOI 10.1016/j.wocn.2010.07.004
   Poellmann K, 2014, J PHONETICS, V46, P101, DOI 10.1016/j.wocn.2014.06.004
   QUENE H, 1992, J PHONETICS, V20, P331
   R Development Core Team, 2014, R LANG ENV STAT COMP
   Ravignani A, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00303
   Redi L, 2001, J PHONETICS, V29, P407, DOI 10.1006/jpho.2001.0145
   Reinisch E, 2016, APPL PSYCHOLINGUIST, V37, P1397, DOI 10.1017/S0142716415000612
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   Reinisch E, 2011, J EXP PSYCHOL HUMAN, V37, P978, DOI 10.1037/a0021923
   REMEZ RE, 1981, SCIENCE, V212, P947, DOI 10.1126/science.7233191
   REPP BH, 1978, J EXP PSYCHOL HUMAN, V4, P621, DOI 10.1037/0096-1523.4.4.621
   Salverda AP, 2003, COGNITION, V90, P51, DOI 10.1016/S0010-0277(03)00139-2
   Samuel AG, 1996, J EXP PSYCHOL GEN, V125, P28, DOI 10.1037/0096-3445.125.1.28
   SAMUEL AG, 1981, J EXP PSYCHOL GEN, V110, P474, DOI 10.1037/0096-3445.110.4.474
   Sawusch JR, 2000, PERCEPT PSYCHOPHYS, V62, P285, DOI 10.3758/BF03205549
   Schuppler B, 2011, J PHONETICS, V39, P96, DOI 10.1016/j.wocn.2010.11.006
   Seyfarth S, 2014, COGNITION, V133, P140, DOI 10.1016/j.cognition.2014.06.013
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Shatzman KB, 2006, PERCEPT PSYCHOPHYS, V68, P1, DOI 10.3758/BF03193651
   Shockey L, 2008, SOUND PATTERNS SPOKE
   Snedeker J, 2003, J MEM LANG, V48, P103, DOI 10.1016/S0749-596X(02)00519-3
   Staub A, 2006, J EXP PSYCHOL LEARN, V32, P425, DOI 10.1037/0278-7393.32.2.425
   Stevens Kenneth N., 2000, ACOUSTIC PHONETICS
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   Tavano A, 2015, CORTEX, V68, P1, DOI 10.1016/j.cortex.2015.05.001
   Tucker BV, 2016, MENT LEX, V11, P375, DOI 10.1075/ml.11.3.03tuc
   Turk AE, 2000, J PHONETICS, V28, P397, DOI 10.1006/jpho.2000.0123
   Turk AE, 2007, J PHONETICS, V35, P445, DOI 10.1016/j.wocn.2006.12.001
   van de Ven M, 2018, LANG SPEECH, V61, P358, DOI 10.1177/0023830917727774
   Vitevitch MS, 1999, J MEM LANG, V40, P374, DOI 10.1006/jmla.1998.2618
   Wade T, 2005, J ACOUST SOC AM, V118, P1701, DOI 10.1121/1.1984839
   WARREN RM, 1974, PERCEPT PSYCHOPHYS, V16, P150, DOI 10.3758/BF03203268
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Wilshire CE, 1999, LANG SPEECH, V42, P57, DOI 10.1177/00238309990420010301
   Wright Richard, 2004, PHONETICALLY BASED P, P34, DOI DOI 10.1017/CBO9780511486401.002
   Zhang XJ, 2015, J MEM LANG, V79, P53, DOI 10.1016/j.jml.2014.12.001
   Zhou XH, 2008, J ACOUST SOC AM, V123, P4466, DOI 10.1121/1.2902168
   Zoefel B, 2018, CURR BIOL, V28, P401, DOI 10.1016/j.cub.2017.11.071
NR 144
TC 9
Z9 8
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD FEB
PY 2019
VL 81
IS 2
BP 571
EP 589
DI 10.3758/s13414-018-1626-4
PG 19
WC Psychology; Psychology, Experimental
SC Psychology
GA HH2UC
UT WOS:000455573300015
PM 30488190
OA Bronze
DA 2021-02-24
ER

PT J
AU Nylund, A
   Toivonen, L
   Korpilahti, P
   Kaljonen, A
   Peltola, V
   Rautakoski, P
AF Nylund, Annette
   Toivonen, Laura
   Korpilahti, Pirjo
   Kaljonen, Anne
   Peltola, Ville
   Rautakoski, Pirkko
TI Recurrent respiratory tract infections or acute otitis media were not a
   risk factor for vocabulary development in children at 13 and 24 months
   of age
SO ACTA PAEDIATRICA
LA English
DT Article
DE Acute otitis media; MacArthur Communicative Development Inventory;
   Respiratory tract infections; Socioeconomic status; Vocabulary size
ID SPEECH-PERCEPTION; LANGUAGE; IDENTIFICATION; EPIDEMIOLOGY; DISABILITY;
   VIROLOGY; VALIDITY; VIRUSES
AB Aim This study examined associations between recurrent respiratory tract infections (RTI) and acute otitis media (AOM) during the first one and two years of life and vocabulary size at 13 and 24 months of age. Methods We studied 646 children born between January 2008 and April 2010 and followed up from birth to two years of age with daily diary and study clinic visits during RTIs and AOM. The families were recruited from maternity health care clinics or delivery wards in south-west Finland. Parents completed the MacArthur Communicative Development Inventory at 13 and 24 months, and the vocabularies of children with high rates of RTIs or AOM were compared to children without recurrent issues. Results Of the 646 children, 9.6% had recurrent RTIs and 9.9% had recurrent AOM from 0 to 24 months. Children with high rates of RTIs or AOM did not have smaller vocabularies than children without recurrent RTIs or AOM. Girls had larger vocabularies and higher parental socioeconomic status was associated with a larger expressive vocabulary at 24 months. Conclusion The child's gender and parental socioeconomic status played a more critical role in vocabulary development in the first two years than a high burden of RTIs or AOM.
C1 [Nylund, Annette; Rautakoski, Pirkko] Abo Akad Univ, Dept Logoped, Fabr Gatan 2, FIN-20500 Turku, Finland.
   [Nylund, Annette; Toivonen, Laura; Peltola, Ville] Univ Turku, Turku Inst Child & Youth Res, Turku, Finland.
   [Toivonen, Laura; Peltola, Ville] Turku Univ Hosp, Dept Paediat & Adolescent Med, Turku, Finland.
   [Toivonen, Laura; Peltola, Ville] Univ Turku, Turku, Finland.
   [Korpilahti, Pirjo] Univ Turku, Dept Speech & Language Pathol, Turku, Finland.
   [Kaljonen, Anne] Univ Turku, Dept Clin Med, Biostat, Turku, Finland.
RP Nylund, A (corresponding author), Abo Akad Univ, Dept Logoped, Fabr Gatan 2, FIN-20500 Turku, Finland.
EM annette.nylund@abo.fi
OI Nylund, Annette/0000-0002-2636-2902
FU Kommunalradet C Gs Sundells stiftelse; Academy of FinlandAcademy of
   FinlandEuropean Commission [123571, 140251, 277535]; Foundation for
   Pediatric Research
FX This work was supported by Kommunalradet C Gs Sundells stiftelse and The
   Academy of Finland (Grants no. 123571, 140251, and 277535) and the
   Foundation for Pediatric Research.
CR Anders KL, 2015, PEDIATR INFECT DIS J, V34, P361, DOI 10.1097/INF.0000000000000643
   [Anonymous], 2015, ED STRUCT POP E PUBL
   Byington CL, 2015, CLIN INFECT DIS, V61, P1217, DOI 10.1093/cid/civ486
   Chetty Krishne, 2007, Paediatr Drugs, V9, P401, DOI 10.2165/00148581-200709060-00007
   Chonmaitree T, 2016, PEDIATRICS, V137, DOI 10.1542/peds.2015-3555
   Feldman HM, 2005, CHILD DEV, V76, P856, DOI 10.1111/j.1467-8624.2005.00882.x
   Feldman HM, 2000, CHILD DEV, V71, P310, DOI 10.1111/1467-8624.00146
   Fenson L., 2007, MACARTHUR BATES COMM, V2
   Fernald A, 2013, DEVELOPMENTAL SCI, V16, P234, DOI 10.1111/desc.12019
   Haapala S, 2015, FIRST LANG, V35, P219, DOI 10.1177/0142723715589695
   Haapala S, 2014, EAR HEARING, V35, pE75, DOI 10.1097/AUD.0000000000000002
   Halfon N, 2012, FUTURE CHILD, V22, P13
   Houtrow AJ, 2014, PEDIATRICS, V134, P530, DOI 10.1542/peds.2014-0594
   Jansson-Verkasalo E, 2010, BMC NEUROSCI, V11, DOI 10.1186/1471-2202-11-88
   Korpilahti P, 2016, INFANT BEHAV DEV, V42, P27, DOI 10.1016/j.infbeh.2015.08.008
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kujala T, 2017, J LARYNGOL OTOL, V131, P128, DOI 10.1017/S0022215116009944
   Lagstrom H, 2013, INT J EPIDEMIOL, V42, P1273, DOI 10.1093/ije/dys150
   Lyytinen P., 1999, VARHAISEN KOMMUNIKAA
   Nokso-Koivisto J, 2015, CURR OPIN PEDIATR, V27, P110, DOI 10.1097/MOP.0000000000000184
   Roberts JE, 2004, PEDIATRICS, V113, pE238, DOI 10.1542/peds.113.3.e238
   Rudolph JM, 2016, J EARLY INTERVENTION, V38, P41, DOI 10.1177/1053815116633861
   Thal DJ, 1999, J SPEECH LANG HEAR R, V42, P482, DOI 10.1044/jslhr.4202.482
   Toivonen L, 2016, PEDIATR INFECT DIS J, V35, pE362, DOI 10.1097/INF.0000000000001304
   Toivonen L, 2016, PEDIATRICS, V138, DOI 10.1542/peds.2016-1309
   Tregoning JS, 2010, CLIN MICROBIOL REV, V23, P74, DOI 10.1128/CMR.00032-09
   Zumach A, 2011, AUDIOL NEURO-OTOL, V16, P304, DOI 10.1159/000322501
   Zumach A, 2010, J SPEECH LANG HEAR R, V53, P34, DOI 10.1044/1092-4388(2009/08-0250)
NR 29
TC 3
Z9 3
U1 1
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0803-5253
EI 1651-2227
J9 ACTA PAEDIATR
JI Acta Paediatr.
PD FEB
PY 2019
VL 108
IS 2
BP 288
EP 294
DI 10.1111/apa.14546
PG 7
WC Pediatrics
SC Pediatrics
GA HH1ZO
UT WOS:000455518600018
PM 30126046
DA 2021-02-24
ER

PT J
AU Goossens, T
   Vercammen, C
   Wouters, J
   van Wieringen, A
AF Goossens, Tine
   Vercammen, Charlotte
   Wouters, Jan
   van Wieringen, Astrid
TI The association between hearing impairment and neural envelope encoding
   at different ages
SO NEUROBIOLOGY OF AGING
LA English
DT Article
DE Hearing impairment; Envelope modulations; Neural synchronization; Age;
   Audibility
ID STEADY-STATE RESPONSES; TEMPORAL FINE-STRUCTURE; HEMISPHERIC-ASYMMETRY;
   LOUDNESS RECRUITMENT; SPEECH RECOGNITION; AUDITORY-SYSTEM; CEREBRAL
   LATERALIZATION; AMPLITUDE-MODULATION; NORMALLY HEARING; LOSS ALTERS
AB Hearing impairment goes with speech perception difficulties, presumably not only because of poor hearing sensitivity but also because of altered central auditory processing. Critical herein is temporal processing of the speech envelope, mediated by synchronization of neural activity to the envelope modulations. It has been suggested that hearing impairment is associated with enhanced sensitivity to envelope modulations which, in turn, relates to poorer speech perception. To verify this hypothesis, we performed a comparative electrophysiological study in hearing-impaired (HI) and normal-hearing (NH) human listeners of three age groups, investigating neural envelope encoding. HI young and middle-aged adults showed enhanced neural synchronization to envelope modulations relative to NH controls, particularly when stimulus audibility was corrected for. At an older age, the degree of neural synchronization was similar for HI and NH persons, yet HI persons showed a synchronization asymmetry toward the right hemisphere. This study demonstrates that hearing impairment is characterized by changes in the neural encoding of envelope modulations, the nature of which varies with age. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Goossens, Tine; Vercammen, Charlotte; Wouters, Jan; van Wieringen, Astrid] Univ Leuven, KU Leuven, Dept Neurosci, Res Grp Expt ORL ExpORL, Herestr 49 Bus 721, B-3000 Leuven, Belgium.
RP Goossens, T (corresponding author), Univ Leuven, KU Leuven, Dept Neurosci, Res Grp Expt ORL ExpORL, Herestr 49 Bus 721, B-3000 Leuven, Belgium.
EM tine.goossens@kuleuven.be
RI Vercammen, Charlotte/L-1783-2019; Wouters, Jan/D-1800-2015
OI Vercammen, Charlotte/0000-0002-4517-6910; Wouters,
   Jan/0000-0002-0093-698X; Goossens, Tine/0000-0002-5513-8694
FU Research Foundation-Flanders (FWO) through an FWO-aspirant grantFWO
   [11Z8817N]; Research Council of KU LeuvenKU Leuven [OT/12/98]
FX This research was funded by the Research Foundation-Flanders (FWO)
   through an FWO-aspirant grant to Tine Goossens (grant number 11Z8817N)
   and by the Research Council of KU Leuven (project OT/12/98).
CR Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Ananthakrishnan S, 2016, EAR HEARING, V37, pe91, DOI 10.1097/AUD.0000000000000247
   Anderson S, 2013, J ACOUST SOC AM, V133, P3030, DOI 10.1121/1.4799804
   Anderson S, 2012, J NEUROSCI, V32, P14156, DOI 10.1523/JNEUROSCI.2176-12.2012
   [Anonymous], 1998, 3891 ISO
   BACON SP, 1992, J SPEECH HEAR RES, V35, P642, DOI 10.1044/jshr.3503.642
   Bellis TJ, 2000, J NEUROSCI, V20, P791, DOI 10.1523/JNEUROSCI.20-02-00791.2000
   Bernstein JGW, 2013, J AM ACAD AUDIOL, V24, P293, DOI 10.3766/jaaa.24.4.5
   Bidelman GM, 2017, J NEUROSCI, V37, P3610, DOI 10.1523/JNEUROSCI.3700-16.2017
   Bidelman GM, 2014, NEUROBIOL AGING, V35, P2526, DOI 10.1016/j.neurobiolaging.2014.05.006
   Bilodeau-Mercure M, 2015, BRAIN STRUCT FUNCT, V220, P979, DOI 10.1007/s00429-013-0695-3
   Boemio A, 2005, NAT NEUROSCI, V8, P389, DOI 10.1038/nn1409
   Buss E, 2004, EAR HEARING, V25, P242, DOI 10.1097/01.AUD.0000130796.73809.09
   Cabeza R, 2002, PSYCHOL AGING, V17, P85, DOI 10.1037//0882-7974.17.1.85
   Caspary DM, 2008, J EXP BIOL, V211, P1781, DOI 10.1242/jeb.013581
   Coffey EBJ, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11070
   Crumling MA, 2007, JARO-J ASSOC RES OTO, V8, P54, DOI 10.1007/s10162-006-0061-8
   da Silva FL, 2013, NEURON, V80, P1112, DOI 10.1016/j.neuron.2013.10.017
   Dobie RA, 1996, J ACOUST SOC AM, V100, P2236, DOI 10.1121/1.417933
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   DRULLMAN R, 1994, J ACOUST SOC AM, V95, P1053, DOI 10.1121/1.408467
   EISENBERG LS, 1995, J SPEECH HEAR RES, V38, P222, DOI 10.1044/jshr.3801.222
   Emara AAY, 2010, J INT ADV OTOL, V6, P371
   Ernst SMA, 2012, J ACOUST SOC AM, V131, P4722, DOI 10.1121/1.3699233
   Fjell AM, 2009, CEREB CORTEX, V19, P2001, DOI 10.1093/cercor/bhn232
   George ELJ, 2006, J ACOUST SOC AM, V120, P2295, DOI 10.1121/1.2266530
   Giraud AL, 2000, J NEUROPHYSIOL, V84, P1588
   Giroud N, 2018, BRAIN STRUCT FUNCT, V223, P145, DOI 10.1007/s00429-017-1477-0
   Goossens T, 2018, HEARING RES, V370, P189, DOI 10.1016/j.heares.2018.07.012
   Goossens T, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00133
   GordonSalant S, 2010, SPRINGER HANDB AUDIT, V34, P1
   Grose JH, 2016, J ACOUST SOC AM, V140, pEL184, DOI 10.1121/1.4960075
   Hamalainen JA, 2012, NEUROIMAGE, V59, P2952, DOI 10.1016/j.neuroimage.2011.09.075
   Heinz MG, 2004, J NEUROPHYSIOL, V91, P784, DOI 10.1152/jn.00776.2003
   Henry KS, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00020
   Herdman AT, 2002, BRAIN TOPOGR, V15, P69, DOI 10.1023/A:1021470822922
   Hopkins K, 2009, J ACOUST SOC AM, V125, P442, DOI 10.1121/1.3037233
   HOPTMAN MJ, 1994, PSYCHOL BULL, V116, P195, DOI 10.1037/0033-2909.116.2.195
   ISO, 2017, 7029 ISO
   John MS, 1998, AUDIOLOGY, V37, P59
   John MS, 2000, COMPUT METH PROG BIO, V61, P125, DOI 10.1016/S0169-2607(99)00035-8
   Joris PX, 2004, PHYSIOL REV, V84, P541, DOI 10.1152/physrev.00029.2003
   Kale S, 2012, HEARING RES, V286, P64, DOI 10.1016/j.heares.2012.02.004
   Kale S, 2010, JARO-J ASSOC RES OTO, V11, P657, DOI 10.1007/s10162-010-0223-6
   Kujawa SG, 2015, HEARING RES, V330, P191, DOI 10.1016/j.heares.2015.02.009
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Luke R, 2017, NEUROIMAGE, V147, P568, DOI 10.1016/j.neuroimage.2016.11.023
   Margolis RH, 2008, OTOL NEUROTOL, V29, P422, DOI 10.1097/MAO.0b013e31816c7c09
   Menard M, 2008, HEARING RES, V235, P105, DOI 10.1016/j.heares.2007.10.007
   Millman RE, 2017, J NEUROSCI, V37, P7727, DOI 10.1523/JNEUROSCI.2722-16.2017
   Moore BCJ, 2014, AUDITORY PROCESSING OF TEMPORAL FINE STRUCTURE: EFFECTS OF AGE AND HEARING LOSS, P1, DOI 10.1142/9064
   Moore BCJ, 2001, J ACOUST SOC AM, V110, P1067, DOI 10.1121/1.1385177
   MOORE BCJ, 1995, BRIT J AUDIOL, V29, P131, DOI 10.3109/03005369509086590
   Moore BCJ, 1996, J ACOUST SOC AM, V100, P481, DOI 10.1121/1.415861
   MOORE BCJ, 1993, J ACOUST SOC AM, V94, P2050, DOI 10.1121/1.407478
   Mudar RA, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00828
   Munro Kevin J, 2008, Trends Amplif, V12, P254, DOI 10.1177/1084713808323483
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Neuman AC, 2005, J REHABIL RES DEV, V42, P169, DOI 10.1682/JRRD.2005.01.0020
   Noordhoek IM, 2001, J ACOUST SOC AM, V109, P1197, DOI 10.1121/1.1349429
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Peters RW, 1998, J ACOUST SOC AM, V103, P577, DOI 10.1121/1.421128
   Poelmans H, 2012, JARO-J ASSOC RES OTO, V13, P867, DOI 10.1007/s10162-012-0348-x
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Presacco A, 2016, J NEUROPHYSIOL, V116, P2346, DOI 10.1152/jn.00372.2016
   Pujol J, 1999, NEUROLOGY, V52, P1038, DOI 10.1212/WNL.52.5.1038
   Rance G, 2008, AUDITORY STEADY STAT
   Salvi R, 2017, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00621
   Sanes DH, 2011, HEARING RES, V279, P140, DOI 10.1016/j.heares.2011.03.015
   Sarro EC, 2008, CEREB CORTEX, V18, P2855, DOI 10.1093/cercor/bhn044
   Scheidt RE, 2010, HEARING RES, V269, P23, DOI 10.1016/j.heares.2010.07.009
   Schlittenlacher J, 2016, J ACOUST SOC AM, V140, P3487, DOI 10.1121/1.4966117
   Sek A, 2015, J ACOUST SOC AM, V138, P1143, DOI 10.1121/1.4928135
   Sergeyenko Y, 2013, J NEUROSCI, V33, P13686, DOI 10.1523/JNEUROSCI.1783-13.2013
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Soros P, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-34
   SOUZA PE, 1994, J SPEECH HEAR RES, V37, P655, DOI 10.1044/jshr.3703.655
   Specht K, 2014, HEARING RES, V307, P121, DOI 10.1016/j.heares.2013.09.011
   Summers V, 2004, J SPEECH LANG HEAR R, V47, P245, DOI 10.1044/1092-4388(2004/020)
   Vale C, 2002, EUR J NEUROSCI, V16, P2394, DOI 10.1046/j.1460-9568.2002.02302.x
   Van Eeckhoutte M, 2016, HEARING RES, V342, P58, DOI 10.1016/j.heares.2016.09.009
   Vercammen C, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518785733
   Verhulst S, 2016, ADV EXP MED BIOL, V894, P467, DOI 10.1007/978-3-319-25474-6_49
   Wallaert N, 2017, J ACOUST SOC AM, V141, P971, DOI 10.1121/1.4976080
   Wang XQ, 2005, NATURE, V435, P341, DOI 10.1038/nature03565
   Wang YD, 2012, J NEUROPHYSIOL, V107, P2033, DOI 10.1152/jn.00310.2011
   World Health Organization, 2012, WHO GLOB EST PREV HE
   Zhong ZW, 2014, HEARING RES, V309, P55, DOI 10.1016/j.heares.2013.11.006
NR 89
TC 6
Z9 6
U1 0
U2 3
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0197-4580
EI 1558-1497
J9 NEUROBIOL AGING
JI Neurobiol. Aging
PD FEB
PY 2019
VL 74
BP 202
EP 212
DI 10.1016/j.neurobiolaging.2018.10.008
PG 11
WC Geriatrics & Gerontology; Neurosciences
SC Geriatrics & Gerontology; Neurosciences & Neurology
GA HG7SG
UT WOS:000455193900019
PM 30472387
DA 2021-02-24
ER

PT J
AU Somers, B
   Verschueren, E
   Francart, T
AF Somers, Ben
   Verschueren, Eline
   Francart, Tom
TI Neural tracking of the speech envelope in cochlear implant users
SO JOURNAL OF NEURAL ENGINEERING
LA English
DT Article
DE cochear implants; signal processing; electroencephalography (EEG);
   speech; stimulus reconstruction; stimulation artifacts
ID AUDITORY-EVOKED POTENTIALS; STEADY-STATE RESPONSES; STIMULATION
   ARTIFACTS; EEG; REPRESENTATION; ENTRAINMENT; FREQUENCY; CORTEX; FILTER
AB Objective. When listening to speech, the brain tracks the speech envelope. It is possible to reconstruct this envelope from EEG recordings. However, in people who hear using a cochlear implant (CI), the artifacts caused by electrical stimulation of the auditory nerve contaminate the EEG. The objective of this study is to develop and validate a method for assessing the neural tracking of speech envelope in CI users. Approach. To obtain EEG recordings free of stimulus artifacts, the electrical stimulation is periodically interrupted. During these stimulation gaps, artifact-free EEG can be sampled and used to train a linear envelope decoder. EEG recordings obtained during audible and inaudible (i.e. sub-threshold) stimulation were used to characterize the artifacts and their influence on the envelope reconstruction. Main results. The present study demonstrates for the first time that neural tracking of the speech envelope can be measured in response to ongoing electrical stimulation. The responses were validated to be truly neural and not affected by stimulus artifact. Significance. Besides applications in audiology and neuroscience, the characterization and elimination of stimulus artifacts will enable future EEG studies involving continuous speech in CI users. Measures of neural tracking of the speech envelope reflect interesting properties of the listener's perception of speech, such as speech intelligibility or attentional state. Successful decoding of neural envelope tracking will open new possibilities to investigate the neural mechanisms of speech perception with a CI.
C1 [Somers, Ben; Verschueren, Eline; Francart, Tom] Univ Leuven, KU Leuven, Dept Neurosci, Expt Otorhinolaryngol, Leuven, Belgium.
RP Somers, B (corresponding author), Univ Leuven, KU Leuven, Dept Neurosci, Expt Otorhinolaryngol, Leuven, Belgium.
EM ben.somers@med.kuleuven.be
OI Verschueren, Eline/0000-0001-5544-6091; Somers, Ben/0000-0002-4997-4602
FU Research Foundation Flanders (FWO)FWO [1S46117N, 1S86118N]; KU Leuven
   Special Research Fund [OT/14/119]; European Research Council
   (ERC)European Research Council (ERC) [637424]
FX This project has received funding from SB PhD grants of the Research
   Foundation Flanders (FWO) awarded to Ben Somers (1S46117N) and Eline
   Verschueren (1S86118N), from the KU Leuven Special Research Fund
   (OT/14/119), and from the European Research Council (ERC) under the
   European Unions Horizon 2020 research and innovation programme starting
   grant to Tom Francart (637424).
CR Aiken SJ, 2008, EAR HEARING, V29, P139, DOI 10.1097/AUD.0b013e31816453dc
   Bertrand A, 2015, IEEE T NEUR SYS REH, V23, P923, DOI 10.1109/TNSRE.2015.2418351
   Biesmans W, 2017, IEEE T NEUR SYS REH, V25, P402, DOI 10.1109/TNSRE.2016.2571900
   Brodbeck C, 2018, BIORXIV 326785
   Crosse MJ, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00604
   Debener S, 2015, SCI REP-UK, V5, DOI 10.1038/srep16743
   Deprez H, 2017, IEEE T NEUR SYS REH, V25, P1322, DOI 10.1109/TNSRE.2016.2622979
   Deprez H, 2017, BIOMED SIGNAL PROCES, V31, P127, DOI 10.1016/j.bspc.2016.07.013
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Ding N, 2013, J NEUROSCI, V33, P5728, DOI 10.1523/JNEUROSCI.5297-12.2013
   Ding N, 2012, J NEUROPHYSIOL, V107, P78, DOI 10.1152/jn.00297.2011
   Francart T, 2008, J NEUROSCI METH, V172, P283, DOI 10.1016/j.jneumeth.2008.04.020
   Friesen LM, 2010, HEARING RES, V259, P95, DOI 10.1016/j.heares.2009.10.012
   Gilley PM, 2006, CLIN NEUROPHYSIOL, V117, P1772, DOI 10.1016/j.clinph.2006.04.018
   Gransier R, 2016, HEARING RES, V335, P149, DOI 10.1016/j.heares.2016.03.006
   Hofmann M, 2010, JARO-J ASSOC RES OTO, V11, P267, DOI 10.1007/s10162-009-0201-z
   Looney D, 2012, IEEE PULSE, V3, P32, DOI 10.1109/MPUL.2012.2216717
   Luke R, 2017, IEEE T NEUR SYS REH, V25, P196, DOI 10.1109/TNSRE.2016.2551302
   Martin BA, 2007, J AM ACAD AUDIOL, V18, P126, DOI 10.3766/jaaa.18.2.5
   Mc Laughlin M, 2013, HEARING RES, V302, P84, DOI 10.1016/j.heares.2013.05.006
   Mc Laughlin M, 2012, IEEE T NEUR SYS REH, V20, P443, DOI 10.1109/TNSRE.2012.2186982
   O'Sullivan J, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa7ab4
   O'Sullivan JA, 2015, CEREB CORTEX, V25, P1697, DOI 10.1093/cercor/bht355
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Petersen EB, 2017, J NEUROPHYSIOL, V117, P18, DOI 10.1152/jn.00527.2016
   Presacco A, 2016, J NEUROPHYSIOL, V116, P2346, DOI 10.1152/jn.00372.2016
   Sandmann P, 2009, BRAIN, V132, P1967, DOI 10.1093/brain/awp034
   Somers B, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aaac92
   Sondergaard PL, 2013, TECHNOLOGY BINAURAL, P33, DOI DOI 10.1007/978-3-642-37762-4_2
   Swanson B, 2006, NUCLEUS MATLAB TOOLB
   Van Eyndhoven S, 2017, IEEE T BIO-MED ENG, V64, P1045, DOI 10.1109/TBME.2016.2587382
   van Wieringen A, 2008, INT J AUDIOL, V47, P348, DOI 10.1080/14992020801895144
   Vanthornhout J, 2018, JARO-J ASSOC RES OTO, V19, P181, DOI 10.1007/s10162-018-0654-z
   Viola FC, 2011, PSYCHOPHYSIOLOGY, V48, P1470, DOI 10.1111/j.1469-8986.2011.01224.x
   Wouters J, 2015, IEEE SIGNAL PROC MAG, V32, P67, DOI 10.1109/MSP.2014.2371671
NR 35
TC 7
Z9 7
U1 1
U2 12
PU IOP PUBLISHING LTD
PI BRISTOL
PA TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND
SN 1741-2560
EI 1741-2552
J9 J NEURAL ENG
JI J. Neural Eng.
PD FEB
PY 2019
VL 16
IS 1
AR 016003
DI 10.1088/1741-2552/aae6b9
PG 13
WC Engineering, Biomedical; Neurosciences
SC Engineering; Neurosciences & Neurology
GA HA5KY
UT WOS:000450311900003
PM 30444216
DA 2021-02-24
ER

PT J
AU Thornton, D
   Harkrider, AW
   Jenson, DE
   Saltuklaroglu, T
AF Thornton, David
   Harkrider, Ashley W.
   Jenson, David E.
   Saltuklaroglu, Tim
TI Sex differences in early sensorimotor processing for speech
   discrimination
SO SCIENTIFIC REPORTS
LA English
DT Article
ID BETA-BAND OSCILLATIONS; EEG MU RHYTHM; ALPHA OSCILLATIONS; AUDIOVISUAL
   SPEECH; FUNCTIONAL NEUROANATOMY; CORTICAL ACTIVATION; INHIBITORY
   CONTROL; FMRI; PERCEPTION; GENDER
AB Sensorimotor activity in speech perception tasks varies as a function of context, cognitive load, and cognitive ability. This study investigated listener sex as an additional variable. Raw EEG data were collected as 21 males and 21 females discriminated /ba/ and /da/ in quiet and noisy backgrounds. Independent component analyses of data from accurately discriminated trials identified sensorimotor mu components with characteristic alpha and beta peaks from 16 members of each sex. Time-frequency decompositions showed that in quiet discrimination, females displayed stronger early mu-alpha synchronization, whereas males showed stronger mu-beta desynchronization. Findings indicate that early attentional mechanisms for speech discrimination were characterized by sensorimotor inhibition in females and predictive sensorimotor activation in males. Both sexes showed stronger early sensorimotor inhibition in noisy discrimination conditions versus in quiet, suggesting sensory gating of the noise. However, the difference in neural activation between quiet and noisy conditions was greater in males than females. Though sex differences appear unrelated to behavioral accuracy, they suggest that males and females exhibit early sensorimotor processing for speech discrimination that is fundamentally different, yet similarly adaptable to adverse conditions. Findings have implications for understanding variability in neuroimaging data and the male prevalence in various neurodevelopmental disorders with inhibitory dysfunction.
C1 [Thornton, David] Gallaudet Univ, Washington, DC 20002 USA.
   [Harkrider, Ashley W.; Saltuklaroglu, Tim] Univ Tennessee, Hlth Sci Ctr, Knoxville, TN 37996 USA.
   [Jenson, David E.] Washington State Univ, Elson S Floyd Coll Med, Spokane, WA 99202 USA.
RP Thornton, D (corresponding author), Gallaudet Univ, Washington, DC 20002 USA.
EM David.Thornton@Gallaudet.edu
OI Jenson, David/0000-0001-5744-0910
CR Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Band GPH, 1999, ACTA PSYCHOL, V101, P179, DOI 10.1016/S0001-6918(99)00005-0
   Baron-Cohen S, 2011, PLOS BIOL, V9, DOI 10.1371/journal.pbio.1001081
   Benjamini Y, 2000, J EDUC BEHAV STAT, V25, P60, DOI 10.3102/10769986025001060
   Berends HI, 2013, EXP BRAIN RES, V229, P337, DOI 10.1007/s00221-013-3571-8
   Bonstrup M, 2015, FRONT AGING NEUROSCI, V7, DOI 10.3389/fnagi.2015.00193
   Bonnefond M, 2012, CURR BIOL, V22, P1969, DOI 10.1016/j.cub.2012.08.029
   Bosco A, 2004, APPL COGNITIVE PSYCH, V18, P519, DOI 10.1002/acp.1000
   Bowers A., 2013, PLOS ONE, V8
   Brinkman L, 2014, J NEUROSCI, V34, P14783, DOI 10.1523/JNEUROSCI.2039-14.2014
   Burton MW, 2006, CORTEX, V42, P644, DOI 10.1016/S0010-9452(08)70400-3
   Callan D, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00275
   Callan D, 2010, NEUROIMAGE, V51, P844, DOI 10.1016/j.neuroimage.2010.02.027
   Cheng C, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001989
   Cheyne DO, 2013, EXP NEUROL, V245, P27, DOI 10.1016/j.expneurol.2012.08.030
   Cogan GB, 2014, NATURE, V507, P94, DOI 10.1038/nature12935
   COMINGS DE, 1985, AM J HUM GENET, V37, P435
   Cuellar M, 2016, CLIN NEUROPHYSIOL, V127, P2625, DOI 10.1016/j.clinph.2016.04.027
   Daliri A, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12521
   Daliri A, 2015, BRAIN LANG, V150, P37, DOI 10.1016/j.bandl.2015.08.008
   de Lange FP, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.007.2008
   Delorme A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0030135
   Dillon DG, 2007, APPL PREV PSYCHOL, V12, P99, DOI 10.1016/j.appsy.2007.09.004
   Duff SJ, 2001, BRAIN COGNITION, V47, P470, DOI 10.1006/brcg.2001.1326
   Etchell A, 2018, NEUROPSYCHOLOGIA, V114, P19, DOI 10.1016/j.neuropsychologia.2018.04.011
   Evans KL, 2015, BRAIN COGNITION, V93, P42, DOI 10.1016/j.bandc.2014.11.006
   Formaggio E, 2010, MAGN RESON IMAGING, V28, P1403, DOI 10.1016/j.mri.2010.06.030
   Fox NA, 2016, PSYCHOL BULL, V142, P291, DOI 10.1037/bul0000031
   Foxe JJ, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00154
   Francisco S., 1986, J CLIN PSYCHOL, V1
   Fujioka T, 2015, J NEUROSCI, V35, P15187, DOI 10.1523/JNEUROSCI.2397-15.2015
   Georgiev S., 2011, INT J BIOAUTOMATION, V15, P33
   Gola M, 2013, INT J PSYCHOPHYSIOL, V89, P334, DOI 10.1016/j.ijpsycho.2013.05.007
   Goldman RI, 2002, NEUROREPORT, V13, P2487, DOI 10.1097/00001756-200212200-00022
   Graimann B, 2006, PROG BRAIN RES, V159, P79, DOI 10.1016/S0079-6123(06)59006-5
   Grin-Yatsenko VA, 2010, CLIN NEUROPHYSIOL, V121, P281, DOI 10.1016/j.clinph.2009.11.015
   Gur RC, 1999, J NEUROSCI, V19, P4065
   Gur RC, 2000, BRAIN LANG, V74, P157, DOI 10.1006/brln.2000.2325
   Haegens S, 2012, J COGNITIVE NEUROSCI, V24, P677, DOI 10.1162/jocn_a_00164
   Haegens S, 2011, J NEUROSCI, V31, P5197, DOI 10.1523/JNEUROSCI.5199-10.2011
   Hansen S, 2011, BRAIN COGNITION, V76, P364, DOI 10.1016/j.bandc.2011.04.004
   Hanslmayr S, 2011, BRAIN RES REV, V67, P331, DOI 10.1016/j.brainresrev.2011.04.002
   Hari R, 2006, PROG BRAIN RES, V159, P253, DOI 10.1016/S0079-6123(06)59017-X
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hyde JS, 2016, CURR OPIN NEUROBIOL, V38, P53, DOI 10.1016/j.conb.2016.02.007
   Ingalhalikar M, 2014, P NATL ACAD SCI USA, V111, P823, DOI 10.1073/pnas.1316909110
   Jensen O, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00186
   Jenson D, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00534
   Jenson D, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00656
   Kikuchi Y, 2011, NEUROIMAGE, V55, P891, DOI 10.1016/j.neuroimage.2010.12.083
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Klimesch W, 2007, BRAIN RES REV, V53, P63, DOI 10.1016/j.brainresrev.2006.06.003
   Klimesch W, 2012, TRENDS COGN SCI, V16, P606, DOI 10.1016/j.tics.2012.10.007
   Kuhl PK, 2005, LANG LEARN DEV, V1, P237, DOI 10.1080/15475441.2005.9671948
   Kuptsova S. V., 2015, Human Physiology, V41, P611, DOI 10.1134/S0362119715050084
   Laufs H, 2003, NEUROIMAGE, V19, P1463, DOI 10.1016/S1053-8119(03)00286-6
   Leisman G, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00016
   Li RN, 2014, J SPORT HEALTH SCI, V3, P155, DOI 10.1016/j.jshs.2014.03.012
   LoCasto PC, 2004, J COGNITIVE NEUROSCI, V16, P1612, DOI 10.1162/0898929042568433
   Lundqvist M, 2016, NEURON, V90, P152, DOI 10.1016/j.neuron.2016.02.028
   Makeig S, 2004, TRENDS COGN SCI, V8, P204, DOI 10.1016/j.tics.2004.03.008
   Montag C, 2015, EARLY HUM DEV, V91, P43, DOI 10.1016/j.earlhumdev.2014.11.003
   Moosmann M, 2003, NEUROIMAGE, V20, P145, DOI 10.1016/S1053-8119(03)00344-6
   Mullinger KJ, 2014, NEUROIMAGE, V94, P263, DOI 10.1016/j.neuroimage.2014.02.029
   Murphy JW, 2014, AUTISM RES, V7, P442, DOI 10.1002/aur.1374
   Neuhaus AH, 2009, HUM BRAIN MAPP, V30, P2997, DOI 10.1002/hbm.20724
   Ojanen V, 2005, NEUROIMAGE, V25, P333, DOI 10.1016/j.neuroimage.2004.12.001
   Okun M, 2008, NAT NEUROSCI, V11, P535, DOI 10.1038/nn.2105
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Oostenveld R, 2002, HUM BRAIN MAPP, V17, P179, DOI 10.1002/hbm.10061
   Pascual-Marqui R. D., 2002, METHOD FIND EXP CLIN, V1-16, P841
   Pavlova MA, 2015, CEREB CORTEX, V25, P3468, DOI 10.1093/cercor/bhu175
   Pekkola J, 2006, NEUROIMAGE, V29, P797, DOI 10.1016/j.neuroimage.2005.09.069
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   Pineda J, 2005, BRAIN RES REV
   Pineda JA, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00203
   Popovich C, 2010, NEUROPSYCHOLOGIA, V48, P4102, DOI 10.1016/j.neuropsychologia.2010.10.016
   Pulvermuller F, 2013, TRENDS COGN SCI, V17, P458, DOI 10.1016/j.tics.2013.06.004
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Quandt LC, 2012, NEUROPSYCHOLOGIA, V50, P2745, DOI 10.1016/j.neuropsychologia.2012.08.005
   Ramos-Loyo J, 2016, NEUROPSYCHOLOGIA, V91, P290, DOI 10.1016/j.neuropsychologia.2016.08.023
   Rauschecker J. P, 2012, FRONT EVOL NEUROSCI, V4, P5
   Ritter P, 2009, HUM BRAIN MAPP, V30, P1168, DOI 10.1002/hbm.20585
   Ruigrok ANV, 2014, NEUROSCI BIOBEHAV R, V39, P34, DOI 10.1016/j.neubiorev.2013.12.004
   Saleh M, 2010, NEURON, V65, P461, DOI 10.1016/j.neuron.2010.02.001
   Saltuklaroglu T, 2017, NEUROIMAGE, V153, P232, DOI 10.1016/j.neuroimage.2017.04.022
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Schnitzler A, 2000, ACTA NEUROBIOL EXP, V60, P271
   Schomers MR, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00435
   Schroeder CE, 2010, CURR OPIN NEUROBIOL, V20, P172, DOI 10.1016/j.conb.2010.02.010
   Sengupta R, 2016, NEUROPSYCHOLOGIA, V93, P242, DOI 10.1016/j.neuropsychologia.2016.11.004
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Specht K, 2014, HEARING RES, V307, P121, DOI 10.1016/j.heares.2013.09.011
   Steffensen SC, 2008, VISION RES, V48, P917, DOI 10.1016/j.visres.2008.01.005
   Strauss A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00350
   Szenkovits G, 2012, NEUROPSYCHOLOGIA, V50, P1380, DOI 10.1016/j.neuropsychologia.2012.02.023
   Thornton D, 2018, BRAIN LANG, V187, P62, DOI 10.1016/j.bandl.2017.03.011
   TOWLE VL, 1993, ELECTROEN CLIN NEURO, V86, P1, DOI 10.1016/0013-4694(93)90061-Y
   Venezia J. H., 2012, FRONT PSYCHOL, V3, P1
   Vollebregt MA, 2016, CLIN NEUROPHYSIOL, V127, P2182, DOI 10.1016/j.clinph.2016.01.021
   Wade AR, 2002, NEURON, V36, P993, DOI 10.1016/S0896-6273(02)01138-8
   Weiss EM, 2003, PERS INDIV DIFFER, V35, P863, DOI 10.1016/S0191-8869(02)00288-X
   Weisz N, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00073
   Xu ZC, 2015, NEUROMOL MED, V17, P1, DOI 10.1007/s12017-014-8338-2
   Yang J., 2016, MULTIMED TOOLS APPL, P1
   Yuan JJ, 2008, PSYCHOPHYSIOLOGY, V45, P986, DOI 10.1111/j.1469-8986.2008.00693.x
   Zaepffel M., 2012, UPS DOWNS BETA OSCIL, DOI [10.1016/j.expneurol.2012.09.014, DOI 10.1016/J.EXPNEUROL.2012.09.014]
   Zagni Emanuela, 2016, Neurosci J, V2016, P2827090, DOI 10.1155/2016/2827090
   Ziegler JC, 2005, P NATL ACAD SCI USA, V102, P14110, DOI 10.1073/pnas.0504446102
   Ziemann U, 1997, AM J PSYCHIAT, V154, P1277
   Zumer JM, 2014, PLOS BIOL, V12, DOI 10.1371/journal.pbio.1001965
NR 115
TC 2
Z9 2
U1 0
U2 2
PU NATURE RESEARCH
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD JAN 23
PY 2019
VL 9
AR 392
DI 10.1038/s41598-018-36775-5
PG 13
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA HI4AE
UT WOS:000456392400073
PM 30674942
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Stevenson, RA
   Philipp-Muller, A
   Hazlett, N
   Wang, ZY
   Luk, J
   Lee, J
   Black, KR
   Yeung, LK
   Shafai, F
   Segers, M
   Feber, S
   Barense, MD
AF Stevenson, Ryan A.
   Philipp-Muller, Aviva
   Hazlett, Naomi
   Wang, Ze Y.
   Luk, Jessica
   Lee, Jong
   Black, Karen R.
   Yeung, Lok-Kin
   Shafai, Fakhri
   Segers, Magali
   Feber, Susanne
   Barense, Morgan D.
TI Conjunctive Visual Processing Appears Abnormal in Autism
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE face processing; autism spectrum disorder; visual processing; sensory;
   vision; holistic; object recognition
ID MULTISENSORY SPEECH-PERCEPTION; RESOLVES FEATURE AMBIGUITY; FACE
   RECOGNITION; SPECTRUM DISORDERS; FUNCTIONING AUTISM; CHILDREN;
   DISCRIMINATION; SPECIALIZATION; INTEGRATION; INVERSION
AB Face processing in autism spectrum disorder (ASD) is thought to be atypical, but it is unclear whether differences in visual conjunctive processing are specific to faces. To address this, we adapted a previously established eye-tracking paradigm which modulates the need for conjunctive processing by varying the degree of feature ambiguity in faces and objects. Typically-developed (TD) participants showed a canonical pattern of conjunctive processing: High-ambiguity objects were processed more conjunctively than low-ambiguity objects, and faces were processed in an equally conjunctive manner regardless of ambiguity level. In contrast, autistic individuals did not show differences in conjunctive processing based on stimulus category, providing evidence that atypical visual conjunctive processing in ASD is the result of a domain general lack of perceptual specialization.
C1 [Stevenson, Ryan A.] Western Univ, Dept Psychol, London, ON, Canada.
   [Stevenson, Ryan A.; Shafai, Fakhri] Western Univ, Brain & Mind Inst, London, ON, Canada.
   [Stevenson, Ryan A.] Western Univ, Schulich Sch Med & Dent, Dept Psychiat, London, ON, Canada.
   [Stevenson, Ryan A.] Western Univ, Schulich Sch Med & Dent, Neurosci Program, London, ON, Canada.
   [Stevenson, Ryan A.] York Univ, Ctr Vis Res, Toronto, ON, Canada.
   [Philipp-Muller, Aviva] Ohio State Univ, Dept Psychol, Columbus, OH USA.
   [Hazlett, Naomi] Coll Occupat Therapists Ontario, Toronto, ON, Canada.
   [Wang, Ze Y.; Luk, Jessica; Lee, Jong; Yeung, Lok-Kin; Feber, Susanne; Barense, Morgan D.] Univ Toronto, Dept Psychol, Toronto, ON, Canada.
   [Black, Karen R.; Segers, Magali] York Univ, Dept Psychol, Toronto, ON, Canada.
   [Feber, Susanne; Barense, Morgan D.] Rotman Res Inst Baycrest, Toronto, ON, Canada.
RP Stevenson, RA (corresponding author), Western Univ, Dept Psychol, London, ON, Canada.; Stevenson, RA (corresponding author), Western Univ, Brain & Mind Inst, London, ON, Canada.; Stevenson, RA (corresponding author), Western Univ, Schulich Sch Med & Dent, Dept Psychiat, London, ON, Canada.; Stevenson, RA (corresponding author), Western Univ, Schulich Sch Med & Dent, Neurosci Program, London, ON, Canada.; Stevenson, RA (corresponding author), York Univ, Ctr Vis Res, Toronto, ON, Canada.
EM rsteve28@uwo.ca
RI Black, Karen R./AAD-1427-2019
OI Black, Karen R./0000-0002-7601-3700; Yeung, Lok-Kin/0000-0002-6687-0282
FU Western University Faculty Development Research Fund; Social Sciences
   and Humanities Research Council of Canada (SSHRC)Social Sciences and
   Humanities Research Council of Canada (SSHRC)CGIAR [R5502A07]; Natural
   Sciences and Engineering Research Council of CanadaNatural Sciences and
   Engineering Research Council of Canada (NSERC)CGIAR [NSERC 17-04656];
   Ontario Early Researcher AwardMinistry of Research and Innovation,
   Ontario; Canada Foundation for Innovation's John R. Evans Leaders Fund;
   Western Brain and Mind Institute postdoctoral fellowship; Natural
   Sciences and Engineering Research Council (NSERC)Natural Sciences and
   Engineering Research Council of Canada (NSERC) [216203-13]; Canadian
   Institutes of Health Research (CIHR)Canadian Institutes of Health
   Research (CIHR) [106436]; Canada Research Chairs ProgramCanada Research
   Chairs; James S. McDonnell Scholar Award; Canadian Institutes of Health
   ResearchCanadian Institutes of Health Research (CIHR) [MOP-115148]
FX RS is supported by the Western University Faculty Development Research
   Fund, a Social Sciences and Humanities Research Council of Canada
   (SSHRC) Insight grant (R5502A07), a Natural Sciences and Engineering
   Research Council of Canada (NSERC 17-04656) Discovery Grant, an Ontario
   Early Researcher Award, and the Canada Foundation for Innovation's John
   R. Evans Leaders Fund. FS is funded through a Western Brain and Mind
   Institute postdoctoral fellowship. SF is funded through a Natural
   Sciences and Engineering Research Council (NSERC) Grant (216203-13) and
   Canadian Institutes of Health Research (CIHR) Grant (106436). MB is
   supported by the Canada Research Chairs Program, a James S. McDonnell
   Scholar Award, and the Canadian Institutes of Health Research
   (MOP-115148).
CR Barense MD, 2005, J NEUROSCI, V25, P10239, DOI 10.1523/JNEUROSCI.2704-05.2005
   Barense MD, 2007, NEUROPSYCHOLOGIA, V45, P2963, DOI 10.1016/j.neuropsychologia.2007.05.023
   Barense MD, 2012, NEURON, V75, P157, DOI 10.1016/j.neuron.2012.05.014
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Bartko SJ, 2007, LEARN MEMORY, V14, P821, DOI 10.1101/lm.749207
   Baum SH, 2015, PROG NEUROBIOL, V134, P140, DOI 10.1016/j.pneurobio.2015.09.007
   Bebko JM, 2006, J CHILD PSYCHOL PSYC, V47, P88, DOI 10.1111/j.1469-7610.2005.01443.x
   Behrmann M, 2006, NEUROPSYCHOLOGIA, V44, P110, DOI 10.1016/j.neuropsychologia.2005.04.002
   Behrmann M., 2015, OXFORD HDB PERCEPTUA, P758, DOI [DOI 10.1093/OXFORDHB/9780199686858.013.010, 10.1093/oxfordhb/9780199686858.013.010]
   Bussey TJ, 2005, Q J EXP PSYCHOL-B, V58, P269, DOI 10.1080/02724990544000004
   Bussey TJ, 2002, EUR J NEUROSCI, V15, P365, DOI 10.1046/j.0953-816x.2001.01851.x
   de Boer-Schellekens L, 2013, FRONT INTEGR NEUROSC, V7, DOI 10.3389/fnint.2013.00008
   Erez J, 2013, NEUROPSYCHOLOGIA, V51, P168, DOI 10.1016/j.neuropsychologia.2012.11.003
   Faja S, 2009, J AUTISM DEV DISORD, V39, P532, DOI 10.1007/s10803-008-0635-x
   Hadad BS, 2017, AUTISM RES, V10, P1510, DOI 10.1002/aur.1800
   Happe F, 1999, TRENDS COGN SCI, V3, P216, DOI 10.1016/S1364-6613(99)01318-2
   Happe F, 2006, J AUTISM DEV DISORD, V36, P5, DOI 10.1007/s10803-005-0039-0
   Herrington JD, 2015, J AUTISM DEV DISORD, V45, P902, DOI 10.1007/s10803-014-2233-4
   HOBSON RP, 1988, BRIT J PSYCHOL, V79, P441, DOI 10.1111/j.2044-8295.1988.tb02745.x
   Johnson MH, 1999, DEV PSYCHOPATHOL, V11, P419, DOI 10.1017/S0954579499002138
   Johnson MH, 2000, CHILD DEV, V71, P75, DOI 10.1111/1467-8624.00120
   Joseph RM, 2003, J CHILD PSYCHOL PSYC, V44, P529, DOI 10.1111/1469-7610.00142
   Lee ACH, 2005, NEUROPSYCHOLOGIA, V43, P1, DOI 10.1016/j.neuropsychologia.2004.07.017
   Morin K, 2015, AUTISM RES, V8, P497, DOI 10.1002/aur.1464
   Mottron L, 2006, J AUTISM DEV DISORD, V36, P27, DOI 10.1007/s10803-005-0040-7
   Mottron L, 2001, DEVELOPMENT OF AUTISM: PERSPECTIVES FROM THEORY AND RESEARCH, P131
   Newsome RN, 2012, HIPPOCAMPUS, V22, P1990, DOI 10.1002/hipo.22071
   Noel JP, 2018, EUR J NEUROSCI, V47, P1230, DOI 10.1111/ejn.13911
   Rose FE, 2007, J AUTISM DEV DISORD, V37, P513, DOI 10.1007/s10803-006-0200-4
   Rossion B, 2008, ACTA PSYCHOL, V128, P274, DOI 10.1016/j.actpsy.2008.02.003
   Stevenson RA, 2018, AUTISM, V22, P609, DOI 10.1177/1362361317704413
   Stevenson RA, 2017, AUTISM RES, V10, P1280, DOI 10.1002/aur.1776
   Stevenson RA, 2016, AUTISM RES, V9, P720, DOI 10.1002/aur.1566
   Stevenson RA, 2014, J AUTISM DEV DISORD, V44, P1470, DOI 10.1007/s10803-013-1992-7
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Tanaka JW, 2016, J AUTISM DEV DISORD, V46, P1538, DOI 10.1007/s10803-013-1976-7
   TANAKA JW, 1993, Q J EXP PSYCHOL-A, V46, P225, DOI 10.1080/14640749308401045
   Taylor N, 2010, J AUTISM DEV DISORD, V40, P1403, DOI 10.1007/s10803-010-1000-4
   Teunisse JP, 2003, BRAIN COGNITION, V52, P285, DOI 10.1016/S0278-2626(03)00042-3
   Van Belle G, 2010, J VISION, V10, DOI 10.1167/10.5.10
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   Weigelt S, 2012, NEUROSCI BIOBEHAV R, V36, P1060, DOI 10.1016/j.neubiorev.2011.12.008
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
NR 43
TC 1
Z9 1
U1 0
U2 6
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD JAN 18
PY 2019
VL 9
AR 2668
DI 10.3389/fpsyg.2018.02668
PG 7
WC Psychology, Multidisciplinary
SC Psychology
GA HH8SA
UT WOS:000456001500001
PM 30713514
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Hillyer, J
   Elkins, E
   Hazlewood, C
   Watson, SD
   Arenberg, JG
   Parbery-Clark, A
AF Hillyer, Jake
   Elkins, Elizabeth
   Hazlewood, Chantel
   Watson, Stacey D.
   Arenberg, Julie G.
   Parbery-Clark, Alexandra
TI Assessing Cognitive Abilities in High-Performing Cochlear Implant Users
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE cochlear implant; cognitive skills; speech perception; clinical outcome;
   working memory
ID QUALITY-OF-LIFE; SPOKEN WORD RECOGNITION; WORKING-MEMORY; SPEECH
   RECOGNITION; HEARING-LOSS; ADULTS; PREDICTORS; COMPREHENSION;
   PERCEPTION; BENEFIT
AB Despite being considered one of the most successful neural prostheses, cochlear implants (Cls) provide recipients with a wide range of speech perception performance. While some CI users can understand speech in the absence of visual cues, other recipients exhibit more limited speech perception. Cognitive skills have been documented as a contributor to complex auditory processing, such as language understanding; however, there are no normative data for existing standardized clinical tests assessing cognitive abilities in CI users. Here, we assess the impact of modality of presentation (i.e., auditory-visual versus visual) for the administration of working memory tests in high-performing CI users in addition to measuring processing speed, cognitive efficiency and intelligence quotient (IQ). Second, we relate performance on these cognitive measures to clinical CI speech perception outcomes.
   Methods: Twenty one post-lingually deafened, high-performing, adult CI users [age range: 52-88 years; 3 unilateral CI, 13 bimodal (i.e., CI with contralateral hearing aid), 5 bilateral CI] with clinical speech perception scores (i.e., AzBio sentences in quiet for the first-ear CI) of >= 60% were recruited. A cognitive test battery assessing auditory-visual working memory (AVWM), visual working memory (VWM), processing speed, cognitive efficiency and IQ was administered, in addition to clinical measures of speech perception in quiet (i.e., AzBio sentences in quiet). AzBio sentences were assessed in two conditions: first-ear CI only, and best-aided everyday wearing condition. Subjects also provided self-reported measures of performance and benefit from their CI using standardized materials, including the Glasgow Benefit Inventory (GBI) and the Nijmegen Cochlear Implant questionnaire (NCIQ).
   Results: High-performing CI users demonstrated greater VWM than AVWM recall. VWM was positively related to AzBio scores when measured in the first-ear CI only. AVWM, processing speed, cognitive efficiency, and IQ did not relate to either measure of speech perception (i.e., first-ear CI or best-aided conditions). Subjects' self-reported benefit as measured by the GBI predicted best-aided CI speech perception performance.
   Conclusion: In high-performing CI recipients, visual presentation of working memory tests may improve our assessment of cognitive function.
C1 [Hillyer, Jake] Oregon Hlth & Sci Univ, Sch Med, Portland, OR 97201 USA.
   [Elkins, Elizabeth; Hazlewood, Chantel; Watson, Stacey D.; Parbery-Clark, Alexandra] Swedish Neurosci Inst, Auditory Res Lab, Ctr Hearing & Skull Base Surg, Seattle, WA 98122 USA.
   [Arenberg, Julie G.] Harvard Med Sch, Massachusetts Eye & Ear Infirm, Dept Otolaryngol, Boston, MA USA.
RP Parbery-Clark, A (corresponding author), Swedish Neurosci Inst, Auditory Res Lab, Ctr Hearing & Skull Base Surg, Seattle, WA 98122 USA.
EM Alexandra.Parbery-Clarke@swedish.org
OI Parbery-Clark, Alexandra/0000-0002-9485-4095
FU Swedish Neuroscience Institute
FX The authors wish to thank the patients who donated their valuable time,
   the Swedish Neuroscience Institute for supporting this study, and
   Jennifer Parada for her contributions to statistical analysis.
CR Ahissar M, 2009, PHILOS T R SOC B, V364, P285, DOI 10.1098/rstb.2008.0253
   Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Arlinger S, 2009, SCAND J PSYCHOL, V50, P371, DOI 10.1111/j.1467-9450.2009.00753.x
   Auditory Potential LLC, 2011, MIN SPEECH TEST BATT
   Barone P, 2011, SPRINGER HANDB AUDIT, V39, P365, DOI 10.1007/978-1-4419-9434-9_15
   Baskent D, 2012, JARO-J ASSOC RES OTO, V13, P683, DOI 10.1007/s10162-012-0334-3
   Blamey P, 1996, Audiol Neurootol, V1, P293
   Brown L., 2010, TONI 4 TEST NONVERBA
   Capretta NR, 2016, LARYNGOSCOPE, V126, P699, DOI 10.1002/lary.25525
   Collison EA, 2004, J SPEECH LANG HEAR R, V47, P496, DOI 10.1044/1092-4388(2004/039)
   Corp I, 2013, IBM SPSS STAT WIND V
   Daneman M, 1996, PSYCHON B REV, V3, P422, DOI 10.3758/BF03214546
   Dawson P W, 2002, Cochlear Implants Int, V3, P126, DOI 10.1179/cim.2002.3.2.126
   Doucet ME, 2006, BRAIN, V129, P3376, DOI 10.1093/brain/awl264
   Dowell RC, 2012, EVIDENCE BASED PRACT, P141
   Dupuis K, 2015, AGING NEUROPSYCHOL C, V22, P413, DOI 10.1080/13825585.2014.968084
   Fabry D, 2009, AUDIOL TODAY, V21, P36
   Field A., 2013, DISCOVERING STAT USI
   Fullgrabe C, 2016, ADV EXP MED BIOL, V894, P29, DOI 10.1007/978-3-319-25474-6_4
   Gajadeera EA, 2017, EAR HEARING, V38, P357, DOI 10.1097/AUD.0000000000000405
   GANTZ BJ, 1993, ANN OTO RHINOL LARYN, V102, P909, DOI 10.1177/000348949310201201
   Gatehouse S, 2006, INT J AUDIOL, V45, P130, DOI 10.1080/14992020500429518
   Gifford RH, 2008, AUDIOL NEURO-OTOL, V13, P193, DOI 10.1159/000113510
   Henkin Y, 2014, AUDIOL NEURO-OTOL, V19, P21, DOI 10.1159/000371602
   Herzog M, 2003, LARYNGO RHINO OTOL, V82, P490
   Heydebrand G, 2007, AUDIOL NEURO-OTOL, V12, P254, DOI 10.1159/000101473
   Hinderink JB, 2000, OTOLARYNG HEAD NECK, V123, P756, DOI 10.1067/mhn.2000.108203
   Ho EC, 2009, OTOL NEUROTOL, V30, P891, DOI 10.1097/MAO.0b013e3181b4ec6f
   Holden LK, 2013, EAR HEARING, V34, P342, DOI 10.1097/AUD.0b013e3182741aa7
   Houtgast T, 2008, INT J AUDIOL, V47, P287, DOI 10.1080/14992020802127109
   Hua H, 2017, J SPEECH LANG HEAR R, V60, P2752, DOI 10.1044/2017_JSLHR-H-16-0276
   Humes LE, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00055
   Lazard DS, 2012, EUR ANN OTORHINOLARY, V129, P98, DOI 10.1016/j.anorl.2011.06.001
   Lazard DS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048739
   Lenarz M, 2012, LARYNGOSCOPE, V122, P1361, DOI 10.1002/lary.23232
   Lunner T, 2007, J AM ACAD AUDIOL, V18, P604, DOI 10.3766/jaaa.18.7.7
   Lyxell B, 1998, SCAND J PSYCHOL, V39, P175, DOI 10.1111/1467-9450.393075
   Mather N, 2014, W JOHNSON 4 TESTS CO
   McGrew K. S., 2014, W JOHNSON 4 TECHNICA
   McRackan TR, 2018, LARYNGOSCOPE, V128, P982, DOI 10.1002/lary.26738
   Moberly AC, 2018, LARYNGOSCOPE, V128, P959, DOI 10.1002/lary.26791
   Moberly AC, 2018, OTOL NEUROTOL, V39, pE195, DOI 10.1097/MAO.0000000000001694
   Moberly AC, 2017, LARYNGOSCOPE INVEST, V2, P254, DOI 10.1002/lio2.90
   Moberly AC, 2017, J SPEECH LANG HEAR R, V60, P1046, DOI 10.1044/2016_JSLHR-H-16-0119
   Moberly AC, 2018, WORLD J OTORHINOLARY, V3, P224, DOI DOI 10.1016/J.WJ0RL.2017.12.003
   Mosnier I, 2015, JAMA OTOLARYNGOL, V141, P442, DOI 10.1001/jamaoto.2015.129
   Olze H, 2012, LARYNGOSCOPE, V122, P196, DOI 10.1002/lary.22356
   Olze H, 2011, LARYNGOSCOPE, V121, P2220, DOI 10.1002/lary.22145
   Pichora-Fuller K., 2006, HEARING CARE ADULTS, P71
   Pichora-Fuller M Kathleen, 2006, Trends Amplif, V10, P29, DOI 10.1177/108471380601000103
   Pichora-Fuller MK, 2016, EAR HEARING, V37, p5S, DOI 10.1097/AUD.0000000000000312
   Pichora-Fuller Margaret Kathleen, 2006, Seminars in Hearing, V27, P284, DOI 10.1055/s-2006-954855
   Pichora-Fuller MK, 2003, INT J AUDIOL, V42, pS26
   Pisoni DB, 2018, EAR HEARING, V39, P720, DOI 10.1097/AUD.0000000000000530
   Pisoni DB, 2003, EAR HEARING, V24, p106S, DOI 10.1097/01.AUD.0000051692.05140.8E
   Pisoni DB, 2000, ANN OTO RHINOL LARYN, V109, P92
   PUNCH JL, 1987, EAR HEARING, V8, P37, DOI 10.1097/00003446-198702000-00007
   Purdy Suzanne Carolyn, 2017, Cochlear Implants Int, V18, P162, DOI 10.1080/14670100.2017.1299393
   Robinson K, 1996, ANN OTO RHINOL LARYN, V105, P415, DOI 10.1177/000348949610500601
   Rouger J, 2007, P NATL ACAD SCI USA, V104, P7295, DOI 10.1073/pnas.0609419104
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   Schrank F. A, 2014, W JOHNSON 4 TESTS CO
   Sharma A, 2016, BRAIN SCI, V6, DOI 10.3390/brainsci6010004
   Smith SL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01394
   Souza PE, 2014, AM J AUDIOL, V23, P394, DOI 10.1044/2014_AJA-14-0006
   Spahr AJ, 2012, EAR HEARING, V33, P112, DOI 10.1097/AUD.0b013e31822c2549
   St Clair-Thompson HL, 2010, EUR J COGN PSYCHOL, V22, P286, DOI 10.1080/09541440902771299
   Stewart R, 2009, J AM ACAD AUDIOL, V20, P147, DOI 10.3766/jaaa.20.2.7
   Strelnikov K, 2010, CEREB CORTEX, V20, P1217, DOI 10.1093/cercor/bhp183
   van Dijk JE, 1999, AUDIOLOGY, V38, P109
   van Eijl RHM, 2017, LARYNGOSCOPE, V127, P476, DOI 10.1002/lary.26154
   VANROOIJ JCGM, 1990, J ACOUST SOC AM, V88, P2611, DOI 10.1121/1.399981
   VERNON PA, 1983, INTELLIGENCE, V7, P53, DOI 10.1016/0160-2896(83)90006-5
   Waters G, 2005, MEMORY, V13, P403, DOI 10.1080/09658210344000459
   WEINSTEIN B E, 1986, Clinical Gerontologist, V4, P3, DOI 10.1300/J018v04n03_02
   Wingfield A, 2007, J AM ACAD AUDIOL, V18, P548, DOI 10.3766/jaaa.18.7.3
   Wingfield A, 2006, J AM ACAD AUDIOL, V17, P487, DOI 10.3766/jaaa.17.7.4
   WOODWARD MF, 1960, J SPEECH HEAR RES, V3, P212, DOI 10.1044/jshr.0303.212
   Zekveld AA, 2011, EAR HEARING, V32, P498, DOI 10.1097/AUD.0b013e31820512bb
NR 79
TC 6
Z9 6
U1 0
U2 5
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
EI 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD JAN 15
PY 2019
VL 12
AR 1056
DI 10.3389/fnins.2018.01056
PG 12
WC Neurosciences
SC Neurosciences & Neurology
GA HH4UF
UT WOS:000455720500001
PM 30713488
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Harding, EE
   Sammler, D
   Henry, MJ
   Large, EW
   Kotz, SA
AF Harding, Eleanor E.
   Sammler, Daniela
   Henry, Molly J.
   Large, Edward W.
   Kotz, Sonja A.
TI Cortical tracking of rhythm in music and speech
SO NEUROIMAGE
LA English
DT Article
DE EEG; Entrainment; Rhythm; Music; Speech; Music training
ID NEURONAL ENTRAINMENT; METRIC STRUCTURE; AUDITORY-CORTEX; N1 WAVE;
   OSCILLATIONS; PERCEPTION; METER; BEAT; TIME; SYNCHRONIZATION
AB Neural activity phase-locks to rhythm in both music and speech. However, the literature currently lacks a direct test of whether cortical tracking of comparable rhythmic structure is comparable across domains. Moreover, although musical training improves multiple aspects of music and speech perception, the relationship between musical training and cortical tracking of rhythm has not been compared directly across domains. We recorded the electroencephalograms (EEG) from 28 participants (14 female) with a range of musical training who listened to melodies and sentences with identical rhythmic structure. We compared cerebral-acoustic coherence (CACoh) between the EEG signal and single-trial stimulus envelopes (as measure of cortical entrainment) across domains and correlated years of musical training with CACoh. We hypothesized that neural activity would be comparably phase-locked across domains, and that the amount of musical training would be associated with increasingly strong phase locking in both domains. We found that participants with only a few years of musical training had a comparable cortical response to music and speech rhythm, partially supporting the hypothesis. However, the cortical response to music rhythm increased with years of musical training while the response to speech rhythm did not, leading to an overall greater cortical response to music rhythm across all participants. We suggest that task demands shaped the asymmetric cortical tracking across domains.
C1 [Harding, Eleanor E.; Kotz, Sonja A.] Max Planck Inst Human Cognit & Brain Sci, Dept Neuropsychol, Leipzig, Germany.
   [Sammler, Daniela] Max Planck Inst Human Cognit & Brain Sci, Otto Hahn Grp Neural Bases Intonat Speech & Mus, Leipzig, Germany.
   [Henry, Molly J.] Max Planck Inst Human Cognit & Brain Sci, Max Planck Res Grp Auditory Cognit, Leipzig, Germany.
   [Large, Edward W.] Univ Connecticut, Dept Psychol, Storrs, CT USA.
   [Henry, Molly J.] Univ Western Ontario, Brain & Mind Inst, Dept Psychol, London, ON, Canada.
   [Kotz, Sonja A.] Maastricht Univ, Fac Psychol & Neurosci, Dept Neuropsychol & Psychopharmacol, Maastricht, Netherlands.
RP Kotz, SA (corresponding author), Max Planck Inst Human Cognit & Brain Sci, Dept Neuropsychol, Leipzig, Germany.
EM kotz@cbs.mpg.de
RI Sammler, Daniela/V-9044-2019
OI Sammler, Daniela/0000-0001-7458-0229; Harding,
   Eleanor/0000-0002-3244-9625
FU Initial Training Network (ITN) European Grant: "Europe, Brain and Music:
   New perspectives for stimulating cognitive and sensory processes
   (EBRAMUS)" [238157]; French Agence Nationale de la Recherche and the
   Deutsche Forschungsgemeinschaft joint project (ANR-DFG) "On the origins
   of grammar: from structural complexity in auditory sequences to
   syntactic structure"; Max Planck SocietyMax Planck Society
FX We thank Burkhard Maess for advice regarding data preprocessing. This
   research was funded by: the Initial Training Network (ITN) European
   Grant: "Europe, Brain and Music: New perspectives for stimulating
   cognitive and sensory processes (EBRAMUS)" [grant agreement 238157]; the
   French Agence Nationale de la Recherche and the Deutsche
   Forschungsgemeinschaft joint project (ANR-DFG) "On the origins of
   grammar: from structural complexity in auditory sequences to syntactic
   structure"; Otto Hahn Award of the Max Planck Society to Daniela
   Sammler.
CR Alexandrou A. M., 2018, LANG COGN NEUROSCI, P1
   [Anonymous], 1991, J CLIN NEUROPHYSIOL, V8, P200, DOI 10.1097/00004691-199104000-00007
   Boersma P., 2011, PRAAT DOING PHONETIC
   Brochard R, 2003, PSYCHOL SCI, V14, P362, DOI 10.1111/1467-9280.24441
   Buiatti M, 2009, NEUROIMAGE, V44, P509, DOI 10.1016/j.neuroimage.2008.09.015
   Capilla A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0014543
   Chen JL, 2008, J COGNITIVE NEUROSCI, V20, P226, DOI 10.1162/jocn.2008.20018
   Chen JL, 2006, NEUROIMAGE, V32, P1771, DOI 10.1016/j.neuroimage.2006.04.207
   Cohen MX, 2014, ISS CLIN COGN NEUROP, P1
   Cummins F, 2012, EMPIR MUSICOL REV, V7, P28, DOI 10.18061/1811/52976
   David O, 2003, NEUROIMAGE, V20, P1743, DOI 10.1016/j.neuroimage.2003.07.015
   DELANEY HD, 1981, MULTIVAR BEHAV RES, V16, P105, DOI 10.1207/s15327906mbr1601_6
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Ding N., 2017, BIORXIV
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Ding N, 2012, J NEUROPHYSIOL, V107, P78, DOI 10.1152/jn.00297.2011
   Doelling KB, 2015, P NATL ACAD SCI USA, V112, pE6233, DOI 10.1073/pnas.1508431112
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Du Y., 2017, P NATL ACAD SCI USA
   Ellis RJ, 2010, ATTEN PERCEPT PSYCHO, V72, P2274, DOI 10.3758/APP.72.8.2274
   Fitzroy AB, 2015, J COGNITIVE NEUROSCI, V27, P2339, DOI 10.1162/jocn_a_00862
   Geiser E, 2010, EUR J NEUROSCI, V32, P1979, DOI 10.1111/j.1460-9568.2010.07462.x
   GIARD MH, 1994, ELECTROEN CLIN NEURO, V92, P238, DOI 10.1016/0168-5597(94)90067-1
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Gordon RL, 2015, DEVELOPMENTAL SCI, V18, P635, DOI 10.1111/desc.12230
   Grahn JA, 2007, J COGNITIVE NEUROSCI, V19, P893, DOI 10.1162/jocn.2007.19.5.893
   Henry MJ, 2014, TIMING TIME PERCEPTI, V2, P62, DOI DOI 10.1163/22134468-00002011
   Herholz SC, 2012, NEURON, V76, P486, DOI 10.1016/j.neuron.2012.10.011
   Iversen JR, 2009, ANN NY ACAD SCI, V1169, P58, DOI 10.1111/j.1749-6632.2009.04579.x
   Jentschke S, 2009, NEUROIMAGE, V47, P735, DOI 10.1016/j.neuroimage.2009.04.090
   Jones M. R., 2009, OXFORD HDB MUSIC PSY, P81, DOI DOI 10.1093/OXFORDHB/9780199298457.013.0008
   Jones MR, 2002, PSYCHOL SCI, V13, P313, DOI 10.1111/1467-9280.00458
   JONES MR, 1976, PSYCHOL REV, V83, P323, DOI 10.1037/0033-295X.83.5.323
   Keitel A, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2004473
   Kotz SA, 2018, TRENDS COGN SCI, V22, P896, DOI 10.1016/j.tics.2018.08.002
   Kraus N., 2014, HEAR REV, V21, P18
   Kraus N, 2010, NAT REV NEUROSCI, V11, P599, DOI 10.1038/nrn2882
   Large E. W., 1994, Connection Science, V6, P177, DOI 10.1080/09540099408915723
   Large EW, 2015, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00159
   Large EW, 2009, ANN NY ACAD SCI, V1169, P46, DOI 10.1111/j.1749-6632.2009.04550.x
   Large EW, 2008, PSYCHOLOGY OF TIME, P189, DOI 10.1016/B978-0-08046-977-5.00006-5
   Large EW, 1999, PSYCHOL REV, V106, P119, DOI 10.1037/0033-295X.106.1.119
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Magne C, 2007, CEREB CORTEX, V17, P2659, DOI 10.1093/cercor/bhl174
   Makeig S, 2002, SCIENCE, V295, P690, DOI 10.1126/science.1066168
   Marie C, 2011, J COGNITIVE NEUROSCI, V23, P294, DOI 10.1162/jocn.2010.21413
   Menninghaus W, 2015, COGNITION, V143, P48, DOI 10.1016/j.cognition.2015.05.026
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Nozaradan S, 2012, J NEUROSCI, V32, P17572, DOI 10.1523/JNEUROSCI.3203-12.2012
   Nozaradan S, 2011, J NEUROSCI, V31, P10234, DOI 10.1523/JNEUROSCI.0411-11.2011
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   PALMER C, 1990, J EXP PSYCHOL HUMAN, V16, P728, DOI 10.1037/0096-1523.16.4.728
   Parbery-Clark A, 2012, NEUROSCIENCE, V219, P111, DOI 10.1016/j.neuroscience.2012.05.042
   Patel A. D., 2008, MUSIC LANGUAGE BRAIN
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Picton TW, 1999, AUDIOL NEURO-OTOL, V4, P64, DOI 10.1159/000013823
   Rimmele JM, 2018, TRENDS COGN SCI, V22, P870, DOI 10.1016/j.tics.2018.08.003
   Schroeder CE, 2009, TRENDS NEUROSCI, V32, P9, DOI 10.1016/j.tins.2008.09.012
   Slaney M., 1998, TECH REP, V10, P1998
   Slater J, 2016, COGN PROCESS, V17, P79, DOI 10.1007/s10339-015-0740-7
   Snyder JS, 2005, COGNITIVE BRAIN RES, V24, P117, DOI 10.1016/j.cogbrainres.2004.12.014
   Stefanics G, 2010, J NEUROSCI, V30, P13578, DOI 10.1523/JNEUROSCI.0703-10.2010
   Thomas MSC, 2009, J SPEECH LANG HEAR R, V52, P336, DOI 10.1044/1092-4388(2009/07-0144)
   Wong PCM, 2007, NAT NEUROSCI, V10, P420, DOI 10.1038/nn1872
   Zoefel B, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00095
NR 68
TC 14
Z9 14
U1 4
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD JAN 15
PY 2019
VL 185
BP 96
EP 101
DI 10.1016/j.neuroimage.2018.10.037
PG 6
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA HC2JN
UT WOS:000451628200009
PM 30336253
DA 2021-02-24
ER

PT J
AU Stevens, M
   Harrington, J
   Schiel, F
AF Stevens, Mary
   Harrington, Jonathan
   Schiel, Florian
TI Associating the origin and spread of sound change using agent-based
   modelling applied to /s/-retraction in English
SO GLOSSA-A JOURNAL OF GENERAL LINGUISTICS
LA English
DT Article
DE sound change; agent-based modelling; sibilants; Australian English
ID INCOMPLETE NEUTRALIZATION; PHONOLOGICAL REPRESENTATION;
   SPEECH-PERCEPTION; SPOKEN; IDENTIFICATION; TRANSMISSION; VARIABILITY;
   VOWELS; WORDS; VOICE
AB The study explored whether an asymmetric phonetic overlap between speech sounds could be turned into sound change through propagation around a community of speakers. The focus was on the change of /s/ to /integral/ which is known to be more likely than a change in the other direction both synchronically and diachronically. An agent-based model was used to test the prediction that communication between agents would advance /s/-retraction in /str/ clusters (e.g. string). There was one agent per speaker and the probabilistic mapping between words, phonological classes, and speech signals could be updated during communication depending on whether an agent listener absorbed an incoming speech signal from an agent talker into memory. Following interaction, sibilants in /str/ clusters were less likely to share a phonological class with prevocalic /s/ and were acoustically closer to /integral/. The findings lend support to the idea that sound change is the outcome of a fortuitous combination of the relative size and orientation of phonetic distributions, their association to phonological classes, and how these types of information vary between speakers that happen to interact with each other.
C1 [Stevens, Mary; Harrington, Jonathan; Schiel, Florian] Ludwig Maximilians Univ Munchen, Inst Phonet & Speech Proc, Schellingstr 3, Munich, Germany.
RP Stevens, M (corresponding author), Ludwig Maximilians Univ Munchen, Inst Phonet & Speech Proc, Schellingstr 3, Munich, Germany.
EM mes@phonetik.uni-muenchen.de
FU European Research CouncilEuropean Research Council (ERC)European
   Commission [742289, 2017-2022]
FX We thank the editors James Kirby, Lauren Hall-Lew and Patrick Honeybone
   as well as Alan Yu and two anonymous referees for thoughtful and helpful
   comments. This research was supported by European Research Council Grant
   no. 742289 'Human interaction and the evolution of spoken accent'
   (2017-2022).
CR Baker A, 2011, LANG VAR CHANGE, V23, P347, DOI 10.1017/S0954394511000135
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beddor P.S., 2015, P 18 INT C PHON SCI
   Beddor P. S., 2012, INITIATION SOUND CHA, P37, DOI DOI 10.1075/CILT.323.06BED
   Beddor PS, 2009, LANGUAGE, V85, P785
   Bermudez-Otero R., 2012, OXFORD HDB HIST ENGL, P691, DOI DOI 10.1093/OXFORDHB/9780199922765.013.0059
   Bermudez-Otero Ricardo, 2013, OXFORD HDB HIST PHON, P374
   Blevins J, 2009, DIACHRONICA, V26, P143, DOI 10.1075/dia.26.2.01ble
   Bloomfield L., 1933, LANGUAGE
   Bybee J., 2001, PHONOLOGY LANGUAGE U, DOI [10.1017/CBO9780511612886, DOI 10.1017/CBO9780511612886, 10.1017/CB09780511612886]
   Castellano C, 2009, REV MOD PHYS, V81, P591, DOI 10.1103/RevModPhys.81.591
   Chang S, 2001, ROLE SPEECH PERCEPTI, P79
   Cruttenden A, 2014, GIMSONS PRONUNCIATIO, DOI [10.4324/9780203784969, DOI 10.4324/9780203784969]
   De Schryver J, 2008, J GER LINGUIST, V20, P159, DOI 10.1017/S1470542708000056
   Dodsworth Robin, GLOSSA J GEN LINGUIS
   Draxler Christoph, 2004, P 4 INT C LANG RES E, P559
   Ernestus M., 2006, LAB PHONOLOGY, V8, P27, DOI DOI 10.1515/9783110197211.1.27
   Ernestus M, 2006, LINGUIST REV, V23, P217, DOI 10.1515/TLR.2006.008
   Ettlinger M., 2007, P 16 INT C PHON SCI, P685
   FORREST K, 1988, J ACOUST SOC AM, V84, P115, DOI 10.1121/1.396977
   FOURAKIS M, 1984, PHONETICA, V41, P140, DOI 10.1159/000261720
   Garrett Andrew, 2013, ORIGINS SOUND CHANGE, P51, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0003
   German JS, 2013, J PHONETICS, V41, P228, DOI 10.1016/j.wocn.2013.03.001
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Gorriz JM, 2010, SPEECH COMMUN, V52, P664, DOI 10.1016/j.specom.2010.03.003
   Guion SG, 1998, PHONETICA, V55, P18
   Haley KL, 2010, J PHONETICS, V38, P548, DOI 10.1016/j.wocn.2010.07.006
   Hall DC, 2016, GLOSSA, V1, DOI 10.5334/gjgl.245
   Hall-Lew Lauren, 2011, P 17 INT C PHON SCI, P807
   Harrington J, 2018, TOP COGN SCI, V10, P707, DOI 10.1111/tops.12329
   Harrington J, 2017, LANGUAGE, V93, P414, DOI 10.1353/lan.2017.0019
   Harrington J, 2011, J PHONETICS, V39, P121, DOI 10.1016/j.wocn.2010.12.006
   Harrington Jonathan, 2012, SPEECH PLANNING DYNA, P33
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hay J, 2006, LINGUIST REV, V23, P321, DOI 10.1515/TLR.2006.013
   Hay J, 2016, LANGUAGE, V92, P298, DOI 10.1353/lan.2016.0036
   Hay J, 2013, ENGL LANG LINGUIST, V17, P241, DOI 10.1017/S1360674313000026
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   HEINZ JM, 1961, J ACOUST SOC AM, V33, P589, DOI 10.1121/1.1908734
   Iskarous K, 2011, J ACOUST SOC AM, V129, P944, DOI 10.1121/1.3514537
   Jespersen O., 1913, LEHRBUCH PHONETIK
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   JONGMAN A, 1992, LANG SPEECH, V35, P137, DOI 10.1177/002383099203500212
   Kataoka R., 2011, THESIS
   Kiparsky P., 2015, OXFORD HDB HIST PHON, P563, DOI DOI 10.1093/OXFORDHB/9780199232819.013.017
   Kiparsky P, 2016, J SOCIOLING, V20, P464, DOI 10.1111/josl.12196
   Kirby JP, 2014, LAB PHONOL, V5, P195, DOI 10.1515/lp-2014-0008
   Kisler T, 2017, COMPUT SPEECH LANG, V45, P326, DOI 10.1016/j.csl.2017.01.005
   Kleber F, 2010, J PHONETICS, V38, P185, DOI 10.1016/j.wocn.2009.10.001
   Koenig LL, 2013, J SPEECH LANG HEAR R, V56, P1175, DOI 10.1044/1092-4388(2012/12-0038)
   Kraljic T, 2008, COGNITION, V107, P54, DOI 10.1016/j.cognition.2007.07.013
   Kummel Martin Joachim, 2007, KONSONANTENWANDEL BA
   Labov W., 1994, PRINCIPLES LINGUISTI, V1
   Labov W., 2001, PRINCIPLES LINGUISTI, V2
   Labov W, 2007, LANGUAGE, V83, P344, DOI 10.1353/lan.2007.0082
   Ladd D. Robert, 2006, LAB PHONOLOGY, V8, P3
   Lawrence WP, 2000, AM SPEECH, V75, P82, DOI 10.1215/00031283-75-1-82
   LOBANOV BM, 1971, J ACOUST SOC AM, V49, P606, DOI 10.1121/1.1912396
   Maclagan Margaret, 1996, LANG VAR CHANGE, V8, P125, DOI [10.1017/S0954394500001095, DOI 10.1017/S0954394500001095]
   Milhlenbemd R., 2013, U PENNSYLVANIA WORKI, V19, P129
   MILROY J, 1985, J LINGUIST, V21, P339, DOI 10.1017/S0022226700010306
   Ohala J. J., 1993, HIST LINGUISTICS PRO, P237
   Ohala John J., 2012, INITIATION SOUND CHA, P21, DOI DOI 10.1075/CILT.323.05OHA
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Pierrehumbert JB, 2003, PROBABILISTIC LINGUISTICS, P177
   POLKA L, 1991, J ACOUST SOC AM, V89, P2961, DOI 10.1121/1.400734
   PORT RF, 1985, J PHONETICS, V13, P455, DOI 10.1016/S0095-4470(19)30797-1
   R Core Team, 2014, R LANG ENV STAT COMP
   Reinisch E, 2016, J PHONETICS, V55, P96, DOI 10.1016/j.wocn.2015.12.004
   Reinisch E, 2014, J PHONETICS, V45, P91, DOI 10.1016/j.wocn.2014.04.002
   Roettger TB, 2014, J PHONETICS, V43, P11, DOI 10.1016/j.wocn.2014.01.002
   Rohlfs Gerhard, 1966, GRAMMATICA STORICA L
   Ruch H, 2014, J PHONETICS, V45, P12, DOI 10.1016/j.wocn.2014.02.009
   Rutter B, 2011, J INT PHON ASSOC, V41, P27, DOI 10.1017/S0025100310000307
   Scobbie JM, 2008, PHONOL PHONET, V13, P87
   Shadle Christine H., 2012, OXFORD HDB LAB PHONO, P511
   Smith Bridget, GLOSSA J GEN LINGUIS
   Soskuthy M, 2015, LINGUA, V163, P40, DOI 10.1016/j.lingua.2015.05.010
   Stanford JN, 2013, LANG VAR CHANGE, V25, P119, DOI 10.1017/S0954394513000069
   Stevens KN, 1998, ACOUSTIC PHONETICS
   Stevens M, 2016, J PHONETICS, V58, P118, DOI 10.1016/j.wocn.2016.08.003
   Stevens M, 2014, LOQUENS, V1, DOI 10.3989/loquens.2014.003
   Stevens Mary, 2015, P 18 INT C PHON SCI
   Strycharczuk P, 2016, J PHONETICS, V59, P76, DOI 10.1016/j.wocn.2016.09.003
   Trudgill P., 2011, SOCIOLINGUISTIC TYPO
   Trudgill P, 2008, LANG SOC, V37, P277, DOI 10.1017/S0047404508080354
   Warner N, 2004, J PHONETICS, V32, P251, DOI 10.1016/S0095-4470(03)00032-9
   Warren P., 1996, P 11 AUSTR INT C SPE, P466
   Wasserman S., 1994, SOCIAL NETWORK ANAL, DOI [10.1017/CBO9780511815478, DOI 10.1017/CBO9780511815478]
   Watson C., 1998, AUST J LINGUIST, V18, P185, DOI DOI 10.1080/07268609808599567
   Watson CI, 1999, J ACOUST SOC AM, V106, P458, DOI 10.1121/1.427069
   Wiese R., 1996, PHONOLOGY GERMAN
   WINITZ H, 1972, J ACOUST SOC AM, V51, P1309, DOI 10.1121/1.1912976
   Winkelmann R, 2017, COMPUT SPEECH LANG, V45, P392, DOI 10.1016/j.csl.2017.01.002
   Yu ACL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0074746
   Yu Alan Chi Lun, GLOSSA J GEN LINGUIS
   Zellou G, 2017, J PHONETICS, V61, P13, DOI 10.1016/j.wocn.2016.12.002
NR 99
TC 7
Z9 7
U1 0
U2 0
PU UBIQUITY PRESS LTD
PI LONDON
PA 2N, 6 OSBORNE ST, LONDON, E1 6TD, ENGLAND
SN 2397-1835
J9 GLOSSA-UK
JI Glossa
PD JAN 14
PY 2019
VL 4
IS 1
AR 8
DI 10.5334/gjgl.620
PG 30
WC Linguistics; Language & Linguistics
SC Linguistics
GA HH9IM
UT WOS:000456051200001
OA DOAJ Gold, Green Accepted
DA 2021-02-24
ER

PT J
AU Barnaud, ML
   Schwartz, JL
   Bessiere, P
   Diard, J
AF Barnaud, Marie-Lou
   Schwartz, Jean-Luc
   Bessiere, Pierre
   Diard, Julien
TI Computer simulations of coupled idiosyncrasies in speech perception and
   speech production with COSMO, a perceptuo-motor Bayesian model of speech
   communication
SO PLOS ONE
LA English
DT Article
ID MOTOR SYSTEM; SELF-ORGANIZATION; VOICE; FAMILIAR; LANGUAGE;
   COMPENSATION; ACQUISITION; EMERGENCE; ROLES; AREAS
AB The existence of a functional relationship between speech perception and production systems is now widely accepted, but the exact nature and role of this relationship remains quite unclear. The existence of idiosyncrasies in production and in perception sheds interesting light on the nature of the link. Indeed, a number of studies explore inter-individual variability in auditory and motor prototypes within a given language, and provide evidence for a link between both sets. In this paper, we attempt to simulate one study on coupled idiosyncrasies in the perception and production of French oral vowels, within COSMO, a Bayesian computational model of speech communication. First, we show that if the learning process in COSMO includes a communicative mechanism between a Learning Agent and a Master Agent, vowel production does display idiosyncrasies. Second, we implement within COSMO three models for speech perception that are, respectively, auditory, motor and perceptuo-motor. We show that no idiosyncrasy in perception can be obtained in the auditory model, since it is optimally tuned to the learning environment, which does not include the motor variability of the Learning Agent. On the contrary, motor and perceptuo-motor models provide perception idiosyncrasies correlated with idiosyncrasies in production. We draw conclusions about the role and importance of motor processes in speech perception, and propose a perceptuo-motor model in which auditory processing would enable optimal processing of learned sounds and motor processing would be helpful in unlearned adverse conditions.
C1 [Barnaud, Marie-Lou; Schwartz, Jean-Luc] Univ Grenoble Alpes, Gipsa Lab, Grenoble, France.
   [Barnaud, Marie-Lou; Schwartz, Jean-Luc] CNRS, Gipsa Lab, Grenoble, France.
   [Barnaud, Marie-Lou; Diard, Julien] Univ Grenoble Alpes, LPNC, Grenoble, France.
   [Barnaud, Marie-Lou; Diard, Julien] CNRS, LPNC, Grenoble, France.
   [Bessiere, Pierre] Sorbonne Univ, CNRS, ISIR, Paris, France.
RP Schwartz, JL (corresponding author), Univ Grenoble Alpes, Gipsa Lab, Grenoble, France.; Schwartz, JL (corresponding author), CNRS, Gipsa Lab, Grenoble, France.
EM Jean-Luc.Schwartz@gipsa-lab.grenoble-inp.fr
OI Diard, Julien/0000-0003-0673-477X
FU European Research CouncilEuropean Research Council (ERC)European
   Commission [339152]
FX This research was supported by a grant from the European Research
   Council (FP7/2007-2013 Grant Agreement no. 339152 to JLS). The funders
   had no role in study design, data collection and analysis, decision to
   publish, or preparation of the manuscript.
CR Bailly G, 1997, SPEECH COMMUN, V22, P251, DOI 10.1016/S0167-6393(97)00025-3
   Barnaud  M.-L., 2017, BRAIN LANGUAGE
   Barnaud ML, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P248, DOI 10.1109/DEVLRN.2015.7346149
   Barnaud ML, 2016, INTERSPEECH 2016
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Belin P, 2011, BRIT J PSYCHOL, V102, P711, DOI 10.1111/j.2044-8295.2011.02041.x
   BELLBERTI F, 1979, PHONETICA, V36, P373, DOI 10.1159/000259974
   Bessiere P., 2013, BAYESIAN PROGRAMMING
   Browman C. P., 1990, PAPERS LABORATORY PH, P341, DOI [10.1017/CBO9780511627736.019, DOI 10.1017/CBO9780511627736.019]
   BROWMAN CP, 1992, PHONETICA, V49, P155, DOI 10.1159/000261913
   Canevari C, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00364
   Castellini C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0024055
   Cristia A, 2019, CHILD DEV, V90, P759, DOI 10.1111/cdev.12974
   D'Ausilio A, 2012, CORTEX, V48, P882, DOI 10.1016/j.cortex.2011.05.017
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   de Boer B, 2000, J PHONETICS, V28, P441, DOI 10.1006/jpho.2000.0125
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   FOWLER CA, 1986, J PHONETICS, V14, P3, DOI 10.1016/S0095-4470(19)30607-2
   Fowler CA, 2016, SPEECH MOTOR CONTROL
   FOX RA, 1982, PHONETICA, V39, P1, DOI 10.1159/000261647
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Gick B, 2009, NATURE, V462, P502, DOI 10.1038/nature08572
   Goldstein L., 2003, PHONETICS PHONOLOGY, P159
   Graux J, 2015, SOC COGN AFFECT NEUR, V10, P101, DOI 10.1093/scan/nsu031
   Graux J, 2013, BRAIN TOPOGR, V26, P72, DOI 10.1007/s10548-012-0233-2
   Guenther FH, 1998, PSYCHOL REV, V105, P611, DOI 10.1037/0033-295X.105.4.611-633
   Guenther FH, 2006, J COMMUN DISORD, V39, P350, DOI 10.1016/j.jcomdis.2006.06.013
   Guenther FH, 2012, J NEUROLINGUIST, V25, P408, DOI 10.1016/j.jneuroling.2009.08.006
   Holt LL, 2008, CURR DIR PSYCHOL SCI, V17, P42, DOI 10.1111/j.1467-8721.2008.00545.x
   Houde JF, 2002, J SPEECH LANG HEAR R, V45, P295, DOI 10.1044/1092-4388(2002/023)
   Houde JF, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00082
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   Kaplan JT, 2008, SOC COGN AFFECT NEUR, V3, P218, DOI 10.1093/scan/nsn014
   Kerzel D, 2000, J EXP PSYCHOL HUMAN, V26, P634, DOI 10.1037//0096-1523.26.2.634
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Krakauer J., 2006, PLOS BIOL, V4, P1
   Kroeger BJ, 2015, J PHONETICS, V53, P88, DOI 10.1016/j.wocn.2015.09.006
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Lametti DR, 2014, J NEUROSCI, V34, P10339, DOI 10.1523/JNEUROSCI.0108-14.2014
   Laurent R, 2017, PSYCHOL REV, V124, P572, DOI 10.1037/rev0000069
   Laurent R, 2013, INTERSPEECH, P2796
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Loakes D., 2006, FORENSIC PHONETIC IN
   MAEDA S, 1990, NATO ADV SCI I D-BEH, V55, P131
   Massaro DW, 1987, CATEGORICAL PARTITIO
   McGettigan C, 2017, OXFORD HDB PSYCHOLIN, DOI [10.1523/JNEUROSCI.0108-14.2014, DOI 10.1523/JNEUROSCI.0108-14.2014]
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Menard L, 2014, ACTA ACUST UNITED AC, V100, P676, DOI 10.3813/AAA.918747
   Meunier C., 2007, LES DYSARTHRIES, P164
   Mottonen R, 2012, APHASIOLOGY, V26, P1103, DOI 10.1080/02687038.2011.619515
   Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009
   Moulin-Frier C, 2012, LANG COGNITIVE PROC, V27, P1240, DOI 10.1080/01690965.2011.645313
   Moulin-Frier C, 2015, J PHONETICS, V53, P5, DOI 10.1016/j.wocn.2015.06.001
   Nakamura K, 2001, NEUROPSYCHOLOGIA, V39, P1047, DOI 10.1016/S0028-3932(01)00037-9
   Nearey TM, 1997, J ACOUST SOC AM, V101, P3241, DOI 10.1121/1.418290
   Newman R., 1997, J ACOUST SOC AM, V102, P3114, DOI [10.1121/1, DOI 10.1121/1]
   Nolan F., 1996, FORENSIC LINGUIST, V3, P39, DOI DOI 10.1558/IJSLL.V3I1.39
   Oudeyer PY, 2005, CONNECT SCI, V17, P325, DOI 10.1080/09540090500217145
   Oudeyer PY, 2001, LECT NOTES COMPUT SC, V2130, P1171
   Patri JF, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005942
   Patri JF, 2015, PROGR MOTOR CONTROL
   Perkell J. S., 1986, INVARIANCE VARIABILI
   Perkell JS, 2012, J NEUROLINGUIST, V25, P382, DOI 10.1016/j.jneuroling.2010.02.011
   Perrier P., 2005, ZAS PAPERS LINGUISTI, V40, P109
   Poeppel D, 2011, LANG COGNITIVE PROC, V26, P935, DOI 10.1080/01690965.2010.493301
   Pulvermuller F, 2005, EUR J NEUROSCI, V21, P793, DOI 10.1111/j.1460-9568.2005.03900.x
   Rapin L, 2017, J ACOUST SOC AM, V141, P3582, DOI [10.1121/1.4987639, DOI 10.1121/1.4987639]
   Rogers JC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00754
   Roon KD, 2015, PSYCHON B REV, V22, P242, DOI 10.3758/s13423-014-0666-6
   Saltzman E., 1989, ECOL PSYCHOL, V1, P333, DOI [10.1207/s15326969eco0104_2, DOI 10.1207/S15326969EC00104_, 10.1207/ s15326969-co0104_2, DOI 10.1207/S15326969ECO0104_2]
   Sato M, 2011, CORTEX, V47, P1001, DOI 10.1016/j.cortex.2011.03.009
   Sato M, 2009, BRAIN LANG, V111, P1, DOI 10.1016/j.bandl.2009.03.002
   SAVARIAUX C, 1995, J ACOUST SOC AM, V98, P2428, DOI 10.1121/1.413277
   Scarbel L, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00568
   Schroeder M. R, 1979, FRONTIERS SPEECH COM, P217
   Schwartz J. L., 2002, PHONETICS PHONOLOGY, P244
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   Schwartz JL, 1997, J PHONETICS, V25, P255, DOI 10.1006/jpho.1997.0043
   Schwartz JL, EXPT APPROACHES PHON, DOI [10.1016/j.jneuroling.2009.12.004, DOI 10.1016/J.JNEUROLING.2009.12.004]
   Shiller DM, 2009, J ACOUST SOC AM, V125, P1103, DOI 10.1121/1.3058638
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Steels L, 1998, ARTIF INTELL, V103, P133, DOI 10.1016/S0004-3702(98)00066-6
   Stevens K., 1967, MODELS PERCEPTION SP, P88
   Treille A., 2017, PERCEVOIR AGIR NATUR
   Tye-Murray N, 2014, J SPEECH LANG HEAR R, V57, P556, DOI 10.1044/2013_JSLHR-H-12-0273
   Tye-Murray N, 2013, PSYCHON B REV, V20, P115, DOI 10.3758/s13423-012-0328-5
   Weiping Cai, 2010, Proceedings of the 2010 International Conference on Electrical and Control Engineering (ICECE 2010), P1246, DOI 10.1109/iCECE.2010.310
   Weirich M, 2013, J ACOUST SOC AM, V134, P3766, DOI 10.1121/1.4822480
   Wilson SM, 2006, NEUROIMAGING STUDIES
NR 93
TC 0
Z9 0
U1 0
U2 3
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD JAN 11
PY 2019
VL 14
IS 1
AR e0210302
DI 10.1371/journal.pone.0210302
PG 34
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA HH1MW
UT WOS:000455485100016
PM 30633745
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Li, Y
   Shen, M
   Long, M
AF Li, Yuan
   Shen, Min
   Long, Mo
TI A preliminary study of auditory mismatch response on the day of cochlear
   implant activation in children with hearing aids prior implantation
SO PLOS ONE
LA English
DT Article
ID NEGATIVITY MMN; SPEECH-PERCEPTION; DEAF-CHILDREN; LANGUAGE; POTENTIALS;
   INFANTS; DISCRIMINATION; MATURATION; VOWEL
AB Objective
   The study aimed to explore the characteristics of auditory mismatch response (MMR) in hearing-impaired children on the day when the cochlear implant (CI) was started (power-up) and the speech processor was programmed, and to investigate the effects of wearing hearing aids (HAs) before cochlear implantation on the early stage of postoperative auditory cortex plasticity, providing some demonstrative data for the objective evaluation of postoperative early auditory ability in children who underwent cochlear implantation.
   Methods
   The participants were 34 children with profound sensorineural hearing loss, who underwent cochlear implantation. The classical passive Oddball paradigm was adopted, using a pair of vowels which only have different lexical tones. The standard stimulus was /a2/ and the devious stimulus was /a4/.
   Results
   1) On the day of CI activation, the auditory MMR has been elicited in 30 children; the MMR incidence was 88%. 2) We observed both positive and negative auditory MMR waveforms. And logistic regression analysis showed that it was influenced by the age at cochlear implantation. 3) The duration with HA before surgery significantly influenced the MMR latency. The children with longer duration of HA use have much earlier latency of MMR. 4) There was a significant positive correlation between the age at HA use initiation and MMR amplitude. Earlier initial HA use was associated with smaller amplitude.
   Conclusions
   MMR in response to Mandarin lexical tone can be recorded in most pediatric patients who had experience with HA on the day of CI power up. MMR is closely associated with the age at cochlear implantation, duration of HA use, and the age at HA use initiation. Hearing impaired children should wear HA as early as possible and ensure consistent usage.
C1 [Li, Yuan] China Japan Friendship Hosp, Beijing, Peoples R China.
   [Shen, Min; Long, Mo] China Rehabil Res Ctr Hearing & Speech Impairment, Beijing, Peoples R China.
RP Shen, M; Long, M (corresponding author), China Rehabil Res Ctr Hearing & Speech Impairment, Beijing, Peoples R China.
EM sarah_shen@126.com; crrcdclongmo@sohu.com
OI Shen, Min/0000-0003-1430-1675
FU Beijing Natural Science Foundation of ChinaBeijing Natural Science
   Foundation [7172251]; National Socical Science Foundation of China
   [13AYY004]; General Programs in China-Japan Friendship Hospital
   [2015-1-MS-5]; China Rehabilitation Research Center for Hearing and
   Speech Impairment [201404]
FX This research is partially supported by Beijing Natural Science
   Foundation of China (grant No: 7172251) and National Socical Science
   Foundation of China (grant No: 13AYY004) and General Programs funded in
   China-Japan Friendship Hospital (grant No: 2015-1-MS-5) and Projects
   funded in China Rehabilitation Research Center for Hearing and Speech
   Impairment (grant No: 201404). The funders had no role in study design,
   data collection and analysis, decision to publish, or preparation of the
   manuscript. The funders had no role in study design, data collection and
   analysis, decision to publish, or preparation of the manuscript.
CR American Speech-Language-Hearing Association, NON TRADITIONAL REF
   Bishop DVM, 2007, PSYCHOL BULL, V133, P651, DOI 10.1037/0033-2909.133.4.651
   [曹永茂 Cao Yongmao], 2003, [中华物理医学与康复杂志, Chinese Journal of Physical Medicine and Rehabilitation], V25, P240
   [陈涛 Chen Tao], 2012, [听力学及言语疾病杂志, Journal of Audiology and Speech Pathology], V20, P574
   Cheour M, 2000, CLIN NEUROPHYSIOL, V111, P4, DOI 10.1016/S1388-2457(99)00191-1
   Dehaene-Lambertz G, 2000, J COGNITIVE NEUROSCI, V12, P449, DOI 10.1162/089892900562264
   Guttorm TK, 2005, CORTEX, V41, P291, DOI 10.1016/S0010-9452(08)70267-3
   Hillyard SA, 1998, P NATL ACAD SCI USA, V95, P781, DOI 10.1073/pnas.95.3.781
   Kelly AS, 2005, CLIN NEUROPHYSIOL, V116, P1235, DOI 10.1016/j.clinph.2005.02.011
   Lee CY, 2012, NEUROPSYCHOLOGIA, V50, P3228, DOI 10.1016/j.neuropsychologia.2012.08.025
   Liang MJ, 2014, OTOL NEUROTOL, V35, pE7, DOI 10.1097/MAO.0000000000000181
   Liu HM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095587
   [刘欣 Liu Xin], 2015, [听力学及言语疾病杂志, Journal of Audiology and Speech Pathology], V23, P287
   Lonka E, 2013, ACTA OTO-LARYNGOL, V133, P853, DOI 10.3109/00016489.2013.780293
   Martin BA, 2008, EAR HEARING, V29, P285, DOI 10.1097/AUD.0b013e3181662c0e
   Martin-Loeches M, 2001, J INTELL DISABIL RES, V45, P63, DOI 10.1046/j.1365-2788.2001.00292.x
   Morr ML, 2002, EAR HEARING, V23, P118, DOI 10.1097/00003446-200204000-00005
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Nicholas JG, 2006, EAR HEARING, V27, P286, DOI 10.1097/01.aud.0000215973.76912.c6
   Nikolopoulos TP, 2005, INT J PEDIATR OTORHI, V69, P175, DOI 10.1016/j.ijporl.2004.08.016
   Partanen E, 2013, NON TRADITIONAL REF
   Roman Stephane, 2005, HEARING RES, V201
   Shafer VL, 2011, J PHONETICS, V39, P527, DOI 10.1016/j.wocn.2010.11.010
   Shafer VL, 2010, EAR HEARING, V31, P735, DOI 10.1097/AUD.0b013e3181e5d1a7
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   [申敏 Shen Min], 2014, [中国康复理论与实践, Chinese Journal of Rehabilitation Theory and Practice], V20, P1001
   Soli SD, 2012, INT J PEDIATR OTORHI, V76, P1255, DOI 10.1016/j.ijporl.2012.05.015
   TIITINEN H, 1994, NATURE, V372, P90, DOI 10.1038/372090a0
   Tong XH, 2014, BRAIN LANG, V138, P61, DOI 10.1016/j.bandl.2014.09.004
   Tong XH, 2014, PSYCHOPHYSIOLOGY, V51, P1158, DOI 10.1111/psyp.12257
   Turgeon C, 2014, CLIN NEUROPHYSIOL, V125, P827, DOI 10.1016/j.clinph.2013.09.035
   van Leeuwen T, 2007, NEUROREPORT, V18, P857, DOI 10.1097/WNR.0b013e3280c1e2bf
   Vavatzanidis NK, 2015, J COGNITIVE NEUROSCI, V27, P2427, DOI 10.1162/jocn_a_00868
   [王俊 Wang Jun], 2015, [听力学及言语疾病杂志, Journal of Audiology and Speech Pathology], V23, P66
   Wang LY, 2013, INT J PEDIATR OTORHI, V77, P1350, DOI 10.1016/j.ijporl.2013.05.033
   Yuan Hao, 2015, Lin Chung Er Bi Yan Hou Tou Jing Wai Ke Za Zhi, V29, P1671
   Zheng Y., 2011, CHIN SCI J HEAR SPEE, V5, P19
NR 37
TC 3
Z9 3
U1 0
U2 5
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD JAN 7
PY 2019
VL 14
IS 1
AR e0210457
DI 10.1371/journal.pone.0210457
PG 12
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA HG5UW
UT WOS:000455045900076
PM 30615690
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Scharenborg, O
   Kakouros, S
   Post, B
   Meunier, F
AF Scharenborg, Odette
   Kakouros, Sofoklis
   Post, Brechtje
   Meunier, Fanny
TI Cross-linguistic Influences on Sentence Accent Detection in Background
   Noise
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Sentence accent detection; phoneme detection; native and non-native
   listening; noise; acoustic cues; prosody; cross-linguistic influence
ID MONITORING REACTION-TIME; FUNDAMENTAL-FREQUENCY; NONNATIVE LISTENERS;
   SPEECH-PERCEPTION; STRESS; PROMINENCE; LANGUAGE; FRENCH; ENGLISH;
   PROSODY
AB This paper investigates whether sentence accent detection in a non-native language is dependent on (relative) similarity between prosodic cues to accent between the non-native and the native language, and whether cross-linguistic differences in the use of local and more widely distributed (i.e., non-local) cues to sentence accent detection lead to differential effects of the presence of background noise on sentence accent detection in a non-native language. We compared Dutch, Finnish, and French non-native listeners of English, whose cueing and use of prosodic prominence is gradually further removed from English, and compared their results on a phoneme monitoring task in different levels of noise and a quiet condition to those of native listeners. Overall phoneme detection performance was high for the native and the non-native listeners, but deteriorated to the same extent in the presence of background noise. Crucially, relative similarity between the prosodic cues to sentence accent of one's native language compared to that of a non-native language does not determine the ability to perceive and use sentence accent for speech perception in that non-native language. Moreover, proficiency in the non-native language is not a straightforward predictor of sentence accent perception performance, although high proficiency in a non-native language can seemingly overcome certain differences at the prosodic level between the native and non-native language. Instead, performance is determined by the extent to which listeners rely on local cues (English and Dutch) versus cues that are more distributed (Finnish and French), as more distributed cues survive the presence of background noise better.
C1 [Scharenborg, Odette; Kakouros, Sofoklis] Radboud Univ Nijmegen, Nijmegen, Netherlands.
   [Kakouros, Sofoklis] Aalto Univ, Espoo, Finland.
   [Post, Brechtje] Univ Cambridge, Cambridge, England.
   [Meunier, Fanny] Univ Cote Azur, Nice, France.
RP Scharenborg, O (corresponding author), Delft Univ Technol, Multimedia Comp Grp, Mourik Broekmanweg 6, NL-2628 XE Delft, Netherlands.
EM o.e.scharenborg@tudelft.nl
RI Kakouros, Sofoklis/E-2404-2012
OI Kakouros, Sofoklis/0000-0001-8996-0793; Scharenborg,
   Odette/0000-0003-0693-8852
FU Netherlands Organisation for Scientific ResearchNetherlands Organization
   for Scientific Research (NWO) [276-89-003]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This
   research is supported by a Vidi-grant from the Netherlands Organisation
   for Scientific Research (grant number 276-89-003) awarded to Odette
   Scharenborg.
CR Akker Evelien, 2003, BILING-LANG COGN, V6, P81, DOI DOI 10.1017/S1366728903001056
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Boersma P., 2005, PRAAT DOING PHONETIC
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Broersma M, 2010, SPEECH COMMUN, V52, P980, DOI 10.1016/j.specom.2010.08.010
   Campbell N., 1997, INTONATION THEORY MO, P67
   Carroll R, 2016, NEUROPSYCHOLOGIA, V82, P91, DOI 10.1016/j.neuropsychologia.2016.01.014
   Clements G. N., 1990, PAPERS LAB PHONOLOGY, P283, DOI DOI 10.1017/CBO9780511627736.017
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Cole J., 2010, LAB PHONOL, V1, DOI [https://doi.org/10.1515/labphon.2010.022, DOI 10.1515/LABPHON.2010.022, DOI 10.1515/LABPH0N.2010.022]
   Cooke M, 2008, J ACOUST SOC AM, V123, P414, DOI 10.1121/1.2804952
   Cooke M, 2010, SPEECH COMMUN, V52, P954, DOI 10.1016/j.specom.2010.04.004
   Cooke M, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1847
   Cruttenden A., 1997, INTONATION
   Cruttenden A., 2006, PRAGMATIC ORG DISCOU, P311, DOI DOI 10.1515/9783110892222.311
   CUTLER A, 1977, LANG SPEECH, V20, P1
   Cutler A, 1997, LANG SPEECH, V40, P141, DOI 10.1177/002383099704000203
   CUTLER A, 1976, PERCEPT PSYCHOPHYS, V20, P55, DOI 10.3758/BF03198706
   CUTLER A, 1981, PERCEPT PSYCHOPHYS, V29, P217, DOI 10.3758/BF03207288
   Cutler A, 2008, J ACOUST SOC AM, V124, P1264, DOI 10.1121/1.2946707
   Dupoux E, 2001, J ACOUST SOC AM, V110, P1606, DOI 10.1121/1.1380437
   Dupoux E, 2008, COGNITION, V106, P682, DOI 10.1016/j.cognition.2007.04.001
   EIMAS PD, 1992, J MEM LANG, V31, P375, DOI 10.1016/0749-596X(92)90019-T
   Fant G., 2004, INT S TON ASP LANG E, P57
   Fletcher H, 1933, J ACOUST SOC AM, V5, P82, DOI 10.1121/1.1915637
   Foss D. J., 1980, PERCEPTION PRODUCTIO, P165
   Frost D, 2011, J INT PHON ASSOC, V41, P67, DOI 10.1017/S0025100310000253
   FRY DB, 1955, J ACOUST SOC AM, V27, P765, DOI 10.1121/1.1908022
   FRY DB, 1958, LANG SPEECH, V1, P126, DOI 10.1177/002383095800100207
   Garcia Lecumberri M. L, 1995, AN SEM JUL URQ ASJU, P581
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Gussenhoven C, 1983, TOEGEPASTE TAALKUNDE, V17, P273
   Gussenhoven C., 2011, UNDERSTANDING PHONOL
   Jun SA, 2000, TEXT SPEECH LANG TEC, V15, P209
   Kakouros S, 2017, INTERSPEECH, P3211, DOI 10.21437/Interspeech.2017-1237
   Kakouros S, 2016, SPEECH COMMUN, V82, P67, DOI 10.1016/j.specom.2016.06.004
   Karaminis T., 2018, P COGN SCI C MAD WI
   Kochanski G, 2005, J ACOUST SOC AM, V118, P1038, DOI 10.1121/1.1923349
   Koopmans-van Beinum F. J., 1989, Eurospeech 89. European Conference on Speech Communication and Technology, P113
   Ladd D.Robert., 1996, INTONATIONAL PHONOLO
   LADD DR, 1990, LANGUAGE, V66, P806, DOI 10.2307/414730
   Ladd DR, 2008, CAMB STUD LINGUIST, V79, P1
   Lambrecht Knud, 1994, INFORM STRUCTURE SEN
   Lecumberri MLG, 2006, J ACOUST SOC AM, V119, P2445, DOI 10.1121/1.2180210
   Lein T, 2016, INT J BILINGUAL, V20, P732, DOI 10.1177/1367006915589424
   Lemhofer K, 2012, BEHAV RES METHODS, V44, P325, DOI 10.3758/s13428-011-0146-0
   LIEBERMAN P, 1960, J ACOUST SOC AM, V32, P451, DOI 10.1121/1.1908095
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Mattys SL, 2009, COGNITIVE PSYCHOL, V59, P203, DOI 10.1016/j.cogpsych.2009.04.001
   Peperkamp S, 2002, PHONOL PHON, V4-1, P203
   Rosenberg A., 2010, P 5 INT C SPEECH PRO
   Rosenberg A., 2009, P HUM LANG TECHN 200, P81, DOI 10.3115/1620853.1620878
   Scharenborg O, 2018, J EXP PSYCHOL LEARN, V44, P233, DOI 10.1037/xlm0000441
   Scharenborg O, 2016, INTERSPEECH, P863, DOI 10.21437/Interspeech.2016-19
   Scharenborg O, 2015, ATTEN PERCEPT PSYCHO, V77, P493, DOI 10.3758/s13414-014-0792-2
   Seguinot A., 1977, STUDIA PHONETICA 12, P1
   ShattuckHufnagel S, 1996, J PSYCHOLINGUIST RES, V25, P193, DOI 10.1007/BF01708572
   SHIELDS JL, 1974, J EXP PSYCHOL, V102, P250, DOI 10.1037/h0035855
   Shinn-Cunningham BG, 2008, TRENDS COGN SCI, V12, P182, DOI 10.1016/j.tics.2008.02.003
   Sluijter AMC, 1996, J ACOUST SOC AM, V100, P2471, DOI 10.1121/1.417955
   Suomi K., 2008, STUDIA HUMANIORA OUL
   TERKEN J, 1991, J ACOUST SOC AM, V89, P1768, DOI 10.1121/1.401019
   Terken J., 2000, PROSODY THEORY EXPT, P89, DOI DOI 10.1007/978-94-015-9413-4_5
   Vainio M, 2006, J PHONETICS, V34, P319, DOI 10.1016/j.wocn.2005.06.004
   Vallduvi E., 1992, INFORM COMPONENT
   van Alphen PM, 2004, J PHONETICS, V32, P455, DOI 10.1016/j.wocn.2004.05.001
   van Kuijk D, 1999, SPEECH COMMUN, V27, P95, DOI 10.1016/S0167-6393(98)00069-7
   Van Zyl M., 2011, J HEARING SCI, V1, P54
   Venditti JJ, 1996, SIGNAL TO SYNTAX: BOOTSTRAPPING FROM SPEECH TO GRAMMAR IN EARLY ACQUISITION, P287
   Wagner P, 2005, P INT 2005 LISB, P2381
   Wagner P., 2015, P INT C PHON SCI ICP
   Zahorian SA, 2008, J ACOUST SOC AM, V123, P4559, DOI 10.1121/1.2916590
NR 72
TC 1
Z9 1
U1 0
U2 1
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD MAR
PY 2020
VL 63
IS 1
BP 3
EP 30
AR 0023830918819573
DI 10.1177/0023830918819573
EA JAN 2019
PG 28
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA LA2NZ
UT WOS:000454993200001
PM 30606083
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Biberauer, T
AF Biberauer, Theresa
TI Factors 2 and 3: Towards a principled approach
SO CATALAN JOURNAL OF LINGUISTICS
LA English
DT Article
DE three factors; Universal Grammar; acquisition; crosslinguistic
   variation; poverty of the stimulus
ID LANGUAGE-ACQUISITION; SPEECH-PERCEPTION; UNIVERSAL GRAMMAR; SYNTAX;
   CONSTRAINTS; CATEGORIES; INTERFACE; EMERGENCE; NURTURE; INPUT
AB This paper seeks to make progress in our understanding of the non-UG components of Chomsky's (2005) Three Factors model. In relation to the input (Factor 2), I argue for the need to formulate a suitably precise hypothesis about which aspects of the input will qualify as 'intake' and, hence, serve as the basis for grammar construction. In relation to Factor 3, I highlight a specific cognitive bias that appears well motivated outside of language, while also having wide-ranging consequences for our understanding of how I-language grammars are constructed, and why they should have the crosslinguistically comparable form that generativists have always argued human languages have. This is Maximise Minimal Means (MMM). I demonstrate how its incorporation into our model of grammar acquisition facilitates understanding of diverse facts about natural language typology, acquisition, both in "stable" and "unstable" contexts, and also the ways in which linguistic systems may change over time.
C1 [Biberauer, Theresa] Univ Cambridge, Cambridge, England.
   [Biberauer, Theresa] Stellenbosch Univ, Stellenbosch, South Africa.
   [Biberauer, Theresa] Univ Western Cape, Cape Town, South Africa.
RP Biberauer, T (corresponding author), Univ Cambridge, Cambridge, England.; Biberauer, T (corresponding author), Stellenbosch Univ, Stellenbosch, South Africa.; Biberauer, T (corresponding author), Univ Western Cape, Cape Town, South Africa.
EM samtb23@gmail.com
FU European Research CouncilEuropean Research Council (ERC)European
   Commission [269752]; Cambridge Humanities Research Grant 'Learning from
   questions and commands: probing the nature and origins of native-speaker
   knowledge' (Biberauer 2015)
FX This paper, which partially reflects the content of a talk given at the
   'Generative Syntax 2017: Questions, Crossroads, and Challenges' meeting
   organized by Angel Gallego and Dennis Ott, is an expanded version of a
   working paper that appeared in the Cambridge Occasional Papers in
   Linguistics (COPiL) in August 2017 (Biberauer 2017e in the references).
   I thank the audience at the above-mentioned Barcelona meeting for their
   questions and comments; Ian Roberts for comments on the COPiL paper;
   Jamie Douglas, Julio Song, Erin Pretorius, Craig Sailor, Paula Buttery,
   Frances Blanchette, Jeroen van Craenenbroeck, Aritz Irurtzun, Daniel
   Harbour, Angel Gallego, Peter Msaka, Valentina Colasanti, and Hedde
   Zeijlstra for valuable discussions of diverse kinds; an anonymous
   reviewer for comments on an earlier draft of the present paper; Angel
   and Dennis for the invitation to write this up; and Angel yet again for
   crucial support at key points. The research reported here was initially
   funded by the European Research Council Advanced Grant No. 269752
   'Rethinking Comparative Syntax' (ReCoS), and a Cambridge Humanities
   Research Grant 'Learning from questions and commands: probing the nature
   and origins of native-speaker knowledge' (Biberauer 2015). Crucially, it
   also reflects unfunded work that has been undertaken on a 'Maximise
   Minimal Means' basis since the completion of the ReCoS project in May
   2017. Usual disclaimers apply.
CR ABLER WL, 1989, J SOC BIOL STRUCT, V12, P1, DOI 10.1016/0140-1750(89)90015-8
   Adger David, 2009, MIRRORS MICROPARAMET
   Ambridge Ben, 2013, LANGUAGE, V90, pe53
   Baunaz Laura, 2018, EXPLORING NANOSYNTAX
   Biberauer T., 2011, WORKSH FORM GRAMM SY
   Biberauer T., 2016, THEORETICAL APPROACH, P259, DOI 10.1075/la.234.10bib
   Biberauer T., 2017, CAMBRIDGE HDB HIST S, P134, DOI DOI 10.1017/9781107279070.008
   BIBERAUER T, 2015, CAMBRIDGE OCCASIONAL, V7, P1
   Biberauer T, 2017, LINGUIST INQ MONOGR, P187
   Biberauer T, 2014, LINGUIST INQ, V45, DOI 10.1162/LING_a_00153
   Biberauer T, 2010, LING AKT, V159, P35
   Biberauer T, 2008, LING AKT, V113, P79
   Biberauer Theresa, 2017, 4 FORM WAYS AN VAR F
   Biberauer Theresa, 2008, P 33 INC GRAMM GEN
   Biberauer Theresa, 2016, LANG CONT CONT CHANG
   Biberauer Theresa, 2014, MEASURING GRAMMATICA, P103, DOI DOI 10.1093/ACPROF:OSO/9780199685301.003.0006
   Biberauer Theresa, 2015, LEARNING QUESTIONS C
   Biberauer Theresa, 2008, LIMITS SYNTACTIC VAR, P1, DOI DOI 10.1075/LA.132
   Biberauer Theresa, 2017, VAR CHANG VERB PHRAS
   Biberauer Theresa, 2018, NULL SUBJECTS GENERA, P94
   Biberauer Theresa, 2012, DIGS 14 C LISB
   Biberauer Theresa, 2017, STELL LING RES SEM S
   Biberauer Theresa, 2013, THEORETICAL APPROACH, P1
   Biberauer Theresa, 2017, 3 DAY LECT SER CTR R
   Biberauer Theresa, 2009, LANGUAGE LINGUISTICS, V10, P699
   Biberauer Theresa, 2012, WAYS STRUCTURE BUILD, P206
   Biberauer Theresa, 2017, CAMBRIDGE OCCASIONAL, V10, P38
   Biberauer Theresa, 2009, HIST SYNTAX LINGUIST, P58
   Bobaljik JD, 2002, NAT LANG LINGUIST TH, V20, P197, DOI 10.1023/A:1015059006439
   Bobaljik JD, 2018, GLOSSA-UK, V3, DOI 10.5334/gjgl.345
   Boeckx C, 2015, CAMB STUD LINGUIST, P1
   Bond Oliver, 2016, ARCHI COMPLEXITIES A
   Bornstein MH, 2010, DEV PSYCHOL, V46, P350, DOI 10.1037/a0018411
   BOTTANI E, 2014, LINGUISTIC VARIATION, P13, DOI DOI 10.1533/9780857098115.13
   Bouchard D., 2013, NATURE ORIGIN LANGUA
   Branigan Phil, 2012, MACROPARAMETER UNPUB
   Brown R., 1973, 1 LANGUAGE EARLY STA
   Caha Pavel, 2009, THESIS
   Chomsky N, 2005, LINGUIST INQ, V36, P1, DOI 10.1162/0024389052993655
   CHOMSKY N, 1959, LANGUAGE, V35, P26, DOI 10.2307/411334
   Chomsky N., 1986, KNOWLEDGE LANGUAGE I
   Chomsky N., 2000, STEP STEP ESSAYS MIN, P89, DOI DOI 10.1017/S0022226702271625
   Chomsky N., 1981, LECT GOVT BINDING
   Chomsky N., 1995, MINIMALIST PROGRAM
   Chomsky N., 2001, KEN HALE LIFE LANGUA, P1, DOI DOI 10.1017/S0022226704322747
   Chomsky N, 2007, BIOLINGUISTICS, V1, P9
   Chomsky Noam, 1993, VIEW BUILDING 20 ESS, P1
   Chung S, 2012, THEOR LINGUIST, V38, P1, DOI 10.1515/tl-2012-0001
   Cinque G, 2013, LINGUA, V130, P50, DOI 10.1016/j.lingua.2012.10.007
   Cinque Guglielmo, 2005, U VENICE WORKING PAP, V15, P49
   Cinque Guglielmo, 2018, LINGUISTIC ANAL, V41, P309
   Clark E.V., 1993, LEXICON ACQUISITION
   Crain S, 2001, LINGUIST PHILOS, V24, P139, DOI 10.1023/A:1005694100138
   DAlessandro Roberta, 2017, THE VERBAL DOMAIN
   DAlessandro Roberta, 2018, MAGNETIC GRAMM UNPUB
   Dehaene Stanislas, 2007, READING BRAIN NEW SC
   DEMUTH K, 2003, BANTU LANGUAGES
   DEMUTH K, 1994, SYNTACTIC THEORY AND FIRST LANGUAGE ACQUISITION: CROSSLINGUISTIC PERSPECTIVES, VOL 1, P119
   Douglas J, 2018, GLOSSA-UK, V3, DOI 10.5334/gjgl.566
   Dresher B. Elan, 2014, NORDLYD, V42, P165, DOI 10.7557/12.3412
   Dresher Elan, 2009, CONTRASTIVE HIERARCH
   Dryer Matthew, 2009, NEGATION PATTERNS W, P307, DOI [10.1075/tsl.87.15dry, DOI 10.1075/TSL.87.15DRY]
   Duffield N, 2017, J EAST ASIAN LINGUIS, V26, P351, DOI 10.1007/s10831-017-9161-1
   Duffield Nigel, 2013, MINIMALISM SEM UNPUB
   Eguren Luis, 2016, RETHINKING PARAMETER
   ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4
   Epstein Samuel D., 2013, P GLOW ASIA, P77
   Evers Arnold, 2008, LIMITS SYNTACTIC VAR, P483
   Fasanella Adriana, 2016, RETHINKING PARAMETER, P105
   Fasanella Adriana, 2014, THESIS
   Ferreira F, 2007, LANG LINGUIST COMPAS, V1, P71, DOI 10.1111/j.1749-818x.2007.00007.x
   Fikkert Paula, 1994, ACQUISITION PROSODIC
   Fodor J. D., 2017, OXFORD HDB UNIVERSAL, P249
   Fodor JD, 2005, J LINGUIST, V41, P513, DOI 10.1017/S0022226705003439
   Foley Claire, 2003, SYNTAX, V6, P1
   Fortuny J, 2010, LING AKT, V164, P131
   Franco L, 2012, POZ STUD CONTEMP LIN, V48, P565, DOI 10.1515/psicl-2012-0026
   Freeman Thomas, 2016, METAPHYSICAL SYNTAX
   Fujita K, 2009, BIOLINGUISTICS, V3, P128
   Gagliardi Annie, 2012, THESIS
   Gallego Angel, 2011, OXFORD HDB LINGUISTI, P523
   Gass S. M., 1997, INPUT INTERACTION 2
   Gervain J, 2008, COGNITIVE PSYCHOL, V57, P56, DOI 10.1016/j.cogpsych.2007.12.001
   Gervain J, 2008, LANG LINGUIST COMPAS, V2, P1149, DOI 10.1111/j.1749-818x.2008.00089.x
   Gervain J, 2010, ANNU REV PSYCHOL, V61, P191, DOI 10.1146/annurev.psych.093008.100408
   Gianollo C., 2008, LIMITS SYNTACTIC VAR, P109, DOI [10.1075/la.132.05gia, DOI 10.1075/LA.132.05GIA]
   Gibson Hannah, 2017, CONJOINT DISJOINT AL, P61
   Gigerenzer G, 2000, EVOLUTION COGNITION, P3
   Grimshaw Jane, 1991, EXTENDED PROJE UNPUB
   Guardiano Cristina, 2017, OXFORD HDB UNIVERSAL, P377
   Guasti MT, 2017, LANGUAGE ACQUISITION
   Hall Daniel Currie, 2007, THESIS
   Harris Jesse, 2011, OCCASIONAL WORKING P, V38, P53
   Haspelmath M, 2010, LANGUAGE, V86, P663
   Hauser MD, 2002, SCIENCE, V298, P1569, DOI 10.1126/science.298.5598.1569
   Hawkins John A., 2009, CASE GRAMMATICAL REL, P167
   Heim Johannes, 2017, COMPLEXITY SPE UNPUB
   Henry Alison, 2015, FORM APPR MORPH VAR
   Henry Alison., 1995, BELFAST ENGLISH STAN
   Henry Alison, 2012, IBERIA, V4, P23
   Hockett Charles F., 1958, COURSE MODERN LINGUI
   Hornstein N, 2009, CATALAN J LINGUIST, V8, P113
   Hornstein N, 2008, BIOLINGUISTICS, V2, P57
   Huddleston Geoffrey, 1984, INTRO GRAMMAR ENGLIS
   Jaspers D, 2012, LOG UNIVERSALIS, V6, P227, DOI 10.1007/s11787-012-0044-y
   Jaspers Dany, 2013, GLOW 36 LUND
   Kahnemann D., 2011, THINKING FAST SLOW
   Kam CLH, 2005, LANG LEARN DEV, V1, P151, DOI 10.1207/s15473341lld0102_3
   Kampen Jacqueline van, 2004, CURRENT ISSUES LINGU, P163
   Kiss KE, 2008, LINGUIST INQ, V39, P441, DOI 10.1162/ling.2008.39.3.441
   Kitahara Hisatsugu, 2012, WAYS STRUCTURE BUILD, P253
   Kroch A., 1989, LANG VAR CHANGE, V1, P199, DOI [DOI 10.1017/S0954394500000168, 10.1017/S0954394500000168]
   LASNIK H, 1995, LINGUIST INQ, V26, P615
   Leffel Timothy, 2013, P NELS, V43, P265
   Leivada E, 2017, BIOLINGUISTICS, V11, P221
   LEVIN T, 2016, NATURAL LANGUAGE LIN, V35, P447
   Lidz J, 2015, ANNU REV LINGUIST, V1, P333, DOI 10.1146/annurev-linguist-030514-125236
   Lleo C, 1999, PROC ANN BUCLD, P407
   Lleo C, 2001, J CHILD LANG, V28, P262, DOI 10.1017/S0305000900004505
   LLEO C, 1998, MODELLE FLEXION
   Longobardi Giuseppe, 2018, LINGUISTIC ANAL, V41, P517
   Marti L, 2015, MIND LANG, V30, P437, DOI 10.1111/mila.12086
   McCloskey J, 2006, GEORGET U R, P87
   McCloskey Jim, 2016, CAMCOS 5 CAMBR UK
   McClosky J, 2000, LINGUIST INQ, V31, P57, DOI 10.1162/002438900554299
   MEHLER J, 1988, COGNITION, V29, P143, DOI 10.1016/0010-0277(88)90035-2
   Mehler Jacques, 1994, WHAT INFANTS KNOW NE
   Miller K. E. G., 2007, THESIS
   Miller K, 2012, LANG LEARN DEV, V8, P255, DOI 10.1080/15475441.2011.601249
   Miller KL, 2012, LANG ACQUIS, V19, P223, DOI 10.1080/10489223.2012.685026
   Milsark Gary, 1974, THESIS
   Mobbs Iain, 2015, THESIS
   Moore DR, 2002, BRIT MED BULL, V63, P171, DOI 10.1093/bmb/63.1.171
   Morin O, 2018, COGNITIVE SCI, V42, P664, DOI 10.1111/cogs.12550
   Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037/0096-1523.24.3.756
   Nespor M., 2003, LINGUE LINGUAGGIO, V2, P203, DOI [10. 1418/ 10879, DOI 10.1418/10879]
   Newmeyer Frederick J., 2004, LINGUISTIC VARIATION, V4, P181, DOI [10.1075/livy.4.06new, DOI 10.1075/LIVY.4.06NEW]
   Newmeyer Frederick J., 2005, POSSIBLE PROBABLE LA
   NEWPORT EL, 1990, COGNITIVE SCI, V14, P11, DOI 10.1016/0364-0213(90)90024-Q
   Panagiotidis Phoevos., 2014, CATEGORIAL FEATURES
   Pearl Lisa, OXFORD HDB EXPT SYNT
   Pearl Lisa, 2018, LANGUAGE APPEAR
   Perez-Leroux AT, 2018, LANGUAGE, V94, P332, DOI 10.1353/lan.2018.0019
   Perez-Leroux AT, 2012, LANG ACQUIS, V19, P301, DOI 10.1080/10489223.2012.685019
   Pesetsky David, 2014, RUSSIAN CASE MORPHOL
   Picallo Carme, 2014, LINGUISTIC VARIATION
   Pinker S., 1984, LANGUAGE LEARNABILIT
   Preminger O, 2018, STUD GENERAT GRAMM, V129, P355, DOI 10.1515/9781501506925-359
   Radford A., 1990, SYNTACTIC THEORY ACQ
   Ramchand G, 2014, LANG SCI, V46, P152, DOI 10.1016/j.langsci.2014.06.013
   Ramchand Gillian Catriona, 2008, VERB MEANING LEXICON
   Richards Marc, 2017, GEN SYNT 2016 CROSSR
   Richards Marc, 2014, SCALES HIERARCHIES C, P173
   Richards Norvin, 2010, UTTERING TREES
   Ritter E, 2014, NAT LANG LINGUIST TH, V32, P1331, DOI 10.1007/s11049-014-9248-6
   Ritter E, 2009, STUD GENERA GRAMMAR, V100, P153, DOI 10.1515/9783110217124.153
   RIZZI L, 1986, LINGUIST INQ, V17, P501
   Rizzi L., 2018, LINGUIST REV, V41, P159
   Rizzi L., 1982, ISSUES ITALIAN SYNTA
   Rizzi L, 2016, ANNU REV LINGUIST, V2, P139, DOI 10.1146/annurev-linguistics-011415-040827
   Rizzi Luigi, 1993, LANG ACQUIS, V3, P341
   Roberts I., 2003, SYNTACTIC CHANGE MIN
   Roberts I., 2019, PARAMETER HIERARCHIE
   ROBERTS Ian, 2007, DIACHRONIC SYNTAX
   Roberts Ian, 2012, PARAMETER THEORY LIN, P319
   Roeper T., 2005, UG EXTERNAL SYSTEMS, P155, DOI DOI 10.1075/LA.75.10ROE
   Roeper T, 2011, BIOLINGUISTICS, V5, P57
   Roeper Tom, 2004, P GEN APPR LANG ACQ, P401
   Sandler W, 2012, LANG LINGUIST COMPAS, V6, P162, DOI 10.1002/lnc3.326
   Sandler W, 2010, T PHILOL SOC, V108, P298, DOI 10.1111/j.1467-968X.2010.01242.x
   Santos A. L., 2009, MINIMAL ANSWERS ELLI
   Schuler Katherine, 2016, P ANN M COGNITIVE SC, P2321
   Schutze CT, 1996, PROC ANN BUCLD, P670
   Seuren PAM, 2014, LANGUAGE, V90, P607
   Sheehan M, 2017, LINGUIST INQ MONOGR, P1, DOI 10.7551/mitpress/8687.001.0001
   Sheehan Michelle, 2013, THEORETICAL APPROACH, P407, DOI DOI 10.1093/ACPROF:OSO/9780199684359.003.0015
   Shi RS, 2001, PSYCHOL SCI, V12, P70, DOI 10.1111/1467-9280.00312
   Shi RS, 1999, COGNITION, V72, pB11, DOI 10.1016/S0010-0277(99)00047-5
   Shlonsky U, 2010, LANG LINGUIST COMPAS, V4, P417, DOI 10.1111/j.1749-818x.2010.00202.x
   Song C., 2019, THESIS
   Starke Michael, 2009, NORDLYD, V36-1, P1, DOI DOI 10.7557/12.213
   Starke Michal, 2014, OXFORD LINGUISTICS, P140, DOI DOI 10.1093/ACPROF:OSO/9780198702894.003.0007
   Stokes SF, 2005, J SPEECH LANG HEAR R, V48, P817, DOI 10.1044/1092-4388(2005/057)
   Svenonius Peter, 2002, SUBJECTS EXPLETIVES, P3
   Thornton R., 1995, LANG ACQUIS, V4, P139, DOI DOI 10.1080/10489223.1995.9671662
   Tsimpli IM, 2014, LINGUIST APPROACH BI, V4, P283, DOI 10.1075/lab.4.3.01tsi
   van Riemsdijk H, 2008, CURR STUD LINGUIST, P227
   Vikner Sten, 1995, VERB MOVEMENT EXPLET
   von Humboldt Wilhelm, 2008, VERSCHIEDENHEIT MENS
   Wallage Phillip, 2017, NEGATION EARLY ENGLI
   Westergaard Marit, 2009, ACQUISITION WORD ORD
   Wexler K, 1998, LINGUA, V106, P23, DOI 10.1016/S0024-3841(98)00029-1
   Willis David, 2016, EXAPTATION LANGUAGE, P227
   Wiltschko W, 2014, CAMB STUD LINGUIST, V142, P1, DOI 10.1017/CBO9781139833899
   Woods Rebecca, RETHINKING VERB 2
   Yang C., 2016, PRICE PRODUCTIVITY C
   Zeijlstra Hedde, 2008, LIMITS SYNTACTIC VAR, P143, DOI DOI 10.1075/LA.132.06ZEI
NR 197
TC 1
Z9 1
U1 0
U2 0
PU UNIV AUTONOMA BARCELONA, SERV PUBLICACIONS
PI BARCELONA
PA EDIFICI A, BELLATERRA, CARDANYOLA VALLES, BARCELONA, 08193, SPAIN
SN 1695-6885
EI 2014-9719
J9 CATALAN J LINGUIST
JI Catalan J. Linguist.
PY 2019
SI SI
BP 45
EP 88
DI 10.5565/rev/catjl.219
PG 44
WC Language & Linguistics
SC Linguistics
GA MY8KL
UT WOS:000558665600003
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Faure, EV
   Shvydkyi, VV
   Lavdanskyi, AO
   Kharin, OO
AF Faure, E., V
   Shvydkyi, V. V.
   Lavdanskyi, A. O.
   Kharin, O. O.
TI METHODS OF FACTORIAL CODING OF SPEECH SIGNALS
SO RADIO ELECTRONICS COMPUTER SCIENCE CONTROL
LA English
DT Article
DE factorial code; permutation; speech sample; samples recovery; decoding
   noise
ID CODES; MATRICES; SYSTEMS
AB Context. The paper outlines the methods of factorial coding of speech signals using a factorial code to provide integrated information security and to maintain a receiver and transmitter clock phase. By integrated information security, for the methods proposed in this article, we mean data protection from effects of noise in communication channel and attempts of data unauthorized access in open multiple access telecommunication networks.
   Objective. The goal of the research is to provide integrated protection of real-time speech signals based on factorial coding. For this, the methods for factorial coding of speech signals and building speech codecs have been developed. These methods are based on the properties of factorial codes to keep synchronism with the working signal, to detect a significant part of errors caused by the action of noise, natural or created intentionally, to provide the ability to correct all detected errors with a finite accuracy, as well as to provide cryptographic protection against voice message unauthorized listening by hiding the law of converting speech signal samples into a permutation.
   Method. The main idea of the proposed methods is to choose permutations for information transferring with a specific set of properties and features that provide the ability to correct errors detected by code and to recover speech signal samples with a finite degree of accuracy (with a nonzero aperture).
   Results. The procedures for information coding/decoding have been determined. The results of the experimental evaluation of the model of such systems when working on a communication channel with both independent and multiple bit errors are presented. The magnitude of decoding noise due to the finite accuracy of speech signal samples recovery is determined as a function of bit error probability in a communication channel.
   Conclusions. The proposed methods of factorial coding of a speech signal provide integrated information security and recovery with finite accuracy of speech signal samples deformed by noise in communication channel. The requirements to the quality of communication channel (to the value of bit error probability) for comfortable speech perception are determined.
C1 [Faure, E., V] Cherkasy State Technol Univ, Res & Int Relat, Cherkassy, Ukraine.
   [Shvydkyi, V. V.; Lavdanskyi, A. O.; Kharin, O. O.] Cherkasy State Technol Univ, Dept Informat Secur & Comp Engn, Cherkassy, Ukraine.
RP Faure, EV (corresponding author), Cherkasy State Technol Univ, Res & Int Relat, Cherkassy, Ukraine.
RI Faure, Emil/Q-8061-2016
OI Faure, Emil/0000-0002-2046-481X
CR Babar Z, 2019, IEEE COMMUN SURV TUT, V21, P970, DOI 10.1109/COMST.2018.2861361
   Borisenko A. A, 2013, VISNIK SUMSKOGO DERZ, P15
   ELLIOTT EO, 1963, AT&T TECH J, V42, P1977, DOI 10.1002/j.1538-7305.1963.tb00955.x
   Ellis M, 2014, COMPUT NETW, V70, P384, DOI 10.1016/j.comnet.2014.05.013
   Faure EV, 2018, RADIO ELECTRON COMPU, P143, DOI 10.15588/1607-3274-2018-2-16
   Faure EV, 2017, RADIO ELECTRON COMPU, P130, DOI 10.15588/1607-3274-2017-3-15
   Faure EV, 2016, RADIO ELECTRON COMPU, P80, DOI 10.15588/1607-3274-2016-3-10
   Faure EV, 2016, CYBERN SYST ANAL+, V52, P277, DOI 10.1007/s10559-016-9824-3
   Faure E'. V, 2017, J BAKU ENG U MATH CO, V1, P3
   Faure E. V, 2016, VISNYK CHERKASKOGO D, P33, DOI 10.24025/bulletinchstu.v1i2.82932
   Pereira FRF, 2019, IEEE T COMMUN, V67, P73, DOI 10.1109/TCOMM.2018.2875754
   GILBERT EN, 1960, BELL SYST TECH J, V39, P1253, DOI 10.1002/j.1538-7305.1960.tb03959.x
   Gnatyuk S, 2020, ADV INTELL SYST, V902, P561, DOI 10.1007/978-3-030-12082-5_51
   Gnatyuk S, 2016, NATO SCI PEAC SECUR, V47, P308
   Hagelbarger D. W., 1960, AIEE WINT GEN M NEW
   HAGELBARGER DW, 1959, AT&T TECH J, V38, P969, DOI 10.1002/j.1538-7305.1959.tb01584.x
   Hasslinger G, 2008, MEAS MOD EV COMP COM
   Heegard C, 1999, TURBO CODING, DOI [10.1007/978-1-4757-2999-3, DOI 10.1007/978-1-4757-2999-3]
   L'Ecuyer P, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1268776.1268777
   Lavdanskyi A. O, 2016, SCI POT PRES INT SCI, P123
   Marsaglia George, DIEHARD BATTERY TEST
   Mazurkov M. I., 2013, Radioelectronics and Communications Systems, V56, P133, DOI 10.3103/S0735272713030047
   Mazurkov M. I., 2011, Radioelectronics and Communications Systems, V54, P227, DOI 10.3103/S0735272711050013
   Mazurkov M I, 2008, Radioelectronics and Communications Systems, V51, P612, DOI 10.3103/S0735272708110095
   McEliece R. J., 1978, 44 DSN JET PROP LAB, V44, P114
   Nooraiepour A, 2017, IEEE T COMMUN, V65, P3442, DOI 10.1109/TCOMM.2017.2704586
   Osmolovskij S. A., 2012, STOXASTICHESKAYA INF
   Panayiotis D. P, 2001, 3 GEN WIR INT C SAN
   Rabiner LR, 2007, FOUND TRENDS SIGNAL, V1, P1, DOI 10.1561/2000000001
   Rukhin A., 2010, NIST SPECIAL PUBLICA, P1, DOI DOI 10.6028/NIST.SP.800-22R1A
   Stakhov AP, 2007, CHAOS SOLITON FRACT, V32, P1138, DOI 10.1016/j.chaos.2006.03.069
   Stakhov AP, 2006, CHAOS SOLITON FRACT, V30, P56, DOI 10.1016/j.chaos.2005.12.054
   STAKHOV AP, 1999, INTRO FIBONACCI CODI
   WANG L, 2016, IEEE-ACM T AUDIO SPE, V24, P571
   Weithoffer S, 2018, INT SYM TURBO CODES
   Yang Q, 2015, IEEE T WIREL COMMUN, V14, P1380, DOI 10.1109/TWC.2014.2365822
NR 36
TC 0
Z9 0
U1 0
U2 0
PU ZAPORIZHZHYA NATL TECHNICAL UNIV
PI ZAPORIZHZHYA
PA VUL ZHUKOVSKA, 64, ZAPORIZHZHYA, 69063, UKRAINE
SN 1607-3274
EI 2313-688X
J9 RADIO ELECTRON COMPU
JI Radio Electron. Comput. Sci. Control
PY 2019
IS 4
BP 186
EP 198
DI 10.15588/1607-3274-2019-4-18
PG 13
WC Computer Science, Hardware & Architecture
SC Computer Science
GA KM5TH
UT WOS:000514201900018
OA DOAJ Gold
DA 2021-02-24
ER

PT S
AU Creel, SC
AF Creel, Sarah C.
BE Federmeier, KD
TI Protracted perceptual learning of auditory pattern structure in spoken
   language
SO PSYCHOLOGY OF LEARNING AND MOTIVATION, VOL 71
SE Psychology of Learning and Motivation
LA English
DT Article; Book Chapter
ID MISMATCH NEGATIVITY MMN; SPEECH-PERCEPTION; DEVELOPMENTAL-CHANGES;
   CHILDRENS PERCEPTION; PHONETIC DETAIL; SENSORY MEMORY; PHONOTACTIC
   PROBABILITY; INFANTS PERCEPTION; VOCABULARY GROWTH; WORD RECOGNITION
AB The chapter addresses the developmental time course of the perceptual learning underlying spoken language. Many researchers suggest that most of this learning has saturated around the end of the first year of life-during infancy. My own work with young children suggests a different perspective: protracted perceptual learning. I lay out the evidence for perceptual precocity and explain why I think the perceptual precocity story is wrong. Following this, I present my findings on young children's perceptual processing in speech and non-speech contexts (word learning, voice learning, melody learning), using visual fixations and pointing accuracy as response measures. Across all measures, children undershoot adult performance, particularly when perceptual attributes are challenging to tell apart. I then describe alternative, non-perceptual explanations for these findings, as well as ways to address said explanations. Last, I outline possible paths toward a unified picture of auditory perceptual learning across development.
C1 [Creel, Sarah C.] Univ Calif San Diego, Dept Cognit Sci, La Jolla, CA 92093 USA.
RP Creel, SC (corresponding author), Univ Calif San Diego, Dept Cognit Sci, La Jolla, CA 92093 USA.
EM screel@ucsd.edu
FU NSFNational Science Foundation (NSF) [BCS-1057080, BCS-1230003]
FX Research described here was supported by NSF Grants BCS-1057080 and
   BCS-1230003. I am also indebted to my coauthors-particularly Carolyn
   Quam, Gail Heyman, and Sofia Jimenez-as well as a large group of lab
   assistants and undergraduate researchers who have allowed all of this
   science to take place.
CR Aoyama K, 2004, J PHONETICS, V32, P233, DOI 10.1016/S0095-4470(03)00036-6
   BARTHOLOMEUS B, 1973, CAN J PSYCHOL, V27, P464, DOI 10.1037/h0082498
   Barton D., 1976, PAPERS REPORTS CHILD, V11, P1
   Bent T., 2018, SHHH NEED QUIET CHIL
   Bent T, 2018, LANG SPEECH, V61, P657, DOI 10.1177/0023830918754598
   Bent T, 2014, J CHILD LANG, V41, P1334, DOI 10.1017/S0305000913000457
   Bergelson E, 2018, CHILD DEV, V89, P1567, DOI 10.1111/cdev.12888
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   Berman JMJ, 2010, J EXP CHILD PSYCHOL, V107, P87, DOI 10.1016/j.jecp.2010.04.012
   Borovsky A, 2014, DEV PSYCHOL, V50, P1600, DOI 10.1037/a0035591
   Bouchon C, 2015, DEVELOPMENTAL SCI, V18, P587, DOI 10.1111/desc.12242
   Brown T, 2012, BREAKING THE FOURTH WALL: DIRECT ADDRESS IN THE CINEMA, P22
   Carpenter SK, 2013, MEM COGNITION, V41, P671, DOI 10.3758/s13421-012-0291-4
   Cepeda NJ, 2009, EXP PSYCHOL, V56, P236, DOI 10.1027/1618-3169.56.4.236
   Cheour M, 2000, CLIN NEUROPHYSIOL, V111, P4, DOI 10.1016/S1388-2457(99)00191-1
   Cheour M, 2002, SCAND J PSYCHOL, V43, P33, DOI 10.1111/1467-9450.00266
   COWAN N, 1993, J EXP PSYCHOL LEARN, V19, P909, DOI 10.1037/0278-7393.19.4.909
   Cowan N, 2017, ADV CHILD DEV BEHAV, V52, P81, DOI 10.1016/bs.acdb.2016.12.001
   Cowan N, 2016, PERSPECT PSYCHOL SCI, V11, P239, DOI 10.1177/1745691615621279
   Creel SC, 2008, COGNITION, V106, P633, DOI 10.1016/j.cognition.2007.03.013
   Creel SC, 2019, ATTEN PERCEPT PSYCHO, V81, P948, DOI 10.3758/s13414-018-01663-7
   Creel SC, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12524
   Creel SC, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12503
   Creel SC, 2016, COGNITIVE SCI, V40, P373, DOI 10.1111/cogs.12237
   Creel SC, 2015, TRENDS COGN SCI, V19, P713, DOI 10.1016/j.tics.2015.09.006
   Creel SC, 2014, J MEM LANG, V73, P81, DOI 10.1016/j.jml.2014.03.001
   Creel SC, 2014, J EXP PSYCHOL HUMAN, V40, P1146, DOI 10.1037/a0036057
   Creel SC, 2012, J EXP CHILD PSYCHOL, V113, P487, DOI 10.1016/j.jecp.2012.07.007
   Davelaar EJ, 2011, COGN AFFECT BEHAV NE, V11, P608, DOI 10.3758/s13415-011-0056-8
   DECASPER AJ, 1980, SCIENCE, V208, P1174, DOI 10.1126/science.7375928
   EILERS RE, 1977, J SPEECH HEAR RES, V20, P766, DOI 10.1044/jshr.2004.766
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   ELLIOTT LL, 1979, J ACOUST SOC AM, V66, P651, DOI 10.1121/1.383691
   EMILFLEGE J, 1987, APPL LINGUIST, V8, P162
   Estes KG, 2011, INFANCY, V16, P180, DOI 10.1111/j.1532-7078.2010.00046.x
   Fallon M, 2000, J ACOUST SOC AM, V108, P3023, DOI 10.1121/1.1323233
   Fallon M, 2002, J ACOUST SOC AM, V111, P2242, DOI 10.1121/1.1466873
   Fancourt A., 2013, PSYCHOMUSICOLOGY, V23, P73, DOI [10.1037/a0033301, DOI 10.1037/A0033301]
   Feldman NH, 2013, COGNITION, V127, P427, DOI 10.1016/j.cognition.2013.02.007
   Feldman NH, 2009, PSYCHOL REV, V116, P752, DOI 10.1037/a0017196
   Fennell CT, 2010, CHILD DEV, V81, P1376, DOI 10.1111/j.1467-8624.2010.01479.x
   Fennell CT, 2003, LANG SPEECH, V46, P245, DOI 10.1177/00238309030460020901
   Fernald A, 1998, PSYCHOL SCI, V9, P228, DOI 10.1111/1467-9280.00044
   Fernald A, 2006, DEV PSYCHOL, V42, P98, DOI 10.1037/0012-1649.42.1.98
   Fernald A, 2012, CHILD DEV, V83, P203, DOI 10.1111/j.1467-8624.2011.01692.x
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege JE, 1992, PHONOLOGICAL DEV MOD, P565
   Floccia C, 2016, COGNITION, V148, P1, DOI 10.1016/j.cognition.2015.12.004
   Floccia C, 2009, INT J BEHAV DEV, V33, P366, DOI 10.1177/0165025409103871
   Friend M, 2000, MERRILL PALMER QUART, V46, P342
   Galle ME, 2015, LANG LEARN DEV, V11, P66, DOI 10.1080/15475441.2014.895249
   Garnica O. K., 1971, PAPERS REPORTS CHILD, V3, P1
   Girard F, 2008, BRIT J DEV PSYCHOL, V26, P409, DOI 10.1348/026151007X251712
   Gomes H, 1999, DEV PSYCHOL, V35, P294, DOI 10.1037/0012-1649.35.1.294
   Gordon KR, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01439
   GRAVEL JS, 1992, INT J PEDIATR OTORHI, V23, P59, DOI 10.1016/0165-5876(92)90080-9
   Haden GP, 2009, PSYCHOPHYSIOLOGY, V46, P69, DOI 10.1111/j.1469-8986.2008.00749.x
   HAITH MM, 1990, MERRILL PALMER QUART, V36, P1
   Halpern AR, 2010, SPRINGER HANDB AUDIT, V36, P233, DOI 10.1007/978-1-4419-6114-3_8
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   Holt RF, 2007, J SPEECH LANG HEAR R, V50, P1404, DOI 10.1044/1092-4388(2007/098)
   Holt RF, 2012, INT J PEDIATR OTORHI, V76, P680, DOI 10.1016/j.ijporl.2012.02.020
   Houston DM, 2000, J EXP PSYCHOL HUMAN, V26, P1570, DOI 10.1037/0096-1523.26.5.1570
   Imada T, 2006, NEUROREPORT, V17, P957, DOI 10.1097/01.wnr.0000223387.51704.89
   Ito K, 2014, J CHILD LANG, V41, P84, DOI 10.1017/S0305000912000554
   Johnson EK, 2011, DEVELOPMENTAL SCI, V14, P1002, DOI 10.1111/j.1467-7687.2011.01052.x
   Jones Z, 2017, J PHONETICS, V60, P20, DOI 10.1016/j.wocn.2016.11.001
   JUSCZYK PW, 1993, J PHONETICS, V21, P3, DOI 10.1016/S0095-4470(19)31319-1
   Kang SHK, 2012, APPL COGNITIVE PSYCH, V26, P97, DOI 10.1002/acp.1801
   Keen R, 2003, CURR DIR PSYCHOL SCI, V12, P79, DOI 10.1111/1467-8721.01234
   KELLER TA, 1994, DEV PSYCHOL, V30, P855, DOI 10.1037/0012-1649.30.6.855
   Kisilevsky BS, 2003, PSYCHOL SCI, V14, P220, DOI 10.1111/1467-9280.02435
   Kuhl PK, 2014, P NATL ACAD SCI USA, V111, P11238, DOI 10.1073/pnas.1410963111
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   KUHL PK, 1983, INFANT BEHAV DEV, V6, P263, DOI 10.1016/S0163-6383(83)80036-8
   KUHL PK, 1979, J ACOUST SOC AM, V66, P1668, DOI 10.1121/1.383639
   KUHL PK, 2006, DEVELOPMENTAL SCI, V9, pF1, DOI DOI 10.1111/J.1467-7687.2006.00468.X
   Magnuson JS, 2003, J EXP PSYCHOL GEN, V132, P202, DOI 10.1037/0096-3445.132.2.202
   MANN VA, 1979, J EXP CHILD PSYCHOL, V27, P153, DOI 10.1016/0022-0965(79)90067-5
   Marchman VA, 2008, DEVELOPMENTAL SCI, V11, pF9, DOI 10.1111/j.1467-7687.2008.00671.x
   McMurray B, 2018, DEV PSYCHOL, V54, P1472, DOI 10.1037/dev0000542
   Morton JB, 2001, CHILD DEV, V72, P834, DOI 10.1111/1467-8624.00318
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Nathan L, 1998, J CHILD LANG, V25, P343, DOI 10.1017/S0305000998003444
   Nelson NL, 2011, J EXP CHILD PSYCHOL, V110, P52, DOI 10.1016/j.jecp.2011.03.014
   Nittrouer S, 2001, J ACOUST SOC AM, V110, P1598, DOI 10.1121/1.1379078
   Oh GE, 2011, J PHONETICS, V39, P156, DOI 10.1016/j.wocn.2011.01.002
   Ohde RN, 1997, J ACOUST SOC AM, V102, P3711, DOI 10.1121/1.420135
   Onnis L, 2008, COGNITION, V109, P423, DOI 10.1016/j.cognition.2008.10.004
   Pajak B, 2016, J EXP PSYCHOL LEARN, V42, P1377, DOI 10.1037/xlm0000247
   Pater J, 2004, LANGUAGE, V80, P384, DOI 10.1353/lan.2004.0141
   Polka L, 2001, J ACOUST SOC AM, V109, P2190, DOI 10.1121/1.1362689
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Quam C, 2012, CHILD DEV, V83, P236, DOI 10.1111/j.1467-8624.2011.01700.x
   Rigler H, 2015, DEV PSYCHOL, V51, P1690, DOI 10.1037/dev0000044
   Rost GC, 2010, INFANCY, V15, P608, DOI 10.1111/j.1532-7078.2010.00033.x
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Saindon MR, 2017, LANG LEARN DEV, V13, P274, DOI 10.1080/15475441.2016.1252681
   Saindon MR, 2016, J CHILD LANG, V43, P1174, DOI 10.1017/S0305000915000458
   SAMS M, 1993, J COGNITIVE NEUROSCI, V5, P363, DOI 10.1162/jocn.1993.5.3.363
   Schwab JF, 2016, DEV PSYCHOL, V52, P879, DOI 10.1037/dev0000125
   Sekerina IA, 2007, J EXP CHILD PSYCHOL, V98, P20, DOI 10.1016/j.jecp.2007.04.005
   Spence MJ, 2002, J SPEECH LANG HEAR R, V45, P214, DOI 10.1044/1092-4388(2002/016)
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Stalinski SM, 2008, J ACOUST SOC AM, V124, P1759, DOI 10.1121/1.2956470
   Storkel HL, 2003, J SPEECH LANG HEAR R, V46, P1312, DOI 10.1044/1092-4388(2003/102)
   Storkel HL, 2001, J SPEECH LANG HEAR R, V44, P1321, DOI 10.1044/1092-4388(2001/103)
   Sundara M, 2006, COGNITION, V100, P369, DOI 10.1016/j.cognition.2005.04.007
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Swingley D, 2002, PSYCHOL SCI, V13, P480, DOI 10.1111/1467-9280.00485
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Thiessen ED, 2007, J MEM LANG, V56, P16, DOI 10.1016/j.jml.2006.07.002
   Tincoff R, 1999, PSYCHOL SCI, V10, P172, DOI 10.1111/1467-9280.00127
   Tincoff R, 2012, INFANCY, V17, P432, DOI 10.1111/j.1532-7078.2011.00084.x
   TRAINOR LJ, 1994, PERCEPT PSYCHOPHYS, V56, P125, DOI 10.3758/BF03213891
   Trehub SE, 2012, ANN NY ACAD SCI, V1252, P37, DOI 10.1111/j.1749-6632.2012.06448.x
   TREHUB SE, 1984, CHILD DEV, V55, P821, DOI 10.2307/1130133
   TREHUB SE, 1979, CAN J PSYCHOL, V33, P368, DOI 10.1037/h0081733
   TREHUB SE, 1985, INFANT BEHAV DEV, V8, P213, DOI 10.1016/S0163-6383(85)80007-2
   van Heugten M, 2014, EAR HEARING, V35, P118, DOI 10.1097/AUD.0b013e3182a468d0
   VANLANCKER D, 1989, DEV NEUROPSYCHOL, V5, P207, DOI 10.1080/87565648909540433
   VIEMEISTER NF, 1991, J ACOUST SOC AM, V90, P858, DOI 10.1121/1.401953
   Vlach HA, 2013, COGNITION, V127, P375, DOI 10.1016/j.cognition.2013.02.015
   Vlach HA, 2012, J EXP PSYCHOL LEARN, V38, P246, DOI 10.1037/a0025260
   Vlach HA, 2008, COGNITION, V109, P163, DOI 10.1016/j.cognition.2008.07.013
   Wagner L, 2014, J CHILD LANG, V41, P1062, DOI 10.1017/S0305000913000330
   Walley AC., 2003, READING WRITING, V16, P5, DOI [DOI 10.1023/A:1021789804977, 10.1023/A:1021789804977]
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1983, CAN J PSYCHOL, V37, P278, DOI 10.1037/h0080725
   White KS, 2008, J MEM LANG, V59, P114, DOI 10.1016/j.jml.2008.03.001
   Yoshida KA, 2009, DEVELOPMENTAL SCI, V12, P412, DOI 10.1111/j.1467-7687.2008.00789.x
NR 134
TC 0
Z9 0
U1 0
U2 2
PU ELSEVIER ACADEMIC PRESS INC
PI SAN DIEGO
PA 525 B STREET, SUITE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0079-7421
BN 978-0-12-817176-9; 978-0-12-817175-2
J9 PSYCHOL LEARN MOTIV
JI Psychol. Learn. Motiv.
PY 2019
VL 71
BP 67
EP 105
DI 10.1016/bs.plm.2019.07.003
PG 39
WC Psychology, Experimental
SC Psychology
GA BO1ON
UT WOS:000501720200003
DA 2021-02-24
ER

PT J
AU Kiakojuri, K
   Ghahari, BY
   Soltanparast, S
   Monadi, M
AF Kiakojuri, Keyvan
   Ghahari, Behnaz Yousef
   Soltanparast, Sanaz
   Monadi, Mohsen
TI Hearing status in patients with rheumatoid arthritis
SO CASPIAN JOURNAL OF INTERNAL MEDICINE
LA English
DT Article
DE Rheumatoid arthritis; Sensorineural hearing loss; Audiometry;
   Tympanometry; Speech perception; Hearing loss
ID MIDDLE-EAR INVOLVEMENT; DISEASE-ACTIVITY; IMPAIRMENT
AB Background: Previous studies showed that one of the complications of rheumatoid arthritis disease was auditory disorder. The goal of the present study was to compare the auditory status in patients with rheumatoid arthritis and healthy individuals.
   Methods: In the present case-control study, 30 normal persons and 60 persons with rheumatoid arthritis with mean age of 46.72 and standard deviation of 6.76 of both genders were appraised using pure tone audiometry, tympanometry and speech audiometry. The mean disease duration in patients with rheumatoid arthritis was 12.51 +/- 6.09 years.
   Results: The frequency of hearing loss in rheumatoid arthritis group was significantly more than the control group (p=0.001). All patients had sensorineural hearing loss. Only in 5% of rheumatoid arthritis group, abnormal tympanometry (as type) was reported. Speech discrimination score analysis showed significant difference between the patients with rheumatoid arthritis and controls. In terms of hearing threshold level, the mean hearing threshold level (in 2000, 4000 and 8000 Hz frequencies) of the patients with rheumatoid arthritis was significantly higher than control group in both ears (p<0.05). A positive significant correlation was found among mean hearing threshold level in 4000 and 8000 Hz frequencies and rheumatoid arthritis duration in both ears.
   Conclusion: The frequency of hearing loss and the average hearing threshold in RA patients were higher than healthy individuals. The most common type hearing loss is sensorineural.
C1 [Kiakojuri, Keyvan] Babol Univ Med Sci, Dept ENT, Babol Sar, Iran.
   [Ghahari, Behnaz Yousef] Babol Univ Med Sci, Dept Internal Med, Babol Sar, Iran.
   [Soltanparast, Sanaz] Iran Univ Med Sci, Dept Audiol, Sch Rehabil, Kargar Sq,Ganj Afrooz Ave, Tehran, Iran.
RP Monadi, M (corresponding author), Iran Univ Med Sci, Dept Audiol, Sch Rehabil, Kargar Sq,Ganj Afrooz Ave, Tehran, Iran.
EM monadi.mohsen@yahoo.com
FU Babol University of Medical Sciences [2219]
FX This article is an approved project of Babol University of Medical
   Sciences with contract number 2219. We would like to acknowledge the
   Rehabilitation Research Center and Ayatollah Rouhani Hospital of Babol
   for their utmost help with the project.
CR Ahmadzadeh A, 2017, J LARYNGOL OTOL, V131, P895, DOI 10.1017/S0022215117001670
   Galarza-Delgado DA, 2018, CLIN RHEUMATOL, V37, P367, DOI 10.1007/s10067-017-3959-0
   Arslan N, 2011, J INT ADV OTOL, V7, P208
   Dikici O, 2009, EUR ARCH OTO-RHINO-L, V266, P1719, DOI 10.1007/s00405-009-0975-y
   ELWANY S, 1986, J RHEUMATOL, V13, P878
   Emamifar A, 2018, J Otol, V13, P1, DOI 10.1016/j.joto.2017.10.002
   Firestein GS, 2003, NATURE, V423, P356, DOI 10.1038/nature01661
   Callejo FJG, 2007, ACTA OTORRINOLAR ESP, V58, P232, DOI 10.1016/S0001-6519(07)74919-1
   Halligan CS, 2006, LARYNGOSCOPE, V116, P2044, DOI 10.1097/01.mlg.0000241365.54017.32
   Huang CM, 2018, BMJ OPEN, V8, DOI 10.1136/bmjopen-2017-018134
   Jeong H, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0164591
   KASTANIOUDAKIS I, 1995, J LARYNGOL OTOL, V109, P713, DOI 10.1017/S0022215100131135
   de la Vega ML, 2016, SCIENTIFICA, V2016, DOI 10.1155/2016/5713283
   Lobo FS, 2016, CLIN RHEUMATOL, V35, P2327, DOI 10.1007/s10067-016-3278-x
   Trevino-Gonzalez JL, 2015, CIR CIR, V83, P364, DOI 10.1016/j.circir.2015.05.026
   MAGARO M, 1990, CLIN EXP RHEUMATOL, V8, P487
   McInnes IB, 2011, NEW ENGL J MED, V365, P2205, DOI 10.1056/NEJMra1004965
   Ozcan M, 2002, RHEUMATOL INT, V22, P16, DOI 10.1007/s00296-002-0185-z
   Ozturk A, 2004, AM J OTOLARYNG, V25, P411, DOI 10.1016/j.amjoto.2004.06.001
   Pascual-Ramos V, 2014, CLIN RHEUMATOL, V33, P315, DOI 10.1007/s10067-014-2485-6
   Pascual-Ramos V, 2012, JCR-J CLIN RHEUMATOL, V18, P393, DOI 10.1097/RHU.0b013e31827732d3
   Rahne T, 2017, CLIN RHEUMATOL, V36, P1501, DOI 10.1007/s10067-017-3651-4
   Raut VV, 2001, J OTOLARYNGOL, V30, P289, DOI 10.2310/7070.2001.19580
   REITER D, 1980, ARCH OTOLARYNGOL, V106, P114
   ROSENBERG JN, 1978, ANN RHEUM DIS, V37, P522, DOI 10.1136/ard.37.6.522
   Salvinelli F, 2004, CLIN OTOLARYNGOL, V29, P75, DOI 10.1111/j.1365-2273.2004.00783.x
   Seckin U, 2000, RHEUMATOL INT, V19, P203, DOI 10.1007/s002960000054
   Takatsu M, 2005, OTOL NEUROTOL, V26, P755, DOI 10.1097/01.mao.0000178138.19848.bd
   Yildirim A, 2016, CLIN RHEUMATOL, V35, P309, DOI 10.1007/s10067-015-3129-1
NR 29
TC 0
Z9 0
U1 0
U2 0
PU BABOL UNIV MEDICAL SCIENCES
PI BABOL
PA ENGLISH JOURNAL OFFICE, GANJ AFROOZ AVE, BABOL, 00000, IRAN
SN 2008-6164
EI 2008-6172
J9 CASP J INTERN MED
JI Casp. J. Intern. Med.
PY 2019
VL 10
IS 4
BP 447
EP 451
DI 10.22088/cjim.10.4.447
PG 5
WC Medicine, General & Internal
SC General & Internal Medicine
GA JU3NM
UT WOS:000501583500013
PM 31814944
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Pastusiak, A
   Niemiec, D
   Kocinski, J
   Warzybok, A
AF Pastusiak, Anna
   Niemiec, Dawid
   Kocinski, Jedrzej
   Warzybok, Anna
TI The Benefit of Binaural Hearing Among Listeners with Sensorineural
   Hearing Loss
SO ARCHIVES OF ACOUSTICS
LA English
DT Article
DE hearing; speech audiometry; speech perception; audiology
ID SPEECH-INTELLIGIBILITY; SENTENCE INTELLIGIBILITY; INFORMATIONAL MASKING;
   FLUCTUATING NOISE; SPATIAL UNMASKING; MATRIX TEST; SEPARATION;
   THRESHOLD; TESTS
AB The performance of binaural processing may be disturbed in the presence of hearing loss, especially of sensorineural type. To assess the impact of hearing loss on speech perception in noise regarding binaural processing, series of speech recognition measurements in controlled laboratory conditions were carried out. The spatial conditions were simulated using dummy head recordings played back on headphones. The Intelligibility Level Difference (ILD) was determined by measuring the change in the speech reception thresholds (SRT) between two configurations of a masking signal source (N) and a speech source (S), namely the S0N90 condition (where numbers stand for angles in horizontal plane) and the co-located condition (S0N0). To disentangle the head shadow effect (better ear effect) from binaural processing in the brain, the difference between binaural and monaural S0N90 condition (so-called Binaural Intelligibility Level Difference, BILD) value was calculated.
   Measurements were performed with a control group of normal-hearing listeners and a group of sensorineural hearing-impaired subjects. In all conditions performance of the hearing-impaired listeners was significantly lower than normal-hearing ones, resulting in higher SRT values (3 dB difference in the S0N0 configuration, 7.6 dB in S0N90 and 5 dB in monaural S0N90). The SRT improvement due to the spatial separation of target and masking signal (ILD) was also higher in the control group (8.1 dB) than in hearing-impaired listeners (3.5 dB). Moreover, a significant deterioration of the binaural processing described by BILD was found in people with sensorineural deficits. This parameter for normal-hearing listeners reached a value of 3 to 6 dB (4.6 dB on average) and decreased more than two times in the hearing-impaired group to 1.9 dB on average (with a deviation of 1.4 dB). These findings could not be explained by individual average hearing threshold (standard in audiological diagnostics) only. The outcomes indicate that there is a contribution of suprathershold deficits and it may be useful to consider binaural SRT measurements in noise in addition to the pure tone audiometry resulting in better diagnostics and hearing aid fitting.
C1 [Pastusiak, Anna; Niemiec, Dawid; Kocinski, Jedrzej] Adam Mickiewicz Univ, Fac Phys, Inst Acoust, Umultowska 85, PL-61614 Poznan, Poland.
   [Warzybok, Anna] Carl von Ossietzky Univ Oldenburg, Med Phys, Kupkersweg 74, D-26129 Oldenburg, Germany.
   [Warzybok, Anna] Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, Kupkersweg 74, D-26129 Oldenburg, Germany.
RP Warzybok, A (corresponding author), Carl von Ossietzky Univ Oldenburg, Med Phys, Kupkersweg 74, D-26129 Oldenburg, Germany.; Warzybok, A (corresponding author), Carl von Ossietzky Univ Oldenburg, Cluster Excellence Hearing4all, Kupkersweg 74, D-26129 Oldenburg, Germany.
EM a.warzybok@uni-oldenburg.de
OI Pastusiak, Anna/0000-0003-0982-9678
FU Deutsche Forschungsgemcinschaft (DFG)German Research Foundation (DFG)
   [325439187]
FX This work was supported by the grant from Deutsche
   Forschungsgemcinschaft (DFG) project Multilingual model-based
   rehabilitative audiology (no. 325439187).
CR Algazi VR, 2001, IEEE WORKSH APPL SIG, DOI [DOI 10.1109/ASPAA.2001.969552, 10.1109/ASPAA.2001.969552]
   ASHA, SENS HEAR LOSS
   Beutelmann R, 2010, J ACOUST SOC AM, V127, P2479, DOI 10.1121/1.3295575
   BIAP, 1996, BIAP REC 02 1 AUD CL
   Billings CJ, 2018, HEARING RES, V369, P90, DOI 10.1016/j.heares.2018.03.024
   Brand T, 2002, J ACOUST SOC AM, V111, P2801, DOI 10.1121/1.1479152
   BRONKHORST AW, 1989, J ACOUST SOC AM, V86, P1374, DOI 10.1121/1.398697
   BRONKHORST AW, 1988, J ACOUST SOC AM, V83, P1508, DOI 10.1121/1.395906
   Bronkhorst AW, 2000, ACUSTICA, V86, P117
   DEMENKO G., 2011, SELECTED PROBLEMS SP, P33
   Durlach NI, 2003, J ACOUST SOC AM, V114, P368, DOI 10.1121/1.1577562
   FESTEN JM, 1983, J ACOUST SOC AM, V73, P652, DOI 10.1121/1.388957
   FESTEN JM, 1990, J ACOUST SOC AM, V88, P1725, DOI 10.1121/1.400247
   Freyman RL, 1999, J ACOUST SOC AM, V106, P3578, DOI 10.1121/1.428211
   Freyman RL, 2001, J ACOUST SOC AM, V109, P2112, DOI 10.1121/1.1354984
   Garadat SN, 2007, J ACOUST SOC AM, V121, P1047, DOI 10.1121/1.2409863
   HAGERMAN B, 1982, SCAND AUDIOL, V11, P79, DOI 10.3109/01050398209076203
   Hickok Gregory, 2015, Handb Clin Neurol, V129, P149, DOI 10.1016/B978-0-444-62630-1.00008-1
   Kollmeier B, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516655795
   Kollmeier B, 2015, INT J AUDIOL, V54, P3, DOI 10.3109/14992027.2015.1020971
   Larsby B, 1998, SCAND AUDIOL, V27, P3, DOI 10.1080/010503998419641
   Lesica NA, 2018, TRENDS NEUROSCI, V41, P174, DOI 10.1016/j.tins.2018.01.008
   Mandel MI, 2010, IEEE T AUDIO SPEECH, V18, P1872, DOI 10.1109/TASL.2010.2052252
   O'SHAUCHNESSY D., 2000, SPEECH COMMUNICATION
   Orduna-Bustamante F, 2018, SPEECH COMMUN, V105, P53, DOI 10.1016/j.specom.2018.10.009
   Ozimek E, 2013, SPEECH COMMUN, V55, P1021, DOI 10.1016/j.specom.2013.06.009
   Ozimek E, 2010, INT J AUDIOL, V49, P444, DOI 10.3109/14992021003681030
   Ozimek E, 2009, INT J AUDIOL, V48, P433, DOI 10.1080/14992020902725521
   PASTUSIAK A., 2018, THESIS
   PEISSIC J., 1992, THESIS
   Peissig J, 1997, J ACOUST SOC AM, V101, P1660, DOI 10.1121/1.418150
   PRUSZEWICZ A., 2010, CLIN AUDIOLOGY, P329
   SEK A., 2004, ARCH ACOUST, V29, P25
   SEKULA A., 2011, SELECTED PROBLEMS SP, P117
   Shinn-Cunningham BG, 2001, J ACOUST SOC AM, V110, P1118, DOI 10.1121/1.1386633
   Soli SD, 2008, INT J AUDIOL, V47, P356, DOI 10.1080/14992020801895136
   Summers V, 2013, J AM ACAD AUDIOL, V24, P274, DOI 10.3766/jaaa.24.4.4
   VETULANI J., 2012, BRAIN FASCINATIONS P
   Wagener KC, 2006, INT J AUDIOL, V45, P26, DOI 10.1080/14992020500243851
   Wagener KC, 2005, INT J AUDIOL, V44, P144, DOI 10.1080/14992020500057517
   Warzybok A, 2015, INT J AUDIOL, V54, P88, DOI 10.3109/14992027.2015.1063715
   World Health Organization, 2019, DEAFN HEAR LOSS
NR 42
TC 0
Z9 0
U1 0
U2 1
PU POLSKA AKAD NAUK, POLISH ACAD SCIENCES, INST FUNDAMENTAL TECH RES PAS
PI WARSZAWA
PA PL DEFILAD 1, WARSZAWA, 00-901, POLAND
SN 0137-5075
EI 2300-262X
J9 ARCH ACOUST
JI Arch. Acoust.
PY 2019
VL 44
IS 4
BP 709
EP 717
DI 10.24425/aoa.2019.129726
PG 9
WC Acoustics
SC Acoustics
GA JT4DN
UT WOS:000500941900008
DA 2021-02-24
ER

PT J
AU Jagadeesh, AB
   Kumar, UA
AF Jagadeesh, Anoop Basavanahalli
   Kumar, Ajith U.
TI Effect of informational masking on auditory working memory: role of
   linguistic information in the maskers
SO HEARING BALANCE AND COMMUNICATION
LA English
DT Article
DE Working memory; informational masking; backward digit span
ID SHORT-TERM-MEMORY; COCKTAIL PARTY PHENOMENON; SPEECH-INTELLIGIBILITY;
   IRRELEVANT SPEECH; UNATTENDED SPEECH; ENERGETIC MASKING; NOISE;
   RECOGNITION; ATTENTION; CAPACITY
AB Purpose: The current study aimed at observing how informational maskers with varying degrees of linguistic information affect working memory (WM) performance. The linguistic information in the maskers was varied by increasing the number of speakers in the babbles as well as by time-reversal of these babbles.Method: Backward digit (BD) span was measured on 24 normal-hearing native speakers of Kannada language. BD spans were measured under six background conditions - quiet, 2- and 8-speaker babbles (2SB and 8SB), time-reversed 2- and 8- speaker babbles (2RB and 8RB), and speech spectrum noise. The digits were presented at 75dB SPL and the SNR was maintained at +5dB to ensure complete audibility and intelligibility of the target digits. Using an adaptive procedure, BD span was calculated as the average of the last four reversals.Results: One-way repeated measures ANOVA showed that the 2SB caused the greatest deterioration in the BD spans. The 8SB and the two RBs resulted in significantly better scores than the 2SB, but were statistically no different from each other. The speech spectrum noise caused negligible deteriorations on the BD spans and was statistically similar to the quiet background condition.Conclusions: Results showed that the lexical-semantic information in the masker (2SB) causes the greatest deterioration in the WM scores, followed by acoustic-phonetic information (8SB and RBs). Energetic masking resulted in minimal deterioration on the BD spans. These results are further discussed based interpretations from different theories and models of working memory and speech perception.
C1 [Jagadeesh, Anoop Basavanahalli] All India Inst Speech & Hearing, Dept Audiol, Facil Adv Auditory Res, Mysuru 570006, India.
   [Kumar, Ajith U.] All India Inst Speech & Hearing, Dept Audiol, Mysuru, India.
RP Jagadeesh, AB (corresponding author), All India Inst Speech & Hearing, Dept Audiol, Facil Adv Auditory Res, Mysuru 570006, India.
EM anoop2187@gmail.com
OI Kumar, Ajith/0000-0002-1368-9834; B J, Anoop/0000-0001-6595-302X
FU AIISH Research Fellowship [D./Admissions/2016-17]
FX This work was supported by the AIISH Research Fellowship [No.
   SH/ACA/Ph.D./Admissions/2016-17] dated 16.08.2016.
CR Ahveninen J, 2017, NEUROIMAGE, V161, P1, DOI 10.1016/j.neuroimage.2017.08.040
   Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Arai T, 2010, ACOUST SCI TECHNOL, V31, P188, DOI 10.1250/ast.31.188
   Atkinson RC., 1968, PSYCHOL LEARN MOTIV, P89, DOI 10.1016/S0079-7421(08)60422-3
   Baddeley A, 2003, J COMMUN DISORD, V36, P189, DOI 10.1016/S0021-9924(03)00019-4
   Baddeley A, 2000, TRENDS COGN SCI, V4, P417, DOI 10.1016/S1364-6613(00)01538-2
   BADDELEY A, 1992, J COGNITIVE NEUROSCI, V4, P281, DOI 10.1162/jocn.1992.4.3.281
   Baddeley A, 1996, PHILOS T ROY SOC B, V351, P1397, DOI 10.1098/rstb.1996.0123
   Baddeley A, 2010, CURR BIOL, V20, pR136, DOI 10.1016/j.cub.2009.12.014
   Balakrishnan U, 2008, J ACOUST SOC AM, V123, P2680, DOI 10.1121/1.2902176
   Beaman CP, 1997, J EXP PSYCHOL LEARN, V23, P459, DOI 10.1037/0278-7393.23.2.459
   Boulenger V, 2010, SPEECH COMMUN, V52, P246, DOI 10.1016/j.specom.2009.11.002
   Bronkhorst AW, 2000, ACUSTICA, V86, P117
   Brungart DS, 2001, J ACOUST SOC AM, V110, P2527, DOI 10.1121/1.1408946
   Brungart DS, 2005, SPEECH SEPARATION BY HUMANS AND MACHINES, P261, DOI 10.1007/0-387-22794-6_17
   Brungart DS, 2002, J ACOUST SOC AM, V112, P664, DOI 10.1121/1.1490592
   Campbell T, 2002, MEMORY, V10, P199, DOI 10.1080/09658210143000335
   Conway ARA, 2001, PSYCHON B REV, V8, P331, DOI 10.3758/BF03196169
   Darwin CJ, 2003, J ACOUST SOC AM, V114, P2913, DOI 10.1121/1.1616924
   Ellermeier W, 2014, ACOUST SCI TECHNOL, V35, P10, DOI 10.1250/ast.35.10
   Freyman RL, 2004, J ACOUST SOC AM, V115, P2246, DOI 10.1121/1.1689343
   Freyman RL, 2001, J ACOUST SOC AM, V109, P2112, DOI 10.1121/1.1354984
   Fullgrabe C, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01268
   Gisselgard J, 2004, NEUROIMAGE, V22, P1107, DOI 10.1016/j.neuroimage.2004.02.031
   Gnanateja GN, 2016, SPEECH SPECTRUM SHAP
   Gordon-Salant S, 2016, EAR HEARING, V37, P593, DOI 10.1097/AUD.0000000000000316
   Heinrich A, 2008, Q J EXP PSYCHOL, V61, P735, DOI 10.1080/17470210701402372
   Hoen M, 2007, SPEECH COMMUN, V49, P905, DOI 10.1016/j.specom.2007.05.008
   Holmes E, 2017, HEARING RES, V350, P160, DOI 10.1016/j.heares.2017.05.005
   Howard CS, 2010, INT J AUDIOL, V49, P928, DOI 10.3109/14992027.2010.520036
   Institute ANS, 2008, S3 ANSI I ANS, P1
   Iyer N, 2010, J ACOUST SOC AM, V128, P2998, DOI 10.1121/1.3479547
   JONES DM, 1990, APPL COGNITIVE PSYCH, V4, P89, DOI 10.1002/acp.2350040203
   Kahneman D., 1973, ATTENTION EFFORT
   Marrone N, 2015, J SPEECH LANG HEAR R, V58, P1793, DOI 10.1044/2015_JSLHR-H-14-0223
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Miller RE, 2018, J ACOUST SOC AM, V143, P3058, DOI 10.1121/1.5038273
   Millman RE, 2017, J SPEECH LANG HEAR R, V60, P1236, DOI 10.1044/2017_JSLHR-S-16-0105
   Murphy DR, 2000, PSYCHOL AGING, V15, P323, DOI 10.1037/0882-7974.15.2.323
   Nagaraj NK, 2017, J SPEECH LANG HEAR R, V60, P2949, DOI 10.1044/2017_JSLHR-H-17-0022
   Neidleman MT, 2015, J AM ACAD AUDIOL, V26, P220, DOI 10.3766/jaaa.26.3.3
   Ng EHN, 2013, INT J AUDIOL, V52, P433, DOI 10.3109/14992027.2013.776181
   Nishiyama R, 2013, EXP PSYCHOL, V60, P131, DOI 10.1027/1618-3169/a000179
   Osman H, 2014, J SPEECH LANG HEAR R, V57, P1503, DOI 10.1044/2014_JSLHR-H-13-0286
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   RABBITT PMA, 1968, Q J EXP PSYCHOL, V20, P241, DOI 10.1080/14640746808400158
   Rhebergen KS, 2005, J ACOUST SOC AM, V118, P1274, DOI 10.1121/1.2000751
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Ronnberg J, 2008, INT J AUDIOL, V47, pS99, DOI 10.1080/14992020802301167
   Rosen S, 2013, J ACOUST SOC AM, V133, P2431, DOI 10.1121/1.4794379
   SALAME P, 1987, ERGONOMICS, V30, P1185, DOI 10.1080/00140138708966007
   SALAME P, 1982, J VERB LEARN VERB BE, V21, P150, DOI 10.1016/S0022-5371(82)90521-7
   Schneider BA, 2007, J AM ACAD AUDIOL, V18, P559, DOI 10.3766/jaaa.18.7.4
   Simpson SA, 2005, J ACOUST SOC AM, V118, P2775, DOI 10.1121/1.2062650
   Stiles DJ, 2012, J SPEECH LANG HEAR R, V55, P764, DOI 10.1044/1092-4388(2011/10-0264)
   The JASP Team, 2017, JASP VERS 0 8 5 1
   Tremblay S, 2000, J EXP PSYCHOL LEARN, V26, P1750, DOI 10.1037/0278-7393.26.6.1750
   Vachon F, 2017, J EXP PSYCHOL LEARN, V43, P622, DOI 10.1037/xlm0000330
   Van Engen KJ, 2007, J ACOUST SOC AM, V121, P519, DOI 10.1121/1.2400666
   Van Engen KJ, 2014, J SPEECH LANG HEAR R, V57, P1908, DOI 10.1044/JSLHR-H-13-0076
   WETHERILL GB, 1965, BRIT J MATH STAT PSY, V18, P1, DOI 10.1111/j.2044-8317.1965.tb00689.x
   Zekveld AA, 2011, EAR HEARING, V32, P498, DOI 10.1097/AUD.0b013e31820512bb
NR 62
TC 0
Z9 0
U1 0
U2 0
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2169-5717
EI 2169-5725
J9 HEARING BALANC COMMU
JI Hearing Balanc. Commun.
PY 2019
VL 17
IS 4
BP 270
EP 279
DI 10.1080/21695717.2019.1630980
PG 10
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA JP2BZ
UT WOS:000498076600005
DA 2021-02-24
ER

PT J
AU Liu, JQ
   Zeng, T
   Lu, XC
AF Liu Jiaqi
   Zeng Ting
   Lu Xiuchuan
TI Challenges in multi-language pronunciation teaching: A cross-linguistic
   study of Chinese students' perception of voiced and voiceless stops
SO CIRCULO DE LINGUISTICA APLICADA A LA COMUNICACION
LA English
DT Article
DE Multi-language education; voiced and voiceless stops; speech perception;
   VOT; Mandarin Chinese
ID SPEECH SOUNDS; ONSET TIME; LANGUAGE; ENGLISH; ACQUISITION; CONSONANTS;
   FRENCH
AB This article reports on a cross-linguistic study of 58 Chinese students' perception of voiced and voiceless stops in their third language (L3). The participants were Japanese, Russian, or Spanish major students in a Chinese university, who were beginner learners of these languages but who had all learned English as their second language (L2) for over 10 years. The purpose of this study was to investigate the L3 learners' perceptual differences in the stop categories, and analyze the effects of the learners' multi-language background on their perception of L3 stops. Results from the perception experiment showed that: 1) the value and range of voice onset time (VOT) play an essential role in Chinese students' perception of voiceless stops; and 2) the pre-voicing during closure is the key to Chinese students' perception of voiced stops. We attribute their difficulty in perceiving L3 voiceless stops to the similarity in the phonemic range of voiceless stops between the learners' L3 and their L1 and L2, as this leads to confusion in perception. On the other hand, the dissimilarity between L3 voiced stops and those of L1 and L2 is conducive to the students' perception of L3 voiced stops. Findings from this study provide empirical evidence for the effect of similarity and dissimilarity in speech sounds as proposed in earlier phonology acquisition theories, and they can also inform the pedagogy of multi-language education.
C1 [Liu Jiaqi; Zeng Ting; Lu Xiuchuan] Fudan Univ, Shanghai, Peoples R China.
   [Zeng Ting] Shanghai Polytech Univ, Shanghai, Peoples R China.
RP Zeng, T; Lu, XC (corresponding author), Fudan Univ, Shanghai, Peoples R China.; Zeng, T (corresponding author), Shanghai Polytech Univ, Shanghai, Peoples R China.
EM jiaqiliu@fudan.edu.cn; zengting@fudan.edu.cn; luxc@fudan.edu.cn
FU National Social Science Foundation of China [18BYY227]
FX This work was supported by the National Social Science Foundation of
   China [Grant Number 18BYY227].
CR Abramson A. S, 1970, ACT 10 C INT LING, V4, P123
   Abramson A. S., 1973, J PHONETICS, V1, P1
   ABRAMSON AS, 1977, PHONETICA, V34, P295, DOI 10.1159/000259888
   Bao Huaiqiao, 2014, INTRO EXPT PHONETICS
   Bigi B., 2017, SPPAS AUTOMATIC ANNO
   Boersma P., 2009, PRAAT DOING PHONETIC
   BOHN OS, 1993, J PHONETICS, V21, P267, DOI 10.1016/S0095-4470(19)31339-7
   CARAMAZZA A, 1973, J ACOUST SOC AM, V54, P421, DOI 10.1121/1.1913594
   Cenoz J, 2001, SERIES BILINGUAL ED, V31
   Chan AYW, 2014, LINGUISTICS, V52, P35, DOI 10.1515/ling-2013-0056
   Chan AYW, 2012, MOD LANG J, V96, P1, DOI 10.1111/j.1540-4781.2012.01291.x
   Chang Junyue, 2006, WORLD ENGLISH, V25, P513, DOI DOI 10.1111/J.1467-971X.2006.00484.X
   De Angelis G., 2007, 3 ADDITIONAL LANGUAG
   Docherty G., 1992, TIMING VOICING BRIT
   ECKMAN FR, 1977, LANG LEARN, V27, P315, DOI 10.1111/j.1467-1770.1977.tb00124.x
   Eckman Fred R., 1991, STUDIES 2ND LANGUAGE, V13, P23, DOI DOI 10.1017/S0272263100009700
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   FLEGE JE, 1991, J ACOUST SOC AM, V89, P395, DOI 10.1121/1.400473
   FLEGE JE, 1981, TESOL QUART, V15, P443, DOI 10.2307/3586485
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   FLEGE JE, 1987, J PHONETICS, V15, P203, DOI 10.1016/S0095-4470(19)30548-0
   Flege JE, 1992, PHONOLOGICAL DEV MOD, P565
   Fukuoka M., 1995, NIHONGO KYOUIKU, V87, P40
   Hammarberg B, 2005, INTRO READINGS L3, P11
   International Phonetic Association, 1999, HDB INT PHON ASS GUI
   KEATING P, 1983, J PHONETICS, V11, P277, DOI 10.1016/S0095-4470(19)30827-7
   Keith J., 2003, ACOUSTIC AUDITORY PH
   Kingston J, 2003, LANG SPEECH, V46, P295, DOI 10.1177/00238309030460020201
   KLATT DH, 1975, J SPEECH HEAR RES, V18, P686, DOI 10.1044/jshr.1804.686
   Kul M., 2010, NEW SOUNDS 2010, P566
   Kulikov V, 2012, THESIS
   LADEFOGED P, 2012, VOWELS CONSONANTS
   Ladefoged Peter, 1975, COURSE PHONETICS
   Lado R., 1957, LINGUISTICS CULTURES
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Liu Jiaqi, 2019, WASEDA NIHONGO KYOIK, V26, P127
   Liu Jiaqi, 2005, WASEDA DAIGAKU NIHON, V6, P79
   Liu Jiaqi, 2011, NIHONGO YUSEI MUSEI
   Llama R, 2010, INT J MULTILING, V7, P39, DOI 10.1080/14790710902972255
   Major RC, 1999, LANG LEARN, V49, P151, DOI 10.1111/0023-8333.49.s1.5
   OLLER JW, 1970, LANG LEARN, V20, P183, DOI 10.1111/j.1467-1770.1970.tb00475.x
   Onishi H, 2016, INT J MULTILING, V13, P459, DOI 10.1080/14790718.2016.1217604
   Pyun K-S., 2005, INTRO READINGS L3, P55
   R Core Team, 2014, R LANG ENV STAT COMP
   Ringbom H., 1987, ROLE MOTHER TONGUE F
   Ringbom H., 2009, HDB LANGUAGE TEACHIN, P106, DOI DOI 10.1002/9781444315783.CH7
   Shimizu K., 1993, J ASIAN AFR STUD, V45, P163
   Tremblay M. C., 2007, SAT WORKSH ICPHS FRE
   Williams S, 1998, APPL LINGUIST, V19, P295, DOI 10.1093/applin/19.3.295
   Wrembel M., 2014, CONCORDIA WORKING PA, V5, P750
   Wu Zongji, 1988, J CHINESE LINGUISTIC, V3, P256
NR 52
TC 2
Z9 2
U1 1
U2 3
PU UNIV COMPLUTENSE MADRID, SERVICIO PUBLICACIONES
PI MADRID
PA CIUDAD UNIV, OBISPO TREJO 3, MADRID, 28040, SPAIN
SN 1576-4737
J9 CIRC LINGUIST APL CO
JI Circ. Linguist. Apl. Comun.
PY 2019
IS 79
SI SI
BP 99
EP 118
DI 10.5209/CLAC.65652
PG 20
WC Linguistics; Language & Linguistics
SC Linguistics
GA JJ2LN
UT WOS:000493993700006
OA Bronze
DA 2021-02-24
ER

PT J
AU Basharat, A
   Mahoney, JR
   Barnett-Cowan, M
AF Basharat, Aysha
   Mahoney, Jeannette R.
   Barnett-Cowan, Michael
TI Temporal Metrics of Multisensory Processing Change in the Elderly
SO MULTISENSORY RESEARCH
LA English
DT Article
DE Multisensory integration; reaction time; simultaneity perception;
   temporal-order perception; temporal binding window; race model
ID AGE-RELATED-CHANGES; VISUAL-SOMATOSENSORY INTEGRATION; INDUCED FLASH
   ILLUSION; ORDER JUDGMENTS; RACE MODEL; STATISTICAL FACILITATION;
   AUDIOVISUAL ASYNCHRONY; SPEECH-PERCEPTION; TIME-WINDOW; SIMULTANEITY
AB Older adults exhibit greater multisensory response time (RT) facilitation by violating the race model more than young adults; this is commonly interpreted as an enhancement in perception. Older adults typically exhibit wider temporal binding windows (TBWs) and points of subjective simultaneity (PSS) that typically lie farther from true simultaneity as compared to young adults when simultaneity judgment (SJ) and temporal-order judgment (TOJ) tasks are utilized; this is commonly interpreted as an impairment in perception. Here we explore the relation between the three tasks in order to better assess audiovisual multisensory temporal processing in both young and older adults. Our results confirm previous reports showing that audiovisual RT, TBWs and PSSs change with age; however, we show for the first time a significant positive relation between the magnitude of race model violation in young adults as a function of the PSS obtained from the audiovisual TOJ task (r: 0.49, p: 0.007), that is absent in older adults (r: 0.13, p: 0.58). Furthermore, we find no evidence for the relation between race model violation as a function of the PSS obtained from the audiovisual SJ task in both young (r: -0.01, p: 0.94) and older adults (r: 0.1, p: 0.66). Our results confirm previous reports that (i) audiovisual temporal processing changes with age; (ii) distinct processes are likely involved in simultaneity and temporal-order perception; and (iii) common processing between race model violation and temporal-order judgment is impaired in the elderly.
C1 [Basharat, Aysha; Barnett-Cowan, Michael] Univ Waterloo, Dept Kinesiol, Waterloo, ON N2L 3G1, Canada.
   [Mahoney, Jeannette R.] Albert Einstein Coll Med, Dept Neurol, Div Cognit & Motor Aging, Bronx, NY 10467 USA.
RP Basharat, A (corresponding author), Univ Waterloo, Dept Kinesiol, Waterloo, ON N2L 3G1, Canada.
EM aysha.basharat@uwaterloo.ca
OI Mahoney, Jeannette/0000-0003-1079-787X
FU Natural Sciences and Engineering Research Council of Canada
   (NSERC)Natural Sciences and Engineering Research Council of Canada
   (NSERC) [RGPIN-05435-2014]
FX This work was generously supported by a Natural Sciences and Engineering
   Research Council of Canada (NSERC) Discovery Grant (#RGPIN-05435-2014)
   to MB-C.
CR Adhikari BM, 2013, BRAIN CONNECT, V3, P536, DOI 10.1089/brain.2013.0163
   ALLAN LG, 1975, PERCEPT PSYCHOPHYS, V18, P29, DOI 10.3758/BF03199363
   Alm M, 2013, J ACOUST SOC AM, V134, P3001, DOI 10.1121/1.4820798
   Babkoff H, 2017, EUR J AGEING, V14, P269, DOI 10.1007/s10433-017-0410-y
   Barnett-Cowan M, 2011, EXP BRAIN RES, V214, P27, DOI 10.1007/s00221-011-2802-0
   Barnett-Cowan M, 2009, EXP BRAIN RES, V198, P221, DOI 10.1007/s00221-009-1779-4
   Basharat A, 2018, FRONT INTEGR NEUROSC, V12, DOI 10.3389/fnint.2018.00015
   Bedard G, 2016, EXP BRAIN RES, V234, P331, DOI 10.1007/s00221-015-4466-7
   Busey T, 2010, VISION RES, V50, P1628, DOI 10.1016/j.visres.2010.05.003
   Calvert GA, 2001, NEUROIMAGE, V14, P427, DOI 10.1006/nimg.2001.0812
   Cardoso-Leite P, 2007, J VISION, V7, DOI 10.1167/7.6.11
   Chan JSS, 2018, MULTISENS RES, V31, P175, DOI 10.1163/22134808-00002605
   Chan JS, 2015, CURR ALZHEIMER RES, V12, P61, DOI 10.2174/1567205012666141218124744
   Chan YM, 2014, J VISION, V14, DOI 10.1167/14.11.13
   Chan YM, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00226
   Colonius H, 2006, PSYCHOL REV, V113, P148, DOI 10.1037/0033-295X.113.1.148
   Couth S, 2018, MULTISENS RES, V31, P151, DOI 10.1163/22134808-00002588
   Davis SW, 2008, CEREB CORTEX, V18, P1201, DOI 10.1093/cercor/bhm155
   Dhamala M, 2007, NEUROIMAGE, V34, P764, DOI 10.1016/j.neuroimage.2006.07.044
   Diaconescu AO, 2013, NEUROIMAGE, V65, P152, DOI 10.1016/j.neuroimage.2012.09.057
   Diederich A, 2008, NEUROPSYCHOLOGIA, V46, P2556, DOI 10.1016/j.neuropsychologia.2008.03.026
   Diederich A, 2015, PSYCHOL REV, V122, P232, DOI 10.1037/a0038696
   Fabiani M, 2012, PSYCHOPHYSIOLOGY, V49, P283, DOI 10.1111/j.1469-8986.2011.01331.x
   Falkenstein M, 2006, INT J PSYCHOPHYSIOL, V59, P22, DOI 10.1016/j.ijpsycho.2005.08.004
   Freiherr J, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00863
   Gao F, 2013, NEUROIMAGE, V78, P75, DOI 10.1016/j.neuroimage.2013.04.012
   Ghazanfar AA, 2006, TRENDS COGN SCI, V10, P278, DOI 10.1016/j.tics.2006.04.008
   Giard MH, 1999, J COGNITIVE NEUROSCI, V11, P473, DOI 10.1162/089892999563544
   Gondan M, 2016, ATTEN PERCEPT PSYCHO, V78, P723, DOI 10.3758/s13414-015-1018-y
   Gondan M, 2010, BEHAV RES METHODS, V42, P23, DOI 10.3758/BRM.42.1.23
   Gordon-Salant S, 1999, J SPEECH LANG HEAR R, V42, P300, DOI 10.1044/jslhr.4202.300
   GRADY CL, 1994, J NEUROSCI, V14, P1450
   Hairston WD, 2003, EXP BRAIN RES, V152, P404, DOI 10.1007/s00221-003-1646-7
   Hay-McCutcheon MJ, 2009, INT J AUDIOL, V48, P321, DOI 10.1080/14992020802644871
   Hillock AR, 2011, NEUROPSYCHOLOGIA, V49, P461, DOI 10.1016/j.neuropsychologia.2010.11.041
   Hillock-Dunn A, 2012, DEVELOPMENTAL SCI, V15, P688, DOI 10.1111/j.1467-7687.2012.01171.x
   HIRSH IJ, 1961, J EXP PSYCHOL, V62, P423, DOI 10.1037/h0045283
   Innes BR, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-39924-6
   KING AJ, 1985, EXP BRAIN RES, V60, P492
   Lacherez P, 2014, OPHTHAL PHYSL OPT, V34, P445, DOI 10.1111/opo.12140
   Laurienti PJ, 2006, NEUROBIOL AGING, V27, P1155, DOI 10.1016/j.neurobiolaging.2005.05.024
   Lewkowicz DJ, 1996, J EXP PSYCHOL HUMAN, V22, P1094, DOI 10.1037/0096-1523.22.5.1094
   Linares D, 2014, I-PERCEPTION, V5, P559, DOI 10.1068/i0675
   Liu XZ, 2007, J PATHOL, V211, P188, DOI 10.1002/path.2102
   Love SA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0054798
   Lupo J, 2018, GAIT POSTURE, V59, P40, DOI 10.1016/j.gaitpost.2017.09.037
   Maguinness C, 2011, FRONT AGING NEUROSCI, V3, DOI 10.3389/fnagi.2011.00019
   Mahoney JR, 2019, JOVE-J VIS EXP, DOI 10.3791/59575
   Mahoney JR, 2018, FRONT AGING NEUROSCI, V10, DOI 10.3389/fnagi.2018.00377
   Mahoney JR, 2019, J GERONTOL A-BIOL, V74, P1429, DOI 10.1093/gerona/gly245
   Mahoney JR, 2015, MULTISENS RES, V28, P11, DOI 10.1163/22134808-00002470
   Mahoney JR, 2014, MULTISENS RES, V27, P17, DOI 10.1163/22134808-00002444
   Mahoney JR, 2012, BRAIN RES, V1472, P63, DOI 10.1016/j.brainres.2012.07.014
   Mahoney JR, 2011, BRAIN RES, V1426, P43, DOI 10.1016/j.brainres.2011.09.017
   Megevand P, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071608
   MEREDITH MA, 1987, J NEUROSCI, V7, P3215
   Meredith MA, 1996, J NEUROPHYSIOL, V75, P1843
   MEREDITH MA, 1983, SCIENCE, V221, P389, DOI 10.1126/science.6867718
   MEREDITH MA, 1986, J NEUROPHYSIOL, V56, P640
   MILLER J, 1982, COGNITIVE PSYCHOL, V14, P247, DOI 10.1016/0010-0285(82)90010-X
   Miller J., 2006, J EXPT PSYCHOL HUMAN, V32, P349
   Miller J, 2016, ATTEN PERCEPT PSYCHO, V78, P516, DOI 10.3758/s13414-015-1017-z
   MITRANI L, 1986, BIOL CYBERN, V54, P159, DOI 10.1007/BF00356854
   Miyazaki M, 2006, NAT NEUROSCI, V9, P875, DOI 10.1038/nn1712
   Molholm S, 2002, COGNITIVE BRAIN RES, V14, P115, DOI 10.1016/S0926-6410(02)00066-6
   Mozolic J. L., 2012, NEURAL BASEMULTISE, P81, DOI [10.1201/9781439812174-25, DOI 10.1201/9781439812174-25]
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Otto T. U., QUANT METHOD PSYCHOL
   Otto TU, 2017, MULTISENS RES, V30, P1, DOI 10.1163/22134808-00002541
   Otto TU, 2012, CURR BIOL, V22, P1391, DOI 10.1016/j.cub.2012.05.031
   Peiffer AM, 2007, NEUROREPORT, V18, P1077, DOI 10.1097/WNR.0b013e3281e72ae7
   Poliakoff E, 2006, NEUROSCI LETT, V396, P207, DOI 10.1016/j.neulet.2005.11.034
   Porges EC, 2017, BIOL PSYCHIAT-COGN N, V2, P38, DOI 10.1016/j.bpsc.2016.06.004
   Powers AR, 2009, J NEUROSCI, V29, P12265, DOI 10.1523/JNEUROSCI.3501-09.2009
   RAAB DH, 1962, T NEW YORK ACAD SCI, V24, P574, DOI 10.1111/j.2164-0947.1962.tb01433.x
   Ramkhalawansingh R, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00595
   Rawson Nancy E, 2006, Sci Aging Knowledge Environ, V2006, ppe6, DOI 10.1126/sageke.2006.5.pe6
   Roudaia E, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00267
   Schroeder CE, 2005, CURR OPIN NEUROBIOL, V15, P454, DOI 10.1016/j.conb.2005.06.008
   Sekuler R, 1997, NATURE, V385, P308, DOI 10.1038/385308a0
   Setti A, 2014, NEUROPSYCHOLOGIA, V61, P259, DOI 10.1016/j.neuropsychologia.2014.06.027
   Setti A, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00575
   Setti A, 2011, NEUROREPORT, V22, P554, DOI 10.1097/WNR.0b013e328348c731
   Setti A, 2011, EXP BRAIN RES, V209, P375, DOI 10.1007/s00221-011-2560-z
   Shams L, 2005, NEUROREPORT, V16, P1923, DOI 10.1097/01.wnr.0000187634.68504.bb
   Shams L, 2000, NATURE, V408, P788, DOI 10.1038/35048669
   Shams L, 2002, COGNITIVE BRAIN RES, V14, P147, DOI 10.1016/S0926-6410(02)00069-1
   SPEAR PD, 1993, VISION RES, V33, P2589, DOI 10.1016/0042-6989(93)90218-L
   Stein BE, 2008, NAT REV NEUROSCI, V9, P255, DOI 10.1038/nrn2331
   Sternberg S., 1973, ATTENTION PERFORM, VIV, P629
   TAKAYAMA H, 1992, EUR J CLIN CHEM CLIN, V30, P271
   van Eijk RLJ, 2008, PERCEPT PSYCHOPHYS, V70, P955, DOI 10.3758/PP.70.6.955
   Vatakis A, 2008, EXP BRAIN RES, V185, P521, DOI 10.1007/s00221-007-1168-9
   Virsu V, 2003, NEUROSCI LETT, V336, P151, DOI 10.1016/s0304-3940(02)01253-3
   Waszak F, 2004, VIS COGN, V11, P947, DOI 10.1080/13506280444000003
   Wise A, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00139
   Wood JM, 2002, HUM FACTORS, V44, P482, DOI 10.1518/0018720024497664
   Wu JL, 2012, NEUROREPORT, V23, P616, DOI [10.1097/00001756-201207110-00008, 10.1097/WNR.0b013e3283552b0f]
   Zampini M, 2003, INT J PSYCHOPHYSIOL, V50, P165, DOI 10.1016/S0167-8760(03)00132-6
NR 99
TC 2
Z9 2
U1 2
U2 5
PU BRILL ACADEMIC PUBLISHERS
PI LEIDEN
PA PLANTIJNSTRAAT 2, P O BOX 9000, 2300 PA LEIDEN, NETHERLANDS
SN 2213-4794
EI 2213-4808
J9 MULTISENS RES
JI Multisens. Res.
PD JAN
PY 2019
VL 32
IS 8
SI SI
BP 715
EP 744
DI 10.1163/22134808-20191458
PG 30
WC Biophysics; Psychology; Psychology, Experimental
SC Biophysics; Psychology
GA JH7ZE
UT WOS:000492987100004
PM 31648192
DA 2021-02-24
ER

PT J
AU Stawicki, M
   Majdak, P
   Baskent, D
AF Stawicki, Marnix
   Majdak, Piotr
   Baskent, Deniz
TI Ventriloquist Illusion Produced With Virtual Acoustic Spatial Cues and
   Asynchronous Audiovisual Stimuli in Both Young and Older Individuals
SO MULTISENSORY RESEARCH
LA English
DT Article
DE Audiovisual integration; minimum audible angle; head-related transfer
   function; ventriloquist illusion; aging
ID ENHANCED MULTISENSORY INTEGRATION; VISUAL SPEECH-PERCEPTION;
   SOUND-LOCALIZATION; DEGRADED SPEECH; NORMAL-HEARING; FREE-FIELD; AGE;
   ADULTS; DIRECTION; INTELLIGIBILITY
AB Ventriloquist illusion, the change in perceived location of an auditory stimulus when a synchronously presented but spatially discordant visual stimulus is added, has been previously shown in young healthy populations to be a robust paradigm that mainly relies on automatic processes. Here, we propose ventriloquist illusion as a potential simple test to assess audiovisual (AV) integration in young and older individuals. We used a modified version of the illusion paradigm that was adaptive, nearly bias-free, relied on binaural stimulus representation using generic head-related transfer functions (HRTFs) instead of multiple loudspeakers, and tested with synchronous and asynchronous presentation of AV stimuli (both tone and speech). The minimum audible angle (MAA), the smallest perceptible difference in angle between two sound sources, was compared with or without the visual stimuli in young and older adults with no or minimal sensory deficits. The illusion effect, measured by means of MAAs implemented with HRTFs, was observed with both synchronous and asynchronous visual stimulus, but only with tone and not speech stimulus. The patterns were similar between young and older individuals, indicating the versatility of the modified ventriloquist illusion paradigm.
C1 [Stawicki, Marnix; Baskent, Deniz] Univ Groningen, Univ Med Ctr Groningen, Dept Otorhinolaryngol Head & Neck Surg, Groningen, Netherlands.
   [Stawicki, Marnix; Baskent, Deniz] Univ Groningen, Grad Sch Med Sci, Res Sch Behav & Cognit Neurosci BCN, Groningen, Netherlands.
   [Majdak, Piotr] Austrian Acad Sci, Acoust Res Inst, Vienna, Austria.
RP Baskent, D (corresponding author), Univ Groningen, Univ Med Ctr Groningen, Dept Otorhinolaryngol Head & Neck Surg, Groningen, Netherlands.; Baskent, D (corresponding author), Univ Groningen, Grad Sch Med Sci, Res Sch Behav & Cognit Neurosci BCN, Groningen, Netherlands.
EM d.baskent@umcg.nl
FU Heinsius Houbolt Foundation; Rosalind Franklin Fellowship from the
   University of Groningen; Netherlands Organization for Scientific
   Research (NWO)Netherlands Organization for Scientific Research (NWO)
   [016.096.397]; Netherlands Organization for Health Research and
   Development (ZonMw)Netherlands Organization for Health Research and
   Development
FX We would like to thank Frits Leemhuis for technical support, Floor
   Burgerhof, Marije Sleurink, and Esmee van der Veen for help with the
   study, and Terrin Tamati for feedback on earlier versions of the
   manuscript. This study was supported by the Heinsius Houbolt Foundation,
   the Rosalind Franklin Fellowship from the University of Groningen, a
   VIDI Grant (016.096.397) from the Netherlands Organization for
   Scientific Research (NWO) and the Netherlands Organization for Health
   Research and Development (ZonMw), and is part of the research program of
   our department: Healthy Aging and Communication.
CR Abel SM, 2000, J ACOUST SOC AM, V108, P743, DOI 10.1121/1.429607
   Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029
   Alm M, 2013, J ACOUST SOC AM, V134, P3001, DOI 10.1121/1.4820798
   Alsius A, 2018, MULTISENS RES, V31, P111, DOI 10.1163/22134808-00002565
   Altieri N, 2014, INT J AUDIOL, V53, P710, DOI 10.3109/14992027.2014.909053
   Basharat A, 2018, FRONT INTEGR NEUROSC, V12, DOI 10.3389/fnint.2018.00015
   Baskent D, 2016, TRENDS HEAR, V20, DOI 10.1177/2331216516670279
   Baskent D, 2011, EAR HEARING, V32, P582, DOI 10.1097/AUD.0b013e31820fca23
   Beauchamp MS, 2005, CURR OPIN NEUROBIOL, V15, P145, DOI 10.1016/j.conb.2005.03.011
   BERGMAN M, 1976, J GERONTOL, V31, P533, DOI 10.1093/geronj/31.5.533
   BERMANT RI, 1976, PERCEPT MOTOR SKILL, V43, P487, DOI 10.2466/pms.1976.43.2.487
   Bertelson P, 2000, PERCEPT PSYCHOPHYS, V62, P321, DOI 10.3758/BF03205552
   Bertelson P, 1998, PSYCHON B REV, V5, P482, DOI 10.3758/BF03208826
   Bosman AJ, 1995, AUDIOLOGY, V34, P260
   Chen LH, 2013, ATTEN PERCEPT PSYCHO, V75, P790, DOI [10.3758/s13414-013-0475-4, 10.3758/s13414-012-0395-8]
   Cienkowski KM, 2002, EAR HEARING, V23, P439, DOI 10.1097/00003446-200210000-00006
   Colonius H, 2001, PERCEPT PSYCHOPHYS, V63, P126, DOI 10.3758/BF03200508
   Couth S, 2018, MULTISENS RES, V31, P151, DOI 10.1163/22134808-00002588
   de Boer-Schellekens L, 2014, EXP BRAIN RES, V232, P253, DOI 10.1007/s00221-013-3736-5
   de Dieuleveult AL, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00524
   de Dieuleveult AL, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00080
   De Gelder B, 2003, TRENDS COGN SCI, V7, P460, DOI 10.1016/j.tics.2003.08.014
   Diederich A, 2008, NEUROPSYCHOLOGIA, V46, P2556, DOI 10.1016/j.neuropsychologia.2008.03.026
   Driver J, 1996, NATURE, V381, P66, DOI 10.1038/381066a0
   ERBER NP, 1975, J SPEECH HEAR DISORD, V40, P481, DOI 10.1044/jshd.4004.481
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   Files BT, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00878
   Fogerty D, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00090
   Freiherr J, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00863
   Frozard J, 1990, HDB PSYCHOL AGING, P150, DOI DOI 10.1016/B978-0-12-101280-9.50015-2
   GARDNER WG, 1995, J ACOUST SOC AM, V97, P3907, DOI 10.1121/1.412407
   Grant KW, 1998, J ACOUST SOC AM, V104, P2438, DOI 10.1121/1.423751
   Hay-McCutcheon MJ, 2009, INT J AUDIOL, V48, P321, DOI 10.1080/14992020802644871
   Helfer K S, 1998, J Am Acad Audiol, V9, P234
   Hoffman HJ, 2012, EAR HEARING, V33, P437, DOI 10.1097/AUD.0b013e3182362790
   Holmes NP, 2009, BRAIN TOPOGR, V21, P168, DOI 10.1007/s10548-009-0097-2
   Katz Jack, 2014, HDB CLIN AUDIOLOGY
   Lalonde K, 2016, J ACOUST SOC AM, V139, P1713, DOI 10.1121/1.4945590
   Langendijk EHA, 2002, J ACOUST SOC AM, V112, P1583, DOI 10.1121/1.1501901
   Laurienti PJ, 2006, NEUROBIOL AGING, V27, P1155, DOI 10.1016/j.neurobiolaging.2005.05.024
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Lovelace CT, 2003, COGNITIVE BRAIN RES, V17, P447, DOI 10.1016/S0926-6410(03)00160-5
   Macpherson EA, 2002, J ACOUST SOC AM, V111, P2219, DOI 10.1121/1.1471898
   Mahoney JR, 2014, MULTISENS RES, V27, P17, DOI 10.1163/22134808-00002444
   Majdak P, 2013, P 134 CONV AUD ENG S
   Massaro DW, 1996, J ACOUST SOC AM, V100, P1777, DOI 10.1121/1.417342
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MIDDLEBROOKS JC, 1991, ANNU REV PSYCHOL, V42, P135, DOI 10.1146/annurev.ps.42.020191.001031
   Musacchia G, 2009, EAR HEARING, V30, P505, DOI 10.1097/AUD.0b013e3181a7f5b7
   Oppenheim A., 1999, DISCRETE TIME SIGNAL
   Otte RJ, 2013, JARO-J ASSOC RES OTO, V14, P261, DOI 10.1007/s10162-012-0367-7
   Peiffer AM, 2007, NEUROREPORT, V18, P1077, DOI 10.1097/WNR.0b013e3281e72ae7
   PERROTT DR, 1990, J ACOUST SOC AM, V87, P1728, DOI 10.1121/1.399421
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   PICK HL, 1969, PERCEPT PSYCHOPHYS, V6, P203, DOI 10.3758/BF03207017
   Rosenblum LD, 1996, J EXP PSYCHOL HUMAN, V22, P318, DOI 10.1037/0096-1523.22.2.318
   Saija JD, 2019, PSYCHOL RES-PSYCH FO, V83, P951, DOI 10.1007/s00426-017-0912-4
   Saija JD, 2014, JARO-J ASSOC RES OTO, V15, P139, DOI 10.1007/s10162-013-0422-z
   Salthouse TA, 1996, PSYCHOL REV, V103, P403, DOI 10.1037/0033-295X.103.3.403
   Setti A, 2011, EXP BRAIN RES, V209, P375, DOI 10.1007/s00221-011-2560-z
   SHAW EAG, 1974, J ACOUST SOC AM, V56, P1848, DOI 10.1121/1.1903522
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   Sondergaard P. L., 2013, TECHNOLOGY BINAURAL, P397, DOI [10.1007/978-3-642-37762-4, DOI 10.1007/978-3-642-37762-4]
   Stein B. E., 1993, MERGING SENSES
   Stevenson RA, 2015, NEUROBIOL AGING, V36, P283, DOI 10.1016/j.neurobiolaging.2014.08.003
   Stevenson RA, 2013, EXP BRAIN RES, V227, P249, DOI 10.1007/s00221-013-3507-3
   Strouse A, 1998, J ACOUST SOC AM, V104, P2385, DOI 10.1121/1.423748
   Tremblay C, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000742
   Tuomainen J, 2005, COGNITION, V96, pB13, DOI 10.1016/j.cognition.2004.10.004
   Tye-Murray N, 2007, EAR HEARING, V28, P656, DOI 10.1097/AUD.0b013e31812f7185
   Tye-Murray N, 2010, EAR HEARING, V31, P636, DOI 10.1097/AUD.0b013e3181ddf7ff
   Tye-Murray N, 2008, INT J AUDIOL, V47, pS31, DOI 10.1080/14992020802301662
   Van Opstal AJ, 2016, AUDITORY SYSTEM HUMA
   Vatakis A, 2006, BRAIN RES, V1111, P134, DOI 10.1016/j.brainres.2006.05.078
   Vroomen J, 2001, PERCEPT PSYCHOPHYS, V63, P651, DOI 10.3758/BF03194427
   Vroomen J., 2004, HDB MULTISENSORY PRO, P141
   Vroomen J., 1998, P INT C AUD VIS SPEE, P131
   WENZEL EM, 1993, J ACOUST SOC AM, V94, P111, DOI 10.1121/1.407089
   WIGHTMAN FL, 1989, J ACOUST SOC AM, V85, P868, DOI 10.1121/1.397558
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
   Ziegelwanger H, 2014, J ACOUST SOC AM, V135, P1278, DOI 10.1121/1.4863196
NR 82
TC 2
Z9 2
U1 0
U2 3
PU BRILL ACADEMIC PUBLISHERS
PI LEIDEN
PA PLANTIJNSTRAAT 2, P O BOX 9000, 2300 PA LEIDEN, NETHERLANDS
SN 2213-4794
EI 2213-4808
J9 MULTISENS RES
JI Multisens. Res.
PD JAN
PY 2019
VL 32
IS 8
SI SI
BP 745
EP 770
DI 10.1163/22134808-20191430
PG 26
WC Biophysics; Psychology; Psychology, Experimental
SC Biophysics; Psychology
GA JH7ZE
UT WOS:000492987100005
PM 31648191
OA Other Gold
DA 2021-02-24
ER

PT J
AU Kliuev, EA
   Sheyko, GE
   Dunayev, MG
   Abramov, SA
   Dvoryaninova, VV
   Balandina, OV
   Karyakin, NN
   Belova, AN
AF Kliuev, E. A.
   Sheyko, G. E.
   Dunayev, M. G.
   Abramov, S. A.
   Dvoryaninova, V. V.
   Balandina, O. V.
   Karyakin, N. N.
   Belova, A. N.
TI The Role of Functional MRI in Understanding the Origin of Speech Delay
   in Autism Spectrum Disorders
SO SOVREMENNYE TEHNOLOGII V MEDICINE
LA English
DT Article
DE autism; autism spectrum disorders; ASD; magnetic resonance imaging;
   functional MRI; speech development
ID MAGNETIC-RESONANCE; NEURAL BASIS; ACTIVATION; COMPREHENSION; CHILDREN;
   FMRI; NETWORK
AB Autism spectrum disorders (ASD) are disorders of psychic development characterized by the difficulties of social interaction and stereotyped and repetitive patterns of behavior. Rather often they are accompanied by disturbances of speech, intelligence, and adaptive behavior. Pathogenesis of ASD is still poorly studied. MRI with its latest modalities is a modern diagnostic method enabling medical providers to evaluate structural, metabolic, and functional features of brain development in this pathology.
   The aim of the study was to assess the capabilities of functional MRI (fMRI) in determining pathophysiological mechanisms of delay in speech development in ASD.
   Materials and Methods. A brief review of international studies is given in the article. Our own results of examining 6 preschool children with one of the ASD forms - early childhood autism and speech disorders, and 6 children of the comparison group without autism and language disturbances are also presented using fMRI and a block design paradigm to analyze speech perception patterns.
   Results. In all children with normal speech development, bilateral symmetric spread of activation along the cortex of the entire superior temporal gyri was revealed whereas children with autism showed lateralized and limited involvement of the auditory cortex. Sevoflurane anesthesia did not influence the character of auditory zone activation.
   Conclusion. The possibility of using fMRI with application of the paradigm for speech understanding to study the individual features of brain functioning in children with autism has been demonstrated. The revealed objective instrumental signs of brain activity differences in the children with autism compared to the healthy children allow the fMRI data to be considered as a potential biomarker of this disease. It has also been shown that the possibility to carry out this examination under general anesthesia makes it more acceptable and convenient for patients with childhood autism.
C1 [Kliuev, E. A.] Privolzhsky Res Med Univ, Dept Radiol Diagnost, 10-1 Minin & Pozharsky Sq, Nizhnii Novgorod 603005, Russia.
   [Sheyko, G. E.; Belova, A. N.] Privolzhsky Res Med Univ, Dept Med Rehabil, 10-1 Minin & Pozharsky Sq, Nizhnii Novgorod 603005, Russia.
   [Dunayev, M. G.; Dvoryaninova, V. V.; Belova, A. N.] Privolzhsky Res Med Univ, Univ Clin, Dept Funct Diagnost, 10-1 Minin & Pozharsky Sq, Nizhnii Novgorod 603005, Russia.
   [Abramov, S. A.] Privolzhsky Res Med Univ, Univ Clin, Inst Pediat, Dept Anesthesiol & Resuscitat, 10-1 Minin & Pozharsky Sq, Nizhnii Novgorod 603005, Russia.
   [Dvoryaninova, V. V.] Privolzhsky Res Med Univ, Dept Psychiat & Med Psychol, 10-1 Minin & Pozharsky Sq, Nizhnii Novgorod 603005, Russia.
   [Balandina, O. V.] Privolzhsky Res Med Univ, Univ Ctr Psychol & Children Dev, 10-1 Minin & Pozharsky Sq, Nizhnii Novgorod 603005, Russia.
   [Karyakin, N. N.] Privolzhsky Res Med Univ, 10-1 Minin & Pozharsky Sq, Nizhnii Novgorod 603005, Russia.
RP Kliuev, EA (corresponding author), Privolzhsky Res Med Univ, Dept Radiol Diagnost, 10-1 Minin & Pozharsky Sq, Nizhnii Novgorod 603005, Russia.
EM eugenekluev@yandex.ru
RI Kluev, Evgenii A/G-8392-2019; Balandina, Oxana/AAF-4655-2021
OI Kluev, Evgenii A/0000-0003-2069-1710; Sheiko,
   Gennadii/0000-0003-0402-7430
CR American Psychiatric Ass ociation, 2013, DIAGN STAT MAN MENT, P271, DOI DOI 10.1176/APPI.BOOKS.9780890425596
   Andrews DS, 2018, CURR TOP BEHAV NEURO, V40, P413, DOI 10.1007/7854_2018_47
   Berg AT, 2015, LANCET NEUROL, V14, P1069, DOI 10.1016/S1474-4422(15)00048-4
   Bernhardt BC, 2017, CURR TOP BEHAV NEURO, V30, P341, DOI 10.1007/7854_2016_438
   Carlisi CO, 2017, CEREB CORTEX, V27, P5804, DOI 10.1093/cercor/bhx265
   Chouinard B, 2017, NEUROSCIENCE, V361, P19, DOI 10.1016/j.neuroscience.2017.08.001
   Di Martino A, 2009, BIOL PSYCHIAT, V65, P63, DOI 10.1016/j.biopsych.2008.09.022
   Dichter Gabriel S, 2012, Dialogues Clin Neurosci, V14, P319
   Ecker C, 2013, MOL PSYCHIATR, V18, P435, DOI 10.1038/mp.2012.102
   Failla MD, 2018, AUTISM, V22, P669, DOI 10.1177/1362361317696043
   Gemma M, 2016, PEDIATR ANESTH, V26, P521, DOI 10.1111/pan.12884
   Geschwind DH, 2007, CURR OPIN NEUROBIOL, V17, P103, DOI 10.1016/j.conb.2007.01.009
   Gu XS, 2018, EUR J NEUROSCI, V47, P592, DOI 10.1111/ejn.13598
   Ha S, 2015, EXP NEUROBIOL, V24, P273, DOI 10.5607/en.2015.24.4.273
   Haigh SM, 2015, J AUTISM DEV DISORD, V45, P1176, DOI 10.1007/s10803-014-2276-6
   Heeger DJ, 2002, NAT REV NEUROSCI, V3, P142, DOI 10.1038/nrn730
   Ismail MMT, 2016, FRONT HUM NEUROSCI, V10, DOI [10.3389/fnhum.7016.00211, 10.3389/fnhum.2016.00211]
   Kana RK, 2006, BRAIN, V129, P2484, DOI 10.1093/brain/awl164
   Kim SY, 2015, PSYCHIAT INVEST, V12, P37, DOI 10.4306/pi.2015.12.1.37
   Knaus TA, 2017, BRAIN COGNITION, V117, P57, DOI 10.1016/j.bandc.2017.06.004
   Lee Y, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00418
   Lenroot RK, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00733
   Logothetis NK, 2002, PHILOS T R SOC B, V357, P1003, DOI 10.1098/rstb.2002.1114
   Logothetis NK, 2004, ANNU REV PHYSIOL, V66, P735, DOI 10.1146/annurev.physiol.66.082602.092845
   Lombardo MV, 2015, NEURON, V86, P567, DOI 10.1016/j.neuron.2015.03.023
   Markou P, 2017, NEUROPSYCHOL REV, V27, P258, DOI 10.1007/s11065-017-9354-4
   Murphy CM, 2017, HUM BRAIN MAPP, V38, P5343, DOI 10.1002/hbm.23718
   Paquet A, 2017, DEV NEUROPSYCHOL, V42, P39, DOI 10.1080/87565641.2016.1274317
   Philip RCM, 2012, NEUROSCI BIOBEHAV R, V36, P901, DOI 10.1016/j.neubiorev.2011.10.008
   Pierce K, 2011, BRAIN RES, V1380, P162, DOI 10.1016/j.brainres.2010.09.028
   Raschle NM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0115549
   Redcay E, 2008, BIOL PSYCHIAT, V64, P589, DOI 10.1016/j.biopsych.2008.05.020
   Redcay E, 2008, NEUROSCI BIOBEHAV R, V32, P123, DOI 10.1016/j.neubiorev.2007.06.004
   [Селиверстов Юрий Александрович Seliverstov Yu.A.], 2015, [Неврологический журнал, Nevrologicheskii zhurnal], V20, P11
   SELIVERSTOVA EV, 2013, ANN KLIN EKSPERIMENT, V7, P39
   Simashkova N. V., 2015, RASSTROYSTVA AUTISTI
   Stanfield AC, 2017, SCHIZOPHRENIA BULL, V43, P1220, DOI 10.1093/schbul/sbx083
   Tang CY, 2016, INT ANESTHESIOL CLIN, V54, P129, DOI 10.1097/AIA.0000000000000081
   Venkatraghavan L, 2017, BRAIN CONNECT, V7, P250, DOI 10.1089/brain.2016.0448
   Wang AT, 2006, BRAIN, V129, P932, DOI 10.1093/brain/awl032
   Yang J, 2018, AUTISM, V22, P134, DOI 10.1177/1362361316667056
NR 41
TC 0
Z9 0
U1 0
U2 2
PU NIZHNIY NOVGOROD STATE MEDICAL ACAD
PI NIZHNIY NOVGOROD
PA MININ & POZHARSKY SQUARE, 10-1, NIZHNIY NOVGOROD, 603005, RUSSIA
SN 2076-4243
J9 SOVREM TEHNOL MED
JI Sovrem. Tehnol. Med.
PY 2019
VL 11
IS 3
BP 66
EP 73
DI 10.17691/stm2019.11.3.09
PG 8
WC Medicine, Research & Experimental
SC Research & Experimental Medicine
GA JB1EO
UT WOS:000488303800009
OA Bronze
DA 2021-02-24
ER

PT J
AU Pilus, Z
   Zakaria, NS
   Zakaria, MK
   Wahid, R
AF Pilus, Zahariah
   Zakaria, Nur Shahida
   Zakaria, Muhamad Khairul
   Wahid, Ridwan
TI Stretching the boundaries Malaysian ESL learners' evaluative reactions
   to inner circle English accents
SO JOURNAL OF ASIAN PACIFIC COMMUNICATION
LA English
DT Article
DE native English accents; ESL learners; spoken English; speech perception;
   international and intercultural communication
ID NONNATIVE TEACHERS; ATTITUDES; STUDENTS; COMPREHENSIBILITY; LANGUAGE;
   INTELLIGIBILITY; EXPERIENCES; PERCEPTION; BRITISH; SPEECH
AB Nowadays, international communication using English as the medium is a common occurrence. To communicate effectively, English as a second language (ESL) speakers need to possess relevant communicative skills including understanding and being familiar with inner circle accents. This paper seeks to find out ESL learners' evaluative reactions to four inner circle accents, representing British, American, Australian and New Zealand English varieties, through an accent perception and a survey task conducted on Malaysian undergraduates at a public university in Malaysia. The participants responded to descriptors on speaker attributes categorized into three dimensions: competence, social appeal and accent preference while or after listening to a recorded passage read in one of the four accents by male and female speakers. The learners showed a tendency to prefer certain accents more than others. In general, the best rated accent was the British accent for the male speakers and the American accent for the female speakers. The New Zealand accent was rated the lowest among the male speakers and one of the lowest among the female speakers. The study also found that speaker's competence, speaker's social appeal and accent preference were positively correlated. These findings highlight the importance of listening practices and exposure to various English accents in ESL classrooms to prepare students for international and intercultural communication.
C1 [Pilus, Zahariah; Wahid, Ridwan] Int Islamic Univ Malaysia, Kuala Lumpur, Malaysia.
   [Zakaria, Nur Shahida; Zakaria, Muhamad Khairul] Univ Malaysia Terengganu, English Language Learning Ctr ELC, Ctr Fundamental & Liberal Educ, Kuala Nerus, Terengganu, Malaysia.
   [Wahid, Ridwan] Int Islamic Univ Malaysia, Kulliyyah Islamic Revealed Knowledge & Human Sci, Dept English Language & Literature, Kuala Lumpur 53100, Malaysia.
RP Pilus, Z (corresponding author), Int Islamic Univ Malaysia, Kulliyyah Islamic Revealed Knowledge & Human Sci, Dept English Language & Literature, Kuala Lumpur 53100, Malaysia.
EM zahariahp@iium.edu.my; nurshahidazakaria@gmail.com;
   muhamad_khairon@yahoo.com; ridwan@iium.edu.my
RI Zakaria, Muhamad Khairul/ABC-9214-2020; Wahid, Ridwan/AAN-6905-2020
OI Zakaria, Muhamad Khairul/0000-0001-8112-3616; ,
   Ridwan/0000-0002-5228-950X
FU International Islamic University Malaysia
FX This work was supported by grants awarded by International Islamic
   University Malaysia. We would like to thank the anonymous reviewers for
   their insightful comments and suggestions.
CR Ahmed Z. T., 2014, ADV LANGUAGE LIT STU, V5, P181
   Aron A., 2002, STAT BEHAV SOCIAL SC
   Ballard L., 2013, MSU WORKING PAPERS S, V4, P47
   Bayard D., 2005, TE REO, V48, P21
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Black S., 2003, ASIAN SOCIAL SCI, V24, P12
   Bradley D, 2004, HDB VARIETIES ENGLIS, P645
   Carey MD, 2011, LANG TEST, V28, P201, DOI 10.1177/0265532210393704
   Chan JYH, 2016, TESOL QUART, V50, P285, DOI 10.1002/tesq.218
   Chan JYH, 2019, ASIAN ENGL, V21, P264, DOI 10.1080/13488678.2018.1482436
   Cheng LRL, 1999, TOP LANG DISORD, V19, P1, DOI 10.1097/00011363-199908000-00004
   Derwing T.M., 1997, STUDIES 2 LANGUAGE A, V19, P1, DOI [10.1017/s0272263197001010, DOI 10.1017/S0272263197001010]
   Derwing TM, 2009, LANG TEACHING, V42, P476, DOI 10.1017/S026144480800551X
   Diaz NR, 2015, PROCD SOC BEHV, V173, P93, DOI 10.1016/j.sbspro.2015.02.036
   Friedrich P., 2000, WORLD ENGLISH, V19, p215 , DOI [10.1111/1467-971X.00170, DOI 10.1111/1467-971X.00170]
   GASS S, 1984, LANG LEARN, V34, P65, DOI 10.1111/j.1467-1770.1984.tb00996.x
   Gill M. M., 1994, J APPL COMMUNICATION, V22, P348, DOI DOI 10.1080/00909889409365409
   Gluszek A, 2010, PERS SOC PSYCHOL REV, V14, P214, DOI 10.1177/1088868309359288
   Gurkan S, 2012, PROCD SOC BEHV, V46, P2951, DOI 10.1016/j.sbspro.2012.05.596
   Hendriks B, 2018, J ENGL ACAD PURP, V34, P28, DOI 10.1016/j.jeap.2018.03.001
   Jenkins Jennifer, 2007, ENGLISH LINGUA FRANC
   Jeon M, 2009, LANG CULT CURRIC, V22, P231, DOI 10.1080/07908310903388933
   Kachru B., 1985, ENGLISH WORLD TEACHI, P11
   Kaur P, 2014, PROCD SOC BEHV, V155, P253, DOI 10.1016/j.sbspro.2014.10.288
   Kawanami S, 2010, LET KYUSHU OKINAWA B, P1
   Kelch K., 2002, CATESOL J, V14, P57
   Kim J., 2012, INT J ENGLISH ED, V1, P127
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Ladegaard HJ, 1998, LANG COMMUN, V18, P251, DOI 10.1016/S0271-5309(98)00008-1
   Lasagabaster D, 2005, EDUC LINGUIST, V5, P217
   Luo WH, 2007, ASIA PAC EDUC REV, V8, P311, DOI 10.1007/BF03029265
   Mahboob A., 2004, LEARNING TEACHING EX, P121
   Major RC, 2005, LANG LEARN, V55, P37, DOI 10.1111/j.0023-8333.2005.00289.x
   Marsden S., 2007, NZ ENGLISH J, V21, P64
   McGee K, 2009, MALAYS J ELT RES, V5, P162
   McKay SL, 2008, INT ENGLISH ITS SOCI
   McKenzie RM, 2008, INT J APPL LINGUIST, V18, P63, DOI 10.1111/j.1473-4192.2008.00179.x
   Munro MJ, 2006, STUD SECOND LANG ACQ, V28, P111, DOI 10.1017/S0272263106060049
   Munro MJ, 1999, LANG LEARN, V49, P285, DOI 10.1111/0023-8333.49.s1.8
   Munro MJ, 1995, LANG SPEECH, V38, P289, DOI 10.1177/002383099503800305
   PILUS Z, 2013, WORLD APPL SCI J, V21, P143, DOI DOI 10.5829/idosi.wasj.2013.21.sltl.2148
   Plakans BS, 1997, TESOL QUART, V31, P95, DOI 10.2307/3587976
   Qi Zhang, 2009, NEWCASTLE WORKING PA, V15, P151
   Scales J, 2006, TESOL QUART, V40, P715, DOI 10.2307/40264305
   Smit Ute, 1997, WORLD ENGLISH, V16, P115, DOI DOI 10.1111/1467-971X.00052
   Timmis I., 2002, ELT J, V56, P240, DOI DOI 10.1093/ELT/56.3.240
   WAHID R, 2013, WORLD APPL SCI J, V21, P133, DOI DOI 10.5829/idosi.wasj.2013.21.sltl.2147
   Walkinshaw I, 2012, ELECT J ENGLISH 2 LA, V16, P1
   Walkinshaw I, 2014, SAGE OPEN, V4, DOI 10.1177/2158244014534451
   Wan Abdul Halim W.F.S., 2016, JURNAL KEMANUSIAAN, V25, P1, DOI [10.1177/0265532212456968, DOI 10.1177/0265532212456968]
   Winke P, 2013, LANG TEST, V30, P231, DOI 10.1177/0265532212456968
NR 52
TC 1
Z9 1
U1 0
U2 4
PU JOHN BENJAMINS PUBLISHING CO
PI AMSTERDAM
PA PO BOX 36224, 1020 ME AMSTERDAM, NETHERLANDS
SN 0957-6851
EI 1569-9838
J9 J ASIAN PAC COMMUN
JI J. Asian Pac. Commun.
PY 2019
VL 29
IS 2
BP 300
EP 321
DI 10.1075/japc.00035.pil
PG 22
WC Communication
SC Communication
GA IQ0EU
UT WOS:000480424400008
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Vanderplank, R
AF Vanderplank, Robert
TI 'Gist watching can only take you so far': attitudes, strategies and
   changes in behaviour in watching films with captions
SO LANGUAGE LEARNING JOURNAL
LA English
DT Article
DE Subtitles; captions; captioned films; multimedia; audiovisual;
   television; strategies
ID TELEVISION; LANGUAGE; LEARNERS; VIDEO; PRINT
AB Watching foreign language programmes and films with captions (samelanguage subtitles intended for the deaf and hard-of-hearing) has been shown to assist learners in phonetic retuning, vocabulary acquisition and listening comprehension [e.g. Mitterer and McQueen, 2009. Foreign subtitles help but native-language subtitles harm foreign speech perception. PLOS ONE 4, no. 1: e7785. doi :10.1371/journal.pone.0007785; Montero Perez, Van Den Noortgate and Desmet, 2013. captioned video for L2 listening and vocabulary learning: A meta-analysis. System 41, no. 3: 720-739; Rodgers and Webb, 2017. The effects of captions on EFL learner's comprehension of English-language television programs. CALICO Journal 34, no. 1: 20-38]. However, relatively little is known about the outcomes and changes in viewing behaviour when learners watch with captions over an extended period if choice and control of viewing material are provided. This article reports qualitative findings of the EURECAP Project in which 36 learners of French, German, Italian and Spanish at intermediate level and above in a large UK university chose from a wide range of films on DVD with optional captions and watched them under their control in their own time. Their experiences as noted in viewing diaries revealed wide differences in viewing behaviour, attitudes to watching with captions and caption-guided viewing strategies over the period of the study. Participants fell into three broad strategic categories: Minimal users who were focused throughout on enjoying films as they would in their L1, evolving users who showed marked changes in their viewing behaviour over time, and maximal users who tended to be experienced at using films to enhance their language learning. We also compare participant behaviour with models of multimedia learning and suggest implications for future practice and research, especially in the light of global video streaming services with captions.
C1 [Vanderplank, Robert] Univ Oxford, Kellogg Coll, Oxford, England.
RP Vanderplank, R (corresponding author), Univ Oxford, Kellogg Coll, Oxford, England.
EM robert.vanderplank@kellogg.ox.ac.uk
CR Bravo M.C.C., 2008, THESIS
   BRAVO MC, 2010, NEW INSIGHTS AUDIOVI, P269
   Charles T., 2015, SUBTITLES LANGUAGE L, P173
   Cole J., 2015, THESIS
   Cole J, 2016, SYSTEM, V61, P31, DOI 10.1016/j.system.2016.07.007
   Frumuselu AD, 2015, LINGUIST EDUC, V32, P107, DOI 10.1016/j.linged.2015.10.001
   Frumuselu A. D., 2018, TRANSLATION TRANSLAN, V4, P55, DOI [10.1075/ttmc.00004.fru, DOI 10.1075/TTMC.00004.FRU]
   Mayer R.E., 2014, CAMBRIDGE HDB MULTIM, P27, DOI DOI 10.1017/CBO9780511816819.003
   Mayer RE, 2014, APPL COGNITIVE PSYCH, V28, P653, DOI 10.1002/acp.3050
   Mayer RE, 2009, MULTIMEDIA LEARNING, 2ND EDITION, P1
   Mitterer H, 2009, PLOS ONE, V4, pA146, DOI 10.1371/journal.pone.0007785
   Montero Perez M, 2018, COMPUT ASSIST LANG L, V31, P1, DOI 10.1080/09588221.2017.1375960
   Montero Perez M, 2014, LANG LEARN TECHNOL, V18, P118
   Moreno R, 2007, EDUC PSYCHOL REV, V19, P309, DOI 10.1007/s10648-007-9047-2
   Moreno R, 2006, CURR DIR PSYCHOL SCI, V15, P63, DOI 10.1111/j.0963-7214.2006.00408.x
   Perez MM, 2013, SYSTEM, V41, P720, DOI 10.1016/j.system.2013.07.013
   Pujola J.-T., 2002, ReCALL, V14, P235, DOI 10.1017/S0958344002000423
   Raatz U., 2002, U LANGUAGE TESTING C, P75
   Rodgers MPH, 2017, CALICO J, V34, P20, DOI 10.1558/cj.29522
   Rodgers Michael P. H., 2013, THESIS
   Ryan RM, 2000, AM PSYCHOL, V55, P68, DOI 10.1037/0003-066X.55.1.68
   SALOMON G, 1984, J EDUC PSYCHOL, V76, P647, DOI 10.1037/0022-0663.76.4.647
   SALOMON G, 1984, J COMMUN, V34, P119, DOI 10.1111/j.1460-2466.1984.tb02164.x
   Salomon G, 2005, EDUC PSYCHO, P71
   Salomon G., 1983, ED PSYCHOL, V18, P42, DOI DOI 10.1080/00461528309529260
   VANDERPLANCK Robert, 1990, SYSTEM, V18, P221, DOI DOI 10.1016/0346-251X(90)90056-B
   Vanderplank R, 2016, NEW LANG LEARN TEACH, P1, DOI 10.1057/978-1-137-50045-8
   Vanderplank R., 1988, ELT J, V42, P272, DOI DOI 10.1093/ELT/42.4.272
   Vanderplank R, 2010, LANG TEACHING, V43, P1, DOI 10.1017/S0261444809990267
   Webb S, 2015, ESL APPL LINGUIST, P159
NR 30
TC 1
Z9 1
U1 3
U2 10
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0957-1736
EI 1753-2167
J9 LANG LEARN J
JI Lang. Learn. J.
PY 2019
VL 47
IS 4
SI SI
BP 407
EP 423
DI 10.1080/09571736.2019.1610033
PG 17
WC Education & Educational Research
SC Education & Educational Research
GA IN6WL
UT WOS:000478822600002
DA 2021-02-24
ER

PT J
AU Zou, QQ
AF Zou, Qiongqiong
TI Influence of L1 Background on Categorical Perception of Mandarin Tones
   by Russian and Vietnamese Listeners
SO INTERNATIONAL JOURNAL OF ENGLISH LINGUISTICS
LA English
DT Article
DE categorical perception; tone; language background; identification;
   discrimination
ID SPEECH-PERCEPTION; ONSET-TIME; LANGUAGE EXPERIENCE; LEXICAL TONES;
   CHINESE TONES; DISCRIMINATION; IDENTIFICATION; PITCH; ENGLISH;
   CONSONANTS
AB This study investigated the influence of L1 background on categorical perception of lexical tones by three language groups, namely native Mandarin, Russian and Vietnamese listeners. Tone identification and discrimination scores of two tone continua (T1-T2 and T1-T4) were measured for each participant. Results showed that the two tone language groups, i e , Mandarin and Vietnamese listeners, perceived both tone continua categorically whereas the non-tone language group, i.e., Russian listeners, did not. More specifically, while the Russian group exhibited significantly broader identification boundaries and performed near chance level in discrimination tasks, the Mandarin and Vietnamese groups presented sharp slopes in identification curves and corresponding discrimination peaks at the cross-boundary positions. Moreover, Mandarin and Vietnamese listeners showed slightly different discrimination curves, which could be attributed to the effect of their different tone inventories. The current findings suggest that native tone language background, to some extent, can facilitate non-native tone perception.
C1 [Zou, Qiongqiong] Hunan Univ, Coll Foreign Languages, 2 Lushan South Rd, Changsha 410082, Hunan, Peoples R China.
RP Zou, QQ (corresponding author), Hunan Univ, Coll Foreign Languages, 2 Lushan South Rd, Changsha 410082, Hunan, Peoples R China.
EM zouqiong@hnu.edu.cn
CR ABRAMSON AS, 1978, LANG SPEECH, V21, P319, DOI 10.1177/002383097802100406
   Altmann CF, 2014, NEUROPSYCHOLOGIA, V64, P13, DOI 10.1016/j.neuropsychologia.2014.09.006
   BRANDT J, 1980, BRAIN LANG, V9, P324, DOI 10.1016/0093-934X(80)90152-2
   CARNEY AE, 1977, J ACOUST SOC AM, V62, P961, DOI 10.1121/1.381590
   Chao Y. R., 1948, MANDARIN PRIMER, DOI [10.4159/harvard.9780674732889, DOI 10.4159/HARVARD.9780674732889]
   Chen F, 2017, J CHILD LANG, V44, P1413, DOI 10.1017/S0305000916000581
   Crosby CF, 2013, THESIS
   Deutsch D, 2006, J ACOUST SOC AM, V119, P719, DOI 10.1121/1.2151799
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Finney D. J., 1971, PROBIT ANAL
   Francis AL, 2003, PERCEPT PSYCHOPHYS, V65, P1029, DOI 10.3758/BF03194832
   Francis AL, 2008, J PHONETICS, V36, P268, DOI 10.1016/j.wocn.2007.06.005
   FRY DB, 1962, LANG SPEECH, V5, P171, DOI 10.1177/002383096200500401
   Gandour J. T., 1978, TONE LINGUISTIC SURV, P41, DOI DOI 10.1016/B978-0-12-267350-4.50007-8
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Hao YC, 2012, J PHONETICS, V40, P269, DOI 10.1016/j.wocn.2011.11.001
   Huang T, 2010, PHONETICA, V67, P243, DOI 10.1159/000327392
   Lee YS, 1996, J PSYCHOLINGUIST RES, V25, P527, DOI 10.1007/BF01758181
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   MOULINES E, 1995, SPEECH COMMUN, V16, P175, DOI 10.1016/0167-6393(94)00054-E
   Peng G, 2010, J PHONETICS, V38, P616, DOI 10.1016/j.wocn.2010.09.003
   PISONI DB, 1977, J ACOUST SOC AM, V61, P1352, DOI 10.1121/1.381409
   ROSNER BS, 1984, J ACOUST SOC AM, V75, P1231, DOI 10.1121/1.390775
   Shen GN, 2016, J ACOUST SOC AM, V140, P4396, DOI 10.1121/1.4971765
   So C. K., 2005, J ACOUST SOC AM, V177, DOI [10.1121/1.4786607, DOI 10.1121/1.4786607]
   So CK, 2014, STUD SECOND LANG ACQ, V36, P195, DOI 10.1017/S0272263114000047
   So CK, 2010, LANG SPEECH, V53, P273, DOI 10.1177/0023830909357156
   Sun KC, 2012, J EAST ASIAN LINGUIS, V21, P305, DOI 10.1007/s10831-012-9092-9
   WANG WSY, 1973, SCI AM, V228, P50, DOI 10.1038/scientificamerican0273-50
   WANG WSY, 1976, ANN NY ACAD SCI, V280, P61, DOI 10.1111/j.1749-6632.1976.tb25472.x
   Wang X., 2006, P SPEECH PROSODY
   Wang XC, 2013, MOD LANG J, V97, P144, DOI 10.1111/j.1540-4781.2013.01386.x
   Wayland R, 2003, APPL PSYCHOLINGUIST, V24, P113, DOI 10.1017/S0142716403000067
   Wayland RP, 2004, LANG LEARN, V54, P681, DOI 10.1111/j.1467-9922.2004.00283.x
   Weenink D, 2018, PRAAT DOING PHONETIC, P43
   Wen B. Y., 2019, LANG TEACH RES, V195, P31
   Xu YS, 2006, J ACOUST SOC AM, V120, P1063, DOI 10.1121/1.2213572
   Yip Moira, 2002, TONE, DOI [10.1017/CBO9781139164559, DOI 10.1017/CBO9781139164559]
   Zheng HY, 2012, LANG COGNITIVE PROC, V27, P184, DOI 10.1080/01690965.2010.520493
   ZLATIN MA, 1974, J ACOUST SOC AM, V56, P981, DOI 10.1121/1.1903359
NR 40
TC 0
Z9 0
U1 0
U2 0
PU CANADIAN CENTER SCIENCE & EDUCATION
PI TORONTO
PA 1120 FINCH AVE W, STE 701-309, TORONTO, ON M3J 3H7, CANADA
SN 1923-869X
EI 1923-8703
J9 INT J ENGL LINGUIST
JI Int. J. Engl. Linguist.
PY 2019
VL 9
IS 4
BP 275
EP 287
DI 10.5539/ijel.v9n4p275
PG 13
WC Linguistics
SC Linguistics
GA IK4ZW
UT WOS:000476596500024
OA Bronze
DA 2021-02-24
ER

PT J
AU Shetty, HN
   Mendhakar, A
AF Shetty, Hemanth Narayan
   Mendhakar, Akshay
TI Effect of rate altered perception of deep band modulated phrase in noise
   from normal hearing younger and older adult groups
SO HEARING BALANCE AND COMMUNICATION
LA English
DT Article
DE Speech enhancement; temporal cues; older adults; speech perception
ID AGE-RELATED-CHANGES; SPEECH RECOGNITION; COMPREHENSION; VARIABILITY;
   MASKERS
AB Purpose: To evaluate the effect of speaking rate on speech perception with unprocessed (UP) and envelope enhancement in noise on normal hearing younger adults (YAG) and older adults (OAG).
   Method: A purposive sampling with repeated measures research design was adopted to evaluate envelope enhancement on speech perception in adverse listening condition. Study samples: Thirty normal hearing participants were grouped into two based on age: YAG (N = 15) within age range of 18-25 years and OAG (N = 15) within the age range of 65-83 years. Phrases prepared in three speech rates (normal, 35% and 40%) at three different signal-to-noise ratios (SNRs) (quiet, -1 dB SNR and -5 dB SNR) were presented at participant's comfortable level.
   Results: In each of the rate of speech at each SNR, the perception score was significantly better in deep band modulation (DBM) than UP. Further, perception score of UP from YAG was almost equal to scores of DBM from OAG, in each experimental condition.
   Conclusion: Older adults can take advantage of envelope enhancement when speech rate is altered and embedded in noise.
C1 [Shetty, Hemanth Narayan] Univ Mysuru, All India Inst Speech & Hearing, Dept Audiol, Mysuru, India.
   [Mendhakar, Akshay] Univ Mysuru, All India Inst Speech & Hearing, Dept Clin Serv, Mysuru, India.
RP Shetty, HN (corresponding author), Univ Mysuru, All India Inst Speech & Hearing, Dept Audiol, Mysuru, India.
EM hemanthn.shetty@gmail.com
CR Apoux F, 2004, HEARING RES, V189, P13, DOI 10.1016/S0378-5955(03)00397-6
   BRONKHORST AW, 1992, J ACOUST SOC AM, V92, P3132, DOI 10.1121/1.404209
   Desjardins JL, 2013, EAR HEARING, V34, P261, DOI 10.1097/AUD.0b013e31826d0ba4
   DUBNO JR, 1984, J ACOUST SOC AM, V76, P87, DOI 10.1121/1.391011
   DUCHIN SW, 1987, J COMMUN DISORD, V20, P245, DOI 10.1016/0021-9924(87)90022-0
   Gordon-Salant S, 2004, J ACOUST SOC AM, V115, P1808, DOI 10.1121/1.1645249
   GORDONSALANT S, 1995, J SPEECH HEAR RES, V38, P1150, DOI 10.1044/jshr.3805.1150
   Hemanth N, 2016, J INDIAN SPEECH LANG, V29, P1
   Hemanth NS, 2015, HEARING BALANCE COMM, V13, P1
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   MILLER JL, 1984, PHONETICA, V41, P215, DOI 10.1159/000261728
   Nagarajan S S, 1998, IEEE Trans Rehabil Eng, V6, P257, DOI 10.1109/86.712220
   Narne VK, 2008, EAR HEARING, V29, P45
   Peters RW, 1998, J ACOUST SOC AM, V103, P577, DOI 10.1121/1.421128
   REISBERG B, 1982, AM J PSYCHIAT, V139, P1136
   Savithri SR, 2005, RATE SPEECH READING, P1
   SCHMITT JF, 1983, J SPEECH HEAR RES, V26, P373, DOI 10.1044/jshr.2603.373
   SCHMITT JF, 1985, J SPEECH HEAR RES, V28, P309, DOI 10.1044/jshr.2802.309
   Schneider BA, 2005, PSYCHOL AGING, V20, P261, DOI 10.1037/0882-7974.20.2.261
   Summers V, 2004, J SPEECH LANG HEAR R, V47, P245, DOI 10.1044/1092-4388(2004/020)
   Tun PA, 1998, PSYCHOL AGING, V13, P424, DOI 10.1037/0882-7974.13.3.424
NR 21
TC 0
Z9 0
U1 0
U2 0
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2169-5717
EI 2169-5725
J9 HEARING BALANC COMMU
JI Hearing Balanc. Commun.
PY 2019
VL 17
IS 2
BP 154
EP 164
DI 10.1080/21695717.2019.1591006
PG 11
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA II0DO
UT WOS:000474875800006
DA 2021-02-24
ER

PT J
AU Jarollahi, F
   Aarabi, S
   Jalaei, S
AF Jarollahi, Farnoush
   Aarabi, Saeid
   Jalaei, Shohre
TI Comparative Study of the ability of selective attention and speech
   perception in noise between 6 to 9 year old normal and learning disabled
   children
SO HEARING BALANCE AND COMMUNICATION
LA English
DT Article
DE Auditory processing; auditory attention; learning disability (LD);
   speech perception; noise
ID AUDITORY ATTENTION
AB Object: Selective auditory attention and speech perception in the presence of noise are necessary skills to correctly process speech. Persian version of monaural selective auditory attention test [P-mSAAT] that simultaneously assesses selective auditory attention and speech in noise perception performance was used in the present study.
   Design: The P-mSAAT was performed on 89 normal children aged 6 to 9 and 24 children with learning disability sampled from different schools in Tehran in two competitive and non-competitive ways.
   Results: The average of test scores had a significant difference in a competitive way between normal and children with learning disability (P<0/001). Furthermore, the test scores improved as a function of age in the both groups.
   Conclusion: Findings of the current study demonstrated that children presented with learning disability had difficulty in speech perception in the presence of competitive noise accompanied by reduced selective auditory attention ability. It is also suggested that P-mSAAT can be used as a screening test in diagnosing Learning disability in children aged 6 to 9 due to its high sensitivity.
C1 [Jarollahi, Farnoush; Aarabi, Saeid] Iran Univ Med Sci, Sch Rehabil Sci, Dept Audiol, Tehran, Iran.
   [Jalaei, Shohre] Univ Tehran Med Sci, Biostat Sch Rehabil, Tehran, Iran.
RP Aarabi, S (corresponding author), Iran Univ Med Sci, Sch Rehabil Sci, Dept Audiol, Tehran, Iran.
EM saeid.aarabi@gmail.com
RI Jarollahi, Farnoush/N-2668-2018; Jarollahi, Farnoush/ABA-4707-2020
OI Jarollahi, Farnoush/0000-0002-0850-3433
FU Iran University of Medical Sciences [33522. -12- 23]
FX This study has been supported by Iran University of Medical Sciences
   [grant no. 33522. -12-23].
CR Aarabi S, 2016, AUDIT VES RES, V25, P49
   Association AP, 2013, DIAGNOSTIC STAT MANU
   Association AS L H, 2005, CENTR AUD PROC DIS
   BOWEN SM, 1988, J LEARN DISABIL, V21, P623, DOI 10.1177/002221948802101007
   CHERMAK GD, 1992, J SPEECH HEAR RES, V35, P661, DOI 10.1044/jshr.3503.661
   Cherry R, 2006, LANG SPEECH HEAR SER, V37, P137, DOI 10.1044/0161-1461(2006/015)
   Cherry R, 1992, SCREENING CHILDREN A, P361
   CHERRY RS, 1983, J LEARN DISABIL, V16, P202, DOI 10.1177/002221948301600405
   Evans GW, 2006, ANNU REV PSYCHOL, V57, P423, DOI 10.1146/annurev.psych.57.102904.190057
   First Michael B., 2004, DSM 4 TR MENTAL DISO
   HEDRICK DL, 1974, PERCEPT MOTOR SKILL, V38, P591, DOI 10.2466/pms.1974.38.2.591
   Iliadou V, 2009, INT J PEDIATR OTORHI, V73, P1029, DOI 10.1016/j.ijporl.2009.04.004
   Koiek S, 2018, AUDITORY VESTIBULAR, V27, P86
   MACCOBY EE, 1966, J EXP CHILD PSYCHOL, V3, P113, DOI 10.1016/0022-0965(66)90086-5
   NOBER LW, 1975, J LEARN DISABIL, V8, P656, DOI 10.1177/002221947500801010
   OBRZUT JE, 1986, J LEARN DISABIL, V19, P308, DOI 10.1177/002221948601900511
   Obrzut JE, 2011, BRAIN COGNITION, V76, P323, DOI 10.1016/j.bandc.2011.02.012
   Shield BM, 2008, J ACOUST SOC AM, V123, P133, DOI 10.1121/1.2812596
NR 18
TC 0
Z9 0
U1 0
U2 1
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2169-5717
EI 2169-5725
J9 HEARING BALANC COMMU
JI Hearing Balanc. Commun.
PY 2019
VL 17
IS 2
BP 165
EP 169
DI 10.1080/21695717.2019.1567198
PG 5
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA II0DO
UT WOS:000474875800007
DA 2021-02-24
ER

PT J
AU Trakantalerngsak, T
AF Trakantalerngsak, Tanporn
TI Nihongo Speech Trainer: A Pronunciation Training System for Japanese
   Sounds
SO JOURNAL OF LANGUAGE AND EDUCATION
LA English
DT Article
DE Nihongo Speech Trainer; HVPT perceptual training; L2 speech perception;
   perception training
ID ENGLISH; LISTENERS; SPEAKERS
AB This article will present the methodology, as well as the results, of a pilot study of the 'Nihongo Speech Trainer' aimed at helping Thai learners improve their ability to identify Japanese contrasts. The pilot study was performed on 15 participants. The tool focuses on specific contrasts that are problematic for Thai learners such as Japanese fricatives and affricates. Perceptual training uses a high-variability phonetic training method (hereafter referred to as "HVPT perceptual training"). Each training session included 90 minimal pairs in which the target contrasts were embedded in initial, medial and final positions. The training stimuli were produced by seven Japanese native speakers. The results of the pilot study showed that the use of the Nihongo Speech Trainer can lead to better perception of the trained Japanese sounds. The results of a questionnaire among the participants also showed that the system helped to improve their perception and production ability. However, despite these positive results with the use of the Nihongo Speech Trainer, there is room for improvement, which may lead to better training results.
C1 [Trakantalerngsak, Tanporn] Mahidol Univ, Nakhon Pathom, Thailand.
RP Trakantalerngsak, T (corresponding author), Mahidol Univ, Fac Liberal Arts, 999 Phutthamonthon Sai 4, Nakhon Pathom 73170, Thailand.
EM tanporn.tra@mahidol.edu
CR Barriuso AT., 2018, CATESOL J, V30, P177
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P977, DOI 10.3758/BF03206911
   Derwing T., 2015, PRONUNCIATION FUNDAM
   Gilakjani AP, 2017, INT J ENGL LINGUIST, V7, P95, DOI 10.5539/ijel.v7n5p95
   Hirata Y., 2004, Computer Assisted Language Learning, V17, P357, DOI 10.1080/0958822042000319629
   Iverson P, 2012, APPL PSYCHOLINGUIST, V33, P145, DOI 10.1017/S0142716411000300
   Lambacher SG, 2005, APPL PSYCHOLINGUIST, V26, P227, DOI 10.1017/S0142716405050150
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   Logan J. S., 1995, SPEECH PERCEPTION LI, P351
   Pirani J, 2004, SUPPORTING ELEARNING
   Thomson RI, 2011, CALICO J, V28, P744
   Tsai P. H., 2015, TURKISH ONLINE J ED, V14, P1
   Yoshida M, 2018, CATESOL J, V30, P195
NR 13
TC 0
Z9 0
U1 0
U2 0
PU NATL RESEARCH UNIV HIGHER SCH ECONOMICS
PI MOSCOW
PA SHABOLOVKA, 26, MOSCOW, 119049, RUSSIA
EI 2411-7390
J9 J LANG EDUC
JI J. Lang. Educ.
PY 2019
VL 5
IS 2
BP 78
EP 85
DI 10.17323/jle.2019.8802
PG 8
WC Education & Educational Research; Linguistics
SC Education & Educational Research; Linguistics
GA IF6VK
UT WOS:000473218000006
OA DOAJ Gold
DA 2021-02-24
ER

PT J
AU Tomaru, K
   Arai, T
AF Tomaru, Kanako
   Arai, Takayuki
TI Evaluation of articulatory similarity using formant and fundamental
   frequencies during perceptual assimilation of English schwa by native
   speakers of Japanese
SO ACOUSTICAL SCIENCE AND TECHNOLOGY
LA English
DT Article
DE Perceptual assimilation model (PAM); English schwa; Japanese vowels;
   Formant frequency; Fundamental frequency; Articulatory similarity
ID SPEECH-PERCEPTION; DISCRIMINATION
AB The main hypothesis behind the perceptual assimilation model (PAM) is that listeners perceive non-native speech sounds based on articulatory similarities between the non-native speech sounds and native speech sounds. When non-native and native sounds are substantially similar, non-native sounds are perceived as equivalent to native ones. Former research shows that the schwa vowel is perceptually assimilated to Japanese /a/ almost exclusively. In this study, we investigate acoustical cues that Japanese listeners rely on to assess the articulatory similarities between the English schwa and the Japanese vowels during the perceptual assimilation. Traditionally, the first two formants (F1 and F2) are considered to be effective for assimilation judgements; however, former investigations imply that these dimensions may be insufficient. In this study, we compared the schwa and the five Japanese vowels in the dimensions of vowel openness and backness using additional information, i.e., the third formant (F3) and fundamental frequencies (F0). The results of the analyses suggest that Japanese listeners use F1, F2, F3 and F0 information to assess articulatory similarities between the schwa and the Japanese vowels during perceptual assimilation.
C1 [Tomaru, Kanako; Arai, Takayuki] Sophia Univ, Fac Sci & Technol, Chiyoda Ku, 7-1 Kioi Cho, Tokyo 1028554, Japan.
   [Tomaru, Kanako] Mejiro Univ, Fac Foreign Language Studies, Shinjuku Ku, 4-31-1 Nakaochiai, Tokyo 1618539, Japan.
RP Tomaru, K (corresponding author), Sophia Univ, Fac Sci & Technol, Chiyoda Ku, 7-1 Kioi Cho, Tokyo 1028554, Japan.; Tomaru, K (corresponding author), Mejiro Univ, Fac Foreign Language Studies, Shinjuku Ku, 4-31-1 Nakaochiai, Tokyo 1618539, Japan.
EM k.tomaru@mejiro.ac.jp; arai@sophia.ac.jp
FU JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [16K16832,
   18K12378]
FX This research was supported by JSPS KAKENHI (Grant Numbers 16K16832,
   18K12378).
CR Ainsworth WA, 1975, AUDITORY ANAL PERCEP, P103, DOI DOI 10.1016/B978-0-12-248550-3.50011-8
   Akagi M., 1994, I ELECT INFORM COMMU, V77, P948
   Best Catherine T., 1991, SR107108 HASK LAB, P1
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P, PRAAT DOING PHONETIC
   Bohn O.-S., 2007, LANGUAGE EXPERIENCE
   Cruttenden Alan, 2014, GIMSONS PRONUNCIATIO
   EIMAS PD, 1963, LANG SPEECH, V6, P206, DOI 10.1177/002383096300600403
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Guion SG, 2000, J ACOUST SOC AM, V107, P2711, DOI 10.1121/1.428657
   KASUYA H, 1968, J ACOUST SOC JPN, V24, P355
   Kent R. D., 2002, ACOUSTIC ANAL SPEECH, P17
   LINDBLOM BE, 1971, J ACOUST SOC AM, V50, P1166, DOI 10.1121/1.1912750
   Maekawa K., 2003, ISCA IEEE WORKSH SPO, P7
   Maekawa K., 2004, P INT S LARG SCAL KN, P19
   Masuko Y., 2011, AREA CULT STUD, V82, P105
   Polka L, 2011, J PHONETICS, V39, P467, DOI 10.1016/j.wocn.2010.08.007
   Silverman D., 2011, BLACKWELL COMPANION, P628
   Strange W, 1998, J PHONETICS, V26, P311, DOI 10.1006/jpho.1998.0078
   SYRDAL AK, 1986, J ACOUST SOC AM, V79, P1086, DOI 10.1121/1.393381
   Tomaru K., 2012, P 26 GEN M PHON SOC, P79
   Tomaru K., 2015, P AUT M AC SOC JPN, P323
   TRAUNMULLER H, 1981, J ACOUST SOC AM, V69, P1465, DOI 10.1121/1.385780
   Tsujimura Natsuko, 1996, INTRO JAPANESE LINGU
   Tyler MD, 2014, PHONETICA, V71, P4, DOI 10.1159/000356237
   Vance Timothy J., 2008, SOUNDS JAPANESE
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   ZWICKER E, 1980, J ACOUST SOC AM, V68, P1523, DOI 10.1121/1.385079
NR 28
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC JAPAN
PI TOKYO
PA NAKAURA 5TH-BLDG. 2F, 2-18-20 SOTOKANDA, CHIYODA-KU, TOKYO, 101-0021,
   JAPAN
SN 1346-3969
EI 1347-5177
J9 ACOUST SCI TECHNOL
JI Acoust. Sci. Technol.
PY 2019
VL 40
IS 4
BP 233
EP 240
DI 10.1250/ast.40.233
PG 8
WC Acoustics
SC Acoustics
GA IF0BC
UT WOS:000472739600001
OA Bronze
DA 2021-02-24
ER

PT J
AU Chen, F
   Hu, Y
AF Chen, Fei
   Hu, Yi
TI Segmental contributions to cochlear implant speech perception
SO SPEECH COMMUNICATION
LA English
DT Article
DE Vowel importance; Vowel-consonant transition; Bilateral CI hearing
ID TONE RECOGNITION; BILATERAL USERS; NORMAL-HEARING; INTELLIGIBILITY;
   ENHANCEMENT; CONSONANTS; ENVELOPE; VOWELS; CUES; IDENTIFICATION
AB The present work assessed segmental contributions to speech perception by listeners who had been bilaterally fitted with cochlear implants (CIs). TIMIT sentences were edited to contain vowels (Vs) (replacing consonants with silence) or consonants (Cs) (replacing vowels with silence) and vowel-consonant (V-C) transitions, then presented to unilaterally or bilaterally fitted CI listeners for recognition. Experimental results showed that segmental interruption had a significant influence on CI speech perception. Vowels contained more perceptual information than consonants, and V-C transitions could significantly improve the intelligibility of V-only or C-only sentences. In addition, the intelligibility of several segmentally processed sentences may be significantly improved with bilateral CI hearing relative to the unilateral scenario. The present work asserted the importance of vowels and V-C transitions for speech perception by implanted patients, which is consistent with early studies of normal-hearing listeners, and suggested that the speech perception performance under segmentally interrupted conditions could benefit from the usage of bilateral CIs.
C1 [Chen, Fei] Southern Univ Sci & Technol, Dept Elect & Elect Engn, Shenzhen, Peoples R China.
   [Hu, Yi] Univ Wisconsin, Dept Elect Engn & Comp Sci, Milwaukee, WI 53201 USA.
RP Chen, F (corresponding author), Southern Univ Sci & Technol, Dept Elect & Elect Engn, Shenzhen, Peoples R China.; Hu, Y (corresponding author), Univ Wisconsin, Dept Elect Engn & Comp Sci, Milwaukee, WI 53201 USA.
EM fchen@sustc.edu.cn; huy@uwm.edu
RI Chen, Fei/AAK-6755-2020
OI Chen, Fei/0000-0002-6988-492X
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61571213]; Basic Research Foundation of
   Shenzhen [JCYJ 20170817110841907]
FX This work was supported by the National Natural Science Foundation of
   China (grant No. 61571213), and the Basic Research Foundation of
   Shenzhen (grant No. JCYJ 20170817110841907).
CR Bhargava P, 2016, JARO-J ASSOC RES OTO, V17, P475, DOI 10.1007/s10162-016-0565-9
   Caselli MC, 2012, J SPEECH LANG HEAR R, V55, P382, DOI 10.1044/1092-4388(2011/10-0248)
   Chen F., 2014, P 15 ANN C INT SPEEC, P2002
   Chen F, 2015, J PHONETICS, V52, P26, DOI 10.1016/j.wocn.2015.04.003
   Chen F, 2014, J SPEECH LANG HEAR R, V57, P338, DOI 10.1044/1092-4388(2013/12-0324)
   Chen F, 2013, J ACOUST SOC AM, V134, pEL178, DOI 10.1121/1.4812820
   Chen J, 2013, J ACOUST SOC AM, V133, P2910, DOI 10.1121/1.4799807
   Chen J, 2012, J ACOUST SOC AM, V131, P2987, DOI 10.1121/1.3689556
   Cole RA, 1996, INT CONF ACOUST SPEE, P853, DOI 10.1109/ICASSP.1996.543255
   Fogerty D, 2014, J ACOUST SOC AM, V135, P1568, DOI 10.1121/1.4863652
   Fogerty D, 2012, J ACOUST SOC AM, V131, P1490, DOI 10.1121/1.3676696
   Fogerty D, 2009, J ACOUST SOC AM, V126, P847, DOI 10.1121/1.3159302
   Fu QJ, 2008, HEARING RES, V242, P198, DOI 10.1016/j.heares.2007.11.010
   Galvin JJ, 2009, ANN NY ACAD SCI, V1169, P518, DOI 10.1111/j.1749-6632.2009.04551.x
   Garofalo J., 1993, TIMIT ACOUSTIC PHONE
   Kewley-Port D, 2007, J ACOUST SOC AM, V122, P2365, DOI 10.1121/1.2773986
   King SE, 2012, J AM ACAD AUDIOL, V23, P313, DOI 10.3766/jaaa.23.5.3
   Koning R, 2016, HEARING RES, V342, P13, DOI 10.1016/j.heares.2016.09.002
   Lee T, 2014, INT J AUDIOL, V53, P546, DOI 10.3109/14992027.2014.893374
   Litovsky R, 2006, EAR HEARING, V27, P714, DOI 10.1097/01.aud.0000246816.50820.42
   Litovsky RY, 2006, EAR HEARING, V27, P43, DOI 10.1097/01.aud.0000194515.28023.4b
   Loizou Philipos C, 2006, Adv Otorhinolaryngol, V64, P109, DOI 10.1159/000094648
   Loizou PC, 2009, J ACOUST SOC AM, V125, P372, DOI 10.1121/1.3036175
   Neuman AC, 2007, EAR HEARING, V28, P73, DOI 10.1097/01.aud.0000249910.80803.b9
   Nie KB, 2005, IEEE T BIO-MED ENG, V52, P64, DOI 10.1109/TBME.2004.839799
   Schleich P, 2004, EAR HEARING, V25, P197, DOI 10.1097/01.AUD.0000130792.43315.97
   Schoen F, 2005, OTOL NEUROTOL, V26, P429, DOI 10.1097/01.mao.0000169772.16045.86
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Srinivasan N.K., 2013, 2013 C IMPL AUD PROS
   Stevens KN, 2002, J ACOUST SOC AM, V111, P1872, DOI 10.1121/1.1458026
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Tong MCF, 2009, ORL-J OTO-RHIN-LARYN, V71, P184, DOI 10.1159/000229295
   Xin L, 2004, J ACOUST SOC AM, V116, P3659, DOI 10.1121/1.1783352
NR 33
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0167-6393
EI 1872-7182
J9 SPEECH COMMUN
JI Speech Commun.
PD JAN
PY 2019
VL 106
BP 79
EP 84
DI 10.1016/j.specom.2018.12.001
PG 6
WC Acoustics; Computer Science, Interdisciplinary Applications
SC Acoustics; Computer Science
GA IE9GY
UT WOS:000472684100008
DA 2021-02-24
ER

PT J
AU McCarthy, JH
   Hedrick, M
   Springer, C
AF McCarthy, Jillian H.
   Hedrick, Mark
   Springer, Cary
TI Relations between speech production, speech perception, and spelling in
   children with complex communication needs: a preliminary examination
SO SPEECH LANGUAGE AND HEARING
LA English
DT Article
DE Speech perception; speech production; spelling
ID ALTERNATIVE COMMUNICATION; PHONOTACTIC PROBABILITY; LITERACY
   INSTRUCTION; PHYSICAL IMPAIRMENTS; CEREBRAL-PALSY; INDIVIDUALS;
   ABILITIES; MEMORY; WORDS
AB Purpose: To determine the influence of speech production and speech perception upon spelling abilities in children with complex communication needs (CCN).
   Methods: Eight children (3 females, 5 males) with cerebral palsy, who did and did not use augmentative and alternative communication (AAC), were recruited to participate. The participants ranged in age from 5 years, 8 months to 11 years, 5 months (M=8 years, 3 months). The children were assessed using clinical tests of speech production (or intelligibility), standardized tests of spelling and receptive vocabulary, and two experimental tasks focusing on spelling generation and spelling identification using pseudo-words matched on phonotactic probability.
   Results: Using Spearman's correlation, significant relationships were found between the number of pseudo-words spelled and identified correctly. Further examination using a Wilcoxon Signed-Ranks test revealed a significant difference between list presentation type for the percentage of correctly spelled pseudo-words during the spelling generation task, but not for percentage of correctly identified words in the spelling identification task. A significantly greater percentage of consonant and vowel sounds were produced during the spelling generation task when individual sounds of the words were provided; however, there was no difference in performance during the identification task.
   Conclusions: Results suggest that speech perception has a strong influence than speech production in the development of spelling skills for children with CCN who do and do not use AAC. Further research is required on how to best teach spelling while taking advantage of perceptual abilities.
C1 [McCarthy, Jillian H.; Hedrick, Mark] Univ Tennessee, Dept Audiol & Speech Pathol, Hlth Sci Ctr, Knoxville, TN 37996 USA.
   [Springer, Cary] Univ Tennessee, Off Informat Technol, Knoxville, TN 37996 USA.
RP McCarthy, JH (corresponding author), Univ Tennessee, Hlth Sci Ctr, 527 South Stadium Hall, Knoxville, TN 37996 USA.
EM jmccar21@uthsc.edu
OI Springer, Cary/0000-0003-3682-360X
FU Barkley Trust; Nebraska Speech-Language-Hearing Endowment (NSLHE) Fund
   Grant 2010; National Institutes of Health (NIH); National Institute on
   Deafness and Other Communication Disorders Ruth L. Kirschstein National
   Research Service Pre-doctoral Fellowship [NIH F31 DC010965-02]
FX The research project was supported in part by the Barkley Trust,
   Nebraska Speech-Language-Hearing Endowment (NSLHE) Fund Grant 2010, and
   the National Institutes of Health (NIH); National Institute on Deafness
   and Other Communication Disorders Ruth L. Kirschstein National Research
   Service Pre-doctoral Fellowship (NIH F31 DC010965-02).
CR American Speech-Hearing Association, 1997, AUD SCREEN GUID PED, DOI [10.1044/policy.GL1997-00199, DOI 10.1044/POLICY.GL1997-00199]
   Baddeley A., 1974, PSYCHOL LEARN MOTIV, V8, P47, DOI [10.1016/S0079-7421(08)60452-1, DOI 10.1016/S0079-7421(08)60452-1]
   BADDELEY AD, 1975, J VERB LEARN VERB BE, V14, P575, DOI 10.1016/S0022-5371(75)80045-4
   BESNER D, 1983, CAN J PSYCHOL, V37, P300, DOI 10.1037/h0080719
   BISHOP DVM, 1989, BRIT J PSYCHOL, V80, P1, DOI 10.1111/j.2044-8295.1989.tb02300.x
   BISHOP DVM, 1985, COGNITIVE NEUROPSYCH, V2, P229, DOI 10.1080/02643298508252867
   Dowden P. A, 1997, AUGMENTATIVE ALTERNA, V13, P48, DOI DOI 10.1080/07434619712331277838
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   Ehri LC, 2000, TOP LANG DISORD, V20, P19, DOI 10.1097/00011363-200020030-00005
   Foley B.E., 1999, AUGMENTATIVE ALTERNA, V15, P156, DOI [10.1080/07434619912331278695, DOI 10.1080/07434619912331278695]
   Hart P, 2007, AUGMENT ALTERN COMM, V23, P16, DOI 10.1080/07434610600802737
   HITCH GJ, 1989, Q J EXP PSYCHOL-A, V41, P321, DOI 10.1080/14640748908402368
   HITCH GJ, 1983, PHILOS T ROY SOC B, V302, P325, DOI 10.1098/rstb.1983.0058
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   Hustad KC, 2004, AM J SPEECH-LANG PAT, V13, P168, DOI 10.1044/1058-0360(2004/017)
   Hustad KC, 2003, J SPEECH LANG HEAR R, V46, P462, DOI 10.1044/1092-4388(2003/038)
   Koppenhaver D. A., 1992, ISSUES RES SPECIAL E, V2, P156
   KOPPENHAVER DA, 1993, TOP LANG DISORD, V13, P1, DOI 10.1097/00011363-199302000-00003
   KOPPENHAVER DA, 1993, TECHNOL DISABIL, V2, P32, DOI 10.3233/TAD-1993-2305
   Larsen S., 1999, TEST WRITTEN SPELLIN
   Larsson M, 2009, J DEV PHYS DISABIL, V21, P369, DOI 10.1007/s10882-009-9149-5
   Light Janice, 2008, Seminars in Speech and Language, V29, P120, DOI 10.1055/s-2008-1079126
   Massaro D. W., 1998, PERCEIVING TALKING F
   Masterson JJ, 2000, TOP LANG DISORD, V20, P50, DOI 10.1097/00011363-200020030-00007
   McCarthy J. H., 2011, IMPACT ARTIFICIAL SU
   McCarthy JH, 2015, DISABIL REHABIL-ASSI, V10, P221, DOI 10.3109/17483107.2014.883650
   Moats L. C., 1995, SPELLING DEV DISABIL
   Peeters M, 2009, RES DEV DISABIL, V30, P712, DOI 10.1016/j.ridd.2008.10.002
   Rosenblum LD, 2005, BLACKW HBK LINGUIST, P51, DOI 10.1002/9780470757024.ch3
   Sandberg AD, 2006, DEV MED CHILD NEUROL, V48, P629, DOI 10.1017/S0012162206001344
   Sandberg AD, 2010, AUGMENT ALTERN COMM, V26, P191, DOI 10.3109/07434618.2010.505607
   Schlosser RW, 2004, J SPEECH LANG HEAR R, V47, P848, DOI [10.1044/1092-4388(2004/063), 10.4044/1092-4388(2004/063)]
   Smith M, 2009, INT J LANG COMM DIS, V44, P864, DOI [10.3109/13682820802389873, 10.1080/13682820802389873]
   Storkel HL, 2001, J SPEECH LANG HEAR R, V44, P1321, DOI 10.1044/1092-4388(2001/103)
   VALLAR G, 1982, Q J EXP PSYCHOL-A, V34, P53, DOI 10.1080/14640748208400857
   Vandervelden M., 1999, AUGMENTATIVE ALTERNA, V15, P191, DOI DOI 10.1080/07434619912331278725
   Vitevitch MS, 2004, BEHAV RES METH INS C, V36, P481, DOI 10.3758/BF03195594
NR 37
TC 0
Z9 0
U1 0
U2 1
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1361-3286
EI 2050-5728
J9 SPEECH LANG HEARING
JI Speech Lang. Hearing
PY 2019
VL 22
IS 2
BP 61
EP 70
DI 10.1080/2050571X.2017.1389338
PG 10
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA IC0UZ
UT WOS:000470676800002
DA 2021-02-24
ER

PT J
AU Bees, KL
   Guan, D
   Alsarrage, N
   Searchfield, GD
AF Bees, K. L.
   Guan, D.
   Alsarrage, N.
   Searchfield, G. D.
TI The effects of auditory object identification and localization (AOIL)
   training on noise acceptance and loudness discomfort in persons with
   normal hearing
SO SPEECH LANGUAGE AND HEARING
LA English
DT Article
DE Acceptable noise level; loudness discomfort level; auditory training;
   hearing
ID BACKGROUND-NOISE; SPEECH-PERCEPTION; EVOKED POTENTIALS; LEVEL;
   HYPERACUSIS; RELIABILITY
AB This study investigated the changes in Acceptable Noise Levels (ANLs) and Loudness Discomfort Levels (LDLs) after at home use of Auditory Object Identification and Localization auditory training (AOIL, [Searchfield, Morrison-Low, & Wise, 2007]. Object identification and attention training for treating tinnitus. Progress in Brain Research, 166, 441-460. doi:S0079-6123(07)66043-9 [pii]).
   Methods: A crossover design was used to compare LDLs and ANLs measured in 40 participants (16 male 24 female, average age 24, SD 2.5 years) with normal hearing, prior to and after 15 days of training and 15 days of no training (control). The auditory training consisted of identifying a mixture of environmental sounds or speech stimuli against various background noises from three different virtual locations (left, right, center). The participants listened to the training stimuli using Philips GoGear Vibe personal music players and recorded their responses on a training record sheet.
   Results: A significant training-specific decrease (improvement) in ANLs was found, but no change in LDLs was observed.
   Summary: The results indicate that the AOIL training program improved noise acceptance, but did not affect LDLs, in persons with normal hearing. The training task should be investigated for use as a therapeutic tool in persons with 'annoyance hyperacusis'.
C1 [Bees, K. L.; Guan, D.; Alsarrage, N.; Searchfield, G. D.] Univ Auckland, Eisdell Moore Ctr, Sect Audiol, Auckland, New Zealand.
RP Searchfield, GD (corresponding author), Univ Auckland, Private Bag 92019, Auckland, New Zealand.
EM g.searchfield@auckland.ac.nz
OI Searchfield, Grant/0000-0001-7303-2159
FU School of Population Health student research
FX The research was funded by School of Population Health student research
   [grant to KLB, DG & NA].
CR Andersson G, 2002, INT J AUDIOL, V41, P545, DOI 10.3109/14992020209056075
   Basner M, 2014, LANCET, V383, P1325, DOI 10.1016/S0140-6736(13)61613-X
   BEATTIE RC, 1979, J SPEECH HEAR DISORD, V44, P435, DOI 10.1044/jshd.4404.435
   BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   Brannstrom KJ, 2014, INT J AUDIOL, V53, P21, DOI 10.3109/14992027.2013.824116
   Brannstrom KJ, 2012, J AM ACAD AUDIOL, V23, P542, DOI 10.3766/jaaa.23.7.6
   Brannstroma KJ, 2017, AM J AUDIOL, V26, P80, DOI 10.1044/2016_AJA-16-0033
   CARHART R, 1959, J SPEECH HEAR DISORD, V24, P330, DOI 10.1044/jshd.2404.330
   Chermak Gail D., 2002, Seminars in Hearing, V23, P297, DOI 10.1055/s-2002-35878
   Filion P R, 1992, J Am Acad Audiol, V3, P193
   Freyaldenhoven MC, 2007, J SPEECH LANG HEAR R, V50, P878, DOI 10.1044/1092-4388(2007/062)
   Freyaldenhoven MC, 2006, J AM ACAD AUDIOL, V17, P640, DOI 10.3766/jaaa.17.9.3
   Freyaldenhoven Melinda C, 2005, J Am Acad Audiol, V16, P677, DOI 10.3766/jaaa.16.9.5
   Gordon-Hickey S, 2012, J AM ACAD AUDIOL, V23, P534, DOI 10.3766/jaaa.23.7.5
   Hill EM, 2014, NOISE HEALTH, V16, P47, DOI 10.4103/1463-1741.127855
   Hoare DJ, 2010, ANN BEHAV MED, V40, P313, DOI 10.1007/s12160-010-9213-5
   Katzenell U, 2001, OTOL NEUROTOL, V22, P321, DOI 10.1097/00129492-200105000-00009
   Mueller H Gustav, 2005, J Am Acad Audiol, V16, P461
   NABELEK AK, 1991, J SPEECH HEAR RES, V34, P679, DOI 10.1044/jshr.3403.679
   Nabelek AK, 2004, J SPEECH LANG HEAR R, V47, P1001, DOI 10.1044/1092-4388(2004/074)
   Nabelek AK, 2006, J AM ACAD AUDIOL, V17, P626, DOI 10.3766/jaaa.17.9.2
   Olsen SO, 2014, INT J AUDIOL, V53, P2, DOI 10.3109/14992027.2013.839887
   Paulin J, 2016, NOISE HEALTH, V18, P178, DOI 10.4103/1463-1741.189244
   Pienkowski M, 2014, AM J AUDIOL, V23, P420, DOI 10.1044/2014_AJA-13-0037
   Plyler P, 2015, AUDIOLOGY
   Rogers Deanna S, 2003, J Am Acad Audiol, V14, P372
   Searchfield GD, 2007, PROG BRAIN RES, V166, P441, DOI 10.1016/S0079-6123(07)66043-9
   Sheehan G, 2016, SPEECH LANG HEARING, V19, P180, DOI 10.1080/2050571X.2016.1182310
   Sweetow Robert, 2005, J Am Acad Audiol, V16, P494, DOI 10.3766/jaaa.16.7.9
   Tampas JW, 2006, J ACOUST SOC AM, V119, P1548, DOI 10.1121/1.2167147
   Teki S, 2011, J NEUROSCI, V31, P164, DOI 10.1523/JNEUROSCI.3788-10.2011
   Tyler RS, 2014, AM J AUDIOL, V23, P402, DOI 10.1044/2014_AJA-14-0010
   Wu YH, 2014, J AM ACAD AUDIOL, V25, P141, DOI 10.3766/jaaa.25.2.3
NR 34
TC 0
Z9 0
U1 0
U2 1
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1361-3286
EI 2050-5728
J9 SPEECH LANG HEARING
JI Speech Lang. Hearing
PY 2019
VL 22
IS 2
BP 71
EP 78
DI 10.1080/2050571X.2017.1386870
PG 8
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA IC0UZ
UT WOS:000470676800003
DA 2021-02-24
ER

PT J
AU Vaidyanath, R
   Yathiraj, A
AF Vaidyanath, Ramya
   Yathiraj, Asha
TI Influence of noise on the equivalence of word-lists in a phonemically
   balanced word test: comparison in young and older adults
SO HEARING BALANCE AND COMMUNICATION
LA English
DT Article
DE Speech perception in noise; ageing; multi-talker speech babble
ID SPEECH RECOGNITION; NORMAL-HEARING; QUIET; AGE; PERCEPTION;
   INTELLIGIBILITY; LISTENERS; SPOKEN
AB Purpose: The main purpose of the study was to determine the influence of noise on the equivalency of word-lists in a speech-in-noise test. Additionally, the performance of young and older adults was compared.
   Method: Thirty-four young adults with normal hearing, aged 18-36 years, were compared with 49 older adults, aged 55-75years having hearing sensitivity <= 20 dB HL till 2000 Hz. The young adults were evaluated using a speech-in-noise test having four word-lists that were equivalent in quiet, with half being tested in the right ear and half in the left ear. The older adults were tested with two of the lists, one in each ear.
   Results: In the presence of speech-babble, the younger adults obtained no significant difference between the two ears as well as between gender. Their scores on all four lists of the test were equivalent. In contrast, in the older adults the females performed significantly better than the males on one of the two lists that they were evaluated on, but no ear difference was observed. There was a significant difference between the lists in the older adults. Additionally, the older adults performed significantly poorer when compared to the younger group.
   Conclusions: In the presence of noise, the lists were found to be equivalent in the young adults but was not in the older adults. A gender difference was absent in the younger adults but was present in the older listeners. The performance of the older listeners was consistently poorer compared to that of the younger listeners.
C1 [Vaidyanath, Ramya] Sri Ramachandra Inst Higher Educ & Res, Dept Speech Language & Hearing Sci, Chennai, Tamil Nadu, India.
   [Yathiraj, Asha] All India Inst Speech & Hearing, Dept Audiol, Mysuru, India.
RP Vaidyanath, R (corresponding author), Sri Ramachandra Univ, Dept Speech Language & Hearing Sci, Med Coll, 1 Ramachandra Nagar, Chennai, Tamil Nadu, India.
EM ramyavaidyanath@sriramachandra.edu.in
RI Vaidyanath, Ramya/AAK-4424-2020
OI Vaidyanath, Ramya/0000-0003-4093-0424
CR American National Standards Institute, 1999, S311999 ANSI
   Amos NE, 2007, J SPEECH LANG HEAR R, V50, P819, DOI 10.1044/1092-4388(2007/057)
   Babu RM, 1972, JAIISH, V3, P7
   CHERMAK GD, 1988, AUDIOLOGY, V27, P324
   Crandell CC, 2000, LANG SPEECH HEAR SER, V31, P362, DOI 10.1044/0161-1461.3104.362
   DUBNO JR, 1984, J ACOUST SOC AM, V76, P87, DOI 10.1121/1.391011
   Dubno JR, 1997, J SPEECH LANG HEAR R, V40, P444, DOI 10.1044/jslhr.4002.444
   Frisina DR, 1997, HEARING RES, V106, P95, DOI 10.1016/S0378-5955(97)00006-3
   GELFAND SA, 1986, J ACOUST SOC AM, V80, P1589, DOI 10.1121/1.394323
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   Kilman L, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00651
   Kimura D, 1967, CORTEX, V3, P163, DOI [DOI 10.1016/S0010-9452(67)80010-8, 10.1016/s0010-9452(67)80010-8]
   KIRK KI, 1995, EAR HEARING, V16, P470, DOI 10.1097/00003446-199510000-00004
   LOVEN FC, 1983, EAR HEARING, V4, P91, DOI 10.1097/00003446-198303000-00005
   McArdle R, 2008, J AM ACAD AUDIOL, V19, P507, DOI 10.3766/jaaa.19.6.6
   McGinnis SM, 2011, BRAIN TOPOGR, V24, P279, DOI 10.1007/s10548-011-0198-6
   Mukari SZMS, 2008, AUDIOL NEURO-OTOL, V13, P328, DOI 10.1159/000128978
   PICHORAFULLER MK, 1995, J ACOUST SOC AM, V97, P593, DOI 10.1121/1.412282
   PROSSER S, 1991, ACTA OTO-LARYNGOL, P136
   Russo FA, 2008, EAR HEARING, V29, P746, DOI 10.1097/AUD.0b013e31817bdd1f
   Salvi RJ, 2002, HEARING RES, V170, P96, DOI 10.1016/S0378-5955(02)00386-6
   SHAYWITZ BA, 1995, NATURE, V373, P607, DOI 10.1038/373607a0
   SINGH S, 1966, J ACOUST SOC AM, V39, P372, DOI 10.1121/1.1909899
   Vaidyanath R, 2012, THESIS
   Wong PCM, 2010, EAR HEARING, V31, P471, DOI 10.1097/AUD.0b013e3181d709c2
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
   Yathiraj A., 2005, PHONEMICALLY BALANCE
NR 27
TC 0
Z9 0
U1 0
U2 0
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2169-5717
EI 2169-5725
J9 HEARING BALANC COMMU
JI Hearing Balanc. Commun.
PY 2019
VL 17
IS 1
BP 42
EP 50
DI 10.1080/21695717.2018.1552737
PG 9
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA IB4UD
UT WOS:000470266700006
DA 2021-02-24
ER

PT J
AU Nassar, AAM
   Elkabarity, RH
   Rahman, TTA
   Mohammed, RA
AF Nassar, Adel Abdel Maksoud
   Elkabarity, Rasha Hamdy
   Rahman, Tayseer Taha Abdel
   Mohammed, Rasha Abdullah
TI Performance of cochlear implant patients while using bimodal stimulation
   and FM system
SO HEARING BALANCE AND COMMUNICATION
LA English
DT Article
DE Bimodal CI; temporal processing; FM system; speech perception in noise
   test
ID USE HEARING-AIDS; SPEECH-PERCEPTION; ADULT USERS; RECOGNITION; CHILDREN;
   NOISE; BENEFITS; IDENTIFICATION; LOCALIZATION; RECIPIENTS
AB Objectives: To study the effectiveness of bimodal stimulation coupled to FM system on the speech discrimination in noise, temporal discrimination and temporal resolution in patients with unilateral cochlear implant.
   Method: A total number of 28 subjects were examined in this study, they were divided into group I (19 subjects) with pre-lingual hearing loss and group II (9 subjects) with post-lingual hearing loss. Both groups had a residual hearing in the non-implanted ear that permits benefit from amplification. Full history taking, Questionnaire, Aided warble tone response, Arabic monosyllabic word test in quiet and in presence of background noise, Pitch discrimination test, Pitch pattern sequence test and Auditory fusion test-subtest 3.
   Results: There is significant statistical difference in CI patients' performance in most of tests while using bimodal stimulation with FM system coupled to CI than with bimodal stimulation alone or CI alone condition.
   Conclusions: It is recommended to use hearing aid in non-implanted ear in order to improve speech discrimination in noise, temporal discrimination and temporal resolution abilities.
C1 [Nassar, Adel Abdel Maksoud; Elkabarity, Rasha Hamdy; Rahman, Tayseer Taha Abdel] Ain Shams Univ, Fac Med, ENT Dept, Cairo, Egypt.
   [Mohammed, Rasha Abdullah] Dept Audiovestibular Med, Aswan, Egypt.
RP Rahman, TTA (corresponding author), Villa 4-7 E, Cairo, Egypt.
EM tayseerhesham2005@gmail.com
CR Abdel Rahman T, 2017, EGYPTIAN J OTOLARYNG, V2017, P33535
   Abdel-Halim P, 2009, THESIS
   Abdeltawwab MM, 2016, ORL J OTO-RHINO-LARY, V78, P126, DOI 10.1159/000381024
   Anderson K, 2005, J ED AUDIOL, V12, P14
   Anderson KL, 2004, LANG SPEECH HEAR SER, V35, P169, DOI 10.1044/0161-1461(2004/017)
   Bartov T, 2014, J SPEECH LANG HEAR R, V57, P1929, DOI 10.1044/2014_JSLHR-H-13-0190
   Bernstein JGW, 2006, J ACOUST SOC AM, V120, P3929, DOI 10.1121/1.2372452
   Campos Patricia Danieli, 2008, Braz J Otorhinolaryngol, V74, P884, DOI 10.1016/S1808-8694(15)30149-X
   CAZALS Y, 1994, J ACOUST SOC AM, V96, P2048, DOI 10.1121/1.410146
   Ching Teresa Y. C., 2000, Australian and New Zealand Journal of Audiology, V22, P123
   Ching TYC, 2005, INT J AUDIOL, V44, P677, DOI 10.1080/00222930500271630
   Ching TYC, 2005, INT J AUDIOL, V44, P513, DOI 10.1080/14992020500190003
   Ching TYC, 2004, EAR HEARING, V25, P9, DOI 10.1097/01.AUD.0000111261.84611.C8
   COX RM, 1995, EAR HEARING, V16, P176, DOI 10.1097/00003446-199504000-00005
   Cusumano C, 2017, OTOL NEUROTOL, V38, P334, DOI 10.1097/MAO.0000000000001322
   Davies Merren G., 2001, Australian and New Zealand Journal of Audiology, V23, P52, DOI 10.1375/audi.23.1.52.31096
   De Ceulaer G, 2016, EUR ARCH OTO-RHINO-L, V273, P1107, DOI 10.1007/s00405-015-3643-4
   Dorman MF, 1998, J ACOUST SOC AM, V104, P3583, DOI 10.1121/1.423940
   Duarte M, 2016, BRAZ J OTORHINOLAR, V82, P304, DOI 10.1016/j.bjorl.2015.05.013
   Dunn CC, 2005, J SPEECH LANG HEAR R, V48, P668, DOI 10.1044/1092-4388(2005/046)
   Eisenberg LS, 2004, ARCH OTOLARYNGOL, V130, P563, DOI 10.1001/archotol.130.5.563
   Eiten Leisha R., 2010, Seminars in Hearing, V31, P233, DOI 10.1055/s-0030-1262328
   Fitzpatrick EM, 2010, TRENDS AMPLIF, V14, P199, DOI 10.1177/1084713810396511
   Frederigue N., 2006, THESIS
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P180, DOI 10.1007/s10162-005-5061-6
   Geers AE, 2004, ARCH OTOLARYNGOL, V130, P634, DOI 10.1001/archotol.130.5.634
   Gifford R. H., 2011, HEARING J, V64, P16, DOI DOI 10.1097/01.HJ.0000399149.53245.B1
   Gifford RH, 2007, J SPEECH LANG HEAR R, V50, P835, DOI 10.1044/1092-4388(2007/058)
   Gifford RH, 2010, J AM ACAD AUDIOL, V21, P441, DOI 10.3766/jaaa.21.7.3
   Hegarty A, 2013, COCHLEAR IMPLANTS IN, V14, pS35
   Helms J, 2004, ORL-J OTO-RHIN-LARYN, V66, P130, DOI 10.1159/000079332
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Bertachini ALL, 2015, CODAS, V27, P292, DOI 10.1590/2317-1782/20152014103
   Limb CJ, 2012, OTOLARYNG CLIN N AM, V45, P129, DOI 10.1016/j.otc.2011.08.021
   Litovsky RY, 2004, ARCH OTOLARYNGOL, V130, P648, DOI 10.1001/archotol.130.5.648
   Luntz M, 2005, ACTA OTO-LARYNGOL, V125, P863, DOI 10.1080/00016480510035395
   Luntz M, 2008, ACTA OTO-LARYNGOL, V128, P1322, DOI 10.1080/00016480801965027
   MCCROSKEY RL, 1980, J LEARN DISABIL, V13, P69, DOI 10.1177/002221948001300205
   Mok M, 2006, J SPEECH LANG HEAR R, V49, P338, DOI 10.1044/1092-4388(2006/027)
   Mok M, 2010, AUDIOL NEURO-OTOL, V15, P44, DOI 10.1159/000219487
   MOORE B C J, 1985, British Journal of Audiology, V19, P189
   MUCHNIK C, 1994, SCAND AUDIOL, V23, P105, DOI 10.3109/01050399409047493
   Musiek F., 1999, SCANDINAVIN AUDIOL, V51, P3346
   PINHEIRO ML, 1971, J ACOUST SOC AM, V49, P1778, DOI 10.1121/1.1912581
   Potts LG, 2009, J AM ACAD AUDIOL, V20, P353, DOI 10.3766/jaaa.20.6.4
   Qin MK, 2006, J ACOUST SOC AM, V119, P2417, DOI 10.1121/1.2178719
   Sagi E, 2009, J SPEECH LANG HEAR R, V52, P385, DOI [10.1044/1092-4388(2008/07-0219), 10.1044/1092-4388(2008/07-0219]
   Saki N, INT J PHARM RES ALLI, V5, P179
   Saphr A, 2007, EAR HEARING, V28, P260
   Schafer E, 2003, J ED AUDIOL, V11, P15
   Schafer EC, 2009, J ED AUDIOL, V15, P4
   Schafer Erin C, 2006, Am J Audiol, V15, P114, DOI 10.1044/1059-0889(2006/015)
   Schafer Erin C, 2004, J Am Acad Audiol, V15, P678, DOI 10.3766/jaaa.15.10.3
   Scorpecci A, 2016, OTOLARYNG HEAD NECK, V155, P1028, DOI 10.1177/0194599816661705
   Sobhy O, 2012, THESIS
   Soliman S, 1984, THESIS
   SOLIMAN S M, 1976, Ain Shams Medical Journal, V27, P27
   Thibodeau L, 2010, AM J AUDIOL, V19, P36, DOI 10.1044/1059-0889(2010/09-0014)
   Tyler RS, 2002, EAR HEARING, V23, P98, DOI 10.1097/00003446-200204000-00003
   Ullauri Alejandra, 2007, Cochlear Implants Int, V8, P29, DOI 10.1002/cii.328
   Wolfe J, 2013, EAR HEARING, V34, P52, DOI 10.1097/AUD.0b013e3182611982
   Wolfe J, 2009, J AM ACAD AUDIOL, V20, P409, DOI 10.3766/jaaa.20.7.3
   Zhang T, 2014, EAR HEARING, V35, P410, DOI 10.1097/AUD.0000000000000032
NR 63
TC 0
Z9 0
U1 0
U2 2
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2169-5717
EI 2169-5725
J9 HEARING BALANC COMMU
JI Hearing Balanc. Commun.
PY 2019
VL 17
IS 1
BP 51
EP 60
DI 10.1080/21695717.2018.1552738
PG 10
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA IB4UD
UT WOS:000470266700007
DA 2021-02-24
ER

PT J
AU Jain, S
   Nataraja, NP
AF Jain, Saransh
   Nataraja, Nuggehalli Puttareviyah
TI Effect of age and hearing loss on sentence perception in noise using
   temporal envelope and temporal fine structure cues
SO HEARING BALANCE AND COMMUNICATION
LA English
DT Article
DE Psychoacoustics; auditory processing; aging; signal processing; speech
   perception; auditory perception
ID SPEECH-PERCEPTION; FREQUENCY; MODULATION
AB Purpose: The perception of speech is affected by many physical, physiological and pathological factors related to the stimuli and the listener. Researchers have addressed the effect of each of these factors independently on the perception of speech. In everyday situations, these factors do not occur in isolation but they may occur simultaneously and affect the overall perception of speech. The information on the extent to which each of these factors affect the speech perception is seldom being investigated.
   Methods: The present study explored the role of temporal envelope and temporal fine structures in the perception of sentences in noise by normal hearing young & older adults; and young & older adults with hearing loss. The envelope and fine structures of the sentences were extracted based on Hilbert transformation using Matlab software. The effect of noise was estimated by processing the sentences in quiet and at 0 dB and -5 dB SNR. The sentences were also filtered using 4, 8, 16 and 32 frequency channels to assess the role of frequency filtering on speech perception.
   Results: The envelope was more important for speech perception in both quiet and noise. The perception of speech was inversely proportional to age, hearing loss and noise levels, whereas it was directly proportional to the number of frequency channels.
   Conclusion: These findings indicate that the temporal envelope is important for speech perception in noise. The research findings may help in designing new signal processing strategies for hearing aids and cochlear implants based on the envelope cues.
C1 [Jain, Saransh] JSS Res Fdn, Dept Audiol, Jagadguru Sri Shivarathreeswara JSS Inst Speech &, Mysuru, India.
   [Nataraja, Nuggehalli Puttareviyah] JSS Res Fdn, Jagadguru Sri Shivarathreeswara JSS Inst Speech &, Dept Speech & Hearing, Mysuru, India.
RP Jain, S (corresponding author), JSS Res Fdn, JSS Inst Speech & Hearing, Dept Audiol, MG Rd, Mysuru 04, Karnataka, India.
EM saranshavi@gmail.com
OI Jain, Saransh/0000-0003-0434-0785
CR Ananthakrishnan S, 2017, EAR HEARING, V38, pE256, DOI 10.1097/AUD.0000000000000432
   Apoux F, 2013, J ACOUST SOC AM, V134, P2205, DOI 10.1121/1.4816413
   Arehart KH, 2010, EAR HEARING, V31, P420, DOI 10.1097/AUD.0b013e3181d3d4f3
   Chen F, 2016, SPEECH COMMUN, V81, P120, DOI 10.1016/j.specom.2016.01.006
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Cooke M, 2006, J ACOUST SOC AM, V119, P1562, DOI 10.1121/1.2166600
   Delgutte B., 2000, CHIMERASOFTWARE RAR
   Eaves JM, 2011, J ACOUST SOC AM, V130, P501, DOI 10.1121/1.3592237
   Fogerty D, 2015, J ACOUST SOC AM, V138, pEL459, DOI 10.1121/1.4935079
   Fullgrabe C, 2013, AM J AUDIOL, V22, P313, DOI 10.1044/1059-0889(2013/12-0070)
   Geetha C, 2014, J HEAR SCI, V4, P18
   Ghitza O, 2001, J ACOUST SOC AM, V110, P1628, DOI 10.1121/1.1396325
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052
   Hillenbrand JM, 2005, J SPEECH LANG HEAR R, V48, P45, DOI 10.1044/1092-4388(2005/005)
   Holt LL, 2010, ATTEN PERCEPT PSYCHO, V72, P1218, DOI 10.3758/APP.72.5.1218
   Hopkins K, 2010, J ACOUST SOC AM, V127, P1595, DOI 10.1121/1.3293003
   Hopkins K, 2009, J ACOUST SOC AM, V125, P442, DOI 10.1121/1.3037233
   Howell Peter, 2008, J Hum Environ Syst, V11, P51
   JERGER J, 1975, ARCH OTOLARYNGOL, V101, P403
   Kale S, 2010, JARO-J ASSOC RES OTO, V11, P657, DOI 10.1007/s10162-010-0223-6
   Klatte M, 2010, NOISE HEALTH, V12, P270, DOI 10.4103/1463-1741.70506
   Leger AC, 2015, J ACOUST SOC AM, V137, P505, DOI 10.1121/1.4904540
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Moore BCJ, 2006, J ACOUST SOC AM, V119, P480, DOI 10.1121/1.2139070
   Moore BCJ, 2008, JARO-J ASSOC RES OTO, V9, P399, DOI 10.1007/s10162-008-0143-x
   Ng EHN, 2013, INT J AUDIOL, V52, P433, DOI 10.3109/14992027.2013.776181
   Nie KB, 2005, IEEE T BIO-MED ENG, V52, P64, DOI 10.1109/TBME.2004.839799
   Schneider Bruce A., 2001, Seminars in Hearing, V22, P227, DOI 10.1055/s-2001-15628
   Sek A, 2006, J ACOUST SOC AM, V119, P507, DOI 10.1121/1.2139631
   Shamma S, 2000, J ACOUST SOC AM, V107, P2631, DOI 10.1121/1.428649
   Sullivan Gail M, 2012, J Grad Med Educ, V4, P279, DOI 10.4300/JGME-D-12-00156.1
   Swaminathan J, 2016, J NEUROSCI, V36, P8250, DOI 10.1523/JNEUROSCI.4421-15.2016
   Teschner MJ, 2016, J NEUROSCI, V36, P2743, DOI 10.1523/JNEUROSCI.2079-15.2016
   The MathWorks Inc, 2017, BUTT FILT ORD CUT FR
   The MathWorks Inc, 2017, SIGN TO NOIS RAT MAT
   Xu L, 2003, J ACOUST SOC AM, V114, P3024, DOI 10.1121/1.1623786
NR 36
TC 0
Z9 0
U1 0
U2 2
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2169-5717
EI 2169-5725
J9 HEARING BALANC COMMU
JI Hearing Balanc. Commun.
PY 2019
VL 17
IS 1
BP 61
EP 68
DI 10.1080/21695717.2018.1552739
PG 8
WC Audiology & Speech-Language Pathology
SC Audiology & Speech-Language Pathology
GA IB4UD
UT WOS:000470266700008
DA 2021-02-24
ER

PT J
AU Baese-Berk, MM
   Morrill, TH
AF Baese-Berk, Melissa M.
   Morrill, Tuuli H.
TI Perceptual Consequences of Variability in Native and Non-Native Speech
SO PHONETICA
LA English
DT Article
ID ARTICULATION RATE; FOREIGN ACCENT; INTELLIGIBILITY; COMPREHENSIBILITY;
   ADAPTATION; SPEAKERS
AB Background/Aims: Native speakers often have a difficult time understanding non-native speech, and this challenge is frequently attributed to a more variable signal. While theories and models of general speech perception are grounded in issues of variability, they rarely consider non-native speech. Here, we ask how a specific type of variability (speaking rate) impacts two measures of perception for both native and non-native speech. Methods: In the present study, one group of listeners transcribed speech, providing a measure of intelligibility. A second group of listeners rated how fluent the speaker was, providing a measure of fluency. Results: The results show that variability in speaking rate correlates with a non-native speaker's intelligibility. However, perceived fluency measures are not predicted by this variability measure. Conclusions: These results, taken with studies of the range of variability in non-native speech, suggest that variability in non-native speech is not a monolithic construct. Current theories and models of perception can be enhanced by examining non-native speech and how variability in that speech impacts perception. (C) 2019 S. Karger AG, Basel
C1 [Baese-Berk, Melissa M.; Morrill, Tuuli H.] Univ Oregon, Dept Linguist, 161 Straub Hall,1290, Eugene, OR 97403 USA.
RP Baese-Berk, MM (corresponding author), Univ Oregon, Dept Linguist, 161 Straub Hall,1290, Eugene, OR 97403 USA.
EM mbaesebe@uoregon.edu
FU University of Oregon Faculty Research Award
FX This work was partially funded by a University of Oregon Faculty
   Research Award to M.M.B.-B.
CR Adank P, 2009, J EXP PSYCHOL HUMAN, V35, P520, DOI 10.1037/a0013552
   ANDERSONHSIEH J, 1992, LANG LEARN, V42, P529, DOI 10.1111/j.1467-1770.1992.tb01043.x
   Baese-Berk MM, 2015, J ACOUST SOC AM, V138, pEL223, DOI 10.1121/1.4929622
   Baese-Berk MM, 2013, J ACOUST SOC AM, V133, pEL174, DOI 10.1121/1.4789864
   Baker RE, 2011, J PHONETICS, V39, P1, DOI 10.1016/j.wocn.2010.10.006
   Bent T, 2003, J ACOUST SOC AM, V114, P1600, DOI 10.1121/1.1603234
   Bent T, 2016, J ACOUST SOC AM, V140, P3775, DOI 10.1121/1.4966677
   Best C., 1995, SPEECH PERCEPTION LI, P171
   BLUMSTEIN SE, 1981, COGNITION, V10, P25, DOI 10.1016/0010-0277(81)90021-4
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Bradlow Ann R, 2011, Proc Int Congr Phon Sci, P356
   COOPER FS, 1952, J ACOUST SOC AM, V24, P597, DOI 10.1121/1.1906940
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   Flipsen P, 2002, J SPEECH LANG HEAR R, V45, P100, DOI 10.1044/1092-4388(2002/008)
   Floccia C, 2006, J EXP PSYCHOL HUMAN, V32, P1276, DOI 10.1037/0096-1523.32.5.1276
   Guion SG, 2000, APPL PSYCHOLINGUIST, V21, P205, DOI 10.1017/S0142716400002034
   Johnson K, 2005, BLACKW HBK LINGUIST, P363, DOI 10.1002/9780470757024.ch15
   KLATT DH, 1979, J PHONETICS, V7, P279, DOI 10.1016/S0095-4470(19)31059-9
   Kraljic T, 2008, PSYCHOL SCI, V19, P332, DOI 10.1111/j.1467-9280.2008.02090.x
   LANE H, 1963, J ACOUST SOC AM, V35, P451, DOI 10.1121/1.1918501
   Laturnus R., 2018, THESIS
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   McLaughlin DJ, 2018, ATTEN PERCEPT PSYCHO, V80, P1559, DOI 10.3758/s13414-018-1537-4
   Mennen I., 2015, PROSODY LANGUAGE CON, P171, DOI [10.1007/978-3-662-45168-7_9, DOI 10.1007/978-3-662-45168-7_9]
   MILLER JL, 1984, PHONETICA, V41, P215, DOI 10.1159/000261728
   Morrill T, 2016, P INT C SPEECH PROS, V2016, P1119
   MUNRO MJ, 1995, LANG LEARN, V45, P73, DOI 10.1111/j.1467-1770.1995.tb00963.x
   Munro MJ, 1995, LANG SPEECH, V38, P289, DOI 10.1177/002383099503800305
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   R Core Team, 2015, R LANG ENV STAT COMP
   Romero-Rivas C, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3389/fnhum.7015.00167, 10.3389/fnhum.2015.00167]
   ROSS AD, 1981, MASS AGR EXP ST RE B, P1
   Sidaras SK, 2009, J ACOUST SOC AM, V125, P3306, DOI 10.1121/1.3101452
   Van Engen KJ, 2010, LANG SPEECH, V53, P510, DOI 10.1177/0023830910372495
   van Wijngaarden SJ, 2001, SPEECH COMMUN, V35, P103, DOI 10.1016/S0167-6393(00)00098-4
   Vaughn C, 2019, PHONETICA, V76, P327, DOI 10.1159/000487269
   Wade T, 2007, PHONETICA, V64, P122, DOI 10.1159/000107913
   Witteman MJ, 2014, PSYCHON B REV, V21, P512, DOI 10.3758/s13423-013-0519-8
   YARUSS JS, 1995, J FLUENCY DISORD, V20, P257, DOI 10.1016/0094-730X(94)00013-J
NR 42
TC 0
Z9 0
U1 0
U2 2
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 0031-8388
EI 1423-0321
J9 PHONETICA
JI Phonetica
PY 2019
VL 76
IS 2-3
BP 126
EP 141
DI 10.1159/000493981
PG 16
WC Acoustics; Audiology & Speech-Language Pathology; Linguistics; Language
   & Linguistics
SC Acoustics; Audiology & Speech-Language Pathology; Linguistics
GA HZ6CZ
UT WOS:000468940900003
PM 31112963
DA 2021-02-24
ER

PT J
AU Evans, BG
   Lourido, GT
AF Evans, Bronwen G.
   Lourido, Gisela Tome
TI Effects of Language Background on the Development of Sociolinguistic
   Awareness: The Perception of Accent Variation in Monolingual and
   Multilingual 5-to 7-Year-Old Children
SO PHONETICA
LA English
DT Article
ID SPEECH-PERCEPTION; PHONOLOGICAL AWARENESS; VOWEL PERCEPTION;
   ACQUISITION; COMPREHENSION; ADAPTATION; DIVERSITY; COMMUNITY; CONTACT;
   NOISE
AB As a result of complex international migration patterns, listeners in large urban centres such as London, UK, likely encounter large amounts of variation in spoken language. However, although dealing with variation is crucial to communication, relatively little is known about how the ability to do this develops. Still less is known about how this might be affected by language background. The current study investigates whether early experience with variation, specifically growing up bilingually in London, affects accent categorization. Sixty children (30 monolingual, 30 bilingual) aged 5-7 years, were tested in their ability to comprehend and categorize talkers in 2 out of 3 accents: a home, unfamiliar regional and unfamiliar foreign-accented variety. All children demonstrated high, above-chance performance in the comprehension task, but language background significantly affected the children's ability to categorize talkers. Bilinguals were able to categorize talkers in all accent conditions, but although all children were able to understand the talkers, monolingual children were only able to categorize talkers in the home-foreign accent condition. Overall, the results are consistent with an approach in which gradient representations of accent variation emerge alongside an understanding of how variation is used meaningfully within a child's environment. (C) 2019 S. Karger AG, Basel
C1 [Evans, Bronwen G.; Lourido, Gisela Tome] UCL, Dept Speech Hearing & Phonet Sci, Chandler House,2 Wakefield St, London WC1N 1PF, England.
   [Lourido, Gisela Tome] Univ Leeds, Sch Languages Cultures & Soc, Leeds, W Yorkshire, England.
RP Evans, BG (corresponding author), UCL, Dept Speech Hearing & Phonet Sci, Chandler House,2 Wakefield St, London WC1N 1PF, England.
EM bronwen.evans@ucl.ac.uk
OI Tome Lourido, Gisela/0000-0002-3456-7334
CR Adank P, 2009, J EXP PSYCHOL HUMAN, V35, P520, DOI 10.1037/a0013552
   Ahlberg A, 1980, MRS PLUG PLUMBER
   Bao Z, 1998, ENGLISH NEW CULTURAL, P127
   Bayard D., 2001, J SOCIOLING, V5, P22, DOI [10.1111/1467-9481.00136, DOI 10.1111/1467-9481.00136]
   Beck E, 2016, AWARENESS CONTROL SO, P104, DOI [10.1017/CBO9781139680448.007, DOI 10.1017/CBO9781139680448.007]
   Beckman ME, 2007, LAB PHONOLOGY, P241
   Benjamin Munson, 2010, LAB PHONOLOGY, V1, P157, DOI DOI 10.1515/LABPHON.2010.008
   Bent T, 2015, J ACOUST SOC AM, V138, P3985, DOI 10.1121/1.4938228
   Bent T, 2014, J CHILD LANG, V41, P1334, DOI 10.1017/S0305000913000457
   Best CT, 2009, PSYCHOL SCI, V20, P539, DOI 10.1111/j.1467-9280.2009.02327.x
   BIALYSTOK E, 1986, CHILD DEV, V57, P498, DOI 10.1111/j.1467-8624.1986.tb00048.x
   Bialystok E, 2003, APPL PSYCHOLINGUIST, V24, P27, DOI 10.1017/S014271640300002X
   Boersma P., 2018, PRAAT DOING PHONETIC
   CAMPBELL R, 1995, BRIT J DEV PSYCHOL, V13, P61, DOI 10.1111/j.2044-835X.1995.tb00664.x
   Campbell-Kibler K. C, 2016, AWARENESS CONTROL SO, P123, DOI [10.1017/CBO9781139680448.008, DOI 10.1017/CBO9781139680448.008]
   Cheshire J, 2011, J SOCIOLING, V15, P151, DOI 10.1111/j.1467-9841.2011.00478.x
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Clopper CG, 2008, LANG SPEECH, V51, P175, DOI 10.1177/0023830908098539
   Darcy I, 2012, J PHONETICS, V40, P568, DOI 10.1016/j.wocn.2012.05.001
   Deterding David, 2005, ENGL WORLD-WIDE, V26, P179, DOI DOI 10.1075/EWW.26.2.04DET
   Docherty GJ, 2014, LINGUA, V142, P42, DOI 10.1016/j.lingua.2013.01.011
   Donaldson J., 2001, GRUFFALOS CHILD
   DONALDSON W, 1992, J EXP PSYCHOL GEN, V121, P275, DOI 10.1037/0096-3445.121.3.275
   Dunn D.M., 2009, BRIT PICTURE VOCABUL
   Evans BG, 2007, J ACOUST SOC AM, V121, P3814, DOI 10.1121/1.2722209
   Floccia C, 2006, J EXP PSYCHOL HUMAN, V32, P1276, DOI 10.1037/0096-1523.32.5.1276
   Floccia C, 2009, INT J BEHAV DEV, V33, P366, DOI 10.1177/0165025409103871
   Foulkes P, 2006, J PHONETICS, V34, P409, DOI 10.1016/j.wocn.2005.08.002
   Girard F, 2008, BRIT J DEV PSYCHOL, V26, P409, DOI 10.1348/026151007X251712
   Goldinger Stephen D., 1997, TALKER VARIABILITY S, P33
   GRIER JB, 1971, PSYCHOL BULL, V75, P424, DOI 10.1037/h0031246
   Grosjean F., 1998, BILING-LANG COGN, V1, P131, DOI DOI 10.1017/S136672899800025X
   Hawkins S, 2003, J PHONETICS, V31, P373, DOI 10.1016/j.wocn.2003.09.006
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Iverson P, 2009, J ACOUST SOC AM, V126, P866, DOI 10.1121/1.3148196
   Jeffries E, 2016, THESIS
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Jones Z, 2017, J PHONETICS, V60, P20, DOI 10.1016/j.wocn.2016.11.001
   Kinzler KD, 2013, Q J EXP PSYCHOL, V66, P1146, DOI 10.1080/17470218.2012.731695
   Kovacs AM, 2009, P NATL ACAD SCI USA, V106, P6556, DOI 10.1073/pnas.0811323106
   KUHL PK, 2006, DEVELOPMENTAL SCI, V9, pF1, DOI DOI 10.1111/J.1467-7687.2006.00468.X
   Kuperman V, 2012, BEHAV RES METHODS, V44, P978, DOI 10.3758/s13428-012-0210-4
   Labov W, 1964, SOCIAL DIALECTS LANG, P77
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Lim Lisa, 2004, SINGAPORE ENGLISH GR, DOI [10.1075/veaw.g33, DOI 10.1075/VEAW.G33]
   Maye J, 2008, COGNITIVE SCI, V32, P543, DOI 10.1080/03640210802035357
   Mayr R, 2015, J CHILD LANG, V42, P146, DOI 10.1017/S0305000913000603
   McCarthy KM, 2013, J PHONETICS, V41, P344, DOI 10.1016/j.wocn.2013.03.006
   McCarthy KM, 2014, CHILD DEV, V85, P1965, DOI 10.1111/cdev.12275
   Nathan L, 1998, J CHILD LANG, V25, P343, DOI 10.1017/S0305000998003444
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Office for National Statistics, 2016, 2011 CENS AGGR DAT
   Pierrehumbert J. B, 2003, CHIC LING SOC CHIC A
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   Pinet M, 2015, P INT C PHON SCI GLA
   Preston Dennis, 1989, PERCEPTUAL DIALECTOL, DOI [10.1515/9783110871913, DOI 10.1515/9783110871913]
   R Core Team, 2018, R LANG ENV STAT COMP
   Rattanasone NX, 2014, BILING-LANG COGN, V17, P646, DOI 10.1017/S1366728913000618
   Sarah Hawkins, 2001, ITALIAN J LINGUISTIC, V13, P99
   SCOTT DR, 1984, J VERB LEARN VERB BE, V23, P450, DOI 10.1016/S0022-5371(84)90291-3
   Seidl A, 2012, FRONT PSYCHOL, V3, DOI [10.3389/fpsyg.2012.00448, 10.3389/fpsyg.2012.00479]
   Shaw JA, 2018, LAB PHONOL, V9, DOI 10.5334/labphon.87
   Strand EA, 1999, J LANG SOC PSYCHOL, V18, P86, DOI 10.1177/0261927X99018001006
   Sundara M, 2011, J PHONETICS, V39, P505, DOI 10.1016/j.wocn.2010.08.006
   Trudgill P, 2002, INT ENGLISH GUIDE VA, P136
   Vertovec S, 2007, ETHNIC RACIAL STUD, V30, P1024, DOI 10.1080/01419870701599465
   Wagner L, 2014, J CHILD LANG, V41, P1062, DOI 10.1017/S0305000913000330
   Weatherhead D, 2016, J EXP CHILD PSYCHOL, V143, P171, DOI 10.1016/j.jecp.2015.10.011
   Wells John C., 1982, ACCENTS ENGLISH, DOI [10.1017/CBO9780511611759, DOI 10.1017/CBO9780511611759]
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   YELLAND GW, 1993, APPL PSYCHOLINGUIST, V14, P423, DOI 10.1017/S0142716400010687
NR 72
TC 0
Z9 0
U1 0
U2 3
PU KARGER
PI BASEL
PA ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND
SN 0031-8388
EI 1423-0321
J9 PHONETICA
JI Phonetica
PY 2019
VL 76
IS 2-3
BP 142
EP 162
DI 10.1159/000493983
PG 21
WC Acoustics; Audiology & Speech-Language Pathology; Linguistics; Language
   & Linguistics
SC Acoustics; Audiology & Speech-Language Pathology; Linguistics
GA HZ6CZ
UT WOS:000468940900004
PM 31112959
OA Green Published
DA 2021-02-24
ER

PT J
AU Yamamoto, K
   Irino, T
   Matsui, T
   Araki, S
   Kinoshita, K
   Nakatani, T
AF Yamamoto, Katsuhiko
   Irino, Toshio
   Matsui, Toshie
   Araki, Shoko
   Kinoshita, Keisuke
   Nakatani, Tomohiro
TI Speech intelligibility prediction with the dynamic compressive
   gammachirp filterbank and modulation power spectrum
SO ACOUSTICAL SCIENCE AND TECHNOLOGY
LA English
DT Article
DE Speech intelligibility; Auditory model; Objective measure; Speech
   enhancement
ID AUDITORY FILTER; DOMAIN; MODEL
AB The speech-based envelope power spectrum model (sEPSM) was developed to predict the speech intelligibility of sounds produced by nonlinear speech enhancement algorithms such as spectral subtraction. It is a linear model with a linear, level-independent gammatone (GT) filterbank as the front-end. Therefore, it seems difficult to evaluate speech sounds with low and high sound pressure levels (SPLs) consistently because the intelligibility of the speech is dependent on the SPL as well as the signal-to-noise ratio. In this study, the sEPSM was extended with the dynamic compressive gammachirp (dcGC) auditory filterbank and a "common" normalization factor of the modulation power spectrum component to improve the predictability of the model. For evaluating the proposed model, we performed subjective experiments on the intelligibility of speech sounds enhanced by spectral subtraction and a Wiener filter algorithm. We compared the subjective speech intelligibility scores with the objective scores predicted by the proposed dcGC-sEPSM, original GT-sEPSM, and other well-known conventional methods such as the short-time objective intelligibility measure (STOI), coherence speech intelligibility index (CSII), and hearing aid speech perception index (HASPI). The result shows that the proposed dcGC-sEPSM predicted the subjective results better did than the other methods.
C1 [Yamamoto, Katsuhiko; Irino, Toshio] Wakayama Univ, Grad Sch Syst Engn, Sakaedani 930, Wakayama 6408510, Japan.
   [Matsui, Toshie] Toyohashi Univ Technol, Grad Sch Engn, 1-1,Hibarigaoka,Tempaku Cho, Toyohashi, Aichi 4418580, Japan.
   [Araki, Shoko; Kinoshita, Keisuke; Nakatani, Tomohiro] NTT Commun Sci Labs, 2-4 Hikaridai,Seika Cho, Kyoto 6190237, Japan.
RP Yamamoto, K (corresponding author), Wakayama Univ, Grad Sch Syst Engn, Sakaedani 930, Wakayama 6408510, Japan.
EM yamamoto.katsuhiko@g.wakayama-u.jp; irino@sys.wakayama-u.ac.jp;
   tmatsui@cs.tut.ac.jp; araki.shoko@lab.ntt.co.jp;
   kinoshita.k@lab.ntt.co.jp; nakatani.tomohiro@lab.ntt.co.jp
OI Yamamoto, Katsuhio/0000-0002-3104-1409; Araki, Shoko/0000-0003-4363-4305
FU JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [JP25280063,
   JP16H01734, JP17J04227]
FX This research was partially supported by JSPS KAKENHI Grant Numbers
   JP25280063, JP16H01734, and JP17J04227.
CR Berouti M., 1979, ICASSP 79. 1979 IEEE International Conference on Acoustics, Speech and Signal Processing, P208
   BLAND JM, 1986, LANCET, V1, P307, DOI 10.1016/s0140-6736(86)90837-8
   Chabot-Leclerc A, 2014, J ACOUST SOC AM, V135, P3502, DOI 10.1121/1.4873517
   Elhilali M, 2003, SPEECH COMMUN, V41, P331, DOI 10.1016/S0167-6393(02)00134-6
   Falk TH, 2015, IEEE SIGNAL PROC MAG, V32, P114, DOI 10.1109/MSP.2014.2358871
   Fujimoto M., 2009, P INT 2009, P1235
   Fujimoto M, 2012, INT CONF ACOUST SPEE, P4713, DOI 10.1109/ICASSP.2012.6288971
   Giavarina D, 2015, BIOCHEM MEDICA, V25, P141, DOI 10.11613/BM.2015.015
   Green D. M., 1964, SIGNAL DETECT RECOG, P609
   Humes LE, 2002, J ACOUST SOC AM, V112, P1112, DOI 10.1121/1.1499132
   Irino T, 2001, J ACOUST SOC AM, V109, P2008, DOI 10.1121/1.1367253
   Irino T, 1997, J ACOUST SOC AM, V101, P412, DOI 10.1121/1.417975
   Irino T, 2006, IEEE T AUDIO SPEECH, V14, P2222, DOI 10.1109/TASL.2006.874669
   Jorgensen S, 2011, J ACOUST SOC AM, V130, P1475, DOI 10.1121/1.3621502
   Kates JM, 2014, SPEECH COMMUN, V65, P75, DOI 10.1016/j.specom.2014.06.002
   Kates JM, 2005, J ACOUST SOC AM, V117, P2224, DOI 10.1121/1.1862575
   Kondo K., 2007, NTT TOHOKU U FAMILIA
   Loizou P. C., 2013, SPEECH ENHANCEMENT T
   Lyon RF, 2011, J ACOUST SOC AM, V130, P3893, DOI 10.1121/1.3658470
   Matsui T., 2016, J ACOUST SOC AM, V140, P3274, DOI 10.1121/1.4970396
   Moore B. C. J., 2013, INTRO PSYCHOL HEARIN
   Patterson RD, 2003, J ACOUST SOC AM, V114, P1529, DOI 10.1121/1.1600720
   Sakamoto S., 2004, Acoustical Science and Technology, V25, P290, DOI 10.1250/ast.25.290
   Smaragdis P, 2017, INT CONF ACOUST SPEE, P86, DOI 10.1109/ICASSP.2017.7952123
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881
   Weninger F, 2014, INTERSPEECH, P865
   Yamamoto K, 2016, INTERSPEECH, P2885, DOI 10.21437/Interspeech.2016-652
NR 27
TC 2
Z9 2
U1 0
U2 1
PU ACOUSTICAL SOC JAPAN
PI TOKYO
PA NAKAURA 5TH-BLDG. 2F, 2-18-20 SOTOKANDA, CHIYODA-KU, TOKYO, 101-0021,
   JAPAN
SN 1346-3969
EI 1347-5177
J9 ACOUST SCI TECHNOL
JI Acoust. Sci. Technol.
PY 2019
VL 40
IS 2
BP 84
EP 92
DI 10.1250/ast.40.84
PG 9
WC Acoustics
SC Acoustics
GA HV3GP
UT WOS:000465877400002
OA Bronze
DA 2021-02-24
ER

PT J
AU Hui, CTJ
   Arai, T
AF Hui, C. T. Justine
   Arai, Takayuki
TI Elderly listeners' identification of Japanese long vowel pair 'obasan'
   and 'obaasan' using pitch and duration
SO ACOUSTICAL SCIENCE AND TECHNOLOGY
LA English
DT Article
DE Japanese long vowels; Pitch perception; Speech perception; Ageing
ID CATEGORICAL PERCEPTION; LENGTH CONTRASTS; AGE; DISCRIMINATION; YOUNG;
   RECOGNITION; TRAIL
AB Japanese has long and short vowel distinction. While duration is the primary cue for listeners, pitch is being used as the secondary cue when duration becomes ambiguous. Duration however is affected by phonetic environment and therefore pitch cues may be more important in daily conversations. At the same time, ageing is known to affect speech recognition, in particular, pitch contour discrimination, such as tones. The current study compared a group of 15 young listeners with 14 elderly listeners using the words 'obasan (aunt)' and 'obaasan (grandmother),' manipulated in six steps duration-wise and pitch-wise. We found elderly listeners to use pitch more than the young listeners at the duration extremes, suggesting a generational effect on acceptability in accents (or lack of). At the same time, we observed half the elderly listeners to be less sensitive to pitch when duration becomes unreliable, depending on their fundamental frequency difference limens. The more sensitive elderly listeners, who performed similarly to the younger participants, significantly differed in their perception results from the less sensitive elderly listeners. This suggests that pitch deficits are present in half of the near-normal hearing elderly group, contributing to their inability to use pitch cues as well as their younger counterpart.
C1 [Hui, C. T. Justine; Arai, Takayuki] Sophia Univ, Grad Sch Sci & Technol, Chiyoda Ku, 7-1 Kioi Cho, Tokyo 1028554, Japan.
RP Hui, CTJ (corresponding author), Sophia Univ, Grad Sch Sci & Technol, Chiyoda Ku, 7-1 Kioi Cho, Tokyo 1028554, Japan.
EM justinehui@eagle.sophia.ac.jp
OI Hui, Justine/0000-0003-1411-8328
CR Adank P, 2010, PSYCHOL AGING, V25, P736, DOI 10.1037/a0020054
   Arehart KH, 2011, J SPEECH LANG HEAR R, V54, P190, DOI 10.1044/1092-4388(2010/09-0145)
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boersma Paul, 2016, PRAAT DOING PHONETIC
   Brunelle M, 2009, J PHONETICS, V37, P79, DOI 10.1016/j.wocn.2008.09.003
   Clinard CG, 2010, HEARING RES, V264, P48, DOI 10.1016/j.heares.2009.11.010
   Deguchi M., 2015, P 6 PRON 2 LANG LEAR, P174
   Ellis RJ, 2016, EAR HEARING, V37, P73, DOI 10.1097/AUD.0000000000000218
   Fitzgibbons PJ, 1995, J ACOUST SOC AM, V98, P3140, DOI 10.1121/1.413803
   Fogerty D, 2012, J ACOUST SOC AM, V132, P1667, DOI 10.1121/1.4739463
   Gordon-Salant S, 2006, J ACOUST SOC AM, V119, P2455, DOI 10.1121/1.2171527
   Gordon-Salant S, 2005, J REHABIL RES DEV, V42, P9, DOI 10.1682/JRRD.2005.01.0006
   GORDONSALANT S, 1986, J ACOUST SOC AM, V80, P1599, DOI 10.1121/1.394324
   Hashimoto R, 2006, PSYCHIAT CLIN NEUROS, V60, P422, DOI 10.1111/j.1440-1819.2006.01526.x
   Hirata Y, 2004, J PHONETICS, V32, P565, DOI 10.1016/j.wocn.2004.02.004
   Hui C. T. J., 2017, P AUT M AC SOC JPN, P1465
   John Fox, 2003, J STAT SOFTW, V8, P1, DOI DOI 10.18637/JSS.V008.I15
   Kinoshita K., 2002, P 7 INT C SPOK LANG, P757
   Lee Hyang-Ran, 2018, [Journal of Japanese Culture, 日本文化學報], V76, P343, DOI 10.21481/jbunka..76.201802.343
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Maekawa K., 1996, ACOUST SOC JPN J, V52, P552
   Minagawa Y., 2003, ICPHS, P2127
   MOORE BCJ, 1992, J ACOUST SOC AM, V91, P2881, DOI 10.1121/1.402925
   Nakaichi T., 2003, Acoustical Science and Technology, V24, P365, DOI 10.1050/ast.24.365
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Reitan RM, 1955, J CONSULT PSYCHOL, V19, P393, DOI 10.1037/h0044509
   Soranzo A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00712
   Tajima K, 2008, J ACOUST SOC AM, V123, P397, DOI 10.1121/1.2804942
   Takano S., 2017, ASIA PAC LANG VAR, V3, P5
   Takiguchi I., 2011, 17 INT C PHON SCI IC, P1950
   Tao L, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00266
   Tsukada K, 2012, SECOND LANG RES, V28, P151, DOI 10.1177/0267658311435870
   Wang YX, 2017, J SPEECH LANG HEAR R, V60, P3667, DOI 10.1044/2017_JSLHR-H-17-0061
   Wang YX, 2017, AM J AUDIOL, V26, P18, DOI 10.1044/2016_AJA-16-0020
NR 34
TC 2
Z9 2
U1 0
U2 0
PU ACOUSTICAL SOC JAPAN
PI TOKYO
PA NAKAURA 5TH-BLDG. 2F, 2-18-20 SOTOKANDA, CHIYODA-KU, TOKYO, 101-0021,
   JAPAN
SN 1346-3969
EI 1347-5177
J9 ACOUST SCI TECHNOL
JI Acoust. Sci. Technol.
PY 2019
VL 40
IS 2
BP 105
EP 115
DI 10.1250/ast.40.105
PG 11
WC Acoustics
SC Acoustics
GA HV3GP
UT WOS:000465877400004
OA Bronze
DA 2021-02-24
ER

PT J
AU Runnion, E
   Gray, S
AF Runnion, Elizabeth
   Gray, Shelley
TI What Clinicians Need to Know About Early Literacy Development in
   Children With Hearing Loss
SO LANGUAGE SPEECH AND HEARING SERVICES IN SCHOOLS
LA English
DT Article
ID PHONOLOGICAL PROCESSING ABILITIES; ENGLISH-SPEAKING CHILDREN; EMERGENT
   LITERACY; PRESCHOOL-CHILDREN; YOUNG-CHILDREN; LANGUAGE-DEVELOPMENT;
   COCHLEAR IMPLANTS; SPEECH-PERCEPTION; READING-COMPREHENSION; 5-YEAR-OLD
   CHILDREN
AB Purpose: Children with hearing loss may not reach the same level of reading proficiency as their peers with typical development. Audiologists and speech-language pathologists (SLPs) have important roles to play in preventing this problem early in children's development. In this tutorial, we aim to communicate how the habilitation practices of audiologists and intervention services of SLPs can support early literacy skill development in children with hearing loss.
   Method: We describe key findings from peer-reviewed research articles to provide a review of early literacy skill development, to explain the relationship between early literacy skills and conventional reading skills, and to highlight findings from early literacy skill intervention studies that included children with hearing loss who use spoken language. We conclude with a hypothetical case study to illustrate how audiologists and SLPs can support early literacy acquisition in children with hearing loss.
   Conclusion: Findings from studies of young children with hearing loss suggest that a promising approach to improving reading outcomes is to provide explicit early literacy instruction and intervention.
C1 [Runnion, Elizabeth; Gray, Shelley] Arizona State Univ, Dept Speech & Hearing Sci, Coll Hlth Solut, Tempe, AZ 85287 USA.
RP Runnion, E (corresponding author), Arizona State Univ, Dept Speech & Hearing Sci, Coll Hlth Solut, Tempe, AZ 85287 USA.
EM erunnion@asu.edu
CR Ambrose SE, 2012, J SPEECH LANG HEAR R, V55, P811, DOI 10.1044/1092-4388(2011/11-0086)
   American Academy of Audiology, 2011, AM AC AUD CLIN PRACT
   American Academy of Audiology, 2013, AM AC AUD CLIN PRACT
   American National Standards Institute, 1997, S351997 ANSI
   American National Standards Institute, 2013, S3462013 ANSI
   Anthony JL, 2002, J EXP CHILD PSYCHOL, V82, P65, DOI 10.1006/jecp.2002.2677
   Archbold S, 2008, INT J PEDIATR OTORHI, V72, P1471, DOI 10.1016/j.ijporl.2008.06.016
   Bagatto Marlene, 2005, Trends Amplif, V9, P199, DOI 10.1177/108471380500900404
   Bagatto M, 2010, INT J AUDIOL, V49, pS70, DOI 10.3109/14992020903080751
   Beach S., 1992, READING PSYCHOL, V13, P309
   Beck I. L., 2013, MAKING SENSE PHONICS
   Benitez-Barrera CR, 2018, J SPEECH LANG HEAR R, V61, P399, DOI 10.1044/2017_JSLHR-H-17-0168
   Bergeron JP, 2009, VOLTA REV, V109, P87
   Bowles RP, 2014, J PSYCHOEDUC ASSESS, V32, P146, DOI 10.1177/0734282913490266
   Brownell R., 2000, EXPRESSIVE ONE WORD
   Bus AG, 1997, J SCHOOL PSYCHOL, V35, P47, DOI 10.1016/S0022-4405(96)00030-1
   Cain K., 2018, REMEDIAL SPECIAL ED
   Cain K, 2014, ANN PSYCHOL, V114, P647
   Catts HW, 2015, READ WRIT, V28, P1407, DOI 10.1007/s11145-015-9576-x
   Ching TYC, 2007, J AM ACAD AUDIOL, V18, P220, DOI 10.3766/jaaa.18.3.4
   Ching TYC, 2017, PEDIATRICS, V140, DOI 10.1542/peds.2016-4274
   Ching TYC, 2013, INT J AUDIOL, V52, pS17, DOI 10.3109/14992027.2012.705903
   Ching TYC, 2013, EAR HEARING, V34, P535, DOI 10.1097/AUD.0b013e3182857718
   Connor CM, 2006, J EDUC PSYCHOL, V98, P665, DOI 10.1037/0022-0663.98.4.665
   Connor CM, 2004, J SPEECH LANG HEAR R, V47, P509, DOI 10.1044/1092-4388(2004/040)
   Cupples L, 2014, READ RES QUART, V49, P85, DOI 10.1002/rrq.60
   Davidson Lisa S, 2014, Cochlear Implants Int, V15, P211, DOI 10.1179/1754762813Y.0000000051
   DesJardin JL, 2017, EAR HEARING, V38, P441, DOI 10.1097/AUD.0000000000000414
   DesJardin JL, 2014, COMMUN DISORD Q, V35, P167, DOI 10.1177/1525740113518062
   Dillon CM, 2012, J DEAF STUD DEAF EDU, V17, P205, DOI 10.1093/deafed/enr043
   DILLON H, 1999, HEARING J, V52, P10
   Drouin M, 2012, EARLY CHILD RES Q, V27, P543, DOI 10.1016/j.ecresq.2011.12.008
   Dunn CC, 2014, EAR HEARING, V35, P148, DOI 10.1097/AUD.0b013e3182a4a8f0
   Dunn L. M., 1997, PEABODY PICTURE VOCA
   Easterbrooks SR, 2012, AM ANN DEAF, V157, P27, DOI 10.1353/aad.2012.1611
   Easterbrooks SR, 2008, VOLTA REV, V108, P91
   Eisenberg LS, 2016, OTOL NEUROTOL, V37, pE75, DOI 10.1097/MAO.0000000000000910
   FOX B, 1975, J PSYCHOLINGUIST RES, V4, P331, DOI 10.1007/BF01067062
   Fung PC, 2005, J DEAF STUD DEAF EDU, V10, P82, DOI 10.1093/deafed/eni005
   Geers AE, 2003, EAR HEARING, V24, p59S, DOI 10.1097/01.AUD.0000051690.43989.5D
   Geers Ann E, 2011, Ear Hear, V32, p49S, DOI 10.1097/AUD.0b013e3181fa41fa
   GELNETT D, 1995, ANN M AM AC AUD DALL
   Gilliver M, 2016, J DEAF STUD DEAF EDU, V21, P268, DOI 10.1093/deafed/enw004
   Goldberg HR, 2015, READ WRIT, V28, P509, DOI 10.1007/s11145-014-9535-y
   Guo LY, 2017, J SPEECH LANG HEAR R, V60, P1062, DOI 10.1044/2016_JSLHR-H-16-0182
   Guo LY, 2013, J DEAF STUD DEAF EDU, V18, P187, DOI 10.1093/deafed/ens069
   Hadley PA, 1998, LANG SPEECH HEAR SER, V29, P132, DOI 10.1044/0161-1461.2903.132
   Holte L, 2012, AM J AUDIOL, V21, P163, DOI 10.1044/1059-0889(2012/12-0016)
   Huttenlocher J, 2010, COGNITIVE PSYCHOL, V61, P343, DOI 10.1016/j.cogpsych.2010.08.002
   Johnson C, 2010, J SPEECH LANG HEAR R, V53, P237, DOI 10.1044/1092-4388(2009/08-0139)
   Justice L. M., 2001, CHILD LANG TEACH THE, V17, P207, DOI DOI 10.1177/026565900101700303
   Justice LM, 2008, DEV PSYCHOL, V44, P855, DOI 10.1037/0012-1649.44.3.855
   Justice LM, 2006, EARLY CHILD RES Q, V21, P374, DOI 10.1016/j.ecresq.2006.07.010
   Justice LM, 2006, LANG SPEECH HEAR SER, V37, P224, DOI 10.1044/0161-1461(2006/024)
   Justice LM, 2009, LANG SPEECH HEAR SER, V40, P67, DOI 10.1044/0161-1461(2008/07-0098)
   Justice LM, 2002, AM J SPEECH-LANG PAT, V11, P17, DOI 10.1044/1058-0360(2002/003)
   Justice LM, 2000, AM J SPEECH-LANG PAT, V9, P257, DOI 10.1044/1058-0360.0903.257
   Keidser G, 2011, AUDIOL RES, V1, P88, DOI 10.4081/audiores.2011.e24
   Kendeou P, 2009, J EDUC PSYCHOL, V101, P765, DOI 10.1037/a0015956
   King AM, 2010, INT J AUDIOL, V49, pS64, DOI 10.3109/14992020903329422
   Koehlinger KM, 2013, J SPEECH LANG HEAR R, V56, P1701, DOI 10.1044/1092-4388(2013/12-0188)
   Language and Reading Research Consortium (LARRC), 2017, J Speech Lang Hear Res, V60, P1273, DOI 10.1044/2017_JSLHR-L-16-0039
   Lederberg AR, 2014, J DEAF STUD DEAF EDU, V19, P438, DOI 10.1093/deafed/enu022
   LIBERMAN IY, 1974, J EXP CHILD PSYCHOL, V18, P201, DOI 10.1016/0022-0965(74)90101-5
   Lonigan C. J., 2007, TEST PRESCHOOL EARLY
   Lonigan CJ, 2011, READ WRIT, V24, P305, DOI 10.1007/s11145-009-9214-6
   Lonigan CJ, 2000, DEV PSYCHOL, V36, P596, DOI [10.1037/0012-1649.36.5.596, 10.1037//0012-1649.36.5.596]
   Lund E, 2018, AM J SPEECH-LANG PAT, V27, P765, DOI 10.1044/2018_AJSLP-16-0239
   Lund E, 2016, EXCEPT CHILDREN, V83, P26, DOI 10.1177/0014402916651848
   Marschark M, 2015, EXCEPT CHILDREN, V81, P350, DOI 10.1177/0014402914563700
   Mayer M., 2003, FROG ARE YOU
   McGinty AS, 2011, EARLY CHILD RES Q, V26, P255, DOI 10.1016/j.ecresq.2011.02.002
   Miller EM, 2013, J DEAF STUD DEAF EDU, V18, P206, DOI 10.1093/deafed/ens067
   Moeller Mary Pat, 2015, Ear Hear, V36 Suppl 1, p4S, DOI 10.1097/AUD.0000000000000210
   Moeller MP, 2000, PEDIATRICS, V106, DOI 10.1542/peds.106.3.e43
   Mol SE, 2008, EARLY EDUC DEV, V19, P7, DOI 10.1080/10409280701838603
   Moog J.S., 1990, EARLY SPEECH PERCEPT
   Moore BCJ, 2008, JARO-J ASSOC RES OTO, V9, P399, DOI 10.1007/s10162-008-0143-x
   Morgan PL, 2008, PREV SCH FAIL, V52, P11, DOI 10.3200/PSFL.52.4.11-16
   National Early Literacy Panel, 2008, DEV EARL LIT REP NAT
   Ng SL, 2011, J AM ACAD AUDIOL, V22, P375, DOI 10.3766/jaaa.22.6.6
   Nittrouer S, 2001, VOLTA REV, V103, P5
   Nittrouer S, 2012, EAR HEARING, V33, P683, DOI 10.1097/AUD.0b013e318258c98e
   Paivio A., 1971, IMAGERY VERBAL PROCE
   Pentimonti J, 2015, CHILD DEV, V86, P1948, DOI 10.1111/cdev.12450
   Phillips BM, 2012, J SCHOOL PSYCHOL, V50, P461, DOI 10.1016/j.jsp.2012.05.002
   Piasta SB, 2012, J EDUC PSYCHOL, V104, P945, DOI 10.1037/a0027757
   Piasta SB, 2012, CHILD DEV, V83, P810, DOI 10.1111/j.1467-8624.2012.01754.x
   Piasta SB, 2010, READ RES QUART, V45, P8, DOI 10.1598/RRQ.45.1.2
   Qi S, 2012, J DEAF STUD DEAF EDU, V17, P1, DOI 10.1093/deafed/enr028
   Rice ML, 1998, J SPEECH LANG HEAR R, V41, P1412, DOI 10.1044/jslhr.4106.1412
   Robertson C., 2007, PHONOLOGICAL AWARENE
   ROSS M, 1971, WORD INTELLIGIBILITY
   Rowe ML, 2012, CHILD DEV, V83, P508, DOI 10.1111/j.1467-8624.2011.01710.x
   Sadoski M., 2013, IMAGERY TEXT DUAL CO
   Sarant JZ, 2015, J SPEECH LANG HEAR R, V58, P1017, DOI 10.1044/2015_JSLHR-H-14-0075
   Schuele C. M., 2014, INTENSIVE PHONOLOGIC
   Scollie SD, 2010, INT J AUDIOL, V49, pS26, DOI 10.3109/14992020903121159
   Shanahan T, 2010, EDUC RESEARCHER, V39, P279, DOI 10.3102/0013189X10369172
   Silva M, 2015, J EDUC PSYCHOL, V107, P321, DOI 10.1037/a0037769
   Sininger YS, 2010, EAR HEARING, V31, P166, DOI 10.1097/AUD.0b013e3181c8e7b6
   Souza PE, 2015, J SPEECH LANG HEAR R, V58, P520, DOI 10.1044/2015_JSLHR-H-14-0138
   Spencer LJ, 2009, J DEAF STUD DEAF EDU, V14, P1, DOI 10.1093/deafed/enn013
   STAHL SA, 1994, J EDUC PSYCHOL, V86, P221, DOI 10.1037/0022-0663.86.2.221
   Stelmachowicz PG, 2001, J ACOUST SOC AM, V110, P2183, DOI 10.1121/1.1400757
   Storch SA, 2002, DEV PSYCHOL, V38, P934, DOI 10.1037//0012-1649.38.6.934
   Tade W. J., 1994, CHILDRENS EARLY INTE
   Tomblin JB, 2006, J SPEECH LANG HEAR R, V49, P1193, DOI 10.1044/1092-4388(2006/086)
   Tomblin J Bruce, 2015, Ear Hear, V36 Suppl 1, p76S, DOI 10.1097/AUD.0000000000000219
   Tomblin JB, 2014, JAMA OTOLARYNGOL, V140, P403, DOI 10.1001/jamaoto.2014.267
   Treiman R, 1998, CHILD DEV, V69, P1524, DOI 10.2307/1132130
   Trussell J. W., 2018, LANG SPEECH HEAR SER, V27, P1
   Wagner R, 1999, COMPREHENSIVE TEST P
   WAGNER RK, 1994, DEV PSYCHOL, V30, P73, DOI 10.1037/0012-1649.30.1.73
   Wagner RK, 1997, DEV PSYCHOL, V33, P468, DOI 10.1037/0012-1649.33.3.468
   Walker Elizabeth A, 2015, Ear Hear, V36 Suppl 1, p38S, DOI 10.1097/AUD.0000000000000208
   Walker EA, 2015, J SPEECH LANG HEAR R, V58, P1611, DOI 10.1044/2015_JSLHR-H-15-0043
   Webb MYL, 2014, J SPEECH LANG HEAR R, V57, P131, DOI 10.1044/1092-4388(2013/12-0106)
   Webb MYL, 2018, EAR HEARING, V39, P278, DOI 10.1097/AUD.0000000000000485
   Werfel KL, 2017, LANG SPEECH HEAR SER, V48, P249, DOI 10.1044/2017_LSHSS-17-0023
   Werfel KL, 2016, DEAF EDUC INT, V18, P134, DOI 10.1080/14643154.2016.1190117
   Werfel KL, 2014, VOLTA REV, V114, P113
   Werfel KL, 2015, COMMUN DISORD Q, V36, P107, DOI 10.1177/1525740114539002
   WHITEHURST GJ, 1988, DEV PSYCHOL, V24, P552, DOI 10.1037/0012-1649.24.4.552
   WORDEN PE, 1990, J READING BEHAV, V22, P277, DOI 10.1080/10862969009547711
   Yoshinaga-Itano C, 1998, PEDIATRICS, V102, P1161, DOI 10.1542/peds.102.5.1161
NR 126
TC 1
Z9 1
U1 0
U2 4
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 0161-1461
EI 1558-9129
J9 LANG SPEECH HEAR SER
JI Lang. Speech Hear. Serv. Sch.
PD JAN
PY 2019
VL 50
IS 1
BP 16
EP 33
DI 10.1044/2018_LSHSS-18-0015
PG 18
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA HU5EA
UT WOS:000465297800002
PM 30950774
DA 2021-02-24
ER

PT J
AU McCloy, DR
   Lee, AKC
AF McCloy, Daniel R.
   Lee, Adrian K. C.
TI Investigating the fit between phonological feature systems and brain
   responses to speech using EEG
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Phonological features; EEG; Neurolinguistics; Speech perception
ID CORTICAL ENTRAINMENT; NEURAL RESPONSES; NATURAL SPEECH; REPRESENTATIONS
AB This paper describes a technique to assess the correspondence between patterns of similarity in the brain's response to speech sounds and the patterns of similarity encoded in phonological feature systems, by quantifying the recoverability of phonological features from the neural data using supervised learning. The technique is applied to EEG recordings collected during passive listening to consonant-vowel syllables. Three published phonological feature systems are compared, and are shown to differ in their ability to recover certain speech sound contrasts from the neural data. For the phonological feature system that best reflects patterns of similarity in the neural data, a leave-one-out analysis indicates some consistency across subjects in which features have greatest impact on the fit, but considerable across-subject heterogeneity remains in the rank ordering of features in this regard.
C1 [McCloy, Daniel R.; Lee, Adrian K. C.] Univ Washington, Inst Learning & Brain Sci, Seattle, WA 98195 USA.
RP Lee, AKC (corresponding author), Univ Washington, Inst Learning & Brain Sci, Seattle, WA 98195 USA.
EM akclee@uw.edu
OI Lee, Adrian KC/0000-0002-7611-0500; McCloy, Daniel/0000-0002-7572-3241
FU National Institute on Deafness and Other Communication Disorders
   (NIDCD)United States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [T32DC005361]
FX This work was supported in part by the National Institute on Deafness
   and Other Communication Disorders (NIDCD) under grant T32DC005361.
CR Arsenault JS, 2015, J NEUROSCI, V35, P634, DOI 10.1523/JNEUROSCI.2454-14.2015
   Bar-Joseph Z, 2001, Bioinformatics, V17 Suppl 1, pS22
   BROMBERGER S, 1989, LINGUIST INQ, V20, P51
   BROWMAN CP, 1992, PHONETICA, V49, P155, DOI 10.1159/000261913
   Browman CP., 1989, PHONOLOGY, V6, P201, DOI [10.1017/S0952675700001019, DOI 10.1017/S0952675700001019]
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   de Cheveigne A, 2008, J NEUROSCI METH, V171, P331, DOI 10.1016/j.jneumeth.2008.03.015
   Di Liberto GM, 2017, HEARING RES, V348, P70, DOI 10.1016/j.heares.2017.02.015
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Evans S, 2015, CEREB CORTEX, V25, P4772, DOI 10.1093/cercor/bhv136
   Gramfort A, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00267
   Hasegawa-Johnson MA, 2017, IEEE-ACM T AUDIO SPE, V25, P50, DOI 10.1109/TASLP.2016.2621659
   Hayes B., 2009, INTRO PHONOLOGY
   Hickok G, 2009, J NEUROPHYSIOL, V101, P2725, DOI 10.1152/jn.91099.2008
   Hume Elizabeth V., 2001, ROLE SPEECH PERCEPTI, P251
   Jones D., 1957, PHONETICS LINGUISTIC, P187
   Jones E., 2001, SCIPY OPEN SOURCE SC
   Khalighinejad B, 2017, J NEUROSCI, V37, P2176, DOI 10.1523/JNEUROSCI.2383-16.2017
   Lahiri A, 2002, PHONOL PHONET, V4-1, P637
   Lahiri A, 2010, J PHONETICS, V38, P44, DOI 10.1016/j.wocn.2010.01.002
   Lalor EC, 2010, EUR J NEUROSCI, V31, P189, DOI 10.1111/j.1460-9568.2009.07055.x
   Leonard MK, 2015, J NEUROSCI, V35, P7203, DOI 10.1523/JNEUROSCI.4100-14.2015
   Markiewicz CJ, 2016, NEUROIMAGE, V141, P174, DOI 10.1016/j.neuroimage.2016.07.023
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Mielke J., 2006, ENCY LANGUAGE LINGUI, P723
   MILLER GA, 1955, J ACOUST SOC AM, V27, P338, DOI 10.1121/1.1907526
   Moran S., 2013, PHOIBLE PHONETICS IN
   Obleser J, 2004, J COGNITIVE NEUROSCI, V16, P31, DOI 10.1162/089892904322755539
   ohman S.E.G., 1965, SPEECH MUSIC HEARING, V6, P10
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Power AJ, 2012, EUR J NEUROSCI, V35, P1497, DOI 10.1111/j.1460-9568.2012.08060.x
   Roberts AC, 2014, NEUROPSYCHOLOGIA, V58, P88, DOI 10.1016/j.neuropsychologia.2014.03.015
   Roman Jakobson, 1952, PRELIMINARIES SPEECH
   Salmelin R, 2007, CLIN NEUROPHYSIOL, V118, P237, DOI 10.1016/j.clinph.2006.07.316
   Sarela J, 2005, J MACH LEARN RES, V6, P233
   Starzak R., 2007, SHAUN SHEEP SEASON 1
   Uusitalo MA, 1997, MED BIOL ENG COMPUT, V35, P135, DOI 10.1007/BF02534144
   Vaden KI, 2010, NEUROIMAGE, V49, P1018, DOI 10.1016/j.neuroimage.2009.07.063
   Wright Richard, 2004, PHONETICALLY BASED P, P34, DOI DOI 10.1017/CBO9780511486401.002
NR 39
TC 1
Z9 1
U1 1
U2 5
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PY 2019
VL 34
IS 5
BP 662
EP 676
DI 10.1080/23273798.2019.1569246
PG 15
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA HR2ES
UT WOS:000462949000008
PM 32984429
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Efimova, VL
   Nikolaeva, EI
AF Efimova, Victoria L.
   Nikolaeva, Elena, I
TI The Relationship of Language and Intelligence Development to the
   Maturity of the Subcortical Structures in Children with Specific
   Language Disorders
SO PSYCHOLOGY IN RUSSIA-STATE OF THE ART
LA English
DT Article
DE cognitive processes; language; subcortical structures of the brain;
   children; severe disorders of language development
ID AUDITORY BRAIN-STEM; PROCESSING DISORDER; SPEECH-PERCEPTION; ATTENTION
AB Objective. To detect possible dysfunctions of subcortical brain structures in children with severe disorders of language development and to study the association of such dysfunctions with linguistic and cognitive development, particularly the development of nonverbal intelligence on the level of the norm.
   Design. 45 children with severe speech disorders, aged 4 to 7 years, took part in the study: 9 girls and 36 boys who were patients at the Prognoz neurological clinic for children (Saint Petersburg). The diagnoses according to ICD10 were the following: F.80.1 - expressive speech disorder - 35 children; F.80.2 - receptive speech disorder - 10 children. The functional state of the brain stem was assessed by the auditory brain stem response (ABR) method. A modified stimulus was used to register peak VI, that is, a short tone burst with a frequency of 4,000 Hz, plateau duration of 0.5 MS, initial front of 0.5 ms, and intensity of 70 dB above the hearing threshold.
   Results. Analysis of the evoked potentials gave the following results: Deceleration of vestibular and/or auditory information conduction on the level of brain stem structures was detected in 98% of the children. Deceleration of vestibular information conduction was manifested in increased latency of the positive wave P13 cVEMP in comparison with the normative value. Deceleration of auditory information conduction was shown in an increase of the peak intervals of ABRs in comparison with normative values.
   Conclusions. All the children displayed conduction disturbancesin the auditory and vestibular systems. Conduction disturbances in the auditory system were directly connected with the severity of their speech problems. Conduction disturbances in the vestibular system were associated with lower nonverbal intelligence.
C1 [Efimova, Victoria L.] Prognoz Neurol Clin Children, St Petersburg, Russia.
   [Nikolaeva, Elena, I] Herzen State Pedag Univ, St Petersburg, Russia.
RP Nikolaeva, EI (corresponding author), Herzen State Pedag Univ, St Petersburg, Russia.
EM klemtina@yandex.ru
RI Nikolaeva, Elena/D-2869-2016
OI Nikolaeva, Elena/0000-0001-8363-8496
CR Abdi S, 2016, IRAN J MED SCI, V41, P415
   Ayres Jean, 1972, SENSORY INTEGRATION
   Basu M, 2010, DEVELOPMENTAL SCI, V13, P77, DOI 10.1111/j.1467-7687.2009.00849.x
   Bigelow RT, 2015, J VESTIBUL RES-EQUIL, V25, P73, DOI 10.3233/VES-150544
   Billiet CR, 2011, J SPEECH LANG HEAR R, V54, P228, DOI 10.1044/1092-4388(2010/09-0239)
   Bishop DVM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0035851
   Cal Renato, 2009, Braz. j. otorhinolaryngol., V75, P456, DOI 10.1590/S1808-86942009000300023
   Choudhury N, 2011, CLIN NEUROPHYSIOL, V122, P320, DOI 10.1016/j.clinph.2010.05.035
   Dawes P, 2009, INT J LANG COMM DIS, V44, P440, DOI 10.1080/13682820902929073
   de Quiros J. B., 1978, NEUROPSYCHOLOGICAL F
   Dodd B., 2013, DIFFERENTIAL DIAGNOS
   Efimov O. I., 2014, Sensornye Sistemy, V28, P36
   Felix RA, 2018, HEARING RES, V362, P48, DOI 10.1016/j.heares.2018.01.008
   Friederici AD, 2012, TRENDS COGN SCI, V16, P262, DOI 10.1016/j.tics.2012.04.001
   Hagoort P, 2014, ANNU REV NEUROSCI, V37, P347, DOI 10.1146/annurev-neuro-071013-013847
   Hornickel J, 2011, BEHAV BRAIN RES, V216, P597, DOI 10.1016/j.bbr.2010.08.051
   Koziol LF., 2009, SUBCORTICAL STRUCTUR, DOI [10.1007/978-0-387-84868-6, DOI 10.1007/978-0-387-84868-6]
   Kraus N, 2001, AUDIOL NEURO-OTOL, V6, P221, DOI 10.1159/000046837
   Leite Renata Aparecida, 2010, Pró-Fono R. Atual. Cient., V22, P561, DOI 10.1590/S0104-56872010000400034
   Leite RA, 2014, CLINICS, V69, P212, DOI 10.6061/clinics/2014(03)12
   Moore DR, 2013, HEARING BALANC COMMU, V11, P160, DOI 10.3109/21695717.2013.821756
   Moser EI, 2008, HIPPOCAMPUS, V18, P1142, DOI 10.1002/hipo.20483
   Murofushi T., 2014, WORLD J OTORHINOLARY, V4, P6, DOI DOI 10.5319/WJ0.V4.I2.6
   Orbeli L. A, 1961, VOPROSY EVOLYUCIONNO, V5
   Rine RM, 2013, NEUROREHABILITATION, V32, P507, DOI 10.3233/NRE-130873
   Rosengren SM, 2010, CLIN NEUROPHYSIOL, V121, P636, DOI 10.1016/j.clinph.2009.10.016
   Rosengren SM, 2013, CURR OPIN NEUROL, V26, P74, DOI 10.1097/WCO.0b013e32835c5ef3
   Skoe E, 2013, NEUROSCIENCE, V243, P104, DOI 10.1016/j.neuroscience.2013.03.009
   Stefanics G, 2011, NEUROIMAGE, V57, P723, DOI 10.1016/j.neuroimage.2011.04.005
   Vandewalle E, 2012, RES DEV DISABIL, V33, P635, DOI 10.1016/j.ridd.2011.11.005
   Vizel T. G, 2015, VESTNIK UGROVEDENIYA, V3, P95
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   Wiener-Vacher SR, 2013, FRONT INTEGR NEUROSC, V7, DOI 10.3389/fnint.2013.00092
   Young YH, 2015, INT J PEDIATR OTORHI, V79, P435, DOI 10.1016/j.ijporl.2015.01.015
   Zhou GW, 2014, MEDICINE, V93, DOI 10.1097/MD.0000000000000037
NR 35
TC 1
Z9 1
U1 1
U2 3
PU LOMONOSOV MOSCOW STATE UNIV, FAC JOURNALISM
PI MOSCOW
PA UL MAKHOVAYA, DOM 11, STROENIE 9, MOSCOW, 125009, RUSSIA
SN 2074-6857
EI 2307-2202
J9 PSYCHOL RUSS
JI Psychol. Russ.
PY 2019
VL 12
IS 1
BP 79
EP 88
DI 10.11621/pir.2019.0106
PG 10
WC Psychology, Multidisciplinary
SC Psychology
GA HQ0LU
UT WOS:000462087300006
OA DOAJ Gold
DA 2021-02-24
ER

PT S
AU Nazzi, T
   Cutler, A
AF Nazzi, Thierry
   Cutler, Anne
BE Liberman, M
   Partee, BH
TI How Consonants and Vowels Shape Spoken-Language Recognition
SO ANNUAL REVIEW OF LINGUISTICS, VOL 5
SE Annual Review of Linguistics
LA English
DT Article; Book Chapter
DE consonants; vowels; phonology; lexicon; speech recognition; adult;
   infant; development
ID POSSIBLE-WORD CONSTRAINTS; OWN-NAME RECOGNITION; SPEECH-PERCEPTION;
   PHONETIC SPECIFICITY; VOCALIC INFORMATION; LEXICAL SELECTION; FINDING
   WORDS; SEGMENTATION; INFANTS; DISCRIMINATION
AB All languages instantiate a consonant/vowel contrast. This contrast has processing consequences at different levels of spoken-language recognition throughout the lifespan. In adulthood, lexical processing is more strongly associated with consonant than with vowel processing; this has been demonstrated across 13 languages from seven language families and in a variety of auditory lexical-level tasks (deciding whether a spoken input is a word, spotting a real word embedded in a minimal context, reconstructing a word minimally altered into a pseudoword, learning new words or the "words" of a made-up language), as well as in written-word tasks involving phonological processing. In infancy, a consonant advantage in word learning and recognition is found to emerge during development in some languages, though possibly not in others, revealing that the stronger lexicon-consonant association found in adulthood is learned. Current research is evaluating the relative contribution of the early acquisition of the acoustic/phonetic and lexical properties of the native language in the emergence of this association.
C1 [Nazzi, Thierry] Univ Paris 05, Lab Psychol Percept, CNRS, F-75270 Paris 06, France.
   [Cutler, Anne] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Penrith, NSW 2751, Australia.
   [Cutler, Anne] Western Sydney Univ, ARC Ctr Excellence Dynam Language, Penrith, NSW 2751, Australia.
   [Cutler, Anne] Max Planck Inst Psycholinguist, NL-6525 XD Nijmegen, Netherlands.
RP Nazzi, T (corresponding author), Univ Paris 05, Lab Psychol Percept, CNRS, F-75270 Paris 06, France.
EM thierry.nazzi@parisdescartes.fr; A.Cutler@westernsydney.edu.au
CR Abboub N, 2016, BRAIN LANG, V162, P46, DOI 10.1016/j.bandl.2016.08.002
   Alexeeva S, 2017, J PSYCHOLINGUIST RES, V46, P629, DOI 10.1007/s10936-016-9458-7
   Benavides-Varela S, 2012, P NATL ACAD SCI USA, V109, P17908, DOI 10.1073/pnas.1205413109
   Bergelson E, 2012, P NATL ACAD SCI USA, V109, P3253, DOI 10.1073/pnas.1113380109
   BERTONCINI J, 1988, J EXP PSYCHOL GEN, V117, P21, DOI 10.1037/0096-3445.117.1.21
   Bishop J, 2012, P 47 ANN M CHIC LING, P1
   Bonatti LL, 2005, PSYCHOL SCI, V16, P451, DOI 10.1111/j.0956-7976.2005.01556.x
   Bonatti LL, 2007, PSYCHOL SCI, V18, P924, DOI 10.1111/j.1467-9280.2007.02002.x
   Bond Z. S., 1980, PERCEPTION PRODUCTIO, P115
   Bouchon C, 2015, DEVELOPMENTAL SCI, V18, P587, DOI 10.1111/desc.12242
   Caramazza A, 2000, NATURE, V403, P428, DOI 10.1038/35000206
   Carreiras M, 2008, CEREB CORTEX, V18, P1727, DOI 10.1093/cercor/bhm202
   Carreiras M, 2009, CEREB CORTEX, V19, P2659, DOI 10.1093/cercor/bhp019
   CHEOURLUHTANEN M, 1995, HEARING RES, V82, P53
   Choi JY, 2017, P NATL ACAD SCI USA, V114, P7307, DOI 10.1073/pnas.1706405114
   Cole RA, 1996, INT CONF ACOUST SPEE, P853, DOI 10.1109/ICASSP.1996.543255
   Costa A, 1998, PERCEPT PSYCHOPHYS, V60, P1022, DOI 10.3758/BF03211936
   Creel SC, 2006, J MEM LANG, V54, P1, DOI 10.1016/j.jml.2005.09.003
   Curtin S, 2009, DEVELOPMENTAL SCI, V12, P725, DOI 10.1111/j.1467-7687.2009.00814.x
   CUTLER A, 1994, J MEM LANG, V33, P824, DOI 10.1006/jmla.1994.1039
   Cutler A, 1997, PERCEPT PSYCHOPHYS, V59, P165, DOI 10.3758/BF03211886
   Cutler A, 2002, J MEM LANG, V46, P296, DOI 10.1006/jmla.2001.2814
   Cutler A, 2002, PSYCHOL SCI, V13, P258, DOI 10.1111/1467-9280.00447
   Cutler A, 2000, MEM COGNITION, V28, P746, DOI 10.3758/BF03198409
   Cutler A, 2002, P 9 AUSTR INT C SPEE, P40
   Cutler A, 1999, P 14 INT C PHON SCI, V3, P2053
   Cutler A, 2009, J ACOUST SOC AM, V125, P1693, DOI 10.1121/1.3075556
   DECASPER AJ, 1980, SCIENCE, V208, P1174, DOI 10.1126/science.7375928
   DECASPER AJ, 1986, INFANT BEHAV DEV, V9, P133, DOI 10.1016/0163-6383(86)90025-1
   Delle Luche C, 2017, INFANCY, V22, P362, DOI 10.1111/infa.12151
   Delle Luche C, 2014, J MEM LANG, V72, P1, DOI 10.1016/j.jml.2013.12.001
   Dumay N, 2002, BRAIN LANG, V81, P144, DOI 10.1006/brln.2001.2513
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   El Aissati A, 2012, COGNITION, V124, P79, DOI 10.1016/j.cognition.2012.03.006
   Erra RG, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148861
   Escudero P, 2016, COGNITIVE SCI, V40, P455, DOI 10.1111/cogs.12243
   Escudero P, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01059
   Feldman NH, 2013, COGNITION, V127, P427, DOI 10.1016/j.cognition.2013.02.007
   Floccia C, 2014, J CHILD LANG, V41, P1085, DOI 10.1017/S0305000913000287
   Fogerty D, 2012, J ACOUST SOC AM, V131, P1490, DOI 10.1121/1.3676696
   Gomez DM, 2018, LANG SPEECH, V61, P84, DOI 10.1177/0023830917706529
   Granier-Deferre C, 2011, DEVELOPMENTAL SCI, V14, P336, DOI 10.1111/j.1467-7687.2010.00978.x
   Groome LJ, 1997, DEV PSYCHOBIOL, V30, P103, DOI 10.1002/(SICI)1098-2302(199703)30:2<103::AID-DEV2>3.0.CO;2-U
   Halle PA, 1996, INFANT BEHAV DEV, V19, P463, DOI 10.1016/S0163-6383(96)90007-7
   Hanulikova A, 2011, BILING-LANG COGN, V14, P506, DOI 10.1017/S1366728910000428
   Hanulikova A, 2010, Q J EXP PSYCHOL, V63, P555, DOI 10.1080/17470210903038958
   Havy M, 2014, LANG SPEECH, V57, P254, DOI 10.1177/0023830913507693
   Havy M, 2009, INFANCY, V14, P439, DOI 10.1080/15250000902996532
   Hochmann JR, 2018, INFANCY, V23, P136, DOI 10.1111/infa.12203
   Hochmann JR, 2011, DEVELOPMENTAL SCI, V14, P1445, DOI 10.1111/j.1467-7687.2011.01089.x
   Hohle B, 2003, DEVELOPMENTAL SCI, V6, P122, DOI 10.1111/1467-7687.00261
   Hojen A, 2016, DEVELOPMENTAL SCI, V19, P41, DOI 10.1111/desc.12286
   Johnson EK, 2003, COGNITIVE PSYCHOL, V46, P65, DOI 10.1016/S0010-0285(02)00507-8
   Johnson EK, 2016, ANNU REV LINGUIST, V2, P391, DOI 10.1146/annurev-linguistics-011415-040616
   JOHNSON K, 1993, J ACOUST SOC AM, V94, P701, DOI 10.1121/1.406887
   Johr J., 2011, ENFANCE, V3, P293
   Jusczyk PW, 1999, COGNITIVE PSYCHOL, V39, P159, DOI 10.1006/cogp.1999.0716
   Jusczyk PW, 1999, J MEM LANG, V40, P62, DOI 10.1006/jmla.1998.2605
   JUSCZYK PW, 1995, COGNITIVE PSYCHOL, V29, P1, DOI 10.1006/cogp.1995.1010
   Kearns RK, 2002, ICLSP 2002 7 INT C S, P1657
   Keidel JL, 2007, PSYCHOL SCI, V18, P922, DOI 10.1111/j.1467-9280.2007.02001.x
   Kewley-Port D, 2007, J ACOUST SOC AM, V122, P2365, DOI 10.1121/1.2773986
   Kisilevsky BS, 2003, PSYCHOL SCI, V14, P220, DOI 10.1111/1467-9280.02435
   Kolinsky R, 2009, COGNITION, V112, P1, DOI 10.1016/j.cognition.2009.02.014
   Kooijman V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00025
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   LADEFOGED P, 2012, VOWELS CONSONANTS
   LECANUET JP, 1987, CR ACAD SCI III-VIE, V305, P161
   Lee HW, 2002, PSYCHON B REV, V9, P766, DOI 10.3758/BF03196333
   Low E., 2000, LANG SPEECH, V43, P377, DOI DOI 10.1177/00238309000430040301
   Lupker SJ, 2008, LANG COGNITIVE PROC, V23, P93, DOI 10.1080/01690960701579714
   Maddieson I., 1984, PATTERNS SOUNDS
   Mani N, 2007, J MEM LANG, V57, P252, DOI 10.1016/j.jml.2007.03.005
   Mani N, 2010, INFANCY, V15, P445, DOI 10.1111/j.1532-7078.2009.00027.x
   Marks E. A., 2002, SW J LINGUISTICS, V21, P73
   MCCARTHY J, 1995, HDB PHONOLOGICAL THE, P318
   McQueen J. M., 1998, P 5 INT C SPOK LANG, V6, P2791
   McQueen JM, 2001, J MEM LANG, V45, P103, DOI 10.1006/jmla.2000.2763
   MEHLER J, 1978, PERCEPTION, V7, P491, DOI 10.1068/p070491
   Mehler J, 2006, CORTEX, V42, P846, DOI 10.1016/S0010-9452(08)70427-1
   Mintz TH, 2018, COGNITION, V171, P95, DOI 10.1016/j.cognition.2017.10.020
   Moates DR, 2012, MENT LEX, V7, P326, DOI 10.1075/ml.7.3.04moa
   Moates DR, 2002, PHONOL PHON, V4-1, P141
   Monaghan P, 2003, BRAIN LANG, V86, P83, DOI 10.1016/S0093-934X(02)00536-9
   Moon C, 2013, ACTA PAEDIATR, V102, P156, DOI 10.1111/apa.12098
   Mueller JL, 2008, J COGNITIVE NEUROSCI, V20, P892, DOI 10.1162/jocn.2008.20511
   Mulak KE, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176762
   Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037/0096-1523.24.3.756
   Nazzi T, 2005, COGNITION, V98, P13, DOI 10.1016/j.cognition.2004.10.005
   Nazzi T, 1998, INFANT BEHAV DEV, V21, P779, DOI 10.1016/S0163-6383(98)90044-3
   Nazzi T, 2007, COGNITIVE DEV, V22, P271, DOI 10.1016/j.cogdev.2006.10.007
   Nazzi T, 2018, J EXP CHILD PSYCHOL, V174, P103, DOI 10.1016/j.jecp.2018.05.011
   Nazzi T, 2009, LANG SPEECH, V52, P463, DOI 10.1177/0023830909336584
   Nazzi T, 2009, J EXP CHILD PSYCHOL, V102, P522, DOI 10.1016/j.jecp.2008.05.003
   Nespor M., 2003, LINGUE LINGUAGGIO, V2, P203, DOI [10. 1418/ 10879, DOI 10.1418/10879]
   NETTLE D, 1994, LANG SPEECH, V37, P425, DOI 10.1177/002383099403700406
   New B, 2014, LANG COGN NEUROSCI, V29, P147, DOI 10.1080/01690965.2012.735678
   New B, 2008, PSYCHOL SCI, V19, P1223, DOI 10.1111/j.1467-9280.2008.02228.x
   Newman RS, 2011, J MEM LANG, V64, P460, DOI 10.1016/j.jml.2010.11.004
   Newport EL, 2004, COGNITIVE PSYCHOL, V48, P127, DOI 10.1016/S0010-0285(03)00128-2
   Nishibayashi LL, 2016, COGNITION, V155, P188, DOI 10.1016/j.cognition.2016.07.003
   Nishibayashi LL, 2015, LANG SPEECH, V58, P334, DOI 10.1177/0023830914551375
   NOOTEBOOM SG, 1980, J ACOUST SOC AM, V67, P276, DOI 10.1121/1.383737
   Norris D, 2001, LANG COGNITIVE PROC, V16, P637, DOI 10.1080/01690960143000119
   Norris D, 1997, COGNITIVE PSYCHOL, V34, P191, DOI 10.1006/cogp.1997.0671
   Onnis L, 2005, J MEM LANG, V53, P225, DOI 10.1016/j.jml.2005.02.011
   Onnis L, 2004, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P1047
   Owren MJ, 2006, J ACOUST SOC AM, V119, P1727, DOI 10.1121/1.2161431
   Parikh G, 2005, J ACOUST SOC AM, V118, P3874, DOI 10.1121/1.2118407
   Pater J, 2004, LANGUAGE, V80, P384, DOI 10.1353/lan.2004.0141
   Pena M, 2002, SCIENCE, V298, P604, DOI 10.1126/science.1072901
   Perea M, 2008, LANG COGNITIVE PROC, V23, P69, DOI 10.1080/01690960701578146
   Perea M, 2009, ACTA PSYCHOL, V130, P127, DOI 10.1016/j.actpsy.2008.11.001
   Perruchet P, 2006, J EXP PSYCHOL GEN, V135, P322, DOI 10.1037/0096-3445.135.2.322
   Perruchet P, 2004, J EXP PSYCHOL GEN, V133, P573, DOI 10.1037/0096-3445.133.4.573
   PISONI DB, 1973, PERCEPT PSYCHOPHYS, V13, P253, DOI 10.3758/BF03214136
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Polka L, 2018, APPL PSYCHOLINGUIST, V39, P757, DOI 10.1017/S0142716418000218
   Poltrock S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01211
   Poltrock S, 2015, J EXP CHILD PSYCHOL, V131, P135, DOI 10.1016/j.jecp.2014.11.011
   Pons F, 2010, COGNITION, V116, P361, DOI 10.1016/j.cognition.2010.05.013
   Ramus F, 1999, COGNITION, V73, P265, DOI 10.1016/S0010-0277(99)00058-X
   Repp BH., 1984, SPEECH LANG ADV BASI, V10, P243, DOI DOI 10.1016/B978-0-12-608610-2.50012-1
   Ridouane R, 2008, PHONOLOGY, V25, P321, DOI 10.1017/S0952675708001498
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Sansavini A, 1997, DEV PSYCHOL, V33, P3, DOI 10.1037/0012-1649.33.1.3
   Schubert T, 2018, Q J EXP PSYCHOL, V71, P642, DOI 10.1080/17470218.2016.1271444
   Seidenberg MS, 2002, SCIENCE, V298, P553, DOI 10.1126/science.1078094
   SHAHIDULLAH S, 1994, EARLY HUM DEV, V36, P13, DOI 10.1016/0378-3782(94)90029-9
   SHANKWEILER D, 1967, Q J EXP PSYCHOL, V19, P59, DOI 10.1080/14640746708400069
   Sharp DJ, 2005, BRAIN LANG, V92, P309, DOI 10.1016/j.bandl.2004.07.002
   Soto-Faraco S, 2001, J MEM LANG, V45, P412, DOI 10.1006/jmla.2000.2783
   Stager CL, 1997, NATURE, V388, P381, DOI 10.1038/41102
   Swingley D, 2005, DEVELOPMENTAL SCI, V8, P432, DOI 10.1111/j.1467-7687.2005.00432.x
   Swingley D, 2009, PHILOS T R SOC B, V364, P3617, DOI 10.1098/rstb.2009.0107
   SWINNEY DA, 1980, PERCEPT PSYCHOPHYS, V27, P104, DOI 10.3758/BF03204296
   SWOBODA PJ, 1976, CHILD DEV, V47, P459, DOI 10.2307/1128802
   Taft M., 1992, LANGUAGE PROCESSING, V90, P151, DOI DOI 10.1016/S0166-4115(08)61891-9
   Tincoff R, 1999, PSYCHOL SCI, V10, P172, DOI 10.1111/1467-9280.00127
   Tincoff R, 2012, INFANCY, V17, P432, DOI 10.1111/j.1532-7078.2011.00084.x
   Toro JM, 2008, PSYCHOL SCI, V19, P137, DOI 10.1111/j.1467-9280.2008.02059.x
   TSANG KK, 1979, PSYCHOLOGIA, V22, P222
   van Ooyen B., 1991, EUROSPEECH 91. 2nd European Conference on Speech Communication and Technology Proceedings, P1451
   vanOoijen B, 1996, MEM COGNITION, V24, P573, DOI 10.3758/BF03201084
   Vihman MM, 2017, BRIT J PSYCHOL, V108, P1, DOI 10.1111/bjop.12207
   Von Holzen K, 2018, BRAIN SCI, V8, DOI 10.3390/brainsci8020024
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Werker JF, 2005, TRENDS COGN SCI, V9, P519, DOI 10.1016/j.tics.2005.09.003
   WERNER LA, 1992, CHILD DEV, V63, P260, DOI 10.2307/1131477
   Wewalaarachchi TD, 2017, J EXP CHILD PSYCHOL, V159, P16, DOI 10.1016/j.jecp.2017.01.009
   Wiener S, 2016, LANG SPEECH, V59, P59, DOI 10.1177/0023830915578000
   WOOD CC, 1975, PERCEPT PSYCHOPHYS, V17, P346, DOI 10.3758/BF03199344
   Ye Y, 1999, LANG COGNITIVE PROC, V14, P609, DOI 10.1080/016909699386202
   Yeung HH, 2014, COGNITION, V132, P151, DOI 10.1016/j.cognition.2014.04.001
   Yip MCW, 2004, PSYCHOLOGIA, V47, P169, DOI 10.2117/psysoc.2004.169
   Yip MCW, 2004, J PSYCHOLINGUIST RES, V33, P165, DOI 10.1023/B:JOPR.0000017225.65288.4b
   Zwitserlood P., 1996, LANG COGNITIVE PROC, V10, P121
NR 157
TC 11
Z9 11
U1 3
U2 15
PU ANNUAL REVIEWS
PI PALO ALTO
PA 4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0897 USA
SN 2333-9691
J9 ANNU REV LINGUIST
PY 2019
VL 5
BP 25
EP 47
DI 10.1146/annurev-linguistics-011718-011919
PG 23
WC Linguistics; Language & Linguistics
SC Linguistics
GA BM1MT
UT WOS:000460289100002
OA Green Published
DA 2021-02-24
ER

PT S
AU Keough, M
   Derrick, D
   Gick, B
AF Keough, Megan
   Derrick, Donald
   Gick, Bryan
BE Liberman, M
   Partee, BH
TI Cross-Modal Effects in Speech Perception
SO ANNUAL REVIEW OF LINGUISTICS, VOL 5
SE Annual Review of Linguistics
LA English
DT Article; Book Chapter
DE cross-modal effects; multisensory; multimodal; speech perception;
   somatosensation
ID TACTILE INTEGRATION; TADOMA METHOD; MULTISENSORY INTERACTIONS; TEMPORAL
   WINDOW; NORMAL-HEARING; SEEING SPEECH; LIP; INFORMATION; ATTENTION;
   PERTURBATIONS
AB Speech research during recent years has moved progressively away from its traditional focus on audition toward a more multisensory approach. In addition to audition and vision, many somatosenses including proprioception, pressure, vibration, and aerotactile sensation are all highly relevant modalities for experiencing and/or conveying speech. In this article, we review both long-standing cross-modal effects stemming from decades of audiovisual speech research and new findings related to somatosensory effects. Cross-modal effects in speech perception to date have been found to be constrained by temporal congruence and signal relevance, but appear to be unconstrained by spatial congruence. The literature reveals that, far from taking place in a one-, two-, or even three-dimensional space, speech occupies a highly multidimensional sensory space. We argue that future research in cross-modal effects should expand to consider each of these modalities both separately and in combination with other modalities in speech.
C1 [Keough, Megan; Gick, Bryan] Univ British Columbia, Dept Linguist, Interdisciplinary Speech Res Lab, Vancouver, BC V6T 1Z4, Canada.
   [Derrick, Donald] Univ Canterbury, New Zealand Inst Brain & Behav, Christchurch 8140, New Zealand.
   [Derrick, Donald] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Penrith, NSW 2751, Australia.
   [Gick, Bryan] Yale Univ, Haskins Labs, New Haven, CT 06511 USA.
RP Keough, M (corresponding author), Univ British Columbia, Dept Linguist, Interdisciplinary Speech Res Lab, Vancouver, BC V6T 1Z4, Canada.
EM keoughm@mail.ubc.ca; donald.derrick@canterbury.ac.nz; gick@mail.ubc.ca
CR ABBS JH, 1984, J NEUROPHYSIOL, V51, P705
   Alcorn S., 1932, VOLTA REV, V34, P195
   Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Alsius A, 2007, EXP BRAIN RES, V183, P399, DOI 10.1007/s00221-007-1110-1
   Anderson DM, 1996, ASSESSMENT NEUROPSYC, P82
   Arnold P, 2001, BRIT J PSYCHOL, V92, P339, DOI 10.1348/000712601162220
   Baart M, 2016, PSYCHOPHYSIOLOGY, V53, P1295, DOI 10.1111/psyp.12683
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Bell A. M., 1867, VISIBLE SPEECH SCI U
   BERNSTEIN LE, 1991, J ACOUST SOC AM, V90, P2971, DOI 10.1121/1.401771
   Bertelson P., 1994, ICSLP 94. 1994 International Conference on Spoken Language Processing, P559
   Bertelson P, 1998, PSYCHON B REV, V5, P482, DOI 10.3758/BF03208826
   Bertelson P, 1996, SPEECHREADING HUMANS, V150, P179
   Bicevskis K, 2016, J ACOUST SOC AM, V140, P3531, DOI 10.1121/1.4965968
   Brancazio L, 2002, J ACOUST SOC AM, V111, P2433
   Bruderer AG, 2015, P NATL ACAD SCI USA, V112, P13531, DOI 10.1073/pnas.1508631112
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593
   Campbell R, 2001, COGNITIVE BRAIN RES, V12, P233, DOI 10.1016/S0926-6410(01)00054-4
   Chang C, 2018, CAN ACOUST, V46
   Derrick D., 2014, P 15 ANN C INT SPEEC, P2580
   Derrick D., 2015, PCT patent, Patent No. [WO2015/122785A1, 2015122785]
   Derrick D, 2015, CAN ACOUST, V43, P3
   Derrick D, 2013, MULTISENS RES, V26, P405, DOI 10.1163/22134808-00002427
   Derrick D, 2009, J ACOUST SOC AM, V125, P2272, DOI 10.1121/1.3081496
   Erickson LC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00534
   FISHER BD, 1994, CAH PSYCHOL COGN, V13, P92
   Fowler C. A., 1986, STATUS REPORT SPEECH, P139
   Fowler CA, 1996, J ACOUST SOC AM, V99, P1730, DOI 10.1121/1.415237
   FOWLER CA, 1991, J EXP PSYCHOL HUMAN, V17, P816, DOI 10.1037/0096-1523.17.3.816
   Fowler CA., 2010, CORSINI ENCY PSYCHOL
   Fowler CA, 1995, SPEECH LANGUAGE COMM, P29
   Frayne E, 2016, EXP BRAIN RES, V234, P1679, DOI 10.1007/s00221-016-4573-0
   Ghosh SS, 2010, J ACOUST SOC AM, V128, P3079, DOI 10.1121/1.3493430
   Gibson J., 1979, ECOLOGICAL APPROACH
   Gibson James J., 1966, SENSES CONSIDERED PE
   Gick B, 2008, J ACOUST SOC AM, V123, pEL72, DOI 10.1121/1.2884349
   Gick B, 2012, J PHONETICS, V40, P46, DOI 10.1016/j.wocn.2011.09.002
   Gick B, 2010, J ACOUST SOC AM, V128, pEL342, DOI 10.1121/1.3505759
   Gick B, 2009, NATURE, V462, P502, DOI 10.1038/nature08572
   Goldenberg D., 2015, P 18 INT C PHON SCI
   GREEN KP, 1995, J EXP PSYCHOL HUMAN, V21, P1409, DOI 10.1037/0096-1523.21.6.1409
   GREEN KP, 1991, PERCEPT PSYCHOPHYS, V50, P524, DOI 10.3758/BF03207536
   Green KP, 1988, J ACOUST SOC AM, V84, pS155, DOI DOI 10.1121/1.2025888
   Holmes NP, 2005, CURR BIOL, V15, pR762, DOI 10.1016/j.cub.2005.08.058
   Hsiao S, 2011, NEUROBIOLOGY SENSATI, P141
   Ito T, 2012, J NEUROPHYSIOL, V107, P442, DOI 10.1152/jn.00029.2011
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   Jones J. A., 1997, Canadian Acoustics, V25, P13
   KELSO JAS, 1984, J EXP PSYCHOL HUMAN, V10, P812, DOI 10.1037/0096-1523.10.6.812
   Keough M, 2016, J ACOUST SOC AM, V140, P3225
   Keough M, 2017, CAN ACOUST, V45, P176
   Klucharev V, 2003, COGNITIVE BRAIN RES, V18, P65, DOI 10.1016/j.cogbrainres.2003.09.004
   Macaluso E, 2005, TRENDS NEUROSCI, V28, P264, DOI 10.1016/j.tins.2005.03.008
   MacSweeney M, 2000, NEUROREPORT, V11, P1729, DOI 10.1097/00001756-200006050-00026
   Massaro D. W., 1998, PERCEIVING TALKING F
   Massaro D. W., 1987, SPEECH PERCEPTION EA
   Massaro DW, 2008, PSYCHON B REV, V15, P453, DOI 10.3758/PBR.15.2.453
   MCGRATH M, 1985, J ACOUST SOC AM, V77, P678, DOI 10.1121/1.392336
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Menard L, 2016, CLIN LINGUIST PHONET, V30, P227, DOI 10.3109/02699206.2015.1079247
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Munhall KG, 1996, PERCEPT PSYCHOPHYS, V58, P351, DOI 10.3758/BF03206811
   Musacchia G, 2006, EXP BRAIN RES, V168, P1, DOI 10.1007/s00221-005-0071-5
   Nasir SM, 2006, CURR BIOL, V16, P1918, DOI 10.1016/j.cub.2006.07.069
   Parker AJ, 2003, CURR OPIN NEUROBIOL, V13, P433, DOI 10.1016/S0959-4388(03)00099-0
   Perkell JS, 2012, J NEUROLINGUIST, V25, P382, DOI 10.1016/j.jneuroling.2010.02.011
   Pickering MJ, 2013, BEHAV BRAIN SCI, V36, P329, DOI 10.1017/S0140525X12001495
   Reed CM, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1489, DOI 10.1109/ICSLP.1996.607898
   REED CM, 1978, J SPEECH HEAR RES, V21, P625, DOI 10.1044/jshr.2104.625
   REED CM, 1989, J SPEECH HEAR RES, V32, P921, DOI 10.1044/jshr.3204.921
   Reisberg D, 1987, HEARING EYE PSYCHOL, P97
   Rosenblum LD, 1997, PERCEPT PSYCHOPHYS, V59, P347, DOI 10.3758/BF03211902
   Rosenblum LD, 1996, J EXP PSYCHOL HUMAN, V22, P318, DOI 10.1037/0096-1523.22.2.318
   SAMS M, 1991, NEUROSCI LETT, V127, P141, DOI 10.1016/0304-3940(91)90914-F
   Schwartz JL, 2010, J ACOUST SOC AM, V127, P1584, DOI 10.1121/1.3293001
   Scott M., 2012, THESIS U B C VANCOUV
   Shen GN, 2018, EXP BRAIN RES, V236, P13, DOI 10.1007/s00221-017-5104-3
   Soto-Faraco S, 2003, NEUROPSYCHOLOGIA, V41, P1847, DOI 10.1016/S0028-3932(03)00185-4
   SPARKS DW, 1978, J ACOUST SOC AM, V63, P246, DOI 10.1121/1.381720
   Sperdin HF, 2010, NEUROPSYCHOLOGIA, V48, P3696, DOI 10.1016/j.neuropsychologia.2010.09.001
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Theys C, 2014, P 32 AUSTR WINT C BR, P37
   Theys C, 2014, HLTH RES SOC CANT PO
   Tian X, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00166
   Tiippana K, 2004, EUR J COGN PSYCHOL, V16, P457, DOI 10.1080/09541440340000268
   Tiippana K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00725
   Tremblay S, 2003, NATURE, V423, P866, DOI 10.1038/nature01710
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   van Wassenhove V, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00388
   Vatikiotis-Bateson E., 1996, SPEECHREADING HUMANS, P221, DOI DOI 10.1007/978-3-662-13015-5_16
   VatikiotisBateson E, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1485, DOI 10.1109/ICSLP.1996.607897
   VATIKTIOTISBATE.E, 2000, LP 98 ITEM ORDER LAN, P439
   VIVIAN RM, 1966, VOLTA REV, V68, P733
   WALKER S, 1995, PERCEPT PSYCHOPHYS, V57, P1124, DOI 10.3758/BF03208369
   Wilson EC, 2009, J ACOUST SOC AM, V126, P1960, DOI 10.1121/1.3204305
   Yehia H, 1998, P ESCA WORKSH AUD VI, P41
   Yeung HH, 2013, PSYCHOL SCI, V24, P603, DOI 10.1177/0956797612458802
NR 97
TC 1
Z9 1
U1 0
U2 4
PU ANNUAL REVIEWS
PI PALO ALTO
PA 4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0897 USA
SN 2333-9691
J9 ANNU REV LINGUIST
PY 2019
VL 5
BP 49
EP 66
DI 10.1146/annurev-linguistics-011718-012353
PG 18
WC Linguistics; Language & Linguistics
SC Linguistics
GA BM1MT
UT WOS:000460289100003
DA 2021-02-24
ER

PT S
AU Yu, ACL
   Zellou, G
AF Yu, Alan C. L.
   Zellou, Georgia
BE Liberman, M
   Partee, BH
TI Individual Differences in Language Processing: Phonology
SO ANNUAL REVIEW OF LINGUISTICS, VOL 5
SE Annual Review of Linguistics
LA English
DT Article; Book Chapter
DE individual differences; phonological processing; speech production;
   speech perception; cognitive processing style; sound change
ID SPEECH-PERCEPTION; ATTENTIONAL MODULATION; NASAL COARTICULATION;
   SELECTIVE ATTENTION; DEPENDENT VARIATION; INHIBITORY SKILL; COGNITIVE
   STYLES; ENGLISH; AUTISM; DISCRIMINATION
AB Individual variation is ubiquitous and empirically observable in most phonological behaviors, yet relatively few studies aim to capture the heterogeneity of language processing among individuals, as opposed to those focusing primarily on group-level patterns. The study of individual differences can shed light on the nature of the cognitive representations and mechanisms involved in phonological processing. To guide our review of individual variation in the processing of phonological information, we consider studies that can illuminate broader issues in the field, such as the nature of linguistic representations and processes. We also consider how the study of individual differences can provide insight into long-standing issues in linguistic variation and change. Since linguistic communities are made up of individuals, the questions raised by examining individual differences in linguistic processing are relevant to those who study all aspects of language.
C1 [Yu, Alan C. L.] Univ Chicago, Dept Linguist, Phonol Lab, Chicago, IL 60637 USA.
   [Zellou, Georgia] Univ Calif Davis, Dept Linguist, Davis, CA 95616 USA.
RP Yu, ACL (corresponding author), Univ Chicago, Dept Linguist, Phonol Lab, Chicago, IL 60637 USA.
EM aclyu@uchicago.edu; gzellou@ucdavis.edu
OI Zellou, Georgia/0000-0001-9167-0744
CR Abdullaev YG, 1997, NEUROSCI LETT, V234, P151, DOI 10.1016/S0304-3940(97)00680-0
   Allen JS, 2003, J ACOUST SOC AM, V113, P544, DOI 10.1121/1.1528172
   American Psychiatric Association (APA), 2013, DIAGN STAT MAN MENT
   AUSBURN LJ, 1978, ECTJ-EDUC COMMUN TEC, V26, P337
   Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001
   Bailey TM, 2001, J MEM LANG, V44, P568, DOI 10.1006/jmla.2000.2756
   Baker A, 2011, LANG VAR CHANGE, V23, P347, DOI 10.1017/S0954394511000135
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Beddor PS, 2009, LANGUAGE, V85, P785
   Beddor PS, 1999, J ACOUST SOC AM, V106, P2868, DOI 10.1121/1.428111
   Bidelman GM, 2013, NEUROIMAGE, V79, P201, DOI 10.1016/j.neuroimage.2013.04.093
   Bishop J, 2015, P 18 INT C PHON SCI
   BISHOP J, 2012, UCLA WORKING PAPERS, V111, P1
   Bishop J., 2013, THESIS U CALIF LOS A
   Bonnel A, 2003, J COGNITIVE NEUROSCI, V15, P226, DOI 10.1162/089892903321208169
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   BYRD D, 1992, J ACOUST SOC AM, V92, P593, DOI 10.1121/1.404271
   Chandrasekaran B, 2010, PSYCHOPHYSIOLOGY, V47, P236, DOI 10.1111/j.1469-8986.2009.00928.x
   Chodroff E, 2017, J PHONETICS, V61, P30, DOI 10.1016/j.wocn.2017.01.001
   Coetzee AW, 2018, J PHONETICS, V66, P185, DOI 10.1016/j.wocn.2017.09.009
   Constantino JN, 2003, ARCH GEN PSYCHIAT, V60, P524, DOI 10.1001/archpsyc.60.5.524
   Conway ARA, 2001, PSYCHON B REV, V8, P331, DOI 10.3758/BF03196169
   Davidson L, 2011, J EXP PSYCHOL HUMAN, V37, P270, DOI 10.1037/a0020988
   DELL GS, 1986, PSYCHOL REV, V93, P283, DOI 10.1037/0033-295X.93.3.283
   Diaz B, 2008, P NATL ACAD SCI USA, V105, P16083, DOI 10.1073/pnas.0805022105
   Eckert Penelope, 1989, LANG VAR CHANGE, V1, P245, DOI [DOI 10.1017/S095439450000017X, 10.1017/S095439450000017X]
   Eichenbaum H, 2001, BEHAV BRAIN RES, V127, P199, DOI 10.1016/S0166-4328(01)00365-5
   Eichenbaum H., 2001, CONDITIONING CONSCIO
   Escudero P, 2004, STUD SECOND LANG ACQ, V26, P551, DOI 10.1017/S0272226310400021
   Ettlinger M, 2012, APPL PSYCHOLINGUIST, V35, P1
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   Foulkes P, 2006, J PHONETICS, V34, P409, DOI 10.1016/j.wocn.2005.08.002
   Fowler CA, 2006, PERCEPT PSYCHOPHYS, V68, P161, DOI 10.3758/BF03193666
   Fowler CA, 2000, PERCEPT PSYCHOPHYS, V62, P21, DOI 10.3758/BF03212058
   Francis AL, 2002, J EXP PSYCHOL HUMAN, V28, P349, DOI 10.1037//0096-1523.28.2.349
   FRISCH SA, 2001, FREQUENCY EMERGENCE, P159, DOI DOI 10.1075/TSL
   Fuchs S., 2015, INDIVIDUAL DIFFERENC, P123, DOI DOI 10.3726/978-3-653-05777-5
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Garrett A, 2013, PHONETIC BIASES SOUN
   GOLDINGER SD, 1989, J MEM LANG, V28, P501, DOI 10.1016/0749-596X(89)90009-0
   GORDON PC, 1993, COGNITIVE PSYCHOL, V25, P1, DOI 10.1006/cogp.1993.1001
   Grosvald M, 2012, APPL PSYCHOLINGUIST, V33, P55, DOI 10.1017/S0142716411000105
   Happe F, 1999, TRENDS COGN SCI, V3, P216, DOI 10.1016/S1364-6613(99)01318-2
   Happe F, 2006, J AUTISM DEV DISORD, V36, P5, DOI 10.1007/s10803-005-0039-0
   Hornickel J, 2009, P NATL ACAD SCI USA, V106, P13022, DOI 10.1073/pnas.0901123106
   Huang HC, 2007, THESIS U EDINBURGH U
   Idemaru K, 2012, J ACOUST SOC AM, V132, P3950, DOI 10.1121/1.4765076
   JOHNSON K, 1993, J ACOUST SOC AM, V94, P701, DOI 10.1121/1.406887
   Jun SA, 2015, STUD THEOR PSYCHOLIN, V46, P217, DOI 10.1007/978-3-319-12961-7_12
   Kapnoula EE, 2016, THESIS U IOWA IOWA C
   Kataoka R, 2011, THESIS U CALIF BERKE
   Kim Y.H., 2010, NEW SOUNDS 2010, P251
   KING J, 1991, J MEM LANG, V30, P580, DOI 10.1016/0749-596X(91)90027-H
   Klatt DH, 1986, INVARIANCE VARIABILI, P300
   Kong EJ, 2018, LANG SPEECH, V61, P384, DOI 10.1177/0023830917729840
   Kong EJ, 2016, J PHONETICS, V59, P40, DOI 10.1016/j.wocn.2016.08.006
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   Labov W., 1994, PRINCIPLES LINGUISTI, V1
   Labov W., 2001, PRINCIPLES LINGUISTI, V2
   Labov W., 2006, ATLAS N AM ENGLISH P
   Labov W, 1979, INDIVIDUAL DIFFERENC, P327
   Labov W, 2011, J SOCIOLING, V15, P431, DOI 10.1111/j.1467-9841.2011.00504.x
   Large NR, 1998, RES SPOKEN LANG P, V22, P95
   Lavie N, 2004, J EXP PSYCHOL GEN, V133, P339, DOI 10.1037/0096-3445.133.3.339
   Lev-Ari S, 2018, Q J EXP PSYCHOL, V71, P2249, DOI 10.1177/1747021817739865
   Lev-Ari S, 2016, J ACOUST SOC AM, V139, P3076, DOI 10.1121/1.4950811
   Lev-Ari S, 2014, J PHONETICS, V47, P36, DOI 10.1016/j.wocn.2014.09.001
   Lev-Ari S, 2013, J PHONETICS, V41, P320, DOI 10.1016/j.wocn.2013.06.002
   Levon E, 2014, J ENGL LINGUIST, V42, P185, DOI 10.1177/0075424214531487
   LEWELLEN MJ, 1993, J EXP PSYCHOL GEN, V122, P316, DOI 10.1037/0096-3445.122.3.316
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Lisker L, 1970, P 6 INT C PHON SCI P, P569
   Lotto AJ, 2006, PERCEPT PSYCHOPHYS, V68, P178, DOI 10.3758/BF03193667
   Luce P, 1998, AM PSYCHOL SOC, V9, P325
   MASSARO DW, 1983, J EXP PSYCHOL HUMAN, V9, P753, DOI 10.1037/0096-1523.9.5.753
   McMurray B, 2014, J SPEECH LANG HEAR R, V57, P1344, DOI 10.1044/2014_JSLHR-L-13-0196
   McMurray B, 2010, COGNITIVE PSYCHOL, V60, P1, DOI 10.1016/j.cogpsych.2009.06.003
   Messick S., 1976, INDIVIDUALITY LEARNI
   Mielke J, 2016, LANGUAGE, V92, P101, DOI 10.1353/lan.2016.0019
   MILROY J, 1985, J LINGUIST, V21, P339, DOI 10.1017/S0022226700010306
   Miyake A, 2012, CURR DIR PSYCHOL SCI, V21, P8, DOI 10.1177/0963721411429458
   Mottron L, 2006, J AUTISM DEV DISORD, V36, P27, DOI 10.1007/s10803-005-0040-7
   Myers EB, 2008, CEREB CORTEX, V18, P278, DOI 10.1093/cercor/bhm053
   Naatanen R, 2001, PSYCHOPHYSIOLOGY, V38, P1, DOI 10.1017/S0048577201000208
   Newman RS, 2001, J ACOUST SOC AM, V109, P1181, DOI 10.1121/1.1348009
   Newman RS, 1997, THESIS SUNY BUFFALO
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Nycz J, 2011, THESIS NYU
   OHALA JJ, 1993, LANG SPEECH, V36, P155, DOI 10.1177/002383099303600303
   Ohala John, 1981, PAPERS PARASESSION L, P178
   Ohala John J., 1994, SOUND SYMBOLISM, P325
   Perkell JS, 2004, J SPEECH LANG HEAR R, V47, P1259, DOI 10.1044/1092-4388(2004/095)
   Perkell JS, 2004, J ACOUST SOC AM, V116, P2338, DOI 10.1121/1.1787524
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Pitt MA, 1998, PERCEPT PSYCHOPHYS, V60, P941, DOI 10.3758/BF03211930
   Prichard H, 2012, U PENNSYLVANIA WORKI, V18, P11
   REPP BH, 1981, PERCEPT PSYCHOPHYS, V30, P217, DOI 10.3758/BF03214276
   Riding RJ, 2000, INT PERSPECTIVES IND, V1
   Sachs J., 1973, LANGUAGE ATTITUDES C, P74
   Scarborough R, 2012, LINGUA, V122, P164, DOI 10.1016/j.lingua.2011.06.006
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   Shankweiler D, 1977, PERCEIVING ACTING KN, P315
   Shultz AA, 2012, J ACOUST SOC AM, V132, pEL95, DOI 10.1121/1.4736711
   Skoe E, 2010, EAR HEARING, V31, P302, DOI 10.1097/AUD.0b013e3181cdb272
   Sonderegger M, 2017, LANGUAGE, V93, P598, DOI 10.1353/lan.2017.0038
   Song JH, 2011, CLIN NEUROPHYSIOL, V122, P346, DOI 10.1016/j.clinph.2010.07.009
   Stevens M, 2014, LOQUENS, V1, DOI 10.3989/loquens.2014.003
   Stewart ME, 2008, COGNITION, V109, P157, DOI 10.1016/j.cognition.2008.07.010
   Stoesz BM, 2008, J VIS, V8, P1138
   Tettamanti M, 2005, NEUROREPORT, V16, P397, DOI 10.1097/00001756-200503150-00018
   Tilsen S, 2016, LAB PHONOL, V7, DOI 10.5334/labphon.52
   Toscano JC, 2010, PSYCHOL SCI, V21, P1532, DOI 10.1177/0956797610384142
   TREHUB SE, 1976, CHILD DEV, V47, P466, DOI 10.2307/1128803
   Tremblay K, 1998, NEUROREPORT, V9, P3557, DOI 10.1097/00001756-199811160-00003
   Turnbull R., 2015, THESIS OHIO STATE U
   Ullman MT, 1999, LANG COGNITIVE PROC, V14, P47, DOI 10.1080/016909699386374
   Viswanathan N, 2010, J EXP PSYCHOL HUMAN, V36, P1005, DOI 10.1037/a0018391
   Vitevitch MS, 2016, ANNU REV LINGUIST, V2, P75, DOI 10.1146/annurev-linguistics-030514-124832
   Vorperian HK, 2011, J SPEECH LANG HEAR R, V54, P995, DOI 10.1044/1092-4388(2010/10-0097)
   Wagner SE, 2012, LANG VAR CHANGE, V24, P179, DOI 10.1017/S0954394512000099
   Weinreich U., 1968, DIRECTIONS HIST LING, P95
   Werker J., 1994, INFANT BEHAV DEV, V7, P49
   *WHO, 1994, INT CLASS DIS
   WITKIN HA, 1977, REV EDUC RES, V47, P1
   Wong PCM, 2007, HUM BRAIN MAPP, V28, P995, DOI 10.1002/hbm.20330
   Wong PCM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0064983
   Yu A. C. L., 2013, ORIGINS SOUND CHANGE, P201, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0010
   Yu ACL, 2016, J ACOUST SOC AM, V139, P1672, DOI 10.1121/1.4944992
   Yu ACL, 2014, J ACOUST SOC AM, V136, P382, DOI 10.1121/1.4883380
   Yu ACL, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011950
   Yutaka N, 2015, PROCEEDINGS OF THE 22ND INTERNATIONAL CONGRESS ON SOUND AND VIBRATION
   Zellou G, 2017, J PHONETICS, V61, P13, DOI 10.1016/j.wocn.2016.12.002
   Zellou G, 2016, J ACOUST SOC AM, V140, P3560, DOI 10.1121/1.4966232
   Zellou G, 2014, J PHONETICS, V47, P18, DOI 10.1016/j.wocn.2014.09.002
NR 137
TC 7
Z9 7
U1 2
U2 10
PU ANNUAL REVIEWS
PI PALO ALTO
PA 4139 EL CAMINO WAY, PO BOX 10139, PALO ALTO, CA 94303-0897 USA
SN 2333-9691
J9 ANNU REV LINGUIST
PY 2019
VL 5
BP 131
EP 150
DI 10.1146/annurev-linguistics-011516-033815
PG 20
WC Linguistics; Language & Linguistics
SC Linguistics
GA BM1MT
UT WOS:000460289100007
DA 2021-02-24
ER

PT J
AU MacCutcheon, D
   Hurtig, A
   Pausch, F
   Hygge, S
   Fels, J
   Ljung, R
AF MacCutcheon, Douglas
   Hurtig, Anders
   Pausch, Florian
   Hygge, Staffan
   Fels, Janina
   Ljung, Robert
TI Second language vocabulary level is related to benefits for second
   language listening comprehension under lower reverberation time
   conditions
SO JOURNAL OF COGNITIVE PSYCHOLOGY
LA English
DT Article
DE Reverberation time; listening comprehension; second language learners;
   classroom acoustics
ID WORKING-MEMORY CAPACITY; INDIVIDUAL-DIFFERENCES; COGNITIVE PERFORMANCE;
   SPEECH-PERCEPTION; NOISE; RECOGNITION; ENGLISH; KNOWLEDGE; AIRCRAFT;
   RECALL
AB The acoustic qualities of a room can have a deleterious effect on the quality of speech signals. The acoustic measurement of reverberation time (RT) has shown to impact second language (L2) speech comprehension positively when lower due to release from spectral and temporal masking effects as well as top-down processing factors. This auralization experiment investigated the benefits of better L2 vocabulary and executive function (updating) skills during L2 listening comprehension tests under shorter versus longer RT conditions (0.3 and 0.9s). 57 bilingual university students undertook L2 vocabulary, number updating and L2 listening comprehension tests. After splitting groups into high/low vocabulary and updating groups, a mixed ANOVA was conducted. The high number updating group showed no significant differences or interactions in L2 listening comprehension than the lower number updating group across RT conditions. The high vocabulary group had 22% better L2 listening comprehension than the low vocabulary group in long RT, and 9% better in short RT. A significant benefit in L2 listening comprehension due to release from reverberation was only evident in the high vocabulary group. Results indicate that the benefit of good room acoustics for listening comprehension is greatest for those with better language (vocabulary) ability.
C1 [MacCutcheon, Douglas; Hurtig, Anders; Hygge, Staffan; Ljung, Robert] Univ Gavle, Fac Engn & Sustainable Dev, Dept Bldg Energy & Environm Engn, Environm Psychol, Gavle, Sweden.
   [Pausch, Florian; Fels, Janina] Rhein Westfal TH Aachen, Inst Tech Acoust Teaching & Res Area Med Acoust, Aachen, Germany.
RP MacCutcheon, D (corresponding author), Univ Gavle, Fac Engn & Sustainable Dev, Dept Bldg Energy & Environm Engn, Environm Psychol, Gavle, Sweden.
EM Douglas.MacCutcheon@hig.se
RI Pausch, Florian/Q-2244-2019; Pausch, Florian/T-1017-2016
OI Pausch, Florian/0000-0003-2728-3170; Pausch,
   Florian/0000-0003-2728-3170; MacCutcheon, Douglas/0000-0002-4947-4579;
   Fels, Janina/0000-0002-8694-7750; Hurtig, Anders/0000-0002-2730-7200
FU European UnionEuropean Commission [FP7-607139]
FX The research leading to these results has received funding from the
   European Union Seventh Framework Programme (FP7/2007-2013) under Grant
   Agreement FP7-607139 (iCARE).
CR [Anonymous], 2008, 338222008 ISO
   BRADLEY JS, 1986, J ACOUST SOC AM, V80, P846, DOI 10.1121/1.393908
   Bradlow AR, 2002, J ACOUST SOC AM, V112, P272, DOI 10.1121/1.1487837
   Carretti B, 2005, J EXP CHILD PSYCHOL, V91, P45, DOI 10.1016/j.jecp.2005.01.005
   Carretti B, 2007, BRIT J PSYCHOL, V98, P45, DOI 10.1348/000712606X104175
   DANEMAN M, 1986, J MEM LANG, V25, P1, DOI 10.1016/0749-596X(86)90018-5
   Daneman M, 1996, PSYCHON B REV, V3, P422, DOI 10.3758/BF03214546
   DANEMAN M, 1980, J VERB LEARN VERB BE, V19, P450, DOI 10.1016/S0022-5371(80)90312-6
   DIN, 2010, 45631A1201003 DIN
   ENGLE RW, 1992, J EXP PSYCHOL LEARN, V18, P972, DOI 10.1037/0278-7393.18.5.972
   ENGLE RW, 1990, J EDUC PSYCHOL, V82, P799, DOI 10.1037/0022-0663.82.4.799
   Engle RW, 2002, CURR DIR PSYCHOL SCI, V11, P19, DOI 10.1111/1467-8721.00160
   Erickson G., 2009, NATL ASSESSMENT FORE
   Everest F.A., 2015, MASTER HDB ACOUSTICS, V6th ed.
   Field J., 2004, SYSTEM, V32, P363, DOI DOI 10.1016/J.SYSTEM.2004.05.002
   Field J., 2003, ELT J, V57, P325, DOI DOI 10.1093/ELT/57.4.325
   Finkbeiner M, 2006, BILING-LANG COGN, V9, P153, DOI 10.1017/S1366728906002501
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   Hurtig A, 2016, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.02029
   Hygge S, 2002, PSYCHOL SCI, V13, P469, DOI 10.1111/1467-9280.00483
   Hygge S, 2003, APPL COGNITIVE PSYCH, V17, P895, DOI 10.1002/acp.926
   ISO, 1975, 5321975EN ISO
   Kaplan E, 2001, BOSTON NAMING TEST
   Kilman L, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00651
   Kjellberg A, 2004, Noise Health, V7, P11
   Klatte M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00578
   Klatte M, 2010, NOISE HEALTH, V12, P270, DOI 10.4103/1463-1741.70506
   Kuttruff H., 2016, ROOM ACOUSTICS
   Ljung R., 2010, THESIS
   Ljung R, 2009, BUILD ACOUST, V16, P301, DOI 10.1260/135101009790291273
   Ljung R, 2009, BUILD ACOUST, V16, P257, DOI 10.1260/135101009789877031
   Miyake A, 2000, COGNITIVE PSYCHOL, V41, P49, DOI 10.1006/cogp.1999.0734
   Moore B.C., 2012, INTRO PSYCHOL HEARIN
   Muijselaar MML, 2015, LEARN INDIVID DIFFER, V43, P111, DOI 10.1016/j.lindif.2015.08.011
   NABELEK AK, 1984, J ACOUST SOC AM, V75, P632
   Nilsson S., 2016, ENGELSKA 6 EXEMPEL U
   Ormrod JE, 1988, READ RES INSTRUCT, V28, P33, DOI DOI 10.1080/19388078809557956
   Palladino P, 2001, MEM COGNITION, V29, P344, DOI 10.3758/BF03194929
   Pelzer S, 2014, BUILD ACOUST, V21, P65, DOI 10.1260/1351-010X.21.1.65
   Peng ZE, 2016, J ACOUST SOC AM, V139, P2772, DOI 10.1121/1.4948564
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Rudner M, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/869726
   Scheuerle J, 2000, EDUC GERONTOL, V26, P237, DOI 10.1080/036012700267222
   SCHMITZ A, 1995, ACUSTICA, V81, P416
   Schroder D., 2011, PHYS BASED REAL TIME, V11
   Sorqvist P, 2014, SCAND J PSYCHOL, V55, P91, DOI 10.1111/sjop.12115
   Sorqvist P, 2010, APPL COGNITIVE PSYCH, V24, P67, DOI 10.1002/acp.1543
   Staehr LS, 2009, STUD SECOND LANG ACQ, V31, P577, DOI 10.1017/S0272263109990039
   Stansfeld SA, 2005, LANCET, V365, P1942, DOI 10.1016/S0140-6736(05)66660-3
   TAKATA Y, 1990, J ACOUST SOC AM, V88, P663, DOI 10.1121/1.399769
   TURNER ML, 1989, J MEM LANG, V28, P127, DOI 10.1016/0749-596X(89)90040-5
   Vorlander M, 2007, AURALIZATION FUNDAME
   Wiley J, 2012, PSYCHOL LEARN MOTIV, V56, P185, DOI 10.1016/B978-0-12-394393-4.00006-6
   WINGFIELD A, 1994, LANG SPEECH, V37, P221, DOI 10.1177/002383099403700301
NR 54
TC 1
Z9 1
U1 5
U2 9
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2044-5911
EI 2044-592X
J9 J COGN PSYCHOL
JI J. Cogn. Psychol.
PY 2019
VL 31
IS 2
BP 175
EP 185
DI 10.1080/20445911.2019.1575387
PG 11
WC Psychology, Experimental
SC Psychology
GA HP3BL
UT WOS:000461550600004
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Chan, KY
   Chiu, MM
   Dailey, BA
   Jalil, DM
AF Chan, Kit Ying
   Chiu, Ming Ming
   Dailey, Brady A.
   Jalil, Daroon M.
TI Effect of Foreign Accent on Immediate Serial Recall
SO EXPERIMENTAL PSYCHOLOGY
LA English
DT Article
DE serial recall; foreign accent; speech perception; short-term memory;
   listening effort
ID PRECATEGORICAL ACOUSTIC STORAGE; SHORT-TERM-MEMORY; NEIGHBORHOOD
   ACTIVATION; SPOKEN WORDS; LONG-TERM; SPEECH; INTELLIGIBILITY;
   RECOGNITION; PERCEPTION; COMPREHENSIBILITY
AB This study disentangled factors contributing to impaired memory for foreign-accented words - misperception and disruption of encoding. When native English and Cantonese-accented words were presented auditorily for serial recall (Experiment 1), intrusion errors for accented words were higher across all serial positions (SPs). Participants made more intrusion errors during auditory presentation than visual and auditory presentation, and more errors for accented words than native words. Lengthening the interstimulus intervals in Experiment 2 reduced intrusion, repetition, order, and omission errors in the middle and late SPs during accented word recall, suggesting that extra time is required for identification and encoding of accented words into memory. Analyses of the intrusions showed that a majority of them were misperceptions and sounded similar to the stimulus words. These findings suggest that effortful perceptual processing of accented speech can induce perceptual difficulty and interfere with downstream memory processes by exhausting the shared pool of working memory.
C1 [Chan, Kit Ying] City Univ Hong Kong, Dept Social & Behav Sci, Acad 1 Y7419,Tat Chee Ave, Hong Kong, Peoples R China.
   [Chiu, Ming Ming] Educ Univ Hong Kong, Dept Special Educ & Counselling, Hong Kong, Peoples R China.
   [Dailey, Brady A.] Boston Univ, Dept Linguist, Boston, MA 02215 USA.
   [Jalil, Daroon M.] Old Dominion Univ, Dept Psychol, Norfolk, VA USA.
RP Chan, KY (corresponding author), City Univ Hong Kong, Dept Social & Behav Sci, Acad 1 Y7419,Tat Chee Ave, Hong Kong, Peoples R China.
EM vivien.chanky@cityu.edu.hk
OI Chan, Kit Ying/0000-0002-5386-9020; Chiu, Ming/0000-0002-5721-1971
CR BADDELEY AD, 1966, Q J EXP PSYCHOL, V18, P302, DOI 10.1080/14640746608400047
   Benjamini Y, 2006, BIOMETRIKA, V93, P491, DOI 10.1093/biomet/93.3.491
   Bent T, 2003, J ACOUST SOC AM, V114, P1600, DOI 10.1121/1.1603234
   Boersma P., 2009, PRAAT DOING PHONETIC
   CARAMAZZA A, 1973, J ACOUST SOC AM, V54, P421, DOI 10.1121/1.1913594
   Chan KY, 2015, J EXP PSYCHOL HUMAN, V41, P69, DOI 10.1037/a0038347
   Charlton C, 2017, MLWIN VERSION 3 00
   Cho KW, 2013, MENT LEX, V8, P295, DOI 10.1075/ml.8.3.02cho
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   CONRAD R, 1968, PSYCHON SCI, V10, P135
   Cousins KAQ, 2014, MEM COGNITION, V42, P622, DOI 10.3758/s13421-013-0377-7
   CROWDER RG, 1969, PERCEPT PSYCHOPHYS, V5, P365, DOI 10.3758/BF03210660
   FLEGE JE, 1984, J ACOUST SOC AM, V76, P708, DOI 10.1121/1.391257
   Francis AL, 2009, ATTEN PERCEPT PSYCHO, V71, P1360, DOI 10.3758/APP.71.6.1360
   Frankish C, 2008, J MEM LANG, V58, P815, DOI 10.1016/j.jml.2007.06.003
   Gill M. M., 1994, J APPL COMMUNICATION, V22, P348, DOI DOI 10.1080/00909889409365409
   GLANZER M, 1966, J VERB LEARN VERB BE, V5, P351, DOI 10.1016/S0022-5371(66)80044-0
   Goldstein H., 2011, MULTILEVEL STAT MODE, V922
   Hendry L, 2005, MEMORY, V13, P364, DOI 10.1080/09658210344000341
   Henson RNA, 1998, J EXP PSYCHOL LEARN, V24, P1162, DOI 10.1037/0278-7393.24.5.1162
   Hurlstone MJ, 2014, PSYCHOL BULL, V140, P339, DOI 10.1037/a0034221
   Imai S, 2005, J ACOUST SOC AM, V117, P896, DOI 10.1121/1.1823291
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   McCormack T, 2000, J EXP CHILD PSYCHOL, V76, P222, DOI 10.1006/jecp.1999.2550
   MUNRO MJ, 1995, LANG LEARN, V45, P73, DOI 10.1111/j.1467-1770.1995.tb00963.x
   Munro MJ, 1998, LANG LEARN, V48, P159, DOI 10.1111/1467-9922.00038
   Munro MJ, 1995, LANG SPEECH, V38, P289, DOI 10.1177/002383099503800305
   MURDOCK BB, 1962, J EXP PSYCHOL, V64, P482, DOI 10.1037/h0045106
   Neisser Ulric, 2014, COGNITIVE PSYCHOL CL
   NYGAARD LC, 1995, PERCEPT PSYCHOPHYS, V57, P989, DOI 10.3758/BF03205458
   Perception Research Systems, 2007, PARADIGM
   Pickel KL, 2012, LAW HUMAN BEHAV, V36, P140, DOI 10.1037/h0093968
   RABBITT PMA, 1968, Q J EXP PSYCHOL, V20, P241, DOI 10.1080/14640746808400158
   Reed M., 2000, J ED, V182, P67, DOI DOI 10.1177/002205740018200306
   Reinisch E, 2014, J EXP PSYCHOL HUMAN, V40, P539, DOI 10.1037/a0034409
   Riazantseva A., 2001, STUDIES 2 LANGUAGE A, V23, P497, DOI DOI 10.1017/S027226310100403X
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Roodenrys S, 2008, MEM COGNITION, V36, P578, DOI 10.3758/MC.36.3.578
   Surprenant AM, 2007, AGING NEUROPSYCHOL C, V14, P126, DOI 10.1080/13825580701217710
   Surprenant AM, 1999, INT J PSYCHOL, V34, P328, DOI 10.1080/002075999399648
   Temple L, 2000, STUD LINGUISTICA, V54, P288, DOI 10.1111/1467-9582.00068
   Van Engen KJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00577
   van Wijngaarden SJ, 2001, SPEECH COMMUN, V35, P103, DOI 10.1016/S0167-6393(00)00098-4
   Vitevitch MS, 2012, J MEM LANG, V67, P30, DOI 10.1016/j.jml.2012.02.008
   Vitevitch MS, 1999, J MEM LANG, V40, P374, DOI 10.1006/jmla.1998.2618
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
   Witteman MJ, 2014, PSYCHON B REV, V21, P512, DOI 10.3758/s13423-013-0519-8
NR 48
TC 1
Z9 1
U1 1
U2 6
PU HOGREFE & HUBER PUBLISHERS
PI GOTTINGEN
PA MERKELSTR 3, D-37085 GOTTINGEN, GERMANY
SN 1618-3169
EI 2190-5142
J9 EXP PSYCHOL
JI Exp. Psychol.
PD JAN
PY 2019
VL 66
IS 1
BP 40
EP 57
DI 10.1027/1618-3169/a000430
PG 18
WC Psychology, Experimental
SC Psychology
GA HN0CG
UT WOS:000459851800004
PM 30777508
DA 2021-02-24
ER

PT J
AU Tremblay, P
   Perron, M
   Deschamps, I
   Kennedy-Higgins, D
   Houde, JC
   Dick, AS
   Descoteaux, M
AF Tremblay, Pascale
   Perron, Maxime
   Deschamps, Isabelle
   Kennedy-Higgins, Dan
   Houde, Jean-Christophe
   Dick, Anthony Steven
   Descoteaux, Maxime
TI The role of the arcuate and middle longitudinal fasciculi in speech
   perception in noise in adulthood
SO HUMAN BRAIN MAPPING
LA English
DT Article
DE cognitive aging; diffusion MRI; HARDI; hearing; language; normal aging;
   speech discrimination; white matter
ID WHITE-MATTER INTEGRITY; AGE-RELATED DIFFERENCES; NEURAL-NETWORK MODEL;
   DIFFUSION-TENSOR; HUMAN BRAIN; HEARING-LOSS; CONSONANT RECOGNITION;
   CLINICAL-IMPLICATIONS; CORTICAL MECHANISMS; PREMOTOR CORTEX
AB In this article, we used High Angular Resolution Diffusion Imaging (HARDI) with advanced anatomically constrained particle filtering tractography to investigate the role of the arcuate fasciculus (AF) and the middle longitudinal fasciculus (MdLF) in speech perception in noise in younger and older adults. Fourteen young and 15 elderly adults completed a syllable discrimination task in the presence of broadband masking noise. Mediation analyses revealed few effects of age on white matter (WM) in these fascicles but broad effects of WM on speech perception, independently of age, especially in terms of sensitivity and criterion (response bias), after controlling for individual differences in hearing sensitivity and head size. Indirect (mediated) effects of age on speech perception through WM microstructure were also found, after controlling for individual differences in hearing sensitivity and head size, with AF microstructure related to sensitivity, response bias and phonological priming, and MdLF microstructure more strongly related to response bias. These findings suggest that pathways of the perisylvian region contribute to speech processing abilities, with relatively distinct contributions for the AF (sensitivity) and MdLF (response bias), indicative of a complex contribution of both phonological and cognitive processes to age-related speech perception decline. These results provide new and important insights into the roles of these pathways as well as the factors that may contribute to elderly speech perception deficits. They also highlight the need for a greater focus to be placed on studying the role of WM microstructure to understand cognitive aging.
C1 [Tremblay, Pascale; Perron, Maxime; Deschamps, Isabelle; Kennedy-Higgins, Dan] CERVO Brain Res Ctr, Quebec City, PQ, Canada.
   [Tremblay, Pascale; Deschamps, Isabelle] Univ Laval, Dept Readaptat, Fac Med, Quebec City, PQ, Canada.
   [Kennedy-Higgins, Dan] UCL, Dept Speech Hearing & Phonet Sci, London, England.
   [Houde, Jean-Christophe; Descoteaux, Maxime] Univ Sherbrooke, Dept Informat, Fac Sci, Sherbrooke Connect Imaging Lab, Sherbrooke, PQ, Canada.
   [Dick, Anthony Steven] Florida Int Univ, Dept Psychol, Miami, FL 33199 USA.
RP Tremblay, P (corresponding author), Univ Laval, Dept Readaptat, 1050 Ave Med,Off 4109, Quebec City, PQ G1V 0A6, Canada.
EM pascale.tremblay@fmed.ulaval.ca
OI Tremblay, Pascale/0000-0001-7161-9255; Kennedy-Higgins,
   Dan/0000-0002-7499-8833
FU Fonds de la Recherche en Sante du QuebecFonds de la Recherche en Sante
   du Quebec [27170, 35016]; Natural Sciences and Engineering Research
   Council of CanadaNatural Sciences and Engineering Research Council of
   Canada (NSERC)CGIAR [195812603]; Quebec Bio-imaging network [5886];
   Brain Canada Foundation [3456]
FX Fonds de la Recherche en Sante du Quebec, Grant/Award Number: 27170,
   35016; Natural Sciences and Engineering Research Council of Canada,
   Grant/Award Number: Discovery Grant (#195812603); Quebec Bio-imaging
   network, Grant/Award Number: Pilot project grant #5886; Brain Canada
   Foundation, Grant/Award Number: Platform support grant (#3456)
CR Adank P, 2010, NEUROIMAGE, V49, P1124, DOI 10.1016/j.neuroimage.2009.07.032
   Alexander AL, 2001, MAGN RESON MED, V45, P770, DOI 10.1002/mrm.1105
   Alexander DC, 2002, MAGN RESON MED, V48, P331, DOI 10.1002/mrm.10209
   Andersson JLR, 2016, NEUROIMAGE, V125, P1063, DOI 10.1016/j.neuroimage.2015.10.019
   Andersson JLR, 2003, NEUROIMAGE, V20, P870, DOI 10.1016/S1053-8119(03)00336-7
   Andrews-Hanna JR, 2007, NEURON, V56, P924, DOI 10.1016/j.neuron.2007.10.038
   Avants B.B., 2011, ADV NORMALIZATION TO
   Bartzokis G, 2004, NEUROBIOL AGING, V25, P5, DOI 10.1016/j.neurobiolaging.2003.03.001
   BASSER PJ, 1994, J MAGN RESON SER B, V103, P247, DOI 10.1006/jmrb.1994.1037
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bennett IJ, 2014, NEUROSCIENCE, V276, P187, DOI 10.1016/j.neuroscience.2013.11.026
   Berwick RC, 2013, TRENDS COGN SCI, V17, P89, DOI 10.1016/j.tics.2012.12.002
   Bilodeau-Mercure M, 2015, BRAIN STRUCT FUNCT, V220, P979, DOI 10.1007/s00429-013-0695-3
   Bishop CW, 2009, J COGNITIVE NEUROSCI, V21, P1790, DOI 10.1162/jocn.2009.21118
   Brauer J, 2013, BRAIN LANG, V127, P289, DOI 10.1016/j.bandl.2013.03.001
   Brown AS, 1996, AM J PSYCHOL, V109, P79, DOI 10.2307/1422928
   BURKE DM, 1991, J MEM LANG, V30, P542, DOI 10.1016/0749-596X(91)90026-G
   Burks JD, 2017, BRAIN BEHAV, V7, DOI 10.1002/brb3.640
   Callan D, 2010, NEUROIMAGE, V51, P844, DOI 10.1016/j.neuroimage.2010.02.027
   Carlson MDA, 2009, J PALLIAT MED, V12, P77, DOI 10.1089/jpm.2008.9690
   Catani M, 2005, ANN NEUROL, V57, P8, DOI 10.1002/ana.20319
   Catani M., 2012, ATLAS HUMAN BRAIN CO
   Catani M, 2008, CORTEX, V44, P953, DOI 10.1016/j.cortex.2008.04.002
   Chang EH, 2017, NEUROIMAGE, V147, P253, DOI 10.1016/j.neuroimage.2016.11.068
   Charlton RA, 2006, NEUROLOGY, V66, P217, DOI 10.1212/01.wnl.0000194256.15247.83
   Concha L, 2006, NEUROIMAGE, V32, P1090, DOI 10.1016/j.neuroimage.2006.04.187
   Corbetta M, 2008, NEURON, V58, P306, DOI 10.1016/j.neuron.2008.04.017
   Correia JM, 2015, J NEUROSCI, V35, P15015, DOI 10.1523/JNEUROSCI.0977-15.2015
   Cote MA, 2013, MED IMAGE ANAL, V17, P844, DOI 10.1016/j.media.2013.03.009
   Cousineau M, 2017, NEUROIMAGE-CLIN, V16, P222, DOI 10.1016/j.nicl.2017.07.020
   Daducci A, 2014, IEEE T MED IMAGING, V33, P384, DOI 10.1109/TMI.2013.2285500
   de Champfleur NM, 2013, EUR J RADIOL, V82, P151, DOI 10.1016/j.ejrad.2012.05.034
   Dell'Acqua F, 2013, HUM BRAIN MAPP, V34, P2464, DOI 10.1002/hbm.22080
   Descoteaux M, 1999, WILEY ENCY ELECT ELE, DOI [10.1002/047134608X.W8258, DOI 10.1002/047134608X.W8258]
   Descoteaux M, 2008, LECT NOTES COMPUT SC, V5242, P122, DOI 10.1007/978-3-540-85990-1_15
   Descoteaux M, 2009, IEEE T MED IMAGING, V28, P269, DOI 10.1109/TMI.2008.2004424
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Deutsch GK, 2005, CORTEX, V41, P354, DOI 10.1016/S0010-9452(08)70272-7
   Dick AS, 2014, NEUROSCIENTIST, V20, P453, DOI 10.1177/1073858413513502
   Dick AS, 2012, BRAIN, V135, P3529, DOI 10.1093/brain/aws222
   Feder K, 2015, HEALTH REP, V26, P18
   Fegen D, 2015, NEUROIMAGE, V105, P120, DOI 10.1016/j.neuroimage.2014.10.034
   Fleischman DA, 2007, CORTEX, V43, P889, DOI 10.1016/S0010-9452(08)70688-9
   Fleysher R., 2017, MAGNETIC RESONANCE I, V47, P97, DOI [10.1016/j.mri.2017.11.003, DOI 10.1016/J.MRI.2017.11]
   Frank LR, 2002, MAGN RESON MED, V47, P1083, DOI 10.1002/mrm.10156
   Frisina DR, 1997, HEARING RES, V106, P95, DOI 10.1016/S0378-5955(97)00006-3
   Garyfallidis E, 2014, FRONT NEUROINFORM, V8, DOI 10.3389/fninf.2014.00008
   Gates GA, 2005, LANCET, V366, P1111, DOI 10.1016/S0140-6736(05)67423-5
   GELFAND SA, 1986, J ACOUST SOC AM, V80, P1589, DOI 10.1121/1.394323
   GELFAND SA, 1985, J ACOUST SOC AM, V78, P1198, DOI 10.1121/1.392888
   Girard G, 2014, NEUROIMAGE, V98, P266, DOI 10.1016/j.neuroimage.2014.04.074
   Gordon-Salant S, 2006, J ACOUST SOC AM, V119, P2455, DOI 10.1121/1.2171527
   GORDONSALANT S, 1986, J SPEECH HEAR RES, V29, P155, DOI 10.1044/jshr.2902.155
   GORDONSALANT S, 1993, J SPEECH HEAR RES, V36, P1276, DOI 10.1044/jshr.3606.1276
   Gough PM, 2005, J NEUROSCI, V25, P8010, DOI 10.1523/JNEUROSCI.2307-05.2005
   Grabski K, 2013, BRAIN RES, V1515, P55, DOI 10.1016/j.brainres.2013.03.024
   GUENTHER FH, 1994, BIOL CYBERN, V72, P43, DOI 10.1007/BF00206237
   Guenther FH, 2006, BRAIN LANG, V96, P280, DOI 10.1016/j.bandl.2005.06.001
   GUENTHER FH, 1995, PSYCHOL REV, V102, P594, DOI 10.1037/0033-295X.102.3.594
   Gunning-Dixon FM, 2009, INT J GERIATR PSYCH, V24, P109, DOI 10.1002/gps.2087
   Guttmann CRG, 1998, NEUROLOGY, V50, P972, DOI 10.1212/WNL.50.4.972
   Hamer PCDW, 2011, HUM BRAIN MAPP, V32, P962, DOI 10.1002/hbm.21082
   Harkrider AW, 2005, CLIN NEUROPHYSIOL, V116, P2153, DOI 10.1016/j.clinph.2005.05.016
   Hartwigsen G, 2010, NEUROPSYCHOLOGIA, V48, P3155, DOI 10.1016/j.neuropsychologia.2010.06.032
   Hayes A. F., 2018, INTRO MEDIATION MODE
   Heine MK, 1999, PSYCHOL AGING, V14, P445, DOI 10.1037/0882-7974.14.3.445
   Jerger J, 1992, J Am Acad Audiol, V3, P33
   Jeurissen B, 2013, HUM BRAIN MAPP, V34, P2747, DOI 10.1002/hbm.22099
   Jolly TAD, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00782
   Katsuki F, 2014, NEUROSCIENTIST, V20, P509, DOI 10.1177/1073858413514136
   Le Bihan D, 2001, J MAGN RESON IMAGING, V13, P534, DOI 10.1002/jmri.1076
   Lebel C, 2012, NEUROIMAGE, V60, P340, DOI 10.1016/j.neuroimage.2011.11.094
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P582, DOI 10.1093/gerona/glr002
   Liu H, 2017, AGEING RES REV, V34, P64, DOI 10.1016/j.arr.2016.11.006
   LOGAN GD, 1990, COGNITIVE PSYCHOL, V22, P1, DOI 10.1016/0010-0285(90)90002-L
   Lopez-Barroso D, 2013, P NATL ACAD SCI USA, V110, P13168, DOI 10.1073/pnas.1301696110
   MACMILLAN NA, 1990, PSYCHOL BULL, V107, P401, DOI 10.1037/0033-2909.107.3.401
   Madden DJ, 2012, BBA-MOL BASIS DIS, V1822, P386, DOI 10.1016/j.bbadis.2011.08.003
   Makris N, 2013, BRAIN IMAGING BEHAV, V7, P335, DOI 10.1007/s11682-013-9235-2
   Makris N, 2013, BRAIN STRUCT FUNCT, V218, P951, DOI 10.1007/s00429-012-0441-2
   Makris N, 2009, CEREB CORTEX, V19, P777, DOI 10.1093/cercor/bhn124
   Makris N, 2009, BRAIN STRUCT FUNCT, V213, P343, DOI 10.1007/s00429-008-0199-8
   Maldonado IL, 2013, J ANAT, V223, P38, DOI 10.1111/joa.12055
   Maldonado IL, 2011, BRAIN STRUCT FUNCT, V216, P263, DOI 10.1007/s00429-011-0309-x
   Mandonnet E, 2007, BRAIN, V130, P623, DOI 10.1093/brain/awl361
   Marner L, 2003, J COMP NEUROL, V462, P144, DOI 10.1002/cne.10714
   Mazelova J, 2003, EXP GERONTOL, V38, P87, DOI 10.1016/S0531-5565(02)00155-9
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Meyer J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0079279
   Miller S. A., 1998, DEV RES METHODS
   Mito R, 2018, BRAIN, V141, P888, DOI 10.1093/brain/awx355
   Moore BCJ, 1999, J ACOUST SOC AM, V105, P400, DOI 10.1121/1.424571
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Niogi SN, 2006, NEUROPSYCHOLOGIA, V44, P2178, DOI 10.1016/j.neuropsychologia.2006.01.011
   O'Brien LM, 2011, PSYCHIAT RES-NEUROIM, V193, P113, DOI 10.1016/j.pscychresns.2011.01.007
   O'Sullivan M, 2001, NEUROLOGY, V57, P632, DOI 10.1212/WNL.57.4.632
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Pakkenberg B, 1997, J COMP NEUROL, V384, P312, DOI 10.1002/(SICI)1096-9861(19970728)384:2<312::AID-CNE10>3.0.CO;2-K
   PLOMP R, 1979, J ACOUST SOC AM, V66, P1333, DOI 10.1121/1.383554
   Preacher KJ, 2004, BEHAV RES METH INS C, V36, P717, DOI 10.3758/BF03206553
   Preacher KJ, 2008, BEHAV RES METHODS, V40, P879, DOI 10.3758/BRM.40.3.879
   Raffelt D, 2012, NEUROIMAGE, V59, P3976, DOI 10.1016/j.neuroimage.2011.10.045
   Rastle KG, 1996, J MEM LANG, V35, P586, DOI 10.1006/jmla.1996.0031
   Reil JC., 1809, ARCH PHYSL HALLE, V9, P195
   Rheault F., 2016, P BREA5 BARR DIFF MR
   Robinson K., 2008, HDB RES METHODS DEV, P1
   Romero L, 2006, J COGNITIVE NEUROSCI, V18, P1147, DOI 10.1162/jocn.2006.18.7.1147
   Sampaio-Baptista C, 2017, NEURON, V96, P1239, DOI 10.1016/j.neuron.2017.11.026
   Sato M, 2009, BRAIN LANG, V111, P1, DOI 10.1016/j.bandl.2009.03.002
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Schacter DL, 1998, NEURON, V20, P185, DOI 10.1016/S0896-6273(00)80448-1
   SELTZER B, 1984, EXP BRAIN RES, V55, P301
   Sen PN, 2005, BIOPHYS J, V89, P2927, DOI 10.1529/biophysj.105.063016
   Sharman MA, 2011, J MAGN RESON IMAGING, V33, P1491, DOI 10.1002/jmri.22577
   Smith SM, 2004, NEUROIMAGE, V23, pS208, DOI 10.1016/j.neuroimage.2004.07.051
   Soares JM, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00031
   Stach B., 2010, CLIN AUDIOLOGY INTRO
   Steffens DC, 2017, AM J GERIAT PSYCHIAT, V25, P1135, DOI 10.1016/j.jagp.2017.03.017
   Strouse A, 1998, J ACOUST SOC AM, V104, P2385, DOI 10.1121/1.423748
   Thiebaut de Schotten M, 2011, NEUROIMAGE, V54, P49, DOI 10.1016/j.neuroimage.2010.07.055
   Toscano JC, 2019, LANG SPEECH, V62, P61, DOI 10.1177/0023830917737112
   Tournier JD, 2007, NEUROIMAGE, V35, P1459, DOI 10.1016/j.neuroimage.2007.02.016
   Tournier JD, 2011, MAGN RESON MED, V65, P1532, DOI 10.1002/mrm.22924
   Tournier JD, 2004, NEUROIMAGE, V23, P1176, DOI 10.1016/j.neuroimage.2004.07.037
   Tremblay KL, 2003, CLIN NEUROPHYSIOL, V114, P1332, DOI 10.1016/S1388-2457(03)00114-7
   Tremblay KL, 2002, NEUROREPORT, V13, P1865, DOI 10.1097/00001756-200210280-00007
   Tun PA, 1999, J GERONTOL B-PSYCHOL, V54, pP317, DOI 10.1093/geronb/54B.5.P317
   Tun PA, 1998, PSYCHOL AGING, V13, P424, DOI 10.1037/0882-7974.13.3.424
   Vallesi A, 2011, J COGNITIVE NEUROSCI, V23, P801, DOI 10.1162/jocn.2010.21490
   Vandermosten M, 2012, BRAIN, V135, P935, DOI 10.1093/brain/awr363
   Voineskos AN, 2012, NEUROBIOL AGING, V33, P21, DOI 10.1016/j.neurobiolaging.2010.02.009
   Voineskos AN, 2010, BRAIN, V133, P1494, DOI 10.1093/brain/awq040
   Vossel S, 2014, NEUROSCIENTIST, V20, P150, DOI 10.1177/1073858413494269
   Wang YB, 2013, CEREB CORTEX, V23, P2347, DOI 10.1093/cercor/bhs225
   Wassermann D, 2016, BRAIN STRUCT FUNCT, V221, P4705, DOI 10.1007/s00429-015-1179-4
   Wassermann D, 2013, LECT NOTES COMPUT SC, V8149, P647, DOI 10.1007/978-3-642-40811-3_81
   Weiner KS, 2017, CORTEX, V97, P274, DOI 10.1016/j.cortex.2016.03.012
   Wheeler-Kingshott CAM, 2009, MAGN RESON MED, V61, P1255, DOI 10.1002/mrm.21965
   Wong PCM, 2008, J SPEECH LANG HEAR R, V51, P1026, DOI 10.1044/1092-4388(2008/075)
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
   Yeatman JD, 2011, J COGNITIVE NEUROSCI, V23, P3304, DOI 10.1162/jocn_a_00061
   YESAVAGE JA, 1983, J PSYCHIATR RES, V17, P37, DOI 10.1016/0022-3956(82)90033-4
NR 143
TC 2
Z9 2
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1065-9471
EI 1097-0193
J9 HUM BRAIN MAPP
JI Hum. Brain Mapp.
PD JAN
PY 2019
VL 40
IS 1
BP 226
EP 241
DI 10.1002/hbm.24367
PG 16
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA HM9HW
UT WOS:000459795200017
PM 30277622
OA Bronze, Green Published
DA 2021-02-24
ER

PT J
AU Owsianny, M
AF Owsianny, Mariusz
TI Perceptual Identification of Polish Vowels Due to F0 Changes
SO ARCHIVES OF ACOUSTICS
LA English
DT Article
DE F0; formants; speech perception; vowel shifts; voice quality
ID SOFTWARE; FEMALE
AB The paper investigates the interdependence between the perceptual identification of the vocalic quality of six isolated Polish vowels traditionally defined by the spectral envelope and the fundamental frequency F0. The stimuli used in the listening experiments were natural female and male voices, which were modified by changing the F0 values in the +/- 1 octave range. The results were then compared with the outcome of the experiments on fully synthetic voices. Despite the differences in the generation of the investigated stimuli and their technical quality, consistent results were obtained. They confirmed the findings that in the perceptual identification of vowels of key importance is not only the position of the formants on the F1 x F2 plane but also their relationship to F0, the connection between the formants and the harmonics and other factors. The paper presents, in quantitative terms, all possible kinds of perceptual shifts of Polish vowels from one phonetic category to another in the function of voice pitch. An additional perceptual experiment was also conducted to check a broader range of F0 changes and their impact on the identification of vowels in CVC (consonant, vowel, consonant) structures. A mismatch between the formants and the glottal tone value can lead to a change in phonetic category.
C1 [Owsianny, Mariusz] Adam Mickiewicz Univ, Inst Linguist, Al Niepodleglosci 4, PL-61874 Poznan, Poland.
   [Owsianny, Mariusz] Poznan Supercomp & Networking Ctr, Jana Pawla 2 10, PL-61139 Poznan, Poland.
RP Owsianny, M (corresponding author), Adam Mickiewicz Univ, Inst Linguist, Al Niepodleglosci 4, PL-61874 Poznan, Poland.; Owsianny, M (corresponding author), Poznan Supercomp & Networking Ctr, Jana Pawla 2 10, PL-61139 Poznan, Poland.
EM marows@amu.edu.pl
FU Polish National Science Centre [2014/14/M/HS2/00631]
FX Part of the present study was carried out within the framework of the
   project "Automatic analysis of phonetic convergence in speech technology
   systems" supported by the Polish National Science Centre (no.:
   2014/14/M/HS2/00631).
CR Assmann PF, 2008, J ACOUST SOC AM, V124, P3203, DOI 10.1121/1.2980456
   Boersma P., 2013, PRAAT DOING PHONETIC
   CARLSON R, 1975, AUDITORY ANAL PERCEP, P55, DOI DOI 10.1016/B978-0-12-248550-3.50008-8
   Chistovich L. A., 1979, FRONTIERS SPEECH COM, P143
   Chladkova K, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P464
   DIBENEDETTO MG, 1994, J PHONETICS, V22, P205
   Diehl RL, 1996, J PHONETICS, V24, P187, DOI 10.1006/jpho.1996.0011
   Dlugosz-Kurczabowa K., 2006, HIST GRAMMAR POLISH, p[96, 129]
   Fant G., 1960, ACOUSTIC THEORY SPEE
   Imiolczyk J., 1991, Archives of Acoustics, V16, P305
   Jassem W., 1992, Archives of Acoustics, V17, P217
   Johnson K., 1988, RES SPEECH PERCEPTIO, V14, P81
   Johnson K., 1988, RES SPEECH PERCEPTIO, V14, P237
   Jorasz U., 1999, SELECTIVITY AUDITORY, P38
   KLATT DH, 1980, J ACOUST SOC AM, V67, P971, DOI 10.1121/1.383940
   KLATT DH, 1990, J ACOUST SOC AM, V87, P820, DOI 10.1121/1.398894
   Kortekaas RWL, 1997, J ACOUST SOC AM, V101, P2202, DOI 10.1121/1.418204
   Maurer Dieter, 2015, Journal of the Acoustical Society of America, V137, DOI 10.1121/1.4920812
   Meister E., 2009, P INTERSPEECH 2009 C, P388
   Mousa A, 2010, J ELECTR ENG-SLOVAK, V61, P57, DOI 10.2478/v10187-010-0008-5
   Obrebowski A., 2008, VOCAL ORGAN ITS IMPO
   Owsianny M., 1994, Archives of Acoustics, V19, P185
   Owsianny M., 1995, P 4 EUR C SPEECH COM, P945
   Owsianny M., 2001, PROSODY 2000, P197
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   SUNDBERG J, 1977, SCI AM, V236, P82, DOI 10.1038/scientificamerican0377-82
   SYRDAL AK, 1985, SPEECH COMMUN, V4, P121, DOI 10.1016/0167-6393(85)90040-8
   Tohkura Y., 1992, SPEECH PERCEPTION PR, P89
   TRAUNMULLER H, 1981, J ACOUST SOC AM, V69, P1465, DOI 10.1121/1.385780
NR 30
TC 0
Z9 0
U1 0
U2 6
PU POLSKA AKAD NAUK, POLISH ACAD SCIENCES, INST FUNDAMENTAL TECH RES PAS
PI WARSZAWA
PA PL DEFILAD 1, WARSZAWA, 00-901, POLAND
SN 0137-5075
EI 2300-262X
J9 ARCH ACOUST
JI Arch. Acoust.
PY 2019
VL 44
IS 1
BP 13
EP 26
DI 10.24425/aoa.2019.126348
PG 14
WC Acoustics
SC Acoustics
GA HL9GV
UT WOS:000459052100002
DA 2021-02-24
ER

PT J
AU Vermiglio, AJ
   Velappan, K
   Heeke, P
   Bulla, E
   Fang, XM
   Bonilla, E
   Garner, E
   Skinner, J
AF Vermiglio, Andrew J.
   Velappan, Keerthana
   Heeke, Paige
   Bulla, Emery
   Fang, Xiangming
   Bonilla, Elizabeth
   Garner, Elizabeth
   Skinner, Julia
TI The relationship between speech recognition in noise and non-speech
   recognition in noise test performances: Implications for central
   auditory processing disorders testing
SO JOURNAL OF COMMUNICATION DISORDERS
LA English
DT Article
DE Central auditory processing disorder; (Central) auditory processing
   disorder; Auditory processing disorder; Speech recognition in noise; FM
   system
ID HEARING-LOSS; CHILDREN; INTELLIGIBILITY; DIFFICULTIES; THRESHOLDS;
   VALIDATION; PERCEPTION
AB Background: According to the American Academy of Audiology, a recommendation for frequency-modulation systems may be based upon performances on speech perception tests that do not include background noise.
   Purpose: The primary purpose of this study was to evaluate the presumption that non-speech recognition in noise test results are related to speech recognition in noise ability for a group of young adults.
   Research design: Performances on the non-speech recognition in noise tests included in the SCAN-3:A test battery were compared to speech recognition in noise performances as measured with the auditory figure ground subtest of the SCAN-3:A and the Hearing in Noise Test.
   Study sample: Fifty-four young, native speakers of American English with normal pure-tone thresholds participated in the study.
   Data collection and analysis: For the purposes of this study, the SCAN-3:A raw scores were used. The Hearing in Noise Test was administered in a simulated soundfield environment under headphones. The Spearman rho statistic was used to determine the relationships between non speech recognition in noise vs. speech recognition in noise test results.
   Results: No significant relationships were found between the auditory figure-ground results and any of the non-speech recognition in noise subtest performances. Modest but statistically significant relationships were found between the Hearing in Noise Test Composite scores vs. the competing words-directed ear and the time compressed sentences subtests of the SCAN-3:A.
   Conclusion: Of the four non-speech recognition in noise subtests that were evaluated, only the competing words-directed ear and the time-compressed sentences performances were significantly correlated to the Composite scores of the Hearing in Noise Test. The results demonstrated a limited external validity for two of the four non-SRN tests for the determination of SRN ability.
C1 [Vermiglio, Andrew J.; Velappan, Keerthana; Heeke, Paige; Bulla, Emery; Bonilla, Elizabeth; Garner, Elizabeth; Skinner, Julia] East Carolina Univ, Dept Commun Sci & Disorders, 3310P Hlth Sci Bldg,Mail Stop 668, Greenville, NC 27834 USA.
   [Fang, Xiangming] East Carolina Univ, Dept Biostat, Greenville, NC 27834 USA.
RP Vermiglio, AJ (corresponding author), East Carolina Univ, Dept Commun Sci & Disorders, 3310P Hlth Sci Bldg,Mail Stop 668, Greenville, NC 27834 USA.
EM vermiglioa@ecu.edu
CR AAA, 2010, AM AC AUD CLIN PRACT
   AAA, 2011, REM MICR HEAR ASS TE, P1
   American Speech-Language-Hearing Association [ASHA], 2005, CENTR AUD PROC DIS
   ASHA, 2002, ASHA DESK REFERENCE, V2, P151
   Attias J., 2013, ISSAR AUD PLAST LIST
   Bamiou DE, 2006, NEUROLOGY, V67, P614, DOI 10.1212/01.wnl.0000230197.40410.db
   Beasley W. C, 1940, J ACOUSTICAL SOC AM, V12
   Bellis TJ, 2008, CONT ISSUES COMMUN S, V35, P143
   BLAETTNER U, 1989, BRAIN, V112, P177, DOI 10.1093/brain/112.1.177
   BOCCA E., 1955, ACTA OTO LARYNGOL, V45, P289, DOI 10.3109/00016485509124282
   Bossuyt PM, 2003, CROAT MED J, V44, P639
   BSA - British Society of Audiology, 2011, POS STAT AUD PROC DI
   Cameron S, 2007, EAR HEARING, V28, P196, DOI 10.1097/AUD.0b013e318031267f
   CAMPBELL DT, 1959, PSYCHOL BULL, V56, P81, DOI 10.1037/h0046016
   CARHART R, 1946, J ACOUST SOC AM, V17, P339, DOI 10.1121/1.1916338
   Chermak G. D., 2001, HEARING J, V54, P10
   DICKSON E D D, 1946, J Laryngol Otol, V61, P139, DOI 10.1017/S0022215100007830
   Dillon H, 2012, J AM ACAD AUDIOL, V23, P97, DOI 10.3766/jaaa.23.2.4
   EGAN JP, 1948, J ACOUST SOC AM, V20, P58, DOI 10.1121/1.1906348
   FABRY DA, 1994, EAR HEARING, V15, P82, DOI 10.1097/00003446-199402000-00009
   Flanagan S, 2018, TRENDS HEAR, V22, DOI 10.1177/2331216518756533
   Fry DB., 1942, J LARYNGOL OTOL, V57, P11, DOI 10.1017/S0022215100044339
   Giraud AL, 1997, NEUROREPORT, V8, P1779, DOI 10.1097/00001756-199705060-00042
   Hinchcliffe R., 1992, J AUDIOL MED, V1, P89
   Hind S, 2008, AUDIOGICAL MED, V6, P207
   HorTech, 2013, MATR SENT TEST AM EN
   Jerger J, 2000, J Am Acad Audiol, V11, P467
   JERGER J, 1975, SCAND AUDIOL, V4, P147, DOI DOI 10.3109/01050397509043077
   Jerger J., 2008, AUDIOLOGY SCI PRACTI, P333
   Johnson M. L., 2007, AUDITORY PROCESSING, P75
   Johnston KN, 2009, INT J AUDIOL, V48, P371, DOI 10.1080/14992020802687516
   KALIKOW DN, 1977, J ACOUST SOC AM, V61, P1337, DOI 10.1121/1.381436
   KATZ J, 1963, ANN OTO RHINOL LARYN, V72, P908, DOI 10.1177/000348946307200405
   Keith R, 2009, SCAN 3 ADOLESCENTS
   Keith R. W., 1986, SCAN SCREENING TEST
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   KIMURA D, 1961, CAN J PSYCHOLOGY, V15, P156, DOI 10.1037/h0083218
   Kuk F, 2008, J AM ACAD AUDIOL, V19, P465, DOI 10.3766/jaaa.19.6.3
   Kukull WA, 2012, NEUROLOGY, V78, P1886, DOI 10.1212/WNL.0b013e318258f812
   Kurdziel S, 1976, J Am Audiol Soc, V2, P3
   LaBossiere M. C, 2011, 30 MORE FALLACIES VE
   Lagace J, 2011, INT J AUDIOL, V50, P385, DOI 10.3109/14992027.2011.553204
   MANNE SL, 1992, PAIN, V48, P45, DOI 10.1016/0304-3959(92)90130-4
   MIDDELWEERD MJ, 1990, AUDIOLOGY, V29, P1
   Mishra SK, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00860
   Musiek F E, 1992, J Am Acad Audiol, V3, P5
   MUSIEK FE, 1990, AUDIOLOGY, V29, P304
   Myklebust H, 1954, AUDITORY DISORDERS C
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Niquette P., 2003, AM AUD SOC
   Normandin N, 1983, SSI ELABORATION VERS
   POST, 2001, PEAC OFF STAND TRAIN
   Pryce H, 2010, INT J AUDIOL, V49, P473, DOI 10.3109/14992021003627892
   ROSS M, 1971, AM ANN DEAF, V116, P580
   Rudmin F, 1983, HUMAN COMMUNICATION, V3, P348
   Saunders GH, 2004, EAR HEARING, V25, P117, DOI 10.1097/01.AUD.0000120360.05510.E5
   Schaette R, 2011, J NEUROSCI, V31, P13452, DOI 10.1523/JNEUROSCI.2156-11.2011
   Sinha P. S, 1959, ROLE TEMPORAL LOBE H
   Soli SD, 2008, INT J AUDIOL, V47, P356, DOI 10.1080/14992020801895136
   Spahr AJ, 2012, EAR HEARING, V33, P112, DOI 10.1097/AUD.0b013e31822c2549
   Steinberg JC, 1940, BELL SYST TECH J, V19, P533, DOI 10.1002/j.1538-7305.1940.tb00845.x
   Stilma W, 2019, NURS CRIT CARE, V24, P132, DOI 10.1111/nicc.12225
   Stoody TM, 2018, AM J AUDIOL, V27, P238, DOI 10.1044/2018_AJA-17-0098
   Swets J A, 2000, Psychol Sci Public Interest, V1, P1, DOI 10.1111/1529-1006.001
   Thibodeau L, 2014, AM J AUDIOL, V23, P201, DOI 10.1044/2014_AJA-13-0065
   Vermiglio AJ, 2007, SPEECH RECOGNITION N
   Vermiglio AJ, 2008, INT J AUDIOL, V47, P386, DOI 10.1080/14992020801908251
   Vermiglio AJ, 2018, J AM ACAD AUDIOL, V29, P634, DOI 10.3766/jaaa.17034
   Vermiglio AJ, 2018, J AM ACAD AUDIOL, V29, P206, DOI 10.3766/jaaa.16128
   Vermiglio AJ, 2016, J AM ACAD AUDIOL, V27, P141, DOI 10.3766/jaaa.15079
   Vermiglio AJ, 2012, J AM ACAD AUDIOL, V23, P779, DOI 10.3766/jaaa.23.10.4
   Wilson RH, 2007, J AM ACAD AUDIOL, V18, P522
NR 72
TC 0
Z9 0
U1 0
U2 6
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0021-9924
EI 1873-7994
J9 J COMMUN DISORD
JI J. Commun. Disord.
PD JAN-FEB
PY 2019
VL 77
BP 31
EP 43
DI 10.1016/j.jcomdis.2018.12.004
PG 13
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA HL1OS
UT WOS:000458469400003
PM 30594730
DA 2021-02-24
ER

PT J
AU Imafuku, M
   Kawai, M
   Niwa, F
   Shinya, Y
   Myowa, M
AF Imafuku, Masahiro
   Kawai, Masahiko
   Niwa, Fusako
   Shinya, Yuta
   Myowa, Masako
TI Audiovisual speech perception and language acquisition in preterm
   infants: A longitudinal study
SO EARLY HUMAN DEVELOPMENT
LA English
DT Article
DE Preterm infants; Audiovisual speech perception; Language acquisition;
   Longitudinal study; Eye-tracking
ID CHILDREN BORN; PHONETIC INFORMATION; GESTATIONAL-AGE; TERM INFANTS;
   FULL-TERM; ATTENTION; LIPS; DISCRIMINATION; RECOGNITION; BEHAVIORS
AB Background: Preterm infants have a higher risk of language delay throughout childhood. The ability to integrate audiovisual speech information is associated with language acquisition in term infants; however, the relation is still unclear in preterm infant.
   Aim and methods: This study longitudinally investigated visual preference for audiovisual congruent and incongruent speech during a preferential looking task using eye-tracking in preterm and term infants at 6, 12, and 18 months of corrected age. The infante receptive and expressive vocabulary at 12 and 18 months were obtained by parent report, using the Japanese MacArthur Communicative Development Inventory.
   Results: We found that preterm infants did not clearly show visual preference for the congruent audiovisual display at any age, whereas term infants looked at the congruent audiovisual display longer than the incongruent audiovisual display at 6 and 18 months. Preterm infante receptive and expressive vocabulary scores were lower than those of term infants at 12 and 18 months. Furthermore, the proportion of looking time toward the congruent audiovisual display at 6 months was positively correlated with receptive vocabulary scores at 12 and 18 months for both groups.
   Conclusions: These findings suggest that better audiovisual speech perception abilities are one factor that results in better language acquisition in preterm as well as term infants. Early identification of behaviors associated with later language in preterm infants may contribute to planning intervention for developmental problems.
C1 [Imafuku, Masahiro; Shinya, Yuta; Myowa, Masako] Kyoto Univ, Grad Sch Educ, Kyoto, Japan.
   [Imafuku, Masahiro] Musashino Univ, Fac Educ, 1-1-20 Shin Machi, Nishitokyo, Tokyo 2028585, Japan.
   [Kawai, Masahiko; Niwa, Fusako] Kyoto Univ, Grad Sch Med, Dept Pediat, Kyoto, Japan.
   [Shinya, Yuta] Univ Tokyo, Grad Sch Educ, Tokyo, Japan.
RP Imafuku, M (corresponding author), Musashino Univ, Fac Educ, 1-1-20 Shin Machi, Nishitokyo, Tokyo 2028585, Japan.
EM masahiro.imafuku@gmail.com
RI Myowa, Masako/E-8965-2010
OI Shinya, Yuta/0000-0002-5229-1554; Kawai, Masahiko/0000-0002-3347-5155
FU JSPS KAKENHIMinistry of Education, Culture, Sports, Science and
   Technology, Japan (MEXT)Japan Society for the Promotion of
   ScienceGrants-in-Aid for Scientific Research (KAKENHI) [24119005,
   17H01016, 17J07474, 13J04767]; Center of Innovation Program from the
   Japan Science and Technology Agency, JST; Maekawa Houonkai Foundation;
   Musashino University Research Fund
FX We thank all the children and their parents who participated in this
   research at Kyoto University. The research is supported by JSPS KAKENHI
   Grant Numbers 24119005, 17H01016 to M. M., 17J07474, 13J04767 to M. I.,
   the Center of Innovation Program from the Japan Science and Technology
   Agency, JST to M. M., the Maekawa Houonkai Foundation to M. M.
   (2015-2017), and Musashino University Research Fund to M. I. (2018).
CR Altvater-Mackensen N, 2016, NEUROIMAGE, V133, P14, DOI 10.1016/j.neuroimage.2016.02.061
   Altvater-Mackensen N, 2015, CHILD DEV, V86, P362, DOI 10.1111/cdev.12320
   Aram D. M., 1999, J SPEECH LANG HEAR R, V34, P1169
   Baron IS, 2009, EARLY HUM DEV, V85, P751, DOI 10.1016/j.earlhumdev.2009.10.002
   Bebko JM, 2006, J CHILD PSYCHOL PSYC, V47, P88, DOI 10.1111/j.1469-7610.2005.01443.x
   Bergvall N, 2006, PEDIATRICS, V117, pE460, DOI 10.1542/peds.2005-0737
   D'Onofrio BM, 2013, JAMA PSYCHIAT, V70, P1231, DOI 10.1001/jamapsychiatry.2013.2107
   De Schuymer L, 2012, INFANT BEHAV DEV, V35, P129, DOI 10.1016/j.infbeh.2011.08.002
   DODD B, 1979, COGNITIVE PSYCHOL, V11, P478, DOI 10.1016/0010-0285(79)90021-5
   Feldman R, 2006, DEV PSYCHOL, V42, P175, DOI 10.1037/0012-1649.42.1.175
   Fenson L., 1993, MACARTHUR COMMUNICAT
   Foster-Cohen S, 2007, J CHILD LANG, V34, P655, DOI 10.1017/S0305000907008070
   Guiraud JA, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036428
   Harel H, 2011, INFANCY, V16, P69, DOI 10.1111/j.1532-7078.2010.00037.x
   Imafuku M., 2018, PSYCHOLOGIA, V59
   Imafuku M, 2017, INFANCY, V22, P223, DOI 10.1111/infa.12144
   Kubicek C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089275
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Kushnerenko E, 2008, P NATL ACAD SCI USA, V105, P11442, DOI 10.1073/pnas.0804275105
   Landry SH, 1997, DEV PSYCHOL, V33, P1040, DOI 10.1037/0012-1649.33.6.1040
   Levine TA, 2015, PEDIATRICS, V135, P126, DOI 10.1542/peds.2014-1143
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Luoma L, 1998, DEV MED CHILD NEUROL, V40, P380
   Naoi N, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00094
   OGURA T, 1998, RES DEV EARLY LANGUA
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Patterson ML, 1999, INFANT BEHAV DEV, V22, P237, DOI 10.1016/S0163-6383(99)00003-X
   PICKENS J, 1994, INFANT BEHAV DEV, V17, P447, DOI 10.1016/0163-6383(94)90036-1
   Pinto-Martin JA, 2011, PEDIATRICS, V128, P883, DOI 10.1542/peds.2010-2846
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Rahkonen P, 2015, ACTA PAEDIATR, V104, P522, DOI 10.1111/apa.12911
   Rosenblum LD, 1997, PERCEPT PSYCHOPHYS, V59, P347, DOI 10.3758/BF03211902
   Sansavini A, 2011, NEUROPSYCHOLOGIA, V49, P3677, DOI 10.1016/j.neuropsychologia.2011.09.023
   SEKIYAMA K, 1993, J PHONETICS, V21, P427, DOI 10.1016/S0095-4470(19)30229-3
   Sekiyama K, 2004, INT 2004 8 INT C SPO
   Shaw K, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126059
   Shinya Y, 2016, DEV PSYCHOBIOL, V58, P724, DOI 10.1002/dev.21412
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Telford EJ, 2016, J CHILD PSYCHOL PSYC, V57, P861, DOI 10.1111/jcpp.12546
   Therien JM, 2004, DEV MED CHILD NEUROL, V46, P816, DOI 10.1017/S0012162204001434
   van de Weijer-Bergsma EV, 2008, INFANT BEHAV DEV, V31, P333, DOI 10.1016/j.infbeh.2007.12.003
   Walker SM, 2009, PAIN, V141, P79, DOI 10.1016/j.pain.2008.10.012
   Weatherhead D, 2017, COGNITION, V160, P103, DOI 10.1016/j.cognition.2017.01.002
   Wickremasinghe AC, 2013, J PERINATOL, V33, P631, DOI 10.1038/jp.2013.12
   Wolke D, 2008, J PEDIATR, V152, P256, DOI 10.1016/j.jpeds.2007.06.043
NR 45
TC 3
Z9 3
U1 0
U2 6
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0378-3782
EI 1872-6232
J9 EARLY HUM DEV
JI Early Hum. Dev.
PD JAN
PY 2019
VL 128
BP 93
EP 100
DI 10.1016/j.earlhumdev.2018.11.001
PG 8
WC Obstetrics & Gynecology; Pediatrics
SC Obstetrics & Gynecology; Pediatrics
GA HK6MH
UT WOS:000458094300015
PM 30541680
DA 2021-02-24
ER

PT J
AU Penido, FA
   Rothe-Neves, R
AF Penido, Fabiana A.
   Rothe-Neves, Rui
TI Developmental Changes in Cue Weighting for Voiceless Sibilants in
   Brazilian Portuguese
SO LANGUAGE LEARNING AND DEVELOPMENT
LA English
DT Article
ID SPEECH-PERCEPTION; CHILDREN; FRICATIVES; ADULTS; SHIFTS
AB An important issue regarding developmental changes in cue weighting is whether children weight the dynamic cue of vowel formant transitions relatively more than do adults, whereas adults depend more on the static cue of the fricative noise level. We investigated this issue in Brazilian Portuguese. Additionally, we inserted the segment to be classified as either [?] or [s] in words versus pseudo-words. Results show that age affects the use of fricative noise level, but not of vowel transition, at least after the four years of age. These results favor the view that phonetic differences are essential for the task at hand, not only within a language but also cross-linguistically. A significant main effect of lexical status means that the experience with one's language is crucial for the distinction of phonetic segments, something so far absent from studies on developmental changes in cue weighting.
C1 [Penido, Fabiana A.] Univ Fed Minas Gerais, Fac Letras, Programa Posgrad Estudos Linguist POSLIN, Belo Horizonte, MG, Brazil.
   [Rothe-Neves, Rui] Univ Fed Minas Gerais, Fac Letras, Lab Fonet, Ave Antonio Carlos 6627, BR-31270217 Belo Horizonte, MG, Brazil.
RP Rothe-Neves, R (corresponding author), Univ Fed Minas Gerais, Fac Letras, Lab Fonet, Ave Antonio Carlos 6627, BR-31270217 Belo Horizonte, MG, Brazil.
EM rothe-neves@ufmg.br
RI ROTHE-NEVES, RUI/V-6051-2018; ROTHE-NEVES, RUI/ABC-8343-2020
OI ROTHE-NEVES, RUI/0000-0002-8896-8862; ROTHE-NEVES,
   RUI/0000-0002-8896-8862
FU CNPq grantNational Council for Scientific and Technological Development
   (CNPq) [Bolsa Pq 312277/2015-6]; CAPES grant; Fundo de Apoio Academico,
   Faculdade de Letras; Pro-Reitoria de Pesquisa, Universidade Federal de
   Minas Gerais
FX The research presented here was made possible by a CNPq grant to the
   second author (Bolsa Pq 312277/2015-6), by a CAPES grant to the first
   author for abroad studies at the University of Edinburgh and by the
   financial support of the Fundo de Apoio Academico, Faculdade de Letras,
   and Pro-Reitoria de Pesquisa, Universidade Federal de Minas Gerais.
CR Andre C., 2003, P 15 INT C PHON SCI, P1421
   Barbosa P. A., 2004, J INT PHON ASSOC, V34, P227, DOI DOI 10.1017/S0025100304001756
   BEHRENS SJ, 1988, J PHONETICS, V16, P295, DOI 10.1016/S0095-4470(19)30504-2
   Boersma P., 2011, PRAAT DOING PHONETIC
   Davis H, 1970, HEARING AND DEAFNESS
   DEMANRIQUE AMB, 1981, J ACOUST SOC AM, V69, P1145, DOI 10.1121/1.385694
   Ernestus M, 2014, LINGUA, V142, P27, DOI 10.1016/j.lingua.2012.12.006
   Field A., 2013, DISCOVERING STAT USI
   Gerrits E., 2001, THESIS
   Haupt C., 2008, LETRAS LETRAS, V24, P59
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   Hernandorena C. L. M., 1997, LETRAS HOJE, V32, P7
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Hume Elizabeth V., 2001, ROLE SPEECH PERCEPTI, P251
   Jesus LMT, 2002, J PHONETICS, V30, P437, DOI 10.1006/jpho.2002.0169
   John Fox, 2003, J STAT SOFTW, V8, P1, DOI DOI 10.18637/JSS.V008.I15
   Johnson K., 2005, UC BERKELEY PHONOLOG, P289
   Johnson K, 2010, J PHONETICS, V38, P127, DOI 10.1016/j.wocn.2009.11.001
   Johnson K, 2006, J PHONETICS, V34, P485, DOI 10.1016/j.wocn.2005.08.004
   JUSCZYK PW, 1993, COGNITIVE MODELS OF SPEECH PROCESSING: THE SECOND SPERLONGA MEETING, P27
   JUSCZYK PW, 1995, J EXP PSYCHOL HUMAN, V21, P822
   Lacerda F., 1995, P 13 INT C PHON SCI, V2, P140
   LOFTUS GR, 1994, PSYCHON B REV, V1, P476, DOI 10.3758/BF03210951
   Mayo C, 2005, J ACOUST SOC AM, V118, P1730, DOI 10.1121/1.1979451
   Mayo C, 2004, J ACOUST SOC AM, V115, P3184, DOI 10.1121/1.1738838
   McQueen JM, 2012, LANG LEARN DEV, V8, P317, DOI 10.1080/15475441.2011.641887
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   NITTROUER S, 1992, J PHONETICS, V20, P351, DOI 10.1016/S0095-4470(19)30639-4
   Nittrouer S, 1997, J ACOUST SOC AM, V101, P2253, DOI 10.1121/1.418207
   Nittrouer S, 1996, J SPEECH HEAR RES, V39, P278, DOI 10.1044/jshr.3902.278
   Nittrouer S, 1997, J ACOUST SOC AM, V102, P572, DOI 10.1121/1.419730
   Nittrouer S, 2000, PERCEPT PSYCHOPHYS, V62, P266, DOI 10.3758/BF03205548
   Nittrouer S, 2002, J ACOUST SOC AM, V112, P711, DOI 10.1121/1.1496082
   NITTROUER S, 1987, J SPEECH HEAR RES, V30, P319, DOI 10.1044/jshr.3003.319
   Nittrouer S., 1993, J ACOUST SOC AM, V94, pS1865
   Nittrouer S, 2006, J ACOUST SOC AM, V120, P1799, DOI 10.1121/1.2335273
   Northern  J. L, 1989, AUDICAO EM CRIANCAS, P101
   Oliveira C. T. F, 2002, THESIS
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Pierrehumbert JB, 2003, LANG SPEECH, V46, P115, DOI 10.1177/00238309030460020501
   R development core team, 2017, R LANGUAGE ENV STAT
   Rothe-Neves R, 2018, REV ESTUD LING, V26, P793, DOI 10.17851/2237-2083.26.2.793-842
   Russo  I. C. P, 1993, PERCEPCAO FALA ANAL
   Savio C. B., 2001, THESIS
   Sussman JE, 2001, J ACOUST SOC AM, V109, P1173, DOI 10.1121/1.1349428
   Vagges K., 1978, J ITALIAN LINGUISTIC, V3, P69
   Wedel A, 2012, LANG COGN, V4, P319, DOI 10.1515/langcog-2012-0018
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3_1
   Yavas M, 2002, AVALIACAO FONOLOGICA
NR 50
TC 0
Z9 0
U1 0
U2 1
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1547-5441
EI 1547-3341
J9 LANG LEARN DEV
JI Lang. Learn. Dev.
PY 2019
VL 15
IS 1
BP 1
EP 13
DI 10.1080/15475441.2018.1469987
PG 13
WC Psychology, Developmental; Linguistics; Language & Linguistics;
   Psychology, Experimental
SC Psychology; Linguistics
GA HK9RJ
UT WOS:000458329200001
DA 2021-02-24
ER

PT J
AU de Klerk, M
   de Bree, E
   Kerkhoff, A
   Wijnen, F
AF de Klerk, Maartje
   de Bree, Elise
   Kerkhoff, Annemarie
   Wijnen, Frank
TI Lost and Found: Decline and Reemergence of Non-Native Vowel
   Discrimination in the First Year of Life
SO LANGUAGE LEARNING AND DEVELOPMENT
LA English
DT Article
ID LANGUAGE SPEECH-PERCEPTION; BILINGUAL INFANTS; ASSIMILATION; EXPERIENCE;
   CONTRASTS
AB Our aim was to investigate perceptual attunement (PA) in vowel perception of Dutch-learning infants (6-8-10-month-olds) using the hybrid visual fixation paradigm (Houston et al., 2007). Infants were habituated to one phoneme and subsequently tested on items in which a token of the habituated phoneme alternated with either another token of the same phoneme, or a token from another phonemic category. Habituation involved tokens of multiple speakers. Infants were tested on a native (/a?/-/e?/) and non-native (//-/ae/) contrast. The 6-month-olds (n=38), 8-month-olds (n=44) and 10-month-olds (n=35) discriminated the native contrast. The non-native contrast was discriminated by the group of 6-month-olds (n=42) but not the 8-month-olds (n=47), in line with PA. However, the 10-month-olds (n=39) also showed discrimination. We conclude that discrimination of phonetic categories can occur after perceptual attunement; discrimination performance is sensitive to tasks applied.
C1 [de Klerk, Maartje; Kerkhoff, Annemarie; Wijnen, Frank] Univ Utrecht, UiL OTS, Trans 10, NL-3512 JK Utrecht, Netherlands.
   [de Bree, Elise] Univ Amsterdam, RICDE, Amsterdam, Netherlands.
RP de Klerk, M (corresponding author), Univ Utrecht, UiL OTS, Trans 10, NL-3512 JK Utrecht, Netherlands.
EM m.k.a.deklerk@uu.nl
OI de Klerk, Maartje/0000-0002-5466-6196; Wijnen,
   Frank/0000-0002-7196-6000; de Bree, Elise/0000-0001-5258-7518
FU Nederlandse Organisatie voor Wetenschappelijk OnderzoekNetherlands
   Organization for Scientific Research (NWO)European Commission
   [360-70-270]
FX This work was supported by the Nederlandse Organisatie voor
   Wetenschappelijk Onderzoek [360-70-270].
CR Adank P, 2004, J ACOUST SOC AM, V116, P1729, DOI 10.1121/1.1779271
   Albareda-Castellot B, 2011, DEVELOPMENTAL SCI, V14, P395, DOI 10.1111/j.1467-7687.2010.00989.x
   [Anonymous], 2008, COGNITION, V106, P833, DOI 10.1016/j.cognition.2007.05.002
   Best C, 2000, INT C INF STUD BRIGH, P16
   Best C.T., 1998, INFANT BEHAV DEV, V21, P295, DOI [10.1016/S0163, DOI 10.1016/S0163, DOI 10.1016/S0163-6383(98)91508-9]
   Best C.T., 1994, DEV SPEECH PERCEPTIO, P167
   Best CC, 2003, LANG SPEECH, V46, P183, DOI 10.1177/00238309030460020701
   BEST CT, 1995, INFANT BEHAV DEV, V18, P339, DOI 10.1016/0163-6383(95)90022-5
   Boersma P, 2015, PRAAT DOING PHONETIC
   Bosch L, 2003, LANG SPEECH, V46, P217, DOI 10.1177/00238309030460020801
   Broersma M, 2011, Q J EXP PSYCHOL, V64, P74, DOI 10.1080/17470218.2010.499174
   Burns TC, 2007, APPL PSYCHOLINGUIST, V28, P455, DOI 10.1017/S0142716407070257
   Cheour M, 1998, NAT NEUROSCI, V1, P351, DOI 10.1038/1561
   Colombo J, 2009, NEUROBIOL LEARN MEM, V92, P225, DOI 10.1016/j.nlm.2008.06.002
   Deterding David, 1997, J INT PHON ASSOC, V27, P47, DOI [DOI 10.1017/S0025100300005417, 10.1017/S0025100300005417]
   Dijkstra N., 2010, BOST U C LANG DEV BO
   Estes KG, 2015, DEV PSYCHOL, V51, P1517, DOI 10.1037/a0039725
   Heeren W. F. L., 2006, THESIS
   Houston DM, 2007, INFANCY, V12, P119, DOI 10.1111/j.1532-7078.2007.tb00237.x
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Liu LQ, 2015, INFANT BEHAV DEV, V38, P27, DOI 10.1016/j.infbeh.2014.12.004
   Lively  S. E, 1993, J EXPT PSYCHOL LEARN, V24, P732, DOI [10.1121/1.408177, DOI 10.1121/1.408177]
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   Mazuka R, 2014, DEV PSYCHOBIOL, V56, P192, DOI 10.1002/dev.21193
   Narayan CR, 2010, DEVELOPMENTAL SCI, V13, P407, DOI 10.1111/j.1467-7687.2009.00898.x
   Pater J, 2004, LANGUAGE, V80, P384, DOI 10.1353/lan.2004.0141
   Pelphrey KA, 2004, DEV PSYCHOL, V40, P836, DOI 10.1037/0012-1649.40.5.836
   Polka L, 1996, J ACOUST SOC AM, V100, P577, DOI 10.1121/1.415884
   Polka L, 2001, J ACOUST SOC AM, V109, P2190, DOI 10.1121/1.1362689
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Polka L, 2011, J PHONETICS, V39, P467, DOI 10.1016/j.wocn.2010.08.007
   Potter CE, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01587
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Sato Y, 2010, DEV PSYCHOL, V46, P106, DOI 10.1037/a0016718
   Schouten M. E. H, 1975, THESIS
   Sebastian-Galles N, 2009, DEVELOPMENTAL SCI, V12, P874, DOI 10.1111/j.1467-7687.2009.00829.x
   Singh L, 2004, J MEM LANG, V51, P173, DOI 10.1016/j.jml.2004.04.004
   Sundara M, 2008, COGNITION, V108, P232, DOI 10.1016/j.cognition.2007.12.013
   Tsuji S, 2014, DEV PSYCHOBIOL, V56, P179, DOI 10.1002/dev.21179
   Tyler MD, 2014, PHONETICA, V71, P4, DOI 10.1159/000356237
   Tyler MD, 2014, DEV PSYCHOBIOL, V56, P210, DOI 10.1002/dev.21195
   Veenker T. J. G, 2008, ZEP EXPT CONTROL APP
   Vukatana E, 2015, INFANCY, V20, P548, DOI 10.1111/infa.12092
   Werker J. F., 1994, DEV SPEECH PERCEPTIO
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1988, DEV PSYCHOL, V24, P672, DOI 10.1037/0012-1649.24.5.672
NR 47
TC 1
Z9 1
U1 0
U2 1
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1547-5441
EI 1547-3341
J9 LANG LEARN DEV
JI Lang. Learn. Dev.
PY 2019
VL 15
IS 1
BP 14
EP 31
DI 10.1080/15475441.2018.1497490
PG 18
WC Psychology, Developmental; Linguistics; Language & Linguistics;
   Psychology, Experimental
SC Psychology; Linguistics
GA HK9RJ
UT WOS:000458329200002
OA Bronze, Green Published
DA 2021-02-24
ER

PT J
AU Borrie, SA
   Barrett, TS
   Yoho, SE
AF Borrie, Stephanie A.
   Barrett, Tyson S.
   Yoho, Sarah E.
TI Autoscore: An open-source automated tool for scoring listener perception
   of speech
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID INTELLIGIBILITY; NOISE; HEARING; FAMILIARIZATION; RECOGNITION;
   INFORMATION; ADAPTATION; CHILDREN; ADULTS; OLDER
AB Speech perception studies typically rely on trained research assistants to score orthographic listener transcripts for words correctly identified. While the accuracy of the human scoring protocol has been validated with strong intra- and inter-rater reliability, the process of hand-scoring the transcripts is time-consuming and resource intensive. Here, an open-source computer-based tool for automated scoring of listener transcripts is built (Autoscore) and validated on three different human-scored data sets. Results show that not only is Autoscore highly accurate, achieving approximately 99% accuracy, but extremely efficient. Thus, Autoscore affords a practical research tool, with clinical application, for scoring listener intelligibility of speech. (C) 2019 Acoustical Society of America.
C1 [Borrie, Stephanie A.; Yoho, Sarah E.] Utah State Univ, Dept Commun Disorders & Deaf Educ, Logan, UT 84322 USA.
   [Barrett, Tyson S.] Utah State Univ, Dept Psychol, Logan, UT 84322 USA.
RP Borrie, SA (corresponding author), Utah State Univ, Dept Commun Disorders & Deaf Educ, Logan, UT 84322 USA.
EM stephanie.borrie@usu.edu
OI Barrett, Tyson/0000-0002-2137-1391; Borrie,
   Stephanie/0000-0002-2336-0071
FU National Institute of Deafness and Other Communication Disorders,
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R21 DC 016084];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R21DC016084] Funding Source: NIH
   RePORTER
FX This paper was written with partial support from the National Institute
   of Deafness and Other Communication Disorders, National Institutes of
   Health Grant No. R21 DC 016084, awarded to S.A.B. We gratefully
   acknowledge Monica Muncy, research assistant in the Speech and Auditory
   Perception Lab at Utah State University for assistance with evaluation
   accuracy. We also gratefully acknowledge Christian Stilp at the
   University of Louisville for sharing his published data set, enabling us
   to carry out an independent evaluation of Autoscore.
CR Allison KM, 2014, INT J SPEECH-LANG PA, V16, P396, DOI 10.3109/17549507.2013.876667
   [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   Bache SM, 2014, R PACKAGE VERSION 1
   Barrett TS, 2017, R J, V9, P142, DOI 10.32614/RJ-2017-037
   BILGER RC, 1984, J SPEECH HEAR RES, V27, P32, DOI 10.1044/jshr.2701.32
   Borrie SA, 2017, J SPEECH LANG HEAR R, V60, P3110, DOI 10.1044/2017_JSLHR-S-17-0127
   Borrie SA, 2017, J SPEECH LANG HEAR R, V60, P561, DOI 10.1044/2016_JSLHR-S-16-0094
   Borrie SA, 2012, LANG COGNITIVE PROC, V27, P1039, DOI 10.1080/01690965.2011.610596
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Cooke M, 2013, SPEECH COMMUN, V55, P572, DOI 10.1016/j.specom.2013.01.001
   Csardi G., 2017, R PACKAGE VERSION 1
   Davis MH, 2005, J EXP PSYCHOL GEN, V134, P222, DOI 10.1037/0096-3445.134.2.222
   Feinerer I, 2008, J STAT SOFTW, V25, P1
   FESTEN JM, 1990, J ACOUST SOC AM, V88, P1725, DOI 10.1121/1.400247
   Guediche S, 2016, J EXP PSYCHOL HUMAN, V42, P1048, DOI 10.1037/xhp0000196
   Healy EW, 2013, J ACOUST SOC AM, V134, P3029, DOI 10.1121/1.4820893
   Henry L., 2018, R PACKAGE VERSION 0
   Hogan CA, 1998, J ACOUST SOC AM, V104, P432, DOI 10.1121/1.423247
   Hustad KC, 2006, AM J SPEECH-LANG PAT, V15, P268, DOI 10.1044/1058-0360(2006/025)
   Hustad KC, 2003, J SPEECH LANG HEAR R, V46, P462, DOI 10.1044/1092-4388(2003/038)
   Huyck JJ, 2018, J SPEECH LANG HEAR R, V61, P1012, DOI 10.1044/2018_JSLHR-H-17-0252
   KILLION MC, 2001, J ACOUST SOC AM, V109, P2502, DOI DOI 10.1121/1.4744912
   Liss JM, 1998, J ACOUST SOC AM, V104, P2457, DOI 10.1121/1.423753
   Liss JM, 2002, J ACOUST SOC AM, V112, P3022, DOI 10.1121/1.1515793
   Liss JM, 2000, J ACOUST SOC AM, V107, P3415, DOI 10.1121/1.429412
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   McAuliffe MJ, 2013, J ACOUST SOC AM, V134, P1358, DOI 10.1121/1.4812764
   Muller K., 2018, R PACKAGE VERSION 1
   Munro M. J., 1998, STUDIES 2 LANGUAGE A, V20, P139, DOI DOI 10.1017/S0272263198002022
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   R Core Team, 2018, R LANG ENV STAT COMP
   Stilp CE, 2010, J ACOUST SOC AM, V128, P2112, DOI 10.1121/1.3483719
   Strand E. A., 1994, MOTOR SPEECH DISORDE, P37
   Turner C W, 1999, Am J Audiol, V8, P47, DOI 10.1044/1059-0889(1999/002)
   Tye-Murray N, 2007, EAR HEARING, V28, P656, DOI 10.1097/AUD.0b013e31812f7185
   Van Engen KJ, 2014, J SPEECH LANG HEAR R, V57, P1908, DOI 10.1044/JSLHR-H-13-0076
   Wang DL, 2009, J ACOUST SOC AM, V125, P2336, DOI 10.1121/1.3083233
   Wickham H., 2018, R PACKAGE VERSION 1
   Wickham H., 2018, R PACKAGE VERSION 0
   Wild A, 2018, AM J SPEECH-LANG PAT, V27, P222, DOI 10.1044/2017_AJSLP-17-0002
   Yoho S. E., 2018, ATTEN PERCEPT PSYCHO
   YORKSTON KM, 1990, J SPEECH HEAR DISORD, V55, P550, DOI 10.1044/jshd.5503.550
   YORKSTON KM, 1980, J COMMUN DISORD, V13, P15, DOI 10.1016/0021-9924(80)90018-0
NR 43
TC 4
Z9 4
U1 1
U2 4
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD JAN
PY 2019
VL 145
IS 1
BP 392
EP 399
DI 10.1121/1.5087276
PG 8
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA HJ9OL
UT WOS:000457528600054
PM 30710955
OA Green Published
DA 2021-02-24
ER

PT J
AU Michael, R
   Attias, J
   Raveh, E
AF Michael, Rinat
   Attias, Joseph
   Raveh, Eyal
TI Cochlear Implantation and Social-Emotional Functioning of Children with
   Hearing Loss
SO JOURNAL OF DEAF STUDIES AND DEAF EDUCATION
LA English
DT Article
ID QUALITY-OF-LIFE; DEAF-CHILDREN; MENTAL-HEALTH; SPEECH-PERCEPTION;
   OUTCOMES; LONELINESS; EXPERIENCE; INCLUSION; TEENAGERS; AGE
AB This study examined the contribution of cochlear implants (CIs) to the social-emotional functioning of children who are deaf or hard of hearing (dhh). Sixty-three parents of children who are dhh participated in the study. Thirty children were CI users and 32 used hearing aids (HAs). They completed the Strengths and Difficulties Questionnaire and a background questionnaire. Parents of children with CIs reported lower levels of hyperactivity/inattention and higher levels of pro-social behavior compared to parents of children with HAs. Additionally, older age when hearing loss was detected was related to more pro-social behavior, and age at implantation among CI users was negatively correlated with children's hyperactivity/inattention and conduct problems. These findings add to the existing knowledge about the many benefits of CIs for individuals with hearing loss and emphasize the possible impact of early implantation to children's social-emotional functioning.
C1 [Michael, Rinat] Beit Berl Coll, Beit Berl, Israel.
   [Attias, Joseph] Univ Haifa, Haifa, Israel.
   [Raveh, Eyal] Schneider Childrens Med Ctr Israel, Petah Tiqwa, Israel.
RP Michael, R (corresponding author), Beit Berl Coll, Fac Educ, IL-4490500 Beit Berl, Israel.
EM rinat.michael@beitberl.ac.il
CR Ackley R. S., 2006, ADV SPOKEN LANGUAGE, P64
   Bat-Chava Y, 2005, J CHILD PSYCHOL PSYC, V46, P1287, DOI 10.1111/j.1469-7610.2005.01426.x
   Bhatia P, 2013, J DEV BEHAV PEDIATR, V34, P15, DOI 10.1097/DBP.0b013e318279899c
   Bouchard ME, 2009, LANG LINGUIST COMPAS, V3, P1, DOI 10.1111/j.1749-818x.2008.00079.x
   CHARLSON E, 1992, AM ANN DEAF, V137, P261, DOI 10.1353/aad.2012.0447
   Connor CM, 2006, EAR HEARING, V27, P628, DOI 10.1097/01.aud.0000240640.59205.42
   Dammeyer J, 2010, J DEAF STUD DEAF EDU, V15, P50, DOI 10.1093/deafed/enp024
   Elander J, 1996, INT J METHOD PSYCH, V6, P63, DOI 10.1002/(SICI)1234-988X(199607)6:2<63::AID-MPR151>3.3.CO;2-M
   Eriks-Brophy A, 2006, VOLTA REV, V106, P53
   Fellinger J, 2009, ACTA PSYCHIAT SCAND, V120, P153, DOI 10.1111/j.1600-0447.2009.01350.x
   Fellinger J, 2008, EUR CHILD ADOLES PSY, V17, P414, DOI 10.1007/s00787-008-0683-y
   Fitzpatrick E, 2009, INT J AUDIOL, V48, P91, DOI 10.1080/14992020802516541
   Geers A, 2008, INT J AUDIOL, V47, pS21, DOI 10.1080/14992020802339167
   Geers Ann E, 2006, Adv Otorhinolaryngol, V64, P50, DOI 10.1159/000094644
   Goodman R, 1997, J CHILD PSYCHOL PSYC, V38, P581, DOI 10.1111/j.1469-7610.1997.tb01545.x
   Goodman R., 2005, HEBREW STRENGTHS DIF
   Halpin KS, 2010, J AM ACAD AUDIOL, V21, P169, DOI 10.3766/jaaa.21.3.5
   Harrison RV, 2001, SCAND AUDIOL, V30, P73, DOI 10.1080/010503901750166727
   Jeddi Zahra, 2014, Cochlear Implants Int, V15, P93, DOI 10.1179/1754762813Y.0000000060
   Kent B. A., 2003, J DEAF STUD DEAF EDU, V8, P315, DOI [DOI 10.1093/DEAFED/ENG017, 10.1093/deafed/eng017]
   Kent B, 2006, J DEAF STUD DEAF EDU, V11, P461, DOI 10.1093/deafed/enj044
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   Laugen NJ, 2016, J DEAF STUD DEAF EDU, V21, P259, DOI 10.1093/deafed/enw005
   Mansbach-Kleinfeld Ivonne, 2010, Front Psychiatry, V1, P151, DOI 10.3389/fpsyt.2010.00151
   Martin D, 2003, CHILD CARE HLTH DEV, V29, P511, DOI 10.1046/j.1365-2214.2003.00371.x
   Moeller MP, 2010, EAR HEARING, V31, P625, DOI 10.1097/AUD.0b013e3181df5cc2
   Most T, 2007, J DEAF STUD DEAF EDU, V12, P495, DOI 10.1093/deafed/enm015
   Most T, 2009, AM ANN DEAF, V154, P284
   Nicholas J. G., 2003, EAR HEAR S, V24, P692
   Potts LG, 2014, AM J AUDIOL, V23, P79, DOI 10.1044/1059-0889(2013/11-0031)
   Power D., 2002, J DEAF STUD DEAF EDU, V7, P302, DOI DOI 10.1093/DEAFED/7.4.302
   Punch R, 2011, J DEAF STUD DEAF EDU, V16, P474, DOI 10.1093/deafed/enr001
   Remine MD, 2010, AUST NZ J PSYCHIAT, V44, P351, DOI 10.3109/00048670903489866
   Schorr EA, 2006, VOLTA REV, V106, P365
   Sorkin DL, 2008, OTOL NEUROTOL, V29, P137, DOI 10.1097/mao.0b013e3181616c88
   Stevenson J, 2015, EUR CHILD ADOLES PSY, V24, P477, DOI 10.1007/s00787-015-0697-1
   STINSON M, 1999, J DEAF STUD DEAF EDU, V4, P191, DOI DOI 10.1093/DEAFED/4.3.191
   Stinson MS, 1996, J EDUC PSYCHOL, V88, P132, DOI 10.1037/0022-0663.88.1.132
   THOUTENHOOFD E, 2005, PEDIAT COCHLEAR IMPL
   Vonen A. M., 2007, CONSTRUCTING ED DISC, P108
   Wake M, 2004, AMBUL PEDIATR, V4, P411, DOI 10.1367/A03-191R.1
   White KR, 2004, AM J MED GENET A, V130A, P29, DOI 10.1002/ajmg.a.30048
   Yoshinaga-Itano C, 2003, J DEAF STUD DEAF EDU, V8, P11, DOI DOI 10.1093/DEAFED/8.1.11
NR 43
TC 5
Z9 5
U1 3
U2 11
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1081-4159
EI 1465-7325
J9 J DEAF STUD DEAF EDU
JI J. Deaf Stud. Deaf Educ.
PD JAN
PY 2019
VL 24
IS 1
BP 25
EP 31
DI 10.1093/deafed/eny034
PG 7
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA HI7TC
UT WOS:000456657900003
PM 30418621
OA Bronze
DA 2021-02-24
ER

PT J
AU Scott, H
   Batten, JP
   Kuhn, G
AF Scott, Hannah
   Batten, Jonathan P.
   Kuhn, Gustav
TI Why are you looking at me? It's because I'm talking, but mostly because
   I'm staring or not doing much
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Attention; Eye movements; Social cognition; Social attention; Audio
   visual interaction; Speech perception; Direct eye gaze
ID EYE CONTACT; GAZE; ATTENTION; FACE; CUES; RESPONSES; DIRECTION;
   FIXATION; BEHAVIOR; OVERT
AB Our attention is particularly driven toward faces, especially the eyes, and there is much debate over the factors that modulate this social attentional orienting. Most of the previous research has presented faces in isolation, and we tried to address this shortcoming by measuring people's eye movements whilst they observe more naturalistic and varied social interactions. Participants' eye movements were monitored whilst they watched three different types of social interactions (monologue, manual activity, active attentional misdirection), which were either accompanied by the corresponding audio as speech or by silence. Our results showed that (1) participants spent more time looking at the face when the person was giving a monologue, than when he/she was carrying out manual activities, and in the latter case they spent more time fixating on the person's hands. (2) Hearing speech significantly increases the amount of time participants spent looking at the face (this effect was relatively small), although this was not accounted for by any increase in mouth-oriented gaze. (3) Participants spent significantly more time fixating on the face when direct eye contact was established, and this drive to establish eye contact was significantly stronger in the manual activities than during the monologue. These results highlight people's strategic top-down control over when they attend to faces and the eyes, and support the view that we use our eyes to signal non-verbal information.
C1 [Scott, Hannah; Kuhn, Gustav] Goldsmiths Univ London, Dept Psychol, London SE14 6NW, England.
   [Batten, Jonathan P.] Birkbeck Univ London, Dept Psychol Sci, London, England.
RP Kuhn, G (corresponding author), Goldsmiths Univ London, Dept Psychol, London SE14 6NW, England.
EM G.Kuhn@gold.ac.uk
OI Batten, Jonathan/0000-0001-9903-5761
CR Argyle M., 1976, GAZE MUTUAL GAZE
   Birmingham E, 2008, Q J EXP PSYCHOL, V61, P986, DOI 10.1080/17470210701410375
   Birmingham E, 2008, VIS COGN, V16, P341, DOI 10.1080/13506280701434532
   Birmingham E, 2009, VISION RES, V49, P2992, DOI 10.1016/j.visres.2009.09.014
   Birmingham E, 2009, VIS COGN, V17, P904, DOI 10.1080/13506280902758044
   Buchan JN, 2007, SOC NEUROSCI-UK, V2, P1, DOI 10.1080/17470910601043644
   Buswell G.T., 1935, PEOPLE LOOK PICTURES
   Emery NJ, 2000, NEUROSCI BIOBEHAV R, V24, P581, DOI 10.1016/S0149-7634(00)00025-7
   Farroni T, 2002, P NATL ACAD SCI USA, V99, P9602, DOI 10.1073/pnas.152159999
   Fausey CM, 2016, COGNITION, V152, P101, DOI 10.1016/j.cognition.2016.03.005
   Flanagan JR, 2003, NATURE, V424, P769, DOI 10.1038/nature01861
   Foulsham T, 2013, VIS COGN, V21, P922, DOI 10.1080/13506285.2013.849785
   Freeth M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053286
   Gobel MS, 2015, COGNITION, V136, P359, DOI 10.1016/j.cognition.2014.11.040
   Gullberg M., 2002, Gesture and Sign Language in Human-Computer Interaction. International Gesture Workshop, GW 2001. Revised Papers (Lecture Notes in Artificial Intelligence Vol.2298), P206
   Gullberg M, 2009, J NONVERBAL BEHAV, V33, P251, DOI 10.1007/s10919-009-0073-2
   Itier RJ, 2007, NEUROPSYCHOLOGIA, V45, P1019, DOI 10.1016/j.neuropsychologia.2006.09.004
   JANIK SW, 1978, PERCEPT MOTOR SKILL, V47, P857, DOI 10.2466/pms.1978.47.3.857
   KLEINKE CL, 1986, PSYCHOL BULL, V100, P78, DOI 10.1037/0033-2909.100.1.78
   Krauss RM, 1996, ADV EXP SOC PSYCHOL, V28, P389, DOI 10.1016/S0065-2601(08)60241-5
   Kuhn G, 2005, PERCEPTION, V34, P1155, DOI 10.1068/p3409bn1
   Kuhn G, 2006, CURR BIOL, V16, pR950, DOI 10.1016/j.cub.2006.10.012
   Kuhn G, 2016, COGNITION, V146, P136, DOI 10.1016/j.cognition.2015.08.005
   Kuhn G, 2009, VIS COGN, V17, P925, DOI 10.1080/13506280902826775
   Kuhn G, 2009, ATTEN PERCEPT PSYCHO, V71, P314, DOI 10.3758/APP.71.2.314
   Langton SRH, 2000, J EXP PSYCHOL HUMAN, V26, P747, DOI 10.1037//0096-1523.26.2.747
   Lansing IR, 2003, PERCEPT PSYCHOPHYS, V65, P536, DOI 10.3758/BF03194581
   Levy J, 2013, BIOL LETTERS, V9, DOI 10.1098/rsbl.2012.0850
   Loschky LC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142474
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   Macdonald RG, 2015, J EXP PSYCHOL HUMAN, V41, P565, DOI 10.1037/xhp0000023
   Macdonald RG, 2013, J VISION, V13, DOI 10.1167/13.4.6
   Neggers SFW, 2000, J NEUROPHYSIOL, V83, P639
   Otero-Millan J, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00133
   Peterson MF, 2016, J VISION, V16, DOI 10.1167/16.7.12
   Ricciardelli P, 2002, NEUROREPORT, V13, P2259, DOI 10.1097/00001756-200212030-00018
   Senju A, 2005, VIS COGN, V12, P127, DOI 10.1080/13506280444000157
   Vo MLH, 2012, J VISION, V12, DOI 10.1167/12.13.3
   vonGrunau M, 1995, PERCEPTION, V24, P1297, DOI 10.1068/p241297
   WALKERSMITH GJ, 1977, PERCEPTION, V6, P313, DOI 10.1068/p060313
   WEBSTER J, 1993, COMPUT HUM BEHAV, V9, P411, DOI 10.1016/0747-5632(93)90032-N
   Wu DWL, 2014, EVOL HUM BEHAV, V35, P211, DOI 10.1016/j.evolhumbehav.2014.01.005
   Wu DWL, 2013, SCI REP-UK, V3, DOI 10.1038/srep02356
   Yarbus A. L., 1967, EYE MOVEMENTS VISION
   Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X
NR 45
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD JAN
PY 2019
VL 81
IS 1
BP 109
EP 118
DI 10.3758/s13414-018-1588-6
PG 10
WC Psychology; Psychology, Experimental
SC Psychology
GA HH6UY
UT WOS:000455867800010
PM 30353500
OA Other Gold, Green Published, Green Accepted
DA 2021-02-24
ER

PT J
AU Sanker, C
AF Sanker, Chelsea
TI Effects of lexical ambiguity, frequency, and acoustic details in
   auditory perception
SO ATTENTION PERCEPTION & PSYCHOPHYSICS
LA English
DT Article
DE Phonology; Speech perception; Psycholinguistics
ID WORD RECOGNITION; SEMANTIC AMBIGUITY; MULTIPLE MEANINGS; SPEECH
   PRODUCTION; FIXATION TIMES; ACCESS; HOMOPHONES; ACTIVATION;
   REPRESENTATION; ORTHOGRAPHY
AB This paper presents a set of auditory perception experiments testing the effects of lexical ambiguity, lemma frequency, and acoustic details. In an AX discrimination task with stimuli produced in isolation, lexically ambiguous phonologically matching forms (e.g., sun-sun, sun-son) were evaluated more slowly and identified as different' more often than lexically unambiguous forms (e.g., cat-cat). For stimuli extracted from meaningful sentences, pairs of homophone mates (sun-son) were evaluated more slowly than same pairs of such words (sun-sun), following from the greater acoustic distance between homophone mates in several measures. The individual lexical frequency of homophone mates was a significant factor in both identification tasks, though frequency effects in the AX tasks were weaker and driven by the lexically unambiguous items. In both studies, greater acoustic distance between items was a predictor of longer response times, though the significance of particular acoustic measures varied. Identification of homophone mates also depended on context of production; listeners were above chance accuracy for choosing between homophone mates extracted from sentences, but not for homophone mates produced in isolation. While results for stimuli produced in sentential contexts indicate that listeners are sensitive to acoustic details and can weakly associate production patterns with lexical items, the absence of such differences for homophone mates produced in isolation suggests that these details are not an inherent part of the representation.
C1 [Sanker, Chelsea] Brown Univ, Dept Cognit Linguist & Psychol Sci, Providence, RI 02912 USA.
RP Sanker, C (corresponding author), Brown Univ, Dept Cognit Linguist & Psychol Sci, Providence, RI 02912 USA.
EM chelsea_sanker@brown.edu
CR ANDRUSKI JE, 1994, COGNITION, V52, P163, DOI 10.1016/0010-0277(94)90042-6
   Anton-Mendez I, 2012, MEM COGNITION, V40, P802, DOI 10.3758/s13421-012-0189-1
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Beretta A, 2005, COGNITIVE BRAIN RES, V24, P57, DOI 10.1016/j.cogbrainres.2004.12.006
   Biedermann B, 2008, CORTEX, V44, P683, DOI 10.1016/j.cortex.2006.12.001
   Binder KS, 1998, PSYCHON B REV, V5, P271, DOI 10.3758/BF03212950
   Boersma P., 2018, PRAAT DOING PHONETIC
   BOND ZS, 1973, LANG SPEECH, V16, P351, DOI 10.1177/002383097301600405
   Borowsky R, 1996, J EXP PSYCHOL LEARN, V22, P63, DOI 10.1037/0278-7393.22.1.63
   Caramazza A, 2001, J EXP PSYCHOL LEARN, V27, P1430, DOI 10.1037//0278-7393.27.6.1430
   CARROLL JB, 1973, Q J EXP PSYCHOL, V25, P85, DOI 10.1080/14640747308400325
   CONNINE CM, 1993, J EXP PSYCHOL LEARN, V19, P81, DOI 10.1037/0278-7393.19.1.81
   Conwell E, 2017, J CHILD LANG, V44, P734, DOI 10.1017/S030500091600009X
   Conwell E, 2012, LANG LEARN DEV, V8, P87, DOI 10.1080/15475441.2011.580236
   DAVELAAR E, 1978, MEM COGNITION, V6, P391, DOI 10.3758/BF03197471
   Davies M, 2008, CORPUS CONT AM ENGLI
   DELL GS, 1990, LANG COGNITIVE PROC, V5, P313, DOI 10.1080/01690969008407066
   DUFFY SA, 1988, J MEM LANG, V27, P429, DOI 10.1016/0749-596X(88)90066-6
   FOLK JR, 1995, J EXP PSYCHOL LEARN, V21, P1412, DOI 10.1037/0278-7393.21.6.1412
   Francis W. N., 1982, FREQUENCY ANAL ENGLI
   Gahl S, 2008, LANGUAGE, V84, P474
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   Grainger J, 2001, MEM COGNITION, V29, P53, DOI 10.3758/BF03195740
   Guion S. G., 1995, TEXAS LINGUISTIC FOR, V35, P103
   Hall KC, 2013, LINGUIST REV, V30, P215, DOI 10.1515/tlr-2013-0008
   Hino Y, 2002, J EXP PSYCHOL LEARN, V28, P686, DOI 10.1037//0278-7393.28.4.686
   HOWES D, 1957, J ACOUST SOC AM, V29, P296, DOI 10.1121/1.1908862
   JASTRZEMBSKI JE, 1981, COGNITIVE PSYCHOL, V13, P278, DOI 10.1016/0010-0285(81)90011-6
   JESCHENIAK JD, 1994, J EXP PSYCHOL LEARN, V20, P824, DOI 10.1037/0278-7393.20.4.824
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Jurafsky D, 2002, PHONOL PHONET, V4-1, P3
   KAWAMOTO AH, 1994, J EXP PSYCHOL HUMAN, V20, P1233, DOI 10.1037/0096-1523.20.6.1233
   KELLAS G, 1988, J EXP PSYCHOL HUMAN, V14, P601, DOI 10.1037/0096-1523.14.4.601
   Klepousniotou E, 2007, J NEUROLINGUIST, V20, P1, DOI 10.1016/j.jneuroling.2006.02.001
   Klepousniotou E, 2012, BRAIN LANG, V123, P11, DOI 10.1016/j.bandl.2012.06.007
   Kuznetsova A., 2015, LMERTEST TESTS LINEA
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1
   LEWELLEN MJ, 1993, J EXP PSYCHOL GEN, V122, P316, DOI 10.1037/0096-3445.122.3.316
   Lohman A., 2017, J LINGUIST, P1
   LUKATELA G, 1994, J EXP PSYCHOL GEN, V123, P107, DOI 10.1037/0096-3445.123.2.107
   MASSON MEJ, 1990, J EXP PSYCHOL LEARN, V16, P355, DOI 10.1037/0278-7393.16.3.355
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   MCQUEEN JM, 1994, J EXP PSYCHOL LEARN, V20, P621, DOI 10.1037/0278-7393.20.3.621
   MONSELL S, 1989, J EXP PSYCHOL GEN, V118, P43, DOI 10.1037/0096-3445.118.1.43
   Murray WS, 2004, PSYCHOL REV, V111, P721, DOI 10.1037/0033-295X.111.3.721
   NICKERSON RS, 1969, ACTA PSYCHOL, V30, P257, DOI 10.1016/0001-6918(69)90054-7
   OLDFIELD RC, 1965, Q J EXP PSYCHOL, V17, P273, DOI 10.1080/17470216508416445
   ONIFER W, 1981, MEM COGNITION, V9, P225, DOI 10.3758/BF03196957
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   Pylkkanen L, 2006, J COGNITIVE NEUROSCI, V18, P97, DOI 10.1162/089892906775250003
   Pylkkanen L, 2002, BRAIN LANG, V81, P666, DOI 10.1006/brln.2001.2555
   RAYNER K, 1986, MEM COGNITION, V14, P191, DOI 10.3758/BF03197692
   Renwick MEL, 2016, LAB PHONOL, V7, DOI 10.5334/labphon.17
   Rodd J, 2002, J MEM LANG, V46, P245, DOI 10.1006/jmla.2001.2810
   SAMUEL AG, 1981, J EXP PSYCHOL HUMAN, V7, P1124, DOI 10.1037/0096-1523.7.5.1124
   Scarborough R. A., 2010, LAB PHONOLOGY, V10, P557
   SCHVANEVELDT RW, 1976, J EXP PSYCHOL HUMAN, V2, P243, DOI 10.1037/0096-1523.2.2.243
   Scobbie JM, 2008, PHONOL PHONET, V13, P87
   SEIDENBERG MS, 1982, COGNITIVE PSYCHOL, V14, P489, DOI 10.1016/0010-0285(82)90017-2
   Siakaluk PD, 2007, LANG COGNITIVE PROC, V22, P453, DOI 10.1080/01690960600834756
   Simon DA, 2012, LANG COGNITIVE PROC, V27, P275, DOI 10.1080/01690965.2011.607712
   SIMPSON GB, 1985, J EXP PSYCHOL HUMAN, V11, P28, DOI 10.1037/0096-1523.11.1.28
   SIMPSON GB, 1991, J MEM LANG, V30, P627, DOI 10.1016/0749-596X(91)90029-J
   SORENSEN JM, 1978, COGNITION, V6, P135, DOI 10.1016/0010-0277(78)90019-7
   STANNERS RF, 1975, J VERB LEARN VERB BE, V14, P259, DOI 10.1016/S0022-5371(75)80069-7
   TANENHAUS MK, 1979, J VERB LEARN VERB BE, V18, P427, DOI 10.1016/S0022-5371(79)90237-8
   Vitevitch MS, 1999, J MEM LANG, V40, P374, DOI 10.1006/jmla.1998.2618
   WHEELDON LR, 1992, Q J EXP PSYCHOL-A, V44, P723, DOI 10.1080/14640749208401307
NR 70
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 1943-3921
EI 1943-393X
J9 ATTEN PERCEPT PSYCHO
JI Atten. Percept. Psychophys.
PD JAN
PY 2019
VL 81
IS 1
BP 323
EP 343
DI 10.3758/s13414-018-1604-x
PG 21
WC Psychology; Psychology, Experimental
SC Psychology
GA HH6UY
UT WOS:000455867800024
PM 30324298
OA Bronze
DA 2021-02-24
ER

PT J
AU Galle, ME
   Klein-Packard, J
   Schreiber, K
   McMurray, B
AF Galle, Marcus E.
   Klein-Packard, Jamie
   Schreiber, Kayleen
   McMurray, Bob
TI What Are You Waiting For? Real-Time Integration of Cues for Fricatives
   Suggests Encapsulated Auditory Memory
SO COGNITIVE SCIENCE
LA English
DT Article
DE Speech perception; Spoken word recognition; Cue integration; Real-time
   processing; Fricatives; Auditory memory
ID SPOKEN-WORD RECOGNITION; EYE-MOVEMENT EVIDENCE; SPEAKING-RATE; LEXICAL
   ACCESS; PERCEPTUAL ORGANIZATION; SENTENCE COMPREHENSION;
   INDIVIDUAL-DIFFERENCES; WORKING-MEMORY; SPEECH; CONTEXT
AB Speech unfolds over time, and the cues for even a single phoneme are rarely available simultaneously. Consequently, to recognize a single phoneme, listeners must integrate material over several hundred milliseconds. Prior work contrasts two accounts: (a) a memory buffer account in which listeners accumulate auditory information in memory and only access higher level representations (i.e., lexical representations) when sufficient information has arrived; and (b) an immediate integration scheme in which lexical representations can be partially activated on the basis of early cues and then updated when more information arises. These studies have uniformly shown evidence for immediate integration for a variety of phonetic distinctions. We attempted to extend this to fricatives, a class of speech sounds which requires not only temporal integration of asynchronous cues (the frication, followed by the formant transitions 150-350 ms later), but also integration across different frequency bands and compensation for contextual factors like coarticulation. Eye movements in the visual world paradigm showed clear evidence for a memory buffer. Results were replicated in five experiments, ruling out methodological factors and tying the release of the buffer to the onset of the vowel. These findings support a general auditory account for speech by suggesting that the acoustic nature of particular speech sounds may have large effects on how they are processed. It also has major implications for theories of auditory and speech perception by raising the possibility of an encapsulated memory buffer in early auditory processing.
C1 [Galle, Marcus E.; Klein-Packard, Jamie; McMurray, Bob] Univ Iowa, Dept Psychol & Brain Sci, W311 SSH, Iowa City, IA 52242 USA.
   [Schreiber, Kayleen] Univ Iowa, Interdisciplinary Program Neurosci, Iowa City, IA USA.
   [McMurray, Bob] Univ Iowa, Dept Commun Sci & Disorders, Iowa City, IA USA.
   [McMurray, Bob] Univ Iowa, Dept Linguist, Iowa City, IA USA.
   [McMurray, Bob] Univ Iowa, Dept Otolaryngol, Iowa City, IA USA.
RP McMurray, B (corresponding author), Univ Iowa, Dept Psychol & Brain Sci, W311 SSH, Iowa City, IA 52242 USA.
EM bob-mcmurray@uiowa.edu
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [DC000242, DC008089]; NATIONAL
   INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, R01DC008089, R01DC008089, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, R01DC008089, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242, P50DC000242, P50DC000242, P50DC000242,
   P50DC000242, P50DC000242] Funding Source: NIH RePORTER
FX The authors thank Dan McEchron and members of the MACLab for assistance
   with data collection; Chuck Clifton, Mark Pitt, James McQueen, and Arty
   Samuel for valuable comments on an earlier draft; and Michael Tanenhaus
   for suggesting Experiment 4. Portions of this work were previously
   reported as the doctoral dissertation of M.E.G. This work was supported
   by NIH grants DC000242 and DC008089 awarded to BM.
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   ANDRUSKI JE, 1994, COGNITION, V52, P163, DOI 10.1016/0010-0277(94)90042-6
   Apfelbaum KS, 2011, PSYCHON B REV, V18, P141, DOI 10.3758/s13423-010-0039-8
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Beddor PS, 2002, J PHONETICS, V30, P591, DOI 10.1006/jpho.2002.0177
   BHARUCHA JJ, 1987, MUSIC PERCEPT, V5, P1
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   Caplan D, 1999, BEHAV BRAIN SCI, V22, P77
   Christiansen MH, 2009, LANG LEARN, V59, P126, DOI 10.1111/j.1467-9922.2009.00538.x
   Cole J, 2010, J PHONETICS, V38, P167, DOI 10.1016/j.wocn.2009.08.004
   Creel SC, 2008, COGNITION, V106, P633, DOI 10.1016/j.cognition.2007.03.013
   Dahan D, 2005, PSYCHON B REV, V12, P453, DOI 10.3758/BF03193787
   Dahan D, 2001, LANG COGNITIVE PROC, V16, P507, DOI 10.1080/01690960143000074
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750
   DANILOFF R, 1968, J SPEECH HEAR RES, V11, P707, DOI 10.1044/jshr.1104.707
   David M, 2017, J ACOUST SOC AM, V142, P1674, DOI 10.1121/1.5003809
   David M, 2017, HEARING RES, V344, P235, DOI 10.1016/j.heares.2016.11.016
   DIEHL RL, 1987, J MEM LANG, V26, P564, DOI 10.1016/0749-596X(87)90143-4
   Dufour S, 2013, COGNITIVE SCI, V37, P489, DOI 10.1111/cogs.12015
   Elman Jeffrey L, 2009, Cogn Sci, V33, P547
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1016/0364-0213(90)90002-E
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Fedorenko E, 2006, J MEM LANG, V54, P541, DOI 10.1016/j.jml.2005.12.006
   FORREST K, 1988, J ACOUST SOC AM, V84, P115, DOI 10.1121/1.396977
   FRAZIER L, 1982, COGNITIVE PSYCHOL, V14, P178, DOI 10.1016/0010-0285(82)90008-1
   Frazier L, 1987, SENTENCE PROCESSING
   Galle M., 2014, THESIS
   Gantz BJ, 2004, ACTA OTO-LARYNGOL, V124, P344, DOI 10.1080/00016480410016423
   Gaskell MG, 1997, LANG COGNITIVE PROC, V12, P613, DOI 10.1080/016909697386646
   GATHERCOLE SE, 1990, J MEM LANG, V29, P336, DOI 10.1016/0749-596X(90)90004-J
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Gupta P, 2009, J MEM LANG, V61, P481, DOI 10.1016/j.jml.2009.08.001
   Hillenbrand JM, 2000, J ACOUST SOC AM, V108, P3013, DOI 10.1121/1.1323463
   HOEQUIST CE, 1983, LANG SPEECH, V26, P367, DOI 10.1177/002383098302600404
   Ishida M, 2016, COGNITION, V151, P68, DOI 10.1016/j.cognition.2016.03.008
   Jacobs RA, 2002, TRENDS COGN SCI, V6, P345, DOI 10.1016/S1364-6613(02)01948-4
   JENKINS JJ, 1994, J ACOUST SOC AM, V95, P1030, DOI 10.1121/1.410014
   JOHNSON K, 1991, LANG SPEECH, V34, P265, DOI 10.1177/002383099103400304
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   JUST MA, 1992, PSYCHOL REV, V99, P122, DOI 10.1037/0033-295X.99.1.122
   KING J, 1991, J MEM LANG, V30, P580, DOI 10.1016/0749-596X(91)90027-H
   Kingston J, 2016, J EXP PSYCHOL HUMAN, V42, P1969, DOI 10.1037/xhp0000269
   Lee CY, 2010, J ACOUST SOC AM, V128, P384, DOI 10.1121/1.3397514
   Levy R, 2009, P NATL ACAD SCI USA, V106, P21086, DOI 10.1073/pnas.0907664106
   LISKER L, 1986, LANG SPEECH, V29, P3, DOI 10.1177/002383098602900102
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P213, DOI 10.3758/BF03204377
   MARCUS SM, 1981, PERCEPT PSYCHOPHYS, V30, P247, DOI 10.3758/BF03214280
   MARSLENWILSON W, 1989, J EXP PSYCHOL HUMAN, V15, P576, DOI 10.1037/0096-1523.15.3.576
   MARSLENWILSON W, 1980, COGNITION, V8, P1, DOI 10.1016/0010-0277(80)90015-3
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   Matuschek H, 2017, J MEM LANG, V94, P305, DOI 10.1016/j.jml.2017.01.001
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McLennan CT, 2005, J EXP PSYCHOL LEARN, V31, P306, DOI 10.1037/0278-7393.31.2.306
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B, 2017, COGNITION, V169, P147, DOI 10.1016/j.cognition.2017.08.013
   McMurray B, 2016, EAR HEARING, V37, pe37, DOI 10.1097/AUD.0000000000000207
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   McMurray B, 2010, COGNITIVE PSYCHOL, V60, P1, DOI 10.1016/j.cogpsych.2009.06.003
   McMurray B, 2009, J MEM LANG, V60, P65, DOI 10.1016/j.jml.2008.07.002
   McMurray B, 2008, PSYCHON B REV, V15, P1064, DOI 10.3758/PBR.15.6.1064
   McMurray B, 2008, J EXP PSYCHOL HUMAN, V34, P1609, DOI 10.1037/a0011747
   McRae K, 1998, J MEM LANG, V38, P283, DOI 10.1006/jmla.1997.2543
   Miller J, 1998, PSYCHOPHYSIOLOGY, V35, P99, DOI 10.1111/1469-8986.3510099
   MILLER JL, 1988, J EXP PSYCHOL HUMAN, V14, P369, DOI 10.1037/0096-1523.14.3.369
   MILLER JL, 1993, PERCEPT PSYCHOPHYS, V54, P205, DOI 10.3758/BF03211757
   MILLER JL, 1989, PERCEPT PSYCHOPHYS, V46, P505, DOI 10.3758/BF03208147
   Mitterer H, 2013, J MEM LANG, V69, P527, DOI 10.1016/j.jml.2013.07.002
   Nearey TM, 1997, J ACOUST SOC AM, V101, P3241, DOI 10.1121/1.418290
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   ODEN GC, 1978, PSYCHOL REV, V85, P172, DOI 10.1037/0033-295X.85.3.172
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   REMEZ RE, 1994, PSYCHOL REV, V101, P129, DOI 10.1037/0033-295X.101.1.129
   REPP BH, 1981, B PSYCHONOMIC SOC, V18, P12
   Seedorff M., 2018, THESIS
   SHINN PC, 1985, PERCEPT PSYCHOPHYS, V38, P397, DOI 10.3758/BF03207170
   Simpson Andrea, 2009, Trends Amplif, V13, P87, DOI 10.1177/1084713809336421
   Sjerps MJ, 2013, ATTEN PERCEPT PSYCHO, V75, P576, DOI 10.3758/s13414-012-0408-7
   Smits R, 2003, J ACOUST SOC AM, V113, P563, DOI 10.1121/1.1525287
   Stachurski M, 2015, HEARING RES, V323, P22, DOI 10.1016/j.heares.2015.01.007
   STRANGE W, 1983, J ACOUST SOC AM, V74, P695, DOI 10.1121/1.389855
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   Tanenhaus M. K., 1995, HDB COGNITION PERCEP, P217
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Toscano JC, 2015, LANG COGN NEUROSCI, V30, P529, DOI 10.1080/23273798.2014.946427
   Toscano JC, 2012, ATTEN PERCEPT PSYCHO, V74, P1284, DOI 10.3758/s13414-012-0306-z
   Toscano JC, 2010, COGNITIVE SCI, V34, P434, DOI 10.1111/j.1551-6709.2009.01077.x
   TYLER LK, 1985, PERCEPT PSYCHOPHYS, V38, P217, DOI 10.3758/BF03207148
   Utman JA, 1998, J ACOUST SOC AM, V103, P1640, DOI 10.1121/1.421297
   Utman JA, 2000, PERCEPT PSYCHOPHYS, V62, P1297, DOI 10.3758/BF03212131
   van den Brink D, 2006, J EXP PSYCHOL LEARN, V32, P364, DOI 10.1037/0278-7393.32.3.364
   Warner N, 2014, J ACOUST SOC AM, V135, P2995, DOI 10.1121/1.4870486
   Yee E, 2006, J EXP PSYCHOL LEARN, V32, P1, DOI 10.1037/0278-7393.32.1.1
   Zhang XJ, 2018, J MEM LANG, V100, P32, DOI 10.1016/j.jml.2018.01.002
   ZWITSERLOOD P, 1989, COGNITION, V32, P25, DOI 10.1016/0010-0277(89)90013-9
NR 97
TC 3
Z9 3
U1 1
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0364-0213
EI 1551-6709
J9 COGNITIVE SCI
JI Cogn. Sci.
PD JAN
PY 2019
VL 43
IS 1
DI 10.1111/cogs.12700
PG 49
WC Psychology, Experimental
SC Psychology
GA HH8FT
UT WOS:000455968000009
PM 30648798
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Feldman, JI
   Kuang, W
   Conrad, JG
   Tu, A
   Santapuram, P
   Simon, DM
   Foss-Feig, JH
   Kwakye, LD
   Stevenson, RA
   Wallace, MT
   Woynaroski, TG
AF Feldman, Jacob I.
   Kuang, Wayne
   Conrad, Julie G.
   Tu, Alexander
   Santapuram, Pooja
   Simon, David M.
   Foss-Feig, Jennifer H.
   Kwakye, Leslie D.
   Stevenson, Ryan A.
   Wallace, Mark T.
   Woynaroski, Tiffany G.
TI Brief Report: Differences in Multisensory Integration Covary with
   Sensory Responsiveness in Children with and without Autism Spectrum
   Disorder
SO JOURNAL OF AUTISM AND DEVELOPMENTAL DISORDERS
LA English
DT Article
DE Autism; Sensory; Audiovisual; Multisensory integration; Temporal
   binding; Speech perception
ID SPEECH-PERCEPTION; FEATURES; PATTERNS; QUESTIONNAIRE; ASSOCIATION;
   CONSTRUCT; WINDOW
AB Research shows that children with autism spectrum disorder (ASD) differ in their behavioral patterns of responding to sensory stimuli (i.e., sensory responsiveness) and in various other aspects of sensory functioning relative to typical peers. This study explored relations between measures of sensory responsiveness and multisensory speech perception and integration in children with and without ASD. Participants were 8-17year old children, 18 with ASD and 18 matched typically developing controls. Participants completed a psychophysical speech perception task, and parents reported on children's sensory responsiveness. Psychophysical measures (e.g., audiovisual accuracy, temporal binding window) were associated with patterns of sensory responsiveness (e.g., hyporesponsiveness, sensory seeking). Results indicate that differences in multisensory speech perception and integration covary with atypical patterns of sensory responsiveness.
C1 [Feldman, Jacob I.] Vanderbilt Univ, Dept Hearing & Speech Sci, 221 Kirkland Hall, Nashville, TN 37235 USA.
   [Kuang, Wayne; Conrad, Julie G.; Tu, Alexander; Santapuram, Pooja] Vanderbilt Univ, Neurosci Undergrad Program, 221 Kirkland Hall, Nashville, TN 37235 USA.
   [Simon, David M.] Vanderbilt Univ, Neurosci Grad Program, 221 Kirkland Hall, Nashville, TN 37235 USA.
   [Simon, David M.; Wallace, Mark T.; Woynaroski, Tiffany G.] Vanderbilt Univ, Vanderbilt Brain Inst, 221 Kirkland Hall, Nashville, TN 37235 USA.
   [Foss-Feig, Jennifer H.] Icahn Sch Med Mt Sinai, Seaver Autism Ctr Res & Treatment, Dept Psychiat, New York, NY 10029 USA.
   [Kwakye, Leslie D.] Oberlin Coll, Dept Neurosci, Oberlin, OH 44074 USA.
   [Stevenson, Ryan A.] Univ Western Ontario, Dept Psychol, London, ON, Canada.
   [Stevenson, Ryan A.] Univ Western Ontario, Brain & Mind Inst, London, ON, Canada.
   [Stevenson, Ryan A.] Univ Western Ontario, Schulich Sch Med & Dent, Dept Psychiat, London, ON, Canada.
   [Stevenson, Ryan A.] Univ Western Ontario, Schulich Sch Med & Dent, Program Neurosci, London, ON, Canada.
   [Stevenson, Ryan A.] York Univ, Ctr Vis Res, Toronto, ON, Canada.
   [Wallace, Mark T.; Woynaroski, Tiffany G.] Vanderbilt Univ, Med Ctr, Dept Hearing & Speech Sci, MCE 8310 South Tower,1215 21st Ave South, Nashville, TN 37232 USA.
   [Wallace, Mark T.; Woynaroski, Tiffany G.] Vanderbilt Univ, Med Ctr, Vanderbilt Kennedy Ctr, Nashville, TN 37235 USA.
   [Wallace, Mark T.] Vanderbilt Univ, Dept Psychol, Nashville, TN 37240 USA.
   [Wallace, Mark T.] Vanderbilt Univ, Med Ctr, Dept Psychiat & Behav Sci, Nashville, TN USA.
   [Wallace, Mark T.] Vanderbilt Univ, Dept Pharmacol, Nashville, TN USA.
RP Woynaroski, TG (corresponding author), Vanderbilt Univ, Vanderbilt Brain Inst, 221 Kirkland Hall, Nashville, TN 37235 USA.; Woynaroski, TG (corresponding author), Vanderbilt Univ, Med Ctr, Dept Hearing & Speech Sci, MCE 8310 South Tower,1215 21st Ave South, Nashville, TN 37232 USA.; Woynaroski, TG (corresponding author), Vanderbilt Univ, Med Ctr, Vanderbilt Kennedy Ctr, Nashville, TN 37235 USA.
EM tiffany.g.woynaroski@vanderbilt.edu
RI Feldman, Jacob/K-8212-2019
OI Feldman, Jacob/0000-0002-5723-5834
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [U54 HD083211]; Wallace Foundation;
   Simons Foundation Autism Research Initiative; Marino Autism Research
   Institute Discovery Grant; National Institute of Child Health and Human
   DevelopmentUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [T32 HD07226];
   National Center for Advancing Translational SciencesUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Center for Advancing Translational Sciences (NCATS)
   [KL2TR000446]; Social Sciences and Humanities Research Counsel Insight
   Grant [435-2017-0936]; Canadian Natural Science and Engineering Research
   Counsel Discovery Grant [RGPIN-2017-04656]; University of Western
   Ontario Faculty Development Research Fund; EUNICE KENNEDY SHRIVER
   NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH Eunice Kennedy Shriver National Institute of Child Health &
   Human Development (NICHD) [U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211] Funding Source: NIH
   RePORTER; NATIONAL CENTER FOR ADVANCING TRANSLATIONAL SCIENCESUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Center for Advancing Translational
   Sciences (NCATS) [KL2TR002245, KL2TR002245, KL2TR002245, KL2TR000446]
   Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R21DC016144,
   R21DC016144, R21DC016144] Funding Source: NIH RePORTER
FX This work was supported by NIH U54 HD083211 (PI: Dykens), the Wallace
   Foundation, the Simons Foundation Autism Research Initiative, a Marino
   Autism Research Institute Discovery Grant (PI: Mark T. Wallace), a
   National Institute of Child Health and Human Development T32 HD07226 and
   Dennis Weatherstone Predoctoral Fellowship for Jennifer H. Foss-Feig, a
   Meharry-Vanderbilt Alliance Training Grant for Leslie D. Kwakye, and by
   CTSA award No. KL2TR000446 for Tiffany G. Woynaroski from the National
   Center for Advancing Translational Sciences. Ryan A. Stevenson is funded
   by a Canadian Natural Science and Engineering Research Counsel Discovery
   Grant (RGPIN-2017-04656), a Social Sciences and Humanities Research
   Counsel Insight Grant (435-2017-0936), and the University of Western
   Ontario Faculty Development Research Fund. Its contents are solely the
   responsibility of the authors and do not necessarily represent the
   official views of the funding agencies.
CR American Psychiatric Association (APA), 2000, DIAGN STAT MAN MENT
   Ausderau K, 2014, J AUTISM DEV DISORD, V44, P915, DOI 10.1007/s10803-013-1945-1
   Baranek GT, 2006, J CHILD PSYCHOL PSYC, V47, P591, DOI 10.1111/j.1469-7610.2005.01546.x
   Barton EE, 2015, RES DEV DISABIL, V37, P64, DOI 10.1016/j.ridd.2014.11.006
   Baum SH, 2015, PROG NEUROBIOL, V134, P140, DOI 10.1016/j.pneurobio.2015.09.007
   Bebko JM, 2006, J CHILD PSYCHOL PSYC, V47, P88, DOI 10.1111/j.1469-7610.2005.01443.x
   Beker S, 2018, NEUROSCI BIOBEHAV R, V84, P182, DOI 10.1016/j.neubiorev.2017.11.008
   Ben-Sasson A, 2009, J AUTISM DEV DISORD, V39, P1, DOI 10.1007/s10803-008-0593-3
   Boyd BA, 2010, AUTISM RES, V3, P78, DOI 10.1002/aur.124
   Cascio CJ, 2016, AUTISM RES, V9, P920, DOI 10.1002/aur.1612
   Cascio CJ, 2015, BRAIN TOPOGR, V28, P895, DOI 10.1007/s10548-015-0439-1
   Dunn W, 1999, SENSORY PROFILE USER
   Enders C.K., 2010, APPL MISSING DATA AN
   Enders CK, 2014, PSYCHOL METHODS, V19, P39, DOI 10.1037/a0035314
   Enders CK, 2013, CHILD DEV PERSPECT, V7, P27, DOI 10.1111/cdep.12008
   Foss-Feig JH, 2012, RES AUTISM SPECT DIS, V6, P337, DOI 10.1016/j.rasd.2011.06.007
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   Iarocci G, 2010, AUTISM, V14, P305, DOI 10.1177/1362361309353615
   Kwakye LD, 2011, FRONT INTEGR NEUROSC, V4, DOI 10.3389/fnint.2010.00129
   Liss M, 2006, AUTISM, V10, P155, DOI 10.1177/1362361306062021
   Lord C, 2000, J AUTISM DEV DISORD, V30, P205, DOI 10.1023/A:1005592401947
   LORD C, 1994, J AUTISM DEV DISORD, V24, P659, DOI 10.1007/BF02172145
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MEREDITH MA, 1987, J NEUROSCI, V7, P3215
   Miller LJ, 2007, AM J OCCUP THER, V61, P135, DOI 10.5014/ajot.61.2.135
   Patten E, 2014, AUTISM RES TREATMENT
   Poole D, 2017, J AUTISM DEV DISORD, V47, P215, DOI 10.1007/s10803-016-2925-z
   Powers AR, 2009, J NEUROSCI, V29, P12265, DOI 10.1523/JNEUROSCI.3501-09.2009
   Righi G, 2018, AUTISM RES
   RUSHTON JP, 1983, PSYCHOL BULL, V94, P18, DOI 10.1037/0033-2909.94.1.18
   Rutter M., 2003, SCQ SOCIAL COMMUNICA
   Smith EG, 2007, J CHILD PSYCHOL PSYC, V48, P813, DOI 10.1111/j.1469-7610.2007.01766.x
   Stevenson RA, 2016, AUTISM RES, V9, P720, DOI 10.1002/aur.1566
   Stevenson RA, 2014, BRAIN TOPOGR, V27, P707, DOI 10.1007/s10548-014-0365-7
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   Watson LR, 2011, J SPEECH LANG HEAR R, V54, P1562, DOI 10.1044/1092-4388(2011/10-0029)
   Wechsler D., 1999, WASI WECHSLER ABBREV
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
   Yoder P., 2010, OBSERVATIONAL MEASUR
NR 40
TC 8
Z9 8
U1 3
U2 9
PU SPRINGER/PLENUM PUBLISHERS
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 0162-3257
EI 1573-3432
J9 J AUTISM DEV DISORD
JI J. Autism Dev. Disord.
PD JAN
PY 2019
VL 49
IS 1
BP 397
EP 403
DI 10.1007/s10803-018-3667-x
PG 7
WC Psychology, Developmental
SC Psychology
GA HH6VM
UT WOS:000455869200037
PM 30043353
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Baayen, RH
   Chuang, YY
   Shafaei-Bajestan, E
   Blevins, JP
AF Baayen, R. Harald
   Chuang, Yu-Ying
   Shafaei-Bajestan, Elnaz
   Blevins, James P.
TI The Discriminative Lexicon: A Unified Computational Model for the
   Lexicon and Lexical Processing in Comprehension and Production Grounded
   Not in (De)Composition but in Linear Discriminative Learning
SO COMPLEXITY
LA English
DT Article
ID VISUAL WORD RECOGNITION; SPEECH-PERCEPTION; NEURAL-NETWORKS; PROSODIC
   THEORY; DUAL-ROUTE; MORPHOLOGY; PHONOLOGY; FREQUENCY; MEANINGS;
   REPRESENTATION
AB The discriminative lexicon is introduced as a mathematical and computational model of the mental lexicon. This novel theory is inspired by word and paradigm morphology but operationalizes the concept of proportional analogy using the mathematics of linear algebra. It embraces the discriminative perspective on language, rejecting the idea that words' meanings are compositional in the sense of Frege and Russell and arguing instead that the relation between form and meaning is fundamentally discriminative. The discriminative lexicon also incorporates the insight from machine learning that end-to-end modeling is much more effective than working with a cascade of models targeting individual subtasks. The computational engine at the heart of the discriminative lexicon is linear discriminative learning: simple linear networks are used for mapping form onto meaning and meaning onto form, without requiring the hierarchies of post-Bloomfieldian hidden' constructs such as phonemes, morphemes, and stems. We show that this novel model meets the criteria of accuracy (it properly recognizes words and produces words correctly), productivity (the model is remarkably successful in understanding and producing novel complex words), and predictivity (it correctly predicts a wide array of experimental phenomena in lexical processing). The discriminative lexicon does not make use of static representations that are stored in memory and that have to be accessed in comprehension and production. It replaces static representations by states of the cognitive system that arise dynamically as a consequence of external or internal stimuli. The discriminative lexicon brings together visual and auditory comprehension as well as speech production into an integrated dynamic system of coupled linear networks.
C1 [Baayen, R. Harald; Chuang, Yu-Ying; Shafaei-Bajestan, Elnaz] Eberhard Karls Univ Tubingen, Seminar Sprachwissensch, Wilhelmstr 19, D-72074 Tubingen, Germany.
   [Blevins, James P.] Univ Cambridge, Homerton Coll, Hills Rd, Cambridge CB2 8PH, England.
RP Baayen, RH (corresponding author), Eberhard Karls Univ Tubingen, Seminar Sprachwissensch, Wilhelmstr 19, D-72074 Tubingen, Germany.
EM harald.baayen@gmail.com; yu-ying.chuang@uni-tuebingen.de;
   elnaz.shafaei-bajestan@uni-tuebingen.de; jpb39@cam.ac.uk
OI Baayen, Harald/0000-0003-3178-3944
FU ERC advanced GrantEuropean Research Council (ERC) [742545]
FX The authors are indebted to Geoff Hollis, Jessie Nixon, Chris Westbury,
   and Luis Mienhardt for their constructive feedback on earlier versions
   of this manuscript. This research was supported by an ERC advanced Grant
   (no. 742545) to the first author.
CR Amenta S, 2017, PSYCHON B REV, V24, P887, DOI 10.3758/s13423-016-1152-0
   [Anonymous], 1988, CELEX GUIDE USERS
   Arnold D, 2017, ACOUSTICNDLCODER COD
   Arnold D, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174623
   Baayen R. H., 2018, MENTAL LEXICON, V13, P232, DOI [10.1515/9783110910186, DOI 10.1515/9783110910186]
   Baayen RH, 2016, APHASIOLOGY, V30, P1174, DOI 10.1080/02687038.2016.1147767
   Baayen RH, 2016, LANG COGN NEUROSCI, V31, P106, DOI 10.1080/23273798.2015.1065336
   Baayen RH, 2011, PSYCHOL REV, V118, P438, DOI 10.1037/a0023851
   Baayen RH, 2000, TEXT SPEECH LANG TEC, V12, P267
   Baayen RH, 2017, SEMANTICS DIALECTOME, P13, DOI DOI 10.1515/9783110261332
   Baayen RH, 1995, CELEX LEXICAL DATABA
   Bauer Laurie, 1983, ENGLISH WORD FORMATI, DOI [10.1017/CBO9781139165846, DOI 10.1017/CBO9781139165846]
   Bauer PJ, 2014, MEMORY, V22, P907, DOI 10.1080/09658211.2013.854806
   BEARD R, 1977, LINGUA, V42, P305, DOI 10.1016/0024-3841(77)90102-4
   Beard R., 1995, LEXEME MORPHEME BASE, DOI [10.2307/416107, DOI 10.2307/416107]
   Bergen BK, 2004, LANGUAGE, V80, P290, DOI 10.1353/lan.2004.0056
   Bertram R, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00207
   Bitan T, 2017, NEUROPSYCHOLOGY, V31, P759, DOI 10.1037/neu0000357
   Blevins J. P., 2016, WORD PARADIGM MORPHO, DOI [10.1093/acprof:oso/9780199593545.001.0001, DOI 10.1093/ACPROF:OSO/9780199593545.001.0001]
   Blevins JP, 2006, J LINGUIST, V42, P531, DOI 10.1017/S0022226706004191
   Blevins JP, 2003, LANGUAGE, V79, P737, DOI 10.1353/lan.2003.0206
   Booij G, 2010, LANG LINGUIST COMPAS, V4, P543, DOI 10.1111/j.1749-818x.2010.00213.x
   Bozic M, 2007, J COGNITIVE NEUROSCI, V19, P1464, DOI 10.1162/jocn.2007.19.9.1464
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   BROWMAN CP, 1992, PHONETICA, V49, P155, DOI 10.1159/000261913
   Bruni E, 2014, J ARTIF INTELL RES, V49, P1, DOI 10.1613/jair.4135
   Butz M. V., 2016, MIND COMES BEING INT, DOI [10.1177/0301006617714547, DOI 10.1177/0301006617714547]
   Chersi F, 2014, TOP COGN SCI, V6, P476, DOI 10.1111/tops.12094
   Cho T, 2001, PHONETICA, V58, P129, DOI 10.1159/000056196
   Chomsky N., 1968, SOUND PATTERN ENGLIS
   Chomsky N., 1957, SYNTACTIC STRUCT, DOI [10.2307/411160, DOI 10.2307/411160]
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   Clarke CM, 2005, P ISCA WORKSH PLAST
   Cohen L., 2009, COGNITIVE NEUROSCIEN, P789
   Coltheart M, 2001, PSYCHOL REV, V108, P204, DOI 10.1037//0033-295X.108.1.204
   COLTHEART M, 1993, PSYCHOL REV, V100, P589, DOI 10.1037/0033-295X.100.4.589
   Coltheart M, 2005, BL HBK DEV PSYCHOL, P6, DOI 10.1002/9780470757642.ch1
   Cotterell R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1651
   Csardi G., 2006, INT J COMPLEX SYST INTERJOURNAL COMPLEX INTER J COMP SYST INTERJOURNAL COMPLEX INTERJOURNAL COMPLEX INTERJ COMPLEX SYST INT J COMPLEX SYST INTERJ COMPLEX SYST INTERJOURNAL COMPLEX INT J COMPLEX SYST INTERJOURNAL COMPLEX INTERJOURNAL COMPLEX INTERJOURNAL 2006 J COMPUT APPL INTERJOURNAL COMPLEX IGRAPH SOFTWARE PACK INTERJOURNAL COMPLEX INT J COMPLEX SYST INT J COMPLEX SYST INTERJ COMPLEX SYST INT J COMPLEX SYST INTER J COMP SYST INT J COMPLEX SYST INTERJOURNAL COMPLEX INTERJOURNAL COMPL S INTERJOURNAL COMPLEX INTERJOURNAL COMPLEX IGRAPH SOFTWARE PACK INTERJOURNAL COMPLEX INT J COMPLEX SYST INT J COMPLEX SYST INT J COMPLEX SYST INTERJ COMPLEX SYST INTERJOURNAL COMPLEX INTERJOURNAL COMPLEX INT J COMPLEX SYST INT J COMPLEX SYSTEM INT J COMPLEX SYST IGRAPH SOFTWARE PACK INTERJOURNAL COMPLEX INTERJOURNAL COMPLEX INTERJOURNAL INT J COMPLEX SYST, V1695, P1, DOI DOI 10.3724/SP.J.1087.2009.02191
   Cucchiarini C, 2003, P ICPHS, P347
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DELL GS, 1986, PSYCHOL REV, V93, P283, DOI 10.1037/0033-295X.93.3.283
   desRosiers G, 1988, Arch Clin Neuropsychol, V3, P47, DOI 10.1016/0887-6177(88)90026-1
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Erelt Mati, 2003, ESTONIAN LANGUAGE
   Ernestus M, 2003, LANGUAGE, V79, P5, DOI 10.1353/lan.2003.0076
   Ernestus M, 2002, BRAIN LANG, V81, P162, DOI 10.1006/brln.2001.2514
   ERNESTUS M, 2000, VOICE ASSIMILATION S
   Ferro M, 2011, LINGUE LINGUAGGIO, V10, P209, DOI 10.1418/35840
   Firth J. R., 1968, SELECTED PAPERS JR F, DOI [10.2307/412194, DOI 10.2307/412194]
   Fletcher H, 1940, REV MOD PHYS, V12, P0047, DOI 10.1103/RevModPhys.12.47
   Forstemann E., 1852, DTSCH VOLKSETYMOLOGI, DOI [10.1017/CBO9781139383110, DOI 10.1017/CBO9781139383110]
   Forsyth R. S., 1996, Literary & Linguistic Computing, V11, P163, DOI 10.1093/llc/11.4.163
   Frege G., 1879, FREGE GODEL SOURCE B, P1, DOI DOI 10.4159/HARVARD.9780674864603
   Freud S., 1905, BASIC WRITINGS SIGMU, DOI [10.1037/10012-000, DOI 10.1037/10012-000]
   Geeraert K, 2017, TOP COGN SCI, V9, P653, DOI 10.1111/tops.12263
   Gonnerman LM, 2007, J EXP PSYCHOL GEN, V136, P323, DOI 10.1037/0096-3445.136.2.323
   Grainger J, 2012, SCIENCE, V336, P245, DOI 10.1126/science.1218152
   Hannagan T, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0084843
   Hannun A., 2014, ARXIV14125567
   Harm MW, 2004, PSYCHOL REV, V111, P662, DOI 10.1037/0033-295X.111.3.662
   Harm MW, 1999, PSYCHOL REV, V106, P491, DOI 10.1037/0033-295X.106.3.491
   Hawkins S, 2003, J PHONETICS, V31, P373, DOI 10.1016/j.wocn.2003.09.006
   Hay J, 2002, LANGUAGE, V78, P527, DOI 10.1353/lan.2002.0159
   Hay J., 2004, PAPERS LAB PHONOLOGY, VVI, P58, DOI DOI 10.1017/CBO9780511486425
   Hay J., 2003, CAUSES CONSEQUENCES, DOI [10.4324/9780203495131, DOI 10.4324/9780203495131]
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Hay Jennifer, 2003, ITALIAN J LINGUISTIC, V15, P99
   Henri V., 1895, PSYCHOL REV, V2, P215
   Hickok G, 2014, LANG COGN NEUROSCI, V29, P2, DOI 10.1080/01690965.2013.834370
   Pham H, 2015, LANG COGN NEUROSCI, V30, P1077, DOI 10.1080/23273798.2015.1054844
   HOCKETT CF, 1960, SCI AM, V203, P88, DOI 10.1038/scientificamerican0960-88
   Hornstein N., 1995, LOGICAL FORM GB MINI, DOI [10.2307/417572, DOI 10.2307/417572]
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Ivens S. H., 1991, DEMANDS READING LITE
   Jackendoff R., 1990, SEMANTIC STRUCTURES, DOI [10.9793/elsj1984.8.226, DOI 10.9793/ELSJ1984.8.226]
   Jared D, 2017, CAN J EXP PSYCHOL, V71, P2, DOI 10.1037/cep0000109
   Jared D, 2017, MEM COGNITION, V45, P334, DOI 10.3758/s13421-016-0661-4
   Jared D, 2016, J EXP PSYCHOL LEARN, V42, P524, DOI 10.1037/xlm0000184
   Johnson K., 1997, OHIO STATE U WORKING
   Johnson K, 2004, SPONTANEOUS SPEECH D, P29
   Kalman RE., 1960, THE J, V82, P35, DOI [DOI 10.1115/1.3662552, 10.1115/1.3662552]
   Kamin L.J., 1969, PUNISHMENT AVERSIVE, P276
   KASTOVSKY D, 1986, LINGUISTICS, V24, P585, DOI 10.1515/ling.1986.24.3.585
   Kaye R., 1998, LINEAR ALGEBRA
   Kemps R, 2004, BRAIN LANG, V90, P117, DOI 10.1016/S0093-934X(03)00425-5
   Keuleers E, 2015, Q J EXP PSYCHOL, V68, P1665, DOI 10.1080/17470218.2015.1022560
   Keuleers E, 2012, BEHAV RES METHODS, V44, P287, DOI 10.3758/s13428-011-0118-4
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kostic A., 1995, MORPHOLOGICAL ASPECT, P189, DOI [10.1007/bf00867333, DOI 10.1007/BF00867333]
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211
   Lapata M., 2008, P 46 ANN M ASS COMP, P236, DOI DOI 10.1039/9781847558633-00236
   Lazaridou A., 2013, ACL, V1, P1517
   Levelt W. J., 1991, SPRACHE KOGNIT, V10, P61, DOI [10.1007/978-3-662-10178-0_4, DOI 10.1007/978-3-662-10178-0_4]
   Levelt WJM, 2008, INTRODUCTION TO THE THEORY OF FORMAL LANGUAGES AND AUTOMATA, P1
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1
   Levinson SC, 2006, LANG CULT COGN, V6, P157, DOI 10.1017/CBO9780511486753.006
   Levinson SC, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00061
   Linke M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0183876
   Love BC, 2004, PSYCHOL REV, V111, P309, DOI 10.1037/0033-295X.111.2.309
   Lund K, 1996, BEHAV RES METH INSTR, V28, P203, DOI 10.3758/BF03204766
   Marantz A, 2013, LANG COGNITIVE PROC, V28, P905, DOI 10.1080/01690965.2013.779385
   Marchand Hans, 1969, CATEGORIES TYPES PRE
   Marelli M, 2015, PSYCHOL REV, V122, P485, DOI 10.1037/a0039267
   Marsolek CJ, 2008, TRENDS COGN SCI, V12, P176, DOI 10.1016/j.tics.2008.02.005
   Martin FMD, 2004, J EXP PSYCHOL LEARN, V30, P1271, DOI 10.1037/0278-7393.30.6.1271
   Marzi C., 2018, ABSTRACT BOOKLET MEN
   Matthews P. H., 1974, MORPHOLOGY INTRO THE, DOI [10.1017/S0022226700004588, DOI 10.1017/S0022226700004588]
   Matthews P. H., 1993, GRAMMATICAL THEORY U, DOI [10.1017/S0022226700015711, DOI 10.1017/S0022226700015711]
   McBrideChang C, 1996, CHILD DEV, V67, P1836, DOI 10.2307/1131735
   MCCARTHY JJ, 1981, LINGUIST INQ, V12, P373
   McQueen JM, 1998, J MEM LANG, V39, P21, DOI 10.1006/jmla.1998.2568
   Mikolov T., 2013, CORR, P3111, DOI DOI 10.1162/JMLR.2003.3.4-5.951
   Milin P, 2017, J EXP PSYCHOL LEARN, V43, P1730, DOI 10.1037/xlm0000410
   Milin P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171935
   Milin P, 2009, J MEM LANG, V60, P50, DOI 10.1016/j.jml.2008.08.007
   MILLER RR, 1995, PSYCHOL BULL, V117, P363, DOI 10.1037/0033-2909.117.3.363
   Montague Richard, 1973, APPROACHES NATURAL L, P221, DOI DOI 10.1007/978-94-010-2506-5_10
   Nault K., 2010, THESIS, DOI [10.1111/j.1440-1630.1968.tb00277.x, DOI 10.1111/J.1440-1630.1968.TB00277.X]
   Newman RL, 2012, LANG COGNITIVE PROC, V27, P1361, DOI 10.1080/01690965.2011.603932
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Perrone-Bertolotti M, 2012, J NEUROSCI, V32, P17554, DOI 10.1523/JNEUROSCI.2982-12.2012
   Phillips C, 2001, COGNITIVE SCI, V25, P711, DOI 10.1016/S0364-0213(01)00049-0
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169
   PICKETT JM, 1963, LANG SPEECH, V6, P151, DOI 10.1177/002383096300600304
   Pirrelli Vito, 2015, UNDERSTANDING MEASUR, P141, DOI DOI 10.1093/ACPROF:OSO/9780198723769.001.0001
   Pitt MA, 2005, SPEECH COMMUN, V45, P89, DOI 10.1016/j.specom.2004.09.001
   Plag I., 2003, WORD FORMATION ENGLI, DOI [10.1017/S0022226704303233, DOI 10.1017/S0022226704303233]
   Plag I, 2017, J LINGUIST, V53, P181, DOI 10.1017/S0022226715000183
   Port RF, 2005, LANGUAGE, V81, P927, DOI 10.1353/lan.2005.0195
   R Core Team, 2016, R LANG ENV STAT COMP
   Ramscar M, 2007, COGNITIVE SCI, V31, P927, DOI 10.1080/03640210701703576
   Ramscar M, 2017, PSYCHOL SCI, V28, P1171, DOI 10.1177/0956797617706393
   Ramscar M, 2015, HANDB SPRACH KOMMUN, V39, P75
   Ramscar M, 2014, TOP COGN SCI, V6, P5, DOI 10.1111/tops.12078
   Ramscar M, 2010, COGNITIVE SCI, V34, P909, DOI 10.1111/j.1551-6709.2009.01092.x
   Rescorla R.A., 1972, CLASSICAL CONDITIONI, V2, P64, DOI DOI 10.1101/GR.110528.110
   RESCORLA RA, 1988, AM PSYCHOL, V43, P151, DOI 10.1037/0003-066X.43.3.151
   Roelofs A, 1997, COGNITION, V64, P249, DOI 10.1016/S0010-0277(97)00027-9
   Russell B., 1942, INQUIRY MEANING TRUT, DOI [10.1017/S0031819100003193, DOI 10.1017/S0031819100003193]
   Russell B, 1905, MIND, V14, P1905, DOI DOI 10.1093/MIND/XIV.4.479
   Scarf D, 2016, P NATL ACAD SCI USA, V113, P11272, DOI 10.1073/pnas.1607870113
   Schmid H, 1995, P ACL SIGDAT WORKSH, P47, DOI [DOI 10.1007/978-94-017-2390-9_2, 10.1007/978-94-017-2390-9_2]
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schreuder R., 1995, MORPHOLOGICAL ASPECT, P131, DOI DOI 10.1002/0470018860.S00254
   Schweitzer A., 2014, P 10 INT SEM SPEECH
   SEIDENBERG MS, 1987, ATTENTION PERFORM, P245
   Seidenberg MS, 2000, TRENDS COGN SCI, V4, P353, DOI 10.1016/S1364-6613(00)01515-1
   Sering T., 2018, STAT NEERL, P1
   Shafaei-Bajestan E., 2018, P INT 2018, DOI [10.21437/Interspeech.2018-2420, DOI 10.21437/INTERSPEECH.2018-2420]
   Shaoul C., 2015, NDL2 NAIVE DISCRIMIN
   Shaoul C, 2010, BEHAV RES METHODS, V42, P393, DOI 10.3758/BRM.42.2.393
   Shockey L., 1998, SOUND PATTERNS SPONT, P97
   Strobl C, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-25
   Stump Gregory T., 2001, INFLECTIONAL MORPHOL, DOI [10.1017/CBO9780511486333, DOI 10.1017/CBO9780511486333]
   TAFT M, 1994, LANG COGNITIVE PROC, V9, P271, DOI 10.1080/01690969408402120
   TAFT M, 1988, LINGUISTICS, V26, P657, DOI 10.1515/ling.1988.26.4.657
   Tomaschek F., 2018, MODELING DURAT UNPUB
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   Trimmer PC, 2012, J THEOR BIOL, V302, P39, DOI 10.1016/j.jtbi.2012.02.014
   Tucker B. V., 2018, OPPOSING FORCE UNPUB, DOI [10.1121/1.3508798, DOI 10.1121/1.3508798]
   Tuske Z, 2014, INTERSPEECH, P890
   Ussishkin A, 2005, NAT LANG LINGUIST TH, V23, P169, DOI 10.1007/s11049-003-7790-8
   Ussishkin A, 2006, MORPHOLOGY, V16, P107, DOI 10.1007/s11525-006-0005-3
   Van Orden GC, 2005, BL HBK DEV PSYCHOL, P61, DOI 10.1002/9780470757642.ch4
   Venables W. N., 2002, MODERN APPL STAT S P
   WAGNER RK, 1994, DEV PSYCHOL, V30, P73, DOI 10.1037/0012-1649.30.1.73
   Warriner AB, 2013, BEHAV RES METHODS, V45, P1191, DOI 10.3758/s13428-012-0314-x
   Weaver W., 1955, MACHINE TRANSLATION, V14, P15
   Weingarten R., 2004, MULTIDISCIPLINARY AP, V157, P529, DOI DOI 10.1515/9783110894028.529
   Widrow B., 1960, IRE Wescon Convention Record, V4, P96
   Wong KFE, 1999, LANG COGNITIVE PROC, V14, P461, DOI 10.1080/016909699386158
   Wood SN., 2017, GEN ADDITIVE MODELS
   Yao B, 2011, J COGNITIVE NEUROSCI, V23, P3146, DOI 10.1162/jocn_a_00022
   Young R. W., 1980, NAVAJO LANGUAGE GRAM, DOI [10.2307/1184395, DOI 10.2307/1184395]
   Zeller Britta, 2014, P COLING 2014 DUBL C, P1728
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zwitserlood P, 2018, STUD MORPHOL, V4, P583, DOI 10.1007/978-3-319-74394-3_20
NR 180
TC 18
Z9 18
U1 0
U2 3
PU WILEY-HINDAWI
PI LONDON
PA ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
SN 1076-2787
EI 1099-0526
J9 COMPLEXITY
JI Complexity
PY 2019
AR 4895891
DI 10.1155/2019/4895891
PG 39
WC Mathematics, Interdisciplinary Applications; Multidisciplinary Sciences
SC Mathematics; Science & Technology - Other Topics
GA HH5EI
UT WOS:000455748400001
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Nkyekyer, J
   Meyer, D
   Pipingas, A
   Reed, NS
AF Nkyekyer, Joanna
   Meyer, Denny
   Pipingas, Andrew
   Reed, Nicholas S.
TI The cognitive and psychosocial effects of auditory training and hearing
   aids in adults with hearing loss
SO CLINICAL INTERVENTIONS IN AGING
LA English
DT Article
DE cognition; depression; hearing loss intervention; speech perception
ID OLDER-ADULTS; FOLLOW-UP; DEMENTIA; IMPAIRMENT; EFFICACY
AB Purpose: Our study assessed the efficacy of the simultaneous use of hearing aids and auditory training for improving cognition and psychosocial function in adults with hearing loss, and the relationships between hearing loss, speech perception and cognition.
   Participants and methods: A 40-person (aged 50-90 years) pilot study in Melbourne, Australia, was conducted. Participants with hearing impairment completed the Geriatric Depression Scale-Short Form, questions about social activity participation, a wide range of cognitive tasks and a speech perception test at baseline, 3 and 6 months. Participants underwent auditory training for 6 months and used hearing aids for 3 months.
   Results: Correlations and structural equation modeling suggested that several cognitive domains were associated with speech perception at baseline, but only the Incongruent Stroop cognition measure was associated with hearing loss. Hearing aid use reduced problems with communication, but there were no significant improvements in speech perception, social interaction or cognition. The effect of hearing aids and auditory training for improving depressive symptoms was significant with a moderate to large effect size (Cohen's d=0.87).
   Conclusion: The small sample size and a relatively high rate of attrition meant that this study was underpowered. However, baseline results suggested relationships between hearing loss, speech perception and cognition, and the hearing intervention provided evidence of reduced depressive symptoms. A full-scale, randomized hearing loss intervention and a longer neuroimaging study with cognitive outcomes measured in the short term as well as after several years of hearing aid use are needed.
C1 [Nkyekyer, Joanna] Swinburne Univ Technol, Australian Res Council Training Ctr Biodevices, POB 218, Hawthorn, Vic 3122, Australia.
   [Meyer, Denny] Swinburne Univ Technol, Dept Stat Data Sci & Epidemiol, Melbourne, Vic, Australia.
   [Pipingas, Andrew] Swinburne Univ Technol, Ctr Human Psychopharmacol, Melbourne, Vic, Australia.
   [Reed, Nicholas S.] Johns Hopkins Univ, Bloomberg Sch Publ Hlth, Cochlear Ctr Hearing & Publ Hlth, Baltimore, MD USA.
RP Nkyekyer, J (corresponding author), Swinburne Univ Technol, Australian Res Council Training Ctr Biodevices, POB 218, Hawthorn, Vic 3122, Australia.
EM jnkyekyer@swin.edu.au
RI Meyer, Denny/H-6266-2016
OI Meyer, Denny/0000-0002-9902-0858
CR Acar B, 2011, ARCH GERONTOL GERIAT, V52, P250, DOI 10.1016/j.archger.2010.04.013
   BERKMAN LF, 1979, AM J EPIDEMIOL, V109, P186, DOI 10.1093/oxfordjournals.aje.a112674
   Blamey P, 2018, CAA CANADIAN AUDIOLO, V2
   BLAMEY P, 2010, HEARING AID BENEFIT
   Blamey P. J., 1994, RES AUDIOLOGICAL REH, V27, P161
   Blamey PJ, 2015, J TELEMED TELECARE, V21, P474, DOI 10.1177/1357633X15611568
   Boi R, 2012, GERIATR GERONTOL INT, V12, P440, DOI 10.1111/j.1447-0594.2011.00789.x
   Burke W J, 1991, J Geriatr Psychiatry Neurol, V4, P173, DOI 10.1177/089198879100400310
   Campbell J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00071
   Chien W, 2012, ARCH INTERN MED, V172, P292, DOI 10.1001/archinternmed.2011.1408
   COX RM, 1995, EAR HEARING, V16, P176, DOI 10.1097/00003446-199504000-00005
   Deal JA, 2017, J GERONTOL A-BIOL, V72, P703, DOI 10.1093/gerona/glw069
   DEFILIPPO CL, 1978, J ACOUST SOC AM, V63, P1186, DOI 10.1121/1.381827
   Enache D, 2011, CURR OPIN PSYCHIATR, V24, P461, DOI 10.1097/YCO.0b013e32834bb9d4
   Ferguson M, 2016, EAR HEARING, V37, P123, DOI 10.1097/AUD.0000000000000237
   GREENWALD BS, 1989, AM J PSYCHIAT, V146, P1472
   Henry B. A., 1998, SCI PUBL, V11, P1998
   Hughes Matthew E, 2018, JMIR Res Protoc, V7, pe174, DOI 10.2196/resprot.9916
   Humes LE, 2009, EAR HEARING, V30, P613, DOI 10.1097/AUD.0b013e3181b00d90
   Leon AC, 2011, J PSYCHIATR RES, V45, P626, DOI 10.1016/j.jpsychires.2010.10.008
   Lin FR, 2014, AGING MENT HEALTH, V18, P671, DOI 10.1080/13607863.2014.915924
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P1131, DOI 10.1093/gerona/glr115
   Lin FR, 2011, ARCH NEUROL-CHICAGO, V68, P214, DOI 10.1001/archneurol.2010.362
   Livingston G, 2017, LANCET, V390, P2673, DOI 10.1016/S0140-6736(17)31363-6
   Lunner T, 2003, INT J AUDIOL, V42, pS49
   Meister H, 2013, AM J AUDIOL, V22, P310, DOI 10.1044/1059-0889(2012/12-0067)
   Meyer C, 2012, INT J AUDIOL, V51, P66, DOI 10.3109/14992027.2011.611178
   Nkyekyer J, 2018, JMIR RES PROTOC, V7, DOI 10.2196/resprot.8936
   Olson Anne D., 2015, Seminars in Hearing, V36, P284, DOI 10.1055/s-0035-1564461
   PETERSON GE, 1962, J SPEECH HEAR DISORD, V27, P62, DOI 10.1044/jshd.2701.62
   Pipingas A, 2010, CURR TOP NUTRACEUT R, V8, P79
   Roberts KL, 2008, J COGNITIVE NEUROSCI, V20, P1063, DOI 10.1162/jocn.2008.20074
   SHEIKH J I, 1986, Clinical Gerontologist, V5, P165
   Strawbridge WJ, 2000, GERONTOLOGIST, V40, P320, DOI 10.1093/geront/40.3.320
   Sweetow Robert, 2005, J Am Acad Audiol, V16, P494, DOI 10.3766/jaaa.16.7.9
   Valentijn SAM, 2005, J AM GERIATR SOC, V53, P374, DOI 10.1111/j.1532-5415.2005.53152.x
   World Med Assoc, 2013, JAMA-J AM MED ASSOC, V310, P2191, DOI 10.1001/jama.2013.281053
NR 37
TC 5
Z9 5
U1 3
U2 8
PU DOVE MEDICAL PRESS LTD
PI ALBANY
PA PO BOX 300-008, ALBANY, AUCKLAND 0752, NEW ZEALAND
SN 1178-1998
J9 CLIN INTERV AGING
JI Clin. Interv. Aging
PY 2019
VL 14
BP 123
EP 135
DI 10.2147/CIA.S183905
PG 13
WC Geriatrics & Gerontology
SC Geriatrics & Gerontology
GA HH1XO
UT WOS:000455513400002
PM 30666098
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Gutierrez, A
AF Gutierrez, Analia
TI A REANALYSIS OF NIVACLE (kl)over-cap AND l: PHONETIC, PHONOLOGICAL, AND
   TYPOLOGICAL EVIDENCE
SO INTERNATIONAL JOURNAL OF AMERICAN LINGUISTICS
LA English
DT Article
DE Nivacle; Mataguayan; phonology; typology; laterals
AB This paper describes and analyzes the typologically unique lateral system of Nivacle (Mataguayan). There is no lateral approximant in this language, but rather two lateral obstruents: the lateral fricative /l/ and the complex segment /(kl) over cap/. These two sounds behave differently in terms of both their phonotactic patterning and their morphophonemic alternations; they do not participate in any phonological processes that invoke their lateral articulation as a shared phonologically relevant property. The main proposal advanced here is that /(kl) over cap/ is a complex segment and not an affricate: (i) there is no fricative release and (ii) the sequence of two phases does not agree in voicing. Further, it is hypothesized that the development of /(kl) over cap/ from Proto-Mataguayan *l can be rooted in speech perception factors. Namely, the lateral approximant was realized with a brief stop closure which was misinterpreted as a real stop burst and reanalyzed as /(kl) over cap/.
C1 [Gutierrez, Analia] Consejo Nacl Invest Cient & Tecn, Buenos Aires, DF, Argentina.
RP Gutierrez, A (corresponding author), Consejo Nacl Invest Cient & Tecn, Buenos Aires, DF, Argentina.
FU Jacobs Research Funds (Whatcom Museum, 2010); Bottom Billion Fieldwork
   Fund (Liu Institute for Global Issues, University of British Columbia,
   2011); Endangered Languages Documentation Programme (School of Oriental
   and African Studies, University of London, 2012)
FX First and foremost, I would like to express my sincere gratitude to my
   consultants Felix Ramirez Flores, Sara Rojas Nunez, Teresita Sanchez,
   and Raquel Fleitas Gonzalez for teaching me their language with patience
   and generosity. Many thanks to Patricia A. Shaw, Gunnar Hansson, and
   Molly Babel for their very valuable and detailed comments on drafts of
   this work. I am also grateful for the help of David Beck, an associate
   editor of IJAL, and three anonymous reviewers, whose insights and
   suggestions greatly improved this paper. Any remaining errors are my
   own. My fieldwork research was funded by the Jacobs Research Funds
   (Whatcom Museum, 2010), the Bottom Billion Fieldwork Fund (Liu Institute
   for Global Issues, University of British Columbia, 2011), and a Small
   Grant from the Endangered Languages Documentation Programme (School of
   Oriental and African Studies, University of London, 2012). I sincerely
   thank each of these sources for supporting my work.
CR arnason K., 2011, PHONOLOGY ICELANDIC
   BAUER MATT, 2006, U PENNSYLVANIA WORKI, V12, P39
   BEAUMONT CH, 1979, TIGAK LANGUAGE NEW I
   BECKMAN JILL, 2004, INT J ENGLISH STUDIE, V4, P105
   BrandaoDeCarvalho J, 2008, STUD GENERAT GRAMM, V99, P1, DOI 10.1515/9783110211443
   Campbell Lyle, 2007, DIACHRONICA, V24, P1
   Carol J., 2014, LENGUA CHOROTE MATAG
   Chase-Sardi Miguel, 1981, PEQUENO DECAMERON NI
   Clements George N., 1995, HDB PHONOLOGICAL THE, P245
   Colantoni Laura, 2005, THEORETICAL EXPT APP, P59
   DE LACY PAUL, 2001, P HUMIT 2000 MITWPL
   DGEEC, 2012, 3 CENS NAC IND POBL
   Dilley L, 1996, J PHONETICS, V24, P423, DOI 10.1006/jpho.1996.0023
   Dryer Matthew S., 2013, WORLD ATLAS LANGUAGE
   ESCURE G, 1977, LINGUA, V43, P55, DOI 10.1016/0024-3841(77)90048-1
   Esling John H., 2001, J INT PHON ASSOC, V31, P275, DOI [10.1017/S0025100301002092, DOI 10.1017/S0025100301002092]
   FABRE ALAIN, 2015, ESTUDIO GRAMMATICAL
   Flemming E, 2008, J PHONETICS, V36, P465, DOI 10.1016/j.wocn.2007.10.002
   Francois A, 2010, PHONOLOGY, V27, P393, DOI 10.1017/S0952675710000205
   Garvin PL, 1948, INT J AM LINGUIST, V14, P37, DOI 10.1086/463977
   Gerzenstein A., 1994, LENGUA MAKA ESTUDIO
   Gerzenstein Ana, 1999, DICCIONARIO ETNOLING
   GERZENSTEIN ANA, 1983, LENGUA CHOROTE VARIE
   Greenberg J. H., 1987, LANGUAGE AM
   Gutierrez A. A., 2015, THESIS
   Gutierrez Analia, 2016, LINGUAS INDIGENAS AM, V16, P323
   Hansson Gunnar O, 1996, PHONETICS PHON UNPUB
   Henry Jules, 1936, IJAL, V10, P86
   Hock Hans Henrich, 1986, PRINCIPLES HIST LING
   Hollien H., 1979, P IPS 77 C MAIM BEAC, P501
   Hunt Richard, 1915, REV MUSEO LA PLATA, V23, P257
   Hyman L. M., 1975, PHONOLOGY THEORY ANA
   INSTITUTO NACIONAL DE ESTADISTICA Y CENSOS (indec), 2004, ENC COMPL PUEBL IND
   ITO J, 1989, NAT LANG LINGUIST TH, V7, P217, DOI 10.1007/BF00138077
   Ito Junko, 1986, THESIS
   Junker Paulino, 1968, ANTROPOLOGICO      S, V3, P159
   Kari James, 1990, AHTNA ATHAPASKAN DIC
   Kaufman Terrence., 1990, AMAZONIAN LINGUISTIC, P3
   Keating P., 2006, SPEECH PRODUCTION MO, P167
   Keating P., 2003, PAPERS LAB PHONOLOGY, P143, DOI DOI 10.1121/1.380986
   KEATING PATRICIA, 1997, UCLA WORKING PAPERS, V92, P88
   Kirchner R, 1998, THESIS U CALIFORNIA
   KLEIN HM, 1977, ANTHROPOL LINGUIST, V19, P378
   KRAUSE SCOTT RUSSELL, 1980, THESIS
   KUIPERS AH, 1960, PHONEME MORPHEME KAB
   Ladefoged Peter, 1996, SOUNDS WORLDS LANGUA
   Lass Roger, 1984, PHONOLOGY
   Lavoie L., 2001, CONSONANT STRENGTH P
   MADDIESON I, 1984, PHONETICA, V41, P181, DOI 10.1159/000261725
   Maddieson I., 2001, ANTHROPOL LINGUIST, V43, P135
   Maddieson I., 1984, PATTERNS SOUNDS
   Maddieson Ian, 2013, WORLD ATLAS LANGUAGE
   Najlis Elena L., 1984, CUADERNOS LINGUISTIC, V9
   Narayanan SS, 1997, J ACOUST SOC AM, V101, P1064, DOI 10.1121/1.418030
   NERCESIAN V., 2014, WICHI LHOMTES ESTUDI
   Ohala J. J., 1997, P 4 SEOUL INT C LING, P84
   Ohala J. J., 1993, HIST LINGUISTICS PRO, P237
   Ohala John, 1981, PAPERS PARASESSION L, P178
   Recasens D., 2005, J INT PHON ASSOC, V35, DOI [DOI 10.1017/S0025100305001878, 10.1017/S0025100305001878]
   Round E, 2014, LANGUAGE DESCRIPTION, P81
   SIVERTSEN E, 1956, INT J AM LINGUIST, V22, P117, DOI 10.1086/464356
   Smith Jennifer L., 2002, THESIS
   STEED WILLIAM, 2004, P 10 AUSTR INT C SPE, P346
   Stell Nelida N., 1987, THESIS
   Stell Noemi Nelida, 1972, FONOLOGIA LENGUA AXL
   STONHAM J, 1999, ASPECTS TSISHAATH NO
   Tovar Antonio, 1961, CATALOGO LENGUAS AM
   Vennemann Theo, 1988, PREFERENCE LAWS SYLL
   WICKE CR, 1969, ETHNOLOGY, V8, P484, DOI 10.2307/3772913
NR 69
TC 1
Z9 1
U1 1
U2 1
PU UNIV CHICAGO PRESS
PI CHICAGO
PA 1427 E 60TH ST, CHICAGO, IL 60637-2954 USA
SN 0020-7071
EI 1545-7001
J9 INT J AM LINGUIST
JI Int. J. Am. Linguist.
PD JAN 1
PY 2019
VL 85
IS 1
BP 45
EP 74
DI 10.1086/700318
PG 30
WC Linguistics; Language & Linguistics
SC Linguistics
GA HG5LL
UT WOS:000455018300003
DA 2021-02-24
ER

PT J
AU Bylund, E
   Abrahamsson, N
   Hyltenstam, K
   Norrman, G
AF Bylund, Emanuel
   Abrahamsson, Niclas
   Hyltenstam, Kenneth
   Norrman, Gunnar
TI Revisiting the bilingual lexical deficit: The impact of age of
   acquisition
SO COGNITION
LA English
DT Article
DE Bilingualism; Lexical deficit; Age of acquisition; International
   adoptees; Cognitive advantage
ID SPEECH-PERCEPTION; LANGUAGE-DEVELOPMENT; VOCABULARY; PLASTICITY;
   ENGLISH; ADULTS; 1ST
AB Whereas the cognitive advantages brought about by bilingualism have recently been called into question, the so-called 'lexical deficit' in bilinguals is still largely taken for granted. Here, we argue that, in analogy with cognitive advantages, the lexical deficit does not apply across the board of bilinguals, but varies as a function of acquisition trajectory. To test this, we implement a novel methodological design, where the variables of bilingualism and first/second language status have been fully crossed in four different groups. While the results confirm effects of bilingualism on lexical proficiency and processing, they show more robust effects of age of acquisition. We conclude that the traditional view of the linguistic costs of bilingualism need to give way to a new understanding of lexical development in which age of acquisition is seen as a major determinant.
C1 [Bylund, Emanuel] Stellenbosch Univ, Stellenbosch, South Africa.
   [Bylund, Emanuel; Abrahamsson, Niclas; Hyltenstam, Kenneth; Norrman, Gunnar] Stockholm Univ, Ctr Res Bilingualism, Stockholm, Sweden.
RP Bylund, E (corresponding author), Dept Gen Linguist, ZA-7600 Stellenbosch, South Africa.
EM mbylund@sun.ac.za
OI Norrman, Gunnar/0000-0001-7915-6777
FU Riksbankens Jubileumsfond (The Bank of Sweden Tercentenary Foundation)
   [M2005-0459, SAB16-0051:1]
FX We are thankful to the three anonymous reviewers for providing
   insightful comments on a previous version of the manuscript. This
   research was funded by Riksbankens Jubileumsfond (The Bank of Sweden
   Tercentenary Foundation), grant no. M2005-0459 (to K.H.) and grant no.
   SAB16-0051:1 (to N.A.).
CR Abrahamsson N, 2009, LANG LEARN, V59, P249, DOI 10.1111/j.1467-9922.2009.00507.x
   BAAYEN FTH, 2010, INTERNATIONAL JOURNA, V3, P12
   Baayen RH, 2008, J MEM LANG, V59, P390, DOI 10.1016/j.jml.2007.12.005
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2013, J STAT SOFTW, V52, P1, DOI 10.18637/jss.v052.i05
   Bialystok E, 2017, PSYCHOL BULL, V143, P233, DOI 10.1037/bul0000099
   Bialystok E, 2016, LINGUIST APPROACH BI, V6, P517, DOI 10.1075/lab.15040.bia
   Bialystok E, 2008, J NEUROLINGUIST, V21, P522, DOI 10.1016/j.jneuroling.2007.07.001
   Bowers JS, 2009, PSYCHOL SCI, V20, P1064, DOI 10.1111/j.1467-9280.2009.02407.x
   Choi D., 2018, MIND BRAIN EDUC, P1, DOI 10.1111/mbe.12162
   De Baene W, 2015, J COGNITIVE NEUROSCI, V27, P1752, DOI 10.1162/jocn_a_00817
   Hernandez A, 2005, TRENDS COGN SCI, V9, P220, DOI 10.1016/j.tics.2005.03.003
   Hernandez A. E., J NEUROLINGUISTICS
   Hernandez AE, 2007, PSYCHOL BULL, V133, P638, DOI 10.1037/0033-2909.133.4.638
   Hernandez Arturo E., 2013, THE BILINGUAL BRAIN
   Hyltenstam K, 2009, BILING-LANG COGN, V12, P121, DOI 10.1017/S1366728908004008
   JOHNSON JS, 1989, COGNITIVE PSYCHOL, V21, P60, DOI 10.1016/0010-0285(89)90003-0
   Kaplan E., 1983, LEA
   Kroll JF, 2014, CURR DIR PSYCHOL SCI, V23, P159, DOI 10.1177/0963721414528511
   Kupisch T, 2013, LINGUIST APPROACH BI, V3, P150, DOI 10.1075/lab.3.2.02kup
   Kupisch T, 2012, BILING-LANG COGN, V15, P736, DOI 10.1017/S1366728911000691
   Lehtonen M, 2018, PSYCHOL BULL, V144, P394, DOI 10.1037/bul0000142
   Lenneberg E. H., 1967, BIOL FDN LANGUAGE
   Li P, 2016, BILING-LANG COGN, V19, P657, DOI 10.1017/S1366728915000280
   Li P, 2015, CORTEX, V73, P358, DOI 10.1016/j.cortex.2015.07.013
   Li P, 2009, COGNITIVE SCI, V33, P629, DOI 10.1111/j.1551-6709.2009.01028.x
   Luk G, 2013, J COGN PSYCHOL, V25, P605, DOI 10.1080/20445911.2013.795574
   Luk G, 2012, LANG COGNITIVE PROC, V27, P1479, DOI 10.1080/01690965.2011.613209
   MacWhinney B, 2005, HDB BILINGUALISM PSY, P49
   MacWhinney B., 1987, PRESS
   Nishikawa T, 2014, APPL LINGUIST, V35, P504, DOI 10.1093/applin/amu018
   Norrman G., 2016, STARTING LANGUAGE DE, P125
   Norrman G, 2016, DEVELOPMENTAL SCI, V19, P513, DOI 10.1111/desc.12332
   Pallier C, 2003, CEREB CORTEX, V13, P155, DOI 10.1093/cercor/13.2.155
   Pelham SD, 2014, J EXP PSYCHOL LEARN, V40, P313, DOI 10.1037/a0035224
   Pierce LJ, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms10073
   Pierce LJ, 2014, P NATL ACAD SCI USA, V111, P17314, DOI 10.1073/pnas.1409411111
   Pinker S., 1994, LANGUAGE INSTINCT MI
   Portocarrero JS, 2007, ARCH CLIN NEUROPSYCH, V22, P415, DOI 10.1016/j.acn.2007.01.015
   R Core Team, 2014, R FDN STAT COMP
   Revisiting the bilingual lexical deficit Open Science Framework, FRAMEWORK
   Rivera-Gaxiola M, 2005, NEUROREPORT, V16, P495, DOI 10.1097/00001756-200504040-00015
   Schmid MS, 2012, LINGUIST APPROACH BI, V2, P177, DOI 10.1075/lab.2.2.03sch
   SEBASTIAN G, 2005, JOURNAL OF MEMORY AN, V52, P240
   Singh L, 2011, DEVELOPMENTAL SCI, V14, P949, DOI 10.1111/j.1467-7687.2011.01044.x
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Vaughn KA, 2018, J NEUROLINGUIST, V46, P69, DOI 10.1016/j.jneuroling.2017.12.012
   Ventureyra VAG, 2004, J NEUROLINGUIST, V17, P79, DOI 10.1016/S0911-6044(03)00053-8
   Waldron EJ, 2013, BRAIN LANG, V125, P28, DOI 10.1016/j.bandl.2013.01.002
   Weikum WM, 2012, P NATL ACAD SCI USA, V109, P17221, DOI 10.1073/pnas.1121263109
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   Werker JF, 2005, DEV PSYCHOBIOL, V46, P233, DOI 10.1002/dev.20060
   Werker JF, 1999, ANNU REV PSYCHOL, V50, P509, DOI 10.1146/annurev.psych.50.1.509
NR 53
TC 5
Z9 5
U1 0
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD JAN
PY 2019
VL 182
BP 45
EP 49
DI 10.1016/j.cognition.2018.08.020
PG 5
WC Psychology, Experimental
SC Psychology
GA HF6VG
UT WOS:000454375800006
PM 30216899
DA 2021-02-24
ER

PT J
AU Gonzales, K
   Byers-Heinlein, K
   Lotto, AJ
AF Gonzales, Kalim
   Byers-Heinlein, Krista
   Lotto, Andrew J.
TI How bilinguals perceive speech depends on which language they think
   they're hearing
SO COGNITION
LA English
DT Article
DE Language switching; Speech perception; Top-down processing; Neural
   network models; Rational listener
ID DOUBLE PHONEMIC-BOUNDARY; VOICE-ONSET TIME; RANK TRANSFORMATIONS;
   FOREIGN-LANGUAGE; T-TEST; ENGLISH; PERCEPTION; FRENCH; SPANISH; CONTEXT
AB Bilinguals understand when the communication context calls for speaking a particular language and can switch from speaking one language to speaking the other based on such conceptual knowledge. There is disagreement regarding whether conceptually-based language selection is also possible in the listening modality. For example, can bilingual listeners perceptually adjust to changes in pronunciation across languages based on their conceptual understanding of which language they're currently hearing? We asked French- and Spanish-English bilinguals to identify nonsense monosyllables as beginning with /b/ or /p/, speech categories that French and Spanish speakers pronounce differently than English speakers. We conceptually cued each bilingual group to one of their two languages or the other by explicitly instructing them that the speech items were word onsets in that language, uttered by a native speaker thereof. Both groups adjusted their /b-p/ identification boundary as a function of this conceptual cue to the language context. These results support a bilingual model permitting conceptually-based language selection on both the speaking and listening end of a communicative exchange.
C1 [Gonzales, Kalim] Huanghuai Univ, Zhumadian 463000, Peoples R China.
   [Byers-Heinlein, Krista] Concordia Univ, Dept Psychol, Montreal, PQ H4B 1R6, Canada.
   [Lotto, Andrew J.] Univ Florida, Dept Speech Language & Hearing Sci, Gainesville, FL 32610 USA.
RP Gonzales, K (corresponding author), Huanghuai Univ, Zhumadian 463000, Peoples R China.
EM kalim_gonzales@yahoo.com; k.byers@concordia.ca; alotto@phhp.ufl.edu
RI Gonzales, Kalim/L-6956-2019
OI Gonzales, Kalim/0000-0003-2598-1338
FU University of Arizona Graduate Diversity Fellowship; NSERCNatural
   Sciences and Engineering Research Council of Canada (NSERC)
   [402470-2011]
FX We thank Jennifer Arnold and two anonymous reviewers for insightful
   feedback; Jessica Londei-Shortall and Olimplia Rosenthal for recording
   the stimuli for French- and Spanish-English bilinguals, respectively;
   and Melanie Brouillard and Chelsea da Estrela for assistance in
   implementing the study and testing participants. This study was
   supported by NSERC 402470-2011 to K.B.-H and by a University of Arizona
   Graduate Diversity Fellowship to K.G.
CR Antoniou M, 2012, J PHONETICS, V40, P582, DOI 10.1016/j.wocn.2012.05.005
   Beaudrie SM, 2011, FOREIGN LANG ANN, V44, P321, DOI 10.1111/j.1944-9720.2011.01137.x
   Blanco-Elorrieta E, 2016, J NEUROSCI, V36, P290, DOI 10.1523/JNEUROSCI.2597-15.2016
   Boberg C, 2012, WORLD ENGLISH, V31, P493, DOI 10.1111/j.1467-971X.2012.01776.x
   Boersma P., 2010, PRAAT DOING PHONETIC
   Bosker HR, 2017, J MEM LANG, V94, P166, DOI 10.1016/j.jml.2016.12.002
   Byers-Heinlein K, 2014, LANG LEARN, V64, P184, DOI 10.1111/lang.12055
   CARAMAZZA A, 1974, CAN J PSYCHOL, V28, P310, DOI 10.1037/h0081997
   CARAMAZZA A, 1973, J ACOUST SOC AM, V54, P421, DOI 10.1121/1.1913594
   Carlson MT, 2019, BILING-LANG COGN, V22, P1101, DOI 10.1017/S136672891800086X
   Casillas JV, 2018, J PHONETICS, V71, P51, DOI 10.1016/j.wocn.2018.07.002
   Colantoni L, 2008, APPL PSYCHOLINGUIST, V29, P489, DOI 10.1017/S0142716408080223
   CONOVER WJ, 1981, AM STAT, V35, P124, DOI 10.2307/2683975
   Corder G. W., 2009, NONPARAMENIC STAT NO
   Dalbor J., 1980, SPANISH PRONUNCIATIO
   Dijkstra T, 1998, SCI PSYCH S, P189
   Dijkstra T, 2002, BILING-LANG COGN, V5, P175, DOI 10.1017/S1366728902003012
   ELMAN JL, 1977, J ACOUST SOC AM, V62, P971, DOI 10.1121/1.381591
   Fagerland MW, 2009, STAT MED, V28, P1487, DOI 10.1002/sim.3561
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   FLEGE JE, 1994, J ACOUST SOC AM, V95, P3623, DOI 10.1121/1.409931
   FLEGE JE, 1987, SPEECH COMMUN, V6, P185, DOI 10.1016/0167-6393(87)90025-2
   FLEGE JE, 1984, J ACOUST SOC AM, V76, P708, DOI 10.1121/1.391257
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   French R. M., 1998, SIMPLE RECURRENT NET, P368
   French RM, 2004, TRENDS COGN SCI, V8, P87, DOI 10.1016/j.tics.2003.12.011
   Garcia-Sierra A, 2012, BRAIN LANG, V121, P194, DOI 10.1016/j.bandl.2012.03.008
   Garcia-Sierra A, 2009, SPEECH COMMUN, V51, P369, DOI 10.1016/j.specom.2008.11.005
   Gonzales K, 2018, COGNITIVE PSYCHOL, V106, P1, DOI 10.1016/j.cogpsych.2018.04.003
   Gonzales K, 2015, COGNITION, V140, P60, DOI 10.1016/j.cognition.2015.03.015
   Gonzales K, 2013, PSYCHOL SCI, V24, P2135, DOI 10.1177/0956797613486485
   Grainger J., 2010, LANG ACQUIS, P267, DOI DOI 10.1075/LALD.52.18GRA
   Green D. W., 1998, BILING-LANG COGN, V1, P67, DOI [10.1017/S1366728998000133, DOI 10.1017/S1366728998000133]
   Grosjean F. M. J., 1988, LANG COGNITIVE PROC, V3, P233, DOI DOI 10.1080/01690968808402089
   Grosjean FF., 2008, STUDYING BILINGUALS, DOI [10.1006/jpho.1999.0097, DOI 10.1006/JPHO.1999.0097]
   Halle PA, 1999, J PHONETICS, V27, P281, DOI 10.1006/jpho.1999.0097
   Hartsuiker R., 2011, LINCOM STUDIES THEOR, V44, P180
   Hay J. F, 2005, THESIS
   HAZAN VL, 1993, LANG SPEECH, V36, P17, DOI 10.1177/002383099303600102
   Heald SLM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00035
   Hernandez A, 2005, TRENDS COGN SCI, V9, P220, DOI 10.1016/j.tics.2005.03.003
   HETTMANSPERGER TP, 1978, PSYCHOMETRIKA, V43, P69, DOI 10.1007/BF02294090
   Hirschfeld LA, 1997, COGNITIVE DEV, V12, P213, DOI 10.1016/S0885-2014(97)90014-9
   Jacquet M, 2002, BILING-LANG COGN, V5, P202, DOI 10.1017/S1366728902223019
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Ju M, 2004, PSYCHOL SCI, V15, P314, DOI 10.1111/j.0956-7976.2004.00675.x
   Kandhadai P, 2014, TRENDS NEUROSCI EDUC, V3, P24, DOI 10.1016/j.tine.2014.02.001
   Kehoe MM., 2004, BILINGUALISM LANGUAG, V7, P71, DOI DOI 10.1017/S1366728904001282
   Kessinger RH, 1997, J PHONETICS, V25, P143, DOI 10.1006/jpho.1996.0039
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Knightly LM, 2003, J ACOUST SOC AM, V114, P465, DOI 10.1121/1.1577560
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299
   Lagrou E, 2013, BILING-LANG COGN, V16, P508, DOI 10.1017/S1366728912000508
   Laing EJC, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00203
   Levy ES, 2009, J ACOUST SOC AM, V125, P1138, DOI 10.1121/1.3050256
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006
   LI P, 2002, BILINGUAL SENTENCE P
   Li P., 1998, BILING-LANG COGN, V1, P92
   Liberman Z, 2017, COGNITIVE SCI, V41, P622, DOI 10.1111/cogs.12403
   Lisker L., 1970, P 6 INT C PHON SCI P, P563
   Llanos F, 2017, LANG SPEECH, V60, P3, DOI 10.1177/0023830915623579
   MacLeod AAN, 2009, APPL PSYCHOLINGUIST, V30, P53, DOI 10.1017/S0142716408090036
   MACNAMARA J, 1971, J VERB LEARN VERB BE, V10, P480, DOI 10.1016/S0022-5371(71)80018-X
   MACNAMARA J, 1967, J SOC ISSUES, V23, P58, DOI 10.1111/j.1540-4560.1967.tb00576.x
   Marian V, 2003, APPL PSYCHOLINGUIST, V24, P173, DOI 10.1017/S0142716403000092
   Marion V, 2007, J SPEECH LANG HEAR R, V50, P940, DOI 10.1044/1092-4388(2007/067)
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   Miikkulainen R., 1993, SUBSYMBOLIC NATURAL
   Molnar M, 2015, J MEM LANG, V81, P91, DOI 10.1016/j.jml.2015.01.002
   Morrison GS, 2007, SEGMENTAL PROSODIC I, P219
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Norman D. A., 1986, CONSCIOUSNESS SELF R, P1, DOI [DOI 10.1007/978-1-4757-0629-1_1, 10.1007/978-1-4757-0629-1_1.]
   Osborn D. M., 2016, THESIS
   Pajak B, 2016, LANG LEARN, V66, P900, DOI 10.1111/lang.12168
   Pellikka J, 2015, BRAIN LANG, V142, P8, DOI 10.1016/j.bandl.2015.01.006
   Quam C, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169001
   Rose M, 2012, FOREIGN LANG ANN, V45, P415, DOI 10.1111/j.1944-9720.2012.01197.x
   Ruxton GD, 2006, BEHAV ECOL, V17, P688, DOI 10.1093/beheco/ark016
   Schulpen B, 2003, J EXP PSYCHOL HUMAN, V29, P1155, DOI 10.1037/0096-1523.29.6.1155
   Shook A, 2013, BILING-LANG COGN, V16, P304, DOI 10.1017/S1366728912000466
   Silverberg S, 2004, J MEM LANG, V51, P381, DOI 10.1016/j.jml.2004.05.003
   Simonet M., 2016, OXFORD HDB ONLINE SC, P1, DOI [10.1093/oxfordhb/9780199935345.013.72, DOI 10.1093/OXFORDHB/9780199935345.013.72]
   Singh L, 2016, J EXP CHILD PSYCHOL, V147, P111, DOI 10.1016/j.jecp.2016.03.006
   Singh L, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00667
   Sundara M, 2006, BILING-LANG COGN, V9, P97, DOI 10.1017/S1366728905002403
   Tare M, 2010, J COGN DEV, V11, P137, DOI 10.1080/15248371003699951
   Vitevitch MS, 2012, BILING-LANG COGN, V15, P167, DOI 10.1017/S1366728911000149
   WILLIAMS L, 1977, PERCEPT PSYCHOPHYS, V21, P289, DOI 10.3758/BF03199477
   Zampini M. L., 2001, ONE MIND 2 LANGUAGES, P23
   Zhang S, 2013, P NATL ACAD SCI USA, V110, P11272, DOI 10.1073/pnas.1304435110
   Zhao JJ, 2008, NEUROIMAGE, V43, P624, DOI 10.1016/j.neuroimage.2008.07.025
   Zimmerman DW, 2012, BRIT J MATH STAT PSY, V65, P122, DOI 10.1111/j.2044-8317.2011.02017.x
   Zimmerman DW, 2011, PSICOLOGICA, V32, P65
   ZIMMERMAN DW, 1993, CAN J EXP PSYCHOL, V47, P523, DOI 10.1037/h0078850
NR 94
TC 3
Z9 3
U1 0
U2 12
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0010-0277
EI 1873-7838
J9 COGNITION
JI Cognition
PD JAN
PY 2019
VL 182
BP 318
EP 330
DI 10.1016/j.cognition.2018.08.021
PG 13
WC Psychology, Experimental
SC Psychology
GA HF6VG
UT WOS:000454375800030
PM 30415133
DA 2021-02-24
ER

PT J
AU Maslowski, M
   Meyer, AS
   Bosker, HR
AF Maslowski, Merel
   Meyer, Antje S.
   Bosker, Hans Rutger
TI How the Tracking of Habitual Rate Influences Speech Perception
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION
LA English
DT Article
DE speech rate; rate-dependent perception; rate normalization; habitual
   speech rate
ID INDIVIDUAL TALKER DIFFERENCES; SPEAKING RATE; CONTEXT; VOICE;
   VARIABILITY; SENSITIVITY; INFANTS; MEMORY; WORDS
AB Listeners are known to track statistical regularities in speech. Yet, which temporal cues are encoded is unclear. This study tested effects of talker-specific habitual speech rate and talker-independent average speech rate (heard over a longer period of time) on the perception of the temporal Dutch vowel contrast /alpha/-/a:/. First, Experiment 1 replicated that slow local (surrounding) speech contexts induce fewer long /a:/ responses than faster contexts. Experiment 2 tested effects of long-term habitual speech rate. A high-rate group listened to ambiguous vowels embedded in "neutral" speech from Talker A, intermixed with fast speech from Talker B. A low-rate group listened to the same neutral speech from Talker A, and/but to Talker B speaking at a slow rate. Between-groups comparison of the neutral trials showed that the high-rate group demonstrated a lower proportion of /a:/ responses, indicating that Talker A's habitual speech rate sounded slower when B was faster. In Experiment 3, both talkers produced speech at both rates, removing the different habitual speech rates of Talkers A and B. while maintaining the average rates differing between groups. In Experiment 3, no global rate effect was observed. Taken together, the present experiments show that a talker's habitual rate is encoded relative to the habitual rate of another talker, carrying implications for episodic and constraint-based models of speech perception.
C1 [Maslowski, Merel; Meyer, Antje S.; Bosker, Hans Rutger] Max Planck Inst Psycholinguist, Postbus 310, NL-6500 AH Nijmegen, Netherlands.
   [Maslowski, Merel] Int Max Planck Res Sch Language Sci, Nijmegen, Netherlands.
   [Meyer, Antje S.] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Nijmegen, Netherlands.
RP Maslowski, M (corresponding author), Max Planck Inst Psycholinguist, Postbus 310, NL-6500 AH Nijmegen, Netherlands.
EM Merel.Maslowski@mpi.nl
RI Maslowski, Merel/AAK-1828-2020
OI Bosker, Hans Rutger/0000-0002-2628-7738
CR Adank P, 2004, J ACOUST SOC AM, V116, P1729, DOI 10.1121/1.1779271
   Allen JS, 2004, J ACOUST SOC AM, V115, P3171, DOI 10.1121/1.1701898
   Baese-Berk MM, 2014, PSYCHOL SCI, V25, P1546, DOI 10.1177/0956797614533705
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bosker HR, 2017, J EXP PSYCHOL LEARN, V43, P1225, DOI 10.1037/xlm0000381
   Bosker HR, 2017, J MEM LANG, V94, P166, DOI 10.1016/j.jml.2016.12.002
   Bosker HR, 2017, ATTEN PERCEPT PSYCHO, V79, P333, DOI 10.3758/s13414-016-1206-4
   Bybee J., 2006, FREQUENCY USE ORG LA
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Cooper A, 2015, ATTEN PERCEPT PSYCHO, V77, P1342, DOI 10.3758/s13414-015-0855-z
   Creel SC, 2011, LANG LINGUIST COMPAS, V5, P190, DOI 10.1111/j.1749-818x.2011.00276.x
   Creel SC, 2012, LANG COGNITIVE PROC, V27, P1021, DOI 10.1080/01690965.2011.610597
   de Brouwer AJ, 2016, I-PERCEPTION, V7, DOI 10.1177/2041669516669155
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   Goldinger S. D., 1992, THESIS
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Jones MR, 2005, PERCEPT PSYCHOPHYS, V67, P398, DOI 10.3758/BF03193320
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Maye J, 2008, DEVELOPMENTAL SCI, V11, P122, DOI 10.1111/j.1467-7687.2007.00653.x
   McAuley JD, 2007, PERCEPT PSYCHOPHYS, V69, P709, DOI 10.3758/BF03193773
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   MILLER JL, 1984, PHONETICA, V41, P215, DOI 10.1159/000261728
   MILLER JL, 1981, PHONETICA, V38, P159, DOI 10.1159/000260021
   Newman RS, 2009, J PHONETICS, V37, P46, DOI 10.1016/j.wocn.2008.09.001
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   PISONI DB, 1993, SPEECH COMMUN, V13, P109, DOI 10.1016/0167-6393(93)90063-Q
   Pitt MA, 2016, ATTEN PERCEPT PSYCHO, V78, P334, DOI 10.3758/s13414-015-0981-7
   Pufahl A, 2014, COGNITIVE PSYCHOL, V70, P1, DOI 10.1016/j.cogpsych.2014.01.001
   Quene H, 2008, J ACOUST SOC AM, V123, P1104, DOI 10.1121/1.2821762
   R Core Team, 2014, R LANG ENV STAT COMP
   Reinisch E, 2016, APPL PSYCHOLINGUIST, V37, P1397, DOI 10.1017/S0142716415000612
   Reinisch E, 2013, J PHONETICS, V41, P101, DOI 10.1016/j.wocn.2013.01.002
   Reinisch E, 2011, J EXP PSYCHOL HUMAN, V37, P978, DOI 10.1037/a0021923
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Saffran JR, 1999, COGNITION, V70, P27, DOI 10.1016/S0010-0277(98)00075-4
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   Theodore RM, 2009, J ACOUST SOC AM, V125, P3974, DOI 10.1121/1.3106131
   Wade T, 2005, PERCEPT PSYCHOPHYS, V67, P939, DOI 10.3758/BF03193621
NR 40
TC 16
Z9 15
U1 0
U2 6
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0278-7393
EI 1939-1285
J9 J EXP PSYCHOL LEARN
JI J. Exp. Psychol.-Learn. Mem. Cogn.
PD JAN
PY 2019
VL 45
IS 1
BP 128
EP 138
DI 10.1037/xlm0000579
PG 11
WC Psychology; Psychology, Experimental
SC Psychology
GA HF6AP
UT WOS:000454316200010
PM 29698048
OA Green Published
DA 2021-02-24
ER

PT J
AU Mueller, JL
   Friederici, AD
   Mannel, C
AF Mueller, Jutta L.
   Friederici, Angela D.
   Maennel, Claudia
TI Developmental changes in automatic rule-learning mechanisms across early
   childhood
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
ID EVENT-RELATED POTENTIALS; EARLY LANGUAGE-ACQUISITION; LATE MISMATCH
   NEGATIVITY; SPEECH-PERCEPTION; EXECUTIVE FUNCTION;
   AUDITORY-DISCRIMINATION; PHONEME DISCRIMINATION; BRAIN POTENTIALS; PRIOR
   EXPERIENCE; 1ST YEAR
AB Infants' ability to learn complex linguistic regularities from early on has been revealed by electrophysiological studies indicating that 3-month-olds, but not adults, can automatically detect non-adjacent dependencies between syllables. While different ERP responses in adults and infants suggest that both linguistic rule learning and its link to basic auditory processing undergo developmental changes, systematic investigations of the developmental trajectories are scarce. In the present study, we assessed 2- and 4-year-olds' ERP indicators of pitch discrimination and linguistic rule learning in a syllable-based oddball design. To test for the relation between auditory discrimination and rule learning, ERP responses to pitch changes were used as predictor for potential linguistic rule-learning effects. Results revealed that 2-year-olds, but not 4-year-olds, showed ERP markers of rule learning. Although, 2-year-olds' rule learning was not dependent on differences in pitch perception, 4-year-old children demonstrated a dependency, such that those children who showed more pronounced responses to pitch changes still showed an effect of rule learning. These results narrow down the developmental decline of the ability for automatic linguistic rule learning to the age between 2 and 4 years, and, moreover, point towards a strong modification of this change by auditory processes. At an age when the ability of automatic linguistic rule learning phases out, rule learning can still be observed in children with enhanced auditory responses. The observed interrelations are plausible causes for age-of-acquisition effects and inter-individual differences in language learning.
C1 [Mueller, Jutta L.] Univ Osnabruck, Inst Cognit Sci, Osnabruck, Germany.
   [Mueller, Jutta L.; Friederici, Angela D.; Maennel, Claudia] Max Planck Inst Human Cognit & Brain Sci, Dept Neuropsychol, Leipzig, Germany.
   [Maennel, Claudia] Max Planck Inst Human Cognit & Brain Sci, Dept Neurol, Leipzig, Germany.
   [Maennel, Claudia] Univ Leipzig, Fac Med, Clin Cognit Neurol, Leipzig, Germany.
RP Mueller, JL (corresponding author), Univ Osnabruck, Inst Cognit Sci, Wachsbleiche Osnabruck, Germany.
EM jutta.mueller@uos.de
RI Mueller, Jutta L./ABC-1954-2020
OI Mueller, Jutta L./0000-0002-5463-9585; Mannel,
   Claudia/0000-0003-0678-4697
FU German Research FoundationGerman Research Foundation (DFG) [MU 3112/1-2,
   FR 519/20-1 (FOR 2253)]; Max Planck SocietyMax Planck Society
FX This research was funded by the German Research Foundation (project MU
   3112/1-2, JLM and project FR 519/20-1 (FOR 2253), ADF, CM) and the Max
   Planck Society (ADF, CM).
CR Ahmmed AU, 2008, DEV MED CHILD NEUROL, V50, P938, DOI 10.1111/j.1469-8749.2008.03093.x
   Bishop DVM, 2007, PSYCHOL BULL, V133, P651, DOI 10.1037/0033-2909.133.4.651
   Blakey E, 2016, CHILD DEV, V87, P513, DOI 10.1111/cdev.12468
   Bonatti LL, 2005, PSYCHOL SCI, V16, P451, DOI 10.1111/j.0956-7976.2005.01556.x
   Bunge SA, 2007, CURR OPIN NEUROBIOL, V17, P243, DOI 10.1016/j.conb.2007.02.005
   Carlson SA, 2005, DEV NEUROPSYCHOL, V28, P595, DOI 10.1207/s15326942dn2802_3
   Carlson SM, 2005, PSYCHOL SCI, V16, P609, DOI 10.1111/j.1467-9280.2005.01583.x
   Ceponiene R, 2004, PSYCHOPHYSIOLOGY, V41, P130, DOI 10.1111/j.1469-8986.2003.00138.x
   Ceponiene R, 2002, INT J PSYCHOPHYSIOL, V43, P199, DOI 10.1016/S0167-8760(01)00172-6
   Cheour M, 1998, NAT NEUROSCI, V1, P351, DOI 10.1038/1561
   Cheour M, 2001, AUDIOL NEURO-OTOL, V6, P2, DOI 10.1159/000046804
   Chobert J, 2012, NEUROPSYCHOLOGIA, V50, P2044, DOI 10.1016/j.neuropsychologia.2012.05.004
   Chrysikou EG, 2011, TOP COGN SCI, V3, P253, DOI 10.1111/j.1756-8765.2011.01137.x
   Citron FMM, 2011, NEUROSCI LETT, V487, P282, DOI 10.1016/j.neulet.2010.10.038
   De Diego Balaguer Ruth, 2007, PLoS One, V2, pe1175, DOI 10.1371/journal.pone.0001175
   de Diego-Balaguer R, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00044
   de Diego-Balaguer R, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01478
   Diamond A., 2002, PRINCIPLES FRONTAL L, P466, DOI DOI 10.1093/ACPROF:OSO/9780195134971.003.0029
   Diaz B, 2008, P NATL ACAD SCI USA, V105, P16083, DOI 10.1073/pnas.0805022105
   Endress AD, 2005, J EXP PSYCHOL GEN, V134, P406, DOI 10.1037/0096-3445.134.3.406
   Endress AD, 2009, Q J EXP PSYCHOL, V62, P2187, DOI 10.1080/17470210902783646
   Fellman V, 2004, PEDIATR RES, V56, P291, DOI 10.1203/01.PDR.0000132750.97066.B9
   Friederici AD, 2005, TRENDS COGN SCI, V9, P481, DOI 10.1016/j.tics.2005.08.008
   Friederici AD, 2002, NEUROREPORT, V13, P1251, DOI 10.1097/00001756-200207190-00006
   Friederici AD, 2013, J COGNITIVE NEUROSCI, V25, P814, DOI 10.1162/jocn_a_00350
   Friederici AD, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017920
   Friederici Angela D., 2014, OXFORD HDB COGNITIVE, P171
   Gervain J, 2010, ANNU REV PSYCHOL, V61, P191, DOI 10.1146/annurev.psych.093008.100408
   Gervain Judit, 2008, Proc Natl Acad Sci U S A, V105, P14222, DOI 10.1073/pnas.0806530105
   Gogtay N, 2004, P NATL ACAD SCI USA, V101, P8174, DOI 10.1073/pnas.0402680101
   Gomez R, 2005, INFANCY, V7, P183, DOI 10.1207/s15327078in0702_4
   Gomez RL, 2002, PSYCHOL SCI, V13, P431, DOI 10.1111/1467-9280.00476
   Goswami U, 2011, DEVELOPMENTAL SCI, V14, P34, DOI 10.1111/j.1467-7687.2010.00955.x
   Grama IC, 2016, J PSYCHOLINGUIST RES, V45, P1427, DOI 10.1007/s10936-016-9412-8
   Gumenyuk V, 2004, PSYCHOPHYSIOLOGY, V41, P30, DOI 10.1111/1469-8986.00123
   Guttorm TK, 2005, CORTEX, V41, P291, DOI 10.1016/S0010-9452(08)70267-3
   Habibi A, 2016, DEV COGN NEUROS-NETH, V21, P1, DOI 10.1016/j.dcn.2016.04.003
   Halliday LF, 2006, J RES READ, V29, P213, DOI 10.1111/j.1467-9817.2006.00286.x
   He C, 2009, NEUROPSYCHOLOGIA, V47, P218, DOI 10.1016/j.neuropsychologia.2008.07.019
   Hochmann JR, 2011, DEVELOPMENTAL SCI, V14, P1445, DOI 10.1111/j.1467-7687.2011.01089.x
   Horvath J, 2009, NEUROSCI LETT, V461, P262, DOI 10.1016/j.neulet.2009.06.035
   HYLTENSTAM K, 2003, HDB 2 LANGUAGE ACQUI, P539, DOI [DOI 10.1002/9780470756492.CH17, DOI 10.1002/9780470756492]
   Jentschke S, 2009, NEUROIMAGE, V47, P735, DOI 10.1016/j.neuroimage.2009.04.090
   Kabdebon C, 2015, BRAIN LANG, V148, P25, DOI 10.1016/j.bandl.2015.03.005
   Korpilahti P, 2001, BRAIN LANG, V76, P332, DOI 10.1006/brln.2000.2426
   Krogh L, 2013, FRONT PSYCHOL, V3, DOI [10.3389/fpsyg.2012.00598, 10.3389/fpsyg.2012.00048]
   Kudo N, 2011, DEVELOPMENTAL SCI, V14, P1100, DOI 10.1111/j.1467-7687.2011.01056.x
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   Kushnerenko E, 2002, NEUROREPORT, V13, P1843, DOI 10.1097/00001756-200210280-00002
   Lany J, 2007, COGNITIVE SCI, V31, P481, DOI 10.1080/15326900701326584
   Lany J, 2008, PSYCHOL SCI, V19, P1247, DOI 10.1111/j.1467-9280.2008.02233.x
   Leppanen PHT, 2010, CORTEX, V46, P1362, DOI 10.1016/j.cortex.2010.06.003
   Mannel C, 2017, DEV COGN NEUROS-NETH, V23, P14, DOI 10.1016/j.dcn.2016.11.007
   Mannel C, 2013, CORTEX, V49, P2788, DOI 10.1016/j.cortex.2013.09.003
   Mannel C, 2013, DEV COGN NEUROS-NETH, V5, P86, DOI 10.1016/j.dcn.2013.01.003
   Mannel C, 2011, DEVELOPMENTAL SCI, V14, P786, DOI 10.1111/j.1467-7687.2010.01025.x
   Magne C, 2006, J COGNITIVE NEUROSCI, V18, P199, DOI 10.1162/089892906775783660
   Marchetto E, 2013, COGNITIVE PSYCHOL, V67, P130, DOI 10.1016/j.cogpsych.2013.08.001
   Marcovitch S, 2009, DEVELOPMENTAL SCI, V12, P1, DOI 10.1111/j.1467-7687.2008.00754.x
   Maurer U, 2003, NEUROREPORT, V14, P2245, DOI 10.1097/00001756-200312020-00022
   Mayberry RI, 2002, NATURE, V417, P38, DOI 10.1038/417038a
   Moriguchi Y, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00867
   Moriguchi Y, 2011, DEV COGN NEUROS-NETH, V1, P153, DOI 10.1016/j.dcn.2010.12.004
   Morr ML, 2002, EAR HEARING, V23, P118, DOI 10.1097/00003446-200204000-00005
   Mueller JL, 2008, J COGNITIVE NEUROSCI, V20, P892, DOI 10.1162/jocn.2008.20511
   Mueller JL, 2012, P NATL ACAD SCI USA, V109, P15953, DOI 10.1073/pnas.1204319109
   Mueller JL, 2010, COGNITIVE SCI, V34, P338, DOI 10.1111/j.1551-6709.2009.01093.x
   Mueller JL, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-89
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9
   Newport EL, 2004, COGNITIVE PSYCHOL, V48, P127, DOI 10.1016/S0010-0285(03)00128-2
   Pacton S, 2008, J EXP PSYCHOL LEARN, V34, P80, DOI 10.1037/0278-7393.34.1.80
   Palmer SD, 2016, Q J EXP PSYCHOL, V69, P2390, DOI 10.1080/17470218.2015.1112825
   Pena M, 2002, SCIENCE, V298, P604, DOI 10.1126/science.1072901
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   Putkinen V, 2012, DEV NEUROPSYCHOL, V37, P51, DOI 10.1080/87565641.2011.615873
   Ramscar M, 2007, TRENDS COGN SCI, V11, P274, DOI 10.1016/j.tics.2007.05.007
   Robinson CW, 2004, CHILD DEV, V75, P1387, DOI 10.1111/j.1467-8624.2004.00747.x
   Ruhnau P, 2010, BMC NEUROSCI, V11, DOI 10.1186/1471-2202-11-126
   Saffran J. R., 2006, HDB CHILD DEV, P58, DOI DOI 10.1002/9780470147658.CHPSY0202
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Schaadt G, 2019, NEUROPSYCHOLOGIA, V126, P147, DOI 10.1016/j.neuropsychologia.2018.01.013
   Schaadt G, 2015, RES DEV DISABIL, V47, P318, DOI 10.1016/j.ridd.2015.10.002
   Schon D, 2004, PSYCHOPHYSIOLOGY, V41, P341, DOI 10.1111/1469-8986.00172.x
   SCHROGER E, 1995, NEUROSCI LETT, V193, P185, DOI 10.1016/0304-3940(95)11696-T
   Schulte-Korne G, 2001, INT J PSYCHOPHYSIOL, V40, P77, DOI 10.1016/S0167-8760(00)00152-5
   Shafer VL, 2010, EAR HEARING, V31, P735, DOI 10.1097/AUD.0b013e3181e5d1a7
   Skeide MA, 2016, NAT REV NEUROSCI, V17, P323, DOI 10.1038/nrn.2016.23
   Teinonen T, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-21
   Thompson-Schill SL, 2009, CURR DIR PSYCHOL SCI, V18, P259, DOI 10.1111/j.1467-8721.2009.01648.x
   Toro JM, 2005, COGNITION, V97, pB25, DOI 10.1016/j.cognition.2005.01.006
   Toro JM, 2008, PSYCHOL SCI, V19, P137, DOI 10.1111/j.1467-9280.2008.02059.x
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   Wellman HM, 2001, CHILD DEV, V72, P655, DOI 10.1111/1467-8624.00304
   Wetzel N, 2006, CLIN NEUROPHYSIOL, V117, P2191, DOI 10.1016/j.clinph.2006.06.717
   Wiesmann CG, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms14692
   Zachau S, 2005, NEUROREPORT, V16, P2015, DOI 10.1097/00001756-200512190-00009
   Zelazo PD, 1996, COGNITIVE DEV, V11, P37, DOI 10.1016/S0885-2014(96)90027-1
   Zelazo PD, 2006, NAT PROTOC, V1, P297, DOI 10.1038/nprot.2006.46
NR 98
TC 5
Z9 5
U1 0
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD JAN
PY 2019
VL 22
IS 1
AR e12700
DI 10.1111/desc.12700
PG 13
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA HE4WB
UT WOS:000453368400011
PM 29949219
DA 2021-02-24
ER

PT J
AU Snowling, MJ
   Lervag, A
   Nash, HM
   Hulme, C
AF Snowling, Margaret J.
   Lervag, Arne
   Nash, Hannah M.
   Hulme, Charles
TI Longitudinal relationships between speech perception, phonological
   skills and reading in children at high-risk of dyslexia
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
ID FAMILY RISK; AUDITORY-SENSITIVITY; LANGUAGE IMPAIRMENT;
   PRESCHOOL-CHILDREN; ORAL LANGUAGE; DEFICITS; MODELS
AB Speech perception deficits are commonly reported in dyslexia but longitudinal evidence that poor speech perception compromises learning to read is scant. We assessed the hypothesis that phonological skills, specifically phoneme awareness and RAN, mediate the relationship between speech perception and reading. We assessed longitudinal predictive relationships between categorical speech perception, phoneme awareness, RAN, language, attention and reading at ages 51/2 and 61/2 years in 237 children many of whom were at high risk of reading difficulties. Speech perception at 51/2 years correlated with language, attention, phoneme awareness and RAN concurrently and was a predictor of reading at 61/2 years. There was no significant indirect effect of speech perception on reading via phoneme awareness, suggesting that its effects are separable from those of phoneme awareness. Children classified with dyslexia at 8 years had poorer speech perception than age-controls at 51/2 years and children with language disorders (with or without dyslexia) had more severe difficulties with both speech perception and attention control. Categorical speech perception tasks tap factors extraneous to perception, including decision-making skills. Further longitudinal studies are needed to unravel the complex relationships between categorical speech perception tasks and measures of reading and language and attention.
C1 [Snowling, Margaret J.] Univ Oxford, Dept Expt Psychol, Oxford, England.
   [Lervag, Arne] Univ Oslo, Dept Educ, Oslo, Norway.
   [Nash, Hannah M.] Univ Leeds, Dept Psychol, Leeds, W Yorkshire, England.
   [Hulme, Charles] Univ Oxford, Dept Educ, Oxford, England.
RP Snowling, MJ (corresponding author), Univ Oxford, Dept Expt Psychol, Oxford, England.
EM maggie.snowling@sjc.ox.ac.uk
FU Wellcome TrustWellcome TrustEuropean Commission [WT082032MA]
FX This study was funded by the Wellcome Trust (Grant no. WT082032MA).
CR Adlard A, 1998, Q J EXP PSYCHOL-A, V51, P153
   Biesanz JC, 2010, MULTIVAR BEHAV RES, V45, P661, DOI 10.1080/00273171.2010.498292
   Bishop DVM, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0158753
   Bishop D. V. M., 2003, TEST RECEPTION GRAMM
   Boets B, 2007, NEUROPSYCHOLOGIA, V45, P1608, DOI 10.1016/j.neuropsychologia.2007.01.009
   BRANDT J, 1980, BRAIN LANG, V9, P324, DOI 10.1016/0093-934X(80)90152-2
   Brownell R., 2000, EXPRESSIVE ONE WORD
   Foster H., 2007, SINGLE WORD READING
   Gerrits E, 2009, J COMMUN DISORD, V42, P180, DOI 10.1016/j.jcomdis.2008.10.004
   GODFREY JJ, 1981, J EXP CHILD PSYCHOL, V32, P401, DOI 10.1016/0022-0965(81)90105-3
   Gooch D, 2014, J CHILD PSYCHOL PSYC, V55, P237, DOI 10.1111/jcpp.12139
   Goswami U, 2015, NAT REV NEUROSCI, V16, P43, DOI 10.1038/nrn3836
   Hazan V, 2013, J SPEECH LANG HEAR R, V56, P44, DOI 10.1044/1092-4388(2012/10-0107)
   Hazan V, 2009, J SPEECH LANG HEAR R, V52, P1510, DOI 10.1044/1092-4388(2009/08-0220)
   Henry LA, 2012, J CHILD PSYCHOL PSYC, V53, P37, DOI 10.1111/j.1469-7610.2011.02430.x
   Horlyck S, 2012, SCI STUD READ, V16, P218, DOI 10.1080/10888438.2010.546460
   Hulme C., 2009, YARC YORK ASSESSMENT
   Hulme C, 2015, PSYCHOL SCI, V26, P1877, DOI 10.1177/0956797615603702
   Joanisse MF, 2000, J EXP CHILD PSYCHOL, V77, P30, DOI 10.1006/jecp.1999.2553
   Klatt D.H., 1980, J ACOUST SOC AM, V68, pS18
   Leppanen PHT, 2012, NEUROPHYSIOL CLIN, V42, P35, DOI 10.1016/j.neucli.2011.08.005
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Manis FR, 1997, J EXP CHILD PSYCHOL, V66, P211, DOI 10.1006/jecp.1997.2383
   McArthur GM, 2000, J CHILD PSYCHOL PSYC, V41, P869, DOI 10.1111/1469-7610.00674
   McBride-Chang C, 1997, J EDUC PSYCHOL, V89, P621, DOI 10.1037/0022-0663.89.4.621
   McBrideChang C, 1996, CHILD DEV, V67, P1836, DOI 10.2307/1131735
   Messaoud-Galusi S, 2011, J SPEECH LANG HEAR R, V54, P1682, DOI 10.1044/1092-4388(2011/09-0261)
   Molfese DL, 2000, BRAIN LANG, V72, P238, DOI 10.1006/brln.2000.2287
   Muthen LK., 1998, MPLUS USERS GUIDE, VSeventh
   Nash HM, 2013, J CHILD PSYCHOL PSYC, V54, P958, DOI 10.1111/jcpp.12091
   Nittrouer S, 1999, J SPEECH LANG HEAR R, V42, P925, DOI 10.1044/jslhr.4204.925
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   Pennala R, 2010, J SPEECH LANG HEAR R, V53, P710, DOI 10.1044/1092-4388(2009/08-0133)
   Ralph MAL, 1997, NEUROPSYCHOLOGIA, V35, P1251, DOI 10.1016/S0028-3932(97)00052-3
   Rice M.L., 2001, RICE WEXLER TEST EAR
   Robertson EK, 2009, DEVELOPMENTAL SCI, V12, P753, DOI 10.1111/j.1467-7687.2009.00806.x
   Rosen S, 2003, J PHONETICS, V31, P509, DOI 10.1016/S0095-4470(03)00046-9
   Schulte-Korne G, 2010, CLIN NEUROPHYSIOL, V121, P1794, DOI 10.1016/j.clinph.2010.04.028
   Semel E. M., 2003, CLIN EVALUATION LANG
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   Snowling MJ, 2016, PSYCHOL BULL, V142, P498, DOI 10.1037/bul0000037
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Treisman M, 1999, J EXP PSYCHOL GEN, V128, P517, DOI 10.1037/0096-3445.128.4.517
   Vandewalle E, 2012, RES DEV DISABIL, V33, P635, DOI 10.1016/j.ridd.2011.11.005
   Wechsler D., 2005, WECHSLER INDIVIDUAL, V2nd edn
   Wechsler D., 2003, WECHSLER INTELLIGENC
   WERKER JF, 1987, CAN J PSYCHOL, V41, P48, DOI 10.1037/h0084150
   Wiig E.H., 2006, CLIN EVALUATION LANG, V2nd
   Wilsenach C., 2004, DYSLEXIA, V10, P265
   Zhang J, 2014, DEV PSYCHOL, V50, P1001, DOI 10.1037/a0035086
   Zhang JA, 2010, EDUC PSYCHOL REV, V22, P323, DOI 10.1007/s10648-010-9137-4
NR 51
TC 11
Z9 12
U1 0
U2 11
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD JAN
PY 2019
VL 22
IS 1
AR e12723
DI 10.1111/desc.12723
PG 12
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA HE4WB
UT WOS:000453368400015
PM 30207641
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Potter, CE
   Lew-Williams, C
AF Potter, Christine E.
   Lew-Williams, Casey
TI Infants' Selective Use of Reliable Cues in Multidimensional Language
   Input
SO DEVELOPMENTAL PSYCHOLOGY
LA English
DT Article
DE statistical learning; infant language learning; rule learning; cognitive
   development
ID WORD SEGMENTATION; SPEECH-PERCEPTION; DISCRIMINATION; VARIABILITY;
   FACILITATION; INFORMATION; SENSITIVITY; EXPERIENCE; PREFERENCE;
   ADVANTAGE
AB Learning always happens from input that contains multiple structures and multiple sources of variability. Though infants possess learning mechanisms to locate structure in the world, lab-based experiments have rarely probed how infants contend with input that contains many different structures and cues. Two experiments explored infants' use of two naturally occurring sources of variability-different sounds and different people-to detect regularities in language. Monolingual infants (9-10 months) heard a male and female talker produce two different speech streams, one of which followed a deterministic pattern (e.g., AAB, le-le-di) and one of which did not. For half of the infants, each speaker produced only one of the streams; for the other half of the infants, each speaker produced 50% of each stream. In Experiment 1, each stream consisted of distinct sounds, and infants successfully demonstrated learning regardless of the correspondence between speaker and stream. In Experiment 2, each stream consisted of the same sounds, and infants failed to show learning, even when speakers provided a perfect cue for separating each stream. Thus, monolingual infants can learn in the presence of multiple speech streams, but these experiments suggest that infants may rely more on sound-based rather than speaker-based distinctions when breaking into the structure of incoming information. This selective use of some cues over others highlights infants' ability to adaptively focus on distinctions that are most likely to be useful as they sort through their inherently multidimensional surroundings.
C1 [Potter, Christine E.; Lew-Williams, Casey] Princeton Univ, Dept Psychol, Princeton, NJ 08544 USA.
RP Potter, CE (corresponding author), Princeton Univ, Dept Psychol, Princeton, NJ 08544 USA.
EM cepotter@princeton.edu
FU National Institute of Child Health and Human DevelopmentUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH Eunice Kennedy Shriver National Institute of Child Health &
   Human Development (NICHD) [R03HD079779]; Overdeck Education Research
   Innovation Fund; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD
   HEALTH & HUMAN DEVELOPMENTUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy
   Shriver National Institute of Child Health & Human Development (NICHD)
   [F32HD093139, R03HD079779, F32HD093139, R01HD095912, F32HD093139]
   Funding Source: NIH RePORTER
FX This work was supported by grants from the National Institute of Child
   Health and Human Development (Grant R03HD079779) and the Overdeck
   Education Research Innovation Fund. We thank the participating families
   and members of the Princeton Baby Lab, especially Eva Fourakis and
   Fernanda Fernandez.
CR Antovich DM, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12548
   Best CT, 2009, PSYCHOL SCI, V20, P539, DOI 10.1111/j.1467-9280.2009.02327.x
   Bosch L, 2001, INFANCY, V2, P29, DOI 10.1207/S15327078IN0201_3
   Bulgarelli Federica, 2017, Proc Annu Boston Univ Conf Lang Dev, V41, P128
   Bulgarelli F, 2016, J EXP PSYCHOL LEARN, V42, P1621, DOI 10.1037/xlm0000263
   Chun MM, 1998, COGNITIVE PSYCHOL, V36, P28, DOI 10.1006/cogp.1998.0681
   Conway CM, 2006, PSYCHOL SCI, V17, P905, DOI 10.1111/j.1467-9280.2006.01801.x
   COOPER RP, 1990, CHILD DEV, V61, P1584, DOI 10.1111/j.1467-8624.1990.tb02885.x
   EIMAS PD, 1971, SCIENCE, V171, P303, DOI 10.1126/science.171.3968.303
   Estes KG, 2015, DEV PSYCHOL, V51, P1517, DOI 10.1037/a0039725
   Estes KG, 2011, INFANCY, V16, P180, DOI 10.1111/j.1532-7078.2010.00046.x
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Ferguson B, 2016, SCI REP-UK, V6, DOI 10.1038/srep25434
   FERNALD A, 1984, DEV PSYCHOL, V20, P104, DOI 10.1037/0012-1649.20.1.104
   Fiser J, 2002, P NATL ACAD SCI USA, V99, P15822, DOI 10.1073/pnas.232472899
   Floccia C, 2000, DEVELOPMENTAL SCI, V3, P333, DOI 10.1111/1467-7687.00128
   FRIEDERICI AD, 1993, PERCEPT PSYCHOPHYS, V54, P287, DOI 10.3758/BF03205263
   Gebhart AL, 2009, COGNITIVE SCI, V33, P1087, DOI 10.1111/j.1551-6709.2009.01041.x
   Gerken L, 2006, COGNITION, V98, pB67, DOI 10.1016/j.cognition.2005.03.003
   Gerken L, 2015, COGNITION, V143, P187, DOI 10.1016/j.cognition.2015.04.018
   Gervain J, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2430
   Gomez R, 2005, INFANCY, V7, P183, DOI 10.1207/s15327078in0702_4
   Gomez RL, 2004, DEVELOPMENTAL SCI, V7, P567, DOI 10.1111/j.1467-7687.2004.00381.x
   Gomez RL, 2002, PSYCHOL SCI, V13, P431, DOI 10.1111/1467-9280.00476
   Gonzales K, 2015, COGNITION, V140, P60, DOI 10.1016/j.cognition.2015.03.015
   GROSJEAN F, 2001, ONE MIND 2 LANGUAGES, P1
   Houston DM, 2000, J EXP PSYCHOL HUMAN, V26, P1570, DOI 10.1037/0096-1523.26.5.1570
   Idemaru K, 2011, J EXP PSYCHOL HUMAN, V37, P1939, DOI 10.1037/a0025641
   Johnson EK, 2011, DEVELOPMENTAL SCI, V14, P1002, DOI 10.1111/j.1467-7687.2011.01052.x
   Johnson EK, 2010, DEVELOPMENTAL SCI, V13, P339, DOI 10.1111/j.1467-7687.2009.00886.x
   JUSCZYK PW, 1992, COGNITION, V43, P253, DOI 10.1016/0010-0277(92)90014-9
   JUSCZYK PW, 1993, J MEM LANG, V32, P402, DOI 10.1006/jmla.1993.1022
   Karuza EA, 2016, J COGNITIVE NEUROSCI, V28, P1484, DOI 10.1162/jocn_a_00990
   Kovacs AM, 2009, SCIENCE, V325, P611, DOI 10.1126/science.1173947
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   KUHL PK, 1983, INFANT BEHAV DEV, V6, P263, DOI 10.1016/S0163-6383(83)80036-8
   Lew-Williams C, 2012, COGNITION, V122, P241, DOI 10.1016/j.cognition.2011.10.007
   Marcus GF, 1999, SCIENCE, V283, P77, DOI 10.1126/science.283.5398.77
   Mattys SL, 1999, COGNITIVE PSYCHOL, V38, P465, DOI 10.1006/cogp.1999.0721
   May L, 2014, INFANCY, V19, P281, DOI 10.1111/infa.12048
   Maye J, 2002, COGNITION, V82, pB101, DOI 10.1016/S0010-0277(01)00157-3
   Maye J, 2008, DEVELOPMENTAL SCI, V11, P122, DOI 10.1111/j.1467-7687.2007.00653.x
   Mazuka R, 2014, DEV PSYCHOBIOL, V56, P192, DOI 10.1002/dev.21193
   Mintz TH, 2002, MEM COGNITION, V30, P678, DOI 10.3758/BF03196424
   Mitchel AD, 2010, LANG COGNITIVE PROC, V25, P456, DOI 10.1080/01690960903209888
   Molnar M, 2014, INFANCY, V19, P326, DOI 10.1111/infa.12041
   Nazzi T, 2000, J MEM LANG, V43, P1, DOI 10.1006/jmla.2000.2698
   Nazzi T, 2014, J CHILD LANG, V41, P600, DOI 10.1017/S0305000913000111
   Newport Elissa L. Henry, 1977, TALKING CHILDREN LAN, P109
   Olmedo IM, 2005, STUD SECOND LANG ACQ, V27, P624, DOI 10.1017/S0272263105250283
   Onnis L, 2005, J MEM LANG, V53, P225, DOI 10.1016/j.jml.2005.02.011
   Ota M, 2016, LANG LEARN DEV, V12, P380, DOI 10.1080/15475441.2016.1165100
   Pacton S, 2008, J EXP PSYCHOL LEARN, V34, P80, DOI 10.1037/0278-7393.34.1.80
   Pelucchi B, 2009, CHILD DEV, V80, P674, DOI 10.1111/j.1467-8624.2009.01290.x
   Perruchet P, 2014, ACTA PSYCHOL, V149, P1, DOI 10.1016/j.actpsy.2014.01.015
   Petitto LA, 2012, BRAIN LANG, V121, P130, DOI 10.1016/j.bandl.2011.05.003
   Piazza EA, 2017, CURR BIOL, V27, P3162, DOI 10.1016/j.cub.2017.08.074
   Potter CE, 2017, COGNITION, V166, P67, DOI 10.1016/j.cognition.2017.05.031
   Potter CE, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01587
   Quam C, 2017, LAB PHONOL, V8, DOI 10.5334/labphon.25
   Rabagliati H, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12704
   Richardson DC, 2004, J EXP PSYCHOL GEN, V133, P46, DOI 10.1037/0096-3445.133.1.46
   Ronjat J., 1913, DEV LANGAGE OBSERVE
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Saffran JR, 2007, COGNITION, V105, P669, DOI 10.1016/j.cognition.2006.11.004
   Saffran JR, 2018, ANNU REV PSYCHOL, V69, P181, DOI 10.1146/annurev-psych-122216-011805
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Sahni SD, 2010, CHILD DEV, V81, P727, DOI 10.1111/j.1467-8624.2010.01430.x
   Sebastian-Galles N, 2012, PSYCHOL SCI, V23, P994, DOI 10.1177/0956797612436817
   Singh L, 2004, J MEM LANG, V51, P173, DOI 10.1016/j.jml.2004.04.004
   Thiessen ED, 2007, LANG LEARN DEV, V3, P73, DOI 10.1080/15475440709337001
   Toscano JC, 2010, COGNITIVE SCI, V34, P434, DOI 10.1111/j.1551-6709.2009.01077.x
   Tummeltshammer KS, 2013, DEVELOPMENTAL SCI, V16, P760, DOI 10.1111/desc.12064
   van den Bos E, 2012, J MEM LANG, V67, P507, DOI 10.1016/j.jml.2012.07.008
   Weisleder A, 2013, PSYCHOL SCI, V24, P2143, DOI 10.1177/0956797613488145
   Weiss DJ, 2009, LANG LEARN DEV, V5, P30, DOI 10.1080/15475440802340101
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1988, DEV PSYCHOL, V24, P672, DOI 10.1037/0012-1649.24.5.672
NR 78
TC 4
Z9 4
U1 0
U2 4
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0012-1649
EI 1939-0599
J9 DEV PSYCHOL
JI Dev. Psychol.
PD JAN
PY 2019
VL 55
IS 1
BP 1
EP 8
DI 10.1037/dev0000610
PG 8
WC Psychology, Developmental
SC Psychology
GA HE3MC
UT WOS:000453259200001
PM 30284882
OA Bronze, Green Accepted
DA 2021-02-24
ER

PT J
AU Delcenserie, A
   Genesee, F
   Trudeau, N
   Champoux, F
AF Delcenserie, A.
   Genesee, F.
   Trudeau, N.
   Champoux, F.
TI A multi-group approach to examining language development in at-risk
   learners
SO JOURNAL OF CHILD LANGUAGE
LA English
DT Article
DE at-risk language acquisition; international adoption; cochlear implants;
   specific language impairment; second-language learning
ID INTERNATIONALLY ADOPTED-CHILDREN; BILINGUAL EXPOSURE; SPEECH-PERCEPTION;
   INDIVIDUAL-DIFFERENCES; COCHLEAR IMPLANT; YOUNG-CHILDREN; MEMORY;
   ACQUISITION; WORKING; AGE
AB A battery of standardized language tests and control measures was administered to three groups of at-risk language learners - internationally adopted children, deaf children with cochlear implants, and children with specific language impairment and to groups of second-language learners and typically developing monolingual children. All children were acquiring French, were matched on age, gender, and socioeconomic status, and were between age 5;0 and 7;3 at the time of testing. Differences between the at-risk and not-at-risk groups were evident in all domains of language testing. The children with SLI or CIs scored significantly lower than the IA children and all three at-risk groups scored lower than the monolingual group; the L2 and IA groups scored similarly. The results suggest that children with limited access to, or ability to process, early language input are at greater risk than children with delayed input to an additional language but otherwise typical or relatively typical early input.
C1 [Delcenserie, A.] Univ Montreal, Dept Psychol, Montreal, PQ, Canada.
   [Genesee, F.] McGill Univ, Dept Psychol, Montreal, PQ, Canada.
   [Delcenserie, A.; Trudeau, N.; Champoux, F.] Univ Montreal, Ecole Orthophonie & Audiol, Montreal, PQ, Canada.
RP Delcenserie, A (corresponding author), Univ Montreal, Dept Psychol, Succursale Ctr Ville, Pavillon Marie Victorin,CP 6128, Montreal, PQ H3C 3J7, Canada.
EM delcenserie@umontreal.ca
FU Centre for Research on Brain, Language, and Music (CRBLM); Social
   Sciences and Humanities Research Council (SSHRC)Social Sciences and
   Humanities Research Council of Canada (SSHRC); Fonds the Recherche du
   Quebec - Societe et Culture (FQRSC)
FX The authors would like to thank Lara Pierce and Gary Morgan for their
   helpful comments. We would also like to thank Lelia Farout, Deborah
   Angelus, and Manon Rivest for their help with recruitment, as well as
   Kristina Maiorino and Cynthia Ayvazian for their help with testing. This
   research was funded by the Centre for Research on Brain, Language, and
   Music (CRBLM), the Social Sciences and Humanities Research Council
   (SSHRC), and the Fonds the Recherche du Quebec - Societe et Culture
   (FQRSC).
CR Abrahamsson N, 2009, LANG LEARN, V59, P249, DOI 10.1111/j.1467-9922.2009.00507.x
   Achenbach T., 2000, MANUAL ASEBA PRESCHO
   Alloway TP, 2005, LEARN INDIVID DIFFER, V15, P271, DOI 10.1016/j.lindif.2005.05.001
   Bishop DVM, 2006, Q J EXP PSYCHOL, V59, P1153, DOI 10.1080/17470210500489372
   Bouton S, 2015, LANG COGN NEUROSCI, V30, P684, DOI 10.1080/23273798.2014.1002796
   Brownell R., 2000, MANUAL EXPRESSIVE ON
   Caselli MC, 2012, J SPEECH LANG HEAR R, V55, P382, DOI 10.1044/1092-4388(2011/10-0248)
   Chilosi AM, 2013, EAR HEARING, V34, pE28, DOI 10.1097/AUD.0b013e31827ad687
   Colantoni L, 2006, SEL P 7 C ACQ SPAN P, P59
   Conti-Ramsden G, 2011, CHILD PSYCHOLOGY AND PSYCHIATRY: FRAMEWORKS FOR PRACTICE, 2ND EDITION, P180
   ContiRamsden G, 1997, J SPEECH LANG HEAR R, V40, P765, DOI 10.1044/jslhr.4004.765
   Delcenserie A, 2017, INT J BILINGUAL, V21, P600, DOI 10.1177/1367006916639158
   Delcenserie A, 2014, J CHILD LANG, V41, P1195, DOI 10.1017/S030500091300041X
   Delcenserie A, 2013, APPL PSYCHOLINGUIST, V34, P541, DOI 10.1017/S0142716411000865
   Dettman SJ, 2007, EAR HEARING, V28, p11S, DOI 10.1097/AUD.0b013e31803153f8
   Dunn LM, 1993, MANUAL ECHELLE VOCAB
   Fernald A, 2012, CHILD DEV, V83, P203, DOI 10.1111/j.1467-8624.2011.01692.x
   Geers A, 2003, EAR HEARING, V24, p24S, DOI 10.1097/01.AUD.0000051687.99218.0F
   Hoff E, 2006, DEV REV, V26, P55, DOI 10.1016/j.dr.2005.11.002
   Hyltenstam K, 1992, COGNITIVE PROCESSING, P351, DOI DOI 10.1016/S0166-4115(08)61505-8
   Hyltenstam K, 2009, BILING-LANG COGN, V12, P121, DOI 10.1017/S1366728908004008
   Jia G, 2003, J SPEECH LANG HEAR R, V46, P1297, DOI 10.1044/1092-4388(2003/101)
   Kapa Leah L, 2015, Curr Dev Disord Rep, V2, P245
   Klem M, 2015, DEVELOPMENTAL SCI, V18, P146, DOI 10.1111/desc.12202
   Korkman M., 2007, NEPSY 2 EDITION NEPS
   Kronenberger WG, 2013, J SPEECH LANG HEAR R, V56, P805, DOI 10.1044/1092-4388(2012/11-0356)
   Kronenberger WG, 2011, J SPEECH LANG HEAR R, V54, P1182, DOI 10.1044/1092-4388(2010/10-0119)
   Kuhl PK, 2014, P NATL ACAD SCI USA, V111, P11238, DOI 10.1073/pnas.1410963111
   Leonard LB, 2014, CHILDREN WITH SPECIFIC LANGUAGE IMPAIRMENT, 2ND EDITION, P1
   Lum JAG, 2012, CORTEX, V48, P1138, DOI 10.1016/j.cortex.2011.06.001
   Mayberry RI, 2007, APPL PSYCHOLINGUIST, V28, P537, DOI 10.1017/S0142716407070294
   Meisel J. M., 2004, HDB BILINGUALISM, P91
   Miller CA, 2001, J SPEECH LANG HEAR R, V44, P416, DOI 10.1044/1092-4388(2001/034)
   Nicholas JG, 2013, OTOL NEUROTOL, V34, P532, DOI 10.1097/MAO.0b013e318281e215
   Nicholas JG, 2007, J SPEECH LANG HEAR R, V50, P1048, DOI 10.1044/1092-4388(2007/073)
   Nicoladis E, 2007, DEVELOPMENTAL SCI, V10, P237, DOI 10.1111/j.1467-7687.2007.00582.x
   Nicoladis E, 2011, LANG LEARN, V61, P734, DOI 10.1111/j.1467-9922.2011.00660.x
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Nittrouer S, 2016, RES DEV DISABIL, V55, P143, DOI 10.1016/j.ridd.2016.03.020
   O'Donoghue GM, 2000, LANCET, V356, P466, DOI 10.1016/S0140-6736(00)02555-1
   Paradis J, 2000, J SPEECH LANG HEAR R, V43, P834, DOI 10.1044/jslhr.4304.834
   Paradis J., 2006, DUAL LANGUAGE DEV DI, P387
   Paradis J, 2011, LINGUIST APPROACH BI, V1, P213, DOI 10.1075/lab.1.3.01par
   Pierce L, 2015, APPL PSYCHOLINGUIST, V36, P1223, DOI 10.1017/S0142716414000125
   Pierce LJ, 2017, APPL PSYCHOLINGUIST, V38, P1265, DOI 10.1017/S0142716417000236
   Pierce LJ, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms10073
   Pierce LJ, 2014, P NATL ACAD SCI USA, V111, P17314, DOI 10.1073/pnas.1409411111
   Pomerleau A, 2005, INT J BEHAV DEV, V29, P445, DOI 10.1177/01650250500206257
   Rice J., 2016, STARTING LANGUAGE DE, P95, DOI [10.1075/tilar.18, DOI 10.1075/TILAR.18]
   Rice ML, 2016, J SPEECH LANG HEAR R, V59, P122, DOI 10.1044/2015_JSLHR-L-15-0255
   Rutter M, 2012, DEV PSYCHOPATHOL, V24, P335, DOI 10.1017/S0954579412000028
   Scott K., 2016, TRENDS LANGUAGE ACQU, P65, DOI [10.1075/tilar.18, DOI 10.1075/TILAR.18]
   Scott KA, 2008, AM J SPEECH-LANG PAT, V17, P150, DOI 10.1044/1058-0360(2008/015)
   Semel E., 1987, CELFR CLIN EVALUATIO
   Semel E., 2009, EVALUATION CLIN NOTI
   Simard D., 2011, BILING-LANG COGN, V16, P19
   Szagun G, 2004, J CHILD LANG, V31, P1, DOI 10.1017/S0305000903005889
   Thordardottir E, 2015, INT J SPEECH-LANG PA, V17, P97, DOI 10.3109/17549507.2014.923509
   Thordardottir E, 2013, J COMMUN DISORD, V46, P1, DOI 10.1016/j.jcomdis.2012.08.002
   Thordardottir E, 2011, INT J BILINGUAL, V15, P426, DOI 10.1177/1367006911403202
   Tomblin J Bruce, 2015, Ear Hear, V36 Suppl 1, p76S, DOI 10.1097/AUD.0000000000000219
   vanderLely HKJ, 1996, LINGUA, V98, P243, DOI 10.1016/0024-3841(95)00044-5
   Victorino KR, 2015, J SPEECH LANG HEAR R, V58, P1245, DOI 10.1044/2015_JSLHR-L-14-0181
   Vlastarakos PV, 2010, INT J PEDIATR OTORHI, V74, P119, DOI 10.1016/j.ijporl.2009.10.004
   Vugs B, 2014, RES DEV DISABIL, V35, P62, DOI 10.1016/j.ridd.2013.10.022
   Wechsler D, 2006, WECHSLER NONVERBAL S
   Werker JF, 1999, ANNU REV PSYCHOL, V50, P509, DOI 10.1146/annurev.psych.50.1.509
   Werker JF, 2002, INFANT BEHAV DEV, V25, P121, DOI 10.1016/S0163-6383(02)00093-0
NR 68
TC 1
Z9 1
U1 1
U2 7
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0305-0009
EI 1469-7602
J9 J CHILD LANG
JI J. Child Lang.
PD JAN
PY 2019
VL 46
IS 1
BP 51
EP 79
DI 10.1017/S030500091800034X
PG 29
WC Psychology, Developmental; Linguistics; Psychology, Experimental
SC Psychology; Linguistics
GA HD7LJ
UT WOS:000452733300003
PM 30221620
DA 2021-02-24
ER

PT J
AU Kleinschmidt, DF
AF Kleinschmidt, Dave F.
TI Structure in talker variability: How much is there and how much can it
   help?
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Speech perception; variability; computational modelling
ID VOICE ONSET TIME; SPEECH-PERCEPTION; ACOUSTIC CHARACTERISTICS;
   CONTRASTIVE HYPERARTICULATION; SELECTIVE ADAPTATION; PHONETIC
   SPECIFICITY; GENDER; CLASSIFICATION; IDENTIFICATION; STEREOTYPES
AB One of the persistent puzzles in understanding human speech perception is how listeners cope with talker variability. One thing that might help listeners is structure in talker variability: rather than varying randomly, talkers of the same gender, dialect, age, etc. tend to produce language in similar ways. Listeners are sensitive to this covariation between linguistic variation and socio-indexical variables. In this paper I present new techniques based on ideal observer models to quantify (1) the amount and type of structure in talker variation (informativity of a grouping variable), and (2) how useful such structure can be for robust speech recognition in the face of talker variability (the utility of a grouping variable). I demonstrate these techniques in two phonetic domainsword-initial stop voicing and vowel identityand show that these domains have different amounts and types of talker variability, consistent with previous, impressionistic findings. An R package (phondisttools) accompanies this paper, and the source and data are available from osf.io/zv6e3.
C1 [Kleinschmidt, Dave F.] Princeton Univ, Princeton Neurosci Inst, Princeton, NJ 08544 USA.
   [Kleinschmidt, Dave F.] Univ Rochester, Dept Brain & Cognit Sci, New York, NY USA.
RP Kleinschmidt, DF (corresponding author), Princeton Univ, Princeton Neurosci Inst, Princeton, NJ 08544 USA.; Kleinschmidt, DF (corresponding author), Univ Rochester, Dept Brain & Cognit Sci, New York, NY USA.
EM davidfk@princeton.edu
OI Kleinschmidt, Dave/0000-0002-7442-2762
FU Eunice Kennedy Shriver National Institute of Child Health and Human
   Development (NIH NICHD) [R01 HD075797]; NIH NICHDUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH Eunice Kennedy Shriver National Institute of Child Health &
   Human Development (NICHD) [F31 HD082893]; EUNICE KENNEDY SHRIVER
   NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH Eunice Kennedy Shriver National Institute of Child Health &
   Human Development (NICHD) [F31HD082893, R01HD075797] Funding Source: NIH
   RePORTER
FX This work was partially funded by Eunice Kennedy Shriver National
   Institute of Child Health and Human Development (NIH NICHD) R01 HD075797
   and NIH NICHD F31 HD082893. The views expressed here are those of the
   author and not necessarily those of the funding agencies.
CR Adank P, 2004, J ACOUST SOC AM, V116, P3099, DOI 10.1121/1.1795335
   Allaire JJ, 2017, RMARKDOWN DYNAMIC DO
   Allen JS, 2003, J ACOUST SOC AM, V113, P544, DOI 10.1121/1.1528172
   Bejjanki VR, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019812
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Chodroff E., 2015, P 18 INT C PHON SCI
   Chodroff E, 2017, J PHONETICS, V61, P30, DOI 10.1016/j.wocn.2017.01.001
   Clarke E., 2017, GGBEESWARM CATEGORIC
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Clayards M, 2018, PHONETICA, V75, P1, DOI 10.1159/000448809
   Clopper CG, 2005, J ACOUST SOC AM, V118, P1661, DOI 10.1121/1.2000774
   Clopper CG, 2007, J PHONETICS, V35, P421, DOI 10.1016/j.wocn.2006.06.001
   Clopper Cynthia G, 2006, Lang Var Change, V18, P193
   Clopper CG, 2006, SPEECH COMMUN, V48, P633, DOI 10.1016/j.specom.2005.09.010
   Cohen E, 2012, CURR ANTHROPOL, V53, P588, DOI 10.1086/667654
   Cole J, 2010, J PHONETICS, V38, P167, DOI 10.1016/j.wocn.2009.08.004
   Eckert P, 2012, ANNU REV ANTHROPOL, V41, P87, DOI 10.1146/annurev-anthro-092611-145828
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   Escudero P, 2007, P 16 INT C PHON SCI, P1413
   Feldman NH, 2009, PSYCHOL REV, V116, P752, DOI 10.1037/a0017196
   Fitch WT, 1999, J ACOUST SOC AM, V106, P1511, DOI 10.1121/1.427148
   Flynn N., 2011, P 17 INT C PHON SCI
   Foulkes P, 2015, EMERGENCE SOCIOPHONE, P292
   Genz A, 2009, LECT NOTES STAT
   Goldinger SD, 1998, PSYCHOL REV, V105, P251, DOI 10.1037/0033-295X.105.2.251
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   Heald SLM, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0136791
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Holt LL, 2005, PSYCHOL SCI, V16, P305, DOI 10.1111/j.0956-7976.2005.01532.x
   Holt LL, 2006, J ACOUST SOC AM, V120, P2801, DOI 10.1121/1.2354071
   Huang JY, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00010
   Idemaru K, 2011, J EXP PSYCHOL HUMAN, V37, P1939, DOI 10.1037/a0025641
   Jaeger TF, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01115
   James G, 2013, INTRO STAT LEARNING
   JOHNSON K, 1993, J ACOUST SOC AM, V94, P701, DOI 10.1121/1.406887
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Johnson K., 1997, OSU WORKING PAP LING, V50, P101
   Johnson K, 2005, BLACKW HBK LINGUIST, P363, DOI 10.1002/9780470757024.ch15
   Johnson K, 2006, J PHONETICS, V34, P485, DOI 10.1016/j.wocn.2005.08.004
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   Kirby J., 2015, P 18 INT C PHON SCI
   Kleinschmidt D. F., 2016, P 38 ANN M COGN SCI
   Kleinschmidt DF, 2018, TOP COGN SCI, V10, P818, DOI 10.1111/tops.12331
   Kleinschmidt DF, 2016, PSYCHON B REV, V23, P678, DOI 10.3758/s13423-015-0943-z
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kording KP, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000943
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   Labov W., 2006, ATLAS N AM ENGLISH, DOI [10.1515/9783110206838, DOI 10.1515/9783110206838]
   Labov William, 1972, SOCIOLINGUISTIC PATT
   Laing EJC, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00203
   Lee S, 1999, J ACOUST SOC AM, V105, P1455, DOI 10.1121/1.426686
   Levon E, 2014, LANG SOC, V43, P539, DOI 10.1017/S0047404514000554
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Lloyd R., 1890, PHONETISCHE STUDIEN, V3, P251
   LOBANOV BM, 1971, J ACOUST SOC AM, V49, P606, DOI 10.1121/1.1912396
   MacKay D. C., 2003, INFORM THEORY INFERE
   Marr D., 1982, VISION COMPUTATIONAL
   MASSARO DW, 1990, PSYCHOL REV, V97, P225, DOI 10.1037/0033-295X.97.2.225
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   Mitchel AD, 2016, J PHONETICS, V56, P66, DOI 10.1016/j.wocn.2016.02.003
   Monahan PJ, 2010, LANG COGNITIVE PROC, V25, P808, DOI 10.1080/01690965.2010.490047
   Morris RJ, 2008, J PHONETICS, V36, P308, DOI 10.1016/j.wocn.2007.06.003
   Munson C.M., 2011, THESIS
   NEAREY TM, 1989, J ACOUST SOC AM, V85, P2088, DOI 10.1121/1.397861
   Nelson NR, 2017, J PHONETICS, V64, P51, DOI 10.1016/j.wocn.2017.01.008
   Newman RS, 2001, J ACOUST SOC AM, V109, P1181, DOI 10.1121/1.1348009
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Perry TL, 2001, J ACOUST SOC AM, V109, P2988, DOI 10.1121/1.1370525
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   Pierrehumbert JB, 2006, J PHONETICS, V34, P516, DOI 10.1016/j.wocn.2006.06.003
   Pitt M., 2007, BUCKEYE CORPUS CONVE
   Podesva RJ, 2002, LANGUAGE AND SEXUALITY: CONTESTING MEANING IN THEORY AND PRACTICE, P175
   Podesva RJ, 2007, J SOCIOLING, V11, P478, DOI 10.1111/j.1467-9841.2007.00334.x
   R Core Team, 2017, R LANG ENV STAT COMP
   Reinisch E, 2014, J EXP PSYCHOL HUMAN, V40, P539, DOI 10.1037/a0034409
   Remez RE, 1997, J EXP PSYCHOL HUMAN, V23, P651, DOI 10.1037/0096-1523.23.3.651
   Sole M.J., 2007, EXPT APPROACHES PHON, P302
   Strand EA, 1999, J LANG SOC PSYCHOL, V18, P86, DOI 10.1177/0261927X99018001006
   Stuart-Smith J, 2015, LAB PHONOL, V6, P505, DOI 10.1515/lp-2015-0015
   Sumner M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01015
   Thomas ER, 2002, AM SPEECH, V77, P115, DOI 10.1215/00031283-77-2-115
   Torre P, 2009, J COMMUN DISORD, V42, P324, DOI 10.1016/j.jcomdis.2009.03.001
   van der Zande P, 2014, J PHONETICS, V43, P38, DOI 10.1016/j.wocn.2014.01.003
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
   Walker A., 2011, LAB PHONOLOGY, V2, P219, DOI DOI 10.1515/LABPHON.2011.007
   Weatherholtz K., 2016, OXFORD RES ENCY LING, DOI [10.1093/acrefore/9780199384655.013.95, DOI 10.1093/ACREFORE/9780199384655.013.95]
   Wedel A, 2018, J MEM LANG, V100, P61, DOI 10.1016/j.jml.2018.01.001
   Wickham H, 2017, TIDYVERSE EASILY INS
   Wilke CO., 2017, COWPLOT STREAMLINED
   Xie Y., 2015, DYNAMIC DOCUMENTS R
NR 94
TC 11
Z9 11
U1 1
U2 13
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PY 2019
VL 34
IS 1
BP 43
EP 68
DI 10.1080/23273798.2018.1500698
PG 26
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA HD3ED
UT WOS:000452396500005
PM 30619905
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Moshgelani, F
   Parsa, V
   Allan, C
   Veeranna, SA
   Allen, P
AF Moshgelani, Farid
   Parsa, Vijay
   Allan, Chris
   Veeranna, Sangamanatha Ankmnal
   Allen, Prudence
TI Objective and subjective assessment of envelope enhancement algorithms
   for assistive hearing devices
SO BIOMEDICAL SIGNAL PROCESSING AND CONTROL
LA English
DT Article
DE Auditory neuropathy spectrum disorder; Auditory processing disorder;
   Dynamic envelope enhancement; Static envelope enhancement; Temporal
   processing; Hearing aid speech perception index
ID NEUROPATHY SPECTRUM DISORDER; AUDITORY NEUROPATHY; SPEECH; NOISE;
   INDIVIDUALS; PERCEPTION; INTELLIGIBILITY; CHILDREN; QUIET; REVERBERANT
AB Speech perception in a noisy environment is a significant challenge for individuals with auditory processing deficits. Evidence exists that exaggerating the slow temporal modulations may enhance speech perception for these individuals in the absence or presence of background noise. Nevertheless, a comprehensive assessment of envelope enhancement algorithms is lacking. In the present research study, two different schemes of envelope enhancement (dynamic and static) were evaluated subjectively and objectively for different types and levels of background noise with and without applying a noise reduction algorithm. In the subjective assessment, the dynamic envelope enhancement algorithm was evaluated with three different subjective groups including, twelve normal adults, twelve normal children, and eleven children with suspected auditory processing disorder (APD). The subjective results revealed that the speech intelligibility scores were lower for APD subjects compared to both normal adults and normal children. The subjective results also demonstrated that enhancing the temporal envelope is much more beneficial for subjects with suspected APD when compared to normal adults and children participating in the subjective experiment. In the objective assessment, the Hearing Aid Speech Perception Index (HASPI) was employed to predict the speech intelligibility scores which correlated highly with the subjective data. Comprehensive objective experiments demonstrated that both dynamic and static envelope enhancement algorithms are only effective in improving speech perception under certain processing conditions that depended on the type, level and location of the background noise. It is also shown that the application of a noise reduction algorithm prior to the envelope enhancement algorithms will increase their range of effectiveness. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Moshgelani, Farid; Parsa, Vijay; Allan, Chris; Veeranna, Sangamanatha Ankmnal; Allen, Prudence] Western Univ, Natl Ctr Audiol, London, ON N6G 1H1, Canada.
   [Moshgelani, Farid; Parsa, Vijay] Western Univ, Dept Elect & Comp Engn, London, ON N6G 1H1, Canada.
RP Moshgelani, F (corresponding author), Western Univ, Natl Ctr Audiol, London, ON N6G 1H1, Canada.; Moshgelani, F (corresponding author), Western Univ, Dept Elect & Comp Engn, London, ON N6G 1H1, Canada.
EM fmoshgel@uwo.ca
FU Natural Sciences and Engineering Research Council (NSERC) of
   CanadaNatural Sciences and Engineering Research Council of Canada
   (NSERC); Ontario Research Fund
FX The authors gratefully acknowledge the funding support from the Natural
   Sciences and Engineering Research Council (NSERC) of Canada, and the
   Ontario Research Fund. We are also thankful to the participants of the
   subjective study.
CR *ASHA, 2005, AUD PROC DIS
   Bernarding C, 2014, IEEE ENG MED BIO, P2653, DOI 10.1109/EMBC.2014.6944168
   Chen F, 2013, BIOMED SIGNAL PROCES, V8, P311, DOI 10.1016/j.bspc.2012.11.007
   CLARKSON PM, 1989, ELECTRON LETT, V25, P1186, DOI 10.1049/el:19890795
   Dillon H., 2012, HEARING AIDS
   Falk TH, 2015, IEEE SIGNAL PROC MAG, V32, P114, DOI 10.1109/MSP.2014.2358871
   Falk TH, 2010, IEEE T AUDIO SPEECH, V18, P1766, DOI 10.1109/TASL.2010.2052247
   Jin SH, 2012, J ACOUST SOC AM, V132, pEL391, DOI 10.1121/1.4757730
   Kates JM, 2017, SPEECH COMMUN, V90, P15, DOI 10.1016/j.specom.2017.04.004
   Kates JM, 2014, SPEECH COMMUN, V65, P75, DOI 10.1016/j.specom.2014.06.002
   Koutsogiannaki M, 2017, INTERSPEECH, P1973, DOI 10.21437/Interspeech.2017-1157
   Kuk Francis, 2011, Seminars in Hearing, V32, P189, DOI 10.1055/s-0031-1277241
   Loizou P. C., 2013, SPEECH ENHANCEMENT T
   Lucker J. R., 2013, AUDITORY PROCESSING, P33
   Nagarajan S S, 1998, IEEE Trans Rehabil Eng, V6, P257, DOI 10.1109/86.712220
   Narne VK, 2008, EAR HEARING, V29, P45
   Narne VK, 2009, INT J AUDIOL, V48, P700, DOI 10.1080/14992020902931574
   Narne VK, 2009, EAR HEARING, V30, P136, DOI 10.1097/AUD.0b013e3181926545
   NILSSON M, 1994, J ACOUST SOC AM, V95, P1085, DOI 10.1121/1.408469
   Pottackal M.J., 2015, J AM ACAD AUDIOL, V26, P815
   Rance G., 2013, AUDITORY PROCESSING, P185
   Rance Gary, 2005, Trends Amplif, V9, P1, DOI 10.1177/108471380500900102
   Reynolds S., 2015, AM J OCCUP THER, V70, P1
   Schafer E. C., 2014, J ED AUDIOLOGY, V20, P1
   Sharma M, 2014, J SPEECH LANG HEAR R, V57, P2308, DOI 10.1044/2014_JSLHR-H-13-0226
   Shetty HN, 2017, NOISE HEALTH, V19, P174, DOI 10.4103/nah.NAH_10_16
   Shetty HN, 2016, J INT ADV OTOL, V12, P282, DOI 10.5152/iao.2016.2540
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Taal CH, 2010, INT CONF ACOUST SPEE, P4214, DOI 10.1109/ICASSP.2010.5495701
   Walker E, 2016, J AM ACAD AUDIOL, V27, P204, DOI 10.3766/jaaa.15050
   Zeng FG, 1999, NEUROREPORT, V10, P3429, DOI 10.1097/00001756-199911080-00031
NR 31
TC 1
Z9 1
U1 0
U2 6
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1746-8094
EI 1746-8108
J9 BIOMED SIGNAL PROCES
JI Biomed. Signal Process. Control
PD JAN
PY 2019
VL 47
BP 16
EP 25
DI 10.1016/j.bspc.2018.08.013
PG 10
WC Engineering, Biomedical
SC Engineering
GA GZ1NJ
UT WOS:000449134500003
DA 2021-02-24
ER

PT J
AU Van der Haegen, L
   Brysbaert, M
AF Van der Haegen, Lise
   Brysbaert, Marc
TI The relationship between behavioral language laterality, face laterality
   and language performance in left-handers
SO PLOS ONE
LA English
DT Article
ID VISUAL HALF-FIELD; HEMISPHERIC-SPECIALIZATION; CEREBRAL LATERALIZATION;
   HANDEDNESS; ASYMMETRY; DOMINANCE; PARADIGM; AREA
AB Left-handers provide unique information about the relationship between cognitive functions because of their larger variability in hemispheric dominance. This study presents the laterality distribution of, correlations between and test-retest reliability of behavioral lateralized language tasks (speech production, reading and speech perception), face recognition tasks, handedness measures and language performance tests based on data from 98 left-handers. The results show that a behavioral test battery leads to percentages of (a) typical dominance that are similar to those found in neuropsychological studies even though the incidence of clear atypical lateralization (about 20%) may be overestimated at the group level. Significant correlations were found between the language tasks for both reaction time and accuracy lateralization indices. The degree of language laterality could however not be linked to face laterality, handedness or language performance. Finally, individuals were classified less consistently than expected as being typical, bilateral or atypical across all tasks. This may be due to the often good (speech production and perception tasks) but sometimes weak (reading and face tasks) test-retest reliabilities. The lack of highly reliable and valid test protocols for functions unrelated to speech remains one of the largest impediments for individual analysis and cross-task investigations in laterality research.
C1 [Van der Haegen, Lise; Brysbaert, Marc] Univ Ghent, Dept Expt Psychol, Ghent, Belgium.
RP Van der Haegen, L (corresponding author), Univ Ghent, Dept Expt Psychol, Ghent, Belgium.
EM lise.vanderhaegen85@gmail.com
RI Brysbaert, Marc/A-3910-2011
OI Brysbaert, Marc/0000-0002-3645-3189
FU Research Council Flanders [12G2916N, 3G091808]
FX This study was funded by (1) grant 12G2916N awarded by the Research
   Council Flanders (http://www.fwo.be/en/) to LVDH who designed the study,
   collected data, ran the analyses, and wrote the manuscript; (2) Odysseus
   grant 3G091808 awarded by the Research Council Flanders
   (http://www.fwo.be/en/) to MB who supervised the study and wrote the
   manuscript.
CR Allendorfer JB, 2016, HUM BRAIN MAPP
   BAAYEN R, 1993, CELEX LEXICAL DATABA
   Behrmann M, 2013, TRENDS COGN SCI, V17, P210, DOI 10.1016/j.tics.2013.03.007
   Bishop DVM, 2017, BISHOPBLOG
   Bless JJ, 2015, LATERALITY, V20, P434, DOI 10.1080/1357650X.2014.997245
   Bless JJ, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00042
   Boles DB, 2011, BRAIN COGNITION, V76, P1, DOI 10.1016/j.bandc.2011.01.013
   Bourne VJ, 2006, LATERALITY, V11, P373, DOI 10.1080/13576500600633982
   Brus B, 1991, MINUUT TEST VORM A B
   BRYSBAERT M, 1990, NEUROPSYCHOLOGIA, V28, P901, DOI 10.1016/0028-3932(90)90107-Y
   Bukowski H, 2013, CORTEX, V49, P2583, DOI 10.1016/j.cortex.2013.05.002
   Cai Q, 2015, NEUROSCI BULL, V31, P220, DOI 10.1007/s12264-014-1505-5
   Cai Q, 2013, P NATL ACAD SCI USA, V110, pE322, DOI 10.1073/pnas.1212956110
   Callens M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038081
   Dundas EM, 2015, J COGNITIVE NEUROSCI, V27, P913, DOI 10.1162/jocn_a_00757
   Dundas EM, 2013, J EXP PSYCHOL GEN, V142, P348, DOI 10.1037/a0029503
   Hedge C, 2017, BEHAV RES METHODS
   Hirnstein M, 2008, BEHAV BRAIN RES, V187, P297, DOI 10.1016/j.bbr.2007.09.023
   Hirnstein M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00997
   Hirnstein M, 2010, BRAIN COGNITION, V73, P119, DOI 10.1016/j.bandc.2010.04.002
   Hugdahl K, 2003, ASYMMETRICAL BRAIN, P441
   Hunter ZR, 2008, NEUROPSYCHOLOGIA, V46, P316, DOI 10.1016/j.neuropsychologia.2007.07.007
   Keuleers E, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00174
   Kimura D, 1967, CORTEX, V3, P163, DOI [DOI 10.1016/S0010-9452(67)80010-8, 10.1016/s0010-9452(67)80010-8]
   Klichowski M, 2017, NEUROPSYCHOLOGIA, V100, P93, DOI 10.1016/j.neuropsychologia.2017.04.019
   Knecht S, 2000, BRAIN, V123, P2512, DOI 10.1093/brain/123.12.2512
   Kuperman V, 2011, J MEM LANG, V65, P42, DOI 10.1016/j.jml.2011.03.002
   Lemhofer K, 2012, BEHAV RES METHODS, V44, P325, DOI 10.3758/s13428-011-0146-0
   Mazoyer B, 2016, NEUROIMAGE, V124, P1225, DOI 10.1016/j.neuroimage.2015.02.071
   Mazoyer B, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0101165
   Mellet E, 2014, LATERALITY, V19, P383, DOI 10.1080/1357650X.2013.796965
   Morris SB, 2002, PSYCHOL METHODS, V7, P105, DOI 10.1037//1082-989X.7.1.105
   Ocklenburg S, 2014, FRONT PSYCHOL, V5, DOI [10.3389/fpsyg.2014.01143, 10.3389/fpsyg.2014.01300]
   Ocklenburg S, 2014, NEUROSCI BIOBEHAV R, V43, P191, DOI 10.1016/j.neubiorev.2014.04.008
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   OREGAN JK, 1992, J EXP PSYCHOL HUMAN, V18, P185, DOI 10.1037/0096-1523.18.1.185
   PETERS M, 1978, CAN J PSYCHOL, V32, P257, DOI 10.1037/h0081694
   Porac C., 1981, LATERAL PREFERENCES
   Pujol J, 1999, NEUROLOGY, V52, P1038, DOI 10.1212/WNL.52.5.1038
   Rossion B, 2011, VISION RES, V51, P1297, DOI 10.1016/j.visres.2011.04.003
   Seghier ML, 2008, MAGN RESON IMAGING, V26, P594, DOI 10.1016/j.mri.2007.10.010
   Spearman C, 1910, BRIT J PSYCHOL, V3, P271, DOI 10.1111/j.2044-8295.1910.tb00206.x
   Specht K, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00629
   Thiel A, 2006, BRAIN LANG, V98, P57, DOI 10.1016/j.bandl.2006.01.007
   Tzourio-Mazoyer N, 2010, J NEUROSCI, V30, P13314, DOI 10.1523/JNEUROSCI.2593-10.2010
   van den Bos K., 1999, KLEPEL VORM A B TEST
   van den Noort M, 2008, NEUROIMAGE, V40, P902, DOI 10.1016/j.neuroimage.2007.11.051
   Van der Haegen L, 2013, J COGNITIVE NEUROSCI, V25, P1442, DOI 10.1162/jocn_a_00412
   Van der Haegen L, 2013, NEUROPSYCHOLOGIA, V51, P91, DOI 10.1016/j.neuropsychologia.2012.11.002
   Van der Haegen L, 2012, BRAIN LANG, V122, P171, DOI 10.1016/j.bandl.2011.11.004
   Van der Haegen L, 2011, NEUROPSYCHOLOGIA, V49, P2879, DOI 10.1016/j.neuropsychologia.2011.06.014
   Willemin J., 2016, LATERALITY, P1, DOI [10.1080/1357650x.2015.1130716, DOI 10.1080/1357650X.2015.1130716, 10.1080/1357650X.2015.1047782]
   Willems RM, 2014, NAT REV NEUROSCI, V15, P193, DOI 10.1038/nrn3679
   Yovel G, 2008, NEUROPSYCHOLOGIA, V46, P3061, DOI 10.1016/j.neuropsychologia.2008.06.017
NR 54
TC 11
Z9 11
U1 2
U2 7
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD DEC 21
PY 2018
VL 13
IS 12
AR e0208696
DI 10.1371/journal.pone.0208696
PG 22
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA HF3QK
UT WOS:000454149400013
PM 30576313
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Geissler, DB
   Weiler, E
   Ehret, G
AF Geissler, Diana B.
   Weiler, Elke
   Ehret, Guenter
TI Adaptation and spectral enhancement at auditory temporal perceptual
   boundaries - Measurements via temporal precision of auditory brainstem
   responses
SO PLOS ONE
LA English
DT Article
ID DISCHARGE RATE REPRESENTATION; INFERIOR COLLICULUS NEURONS; VOICE-ONSET
   TIME; HEARING-LOSS; HOUSE-MOUSE; COCHLEAR NUCLEUS; NERVE FIBERS;
   COMMUNICATION CALLS; FREQUENCY-RESPONSE; SPEECH-PERCEPTION
AB In human and animal auditory perception the perceived quality of sound streams changes depending on the duration of inter-sound intervals (ISIs). Here, we studied whether adaptation and the precision of temporal coding in the auditory periphery reproduce general perceptual boundaries in the time domain near 20, 100, and 400 ms ISIs, the physiological origin of which are unknown. In four experiments, we recorded auditory brainstem responses with five wave peaks (P1 -P5) in response to acoustic models of communication calls of house mice, who perceived these calls with the mentioned boundaries. The newly introduced measure of average standard deviations of wave latencies of individual animals indicate the wave's temporal precision (latency jitter) mostly in the range of 30-100 mu s, very similar to latency jitter of single neurons. Adaptation effects of response latencies and latency jitter were measured for ISIs of 10-1000 ms. Adaptation decreased with increasing ISI duration following exponential or linear (on a logarithmic scale) functions in the range of up to about 200 ms ISIs. Adaptation effects were specific for each processing level in the auditory system. The perceptual boundaries near 20-30 and 100 ms ISIs were reflected in significant adaptation of latencies together with increases of latency jitter at P2-P5 for ISIs < similar to 30 ms and at P5 for ISIs < similar to 100 ms, respectively. Adaptation effects occurred when frequencies in a sound stream were within the same critical band. Ongoing low-frequency components/formants in a sound enhanced (decrease of latencies) coding of high-frequency components/formants when the frequencies concerned different critical bands. The results are discussed in the context of coding multi-harmonic sounds and stop-consonants-vowel pairs in the auditory brainstem. Furthermore, latency data at P1 (cochlea level) offer a reasonable value for the base-to-apex cochlear travel time in the mouse (0.342 ms) that has not been determined experimentally.
C1 [Geissler, Diana B.; Weiler, Elke; Ehret, Guenter] Univ Ulm, Inst Neurobiol, Ulm, Germany.
   [Weiler, Elke] Max Planck Inst Biol Cybernet, Tubingen, Germany.
RP Ehret, G (corresponding author), Univ Ulm, Inst Neurobiol, Ulm, Germany.
EM guenter.ehret@uni-ulm.de
OI Ehret, Gunter/0000-0002-1201-4878
FU Deutsche ForschungsgemeinschaftGerman Research Foundation (DFG) [EH
   53/22-1]
FX This work was supported by the Deutsche Forschungsgemeinschaft (EH
   53/22-1 to G.E.).
CR [Anonymous], 1961, R226 ISO
   ANSTIS S, 1985, J EXP PSYCHOL HUMAN, V11, P257, DOI 10.1037/0096-1523.11.3.257
   Ballachanda B B, 1992, J Am Acad Audiol, V3, P275
   Bregman A. S., 1990, AUDITORY SCENE ANAL, P1990
   Brittan-Powell EF, 2005, J ACOUST SOC AM, V118, P314, DOI 10.1121/1.1928767
   Brosch M, 2000, CEREB CORTEX, V10, P1155, DOI 10.1093/cercor/10.12.1155
   Brosch M, 1999, J NEUROPHYSIOL, V82, P1542
   BUDD TW, 1994, NEUROREPORT, V5, P2513, DOI 10.1097/00001756-199412000-00027
   Burkard R, 2001, HANDBOOK OF MOUSE AUDITORY RESEARCH: FROM BEHAVIOR TO MOLECULAR BIOLOGY, P603
   Burkard R, 1996, J ACOUST SOC AM, V100, P978, DOI 10.1121/1.416209
   BURKARD R, 1994, J ACOUST SOC AM, V95, P2126, DOI 10.1121/1.408674
   BURKARD R, 1989, J ACOUST SOC AM, V85, P2514, DOI 10.1121/1.397746
   Burkard R, 2012, TRANSLATIONAL PERSPE, P161
   Burkard R.F., 2007, AUDITORY EVOKED POTE
   CARLSON R, 1975, AUDITORY ANAL PERCEP, P55, DOI DOI 10.1016/B978-0-12-248550-3.50008-8
   Catrerette E. C., 1978, HDB PERCEPTION, P187
   Chandrasekaran B, 2010, PSYCHOPHYSIOLOGY, V47, P236, DOI 10.1111/j.1469-8986.2009.00928.x
   Chen GD, 1996, AUDIT NEUROSCI, V3, P179
   DARWIN CJ, 1984, Q J EXP PSYCHOL-A, V36, P193, DOI 10.1080/14640748408402155
   DEBRUYNE F, 1986, AUDIOLOGY, V25, P101
   DELGUTTE B, 1990, J ACOUST SOC AM, V87, P791, DOI 10.1121/1.398891
   DIXON WJ, 1953, BIOMETRICS, V9, P74, DOI 10.2307/3001634
   DON M, 1977, ANN OTO RHINOL LARYN, V86, P186, DOI 10.1177/000348947708600209
   Drayton M, 2006, HEARING RES, V212, P128, DOI 10.1016/j.heares.2005.11.006
   Eggermont JJ, 2001, HEARING RES, V157, P1, DOI 10.1016/S0378-5955(01)00259-3
   Egorova M, 2001, EXP BRAIN RES, V140, P145, DOI 10.1007/s002210100786
   Egorova M, 2008, EUR J NEUROSCI, V28, P675, DOI 10.1111/j.1460-9568.2008.06376.x
   EHRET G, 1986, ANIM BEHAV, V34, P821, DOI 10.1016/S0003-3472(86)80067-7
   EHRET G, 1984, HEARING RES, V14, P45, DOI 10.1016/0378-5955(84)90068-6
   EHRET G, 1975, BEHAVIOUR, V52, P38
   EHRET G, 1975, J COMP PHYSIOL, V103, P329, DOI 10.1007/BF00612025
   EHRET G, 1976, BIOL CYBERN, V24, P35, DOI 10.1007/BF00365592
   EHRET G, 1985, SCIENCE, V227, P1245, DOI 10.1126/science.3975613
   Ehret G, 2002, P NATL ACAD SCI USA, V99, P479, DOI 10.1073/pnas.012361999
   EHRET G, 1977, J COMP PHYSIOL, V122, P65, DOI 10.1007/BF00611249
   EHRET G, 1992, ANIM BEHAV, V43, P409, DOI 10.1016/S0003-3472(05)80101-0
   Ehret G, 1983, AUDITORY PSYCHOBIOLO, P1
   Ehret G, 2013, EVOLUTION EMOTIONAL, P63
   Ehret G, 2010, HBK BEHAV NEUROSCI, V19, P125, DOI 10.1016/B978-0-12-374593-4.00013-9
   Finlayson PG, 1999, HEARING RES, V131, P177, DOI 10.1016/S0378-5955(99)00032-5
   FULLERTON BC, 1987, ELECTROEN CLIN NEURO, V66, P547, DOI 10.1016/0013-4694(87)90102-7
   Gaub S, 2005, J COMP PHYSIOL A, V191, P1131, DOI 10.1007/s00359-005-0036-y
   Gaub S, 2010, GENES BRAIN BEHAV, V9, P390, DOI 10.1111/j.1601-183X.2010.00570.x
   Geissler DB, 2002, P NATL ACAD SCI USA, V99, P9021, DOI 10.1073/pnas.122606499
   Gittelman JX, 2006, J NEUROPHYSIOL, V96, P1203, DOI 10.1152/jn.00092.2005
   GOLDING NL, 1995, J NEUROSCI, V15, P3138
   Hackett TA, 2011, J NEUROSCI, V31, P2983, DOI 10.1523/JNEUROSCI.5333-10.2011
   HENRY KR, 1979, J AM AUDITORY SOC, V4, P173
   HENRY KR, 1979, AUDIOLOGY, V18, P93
   HENRY KR, 1978, DEV PSYCHOBIOL, V11, P161, DOI 10.1002/dev.420110208
   HIRSH IJ, 1959, J ACOUST SOC AM, V31, P759, DOI 10.1121/1.1907782
   HUANG C, 1980, BRAIN RES, V184, P215, DOI 10.1016/0006-8993(80)90601-0
   HUNTER KP, 1987, HEARING RES, V30, P207, DOI 10.1016/0378-5955(87)90137-7
   JORIS PX, 1994, J NEUROPHYSIOL, V71, P1022
   KATBAMNA B, 1993, AUDIOLOGY, V32, P344
   Klug A, 2000, HEARING RES, V148, P107, DOI 10.1016/S0378-5955(00)00146-5
   Knipper M, 2000, J NEUROPHYSIOL, V83, P3101
   KRAUS N, 1985, HEARING RES, V17, P219, DOI 10.1016/0378-5955(85)90066-8
   KUHL PK, 1978, J ACOUST SOC AM, V63, P905, DOI 10.1121/1.381770
   Kurt S, 2009, BRAIN RES, V1289, P30, DOI 10.1016/j.brainres.2009.06.092
   Land R, 2016, HEARING RES, V341, P109, DOI 10.1016/j.heares.2016.08.008
   Langner G.D, 2015, NEURAL CODE PITCH HA
   LIBERMAN AM, 1967, PSYCHOL REV, V74, P431, DOI 10.1037/h0020279
   Lina IA, 2013, HEARING RES, V298, P73, DOI 10.1016/j.heares.2013.01.002
   Liu RC, 2006, EUR J NEUROSCI, V23, P3087, DOI 10.1111/j.1460-9568.2006.04840.x
   MACHMERTH H, 1975, ACUSTICA, V34, P81
   Malinina E S, 2016, Dokl Biol Sci, V470, P209
   Malinina E S, 2005, Neurosci Behav Physiol, V35, P723, DOI 10.1007/s11055-005-0116-z
   Mauger SJ, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/3/036004
   Mehraei G, 2017, HEARING RES, V346, P34, DOI 10.1016/j.heares.2017.01.016
   Mehraei G, 2016, J NEUROSCI, V36, P3755, DOI 10.1523/JNEUROSCI.4460-15.2016
   Melcher JR, 1996, HEARING RES, V93, P1, DOI 10.1016/0378-5955(95)00178-6
   Muller M, 2010, HEARING RES, V268, P184, DOI 10.1016/j.heares.2010.05.021
   Nelson PC, 2009, J NEUROSCI, V29, P2553, DOI 10.1523/JNEUROSCI.5359-08.2009
   Parham K, 2001, HANDBOOK OF MOUSE AUDITORY RESEARCH: FROM BEHAVIOR TO MOLECULAR BIOLOGY, P37
   Patuzzi R, 1996, COCHLEA, P186
   PENNER MJ, 1975, PERCEPT PSYCHOPHYS, V18, P114, DOI 10.3758/BF03204097
   Perez-Gonzalez D, 2014, FRONT INTEGR NEUROSC, V8, DOI 10.3389/fnint.2014.00019
   PETERSON GE, 1952, J ACOUST SOC AM, V24, P175, DOI 10.1121/1.1906875
   PISONI DB, 1977, J ACOUST SOC AM, V61, P1352, DOI 10.1121/1.381409
   PISONI DB, 1974, J ACOUST SOC AM, V55, P328, DOI 10.1121/1.1914506
   Pressnitzer D, 2008, CURR BIOL, V18, P1124, DOI 10.1016/j.cub.2008.06.053
   PRIJS VF, 1981, HEARING RES, V4, P23, DOI 10.1016/0378-5955(81)90034-4
   Reichenbach CS, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00047
   Reimer K, 1996, AUDIOLOGY, V35, P55
   RHODE WS, 1978, J NEUROPHYSIOL, V41, P692
   RHODE WS, 1992, MAMMALIAN AUDITORY P, P94
   Robles L, 2001, PHYSIOL REV, V81, P1305
   Russo N, 2004, CLIN NEUROPHYSIOL, V115, P2021, DOI 10.1016/j.clinph.2004.04.003
   Sachs L, 1999, ANGEW STAT
   SAITOH Y, 1994, HEARING RES, V75, P27, DOI 10.1016/0378-5955(94)90052-3
   SHAW NA, 1988, PROG NEUROBIOL, V31, P19, DOI 10.1016/0301-0082(88)90021-4
   SINEX DG, 1989, J ACOUST SOC AM, V85, P1995, DOI 10.1121/1.397852
   SINEX DG, 1988, J ACOUST SOC AM, V83, P1817, DOI 10.1121/1.396516
   Someya S, 2009, P NATL ACAD SCI USA, V106, P19432, DOI 10.1073/pnas.0908786106
   Song L, 2006, J ACOUST SOC AM, V119, P2242, DOI 10.1121/1.2180533
   STEVENS KN, 1974, J ACOUST SOC AM, V55, P653, DOI 10.1121/1.1914578
   STIEBLER I, 1985, J COMP NEUROL, V238, P65, DOI 10.1002/cne.902380106
   Taberner AM, 2005, J NEUROPHYSIOL, V93, P557, DOI 10.1152/jn.00574.2004
   Tan XD, 2008, HEARING RES, V235, P90, DOI 10.1016/j.heares.2007.10.002
   Temchin AN, 2005, J NEUROPHYSIOL, V93, P3635, DOI 10.1152/jn.00885.2004
   Temchin AN, 2012, J NEUROSCI, V32, P10522, DOI 10.1523/JNEUROSCI.1138-12.2012
   WALTON JP, 1995, HEARING RES, V88, P19, DOI 10.1016/0378-5955(95)00093-J
   Walton JP, 1997, J COMP PHYSIOL A, V181, P161, DOI 10.1007/s003590050103
   WINTER IM, 1995, J NEUROPHYSIOL, V73, P141
   Wynne DP, 2013, BRAIN, V136, P1626, DOI 10.1093/brain/awt056
   Zheng QY, 1999, HEARING RES, V130, P94, DOI 10.1016/S0378-5955(99)00003-9
   Zhou XM, 2006, BRAIN RES, V1091, P16, DOI 10.1016/j.brainres.2006.01.107
   Zwicker E, 1967, OHR ALS NACHRICHTENE
   ZWISLOCKI J, 1962, J ACOUST SOC AM, V34, P1648
NR 110
TC 1
Z9 1
U1 0
U2 2
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD DEC 20
PY 2018
VL 13
IS 12
AR e0208935
DI 10.1371/journal.pone.0208935
PG 26
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA HF0HP
UT WOS:000453841700029
PM 30571726
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Kim, H
   Kang, WS
   Park, HJ
   Lee, JY
   Park, JW
   Kim, Y
   Seo, JW
   Kwak, MY
   Kang, BC
   Yang, CJ
   Duffy, B
   Cho, YS
   Lee, SY
   Suh, MW
   Moon, IJ
   Ahn, JH
   Cho, YS
   Oh, SH
   Chung, JW
AF Kim, Hosung
   Kang, Woo Seok
   Park, Hong Ju
   Lee, Jee Yeon
   Park, Jun Woo
   Kim, Yehree
   Seo, Ji Won
   Kwak, Min Young
   Kang, Byung Chul
   Yang, Chan Joo
   Duffy, Ben A.
   Cho, Young Sang
   Lee, Sang-Youp
   Suh, Myung Whan
   Moon, Il Joon
   Ahn, Joong Ho
   Cho, Yang-Sun
   Oh, Seung Ha
   Chung, Jong Woo
TI Cochlear Implantation in Postlingually Deaf Adults is Time-sensitive
   Towards Positive Outcome: Prediction using Advanced Machine Learning
   Techniques
SO SCIENTIFIC REPORTS
LA English
DT Article
ID CROSS-MODAL PLASTICITY; SPIRAL GANGLION-CELLS; AUDITORY-CORTEX;
   HEARING-LOSS; SPEECH-PERCEPTION; AGE; PERFORMANCE; NEUROPLASTICITY;
   RECOGNITION; CHILDREN
AB Given our aging society and the prevalence of age-related hearing loss that often develops during adulthood, hearing loss is a common public health issue affecting almost all older adults. Moderate-to-moderately severe hearing loss can usually be corrected with hearing aids; however, severe-to-profound hearing loss often requires a cochlear implant (CI). However, post-operative CI results vary, and the performance of the previous prediction models is limited, indicating that a new approach is needed. For postlingually deaf adults (n de120) who received CI with full insertion, we predicted CI outcomes using a Random-Forest Regression (RFR) model and investigated the effect of preoperative factors on CI outcomes. Postoperative word recognition scores (WRS) served as the dependent variable to predict. Predictors included duration of deafness (DoD), age at CI operation (ageCI), duration of hearing-aid use (DoHA), preoperative hearing threshold and sentence recognition score. Prediction accuracy was evaluated using mean absolute error (MAE) and Pearson's correlation coefficient r between the true WRS and predicted WRS. The fitting using a linear model resulted in prediction of WRS with r = 0.7 and MAE = 15.6 +/- 9. RFR outperformed the linear model (r = 0.96, MAE = 6.1 +/- 4.7, p < 0.00001). Cross-hospital data validation showed reliable performance using RFR (r = 0.91, MAE = 9.6 +/- 5.2). The contribution of DoD to prediction was the highest (MAE increase when omitted: 14.8), followed by ageCI (8.9) and DoHA (7.5). After CI, patients with DoD < 10 years presented better WRSs and smaller variations (p < 0.01) than those with longer DoD. Better WRS was also explained by younger age at CI and longer-term DoHA. Machine learning demonstrated a robust prediction performance for CI outcomes in postlingually deaf adults across different institutes, providing a reference value for counseling patients considering CI. Health care providers should be aware that the patients with severe-to-profound hearing loss who cannot have benefit from hearing aids need to proceed with CI as soon as possible and should continue using hearing aids until after CI operation.
C1 [Kim, Hosung; Duffy, Ben A.] Univ Southern Calif, USC Stevens Neuroimaging & Informat Inst, Keck Sch Med, Dept Neurol, Los Angeles, CA USA.
   [Kang, Woo Seok; Park, Hong Ju; Lee, Jee Yeon; Park, Jun Woo; Kim, Yehree; Seo, Ji Won; Kwak, Min Young; Ahn, Joong Ho; Chung, Jong Woo] Univ Ulsan, Dept Otolaryngol, Asan Med Ctr, Coll Med, Seoul, South Korea.
   [Kang, Byung Chul] Univ Ulsan, Ulsan Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg, Coll Med, Ulsan, South Korea.
   [Yang, Chan Joo] Hanil Gen Hosp, Dept Otolaryngol, Seoul, South Korea.
   [Cho, Young Sang; Moon, Il Joon; Cho, Yang-Sun] Sungkyunkwan Univ, Dept Otorhinolaryngol Head & Neck Surg, Samsung Med Ctr, Sch Med, Seoul, South Korea.
   [Lee, Sang-Youp; Suh, Myung Whan; Oh, Seung Ha] Seoul Natl Univ, Seoul Natl Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg, Coll Med, Seoul, South Korea.
RP Park, HJ (corresponding author), Univ Ulsan, Dept Otolaryngol, Asan Med Ctr, Coll Med, Seoul, South Korea.
EM dzness@amc.seoul.kr
RI Cho, Yang Sun/F-4611-2014; Suh, Myung-Whan/AAZ-9615-2020
OI Suh, Myung-Whan/0000-0003-1301-2249; Park, Hong Ju/0000-0002-6331-8556
CR Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585
   Beyea JA, 2016, OTOL NEUROTOL, V37, P1238, DOI 10.1097/MAO.0000000000001162
   Budenz CL, 2011, J AM GERIATR SOC, V59, P446, DOI 10.1111/j.1532-5415.2010.03310.x
   Campbell J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090594
   Champoux F, 2009, NEUROPSYCHOLOGIA, V47, P17, DOI 10.1016/j.neuropsychologia.2008.08.028
   Connor CM, 2006, EAR HEARING, V27, P628, DOI 10.1097/01.aud.0000240640.59205.42
   Cunningham LL, 2017, NEW ENGL J MED, V377, P2465, DOI 10.1056/NEJMra1616601
   Fayad JN, 2006, LARYNGOSCOPE, V116, P1310, DOI 10.1097/01.mlg.0000227176.09500.28
   Francis HW, 2005, EAR HEARING, V26, p7S, DOI 10.1097/00003446-200508001-00003
   Friedland DR, 2003, OTOL NEUROTOL, V24, P582, DOI 10.1097/00129492-200307000-00009
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   GANTZ BJ, 1993, ANN OTO RHINOL LARYN, V102, P909, DOI 10.1177/000348949310201201
   Glick H, 2017, HEARING RES, V343, P191, DOI 10.1016/j.heares.2016.08.012
   Green K M J, 2007, Cochlear Implants Int, V8, P1, DOI 10.1002/cii.326
   Hiel AL, 2016, EUR ARCH OTO-RHINO-L, V273, P2495, DOI 10.1007/s00405-015-3849-5
   Holden LK, 2013, EAR HEARING, V34, P342, DOI 10.1097/AUD.0b013e3182741aa7
   Khan AM, 2005, LARYNGOSCOPE, V115, P672, DOI 10.1097/01.mlg.0000161335.62139.80
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   Kral A, 2010, NEW ENGL J MED, V363, P1438, DOI 10.1056/NEJMra0911225
   Krittanawong C, 2017, J AM COLL CARDIOL, V69, P2657, DOI 10.1016/j.jacc.2017.03.571
   Lambertz N, 2005, COGNITIVE BRAIN RES, V25, P884, DOI 10.1016/j.cogbrainres.2005.09.010
   Lazard DS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048739
   Lee DS, 2001, NATURE, V409, P149, DOI 10.1038/35051653
   Lee JS, 2003, J NUCL MED, V44, P1435
   Lenarz M, 2012, LARYNGOSCOPE, V122, P1361, DOI 10.1002/lary.23232
   Leung J, 2005, ARCH OTOLARYNGOL, V131, P1049, DOI 10.1001/archotol.131.12.1049
   Lin FR, 2012, MEDICINE, V91, P229, DOI 10.1097/MD.0b013e31826b145a
   Moradi E, 2015, NEUROIMAGE, V104, P398, DOI 10.1016/j.neuroimage.2014.10.002
   NADOL JB, 1989, ANN OTO RHINOL LARYN, V98, P411, DOI 10.1177/000348948909800602
   Pacala JT, 2012, JAMA-J AM MED ASSOC, V307, P1185, DOI 10.1001/jama.2012.305
   Pantev C, 2006, CEREB CORTEX, V16, P31, DOI 10.1093/cercor/bhi081
   Park HJ, 2018, OTOL NEUROTOL, V39, P177, DOI 10.1097/MAO.0000000000001640
   Polonenko MJ, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-17129-z
   Roditi RE, 2009, OTOL NEUROTOL, V30, P449, DOI 10.1097/MAO.0b013e31819d3480
   Rubinstein JT, 1999, AM J OTOL, V20, P445
   Salthouse TA, 1996, PSYCHOL REV, V103, P403, DOI 10.1037/0033-295X.103.3.403
   Sandmann P, 2015, CLIN NEUROPHYSIOL, V126, P594, DOI 10.1016/j.clinph.2014.06.029
   Sandmann P, 2012, BRAIN, V135, P555, DOI 10.1093/brain/awr329
   Sharma Anu, 2002, Ear and Hearing, V23, P532, DOI 10.1097/00003446-200212000-00004
   Stropahl M, 2017, HEARING RES, V343, P128, DOI 10.1016/j.heares.2016.07.005
   Svetnik V, 2003, J CHEM INF COMP SCI, V43, P1947, DOI 10.1021/ci034160g
   Svirsky MA, 2004, AUDIOL NEURO-OTOL, V9, P224, DOI 10.1159/000078392
   Tun PA, 2009, PSYCHOL AGING, V24, P761, DOI 10.1037/a0014802
   Vermeire K, 2005, OTOL NEUROTOL, V26, P188, DOI 10.1097/00129492-200503000-00010
NR 44
TC 7
Z9 7
U1 0
U2 4
PU NATURE PUBLISHING GROUP
PI LONDON
PA MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD DEC 20
PY 2018
VL 8
AR 18004
DI 10.1038/s41598-018-36404-1
PG 9
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA HF0FX
UT WOS:000453836200010
PM 30573747
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Brodbeck, C
   Hong, LE
   Simon, JZ
AF Brodbeck, Christian
   Hong, L. Elliot
   Simon, Jonathan Z.
TI Rapid Transformation from Auditory to Linguistic Representations of
   Continuous Speech
SO CURRENT BIOLOGY
LA English
DT Article
ID SPOKEN-WORD RECOGNITION; LEXICAL ACCESS; TIME-COURSE; MEG;
   COMPREHENSION; CORTEX; LOCALIZATION; SEGMENTATION; INTEGRATION;
   PERCEPTION
AB During speech perception, a central task of the auditory cortex is to analyze complex acoustic patterns to allow detection of the words that encode a linguistic message [1]. It is generally thought that this process includes at least one intermediate, phonetic, level of representations [2-6], localized bilaterally in the superior temporal lobe [7-9]. Phonetic representations reflect a transition from acoustic to linguistic information, classifying acoustic patterns into linguistically meaningful units, which can serve as input to mechanisms that access abstract word representations [10, 11]. While recent research has identified neural signals arising from successful recognition of individual words in continuous speech [12-15], no explicit neurophysiological signal has been found demonstrating the transition from acoustic and/or phonetic to symbolic, lexical representations. Here, we report a response reflecting the incremental integration of phonetic information for word identification, dominantly localized to the left temporal lobe. The short response latency, approximately 114 ms relative to phoneme onset, suggests that phonetic information is used for lexical processing as soon as it becomes available. Responses also tracked word boundaries, confirming previous reports of immediate lexical segmentation [16, 17]. These new results were further investigated using a cocktail-party paradigm [18, 19] in which participants listened to a mix of two talkers, attending to one and ignoring the other. Analysis indicates neural lexical processing of only the attended, but not the unattended, speech stream. Thus, while responses to acoustic features reflect attention through selective amplification of attended speech, responses consistent with a lexical processing model reveal categorically selective processing.
C1 [Brodbeck, Christian; Simon, Jonathan Z.] Univ Maryland, Inst Syst Res, College Pk, MD 20742 USA.
   [Hong, L. Elliot] Univ Maryland, Maryland Psychiat Res Ctr, Sch Med, Dept Psychiat, Baltimore, MD 21201 USA.
   [Simon, Jonathan Z.] Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA.
   [Simon, Jonathan Z.] Univ Maryland, Dept Biol, College Pk, MD 20742 USA.
RP Brodbeck, C; Simon, JZ (corresponding author), Univ Maryland, Inst Syst Res, College Pk, MD 20742 USA.; Simon, JZ (corresponding author), Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA.; Simon, JZ (corresponding author), Univ Maryland, Dept Biol, College Pk, MD 20742 USA.
EM brodbeck@umd.edu; jzsimon@umd.edu
RI Brodbeck, Christian/R-2207-2019; Simon, Jonathan Z/A-8196-2008
OI Brodbeck, Christian/0000-0001-8380-639X; Simon, Jonathan
   Z/0000-0003-0858-0698
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01-DC-014085];
   University of Maryland Seed Grant; NATIONAL INSTITUTE OF MENTAL
   HEALTHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute of Mental Health
   (NIMH) [R01MH112180, R01MH116948, R01MH112180, R01MH112180, R01MH116948,
   R01MH112180] Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC014085, R01DC014085, R01DC014085, R01DC014085, R01DC014085]
   Funding Source: NIH RePORTER
FX This work was supported by a National Institutes of Health grant
   R01-DC-014085 (to J.Z.S.) and by a University of Maryland Seed Grant (to
   L.E.H. and J.Z.S.). We would like to thank Krishna Puvvada for his
   assistance in designing and preparing the stimuli and Natalia Lapinskaya
   for her help in collecting data and for excellent technical support.
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   Balling LW, 2012, COGNITION, V125, P80, DOI 10.1016/j.cognition.2012.06.003
   Boersma P., 2018, PRAAT DOING PHONETIC
   Brodbeck C., 2018, EELBRAIN 0 27 ZENODO
   Brodbeck C, 2018, NEUROIMAGE, V172, P162, DOI 10.1016/j.neuroimage.2018.01.042
   Broderick MP, 2018, CURR BIOL, V28, P803, DOI 10.1016/j.cub.2018.01.080
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Dahan D, 2001, LANG COGNITIVE PROC, V16, P507, DOI 10.1080/01690960143000074
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750
   DALE AM, 1993, J COGNITIVE NEUROSCI, V5, P162, DOI 10.1162/jocn.1993.5.2.162
   David SV, 2007, NETWORK-COMP NEURAL, V18, P191, DOI 10.1080/09548980701609235
   David SV, 2009, J NEUROSCI, V29, P3374, DOI 10.1523/JNEUROSCI.5249-08.2009
   Davis MH, 2007, P NATL ACAD SCI USA, V104, P16032, DOI 10.1073/pnas.0701309104
   Davis MH, 2003, J NEUROSCI, V23, P3423
   Dehaene-Lambertz G, 2006, HUM BRAIN MAPP, V27, P360, DOI 10.1002/hbm.20250
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Ding N, 2018, J NEUROSCI, V38, P1178, DOI 10.1523/JNEUROSCI.2606-17.2017
   Ding N, 2016, NAT NEUROSCI, V19, P158, DOI 10.1038/nn.4186
   Ding N, 2013, J NEUROSCI, V33, P5728, DOI 10.1523/JNEUROSCI.5297-12.2013
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Ettinger A, 2014, BRAIN LANG, V129, P14, DOI 10.1016/j.bandl.2013.11.004
   Fischl B, 2012, NEUROIMAGE, V62, P774, DOI 10.1016/j.neuroimage.2012.01.021
   Gagnepain P, 2008, J NEUROSCI, V28, P5281, DOI 10.1523/JNEUROSCI.0565-08.2008
   Gagnepain P, 2012, CURR BIOL, V22, P615, DOI 10.1016/j.cub.2012.02.015
   Gaston P, 2018, LANG COGN NEUROSCI, V33, P402, DOI 10.1080/23273798.2017.1395466
   Gramfort A, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00267
   Gramfort A, 2014, NEUROIMAGE, V86, P446, DOI 10.1016/j.neuroimage.2013.10.027
   Greve DN, 2013, J COGNITIVE NEUROSCI, V25, P1477, DOI 10.1162/jocn_a_00405
   Gwilliams L, 2015, BRAIN LANG, V147, P1, DOI 10.1016/j.bandl.2015.04.006
   HAMALAINEN MS, 1994, MED BIOL ENG COMPUT, V32, P35, DOI 10.1007/BF02512476
   Hamilton LS, 2018, CURR BIOL, V28, P1860, DOI 10.1016/j.cub.2018.04.033
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Kazanina N, 2018, PSYCHON B REV, V25, P560, DOI 10.3758/s13423-017-1362-0
   Kluender KR, 2003, SPEECH COMMUN, V41, P59, DOI 10.1016/S0167-6393(02)00093-6
   Lalor EC, 2006, NEUROIMAGE, V32, P1549, DOI 10.1016/j.neuroimage.2006.05.054
   Lerner Y, 2011, J NEUROSCI, V31, P2906, DOI 10.1523/JNEUROSCI.3684-10.2011
   Lin FH, 2006, NEUROIMAGE, V31, P160, DOI 10.1016/j.neuroimage.2005.11.054
   MARSLENWILSON W, 1994, PSYCHOL REV, V101, P653, DOI 10.1037/0033-295X.101.4.653
   MARSLENWILSON WD, 1987, COGNITION, V25, P71, DOI 10.1016/0010-0277(87)90005-9
   Mattys SL, 2005, J EXP PSYCHOL GEN, V134, P477, DOI 10.1037/0096-3445.134.4.477
   Mattys SL, 2017, CUR ISS PSYCHOL LANG, P55
   McDermott JH, 2009, CURR BIOL, V19, pR1024, DOI 10.1016/j.cub.2009.09.005
   McQueen J., 2007, OXFORD HDB PSYCHOLIN, P37, DOI DOI 10.1093/0XF0RDHB/9780198568971.013.0003
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Obleser J, 2009, TRENDS COGN SCI, V13, P14, DOI 10.1016/j.tics.2008.09.005
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Phillips C, 2000, J COGNITIVE NEUROSCI, V12, P1038, DOI 10.1162/08989290051137567
   Puvvada KC, 2017, J NEUROSCI, V37, P9189, DOI 10.1523/JNEUROSCI.0938-17.2017
   Revill KP, 2008, P NATL ACAD SCI USA, V105, P13111, DOI 10.1073/pnas.0807054105
   Sanders LD, 2003, COGNITIVE BRAIN RES, V15, P228, DOI 10.1016/S0926-6410(02)00195-7
   Sanders LD, 2002, NAT NEUROSCI, V5, P700, DOI 10.1038/nn873
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Smith SM, 2009, NEUROIMAGE, V44, P83, DOI 10.1016/j.neuroimage.2008.03.061
   Stevens KN, 2002, J ACOUST SOC AM, V111, P1872, DOI 10.1121/1.1458026
   Taulu S, 2006, PHYS MED BIOL, V51, P1759, DOI 10.1088/0031-9155/51/7/008
   TYLER LK, 1984, PERCEPT PSYCHOPHYS, V36, P417, DOI 10.3758/BF03207496
   Vitevitch MS, 2002, J EXP PSYCHOL HUMAN, V28, P270, DOI 10.1037//0096-1523.28.2.270
   WARREN P, 1987, PERCEPT PSYCHOPHYS, V41, P262, DOI 10.3758/BF03208224
   Wurm LH, 2006, MENT LEX, V1, P125, DOI 10.1075/ml.1.1.08wur
   YANG XW, 1992, IEEE T INFORM THEORY, V38, P824, DOI 10.1109/18.119739
NR 66
TC 32
Z9 32
U1 0
U2 14
PU CELL PRESS
PI CAMBRIDGE
PA 50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA
SN 0960-9822
EI 1879-0445
J9 CURR BIOL
JI Curr. Biol.
PD DEC 17
PY 2018
VL 28
IS 24
BP 3976
EP +
DI 10.1016/j.cub.2018.10.042
PG 13
WC Biochemistry & Molecular Biology; Biology; Cell Biology
SC Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other
   Topics; Cell Biology
GA HE6ST
UT WOS:000453543800026
PM 30503620
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Chen, L
   Lei, JH
   Gong, HN
AF Chen, Liang
   Lei, Jianghua
   Gong, Huina
TI The effect of hearing status on speechreading performance of Chinese
   adolescents
SO CLINICAL LINGUISTICS & PHONETICS
LA English
DT Article
DE Speechreading; hearing status; deafness; Mandarin Chinese; visual speech
   perception; lipreading
ID VISUAL SPEECH-PERCEPTION; DEAF; CHILDREN; INTEGRATION; OLDER;
   INDIVIDUALS; ABILITIES; MEMORY; ADULTS
AB The effect of hearing status on the ability to speechread is poorly understood, and current findings are inconclusive regarding differences in speechreading performance between children and adults with hearing impairment and those with normal hearing. In this study, we investigated the effect of hearing status on speechreading skills in Chinese adolescents. Thirty seven severely deaf students with a mean pure-tone average of 93 dB hearing threshold level and 21 hearing controls aged 16 completed tasks measuring their speechreading of simplex finals (monophthongs), complex finals (diphthongs or vowel + nasal constellations) and initials (consonants) in Chinese. Both accuracy rate and response time data were collected. Results showed no significant difference in accuracy between groups. By contrast, deaf individuals were significantly faster at speechreading than their hearing controls. In addition, for both groups, performance on speechreading simplex finals was faster and more accurate than complex finals, which in turn was better than initial consonants. We conclude that speechreading skills in Chinese adolescents are influenced by hearing status, characteristics of sounds to be identified, as well as the measures used.
C1 [Chen, Liang] Univ Georgia, Commun Sci & Special Educ, 542 Aderhold Hall, Athens, GA 30602 USA.
   [Lei, Jianghua; Gong, Huina] Cent China Normal Univ, Dept Special Educ, Wuhan, Hubei, Peoples R China.
RP Chen, L (corresponding author), Univ Georgia, Commun Sci & Special Educ, 542 Aderhold Hall, Athens, GA 30602 USA.
EM chen@uga.edu
FU China National Social Science Foundation [15BYY069]
FX This work was supported by the China National Social Science Foundation:
   [Grant Number 15BYY069].
CR Alm M, 2015, FRONT PSYCHOL, V6, DOI [10.3389/fpsyg.2015.01014, 10.3389/fpgyg.2015.01014]
   Altieri N, 2016, INT J AUDIOL, V55, P206, DOI 10.3109/14992027.2015.1120895
   Andersson U., 2001, J DEAF STUD DEAF EDU, V6, P103, DOI DOI 10.1093/DEAFED/6.2.103
   Arnold P, 1996, SCAND AUDIOL, V25, P13, DOI 10.3109/01050399609047550
   Auer ET, 2008, J SPEECH LANG HEAR R, V51, P750, DOI 10.1044/1092-4388(2008/053)
   Auer ET, 2007, J SPEECH LANG HEAR R, V50, P1157, DOI 10.1044/1092-4388(2007/080)
   Bavelier D, 2006, TRENDS COGN SCI, V10, P512, DOI 10.1016/j.tics.2006.09.006
   Beattie R., 1992, ACEHI J, V18, P110
   Bernstein LE, 2000, PERCEPT PSYCHOPHYS, V62, P233, DOI 10.3758/BF03205546
   Burnham D, 2004, DEV PSYCHOBIOL, V45, P204, DOI 10.1002/dev.20032
   Chen L, 2017, CLIN LINGUIST PHONET, V31, P514, DOI 10.1080/02699206.2016.1277391
   Chen TH, 2008, J ACOUST SOC AM, V123, P2356, DOI 10.1121/1.2839004
   CONRAD R, 1977, BRIT J EDUC PSYCHOL, V47, P60, DOI 10.1111/j.2044-8279.1977.tb03001.x
   de Oliveira LN, 2014, CODAS, V26, P53, DOI 10.1590/s2317-17822014000100008
   DEGELDER B, 1994, J MEM LANG, V33, P737, DOI 10.1006/jmla.1994.1035
   Elphick R, 1996, BRIT J EDUC PSYCHOL, V66, P357, DOI 10.1111/j.2044-8279.1996.tb01202.x
   Fine I, 2002, J VISION, V2, P190, DOI 10.1167/2.2.5
   Gagne JP, 2006, INT J AUDIOL, V45, P295, DOI 10.1080/14992020500485718
   GREEN WB, 1981, VOLTA REV, V83, P389
   Heathcote A, 2000, PSYCHON B REV, V7, P185, DOI 10.3758/BF03212979
   Heitz RP, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00150
   Jerger S, 2009, J SPEECH LANG HEAR R, V52, P412, DOI 10.1044/1092-4388(2009/08-0021)
   Jerger S, 2009, J EXP CHILD PSYCHOL, V102, P40, DOI 10.1016/j.jecp.2008.08.002
   Joni S. B., 1998, HRVATSKA REVIJA REHA, V34, P147
   Kyle FE, 2006, J DEAF STUD DEAF EDU, V11, P273, DOI 10.1093/deafed/enj037
   Kyle FE, 2013, J SPEECH LANG HEAR R, V56, P416, DOI 10.1044/1092-4388(2012/12-0039)
   Kyle FE, 2016, RES DEV DISABIL, V48, P13, DOI 10.1016/j.ridd.2015.10.004
   LESNER SA, 1987, EAR HEARING, V8, P283
   Li YL, 2018, INT J AUDIOL, V57, P135, DOI 10.1080/14992027.2017.1374566
   Lin H., 2001, GRAMMAR MANDARIN CHI
   Lyxell B, 2000, BRIT J EDUC PSYCHOL, V70, P505, DOI 10.1348/000709900158272
   Mohammed T, 2006, CLIN LINGUIST PHONET, V20, P621, DOI 10.1080/02699200500266745
   Myklebust H. R., 1970, DIAGNOSTIC TEST SPEE
   Pimperton H, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00106
   Rodriguez-Ortiz IR, 2017, J RES READ, V40, P75, DOI 10.1111/1467-9817.12062
   Ronnberg J., 1995, COMPENSATING PSYCHOL, P251
   Ronnberg J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00031
   Rosenblum LD, 1997, PERCEPT PSYCHOPHYS, V59, P347, DOI 10.3758/BF03211902
   Schwartz JL, 2004, COGNITION, V93, pB69, DOI 10.1016/j.cognition.2004.01.006
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   Strelnikov K, 2009, NEUROPSYCHOLOGIA, V47, P972, DOI 10.1016/j.neuropsychologia.2008.10.017
   Tye-Murray N., 2001, CHILDRENS AUDIO VISU
   Tye-Murray N, 2007, EAR HEARING, V28, P656, DOI 10.1097/AUD.0b013e31812f7185
   Tye-Murray N, 2014, J SPEECH LANG HEAR R, V57, P556, DOI 10.1044/2013_JSLHR-H-12-0273
   Tye-Murray N, 2008, INT J AUDIOL, V47, pS31, DOI 10.1080/14992020802301662
   Woodhouse L, 2009, INT J LANG COMM DIS, V44, P253, DOI 10.1080/13682820802090281
   Zhao XW, 2009, BEHAV RES METHODS, V41, P575, DOI 10.3758/BRM.41.2.575
NR 47
TC 3
Z9 3
U1 0
U2 16
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0269-9206
EI 1464-5076
J9 CLIN LINGUIST PHONET
JI Clin. Linguist. Phon.
PD DEC 2
PY 2018
VL 32
IS 12
SI SI
BP 1090
EP 1102
DI 10.1080/02699206.2018.1510986
PG 13
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GZ0ZG
UT WOS:000449093700003
PM 30183411
DA 2021-02-24
ER

PT J
AU Sfakianaki, A
   Nicolaidis, K
   Okalidou, A
   Vlahavas, G
AF Sfakianaki, Anna
   Nicolaidis, Katerina
   Okalidou, Areti
   Vlahavas, George
TI Coarticulatory dynamics in Greek disyllables produced by young adults
   with and without hearing loss
SO CLINICAL LINGUISTICS & PHONETICS
LA English
DT Article
DE Hearing impairment; coarticulation; acoustics; Greek
ID TO-VOWEL COARTICULATION; ACOUSTIC CHARACTERISTICS; INTELLIGIBLE
   SPEAKERS; CONSONANT PRODUCTION; SPEECH; VARIABILITY; CHILDREN;
   IMPAIRMENT; AGGRESSIVENESS; ARTICULATION
AB Hearing loss affects both speech perception and production with detrimental effects on various speech characteristics including coarticulatory dynamics. The aim of the present study is to explore consonant-to-vowel (C-to-V) and vowel-to-vowel (V-to-V) coarticulation in magnitude, direction and temporal extent in the speech of young adult male and female speakers of Greek with normal hearing (NH) and hearing impairment (HI). Nine intelligible speakers with profound HI, using conventional hearing aids, and five speakers with NH produced /pV(1)CV(2)/ disyllables, with the point vowels /i, a, u/ and the consonants /p, t, s/, stressed either on the first or the second syllable. Formant frequencies F1 and F2 were measured in order to examine C-to-V effects at vowel midpoint and V-to-V effects at vowel onset, midpoint and offset. The acoustic and statistical analyses revealed similarities but also significant differences regarding coarticulatory patterns of the two groups. Interestingly, prevalence of anticipatory coarticulation effects in alveolar contexts was observed for speakers with HI. Findings are interpreted on account of possible differences in articulation strategies between the two groups and with reference to current coarticulatory models.
C1 [Sfakianaki, Anna] Univ Crete, Dept Comp Sci, Speech Signal Proc Lab, Voutes Campus, Iraklion 70013, Crete, Greece.
   [Nicolaidis, Katerina] Aristotle Univ Thessaloniki, Sch English, Dept Theoret & Appl Linguist, Thessaloniki, Greece.
   [Okalidou, Areti] Univ Macedonia, Dept Educ & Social Policy, Thessaloniki, Greece.
   [Vlahavas, George] Aristotle Univ Thessaloniki, Sch Informat, Thessaloniki, Greece.
RP Sfakianaki, A (corresponding author), Univ Crete, Dept Comp Sci, Speech Signal Proc Lab, Voutes Campus, Iraklion 70013, Crete, Greece.
EM asfakianaki@csd.uoc.gr
OI SFAKIANAKI, ANNA/0000-0001-6648-6865
FU Greek Ministry of Culture, Education and Religious Affairs
FX This study is based on part of the first author's doctoral thesis which
   was funded by the Greek Ministry of Culture, Education and Religious
   Affairs. The authors report no conflict of interest.
CR Asteriadou I., 2008, THESIS
   Beddor PS, 2002, J PHONETICS, V30, P591, DOI 10.1006/jpho.2002.0177
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Browman Catherine, 1986, PHONOLOGY YB, V3, P219, DOI DOI 10.1017/S0952675700000658
   BUTCHER A, 1989, CLIN LINGUIST PHONET, V3, P39, DOI 10.3109/02699208908985269
   Clark J G, 1981, ASHA, V23, P493
   DAGENAIS PA, 1991, J SPEECH HEAR RES, V34, P1423, DOI 10.1044/jshr.3406.1423
   Ellis L, 2009, LANG LINGUIST COMPAS, V3, DOI 10.1111/j.1749-818x.2009.00151.x
   Farnetani E., 2010, HDB PHONETIC SCI, P316, DOI [10.1002/9781444317251.ch9, DOI 10.1002/9781444317251.CH9]
   FOWLER CA, 1980, J PHONETICS, V8, P113, DOI 10.1016/S0095-4470(19)31446-9
   GOODELL EW, 1993, J SPEECH HEAR RES, V36, P707, DOI 10.1044/jshr.3604.707
   Graetzer S, 2015, J ACOUST SOC AM, V137, P806, DOI 10.1121/1.4904488
   Guenther F.H., 2004, SPEECH MOTOR CONTROL, P29
   KEATING PA, 1994, J PHONETICS, V22, P407, DOI 10.1016/S0095-4470(19)30293-1
   MANUEL SY, 1990, J ACOUST SOC AM, V88, P1286, DOI 10.1121/1.399705
   McGarr N. S., 1995, PRODUCING SPEECH CON, P433
   Modarresi G, 2004, J PHONETICS, V32, P291, DOI 10.1016/j.wocn.2003.11.002
   Mok PKP, 2010, J ACOUST SOC AM, V128, P1346, DOI 10.1121/1.3466859
   Mok PPK, 2011, LANG SPEECH, V54, P527, DOI 10.1177/0023830911404961
   Monsen R, 1976, J PHONETICS, V4, P189
   MONSEN RB, 1976, J SPEECH HEAR RES, V19, P279, DOI 10.1044/jshr.1902.279
   Morrison HM, 2008, CLIN LINGUIST PHONET, V22, P726, DOI 10.1080/02699200802176402
   Morrison HM, 2012, CLIN LINGUIST PHONET, V26, P288, DOI 10.3109/02699206.2011.614718
   Nicolaidis K, 2004, CLIN LINGUIST PHONET, V18, P419, DOI 10.1080/02699200410001703574
   Nicolaidis K., 1997, THESIS
   Nicolaidis K, 2007, CLIN LINGUIST PHONET, V21, P405, DOI 10.1080/02699200701267377
   Nicolaidis K, 2016, INT J SPEECH-LANG PA, V18, P378, DOI 10.3109/17549507.2015.1101155
   Nicolaidis K, 2016, INT J SPEECH-LANG PA, V18, P388, DOI 10.3109/17549507.2016.1151934
   NITTROUER S, 1993, J SPEECH HEAR RES, V36, P959, DOI 10.1044/jshr.3605.959
   Okalidou A, 1999, J ACOUST SOC AM, V106, P394, DOI 10.1121/1.427064
   Okalidou A., 1999, J ACOUST SOC AM, V105, P1094, DOI [10.1121/1.425129, DOI 10.1121/1.425129]
   OSBERGER MJ, 1993, J SPEECH HEAR RES, V36, P186, DOI 10.1044/jshr.3601.186
   Ozbic M, 2010, DEAF EDUC INT, V12, P99, DOI 10.1179/146431510X12626982043804
   Panhellenic Association of Logopedists, 1995, DOK PHON KAI PHON EK
   Pratt S. R., 2009, CLIN MANAGEMENT SENS
   RECASENS D, 1987, J PHONETICS, V15, P299, DOI 10.1016/S0095-4470(19)30580-7
   Recasens D, 1997, J ACOUST SOC AM, V102, P544, DOI 10.1121/1.419727
   Recasens D, 2000, J SPEECH LANG HEAR R, V43, P501, DOI 10.1044/jslhr.4302.501
   Recasens D, 1999, COARTICULATION THEOR, P80
   Recasens D, 2017, PHONETICA, V74, P125, DOI 10.1159/000452475
   Recasens D, 2016, J PHONETICS, V59, P58, DOI 10.1016/j.wocn.2016.09.002
   Recasens D, 2009, J ACOUST SOC AM, V125, P2288, DOI 10.1121/1.3089222
   Rothman H. B., 1976, J PHONETICS, V4, P129
   RYALLS J, 1993, EUR J DISORDER COMM, V28, P87
   Sfakianaki A., 2016, 21 INT S THEOR APPL, P401
   Sfakianaki A., 2012, THESIS
   Sfakianaki A., 2017, P INT S MON BIL SPEE, P258
   Sfakianaki A., 2016, GLOSSOLOGIA, V24, P75
   WALDSTEIN RS, 1991, J SPEECH HEAR RES, V34, P1276, DOI 10.1044/jshr.3406.1276
   Yutaka N, 2015, PROCEEDINGS OF THE 22ND INTERNATIONAL CONGRESS ON SOUND AND VIBRATION
   ZHARKOVA N, 2007, QMU SPEECH SCI RES C, V13, P1
   Zharkova N, 2018, PHONETICA, V75, P245, DOI 10.1159/000485802
   Zharkova N, 2011, MOTOR CONTROL, V15, P118, DOI 10.1123/mcj.15.1.118
NR 53
TC 0
Z9 0
U1 0
U2 1
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0269-9206
EI 1464-5076
J9 CLIN LINGUIST PHONET
JI Clin. Linguist. Phon.
PD DEC 2
PY 2018
VL 32
IS 12
SI SI
BP 1162
EP 1184
DI 10.1080/02699206.2018.1510987
PG 23
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GZ0ZG
UT WOS:000449093700007
PM 30183418
DA 2021-02-24
ER

PT J
AU Ou, JH
   Law, SP
AF Ou, Jinghua
   Law, Sam-Po
TI Induced gamma oscillations index individual differences in speech sound
   perception and production
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE EEG; Neural oscillations; Speech perception; Speech production;
   Individual differences; Induced gamma oscillations
ID MISMATCH NEGATIVITY; THETA OSCILLATION; AUDITORY-CORTEX; BAND ACTIVITY;
   RESPONSES; DISCRIMINATION; EEG; ATTENTION; DYNAMICS; REFLECTS
AB Auditory neuroscience has provided strong evidence that neural oscillations synchronize to the rhythm of speech stimuli, and oscillations at different frequencies have been linked to processing of different language structures. The present study aims to examine how these ubiquitous neurophysiological attributes may inform us about the brain processes that underpin individual differences in speech perception and production, which in turn elucidate the specific functions of neural oscillations in the domain of speech processing. To this end, we recorded electrophysiological responses to a lexical tone contrast in a passive auditory oddball paradigm from two groups of healthy tone-language speakers who were equal in perceptual discriminability but differed in response latency and production distinctiveness of the tone contrast. Time-frequency analysis was applied to the EEG data, and decomposed into theta (4-7 Hz), beta (12-30 Hz), and gamma (30-50 Hz) frequency bands. Results show that listeners with longer discrimination RT and less distinctive production showed significantly higher induced (non-phase-locked) gamma during tone processing. Moreover, among speakers with less distinctive production, individual differences in induced gamma were significantly correlated with discrimination latency and production distinction. Based on the present findings, we propose that differences in gamma oscillations reflect differential sensory/perceptual computations during acoustic encoding, impacting the quality of perceptual representations, which further mediates individual differences in speech perception and production.
C1 [Ou, Jinghua] Chinese Univ Hong Kong, Dept Linguist & Modern Languages, Hong Kong, Peoples R China.
   [Law, Sam-Po] Univ Hong Kong, Div Speech & Hearing Sci, Hong Kong, Peoples R China.
RP Ou, JH (corresponding author), Chinese Univ Hong Kong, Dept Linguist & Modern Languages, Hong Kong, Peoples R China.
EM jhou@cuhk.edu.hk
FU Small Project Fund at the University of Hong Kong
FX Portions of this work was supported by a Small Project Fund at the
   University of Hong Kong [project titled "Neural correlates and cognitive
   capability associated with individual variations in tone perception and
   production in Cantonese - An event-related potential (ERP) study"). We
   are grateful to the editor and two anonymous reviewers whose insightful
   suggestions have appreciably improved the manuscript.
CR Basar E, 1999, BRAIN LANG, V66, P146, DOI 10.1006/brln.1998.2029
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bertrand O, 2000, INT J PSYCHOPHYSIOL, V38, P211, DOI 10.1016/S0167-8760(00)00166-5
   Bhattacharya J, 2001, J NEUROSCI, V21, P6329
   Bidelman GM, 2017, NEUROSCIENCE, V348, P107, DOI 10.1016/j.neuroscience.2017.02.015
   Bidelman GM, 2015, BRAIN LANG, V141, P62, DOI 10.1016/j.bandl.2014.11.003
   Bishop DVM, 2010, PSYCHOPHYSIOLOGY, V47, P697, DOI 10.1111/j.1469-8986.2009.00970.x
   Choi JW, 2013, NEUROSCI LETT, V548, P120, DOI 10.1016/j.neulet.2013.05.079
   Crone NE, 2001, CLIN NEUROPHYSIOL, V112, P565, DOI 10.1016/S1388-2457(00)00545-9
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Diaz B, 2008, P NATL ACAD SCI USA, V105, P16083, DOI 10.1073/pnas.0805022105
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Engel AK, 2001, NAT REV NEUROSCI, V2, P704, DOI 10.1038/35094565
   Fuentemilla L, 2008, BRAIN RES, V1220, P93, DOI 10.1016/j.brainres.2007.07.079
   Ghitza O, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00138
   Ghitza O, 2013, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00340
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   GRAY CM, 1989, NATURE, V338, P334, DOI 10.1038/338334a0
   Groppe DM, 2011, PSYCHOPHYSIOLOGY, V48, P1711, DOI 10.1111/j.1469-8986.2011.01273.x
   Gruber T, 2002, J COGNITIVE NEUROSCI, V14, P732, DOI 10.1162/08989290260138636
   GUENTHER FH, 1995, PSYCHOL REV, V102, P594, DOI 10.1037/0033-295X.102.3.594
   Herrmann CS, 2004, TRENDS COGN SCI, V8, P347, DOI 10.1016/j.tics.2004.06.006
   Herrmann CS, 2001, NEUROSCI BIOBEHAV R, V25, P465, DOI 10.1016/S0149-7634(01)00027-6
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hsiao FJ, 2009, BIOL PSYCHOL, V81, P58, DOI 10.1016/j.biopsycho.2009.01.007
   Indefrey P, 2004, COGNITIVE NEUROSCIENCES III, THIRD EDITION, P759
   Jakoby H, 2011, PSYCHOPHYSIOLOGY, V48, P1516, DOI 10.1111/j.1469-8986.2011.01227.x
   Jensen O, 2007, TRENDS NEUROSCI, V30, P317, DOI 10.1016/j.tins.2007.05.001
   Jin Y, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0100901
   KALCHER J, 1995, ELECTROEN CLIN NEURO, V94, P381, DOI 10.1016/0013-4694(95)00040-6
   Ko D, 2012, J CLIN NEUROL, V8, P35, DOI 10.3988/jcn.2012.8.1.35
   Koerner TK, 2016, HEARING RES, V339, P40, DOI 10.1016/j.heares.2016.06.001
   Labov W., 1994, PRINCIPLES LANGUAGE
   Lehongre K, 2011, NEURON, V72, P1080, DOI 10.1016/j.neuron.2011.11.002
   Lenz D, 2007, INT J PSYCHOPHYSIOL, V64, P31, DOI 10.1016/j.ijpsycho.2006.07.008
   Levelt WJM, 1999, TRENDS COGN SCI, V3, P223, DOI 10.1016/S1364-6613(99)01319-4
   Lotto AJ, 2009, TRENDS COGN SCI, V13, P110, DOI 10.1016/j.tics.2008.11.008
   Makeig S, 2004, TRENDS COGN SCI, V8, P204, DOI 10.1016/j.tics.2004.03.008
   MAKEIG S, 1993, ELECTROEN CLIN NEURO, V86, P283, DOI 10.1016/0013-4694(93)90110-H
   McQueen J. M, 2005, HDB COGNITION, P255, DOI DOI 10.4135/9781848608177.N11
   Meyer L., 2017, EUR J NEUROSCI
   Meyer L, 2018, J COGNITIVE NEUROSCI, V30, P1066, DOI 10.1162/jocn_a_01236
   Naatanen R, 2001, PERCEPTION SPEECH SO
   Ou JH, 2016, J ACOUST SOC AM, V139, P3226, DOI 10.1121/1.4954252
   Ou JH, 2015, PSYCHON B REV, V22, P1725, DOI 10.3758/s13423-015-0839-y
   Palva S, 2002, J NEUROSCI, V22, DOI 10.1523/JNEUROSCI.22-04-j0003.2002
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Power AJ, 2016, BRAIN LANG, V160, P1, DOI 10.1016/j.bandl.2016.06.006
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Sauseng P, 2007, NEUROSCIENCE, V146, P1435, DOI 10.1016/j.neuroscience.2007.03.014
   Scharinger M, 2016, NEUROIMAGE, V128, P293, DOI 10.1016/j.neuroimage.2016.01.003
   Shahin AJ, 2008, NEUROIMAGE, V41, P113, DOI 10.1016/j.neuroimage.2008.01.067
   Snyder JS, 2005, COGNITIVE BRAIN RES, V24, P117, DOI 10.1016/j.cogbrainres.2004.12.014
   Tallon-Baudry C, 1999, TRENDS COGN SCI, V3, P151, DOI 10.1016/S1364-6613(99)01299-1
   TallonBaudry C, 1997, NEUROREPORT, V8, P1103, DOI 10.1097/00001756-199703240-00008
   TIITINEN H, 1993, NATURE, V364, P59, DOI 10.1038/364059a0
   Trainor LJ, 2009, ANN NY ACAD SCI, V1169, P133, DOI 10.1111/j.1749-6632.2009.04589.x
   Tsang YK, 2011, NEUROSCI LETT, V487, P268, DOI 10.1016/j.neulet.2010.10.035
   Wang XY, 2017, SCI REP-UK, V7, P1, DOI 10.1038/srep43254
   Wostmann M, 2017, LANG COGN NEUROSCI, V32, P855, DOI 10.1080/23273798.2016.1262051
NR 62
TC 1
Z9 1
U1 0
U2 1
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD DEC
PY 2018
VL 121
BP 28
EP 36
DI 10.1016/j.neuropsychologia.2018.10.028
PG 9
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA HO3XG
UT WOS:000460855700004
PM 30391567
DA 2021-02-24
ER

PT J
AU Hambrook, DA
   Soni, S
   Tata, MS
AF Hambrook, Dillon A.
   Soni, Shweta
   Tata, Matthew S.
TI The effects of periodic interruptions on cortical entrainment to speech
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE EEG; Oscillations; Speech; Cortical entrainment; Phonemic restoration
ID SENSORY-PERCEPTUAL TRANSFORMATIONS; HEARING ILLUSORY SOUNDS; TEMPORAL
   FINE-STRUCTURE; FUNDAMENTAL-FREQUENCY; THETA OSCILLATIONS;
   EVOKED-RESPONSES; NEURAL MODEL; INTELLIGIBILITY; ENVELOPE; RESTORATION
AB Speech is perceived as a continuous stream of words despite consisting of a discontinuous, quasi-periodic signal of interleaved sounds and silences. Speech perception is surprisingly robust to interference by interruption, however speech that is replaced by gaps of silence is difficult to understand. When those silences are filled with noise, the speech is once again perceived as continuous even when the underlying speech sounds are removed completely. This is a phenomenon known as phonemic restoration. Perception of normal speech is accompanied by robust phase-locking of EEG signals to acoustic and linguistic features of speech. In this study we test the theory that interrupting speech with silence impairs perception by interfering with neural speech tracking. Further, we test the theory that we can restore perception and phase-tracking of the original acoustics by inserting noise in the interruptions. We find that disruptions of the acoustic envelope reduce the tracking of both acoustic and phonemic features. By inserting amplitude modulated noise such that the original broadband envelope is restored, we improved perception of the degraded speech and restored the magnitude of the speech tracking response; however, topographic analysis suggests that the neural response to noise-interrupted speech may recruit systematically different brain areas. The acoustic envelope seems to be an important physical component of speech that facilitates the dynamic neural mechanisms for perception of spoken language, particularly in adverse listening conditions.
C1 [Hambrook, Dillon A.; Soni, Shweta; Tata, Matthew S.] Univ Lethbridge, 4401 Univ Dr, Lethbridge, AB T1K 3M4, Canada.
RP Hambrook, DA (corresponding author), Univ Lethbridge, Dept Neurosci, 4401 Univ Dr, Lethbridge, AB T1K 3M4, Canada.
EM Dillon.hambrook@uleth.ca
FU National Sciences and Engineering Research Council of Canada
   (NSERC)Natural Sciences and Engineering Research Council of Canada
   (NSERC) [G2463]
FX This work was supported by the National Sciences and Engineering
   Research Council of Canada (NSERC) [Discovery grant number G2463].
CR [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   BASHFORD JA, 1992, PERCEPT PSYCHOPHYS, V51, P211, DOI 10.3758/BF03212247
   Bashford JA, 1996, PERCEPT PSYCHOPHYS, V58, P342, DOI 10.3758/BF03206810
   BASHFORD JA, 1987, PERCEPT PSYCHOPHYS, V42, P114, DOI 10.3758/BF03210499
   Baskent D, 2009, J ACOUST SOC AM, V125, P3995, DOI 10.1121/1.3125329
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bosker HR, 2018, LANG COGN NEUROSCI, V33, P955, DOI 10.1080/23273798.2018.1439179
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Brookes M, 2003, VOICEBOX SPEECH PROC
   Chait Maria, 2015, FRONTIERS NEUROSCIEN, V9, P1, DOI DOI 10.IMPS://D0I.0RG/10.3389/FNINS.2015.00214
   Chandrasekaran C, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000436
   Cogan GB, 2011, J NEUROPHYSIOL, V106, P554, DOI 10.1152/jn.00075.2011
   Cooke M, 2003, J PHONETICS, V31, P579, DOI 10.1016/S0095-4470(03)00013-5
   Cowan N, 2001, BEHAV BRAIN SCI, V24, P87, DOI 10.1017/S0140525X01003922
   Crosse MJ, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00604
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Di Liberto G. M, 2018, ENEURO, V2018, DOI [10.1523/ENEUR0.0084-18.2018, DOI 10.1523/ENEUR0.0084-18.2018]
   Di Liberto GM, 2018, NEUROIMAGE, V166, P247, DOI 10.1016/j.neuroimage.2017.10.066
   Di Liberto GM, 2017, HEARING RES, V348, P70, DOI 10.1016/j.heares.2017.02.015
   Di Liberto GM, 2015, CURR BIOL, V25, P2457, DOI 10.1016/j.cub.2015.08.030
   Ding N, 2012, P NATL ACAD SCI USA, V109, P11854, DOI 10.1073/pnas.1205381109
   Ding N, 2009, J NEUROPHYSIOL, V102, P2731, DOI 10.1152/jn.00523.2009
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Engel AK, 2001, NAT REV NEUROSCI, V2, P704, DOI 10.1038/35094565
   Fishbach A, 2001, J NEUROPHYSIOL, V85, P2303
   Fogerty D, 2013, J SPEECH LANG HEAR R, V56, P1402, DOI 10.1044/1092-4388(2013/12-0203)
   Fogerty D, 2012, J ACOUST SOC AM, V132, P1667, DOI 10.1121/1.4739463
   Fogerty D, 2012, J ACOUST SOC AM, V131, P1490, DOI 10.1121/1.3676696
   Fries P, 2005, TRENDS COGN SCI, V9, P474, DOI 10.1016/j.tics.2005.08.011
   Ghitza O, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00652
   Ghitza O, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00130
   Ghitza O, 2009, PHONETICA, V66, P113, DOI 10.1159/000208934
   Gilbert G, 2007, J ACOUST SOC AM, V122, P1336, DOI 10.1121/1.2756161
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   Grossberg S, 2011, J ACOUST SOC AM, V130, P440, DOI 10.1121/1.3589258
   Haegens S, 2018, NEUROSCI BIOBEHAV R, V86, P150, DOI 10.1016/j.neubiorev.2017.12.002
   Hambrook DA, 2014, BRAIN LANG, V135, P52, DOI 10.1016/j.bandl.2014.05.003
   Hertrich I, 2012, PSYCHOPHYSIOLOGY, V49, P322, DOI 10.1111/j.1469-8986.2011.01314.x
   Hickok G, 2015, PSYCHOL SCI, V26, P1006, DOI 10.1177/0956797615576533
   Holdgraf C. R, 2016, NAT COMMUN, V7, DOI [10.1038/ncomins13654, DOI 10.1038/NCOMINS13654]
   Howard MF, 2010, J NEUROPHYSIOL, V104, P2500, DOI 10.1152/jn.00251.2010
   HUGGINS AWF, 1975, PERCEPT PSYCHOPHYS, V18, P149, DOI 10.3758/BF03204103
   Ille N, 2002, J CLIN NEUROPHYSIOL, V19, P113, DOI 10.1097/00004691-200203000-00002
   Jin SH, 2010, J ACOUST SOC AM, V128, P881, DOI 10.1121/1.3458851
   Kaiser M, 2018, EUR J NEUROSCI, V48, P2849, DOI 10.1111/ejn.13861
   Kayser SJ, 2015, J NEUROSCI, V35, P14691, DOI 10.1523/JNEUROSCI.2243-15.2015
   Kerlin JR, 2010, J NEUROSCI, V30, P620, DOI 10.1523/JNEUROSCI.3631-09.2010
   Kong YY, 2015, J ACOUST SOC AM, V137, P2846, DOI 10.1121/1.4919337
   Leonard MK, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13619
   Leonard MK, 2015, J NEUROSCI, V35, P7203, DOI 10.1523/JNEUROSCI.4100-14.2015
   McCloy D, 2013, PN NC CORPUS VERSION
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Mesgarani N, 2012, NATURE, V485, P233, DOI 10.1038/nature11020
   MILLER GA, 1950, J ACOUST SOC AM, V22, P167, DOI 10.1121/1.1906584
   Murray MM, 2008, BRAIN TOPOGR, V20, P249, DOI 10.1007/s10548-008-0054-5
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Perez A, 2015, BRAIN LANG, V147, P51, DOI 10.1016/j.bandl.2015.05.008
   Petkov CI, 2007, NEURON, V54, P153, DOI 10.1016/j.neuron.2007.02.031
   Picton TW, 2000, PSYCHOPHYSIOLOGY, V37, P127, DOI 10.1111/1469-8986.3720127
   Poeppel D, 2003, SPEECH COMMUN, V41, P245, DOI 10.1016/S0167-6393(02)00107-3
   Riecke L, 2007, J NEUROSCI, V27, P12684, DOI 10.1523/JNEUROSCI.2713-07.2007
   Riecke L, 2015, BRAIN STIMUL, V8, P777, DOI 10.1016/j.brs.2015.04.004
   Riecke L, 2009, NEURON, V64, P550, DOI 10.1016/j.neuron.2009.10.016
   Samuel A, 1996, LANG COGNITIVE PROC, V11, P647, DOI 10.1080/016909696387051
   Schoof T, 2015, J ACOUST SOC AM, V138, pEL181, DOI 10.1121/1.4929627
   Schroeder CE, 2009, TRENDS NEUROSCI, V32, P9, DOI 10.1016/j.tins.2008.09.012
   Shahin AJ, 2009, NEUROIMAGE, V44, P1133, DOI 10.1016/j.neuroimage.2008.09.045
   SHANNON RV, 1995, SCIENCE, V270, P303, DOI 10.1126/science.270.5234.303
   Shinn-Cunningham BG, 2008, J ACOUST SOC AM, V123, P295, DOI 10.1121/1.2804701
   VAUGHAN HG, 1970, ELECTROEN CLIN NEURO, V28, P360, DOI 10.1016/0013-4694(70)90228-2
   Wang X, 2010, J ACOUST SOC AM, V128, P2100, DOI 10.1121/1.3483733
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Zoefel B, 2015, FRONT HUM NEUROSCI, V9, DOI [10.3389/fnhum.2015.00651, 10.1038/NATURE11020]
   Zoefel B, 2015, J NEUROSCI, V35, P1954, DOI 10.1523/JNEUROSCI.3484-14.2015
NR 77
TC 0
Z9 0
U1 0
U2 1
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD DEC
PY 2018
VL 121
BP 58
EP 68
DI 10.1016/j.neuropsychologia.2018.10.019
PG 11
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA HO3XG
UT WOS:000460855700007
PM 30385119
DA 2021-02-24
ER

PT J
AU Ripamonti, E
   Frustaci, M
   Zonca, G
   Aggujaro, S
   Molteni, F
   Luzzatti, C
AF Ripamonti, Enrico
   Frustaci, Mirella
   Zonca, Giuseppina
   Aggujaro, Silvia
   Molteni, Franco
   Luzzatti, Claudio
TI Disentangling phonological and articulatory processing: A
   neuroanatomical study in aphasia
SO NEUROPSYCHOLOGIA
LA English
DT Article
DE Phonological impairment; Apraxia of speech; Articulatory programming;
   Insula; Broca's area; Superior temporal gyrus; Subtraction; Voxel-based
   lesion-symptom mapping; Seed-to-voxel connectivity
ID SUPERIOR TEMPORAL GYRUS; SPEECH-PERCEPTION; FUNCTIONAL CONNECTIVITY;
   PURE ANARTHRIA; WORKING-MEMORY; APRAXIA; FMRI; RESPONSES; REGIONS;
   SOUNDS
AB Phonological and articulatory programming impairments may co-occur in aphasic patients and previous research does not offer a clear-cut picture of their anatomical counterparts. Hickok and Poeppel (2007) put forward a seminal model of speech processes. The ventral stream (mostly bilateral) would be involved in speech recognition and phonological:lexical processing, whereas the dorsal stream (largely lateralized to the left hemisphere) would map phonological representations onto articulatory motor patterns. In this study we analyzed repetition errors for single words and spontaneous speech ratings on the Italian version of the Aachen Aphasia Test. Through a VLSM procedure we aimed at discriminating the neuroanatomical substrates of the phonological and articulatory impairment (and of their normal functional processing). We also estimated functional connectivity networks related to articulation and phonology using seed-to-voxel connectivity analysis with resting state fMRI data. Results indicate that repetition deficit of single words is associated with lesions in a network of left perisylvian areas including the central operculum, the Heschl's gyrus, the angular gyrus, and the supramarginal gyrus (posterior part). Articulatory impairment is associated with lesions in a number of areas in the left dorsal stream, such as the insula (anterior portion), the pars opercularis of the inferior frontal gyrus, the central operculum and the precentral gyms. On the contrary, phonological impairment is underpinned by lesions of the Heschl's gyms, and of the posterion portion of the superior temporal and supramarginal gyri. Anatomoclinical correlative results partly support Hickok and Poeppel's functional model of phonological and articulatory processing.
C1 [Ripamonti, Enrico] IRCCS Fdn Don Carlo Gnocchi, Via Alfonso Capecelatro 66, I-20148 Milan, Italy.
   [Frustaci, Mirella] ASST Rhodense, Milan, Italy.
   [Zonca, Giuseppina] IRCCS Montescano, Ist Clin Sci Maugeri Spa Soc Benefit, Pavia, Italy.
   [Aggujaro, Silvia; Molteni, Franco] Osped Valduce, Ctr Villa Beretta, Unita Operat Complessa Med Riabilitat, Costamasnaga, Lecco, Italy.
   [Luzzatti, Claudio] Univ Milano Bicocca, Dipartimento Psicol, Milan, Italy.
   [Luzzatti, Claudio] Ctr Neurosci Milano, Milan, Italy.
RP Ripamonti, E (corresponding author), IRCCS Fdn Don Carlo Gnocchi, Via Alfonso Capecelatro 66, I-20148 Milan, Italy.
EM enrico.ripamonti@unimib.it
OI LUZZATTI, CLAUDIO GIUSEPPE/0000-0001-6334-6293; Ripamonti,
   Enrico/0000-0002-0584-8401
FU Center for Brain Science Neuroinformatics Research Group; Athinoula A.
   Martinos Center for Biomedical Imaging; Center for Human Genetic
   Research
FX Data for resting state fMRI were provided by the Brain Genomics
   Superstruct Project of Harvard University and Massachussets General
   Hospital, MGH (Principal Investigators: Randy Buckner, Joshua Roffman,
   and Jordan SmoIler), with support from the Center for Brain Science
   Neuroinformatics Research Group, the Athinoula A. Martinos Center for
   Biomedical Imaging, and the Center for Human Genetic Research. Twenty
   individual investigators at Harvard and MGH generously contributed data
   to the overall project. We are grateful to Otto Karnath, Cristoph
   Sperber, Klaus Willmes, and two anonymous reviewers for their valuable
   remarks on a first draft of this paper. A preliminary version of the
   study has been presented during the 35th European Workshop on Cognitive
   Neuropsychology. Bressanone, January 22-27, 2017.
CR Ackermann H, 2004, BRAIN LANG, V89, P320, DOI 10.1016/S0093-934X(03)00347-X
   Agnew ZK, 2011, J COGNITIVE NEUROSCI, V23, P4038, DOI 10.1162/jocn_a_00106
   Alajouanine T., 1939, SYNDROME DESINTEGRAT
   Anderson JM, 1999, BRAIN LANG, V70, P1, DOI 10.1006/brln.1999.2135
   Baldo JV, 2011, CORTEX, V47, P800, DOI 10.1016/j.cortex.2010.07.001
   Basilakos A, 2015, STROKE, V46, P1561, DOI 10.1161/STROKEAHA.115.009211
   Bates E, 2003, NAT NEUROSCI, V6, P448, DOI 10.1038/nn1050
   Benjamin DJ, 2018, NAT HUM BEHAV, V2, P6, DOI 10.1038/s41562-017-0189-z
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Benson RR, 2006, NEUROIMAGE, V31, P342, DOI 10.1016/j.neuroimage.2005.11.029
   BERNDT RS, 1980, APPL PSYCHOLINGUIST, V1, P225, DOI 10.1017/S0142716400000552
   Binder JR, 2000, CEREB CORTEX, V10, P512, DOI 10.1093/cercor/10.5.512
   BISWAL B, 1995, MAGNET RESON MED, V34, P537, DOI 10.1002/mrm.1910340409
   Boes AD, 2015, BRAIN, V138, P3061, DOI 10.1093/brain/awv228
   Broca P., 1861, B SOC ANAT PARIS, V6, P330, DOI DOI 10.1093/ACPROF:OSO/9780195177640.003.0018
   BROWMAN CP, 1992, PHONETICA, V49, P155, DOI 10.1159/000261913
   Brunner E, 2000, BIOMETRICAL J, V42, P17, DOI 10.1002/(SICI)1521-4036(200001)42:1<17::AID-BIMJ17>3.0.CO;2-U
   Buchsbaum BR, 2001, COGNITIVE SCI, V25, P663, DOI 10.1207/s15516709cog2505_2
   Buckingham H. W., 1981, JARGONAPHASIA, P39
   Buckingham HW, 2008, HANDBOOK OF THE NEUROSCIENCE OF LANGUAGE, P127
   Buckner RL, BRAIN GENOMICS SUEPR, DOI [10.7910/DVN/25833, DOI 10.7910/DVN/25833]
   Burton MW, 2000, J COGNITIVE NEUROSCI, V12, P679, DOI 10.1162/089892900562309
   CANTER GJ, 1988, APHASIOLOGY, V2, P251, DOI 10.1080/02687038808248919
   Caplan DN, 2003, CLIN NEUROPSYCHOLOGY, P14
   Code C, 1998, CLIN LINGUIST PHONET, V12, P47, DOI 10.3109/02699209808985212
   DAMASIO H, 1980, BRAIN, V103, P337, DOI 10.1093/brain/103.2.337
   de Haan B, 2018, NEUROPSYCHOLOGIA, V115, P5, DOI 10.1016/j.neuropsychologia.2017.10.021
   Dehaene-Lambertz G, 2005, NEUROIMAGE, V24, P21, DOI 10.1016/j.neuroimage.2004.09.039
   Dell GS, 2013, COGNITION, V128, P380, DOI 10.1016/j.cognition.2013.05.007
   Dick F, 2011, CEREB CORTEX, V21, P938, DOI 10.1093/cercor/bhq166
   Dronkers N, 2004, BRAIN, V127, P1461, DOI 10.1093/brain/awh233
   Dronkers NF, 1996, NATURE, V384, P159, DOI 10.1038/384159a0
   Fox MD, 2007, NAT REV NEUROSCI, V8, P700, DOI 10.1038/nrn2201
   Fox MD, 2012, BIOL PSYCHIAT, V72, P595, DOI 10.1016/j.biopsych.2012.04.028
   Fridriksson J, 2018, BRAIN, V141, P848, DOI 10.1093/brain/awx363
   Friston KJ, 2011, BRAIN CONNECT, V1, P13, DOI 10.1089/brain.2011.0008
   Garrett M. F., 1982, NORMALITY PATHOLOGY, P19
   Genovese CR, 2002, NEUROIMAGE, V15, P870, DOI 10.1006/nimg.2001.1037
   Giraud AL, 2004, CEREB CORTEX, V14, P247, DOI 10.1093/cercor/bhg124
   Goldstein JM, 2007, BIOL PSYCHIAT, V61, P935, DOI 10.1016/j.biopsych.2006.06.027
   Goodglass H., 1972, BOSTON DIAGNOSTIC AP
   Harley T. A., 2013, PSYCHOL LANGUAGE DAT
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2003, J COGNITIVE NEUROSCI, V15, P673, DOI 10.1162/089892903322307393
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2014, LANG COGN NEUROSCI, V29, P2, DOI 10.1080/01690965.2013.834370
   Hickok G, 2012, NAT REV NEUROSCI, V13, P135, DOI 10.1038/nrn3158
   Hillis AE, 2004, BRAIN, V127, P1479, DOI 10.1093/brain/awh172
   Holmes AJ, 2015, SCI DATA, V2, DOI 10.1038/sdata.2015.31
   Holmes CJ, 1998, J COMPUT ASSIST TOMO, V22, P324, DOI 10.1097/00004728-199803000-00032
   Huber W., 1983, AACHENER APHASIC TES
   Hugdahl K, 2003, BRAIN LANG, V85, P37, DOI 10.1016/S0093-934X(02)00500-X
   Indefrey P, 2004, COGNITION, V92, P101, DOI 10.1016/j.cognition.2002.06.001
   Joanisse MF, 2003, NEUROIMAGE, V19, P64, DOI 10.1016/S1053-8119(03)00046-6
   JOHNS DF, 1970, J SPEECH HEAR RES, V13, P556, DOI 10.1044/jshr.1303.556
   Karnath HO, 2018, NEUROIMAGE, V165, P180, DOI 10.1016/j.neuroimage.2017.10.028
   KUSHNER M, 1987, BRAIN LANG, V31, P201, DOI 10.1016/0093-934X(87)90070-8
   LAPOINTE LL, 1975, J COMMUN DISORD, V8, P259, DOI 10.1016/0021-9924(75)90018-0
   Leaver AM, 2010, J NEUROSCI, V30, P7604, DOI 10.1523/JNEUROSCI.0296-10.2010
   LECOURS AR, 1976, BRAIN LANG, V3, P88, DOI 10.1016/0093-934X(76)90008-0
   Leech R, 2009, J NEUROSCI, V29, P5234, DOI 10.1523/JNEUROSCI.5758-08.2009
   Leff AP, 2009, CORTEX, V45, P517, DOI 10.1016/j.cortex.2007.10.008
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1
   Lichtheim L., 1885, BRAIN, V7, P433, DOI DOI 10.1093/BRAIN/7.4.433
   Liebenthal E, 2005, CEREB CORTEX, V15, P1621, DOI 10.1093/cercor/bhi040
   Liebenthal E, 2010, CEREB CORTEX, V20, P2958, DOI 10.1093/cercor/bhq045
   Liepmann H, 1900, MON PSYCHIATR NEUROL, V8, P15
   Luzzatti C., 1996, AACHENER APHASICTEST
   Margulis EH, 2009, HUM BRAIN MAPP, V30, P267, DOI 10.1002/hbm.20503
   Marie P, 1906, SEM MED, V26, P241
   McGuire PK, 1996, BRAIN, V119, P907, DOI 10.1093/brain/119.3.907
   Medina J, 2010, NEUROPSYCHOLOGIA, V48, P341, DOI 10.1016/j.neuropsychologia.2009.09.016
   Milchenko M, 2013, NEUROINFORMATICS, V11, P65, DOI 10.1007/s12021-012-9160-3
   Mirman D, 2018, NEUROPSYCHOLOGIA, V115, P112, DOI 10.1016/j.neuropsychologia.2017.08.025
   Mummery CJ, 1999, J ACOUST SOC AM, V106, P449, DOI 10.1121/1.427068
   NAESER MA, 1978, NEUROLOGY, V28, P545, DOI 10.1212/WNL.28.6.545
   Narain C, 2003, CEREB CORTEX, V13, P1362, DOI 10.1093/cercor/bhg083
   Oishi K., 2011, MRI ATLAS HUMAN WHIT
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Papathanassiou D, 2000, NEUROIMAGE, V11, P347, DOI 10.1006/nimg.2000.0546
   Patterson K, 1987, COGNITIVE NEUROPSYCH, P273
   Pillay SB, 2017, NEUROLOGY, V88, P970, DOI 10.1212/WNL.0000000000003683
   Poldrack RA, 1999, NEUROIMAGE, V10, P15, DOI 10.1006/nimg.1999.0441
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Price CJ, 1996, BRAIN, V119, P919, DOI 10.1093/brain/119.3.919
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Richardson JD, 2012, BRAIN LANG, V123, P125, DOI 10.1016/j.bandl.2012.08.007
   Rimol LM, 2005, NEUROIMAGE, V26, P1059, DOI 10.1016/j.neuroimage.2005.03.028
   Rorden C, 2000, BEHAV NEUROL, V12, P191, DOI 10.1155/2000/421719
   Rorden C, 2007, J COGNITIVE NEUROSCI, V19, P1081, DOI 10.1162/jocn.2007.19.7.1081
   SCHIFF HB, 1983, ARCH NEUROL-CHICAGO, V40, P720, DOI 10.1001/archneur.1983.04050110038005
   Smith EE, 1998, P NATL ACAD SCI USA, V95, P876, DOI 10.1073/pnas.95.3.876
   Specht K, 2009, HUM BRAIN MAPP, V30, P3436, DOI 10.1002/hbm.20768
   Sperber C, 2018, NEUROPSYCHOLOGIA, V115, P17, DOI 10.1016/j.neuropsychologia.2017.07.035
   Tanji K, 2001, CORTEX, V37, P671, DOI 10.1016/S0010-9452(08)70613-0
   Vouloumanos A, 2001, J COGNITIVE NEUROSCI, V13, P994, DOI 10.1162/089892901753165890
   Wasserstein RL, 2016, AM STAT, V70, P129, DOI 10.1080/00031305.2016.1154108
   Wernicke C., 1977, WERNICKES WORKS APHA
   Whitfield-Gabrieli S, 2012, BRAIN CONNECT, V2, P125, DOI 10.1089/brain.2012.0073
   Wise RJS, 1999, LANCET, V353, P1057, DOI 10.1016/S0140-6736(98)07491-1
   Ziegler Wolfram, 2008, Handb Clin Neurol, V88, P269, DOI 10.1016/S0072-9752(07)88013-4
NR 101
TC 4
Z9 5
U1 3
U2 6
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0028-3932
EI 1873-3514
J9 NEUROPSYCHOLOGIA
JI Neuropsychologia
PD DEC
PY 2018
VL 121
BP 175
EP 185
DI 10.1016/j.neuropsychologia.2018.10.015
PG 11
WC Behavioral Sciences; Neurosciences; Psychology, Experimental
SC Behavioral Sciences; Neurosciences & Neurology; Psychology
GA HO3XG
UT WOS:000460855700018
PM 30367847
DA 2021-02-24
ER

PT J
AU Choi, D
   Black, AK
   Werker, JF
AF Choi, Dawoon
   Black, Alexis K.
   Werker, Janet F.
TI Cascading and Multisensory Influences on Speech Perception Development
SO MIND BRAIN AND EDUCATION
LA English
DT Article
ID VISUAL LANGUAGE DISCRIMINATION; NATIVE LANGUAGE; DIRECTED SPEECH;
   PHONOLOGICAL AWARENESS; PHONETIC INFORMATION; NEONATES PREFERENCE; WORD
   RECOGNITION; HEARING LIPS; 1ST YEAR; INFANTS
AB Over the first weeks and months following birth, infants' initial, broad-based perceptual sensitivities become honed to the characteristics of their native language. In this article, we review this process of emerging specialization within the context of a cascading "critical period" (CP) framework, in which periods of maximal openness to experience of different aspects of language occur at sequential, overlapping points in development. Importantly, as infants' experience of speech is not limited to auditory signals, but is informed by-for example-their experience of talking faces and their own oral motor movements, we review the trajectory of perceptual specialization in multisensory language processing. Throughout, we highlight the impact of increasing perceptual specialization on later language outcomes (e.g., word learning, foundations of syntax, literacy), and consider how the outcomes can be compromised if/when the timing of perceptual specialization has been perturbed.
C1 [Choi, Dawoon; Black, Alexis K.; Werker, Janet F.] Univ British Columbia, Vancouver, BC, Canada.
RP Werker, JF (corresponding author), Univ British Columbia, Dept Psychol, 2136 West Mall, Vancouver, BC V6T 1Z4, Canada.
EM jwerker@psych.ubc.ca
OI Black, Alexis/0000-0001-6764-4319; Werker, Janet F./0000-0002-1168-9013
FU NSERCNatural Sciences and Engineering Research Council of Canada (NSERC)
   [RGPIN-2015-03967]; SSHRCSocial Sciences and Humanities Research Council
   of Canada (SSHRC) [435-2014-0917]; Canadian Institute for Advanced
   ResearchCanadian Institute for Advanced Research (CIFAR)
FX Preparation of this article, and much of the research by JFW described
   therein, was supported by Grants from NSERC (RGPIN-2015-03967), SSHRC
   (435-2014-0917), and the Canadian Institute for Advanced Research.
   Special thanks to Savannah Nijeboer for editing the manuscript and
   creating the figure.
CR Anthony JL, 2005, CURR DIR PSYCHOL SCI, V14, P255, DOI 10.1111/j.0963-7214.2005.00376.x
   Baker SA, 2005, MEM COGNITION, V33, P887, DOI 10.3758/BF03193083
   Baker SA, 2006, LANG LEARN DEV, V2, P147, DOI 10.1207/s15473341lld0203_1
   Bavelier D, 2002, NAT REV NEUROSCI, V3, P443, DOI 10.1038/nrn848
   Bernard C, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00451
   Bernhardt B. M., 2007, FIRST LANG, V27, P315, DOI DOI 10.1177/0142723707081652
   Best CC, 2003, LANG SPEECH, V46, P183, DOI 10.1177/00238309030460020701
   Bolhuis JJ, 2010, NAT REV NEUROSCI, V11, P747, DOI 10.1038/nrn2931
   Bosseler AN, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162177
   Brainard MS, 2002, NATURE, V417, P351, DOI 10.1038/417351a
   Brent MR, 1996, COGNITION, V61, P93, DOI 10.1016/S0010-0277(96)00719-6
   Bristow D, 2009, J COGNITIVE NEUROSCI, V21, P905, DOI 10.1162/jocn.2009.21076
   Bruderer AG, 2015, P NATL ACAD SCI USA, V112, P13531, DOI 10.1073/pnas.1508631112
   Chang EF, 2003, SCIENCE, V300, P498, DOI 10.1126/science.1082163
   Ching TYC, 2017, PEDIATRICS, V140, DOI 10.1542/peds.2016-4274
   Choi JY, 2017, P NATL ACAD SCI USA, V114, P7307, DOI 10.1073/pnas.1706405114
   Choi J, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.160660
   Christophe A, 1997, LANG COGNITIVE PROC, V12, P585, DOI 10.1080/016909697386637
   Cristia A, 2014, CHILD DEV, V85, P1330, DOI 10.1111/cdev.12193
   Cristia A, 2011, PROC ANN BUCLD, P145
   Danielson DK, 2017, COGNITIVE DEV, V42, P37, DOI 10.1016/j.cogdev.2017.02.004
   DECASPER AJ, 1980, SCIENCE, V208, P1174, DOI 10.1126/science.7375928
   DECASPER AJ, 1986, INFANT BEHAV DEV, V9, P133, DOI 10.1016/0163-6383(86)90025-1
   Dehaene-Lambertz G, 2006, P NATL ACAD SCI USA, V103, P14240, DOI 10.1073/pnas.0606302103
   Dietrich C, 2007, P NATL ACAD SCI USA, V104, P16027, DOI 10.1073/pnas.0705270104
   Doupe AJ, 1999, ANNU REV NEUROSCI, V22, P567, DOI 10.1146/annurev.neuro.22.1.567
   Elsabbagh M, 2013, BEHAV SCI-BASEL, V3, P120, DOI 10.3390/bs3010120
   Fausey CM, 2016, COGNITION, V152, P101, DOI 10.1016/j.cognition.2016.03.005
   FENG AS, 1980, BRAIN RES, V189, P530, DOI 10.1016/0006-8993(80)90112-2
   Fennell CT, 2007, CHILD DEV, V78, P1510, DOI 10.1111/j.1467-8624.2007.01080.x
   Fisher SE, 2009, TRENDS GENET, V25, P166, DOI 10.1016/j.tig.2009.03.002
   Floccia C, 2016, COGNITION, V148, P1, DOI 10.1016/j.cognition.2015.12.004
   Frost R, 1998, PSYCHOL BULL, V123, P71, DOI 10.1037/0033-2909.123.1.71
   Gerhardt KJ, 1996, SEMIN PERINATOL, V20, P11, DOI 10.1016/S0146-0005(96)80053-X
   Gervain J, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2430
   Goldstein MH, 2003, P NATL ACAD SCI USA, V100, P8030, DOI 10.1073/pnas.1332441100
   Goldstein MH, 2008, PSYCHOL SCI, V19, P515, DOI 10.1111/j.1467-9280.2008.02117.x
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   GREENOUGH WT, 1987, CHILD DEV, V58, P539, DOI 10.2307/1130197
   Haesler S, 2007, PLOS BIOL, V5, P2885, DOI 10.1371/journal.pbio.0050321
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hoff Erika, 2013, LANGUAGE DEV
   HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085
   Hyltenstam K, 2009, BILING-LANG COGN, V12, P121, DOI 10.1017/S1366728908004008
   Jarvis ED, 2004, ANN NY ACAD SCI, V1016, P749, DOI 10.1196/annals.1298.038
   Junge C, 2012, DEVELOPMENTAL SCI, V15, P463, DOI 10.1111/j.1467-7687.2012.1144.x
   Kemp N, 2017, APPL PSYCHOLINGUIST, V38, P289, DOI 10.1017/S0142716416000199
   Kisilevsky BS, 2003, PSYCHOL SCI, V14, P220, DOI 10.1111/1467-9280.02435
   Krentz UC, 2008, DEVELOPMENTAL SCI, V11, P1, DOI 10.1111/j.1467-7687.2007.00652.x
   Kuhl PK, 2014, P NATL ACAD SCI USA, V111, P11238, DOI 10.1073/pnas.1410963111
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   LECANUET JP, 1987, CR ACAD SCI III-VIE, V305, P161
   Lee GY, 2014, DEV PSYCHOBIOL, V56, P1, DOI 10.1002/dev.21084
   Leroy F, 2011, J NEUROSCI, V31, P1500, DOI 10.1523/JNEUROSCI.4141-10.2011
   Lesnick J., 2010, READING GRADE LEVEL
   Levine D, 2016, OTOL NEUROTOL, V37, pE56, DOI 10.1097/MAO.0000000000000908
   Liu HM, 2003, DEVELOPMENTAL SCI, V6, pF1, DOI 10.1111/1467-7687.00275
   Marchman VA, 2008, DEVELOPMENTAL SCI, V11, pF9, DOI 10.1111/j.1467-7687.2008.00671.x
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   May L., 2017, DEVELOPMENTAL SCI
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McNeill BC, 2009, INT J LANG COMM DIS, V44, P175, DOI 10.1080/13682820801997353
   Merabet L. B., 2012, NATURE REV NEUROSCIE, V11, P44
   Molfese DL, 2000, BRAIN LANG, V72, P238, DOI 10.1006/brln.2000.2287
   MOON C, 1993, INFANT BEHAV DEV, V16, P495, DOI 10.1016/0163-6383(93)80007-U
   Moon C, 2013, ACTA PAEDIATR, V102, P156, DOI 10.1111/apa.12098
   Morgan J. L., 1986, SIMPLE INPUT COMPLEX
   Munhall K.G., 2004, HDB MULTISENSORY PRO, P177
   NARAYAN C, 2009, DEVELOPMENTAL SCI, V13, P407, DOI DOI 10.1111/J.1467-7687.2009.00898.X
   Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037/0096-1523.24.3.756
   Newman RS, 2016, J CHILD LANG, V43, P1158, DOI 10.1017/S0305000915000446
   Oh JS, 2010, J CHILD LANG, V37, P1123, DOI 10.1017/S0305000909990286
   Okada K, 2009, NEUROSCI LETT, V452, P219, DOI 10.1016/j.neulet.2009.01.060
   Pallier C, 2003, CEREB CORTEX, V13, P155, DOI 10.1093/cercor/13.2.155
   Palmer SB, 2012, CHILD DEV, V83, P543, DOI 10.1111/j.1467-8624.2011.01715.x
   Partanen E, 2013, P NATL ACAD SCI USA, V110, P15145, DOI 10.1073/pnas.1302159110
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Patterson ML, 1999, INFANT BEHAV DEV, V22, P237, DOI 10.1016/S0163-6383(99)00003-X
   Pena M, 2003, P NATL ACAD SCI USA, V100, P11702, DOI 10.1073/pnas.1934290100
   Pena M, 2012, J NEUROSCI, V32, P11159, DOI 10.1523/JNEUROSCI.6516-11.2012
   Perani D, 2011, P NATL ACAD SCI USA, V108, P16056, DOI 10.1073/pnas.1102991108
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Ramus F, 2008, Q J EXP PSYCHOL, V61, P129, DOI 10.1080/17470210701508822
   Rosenblum LD, 1996, J EXP PSYCHOL HUMAN, V22, P318, DOI 10.1037/0096-1523.22.2.318
   Sams M, 2005, COGNITIVE BRAIN RES, V23, P429, DOI 10.1016/j.cogbrainres.2004.11.006
   Scott M, 2013, J ACOUST SOC AM, V133, pEL286, DOI 10.1121/1.4794932
   Sebastian-Galles N, 2012, PSYCHOL SCI, V23, P994, DOI 10.1177/0956797612436817
   Selkirk Elisabeth O., 2011, HDB PHONOLOGICAL THE, P550, DOI [DOI 10.1002/9781444343069.CH14, 10.1002/9781444343069.ch14]
   SHAHIDULLAH S, 1994, EARLY HUM DEV, V36, P13, DOI 10.1016/0378-3782(94)90029-9
   Shi RS, 2001, PSYCHOL SCI, V12, P70, DOI 10.1111/1467-9280.00312
   Shi RS, 1999, COGNITION, V72, pB11, DOI 10.1016/S0010-0277(99)00047-5
   Shu H., 2007, DEVELOPMENTAL SCI, V11, P171
   Shultz S, 2014, DEVELOPMENTAL SCI, V17, P766, DOI 10.1111/desc.12151
   Simpson KL, 2011, P NATL ACAD SCI USA, V108, P18465, DOI 10.1073/pnas.1109353108
   Singh L, 2012, DEVELOPMENTAL SCI, V15, P482, DOI 10.1111/j.1467-7687.2012.01141.x
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Snowling M., 2000, DYSLEXIA
   Song S, 2016, SCI STUD READ, V20, P99, DOI 10.1080/10888438.2015.1088543
   STREETER LA, 1976, NATURE, V259, P39, DOI 10.1038/259039a0
   Sugden NA, 2014, DEV PSYCHOBIOL, V56, P249, DOI 10.1002/dev.21183
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Swingley D, 2009, PHILOS T R SOC B, V364, P3617, DOI 10.1098/rstb.2009.0107
   Takesian AE, 2013, PROG BRAIN RES, V207, P3, DOI 10.1016/B978-0-444-63327-9.00001-1
   Thiessen ED, 2005, INFANCY, V7, P53, DOI 10.1207/s15327078in0701_5
   TREHUB SE, 1976, CHILD DEV, V47, P466, DOI 10.2307/1128803
   Truckenbrodt H, 1999, LINGUIST INQ, V30, P219, DOI 10.1162/002438999554048
   Tsao FM, 2004, CHILD DEV, V75, P1067, DOI 10.1111/j.1467-8624.2004.00726.x
   van Wassenhove V, 2005, P NATL ACAD SCI USA, V102, P1181, DOI 10.1073/pnas.0408949102
   Vouloumanos A, 2007, DEVELOPMENTAL SCI, V10, P159, DOI 10.1111/j.1467-7687.2007.00549.x
   Vouloumanos A, 2007, DEVELOPMENTAL SCI, V10, P169, DOI 10.1111/j.1467-7687.2007.00551.x
   Vouloumanos A, 2010, CHILD DEV, V81, P517, DOI 10.1111/j.1467-8624.2009.01412.x
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   Weikum WM, 2012, P NATL ACAD SCI USA, V109, P17221, DOI 10.1073/pnas.1121263109
   Werker J. F., APPL PSYCHOLINGUISTI
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2015, ANNU REV PSYCHOL, V66, P173, DOI 10.1146/annurev-psych-010814-015104
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Yeung HH, 2013, PSYCHOL SCI, V24, P603, DOI 10.1177/0956797612458802
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
   Zhang LI, 2001, NAT NEUROSCI, V4, P1123, DOI 10.1038/nn745
   Ziegler JC, 2005, PSYCHOL BULL, V131, P3, DOI 10.1037/0033-2909.131.1.3
NR 123
TC 5
Z9 5
U1 1
U2 10
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1751-2271
EI 1751-228X
J9 MIND BRAIN EDUC
JI Mind Brain Educ.
PD DEC
PY 2018
VL 12
IS 4
SI SI
BP 212
EP 223
DI 10.1111/mbe.12162
PG 12
WC Education & Educational Research; Psychology, Developmental
SC Education & Educational Research; Psychology
GA HL2XW
UT WOS:000458574300006
DA 2021-02-24
ER

PT J
AU Case, J
   Seyfarth, S
   Levi, SV
AF Case, Julie
   Seyfarth, Scott
   Levi, Susannah V.
TI Short-term implicit voice-learning leads to a Familiar Talker Advantage:
   The role of encoding specificity
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SPEECH-PERCEPTION; RECOGNITION; ADAPTATION; CONTEXT
AB Whereas previous research has found that a Familiar Talker Advantage-better spoken language perception for familiar voices-occurs following explicit voice-learning, Case, Seyfarth, and Levi [(2018). J. Speech, Lang., Hear. Res. 61(5), 1251-1260] failed to find this effect after implicit voice-learning. To test whether the advantage is limited to explicit voice-learning, a follow-up experiment evaluated implicit voice-learning under more similar encoding (training) and retrieval (test) conditions. Sentence recognition in noise improved significantly more for familiar than unfamiliar talkers, suggesting that short-term implicit voice-learning can lead to a Familiar Talker Advantage. This paper explores how similarity in encoding and retrieval conditions might affect the acquired processing advantage. (C) 2018 Acoustical Society of America
C1 [Case, Julie; Levi, Susannah V.] NYU, Dept Commun Sci & Disorders, 665 Broadway,9th Floor, New York, NY 10012 USA.
   [Seyfarth, Scott] Ohio State Univ, Dept Linguist, 1712 Neil Ave,Oxley Hall, Columbus, OH 43210 USA.
RP Case, J (corresponding author), NYU, Dept Commun Sci & Disorders, 665 Broadway,9th Floor, New York, NY 10012 USA.
EM julie.case@nyu.edu; seyfarth.2@osu.edu; svlevi@nyu.edu
OI Levi, Susannah/0000-0002-3115-8981
FU NIH-NIDCDUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [1R03DC009851]; NATIONAL INSTITUTE
   ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R03DC009851, R03DC009851, R03DC009851] Funding Source: NIH RePORTER
FX This work was supported in part by a grant from the NIH-NIDCD, Grant No.
   1R03DC009851 (S.V.L.). We would like to thank Gabrielle Alfano,
   Stephanie Lee, Maddy Lippman, Rebecca Piper, and Ashley Quinto for help
   with data collection and the children and families for their
   participation. Portions of this work were presented at the American
   Speech Language and Hearing Annual Convention (2016) and at the
   Symposium on Research in Child Language Disorders (2017).
CR Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Benki JR, 2003, J ACOUST SOC AM, V113, P1689, DOI 10.1121/1.1534102
   Bent T, 2009, J ACOUST SOC AM, V126, P2660, DOI 10.1121/1.3212930
   Bradlow AR, 2008, COGNITION, V106, P707, DOI 10.1016/j.cognition.2007.04.005
   Case J, 2018, J SPEECH LANG HEAR R, V61, P1251, DOI 10.1044/2018_JSLHR-L-17-0298
   Felty R. A., 2007, THESIS
   Johnsrude IS, 2013, PSYCHOL SCI, V24, P1995, DOI 10.1177/0956797613482467
   Kreitewolf J, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01584
   Lenth R, 2018, EMMEANS ESTIMATED MA EMMEANS ESTIMATED MA EMMEANS ESTIMATED MA EMMEANS ESTIMATED MA EMMEANS ESTIMATED MA EMMEANS ESTIMATED MA EMMEANS ESTIMATED MA EMMEANS ESTIMATED MA EMMEANS ESTIMATED MA EMMEANS ESTIMATED MA EMMEANS ESTIMATED MA EMMEANS ESTIMATED MA
   Levi SV, 2015, J CHILD LANG, V42, P843, DOI 10.1017/S0305000914000506
   Levi SV, 2011, J ACOUST SOC AM, V130, P4053, DOI 10.1121/1.3651816
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   R Core Team, 2016, R LANG ENV STAT COMP
   Reinisch E, 2014, J PHONETICS, V45, P91, DOI 10.1016/j.wocn.2014.04.002
   Schneider W., 2007, E PRIME 2 0 PROFESSI
   Semel E. M., 2003, CLIN EVALUATION LANG
   Souza P, 2013, J AM ACAD AUDIOL, V24, P689, DOI 10.3766/jaaa.24.8.6
   Stelmachowicz PG, 2000, J SPEECH LANG HEAR R, V43, P902, DOI 10.1044/jslhr.4304.902
   TULVING E, 1973, PSYCHOL REV, V80, P352, DOI 10.1037/h0020071
   Van Engen KJ, 2012, LANG COGNITIVE PROC, V27, P1089, DOI 10.1080/01690965.2012.654644
   Yonan CA, 2000, PSYCHOL AGING, V15, P88, DOI 10.1037/0882-7974.15.1.88
NR 22
TC 2
Z9 2
U1 0
U2 5
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD DEC
PY 2018
VL 144
IS 6
BP EL497
EP EL502
DI 10.1121/1.5081469
PG 6
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA HG0HV
UT WOS:000454625000003
PM 30599692
OA Green Published, Bronze
DA 2021-02-24
ER

PT J
AU Torppa, R
   Faulkner, A
   Kujala, T
   Huotilainen, M
   Lipsanen, J
AF Torppa, Ritva
   Faulkner, Andrew
   Kujala, Teija
   Huotilainen, Minna
   Lipsanen, Jari
TI DEVELOPMENTAL LINKS BETWEEN SPEECH PERCEPTION IN NOISE, SINGING, AND
   CORTICAL PROCESSING OF MUSIC IN CHILDREN WITH COCHLEAR IMPLANTS
SO MUSIC PERCEPTION
LA English
DT Article
DE ERP; MMN and P3a; informal singing and music instrument playing;
   perception of speech in noise; attention
ID SCHOOL-AGE-CHILDREN; MISMATCH NEGATIVITY; WORD RECOGNITION;
   AUDITORY-SYSTEM; DEAF-CHILDREN; HEARING; ATTENTION; SOUNDS; INVOLUNTARY;
   INFANTS
AB THE PERCEPTION OF SPEECH IN NOISE IS challenging for children with cochlear implants (CIs). Singing and musical instrument playing have been associated with improved auditory skills in normal-hearing (NH) children. Therefore, we assessed how children with CIs who sing informally develop in the perception of speech in noise compared to those who do not. We also sought evidence of links of speech perception in noise with MMN and P3a brain responses to musical sounds and studied effects of age and changes over a 14-17 month time period in the speech-in-noise performance of children with CIs. Compared to the NH group, the entire CI group was less tolerant of noise in speech perception, but both groups improved similarly. The CI singing group showed better speech-in-noise perception than the CI non-singing group. The perception of speech in noise in children with CIs was associated with the amplitude of MMN to a change of sound from piano to cymbal, and in the CI singing group only, with earlier P3a for changes in timbre. While our results cannot address causality, they suggest that singing and musical instrument playing may have a potential to enhance the perception of speech in noise in children with CIs.
C1 [Torppa, Ritva; Kujala, Teija; Huotilainen, Minna; Lipsanen, Jari] Univ Helsinki, POB 21,Haartmaninkatu 3, FIN-00014 Helsinki, Finland.
   [Faulkner, Andrew] UCL, London, England.
RP Torppa, R (corresponding author), Univ Helsinki, POB 21,Haartmaninkatu 3, FIN-00014 Helsinki, Finland.
EM ritva.torppa@helsinki.fi
RI Torppa, Ritva/V-2892-2019; Faulkner, Andrew/A-8212-2008
OI Faulkner, Andrew/0000-0002-2969-5630; Lipsanen, Jari
   Olavi/0000-0003-0746-2745; Torppa, Ritva/0000-0003-3219-9790;
   Huotilainen, Minna/0000-0002-7251-6984; Kujala,
   Teija/0000-0002-8814-605X
FU Signe and Ane Gyllenberg Foundation; Finnish Concordia Fund; Ella and
   Georg Ehrnrooth Foundation; Emil Aaltonen Foundation; Academy of
   FinlandAcademy of FinlandEuropean Commission [276414]; Jane and Aatos
   Erkko Foundation; National doctoral program Langnet
FX This work was financially supported by Signe and Ane Gyllenberg
   Foundation, the Finnish Concordia Fund, the Ella and Georg Ehrnrooth
   Foundation, National doctoral program Langnet, the Emil Aaltonen
   Foundation, the Academy of Finland (grant 276414), and the Jane and
   Aatos Erkko Foundation. The authors wish to thank the Lindfors
   Foundation (Eila Lonka and Helena Ahti), Finnish Audiological Society,
   the personnel of Departments of Audiology in Helsinki, Turku, Tampere
   and Kuopio University Hospitals and Cognitive Brain Research Unit
   (especially Tanja Linnavalli, Johannes Pykalainen, Hannu Loimo, Emma
   Salo, Miika Leminen, and Tommi Makkonen) involved in this study, and
   most importantly, the parents and children for their participation.
CR Adank P, 2012, NEUROPSYCHOLOGIA, V50, P77, DOI 10.1016/j.neuropsychologia.2011.10.024
   AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   Alho K, 1998, PSYCHOPHYSIOLOGY, V35, P211, DOI 10.1111/1469-8986.3520211
   Anderson CA, 2017, P NATL ACAD SCI USA, V114, P10256, DOI 10.1073/pnas.1704785114
   Asp F, 2012, INT J AUDIOL, V51, P817, DOI 10.3109/14992027.2012.705898
   Baker M, 2014, J SPEECH LANG HEAR R, V57, P327, DOI 10.1044/1092-4388(2013/12-0287)
   Beer Jessica, 2011, Cochlear Implants Int, V12 Suppl 1, pS89, DOI 10.1179/146701011X13001035752570
   Bergeson TR, 2002, PSYCHOL SCI, V13, P72, DOI 10.1111/1467-9280.00413
   Besson M, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00094
   Bolger D, 2014, J COGNITIVE NEUROSCI, V26, P593, DOI 10.1162/jocn_a_00511
   Bradley JS, 2008, J ACOUST SOC AM, V123, P2078, DOI 10.1121/1.2839285
   Bryk S. W., 2002, HIERARCHICAL LINEAR
   Caldwell A, 2013, J SPEECH LANG HEAR R, V56, P13, DOI 10.1044/1092-4388(2012/11-0338)
   Cason N, 2012, NEUROPSYCHOLOGIA, V50, P2652, DOI 10.1016/j.neuropsychologia.2012.07.018
   Coffey EBJ, 2017, HEARING RES, V352, P49, DOI 10.1016/j.heares.2017.02.006
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Drennan WR, 2008, J REHABIL RES DEV, V45, P779, DOI 10.1682/JRRD.2007.08.0118
   Dreschler WA, 2001, AUDIOLOGY, V40, P148
   Du Y, 2017, P NATL ACAD SCI USA, V114, P13579, DOI 10.1073/pnas.1712223114
   Escera C, 2007, J PSYCHOPHYSIOL, V21, P251, DOI 10.1027/0269-8803.21.34.251
   Estabrooks W, 1994, AUDITORY VERBAL THER
   Falk S, 2016, LANG COGN NEUROSCI, V31, P699, DOI 10.1080/23273798.2016.1144892
   Fallon M, 2000, J ACOUST SOC AM, V108, P3023, DOI 10.1121/1.1323233
   Flaugnacco E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138715
   Francois C, 2013, CEREB CORTEX, V23, P2038, DOI 10.1093/cercor/bhs180
   Friesen LM, 2001, J ACOUST SOC AM, V110, P1150, DOI 10.1121/1.1381538
   Fu QJ, 2008, HEARING RES, V242, P198, DOI 10.1016/j.heares.2007.11.010
   Fu QJ, 2005, JARO-J ASSOC RES OTO, V6, P180, DOI 10.1007/s10162-005-5061-6
   Geers AE, 2013, EAR HEARING, V34, P562, DOI 10.1097/AUD.0b013e31828d2bd6
   GFELLER K, 2016, EUROPEAN ANN OTORHIN, V133, P50
   Gordon RL, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00352
   Hall JW, 2002, EAR HEARING, V23, P159, DOI 10.1097/00003446-200204000-00008
   Hausen M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00566
   Horvath J, 2008, BIOL PSYCHOL, V79, P139, DOI 10.1016/j.biopsycho.2008.04.001
   Houston DM, 2014, LINGUA, V139, P10, DOI 10.1016/j.lingua.2013.08.001
   Ibrahim JG, 2009, TEST-SPAIN, V18, P1, DOI 10.1007/s11749-009-0138-x
   Jung KH, 2012, AUDIOL NEURO-OTOL, V17, P189, DOI 10.1159/000336407
   Jusczyk PW, 1999, TRENDS COGN SCI, V3, P323, DOI 10.1016/S1364-6613(99)01363-7
   Kelly AS, 2005, CLIN NEUROPHYSIOL, V116, P1235, DOI 10.1016/j.clinph.2005.02.011
   Kileny PR, 1997, OTOLARYNG HEAD NECK, V117, P161, DOI 10.1016/S0194-5998(97)70169-4
   KLATT DH, 1980, J ACOUST SOC AM, V67, P971, DOI 10.1121/1.383940
   Kong YY, 2011, J SPEECH LANG HEAR R, V54, P981, DOI 10.1044/1092-4388(2010/10-0196)
   Kral A, 2012, TRENDS NEUROSCI, V35, P111, DOI 10.1016/j.tins.2011.09.004
   Kujala T, 2010, PROG NEUROBIOL, V91, P55, DOI 10.1016/j.pneurobio.2010.01.006
   Lebedeva GC, 2010, INFANT BEHAV DEV, V33, P419, DOI 10.1016/j.infbeh.2010.04.006
   Leong V., 2017, OPEN MIND, V1, P78, DOI [10.1162/OPMI_a_00008, DOI 10.1162/OPMI_A_00008]
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Lo CY, 2015, BEHAV NEUROL, V2015, DOI 10.1155/2015/352869
   Lonka E, 2004, AUDIOL NEURO-OTOL, V9, P160, DOI 10.1159/000077265
   Looi V, 2011, INT J PEDIATR OTORHI, V75, P472, DOI 10.1016/j.ijporl.2010.12.023
   Makeig S, 2004, TRENDS COGN SCI, V8, P204, DOI 10.1016/j.tics.2004.03.008
   Mattys SL, 1997, PSYCHON B REV, V4, P310, DOI 10.3758/BF03210789
   Mishra SK, 2015, J SPEECH LANG HEAR R, V58, P1052, DOI 10.1044/2015_JSLHR-H-14-0340
   Moore BCJ, 2003, OTOL NEUROTOL, V24, P243, DOI 10.1097/00129492-200303000-00019
   Moore JK, 2007, INT J AUDIOL, V46, P460, DOI 10.1080/14992020701383019
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 2017, HEARING RES, V353, P57, DOI 10.1016/j.heares.2017.07.007
   Nager W, 2007, RESTOR NEUROL NEUROS, V25, P391
   NITTROUER S, 1990, J ACOUST SOC AM, V87, P2705, DOI 10.1121/1.399061
   O'Halpin R., 2010, THESIS
   Oba SI, 2011, EAR HEARING, V32, P573, DOI 10.1097/AUD.0b013e31820fc821
   OPOLKO F., 2006, MCGILL U MASTER SAMP
   Parbery-Clark A, 2011, NEUROPSYCHOLOGIA, V49, P3338, DOI 10.1016/j.neuropsychologia.2011.08.007
   Parbery-Clark A, 2009, EAR HEARING, V30, P653, DOI 10.1097/AUD.0b013e3181b412e9
   Patel AD, 2014, HEARING RES, V308, P98, DOI 10.1016/j.heares.2013.08.011
   Patel AD, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00142
   PICHENY MA, 1985, J SPEECH HEAR RES, V28, P96, DOI 10.1044/jshr.2801.96
   Ponton CW, 2000, AUDIOL NEURO-OTOL, V5, P167, DOI 10.1159/000013878
   Putkinen V, 2013, EUR J NEUROSCI, V37, P654, DOI 10.1111/ejn.12049
   Rock AML, 1999, DEV PSYCHOL, V35, P527, DOI 10.1037/0012-1649.35.2.527
   ROSEN S, 1992, PHILOS T ROY SOC B, V336, P367, DOI 10.1098/rstb.1992.0070
   Ruffin CV, 2013, AUDIOL NEURO-OTOL, V18, P289, DOI 10.1159/000353405
   Ruggles DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086980
   Sandmann P, 2010, CLIN NEUROPHYSIOL, V121, P2070, DOI 10.1016/j.clinph.2010.04.032
   Schon D, 2015, ANN NY ACAD SCI, V1337, P32, DOI 10.1111/nyas.12635
   Shahin AJ, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00126
   Singer J.D., 2003, APPL LONGITUDINAL DA
   Slater J, 2016, COGN PROCESS, V17, P79, DOI 10.1007/s10339-015-0740-7
   Slater J, 2015, BEHAV BRAIN RES, V291, P244, DOI 10.1016/j.bbr.2015.05.026
   Strait DL, 2012, BRAIN LANG, V123, P191, DOI 10.1016/j.bandl.2012.09.001
   Strelnikov K, 2009, SCAND J PSYCHOL, V50, P437, DOI 10.1111/j.1467-9450.2009.00741.x
   Stuart A, 2005, EAR HEARING, V26, P78, DOI 10.1097/00003446-200502000-00007
   Torppa R., 2010, SPEECH PROSODY 2010
   TORPPA R, 2015, STUDIES PSYCHOL, V113
   Torppa R, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01389
   Torppa R, 2014, INT J AUDIOL, V53, P182, DOI 10.3109/14992027.2013.872302
   Torppa R, 2012, CLIN NEUROPHYSIOL, V123, P1966, DOI 10.1016/j.clinph.2012.03.008
   Trainor LJ, 1997, INFANT BEHAV DEV, V20, P383, DOI 10.1016/S0163-6383(97)90009-6
   Trehub SE, 2009, ANN NY ACAD SCI, V1169, P534, DOI 10.1111/j.1749-6632.2009.04554.x
   Tyler R, 1987, CLOSED SET SPEECH PE
   Uther M, 2006, BRAIN RES, V1073, P417, DOI 10.1016/j.brainres.2005.12.047
   West BT, 2009, EVAL HEALTH PROF, V32, P207, DOI 10.1177/0163278709338554
   Wetzel N, 2006, CLIN NEUROPHYSIOL, V117, P2191, DOI 10.1016/j.clinph.2006.06.717
   WILD C. J, 2012, EFFORTFUL LISTENING, V32, P14016
   Winkler I, 1998, NEUROSCI LETT, V242, P49, DOI 10.1016/S0304-3940(98)00022-6
   Winkler I, 2009, TRENDS COGN SCI, V13, P532, DOI 10.1016/j.tics.2009.09.003
   Won JH, 2010, EAR HEARING, V31, P796, DOI 10.1097/AUD.0b013e3181e8b7bd
   Woodfield A, 2010, J ACOUST SOC AM, V128, pEL26, DOI 10.1121/1.3443570
   YABE H, 1993, ELECTROEN CLIN NEURO, V87, P403, DOI 10.1016/0013-4694(93)90154-N
NR 99
TC 7
Z9 7
U1 4
U2 14
PU UNIV CALIFORNIA PRESS
PI OAKLAND
PA 155 GRAND AVE, SUITE 400, OAKLAND, CA 94612-3758 USA
SN 0730-7829
J9 MUSIC PERCEPT
JI Music Percept.
PD DEC
PY 2018
VL 36
IS 2
BP 156
EP 174
DI 10.1525/MP.2018.36.2.156
PG 19
WC Music; Psychology, Experimental
SC Music; Psychology
GA HF7TO
UT WOS:000454443900002
OA Green Published
DA 2021-02-24
ER

PT J
AU Beddor, PS
   Coetzee, AW
   Styler, W
   McGowan, KB
   Boland, JE
AF Beddor, Patrice Speeter
   Coetzee, Andries W.
   Styler, Will
   McGowan, Kevin B.
   Boland, Julie E.
TI THE TIME COURSE OF INDIVIDUALS' PERCEPTION OF COARTICULATORY INFORMATION
   IS LINKED TO THEIR PRODUCTION: IMPLICATIONS FOR SOUND CHANGE
SO LANGUAGE
LA English
DT Article
DE individual differences; coarticulation; sound change; nasalization;
   speech production; speech perception
ID TO-VOWEL COARTICULATION; VOICE ONSET TIME; PHONETIC CONVERGENCE;
   SPEECH-PERCEPTION; CUE; COMPENSATION; NASALIZATION; CONSEQUENCES;
   MISMATCHES; PATTERNS
AB Understanding the relation between speech production and perception is foundational to phonetic theory, and is similarly central to theories of the phonetics of sound change. For sound changes that are arguably perceptually motivated, it is particularly important to establish that an individual listener's selective attention-for example, to the redundant information afforded by coarticulation-is reflected in that individual's own productions. This study reports the results of a pair of experiments designed to test the hypothesis that individuals who produce more consistent and extensive coarticulation will attend to that information especially closely in perception. The production experiment used nasal airflow to measure the time course of participants' coarticulatory vowel nasalization; the perception experiment used an eye-tracking paradigm to measure the time course of those same participants' attention to coarticulated nasality. Results showed that a speaker's coarticulatory patterns predicted, to some degree, that individual's perception, thereby supporting the hypothesis: participants who produced earlier onset of coarticulatory nasalization were, as listeners, more efficient users of nasality as that information unfolded over time. Thus, an individual's perception of coarticulated speech is made public through their productions.*
C1 [Beddor, Patrice Speeter; Coetzee, Andries W.; Boland, Julie E.] Univ Michigan, Ann Arbor, MI 48109 USA.
   [Coetzee, Andries W.] North West Univ, Potchefstroom, South Africa.
   [Styler, Will] Univ Calif San Diego, San Diego, CA 92103 USA.
   [McGowan, Kevin B.] Univ Kentucky, Lexington, KY 40506 USA.
RP Beddor, PS (corresponding author), Univ Michigan, Ann Arbor, MI 48109 USA.
EM beddor@umich.edu; coetzee@umich.edu; wstyler@ucsd.edu;
   kbmcgowan@uky.edu; jeboland@umich.edu
OI Boland, Julie/0000-0002-3343-496X
FU National Science FoundationNational Science Foundation (NSF)
   [BCS-1348150]; Direct For Social, Behav & Economic ScieNational Science
   Foundation (NSF)NSF - Directorate for Social, Behavioral & Economic
   Sciences (SBE) [1348150] Funding Source: National Science Foundation;
   Division Of Behavioral and Cognitive SciNational Science Foundation
   (NSF)NSF - Directorate for Social, Behavioral & Economic Sciences (SBE)
   [1348150] Funding Source: National Science Foundation
FX We thank Kerby Shedden for advice on statistical modeling, Skye Huerta
   and Karen Tan for assistance with data coding, and Anthony Brasher for
   help with pilot data collection. This work has greatly benefited from
   the comments of members of several audiences, especially those at ICPhS
   2015, the 2017 Fourth Workshop on Sound Change, and the University of
   Michigan Phonetics-Phonology Research Group. Given that the current
   editor of Language is a coauthor of this article, the editorial process
   was anonymously managed by a guest editor. We express our appreciation
   to the guest editor for their professional handling of the manuscript,
   and to three anonymous referees for their valuable comments. This
   material is based on work supported by the National Science Foundation
   under Grant No. BCS-1348150 to Patrice Beddor and Andries Coetzee; any
   opinions, findings, and conclusions or recommendations expressed in this
   material are those of the authors and do not necessarily reflect the
   views of the NSF.
CR Baayen RH, 2018, QUANT METH HUMAN SOC, P49, DOI 10.1007/978-3-319-69830-4_4
   Babel M, 2012, J PHONETICS, V40, P177, DOI 10.1016/j.wocn.2011.09.001
   Beddor P. S., 2012, INITIATION SOUND CHA, P37, DOI DOI 10.1075/CILT.323.06BED
   Beddor PS, 2013, J ACOUST SOC AM, V133, P2350, DOI 10.1121/1.4794366
   Beddor PS, 2009, LANGUAGE, V85, P785
   Beddor PS, 2002, J PHONETICS, V30, P591, DOI 10.1006/jpho.2002.0177
   Beddor PS, 1999, J ACOUST SOC AM, V106, P2868, DOI 10.1121/1.428111
   BOYCE SE, 1990, J ACOUST SOC AM, V88, P2584, DOI 10.1121/1.400349
   Brooks SP, 1998, J COMPUT GRAPH STAT, V7, P434, DOI 10.2307/1390675
   Busa M. Grazia, 2007, EXPT APPROACHES PHON, P155
   Bybee Joan, 2012, INITIATION SOUND CHA, P211, DOI DOI 10.1075/CILT.323.16BYB
   Coetzee AW, 2018, J PHONETICS, V66, P185, DOI 10.1016/j.wocn.2017.09.009
   COHN ABIGAIL C., 1990, UCLA WORKING PAPERS, V76
   Dahan D, 2001, LANG COGNITIVE PROC, V16, P507, DOI 10.1080/01690960143000074
   deBoor C., 1978, APPL MATH SCI, V27
   Delvaux V, 2008, J PHONETICS, V36, P578, DOI 10.1016/j.wocn.2008.02.002
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Dmitrieva O, 2015, J PHONETICS, V49, P77, DOI 10.1016/j.wocn.2014.12.005
   Flagg EJ, 2006, NEUROSCI LETT, V397, P263, DOI 10.1016/j.neulet.2005.12.034
   Fowler C. A., 2007, OXFORD HDB PSYCHOLIN, P489, DOI [10.1093/oxfordhb/9780198568971.013.0029, DOI 10.1093/OXFORDHB/9780198568971.013.0029]
   Fowler CA, 2006, PERCEPT PSYCHOPHYS, V68, P161, DOI 10.3758/BF03193666
   Fowler CA, 2005, J PHONETICS, V33, P199, DOI 10.1016/j.wocn.2004.10.003
   Fowler CA, 2000, PERCEPT PSYCHOPHYS, V62, P21, DOI 10.3758/BF03212058
   Garrett Andrew, 2013, ORIGINS SOUND CHANGE, P51, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0003
   Gelman A, 2014, STAT COMPUT, V24, P997, DOI 10.1007/s11222-013-9416-2
   Gelman A, 2011, CH CRC HANDB MOD STA, P163
   Grosvald M., 2012, INITIATION SOUND CHA, P77, DOI DOI 10.1075/CILT.323.08GRO
   Grosvald M, 2009, J PHONETICS, V37, P173, DOI 10.1016/j.wocn.2009.01.002
   Guion SG, 1998, PHONETICA, V55, P18
   Hadfield JD, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i02
   HAJEK JOHN, 2013, WORLD ATLAS LANGUAGE
   Hajek John, 1997, UNIVERSALS SOUND CHA
   HARRINGTO JONATHAN, 2019, ROUTLEDGE HDB PHONET
   Harrington J, 2008, J ACOUST SOC AM, V123, P2825, DOI 10.1121/1.2897042
   Harrington Jonathan, 2012, SPEECH PLANNING DYNA, P33
   Idemaru K, 2012, J ACOUST SOC AM, V132, P3950, DOI 10.1121/1.4765076
   Iskarous K, 2005, J PHONETICS, V33, P363, DOI 10.1016/j.wocn.2004.09.001
   Kang YJ, 2014, J PHONETICS, V45, P76, DOI 10.1016/j.wocn.2014.03.005
   KATAOKA REIKO, 2011, PHONETIC COGNITIVE B
   Kleber F, 2012, LANG SPEECH, V55, P383, DOI 10.1177/0023830911422194
   Kong EJ, 2016, J PHONETICS, V59, P40, DOI 10.1016/j.wocn.2016.08.006
   KRAKOW RA, 1988, J ACOUST SOC AM, V83, P1146, DOI 10.1121/1.396059
   KRAKOW RENA A, 1989, ARTICULATORY ORG SYL
   Krakow Rena A., 1993, NASALS NASALIZATION, V5, P3
   KWON HARIM, 2015, CUE PRIMACY SPONTANE
   Liberman AM, 2000, TRENDS COGN SCI, V4, P187, DOI 10.1016/S1364-6613(00)01471-6
   LINDBLOM B, 1990, NATO ADV SCI I D-BEH, V55, P403
   LINDBLOM BJORN, 1995, RIV LINGUISTICA, P75
   LUBKER J, 1982, J ACOUST SOC AM, V71, P437, DOI 10.1121/1.387447
   Magen HS, 1997, J PHONETICS, V25, P187, DOI 10.1006/jpho.1996.0041
   MALECOT A, 1960, LANGUAGE, V36, P222, DOI 10.2307/410987
   MANN VA, 1980, PERCEPT PSYCHOPHYS, V28, P213, DOI 10.3758/BF03204377
   MANUEL SY, 1990, J ACOUST SOC AM, V88, P1286, DOI 10.1121/1.399705
   MARTIN JG, 1982, J EXP PSYCHOL HUMAN, V8, P473, DOI 10.1037/0096-1523.8.3.473
   Mitterer H, 2008, COGNITION, V109, P168, DOI 10.1016/j.cognition.2008.08.002
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007
   Noiray A, 2011, J ACOUST SOC AM, V129, P340, DOI 10.1121/1.3518452
   OHALA JJ, 1993, LANG SPEECH, V36, P155, DOI 10.1177/002383099303600303
   Ohala John, 1981, PAPERS PARASESSION L, P178
   Pardo JS, 2012, LANG LINGUIST COMPAS, V6, P753, DOI 10.1002/lnc3.367
   Pardo JS, 2006, J ACOUST SOC AM, V119, P2382, DOI 10.1121/1.2178720
   Parrell B, 2012, J PHONETICS, V40, P37, DOI 10.1016/j.wocn.2011.08.004
   Pierrehumbert Janet, 2001, FREQUENCY EFFECTS EM, P137, DOI [DOI 10.1075/TSL.45.08PIE, 10.1075/tsl. 45.08pie]
   Pinget A., 2015, THESIS
   R Core Team, 2013, R LANG ENV STAT COMP
   RAPHAEL LJ, 1975, J SPEECH HEAR RES, V18, P389, DOI 10.1044/jshr.1803.389
   Ruhlen M., 1978, UNIVERSALS HUMAN LAN, V2, P203
   Sampson Rodney, 1999, NASAL VOWEL EVOLUTIO
   Samuel AG, 2011, ANNU REV PSYCHOL, V62, P49, DOI 10.1146/annurev.psych.121208.131643
   Schertz J, 2015, J PHONETICS, V52, P183, DOI 10.1016/j.wocn.2015.07.003
   Shosted R, 2012, J ACOUST SOC AM, V131, P455, DOI 10.1121/1.3665998
   Shultz AA, 2012, J ACOUST SOC AM, V132, pEL95, DOI 10.1121/1.4736711
   SOLE MARIA-JOSEP, 2012, INITIATION SOUND CHA
   Stevens KN, 1998, ACOUSTIC PHONETICS
   Stevens M, 2014, LOQUENS, V1, DOI 10.3989/loquens.2014.003
   STRANGE W, 1983, J ACOUST SOC AM, V74, P695, DOI 10.1121/1.389855
   Trude AM, 2012, LANG COGNITIVE PROC, V27, P979, DOI 10.1080/01690965.2011.597153
   WHALEN DH, 1990, J PHONETICS, V18, P3, DOI 10.1016/S0095-4470(19)30356-0
   WHALEN DH, 1984, PERCEPT PSYCHOPHYS, V35, P49, DOI 10.3758/BF03205924
   WHALEN DH, 1993, J ACOUST SOC AM, V93, P2152, DOI 10.1121/1.406678
   Yu A. C. L., 2013, ORIGINS SOUND CHANGE, P201, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0010
   Yu ACL, 2016, J ACOUST SOC AM, V139, P1672, DOI 10.1121/1.4944992
   Yu ACL, 2014, J ACOUST SOC AM, V136, P382, DOI 10.1121/1.4883380
   Yu ACL, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011950
   Zellou G, 2017, J PHONETICS, V61, P13, DOI 10.1016/j.wocn.2016.12.002
NR 85
TC 14
Z9 14
U1 0
U2 6
PU LINGUISTIC SOC AMER
PI WASHINGTON
PA 1325 18TH ST NW, SUITE 211, WASHINGTON, DC 20036-6501 USA
SN 0097-8507
EI 1535-0665
J9 LANGUAGE
JI Language
PD DEC
PY 2018
VL 94
IS 4
BP 931
EP 968
DI 10.1353/lan.2018.0051
PG 38
WC Linguistics; Language & Linguistics
SC Linguistics
GA HF0AH
UT WOS:000453818000012
DA 2021-02-24
ER

PT J
AU Wang, Y
   Silvestri, JA
   Jahromi, LB
AF Wang, Ye
   Silvestri, Julia A.
   Jahromi, Laudan B.
TI SELECTED FACTORS IN READING COMPREHENSION FOR DEAF AND HEARING ADULTS:
   PHONOLOGICAL SKILLS AND METACOGNITION
SO AMERICAN ANNALS OF THE DEAF
LA English
DT Article
DE deafness; reading; phonology; metacognition; think-aloud
ID HARD-OF-HEARING; QUALITATIVE SIMILARITY HYPOTHESIS; SPEECH-PERCEPTION;
   WORD RECOGNITION; VISUAL PHONICS; SIGN-LANGUAGE; CUED SPEECH; STUDENTS;
   CHILDREN; READERS
AB The purpose of the study was to identify factors related to reading comprehension, and to compare similarities and differences in the reading processes of deaf and hearing adults. The sample included four groups, each consisting of 15 adults. The groups were identified as (a) deaf high achieving readers, (b) deaf low-achieving readers, (c) hearing high achieving readers, and (d) hearing low-achieving readers. Measurement instruments included a demographic form along with assessments of reading comprehension, phonological skills, and metacognition, the latter of which contained both a making-inferences measure and a think aloud discussion with a reading strategies checklist. Results indicated that deaf high-achieving readers performed similarly to hearing high achieving readers, except for phonological skills, and that for all participants, phonological skills and metacognition were related to reading comprehension skills.
C1 [Wang, Ye; Silvestri, Julia A.; Jahromi, Laudan B.] Columbia Univ, Teachers Coll, New York, NY 10027 USA.
RP Wang, Y (corresponding author), Columbia Univ, Teachers Coll, New York, NY 10027 USA.
CR ADAMS M, 2002, HDB EARLY LITERACY R, P66
   Adams M., 1990, BEGINNING READ THINK
   ADAMS MJ, 1994, READING, LANGUAGE, AND LITERACY : INSTRUCTION FOR THE TWENTY-FIRST CENTURY, P3
   Allen T., 1986, DEAF CHILDREN AM, P161, DOI DOI 10.1177/15257401050270010201
   Andrews JF, 2015, AM ANN DEAF, V159, P468, DOI 10.1353/aad.2015.0005
   ANDREWS JF, 1991, EXCEPT CHILDREN, V57, P536, DOI 10.1177/001440299105700607
   Aparicio M, 2007, NEUROIMAGE, V35, P1303, DOI 10.1016/j.neuroimage.2006.12.046
   Archbold S, 2015, ED DEAF LEARNERS CRE, P23
   Baker-Shenk C. L., 1991, AM SIGN LANGUAGE TEA
   Banner A, 2011, J DEAF STUD DEAF EDU, V16, P2, DOI 10.1093/deafed/enq027
   Beal-Alvarez JS, 2012, J DEAF STUD DEAF EDU, V17, P39, DOI 10.1093/deafed/enr030
   Belanger NN, 2012, SCI STUD READ, V16, P263, DOI 10.1080/10888438.2011.568555
   Bochner J. H., 2016, OXFORD HDB DEAF STUD, P393
   Borgna G, 2011, J DEAF STUD DEAF EDU, V16, P79, DOI 10.1093/deafed/enq036
   Bouton S, 2011, J DEAF STUD DEAF EDU, V16, P458, DOI 10.1093/deafed/enr014
   Brown P, 1996, J DEAF STUD DEAF EDU, V1, P264
   Campbell R, 2008, INT J AUDIOL, V47, pS3, DOI 10.1080/14992020802233907
   Chall J. S., 1996, STAGES READING DEV
   Cohen J, 2013, STAT POWER ANAL BEHA, V3rd, P77
   Colin S, 2007, J CHILD PSYCHOL PSYC, V48, P139, DOI 10.1111/j.1469-7610.2006.01700.x
   Colin S, 2013, RES DEV DISABIL, V34, P1781, DOI 10.1016/j.ridd.2013.02.001
   Commission on Education of the Deaf (U.S.) , 1988, EQ ED DEAF
   CONRAD R, 1979, DEAF SCHOOLCHILD LAN
   DAVEY B, 1987, J READING BEHAV, V19, P261, DOI 10.1080/10862968709547604
   Doran J, 2003, J RES READ, V26, P256, DOI 10.1111/1467-9817.00201
   Easterbrooks S., 2013, LITERACY INSTRUCTION
   Easterbrooks S.R., 2016, OXFORD HDB DEAF STUD, P377
   Easterbrooks SR, 2012, AM ANN DEAF, V157, P27, DOI 10.1353/aad.2012.1611
   Ehri L.C., 2013, THEORETICAL MODELS P, V6, P339
   Emmorey K, 2013, BRAIN LANG, V126, P169, DOI 10.1016/j.bandl.2013.05.001
   Geers A, 2008, INT J AUDIOL, V47, pS21, DOI 10.1080/14992020802339167
   Hannon B, 2013, THEORETICAL MODELS P, P840
   Holmer E, 2016, RES DEV DISABIL, V48, P145, DOI 10.1016/j.ridd.2015.10.008
   Hulme C, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2012.0395
   Kelly RR, 2001, AM ANN DEAF, V146, P385, DOI 10.1353/aad.2012.0206
   Koo D, 2008, ANN NY ACAD SCI, V1145, P83, DOI 10.1196/annals.1416.025
   Kyle FE, 2006, J DEAF STUD DEAF EDU, V11, P273, DOI 10.1093/deafed/enj037
   Kyle FE, 2015, TOP LANG DISORD, V35, P144, DOI 10.1097/TLD.0000000000000053
   Kyle FE, 2011, J DEAF STUD DEAF EDU, V16, P289, DOI 10.1093/deafed/enq069
   Kyle FE, 2010, J EXP CHILD PSYCHOL, V107, P229, DOI 10.1016/j.jecp.2010.04.011
   LaSasso CJ, 2015, AM ANN DEAF, V159, P447, DOI 10.1353/aad.2015.0004
   Lederberg AR, 2013, DEV PSYCHOL, V49, P15, DOI 10.1037/a0029558
   Leybaert J., 2016, OXFORD HDB DEAF STUD, P359
   Luckner J., 2016, PROMOTING LANGUAGE L, P329
   Luckner JL, 2003, AM ANN DEAF, V148, P243, DOI 10.1353/aad.2003.0020
   Luckner JL, 2006, AM ANN DEAF, V151, P410, DOI 10.1353/aad.2006.0046
   Luckner JL, 2013, AM ANN DEAF, V158, P7, DOI 10.1353/aad.2013.0012
   Marschark M., 2016, OXFORD HDB DEAF STUD, P431
   Marschark M, 2009, AM ANN DEAF, V154, P357
   Mather N., 2001, WOODCOCKJOHNSON 3 TE
   Mayberry RI, 2011, J DEAF STUD DEAF EDU, V16, P164, DOI 10.1093/deafed/enq049
   Mayer C., 2015, EARLY LITERACY DEV D
   Mayer C, 2014, AM ANN DEAF, V159, P359, DOI 10.1353/aad.2014.0032
   McAnally P. L., 1994, LANGUAGE LEARNING PR
   McGuinness D, 2005, LANGUAGE DEV LEARNIN
   McGuinness D., 2004, EARLY READING INSTRU
   McQuarrie L, 2013, SIGN LANG STUD, V14, P80, DOI 10.1353/sls.2013.0028
   McQuarrie L, 2014, AM ANN DEAF, V159, P372, DOI 10.1353/aad.2014.0034
   McQuarrie L, 2009, J DEAF STUD DEAF EDU, V14, P137, DOI 10.1093/deafed/enn025
   Miller P, 2012, J DEAF STUD DEAF EDU, V17, P439, DOI 10.1093/deafed/ens022
   Moeller M.P., 2016, PROMOTING LANGUAGE L
   National Early Literacy Panel, 2008, DEV EARL LIT REP NAT
   National Reading Panel, 2000, REP NAT READ PAN TEA
   Paris S. G., 2009, HDB RES READING COMP, P32
   Paul P. V., 2013, DEAF STUDENTS QUALIT
   Paul PV, 2010, AM ANN DEAF, V154, P456, DOI 10.1353/aad.0.0125
   Perfetti Charles A., 2000, J DEAF STUD DEAF EDU, V5, P32, DOI [DOI 10.1093/DEAFED/5.1.32, 10.1093/deafed/5.1.32]
   Qi S, 2012, J DEAF STUD DEAF EDU, V17, P1, DOI 10.1093/deafed/enr028
   Rees R, 2013, DEAF EDUC INT, V15, P182, DOI 10.1179/1557069X13Y.0000000025
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   Ruddell R. B., 2013, THEORETICAL MODELS P
   Rumelhart D, 2013, THEORETICAL MODELS P, P719
   Schirmer B., 2003, J DEAF STUD DEAF EDU, V8, P157, DOI DOI 10.1093/DEAFED/ENG009
   Schirmer BR, 2005, REV EDUC RES, V75, P83, DOI 10.3102/00346543075001083
   Schirmer BR, 2004, AM ANN DEAF, V149, P5, DOI 10.1353/aad.2004.0016
   Scott G., 2011, DEAF HARD HEARING CH
   Smith A, 2010, AM ANN DEAF, V155, P124
   Strassman B, 1997, J Deaf Stud Deaf Educ, V2, P140
   STRASSMAN BK, 1992, AM ANN DEAF, V137, P326, DOI 10.1353/aad.2012.0456
   Traxler C.B., 2000, J DEAF STUDIES DEAF, V5, DOI [https://doi.org/10.1093/deafed/5.4.337, DOI 10.1093/DEAFED/5.4.337]
   Trezek B. J, 2010, READING DEAFNESS THE
   Trezek B. J., 2011, OXFORD HDB DEAF STUD, P99
   Trezek BJ, 2007, J DEAF STUD DEAF EDU, V12, P373, DOI 10.1093/deafed/enm014
   Trezek BJ, 2013, J DEAF STUD DEAF EDU, V18, P391, DOI 10.1093/deafed/ent016
   Trezek BJ, 2006, J DEAF STUD DEAF EDU, V11, P202, DOI 10.1093/deafed/enj031
   Trezek BJ, 2005, J DEAF STUD DEAF EDU, V10, P256, DOI 10.1093/deafed/eni028
   Tucci SL, 2015, J SPEC EDUC, V48, P279, DOI 10.1177/0022466913504462
   Wang Y, 2017, J DEV PHYS DISABIL, V29, P35, DOI 10.1007/s10882-016-9520-2
   Wang Y, 2014, AM ANN DEAF, V159, P319, DOI 10.1353/aad.2014.0028
   Wang Y, 2013, AM ANN DEAF, V158, P107, DOI 10.1353/aad.2013.0021
   Wang Y, 2008, AM ANN DEAF, V153, P396
   Whitehurst GJ, 1998, CHILD DEV, V69, P848, DOI 10.1111/j.1467-8624.1998.00848.x
   Wiig E., 2015, CELF 5 METALINGUISTI
   Wilson-Taber D, 2016, PROMOTING LANGUAGE L, P297
NR 94
TC 5
Z9 6
U1 3
U2 83
PU GALLAUDET UNIV PRESS
PI WASHINGTON
PA 800 FLORIDA AVE NE, WASHINGTON, DC 20002 USA
SN 0002-726X
EI 1543-0375
J9 AM ANN DEAF
JI Am. Ann. Deaf
PD WIN
PY 2018
VL 162
IS 5
BP 445
EP 462
PG 18
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA FX6WR
UT WOS:000426228500004
PM 29478998
DA 2021-02-24
ER

PT J
AU Liu, M
   Xing, YS
   Zhao, LM
   Deng, NL
   Li, WJ
AF Liu, Meng
   Xing, Yushan
   Zhao, Liming
   Deng, Nali
   Li, Weijun
TI Abnormal processing of prosodic boundary in adults who stutter: An ERP
   study
SO BRAIN AND COGNITION
LA English
DT Article
DE Stutter; Prosodic boundary; Ambiguous phrases; ERPs
ID EVENT-RELATED POTENTIALS; FUNCTIONING AUTISM; SPEECH-PERCEPTION; BRAIN
   POTENTIALS; CORPUS-CALLOSUM; ACTIVATION; CHILDREN; CONSTRAINTS; FLUENCY;
   CUES
AB Characterized by involuntary disruptions in fluency speech, adults who stutter (AWS) are different from normally fluent speakers (NFS) in speech-language processing indices of phonological, semantic, and syntactic information coding. However, the neural base of the prosodic information (i.e. prosodic boundary) processing in AWS is still elusive at this point. To investigate this question, Chinese temporarily ambiguous phrases (narrative-object/modifier-noun construction) were presented in pairs to AWS and NFS in both lexical judgment and structural judgment task by using structural priming paradigm. Results showed that both AWS and NFS produced prosodic priming in the two tasks, however, AWS were more sensitive to the priming than NFS in the midline. Besides, unlike the greater right hemisphere involvement of priming effect for NFS, AWS exhibited a left hemisphere asymmetry in the lateral areas. In addition, structural judgment task elicited stronger prosodic priming effect than lexical judgment task for both groups. These results indicate that the mode of prosodic priming for AWS is different from NFS, and the priming effect is influenced by the experimental task that participants completed.
C1 [Liu, Meng; Xing, Yushan; Deng, Nali; Li, Weijun] Liaoning Normal Univ, Res Ctr Brain & Cognit Neurosci, Huanghe Rd 850, Dalian 116029, Peoples R China.
   [Zhao, Liming] Tianjin Normal Univ, Acad Psychol & Behav, Tianjin 300074, Peoples R China.
RP Li, WJ (corresponding author), Liaoning Normal Univ, Res Ctr Brain & Cognit Neurosci, Huanghe Rd 850, Dalian 116029, Peoples R China.
EM li_wj@126.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [31000505, 31600873]; Ministry of Education
   Humanities and Social Science Fund [17YJC190013]
FX This research was supported by National Natural Science Foundation of
   China (grant numbers 31000505, 31600873), and Ministry of Education
   Humanities and Social Science Fund (17YJC190013).
CR Allen JJB, 2004, BIOL PSYCHOL, V67, P183, DOI 10.1016/j.biopsycho.2004.03.007
   Anderson JD, 2004, J SPEECH LANG HEAR R, V47, P552, DOI 10.1044/1092-4388(2004/043)
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Bauman J, 2012, J FLUENCY DISORD, V37, P314, DOI 10.1016/j.jfludis.2012.04.003
   Beal DS, 2011, NEUROIMAGE, V54, P2994, DOI 10.1016/j.neuroimage.2010.11.026
   BERGMANN G, 1986, J SPEECH HEAR RES, V29, P290, DOI 10.1044/jshr.2903.290
   BERNSTEIN NE, 1981, J FLUENCY DISORD, V6, P341, DOI 10.1016/0094-730X(81)90021-8
   Biermann-Ruben K, 2005, NEUROIMAGE, V25, P793, DOI 10.1016/j.neuroimage.2004.11.024
   Bloodstein O., 2008, HDB STUTTERING
   Bosshardt HG, 1996, J SPEECH HEAR RES, V39, P785, DOI 10.1044/jshr.3904.785
   Bosshardt HG, 2002, J FLUENCY DISORD, V27, P93, DOI 10.1016/S0094-730X(02)00113-4
   Branigan HP, 2000, MEM COGNITION, V28, P1297, DOI 10.3758/BF03211830
   Brocklehurst P., 2008, CONT ISSUES COMMUNIC, V35, P25
   Brown S, 2005, HUM BRAIN MAPP, V25, P105, DOI 10.1002/hbm.20140
   Carlson K, 2001, J MEM LANG, V45, P58, DOI 10.1006/jmla.2000.2762
   Chang SE, 2009, NEUROIMAGE, V46, P201, DOI 10.1016/j.neuroimage.2009.01.066
   Choo AL, 2011, J COMMUN DISORD, V44, P470, DOI 10.1016/j.jcomdis.2011.03.001
   Civier O, 2015, BRAIN LANG, V143, P20, DOI 10.1016/j.bandl.2015.01.012
   Clifton C, 2002, LANG SPEECH, V45, P87, DOI 10.1177/00238309020450020101
   Cuadrado EM, 2003, J SPEECH LANG HEAR R, V46, P960, DOI 10.1044/1092-4388(2003/075)
   De Nil LF, 2008, BRAIN LANG, V107, P114, DOI 10.1016/j.bandl.2008.07.003
   Etchell AC, 2018, J FLUENCY DISORD, V55, P6, DOI 10.1016/j.jfludis.2017.03.007
   Foundas AL, 2001, NEUROLOGY, V57, P207, DOI 10.1212/WNL.57.2.207
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   Garrod S, 2004, TRENDS COGN SCI, V8, P8, DOI 10.1016/j.tics.2003.10.016
   Giles H, 1992, CONTEXTS ACCOMMODATI, P1, DOI DOI 10.1017/CBO9780511663673.001
   Grunewald BD, 2018, BIOL PSYCHOL, V132, P212, DOI 10.1016/j.biopsycho.2018.01.003
   Hahne A, 2002, COGNITIVE BRAIN RES, V13, P339, DOI 10.1016/S0926-6410(01)00127-6
   Halag-Milo T, 2016, NEUROIMAGE-CLIN, V11, P328, DOI 10.1016/j.nicl.2016.02.017
   HOCKETT Charles F., 1973, SPEECH ERRORS LINGUI, P93
   Holzgrefe J, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00421
   Honbolygo F, 2016, J NEUROLINGUIST, V37, P22, DOI 10.1016/j.jneuroling.2015.08.001
   Jun SA, 2015, STUD THEOR PSYCHOLIN, V46, P217, DOI 10.1007/978-3-319-12961-7_12
   Jun SA, 2015, LANG SPEECH, V58, P459, DOI 10.1177/0023830914563368
   Kell CA, 2009, BRAIN, V132, P2747, DOI 10.1093/brain/awp185
   Kolk A, 1997, NATURE TREATMENT STU, P189
   Levelt WJ, 1989, SPEAKING INTENTION A
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1
   Li W, 2010, NEUROSCIENCE, V168, P757, DOI 10.1016/j.neuroscience.2010.03.069
   Li W, 2009, NEUROSCIENCE, V158, P1416, DOI 10.1016/j.neuroscience.2008.10.065
   Li XQ, 2010, BIOL PSYCHOL, V83, P250, DOI 10.1016/j.biopsycho.2010.01.009
   Liberman A.M, 1975, TRENDS COGN SCI, V4, P187
   Liotti M, 2010, BRAIN LANG, V115, P141, DOI 10.1016/j.bandl.2010.07.007
   Loucks T, 2011, J FLUENCY DISORD, V36, P302, DOI 10.1016/j.jfludis.2011.04.004
   Mari-Beffa P, 2005, COGNITIVE BRAIN RES, V23, P293, DOI 10.1016/j.cogbrainres.2004.10.016
   Mari-Beffa P, 2000, MEM COGNITION, V28, P635, DOI 10.3758/BF03201253
   Mock JR, 2016, CLIN NEUROPHYSIOL, V127, P3093, DOI 10.1016/j.clinph.2016.06.005
   Mock JR, 2015, BRAIN LANG, V149, P97, DOI 10.1016/j.bandl.2015.05.009
   Mock JR, 2011, EUR J NEUROSCI, V33, P1001, DOI 10.1111/j.1460-9568.2010.07585.x
   Morgan MD, 1997, J SPEECH LANG HEAR R, V40, P1334, DOI 10.1044/jslhr.4006.1334
   Neumann K, 2005, J FLUENCY DISORD, V30, P23, DOI 10.1016/j.jfludis.2004.12.002
   Neumann K, 2018, J FLUENCY DISORD, V55, P1, DOI 10.1016/j.jfludis.2017.08.001
   Neumann R, 2000, J PERS SOC PSYCHOL, V79, P211, DOI 10.1037//0022-3514.79.2.211
   Nieuwland MS, 2010, J MEM LANG, V63, P324, DOI 10.1016/j.jml.2010.06.005
   Ntourou K, 2011, AM J SPEECH-LANG PAT, V20, P163, DOI 10.1044/1058-0360(2011/09-0102)
   Pannekamp A, 2005, J COGNITIVE NEUROSCI, V17, P407, DOI 10.1162/0898929053279450
   Peter V, 2014, BMC NEUROSCI, V15, DOI 10.1186/s12868-014-0129-z
   Pickering MJ, 1999, TRENDS COGN SCI, V3, P136, DOI 10.1016/S1364-6613(99)01293-0
   POSTMA A, 1993, J SPEECH HEAR RES, V36, P472, DOI 10.1044/jshr.3603.472
   Preibisch C, 2003, NEUROIMAGE, V20, P1356, DOI 10.1016/S1053-8119(03)00376-8
   Richels C, 2010, J FLUENCY DISORD, V35, P314, DOI 10.1016/j.jfludis.2010.06.001
   Salverda AP, 2003, COGNITION, V90, P51, DOI 10.1016/S0010-0277(03)00139-2
   Schafer AJ, 2000, J PSYCHOLINGUIST RES, V29, P169, DOI 10.1023/A:1005192911512
   Schmid PC, 2018, PSYCHOPHYSIOLOGY, V55, DOI 10.1111/psyp.12911
   Shriberg LD, 2001, J SPEECH LANG HEAR R, V44, P1097, DOI 10.1044/1092-4388(2001/087)
   Speer S, 2015, STUDIES THEORETICAL, V46
   Steinhauer K, 1999, NAT NEUROSCI, V2, P191, DOI 10.1038/5757
   Tooley KM, 2014, J EXP PSYCHOL LEARN, V40, P348, DOI 10.1037/a0034900
   Tooley KM, 2009, J EXP PSYCHOL LEARN, V35, P19, DOI 10.1037/a0013984
   Tsiamtsiouris J, 2009, J SPEECH LANG HEAR R, V52, P16
   Usler E, 2015, J NEURODEV DISORD, V7, DOI 10.1186/1866-1955-7-4
   Watson JB, 2011, AM J SPEECH-LANG PAT, V20, P209, DOI 10.1044/1058-0360(2011/10-0019)
   Weber-Fox C, 2004, J SPEECH LANG HEAR R, V47, P1244, DOI 10.1044/1092-4388(2004/094)
   Weber-Fox C, 2001, J SPEECH LANG HEAR R, V44, P814, DOI 10.1044/1092-4388(2001/064)
   Weber-Fox C, 2008, J SPEECH LANG HEAR R, V51, P1058, DOI 10.1044/1092-4388(2008/07-0164)
   Weber-Fox C, 2013, J FLUENCY DISORD, V38, P206, DOI 10.1016/j.jfludis.2013.01.001
   WELLS BG, 1990, NEUROPSYCHOLOGIA, V28, P1295, DOI 10.1016/0028-3932(90)90045-P
   Xiang Ming, 2013, Front Psychol, V4, P708, DOI 10.3389/fpsyg.2013.00708
   Yaruss JS, 2006, J FLUENCY DISORD, V31, P90, DOI 10.1016/j.jfludis.2006.02.002
NR 80
TC 0
Z9 0
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0278-2626
EI 1090-2147
J9 BRAIN COGNITION
JI Brain Cogn.
PD DEC
PY 2018
VL 128
BP 17
EP 27
DI 10.1016/j.bandc.2018.10.009
PG 11
WC Neurosciences; Psychology, Experimental
SC Neurosciences & Neurology; Psychology
GA HE0EI
UT WOS:000452939200003
PM 30423511
DA 2021-02-24
ER

PT J
AU Barnaud, ML
   Bessiere, P
   Diard, J
   Schwartz, JL
AF Barnaud, Marie-Lou
   Bessiere, Pierre
   Diard, Julien
   Schwartz, Jean-Luc
TI Reanalyzing neurocognitive data on the role of the motor system in
   speech perception within COSMO, a Bayesian perceptuo-motor model of
   speech communication
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Computational modeling; Neurocognitive architecture; Perceptuo-motor
   interactions; Adverse conditions; Motor perturbations; Repeated
   transcranial stimulation; Motor representations; Speech perception
ID RELATIVE ONSET TIME; AUDIOVISUAL SPEECH; PLANUM TEMPORALE; AUDITORY
   SPEECH; PREMOTOR CORTEX; HEARING LIPS; TOP-DOWN; INTEGRATION; LANGUAGE;
   DISCRIMINATION
AB While neurocognitive data provide clear evidence for the involvement of the motor system in speech perception, its precise role and the way motor information is involved in perceptual decision remain unclear. In this paper, we discuss some recent experimental results in light of COSMO, a Bayesian perceptuo-motor model of speech communication. COSMO enables us to model both speech perception and speech production with probability distributions relating phonological units with sensory and motor variables. Speech perception is conceived as a sensory-motor architecture combining an auditory and a motor decoder thanks to a Bayesian fusion process. We propose the sketch of a neuroanatomical architecture for COSMO, and we capitalize on properties of the auditory vs. motor decoders to address three neurocognitive studies of the literature. Altogether, this computational study reinforces functional arguments supporting the role of a motor decoding branch in the speech perception process.
C1 [Barnaud, Marie-Lou; Schwartz, Jean-Luc] Univ Grenoble Alpes, Gipsa Lab, F-38000 Grenoble, France.
   [Barnaud, Marie-Lou; Schwartz, Jean-Luc] CNRS, Gipsa Lab, F-38000 Grenoble, France.
   [Barnaud, Marie-Lou; Diard, Julien] Univ Grenoble Alpes, LPNC, F-38000 Grenoble, France.
   [Barnaud, Marie-Lou; Diard, Julien] CNRS, LPNC, F-38000 Grenoble, France.
   [Bessiere, Pierre] SORBONNE Univ UPMC, ISIR, CNRS, Paris, France.
RP Schwartz, JL (corresponding author), Univ Grenoble Alpes, Gipsa Lab, F-38000 Grenoble, France.
EM marie-lou.barnaud@gipsa-lab.grenoble-inp.fr;
   jean-luc.schwartz@gipsa-lab.gre
OI Diard, Julien/0000-0003-0673-477X
FU European Research Council under the European CommunityEuropean Research
   Council (ERC) [339152]
FX The research leading to these results received funding from the European
   Research Council under the European Community's Seventh Framework
   Programme (FP7/2007-2013 Grant Agreement no. 339152, "Speech Unit(e)s",
   J.-L. Schwartz PI).
CR Andersen TS, 2015, J ACOUST SOC AM, V137, P2884, DOI 10.1121/1.4916691
   Bailly G, 1997, SPEECH COMMUN, V22, P251, DOI 10.1016/S0167-6393(97)00025-3
   Barnaud M. L., 2016, 6 JOINT IEEE INT C D
   Barnaud ML, 2015, 5TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING AND ON EPIGENETIC ROBOTICS (ICDL-EPIROB), P248, DOI 10.1109/DEVLRN.2015.7346149
   Beauchamp MS, 2010, J NEUROSCI, V30, P2414, DOI 10.1523/JNEUROSCI.4865-09.2010
   Bessiere P., 2013, BAYESIAN PROGRAMMING
   Bever TG, 2010, BIOLINGUISTICS, V4, P174
   Binder JR, 2004, NAT NEUROSCI, V7, P295, DOI 10.1038/nn1198
   Boe Luis-Jean, 2007, EXPT APPROACHES PHON, P104
   Bouchard KE, 2013, NATURE, V495, P327, DOI 10.1038/nature11911
   Buchsbaum BR, 2001, COGNITIVE SCI, V25, P663, DOI 10.1207/s15516709cog2505_2
   Callan D, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00275
   Callan DE, 2003, NEUROREPORT, V14, P2213, DOI 10.1097/00001756-200312020-00016
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155
   Cheung C, 2016, ELIFE, V5, DOI 10.7554/eLife.12577
   Colas F, 2010, ACTA BIOTHEOR, V58, P191, DOI 10.1007/s10441-010-9101-1
   D'Ausilio A, 2012, CORTEX, V48, P882, DOI 10.1016/j.cortex.2011.05.017
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   Davis C, 2004, Q J EXP PSYCHOL-A, V57, P1103, DOI 10.1080/02724980343000701
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014
   DEBOYSSONBARDIES B, 1984, J CHILD LANG, V11, P1, DOI 10.1017/S0305000900005559
   DEBOYSSONBARDIES B, 1989, J CHILD LANG, V16, P1, DOI 10.1017/S0305000900013404
   Diard J, 2015, BAYESIAN ALGORITHMIC
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   ERBER NP, 1969, J SPEECH HEAR RES, V12, P423, DOI 10.1044/jshr.1202.423
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Feldman NH, 2009, PSYCHOL REV, V116, P752, DOI 10.1037/a0017196
   Frey S, 2008, J NEUROSCI, V28, P11435, DOI 10.1523/JNEUROSCI.2388-08.2008
   Friederici AD, 2015, TRENDS COGN SCI, V19, P329, DOI 10.1016/j.tics.2015.03.012
   Friederici AD, 2013, CURR OPIN NEUROBIOL, V23, P250, DOI 10.1016/j.conb.2012.10.002
   Friederici AD, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020726
   Gick B, 2009, NATURE, V462, P502, DOI 10.1038/nature08572
   Gilet E, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020387
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Griffiths TD, 2002, TRENDS NEUROSCI, V25, P348, DOI 10.1016/S0166-2236(02)02191-4
   Guenther FH, 2006, BRAIN LANG, V96, P280, DOI 10.1016/j.bandl.2005.06.001
   Guenther FH, 2012, J NEUROLINGUIST, V25, P408, DOI 10.1016/j.jneuroling.2009.08.006
   Halle M, 1959, P SEM SPEECH COMPR P
   Hickok G, 2000, TRENDS COGN SCI, V4, P131, DOI 10.1016/S1364-6613(00)01463-7
   Hickok G, 2004, COGNITION, V92, P67, DOI 10.1016/j.cognition.2003.10.011
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2013, NEUROSCI LETT, V540, P56, DOI 10.1016/j.neulet.2012.11.001
   Hickok G, 2009, J NEUROPHYSIOL, V101, P2725, DOI 10.1152/jn.91099.2008
   Ito T, 2009, P NATL ACAD SCI USA, V106, P1245, DOI 10.1073/pnas.0810063106
   Jacquemot C, 2006, TRENDS COGN SCI, V10, P480, DOI 10.1016/j.tics.2006.09.002
   Jones JA, 2003, NEUROREPORT, V14, P1129, DOI 10.1097/00001756-200306110-00006
   JUSCZYK PW, 1980, J ACOUST SOC AM, V67, P262, DOI 10.1121/1.383735
   KLATT DH, 1980, J ACOUST SOC AM, V67, P971, DOI 10.1121/1.383940
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Lametti DR, 2014, J NEUROSCI, V34, P10339, DOI 10.1523/JNEUROSCI.0108-14.2014
   Laurent R, 2017, PSYCHOL REV, V124, P572, DOI 10.1037/rev0000069
   Laurent R, 2013, INTERSPEECH, P2796
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Liebenthal E, 2005, CEREB CORTEX, V15, P1621, DOI 10.1093/cercor/bhi040
   Lyu BJ, 2016, J NEUROSCI, V36, P10813, DOI 10.1523/JNEUROSCI.0583-16.2016
   Marr D., 1982, VISION COMPUTATIONAL
   Massaro D. W., 1998, PERCEIVING TALKING F, V1
   Massaro D. W., 1987, SPEECH PERCEPTION EA
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   McMurray B, 2009, DEVELOPMENTAL SCI, V12, P369, DOI 10.1111/j.1467-7687.2009.00822.x
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Mesgarani N, 2014, SCIENCE, V343, P1006, DOI 10.1126/science.1245994
   Miller LM, 2005, J NEUROSCI, V25, P5884, DOI 10.1523/JNEUROSCI.0896-05.2005
   Mottonen R, 2013, CEREB CORTEX, V23, P1190, DOI 10.1093/cercor/bhs110
   Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009
   Moulin-Frier C, 2012, LANG COGNITIVE PROC, V27, P1240
   Moulin-Frier C, 2015, J PHONETICS, V53, P5, DOI 10.1016/j.wocn.2015.06.001
   Obleser J, 2007, CEREB CORTEX, V17, P2251, DOI 10.1093/cercor/bhl133
   Ojanen V, 2005, NEUROIMAGE, V25, P333, DOI 10.1016/j.neuroimage.2004.12.001
   Okada K, 2009, NEUROSCI LETT, V452, P219, DOI 10.1016/j.neulet.2009.01.060
   Osnes B, 2011, NEUROIMAGE, V54, P2437, DOI 10.1016/j.neuroimage.2010.09.078
   Patri JF, 2016, INTERSPEECH, P3588, DOI 10.21437/Interspeech.2016-441
   Patri JF, 2015, BIOL CYBERN, V109, P611, DOI 10.1007/s00422-015-0664-4
   PAULESU E, 1993, NATURE, V362, P342, DOI 10.1038/362342a0
   PISONI DB, 1977, J ACOUST SOC AM, V61, P1352, DOI 10.1121/1.381409
   POLLACK I, 1971, PSYCHON SCI, V24, P299
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Reisberg D, 1987, HEARING EYE PSYCHOL, P97
   Repp B. H., 1984, SPEECH LANGUAGE ADV, V10, P244
   Rogers JC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00754
   Sato M, 2011, CORTEX, V47, P1001, DOI 10.1016/j.cortex.2011.03.009
   Sato M, 2009, BRAIN LANG, V111, P1, DOI 10.1016/j.bandl.2009.03.002
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Schwartz J., 1998, HEARING EYE, P85
   Schwartz JL, 2016, PHYS LIFE REV, V16, P93, DOI 10.1016/j.plrev.2016.01.007
   Schwartz JL, 2012, J NEUROLINGUIST, V25, P336, DOI 10.1016/j.jneuroling.2009.12.004
   Schwartz JL, 2010, J ACOUST SOC AM, V127, P1584, DOI 10.1121/1.3293001
   Schwartz JL, 2002, PHONETICS PHONOLOGY, P255
   Shiller DM, 2009, J ACOUST SOC AM, V125, P1103, DOI 10.1121/1.3058638
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Sprenger-Charolles L, 2003, BEHAV BRAIN COGNITIO, V1, P1
   Stevens Kenneth N., 1972, HUMAN COMMUNICATION, P51
   STEVENS KN, 1989, J PHONETICS, V17, P3, DOI 10.1016/S0095-4470(19)31520-7
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Summerfield Q., 1987, HEARING EYE PSYCHOL, P3, DOI DOI 10.2307/1423237
   Vallabha GK, 2007, P NATL ACAD SCI USA, V104, P13273, DOI 10.1073/pnas.0705369104
   Wilson SM, 2006, NEUROIMAGE, V33, P316, DOI 10.1016/j.neuroimage.2006.05.032
   Zekveld AA, 2006, NEUROIMAGE, V32, P1826, DOI 10.1016/j.neuroimage.2006.04.199
NR 103
TC 4
Z9 4
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD DEC
PY 2018
VL 187
BP 19
EP 32
DI 10.1016/j.bandl.2017.12.003
PG 14
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA HE0DL
UT WOS:000452936900004
PM 29241588
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Nuttall, HE
   Kennedy-Higgins, D
   Devlin, JT
   Adank, P
AF Nuttall, Helen E.
   Kennedy-Higgins, Dan
   Devlin, Joseph T.
   Adank, Patti
TI Modulation of intra- and inter-hemispheric connectivity between primary
   and premotor cortex during speech perception
SO BRAIN AND LANGUAGE
LA English
DT Article
ID THETA-BURST STIMULATION; PRIMARY MOTOR CORTEX; INTERHEMISPHERIC
   INHIBITION; CORTICAL PLASTICITY; EXCITABILITY; AREAS; FACILITATION;
   SYSTEM; STREAM; COMPREHENSION
AB Primary motor (M1) areas for speech production activate during speech perception. It has been suggested that such activation may be dependent upon modulatory inputs from premotor cortex (PMv). If and how PMv differentially modulates M1 activity during perception of speech that is easy or challenging to understand, however, is unclear. This study aimed to test the link between PMv and M1 during challenging speech perception in two experiments. The first experiment investigated intra-hemispheric connectivity between left hemisphere PMv and left M1 lip area during comprehension of speech under clear and distorted listening conditions. Continuous theta burst stimulation (cTBS) was applied to left PMv in eighteen participants (aged 18-35). Post-cTBS, participants performed a sentence verification task on distorted (imprecisely articulated), and clear speech, whilst also undergoing stimulation of the lip representation in the left M1 to elicit motor evoked potentials (MEPs). In a second, separate experiment, we investigated the role of inter-hemispheric connectivity between right hemisphere PMv and left hemisphere M1 lip area. Dual-coil transcranial magnetic stimulation was applied to right PMv and left M1 lip in fifteen participants (aged 18-35). Results indicated that disruption of PMv during speech perception affects comprehension of distorted speech specifically. Furthermore, our data suggest that listening to distorted speech modulates the balance of intra- and inter-hemispheric interactions, with a larger sensorimotor network implicated during comprehension of distorted speech than when speech perception is optimal. The present results further understanding of PMv-M1 interactions during auditory-motor integration.
C1 [Nuttall, Helen E.] Univ Lancaster, Fylde Coll, Dept Psychol, Lancaster LA1 4YF, England.
   [Nuttall, Helen E.; Kennedy-Higgins, Dan; Adank, Patti] UCL, Dept Speech Hearing & Phonet Sci, Chandler House,2 Wakefield St, London WC1N 1PF, England.
   [Devlin, Joseph T.] UCL, Dept Expt Psychol, 26 Bedford Way, London WC1H 0AP, England.
RP Nuttall, HE (corresponding author), Univ Lancaster, Dept Psychol, Fylde Coll, D5, Bailrigg LA1 4YW, England.
EM h.nuttall1@lancaster.ac.uk
OI Nuttall, Helen/0000-0001-8497-5603; Kennedy-Higgins,
   Dan/0000-0002-7499-8833
FU Leverhulme TrustLeverhulme Trust
FX This work was supported by a Project Grant from The Leverhulme Trust
   (RPG-2013-13 254). Our thanks go to The Leverhulme Trust, and the
   individuals who participated in this study.
CR Adank P, 2009, J EXP PSYCHOL HUMAN, V35, P520, DOI 10.1037/a0013552
   Baddeley A. D, 1992, THE SPEED AND CAPACI
   British Society of Audiology, 2011, REC PROC PUR TON AIR
   Catmur C, 2011, J COGNITIVE NEUROSCI, V23, P2352, DOI 10.1162/jocn.2010.21590
   Chen R, 2004, EXP BRAIN RES, V154, P1, DOI 10.1007/s00221-003-1684-1
   D'Ausilio A, 2012, CORTEX, V48, P882, DOI 10.1016/j.cortex.2011.05.017
   D'Ostilio K, 2016, CLIN NEUROPHYSIOL, V127, P675, DOI 10.1016/j.clinph.2015.05.017
   Davare M, 2008, J PHYSIOL-LONDON, V586, P2735, DOI 10.1113/jphysiol.2008.152603
   de Beukelaar TT, 2016, CORTEX, V75, P180, DOI 10.1016/j.cortex.2015.11.009
   Devlin JT, 2003, J COGNITIVE NEUROSCI, V15, P71, DOI 10.1162/089892903321107837
   Di Lazzaro V, 1999, EXP BRAIN RES, V124, P520, DOI 10.1007/s002210050648
   Dial H, 2017, NEUROPSYCHOLOGIA, V96, P192, DOI 10.1016/j.neuropsychologia.2017.01.009
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Frey S, 2008, J NEUROSCI, V28, P11435, DOI 10.1523/JNEUROSCI.2388-08.2008
   Goldsworthy MR, 2016, CLIN NEUROPHYSIOL, V127, P740, DOI 10.1016/j.clinph.2015.06.014
   Hannah R, 2017, BRAIN STIMUL, V10, P106, DOI 10.1016/j.brs.2016.09.008
   Hannah R, 2016, FRONT NEURAL CIRCUIT, V10, DOI 10.3389/fncir.2016.00097
   Hickok G, 2012, J COMMUN DISORD, V45, P393, DOI 10.1016/j.jcomdis.2012.06.004
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Hordacre B, 2017, BRAIN STIMUL, V10, P588, DOI 10.1016/j.brs.2016.12.001
   Huang YZ, 2005, NEURON, V45, P201, DOI 10.1016/j.neuron.2004.12.033
   Krieger-Redwood K, 2013, J COGNITIVE NEUROSCI, V25, P2179, DOI 10.1162/jocn_a_00463
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Mochizuki H, 2004, J PHYSIOL-LONDON, V561, P331, DOI 10.1113/jphysiol.2004.072843
   Mottonen R, 2014, JOVE-J VIS EXP, DOI 10.3791/51665
   Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009
   Murakami T, 2015, J NEUROSCI, V35, P1411, DOI 10.1523/JNEUROSCI.0246-14.2015
   Murakami T, 2012, BRAIN LANG, V122, P135, DOI 10.1016/j.bandl.2011.09.005
   Murakami T, 2011, NEUROPSYCHOLOGIA, V49, P2045, DOI 10.1016/j.neuropsychologia.2011.03.034
   Ni Z, 2009, CEREB CORTEX, V19, P1654, DOI 10.1093/cercor/bhn201
   Nuttall HE, 2017, NEUROPSYCHOLOGIA, V94, P13, DOI 10.1016/j.neuropsychologia.2016.11.016
   Nuttall HE, 2016, NEUROIMAGE, V128, P218, DOI 10.1016/j.neuroimage.2015.12.038
   Pobric G, 2007, P NATL ACAD SCI USA, V104, P20137, DOI 10.1073/pnas.0707383104
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Ridding MC, 2010, J PHYSIOL-LONDON, V588, P2291, DOI 10.1113/jphysiol.2010.190314
   Rogers JC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00754
   Roy AC, 2008, J PHYSIOLOGY-PARIS, V102, P101, DOI 10.1016/j.jphysparis.2008.03.006
   Sato M, 2009, BRAIN LANG, V111, P1, DOI 10.1016/j.bandl.2009.03.002
   Saur D, 2010, NEUROIMAGE, V49, P3187, DOI 10.1016/j.neuroimage.2009.11.009
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Schomers MR, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00435
   Schomers MR, 2015, CEREB CORTEX, V25, P3894, DOI 10.1093/cercor/bhu274
   Silbert LJ, 2014, P NATL ACAD SCI USA, V111, pE4687, DOI 10.1073/pnas.1323812111
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Vallence AM, 2015, NEUROSCIENCE, V304, P266, DOI 10.1016/j.neuroscience.2015.07.043
   Vernet M, 2014, CLIN NEUROPHYSIOL, V125, P320, DOI 10.1016/j.clinph.2013.07.004
   Vigneau M, 2006, NEUROIMAGE, V30, P1414, DOI 10.1016/j.neuroimage.2005.11.002
   Volz L. J, 2014, CEREBRAL CORTEX NEW, P1, DOI [10.1093/cercor/bhu032Friston1994, DOI 10.1093/CERCOR/BHU032FRISTON1994]
   Watkins K, 2004, J COGNITIVE NEUROSCI, V16, P978, DOI 10.1162/0898929041502616
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   Whitney C, 2011, CEREB CORTEX, V21, P1066, DOI 10.1093/cercor/bhq180
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Wilson SM, 2006, NEUROIMAGE, V33, P316, DOI 10.1016/j.neuroimage.2006.05.032
NR 54
TC 4
Z9 4
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD DEC
PY 2018
VL 187
BP 74
EP 82
DI 10.1016/j.bandl.2017.12.002
PG 9
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA HE0DL
UT WOS:000452936900008
PM 29397191
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Sato, M
   Shiller, DM
AF Sato, Marc
   Shiller, Douglas M.
TI Auditory prediction during speaking and listening
SO BRAIN AND LANGUAGE
LA English
DT Article
DE Speech motor control; Auditory speech perception; Sensorimotor
   adaptation; Auditory feedback; Speech-induced suppression; EEG
ID COROLLARY DISCHARGE DYSFUNCTION; SENSORIMOTOR ADAPTATION; SPEECH
   PRODUCTION; ELECTROPHYSIOLOGICAL EVIDENCE; REPETITION SUPPRESSION;
   FORMANT TRAJECTORIES; FEEDBACK-CONTROL; MOTOR; CORTEX; ACQUISITION
AB In the present EEG study, the role of auditory prediction in speech was explored through the comparison of auditory cortical responses during active speaking and passive listening to the same acoustic speech signals. Two manipulations of sensory prediction accuracy were used during the speaking task: (1) a real-time change in vowel F1 feedback (reducing prediction accuracy relative to unaltered feedback) and (2) presenting a stable auditory target rather than a visual cue to speak (enhancing auditory prediction accuracy during baseline productions, and potentially enhancing the perturbing effect of altered feedback). While subjects compensated for the F1 manipulation, no difference between the auditory-cue and visual-cue conditions were found. Under visually-cued conditions, reduced N1/P2 amplitude was observed during speaking vs. listening, reflecting a motor-to-sensory prediction. In addition, a significant correlation was observed between the magnitude of behavioral compensatory F1 response and the magnitude of this speaking induced suppression (SIS) for P2 during the altered auditory feedback phase, where a stronger compensatory decrease in F1 was associated with a stronger the SIS effect. Finally, under the auditory-cued condition, an auditory repetition-suppression effect was observed in N1/P2 amplitude during the listening task but not active speaking, suggesting that auditory predictive processes during speaking and passive listening are functionally distinct.
C1 [Sato, Marc] Aix Marseille Univ, Lab Parole & Langage, Aix En Provence, France.
   [Sato, Marc] CNRS, Aix En Provence, France.
   [Sato, Marc] Brain & Language Res Inst, Aix En Provence, France.
   [Shiller, Douglas M.] Univ Montreal, Sch Speech Language Pathol & Audiol, Montreal, PQ, Canada.
   [Shiller, Douglas M.] Sainte Justine Hosp, Res Ctr, Montreal, PQ, Canada.
   [Shiller, Douglas M.] Ctr Res Brain Language & Mus, Montreal, PQ, Canada.
RP Shiller, DM (corresponding author), Univ Montreal, Fac Med, Ecole Orthophonie & Audiol, CF 6128,Succursale Ctr Ville, Montreal, PQ H3C 3J7, Canada.
EM douglas.shiller@umontreal.ca
FU Brain and Language Research Institute; National Institutes of Health -
   United StatesUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R01DC012502]; Natural Sciences and
   Engineering Research Council (NSERC-Canada)Natural Sciences and
   Engineering Research Council of Canada (NSERC); NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC012502, R01DC012502, R01DC012502, R01DC012502, R01DC012502]
   Funding Source: NIH RePORTER
FX This study was supported by research grants from the Brain and Language
   Research Institute to MS and DMS, the National Institutes of Health -
   United States (R01DC012502) and the Natural Sciences and Engineering
   Research Council (NSERC-Canada). We thank Thierry Legou, Virginie
   Epting, Deidre Bolger and Nadera Bureau for their help with this study.
CR Behroozmand R, 2011, BMC NEUROSCI, V12, DOI 10.1186/1471-2202-12-54
   Bourguignon NJ, 2016, J EXP PSYCHOL HUMAN, V42, P1039, DOI 10.1037/xhp0000209
   Bourguignon Nicolas J, 2014, Front Hum Neurosci, V8, P208, DOI 10.3389/fnhum.2014.00208
   Cai S., 2008, PROCEEDINGS OF THE 8, P65
   Cai SQ, 2014, BRAIN LANG, V129, P24, DOI 10.1016/j.bandl.2014.01.002
   Cai SQ, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0041830
   Cai SQ, 2011, J NEUROSCI, V31, P16483, DOI 10.1523/JNEUROSCI.3653-11.2011
   Cai SQ, 2010, J ACOUST SOC AM, V128, P2033, DOI 10.1121/1.3479539
   Chang EF, 2013, P NATL ACAD SCI USA, V110, P2653, DOI 10.1073/pnas.1216827110
   Chen CMA, 2011, J COGNITIVE NEUROSCI, V23, P2892, DOI 10.1162/jocn.2010.21589
   Chen SH, 2007, J ACOUST SOC AM, V121, P1157, DOI 10.1121/1.2404624
   CREUTZFELDT O, 1989, EXP BRAIN RES, V77, P476, DOI 10.1007/BF00249601
   Curio G, 2000, HUM BRAIN MAPP, V9, P183, DOI 10.1002/(SICI)1097-0193(200004)9:4<183::AID-HBM1>3.0.CO;2-Z
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Eliades SJ, 2003, J NEUROPHYSIOL, V89, P2194, DOI 10.1152/jn.00627.2002
   Espy-Wilson C, 2000, P ICSLP 2000 BEIJ CH
   Flinker A, 2010, J NEUROSCI, V30, P16643, DOI 10.1523/JNEUROSCI.1809-10.2010
   Ford JM, 2004, J PSYCHIATR RES, V38, P37, DOI 10.1016/S0022-3956(03)00095-5
   Ford JM, 2001, AM J PSYCHIAT, V158, P2069, DOI 10.1176/appi.ajp.158.12.2069
   Ford JM, 2010, NAT PROTOC, V5, P1160, DOI 10.1038/nprot.2010.67
   Franken MK, 2015, BRAIN LANG, V142, P18, DOI 10.1016/j.bandl.2015.01.001
   Friston KJ, 2012, COGN NEUROSCI-UK, V3, P238, DOI 10.1080/17588928.2012.691277
   Garrido MI, 2009, NEUROIMAGE, V48, P269, DOI 10.1016/j.neuroimage.2009.06.034
   Gotts SJ, 2012, COGN NEUROSCI-UK, V3, P227, DOI 10.1080/17588928.2012.670617
   Grill-Spector K, 2006, TRENDS COGN SCI, V10, P14, DOI 10.1016/j.tics.2005.11.006
   GUENTHER FH, 1994, BIOL CYBERN, V72, P43, DOI 10.1007/BF00206237
   Heinks-Maldonado TH, 2006, NEUROREPORT, V17, P1375, DOI 10.1097/01.wnr.0000233102.43526.e9
   HELD R, 1963, SCIENCE, V142, P455, DOI 10.1126/science.142.3591.455
   Henson RN, 2012, COGN NEUROSCI-UK, V3, P240, DOI 10.1080/17588928.2012.689962
   Houde JF, 1998, SCIENCE, V279, P1213, DOI 10.1126/science.279.5354.1213
   Houde JF, 2002, J COGNITIVE NEUROSCI, V14, P1125, DOI 10.1162/089892902760807140
   Houde JF, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00082
   Jones JA, 2000, J ACOUST SOC AM, V108, P1246, DOI 10.1121/1.1288414
   Jones JA, 2005, CURR BIOL, V15, P1768, DOI 10.1016/j.cub.2005.08.063
   Kawato M, 1999, CURR OPIN NEUROBIOL, V9, P718, DOI 10.1016/S0959-4388(99)00028-8
   KUHL PK, 1991, PERCEPT PSYCHOPHYS, V50, P93, DOI 10.3758/BF03212211
   Lametti DR, 2014, PSYCHOL SCI, V25, P1325, DOI 10.1177/0956797614529978
   Lametti DR, 2012, J NEUROSCI, V32, P9351, DOI 10.1523/JNEUROSCI.0404-12.2012
   Lombard E., 1911, ANN MALADIES OREILLE, V37, P101
   Miall RC, 1996, NEURAL NETWORKS, V9, P1265, DOI 10.1016/S0893-6080(96)00035-4
   Mollaei F, 2013, MOVEMENT DISORD, V28, P1668, DOI 10.1002/mds.25588
   NAATANEN R, 1987, PSYCHOPHYSIOLOGY, V24, P375, DOI 10.1111/j.1469-8986.1987.tb00311.x
   Niziolek CA, 2013, J NEUROSCI, V33, P16110, DOI 10.1523/JNEUROSCI.2137-13.2013
   Numminen J, 1999, NEUROSCI LETT, V265, P119, DOI 10.1016/S0304-3940(99)00218-9
   Numminen J, 1999, NEUROSCI LETT, V272, P29, DOI 10.1016/S0304-3940(99)00573-X
   Oestreich LKL, 2015, INT J PSYCHOPHYSIOL, V97, P131, DOI 10.1016/j.ijpsycho.2015.05.014
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Oostenveld R, 2001, CLIN NEUROPHYSIOL, V112, P713, DOI 10.1016/S1388-2457(00)00527-7
   PANTEV C, 1995, ELECTROEN CLIN NEURO, V94, P26, DOI 10.1016/0013-4694(94)00209-4
   Perez VB, 2012, SCHIZOPHRENIA BULL, V38, P1216, DOI 10.1093/schbul/sbr124
   Purcell DW, 2006, J ACOUST SOC AM, V119, P2288, DOI 10.1121/1.2173514
   Rochet-Capellan A, 2011, J NEUROSCI, V31, P2657, DOI 10.1523/JNEUROSCI.6020-10.2011
   Sato M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00422
   SCHERG M, 1986, ELECTROEN CLIN NEURO, V65, P344, DOI 10.1016/0168-5597(86)90014-6
   Shadmehr R, 2010, ANNU REV NEUROSCI, V33, P89, DOI 10.1146/annurev-neuro-060909-153135
   Shiller DM, 2014, J EXP PSYCHOL HUMAN, V40, P1308, DOI 10.1037/a0036660
   Shiller DM, 2009, J ACOUST SOC AM, V125, P1103, DOI 10.1121/1.3058638
   Sitek KR, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082925
   Tourville J. A., 2013, P M AC 165 M AC SOC, V9
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   Ventura MI, 2009, BMC NEUROSCI, V10, DOI 10.1186/1471-2202-10-58
   Villacorta VM, 2007, J ACOUST SOC AM, V122, P2306, DOI 10.1121/1.2773966
   VONHELMHOLTZ H, 1925, TREATISE PHYSL OPTIC, V3
   Wang J, 2014, NEUROIMAGE, V91, P91, DOI 10.1016/j.neuroimage.2014.01.003
   Woods DL, 1995, EEG CL N SU, P102
NR 65
TC 7
Z9 7
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0093-934X
EI 1090-2155
J9 BRAIN LANG
JI Brain Lang.
PD DEC
PY 2018
VL 187
BP 92
EP 103
DI 10.1016/j.bandl.2018.01.008
PG 12
WC Audiology & Speech-Language Pathology; Linguistics; Neurosciences;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Neurosciences &
   Neurology; Psychology
GA HE0DL
UT WOS:000452936900010
PM 29402437
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Kwak, C
   Han, W
   Lee, J
   Kim, J
   Kim, S
AF Kwak, Chanbeom
   Han, Woojae
   Lee, Jihyeon
   Kim, Jinsook
   Kim, Sungkyun
TI Effect of noise and reverberation on speech recognition and listening
   effort for older adults
SO GERIATRICS & GERONTOLOGY INTERNATIONAL
LA English
DT Article
DE aging; background noise; listening effort; reverberation; speech
   recognition
ID INTELLIGIBILITY; FATIGUE
AB Aim The purpose of the present study was to evaluate the speech recognition ability and degree of listening effort for older adults in noisy and reverberating environments. Methods A total of 80 participants (40 older and 40 younger adults) participated in a sentence recognition test under 20 conditions with four levels of background noise and five levels of reverberation time. In each condition, the degree of listening effort was self-reported using a 5-point Likert scale. Results The older and younger groups showed that both the error percentage of the sentence recognition task and scale of the listening effort increased as the background noise and reverberation time increased. In the sentence recognition task, the older group was more affected by the reverberation condition than the noisy background compared with their younger counterparts. For the listening effort, the older group had higher scales than the younger group in all conditions, thereby explaining that they required significant effort during the listening task. Conclusions The older adults had poorer speech perception ability and required more listening effort than their younger counterparts in all conditions. Reverberation reversely significantly affected the speech recognition and listening effort for the older adults when compared with the background noise, suggesting that an appropriate level of noise and reverberation should be considered for comfort and a less stressful listening environment for the older adult population. Geriatr Gerontol Int 2018; 18: 1603-1608.
C1 [Kwak, Chanbeom; Lee, Jihyeon] Hallym Univ, Grad Sch, Dept Speech Pathol & Audiol, Chunchon, South Korea.
   [Han, Woojae; Kim, Jinsook] Hallym Univ, Div Speech Pathol & Audiol, Coll Nat Sci, Chunchon, South Korea.
   [Kim, Sungkyun] Hallym Univ, Dongtan Scared Heart Hosp, Dept Otorhinolaryngol Head & Neck Surg, Hwaseong, South Korea.
RP Han, W (corresponding author), Hallym Univ, 8603 Nat Sci Bldg,1 Hallymdaehak Gil, Chunchon 24252, Kangwon Do, South Korea.
EM woojaehan@hallym.ac.kr
RI Lee, Jihyeon/K-3199-2016
OI Han, Woojae/0000-0003-1623-9676; kwak, chanbeom/0000-0001-5657-7536
FU Hallym University Research Fund [H20180250]; Ministry of Education of
   the Republic of Korea; National Research Foundation of KoreaNational
   Research Foundation of Korea [NRF-2015S1A3A2046760]
FX We are grateful to Dr. Jungho Jung (Fire Insurers Laboratories of Korea)
   for developing our simulation model. This work was supported by Hallym
   University Research Fund 2018 (H20180250) and the Ministry of Education
   of the Republic of Korea and the National Research Foundation of Korea
   (NRF-2015S1A3A2046760).
CR Brons I, 2013, EAR HEARING, V34, P29, DOI 10.1097/AUD.0b013e31825f299f
   Gosselin PA, 2011, J SPEECH LANG HEAR R, V54, P944, DOI 10.1044/1092-4388(2010/10-0069)
   Hazrati O, 2012, INT J AUDIOL, V51, P437, DOI 10.3109/14992027.2012.658972
   HELFER KS, 1990, J SPEECH HEAR RES, V33, P149, DOI 10.1044/jshr.3301.149
   HELFER KS, 1992, J SPEECH HEAR RES, V35, P1394, DOI 10.1044/jshr.3506.1394
   Hodgson M, 2002, J ACOUST SOC AM, V111, P931, DOI 10.1121/1.1428264
   Holube I., 2016, TRENDS HEAR, V20, P1
   Hornsby BWY, 2013, EAR HEARING, V34, P523, DOI 10.1097/AUD.0b013e31828003d8
   Howard CS, 2010, INT J AUDIOL, V49, P928, DOI 10.3109/14992027.2010.520036
   International Organization for Standardization, 2000, 7029 ISO
   Johnson J, 2015, AM J AUDIOL, V24, P419, DOI 10.1044/2015_AJA-14-0058
   Kahneman D., 1973, ATTENTION EFFORT
   KIM JS, 2000, KOREAN J SPEECH SCI, V7, P37
   Kwon Y. C., 1989, J KOREAN NEUROPSYCHI, V28, P125
   McGarrigle R, 2014, INT J AUDIOL, V53, P433, DOI 10.3109/14992027.2014.890296
   Obleser J, 2011, NEUROIMAGE, V55, P713, DOI 10.1016/j.neuroimage.2010.12.020
   Peelle JE, 2018, EAR HEARING, V39, P204, DOI 10.1097/AUD.0000000000000494
   Picou EM, 2016, EAR HEARING, V37, P1, DOI 10.1097/AUD.0000000000000222
   Piquado T, 2010, PSYCHOPHYSIOLOGY, V47, P560, DOI 10.1111/j.1469-8986.2009.00947.x
   Rennies J, 2014, J ACOUST SOC AM, V136, P2642, DOI 10.1121/1.4897398
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
NR 21
TC 3
Z9 3
U1 0
U2 8
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1444-1586
EI 1447-0594
J9 GERIATR GERONTOL INT
JI Geriatr. Gerontol. Int.
PD DEC
PY 2018
VL 18
IS 12
BP 1603
EP 1608
DI 10.1111/ggi.13535
PG 6
WC Geriatrics & Gerontology; Gerontology
SC Geriatrics & Gerontology
GA HE1QD
UT WOS:000453046900004
PM 30328231
DA 2021-02-24
ER

PT J
AU Noel, JP
   De Niear, MA
   Lazzara, NS
   Wallace, MT
AF Noel, Jean-Paul
   De Niear, Matthew A.
   Lazzara, Nicholas S.
   Wallace, Mark T.
TI Uncoupling Between Multisensory Temporal Function and Nonverbal
   Turn-Taking in Autism Spectrum Disorder
SO IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS
LA English
DT Article
DE Autism; body; communication; interaction; multisensory; nonverbal
ID SOCIAL-INTERACTION; SPEECH-PERCEPTION; ASPERGER-SYNDROME; BODY MOVEMENT;
   COMMUNICATION; CHILDREN; ROBOTS; LANGUAGE; INDIVIDUALS; RELIABILITY
AB The integration of information across distinct modalities enhances perceptual abilities. An ecologically important role of multisensory integration is in scaffolding verbal communication, which relies upon the precise temporal integration of auditory and visual cues. However, the role of (multi)sensory function in supporting another important aspect of communication, namely, nonverbal communication, is unknown. Here, individuals with autism spectrum disorder (ASD) and a group of typically developing (TD) participants performed a simultaneity judgment task to index their audiovisual temporal acuity for speech stimuli. Further, under a naturalistic scenario, nonverbal synchrony between the participant and a naive experimenter was measured. Automated motion analysis was performed to quantify movements of different body-parts. Results demonstrate a wider window of audiovisual temporal integration for ASD participants in comparison to their TD counterparts. Moreover, ASD individuals performed less complex movements and demonstrated less nonverbal synchrony during the interactive exchange. Lastly, multisensory temporal acuity significantly predicted the synchrony in hand and head movements between TD participants and the experimenter, but not between the ASD participants and the experimenter. Taken together, the results suggest an important role for multisensory perceptual abilities in shaping nonverbal communication between dyads and highlight the important role of perceptual systems in supporting social interactive skills.
C1 [Noel, Jean-Paul; De Niear, Matthew A.; Lazzara, Nicholas S.; Wallace, Mark T.] Vanderbilt Univ, Vanderbilt Brain Inst, Nashville, TN 37232 USA.
RP Noel, JP (corresponding author), Vanderbilt Univ, Vanderbilt Brain Inst, Nashville, TN 37232 USA.
EM jean-paul.noel@vanderbilt.edu
OI Wallace, Mark/0000-0002-0166-906X; Noel, Jean-Paul/0000-0001-5297-3363
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [HD083211, MH109225]
FX This work was supported by NIH under Grant HD083211 and Grant MH109225.
CR Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029
   American Psychiatric Association, 2013, DIAGN STAT MAN MENT, V5th
   Bailenson JN, 2004, PRESENCE-VIRTUAL AUG, V13, P428, DOI 10.1162/1054746041944803
   Baron-Cohen S, 2004, J AUTISM DEV DISORD, V34, P163, DOI 10.1023/B:JADD.0000022607.19833.00
   Baud-Bovy G., 2014, BIOINSPIRED APPROACH, P241
   Baum SH, 2015, PROG NEUROBIOL, V134, P140, DOI 10.1016/j.pneurobio.2015.09.007
   Billard A, 1999, ADAPT BEHAV, V7, P415, DOI 10.1177/105971239900700311
   Bisio A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0106172
   Breazeal C., 2002, DESIGNING SOCIABLE R
   Brown L., 2010, TEST NONVERBAL INTEL
   Castelli F, 2002, BRAIN, V125, P1839, DOI 10.1093/brain/awf189
   Celani G, 1999, J AUTISM DEV DISORD, V29, P57, DOI 10.1023/A:1025970600181
   Chamberlain B, 2007, J AUTISM DEV DISORD, V37, P230, DOI 10.1007/s10803-006-0164-4
   Coey C, 2011, EXP BRAIN RES, V211, P483, DOI 10.1007/s00221-011-2689-9
   Couzin ID, 2005, NATURE, V433, P513, DOI 10.1038/nature03236
   Dautenhahn K, 2007, PHILOS T R SOC B, V362, P679, DOI 10.1098/rstb.2006.2004
   Van de Cruys S, 2014, PSYCHOL REV, V121, P649, DOI 10.1037/a0037665
   De Niear MA, 2017, NEURAL PLAST, V2017, DOI 10.1155/2017/3478742
   de Vos C, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00268
   Diehl JJ, 2012, RES AUTISM SPECT DIS, V6, P249, DOI 10.1016/j.rasd.2011.05.006
   DIXON NF, 1980, PERCEPTION, V9, P719, DOI 10.1068/p090719
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Flack JC, 2013, CURR BIOL, V23, pR967, DOI 10.1016/j.cub.2013.10.001
   Fong T., 2001, P INT S ROB RES, P255, DOI DOI 10.1055/S-0031-1280784
   Foss-Feig JH, 2010, EXP BRAIN RES, V203, P381, DOI 10.1007/s00221-010-2240-4
   Frassinetti F, 2002, EXP BRAIN RES, V147, P332, DOI 10.1007/s00221-002-1262-y
   Gardner M. F., 1990, EXPRESSIVE ONE WORD
   GEPNER B, 1995, NEUROREPORT, V6, P1211, DOI 10.1097/00001756-199505300-00034
   Goodrich Michael A, 2007, Foundations and Trends in Human-Computer Interaction, V1, P203, DOI 10.1561/1100000005
   Grammer K, 1999, J PERS SOC PSYCHOL, V77, P487, DOI 10.1037/0022-3514.77.3.487
   Grice H. Paul, 1975, SYNTAX SEMANTICS, V3, P41, DOI [10.1057/9780230005853_5., DOI 10.1111/J.1365-2664.2006.01229.X]
   Hancock PA, 2011, HUM FACTORS, V53, P517, DOI 10.1177/0018720811417254
   Kanda T, 2007, IEEE T ROBOT, V23, P962, DOI 10.1109/TRO.2007.904904
   Kanner L, 1943, NERV CHILD, V2, P217
   Keetels M, 2012, NEURAL BASEMULTISE, P147
   Kidd CD, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3230, DOI 10.1109/IROS.2008.4651113
   Klin A, 2000, J AUTISM DEV DISORD, V30, P163, DOI 10.1023/A:1005415823867
   Klin A, 2009, NATURE, V459, P257, DOI 10.1038/nature07868
   Kupper Z, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145882
   Kupper Z, 2010, SCHIZOPHR RES, V121, P90, DOI 10.1016/j.schres.2010.03.032
   Kwakye LD, 2011, FRONT INTEGR NEUROSC, V4, DOI 10.3389/fnint.2010.00129
   LEMPEL A, 1976, IEEE T INFORM THEORY, V22, P75, DOI 10.1109/TIT.1976.1055501
   Levinson SC, 2016, TRENDS COGN SCI, V20, P6, DOI 10.1016/j.tics.2015.10.010
   Lohan KS, 2014, TOP COGN SCI, V6, P492, DOI 10.1111/tops.12098
   Lord C, 2000, J AUTISM DEV DISORD, V30, P205, DOI 10.1023/A:1005592401947
   LORD C, 1994, J AUTISM DEV DISORD, V24, P659, DOI 10.1007/BF02172145
   Magyari L, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00376
   Marco EJ, 2011, PEDIATR RES, V69, p48R, DOI [10.1203/PDR.0b013e3182130c54, 10.1109/SPL.2011.5782616]
   MEREDITH MA, 1987, J NEUROSCI, V7, P3215
   Molloy CA, 2003, J AUTISM DEV DISORD, V33, P643, DOI 10.1023/B:JADD.0000006001.00667.4c
   MORRISSUZUKI T, 1984, NEW LEFT REV, P109
   MUNDY P, 1987, J AUTISM DEV DISORD, V17, P349, DOI 10.1007/BF01487065
   MUNDY P, 1986, J CHILD PSYCHOL PSYC, V27, P657, DOI 10.1111/j.1469-7610.1986.tb00190.x
   Murray M.M., 2012, NEURAL BASEMULTISE
   Noel JP, 2017, EPILEPSY BEHAV, V70, P166, DOI 10.1016/j.yebeh.2017.02.018
   Noel JP, 2017, SCHIZOPHR RES, V179, P8, DOI 10.1016/j.schres.2016.09.021
   Noel JP, 2017, AUTISM RES, V10, P121, DOI 10.1002/aur.1633
   Noel JP, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161698
   Noel JP, 2016, J VISION, V16, DOI 10.1167/16.3.21
   Noel JP, 2016, NEUROPSYCHOLOGIA, V82, P84, DOI 10.1016/j.neuropsychologia.2016.01.005
   Noel JP, 2015, SCI REP-UK, V5, DOI 10.1038/srep17467
   Ostrom E, 2000, J ECON PERSPECT, V14, P137, DOI 10.1257/jep.14.3.137
   OZONOFF S, 1995, NEUROPSYCHOLOGY, V9, P491, DOI 10.1037/0894-4105.9.4.491
   Pellicano E, 2007, CURR BIOL, V17, P1508, DOI 10.1016/j.cub.2007.07.065
   Pellicano E, 2012, TRENDS COGN SCI, V16, P504, DOI 10.1016/j.tics.2012.08.009
   PREISING B, 1991, IEEE ENG MED BIOL, V10, P13, DOI 10.1109/51.82001
   Ramseyer F., 2006, CONSTRUCTIVISM HUMAN, V11, P150
   Ramseyer F., 2008, SIMULTANEITY TEMPORA, P329, DOI [10.1142/9789812792426_0020, DOI 10.1142/9789812792426_0020]
   Ramseyer F, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00979
   Ramseyer F, 2011, J CONSULT CLIN PSYCH, V79, P284, DOI 10.1037/a0023419
   Redcay E, 2008, NEUROSCI BIOBEHAV R, V32, P123, DOI 10.1016/j.neubiorev.2007.06.004
   Robins B, 2006, INTERACT STUD, V7, P479
   Rogoff B, 2003, CULTURAL NATURE HUMA
   Schaal S, 1999, TRENDS COGN SCI, V3, P233, DOI 10.1016/S1364-6613(99)01327-3
   Sciutti A, 2012, INT J SOC ROBOT, V4, P223, DOI 10.1007/s12369-012-0143-1
   Semel E., 2003, CELF 4 CLIN EVALUATI
   Serino A, 2015, SCI REP-UK, V5, DOI 10.1038/srep18603
   Simon DM, 2017, FRONT INTEGR NEUROSC, V11, DOI 10.3389/fnint.2017.00008
   Stevenson RA, 2017, SCHIZOPHR RES, V179, P97, DOI 10.1016/j.schres.2016.09.035
   Stevenson RA, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00379
   Stevenson RA, 2014, J NEUROSCI, V34, P691, DOI 10.1523/JNEUROSCI.3615-13.2014
   Stivers T, 2009, P NATL ACAD SCI USA, V106, P10587, DOI 10.1073/pnas.0903616106
   Stone WL, 1997, J AUTISM DEV DISORD, V27, P677, DOI 10.1023/A:1025854816091
   Sugita Y, 2003, NATURE, V421, P911, DOI 10.1038/421911a
   Tomasello M, 2008, JEAN NICOD LECT, P1
   Torgesen J, 1999, TEST WORD READING EF
   Turi M, 2016, SCI REP-UK, V6, DOI 10.1038/srep21756
   Wallace MT, 2014, NEUROPSYCHOLOGIA, V64, P105, DOI 10.1016/j.neuropsychologia.2014.08.005
   Woodcock R. W., 2001, WOODCOCK JOHNSON TES
   Woynaroski TG, 2013, J AUTISM DEV DISORD, V43, P2891, DOI 10.1007/s10803-013-1836-5
NR 90
TC 18
Z9 18
U1 1
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2379-8920
EI 2379-8939
J9 IEEE T COGN DEV SYST
JI IEEE Trans. Cogn. Dev. Syst.
PD DEC
PY 2018
VL 10
IS 4
BP 973
EP 982
DI 10.1109/TCDS.2017.2778141
PG 10
WC Computer Science, Artificial Intelligence; Robotics; Neurosciences
SC Computer Science; Robotics; Neurosciences & Neurology
GA HD6HK
UT WOS:000452636400013
OA Bronze
DA 2021-02-24
ER

PT J
AU Mzah, Y
   Chaoui, S
   Jaidane, M
AF Mzah, Yosra
   Chaoui, Sandra
   Jaidane, Meriem
TI Enhancing speech intelligibility in reverberant spaces by a speech
   features distributions dependent pre-processing
SO INTERNATIONAL JOURNAL OF SPEECH TECHNOLOGY
LA English
DT Article
DE Intelligibility; Reverberation; Pre-processing; Envelope; Overlap
   masking
ID STEADY-STATE SUPPRESSION; DEREVERBERATION; IDENTIFICATION; ENVIRONMENTS;
   HEARING; NOISE
AB In this paper, we deal with a pre-processing based on speech envelope modulation for intelligibility enhancement in reverberant large dimension public enclosed spaces. In fact, the blurring effect due to reverberation alters the speech perception in such conditions. This phenomenon results from the masking of consonants by the reverberated tails of the previous vowels. This is particularly accentuated for elderly persons suffering from presbycusis. The proposed pre-processing is inspired from the steady-state suppression technique which consists in the detection of the steady-state portions of speech and the multiplication of their waveforms with an attenuation coefficient in order to decrease their masking effect. While the steady-state suppression technique is performed in the frequency domain, the pre-processing described in this paper is rather performed in the temporal domain. Its key novelty consists in the detection of the speech voiced segments using a priori knowledge about the distributions of the powers and the durations of voiced and unvoiced phonemes. The performances of this pre-processing are evaluated with an objective criterion and with subjective listening tests involving normal hearing persons and using a set of nonsense Vowel-Consonant-Vowel syllables and railway station vocal announcements.
C1 [Mzah, Yosra; Chaoui, Sandra] Telnet, CEA, LinkLab Lab, Tunis 1082, Tunisia.
   [Mzah, Yosra; Jaidane, Meriem] Univ Tunis El Manar, Ecole Natl Ingn Tunis, Tunis 1068, Tunisia.
RP Mzah, Y (corresponding author), Telnet, CEA, LinkLab Lab, Tunis 1082, Tunisia.; Mzah, Y (corresponding author), Univ Tunis El Manar, Ecole Natl Ingn Tunis, Tunis 1068, Tunisia.
EM yosra.mzah@rrocea.net
OI Jaidane, Meriem/0000-0002-9096-6161
FU European project entitled Intelligible City For All from Active and
   Assisted Living Program [AAL 2011-4-056]
FX This work is a part of a European project entitled Intelligible City For
   All (http://www.icityforall.eu/) from the Active and Assisted Living
   Program (AAL 2011-4-056). The main objective of this project is to
   enhance the sense of security, self-confidence and comfort for elderly
   people suffering from presbycusis.
CR Arai T., 2002, Acoustical Science and Technology, V23, P229, DOI 10.1250/ast.23.229
   Arai T, 2010, IEEE T AUDIO SPEECH, V18, P1775, DOI 10.1109/TASL.2010.2052165
   Arai T, 2007, ACOUST SCI TECHNOL, V28, P438, DOI 10.1250/ast.28.438
   Assmann Peter, 2004, VVolume 18, P231
   BOLT RH, 1949, J ACOUST SOC AM, V21, P577, DOI 10.1121/1.1906551
   Bouguelia MR, 2018, INT J MACH LEARN CYB, V9, P1307, DOI 10.1007/s13042-017-0645-0
   DUQUESNOY AJ, 1980, J ACOUST SOC AM, V68, P537, DOI 10.1121/1.384767
   FLANAGAN JL, 1991, ACUSTICA, V73, P58
   FURUI S, 1986, J ACOUST SOC AM, V80, P1016, DOI 10.1121/1.393842
   Habets EAP, 2005, INT CONF ACOUST SPEE, P173
   Habets EAP, 2010, SIGNALS COMMUN TECHN, P57, DOI 10.1007/978-1-84996-056-4_3
   Halling DC, 2000, J SPEECH LANG HEAR R, V43, P414, DOI 10.1044/jslhr.4302.414
   HELFER KS, 1991, J ACOUST SOC AM, V90, P1786, DOI 10.1121/1.401659
   Hodoshima N, 2007, ACOUST SCI TECHNOL, V28, P53, DOI 10.1250/ast.28.53
   Humes LE, 2010, SPRINGER HANDB AUDIT, V34, P211, DOI 10.1007/978-1-4419-0993-0_8
   Kodrasi I, 2016, IEEE-ACM T AUDIO SPE, V24, P680, DOI 10.1109/TASLP.2016.2518804
   Langhans T., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P156
   Mechergui N, 2017, J ACOUST SOC AM, V141, P1470, DOI 10.1121/1.4976628
   MIYOSHI M, 1988, IEEE T ACOUST SPEECH, V36, P145, DOI 10.1109/29.1509
   Mzah Y, 2016, 2016 INTERNATIONAL SYMPOSIUM ON SIGNAL, IMAGE, VIDEO AND COMMUNICATIONS (ISIVC), P291, DOI 10.1109/ISIVC.2016.7894003
   NABELEK AK, 1978, J ACOUST SOC AM, V63, P187
   Vajda S, 2016, INT C REC TRENDS IM, P185
NR 22
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1381-2416
EI 1572-8110
J9 INT J SPEECH TECHNOL
JI Int. J. Speech Technol.
PD DEC
PY 2018
VL 21
IS 4
BP 773
EP 781
DI 10.1007/s10772-018-9536-3
PG 9
WC Engineering, Electrical & Electronic
SC Engineering
GA HD9WD
UT WOS:000452913900003
DA 2021-02-24
ER

PT J
AU Xiao, NQG
   Mukaida, M
   Quinn, PC
   Pascalis, O
   Lee, K
   Itakura, S
AF Xiao, Naiqi G.
   Mukaida, Mai
   Quinn, Paul C.
   Pascalis, Olivier
   Lee, Kang
   Itakura, Shoji
TI Narrowing in face and speech perception in infancy: Developmental change
   in the relations between domains
SO JOURNAL OF EXPERIMENTAL CHILD PSYCHOLOGY
LA English
DT Article
DE Perceptual narrowing; Face perception; Speech perception; Perceptual
   development; Infancy; Habituation
ID 1ST YEAR; LEXICAL TONE; HEMISPHERIC LATERALIZATION; SELECTIVE ATTENTION;
   PHONETIC PERCEPTION; 9-MONTH-OLD INFANTS; NATIVE LANGUAGE; EYE TRACKING;
   RACE; EXPERIENCE
AB Although prior research has established that perceptual narrowing reflects the influence of experience on the development of face and speech processing, it is unclear whether narrowing in the two domains is related. A within-participant design (N= 72) was used to investigate discrimination of own- and other-race faces and native and non-native speech sounds in 3-, 6-, 9-, and 12-month-old infants. For face and speech discrimination, whereas 3-month-olds discriminated own-race faces and native speech sounds as well as other-race faces and non-native speech sounds, older infants discriminated only own-race faces and native speech sounds. Narrowing in face and narrowing in speech were not correlated at 6 months, negatively correlated at 9 months, and positively correlated at 12 months. The findings reveal dynamic developmental changes in the relation between modalities during the first year of life. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Xiao, Naiqi G.] Princeton Univ, Dept Psychol, Princeton, NJ 08540 USA.
   [Mukaida, Mai; Itakura, Shoji] Kyoto Univ, Grad Sch Letters, Dept Psychol, Kyoto 6068501, Japan.
   [Quinn, Paul C.] Univ Delaware, Dept Psychol & Brain Sci, Newark, DE 19716 USA.
   [Pascalis, Olivier] Univ Grenoble Alpes, CNRS, Lab Psychol & NeuroCognit, F-38058 Grenoble, France.
   [Lee, Kang] Univ Toronto, Dr Eric Jackman Inst Child Study, Toronto, ON M5R 2X2, Canada.
RP Itakura, S (corresponding author), Kyoto Univ, Grad Sch Letters, Dept Psychol, Kyoto 6068501, Japan.
EM sitakura@bun.kyoto-u.ac.jp
FU Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR;
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01 HD046526]; Japan
   Society for the Promotion of ScienceMinistry of Education, Culture,
   Sports, Science and Technology, Japan (MEXT)Japan Society for the
   Promotion of Science [25245067, 25240020]
FX This research was supported by grants from the Natural Sciences and
   Engineering Research Council of Canada, National Institutes of Health
   (R01 HD046526), and Japan Society for the Promotion of Science (25245067
   and 25240020).
CR Altvater-Mackensen N, 2016, NEUROIMAGE, V133, P14, DOI 10.1016/j.neuroimage.2016.02.061
   Amso D, 2015, NAT REV NEUROSCI, V16, P606, DOI 10.1038/nrn4025
   Anzures G, 2012, J EXP CHILD PSYCHOL, V112, P484, DOI 10.1016/j.jecp.2012.04.005
   Bahrick LE, 2000, DEV PSYCHOL, V36, P190, DOI 10.1037//0012-1649.36.2.190
   Bahrick LE, 2013, DEV PSYCHOL, V49, P1919, DOI 10.1037/a0031238
   Bruderer AG, 2015, P NATL ACAD SCI USA, V112, P13531, DOI 10.1073/pnas.1508631112
   Cashon CH, 2013, CHILD DEV, V84, P802, DOI 10.1111/cdev.12024
   Cassia VM, 2014, DEV PSYCHOBIOL, V56, P238, DOI 10.1002/dev.21191
   Chien SHL, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01606
   COHEN LB, 1979, AM PSYCHOL, V34, P894, DOI 10.1037/0003-066X.34.10.894
   de Boisferon AH, 2017, DEVELOPMENTAL SCI, V20, DOI 10.1111/desc.12381
   Dundas E. M., 2014, J COGNITIVE NEUROSCI, V27, P1
   Dundas EM, 2014, NEUROPSYCHOLOGIA, V61, P315, DOI 10.1016/j.neuropsychologia.2014.05.006
   Dundas EM, 2013, J EXP PSYCHOL GEN, V142, P348, DOI 10.1037/a0029503
   Emberson LL, 2015, P NATL ACAD SCI USA, V112, P9585, DOI 10.1073/pnas.1510343112
   Fodor J., 1983, MODULARITY MIND
   Geangu E, 2016, CURR BIOL, V26, pR663, DOI 10.1016/j.cub.2016.05.072
   Hadley H, 2014, BRAIN SCI, V4, P613, DOI 10.3390/brainsci4040613
   Hannon EE, 2005, P NATL ACAD SCI USA, V102, P12639, DOI 10.1073/pnas.0504254102
   Harrison P, 2000, LINGUA, V110, P581, DOI 10.1016/S0024-3841(00)00003-6
   Heron-Delaney M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019858
   Kelly DJ, 2007, PSYCHOL SCI, V18, P1084, DOI 10.1111/j.1467-9280.2007.02029.x
   Kelly DJ, 2009, J EXP CHILD PSYCHOL, V104, P105, DOI 10.1016/j.jecp.2009.01.006
   Kobayashi M, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12498
   Kuhl PK, 2003, P NATL ACAD SCI USA, V100, P9096, DOI 10.1073/pnas.1532872100
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Le Grand R, 2001, NATURE, V410, P890, DOI 10.1038/35073749
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Lewkowicz DJ, 2006, P NATL ACAD SCI USA, V103, P6771, DOI 10.1073/pnas.0602027103
   Li S, 2013, NEUROPSYCHOLOGIA, V51, P950, DOI 10.1016/j.neuropsychologia.2013.02.006
   Liu SY, 2018, PSYCH J, V7, P92, DOI 10.1002/pchj.211
   Liu SY, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00593
   Liu SY, 2011, J EXP CHILD PSYCHOL, V108, P180, DOI 10.1016/j.jecp.2010.06.008
   LYNCH MP, 1990, PSYCHOL SCI, V1, P272, DOI 10.1111/j.1467-9280.1990.tb00213.x
   Markant J, 2016, DEV PSYCHOBIOL, V58, P355, DOI 10.1002/dev.21375
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Mattock K, 2006, INFANCY, V10, P241, DOI 10.1207/s15327078in1003_3
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   Minar NJ, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12604
   MOON C, 1993, INFANT BEHAV DEV, V16, P495, DOI 10.1016/0163-6383(93)80007-U
   Pascalis O, 2005, P NATL ACAD SCI USA, V102, P5297, DOI 10.1073/pnas.0406627102
   Pascalis O, 2002, SCIENCE, V296, P1321, DOI 10.1126/science.1070223
   Pascalis O, 2014, CHILD DEV PERSPECT, V8, P65, DOI 10.1111/cdep.12064
   Piaget J, 1950, PSYCHOL INTELLIGENCE
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Quinn PC, 2016, DEVELOPMENTAL SCI, V19, P362, DOI 10.1111/desc.12301
   Rennels JL, 2008, INFANT BEHAV DEV, V31, P665, DOI 10.1016/j.infbeh.2008.04.009
   Reynolds GD, 2016, FRONT SYST NEUROSCI, V10, DOI 10.3389/fnsys.2016.00015
   Scott LS, 2007, CURR DIR PSYCHOL SCI, V16, P197, DOI 10.1111/j.1467-8721.2007.00503.x
   Scott LS, 2009, PSYCHOL SCI, V20, P676, DOI 10.1111/j.1467-9280.2009.02348.x
   Singh L, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01563
   Spangler SM, 2013, INFANCY, V18, P516, DOI 10.1111/j.1532-7078.2012.00137.x
   Sugden NA, 2017, PSYCHOL BULL, V143, P1201, DOI 10.1037/bul0000116
   Sugden NA, 2014, DEV PSYCHOBIOL, V56, P249, DOI 10.1002/dev.21183
   Teinonen T, 2008, COGNITION, V108, P850, DOI 10.1016/j.cognition.2008.05.009
   Tham DSY, 2015, INFANT BEHAV DEV, V40, P131, DOI 10.1016/j.infbeh.2015.05.006
   Vogel M, 2012, DEVELOPMENTAL SCI, V15, P359, DOI 10.1111/j.1467-7687.2012.01138.x
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   WERKER JF, 1981, CHILD DEV, V52, P349, DOI 10.2307/1129249
   Wheeler A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018621
   Xiao NQG, 2015, DEV PSYCHOL, V51, P744, DOI 10.1037/dev0000019
   Yeung HH, 2013, J MEM LANG, V68, P123, DOI 10.1016/j.jml.2012.09.004
NR 65
TC 3
Z9 3
U1 1
U2 15
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0022-0965
EI 1096-0457
J9 J EXP CHILD PSYCHOL
JI J. Exp. Child Psychol.
PD DEC
PY 2018
VL 176
BP 113
EP 127
DI 10.1016/j.jecp.2018.06.007
PG 15
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA GU0GE
UT WOS:000444927000009
PM 30149243
DA 2021-02-24
ER

PT J
AU Fecher, N
   Johnson, EK
AF Fecher, Natalie
   Johnson, Elizabeth K.
TI The Native-Language Benefit for Talker Identification Is Robust in
   7.5-Month-Old Infants
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION
LA English
DT Article
DE talker recognition; language familiarity effect; infant speech
   perception; visual fixation procedure; phonological development
ID VOICE RECOGNITION; WORD SEGMENTATION; 1ST YEAR; DISCRIMINATION;
   SENSITIVITY; EXPOSURE; ABILITY; FACES; EVEN
AB Adults recognize talkers better when the talkers speak a familiar language than when they speak an unfamiliar language. This language familiarity effect (LFE) demonstrates the inseparable nature of linguistic and indexical information in adult spoken language processing. Relatively little is known about children's integration of linguistic and indexical information in speech. For example, to date, only one study has explored the LFE in infants. Here, we sought to better understand the maturation of speech processing abilities in infants by replicating this earlier study using a more stringent experimental design (eliminating a potential voice-language confound), a different test population (English-rather than Dutch-learning infants), and a new language pairing (English vs. Polish rather than Dutch vs. Italian or Japanese). Furthermore, we explored the language exposure conditions required for infants to develop an LFE for a formerly unfamiliar language. We hypothesized based on previous studies (including the perceptual narrowing literature) that infants might develop an LFE more readily than would adults. Although our findings replicate those of the earlier study-demonstrating that the LFE is robust in 7.5-month-olds-we found no evidence that infants need less language exposure than do adults to develop an LFE. We concluded that both infants and adults need extensive (potentially live) exposure to an unfamiliar language before talker identification in that language improves. Moreover, our study suggests that the LFE is likely rooted in early emerging phonology rather than shared lexical knowledge and that infants already closely resemble adults in their processing of linguistic and indexical information.
C1 [Fecher, Natalie; Johnson, Elizabeth K.] Univ Toronto, Dept Psychol, 3359 Mississauga Rd, Mississauga, ON L5L 1C6, Canada.
RP Fecher, N (corresponding author), Univ Toronto, Dept Psychol, 3359 Mississauga Rd, Mississauga, ON L5L 1C6, Canada.
EM natalie.fecher@utoronto.ca
OI Johnson, Elizabeth Kay/0000-0002-9941-9949
FU Social Sciences and Humanities Research Council of CanadaSocial Sciences
   and Humanities Research Council of Canada (SSHRC); Natural Sciences and
   Engineering Research Council of CanadaNatural Sciences and Engineering
   Research Council of Canada (NSERC)CGIAR; Canada Research Chairs
   ProgramCanada Research Chairs
FX This research was supported by grants awarded to Elizabeth K. Johnson
   from the Social Sciences and Humanities Research Council of Canada, the
   Natural Sciences and Engineering Research Council of Canada, and the
   Canada Research Chairs Program. The authors thank Lisa Rustom, Natalie
   Rzeszutek, and Lisa Hotson for assistance with stimulus creation and
   data collection; Angela Cooper for assistance with data analysis; and
   all families that participated. The content is solely the responsibility
   of Natalie Fecher and Elizabeth K. Johnson and does not necessarily
   reflect the official views of the aforementioned funding agencies.
CR Anzures G, 2012, J EXP CHILD PSYCHOL, V112, P484, DOI 10.1016/j.jecp.2012.04.005
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bergelson E, 2018, CHILD DEV, V89, P1567, DOI 10.1111/cdev.12888
   Bregman MR, 2014, COGNITION, V130, P85, DOI 10.1016/j.cognition.2013.09.010
   Cohen L. B, 2000, HABIT 2000 NEW PROGR
   Creel SC, 2012, J EXP CHILD PSYCHOL, V113, P487, DOI 10.1016/j.jecp.2012.07.007
   DECASPER AJ, 1980, SCIENCE, V208, P1174, DOI 10.1126/science.7375928
   Fair J, 2012, CHILD DEV, V83, P1996, DOI 10.1111/j.1467-8624.2012.01814.x
   Floccia C, 2000, DEVELOPMENTAL SCI, V3, P333, DOI 10.1111/1467-7687.00128
   Frank MC, 2017, INFANCY, V22, P421, DOI 10.1111/infa.12182
   GOGGIN JP, 1991, MEM COGNITION, V19, P448, DOI 10.3758/BF03199567
   Hannon EE, 2005, P NATL ACAD SCI USA, V102, P12639, DOI 10.1073/pnas.0504254102
   Heron-Delaney M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019858
   Houston DM, 2000, J EXP PSYCHOL HUMAN, V26, P1570, DOI 10.1037/0096-1523.26.5.1570
   Johnson E, 2010, LANG LEARN LANG TEAC, V27, P73
   Johnson EK, 2018, COGNITIVE SCI, V42, P633, DOI 10.1111/cogs.12520
   Johnson EK, 2016, ANNU REV LINGUIST, V2, P391, DOI 10.1146/annurev-linguistics-011415-040616
   Johnson EK, 2011, DEVELOPMENTAL SCI, V14, P1002, DOI 10.1111/j.1467-7687.2011.01052.x
   JUSCZYK P. W., 1997, DISCOVERY SPOKEN LAN
   Jusczyk PW, 1999, PERCEPT PSYCHOPHYS, V61, P1465, DOI 10.3758/BF03213111
   Jusczyk PW, 1999, COGNITIVE PSYCHOL, V39, P159, DOI 10.1006/cogp.1999.0716
   JUSCZYK PW, 1994, J MEM LANG, V33, P630, DOI 10.1006/jmla.1994.1030
   Kadam MA, 2016, J ACOUST SOC AM, V139, pEL6, DOI 10.1121/1.4937488
   Kitamura C, 2013, CHILD DEV, V84, P1686, DOI 10.1111/cdev.12068
   Koster O, 1997, FORENSIC LINGUIST, V4, P18, DOI DOI 10.1558/IJSLL.V4I1.18
   Kuhl PK, 2003, P NATL ACAD SCI USA, V100, P9096, DOI 10.1073/pnas.1532872100
   Lee B, 2017, SPEECH LANG HEARING, V20, P174, DOI 10.1080/2050571X.2016.1273572
   Levi SV, 2018, BILING-LANG COGN, V21, P523, DOI 10.1017/S1366728917000153
   Levi SV, 2013, J SPEECH LANG HEAR R, V56, P913, DOI 10.1044/1092-4388(2012/12-0095)
   Mattock K, 2008, COGNITION, V106, P1367, DOI 10.1016/j.cognition.2007.07.002
   Nazzi T, 2000, J MEM LANG, V43, P1, DOI 10.1006/jmla.2000.2698
   Ngon C, 2013, DEVELOPMENTAL SCI, V16, P24, DOI 10.1111/j.1467-7687.2012.01189.x
   Orena AJ, 2015, COGNITION, V143, P36, DOI 10.1016/j.cognition.2015.06.002
   Pascalis O, 2005, P NATL ACAD SCI USA, V102, P5297, DOI 10.1073/pnas.0406627102
   Perea M, 2014, EXP PSYCHOL, V61, P480, DOI 10.1027/1618-3169/a000265
   Perrachione T. K, 2015, P 18 INT C PHON SCI
   Perrachione TK, 2007, NEUROPSYCHOLOGIA, V45, P1899, DOI 10.1016/j.neuropsychologia.2006.11.015
   Perrachione TK, 2011, SCIENCE, V333, P595, DOI 10.1126/science.1207327
   R Core Team, 2016, R A LANGUAGE AND ENV
   Remez RE, 1997, J EXP PSYCHOL HUMAN, V23, P651, DOI 10.1037/0096-1523.23.3.651
   Romberg AR, 2010, WIRES COGN SCI, V1, P906, DOI 10.1002/wcs.78
   Rost GC, 2009, DEVELOPMENTAL SCI, V12, P339, DOI 10.1111/j.1467-7687.2008.00786.x
   Schiller NG, 1997, IDENTITIES-GLOB STUD, V4, P1
   van Heugten M, 2014, J EXP PSYCHOL GEN, V143, P340, DOI 10.1037/a0032192
   van Heugten M, 2012, J SPEECH LANG HEAR R, V55, P554, DOI 10.1044/1092-4388(2011/10-0347)
   Watson TL, 2014, DEV PSYCHOBIOL, V56, P1454, DOI 10.1002/dev.21243
   Winters SJ, 2008, J ACOUST SOC AM, V123, P4524, DOI 10.1121/1.2913046
NR 47
TC 7
Z9 7
U1 1
U2 15
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0278-7393
EI 1939-1285
J9 J EXP PSYCHOL LEARN
JI J. Exp. Psychol.-Learn. Mem. Cogn.
PD DEC
PY 2018
VL 44
IS 12
BP 1911
EP 1920
DI 10.1037/xlm0000555
PG 10
WC Psychology; Psychology, Experimental
SC Psychology
GA HB4RE
UT WOS:000451042000004
PM 29698034
DA 2021-02-24
ER

PT J
AU Fernandes, EG
   Luegi, P
   Soares, EC
   de la Fuente, I
   Hemforth, B
AF Fernandes, Eunice G.
   Luegi, Paula
   Soares, Eduardo Correa
   de la Fuente, Israel
   Hemforth, Barbara
TI Adaptation in Pronoun Resolution: Evidence From Brazilian and European
   Portuguese
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION
LA English
DT Article
DE adaptation; pronoun resolution; probabilistic comprehension; ambiguity
ID VISUAL WORLD PARADIGM; SPEECH-PERCEPTION; TIME-COURSE; EXPRESSIONS;
   INFORMATION; PREDICTION; MODELS; FOCUS; FORM; NULL
AB Previous research accounting for pronoun resolution as a problem of probabilistic inference has not explored the phenomenon of adaptation, whereby the processor constantly tracks and adapts, rationally, to changes in a statistical environment. We investigate whether Brazilian (BP) and European Portuguese (EP) speakers adapt to variations in the probability of occurrence of ambiguous overt and null pronouns, in two experiments assessing resolution toward subject and object referents. For each variety (BP, EP), participants were faced with either the same number of null and overt pronouns (equal distribution), or with an environment with fewer overt (than null) pronouns (unequal distribution). We find that the preference for interpreting overt pronouns as referring back to an object referent (object-biased interpretation) is higher when there are fewer overt pronouns (i.e., in the unequal, relative to the equal distribution condition). This is especially the case for BP, a variety with higher prior frequency and smaller object-biased interpretation of overt pronouns, suggesting that participants adapted incrementally and integrated prior statistical knowledge with the knowledge obtained in the experiment. We hypothesize that comprehenders adapted rationally, with the goal of maintaining, across variations in pronoun probability, the likelihood of subject and object referents. Our findings unify insights from research in pronoun resolution and in adaptation, and add to previous studies in both topics: They provide evidence for the influence of pronoun probability in pronoun resolution, and for an adaptation process whereby the language processor not only tracks statistical information, but uses it to make interpretational inferences.
C1 [Fernandes, Eunice G.; de la Fuente, Israel; Hemforth, Barbara] Paris Diderot Univ, Lab Formal Linguist, Paris, France.
   [Luegi, Paula] Univ Lisbon, Ctr Linguist, Alameda,Univ, P-1600214 Lisbon, Portugal.
   [Soares, Eduardo Correa] Paris Diderot Univ, Lab Formal Linguist, Phonet Res Ctr, Paris, France.
   [Soares, Eduardo Correa] Paris Diderot Univ, Ctr Crosslinguist English & Corpus Linguist & Lex, Phonet Res Ctr, Paris, France.
   [de la Fuente, Israel] Univ Lille 3, CNRS, UMR 8163, Savoirs,Textes,Langage, Lille, France.
RP Fernandes, EG (corresponding author), Univ Lisbon, Ctr Linguist, Alameda,Univ, P-1600214 Lisbon, Portugal.
EM fernandese@campus.ul.pt
OI Fernandes, Eunice/0000-0002-1448-3256; de la Fuente,
   Israel/0000-0001-9276-6844; Bernardes Ribeiro, Paula
   Luegi/0000-0001-8575-3113
FU French National Research AgencyFrench National Research Agency (ANR)
   [ANR-10-LABX-0083]; CAPES FoundationCAPES [0628-14-0]; Fundacao para a
   Ciencia e a TecnologiaPortuguese Foundation for Science and
   TechnologyEuropean Commission [SFRH/BPD/84138/2012]
FX We thank Heather Burnett for comments on an earlier version of this
   article. Any remaining errors are our own. We also thank Moreno I. Coco
   for generously providing the R code used in Experiment 2 data
   preprocessing; Muriel Assmann, for her help with the creation of BP
   materials, and Doriane Gras for technical help with Experiment 1. This
   work was supported by the French National Research Agency
   (ANR-10-LABX-0083) and partially supported by the CAPES Foundation
   (under Grant 0628-14-0 awarded to Eduardo Correa Soares) and by Fundacao
   para a Ciencia e a Tecnologia (under Grant SFRH/BPD/84138/2012 awarded
   to Paula Luegi).
CR Almor A, 1999, PSYCHOL REV, V106, P748, DOI 10.1037/0033-295X.106.4.748
   Almor A, 2017, J MEM LANG, V92, P98, DOI 10.1016/j.jml.2016.06.001
   ANDERSON JR, 1991, PSYCHOL REV, V98, P409, DOI 10.1037/0033-295X.98.3.409
   ARIEL M, 1994, J LINGUIST, V30, P3, DOI 10.1017/S0022226700016170
   Ariel M., 1990, ACCESSING NOUN PHRAS
   Arnold JE, 2001, DISCOURSE PROCESS, V31, P137, DOI 10.1207/S15326950DP3102_02
   Arnold JE, 2000, COGNITION, V76, pB13, DOI 10.1016/S0010-0277(00)00073-1
   Arnold JE, 2008, LANG COGNITIVE PROC, V23, P495, DOI 10.1080/01690960801920099
   Barbosa P, 2005, J PORT LINGUIST, V4, P11, DOI 10.5334/jpl.158
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boland JE, 2004, ON-LINE STUDY OF SENTENCE COMPREHENSION, P51
   Carminati M. N., 2002, THESIS
   Chamorro G, 2016, BILING-LANG COGN, V19, P520, DOI 10.1017/S1366728915000152
   Chang F, 2006, PSYCHOL REV, V113, P234, DOI 10.1037/0033-295X.113.2.234
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Coco MI, 2016, COGNITIVE SCI, V40, P1995, DOI 10.1111/cogs.12313
   Colonna S, 2016, SHS WEB CONF, V27, DOI 10.1051/shsconf/20162710004
   Colonna S, 2015, LANG COGN NEUROSCI, V30, P1306, DOI 10.1080/23273798.2015.1066510
   Correa L. M. S, 1998, DELTA, V14, P95, DOI [10.1590/S0102-44501998000200002, DOI 10.1590/S0102-44501998000200002]
   Costa A, 1998, NON TRADITIONAL REF
   Costa M. A, 2004, DAARC 2004, P45
   Courville AC, 2006, TRENDS COGN SCI, V10, P294, DOI 10.1016/j.tics.2006.05.004
   Crocker MW, 2000, J PSYCHOLINGUIST RES, V29, P647, DOI 10.1023/A:1026560822390
   de la Fuente I., 2013, EFFECTS CLEFTING LEF
   Demberg V, 2008, COGNITION, V109, P193, DOI 10.1016/j.cognition.2008.07.008
   Drummond A, 2013, NON TRADITIONAL REF
   Duarte M. E., 2000, BRAZILIAN PORTUGUESE, P17, DOI DOI 10.31819/9783964561497-002
   DUARTE M. E. L., 1993, PORTUGUES BRASILEIRO, P107
   Filiaci F, 2014, LANG COGN NEUROSCI, V29, P825, DOI 10.1080/01690965.2013.801502
   Fine AB, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077661
   Fine AB, 2013, COGNITIVE SCI, V37, P578, DOI 10.1111/cogs.12022
   Frank MC, 2012, SCIENCE, V336, P998, DOI 10.1126/science.1218633
   Fukumura K, 2015, J EXP PSYCHOL LEARN, V41, P501, DOI 10.1037/xlm0000041
   Garrod S. C., 1982, J SEMANT, V1, P21, DOI [10.1093/jos/1.1.21, DOI 10.1093/JOS/1.1.21]
   GERNSBACHER MA, 1988, J MEM LANG, V27, P699, DOI 10.1016/0749-596X(88)90016-2
   GORDON PC, 1993, COGNITIVE SCI, V17, P311, DOI 10.1207/s15516709cog1703_1
   GUNDEL JK, 1993, LANGUAGE, V69, P274, DOI 10.2307/416535
   Huettig F, 2011, ACTA PSYCHOL, V137, P151, DOI 10.1016/j.actpsy.2010.11.003
   Jaeger TF, 2013, COGNITION, V127, P57, DOI 10.1016/j.cognition.2012.10.013
   Jaeger TF, 2008, J MEM LANG, V59, P434, DOI 10.1016/j.jml.2007.11.007
   Jarvikivi J, 2005, PSYCHOL SCI, V16, P260, DOI 10.1111/j.0956-7976.2005.01525.x
   Jurafsky D, 1996, COGNITIVE SCI, V20, P137, DOI 10.1016/S0364-0213(99)80005-6
   Kaiser E, 2016, VISUALLY SITUATED LA, P151, DOI [10.1075/aicr.93.06kai, DOI 10.1075/AICR.93.06KAI]
   Kaiser E, 2008, LANG COGNITIVE PROC, V23, P709, DOI 10.1080/01690960701771220
   Kamide Y, 2003, J MEM LANG, V49, P133, DOI 10.1016/S0749-596X(03)00023-8
   Kaschak MP, 2004, J EXP PSYCHOL GEN, V133, P450, DOI 10.1037/0096-3445.133.3.450
   Kehler A, 2013, THEOR LINGUIST, V39, P1, DOI 10.1515/tl-2013-0001
   Kehler A, 2008, J SEMANT, V25, P1, DOI 10.1093/jos/ffm018
   Kleinschmidt D. F., 2012, P 34 ANN C COGN SCI, P599
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kolmogorov AN., 1956, FDN THEORY PROBABILI
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006
   Luegi P, 2012, THESIS
   Luegi P, 2014, CADERNOS LETRAS UFF, V49, P67
   Metzing C, 2003, J MEM LANG, V49, P201, DOI 10.1016/S0749-596X(03)00028-7
   Mirman D, 2008, J MEM LANG, V59, P475, DOI 10.1016/j.jml.2007.11.006
   NELSON WW, 1980, J EXP PSYCHOL-HUM L, V6, P391, DOI 10.1037/0278-7393.6.4.391
   R Core Team, 2017, R LANGUAGE ENV STAT
   Rohde H, 2014, LANG COGN NEUROSCI, V29, P912, DOI 10.1080/01690965.2013.854918
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sanford AJ, 2004, ON-LINE STUDY OF SENTENCE COMPREHENSION, P151
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Teixeira E. N, 2014, VEREDAS, V18, P281
   Tily H, 2009, P WORKSH PROD REF EX, P1
   VONK W, 1992, LANG COGNITIVE PROC, V7, P301, DOI 10.1080/01690969208409389
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
   Yildirim I, 2016, J MEM LANG, V87, P128, DOI 10.1016/j.jml.2015.08.003
NR 68
TC 3
Z9 3
U1 0
U2 5
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0278-7393
EI 1939-1285
J9 J EXP PSYCHOL LEARN
JI J. Exp. Psychol.-Learn. Mem. Cogn.
PD DEC
PY 2018
VL 44
IS 12
BP 1986
EP 2008
DI 10.1037/xlm0000569
PG 23
WC Psychology; Psychology, Experimental
SC Psychology
GA HB4RE
UT WOS:000451042000010
PM 29698041
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Vaughn, C
   Kendall, T
AF Vaughn, Charlotte
   Kendall, Tyler
TI Listener sensitivity to probabilistic conditioning of sociolinguistic
   variables: The case of (ING)
SO JOURNAL OF MEMORY AND LANGUAGE
LA English
DT Article
DE Speech perception; Sociolinguistic variables; Expectation; Listener
   knowledge; Grammatical conditioning; Stylistic/phonetic congruence
ID SPOKEN WORD RECOGNITION; SPEECH-PERCEPTION; PRONUNCIATION VARIANTS;
   TIME-COURSE; FREQUENCY; COMPREHENSION; ATTENTION; LANGUAGE; ENGLISH;
   RULES
AB This paper investigates the extent to which listeners are cued into the systematicity of variability in speech, particularly the grammatical conditioning constraints of the English sociolinguistic variable (ING) (e.g., talking vs. talkin). Listeners' sensitivity to the realization of (ING) words embedded in sentences was tested under various conditions. Comprehenders demonstrated expectations about the grammatical category constraints conditioning the realization of (ING) even though such knowledge may not be very informative about word recognition (Experiment 1). As more reliable phonetic information was available, listeners weighted grammatical expectations less, favoring other cues in the signal (Experiments 2 and 3). Bridging a gap between psycholinguistic and sociolinguistic accounts of probabilistic conditioning, these results suggest that factors beyond utility for word recognition may contribute to the probabilistic monitoring of a variable, and underscore the opportunistic nature of the speech comprehension system, where listeners make use of whatever information they have to process the signal.
C1 [Vaughn, Charlotte; Kendall, Tyler] Univ Oregon, Dept Linguist, 1290 Univ Oregon, Eugene, OR 97403 USA.
RP Vaughn, C (corresponding author), Univ Oregon, Dept Linguist, 1290 Univ Oregon, Eugene, OR 97403 USA.
EM cvaughn@uoregon.edu; tsk@uoregon.edu
OI Kendall, Tyler/0000-0002-0989-1765
CR Abramowicz L, 2007, U PENNSYLVANIA WORKI, V13, P3
   Allen JS, 2004, J ACOUST SOC AM, V115, P3171, DOI 10.1121/1.1701898
   Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Baayen RH, 2013, LANG SPEECH, V56, P329, DOI 10.1177/0023830913484896
   Bender EM, 2005, LINGUA, V115, P1579, DOI 10.1016/j.lingua.2004.07.005
   Boersma P., 2015, PRAAT VERSION 5 4 08
   Bresnahan MJ, 2002, LANG COMMUN, V22, P171, DOI 10.1016/S0271-5309(01)00025-8
   Bresnan J, 2010, LANGUAGE, V86, P168
   Brouwer S, 2013, APPL PSYCHOLINGUIST, V34, P519, DOI 10.1017/S0142716411000853
   Burki A, 2010, J MEM LANG, V62, P421, DOI 10.1016/j.jml.2010.01.002
   Campbell-Kibler K, 2007, AM SPEECH, V82, P32, DOI 10.1215/00031283-2007-002
   Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   Connine CM, 2004, PSYCHON B REV, V11, P1084, DOI 10.3758/BF03196741
   CONNINE CM, 1987, J EXP PSYCHOL HUMAN, V13, P291, DOI 10.1037/0096-1523.13.2.291
   Connine CM, 2008, PERCEPT PSYCHOPHYS, V70, P403, DOI 10.3758/PP.70.3.403
   Cutler A, 2012, NATIVE LISTENING LAN
   Davies M., 2008, CORPUS CONT AM ENGLI
   Davis MH, 2007, HEARING RES, V229, P132, DOI 10.1016/j.heares.2007.01.014
   Docherty GJ, 2013, LINGUISTICS, V51, P355, DOI 10.1515/ling-2013-0014
   Fine AB, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077661
   FISCHER JL, 1958, WORD, V14, P47, DOI 10.1080/00437956.1958.11659655
   Forrest J, 2015, LANG VAR CHANGE, V27, P377, DOI 10.1017/S0954394515000137
   Foulkes Paul, 2015, HDB LANGUAGE EMERGEN, P292, DOI [10.1002/9781118346136.ch13., DOI 10.1002/9781118346136.CH13]
   Fox J., 2011, R COMPANION APPL REG
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Garnsey SM, 1997, J MEM LANG, V37, P58, DOI 10.1006/jmla.1997.2512
   Goldinger SD, 1996, J EXP PSYCHOL LEARN, V22, P1166, DOI 10.1037/0278-7393.22.5.1166
   Goldinger SD, 2004, PSYCHON B REV, V11, P716, DOI 10.3758/BF03196625
   Hazen K, 2008, AM SPEECH, V83, P116, DOI 10.1215/00031283-2008-008
   Hothorn T, 2008, BIOMETRICAL J, V50, P346, DOI 10.1002/bimj.200810425
   Houston Ann Celeste, 1985, THESIS
   Huettig F, 2015, BRAIN RES, V1626, P118, DOI 10.1016/j.brainres.2015.02.014
   HURA SL, 1992, LANG SPEECH, V35, P59, DOI 10.1177/002383099203500206
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Kendall T, 2013, SPEECH RATE, PAUSE, AND SOCIOLINGUISTIC VARIATION: STUDIES IN CORPUS SOCIOPHONETICS, P1, DOI 10.1057/9781137291448
   Kendall T, 2008, P METHODS 13 PAPERS, P351
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299
   Kuznetsova A., 2014, LMERTEST TESTS RANDO
   Labov W, 2011, J SOCIOLING, V15, P431, DOI 10.1111/j.1467-9841.2011.00504.x
   Labov William, 1966, SOCIAL STRATIFICATIO
   Labov William., 2001, PRINCIPLES LINGUISTI
   Levon E, 2014, J ENGL LINGUIST, V42, P185, DOI 10.1177/0075424214531487
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006
   Loudermilk B. C., 2013, THESIS
   LUCE PA, 1986, PERCEPT PSYCHOPHYS, V39, P155, DOI 10.3758/BF03212485
   MacDonald M. C., 2006, HDB PSYCHOLINGUISTIC, P581, DOI DOI 10.1016/B978-012369374-7/50016-X
   MARSLENWILSON W, 1989, J EXP PSYCHOL HUMAN, V15, P576, DOI 10.1037/0096-1523.15.3.576
   McAuliffe M., 2017, P INT
   McAuliffe M, 2016, J ACOUST SOC AM, V140, P1727, DOI 10.1121/1.4962529
   McMurray B, 2011, PSYCHOL REV, V118, P219, DOI 10.1037/a0022325
   McQueen JM, 2012, J ACOUST SOC AM, V131, P509, DOI 10.1121/1.3664087
   Pierrehumbert JB, 2006, J PHONETICS, V34, P516, DOI 10.1016/j.wocn.2006.06.003
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Pinnow E, 2014, LANG SPEECH, V57, P42, DOI 10.1177/0023830913479105
   PITT MA, 1993, J EXP PSYCHOL HUMAN, V19, P699, DOI 10.1037/0096-1523.19.4.699
   Pitt MA, 2011, J PHONETICS, V39, P304, DOI 10.1016/j.wocn.2010.07.004
   Pitt MA, 2009, J MEM LANG, V61, P19, DOI 10.1016/j.jml.2009.02.005
   Preston DR, 2013, BLACKW HBK LINGUIST, P157
   Psychology Software Tools, 2012, E PRIM 2 0
   Racz P, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00051
   Ranbom LJ, 2007, J MEM LANG, V57, P273, DOI 10.1016/j.jml.2007.04.001
   Sali Tagliamonte, 2004, LANG VAR EUR 2 INT C, P390
   SUMNER M, 2013, P ANN M 35 ANN C COG, P3486
   Sumner M, 2014, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.01015
   Sumner M, 2013, J ACOUST SOC AM, V134, pEL26, DOI 10.1121/1.4807432
   Tamminga M, 2017, J ACOUST SOC AM, V142, pEL18, DOI 10.1121/1.4990399
   Theodore RM, 2015, J ACOUST SOC AM, V138, P1068, DOI 10.1121/1.4927489
   Theodore RM, 2015, ATTEN PERCEPT PSYCHO, V77, P1674, DOI 10.3758/s13414-015-0854-0
   TRAUNMULLER H, 1990, J ACOUST SOC AM, V88, P97, DOI 10.1121/1.399849
   TRUESWELL JC, 1993, J EXP PSYCHOL LEARN, V19, P528, DOI 10.1037/0278-7393.19.3.528
   Van Berkum JJA, 2008, J COGNITIVE NEUROSCI, V20, P580, DOI 10.1162/jocn.2008.20054
   Vaughn C., 2018, LABPHON 16 LISB PORT, V16
   WALD B, 1981, STYLE VARIABLES ENGL, P219
   Walker A., 2011, LAB PHONOLOGY, V2, P219, DOI DOI 10.1515/LABPHON.2011.007
   WARREN RM, 1970, SCIENCE, V167, P392, DOI 10.1126/science.167.3917.392
   Weiss DJ, 2009, LANG LEARN DEV, V5, P30, DOI 10.1080/15475440802340101
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
   Zarcone A, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00844
NR 80
TC 3
Z9 3
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0749-596X
EI 1096-0821
J9 J MEM LANG
JI J. Mem. Lang.
PD DEC
PY 2018
VL 103
BP 58
EP 73
DI 10.1016/j.jml.2018.07.006
PG 16
WC Linguistics; Psychology; Psychology, Experimental
SC Linguistics; Psychology
GA GW6OA
UT WOS:000447076600005
DA 2021-02-24
ER

PT J
AU Miller, CW
   Bernstein, JGW
   Zhang, XY
   Wu, YH
   Bentler, RA
   Tremblay, K
AF Miller, Christi W.
   Bernstein, Joshua G. W.
   Zhang, Xuyang
   Wu, Yu-Hsiang
   Bentler, Ruth A.
   Tremblay, Kelly
TI The Effects of Static and Moving Spectra Ripple Sensitivity on Unaided
   and Aided Speech Perception in Noise
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID TEMPORAL FINE-STRUCTURE; HEARING-IMPAIRED LISTENERS; SPECTROTEMPORAL
   MODULATION SENSITIVITY; MULTICHANNEL COMPRESSION; FREQUENCY-MODULATION;
   COGNITIVE FUNCTION; CARRIER FREQUENCY; STRUCTURE CUES; RECOGNITION;
   INTELLIGIBILITY
AB Purpose: This study evaluated whether certain spectral ripple conditions were more informative than others in predicting ecologically relevant unaided and aided speech outcomes.
   Method: A quasi-experimental study design was used to evaluate 67 older adult hearing aid users with bilateral, symmetrical hearing loss. Speech perception in noise was tested under conditions of unaided and aided, auditory-only and auditory-visual, and 2 types of noise. Predictors included age, audiometric thresholds, audibility, hearing aid compression, and modulation depth detection thresholds for moving (4-Hz) or static (0-Hz) 2-cycle/octave spectral ripples applied to carriers of broadband noise or 2000-Hz low- or high-pass filtered noise.
   Results: A principal component analysis of the modulation detection data found that broadband and low-pass static and moving ripple detection thresholds loaded onto the first factor whereas high-pass static and moving ripple detection thresholds loaded onto a second factor. A linear mixed model revealed that audibility and the first factor (reflecting broadband and low-pass static and moving ripples) were significantly associated with speech perception performance. Similar results were found for unaided and aided speech scores. The interactions between speech conditions were not significant, suggesting that the relationship between ripples and speech perception was consistent regardless of visual cues or noise condition. High-pass ripple sensitivity was not correlated with speech understanding.
   Conclusions: The results suggest that, for hearing aid users, poor speech understanding in noise and sensitivity to both static and slow-moving ripples may reflect deficits in the same underlying auditory processing mechanism. Significant factor loadings involving ripple stimuli with low-frequency content may suggest an impaired ability to use temporal fine structure information in the stimulus waveform. Support is provided for the use of spectral ripple testing to predict speech perception outcomes in clinical settings.
C1 [Miller, Christi W.; Tremblay, Kelly] Univ Washington, Dept Speech & Hearing Sci, Seattle, WA 98195 USA.
   [Bernstein, Joshua G. W.] Walter Reed Natl Mil Med Ctr, Natl Mil Audiol & Speech Pathol Ctr, Bethesda, MD USA.
   [Zhang, Xuyang; Wu, Yu-Hsiang; Bentler, Ruth A.] Univ Iowa, Dept Commun Sci & Disorders, Iowa City, IA USA.
RP Miller, CW (corresponding author), Univ Washington, Dept Speech & Hearing Sci, Seattle, WA 98195 USA.
EM christim@uw.edu
FU American Speech-Language-Hearing Foundation; NIH NIDCDUnited States
   Department of Health & Human ServicesNational Institutes of Health (NIH)
   - USANIH National Institute on Deafness & Other Communication Disorders
   (NIDCD) [P30 DC004661, R21 DC016380-01, R01 DC012769-04]; NIH
   NCATSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Center for Advancing
   Translational Sciences (NCATS) [U54 TR001356]; NATIONAL CENTER FOR
   ADVANCING TRANSLATIONAL SCIENCESUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Center for Advancing Translational Sciences (NCATS) [U54TR001356]
   Funding Source: NIH RePORTER; NATIONAL INSTITUTE ON DEAFNESS AND OTHER
   COMMUNICATION DISORDERSUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R21DC016380,
   R01DC012769, R21DC016380, R21DC016380, R01DC012769] Funding Source: NIH
   RePORTER
FX We thank our funding sources for making this work possible: the American
   Speech-Language-Hearing Foundation (C. M.), NIH NIDCD R21 DC016380-01
   (C. M.), NIH NIDCD R01 DC012769-04 (K. T. and R. B.), NIH NIDCD P30
   DC004661 (Edwin Rubel), and NIH NCATS U54 TR001356 (Gary Rosenthal). We
   would like to thank the community practitioners for advertising our
   study and the participants for their time. We also thank Elizabeth
   Stangl, Claire Jordan, and Gina Hone for collecting data and Elisabeth
   Went for data analysis assistance. The identification of specific
   products or scientific instrumentation does not constitute endorsement
   or implied endorsement on the part of the authors, Department of
   Defense, or any component agency. The views expressed in this
   presentation are those of the authors and do not reflect the official
   policy of the Department of Army/Navy/Air Force, Department of Defense,
   or U.S. Government.
CR Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   *AM NAT STAND I, 2003, S3222003 ANSI
   Anderson ES, 2012, J ACOUST SOC AM, V132, P3925, DOI 10.1121/1.4763999
   ANSI, 1997, S35 ANSI
   BAER T, 1994, J ACOUST SOC AM, V95, P2277, DOI 10.1121/1.408640
   BAER T, 1993, J ACOUST SOC AM, V94, P1229, DOI 10.1121/1.408176
   Bernstein J.G.W., 2016, TRENDS HEARING, V20, P1, DOI [10.1177/2331216516670387, DOI 10.1177/2331216516670387]
   Bernstein JGW, 2013, J AM ACAD AUDIOL, V24, P293, DOI 10.3766/jaaa.24.4.5
   Bernstein JGW, 2009, J ACOUST SOC AM, V125, P3358, DOI 10.1121/1.3110132
   Bor S, 2008, J SPEECH LANG HEAR R, V51, P1315, DOI 10.1044/1092-4388(2008/07-0009)
   BROADBENT DE, 1952, J EXP PSYCHOL, V44, P51, DOI 10.1037/h0056491
   BROKX JPL, 1982, J PHONETICS, V10, P23, DOI 10.1016/S0095-4470(19)30909-X
   Buss E, 2004, EAR HEARING, V25, P242, DOI 10.1097/01.AUD.0000130796.73809.09
   Cabrera L, 2014, J ACOUST SOC AM, V136, P877, DOI 10.1121/1.4887444
   Chi T, 2005, J ACOUST SOC AM, V118, P887, DOI 10.1121/1.1945807
   Chi TS, 1999, J ACOUST SOC AM, V106, P2719, DOI 10.1121/1.428100
   Dau T., 2008, AUDITORY SIGNAL PROC, P263
   Davies-Venn E, 2015, J ACOUST SOC AM, V138, P492, DOI 10.1121/1.4922700
   Dryden A., 2017, TRENDS HEAR, V21, P1
   DUBNO JR, 1984, J ACOUST SOC AM, V76, P87, DOI 10.1121/1.391011
   Dubno JR, 2015, AM J AUDIOL, V24, P84, DOI 10.1044/2015_AJA-14-0052
   Elhilali M, 2003, SPEECH COMMUN, V41, P331, DOI 10.1016/S0167-6393(02)00134-6
   Ewert S. D., 2018, EUROPEAN J NEUROSCIE, DOI [10.1111/ejn.13846, DOI 10.1111/EJN.13846]
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   GLASBERG BR, 1986, J ACOUST SOC AM, V79, P1020, DOI 10.1121/1.393374
   Gorsuch RL, 2013, FACTOR ANAL
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   HALL JW, 1983, J ACOUST SOC AM, V74, P1172, DOI 10.1121/1.390040
   Helfer KS, 2009, J AM ACAD AUDIOL, V20, P264, DOI 10.3766/jaaa.20.4.6
   Helfer KS, 2005, J ACOUST SOC AM, V117, P842, DOI 10.1121/1.1836832
   Henning RLW, 2008, J SPEECH LANG HEAR R, V51, P471, DOI 10.1044/1092-4388(2008/034)
   Henry KS, 2012, NAT NEUROSCI, V15, P1362, DOI 10.1038/nn.3216
   Holube I, 2010, INT J AUDIOL, V49, P891, DOI 10.3109/14992027.2010.506889
   Hopkins K, 2008, J ACOUST SOC AM, V123, P1140, DOI 10.1121/1.2824018
   Hopkins K, 2007, J ACOUST SOC AM, V122, P1055, DOI 10.1121/1.2749457
   Humes LE, 2007, J AM ACAD AUDIOL, V18, P590, DOI 10.3766/jaaa.18.7.6
   Humes Larry E, 2003, Trends Amplif, V7, P41, DOI 10.1177/108471380300700202
   Humes LE, 2015, AM J AUDIOL, V24, P94, DOI 10.1044/2015_AJA-14-0063
   IRWIN RJ, 1982, J ACOUST SOC AM, V71, P967, DOI 10.1121/1.387578
   Jenstad LM, 2005, J SPEECH LANG HEAR R, V48, P651, DOI 10.1044/1092-4388(2005/045)
   Jenstad LM, 2007, J SPEECH LANG HEAR R, V50, P1123, DOI 10.1044/1092-4388(2007/078)
   JOHNSON DH, 1980, J ACOUST SOC AM, V68, P1115, DOI 10.1121/1.384982
   Kale S, 2010, JARO-J ASSOC RES OTO, V11, P657, DOI 10.1007/s10162-010-0223-6
   Kates JM, 2018, EAR HEARING, V39, P1165, DOI 10.1097/AUD.0000000000000574
   KIDD G, 1984, J ACOUST SOC AM, V75, P937, DOI 10.1121/1.390558
   Kirk KI, 2012, J AM ACAD AUDIOL, V23, P464, DOI 10.3766/jaaa.23.6.8
   Kirk KI, 1997, J SPEECH LANG HEAR R, V40, P1395, DOI 10.1044/jslhr.4006.1395
   LEEK MR, 1987, J ACOUST SOC AM, V81, P148, DOI 10.1121/1.395024
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   LOEB GE, 1983, BIOL CYBERN, V47, P149, DOI 10.1007/BF00337005
   Lorenzi C, 2006, P NATL ACAD SCI USA, V103, P18866, DOI 10.1073/pnas.0607364103
   Lorenzi C, 2009, J ACOUST SOC AM, V125, P27, DOI 10.1121/1.2939125
   Lunner T, 2003, INT J AUDIOL, V42, pS49
   MATLAB and Statistics Toolbox, 2013, REL 2013B
   Mehraei G, 2014, J ACOUST SOC AM, V136, P301, DOI 10.1121/1.4881918
   Miller RL, 1997, J ACOUST SOC AM, V101, P3602, DOI 10.1121/1.418321
   Moore B. C. J., 2008, TRENDS AMPLIF, V12, P102
   Moore BCJ, 2002, J ACOUST SOC AM, V111, P327, DOI 10.1121/1.1424871
   Moore BCJ, 1996, J ACOUST SOC AM, V100, P2320, DOI 10.1121/1.417941
   MOORE BCJ, 1994, J ACOUST SOC AM, V96, P741, DOI 10.1121/1.410312
   Moore BCJ, 2003, SPEECH COMMUN, V41, P81, DOI 10.1016/S0167-6393(02)00095-X
   MULLENNIX JW, 1989, J ACOUST SOC AM, V85, P365, DOI 10.1121/1.397688
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Neher T, 2012, J ACOUST SOC AM, V131, P2561, DOI 10.1121/1.3689850
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Pearsons K. S., 1977, 600177025 US ENV PRO
   RUGGERO MA, 1994, AUDIOLOGY, V33, P131
   Smeds K, 2015, J AM ACAD AUDIOL, V26, P183, DOI 10.3766/jaaa.26.2.7
   SMOORENBURG GF, 1992, J ACOUST SOC AM, V91, P421, DOI 10.1121/1.402729
   Souza PE, 1998, J SPEECH LANG HEAR R, V41, P315, DOI 10.1044/jslhr.4102.315
   Stone MA, 2007, J ACOUST SOC AM, V121, P1654, DOI 10.1121/1.2434754
   Stone MA, 2009, J ACOUST SOC AM, V126, P2155, DOI 10.1121/1.3238159
   Strelcyk O, 2009, J ACOUST SOC AM, V125, P3328, DOI 10.1121/1.3097469
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   SUMMERS V, 1994, J ACOUST SOC AM, V95, P3518, DOI 10.1121/1.409969
   Van Engen KJ, 2007, J ACOUST SOC AM, V121, P519, DOI 10.1121/1.2400666
   Won JH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140920
   Wu YH, 2018, EAR HEARING, V39, P293, DOI 10.1097/AUD.0000000000000486
   YUND EW, 1995, J ACOUST SOC AM, V97, P1206, DOI 10.1121/1.413093
   Zekveld AA, 2013, J ACOUST SOC AM, V134, P2225, DOI 10.1121/1.4817926
   Zheng Y, 2017, HEARING RES, V351, P45, DOI 10.1016/j.heares.2017.05.009
NR 83
TC 3
Z9 3
U1 0
U2 3
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD DEC
PY 2018
VL 61
IS 12
BP 3113
EP 3126
DI 10.1044/2018_JSLHR-H-17-0373
PG 14
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA HD6AD
UT WOS:000452612800019
PM 30515519
OA Green Published
DA 2021-02-24
ER

PT J
AU Carlson, MT
AF Carlson, Matthew T.
TI Making Room for Second Language Phonotactics: Effects of L2 Learning and
   Environment on First Language Speech Perception
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Speech perception; bilingualism; phonotactics; perceptual illusion
ID BILINGUALS; KNOWLEDGE; CONSTRAINTS; PLASTICITY; DEAFNESS; JAPANESE
AB Language-specific restrictions on sound sequences in words can lead to automatic perceptual repair of illicit sound sequences. As an example, no Spanish words begin with /s/-consonant sequences ([#sC]), and where necessary (e.g., foreign loanwords) [#sC] is repaired by inserting an initial [e], (e.g. foreign loanwords, cf., esnob, from English snob). As a result, Spanish speakers tend to perceive an illusory [e] before [#sC] sequences. Interestingly, this perceptual illusion is weaker in early Spanish-English bilinguals, whose other language, English, allows [#sC]. The present study explored whether this apparent influence of the English language on Spanish is restricted to early bilinguals, whose early language experience includes a mixture of both languages, or whether later learning of second language (L2) English can also induce a weakening of the first language (L1) perceptual illusion. Two groups of late Spanish-English bilinguals, immersed in Spanish or English, were tested on the same Spanish AX (same-different) discrimination task used in a study by Carlson et al., (2016) and their results compared with the Spanish monolinguals from Carlson et al.'s study. Like early bilinguals, late bilinguals exhibited a reduced impact of perceptual prothesis on discrimination accuracy. Additionally, late bilinguals, particularly in English immersion, were slowest when responding against the Spanish perceptual illusion. Robust L1 perceptual illusions thus appear to be malleable in the face of later L2 learning. It is argued that these results are consonant with the need for late bilinguals to navigate alternative, conflicting representations of the same acoustic material, even in unilingual L1 speech perception tasks.
C1 [Carlson, Matthew T.] Penn State Univ, Dept Spanish Italian & Portuguese, 442 Burrowes Bldg, University Pk, PA 16802 USA.
RP Carlson, MT (corresponding author), Penn State Univ, Dept Spanish Italian & Portuguese, 442 Burrowes Bldg, University Pk, PA 16802 USA.
EM mtc173@psu.edu
FU National Science FoundationNational Science Foundation (NSF)
   [OISE-0968369]
FX Portions of this work were supported by the National Science Foundation
   Partnerships for International Research and Education grant to the
   Center for Language Science at Penn State [OISE-0968369].
CR ALTENBERG EP, 1983, J VERB LEARN VERB BE, V22, P174, DOI 10.1016/S0022-5371(83)90134-2
   ANISFELD M, 1969, J VERB LEARN VERB BE, V8, P257, DOI 10.1016/S0022-5371(69)80072-1
   Baus C, 2013, ACTA PSYCHOL, V142, P402, DOI 10.1016/j.actpsy.2013.01.010
   Berent I, 2007, COGNITION, V104, P591, DOI 10.1016/j.cognition.2006.05.015
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   CARAMAZZA A, 1974, CAN J PSYCHOL, V28, P310, DOI 10.1037/h0081997
   CARLISLE RS, 1991, APPL LINGUIST, V12, P76, DOI 10.1093/applin/12.1.76
   Carlson MT, 2016, BILING-LANG COGN, V19, P939, DOI 10.1017/S1366728915000334
   Chang CB, 2012, J PHONETICS, V40, P249, DOI 10.1016/j.wocn.2011.10.007
   Cook VJ., 2003, EFFECTS 2 LANGUAGE 1
   Cuetos F, 2011, P 17 INT C PHON SCI, P540
   Daland R, 2015, OPEN LINGUIST, V1, P650, DOI 10.1515/opli-2015-0024
   Davidson L, 2011, J EXP PSYCHOL HUMAN, V37, P270, DOI 10.1037/a0020988
   Dijkstra T., 1998, BILING-LANG COGN, V1, P51, DOI DOI 10.1017/S1366728998000121
   Dupoux E, 2001, LANG COGNITIVE PROC, V16, P491, DOI 10.1080/01690960143000191
   Dupoux E, 1997, J MEM LANG, V36, P406, DOI 10.1006/jmla.1996.2500
   Dupoux E, 1999, J EXP PSYCHOL HUMAN, V25, P1568, DOI 10.1037/0096-1523.25.6.1568
   Dupoux E, 2008, COGNITION, V106, P682, DOI 10.1016/j.cognition.2007.04.001
   Dupoux E, 2011, J MEM LANG, V64, P199, DOI 10.1016/j.jml.2010.12.004
   English language Institute, 2001, MELICET GCVR US MAN
   Flege J. E., 2003, PHONETICS PHONOLOGY, P319, DOI DOI 10.1515/9783110895094.319
   FLEGE JE, 1987, J PHONETICS, V15, P67, DOI 10.1016/S0095-4470(19)30538-8
   Freeman MR, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00702
   Gildersleeve-Neumann CE, 2009, BILING-LANG COGN, V12, P259, DOI 10.1017/S1366728908003994
   Goldrick M, 2014, PSYCHOL SCI, V25, P1031, DOI 10.1177/0956797613520014
   Gollan TH, 2012, BILING-LANG COGN, V15, P594, DOI 10.1017/S1366728911000332
   Gonzales K, 2013, PSYCHOL SCI, V24, P2135, DOI 10.1177/0956797613486485
   Green DW, 2013, J COGN PSYCHOL, V25, P515, DOI 10.1080/20445911.2013.796377
   Hall JK, 2006, APPL LINGUIST, V27, P220, DOI 10.1093/applin/aml013
   Kroll JF, 2006, BILING-LANG COGN, V9, P119, DOI 10.1017/S1366728906002483
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Lentz TO, 2015, LANG SPEECH, V58, P387, DOI 10.1177/0023830914559572
   Li P, 2014, BILING-LANG COGN, V17, P673, DOI 10.1017/S1366728913000606
   Linck JA, 2009, PSYCHOL SCI, V20, P1507, DOI 10.1111/j.1467-9280.2009.02480.x
   MacWhinney B, 2005, HDB BILINGUALISM PSY, P49
   MacWhinney B., 2008, HDB COGNITIVE LINGUI, P341
   Ministry of Education Culture and Sport of Spain, 2006, DIPL ESP COM LENG EX
   Pallier C, 1997, COGNITION, V64, pB9, DOI 10.1016/S0010-0277(97)00030-9
   Parlato-Oliveira E, 2010, J ACOUST SOC AM, V127, P3738, DOI 10.1121/1.3327792
   Polivanov Evgenij D., 1931, TRAVAUX CERCLE LINGU, V4, P79
   Psychology Software Tools, E PRIM VERS 2 0
   Sancier ML, 1997, J PHONETICS, V25, P421, DOI 10.1006/jpho.1997.0051
   Sebastian-Galles N, 2002, J EXP PSYCHOL HUMAN, V28, P974, DOI 10.1037//0096-1523.28.4.974
   Trapman M, 2009, LANG ACQUIS, V16, P178, DOI 10.1080/10489220903011636
NR 44
TC 2
Z9 2
U1 1
U2 9
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD DEC
PY 2018
VL 61
IS 4
SI SI
BP 598
EP 614
DI 10.1177/0023830918767208
PG 17
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA HA5XW
UT WOS:000450354100006
PM 29629824
OA Bronze
DA 2021-02-24
ER

PT J
AU Wiener, S
   Ito, K
   Speer, SR
AF Wiener, Seth
   Ito, Kiwako
   Speer, Shari R.
TI Early L2 Spoken Word Recognition Combines Input-Based and
   Knowledge-Based Processing
SO LANGUAGE AND SPEECH
LA English
DT Article
DE Spoken word recognition; speaker variability; lexical tone; Mandarin
   Chinese; second language acquisition
ID TRAINING JAPANESE LISTENERS; R-VERTICAL-BAR; MANDARIN CHINESE TONES;
   SPEECH-PERCEPTION; LEXICAL ACCESS; SPEAKER NORMALIZATION; ACOUSTIC
   VARIABILITY; TALKER VARIABILITY; CUE-INTEGRATION; TIME-COURSE
AB This study examines the perceptual trade-off between knowledge of a language's statistical regularities and reliance on the acoustic signal during L2 spoken word recognition. We test how early learners track and make use of segmental and suprasegmental cues and their relative frequencies during non-native word recognition. English learners of Mandarin were taught an artificial tonal language in which a tone's informativeness for word identification varied according to neighborhood density. The stimuli mimicked Mandarin's uneven distribution of syllable+tone combinations by varying syllable frequency and the probability of particular tones co-occurring with a particular syllable. Use of statistical regularities was measured by four-alternative forced-choice judgments and by eye fixations to target and competitor symbols. Half of the participants were trained on one speaker, that is, low speaker variability while the other half were trained on four speakers. After four days of learning, the results confirmed that tones are processed according to their informativeness. Eye movements to the newly learned symbols demonstrated that L2 learners use tonal probabilities at an early stage of word recognition, regardless of speaker variability. The amount of variability in the signal, however, influenced the time course of recovery from incorrect anticipatory looks: participants exposed to low speaker variability recovered from incorrect probability-based predictions of tone more rapidly than participants exposed to greater variability. These results motivate two conclusions: early L2 learners track the distribution of segmental and suprasegmental co-occurrences and make predictions accordingly during spoken word recognition; and when the acoustic input is more variable because of multi-speaker input, listeners rely more on their knowledge of tone-syllable co-occurrence frequency distributions and less on the incoming acoustic signal.
C1 [Wiener, Seth] Carnegie Mellon Univ, Dept Modern Languages, 160 Baker Hall,5000 Forbes Ave, Pittsburgh, PA 15213 USA.
   [Ito, Kiwako; Speer, Shari R.] Ohio State Univ, Dept Linguist, Columbus, OH 43210 USA.
RP Wiener, S (corresponding author), Carnegie Mellon Univ, Dept Modern Languages, 160 Baker Hall,5000 Forbes Ave, Pittsburgh, PA 15213 USA.
EM sethw1@cmu.edu
OI Wiener, Seth/0000-0002-7383-3682; Ito, Kiwako/0000-0001-9778-6940
FU National Science FoundationNational Science Foundation (NSF)
   [BCS-1451677]
FX This work was supported by a Doctoral Dissertation Research Improvement
   Grant from the National Science Foundation (grant number BCS-1451677) to
   the first two authors.
CR Aoyama K, 2004, J PHONETICS, V32, P233, DOI 10.1016/S0095-4470(03)00036-6
   Barcroft J, 2005, STUD SECOND LANG ACQ, V27, P387, DOI 10.1017/S0272263105050175
   Barr DJ, 2011, ACTA PSYCHOL, V137, P201, DOI 10.1016/j.actpsy.2010.09.011
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   BLICHER DL, 1990, J PHONETICS, V18, P37, DOI 10.1016/S0095-4470(19)30357-2
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P977, DOI 10.3758/BF03206911
   Broselow E., 1987, INTERLANGUAGE PHONOL, P350
   Cai Q, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010729
   Caldwell-Harris CL, 2015, STUD SECOND LANG ACQ, V37, P335, DOI 10.1017/S0272263114000849
   CC CEDICT, 2016, ONL OP SOURC CHIN DI
   Chandrasekaran B, 2010, J ACOUST SOC AM, V128, P456, DOI 10.1121/1.3445785
   Chen HC, 2009, LANG COGNITIVE PROC, V24, P967, DOI 10.1080/01690960902804515
   Clayards M, 2008, COGNITION, V108, P804, DOI 10.1016/j.cognition.2008.04.004
   CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407
   Creel SC, 2006, J EXP PSYCHOL LEARN, V32, P15, DOI 10.1037/0278-7393.32.1.15
   Creel SC, 2006, J MEM LANG, V54, P1, DOI 10.1016/j.jml.2005.09.003
   Dahan D, 2001, COGNITIVE PSYCHOL, V42, P317, DOI 10.1006/cogp.2001.0750
   Duanmu S., 2007, PHONOLOGY STANDARD C
   Duanmu S., 2009, SYLLABLE STRUCTURE L
   Ellis N. C., 2011, HDB 2 LANGUAGE ACQUI, P193
   Escudero P, 2004, STUD SECOND LANG ACQ, V26, P551, DOI 10.1017/S0272226310400021
   Escudero P, 2014, COGNITION, V133, P408, DOI 10.1016/j.cognition.2014.07.002
   Escudero P, 2011, J ACOUST SOC AM, V130, pEL206, DOI 10.1121/1.3629144
   Escudero P, 2009, J PHONETICS, V37, P452, DOI 10.1016/j.wocn.2009.07.006
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   FLEGE JE, 1995, SPEECH COMMUN, V16, P1, DOI 10.1016/0167-6393(94)00044-B
   Flege JE, 1999, SEC LANG ACQ RES, P101
   FOX RA, 1985, J CHINESE LINGUIST, V13, P69
   FOX RA, 1990, J CHINESE LINGUIST, V18, P261
   Gelman A, 2014, PERSPECT PSYCHOL SCI, V9, P641, DOI 10.1177/1745691614551642
   Gomez RL, 2000, TRENDS COGN SCI, V4, P178, DOI 10.1016/S1364-6613(00)01467-4
   GOTO H, 1971, NEUROPSYCHOLOGIA, V9, P317, DOI 10.1016/0028-3932(71)90027-3
   Gottfried TL, 1997, J PHONETICS, V25, P207, DOI 10.1006/jpho.1997.0042
   Green P, 2016, METHODS ECOL EVOL, V7, P493, DOI 10.1111/2041-210X.12504
   Halle PA, 2004, J PHONETICS, V32, P395, DOI 10.1016/S0095-4470(03)00016-0
   Hao YC, 2012, J PHONETICS, V40, P269, DOI 10.1016/j.wocn.2011.11.001
   Hayes-Harb R, 2007, SECOND LANG RES, V23, P65, DOI 10.1177/0267658307071601
   Hirata Y, 2007, J ACOUST SOC AM, V121, P3837, DOI 10.1121/1.2734401
   HO AT, 1976, PHONETICA, V33, P353, DOI 10.1159/000259792
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Howie J.M., 1976, ACOUSTICAL STUDIES M
   Huang JY, 2009, J ACOUST SOC AM, V125, P3983, DOI 10.1121/1.3125342
   Idemaru K, 2014, J EXP PSYCHOL HUMAN, V40, P1009, DOI 10.1037/a0035269
   Idemaru K, 2011, J EXP PSYCHOL HUMAN, V37, P1939, DOI 10.1037/a0025641
   Jongman A, 2006, HANDBOOK OF EAST ASIAN PSYCHOLINGUISTICS, VOL 1: CHINESE, P209
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   Kroll J.F., 2002, SECOND LANG RES, V18, P137, DOI DOI 10.1191/0267658302SR2010A
   Kuperberg GR, 2016, LANG COGN NEUROSCI, V31, P32, DOI 10.1080/23273798.2015.1102299
   LEATHER J, 1983, J PHONETICS, V11, P373, DOI 10.1016/S0095-4470(19)30836-8
   Lee C.-Y., 2013, SPEECH LANGUAGE HEAR, V16, P1, DOI DOI 10.1179/2050571X12Z.0000000003
   Lee CY, 2010, SPEECH COMMUN, V52, P900, DOI 10.1016/j.specom.2010.01.004
   Lee CY, 2009, J PHONETICS, V37, P1, DOI 10.1016/j.wocn.2008.08.001
   LI CN, 1977, J CHILD LANG, V4, P185, DOI 10.1017/S0305000900001598
   Li P, 1998, READ WRIT, V10, P223, DOI 10.1023/A:1008091816322
   Li P., 2002, SENTENCE PROCESSING, P111
   Lim SJ, 2011, COGNITIVE SCI, V35, P1390, DOI 10.1111/j.1551-6709.2011.01192.x
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   Liu SY, 2007, LANG COGNITIVE PROC, V22, P566, DOI 10.1080/01690960600989600
   Liu SY, 2004, LANG SPEECH, V47, P109, DOI 10.1177/00238309040470020101
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   LOGAN JS, 1991, J ACOUST SOC AM, V89, P874, DOI 10.1121/1.1894649
   MacWhinney B, 2005, HDB BILINGUALISM PSY, P49
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   Magnuson JS, 2003, J EXP PSYCHOL GEN, V132, P202, DOI 10.1037/0096-3445.132.2.202
   Malins JG, 2010, J MEM LANG, V62, P407, DOI 10.1016/j.jml.2010.02.004
   MATIN E, 1993, PERCEPT PSYCHOPHYS, V53, P372, DOI 10.3758/BF03206780
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   McMurray B, 2008, J EXP PSYCHOL HUMAN, V34, P1609, DOI 10.1037/a0011747
   McQueen J. M., 2010, HDB PHONETIC SCI, P489
   McQueen JM, 2006, COGNITIVE SCI, V30, P1113, DOI 10.1207/s15516709cog0000_79
   Misyak JB, 2012, LANG LEARN, V62, P302, DOI 10.1111/j.1467-9922.2010.00626.x
   Moore CB, 1997, J ACOUST SOC AM, V102, P1864, DOI 10.1121/1.420092
   MULLENNIX JW, 1989, J ACOUST SOC AM, V85, P365, DOI 10.1121/1.397688
   Myers J., 2002, J CHINESE PHONOLOGY, V11, P163
   Myers J., 2010, MENTAL LEXICON, V5, P423
   Nixon JS, 2016, J MEM LANG, V90, P103, DOI 10.1016/j.jml.2016.03.005
   Nixon JS, 2015, LANG COGN NEUROSCI, V30, P491, DOI 10.1080/23273798.2014.942326
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Norris D, 2008, PSYCHOL REV, V115, P357, DOI 10.1037/0033-295X.115.2.357
   Nusbaum HC, 1992, SPEECH PERCEPTION PR, P113
   Nygaard LC, 1998, PERCEPT PSYCHOPHYS, V60, P355, DOI 10.3758/BF03206860
   NYGAARD LC, 1994, PSYCHOL SCI, V5, P42, DOI 10.1111/j.1467-9280.1994.tb00612.x
   Ong JH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0133446
   Packard J.L., 2000, MORPHOLOGY CHINESE L
   Packard JL, 1999, BRAIN LANG, V68, P89, DOI 10.1006/brln.1999.2102
   Peng S.-H., 2000, PAPERS LAB PHONOLOGY, P152
   Perrachione TK, 2011, J ACOUST SOC AM, V130, P461, DOI 10.1121/1.3593366
   R Core Team, 2016, R LANG ENV STAT COMP
   REPP BH, 1990, J PHONETICS, V18, P481, DOI 10.1016/S0095-4470(19)30410-3
   Rost GC, 2010, INFANCY, V15, P608, DOI 10.1111/j.1532-7078.2010.00033.x
   Sadakata M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01318
   Sadakata M, 2013, J ACOUST SOC AM, V134, P1324, DOI 10.1121/1.4812767
   Saffran JR, 2003, CURR DIR PSYCHOL SCI, V12, P110, DOI 10.1111/1467-8721.01243
   Saffran JR, 1996, J MEM LANG, V35, P606, DOI 10.1006/jmla.1996.0032
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Samuel AG, 2011, ANNU REV PSYCHOL, V62, P49, DOI 10.1146/annurev.psych.121208.131643
   SHEN XNS, 1991, LANG SPEECH, V34, P145, DOI 10.1177/002383099103400202
   SHEN XS, 1990, J PHONETICS, V18, P281, DOI 10.1016/S0095-4470(19)30394-8
   Shih C., 1997, STUDIES CHINESE PHON, P81, DOI [DOI 10.1515/9783110822014.81, 10.1515/9783110822014.81]
   Shook A, 2013, BILING-LANG COGN, V16, P304, DOI 10.1017/S1366728912000466
   Shuai L, 2017, BEHAV RES METHODS, V49, P230, DOI 10.3758/s13428-015-0690-0
   So CK, 2010, LANG SPEECH, V53, P273, DOI 10.1177/0023830909357156
   Sommers MS, 2007, APPL PSYCHOLINGUIST, V28, P231, DOI 10.1017/S0142716407070129
   STRANGE W, 1995, SPEECH PERCEPTION LI
   Sulpizio S, 2012, J MEM LANG, V66, P177, DOI 10.1016/j.jml.2011.08.001
   Tan L. H., 1998, COGNITIVE PROCESSING, P11, DOI DOI 10.1007/978-94-015-9161-4_2
   Toscano JC, 2012, ATTEN PERCEPT PSYCHO, V74, P1284, DOI 10.3758/s13414-012-0306-z
   Toscano JC, 2010, COGNITIVE SCI, V34, P434, DOI 10.1111/j.1551-6709.2009.01077.x
   Walker G., 1989, CHINESE PEDAGOGY, P181
   Wang H. S., 1998, STUDIA LINGUISTICA S, P259
   Wang Y, 2003, J ACOUST SOC AM, V113, P1033, DOI 10.1121/1.1531176
   Wang Y, 1999, J ACOUST SOC AM, V106, P3649, DOI 10.1121/1.428217
   Wang Y, 2006, HANDBOOK OF EAST ASIAN PSYCHOLINGUISTICS, VOL 1: CHINESE, P250
   Wanrooij K, 2013, J PHONETICS, V41, P307, DOI 10.1016/j.wocn.2013.03.005
   Wayland RP, 2004, LANG LEARN, V54, P681, DOI 10.1111/j.1467-9922.2004.00283.x
   Weber A, 2004, J MEM LANG, V50, P1, DOI 10.1016/S0749-596X(03)00105-0
   Wiener S, 2016, J PHONETICS, V56, P38, DOI 10.1016/j.wocn.2016.02.001
   Wiener S, 2016, LANG SPEECH, V59, P59, DOI 10.1177/0023830915578000
   Wiener S, 2015, LANG COGN NEUROSCI, V30, P1048, DOI 10.1080/23273798.2014.946934
   Wong PCM, 2007, APPL PSYCHOLINGUIST, V28, P565, DOI 10.1017/S0142716407070312
   Wu JR, 2014, LANG COGN NEUROSCI, V29, P1317, DOI 10.1080/23273798.2014.915977
   Xu Y, 1997, J PHONETICS, V25, P61, DOI 10.1006/jpho.1996.0034
   XU Y, 1994, J ACOUST SOC AM, V95, P2240, DOI 10.1121/1.408684
   Xu Y., 2001, J CHINESE LINGUISTIC, V17, P1
   Ye Y, 1999, LANG COGNITIVE PROC, V14, P609, DOI 10.1080/016909699386202
   Zee Y.-Y., 1980, THESIS
NR 130
TC 6
Z9 6
U1 1
U2 9
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0023-8309
EI 1756-6053
J9 LANG SPEECH
JI Lang. Speech
PD DEC
PY 2018
VL 61
IS 4
SI SI
BP 632
EP 656
DI 10.1177/0023830918761762
PG 25
WC Audiology & Speech-Language Pathology; Linguistics; Psychology,
   Experimental
SC Audiology & Speech-Language Pathology; Linguistics; Psychology
GA HA5XW
UT WOS:000450354100008
PM 29560782
OA Bronze
DA 2021-02-24
ER

PT J
AU Iino, H
   Ohta, K
   Hara, K
   Miyajima, M
   Hara, M
   Matsushima, E
   Matsuura, M
AF Iino, Hiroko
   Ohta, Katsuya
   Hara, Keiko
   Miyajima, Miho
   Hara, Minoru
   Matsushima, Eisuke
   Matsuura, Masato
TI Vowel-speech versus pure-tone processing in healthy subjects
SO NEUROSCIENCE RESEARCH
LA English
DT Article
DE MMN; ERP; Language; Perception; Verbal; Auditory; Gender; Age
ID PHONETIC MISMATCH NEGATIVITY; LANGUAGE; REPRESENTATION; INTEGRATION;
   PITCH; MMN
AB To investigate the characteristics of speech perception, we evaluated the differences in mismatch negativity (MMN) between vowel change and frequency change. Additionally, we examined the effects of gender, age, and educational length on MMN. Forty healthy adults (21 females), who were native Japanese speak- ers, participated in the study. A Japanese vowel-speech pair (standard/a/vs. deviant/o/) and a pure-tone pair (standard 1000 Hz vs. deviant 1050 Hz) were constructed. MMN elicited by vowel-speech sounds was larger and earlier compared with pure-tone sounds. Larger and earlier MMNs for vowel-speech sounds than for pure-tone sounds suggest different processing of linguistically relevant information at the early stage in the auditory cortex. In conclusion, the factors influencing on MMN are different between vowel-speech sounds and pure-tone sounds. (C) 2018 Elsevier B.V. and Japan Neuroscience Society. All rights reserved.
C1 [Iino, Hiroko; Ohta, Katsuya; Hara, Keiko; Matsuura, Masato] Tokyo Med & Dent Univ, Grad Sch Hlth Care Sci, Biomed Lab Sci,Biofunct Informat, Bunkyo Ku, 1-5-45 Yushima, Tokyo 1138510, Japan.
   [Iino, Hiroko] Univ Tokyo Hosp, Dept Clin Lab, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138655, Japan.
   [Ohta, Katsuya; Miyajima, Miho; Matsushima, Eisuke] Tokyo Med & Dent Univ, Grad Sch Med & Dent Sci, Sect Liaison Psychiat & Palliat Med, Bunkyo Ku, 1-5-45 Yushima, Tokyo 1138510, Japan.
   [Ohta, Katsuya] Onda Daini Hosp, 302 Kanegasaku, Matsudo, Chiba 2702251, Japan.
   [Hara, Keiko; Hara, Minoru] Hara Clin, Minami Ku, 1-1 Urahuna Cho, Yokohama, Kanagawa 2320024, Japan.
RP Iino, H (corresponding author), Tokyo Med & Dent Univ, Grad Sch Hlth Care Sci, Biomed Lab Sci,Biofunct Informat, Bunkyo Ku, 1-5-45 Yushima, Tokyo 1138510, Japan.
EM iinoh-lab@h.u-tokyo.ac.jp
CR Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Bronnick KS, 2010, NEUROBIOL AGING, V31, P104, DOI 10.1016/j.neurobiolaging.2008.02.021
   Diesch E, 1997, PSYCHOPHYSIOLOGY, V34, P501, DOI 10.1111/j.1469-8986.1997.tb01736.x
   Fischer C, 2004, NEUROLOGY, V63, P669, DOI 10.1212/01.WNL.0000134670.10384.E2
   Fisher DJ, 2008, INT J PSYCHOPHYSIOL, V70, P3, DOI 10.1016/j.ijpsycho.2008.04.001
   Hagoort P, 2008, PHILOS T R SOC B, V363, P1055, DOI 10.1098/rstb.2007.2159
   Inouchi M, 2004, NEUROSCI LETT, V366, P342, DOI 10.1016/j.neulet.2004.05.065
   Inouchi M, 2008, BRAIN RES, V1232, P155, DOI 10.1016/j.brainres.2008.07.026
   Kasai K, 2002, COGNITIVE BRAIN RES, V13, P305, DOI 10.1016/S0926-6410(01)00125-2
   Kasai K, 2002, AM J PSYCHIAT, V159, P546, DOI 10.1176/appi.ajp.159.4.546
   Kawakubo Y, 2007, PSYCHIAT RES, V152, P261, DOI 10.1016/j.psychres.2006.02.010
   Kraus N, 1998, AUDIOL NEURO-OTOL, V3, P168, DOI 10.1159/000013788
   KURIKI S, 1989, EXP BRAIN RES, V77, P127
   Lidji P, 2010, CLIN NEUROPHYSIOL, V121, P533, DOI 10.1016/j.clinph.2009.12.018
   May P, 1999, J COMPUT NEUROSCI, V6, P99, DOI 10.1023/A:1008896417606
   Miyajima M, 2011, EPILEPSY RES, V94, P149, DOI 10.1016/j.eplepsyres.2011.01.009
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 1997, NATURE, V385, P432, DOI 10.1038/385432a0
   Naatanen R, 2000, INT J PSYCHOPHYSIOL, V37, P3, DOI 10.1016/S0167-8760(00)00091-X
   Pantev C, 1996, HEARING RES, V101, P62, DOI 10.1016/S0378-5955(96)00133-5
   Pulvermuller F, 2006, PROG NEUROBIOL, V79, P49, DOI 10.1016/j.pneurobio.2006.04.004
   Samson F, 2006, J AUTISM DEV DISORD, V36, P65, DOI 10.1007/s10803-005-0043-4
   Schiff S, 2008, CLIN NEUROPHYSIOL, V119, P1795, DOI 10.1016/j.clinph.2008.04.007
   Sorokin A, 2010, BRAIN RES, V1327, P77, DOI 10.1016/j.brainres.2010.02.052
   Takei Y, 2009, PSYCHOPHYSIOLOGY, V46, P52, DOI 10.1111/j.1469-8986.2008.00748.x
   Tervaniemi M, 2003, ANN NY ACAD SCI, V999, P23
   TIITINEN H, 1994, NEUROREPORT, V6, P190, DOI 10.1097/00001756-199412300-00048
   Uppenkamp S, 2006, NEUROIMAGE, V31, P1284, DOI 10.1016/j.neuroimage.2006.01.004
   Young ED, 2008, PHILOS T R SOC B, V363, P923, DOI 10.1098/rstb.2007.2151
   Zatorre RJ, 2008, PHILOS T R SOC B, V363, P1087, DOI 10.1098/rstb.2007.2161
NR 30
TC 0
Z9 0
U1 0
U2 2
PU ELSEVIER IRELAND LTD
PI CLARE
PA ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000,
   IRELAND
SN 0168-0102
EI 1872-8111
J9 NEUROSCI RES
JI Neurosci. Res.
PD DEC
PY 2018
VL 137
BP 43
EP 48
DI 10.1016/j.neures.2018.03.002
PG 6
WC Neurosciences
SC Neurosciences & Neurology
GA HB4MJ
UT WOS:000451026800006
PM 29630919
DA 2021-02-24
ER

PT J
AU Schmidt, LB
AF Schmidt, Lauren B.
TI L2 DEVELOPMENT OF PERCEPTUAL CATEGORIZATION OF DIALECTAL SOUNDS A STUDY
   IN SPANISH
SO STUDIES IN SECOND LANGUAGE ACQUISITION
LA English
DT Article
ID SPEECH-PERCEPTION; ABROAD CONTEXT; ACQUISITION; ENGLISH; VOWELS
AB The present study examined second language (L2) development in the perceptual identification of a dialectal sound of the target language, through an investigation of the role of individual learner experiences in L2 phonological development. A total of 213 English-speaking learners of Spanish across five levels of study and with varying dialect contact experiences completed an identification task, which tested perceptual categorization of Spanish dialectal aspirated-s (e.g., siesta [sieh-ta]). In accordance with postulates of L2 speech perception models (PAM-L2, SLM, L2LP), findings revealed influence of the first language phonology on categorization at early levels shifting toward nativelike, dialect-specific categorizations of aspirated-s for more experienced learners. Dialect contact factors of prior study abroad location, native speaker social contacts, and metalinguistic training were found to be predictors of the dialectal perceptual targets toward which the L2 learners developed for those learners past intermediate-level language courses-highlighting how individual experiences shape L2 perceptual abilities.
C1 [Schmidt, Lauren B.] San Diego State Univ, 5500 Campanile Dr, San Diego, CA 92182 USA.
RP Schmidt, LB (corresponding author), San Diego State Univ, 5500 Campanile Dr, San Diego, CA 92182 USA.
EM lschmidt@sdsu.edu
OI Schmidt, Lauren/0000-0002-6733-7332
CR Baker W, 2010, CAN MOD LANG REV, V66, P711, DOI 10.3138/cmlr.66.5.711
   Baker W, 2009, AM SPEECH, V84, P48, DOI 10.1215/00031283-2009-004
   Bayley R., 1996, 2 LANGUAGE ACQUISITI, P97, DOI DOI 10.1075/SIBIL.10.05BAY
   BEEBE LM, 1980, LANG LEARN, V30, P433, DOI 10.1111/j.1467-1770.1980.tb00327.x
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2009, PRAAT DOING PHONETIC
   Canale M., 1980, APPL LINGUIST, V1, P1, DOI [DOI 10.1093/APPLIN/1.1.1, 10.1093/applin/1.1.1]
   Dohotaru P, 2004, PENSAMIENTO LINGUIST, P68
   Drummond R, 2013, J ENGL LINGUIST, V41, P65, DOI 10.1177/0075424212449172
   Escudero P, 2004, STUD SECOND LANG ACQ, V26, P551, DOI 10.1017/S0272226310400021
   ESCUDERO P., 2005, THESIS, P348
   File-Muriel R. J., 2007, THESIS
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Fox R. A., 2007, LANGUAGE EXPERIENCE, P117
   Geeslin K. L., 2008, SEL P 10 HISP LING S, P64
   Geeslin K. L., 2018, SPEAKING 2 LANGUAGE, P2
   Geeslin K. L., 2011, J APPL LINGUISTICS, V5, P137
   Geeslin K. L., 2014, SOCIOLINGUISTICS 2 L
   George A, 2014, FOREIGN LANG ANN, V47, P97, DOI 10.1111/flan.12065
   Hammond RM, 2001, SOUNDS SPANISH ANAL
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Henriksen N. C., 2010, STUDIES HISPANIC LUS, V3, P113, DOI DOI 10.1515/SHLL-2010-1067
   Howard Martin, 2013, OXFORD HDB SOCIOLING, P340, DOI DOI 10.1093/OXFORDHB/9780199744084.013.0017
   Hualde Jose Ignacio, 2005, SOUNDS SPANISH
   IBM Corp, 2016, IBM SPSS STAT WIND V
   Knouse SM, 2012, FOREIGN LANG ANN, V45, P512, DOI 10.1111/j.1944-9720.2013.12003.x
   Ladefoged P., 2006, COURSE PHONETICS
   Lafford B, 1986, ESTUDIOS FONOLOGIA E, P53
   Lipski John M., 1994, LATIN AM SPANISH
   Marriott H, 1995, 2 LANGUAGE ACQUISITI, P198, DOI DOI 10.1075/SIBIL.9.13MAR
   McMahon A., 2002, INTRO ENGLISH PHONOL
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   Raish M, 2015, FOREIGN LANG ANN, V48, P267, DOI 10.1111/flan.12140
   Rehner K., 2003, STUDIES 2 LANGUAGE A, V25, P127, DOI DOI 10.1017/S0272263103000056
   Rehner Katherine, 2002, THESIS
   Ringer-Hilfinger K, 2012, FOREIGN LANG ANN, V45, P430, DOI 10.1111/j.1944-9720.2012.01201.x
   Ruiz-Sanchez Carmen, 2004, B LINGUIST, V21, P48
   SALGADO-ROBLES F., 2011, THESIS
   Samper Padilla Jose A, 1990, ESTUDIO SOCIOLINGUIS
   Schmidt Lauren B, 2015, BOREALIS INT J HISPA, V4, P99
   Schmidt R., 2001, COGNITION 2 LANGUAGE, P3, DOI DOI 10.1017/CBO9781139524780.003
   SCHMIDT RW, 1990, APPL LINGUIST, V11, P129, DOI 10.1093/applin/11.2.129
   Smith LC, 2011, POZ STUD CONTEMP LIN, V47, P120, DOI 10.2478/psicl-2011-0010
   Strange W., 2008, PHONOLOGY 2 LANGUAGE, P153
   Sumner M, 2009, J MEM LANG, V60, P487, DOI 10.1016/j.jml.2009.01.001
   TERRELL T, 1981, VARIATION OMNIBUS, P115
   Terrell Tracy D, 1979, HISPANIA, V62, P599, DOI DOI 10.2307/340142
   Trimble J. C, 2013, SEL P 15 HISP LING S, P78
   Valdman A, 1988, WORLD ENGLISH, V7, P221, DOI [10.1111/j.1467-971X.1988.tb00233.x, DOI 10.1111/J.1467-971X.1988.TB00233.X]
   van Leussen JW, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01000
   Wolfram W, 2004, J SOCIOLING, V8, P339, DOI 10.1111/j.1467-9841.2004.00264.x
   Young R, 1988, THESIS
NR 53
TC 3
Z9 3
U1 1
U2 9
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0272-2631
EI 1470-1545
J9 STUD SECOND LANG ACQ
JI Stud. Second Lang. Acquis.
PD DEC
PY 2018
VL 40
IS 4
BP 857
EP 882
DI 10.1017/S0272263118000116
PG 26
WC Linguistics
SC Linguistics
GA HC3PD
UT WOS:000451713700007
DA 2021-02-24
ER

PT J
AU Joseph, BE
   Vinod, N
   Thomas, DM
   Krishnan, SA
AF Joseph, Bennet Elsa
   Vinod, Nituna
   Thomas, Dona Maria
   Krishnan, Arya S.
TI Awareness amongst Audiologists Regarding Effects of Radiation Therapy on
   Auditory System
SO NITTE UNIVERSITY JOURNAL OF HEALTH SCIENCE
LA English
DT Article
DE Audiologists; radiation therapy; hearing loss; auditory symptoms
AB Background: Radiation therapy has been a life saver for patients suffering from cancer. Hearing loss can be one of the many side effects of radiation therapy. It can affect the integration of the patient into society after the treatment of cancer is complete. Along with hearing loss, the patients may also experience other auditory symptoms like tinnitus, loudness intolerance and speech perception difficulties which are to be assessed, diagnosed and treated by Audiologists. In order to provide effective rehabilitation, it is necessary that Audiologists are aware of the effect of radiation therapy on the auditory system and what role they play in the interdisciplinary approach. The aim of the present study was to briefly assess whether this awareness is present amongst Audiologists.
   Method: A questionnaire was prepared to comprise of questions related to the various aspects of effects of radiation therapy on the auditory system. The questionnaire was circulated online amongst Audiologists and completed questionnaires were subjected to descriptive statistical analysis.
   Results : Only 76.9% Audiologists who were part of the survey were sure that hearing loss can be a side effect of radiation therapy. Many of the Audiologists were not sure whether they should provide audiological services to the patient before radiation therapy or after radiation therapy. 44% were not sure about what measures could be taken to reduce the effect of radiation therapy on the auditory system. 96.3% stated that there is a need to receive more specific training in dealing with rehabilitative cases post radiation therapy.
C1 [Joseph, Bennet Elsa; Vinod, Nituna; Thomas, Dona Maria; Krishnan, Arya S.] Nitte Inst Speech & Hearing, Mangaluru, India.
RP Joseph, BE (corresponding author), Nitte Inst Speech & Hearing, Mangaluru, India.
EM bennetelsa@gmail.com
CR Bentzen SM, 2006, NAT REV CANCER, V6, P702, DOI 10.1038/nrc1950
   Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492
   de Oliveira PF, 2017, OTOLARYNGOLOGY, V07, P7, DOI [10.4172/2161-119X.1000299, DOI 10.4172/2161-119X.1000299]
   GABRIELE P, 1992, RADIOTHER ONCOL, V25, P25, DOI 10.1016/0167-8140(92)90191-V
   Hua CH, 2008, INT J RADIAT ONCOL, V72, P892, DOI 10.1016/j.ijrobp.2008.01.050
   Kramer SE, 2002, J AGING HEALTH, V14, P122, DOI 10.1177/089826430201400107
   Lambert EM, 2016, HEAD NECK-J SCI SPEC, V38, P1428, DOI 10.1002/hed.24267
   Merchant TE, 2009, J CLIN ONCOL, V27, P3691, DOI 10.1200/JCO.2008.21.2738
   Schultz C, 2010, ARCH OTOLARYNGOL, V136, P1065, DOI 10.1001/archoto.2010.180
   Sharad Nilakhe S., 2014, EFFECTS RADIOTHERAPY
   Shiel William C, RAD THERAPY
   Wang LF, 2004, OTOL NEUROTOL, V25, P168, DOI 10.1097/00129492-200403000-00015
   Zhang Yu, 2009, Ai Zheng, V28, P1143
NR 13
TC 0
Z9 0
U1 0
U2 0
PU NITTE UNIV
PI KARNATAKA
PA 6TH FL, UNIV ENCLAVE, MEDICAL SCIENCES COMPLEX, MANGALORE, KARNATAKA,
   575 018, INDIA
SN 2249-7110
J9 NITTE UNIV J HEALTH
JI NITTE UNIV. J. HEALTH SCI.
PD DEC
PY 2018
VL 8
IS 4
BP 15
EP 19
PG 5
WC Medicine, General & Internal
SC General & Internal Medicine
GA VJ0XE
UT WOS:000531496100004
DA 2021-02-24
ER

PT J
AU Arunphalungsanti, K
   Pichitpornchai, C
AF Arunphalungsanti, Kittipun
   Pichitpornchai, Chailerd
TI Brain Processing (Auditory Event-Related Potential) of Stressed Versus
   Unstressed Words in Thai Speech
SO PERCEPTUAL AND MOTOR SKILLS
LA English
DT Article
DE stressed word; preattentive; mismatch negativity; auditory event-related
   potential; tonal language
ID MISMATCH NEGATIVITY; HEMISPHERIC-ASYMMETRY; LANGUAGE EXPERIENCE;
   SELECTIVE-ATTENTION; PERCEPTION; PROSODY; INFORMATION; CONTRASTS;
   FREQUENCY; EMOTION
AB This study investigated the effect of the stressed word in Thai language on auditory event-related potential (aERP) in unattended conditions. We presented 30 healthy participants with monosyllabic Thai words consisting of either stressed or unstressed words. We instructed them not to attend to the sound stimuli, but rather to watch and memorize the contents of a silent natural documentary without subtitles. The two listening conditions consisted of 20% deviant stimuli (70 stressed and 70 unstressed words, respectively) and 80% standard stimuli (other 280 unstressed words) presented pseudorandomly and binaurally via a pair of earphones. Participants' aERPs from the two conditions were evaluated by the mismatch negativity (MMN) component of aERP. The mismatch negativity amplitudes in the stressed word condition were significantly higher than those in the unstressed word condition, especially in frontal and left fronto-central brain areas. Therefore, these data show the role of the frontal and left fronto-central brain regions in auditory preattentive processing of stressed word perception among native Thai speakers. This is the first study demonstration that stressed meaningful monosyllable words in tonal language facilitate word perception in this preattentive stage. This result has implications for developing clinical tests evaluating preattentive speech perception.
C1 [Arunphalungsanti, Kittipun; Pichitpornchai, Chailerd] Mahidol Univ, Siriraj Hosp, Fac Med, Dept Physiol, 2 Wanglang Rd, Bangkok 10700, Thailand.
RP Pichitpornchai, C (corresponding author), Mahidol Univ, Siriraj Hosp, Fac Med, Dept Physiol, 2 Wanglang Rd, Bangkok 10700, Thailand.
EM Chailerd.Pic@mahidol.ac.th
RI Arunphalungsanti, Kittipun/AAA-2160-2020; Pichitpornchai,
   Chailerd/AAM-5183-2020
OI Pichitpornchai, Chailerd/0000-0003-2574-3858
CR Arunphalungsanti K., 2016, SONGKLA J SCI TECHNO, V38, P599, DOI 10. 14456/sjst-psu. 2016. 76
   Atienza M, 2001, CLIN NEUROPHYSIOL, V112, P2031, DOI 10.1016/S1388-2457(01)00650-2
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Chandrasekaran B, 2007, BRAIN RES, V1128, P148, DOI 10.1016/j.brainres.2006.10.064
   CONNOLLY JF, 1995, ELECTROEN CLIN NEURO, V94, P276, DOI 10.1016/0013-4694(95)98479-R
   Dara C, 2008, BRAIN RES, V1188, P100, DOI 10.1016/j.brainres.2007.10.034
   Duanmu San, 2004, LANGUAGE LINGUISTICS, V5, P891
   FRIEDERICI AD, 1993, COGNITIVE BRAIN RES, V1, P183, DOI 10.1016/0926-6410(93)90026-2
   FRY DB, 1958, LANG SPEECH, V1, P126, DOI 10.1177/002383095800100207
   Gandour J, 2000, BRAIN LANG, V71, P75, DOI 10.1006/brln.1999.2217
   Gandour J, 2003, BRAIN LANG, V84, P318, DOI 10.1016/S0093-934X(02)00505-9
   Gandour J, 2003, HUM BRAIN MAPP, V18, P149, DOI 10.1002/hbm.10088
   Gu F, 2013, NEUROIMAGE, V83, P637, DOI 10.1016/j.neuroimage.2013.02.080
   HAGOORT P, 1993, BRAIN LANG, V45, P189, DOI 10.1006/brln.1993.1043
   Honbolygo F, 2004, NEUROSCI LETT, V363, P84, DOI 10.1016/j.neulet.2004.03.057
   Jemel B, 2002, BRAIN TOPOGR, V15, P13, DOI 10.1023/A:1019944805499
   Kaan E, 2003, COGNITIVE BRAIN RES, V17, P621, DOI 10.1016/S0926-6410(03)00175-7
   Kaan E, 2007, BRAIN RES, V1148, P113, DOI 10.1016/j.brainres.2007.02.019
   Kaan E, 2008, BMC NEUROSCI, V9, DOI 10.1186/1471-2202-9-53
   Kujala T, 2007, BIOL PSYCHOL, V74, P1, DOI 10.1016/j.biopsycho.2006.06.001
   NAATANEN R, 1978, ACTA PSYCHOL, V42, P313, DOI 10.1016/0001-6918(78)90006-9
   Naatanen R, 2004, CLIN NEUROPHYSIOL, V115, P140, DOI 10.1016/j.clinph.2003.04.001
   Norris D, 1997, COGNITIVE PSYCHOL, V34, P191, DOI 10.1006/cogp.1997.0671
   Okamoto H, 2009, CEREB CORTEX, V19, P2290, DOI 10.1093/cercor/bhn245
   OSTERHOUT L, 1994, J EXP PSYCHOL LEARN, V20, P786, DOI 10.1037/0278-7393.20.4.786
   Patel Salil H, 2005, Int J Med Sci, V2, P147
   Pichitpornchai C, 2016, SPEECH COMMUN, V85, P1, DOI 10.1016/j.specom.2016.10.003
   Pilling M, 2009, J SPEECH LANG HEAR R, V52, P1073, DOI [10.1044/1092-4388, 10.1044/1092-4388(2009/07-0276)]
   Polich J, 1996, PSYCHOPHYSIOLOGY, V33, P334, DOI 10.1111/j.1469-8986.1996.tb01058.x
   Rinne T, 1999, NEUROREPORT, V10, P1113, DOI 10.1097/00001756-199904060-00038
   Sabri M, 2014, NEUROPSYCHOLOGIA, V61, P269, DOI 10.1016/j.neuropsychologia.2014.06.009
   Schonwiesner M, 2005, EUR J NEUROSCI, V22, P1521, DOI 10.1111/j.1460-9568.2005.04315.x
   Sittiprapaporn W, 2002, DISSERTATION
   Steinhauer K, 2008, HANDBOOK OF THE NEUROSCIENCE OF LANGUAGE, P91, DOI 10.1016/B978-0-08-045352-1.00009-4
   Stoody TM, 2011, PERCEPT MOTOR SKILL, V113, P268, DOI 10.2466/22.24.27.PMS.113.4.268-276
   Sur Shravani, 2009, Ind Psychiatry J, V18, P70, DOI 10.4103/0972-6748.57865
   TERKEN J, 1991, J ACOUST SOC AM, V89, P1768, DOI 10.1121/1.401019
   Tramo MJ, 2001, SCIENCE, V291, P54, DOI 10.1126/SCIENCE.1056899
   Tsang YK, 2011, NEUROSCI LETT, V487, P268, DOI 10.1016/j.neulet.2010.10.035
   Waibel A., 1988, PROSODY SPEECH RECOG
   White L, 2011, PERCEPT MOTOR SKILL, V113, P425, DOI 10.2466/22.24.27.PMS.113.5.425-430
   Yip M., 2002, TONE
   Ylinen S, 2009, INT J PSYCHOPHYSIOL, V73, P362, DOI 10.1016/j.ijpsycho.2009.05.013
   Zatorre RJ, 2002, TRENDS COGN SCI, V6, P37, DOI 10.1016/S1364-6613(00)01816-7
   Zora H, 2011, THESIS
NR 45
TC 0
Z9 0
U1 0
U2 1
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 0031-5125
EI 1558-688X
J9 PERCEPT MOTOR SKILL
JI Percept. Mot. Skills
PD DEC
PY 2018
VL 125
IS 6
BP 995
EP 1010
DI 10.1177/0031512518794107
PG 16
WC Psychology, Experimental
SC Psychology
GA HA3NU
UT WOS:000450160300001
PM 30114988
DA 2021-02-24
ER

PT J
AU Panouilleres, MTN
   Mottonen, R
AF Panouilleres, Muriel T. N.
   Mottonen, Riikka
TI Decline of auditory-motor speech processing in older adults with hearing
   loss
SO NEUROBIOLOGY OF AGING
LA English
DT Article
DE Aging; Hearing loss; Tongue primary motor cortex; Speech perception;
   Transcranial magnetic stimulation; Motor evoked potential
ID TRANSCRANIAL MAGNETIC STIMULATION; WORKING-MEMORY CAPACITY; PREMOTOR
   CORTEX; CATEGORICAL PERCEPTION; INDIVIDUAL-DIFFERENCES; NEURAL
   MECHANISMS; SPOKEN SENTENCES; LIFE-SPAN; NOISE; COMPREHENSION
AB Older adults often experience difficulties in understanding speech, partly because of age-related hearing loss (HL). In young adults, activity of the left articulatory motor cortex is enhanced and it interacts with the auditory cortex via the left-hemispheric dorsal stream during speech processing. Little is known about the effect of aging and age-related HL on this auditory-motor interaction and speech processing in the articulatory motor cortex. It has been proposed that upregulation of the motor system during speech processing could compensate for HL and auditory processing deficits in older adults. Alternatively, age-related auditory deficits could reduce and distort the input from the auditory cortex to the articulatory motor cortex, suppressing recruitment of the motor system during listening to speech. The aim of the present study was to investigate the effects of aging and age-related HL on the excitability of the tongue motor cortex during listening to spoken sentences using transcranial magnetic stimulation and electromyography. Our results show that the excitability of the tongue motor cortex was facilitated during listening to speech in young and older adults with normal hearing. This facilitation was significantly reduced in older adults with HL. These findings suggest a decline of auditory-motor processing of speech in adults with age-related HL. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Panouilleres, Muriel T. N.; Mottonen, Riikka] Univ Oxford, Dept Expt Psychol, Oxford, England.
   [Panouilleres, Muriel T. N.] Univ Paris Saclay, Univ Paris Sud, Sch Sports Sci & Human Movement, CIAMS, Orsay, France.
   [Panouilleres, Muriel T. N.] Univ Orleans, CIAMS, UFR Coll Sci & Tech, Orleans, France.
   [Mottonen, Riikka] Univ Nottingham, Sch Psychol, Nottingham, England.
RP Panouilleres, MTN (corresponding author), Univ Paris Saclay, Univ Paris Sud, CIAMS, Batiment 335,Rue Pierre Coubertin, F-91405 Orsay, France.
EM muriel.panouilleres@u-psud.fr
OI Panouilleres, Muriel/0000-0003-0264-2093; Mottonen,
   Riikka/0000-0003-4533-4277
FU Medical Research Council, UKUK Research & Innovation (UKRI)Medical
   Research Council UK (MRC) [G1000566]
FX This work was supported by the Medical Research Council, UK (G1000566,
   Career Development Award for R.M.).
CR Aczel B., 2018, ADV METHODS PRACT PS, V1, P357, DOI DOI 10.1177/2515245918773742
   Adank P, 2017, LANG COGN NEUROSCI, V32, P900, DOI 10.1080/23273798.2016.1257816
   Adank P, 2012, BRAIN LANG, V122, P42, DOI 10.1016/j.bandl.2012.04.014
   Akeroyd M, 2008, INT J AUDIOL, V47, pS53, DOI 10.1080/14992020802301142
   Alain C, 2014, HEARING RES, V308, P162, DOI 10.1016/j.heares.2013.06.008
   Anderson S, 2012, J NEUROSCI, V32, P14156, DOI 10.1523/JNEUROSCI.2176-12.2012
   Bartoli E, 2015, CEREB CORTEX, V25, P281, DOI 10.1093/cercor/bht257
   Bidelman GM, 2014, NEUROBIOL AGING, V35, P2526, DOI 10.1016/j.neurobiolaging.2014.05.006
   Callan D, 2010, NEUROIMAGE, V51, P844, DOI 10.1016/j.neuroimage.2010.02.027
   Cardin V, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00199
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   Davis MF, 2011, J OCCUP ENVIRON MED, V53, P190, DOI [10.1097/JOM.0b013e31820805d5, 10.1162/jocn_a_00084]
   Du Y, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12241
   Du Y, 2014, P NATL ACAD SCI USA, V111, P7126, DOI 10.1073/pnas.1318738111
   DUBNO JR, 1984, J ACOUST SOC AM, V76, P87, DOI 10.1121/1.391011
   Eckert MA, 2008, JARO-J ASSOC RES OTO, V9, P252, DOI 10.1007/s10162-008-0113-3
   Eckert MA, 2012, JARO-J ASSOC RES OTO, V13, P703, DOI 10.1007/s10162-012-0332-5
   Erb J, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00116
   Fadiga L, 2002, EUR J NEUROSCI, V15, P399, DOI 10.1046/j.0953-816x.2001.01874.x
   Foster JL, 2015, MEM COGNITION, V43, P226, DOI 10.3758/s13421-014-0461-7
   Frisina DR, 1997, HEARING RES, V106, P95, DOI 10.1016/S0378-5955(97)00006-3
   Fullgrabe C, 2015, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00347
   Goossens T, 2017, HEARING RES, V344, P109, DOI 10.1016/j.heares.2016.11.004
   Harris KC, 2009, J NEUROSCI, V29, P6078, DOI 10.1523/JNEUROSCI.0412-09.2009
   Hervais-Adelman AG, 2012, LANG COGNITIVE PROC, V27, P1145, DOI 10.1080/01690965.2012.662280
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Humes LE, 2010, SPRINGER HANDB AUDIT, V34, P211, DOI 10.1007/978-1-4419-0993-0_8
   Husain FT, 2011, BRAIN RES, V1369, P74, DOI 10.1016/j.brainres.2010.10.095
   Jin SH, 2014, J AM ACAD AUDIOL, V25, P656, DOI 10.3766/jaaa.25.7.4
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   Liebenthal E, 2018, BRAIN LANG, V187, P33, DOI 10.1016/j.bandl.2017.12.004
   Lin FR, 2014, NEUROIMAGE, V90, P84, DOI 10.1016/j.neuroimage.2013.12.059
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Lin FR, 2011, NEUROPSYCHOLOGY, V25, P763, DOI 10.1037/a0024238
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P1131, DOI 10.1093/gerona/glr115
   Londei A, 2010, HUM BRAIN MAPP, V31, P567, DOI 10.1002/hbm.20888
   Mathews A, 2005, ANNU REV CLIN PSYCHO, V1, P167, DOI 10.1146/annurev.clinpsy.1.102803.143916
   Meister IG, 2007, CURR BIOL, V17, P1692, DOI 10.1016/j.cub.2007.08.064
   Mottonen R, 2012, APHASIOLOGY, V26, P1103, DOI 10.1080/02687038.2011.619515
   Mottonen R, 2009, J NEUROSCI, V29, P9819, DOI 10.1523/JNEUROSCI.6018-08.2009
   Mullensiefen D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0101091
   Murakami T, 2015, J NEUROSCI, V35, P1411, DOI 10.1523/JNEUROSCI.0246-14.2015
   Murakami T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00446
   Murakami T, 2011, NEUROPSYCHOLOGIA, V49, P2045, DOI 10.1016/j.neuropsychologia.2011.03.034
   Nuttall HE, 2017, NEUROPSYCHOLOGIA, V94, P13, DOI 10.1016/j.neuropsychologia.2016.11.016
   Nuttall HE, 2016, NEUROIMAGE, V128, P218, DOI 10.1016/j.neuroimage.2015.12.038
   Osnes B, 2011, NEUROIMAGE, V54, P2437, DOI 10.1016/j.neuroimage.2010.09.078
   Oswald FL, 2015, BEHAV RES METHODS, V47, P1343, DOI 10.3758/s13428-014-0543-2
   Panouilleres MTN, 2018, CORTEX, V103, P44, DOI 10.1016/j.cortex.2018.02.007
   Peelle JE, 2016, TRENDS NEUROSCI, V39, P486, DOI 10.1016/j.tins.2016.05.001
   Peelle JE, 2011, J NEUROSCI, V31, P12638, DOI 10.1523/JNEUROSCI.2559-11.2011
   Peelle JE, 2010, CEREB CORTEX, V20, P773, DOI 10.1093/cercor/bhp142
   Presacco A, 2016, J NEUROPHYSIOL, V116, P2346, DOI 10.1152/jn.00372.2016
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Rajan R, 2008, NEUROSCIENCE, V154, P784, DOI 10.1016/j.neuroscience.2008.03.067
   Rauschecker JP, 2009, NAT NEUROSCI, V12, P718, DOI 10.1038/nn.2331
   Ries P W, 1994, Vital Health Stat 10, P1
   Rodd JM, 2005, CEREB CORTEX, V15, P1261, DOI 10.1093/cercor/bhi009
   Rogers JC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00754
   Schneider BA, 2002, CAN J EXP PSYCHOL, V56, P139, DOI 10.1037/h0087392
   Schomers MR, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00435
   Schomers MR, 2015, CEREB CORTEX, V25, P3894, DOI 10.1093/cercor/bhu274
   Schoof T, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00307
   Scott SK, 2003, TRENDS NEUROSCI, V26, P100, DOI 10.1016/S0166-2236(02)00037-1
   Skipper JI, 2017, BRAIN LANG, V164, P77, DOI 10.1016/j.bandl.2016.10.004
   Skipper JI, 2005, NEUROIMAGE, V25, P76, DOI 10.1016/j.neuroimage.2004.11.006
   Smalle EHM, 2015, CEREB CORTEX, V25, P3690, DOI 10.1093/cercor/bhu218
   Stewart R, 2009, J AM ACAD AUDIOL, V20, P147, DOI 10.3766/jaaa.20.2.7
   Swaminathan S, 2013, BRAIN LANG, V126, P1, DOI 10.1016/j.bandl.2013.03.002
   Szenkovits G, 2012, NEUROPSYCHOLOGIA, V50, P1380, DOI 10.1016/j.neuropsychologia.2012.02.023
   Tay T, 2006, GERONTOLOGY, V52, P386, DOI 10.1159/000095129
   Tun PA, 2010, PSYCHOL AGING, V25, P730, DOI 10.1037/a0019300
   Tyler LK, 2010, CEREB CORTEX, V20, P352, DOI 10.1093/cercor/bhp105
   Vaden KI, 2015, J NEUROSCI, V35, P3929, DOI 10.1523/JNEUROSCI.2908-14.2015
   Watkins KE, 2003, NEUROPSYCHOLOGIA, V41, P989, DOI 10.1016/S0028-3932(02)00316-0
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Wingfield A, 2006, J AM ACAD AUDIOL, V17, P487, DOI 10.3766/jaaa.17.7.4
   Wong PCM, 2010, EAR HEARING, V31, P471, DOI 10.1097/AUD.0b013e3181d709c2
   Wong PCM, 2009, NEUROPSYCHOLOGIA, V47, P693, DOI 10.1016/j.neuropsychologia.2008.11.032
   Yang M, 2014, HEARING RES, V316, P37, DOI 10.1016/j.heares.2014.07.006
NR 80
TC 5
Z9 5
U1 0
U2 6
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA
SN 0197-4580
EI 1558-1497
J9 NEUROBIOL AGING
JI Neurobiol. Aging
PD DEC
PY 2018
VL 72
BP 89
EP 97
DI 10.1016/j.neurobiolaging.2018.07.013
PG 9
WC Geriatrics & Gerontology; Neurosciences
SC Geriatrics & Gerontology; Neurosciences & Neurology
GA GZ0RX
UT WOS:000449073700010
PM 30240945
DA 2021-02-24
ER

PT J
AU Rennig, J
   Beauchamp, MS
AF Rennig, Johannes
   Beauchamp, Michael S.
TI Free viewing of talking faces reveals mouth and eye preferring regions
   of the human superior temporal sulcus
SO NEUROIMAGE
LA English
DT Article
DE Audiovisual; Face; Multisensory; Speech; Eye tracking; fMRI
ID AUDIOVISUAL SPEECH-PERCEPTION; HIGH-FUNCTIONING AUTISM; SURFACE-BASED
   ANALYSIS; INTERINDIVIDUAL DIFFERENCES; MULTISENSORY INTEGRATION;
   INDIVIDUAL-DIFFERENCES; HAND MOVEMENTS; GAZE BEHAVIOR; FMRI; CORTEX
AB During face-to-face communication, the mouth of the talker is informative about speech content, while the eyes of the talker convey other information, such as gaze location. Viewers most often fixate either the mouth or the eyes of the talker's face, presumably allowing them to sample these different sources of information. To study the neural correlates of this process, healthy humans freely viewed talking faces while brain activity was measured with BOLD fMRI and eye movements were recorded with a video-based eye tracker. Post hoc trial sorting was used to divide the data into trials in which participants fixated the mouth of the talker and trials in which they fixated the eyes. Although the audiovisual stimulus was identical, the two trials types evoked differing responses in subregions of the posterior superior temporal sulcus (pSTS). The anterior pSTS preferred trials in which participants fixated the mouth of the talker while the posterior pSTS preferred fixations on the eye of the talker. A second fMRI experiment demonstrated that anterior pSTS responded more strongly to auditory and audiovisual speech than posterior pSTS eye-preferring regions. These results provide evidence for functional specialization within the pSTS under more realistic viewing and stimulus conditions than in previous neuroimaging studies.
C1 Baylor Coll Med, Dept Neurosurg, Houston, TX 77030 USA.
   Baylor Coll Med, Core Adv MRI, Houston, TX 77030 USA.
RP Beauchamp, MS (corresponding author), Baylor Coll Med, Core Adv Magnet Resonance Imaging, Dept Neurosurg, 1 Baylor Plaza, Houston, TX 77030 USA.
EM Michael.Beauchamp@bcm.edu
RI Beauchamp, Michael/AAK-9813-2020
OI Beauchamp, Michael/0000-0002-7599-9934; Rennig,
   Johannes/0000-0003-1819-9145
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01NS065395];
   Deutsche ForschungsgemeinschaftGerman Research Foundation (DFG) [RE
   3693/1-1]; NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKEUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute of Neurological Disorders &
   Stroke (NINDS) [R01NS065395, R01NS065395, R01NS065395, R01NS065395,
   R01NS065395, R01NS065395, R01NS065395, R01NS065395, R01NS065395,
   R01NS065395] Funding Source: NIH RePORTER
FX This work was supported by the National Institutes of Health
   (R01NS065395 to M.S.B) and the Deutsche Forschungsgemeinschaft (RE
   3693/1-1 to J.R.). We acknowledge the Core for Advanced MRI at Baylor
   College of Medicine. The authors declare no competing financial
   interests.
CR Argall BD, 2006, HUM BRAIN MAPP, V27, P14, DOI 10.1002/hbm.20158
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Beauchamp MS, 2004, NAT NEUROSCI, V7, P1190, DOI 10.1038/nn1333
   Beauchamp MS, 2003, J COGNITIVE NEUROSCI, V15, P991, DOI 10.1162/089892903770007380
   Beauchamp MS, 2004, NEURON, V41, P809, DOI 10.1016/S0896-6273(04)00070-4
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Bernstein LE, 2011, HUM BRAIN MAPP, V32, P1660, DOI 10.1002/hbm.21139
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Buchan JN, 2008, BRAIN RES, V1242, P162, DOI 10.1016/j.brainres.2008.06.083
   Calder AJ, 2002, NEUROPSYCHOLOGIA, V40, P1129, DOI 10.1016/S0028-3932(02)00008-8
   Calvert GA, 2003, J COGNITIVE NEUROSCI, V15, P57, DOI 10.1162/089892903321107828
   Chang EF, 2010, NAT NEUROSCI, V13, P1428, DOI 10.1038/nn.2641
   Cox RW, 1996, COMPUT BIOMED RES, V29, P162, DOI 10.1006/cbmr.1996.0014
   Cremers HR, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184923
   Dale AM, 1999, HUM BRAIN MAPP, V8, P109, DOI 10.1002/(SICI)1097-0193(1999)8:2/3<109::AID-HBM7>3.0.CO;2-W
   Dale AM, 1999, NEUROIMAGE, V9, P179, DOI 10.1006/nimg.1998.0395
   Deen B, 2015, CEREB CORTEX, V25, P4596, DOI 10.1093/cercor/bhv111
   Destrieux C, 2010, NEUROIMAGE, V53, P1, DOI 10.1016/j.neuroimage.2010.06.010
   Fischl B, 1999, NEUROIMAGE, V9, P195, DOI 10.1006/nimg.1998.0396
   Fixmer E., 1998, P AUD VIS SPEECH PRO, P27
   Grossman RB, 2015, AUTISM RES, V8, P307, DOI 10.1002/aur.1447
   Gurler D, 2015, ATTEN PERCEPT PSYCHO, V77, P1333, DOI 10.3758/s13414-014-0821-1
   Hoffman EA, 2000, NAT NEUROSCI, V3, P80, DOI 10.1038/71152
   Irwin JR, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00397
   Jiang J, 2017, SOC COGN AFFECT NEUR, V12, P319, DOI 10.1093/scan/nsw127
   Kanwisher N, 1997, J NEUROSCI, V17, P4302
   Kliemann D, 2010, J NEUROSCI, V30, P12281, DOI 10.1523/JNEUROSCI.0688-10.2010
   Klin A, 2002, ARCH GEN PSYCHIAT, V59, P809, DOI 10.1001/archpsyc.59.9.809
   Kuznetsova A., 2015, R PACKAG VERSION 2
   Magnotti J.F., 2018, BIORXIV, P1
   Magnotti JF, 2015, PSYCHON B REV, V22, P701, DOI 10.3758/s13423-014-0722-2
   Mehoudar E, 2014, J VISION, V14, DOI 10.1167/14.7.6
   Moeller S, 2010, MAGN RESON MED, V63, P1144, DOI 10.1002/mrm.22361
   Munhall KG, 2004, PSYCHOL SCI, V15, P133, DOI 10.1111/j.0963-7214.2004.01502010.x
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Nath AR, 2011, J NEUROSCI, V31, P13963, DOI 10.1523/JNEUROSCI.2605-11.2011
   Neumann D, 2006, SOC COGN AFFECT NEUR, V1, P194, DOI 10.1093/scan/nsl030
   Pare M, 2003, PERCEPT PSYCHOPHYS, V65, P553, DOI 10.3758/BF03194582
   Pelli DG, 1997, SPATIAL VISION, V10, P437, DOI 10.1163/156856897X00366
   Pelphrey KA, 2005, CEREB CORTEX, V15, P1866, DOI 10.1093/cercor/bhi064
   Peterson MF, 2013, PSYCHOL SCI, V24, P1216, DOI 10.1177/0956797612471684
   Peterson MF, 2012, P NATL ACAD SCI USA, V109, pE3314, DOI 10.1073/pnas.1214269109
   Puce A, 2003, NEUROIMAGE, V19, P861, DOI 10.1016/S1053-8119(03)00189-7
   Puce A, 1998, J NEUROSCI, V18, P2188
   Saad ZS, 2009, NEUROIMAGE, V44, P839, DOI 10.1016/j.neuroimage.2008.09.037
   Setsompop K, 2012, MAGN RESON MED, V67, P1210, DOI 10.1002/mrm.23097
   Spezio ML, 2007, J AUTISM DEV DISORD, V37, P929, DOI 10.1007/s10803-006-0232-9
   Thompson JC, 2007, NEUROIMAGE, V37, P966, DOI 10.1016/j.neuroimage.2007.05.058
   Tjan BS, 2014, EUR J NEUROSCI, V39, P1323, DOI 10.1111/ejn.12471
   van Atteveldt N, 2004, NEURON, V43, P271, DOI 10.1016/j.neuron.2004.06.025
   van Atteveldt NM, 2007, CEREB CORTEX, V17, P962, DOI 10.1093/cercor/bhl007
   Vatikiotis-Bateson E, 1998, PERCEPT PSYCHOPHYS, V60, P926, DOI 10.3758/BF03211929
   Westfall Jacob, 2016, Wellcome Open Res, V1, P23, DOI 10.12688/wellcomeopenres.10298.2
   Wright TM, 2003, CEREB CORTEX, V13, P1034, DOI 10.1093/cercor/13.10.1034
   Yarkoni T, 2009, PERSPECT PSYCHOL SCI, V4, P294, DOI 10.1111/j.1745-6924.2009.01127.x
   Zhu LL, 2017, J NEUROSCI, V37, P2697, DOI 10.1523/JNEUROSCI.2914-16.2017
NR 56
TC 5
Z9 5
U1 3
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD DEC
PY 2018
VL 183
BP 25
EP 36
DI 10.1016/j.neuroimage.2018.08.008
PG 12
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA GX4ZU
UT WOS:000447750200003
PM 30092347
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Aglieri, V
   Chaminade, T
   Takerkart, S
   Belin, P
AF Aglieri, Virginia
   Chaminade, Thierry
   Takerkart, Sylvain
   Belin, Pascal
TI Functional connectivity within the voice perception network and its
   behavioural relevance
SO NEUROIMAGE
LA English
DT Article
DE fMRI; Functional connectivity; Voice perception; Auditory cortex;
   Individual differences; Voice recognition
ID INFERIOR FRONTAL GYRUS; SUPERIOR TEMPORAL SULCUS; ARCUATE FASCICULUS;
   FACE PERCEPTION; CONGENITAL PROSOPAGNOSIA; PREFRONTAL CORTEX;
   SPEECH-PERCEPTION; CORTICAL NETWORK; FIBER DENSITY; COMBINED FMRI
AB Recognizing who is speaking is a cognitive ability characterized by considerable individual differences, which could relate to the inter-individual variability observed in voice-elicited BOLD activity. Since voice perception is sustained by a complex brain network involving temporal voice areas (TVAs) and, even if less consistently, extra-temporal regions such as frontal cortices, functional connectivity (FC) during an fMRI voice localizer (passive listening of voices vs non-voices) has been computed within twelve temporal and frontal voice-sensitive regions ("voice patches") individually defined for each subject (N = 90) to account for inter-individual variability. Results revealed that voice patches were positively co-activated during voice listening and that they were characterized by different FC pattern depending on the location (anterior/posterior) and the hemisphere. Importantly, FC between right frontal and temporal voice patches was behaviorally relevant: FC significantly increased with voice recognition abilities as measured in a voice recognition test performed outside the scanner. Hence, this study highlights the importance of frontal regions in voice perception and it supports the idea that looking at FC between stimulus-specific and higher-order frontal regions can help understanding individual differences in processing social stimuli such as voices.
C1 [Aglieri, Virginia; Chaminade, Thierry; Takerkart, Sylvain; Belin, Pascal] CNRS, UMR 7289, Inst Neurosci Timone, Marseille, France.
   [Aglieri, Virginia; Chaminade, Thierry; Takerkart, Sylvain; Belin, Pascal] Univ Aix Marseille, Marseille, France.
   [Chaminade, Thierry; Takerkart, Sylvain; Belin, Pascal] Inst Language Commun & Brain, Marseille, France.
   [Belin, Pascal] McGill Univ, Univ Montreal, Dept Psychol, Int Labs Brain Mus & Sound, Montreal, PQ, Canada.
RP Aglieri, V (corresponding author), CNRS, UMR 7289, Inst Neurosci Timone, Marseille, France.; Aglieri, V (corresponding author), Univ Aix Marseille, Marseille, France.
EM virginia.aglieri@univ-amu.fr
RI Chaminade, Thierry/AAF-6072-2020
FU French Foundation for Medical ResearchFondation pour la Recherche
   Medicale [AJE201214]; BBSRCUK Research & Innovation (UKRI)Biotechnology
   and Biological Sciences Research Council (BBSRC) [BB/E003958/1,
   BBJ003654/1, BB/I022287/1]; ESRC-MRC large grant [RES-060-25-0010];
   Excellence Initiative of Aix-Marseille University (A*MIDEX)French
   National Research Agency (ANR);  [ANR-16-CONV-0002];  [ANR-11-LABX-0036]
FX This work was supported by grant AJE201214 from French Foundation for
   Medical Research, and grants ANR-16-CONV-0002 (Institute of Language,
   Communication and the Brain), ANR-11-LABX-0036 (Brain and Language
   Research Institute), BBSRC grants BB/E003958/1, BBJ003654/1 and
   BB/I022287/1, ESRC-MRC large grant RES-060-25-0010 and the Excellence
   Initiative of Aix-Marseille University (A*MIDEX).
CR Abrams DA, 2016, P NATL ACAD SCI USA, V113, P6295, DOI 10.1073/pnas.1602948113
   Aglieri V., 2016, BEHAV RES METHODS, P1
   Allison T, 2000, TRENDS COGN SCI, V4, P267, DOI 10.1016/S1364-6613(00)01501-1
   Andics A, 2013, NEUROIMAGE, V79, P351, DOI 10.1016/j.neuroimage.2013.05.002
   Andics A, 2010, NEUROIMAGE, V52, P1528, DOI 10.1016/j.neuroimage.2010.05.048
   Ashburner J, 2007, NEUROIMAGE, V38, P95, DOI 10.1016/j.neuroimage.2007.07.007
   Avidan G, 2014, CEREB CORTEX, V24, P1565, DOI 10.1093/cercor/bht007
   Behzadi Y, 2007, NEUROIMAGE, V37, P90, DOI 10.1016/j.neuroimage.2007.04.042
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Belin P, 2000, NATURE, V403, P309, DOI 10.1038/35002078
   Belin P, 2011, BRIT J PSYCHOL, V102, P711, DOI 10.1111/j.2044-8295.2011.02041.x
   Belyk M, 2017, NEUROIMAGE, V156, P240, DOI 10.1016/j.neuroimage.2017.04.020
   Bernal B, 2009, BRAIN, V132, P2309, DOI 10.1093/brain/awp206
   Bestelmeyer PEG, 2012, CEREB CORTEX, V22, P1263, DOI 10.1093/cercor/bhr204
   Blank H, 2014, NEUROSCI BIOBEHAV R, V47, P717, DOI 10.1016/j.neubiorev.2014.10.022
   Bonte M, 2014, J NEUROSCI, V34, P4548, DOI 10.1523/JNEUROSCI.4339-13.2014
   Brown S, 2008, CEREB CORTEX, V18, P837, DOI 10.1093/cercor/bhm131
   Castello MVD, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12559-1
   Charest I, 2013, CEREB CORTEX, V23, P958, DOI 10.1093/cercor/bhs090
   Cheung C, 2016, ELIFE, V5, DOI 10.7554/eLife.12577
   D'Ausilio A, 2014, NEUROPSYCHOLOGIA, V63, P85, DOI 10.1016/j.neuropsychologia.2014.08.018
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Duchaine B, 2015, ANNU REV VIS SCI, V1, P393, DOI 10.1146/annurev-vision-082114-035518
   Eickhoff SB, 2005, NEUROIMAGE, V25, P1325, DOI 10.1016/j.neuroimage.2004.12.034
   Erickson LC, 2017, BRAIN STRUCT FUNCT, V222, P267, DOI 10.1007/s00429-016-1215-z
   Fairhall SL, 2007, CEREB CORTEX, V17, P2400, DOI 10.1093/cercor/bhl148
   Fecteau S, 2005, J NEUROPHYSIOL, V94, P2251, DOI 10.1152/jn.00329.2005
   Flagmeier SG, 2014, BRAIN LANG, V132, P7, DOI 10.1016/j.bandl.2014.02.001
   Friston KJ, 2011, BRAIN CONNECT, V1, P13, DOI 10.1089/brain.2011.0008
   Garrido L, 2009, NEUROPSYCHOLOGIA, V47, P123, DOI 10.1016/j.neuropsychologia.2008.08.003
   Glasser MF, 2008, CEREB CORTEX, V18, P2471, DOI 10.1093/cercor/bhn011
   Hagoort P, 2005, TRENDS COGN SCI, V9, P416, DOI 10.1016/j.tics.2005.07.004
   Hamzei F, 2016, CEREB CORTEX, V26, P2215, DOI 10.1093/cercor/bhv066
   Haxby JV, 2000, TRENDS COGN SCI, V4, P223, DOI 10.1016/S1364-6613(00)01482-0
   Hein G, 2008, J COGNITIVE NEUROSCI, V20, P2125, DOI 10.1162/jocn.2008.20148
   HILLENBRAND J, 1995, J ACOUST SOC AM, V97, P3099, DOI 10.1121/1.411872
   Ishai A, 2008, NEUROIMAGE, V40, P415, DOI 10.1016/j.neuroimage.2007.10.040
   Jones AB, 2015, CORTEX, V71, P232, DOI 10.1016/j.cortex.2015.07.004
   Juch H, 2005, NEUROIMAGE, V24, P504, DOI 10.1016/j.neuroimage.2004.08.037
   Koelsch S, 2009, HUM BRAIN MAPP, V30, P859, DOI 10.1002/hbm.20550
   Kreiman J., 2011, FDN VOICE STUDIES IN
   Kriegstein KV, 2004, NEUROIMAGE, V22, P948, DOI 10.1016/j.neuroimage.2004.02.020
   Lahnakoski JM, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00233
   Latinus M, 2011, CEREB CORTEX, V21, P2820, DOI 10.1093/cercor/bhr077
   Meyer M, 2002, HUM BRAIN MAPP, V17, P73, DOI 10.1002/hbm.10042
   Michalka SW, 2015, NEURON, V87, P882, DOI 10.1016/j.neuron.2015.07.028
   Mou XD, 2013, PROG NEURO-PSYCHOPH, V44, P265, DOI 10.1016/j.pnpbp.2013.03.006
   Nakamura K, 2001, NEUROPSYCHOLOGIA, V39, P1047, DOI 10.1016/S0028-3932(01)00037-9
   Nucifora PGP, 2005, NEUROREPORT, V16, P791, DOI 10.1097/00001756-200505310-00002
   O'Reilly JX, 2012, SOC COGN AFFECT NEUR, V7, P604, DOI 10.1093/scan/nss055
   Osnes B, 2011, NEUROIMAGE, V54, P2437, DOI 10.1016/j.neuroimage.2010.09.078
   Paulesu E, 1997, NEUROREPORT, V8, P2011, DOI 10.1097/00001756-199705260-00042
   Perea M, 2014, EXP PSYCHOL, V61, P480, DOI 10.1027/1618-3169/a000265
   Pernet CR, 2015, NEUROIMAGE, V119, P164, DOI 10.1016/j.neuroimage.2015.06.050
   Pulvermuller F, 2006, P NATL ACAD SCI USA, V103, P7865, DOI 10.1073/pnas.0509989103
   Pyles JA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0061611
   Rota G, 2009, HUM BRAIN MAPP, V30, P1605, DOI 10.1002/hbm.20621
   Sammler D, 2015, CURR BIOL, V25, P3079, DOI 10.1016/j.cub.2015.10.009
   Sarubbo S, 2015, HUM BRAIN MAPP, V36, P3117, DOI 10.1002/hbm.22832
   Saur D, 2010, NEUROIMAGE, V49, P3187, DOI 10.1016/j.neuroimage.2009.11.009
   Saur D, 2008, P NATL ACAD SCI USA, V105, P18035, DOI 10.1073/pnas.0805234105
   Saygin ZM, 2012, NAT NEUROSCI, V15, P321, DOI 10.1038/nn.3001
   Schomers MR, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00435
   Shamay-Tsoory SG, 2009, BRAIN, V132, P617, DOI 10.1093/brain/awn279
   Stevenage SV, 2018, NEUROPSYCHOLOGIA, V116, P162, DOI 10.1016/j.neuropsychologia.2017.07.005
   Thomas C, 2009, NAT NEUROSCI, V12, P29, DOI 10.1038/nn.2224
   Tsao DY, 2008, ANNU REV NEUROSCI, V31, P411, DOI 10.1146/annurev.neuro.30.051606.094238
   Turk-Browne NB, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00176
   Vernooij MW, 2007, NEUROIMAGE, V35, P1064, DOI 10.1016/j.neuroimage.2006.12.041
   von Kriegstein K, 2005, J COGNITIVE NEUROSCI, V17, P367, DOI 10.1162/0898929053279577
   Wang L, 2012, NEURON, V76, P1010, DOI 10.1016/j.neuron.2012.09.033
   Watson R, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00089
   Whitfield-Gabrieli S, 2012, BRAIN CONNECT, V2, P125, DOI 10.1089/brain.2012.0073
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Zaske R, 2017, CORTEX, V94, P100, DOI 10.1016/j.cortex.2017.06.005
   ZATORRE RJ, 1992, SCIENCE, V256, P846, DOI 10.1126/science.1589767
   Zhu Q, 2011, J NEUROSCI, V31, P10323, DOI 10.1523/JNEUROSCI.0873-11.2011
NR 77
TC 8
Z9 8
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1053-8119
EI 1095-9572
J9 NEUROIMAGE
JI Neuroimage
PD DEC
PY 2018
VL 183
BP 356
EP 365
DI 10.1016/j.neuroimage.2018.08.011
PG 10
WC Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical
   Imaging
SC Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging
GA GX4ZU
UT WOS:000447750200031
PM 30099078
OA Green Published, Other Gold
DA 2021-02-24
ER

PT J
AU Cross, AM
   Joanisse, MF
AF Cross, Alexandra M.
   Joanisse, Marc F.
TI Eyetracking of coarticulatory cue responses in children and adults
SO LANGUAGE COGNITION AND NEUROSCIENCE
LA English
DT Article
DE Spoken word recognition; coarticulation; speech perception; eyetracking;
   lexical competition
ID SPOKEN-WORD RECOGNITION; LEXICAL ACCESS; ANTICIPATORY COARTICULATION;
   SUBCATEGORICAL MISMATCHES; LANGUAGE COMPREHENSION; NONWORD REPETITION;
   TIME-COURSE; NEIGHBORHOODS; REPRESENTATION; COMPENSATION
AB Prior work suggests listeners are sensitive to coarticulatory cues during spoken word recognition; however, little is known about how this ability develops in children. In the present study, children and adults listened to words containing congruent and incongruent coarticulatory cues while looking at a two-picture display. We manipulated the congruency of the auditory-coarticulatory information such that the initial phoneme of the auditory cue matched the target, or contained an incongruent initial phoneme that instead matched the distractor picture. Accordingly, we observed both slower rates of looks to the target and higher rates of looks to the distractor on incongruent trials, indicating that both children and adults were sensitive to coarticulatory congruency. These findings suggest that children maintain detailed phonological representations of words, and may use coarticulatory information to facilitate spoken word recognition.
C1 [Cross, Alexandra M.; Joanisse, Marc F.] Univ Western Ontario, Brain & Mind Inst, London, ON, Canada.
   [Cross, Alexandra M.] Univ Western Ontario, Hlth & Rehabil Sci, London, ON, Canada.
RP Cross, AM (corresponding author), Univ Western Ontario, Brain & Mind Inst, London, ON, Canada.; Cross, AM (corresponding author), Univ Western Ontario, Hlth & Rehabil Sci, London, ON, Canada.
EM across22@uwo.ca
FU Natural Sciences and Engineering Research Council of CanadaNatural
   Sciences and Engineering Research Council of Canada (NSERC)CGIAR;
   Canadian Foundation for InnovationCanada Foundation for Innovation
FX This work was supported by the Natural Sciences and Engineering Research
   Council of Canada; Canadian Foundation for Innovation.
CR Allopenna PD, 1998, J MEM LANG, V38, P419, DOI 10.1006/jmla.1997.2558
   Archibald LMD, 2011, J EXP PSYCHOL HUMAN, V37, P1275, DOI 10.1037/a0023506
   ASLIN RN, 1998, HDB CHILD PSYCHOL, V2, P147
   Bladon R. A. W, 1976, J PHONETICS, V4, P137
   BLUMSTEIN SE, 1980, J ACOUST SOC AM, V67, P648, DOI 10.1121/1.383890
   BOND GL, 1967, READ RES QUART, V2, P5, DOI 10.2307/746948
   BOWERS PG, 1993, READ WRIT, V5, P69, DOI 10.1007/BF01026919
   CHARLESLUCE J, 1990, J CHILD LANG, V17, P205, DOI 10.1017/S0305000900013180
   Dahan D, 2001, LANG COGNITIVE PROC, V16, P507, DOI 10.1080/01690960143000074
   DENCKLA MB, 1976, NEUROPSYCHOLOGIA, V14, P471, DOI 10.1016/0028-3932(76)90075-0
   DOLLAGHAN CA, 1994, J CHILD LANG, V21, P257, DOI 10.1017/S0305000900009260
   Edwards J, 2004, J SPEECH LANG HEAR R, V47, P421, DOI 10.1044/1092-4388(2004/034)
   Fikkert P, 2010, LAB PHONOL, V10, P227, DOI DOI 10.1515/9783110224917.3.227
   Fowler C. A., 1986, INVARIANCE VARIABILI, P123
   FOWLER CA, 1981, PHONETICA, V38, P35, DOI 10.1159/000260013
   Fowler CA, 2006, PERCEPT PSYCHOPHYS, V68, P161, DOI 10.3758/BF03193666
   Gow D. W., 2007, LAB PHONOLOGY, V9, P173
   KAIL R, 1991, PSYCHOL BULL, V109, P490, DOI 10.1037/0033-2909.109.3.490
   LARIVIERE C, 1975, J SPEECH HEAR RES, V18, P613, DOI 10.1044/jshr.1804.613
   LARIVIERE C, 1975, J ACOUST SOC AM, V57, P470, DOI 10.1121/1.380470
   Mahr T, 2015, COGNITION, V142, P345, DOI 10.1016/j.cognition.2015.05.009
   MARSLENWILSON W, 1994, PSYCHOL REV, V101, P653, DOI 10.1037/0033-295X.101.4.653
   McQueen JM, 1999, J EXP PSYCHOL HUMAN, V25, P1363, DOI 10.1037/0096-1523.25.5.1363
   Metsala JL, 1999, J EDUC PSYCHOL, V91, P3, DOI 10.1037/0022-0663.91.1.3
   Mirman D., 2014, GROWTH CURVE ANAL VI
   Mirman D, 2008, J MEM LANG, V59, P475, DOI 10.1016/j.jml.2007.11.006
   Mitterer H, 2006, PERCEPT PSYCHOPHYS, V68, P1227, DOI 10.3758/BF03193723
   Redmond SM, 2005, CLIN LINGUIST PHONET, V19, P109, DOI 10.1080/02699200410001669870
   Salverda AP, 2014, J MEM LANG, V71, P145, DOI 10.1016/j.jml.2013.11.002
   Scarborough HS, 1998, ANN DYSLEXIA, V48, P115, DOI 10.1007/s11881-998-0006-5
   Smits R, 2001, J EXP PSYCHOL HUMAN, V27, P1145, DOI 10.1037/0096-1523.27.5.1145
   STEVENS KN, 1963, J SPEECH HEAR RES, V6, P111, DOI 10.1044/jshr.0602.111
   Swingley D, 2000, COGNITION, V76, P147, DOI 10.1016/S0010-0277(00)00081-0
   Swingley D, 2002, PSYCHOL SCI, V13, P480, DOI 10.1111/1467-9280.00485
   Tanenhaus MK, 2000, J PSYCHOLINGUIST RES, V29, P557, DOI 10.1023/A:1026464108329
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Werker JF, 2002, INFANCY, V3, P1, DOI 10.1207/S15327078IN0301_1
   Zamuner TS, 2016, J EXP CHILD PSYCHOL, V152, P136, DOI 10.1016/j.jecp.2016.07.012
NR 39
TC 3
Z9 3
U1 0
U2 1
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2327-3798
EI 2327-3801
J9 LANG COGN NEUROSCI
JI Lang. Cogn. Neurosci.
PD NOV 26
PY 2018
VL 33
IS 10
BP 1315
EP 1324
DI 10.1080/23273798.2018.1484148
PG 10
WC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology, Experimental
SC Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics;
   Psychology
GA GX4OW
UT WOS:000447714900006
DA 2021-02-24
ER

PT J
AU Sorcinelli, A
   Vouloumanos, A
AF Sorcinelli, Andrea
   Vouloumanos, Athena
TI Is Visual Perceptual Narrowing an Obligatory Developmental Process?
SO FRONTIERS IN PSYCHOLOGY
LA English
DT Article
DE perceptual narrowing; perceptual development; face perception;
   eye-tracking; conspecific; monkey
ID PHONETIC PERCEPTION; SPEECH-PERCEPTION; FACE RECOGNITION; 1ST YEAR;
   LANGUAGE; DISCRIMINATION; INFANTS; SHEEP
AB Perceptual narrowing, or a diminished perceptual sensitivity to infrequently encountered stimuli, sometimes accompanied by an increased sensitivity to frequently encountered stimuli, has been observed in unimodal speech and visual perception, as well as in multimodal perception, leading to the suggestion that it is a fundamental feature of perceptual development. However, recent findings in unimodal face perception suggest that perceptual abilities are flexible in development. Similarly, in multimodal perception, new paradigms examining temporal dynamics, rather than standard overall looking time, also suggest that perceptual narrowing might not be obligatory. Across two experiments, we assess perceptual narrowing in unimodal visual perception using remote eye-tracking. We compare adults' looking at human faces and monkey faces of different species, and present analyses of standard overall looking time and temporal dynamics. As expected, adults discriminated between different human faces, but, unlike previous studies, they also discriminated between different monkey faces. Temporal dynamics revealed that adults more readily discriminated human compared to monkey faces, suggesting a processing advantage for conspecifics compared to other animals. Adults' success in discriminating between faces of two unfamiliar monkey species calls into question whether perceptual narrowing is an obligatory developmental process. Humans undoubtedly diminish in their ability to perceive distinctions between infrequently encountered stimuli as compared to frequently encountered stimuli, however, consistent with recent findings, this narrowing should be conceptualized as a refinement and not as a loss of abilities. Perceptual abilities for infrequently encountered stimuli may be detectable, though weaker compared to adults' perception of frequently encountered stimuli. Consistent with several other accounts we suggest that perceptual development must be more flexible than a perceptual narrowing account posits.
C1 [Sorcinelli, Andrea; Vouloumanos, Athena] NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
RP Sorcinelli, A (corresponding author), NYU, Dept Psychol, 6 Washington Pl, New York, NY 10003 USA.
EM andrea.sorcinelli@nyu.edu
FU Eunice Kennedy Shriver National Institute of Child Health & Human
   Development of the National Institutes of Health [R01HD072018]; EUNICE
   KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN
   DEVELOPMENTUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [R01HD072018,
   R01HD072018, R01HD072018, R01HD072018, R01HD072018] Funding Source: NIH
   RePORTER
FX This research was supported by the Eunice Kennedy Shriver National
   Institute of Child Health & Human Development of the National Institutes
   of Health under Award Number R01HD072018 awarded to AV.
CR Araki M, 2016, SCIENCE, V354, P1282, DOI 10.1126/science.aah6799
   Burns TC, 2007, APPL PSYCHOLINGUIST, V28, P455, DOI 10.1017/S0142716407070257
   Chien SHL, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01606
   Curtin S., 2007, OXFORD HDB PSYCHOLIN, P579, DOI [DOI 10.1093/OXFORDHB/9780198568971.001.0001, 10.1093/ oxfordhb/9780198568971.013.0035.]
   Dufour V, 2010, J ETHOL, V28, P231, DOI 10.1007/s10164-009-0174-8
   Fair J, 2012, CHILD DEV, V83, P1996, DOI 10.1111/j.1467-8624.2012.01814.x
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Flom R, 2014, DEV PSYCHOBIOL, V56, P1442, DOI 10.1002/dev.21238
   Godard O, 2016, DEVELOPMENTAL SCI, V19, P155, DOI 10.1111/desc.12292
   Kendrick KM, 2001, NATURE, V414, P165, DOI 10.1038/35102669
   Kubicek C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089275
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Kuhl PK, 2006, DEVELOPMENTAL SCI, V9, pF13, DOI 10.1111/j.1467-7687.2006.00468.x
   Lewkowicz DJ, 2006, P NATL ACAD SCI USA, V103, P6771, DOI 10.1073/pnas.0602027103
   LOGAN JS, 1991, J ACOUST SOC AM, V89, P874, DOI 10.1121/1.1894649
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   Musser WB, 2014, J ACOUST SOC AM, V136, P1990, DOI 10.1121/1.4893906
   Pascalis O, 2005, P NATL ACAD SCI USA, V102, P5297, DOI 10.1073/pnas.0406627102
   Pascalis O, 2002, SCIENCE, V296, P1321, DOI 10.1126/science.1070223
   Pascalis O, 1998, BEHAV PROCESS, V43, P87, DOI 10.1016/S0376-6357(97)00090-9
   Peirce JW, 2001, BEHAV PROCESS, V55, P13, DOI 10.1016/S0376-6357(01)00158-9
   Pisoni DB, 1995, SPEECH PERCEPTION LI, P433
   POLKA L, 1994, J EXP PSYCHOL HUMAN, V20, P421, DOI 10.1037/0096-1523.20.2.421
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Scheumann M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0091192
   Scott LS, 2007, CURR DIR PSYCHOL SCI, V16, P197, DOI 10.1111/j.1467-8721.2007.00503.x
   STRANGE W, 1984, PERCEPT PSYCHOPHYS, V36, P131, DOI 10.3758/BF03202673
   Sundara M, 2006, COGNITION, V100, P369, DOI 10.1016/j.cognition.2005.04.007
   Tottenham N, 2009, PSYCHIAT RES, V168, P242, DOI 10.1016/j.psychres.2008.05.006
   Uttley L, 2013, INT J BEHAV DEV, V37, P84, DOI 10.1177/0165025412467583
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Yang Q, 2002, INVEST OPHTH VIS SCI, V43, P2939
NR 32
TC 0
Z9 0
U1 0
U2 2
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1664-1078
J9 FRONT PSYCHOL
JI Front. Psychol.
PD NOV 23
PY 2018
VL 9
AR 2326
DI 10.3389/fpsyg.2018.02326
PG 10
WC Psychology, Multidisciplinary
SC Psychology
GA HB5KN
UT WOS:000451099500001
PM 30532728
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Abou-Ghazaleh, A
   Khateb, A
   Nevat, M
AF Abou-Ghazaleh, Afaf
   Khateb, Asaid
   Nevat, Michael
TI Lexical Competition between Spoken and Literary Arabic: A New Look into
   the Neural Basis of Diglossia Using fMRI
SO NEUROSCIENCE
LA English
DT Article
DE Arabic language; picture naming; Hebrew; spoken Arabic; literary arabic;
   bilingualism
ID BILINGUAL LANGUAGE PRODUCTION; COGNITIVE CONTROL; NAME AGREEMENT;
   FUNCTIONAL CONNECTIVITY; SPEECH-PERCEPTION; IMAGE AGREEMENT; ANGULAR
   GYRUS; DIALECT USE; BRAIN; 2ND-LANGUAGE
AB Diglossia in the Arabic language refers to the socio-linguistic situation in which Spoken Arabic (SA), which is the first to be acquired, is used for everyday communications, while Literary Arabic (LA), acquired at school for reading and writing, is also used for formal functions. Although some authors consider SA and LA as a first and second language, the question of how these are managed in the brain has not yet been understood. Using functional magnetic resonance brain imaging (fMRI) analysis, this study aimed at exploring the neural basis of diglossia during picture naming in two contexts. In the first, healthy young participants were instructed to name each image either in SA or LA on the basis of cue word appearing after the stimulus. In the second, they were instructed to name images either in SA or in Hebrew. Behavioral analysis showed that naming in SA was slightly easier than LA and considerably easier than Hebrew. fMRI analysis showed no difference between SA and LA. Hebrew compared to SA revealed activation differences explainable in terms of engagement of language control modules and second- to first-language effects. These findings, discussed in the light of previous findings in bilingual literature, support the view that dominance in diglossia is modality-dependent. (C) 2018 Published by Elsevier Ltd on behalf of IBRO.
C1 [Abou-Ghazaleh, Afaf; Khateb, Asaid; Nevat, Michael] Univ Haifa, Fac Educ, Edmond J Safra Brain Res Ctr Study Learning Disab, Unit Study Arab Language, Haifa, Israel.
   [Abou-Ghazaleh, Afaf; Khateb, Asaid; Nevat, Michael] Univ Haifa, Fac Educ, Dept Learning Disabil, Haifa, Israel.
RP Khateb, A (corresponding author), Univ Haifa, Fac Educ, Edmond J Safra Brain Res Ctr Study Learning Disab, Dept Learning Disabil,Unit Study Arab Language, IL-31905 Haifa, Israel.
EM akhateb@edu.haifa.ac.il
RI Khateb, Asaid/AAF-1609-2020
OI Khateb, Asaid/0000-0003-4639-1564
FU Israeli Science FoundationIsrael Science Foundation [623/11]; Edmond J.
   Safra Brain Research Center for the Study of Learning Disabilities
FX This work was supported by the Israeli Science Foundation (Grant no'
   623/11) and by the Edmond J. Safra Brain Research Center for the Study
   of Learning Disabilities. We thank all the participants for their
   participation in this study.
CR Abutalebi J, 2008, ACTA PSYCHOL, V128, P466, DOI 10.1016/j.actpsy.2008.03.014
   Abutalebi J, 2008, CEREB CORTEX, V18, P1496, DOI 10.1093/cercor/bhm182
   Abutalebi J, 2008, LANG COGNITIVE PROC, V23, P557, DOI 10.1080/01690960801920602
   Abutalebi J, 2007, J NEUROLINGUIST, V20, P242, DOI 10.1016/j.jneuroling.2006.10.003
   Abutalebi J, 2016, BILING-LANG COGN, V19, P689, DOI 10.1017/S1366728916000225
   Abutalebi J, 2013, CORTEX, V49, P905, DOI 10.1016/j.cortex.2012.08.018
   Alario FX, 1999, BEHAV RES METH INS C, V31, P531, DOI 10.3758/BF03200732
   Ali N, 2010, J COGNITIVE NEUROSCI, V22, P2369, DOI 10.1162/jocn.2009.21352
   Bentin S, 1996, J EXP PSYCHOL LEARN, V22, P309, DOI 10.1037/0278-7393.22.2.309
   Berken JA, 2016, BRAIN STRUCT FUNCT, V221, P3591, DOI 10.1007/s00429-015-1121-9
   Berken JA, 2015, NEUROIMAGE, V112, P208, DOI 10.1016/j.neuroimage.2015.03.016
   Bloch C, 2009, NEUROPSYCHOLOGIA, V47, P625, DOI 10.1016/j.neuropsychologia.2008.11.009
   Buchweitz A, 2013, PHYS LIFE REV, V10, P428, DOI 10.1016/j.plrev.2013.07.020
   Buhler JC, 2017, LANG COGN NEUROSCI, V32, P757, DOI 10.1080/23273798.2016.1272704
   Buhler JC, 2018, J COGN PSYCHOL, V30, P336, DOI 10.1080/20445911.2018.1444614
   Buhler JC, 2017, BRAIN TOPOGR, V30, P610, DOI 10.1007/s10548-017-0562-2
   Burgaleta M, 2016, NEUROIMAGE, V125, P437, DOI 10.1016/j.neuroimage.2015.09.073
   Chee MWL, 2001, NEUROIMAGE, V13, P1155, DOI 10.1006/nimg.2001.0781
   Christoffels IK, 2006, J MEM LANG, V54, P324, DOI 10.1016/j.jml.2005.12.004
   Christoffels IK, 2007, BRAIN RES, V1147, P192, DOI 10.1016/j.brainres.2007.01.137
   Corina DP, 2010, BRAIN LANG, V115, P101, DOI 10.1016/j.bandl.2010.04.001
   Crinion J, 2006, SCIENCE, V312, P1537, DOI 10.1126/science.1127761
   Cycowicz YM, 1997, J EXP CHILD PSYCHOL, V65, P171, DOI 10.1006/jecp.1996.2356
   De Baene W, 2015, J COGNITIVE NEUROSCI, V27, P1752, DOI 10.1162/jocn_a_00817
   De Bleser R, 2003, J NEUROLINGUIST, V16, P439, DOI 10.1016/S0911-6044(03)00022-8
   Dehaene S, 1997, NEUROREPORT, V8, P3809, DOI 10.1097/00001756-199712010-00030
   Del Maschio N., 2018, BILINGUAL COGNITION, P325
   Emmorey K, 2016, BILING-LANG COGN, V19, P223, DOI 10.1017/S1366728915000085
   Eviatar Z, 2000, APPL PSYCHOLINGUIST, V21, P451, DOI 10.1017/S0142716400004021
   Fabbro F, 2001, BRAIN LANG, V79, P211, DOI 10.1006/brln.2001.2481
   Feng L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110896
   FERGUSON CA, 1959, WORD, V15, P325, DOI 10.1080/00437956.1959.11659702
   Friston K, 2007, STATISTICAL PARAMETRIC MAPPING: THE ANALYSIS OF FUNCTIONAL BRAIN IMAGES, P1
   Friston KJ, 2005, NEUROIMAGE, V25, P661, DOI 10.1016/j.neuroimage.2005.01.013
   Friston KJ, 1999, NEUROIMAGE, V10, P385, DOI 10.1006/nimg.1999.0484
   Fu YB, 2017, BRAIN LANG, V175, P123, DOI 10.1016/j.bandl.2017.10.005
   Garbin G, 2010, NEUROIMAGE, V53, P1272, DOI 10.1016/j.neuroimage.2010.05.078
   Grant AM, 2015, BRAIN LANG, V144, P35, DOI 10.1016/j.bandl.2015.03.010
   Green D. W., 2003, INTERFACE SYNTAX LEX, P197, DOI DOI 10.1075/LALD.30
   Green DW, 2006, LANG LEARN, V56, P99, DOI 10.1111/j.1467-9922.2006.00357.x
   Guo TM, 2011, NEUROIMAGE, V56, P2300, DOI 10.1016/j.neuroimage.2011.03.049
   Hacquard V, 2007, BRAIN LANG, V100, P295, DOI 10.1016/j.bandl.2006.04.009
   Haddad E. S., 2014, HDB ARABIC LITERACY, V9, P3, DOI [10.1007/978-94-017-8545-7_1, DOI 10.1007/978-94-017-8545-7_1]
   Hernandez AE, 2001, NEUROIMAGE, V14, P510, DOI 10.1006/nimg.2001.0810
   Hernandez AE, 2007, PSYCHOL BULL, V133, P638, DOI 10.1037/0033-2909.133.4.638
   Hernandez AE, 2006, BILING-LANG COGN, V9, P177, DOI 10.1017/S1366728906002525
   Hernandez AE, 2015, BRAIN LANG, V143, P11, DOI 10.1016/j.bandl.2015.01.010
   Hernandez AE, 2009, BRAIN LANG, V109, P133, DOI 10.1016/j.bandl.2008.12.005
   Hervais-Adelman A, 2014, BRAIN LANG, V132, P1, DOI 10.1016/j.bandl.2014.01.009
   Hillis AE, 2004, BRAIN, V127, P1479, DOI 10.1093/brain/awh172
   Hoshino N, 2008, COGNITION, V106, P501, DOI 10.1016/j.cognition.2007.02.001
   Ibrahim R, 2005, J PSYCHOLINGUIST RES, V34, P51, DOI 10.1007/s10936-005-3631-8
   Ibrahim R, 2007, J PSYCHOLINGUIST RES, V36, P297, DOI 10.1007/s10936-006-9046-3
   Ibrahim R, 2006, READ WRIT, V19, P563, DOI 10.1007/s11145-006-9009-y
   Ibrahim R, 2009, PSYCHOL RES BEHAV MA, V2, P93
   Indefrey P, 2006, LANG LEARN, V56, P279, DOI 10.1111/j.1467-9922.2006.00365.x
   KEATLEY CW, 1994, MEM COGNITION, V22, P70, DOI 10.3758/BF03202763
   Khateb A, 2007, INT J PSYCHOPHYSIOL, V65, P201, DOI 10.1016/j.ijpsycho.2007.04.008
   Kim SY, 2016, NEUROIMAGE, V129, P25, DOI 10.1016/j.neuroimage.2015.11.068
   Klein D, 2006, HUM BRAIN MAPP, V27, P153, DOI 10.1002/hbm.20174
   Klostermann F, 2013, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00032
   Kovelman I, 2008, J COGNITIVE NEUROSCI, V20, P153, DOI 10.1162/jocn.2008.20011
   Kroll J.F., 2002, SECOND LANG RES, V18, P137, DOI DOI 10.1191/0267658302SR2010A
   Kroll JF, 2015, ANNU REV LINGUIST, V1, P377, DOI 10.1146/annurev-linguist-030514-124937
   Lei M, 2018, JAP PSYCHOL RES, P1
   Li L, 2015, NEUROPSYCHOLOGIA, V71, P236, DOI 10.1016/j.neuropsychologia.2015.04.007
   Li P, 2014, CORTEX, V58, P301, DOI 10.1016/j.cortex.2014.05.001
   Liu HS, 2016, BRAIN LANG, V159, P60, DOI 10.1016/j.bandl.2016.05.013
   Liu HY, 2010, BRAIN RES, V1316, P75, DOI 10.1016/j.brainres.2009.12.030
   Llano DA, 2013, BRAIN LANG, V126, P62, DOI 10.1016/j.bandl.2012.06.004
   Martin A, 2001, CURR OPIN NEUROBIOL, V11, P194, DOI 10.1016/S0959-4388(00)00196-3
   Meschyan G, 2006, NEUROIMAGE, V29, P1135, DOI 10.1016/j.neuroimage.2005.08.055
   Miglietta S, 2013, BRAIN LANG, V126, P285, DOI 10.1016/j.bandl.2013.06.001
   Nevat M, 2014, EUR J NEUROSCI, V40, P3387, DOI 10.1111/ejn.12673
   Noonan KA, 2013, J COGNITIVE NEUROSCI, V25, P1824, DOI 10.1162/jocn_a_00442
   Perani D, 2005, CURR OPIN NEUROBIOL, V15, P202, DOI 10.1016/j.conb.2005.03.007
   Perani D, 2003, HUM BRAIN MAPP, V19, P170, DOI 10.1002/hbm.10110
   Pillai JJ, 2004, AM J NEURORADIOL, V25, P523
   Price CJ, 2012, NEUROIMAGE, V62, P816, DOI 10.1016/j.neuroimage.2012.04.062
   Rodriguez-Fornells A, 2006, LANG LEARN, V56, P133, DOI 10.1111/j.1467-9922.2006.00359.x
   Rodriguez-Fornells A, 2005, J COGNITIVE NEUROSCI, V17, P422, DOI 10.1162/0898929053279559
   Rodriguez-Fornells A, 2009, PHILOS T R SOC B, V364, P3711, DOI 10.1098/rstb.2009.0130
   Ruschemeyer SA, 2005, HUM BRAIN MAPP, V25, P266, DOI 10.1002/hbm.20098
   Saidi LG, 2013, BRAIN LANG, V124, P56, DOI 10.1016/j.bandl.2012.11.008
   Saiegh-Haddad E, 2004, APPL PSYCHOLINGUIST, V25, P495, DOI 10.1017/s0142716404001249
   Saiegh-Haddad E, 2003, APPL PSYCHOLINGUIST, V24, P431, DOI 10.1017/S0142716403000225
   Saiegh-Haddad E, 2018, J CHILD LANG, P1
   Saiegh-Haddad E., 2005, READ WRIT, V18, P559, DOI DOI 10.1007/S11145-005-3180-4
   Saiegh-Haddad E., 2012, CURRENT ISSUES BILIN, P43, DOI DOI 10.1007/978-94-007-2327-6_3
   Saiegh-Haddad E, 2007, APPL PSYCHOLINGUIST, V28, P607, DOI 10.1017/S0142716407070336
   Saiegh-Haddad E, 2018, J LEARN DISABIL-US, V51, P454, DOI 10.1177/0022219417720460
   Saiegh-Haddad E, 2016, SCI STUD READ, V20, P311, DOI 10.1080/10888438.2016.1180526
   Saiegh-Haddad E, 2011, J CHILD LANG, V38, P297, DOI 10.1017/S0305000909990365
   Schiff R, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00356
   Seghier ML, 2010, J NEUROSCI, V30, P16809, DOI 10.1523/JNEUROSCI.3377-10.2010
   Silbert LJ, 2014, P NATL ACAD SCI USA, V111, pE4687, DOI 10.1073/pnas.1323812111
   SNODGRASS JG, 1980, J EXP PSYCHOL-HUM L, V6, P174, DOI 10.1037/0278-7393.6.2.174
   Stoodley CJ, 2010, CORTEX, V46, P831, DOI 10.1016/j.cortex.2009.11.008
   Tu L, 2015, CORTEX, V64, P8, DOI 10.1016/j.cortex.2014.09.019
   Tussis L, 2017, BRAIN LANG, V168, P106, DOI 10.1016/j.bandl.2017.01.011
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Videsott G, 2010, BRAIN LANG, V113, P103, DOI [10.1016/j.bandl.2010.01.006, 10.1016/j.band1.2010.01.006]
   Vingerhoets G, 2003, NEUROIMAGE, V20, P2181, DOI 10.1016/j.neuroimage.2003.07.029
   Wang X, 2013, NEUROCASE, V19, P462, DOI 10.1080/13554794.2012.701635
   Wang YP, 2007, NEUROIMAGE, V35, P862, DOI 10.1016/j.neuroimage.2006.09.054
   Wang YP, 2009, NEUROIMAGE, V47, P414, DOI 10.1016/j.neuroimage.2008.12.055
   Wartenburger I, 2003, NEURON, V37, P159, DOI 10.1016/S0896-6273(02)01150-9
   Yang J, 2015, J NEUROLINGUIST, V33, P29, DOI 10.1016/j.jneuroling.2014.09.004
NR 108
TC 3
Z9 3
U1 0
U2 7
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0306-4522
EI 1873-7544
J9 NEUROSCIENCE
JI Neuroscience
PD NOV 21
PY 2018
VL 393
BP 83
EP 96
DI 10.1016/j.neuroscience.2018.09.045
PG 14
WC Neurosciences
SC Neurosciences & Neurology
GA HB1JE
UT WOS:000450777900008
PM 30312783
DA 2021-02-24
ER

PT J
AU Fischer-Baum, S
   Mis, R
   Dial, H
AF Fischer-Baum, Simon
   Mis, Rachel
   Dial, Heather
TI Word deafness with preserved number word perception
SO COGNITIVE NEUROPSYCHOLOGY
LA English
DT Article
DE Aphasia; numerosity; category-specific deficits; speech perception
ID SPARING NUMBERS; KNOWLEDGE; DEFICIT; BRAIN; MODEL; DISSOCIATIONS;
   PATIENT; SYSTEMS; MEMORY; FRUIT
AB We describe the performance of an aphasic individual, K.A., who showed a selective impairment affecting his ability to perceive spoken language, while largely sparing his ability to perceive written language and to produce spoken language. His spoken perception impairment left him unable to distinguish words or nonwords that differed on a single phoneme and he was no better than chance at auditory lexical decision or single spoken word and single picture matching with phonological foils. Strikingly, despite this profound impairment, K.A. showed a selective sparing in his ability to perceive number words, which he was able to repeat and comprehend largely without error. This case adds to a growing literature demonstrating modality-specific dissociations between number word and non-number word processing. Because of the locus of K.A.'s speech perception deficit for non-number words, we argue that this distinction between number word and non-number word processing arises at a sublexical level of representations in speech perception, in a parallel fashion to what has previously been argued for in the organization of the sublexical level of representation for speech production.
C1 [Fischer-Baum, Simon] Rice Univ, Dept Psychol, Houston, TX 77251 USA.
   [Mis, Rachel] Temple Univ, Dept Psychol, Philadelphia, PA 19122 USA.
   [Dial, Heather] Univ Texas Austin, Dept Commun Sci & Disorders, Austin, TX 78712 USA.
RP Fischer-Baum, S (corresponding author), Rice Univ, Dept Psychol, Houston, TX 77251 USA.
EM simon.j.fischer-baum@rice.edu
RI Mis, Rachel/W-8149-2019
FU National Institute on Deafness and Other Communication Disorders of the
   National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USANIH National Institute
   on Deafness & Other Communication Disorders (NIDCD) [R21DC01671,
   F32DC016812]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [F32DC016812, R21DC016715,
   F32DC016812, R21DC016715, R21DC016715, F32DC016812] Funding Source: NIH
   RePORTER
FX Research was supported by National Institute on Deafness and Other
   Communication Disorders of the National Institutes of Health under award
   number R21DC01671 to S.F.B. and F32DC016812 to H.D.
CR Amalric M, 2016, P NATL ACAD SCI USA, V113, P4909, DOI 10.1073/pnas.1603205113
   ANDERSON SW, 1990, BRAIN, V113, P749, DOI 10.1093/brain/113.3.749
   Bencini GML, 2011, CORTEX, V47, P1052, DOI 10.1016/j.cortex.2011.03.013
   Brannon EM, 1998, SCIENCE, V282, P746, DOI 10.1126/science.282.5389.746
   BREEDIN SD, 1994, COGNITIVE NEUROPSYCH, V11, P617, DOI 10.1080/02643299408251987
   Cano A, 2008, NEUROPSYCHOLOGIA, V46, P63, DOI 10.1016/j.neuropsychologia.2007.08.008
   Cantlon JF, 2012, P NATL ACAD SCI USA, V109, P10725, DOI 10.1073/pnas.1201893109
   Capitani E, 2003, COGN NEUROPSYCHOL, V20, P213, DOI 10.1080/02643290244000266
   Cappelletti M, 2005, COGN NEUROPSYCHOL, V22, P771, DOI 10.1080/02643290442000293
   Caramazza A, 2003, TRENDS COGN SCI, V7, P354, DOI 10.1016/S1364-6613(03)00159-1
   Caramazza A, 1998, J COGNITIVE NEUROSCI, V10, P1, DOI 10.1162/089892998563752
   CIPOLOTTI L, 1991, BRAIN, V114, P2619, DOI 10.1093/brain/114.6.2619
   COHEN J, 1993, BEHAV RES METH INSTR, V25, P257, DOI 10.3758/BF03204507
   Cohen L, 1997, COGN NEUROPSYCHOL, V14, P1029, DOI 10.1080/026432997381349
   CRANNELL CW, 1957, J PSYCHOL, V44, P319, DOI 10.1080/00223980.1957.9713089
   Crawford JR, 1998, CLIN NEUROPSYCHOL, V12, P482, DOI 10.1076/clin.12.4.482.7241
   Crutch SJ, 2003, COGN NEUROPSYCHOL, V20, P355, DOI 10.1080/02643290244000220
   CUTLER A, 1986, J MEM LANG, V25, P385, DOI 10.1016/0749-596X(86)90033-1
   Dehaene S., 2011, NUMBER SENSE MIND CR
   Delazer M, 2002, NEUROPSYCHOLOGIA, V40, P2167, DOI 10.1016/S0028-3932(02)00044-1
   Dell GS, 2007, J MEM LANG, V56, P490, DOI 10.1016/j.jml.2006.05.007
   Dial H, 2017, NEUROPSYCHOLOGIA, V96, P192, DOI 10.1016/j.neuropsychologia.2017.01.009
   Dotan D, 2015, CORTEX, V63, P317, DOI 10.1016/j.cortex.2014.08.014
   Dunn D. M., 2007, PEABODY PICTURE VOCA
   FARAH MJ, 1992, NEUROPSYCHOLOGIA, V30, P609, DOI 10.1016/0028-3932(92)90066-U
   Feigenson L, 2004, TRENDS COGN SCI, V8, P307, DOI 10.1016/j.tics.2004.05.002
   Goldinger SD, 2003, J PHONETICS, V31, P305, DOI 10.1016/S0095-4470(03)00030-5
   Gordon P, 2004, SCIENCE, V306, P496, DOI 10.1126/science.1094492
   Grotheer M, 2016, NEUROIMAGE, V132, P314, DOI 10.1016/j.neuroimage.2016.02.069
   Han ZZ, 2011, NEUROCASE, V17, P418, DOI 10.1080/13554794.2010.532140
   HART J, 1992, NATURE, V359, P60, DOI 10.1038/359060a0
   Huth AG, 2016, NATURE, V532, P453, DOI 10.1038/nature17637
   Jones G, 2015, COGNITION, V144, P1, DOI 10.1016/j.cognition.2015.07.009
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   Marangolo P, 2005, NEUROPSYCHOLOGIA, V43, P1177, DOI 10.1016/j.neuropsychologia.2004.11.001
   Martin RC, 1999, J MEM LANG, V41, P3, DOI 10.1006/jmla.1999.2637
   MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0
   McCloskey M, 2013, PROCD SOC BEHV, V94, P203, DOI 10.1016/j.sbspro.2013.09.100
   McCrink K, 2013, DEVELOPMENTAL SCI, V16, P451, DOI 10.1111/desc.12037
   Nieder A, 2009, ANNU REV NEUROSCI, V32, P185, DOI 10.1146/annurev.neuro.051508.135550
   NORRIS D, 1994, COGNITION, V52, P189, DOI 10.1016/0010-0277(94)90043-4
   Roach A., 1996, CLIN APHASIOLOGY, V24, P121, DOI DOI 10.1037/t56477-000
   SACCHETT C, 1992, COGNITIVE NEUROPSYCH, V9, P73, DOI 10.1080/02643299208252053
   Samson D, 2003, COGN NEUROPSYCHOL, V20, P373, DOI 10.1080/02643290244000329
   Shum J, 2013, J NEUROSCI, V33, P6709, DOI 10.1523/JNEUROSCI.4558-12.2013
   Slevc L Robert, 2015, Handb Clin Neurol, V129, P573, DOI 10.1016/B978-0-444-62630-1.00032-9
   Starrfelt R, 2007, BRAIN LANG, V102, P52, DOI 10.1016/j.bandl.2006.09.005
   Wolmetz M, 2011, J COGNITIVE NEUROSCI, V23, P552, DOI 10.1162/jocn.2010.21495
NR 48
TC 1
Z9 1
U1 1
U2 5
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0264-3294
EI 1464-0627
J9 COGN NEUROPSYCHOL
JI Cogn. Neuropsychol.
PD NOV 17
PY 2018
VL 35
IS 8
BP 415
EP 429
DI 10.1080/02643294.2018.1515734
PG 15
WC Psychology; Psychology, Experimental
SC Psychology
GA HD7ZF
UT WOS:000452772200002
PM 30175931
OA Green Accepted
DA 2021-02-24
ER

PT J
AU O'Brien, GE
   McCloy, DR
   Kubota, EC
   Yeatman, JD
AF O'Brien, Gabrielle E.
   McCloy, Daniel R.
   Kubota, Emily C.
   Yeatman, Jason D.
TI Reading ability and phoneme categorization
SO SCIENTIFIC REPORTS
LA English
DT Article
ID FORMANT TRANSITION DURATION; SPEECH-PERCEPTION; DEVELOPMENTAL DYSLEXIA;
   PSYCHOPHYSICAL PERFORMANCE; HYPERACTIVITY DISORDER; CATEGORICAL
   PERCEPTION; PSYCHOMETRIC FUNCTION; PROCESSING DEFICITS; SPECTRAL
   RESOLUTION; ENVELOPE PERCEPTION
AB Dyslexia is associated with abnormal performance on many auditory psychophysics tasks, particularly those involving the categorization of speech sounds. However, it is debated whether those apparent auditory deficits arise from (a) reduced sensitivity to particular acoustic cues, (b) the difficulty of experimental tasks, or (c) unmodeled lapses of attention. Here we investigate the relationship between phoneme categorization and reading ability, with special attention to the nature of the cue encoding the phoneme contrast (static versus dynamic), differences in task paradigm difficulty, and methodological details of psychometric model fitting. We find a robust relationship between reading ability and categorization performance, show that task difficulty cannot fully explain that relationship, and provide evidence that the deficit is not restricted to dynamic cue contrasts, contrary to prior reports. Finally, we demonstrate that improved modeling of behavioral responses suggests that performance does differ between children with dyslexia and typical readers, but that the difference may be smaller than previously reported.
C1 [O'Brien, Gabrielle E.] Univ Washington, Inst Learning & Brain Sci, Seattle, WA 98195 USA.
   Univ Washington, Dept Speech & Hearing Sci, Seattle, WA 98195 USA.
RP O'Brien, GE (corresponding author), Univ Washington, Inst Learning & Brain Sci, Seattle, WA 98195 USA.
EM eobrien3@uw.edu
OI McCloy, Daniel/0000-0002-7572-3241
FU Auditory Neuroscience Training Grant (NIH)United States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USA
   [2T32DC005361-16]; Microsoft; NSF BCSNational Science Foundation (NSF)
   [1551330]; NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [T32DC005361, T32DC005361,
   T32DC005361, T32DC005361, T32DC005361] Funding Source: NIH RePORTER
FX We would like to thank Richard Wright for helpful discussions and
   feedback in the study design and interpretation. G.E.O. and D.R.M. were
   supported by the Auditory Neuroscience Training Grant (NIH grant
   2T32DC005361-16) This work was also supported by research grants from
   Microsoft and NSF BCS #1551330 to J.D.Y.
CR Adlard A, 1998, Q J EXP PSYCHOL-A, V51, P153
   Ahissar M, 2007, TRENDS COGN SCI, V11, P458, DOI 10.1016/j.tics.2007.08.015
   Ahissar M, 2006, NAT NEUROSCI, V9, P1558, DOI 10.1038/nn1800
   Amitay S, 2002, BRAIN, V125, P2272, DOI 10.1093/brain/awf231
   Banai K, 2004, AUDIOL NEURO-OTOL, V9, P328, DOI 10.1159/000081282
   Banai K, 2006, CEREB CORTEX, V16, P1718, DOI 10.1093/cercor/bhj107
   BARON RM, 1986, J PERS SOC PSYCHOL, V51, P1173, DOI 10.1037/0022-3514.51.6.1173
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Boets B, 2007, NEUROPSYCHOLOGIA, V45, P1608, DOI 10.1016/j.neuropsychologia.2007.01.009
   Boets B, 2013, SCIENCE, V342, P1251, DOI 10.1126/science.1244333
   Boets B, 2011, RES DEV DISABIL, V32, P560, DOI 10.1016/j.ridd.2010.12.020
   Boets B, 2010, BRIT J DEV PSYCHOL, V28, P5, DOI 10.1348/026151010X485223
   Bogliotti C, 2008, J EXP CHILD PSYCHOL, V101, P137, DOI 10.1016/j.jecp.2008.03.006
   BRADLEY L, 1983, NATURE, V301, P419, DOI 10.1038/301419a0
   Bradlow AR, 1999, J ACOUST SOC AM, V106, P2086, DOI 10.1121/1.427953
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Breier JI, 2001, J EXP CHILD PSYCHOL, V80, P245, DOI 10.1006/jecp.2001.2630
   Bus AG, 1999, J EDUC PSYCHOL, V91, P403, DOI 10.1037/0022-0663.91.3.403
   Calcus A, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12558
   Calcus A, 2016, J SPEECH LANG HEAR R, V59, P835, DOI 10.1044/2016_JSLHR-H-15-0076
   Chiappe P, 2001, J EXP CHILD PSYCHOL, V80, P58, DOI 10.1006/jecp.2000.2624
   Collet G, 2012, RES DEV DISABIL, V33, P1805, DOI 10.1016/j.ridd.2012.05.003
   Dawes P, 2009, EAR HEARING, V30, P675, DOI 10.1097/AUD.0b013e3181b34cc5
   Dole M, 2012, NEUROPSYCHOLOGIA, V50, P1543, DOI 10.1016/j.neuropsychologia.2012.03.007
   Farmer ME, 1995, PSYCHON B REV, V2, P460, DOI 10.3758/BF03210983
   FRY D B, 1975, Cortex, V11, P355
   Garnica O. K, 1973, COGNITIVE DEV ACQUIS, P215
   Gibson LY, 2006, COGN NEUROPSYCHOL, V23, P621, DOI 10.1080/02643290500412545
   Goswami U, 2002, P NATL ACAD SCI USA, V99, P10911, DOI 10.1073/pnas.122368599
   Goswami U, 2011, TRENDS COGN SCI, V15, P3, DOI 10.1016/j.tics.2010.10.001
   Goswami U, 2011, DEVELOPMENTAL SCI, V14, P34, DOI 10.1111/j.1467-7687.2010.00955.x
   Hakvoort B, 2016, J SPEECH LANG HEAR R, V59, P1448, DOI 10.1044/2016_JSLHR-L-15-0306
   Hamalainen JA, 2009, APPL PSYCHOLINGUIST, V30, P511, DOI 10.1017/S0142716409090250
   Hamalainen JA, 2013, J LEARN DISABIL-US, V46, P413, DOI 10.1177/0022219411436213
   Hastie T., 2009, ELEMENTS, V1, P337, DOI DOI 10.1007/B94608
   Hulme C, 2002, J EXP CHILD PSYCHOL, V82, P2, DOI 10.1006/jecp.2002.2670
   Ingelghem V, 2005, CHILDREN LEARNING DI, P47
   Joanisse MF, 2000, J EXP CHILD PSYCHOL, V77, P30, DOI 10.1006/jecp.1999.2553
   Joo SJ, 2018, CORTEX, V103, P291, DOI 10.1016/j.cortex.2018.03.013
   Joo SJ, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04471-5
   Law JM, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00482
   Lehongre K, 2011, NEURON, V72, P1080, DOI 10.1016/j.neuron.2011.11.002
   LIGHT JG, 1995, DEV NEUROPSYCHOL, V11, P323, DOI 10.1080/87565649509540623
   Lyon GR, 2003, ANN DYSLEXIA, V53, P1, DOI 10.1007/s11881-003-0001-9
   Maassen B, 2001, CLIN LINGUIST PHONET, V15, P319
   Manis FR, 1997, J EXP CHILD PSYCHOL, V66, P211, DOI 10.1006/jecp.1997.2383
   McAnally KI, 1997, J SPEECH LANG HEAR R, V40, P939, DOI 10.1044/jslhr.4004.939
   Menell P, 1999, J SPEECH LANG HEAR R, V42, P797, DOI 10.1044/jslhr.4204.797
   Merzenich MM, 1996, SCIENCE, V271, P77, DOI 10.1126/science.271.5245.77
   Messaoud-Galusi S, 2011, J SPEECH LANG HEAR R, V54, P1682, DOI 10.1044/1092-4388(2011/09-0261)
   MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z
   Noordenbos MW, 2015, SCI STUD READ, V19, P340, DOI 10.1080/10888438.2015.1052455
   Noordenbos MW, 2013, CLIN NEUROPHYSIOL, V124, P1151, DOI 10.1016/j.clinph.2012.12.044
   Pennington BF, 2006, COGNITION, V101, P385, DOI 10.1016/j.cognition.2006.04.008
   Peterson RL, 2015, ANNU REV CLIN PSYCHO, V11, P283, DOI 10.1146/annurev-clinpsy-032814-112842
   PISONI DB, 1974, PERCEPT PSYCHOPHYS, V15, P285, DOI 10.3758/BF03213946
   Poelmans H, 2011, RES DEV DISABIL, V32, P2810, DOI 10.1016/j.ridd.2011.05.025
   Ramus F, 2003, BRAIN, V126, P841, DOI 10.1093/brain/awg076
   Ramus F, 2008, Q J EXP PSYCHOL, V61, P129, DOI 10.1080/17470210701508822
   REED MA, 1989, J EXP CHILD PSYCHOL, V48, P270, DOI 10.1016/0022-0965(89)90006-4
   REPP BH, 1981, B PSYCHONOMIC SOC, V18, P12
   Roach NW, 2004, PERCEPTION, V33, P817, DOI 10.1068/p5207
   Robertson EK, 2009, DEVELOPMENTAL SCI, V12, P753, DOI 10.1111/j.1467-7687.2009.00806.x
   Rocheron I, 2002, NEUROREPORT, V13, P1683, DOI 10.1097/00001756-200209160-00023
   Rosen S, 2003, J PHONETICS, V31, P509, DOI 10.1016/S0095-4470(03)00046-9
   Rosen S, 2001, J SPEECH LANG HEAR R, V44, P720, DOI 10.1044/1092-4388(2001/057)
   Rosen S, 1999, CURR BIOL, V9, pR698, DOI 10.1016/S0960-9822(99)80443-6
   Schulte-Korne G, 1998, PERCEPT MOTOR SKILL, V86, P1043, DOI 10.2466/pms.1998.86.3.1043
   Schutt H., 2015, J VISION, V15, P474, DOI [10.1167/15.12.474, DOI 10.1167/15.12.474]
   Serniclaes WI, 2004, J EXP CHILD PSYCHOL, V87, P336, DOI 10.1016/j.jecp.2004.02.001
   Shaywitz SE, 1998, NEW ENGL J MED, V338, P307, DOI 10.1056/NEJM199801293380507
   SHAYWITZ SE, 1992, NEW ENGL J MED, V326, P145, DOI 10.1056/NEJM199201163260301
   Siegel L., 1989, READING WRITING INTE, V2, P257, DOI DOI 10.1007/BF00377646
   Snowling M., 1998, CHILD ADOL MENT H-UK, V3, P4, DOI [10.1111/1475-3588.00201, DOI 10.1111/1475-3588.00201]
   Snowling M., 2000, DYSLEXIA
   Steinbrink C, 2014, CHILD DEV, V85, P1711, DOI 10.1111/cdev.12208
   Stevenson J, 2005, J CHILD PSYCHOL PSYC, V46, P1081, DOI 10.1111/j.1469-7610.2005.01533.x
   STOLLMAN MHP, 1994, SCAND AUDIOL, V23, P39, DOI 10.3109/01050399409047484
   Stoodley CJ, 2006, BRAIN RES, V1121, P190, DOI 10.1016/j.brainres.2006.08.095
   SWANSON HL, 1993, J EXP CHILD PSYCHOL, V56, P87, DOI 10.1006/jecp.1993.1027
   Talcott JB, 2000, NEUROPSYCHOLOGIA, V38, P935, DOI 10.1016/S0028-3932(00)00020-8
   TALLAL P, 1980, BRAIN LANG, V9, P182, DOI 10.1016/0093-934X(80)90139-X
   Tallal P, 1996, SCIENCE, V271, P81, DOI 10.1126/science.271.5245.81
   The Mathworks Inc, 2016, MATLAB MATH WORKS
   Thomson JM, 2008, J PHYSIOL-PARIS, V102, P120, DOI 10.1016/j.jphysparis.2008.03.007
   Thomson JM, 2006, J RES READ, V29, P334, DOI 10.1111/j.1467-9817.2006.00312.x
   Tingley D, 2015, CRAN, DOI [10.1037/a0020761, DOI 10.1037/A0020761]
   Treutwein B, 1999, PERCEPT PSYCHOPHYS, V61, P87, DOI 10.3758/BF03211951
   Vandermosten M, 2011, RES DEV DISABIL, V32, P593, DOI 10.1016/j.ridd.2010.12.015
   Vandermosten M, 2010, P NATL ACAD SCI USA, V107, P10389, DOI 10.1073/pnas.0912858107
   VARGO FE, 1995, PERCEPT MOTOR SKILL, V80, P1219, DOI 10.2466/pms.1995.80.3c.1219
   Wang SM, 2013, J EXP CHILD PSYCHOL, V115, P188, DOI 10.1016/j.jecp.2012.11.015
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1314, DOI 10.3758/BF03194545
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1293, DOI 10.3758/BF03194544
   Winn MB, 2015, J ACOUST SOC AM, V137, P1430, DOI 10.1121/1.4908308
   Witton C, 1998, CURR BIOL, V8, P791, DOI 10.1016/S0960-9822(98)70320-3
   Witton C, 2002, J COGNITIVE NEUROSCI, V14, P866, DOI 10.1162/089892902760191090
   Wright BA, 1997, NATURE, V387, P176, DOI 10.1038/387176a0
   Zhang YJ, 2012, J CHILD PSYCHOL PSYC, V53, P874, DOI 10.1111/j.1469-7610.2012.02528.x
   Ziegler JC, 2008, TRENDS COGN SCI, V12, P244, DOI 10.1016/j.tics.2008.04.001
   Ziegler JC, 2009, DEVELOPMENTAL SCI, V12, P732, DOI 10.1111/j.1467-7687.2009.00817.x
NR 102
TC 8
Z9 8
U1 0
U2 3
PU NATURE RESEARCH
PI BERLIN
PA HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY
SN 2045-2322
J9 SCI REP-UK
JI Sci Rep
PD NOV 15
PY 2018
VL 8
AR 16842
DI 10.1038/s41598-018-34823-8
PG 17
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA HA3PY
UT WOS:000450167700013
PM 30442952
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Brown, VA
   Hedayati, M
   Zanger, A
   Mayn, S
   Ray, L
   Dillman-Hasso, N
   Strand, JF
AF Brown, Violet A.
   Hedayati, Maryam
   Zanger, Annie
   Mayn, Sasha
   Ray, Lucia
   Dillman-Hasso, Naseem
   Strand, Julia F.
TI What accounts for individual differences in susceptibility to the McGurk
   effect?
SO PLOS ONE
LA English
DT Article
ID VISUAL SPEECH-PERCEPTION; WORKING-MEMORY; AUDIOVISUAL INTEGRATION;
   SENTENCE RECOGNITION; SELECTIVE ADAPTATION; CHILDRENS SPEECH; PHONETIC
   DETAIL; MECHANICAL TURK; HEARING-LIPS; INFORMATION
AB The McGurk effect is a classic audiovisual speech illusion in which discrepant auditory and visual syllables can lead to a fused percept (e.g., an auditory /ba/ paired with a visual /ga/ often leads to the perception of MO. The McGurk effect is robust and easily replicated in pooled group data, but there is tremendous variability in the extent to which individual participants are susceptible to it. In some studies, the rate at which individuals report fusion responses ranges from 0% to 100%. Despite its widespread use in the audiovisual speech perception literature, the roots of the wide variability in McGurk susceptibility are largely unknown. This study evaluated whether several perceptual and cognitive traits are related to McGurk susceptibility through correlational analyses and mixed effects modeling. We found that an individual's susceptibility to the McGurk effect was related to their ability to extract place of articulation information from the visual signal (i.e., a more fine-grained analysis of lipreading ability), but not to scores on tasks measuring attentional control, processing speed, working memory capacity, or auditory perceptual gradiency. These results provide support for the claim that a small amount of the variability in susceptibility to the McGurk effect is attributable to lipreading skill. In contrast, cognitive and perceptual abilities that are commonly used predictors in individual differences studies do not appear to underlie susceptibility to the McGurk effect.
C1 [Brown, Violet A.; Hedayati, Maryam; Zanger, Annie; Mayn, Sasha; Ray, Lucia; Dillman-Hasso, Naseem; Strand, Julia F.] Carleton Coll, Dept Psychol, Northfield, MN 55057 USA.
RP Brown, VA; Strand, JF (corresponding author), Carleton Coll, Dept Psychol, Northfield, MN 55057 USA.
EM violet.brown@wustl.edu; jstrand@carleton.edu
RI ; Strand, Julia/J-5432-2014
OI Ray, Lucia/0000-0001-9692-0909; Strand, Julia/0000-0001-5950-0139;
   Brown, Violet/0000-0001-5310-6499; Dillman-Hasso,
   Naseem/0000-0002-8284-4383
FU Carleton CollegeEuropean Commission
FX We are grateful to Eun Jong Kong and Jan Edwards for providing stimuli
   for the Visual Analogue Scale task, to Hunter Brown for feedback on an
   early draft of the paper, and to Aaron Swoboda for helpful suggestions
   on figure design. Carleton College supported this work. Correspondence
   should be addressed to Violet Brown(violet.brown@wustl.edu) or Julia
   Strand (jstrand@carleton.edu).
CR Aloufy S, 1996, BRAIN LANG, V53, P51, DOI 10.1006/brln.1996.0036
   Alsius A, 2005, CURR BIOL, V15, P839, DOI 10.1016/j.cub.2005.03.046
   Alsius A, 2007, EXP BRAIN RES, V183, P399, DOI 10.1007/s00221-007-1110-1
   Alsius A, 2018, MULTISENS RES, V31, P111, DOI 10.1163/22134808-00002565
   Alsius A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00727
   Auer ET, 2007, J SPEECH LANG HEAR R, V50, P1157, DOI 10.1044/1092-4388(2007/080)
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Mallick D, 2015, PSYCHON B REV, V22, P1299, DOI 10.3758/s13423-015-0817-4
   Bates Douglas, 2014, PACKAGE LME4, P12, DOI DOI 10.18637/JSS.V067.I01
   Beauchamp MS, 2018, MULTISENS RES, V31, P1, DOI 10.1163/22134808-00002598
   Beauchamp MS, 2010, J NEUROSCI, V30, P2414, DOI 10.1523/JNEUROSCI.4865-09.2010
   Bebko JM, 2014, AUTISM RES, V7, P50, DOI 10.1002/aur.1343
   Benoit MM, 2010, HUM BRAIN MAPP, V39
   Besser J, 2012, J SPEECH LANG HEAR R, V55, P194, DOI 10.1044/1092-4388(2011/11-0008)
   Bleckley MK, 2003, PSYCHON B REV, V10, P884, DOI 10.3758/BF03196548
   Brancazio L, 2005, PERCEPT PSYCHOPHYS, V67, P759, DOI 10.3758/BF03193531
   Brancazio L, 2004, J EXP PSYCHOL HUMAN, V30, P445, DOI 10.1037/0096-1523.30.3.445
   Buchan JN, 2012, SEEING PERCEIVING, V25, P87, DOI 10.1163/187847611X620937
   Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980
   Calvert GA, 2000, CURR BIOL, V10, P649, DOI 10.1016/S0960-9822(00)00513-3
   Chambers CD, 2013, CORTEX, V49, P609, DOI 10.1016/j.cortex.2012.12.016
   Cienkowski KM, 2002, EAR HEARING, V23, P439, DOI 10.1097/00003446-200210000-00006
   Conway ARA, 2001, PSYCHON B REV, V8, P331, DOI 10.3758/BF03196169
   Crump MJC, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057410
   DANEMAN M, 1980, J VERB LEARN VERB BE, V19, P450, DOI 10.1016/S0022-5371(80)90312-6
   de Gelder B, 2003, SCHIZOPHR RES, V59, P211, DOI 10.1016/S0920-9964(01)00344-9
   ERBER NP, 1969, J SPEECH HEAR RES, V12, P423, DOI 10.1044/jshr.1202.423
   Erickson LC, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00534
   ERIKSEN BA, 1974, PERCEPT PSYCHOPHYS, V16, P143, DOI 10.3758/BF03203267
   Fanelli D, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010271
   Feld JE, 2009, J SPEECH LANG HEAR R, V52, P1555, DOI 10.1044/1092-4388(2009/08-0137)
   Fernald A, 2006, DEV PSYCHOL, V42, P98, DOI 10.1037/0012-1649.42.1.98
   Fullgrabe C, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01268
   Gentilucci M, 2005, EXP BRAIN RES, V167, P66, DOI 10.1007/s00221-005-0008-z
   Grant KW, 1996, J ACOUST SOC AM, V100, P2415, DOI 10.1121/1.417950
   Grant KW, 1998, J ACOUST SOC AM, V104, P2438, DOI 10.1121/1.423751
   Grant KW, 1998, J ACOUST SOC AM, V103, P2677, DOI 10.1121/1.422788
   GREEN KP, 1991, J EXP PSYCHOL HUMAN, V17, P278, DOI 10.1037/0096-1523.17.1.278
   GREEN KP, 1991, PERCEPT PSYCHOPHYS, V50, P524, DOI 10.3758/BF03207536
   Hawkins S, 1998, AVSP 98 INT C AUD VI
   Hedge C, 2018, BEHAV RES METHODS, V50, P1166, DOI 10.3758/s13428-017-0935-1
   Hutchison KA, 2007, J EXP PSYCHOL LEARN, V33, P645, DOI 10.1037/0278-7393.33.4.645
   Irwin JR, 2006, PERCEPT PSYCHOPHYS, V68, P582, DOI 10.3758/BF03208760
   JACKSON PL, 1988, VOLTA REV, V90, P99
   Julien HM, 2012, J SPEECH LANG HEAR R, V55, P1836, DOI 10.1044/1092-4388(2012/11-0131)
   KAIL R, 1994, DEV PSYCHOL, V30, P949, DOI 10.1037/0012-1649.30.6.949
   Kapnoula EC, 2017, J EXP PSYCHOL HUMAN, V43, P1594, DOI 10.1037/xhp0000410
   Keane BP, 2010, RES AUTISM SPECT DIS, V4, P276, DOI 10.1016/j.rasd.2009.09.015
   Kong EJ, 2011, INDIVIDUAL DIFFERENC
   Kong EJ, 2016, J PHONETICS, V59, P40, DOI 10.1016/j.wocn.2016.08.006
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Lange ND, 2012, FRONT PSYCHOL, V3, DOI [10.3389/fpsyg.2012.00215, 10.3389/fpsyg.2012.00552]
   LIBERMAN AM, 1957, J EXP PSYCHOL, V54, P358, DOI 10.1037/h0044417
   Luce PA, 1999, J EXP PSYCHOL HUMAN, V25, P174, DOI 10.1037/0096-1523.25.1.174
   Ma WJ, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004638
   MacDonald J, 2000, PERCEPTION, V29, P1155, DOI 10.1068/p3020
   Magnotti JF, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202908
   Magnotti JF, 2018, MULTISENS RES, V31, P19, DOI 10.1163/22134808-00002586
   Magnotti JF, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005229
   Magnotti JF, 2015, EXP BRAIN RES, V233, P2581, DOI 10.1007/s00221-015-4324-7
   Massaro D. W., 1987, SPEECH PERCEPTION EA
   MASSARO DW, 1993, AM J PSYCHOL, V106, P25, DOI 10.2307/1422864
   MASSARO DW, 1983, J EXP PSYCHOL HUMAN, V9, P753, DOI 10.1037/0096-1523.9.5.753
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   MEYER DE, 1971, J EXP PSYCHOL, V90, P227, DOI 10.1037/h0031564
   Mongillo EA, 2008, J AUTISM DEV DISORD, V38, P1349, DOI 10.1007/s10803-007-0521-y
   Fernandez LM, 2017, HUM BRAIN MAPP, V38, P5691, DOI 10.1002/hbm.23758
   MULLENNIX JW, 1989, J ACOUST SOC AM, V85, P365, DOI 10.1121/1.397688
   Munhall KG, 1996, PERCEPT PSYCHOPHYS, V58, P351, DOI 10.3758/BF03206811
   Munson B, 2009, J ACOUST SOC AM, V125, P2529
   Munson B, 2017, CLIN LINGUIST PHONET, V31, P56, DOI 10.1080/02699206.2016.1233292
   Munson B, 2016, SPEECH LANG HEARING, V19, P36, DOI 10.1080/2050571X.2015.1116154
   Munson B, 2012, AM J SPEECH-LANG PAT, V21, P124, DOI 10.1044/1058-0360(2011/11-0009)
   Nahorna O, 2015, J ACOUST SOC AM, V137, P362, DOI 10.1121/1.4904536
   Nahorna O, 2012, J ACOUST SOC AM, V132, P1061, DOI 10.1121/1.4728187
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Nieuwenhuis S, 2006, MEM COGNITION, V34, P1260, DOI 10.3758/BF03193270
   Ostrand R, 2016, COGNITION, V151, P96, DOI 10.1016/j.cognition.2016.02.019
   ROBERTS M, 1981, PERCEPT PSYCHOPHYS, V30, P309, DOI 10.3758/BF03206144
   Rosenblum LD, 1996, J EXP PSYCHOL HUMAN, V22, P318, DOI 10.1037/0096-1523.22.2.318
   ROSENTHAL R, 1979, PSYCHOL BULL, V86, P638, DOI 10.1037/0033-2909.86.3.638
   SALDANA HM, 1994, J ACOUST SOC AM, V95, P3658, DOI 10.1121/1.409935
   Schellinger SK, 2017, CLIN LINGUIST PHONET, V31, P80, DOI 10.1080/02699206.2016.1205665
   Schmidt JR, 2011, ACTA PSYCHOL, V138, P176, DOI 10.1016/j.actpsy.2011.06.002
   SEKIYAMA K, 1993, J PHONETICS, V21, P427, DOI 10.1016/S0095-4470(19)30229-3
   SEKIYAMA K, 1991, J ACOUST SOC AM, V90, P1797, DOI 10.1121/1.401660
   Setti A, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00575
   Simcox T, 2014, BEHAV RES METHODS, V46, P95, DOI 10.3758/s13428-013-0345-y
   SIMON JR, 1969, J EXP PSYCHOL, V81, P174, DOI 10.1037/h0027448
   Slote J, 2016, BEHAV RES METHODS, V48, P553, DOI 10.3758/s13428-015-0599-7
   Sommers MS, 2005, EAR HEARING, V26, P263, DOI 10.1097/00003446-200506000-00003
   Soto-Faraco S, 2009, J EXP PSYCHOL HUMAN, V35, P580, DOI 10.1037/a0013483
   Strand J, 2014, J SPEECH LANG HEAR R, V57, P2322, DOI 10.1044/2014_JSLHR-H-14-0059
   Strand JF, 2018, J SPEECH LANG HEAR R, V61, P1463, DOI 10.1044/2018_JSLHR-H-17-0257
   Stroop JR., 1935, J EXP PSYCHOL PSYCNE
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Thomas SM, 2002, PERCEPT PSYCHOPHYS, V64, P932, DOI 10.3758/BF03196797
   Thornton A, 2000, J CLIN EPIDEMIOL, V53, P207, DOI 10.1016/S0895-4356(99)00161-4
   Tiippana K, 2004, EUR J COGN PSYCHOL, V16, P457, DOI 10.1080/09541440340000268
   Tiippana K, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00725
   TURNER ML, 1989, J MEM LANG, V28, P127, DOI 10.1016/0749-596X(89)90040-5
   Tye-Murray N, 2007, J AM ACAD AUDIOL, V18, P883, DOI 10.3766/jaaa.18.10.7
   Tye-Murray N, 2016, PSYCHOL AGING, V31, P380, DOI 10.1037/pag0000094
   TYLER RS, 1982, J ACOUST SOC AM, V72, P740, DOI 10.1121/1.388254
   Unsworth N, 2005, BEHAV RES METHODS, V37, P498, DOI 10.3758/BF03192720
   Van Engen KJ, 2017, ATTEN PERCEPT PSYCHO, V79, P396, DOI 10.3758/s13414-016-1238-9
   Van Engen KJ, 2014, J SPEECH LANG HEAR R, V57, P1908, DOI 10.1044/JSLHR-H-13-0076
   Van Hedger SC, 2015, COGNITION, V140, P95, DOI 10.1016/j.cognition.2015.03.012
   Woods KJP, 2017, ATTEN PERCEPT PSYCHO, V79, P2064, DOI 10.3758/s13414-017-1361-2
NR 109
TC 5
Z9 5
U1 1
U2 3
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD NOV 12
PY 2018
VL 13
IS 11
AR e0207160
DI 10.1371/journal.pone.0207160
PG 20
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA HA0PF
UT WOS:000449909200052
PM 30418995
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Shi, Y
   Peng, KA
   Chen, B
   Gong, Y
   Chen, JY
   Li, YX
   Fu, QJ
AF Shi, Ying
   Peng, Kevin A.
   Chen, Biao
   Gong, Yue
   Chen, Jingyuan
   Li, Yongxin
   Fu, Qian-Jie
TI Interaction between speech variations and background noise on speech
   intelligibility by Mandarin-speaking cochlear implant patients
SO SPEECH COMMUNICATION
LA English
DT Article
DE Cochlear implant; Speech variations; Speaking rate; Speaking styles
ID CLEAR SPEECH; PERCEPTION; VALIDATION; DURATION; HEARING; EMOTION
AB Cochlear implant (CI) users have been shown to be more susceptible to the variations in speech production encountered in everyday listening, in which speaking rate, amplitude, duration, and voice pitch information may be quite variable, depending on the production context. Such variations may be further enlarged by the background noise, especially dynamic noise. The limited spectral resolution provided by the CI limits perception of voice pitch, which is an important cue for speech prosody and for tonal languages such as Mandarin Chinese. In this study, the effect of varying speaking rates and styles and background noise on speech understanding was investigated in Mandarin-speaking CI and normal-hearing (NH) listeners. Thirteen (5 male and 8 female, age 19-62 years) Mandarin-speaking, post-lingually deafened adult CI patients using their clinical processors and 9 (5 male and 4 female, age 23-59 years) NH subjects listening to unprocessed speech. Five different types of speech variations, including 3 speaking rates (slow, normal, fast) and 2 speaking styles (emotional, shouted) were presented with two masking noises (speech-shaped steady state noise-SSN or six-talker babble). Speech reception threshold, defined as the signal-to-noise ratio producing 50% correct word-in-sentence recognition using Mandarin Speech Perception materials was measured. NH listeners performed significantly better (16.7 dB) than CI patients across all conditions regardless of speech variations and noise types. CI patients' performance deficit was highly dependent on speech rate and noise type; the deficit was smallest (11.7 dB) when slowly spoken speech was presented in SSN and largest (20.6 dB) when shouted speech was presented in six-talker speech babble. NH listeners performed significantly better in speech babble than in SSN for all speech variations, while CI patients performed similarly in both noise types. The use of clear and slowly-spoken speech in the laboratory setting may largely underestimate CI patients' performance deficits in real-world listening conditions, where acoustic variations introduced by speech variations and dynamic noise may present additional challenges.
C1 [Shi, Ying; Chen, Biao; Gong, Yue; Chen, Jingyuan; Li, Yongxin] Capital Med Univ, Beijing TongRen Hosp, Dept Otolaryngol Head & Neck Surg, Minist Educ China, Beijing, Peoples R China.
   [Peng, Kevin A.] House Clin, Los Angeles, CA 90057 USA.
   [Peng, Kevin A.; Fu, Qian-Jie] Univ Calif Los Angeles, David Geffen Sch Med, Dept Head & Neck Surg, Los Angeles, CA 90095 USA.
RP Li, YX (corresponding author), Capital Med Univ, Beijing TongRen Hosp, Dept Otolaryngol Head & Neck Surg, Minist Educ China, Beijing, Peoples R China.
EM entlyx@sina.com
OI Fu, Qian-Jie/0000-0003-3494-7633
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01-004792]; National
   Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [81670923]; China Scholarship CouncilChina Scholarship
   Council [201708110198]
FX The authors thank all the subjects who participated in this study. This
   work was partly supported by the National Institutes of Health [grant
   no. R01-004792]; the National Natural Science Foundation of China [grant
   no.81670923]; and the China Scholarship Council [no. 201708110198].
CR Banse R, 1996, J PERS SOC PSYCHOL, V70, P614, DOI 10.1037/0022-3514.70.3.614
   CRYSTAL TH, 1988, J SPEECH HEAR RES, V31, P497, DOI 10.1044/jshr.3103.497
   Ellis A. W., 1987, PROGR PSYCHOL LANGUA, V3, P119
   ESKENAZI M, 1993, P EUROSPEECH 93 BERL, P501
   Eskridge EN, 2012, J SPEECH LANG HEAR R, V55, P800, DOI 10.1044/1092-4388(2011/11-0124)
   Fu QJ, 2011, J ACOUST SOC AM, V129, pEL267, DOI 10.1121/1.3590739
   KOHLER KJ, 1986, LANG SPEECH, V29, P115, DOI 10.1177/002383098602900202
   Krause JC, 2002, J ACOUST SOC AM, V112, P2165, DOI 10.1121/1.1509432
   Lass N J, 1970, J Speech Hear Res, V13, P777
   Li YX, 2011, J ACOUST SOC AM, V129, pEL242, DOI 10.1121/1.3582148
   LISKER L, 1957, LANGUAGE, V33, P42, DOI 10.2307/410949
   Liu S, 2004, J ACOUST SOC AM, V116, P2374, DOI 10.1121/1.1787528
   Lombard  E., 1911, ANN MALADIES OREILLE, V37, P101
   MILLER JL, 1983, J ACOUST SOC AM, V73, P1751, DOI 10.1121/1.389399
   MURRAY IR, 1993, J ACOUST SOC AM, V93, P1097, DOI 10.1121/1.405558
   Newman RS, 1996, PERCEPT PSYCHOPHYS, V58, P540, DOI 10.3758/BF03213089
   PICHENY MA, 1989, J SPEECH HEAR RES, V32, P600, DOI 10.1044/jshr.3203.600
   PICKETT JM, 1956, J ACOUST SOC AM, V28, P902, DOI 10.1121/1.1908510
   Raitio T., 2013, ANAL SYNTHESIS SHOUT
   ROSTOLLAND D, 1985, ACUSTICA, V57, P103
   Shi Y, 2018, J ACOUST SOC AM, V143, P2886, DOI 10.1121/1.5037590
   Spahr AJ, 2012, EAR HEARING, V33, P112, DOI 10.1097/AUD.0b013e31822c2549
   Uchanski RM, 1996, J SPEECH HEAR RES, V39, P494, DOI 10.1044/jshr.3903.494
   Xin Luo, 2007, Trends Amplif, V11, P301
   Yildirim S., 2004, 8 INT C SPOK LANG PR, P2193
NR 25
TC 1
Z9 1
U1 1
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0167-6393
EI 1872-7182
J9 SPEECH COMMUN
JI Speech Commun.
PD NOV
PY 2018
VL 104
BP 89
EP 94
DI 10.1016/j.specom.2018.09.007
PG 6
WC Acoustics; Computer Science, Interdisciplinary Applications
SC Acoustics; Computer Science
GA HH0PE
UT WOS:000455419500009
DA 2021-02-24
ER

PT J
AU Kokabi, O
   Brinkmann, F
   Weinzierl, S
AF Kokabi, Omid
   Brinkmann, Fabian
   Weinzierl, Stefan
TI Segmentation of binaural room impulse responses for speech
   intelligibility prediction
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID PERCEPTUAL COMPENSATION; SPATIAL UNMASKING; REVERBERATION; NOISE;
   REFLECTIONS
AB The two most important aspects in binaural speech perception-better-ear-listening and spatialrelease- from-masking-can be predicted well with current binaural modeling frameworks operating on head-related impulse responses, i. e., anechoic binaural signals. To incorporate effects of reverberation, a model extension was proposed, splitting binaural room impulse responses into an early, useful, and late, detrimental part, before being fed into the modeling framework. More recently, an interaction between the applied splitting time, room properties, and the resulting prediction accuracy was observed. This interaction was investigated here by measuring speech reception thresholds (SRTs) in quiet with 18 normal-hearing subjects for four simulated rooms with different reverberation times and a constant room geometry. The mean error with one of the most promising binaural prediction models could be reduced by about 1 dB by adapting the applied splitting time to room acoustic parameters. This improvement in prediction accuracy can make up a difference of 17% in absolute intelligibility within the applied SRT measurement paradigm. (C) 2018 Acoustical Society of America.
C1 [Kokabi, Omid; Brinkmann, Fabian; Weinzierl, Stefan] TU Berlin, Audio Commun Grp, Einsteinufer 17c, D-10587 Berlin, Germany.
RP Kokabi, O (corresponding author), TU Berlin, Audio Commun Grp, Einsteinufer 17c, D-10587 Berlin, Germany.
EM kokabi@tu-berlin.de
OI Brinkmann, Fabian/0000-0003-1905-1361
CR American National Standards Institute, 1997, METHODS CALCULATION
   [Anonymous], 2017, 606451 IEC
   [Anonymous], 2010, 82531 ISO
   Beeston A. V., 2015, THESIS
   Beeston AV, 2014, J ACOUST SOC AM, V136, P3072, DOI 10.1121/1.4900596
   Beutelmann R, 2006, J ACOUST SOC AM, V120, P331, DOI 10.1121/1.2202888
   Beutelmann R, 2010, J ACOUST SOC AM, V127, P2479, DOI 10.1121/1.3295575
   Bradley JS, 2003, J ACOUST SOC AM, V113, P3233, DOI 10.1121/1.1570439
   BRADLEY JS, 1986, J ACOUST SOC AM, V80, P837, DOI 10.1121/1.393907
   Brinkmann F., 2017, FABIAN HEAD RELATED
   Brinkmann F, 2017, J AUDIO ENG SOC, V65, P841, DOI 10.17743/jaes.2017.0033
   Culling J. F., 2013, TECHNOLOGY BINAURAL, P427
   Dietrich P., 2010, FORTSCHRITTE AKUSTIK, P517
   DURLACH NI, 1963, J ACOUST SOC AM, V35, P1206, DOI 10.1121/1.1918675
   Edmonds BA, 2006, J ACOUST SOC AM, V120, P1539, DOI 10.1121/1.2228573
   Ellis G. M., 2015, P MTGS ACOUST, V23
   GELFAND SA, 1976, AUDIOLOGY, V15, P72
   ISO, 2009, 33821 ISO
   Jelfs S, 2011, HEARING RES, V275, P96, DOI 10.1016/j.heares.2010.12.005
   KOCK WE, 1950, J ACOUST SOC AM, V22, P801, DOI 10.1121/1.1906692
   Kokabi O., 2018, ASSESSMENT SPEECH PE
   Kuhnel V., 1999, Z AUDIOL, V38, P4
   Lavandier M, 2010, J ACOUST SOC AM, V127, P387, DOI 10.1121/1.3268612
   Leclere T, 2015, J ACOUST SOC AM, V137, P3335, DOI 10.1121/1.4921028
   LOCHNER JPA, 1964, J SOUND VIB, V1, P426, DOI 10.1016/0022-460X(64)90057-4
   Middlebrooks J. C., 2017, AUDITORY SYSTEM COCK
   MONCUR JP, 1967, J SPEECH HEAR RES, V10, P186, DOI 10.1044/jshr.1002.186
   NABELEK AK, 1982, J ACOUST SOC AM, V71, P1242
   Paquier M., 2012, P AC 2012 C NANT FRA, P3925
   Paquier M, 2015, APPL ACOUST, V93, P130, DOI 10.1016/j.apacoust.2015.01.023
   Rennies J, 2014, J ACOUST SOC AM, V135, P1556, DOI 10.1121/1.4863197
   Rennies J, 2011, J ACOUST SOC AM, V130, P2999, DOI 10.1121/1.3641368
   Schroder D., 2011, FORUM ACUSTICUM
   Sondergaard PL, 2013, TECHNOLOGY BINAURAL, P33, DOI DOI 10.1007/978-3-642-37762-4_2
   Wagener K., 1999, Z FR AUDIOLOGIE AUDI, V38, P8695
   Wagener K, 1999, Z AUDIOL, V38, P44
   Watkins AJ, 2005, ACTA ACUST UNITED AC, V91, P892
   Watkins AJ, 2005, J ACOUST SOC AM, V118, P249, DOI 10.1121/1.1923369
   Zahorik P, 2002, J ACOUST SOC AM, V112, P2110, DOI 10.1121/1.1506692
   Zahorik P, 2016, J ACOUST SOC AM, V140, P74, DOI 10.1121/1.4954723
NR 40
TC 2
Z9 2
U1 0
U2 4
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD NOV
PY 2018
VL 144
IS 5
BP 2793
EP 2800
DI 10.1121/1.5078598
PG 8
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA HF2YJ
UT WOS:000454102300033
PM 30522312
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Lee, H
AF Lee, Hyunjung
TI Age-related perceptual difference of Kyungsang Korean accent contrast: A
   diachronic observation
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID SEOUL
AB This study investigated the perception of lexical pitch accent contrasts between innovative and conservative listeners under a sound change. Younger and older listeners speaking Kyungsang Korean participated in the 2AFC identification task. The participants responded to stimuli systematically varying spectral and temporal F0 properties (i.e., peak duration, onset/peak F0 values) and talker voices (i.e., older vs younger talker). Results showed that younger listeners utilized the temporal cue differently from older listeners, and listeners' perception also varied by talker age. Discussion was made in terms of consistency between the perception and production and the effect of social information in speech perception. (C) 2018 Acoustical Society of America
C1 [Lee, Hyunjung] Incheon Natl Univ, Michuhol Campus,12 Gaetbeol Ro, Incheon 21999, South Korea.
RP Lee, H (corresponding author), Incheon Natl Univ, Michuhol Campus,12 Gaetbeol Ro, Incheon 21999, South Korea.
EM hyunjunglee123@gmail.com
CR Arvaniti A, 1998, J PHONETICS, V26, P3, DOI 10.1006/jpho.1997.0063
   Baayen R.H., 2008, ANAL LINGUISTIC DATA
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Beddor PS, 2009, LANGUAGE, V85, P785
   Boersma P, 2015, PRAAT DOING PHONETIC
   Chang S. C., 2007, THESIS
   Chang SE, 2013, LANG SPEECH, V56, P211, DOI 10.1177/0023830912443951
   Clopper CG, 2017, PHONETICA, V74, P25, DOI 10.1159/000446809
   Do Y, 2014, LINGUA, V148, P147, DOI 10.1016/j.lingua.2014.05.006
   Hyunjung Lee, 2017, [Phonetics and Speech Sciences, 말소리와 음성과학], V9, P53, DOI 10.13064/KSSS.2017.9.2.053
   Ito C., 2017, OXFORD RES ENCY LING
   Kenstowicz Michael, 2006, [Studies in Phonetics, Phonology, and Morphology, 음성음운형태론연구], V12, P247
   Kong EJ, 2018, LANG SPEECH, V61, P384, DOI 10.1177/0023830917729840
   Koops C, 2008, U PENNSYLVANIA WORKI, V14, P12
   Lee Hyun Su, 2008, THESIS
   Lee H, 2016, J INT PHON ASSOC, V46, P157, DOI 10.1017/S0025100316000013
   Lee H, 2015, J PHONETICS, V50, P15, DOI 10.1016/j.wocn.2015.01.003
   R Core Team, 2015, R LANG ENV STAT COMP
   Warren P., 2007, LAB PHONOL, V9, P87
NR 19
TC 0
Z9 0
U1 0
U2 0
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD NOV
PY 2018
VL 144
IS 5
BP EL367
EP EL373
DI 10.1121/1.5066344
PG 7
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA HF2YJ
UT WOS:000454102300002
PM 30522281
OA Bronze
DA 2021-02-24
ER

PT J
AU Mehta, AH
   Oxenham, AJ
AF Mehta, Anahita H.
   Oxenham, Andrew J.
TI Fundamental-frequency discrimination based on temporal-envelope cues:
   Effects of bandwidth and interference
SO JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA
LA English
DT Article
ID PITCH PERCEPTION; TONES
AB Both music and speech perception rely on hearing out one pitch in the presence of others. Pitch discrimination of narrowband sounds based only on temporal-envelope cues is rendered nearly impossible by introducing interferers in both normal-hearing listeners and cochlear-implant (CI) users. This study tested whether performance improves in normal-hearing listeners if the target is presented over a broad spectral region. The results indicate that performance is still strongly affected by spectrally remote interferers, despite increases in bandwidth, suggesting that envelope-based pitch is unlikely to allow CI users to perceive pitch when multiple harmonic sounds are presented at once. (C) 2018 Acoustical Society of America
C1 [Mehta, Anahita H.; Oxenham, Andrew J.] Univ Minnesota, Dept Psychol, 75 East River Pkwy, Minneapolis, MN 55455 USA.
RP Mehta, AH (corresponding author), Univ Minnesota, Dept Psychol, 75 East River Pkwy, Minneapolis, MN 55455 USA.
EM mehta@umn.edu; oxenham@umn.edu
OI Oxenham, Andrew/0000-0002-9365-1157
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R01DC005216]; NATIONAL INSTITUTE ON
   DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC005216, R01DC005216, R01DC005216, R01DC005216, R01DC005216,
   R01DC005216, R01DC005216, R01DC005216, R01DC005216, R01DC005216,
   R01DC005216, R01DC005216, R01DC005216, R01DC005216, R01DC005216,
   R01DC005216, R01DC005216, R01DC005216, R01DC005216] Funding Source: NIH
   RePORTER
FX This work was supported by NIH grant R01DC005216 (AJO).
CR Bernstein JG, 2003, J ACOUST SOC AM, V113, P3323, DOI 10.1121/1.1572146
   Busby PA, 1997, J ACOUST SOC AM, V101, P1687, DOI 10.1121/1.418178
   Carlyon RP, 2007, JARO-J ASSOC RES OTO, V8, P119, DOI 10.1007/s10162-006-0068-1
   Carlyon RP, 1996, J ACOUST SOC AM, V99, P517, DOI 10.1121/1.414510
   Carlyon RP, 1996, J ACOUST SOC AM, V99, P525, DOI 10.1121/1.414511
   Deeks JM, 2013, J ACOUST SOC AM, V133, P377, DOI 10.1121/1.4770254
   Gockel H, 1999, J ACOUST SOC AM, V106, P3553, DOI 10.1121/1.428208
   Gockel H, 2004, J ACOUST SOC AM, V116, P1092, DOI 10.1121/1.1766021
   HOUTSMA AJM, 1990, J ACOUST SOC AM, V87, P304, DOI 10.1121/1.399297
   Kaernbach C, 2001, J ACOUST SOC AM, V110, P1039, DOI 10.1121/1.1381535
   Kong YY, 2009, J ACOUST SOC AM, V125, P1649, DOI 10.1121/1.3068457
   Kreft HA, 2013, JARO-J ASSOC RES OTO, V14, P591, DOI 10.1007/s10162-013-0391-2
   Lau BK, 2017, J NEUROSCI, V37, P9013, DOI 10.1523/JNEUROSCI.1507-17.2017
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   McDermott Hugh J, 2004, Trends Amplif, V8, P49, DOI 10.1177/108471380400800203
   Micheyl C, 2006, HEARING RES, V219, P36, DOI 10.1016/j.heares.2006.05.004
   Moore BCJ, 2000, BRIT J AUDIOL, V34, P205, DOI 10.3109/03005364000000131
   Oxenham AJ, 2018, ANNU REV PSYCHOL, V69, P27, DOI 10.1146/annurev-psych-122216-011635
   Ruggles DR, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086980
   SHACKLETON TM, 1994, J ACOUST SOC AM, V95, P3529, DOI 10.1121/1.409970
   vandePar S, 1997, J ACOUST SOC AM, V101, P1671, DOI 10.1121/1.418151
   Wang J, 2012, J ACOUST SOC AM, V132, P339, DOI 10.1121/1.4728165
NR 22
TC 1
Z9 1
U1 0
U2 0
PU ACOUSTICAL SOC AMER AMER INST PHYSICS
PI MELVILLE
PA STE 1 NO 1, 2 HUNTINGTON QUADRANGLE, MELVILLE, NY 11747-4502 USA
SN 0001-4966
EI 1520-8524
J9 J ACOUST SOC AM
JI J. Acoust. Soc. Am.
PD NOV
PY 2018
VL 144
IS 5
BP EL423
EP EL428
DI 10.1121/1.5079569
PG 6
WC Acoustics; Audiology & Speech-Language Pathology
SC Acoustics; Audiology & Speech-Language Pathology
GA HF2YJ
UT WOS:000454102300011
PM 30522318
OA Bronze, Green Published
DA 2021-02-24
ER

PT J
AU Mayberry, RI
   Kluender, R
AF Mayberry, Rachel I.
   Kluender, Robert
TI Rethinking the critical period for language: New insights into an old
   question from American Sign Language
SO BILINGUALISM-LANGUAGE AND COGNITION
LA English
DT Article
DE critical period for language; first language acquisition; second
   language acquisition; sign language; neurolinguistic processing
ID WOLVES CANIS-LUPUS; 2ND-LANGUAGE ACQUISITION; 1ST-LANGUAGE ACQUISITION;
   MATURATIONAL CONSTRAINTS; FUNCTIONAL-ORGANIZATION; PHONOLOGICAL
   SIMILARITY; LINGUISTIC EXPERIENCE; SUBLEXICAL STRUCTURE; PHONETIC
   PERCEPTION; SPEECH-PERCEPTION
AB The hypothesis that children surpass adults in long-term second-language proficiency is accepted as evidence for a critical period for language. However, the scope and nature of a critical period for language has been the subject of considerable debate. The controversy centers on whether the age-related decline in ultimate second-language proficiency is evidence for a critical period or something else. Here we argue that age-onset effects for first vs. second language outcome are largely different. We show this by examining psycholinguistic studies of ultimate attainment in L2 vs. L1 learners, longitudinal studies of adolescent L1 acquisition, and neurolinguistic studies of late L2 and L1 learners. This research indicates that L1 acquisition arises from post-natal brain development interacting with environmental linguistic experience. By contrast, L2 learning after early childhood is scaffolded by prior childhood L1 acquisition, both linguistically and neurally, making it a less clear test of the critical period for language.
C1 [Mayberry, Rachel I.; Kluender, Robert] Univ Calif San Diego, Dept Linguist, 9500 Gillman Dr, La Jolla, CA 92093 USA.
RP Mayberry, RI (corresponding author), Univ Calif San Diego, Dept Linguist, 9500 Gillman Dr, La Jolla, CA 92093 USA.
EM rmayberry@ucsd.edu
FU NIHUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [R01DC012797]; Kavli Institute for
   Brain Mind at UCSD; Natural Science and Engineering Research Council of
   CanadaNatural Sciences and Engineering Research Council of Canada
   (NSERC); NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION
   DISORDERSUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R01DC012797, R01DC012797,
   R01DC012797, R01DC012797] Funding Source: NIH RePORTER
FX Preparation of this paper and the recent research reported here was
   supported by NIH grant R01DC012797 to RM. Some research was supported by
   a grant from the Kavli Institute for Brain & Mind at UCSD, and other
   research conducted at McGill University was supported by grants from the
   Natural Science and Engineering Research Council of Canada to RM. The
   content is solely the responsibility of the authors and does not
   necessarily represent the official views of the National Institutes of
   Health. The authors thank the many individuals who graciously
   volunteered for the studies described here, and Marla Hatrak, Deniz
   Ilkbasaran, Drucilla Ronchen, and Pamela Witcher for invaluable research
   assistance.
CR Abrahamsson N, 2009, LANG LEARN, V59, P249, DOI 10.1111/j.1467-9922.2009.00507.x
   Ambridge B., 2011, CHILD LANGUAGE ACQUI
   Anderson D., 2002, J DEAF STUD DEAF EDU, V7, P83, DOI DOI 10.1093/DEAFED/7.2.83
   Bates E, 1997, LANG COGNITIVE PROC, V12, P507
   BATES E, 1994, J CHILD LANG, V21, P85, DOI 10.1017/S0305000900008680
   Berk S, 2012, COGNITIVE PSYCHOL, V65, P118, DOI 10.1016/j.cogpsych.2012.02.002
   Berl MM, 2014, HUM BRAIN MAPP, V35, P270, DOI 10.1002/hbm.22179
   Best CT, 2010, ATTEN PERCEPT PSYCHO, V72, P747, DOI 10.3758/APP.72.3.747
   Birdsong D, 2001, J MEM LANG, V44, P235, DOI 10.1006/jmla.2000.2750
   BIRDSONG D, 2003, ACQUISITION INTERACT, V18, P17
   Bongaerts T, 2000, STUD LINGUISTICA, V54, P298, DOI 10.1111/1467-9582.00069
   Bongaerts T., 1997, STUDIES 2 LANGUAGE A, V19, P447, DOI DOI 10.1017/S0272263197004026
   Boudreault P, 2006, LANG COGNITIVE PROC, V21, P608, DOI 10.1080/01690960500139363
   Brentari Diane, 1998, PROSODIC MODEL SIGN
   Brown TT, 2005, CEREB CORTEX, V15, P275, DOI 10.1093/cercor/bhh129
   Cardin V, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2463
   Carreiras M, 2008, J MEM LANG, V58, P100, DOI 10.1016/j.jml.2007.05.004
   Carrigan EM, 2017, COGNITION, V158, P10, DOI 10.1016/j.cognition.2016.09.012
   Chen Pichler D., 2012, HDB LINGUISTICS COMM, P647
   Chen Q., ADOLESCENT 1 LANGUAG
   Chen Q., LANGUAGE PATHWAYS DE
   CHERRY EC, 1954, J ACOUST SOC AM, V26, P554, DOI 10.1121/1.1907373
   CHOMSKY N, 1959, LANGUAGE, V35, P26, DOI 10.2307/411334
   Chomsky Noam, 1965, ASPECTS THEORY SYNTA, V11
   Colantoni L, 2006, SEL P 7 C ACQ SPAN P, P59
   COPPIETERS R, 1987, LANGUAGE, V63, P544, DOI 10.2307/415005
   Corina DP, 1999, NEUROIMAGE, V10, P570, DOI 10.1006/nimg.1999.0499
   Cormier K, 2012, COGNITION, V124, P50, DOI 10.1016/j.cognition.2012.04.003
   Curtiss Susan, 1977, GENIE PSYCHOL STUDY
   Davidson K, 2014, J DEAF STUD DEAF EDU, V19, P238, DOI 10.1093/deafed/ent045
   Decety J, 1999, TRENDS COGN SCI, V3, P172, DOI 10.1016/S1364-6613(99)01312-1
   Dehaene S, 1997, NEUROREPORT, V8, P3809, DOI 10.1097/00001756-199712010-00030
   DeKeyser R, 2010, APPL PSYCHOLINGUIST, V31, P413, DOI 10.1017/S0142716410000056
   Dickinson D. K., 2001, LEARNING DISABILITIE, V16, DOI [DOI 10.1111/0938-8982.00019, 10.1111/0938-8982.00019]
   Diessel H., 2004, ACQUISITION COMPLEX
   Dye M. W. G., 2006, LAB PHONOLOGY, V8, P241, DOI DOI 10.1515/9783110197211.1.241
   EMMOREY K, 1995, APPL PSYCHOLINGUIST, V16, P1, DOI 10.1017/S0142716400006391
   Fenson Larry, 1994, Monographs of the Society for Research in Child Development, V59, P1
   Flege JE, 1999, J MEM LANG, V41, P78, DOI 10.1006/jmla.1999.2638
   Flege JE, 2003, SPEECH COMMUN, V40, P467, DOI 10.1016/S0167-6393(02)00128-0
   FROMKIN V, 1974, BRAIN LANG, V1, P81, DOI 10.1016/0093-934X(74)90027-3
   FUJINAGA T, 1990, GENET SOC GEN PSYCH, V116, P39
   Goldin-Meadow S., 2005, RESILIENCE LANGUAGE
   GOLDINMEADOW S, 1983, SCIENCE, V221, P372, DOI 10.1126/science.6867713
   Granena G, 2013, SECOND LANG RES, V29, P311, DOI 10.1177/0267658312461497
   GREENOUGH WT, 1987, CHILD DEV, V58, P539, DOI 10.2307/1130197
   Grimshaw GM, 1998, BRAIN LANG, V63, P237, DOI 10.1006/brln.1997.1943
   Hakuta K, 2003, PSYCHOL SCI, V14, P31, DOI 10.1111/1467-9280.01415
   Hall ML, 2012, SIGN LANG LINGUIST, V15, P104, DOI 10.1075/sll.15.1.05hal
   Hare B, 2002, SCIENCE, V298, P1634, DOI 10.1126/science.1072702
   Hart B., 1995, MEAINGFUL DIFFERENCE
   Hassanzadeh S, 2012, J LARYNGOL OTOL, V126, P989, DOI 10.1017/S0022215112001909
   Hebb D. O., 1949, ORG BEHAV NEUROPSYCH
   Hensch TK, 2005, NAT REV NEUROSCI, V6, P877, DOI 10.1038/nrn1787
   Hickok G, 2002, BRAIN LANG, V82, P167, DOI 10.1016/S0093-934X(02)00013-5
   Hildebrandt U, 2002, LANG COGNITIVE PROC, V17, P593, DOI 10.1080/01690960143000371
   Hoff E, 2003, CHILD DEV, V74, P1368, DOI 10.1111/1467-8624.00612
   Huttenlocher J, 2002, COGNITIVE PSYCHOL, V45, P337, DOI 10.1016/S0010-0285(02)00500-5
   HUTTENLOCHER PR, 1990, NEUROPSYCHOLOGIA, V28, P517, DOI 10.1016/0028-3932(90)90031-I
   Indefrey P, 2006, LANG LEARN, V56, P279, DOI 10.1111/j.1467-9922.2006.00365.x
   Ioup G, 1995, AGE FACTOR IN SECOND LANGUAGE ACQUISITION, P95
   Ioup G., 1994, STUDIES 2 LANGUAGE A, V16, P73, DOI DOI 10.1017/S0272263100012596
   Ishibashi T, 2006, NEURON, V49, P823, DOI 10.1016/j.neuron.2006.02.006
   Itard J.-M. G., 1962, RAPPORTS MEMOIRES SA
   Jackendoff R, 2011, LANGUAGE, V87, P586
   JOHNSON JS, 1989, COGNITIVE PSYCHOL, V21, P60, DOI 10.1016/0010-0285(89)90003-0
   KOLUCHOV.J, 1972, J CHILD PSYCHOL PSYC, V13, P107, DOI 10.1111/j.1469-7610.1972.tb01124.x
   KUHL PK, 1992, SCIENCE, V255, P606, DOI 10.1126/science.1736364
   Lenneberg E. H., 1967, BIOL FDN LANGUAGE
   Leonard MK, 2012, J NEUROSCI, V32, P9700, DOI 10.1523/JNEUROSCI.1002-12.2012
   Leonard MK, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018240
   Lieberman AM, 2016, J EXP PSYCHOL LEARN, V42, P2002, DOI 10.1037/xlm0000309
   Lieberman AM, 2015, J EXP PSYCHOL LEARN, V41, P1130, DOI 10.1037/xlm0000088
   Lillo-Martin D, 2011, THEOR LINGUIST, V37, P95, DOI 10.1515/THLI.2011.009
   Lord K, 2013, ETHOLOGY, V119, P110, DOI 10.1111/eth.12044
   Lorenz K., 1965, EVOLUTION MODIFICATI
   MacSweeney M, 2006, HUM BRAIN MAPP, V27, P63, DOI 10.1002/hbm.20167
   Makinodan M, 2012, SCIENCE, V337, P1357, DOI 10.1126/science.1220845
   Marler P, 1989, ASHA, V31, P75
   Mayberry R. I., 2006, ENCY LANGUAGE LINGUI, P11
   Mayberry R. I, 2017, INT ASS CHILD LANG L
   Mayberry RI, 2011, BRAIN LANG, V119, P16, DOI 10.1016/j.bandl.2011.05.007
   Mayberry RI, 2003, BRAIN LANG, V87, P369, DOI 10.1016/S0093-934X(03)00137-8
   Mayberry RI, 2002, NATURE, V417, P38, DOI 10.1038/417038a
   MAYBERRY RI, 1993, J SPEECH HEAR RES, V36, P1258, DOI 10.1044/jshr.3606.1258
   MAYBERRY RI, 1989, MEM COGNITION, V17, P740, DOI 10.3758/BF03202635
   MAYBERRY RI, 1991, J MEM LANG, V30, P486, DOI 10.1016/0749-596X(91)90018-F
   Mayberry RI, NEUROLINGUISTIC PROC
   Meisel Jurgen, 2013, CAMBRIDGE HDB BIOLIN, P69, DOI [10.1017/CBO9780511980435.007, DOI 10.1017/CBO9780511980435]
   Mitchell Ross, 2004, SIGN LANGUAGE STUDIE, V4, P138, DOI DOI 10.1353/SLS.2004.0005
   MOON C, 1993, INFANT BEHAV DEV, V16, P495, DOI 10.1016/0163-6383(93)80007-U
   Morford JP, 2011, LANG LEARN DEV, V7, P149, DOI 10.1080/15475441.2011.543393
   Morford JP, 2003, LINGUISTICS, V41, P681, DOI 10.1515/ling.2003.022
   Morgan HE, 2012, SIGN LANG LINGUIST, V15, P147, DOI 10.1075/sll.15.1.07mor
   Moyer A., 1999, STUD SECOND LANG ACQ, V21, DOI [DOI 10.1017/S0272263199001035, https://doi.org/10.1017/S0272263199001035]
   Newman AJ, 2015, P NATL ACAD SCI USA, V112, P11684, DOI 10.1073/pnas.1510527112
   NEWPORT EL, 1990, COGNITIVE SCI, V14, P11, DOI 10.1016/0364-0213(90)90024-Q
   Norrman G, 2016, DEVELOPMENTAL SCI, V19, P513, DOI 10.1111/desc.12332
   Orfanidou E, 2010, J MEM LANG, V62, P272, DOI 10.1016/j.jml.2009.12.001
   Palmen M.-J., 1997, ACQUISITION INTERACT, V9, P173
   PERLMUTTER DM, 1992, LINGUIST INQ, V23, P407
   Petitto LA, 2000, P NATL ACAD SCI USA, V97, P13961, DOI 10.1073/pnas.97.25.13961
   Petitto LA, 2004, COGNITION, V93, P43, DOI 10.1016/j.cognition.2003.10.007
   Pierce LJ, 2017, APPL PSYCHOLINGUIST, V38, P1265, DOI 10.1017/S0142716417000236
   POIZNER H, 1981, SCIENCE, V212, P691, DOI 10.1126/science.212.4495.691
   Poizner H., 1987, WHAT HANDS REVEAL BR
   Pujol J, 2006, NEUROLOGY, V66, P339, DOI 10.1212/01.wnl.0000201049.66073.8d
   Ramirez NF, 2016, CEREB CORTEX, V26, P1015, DOI 10.1093/cercor/bhu273
   Ramirez NF, 2014, CEREB CORTEX, V24, P2772, DOI 10.1093/cercor/bht137
   Ramirez NF, 2013, J CHILD LANG, V40, P391, DOI 10.1017/S0305000911000535
   Reilly J., 2006, ADV SIGN LANGUAGE DE, P262
   Ressel V, 2008, BRAIN LANG, V106, P167, DOI 10.1016/j.bandl.2008.01.004
   Sakai KL, 2005, BRAIN, V128, P1407, DOI 10.1093/brain/awh465
   Sandler W, 2006, SIGN LANGUAGE AND LINGUISTIC UNIVERSALS, P1, DOI 10.2277/ 0521483956
   Schlaggar BL, 2002, SCIENCE, V296, P1476, DOI 10.1126/science.1069464
   Scovel T., 1988, TIME SPEAK PSYCHOLIN
   Seidenberg MS, 2006, ATTENTION PERFORM, P585
   Skeide MA, 2016, CEREB CORTEX, V26, P2127, DOI 10.1093/cercor/bhv042
   Skinner B. F., 1957, VERBAL BEHAV
   Trut LN, 1999, AM SCI, V87, P160, DOI 10.1511/1999.2.160
   Valli C., 1992, ASL PAH DEAF STUDENT
   Vannasing P, 2016, NEUROPSYCHOLOGIA, V84, P63, DOI 10.1016/j.neuropsychologia.2016.01.038
   VarghaKhadem F, 1997, BRAIN, V120, P159, DOI 10.1093/brain/120.1.159
   Viranyi Z, 2008, ANIM COGN, V11, P373, DOI 10.1007/s10071-007-0127-y
   Wartenburger I, 2003, NEURON, V37, P159, DOI 10.1016/S0896-6273(02)01150-9
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Werker JF, 2005, DEV PSYCHOBIOL, V46, P233, DOI 10.1002/dev.20060
   Wexler K., 1980, FORMAL PRINCIPLES LA
   WHITE L, 1996, 2 LANGUAGE RES, V0012
   WIESEL TN, 1982, NATURE, V299, P583, DOI 10.1038/299583a0
   Wilbur R. B., 2011, BLACKWELL COMPANION, P1, DOI [10.1002/9781444335262, DOI 10.1002/9781444335262]
   WILSON WM, 1973, NATURE, V244, P522, DOI 10.1038/244522a0
NR 132
TC 36
Z9 36
U1 5
U2 35
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 1366-7289
EI 1469-1841
J9 BILING-LANG COGN
JI Biling.-Lang. Cogn.
PD NOV
PY 2018
VL 21
IS 5
BP 886
EP 905
DI 10.1017/S1366728917000724
PG 20
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA GY1NA
UT WOS:000448296400002
PM 30643489
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Prevost, F
   Lehmann, A
AF Prevost, Francois
   Lehmann, Alexandre
TI Saliency of Vowel Features in Neural Responses of Cochlear Implant Users
SO CLINICAL EEG AND NEUROSCIENCE
LA English
DT Article
DE cochlear implant; speech perception; evoked potentials; mismatch
   negativity; fundamental frequency; formant; vowel
ID MISMATCH NEGATIVITY MMN; AUDITORY-EVOKED POTENTIALS; INDEPENDENT
   COMPONENT ANALYSIS; SCHOOL-AGE-CHILDREN; IN-NOISE PERCEPTION;
   SPEECH-PERCEPTION; SOUND DISCRIMINATION; MUSIC PERCEPTION; ELECTRIC
   HEARING; TEMPORAL CUES
AB Cochlear implants restore hearing in deaf individuals, but speech perception remains challenging. Poor discrimination of spectral components is thought to account for limitations of speech recognition in cochlear implant users. We investigated how combined variations of spectral components along two orthogonal dimensions can maximize neural discrimination between two vowels, as measured by mismatch negativity. Adult cochlear implant users and matched normal-hearing listeners underwent electroencephalographic event-related potentials recordings in an optimum-1 oddball paradigm. A standard /a/ vowel was delivered in an acoustic free field along with stimuli having a deviant fundamental frequency (+3 and +6 semitones), a deviant first formant making it a /i/ vowel or combined deviant fundamental frequency and first formant (+3 and +6 semitones /i/ vowels). Speech recognition was assessed with a word repetition task. An analysis of variance between both amplitude and latency of mismatch negativity elicited by each deviant vowel was performed. The strength of correlations between these parameters of mismatch negativity and speech recognition as well as participants' age was assessed. Amplitude of mismatch negativity was weaker in cochlear implant users but was maximized by variations of vowels' first formant. Latency of mismatch negativity was later in cochlear implant users and was particularly extended by variations of the fundamental frequency. Speech recognition correlated with parameters of mismatch negativity elicited by the specific variation of the first formant. This nonlinear effect of acoustic parameters on neural discrimination of vowels has implications for implant processor programming and aural rehabilitation.
C1 [Prevost, Francois] McGill Univ, Ctr Hlth, Dept Speech Pathol & Audiol, 1001 Blvd Decarie D04-7317, Montreal, PQ H4A 3J1, Canada.
   [Prevost, Francois; Lehmann, Alexandre] Int Lab Brain Mus & Sound Res, Montreal, PQ, Canada.
   [Lehmann, Alexandre] McGill Univ, Dept Otolaryngol Head & Neck Surg, Montreal, PQ, Canada.
   [Lehmann, Alexandre] Ctr Res Brain Language & Mus, Montreal, PQ, Canada.
RP Prevost, F (corresponding author), McGill Univ, Ctr Hlth, Dept Speech Pathol & Audiol, 1001 Blvd Decarie D04-7317, Montreal, PQ H4A 3J1, Canada.
EM francois.prevost@umontreal.ca
OI Prevost, Francois/0000-0001-7638-861X
FU Centre for Research on Brain, Music and Language via a Research
   Incubator Seed Funding Grant
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This study
   received financial support from the Centre for Research on Brain, Music
   and Language via a Research Incubator Seed Funding Grant.
CR Alain C, 2005, J COGNITIVE NEUROSCI, V17, P811, DOI 10.1162/0898929053747621
   Alain C, 2001, J EXP PSYCHOL HUMAN, V27, P1072, DOI 10.1037/0096-1523.27.5.1072
   Anderson S, 2010, TRENDS AMPLIF, V14, P73, DOI 10.1177/1084713810380227
   Anderson S, 2010, EUR J NEUROSCI, V32, P1407, DOI 10.1111/j.1460-9568.2010.07409.x
   Blamey P, 1996, Audiol Neurootol, V1, P293
   Blamey P, 2013, AUDIOL NEURO-OTOL, V18, P36, DOI 10.1159/000343189
   BROKX JPL, 1982, J PHONETICS, V10, P23, DOI 10.1016/S0095-4470(19)30909-X
   Cleary M, 2002, ANN OTO RHINOL LARYN, V111, P113
   Cone-Wesson Barbara, 2003, Curr Opin Otolaryngol Head Neck Surg, V11, P372, DOI 10.1097/00020840-200310000-00011
   Corina DP, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00059
   Debener S, 2008, PSYCHOPHYSIOLOGY, V45, P20, DOI 10.1111/j.1469-8986.2007.00610.x
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Deouell LY, 1998, PSYCHOPHYSIOLOGY, V35, P355, DOI 10.1017/S0048577298970287
   Drennan WR, 2008, J REHABIL RES DEV, V45, P779, DOI 10.1682/JRRD.2007.08.0118
   Erfania Saeedi N, 2016, HEARING RES, V344, P135
   Galvin JJ, 2007, EAR HEARING, V28, P302, DOI 10.1097/01.aud.0000261689.35445.20
   Getzmann S, 2011, BRAIN RES, V1415, P8, DOI 10.1016/j.brainres.2011.08.001
   Geurts L, 2001, J ACOUST SOC AM, V109, P713, DOI 10.1121/1.1340650
   Gfeller Kate E, 2006, Audiol Neurootol, V11 Suppl 1, P12, DOI 10.1159/000095608
   Gilley PM, 2008, BRAIN RES, V1239, P56, DOI 10.1016/j.brainres.2008.08.026
   Groenen PAP, 2001, SCAND AUDIOL, V30, P31, DOI 10.1080/010503901750069554
   Halgren E, 1998, ELECTROEN CLIN NEURO, V106, P156, DOI 10.1016/S0013-4694(97)00119-3
   Henkin Y, 2009, AUDIOL NEURO-OTOL, V14, P39, DOI 10.1159/000153434
   Hyde M, 1997, AUDIOL NEURO-OTOL, V2, P281, DOI 10.1159/000259253
   Ilvonen T, 2004, NEUROSCI LETT, V366, P235, DOI 10.1016/j.neulet.2004.05.024
   Jung TP, 2000, CLIN NEUROPHYSIOL, V111, P1745, DOI 10.1016/S1388-2457(00)00386-2
   Kelly AS, 2005, CLIN NEUROPHYSIOL, V116, P1235, DOI 10.1016/j.clinph.2005.02.011
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Koelsch S, 2004, CLIN NEUROPHYSIOL, V115, P966, DOI 10.1016/j.clinph.2003.11.032
   Kong YY, 2004, EAR HEARING, V25, P173, DOI 10.1097/01.AUD.0000120365.97792.2F
   Kraus N, 1999, J SPEECH LANG HEAR R, V42, P1042, DOI 10.1044/jslhr.4205.1042
   Krishnan A, 2005, COGNITIVE BRAIN RES, V25, P161, DOI 10.1016/j.cogbrainres.2005.05.004
   Kropotov JD, 2000, NEUROSCI LETT, V280, P87, DOI 10.1016/S0304-3940(00)00765-5
   Lazard DS, 2012, EUR ANN OTORHINOLARY, V129, P98, DOI 10.1016/j.anorl.2011.06.001
   Lazard DS, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms14872
   Lazard DS, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048739
   Lin JY, 1998, J ACOUST SOC AM, V103, P2608, DOI 10.1121/1.422781
   Lonka E, 2004, AUDIOL NEURO-OTOL, V9, P160, DOI 10.1159/000077265
   Lopez-Valdes A, 2013, IEEE ENG MED BIO, P3555, DOI 10.1109/EMBC.2013.6610310
   Luo X, 2010, J ACOUST SOC AM, V127, pEL23, DOI 10.1121/1.3280236
   Marklund E, 2014, NEUROREPORT, V25, P756, DOI 10.1097/WNR.0000000000000168
   Meddis R, 1997, J ACOUST SOC AM, V102, P1811, DOI 10.1121/1.420088
   Miller S, 2016, EAR HEARING, V37, P514, DOI 10.1097/AUD.0000000000000287
   MOORE BCJ, 1985, J ACOUST SOC AM, V77, P1861, DOI 10.1121/1.391937
   Moore DR, 2005, BRAIN LANG, V94, P72, DOI 10.1016/j.bandl.2004.11.009
   Naatanen R, 2007, CLIN NEUROPHYSIOL, V118, P2544, DOI 10.1016/j.clinph.2007.04.026
   Naatanen R, 2004, CLIN NEUROPHYSIOL, V115, P140, DOI 10.1016/j.clinph.2003.04.001
   NAATANEN R, 1993, PSYCHOPHYSIOLOGY, V30, P436, DOI 10.1111/j.1469-8986.1993.tb02067.x
   Naatanen R, 2000, INT J PSYCHOPHYSIOL, V37, P3, DOI 10.1016/S0167-8760(00)00091-X
   Olds C, 2016, EAR HEARING, V37, pE160, DOI 10.1097/AUD.0000000000000258
   Oxenham Andrew J, 2008, Trends Amplif, V12, P316, DOI 10.1177/1084713808325881
   Palmer A. R., 1998, PSYCHOPHYSICAL PHYSL, P263
   Parbery-Clark A, 2011, EUR J NEUROSCI, V33, P549, DOI 10.1111/j.1460-9568.2010.07546.x
   Petersen B, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00007
   Ponton CW, 2000, CLIN NEUROPHYSIOL, V111, P220, DOI 10.1016/S1388-2457(99)00236-9
   Ponton CW, 2000, AUDIOL NEURO-OTOL, V5, P167, DOI 10.1159/000013878
   Rahne T, 2014, BRAIN RES, V1586, P143, DOI 10.1016/j.brainres.2014.08.045
   Rahne T, 2010, THESCIENTIFICWORLDJO, V10, P329, DOI 10.1100/tsw.2010.28
   Sagi E, 2017, J ACOUST SOC AM, V141, P1027, DOI 10.1121/1.4976059
   Sagi E, 2010, J ACOUST SOC AM, V127, P1069, DOI 10.1121/1.3277215
   Sandmann P, 2010, CLIN NEUROPHYSIOL, V121, P2070, DOI 10.1016/j.clinph.2010.04.032
   Shafer VL, 2000, EAR HEARING, V21, P242, DOI 10.1097/00003446-200006000-00008
   Sharma A, 2005, HEARING RES, V203, P134, DOI 10.1016/j.heares.2004.12.010
   Shinn-Cunningham Barbara G, 2008, Trends Amplif, V12, P283, DOI 10.1177/1084713808325306
   Song JH, 2011, CLIN NEUROPHYSIOL, V122, P346, DOI 10.1016/j.clinph.2010.07.009
   Timm L, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00181
   Torppa R, 2012, CLIN NEUROPHYSIOL, V123, P1966, DOI 10.1016/j.clinph.2012.03.008
   Turgeon C, 2014, CLIN NEUROPHYSIOL, V125, P827, DOI 10.1016/j.clinph.2013.09.035
   Turgeon Christine, 2015, Cochlear Implants Int, V16, P88, DOI 10.1179/1754762814Y.0000000091
   Uhlen I, 2017, SCAND J PSYCHOL, V58, P409, DOI 10.1111/sjop.12391
   Viola FC, 2011, PSYCHOPHYSIOLOGY, V48, P1470, DOI 10.1111/j.1469-8986.2011.01224.x
   Viola FC, 2012, HEARING RES, V284, P6, DOI 10.1016/j.heares.2011.12.010
   Vongphoe M, 2005, J ACOUST SOC AM, V118, P1055, DOI 10.1121/1.1944507
   Werner S, 2010, CEREB CORTEX, V20, P1829, DOI 10.1093/cercor/bhp248
   Winn MB, 2015, J ACOUST SOC AM, V137, P1430, DOI 10.1121/1.4908308
   Won JH, 2016, J ACOUST SOC AM, V139, P1, DOI 10.1121/1.4931909
   Ylinen S, 2006, BRAIN RES, V1072, P175, DOI 10.1016/j.brainres.2005.12.004
   Zhang FW, 2013, AUDIOL NEURO-OTOL, V18, P275, DOI 10.1159/000351802
   Zhang FW, 2011, HEARING RES, V275, P17, DOI 10.1016/j.heares.2010.11.007
   Zhang FW, 2010, INT J AUDIOL, V49, P277, DOI 10.3109/14992020903321759
NR 80
TC 0
Z9 0
U1 0
U2 4
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1550-0594
EI 2169-5202
J9 CLIN EEG NEUROSCI
JI Clin. EEG Neurosci.
PD NOV
PY 2018
VL 49
IS 6
BP 388
EP 397
DI 10.1177/1550059418770051
PG 10
WC Clinical Neurology; Neurosciences; Neuroimaging; Psychiatry; Psychology
SC Neurosciences & Neurology; Psychiatry; Psychology
GA GV4VC
UT WOS:000446098200004
PM 29690785
DA 2021-02-24
ER

PT J
AU Altvater-Mackensen, N
   Grossmann, T
AF Altvater-Mackensen, Nicole
   Grossmann, Tobias
TI Modality-independent recruitment of inferior frontal cortex during
   speech processing in human infants
SO DEVELOPMENTAL COGNITIVE NEUROSCIENCE
LA English
DT Article
DE Infant speech perception; Modality differences; Inferior frontal cortex;
   fNIRS
ID AUDIOVISUAL SPEECH; SENSORIMOTOR INTEGRATION; VISUAL-STIMULATION;
   SOCIAL-INTERACTION; CORTICAL RESPONSE; BRAIN RESPONSES; AWAKE INFANTS;
   HEARING LIPS; NEURAL BASIS; PERCEPTION
AB Despite increasing interest in the development of audiovisual speech perception in infancy, the underlying mechanisms and neural processes are still only poorly understood. In addition to regions in temporal cortex associated with speech processing and multimodal integration, such as superior temporal sulcus, left inferior frontal cortex (IFC) has been suggested to be critically involved in mapping information from different modalities during speech perception. To further illuminate the role of IFC during infant language learning and speech perception, the current study examined the processing of auditory, visual and audiovisual speech in 6-month-old infants using functional near-infrared spectroscopy (fNIRS). Our results revealed that infants recruit speech-sensitive regions in frontal cortex including IFC regardless of whether they processed unimodal or multimodal speech. We argue that IFC may play an important role in associating multimodal speech information during the early steps of language learning.
C1 [Altvater-Mackensen, Nicole] Johannes Gutenberg Univ Mainz, Dept Psychol, Binger Str 14-16, D-55122 Mainz, Germany.
   [Grossmann, Tobias] Univ Virginia, Dept Psychol, Charlottesville, VA 22903 USA.
   [Altvater-Mackensen, Nicole; Grossmann, Tobias] Max Planck Inst Human Cognit & Brain Sci, Leipzig, Germany.
RP Altvater-Mackensen, N (corresponding author), Johannes Gutenberg Univ Mainz, Dept Psychol, Binger Str 14-16, D-55122 Mainz, Germany.
EM altvater@uni-mainz.de
RI ARSLAN, Okan/AAA-3232-2020
OI Altvater-Mackensen, Nicole/0000-0002-8075-4720; Grossmann,
   Tobias/0000-0002-1116-6423
FU Max Planck SocietyMax Planck Society
FX We thank Caterina Bottcher for her help with data collection and coding.
   We also thank all families who participanted in this study. This work
   was supported by funding awarded by the Max Planck Society (to T.G.).
CR Altvater-Mackensen N, 2016, NEUROIMAGE, V133, P14, DOI 10.1016/j.neuroimage.2016.02.061
   Altvater-Mackensen N, 2016, DEV PSYCHOL, V52, P191, DOI 10.1037/a0039964
   Baum SH, 2012, NEUROIMAGE, V62, P1825, DOI 10.1016/j.neuroimage.2012.05.034
   Beauchamp MS, 2004, NAT NEUROSCI, V7, P1190, DOI 10.1038/nn1333
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bortfeld H, 2009, DEV NEUROPSYCHOL, V34, P52, DOI 10.1080/87565640802564481
   Bortfeld H, 2007, NEUROIMAGE, V34, P407, DOI 10.1016/j.neuroimage.2006.08.010
   Bristow D, 2009, J COGNITIVE NEUROSCI, V21, P905, DOI 10.1162/jocn.2009.21076
   Bruderer AG, 2015, P NATL ACAD SCI USA, V112, P13531, DOI 10.1073/pnas.1508631112
   Callan DE, 2001, COGNITIVE BRAIN RES, V10, P349, DOI 10.1016/S0926-6410(00)00054-9
   Calvert GA, 1999, NEUROREPORT, V10, P2619, DOI 10.1097/00001756-199908200-00033
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593
   Calvert GA, 2001, CEREB CORTEX, V11, P1110, DOI 10.1093/cercor/11.12.1110
   Campbell R, 2001, COGNITIVE BRAIN RES, V12, P233, DOI 10.1016/S0926-6410(01)00054-4
   Cappa SF, 2012, CORTEX, V48, P785, DOI 10.1016/j.cortex.2012.04.010
   Csibra G, 2009, TRENDS COGN SCI, V13, P148, DOI 10.1016/j.tics.2009.01.005
   Danielson DK, 2017, COGNITIVE DEV, V42, P37, DOI 10.1016/j.cogdev.2017.02.004
   Dehaene-Lambertz G, 2010, BRAIN LANG, V114, P53, DOI 10.1016/j.bandl.2009.09.003
   Dehaene-Lambertz G, 2002, SCIENCE, V298, P2013, DOI 10.1126/science.1077066
   Dehaene-Lambertz G, 2006, P NATL ACAD SCI USA, V103, P14240, DOI 10.1073/pnas.0606302103
   Desjardins RN, 2004, DEV PSYCHOBIOL, V45, P187, DOI 10.1002/dev.20033
   Desjardins RN, 1997, J EXP CHILD PSYCHOL, V66, P85, DOI 10.1006/jecp.1997.2379
   Dick AS, 2010, BRAIN LANG, V114, P101, DOI 10.1016/j.bandl.2009.08.005
   EIMAS PD, 1980, SCIENCE, V209, P1140, DOI 10.1126/science.7403875
   Eisner F, 2010, J NEUROSCI, V30, P7179, DOI 10.1523/JNEUROSCI.4040-09.2010
   Fava E, 2014, BRAIN SCI, V4, P471, DOI 10.3390/brainsci4030471
   Friederici AD, 2002, TRENDS COGN SCI, V6, P78, DOI 10.1016/S1364-6613(00)01839-8
   Friederici AD, 2011, PHYSIOL REV, V91, P1357, DOI 10.1152/physrev.00006.2011
   Galantucci B, 2006, PSYCHON B REV, V13, P361, DOI 10.3758/BF03193857
   Goldstein MH, 2003, P NATL ACAD SCI USA, V100, P8030, DOI 10.1073/pnas.1332441100
   Grossmann T, 2008, P ROY SOC B-BIOL SCI, V275, P2803, DOI 10.1098/rspb.2008.0986
   Grossmann T, 2015, PSYCHOL BULL, V141, P1266, DOI 10.1037/bul0000002
   Grossmann T, 2013, INFANCY, V18, P303, DOI 10.1111/infa.12016
   Grossmann T, 2010, NEURON, V65, P852, DOI 10.1016/j.neuron.2010.03.001
   Guellai B., 2014, FRONT PSYCHOL, V5, P1
   Hagoort P, 2014, CURR OPIN NEUROBIOL, V28, P136, DOI 10.1016/j.conb.2014.07.013
   Hall DA, 2005, J COGNITIVE NEUROSCI, V17, P939, DOI 10.1162/0898929054021175
   Hickok G, 2007, NAT REV NEUROSCI, V8, P393, DOI 10.1038/nrn2113
   Hickok G, 2011, NEURON, V69, P407, DOI 10.1016/j.neuron.2011.01.019
   Hocking J, 2008, CEREB CORTEX, V18, P2439, DOI 10.1093/cercor/bhn007
   Hyde DC, 2011, DEV PSYCHOBIOL, V53, P359, DOI 10.1002/dev.20525
   Hyde DC, 2010, DEV PSYCHOBIOL, V52, P181, DOI 10.1002/dev.20417
   Imada T, 2006, NEUROREPORT, V17, P957, DOI 10.1097/01.wnr.0000223387.51704.89
   JOHNSON MH, 1991, COGNITION, V40, P1, DOI 10.1016/0010-0277(91)90045-6
   Jusczyk PW, 1998, LINGUA, V106, P197, DOI 10.1016/S0024-3841(98)00034-5
   Kabdebon C, 2014, NEUROIMAGE, V99, P342, DOI 10.1016/j.neuroimage.2014.05.046
   Kubicek C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089275
   Kuhl PK, 2007, DEVELOPMENTAL SCI, V10, P110, DOI 10.1111/j.1467-7687.2007.00572.x
   Kuhl PK, 2014, P NATL ACAD SCI USA, V111, P11238, DOI 10.1073/pnas.1410963111
   KUHL PK, 1982, SCIENCE, V218, P1138, DOI 10.1126/science.7146899
   Kuhl PK, 2003, P NATL ACAD SCI USA, V100, P9096, DOI 10.1073/pnas.1532872100
   Kushnerenko E, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00432
   Lewkowicz DJ, 2012, P NATL ACAD SCI USA, V109, P1431, DOI 10.1073/pnas.1114783109
   Lewkowicz DJ, 2010, DEV PSYCHOL, V46, P66, DOI 10.1037/a0015579
   Lewkowicz DJ, 2006, P NATL ACAD SCI USA, V103, P6771, DOI 10.1073/pnas.0602027103
   LIBERMAN AM, 1957, J ACOUST SOC AM, V29, P117, DOI 10.1121/1.1908635
   Lloyd-Fox S, 2010, NEUROSCI BIOBEHAV R, V34, P269, DOI 10.1016/j.neubiorev.2009.07.008
   Majorano M, 2014, LANG LEARN DEV, V10, P179, DOI 10.1080/15475441.2013.829740
   Mampe B, 2009, CURR BIOL, V19, P1994, DOI 10.1016/j.cub.2009.09.064
   Mani N, 2013, J EXP PSYCHOL HUMAN, V39, P623, DOI 10.1037/a0030402
   Maurer D, 2014, DEV PSYCHOBIOL, V56, P154, DOI 10.1002/dev.21177
   McGettigan C, 2012, NEUROPSYCHOLOGIA, V50, P762, DOI 10.1016/j.neuropsychologia.2012.01.010
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Meek J, 2002, DEVELOPMENTAL SCI, V5, P371, DOI 10.1111/1467-7687.00376
   MEHLER J, 1988, COGNITION, V29, P143, DOI 10.1016/0010-0277(88)90035-2
   Miller EK, 2001, ANNU REV NEUROSCI, V24, P167, DOI 10.1146/annurev.neuro.24.1.167
   Minagawa-Kawai Y, 2011, DEV COGN NEUROS-NETH, V1, P217, DOI 10.1016/j.dcn.2011.03.005
   MOON C, 1993, INFANT BEHAV DEV, V16, P495, DOI 10.1016/0163-6383(93)80007-U
   Mugitani R, 2008, INFANT BEHAV DEV, V31, P307, DOI 10.1016/j.infbeh.2007.12.002
   Naoi N, 2012, NEUROIMAGE, V59, P1735, DOI 10.1016/j.neuroimage.2011.07.093
   Nath AR, 2012, NEUROIMAGE, V59, P781, DOI 10.1016/j.neuroimage.2011.07.024
   Ojanen V, 2005, NEUROIMAGE, V25, P333, DOI 10.1016/j.neuroimage.2004.12.001
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Paulesu E, 2003, J NEUROPHYSIOL, V90, P2005, DOI 10.1152/jn.00926.2002
   Peelle JE, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00309
   Pena M, 2003, P NATL ACAD SCI USA, V100, P11702, DOI 10.1073/pnas.1934290100
   Perani D, 2011, P NATL ACAD SCI USA, V108, P16056, DOI 10.1073/pnas.1102991108
   Poeppel D, 2011, LANG COGNITIVE PROC, V26, P935, DOI 10.1080/01690965.2010.493301
   Pons F, 2009, P NATL ACAD SCI USA, V106, P10598, DOI 10.1073/pnas.0904134106
   Pulvermuller F, 2010, NAT REV NEUROSCI, V11, P351, DOI 10.1038/nrn2811
   Reynolds GD, 2014, DEV PSYCHOBIOL, V56, P355, DOI 10.1002/dev.21104
   Rossi S, 2012, BRAIN LANG, V121, P152, DOI 10.1016/j.bandl.2011.03.008
   SAMS M, 1991, NEUROSCI LETT, V127, P141, DOI 10.1016/0304-3940(91)90914-F
   Schwartz JL, 2004, COGNITION, V93, pB69, DOI 10.1016/j.cognition.2004.01.006
   Scott SK, 2009, NAT REV NEUROSCI, V10, P295, DOI 10.1038/nrn2603
   Shaw K, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0126059
   Shaw KE, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01844
   Skipper JI, 2007, CEREB CORTEX, V17, P2387, DOI 10.1093/cercor/bhl147
   Song JJ, 2015, BRAIN STRUCT FUNCT, V220, P1109, DOI 10.1007/s00429-013-0704-6
   Taga G, 2003, P NATL ACAD SCI USA, V100, P10722, DOI 10.1073/pnas.1932552100
   Taga G, 2007, NEUROIMAGE, V36, P1246, DOI 10.1016/j.neuroimage.2007.04.037
   Teinonen T, 2008, COGNITION, V108, P850, DOI 10.1016/j.cognition.2008.05.009
   Tenenbaum EJ, 2013, INFANCY, V18, P534, DOI 10.1111/j.1532-7078.2012.00135.x
   Ter Schure S, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00525
   Venezia JH, 2016, NEUROIMAGE, V126, P196, DOI 10.1016/j.neuroimage.2015.11.038
   Vihman MM, 1996, PHONOLOGICAL DEV ORI
   Vouloumanos A, 2010, CHILD DEV, V81, P517, DOI 10.1111/j.1467-8624.2009.01412.x
   Watanabe H, 2013, HUM BRAIN MAPP, V34, P543, DOI 10.1002/hbm.21453
   Weikum WM, 2007, SCIENCE, V316, P1159, DOI 10.1126/science.1137686
   WERKER JF, 1983, CAN J PSYCHOL, V37, P278, DOI 10.1037/h0080725
   Westermann G, 2004, BRAIN LANG, V89, P393, DOI 10.1016/S0093-934X(03)00345-6
   Wilson SM, 2004, NAT NEUROSCI, V7, P701, DOI 10.1038/nn1263
   Yeung HH, 2013, PSYCHOL SCI, V24, P603, DOI 10.1177/0956797612458802
NR 103
TC 4
Z9 4
U1 0
U2 0
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 1878-9293
EI 1878-9307
J9 DEV COGN NEUROS-NETH
JI Dev. Cogn. Neurosci.
PD NOV
PY 2018
VL 34
BP 130
EP 138
DI 10.1016/j.dcn.2018.10.002
PG 9
WC Psychology, Developmental; Neurosciences
SC Psychology; Neurosciences & Neurology
GA HB5FB
UT WOS:000451083300015
PM 30391756
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Zhang, XJ
   Holt, LL
AF Zhang, Xujin
   Holt, Lori L.
TI Simultaneous Tracking of Coevolving Distributional Regularities in
   Speech
SO JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE
LA English
DT Article
DE speech perception; perceptual learning; statistical learning; talker
   adaptation; dimension-based statistical learning
ID VISUAL RECALIBRATION; WORD RECOGNITION; PERCEPTION; CATEGORIZATION;
   INFORMATION; IDENTIFICATION; SPECIFICITY; ADAPTATION; VOWELS
AB Speech processing depends upon mapping variable acoustic speech input in a manner that reflects the long-term regularities of the native language. Yet, these mappings are flexible such that introduction of short-term distributional regularities in speech input, like those arising from foreign accents or talker idiosyncrasies, leads to rapid adjustments in the effectiveness of acoustic dimensions in signaling phonetic categories. The present experiments investigate whether the system is able to track simultaneous short-term distributional statistics present in speech input or if, instead, the global regularity jointly defined by these distributions dominates. Three experiments establish that adult listeners are able to track distinct simultaneously evolving regularities across time, given information to support the "binning" of acoustic instances. Both voice quality and visual information to indicate talker supported tracking of coevolving distributional regularities, even when the regularities are opposing and even when the acoustic speech tokens contributing to the distinct distributions are identical. This indicates that reweighting of perceptual dimensions in response to short-term regularities in speech input is not simply an accumulation of acoustic instances. Rather, the system is able to track multiple context-sensitive regularities simultaneously, with rapid context-dependent adaptive adjustments in how acoustic speech input maps to phonetic categories.
C1 [Zhang, Xujin; Holt, Lori L.] Carnegie Mellon Univ, Dept Psychol, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.
   [Zhang, Xujin; Holt, Lori L.] Carnegie Mellon Univ, Ctr Neural Basis Cognit, Pittsburgh, PA 15213 USA.
   [Zhang, Xujin] Google Inc, Mountain View, CA USA.
RP Holt, LL (corresponding author), Carnegie Mellon Univ, Dept Psychol, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.
EM loriholt@cmu.edu
FU National Institutes of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [R01DC004674];
   NATIONAL INSTITUTE ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited
   States Department of Health & Human ServicesNational Institutes of
   Health (NIH) - USANIH National Institute on Deafness & Other
   Communication Disorders (NIDCD) [R01DC004674, R01DC004674, R01DC004674,
   R01DC004674, R01DC004674, R01DC004674, R01DC004674, R01DC004674,
   R01DC004674, R01DC004674, R01DC004674, R01DC004674, R01DC004674,
   R01DC004674] Funding Source: NIH RePORTER
FX Research was supported by the National Institutes of Health
   (R01DC004674). Thanks to Christi Gomez for support in testing human
   participants.
CR Abramson A. S., 1985, PHONETIC LINGUISTICS, P25
   Bertelson P, 2003, PSYCHOL SCI, V14, P592, DOI 10.1046/j.0956-7976.2003.psci_1470.x
   Castleman WA, 1996, J PHONETICS, V24, P383, DOI 10.1006/jpho.1996.0021
   Clarke-Davidson CM, 2008, PERCEPT PSYCHOPHYS, V70, P604, DOI 10.3758/PP.70.4.604
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Francis AL, 2008, J ACOUST SOC AM, V124, P1234, DOI 10.1121/1.2945161
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Guediche S, 2014, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00126
   Holt LL, 2005, PSYCHOL SCI, V16, P305, DOI 10.1111/j.0956-7976.2005.01532.x
   Holt LL, 2006, J ACOUST SOC AM, V119, P3059, DOI 10.1121/1.2188377
   Idemaru K, 2014, J EXP PSYCHOL HUMAN, V40, P1009, DOI 10.1037/a0035269
   Idemaru K, 2011, J EXP PSYCHOL HUMAN, V37, P1939, DOI 10.1037/a0025641
   KIM MRC, 2002, KOREAN LANGUAGE AM, V7, P177
   KINGSTON J, 1994, LANGUAGE, V70, P419, DOI 10.2307/416481
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2008, COGNITION, V107, P54, DOI 10.1016/j.cognition.2007.07.013
   Kraljic T, 2008, PSYCHOL SCI, V19, P332, DOI 10.1111/j.1467-9280.2008.02090.x
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   LADEFOGED P, 1957, J ACOUST SOC AM, V29, P98, DOI 10.1121/1.1908694
   Lehet M, 2017, COGNITIVE SCI, V41, P885, DOI 10.1111/cogs.12413
   LINDBLOM BE, 1967, J ACOUST SOC AM, V42, P830, DOI 10.1121/1.1910655
   Liu R, 2015, J EXP PSYCHOL HUMAN, V41, P1783, DOI 10.1037/xhp0000092
   Lotto AJ, 1998, PERCEPT PSYCHOPHYS, V60, P602, DOI 10.3758/BF03206049
   McMurray B, 2002, COGNITION, V86, pB33, DOI 10.1016/S0010-0277(02)00157-9
   MILLER JL, 1979, PERCEPT PSYCHOPHYS, V25, P457, DOI 10.3758/BF03213823
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Reinisch E, 2014, J EXP PSYCHOL HUMAN, V40, P539, DOI 10.1037/a0034409
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   Schertz J, 2016, ATTEN PERCEPT PSYCHO, V78, P355, DOI 10.3758/s13414-015-0987-1
   Trude AM, 2012, LANG COGNITIVE PROC, V27, P979, DOI 10.1080/01690965.2011.597153
   van der Zande P, 2013, J ACOUST SOC AM, V134, P562, DOI 10.1121/1.4807814
   Vroomen J, 2007, NEUROPSYCHOLOGIA, V45, P572, DOI 10.1016/j.neuropsychologia.2006.01.031
   Vroomen J, 2009, COGNITION, V110, P254, DOI 10.1016/j.cognition.2008.10.015
   Weatherholtz K., 2016, OXFORD RES ENCY LING, DOI [10.1093/acrefore/9780199384655.013.95, DOI 10.1093/ACREFORE/9780199384655.013.95]
   WHALEN DH, 1993, J ACOUST SOC AM, V93, P2152, DOI 10.1121/1.406678
   Witteman M. J., 2013, ATTEN PERCEPT PSYCHO, V75, P53
NR 39
TC 6
Z9 6
U1 0
U2 7
PU AMER PSYCHOLOGICAL ASSOC
PI WASHINGTON
PA 750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA
SN 0096-1523
EI 1939-1277
J9 J EXP PSYCHOL HUMAN
JI J. Exp. Psychol.-Hum. Percept. Perform.
PD NOV
PY 2018
VL 44
IS 11
BP 1760
EP 1779
DI 10.1037/xhp0000569
PG 20
WC Psychology; Psychology, Experimental
SC Psychology
GA GY6JN
UT WOS:000448694000009
PM 30272462
OA Green Accepted, Bronze
DA 2021-02-24
ER

PT J
AU Casillas, JV
   Simonet, M
AF Casillas, Joseph V.
   Simonet, Miguel
TI Perceptual categorization and bilingual language modes: Assessing the
   double phonemic boundary in early and late bilinguals
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Speech perception; Bilingualism; Double phonemic boundary; Bilingual
   language modes; Voice onset time
ID VOICE ONSET TIME; CROSS-LANGUAGE; FOREIGN-LANGUAGE; SPEECH; ENGLISH;
   CONTRAST; SPANISH; ACQUISITION; SPEAKERS; STOPS
AB In the present study, Spanish-English bilinguals' perceptual boundaries between voiced and voiceless stops (a/b/-/p/ continuum including pre-voiced, voiceless unaspirated, and voiceless aspirated tokens) are shown to be modulated by whether participants are "led to believe" they are classifying Spanish or English sounds. In Experiment 1, simultaneous Spanish-English bilinguals and beginner second-language learners of Spanish labeled the same acoustic continuum in two experimental sessions (Spanish mode, English mode), and both groups were found to display language-specific perceptual boundaries (or session effects). In Experiment 2, early bilinguals and late second-language learners of various levels of proficiency participated in a single session in which, in random order, they labeled nonwords that were designed to prime either Spanish or English language modes. Early bilinguals and relatively proficient second-language learners, but not less proficient learners, displayed mode-specific perceptual normalization criteria even in conditions of rapid, random mode switching. Along with similar ones, the experiments reported here demonstrate that bilinguals are able to exploit language-specific perceptual processes (or norms) when processing speech sounds, which entails some degree of separation between their sound systems. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Casillas, Joseph V.] Rutgers State Univ, New Brunswick, NJ USA.
   [Simonet, Miguel] Univ Arizona, Tucson, AZ 85721 USA.
RP Simonet, M (corresponding author), Modern Languages 545,1423 E Univ Blvd, Tucson, AZ 85721 USA.
EM joseph.casillas@rutgers.edu; simonet@email.arizona.edu
OI Casillas, Joseph/0000-0001-8735-9910
CR Abramson A. S., 1972, J PHONETICS, V1, P1
   Antoniou M, 2012, J PHONETICS, V40, P582, DOI 10.1016/j.wocn.2012.05.005
   Antoniou M, 2010, J PHONETICS, V38, P640, DOI 10.1016/j.wocn.2010.09.005
   Apfelbaum KS, 2014, LANG COGN NEUROSCI, V29, P1070, DOI 10.1080/01690965.2013.824995
   Barr DJ, 2013, J MEM LANG, V68, P255, DOI 10.1016/j.jml.2012.11.001
   Beckman J, 2013, J LINGUIST, V49, P259, DOI 10.1017/S0022226712000424
   Best CT., 2007, LANGUAGE EXPERIENCE, P13, DOI [DOI 10.1075/LLLT.17.07BES, 10.1075/lllt.17.07bes]
   Boersma P., 2001, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   BOHN OS, 1993, J PHONETICS, V21, P267, DOI 10.1016/S0095-4470(19)31339-7
   BRADY SA, 1978, J ACOUST SOC AM, V63, P1556, DOI 10.1121/1.381849
   CARAMAZZA A, 1974, CAN J PSYCHOL, V28, P310, DOI 10.1037/h0081997
   CARAMAZZA A, 1973, J ACOUST SOC AM, V54, P421, DOI 10.1121/1.1913594
   Clarke CM, 2004, J ACOUST SOC AM, V116, P3647, DOI 10.1121/1.1815131
   DIEHL RL, 1978, J EXP PSYCHOL HUMAN, V4, P599, DOI 10.1037/0096-1523.4.4.599
   Eisner F, 2006, J ACOUST SOC AM, V119, P1950, DOI 10.1121/1.2178721
   Eisner F, 2005, PERCEPT PSYCHOPHYS, V67, P224, DOI 10.3758/BF03206487
   ELMAN JL, 1977, J ACOUST SOC AM, V62, P971, DOI 10.1121/1.381591
   EMILFLEGE J, 1987, APPL LINGUIST, V8, P162
   Escudero P., 2005, LOT DISSERTATION SER, V113
   Flege J. E., 2007, LAB PHONOLOGY, P353
   Flege James, 1995, SPEECH PERCEPTION LI, P229
   FLEGE JE, 1987, J PHONETICS, V15, P47, DOI 10.1016/S0095-4470(19)30537-6
   FLEGE JE, 1987, SPEECH COMMUN, V6, P185, DOI 10.1016/0167-6393(87)90025-2
   FLEGE JE, 1984, J ACOUST SOC AM, V76, P708, DOI 10.1121/1.391257
   Fowler CA, 2008, J PHONETICS, V36, P649, DOI 10.1016/j.wocn.2008.04.001
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   Garcia-Sierra A, 2012, BRAIN LANG, V121, P194, DOI 10.1016/j.bandl.2012.03.008
   Garcia-Sierra A, 2009, SPEECH COMMUN, V51, P369, DOI 10.1016/j.specom.2008.11.005
   Gertken Libby, 2012, BILINGUAL LANGUAGE P
   Goldrick M, 2014, PSYCHOL SCI, V25, P1031, DOI 10.1177/0956797613520014
   Gonzales K, 2013, PSYCHOL SCI, V24, P2135, DOI 10.1177/0956797613486485
   GROSJEAN F, 1989, BRAIN LANG, V36, P3, DOI 10.1016/0093-934X(89)90048-5
   GROSJEAN F, 1994, PSYCHOL SCI, V5, P201, DOI 10.1111/j.1467-9280.1994.tb00501.x
   Grosjean F, 1985, J MULTILING MULTICUL, V6, P467, DOI [10.1080/01434632.1985.9994221, DOI 10.1080/01434632.1985.9994221]
   Grosjean F, 1998, BILING-LANG COGN, V1, P175, DOI DOI 10.1017/S1366728998000285S1366728998000285
   Grosjean F., 1998, BILING-LANG COGN, V1, P131, DOI DOI 10.1017/S136672899800025X
   Hay J, 2017, J PHONETICS, V65, P94, DOI 10.1016/j.wocn.2017.06.005
   Hay J, 2010, LINGUISTICS, V48, P865, DOI 10.1515/LING.2010.027
   HAZAN VL, 1993, LANG SPEECH, V36, P17, DOI 10.1177/002383099303600102
   Holt LL, 2002, HEARING RES, V167, P156, DOI 10.1016/S0378-5955(02)00383-0
   KEATING PA, 1981, J ACOUST SOC AM, V70, P1261, DOI 10.1121/1.387139
   Kirby JP, 2016, J ACOUST SOC AM, V140, P2400, DOI 10.1121/1.4962445
   Kraljic T, 2005, COGNITIVE PSYCHOL, V51, P141, DOI 10.1016/j.cogpsych.2005.05.001
   Kraljic T, 2006, PSYCHON B REV, V13, P262, DOI 10.3758/BF03193841
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Magloire J, 1999, PHONETICA, V56, P158, DOI 10.1159/000028449
   McMurray B, 2016, PSYCHOL SCI, V27, P43, DOI 10.1177/0956797615609578
   Nakagawa S, 2013, METHODS ECOL EVOL, V4, P133, DOI 10.1111/j.2041-210x.2012.00261.x
   Norris D, 2003, COGNITIVE PSYCHOL, V47, P204, DOI 10.1016/S0010-0285(03)00006-9
   Olson DJ, 2013, J PHONETICS, V41, P407, DOI 10.1016/j.wocn.2013.07.005
   OYAMA S, 1976, J PSYCHOLINGUIST RES, V5, P261, DOI 10.1007/BF01067377
   Pallier C, 1997, COGNITION, V64, pB9, DOI 10.1016/S0010-0277(97)00030-9
   Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017
   Piske T, 2001, J PHONETICS, V29, P191, DOI 10.1006/jpho.2001.0134
   Rosner BS, 2000, J PHONETICS, V28, P217, DOI 10.1006/jpho.2000.0113
   Salmons J. C., 1995, PHONOLOGY, V12, P369, DOI DOI 10.1017/S0952675700002566
   Samuel AG, 2001, PSYCHOL SCI, V12, P348, DOI 10.1111/1467-9280.00364
   SAMUEL AG, 1982, PERCEPT PSYCHOPHYS, V31, P307, DOI 10.3758/BF03202653
   Samuel AG, 1997, COGNITIVE PSYCHOL, V32, P97, DOI 10.1006/cogp.1997.0646
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   Simonet M., 2016, OXFORD HDB ONLINE SC, P1, DOI [10.1093/oxfordhb/9780199935345.013.72, DOI 10.1093/OXFORDHB/9780199935345.013.72]
   Simonet M, 2014, J PHONETICS, V43, P26, DOI 10.1016/j.wocn.2014.01.004
   Sundara M, 2008, COGNITION, V106, P234, DOI 10.1016/j.cognition.2007.01.011
   van Leussen JW, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01000
   WILLIAMS L, 1977, ATTEN PERCEPT PSYCHO, V21, P289
NR 65
TC 5
Z9 5
U1 1
U2 3
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD NOV
PY 2018
VL 71
BP 51
EP 64
DI 10.1016/j.wocn.2018.07.002
PG 14
WC Linguistics; Language & Linguistics
SC Linguistics
GA HD5PB
UT WOS:000452581300004
OA Green Published
DA 2021-02-24
ER

PT J
AU Stewart, J
AF Stewart, Jesse
TI Vowel perception by native Media Lengua, Quichua, and Spanish speakers
SO JOURNAL OF PHONETICS
LA English
DT Article
DE Media Lengua; Quichua; Spanish; Mixed language; Vowel perception;
   Ecuador
ID INCOMPLETE NEUTRALIZATION; WORD-FREQUENCY; SYSTEMS; BILINGUALS;
   PHONOLOGY
AB This study explores mid and high vowel perception in and across Ecuadorian Spanish, Quichua, and Media Lengua (a mixed language containing Quichua systemic elements and Spanish lexicon). Quichua and Media Lengua were originally considered three vowel systems comprised of /i, u, a/. However, recent production results reveal that mid vowels /e, o/ may have entered these languages through Spanish lexical borrowings. The aim of the present study is to test listener perception with minimal pairs containing different mid and high vowels to determine how listeners identify them. A two-alternative forced choice (2AFC) identification task experiment with paired stimuli, gradually modified along 10-step continua, revealed that listeners of all three languages demonstrate a relatively high degree of consistent response patterns with the exception of older Quichua listeners. The results of this study coupled with the 'intermixed' acoustic spaces in which the vowels are produced also call into question the predictions that might be made in theoretical models of L2/non-native speech perception. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Stewart, Jesse] Univ Saskatchewan, Dept Linguist, 916 Arts Bldg, Saskatoon, SK S7N 5A5, Canada.
RP Stewart, J (corresponding author), Univ Saskatchewan, Dept Linguist, 916 Arts Bldg, Saskatoon, SK S7N 5A5, Canada.
EM stewart.jesse@usask.ca
RI Stewart, Jesse/F-4332-2015
OI Stewart, Jesse/0000-0001-8678-7884
FU University of Manitoba Graduate Fellowship (UMGF)
FX This research was funded by the University of Manitoba Graduate
   Fellowship (UMGF). I would like to thank Isabel Deibel, Christiani
   Thompson, Nicole Rosen, Kevin Russell, and the anonymous reviewers for
   their insightful comments and suggestions on the drafts of this paper.
   Finally, I would like to thank Gabriela Prado, Cecilia Ayala, Antonio
   Maldonado, Lucia Gonza, Elvis Tuquerres, and the participants for taking
   part in this investigation. Any remaining errors are my responsibility.
CR Adelaar William, 2004, LANGUAGES ANDES
   Amengual M, 2016, INT J BILINGUAL, V20, P133, DOI 10.1177/1367006914544988
   Bakker P, 1997, LANGUAGE OUR OWN GEN, V10
   Bates M, 2012, IME4 MIXED EFFECTS M
   Best C., 1995, SPEECH PERCEPTION LI, P171
   Best C. T., 2003, INT C PHONETIC SCI, P2889
   BEST CT, 1993, NATO ADV SCI INST SE, V69, P289
   Birdsong D, 2012, NON TRADITIONAL REF
   BROADBEN.DE, 1967, PSYCHOL REV, V74, P1, DOI 10.1037/h0024206
   Chladkova K, 2011, J ACOUST SOC AM, V130, P416, DOI 10.1121/1.3592242
   Cole P, 1982, IMBABURA QUICHUA
   Deibel I, 2017, J LANGUAGE CONTACT
   Flege J.E., 1995, SPEECH PERCEPTION LI, P233, DOI DOI 10.1075/LLLT.17.08STR
   Flege JE, 2003, SPEECH COMMUN, V40, P467, DOI 10.1016/S0167-6393(02)00128-0
   Flemming Edward, 1995, THESIS
   GOLDIAMOND I, 1958, J EXP PSYCHOL, V56, P457, DOI 10.1037/h0043051
   Gomez Rendon J., 2005, ENCUENTROS CONFLICTO, P39, DOI 10.31819/9783865278968-003
   Gomez-Renden J, 2008, HISPANISATION IMPACT, P95
   Gomez-Rendon J, 2007, EMPIR APPROACH LANG, V38, P481
   Guion SG, 2003, PHONETICA, V60, P98, DOI 10.1159/000071449
   Guirao M., 1990, REV QUEBECOISE LINGU, V19, P135, DOI [10.7202/602680ar, DOI 10.7202/602680AR]
   Hartig F., 2017, DHARMA RESIDUAL DIAG
   Hickey Raymond, 2004, NEW PERSPECTIVES ENG, P125
   Jarrin Paredes G, 2014, ESTEREOTIPOS LINGULS
   Johnson K, 2000, PHONETICA, V57, P181, DOI 10.1159/000028471
   Kewley-Port D, 2001, J ACOUST SOC AM, V85, P1726
   Kuznetsova A, 2014, NON TRADITIONAL REF
   Labov W., 1972, QUANTITATIVE STUDY S
   Labov W., 1994, PRINCIPLES LINGUISTI, V1
   Labov W., 1991, LANG VAR CHANGE, V3, P33, DOI [10.1017/S0954394500000442, DOI 10.1017/S0954394500000442]
   LEHISTE I, 1959, J ACOUST SOC AM, V31, P428, DOI 10.1121/1.1907729
   LILJENCRANTS J, 1972, LANGUAGE, V48, P839, DOI 10.2307/411991
   LINDBLOM B, 1990, NATO ADV SCI I D-BEH, V55, P403
   LINDBLOM B., 1986, EXPT PHONOLOGY, P13
   Lipski J, 2015, LINGUIST APPROACH BI, V5, P91, DOI 10.1075/lab.5.1.04lip
   Livijn P, 2000, PERILUS, V23
   Meakins F, 2013, LANG CONTACT BILING, V6, P159
   Mitleb F. M., 1981, THESIS
   Mufwene S., 2019, CAMBRIDGE HDB LANGUA
   Muller A., 2011, THESIS
   Muysken P, 1981, HIST VARIATION CREOL, P57
   Muysken P., 1980, AMSTERDAM CREOLE STU, V3, P66
   Muysken Pieter, 1997, CONTACT LANGUAGES WI, P365, DOI DOI 10.1075/CLL.17.13MUY
   Navarra J, 2005, J EXP PSYCHOL HUMAN, V31, P912, DOI 10.1037/0096-1523.31.5.912
   Pallier C, 2001, PSYCHOL SCI, V12, P445, DOI 10.1111/1467-9280.00383
   Pallier C, 1997, COGNITION, V64, pB9, DOI 10.1016/S0010-0277(97)00030-9
   PORT R, 1989, J PHONETICS, V17, P257, DOI 10.1016/S0095-4470(19)30444-9
   PORT RF, 1985, J PHONETICS, V13, P455, DOI 10.1016/S0095-4470(19)30797-1
   Roettger TB, 2014, J PHONETICS, V43, P11, DOI 10.1016/j.wocn.2014.01.002
   Shappeck M., 2011, THESIS
   Stewart J, 2011, THESIS
   Stewart J, 2014, PHONETICA, V71, P159, DOI 10.1159/000369629
   TRAUNMULLER H, 1990, J ACOUST SOC AM, V88, P97, DOI 10.1121/1.399849
   Vainio M., 2002, P 2002 IEEE WORKSH S
   van Gijn R, 2009, J PIDGIN CREOLE LANG, V24, P91, DOI 10.1075/jpcl.24.1.04gij
   Winter B., 2011, GRAZER LINGUISTISCHE, V76, P55
NR 56
TC 2
Z9 2
U1 1
U2 1
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD NOV
PY 2018
VL 71
BP 177
EP 193
DI 10.1016/j.wocn.2018.08.005
PG 17
WC Linguistics; Language & Linguistics
SC Linguistics
GA HD5PB
UT WOS:000452581300012
DA 2021-02-24
ER

PT J
AU Kleber, F
AF Kleber, Felicitas
TI VOT or quantity: What matters more for the voicing contrast in German
   regional varieties? Results from apparent-time analyses
SO JOURNAL OF PHONETICS
LA English
DT Article
DE VOT; German varieties; Dialect leveling; Production; Perception
ID SOUND CHANGE; SPEECH-PERCEPTION; CROSS-LANGUAGE; ONSET TIME; DIALECT;
   COARTICULATION; CUE; NEUTRALIZATION; INFORMATION; IDENTITY
AB Standard German distinguishes voiced (short-lag) and voiceless (long-lag) stops in domain-initial and -medial position with VOT being the most important cue. This phonemic distinction has been neutralized in many dialects but the merger appears to have been reversed in the corresponding regional accents probably due to the increasing influence of the standard language. This apparent-time study investigates the emerging importance of VOT and VCratio (a combined measure of proportional vowel and closure duration) in Bavarian and Saxon, two German regional varieties prone to reverse the merger. To this end we analyzed acoustically minimal pairs with stops in medial and initial position and investigated the integrated effects of VOT and VCratio in perception. VOT is becoming more important in younger speakers and dialectal traces are more pronounced in older participants. While a trading relation between VOT and VCratio was present in the perception of all groups it has only emerged in younger Bavarians' production (possibly reinforced by a greater amount of schwa deletion in this group). The findings are discussed within a usage-based model. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Kleber, Felicitas] Ludwig Maximilians Univ Munchen, Inst Phonet & Speech Proc, Schellingstr 3, D-80799 Munich, Germany.
RP Kleber, F (corresponding author), Ludwig Maximilians Univ Munchen, Inst Phonet & Speech Proc, Schellingstr 3, D-80799 Munich, Germany.
EM kleber@phonetik.uni-muenchen.de
RI Kleber, Felicitas/N-6197-2018
OI Kleber, Felicitas/0000-0001-8952-6874
FU DFGGerman Research Foundation (DFG)European Commission [KL 2697/1-1]
FX The author thanks the editor Gerry Docherty and two anonymous reviewers
   for their many valuable, constructive comments on earlier versions of
   this paper and the participants for their time to partake in the
   experiments. This research was supported by DFG grant number KL 2697/1-1
   "Typology of Vowel and Consonant Quantity in Southern German varieties:
   acoustic, perception, and articulatory analyses of adult and child
   speakers" to the author.
CR Abramson AS, 2017, J PHONETICS, V63, P75, DOI 10.1016/j.wocn.2017.05.002
   Babel M, 2010, LANG SOC, V39, P437, DOI 10.1017/S0047404510000400
   Bailey Guy, 1991, LANG VAR CHANGE, V3.3, P241, DOI [10.1017/S0954394500000569, DOI 10.1017/S0954394500000569]
   Baker A, 2011, LANG VAR CHANGE, V23, P347, DOI 10.1017/S0954394511000135
   Bannert R, 1976, MITTELBAIRISCHE PHON
   Barbour S., 1990, VARIATION GERMAN CRI
   Beckman ME, 2007, LAB PHONOLOGY, P241
   Beddor PS, 2009, LANGUAGE, V85, P785
   Bergmann Gunter., 1990, DIALECTS MODERN GERM, P290
   Besch W., 1983, HDB LINGUISTICS COMM, P961
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Braun A, 1988, ZUM MERKMAL FORTIS L
   Braunschweiler N, 1997, LANG SPEECH, V40, P353, DOI 10.1177/002383099704000403
   Bukmaier V, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00828
   Bybee Joan, 2002, LANG VAR CHANGE, V14, P261, DOI DOI 10.1017/S0954394502143018
   Cho T, 1999, J PHONETICS, V27, P207, DOI 10.1006/jpho.1999.0094
   Clayards M, 2018, PHONETICA, V75, P1, DOI 10.1159/000448809
   Clopper CG, 2008, J ACOUST SOC AM, V124, P1682, DOI 10.1121/1.2953322
   Clopper Cynthia G, 2006, Lang Var Change, V18, P193
   Coetzee AW, 2018, J PHONETICS, V66, P185, DOI 10.1016/j.wocn.2017.09.009
   Dmitrieva O, 2015, J PHONETICS, V49, P77, DOI 10.1016/j.wocn.2014.12.005
   Draxler Christoph, 2004, P 4 INT C LANG RES E, P559
   Eger N. A, J EXPT PSYCHOL LEARN
   Foulkes P, 2006, J PHONETICS, V34, P409, DOI 10.1016/j.wocn.2005.08.002
   Fowler CA, 2005, J PHONETICS, V33, P199, DOI 10.1016/j.wocn.2004.10.003
   Garrett Andrew, 2013, ORIGINS SOUND CHANGE, P51, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0003
   German JS, 2013, J PHONETICS, V41, P228, DOI 10.1016/j.wocn.2013.03.001
   Gordon E, 2007, CREATING AND DIGITIZING LANGUAGE CORPORA VOLUME 2: DIACHRONIC DATABASES, P82
   HAGGARD M, 1970, J ACOUST SOC AM, V47, P613, DOI 10.1121/1.1911936
   Hahn M, METHODIK MODERNER DI
   Harrington J., 2010, PHONETIC ANAL SPEECH
   Harrington J, 2008, J ACOUST SOC AM, V123, P2825, DOI 10.1121/1.2897042
   Harrington Jonathan, 2012, SPEECH PLANNING DYNA, P39
   HAWKINS SARAH, 2005, J INT PHON ASSOC, V35, P183, DOI [DOI 10.1017/S0025100305002124, 10.1017/S0025100305002124]
   HINSKENS F, 1996, DIALECT LEVELLING LI
   HOMBERT JM, 1979, LANGUAGE, V55, P37, DOI 10.2307/412518
   JANSON T, 1983, J LINGUIST, V19, P321, DOI 10.1017/S0022226700007763
   Jessen M., 1998, PHONETICS PHONOLOGY
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Johnson K, 2005, BLACKW HBK LINGUIST, P363, DOI 10.1002/9780470757024.ch15
   Johnson K, 2006, J PHONETICS, V34, P485, DOI 10.1016/j.wocn.2005.08.004
   Kerswill Paul, 2003, SOCIAL DIALECTOLOGY, P223, DOI [DOI 10.1075/IMPACT.16, 10.1075/impact. 16.16ker]
   Khan SUD, 2013, J INT PHON ASSOC, V43, P231, DOI 10.1017/S0025100313000145
   Kim MR, 2002, J PHONETICS, V30, P77, DOI 10.1006/jpho.2001.0152
   Kiparsky Paul, 1995, HDB PHONOLOGICAL THE, P640
   Kirby J., 2013, ORIGINS SOUND CHANGE, P228, DOI DOI 10.1093/ACPROF:OSO/9780199573745.003.0011
   Kirby JP, 2014, LAB PHONOL, V5, P195, DOI 10.1515/lp-2014-0008
   Kleber F, 2020, J INT PHON ASSOC, V50, P1, DOI 10.1017/S0025100317000238
   Kleber F, 2012, LANG SPEECH, V55, P383, DOI 10.1177/0023830911422194
   Kleber Felicitas, 2011, THESIS
   Kleber Felicitas, 2014, PERZEPTIVE LINGUISTI, P19
   Kohler K. J, 2001, ARB I PHONETIK DIG S, V35, P97
   KOHLER KJ, 1984, PHONETICA, V41, P150, DOI 10.1159/000261721
   KOHLER KJ, 1979, PHONETICA, V36, P332, DOI 10.1159/000259970
   KOHLER KJ, 1977, ARBEITSBER I PHONET, V8, P30
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Labov W., 1994, PRINCIPLES LANGUAGE
   Lameli Alfred, 2004, LANGUAGE VARIATION E, P253
   LINDBLOM BJORN, 1995, RIV LINGUISTICA, P75
   LISKER L, 1964, WORD, V20, P384, DOI 10.1080/00437956.1964.11659830
   Maddieson Ian, 1997, HDB PHONETIC SCI, P619
   Milroy Lesley, 2002, J SOCIOLING, V6, P3, DOI DOI 10.1111/1467-9481.00174
   Moosmuller S, 2014, LANG SCI, V46, P84, DOI 10.1016/j.langsci.2014.06.016
   Nielsen K, 2011, J PHONETICS, V39, P132, DOI 10.1016/j.wocn.2010.12.007
   OHALA JJ, 1993, SPEECH COMMUN, V13, P155, DOI 10.1016/0167-6393(93)90067-U
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Pierrehumbert JB, 2002, PHONOL PHONET, V4-1, P101
   Pinget A., 2015, THESIS
   PORT R, 1989, J PHONETICS, V17, P257, DOI 10.1016/S0095-4470(19)30444-9
   PORT RF, 1985, J PHONETICS, V13, P455, DOI 10.1016/S0095-4470(19)30797-1
   R Core Team, 2016, R LANG ENV STAT COMP
   Ruch H, 2016, J ASS LAB PHONOLOGY, V7, P2, DOI [10.5334/Iabphon.2, DOI 10.5334/IABPHON.2]
   Rues B, 2007, PHONETISCHE TRANSKNO
   Russ C, 1990, DIALECTS MODERN GERM
   Schiel F., 1999, P ICPHS 1999 SAN FRA, P607
   Schmidt Jurgen Erich, 2011, SPRACHDYNAMIK EINFUH
   Seiler G., 2005, INTERDISCIPLINARY J, V10, P103
   Shultz AA, 2012, J ACOUST SOC AM, V132, pEL95, DOI 10.1121/1.4736711
   Stuart-Smith J, 2013, LANGUAGE, V89, P501, DOI 10.1353/lan.2013.0041
   Trudgill P., 1986, DIALECTS CONTACT
   Trudgill P, 2008, LANG SOC, V37, P241, DOI 10.1017/S0047404508080287
   Wagener P., 2002, J GER LINGUIST, V14, P271
   WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3
   Wiesinger Peter, 1990, DIALECTS MODERN GERM, P438
NR 84
TC 3
Z9 3
U1 1
U2 2
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0095-4470
J9 J PHONETICS
JI J. Phon.
PD NOV
PY 2018
VL 71
BP 468
EP 486
DI 10.1016/j.wocn.2018.10.004
PG 19
WC Linguistics; Language & Linguistics
SC Linguistics
GA HD5PB
UT WOS:000452581300027
DA 2021-02-24
ER

PT J
AU Senior, B
   Hui, J
   Babel, M
AF Senior, Brianne
   Hui, Jobie
   Babel, Molly
TI Liu vs. Liu vs. Luke ? Name influence on voice recall
SO APPLIED PSYCHOLINGUISTICS
LA English
DT Article
ID UNFAMILIAR VOICES; SPEECH-PERCEPTION; 1ST NAMES; LANGUAGE;
   IDENTIFICATION; DISCRIMINATION; RECOGNITION; EXPECTATIONS; INTEGRATION
AB Listeners are better at remembering voices speaking in familiar languages and accents, and this finding is often dubbed the Ianguage-familiarity effect (LFE). A potential mechanism behind the LFE relates to a combination of list listener's implicit knowledge about lower level phonetic cues and higher level linguistic processes. While previous work has established that listeners' social expectations influence various aspects of linguistic processing and speech perception, it remains unknown how such expectations might affect talker recognition. To this end, Mandarin-accented English voices and locally accented English voices were used in a talker recognition paradigm in conditions which paired voices with stereotypically congruent names (Mandarin-accented English voice as Chen and locally accented English voice as Connor) and stereotypically incongruent names (vice versa). Across two experiments. listeners showed greater recall for the familiar, local voices than the Mandarin-accented confirming the basic premise of the LFE. Further, incongruent accent/name pairings negatively listener's performance, although listeners with experience speaking Mandarin were less influenced by he incongruent accent/name pairings. These results indicate that the LFE, while relying largely on listener's ability to parse linguistic information, is also affected by nonlinguistic information about a talker's social identity.
C1 [Senior, Brianne; Hui, Jobie; Babel, Molly] Univ British Columbia, Vancouver, BC, Canada.
RP Babel, M (corresponding author), Univ British Columbia, Dept Linguist, 2613 West Mall, Vancouver, BC V6T 1Z4, Canada.
EM molly.babel@ubc.ca
FU Alma Mater Society's Impact Fund at UBC
FX This work was supported by the Alma Mater Society's Impact Fund at UBC.
   Thank you to Rheanne Brownridge for help with subject running, Michelle
   Chan and David Kurbis for their help with stimuli selection, Qiu Ting
   Liu for her help with manuscript preparation, Ziya Wang for help with
   recording, our research participants for volunteering their time, and
   the speakers who lent their voices.
CR Anderson-Clark TN, 2008, J LANG SOC PSYCHOL, V27, P94, DOI 10.1177/0261927X07309514
   Babel M, 2015, J ACOUST SOC AM, V137, P2823, DOI 10.1121/1.4919317
   Bertrand M, 2004, AM ECON REV, V94, P991, DOI 10.1257/0002828042002561
   Boersma P., 2018, PRAAT DOING PHONETIC
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Bregman MR, 2014, COGNITION, V130, P85, DOI 10.1016/j.cognition.2013.09.010
   Devos T, 2005, J PERS SOC PSYCHOL, V88, P447, DOI 10.1037/0022-3514.88.3.447
   Drager K, 2010, LANG LINGUIST COMPAS, V4, P473, DOI 10.1111/j.1749-818x.2010.00210.x
   Drager K, 2011, LANG SPEECH, V54, P99, DOI 10.1177/0023830910388017
   Edwards R., 2006, LANG CULT CURRIC, V19, P90, DOI DOI 10.1080/07908310608668756
   GANONG WF, 1980, J EXP PSYCHOL HUMAN, V6, P110, DOI 10.1037/0096-1523.6.1.110
   GARWOOD SG, 1980, J APPL SOC PSYCHOL, V10, P431, DOI 10.1111/j.1559-1816.1980.tb00721.x
   GOGGIN JP, 1991, MEM COGNITION, V19, P448, DOI 10.3758/BF03199567
   Hall K. C., 2016, PHONOLOGICAL CORPUST
   Hay J, 2006, J PHONETICS, V34, P458, DOI 10.1016/j.wocn.2005.10.001
   Heffernan K, 2010, NAMES, V58, P24, DOI 10.1179/175622710X12590782368026
   Johnson EK, 2011, DEVELOPMENTAL SCI, V14, P1002, DOI 10.1111/j.1467-7687.2011.01052.x
   Johnson K, 1999, J PHONETICS, V27, P359, DOI 10.1006/jpho.1999.0100
   Kang O, 2009, J LANG SOC PSYCHOL, V28, P441, DOI 10.1177/0261927X09341950
   KREIMAN J, 1991, SPEECH COMMUN, V10, P265, DOI 10.1016/0167-6393(91)90016-M
   Laham SM, 2012, J EXP SOC PSYCHOL, V48, P752, DOI 10.1016/j.jesp.2011.12.002
   LEIRER VO, 1982, PERS SOC PSYCHOL B, V8, P712, DOI 10.1177/0146167282084018
   Mehrabian A, 2001, GENET SOC GEN PSYCH, V127, P59
   Munson B, 2006, J ACOUST SOC AM, V119, P2427, DOI 10.1121/1.2173521
   Niedzielski N, 1999, J LANG SOC PSYCHOL, V18, P62, DOI 10.1177/0261927X99018001005
   ORCHARD TL, 1995, APPL COGNITIVE PSYCH, V9, P249, DOI 10.1002/acp.2350090306
   Orena AJ, 2015, COGNITION, V143, P36, DOI 10.1016/j.cognition.2015.06.002
   PAPCUN G, 1989, J ACOUST SOC AM, V85, P913, DOI 10.1121/1.397564
   Perrachione T. K., OXFORD HDB VOICE PER
   Perrachione TK, 2007, NEUROPSYCHOLOGIA, V45, P1899, DOI 10.1016/j.neuropsychologia.2006.11.015
   Perrachione TK, 2011, SCIENCE, V333, P595, DOI 10.1126/science.1207327
   Pitt MA, 1998, J MEM LANG, V39, P347, DOI 10.1006/jmla.1998.2571
   Pitt MA, 2012, LANG COGNITIVE PROC, V27, P1225, DOI 10.1080/01690965.2011.619370
   Psychology Software Tools, 2012, E PRIM 2 0
   RUBIN DL, 1992, RES HIGH EDUC, V33, P511, DOI 10.1007/BF00973770
   Samuel AG, 2001, PSYCHOL SCI, V12, P348, DOI 10.1111/1467-9280.00364
   Sprietsma M, 2013, EMPIR ECON, V45, P523, DOI 10.1007/s00181-012-0609-x
   Staum Casasanto L., 2008, P 30 ANN C COGN SCI, V30, P799
   Stevenage SV, 2012, J COGN PSYCHOL, V24, P647, DOI 10.1080/20445911.2012.675321
   Strand EA, 1996, NATURAL LANGUAGE PROCESSING AND SPEECH TECHNOLOGY, P14
   Tan Peter K. W., 2001, ENGL TODAY, V17.4, P45, DOI DOI 10.1017/S0266078401004059
   THOMPSON CP, 1987, APPL COGNITIVE PSYCH, V1, P121, DOI 10.1002/acp.2350010205
   Winters SJ, 2008, J ACOUST SOC AM, V123, P4524, DOI 10.1121/1.2913046
   Xie X, 2015, J ACOUST SOC AM, V137, P419, DOI 10.1121/1.4904699
   YARMEY AD, 1991, J FORENSIC SCI SOC, V31, P421
   Yi HG, 2013, J ACOUST SOC AM, V134, pEL387, DOI 10.1121/1.4822320
NR 46
TC 1
Z9 1
U1 0
U2 10
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0142-7164
EI 1469-1817
J9 APPL PSYCHOLINGUIST
JI Appl. Psycholinguist.
PD NOV
PY 2018
VL 39
IS 6
BP 1117
EP 1146
DI 10.1017/S0142716418000267
PG 30
WC Linguistics; Psychology, Experimental
SC Linguistics; Psychology
GA HA3YT
UT WOS:000450194700002
DA 2021-02-24
ER

PT J
AU Pittman, AL
   Daliri, A
   Meadows, L
AF Pittman, Andrea L.
   Daliri, Ayoub
   Meadows, Lauren
TI Vocal Biomarkers of Mild-to-Moderate Hearing Loss in Children and
   Adults: Voiceless Sibilants
SO JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH
LA English
DT Article
ID COCHLEAR IMPLANTS; SPEECH PRODUCTION; ENGLISH FRICATIVES; ACOUSTIC
   CHANGES; LOMBARD SPEECH; LANGUAGE; FREQUENCY; PERCEPTION; SKILLS;
   INTELLIGIBILITY
AB Purpose: The purpose of this study was to determine if an objective measure of speech production could serve as a vocal biomarker for the effects of high-frequency hearing loss on speech perception. It was hypothesized that production of voiceless sibilants is governed sufficiently by auditory feedback that high-frequency hearing loss results in subtle but significant shifts in the spectral characteristics of these sibilants.
   Method: Sibilant production was examined in individuals with mild to moderately severe congenital (22 children; 8-17 years old) and acquired (23 adults; 55-80 years old) hearing losses. Measures of hearing level (pure-tone average thresholds at 4 and 8 kHz), speech perception (detection of nonsense words within sentences), and speech production (spectral center of gravity [COG] for /s/ and /j/) were obtained in unaided and aided conditions.
   Results: For both children and adults, detection of nonsense words increased significantly as heating thresholds improved. Spectral COG for was unaffected by hearing loss in both listening conditions, whereas the spectral COG for /s/ significantly decreased as high-frequency hearing loss increased. The distance in spectral COG between /s/ and /f/ decreased significantly with increasing hearing level. COG distance significantly predicted nonsense-word detection in children but not in adults.
   Conclusions: At least one aspect of speech production (voiceless sibilants) is measurably affected by high-frequency hearing loss and is related to speech perception in children. Speech production did not predict speech perception in adults, suggesting a more complex relationship between auditory feedback and feedforward mechanisms with age. Even so, these results suggest that this vocal biomarker may be useful for identifying the presence of high-frequency hearing loss in adults and children and for predicting the impact of hearing loss in children.
C1 [Pittman, Andrea L.; Daliri, Ayoub; Meadows, Lauren] Arizona State Univ, Dept Speech & Hearing Sci, Tempe, AZ 85287 USA.
RP Pittman, AL (corresponding author), Arizona State Univ, Dept Speech & Hearing Sci, Tempe, AZ 85287 USA.
EM andrea.pittman@asu.edu
RI Daliri, Ayoub/AAM-5004-2020
OI Pittman, Andrea/0000-0003-2730-383X; Daliri, Ayoub/0000-0003-3793-2947
FU Oticon Foundation
FX This study was funded by a grant from the Oticon Foundation, awarded to
   the first author. The authors would like to thank Drs. Elizabeth
   Stewart, Ashley Wright, and Jacelyn Olsen for their help with data
   collection.
CR Arciuli J, 2014, LANG SPEECH, V57, P149, DOI 10.1177/0023830913495652
   Atkinson AJ, 2001, CLIN PHARMACOL THER, V69, P89, DOI 10.1067/mcp.2000.113989
   Bagatto Marlene, 2005, Trends Amplif, V9, P199, DOI 10.1177/108471380500900404
   Baudonck N, 2011, INT J AUDIOL, V50, P912, DOI 10.3109/14992027.2011.605803
   Baudonck N, 2011, J VOICE, V25, P683, DOI 10.1016/j.jvoice.2010.05.005
   Blamey PJ, 2001, J SPEECH LANG HEAR R, V44, P264, DOI 10.1044/1092-4388(2001/022)
   Boersman P., 2013, PRAAT DOING PHONETIC
   Callan DE, 2000, J SPEECH LANG HEAR R, V43, P721, DOI 10.1044/jslhr.4303.721
   Campisi P, 2006, PERCEPT MOTOR SKILL, V103, P40, DOI 10.2466/PMS.103.1.40-50
   Casserly ED, 2011, J ACOUST SOC AM, V129, P2181, DOI 10.1121/1.3552883
   Coelho AC, 2016, BRAZ J OTORHINOLAR, V82, P70, DOI 10.1016/j.bjorl.2015.11.002
   Coelho AC, 2015, INT J AUDIOL, V54, P417, DOI 10.3109/14992027.2014.998784
   Coelho Ana Cristina de Castro, 2009, Pró-Fono R. Atual. Cient., V21, P7, DOI 10.1590/S0104-56872009000100002
   ELFENBEIN JL, 1994, J SPEECH HEAR RES, V37, P216, DOI 10.1044/jshr.3701.216
   FORREST K, 1988, J ACOUST SOC AM, V84, P115, DOI 10.1121/1.396977
   Fox J., 2015, APPL REGRESSION ANAL
   Fox RA, 2005, J SPEECH LANG HEAR R, V48, P753, DOI 10.1044/1092-4388(2005/052)
   Ghosh SS, 2010, J ACOUST SOC AM, V128, P3079, DOI 10.1121/1.3493430
   Gordon T G, 1987, ASHA Monogr, P108
   Guenther FH, 2006, J COMMUN DISORD, V39, P350, DOI 10.1016/j.jcomdis.2006.06.013
   Hung YC, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178588
   Iskarous K, 2011, J ACOUST SOC AM, V129, P944, DOI 10.1121/1.3514537
   Jafari N, 2017, J VOICE, V31, DOI 10.1016/j.jvoice.2016.10.018
   Jongman A, 2000, J ACOUST SOC AM, V108, P1252, DOI 10.1121/1.1288413
   KUHL PK, 1994, CURR OPIN NEUROBIOL, V4, P812, DOI 10.1016/0959-4388(94)90128-7
   Kuhl PK, 2004, NAT REV NEUROSCI, V5, P831, DOI 10.1038/nrn1533
   LANE H, 1971, J SPEECH HEAR RES, V14, P677, DOI 10.1044/jshr.1404.677
   Lane H, 1997, J ACOUST SOC AM, V101, P2244, DOI 10.1121/1.418245
   Lejska M, 2004, J VOICE, V18, P209, DOI 10.1016/j.jvoice.2003.08.002
   Matthies ML, 2008, J ACOUST SOC AM, V124, P3191, DOI 10.1121/1.2987427
   MATTHIES ML, 1994, J ACOUST SOC AM, V96, P1367, DOI 10.1121/1.410281
   PERKELL J, 1992, J ACOUST SOC AM, V91, P2961, DOI 10.1121/1.402932
   Perkell JS, 2012, J NEUROLINGUIST, V25, P382, DOI 10.1016/j.jneuroling.2010.02.011
   Pittman AL, 2013, EAR HEARING, V34, P213, DOI 10.1097/AUD.0b013e31826e5006
   Reidy PF, 2017, EAR HEARING, V38, P42, DOI 10.1097/AUD.0000000000000349
   Reidy PF, 2016, J ACOUST SOC AM, V140, P2518, DOI 10.1121/1.4964510
   Shiller DM, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0012975
   Shiller DM, 2009, J ACOUST SOC AM, V125, P1103, DOI 10.1121/1.3058638
   Cysneiros HRS, 2016, CODAS, V28, DOI 10.1590/2317-1782/20162015165
   Simko J, 2016, J ACOUST SOC AM, V139, P151, DOI 10.1121/1.4939495
   Stelmachowicz PG, 2004, ARCH OTOLARYNGOL, V130, P556, DOI 10.1001/archotol.130.5.556
   Stevens K. N., 2000, ACOUSTIC PHONETICS, V30
   Stowe LM, 2013, J ACOUST SOC AM, V134, P640, DOI 10.1121/1.4807645
   Strimbu K, 2010, CURR OPIN HIV AIDS, V5, P463, DOI 10.1097/COH.0b013e32833ed177
   Tourville JA, 2011, LANG COGNITIVE PROC, V26, P952, DOI 10.1080/01690960903498424
   TYEMURRAY N, 1995, J ACOUST SOC AM, V98, P2454, DOI 10.1121/1.413278
   Valero-Garcia J, 2010, INT J PEDIATR OTORHI, V74, P843, DOI 10.1016/j.ijporl.2010.04.011
   Van Lierde KM, 2005, INT J AUDIOL, V44, P452, DOI 10.1080/14992020500189146
   Verhoeven J, 2016, J COMMUN DISORD, V59, P24, DOI 10.1016/j.jcomdis.2015.10.007
   Vitevitch MS, 2004, BEHAV RES METH INS C, V36, P481, DOI 10.3758/BF03195594
   Williams K, 2007, EXPRESSIVE VOCABULAR
   Zhou N, 2008, J ACOUST SOC AM, V123, P1653, DOI 10.1121/1.2832623
NR 52
TC 1
Z9 1
U1 0
U2 2
PU AMER SPEECH-LANGUAGE-HEARING ASSOC
PI ROCKVILLE
PA 2200 RESEARCH BLVD, #271, ROCKVILLE, MD 20850-3289 USA
SN 1092-4388
EI 1558-9102
J9 J SPEECH LANG HEAR R
JI J. Speech Lang. Hear. Res.
PD NOV
PY 2018
VL 61
IS 11
BP 2814
EP 2826
DI 10.1044/2018_JSLHR-H-17-0460
PG 13
WC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
SC Audiology & Speech-Language Pathology; Linguistics; Rehabilitation
GA GZ7WT
UT WOS:000449697900016
PM 30458528
DA 2021-02-24
ER

PT J
AU Lui, M
   So, WC
   Tsang, YK
AF Lui, Ming
   So, Wing-Chee
   Tsang, Yiu-Kei
TI Neural evidence for reduced automaticity in processing emotional prosody
   among men with high levels of autistic traits
SO PHYSIOLOGY & BEHAVIOR
LA English
DT Article
DE Autistic traits; Emotions; Speech comprehension; Communication; Language
   processing
ID HIGH-FUNCTIONING AUTISM; SPECTRUM DISORDER; SPEECH-PERCEPTION; BRAIN
   POTENTIALS; CHILDREN; TASK; ADOLESCENTS; INTEGRATION; QUOTIENT; DYNAMICS
AB This study aimed to examine individual differences in the integration of emotional prosody when processing semantic meaning in speech among men with high and low levels of autistic traits, as measured by the Autism Spectrum Quotient (AQ). The behavioral and neural responses of high- and low-AQ men during semantic valence judgment were compared. The stimuli were positive or negative words spoken with either happy or sad prosody; in other words, the prosody was either congruous or incongruous to the valence of meaning. Participants were required to judge the (positive vs. negative) valence of word meaning as accurately and as quickly as possible while ignoring emotional prosody. Behavioral results showed that high-AQ men responded significantly more slowly than low-AQ men in all stimulus conditions, indicating lower automaticity in processing emotional speech. Neural data revealed that low-AQ men (but not high-AQ men) had significantly increased N200 and N400 amplitudes for incongruous (compared to congruous) stimuli spoken with happy prosody. Our findings supported our hypotheses that high levels of autistic traits are associated with reduced behavioral automaticity and less differential neural resources allocated to processing emotional speech stimuli with different cognitive demands.
C1 [Lui, Ming; Tsang, Yiu-Kei] Hong Kong Baptist Univ, Dept Educ Studies, Hong Kong, Hong Kong, Peoples R China.
   [So, Wing-Chee] Chinese Univ Hong Kong, Dept Educ Psychol, Hong Kong, Hong Kong, Peoples R China.
RP Lui, M (corresponding author), Hong Kong Baptist Univ, Dept Educ Studies, Hong Kong, Hong Kong, Peoples R China.
EM m-lui@u.northwestem.edu
OI So, Wing Chee/0000-0002-6538-1663; Lui, Ming/0000-0001-7996-0386; Tsang,
   Yiu Kei/0000-0002-4978-1333
FU Hong Kong Baptist University Research Committee Interdisciplinary
   Research Matching Scheme; Hong Kong Baptist University Faculty Research
   Grant [FRG1/16-17/037]; General Research Fund of Research Grants
   Council, University Grants Committee, Hong Kong [12604418]
FX No financial interest or benefit is expected to arise from direct
   applications of this research. All authors declare that they have no
   conflict of interest. We thank the anonymous reviewers for the valuable
   comments, and Ms. Rachel Li and Ms. Lavender Chiu for assistance in data
   collection. This work was supported by the Hong Kong Baptist University
   Research Committee Interdisciplinary Research Matching Scheme 2016/17,
   and Hong Kong Baptist University Faculty Research Grant (grant number
   FRG1/16-17/037), and the General Research Fund of Research Grants
   Council, University Grants Committee, Hong Kong (Project No: 12604418).
CR Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Baron-Cohen S, 2004, J AUTISM DEV DISORD, V34, P163, DOI 10.1023/B:JADD.0000022607.19833.00
   Boucher J, 2000, J CHILD PSYCHOL PSYC, V41, P847, DOI 10.1111/1469-7610.00672
   Breitenstein C, 2001, COGNITION EMOTION, V15, P57, DOI 10.1080/0269993004200114
   Brennand R, 2011, RES AUTISM SPECT DIS, V5, P1567, DOI 10.1016/j.rasd.2011.03.002
   Chen HC, 2000, MEM COGNITION, V28, P427, DOI 10.3758/BF03198558
   Chevallier C, 2012, TRENDS COGN SCI, V16, P231, DOI 10.1016/j.tics.2012.02.007
   Critchley HD, 2000, BRAIN, V123, P2203, DOI 10.1093/brain/123.11.2203
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Efron B., 1993, INTRO BOOTSTRAP MONO, V57
   ERIKSEN BA, 1974, PERCEPT PSYCHOPHYS, V16, P143, DOI 10.3758/BF03203267
   Fan YT, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0102471, 10.1371/journal.pone.0085880]
   Gaigg SB, 2008, NEUROPSYCHOLOGIA, V46, P2336, DOI 10.1016/j.neuropsychologia.2008.03.008
   Gaigg SB, 2009, J AUTISM DEV DISORD, V39, P1211, DOI 10.1007/s10803-009-0719-2
   GEHRING WJ, 1992, J EXP PSYCHOL HUMAN, V18, P198, DOI 10.1037/0096-1523.18.1.198
   Golan O, 2007, J AUTISM DEV DISORD, V37, P1096, DOI 10.1007/s10803-006-0252-5
   Grossman RB, 2010, J SPEECH LANG HEAR R, V53, P778, DOI 10.1044/1092-4388(2009/08-0127)
   Hagoort P, 2000, NEUROPSYCHOLOGIA, V38, P1518, DOI 10.1016/S0028-3932(00)00052-X
   Hahne A, 2002, COGNITIVE BRAIN RES, V13, P339, DOI 10.1016/S0926-6410(01)00127-6
   Han DH, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0091214
   Happe F, 2006, J AUTISM DEV DISORD, V36, P5, DOI 10.1007/s10803-005-0039-0
   Hill EL, 2004, TRENDS COGN SCI, V8, P26, DOI 10.1016/j.tics.2003.11.003
   Humphreys K, 2007, NEUROPSYCHOLOGIA, V45, P685, DOI 10.1016/j.neuropsychologia.2006.08.003
   Keehn RJJ, 2017, AUTISM RES, V10, P130, DOI 10.1002/aur.1636
   Kleinhans N, 2005, DEV NEUROPSYCHOL, V27, P379, DOI 10.1207/s15326942dn2703_5
   Kutas M, 2000, TRENDS COGN SCI, V4, P463, DOI 10.1016/S1364-6613(00)01560-6
   KUTAS M, 1984, NATURE, V307, P161, DOI 10.1038/307161a0
   Lartseva A, 2015, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00991
   Luck S.J., 2012, OXFORD HDB EVENT REL, P295, DOI DOI 10.1093/OXFORDHB/9780195374148.013.0144
   Lyons M, 2014, AUTISM RES, V7, P181, DOI 10.1002/aur.1355
   Mazefsky CA, 2007, J AUTISM DEV DISORD, V37, P1086, DOI 10.1007/s10803-006-0251-6
   Moors A, 2006, PSYCHOL BULL, V132, P297, DOI 10.1037/0033-2909.132.2.297
   Ozyurek A, 2007, J COGNITIVE NEUROSCI, V19, P605, DOI 10.1162/jocn.2007.19.4.605
   Ozonoff S, 1999, J AUTISM DEV DISORD, V29, P171, DOI 10.1023/A:1023052913110
   Ozonoff S, 1997, J AUTISM DEV DISORD, V27, P59, DOI 10.1023/A:1025821222046
   Paulmann S, 2008, BRAIN LANG, V105, P59, DOI 10.1016/j.bandl.2007.11.005
   Raven J, 2003, HANDBOOK OF NONVERBAL ASSESSMENT, P223
   Russell J, 1999, J AUTISM DEV DISORD, V29, P103, DOI 10.1023/A:1023084425406
   SCHERER KR, 1991, MOTIV EMOTION, V15, P123, DOI 10.1007/BF00995674
   Schirmer A, 2004, NEUROIMAGE, V21, P1114, DOI 10.1016/j.neuroimage.2003.10.048
   Schirmer A, 2002, COGNITIVE BRAIN RES, V14, P228, DOI 10.1016/S0926-6410(02)00108-8
   Schirmer A, 2006, EMOTION, V6, P406, DOI 10.1037/1528-3542.6.3.406
   Segal O, 2014, FOLIA PHONIATR LOGO, V66, P25, DOI 10.1159/000363739
   So WC, 2015, AUTISM, V19, P956, DOI 10.1177/1362361314556783
   Stevenson RA, 2014, J AUTISM DEV DISORD, V44, P1470, DOI 10.1007/s10803-013-1992-7
   Wang YP, 2004, PSYCHOPHYSIOLOGY, V41, P21, DOI 10.1111/j.1469-8986.2003.00134.x
   Williams D, 2010, AUTISM, V14, P285, DOI 10.1177/1362361309344849
NR 47
TC 1
Z9 1
U1 2
U2 10
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0031-9384
J9 PHYSIOL BEHAV
JI Physiol. Behav.
PD NOV 1
PY 2018
VL 196
BP 47
EP 58
DI 10.1016/j.physbeh.2018.08.014
PG 12
WC Psychology, Biological; Behavioral Sciences
SC Psychology; Behavioral Sciences
GA GZ1ME
UT WOS:000449131400006
PM 30157447
DA 2021-02-24
ER

PT J
AU Wang, YY
   Shafto, CL
   Houston, DM
AF Wang, Yuanyuan
   Shafto, Carissa L.
   Houston, Derek M.
TI Attention to speech and spoken language development in deaf children
   with cochlear implants: a 10-year longitudinal study
SO DEVELOPMENTAL SCIENCE
LA English
DT Article
ID VISUAL-ATTENTION; WORKING-MEMORY; PERCEPTION; INFANTS; AGE; HEARING;
   ORGANIZATION; BRAIN; REORGANIZATION; VARIABILITY
AB Early auditory/language experience plays an important role in language development. In this study, we examined the effects of severe-to-profound hearing loss and subsequent cochlear implantation on the development of attention to speech in children with cochlear implants (CIs). In addition, we investigated the extent to which attention to speech may predict spoken language development in children with CIs. We tested children with CIs and compared them to chronologically age-matched peers with normal hearing (NH) on their attention to speech at four time points post implantation; specifically, less than 1 month, 3 to 6 months, 12 months, and 18 months post implantation. We also collected a variety of well-established speech perception and spoken language measures from the children with CIs in a 10-year longitudinal study. Children with CIs showed reduced attention to speech as compared to their peers with NH at less than 1 month post implantation, but a similar degree of attention to speech as their NH peers during later time points. In addition, attention to speech at 3 to 6 months post implantation predicts speech perception in children with CIs. These results inform language acquisition theories and bring insights into our understanding of early severe-to-profound hearing loss on infants' attention to speech skills. In addition, the findings have significant clinical implications for early intervention on hearing loss, which emphasizes the importance of developing strong listening skills. A video abstract of this article can be viewed at: https://www.youtube.com/watch?v=f7xiYo3Ua08&feature=youtu.be
C1 [Wang, Yuanyuan; Houston, Derek M.] Ohio State Univ, Dept Otolaryngol Head & Neck Surg, Columbus, OH 43210 USA.
   [Shafto, Carissa L.] Galen Coll Nursing, Louisville, KY USA.
RP Wang, YY (corresponding author), Ohio State Univ, Wexner Med Ctr, Dept Otolaryngol Head & Neck Surg, Columbus, OH 43210 USA.
EM Yuanyuan.Wang@osumc.edu
RI Houston, Derek/AAM-6553-2020
FU National Institute on Deafness and Other Communication Disorders
   GrantUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Institute on Deafness &
   Other Communication Disorders (NIDCD) [R01 DC008581]; NATIONAL INSTITUTE
   ON DEAFNESS AND OTHER COMMUNICATION DISORDERSUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   National Institute on Deafness & Other Communication Disorders (NIDCD)
   [R01DC008581, R01DC008581, R01DC008581, R01DC008581, R01DC008581,
   R01DC008581, R01DC008581, R01DC008581, R01DC008581, R01DC008581,
   R01DC008581] Funding Source: NIH RePORTER
FX This research was supported in part by National Institute on Deafness
   and Other Communication Disorders Grant (R01 DC008581).
CR Baayen R, 2011, LANGUAGER DATA SETS
   Barton Christine, 2015, Cochlear Implants Int, V16 Suppl 3, pS51, DOI 10.1179/1467010015Z.000000000267
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bavelier D, 2001, J NEUROSCI, V21, P8931, DOI 10.1523/JNEUROSCI.21-22-08931.2001
   Bavelier D, 2000, J NEUROSCI, V20, DOI 10.1523/JNEUROSCI.20-17-j0001.2000
   BEST CT, 1988, J EXP PSYCHOL HUMAN, V14, P345, DOI 10.1037/0096-1523.14.3.345
   Bharadwaj SV, 2016, INT J PEDIATR OTORHI, V85, P158, DOI 10.1016/j.ijporl.2016.03.036
   Butterfield E., 1970, 3 S OR SENS PERC MOU
   Clopper CG, 2006, J AM ACAD AUDIOL, V17, P331, DOI 10.3766/jaaa.17.5.4
   Connor CM, 2006, EAR HEARING, V27, P628, DOI 10.1097/01.aud.0000240640.59205.42
   Conway CM, 2011, DEVELOPMENTAL SCI, V14, P69, DOI 10.1111/j.1467-7687.2010.00960.x
   Conway CM, 2009, CURR DIR PSYCHOL SCI, V18, P275, DOI 10.1111/j.1467-8721.2009.01651.x
   Curtin S, 2011, J PHONETICS, V39, P492, DOI 10.1016/j.wocn.2010.12.002
   Davidson K, 2014, J DEAF STUD DEAF EDU, V19, P238, DOI 10.1093/deafed/ent045
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   Dunn L. M., 1997, PEABODY PICTURE VOCA
   FryaufBertschy H, 1997, J SPEECH LANG HEAR R, V40, P183, DOI 10.1044/jslhr.4001.183
   Geers A, 2008, INT J AUDIOL, V47, pS21, DOI 10.1080/14992020802339167
   Geers Ann E, 2011, Ear Hear, V32, p84S, DOI 10.1097/AUD.0b013e3181ffd5b5
   GOLDMAN R, 1986, GOLDMAN FRISTOE TEST
   Hall ML, 2017, J DEAF STUD DEAF EDU, V22, P9, DOI 10.1093/deafed/enw054
   Holt RF, 2008, EAR HEARING, V29, P492, DOI 10.1097/AUD.0b013e31816c409f
   Holt RF, 2012, J SPEECH LANG HEAR R, V55, P848, DOI 10.1044/1092-4388(2011/11-0143)
   Horn DL, 2005, EAR HEARING, V26, P389, DOI 10.1097/00003446-200508000-00003
   Houston DM, 2014, LINGUA, V139, P10, DOI 10.1016/j.lingua.2013.08.001
   Houston DM, 2012, J AM ACAD AUDIOL, V23, P446, DOI 10.3766/jaaa.23.6.7
   Houston DM, 2012, DEVELOPMENTAL SCI, V15, P448, DOI 10.1111/j.1467-7687.2012.01140.x
   Houston DM, 2003, INT J PEDIATR OTORHI, V67, P479, DOI 10.1016/S0165-5876(03)00005-3
   Jerger S., 1984, PEDIAT SPEECH INTELL
   JUSCZYK PW, 1993, J PHONETICS, V21, P3, DOI 10.1016/S0095-4470(19)31319-1
   Kirk K. I., 1999, J AM ACAD AUDIOL, V10, P113
   Kirk KI, 1997, J SPEECH LANG HEAR R, V40, P1395, DOI 10.1044/jslhr.4006.1395
   Kirk KI, 2000, VOLTA REV, V102, P127
   Kirk KI, 2000, COCHLEAR IMPLANTS, P225
   Kozak L.V., 2013, 11 C THEOR ISS SIGN
   Kuhl PK, 2005, DEVELOPMENTAL SCI, V8, pF1, DOI 10.1111/j.1467-7687.2004.00384.x
   Kuznetsova A, 2015, IMERTEST TESTS LINEA
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Marshall C, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00527
   May L, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12564
   Merabet LB, 2010, NAT REV NEUROSCI, V11, P44, DOI 10.1038/nrn2758
   Mills DL, 2004, J COGNITIVE NEUROSCI, V16, P1452, DOI 10.1162/0898929042304697
   Miyamoto RT, 2000, ADV OTO-RHINO-LARYNG, V57, P212
   Miyamoto RT, 1997, ACTA OTO-LARYNGOL, V117, P154, DOI 10.3109/00016489709117758
   Molfese DL, 2000, BRAIN LANG, V72, P238, DOI 10.1006/brln.2000.2287
   MOOG J, 1983, GRAMMATICAL ANAL ELI
   Moossavi A., 2016, AUDITORY VESTIBULAR, V25, P227
   MULLENNIX JW, 1989, J ACOUST SOC AM, V85, P365, DOI 10.1121/1.397688
   NEVILLE HJ, 1987, BRAIN RES, V405, P268, DOI 10.1016/0006-8993(87)90296-4
   Niparko JK, 2010, JAMA-J AM MED ASSOC, V303, P1498, DOI 10.1001/jama.2010.451
   Nittrouer S., 2010, EARLY DEV CHILDREN H
   Oakes L. M., 2015, HABIT 2 UNPUB
   Peterson CC, 2000, MIND LANG, V15, P123, DOI 10.1111/1468-0017.00126
   PETITTO LA, 1991, SCIENCE, V251, P1493, DOI 10.1126/science.2006424
   Pisoni DB, 2003, EAR HEARING, V24, p106S, DOI 10.1097/01.AUD.0000051692.05140.8E
   Pisoni DB, 2000, ANN OTO RHINOL LARYN, V109, P92
   R Core Team, 2014, R LANG ENV STAT COMP
   RAUSCHECKER JP, 1993, J NEUROSCI, V13, P4538
   Richards JE, 1997, DEV PSYCHOL, V33, P22, DOI 10.1037/0012-1649.33.1.22
   Richards JE, 2002, DEV PSYCHOBIOL, V40, P226, DOI 10.1002/dev.10029
   Robertson S, 2013, J SPEECH LANG HEAR R, V56, P1108, DOI 10.1044/1092-4388(2012/12-0110)
   Sevy ABG, 2010, HEARING RES, V270, P39, DOI 10.1016/j.heares.2010.09.010
   Shultz S, 2014, DEVELOPMENTAL SCI, V17, P766, DOI 10.1111/desc.12151
   Shultz S, 2010, LANG LEARN DEV, V6, P241, DOI 10.1080/15475440903507830
   Smith LB, 1998, DEV PSYCHOL, V34, P840, DOI 10.1037/0012-1649.34.5.840
   SPENCE MJ, 1987, INFANT BEHAV DEV, V10, P133, DOI 10.1016/0163-6383(87)90028-2
   Strait DL, 2015, DEV COGN NEUROS-NETH, V12, P94, DOI 10.1016/j.dcn.2015.01.001
   Svirsky MA, 2004, AUDIOL NEURO-OTOL, V9, P224, DOI 10.1159/000078392
   Tomblin JB, 2007, INT J AUDIOL, V46, P512, DOI 10.1080/14992020701383043
   Tomblin JB, 1999, J SPEECH LANG HEAR R, V42, P497, DOI 10.1044/jslhr.4202.497
   Voss P, 2012, CURR BIOL, V22, pR168, DOI 10.1016/j.cub.2012.01.030
   Vouloumanos A, 2004, DEVELOPMENTAL SCI, V7, P270, DOI 10.1111/j.1467-7687.2004.00345.x
   Vouloumanos A, 2007, DEVELOPMENTAL SCI, V10, P159, DOI 10.1111/j.1467-7687.2007.00549.x
   Vouloumanos A, 2014, COGNITIVE SCI, V38, P1675, DOI 10.1111/cogs.12128
   Wang YY, 2017, J SPEECH LANG HEAR R, V60, P3321, DOI 10.1044/2017_JSLHR-H-17-0149
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   Willstedt-Svensson U, 2004, INT J AUDIOL, V43, P506, DOI 10.1080/14992020400050065
   Zeng Fan-Gang, 2004, Trends Amplif, V8, P1, DOI 10.1177/108471380400800102
NR 78
TC 3
Z9 3
U1 2
U2 21
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1363-755X
EI 1467-7687
J9 DEVELOPMENTAL SCI
JI Dev. Sci.
PD NOV
PY 2018
VL 21
IS 6
AR e12677
DI 10.1111/desc.12677
PG 12
WC Psychology, Developmental; Psychology, Experimental
SC Psychology
GA GY1FF
UT WOS:000448269700014
PM 29761835
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Gonzales, K
   Gerken, L
   Gomez, RL
AF Gonzales, Kalim
   Gerken, LouAnn
   Gomez, Rebecca L.
TI How who is talking matters as much as what they say to infant language
   learners
SO COGNITIVE PSYCHOLOGY
LA English
DT Article
DE Language acquisition; Paralinguistic variation; Voice perception;
   Sociolinguistic variation; Exemplar models; General auditory account
ID BILINGUAL INFANTS; WORD SEGMENTATION; SPEECH-PERCEPTION; STIMULUS
   VARIABILITY; MULTIPLE SPEAKERS; ACQUISITION; INPUT; DISCRIMINATION;
   ENGLISH; VOICES
AB Human vocalizations contain both voice characteristics that convey who is talking and sophisticated linguistic structure. Inter-talker variation in voice characteristics is traditionally seen as posing a challenge for infant language learners, who must disregard this variation when the task is to detect talkers' shared linguistic conventions. However, talkers often differ markedly in their pronunciation, vocabulary, and grammar. This is true even in monolingual environments, given factors like gender, dialect, and proficiency. We therefore asked whether infants treat the voice characteristics distinguishing talkers as a cue for learning linguistic conventions that one talker may follow more closely than another. Supporting this previously untested hypothesis, 12-month-olds did not freely combine two talkers' sentences distinguished by voice to more robustly learn the talkers' shared grammar rules. Rather, they used this voice information to learn rules to which only one talker adhered, a finding replicated in same-aged infants with greater second language exposure. Both language groups generalized the rules to novel sentences produced by a novel talker. Voice characteristics can thus help infants learn and generalize talker-dependent linguistic structure, which pervades natural language. Results are interpreted in light of theories linking language learning with voice perception.
C1 [Gonzales, Kalim] Huanghuai Univ, Zhumadian 463000, Peoples R China.
   [Gerken, LouAnn; Gomez, Rebecca L.] Univ Arizona, Dept Psychol, Tucson, AZ 85721 USA.
RP Gonzales, K (corresponding author), Huanghuai Univ, Zhumadian 463000, Peoples R China.
EM kalim_gonzales@yahoo.com; gerken@email.arizona.edu;
   rgomez@email.arizona.edu
RI Gonzales, Kalim/L-6956-2019
OI Gonzales, Kalim/0000-0003-2598-1338
FU National Institute of HealthUnited States Department of Health & Human
   ServicesNational Institutes of Health (NIH) - USA [NIH HD42170];
   National Science Foundation [NSF CAREER Award]National Science
   Foundation (NSF)NSF - Office of the Director (OD) [BCS-0238584]
FX We thank Andrew J. Lotto, Elena Plante, Roger W. Schvaneveldt, Rushen
   Shi and two anonymous reviewers for valuable feedback on previous
   drafts, and Elizabeth Salvagio for assistance both with implementing the
   experiments and with overseeing data collection. This study was
   supported by the National Institute of Health [NIH HD42170 to LAG and
   RLG] and the National Science Foundation [NSF CAREER Award BCS-0238584
   to RLG]. H
CR [Anonymous], 2008, COGNITION, V106, P833, DOI 10.1016/j.cognition.2007.05.002
   Apfelbaum KS, 2011, COGNITIVE SCI, V35, P1105, DOI 10.1111/j.1551-6709.2011.01181.x
   Bedore LM, 2005, APPL PSYCHOLINGUIST, V26, P195, DOI 10.1017/S0142716405050149
   Bialystok E, 2015, CHILD DEV PERSPECT, V9, P117, DOI 10.1111/cdep.12116
   BIJELJACBABIC R, 1993, DEV PSYCHOL, V29, P711, DOI 10.1037/0012-1649.29.4.711
   Bosch L, 2001, INFANCY, V2, P29, DOI 10.1207/S15327078IN0201_3
   Braine M., 1987, MECH LANGUAGE ACQUIS, P65, DOI DOI 10.4324/9781315798721
   Chambers JK, 2005, CAN J LING/REV CAN L, V50, P215, DOI 10.1353/cjl.2007.0002
   Christophe A, 1998, DEVELOPMENTAL SCI, V1, P215, DOI 10.1111/1467-7687.00033
   Cohen E, 2012, CURR ANTHROPOL, V53, P588, DOI 10.1086/667654
   Culbertson J, 2015, COGNITION, V139, P71, DOI 10.1016/j.cognition.2015.02.007
   Curtin S, 2011, J PHONETICS, V39, P492, DOI 10.1016/j.wocn.2010.12.002
   Dabrowska E, 2012, LINGUIST APPROACH BI, V2, P219, DOI 10.1075/lab.2.3.01dab
   DECASPER AJ, 1984, DEV PSYCHOBIOL, V17, P481, DOI 10.1002/dev.420170506
   Diehl RL, 2004, ANNU REV PSYCHOL, V55, P149, DOI 10.1146/annurev.psych.55.090902.142028
   Don J, 2008, STUD LANG, V32, P670, DOI 10.1075/sl.32.3.09don
   Estes KG, 2015, DEV PSYCHOL, V51, P1517, DOI 10.1037/a0039725
   Estes KG, 2015, CHILD DEV, V86, P1371, DOI 10.1111/cdev.12392
   Ferguson B, 2014, BEHAV BRAIN SCI, V37, DOI 10.1017/S0140525X13004019
   Fine AB, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077661
   Fitch WT, 2000, TRENDS COGN SCI, V4, P258, DOI 10.1016/S1364-6613(00)01494-7
   Floccia C, 2012, COGNITION, V124, P95, DOI 10.1016/j.cognition.2012.03.011
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   Friendly RH, 2014, DEV PSYCHOBIOL, V56, P228, DOI 10.1002/dev.21164
   Gerken L, 2005, J CHILD LANG, V32, P249, DOI 10.1017/S0305000904006786
   Gerken L, 1996, SIGNAL TO SYNTAX: BOOTSTRAPPING FROM SPEECH TO GRAMMAR IN EARLY ACQUISITION, P411
   Gerken L, 2015, DEVELOPMENTAL SCI, V18, P80, DOI 10.1111/desc.12183
   Gerken L, 2011, DEVELOPMENTAL SCI, V14, P972, DOI 10.1111/j.1467-7687.2011.01046.x
   Goldberg AE, 2009, COGN LINGUIST, V20, P93, DOI 10.1515/COGL.2009.005
   Gomez RL, 2004, DEVELOPMENTAL SCI, V7, P567, DOI 10.1111/j.1467-7687.2004.00381.x
   Gonzales K, 2015, COGNITION, V140, P60, DOI 10.1016/j.cognition.2015.03.015
   Gonzales K, 2013, PSYCHOL SCI, V24, P2135, DOI 10.1177/0956797613486485
   Hahn U, 2000, COGNITIVE PSYCHOL, V41, P313, DOI 10.1006/cogp.2000.0737
   Hay J, 2010, LANG SPEECH, V53, P447, DOI 10.1177/0023830910372489
   Houston D, 2008, 29 IND U SPEECH RES, P316
   Houston DM, 2000, J EXP PSYCHOL HUMAN, V26, P1570, DOI 10.1037/0096-1523.26.5.1570
   Houston DM, 2003, J EXP PSYCHOL HUMAN, V29, P1143, DOI 10.1037/0096-1523.29.6.1143
   Hunter M. A., 1988, ADV INFANCY RES, V5, P69, DOI DOI 10.1037/0012-1649.19.3.338
   Huttenlocher J, 2002, COGNITIVE PSYCHOL, V45, P337, DOI 10.1016/S0010-0285(02)00500-5
   Johnson K., 1997, TALKER VARIABILITY S, P145, DOI DOI 10.1017/S1366728914000790
   Johnson K, 2006, J PHONETICS, V34, P485, DOI 10.1016/j.wocn.2005.08.004
   JUSCZYK PW, 1992, COGNITION, V43, P253, DOI 10.1016/0010-0277(92)90014-9
   JUSCZYK PW, 1993, J PHONETICS, V21, P3, DOI 10.1016/S0095-4470(19)31319-1
   Kam CLH, 2005, LANG LEARN DEV, V1, P151, DOI 10.1207/s15473341lld0102_3
   Kamide Y, 2012, COGNITION, V124, P66, DOI 10.1016/j.cognition.2012.03.001
   KELLY MH, 1992, PSYCHOL REV, V99, P349, DOI 10.1037/0033-295X.99.2.349
   Kitamura C, 2013, CHILD DEV, V84, P1686, DOI 10.1111/cdev.12068
   Koenig MA, 2005, CHILD DEV, V76, P1261, DOI 10.1111/j.1467-8624.2005.00849.x
   Kopcke KM, 1998, J CHILD LANG, V25, P293, DOI 10.1017/S0305000998003407
   Kovacs AM, 2009, SCIENCE, V325, P611, DOI 10.1126/science.1173947
   Kraljic T, 2007, J MEM LANG, V56, P1, DOI 10.1016/j.jml.2006.07.010
   Kuhl P. K., 1988, HUMAN EVOL, V3, P19, DOI DOI 10.1007/BF02436589
   Labov W., 1973, SOCIOLINGUISTIC PATT
   Labov W, 2008, IMPACT, V24, P315
   Lew-Williams C, 2010, J MEM LANG, V63, P447, DOI 10.1016/j.jml.2010.07.003
   Li FF, 2016, J PHONETICS, V57, P59, DOI 10.1016/j.wocn.2016.05.004
   Li P., 2008, P 30 ANN C COGN SCI, P1900
   Liu LQ, 2014, COGNITION, V133, P385, DOI 10.1016/j.cognition.2014.06.004
   MacDonald P, 1999, J EXP EDUC, V67, P367, DOI 10.1080/00220979909598489
   Magnuson JS, 2007, J EXP PSYCHOL HUMAN, V33, P391, DOI 10.1037/0096-1523.33.2.391
   Mani N, 2010, INFANCY, V15, P445, DOI 10.1111/j.1532-7078.2009.00027.x
   Mareschal D, 2001, TRENDS COGN SCI, V5, P443, DOI 10.1016/S1364-6613(00)01752-6
   McLennan CT, 2006, LANG SPEECH, V49, P113, DOI 10.1177/00238309060490010701
   Mehler J, 1996, SIGNAL TO SYNTAX: BOOTSTRAPPING FROM SPEECH TO GRAMMAR IN EARLY ACQUISITION, P101
   Mintz TH, 2003, COGNITION, V90, P91, DOI 10.1016/S0010-0277(03)00140-9
   Montrul S, 2008, LANG LEARN, V58, P503, DOI 10.1111/j.1467-9922.2008.00449.x
   MORGAN JL, 1987, COGNITIVE PSYCHOL, V19, P498, DOI 10.1016/0010-0285(87)90017-X
   Mullennix JW, 2010, APPL COGNITIVE PSYCH, V24, P513, DOI 10.1002/acp.1566
   NELSON DGK, 1995, INFANT BEHAV DEV, V18, P111
   Newman RS, 2008, CURR DIR PSYCHOL SCI, V17, P229, DOI 10.1111/j.1467-8721.2008.00580.x
   NYGAARD LC, 1995, PERCEPT PSYCHOPHYS, V57, P989, DOI 10.3758/BF03205458
   Quam C, 2017, LAB PHONOL, V8, DOI 10.5334/labphon.25
   Quam C, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169001
   Remez RE, 1997, J EXP PSYCHOL HUMAN, V23, P651, DOI 10.1037/0096-1523.23.3.651
   Rische JL, 2016, COGNITIVE PSYCHOL, V84, P1, DOI 10.1016/j.cogpsych.2015.10.001
   Rost GC, 2010, INFANCY, V15, P608, DOI 10.1111/j.1532-7078.2010.00033.x
   Saffran J, 2008, COGNITION, V107, P479, DOI 10.1016/j.cognition.2007.10.010
   Schuler Katherine, 2016, P ANN M COGNITIVE SC, P2321
   Sebastian-Galles N, 2012, PSYCHOL SCI, V23, P994, DOI 10.1177/0956797612436817
   Seidl A, 2006, DEVELOPMENTAL SCI, V9, P565, DOI 10.1111/j.1467-7687.2006.00534.x
   Seidl A, 2014, LANG LEARN DEV, V10, P297, DOI 10.1080/15475441.2013.858575
   Shi RS, 2014, CHILD DEV PERSPECT, V8, P6, DOI 10.1111/cdep.12052
   Singh L, 2008, LANG LEARN DEV, V4, P157, DOI 10.1080/15475440801922131
   Singleton JL, 2004, COGNITIVE PSYCHOL, V49, P370, DOI 10.1016/j.cogpsych.2004.05.001
   Soderstrom M, 2007, INFANCY, V12, P1, DOI 10.1111/j.1532-7078.2007.tb00231.x
   Sundara M, 2011, J PHONETICS, V39, P505, DOI 10.1016/j.wocn.2010.08.006
   Thiessen ED, 2013, COGNITIVE SCI, V37, P310, DOI 10.1111/cogs.12011
   VALIAN V, 1988, J MEM LANG, V27, P71, DOI 10.1016/0749-596X(88)90049-6
   van Heugten M, 2012, J SPEECH LANG HEAR R, V55, P554, DOI 10.1044/1092-4388(2011/10-0347)
   Ward CD, 1999, DEV PSYCHOBIOL, V35, P49, DOI 10.1002/(SICI)1098-2302(199907)35:1<49::AID-DEV7>3.0.CO;2-3
   Weiss D.J., 2015, IMPLICIT EXPLICIT LE, P167, DOI DOI 10.1075/SIBIL.48.08WEI01915.X
   Weiss DJ, 2009, LANG LEARN DEV, V5, P30, DOI 10.1080/15475440802340101
   Werker JF, 2005, LANG LEARN DEV, V1, P197, DOI 10.1080/15475441.2005.9684216
   White L, 2014, LANG LEARN, V64, P27, DOI 10.1111/lang.12060
NR 94
TC 7
Z9 6
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0010-0285
EI 1095-5623
J9 COGNITIVE PSYCHOL
JI Cogn. Psychol.
PD NOV
PY 2018
VL 106
BP 1
EP 20
DI 10.1016/j.cogpsych.2018.04.003
PG 20
WC Psychology; Psychology, Experimental
SC Psychology
GA GX5VQ
UT WOS:000447819500001
PM 30121306
DA 2021-02-24
ER

PT J
AU Kleckner, IR
   Anderson, EC
   Betz, NJ
   Wormwood, JB
   Eskew, RT
   Barrett, LF
AF Kleckner, Ian R.
   Anderson, Eric C.
   Betz, Nicole J.
   Wormwood, Jolie B.
   Eskew, Rhea T., Jr.
   Barrett, Lisa Feldman
TI Conscious awareness is necessary for affective faces to influence social
   judgments
SO JOURNAL OF EXPERIMENTAL SOCIAL PSYCHOLOGY
LA English
DT Article
DE Consciousness; Emotions; Social perception; Individual differences;
   Perception
ID VISUAL AWARENESS; SUPPRESSION; ACCURACY; FEEL; TASK
AB A growing body of research claims that stimuli presented outside conscious awareness can influence affect, speech perception, decision-making, eating behavior, and social judgments. However, research has shown that conscious awareness is a continuous phenomenon. Using a continuous flash suppression (CFS) paradigm to suppress awareness of affective faces (smiling and scowling), we demonstrate that some awareness of suppressed stimuli is required for the stimuli to influence social judgments. We discovered this using a rigorous within participants psychophysics method that allowed us to assess awareness at very low levels, which is difficult using traditional methods. Our findings place boundary conditions on claims (made previously by us and others) that stimuli presented completely outside conscious awareness influence judgments. This work contributes to the literature highlighting the need to study conscious awareness as a continuous phenomenon and provides a framework for researchers to ask and answer questions regarding conscious awareness and its relation to judgment and behavior.
C1 [Kleckner, Ian R.; Anderson, Eric C.; Betz, Nicole J.; Wormwood, Jolie B.; Eskew, Rhea T., Jr.; Barrett, Lisa Feldman] Northeastern Univ, Dept Psychol, Boston, MA 02115 USA.
   [Kleckner, Ian R.] Univ Rochester, Med Ctr, Rochester, NY 14642 USA.
   [Anderson, Eric C.] Maine Med Ctr, Ctr Outcomes Res & Evaluat, Portland, ME 04102 USA.
   [Anderson, Eric C.] Tufts Univ, Sch Med, Boston, MA 02111 USA.
   [Barrett, Lisa Feldman] Harvard Med Sch, Massachusetts Gen Hosp, Dept Psychiat, Boston, MA USA.
   [Barrett, Lisa Feldman] Harvard Med Sch, Massachusetts Gen Hosp, Martinos Ctr Biomed Imaging, Boston, MA USA.
RP Kleckner, IR (corresponding author), Univ Rochester, Med Ctr, Dept Surg, 265 Crittenden Blvd,Box CU 420658, Rochester, NY 14642 USA.
EM Ian_Kleckner@URMC.Rochester.edu
RI Barrett, Lisa Feldman/ABC-8157-2020
FU National Institute of Mental HealthUnited States Department of Health &
   Human ServicesNational Institutes of Health (NIH) - USANIH National
   Institute of Mental Health (NIMH) [F32MH096533]; National Cancer
   Institute awards [R25 CA102618, U10 CA037420, K07CA221931]; National
   Science FoundationNational Science Foundation (NSF) [BCS - 1353338, BCS
   - 1422327, BCS 1052790]; National Institutes of Health Director's
   Pioneer AwardUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USA [DP1OD003312]; NATIONAL CANCER
   INSTITUTEUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Cancer Institute (NCI)
   [K07CA221931, U01CA193632, UG1CA189961, R25CA102618, R25CA102618,
   U01CA193632, U01CA193632, R25CA102618, UG1CA189961, UG1CA189961,
   U01CA193632, U01CA193632, K07CA221931] Funding Source: NIH RePORTER
FX We acknowledge the following people for helping with data acquisition:
   Anthony Aguaza, Melissa Broughton, Casey Burns, Dominique Cammarata,
   Maria Castano, Sean Colligan, Delaney Foley, Aileen Gabriel, Adam Giard,
   Lindsey Kurosu, Katie Levitsky, Samantha Lyons, Jess Nicolosi, Lauren
   Nisotel, Kayleigh O'Neill, Elijah Petter, Anais Rodriguez-Thompson,
   Savanna Santarpio, Anthony Siena, Samantha Sininsky, Mary Smith,
   Danielle Sorcher, Cynthia Tu, Trang Vo, Katherine Walsh, Leah Way,
   Amanda White, Maryann William, and Eunice Yo. We also thank Dr. Amber
   Kleckner for feedback on this manuscript. This research was supported by
   the National Institute of Mental Health post-doctoral award
   (F32MH096533) to I.R.K and the National Cancer Institute awards (R25
   CA102618, U10 CA037420, U10 CA037420, and K07CA221931) supporting
   I.R.K., National Science Foundation award (BCS - 1353338) to R.T.E,
   National Science Foundation award (BCS - 1422327) to J.B.W., and these
   awards to L.F.B: National Science Foundation grant (BCS 1052790), the
   National Institutes of Health Director's Pioneer Award (DP1OD003312).
   Development of the Interdisciplinary Affective Science Laboratory Face
   Set was supported by the National Institutes of Health Director's
   Pioneer Award (DP1OD003312) to Lisa Feldman Barrett. The study was
   designed by all the authors. The data were collected by I.R.K., E.C.A.,
   N.J.B., and J.B.W. The data were analyzed by I.R.K with input from all
   the authors. The manuscript was written by I.R.K., E.C.A., N.J.B., and
   J.B.W. with supervision from R.T.E. and L.F.B. All authors approved the
   final version of the manuscript for submission.
CR Anderson E, 2012, EMOTION, V12, P1210, DOI 10.1037/a0027514
   Ansorge U, 2005, J EXP PSYCHOL HUMAN, V31, P762, DOI 10.1037/0096-1523.31.4.762
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Dolman C. P., 1919, AM J OPHTHALMOL, V2, P867, DOI [10.1016/S0002-9394(19)90258-3, DOI 10.1016/S0002-9394(19)90258-3]
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Green D. M., 1966, SIGNAL DETECTION THE
   Hedger N, 2015, J EXP PSYCHOL HUMAN, V41, P798, DOI 10.1037/xhp0000051
   Kanai R, 2011, NAT REV NEUROSCI, V12, P231, DOI 10.1038/nrn3000
   Kang MS, 2011, J NEUROSCI, V31, P13535, DOI 10.1523/JNEUROSCI.1691-11.2011
   Kim CY, 2005, TRENDS COGN SCI, V9, P381, DOI 10.1016/j.tics.2005.06.012
   Kleiner M, 2007, PERCEPTION, V36, P14
   Li W, 2008, J COGNITIVE NEUROSCI, V20, P95
   Motulsky H., 2003, FITTING MODELS BIOLO
   Mudrik L, 2011, PSYCHOL SCI, V22, P764, DOI 10.1177/0956797611408736
   Overgaard M, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00116
   Pelli D. G., 1997, VIDEOTOOLBOX SOFTWAR
   Pessoa L, 2005, EMOTION, V5, P243, DOI 10.1037/1528-3542.5.2.243
   Plass J, 2014, PSYCHOL SCI, V25, P1835, DOI 10.1177/0956797614542132
   Ramsoy T., 2004, PHENOMENOL COGN SCI, V3, P1, DOI [10.1023/B:PHEN.0000041900.30172.e8, DOI 10.1023/B:PHEN.0000041900.30172.E8]
   Rouder JN, 2009, PSYCHOL REV, V116, P655, DOI 10.1037/a0016413
   Sandberg K, 2011, CONSCIOUS COGN, V20, P1659, DOI 10.1016/j.concog.2011.09.002
   Siegel EH, 2018, PSYCHOL SCI, V29, P496, DOI 10.1177/0956797617741718
   Tamietto M, 2015, CORTEX, V62, P56, DOI 10.1016/j.cortex.2014.10.009
   Tsuchiya N, 2005, NAT NEUROSCI, V8, P1096, DOI 10.1038/nn1500
   Vlassova A, 2014, P NATL ACAD SCI USA, V111, P16214, DOI 10.1073/pnas.1403619111
   Wickens T.D., 2002, ELEMENTARY SIGNAL DE
   Winkielman P, 2004, CURR DIR PSYCHOL SCI, V13, P120, DOI 10.1111/j.0963-7214.2004.00288.x
   Yang E, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00724
NR 28
TC 4
Z9 4
U1 2
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 0022-1031
EI 1096-0465
J9 J EXP SOC PSYCHOL
JI J. Exp. Soc. Psychol.
PD NOV
PY 2018
VL 79
BP 181
EP 187
DI 10.1016/j.jesp.2018.07.013
PG 7
WC Psychology, Social
SC Psychology
GA GX9BI
UT WOS:000448093100018
PM 31097841
OA Green Accepted
DA 2021-02-24
ER

PT J
AU Bent, T
AF Bent, Tessa
TI Development of unfamiliar accent comprehension continues through
   adolescence
SO JOURNAL OF CHILD LANGUAGE
LA English
DT Article
DE non-native accents; speech perception; language development
ID CHILDRENS PERCEPTION; MULTIPLE ACCENTS; WORD RECOGNITION; REGIONAL
   ACCENT; SPEECH; CATEGORIZATION; ADAPTATION; EXPOSURE; TODDLERS; ENGLISH
AB School-age children's understanding of unfamiliar accents is not adult-like and the age at which this ability fully matures is unknown. To address this gap, eight- to fifteen-year-old children's (n = 74) understanding of native- and non-native-accented sentences in quiet and noise was assessed. Children's performance was adult-like by eleven to twelve years for the native accent in noise and by fourteen to fifteen years for the non-native accent in quiet. However, fourteen- to fifteen-year old's performance was not adult-like for the non-native accent in noise. Thus, adult-like comprehension of unfamiliar accents may require greater exposure to linguistic variability or additional cognitive-linguistic growth.
C1 [Bent, Tessa] Indiana Univ, Dept Speech & Hearing Sci, 200 S Jordan Ave, Bloomington, IN 47405 USA.
RP Bent, T (corresponding author), Indiana Univ, Dept Speech & Hearing Sci, 200 S Jordan Ave, Bloomington, IN 47405 USA.
EM tbent@indiana.edu
CR Atagi E, 2015, J ACOUST SOC AM, V137, pEL44, DOI 10.1121/1.4903916
   Baese-Berk MM, 2013, J ACOUST SOC AM, V133, pEL174, DOI 10.1121/1.4789864
   Banks B, 2015, J ACOUST SOC AM, V137, P2015, DOI 10.1121/1.4916265
   Bent T, 2017, LANG SPEECH, V60, P110, DOI 10.1177/0023830916645374
   Bent T, 2015, J ACOUST SOC AM, V138, P3985, DOI 10.1121/1.4938228
   Bent T, 2014, J CHILD LANG, V41, P1334, DOI 10.1017/S0305000913000457
   Best CT, 2009, PSYCHOL SCI, V20, P539, DOI 10.1111/j.1467-9280.2009.02327.x
   Buckler H, 2017, J EXP CHILD PSYCHOL, V164, P87, DOI 10.1016/j.jecp.2017.06.017
   Butler J, 2011, INFANCY, V16, P392, DOI 10.1111/j.1532-7078.2010.00050.x
   CARLISLE RS, 1991, APPL LINGUIST, V12, P76, DOI 10.1093/applin/12.1.76
   Coch D, 2005, J COGNITIVE NEUROSCI, V17, P605, DOI 10.1162/0898929053467631
   Creel SC, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12524
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   Flege JE, 1997, J PHONETICS, V25, P437, DOI 10.1006/jpho.1997.0052
   Floccia C, 2009, INT J BEHAV DEV, V33, P366, DOI 10.1177/0165025409103871
   Gathercole SE, 1999, TRENDS COGN SCI, V3, P410, DOI 10.1016/S1364-6613(99)01388-1
   Goldman R, 2000, GOLDMAN FRISTOE TEST
   Hazan V, 2000, J PHONETICS, V28, P377, DOI 10.1006/jpho.2000.0121
   Huyck JJ, 2011, DEVELOPMENTAL SCI, V14, P614, DOI 10.1111/j.1467-7687.2010.01009.x
   Johnson CE, 2000, J SPEECH LANG HEAR R, V43, P144, DOI 10.1044/jslhr.4301.144
   Jones Z, 2017, J PHONETICS, V60, P20, DOI 10.1016/j.wocn.2016.11.001
   Kinzler KD, 2007, P NATL ACAD SCI USA, V104, P12577, DOI 10.1073/pnas.0705345104
   Kinzler KD, 2013, Q J EXP PSYCHOL, V66, P1146, DOI 10.1080/17470218.2012.731695
   Kinzler KD, 2011, DEVELOPMENTAL SCI, V14, P106, DOI 10.1111/j.1467-7687.2010.00965.x
   Kleinschmidt DF, 2015, PSYCHOL REV, V122, P148, DOI 10.1037/a0038695
   McQueen JM, 2012, LANG LEARN DEV, V8, P317, DOI 10.1080/15475441.2011.641887
   Mulak KE, 2013, CHILD DEV, V84, P2064, DOI 10.1111/cdev.12087
   Nathan L, 1998, J CHILD LANG, V25, P343, DOI 10.1017/S0305000998003444
   Nilsson M. J., 1996, DEV HEARING NOISE TE
   OCONNOR C, 2011, J CLIN SPEECH LANGUA, V18, P1
   Pierrehumbert JB, 2016, ANNU REV LINGUIST, V2, P33, DOI 10.1146/annurev-linguistics-030514-125050
   Porretta V, 2016, J PHONETICS, V58, P1, DOI 10.1016/j.wocn.2016.05.006
   Potter CE, 2017, COGNITION, V166, P67, DOI 10.1016/j.cognition.2017.05.031
   Rogers CL, 2004, LANG SPEECH, V47, P139, DOI 10.1177/00238309040470020201
   Segbers J, 2017, LANG TEST, V34, P297, DOI 10.1177/0265532216641152
   Seidl A, 2012, FRONT PSYCHOL, V3, DOI [10.3389/fpsyg.2012.00448, 10.3389/fpsyg.2012.00479]
   Sereno J, 2016, APPL PSYCHOLINGUIST, V37, P303, DOI 10.1017/S0142716414000575
   STUDEBAKER GA, 1985, J SPEECH HEAR RES, V28, P455, DOI 10.1044/jshr.2803.455
   Sumner M, 2011, COGNITION, V119, P131, DOI 10.1016/j.cognition.2010.10.018
   van Heugten M, 2017, J ACOUST SOC AM, V142, pEL196, DOI 10.1121/1.4997604
   van Heugten M, 2016, LANG SPEECH, V59, P353, DOI 10.1177/0023830915600471
   Wagner L, 2014, J CHILD LANG, V41, P1062, DOI 10.1017/S0305000913000330
   White KS, 2011, DEVELOPMENTAL SCI, V14, P372, DOI 10.1111/j.1467-7687.2010.00986.x
NR 43
TC 3
Z9 3
U1 1
U2 4
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0305-0009
EI 1469-7602
J9 J CHILD LANG
JI J. Child Lang.
PD NOV
PY 2018
VL 45
IS 6
BP 1400
EP 1411
DI 10.1017/S0305000918000053
PG 12
WC Psychology, Developmental; Linguistics; Psychology, Experimental
SC Psychology; Linguistics
GA GW1XN
UT WOS:000446676000008
PM 29619915
OA Bronze
DA 2021-02-24
ER

PT J
AU Bernier, DE
   Soderstrom, M
AF Bernier, Dana E.
   Soderstrom, Melanie
TI Was that my name? Infants' listening in conversational multi-talker
   backgrounds
SO JOURNAL OF CHILD LANGUAGE
LA English
DT Article
DE infant speech perception; speech in noise; infant-directed speech
ID SPEECH-SOUND DISCRIMINATION; ENVIRONMENTS; RECOGNITION; THRESHOLDS;
   FEATURES; MASKING; NOISE; READ; ME
AB This study tested infants' ability to segregate target speech from a background of ecologically valid multi-talker speech at a 10 dB SNR. Using the Headturn Preference Procedure, 72 English-learning 5-, 9-, and 12-month-old monolinguals were tested on their ability to detect and perceive their own name. At all three ages infants were able to detect the presence of the target speech, but only at 9 months did they show sensitivity to the phonetic details that distinguished their own name from other names. These results extend previous findings on infants' speech perception in noise to more naturalistic forms of background speech.
C1 [Bernier, Dana E.] Univ Waterloo, Dept Psychol, 200 Univ Ave West,PAS 3020, Waterloo, ON N2L 3G1, Canada.
   [Soderstrom, Melanie] Univ Manitoba, Dept Psychol, P404 Duff Roblin Bldg,190 Dysart Rd, Winnipeg, MB R3T 2N2, Canada.
RP Bernier, DE (corresponding author), Univ Waterloo, Dept Psychol, 200 Univ Ave West,PAS 3020, Waterloo, ON N2L 3G1, Canada.
EM dbernier@uwaterloo.ca
OI Forth, Richard/0000-0002-1896-8808; Soderstrom,
   Melanie/0000-0003-3212-5775
FU University of Manitoba; NSERCNatural Sciences and Engineering Research
   Council of Canada (NSERC) [371683-2010]
FX We would like to thank the participating families and the members of the
   Baby Language Lab, especially Robin O'Hagan, Jacquelyn Klassen, Alex
   Holt, and Laurisa Adams. We would also like to thank Manitoba Health for
   their assistance with participant recruitment. The results and
   conclusions are those of the authors and no official endorsement by
   Manitoba Health is intended or should be inferred. This research was
   funded by the University of Manitoba, and NSERC Discovery grant
   371683-2010 to the second author.
CR Barker BA, 2004, COGNITION, V94, pB45, DOI 10.1016/j.cognition.2004.06.001
   Batliner A, 1995, SPEECH RECOGNITION C, P321
   Bernier D. E., 2014, DEV 2014 CAN C DEV P
   BLAAUW E, 1994, SPEECH COMMUN, V14, P359, DOI 10.1016/0167-6393(94)90028-0
   Boersma P., 2014, PRAAT DOING PHONETIC
   Bortfeld H, 2005, PSYCHOL SCI, V16, P298, DOI 10.1111/j.0956-7976.2005.01531.x
   Bouchon C, 2015, DEVELOPMENTAL SCI, V18, P587, DOI 10.1111/desc.12242
   BROADBENT DE, 1952, J EXP PSYCHOL, V44, P51, DOI 10.1037/h0056491
   CHERRY EC, 1954, J ACOUST SOC AM, V26, P554, DOI 10.1121/1.1907373
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   Greenwood CR, 2011, COMM DISORD Q, V32, P83, DOI 10.1177/1525740110367826
   HIRSH IJ, 1950, J ACOUST SOC AM, V22, P196, DOI 10.1121/1.1906588
   Laan GPM, 1997, SPEECH COMMUN, V22, P43, DOI 10.1016/S0167-6393(97)00012-5
   LEEK MR, 1991, PERCEPT PSYCHOPHYS, V50, P205, DOI 10.3758/BF03206743
   LEVIN H, 1982, LANG SPEECH, V25, P43, DOI 10.1177/002383098202500104
   MANDEL DR, 1995, PSYCHOL SCI, V6, P314, DOI 10.1111/j.1467-9280.1995.tb00517.x
   McMillan BTM, 2016, CHILD DEV, V87, P1841, DOI 10.1111/cdev.12559
   Mertus J., 2011, WELCOME BLISS BROWN
   Miller G. A., 1947, PSYCHOL BULL, V51, P327
   Newman RS, 2006, INFANCY, V10, P61, DOI 10.1207/s15327078in1001_4
   Newman RS, 2011, INFANCY, V16, P447, DOI 10.1111/j.1532-7078.2010.00062.x
   Newman RS, 2009, ATTEN PERCEPT PSYCHO, V71, P822, DOI 10.3758/APP.71.4.822
   Newman RS, 2005, DEV PSYCHOL, V41, P352, DOI 10.1037/0012-1649.41.2.352
   Newman RS, 1996, PERCEPT PSYCHOPHYS, V58, P1145, DOI 10.3758/BF03207548
   NOZZA RJ, 1990, J ACOUST SOC AM, V87, P339, DOI 10.1121/1.399301
   NOZZA RJ, 1988, J SPEECH HEAR RES, V31, P212, DOI 10.1044/jshr.3102.212
   NOZZA RJ, 1991, AUDIOLOGY, V30, P102
   NOZZA RJ, 1984, J SPEECH HEAR RES, V27, P613, DOI 10.1044/jshr.2704.613
   NOZZA RJ, 1991, J SPEECH HEAR RES, V34, P643, DOI 10.1044/jshr.3403.643
   POLLACK I, 1958, J ACOUST SOC AM, V30, P131, DOI 10.1121/1.1909505
   POULTON EC, 1953, J EXP PSYCHOL, V46, P91, DOI 10.1037/h0057873
   Shultz S, 2010, LANG LEARN DEV, V6, P241, DOI 10.1080/15475440903507830
   SINNOTT JM, 1983, INFANT BEHAV DEV, V6, P3, DOI 10.1016/S0163-6383(83)80003-4
   Smith NA, 2011, INFANCY, V16, P655, DOI 10.1111/j.1532-7078.2011.00067.x
   TREHUB SE, 1981, J SPEECH HEAR RES, V24, P202, DOI 10.1044/jshr.2402.202
   Vouloumanos A, 2004, DEVELOPMENTAL SCI, V7, P270, DOI 10.1111/j.1467-7687.2004.00345.x
   Werner LA, 2001, J ACOUST SOC AM, V109, P2103, DOI 10.1121/1.1365112
NR 37
TC 7
Z9 7
U1 1
U2 3
PU CAMBRIDGE UNIV PRESS
PI NEW YORK
PA 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA
SN 0305-0009
EI 1469-7602
J9 J CHILD LANG
JI J. Child Lang.
PD NOV
PY 2018
VL 45
IS 6
BP 1439
EP 1449
DI 10.1017/S0305000918000247
PG 11
WC Psychology, Developmental; Linguistics; Psychology, Experimental
SC Psychology; Linguistics
GA GW1XN
UT WOS:000446676000011
PM 28961020
OA Bronze
DA 2021-02-24
ER

PT J
AU Alexandrou, AM
   Saarinen, T
   Kujala, J
   Salmelin, R
AF Alexandrou, Anna Maria
   Saarinen, Timo
   Kujala, Jan
   Salmelin, Riitta
TI Cortical Tracking of Global and Local Variations of Speech Rhythm during
   Connected Natural Speech Perception
SO JOURNAL OF COGNITIVE NEUROSCIENCE
LA English
DT Article; Proceedings Paper
CT 24th Annual Meeting of Cognitive-Neuroscience-Society (CNS) on Dynamics
   of Cognitive Processes - Multivariate Approaches
CY MAR 25-28, 2017
CL San Francisco, CA
SP Cognit Neurosci Soc
ID LOW-FREQUENCY OSCILLATIONS; HUMAN AUDITORY-CORTEX; NEURONAL
   OSCILLATIONS; ARTICULATION RATE; RIGHT-HEMISPHERE; SPEAKING RATE;
   COMPRESSED SPEECH; PERCEIVED SPEECH; ATTENDED SPEECH; PRIOR KNOWLEDGE
AB During natural speech perception, listeners must track the global speaking rate, that is, the overall rate of incoming linguistic information, as well as transient, local speaking rate variations occurring within the global speaking rate. Here, we address the hypothesis that this tracking mechanism is achieved through coupling of cortical signals to the amplitude envelope of the perceived acoustic speech signals. Cortical signals were recorded with magnetoencephalography (MEG) while participants perceived spontaneously produced speech stimuli at three global speaking rates (slow, normal/habitual, and fast). Inherently to spontaneously produced speech, these stimuli also featured local variations in speaking rate. The coupling between cortical and acoustic speech signals was evaluated using audio-MEG coherence. Modulations in audio-MEG coherence spatially differentiated between tracking of global speaking rate, highlighting the temporal cortex bilaterally and the right parietal cortex, and sensitivity to local speaking rate variations, emphasizing the left parietal cortex. Cortical tuning to the temporal structure of natural connected speech thus seems to require the joint contribution of both auditory and parietal regions. These findings suggest that cortical tuning to speech rhythm operates on two functionally distinct levels: one encoding the global rhythmic structure of speech and the other associated with online, rapidly evolving temporal predictions. Thus, it may be proposed that speech perception is shaped by evolutionary tuning, a preference for certain speaking rates, and predictive tuning, associated with cortical tracking of the constantly changing-rate of linguistic information in a speech stream.
C1 [Alexandrou, Anna Maria; Saarinen, Timo; Kujala, Jan; Salmelin, Riitta] Aalto Univ, Aalto, Finland.
RP Alexandrou, AM (corresponding author), Aalto Yliopisto Perustieteiden Korkeakoulu, Dept Neurosci & Biomed Engn, Rakentajanaukio 2C, Aalto 00076, Finland.
EM anna.alexandrou@aalto.fi
RI Kujala, Jan/J-3092-2012; Salmelin, Riitta/I-7044-2012
OI Kujala, Jan/0000-0002-3056-753X; Salmelin, Riitta/0000-0003-2499-193X
FU Academy of FinlandAcademy of FinlandEuropean Commission [255349, 256459,
   283071, 257576]; Alfred Kordelin Foundation [160143]; Emil Aaltonen
   Foundation [170011 N1]; Finnish Cultural FoundationFinnish Cultural
   Foundation [00170944]; Sigrid Juselius FoundationSigrid Juselius
   Foundation
FX This work was financially supported by the Academy of Finland (Grants
   255349, 256459, and 283071 to R. S. and Grant 257576 to J. K.), the
   Alfred Kordelin Foundation (Grant 160143 to A. A.), the Emil Aaltonen
   Foundation (Grant 170011 N1 to A. A.), the Finnish Cultural Foundation
   (Grant 00170944 to T. S.), and the Sigrid Juselius Foundation (grant to
   R. S.). MEG and MRI data were recorded at the Aalto Neurolmaging
   research infrastructure.
CR Ahissar E, 2001, P NATL ACAD SCI USA, V98, P13367, DOI 10.1073/pnas.201400998
   Aiken SJ, 2008, EAR HEARING, V29, P139, DOI 10.1097/AUD.0b013e31816453dc
   Alexandrou AM, 2017, NEUROIMAGE, V152, P628, DOI 10.1016/j.neuroimage.2017.03.006
   Alexandrou AM, 2016, J ACOUST SOC AM, V139, P215, DOI 10.1121/1.4939496
   Andersen RA, 2002, ANNU REV NEUROSCI, V25, P189, DOI 10.1146/annurev.neuro.25.112701.142922
   Arnal LH, 2012, TRENDS COGN SCI, V16, P390, DOI 10.1016/j.tics.2012.05.003
   Baese-Berk MM, 2014, PSYCHOL SCI, V25, P1546, DOI 10.1177/0956797614533705
   Bar M, 2007, TRENDS COGN SCI, V11, P280, DOI 10.1016/j.tics.2007.05.005
   Bekinschtein TA, 2009, P NATL ACAD SCI USA, V106, P1672, DOI 10.1073/pnas.0809667106
   Belin P, 2004, TRENDS COGN SCI, V8, P129, DOI 10.1016/j.tics.2004.01.008
   Bonte ML, 2005, CLIN NEUROPHYSIOL, V116, P2765, DOI 10.1016/j.clinph.2005.08.012
   Bourguignon M, 2013, HUM BRAIN MAPP, V34, P314, DOI 10.1002/hbm.21442
   Brennan SE, 2001, J MEM LANG, V44, P274, DOI 10.1006/jmla.2000.2753
   Brown M., 2012, P 34 ANN C COGN SCI, P1374
   Byrd D., 2000, PAPERS LAB PHONOLOGY, P70
   Calderone DJ, 2014, TRENDS COGN SCI, V18, P300, DOI 10.1016/j.tics.2014.02.005
   CHAWLA P, 1994, J EXP SOC PSYCHOL, V30, P580, DOI 10.1006/jesp.1994.1027
   Cravo AM, 2013, J NEUROSCI, V33, P4002, DOI 10.1523/JNEUROSCI.4675-12.2013
   Demanuele C, 2007, BEHAV BRAIN FUNCT, V3, DOI 10.1186/1744-9081-3-62
   Dilley LC, 2010, PSYCHOL SCI, V21, P1664, DOI 10.1177/0956797610384743
   Doelling KB, 2014, NEUROIMAGE, V85, P761, DOI 10.1016/j.neuroimage.2013.06.035
   Dupoux E, 1997, J EXP PSYCHOL HUMAN, V23, P914, DOI 10.1037/0096-1523.23.3.914
   Engel AK, 2001, NAT REV NEUROSCI, V2, P704, DOI 10.1038/35094565
   Federmeier KD, 2008, LANG LINGUIST COMPAS, V2, P1, DOI 10.1111/j.1749-818x.2007.00042.x
   Finke M, 1997, INT CONF ACOUST SPEE, P1743, DOI 10.1109/ICASSP.1997.598861
   Fischl B, 1999, HUM BRAIN MAPP, V8, P272, DOI 10.1002/(SICI)1097-0193(1999)8:4<272::AID-HBM10>3.0.CO;2-4
   Fischl B, 2012, NEUROIMAGE, V62, P774, DOI 10.1016/j.neuroimage.2012.01.021
   Assaneo MF, 2016, NEUROIMAGE, V141, P31, DOI 10.1016/j.neuroimage.2016.07.033
   Fougeron C, 1998, J PHONETICS, V26, P45, DOI 10.1006/jpho.1997.0062
   Fries P, 2005, TRENDS COGN SCI, V9, P474, DOI 10.1016/j.tics.2005.08.011
   Friston KJ, 2012, INT J PSYCHOPHYSIOL, V83, P248, DOI 10.1016/j.ijpsycho.2011.11.014
   Ghazanfar AA, 2013, P NATL ACAD SCI USA, V110, P1959, DOI 10.1073/pnas.1214956110
   Ghinst MV, 2016, J NEUROSCI, V36, P1596, DOI 10.1523/JNEUROSCI.1730-15.2016
   Ghitza O, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00238
   Ghitza O, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00130
   Giordano BL, 2017, ELIFE, V6, DOI 10.7554/eLife.24763
   Giraud AL, 2012, NAT NEUROSCI, V15, P511, DOI 10.1038/nn.3063
   Golumbic EMZ, 2013, NEURON, V77, P980, DOI 10.1016/j.neuron.2012.12.037
   GROSJEAN F, 1976, J EXP PSYCHOL HUMAN, V2, P538, DOI 10.1037/0096-1523.2.4.538
   Gross J, 2001, P NATL ACAD SCI USA, V98, P694, DOI 10.1073/pnas.98.2.694
   Gross J, 2013, PLOS BIOL, V11, DOI 10.1371/journal.pbio.1001752
   Gutig R, 2009, PLOS BIOL, V7, DOI 10.1371/journal.pbio.1000141
   Hari R, 2009, PHYSIOL REV, V89, P453, DOI 10.1152/physrev.00041.2007
   Hasson U, 2008, J NEUROSCI, V28, P2539, DOI 10.1523/JNEUROSCI.5487-07.2008
   Hertrich I, 2013, BRAIN LANG, V124, P9, DOI 10.1016/j.bandl.2012.10.006
   Hertrich I, 2012, PSYCHOPHYSIOLOGY, V49, P322, DOI 10.1111/j.1469-8986.2011.01314.x
   Jacewicz E, 2009, LANG VAR CHANGE, V21, P233, DOI 10.1017/S0954394509990093
   Janse E, 2004, SPEECH COMMUN, V42, P155, DOI 10.1016/j.specom.2003.07.001
   Janse E, 2003, SPEECH COMMUN, V41, P287, DOI 10.1016/S0167-6393(02)00130-9
   Kayser SJ, 2015, J NEUROSCI, V35, P14691, DOI 10.1523/JNEUROSCI.2243-15.2015
   Keitel A, 2017, NEUROIMAGE, V147, P32, DOI 10.1016/j.neuroimage.2016.11.062
   Kiebel SJ, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000209
   Koreman J, 2006, J ACOUST SOC AM, V119, P582, DOI 10.1121/1.2133436
   Kriegstein KV, 2004, NEUROIMAGE, V22, P948, DOI 10.1016/j.neuroimage.2004.02.020
   Kujala J, 2007, CEREB CORTEX, V17, P1476, DOI 10.1093/cercor/bhl059
   Lakatos P, 2008, SCIENCE, V320, P110, DOI 10.1126/science.1154735
   Lancaster JL, 2000, HUM BRAIN MAPP, V10, P120, DOI 10.1002/1097-0193(200007)10:3<120::AID-HBM30>3.0.CO;2-8
   LASKY EZ, 1976, BRAIN LANG, V3, P386, DOI 10.1016/0093-934X(76)90034-1
   Lerner Y, 2014, J NEUROPHYSIOL, V111, P2433, DOI 10.1152/jn.00497.2013
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1
   Liberman AM, 2000, TRENDS COGN SCI, V4, P187, DOI 10.1016/S1364-6613(00)01471-6
   LIBERMAN AM, 1956, J EXP PSYCHOL, V52, P127, DOI 10.1037/h0041240
   LIEBERMAN P, 1963, LANG SPEECH, V6, P172, DOI 10.1177/002383096300600306
   Luo H, 2007, NEURON, V54, P1001, DOI 10.1016/j.neuron.2007.06.004
   Maguire EA, 1999, BRAIN, V122, P1839, DOI 10.1093/brain/122.10.1839
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   Meyer L, 2017, CEREB CORTEX, V27, P4293, DOI 10.1093/cercor/bhw228
   MILLER JL, 1984, PHONETICA, V41, P215, DOI 10.1159/000261728
   MILLER JL, 1984, PERCEPT PSYCHOPHYS, V36, P329, DOI 10.3758/BF03202785
   Molinaro N, 2016, HUM BRAIN MAPP, V37, P2767, DOI 10.1002/hbm.23206
   Morillon B, 2015, ANN NY ACAD SCI, V1337, P26, DOI 10.1111/nyas.12629
   Morrill RJ, 2012, DEVELOPMENTAL SCI, V15, P557, DOI 10.1111/j.1467-7687.2012.01149.x
   NAKAJIMA S, 1993, PHONETICA, V50, P197, DOI 10.1159/000261940
   Nobrel AC, 2007, CURR OPIN NEUROBIOL, V17, P465, DOI 10.1016/j.conb.2007.07.006
   Park H, 2015, CURR BIOL, V25, P1649, DOI 10.1016/j.cub.2015.04.049
   Peelle JE, 2013, CEREB CORTEX, V23, P1378, DOI 10.1093/cercor/bhs118
   Peelle JE, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00320
   Poeppel D, 2008, PHILOS T R SOC B, V363, P1071, DOI 10.1098/rstb.2007.2160
   Poeppel D, 2012, J NEUROSCI, V32, P14125, DOI 10.1523/JNEUROSCI.3244-12.2012
   Priva UC, 2017, COGNITION, V160, P27, DOI 10.1016/j.cognition.2016.12.002
   Puschmann S, 2017, J NEUROSCI, V37, P11505, DOI 10.1523/JNEUROSCI.1007-17.2017
   Quene H, 2007, J PHONETICS, V35, P353, DOI 10.1016/j.wocn.2006.09.001
   Ramus F, 1999, COGNITION, V73, P265, DOI 10.1016/S0010-0277(99)00058-X
   Reinisch E, 2016, APPL PSYCHOLINGUIST, V37, P1397, DOI 10.1017/S0142716415000612
   Rohenkohl G, 2012, J NEUROSCI, V32, P8424, DOI 10.1523/JNEUROSCI.0804-12.2012
   Ruspantini I, 2012, J NEUROSCI, V32, P3786, DOI 10.1523/JNEUROSCI.3191-11.2012
   Saarinen T, 2015, HUM BRAIN MAPP, V36, P2455, DOI 10.1002/hbm.22784
   Saleh M, 2010, NEURON, V65, P461, DOI 10.1016/j.neuron.2010.02.001
   Schroeder CE, 2008, TRENDS COGN SCI, V12, P106, DOI 10.1016/j.tics.2008.01.002
   Schroeder CE, 2010, CURR OPIN NEUROBIOL, V20, P172, DOI 10.1016/j.conb.2010.02.010
   Schwartze M, 2012, INT J PSYCHOPHYSIOL, V83, P200, DOI 10.1016/j.ijpsycho.2011.11.003
   Sepulcre J, 2012, J NEUROSCI, V32, P10649, DOI 10.1523/JNEUROSCI.0759-12.2012
   Small JA, 1997, AGING NEUROPSYCHOL C, V4, P126, DOI 10.1080/13825589708256641
   SMITH A, 1995, EXP BRAIN RES, V104, P493
   Sohoglu E, 2012, J NEUROSCI, V32, P8443, DOI 10.1523/JNEUROSCI.5069-11.2012
   St George M, 1999, BRAIN, V122, P1317, DOI 10.1093/brain/122.7.1317
   SUMMERFIELD Q, 1981, J EXP PSYCHOL HUMAN, V7, P1074, DOI 10.1037/0096-1523.7.5.1074
   Taulu S, 2006, PHYS MED BIOL, V51, P1759, DOI 10.1088/0031-9155/51/7/008
   Telkemeyer S, 2009, J NEUROSCI, V29, P14726, DOI 10.1523/JNEUROSCI.1246-09.2009
   ten Oever S, 2017, J NEUROSCI, V37, P4903, DOI 10.1523/JNEUROSCI.3658-16.2017
   Tilsen S, 2013, J ACOUST SOC AM, V134, P628, DOI 10.1121/1.4807565
   Tsao YC, 1997, J SPEECH LANG HEAR R, V40, P858, DOI 10.1044/jslhr.4004.858
   Uusitalo MA, 1997, MED BIOL ENG COMPUT, V35, P135, DOI 10.1007/BF02534144
   VOSS RF, 1975, NATURE, V258, P317, DOI 10.1038/258317a0
   Wild CJ, 2012, J NEUROSCI, V32, P14010, DOI 10.1523/JNEUROSCI.1528-12.2012
NR 105
TC 4
Z9 4
U1 1
U2 7
PU MIT PRESS
PI CAMBRIDGE
PA ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA
SN 0898-929X
EI 1530-8898
J9 J COGNITIVE NEUROSCI
JI J. Cogn. Neurosci.
PD NOV
PY 2018
VL 30
IS 11
BP 1704
EP 1719
DI 10.1162/jocn_a_01295
PG 16
WC Neurosciences; Psychology, Experimental
SC Neurosciences & Neurology; Psychology
GA GV1RV
UT WOS:000445859200011
PM 29916785
OA Green Published
DA 2021-02-24
ER

PT J
AU Gabay, Y
   Karni, A
   Banai, K
AF Gabay, Yafit
   Karni, Avi
   Banai, Karen
TI Learning to decipher time-compressed speech: Robust acquisition with a
   slight difficulty in generalization among young adults with
   developmental dyslexia
SO PLOS ONE
LA English
DT Article
ID ATTENTIONAL REQUIREMENTS; ADVERSE CONDITIONS; PERCEPTION; LANGUAGE;
   MEMORY; CHILDREN; SKILL; DISSOCIATION; RECOGNITION; SYSTEMS
AB Learning to decipher acoustically distorted speech serves as a test case for the study of language-related skill acquisition in persons with developmental dyslexia (DD). Deciphering this type of input is rarely learned explicitly and does not yield conscious insights. Problems in implicit and procedural skill learning have been proposed as possible causes of DD. Here we examined the learning of time-compressed (accelerated) speech and its generalization to novel materials among young adults with DD compared to typical readers (TD). All participants completed a training session that involved judging the semantic plausibility of sentences, during which the level of time-compression was changed using an adaptive (staircase) procedure according to each participant's performance. In the test, phase learning (test on same items) and generalization (test on new items and same items spoken by a new speaker) were assessed. Both groups showed robust gains after training. Moreover, after training, the initial disadvantage of the DD group was no longer significant. After training, both groups experienced relative difficulties in deciphering learned tokens spoken by a different voice, though participants with DD were less able to generalize the gains to deciphering new tokens. Thus, DD individuals benefited from repeated experience with time-compressed speech no less than typical readers, but their evolving skill was apparently more dependent on the specific characteristics of the tokens. Atypical generalization, which indicates that perceptual learning is contingent on lower-level features of the input though does not necessarily point to impaired learning potential per se, may explain some of the contradictory findings in published studies of speech perception in DD.
C1 [Gabay, Yafit] Univ Haifa, Dept Special Educ, Haifa, Israel.
   [Gabay, Yafit; Karni, Avi] Univ Haifa, Edmond J Safra Brain Res Ctr Study Learning Disab, Dept Learning Disabil, Haifa, Israel.
   [Karni, Avi] Univ Haifa, Sagol Dept Neurobiol, Haifa, Israel.
   [Banai, Karen] Univ Haifa, Dept Commun Sci & Disorders, Haifa, Israel.
RP Gabay, Y (corresponding author), Univ Haifa, Dept Special Educ, Haifa, Israel.; Gabay, Y (corresponding author), Univ Haifa, Edmond J Safra Brain Res Ctr Study Learning Disab, Dept Learning Disabil, Haifa, Israel.
EM yagabay@edu.haifa.ac.il
RI Banai, Karen/J-1448-2019; Gabay, Yafit/P-8315-2019
OI Banai, Karen/0000-0002-2990-0470; Gabay, Yafit/0000-0002-7899-3044
FU National Institute of Psychobiology in Israel, Hebrew University of
   Jerusalem [108-14-15]; National Institute of Psychobiology in Israel
FX This research was supported by a grant from the National Institute of
   Psychobiology in Israel, Hebrew University of Jerusalem, to KB,
   108-14-15.; This research was supported by a grant from the National
   Institute of Psychobiology in Israel to KB.
CR Adi-Japha E, 2011, RES DEV DISABIL, V32, P1011, DOI 10.1016/j.ridd.2011.01.048
   Agnew JA, 2004, BRAIN LANG, V88, P21, DOI 10.1016/S0093-934X(03)00157-3
   Agus TR, 2014, J SPEECH LANG HEAR R, V57, P1069, DOI 10.1044/1092-4388(2013/13-0020)
   Ashby FG, 1998, PSYCHOL REV, V105, P442, DOI 10.1037/0033-295X.105.3.442
   Banai K., 2009, LEARNING PERCEPTION, V1, P115, DOI DOI 10.1556/LP.1.2009.1.9
   Banai K, 2017, LANG COGN NEUROSCI, P1
   Banai K, 2018, LANG COGN NEUROSCI, V33, P321, DOI 10.1080/23273798.2017.1408851
   Banai K, 2016, J ACOUST SOC AM, V140, P1686, DOI 10.1121/1.4962499
   Banai K, 2014, J ACOUST SOC AM, V136, P1908, DOI 10.1121/1.4895684
   Banai K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047099
   Ben-Simon A, 2012, MATAL TEST BATTERY D
   Breznitz Z, 2003, GENET SOC GEN PSYCH, V129, P183
   Breznitz Z, 2003, BRAIN LANG, V85, P486, DOI 10.1016/S0093-934X(03)00071-3
   Breznitz Z., 1997, PARSING TEST UNPUB
   Breznitz Z, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2488
   COHEN NJ, 1980, SCIENCE, V210, P207, DOI 10.1126/science.7414331
   Conway CM, 2010, COGNITION, V114, P356, DOI 10.1016/j.cognition.2009.10.009
   Conway CM, 2008, ANN NY ACAD SCI, V1145, P113, DOI 10.1196/annals.1416.009
   Daikhin L, 2017, J SPEECH LANG HEAR R, V60, P471, DOI 10.1044/2016_JSLHR-H-16-0114
   Doyon J, 2003, NEUROPSYCHOLOGIA, V41, P252, DOI 10.1016/S0028-3932(02)00158-6
   Fahle M, 2005, CURR OPIN NEUROBIOL, V15, P154, DOI 10.1016/j.conb.2005.03.010
   Finkelstein M, 2013, STUD MEDIA COMMUN, V1, P131
   Franceschini S, 2013, CURR BIOL, V23, P462, DOI 10.1016/j.cub.2013.01.044
   FREEMAN BA, 1978, J SPEECH HEAR RES, V21, P497, DOI 10.1044/jshr.2103.487
   Gabay Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176488
   Gabay Y, 2015, CORTEX, V73, P131, DOI 10.1016/j.cortex.2015.08.008
   Gabay Y, 2015, NEUROPSYCHOLOGY, V29, P844, DOI 10.1037/neu0000194
   Gabay Y, 2015, J EXP PSYCHOL HUMAN, V41, P1124, DOI 10.1037/xhp0000073
   Gabay Y, 2015, J SPEECH LANG HEAR R, V58, P934, DOI 10.1044/2015_JSLHR-L-14-0324
   Gabay Y, 2012, NEUROPSYCHOLOGY, V26, P744, DOI 10.1037/a0030235
   Gabay Y, 2012, NEUROPSYCHOLOGIA, V50, P2435, DOI 10.1016/j.neuropsychologia.2012.06.014
   Gabay Y, 2012, J CLIN EXP NEUROPSYC, V34, P279, DOI 10.1080/13803395.2011.633499
   Gori S, 2014, VISION RES, V99, P78, DOI 10.1016/j.visres.2013.11.011
   Guediche S, 2016, J EXP PSYCHOL HUMAN, V42, P1048, DOI 10.1037/xhp0000196
   Guediche S, 2015, CEREB CORTEX, V25, P1867, DOI 10.1093/cercor/bht428
   Guediche S, 2014, FRONT SYST NEUROSCI, V7, DOI 10.3389/fnsys.2013.00126
   Heald SLM, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00035
   Hedenius M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0063998
   Inacio F, 2018, ANN DYSLEXIA, V68, P1, DOI 10.1007/s11881-018-0158-x
   Inspector M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082042
   JACOBY LL, 1984, PSYCHOL LEARN MOTIV, V18, P1, DOI 10.1016/S0079-7421(08)60358-8
   KARNI A, 1991, P NATL ACAD SCI USA, V88, P4966, DOI 10.1073/pnas.88.11.4966
   Karni A, 1998, P NATL ACAD SCI USA, V95, P861, DOI 10.1073/pnas.95.3.861
   Karni A, 1996, COGNITIVE BRAIN RES, V5, P39, DOI 10.1016/S0926-6410(96)00039-0
   Karni A, 1997, CURR OPIN NEUROBIOL, V7, P530, DOI 10.1016/S0959-4388(97)80033-5
   Karni A., 1996, ACQUISITION PERCEPTU
   Kelly Steve W, 2002, Dyslexia, V8, P43, DOI 10.1002/dys.208
   Korman M, 2015, NEUROSCI LETT, V606, P173, DOI 10.1016/j.neulet.2015.08.051
   Krishnan S, 2016, TRENDS COGN SCI, V20, P701, DOI 10.1016/j.tics.2016.06.012
   Kujala T, 2001, P NATL ACAD SCI USA, V98, P10509, DOI 10.1073/pnas.181589198
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Lum JAG, 2013, RES DEV DISABIL, V34, P3460, DOI 10.1016/j.ridd.2013.07.017
   Magnan A, 2004, DYSLEXIA, V10, P131, DOI 10.1002/dys.270
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Nicolson RI, 2007, TRENDS NEUROSCI, V30, P135, DOI 10.1016/j.tins.2007.02.003
   Nicolson RI, 2011, CORTEX, V47, P117, DOI 10.1016/j.cortex.2009.08.016
   NISSEN MJ, 1987, COGNITIVE PSYCHOL, V19, P1, DOI 10.1016/0010-0285(87)90002-8
   Obleser J, 2009, TRENDS COGN SCI, V13, P14, DOI 10.1016/j.tics.2008.09.005
   Ofen-Noy N, 2003, COGNITIVE BRAIN RES, V17, P507, DOI 10.1016/S0926-6410(03)00166-6
   Pavlidou EV, 2014, RES DEV DISABIL, V35, P1457, DOI 10.1016/j.ridd.2014.03.040
   Pavlidou EV, 2010, DYSLEXIA, V16, P143, DOI 10.1002/dys.400
   Perrachione TK, 2011, SCIENCE, V333, P595, DOI 10.1126/science.1207327
   PISONI DB, 1993, SPEECH COMMUN, V13, P109, DOI 10.1016/0167-6393(93)90063-Q
   Primor L, 2011, ANN DYSLEXIA, V61, P242, DOI 10.1007/s11881-011-0059-8
   Prior A, 2006, PSYCHOPHYSIOLOGY, V43, P440, DOI 10.1111/j.1469-8986.2006.00426.x
   REBER AS, 1967, J VERB LEARN VERB BE, V6, P855, DOI 10.1016/S0022-5371(67)80149-X
   REED J, 1994, J EXP PSYCHOL LEARN, V20, P585, DOI 10.1037/0278-7393.20.3.585
   Rosen S, 2003, J PHONETICS, V31, P509, DOI 10.1016/S0095-4470(03)00046-9
   Russeler J, 2006, J CLIN EXP NEUROPSYC, V28, P808, DOI 10.1080/13803390591001007
   Samuel AG, 2009, ATTEN PERCEPT PSYCHO, V71, P1207, DOI 10.3758/APP.71.6.1207
   Seitz AR, 2009, VISION RES, V49, P2604, DOI 10.1016/j.visres.2009.08.003
   Shatil E., 1995, ONE MINUTE TES UNPUB
   Shaywitz SE, 1998, NEW ENGL J MED, V338, P307, DOI 10.1056/NEJM199801293380507
   Shiran A, 2011, J NEUROLINGUIST, V24, P524, DOI 10.1016/j.jneuroling.2010.12.001
   Svirsky MA, 2015, HEARING RES, V322, P163, DOI 10.1016/j.heares.2014.10.008
   Ullman MT, 2001, NAT REV NEUROSCI, V2, P717, DOI 10.1038/35094573
   Ullman MT, 2004, COGNITION, V92, P231, DOI 10.1016/j.cognition.2003.10.008
   Vandermosten M, 2010, P NATL ACAD SCI USA, V107, P10389, DOI 10.1073/pnas.0912858107
   Verhelst W, 1993, AC SPEECH SIGN PROC
   WATSON M, 1990, PERCEPT MOTOR SKILL, V71, P107
   Wechsler D., 1997, WAIS 3 ADM SCORING M
NR 81
TC 1
Z9 1
U1 0
U2 0
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD OCT 24
PY 2018
VL 13
IS 10
AR e0205110
DI 10.1371/journal.pone.0205110
PG 17
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GY3FL
UT WOS:000448434000030
PM 30356320
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Ren, FX
   Ma, W
   Li, MW
   Sun, HQ
   Xin, Q
   Zong, W
   Chen, WB
   Wang, GB
   Gao, F
   Zhao, B
AF Ren, Fuxin
   Ma, Wen
   Li, Muwei
   Sun, Huaiqiang
   Xin, Qian
   Zong, Wei
   Chen, Weibo
   Wang, Guangbin
   Gao, Fei
   Zhao, Bin
TI Gray Matter Atrophy Is Associated With Cognitive Impairment in Patients
   With Presbycusis: A Comprehensive Morphometric Study
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE presbycusis; cognitive impairment; hearing loss; GM atrophy;
   surface-based morphometry
ID POSTERIOR CINGULATE CORTEX; AGE-RELATED-CHANGES; HEARING-LOSS;
   OLDER-ADULTS; DEFAULT MODE; NETWORK
AB Presbycusis (PC) is characterized by bilateral sensorineural hearing loss at high frequencies and speech-perception difficulties in noisy environments and has a strikingly detrimental impact on cognitive function. As the neural consequences of PC may involve the whole brain, we hypothesized that patients with PC would show structural alterations not only in the auditory cortex but also in the cortexes involved in cognitive function. The purpose of this study was to use surface-based morphometry (SBM) analysis to elucidate whole-brain structural differences between patients with PC and age-matched normal hearing controls. Three-dimensional T1 -weighted MR images of 26 patients with mild PC and 26 age-, sex- and education-matched healthy controls (HCs) were acquired. All participants underwent a battery of neuropsychological tests. Our results revealed gray matter atrophy in several auditory cortical areas, nodes of the default mode network (DMN), including the bilateral precuneus and inferior parietal lobule, the right posterior cingulate cortex (PCC), and the right insula of patients with PC compared to that in the HCs. Our findings also revealed that hearing loss was associated with reduced gray matter volume in the right primary auditory cortex of patients with PC. Moreover, structural alterations in the nodes of the DMN were associated with cognitive impairments in PC patients. Additionally, this study provides evidence that a thicker right insula is associated with better speech perception in patients with PC. Based on these findings, we argue that the onset of PC seems to trigger its own cascade of conditions, including a need for increased cognitive resources during speech comprehension, which might lead to auditory and cognition-related cortical reorganization.
C1 [Ren, Fuxin; Zong, Wei; Wang, Guangbin; Gao, Fei; Zhao, Bin] Shandong Univ, Shandong Med Imaging Res Inst, Jinan, Shandong, Peoples R China.
   [Ma, Wen] Shandong Univ, Jinan Cent Hosp, Dept Otolaryngol, Jinan, Shandong, Peoples R China.
   [Li, Muwei] Vanderbilt Univ, Inst Imaging Sci, 221 Kirkland Hall, Nashville, TN 37235 USA.
   [Sun, Huaiqiang] Sichuan Univ, Huaxi MR Res Ctr, Dept Radiol, West China Hosp, Chengdu, Sichuan, Peoples R China.
   [Xin, Qian] Shandong Univ, Cent Lab, Hosp 2, Jinan, Shandong, Peoples R China.
   [Chen, Weibo] Philips Healthcare, Shanghai, Peoples R China.
RP Gao, F; Zhao, B (corresponding author), Shandong Univ, Shandong Med Imaging Res Inst, Jinan, Shandong, Peoples R China.
EM feigao6262@163.com; gpgpoo6262@163.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [81601479]; Shandong Provincial Key Research
   and Development Plan of China [2016GSF201090]; Shandong Provincial
   Natural Science Foundation of ChinaNatural Science Foundation of
   Shandong Province [BS2015YY003]; Shandong Provincial Medical and Healthy
   Technology Development Program of China [2015WS0176, 2017WS610]; China
   Postdoctoral Science FoundationChina Postdoctoral Science Foundation
   [2017M621089]
FX This work was supported by the National Natural Science Foundation of
   China for Young Scholars (No. 81601479); Shandong Provincial Key
   Research and Development Plan of China (No. 2016GSF201090); Shandong
   Provincial Natural Science Foundation of China (No. BS2015YY003);
   Shandong Provincial Medical and Healthy Technology Development Program
   of China (Nos. 2015WS0176 and 2017WS610); and China Postdoctoral Science
   Foundation funded project (No. 2017M621089).
CR Bamiou DE, 2003, BRAIN RES REV, V42, P143, DOI 10.1016/S0165-0173(03)00172-3
   Cardin V, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00199
   Cavanna AE, 2006, BRAIN, V129, P564, DOI 10.1093/brain/awl004
   Cole MW, 2007, NEUROIMAGE, V37, P343, DOI 10.1016/j.neuroimage.2007.03.071
   Galea M, 2005, AUST J PHYSIOTHER, V51, P198, DOI 10.1016/S0004-9514(05)70034-9
   Gao F, 2015, NEUROIMAGE, V106, P311, DOI 10.1016/j.neuroimage.2014.11.023
   Gates GA, 2005, LANCET, V366, P1111, DOI 10.1016/S0140-6736(05)67423-5
   Gong GL, 2005, NEUROREPORT, V16, P1701, DOI 10.1097/01.wnr.0000183327.98370.6a
   Gurgel RK, 2014, OTOL NEUROTOL, V35, P775, DOI 10.1097/MAO.0000000000000313
   Gutierrez-Galve L, 2010, BIOL PSYCHIAT, V68, P51, DOI 10.1016/j.biopsych.2010.03.019
   Hatta Takeshi, 2007, Magn Reson Med Sci, V6, P99, DOI 10.2463/mrms.6.99
   Hewitt D, 2017, FRONT AGING NEUROSCI, V9, DOI 10.3389/fnagi.2017.00112
   Humes LE, 2013, ATTEN PERCEPT PSYCHO, V75, P508, DOI 10.3758/s13414-012-0406-9
   Jayakody DMP, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00125
   Langers DRM, 2007, NEUROIMAGE, V34, P264, DOI 10.1016/j.neuroimage.2006.09.002
   Leech R, 2014, BRAIN, V137, P12, DOI 10.1093/brain/awt162
   Leech R, 2011, J NEUROSCI, V31, P3217, DOI 10.1523/JNEUROSCI.5626-10.2011
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P1131, DOI 10.1093/gerona/glr115
   Lin FR, 2011, J GERONTOL A-BIOL, V66, P582, DOI 10.1093/gerona/glr002
   Lin FR, 2011, ARCH NEUROL-CHICAGO, V68, P214, DOI 10.1001/archneurol.2010.362
   Mantini D, 2007, P NATL ACAD SCI USA, V104, P13170, DOI 10.1073/pnas.0700668104
   Mudar RA, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00828
   Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x
   Ouda L, 2015, CELL TISSUE RES, V361, P337, DOI 10.1007/s00441-014-2107-2
   Peelle JE, 2016, TRENDS NEUROSCI, V39, P486, DOI 10.1016/j.tins.2016.05.001
   Peelle JE, 2011, J NEUROSCI, V31, P12638, DOI 10.1523/JNEUROSCI.2559-11.2011
   Profant O, 2014, NEUROSCIENCE, V260, P87, DOI 10.1016/j.neuroscience.2013.12.010
   Raichle ME, 2001, P NATL ACAD SCI USA, V98, P676, DOI 10.1073/pnas.98.2.676
   Sanchez-Cubillo I, 2009, J INT NEUROPSYCH SOC, V15, P438, DOI 10.1017/S1355617709090626
   Savitz JB, 2003, J GENET PSYCHOL, V164, P319, DOI 10.1080/00221320309597986
   Singh-Curry V, 2009, NEUROPSYCHOLOGIA, V47, P1434, DOI 10.1016/j.neuropsychologia.2008.11.033
   Vainik U, 2018, P NATL ACAD SCI USA, V115, P9312, DOI 10.1073/pnas.1718206115
   Van Schependom J, 2014, EUR J NEUROL, V21, P1219, DOI 10.1111/ene.12463
   Wang XC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096126
   Wayne RV, 2015, AGEING RES REV, V23, P154, DOI 10.1016/j.arr.2015.06.002
   WILK MB, 1968, BIOMETRIKA, V55, P1
   Wingfield Arthur, 2012, Aging health, V8, P107
   Wong PCM, 2008, CEREB CORTEX, V18, P828, DOI 10.1093/cercor/bhm115
   World Health Organisation, 1991, REP INF WORK GROUP P
   Zhao QH, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0051157
   ZIGMOND AS, 1983, ACTA PSYCHIAT SCAND, V67, P361, DOI 10.1111/j.1600-0447.1983.tb09716.x
NR 41
TC 12
Z9 12
U1 0
U2 0
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD OCT 23
PY 2018
VL 12
AR 744
DI 10.3389/fnins.2018.00744
PG 9
WC Neurosciences
SC Neurosciences & Neurology
GA GX7XY
UT WOS:000447995700001
PM 30405333
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Liu, YC
   Ayaz, H
AF Liu, Yichuan
   Ayaz, Hasan
TI Speech Recognition via fNIRS Based Brain Signals
SO FRONTIERS IN NEUROSCIENCE
LA English
DT Article
DE BCI; fNIRS; prefrontal cortex (PFC); parietal lobe; speech perception;
   decoding
ID SYSTEM
AB In this paper, we present the first evidence that perceived speech can be identified from the listeners' brain signals measured via functional-near infrared spectroscopy (fNIRS)- a non-invasive, portable, and wearable neuroimaging technique suitable for ecologically valid settings. In this study, participants listened audio clips containing English stories while prefrontal and parietal cortices were monitored with fNIRS. Machine learning was applied to train predictive models using fNIRS data from a subject pool to predict which part of a story was listened by a new subject not in the pool based on the brain's hemodynamic response as measured by fNIRS. fNIRS signals can vary considerably from subject to subject due to the different head size, head shape, and spatial locations of brain functional regions. To overcome this difficulty, a generalized canonical correlation analysis (GCCA) was adopted to extract latent variables that are shared among the listeners before applying principal component analysis (PCA) for dimension reduction and applying logistic regression for classification. A 74.7% average accuracy has been achieved for differentiating between two 50 s. long story segments and a 43.6% average accuracy has been achieved for differentiating four 25 s. long story segments. These results suggest the potential of an fNIRS based-approach for building a speech decoding brain-computer-interface for developing a new type of neural prosthetic system.
C1 [Liu, Yichuan; Ayaz, Hasan] Drexel Univ, Sch Biomed Engn, Sci & Hlth Syst, Philadelphia, PA 19104 USA.
   [Liu, Yichuan; Ayaz, Hasan] Drexel Univ, Cognit Neuroengn & Quantitat Expt Res CONQUER Col, Philadelphia, PA 19104 USA.
   [Ayaz, Hasan] Univ Penn, Dept Family & Community Hlth, Philadelphia, PA 19104 USA.
   [Ayaz, Hasan] Childrens Hosp Philadelphia, Div Gen Pediat, Philadelphia, PA 19104 USA.
RP Ayaz, H (corresponding author), Drexel Univ, Sch Biomed Engn, Sci & Hlth Syst, Philadelphia, PA 19104 USA.; Ayaz, H (corresponding author), Drexel Univ, Cognit Neuroengn & Quantitat Expt Res CONQUER Col, Philadelphia, PA 19104 USA.; Ayaz, H (corresponding author), Univ Penn, Dept Family & Community Hlth, Philadelphia, PA 19104 USA.; Ayaz, H (corresponding author), Childrens Hosp Philadelphia, Div Gen Pediat, Philadelphia, PA 19104 USA.
EM hasan.ayaz@drexel.edu
RI Liu, Yichuan/AAA-4837-2021
OI Liu, Yichuan/0000-0002-1899-2082; Ayaz, Hasan/0000-0001-5514-2741
CR Alsarray M., 2016, 2016 LOUGHB ANT PROP, P1, DOI [10.1109/APSIPA.2016.7820826, DOI 10.1109/APSIPA.2016.7820826]
   AYAZ H, 2013, FRONT HUM NEUROSCI, V7, DOI DOI 10.3389/FNHUM.2013.00871
   Ayaz H, 2011, JOVE-J VIS EXP, DOI 10.3791/3443
   Ayaz H, 2010, IEEE ENG MED BIO, P6567, DOI 10.1109/IEMBS.2010.5627113
   Ayaz H, 2009, LECT NOTES ARTIF INT, V5638, P699, DOI 10.1007/978-3-642-02812-0_79
   Brumberg JS, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00065
   Chakrabarti S, 2015, BIOMED ENG LETT, V5, P10, DOI 10.1007/s13534-015-0175-1
   Chance B, 1998, OPT EXPRESS, V2, P411, DOI 10.1364/OE.2.000411
   Chen P.-H, 2015, P 28 INT C NEUR INF
   COPE M, 1988, MED BIOL ENG COMPUT, V26, P289, DOI 10.1007/BF02447083
   Fazli S, 2012, IEEE ENG MED BIO, P4911, DOI 10.1109/EMBC.2012.6347095
   Fazli S, 2012, NEUROIMAGE, V59, P519, DOI 10.1016/j.neuroimage.2011.07.084
   Hasson U, 2012, TRENDS COGN SCI, V16, P114, DOI 10.1016/j.tics.2011.12.007
   Herff C, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00429
   Herff C, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00217
   Herff C, 2012, IEEE ENG MED BIO, P1715, DOI 10.1109/EMBC.2012.6346279
   Hoefle S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20732-3
   Izzetoglu M, 2005, IEEE T NEUR SYS REH, V13, P153, DOI 10.1109/TNSRE.2005.847377
   Khan MJ, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00244
   Lerner Y, 2011, J NEUROSCI, V31, P2906, DOI 10.1523/JNEUROSCI.3684-10.2011
   Liu YC, 2017, BRAIN-COMPUT INTERFA, V4, P175, DOI 10.1080/2326263X.2017.1304020
   Liu YC, 2017, SCI REP-UK, V7, DOI 10.1038/srep43293
   Liu YZ, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00316
   Martin S, 2016, SCI REP-UK, V6, DOI 10.1038/srep25803
   McKendrick R, 2015, FRONT SYST NEUROSCI, V9, DOI 10.3389/fnsys.2015.00027
   Moghimi S, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/2/026022
   Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058
   O'Sullivan JA, 2015, CEREB CORTEX, V25, P1697, DOI 10.1093/cercor/bht355
   Piper SK, 2014, NEUROIMAGE, V85, P64, DOI 10.1016/j.neuroimage.2013.06.062
   Power Sarah D, 2012, BMC Res Notes, V5, P141, DOI 10.1186/1756-0500-5-141
   Power SD, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/2/026002
   Putze F, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00373
   Shen CC, 2014, J MULTIVARIATE ANAL, V130, P310, DOI 10.1016/j.jmva.2014.05.011
   Stephens GJ, 2010, P NATL ACAD SCI USA, V107, P14425, DOI 10.1073/pnas.1008662107
   Telkemeyer S, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00062
   Tsuzuki D, 2014, NEUROIMAGE, V85, P92, DOI 10.1016/j.neuroimage.2013.07.025
   Vodrahalli K, 2018, NEUROIMAGE, V180, P223, DOI 10.1016/j.neuroimage.2017.06.042
   Yoshimura N, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00175
NR 38
TC 6
Z9 6
U1 2
U2 12
PU FRONTIERS MEDIA SA
PI LAUSANNE
PA AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND
SN 1662-453X
J9 FRONT NEUROSCI-SWITZ
JI Front. Neurosci.
PD OCT 9
PY 2018
VL 12
AR 695
DI 10.3389/fnins.2018.00695
PG 9
WC Neurosciences
SC Neurosciences & Neurology
GA GW3VJ
UT WOS:000446836400001
PM 30356771
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU Leong, CXR
   Price, JM
   Pitchford, NJ
   van Heuven, WJB
AF Leong, Christine Xiang Ru
   Price, Jessica M.
   Pitchford, Nicola J.
   van Heuven, Walter J. B.
TI High variability phonetic training in adaptive adverse conditions is
   rapid, effective, and sustained
SO PLOS ONE
LA English
DT Article
ID R-VERTICAL-BAR; NONNATIVE SPEECH-PERCEPTION; LONG-TERM RETENTION;
   JAPANESE LISTENERS; LEARNING-ENGLISH; TALKER VARIABILITY; AMERICAN
   ENGLISH; NATIVE SPEAKERS; DISCRIMINATION; LANGUAGE
AB This paper evaluates a novel high variability phonetic training paradigm that involves presenting spoken words in adverse conditions. The effectiveness, generalizability, and longevity of this high variability phonetic training in adverse conditions was evaluated using English phoneme contrasts in three experiments with Malaysian multilinguals. Adverse conditions were created by presenting spoken words against background multi-talker babble. In Experiment 1, the adverse condition level was set at a fixed level throughout the training and in Experiment 2 the adverse condition level was determined for each participant before training using an adaptive staircase procedure. To explore the effectiveness and sustainability of the training, phonemic discrimination ability was assessed before and immediately after training (Experiments 1 and 2) and 6 months after training (Experiment 3). Generalization of training was evaluated within and across phonemic contrasts using trained and untrained stimuli. Results revealed significant perceptual improvements after just three 20-minute training sessions and these improvements were maintained after 6 months. The training benefits also generalized from trained to untrained stimuli. Crucially, perceptual improvements were significantly larger when the adverse conditions were adapted before each training session than when it was set at a fixed level. As the training improvements observed here are markedly larger than those reported in the literature, this indicates that the individualized phonetic training regime in adaptive adverse conditions (HVPT-AAC) is highly effective at improving speech perception.
C1 [Leong, Christine Xiang Ru; Price, Jessica M.] Univ Nottingham Malaysia Campus, Sch Psychol, Semenyih, Selangor, Malaysia.
   [Pitchford, Nicola J.; van Heuven, Walter J. B.] Univ Nottingham, Sch Psychol, Nottingham, England.
RP van Heuven, WJB (corresponding author), Univ Nottingham, Sch Psychol, Nottingham, England.
EM walter.vanheuven@nottingham.ac.uk
RI van Heuven, Walter J B/K-9034-2013
OI van Heuven, Walter J B/0000-0003-3183-4449; Price,
   Jessica/0000-0001-7200-8691; Leong, Christine, Xiang
   Ru/0000-0003-1110-545X
FU Experimental Psychology Society; University of Nottingham Malaysia
   campus; University of Nottingham
FX This research was partly supported by a summer bursary from the
   Experimental Psychology Society awarded to WJBVH. CLXR was supported by
   a funded PhD scholarship from the University of Nottingham Malaysia
   campus. The development of the HVPT-AAC paradigm was supported by
   funding from the University of Nottingham, which included an Innovation
   Fellowship awarded to NJP and WJBVH. The funders had no role in study
   design, data collection and analysis, decision to publish, or
   preparation of the manuscript.
CR Aliaga-Garcia C., 2009, RECENT RES 2 LANGUAG, P2
   Aliaga-Garcoaa C, RECENT RES 2 LANGUAG
   Bent T, 2010, J ACOUST SOC AM, V128, P3142, DOI 10.1121/1.3493428
   Best CT, 2001, J ACOUST SOC AM, V109, P775, DOI 10.1121/1.1332378
   Boersma P., 2002, GLOT INT, V5, P341, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bradlow AR, 2007, J ACOUST SOC AM, V121, P2339, DOI 10.1121/1.2642103
   Bradlow AR, 2002, J ACOUST SOC AM, V112, P272, DOI 10.1121/1.1487837
   Bradlow AR, 1997, J ACOUST SOC AM, V101, P2299, DOI 10.1121/1.418276
   Bradlow AR, 1999, PERCEPT PSYCHOPHYS, V61, P977, DOI 10.3758/BF03206911
   Brosseau-Lapre F, 2013, APPL PSYCHOLINGUIST, V34, P419, DOI 10.1017/S0142716411000750
   Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977
   Burk MH, 2006, EAR HEARING, V27, P263, DOI 10.1097/01.aud.0000215980.21158.a2
   Calandruccio L, 2014, J AM ACAD AUDIOL, V25, P355, DOI 10.3766/jaaa.25.4.7
   Callan DE, 2003, NEUROIMAGE, V19, P113, DOI 10.1016/S1053-8119(03)00020-X
   Cebrian J, 2014, CAN MOD LANG REV, V70, P474, DOI 10.3138/cmlr.2318
   Clopper CG, 2004, LANG SPEECH, V47, P207, DOI 10.1177/00238309040470030101
   Cooke M, 2008, J ACOUST SOC AM, V123, P414, DOI 10.1121/1.2804952
   Flege J., 1995, 2 LANGUAGE SPEECH LE, P233
   FLEGE JE, 1989, J ACOUST SOC AM, V86, P1684, DOI 10.1121/1.398599
   Lecumberri MLG, 2010, SPEECH COMMUN, V52, P864, DOI 10.1016/j.specom.2010.08.014
   GAT IB, 1978, AUDIOLOGY, V17, P339
   Giannakopoulou A, 2017, PEERJ, V5, DOI 10.7717/peerj.3209
   Giannakopoulou A, 2013, CHILD LANG TEACH THE, V29, P201, DOI 10.1177/0265659012467473
   Handley Z, 2009, SPEECH LANGUAGE TECH
   Hassan A, 2005, LINGUISTIK AM, P77
   Hazan V, 2005, SPEECH COMMUN, V47, P360, DOI 10.1016/j.specom.2005.04.007
   Hazan V, 2010, SPEECH COMMUN, V52, P996, DOI 10.1016/j.specom.2010.05.003
   Heeren WFL, 2010, J PHONETICS, V38, P594, DOI 10.1016/j.wocn.2010.08.005
   Huang L.M., 1992, B NATL TAIWAN NORMAL, V37, P363
   Huensch A, 2015, J PHONETICS, V52, P105, DOI 10.1016/j.wocn.2015.06.007
   Iverson P, 2005, J ACOUST SOC AM, V118, P3267, DOI 10.1121/1.2062307
   Iverson P, 2012, APPL PSYCHOLINGUIST, V33, P145, DOI 10.1017/S0142716411000300
   JAMIESON DG, 1986, PERCEPT PSYCHOPHYS, V40, P205, DOI 10.3758/BF03211500
   Jenkins Jennifer, 2014, ENGLISH LINGUA FRANC
   Karim NS, 2015, TATABAHASA DEWAN, P617
   KRAUS N, 1995, J COGNITIVE NEUROSCI, V7, P25, DOI 10.1162/jocn.1995.7.1.25
   Kuhl PK, 2008, PHILOS T R SOC B, V363, P979, DOI 10.1098/rstb.2007.2154
   Lakens D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00863
   Leek MR, 2001, PERCEPT PSYCHOPHYS, V63, P1279, DOI 10.3758/BF03194543
   Lengeris A, 2010, J ACOUST SOC AM, V128, P3757, DOI 10.1121/1.3506351
   LIVELY SE, 1994, J ACOUST SOC AM, V96, P2076, DOI 10.1121/1.410149
   LIVELY SE, 1993, J ACOUST SOC AM, V94, P1242, DOI 10.1121/1.408177
   LOGAN JS, 1991, J ACOUST SOC AM, V89, P874, DOI 10.1121/1.1894649
   Mattys SL, 2012, LANG COGNITIVE PROC, V27, P953, DOI 10.1080/01690965.2012.705006
   Mayo LH, 1997, J SPEECH LANG HEAR R, V40, P686, DOI 10.1044/jslhr.4003.686
   McCandliss BD, 2002, COGN AFFECT BEHAV NE, V2, P89, DOI 10.3758/CABN.2.2.89
   Meador D, 2000, BILING-LANG COGN, V3, P55, DOI DOI 10.1017/S1366728900000134
   Miller JD, 2011, ROLE CALL HYBRID ONL
   Moore DR, 2005, BRAIN LANG, V94, P72, DOI 10.1016/j.bandl.2004.11.009
   Munro M. J., 2004, SYSTEM, V32, P539, DOI DOI 10.1016/J.SYSTEM.2004.09.011
   Nishi K, 2007, J SPEECH LANG HEAR R, V50, P1496, DOI 10.1044/1092-4388(2007/103)
   Nobre-Oliveira D., 2008, NEW SOUNDS 2007 P 5, P382
   Peng ZE, 2016, J ACOUST SOC AM, V139, P2772, DOI 10.1121/1.4948564
   Perrachione TK, 2011, J ACOUST SOC AM, V130, P461, DOI 10.1121/1.3593366
   Pillai S, 2010, WORLD ENGLISH, V29, P159, DOI 10.1111/j.1467-971X.2010.01636.x
   Richie C, 2008, J SPEECH LANG HEAR R, V51, P1607, DOI 10.1044/1092-4388(2008/07-0069)
   Shinohara Y, 2018, J PHONETICS, V66, P242, DOI 10.1016/j.wocn.2017.11.002
   STRANGE W, 1984, PERCEPT PSYCHOPHYS, V36, P131, DOI 10.3758/BF03202673
   TAKATA Y, 1990, J ACOUST SOC AM, V88, P663, DOI 10.1121/1.399769
   Wang XC, 2013, MOD LANG J, V97, P144, DOI 10.1111/j.1540-4781.2013.01386.x
   Thai YN, 2010, PERTANIKA J SOC SCI, V18, P379
NR 61
TC 0
Z9 0
U1 0
U2 3
PU PUBLIC LIBRARY SCIENCE
PI SAN FRANCISCO
PA 1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA
SN 1932-6203
J9 PLOS ONE
JI PLoS One
PD OCT 9
PY 2018
VL 13
IS 10
AR e0204888
DI 10.1371/journal.pone.0204888
PG 24
WC Multidisciplinary Sciences
SC Science & Technology - Other Topics
GA GW4OW
UT WOS:000446897200025
PM 30300372
OA DOAJ Gold, Green Published
DA 2021-02-24
ER

PT J
AU McDaniel, J
   Camarata, S
   Yoder, P
AF McDaniel, Jena
   Camarata, Stephen
   Yoder, Paul
TI Comparing Auditory-Only and Audiovisual Word Learning for Children With
   Hearing Loss
SO JOURNAL OF DEAF STUDIES AND DEAF EDUCATION
LA English
DT Article
ID PRELINGUALLY DEAF-CHILDREN; CROSS-MODAL PLASTICITY; COCHLEAR IMPLANTS;
   SPEECH-PERCEPTION; MULTISENSORY INTEGRATION; INDIVIDUAL-DIFFERENCES;
   VOCABULARY; LANGUAGE; RECOGNITION; KNOWLEDGE
AB Although reducing visual input to emphasize auditory cues is a common practice in pediatric auditory (re) habilitation, the extant literature offers minimal empirical evidence for whether unisensory auditory-only (AO) or multisensory audiovisual (AV) input is more beneficial to children with hearing loss for developing spoken language skills. Using an adapted alternating treatments single case research design, we evaluated the effectiveness and efficiency of a receptive word learning intervention with and without access to visual speechreading cues. Four preschool children with prelingual hearing loss participated. Based on probes without visual cues, three participants demonstrated strong evidence for learning in the AO and AV conditions relative to a control (no-teaching) condition. No participants demonstrated a differential rate of learning between AO and AV conditions. Neither an inhibitory effect predicted by a unisensory theory nor a beneficial effect predicted by a multisensory theory for providing visual cues was identified. Clinical implications are discussed.
C1 [McDaniel, Jena; Yoder, Paul] Vanderbilt Univ, 221 Kirkland Hall, Nashville, TN 37235 USA.
   [Camarata, Stephen] Vanderbilt Univ, Med Ctr, Nashville, TN USA.
RP McDaniel, J (corresponding author), 615-936-5136,1215 21st Ave South,MCE 8310, Nashville, TN 37232 USA.
EM jena.c.mcdaniel@vanderbilt.edu
FU American Speech-Language-Hearing Foundation; National Center for
   Advancing Translational Sciences of the National Institute of Health
   [UL1 TR000445]; United States Department of EducationUS Department of
   Education [H325D140087]; Eunice Kennedy Shriver National Institute of
   Child Health and Human Development of the National Institutes of
   HealthUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National
   Institute of Child Health & Human Development (NICHD) [U54HD083211];
   Scottish Rite Foundation of Nashville; EUNICE KENNEDY SHRIVER NATIONAL
   INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENTUnited States Department of
   Health & Human ServicesNational Institutes of Health (NIH) - USANIH
   Eunice Kennedy Shriver National Institute of Child Health & Human
   Development (NICHD) [U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211,
   U54HD083211, U54HD083211, U54HD083211, U54HD083211, U54HD083211] Funding
   Source: NIH RePORTER; NATIONAL CENTER FOR ADVANCING TRANSLATIONAL
   SCIENCESUnited States Department of Health & Human ServicesNational
   Institutes of Health (NIH) - USANIH National Center for Advancing
   Translational Sciences (NCATS) [UL1TR000445] Funding Source: NIH
   RePORTER
FX This work was supported by the American Speech-Language-Hearing
   Foundation [2016 Student Research Grant in Early Childhood Language
   Development]; the National Center for Advancing Translational Sciences
   of the National Institute of Health [UL1 TR000445]; the United States
   Department of Education [Preparation of Leadership Personnel grant
   H325D140087]; the Eunice Kennedy Shriver National Institute of Child
   Health and Human Development of the National Institutes of Health
   [U54HD083211]; and the Scottish Rite Foundation of Nashville. Its
   contents are solely the responsibility of the authors and do not
   necessarily represent the official views of the funding agencies.
CR Anderson KL, 2015, AM SPEECH LANGUAGE H, V25, P24
   [Anonymous], 2014, PROC STAND HDB VERS
   Ayres K., 2014, SINGLE CASE RES METH, P124
   Baum SH, 2015, JOVE-J VIS EXP, DOI 10.3791/52677
   Bergeson T. R, 2004, HDB MULTISENSORY PRO, P749
   Bergeson TR, 2005, EAR HEARING, V26, P149, DOI 10.1097/00003446-200504000-00004
   Bergeson TR, 2003, VOLTA REV, V103, P347
   Bernstein LE, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00934
   Bernthal J. E., 2009, ARTICULATION PHONOLO
   Camarata S. M., 1985, PAPERS REPORTS CHILD, V24, P38
   Campbell R, 2008, PHILOS T R SOC B, V363, P1001, DOI 10.1098/rstb.2007.2155
   Cannon JE, 2016, AM ANN DEAF, V160, P440, DOI 10.1353/aad.2016.0007
   Carey S., 1978, PAPERS REPORTS CHILD, P17
   Carrow-Woolfolk E., 2014, TEST AUDITORY COMPRE
   Carrow-Woolfolk E. A., 2014, TEST EXPRESSIVE LANG
   Cochrane, 2017, ASSESSING RISK BIAS
   Cockersole FW, 1938, BRIT J EDUC PSYCHOL, V8, P307
   Contrera KJ, 2014, OTOL NEUROTOL, V35, P426, DOI 10.1097/MAO.0000000000000243
   Convertino C, 2014, J DEAF STUD DEAF EDU, V19, P471, DOI 10.1093/deafed/enu024
   Davidson Lisa S, 2014, Cochlear Implants Int, V15, P211, DOI 10.1179/1754762813Y.0000000051
   de Villers-Sidani E, 2007, J NEUROSCI, V27, P180, DOI 10.1523/JNEUROSCI.3227-06.2007
   DOEHRING DG, 1971, J SPEECH HEAR RES, V14, P746, DOI 10.1044/jshr.1404.746
   Dunn L. M., 2007, PEABODY PICTURE VOCA
   Ehrler D. J., 2008, PRIMARY TEST NONVERB
   ERBER NP, 1972, J SPEECH HEAR RES, V15, P413, DOI 10.1044/jshr.1502.413
   ERBER NP, 1979, J SPEECH HEAR DISORD, V44, P255, DOI 10.1044/jshd.4403.255
   ERBER NP, 1969, J SPEECH HEAR RES, V12, P423, DOI 10.1044/jshr.1202.423
   Estabrooks W., 2001, 50 FREQUENTLY ASKED
   ESTABROOKS W, 1998, COCHLEAR IMPLANTS KI
   Fu Qian-Jie, 2007, Trends Amplif, V11, P193, DOI 10.1177/1084713807301379
   Fudala J. B., 2000, ARIZONA ARTICULATION
   Gast D. L, 2014, SINGLE CASE RES METH, P176, DOI 10.4324/9780203521892-9
   Gast D. L, 2014, SINGLE CASE RES METH, P85
   Geers A, 2003, EAR HEARING, V24, p24S, DOI 10.1097/01.AUD.0000051687.99218.0F
   Geers AE, 2002, LANG SPEECH HEAR SER, V33, DOI 10.1044/0161-1461(2002/015)
   Geers AE, 2017, PEDIATRICS, V140, DOI 10.1542/peds.2016-3489
   Ghazanfar AA, 2006, TRENDS COGN SCI, V10, P278, DOI 10.1016/j.tics.2006.04.008
   Gilley PM, 2010, RESTOR NEUROL NEUROS, V28, P207, DOI 10.3233/RNN-2010-0525
   Glick H, 2017, HEARING RES, V343, P191, DOI 10.1016/j.heares.2016.08.012
   Holt RF, 2011, J SPEECH LANG HEAR R, V54, P632, DOI 10.1044/1092-4388(2010/09-0148)
   Horner RH, 2005, EXCEPT CHILDREN, V71, P165, DOI 10.1177/001440290507100203
   Houston DM, 2012, J AM ACAD AUDIOL, V23, P446, DOI 10.3766/jaaa.23.6.7
   Houston DM, 2012, DEVELOPMENTAL SCI, V15, P448, DOI 10.1111/j.1467-7687.2012.01140.x
   Houston Derek M, 2005, Volta Rev, V105, P41
   Johnson C, 2010, J SPEECH LANG HEAR R, V53, P237, DOI 10.1044/1092-4388(2009/08-0139)
   Kaufman A., 2004, KAUFMAN BRIEF INTELL, V2nd
   Kirk Karen Iler, 2002, Proc Int Conf Spok Lang Process, V2002, P1689
   Kirk Karen Iler, 2007, Audiol Med, V5, P250, DOI 10.1080/16513860701673892
   Kral A, 2005, CEREB CORTEX, V15, P552, DOI 10.1093/cercor/bhh156
   Kral A, 2006, PROG BRAIN RES, V157, P283, DOI 10.1016/S0079-6123(06)57018-9
   Lachs L, 2001, EAR HEARING, V22, P236, DOI 10.1097/00003446-200106000-00007
   Lederberg A.R., 2001, CONTEXT COGNITION DE, P88
   Lederberg AR, 2009, J DEAF STUD DEAF EDU, V14, P44, DOI 10.1093/deafed/enn021
   Lederberg AR, 2000, CHILD DEV, V71, P1571, DOI 10.1111/1467-8624.00249
   Ledford J.R., 2018, SINGLE CASE RES METH
   Ledford JR, 2016, J EARLY INTERVENTION, V38, P79, DOI 10.1177/1053815116648000
   LEONARD LB, 1982, J SPEECH HEAR RES, V25, P554, DOI 10.1044/jshr.2504.554
   Lewkowicz DJ, 2010, DEV PSYCHOL, V46, P66, DOI 10.1037/a0015579
   Ling A. H., 1976, EAR HEARING, V1, P150
   Ling D., 1989, FDN SPOKEN LANGUAGE
   Luckner JL, 2010, AM ANN DEAF, V155, P38, DOI 10.1353/aad.0.0129
   Lund E, 2016, EXCEPT CHILDREN, V83, P26, DOI 10.1177/0014402916651848
   Lund E, 2016, LANG SPEECH HEAR SER, V47, P236, DOI 10.1044/2016_LSHSS-15-0032
   Lund E, 2016, J DEAF STUD DEAF EDU, V21, P107, DOI 10.1093/deafed/env060
   Lund E, 2015, DEAF EDUC INT, V17, P163, DOI 10.1179/1557069X15Y.0000000004
   Lund E, 2014, J DEAF STUD DEAF EDU, V19, P68, DOI 10.1093/deafed/ent036
   Martin N., 2005, TEST AUDITORY PROCES
   Marulis LM, 2010, REV EDUC RES, V80, P300, DOI 10.3102/0034654310377087
   Massaro DW, 2004, VOLTA REV, V104, P141
   MASSARO DW, 1984, CHILD DEV, V55, P1777, DOI 10.1111/j.1467-8624.1984.tb00420.x
   MASSARO DW, 1986, J EXP CHILD PSYCHOL, V41, P93, DOI 10.1016/0022-0965(86)90053-6
   McDaniel J., 2017, PERSPECTIVES ASHA SP, V2, P10
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Murray MM, 2016, TRENDS NEUROSCI, V39, P567, DOI 10.1016/j.tins.2016.05.003
   Murray MM, 2016, NEUROPSYCHOLOGIA, V83, P161, DOI 10.1016/j.neuropsychologia.2015.08.011
   Norena AJ, 2005, J NEUROSCI, V25, P699, DOI 10.1523/JNEUROSCI.2226-04.2005
   Ohde R. N., 1992, PHONETIC ANAL NORMAL
   Patterson ML, 2003, DEVELOPMENTAL SCI, V6, P191, DOI 10.1111/1467-7687.00271
   Pilling M, 2011, LANG SPEECH, V54, P487, DOI 10.1177/0023830911404958
   Pisoni DB, 1999, VOLTA REV, V101, P111
   Pollack D., 1970, ED AUDIOLOGY LTD HEA
   Polley DB, 2006, J NEUROSCI, V26, P4970, DOI 10.1523/JNEUROSCI.3771-05.2006
   Qi S, 2012, J DEAF STUD DEAF EDU, V17, P1, DOI 10.1093/deafed/enr028
   Rhoades E. A., 2016, AUDITORY VERBAL THER, P285
   RICE ML, 1990, J SPEECH HEAR DISORD, V55, P33, DOI 10.1044/jshd.5501.33
   Robbins A. M., 2016, PROMOTING LANGUAGE L, P181
   Robertson VS, 2017, EAR HEARING, V38, P701, DOI 10.1097/AUD.0000000000000455
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Rouger J, 2008, BRAIN RES, V1188, P87, DOI 10.1016/j.brainres.2007.10.049
   Sacks C, 2014, CHILD LANG TEACH THE, V30, P91, DOI 10.1177/0265659013494873
   Schorr EA, 2005, P NATL ACAD SCI USA, V102, P18748, DOI 10.1073/pnas.0508862102
   SCHWARTZ RG, 1984, J SPEECH HEAR RES, V27, P119, DOI 10.1044/jshr.2701.119
   Seitz AR, 2006, CURR BIOL, V16, P1422, DOI 10.1016/j.cub.2006.05.048
   Sharma A, 2007, INT J AUDIOL, V46, P494, DOI 10.1080/14992020701524836
   Sharma A, 2016, BRAIN SCI, V6, DOI 10.3390/brainsci6010004
   Sharma A, 2015, INT J PSYCHOPHYSIOL, V95, P135, DOI 10.1016/j.ijpsycho.2014.04.007
   Sheffert S. M., 1996, RES SPOKEN LANGUAGE, V21, P578
   Sindelar P.T., 1985, ED TREATMENT CHILDRE, V8, P67, DOI DOI 10.1177/01454455155832
   Stacey PC, 2010, INT J AUDIOL, V49, P347, DOI 10.3109/14992020903397838
   Stanford TR, 2007, NEUROREPORT, V18, P787, DOI 10.1097/WNR.0b013e3280c1e315
   Stevenson RA, 2017, EAR HEARING, V38, P521, DOI 10.1097/AUD.0000000000000435
   Stevenson RA, 2015, NEUROBIOL AGING, V36, P283, DOI 10.1016/j.neurobiolaging.2014.08.003
   Stevenson RA, 2012, J EXP PSYCHOL HUMAN, V38, P1517, DOI 10.1037/a0027339
   Stoel-Gammon C, 2011, J CHILD LANG, V38, P1, DOI 10.1017/S0305000910000425
   Storkel HL, 2010, BEHAV RES METHODS, V42, P497, DOI 10.3758/BRM.42.2.497
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Tomblin J Bruce, 2015, Ear Hear, V36 Suppl 1, p76S, DOI 10.1097/AUD.0000000000000219
   Tye-Murray N, 2014, FDN AURAL REHABILITA
   Walker EA, 2013, J SPEECH LANG HEAR R, V56, P375, DOI 10.1044/1092-4388(2012/11-0343)
   Wallace MT, 2007, J NEUROPHYSIOL, V97, P921, DOI 10.1152/jn.00497.2006
   Wallace MT, 2004, J NEUROSCI, V24, P9580, DOI 10.1523/JNEUROSCI.2535-04.2004
   Wechsler-Kashi D, 2014, J SPEECH LANG HEAR R, V57, P1870, DOI 10.1044/2014_JSLHR-L-13-0321
   Wendel E, 2015, J DEAF STUD DEAF EDU, V20, P103, DOI 10.1093/deafed/enu049
   Williams K, 2007, EXPRESSIVE VOCABULAR
   Willstedt-Svensson U, 2004, INT J AUDIOL, V43, P506, DOI 10.1080/14992020400050065
   Wolery M., 2014, SINGLE CASE RES METH, P297, DOI DOI 10.4324/9781315150666
   Xu JH, 2012, J NEUROSCI, V32, P2287, DOI 10.1523/JNEUROSCI.4304-11.2012
   Yu LP, 2010, J NEUROSCI, V30, P4904, DOI 10.1523/JNEUROSCI.5575-09.2010
   Zhang LI, 2001, NAT NEUROSCI, V4, P1123, DOI 10.1038/nn745
   Zupan B, 2009, J COMMUN DISORD, V42, P381, DOI 10.1016/j.jcomdis.2009.04.002
NR 120
TC 1
Z9 1
U1 1
U2 5
PU OXFORD UNIV PRESS
PI OXFORD
PA GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND
SN 1081-4159
EI 1465-7325
J9 J DEAF STUD DEAF EDU
JI J. Deaf Stud. Deaf Educ.
PD OCT
PY 2018
VL 23
IS 4
BP 382
EP 398
DI 10.1093/deafed/eny016
PG 17
WC Education, Special; Rehabilitation
SC Education & Educational Research; Rehabilitation
GA HI7SO
UT WOS:000456656500009
PM 29767759
OA Green Published, Bronze
DA 2021-02-24
ER

EF