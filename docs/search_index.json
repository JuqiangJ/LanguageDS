[["index.html", "语言数据科学教程 Chapter 1 第一章 数据科学简介 1.1 数据科学发展简史 1.2 数据科学家 1.3 数据科学工作流程", " 语言数据科学教程 陈居强 2024-09-01 Chapter 1 第一章 数据科学简介 欢迎关注我的个人主页： 1.1 数据科学发展简史 1.2 数据科学家 1.3 数据科学工作流程 "],["第二章-r语言简介.html", "Chapter 2 第二章 R语言简介 2.1 R语言发展简史 2.2 R、R-Studio、R软件包的安装简介 2.3 R语言的数据结构", " Chapter 2 第二章 R语言简介 2.1 R语言发展简史 2.2 R、R-Studio、R软件包的安装简介 R语言的安装 使用这个链接https://cloud.r-project.org/来下载R语言软件。根据你的电脑操作系统，选择相应的版本。 R语言可以在计算机上通过终端命令直接运行，也有自己的图形界面。但是RStudio 是最适用于初学者的R 编程的集成开发环境(integrated development environment，IDE)。使用者可以从 http://www.rstudio.com/download 下载并安装。其中免费版已经可以满足数据科学的需求了。 它提供了许多功能，如代码编辑器、调试器、数据可视化和包管理器等，使得R语言的学习和使用变得更加方便和高效。R-Studio被广泛用于数据科学、统计分析、机器学习和数据可视化等领域。 不同软件包使用：https://github.com/JuqiangJ/cheatsheets 图2.1 R-studio初始化 首先，初始界面有3个区域。在图中左侧区域是输入和运行代码区域，右侧上部的区域目前选中的是environment也就是环境变量的显示窗口。当前并没有输入任何代码，所以环境变量的窗口是空白。在右侧下部，对窗口有5个不同的按键：文件（File），制图（Plots），程序包（Packages），帮助（Help），视图（Viewer）。目前选中的是作图窗口。 在代码运行窗口，我们可以输入命令，然后按回车键即可运行命令。如果我们想要将命令写成脚本，方便重复使用，修改，那需要新建一个脚本文件。 我们推荐两种方式书写脚本，一种是把脚本文件格式，另外一种是Rmarkdown文件格式。 脚本文件格式 图2.2 新建脚本 当我们新建了一个脚本文件，就会出现一个窗口。原先的代码运行窗口，变换到了左边的下部，而在左边上部出现了一个新的窗口。这就是脚本书写窗口。在这里书写的脚本，我们可以通过选中来运行。 安装一个软件包package install.packages(&quot;tidyverse&quot;) ## Error in install.packages : Updating loaded packages 2.3 R语言的数据结构 在R中，基本的数据结构有向量（vector），数组（array），列表（list），数据框（data frame）和因子（factor）。 2.3.1 向量（vector） 向量是一种最基本的一维数据结构，可以包含相同类型的元素（data element）。元素的类型有数值型、字符串型、布尔型。可以通过使用c()函数创建向量，并且可以使用一系列基本函数索引、访问和修改向量中的元素。 #创建一个包含整数的向量 vector &lt;- c(1, 2, 3, 4, 5) # 创建不同类型的向量 # 数值型 a = 8:17 b &lt;- c(9, 10, 100, 38) # 布尔型 c = c (TRUE, FALSE, TRUE, FALSE) c = c (T, F, T, F) # 字符型 d = c (&quot;TRUE&quot;, &quot;FALSE&quot;, &quot;FALSE&quot;) # 改变向量的类型 as.vector(b, mode = &quot;character&quot;) 值得注意的是，如果不同类型的数据被放入同一个向量，数据类型会发生改变。数值型数据会强制改变为字符型数据或布尔型数据。 e = c(9,10, &quot;ab&quot;, &quot;cd&quot;) f = c(10, 11, T, F) 除了单个输入之外，我们可以借助R语言的一些函数，批量生成向量中的元素。 A = 9:20 + 1 # A 是一个从9到20的向量，并且每个元素都加上了1。 B = seq(1, 10)# B 是一个从1到10的向量，其中的数字是连续的。 C = seq(1, 20, by = 2)#C 是一个从1到20的向量，步长为2，也就是只包含奇数。 D = rep(5, 4)# D 是一个包含了4个5的向量。 E = rep(c(1, 2, 3), 4)# E 是一个重复了4次的向量，其中包含了1、2、3这三个元素。 G = rep(c(1, 2, 3), each = 4)# G 是一个重复了4次的向量，其中每个元素都重复了4次，即先重复1四次，然后重复2四次，最后重复3四次。 R语言中的一些基本函数，可以对包含不同类型数据的向量进行操作。 #length(): 返回向量的长度。 vector &lt;- c(1, 2, 3, 4, 5) length(vector) # is.na(): 检查向量中是否存在缺失值（NA）。 vector&lt;- c(1, NA, 3, NA, 5) is.na(vector) # which(): 返回满足条件的元素在向量中的索引。 vector&lt;- c(1, 2, 6, 7, 8) which(vector &gt; 3) # sample(): 随机从向量中抽取元素。可以用于实验随机抽样。 vector &lt;- c(1:100) sample(vector, size = 3) 针对数值型向量的简单计算函数 # sum(): 计算向量中所有元素的和。 vector &lt;- c(1:50) sum(vector) # mean(): 计算向量的平均值。 mean(vector) # median(): 计算向量的中位数。 median(vector) # min(): 返回向量中的最小值。 min(vector) # max(): 返回向量中的最大值。 max(vector) # sort(): 将向量中的元素按升序排序。 sort(vector) # rev(): 反转向量中元素的顺序。 rev(vector) # unique(): 返回向量中唯一的元素。 vector = c(1,2,33,4,4,4,5,6,345) unique(vector) # range(): 返回向量的取值范围（最小值和最大值）。 range(vector ) quantile(vector) round(sd(vector), 2) 针对字符串型向量的函数 # paste(): 将向量中的元素连接为一个字符串。 vector &lt;- c(&quot;我&quot;, &quot;爱&quot;, &quot;XXX!&quot;) paste(vector, collapse = &quot; &quot;) # tolower(): 转换向量中的字符为小写。 vector &lt;- c(&quot;HELLO&quot;, &quot;WORLD&quot;, &quot;!&quot;) tolower(vector) # toupper(): 转换向量中的字符为大写。 vector &lt;- c(&quot;hello&quot;, &quot;world&quot;, &quot;!&quot;) toupper(vector) # grep(): 在向量中搜索满足条件的模式，并返回其索引。 vector &lt;- c(&quot;苹果&quot;, &quot;香蕉&quot;, &quot;胡萝卜&quot;, &quot;橙子&quot;) grep(&quot;果&quot;, vector) 2.3.2 列表（list） 列表是一种可以包含不同类型的元素的数据结构。列表可以使用list()函数创建，可以使用索引或元素名称来访问和修改列表中的元素。 # 创建一个包含整数、字符和向量的列表： my_list &lt;- list(1, &quot;a&quot;, c(2, 3, 4)) my_list 列表的简单操作 # unlist() 函数：将list转换为向量。 my_list &lt;- list(&quot;apple&quot;, &quot;banana&quot;, &quot;orange&quot;) unlist(my_list) # lapply()：对list中的每个元素应用一个函数。 my_list &lt;- list(1:3, 4:6, 7:9) lapply(my_list, mean) # sapply()：对list中的每个元素应用一个函数，并将结果简化为向量。 my_list &lt;- list(1:3, 4:6, 7:9) sapply(my_list, mean) 在建立回归模型后，可以将结果存储在一个列表中。 # 这行代码使用R中的lm()函数（线性模型）来拟合一个线性回归模型。模型的目标（因变量）是mpg（每加仑英里数），预测变量（自变量）是hp（马力）。数据源是R自带的mtcars数据集。 model &lt;- lm(mpg ~ hp, data = mtcars) # 这行代码创建一个列表，其中包含了线性模型的系数（coefficients）、残差（residuals）和拟合值（fitted.values）。 model_summary &lt;- list(coefficients = model$coefficients, residuals = model$residuals, fitted.values = model$fitted.values) #这行代码返回并打印model_summary列表的内容。 model_summary 2.3.3 矩阵（matrix） 矩阵是一个二维数组，其中的所有元素都具有相同的模式（数字、字符或逻辑）。你可以通过matrix()函数来创建矩阵。 # 创建一个3行2列的矩阵： data &lt;- 1:6 matrix1 &lt;- matrix(data, nrow = 3, ncol = 2) print(matrix1) 在这个示例中，我们首先创建了一个从1到6的向量 data，然后我们创建了一个3行2列的矩阵 matrix1，并将这个向量的数据按列存入矩阵。输出的结果会是一个3行2列的矩阵，元素值按列从1到6。 2.3.4 数据框（data frame） 数据框是一种表格形式的数据结构。数据框可以包含不同类型的列，但是每列长度必须相同。数据框可以使用data.frame()函数创建，并可以使用列名称或索引来访问和修改数据框中的数据。 例如，创建一个包含姓名和年龄的数据框： # 创建一个数据框 df &lt;- data.frame( name = c(&quot;John&quot;, &quot;Mary&quot;, &quot;Peter&quot;), age = c(25, 32, 45), gender = c(&quot;Male&quot;, &quot;Female&quot;, &quot;Male&quot;) ) # summary()：用于查看数据框的统计信息。 summary(df) #（输出df的基本统计信息，包括均值、中位数、最大值、最小值等。） 对于字符类型（如 name 和 gender），summary() 函数会显示变量长度。 对于数值类型（如 age），summary() 函数会显示最小值（Min.）、第一四分位数（1st Qu.）、中位数（Median）、平均值（Mean）、第三四分位数（3rd Qu.）和最大值（Max.）。 # 查看数据框的结构 str(df) ## &#39;data.frame&#39;: 3 obs. of 3 variables: ## $ name : chr &quot;John&quot; &quot;Mary&quot; &quot;Peter&quot; ## $ age : num 25 32 45 ## $ gender: chr &quot;Male&quot; &quot;Female&quot; &quot;Male&quot; 在输出结果中，以下是每一部分的含义： ‘data.frame’：这是 df 的数据类型，即数据框（data frame）。 3 obs. of 3 variables：这表示 df 有3个观察值（即行）和3个变量（即列）。 接下来的部分列出了数据框的每一个变量（列）： name : chr “John” “Mary” “Peter”： name 表示 df 的一个变量是 name，: chr 表示 name 变量的数据类型是字符型 (character)，接着的 “John” “Mary” “Peter” 是 name 变量的前几个观察值。 age : num 25 32 45：age 表示 df 的另一个变量是 age，: num 表示 age 变量的数据类型是数值型 (numeric)，接着的 25 32 45 是 age 变量的前几个观察值。 gender: chr “Male” “Female” “Male”：gender 表示 df 的另一个变量是 gender，: chr 表示 gender 变量的数据类型是字符型 (character)，接着的 “Male” “Female” “Male” 是 gender 变量的前几个观察值。 # nrow()：用于计算数据框的行数。 nrow(df) #（输出df的行数。） # ncol()：用于计算数据框的列数。 ncol(df) #（输出df的列数。） # head()：用于查看数据框的前几行数据。 head(df, n = 2) #（输出df的前10行数据。） # tail()：用于查看数据框的后几行数据。 tail(df, n = 2) #（输出df的后5行数据。） # unique()：用于去重并输出数据框中唯一的值。 unique(df$gender) #（输出df中gender列的唯一值。） 矩阵和数据框都是二维数据结构。有时候，我们可能需要将数据框转换为矩阵格式，以便于进行某些特定的数据处理（比如进行归一化处理）。很多机器学习算法（例如SVM、KNN等）在训练时，需要数据以矩阵形式输入。此外，在文本分析中，词频-文档矩阵通常非常稀疏，也就是说，矩阵中的大部分元素都是零（因为每个文档只包含词汇表中的一小部分词语）。而在R中，数据框不支持稀疏数据，如果我们尝试将一个大的稀疏矩阵存储为数据框，那么它将占用大量的内存。相反，词频-文档矩阵通常以稀疏矩阵的形式存储，这种格式只存储非零元素，从而大大节省了内存。在文本分析中，我们经常需要对词频-文档矩阵进行各种矩阵运算，例如矩阵乘法、转置等。在R中，数据框不支持这些矩阵运算，如果我们尝试对数据框执行这些操作，那么我们需要先将其转换为矩阵。 2.3.5 数组（array） 数组是一个可以存储具有相同数据类型元素的多维数据结构。可以使用array()函数创建数组。 # 创建一个一维数组： data &lt;- 1:10 array1 &lt;- array(data, dim = c(10)) print(array1) # 在这个示例中，我们首先创建了一个从1到10的向量 data，然后我们创建了一个一维数组 array1，并将这个向量的数据存入数组。输出的结果会是1到10的一维数组。 # 创建一个二维数组： data &lt;- 1:12 array2 &lt;- array(data, dim = c(3, 4)) print(array2) # 在这个示例中，我们创建了一个二维数组 array2，它有3行4列。输出的结果会是一个3行4列的二维数组，元素值从1到12。 # 创建一个三维数组： data &lt;- 1:24 array3 &lt;- array(data, dim = c(2, 3, 4)) print(array3) # 在这个示例中，我们创建了一个三维数组 array3，它有2个2行3列的面。输出的结果会是一个2行3列，共有2个面的三维数组，元素值从1到24。 在数据科学实践中，尽管数组可能不如数据框或列表那么常用，但它们在某些特定的情况下是非常有用的。例如，数据以多维形式出现时，数组可以是理想的数据结构。例如，不同时间、不同地点收集到了大气温度数据，可以存储在一个三维数组中，其中一个维度代表时间，另一个维度代表经度，第三个维度代表纬度。在这种情况下，使用数组可以使数据的处理和分析更加直观和方便。 Dimensions Homogenous Heterogeneous 1D Vector List 2D Matrix Data frame nD Array 在R语言中，有五种主要的数据结构：向量（vector）、矩阵（matrix）、数组（array）、列表（list）和数据框（data frame）。这些数据结构是R编程中非常常用的，可以帮助我们有效地组织和处理数据。每种数据结构都有其特定的用途，适用于处理不同类型和维度的数据。 "],["第三章-数据整理.html", "Chapter 3 第三章 数据整理 3.1 数据与变量 3.2 数据清洁 3.3 变量筛选 3.4 数据塑形 3.5 数据整合", " Chapter 3 第三章 数据整理 数据整理（Data wrangling）是指对原始数据进行一系列的处理，以消除数据中错误，选择合适的数据，调整数据格式，为后续的探索性数据分析做好准备。数据加工主要包括数据清理（Data Cleaning）、变量筛选、数据合成（Data Integration）、数据塑形（Data reshaping）等。在学习数据处理之前，我们需要对数据与变量的类型有所了解。 3.1 数据与变量 3.1.1 结构型数据和非结构型数据 根据数据的组织方式，数据科学中将数据分为结构型数据（Structured Data）和非结构型数据（Unstructured Data）。 结构型数据是指以明确定义的数据结构和数据模式组织的数据，其数据元素之间存在预定义的关系和属性，以便于存储、检索和分析。结构型数据具有固定的格式和字段，通常以表格、数据库、CSV（逗号分隔值）文件等形式存储。每个数据项都有预定义的类型，例如整数、浮点数、日期、文本等，且数据之间可以通过键值或主键进行关联。 非结构型数据是指没有固定格式和明确定义的数据，数据元素之间缺乏预定义的关系和属性，不易于直接存储和分析的数据形式。常见的非结构型数据有文本、图像、音频、视频等内容，其结构和含义需要进一步的处理和解析。这些数据通常存储在文档、图像文件、日志、社交媒体帖子等中。 示例： 文本数据：社交媒体帖子、新闻文章、电子邮件等。 图像数据：照片、绘画、图表等。 音频数据：录音、音乐等。 在语言研究中，语言本体数据包括文本数据（含口语转录的文本）和语音数据。语言使用者的社会人口学数据也是语言研究的重要组成部分。在实验语言学或心理语言学研究中，数据还包括语言使用者加工语言的行为数据和神经活动数据。语言研究涉及的数据类型十分丰富，同时也为数据处理提出了巨大的挑战。 语言研究中，实验数据通常是结构性的。语音数据及标注，还有相应的声学指标，如时长，元音的共振峰，响音部分的基频等一般也是以结构性数据形式存在。结构化数据是较为容易存储，处理的。 文本数据比如博客，文章，小说等是非结构化的，不能直接用数据科学中的数据探索分析方法或者数据建模和数据可视化。文本数据可以通过分词，词频统计，特征提取等方法转化为结构性数据。只有当转化为结构性数据之后，进一步加入元数据，我们才能够来讨论变量之间的关系。在语言研究中，语料库数据通常是非结构性的，对语料库进行量化分析需要我们提取相应信息并转化成为结构性的数据。 3.1.2 质性数据和量化数据 根据数据的统计学特性，数据可以分为质性数据和量化数据。质性数据是指不能够用数字来表示，也不能够进行简单的数学计算，而仅仅用来描述某个事物的范畴属性。比如，语音学中一个音是元音，还是辅音。一个词的词性，名词，动词。一句话所具有的语用功能。 量化数据是可以用数字来描述并且可以进行简单的数学运算。进一步可以分为离散数据（Discrete）和连续数据（ Continuous）。离散数据只能用某一些数值代表，比如参与实验的人数，实验中刺激的个数。连续数据（ Continuous）可以有无限的数据数值代表，比如实验任务的反应时。 在科学研究中，为了探究一些问题，我们通过实验、调查、观察或其他数据收集方法获得的数据。数据通常用于描述和分析研究中的变量，并用于回答研究问题或测试假设。数据是对变量的测量或观察结果。 3.1.3 变量 变量是指任何可以被测量或计数的特征，用于描述不同个体或实物的特征，比如年龄、性别、企业收入和支出、出生国家、班级成绩、眼睛颜色和车辆类型都是常见的变量。变量之所以称为变量，是因为在一个总体（population）或数据集中，其值可能会在不同的个体之间有所变化，或者随着时间的推移可能会发生变化。例如，一个人的身高可以随着时间的推移而增长，一个企业的收入和支出可以随着季度或年份的变化而变化。 变量根据其描述性统计特性分为四种不同层次，分别为定类（nominal）、定序(ordinal)、定距（interval）及定比（ratio）变量。同时，定类和定序变量为类别变量（categorical），定距和定比变量为数值变量（numberic）。 3.1.4 类别变量 定性变量描述事物的“特征”、“类型”或“范畴”，通常使用非数字值表示。分类变量通常是排他的性，即一个个体属于同一变量中的一个类别。分类变量应该是详尽的，包括所有可能的类别。 类别变量可以进一步分为定类和定序两种。定类变量描述一个类别，无法按逻辑顺序进行组织。常见的该类变量包括性别、企业类型、眼睛颜色、宗教和品牌。我们可以描述其频数（率），或者一组数据中的众数 （出现频数最高的）。 定序变量描述一个有顺序类别。比如，调查问卷中，喜欢、一般、厌恶，这3个选项就构成了有顺序数据。定序数据可以按数据顺序排列，因此除了众数之外，我们还可以描述其中位数，也就是将一组数据按一定顺序排列，其中处于中间位置的数据。定序变量的类别相互比较高低大小，但不一定能建立各个类别之间的数字差异。换句话说，变量水平之间的间隔是未知的。 在一些情况下，我们可以为有序变量的不同水平分配数字，实现定序变量转化为数值变量，但我们需要注意这些变量不是数值型的。例如，“非常同意”和“中立”不能平均为“同意”，即使我们将“非常同意”分配为5，将“中立”分配为3。 3.1.5 数值型变量 数值型变量描述了一个可测量的数量，其中数字之间的间隔是相等的。比如，1千克和2千克之间的间隔与3千克和4千克之间的间隔相等。 定距数据是一种数值性变量，一种具有等距间隔的变量，其中相邻数值之间的差异是相等的。比如气温。定距数据可以进行加减。 定比数据和定距数据的区别在于，定比数据有一个零点。比如，年龄、体重、身高都属于定比数据，不存在负值。定比数据除了可以加减运算以外，还可以乘除运算。我们可以说一个人的年龄是另外一个人的两倍。 数值型变量可以进一步分为连续（continuous）变量和离散（discrete）变量两个子类。 离散变量由整数值组成，不能取介于两个值之间的值。常见的离散变量有：车辆数量、家庭子女数量。它们都以整数单位衡量。 连续变量可以取一定集合范围内任意一个值。连续变量的观测值可以包括仪器测量允许的最小值。连续变量的例子包括身高、时间、年龄和温度。 变量类型将决定（1）统计分析的方法；（2）我们如何使用统计数据和图表总结数据。 数据层级 趋中性描述 变异性描述 数学运算 举例 定类 众数 不能 是否相等，集合关系 实验反应选项、词性、语音类别 定序 众数、中位数 不能 排序、比较 李克特量表问题数据 定距 众数、中位数、算数平均值 极差、方差、标准差 加减 温度 定比 众数、中位数、几何平均值 极差、方差、标准差 乘除 年龄、体重、身高 不同的变量需要以不同的数据类型存储在R中。名义变量和定序变量可以存储为字符类型（character）或因子（factors，具有级别）。数值型数据存储为数字，可以是整数（integer）、实数（real）、小数（decimal）。一个数据集（dataset）可以包含一个或者多个变量，这些变量可能有一种或者多种不同的类型。 3.2 数据清洁 数据清理（Data Cleaning）是数据科学和数据分析中的重要步骤，指的是对原始数据进行检查或修正，处理数据中的错误、缺失、异常和重复值等问题，从而得到干净、可靠的数据集，使数据更适合后续的分析和建模工作。 library(tidyverse) ## ── Attaching core tidyverse packages ───────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.3 ✔ readr 2.1.4 ## ✔ forcats 1.0.0 ✔ stringr 1.5.1 ## ✔ ggplot2 3.4.4 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.3 ✔ tidyr 1.3.0 ## ✔ purrr 1.0.2 ## ── Conflicts ─────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors # 创建含有错误值的数据 set.seed(123) # 设置随机种子以确保可重复性 df_errors &lt;- data.frame(Student_ID = 1:100, Listening_Score = sample(-5:100, 100, replace = TRUE), Speaking_Score = sample(0:999, 100, replace = TRUE), Reading_Score = sample(0:105, 100, replace = TRUE), Writing_Score = sample(0:100, 100, replace = TRUE), Age = sample(c(18:40, NA), 100, replace = TRUE), Gender = sample(c(&quot;Male&quot;, &quot;Female&quot;), 100, replace = TRUE)) 3.2.1 任务-处理异常值 异常值是指与其他观测值明显不同的异常点，可能是数据录入错误或者异常情况。可以选择删除异常值或者采用合适的方法进行处理。 筛除学生听力分数小于0的数据。 筛除学生阅读分数超过满分100分的数据。 筛除年龄缺失的数据 df.clean = df_errors %&gt;% filter(Listening_Score &gt; 0 | Reading_Score &lt; 100)%&gt;% filter(!is.na(Age)) 3.3 变量筛选 当变量过多时，我们可以选择部分变量组成新的数据框。 3.3.1 任务-变量筛选 选择所有女生的听力数据 选择所有男生的阅读数据 df.girl = df_errors %&gt;% filter(Gender == &quot;Female&quot;)%&gt;% select(Listening_Score) df.boy = df_errors %&gt;% filter(Gender == &quot;Male&quot;)%&gt;% select(Reading_Score) 3.4 数据塑形 数据重塑（Data Reshaping）是指将原始数据在行和列之间进行转换，从而改变数据的排列方式，以便于进行特定的数据分析或建模。tidyr是一个常用的数据整理包，主要用于处理数据的宽格式和长格式之间的转换。 Tidy data（整洁数据）是Hadley Wickham在2014年提出的一种数据组织原则，其目标是使数据集易于分析、可读性强，并且方便进行数据操作和可视化。在整洁数据中，每个变量都是一个列，每个观察值都是一个行，每个数据集都是一个表格。整洁数据遵循三个基本规则： 例子：学生考试成绩数据集 Student Subject Score Alice Math 85 Alice English 78 Bob Math 92 Bob English 88 在上面的例子中，每个变量都在数据集的一列中表示（例如，学生、科目、分数在学生考试成绩数据集中是列名），每个观察值在数据集的一行中表示（例如，每个学生的考试成绩是一行）。又称为长数据（Long data）。 相对而言，宽数据（Wide data）中每一行代表一个观察单元，不同属性或测量结果被放置在同一行的不同列中。 如下： 学生姓名 数学成绩 英语成绩 Alice 85 78 Bob 92 88 长数据和宽数据的选择取决于具体的数据分析需求和使用场景。在某些情况下，长数据更适合进行数据处理和可视化，而在其他情况下，宽数据更便于进行数据呈现。它们可以相互转换。 # 生成一个二语学术写作数据集 set.seed(123) # 设置随机种子，以确保结果可复现 academic_writing_data &lt;- tibble( student_id = 1:50, # 学生ID native_language = sample(c(&quot;Chinese&quot;, &quot;Spanish&quot;, &quot;French&quot;, &quot;Russian&quot;, &quot;German&quot;, &quot;Italian&quot;), 50, replace = TRUE), # 母语 second_language = sample(c(&quot;English&quot;, &quot;Chinese&quot;, &quot;Spanish&quot;, &quot;French&quot;, &quot;German&quot;, &quot;Italian&quot;), 50, replace = TRUE), # 二语 essay1_length = sample(200:2000, 50, replace = TRUE), # 论文1长度 essay2_length = sample(200:2000, 50, replace = TRUE), # 论文2长度 essay3_length = sample(200:2000, 50, replace = TRUE), # 论文3长度 academic_performance = sample(60:100, 50, replace = TRUE), # 学术成绩 writing_speed = sample(200:800, 50, replace = TRUE), # 写作速度（单词/分钟） language_anxiety = sample(1:5, 50, replace = TRUE), # 语言焦虑水平（1-5分） writing_errors = sample(0:30, 50, replace = TRUE), # 写作错误数 research_experience = sample(c(TRUE, FALSE), 50, replace = TRUE), # 是否有研究经验 self_evaluation = sample(c(&quot;Excellent&quot;, &quot;Good&quot;, &quot;Fair&quot;, &quot;Poor&quot;), 50, replace = TRUE) # 自我评价 ) 3.4.1 任务-数据塑形 把essay1_length、essay2_length和essay3_length三列汇总到一列中 把gathered_data_1转回宽格式 # 把essay1_length、essay2_length和essay3_length三列汇总到一列中 gathered_data_1 &lt;- gather(academic_writing_data, essay, length, essay1_length:essay3_length) # 把gathered_data_1转回宽格式 spreaded_data_1 &lt;- spread(gathered_data_1, essay, length) 3.5 数据整合 如果数据来自不同的源头，可能需要将多个数据集合并成一个整体数据集，进行数据整合和关联分析，即数据整合 （Data Integration）。 我们模拟了以下2个数据集： - 学生信息数据集（Student_Info）：包含学生ID、性别、年龄等学生信息。 - 语言测试数据集（Language_Test）：包含学生ID、听说读写分数等语言测试结果。 在这里，我们将把不同数据集中的学生ID作为核心进行合并。 3.5.1 任务-数据整合 合并学生信息数据集和语言测试数据集，创建一个包含学生信息和语言测试结果的数据集。 # 创建学生信息数据集 student_info &lt;- data.frame(Student_ID = 1:100, Gender = sample(c(&quot;Male&quot;, &quot;Female&quot;), 100, replace = TRUE), Age = sample(18:25, 100, replace = TRUE)) # 创建语言测试数据集 language_test &lt;- data.frame(Student_ID = 1:100, Listening_Score = sample(0:100, 100, replace = TRUE), Speaking_Score = sample(0:100, 100, replace = TRUE), Reading_Score = sample(0:100, 100, replace = TRUE), Writing_Score = sample(0:100, 100, replace = TRUE)) # 使用inner_join函数将学生信息数据集和语言测试数据集合并 merged_data &lt;- inner_join(student_info, language_test, by = &quot;Student_ID&quot;) "],["第四章-探索性数据分析.html", "Chapter 4 第四章 探索性数据分析 4.1 数据转换 4.2 数据可视化", " Chapter 4 第四章 探索性数据分析 探索性数据分析（Exploratory Data Analysis，简称EDA）通过可视化和统计手段来帮助人们理解数据中的模式和特征，发现数据中隐藏的关联性和趋势，为进一步的数据建模和分析提供基础,帮助数据科学家和分析师提出假设或问题。 探索性数据分析过程中会不断反复使用以下几个工具： 数据转换（Data Transformation）：对数据集中的数值变量进行变换、重构，进行描述性统计值计算（包括数据的趋中性和分布）。 数据可视化：通过绘制条形图、直方图、散点图、箱线图、密度图等，将数据可视化，更好地展示数据的趋中性和分布。 数据建模：通过统计模型验证数据之间的关系。 4.1 数据转换 对原始数据进行变换、重构的常见操作有： 标准化（Standardization）：将不同特征的数据缩放到相同的尺度。 归一化（Normalization）：将数据缩放到[0, 1]范围内。 对数化（Logarithm）：将数据进行对数变换，使得数据更加符合线性关系或满足某些假设。 此处，我们模拟创建一个包含200个汉语词汇的数据集，包含词频、抽象度、意象度、词汇起始习得年龄、词汇难度、词汇情感评分等变量。这里的数据均为模拟数据。 library(tidyverse) setwd(&quot;~/Nutstore Files/310_Tutorial/LanguageDS-e&quot;) # 创建含有真实汉语词汇的数据集 set.seed(123) # 设置随机种子以确保可重复性 df_vocabulary &lt;- data.frame(Word = c(&quot;苹果&quot;, &quot;梨子&quot;, &quot;香蕉&quot;, &quot;草莓&quot;, &quot;桃子&quot;, &quot;西瓜&quot;, &quot;橙子&quot;, &quot;柚子&quot;, &quot;葡萄&quot;, &quot;芒果&quot;, &quot;书&quot;, &quot;笔&quot;, &quot;课本&quot;, &quot;教室&quot;, &quot;黑板&quot;, &quot;学生&quot;, &quot;老师&quot;, &quot;考试&quot;, &quot;作业&quot;, &quot;校园&quot;, &quot;美食&quot;, &quot;旅游&quot;, &quot;音乐&quot;, &quot;电影&quot;, &quot;运动&quot;, &quot;阅读&quot;, &quot;绘画&quot;, &quot;写作&quot;, &quot;摄影&quot;, &quot;游戏&quot;, &quot;猫&quot;, &quot;狗&quot;, &quot;兔子&quot;, &quot;鱼&quot;, &quot;鸟&quot;, &quot;大象&quot;, &quot;狮子&quot;, &quot;熊猫&quot;, &quot;猴子&quot;, &quot;蛇&quot;, &quot;早晨&quot;, &quot;中午&quot;, &quot;下午&quot;, &quot;晚上&quot;, &quot;春天&quot;, &quot;夏天&quot;, &quot;秋天&quot;, &quot;冬天&quot;, &quot;天气&quot;, &quot;季节&quot;, &quot;篮球&quot;, &quot;足球&quot;, &quot;乒乓球&quot;, &quot;网球&quot;, &quot;羽毛球&quot;, &quot;游泳&quot;, &quot;滑雪&quot;, &quot;跑步&quot;, &quot;健身&quot;, &quot;瑜伽&quot;), Frequency = sample(1:1000, 60, replace = TRUE), Abstractness = sample(1:5, 60, replace = TRUE), Imagery = sample(1:5, 60, replace = TRUE), Age_of_Acquisition = sample(3:12, 60, replace = TRUE), Difficulty = sample(1:5, 60, replace = TRUE), Emotion_Score = sample(1:5, 60, replace = TRUE)) 4.1.1 任务-数据转化 计算每个词汇的情感得分与抽象度的乘积作为新特征Emotion_Abstractness_Product。 计算每个词汇的词频与意象度的差作为新特征Frequency_Imagery_Difference。 对词频特征进行Z-score标准化，并创建新特征Frequency_Zscore。 对词汇抽象度进行Min-Max归一化，并创建新特征Abstractness_Normalized 对词频特征进行对数化，并创建新特征Frequency_Log。 # 使用mutate函数创建新特征 df_vocabulary %&gt;% mutate(Emotion_Abstractness_Product = Emotion_Score * Abstractness, Frequency_Imagery_Difference = Frequency - Imagery, Frequency_Zscore = scale(Frequency), Abstractness_Normalized = (Abstractness - min(Abstractness)) / (max(Abstractness) - min(Abstractness)), Frequency_Log = log(Frequency)) ## Word Frequency Abstractness Imagery Age_of_Acquisition Difficulty ## 1 苹果 415 4 1 11 2 ## 2 梨子 463 5 2 6 5 ## 3 香蕉 179 2 1 12 1 ## 4 草莓 526 1 2 9 1 ## 5 桃子 195 1 5 11 2 ## 6 西瓜 938 3 3 9 1 ## 7 橙子 818 1 4 12 2 ## 8 柚子 118 5 4 6 5 ## 9 葡萄 299 1 1 10 1 ## 10 芒果 229 2 4 11 3 ## 11 书 244 4 1 11 2 ## 12 笔 14 4 3 11 2 ## 13 课本 374 3 4 7 5 ## 14 教室 665 1 3 9 4 ## 15 黑板 602 2 5 8 1 ## 16 学生 603 1 4 3 5 ## 17 老师 768 2 4 12 2 ## 18 考试 709 4 4 12 5 ## 19 作业 91 5 1 3 2 ## 20 校园 953 5 2 12 2 ## 21 美食 348 3 3 3 4 ## 22 旅游 649 1 4 12 3 ## 23 音乐 989 4 3 7 4 ## 24 电影 355 1 1 9 3 ## 25 运动 840 1 5 7 3 ## 26 阅读 26 3 5 12 3 ## 27 绘画 519 4 2 11 5 ## 28 写作 426 1 3 6 3 ## 29 摄影 649 3 5 8 2 ## 30 游戏 766 5 1 4 3 ## 31 猫 211 3 4 3 1 ## 32 狗 932 2 2 7 5 ## 33 兔子 590 5 4 11 1 ## 34 鱼 593 5 5 6 4 ## 35 鸟 555 3 5 5 2 ## 36 大象 871 2 5 11 2 ## 37 狮子 373 2 5 3 4 ## 38 熊猫 844 2 1 4 1 ## 39 猴子 143 4 2 6 4 ## 40 蛇 544 2 1 12 5 ## 41 早晨 490 2 2 3 5 ## 42 中午 621 4 5 7 3 ## 43 下午 775 4 5 7 5 ## 44 晚上 905 1 1 11 5 ## 45 春天 937 3 2 10 3 ## 46 夏天 842 3 5 9 1 ## 47 秋天 23 1 4 11 3 ## 48 冬天 923 3 2 7 4 ## 49 天气 956 5 2 4 2 ## 50 季节 309 2 3 12 5 ## 51 篮球 135 3 1 8 1 ## 52 足球 821 2 1 9 4 ## 53 乒乓球 923 5 5 11 3 ## 54 网球 224 5 5 3 1 ## 55 羽毛球 166 3 3 7 2 ## 56 游泳 217 4 2 7 3 ## 57 滑雪 290 4 5 10 3 ## 58 跑步 989 4 5 7 1 ## 59 健身 581 5 3 9 2 ## 60 瑜伽 72 3 3 6 1 ## Emotion_Score Emotion_Abstractness_Product Frequency_Imagery_Difference ## 1 2 8 414 ## 2 2 10 461 ## 3 2 4 178 ## 4 5 5 524 ## 5 4 4 190 ## 6 4 12 935 ## 7 5 5 814 ## 8 4 20 114 ## 9 1 1 298 ## 10 2 4 225 ## 11 1 4 243 ## 12 2 8 11 ## 13 3 9 370 ## 14 2 2 662 ## 15 3 6 597 ## 16 1 1 599 ## 17 4 8 764 ## 18 2 8 705 ## 19 3 15 90 ## 20 5 25 951 ## 21 5 15 345 ## 22 3 3 645 ## 23 2 8 986 ## 24 5 5 354 ## 25 4 4 835 ## 26 2 6 21 ## 27 1 4 517 ## 28 4 4 423 ## 29 1 3 644 ## 30 4 20 765 ## 31 5 15 207 ## 32 4 8 930 ## 33 2 10 586 ## 34 2 10 588 ## 35 4 12 550 ## 36 3 6 866 ## 37 5 10 368 ## 38 2 4 843 ## 39 3 12 141 ## 40 3 6 543 ## 41 3 6 488 ## 42 1 4 616 ## 43 1 4 770 ## 44 3 3 904 ## 45 4 12 935 ## 46 4 12 837 ## 47 5 5 19 ## 48 2 6 921 ## 49 2 10 954 ## 50 4 8 306 ## 51 2 6 134 ## 52 1 2 820 ## 53 4 20 918 ## 54 3 15 219 ## 55 1 3 163 ## 56 5 20 215 ## 57 3 12 285 ## 58 4 16 984 ## 59 2 10 578 ## 60 5 15 69 ## Frequency_Zscore Abstractness_Normalized Frequency_Log ## 1 -0.371413868 0.75 6.028279 ## 2 -0.212354843 1.00 6.137727 ## 3 -1.153454071 0.25 5.187386 ## 4 -0.003589874 0.00 6.265301 ## 5 -1.100434396 0.00 5.273000 ## 6 1.361666752 0.50 6.843750 ## 7 0.964019191 0.00 6.706862 ## 8 -1.355591581 1.00 4.770685 ## 9 -0.755806510 0.00 5.700444 ## 10 -0.987767587 0.25 5.433722 ## 11 -0.938061642 0.75 5.497168 ## 12 -1.700219467 0.75 2.639057 ## 13 -0.507276784 0.50 5.924256 ## 14 0.457018551 0.00 6.499787 ## 15 0.248253581 0.25 6.400257 ## 16 0.251567311 0.00 6.401917 ## 17 0.798332708 0.25 6.643790 ## 18 0.602822657 0.75 6.563856 ## 19 -1.445062282 1.00 4.510860 ## 20 1.411372697 1.00 6.859615 ## 21 -0.593433756 0.50 5.852202 ## 22 0.403998876 0.00 6.475433 ## 23 1.530666966 0.75 6.896694 ## 24 -0.570237648 0.00 5.872118 ## 25 1.036921244 0.00 6.733402 ## 26 -1.660454711 0.50 3.258097 ## 27 -0.026785982 0.75 6.251904 ## 28 -0.334962841 0.00 6.054439 ## 29 0.403998876 0.50 6.475433 ## 30 0.791705248 1.00 6.641182 ## 31 -1.047414721 0.50 5.351858 ## 32 1.341784374 0.25 6.837333 ## 33 0.208488825 1.00 6.380123 ## 34 0.218430014 1.00 6.385194 ## 35 0.092508287 0.50 6.318968 ## 36 1.139646864 0.25 6.769642 ## 37 -0.510590514 0.25 5.921578 ## 38 1.050176163 0.25 6.738152 ## 39 -1.272748339 0.75 4.962845 ## 40 0.056057260 0.25 6.298949 ## 41 -0.122884142 0.25 6.194405 ## 42 0.311214445 0.75 6.431331 ## 43 0.821528815 0.75 6.652863 ## 44 1.252313673 0.00 6.807935 ## 45 1.358353023 0.50 6.842683 ## 46 1.043548704 0.50 6.735780 ## 47 -1.670395900 0.00 3.135494 ## 48 1.311960807 0.50 6.827629 ## 49 1.421313886 1.00 6.862758 ## 50 -0.722669213 0.25 5.733341 ## 51 -1.299258177 0.50 4.905275 ## 52 0.973960380 0.25 6.710523 ## 53 1.311960807 1.00 6.827629 ## 54 -1.004336236 1.00 5.411646 ## 55 -1.196532557 0.50 5.111988 ## 56 -1.027532343 0.75 5.379897 ## 57 -0.785630077 0.75 5.669881 ## 58 1.530666966 0.75 6.896694 ## 59 0.178665258 1.00 6.364751 ## 60 -1.508023146 0.50 4.276666 对于数据集中的连续型变量，我们常常会根据不同组别进行描述性统计。通常我们从两个方面描述连续型变量：中心趋势（Measures of Central Tendency）和分布。 中心趋势度量可以由众数（Mode）、中位数（Median）和均值（Mean），每个指标都描述了分布中不同的典型值或中心值。均值（Mean）是数据集中每个观测值的值之和除以观测值的数量。这也被称为算术平均值。均值适用于连续和离散数值数据。但是均值无法计算分类数据，因为无法对这些值进行求和。由于均值包括分布中的每个值，因此受到异常值和偏斜分布的影响。总体均值是用希腊字母μ（读作“mu”）表示的。当从样本中计算均值时，用符号x̅（读作X-bar）表示。 中位数（Median）是数据按升序或降序排列时的中间值。中位数将分布分成两半（中位数值的两侧各有50％的观测值）。在具有奇数个观测值的分布中，中位数是中间值。当分布中有偶数个观测值时，中位数是两个中间值的平均值。中位数对于异常值和偏斜数据的影响较小，通常在分布不对称时作为首选的中心趋势度量。对于分类名义数据，无法确定中位数，因为它们无法进行逻辑排序。 众数（Mode）是分布中出现最频繁的值。与中位数和均值相比，众数对于数值和分类（非数值）数据都适用。 在某些分布中，众数可能无法很好地反映分布的中心。 &gt; 54, 54, 54, 55, 56, 57, 57, 58, 58, 60, 60 上述数据集中的分布中心是57岁，但众数却较低，为54岁。 同一个数据集中可能存在多个众数，称为双峰分布或多峰分布。多个众数的存在限制了众数对于描述分布的中心或典型值的能力，因为无法确定单个值来描述中心。在某些情况下，特别是在数据连续的情况下，分布可能根本没有众数（即所有值都不同）。在这种情况下，更好地考虑使用中位数或均值，或者将数据分组为适当的间隔，并找到众数组。 除了中心趋势之外，数值型变量的另一个描述维度是分布。 比如下面这两组数据的中心趋势相同但是二者的离散程度不同 集合1: 4, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8 集合2: 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11 dataset1 = c(4, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 8) dataset2 = c(1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11) dataset = data.frame(dataset1, dataset2) dataset = gather(dataset, type, data) ggplot(dataset, aes(data, fill = type)) + geom_bar(position=position_dodge()) range(dataset1) ## [1] 4 8 quantile(dataset1) ## 0% 25% 50% 75% 100% ## 4 5 6 7 8 quantile(dataset2) ## 0% 25% 50% 75% 100% ## 1.00 3.75 6.00 8.25 11.00 var(dataset1) ## [1] 1.272727 sqrt(var(dataset1)) ## [1] 1.128152 sd(dataset1) ## [1] 1.128152 对于数据分布的度量指标有极差（Range）、四分位数（Quartiles）、四分位距（Interquartile Range，IQR）、方差（variance） 和标准差（standard deviation）。 极差是最大值和最小值之间的差异。四分位数（Quartiles）将有序数据集分为四个等份。四分位距（Interquartile Range，IQR）是上四分位数（Q3）和下四分位数（Q1）之间的差值，用于描述数据集从最低到最高排序的中间50％的值。与极差相比，IQR通常被视为更好的散布度量，因为它不受异常值的影响。方差和标准差是衡量每个观察数据值与均值的接近程度的度量。在具有较小散布的数据集中，所有值都非常接近均值，导致方差和标准差较小。当数据集更为分散时，值离均值的距离较远，导致方差和标准差较大。方差和标准差越小，均值就越能代表整个数据集。因此，如果数据集的所有值都相同，则标准差和方差为零。 标准差是方差的平方根。正态分布的标准差使我们能够计算置信区间。在正态分布中，约68％的值在均值的一个标准差内，约95％的分数在均值的两个标准差内。 五数概括（Five-number summary）是一组描述性统计量，样本最小值（最小观测值）、第一四分位数、中位数（中间值）、第三四分位数、样本最大值（最大观测值）。五数概括提供了数据观测分布的简洁概述。报告这五个数字避免了需要决定最适合的摘要统计量。 通常我们会基于一个分组变量来计算另一个变量的描述性统计指标。 4.1.2 任务-描述性统计 计算男女生各门成绩的均分和标准差 df.score = data.frame(Student_ID = 1:100, Listening_Score = sample(-5:100, 100, replace = TRUE), Speaking_Score = sample(0:999, 100, replace = TRUE), Reading_Score = sample(0:105, 100, replace = TRUE), Writing_Score = sample(0:100, 100, replace = TRUE), Gender = sample(c(&quot;Male&quot;, &quot;Female&quot;), 100, replace = TRUE)) # 计算每种母语的学习者的平均学习时长 df.mean.sd &lt;- df.score %&gt;% filter(Listening_Score &gt; 0 | Reading_Score &lt; 100)%&gt;% group_by(Gender) %&gt;% summarise(Listening.mean = mean(Listening_Score), Listening.sd = sd(Listening_Score)) 4.2 数据可视化 上面我们已经对于数据进行了一些转换操作，并通过描述性统计指标对数据中的变量有所了解。我们可以通过图表对数据进行可视化来进一步揭示数据之间的关系。数据可视化过程中需要考虑到数据中变量的类型和数量。 4.2.1 单变量数据可视化 描述分类变量的最佳方式是通过频率。频率可以用不同的方式表示。绝对频率描述一个特定变量出现的次数,就是计数。相对频率描述一个特定变量出现的次数与该变量的总值之间的关系。比如，在语言研究中，我们最常见的分类变量就是词汇或者语法类别。在语料库研究中我们会统计词汇的相对整个语料库总词数的频率。在写作研究中，我们会统计学生名词、动词等不同词类的使用次数。 常见的显示频率分布的方法包括频率表和条形图。频率表是一种简单直接的方式，用于显示特定值或特征出现的次数。条形图则可以基于频率表进行可视化，使得结果更加便于展示。这里我们使用janeaustenr这个包里所包含的简奥斯丁小说数据来构建小说中的词频表，并基于词频表产生条形图。 #用于数据 library(janeaustenr) #用于分词 library(tidytext) library(dplyr) library(stringr) austen.emma.word &lt;- austen_books() %&gt;% group_by(book) %&gt;% mutate(linenumber = row_number(), chapter = cumsum(str_detect(text, regex(&quot;^chapter [\\\\divxlc]&quot;, ignore_case = TRUE)))) %&gt;% unnest_tokens(word, text)%&gt;% count(word, sort = TRUE) %&gt;% #筛选Emma这个小说 filter(book == &quot;Emma&quot;)%&gt;% #显示前20个高频词 head(20) 4.2.1.1 条形图 条形图是一种图表类型，其中每个列（可以是垂直或水平绘制）的高度（如果是垂直条形图）或长度（如果是水平条形图）表示一个分类变量的频率（计数）。每个条之间都包含有间隔，可以按任意顺序排列，而不影响数据。 我们根据上述Emma小说最高频的20个词，绘制条形图。 library(ggplot2) austen.emma.word %&gt;% #给高频词排序 mutate(word = reorder(word, n)) %&gt;% ggplot(aes(n, word)) + geom_col() + labs(y = NULL) 连续变量的描述包括中心趋势和分布。在可视化中我们可以使用箱线图、小提琴图和直方图来显示这两个方面的不同特征。 4.2.1.2 箱线图和小提琴图 箱线图通过从盒子（也称为“须”）延伸垂直线来表示上下四分位数外的变异性。异常值会以单独的点显示。盒子的不同部分之间的间隔表示数据的离散程度。箱线图通常绘制六个数据点，最小值（排除异常值）、第一四分位数、中位数、第三四分位数、最大值（排除异常值）、异常值。 小提琴图结合了箱线图和密度图的特点，可以更直观地展示数据的分布情况。在小提琴图中，箱线图表示五数概括，而密度图展示数据的概率密度分布。 # `languageR` 包中包含了多个数据集，供用户在语言学研究和数据分析中使用。其中`lexdec`:包含了英语词汇决策任务的数据，用于研究词汇的判断和决策过程。 library(languageR) data(&quot;lexdec&quot;) ggplot(lexdec, aes(x=&quot;RT&quot;, y=RT))+ geom_boxplot() #violin plot ggplot(lexdec, aes(x=&quot;RT&quot;, y=RT))+ geom_violin() 4.2.1.3 直方图 直方图展示了数据集中所有观察值的分布情况。柱的高度显示了特定数值范围的频数。柱通常具有相等的宽度，每个柱所代表的数值必须是互斥且完整的，之间没有空隙，每个观察值只能属于一个柱。 直方图和柱状图有一些区别：柱状图适用于展示不同类别变量，每个柱子代表一个类别，高度表示该类别的频数或频率。直方图适用于展示连续变量的分布情况，将数据分成若干连续的区间，每个区间称为一个“柱”，高度表示该区间内数据的频数或频率。 柱状图的X轴通常显示不同的类别标签，例如产品名称、地区等。直方图的X轴显示连续变量的数值范围，例如温度、成绩等。在柱状图中，各个柱体之间通常有间隔，以区分不同的类别。在直方图中，各个柱体紧密相邻，没有间隔，因为它们代表连续的数值区间。 # histogram ggplot(lexdec)+ geom_histogram(aes(RT), binwidth = 0.1) 4.2.1.4 密度图 密度图（Density Plot）也可以展示数据分布，它通过平滑数据点来显示数据在不同区间的密度，提供数据分布的连续视图。与直方图不同，密度图通过使用核密度估计（Kernel Density Estimation, KDE）等方法对数据进行平滑处理，形成一条连续的曲线。可以在同一图上绘制多条密度曲线，便于比较不同组数据的分布差异。 ggplot(lexdec, aes(RT))+ geom_freqpoly(binwidth = 0.1) 4.2.2 多变量数据 变异性（Covariation）用来描述一个变量，协变性描述的是两个或多个变量之间的相互作用。 4.2.2.1 瓦片图（tile plot） 对于两个分类变量，我们可以使用交叉表（contingency table）来描述两个分类变量之间的协变性，显示各自的频率。 table(lexdec$NativeLanguage,lexdec$Sex) ## ## F M ## English 553 395 ## Other 553 158 lexdec%&gt;% count(Class, Correct)%&gt;% ggplot(aes(Class, Correct))+ geom_tile(aes(fill=n)) ggplot(lexdec)+ geom_count(aes(Class, Correct)) 4.2.2.2 分类变量+连续变量 如果既包含分类变量也包含连续变量，可以通过将分类变量视为组别来可视化，其与连续变量之间的协变性。我们可以通过柱状图加误差线的方法来表示不同组之间均值和变异性的差别。也可以通过箱型图和小提琴图来表示。此外我们还可以通过密度图来表示不同的分布特征。 #bar plot lexdec%&gt;% group_by(PrevType)%&gt;% summarise(mean = mean(RT))%&gt;% ggplot(aes(PrevType, mean))+ geom_bar(stat=&quot;identity&quot;) lexdec%&gt;% group_by(PrevType)%&gt;% summarise(mean = mean(RT), sd = sd(RT))%&gt;% ggplot(aes(PrevType, mean, fill = PrevType))+ geom_bar(stat=&quot;identity&quot;)+ geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd), width = .2, size = 0.7, position = position_dodge(.9)) ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. lexdec%&gt;% ggplot(., aes(x=PrevType, y=RT))+ geom_boxplot() #violin plot lexdec%&gt;% ggplot(., aes(x=PrevType, y=RT))+ geom_violin() # 密度图 ggplot(lexdec, aes(x = RT, y = ..density..))+ geom_freqpoly(aes(color = PrevType), binwidth = 0.1) ## Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0. ## ℹ Please use `after_stat(density)` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. 如果变量均为连续变量，我们最常见的方式是使用散点图来可视化两个连续变量之间的关系。 4.2.2.3 两个连续变量 散点图 ggplot(lexdec)+ geom_point(aes(RT, Frequency)) "],["第五章-语言实验数据分析.html", "Chapter 5 第五章 语言实验数据分析 5.1 数据导入 5.2 数据整理 5.3 数据转化 5.4 可视化", " Chapter 5 第五章 语言实验数据分析 实验是心理语言学常用的研究方法。对于实验数据的基本分析，包括数据导入，数据整理，数据转换，数据可视化和数据建模。本章以语音感知领域的一个实验为例，介绍在R语言环境中行为实验中数据分析的过程。 研究背景 成年人对言语语音的感知受到母语语音系统的影响。对于母语中没有，而外语中存在的音位对立，人们感知起来会存在困难。因此，对于母语和外语语音感知关系的研究对于外语学习和教学来说非常重要。常用的实验方法或者任务是跨语言感知实验。此类实验中，被试会听到外语语音，然后需要选择与之最相似的母语语音，并且为这种相似度评分。通过对于母语和外语映射关系的分析，结合相关理论，如感知同化模型，我们可以预测不同外语音位对立的感知难度。声调语言占全世界语言的70%，但是相关的跨语言感知研究却很有限，下面的分析基于Chen et al 2020中的部分数据，分析汉语母语者跨语言感知泰语声调的模式。 5.1 数据导入 为了方便数据读取和存储，建议设置工作路径。这里可以将工作路径设置在配套数据文件夹ch5中。实验是使用E-prime进行编程获取的感知数据，单个人的原始数据可以用E-prime进行合成导出成为txt纯文本格式。首先我们使用R的导入函数进行导入得到一个数据框。 library(tidyverse) setwd(&quot;~/Nutstore Files/310_Tutorial/LanguageDS-e&quot;) cm13 &lt;- read.delim(&quot;data/ch5/cm13.txt&quot;) head(cm13) ## ExperimentName Subject Session ## 1 Assimilation_2b 101 1 ## 2 Assimilation_2b 101 1 ## 3 Assimilation_2b 101 1 ## 4 Assimilation_2b 101 1 ## 5 Assimilation_2b 101 1 ## 6 Assimilation_2b 101 1 ## Clock.Information ## 1 &lt;?xml version=1.0?&gt;\\\\n&lt;Clock xmlns:dt=urn:schemas-microsoft-com:datatypes&gt;&lt;Description dt:dt=string&gt;E-Prime Primary Realtime Clock&lt;/Description&gt;&lt;StartTime&gt;&lt;Timestamp dt:dt=int&gt;0&lt;/Timestamp&gt;&lt;DateUtc dt:dt=string&gt;2017-12-26T06:39:05Z&lt;/DateUtc&gt;&lt;/StartTime&gt;&lt;FrequencyChanges&gt;&lt;FrequencyChange&gt;&lt;Frequency dt:dt=r8&gt;2742343&lt;/Frequency&gt;&lt;Timestamp dt:dt=r8&gt;15765959310&lt;/Timestamp&gt;&lt;Current dt:dt=r8&gt;0&lt;/Current&gt;&lt;DateUtc dt:dt=string&gt;2017-12-26T06:39:05Z&lt;/DateUtc&gt;&lt;/FrequencyChange&gt;&lt;/FrequencyChanges&gt;&lt;/Clock&gt;\\\\n ## 2 &lt;?xml version=1.0?&gt;\\\\n&lt;Clock xmlns:dt=urn:schemas-microsoft-com:datatypes&gt;&lt;Description dt:dt=string&gt;E-Prime Primary Realtime Clock&lt;/Description&gt;&lt;StartTime&gt;&lt;Timestamp dt:dt=int&gt;0&lt;/Timestamp&gt;&lt;DateUtc dt:dt=string&gt;2017-12-26T06:39:05Z&lt;/DateUtc&gt;&lt;/StartTime&gt;&lt;FrequencyChanges&gt;&lt;FrequencyChange&gt;&lt;Frequency dt:dt=r8&gt;2742343&lt;/Frequency&gt;&lt;Timestamp dt:dt=r8&gt;15765959310&lt;/Timestamp&gt;&lt;Current dt:dt=r8&gt;0&lt;/Current&gt;&lt;DateUtc dt:dt=string&gt;2017-12-26T06:39:05Z&lt;/DateUtc&gt;&lt;/FrequencyChange&gt;&lt;/FrequencyChanges&gt;&lt;/Clock&gt;\\\\n ## 3 &lt;?xml version=1.0?&gt;\\\\n&lt;Clock xmlns:dt=urn:schemas-microsoft-com:datatypes&gt;&lt;Description dt:dt=string&gt;E-Prime Primary Realtime Clock&lt;/Description&gt;&lt;StartTime&gt;&lt;Timestamp dt:dt=int&gt;0&lt;/Timestamp&gt;&lt;DateUtc dt:dt=string&gt;2017-12-26T06:39:05Z&lt;/DateUtc&gt;&lt;/StartTime&gt;&lt;FrequencyChanges&gt;&lt;FrequencyChange&gt;&lt;Frequency dt:dt=r8&gt;2742343&lt;/Frequency&gt;&lt;Timestamp dt:dt=r8&gt;15765959310&lt;/Timestamp&gt;&lt;Current dt:dt=r8&gt;0&lt;/Current&gt;&lt;DateUtc dt:dt=string&gt;2017-12-26T06:39:05Z&lt;/DateUtc&gt;&lt;/FrequencyChange&gt;&lt;/FrequencyChanges&gt;&lt;/Clock&gt;\\\\n ## 4 &lt;?xml version=1.0?&gt;\\\\n&lt;Clock xmlns:dt=urn:schemas-microsoft-com:datatypes&gt;&lt;Description dt:dt=string&gt;E-Prime Primary Realtime Clock&lt;/Description&gt;&lt;StartTime&gt;&lt;Timestamp dt:dt=int&gt;0&lt;/Timestamp&gt;&lt;DateUtc dt:dt=string&gt;2017-12-26T06:39:05Z&lt;/DateUtc&gt;&lt;/StartTime&gt;&lt;FrequencyChanges&gt;&lt;FrequencyChange&gt;&lt;Frequency dt:dt=r8&gt;2742343&lt;/Frequency&gt;&lt;Timestamp dt:dt=r8&gt;15765959310&lt;/Timestamp&gt;&lt;Current dt:dt=r8&gt;0&lt;/Current&gt;&lt;DateUtc dt:dt=string&gt;2017-12-26T06:39:05Z&lt;/DateUtc&gt;&lt;/FrequencyChange&gt;&lt;/FrequencyChanges&gt;&lt;/Clock&gt;\\\\n ## 5 &lt;?xml version=1.0?&gt;\\\\n&lt;Clock xmlns:dt=urn:schemas-microsoft-com:datatypes&gt;&lt;Description dt:dt=string&gt;E-Prime Primary Realtime Clock&lt;/Description&gt;&lt;StartTime&gt;&lt;Timestamp dt:dt=int&gt;0&lt;/Timestamp&gt;&lt;DateUtc dt:dt=string&gt;2017-12-26T06:39:05Z&lt;/DateUtc&gt;&lt;/StartTime&gt;&lt;FrequencyChanges&gt;&lt;FrequencyChange&gt;&lt;Frequency dt:dt=r8&gt;2742343&lt;/Frequency&gt;&lt;Timestamp dt:dt=r8&gt;15765959310&lt;/Timestamp&gt;&lt;Current dt:dt=r8&gt;0&lt;/Current&gt;&lt;DateUtc dt:dt=string&gt;2017-12-26T06:39:05Z&lt;/DateUtc&gt;&lt;/FrequencyChange&gt;&lt;/FrequencyChanges&gt;&lt;/Clock&gt;\\\\n ## 6 &lt;?xml version=1.0?&gt;\\\\n&lt;Clock xmlns:dt=urn:schemas-microsoft-com:datatypes&gt;&lt;Description dt:dt=string&gt;E-Prime Primary Realtime Clock&lt;/Description&gt;&lt;StartTime&gt;&lt;Timestamp dt:dt=int&gt;0&lt;/Timestamp&gt;&lt;DateUtc dt:dt=string&gt;2017-12-26T06:39:05Z&lt;/DateUtc&gt;&lt;/StartTime&gt;&lt;FrequencyChanges&gt;&lt;FrequencyChange&gt;&lt;Frequency dt:dt=r8&gt;2742343&lt;/Frequency&gt;&lt;Timestamp dt:dt=r8&gt;15765959310&lt;/Timestamp&gt;&lt;Current dt:dt=r8&gt;0&lt;/Current&gt;&lt;DateUtc dt:dt=string&gt;2017-12-26T06:39:05Z&lt;/DateUtc&gt;&lt;/FrequencyChange&gt;&lt;/FrequencyChanges&gt;&lt;/Clock&gt;\\\\n ## DataFile.Basename Display.RefreshRate ExperimentVersion Group ## 1 Assimilation_2b-101-1 60.015 1.0.0.62 1 ## 2 Assimilation_2b-101-1 60.015 1.0.0.62 1 ## 3 Assimilation_2b-101-1 60.015 1.0.0.62 1 ## 4 Assimilation_2b-101-1 60.015 1.0.0.62 1 ## 5 Assimilation_2b-101-1 60.015 1.0.0.62 1 ## 6 Assimilation_2b-101-1 60.015 1.0.0.62 1 ## RandomSeed RuntimeCapabilities RuntimeVersion RuntimeVersionExpected ## 1 -1413574928 Professional 2.0.10.353 2.0.10.353 ## 2 -1413574928 Professional 2.0.10.353 2.0.10.353 ## 3 -1413574928 Professional 2.0.10.353 2.0.10.353 ## 4 -1413574928 Professional 2.0.10.353 2.0.10.353 ## 5 -1413574928 Professional 2.0.10.353 2.0.10.353 ## 6 -1413574928 Professional 2.0.10.353 2.0.10.353 ## SessionDate SessionStartDateTimeUtc SessionTime StudioVersion Block ## 1 12-26-2017 26-Dec-17 6:39:05 AM 17:39:05 2.0.10.248 1 ## 2 12-26-2017 26-Dec-17 6:39:05 AM 17:39:05 2.0.10.248 2 ## 3 12-26-2017 26-Dec-17 6:39:05 AM 17:39:05 2.0.10.248 3 ## 4 12-26-2017 26-Dec-17 6:39:05 AM 17:39:05 2.0.10.248 4 ## 5 12-26-2017 26-Dec-17 6:39:05 AM 17:39:05 2.0.10.248 5 ## 6 12-26-2017 26-Dec-17 6:39:05 AM 17:39:05 2.0.10.248 6 ## explist explist.Cycle explist.Sample filename.Block. praclist ## 1 NA NA NA Thai_F4_maa241-5 2 ## 2 NA NA NA Thai_F4_maa45-4 15 ## 3 NA NA NA Thai_F4_maa45-3 5 ## 4 NA NA NA Thai_F4_mii33-5 9 ## 5 NA NA NA Thai_F4_mii315-6 18 ## 6 NA NA NA Thai_F4_mii45-3 20 ## praclist.Cycle praclist.Sample pracSlide1.ACC pracSlide1.CRESP ## 1 1 1 0 NA ## 2 1 2 0 NA ## 3 1 3 0 NA ## 4 1 4 0 NA ## 5 1 5 0 NA ## 6 1 6 0 NA ## pracSlide1.DurationError pracSlide1.OnsetDelay pracSlide1.OnsetTime ## 1 0 -1 146763 ## 2 0 0 155761 ## 3 0 -1 164758 ## 4 0 -1 173756 ## 5 0 -1 182754 ## 6 0 0 191752 ## pracSlide1.OnsetToOnsetTime pracSlide1.RESP pracSlide1.RT ## 1 0 2 2590 ## 2 0 5 1992 ## 3 0 6 2584 ## 4 0 7 2443 ## 5 0 7 2329 ## 6 0 7 2480 ## pracSlide1.RTTime pracSoundOut1.ACC pracSoundOut1.CRESP ## 1 149353 1 NA ## 2 157753 0 NA ## 3 167342 0 NA ## 4 176199 0 NA ## 5 185083 0 NA ## 6 194232 0 NA ## pracSoundOut1.DurationError pracSoundOut1.OnsetDelay ## 1 369 -1 ## 2 0 -1 ## 3 0 -1 ## 4 0 -1 ## 5 0 -1 ## 6 0 -1 ## pracSoundOut1.OnsetTime pracSoundOut1.RESP pracSoundOut1.RT ## 1 142763 0 ## 2 151761 h 2823 ## 3 160759 g 3714 ## 4 169756 f 2269 ## 5 178754 h 1286 ## 6 187752 g 1549 ## pracSoundOut1.RTTime Procedure.Block. Running.Block. speaker.Block. ## 1 0 pracproc praclist F4 ## 2 154584 pracproc praclist F4 ## 3 164473 pracproc praclist F4 ## 4 172025 pracproc praclist F4 ## 5 180040 pracproc praclist F4 ## 6 189301 pracproc praclist F4 ## syllable.Block. token.Block. tone.Block. Trial f1List1 f1List1.Cycle ## 1 maa 5 241 NA NA NA ## 2 maa 4 45 NA NA NA ## 3 maa 3 45 NA NA NA ## 4 mii 5 33 NA NA NA ## 5 mii 6 315 NA NA NA ## 6 mii 3 45 NA NA NA ## f1List1.Sample f1List2 f1List2.Cycle f1List2.Sample f2List1 f2List1.Cycle ## 1 NA NA NA NA NA NA ## 2 NA NA NA NA NA NA ## 3 NA NA NA NA NA NA ## 4 NA NA NA NA NA NA ## 5 NA NA NA NA NA NA ## 6 NA NA NA NA NA NA ## f2List1.Sample f2List2 f2List2.Cycle f2List2.Sample filename.Trial. ## 1 NA NA NA NA ## 2 NA NA NA NA ## 3 NA NA NA NA ## 4 NA NA NA NA ## 5 NA NA NA NA ## 6 NA NA NA NA ## Procedure.Trial. Running.Trial. Slide1.ACC Slide1.CRESP ## 1 NA NA ## 2 NA NA ## 3 NA NA ## 4 NA NA ## 5 NA NA ## 6 NA NA ## Slide1.DurationError Slide1.OnsetDelay Slide1.OnsetTime ## 1 NA NA NA ## 2 NA NA NA ## 3 NA NA NA ## 4 NA NA NA ## 5 NA NA NA ## 6 NA NA NA ## Slide1.OnsetToOnsetTime Slide1.RESP Slide1.RT Slide1.RTTime SoundOut1.ACC ## 1 NA NA NA NA NA ## 2 NA NA NA NA NA ## 3 NA NA NA NA NA ## 4 NA NA NA NA NA ## 5 NA NA NA NA NA ## 6 NA NA NA NA NA ## SoundOut1.CRESP SoundOut1.DurationError SoundOut1.OnsetDelay ## 1 NA NA NA ## 2 NA NA NA ## 3 NA NA NA ## 4 NA NA NA ## 5 NA NA NA ## 6 NA NA NA ## SoundOut1.OnsetTime SoundOut1.RESP SoundOut1.RT SoundOut1.RTTime ## 1 NA NA NA ## 2 NA NA NA ## 3 NA NA NA ## 4 NA NA NA ## 5 NA NA NA ## 6 NA NA NA ## speaker.Trial. syllable.Trial. token.Trial. tone.Trial. ## 1 NA NA ## 2 NA NA ## 3 NA NA ## 4 NA NA ## 5 NA NA ## 6 NA NA # library(readr) # assimilation &lt;- read_csv(&quot;~/Nutstore Files/310_Tutorial/Language data science/data/ch5/assimilation.csv&quot;) # # head(assimilation) 此时我们得到一个1820行，84列的数据框，里面包含了13名汉语普通话母语者感知不同泰语声调，并将其同化为普通话四个声调的数据。 5.2 数据整理 在正式实验之前，我们让被试进行了几个试次的练习。因此，首先我们需要去掉被试在练习时的数据。原始数据中每列的名称受到E-prime编程和运行的影响，有很多列是没有用的。为了方便后续数据处理，我们选择需要的列（即刺激和对于的选择和反应时数据），并去除被试没有作答的试次。 assim.clean = cm13%&gt;% # 除去练习数据 filter(., Procedure.Block. != &quot;pracproc&quot;) %&gt;% # 选择需要的列并将变量名修改 select(., subject = &quot;Subject&quot;, stimuli = &quot;tone.Trial.&quot;, response = &quot;SoundOut1.RESP&quot;, response_rt = &quot;SoundOut1.RT&quot;, rating = &quot;Slide1.RESP&quot;, rating_rt = &quot;Slide1.RT&quot;)%&gt;% # 除去被试未作答的试次 filter(., response !=&quot;&quot;)%&gt;% # 反应时为刺激播放后1000毫秒后的被试反应，原始数据从刺激播放开始记录，因此进行调整。 mutate(., response_rt = response_rt-1000)%&gt;% # 将被试的按键反应改写成相应的母语声调类别，修改刺激名称 mutate(response =dplyr:: recode(response, f = &quot;M55&quot;, g = &quot;M35&quot;, h = &quot;M214&quot;, j = &quot;M51&quot;), stimuli = dplyr:: recode(stimuli, &quot;33&quot; = &quot;T33&quot;, &quot;21&quot; = &quot;T21&quot;, &quot;45&quot; = &quot;T45&quot;, &quot;315&quot; = &quot;T315&quot;, &quot;241&quot; = &quot;T241&quot;)) # mutate(n = 1)%&gt;% # group_by(language, subject, stimuli, response)%&gt;% # summarise(cat = sum(n), # response_rt = mean(response_rt, na.rm = TRUE), # rating = mean(rating, na.rm = TRUE), # #rating_rt = mean(rating_rt,na.rm = TRUE) # )%&gt;% # group_by(subject, stimuli)%&gt;% # mutate(percent = cat/sum(cat))%&gt;% # ungroup()%&gt;% # mutate() # tbl.cat = cat.final%&gt;% # mutate(stimuli = as_factor(stimuli), # response = as_factor(response), # stimuli = fct_relevel(stimuli, &quot;T45&quot;,&quot;T33&quot;,&quot;T21&quot;,&quot;T315&quot;,&quot;T241&quot;), # response = fct_relevel(response, # &quot;M55&quot;,&quot;M35&quot;,&quot;M214&quot;,&quot;M51&quot;, # &quot;NV44&quot;,&quot;NV22&quot;,&quot;NV35&quot;,&quot;NV21&quot;,&quot;NV415&quot;,&quot;NV214&quot;, # &quot;SV44&quot;,&quot;SV22&quot;,&quot;SV35&quot;,&quot;SV21&quot;,&quot;SV214&quot;))%&gt;% # group_by(stimuli,response)%&gt;% # summarise(cat.mean = round(sum(percent)/13, 3)*100, # rate.mean = round(mean(rating,na.rm = TRUE),1))%&gt;% # gather(temp, score, ends_with(&quot;.mean&quot;)) %&gt;% # unite(temp1, stimuli, temp, sep = &quot;_&quot;)%&gt;% # spread(temp1, score)%&gt;% # #change the order of columns # select(&quot;response&quot; , &quot;T45_cat.mean&quot;, &quot;T45_rate.mean&quot;, # &quot;T33_cat.mean&quot; , &quot;T33_rate.mean&quot;, # &quot;T21_cat.mean&quot;,&quot;T21_rate.mean&quot;, # &quot;T315_cat.mean&quot;, &quot;T315_rate.mean&quot;, # &quot;T241_cat.mean&quot;, &quot;T241_rate.mean&quot;) 5.3 数据转化 下面我们希望能够先计算每个人在听到泰语五个声调时的选择模式和反应时。然后基于此计算出汉语普通话组的选择模式和反应时。 assim.individual = assim.clean %&gt;% #为每个反应计数 mutate(n = 1)%&gt;% # 计算每个人每个泰语声调及对应汉语声调反应的次数、评分和反应时均值 group_by(subject, stimuli, response)%&gt;% summarise(cat = sum(n), response_rt = mean(response_rt, na.rm = TRUE), rating = mean(rating, na.rm = TRUE))%&gt;% # 计算每个人每个泰语声调及对应汉语声调反应的比例 group_by(subject, stimuli)%&gt;% mutate(percent = cat/sum(cat))%&gt;% ungroup() ## `summarise()` has grouped output by &#39;subject&#39;, &#39;stimuli&#39;. You can override ## using the `.groups` argument. assim.group = assim.individual%&gt;% # mutate(stimuli = as_factor(stimuli), # response = as_factor(response), # stimuli = fct_relevel(stimuli, &quot;T45&quot;,&quot;T33&quot;,&quot;T21&quot;,&quot;T315&quot;,&quot;T241&quot;), # response = fct_relevel(response, # &quot;M55&quot;,&quot;M35&quot;,&quot;M214&quot;,&quot;M51&quot;))%&gt;% group_by(stimuli,response)%&gt;% # 计算每组反应平均值和评分均值 summarise(cat.mean = round(sum(percent)/13, 3)*100, rate.mean = round(mean(rating,na.rm = TRUE),1))%&gt;% gather(temp, score, ends_with(&quot;.mean&quot;)) %&gt;% # 将刺激和对应的反应均值和评分均值组合 unite(temp1, stimuli, temp, sep = &quot;_&quot;)%&gt;% # 将表格进行转换，得到最终需要的感知同化模式图 spread(temp1, score)%&gt;% #change the order of columns select(&quot;response&quot; , &quot;T45_cat.mean&quot;, &quot;T45_rate.mean&quot;, &quot;T33_cat.mean&quot; , &quot;T33_rate.mean&quot;, &quot;T21_cat.mean&quot;,&quot;T21_rate.mean&quot;, &quot;T315_cat.mean&quot;, &quot;T315_rate.mean&quot;, &quot;T241_cat.mean&quot;, &quot;T241_rate.mean&quot;) ## `summarise()` has grouped output by &#39;stimuli&#39;. You can override using the ## `.groups` argument. 5.4 可视化 上述表格包含两个分类变量（泰语刺激的声调类型以及汉语反应的声调类型）和两个连续变量（选择的百分比以及评分）。两个分类变量是自变量，两个连续变量是因变量，我们可以根据因变量不同分别作图。首先，我们可以为感知同化模式画一个堆叠柱状图。普通柱状图的横纵表表示一个分类变量，为了让柱状图可以表示两个分类变量，我们需要在每个柱子中加入不同的颜色来区分。 assim.individual %&gt;% group_by(stimuli,response)%&gt;% summarise(percent = round(sum(percent)/13, 3)*100)%&gt;% filter(percent&gt;1)%&gt;% ggplot(aes(fill=response, y=percent, x=stimuli)) + geom_bar( stat=&quot;identity&quot;)+ scale_fill_manual( values=c(&quot;M55&quot; = &quot;black&quot;, &quot;M35&quot;=&quot;gray50&quot;, &quot;M214&quot;=&quot;gray75&quot;, &quot;M51&quot;=&quot;white&quot;), name=&quot;Mandarin&quot;, breaks=c(&quot;M55&quot;, &quot;M35&quot;, &quot;M214&quot;,&quot;M51&quot;), labels=c(&quot;M55&quot;, &quot;M35&quot;, &quot;M214&quot;,&quot;M51&quot;))+ geom_bar(colour=&quot;black&quot;, stat=&quot;identity&quot;)+ xlab(&quot;Thai tones (stimuli)&quot;)+ ylab(&quot;Percentage of choice (%)&quot;) + scale_y_continuous(expand = c(0, 0), limits = c(0, 101))+ labs(title = &quot;Perceputal assimialtion of Thai tones by Mandarin listeners&quot;)+ theme_classic()+ theme(legend.title = element_text(size=12, face=&quot;bold&quot;))+ theme(legend.text = element_text(size = 12, face = &quot;bold&quot;))+ theme(axis.text.x = element_text(face=&quot;bold&quot;, size=10)) ## `summarise()` has grouped output by &#39;stimuli&#39;. You can override using the ## `.groups` argument. 两个分类变量的另一种可视化方法是热力图。我们可以用泰语的刺激作为横轴，普通话声调类别作为纵轴，用色块的深浅表示评分的高低。 assim.individual %&gt;% group_by(stimuli,response)%&gt;% summarise(percent = round(sum(percent)/13, 3)*100, # 计算评分的均值 rate.mean = round(mean(rating,na.rm = TRUE),1))%&gt;% mutate(text.color = (stimuli== response))%&gt;% # 构建xy轴 ggplot(aes(stimuli,response))+ # 构建热力图 geom_tile(aes(fill = rate.mean))+ # 将评分作为标记填入，并设置相应的颜色、大小 geom_text(aes(label = round(rate.mean, 1)), color = &quot;red&quot;, size = 4) + scale_colour_manual(values=c(&quot;black&quot;, &quot;white&quot;))+ scale_x_discrete(name = &quot;Thai stimuli (%)&quot;)+ scale_y_discrete(name = &quot;Mandarin responses (%)&quot;)+ scale_fill_gradient(name=&quot;%&quot;,low = &quot;white&quot;, high = &quot;black&quot;) + theme(axis.text.x = element_text(face=&quot;bold&quot;, size=8), axis.title.x = element_text(face=&quot;bold&quot;, size=10), axis.title.y = element_text(face=&quot;bold&quot;, size=10), #axis.title.y = element_blank(), axis.text.y = element_text(face=&quot;bold&quot;, size=8), #axis.text.y = element_blank(), axis.ticks.y = element_blank(), axis.ticks.x = element_blank()) ## `summarise()` has grouped output by &#39;stimuli&#39;. You can override using the ## `.groups` argument. "],["第六章-文本数据分析.html", "Chapter 6 第六章 文本数据分析 6.1 数据导入 6.2 数据整理 6.3 词汇特征 6.4 文本风格分析", " Chapter 6 第六章 文本数据分析 文本数据属于非结构化数据，通常需要通过分词、词性赋码等自然语言处理方法，将文本数据进行结构化。 在语言学研究中，语料库研究与文本最为相关。Tognini-Bonelli（2001）提出基于语料库（corpus-based）和语料库驱动（corpus-driven）的区分。基于语料库的研究将语料库用作验证研究者直觉或检查小型数据集中语言的频率和/或合理性的例子来源。研究者不会质疑预先存在的传统描述单元和类别。语料库驱动的分析则是一种更具归纳性的过程：语料库本身就是数据，分析过程中通过记录语料库中的模式来表达语言中的规律性（和例外情况）。语料库驱动的分析倾向于只使用关于语法结构的最低限度的理论预设。 在词汇层面的语料库研究中，我们一般会进行词频统计（Word Frequency Count），即统计词汇在语料库中的出现频率，以了解词汇的使用频率和分布情况，构建词表。其次，与参考语料库比较，我们可以进行关键词提取（Keyword Extraction）即识别出在特定语境或文本类型中特别频繁出现的词汇。 再者，如果对于某些特定词汇感兴趣，我们可以通过共现分析（concordance Analysis）研究哪些词汇经常一起出现，以了解词汇之间的关系和语境。 最后，通过collocation anlysis我们可以分析词组搭配。 除了对文本中的词汇进行分析，也可以通过词汇来分析文本的风格。词汇丰富度和可读性分析可以帮我们比较不同文本之间词汇复杂性的差异。在分析不同翻译文本的特征是我们常常用到。此外，通过文本中最高频的几百个词的频率特征我们可以解锁不同作家的创作指纹。这样的分析可以帮我们鉴定一些归属存疑的文本作品。 在R语言中常用的文本处理的程序包有tidytext和quenteda。他们各有不同的功能，同时彼此之间可以相互转化。 6.1 数据导入 library(tidyverse) setwd(&quot;~/Nutstore Files/310_Tutorial/LanguageDS-e&quot;) library(quanteda) #install.packages(&quot;readtext&quot;) require(readtext) detectives.raw &lt;- readtext(&quot;data/ch6/detectives/*txt&quot;) corps.detectives = corpus(detectives.raw) summary(corpus(corps.detectives), 5) ## Corpus consisting of 2 documents, showing 2 documents: ## ## Text Types Tokens Sentences ## A_Study_in_Scarlet.txt 6313 51368 2736 ## Judge_dee.txt 6010 79276 3686 docvars(corps.detectives, &quot;book&quot;) &lt;- names(corps.detectives) 6.2 数据整理 # make a dfm dfm_detectives &lt;- corps.detectives %&gt;% tokens(remove_punct = TRUE) %&gt;% tokens_remove(stopwords(&quot;en&quot;)) %&gt;% dfm()%&gt;% dfm_group(groups = book) print(dfm_detectives) ## Document-feature matrix of: 2 documents, 8,565 features (35.77% sparse) and 1 docvar. ## features ## docs study scarlet part _being reprint reminiscences of_ ## A_Study_in_Scarlet.txt 11 4 14 1 1 2 1 ## Judge_dee.txt 3 3 26 0 0 0 0 ## features ## docs john h watson ## A_Study_in_Scarlet.txt 36 2 7 ## Judge_dee.txt 0 0 0 ## [ reached max_nfeat ... 8,555 more features ] topfeatures(dfm_detectives, 20) ## judge said dee one now man old two upon shall mrs time ## 701 553 542 326 315 300 225 222 217 207 204 197 ## young room case back ma come see joong ## 179 177 167 166 160 158 156 154 6.3 词汇特征 6.3.1 词频提取与词表构建 词频是语料库语言学最基本的概念。频率可以以原始数据的形式给出，例如在某个文本中，某个词出现了58次；或者可以以百分比或比例的形式给出，某个词在每百万词中出现602.91次。这使得可以在不同大小的语料库之间进行比较。 通过对语料库中每个词进行词频统计编制的词表可以用来生成关键词列表。 library(&quot;quanteda.textstats&quot;) library(&quot;quanteda.textplots&quot;) dfm_detectives.freq &lt;- textstat_frequency(dfm_detectives, n = 20, groups = book) ggplot(dfm_detectives.freq, aes(x = frequency, y = reorder(feature, frequency))) + geom_point() + labs(x = &quot;Frequency&quot;, y = &quot;Feature&quot;)+ facet_wrap(~ group, scales = &quot;free&quot;) 6.3.2 关键词提取 在语料库语言学中，关键词分析（keyword analysis）是一种通过与参考语料库进行比较，识别出在特定语料库中出现频率异常高（正关键词）或异常低（负关键词）的词语的方法。 关键词（Keyword）是指在一个文本或语料库中，与参考语料库相比，出现频率显著高于或低于预期的词语。通常，使用统计测试（如对数似然检验或卡方检验）来比较两个词表，以得出关键词。 参考语料库（Reference corpus）是一个平衡且代表性的语料库，通常用于关键词分析中提供参考词表。在关键词分析中，通过与参考语料库的比较，可以发现哪些词在特定语料库中是关键的。 在关键词分析中，一个词可能仅仅因为在某些文本中频率极高，而被误认为是关键词。为了确认一个词是否真的具有代表性，可以使用分布图查看这个词在整个语料库中的分布，或者计算在多个文本中均为关键词的词汇列表，以避免因不均匀分布导致的偏差。 # Calculate keyness and determine Trump as target group tstat_keyness &lt;- textstat_keyness(dfm_detectives , target = &quot;Judge_dee.txt&quot;) # Plot estimated word keyness textplot_keyness(tstat_keyness) 6.3.3 上下文中的关键词索引（KWIC） 索引（Concordance）是指在语料库中按照字母顺序排列的搜索模式索引，显示该搜索模式在每个上下文中的出现。上下文中的关键词索引（Key-Word-In-Context Concordance，简称KWIC）是一种显示关键词在语料库中实际使用情况的工具或方法。具体来说，KWIC 索引会将目标关键词放在中心位置，并显示该词在文本中的所有出现位置，同时显示它前后的一定数量的单词或词组。这种排列方式可以帮助研究者观察关键词在不同上下文中的用法和意义。 例如，如果你想研究英语中“education”一词的用法，KWIC 索引会将所有包含“education”的句子或句段列出，展示该词左右的上下文。这样，研究者就可以一目了然地看到“education”在不同语境下的使用方式，并分析其频率、搭配、语法特征以及语义变化。 KWIC 索引在语料库语言学中被广泛应用，因为它能够帮助研究者深入理解词语在实际语言使用中的行为，而不仅仅是关注词频等表面数据。 toks_corpus_detectives &lt;- corps.detectives%&gt;% tokens(remove_punct = TRUE)%&gt;% tokens_remove(stopwords(&quot;en&quot;)) kwic(toks_corpus_detectives , pattern = &quot;murder&quot;) %&gt;% head()%&gt;% as.data.frame() ## docname from to pre ## 1 A_Study_in_Scarlet.txt 3864 3864 second individual 8 presumably murderer ## 2 A_Study_in_Scarlet.txt 4560 4560 case continued turning two detectives ## 3 A_Study_in_Scarlet.txt 5492 5492 across table constable get arresting ## 4 A_Study_in_Scarlet.txt 5747 5747 little art jargon scarlet thread ## 5 A_Study_in_Scarlet.txt 6186 6186 reason eyes finding ring connected ## 6 A_Study_in_Scarlet.txt 8837 8837 must stayed room little time ## keyword post pattern ## 1 murder committed reminds circumstances attendant death murder ## 2 murder done murderer man six feet murder ## 3 murder said one hounds wolf Mr murder ## 4 murder running colourless skein life duty murder ## 5 murder come come shall see within murder ## 6 murder found blood-stained water basin washed murder # 对于词组 kwic(toks_corpus_detectives, pattern = phrase(&quot;commit crime&quot;)) %&gt;% head()%&gt;% as.data.frame() ## docname from to pre keyword ## 1 Judge_dee.txt 2617 2618 bamboo still faced original problem commit crime ## post pattern ## 1 thus ruminated Sergeant Hoong set commit crime kwic(toks_corpus_detectives , pattern = &quot;murder&quot;) %&gt;% textplot_xray() textplot_xray( kwic(toks_corpus_detectives, pattern = &quot;murder&quot;), kwic(toks_corpus_detectives, pattern = &quot;judge&quot;), kwic(toks_corpus_detectives, pattern = &quot;police&quot;), scale = &quot;absolute&quot;) ## Warning: Use of `x$ntokens` is discouraged. ## ℹ Use `ntokens` instead. 6.3.4 搭配分析 搭配分析（collocation analysis）是语料库语言学中的一种方法，用于研究词汇之间的共现关系，即在自然语言中某些词语经常一起出现的现象。搭配分析通过识别和分析这些词语的共现频率和模式，可以揭示出词语之间的语义或语法关系。 搭配（Collocation）：搭配是指两个或多个词在特定的上下文中经常一起出现。例如，在英语中，“strong”常常与“tea”搭配，而“powerful”则很少与“tea”搭配。类似地，“make a decision”和“take a photo”也是常见的搭配。 搭配强度（Collocational Strength）：搭配强度是衡量词语之间共现关系的紧密程度。它通常通过统计方法计算，比如互信息（Mutual Information，MI）或t检验（t-score）等。高搭配强度表明这些词语经常一起出现，并且比随机出现的可能性大得多。 搭配范围（Collocational Range）：搭配范围指的是词语在多大范围内（比如在前后几个词内）出现的频率。例如，“make”在前面紧跟着“decision”或“mistake”时，是一个常见的搭配，这个范围通常称为“window size”。 搭配分析的应用： 1. 语言学习： 搭配分析有助于语言学习者理解哪些词语经常一起使用，从而提高语言的自然性和流利度。例如，学习者可以通过搭配分析了解“do homework”比“make homework”更自然。 词典编纂： 词典编纂者使用搭配分析来确定哪些词语组合应该被列为固定搭配，从而为使用者提供更准确的词语用法信息。 语义分析： 通过分析一个词的搭配，可以推测其语义。例如，“dark”通常与“night”搭配，而“dark”与“mood”搭配时，可以暗示“mood”是消极的。 搭配分析是通过统计方法研究词语之间的共现关系，揭示语言使用中的规律性和隐含语义。它在语言研究、教育和自然语言处理等领域具有广泛的应用。 toks_corpus_detectives%&gt;% #提取包含大写字母的专有名词 tokens_select(pattern = &quot;^[A-Z]&quot;, valuetype = &quot;regex&quot;, case_insensitive = FALSE, padding = TRUE) %&gt;% textstat_collocations(min_count = 5, size = 3, tolower = FALSE) ## collocation count count_nested length lambda ## 1 Mrs Bee Mrs 9 0 3 2.2919763 ## 2 Mr Joseph Stangerson 5 0 3 0.1381491 ## 3 Six Mile Village 31 0 3 -1.9053123 ## 4 Mr Sherlock Holmes 7 0 3 -3.2857683 ## 5 Old Mr Hua 6 0 3 -2.9543269 ## 6 Joong Chiao Tai 26 0 3 -6.0239003 ## 7 Salt Lake City 8 0 3 -7.4583249 ## 8 Halliday&#39;s Private Hotel 5 0 3 -9.1930925 ## 9 Ma Joong Chiao 26 0 3 -6.6460942 ## 10 Chiao Tai Ma 5 0 3 -8.0017108 ## 11 Tai Ma Joong 5 0 3 -7.7720469 ## 12 Dragon Boat Festival 5 0 3 -10.8024934 ## 13 Warden Ho Kai 29 0 3 -8.5385706 ## 14 Bee Mrs Djou 7 0 3 -4.8207475 ## 15 Excellency Judge Dee 5 0 3 -6.6373310 ## z ## 1 1.36609804 ## 2 0.06382149 ## 3 -0.64514763 ## 4 -1.32091898 ## 5 -1.39733298 ## 6 -2.11855345 ## 7 -2.49079675 ## 8 -2.63393615 ## 9 -2.66082620 ## 10 -2.79263343 ## 11 -3.08084494 ## 12 -3.32080583 ## 13 -3.38490330 ## 14 -3.77602086 ## 15 -4.10986859 collocation.3wd &lt;- textstat_collocations(corps.detectives, size = 3, tolower = FALSE) 6.4 文本风格分析 6.4.1 词汇多样性 词汇丰富度（Lexical Richness）是指在语言学和语言习得研究中，用来衡量一个人使用语言时，所表现出的词汇多样性和复杂程度的指标。它反映了一个人语言表达的广度和深度，具体而言，就是在一个语言片段中，使用多少不同的词汇以及这些词汇的复杂性。 词汇丰富度通常通过以下几个方面来衡量： 类型-标记比率（Type-Token Ratio, TTR）：这是最常见的词汇丰富度衡量指标。类型指的是不同的词汇种类，而标记指的是词汇的总数。类型-标记比率就是不同词汇种类数与总词汇数的比值。TTR 比值越高，表示词汇丰富度越高，但它会受到文本长度的影响。 词汇密度（Lexical Density）：衡量一个文本中实词（如名词、动词、形容词、副词）所占的比例。高词汇密度意味着文本中使用了较多的实词，相对内容较为丰富。 平均词长（Mean Word Length）：平均词长可以作为词汇复杂性的一种衡量方式，通常较长的词汇意味着较高的词汇丰富度。 稀有词汇比例（Proportion of Rare Words）：这个指标衡量的是在文本中使用的稀有或不常见词汇的比例。稀有词汇使用越多，词汇丰富度通常越高。 D值（D-measure）：这是一个更复杂的指标，试图通过建模解决 TTR 中的文本长度影响问题，提供一个更稳定的词汇丰富度衡量方式。 词汇丰富度的分析在二语习得、语言能力评估、心理语言学等领域中具有重要意义。通过衡量一个人词汇丰富度，可以判断其语言能力、表达能力、认知水平，甚至可以用来诊断语言障碍或认知功能衰退。 lexical.diversity &lt;- textstat_lexdiv(dfm_detectives, measure = &quot;all&quot;) lexical.diversity.df = lexical.diversity%&gt;% as.data.frame()%&gt;% # mutate(id = 1:n())%&gt;% # filter(id &gt;1 )%&gt;% select(&quot;document&quot;,&quot;TTR&quot;,&quot;C&quot;,&quot;R&quot;,&quot;K&quot;,&quot;D&quot;,&quot;Vm&quot;)%&gt;% gather(&quot;measures&quot;, &quot;values&quot;, -c(&quot;document&quot;))%&gt;% mutate(measures = as.factor(measures), measures = fct_relevel(measures, &quot;TTR&quot;,&quot;C&quot;,&quot;R&quot;,&quot;K&quot;,&quot;D&quot;,&quot;Vm&quot;)) lexical.diversity.df ## document measures values ## 1 A_Study_in_Scarlet.txt TTR 0.288416556 ## 2 Judge_dee.txt TTR 0.153516445 ## 3 A_Study_in_Scarlet.txt C 0.874239515 ## 4 Judge_dee.txt C 0.820550958 ## 5 A_Study_in_Scarlet.txt R 40.446244676 ## 6 Judge_dee.txt R 28.429985636 ## 7 A_Study_in_Scarlet.txt K 10.631269445 ## 8 Judge_dee.txt K 18.348438591 ## 9 A_Study_in_Scarlet.txt D 0.001063181 ## 10 Judge_dee.txt D 0.001834897 ## 11 A_Study_in_Scarlet.txt Vm 0.030621422 ## 12 Judge_dee.txt Vm 0.040915379 ## 移动窗口词汇丰富度 lexical.mattr &lt;- textstat_lexdiv(tokens(corps.detectives), measure = &quot;MATTR&quot;, MATTR_window = 500) lexical.mattr ## document MATTR ## 1 A_Study_in_Scarlet.txt 0.5203928 ## 2 Judge_dee.txt 0.4970508 6.4.2 文本可读性 readability &lt;- textstat_readability(corps.detectives, measure = &quot;all&quot;) readability.df = readability %&gt;% select(&quot;document&quot;,&quot;ARI&quot;,&quot;Flesch&quot;,&quot;FOG&quot;, &quot;Coleman.Liau.short&quot;,&quot;Dale.Chall&quot;,&quot;Spache&quot;)%&gt;% gather(&quot;measures&quot;, &quot;values&quot;, -c(&quot;document&quot;))%&gt;% mutate(measures = as.factor(measures), measures = fct_relevel(measures, &quot;ARI&quot;,&quot;Flesch&quot;,&quot;FOG&quot;, &quot;Coleman.Liau.short&quot;,&quot;Dale.Chall&quot;,&quot;Spache&quot;)) 6.4.3 文本信息熵 文本信息熵（Textual Information Entropy）是信息理论中的一个概念，用来衡量文本中信息的复杂性和不确定性。它是由克劳德·香农（Claude Shannon）在1948年提出的，并广泛应用于语言学、计算机科学和信息论等领域。 信息熵的基本概念： 不确定性（Uncertainty）：信息熵反映了一个系统的不确定性程度。如果某个事件的发生是完全确定的，那么其信息熵为零；相反，如果事件的发生非常不确定，其信息熵则较高。 概率分布（Probability Distribution）：信息熵的计算基于事件出现的概率分布。在文本处理中，这通常意味着计算某个字母、单词或符号在整个文本中出现的概率。 香农熵（Shannon Entropy）：这是信息熵最常用的形式，表示为： \\[ H(X) = -\\sum_{i=1}^{n} P(x_i) \\log_2 P(x_i) \\] 其中，\\(H(X)\\) 是信息熵，\\(P(x_i)\\) 是事件 \\(x_i\\) 发生的概率，\\(n\\) 是可能的事件总数。对于文本信息熵，事件通常是字符、单词或其他文本元素的出现。 文本信息熵在语言学中的应用： 通过计算文本的熵，可以分析文本的语言复杂性。熵值越高，意味着文本的信息量大、复杂性高；熵值越低，意味着文本更为简单、信息量较少。 textstat_entropy(dfm_detectives) ## document entropy ## 1 A_Study_in_Scarlet.txt 11.24657 ## 2 Judge_dee.txt 10.71768 6.4.4 文本情感分析 library(dplyr) library(stringr) library(tidytext) tidy_books &lt;- detectives.raw %&gt;% unnest_sentences(sentence, text)%&gt;% group_by(doc_id) %&gt;% mutate(linenumber = row_number()) %&gt;% ungroup() %&gt;% unnest_tokens(word, sentence) tidy.sent = tidy_books %&gt;% inner_join(get_sentiments(&quot;bing&quot;)) %&gt;% count(doc_id, index = linenumber %/% 80, sentiment) %&gt;% pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %&gt;% mutate(sentiment = positive - negative) ## Joining with `by = join_by(word)` library(ggplot2) ggplot(tidy.sent , aes(index, sentiment, fill = doc_id)) + geom_col(show.legend = FALSE) + facet_wrap(~doc_id, ncol = 2, scales = &quot;free_x&quot;) # 进一步看看哪些积极或者消极的词 bing_word_counts &lt;- tidy_books %&gt;% inner_join(get_sentiments(&quot;bing&quot;)) %&gt;% group_by(doc_id) %&gt;% count(word, sentiment, sort = TRUE) %&gt;% ungroup() ## Joining with `by = join_by(word)` bing_word_counts %&gt;% group_by(sentiment) %&gt;% slice_max(n, n = 10) %&gt;% ungroup() %&gt;% mutate(word = reorder(word, n)) %&gt;% ggplot(aes(n, word, fill = sentiment)) + geom_col(show.legend = FALSE) + facet_wrap(doc_id~sentiment, scales = &quot;free_y&quot;) + labs(x = &quot;Contribution to sentiment&quot;, y = NULL) "],["第七章-语音数据分析.html", "Chapter 7 第七章 语音数据分析 7.1 语音库创建 7.2 时长提取 7.3 共振峰提取 7.4 基频分析", " Chapter 7 第七章 语音数据分析 语音数据在我们的生活中无处不在，从微信语音消息到智能音箱，不断提高着我们的生活质量。语音是声音的一种，是由人类的发音器官发出的声音。从声学上，语音是一种声波。对于声波我们可以分析它的时长和频率。常见的语音分析软件有Praat，可以提供各种各样的语音声学指标的提取。用Praat提取的结构化语音数据，经过数据整理，数据转化，可以像语言实验数据一样进行分析。 本章我们从数据科学的角度，介绍R语言中的一个语音库构建程序包EMU-R。 EMU语音库管理系统（the EMU Speech Database Management System，简称 EMU-SDMS）是集语音库建立、控制、检索、分析和管理为一体的多种软件工具的集合体。该系统最早由澳大利亚麦考瑞大学的语音学家Harrington开发的mu+系统(Harrington et al., 1993)，后来发展为EMU软件(Cassidy &amp; Harrington, 2001)。为了适应大数据时代的发展，兼容不同平台，Winkelmann等人将EMU软件的整体构想和功能保留，使用R语言及相关工具包作为依托，优化升级创建了新系统，即EMU-SDMS。由于R语言本身是开源免费的开发环境，EMU-SDMS系统也是完全免费供研究人员使用。EMU-SDMS系统包含三个软件部分：emuR工具包负责语音库构建和管理；wrassp工具包负责声学数据的处理；EMU-webApp负责语音数据的标注。 与目前的语音库管理系统相比，EMU-SDMS系统有三个优点。 第一，EMU-SDMS系统的数据结构既包含基于时间（time-based）语音信息，也包含层级性的语音信息。传统的语音标注系统和软件，如Praat必须也只能标注基于时间的语音信息。 第二，EMU-SDMS系统是第一个使用网页端作为语音标注界面的语音数据管理系统。网页端的标注界面可以单独使用，用户可以对自己加载的语音库进行标注。 第三，EMU-SDMS系统可以基于检索结果，在线提取语音库中的声学数据（如基频，共振峰）或发音生理数据（如电磁发音数据，electromagnetic articulography，简称 EMA）。传统的语音所有学数据处理流程是将所有数据提取和保存，再通过检索的方式获得。如果修改数据标注，或者修改检索条件，提取数据将会困难且容易出错。 7.1 语音库创建 语音库的构建离不开录音材料的准备、发音人的选取、录音等工作，本文重点在于如何基于语音数据构建语音库，因此对数据收集不做赘述。EMU-SDMS系统可以基于原始声音数据，直接创建语音库，然后用其EMU-webApp进行语音数据的标注，也可以基于已经标注的语音数据（声音文件和Textgrid文件）来创建语音库。如果是根据原始声音文件直接创建语音库，需要首先自定义语音库标注的层级，每一层的属性，以及层与层的关系。如果是根据已经标注的语音数据，程序包会默认将标注文件的层级设置为语音库的层级。 # load the package library(emuR) ## ## Attaching package: &#39;emuR&#39; ## The following object is masked from &#39;package:base&#39;: ## ## norm library(tidyverse) setwd(&quot;~/Nutstore Files/310_Tutorial/LanguageDS-e&quot;) # 设置语音库的位置 corpusPath = &quot;data/ch7/speech_corp&quot; # # # 设置已经标注的语音文件 .wav 和标注文件.TextGrid files的位置 # path2folder = &quot;/Users/chenjuqiang/Desktop/AmE_Consonants/&quot; # # # 基于语音文件和对应标注文件构建 emuDB 语音库 # # 注意：这一步只需要一次，语音库建设完成后不需要重复构建 # convert_TextGridCollection(dir = path2folder, # dbName = &quot;AmE_Consonants&quot;, # targetDir = corpusPath) # # # 将语音库文件位置设置为一个变量 AMECpath = paste(corpusPath, &quot;/AmE_Consonants_emuDB&quot;,sep = &quot;&quot;) # 将语音库载入R语言环境 # 注意这一步每次都需要先运行 AmeC.corp = load_emuDB(AMECpath, verbose = FALSE) # 了解一下语音库 summary(AmeC.corp) ## ## ── Summary of emuDB ───────────────────────────────────────────────────────── ## Name: AmE_Consonants ## UUID: 6280f273-9c1b-4fae-ae01-99413dda6fb8 ## Directory: /Users/chenjuqiang/Nutstore Files/310_Tutorial/LanguageDS-e/data/ch7/speech_corp/AmE_Consonants_emuDB ## Session count: 1 ## Bundle count: 24 ## Annotation item count: 338 ## Label count: 338 ## Link count: 0 ## ## ── Database configuration ─────────────────────────────────────────────────── ## ## ── SSFF track definitions ── ## ## data frame with 0 columns and 0 rows ## ── Level definitions ── ## name type nrOfAttrDefs attrDefNames ## token SEGMENT 1 token; ## word SEGMENT 1 word; ## segment SEGMENT 1 segment; ## closure SEGMENT 1 closure; ## burst SEGMENT 1 burst; ## aspiration SEGMENT 1 aspiration; ## ── Link definitions ── ## data frame with 0 columns and 0 rows 我们可以看到，构建的语音库由24个语音文件（Bundle count），在这些文件中共有338个标注信息。每个文件有6层，分别为token, word, segment, closure, burst, aspiration。需要注意的是，我们如果使用Praat对语音文件进行标注，最好再标注工作开始之前确定好标注层数和名称，并用脚本生成对于的标注文件，确保语音库中所有标注文件的层数和名称（包括大小写）是完全相同的。否则会出现无法构建语音库的情况。 7.1.1 检索相关语音信息 EMU-SDMS系统的最大优点是拥有强大的检索系统，可以完成固定语音元素查找（例如某个元音），基于正则表达式的模糊查找，以及不同层级多重条件限定的复杂查找。其中，不同层级多重条件限定的复杂查找，可以回答研究问题，比如元音的高低是否收到所在语音环境包括辅音，音节位置，甚至句中位置的影响。在传统的语音库数据处理中，这种检索实现很难，需要复杂的步骤，因为传统的语音库标注中每个层级之间是没有关联的。EMU-SDMS系统的灵活检索，使得语音库研究的数据探索更加高效。 EMU-SDMS系统的另一个优点是基于检索结果的声学分析。传统的语音库数据提取完成后会保存下来，占据很大的空间，特别是语音库标注修改过程中版本控制很难。EMU-SDMS系统可以基于检索结果直接通过wrassp程序包进行声学分析，可以快速的得到所研究的语音目标的声学特征，而不要对于整个语料库进行声学分析。这使得语音分析的流程更加高效。 EMU-SDMS系统可以无缝和R语言的其他数据处理，可视化，建模的程序包对接，不需要产生不必要的中间数据，减少版本或人工操作错误的可能性。 下面我们分别提取语音中的三个常见指标，时长、基频和共振峰。 # 通过检索函数检索语音库的内容 query(emuDBhandle = AmeC.corp, query = &quot;segment =~ .*&quot;)%&gt;% head() ## # A tibble: 6 × 16 ## labels start end db_uuid session bundle start_item_id end_item_id level ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 &quot;&quot; 0 74.9 6280f273… 0000 azure 7 7 segm… ## 2 &quot;\\\\ae&quot; 74.9 191. 6280f273… 0000 azure 8 8 segm… ## 3 &quot;\\\\zh&quot; 191. 305. 6280f273… 0000 azure 9 9 segm… ## 4 &quot;u&quot; 305. 498. 6280f273… 0000 azure 10 10 segm… ## 5 &quot;\\\\sw&quot; 498. 651. 6280f273… 0000 azure 11 11 segm… ## 6 &quot;&quot; 651. 735. 6280f273… 0000 azure 12 12 segm… ## # ℹ 7 more variables: attribute &lt;chr&gt;, start_item_seq_idx &lt;int&gt;, ## # end_item_seq_idx &lt;int&gt;, type &lt;chr&gt;, sample_start &lt;int&gt;, ## # sample_end &lt;int&gt;, sample_rate &lt;int&gt; 7.2 时长提取 # 检索语音库中的鼻音和爆破音 nasals = query(AmeC.corp, query = &quot;segment==n&quot;)%&gt;% mutate(type = &quot;nasals&quot;) plosives = query(AmeC.corp, &quot;segment==b|p|t|d|k|g&quot;)%&gt;% mutate(type = &quot;plosives&quot;) #计算各自的时长 duration.df = rbind(nasals,plosives)%&gt;% mutate(duration = end-start)%&gt;% select(labels, type, duration, bundle) duration.df ## # A tibble: 10 × 4 ## labels type duration bundle ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 n nasals 148. chin ## 2 n nasals 165. gin ## 3 n nasals 53.7 nigh ## 4 b plosives 18.5 buy ## 5 d plosives 17.1 die ## 6 g plosives 21.2 guy ## 7 k plosives 82.2 kite ## 8 t plosives 231. kite ## 9 p plosives 97 pie ## 10 t plosives 74.5 tie 7.3 共振峰提取 # 元音ai在Praat中的标注是“a\\\\ic”, vwl = query(AmeC.corp, query = &quot;segment== a\\\\ic&quot;) # 提取共振峰信息 # 所得表格中最后为共振峰信息，T1、T2、T3、T4 vwl.fm = get_trackdata(AmeC.corp, vwl, onTheFlyFunctionName = &quot;forest&quot;, resultType = &quot;emuRtrackdata&quot;) ## Warning in get_trackdata(AmeC.corp, vwl, onTheFlyFunctionName = &quot;forest&quot;, : The emusegs/emuRsegs object passed in refers to bundles with in-homogeneous sampling rates in their audio files! Here is a list of all refered to bundles incl. their sampling rate: ## session bundle media_file sample_rate md5_annot_json ## 1 0000 buy buy.wav 20000 59639695211954ddb3e36ff5978900e7 ## 2 0000 die die.wav 20000 893d54219221b71cef3fdb6f7b5e3d98 ## 3 0000 fie fie.wav 20000 bea76ca68ea7e633942ae47b297c6b8f ## 4 0000 guy guy.wav 20000 16488b8b385da79c6e4243fbb0bb0eb3 ## 5 0000 high high.wav 20000 ec2a22f18c2854e68b0851e79c7fcfb3 ## 6 0000 kite kite.wav 20000 e8c91461c11d0c80435ddf54e56afcbd ## 7 0000 lie lie.wav 20000 09954d57f5b94a7c0d5763f154712ad5 ## 8 0000 my my.wav 20000 1c5333b5c56ff005e37c1bd249b71819 ## 9 0000 nigh nigh.wav 20000 1a9efacfafe1718d9b51322a3d71af14 ## 10 0000 pie pie.wav 20000 b3d05e6277fe8892e7117fe25ef48460 ## 11 0000 rye rye.wav 20000 d8d76184b99f972d62290432c571e2ca ## 12 0000 shy shy.wav 20000 359535c49c56d59f8a99aed2b78dd288 ## 13 0000 sigh sigh.wav 20000 28b3d66baf0232553a744a8fcfffe498 ## 14 0000 thigh thigh.wav 20000 470573b53a3e657a7400f3769304665d ## 15 0000 thy thy.wav 20000 ab204ada14eaee2ad3ae12c0954fb849 ## 16 0000 tie tie.wav 20000 7f03f2dbafe1e8125eef39bbf4b92997 ## 17 0000 vie vie.wav 20000 eb769439797466b5903acb51fac43694 ## 18 0000 why why.wav 22050 357bff9530cf2f5145a46e3f059865f2 ## ## INFO: applying forest to 18 segments/events ## | | | 0% | |==== | 6% | |======= | 11% | |=========== | 17% | |=============== | 22% | |=================== | 28% | |====================== | 33% | |========================== | 39% | |============================== | 44% | |================================== | 50% | |===================================== | 56% | |========================================= | 61% | |============================================= | 67% | |================================================ | 72% | |==================================================== | 78% | |======================================================== | 83% | |============================================================ | 89% | |=============================================================== | 94% | |===================================================================| 100% # load package library(ggplot2) # 第一共振峰 ggplot(vwl.fm ) + aes(x = times_rel, y = T1, col = labels, group = sl_rowIdx) + geom_line() + labs(x = &quot;Duration (ms)&quot;, y = &quot;F1 (Hz)&quot;) # 将共振峰信息进行时长归一化 td_vowels_norm = normalize_length(vwl.fm) ggplot(td_vowels_norm) + aes(x = times_norm, y = T1, col = labels, group = labels) + geom_smooth() + labs(x = &quot;Duration (normalized)&quot;, y = &quot;F1 (Hz)&quot;) ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; # 下面我们提取共振峰中最稳定的部分，中间点 td_vowels_midpoint = td_vowels_norm %&gt;% filter(times_norm == 0.5) # 计算元音在一、二共振峰的中心点 td_centroids = td_vowels_midpoint %&gt;% group_by(labels) %&gt;% summarise(T1 = mean(T1), T2 = mean(T2)) # 画元音的位置图 ggplot(td_vowels_midpoint, aes(x = T2, y = T1, colour = labels, label = labels)) + geom_text(data = td_centroids) + stat_ellipse() + scale_y_reverse() + scale_x_reverse() + labs(x = &quot;F2 (Hz)&quot;, y = &quot;F1 (Hz)&quot;) + theme(legend.position=&quot;none&quot;) 7.4 基频分析 基频是语音中音高的声学基础。所有响音（如元音和鼻音）都有基频。我们说话的语调也是由基频的变化体现的。此外，一些语言如汉语使用基频区分不同词的意思，又称声调。 vwl.f0 = get_trackdata(AmeC.corp, vwl, onTheFlyFunctionName = &quot;ksvF0&quot;, resultType = &quot;emuRtrackdata&quot;) ## Warning in get_trackdata(AmeC.corp, vwl, onTheFlyFunctionName = &quot;ksvF0&quot;, : The emusegs/emuRsegs object passed in refers to bundles with in-homogeneous sampling rates in their audio files! Here is a list of all refered to bundles incl. their sampling rate: ## session bundle media_file sample_rate md5_annot_json ## 1 0000 buy buy.wav 20000 59639695211954ddb3e36ff5978900e7 ## 2 0000 die die.wav 20000 893d54219221b71cef3fdb6f7b5e3d98 ## 3 0000 fie fie.wav 20000 bea76ca68ea7e633942ae47b297c6b8f ## 4 0000 guy guy.wav 20000 16488b8b385da79c6e4243fbb0bb0eb3 ## 5 0000 high high.wav 20000 ec2a22f18c2854e68b0851e79c7fcfb3 ## 6 0000 kite kite.wav 20000 e8c91461c11d0c80435ddf54e56afcbd ## 7 0000 lie lie.wav 20000 09954d57f5b94a7c0d5763f154712ad5 ## 8 0000 my my.wav 20000 1c5333b5c56ff005e37c1bd249b71819 ## 9 0000 nigh nigh.wav 20000 1a9efacfafe1718d9b51322a3d71af14 ## 10 0000 pie pie.wav 20000 b3d05e6277fe8892e7117fe25ef48460 ## 11 0000 rye rye.wav 20000 d8d76184b99f972d62290432c571e2ca ## 12 0000 shy shy.wav 20000 359535c49c56d59f8a99aed2b78dd288 ## 13 0000 sigh sigh.wav 20000 28b3d66baf0232553a744a8fcfffe498 ## 14 0000 thigh thigh.wav 20000 470573b53a3e657a7400f3769304665d ## 15 0000 thy thy.wav 20000 ab204ada14eaee2ad3ae12c0954fb849 ## 16 0000 tie tie.wav 20000 7f03f2dbafe1e8125eef39bbf4b92997 ## 17 0000 vie vie.wav 20000 eb769439797466b5903acb51fac43694 ## 18 0000 why why.wav 22050 357bff9530cf2f5145a46e3f059865f2 ## ## INFO: applying ksvF0 to 18 segments/events ## | | | 0% | |==== | 6% | |======= | 11% | |=========== | 17% | |=============== | 22% | |=================== | 28% | |====================== | 33% | |========================== | 39% | |============================== | 44% | |================================== | 50% | |===================================== | 56% | |========================================= | 61% | |============================================= | 67% | |================================================ | 72% | |==================================================== | 78% | |======================================================== | 83% | |============================================================ | 89% | |=============================================================== | 94% | |===================================================================| 100% # 此时T1表示的是基频FO ggplot(vwl.f0 ) + aes(x = times_rel, y = T1, col = labels, group = sl_rowIdx) + geom_line() + labs(x = &quot;Duration (ms)&quot;, y = &quot;F0 (Hz)&quot;) # 将基频信息进行时长归一化 f0_norm = normalize_length(vwl.f0) ggplot(f0_norm) + aes(x = times_norm, y = T1, col = labels, group = labels) + geom_smooth() + labs(x = &quot;Duration (normalized)&quot;, y = &quot;F0 (Hz)&quot;) ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; "],["第八章-统计建模.html", "Chapter 8 第八章 统计建模 8.1 因变量和自变量均为分类变量 8.2 因变量为连续变量而自变量为分类变量 8.3 因变量为连续变量，自变量为分类变量 8.4 因变量与自变量均为连续变量", " Chapter 8 第八章 统计建模 在之前的章节中，我们介绍了数据的描述性统计和可视化方法。这些方法可以帮助我们对数据本身的基本趋势有所了解。然而在科学研究中，我们收集到的数据是我们研究问题中研究对象的样本。如何将我们在样本数据上观察到的结果推广到总体中去呢？这个时候我们需要借助推断性统计（inferential statistics）。 统计建模中，我们不仅需要明确变量是分类变量还是连续变量，还有明确变量之间的关系（因变量和自变量）。 因变量（Dependent Variable）是研究中被测量或观察的变量，它是研究者感兴趣的结果。因变量的变化被假设为由自变量的变化引起的。在实验或研究中，因变量通常是研究者希望解释或预测的现象。 自变量（Independent Variable） 自变量是研究中被操纵或分类的变量，它是研究者用来影响因变量的因素。自变量是研究中主动改变或控制的条件，用于测试其对因变量的影响。在一个研究咖啡因对学习成绩影响的实验中，咖啡因的摄入量就是自变量，学生的学习成绩就是因变量。 此外，在选择统计模型时我们还要考虑数据本身的特点是否满足一些模型的需要。参数统计检验（Parametric Statistical Tests）和非参数统计检验（Non-Parametric Statistical Tests）是统计分析中两类主要的方法，它们在假设前提和应用场景上有所不同。 参数统计检验，通常假设数据来自一个正态分布（即正态性假设），并且数据为连续型。这类检验依赖于数据参数（如均值和标准差），因此得名为参数统计检验。常见的参数检验：t检验（t-test，用于比较两个样本均值之间的差异）、方差分析（ANOVA，用于比较多个样本均值之间的差异）、线性回归（Linear Regression，用于分析两个或多个变量之间的线性关系）。 在假设满足的情况下，参数统计检验通常具有更高的统计效率（即更强的检验能力）。如果假设不满足，结果可能不可靠。 非参数统计检验不依赖于数据的特定分布假设，适用于数据不满足参数统计检验的假设前提的情况，特别是当数据为分类数据时。 常见的非参数检验：Mann-Whitney U检验（用于比较两组独立样本的秩次）、Wilcoxon符号秩检验（用于比较两组配对样本的秩次）、 斯皮尔曼相关系数（Spearman’s Rank Correlation，用于分析两个变量之间的秩次相关性）。 非参数统计检验能处理小样本和异常值。但是统计效率通常低于参数统计检验，可能需要更大的样本量来达到相同的统计检验能力。 图8.1 统计建模 library(tidyverse) setwd(&quot;~/Nutstore Files/310_Tutorial/LanguageDS-e&quot;) 8.1 因变量和自变量均为分类变量 如果统计建模的因变量和自变量均为分类变量，我们可以使用卡方检验（Chi-Square Test）。卡方检验是一种常用的非参数统计检验方法，通过比较观察频数和期望频数来判断变量之间是否存在显著关系。 卡方独立性检验用于检验两个分类变量之间是否存在关联，通常适用于二维列联表（contingency table）。它回答的问题是：一个变量的分类是否依赖于另一个变量的分类。 library(languageR) data(&quot;lexdec&quot;) tbl= table(lexdec$Correct, lexdec$PrevType) tbl ## ## nonword word ## correct 825 769 ## incorrect 30 35 # 卡方检验 chisq.test(tbl) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: tbl ## X-squared = 0.57663, df = 1, p-value = 0.4476 8.2 因变量为连续变量而自变量为分类变量 当因变量为分类变量而自变量为连续变量时，我们可以使用逻辑回归（Logistic Regression）。逻辑回归是一种广泛使用的统计模型，特别适用于处理分类问题，尤其是二分类问题。它通过建立自变量和因变量之间的关系来预测因变量的类别概率。逻辑回归通过一个逻辑函数（Logistic Function），也称为Sigmoid函数，将自变量的线性组合转换为一个概率值。它输出的结果是一个在0到1之间的概率值，用来表示某个事件发生的可能性。 #fit logistic regression model model &lt;- glm(Correct ~ Frequency+FamilySize, family=&quot;binomial&quot;, data=lexdec) #disable scientific notation for model summary options(scipen=999) #view model summary summary(model) ## ## Call: ## glm(formula = Correct ~ Frequency + FamilySize, family = &quot;binomial&quot;, ## data = lexdec) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.5767 -0.3081 -0.2394 -0.1848 3.0482 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.5871 0.5070 -1.158 0.247 ## Frequency -0.6266 0.1407 -4.453 0.00000845 *** ## FamilySize 0.2064 0.2541 0.812 0.417 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 548.57 on 1658 degrees of freedom ## Residual deviance: 518.48 on 1656 degrees of freedom ## AIC: 524.48 ## ## Number of Fisher Scoring iterations: 6 caret::varImp(model) ## Overall ## Frequency 4.4533767 ## FamilySize 0.8123094 8.3 因变量为连续变量，自变量为分类变量 如果自变量只有两层，可以使用t检验（T-tests）。t检验是一种常见的统计检验方法，用于比较两个样本均值之间的差异。单样本t检验（One-Sample T-test）用于比较一个样本的均值与一个已知的总体均值之间的差异。应用前提是，数据是从正态分布的总体中抽取的。样本是独立随机抽取的。比如，假设某学校声称其学生的平均IQ为100。我们抽取一个班级的学生进行IQ测试，想验证这个班级的平均IQ是否显著不同于100。 独立样本t检验（Independent Samples T-test），用于比较两个独立样本的均值是否显著不同。应用前提是两个样本来自正态分布的总体。两个样本是独立的，即每个样本中的观测值不依赖于另一个样本的观测值。 两个样本的方差相等（同方差性假设）。当不满足同方差性假设时，可以使用Welch’s t检验。 比如，我们想比较男性和女性的平均工资，抽取了一组男性和女性的工资数据，检验两者的平均工资是否有显著差异。 配对样本t检验（Paired Samples T-test）用于比较两个相关样本的均值是否显著不同。通常用于前后测量或配对设计。应用前提是配对差值（即每对观测值的差值）来自正态分布。样本是成对的，每对数据之间有某种相关性。比如，我们想比较一组学生在参加培训前后的考试成绩，检查培训是否对考试成绩有显著影响。 # 检测数据是否符合正态分布，P&lt;0.05 不符合正态分布 shapiro.test(lexdec$RT) ## ## Shapiro-Wilk normality test ## ## data: lexdec$RT ## W = 0.94738, p-value &lt; 0.00000000000000022 plot(density(lexdec$RT)) # 参与者母语是否是英语 t.test(RT ~ NativeLanguage, data=lexdec) ## ## Welch Two Sample t-test ## ## data: RT by NativeLanguage ## t = -13.184, df = 1267.7, p-value &lt; 0.00000000000000022 ## alternative hypothesis: true difference in means between group English and group Other is not equal to 0 ## 95 percent confidence interval: ## -0.1790089 -0.1326335 ## sample estimates: ## mean in group English mean in group Other ## 6.318309 6.474130 # 汇报Mann–Whitney U test 更好 wilcox.test(RT ~ NativeLanguage, data=lexdec) ## ## Wilcoxon rank sum test with continuity correction ## ## data: RT by NativeLanguage ## W = 212168, p-value &lt; 0.00000000000000022 ## alternative hypothesis: true location shift is not equal to 0 当自变量有两个以上，或者自变量超过两个水平，我们可以使用方差分析（Analysis of Variance, ANOVA）。方差分析通过分析数据中的变异来源，确定不同组之间的均值是否有显著差异。ANOVA的主要优势在于它能够同时比较多个组的均值，而无需进行多次t检验，从而减少第一类错误的概率。 单因素方差分析（One-Way ANOVA）：用于比较一个因子（自变量）下的多个组（水平）的均值是否存在显著差异。 比如比较不同教学方法对学生成绩的影响。 双因素方差分析（Two-Way ANOVA）：用于比较两个因子（自变量）及其交互作用对因变量的影响。 适用场景：研究不同教学方法和不同学习时间对学生成绩的影响。 重复测量方差分析（Repeated Measures ANOVA）：用于处理同一组受试者在不同时间点或不同条件下的测量数据。比如，同一组学生在不同教学方法下的成绩变化等。 ANOVA 的基本原理是通过将总变异分解为组间变异和组内变异，来判断不同组的均值是否存在显著差异。 在发现整体组间均值存在显著差异后，进一步确定哪些具体组之间存在差异需要使用事后比较（Post-Hoc Comparisons）。因为ANOVA只告诉我们至少有一组均值不同，但不能明确指出哪些组之间存在差异。事后比较中，我们要控制多重比较带来的第一类错误（即假阳性）。常见的方法有Tukey’s HSD（Honestly Significant Difference）检验、Bonferroni检验等。 lex.aov = aov (RT ~ PrevType + Class, data = lexdec) summary(lex.aov) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## PrevType 1 1.71 1.7144 29.891 0.0000000527 *** ## Class 1 0.01 0.0119 0.208 0.648 ## Residuals 1656 94.98 0.0574 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 TukeyHSD(lex.aov) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = RT ~ PrevType + Class, data = lexdec) ## ## $PrevType ## diff lwr upr p adj ## word-nonword -0.06432275 -0.08739882 -0.04124667 0.0000001 ## ## $Class ## diff lwr upr p adj ## plant-animal -0.005397916 -0.02861424 0.01781841 0.6484245 8.4 因变量与自变量均为连续变量 当我们为两个或以上连续型变量建模时，我们可以使用相关分析和线性回归。 相关分析确定一个变量是否随着另一个变量的变化而系统地变化。它不指定哪个变量是因变量，哪个变量是自变量。比较合适观察数据集中哪些变量彼此相关。Pearson, Spearman 和 Kendall 是三种常见的相关性检验方法，主要用于衡量两个变量之间的相关程度。尽管它们都用于相关性分析，但它们有不同的假设和适用场景。 Pearson相关系数（Pearson Correlation Coefficient）是最常用的相关性测量方法，用于衡量两个变量之间的线性关系。假设前提：数据是连续的，符合正态分布，数据之间存在线性关系。数据是独立的。简单易计算，结果易于解释。在数据符合正态分布且有线性关系时，效果最好。对异常值敏感。不能有效处理非线性关系。 Spearman相关系数（Spearman Rank Correlation Coefficient）是基于数据排序的非参数检验方法，用于衡量两个变量之间的单调关系。假设前提有数据是连续的或离散的。数据不需要符合正态分布。数据之间存在单调关系。适用于衡量两个变量之间的单调关系，例如学生成绩排名和运动成绩排名的关系。对异常值不敏感。可以处理非线性关系。对于完全线性关系，效率不如Pearson相关系数。 cor.test( ~ RT + Frequency, data = lexdec, method = &quot;pearson&quot;) ## ## Pearson&#39;s product-moment correlation ## ## data: RT and Frequency ## t = -9.4587, df = 1657, p-value &lt; 0.00000000000000022 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.2715046 -0.1801720 ## sample estimates: ## cor ## -0.2263358 cor.test( ~ RT + Frequency, data = lexdec, method = &quot;kendall&quot;) ## ## Kendall&#39;s rank correlation tau ## ## data: RT and Frequency ## z = -9.5751, p-value &lt; 0.00000000000000022 ## alternative hypothesis: true tau is not equal to 0 ## sample estimates: ## tau ## -0.1581668 cor.test( ~ RT + Frequency, data = lexdec, method = &quot;spearman&quot;) ## Warning in cor.test.default(x = mf[[1L]], y = mf[[2L]], ...): Cannot compute ## exact p-value with ties ## ## Spearman&#39;s rank correlation rho ## ## data: RT and Frequency ## S = 937771196, p-value &lt; 0.00000000000000022 ## alternative hypothesis: true rho is not equal to 0 ## sample estimates: ## rho ## -0.2322793 线性回归指定一个变量为自变量，另一个为因变量。所得模型用线性关系来描述这些变量之间的关系。线性回归是参数检验，假设残差的正态性、同方差性和独立性，以及两个变量之间的线性关系。如果模型中有多个区间/比例类型的自变量，那么线性回归将扩展为多元回归。如果自变量是分类变量，那么线性回归将变成单因素方差分析。可以使用 lm 函数来执行线性回归，这与我们用于方差分析的函数相同。 lm.model = lm(RT ~ Frequency, data = lexdec) summary(lm.model) ## ## Call: ## lm(formula = RT ~ Frequency, data = lexdec) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.55407 -0.16153 -0.03494 0.11699 1.08768 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.588778 0.022296 295.515 &lt;0.0000000000000002 *** ## Frequency -0.042872 0.004533 -9.459 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2353 on 1657 degrees of freedom ## Multiple R-squared: 0.05123, Adjusted R-squared: 0.05066 ## F-statistic: 89.47 on 1 and 1657 DF, p-value: &lt; 0.00000000000000022 lm模型对象的summary函数包括对模型参数（截距和斜率）的估计，以及模型的R平方值和模型的p值。 如何解读模型？ 模型产生了截距的系数（6.5）和斜率的系数（-0.04）； 每个系数还伴随着其他三个数字：其标准误差、t值和p值。p值告诉我们系数是否显著不同于零。 如果预测变量的系数为零，则预测变量与因变量之间没有任何关系，因此作为预测变量是毫无价值的。为了确定系数是否显著不同于零，从而具有潜在的预测能力，进行双侧t检验，使用t值和相关的自由度。 t值本身是系数除以其标准误差得到的值。这个标准误差是系数估计的确定程度的衡量。标准误差越小，估计周围的置信区间就越小，接受区域中包含零的可能性就越小，因此系数可能为零的概率也越小。 残差标准误差是模型不成功的度量；它衡量了我们无法通过预测变量处理的因变量的变异性。模型越好，其残差标准误差就越小。 多重R平方为0.8115。这个R平方是平方相关系数r²，它在0到1的范围内量化了模型解释的方差的比例。 "],["第九章-机器学习建模基础.html", "Chapter 9 第九章 机器学习建模基础 9.1 监督学习 9.2 非监督学习", " Chapter 9 第九章 机器学习建模基础 详细背景请看原文献 机器学习（Machine Learning）是人工智能（Artificial Intelligence, AI）的一个重要分支，其主要目标是使计算机通过学习经验数据自动改进和发展。机器学习使计算机从数据中学习模式和规律，从而做出预测或决策，而无需显式地编程。机器学习主要分为2种主要类型，监督学习（Supervised Learning）和无监督学习（Unsupervised Learning）。 根据学习方式和目标任务的不同，它们各自解决不同类型的问题。监督学习是一种通过已标记的训练数据来训练模型，从而预测或估计新数据的输出。在监督学习中，训练数据包含了输入特征和相应的标签。模型学习从输入到标签之间的映射关系，以便对未知数据进行预测。监督学习的任务可以分为分类（Classification）任务即预测离散类别标签，如垃圾邮件检测、疾病诊断。典型算法包括支持向量机（SVM）、逻辑回归、决策树、随机森林等。回归（Regression）任务则是预测连续数值，如房价预测、销售预测。典型算法包括，线性回归、多项式回归、支持向量回归（SVR）等。 无监督学习使用未标记的数据，没有预先定义的输出，其目标是发现数据中的隐藏结构或模式。这种学习方法通常用于探索数据的内在关系，发现数据的聚类、降维或异常检测等特征。常见的无监督学习包括聚类分析（Clustering）和降维（Dimensionality Reduction）。聚类分析将数据集划分为不同的组（簇），使每个组内的数据点相似度最大化，而组间的相似度最小化。典型算法包括K均值聚类、层次聚类等。降维减少数据的特征维度，保留最重要的信息，以便更好地可视化和理解数据，同时降低计算复杂度。典型算法包括主成分分析（PCA）、因子分析、独立成分分析（ICA）等。 9.1 监督学习 下面将用一个二语语音研究的例子讲解如何使用支持向量机（SVM）和随机森林来对中国英语学习者的焦点语音实现进行自动评估。 传统的统计建模（如广义线性模型）在大多数先前研究中用于调查信息焦点的语音实现，这些研究检查整个数据集，并通过离散指标检测焦点类型的效果。通常，基于不同的声学测量构建几个模型，以测试不同焦点和语言组的效果，但很难得到全面的图景。而人类听众则逐一听取话语并据此作出判断。这个过程可以通过机器学习算法来模拟，这些算法输入一组特征并基于这些特征输出分类结果。 支持向量机（SVM）和随机森林模型被用于基于不同的声学测量集分类鼻音元音和口音元音。我们理解，计算感知与人类感知并不完全相同，但计算感知在语音研究中的优势在于它纯粹基于声学特征，因此可以剔除句法或词汇的影响。此外，与识别元音或辅音不同，仅仅给听众一些目标词并测试他们如何识别不同的焦点是困难的。机器学习算法可以在没有上下文的情况下识别不同的焦点，从而从感知的角度接近这个问题。 焦点是话语中提供信息的部分，与句子的背景信息形成对比。为了进一步解释焦点在话语中的作用，以下是具体例子： 广泛焦点（Broad Focus, BF） A: 你明天有什么计划？ B: 我想去纽约。 在这个例子中，B的整个回答都在提供新信息，因此整个句子是焦点。 狭窄焦点（Narrow Focus, NF） A: Karel想带你去哪里？ B: 他想带我去纽约。 在这个例子中，焦点是“纽约”，因为这是B回答A的问题“哪里”的特定信息。 纠正焦点（Corrective Focus, CF） A: 你妈妈想送你去芝加哥吗？ B: 不，她想送我去纽约。 在这个例子中，焦点也是“纽约”，但这次是为了纠正A的问题中的错误信息“芝加哥”。通过这些例子可以看出，焦点的范围和功能可以根据对话中的具体信息需求和信息状态有所不同。 不同语言的母语者使用不同语音手段（如音高重音分布、短语边界、音高范围和持续时间）来表达不同焦点条件下的意义。本研究采用两种机器学习模型，支持向量机（SVM）和随机森林（Random Forest），来探讨基于语音特征的不同类型信息焦点。我们还比较了美国英语母语者（AE）与低熟练度的中国英语学习者（CE1）和高熟练度的中国英语学习者（CE2）在分类准确性和不同语音特征排名方面的差异。此外，我们使用AE的语音数据训练了两个模型，并用CE1和CE2的数据进行测试，以模拟AE听者如何感知非母语者在不同信息焦点下的语音产出。 我们在本研究中使用了两种机器学习分类器，随机森林（RandomForests）和支持向量机（SVM）。随机森林是一种机器学习模型，由一组在数据的随机子集上训练和测试的决策树组成。在本研究中，我们在所有随机森林模型中使用了500棵树，如[9]所述。随机森林分类器检查每棵决策树的输出，并产生分类准确率。此外，随机森林分类器为每个模型提供了直接的特征重要性度量。本研究中使用了R语言中的randomForest包[10]来构建分类器。 然而，随机森林为了其可解释性在分类中牺牲了一些准确性。为了弥补这一点，我们使用了SVM，这在机器学习领域中整体表现良好。SVM通过找到最佳分离数据中不同类别的线来工作。当数据不是线性可分时，可以使用核函数来处理非线性关系。在本研究中，使用了“径向基函数”（radial）核。然而，使用核函数时我们无法得到特征权重。因此，我们主要依赖随机森林来指示每个语音特征的重要性。 此外，由于数据集相对较小（从机器学习的角度来看），我们使用了“10折交叉验证”，即对数据运行10次分析，每次使用不同的9/10数据作为“训练”集，剩余的1/10作为“测试”集。本研究中使用了R语言中的e1071包[11]来构建SVM分类器。 9.1.1 数据导入 library(tidyverse) setwd(&quot;~/Nutstore Files/310_Tutorial/LanguageDS-e&quot;) # install.packages(&#39;caTools&#39;) library(caTools) set.seed(123) # 美国英语本族语者数据 datasetAE &lt;- read_csv(&quot;data/ch9/datasetAE.CSV&quot;) # 中国英语学习者大一 datasetCE1 = read_csv(&quot;data/ch9/datasetCE1.CSV&quot;) # 中国英语学习者大三 datasetCE2 = read_csv(&quot;data/ch9/datasetCE2.CSV&quot;) datasetAE$focus_type = as.factor(datasetAE$focus_type) datasetCE1$focus_type = as.factor(datasetCE1$focus_type) datasetCE2$focus_type = as.factor(datasetCE2$focus_type) # install.packages(&#39;e1071&#39;) library(e1071) 9.1.2 构建SVM模型 svm_AE = svm(formula = focus_type ~ ., data = datasetAE, #regression or classification type = &#39;C-classification&#39;, kernel = &#39;radial&#39;, cost = &quot;2&quot;, cross = 10) # 交叉验证（Cross Validation）是一种用于评估和验证机器学习模型性能的方法，通过将数据集划分为多个子集，交替进行训练和测试，以确保模型在不同的数据集上都具有良好的泛化能力。最常见的方法是K折交叉验证（K-Fold Cross Validation），将数据集划分为K个大小大致相同的子集，每个子集轮流作为验证集，其余子集作为训练集，重复K次后将结果平均，作为模型的最终性能评估指标。交叉验证可以充分利用数据，提高模型评估的可靠性，防止过拟合问题，是机器学习和数据挖掘中广泛应用的技术。 summary(svm_AE) ## ## Call: ## svm(formula = focus_type ~ ., data = datasetAE, type = &quot;C-classification&quot;, ## kernel = &quot;radial&quot;, cost = &quot;2&quot;, cross = 10) ## ## ## Parameters: ## SVM-Type: C-classification ## SVM-Kernel: radial ## cost: 2 ## ## Number of Support Vectors: 174 ## ## ( 58 61 55 ) ## ## ## Number of Classes: 3 ## ## Levels: ## bro cor nar ## ## 10-fold cross-validation on training data: ## ## Total Accuracy: 42.24599 ## Single Accuracies: ## 50 42.10526 36.84211 33.33333 42.10526 31.57895 55.55556 52.63158 36.84211 42.10526 svm_AE$tot.accuracy ## [1] 42.24599 svm_AE$accuracies ## [1] 50.00000 42.10526 36.84211 33.33333 42.10526 31.57895 55.55556 52.63158 ## [9] 36.84211 42.10526 9.1.3 random forest library(randomForest) ## randomForest 4.7-1.1 ## Type rfNews() to see new features/changes/bug fixes. ## ## Attaching package: &#39;randomForest&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## combine ## The following object is masked from &#39;package:ggplot2&#39;: ## ## margin set.seed(123) #AE RF_AE = randomForest(focus_type ~ ., ntree = 500, data = datasetAE, importance = TRUE) importance(RF_AE) ## bro cor nar MeanDecreaseAccuracy ## Odur 0.5140828 2.1340207 -2.1872216 0.35538483 ## Vdur 0.0429139 1.1813533 2.4925858 2.07368177 ## Cdur 4.2245241 1.3416428 1.8691133 4.42392485 ## Rdur 3.1940865 -1.5403027 1.6942768 2.09952920 ## Sylldur -0.7632086 0.7226848 0.1116193 -0.07377943 ## Wdur 0.4031192 1.2760254 0.5353081 1.25499400 ## O1Hexc 3.2166992 1.3994444 -0.3550104 2.58880098 ## Fallexc -0.3784383 4.4299155 6.2340216 6.18100973 ## Nucleusfallexc 5.0580749 2.0103623 -2.1740778 2.88325662 ## H_N2exc 0.1552991 2.3525700 1.0984669 1.94682400 ## pd 0.4784784 0.8331123 -0.6137476 0.71097692 ## Pd_rime 3.8104797 -0.2959070 0.3361559 2.10364327 ## Falldur 1.1514921 0.2380824 8.1123263 6.18477738 ## Risedur 3.9233410 1.3787518 2.9428743 5.15879783 ## Hf0_Ef0 1.7389798 3.0422496 3.2327149 4.67262290 ## L1_Hexc 2.5726081 0.1309762 3.1346224 3.35089696 ## O1f0_Ef0 1.0765409 2.7237252 1.0950456 2.70134078 ## L1f0_Ef0 0.9964942 4.8822834 -1.4506798 2.70266139 ## L2f0_Ef0 0.6635268 1.0752717 -1.6661622 0.51157262 ## Risesp 0.1264366 -0.1587295 2.0082139 0.94940044 ## Fallsp -0.1783400 3.6014926 4.0233803 4.18582556 ## MeanDecreaseGini ## Odur 5.317048 ## Vdur 5.604926 ## Cdur 8.415981 ## Rdur 5.386566 ## Sylldur 5.040385 ## Wdur 6.202501 ## O1Hexc 5.439555 ## Fallexc 6.970555 ## Nucleusfallexc 7.725118 ## H_N2exc 5.702467 ## pd 4.687184 ## Pd_rime 5.994991 ## Falldur 9.538895 ## Risedur 6.624772 ## Hf0_Ef0 5.265986 ## L1_Hexc 5.677258 ## O1f0_Ef0 4.712215 ## L1f0_Ef0 5.059596 ## L2f0_Ef0 4.394975 ## Risesp 5.059293 ## Fallsp 5.154706 varImpPlot(RF_AE, n.var= 5, main =&quot;AE&quot;) # 在构建随机森林的过程中，每棵决策树都是通过对原始训练数据进行有放回抽样（Bootstrap Sampling）得到的子样本训练出来的。剩下样本则没有被该树用于训练，这些样本就是袋外样本。利用那些没有进行训练的数据来进行预测。 RF_AE$confusion ## bro cor nar class.error ## bro 26 22 15 0.5873016 ## cor 21 30 13 0.5312500 ## nar 14 17 29 0.5166667 为了模拟美国英语（AE）听众如何感知由中国英语（CE1和CE2）学习者发出的焦点目标词语，使用所有AE数据特征训练了一个支持向量机（SVM）模型，并分别使用两个中国英语学习者组的数据进行测试。 #Cross langauge preception #svm y_predCE1 = predict(svm_AE, newdata = datasetCE1[-1]) y_predCE2 = predict(svm_AE, newdata = datasetCE2[-1]) #output the data #install.packages(&quot;caret&quot;) library(caret) ## Loading required package: lattice ## ## Attaching package: &#39;caret&#39; ## The following object is masked from &#39;package:emuR&#39;: ## ## train ## The following object is masked from &#39;package:purrr&#39;: ## ## lift conf_ce1 = confusionMatrix(as.factor(datasetCE1$focus_type), y_predCE1) conf_ce2 = confusionMatrix(as.factor(datasetCE2$focus_type), y_predCE2) CE1.TEST = as.data.frame(conf_ce1$table)%&gt;% group_by(Reference)%&gt;% mutate(accuracy = Freq/sum(Freq), LANG = &quot;CE1&quot;) CE2.TEST = as.data.frame(conf_ce2$table)%&gt;% group_by(Reference)%&gt;% mutate(accuracy = Freq/sum(Freq), LANG = &quot;CE2&quot;) # 总体准确率在CE1和CE2两组中均高于随机水平，且两组之间的差异较小。在每个组内，BF类词汇相对容易分类，而NF和CF类词汇则较难分类，反映在较低的准确率上。 rbind(CE1.TEST, CE2.TEST)%&gt;% filter(Prediction == Reference) ## # A tibble: 6 × 5 ## # Groups: Reference [3] ## Prediction Reference Freq accuracy LANG ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 bro bro 54 0.535 CE1 ## 2 cor cor 30 0.417 CE1 ## 3 nar nar 27 0.403 CE1 ## 4 bro bro 42 0.494 CE2 ## 5 cor cor 31 0.360 CE2 ## 6 nar nar 33 0.478 CE2 根据机器学习算法，仅基于目标词的语音特征对不同信息焦点进行分类的总体准确率并不高。这从感知的角度支持了目标词本身没有稳健的语音线索来区分广义、狭义和对比焦点的观点。然而，与持续时间相关的特征在重要性指数中的高排名与之前的文献一致。然而，目标词焦点中缺乏稳健的语音特征并不意味着语音信息不能足以建模信息焦点。相反，目标词以外的语音信息可能有助于区分不同的焦点。在文献[3]中，所有焦点后的词的f0峰值均低于这些词在中性焦点句子中的f0峰值。包含焦点后词的语音信息可能会提高分类准确率。 使用AE数据训练的SVM模型对第二语言学习者的发音进行分类，生成的准确率与对AE发音进行分类的结果相当。这表明尽管AE和CE之间存在语音差异，但两个CE组的目标词至少在SVM模型区分这些词的能力上与AE相当。两个CE组之间的差异非常小，表明英语水平并未改变CE学习者的焦点实现模式。 9.2 非监督学习 下面我们基于词频特征计算两个文本的文体风格特征并通过不同的非监督学习的方法对两个不同的文本进行分类。 9.2.1 文本数据预处理 library(stylo) # 导入文本数据 style.corpus &lt;- load.corpus(files = &quot;all&quot;, corpus.dir = &quot;~/Nutstore Files/310_Tutorial/Language data science/data/ch6/detectives&quot;, encoding = &quot;UTF-8&quot;) # 对文本进行分词 tokenized.corpus &lt;- txt.to.words.ext(style.corpus, preserve.case = TRUE) # 根据研究目的我们可以设置一个词表去除一些干扰词。比如我们想排除文本中高频专有名词的干扰。 #proper.noun = c(&quot;DEE&quot;,&quot;Judge&quot;,&quot;Dee&quot;,&quot;&quot;) # clean.corpus = delete.stop.words(tokenized.corpus, # stop.words = proper.noun) # 一些研究认为代词对于计算文体风格有干扰，比如如果是一个大女主的小说，那么女性代词就会很多。但是这些不能代表作者风格，只能代表作品风格。 clean.corpus = delete.stop.words(tokenized.corpus, stop.words = stylo.pronouns(corpus.lang = &quot;English&quot;)) corpus.char.1 &lt;- txt.to.features(clean.corpus, ngram.size = 1, features = &quot;w&quot;) # 将数据划分成1000个词一份 sliced.corpus.char.1 &lt;- make.samples(corpus.char.1, sampling = &quot;normal.sampling&quot;, sample.size = 1000) # 提取词频特征 features1 &lt;- make.frequency.list(sliced.corpus.char.1) # 制作词频特征表 freqs1 &lt;- make.table.of.frequencies(sliced.corpus.char.1, features = features1) # Culling # 通过删选，用户可以指定特征在语料库中的出现比例，以决定其是否被纳入分析。在语料库中未达到指定比例的词语将被忽略。 culled.freqs1 &lt;- perform.culling(freqs1, culling.level = 80) 9.2.2 文本聚类分析 # 主成分分析 stylo(frequencies = culled.freqs1, analysis.type = &quot;PCR&quot;, custom.graph.title = &quot;Judge Dee and Sherlock&quot;, pca.visual.flavour = &quot;technical&quot;, write.png.file = TRUE, gui = FALSE) # 显示两本书在第一第二主成分空间的分布 stylo(frequencies = culled.freqs1, analysis.type = &quot;PCR&quot;, mfw.min = 100, mfw.max = 500, custom.graph.title = &quot;Judge Dee and Sherlock&quot;, write.png.file = FALSE, gui = FALSE) # 显示不同高频词的权重loadings stylo(frequencies = culled.freqs1, analysis.type = &quot;PCR&quot;, custom.graph.title = &quot;Judge Dee and Sherlock&quot;, pca.visual.flavour = &quot;loadings&quot;, write.png.file = FALSE, gui = FALSE) # cluster analysis stylo(frequencies = culled.freqs1, analysis.type = &quot;CA&quot;, write.png.file = FALSE, custom.graph.title = &quot;Judge Dee and Sherlock&quot;, gui = FALSE) "],["案例一行为实验数据分析.html", "Chapter 10 案例一、行为实验数据分析 10.1 研究背景 10.2 数据整理+描述性统计 10.3 数据可视化 10.4 统计建模 10.5 结论", " Chapter 10 案例一、行为实验数据分析 10.1 研究背景 在第五章中，我们分析了汉语普通话母语者是如何将泰语声调同化到母语声调中的。成年人对言语语音的感知受到母语语音系统的影响。本章中我们将结合相关理论，感知同化模型，预测不同外语音位对立的感知难度。并且通过声调区分感知实验来验证。感知同化模型预测了几种同化模式的感知区分难度。单类别同化（Single Category, SC）中，两个不同的目标音素被同化为一个母语音素类别。类别差异同化（Category Goodness, CG）两个目标音素被同化为同一个母语音素类别，但一个音素更接近于该类别的原型。两类别同化（Two Category, TC），两个目标音素被同化为两个不同的母语音素类别。其中TC的区分度要好于CG，CG要好于SC。 除了不同的同化类型之外，感知模式也会影响区分任务中的表现。如果任务的记忆负荷大、刺激材料由不同的说话人产出、语音环境比较复杂（例如对于声调实验来说，刺激不仅声调不同而且元音也不同），这时听者会使用音位感知模式。在这个模式中，听者会比较粗放地感知语音，一些语音细节被忽视。反之，听者会使用语音感知模式，比较精细地感知。 在实验中，我们让参与者判断两个声调是否相同，操纵了记忆负荷（两个声调呈现的时间间隔）、语音是否来自同一个人，以及声调所在的音节元音是否相同。 library(lme4) library(lsmeans) setwd(&quot;~/Nutstore Files/310_Tutorial/LanguageDS-e&quot;) library(tidyverse) # 显示小数点后很多位 options(scipen=999) # 计算置信区间 library(rcompanion) # 改变y轴度量 library(scales) # 组合图 library(cowplot) 10.2 数据整理+描述性统计 # 我们先处理一下感知同化数据 # 我们可以将数据处理过程封装成一个函数 # 方便后面如果有不同实验组进行调用 cat.table = function(catdata){ catdata %&gt;% select(subject, isi, rating, stimuli, response, percentage)%&gt;% # add cgload if necessary group_by(isi, stimuli, response)%&gt;% summarise(cat.mean = round(sum(percentage)/16, 3)*100, rate.mean = round(mean(rating),1))%&gt;% gather(temp, score, ends_with(&quot;.mean&quot;)) %&gt;% unite(temp1, stimuli, temp, sep = &quot;_&quot;) %&gt;% spread(temp1, score)%&gt;% select(&quot;isi&quot;,&quot;response&quot;, &quot;T45_cat.mean&quot;,&quot;T45_rate.mean&quot;, &quot;T33_cat.mean&quot;, &quot;T33_rate.mean&quot;, &quot;T21_cat.mean&quot;,&quot;T21_rate.mean&quot;, &quot;T315_cat.mean&quot;, &quot;T315_rate.mean&quot;,&quot;T241_cat.mean&quot;, &quot;T241_rate.mean&quot;)-&gt;catdata2 return(catdata2) } # 感知同化数据 cm.cat.fnl = read.csv(&quot;data/ch10/md.cat.fnl.2020-08-04.CSV&quot;)%&gt;% mutate(isi = fct_relevel(isi, &quot;Low&quot;,&quot;High&quot;), response = as_factor(response), response = fct_relevel(response, &quot;M55&quot;,&quot;M35&quot;,&quot;M214&quot;,&quot;M51&quot;)) md.cat.tbl = cat.table(cm.cat.fnl) ## `summarise()` has grouped output by &#39;isi&#39;, &#39;stimuli&#39;. You can override using ## the `.groups` argument. knitr::kable( md.cat.tbl, caption = &#39;Table 3 &#39;, booktabs = TRUE ) Table 10.1: Table 3 isi response T45_cat.mean T45_rate.mean T33_cat.mean T33_rate.mean T21_cat.mean T21_rate.mean T315_cat.mean T315_rate.mean T241_cat.mean T241_rate.mean Low M55 0.4 4.0 77.3 5.3 19.9 3.3 NA NA 21.6 4.2 Low M35 88.8 5.8 2.8 2.8 1.6 2.1 48.6 5.5 2.9 3.7 Low M214 10.3 4.3 0.7 3.3 25.8 3.7 51.2 5.4 0.4 3.5 Low M51 0.4 5.5 19.2 4.9 52.7 4.6 0.2 7.0 75.1 5.6 High M55 NA NA 84.7 5.2 26.4 3.2 0.2 7.0 28.1 5.0 High M35 85.0 5.3 0.2 5.0 1.1 3.3 44.2 5.1 0.2 2.0 High M214 14.7 4.8 1.7 5.9 6.3 3.8 55.6 5.5 0.5 6.0 High M51 0.2 2.0 13.4 4.4 66.2 4.0 NA NA 71.2 5.1 我们结合了感知同化数据和母语选项之间的重合关系对两种不同的记忆负荷下的感知区分表现进行了预测。 低记忆负荷，感知表现由好到差：Two-Category/Non-overlap {T33-T45 = T33-T21 = T33-T241} &gt; Category-Goodness/Non-overlap {T241-T21 } &gt; UnCategorised-Categorised/Partial-overlap {T315-T45}. 高记忆负荷，感知表现由好到差: Two-Category/Non-overlap {T33-T45 = T33-T21} &gt; CategoryGoodness/Non-overlap {T241-T21} &gt; Two-Category/Partial-o verlap {T33-T241} = UnCategorised-Categorised/Partial-over lap {T315-T45} # Load the data md.dis.all = read.csv(&quot;data/ch10/md.dis.all.2021-03-21.CSV&quot;) %&gt;% # set the order of the contrast mutate(Tone_contrast = fct_relevel(Tone_contrast, &quot;T33-T45&quot;,&quot;T33-T21&quot;,&quot;T241-T21&quot;, &quot;T315-T45&quot;, &quot;T33-T241&quot; ), cgload = factor(cgload,c(&quot;sssv&quot;,&quot;ssdv&quot;,&quot;dssv&quot;,&quot;dsdv&quot;))) 10.3 数据可视化 我们计算了每个认知条件下每个声调对立的作为区分表现的指标。 library(showtext) ## Loading required package: sysfonts ## Loading required package: showtextdb showtext_auto() # Overall effect of taker and vowel variability plot label.md = c(&quot;T33-T45(TC-N)&quot;,&quot;T33-T21(TC-N)&quot;, &quot;T241-T21(CG-N)&quot;,&quot;T315-T45(UC-P)&quot;, &quot;T33-T241(TC-N/P)&quot;) names(label.md) &lt;- c(&quot;T33-T45&quot;,&quot;T33-T21&quot;,&quot;T241-T21&quot;, &quot;T315-T45&quot;,&quot;T33-T241&quot;) # 计算不同实验条件下每个声调对立的感知表现平均值 md.dis.df = md.dis.all%&gt;% mutate(speaker = case_when(speaker == &quot;Constant&quot; ~ &quot;单个说话人&quot;, speaker== &quot;Variable&quot; ~ &quot;两个说话人&quot;), speaker = fct_relevel(speaker, &quot;单个说话人&quot;, &quot;两个说话人&quot;))%&gt;% groupwiseMean(dprime2 ~ speaker+vowel + Tone_contrast, data = ., conf = 0.95, digits = 3) # 画柱状图 md.dis.df%&gt;% ggplot(.,aes(speaker, Mean, fill = vowel))+ geom_bar(colour = &quot;black&quot;, stat = &quot;identity&quot;, position = position_dodge(.9))+ geom_errorbar(aes(ymin = Trad.lower, ymax = Trad.upper), width = .2, size = 0.7, position = position_dodge(.9))+ facet_wrap( ~ Tone_contrast, ncol = 3, strip.position = &quot;bottom&quot;, labeller = labeller( Tone_contrast = label.md))+ scale_fill_manual(values=c(&quot;grey75&quot;, &quot;white&quot;), name=&quot;元音变异性&quot;, labels=c(&quot;单个元音&quot;, &quot;两个元音&quot;))+ labs(y = &quot;感知准确性&quot;, x = &quot;说话人变异&quot;)+ theme_classic()+ #设置xy轴标注的字体大小 theme(axis.title.y = element_text(size = 12,face = &quot;bold&quot;), axis.title.x = element_text(size = 12,face = &quot;bold&quot;), axis.ticks = element_blank(), axis.text.x = element_text(size = 12,face = &quot;bold&quot;), axis.text.y = element_text(size = 12,face = &quot;bold&quot;))+ # 设置图例的位置 theme(legend.justification=c(1,1), legend.position=c(1,0.3), legend.text = element_text(size = 12), legend.title = element_text(size = 12))+ theme(legend.key.size = unit(1, &quot;cm&quot;))+ theme(strip.text.x = element_text(size = 12, face = &quot;bold&quot;)) 10.4 统计建模 我们使用LMER模型（通过lme4，Bates, Mächler, Bolker, &amp; Walker, 2015）拟合数据，以d’为因变量，记忆负荷（低和高）、说话人和元音变异性（恒定与可变）以及音调对比（T241-T21, T33-T21, T315-T45, T33-T241, T33-T45）为固定因素，参与者为随机因素，包括受试者内固定因素的随机截距和斜率，即说话人和元音变异性条件，以使模型在数据中最大程度地具有普遍性（如Barr, Levy, Scheepers, &amp; Tily, 2013所建议的）。 对于LMER模型中固定因素显著性的估计和相关p值的计算，有几种不同的方法（Luke, 2017）。我们使用了Kenward-Roger自由度近似法（Halekoh &amp; Hojsgaard, 2014）和R中car包的Anova函数。在此，我们报告多级因素或交互作用的主要效应，而不是使用t检验与基线水平进行比较。因此，报告的主要/交互作用效应是所有其他效应水平的平均值，可以直接用于测试我们的预测。 library(car) ## Loading required package: carData ## ## Attaching package: &#39;car&#39; ## The following object is masked from &#39;package:emuR&#39;: ## ## ellipse ## The following object is masked from &#39;package:dplyr&#39;: ## ## recode ## The following object is masked from &#39;package:purrr&#39;: ## ## some ## 为了进一步验证假设，我们对数据使用混合模型 md.dis.mdl = lmer(dprime2 ~ ISI * speaker * vowel* Tone_contrast + (1 + speaker|Subject)+(1 + vowel|Subject), data = md.dis.all) ## boundary (singular) fit: see help(&#39;isSingular&#39;) # 模型结果 md.mdl.smry = data.frame(coef(summary(md.dis.mdl))) # 计算不同效应的P值 md.dis.mdl.tbl = data.frame(Anova(md.dis.mdl, test = &quot;F&quot;)) md.dis.mdl.tbl ## F Df Df.res ## ISI 0.08144421 1 30 ## speaker 41.07944654 1 30 ## vowel 57.40271150 1 30 ## Tone_contrast 127.22783834 4 510 ## ISI:speaker 0.04256406 1 30 ## ISI:vowel 0.02175984 1 30 ## speaker:vowel 20.06062170 1 510 ## ISI:Tone_contrast 0.31491830 4 510 ## speaker:Tone_contrast 1.54945070 4 510 ## vowel:Tone_contrast 1.02610302 4 510 ## ISI:speaker:vowel 0.40565309 1 510 ## ISI:speaker:Tone_contrast 0.04896495 4 510 ## ISI:vowel:Tone_contrast 0.90573265 4 510 ## speaker:vowel:Tone_contrast 0.33158765 4 510 ## ISI:speaker:vowel:Tone_contrast 0.11884579 4 510 ## Pr..F. ## ISI 0.777310856349093248773840514331823214888572692871093750000000000000000000000000000 ## speaker 0.000000446732319194840525892266662119634013095037516904994845390319824218750000000 ## vowel 0.000000018974107701813392937758355970799539758075979989371262490749359130859375000 ## Tone_contrast 0.000000000000000000000000000000000000000000000000000000000000000000000000002911086 ## ISI:speaker 0.837942106026152933040407333464827388525009155273437500000000000000000000000000000 ## ISI:vowel 0.883714736199696204721476533450186252593994140625000000000000000000000000000000000 ## speaker:vowel 0.000009266734389606409372165847504465574502319213934242725372314453125000000000000 ## ISI:Tone_contrast 0.868026640492182921526875816198298707604408264160156250000000000000000000000000000 ## speaker:Tone_contrast 0.186630853689322862010158132761716842651367187500000000000000000000000000000000000 ## vowel:Tone_contrast 0.393171291943390510681410887627862393856048583984375000000000000000000000000000000 ## ISI:speaker:vowel 0.524469889350749340906077122781425714492797851562500000000000000000000000000000000 ## ISI:speaker:Tone_contrast 0.995491349899420452373988155159167945384979248046875000000000000000000000000000000 ## ISI:vowel:Tone_contrast 0.460284356416936102363024474470876157283782958984375000000000000000000000000000000 ## speaker:vowel:Tone_contrast 0.856740099033116431215262309706304222345352172851562500000000000000000000000000000 ## ISI:speaker:vowel:Tone_contrast 0.975786261551118694335116288129938766360282897949218750000000000000000000000000000 # 对泰语声调对进行事后检验 md.dis.mdl.tone = data.frame(lsmeans(md.dis.mdl, pairwise ~ Tone_contrast)$contrasts) ## NOTE: Results may be misleading due to involvement in interactions md.dis.mdl.tone ## contrast estimate SE df t.ratio ## 1 (T33-T45) - (T33-T21) 0.9175000 0.1154371 510 7.948049 ## 2 (T33-T45) - (T241-T21) 1.2834375 0.1154371 510 11.118064 ## 3 (T33-T45) - (T315-T45) 2.0775781 0.1154371 510 17.997484 ## 4 (T33-T45) - (T33-T241) 2.2747656 0.1154371 510 19.705665 ## 5 (T33-T21) - (T241-T21) 0.3659375 0.1154371 510 3.170015 ## 6 (T33-T21) - (T315-T45) 1.1600781 0.1154371 510 10.049436 ## 7 (T33-T21) - (T33-T241) 1.3572656 0.1154371 510 11.757616 ## 8 (T241-T21) - (T315-T45) 0.7941406 0.1154371 510 6.879420 ## 9 (T241-T21) - (T33-T241) 0.9913281 0.1154371 510 8.587601 ## 10 (T315-T45) - (T33-T241) 0.1971875 0.1154371 510 1.708181 ## p.value ## 1 0.0000000001850168 ## 2 0.0000000001848676 ## 3 0.0000000001848434 ## 4 0.0000000001848434 ## 5 0.0139264721185274 ## 6 0.0000000001848901 ## 7 0.0000000001848456 ## 8 0.0000000003614909 ## 9 0.0000000001848907 ## 10 0.4297741957500414 预测 低记忆负荷，感知表现由好到差：{T33-T45 = T33-T21 = T33-T241} &gt; {T241-T21 } &gt; {T315-T45}. 高记忆负荷，感知表现由好到差: {T33-T45 = T33-T21} &gt; {T241-T21} &gt; {T33-T241} = {T315-T45} 结果： T33-T45 (M = 4.33, 95 % CIs [4.15, 4.52]) &gt; T33-T21 (M = 3.42, 95 % CIs [3.21, 3.63]) &gt; T241-T21 (M = 3.05, 95 % CIs [2.85, 3.26]) &gt; T33-241 (M = 2.06, 95 % CIs [1.87, 2.25]) = T315-T45 (M = 2.26, 95 % CIs [2.06, 2.45]). # 对刺激说话人变异和元音环境两个变量的交互作用进行进行事后检验 md.dis.mdl.vwl.tlk = data.frame(lsmeans(md.dis.mdl, pairwise ~ speaker:vowel)$contrasts) ## NOTE: Results may be misleading due to involvement in interactions md.dis.mdl.vwl.tlk ## contrast estimate SE df ## 1 Constant Constant - Variable Constant 0.7949375 0.1032501 113.33333 ## 2 Constant Constant - Constant Variable 0.8951875 0.1046631 108.10159 ## 3 Constant Constant - Variable Variable 1.0361250 0.1046631 59.95688 ## 4 Variable Constant - Constant Variable 0.1002500 0.1046631 59.95688 ## 5 Variable Constant - Variable Variable 0.2411875 0.1046631 108.10159 ## 6 Constant Variable - Variable Variable 0.1409375 0.1032501 113.33333 ## t.ratio p.value ## 1 7.6991437 0.0000000000334174910 ## 2 8.5530376 0.0000000000006066259 ## 3 9.8996200 0.0000000000200567341 ## 4 0.9578351 0.7736955322903441568 ## 5 2.3044175 0.1033637878297640755 ## 6 1.3650105 0.5238382126248282145 # Mandarin talker vowel interaction md.tlk.vwl = groupwiseMean(dprime2 ~ speaker + vowel, data = md.dis.all, conf = 0.95, digits = 3) md.tlk.vwl%&gt;% ggplot(aes(x=speaker, y= Mean, fill=vowel)) + geom_bar(colour = &quot;black&quot;, stat = &quot;identity&quot;, position = position_dodge(.9))+ geom_errorbar(aes(ymin = Trad.lower, ymax = Trad.upper), width = .2, size = 0.7,position = position_dodge(.9))+ labs(y = &quot;d&#39; values&quot;, x = &quot;Talker variability&quot;)+ theme_classic()+ scale_y_continuous(expand = c(0, 0), limits = c(0, 4))+ theme(axis.title.y = element_text(size = 12,face = &quot;bold&quot;), axis.title.x = element_text(size = 12,face = &quot;bold&quot;), axis.text.x = element_text(size = 12,face = &quot;bold&quot;), axis.text.y = element_text(size = 12,face = &quot;bold&quot;))+ #change lengent style scale_x_discrete(labels=c(&quot;Constant&quot;, &quot;Variable&quot;))+ scale_fill_manual(values=c(&quot;white&quot;,&quot;grey75&quot;), name=&quot;Vowel variability&quot;)+ theme(legend.title = element_text(size=12, face=&quot;bold&quot;), legend.text = element_text(size = 12, face = &quot;bold&quot;)) 除了主要效应外，我们还进行了多重比较，并使用Tukey调整来解析说话人变异性和元音变异性的交互作用。在恒定说话人的条件下，恒定元音条件（M = 3.71, 95% CI [3.51, 3.90]）的辨别效果优于可变元音条件（M = 2.81, 95% CI [2.60, 3.03]），b = 0.90, SE = 0.11, t(108) = 8.55, p &lt; 0.001。 同样地，在恒定元音的条件下，恒定说话人条件（M = 3.71）的辨别效果优于可变说话人条件（M = 2.91, 95% CI [2.70, 3.12]），b = 0.80, SE = 0.10, t(113) = 7.70, p &lt; 0.001。此外，恒定说话人 + 元音条件（M = 3.71）的得分显著高于可变说话人 + 元音条件（M = 2.67, 95% CI [2.46, 2.88]），b = 1.04, SE = 0.11, t(60) = 9.90, p &lt; 0.001。 10.5 结论 记忆负荷对感知区分任务没有影响，这与先前有关辅音的研究（Werker &amp; Logan, 1985）不同，但与之前关于声调感知的发现一致（Lee et al., 1996）。这一发现与“线索持续时间假设”相一致，即音响特性的持续时间越长，在短期记忆中衰退的可能性就越小（Fujisaki &amp; Kawashima, 1970）。词汇声调的音响特性，即基频和音调轮廓，贯穿整个响音音节的持续时间，即[ma:]和[mi:]，因此不太可能衰退，更有可能在记忆中保持稳定，而辅音的更短暂的音响特性，如共振峰转换或发声起始时间，则更容易衰退。 与同化过程没有显著影响不同的是，说话人和元音上下文的变化对非母语声调的辨别产生了影响。 在辨别任务中，听众被要求注意语音差异，因此他们默认应倾向于语音模式。然而，高刺激变异性应使听众即使在辨别任务中也倾向于更多的音位模式，这需要他们感知抽象的音高轮廓和相对高度，并减少对具体语音基频差异的注意，这些差异在辨别声调时是重要的。因此，他们的辨别准确性降低了。 "],["案例二文本数据分析.html", "Chapter 11 案例二、文本数据分析 11.1 研究背景 11.2 数据处理 11.3 数据可视化 11.4 统计建模 11.5 结论", " Chapter 11 案例二、文本数据分析 11.1 研究背景 详细背景请看原文献 罗伯特·范·古利克（Robert Van Gulik）是一位荷兰小说家和汉学家。他的《狄公案》侦探小说系列（总共17本）在1949年至1968年间陆续出版。该系列的第一本书，即《狄公奇案》（Celebrated Cases of Judge Dee），是从一本中文书《狄公案》翻译而来。狄公或狄仁杰是一位真实存在的历史上的侦探和政治家，生活在公元630年至700年之间，即唐代（公元618年至907年）。这部翻译作品激发了译者对中国侦探故事的兴趣，并为他自己的侦探小说（其余16本）创造了狄仁杰这一角色。 在翻译的前言中，作者声称他保留了原文中的所有中国元素，并谴责那些涉及过多改写并扭曲中国文化和历史现实的伪造“中国”故事。相反，在创作中，作者在第15册中承认，尽管他在创作后来的故事时借用了一些古代中国刑侦文学的元素，但这些故事本身是完全虚构的，即非翻译作品。于是，一个想法诞生了。 对于同一个主题故事，翻译和创造的文本语言上有什么不同呢？ 我收集了这17本书，进行了文本分析，从词汇丰富度、可读性、和句法复杂度进行了研究。 11.2 数据处理 library(lme4) library(lsmeans) setwd(&quot;~/Nutstore Files/310_Tutorial/LanguageDS-e&quot;) library(tidyverse) # 显示小数点后很多位 options(scipen=999) # 计算置信区间 library(rcompanion) # 改变y轴度量 library(scales) # 组合图 library(cowplot) library(tidytext) require(readtext) library(rstatix) library(flextable) library(quanteda) library(quanteda.textstats) 11.2.1 特征提取 11.2.1.1 词汇复杂度特征 dee.raw =readtext(&quot;data/ch11/*txt&quot;, docvarsfrom = &quot;filenames&quot;) dee.corpus = corpus(dee.raw) dee.corpus.summary = data.frame(summary(dee.corpus)) dee.dfm &lt;- dfm(dee.corpus, remove_numbers = TRUE, remove_punct = TRUE, remove_symbols = TRUE #remove = stopwords(&quot;english&quot;) ) ## Warning: &#39;dfm.corpus()&#39; is deprecated. Use &#39;tokens()&#39; first. ## Warning: &#39;...&#39; should not be used for tokens() arguments; use &#39;tokens()&#39; ## first. dee.corpus.summary%&gt;% flextable()%&gt;% set_caption(caption = &quot;Table 1. Number of types, tokens, and sentences of each book in the Judge Dee series.&quot;) .cl-56d95d92{}.cl-56b3615a{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-56d410d0{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-56d410da{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-56d42d9a{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-56d42da4{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-56d42da5{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-56d42dae{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-56d42daf{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-56d42db8{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 11.1: Table 1. Number of types, tokens, and sentences of each book in the Judge Dee series. TextTypesTokensSentencesdocvar1docvar201_Celebrated-Cases.txt6,01079,2763,6861Celebrated-Cases02_The-Chinese-Bell-Murders.txt7,85889,6114,6962The-Chinese-Bell-Murders lexical.diversity &lt;- textstat_lexdiv(dee.dfm, measure = &quot;all&quot;) lexical.diversity%&gt;% flextable()%&gt;% set_caption(caption = &quot;词汇复杂度指标.&quot;) .cl-57030b4c{}.cl-56fa719e{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-56fe4080{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-56fe408a{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-56fe585e{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-56fe5868{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-56fe5869{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-56fe5872{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-56fe5873{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-56fe587c{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 11.1: 词汇复杂度指标. documentTTRCRCTTRUSKIDVmMaaslgV0lgeV001_Celebrated-Cases.txt0.077996240.771085720.5131614.5049921.142930.835147497.795960.62120490.0097797380.098023960.21747915.86117113.4958502_The-Chinese-Bell-Murders.txt0.090611020.787001925.4176417.9729922.985700.8492039104.172920.78727360.0104174240.101438390.20857936.24537914.38052 # 信息熵 textstat_entropy(dee.dfm)$entropy ## [1] 9.176072 9.449439 readability &lt;- textstat_readability(dee.corpus, measure = &quot;all&quot;) readability.df = readability%&gt;% as.data.frame()%&gt;% select(document, ARI, Flesch, FOG, Coleman.Liau.short, Dale.Chall, Spache) 11.2.1.2 句法特征提取 句法复杂度分析器，L2SCA L2 Syntactic Complexity Analyzer (“L2SCA”) is a tool that allows ESL and EFL teachers and researchers to analyze the syntactic complexity of written English language samples produced by advanced English learners. L2SCA was developed by Xiaofei Lu at The Pennsylvania State University (“PSU”), University Park, PA, USA. Unless stated otherwise, these Terms of Service apply to all usage of L2SCA, including those currently offered as well as any new products or services that we may add in the future. 陆小飞老师的官网 需要注意的是，这个句法复杂度分析器是基于英语笔语开发的，基本的要求是句法分词和标注是准确的。如果是中文，标注正确率一般不如英文，如果是口语，转写时如何确定句子的单位边界也是问题。 由于文本数据处理需要一定时间，此处我们导入已经处理完成的词汇和句法数据进行分析。 lexical.diversity.df = read_csv(&quot;data/ch11/lexical.diversity.df.2022-07-21.CSV&quot;) ## Rows: 17 Columns: 6 ## ── Column specification ───────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (1): document ## dbl (5): TTR, C, R, MATTR, entropy ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. readability.df = read.csv(&quot;data/ch11/readability.df.2022-07-21.CSV&quot;) metrics_SCA &lt;- read_csv(&quot;data/ch11/metrics_SCA.csv&quot;) ## Rows: 38 Columns: 15 ## ── Column specification ───────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (1): text ## dbl (14): MLS, MLT, MLC, C/S, VP/T, C/T, DC/C, DC/T, T/S, CT/T, CP/T, CP/... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. 11.3 数据可视化 11.4 统计建模 t.test(lexical.diversity.df$TTR[2:17], mu = lexical.diversity.df$TTR[1], alternative = &quot;greater&quot;) ## ## One Sample t-test ## ## data: lexical.diversity.df$TTR[2:17] ## t = 7.8923, df = 15, p-value = 0.0000005086 ## alternative hypothesis: true mean is greater than 0.08 ## 95 percent confidence interval: ## 0.09701608 Inf ## sample estimates: ## mean of x ## 0.101875 # t.test(lexical.diversity.df$C[2:17], mu = lexical.diversity.df$C[1], alternative = &quot;greater&quot;) # # t.test(lexical.diversity.df$R[2:17], mu = lexical.diversity.df$R[1], alternative = &quot;greater&quot;) # # t.test(lexical.diversity.df$MATTR[2:17], mu = lexical.diversity.df$MATTR[1], alternative = &quot;greater&quot;) # # lexical.diversity.stat = lexical.diversity.df%&gt;% # as.data.frame()%&gt;% # mutate(id = 1:n())%&gt;% # select(&quot;document&quot;, &quot;id&quot;,&quot;TTR&quot;,&quot;C&quot;,&quot;R&quot;)%&gt;% # mutate(txt.type = case_when(id &lt; 2 ~ &quot;ref&quot;, # id &gt; 1 ~ &quot;freewriting&quot;))%&gt;% # gather(&quot;measures&quot;, &quot;values&quot;, -c(&quot;document&quot;, &quot;id&quot;,&quot;txt.type&quot;))%&gt;% # mutate(measures = as.factor(measures), # measures = fct_relevel(measures, &quot;TTR&quot;,&quot;C&quot;,&quot;R&quot;))%&gt;% # filter(measures == &quot;TTR&quot;)%&gt;% # group_by(measures)%&gt;% # rstatix::t_test(values ~ 1, mu = &quot;ref&quot;) # %&gt;% # rstatix::adjust_pvalue() %&gt;% # rstatix::add_significance(&quot;p.adj&quot;) metrics_SCA.ci = metrics_SCA%&gt;% filter(text !=&quot;01.txt&quot;)%&gt;% gather(&quot;measures&quot;, &quot;values&quot;, -c(&quot;text&quot;))%&gt;% groupwiseMean(values ~ measures, data = ., conf = 0.95, digits = 3) # mean length of clause (MLC): number of words divided by number of clauses; t.test(metrics_SCA$MLC[2:17], mu = metrics_SCA$MLC[1], alternative = &quot;less&quot;) ## ## One Sample t-test ## ## data: metrics_SCA$MLC[2:17] ## t = -9.8862, df = 15, p-value = 0.00000002904 ## alternative hypothesis: true mean is less than 9.508 ## 95 percent confidence interval: ## -Inf 8.726519 ## sample estimates: ## mean of x ## 8.558075 t.test(metrics_SCA$MLS[2:17], mu = metrics_SCA$MLS[1], alternative = &quot;less&quot;) ## ## One Sample t-test ## ## data: metrics_SCA$MLS[2:17] ## t = -22.252, df = 15, p-value = 0.0000000000003344 ## alternative hypothesis: true mean is less than 18.8517 ## 95 percent confidence interval: ## -Inf 14.27011 ## sample estimates: ## mean of x ## 13.87829 # # t.test(metrics_SCA$MLT[2:17], mu = metrics_SCA$MLT[1], alternative = &quot;less&quot;) # # t.test(metrics_SCA$&quot;C/S&quot;[2:17], mu = metrics_SCA$&quot;C/S&quot;[1], alternative = &quot;less&quot;) # # t.test(metrics_SCA$&quot;C/T&quot;[2:17], mu = metrics_SCA$&quot;C/T&quot;[1], alternative = &quot;less&quot;) # # t.test(metrics_SCA$&quot;CT/T&quot;[2:17], mu = metrics_SCA$&quot;CT/T&quot;[1], alternative = &quot;less&quot;) # # t.test(metrics_SCA$&quot;DC/C&quot;[2:17], mu = metrics_SCA$&quot;DC/C&quot;[1], alternative = &quot;less&quot;) # # t.test(metrics_SCA$&quot;DC/T&quot;[2:17], mu = metrics_SCA$&quot;DC/T&quot;[1], alternative = &quot;less&quot;) # # t.test(metrics_SCA$&quot;CP/C&quot;[2:17], mu = metrics_SCA$&quot;CP/C&quot;[1], alternative = &quot;less&quot;) # # t.test(metrics_SCA$&quot;CP/T&quot;[2:17], mu = metrics_SCA$&quot;CP/T&quot;[1], alternative = &quot;less&quot;) # # t.test(metrics_SCA$&quot;T/S&quot;[2:17], mu = metrics_SCA$&quot;T/S&quot;[1], alternative = &quot;less&quot;) # # t.test(metrics_SCA$&quot;CN/C&quot;[2:17], mu = metrics_SCA$&quot;CN/C&quot;[1], alternative = &quot;less&quot;) # # t.test(metrics_SCA$&quot;CN/T&quot;[2:17], mu = metrics_SCA$&quot;CN/T&quot;[1], alternative = &quot;less&quot;) # # t.test(metrics_SCA$&quot;VP/T&quot;[2:17], mu = metrics_SCA$&quot;VP/T&quot;[1], alternative = &quot;less&quot;) t.test(readability.df$ARI[2:17], mu = readability.df$ARI[1], alternative = &quot;less&quot;) ## ## One Sample t-test ## ## data: readability.df$ARI[2:17] ## t = -15.986, df = 15, p-value = 0.00000000003939 ## alternative hypothesis: true mean is less than 8.35 ## 95 percent confidence interval: ## -Inf 5.834795 ## sample estimates: ## mean of x ## 5.525 t.test(readability.df$Flesch[2:17], mu = readability.df$Flesch[1], alternative = &quot;greater&quot;) ## ## One Sample t-test ## ## data: readability.df$Flesch[2:17] ## t = 11.582, df = 15, p-value = 0.000000003502 ## alternative hypothesis: true mean is greater than 71.94 ## 95 percent confidence interval: ## 77.78876 Inf ## sample estimates: ## mean of x ## 78.83187 t.test(readability.df$FOG[2:17], mu = readability.df$FOG[1], alternative = &quot;less&quot;) ## ## One Sample t-test ## ## data: readability.df$FOG[2:17] ## t = -15.11, df = 15, p-value = 0.00000000008754 ## alternative hypothesis: true mean is less than 10.71 ## 95 percent confidence interval: ## -Inf 8.611097 ## sample estimates: ## mean of x ## 8.335625 t.test(readability.df$Coleman.Liau.short[2:17], mu = readability.df$Coleman.Liau.short[1], alternative = &quot;less&quot;) ## ## One Sample t-test ## ## data: readability.df$Coleman.Liau.short[2:17] ## t = -7.2341, df = 15, p-value = 0.000001453 ## alternative hypothesis: true mean is less than 8.02 ## 95 percent confidence interval: ## -Inf 7.366983 ## sample estimates: ## mean of x ## 7.158125 t.test(readability.df$Dale.Chall[2:17], mu = readability.df$Dale.Chall[1], alternative = &quot;greater&quot;) ## ## One Sample t-test ## ## data: readability.df$Dale.Chall[2:17] ## t = 9.4143, df = 15, p-value = 0.00000005494 ## alternative hypothesis: true mean is greater than 34.89 ## 95 percent confidence interval: ## 38.30639 Inf ## sample estimates: ## mean of x ## 39.08812 t.test(readability.df$Spache[2:17], mu = readability.df$Spache[1], alternative = &quot;less&quot;) ## ## One Sample t-test ## ## data: readability.df$Spache[2:17] ## t = -11.792, df = 15, p-value = 0.000000002742 ## alternative hypothesis: true mean is less than 5.17 ## 95 percent confidence interval: ## -Inf 4.62461 ## sample estimates: ## mean of x ## 4.529375 我们发现，翻译文本和创作文本相比，词汇丰富性较低。 翻译文本和创作文本相比，句法复杂度较高。 可读性指标显示，翻译文本的可读性比创作文本差。 11.5 结论 根据受限语言理论（the constrained language theory,），翻译中的复杂认知过程，如激活两种语言系统和不断进行编码切换，给翻译者增加了额外的认知负担并降低了他的工作记忆容量，促使他采用简化等策略。此外，源文本在翻译过程中也可能限制了他可用的词汇资源。相反，作家能够充分发挥他的语言库，因此产生了更丰富的词汇多样性的文本。 然而，翻译文本的句法结构比创作的更为复杂。这不能归因于翻译过程的内在限制，因为翻译者需要面对更大的认知需求，并且预计他们将使用降低认知负担的策略，导致更短或更简单的句子。 于是，我们考虑英汉语的差异性。原生的汉语往往更依赖意义而不是功能词或结构来连接从句和句子，而西方语言则依靠丰富的句法手段。因此，受源语言影响的翻译汉语相对于原生汉语展现出更复杂的句法结构。在本研究中，翻译的方向是从古代汉语到英语，因此源文本的语言结构不太可能在整体上导致更复杂的目标文本句子。 抛开这一解释，我们认为罗伯特·范·古利克作为翻译者特别意识到自己作为中介者的角色，希望承担起让古代中国侦探故事为西方世界所理解的责任。为了实现这一目标，他在翻译中使用了符合西方风格的句法手段，可能过度使用了它们。我们还可以推测，翻译文本中更复杂的句子可能与显性化效应有关。也就是说，翻译者仔细说明了原始古代中国故事中包含的信息，这些故事发生在地理和文化上与他的读者相距甚远的国家。 可读性指标显示，翻译文本可能比创作文本更难阅读。这表明翻译文本中的句子可能要么更长，要么词更难，要么两者兼而有之。考虑到翻译文本的词汇多样性较低，我们推断句法复杂性在相对较低的可读性中发挥了更大的作用。正如我们所论证的，翻译中更复杂的句子可能表明翻译者在传达源文本信息时的努力，导致可读性的下降是无意的。尽管罗伯特·范·古利克作为翻译者和小说作家将目标读者放在心中，但似乎作为翻译者，他受到了源文本的限制，并在跨越语言和文化传达古代中国侦探故事时在一定程度上牺牲了可读性。翻译者和读者在翻译/阅读来自不同文化和非常古老时期的故事时可能不得不付出代价。 "],["案例三语音数据处理案例.html", "Chapter 12 案例三、语音数据处理案例 12.1 研究背景 12.2 数据导入及整理 12.3 数据建模 12.4 展示与呈现", " Chapter 12 案例三、语音数据处理案例 12.1 研究背景 详细背景请看原文献 越南南部方言中SV214调（hỏi）和SV415调（ngã）的音调合并，使得南部越南语的音系系统与北部越南语不同。鉴于这一差异的重要性及其对泰语音调感知同化模式的潜在影响，我们在声学研究中验证了南部越南语中这两个音调的合并情况。为了对基频（f0）轮廓进行全面而动态的比较，我们采用了广义加性混合模型（GAMM），这是一种非线性回归方法，不需要对数据进行聚合或预先选择轮廓中的固定时间点。该方法能够检测动态变化数据中的一般模式，同时考虑到受试者和项目相关的变异性（Nixon, van Rij, Mok, Baayen, &amp; Chen, 2016; Wieling, 2018）。通过这种方式，它可以揭示在数据聚合或任意选择单一时间点时被掩盖的模式。 setwd(&quot;~/Nutstore Files/310_Tutorial/LanguageDS-e&quot;) #install.packages(&quot;plotfunctions&quot;) library(tidyverse) ## 构建模型 library(mgcv) ## 作图 library(itsadug) 12.2 数据导入及整理 contour_data_all = read.csv(&quot;data/ch12/nv.sv.data.2024-08-24.csv&quot;) # modelling NV difference nv.data = contour_data_all%&gt;% ungroup()%&gt;% filter(tone %in% c(&quot;NV415&quot;, &quot;NV214&quot;) )%&gt;% #filter(subject != 214)%&gt;% rename(Time = Timepoint)%&gt;% select(-language)%&gt;% mutate(id = as.factor(id), tone = as.factor(tone), subject = as.factor(subject)) #sort data per individual trajectory (for autocorrelation) nv.data = data.frame(nv.data) nv.data$id = as.factor(nv.data$id) nv.data = start_event(nv.data, event = c(&quot;subject&quot;, &quot;id&quot;)) 12.3 数据建模 12.3.1 越南语北部方言声调建模 # preliminary model without autocorrelation correction model.nv = bam(normF0 ~ tone + s(Time, by=tone)+ s(Time, subject, by = tone, bs = &quot;fs&quot;, m = 1), data= nv.data) ## Warning in gam.side(sm, X, tol = .Machine$double.eps^0.5): model has repeated ## 1-d smooths of same variable. summary(model.nv) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## normF0 ~ tone + s(Time, by = tone) + s(Time, subject, by = tone, ## bs = &quot;fs&quot;, m = 1) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.11948 0.01606 -7.441 0.000000000000187 *** ## toneNV415 0.21877 0.02108 10.378 &lt; 0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(Time):toneNV214 2.90 3.290 7.629 0.0000313 *** ## s(Time):toneNV415 4.84 5.425 10.217 &lt; 0.0000000000000002 *** ## s(Time,subject):toneNV214 17.74 35.000 2.491 &lt; 0.0000000000000002 *** ## s(Time,subject):toneNV415 21.47 35.000 5.316 &lt; 0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.676 Deviance explained = 68.8% ## fREML = -878.66 Scale est. = 0.013402 n = 1280 nvacf = acf_resid(model.nv) #获取参数 nvacf[2] ## 1 ## 0.7104244 ## with autocorrelation correction model.nv.b = bam(normF0 ~ tone + s(Time, by=tone)+ s(Time, subject, by = tone, bs = &quot;fs&quot;, m = 1), rho = nvacf[2], AR.start = nv.data$start.event, discrete = T, nthreads = 2, data= nv.data) ## Warning in bam(normF0 ~ tone + s(Time, by = tone) + s(Time, subject, by = ## tone, : openMP not available: single threaded computation only ## Warning in bam(normF0 ~ tone + s(Time, by = tone) + s(Time, subject, by = ## tone, : model has repeated 1-d smooths of same variable. summary(model.nv.b) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## normF0 ~ tone + s(Time, by = tone) + s(Time, subject, by = tone, ## bs = &quot;fs&quot;, m = 1) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.12704 0.01503 -8.455 &lt;0.0000000000000002 *** ## toneNV415 0.23482 0.01943 12.083 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(Time):toneNV214 3.796 4.208 6.028 0.0000918 *** ## s(Time):toneNV415 5.725 6.114 9.966 &lt; 0.0000000000000002 *** ## s(Time,subject):toneNV214 25.133 35.000 3.414 &lt; 0.0000000000000002 *** ## s(Time,subject):toneNV415 25.402 35.000 6.310 &lt; 0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.672 Deviance explained = 68.8% ## fREML = -1436.5 Scale est. = 0.01023 n = 1280 # plot plot_smooth(model.nv.b, ylab = &quot;Normalised f0&quot;, xlab = &quot;Normalised time&quot;, view=&quot;Time&quot;, cond=list(tone=c(&quot;NV415&quot;)), ylim=c(-0.5,1), rm.ranef=T, main=&quot;Northen Vietnamese&quot;, rug=FALSE, col=&quot;blue&quot;, hide.label = &quot;fitted values&quot;) ## Summary: ## * tone : factor; set to the value(s): NV415. ## * Time : numeric predictor; with 30 values ranging from 1.000000 to 10.000000. ## * subject : factor; set to the value(s): 211. (Might be canceled as random effect, check below.) ## * NOTE : The following random effects columns are canceled: s(Time,subject):toneNV214,s(Time,subject):toneNV415 ## plot_smooth(model.nv.b, view=&quot;Time&quot;, cond=list(tone=c(&quot;NV214&quot;)), v0 = 6, rug=FALSE,rm.ranef=T, col=&quot;green&quot;,add=T) ## Summary: ## * tone : factor; set to the value(s): NV214. ## * Time : numeric predictor; with 30 values ranging from 1.000000 to 10.000000. ## * subject : factor; set to the value(s): 211. (Might be canceled as random effect, check below.) ## * NOTE : The following random effects columns are canceled: s(Time,subject):toneNV214,s(Time,subject):toneNV415 ## 验证越南语北部方言是否存在这个声调对立 模型比较法 模型1区分两个对立 model.nv = bam(normF0 ~ tone + s(Time, by=tone)+ s(Time, subject, by = tone, bs = &quot;fs&quot;, m = 1), data= nv.data) ## Warning in gam.side(sm, X, tol = .Machine$double.eps^0.5): model has repeated ## 1-d smooths of same variable. #模型2不区分两个对立 model.nv0 = bam(normF0 ~ tone + s(Time)+ s(Time, subject, by = tone, bs = &quot;fs&quot;, m = 1), data= nv.data) #比较两个模型 compareML(model.nv, model.nv0) ## model.nv: normF0 ~ tone + s(Time, by = tone) + s(Time, subject, by = tone, ## bs = &quot;fs&quot;, m = 1) ## ## model.nv0: normF0 ~ tone + s(Time) + s(Time, subject, by = tone, bs = &quot;fs&quot;, ## m = 1) ## ## Chi-square test of fREML scores ## ----- ## Model Score Edf Difference Df p.value Sig. ## 1 model.nv0 -868.0538 8 ## 2 model.nv -878.6559 10 10.602 2.000 2.486e-05 *** ## ## AIC difference: -4.63, model model.nv has lower AIC. #此方法缺点是计算量比较大。但是对于不是很复杂的模型没有影响。 差值比较法 通过修改模型的设定，将表示两个原始平滑函数之间差异的函数包含在模型中。接下来，发现这个差异平滑函数是显著的，这就表明有显著差异。为了拟合这个新模型，我们首先需要创建一个新的二元变量，该变量在一个水平上等于0，而在另一个水平上等于1。我们现在创建一个名为IS214的变量，该变量在单词‘NV214’上为1，而在单词‘NV415’上为0。 nv.data$IS214 = (nv.data$tone == &quot;NV214&quot;)*1 model.nv.binary = bam(normF0 ~ s(Time) + s(Time, by=IS214)+ s(Time, subject, by = tone, bs = &quot;fs&quot;, m = 1), rho = nvacf[2], AR.start = nv.data$start.event, discrete = T, nthreads = 2, data= nv.data) ## Warning in bam(normF0 ~ s(Time) + s(Time, by = IS214) + s(Time, subject, : ## openMP not available: single threaded computation only summary(model.nv.binary) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## normF0 ~ s(Time) + s(Time, by = IS214) + s(Time, subject, by = tone, ## bs = &quot;fs&quot;, m = 1) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.09447 0.01406 6.718 0.0000000000283 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(Time) 5.770 6.150 8.406 &lt;0.0000000000000002 *** ## s(Time):IS214 4.732 5.074 31.089 &lt;0.0000000000000002 *** ## s(Time,subject):toneNV214 23.543 35.000 3.181 &lt;0.0000000000000002 *** ## s(Time,subject):toneNV415 27.465 35.000 6.699 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.672 Deviance explained = 68.8% ## fREML = -1434.9 Scale est. = 0.01023 n = 1280 soluation 3 nv.data$toneO = as.ordered(nv.data$tone) contrasts(nv.data$toneO) = &quot;contr.treatment&quot; model.nv.ord = bam(normF0 ~ toneO+ s(Time) + s(Time, by=toneO)+ s(Time, subject, by = tone, bs = &quot;fs&quot;, m = 1), rho = nvacf[2], AR.start = nv.data$start.event, discrete = T, nthreads = 2, data= nv.data) ## Warning in bam(normF0 ~ toneO + s(Time) + s(Time, by = toneO) + s(Time, : ## openMP not available: single threaded computation only summary(model.nv.ord ) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## normF0 ~ toneO + s(Time) + s(Time, by = toneO) + s(Time, subject, ## by = tone, bs = &quot;fs&quot;, m = 1) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.11903 0.01444 -8.241 0.000000000000000437 *** ## toneONV415 0.21311 0.02010 10.605 &lt; 0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(Time) 4.385 4.798 5.805 0.0000695 *** ## s(Time):toneONV415 4.855 5.224 9.888 &lt; 0.0000000000000002 *** ## s(Time,subject):toneNV214 24.989 35.000 3.374 &lt; 0.0000000000000002 *** ## s(Time,subject):toneNV415 25.920 35.000 6.324 &lt; 0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.673 Deviance explained = 68.8% ## fREML = -1436.8 Scale est. = 0.010231 n = 1280 12.3.2 越南语南部方言声调建模 sv.data = contour_data_all%&gt;% ungroup()%&gt;% filter(tone %in% c(&quot;SV415&quot;, &quot;SV214&quot;) )%&gt;% rename(Time = Timepoint)%&gt;% select(-language)%&gt;% mutate(id = as.factor(id), tone = as.factor(tone), subject = as.factor(subject)) #sort data per individual trajectory (for autocorrelation) sv.data = start_event(sv.data, event = c(&quot;subject&quot;, &quot;id&quot;)) # preliminary model without autocorrelation correction model.sv = bam(normF0 ~ tone + s(Time, by=tone)+ s(Time, subject, by = tone, bs = &quot;fs&quot;, m = 1), data= sv.data) ## Warning in gam.side(sm, X, tol = .Machine$double.eps^0.5): model has repeated ## 1-d smooths of same variable. summary(model.sv) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## normF0 ~ tone + s(Time, by = tone) + s(Time, subject, by = tone, ## bs = &quot;fs&quot;, m = 1) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.041462 0.003706 -11.189 &lt;0.0000000000000002 *** ## toneSV415 0.022919 0.010785 2.125 0.0338 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(Time):toneSV214 5.503 6.116 25.066 &lt;0.0000000000000002 *** ## s(Time):toneSV415 5.433 6.061 25.096 &lt;0.0000000000000002 *** ## s(Time,subject):toneSV214 19.606 35.000 5.389 &lt;0.0000000000000002 *** ## s(Time,subject):toneSV415 21.771 35.000 5.725 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.81 Deviance explained = 81.8% ## fREML = -1135.6 Scale est. = 0.0087883 n = 1280 svacf = acf_resid(model.sv) svacf[2] ## 1 ## 0.5071284 ## with autocorrelation correction model.sv.b = bam(normF0 ~ tone + s(Time, by=tone)+ s(Time, subject, by = tone, bs = &quot;fs&quot;, m = 1), rho = svacf[2], AR.start = sv.data$start.event, discrete = T, nthreads = 2, data= sv.data) ## Warning in bam(normF0 ~ tone + s(Time, by = tone) + s(Time, subject, by = ## tone, : openMP not available: single threaded computation only ## Warning in bam(normF0 ~ tone + s(Time, by = tone) + s(Time, subject, by = ## tone, : model has repeated 1-d smooths of same variable. summary(model.sv.b) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## normF0 ~ tone + s(Time, by = tone) + s(Time, subject, by = tone, ## bs = &quot;fs&quot;, m = 1) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.042435 0.005763 -7.363 0.000000000000329 *** ## toneSV415 0.024513 0.010851 2.259 0.0241 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(Time):toneSV214 5.965 6.442 24.104 &lt;0.0000000000000002 *** ## s(Time):toneSV415 5.887 6.383 23.590 &lt;0.0000000000000002 *** ## s(Time,subject):toneSV214 22.274 35.000 4.895 &lt;0.0000000000000002 *** ## s(Time,subject):toneSV415 23.859 35.000 4.822 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.809 Deviance explained = 81.8% ## fREML = -1371.9 Scale est. = 0.0078498 n = 1280 # plot plot_smooth(model.sv.b, ylab = &quot;Normalised f0&quot;, xlab = &quot;Normalised time&quot;, view=&quot;Time&quot;, cond=list(tone=c(&quot;SV415&quot;)), ylim=c(-0.5,1), rm.ranef=T, main=&quot;Southen Vietnamese&quot;, rug=FALSE, col=&quot;blue&quot;, hide.label = &quot;fitted values&quot;) ## Summary: ## * tone : factor; set to the value(s): SV415. ## * Time : numeric predictor; with 30 values ranging from 1.000000 to 10.000000. ## * subject : factor; set to the value(s): 411. (Might be canceled as random effect, check below.) ## * NOTE : The following random effects columns are canceled: s(Time,subject):toneSV214,s(Time,subject):toneSV415 ## plot_smooth(model.sv.b, view=&quot;Time&quot;, cond=list(tone=c(&quot;SV214&quot;)), v0 = 6, rug=FALSE,rm.ranef=T, col=&quot;green&quot;,add=T) ## Summary: ## * tone : factor; set to the value(s): SV214. ## * Time : numeric predictor; with 30 values ranging from 1.000000 to 10.000000. ## * subject : factor; set to the value(s): 411. (Might be canceled as random effect, check below.) ## * NOTE : The following random effects columns are canceled: s(Time,subject):toneSV214,s(Time,subject):toneSV415 ## # testing if the tone contrast exists #solution 1 model.sv.b = bam(normF0 ~ tone + s(Time, by=tone)+ s(Time, subject, by = tone, bs = &quot;fs&quot;, m = 1), rho = svacf[2], AR.start = sv.data$start.event, discrete = T, nthreads = 2, data= sv.data) ## Warning in bam(normF0 ~ tone + s(Time, by = tone) + s(Time, subject, by = ## tone, : openMP not available: single threaded computation only ## Warning in bam(normF0 ~ tone + s(Time, by = tone) + s(Time, subject, by = ## tone, : model has repeated 1-d smooths of same variable. model.sv.b0 = bam(normF0 ~ tone + s(Time, subject, by = tone, bs = &quot;fs&quot;, m = 1), rho = svacf[2], AR.start = sv.data$start.event, discrete = T, nthreads = 2, data= sv.data) ## Warning in bam(normF0 ~ tone + s(Time, subject, by = tone, bs = &quot;fs&quot;, m = ## 1), : openMP not available: single threaded computation only compareML(model.sv, model.sv.b0) ## model.sv: normF0 ~ tone + s(Time, by = tone) + s(Time, subject, by = tone, ## bs = &quot;fs&quot;, m = 1) ## ## model.sv.b0: normF0 ~ tone + s(Time, subject, by = tone, bs = &quot;fs&quot;, m = 1) ## ## Model model.sv.b0 preferred: lower fREML score (197.409), and lower df (4.000). ## ----- ## Model Score Edf Difference Df ## 1 model.sv -1135.594 10 ## 2 model.sv.b0 -1333.003 6 -197.409 4.000 ## ## AIC difference: 478.04, model model.sv.b0 has lower AIC. # solution 2 sv.data$IS214 = (sv.data$tone == &quot;SV214&quot;)*1 model.sv.binary = bam(normF0 ~ s(Time) + s(Time, by=IS214)+ s(Time, subject, by = tone, bs = &quot;fs&quot;, m = 1), rho = svacf[2], AR.start = sv.data$start.event, discrete = T, nthreads = 2, data= sv.data) ## Warning in bam(normF0 ~ s(Time) + s(Time, by = IS214) + s(Time, subject, : ## openMP not available: single threaded computation only summary(model.sv.binary) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## normF0 ~ s(Time) + s(Time, by = IS214) + s(Time, subject, by = tone, ## bs = &quot;fs&quot;, m = 1) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.02383 0.00942 -2.53 0.0115 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(Time) 6.956 7.387 42.964 &lt;0.0000000000000002 *** ## s(Time):IS214 2.000 2.000 2.206 0.111 ## s(Time,subject):toneSV214 23.485 35.000 4.868 &lt;0.0000000000000002 *** ## s(Time,subject):toneSV415 24.879 35.000 4.749 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.809 Deviance explained = 81.8% ## fREML = -1378 Scale est. = 0.0078415 n = 1280 # soluation 3 sv.data$toneO = as.ordered(sv.data$tone) contrasts(sv.data$toneO) = &quot;contr.treatment&quot; model.sv.ord = bam(normF0 ~ toneO+ s(Time) + s(Time, by=toneO)+ s(Time, subject, by = tone, bs = &quot;fs&quot;, m = 1), rho = svacf[2], AR.start = sv.data$start.event, discrete = T, nthreads = 2, data= sv.data) ## Warning in bam(normF0 ~ toneO + s(Time) + s(Time, by = toneO) + s(Time, : ## openMP not available: single threaded computation only summary(model.sv.ord ) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## normF0 ~ toneO + s(Time) + s(Time, by = toneO) + s(Time, subject, ## by = tone, bs = &quot;fs&quot;, m = 1) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.046695 0.005703 -8.188 0.000000000000000665 *** ## toneOSV415 0.022863 0.011004 2.078 0.0379 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(Time) 6.956 7.387 42.114 &lt;0.0000000000000002 *** ## s(Time):toneOSV415 1.000 1.000 0.095 0.758 ## s(Time,subject):toneSV214 23.485 35.000 4.868 &lt;0.0000000000000002 *** ## s(Time,subject):toneSV415 24.879 35.000 4.749 &lt;0.0000000000000002 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.809 Deviance explained = 81.8% ## fREML = -1378 Scale est. = 0.0078415 n = 1280 12.4 展示与呈现 # plot the comparison library(cowplot) # png(paste(dir.fig, paste(&quot;gam.mdl&quot;,Sys.Date(),&quot;png&quot;,sep = &quot;.&quot;),sep = &quot;&quot;), units=&quot;in&quot;, width=14, height=10, res=600) par(mfrow=c(1,2)) # Northen Vietnamese plot_smooth(model.nv.b, ylab = &quot;Normalised f0&quot;, xlab = &quot;Normalised time&quot;, view=&quot;Time&quot;, cond=list(tone=c(&quot;NV415&quot;)), ylim=c(-0.5,0.6), rm.ranef=T, main=&quot;Northern Vietnamese&quot;, rug=FALSE, col=&quot;black&quot;, hide.label = &quot;fitted values&quot;) ## Summary: ## * tone : factor; set to the value(s): NV415. ## * Time : numeric predictor; with 30 values ranging from 1.000000 to 10.000000. ## * subject : factor; set to the value(s): 211. (Might be canceled as random effect, check below.) ## * NOTE : The following random effects columns are canceled: s(Time,subject):toneNV214,s(Time,subject):toneNV415 ## plot_smooth(model.nv.b, view=&quot;Time&quot;, cond=list(tone=c(&quot;NV214&quot;)), v0 = 6, rug=FALSE,rm.ranef=T, col=&quot;gray&quot;,add=T) ## Summary: ## * tone : factor; set to the value(s): NV214. ## * Time : numeric predictor; with 30 values ranging from 1.000000 to 10.000000. ## * subject : factor; set to the value(s): 211. (Might be canceled as random effect, check below.) ## * NOTE : The following random effects columns are canceled: s(Time,subject):toneNV214,s(Time,subject):toneNV415 ## # Southern vietnamese plot_smooth(model.sv.b, ylab = &quot;Normalised f0&quot;, xlab = &quot;Normalised time&quot;, view=&quot;Time&quot;, cond=list(tone=c(&quot;SV415&quot;)), ylim=c(-0.5,0.6), rm.ranef=T, main=&quot;Southern Vietnamese&quot;, rug=FALSE, col=&quot;black&quot;, hide.label = &quot;fitted values&quot;) ## Summary: ## * tone : factor; set to the value(s): SV415. ## * Time : numeric predictor; with 30 values ranging from 1.000000 to 10.000000. ## * subject : factor; set to the value(s): 411. (Might be canceled as random effect, check below.) ## * NOTE : The following random effects columns are canceled: s(Time,subject):toneSV214,s(Time,subject):toneSV415 ## plot_smooth(model.sv.b, view=&quot;Time&quot;, cond=list(tone=c(&quot;SV214&quot;)), v0 = 6, rug=FALSE,rm.ranef=T, col=&quot;gray&quot;,add=T) ## Summary: ## * tone : factor; set to the value(s): SV214. ## * Time : numeric predictor; with 30 values ranging from 1.000000 to 10.000000. ## * subject : factor; set to the value(s): 411. (Might be canceled as random effect, check below.) ## * NOTE : The following random effects columns are canceled: s(Time,subject):toneSV214,s(Time,subject):toneSV415 ## # dev.off() # write.csv(nv.data, # file = paste(&quot;data/ch12/&quot;, # paste(&quot;nv.sv.data&quot;, # Sys.Date(), # &quot;csv&quot;, # sep = &quot;.&quot;), # sep = &quot;&quot;) ,row.names = FALSE) "],["案例四机器学习.html", "Chapter 13 案例四、机器学习 13.1 训练普通话声调模型 13.2 训练泰语母语者声调模型 13.3 模拟普通话听者感知泰语声调 13.4 模拟泰语母语听者感知普通话声调", " Chapter 13 案例四、机器学习 详细背景请看原文献 13.1 训练普通话声调模型 # import data md_discrete = read.csv(&quot;data/ch13/md_discrete.csv&quot;) # Selecting features dataset_md = md_discrete[ , c(3, 4:9)] # scale the data dataset_md[,-1] = scale(dataset_md[-1]) dataset_md$tone = as.factor(dataset_md$tone) # Fitting classifier # model based on discrete features svm_md = svm(formula = tone ~ ., data = dataset_md, type = &#39;C-classification&#39;,#regression or classification kernel = &#39;radial&#39;, cost = &quot;2&quot;, cross = 10) # total accuracy # summary(svm_md) svm_md$tot.accuracy ## [1] 96.4775 # # model based on contour features # svm_contour = svm(formula = tone ~ ., # data = dataset_thai_8point, # type = &#39;C-classification&#39;,#regression or classification # kernel = &#39;radial&#39;, # cost = &quot;2&quot;, # cross = 10) # svm_contour$tot.accuracy # producing confusion matrix prediction_md &lt;- predict(svm_md, dataset_md) md_confusion = data.frame(pred = prediction_md, tone = md_discrete$tone) md_confusion_table = md_confusion%&gt;% group_by(tone,pred)%&gt;% summarize(n = n())%&gt;% group_by(tone)%&gt;% mutate(sum = sum(n), percent = round((n/sum)*100,2))%&gt;% select(tone,pred,percent)%&gt;% spread(tone, percent) ## `summarise()` has grouped output by &#39;tone&#39;. You can override using the ## `.groups` argument. md_confusion_table ## # A tibble: 4 × 5 ## pred M214 M35 M51 M55 ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 M214 96.1 NA NA NA ## 2 M35 3.91 100 NA 0.78 ## 3 M51 NA NA 98.4 NA ## 4 M55 NA NA 1.57 99.2 # write.csv(md_confusion_table, # file =&quot;data/processed/md_confusion_table.csv&quot;, # row.names = FALSE) md_plot = md_confusion%&gt;% group_by(pred, tone)%&gt;% summarise(n = n())%&gt;% group_by(tone)%&gt;% mutate(percent = n/sum(n), sum = sum(n))%&gt;% ggplot(aes(pred, tone))+ geom_tile(aes(fill = percent*100 ))+ geom_text(aes(label = round(percent*100, 1)), size = 4) + scale_x_discrete(name = &quot;Predictions&quot;, limits=c(&quot;M55&quot;,&quot;M35&quot;,&quot;M214&quot;,&quot;M51&quot;), labels=c(&quot;M55&quot;,&quot;M35&quot;,&quot;M214&quot;,&quot;M51&quot;))+ scale_y_discrete(name = &quot;Mandarin tones&quot;, limits=c(&quot;M55&quot;,&quot;M35&quot;,&quot;M214&quot;,&quot;M51&quot;), labels=c(&quot;M55&quot;,&quot;M35&quot;,&quot;M214&quot;,&quot;M51&quot;))+ scale_fill_gradient(name=&quot;Percentage (%)&quot;, low = &quot;white&quot;, high = &quot;blue&quot;) + theme(axis.text.x = element_text(face=&quot;bold&quot;, size=10), axis.text.y = element_text(face=&quot;bold&quot;, size=10), panel.background = element_blank()) ## `summarise()` has grouped output by &#39;pred&#39;. You can override using the ## `.groups` argument. md_plot # Print this our for publication # png(&quot;figure4.png&quot;, units=&quot;in&quot;, width=5, height=4, res=600) # md_plot # dev.off() 13.2 训练泰语母语者声调模型 # import data thai_discrete = read.csv(&quot;data/ch13/thai_discrete.csv&quot;) # Selecting features dataset_thai = thai_discrete[ , c(2, 6:11)] # scale the data dataset_thai[,-1] = scale(dataset_thai[-1]) # Fitting classifier # model based on discrete features svm_thai = svm(formula = tone ~ ., data = dataset_thai, type = &#39;C-classification&#39;,#regression or classification kernel = &#39;radial&#39;, cost = &quot;2&quot;, cross = 10) # total accuracy # summary(svm_thai) svm_thai$tot.accuracy ## [1] 91.86047 检测泰语母语者声调模型的正确率。 # confusion matrix prediction &lt;- predict(svm_thai, dataset_thai) thai_confusion = data.frame(pred = prediction, tone = thai_discrete$tone) thai_confusion_table = thai_confusion%&gt;% group_by(tone,pred)%&gt;% summarize(n = n())%&gt;% group_by(tone)%&gt;% mutate(sum = sum(n), percent = round((n/sum)*100,2))%&gt;% select(tone,pred,percent)%&gt;% spread(tone, percent) ## `summarise()` has grouped output by &#39;tone&#39;. You can override using the ## `.groups` argument. thai_confusion$tone = as.factor(thai_confusion$tone) # write.csv(thai_confusion_table, # file = &quot;data/processed/thai_confusion_table &quot;, # row.names = FALSE) thai_plot = thai_confusion%&gt;% group_by(pred, tone)%&gt;% summarise(n = n())%&gt;% group_by(tone)%&gt;% mutate(percent = n/sum(n), sum = sum(n))%&gt;% ggplot(aes(pred, tone))+ geom_tile(aes(fill = percent*100 ))+ geom_text(aes(label = round(percent*100, 1)), size = 4)+ scale_x_discrete(name = &quot;Predictions&quot;, limits=c(&quot;21&quot;,&quot;33&quot;,&quot;45&quot;,&quot;315&quot;,&quot;241&quot;), labels=c(&quot;T21&quot;, &quot;T33&quot;, &quot;T45&quot;,&quot;T315&quot;,&quot;T241&quot;))+ scale_y_discrete(name = &quot;Thai tones&quot;, limits=c(&quot;21&quot;,&quot;33&quot;,&quot;45&quot;,&quot;315&quot;,&quot;241&quot;), labels=c(&quot;T21&quot;, &quot;T33&quot;, &quot;T45&quot;,&quot;T315&quot;,&quot;T241&quot;))+ scale_fill_gradient(name=&quot;Percentage (%)&quot;, low = &quot;white&quot;, high = &quot;red&quot;) + theme(axis.text.x = element_text(face=&quot;bold&quot;, size=10), axis.text.y = element_text(face=&quot;bold&quot;, size=10), panel.background = element_blank()) ## `summarise()` has grouped output by &#39;pred&#39;. You can override using the ## `.groups` argument. thai_plot # Print this our for publication # png(&quot;thai_tones.png&quot;, units=&quot;in&quot;, width=5, height=4, res=600) # thai_plot # dev.off() 13.3 模拟普通话听者感知泰语声调 # mandarin listeners percieve Thai tones prediction_md_thai &lt;- predict(svm_md, dataset_thai) table( prediction_md_thai, thai_discrete$tone) ## ## prediction_md_thai 21 33 45 241 315 ## M214 65 26 0 0 21 ## M35 0 3 55 1 61 ## M51 20 22 7 79 4 ## M55 1 35 24 6 0 # SVM assimilation table md.svm.assim = data.frame(pred = prediction_md_thai, tone = thai_discrete$tone)%&gt;% group_by(pred, tone)%&gt;% summarise(n = n())%&gt;% group_by(tone)%&gt;% mutate(percent = round((n/sum(n)),3)*100, sum = sum(n)) ## `summarise()` has grouped output by &#39;pred&#39;. You can override using the ## `.groups` argument. md.svm.assim$pred = factor(md.svm.assim$pred, c(&quot;M55&quot;,&quot;M35&quot;,&quot;M214&quot;,&quot;M51&quot;)) md.svm.assim$tone = factor(md.svm.assim$tone,c(&quot;45&quot;,&quot;33&quot;,&quot;21&quot;,&quot;315&quot;,&quot;241&quot;)) # Stacked barplot md.svm.assim.stacked = ggplot(md.svm.assim, aes(fill=pred, y=percent, x=tone, label = percent)) + geom_bar( stat=&quot;identity&quot;)+ scale_fill_manual( values=c(&quot;M55&quot; = &quot;black&quot;, &quot;M35&quot;=&quot;gray25&quot;, &quot;M214&quot;=&quot;gray75&quot;, &quot;M51&quot;=&quot;white&quot;), name=&quot;Mandarin&quot;, breaks=c(&quot;M55&quot;, &quot;M35&quot;, &quot;M214&quot;,&quot;M51&quot;), labels=c(&quot;M55&quot;, &quot;M35&quot;, &quot;M214&quot;,&quot;M51&quot;))+ geom_bar(colour=&quot;black&quot;, stat=&quot;identity&quot;)+ xlab(&quot;Thai tones&quot;)+ ylab(&quot;Mandarin responses(%)&quot;) + scale_y_continuous(expand = c(0, 0), limits = c(0, 101))+ theme_classic()+ theme(legend.title = element_text(size=12, face=&quot;bold&quot;))+ theme(legend.text = element_text(size = 12, face = &quot;bold&quot;))+ theme(axis.text.x = element_text(face=&quot;bold&quot;, size=10))+ scale_x_discrete(breaks = c(&quot;45&quot;, &quot;33&quot;, &quot;21&quot;,&quot;315&quot;,&quot;241&quot;), labels=c(&quot;T45&quot;, &quot;T33&quot;, &quot;T21&quot;,&quot;T315&quot;,&quot;T241&quot;))+ geom_text(size = 4, position = position_stack(vjust = 0.5),color=&quot;blue&quot;) md.svm.assim.stacked # png(&quot;figure/md.svm.assim.stacked .png&quot;, # units=&quot;in&quot;, width=5, height=4, res=600) # md.svm.assim.stacked # dev.off() # heat map md.svm.assim.heat = md.svm.assim%&gt;% filter(percent&gt;10)%&gt;% ggplot(aes(tone, pred))+ geom_tile(aes(fill = percent ))+ geom_text(aes(label = percent)) + scale_x_discrete(name = &quot;Thai stimuli&quot;, limits=c(&quot;45&quot;,&quot;33&quot;,&quot;21&quot;,&quot;315&quot;,&quot;241&quot;), labels=c(&quot;T45&quot;,&quot;T33&quot;,&quot;T21&quot;,&quot;T315&quot;,&quot;T241&quot;))+ scale_y_discrete(name = &quot;Predicted responses&quot;, limits=c(&quot;M51&quot;,&quot;M214&quot;,&quot;M35&quot;,&quot;M55&quot;), labels=c(&quot;M51&quot;,&quot;M214&quot;,&quot;M35&quot;,&quot;M55&quot;))+ scale_fill_gradient(name=&quot;Percentage (%)&quot;, low = &quot;white&quot;, high = &quot;gray&quot;) + theme(axis.text.x = element_text(face=&quot;bold&quot;, size=10), axis.text.y = element_text(face=&quot;bold&quot;, size=10), panel.background = element_blank())+ theme(legend.position=&quot;none&quot;) md.svm.assim.heat final.cm = read.csv(file = &quot;data/ch13/final.cm.csv&quot;) final.cm$stimuli = as.factor(final.cm$stimuli) md.human.assim.heat = final.cm%&gt;% group_by(stimuli, response)%&gt;% filter(subject !=&quot;106&quot;)%&gt;% summarise(cat.mean = round ((sum(percentage)/12)*100, 1))%&gt;% filter(cat.mean &gt;10)%&gt;% ggplot(aes(stimuli, response))+ geom_tile(aes(fill = cat.mean ))+ geom_text(aes(label = cat.mean)) + scale_x_discrete(name = &quot;Thai stimuli&quot;, limits=c(&quot;45&quot;,&quot;33&quot;,&quot;21&quot;,&quot;315&quot;,&quot;241&quot;), labels=c(&quot;T45&quot;,&quot;T33&quot;,&quot;T21&quot;,&quot;T315&quot;,&quot;T241&quot;))+ scale_y_discrete(name = &quot;Mandarin listeners&#39; responses&quot;, limits=c(&quot;M51&quot;,&quot;M214&quot;,&quot;M35&quot;,&quot;M55&quot;), labels=c(&quot;M51&quot;,&quot;M214&quot;,&quot;M35&quot;,&quot;M55&quot;))+ scale_fill_gradient(name=&quot;Percentage (%)&quot;, low = &quot;white&quot;, high = &quot;gray&quot;) + theme(axis.text.x = element_text(face=&quot;bold&quot;, size=10), axis.text.y = element_text(face=&quot;bold&quot;, size=10), panel.background = element_blank()) ## `summarise()` has grouped output by &#39;stimuli&#39;. You can override using the ## `.groups` argument. md.human.assim.heat md_compare = plot_grid(md.svm.assim.heat, md.human.assim.heat, nrow=1, labels=c(&#39;A&#39;, &#39;B&#39;), rel_widths = c(1, 1.4) ) #Or labels=&quot;AUTO&quot; md_compare # png(&quot;md_compare.png&quot;, units=&quot;in&quot;, width=8, height=3, res=600) # md_compare # dev.off() 13.4 模拟泰语母语听者感知普通话声调 # thai listeners percieve mandarin tones prediction_thai_md &lt;- predict(svm_thai, dataset_md) table(prediction_thai_md, md_discrete$tone) ## ## prediction_thai_md M214 M35 M51 M55 ## 21 82 0 15 0 ## 33 6 2 7 41 ## 45 0 49 8 55 ## 241 5 4 91 32 ## 315 35 73 6 0 # set the order of thai tones thai.svm.assim = data.frame(pred = prediction_thai_md, tone = md_discrete$tone)%&gt;% group_by(pred, tone)%&gt;% summarise(n = n())%&gt;% group_by(tone)%&gt;% mutate(percent = round((n/sum(n)),3)*100, sum = sum(n)) ## `summarise()` has grouped output by &#39;pred&#39;. You can override using the ## `.groups` argument. thai.svm.assim$tone = factor(thai.svm.assim$tone, c(&quot;M55&quot;,&quot;M35&quot;,&quot;M214&quot;,&quot;M51&quot;)) thai.svm.assim$pred = factor(thai.svm.assim$pred, c(&quot;45&quot;,&quot;33&quot;,&quot;21&quot;,&quot;315&quot;,&quot;241&quot;)) thai.svm.assim.stacked = ggplot(thai.svm.assim, aes(fill=pred, y=percent, x=tone, label = percent)) + geom_bar( stat=&quot;identity&quot;)+ scale_fill_manual( values=c(&quot;45&quot; = &quot;black&quot;, &quot;33&quot;=&quot;gray25&quot;, &quot;21&quot;=&quot;gray50&quot;, &quot;315&quot;=&quot;gray75&quot;, &quot;241&quot;=&quot;white&quot;), name=&quot;Thai&quot;, breaks=c(&quot;45&quot;, &quot;33&quot;, &quot;21&quot;,&quot;315&quot;,&quot;241&quot;), labels=c(&quot;T45&quot;, &quot;T33&quot;, &quot;T21&quot;,&quot;T315&quot;,&quot;T241&quot;))+ geom_bar(colour=&quot;black&quot;, stat=&quot;identity&quot;)+ xlab(&quot;Mandarin tones&quot;)+ ylab(&quot;Thai responses(%)&quot;) + scale_y_continuous(expand = c(0, 0), limits = c(0, 100))+ theme_classic()+ theme(legend.title = element_text(size=12, face=&quot;bold&quot;))+ theme(legend.text = element_text(size = 12, face = &quot;bold&quot;))+ theme(axis.text.x = element_text(face=&quot;bold&quot;, size=10))+ scale_x_discrete(breaks = c(&quot;M55&quot;, &quot;M35&quot;, &quot;M214&quot;,&quot;M51&quot;), labels=c(&quot;M55&quot;, &quot;M35&quot;, &quot;M214&quot;,&quot;M51&quot;))+ geom_text(size = 4, position = position_stack(vjust = 0.5),color=&quot;blue&quot;) # Print this our for publication # png(&quot;figure3.png&quot;, units=&quot;in&quot;, width=5, height=4, res=600) # figure3 # dev.off() # svm predictions thai.svm.assim.heat = thai.svm.assim%&gt;% filter(percent&gt;10)%&gt;% ggplot(aes(tone, pred))+ geom_tile(aes(fill = percent ))+ geom_text(aes(label = percent))+ scale_fill_gradient(name=&quot;Percentage (%)&quot;, low = &quot;white&quot;, high = &quot;gray&quot;)+ theme(axis.text.x = element_text(face=&quot;bold&quot;, size=10), axis.text.y = element_text(face=&quot;bold&quot;, size=10), panel.background = element_blank())+ scale_x_discrete(name = &quot;Mandarin stimuli&quot;, breaks = c(&quot;M55&quot;, &quot;M35&quot;, &quot;M214&quot;,&quot;M51&quot;), labels=c(&quot;M55&quot;, &quot;M35&quot;, &quot;M214&quot;,&quot;M51&quot;))+ scale_y_discrete(name = &quot;Predicted responses&quot;, limits=c(&quot;241&quot;,&quot;315&quot;,&quot;21&quot;,&quot;33&quot;,&quot;45&quot;), labels=c(&quot;T241&quot;, &quot;T315&quot;, &quot;T21&quot;,&quot;T33&quot;,&quot;T45&quot;))+ theme(legend.position=&quot;none&quot;) thai.svm.assim.heat # human listener predictions thai_assm &lt;- read_csv(&quot;data/ch13/thai_assm.csv&quot;) ## Rows: 20 Columns: 3 ## ── Column specification ───────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (1): tone ## dbl (2): pred, percent ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. thai_assm$pred = as.character(thai_assm$pred) thai_assm$tone = factor(thai_assm$tone, c(&quot;M55&quot;,&quot;M35&quot;,&quot;M214&quot;,&quot;M51&quot;)) thai_assm$pred = factor(thai_assm$pred,c(&quot;45&quot;,&quot;33&quot;,&quot;21&quot;,&quot;315&quot;,&quot;241&quot;)) thai.human.assim.heat = thai_assm%&gt;% filter(percent&gt;10)%&gt;% ggplot(aes(tone, pred))+ geom_tile(aes(fill = percent ))+ geom_text(aes(label = percent))+ scale_fill_gradient(name=&quot;Percentage (%)&quot;, low = &quot;white&quot;, high = &quot;gray&quot;)+ theme(axis.text.x = element_text(face=&quot;bold&quot;, size=10), axis.text.y = element_text(face=&quot;bold&quot;, size=10), panel.background = element_blank())+ scale_x_discrete(name = &quot;Mandarin stimuli&quot;, breaks = c(&quot;M55&quot;, &quot;M35&quot;, &quot;M214&quot;,&quot;M51&quot;), labels=c(&quot;M55&quot;, &quot;M35&quot;, &quot;M214&quot;,&quot;M51&quot;))+ scale_y_discrete(name = &quot;Thai listners&#39; responses&quot;, limits=c(&quot;241&quot;,&quot;315&quot;,&quot;21&quot;,&quot;33&quot;,&quot;45&quot;), labels=c(&quot;T241&quot;, &quot;T315&quot;, &quot;T21&quot;,&quot;T33&quot;,&quot;T45&quot;)) thai_compare = plot_grid(thai.svm.assim.heat , thai.human.assim.heat, nrow=1, labels=c(&#39;A&#39;, &#39;B&#39;), rel_widths = c(1, 1.3)) thai_compare png(&quot;thai_compare.png&quot;, units=&quot;in&quot;, width=8, height=3, res=600) thai_compare dev.off() ## quartz_off_screen ## 2 "],["文献计量研究案例-语音感知.html", "Chapter 14 文献计量研究案例-语音感知 14.1 数据导入及整理 14.2 数据可视化与展示", " Chapter 14 文献计量研究案例-语音感知 详细背景请看原文献 首先，我们使用Web of Science核心合集进行了主题为“speech perception”（带引号）的搜索，搜索对象为社会科学引文索引（SSCI）、科学引文索引扩展版（SCIE）、新兴资源引文索引（ESCI）中发表的研究文章（文档类型=文章），搜索日期为2021年2月24日。时间跨度设定为2000年至2020年，非英语论文被排除。最初找到了9436篇研究文章。鉴于本次文献计量分析的重点是从语音学/语言学、心理学、神经科学和言语病理学的角度研究言语感知，因此排除了属于Web of Science分类中的耳鼻喉科的纯医学研究（n = 2731）。 这些文章的完整记录和被引用参考文献被下载并通过R语言中的bibliometrix包（Aria 和 Cuccurullo, 2017）进行处理。我们检查了数据集，并移除了数据缺失的文章，这进一步将研究文章的数量减少到6407篇（见图1）。bibliometrix包是用R语言开发的，提供了多种用于综合文献计量分析的功能，并且可以无缝集成其他R包，以实现更高级的数据建模和可视化。我们选择bibliometrix包而非其他软件，是因为它提供了一个更加开放、灵活、可定制且可重复的工作流程。 14.1 数据导入及整理 # read files filenames = list.files(path = &quot;data/ch14/data-24-02-2021&quot;, pattern = &quot;txt&quot;, full.names = TRUE) # converting to bibliometric data frame speech.data = convert2df(filenames, dbsource = &quot;wos&quot;, format = &quot;plaintext&quot;) ## ## Converting your wos collection into a bibliographic dataframe ## ## Done! ## ## ## Generating affiliation field tag AU_UN from C1: Done! # use only research articles speech.data = speech.data%&gt;% filter(PY != 2021 &amp; !is.na(PY))%&gt;% filter(DT == &quot;ARTICLE&quot;) speech.df = select(speech.data, &quot;AU&quot; , &quot;AF&quot; , &quot;CR&quot; , &quot;AB&quot; )%&gt;% mutate(AB = tolower(AB)) 14.2 数据可视化与展示 14.2.1 语音感知研究概况(2000-2020). Description Results MAIN INFORMATION ABOUT DATA Timespan 2000:2020 Sources (Journals, Books, etc) 725 Documents 6407 Annual Growth Rate % 6.11 Document Average Age 11.4 Average citations per doc 27.91 Average citations per year per doc 1.842 References 129988 DOCUMENT TYPES article 6407 DOCUMENT CONTENTS Keywords Plus (ID) 7243 Author’s Keywords (DE) 8001 AUTHORS Authors 12381 Author Appearances 23242 Authors of single-authored docs 438 AUTHORS COLLABORATION Single-authored docs 564 Documents per Author 0.517 Co-Authors per Doc 3.63 International co-authorships % 27.59 14.2.2 语音感知研究发表最多的杂志 Sources Articles JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA 443 JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH 360 FRONTIERS IN PSYCHOLOGY 232 PLOS ONE 190 NEUROIMAGE 155 BRAIN AND LANGUAGE 150 JOURNAL OF PHONETICS 145 NEUROPSYCHOLOGIA 132 COGNITION 131 JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE 100 JOURNAL OF NEUROSCIENCE 99 SPEECH COMMUNICATION 98 ATTENTION PERCEPTION &amp; PSYCHOPHYSICS 94 FRONTIERS IN HUMAN NEUROSCIENCE 82 JOURNAL OF MEMORY AND LANGUAGE 81 DEVELOPMENTAL SCIENCE 74 LANGUAGE AND SPEECH 74 PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA 74 CEREBRAL CORTEX 71 NEUROREPORT 70 14.2.3 研究能产性分析 14.2.4 语音感知研究产出量 (2000-2020). 14.2.5 语音感知研究数量最高的10个国家（地区） (2000-2020). SCP = 单一国家发表; MCP = 多个国家合作发表 Country Articles Freq SCP MCP MCP_Ratio USA 2444 0.38217 2074 370 0.151 UNITED KINGDOM 574 0.08976 405 169 0.294 CANADA 462 0.07224 306 156 0.338 GERMANY 399 0.06239 255 144 0.361 FRANCE 310 0.04848 163 147 0.474 NETHERLANDS 301 0.04707 187 114 0.379 CHINA 262 0.04097 151 111 0.424 AUSTRALIA 251 0.03925 160 91 0.363 JAPAN 161 0.02518 129 32 0.199 SPAIN 136 0.02127 73 63 0.463 FINLAND 131 0.02048 84 47 0.359 BELGIUM 107 0.01673 66 41 0.383 ITALY 92 0.01439 59 33 0.359 ISRAEL 79 0.01235 70 9 0.114 KOREA 77 0.01204 43 34 0.442 INDIA 63 0.00985 55 8 0.127 SWITZERLAND 56 0.00876 25 31 0.554 NORWAY 51 0.00797 30 21 0.412 BRAZIL 50 0.00782 44 6 0.120 SWEDEN 47 0.00735 33 14 0.298 14.2.6 发表量最大的10个国家发表趋势 14.2.7 语音感知领域发表量最高20位学者(2000-2020). Element h_index TC NP ACKERMANN H 18 1219 30 BIDELMAN GM 13 658 26 ESCUDERO P 14 660 31 HICKOK G 22 2002 30 HOLT LL 20 931 35 HUGDAHL K 21 1280 33 KRAUS N 29 3232 40 MCMURRAY B 21 1671 36 MCQUEEN JM 18 956 41 MITTERER H 22 1124 44 NITTROUER S 14 680 30 PISONI DB 23 1944 39 POEPPEL D 19 3503 28 ROSEN S 22 3177 41 SAMUEL AG 15 1159 28 SATO M 15 660 31 SCHWARTZ JL 15 787 34 SOTO-FARACO S 15 842 31 STEVENSON RA 18 1292 27 WERKER JF 23 2865 38 14.2.8 语音感知领域发表量最高20位学者每年发表和引用趋势(2000-2020). . TC = 所有发表. 圆圈大小代表发表数量；颜色深度表示引用数数量。 14.2.9 合作情况 语音感知研究中最活跃的20所大学/研究机构及其合作网络。网络中的每个节点代表一个不同的大学/研究机构，节点的直径与该机构与其他机构的合作强度成正比。节点之间的连线表示这些大学或研究机构之间的合作路径。 语音感知研究中前20个国家的合作网络。 网络中的每个节点代表一个不同的国家，节点的直径与该国家与其他国家合作的强度成正比。节点之间的连线表示国家之间的合作路径。 14.2.10 研究影响力 最高被引研究 Researcher Year source DOI Citations MCGURK H 1976 NATURE DOI 10.1038/264746A0 582 WERKER JF 1984 INFANT BEHAV DEV DOI 10.1016/S0163-6383(84)80022-3 498 SUMBY WH 1954 J ACOUST SOC AM DOI 10.1121/1.1907309 449 HICKOK G 2007 NAT REV NEUROSCI DOI 10.1038/NRN2113 441 LIBERMAN AM 1985 COGNITION DOI 10.1016/0010-0277(85)90021-6 438 MCCLELLAND JL 1986 COGNITIVE PSYCHOL DOI 10.1016/0010-0285(86)90015-0 397 OLDFIELD RC 1971 NEUROPSYCHOLOGIA DOI 10.1016/0028-3932(71)90067-4 389 LIBERMAN AM 1967 PSYCHOL REV DOI 10.1037/H0020279 328 SHANNON RV 1995 SCIENCE DOI 10.1126/SCIENCE.270.5234.303 305 KUHL PK 1992 SCIENCE DOI 10.1126/SCIENCE.1736364 298 GOLDINGER SD 1998 PSYCHOL REV DOI 10.1037/0033-295X.105.2.251 272 TALLAL P 1980 BRAIN LANG DOI 10.1016/0093-934X(80)90139-X 231 BEST C. 1995 SPEECH PERCEPTION LI NA 224 EIMAS PD 1971 SCIENCE DOI 10.1126/SCIENCE.171.3968.303 224 FLEGE J.E. 1995 SPEECH PERCEPTION LI NA 219 NORRIS D 2003 COGNITIVE PSYCHOL DOI 10.1016/S0010-0285(03)00006-9 215 BINDER JR 2000 CEREB CORTEX DOI 10.1093/CERCOR/10.5.512 213 HICKOK G 2004 COGNITION DOI 10.1016/J.COGNITION.2003.10.011 207 LISKER L 1964 WORD DOI 10.1080/00437956.1964.11659830 203 SCOTT SK 2000 BRAIN DOI 10.1093/BRAIN/123.12.2400 203 语音感知高被引作者 Authors Citations KUHL PK 1994 WERKER JF 1693 HICKOK G 1433 LIBERMAN AM 1347 NAATANEN R 1268 TALLAL P 1126 BOERSMA P 872 FLEGE JE 844 NITTROUER S 790 JUSCZYK PW 784 CUTLER A 759 ZATORRE RJ 758 BEST CT 726 NORRIS D 713 SCOTT SK 664 BRADLOW AR 653 FOWLER CA 634 PISONI DB 633 MCCLELLAND JL 631 BINDER JR 604 语音感知研究的共引网络。节点代表研究文章。每个节点的标签颜色与其所在的集群相同，节点的大小与其共引度成正比。 vertex cluster btw_centrality clos_centrality pagerank_centrality 1 mcgurk h 1976 1 15.2635617 0.0303030 0.0480495 3 sumby wh 1954 1 9.5227885 0.0303030 0.0420926 5 liberman am 1985-1 1 40.9724291 0.0303030 0.0334798 8 liberman am 1967 1 33.2167686 0.0303030 0.0276759 25 van wassenhove 2005 1 4.0447249 0.0303030 0.0244103 2 werker jf 1984-1 2 1.2448940 0.0238095 0.0714746 10 kuhl pk 1992-1 2 0.9467332 0.0238095 0.0526162 11 goldinger sd 1998-1 2 1.7304269 0.0238095 0.0270523 12 tallal p 1980-1 2 0.6760632 0.0232558 0.0090834 13 eimas pd 1971 2 0.7466488 0.0238095 0.0367231 14 best c. 1995-1 2 0.3031579 0.0238095 0.0290432 15 flege j.e. 1995 2 0.1627206 0.0227273 0.0288952 16 norris d 2003 2 1.6333429 0.0238095 0.0209435 19 lisker l 1964 2 0.9477373 0.0238095 0.0251291 20 peterson ge 1952 2 1.1605696 0.0238095 0.0206468 22 maye j 2002 2 0.2124056 0.0238095 0.0426923 23 saffran jr 1996-1 2 0.3801173 0.0238095 0.0302510 27 stager cl 1997 2 0.1064318 0.0232558 0.0327461 28 kuhl pk 2004-1 2 0.9889261 0.0238095 0.0278373 4 hickok g 2007-1 3 8.1022227 0.0256410 0.0622358 6 mcclelland jl 1986-1 3 20.3301412 0.0256410 0.0221149 7 oldfield rc 1971-1 3 3.6281583 0.0256410 0.0340063 9 shannon rv 1995 3 3.8120309 0.0256410 0.0204179 17 binder jr 2000-1 3 0.9234015 0.0256410 0.0371099 18 hickok g 2004 3 1.7757471 0.0256410 0.0388617 21 scott sk 2000 3 0.8692364 0.0250000 0.0369853 24 hickok g 2000-1 3 1.3611736 0.0256410 0.0360646 26 wilson sm 2004-1 3 2.5644671 0.0256410 0.0266347 29 poeppel d 2003 3 1.3686819 0.0250000 0.0235652 30 rauschecker jp 2009 3 1.0042912 0.0243902 0.0311617 语音感知研究的文献耦合网络，其中节点代表研究文章。每个节点的标签颜色与其所在的集群相同，节点的大小与其文献耦合度成正比。 vertex cluster btw_centrality clos_centrality pagerank_centrality 1 sato m, 2010-2 1 0.7164865 0.0222222 0.0422785 7 barnaud ml, 2018 1 2.9212251 0.0232558 0.0478014 9 treille a, 2018 1 1.0317870 0.0217391 0.0412177 10 schmitz j, 2018 1 3.8122417 0.0232558 0.0318383 11 laurent r, 2017 1 18.0738573 0.0243902 0.0499274 13 irwin j, 2017-3 1 6.2482815 0.0243902 0.0344240 21 sato m, 2013-1 1 5.5514049 0.0238095 0.0312268 23 grabski k, 2013-2 1 1.7199251 0.0222222 0.0511367 24 sanchez-garcia c, 2013 1 4.6155264 0.0243902 0.0291568 26 bernstein le, 2013 1 2.2834294 0.0227273 0.0248360 27 hickok g, 2012 1 3.3007337 0.0227273 0.0386245 29 tremblay p, 2011-1 1 0.6086756 0.0222222 0.0358885 30 hickok g, 2011-2 1 1.2554936 0.0222222 0.0429051 2 hawkins s, 2010 2 9.3703836 0.0263158 0.0239215 3 feldman nh, 2009 2 3.8011565 0.0232558 0.0258212 5 baese-berk mm, 2019-1 2 9.3727377 0.0263158 0.0207865 12 heald slm, 2017 2 11.2805244 0.0263158 0.0401531 14 blank h, 2016 2 4.0603971 0.0238095 0.0235782 15 fowler ca, 2016 2 8.9413695 0.0256410 0.0262904 16 christiansen mh, 2016 2 6.4460889 0.0256410 0.0307733 17 kleinschmidt df, 2015 2 7.8949937 0.0263158 0.0449141 19 heald slm, 2014-2 2 8.2948035 0.0263158 0.0367782 20 guediche s, 2014 2 6.5318437 0.0243902 0.0354950 4 werker jf, 2005 3 1.3277236 0.0217391 0.0310011 6 choi d, 2018 3 6.3736653 0.0285714 0.0271317 8 werker jf, 2018 3 1.1648052 0.0222222 0.0442706 18 kuhl pk, 2014 3 15.1309787 0.0277778 0.0193553 22 vouloumanos a, 2013 3 5.9773141 0.0285714 0.0219283 25 yeung hh, 2013-2 3 0.8147466 0.0212766 0.0247105 28 calabrese a, 2012 3 25.0774001 0.0285714 0.0218293 前20个作者定义关键词、机器生成关键词、基于标题和摘要的两词短语（Freq = 频率）注意：在论文表格中，一些术语进行了合并处理，例如在标题两词短语列中，“Cochlear implant”（人工耳蜗）和“cochlear implantation”（人工耳蜗植入）被合并。 AuthorKeywords AuFreq MachineKeywords MFreq Title2gram TFreq Abstract2gram ABFreq Cochlearimplant 251 Recognition 783 Cochlearimplant 408 Hearingloss 950 Fmri 199 Discrimination 746 Hearingloss 155 Normalhearing 840 Dyslexia 161 Children 653 Wordrecognition 132 Cochlearimplant 587 Speechproduction 158 Information 525 Audiovisualspeech 117 Speechsounds 587 Children 139 Noise 418 Spokenword 97 Auditorycortex 541 Hearingloss 129 Identification 396 Auditoryprocessing 93 Wordrecognition 535 Aging 116 Acquisition 378 Auditorycortex 91 Auditoryprocessing 515 Spokenwordrecognition 112 English 368 Visualspeech 91 Superiortemporal 509 Auditorycortex 104 Brain 363 Cochlearimplantation 87 Speechproduction 494 Phonology 101 Intelligibility 336 Implantusers 82 Visualspeech 465 Auditoryperception 98 Integration 326 Eventrelated 71 Speechprocessing 460 Auditoryprocessing 98 Infants 307 Speechprocessing 70 Speechrecognition 448 Languageacquisition 94 Adults 305 Developmentaldyslexia 64 Nativelanguage 439 Mismatchnegativity 93 Workingmemory 300 Normalhearing 64 Eventrelated 427 Bilingualism 90 Activation 296 Wordlearning 64 Cochlearimplant 409 Attention 85 Age 296 Languageimpairment 62 Acousticalsociety 399 Eeg 84 Comprehension 295 Speechrecognition 61 Ciusers 347 Eventrelatedpotentials 82 Hearing 294 Specificlanguage 60 Currentstudy 342 Audiovisual 80 Cortex 288 Audiovisual 58 Findingssuggest 314 Multisensoryintegration 80 Attention 285 Speechproduction 58 Phonologicalawareness 311 Development 78 Developmentaldyslexia 276 Verticalbar 56 Audiovisualspeech 305 Perceptuallearning 78 Auditorycortex 264 Fmristudy 53 Montholds 300 Auditory 75 Model 258 Individualdifferences 53 Speechintelligibility 293 Prosody 73 Sounds 251 Temporalprocessing 53 Speechsignal 289 作者自定义词网络 "],["实践案例-汉语失语症话语产出.html", "Chapter 15 实践案例 汉语失语症话语产出 15.1 研究背景 15.2 Jieba 分词 15.3 汉语失语症语料分词 15.4 计算词汇丰富度 15.5 提取核心词汇 15.6 比较核心词汇分数 15.7 核心词汇分数和词汇丰富度相关性分析", " Chapter 15 实践案例 汉语失语症话语产出 详细背景请看原文献 15.1 研究背景 口语话语产出越来越被视为评估失语症患者（PWA）语言能力的重要来源。如果有相关话语产出的转录本，一些语言学指标，如类型-标记比（TTR）或平均语句长度，可以自动化处理，以辅助PWA的话语分析。其他类型的指标，如主要概念（Dalton &amp; Richardson, 2015; Dalton &amp; Richardson, 2019; Kong, 2009; Nicholas &amp; Brookshire, 1995; Richardson &amp; Dalton, 2016; Richardson et al., 2021）、内容单元（Yorkston &amp; Beukelman, 1980）、正确信息单元（CIUs，Nicholas &amp; Brookshire, 1993）和主要事件（Capilouto et al., 2005），则需要经过训练的标注员进行主观判断。虽然这些指标在揭示PWA语言能力和缺陷的不同方面具有重要意义，但它们通常涉及到劳动密集且耗时的过程，如转录和标注，因此很少在临床实践中实时使用。因此，需要一种可以在临床环境中轻松应用的标准化和有参照的指标。 最近，核心词汇分析被开发并提出作为一种可行且易于使用的PWA评估方法（Dalton &amp; Richardson, 2015; Kim, Berube et al., 2022; Kim et al., 2019; Kim &amp; Wright, 2020）。核心词汇分析的基本假设是，通过一组典型词汇或核心词汇（MacWhinney et al., 2010），可以评估在话语产出任务中PWA的功能性沟通能力。基于健康控制组在特定任务中的产出生成的核心词汇列表可以作为指标，衡量PWA在该任务中检索词汇的能力。这种任务特定且有参照的核心词汇列表在临床环境中非常有用，因为临床医生可以通过实时检查该列表来评估PWA的口语话语产出。核心词汇列表已被证明在区分PWA与对照组以及失语症亚型方面有效（S. G. Dalton &amp; Richardson, 2015; Kim et al., 2021, 2019）。它们还与其他语言学指标（如正确信息单元、词汇多样性、句法复杂性（Kim &amp; Wright, 2020）、主要概念（Dalton &amp; Richardson, 2015）、主题单元和连贯性指标（Kim &amp; Wright, 2020））显著相关，显示出良好的同时效度。即使对于经验和训练时间非常有限的评分员来说，核心词汇列表也表现出了可接受的评分员间信度（Kim &amp; Wright, 2020）。因此，与大多数传统指标（如TTR）需要录音、转录和标注话语产出相比，核心词汇列表节省了时间，而且比其他需要长期训练且难以维持评分员一致性的指标（如主要概念）更为客观。 到目前为止，关于普通话失语症患者（PWA）话语产出的核心词汇研究仅有一项。江及其同事使用普通话失语症语料库数据（Jiang et al., 2023），为三种不同的任务类型（即图片描述、故事叙述和程序性话语）开发了核心名词和动词列表。研究发现，PWA产生的核心词汇少于对照组参与者，但核心词汇的使用与失语症的严重程度之间没有相关性。作为该领域的开创性工作，他们的研究总体上支持了核心词汇分析在评估普通话口语话语产出中的可行性和适用性。然而，核心词汇评分是否以及如何与其他语言学指标（如词汇多样性）以及话语信息性指标（如正确信息单元，Nicholas &amp; Brookshire, 1993）相关，仍然未得到解决。 从方法论上讲，江等人（2023）研究中高频词被提取为核心词汇，但如果某个特定参与者频繁使用某个单词，这可能会导致偏差。此外，在计算核心词汇评分时，特定任务类型中的任务被合并。例如，在他们的研究中，“破窗事件”、“拒绝的雨伞”、“营救小猫”和“洪水事件”被组合为图片描述任务，而“龟兔赛跑”和“狼来了”则作为故事叙述任务的一部分。然而，考虑到核心词汇列表不仅是任务特定的，而且对引发材料敏感，不同具体任务之间可能存在重要的差异。此外，江及其同事并未将功能词纳入其核心词汇列表中，而这些词已被证明与普通话PWA的语言产出相关（Wang et al., 2019）。 因此，本研究报告了我们针对每个具体任务开发的核心词汇列表，包括内容词和功能词，并使用普通话失语症语料库中的PWA数据。此外，我们假设核心词汇评分评估了词汇层面的语言产出能力和话语信息性。通过对核心词汇评分、词汇多样性指标和CIU进行相关性分析，我们检验了这些假设。 library(tidyverse) library(tidytext) library(quanteda) library(stringr) library(jiebaR) library(readtext) library(rstatix) # for cleaning up stats library(broom) # calculate confidence intervals library(rcompanion) library(cowplot) library(flextable) # remove scientific notation options(scipen=999) # add r values in regression lines library(ggpubr) # show chinese characters in ggplot library(showtext) showtext_auto() #filter function `%!in%` &lt;- Negate(`%in%`) setwd(&quot;~/Nutstore Files/310_Tutorial/LanguageDS-e&quot;) 15.2 Jieba 分词 text = &quot;口语话语产出越来越被视为评估失语症患者（PWA）语言能力的重要来源。&quot; # 创建一个默认的分词器 seg1 &lt;- worker() # 使用seg1进行分词 segment(text, seg1) ## [1] &quot;口语&quot; &quot;话语&quot; &quot;产出&quot; &quot;越来越&quot; &quot;被&quot; &quot;视为&quot; &quot;评估&quot; &quot;失语症&quot; ## [9] &quot;患者&quot; &quot;PWA&quot; &quot;语言&quot; &quot;能力&quot; &quot;的&quot; &quot;重要&quot; &quot;来源&quot; # # seg3 &lt;- worker(user = &quot;demo_data/dict-ch-user-demo.txt&quot;, #设置自定义词典 # # 设置停用词 # stop_word = &quot;demo_data/stopwords-ch-demo.txt&quot;) # # segment(text, seg3) 15.3 汉语失语症语料分词 # 导入被试信息 subjects_all &lt;- read_csv(&quot;data/ch15/subjects.all4corelexV2.csv&quot;, na = &quot;NA&quot;) ## 导入语料 df.clean &lt;- read_csv(&quot;data/ch15/df.all.clean.2022-10-05.csv&quot;)%&gt;% mutate(subject = dplyr::recode(subject,&quot;/JiangLin40a2.cha&quot;=&quot;/JiangLin40a.cha&quot;, &quot;/JiangLin40a1.cha&quot;=&quot;/JiangLin40a.cha&quot;, &quot;/JiangLin01a2.cha&quot;=&quot;/JiangLin01a.cha&quot;, &quot;/JiangLin01a1.cha&quot;=&quot;/JiangLin01a.cha&quot;, &quot;/JiangLin70a1.cha&quot;=&quot;/JiangLin70a.cha&quot;, &quot;/JiangLin70a2.cha&quot;=&quot;/JiangLin70a.cha&quot;, &quot;/JiangLin08a2.cha&quot;= &quot;/JiangLin08a.cha&quot;, &quot;/JiangLin08a1.cha&quot;= &quot;/JiangLin08a.cha&quot;))%&gt;% filter(!is.na(task))%&gt;% mutate(subject = str_remove(subject,&quot;\\\\/&quot;), subject = str_remove(subject,&quot;.cha&quot;))%&gt;% left_join(subjects_all)%&gt;% mutate(normative = as.character(normative))%&gt;% filter(normative != &quot;0&quot;)%&gt;% filter(include == &quot;Y&quot;)%&gt;% select(-Onset_Date, -Video_Date, -Informed_Consent) ## 批量分词 my_seg &lt;- worker(bylines = T, #user = &quot;demo_data/dict-ch-user-demo.txt&quot;, symbol=T) df.tokenised = df.clean%&gt;% mutate(clean = str_replace_all(clean_new, c(&quot; 一 个 &quot; = &quot; 一个 &quot;, &quot; 一 条 &quot; = &quot;一条&quot;,&quot; 一 场 &quot; = &quot; 一场 &quot;, &quot; 一 把 &quot; = &quot; 一把 &quot;, &quot; 一 群 &quot; = &quot; 一群 &quot;, &quot; 一 次 &quot; = &quot; 一次 &quot;, &quot; 一 辆 &quot; = &quot; 一辆 &quot;, &quot; 一 只 &quot; = &quot; 一只 &quot;, &quot; 一 天 &quot; = &quot; 一天 &quot;, &quot; 一 下 &quot; = &quot; 一下 &quot;, &quot; 一 张 &quot; = &quot; 一张 &quot;, &quot; 一 道 &quot; = &quot; 一道 &quot;, &quot; 一 起 &quot; = &quot; 一起 &quot;,&quot; 一 步 &quot; = &quot; 一步 &quot;,&quot; 一 看 &quot; = &quot; 一看 &quot;, &quot; 一 匹 &quot; = &quot; 一匹 &quot;,&quot; 一 觉 &quot; = &quot; 一觉 &quot;,&quot; 一 件 &quot; = &quot; 一件 &quot;, &quot;一 位&quot; = &quot;一位&quot;,&quot;一 架&quot; = &quot;一架&quot;,&quot;一 项&quot; = &quot;一项&quot;, &quot; 发 洪水 &quot; = &quot; 发洪水 &quot;,&quot; 发 大水 &quot; = &quot; 发大水 &quot;, &quot; 一 队 &quot; = &quot; 一队 &quot;)))%&gt;% # 分词 unnest_tokens(word, ## new tokens unnested clean, ## original larger units token = function(x) ## self-defined tokenization method segment(x, jiebar = my_seg) )%&gt;% #filter non-words filter(str_detect(word, &quot;\\\\w&quot;))%&gt;% #filter english words filter(!str_detect(word, &quot;[a-zA-Z]&quot;))%&gt;% filter(word !=&quot;_&quot;)%&gt;% mutate(task = dplyr::recode(task, &quot;@task2&quot;=&quot;Pic-Window&quot;,&quot;@task3&quot;=&quot;Pic-Umbrella&quot;, &quot;@task4&quot;=&quot;Pic-CatRescue&quot;,&quot;@task5&quot;=&quot;Pic-Flood&quot;, &quot;@task6&quot;=&quot;S-TortioseHare&quot;, &quot;@task7&quot;=&quot;S-CryWolf&quot;,&quot;@task8&quot;=&quot;Proc-FriedRice&quot;))%&gt;% filter(task %!in% c(&quot;@task1&quot;, &quot;@task10&quot;, &quot;@task11&quot;, &quot;@task9&quot;)) ## 计算被试年龄和教育程度 age.aq.edu.stroke = df.tokenised%&gt;% select(subject, Age, Gender, group, normative, Education_Level, PostOnsetMonth, Aphasia_Type, AQ)%&gt;% distinct()%&gt;% mutate(AQ = as.numeric(AQ))%&gt;% group_by( normative)%&gt;% summarise(n = n(), mean.age = round(mean(Age),1), max.age = round(max(Age),1), min.age = round(min(Age),1), sd.age = round(sd(Age),1), mean.edu = round(mean(Education_Level, na.rm = TRUE),1), sd.edu = round(sd(Education_Level, na.rm = TRUE),1), max.edu= round(max(Education_Level, na.rm = TRUE),1), min.edu = round(min(Education_Level, na.rm = TRUE),1), mean.AQ = round(mean(AQ, na.rm = TRUE),1), sd.AQ = round(sd(AQ, na.rm = TRUE),1), max.AQ= round(max(AQ, na.rm = TRUE),1), min.AQ = round(min(AQ, na.rm = TRUE),1), mean.stroke = round(mean(PostOnsetMonth, na.rm = TRUE),1), sd.stroke = round(sd(PostOnsetMonth, na.rm = TRUE),1)) ## 被试年龄和教育程度统计分析 age.aq.edu.stroke.t.test = df.tokenised%&gt;% select(subject, Age, Gender, group, normative, Education_Level, Aphasia_Type)%&gt;% distinct()%&gt;% gather(measures, values, c(&quot;Age&quot;, &quot;Education_Level&quot;))%&gt;% filter(normative %in%c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;))%&gt;% group_by(measures)%&gt;% rstatix::t_test(values~ normative) age.aq.edu.stroke%&gt;% filter(normative != &quot;4&quot;)%&gt;% flextable()%&gt;% set_caption(caption = &quot;Table 1 Demographic information for all individuals. &quot;) .cl-64161270{}.cl-640cc21a{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-6410ce32{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-6410ce46{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-6410e55c{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6410e570{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6410e571{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6410e57a{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6410e584{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6410e585{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 15.1: Table 1 Demographic information for all individuals. normativenmean.agemax.agemin.agesd.agemean.edusd.edumax.edumin.edumean.AQsd.AQmax.AQmin.AQmean.strokesd.stroke14343.1702216.212.64.420699.01.0100.095.40.00.021847.9672812.712.83.120998.91.2100.095.30.00.031844.6672313.314.25.932578.412.092.954.06.35.8 age.aq.edu.stroke.t.test%&gt;% flextable()%&gt;% set_caption(caption = &quot;Table 2. Statistical tests of age and years of education among three groups.&quot;) .cl-64569e4e{}.cl-644dc22e{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-6451801c{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-64518030{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-64519318{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-64519322{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6451932c{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6451932d{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-64519336{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-64519337{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 15.1: Table 2. Statistical tests of age and years of education among three groups. measures.y.group1group2n1n2statisticdfpp.adjp.adj.signifAgevalues124318-1.241864240.419890.2210.663nsAgevalues134318-0.360084938.629650.7210.882nsAgevalues2318180.780464533.929230.4410.882nsEducation_Levelvalues124318-0.224318444.353950.8240.948nsEducation_Levelvalues134318-1.023219225.229150.3160.948nsEducation_Levelvalues231818-0.861366325.852690.3970.948ns 15.4 计算词汇丰富度 chinese.TTR = df.tokenised%&gt;% mutate(word2 = dplyr::recode(word, #task 2 &quot;电视机&quot;=&quot;电视&quot;,&quot;窗&quot;=&quot;窗户&quot;,&quot;电视机&quot;=&quot;电视&quot;, &quot;男孩&quot;=&quot;小孩&quot;,&quot;小朋友&quot;=&quot;小孩&quot;,&quot;足球&quot;=&quot;球&quot;, #task3 &quot;雨伞&quot;=&quot;伞&quot;,&quot;孩子&quot;=&quot;小孩&quot;,&quot;小孩子&quot;=&quot;小孩&quot;, &quot;母亲&quot;=&quot;妈妈&quot;,&quot;电视机&quot;=&quot;电视&quot;,&quot;电视机&quot;=&quot;电视&quot;, #task4 &quot;女孩&quot;=&quot;小孩&quot;,&quot;女儿&quot;=&quot;小孩&quot;,&quot;孩子&quot;=&quot;小孩&quot;, &quot;父亲&quot;=&quot;爸爸&quot;,&quot;车子&quot;=&quot;消防车&quot;,&quot;电视机&quot;=&quot;电视&quot;, #task5 &quot;大水&quot;=&quot;洪水&quot;,&quot;女&quot;=&quot;小孩&quot;,&quot;消防员&quot;=&quot;战士&quot;,&quot;发大水&quot;=&quot;发洪水&quot;, &quot;解放军&quot;=&quot;战士&quot;,&quot;电视机&quot;=&quot;电视&quot;,&quot;电视机&quot;=&quot;电视&quot;, #task 6 &quot;兔&quot;=&quot;兔子&quot;,&quot;龟&quot;=&quot;乌龟&quot;,&quot;白兔&quot;=&quot;兔子&quot;, #task 7 &quot;孩子&quot;=&quot;小孩&quot;,&quot;农民&quot;=&quot;村民&quot;,&quot;电视机&quot;=&quot;电视&quot; ))%&gt;% select(subject, normative, group, task, word2)%&gt;% mutate(token = 1, character = nchar(word2))%&gt;% group_by(subject, normative, task)%&gt;% summarise(token = sum(token), character = sum(character), type = n_distinct(word2), ttr = type/token, c = log(type)/log(token), r = type/sqrt(token))%&gt;% filter(normative %in% c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;))%&gt;% group_by(normative, task)%&gt;% get_summary_stats(token, type, character, ttr,c,r, type = &quot;mean_sd&quot;)%&gt;% select(-n)%&gt;% gather(stats, value, -(normative:variable))%&gt;% mutate(value = round(value, 1))%&gt;% unite(temp, variable, stats)%&gt;% spread(temp, value)%&gt;% select( &quot;task&quot;, &quot;normative&quot;,&quot;character_mean&quot;, &quot;character_sd&quot;, &quot;type_mean&quot;, &quot;type_sd&quot;, &quot;token_mean&quot;, &quot;token_sd&quot;, &quot;ttr_mean&quot;, &quot;ttr_sd&quot;, &quot;c_mean&quot;, &quot;c_sd&quot;, &quot;r_mean&quot;, &quot;r_sd&quot;) chinese.TTR.test = df.tokenised%&gt;% mutate(word2 = dplyr::recode(word, #task 2 &quot;电视机&quot;=&quot;电视&quot;,&quot;窗&quot;=&quot;窗户&quot;,&quot;电视机&quot;=&quot;电视&quot;, &quot;男孩&quot;=&quot;小孩&quot;,&quot;小朋友&quot;=&quot;小孩&quot;,&quot;足球&quot;=&quot;球&quot;, #task3 &quot;雨伞&quot;=&quot;伞&quot;,&quot;孩子&quot;=&quot;小孩&quot;,&quot;小孩子&quot;=&quot;小孩&quot;, &quot;母亲&quot;=&quot;妈妈&quot;,&quot;电视机&quot;=&quot;电视&quot;,&quot;电视机&quot;=&quot;电视&quot;, #task4 &quot;女孩&quot;=&quot;小孩&quot;,&quot;女儿&quot;=&quot;小孩&quot;,&quot;孩子&quot;=&quot;小孩&quot;, &quot;父亲&quot;=&quot;爸爸&quot;,&quot;车子&quot;=&quot;消防车&quot;,&quot;电视机&quot;=&quot;电视&quot;, #task5 &quot;大水&quot;=&quot;洪水&quot;,&quot;女&quot;=&quot;小孩&quot;,&quot;消防员&quot;=&quot;战士&quot;,&quot;发大水&quot;=&quot;发洪水&quot;, &quot;解放军&quot;=&quot;战士&quot;,&quot;电视机&quot;=&quot;电视&quot;,&quot;电视机&quot;=&quot;电视&quot;, #task 6 &quot;兔&quot;=&quot;兔子&quot;,&quot;龟&quot;=&quot;乌龟&quot;,&quot;白兔&quot;=&quot;兔子&quot;, #task 7 &quot;孩子&quot;=&quot;小孩&quot;,&quot;农民&quot;=&quot;村民&quot;,&quot;电视机&quot;=&quot;电视&quot; ))%&gt;% select(subject, normative, group, task, word2)%&gt;% mutate(token = 1, character = nchar(word2))%&gt;% group_by(subject, normative, task)%&gt;% summarise(token = sum(token), character = sum(character), type = n_distinct(word2), ttr = type/token, c = log(type)/log(token), r = type/sqrt(token))%&gt;% #filter(normative%in%c(&quot;2&quot;))%&gt;% #group_by(normative, task)%&gt;% gather(measures, values, c(&quot;token&quot;, &quot;character&quot;,&quot;type&quot;,&quot;ttr&quot;,&quot;c&quot;,&quot;r&quot;))%&gt;% filter(normative %in% c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;))%&gt;% group_by(measures, task)%&gt;% rstatix::wilcox_test(values~ normative)%&gt;% mutate(p.adj = round(p.adj,4))%&gt;% select(-p) chinese.TTR%&gt;% filter(normative != &quot;4&quot;)%&gt;% select(-c(&quot;ttr_mean&quot;,&quot;ttr_sd&quot;,&quot;c_mean&quot;,&quot;c_sd&quot;,&quot;r_mean&quot;,&quot;r_sd&quot;))%&gt;% arrange(task)%&gt;% flextable()%&gt;% set_caption(caption = &quot;Table 3. Number of characters, word types, and tokens for each task and each group. &quot;) .cl-69c9d76a{}.cl-69c04c36{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-69c41a1e{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-69c41a32{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-69c42f72{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-69c42f86{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-69c42f87{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-69c42f90{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-69c42f9a{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-69c42fa4{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 15.2: Table 3. Number of characters, word types, and tokens for each task and each group. tasknormativecharacter_meancharacter_sdtype_meantype_sdtoken_meantoken_sdPic-CatRescue1156.895.759.222.6115.368.1Pic-CatRescue2148.564.259.218.1109.645.9Pic-CatRescue383.854.535.116.666.745.1Pic-Flood1108.080.844.222.973.554.3Pic-Flood299.867.841.319.067.944.4Pic-Flood357.955.026.219.545.040.6Pic-Umbrella1142.484.255.923.8104.059.6Pic-Umbrella2131.647.353.314.699.032.7Pic-Umbrella376.841.232.313.959.533.5Pic-Window1120.497.847.624.187.269.6Pic-Window2120.364.548.314.187.746.4Pic-Window353.032.124.310.540.124.5Proc-FriedRice1127.784.848.022.188.662.2Proc-FriedRice2119.760.047.618.083.541.5Proc-FriedRice352.134.423.714.139.226.8S-CryWolf1247.9168.480.437.4183.3122.6S-CryWolf2246.8126.278.729.7185.895.6S-CryWolf3100.676.838.624.076.460.1S-TortioseHare1256.4162.186.537.3176.5112.5S-TortioseHare2240.6113.284.729.9166.179.0S-TortioseHare3100.365.735.119.171.145.6 chinese.TTR.test%&gt;% filter(measures %!in% c(&quot;c&quot;,&quot;r&quot;,&quot;ttr&quot;))%&gt;% flextable()%&gt;% set_caption(caption = &quot;Table 4 Statistical comparisions of linguistic variables among normative, control and PWA goups.&quot;) .cl-6a185c64{}.cl-6a027e94{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-6a080b52{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-6a080b66{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-6a08240c{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6a082416{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6a082420{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6a08242a{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6a082434{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6a082435{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 15.2: Table 4 Statistical comparisions of linguistic variables among normative, control and PWA goups. taskmeasures.y.group1group2n1n2statisticp.adjp.adj.signifPic-CatRescuecharactervalues124318350.50.5690nsPic-CatRescuecharactervalues134318617.00.0009***Pic-CatRescuecharactervalues231818258.50.0050**Pic-Floodcharactervalues124318382.50.9500nsPic-Floodcharactervalues134318597.50.0030**Pic-Floodcharactervalues231818247.00.0150*Pic-Umbrellacharactervalues124318340.00.4620nsPic-Umbrellacharactervalues134317603.50.0003***Pic-Umbrellacharactervalues231817255.00.0020**Pic-Windowcharactervalues124318348.00.5430nsPic-Windowcharactervalues134318658.00.0001****Pic-Windowcharactervalues231818282.00.0003***Proc-FriedRicecharactervalues124318394.50.9120nsProc-FriedRicecharactervalues134318666.00.0000****Proc-FriedRicecharactervalues231818275.00.0007***S-CryWolfcharactervalues124318351.00.5750nsS-CryWolfcharactervalues134318633.50.0003***S-CryWolfcharactervalues231818272.00.0010**S-TortioseHarecharactervalues124318381.00.9310nsS-TortioseHarecharactervalues134318684.00.0000****S-TortioseHarecharactervalues231818274.00.0004***Pic-CatRescuetokenvalues124318358.00.6520nsPic-CatRescuetokenvalues134318589.50.0040**Pic-CatRescuetokenvalues231818250.00.0110*Pic-Floodtokenvalues124318384.50.9750nsPic-Floodtokenvalues134318559.00.0200*Pic-Floodtokenvalues231818233.50.0490*Pic-Umbrellatokenvalues124318335.50.4200nsPic-Umbrellatokenvalues134317589.00.0008***Pic-Umbrellatokenvalues231817256.50.0010**Pic-Windowtokenvalues124318345.50.5170nsPic-Windowtokenvalues134318654.00.0001****Pic-Windowtokenvalues231818280.50.0004***Proc-FriedRicetokenvalues124318387.51.0000nsProc-FriedRicetokenvalues134318633.50.0003***Proc-FriedRicetokenvalues231818266.50.0020**S-CryWolftokenvalues124318349.00.5530nsS-CryWolftokenvalues134318634.00.0003***S-CryWolftokenvalues231818265.50.0020**S-TortioseHaretokenvalues124318378.50.8990nsS-TortioseHaretokenvalues134318672.00.0000****S-TortioseHaretokenvalues231818274.00.0008***Pic-CatRescuetypevalues124318334.50.4110nsPic-CatRescuetypevalues134318647.00.0001***Pic-CatRescuetypevalues231818269.00.0010**Pic-Floodtypevalues124318397.00.8810nsPic-Floodtypevalues134318613.50.0010**Pic-Floodtypevalues231818250.00.0110*Pic-Umbrellatypevalues124318368.00.7700nsPic-Umbrellatypevalues134317616.00.0001***Pic-Umbrellatypevalues231817263.00.0006***Pic-Windowtypevalues124318321.00.3000nsPic-Windowtypevalues134318693.00.0000****Pic-Windowtypevalues231818303.00.0000****Proc-FriedRicetypevalues124318381.50.9370nsProc-FriedRicetypevalues134318651.00.0001****Proc-FriedRicetypevalues231818278.00.0005***S-CryWolftypevalues124318364.50.7280nsS-CryWolftypevalues134318649.00.0001***S-CryWolftypevalues231818273.50.0009***S-TortioseHaretypevalues124318364.50.7280nsS-TortioseHaretypevalues134318727.50.0000****S-TortioseHaretypevalues231818293.50.0001**** 15.5 提取核心词汇 core.lex.raw = df.tokenised%&gt;% filter(normative == &quot;1&quot;)%&gt;% ## filter some functional words # anti_join(fWord)%&gt;% #merge some words mutate(word2 = dplyr::recode(word, #task 2 &quot;电视机&quot;=&quot;电视&quot;,&quot;窗&quot;=&quot;窗户&quot;,&quot;电视机&quot;=&quot;电视&quot;, &quot;男孩&quot;=&quot;小孩&quot;,&quot;小朋友&quot;=&quot;小孩&quot;,&quot;足球&quot;=&quot;球&quot;, #task3 &quot;雨伞&quot;=&quot;伞&quot;,&quot;孩子&quot;=&quot;小孩&quot;,&quot;小孩子&quot;=&quot;小孩&quot;, &quot;母亲&quot;=&quot;妈妈&quot;,&quot;电视机&quot;=&quot;电视&quot;,&quot;电视机&quot;=&quot;电视&quot;, #task4 &quot;女孩&quot;=&quot;小孩&quot;,&quot;女儿&quot;=&quot;小孩&quot;,&quot;孩子&quot;=&quot;小孩&quot;, &quot;父亲&quot;=&quot;爸爸&quot;,&quot;车子&quot;=&quot;消防车&quot;,&quot;电视机&quot;=&quot;电视&quot;, #task5 &quot;大水&quot;=&quot;洪水&quot;,&quot;女&quot;=&quot;小孩&quot;,&quot;消防员&quot;=&quot;战士&quot;, &quot;发大水&quot;=&quot;发洪水&quot;, &quot;解放军&quot;=&quot;战士&quot;,&quot;电视机&quot;=&quot;电视&quot;,&quot;电视机&quot;=&quot;电视&quot;, #task 6 &quot;兔&quot;=&quot;兔子&quot;,&quot;龟&quot;=&quot;乌龟&quot;,&quot;白兔&quot;=&quot;兔子&quot;, #task 7 &quot;孩子&quot;=&quot;小孩&quot;,&quot;农民&quot;=&quot;村民&quot;,&quot;电视机&quot;=&quot;电视&quot;, &quot;饭&quot;=&quot;米饭&quot; ))%&gt;% group_by(subject,task)%&gt;% count(word2, sort = TRUE) core.lex.freq = core.lex.raw%&gt;% group_by(task, word2)%&gt;% summarise(freq = sum(n)) # number of controls n.ctr = df.tokenised%&gt;% filter(normative == &quot;1&quot;)%&gt;% distinct(subject)%&gt;% nrow() core.lex.ctrl = core.lex.raw%&gt;% mutate(present = 1)%&gt;% group_by(task, word2)%&gt;% summarise(x1distribute = sum(present)/n.ctr)%&gt;% mutate(x1distribute = round(x1distribute, 2)*100)%&gt;% arrange(desc(x1distribute)) %&gt;% mutate(top.no = 1:n())%&gt;% #filter(distribute &gt; 0.5) filter(top.no &lt; 31)%&gt;% mutate(x2chinese = case_when( word2 == &quot;了&quot; ~ &quot;FC1&quot;, word2 == &quot;的&quot; ~ &quot;FC2&quot;, word2 == &quot;一&quot; ~ &quot;one&quot;, word2 == &quot;树&quot; ~ &quot;tree&quot;, word2 == &quot;上&quot; ~ &quot;up&quot;, word2 == &quot;猫&quot; ~ &quot;cat&quot;, word2 == &quot;在&quot; ~ &quot;in&quot;, word2 == &quot;狗&quot; ~ &quot;dog&quot;, word2 == &quot;小&quot; ~ &quot;small&quot;, word2 == &quot;救&quot; ~ &quot;save&quot;, word2 == &quot;有&quot; ~ &quot;have&quot;, word2 == &quot;下来&quot; ~ &quot;come down&quot;, word2 == &quot;这个&quot; ~ &quot;this&quot;,word2 == &quot;是&quot; ~ &quot;link verb&quot;,word2 == &quot;然后&quot; ~ &quot;then&quot;, word2 == &quot;一个&quot; ~ &quot;classifier (one)&quot;,word2 == &quot;一只&quot; ~ &quot;classifier (one)&quot;, word2 == &quot;不&quot; ~ &quot;negative marker&quot;, word2 == &quot;把&quot; ~ &quot;FC3&quot;, word2 == &quot;来&quot; ~ &quot;come&quot;, word2 == &quot;梯子&quot; ~ &quot;ladder&quot;, word2 == &quot;爬&quot; ~ &quot;climb&quot;, word2 == &quot;到&quot; ~ &quot;arrive&quot;, word2 == &quot;小孩&quot; ~ &quot;kid&quot;, word2 == &quot;就&quot; ~ &quot;FC4&quot;, word2 == &quot;着&quot; ~ &quot;FC5&quot;, word2 == &quot;这&quot; ~ &quot;this&quot;, word2 == &quot;下&quot; ~ &quot;down&quot;, word2 == &quot;想&quot; ~ &quot;think&quot;, word2 == &quot;也&quot; ~ &quot;too&quot;, word2 == &quot;叫&quot; ~ &quot;shout&quot;, word2 == &quot;她&quot; ~ &quot;she&quot;, word2 == &quot;树枝&quot; ~ &quot;branch&quot;, word2 == &quot;被&quot; ~ &quot;FC6&quot;, word2 == &quot;水&quot; ~ &quot;water&quot;, word2 == &quot;吧&quot; ~ &quot;FC7&quot;, word2 == &quot;就是&quot; ~ &quot;be exactly&quot;, word2 == &quot;一&quot; ~ &quot;one&quot;, word2 == &quot;发&quot; ~ &quot;flooding&quot;, word2 == &quot;个&quot; ~ &quot;classifier&quot;, word2 == &quot;里&quot; ~ &quot;inside&quot;, word2 == &quot;伞&quot; ~ &quot;umbrella&quot;, word2 == &quot;妈妈&quot; ~ &quot;mum&quot;, word2 == &quot;他&quot; ~ &quot;he&quot;, word2 == &quot;下雨&quot; ~ &quot;raining&quot;, word2 == &quot;带&quot; ~ &quot;carry&quot;, word2 == &quot;雨&quot; ~ &quot;rain&quot;, word2 == &quot;上学&quot; ~ &quot;go to school&quot;, word2 == &quot;走&quot; ~ &quot;go&quot;, word2 == &quot;淋&quot; ~ &quot;get wet (by rain)&quot;, word2 == &quot;去&quot; ~ &quot;go&quot;, word2 == &quot;要&quot; ~ &quot;want&quot;, word2 == &quot;时候&quot; ~ &quot;time&quot;, word2 == &quot;跑&quot; ~ &quot;run&quot;, word2 == &quot;没&quot; ~ &quot;none&quot;, word2 == &quot;给&quot; ~ &quot;give&quot;, word2 == &quot;说&quot; ~ &quot;say&quot;, word2 == &quot;窗户&quot; ~ &quot;window&quot;, word2 == &quot;看&quot; ~ &quot;look&quot;, word2 == &quot;玻璃&quot; ~ &quot;glass&quot;, word2 == &quot;踢&quot; ~ &quot;kick&quot;, word2 == &quot;球&quot; ~ &quot;ball&quot;, word2 == &quot;人&quot; ~ &quot;man&quot;, word2 == &quot;电视&quot; ~ &quot;TV&quot;, word2 == &quot;那个&quot; ~ &quot;that&quot;, word2 == &quot;家&quot; ~ &quot;home&quot;, word2 == &quot;我&quot; ~ &quot;I&quot;, word2 == &quot;火腿肠&quot; ~ &quot;sausage&quot;, word2 == &quot;油&quot; ~ &quot;oil&quot;, word2 == &quot;蛋炒饭&quot; ~ &quot;egg fried rice&quot;, word2 == &quot;放&quot; ~ &quot;put&quot;, word2 == &quot;先&quot; ~ &quot;first&quot;, word2 == &quot;锅&quot; ~ &quot;wok&quot;, word2 == &quot;鸡蛋&quot; ~ &quot;egg&quot;, word2 == &quot;再&quot; ~ &quot;then&quot;, word2 == &quot;切&quot; ~ &quot;cut&quot;, word2 == &quot;倒&quot; ~ &quot;pour&quot;, word2 == &quot;米饭&quot; ~ &quot;rice&quot;, word2 == &quot;可以&quot; ~ &quot;can&quot;, word2 == &quot;米饭&quot; ~ &quot;that&quot;, word2 == &quot;家&quot; ~ &quot;home&quot;, word2 == &quot;好&quot; ~ &quot;good&quot;, word2 == &quot;做&quot; ~ &quot;do&quot;, word2 == &quot;进去&quot; ~ &quot;into&quot;, word2 == &quot;盐&quot; ~ &quot;salt&quot;, word2 == &quot;一下&quot; ~ &quot;one time&quot;, word2 == &quot;那个&quot; ~ &quot;that&quot;, word2 == &quot;狼&quot; ~ &quot;wolf&quot;, word2 == &quot;羊&quot; ~ &quot;sheep&quot;, word2 == &quot;都&quot; ~ &quot;all&quot;, word2 == &quot;喊&quot; ~ &quot;shout&quot;, word2 == &quot;吃&quot; ~ &quot;eat&quot;, word2 == &quot;真的&quot; ~ &quot;real&quot;, word2 == &quot;次&quot; ~ &quot;(this) time&quot;, word2 == &quot;又&quot; ~ &quot;again&quot;, word2 == &quot;山&quot; ~ &quot;hill&quot;, word2 == &quot;兔子&quot; ~ &quot;rabbit&quot;, word2 == &quot;乌龟&quot; ~ &quot;tortoise&quot;, word2 == &quot;它&quot; ~ &quot;it&quot;, word2 == &quot;赛跑&quot; ~ &quot;race&quot;, word2 == &quot;过&quot; ~ &quot;FC9&quot;, word2 == &quot;和&quot; ~ &quot;and&quot;, word2 == &quot;得&quot; ~ &quot;FC8&quot;, word2 == &quot;快&quot; ~ &quot;quick&quot;, word2 == &quot;睡&quot; ~ &quot;sleep&quot;, word2 == &quot;喊&quot; ~ &quot;shout&quot;, word2 == &quot;吃&quot; ~ &quot;eat&quot;, word2 == &quot;终点&quot; ~ &quot;end&quot;, word2 == &quot;很&quot; ~ &quot;very&quot;, word2 == &quot;森林&quot; ~ &quot;forest&quot;, word2 == &quot;比赛&quot; ~ &quot;games&quot;, word2 == &quot;听&quot; ~ &quot;hear&quot;, word2 == &quot;已经&quot; ~ &quot;already&quot;,word2 == &quot;开始&quot; ~ &quot;begin&quot;, word2 == &quot;洪水&quot; ~ &quot;flood&quot;, word2 == &quot;炒&quot; ~ &quot;stir fry&quot;, word2 == &quot;村民&quot; ~ &quot;villager&quot;, word2 == &quot;里面&quot; ~ &quot;inside&quot;, TRUE ~ &quot;####&quot;)) core.lex.ctrl.wide = core.lex.ctrl%&gt;% ungroup()%&gt;% gather(measures, value, c(&quot;word2&quot;, &quot;x1distribute&quot;, &quot;x2chinese&quot;))%&gt;% mutate(measures = paste(task, measures, sep = &quot;-&quot;))%&gt;% select(-task)%&gt;% spread(measures, value) core.lex.ctrl.wide%&gt;% flextable()%&gt;% set_caption(caption = &quot;Table 5 Core lexicon for different tasks&quot;) .cl-6ac0b1ca{}.cl-6ab2c998{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-6ab7d320{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-6ab7d334{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-6ab7ee82{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6ab7ee96{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6ab7eea0{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6ab7eea1{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6ab7eeaa{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6ab7eeab{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 15.3: Table 5 Core lexicon for different tasks top.noPic-CatRescue-word2Pic-CatRescue-x1distributePic-CatRescue-x2chinesePic-Flood-word2Pic-Flood-x1distributePic-Flood-x2chinesePic-Umbrella-word2Pic-Umbrella-x1distributePic-Umbrella-x2chinesePic-Window-word2Pic-Window-x1distributePic-Window-x2chineseProc-FriedRice-word2Proc-FriedRice-x1distributeProc-FriedRice-x2chineseS-CryWolf-word2S-CryWolf-x1distributeS-CryWolf-x2chineseS-TortioseHare-word2S-TortioseHare-x1distributeS-TortioseHare-x2chinese1了100FC1了91FC1了100FC1了100FC1火腿肠100sausage了100FC1乌龟100tortoise2树95tree的86FC2伞100umbrella踢100kick炒98stir fry他100he了100FC13上93up在84in妈妈95mum球95ball把95FC3来98come兔子100rabbit4在88in一个81classifier (one)他91he在91in米饭95rice狼98wolf就98FC45下来84come down这个77this下雨88raining的86FC2放88put的98FC2的98FC26猫84cat小孩74kid的86FC2到79arrive了84FC1就95FC4在95in7的84FC2是74link verb不81negative marker把77FC3油81oil在93in它93it8狗81dog救72save带81carry窗户72window然后81then羊93sheep跑93run9不79negative marker洪水67flood上学79go to school这个72this蛋炒饭81egg fried rice没91none快79quick10把77FC3有60have着79FC5是70link verb先79first放86put赛跑79race11小74small然后58then就74FC4然后70then就74FC4有86have过79FC912来74come这58this小孩70kid一个65classifier (one)锅70wok一个84classifier (one)一77one13梯子74ladder她51she雨70rain他63he的67FC2小孩79kid到74arrive14然后74then着51FC5然后67then看60look再63then人77man得74FC815爬74climb把47FC3要65want不53negative marker鸡蛋63egg喊77shout我74I16救72save树枝47branch走65go就53FC4切60cut是77link verb时候74time17是72link verb一44one去60go玻璃53glass可以56can都77all睡74sleep18这个72this水44water时候60time一51one好53good真的72real不72negative marker19有70have上42up淋60get wet (by rain)上51up是53link verb不70negative marker有72have20到67arrive吧37FC7在58in小孩51kid做51do时候70time是67link verb21着67FC5就37FC4有53have吧49FC7在51in说70say然后67then22一个65classifier (one)不35negative marker说53say电视49TV倒49pour又65again动物65####23就65FC4个35classifier这个53this这49this盐44salt然后65then听65hear24下60down去35go上51up有44have里面44inside吃63eat和65and25也60too来35come是51link verb着44FC5我42I这个60this很65very26这60this被35FC6跑51run人42man进去42into听58hear比赛63games27去58go小33small把49FC3个40classifier一下40one time呢58####爬63climb28她58she里33inside没49none那个40that之后37####把58FC3终点63end29小孩58kid中28####到47arrive里面40inside以后37####次58(this) time开始60begin30想58think到28arrive回47####家37home就是37be exactly上56up没60none 15.6 比较核心词汇分数 core.score.pwa.ctrl = df.tokenised%&gt;% #filter(Age &gt; 20 &amp; Age &lt; 65 )%&gt;% filter(normative %in% c(&quot;2&quot;,&quot;3&quot;))%&gt;% select(subject,group,task,word, AQ, Aphasia_Type, include)%&gt;% filter(include == &quot;Y&quot;)%&gt;% ## filter some functional words #anti_join(fWord)%&gt;% #merge some words mutate(word2 = dplyr::recode(word, #task 2 &quot;电视机&quot;=&quot;电视&quot;,&quot;窗&quot;=&quot;窗户&quot;,&quot;电视机&quot;=&quot;电视&quot;, &quot;男孩&quot;=&quot;小孩&quot;,&quot;小朋友&quot;=&quot;小孩&quot;,&quot;足球&quot;=&quot;球&quot;, #task3 &quot;雨伞&quot;=&quot;伞&quot;,&quot;孩子&quot;=&quot;小孩&quot;,&quot;小孩子&quot;=&quot;小孩&quot;, &quot;母亲&quot;=&quot;妈妈&quot;,&quot;电视机&quot;=&quot;电视&quot;,&quot;电视机&quot;=&quot;电视&quot;, #task4 &quot;女孩&quot;=&quot;小孩&quot;,&quot;女儿&quot;=&quot;小孩&quot;,&quot;孩子&quot;=&quot;小孩&quot;, &quot;父亲&quot;=&quot;爸爸&quot;,&quot;车子&quot;=&quot;消防车&quot;,&quot;电视机&quot;=&quot;电视&quot;, #task5 &quot;大水&quot;=&quot;洪水&quot;,&quot;女&quot;=&quot;小孩&quot;,&quot;消防员&quot;=&quot;战士&quot;,&quot;发大水&quot;=&quot;发洪水&quot;, &quot;解放军&quot;=&quot;战士&quot;,&quot;电视机&quot;=&quot;电视&quot;,&quot;电视机&quot;=&quot;电视&quot;, #task 6 &quot;兔&quot;=&quot;兔子&quot;,&quot;龟&quot;=&quot;乌龟&quot;,&quot;白兔&quot;=&quot;兔子&quot;, #task 7 &quot;孩子&quot;=&quot;小孩&quot;,&quot;农民&quot;=&quot;村民&quot;,&quot;电视机&quot;=&quot;电视&quot; ))%&gt;% select(-word)%&gt;% distinct()%&gt;% inner_join(core.lex.ctrl, by = c(&quot;task&quot;,&quot;word2&quot;))%&gt;% mutate(present = 1)%&gt;% group_by(subject, group, task)%&gt;% filter(task!=&quot;@task1&quot; &amp; task != &quot;@task9&quot;)%&gt;% summarise(score = sum(present))%&gt;% mutate(id = paste(subject, group, sep = &quot;_&quot;)) cn.matrix = data.frame( expand.grid(task2 = unique(core.score.pwa.ctrl$task), id2 = unique(core.score.pwa.ctrl$id)))%&gt;% mutate(unique_id = paste(id2, task2, sep = &quot;_&quot;)) fig.core.score = core.score.pwa.ctrl %&gt;% mutate(unique_id = paste(id, task, sep = &quot;_&quot;))%&gt;% right_join(cn.matrix)%&gt;% mutate(subject= str_extract(id2, &quot;^\\\\w*_&quot;), subject = str_remove(subject,&quot;_&quot;), task = task2, group = str_extract(id2, &quot;control|patient&quot;))%&gt;% # replace na with 0 mutate(score = coalesce(score, 0))%&gt;% groupwiseMean(score ~ group + task, data = ., conf = 0.95, digits = 3) %&gt;% ggplot(.,aes(task, Mean, fill = group))+ geom_bar(colour = &quot;black&quot;, stat = &quot;identity&quot;, position = position_dodge(.9))+ geom_errorbar(aes(ymin = Trad.lower, ymax = Trad.upper), width = .2, size = 0.7, position = position_dodge(.9))+ scale_fill_manual(values=c(&quot;grey75&quot;, &quot;white&quot;), name=&quot;Participants&quot;, labels=c(&quot;Control&quot;, &quot;PWA&quot;))+ labs(y = &quot;Core Lexicon scores&quot;, x = &quot;Task&quot;)+ theme_bw() fig.core.score ## 统计分析 core.score.pwa.ctrl.df = core.score.pwa.ctrl %&gt;% mutate(unique_id = paste(id, task, sep = &quot;_&quot;))%&gt;% right_join(cn.matrix)%&gt;% mutate(subject= str_extract(id2, &quot;^\\\\w*_&quot;), subject = str_remove(subject,&quot;_&quot;), task = task2, group = str_extract(id2, &quot;control|patient&quot;))%&gt;% # replace na with 0 mutate(score = coalesce(score, 0)) stat.test.normality = core.score.pwa.ctrl.df %&gt;% group_by(task)%&gt;% rstatix::shapiro_test(score)%&gt;% rstatix::add_significance(&quot;p&quot;) core.lex.wilcox = core.score.pwa.ctrl.df %&gt;% group_by(task)%&gt;% rstatix::wilcox_test(score ~ group)%&gt;% rstatix::add_significance(&quot;p&quot;) core.lex.wilcox.effectsize = core.score.pwa.ctrl.df %&gt;% group_by(task)%&gt;% wilcox_effsize(score ~ group) core.lex.wilcox.result = core.lex.wilcox%&gt;% select(task, n1, n2, statistic, p, p.signif)%&gt;% left_join(core.lex.wilcox.effectsize)%&gt;% select(task, n1, n2, statistic, p, p.signif, effsize, magnitude)%&gt;% mutate(effsize = round(effsize,2), statistic = round(statistic, 0)) core.lex.wilcox.result%&gt;% flextable()%&gt;% set_caption(caption = &quot;Table 7 Statistical comparisons of core lexicon scores between healthy controls and PWA in each discourse production task. &quot;) .cl-6bf0663a{}.cl-6be7c0d4{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-6beb6a72{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-6beb6a7c{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-6beb802a{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6beb8034{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6beb8035{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6beb803e{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6beb8048{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6beb8052{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 15.4: Table 7 Statistical comparisons of core lexicon scores between healthy controls and PWA in each discourse production task. taskn1n2statisticpp.signifeffsizemagnitudePic-CatRescue18182910.00004570****0.68largePic-Flood18182680.00082000***0.56largePic-Umbrella18182900.00005000****0.68largePic-Window18183110.00000240****0.79largeProc-FriedRice18182910.00004450****0.68largeS-CryWolf18183080.00000373****0.77largeS-TortioseHare18183000.00001320****0.73large 15.7 核心词汇分数和词汇丰富度相关性分析 ### correlation with aphasia severity score.aq.correlation = core.score.pwa.ctrl.df %&gt;% left_join(subjects_all)%&gt;% filter(group == &quot;patient&quot;)%&gt;% select(subject, group, task, AQ, score)%&gt;% mutate(AQ = as.numeric(AQ), task = dplyr::recode(task, &quot;@task2&quot;=&quot;Pic-Window&quot;,&quot;@task3&quot;=&quot;Pic-Umbrella&quot;, &quot;@task4&quot;=&quot;Pic-CatRescue&quot;,&quot;@task5&quot;=&quot;Pic-Flood&quot;, &quot;@task6&quot;=&quot;S-TortioseHare&quot;, &quot;@task7&quot;=&quot;S-CryWolf&quot;,&quot;@task8&quot;=&quot;Proc-FriedRice&quot;))%&gt;% group_by(task)%&gt;% cor_test(AQ, score, method = &quot;spearman&quot;) ### linguistic variables linguistic = df.tokenised%&gt;% mutate(word2 = dplyr::recode(word, #task 2 &quot;电视机&quot;=&quot;电视&quot;,&quot;窗&quot;=&quot;窗户&quot;,&quot;电视机&quot;=&quot;电视&quot;, &quot;男孩&quot;=&quot;小孩&quot;,&quot;小朋友&quot;=&quot;小孩&quot;,&quot;足球&quot;=&quot;球&quot;, #task3 &quot;雨伞&quot;=&quot;伞&quot;,&quot;孩子&quot;=&quot;小孩&quot;,&quot;小孩子&quot;=&quot;小孩&quot;, &quot;母亲&quot;=&quot;妈妈&quot;,&quot;电视机&quot;=&quot;电视&quot;,&quot;电视机&quot;=&quot;电视&quot;, #task4 &quot;女孩&quot;=&quot;小孩&quot;,&quot;女儿&quot;=&quot;小孩&quot;,&quot;孩子&quot;=&quot;小孩&quot;, &quot;父亲&quot;=&quot;爸爸&quot;,&quot;车子&quot;=&quot;消防车&quot;,&quot;电视机&quot;=&quot;电视&quot;, #task5 &quot;大水&quot;=&quot;洪水&quot;,&quot;女&quot;=&quot;小孩&quot;,&quot;消防员&quot;=&quot;战士&quot;,&quot;发大水&quot;=&quot;发洪水&quot;, &quot;解放军&quot;=&quot;战士&quot;,&quot;电视机&quot;=&quot;电视&quot;,&quot;电视机&quot;=&quot;电视&quot;, #task 6 &quot;兔&quot;=&quot;兔子&quot;,&quot;龟&quot;=&quot;乌龟&quot;,&quot;白兔&quot;=&quot;兔子&quot;, #task 7 &quot;孩子&quot;=&quot;小孩&quot;,&quot;农民&quot;=&quot;村民&quot;,&quot;电视机&quot;=&quot;电视&quot; ))%&gt;% select(subject, normative, group, task, word2)%&gt;% mutate(token = 1, character = nchar(word2))%&gt;% group_by(subject, normative, task)%&gt;% summarise(token = sum(token), character = sum(character), type = n_distinct(word2), ttr = type/token, c = log(type)/log(token), r = type/sqrt(token))%&gt;% filter(normative %in% c(&quot;2&quot;,&quot;3&quot;))%&gt;% mutate(group = dplyr::recode(normative, &quot;2&quot;=&quot;control&quot;,&quot;3&quot;=&quot;patient&quot;)) score.linguistic.correlation.full = core.score.pwa.ctrl.df%&gt;% #filter(group == &quot;patient&quot;)%&gt;% left_join(linguistic)%&gt;% mutate_all(~ifelse(is.na(.), 0, .))%&gt;% left_join(subjects_all, by = c(&quot;subject&quot;, &quot;group&quot;))%&gt;% mutate(AQ = as.numeric(AQ))%&gt;% group_by(group, task)%&gt;% cor_test(token, character, type, ttr, score, c,r,AQ, method = &quot;spearman&quot;) score.linguistic.cor.final = score.linguistic.correlation.full%&gt;% mutate(var = paste(var1, var2, sep = &quot;-&quot;), statistic = round(statistic, 0), p = round(p,4))%&gt;% filter(group == &quot;patient&quot;)%&gt;% filter(var %in% c(&quot;score-ttr&quot;,&quot;score-c&quot;,&quot;score-r&quot;,&quot;score-AQ&quot;, &quot;ttr-AQ&quot;,&quot;c-AQ&quot;,&quot;r-AQ&quot;)) score.aq.correlation %&gt;% flextable()%&gt;% set_caption(caption = &quot;Table 8 Correlations of core lexicon scores with aphasia serverity. &quot;) .cl-788ab404{}.cl-7881deba{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-7885a950{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-7885a95a{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-7885c7c8{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-7885c7d2{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-7885c7dc{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-7885c7e6{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-7885c7e7{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-7885c7f0{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 15.5: Table 8 Correlations of core lexicon scores with aphasia serverity. taskvar1var2corstatisticpmethodPic-CatRescueAQscore0.460524.46970.0555SpearmanPic-FloodAQscore0.390593.64180.1120SpearmanPic-UmbrellaAQscore0.230748.08620.3630SpearmanPic-WindowAQscore0.069901.68670.7840SpearmanProc-FriedRiceAQscore0.410573.86960.0930SpearmanS-CryWolfAQscore0.470517.13080.0511SpearmanS-TortioseHareAQscore0.510474.97930.0307Spearman chinese.TTR %&gt;% select(&quot;task&quot;,&quot;normative&quot;,&quot;ttr_mean&quot;,&quot;ttr_sd&quot;,&quot;c_mean&quot;,&quot;c_sd&quot;,&quot;r_mean&quot;,&quot;r_sd&quot;)%&gt;% arrange(task)%&gt;% flextable()%&gt;% set_caption(caption = &quot;Table 9. Lexical diversity measures of each group per task. &quot;) .cl-78ac3250{}.cl-78a2e1d2{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-78a6a790{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-78a6a79a{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-78a6bb90{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-78a6bb9a{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-78a6bba4{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-78a6bbae{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-78a6bbb8{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-78a6bbb9{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 15.5: Table 9. Lexical diversity measures of each group per task. tasknormativettr_meanttr_sdc_meanc_sdr_meanr_sdPic-CatRescue10.60.10.90.05.60.7Pic-CatRescue20.60.10.90.05.70.7Pic-CatRescue30.60.10.90.04.30.8Pic-Flood10.70.10.90.05.20.9Pic-Flood20.60.10.90.05.01.0Pic-Flood30.70.20.90.13.91.1Pic-Umbrella10.60.10.90.05.50.9Pic-Umbrella20.60.10.90.05.30.7Pic-Umbrella30.60.10.90.04.20.8Pic-Window10.60.10.90.05.20.8Pic-Window20.60.10.90.05.30.4Pic-Window30.70.20.90.13.90.8Proc-FriedRice10.60.10.90.05.10.8Proc-FriedRice20.60.10.90.05.20.7Proc-FriedRice30.70.20.90.13.71.0S-CryWolf10.50.10.90.06.00.9S-CryWolf20.50.10.80.05.80.8S-CryWolf30.60.10.90.04.41.2S-TortioseHare10.50.10.90.06.60.9S-TortioseHare20.50.10.90.06.60.9S-TortioseHare30.50.10.80.04.11.1 chinese.TTR.test %&gt;% filter(measures %in% c(&quot;c&quot;,&quot;r&quot;,&quot;ttr&quot;))%&gt;% flextable()%&gt;% set_caption(caption = &quot;Table 10 Statistical comparisions of lexical diversity measures among normative, control and PWA goups per task. &quot;) .cl-78ef1b9c{}.cl-78e1c41a{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-78e67460{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-78e67474{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-78e68d88{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-78e68d92{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-78e68d9c{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-78e68d9d{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-78e68da6{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-78e68db0{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 15.5: Table 10 Statistical comparisions of lexical diversity measures among normative, control and PWA goups per task. taskmeasures.y.group1group2n1n2statisticp.adjp.adj.signifPic-CatRescuecvalues124318352.00.7680nsPic-CatRescuecvalues134318443.00.7680nsPic-CatRescuecvalues231818199.00.7560nsPic-Floodcvalues124318455.00.8670nsPic-Floodcvalues134318414.51.0000nsPic-Floodcvalues231818159.01.0000nsPic-Umbrellacvalues124318463.50.4580nsPic-Umbrellacvalues134317465.00.3150nsPic-Umbrellacvalues231817190.00.4580nsPic-Windowcvalues124318387.01.0000nsPic-Windowcvalues134318407.51.0000nsPic-Windowcvalues231818167.01.0000nsProc-FriedRicecvalues124318308.00.6510nsProc-FriedRicecvalues134318370.01.0000nsProc-FriedRicecvalues231818168.01.0000nsS-CryWolfcvalues124318471.00.5610nsS-CryWolfcvalues134318338.00.5610nsS-CryWolfcvalues231818126.00.5610nsS-TortioseHarecvalues124318357.00.6440nsS-TortioseHarecvalues134318543.00.0390*S-TortioseHarecvalues231818234.00.0450*Pic-CatRescuervalues124318336.00.4280nsPic-CatRescuervalues134318685.00.0000****Pic-CatRescuervalues231818294.00.0000****Pic-Floodrvalues124318398.00.8690nsPic-Floodrvalues134318665.50.0000****Pic-Floodrvalues231818259.00.0030**Pic-Umbrellarvalues124318431.50.4870nsPic-Umbrellarvalues134317635.00.0000****Pic-Umbrellarvalues231817261.00.0004***Pic-Windowrvalues124318332.00.3890nsPic-Windowrvalues134318688.50.0000****Pic-Windowrvalues231818315.00.0000****Proc-FriedRicervalues124318363.00.7130nsProc-FriedRicervalues134318657.00.0001****Proc-FriedRicervalues231818281.00.0004***S-CryWolfrvalues124318432.00.4820nsS-CryWolfrvalues134318657.00.0001****S-CryWolfrvalues231818270.00.0008***S-TortioseHarervalues124318351.00.5780nsS-TortioseHarervalues134318742.00.0000****S-TortioseHarervalues231818308.00.0000****Pic-CatRescuettrvalues124318375.01.0000nsPic-CatRescuettrvalues134318344.01.0000nsPic-CatRescuettrvalues231818150.51.0000nsPic-Floodttrvalues124318441.51.0000nsPic-Floodttrvalues134318358.01.0000nsPic-Floodttrvalues231818132.01.0000nsPic-Umbrellattrvalues124318440.01.0000nsPic-Umbrellattrvalues134317379.01.0000nsPic-Umbrellattrvalues231817129.01.0000nsPic-Windowttrvalues124318404.50.8670nsPic-Windowttrvalues134318319.50.8670nsPic-Windowttrvalues231818130.50.8670nsProc-FriedRicettrvalues124318332.50.4700nsProc-FriedRicettrvalues134318268.50.1860nsProc-FriedRicettrvalues231818124.00.4700nsS-CryWolfttrvalues124318445.00.3630nsS-CryWolfttrvalues134318230.00.0270*S-CryWolfttrvalues23181879.00.0270*S-TortioseHarettrvalues124318364.01.0000nsS-TortioseHarettrvalues134318367.01.0000nsS-TortioseHarettrvalues231818165.51.0000ns score.linguistic.cor.final %&gt;% flextable()%&gt;% set_caption(caption = &quot;Table 11. Correlations of core lexicon scores with lexical diversity R.&quot;) .cl-79283ff8{}.cl-791c4888{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-7920ae14{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-7920ae28{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-7920c502{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-7920c50c{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-7920c516{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-7920c517{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-7920c520{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-7920c521{width:0.75in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;} Table 15.5: Table 11. Correlations of core lexicon scores with lexical diversity R. grouptaskvar1var2corstatisticpmethodvarpatientPic-CatRescuettrAQ0.2107660.4030Spearmanttr-AQpatientPic-FloodttrAQ-0.1301,0920.6160Spearmanttr-AQpatientPic-UmbrellattrAQ0.0159540.9540Spearmanttr-AQpatientPic-WindowttrAQ0.3706120.1330Spearmanttr-AQpatientProc-FriedRicettrAQ0.0938790.7140Spearmanttr-AQpatientS-CryWolfttrAQ-0.2001,1630.4250Spearmanttr-AQpatientS-TortioseHarettrAQ0.3706140.1350Spearmanttr-AQpatientPic-CatRescuescorettr-0.4101,3690.0884Spearmanscore-ttrpatientPic-Floodscorettr-0.6801,6320.0018Spearmanscore-ttrpatientPic-Umbrellascorettr0.1208540.6380Spearmanscore-ttrpatientPic-Windowscorettr-0.5001,4530.0347Spearmanscore-ttrpatientProc-FriedRicescorettr-0.4101,3630.0937Spearmanscore-ttrpatientS-CryWolfscorettr-0.7001,6490.0012Spearmanscore-ttrpatientS-TortioseHarescorettr-0.4001,3570.0996Spearmanscore-ttrpatientPic-CatRescuescorec-0.1101,0780.6580Spearmanscore-cpatientPic-Floodscorec-0.5501,5030.0177Spearmanscore-cpatientPic-Umbrellascorec0.4405410.0667Spearmanscore-cpatientPic-Windowscorec-0.3501,3080.1550Spearmanscore-cpatientProc-FriedRicescorec-0.2001,1650.4220Spearmanscore-cpatientS-CryWolfscorec-0.3201,2800.1940Spearmanscore-cpatientS-TortioseHarescorec-0.1201,0890.6240Spearmanscore-cpatientPic-CatRescuescorer0.8001980.0001Spearmanscore-rpatientPic-Floodscorer0.8301690.0000Spearmanscore-rpatientPic-Umbrellascorer0.8101820.0000Spearmanscore-rpatientPic-Windowscorer0.6103800.0075Spearmanscore-rpatientProc-FriedRicescorer0.8701290.0000Spearmanscore-rpatientS-CryWolfscorer0.8701240.0000Spearmanscore-rpatientS-TortioseHarescorer0.8801170.0000Spearmanscore-rpatientPic-CatRescuescoreAQ0.4605240.0555Spearmanscore-AQpatientPic-FloodscoreAQ0.3905940.1120Spearmanscore-AQpatientPic-UmbrellascoreAQ0.2307480.3630Spearmanscore-AQpatientPic-WindowscoreAQ0.0699020.7840Spearmanscore-AQpatientProc-FriedRicescoreAQ0.4105740.0930Spearmanscore-AQpatientS-CryWolfscoreAQ0.4705170.0511Spearmanscore-AQpatientS-TortioseHarescoreAQ0.5104750.0307Spearmanscore-AQpatientPic-CatRescuecAQ0.4205660.0874Spearmanc-AQpatientPic-FloodcAQ-0.0881,0540.7290Spearmanc-AQpatientPic-UmbrellacAQ0.2007760.4270Spearmanc-AQpatientPic-WindowcAQ0.3905900.1090Spearmanc-AQpatientProc-FriedRicecAQ0.1408350.5840Spearmanc-AQpatientS-CryWolfcAQ0.1308400.5980Spearmanc-AQpatientS-TortioseHarecAQ0.5004840.0363Spearmanc-AQpatientPic-CatRescuerAQ0.6003920.0105Spearmanr-AQpatientPic-FloodrAQ0.4605240.0569Spearmanr-AQpatientPic-UmbrellarAQ0.2007760.4270Spearmanr-AQpatientPic-WindowrAQ0.1208560.6440Spearmanr-AQpatientProc-FriedRicerAQ0.1508190.5390Spearmanr-AQpatientS-CryWolfrAQ0.6303620.0065Spearmanr-AQpatientS-TortioseHarerAQ0.6803120.0026Spearmanr-AQ "],["r语言学习资源分类汇总.html", "Chapter 16 R语言学习资源分类汇总 16.1 统计建模 16.2 机器学习 16.3 数据整理 16.4 数据可视化 16.5 网络分析 16.6 文本分析 16.7 网络抓取 16.8 社交媒体分析 16.9 语音分析 16.10 学科研究 16.11 R-markdown", " Chapter 16 R语言学习资源分类汇总 16.1 统计建模 首先，很多人了解R并开始使用它，尤其是用于研究目的，通常是因为他们需要进行一些统计建模，而R有相应的包可以完成这项工作。事实上，统计建模是R的一个重要优势。对于简单的统计建模，像SPSS这样的不需要编码的程序可以和R一样出色，许多人仍然依赖SPSS进行统计建模。然而，SPSS不是开源的，它是由公司拥有的，而R是开源的。这意味着全球的R用户可以通过开发包来丰富R的功能，而不是依赖于公司内部的一小部分人。如果需要更复杂和精密的模型，可以简单地用Google搜索：“model name” with R。 Summary and Analysis of Extension Program Evaluation in R 当我需要了解如何进行各种t检验、ANOVA或回归分析时，我常用的参考。 16.2 机器学习 Tidymodels packages The caret package (short for Classification And REgression Training) is a set of functions that attempt to streamline the process for creating predictive models. 16.3 数据整理 R for Data Science by Garrett Grolemund和Hadley Wickham 我的工作坊的教程。 其他书籍: Data Science Live Book The Pirate’s Guide to R 16.4 数据可视化 ggplot2: Elegant Graphics for Data Analysis。 cookbook R。 R Graphics Cookbook, 2nd edition。 地图可视化Geocomputation with R 流程图DiagramR 16.5 网络分析 Network Analysis in R by Robert Wiederstein An Introduction to Network Analysis for Psycholinguists by Cynthia Siew 网络可视化 Static and dynamic network visualization with R Introduction to Network Analysis with R ggnet2: network visualization with ggplot2 论文。 16.6 文本分析 Corpus Linguistics by Alvin Cheng-Hsien Chen Text mining with R Computational Stylistics Group is a cross-institutional research team focused on computer-assisted text analysis, stylometry, authorship attribution, sentiment analysis, and the like stuff. The research projects conducted by the team members could be described as an intersection of linguistics, literary criticism, and computer science – however the best name here would be “Digital Humanities”. The group is based mostly in Kraków, at the Institute of Polish Language (Polish Academy of Sciences), but also at the Jagiellonian University and the University of Antwerp. 16.7 网络抓取 rvest: easy web scraping with R 教程 1 教程 2 16.8 社交媒体分析 随着越来越多的人深深沉浸在社交媒体中，分析他们的语言行为可能会揭示出有价值的信息。 Learning Social Media Analytics with R 教程 1 16.9 语音分析 wrassp 是R的一个封装包，围绕Michel Scheffers的libassp（高级语音信号处理器）构建。libassp库旨在提供处理大多数常见音频格式的语音信号文件并执行语音科学/语音科学中常见分析的功能。这包括计算共振峰、基频、均方根、自动相关、一系列频谱分析、零交叉率、滤波等。这个封装包为R提供了libassp信号处理功能的大部分子集，并以一种（希望）用户友好的方式提供给用户。 -教程 soundgen 基于seewave的功能，增加了用于声音合成、操作和分析的高级函数（参见关于声音合成的小册子）。教程 EMU-R: EMU语音数据库管理系统（EMU-SDMS）是一组软件工具，旨在尽可能接近一个集成解决方案，用于生成、操作、查询、分析和管理语音数据库。手册 16.10 学科研究 文献计量bibliometrix Using R for psychological research The psych and psychTools packages 16.11 R-markdown 当你希望输出你的R工作时，将代码与分析嵌入在一起是理想的选择。这在Word或其他文件类型中并不容易实现。感谢r markdown包，你现在可以： 将单个R Markdown文档编译为不同格式的报告，如PDF、HTML或Word。 创建可以直接交互运行代码块的笔记本。 R Markdown: The Definitive Guide Tufte DataTables 生成网站和博客。 教程: blogdown: Creating Websites with R Markdown 编写多章节的书籍。 教程: bookdown: Authoring Books and Technical Documents with R Markdown 制作演示幻灯片 xaringan, creating remark.js through R Markdown reveal.js Presentations reveal.js 创建R的交互式教程 教程 pkgdown Markdown 语法 - 字体 + 我是宋体 + 我是楷体- 字号 + 我是尺寸 + 我是尺寸 - 颜色 + 我是蓝色 + 我是紫色 - 背景 + 黑色背景白字 对齐 这是居中对齐的段落 这是右对齐的段落 分散对齐 缩进 首行缩进：这是一行以上的段落，第1行进行了缩进，之后所有行没有缩进。缩进的宽度是可以调节的，这里展示的常见的缩进两个汉字宽度的形式，可以设置为2em或32px。 每当我开展R语言的工作坊时，我首先需要向参与者解释为什么他们应该学习R语言。 下面是使用R可以做的一些很酷的事情，涵盖了从数据分析、统计建模、可视化到制作幻灯片、仪表板、博客文章、互动教程等多个方面。 "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
